[
  {
    "title": "具备阅读长文能力的重要性",
    "url": "https://www.v2ex.com/t/879381",
    "summary": "delegate: <p>首先来做两个测验，注意长句和短句的区别：</p>\n<p>Ⅰ.文学语言应当尽量使用浅显易懂的语言进行表达，一部作品的伟大之处在于作者的思想而不在于华丽的辞藻和繁复的修辞。</p>\n<p>Ⅱ. 文学语言应当尽量浅显，尽量易懂，作品因作者思想而伟大，而不在于辞藻和修辞。</p>\n<p>可以看得出第一句阅读障碍大于第二句，接下来我再举一个长文与短文的例子。</p>\n<p>Ⅰ.卢梭相信，一个理想的社会建立于人与人之间而非人与 goverment 之间的契约关系。与约翰·洛克一样，卢梭认为 goverment 的权力来自被统治者的认可。卢梭声称，一个完美的社会是为人民的“公共意志”所控制的，虽然他没有定义如何达成这个目标，但他建议由公民团体组成的代议机构作为立法者，通过讨论来产生公共意志。\n社会契约论的主要表述是探究是否存在合法的 politics 权威，“人是生而自由的，但却无往不在枷锁之中”。他所说的 politics 权威在我们的自然状态中并不存在，所以我们需要一个社会契约。在社会契约中，每个人都放弃天然自由，而获取契约自由；在参与政治的过程中，只有每个人同等地放弃全部天然自由，转让给整个集体，人类才能得到平等的契约自由。(来自维基百科)</p>\n<p>Ⅱ.卢梭相信，一个理想的社会，建立于人与人之间，而非人与 goverment 之间的契约关系。</p>\n<p>与约翰·洛克一样，卢梭认为，goverment 的权力来自，被统治者的认可。</p>\n<p>卢梭声称，一个完美的社会，是为人民的“公共意志”所控制的，虽然他没有定义，如何达成这个目标。</p>\n<p>但他建议，由公民团体组成的代议机构，作为立法者，通过讨论，来产生公共意志。</p>\n<p>请读完后回答两个问题：</p>\n<p>一、在第一个例子中，是否感觉到第二句比第一句更加容易理解？\n二、在第二个例子中，读完第一句后再读第二句，是否开始觉得可以理解了。</p>\n<p>如果你的答案是两个“是”，那么说明接受测验者不具备阅读长文的能力，尤其是在阅读科研论文上，可能会倍觉痛苦。那么产生这种问题的原因是什么呢？我认为，首先是内心浮躁，因为这些文字如果拆开成短句，被按照句意进行划分，就如同小学生用手指指着书本才能阅读一样。</p>\n<p>这很好的解释了，为什么很多 V2er 根本不看帖子内容就开始回复，只输出情绪而不输出任何有意义的论证和观点。因为他们并不在乎作者想表达什么，只想宣泄情绪，所以只看标题就开始谩骂，或者甩下几个不负责任的汉字就继续带着情绪浏览其他帖子，直到整个论坛变得乌烟瘴气为止。</p>",
    "publish_time": "2022-09-12 09:54:00",
    "source": {
      "name": "v2ex_hot",
      "desc": "v2ex 最热主题",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/v2ex.png"
    }
  },
  {
    "title": "人为什么害怕关系的缺失？",
    "url": "https://www.v2ex.com/t/879407",
    "summary": "justanetizen: <p>都 2202 年了，程序员都用上 nosql 了，为什么还有无数人沉迷于所谓的人脉、人际关系里不能自拔？</p>",
    "publish_time": "2022-09-12 12:20:41",
    "source": {
      "name": "v2ex_hot",
      "desc": "v2ex 最热主题",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/v2ex.png"
    }
  },
  {
    "title": "watch s5 有必要换 s8 吗？",
    "url": "https://www.v2ex.com/t/879419",
    "summary": "leon912: <p>s5 发售开始戴到现在，除了续航短，好像也没啥不满意的地方。\n大家觉着有换 s8 的必要吗？</p>",
    "publish_time": "2022-09-12 13:19:10",
    "source": {
      "name": "v2ex_hot",
      "desc": "v2ex 最热主题",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/v2ex.png"
    }
  },
  {
    "title": "有人存身份证号时丢掉最后一位吗",
    "url": "https://www.v2ex.com/t/879424",
    "summary": "iseki: 最后一位校验位去掉，剩下的部分按数字存 int64 理论上没问题，有人考虑这么干吗",
    "publish_time": "2022-09-12 13:32:44",
    "source": {
      "name": "v2ex_hot",
      "desc": "v2ex 最热主题",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/v2ex.png"
    }
  },
  {
    "title": "鸿雁输入法——整句输入法中一颗冉冉升起的新星",
    "url": "https://www.v2ex.com/t/879486",
    "summary": "dfgddgf: <p>鸿雁输入法经过重大升级，在整句输入上做到物理上的极致优化。</p>\n<p>首先是语料库的升级。目前的语料库有 150GB ，包含 702 亿个字符，有效汉字字符 380 亿个。</p>\n<p>其中：\nepubee 整站电子书 5.3 万本，65.6GB\n全网能找到的所有微博语料，38.6GB\n百度百科 500 多万条，15.6GB\n中文维基百科全部条目，10.1GB\n各类新闻语料，12.6GB\n微信公众号语料，2.9GB\n联合国平行语料库中文部分，1.4GB\n1946 年-2003 年人民日报全部数据纯文本，3.1GB</p>\n<p><a href=\"https://ai.tencent.com/ailab/nlp/zh/index.html\" rel=\"nofollow\">腾讯的自然语言处理研究</a>开源了一个<a href=\"https://ai.tencent.com/ailab/nlp/zh/embedding.html\" rel=\"nofollow\">大规模中文词向量</a>: 提供在 300 亿词的语料上训练的、包含 8 百万词汇的中文词向量数据，向量维度为 200 维。</p>\n<p>以腾讯的大规模中文词向量作为比较：</p>\n<p>腾讯的大规模中文词向量是在 300 亿词的语料上训练的；鸿雁输入法的语料包含 702 亿个字符，有效汉字字符 380 亿个。\n腾讯的大规模中文词向量包含 8 百万词汇(最新版是 1200 万)；鸿雁输入法包含的词汇量是 2471 万，而且这个数量刚好位于有序与无序的临界点。也就是超过 2471 万的词汇量对词语的质量没有太大提升，反而会浪费储存空间。\n腾讯的大规模中文词向量依赖于结巴分词这样的分词软件，会出现分词不完全的情况；鸿雁输入法的分词采用的是机械分词，不会遗漏任何一个可能的词汇，并且从 2-16 个长度的词语全部进行统计。\n腾讯的大规模中文词向量语料如果猜测的没错的话，主要是来源于网页抓取；鸿雁输入法同样大部分也是来源于网页抓取，不过数量更加庞大，选择的语料库是经过精心挑选的，具备典型性。</p>\n<p>腾讯的大规模中文词向量底层采用 word2vec 技术，将分析的词语赋予一个多维空间的向量，依据向量的空间距离可以获得不同词语的相似度；</p>\n<p><img alt=\"image\" class=\"embedded_image\" rel=\"noreferrer\" src=\"https://s1.ax1x.com/2022/09/12/vXY7gs.png\" /></p>\n<p>近距离语义分析，只有在切换输入法的情景才会有效，腾讯的语料库嵌入数据集，1200 万的词条解压后，100 维的版本有 12GB ，200 维的版本有 22GB ，占用空间太大。而且需要相对复杂的余弦相似度运算。\n如果要把腾讯的大规模中文词向量用于输入法，还需要调整算法，对一个已知词语的前面和后面的词语进行关联概率统计，概率模型是马尔可夫链。</p>\n<p>鸿雁输入法基于词频统计的最大概率排序，同样可以对千万级的词汇进行统计。如果把 2-4 个字的词语前后组合排列，就构成一个更大的词语。在不考虑中文语法规则得情况下，把一个句子当作一个词语，和词语一样，按照语料库的出现概率大小进行排序，同样可以实现整句输入的效果。只要保证足够大、足够全面的语料样本，语句按照词语分割后，按照所有分词组合对应的概率排序，就可以获得质量相当高的整句输入法。鸿雁输入法在语料库分析的时候，最大的词语长度是 16 ，这个长度已经足以覆盖绝大部分中文语句的使用场合。</p>\n<p>下图是不同长度的词语出现的数量横向对比图</p>\n<p><img alt=\"image\" class=\"embedded_image\" rel=\"noreferrer\" src=\"https://s1.ax1x.com/2022/09/12/vXYBND.png\" /></p>\n<p>根据上图可以看出，中文词语在超过 8 个字的长度，比例大幅减少。中文词语的长度主要集中在 2-6 个字。</p>\n<p>在对 702 亿个字符的语料库统计后，获得 70 亿个词语的数据，约为 63GB 。</p>\n<p>下面就面临一个高频词语的选择问题。</p>\n<p>一个输入法包含 70 亿个数据，显然这个数据过于庞大。</p>\n<p>如果选择的高频词语数量过少，那么输入法的词语准确率就会偏低。\n如果选择的高频词语数量太大，因为各种原因产生的错误的词语就会增多。</p>\n<p>选择高频词，需要兼顾数据储存空间的效率和语义复杂度的涵盖率。</p>\n<p>有一个简单的办法:</p>\n<p>1.把 702 亿个字符的语料库分割成 791 个区块，统计出现同一个词语的区块数量。区块数是 1-791 ，而最常见的词语数量数以亿计，最罕见的词语数量只有 1 。使用区块数代替词语数量数，可以将数值缩小在一个相对均匀的范围内。</p>\n<p>2.把区块数目相同的词语看作一个集合，并统计这个集合的词语数量，这样就得到一个类似于直方图的统计图</p>\n<p>3.得到图像显示，在这种方式下的词频关系图并不是完全和长尾效应完全一致的，而是一种泊松分布和指数增长的结合体。这在 2 个字的词语统计分布图中尤为明显。随着词语长度的增加，高频词的出现次数和比例大幅度减小，低频词的出现次数和比例随着词语的长度增加而大幅增长。相对高频的词语位于这个与长尾效应类似的曲线尾部和中部。</p>\n<p>1 单个字</p>\n<p><img alt=\"image\" class=\"embedded_image\" rel=\"noreferrer\" src=\"https://s1.ax1x.com/2022/09/12/vXY0AO.png\" /></p>\n<p>2 个字的词语</p>\n<p><img alt=\"image\" class=\"embedded_image\" rel=\"noreferrer\" src=\"https://s1.ax1x.com/2022/09/12/vXYD4e.png\" /></p>\n<p>3 个字的词语</p>\n<p><img alt=\"image\" class=\"embedded_image\" rel=\"noreferrer\" src=\"https://s1.ax1x.com/2022/09/12/vXYs9H.png\" /></p>\n<p>4 个字的词语</p>\n<p><img alt=\"image\" class=\"embedded_image\" rel=\"noreferrer\" src=\"https://s1.ax1x.com/2022/09/12/vXYy3d.png\" /></p>\n<p>5 个字的词语</p>\n<p><img alt=\"image\" class=\"embedded_image\" rel=\"noreferrer\" src=\"https://s1.ax1x.com/2022/09/12/vXY6gA.png\" /></p>\n<p>6 个字的词语</p>\n<p><img alt=\"image\" class=\"embedded_image\" rel=\"noreferrer\" src=\"https://s1.ax1x.com/2022/09/12/vXYcjI.png\" /></p>\n<p>7 个字的词语</p>\n<p><img alt=\"image\" class=\"embedded_image\" rel=\"noreferrer\" src=\"https://s1.ax1x.com/2022/09/12/vXY2ut.png\" /></p>\n<p>4.以区块数量的某一数值作为边界，对 70 亿个词语进行数据缩减，只保留相对高频的词语。大部分图像显示为长尾图，横轴代表区块数量，竖轴代表同一区块数量对应的词语数量。横轴越小，斜率越大，说明因为词语对应字的排列组合导致无序效应在罕见的词语中越来越明显。为了覆盖足够高的语义复杂度，只需要计算曲线斜率最大值按照一定比例缩小后对应的点，就是无序与有序的临界点。\n临界点的斜率是曲线最大斜率的固定比例的关系，如果选择比较合适的临界点处，语义复杂度正在增长，还没到无序到不受控制的增长程度。\n临界点选择，使用暴力穷举法，试用不同的比例参数，可以看到，在选择某个参数附近后，分割获得的高频词语数量增长趋于稳定。这个参数就是理想的分割参数。</p>\n<p>下图显示通过实验获得的理想参数下的临界点位置：</p>\n<p>1 单个字</p>\n<p><img alt=\"image\" class=\"embedded_image\" rel=\"noreferrer\" src=\"https://s1.ax1x.com/2022/09/12/vXYRDP.png\" /></p>\n<p>2 个字的词语</p>\n<p><img alt=\"image\" class=\"embedded_image\" rel=\"noreferrer\" src=\"https://s1.ax1x.com/2022/09/12/vXYWHf.png\" /></p>\n<p>3 个字的词语</p>\n<p><img alt=\"image\" class=\"embedded_image\" rel=\"noreferrer\" src=\"https://s1.ax1x.com/2022/09/12/vXYhE8.png\" /></p>\n<p>4 个字的词语</p>\n<p><img alt=\"image\" class=\"embedded_image\" rel=\"noreferrer\" src=\"https://s1.ax1x.com/2022/09/12/vXY4US.png\" /></p>\n<p>5 个字的词语</p>\n<p><img alt=\"image\" class=\"embedded_image\" rel=\"noreferrer\" src=\"https://s1.ax1x.com/2022/09/12/vXY54g.png\" /></p>\n<p>6 个字的词语</p>\n<p><img alt=\"image\" class=\"embedded_image\" rel=\"noreferrer\" src=\"https://s1.ax1x.com/2022/09/12/vXYoCQ.png\" /></p>\n<p>7 个字的词语</p>\n<p><img alt=\"image\" class=\"embedded_image\" rel=\"noreferrer\" src=\"https://s1.ax1x.com/2022/09/12/vXYT3j.png\" /></p>\n<p>15 个字的词语</p>\n<p><img alt=\"image\" class=\"embedded_image\" rel=\"noreferrer\" src=\"https://s1.ax1x.com/2022/09/12/vXYHvn.png\" /></p>\n<p>16 个字的词语</p>\n<p><img alt=\"image\" class=\"embedded_image\" rel=\"noreferrer\" src=\"https://s1.ax1x.com/2022/09/12/vXYquq.png\" /></p>\n<p>使用临界算法初步获得约为 2400 万的词语。</p>\n<p><img alt=\"image\" class=\"embedded_image\" rel=\"noreferrer\" src=\"https://s1.ax1x.com/2022/09/12/vXYLD0.png\" /></p>\n<p>加入其他高权词库，合计 2471 万。</p>\n<p>这个数量级别的词库，到底整句输入法准确率怎么样呢？</p>\n<p>上图</p>\n<p><img alt=\"image\" class=\"embedded_image\" rel=\"noreferrer\" src=\"https://s1.ax1x.com/2022/09/12/vXYObV.png\" /></p>\n<p>使用搜狗拼音，同样可以打出正确的语句。</p>\n<p>值得注意的是，搜狗输入法是经过高度算法优化的，一定包含中文语法逻辑。\n而鸿雁输入法仅仅是采用 rime 输入法的整句引擎和 1-16 个字长度的词语概率统计。rime 输入法的整句引擎的算法没有仔细看，应该是基于拼音不同拆分，对应的语句组合相应的概率进行优先级排序。</p>\n<p>对于底层细节的了解，作者就没有进行更多的整句测试。有兴趣的可以打开中央电视台，按照电视台播音打出语句，测试准确度怎么样。</p>\n<p>包含 2471 万词语的鸿雁输入法并没有采用中文语法算法的引擎，仅仅依靠庞大的词语频率统计，在整句输入功能上已经和搜狗输入法不相上下(这只是个人的看法，是否真实需要广大网友的验证)。</p>\n<p>在鸿雁输入法之前的描述，可以得知，鸿雁输入法自带的单字拼音库，是目前互联网上公开的最为准确的拼音库。\n原来词语的拼音采用暴力穷举的方法，正确的拼音一定有，但是还存在大量的字的拼音是正确的，词语的拼音确是错误的情况。最近，使用现代汉语词典的数据对词语拼音大幅优化，这种情况大大改善。</p>\n<p>同时优化了国家拼音标准移植到 rime 输入法后存在的缺陷。</p>\n<p>更改特殊拼音</p>\n<p>㕶&nbsp;&nbsp;&nbsp; n ng&nbsp; 呒&nbsp;&nbsp;&nbsp; fu m&nbsp; 呣&nbsp;&nbsp;&nbsp; m mou&nbsp; 哏&nbsp;&nbsp;&nbsp; gen hen n&nbsp; 哼&nbsp;&nbsp;&nbsp; heng hng&nbsp; 哽&nbsp;&nbsp;&nbsp; geng ng ying&nbsp; 唔&nbsp;&nbsp;&nbsp; m n ng wu&nbsp; 嗯&nbsp;&nbsp;&nbsp; n ng&nbsp; 嘸&nbsp;&nbsp;&nbsp; fu m wu&nbsp; 噷&nbsp;&nbsp;&nbsp; hen hm xin&nbsp; 姆&nbsp;&nbsp;&nbsp; m mu</p>\n<p>n&nbsp;&nbsp;&nbsp; --&gt;&nbsp;&nbsp;&nbsp; en\nm&nbsp;&nbsp;&nbsp; --&gt;&nbsp;&nbsp;&nbsp; mu\nhng&nbsp;&nbsp;&nbsp; --&gt;&nbsp;&nbsp;&nbsp; heng\nng&nbsp;&nbsp;&nbsp; --&gt;&nbsp;&nbsp;&nbsp; en\nhm&nbsp;&nbsp;&nbsp; --&gt;&nbsp;&nbsp;&nbsp; hen</p>\n<p>在单个字的拼音存在多个声母后，使用 rime 输入法相关的拼音输入会出现优先级被这些特殊的拼音占用的情况。</p>\n<p>在从底层消除这些特殊的拼音后，这种情况将彻底消失。</p>\n<p>以前输入 ng ，“那个”这样的词语将不会出现在候选列表，除非输入“nge”或者其他组合。\n“n”“m”作为拼音的首字母输入的时候，以前不能显示“你”“们”这样的词语，现在这种情况将不复存在。</p>\n<p>鸿雁输入法同时优化了 rime 输入法另外一个缺陷。</p>\n<p>rime 输入法有两个拼音输入引擎，一个是基于词语的，另外一个是基于语句的。</p>\n<p>词语引擎不能支持整句输入，整句输入引擎使用空格作为分词的按键，这个设计并不合理。\n一般用户都习惯使用空格键作为上屏的按键，因为这个按键尺寸最大，而且可以说是跟手距离最近的按键。使用空格分词对词语输入转确率提升不大，使用空格上屏需要按两次，这会影响输入舒适度的设计。一般拼音分词，如果前面的词语出现错误，可以使用 TAB 键或者退格键进行词语重新选择。</p>\n<p>稍微修改了一些 rime 输入法的源代码，空格键去除分词功能，改为上屏键。</p>\n<p>鸿雁输入法包含五笔、全拼、双拼方案。理论上五笔方案应该重码率更低，也支持整句输入，输入体验更为流畅，作者不懂五笔，有待广大网友的测试。</p>\n<p>下图是搜狗输入法和鸿雁输入法语义复杂度的对比，以拼音“jidong”为例：</p>\n<p><img alt=\"image\" class=\"embedded_image\" rel=\"noreferrer\" src=\"https://s1.ax1x.com/2022/09/12/vXYx5F.png\" /></p>\n<p><img alt=\"image\" class=\"embedded_image\" rel=\"noreferrer\" src=\"https://s1.ax1x.com/2022/09/12/vXtp8J.png\" /></p>\n<p>搜狗输入法仅有 14 个候选词语；鸿雁输入法有 83 个候选词语。</p>\n<p>这只是随机抽取的词语，如果遇到罕见的拼音，那么一定会出现搜狗输入法不能打出的拼音，而鸿雁输入法可以打出的词语。</p>\n<p>候选词语数量，上面的例子约为六倍，候选词语倍数是十倍，二十倍的应该是存在的。</p>\n<p>输入安装包仅仅包含 262 万的一个轻量版的词语，这是因为 windows 平台的 rime 输入法支持最大数据量有限，超过一定数据量将无法生成索引。\n在 linux 平台可以成功生成 2471 万的索引，这个索引拿到 windows 平台和安卓平台都可以使用。</p>\n<p>用户需要注意，如果轻量级的词库不能满足实际输入中的准确度需求，需要安装另外一个“预编译词库索引(拼音、五笔)_2471 万词语增强包”。</p>\n<p>在 linux 平台生成词库索引需要 22.2GB 的内存</p>\n<p><img alt=\"image\" class=\"embedded_image\" rel=\"noreferrer\" src=\"https://s1.ax1x.com/2022/09/12/vXt929.png\" /></p>\n<p>输入法安装包自带 262 万轻量级词库生成的词库索引</p>\n<p><img alt=\"image\" class=\"embedded_image\" rel=\"noreferrer\" src=\"https://s1.ax1x.com/2022/09/12/vXYvUU.png\" /></p>\n<p>安装“预编译词库索引(拼音、五笔)_2471 万词语增强包”后的词库索引</p>\n<p><img alt=\"image\" class=\"embedded_image\" rel=\"noreferrer\" src=\"https://s1.ax1x.com/2022/09/12/vXtSC4.png\" /></p>\n<p>可以看到词库索引从 80 多兆上升到 800 多兆</p>\n<p>希望鸿雁输入法能够成为文字工作者、学生、老师、社会各界人士常用的输入法软件。</p>\n<p>以上，从技术细节和理论上说明了鸿雁输入法更懂中文，具体实际使用中的体验是否能够达到预期，还需要广大网友的亲身体验。</p>\n<p><strong>下载链接：</strong></p>\n<p><a href=\"https://hong-yan.lanzouw.com/b00vvkivc\" rel=\"nofollow\">https://hong-yan.lanzouw.com/b00vvkivc</a>\n密码:1234</p>",
    "publish_time": "2022-09-12 17:53:43",
    "source": {
      "name": "v2ex_hot",
      "desc": "v2ex 最热主题",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/v2ex.png"
    }
  }
]