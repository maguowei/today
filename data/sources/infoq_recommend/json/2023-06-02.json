[
  {
    "title": "Patcher：实现基础设施即代码持续更新的利器",
    "url": "https://www.infoq.cn/article/Sq6akvwJgu6LzuBM5pkx",
    "summary": "<p>Gruntwork<a href=\"https://blog.gruntwork.io/introducing-patcher-a-new-tool-for-keeping-infrastructure-code-up-to-date-e65b0c203b6b\">发布</a>\"Patcher的Beta测试版。该工具可以自动保持基础设施即代码的更新，即使有重大更改也没问题。</p><p>&nbsp;</p><p>在撰写本文时，Patcher允许将<a href=\"https://gruntwork.io/reference-architecture/\">参考架构</a>\"从<a href=\"https://docs.aws.amazon.com/securityhub/latest/userguide/cis-aws-foundations-benchmark.html\">CIS AWS Foundation Benchmark</a>\" 1.4版本升级到1.5版本。该版本引入了200多项更改并修复了3项重大更改。参考架构是一系列建议和最佳实践，将来自Gruntwork的<a href=\"https://gruntwork.io/infrastructure-as-code-library/\">基础设施即代码库</a>\"组装成AWS上的端到端技术栈。Patcher的目标是让用户可以管理Gruntwork基础设施即代码库的所有升级工作，并自动执行一系列的操作。</p><p>&nbsp;</p><p>用户可以从GitHub存储库安装Patcher（在撰写本文时，访问其存储库还需要向Gruntwork申请）。Patcher使用Docker在沙盒环境中执行升级。</p><p>&nbsp;</p><p>安装完成后，要升级IaC存储库，Patcher会执行以下步骤：</p><p>查找依赖项更新应用更改的补丁检查更改部署</p><p>&nbsp;</p><p>Patcher使用以下命令查找并更新依赖项：</p><p><code lang=\"null\">patcher upgrade</code></p><p>&nbsp;</p><p>该工具会分析源代码并自动发现依赖项、每个依赖项的版本，以及是否有新版本。在下面的示例中，Patcher发现了一些需要升级的依赖项。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f2/f22c4bdaf32faf29066e39a46db35fae.jpeg\" /></p><p></p><p><a href=\"https://blog.gruntwork.io/introducing-patcher-a-new-tool-for-keeping-infrastructure-code-up-to-date-e65b0c203b6b\">Patcher如何显示需要升级的依赖项</a>\"</p><p>&nbsp;</p><p>Patcher允许维护人员定义一个补丁，指定如何转换代码以完成重大更改。应用于代码的补丁通过YAML文件描述。Patcher会执行YAML代码中定义的步骤。那些步骤可能是任意命令。例如，tflint（一种强制执行与安全组相关的新建议的方法）的补丁可以指定为：</p><p><code lang=\"null\">name: \"Add tflint hook to Terragrunt configuration for CIS compliance checks\"\nauthor: Gruntwork \nimage: gruntwork/patcher_bash_env:v0.0.12\nsteps:\n  - name: \"Create tflint configuration\"\n    run: create_tf_lint_config.sh\n  - name: \"Add to the root terragrunt.hcl a hook for tflint\"\n    run: add_hook.sh</code></p><p>&nbsp;</p><p>Patcher在已定义的Docker镜像中执行升级。这使得代码可移植，并且能够通过限制镜像可以查看的内容和执行的操作来保证用户的安全。当Patcher升级完成后，它会显示应用的所有补丁的摘要信息。这样，用户就可以查看更改并应用它们。</p><p>&nbsp;</p><p>可以使用git diff进行检查，因为Patcher会将所有的更改都保存在本地存储库中。然后，用户可以决定提交所有更改，还是进行部分更改。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ef/ef7a980fa6c7481e48a80238ed621cc0.jpeg\" /></p><p></p><p><a href=\"https://blog.gruntwork.io/introducing-patcher-a-new-tool-for-keeping-infrastructure-code-up-to-date-e65b0c203b6b\">在Patcher升级后执行git diff</a>\"</p><p>&nbsp;</p><p>在上面的屏幕截图中，作为从CIS 1.4到1.5升级的一部分，Patcher做了一些更改，应用了一些补丁。</p><p>&nbsp;</p><p>Patcher的第一个版本专注于支持从CIS 1.4到1.5的迁移，但Gruntwork的愿景是将Gruntwork基础设施即代码和参考架构的所有更新都自动化。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/04/patcher-iac-upgrade/\">https://www.infoq.com/news/2023/04/patcher-iac-upgrade/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/Rxk0KGocM5ygWH8mS90v\">谷歌发布云基础设施可靠性指南，帮助消费者做出正确决策</a>\"</p><p><a href=\"https://www.infoq.cn/article/6puCE2lCFJPgz0YLexg5\">Medium的Kubernetes基础设施</a>\"</p>",
    "publish_time": "2023-06-02 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "降本增效三部曲：算好帐、定目标、抓增效 ｜ QCon闭门会",
    "url": "https://www.infoq.cn/article/ShUXt8wQpm9Zc17dXxDg",
    "summary": "<p>在5月26日，<a href=\"https://qcon.infoq.cn/2023/guangzhou/schedule\">QCon全球开发者大会（广州站）</a>\"顺利落地，在现场，InfoQ 特别策划了五场闭门会，主题分别为《企业在 LLM、AIGC 浪潮下的研发探索》《DevOps vs 平台工程，必要性和 ROI 探讨》《破解成本优化后的稳定性问题》《业务出海之架构、合规、运营》《<a href=\"https://www.infoq.cn/article/2SKxCHfga7XBmatYS0oW\">金融行业数据治理经验分享</a>\"》，本文为《破解成本优化后的稳定性问题》研讨纪要整理～</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/82/821c8b9b0cf4f284043d45334f20098e.jpeg\" /></p><p></p><h3>参会嘉宾</h3><p></p><p>主持人：Yolanda&nbsp;InfoQ&nbsp;极客传媒总经理</p><p>刘亚丹，趣丸保障部负责人王兴刚，虎牙基础架构总监姚创沐，腾讯后台开发组长张靖，B&nbsp;站高级技术总监许文强，腾讯云&nbsp;/高级开发工程师冯江，小红书iOS技术专家郭凤钊（已晨）&nbsp;菜鸟网络&nbsp;/高级技术专家王远航&nbsp;神州泰岳/事业部总经理汤海涛&nbsp;麦当劳中国&nbsp;/数字化副总裁</p><p>&nbsp;</p><p></p><h3>研讨话题：</h3><p></p><p></p><h4>目前所在公司所发展的阶段，对于稳定、效率、成本的取舍</h4><p></p><p>&nbsp;</p><p>王兴刚：在过去一年，公司在成本方面表现良好，但今年面临更大的挑战，尤其是在成本已经缩减的情况下，进一步降低成本比例将变得更加困难。目前的重点是提高效率，尽管作为技术部门负责人，成本仍然是重要因素。同时，要满足领导对效率的要求，你需要承担提高效率和降低成本的责任。在成本压力下，业务稳定性的要求有所降低，但仍需保证在不影响核心业务的前提下达到一定水平（如90分以上）。此外，提到腾讯云是因为去年云服务成本较高，转用云服务可以节省开支，尽管这可能不是云服务商愿意听到的消息。</p><p>&nbsp;</p><p>许文强，我认为当前的定义可能不太准确，因为当我们让用户考虑上云时，企业会从两个维度来考虑，即人力成本和资源成本，这两个维度最直观的表现是金钱。然而，另一个维度是在上云后，业务的迭代速度和底层维护的稳定性是否为业务带来价值。这个维度是无法量化的，取决于我们的公司如何评估当前发展阶段。就个人而言，我认为在早期上云可以带来巨大的便利，云成本可能是不可控的，但我们可以通过细致的沟通和提高利用率来降低成本。这其中还涉及到许多商务维度的沟通，可以降低成本，并且在业务价值方面，这是两个不同的话题。</p><p>&nbsp;</p><p>张靖，在做成本优化方面，我们采取了三个步骤。首先，我们花了很多时间去计算降低成本的方法，包括服务器的采购成本和分摊逻辑，以及数据存储等，然后我们将成本分摊到业务上，其次，制定了指标和资产运营统计的工作等；最后是一些治理的手段——针对表可能我们会从格式上做一些压缩。我认为清楚地计算账目是非常重要的事情。最初，我们更关注预算和业务机器成本的分摊逻辑，而现在我们希望能够改变思维方式，更注重用量而不仅仅是机器的数量。</p><p>&nbsp;</p><p>王远航：我所处的事业部在疫情期间经历了分子公司（含独立经营单元）融合成立行业事业群的过程，并在疫情初期伴随事业群的成立根据业务变革进行对应“瘦身”，通过业务整合和技术层面的努力，有效降低了成本。然而，这个过程并非没有代价，业务稳定性和交付质量受到了一定的挑战。稳定性成本的付出取决于经营压力、领导决策力的平衡。为了进一步降低成本，提高效能成为了关键的手段。</p><p>&nbsp;</p><p>冯江：业内一些成熟的互联网企业，在内部已经形成了大量的私有云，有的甚至在讨论是否将其商业化，以降低成本并获得利润。相比之下，红书在业务高速发展阶段，基础架构相对较弱，主要依赖公有云采购。对于前端团队来说，人力成本是最大的。为了降低成本和提高效率，业内比较常用的是构建可复用的低代码平台的方式，此外，引入大量外包人员处理要求不高和不涉密性的工作，从而降低整体人力成本。前端作为流量入口，稳定性至关重要。团队在成本取舍时，将高端人才和核心研发力量集中在用户侧，通过引入外包来处理不太重要的场景，以确保稳定性。</p><p>&nbsp;</p><p>许文强补充道：老板对于稳定、效率和成本都有要求，但我们作为研发人员更注重稳定性。我们认为稳定性比成本更重要，愿意支付更高的费用以确保客户不会遇到问题。因此，在成本优化方面，我们不能牺牲稳定性。我们更多地进行技术探索，包括运营调度和架构升级，以降低成本并保持稳定性。</p><p>&nbsp;</p><p>郭凤钊，今年是菜鸟公司降本的第三年，我们是经营责任制，将成本分摊给各团队。第一年我们着重梳理账务，让团队明确成本，并成功削减了预算；第二年我们深度降本，实现了零增长并支持业务增长。我们采取了“捞浮油”的策略。起初，大家并没有过多关注成本优化，无论是开发人员编写代码、申请资源还是进行技术方案评估，都没有意识到成本。因此，在第一年进行成本规划时，我们将重点放在了提醒开发人员和决策者的意识上，让他们知道成本是多少，不能超出预算，否则将面临什么后果；第三年，我们设定更高目标，要实现三年零增长并保持业务两位数增长，这非常具有挑战性。我们也采取了低码开发、资源外包等方式降低人力成本，同时与云服务商进行博弈，也可以一定程度上实现成本优化。</p><p>&nbsp;</p><p>汤海涛：第一点，在过去的三年中，麦当劳自己开发了应用程序、小程序，建立了私有云，实施了双活等各种措施。这些费用主要来自我们对云服务提供商的削减，尤其是AWS和其他一些全球供应商；第二点，麦当劳的IT团队从过去的30人规模增长到250人，同时借助外包人员和服务供应商的支持来提供各支持，以保障服务的稳定性；第三点，在麦当劳，稳定性优先于成本：麦当劳在提升稳定性方面投入了大量资源，并获得了管理层和董事会的支持。当然，为了提高稳定性和备份能力，麦当劳选择了多云架构，并与阿里云、腾讯云进行了合作；与此同时麦当劳也有私有云的投资，尽管公有云和私有云的机器数量差不多，但我们认为拥有自己的数据中心和私有云是一项长期的投资决策，可以降低每年的云服务费用。</p><p>&nbsp;</p><p>姚创沐：近几年，随着降低成本和提高效率的需求增加，公司开始对业务链路进行成本梳理，包括人力和机器成本，发现在过去的业务发展初期存在许多资源浪费现象。而这些浪费对业务并没有增量。除此之外大老板把成本放在第一位，但他也希望兼顾稳定性和效率，并给出了相应的目标。团队进行了目标对齐，包括有损操作，如通过优化算法减少CPU和GPU等资源的消耗，降低存储成本。同时，我们还对整个业务产品侧的效率进行了盘点，特别是基于大数据的策略，包括实验周期和流程的优化，以提高整体效率，同时这也对成本产生了影响。</p><p></p><h4>降本之后，遇到了哪些稳定性的问题</h4><p></p><p>&nbsp;</p><p>王远航：交付质量如何持续提升、员工工作压力增大如何调节的问题突出。虽然我们客户主要来自非互联网行业，如运营商、航空公司和能源石化等，相比互联网领域，对前沿热点技术的应用相对较慢。但降本增效的压力也驱动我们要引入更高效能技术应用，如：AI相关、低代码相关、数字化转型相关等，对应的人员结构和技能也需要调整，来适应数字化转型和新技术应用的要求，公司也通过一系列手段来帮助组织和员工提升，如：开设云学堂、新技术培训课程、定期技术沙龙等。同时公司技术管理层也持续的关注和确定引入那些新方向和技术作为应用选择。此外，生态圈合作也是降本增效的有效渠道，我们也正在寻找生态合作机会。</p><p>&nbsp;</p><p>汤海涛：我们的期望是从供应商原本提供整套解决方案、提供软件的模式转变为提供能力的模式，这种能力可以是组件、API或算力。企业在数字化转型过程中，可以打造自己的乐高积木，定义接口标准，并允许按照标准接入组件。举例来说，麦当劳采用外部供应商的系统进行员工排班，该供应商将自动排班引擎做成API，使其能够与其他系统连接。这种从提供软件到提供能力的转变带来了更高效的解决方案。然而，全球供应链专业厂商对此意识较弱，国内软件企业有机会在小而美的能力方面发展。在人才结构培养方面，现在的趋势是停止招聘程序员，而是招聘产品经理和业务模式方面的人才。目标是培养既了解业务又了解产品的人才，并将编码工作部分外包给工程师，自身工程师负责20%的编码工作。</p><p>&nbsp;</p><p>郭凤钊：我们发现产业互联网的成本要比传统云服务低很多。为什么之前我们谈论云服务的价格很高呢？因为云服务的定价规则包括了技术开发和人力成本，这些成本会均摊给用户。云服务需要许多高技能的人才，否则无法进行开发和维护。但是实际的业务场景并不需要我们自己去搭建云服务。因此，我们现在正在关注人力成本，我们设定了年度目标，要将人力成本从一定金额降低到另一个金额。与外部创业者相比，他们在一年内可能实现了数十万元的成本，而云服务的成本可能是其三倍。</p><p>&nbsp;</p><p>Yolanda：降本增效的三部曲。第一年账先算好，第二年然后定目标，第三年考虑增效</p><p></p><h3>活动推荐：</h3><p></p><p>&nbsp;</p><p>2023 年 9 月 3 - 5 日，在北京·富力万丽酒店， <a href=\"https://qcon.infoq.cn/202309/beijing/\">QCon 全球软件开发大会（北京站）</a>\"已开启，现已开启售票，提前订票，可享受7折早鸟价，购票参会可以直接电话 / 微信联系票务经理 18514549229。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/e2/e2cc6621bc634e6d3fcacee922604626.jpeg\" /></p><p></p>",
    "publish_time": "2023-06-02 10:01:54",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "F5 分享三大技术趋势，现代应用重点关注服务代理和DNS",
    "url": "https://www.infoq.cn/article/kv2gtP4qdktq1GJjAwmW",
    "summary": "<p></p><p>近期，F5 2023科技趋势线上峰会开幕。会上，F5分享了其观察到的目前数字世界的三大技术趋势：</p><p></p><p>混合模式被企业视为良策。兼容多云或混合环境的技术受到企业的欢迎，众多企业将混合战略视为良策。零信任和 API 安全成为IT领导者关注的重点。根据F5发布的《2023年应用策略现状报告》，90% 的受访者表示面临多云挑战，其中复杂性和安全性挑战高居榜首。为应对这一挑战，81% 的受访者表示已经或即将采用零信任安全。数据和生成式人工智能将改变世界。生成式人工智能目前正处于高速发展阶段，该领域的突破层出不穷。</p><p></p><p>伴随着三大趋势的演进，将对企业现有的IT基础架构，应用架构及安全架构的健壮性与灵活性带来新的压力与挑战，其中，混合模式和多云环境不仅会增加运维的复杂性，带来高昂的成本和模糊的可视性，还会导致潜在网络攻击面的扩大，而生成式人工智能的发展会导致API调用爆炸式增长。</p><p></p><p>针对这些挑战，围绕新一代应用交付设施的三大架构——基础架构、安全架构和应用架构，F5面向多中心多云的基础架构，推出了分布式云服务（F5 Distributed Cloud Services），打造在网络层和应用层实现连接和安全能力的差异化云服务，允许用户借助单一的管理控制台实现网络运维、应用性能优化、故障排除以及可视性的整合。此外，F5还扩展了包括F5分布式云应用基础设施防护在内的多项SaaS和管理服务能力，帮助企业快速、安全地连接分布式云实例和工作负载。</p><p></p><p>在安全架构方面，F5通过SSLO和应用层安全解决方案，为企业的应用基础设施、应用访问和应用层提供全面灵活的防护。</p><p></p><p>伴随着微服务架构、容器化部署成为许多企业首选的架构，F5表示将通过NGINX帮助客户对应用程序和基础架构进行改造，加速企业的现代化进程。</p><p></p><p>其中，<a href=\"https://xie.infoq.cn/article/40c2faf31b6322e680d03fe92\">现代应用</a>\"是F5本地化战略的一大重点。伴随企业数字化转型要求，能力会落到APP的表现上，但APP所依赖于底层运行环境的能力必须得有效支持，否则看到的还是经过包装的传统应用，并未实现真正的企业数字化转型或者现代化应用。想要真正实现现代应用，必须有底层平台的有效支撑。但平台支持能力最终还是由网络、计算、存储提供并组装。</p><p></p><p>F5资深架构师林静表示，F5最强调<a href=\"https://www.infoq.cn/article/eBRp9AervUEZCbikdTeD\">服务代理</a>\"（F5内部也称为软负载或网关）、网络和DNS。以服务代理为例，服务代理本质上是基于软负载发展而来，在企业中，服务代理往往由三大部分驱动：基础网络架构驱动、软件架构驱动和基础平台架构驱动。</p><p><img src=\"https://static001.infoq.cn/resource/image/96/cc/9617c9ayyd755c0d28dc5d33f93475cc.png\" /></p><p></p><p>基础网络架构的驱动涉及到传统的ADC如何保证应用更安全、更可靠、更快速发布，解决多活中心的流量调度、多活中心的业务调配问题，如何更好地让用户接入到数据中心或业务中，这是非常传统的部分，这个领域大部分是硬件类产品。但随着企业向纯软化的方向发展，部分用户想要尽可能软件化部署。</p><p></p><p>软件架构驱动从技术形态上分成两大部分：分布式服务架构（DSA）和微服务服务架构。传统企业基本都是渐进式的方式，里面不同的异构系统之间会涉及到通过网关处理的各种接口。F5的主要能力集中在网关异构协议之间的处理等方面。</p><p></p><p>引进基础架构后，企业越来越重视基于Kubernetes平台、容器化基础架构的演进。很多企业正是基于此进行应用和迁移。企业要做的是从产研端到运维端，拉通整个平台的能力。在这样的基础平台里，涉及到策略的东西比以前多很多，比如通用的API接入网关、流量网关等，然后是Kubernetes技术平台本身的入口网关、微网关，甚至到服务网格。所有位置的地方都涉及到代理性的技术存在。</p><p></p><p>从应用角度看，<a href=\"https://www.infoq.cn/theme/156\">网关技术</a>\"的重要性在提升。稳态的传统应用的架构下，网关是很具像的，但是随着应用进入到虚拟化、容器化场景，这一类负载均衡或者代理类技术已经变成云上的标准ELB（弹性负载均衡），从传统的ELB演化成了NLB（网络型负载均衡）、ALB（应用型负载均衡），大家不再强调底层表现，而是强调云上的服务能力。</p><p></p><p>进一步来讲，企业PaaS或容器化以后，网关的地位进一步提升。企业要想在Kubernetes上容器正常运行起来，离不开流量入口、流量出口，以及Kubernetes标准的Services。Kubernetes标准的Services表现出来就是可访问的对象，这背后的技术就是服务代理与负载均衡。</p><p></p><p>在林静看来，现代应用涉及到应用的发布模型、应用开发模型和应用的运行模式，这些与以往的架构有很大不同。实际上，还存在许多细节技术，其中大家最熟知的是云技术、容器技术以及像Kubernetes编排等技术，这些都被引入了现代应用架构中。而服务代理则又是支撑现代应用的关键技术，服务代理技术帮助解决访客与应用，服务与服务之间的流量管理、服务治理、安全管理等工作。尽管解决的场景问题不同，但底层技术相通，因此企业应考虑成熟、稳定统一数据面，来解决这些不同场景问题。</p><p></p><p>林静表示，当前，阻碍现代应用发展的因素来源于技术方面和非技术两个方面。非技术方面需要从企业的高层进行自上而下的推动，包括人才、团队和技能的适配。如果组织的各个部门相互割裂，所做的事情也必然是零散的，就很难构建上层应用所需的平台能力以及打通自动化编排的能力。</p><p></p><p>现今的上层应用需要企业整体的支持，无论是数字化能力、数据消费能力还是从数据挖掘中获得的能力，都需要底层各种业务系统之间能够进行有效的横向整合，这些都要求底层能力必须跟得上。同时，如何统一支持各种传统技术和现代技术，以满足上层应用的需求，也是业内面临的一大难题，企业的传统基础设施应面向现代应用进行转型，无论是服务代理、DNS还是基础网络。</p><p></p>",
    "publish_time": "2023-06-02 10:29:17",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "快速实现不打折扣的云原生Java应用",
    "url": "https://www.infoq.cn/article/R8sh9XHuojBsX9DpGYvJ",
    "summary": "<p>近年来，向云原生计算迁移一直是开发人员比较关注的事情，按照云原生方式他们的业务应用能够从减少IT基础设施，提高可扩展性等方面受益。当涉及到云端部署应用程序时，“伸缩至零（scale-to-zero）”是标准的供应（provisioning）策略，以便于在业务需求较低的时候降低成本。随着需求的增加，会供应更多的应用程序实例和运行时，这种扩展必须非常迅速，这样终端用户才不会遇到响应滞后的问题。运行时的启动时间会对扩展性能产生很大的影响。</p><p>&nbsp;</p><p><a href=\"https://openliberty.io/?utm_source=infoq&amp;utm_medium=article&amp;utm_content=instanton\">Open Liberty</a>\"是一个云原生Java运行时，与其他Java运行时类似，它是建立在JVM技术之上的。JVM（更广泛地说，整个JDK）所提供的性能、调试能力和类库使其成为支撑应用程序的重要技术。尽管JVM以出色的吞吐能力而闻名，但是其启动时间却落后于Go和C++等静态编译语言。考虑到伸缩至零的需求，所以多年以来，显著改善启动时间一直是所有JVM实现的关键创新领域。<a href=\"https://wiki.openjdk.org/display/HotSpot/Application+Class+Data+Sharing+-+AppCDS\">AppCDS（HotSpot）</a>\"和<a href=\"https://www.eclipse.org/openj9/docs/shrc/\">Shared Classes Cache</a>\"（Eclipse&nbsp;<a href=\"https://www.eclipse.org/openj9/\">OpenJ9</a>\"）这样的元数据缓存技术在启动时间方面做出了令人瞩目的改进，但并没有在启动时间方面实现数量级级别的减少，而这恰好是serverless计算的扩展场景所需要的。</p><p></p><h2>&nbsp;</h2><p></p><p></p><h2>编译为原生镜像以减少启动时间</h2><p></p><p>&nbsp;</p><p><a href=\"https://www.graalvm.org/22.0/reference-manual/native-image/\">Graal Native Image</a>\"曾经宣布，借助编译为原生的方式，它能够实现低于100毫秒的启动时间，因此得到很多的关注。这是JVM领域的一个重大转变，因为这是Java第一次在启动时间方面能够与C++相抗衡。虽然Graal Native Image显著降低了启动时间，但这也是有一定代价的。</p><p>&nbsp;</p><p>首先，静态编译要求在构建时对应用有一个全局的了解。对于开发人员来说，他们在构建应用时一直依赖的动态能力将会受到限制。比如，像反射、动态类加载和invokedynamic等操作均需要特殊处理，因为它们会干扰生成原生镜像时的静态分析。这意味着，我们可能需要对应用程序进行大量的修改，这样原生镜像才能够正常运行，更糟糕的是，应用程序的依赖可能也需要更新。</p><p>其次，调试会变得更具挑战性，因为我们此时调试的已经不是一个JVM应用，而是一个原生可执行文件。我们需要将熟悉的Java调试器替换为原生调试器（如<a href=\"https://www.sourceware.org/gdb/\">gdb</a>\"）来调查问题。有种解决方式是在开发环境中使用JVM，在生产环境中使用原生镜像。但是，这意味着生产环境与开发环境是不一致的，最终我们可能必须要在两个不同的运行时中修复缺陷！</p><p>&nbsp;</p><p>最后，JVM提供的优秀的特性之一就是出色的吞吐量，即时（just-in-time）编译器能够在运行时根据实时数据优化应用程序以达到最佳性能。这一点也必须在原生镜像中牺牲掉，因为开发人员只有一次编译的机会，那就是在构建时。有些框架，比如<a href=\"https://docs.spring.io/spring-boot/docs/current/reference/html/native-image.html\">Spring Native</a>\"，已经建立了帮助Java开发人员在原生镜像约束下运行应用程序的能力，但不得不承认的是，开发人员必须放弃一些东西以获取原生镜像在启动时间方面的收益。</p><p>&nbsp;</p><p></p><h2>使用检查点/恢复功能跳过启动时间</h2><p></p><p>&nbsp;</p><p>Liberty运行时采用了一种不同的方式来改善启动时间。Liberty的目标是提供快速启动，而不必进行取舍，这是通过一项名为<a href=\"https://openliberty.io/blog/2023/02/10/instant-on-beta-update.html?utm_source=infoq&amp;utm_medium=article&amp;utm_content=instanton\">Liberty InstantOn</a>\"的特性实现的。该特性提供了Java开发人员熟悉的所有功能，相对于没有使用InstantOn的JVM运行环境，它的运行时启动时间最多能够优化10倍。</p><p>&nbsp;</p><p>从基础上来讲，Liberty InstantOn是基于<a href=\"https://criu.org/Main_Page\">检查点/恢复（checkpoint/restore）</a>\"技术的。我们启动一个应用程序，然后暂停它，并在某些明确定义的点上持久化应用程序的状态，这就是检查点。这个检查点就会成为应用镜像，当部署应用的时候，我们只需要从已保存的状态恢复镜像即可，这就是恢复，通过这种方式，应用程序就跳过了它通常要经历的启动和初始化过程（因为这些步骤已经运行过了）。</p><p>&nbsp;</p><p>Liberty使用了<a href=\"https://blog.openj9.org/2022/09/26/fast-jvm-startup-with-openj9-criu-support/\">OpenJ9 CRIU</a>\"提供的支撑功能，这是一项基于<a href=\"https://criu.org/\">Linux CRIU</a>\"的技术，它能够让任意应用均支持检查点和恢复。在Liberty InstantOn方式中，因为我们依然在JVM上运行，所以在吞吐量性能方面没有任何损失。Java调试也能按照预期方式运行，所有依赖动态JVM能力的库也能正常运行。</p><p>&nbsp;</p><p></p><h2>解决检查点/恢复机制的局限性</h2><p></p><p>&nbsp;</p><p>尽管检查点/恢复的概念听起来很简单，但在现实中，会有一些限制（这是<a href=\"https://criu.org/What_cannot_be_checkpointed\">CRIU</a>\"的运行方式所导致的）需要由运行时和JVM共同来解决，以便于让应用程序体验到这些收益。当执行检查点时（此时会构建镜像），CRIU会将环境“冻结”在检查点状态中，包括环境变量、计算资源的信息（CPU、内存）以及时间本身的信息都会打包到镜像中。这些东西中的任何一项在恢复环境中都可能是不同的，从而导致应用程序的不一致，这是很难追踪的。此外，检查点可能会捕获一些数据，如果镜像要通过容器注册中心跨公共网络传输到部署环境中，这就不是很理想了。这些数据可能包含对端点的外部连接，而这些连接在恢复环境中可能并不存在，另外数据中还可能包含我们不想在检查点镜像中嵌入的安全令牌。</p><p>&nbsp;</p><p>基于这些原因，OpenJ9 CRIU支持内置的补偿机制，以确保在检查点保存的应用在恢复时的行为是正确和安全的。对时间敏感的API进行了修改以补偿检查点和恢复时的停机时间。对于像<a href=\"https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/security/SecureRandom.html\">SecureRandom</a>\"这样的随机API在恢复的时候对种子进行了重置（re-seed），以确保每次检查点恢复时，它都会被恢复为唯一的实例。</p><p>&nbsp;</p><p>JVM可以解决它所知道的所有事情，但是应用程序代码可能也需要类似的处理。Liberty运行时通过与JVM合作来解决JVM无法自行处理的剩余问题，从而帮助开发人员摆脱检查点/恢复的复杂性。为了实现这一点，<a href=\"https://www.eclipse.org/openj9/\">OpenJ9</a>\"提供了一个钩子机制，开发人员可以利用它来注册在检查点之前和之后要执行的方法。这种机制被Liberty广泛采用，比如，在部署时重新解析配置，以确保为环境使用正确的配置。</p><p>&nbsp;</p><p>所以，尽管OpenJ9提供了高效利用检查点/恢复技术的工具，但是增强现有应用程序启动时间的最简单的方式是在Liberty上使用Liberty InstantOn来运行它。Liberty InstantOn对检查点/恢复过程进行了抽象，将开发人员的选择简化为只有几项，比如确定检查点用于应用程序启动之前还是之后。</p><p>&nbsp;</p><p>总而言之，我们的终极目标是改善Java应用程序的云原生体验，这意味着无论采用什么样的技术，都必须要在云环境中高效运行。Liberty InstantOn与容器技术（如Docker和<a href=\"https://docs.podman.io/en/latest/\">Podman</a>\"）实现了无缝集成。Liberty InstantOn还能与<a href=\"https://cloud.google.com/knative\">Knative</a>\"和<a href=\"https://www.redhat.com/en/technologies/cloud-computing/openshift\">OpenShift</a>\"等容器引擎协作。我们完成了相关的工作以确保Liberty InstantOn能够在非特权模式下运行，因为这对生产环境的安全性是非常重要的。这项工作的成果正在回馈给CRIU项目。</p><p>&nbsp;</p><p></p><h2>使用自己的项目尝试一下Liberty InstantOn</h2><p></p><p>&nbsp;</p><p>Liberty InstantOn的beta版本已经<a href=\"https://openliberty.io/blog/2023/02/10/instant-on-beta-update.html?utm_source=infoq&amp;utm_medium=article&amp;utm_content=instanton\">公开可用</a>\"，开发人员可以使用现有的应用程序进行尝试，以观察启动时间的改进（最多能够快10倍）。你只需要使用Liberty InstantOn工具为你的应用程序创建一个应用容器镜像即可。Open Liberty发布了<a href=\"https://github.com/OpenLiberty/ci.docker\">生产就绪的容器镜像</a>\"，使你的应用程序可以很容易地进行容器化，以便于在容器引擎中运行，比如Docker、Podman或Red Hat OpenShift这样的Kubernetes环境。</p><p>&nbsp;</p><p>Open Liberty容器镜像包含了所有必要的依赖，以便于在Open Liberty运行时中运行应用程序。如下针对开发人员的指南描述了如何基于Open Liberty&nbsp;beta-instanton镜像（icr.io/appcafe/open-liberty:beta-instanton）创建一个带有应用程序的基础应用容器镜像，然后如何在此基础之上创建并添加一个包含检查点进程状态的层。beta-instanton镜像包含了对Open Liberty创建检查点并将检查点进程存储到容器镜像层中所需的所有先决条件。这包括对OpenJ9 CRIU和Linux CRIU支持的早期访问构建。</p><p>&nbsp;</p><p></p><h3>如何使用Liberty InstantOn容器化应用程序，使其能够更快启动</h3><p></p><p>如下的指南使用Podman来构建和运行容器，并且使用了<a href=\"https://github.com/OpenLiberty/guide-getting-started/tree/prod/finish\">Open Liberty入门指南中的应用程序</a>\"。如果你手头有自己的应用程序，可以将其替换掉。</p><p>&nbsp;</p><p>入门应用程序包含了一个<a href=\"https://raw.githubusercontent.com/OpenLiberty/guide-getting-started/eb42c3ebe489054e0385ca7668f8069940bf20de/finish/Dockerfile\">Dockerfile</a>\"，如下所示：</p><p>&nbsp;</p><p><code lang=\"null\">FROM icr.io/appcafe/open-liberty:full-java11-openj9-ubi\n\n\nARG VERSION=1.0\nARG REVISION=SNAPSHOT\n\n\nCOPY --chown=1001:0 src/main/liberty/config/ /config/\nCOPY --chown=1001:0 target/*.war /config/apps/\n\n\nRUN configure.sh</code></p><p>&nbsp;</p><p>首先，开发人员需要更新FROM指令以使用beta-instanton镜像：</p><p>&nbsp;</p><p><code lang=\"null\">FROM icr.io/appcafe/open-liberty:beta-instanton</code></p><p>&nbsp;</p><p>然后，借助更新后的Dockerfile，可以使用如下的命令构建应用容器镜像：</p><p>&nbsp;</p><p><code lang=\"null\">podman build –t getting-started .</code></p><p>&nbsp;</p><p>该命令会创建应用容器镜像，但是还没有创建检查点进程。应用程序的检查点进程是通过如下命令运行应用容器镜像来创建的，这里添加了一些额外的选项：</p><p>&nbsp;</p><p><code lang=\"null\">podman run \\\n--name getting-started-checkpoint-container \\\n--privileged \\\n--env WLP_CHECKPOINT=applications \\\ngetting-started</code></p><p>&nbsp;</p><p>通过WLP_CHECKPOINT变量，Open Liberty运行时声明在被配置的应用启动后但在打开端口以接受传入的请求之前对应用进程生成检查点。当应用程序进程完成检查点生成后，运行中的容器将会停止。这将会形成一个包含检查点进程状态的已停止的容器。</p><p>&nbsp;</p><p>最后一步是将这个检查点进程状态以层的形式添加到原始应用程序的进程镜像中。这可以通过如下的命令将名为getting-started-checkpoint-container的已停止应用容器提交给一个新的容器镜像：</p><p>&nbsp;</p><p><code lang=\"null\">podman commit \\\ngetting-started-checkpoint-container \\\ngetting-started-instanton</code></p><p>&nbsp;</p><p>最终的结果是可运行的getting-started-instanton容器镜像。</p><p>&nbsp;</p><p></p><h3>运行具有Linux特权能力的容器</h3><p></p><p>当运行getting-started-instanton容器时，开发人员必须授予其一组<a href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux_atomic_host/7/html/container_security_guide/linux_capabilities_and_seccomp\">Linux能力</a>\"，以便容器镜像中的CRIU二进制文件执行恢复过程：</p><p>&nbsp;</p><p>cap_checkpoint_restorecap_net_admincap_sys_ptrace</p><p>&nbsp;</p><p>在创建检查点进程时，使用了一个具有特权的容器，它授予了容器镜像中的CRIU二进制文件所需的<a href=\"https://man7.org/linux/man-pages/man7/capabilities.7.html\">Linux能力</a>\"。</p><p>&nbsp;</p><p>请通过如下的Podman命令以运行具有三种所需能力的容器：</p><p><code lang=\"null\">podman run \\\n--rm \\\n--cap-add=CHECKPOINT_RESTORE \\\n--cap-add=NET_ADMIN \\\n--cap-add=SYS_PTRACE \\\n-p 9080:9080 \\\ngetting-started-instanton</code></p><p>&nbsp;</p><p>getting-started-instanton容器会以必要的权限来运行，以执行恢复过程，应用程序的运行速度要比原始的getting-started应用程序快10倍。</p><p>&nbsp;</p><p></p><h3>未来的改进</h3><p></p><p>&nbsp;</p><p><a href=\"https://openliberty.io/blog/?search=beta&amp;utm_source=infoq&amp;utm_medium=article&amp;utm_content=instanton\">Open Liberty的beta版本</a>\"发布了对Liberty InstantOn的定期更新。未来的版本已经规划了一些改进，它们将会让Liberty InstantOn构建和运行应用镜像变得更加容易。例如，为了消除对NET_ADMIN&nbsp;<a href=\"https://man7.org/linux/man-pages/man7/capabilities.7.html\">Linux能力</a>\"的要求，一些额外的相关工作已经完成。还有一项计划是在恢复应用的过程中移除对SYS_PTRACE能力的要求。这将减少运行应用所需的能力清单，在运行应用程序的时候，仅需CHECKPOINT_RESTORE能力即可。</p><p>&nbsp;</p><p>其他规划包括在应用容器的构建步骤中执行应用进程检查点，这样不需要容器运行和容器提交命令就能将应用进程状态存储到应用容器镜像层中了。</p><p>&nbsp;</p><p></p><h3>请反馈你们的想法</h3><p></p><p>&nbsp;</p><p>虽然云原生需要对组织的业务方式做出许多变化，但是有了Liberty InstantOn，开发人员就不用担心改变他们的应用开发方式了。</p><p>&nbsp;</p><p>我们鼓励开发人员使用Open Liberty 22.0.0.11-beta或后续版本来尝试<a href=\"https://openliberty.io/blog/2023/02/10/instant-on-beta-update.html?utm_source=infoq&amp;utm_medium=article&amp;utm_content=instanton\">Liberty InstantOn的beta功能</a>\"。欢迎通过项目的<a href=\"https://groups.io/g/openliberty\">邮件列表</a>\"进行反馈。如果遇到问题，开发人员可以在<a href=\"https://stackoverflow.com/questions/tagged/open-liberty\">StackOverflow上发布问题</a>\"。如果发现缺陷的话，欢迎<a href=\"https://github.com/OpenLiberty/open-liberty/issues\">提交issue</a>\"。</p><p>&nbsp;</p><p></p><h2>背景说明</h2><p></p><p>&nbsp;</p><p><a href=\"https://openliberty.io/?utm_source=infoq&amp;utm_medium=article&amp;utm_content=instanton\">Open Liberty</a>\"和<a href=\"https://www.eclipse.org/openj9/\">Eclipse OpenJ9</a>\"均是开源项目。IBM基于这些项目构建了其商业的<a href=\"https://www.ibm.com/products/websphere-liberty?utm_source=infoq&amp;utm_medium=article&amp;utm_content=instanton\">WebSphere Liberty</a>\"&nbsp;Java运行时和<a href=\"https://www.ibm.com/support/pages/semeru-runtimes-getting-started?utm_source=infoq&amp;utm_medium=article&amp;utm_content=instanton\">IBM Semeru Runtimes</a>\"&nbsp;Java发行版。Liberty InstantOn使用了Linux Checkpoint/Restore In Userspace（<a href=\"https://criu.org/\">CRIU</a>\"）项目提供的检查点/恢复技术，并与CRIU合作，将代码反馈给该项目。</p><p>&nbsp;</p><p></p><h5>原文链接：</h5><p></p><p></p><p><a href=\"https://www.infoq.com/articles/rapid-startup-of-your-cloud-native-java/\">https://www.infoq.com/articles/rapid-startup-of-your-cloud-native-java/</a>\"</p><p>&nbsp;</p><p></p><h5>相关阅读：</h5><p></p><p></p><p><a href=\"https://xie.infoq.cn/article/5949911f01f93aa5f4ba477ee\">Java&nbsp;是如何毁掉你的编程思维的？</a>\"</p><p><a href=\"https://xie.infoq.cn/article/28097a6f5549ebd8f1f0dcd7e\">系统学&nbsp;Java，看这篇&nbsp;Java&nbsp;综合笔记万字总结就够了！..</a>\"</p><p><a href=\"https://xie.infoq.cn/article/6908e13ab21e3066c4657a72b\">Java&nbsp;8 之后的新特性都是鸡肋吗？</a>\"</p><p><a href=\"https://xie.infoq.cn/article/cbcc483066428210d9fb6951c\">扫盲篇：Java&nbsp;中为啥一个 main 方法就能启动项目？</a>\"</p>",
    "publish_time": "2023-06-02 11:00:10",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "全球数据库领域的攻坚方向及国内外差异",
    "url": "https://www.infoq.cn/article/ltLzNOG4T1OiGddjtFAM",
    "summary": "<p>Q：全球数据库技术发展多年，目前整体的攻坚方向是什么？国内数据库发展如何？</p>\n<p>魏凯：全球数据库发展趋势可以用以下八个方向概括：HTAP；多模数据管理；人工智能技术和数据库技术的融合发展；可信数据库；全密态数据库；一体机；云原生深度融合；图数据库。</p>\n<p>周傲英：数据库的发展可以用突破、超越、赋能六个字来形容。突破原来的体系结构和数据模型，从应用中抽象出来，提出新的理论和架构，发展基于数据的人工智能。</p>\n<p>李飞飞：数据库发展有云原生化、平台化、一体化、智能化的趋势。云原生化是指新一代数据库必须采用云原生的架构设计；平台化是通过结合平台能力与数据库赋能用户；一体化是实现数据在多个引擎之间的无缝流转；智能化包括智能化运维和支持 AI 负载的数据库。</p>\n<p>刘松：数据库行业的发展可以用“四世同堂”和“诸子百家”来形容——目前ZICO、大型机、各种开源数据库、分布式等都在有客户使用，此外互联网和分布式的兴起促成了数据的变革，现在数据库应用已经拓展到物联网和多模领域，随着数据总量和需求形态的变化，在开源、多云、智能介入这三大因素的影响下，未来数据库技术将趋向“多元”和“厚实”。</p>",
    "publish_time": "2023-06-02 11:13:29",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "推动UI层现代化：聊聊取代微前端的交互式微服务",
    "url": "https://www.infoq.cn/article/cJQmZ5m3bAFNNQVepfLy",
    "summary": "<p>根据InfoQ最新发布的《软件架构与设计趋势》报告，微服务架构在IT社区中已经得到广泛采用。具体来讲，报告将微服务与事件驱动架构列入了“晚期大众”的划定区间。</p><p>&nbsp;</p><p>报告还提出了可能令人意外的事实，即微前端时至今日仍处于“早期应用”区间，未能与微服务一道成功进入“晚期大众”阶段。尽管存在几种较为成熟的微前端框架选项，但2020年针对650多名技术领导者开展的调查发现，只有24%的受访者使用过微前端。</p><p>&nbsp;</p><p>由此可以得出结论：虽然微服务架构在软件系统的后端应用已经非常成熟，但在前端层面却并非如此。可以肯定，对于涉及多支DevOps团队的大型软件系统来说，这种前端仍处于单体时代的现状无疑代表着运营和生产力层面的巨大瓶颈。</p><p>&nbsp;</p><p>也就是说，负责补充甚至替代微前端的生态位上仍有发展空间。而当仁不让的后起之秀，正是交互式微服务。</p><p>&nbsp;</p><p></p><h2>交互式微服务</h2><p></p><p></p><p>交互式微服务，也被称为Qworum服务，是由Qworum平台开创的Web前端模块化新概念。</p><p>&nbsp;</p><p></p><h3>多阶段Web API</h3><p></p><p></p><p>交互式微服务基于Qworum所定义的新型Web API，即多阶段Web API。这类API与传统REST或JSON-RPC Web API的最大区别，在于端点调用可能涉及多个请求-响应对，也就是“阶段”。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/06/06c80741d4befe120713b24a0df8beff.png\" /></p><p></p><p>多段调用会接收调用参数并返回结果</p><p>&nbsp;</p><p>如果调用中包含参数，Qworum并不会真正将其发送至服务器，而是开放给浏览器内的被调用服务。如有必要，被调用的服务可以在不经Qworum的情况下，自行将数据发送至服务器。</p><p></p><h3>基于HTML的用户交互</h3><p></p><p></p><p>多阶段设计允许各端点在返回结果之前，先通过见面与最终用户交互。正是这一点，让微服务获得了交互能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f1/f1fa50855c6f2678938d4f6d25ffa1ab.png\" /></p><p></p><p>交互式多段调用</p><p></p><h3>服务组合</h3><p></p><p></p><p>Qworum的另一个重要特性，是端点可以要求由网络浏览器执行调用，借此调用其他端点甚至是源端点自己。其他端点可以托管在源调用端点所处的同一网站，也可以托管在网络上任意位置的其他网站。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/63/631f2dedcd29971af435364615ad13ff.png\" /></p><p></p><p>由网络浏览器负责介导的服务组合</p><p></p><h3>新的顶级网络格式</h3><p></p><p></p><p>说到这里，很多朋友肯定好奇Qworum服务要如何执行嵌套调用，这些服务又要如何返回结果。</p><p>为此，Qworum定义了一种新的顶级Web格式，名为Qworum脚本。支持Qworum的浏览器中，内置一个可以运行此类脚本的解释器。关于更多细节，我们将在“Qworum脚本”小节中具体讨论。</p><p>&nbsp;</p><p></p><h3>用户体验</h3><p></p><p></p><p>在使用体验上，基于Qworum的Web应用程序跟传统Web应用程序没有多大差别。</p><p>&nbsp;</p><p>但在使用Qworum应用程序时，用户可能会发现浏览器显示页面中的DNS域可能会不时变更，但所有页面的使用感觉仍像是Web应用程序的一部分。这是因为Qworum应用程序采用分布式设计，可通过组合托管使用不同来源上的多个Qworum服务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/91/916bbf76552414025f64c2c4b1037dac.png\" /></p><p></p><p>跨多个源和DNS域的用户流示例。</p><p>&nbsp;</p><p>第二个区别，是浏览器的后退按钮无法在应用程序UI中导航至上一页面，这是因为Qworum应用程序和服务在执行期间不会向浏览器选项卡的历史记录添加新条目。之所以有此限制，是为了避免应用程序UI与Qworum附加至选项卡的应用状态不同步。</p><p></p><h3>与微前端的区别</h3><p></p><p></p><p>到这里，Qworum和微前端的区别已经很明显了：</p><p></p><p>无限的可组合性：交互式微服务能够在执行期间调用其他端点，甚至调用自己。这意味着嵌套调用的深度将没有上限，而且无论嵌套深度如何，每次调用都会处理整页UI。这与通常只能嵌套1或2层的微前端不同，因为随着嵌套深度的增加，分配给每个微前端的UI面积会越来越小。广泛的适用性——Qworum服务比微前端更适用于分布式应用程序，因为这类应用往往与特定Web应用程序（即席微前端）、前端框架（React微前端、Angular微前端）或者组织（各组织间的微前端通常无法互通）相绑定。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ee/eec620ae142d278bf34d72972c3ca580.png\" /></p><p></p><p>Qworum采用的是“一切皆是微服务，包括应用程序”的UI范式</p><p>微前端采用的是“微前端加容器应用程序”的UI范式</p><p></p><h2>新的网络浏览器功能</h2><p></p><p></p><p>Qworum还为Web环境带来了以下久经考验的计算机制：</p><p></p><p>子例程——子例程是实现软件模块化的基础机制。事实上，大多数（甚至是全部）CPU指令集都包含负责调用子例程和从子例程返回的操作码。在高级编程语言中，子例程表现为过程、函数和方法。Qworum的端点调用机制也是子例程的另一种高级表现形式。对象——在面向对象编程中，对象主要作为数据的容器。在对象生命周期中，这些数据会在一组称为“方法”的子例程之间共享并保持可访问性。这个概念在Qworum中表现为Qworum对象，适用于构建购物车等有状态服务。</p><p></p><h3>框架及其他</h3><p></p><p></p><p>需要明确的是，Qworum并不是那种能够轻松使用浏览器现有功能的JavaScript框架。相反，Qworum自身定义了Web应用程序能够利用哪些新的浏览器功能。</p><p>&nbsp;</p><p>因此，尽管也提供用于Web前端的官方Qworum JavaScript库，但该库只能算是官方Qworum浏览器扩展提供的功能“薄层”。Qworum目前支持基于Chromium内核的浏览器，并将在不久的将来支持其他所有主流浏览器。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/42/4242a8923e1b1134558d869400b598d2.png\" /></p><p></p><p>安装在谷歌Chrome上的Qworum官方扩展</p><p></p><h3>新的浏览器内数据存储机制</h3><p></p><p></p><p>Qworum之所以无法单纯作为JavaScript库实现，包括之所以需要以浏览器扩展或者本机浏览器实现的形式起效，原因就是浏览器目前只面向单源Web应用程序。而Qworum所支持的是分布式Web应用程序，这也是由Qworum开创的全新通行概念。下面，我们来具体聊聊为什么当前浏览器功能不足以支持分布式应用程序：</p><p></p><p>符合标准的网络浏览器需要实施所谓同源策略，以便彼此隔离来源。其中特别要求“一个来源中的JavaScript，将无法读取或写入属于另一来源的存储”。同源策略会对Qworum形成极大限制，因为Qworum会话使用的是单一调用堆栈，会话中的所有Qworum服务都必须能够访问该调用堆栈，且无论具体来源如何。在传统编程中，执行线程也将单一调用堆栈视为标准实践。因此，Qworum建立了一种新的、粒度更细的对象数据分离策略，而不再粗暴按源进行数据分离。新策略要求：1）属于同一Qworum对象的端点的所有阶段，都必须包含在同一来源中；2）如果对象A包含对象B，或者B调用了A的某一端点并将其数据作为调用参数，则Qworum中的对象A可以访问另一Qworum对象B的数据。除此之外，Qworum对象还可根据HTTP(S)请求中Referer标头指示的调用者URL，主动拒绝向调用者提供服务。这种情况意味着即使A包含B，某些情况下B也不会向A提供有意义的数据。</p><p>&nbsp;</p><p>在应用程序执行期间，Qworum内部会使用各个浏览器选项卡的跨源调用堆栈来处理服务调用和数据。调用堆栈仅在应用程序执行期间存在，一旦应用程序退出或者最终用户关闭应用程序所在的浏览器选项卡，调用堆栈即被删除。这类似于在终端中打开Deno或Node REPL会话，所有会话对象都将在退出时被自动删除。</p><p>&nbsp;</p><p>请注意，虽然浏览器的History API已经提供类似于堆栈的结构以将数据附加至浏览器选项卡，但这种数据结构并不适合管理Qworum的调用堆栈。这两种数据结构分别针对不同的用例，History API的数据堆栈可通过Web前端直接访问，并可基于多种用途进行调整或使用；但Qworum调用堆栈仅独立存在。</p><p></p><h3>为网站启用Qworum</h3><p></p><p></p><p>要在给定网站上运行Qworum，需要满足以下所有条件：</p><p></p><p>在浏览器上安装Qworum扩展。Qworum扩展未被最终用户禁用。网站的DNS域当前已订阅Qworum。默认情况下，Qworum仅针对本地开发启用。</p><p></p><p>网站可以使用Qworum JavaScript库来检查以上条件，并在不满足时向最终用户发出提醒。</p><p>&nbsp;</p><p></p><h2>用Qworum编程</h2><p></p><p></p><h3>Qworum脚本</h3><p></p><p></p><p>官方Qworum规范中定义了一种新的顶级Web格式，即Qworum脚本。这种格式以XML为基础，XML是Web服务器除HTML页面以外向浏览器发送的另一种数据形式。XML具备可样式化属性，允许对最终用户隐藏脚本内容。</p><p>&nbsp;</p><p>Web服务器会将Qworum脚本作为标准XML文档进行交付，内容类型为application/xml或text/xml。浏览器会通过查看文档根元素的命名空间，来理解当前XML文档实际上是Qworum脚本。</p><p>&nbsp;</p><p>Qworum脚本的推荐文件扩展名为.qrm.xml。Qworum还提供官方的Visual Studio Code扩展，可用于促进静态Qorum脚本的创建。此扩展目前仅可提供建议片段。也有其他功能正在规划当中，包括检查脚本语法、脚本中可能包含的任何JSON或语义数据的语法，以及对嵌入式数据语法的高亮显示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c0/c0db9b1dd38bff233f98cb364bf22a2a.png\" /></p><p></p><p>正在运行的Qworum官方VS Code扩展</p><p></p><h3>如何生成客户端脚本</h3><p></p><p></p><p>除了以XML的形式从服务器发送到浏览器外，Web前端还可以通过Qworum JavaScript库生成并执行Qworum脚本。</p><p>&nbsp;</p><p>在库说明文档中，提到了Qworum.eval()这种API方法，能够执行动态生成的Qworum脚本。要知道，传统上在JavaScript代码中使用eval()&nbsp;属于风险行为，所以很多朋友可能会怀疑使用Qworum.eval()到底安不安全。令人欣慰的是，答案是肯定的，具体原因如下：</p><p></p><p>Qworum脚本是用特定领域语言编写，而非图灵完备语言。Qworum脚本只能将最终用户重新定向至新的URL，或者关闭浏览器选项卡。由Qworum脚本发起的重新定向由HTTP GET请求组成。换句话说，Qworum脚本不会向服务器发送任何数据。Qworum脚本只能通过Qworum浏览器扩展（用于Qworum脚本的内部存储和管理）对Qworum调用堆栈进行间接访问。该浏览器扩展将监督脚本具体可以对调用堆栈执行哪些操作。Qworum脚本无法访问Web前端存储在客户端存储中的数据，例如localStorage、sessionStorage&nbsp;和&nbsp;IndexedDB。</p><p></p><h3>用户体验</h3><p></p><p></p><p>大多数Qworum脚本在执行时，会将最终用户重新定向至新的URL。例如，以下电子商务示例项目的链接和按钮都将执行Qworum脚本，在单击后即重新定向最终用户。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fa/faac94fc955475eb6df64021727e35b5.png\" /></p><p></p><p>点击按钮即运行Qworum脚本，对用户执行重新定向</p><p>&nbsp;</p><p>在某些情况下，Qworum应用程序会关闭当前浏览器选项卡以退出。引发这种情况的原因之一，是Qworum脚本发现了应用程序未能捕获的故障。Qworum应用程序会尽可能防止这类情况，以避免破坏用户体验。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/73/731bf47f9fb9d30d6cc3e716023826c5.png\" /></p><p></p><p>Qworum应用程序由于未捕获的错误而退出。</p><p></p><h3>Qworum应用程序示例</h3><p></p><p></p><p>下面，我们将具体了解以上提到的电子商务演示项目将如何工作。请注意，Qworum目前主要面向商业和企业级应用程序，可能不太擅长处理消费级应用程序，毕竟大多数浏览器尚未预安装Qworum。</p><p></p><h3>伪代码</h3><p></p><p></p><p>我们首先会在较高层次上描述这款分布式电子商务应用的结构。其实任何面向对象的编程语言都可用于开发此任务，因为Qworum平台本身就是面向对象的。这里我们使用TypeScript。请注意，此代码并是要交由Qworum执行。相反，其内容是要帮助读者厘清分布式应用程序的结构。</p><p>以下伪代码，描述了一套由两种Qworum服务类型组成的软件系统：</p><p></p><p>具有两个交互式端点home()与viewArticle()的电子商店，以及作为对象状态的购物车。带有两个交互式端点addItems()和showCart()的购物车，以及作为对象状态的车内总价和商品列表。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/94/947b0bc04d5c556614cca9c615ab7854.png\" /></p><p></p><p>伪代码：由两个服务组成的分布式Qworum应用程序</p><p>&nbsp;</p><p>这里的伪代码描述了一个依赖于购物车Qworum服务的电子商店应用程序。按照惯例，假定所有接口方法都代表交互式Qworum&nbsp;API端口。</p><p>&nbsp;</p><p></p><h3>使用Qworum的JavaScript库</h3><p></p><p></p><p>在通过JavaScript使用Qworum之前，网页首先需要导入Qworum库。下图所示为导入过程：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a9/a9e93c1c9e0ad2878e34997b8c296f48.png\" /></p><p></p><p>导入Qworum JavaScript库</p><p>&nbsp;</p><p>大家可能注意到，在以上伪代码中，e-shop Qworum对象包含一个购物车对象。也就是说，任何电子商店端点都可以访问购物车总金额及其商品条目列表。例如，电子商店端点可以使用Qworum.getData()来读取购物车总价，如下所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/19/198807569b02c5d8322261543d5f519a.png\" /></p><p></p><p>由e-shop端点读取购物车数据</p><p>&nbsp;</p><p>Qworum.getData()&nbsp;会接收数据容器的路径作为调用参数。在以上代码中，Qworum.getData()&nbsp;将查找名为“total”的数据容器，该数据容器包含在名为“shopping cart”的Qworum对象中，而此对象又包含在拥有当前Qworum端点调用的Qworum对象当中，具体如“@”路径元素所示。</p><p>&nbsp;</p><p>也可以使用Qworum.setData()&nbsp;方法设置数据容器的值。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3d/3dc370f68d06e901eb393c4717e3a33a.png\" /></p><p></p><p>由购物车端点设置购物车状态</p><p>&nbsp;</p><p>Qworum脚本的生成和执行也同样简单：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cc/ccd98b1366d41c92b3ddef13ab134885.png\" /></p><p></p><p>由购物车的showCart()端点结束执行</p><p>&nbsp;</p><p>这会将最终用户重新定向至新的URL。Web前端可能希望在执行Qworum脚本之前，先检查浏览器是否在线。当前的Qworum会假定浏览器已经在线，但如果浏览器已离线，那么尝试启动重新定向的脚本可能会自动引发网络故障。</p><p>&nbsp;</p><p>请注意，Qworum端点并不清楚执行完成后会发生什么。与之对应，当前的Web应用程序必须将返回的URL传递至登录对话框页面，所以如果要在同一个页面上处理错误条件，有时可能需要传递多个返回URL。由此可知，与当前Web编程方式相比，Qworum的处理风格更类似于传统编程。</p><p></p><h3>部分执行流程</h3><p></p><p></p><p>当最终用户在电子商店的商品详情页面中单击“添加至购物车”按钮时，交执行以下JavaScript函数：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5d/5d28ec438eb7528c7ee94a571eba0aeb.png\" /></p><p></p><p>用户在电子商店应用中向购物车添加商品</p><p>&nbsp;</p><p>关于以上代码的几点说明：</p><p></p><p>在执行过程中，调用指令不会终止脚本执行，只是将其暂时中断。当调用返回结果或引发错误时，脚本将恢复执行。在对购物车addItems()端点的调用完成之后，对电子商店viewArticle()端点的调用也将同步完成。这是因为顶级序列指令将产生由addItems()返回的结果，且当顶级指令在Qworum脚本中产生结果时，当前端点调用会返回该结果。如果goto指令未被注释，则viewArticle()端点调用将改为在addItems()返回时，继续执行goto定义的下一阶段。</p><p>&nbsp;</p><p>现在，让我们看看购物车在其addItems()端点被调用时，具体执行了哪些操作。以下为实际执行的函数：&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ff/ffddd2cb128a8efd5d437fb262252680.png\" /></p><p></p><p>添加新商品时，购物车会更新所存储的会话状态</p><p>&nbsp;</p><p>再次强调以下几点：</p><p></p><p>调用参数可作为本地数据供Qworum端点使用，通过Qworum.getData()进行读取。addItems()端点仅更新购物车状态，而不与最终用户交互；它会调用showCart()端点以向最终用户显示UI。addItems()端点将返回与嵌套调用showCart()相同的结果。</p><p>&nbsp;</p><p>根据以上示例可知，Qworum为Web开发者提供了一系列高效的面向对象编程原语。</p><p>&nbsp;</p><p></p><h2>企业与商业用例</h2><p></p><p></p><p>虽然本文主要介绍Qworum平台所提供的功能和技术原理，但这里也要简要讲解如何使用Qworum平台即服务构建企业和商业软件。</p><p>&nbsp;</p><p>Qworum是一套通用平台，特别适合作为微服务架构的基础设施。在Qworum的帮助下，您可以轻松实现软件系统当中UI层的模块化。</p><p></p><h3>供应商用例</h3><p></p><p></p><p>适合软件供应商的Qworum应用场景包括：</p><p></p><p>企业套件供应商可在内部使用Qworum，借此集成企业套件中的各类元素。在企业套件中集成同类最佳的各种应用程序。使用Qworum将多种彼此独立的同类最佳应用程序集成起来。</p><p></p><h3>部署用例</h3><p></p><p></p><p>Qworum适用于各种部署和集成类型，包括本地、云端，也涵盖定制化软件、现成商业软件乃至SaaS。</p><p></p><h3>项目管理应用程序示例</h3><p></p><p></p><p>这里以人力资源应用、资源预订应用和在线协作应用等功能集成构建的项目管理应用程序为例。本文不提供具体工作代码，但此类系统的为代码可能如下所示：</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/f6/f6caf2866d070a0909d66a3cc0755d0c.png\" /></p><p></p><p>分布式项目管理应用程序的高级描述。</p><p></p><h2>知识产权</h2><p></p><p></p><p>多阶段Web API的概念最早出现在名为“服务组合的方法和系统”的实用专利当中。尽管该专利已经过期，但为了防止平台出现碎片化倾向、避免因碎片化对开发者的生产力带来负面影响，我们还是决定为Qworum的新功能申请相应专利。</p><p>&nbsp;</p><p>Qworum是一家商业机构，但也欢迎广泛的IT社区向Qworum Google官方群组做贡献，或者针对Qworum规范提交反馈、建议和请求。</p><p></p><h2>总结</h2><p></p><p></p><p>大家应该还记得，当初万维网的设计方向其实是内容平台、而非具体应用。所以考虑到网络体系的发展历程以及客观存在的改进空间，Qworum出于更好支持Web应用程序而做出的重大更新自然也在情理之中。</p><p>&nbsp;</p><p>总而言之，Qworum为Web平台带来了高级浏览器功能，有助于提高工作效率、并为使用微服务架构的开发运营团队提供用例支持。期待大家多多提供宝贵意见！</p><p>&nbsp;</p><p></p><h5>原文链接：</h5><p></p><p></p><p><a href=\"https://www.infoq.com/articles/qworum-modular-ui-architecture/\">https://www.infoq.com/articles/qworum-modular-ui-architecture/</a>\"</p><p>&nbsp;</p><p></p><h5>相关阅读：</h5><p></p><p></p><p><a href=\"https://xie.infoq.cn/article/7e2df43d6d76e39b58813eee6\">UI&nbsp;自动化测试革命：拥抱 Maestro 框架的未来之旅</a>\"</p><p><a href=\"https://xie.infoq.cn/article/0116d901443949d082bba5440\">ui&nbsp;设计网站：全网最热门的 30 个&nbsp;UI&nbsp;设计网站合集</a>\"</p><p><a href=\"https://xie.infoq.cn/article/94991c47c0bf662d9dd559fd1\">UI&nbsp;自动化助力业务效率提升</a>\"</p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MzUxMzcxMzE5Ng==&amp;mid=2247513197&amp;idx=1&amp;sn=bd95e13109b8eca3459eec98c30029cc&amp;chksm=f952012ece25883862571f74417c3529294546d507673b34245f2b61439f42ccaeefd3afd67e&amp;scene=27#wechat_redirect\">字节跳动二次生成能力加持下的&nbsp;UI&nbsp;智能生成实践</a>\"</p>",
    "publish_time": "2023-06-02 11:15:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AIGC 具体将如何影响数据库技术的演进？",
    "url": "https://www.infoq.cn/article/eN4jQf9gziBysgD05uzi",
    "summary": "<p><strong>Q：AIGC 具体将如何影响数据库技术的演进？</strong></p>\n<p>周傲英：数据是人对世界的认知结果在计算机中的表示，数据库的设计和技术等都是在把数据变成一个公共事业，以后的数据技术需要提高数据的层次，建造新生态而不是重塑生态。</p>\n<p>李飞飞：AIGC 在数据建模、数据分析挖掘、SQL 质量管理等方向的应用还处于相对早期的阶段，但仍有大量的机会：一个机会点是让 AI 理解业务逻辑、构建建模的 pipeline；二是程序设计流程各环节和 AIGC 的 Coin。</p>\n<p>刘松：随着 AIGC 知识经验的积累、推理能力的标准化、可信度和精确性的增加，未来大多数工作将可以交给 AIGC。但目前这还没有以工业或者商业服务的形态大规模发生，行业和企业需要利用 AIGC 去提质提效。</p>",
    "publish_time": "2023-06-02 11:16:24",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AI for DB 还是 DB for AI，该如何理解？",
    "url": "https://www.infoq.cn/article/pJQkY4RaC4iNRHdMFo6c",
    "summary": "<p><strong>Q：AI 和 DB 彼此之间怎样去融合？这个过程中会遇到什么挑战？</strong></p>\n<p>李飞飞：AI 和数据库的结合一定会发生且也已发生了很长一段时间。AI for DB 就是利用 AI 技术提升运维效率、简化运维复杂度。在 DB for AI 方面，通过自然语言的方法转换成 SQL 并与数据库完成交互将很快产品化。在 AIGC 应用中，如何融合向量和数据库能力也是一个机会点。</p>\n<p>周傲英：AI 和 DB 相互促进、相互帮助。DB for AI 是基于数据的人工智能化，让 database 赋能 AI；在 AI for DB 中，AI 倒逼数据库的发展让数据变得好用。</p>\n<p>刘松：下一个数据库时代将在云原生基础上实现 AI 和数据库的深度耦合。虽然我们在五年前就开始讨论AI for DB和DB for AI的问题，但最值得关注的地方还未出现，新一波AIGC和数据库的底层内核应更靠下，从而形成一个更具面向未来、在线数据分析能力更强的解决方案，特别是针对企业问题的解决方案。关于“AI for DB 和 DB for AI 是否是同步进行的，那答案是肯定的，AI for DB 的智能运维、智能诊断其实已经都在使用且不止一年，而 DB for AI 方面，多模态数据库、包括整个数据一体化方面可以让 AI 更友好。</p>",
    "publish_time": "2023-06-02 11:19:04",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "重新思考流处理与流数据库",
    "url": "https://www.infoq.cn/article/aa368384d07d286682990be64",
    "summary": "<p>在过去的数年里，我们见证了流处理技术的飞速进步与普及。我第一次接触流处理是在2012年。那时候的我有幸在微软亚洲研究院实习，在系统组里做分布式流处理系统。之后我分别在新加坡国立大学、卡耐基梅隆大学、IBM Almaden研究院、AWS Redshift从事流处理与数据库系统的研究与开发。如今，我正在RisingWave Labs（<a href=\"https://link.zhihu.com/?target=https%3A//www.risingwave-labs.com/\">RisingWave: A Cloud-Native Streaming Database</a>\"）搭建下一代流数据库系统。</p><p></p><p>一晃11年过去，当时在微软亚研院实习的我万万没想到，我在这个领域持续做了十多年，并不断突破边界，从纯技术开发逐步转向探索该领域商业化的道路。在创业公司里，最令人兴奋也最具有挑战的事情便是预测未来 — 根据历史的轨迹思考与判断行业的发展方向。在过去的数月中，我一直在思考几个问题：为什么需要流处理？为什么需要流数据库？流处理系统真的能够颠覆批处理系统吗？在这篇文章中，我将结合自己的软件开发与客户沟通经验，从实践角度探讨流处理与流数据库的过去、现在与未来。</p><p></p><h2>流处理系统的正确使用姿势</h2><p></p><p>说到流处理系统，大家自然而然的会想到一些低延迟用例：股票交易、异常监控、广告计算等等。然而，在这些用例中，流处理系统到底如何被使用的呢？使用流处理系统时，用户期望的延迟到底有多低？为什么不用一些批处理系统来解决问题？在这里，我来结合自己的经验回答这些问题。</p><p></p><h3>典型流处理场景</h3><p></p><p>无论什么具体的用例，流处理系统通常被应用在以下两个场景中：数据接入与数据分析。</p><p><img src=\"https://static001.geekbang.org/infoq/df/dfcdec566d55877731b4e8aaaffcb4af.png\" /></p><p></p><p>数据接入（data ingestion）。所谓数据接入，就是将数据从一个（或多个）数据系统经过一定计算之后插入到另一个（或多个）数据系统中。另一种常见的说法便是ETL。用户为什么要做数据接入？我举几个简单例子大家就明白了。我们可以考虑有个电商网站，使用一个OLTP数据库（比如AWS Aurora、CockroachDB、TiDB等）支撑线上交易。同时，为了更好的分析用户的行为，网站也可能使用了一个程序采集用户行为（比如点击广告等），并将用户行为日志插入了消息队列（如Kafka、Pulsar、Redpanda等）中。为了更好的提升销量，电商网站通常会将交易数据与用户行为日志导入到同一个数据系统，如Snowflake或是Redshift这样的数据仓库中，以便进行分析。在这里，电商网站的工程师们便可以使用流处理系统将数据从OLTP数据库与消息队列实时的搬到数据仓库里。在数据搬运的过程中，流处理系统会做各类计算，来进行脏数据清理、多个数据源join等操作。在我们接触过的场景中， 数据的源头往往是OLTP数据库、消息队列、存储系统等，而数据的终点除了OLTP数据库、消息队列、存储系统外，更常见的便是数据仓库与数据湖。值得一提的是，我们目前没有见过从数据仓库与数据湖导出数据到其他系统的案例，主要原因还是用户通常将数据仓库与数据湖看作是数据的终点，同时由于数据仓库与数据湖一般不提供数据变更日志，这使得数据实时导出更加困难。数据分析（data analytics）。数据分析很容易理解，就是对一个（或多个）数据系统中的数据进行计算得到分析结果，并将结果推送给用户。当使用流处理系统做数据分析时，往往意味着用户希望是对最近（比如30分钟、1小时、7天等）的数据更加感兴趣，而不是去到数仓中批量处理数月甚至数年的数据。在数据分析场景中，流数据系统的上游往往还是OLTP数据库、消息队列、存储系统等，而下游通常是个key-value store（如Cassandra、DynamoDB等）或者是个缓存系统（如Redis等）。当然，也有些用户会直接将流处理的结果发送给应用层，这种使用方式一般在告警系统中比较普遍。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/68/68db379af04a88de955addc092090a39.png\" /></p><p></p><p>尽管批处理系统同样能做数据接入与数据分析，但是流处理系统相比于批处理系统，能够将延迟从小时或者天级别降低到秒级或者分钟级。这在一些业务中将带来巨大好处。对于数据接入这个场景中，降低延迟可以让下游系统（比如数据仓库）用户更及时的得到最新的数据，并对最新的数据进行处理。而在数据分析这个场景中，下游系统可以实时看到最新的数据处理结果，从而能够将结果及时呈现给用户。</p><p>有朋友一定会问：</p><p>对于数据接入（或者ETL）这个场景，我们拿个编排工具（比如Apache Airflow）定时触发批处理系统（比如Apache Spark）做计算不就可以了吗？对于数据分析场景，许多实时分析系统（比如Clickhouse、Apache Pinot、Apache Doris等）都能对数据进行在线分析，为什么还要用流处理系统？</p><p>这两个问题非常值得深入探讨，我们将会在文章最后一节进行讨论。</p><p></p><h3>用户的期望：延迟到底需要有多低？</h3><p></p><p>对于流处理系统的用户来说，他们期望的延迟到底是多少呢？秒？毫秒？微秒？越低越好？根据我们的客户访谈结果，多数流处理系统用户的用例所需要的延迟在百毫秒到数十分钟不等。在我们的用户访谈中，不少科技企业的在线数据系统工程师对我们说：“使用了流处理系统之后，我们的计算延迟从天级别降到了分钟级，这样的转变已经让我们非常满意了，并没有特别的需求进一步降低延迟。”所谓”延迟越低越好“，在我们看来，听上去很美好，但实际上并没有太多实际用例做支撑。事实上，在一些超低延迟场景中，通用的流处理系统也达不到其所需的延迟需求。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9e/9e12a6d8278aff951f3ee5822c15f767.png\" /></p><p></p><p>一个很典型的超低延迟场景便是高频量化交易场景。量化公司都期望自己的系统能够在极短时间内响应市场的波动，从而对股票或者期货进行买入卖出。量化公司需要的延迟通常在微秒级别。为了达到这种级别的延迟，许多量化公司都会将自己的机房搬去离交易所物理位置更近的大楼，并精心挑选网络运营商来减少由于网络通信造成的延迟。在这种场景中，量化公司几乎都会选择自己自建系统，而非采用市面上的通用流处理系统（如Flink、RisingWave等）。这不仅是因为通用流处理系统往往由于封装达不到延迟的需求，也是因为量化交易通常需要一些特殊的自定义算子，而这些算子一般都不会被通用流处理系统所支持。</p><p>还有一些低延迟场景是IoT（物联网）与网络监控。这类场景的延迟通常在毫秒级，可能是几毫秒，也可能是几百毫秒。在这类场景中，通用流处理系统（如Flink、RisingWave等）可能可以做到很好的支撑。但在一些用例中，还是需要使用特化的系统。一个很好的例子就是车载传感器。车载传感器可能会监控车辆的行驶速度、车辆坐标、踩油门与刹车的频率等等信息。这类信息可能由于隐私、网络带宽等原因，一般不会回传给数据中心。因此，常见的解决方案就是在车辆上直接装处理器（或者说是嵌入式设备）来进行数据处理。在这类设备上安装通用流处理系统还是不太合适的。</p><p>接下来要谈的便是一些大家耳熟能详的低延迟场景了：广告推荐、欺诈检测、股市大盘报表、订餐APP等。这类场景的延迟通常来说都是在百毫秒或者数分钟之间。更低的延迟听起来可能更好，但不一定有必要。就拿股票大盘报表来举例。普通散户通常通过盯着网站或者手机看股票波动来进行交易决策。这些散户真的有需求知道10毫秒之前的股票交易信息吗？其实是没有必要的。人眼看到的极限频率是60Hz，也就是人眼根本分辨不出16毫秒以下的刷新。同时，人做决策的反应速度都是在秒级，哪怕是训练有素的运动员听到枪声的反应速度也只能在100-200毫秒左右。因此，对于股票大盘这种给人提供决策信息的场景，低于百毫秒的延迟都是没有必要的。而这类需求百毫秒到分钟级的场景，便是通用流处理系统（如Flink、RisingWave等）最擅长的场景了。</p><p>然后就到了一些对延迟没有很高要求的场景了：酒店预订、库存管理等。对于这类延迟不敏感场景来说，流处理系统与批处理系统其实都能做比较好的支持，因此在用户选择系统的时候，考虑的点往往不是性能，而是成本、灵活性等方面了。</p><p>对于机器学习模型训练、数据科学、财务报表等这些对延迟完全没有要求的场景，很显然批处理系统更加适用。当然了，随着技术的不断进步，我们也看到了在线机器学习、在线数据科学等方向的兴起，而不少公司也的确开始使用流处理系统来将这些应用实时化。在本文，我们就不对这类场景进行过多讨论了。</p><p></p><h2>回顾（被遗忘的）历史</h2><p></p><p>上一节讲了流处理系统的使用场景。在这一节里，我们来谈谈流处理系统的历史。</p><p></p><h3>Apache Storm与其之后的系统</h3><p></p><p>对于许多资深工程师来说，Apache Storm也许是他们接触过的第一个流处理的系统。Storm是使用一门称为Clojure的小众JVM编程语言编写的分布式流计算引擎。相信很多新一代的程序员可能都没听说过Clojure这种语言。Storm在2011年被Twitter公司开源。在那个被Apache Hadoop统治的年代，Storm的出现改变了许多人对数据处理的认知。传统来讲，用户处理数据的方式都是将大量数据首先导入到HDFS，再用Hadoop等批计算引擎对数据进行分析。而有了Storm，用户可以在数据刚流入系统的时候就被处理。用户也能够在几秒钟或者几分钟内获得结果，而不是要等待数小时或者数天。</p><p><img src=\"https://static001.geekbang.org/infoq/80/80f8d2811a4d659136c5c9f6c2c22a41.png\" /></p><p></p><p>Storm在当时是相当有突破性的。然而，早期Storm的设计远远没有达到用户预期的完美：它所要求的编程方式过于复杂，并缺少很多现代流处理系统中默认提供的基本功能，例如状态管理、exactly-once语义、动态扩缩容等等。当然也正是因为这些设计的不完美，才使得诸多才华横溢的工程师去搭建下一代流计算引擎。在Storm开源之后两三年内，我们鉴证了一批流计算引擎的诞生：Apache Spark Streaming，Apache Flink，Apache Samza，Apache Heron，Apache S4等等。 而如今，Spark Streaming与Flink成了非常成功的两个流计算引擎。</p><p></p><h3>Apache Storm之前的历史</h3><p></p><p>如果你认为流处理系统的历史起源于Storm的诞生，那就错了。 事实上，流处理系统的历史远比很多人想象的精彩。不算特别意外的是，流处理这一概念来自于数据库圈。在2002年的数据库领域顶级会议VLDB上，布朗大学与MIT的学者发表了“Monitoring Streams – A New Class of Data Management Applications”论文，指出了流处理这一新的需求。在这篇文章中，作者提出，为了处理流数据，我们应该抛弃传统的“Human-Active, DBMS-Passive”传统数据库处理模式，而转向“DBMS-Active, Human-Passive”这一新型处理模式。也就是说，在新型的流处理系统中，数据库应该主动接收数据并触发查询，而人只需要被动接受结果即可。在学术界，最早的流处理系统叫做Aurora，随后又有Borealis、STREAM等系统在同时代诞生。</p><p><img src=\"https://static001.geekbang.org/infoq/a3/a3197f8ec64730ae2e59de68c858d927.png\" /></p><p></p><p>在被学术界提出的几年后，流处理技术便在大型数据库厂商中得到了应用。数据库领域的三大老牌厂商Oracle、IBM、Microsoft分别推出了他们自己的流处理解决方案，分别称为Oracle CQL、IBM System S、Microsoft SQL Sever StreamInsight。非常一致的是，三个厂商都选择了在自己现有系统中集成流处理功能，而非将流处理功能单独拿出来开发成独立系统。</p><p></p><p></p><h3>2002年至今：到底什么被改变了？</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/d4/d43857ffa340f06264632a40b18f8999.png\" /></p><p></p><p>通过以上的讨论，大家可以看到，在2002年第一个流处理系统Aurora在学术界诞生之后，很快被数据库巨头吸收进自身产品中。但在2010年前后，该领域出现了一个重大转变，那便是流处理模块被从数据库系统中独立出来，并单独发展成了完整的、可扩展的分布式流计算引擎。是什么造成了这一变革？我认为是与Hadoop（或者说MapReduce）的诞生与发展息息相关。在传统单机数据库世界中，计算与存储都被封装在同一个系统中。尽管这样可以大大简化系统架构，给用户单一接口进行操作，但这种架构无法很好的扩展到集群环境中。Hadoop所统治的大数据时代的理念便是将计算与持久化存储分割成独立的系统（注意这里所说的“分割成独立的系统”跟人们时常讨论的“存算分离”还是有不少区别），并暴露底层接口给用户，依赖用户提供足够多的信息（例如并行度、partition key等）来去做水平扩展。这样的模式完美的满足了工程师驱动的新一批互联网公司（如Twitter、LinkedIn、Uber等）的需求。我们现在看到的Storm及其之后的大数据流计算引擎，无一不是这种设计思路：只负责计算层、暴露底层接口、通过partition方式暴力使用资源进行无限扩展。很显然，Storm、Flink所代表的大数据时代流计算引擎的发展规律，与Hadoop、Spark所代表的同一时代的批计算引擎的发展规律完全吻合。</p><p></p><h2>流数据库的复兴</h2><p></p><p>回望历史我们发现，流数据库这一概念在20多年前便已被提出并实现。然而，大数据时代所带来的巨大技术变革推动了Storm、Flink、Spark Streaming等一批流计算引擎的诞生与发展，并推翻了Oracle、IBM、Microsoft这三巨头在流处理技术上的垄断。历史总是螺旋形上升的。在批处理系统领域，我们看到了Redshift、Snowflake、Clickhouse等系统重新将人们从“计算引擎”拉回到“数据库“这一理念中来。同样，在流处理领域，我们也看到了如RisingWave、Materialize等流数据库的诞生。为什么会这样？我们在这一节详细分析。</p><p></p><h3>PipelineDB与ksqlDB的故事</h3><p></p><p>随着2011年Storm开源之后，流计算引擎便进入了发展的快车道。但流数据库并没有就此销声匿迹。有两个知名流数据库系统就诞生在大数据时代中。一个名叫PipelineDB，另一个名叫ksqlDB。先不说技术，这两个系统在商业上有着不小的联系。PipelineDB是于2013年创立，2014年PipelineDB团队加入了硅谷知名孵化器Y Combinator孵化， 2019年PipelineDB被Apache Kafka原创团队所成立的商业化公司Confluent收购。而ksqlDB正是由Confluent公司于2016年创立（其实最早是先做了Kafka Stream）。PipelineDB与ksqlDB尽管都是流数据库，但它们在技术路线上的选择截然不同。PipelineDB是完全基于PostgreSQL的。更准确的说，PipelineDB使用了PostgreSQL的扩展接口。也就是说，只要用户安装了PostgreSQL，就可以像安装插件一样安装PipelineDB。这一理念对用户非常友好：用户无需迁移自己的数据库，便可以使用PipelineDB。PipelineDB非常核心的卖点就是实时更新的物化视图。当用户将数据插入PipelineDB之后，用户所创建的物化视图上便会实时显示最新结果。KsqlDB选择了与Kafka强耦合的策略：在ksqlDB中，计算的中间结果存储在Kafka中；节点之间的通信使用Kafka。这种技术路线的优势与缺陷非常鲜明：其优势是高度复用成熟组件，大大降低开发成本，缺陷是强绑Kafka，严重缺乏灵活性，使得系统的性能与可扩展性大打折扣。</p><p>PipelineDB与ksqlDB从用户认可度来讲还是逊色于Spark Streaming与Flink：PipelineDB已于2019年被收购之后停止了更新，而ksqlDB由于强绑Kafka以及技术成熟度等原因，在Kafka生态以外并没有得到足够多的关注。而在最近（2023年1月），Confluent公司又收购了由Flink核心成员创立的Flink商业化公司Immerok，并高调宣布会推出基于Flink SQL的计算平台。这使得ksqlDB未来在Confluent内部的地位变得更加扑朔迷离。</p><p></p><h3>云原生流数据库的兴起</h3><p></p><p>经历了Hadoop、Spark领导的大数据时代， 我们便来到了云时代。近年来，诸多云原生系统逐步超越并颠覆了其所对标的大数据系统。一个最为人所知的例子便是Snowflake的崛起。Snowflake基于云构建出的存算分离的新一代云数据仓库形成了对Impala等上一代大数据系统的降维打击，在市场上实现了称霸。在流数据库领域，类似的事情可能会再次发生。RisingWave、Materialize、DeltaStream、TimePlus等就是近几年涌现出来的云上流数据库。尽管商业化路线、技术路线等方面的选择有着各种差异，但它们的大方向都是希望为用户在云上提供流数据库服务。在云上构建流数据库，重点就在于如何使用云的架构来实现无限水平扩展与成本降低。如果能够很好的选择技术路线与产品方向，相信会逐步挑战上一代流处理系统（如Flink与Spark Streaming）的地位。</p><p></p><h3>流计算引擎与流数据库</h3><p></p><p>上面两段简述了流数据库在最近几年的兴起。相信大家都能够看出云原生是个趋势，但为什么大家在云上构建的是“云原生流数据库”，而不是“云原生流计算引擎”？</p><p>也许有人会认为是SQL的影响。云服务带来的一大变革便是普及数据系统的使用。在大数据时代，系统用户基本都是工程师，他们熟悉Java等编程语言进行应用开发。而云服务的兴起急需系统提供一种简单易懂的语言使广大没有编程基础的工作者受益。SQL这种标准化的数据库语言很显然满足了这个需求。看起来，SQL的广泛应用推动了“数据库”这个概念在流处理领域的普及。然而，SQL只是间接因素，而非直接因素。证据很清晰：诸多流计算引擎（如Flink与Spark Streaming）已经提供了SQL接口。尽管这些系统的SQL接口与MySQL、PostgreSQL等传统数据库的SQL使用体验有极大区别，但至少证明了有SQL不一定代表要有数据库。</p><p>我们回看“流数据库”与“流计算引擎”的区别，会发现流数据库拥有自的存储，而流计算引擎并没有。在这一表象底下更加深层的理念是：流数据库将存储视为一等公民（first-class citizen）。这一理念使得流数据库很好的满足了用户的两个最根本需求：简单、好用。这是如何做到呢？我们列举以下几个方面。</p><p>统一数据操作对象。在流计算引擎中，流（stream）是基本的数据操作对象；在数据库中，表（table）是基本的数据操作对象。在流数据库中，流与表的概念得到了完美的统一：用户不再需要考虑流与表的区别，而是可以把流看做是无限大小的表，并使用操作传统数据库的方式对表这个概念进行处理。简化用户数据栈。相比于流计算引擎，流数据库拥有了对数据的所有权：用户可以直接将数据存储在表中。当用户通过流数据库处理完数据之后，可以直接将处理后的结果存储在同一系统中，供用户进行并发访问。而由于流计算引擎无法存储数据，这就意味着其进行计算之后，必须将结果导出到key-value store或缓存系统中，才能供用户访问。这也就是说，用户可以使用单一的流数据库系统替换掉之前Flink+Cassandra/DynamoDB等服务组合。简化用户的数据栈，削减运维成本，这很显然是很多公司期待的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/42/42dfd95c7a7db1a9e3743767bdc06ee7.png\" /></p><p></p><p>减少外部访问开销。现代企业的数据源是多样的。当使用流处理系统的时候，用户往往需要访问外部系统数据（考虑要将Kafka导出的数据流与MySQL中的一个表做join）。对于流计算引擎来说，要想访问MySQL中的数据，必须进行一次跨系统外部调用。这种调用造成的性能代价是巨大的。当流数据库拥有存储数据的能力之后，很显然能将外部系统中的数据保存（或缓存）在流数据库内部，从而大幅提升数据访问性能。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a5/a5ec5666209c81bedb01c48768848724.png\" /></p><p></p><p>提供结果可解释性与一致性保证。流计算引擎的一大痛点在于计算结果缺乏可解释性与一致性保证。我们考虑一个非常简单的例子：用户使用Flink提交了两个job，一个是求过去十分钟内Tesla股票的被买入次数，另一个是求过去十分钟内Tesla股票的被卖出次数。在Flink中，不同job独立运行，两个job不断向下游系统输出结果。由于流计算引擎的计算进度不同、输入输出不被系统管理，导致下游系统接收到的两个结果缺乏一致性（比如一个可能是8点10分的结果，另一个可能是8点11分的结果），也无法被溯源。看到这样的结果，用户是非常困惑的：他们无法判断结果是否正确、如何得出、如何演变。而当流数据库可以拥有对输入、输出数据的所有权之后，系统的计算行为从理论来说都变得可观测、可解释、强一致了。毕竟，在流数据库中，一切计算的输入数据都可以被存储到表中并打上时间戳，一切计算产生的结果都可以保存在物化视图中并通过时间戳溯源。这样，用户就可以很好的理解计算结果了。当然理论归理论，实际还得看系统是否实现。RisingWave就是实现了这种强一致性并提供可解释性的系统之一。</p><p></p><p>深度优化计算执行。将“存储被视为一等公民”，意味着流数据库的计算层可以感知存储，而这种感知能力使得系统能够在查询优化层以及计算执行层进行大幅优化。一个简单的例子就是可以更好的共享计算状态节省资源开销。由于涉及大量技术细节，我们不在这里进行过多讨论，有兴趣的朋友可以参考其他一些文章：<a href=\"https://zhuanlan.zhihu.com/p/521759464\">https://zhuanlan.zhihu.com/p/521759464</a>\"。</p><p></p><h3>云原生流数据库的设计准则</h3><p></p><p>（这一节的讨论可能会显得无趣，因为已经有太多文章讨论过云原生系统的设计与实现了。大家可以选择跳过。）</p><p>云与集群的最大区别在于，云可以被认为是资源无限，且资源解耦；而集群是资源有限，且资源耦合。什么意思呢？第一，云上用户已经不再需要感知物理机器的数量：他们只需要付钱就可以获得他们想要的资源；而大数据时代的集群用户往往只拥有有限的物理机器；第二，云对用户暴露出来的是分类资源：用户可以根据需求单独购买计算、存储、缓存等资源。而大数据集群暴露出来的就是一台一台物理机器，用户只能是按机器数量来请求资源。第一点区别使得数据系统的设计目标发生了本质转变：大数据系统的目标是在有限资源内最大化系统性能，而云系统的目标是在无限资源内最小化成本开销；第二点区别则使得数据系统的实现方式发生了本质转变：大数据系统通过存算耦合的shared-nothing架构实现暴力并行，而云系统则通过存算分离的shared-storage架构实现按需伸缩。在流处理系统中，所谓中间计算结果即是存储。当中间计算结果需要从计算节点剥离出来放到S3等持久化云存储服务上时，大家会很自然的想到，S3带来的数据访问延迟可能大幅影响流处理系统这种低延迟系统的性能。因此，云原生流处理系统不得不去考虑使用计算节点的本地存储以及外挂存储（如EBS等）去缓存数据，从而最大化减小S3访问带来的性能下降问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/20/20af69c183c0dfc53c6f3abd92d499fa.png\" /></p><p></p><p></p><h2>流处理还是批处理：替代还是共存？</h2><p></p><p>流处理技术因其能够极大降低数据处理延迟，被很多人视为一种可以颠覆批处理的技术。当然也有另一种观点认为，大多数批处理系统都已经“升级”成实时分析系统，流处理系统的价值将非常有限。我自己投身于流处理技术的研发与商业化，自然对流处理的前景极度乐观。而我并不认同流处理与批处理会互相取代。在本章，我们详细探究流处理与批处理各自的独特之处。</p><p></p><h3>流处理与实时分析</h3><p></p><p>目前多数的批处理系统，包括Snowflake、Redshift、Clickhouse等，都宣称自己是实时分析系统，能够对数据进行实时大规模分析。我们在第一章也提到一个问题：对于数据分析场景，在已有许多实时分析系统的情况下，为什么还要用流处理系统？”我认为这完全是对所谓”实时“定义的不同。在流处理系统中，查询被用户事先定义，而查询处理由数据驱动；在实时分析系统中，查询由用户随时定义，而查询处理由用户驱动。流处理系统所说的“实时”是指系统对用户预定义的查询实时给出最新的结果，而实时分析系统所说的”实时“是指用户随时给出的查询实时给出结果。没看出来区别？那更简化一下，就是流处理系统强调计算结果的实时性，而实时分析系统强调用户交互的实时性。对于股票交易、广告计算、网络异常监控等对数据结果新鲜度要求很高的场景，流处理系统也许是最佳选择；而对于交互式自定义报表、用户行为日志查询等对用户交互式体验要求很高的场景，实时分析系统可能会更胜一筹。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a1/a11d84587fa38fae12e8039e93e79c64.png\" /></p><p></p><p></p><p>也许有人会说，既然实时分析系统能够对用户发送的查询实时给出结果，那么只要用户一直向实时分析系统中发送相同的查询，岂不是就能时刻保证结果的新鲜度，实现流处理系统的效果？这种想法有两个问题。第一个问题是实现复杂。用户毕竟不是机器，无法一直守在电脑前不间断的发送查询。想要实现这一效果无非只有两条路：要么是自己写程序定时发送查询，要么是自己运维编排工具（如Airflow等）循环发送查询。无论是哪条路，都意味着用户需要付出额外的代价运维外部系统（或程序）。第二个问题（也是最根本的问题）是成本过高。原因很简单：实时分析系统进行的是全量计算，而流处理系统进行的是增量计算。当所需处理的数据量较大时，实时分析系统不得不进行大量冗余的计算，带来巨量资源浪费。说到这里，相信大家应该也对之前本文第一章“为什么不拿个编排工具定时触发批处理系统做计算”这个问题有了答案。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f1/f14508907663e9aceae720883b0499e2.png\" /></p><p></p><p></p><h3>流处理与实时物化视图</h3><p></p><p>如今诸多实时分析系统都已经提供了实时物化视图功能，而实时物化视图就是流处理在数据库内的表达形式。有种观点认为，有了带有实时物化视图的分析系统，我们就不再需要需要单独的流处理系统。我认为这个观点并不成立。我们可以从以下几个方面考虑。</p><p>资源竞争。分析型数据库要解决的核心问题是在大规模数据集上高效的对复杂查询进行处理。在这类系统中， 物化视图的定位本质上与数据库索引无异：都是计算的缓存。创建这样的缓存有两个好处：一方面，为经常处理的查询创建物化视图可以有效避免重复计算；另一方面，为不同查询的共享子查询创建物化视图可以加速查询执行。这样的定位实质上使得物化视图几乎不可能得到及时更新：积极主动的更新物化视图势必会持续抢占计算与内存资源，导致用户发送的查询得不到及时响应。为了防止这种“本末倒置”的事情发生，几乎所有分析性数据库采用的都是被动更新（也就是需要用户主动驱动）或是延迟更新（等到系统空闲时再更新）的方式。正确性保证。如果说资源竞争问题可以通过多加计算节点来解决，那么正确性问题就不是实时分析系统的物化视图能够解决的问题了。批处理系统处理的是有限有边界数据，而流处理系统处理的是无限无边界数据。在处理无边界数据时，由于网络通信等各种原因可能产生数据乱序问题。而流处理系统特别设计了水位线等概念来解决这一问题。当乱序数据只有当按照某一特定顺序至行之后，输出的结果才被认为是完全正确的。然而，实时分析系统缺少水位线等基础设计，这使得无法达到流处理系统所能达到的正确性。而这种正确性保证在各种流处理场景（比如风险控制、广告计算等）中至关重要。缺少了正确性保证的系统，自然无法替代流处理系统。</p><p></p><h3>流处理的软肋</h3><p></p><p>流处理并不是万能的，流处理也不无法彻底替代批处理。有几方面的原因。</p><p>灵活性。流处理要求用户事先预定义好查询，从而来实现不间断的对最新数据进行实时计算。这一要求使得流处理在灵活性方面弱于批处理。正如本文之前所提到的，尽管流处理对查询相对固定的场景有很好的支持，但是当面对需要与用户频繁交互的场景时，批处理系统会更加适合。表达性。我们在上文提到，流处理使用增量计算的方式通过避免冗余计算来减小资源开销。但增量计算也带来了一大问题，就是系统的表达性受限。主要原因就是并非所有计算都能够被增量的处理。一个很简单的例子就是求中位数：并没有增量算法保证精确求出中位数值。因此，当面对一些及其复杂的场景时，流处理系统难以胜任。计算成本。流处理可以大幅降低实时计算的成本。但这并不意味着，流处理在任何场景下都能够比批处理更具成本优势。事实上，在对计算结果新鲜度不敏感的场景中（比如财务报表统计等），批处理才能更加节约成本。这是因为，为了在数据进入系统时便进行增量计算，流处理系统不得不持续维护计算状态，消耗资源。相比之下，批处理在只有用户请求到达时才进行计算，自然在无需实时结果的场景下节省成本。</p><p></p><h3>流处理与批处理的融合</h3><p></p><p>讨论了这么多，相信大家也看出来，流处理与批处理各具特点，很难在全场景中实现完全替代。既然这两种处理模式会共存，那很自然有些人会想到在同一套系统中同时支持流处理与批处理。不少系统已经进行了一些探索，这里就包括了Flink、Spark等这类老牌大数据系统。尽管这些系统的流批一体方案已经在一些场景落地，但是从实际的市场接受度来看，至少目前来讲，大多数用户仍然选择分别部署流处理、批处理两套系统。这其中不仅包含性能、稳定性的考量，同时也能在功能上各取所长：既保证了实时性，又同时能对归档数据运行复杂的AI算法、ad-hoc分析等等。</p><p>目前阶段， RisingWave还是更加专注于流处理本身，但也会通过Sink、开放格式以及第三方connector等方式，方便用户使用第三方实时分析系统进行数据分析。事实上，在现在的RisingWave版本中，用户可以很轻松的将数据导出到Snowflake、Redshift、Spark、ClickHouse等系统中。我认可流批一体方案的意义，从长期来讲，RisingWave也会进行这方面的探索。实际上，流数据库就是在做流处理与批处理的统一：当有新的数据流入流数据库时，流数据库就进行流计算；当有用户发起随机查询请求时，流数据库就进行批计算。至于内部实现如何，本文就不再展开赘述了，我们可以开一篇新文章详细探讨流批一体的设计。</p><p></p><h2>后记</h2><p></p><p>在文章最开始的时候，我提到自己已经在流处理领域做了11年的时间。然而，在2015到2016年的时候，我一度认为流处理的这座大厦已经建成，剩下的工作仅是小修小补。那时的我并没有想到，云计算的快速发展与普及让流处理系统在2020年之后重新回到了舞台的正中央，越来越多的人正在研究、开发、使用这一技术。本文是我最近几个月结合技术与商业化对流处理进行的思考。希望能够抛砖引玉，欢迎大家一起讨论！</p><p></p><p></p><h2>鸣谢</h2><p></p><p>感谢Tianshuo Shi，Eric Fu，Tianyi Zhuang对本文提出的意见与建议！</p><p></p><h2>关于 RisingWave</h2><p></p><p>RisingWave是一个云原生SQL流式数据库。其旨在降低构建实时应用的门槛以及成本。</p><p>GitHub：&nbsp;<a href=\"http://link.zhihu.com/?target=http%3A//risingwave.com/github\">risingwave.com/github</a>\"</p><p>官网：&nbsp;<a href=\"http://link.zhihu.com/?target=http%3A//risingwave.com\">risingwave.com</a>\"</p><p>‍Slack：<a href=\"http://link.zhihu.com/?target=http%3A//risingwave.com/slack\">risingwave.com/slack</a>\"</p><p>文档：&nbsp;<a href=\"http://link.zhihu.com/?target=http%3A//risingwave.dev\">risingwave.dev</a>\"</p><p>B 站：<a href=\"https://space.bilibili.com/3493144316348526?spm_id_from=333.999.0.0\">RisingWave中文开源社区</a>\" </p><p>微信公众号：RisingWave中文开源社区</p><p>社区用户交流群：risingwave_assistant</p>",
    "publish_time": "2023-06-02 11:27:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "国产GPU重要应用场景迎来突破！摩尔线程发布重磅产品与创新解决方案",
    "url": "https://www.infoq.cn/article/1UyH2okZUKWlbwby3dQV",
    "summary": "<p>5月31日，摩尔线程2023夏季发布会在北京举办。会上，摩尔线程宣布了一系列新产品与技术更新，涵盖数字办公、娱乐与创作、AI与云计算以及元宇宙等GPU重要应用场景。</p><p>&nbsp;</p><p>主要发布包括：面向游戏爱好者的DirectX 11社区版驱动、全新游戏显卡MTT S70及整机产品“智娱摩方”；GPU物理引擎AlphaCore迎来全新升级并开放测试下载；推出云桌面产品MT vGPU 2.1和MCCX VDI云桌面一体机；发布MUSA Toolkit 1.0软件工具包及代码移植工具MUSIFY；MTVERSE元宇宙平台重磅更新，可支持云端实时渲染；AIGC内容创作平台摩笔马良内测上线；DIGITALME数字人解决方案能力升级。</p><p>&nbsp;</p><p>摩尔线程创始人兼CEO张建中表示：“GPU在现代科技中的重要性不言而喻，它的强大计算能力和高效率使之成为各行各业的创新引擎，驱动着图形处理、计算机视觉、人工智能、科学研究等领域的突破性进展。作为一家创业公司，我们的战略是通过持续快速的元计算创新和生态合作伙伴的支持，致力于为客户提供更高效能、更可靠、更好用的GPU解决方案，以期推动行业的发展和进步。我们期待与各界伙伴共同合作，将这些创新成果应用于实际场景，推动GPU在数字经济时代的广泛应用。”</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/37/379da8509f365d21a563a5f2cb6ef2cd.png\" /></p><p></p><h2>从可用到好用，国产PC数字办公全面升级</h2><p></p><p></p><p>在国产数字办公领域，摩尔线程的目标是不断提升产品性能和应用体验，提供广泛的兼容性与全新的解决方案，推动国产化PC产品从“可用”迈向“好用”，助力行业数字化全面升级。</p><p>新增对OpenGL4.0与Vulkan1.3的支持，实现更高效的图形渲染：为满足国产化软件的需求，提供更丰富的图形特性支持，摩尔线程率先支持OpenGL 4.0和Vulkan 1.3的完整功能，并100%通过了接口兼容性测试。摩尔线程全功能GPU还可以借助新的Tessellation等图形特性，为应用提供更加精细的几何纹理效果。</p><p>&nbsp;</p><p>新增DKMS技术支持，快速适配不同操作系统内核：国产办公生态发展迅速，各种CPU与操作系统版本的组合上百种，适配的难度与复杂度极高。摩尔线程的驱动软件支持DKMS技术，可以快速适配不同操作系统的内核，从而使得开发效率提升数十倍。近期，摩尔线程成功适配了麒麟、统信、openKylin、deepin、凝思、中科方德、普华等国产操作系统，并率先与统信、麒麟OS完成了全面的兼容性认证，成为国内首家通过统信UHQL质量认证的GPU企业。</p><p>&nbsp;</p><p>性能不断优化，可加速近百款国产应用：通过驱动的不断优化，摩尔线程GPU的整体性能较初次发布时提升了2倍以上。目前，基于全国产化平台，对比国内外同类代表产品，摩尔线程全功能GPU性能在各种标准测评项目上均有2-3倍的提升。此外，摩尔线程GPU硬件产品已经加速了近百款国产应用，包括办公类、视频会议类、影音类、浏览器类、视频剪辑类、设计类以及GIS类软件等。</p><p>&nbsp;</p><p>摩尔线程持续在国产化数字办公的路上深耕，通过软硬件一体化的高质量交付，陆续完成了10余家ODM和18家OEM厂商的产品导入，共同推出了30余款PC机型，应用于电信、金融、能源等数字经济关键行业。</p><p>&nbsp;</p><p></p><h2>性能体验双升级，打造GPU云桌面办公新标准</h2><p></p><p></p><p>随着行业数字化转型的加速，企业对上云、用云的需求日益增长，传统的云桌面方案仅依靠CPU已无法满足新型办公和富媒体类应用的需求。中国信通院联合移动云、中国电信研究院、摩尔线程发布的《新型GPU云桌面发展白皮书 》中，明确定义了云桌面场景的体验标准，基于该标准，在视频播放、网页浏览、Office办公和教育教学软件四个主要场景，搭载摩尔线程MTT&nbsp;S2000的单台服务器，能够同时支持超过40路高清用户，这相比于传统只有CPU的方案，性能提升近5倍，整体的TCO降低60%以上。摩尔线程vGPU技术的创新及全新产品的发布，将带来云桌面性能和体验的双重提升。</p><p>&nbsp;</p><p>发布云桌面产品MT vGPU 2.1，性能全面升级：该产品新增了对摩尔线程MTT S3000显卡的支持，单卡并发的虚拟机数量达到28个，相较于之前，并发性能提升了40%；新增了GPU超分技术和对SRIOV的支持，在不改变硬件资源的情况下，超分技术会使得虚拟机数量实现翻倍，从而大幅降低客户成本，SRIOV技术则能提供更好的QoS、隔离性和安全性，保护客户数据免受侵犯；MT vGPU 2.1还将云桌面的整体体验升级到4K画质；通过对驱动进行升级，MT vGPU 2.1更是增加了对Windows Server版的支持，扩展了硬件能力和应用的支持范围。</p><p>&nbsp;</p><p>推出MCCX VDI云桌面一体机，助力教育和办公：摩尔线程MCCX VDI云桌面一体机，是包括服务器、瘦终端和软件在内的端到端交付方案，并专门推出教改特别版和办公体验增强版。教改特别版方案可以有效加速19款教改类软件（例如：Tello&nbsp;Edu、Code&nbsp;Craft等），办公体验增强版则针对60余款办公类软件（例如：WPS、PDF阅读器、视频会议和解压缩软件等）进行了定制优化。</p><p>&nbsp;</p><p>目前，摩尔线程已经与包括天翼云电脑、移动云电脑等在内的10余家客户的产品完成适配，并与深信服、新华三信息、华云、酷栈和庭宇科技完成了产品导入，基于摩尔线程vGPU的云桌面产品和解决方案将在各行各业落地。</p><p>&nbsp;</p><p></p><h2>DirectX 11抢鲜体验，解锁娱乐与创作新玩法</h2><p></p><p></p><p>“无图形，不GPU”，图形技术是衡量GPU技术创新能力的重要标志。自摩尔线程发布首张游戏显卡以来，近半年时间内，其显卡Windows驱动已完成5次升级，支持的游戏数量超过60款，并完成了对50多款主板和30多款显示器的支持，兼容性得到极大提升。性能方面，自显卡发布以来，游戏性能平均提升约50%，使得《英雄联盟》和《穿越火线》等主流网游在摩尔线程游戏显卡上的表现更加卓越。</p><p></p><p>摩尔线程旨在通过持续的软件技术创新和丰富的产品选择，以满足玩家和创作者对体验的高追求。</p><p></p><p>重磅发布DirectX 11社区版驱动，支持更多3A游戏：摩尔线程即将于6月下旬发布基于DirectX 11的社区版驱动，解锁包括《原神》和《DOTA2》等备受瞩目的3A级游戏作品，进一步为显卡玩家提供最新功能体验。同时，摩尔线程在“摩卡玩家”社区启动“Alpha行动”，召集更多玩家对DirectX 11社区版驱动的使用和反馈，以加速驱动的迭代速度。DirectX 11社区版驱动的发布，标志着摩尔线程成为首个真正支持DirectX 11游戏的中国GPU公司。</p><p>&nbsp;</p><p>发布MTT S70游戏显卡，提供丰富产品选择：MTT S70是专为游戏和视频场景打造的产品，搭载摩尔线程第二颗全功能GPU芯片“春晓”，内含3584个MUSA计算核心,&nbsp;在1.6G的主频下，能够提供11.2T FP32算力。显存搭配7GB高速GDDR6，带宽为392GB/s，支持多达4路8K30帧的超高清显示输出。此外，MTT S70对于剪映、OBS等视频直播和剪辑类软件可直接支持。</p><p>&nbsp;</p><p>推出整机产品“智娱摩方”，游戏与AI开箱即用：摩尔线程“智娱摩方”是业界首个基于国产GPU、集游戏和生成式AI应用于一体的智能终端设备，搭载MTT S80和MTT S70两款全功能GPU显卡，提供全方位的娱乐和创作体验。高颜值的外观下，预装了精选游戏中心和PES系统管理中心，可为用户提供开箱即用的体验。摩尔线程还将为用户开放Ubuntu驱动下载，凭借摩尔线程显卡高算力、大显存的特性，“智娱摩方”将更好地赋能AI计算领域的学习与应用开发。</p><p>&nbsp;</p><p>升级物理引擎AlphaCore，试用版本开放下载：AlphaCore是摩尔线程自研的下一代&nbsp;GPU多平台物理引擎，基于该引擎开发的实时流体仿真工具Catalyst FX全新版本，可以直接在Houdini中不改变原有工作流的前提下进行流体效果的制作，相比原生的PyroFX，可以达到5-10倍的性能提升；同时，相比过去传统的Houdini Vellume的制作流程，摩尔线程GPU加速的柔性体仿真工具VeraFiber能够将解算效率提升至先前的3-5倍。目前，Catalyst FX和VeraFiber已经完成了Houdini插件接口的开发，Houdini插件Beta版本将于6月6日开放下载。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9f/9f8ef434eb8c2a342b31ca0dc64ac4b6.png\" /></p><p>&nbsp;</p><p>值得一提的是，Catalyst FX Houdini版插件已与国内著名电影后期特效制作公司MOREVFX完成交付对接，AlphaCore也与网易游戏投资的CG动画制作团队DOVFX&nbsp;数海文化，进行了联合开发，成功将VeraFiber运用在游戏CG片头中复杂角色的布料和毛发仿真中。与此同时，AlphaCore也对DirectX 11的Compute Shader计算版本进行了深度优化，在流体力学仿真方面，Catalyst FX在MTT S80上的实际运行性能，已经达到了市场主流高端显卡的2倍以上。</p><p></p><h2>MUSA软硬件创新，助力AI与云计算高效开发</h2><p></p><p></p><p>GPU的应用创新，离不开广大开发者的贡献与支持。摩尔线程去年发布了MUSA元计算统一系统架构，包括统一的编程模型、软件运行库、驱动程序框架、指令集架构和芯片架构。围绕MUSA架构，摩尔线程面向开发者宣布系列重要技术更新，以打造更好的AI与云计算开发平台，满足AIGC时代的计算需求。</p><p>启动MUSA社区开发者计划，共建MUSA开发者生态：摩尔线程将为合作伙伴和开发者提供全套的MUSA开发工具、编程指南、系列教程和开源的框架及模型库等资源。同时，摩尔线程将与第三方社区合作，推动新算法模型、计算系统和平台的开发，不断提升社区价值。</p><p>&nbsp;</p><p>推出MUSA Toolkit 1.0软件工具包和“MUSIFY”代码移植工具：该工具包包含MUSA驱动、运行时库、编译器、AI加速库、数学库、通信库等，可充分发挥摩尔线程GPU的计算能力。与此同时，摩尔线程还推出了代码移植工具\"musify\"，可快速将现有的CUDA程序迁移至MUSA，零成本完成CUDA代码自动移植，之后用户短时间内即可完成热点分析和针对性优化，大大缩短迁移优化的周期，让开发者省时、省力、省事、省心。</p><p>&nbsp;</p><p>开源MT PyTorch，快速赋能开发者：基于MUSA，用户可以复用PyTorch开源社区的大量模型算子，降低开发成本；MT PyTorch支持多种模型的推理，覆盖CV、NLP、语音等多个领域，能够运行ChatGLM、Stable Diffusion、LLaMA等典型的大模型分布式多卡推理。利用数据并行、模型并行以及ZERO等分布式训练技术，MT PyTorch可完成简单基础模型以及典型Transformer结构的NLP语言模型的训练。</p><p>&nbsp;</p><p></p><h2>全场景多元化方案，推动元宇宙应用落地</h2><p></p><p></p><p>结合图形渲染、物理仿真、AI训练和推理等能力，摩尔线程不断完善元宇宙应用中的人、场景、内容等核心要素，并带来系列重大升级，以更好赋能数字城市、数字教育、数字医疗、数字能源、数字办公等行业，与合作伙伴共同探索数字经济的未来。</p><p>&nbsp;</p><p>MTVERSE元宇宙平台升级，支持云端实时渲染：MTVERSE是一个提供可扩展性能、实时渲染与模拟以及AI驱动的多元化算力支持的元宇宙平台。领先的第三方IDC服务商世纪互联在云端率先部署了摩尔线程千卡级别的GPU算力集群，并成功将MTVERSE平台与虚幻引擎和云渲染流化技术结合，为51WORLD旗下的51Meet元宇宙高精度开放平台提供了计算加速，这也是首个实现国产化闭环的元宇宙应用。在多人并发下，用户可以享受低延迟、高保真、沉浸式的元宇宙体验。此外，包括咪咕元宇宙、智汇云舟视频孪生、瞰景三维重构等都在陆续更新中。</p><p>&nbsp;</p><p>AIGC内容创作平台摩笔马良，内测上线：摩笔马良是摩尔线程推出的软硬件一体化的AIGC内容创作平台，提供了多种接入方式，可以通过Web和小程序登录，也可以通过丰富的API供用户远程调用。对于需要完整解决方案的用户，摩尔线程提供私有化部署能力，包括GPU集群、异构算力调度平台、API接口以及类似于摩笔马良的样板应用。</p><p>&nbsp;</p><p>DIGITALME数字人解决方案升级，包含2D和3D：DIGITALME包括“女娲”数字人生成器、“画皮”表情驱动引擎、“随影”动作驱动引擎和“随答”对话系统。其中，“随答”迎来了两大主体能力的升级：一是通过语音与人自然交互，实现了“能听能说”的功能；二是基于大语言模型的智能问答，实现了“会思考且言之有物”的功能。发布会还展示了基于DIGITALME技术平台制作的两个数字人产品方案——2D播报数字人和3D交互数字人。摩尔线程期待与各行业的合作伙伴共同创作多类身份职能的数字人，在直播、社交、影视动画、办公、娱乐等场景中广泛应用。</p><p>&nbsp;</p><p>GPU的应用落地是检验其技术创新的“验金石”。随着摩尔线程PES完美体验系统联盟不断扩大，摩尔线程将携手更多的生态合作伙伴，持续迭代和优化产品性能，提供稳定可靠解决方案，以此融入和落地更丰富的应用场景。作为一项长期事业，摩尔线程将始终以全功能GPU为核心，推进持续的产品创新和扩展生态力量，推动更多数字经济应用落地。</p>",
    "publish_time": "2023-06-02 13:56:21",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "技术团队很刻板？这些团队的日常可不这样！",
    "url": "https://www.infoq.cn/article/quHs8XqTeyIQcsvJqNIQ",
    "summary": "<p>怎么融入新团队？都给同事起啥外号？团建都做点什么？快来看看阿里云可观测团队、<a href=\"http://mp.weixin.qq.com/s/duNr-fxdUylc6fiKuY_qjQ\">中关村科金AI平台能力中心</a>、<a href=\"http://www.infoq.cn/article/l9mI8rKrka6RUt2xvZDo\">深算院YashanDB研发团队</a>的有趣日常！</p>\n<p>查看更多技术团队的精彩故事，可点击下载<a href=\"http://www.infoq.cn/minibook/oNFwzf07ulmVajPeIBVF\">《中国卓越技术团队访谈录（2023 年第一季）》</a></p>",
    "publish_time": "2023-06-02 13:56:21",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "DevOps vs 平台工程，你想了解的都在这里 ｜ QCon闭门会",
    "url": "https://www.infoq.cn/article/4uHEPy7XI5ORkaTTiZXN",
    "summary": "<p>在5月26日，<a href=\"https://qcon.infoq.cn/2023/guangzhou/schedule\">QCon全球开发者大会（广州站）</a>\"顺利落地，在现场，InfoQ 特别策划了五场闭门会，主题分别为《企业在 LLM、AIGC 浪潮下的研发探索》《DevOps vs 平台工程，必要性和 ROI 探讨》《破解成本优化后的稳定性问题》《业务出海之架构、合规、运营》《金融行业数据治理经验分享》，本文为《DevOps vs 平台工程，必要性和 ROI 探讨》研讨纪要整理～</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/f7/f7a9fac33999697a391834dc72445172.jpeg\" /></p><p></p><h4>参与嘉宾</h4><p></p><p>主持人：李忠良&nbsp;InfoQ&nbsp;会议编辑&nbsp;</p><p>William&nbsp;Yang，HashiCorp资深SA，讲师金李东，涂鸦智能（技术总监）杨振兴，东软瑞驰大连研发团队负责人汪维敏，华为云&nbsp;PaaS产品总监&nbsp;李大元，蚂蚁技术专家，KusionStack子项目负责人周玄，小红书Android&nbsp;架构负责人刘星辰，众安保险工程效能高级专家江鹏，数澈科技联合创始人彭伟国，解决方案架构师</p><p>&nbsp;</p><p></p><h4>研讨话题：</h4><p></p><p>讨论话题一：你如何看待&nbsp;DevOps与平台工程的关系讨论话题二：你认为是否有必要上平台工程？投入产出比怎么样？讨论话题三：平台工程的落地难点</p><p></p><p></p><h4>精彩观点</h4><p></p><p></p><h5>你如何看待&nbsp;DevOps与平台工程的关系</h5><p></p><p>李大元：前段时间有“DevOps已死，平台工程才是未来”，我不认同，我认为平台工程是 DevOps的延伸。</p><p>&nbsp;</p><p>汪维敏：我在平台工程领域的经历中，发现以下要点值得分享。首先，仅仅开发工具是不够的，我们需要将其以商业化的方式进行开发，以实现产品的精品化。其次，了解方法论对于成功开发受人接受的工具至关重要。平台工程与DevOps相互关联，共同推动研发效能的提升。商业化是取得出色成果的关键，仅在公司内部提供工具服务的平台工程组织很难实现优质用户体验。同时，平台工程在落地过程中面临各种挑战，如工具集成、权限系统整合、多租户问题以及可靠性和安全性等。通过持续努力和创新，我们能够推动研发效能的提升，实现产品的精品化，并为用户提供优质体验。</p><p>&nbsp;</p><p>刘星辰：众安保险在研发运维方面建立了一套完善的体系，并通过科技公司的商业化输出来扩大影响。在内部和外部的研发运维中存在一些差异，外部客户更注重第三方解决方案，而内部则受到一些限制。DevOps与平台工程的关系是相互补充的，DevOps关注整个从需求到上线的流程，而平台工程则为开发者提供自动化和产品化的服务。在平台工程阶段，通过标准化和服务化，开发者可以屏蔽底层基础设施并获得赋能服务。这个阶段是横向和纵向结合的过程，能够产生协同效应。</p><p>&nbsp;</p><p>彭伟国：我从事IBM Rational产品的实施大约十几年，期间接触到了IBM的一些DevOps产品。在实施DevOps时，面临着客户项目的多样性，涉及不同的价格和语言，起初推广DevOps非常困难。然而，在过去的两年里，大家形成了共识，推广变得更加容易，我认为这与平台工程密切相关。</p><p>&nbsp;</p><p>过去，我在公司内部有各种语言和架构，想要实施DevOps非常困难，尤其是面对部门的限制。比如当我在广发银行工作时，首先，我们需要一个统一的开发框架，所有产品都基于同一平台的架构开发。有了这样的情况，推广DevOps就变得非常快速。我记得起初花了大约半年时间推广到广发银行的6个系统，但后来仅仅花了半年时间推广到200多个应用系统。</p><p>&nbsp;</p><p>平台工程与此密切相关，因为在这种情况下，可以快速复制，DevOps快速推出。所以我认为DevOps和平台工程是相辅相成的。在平台工程中，你需要有一个团队进行研发，在这个过程中，你如何管理需求？如何进行配置管理和持续集成？这些都需要DevOps来指导。但是，如果你公司内部所有系统都是通过统一的平台工程整合和开发的，推广会更顺利。</p><p>&nbsp;</p><p>杨振兴：过去我们作为DevOps需求方，在实现过程中遇到了许多场景。我们希望OpenAI团队能够为我们提供帮助，提升整个研发效能。现在我更加偏向于ToB，我们可以通过从需求到持续集成，持续交付等多种开源工具的组合来实现。但是每个行业都有其特有的东西，这些标准工具无法替代。因此，我们将整合这些东西，并结合行业特点，打包成一个完整的产品体系，然后将其推广给特定行业的客户。</p><p>&nbsp;</p><p>例如我们现在正在与一家汽车制造商合作，对于车联网而言，每当我们将解决方案成功应用于一家汽车系列后，我们就可以将其作为一个整体产品引入到另一家汽车系列的新项目中。这样，我们实际上就是利用了DevOps工具，打造了一个特定领域的完整产品，并作为一个平台工程来提供服务。不管是产业互联网还是其他领域，借助DevOps的方式结合行业特点，推出平台工程是可行的方式。</p><p>&nbsp;</p><p>金李东：平台工程与DevOps密切相关，它在支持DevOps实施方面起到关键作用。在我们公司的发展过程中，我们经历了快速膨胀，并尝试了多种DevOps工具，却未能满足特定的需求。团队的扩张速度、节奏、人员能力和文化体系等方面存在差距，使得推动DevOps变得困难。</p><p>&nbsp;</p><p>为了处理全球不同数据中心和节点的流量以及配置问题，我们尝试了公有云和私有化部署，但发现每个云和数据中心的配置需求各不相同。为了解决这些问题，我们决定将研发团队与平台工程结合起来，以处理不同云、数据中心和版本的配置，并根据规模确定适当的支撑能力。尽管曾尝试将开发和运维分开管理，但目前还未取得成功。</p><p>&nbsp;</p><p>江鹏：对于Devops的理解在不同公司和行业之间存在差异。个人认为，Devops更像是一种文化，旨在推动研发和运维部门之间的协作，提高交付应用业务价值的速度。在实际落地时，个人经验是，不同公司的形态可能不太相同。传统企业很难让研发完全掌控应用的部署和生产环境，因此可能会设立所谓的Devops团队或工程师，作为技术架构和运维之间的桥梁。</p><p>&nbsp;</p><p>然而，也有一些规模较小的公司，每个工程师都精通研发和技术架构知识，并能够负责从产品开发到应用发布的整个流程。因此，对于如何实施Devops，并没有一个统一的标准和规范。</p><p>&nbsp;</p><p>对于大型企业来说，不可能每个研发人员都精通各种基础设施知识，完全驱动应用的开发和部署。因此，平台工程的作用在于建设一个平台，通过屏蔽复杂性，为开发和产品团队提供可复用的能力，以降低他们的认知负担，实现产品的交付。个人理解中，这需要建立一些方法论，并构建相应的平台。</p><p>&nbsp;</p><p></p><h5>你认为是否有必要上平台工程？投入产出比怎么样？</h5><p></p><p>&nbsp;</p><p>江鹏：是否需要引入平台工程：个人观点认为，是否需要引入平台工程与团队情况和公司规模有关。对于创业公司等规模较小、研发人员都懂得容器和Kubernetes等技术的公司来说，暂时可能没有必要引入平台工程。至于投入产出比：在考虑是否引入平台工程时，需要关注投入产出比。海外案例显示，引入平台工程可以提升运维和Devops功能支撑的研发数量，并加快交付速度。</p><p>&nbsp;</p><p>然而，一个广州的大型银行客户的案例显示，他们已经引入了平台工程，包括内部开发者门户和使用Git、GCP和AWS等工具来实现整个流水线。该银行通过试用平台工程并比较原有方式的时间和成本差距，说服研发团队使用该平台工程，因为投入产出比明显提高。</p><p>&nbsp;</p><p>汪维敏：平台工程的建设需要大量资金支持，而华为作为一个投入较大且拥有众多研发人员的公司，通过从各个产品线预算中拨出一部分资金来支持平台工程。随着团队规模和研发组织复杂度的增加，以及内部使用的工具增多，统一语言、环境和工具的重要性变得更加突出，以提升沟通和效率。</p><p>&nbsp;</p><p>对于公司而言，投入产出比是决定是否愿意持续投资于平台工程的关键因素，当产品线或部门能够通过平台工程解决问题并实现成本节省时，公司会有更大的动力投入资金，无论是通过整个公司直接拨款还是通过各个产品线的预算汇总来支持公共的平台工程部门。</p><p>&nbsp;</p><p>William&nbsp;Yang：从工具提供商原厂的角度来看，我们经常遇到一个情况，即客户对DevOps的理解和需求不同，导致他们在开发平台工程方面采取不同的方法。有些人可能基于成熟产品如IBM，有些人可能选择GitLab，而我们Hashcop则根据自己的理解开发了Telephone Enterprise和Clock Operation Model，并将其与我们的产品集成。</p><p>&nbsp;</p><p>因此，根据企业规模和业务需求的不同，选择基于成熟产品模式还是完全自研的方式来构建平台工程会有所偏向。前面提到的企业规模和业务差异都会影响人们在选择和实施时的倾向。</p><p>&nbsp;</p><p>我注意到有时候基于自研方式可能会导致过多功能的堆积，最终无法完全实现这些功能。我不清楚这种自研方式在安全性和效率方面的表现如何，特别是投入产出比方面的投入情况，以及后续维护成本的变化，例如员工离职和核心团队流失等。维护成本会随着业务的变化而不断更新。</p><p>&nbsp;</p><p>因此，我们会看到一些成功的案例，也有一些自研方式的失败案例。有些案例刚开始做得很好，但最终发现投入的成本过高，无法持续下去，因为缺乏业务驱动。因此，基于已经成熟的产品来构建平台工程仍然是一个值得考虑的选择。在这方面，我们已经看到了许多成功的案例。</p><p>&nbsp;</p><p>彭伟国：大家刚才提到了是否需要进行平台工程，实际上在我实施的几个客户项目中，像XX银行，当时并不是从头开始构建平台工程。他们首先基于一些工具来开发了整体框架，其中还没有包括用户管理和权限管理等功能，但他们提供了一个基础平台。这涉及到一个投入产出比的问题，即如果你在运维和维护团队方面投入大量精力，最后的投入是否划算。所以XX银行当时只是基于这个框架提供了一些基础服务，其他方面如客户管理则由业务团队开发，平台团队提供基础的开发工具。因此，在考虑投入产出比时，首先要看团队的规模，如果你的团队规模较大，比如上千人的开发团队，我认为是有必要进行平台工程的。</p><p>&nbsp;</p><p>李大元：平台工程是一项工程化的任务，需要规模才能实现收益。对于规模庞大的团队来说，是否进行平台工程取决于技术投资的问题。技术投资意味着解决当前架构和技术无法解决的问题。在云原生时代，基础设施的多样性增加，平台团队无法成倍增加。因此，通过技术手段和进化来保证团队在人数不变的情况下，仍能管理更多的基础设施是必要的。进行平台工程的决策应基于实际问题和投资回报率（ROI）的价值判断。如果认为投资值得，就应该进行平台工程；如果认为不值得，即使团队规模庞大，也可能不需要。</p><p>&nbsp;</p><p>周玄：过去两年，我们经历了快速增长的阶段，业务和研发团队都翻了倍。然而，我们面临了一个问题，尽管我们依然保持高标准的招聘要求，但由于产品增多，整个迭代速度并未放缓。我们发现业务产品和研发团队的需求吞吐量正在下降，交付质量也在下降。因此，我们开始意识到，产品和研发团队的增长不是突然跃升，而是一个持续迭代的过程。</p><p>&nbsp;</p><p>现在，我们面临着一个增长过程，需要讨论的是，是基于我们已有的DevOps工具进行迭代和需求收集，还是引入一套成熟且产品化的解决方案。目前，我们可能暂时选择前者，因为后者的投入存在不确定性，并且公司目前还没有形成一个专门的团队来考虑投入和产出的具体过程。我们认为维持一个小团队可以解决当前的问题。然而，从这个阶段来看，这可能是一个从量变到质变的过程。我不太相信在未来一年中，我们的规模再翻倍后，仅通过迭代从第一版到第二版，再到第三版就能解决问题。</p><p>&nbsp;</p><p>杨振兴：公司规模和产研能力是其中的重要考虑因素。我认为还有几个点也值得讨论。首先，公司处于不同的阶段，特别是在快速扩张阶段，很可能会出现混乱的情况。不同团队在技术栈和技术理念上可能存在差异，很难统一起来。因此，在不同阶段需要进行整合和规范化。</p><p>&nbsp;</p><p>另一个要考虑的问题是是否需要采用平台化的公司架构。我有过两种不同公司的经历，感受差别很大。对于像整个技术内部一体化的公司来说，一个重要的指标是研发人员的效率。比如，在短时间内能否交付小需求，以及交付后的反馈速度。对于ToB领域来说，这涉及到项目回款的算法。在我们的场景中，关键问题是能在多长时间内收到项目回款。如果公司的盈利指标与项目回款有关，那么根据这个指标来决定是否采用平台化架构将是一个重要的决策因素。</p><p>&nbsp;</p><p>金李东：根据业务团队的预算来计算DevOps或基础支持团队的存在和体现的价值。我们的目标是解决研发项目的问题。对比涂鸦和小红书，涂鸦在几年内扩张到了几千人规模，但我们的DevOps团队的比例是根据业务团队的需求同步扩招。</p><p>&nbsp;</p><p>我们使用了许多云服务，包括海外和国内的云服务。每个云平台的特性和适配要求都不同，但我们的人员资源有限。因此，ROI（投资回报率）成为体现价值的重要指标。当然，对于平台的工程建设，可能会有一个节点，当平台的数据稳定时，我们需要评估现有的人力资源支持情况。这时，我们可以根据ROI来评估整个团队的价值。</p><p></p><h5>平台工程的落地难点？</h5><p></p><p>&nbsp;</p><p>汪维敏：当构建一个开源平台时，有几个关键问题需要解决。首先是整合账户和权限体系，确保各个工具之间的账户和权限可以通用。其次是要考虑平台的开放性，采用全插件化的架构，以兼容各种开源工具。数据一致性也是一个重要挑战，因为每个工具都有自己的数据模型和数据库，需要统一数据架构模型来实现数据的集中存储。另外，可靠性问题也需要被关注，因为开源工具可能存在限制和性能瓶颈，需要技术能力来解决并确保系统的稳定性和安全性。</p><p>&nbsp;</p><p>另外，开发者通常缺乏忠诚度，他们对新技术和工具的期望极高，迅速抛弃旧有解决方案。因此，在开发工具时，我们必须采用产品化思维，确保立项阶段明确资源投入和功能场景化设计。此外，内部开发团队应当以产品化思维为导向，设立产品经理来管理和开发工具，而不仅依赖开发人员。</p><p>&nbsp;</p><p>杨振兴：推进平台工程需要综合考虑公司的业务架构、组织架构和技术架构。首先要了解使用平台的各方用户，包括研发、运维、产品、运营和客户等，以及整个公司的技术架构。对于技术架构较为分散的公司，需要从公司的线索中进行思考，确定优先满足的需求，并逐步推广给其他用户。在组织架构方面，可以通过扁平化结构和开放心态促进工具的使用，同时解决组织层面的问题。在ToB领域中，若公司习惯难以改变，引进外部人才并借鉴他们的经验和思想，有助于推动工具的接受和落地。沟通和协作也是解决组织架构问题的重要因素。</p><p>&nbsp;</p><p>刘星辰： 首先，需要确定团队的定位和服务角色，并在短期内展示比现有工具更好的表现，同时说服用户相信未来会有更好的发展。其次，落地过程中需要借助技巧和说明产品的价值，不论是面向甲方还是乙方团队，都要明确产品相对于现有工具的优势。接着，以产品化的思路进行工作，制定明确的目标和路线图，迭代过程要渐进进行，周期内的替换和升级是对内部用户的承诺，同时促使研发资源跟进以实现承诺的目标。最后，要注意系统化的替换和演进是一项艰巨的任务，需要整个体系的全面支持，企业内部可能存在赛马机制和团队间的竞争，也会采用开源等方式，通过最佳实践的形成来推动落地过程。</p><p>&nbsp;</p><p>江鹏：我分享三方面，首先是开发者体验：平台工程需要提升开发者的体验，让他们更高效地工作。同时，设计要屏蔽基础设施的复杂性，通过抽象和定义新的模型来实现。关键是确保设计能够提供比现有工具更好的开发者体验，而不需要用户花费高成本学习使用平台；</p><p>&nbsp;</p><p>其次是产品的差异化：当推出一个新工具时，需要让用户明白为什么要使用你的工具而不是已经存在的工具。根据\"十倍理论\"，你的产品必须比现有方案更好10倍，才能打动用户。平台功能可能是基于现有工具进行改良，所以要结合类似工具并创造差异化；</p><p>&nbsp;</p><p>最后是自服务与安全管控的权衡：平台工程追求开发人员自服务的同时，企业也需要安全管控。需要权衡如何让开发人员自服务的同时满足企业的合规要求。底层需提供足够的能力支撑，例如在部署前进行合规检查，确保拦截不合规的情况。</p><p>&nbsp;</p><p>金李东：我们团队开发了VPA和HPA解决方案，旨在降低成本并提高效率，改善整体可用性。起初，在管理周会上，我向团队提出了推广的建议，所有的团队负责人都认可这个方案。然而，当我们最终推广方案时，只有大约10%不到的应用选择开启这两个功能。团队负责人不愿意强制要求各个团队负责人或应用的负责人开启这些功能。我们首先选择了一些小规模试点，经过一段时间的运行，没有出现任何问题，我们随后强制性地开启了所有线上应用的VPA和HPA功能。现在，所有的自动弹性伸缩功能都已经开启，并且没有遇到任何问题。通过柔性和硬性相结合的方法，我们最终取得了成功。</p><p></p><h4>活动推荐：</h4><p></p><p>&nbsp;</p><p>2023 年 9 月 3 - 5 日，在<a href=\"https://qcon.infoq.cn/202309/beijing\">北京·富力万丽酒店</a>\"， QCon 全球软件开发大会（北京站）已开启，现已开启售票，提前订票，可享受7折早鸟价，购票参会可以直接电话 / 微信联系票务经理 18514549229。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/e2/e2cc6621bc634e6d3fcacee922604626.jpeg\" /></p><p></p>",
    "publish_time": "2023-06-02 14:46:17",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "腾讯云 TEG 云架构平台部应用框架负责人罗成确认担任 ArchSummit 深圳专题出品人",
    "url": "https://www.infoq.cn/article/XApSDVKVfsDGccMMjAox",
    "summary": "<p>7&nbsp;月&nbsp;21&nbsp;日&nbsp;-&nbsp;22&nbsp;日，&nbsp;在&nbsp;<a href=\"https://archsummit.infoq.cn/2023/shenzhen?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">ArchSummit&nbsp;全球架构师峰会（深圳站）</a>\"，腾讯云&nbsp;TEG&nbsp;云架构平台部应用框架负责人罗成，将担任「QUIC&nbsp;传输和架构优化」的专题出品人，在此次专题中将重点介绍&nbsp;QUIC&nbsp;在各个业务场景的应用和优化，比如直播，点播，广告，游戏；同时也会从工程架构和传输算法角度介绍&nbsp;QUIC&nbsp;的单机转发能力和传输效果的优化提升。</p><p></p><p>罗成是腾讯&nbsp;TEG&nbsp;云架构平台部应用框架负责人，13级专家工程师。目前主要负责腾讯&nbsp;CDN&nbsp;和边缘云的四层云原生网关&nbsp;Legate，七层转发框架&nbsp;LEGO&nbsp;以及传输协议&nbsp;TQUIC&nbsp;的技术管理和研发工作。在高性能网络转发、负载均衡、TCP/QUIC&nbsp;传输协议优化、安全防攻击等领域有较多的工作经验。</p><p></p><p>欢迎了解罗成此前的两次协议优化实践：《<a href=\"https://zhuanlan.zhihu.com/p/33940885?group_id=962283933237456896\">Web协议未来优化指南</a>\"》、《<a href=\"https://zhuanlan.zhihu.com/p/25290538\">HTTPS性能优化实践</a>\"》</p><p></p><p>除上述专题外&nbsp;，ArchSummit&nbsp;深圳还将围绕<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1537?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">基础架构技术</a>\"、<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1536?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">智能化数据治理</a>\"、<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1532?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">DataOps、Data&nbsp;Fabric&nbsp;等高效数据开发与服务模式</a>\"、<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1534?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">Mesh&nbsp;技术实践案例</a>\"等进行分享。</p><p></p><p>数十位业界专家，上百个国内外一线大厂前沿技术案例，一定会给你带来很多全新的开发灵感。期待与你线下交流！&nbsp;现在购票，享&nbsp;8&nbsp;折特惠，立省&nbsp;¥1760！咨询购票请联系&nbsp;18514549229（微信同手机号）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9d/9d6a27547062ee2e089f91bdc4ba1eaa.png\" /></p><p></p>",
    "publish_time": "2023-06-02 16:22:14",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "年薪60万的数据分析师工作保不住了？！阿里达摩院研究发现，改用GPT-4成本只需几千元",
    "url": "https://www.infoq.cn/article/6LAGtDef93ytGip8YVd1",
    "summary": "<p></p><blockquote>GPT-4 真的可以取代数据分析师吗？</blockquote><p></p><p>&nbsp;</p><p>今年 3 月 14 日，OpenAI 发布了新“核弹”——<a href=\"https://www.infoq.cn/article/HFSPasQ7SXZ9QzdFXhGO\">GPT-4</a>\"。OpenAI 联合创始人 Sam Altman 表示，GPT-4 是“迄今为止功能最强大的语言模型”。与上一代相比，GPT-4 更强大更可靠，且更有创造性。</p><p>&nbsp;</p><p>GPT-4 的发布让更多的人意识到，在聊天之外，人工智能的能力已不断扩展，并引发了部分人群对职业危机的担忧。有开发者担心，在未来的几十年内，AI 会循序渐进地取代一些开发岗位。</p><p>&nbsp;</p><p>不过，GPT-4 的“野心”似乎不止于此，“取代程序员”浪潮未过，新一轮“取代潮”已经掀起。这一次，GPT-4 瞄准了年薪60万的数据分析师。</p><p>&nbsp;</p><p>近日，阿里达摩院与新加坡南洋理工大学发布了一个关于用 GPT-4 取代数据分析师的成本核算的研究论文。论文指出，随着LLM的兴起和流行，不仅在NLP社区，其他诸多领域的人们都在考虑、或者担心自己的岗位可能被AI所取代。其中数据分析师成为AI时代下“首当其冲”的取代对象。</p><p>&nbsp;</p><p>论文认为，数据分析师的主要工作内容就是从业务数据中识别出有意义的模式和趋势，并为利益相关者提供有价值的见解、协助制定战略决策。为了实现这个目标，数据分析师必须具备多种技能，包括SQL查询编写、数据清洗和转换、可视化生成和数据分析。由于工作流程相对较为固化确定，因此公众对于AI是否将取代数据分析师展开了激烈讨论。</p><p>&nbsp;</p><p>论文指出：“除了所有数据分析师和<a href=\"https://www.infoq.cn/article/XjQulGof86OSHoPU0xbX\"> GPT-4 </a>\"之间的可比绩效外，我们可以注意到 GPT-4 所花费的时间要比人类数据分析师短得多。我们假设每个月有大约 21 个工作日，每天工作 8 小时左右，并根据每个级别的数据分析师所花费的平均时间计算出每个实例在美元方面的成本。GPT-4 的成本约为初级数据分析师成本的 0.71％和高级数据分析师成本的 0.45％。”</p><p>&nbsp;</p><p>在脉脉上，不少<a href=\"https://xie.infoq.cn/article/628fb5c35dbf860258108c1c1\">数据分析师</a>\"岗位给到了月薪40k以上，以高级数据分析师年薪60万元为例，GPT-4 的成本大概在2700元左右。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bd/bd674b43d843d2c14f480b7bfe64a003.jpeg\" /></p><p>论文地址：</p><p><a href=\"https://arxiv.org/abs/2305.15038\">https://arxiv.org/abs/2305.15038</a>\"</p><p></p><h2>作为数据分析师，GPT-4大概是什么水平？</h2><p></p><p>&nbsp;</p><p>在论文中，研究人员试图分析：作为数据分析师，GPT-4大概是个什么水平？</p><p>&nbsp;</p><p>首先，研究人员将数据分析师的主要工作内容分成三个步骤：</p><p></p><p>数据收集：主要包括理解业务需求，并决定哪些数据源与需求有所关联。确定了相关数据后，分析师就可以通过SQL查询或其他工具提取所需的数据。数据可视化：创建视觉辅助工具，例如图形和图表，借此高效传达见解。数据分析：在数据分析阶段，分析师可能需要确定不同数据点之间的关联性，识别异常和异常值，并跟踪随时间而变化的趋势。在此过程中得出的见解，可以通过书面报告或演示文稿的形式传达给利益相关者。</p><p>&nbsp;</p><p>根据数据分析师的主要工作范围，研究人员专门设计了一个GPT-4数据分析师模拟流程。如下图所示，其中，业务问题和数据库等强制输入信息显示在右上角的蓝色框内，参考的外部知识源作为可选输入则位于左上角的红色虚线框内。下方绿色框中的是提取数据（data.txt）、数据可视化（figure.pdf）和分析等输出结果。</p><p><img src=\"https://static001.geekbang.org/infoq/eb/ebfa938aed9bde5665c4b2cd07ad6c15.png\" /></p><p></p><p>具体而言，给定一个与业务相关的问题（q）和一个或多个相关数据库表（d）及其模式（s）。目标是提取所需数据（D），生成可视化图表（G），并提供分析和见解（A）。</p><p>&nbsp;</p><p>根据给定问题，分析师需要从数据库中挑选出生成图表所需要的数据，并对这些数据做有意义的组织排列。例如，“请展示散点图中身高和体重之间的相关性”。可以看到，问题中还包含了图表类型信息，因此应当根据数据的性质和所提问题选择合适的图表类型，并使用合适的软件或编程语言生成图表。最后，需要分析数据以确定有助于回答问题的趋势、模式和见解。</p><p>&nbsp;</p><p>研究人员希望使用GPT-4实现整个数据分析过程的自动化，并按图1所示的步骤进行。这主要涉及三个步骤：代码生成（蓝色箭头所示）、代码执行（橙色箭头所示、分析生成（绿色箭头所示）。该框架的算法如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/da/da8054a053486226d1f4e3123a598c9c.png\" /></p><p></p><p>为了判断GPT-4作为数据分析师的水平如何，研究人员选取了200个样本，并对GPT-4的输出进行了系统且专业的人工评估，整个评估共分为两组。研究人员主要通过以下指标，对LLM的数据分析能力做定量评估：性能、时间和成本。具体来说，研究人员让GPT-4作为数据分析师解决几个端到端数据分析问题。由于此类数据分析问题没有可供参考的现成数据集，所以研究人员选择了相关度最高的数据集NvBench，并在其中添加了数据分析部分。研究人员还设计了几项自动和人工评估指标，用以综合评估提取的数据、绘制的图表和生成的数据分析结论的实际质量。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fe/fe2f279f4ba7877fd0ed0341b7c63a8f.png\" /></p><p></p><p>结果发现，在正确选取图表类型方面，两个评估组几乎都拿下了满分。这说明对于“绘制条形图”、“显示饼状图”等简单明了的指令，GPT-4能够轻松理解其含义，并结合关于图表类型的背景知识正确绘制出适合的图表。在美学得分方面，GPT-4的平均得分为2.73分（满分3分），这表明生成的大部分图形对受众来说清晰、不存在格式错误。但在所绘制图表的信息正确性方面，GPT-4的得分无法令人满意。研究人员手动检查了这些图表，从中发现了一些小错误，但大部分图表仍给出了基本正确的数字。研究人员的评估标准非常严格，只要任何数据或者x轴/y轴标签有误就必须扣分。从这个角度看，GPT-4的工作能力仍有进一步改进的空间。</p><p>&nbsp;</p><p>在对分析能力的评估方面，GPT-4的对齐度和流畅度均获得满分。这再次证明GPT-4特别善于生成顺畅且语法正确的句子。不过，分析的平均正确性分数远高于数字的信息正确性分数，也就是说，GPT-4可能会生成错误数字，但分析结论却是正确的。图表当中只有少数会产生重要影响的数据错误点。而在复杂度得分上，GPT-4的2.16分（满分3分）也合理且令人满意。</p><p></p><h2>人类数据分析师 VS GPT-4，谁更胜一筹？</h2><p></p><p>&nbsp;</p><p>同样的任务，专业的数据分析师会做得比 GPT-4 更好吗？</p><p>&nbsp;</p><p>为了对比GPT-4与人类数据分析师的表现，研究人员聘请了几位不同背景的专业数据分析师重复完成任务，并与GPT-4做了全面比较。结果发现，总体来看，GPT-4的表现与人类数据分析师基本相当，但双方在不同指标上各有优势侧重。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/43/43e9bac68583f594990a7710d7b802a4.png\" /></p><p></p><p>图4第一部分表示一位在金融行业有6年以上工作经验的高级数据分析师（Senior Data Analyst 1）在10个样本上的表现。从表中可以看到，GPT-4的性能在大多数指标上都与这位专业分析师相当。虽然GPT-4的正确性得分比人类分析师低，但复杂度得分和对齐度得分更高。</p><p>&nbsp;</p><p>第二部分为GPT-4同另一位在互联网领域拥有5年以上经验的高级数据分析师（Senior Data Analyst 2）在8个样本上的性能比较。由于样本量相对较小，结果显示人类分析师与AI之间存在较大差异。人类分析师在信息正确性、图形美观性、见解正确性和复杂度等方面均超过了GPT-4，表明大语言模型仍有改进的空间。</p><p>&nbsp;</p><p>第三部分比较了GPT-4同一位在咨询公司工作不足2年的初级数据分析师间在9个随机样本上的性能。GPT-4不仅在数字和分析正确性上表现更好，而且也比人类分析师更倾向于生成较为复杂的分析结论。</p><p>&nbsp;</p><p>此外，研究人员还对比了GPT-4与人类分析师所需的成本，结果发现GPT-4花费的时间比人类分析师短得多。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1c/1cc08044ee8c1e960a1a72f65e3bb348.png\" /></p><p>&nbsp;</p><p>图5为不同受试方之间的成本比较。研究人员从level.fyi提取了新加坡数据分析师的年薪中位数，从Glassdoor查到了新加坡数据分析师的平均年薪。假定每个月约有21个工作日，每天工作8个小时左右，并按不同级别的数据分析师平均花费的时间来计算各个实例的具体成本（以美元计价）。最终结果是：在根据市场价格为各位数据分析师计费时，GPT-4的成本约是初级数据分析师的0.71%，是高级数据分析师的0.45%。</p><p>&nbsp;</p><p>GPT-4这样的大语言模型真能取代人类数据分析师吗？在论文的结尾，研究人员并未给出明确结论。虽然从分析结果来看，GPT-4的实际表现几乎与人类相当，并且所需的成本更低，但能否全面取代人类数据分析师仍需要进一步研究。</p>",
    "publish_time": "2023-06-02 16:23:29",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "红帽已经将AIGC技术融入产品线，为企业级场景提供服务",
    "url": "https://www.infoq.cn/article/4m0JmOXJzLyebBaFcxJ6",
    "summary": "<p>去年底至今，AIGC技术引发了全球范围内的讨论，从技术创新到落地实践，再到对各行各业从业者带来的实际影响不绝于耳。</p><p></p><p>在近期的红帽全球峰会上，<a href=\"https://www.infoq.cn/article/29hcONeZ4YbQpGkNzchp\">红帽</a>\"宣布已经将AIGC的能力与产品线进行了融合，部分已经在企业级场景进行落地。本文，红帽总裁兼CEO&nbsp;Matt&nbsp;Hicks，红帽首席技术官&nbsp;Chris&nbsp;Wright，红帽首席产品官&nbsp;Ashesh&nbsp;Badami&nbsp;就具体情况做了简要分享。</p><p>&nbsp;</p><p></p><h2>生成式AI在企业场景的落地探索</h2><p></p><p>&nbsp;</p><p>InfoQ：红帽计划如何在产品中利用生成式AI技术？</p><p>&nbsp;</p><p>Matt：对于<a href=\"https://www.infoq.cn/article/wAM6PJiYjiyyj3l2jt4x\">生成式AI</a>\"，最大的变革在于不再需要标记数据进行训练，这为它带来了许多新的选择。展望未来，我们将看到许多基于开源的创新。红帽希望能够更好的定位自己，以便将这些创新应用于企业中。目前，红帽已经将该技术引入红帽的产品（如Red&nbsp;Hat&nbsp;Insights），这将使我们能够以更高效的方式进行实验和数据训练。</p><p>&nbsp;</p><p>Chris：生成式AI是一项重要进步。过去几年，深度学习要求数据科学家具备深厚的专业知识来构建模型。如今，基于大型语言模型和基础模型的迁移学习为企业提供了更多机会。</p><p>&nbsp;</p><p>企业环境下，我们不能仅仅依赖类似<a href=\"https://www.infoq.cn/video/So2yItKrdYsDZpEG7DjS\">ChatGPT</a>\"或BART这样的模型进行提问和回答，虽然这类产品的回答形式完整，但不总是准确的。因此，我们专注于将这些技术集成到红帽的平台中。今天，我们谈到的第一个例子是Ansible&nbsp;Playbook，这是与IBM合作开发的，IBM在生成式AI和领域特定AI技术方面经验丰富。Ansible&nbsp;Playbook利用自然语言生成可执行的操作指南，我们还将这一技术扩展到产品组合中，尤其是OpenShift平台。未来，我们将进一步利用生成式AI技术来生成运算符，从而帮助运维人员和开发人员更高效地利用我们的产品组合。这只是生成式AI融入产品组合的众多方式之一，未来我们还将不断探索更多可能性。</p><p>&nbsp;</p><p>InfoQ：企业的首席信息官（CIO）在采纳新技术时往往会慎重考虑。您认为，在人工智能真正超越概念验证阶段之前，需要从系统角度做哪些准备工作或满足哪些条件？</p><p>&nbsp;</p><p>Matt：首先，AI领域的发展需要可靠的资金支持。因此，需要着重提高现有环境的效率和运行方式。同时，AI领域必须建立对核心模型的信任。然而，对于使用数十亿或数万亿参数进行训练的模型，了解其中所使用的数据以及其生成的建议或输出是非常困难的。所以，必须谨慎处理这些问题，就像在开源世界需要遵守软件许可和版权法一样。因此，训练模型和获取建议方面的归因和来源是至关重要的。IBM与Ansible的合作项目为此提供了一个很好的示例。最后，为了将AI应用于生产和关键任务领域，我们还需要强调治理的重要性。</p><p></p><p>InfoQ：Ansible&nbsp;Light&nbsp;Speed看起来像是一个GitHub，能够生成脚本用于运维自动化操作和部署的协助工具。为什么红帽选择在运维自动化领域应用生成式人工智能？</p><p>&nbsp;</p><p>Chris：Copilot工具主要专注于应用程序开发，它提供了对各种不同编程语言的支持，帮助开发人员快速进行原型设计或将功能集成到现有软件中。而Ansible则专注于企业级IT自动化。在构建playbook时，开发人员使用的是我们熟悉的Ansible&nbsp;YAML语言。虽然Ansible&nbsp;YAML是一种相对容易理解的基础设施自动化和开发语言，但在当今企业面临的挑战背景下，我们发现它们希望尽可能减少手动工作量，实现更多的自动化。而通过使用生成式人工智能模型，可以针对特定领域进行训练，基于在Ansible社区中被认为是成功且有用的playbook，产生高度准确的输出结果。这种生成式人工智能工具既可以帮助我们探索特定领域的需求，又能帮助企业IT客户实现更多自动化，提高企业效率。</p><p>&nbsp;</p><p>InfoQ：你认为IT自动化是否会成为通往企业采用人工智能的桥梁？</p><p>&nbsp;</p><p>Chris：当然，是的。自主系统是自动化和智能的结合，而自动化是基石和起点，没有自动化就无法实现自主系统。在自动化中，通常涉及人类的参与，可以选择何时应用自动化。然而，我认为未来的发展非常依赖于对系统产生的所有数据的理解，无论是日志文件、度量指标还是系统的遥测信息。我们可以利用这些数据来训练模型，帮助我们了解系统的当前状态，并通过自动化确保当前状态与期望状态保持一致。在企业领域，有时将应用人工智能来帮助操作系统称为\"AI运维\"。如果考虑我们在OpenShift上所做的工作，我们提供了一个与Kubernetes平台连接的工具，称之为\"operators\"，或者利用Operator&nbsp;SDK来自动化操作OpenShift本身以及运行在OpenShift上的应用程序。</p><p>&nbsp;</p><p>InfoQ：红帽&nbsp;OpenShift&nbsp;AI&nbsp;平台如何扩展或加速红帽在人工智能、机器学习和数据科学领域的现有工作？</p><p>&nbsp;</p><p>Chris：OpenShift作为一个容器平台，在其最初阶段完全专注于应用程序。红帽将应用程序视为业务逻辑，帮助客户运行业务。机器学习的第一阶段开始涉足容器领域，通过在容器中运行一些训练工具和模型开发。最终，甚至在容器中运行一些已训练好的模型。所以，将应用程序开发和模型开发的世界融合到一个共同的平台上是一个机会。这里的一个重要的问题是：是否可以拥有一个单一的平台，实现企业更多的共性。OpenShift&nbsp;AI提供了这样一个绝佳的机会，将AI工作负载和AI开发模型带到与应用程序开发相同的平台上。红帽的OpenShift&nbsp;AI系列功能包括整个ML&nbsp;Ops过程，从数据的收集和特征工程，到模型的开发和参数调优，以确保模型能够提供准确的预测结果，并将其推送到生产环境中，作为构建智能应用程序的关键组成部分。</p><p>&nbsp;</p><p>InfoQ：你认为行业和企业应该关注的最紧迫或最明确的IT相关趋势是什么？为什么？</p><p>&nbsp;</p><p>Matt：当谈到生成式人工智能、基础模型或Transformer时，它代表了一种迭代的进步，而且这种进步的影响非常显著。Chris提到的能够降低实验成本、增加运行实验并取得更多成功的可能性，具有强大的作用。这是一个值得公司关注的趋势，他们需要思考如何在内部应用这些技术。当然，也要考虑到数据理解和治理等方面的各种限制条件，但这并不妨碍我们专注于提高效率以便能够更好地应用这些趋势。</p><p>&nbsp;</p><p>Ashesh：在经济压力下，人们想要保持现状、继续做自己正在做的事情是很自然的反应。在这样的时刻，我们需要思考：我该如何提高效率，以便能够释放更多时间、精力、资源和技能，以实现未来3年、5年甚至10年的创新和发展。这是至关重要的。而现在可能是一个绝佳的时机，因为我们有机会接触到众多工具和创新，我们需要思考如何利用它们。</p><p>&nbsp;</p><p>Chris：在今天的红帽峰会上，我们将内容划分为两个关键领域：如何提高效率以及如何借助这种效率来推动业务增长。今天，在众多对话中，一个共同的问题备受关注，那就是技能缺口。在这个技能缺口中，我们看到了技术解决方案的潜力，无论是通过人工智能弥补技能缺口，还是通过在企业中建立一致性，利用已有的技能来提高业务效果。对于企业来说，提高效率并借助技术推动业务增长是当务之急。在我看来，关键的趋势是利用人工智能来发挥人类的技能，实现机器辅助人类智能，从而为企业实现惊人的效率，促进业务增长。</p><p>&nbsp;</p><p></p><h2>5G与边缘计算的发展将带来哪些变化？</h2><p></p><p>&nbsp;</p><p>InfoQ：红帽和通用汽车一直在合作开发车载操作系统。您是否能分享一些红帽OpenShift和RHEL的开发方面的进展？未来在汽车中运行容器的下一步计划是什么？</p><p>&nbsp;</p><p>Chris：红帽在边缘计算领域的工作一直集中在电信领域的无线接入网络上。随着红帽将边缘应用扩展到非网络焦点的用例，车辆成为了一个很好的例子，它既与网络连接，又是一个非常复杂的设备，有人形容它为移动的数据中心。红帽与通用汽车的合作重点是将红帽的旗舰企业Linux产品引入车辆中，这需要进行一些技术性的工作，以确保与正确的硬件匹配。在这种硬件架构下，许多车辆都采用基于ARM架构的处理器，并且形状适应车辆的尺寸和空间限制。</p><p>&nbsp;</p><p>另一个关键领域是，在考虑到RHEL在车辆中的应用时，它可以为娱乐系统、广告系统、辅助驾驶和自动驾驶系统提供底层平台。这些系统对功能安全有不同级别的要求。将功能安全引入传统的Linux发行版（如RHEL），实际上是一项非常重要的工作。从工程角度来看，红帽正在大力推进能够提供功能安全性的技术，而这对于任何车载解决方案来说都是一个基本要求。</p><p>&nbsp;</p><p>至于如何在车辆中运行容器或原生支持容器化技术，红帽在车辆操作系统（ROW）中直接采用了Podman，还在OpenShift中做出了两个重要的改进。首先，我们从电信领域的无线接入网络用例开始，将OpenShift精简为可以在单个节点、单个服务器上运行的版本，我们称之为单节点OpenShift。这些服务器通常具备标准的规模，更多的核心和内存。同时，红帽还推出了MicroShift，它在OpenShift的基础上进一步减小了占用空间，可以在更小的设备上运行，可以将其看作是一种边缘设备。</p><p>&nbsp;</p><p>Ashesh：在汽车行业中，存在着一个庞大的生态系统，包括众多供应商为原始设备制造商提供产品。因此，红帽与这个庞大的生态系统合作，确保我们的产品，无论是合规的操作系统、针对边缘优化的Linux，还是边缘优化的OpenShift和MicroShift，能够与整个汽车生态系统无缝结合。</p><p>&nbsp;</p><p>InfoQ：随着5G的普及，预计超级云和边缘计算尤其是通过物联网设备的应用将得到大规模发展。红帽对这一变化有何策略和计划呢？</p><p>&nbsp;</p><p>Matt：红帽将5G的发展置于最高优先级，尤其是在无线接入网络方面的影响。我们已经看到了RHEL在嵌入式设备上的应用和OpenShift能够在单个节点上高效运行的进展。这些工作是基于电信拓扑结构的需求，并且红帽与强大的合作伙伴和设备供应商紧密合作，构建了一系列核心网络的基础设施。</p><p>&nbsp;</p><p>Chris：5G的出现对网络领域是一次重大变革。5G通过提供更高的带宽、更低的延迟和更多的连接密度，将扩展到企业应用场景。红帽在与爱立信和诺基亚等全球领先的网络应用提供商建立的生态系统上进行了大量的工程和产品投资。这对于红帽及其合作伙伴生态系统来说是一个重要机遇。预计未来5G的收入增长将主要来自企业应用，而不是消费者市场。企业应用需要专注于满足企业需求的应用程序，而红帽拥有一个庞大的合作伙伴生态系统，可以提供专为企业设计的应用。通过多接入边缘计算和我们的容器平台OpenShift，红帽能够运行网络应用程序和面向企业的应用程序，甚至在体育场馆等场景中为消费者提供创新的应用体验。这有助于运营商获得对建设5G网络所需的巨额投资的回报。</p><p>&nbsp;</p><p></p><h2>红帽在产品投入层面是否有变化？</h2><p></p><p>&nbsp;</p><p>InfoQ：本届红帽全球峰会发布了许多令人振奋的产品。红帽会从全新产品线中获得更多利益，还是通过扩展现有产品来获得更多的利益？</p><p>&nbsp;</p><p>Matt：我更偏向于创新发展而不仅仅局限于产品本身。正如我之前提到的，关键在于将潜力与实际应用结合起来。对红帽而言，最重要的是考虑如何让企业更容易接受。在红帽公司，我们的策略主要围绕几大平台展开。相比于推出20个可能更为专业或特定领域的新平台，我们更注重将新特性与已有平台相结合。在管理策略方面，我们的重心放在Ansible。红帽公司的重点始终在其核心产品RHEL、OpenShift和Ansible。</p><p>&nbsp;</p><p>Ashesh：我认为关键是要理解，红帽正在采取很多措施来使技术的使用和采纳更加便捷。以RHEL为例，比如通过Web界面更方便地管理RHEL，而不需要使用单独的工具；或者通过镜像构建服务更轻松地构建和管理镜像。红帽提供了越来越多的服务，如软件供应链、先进的集群区域服务等，以便更容易开始采用产品。因此，红帽的目标不仅是增加新的功能，还包括如何减少阻力，使采纳变得更加容易。</p><p>&nbsp;</p><p>InfoQ：与红帽&nbsp;OpenShift&nbsp;相比，其他解决方案似乎受到的关注较少。那么红帽产品的资源分配状况如何呢？</p><p>&nbsp;</p><p>Ashesh：我们看到了许多与&nbsp;Red&nbsp;Hat&nbsp;OpenShift&nbsp;相关的案例研究，这实际上是对于正在发生的巨大转变的强有力证明。全球各个行业的企业，无论是银行、金融服务公司还是公共部门和零售业，都在进行着深刻的转型。容器技术的应用广泛，在混合云环境中，OpenShift&nbsp;是首选解决方案。这也说明了企业目前正处于转型的关键阶段。同时，我们也看到了其他领域的浓厚兴趣，如&nbsp;Ansible&nbsp;和自动化。红帽与西班牙的一家大型保险公司合作是一个很好的例子，他们分享了在使用&nbsp;Ansible&nbsp;和相关工具方面的经验。红帽在过去的&nbsp;Ansible&nbsp;Fest&nbsp;上也获得了更多类似的客户支持证言。</p><p>&nbsp;</p><p>InfoQ：红帽将更多的注意力放在开发人员身上。红帽如何平衡&nbsp;IT&nbsp;系统运维人员和开发人员的需求呢？</p><p>&nbsp;</p><p>Matt：红帽为开发人员所做的Red&nbsp;Hat&nbsp;Developer&nbsp;Hub&nbsp;和&nbsp;Red&nbsp;Hat&nbsp;Service&nbsp;Interconnect，着重关注如何引导开发人员在环境选择上做出良好的决策，以及如何更轻松地构建跨多个集群的混合应用程序。红帽也试图在运维和安全性之间保持平衡。在Ansible中，Ansible是我们运维技能集的一个非常强大的默认选择，Ansible的速度和灵活性能帮助平衡开发速度，因为我们同时存在于这两个世界中。</p><p>&nbsp;</p><p>Ashesh：我们看到越来越多的容器和Kubernetes的采用速度在不断增加，已经达到了每个人都越来越习惯于运行、部署和扩展应用程序的程度。红帽越来越关注的是整体应用平台体验，但主要是面向开发人员。红帽可以帮助开发人员充分利用项目安全、CI/CD（如Argocd或Tekton）等，帮助他们在云原生计算基金会的项目中得到支持，使他们不仅仅是在线操作，还可以通过图形用户界面与许多他们自己的开发工具集成。这样就更好地将DevOps的世界连接在一起。</p><p>&nbsp;</p><p>InfoQ：红帽是如何通过其软件供应链可信解决方案来应对安全性这个挑战的？此外，它还为企业&nbsp;IT&nbsp;提供了哪些内部工具？</p><p>&nbsp;</p><p>Chris：近年来，对软件安全性尤其是开源软件的关注和认识不断增强。在企业中，开源软件扮演着许多业务的重要角色。作为一家企业，红帽从一开始就深度参与开源社区的工作并将所有的开发工作汇集到一个发行版中，经过验证、测试和加固，其中包括了针对安全性的配置。然后为客户提供可信赖的解决方案。</p><p>&nbsp;</p><p>红帽在可信赖的软件供应链解决方案中所做的是添加一些功能，这些功能实际上是我们在开源项目中发起的。红帽致力于构建更好的溯源、签名和验证机制，确保软件源自开源社区，并通过整个供应链进行验证。为此，红帽利用了一项名为sigstore的技术，它能对内容进行数字签名，并在流程的各个阶段进行验证。这是我们整体解决方案中的一个重要新方面。</p><p>&nbsp;</p><p>然而，在构建可信赖的软件供应链时，构建容器镜像所使用的内容也非常重要。我们在红帽企业版&nbsp;Linux&nbsp;中提供的产品已经为此做出了很多贡献。我们将最近在开源社区中创建的工具与我们目前构建和交付软件的方式相结合，并以一种方式对外提供，让客户能够使用工具链来管理将软件引入企业并推入生产环境的风险。在这一过程中，元数据对于了解风险概况非常重要。</p><p>&nbsp;</p><p></p><h2>未来规划</h2><p></p><p>&nbsp;</p><p>InfoQ：自从你成为CEO以来，过去的一年对你来说是怎样的？你有什么看法想要分享吗？你对APAC地区有什么看法？</p><p>&nbsp;</p><p>Matt：如今的环境既充满了积极的因素，也存在着消极的干扰。消极的一面包括通货膨胀、疫情后的不确定性以及其他一些我们无法直接控制的因素。而积极的一面是，开源社区中正在发生许多令人兴奋的发展。我认为将大量精力投入到专注于我们的核心价值主张上是至关重要的，这样可以让人们感受到我们的使命，并受到鼓舞。</p><p>有一件令我兴奋的事情，那就是开源模式在全球范围内的应用速度比以往任何时候都要快。开源不受国家或地区的限制，而在创新和技术应用方面，它是一种非常出色的模式。亚太地区是一个相当多元化且具有增长潜力的地区，尤其在电信行业和技术采用方面有着巨大的机会。我相信亚太地区将在开源领域发挥重要作用，无论是在传统领域还是在新兴领域。</p><p>&nbsp;</p><p>InfoQ：在面对不确定的经济环境并更加谨慎时，红帽的客户如何重新评估他们的技术投资？在这方面，你从客户那里听到了什么样的反馈？</p><p>&nbsp;</p><p>Matt：在这方面，我们听到了一些不同的趋势。过去，混合部署对于客户来说是为了追求增长而发生的情况，他们发现自己处于多个位置、多个云端和边缘环境中。然而，在当前的环境下，客户们变得更加谨慎和审慎，对于未来的建设方式进行了更加详细的规划。在某些市场上，不惜一切代价追求增长的欲望已经大大降低，现在更加注重可持续增长。这种趋势也直接影响了他们在架构选择方面的决策，他们会思考在哪些方面应用创新并做出明智的抉择。</p><p>&nbsp;</p><p>Ashesh：我们发现客户已经进行了某种超大规模的选择性投资，这在全球范围内都是如此。他们选择与超大规模提供商合作，通常不只是一个，但这种趋势在世界各地都很明显。此外，红帽订阅、传统软件产品以及托管服务的提供使客户能够更好地进行决策，并在支出方面更加高效。红帽的产品在AWS、Azure、Google和其他市场上的可用性，使客户能够根据自己的需求选择在本地或公共云中自行管理某些应用程序，或者将管理工作交给我们作为云服务来完成。这使得客户能够在技能和人员招聘方面取得平衡，并以更加有效的方式进行管理。因此，与红帽和超大规模提供商合作，给客户提供这种选择是非常有效的，并产生了显著的效果。</p><p>&nbsp;</p><p>InfoQ：请分享关于红帽在未来12个月的发展方向的任何最终想法。</p><p></p><p>Matt：无论环境如何，创新应用都变得非常关键。正如Ashesh所说，无论客户是自然而然地进行创新，还是有意识地摆脱经济挑战，我们都看到了很多围绕开源的创新，而红帽乐意成为这种桥梁。因此，对于未来的12个月，红帽将专注于实现这种技术的潜力，无论是通过与红帽合作在特定领域运用人工智能来提升客户在Ansible方面的能力，还是在开发者和DevOps方面取得更好的表现，又或者是在实现一些人工智能创新方面取得成功。红帽将在不同行业、不同应用场景中充分应用这些技术，与客户一起度过这段时间。所以，现在是身处开源领域的好时机。</p><p>&nbsp;</p><p>InfoQ：您任职CEO已经有9个月了，您的愿景是什么，将如何推动红帽迈向更高层次？</p><p>&nbsp;</p><p>Matt：红帽的发展模式基于开源，正如红帽的“Why&nbsp;statement”所言，我们深信开放释放世界潜能。这并不仅仅代表开源代码释放世界潜能，而是强调如何与全球社区互动和利用创造力，并将其应用于实践。展望红帽的未来，我们的愿景即是我们的存在目标。在人工智能领域，我们看到了一个巨大的机遇，可以超越代码和IT的影响，涉足其他领域，并帮助企业充分利用创新。红帽在为企业提供精心策划的开源代码方面有着丰富的经验，这是我们几十年来一直致力于的领域。新的机会将推动红帽进入数据和其他领域，而开放的模式将在其中发挥巨大作用。同时，红帽将致力于将这些创新应用于企业，这也将成为红帽未来十年的挑战。</p>",
    "publish_time": "2023-06-02 17:11:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "知乎运营分析平台 — 舰桥平台如何通过 Apache Doris 实现查询速度 10+ 倍提升？",
    "url": "https://www.infoq.cn/article/YXq3zrAT5vx2zAcP3o1j",
    "summary": "<p></p><blockquote>知乎为实现精细化运营，提高运营效率，依赖 Apache Doris 构建了内部统一的运营分析平台——舰桥平台，主要应用于事实接入层、事实建模层和事实运算层等架构核心层的建设，并持续对导入、查询等方面进行性能调优，最终实现上千亿行数据分钟级导入，千亿级数据秒级查询响应。该平台当前已经广泛应用于知乎不同事业部的社区、商广、教育&amp;会员、技术中台等领域，得到各部门广泛认可。</blockquote><p></p><p></p><p>作者｜知乎舰桥平台 Leader 侯容</p><p></p><p>在长期的业务运营中，知乎团队发现在内容运营、创作者运营、热点运营等许多场景中，运营团队需要依赖 SQL 或自行编写 SQL 代码来对用户信息、业务数据进行查询分析。这往往需要投入大量的精力，造成人力投入大、工作效率低等问题，无法实现精细化运营，无法高效完成业务目标。</p><p></p><p>为了解决上述问题，知乎舰桥平台应运而生。舰桥平台是知乎内部统一的运营分析平台（即一站式内容&amp;用户管理平台），主要应用于知乎的六大核心运营场景，包括找人、找内容、盯人、盯内容、找机会、查问题场景。该平台当前已经广泛应用于知乎不同事业部的社区、商广、教育&amp;会员、技术中台等领域。</p><p></p><p>知乎舰桥平台的基础能力包括筛选、分析、打包和监控，这些能力都不同程度地依赖 <a href=\"https://github.com/apache/doris\">Apache Doris </a>\"提供的计算、存储和分析能力。在本文中，我们将主要介绍 Doris 在舰桥平台中的应用，以及在 Doris 的优化实践。</p><p></p><h2>业务架构</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/7a/7a8aab0dc385a4eeac9a7db0a8a66e83.png\" /></p><p></p><p>如业务<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1537\">架构</a>\"图所示，知乎舰桥是一个数据密集型的一个应用，架构共由五层组成，这里对较为重要的层级进行介绍：</p><p></p><p>数据层和事实层： <a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1536\">数据</a>\"层主要由内容数据、用户数据和流量数据组成，考虑到原始数据不具备可展示性和可描述性，因此我们将原始数据抽象出内容事实、用户事实和流量事实，并存储在事实层以供上层应用。基础能力层： 在基础能力层我们搭建筛选、打包、分析和监控四大基础能力。一般来说先按照业务要求筛选出目标用户数据，接着对这些用户进行下载并打包，打包后形成内容池、人群包或领域（可别用于投放、推荐、Push、推送等场景）；同时我们提供了基于筛选、打包、全栈等的多维度面向分析的能力，具体体现为榜单、分布、趋势、明细等；除此之外还提供了监控的能力，包括实时/定时监控、监控模板和监控协作。业务工具层： 我们将基础能力层的四大基础能力搭建成不同的业务工具，分别为榜单&amp;列表、业务分析、异动发现和问题诊断，用于支持业务侧的不同行动。</p><p></p><p>基于业务<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1536\">架构</a>\"，我们思考虑应该通过一个怎样的技术架构可以低成本、高效率的实现我们的需求，因此我们先对技术架构进行了模块职责的划分，并希望各模块可具备以下能力：</p><p></p><p>人机（UI ）界面：以用户体验为中心，构建高效易用、简单易懂的 UI 界面，帮助运营同学快速理解并上手。协作能力：针对多场景、多部门的业务需求，构建统一完备的协作平台，最大程度地降低业务交互成本。核心业务能力：需要将数据进行业务抽象，确保所有需求都在已知的概念中被定义，方便使用、降低使用成本。事实运算：需要支持大规模数据的高效低延迟复杂运算，以满足各业务线的运营需求。事实建模：隔绝接入层与业务层，提高迭代效率，以便更快地满足业务需求。事实接入层：支持海量数据导入，并能够实现大量数据快速导入，同时支持敏捷接入，低成本扩展，以适应业务的快速发展和变化。</p><p></p><h2>技术架构</h2><p></p><p>为了建设符合要求和目标的<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1537\">技术架构</a>\"，我们对多个大数据组件进行了调研选型，在调研中发现，Apache Doris 各方面能力都比较优秀，可以提供多种数据导入方案、拥有便捷易用的建表能力、更灵活的的物化视图以及对向量化的全面支持，基于这些优异性能，最终我们决定引入<a href=\"https://www.infoq.cn/article/WIqFubWLS6HuExJPTuT7\"> Apache Doris</a>\" 建设舰桥平台技术架构，并被主要应用在舰桥平台的三个核心层，即事实接入层、事实建模层和事实运算层。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f2/f2aba98bf01893b9833b264d54e23a9d.jpeg\" /></p><p></p><p>事实接入层： 事实接入层采用了 Segment 文件预处理技术和大规模导入技术，极大程度地加速数据从 HDFS 导入到 Doris 的速度，在此过程中，广泛应用了 Spark 技术，此外我们还通过 Flink 直接将另一部分数据流式写入，数据流式写入有两个步骤：一部分通过 Flink Connector 直接写入的，另一部分先通过 Flink 完成 ETL 处理，再通过 Routine Load 完成写入。该层借助于 Doris 丰富的 Load 协议，实现了多种数据的规模化快速导入。事实建模层： 事实建模层我们对业务进行了梳理和拆分，搭建了合适的业务模型，包括用户模型、内容模型、流量模型等等，同时还包括业务场景化的模型，例如主题模型和分层模型等等。因为 Doris 具有数据结构管理简单的特性，可以帮助我们快速试错和优化数据模型，极大程度的提升了数据模型迭代的效率。事实运算层： 事实运算层我们采用了数据和机器预绑定的技术，并应用了 Doris 的向量化技术和物化视图。此外，我们还进行了大量的调优工作，例如，查询计划的调优、<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1537\">数据结构</a>\"优化、算子合并技术等，从而实现性能的优化。</p><p></p><p>在基于 Doris 的事实接入、事实建模和事实运算层的支持下，我们高效地搭建了核心业务能力、人机界面和协作能力，最大程度地满足业务需求，充分达成了业务架构提出的目标。因本文以介绍 Doris 的应用为主，其他层的将不做具体描述。</p><p></p><h2>优化实践</h2><p></p><p></p><h3>大量数据快速查询</h3><p></p><p>在人群圈选和筛选场景中，我们需要处理大规模的数据，包括 240 万个标签、千亿级别的对象和标签量的关联数据，同时，我们需要在极短时间内完成查询操作，通常要求在 1s 内返回查询结果，10s 内完成数据打包，时效要求非常高。那么怎样可以实现大量数据的快速查询呢？</p><p></p><p>步骤 1：分而治之</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/98/98930263e0c9bca0ffd9cae3ce7b6ca0.png\" /></p><p></p><p></p><blockquote>分而治之的核心思想是将整体数据的与或非，转化为分组与或非后的合集。如果将它变成了一种倒排的 Bitmap，就能变成绘图的交并差。</blockquote><p></p><p></p><p>我们发现整体数据的交并差等价于先对某一个分组数据交并差、再进行合并操作。在这个基础上如果先将整个 Bitmap 取出完成交并差，实际上可以理解为只有一个线程在运算（实际不是），基于该发现我们可以先将每一个数据进行交并差，这样就可以将其拆分成与分组相同数量的线程或队列进行计算，计算完再由一个队列来进行数据合并。</p><p></p><p>优化前一般是在一个存储区中存储所有的特征，每个特征分布在不同的机器上，而在上述思路的驱动下，我们修改了分组策略，先将人群特征分为许多小的分组，并将特征随机分布在不同机器上进行计算，通过该操作最终实现了速度的明显提升。</p><p></p><p>以用户筛选为例：</p><p></p><p>通过将用户 id 分组，如每 100 万 id 为一组，设置一个 group_id。将该分组下不同用户特征、标签统一指向分组 group_id。先在每一个分组中计算特征、标签计算的与或非（即并差）。当分组数据完成计算后，最后进行数据汇总。同时开启多线程模式，提升每组的计算效率</p><p></p><p>然而，在这个过程中，我们又遇到了第二个问题，即特征计算带来了非常大的网络开销。这是因为各个特征随机分布在不同的机器上，这就导致在一个机器上完成了一部分特征运算，然后执行 Shuffle 进行数据交换，再进行第二次运算，再交换进行第三次运算，以此类推，假设条件非常多，网络开销就会非常大。</p><p></p><p>步骤2：数据机器预绑定</p><p></p><p>我们探索并发现 <a href=\"https://www.infoq.cn/article/8SU754VFuKpw8gwjF24v\">Doris</a>\" 的 Colocate 原理可以有效解决该问题，利用 Colocate 可以减少数据 Shuffle 的次数，从而减少运算的次数。因此我们我们尝试使用对数据分布和机器进行预绑定，数据机器预绑定应用了 Doris 底层的 Colocate 原理。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0b/0bac75e00486f05ba551d18f877b1421.png\" /></p><p></p><p>我们将某一个分组 Key 和机器进行绑定，当数据与该分组 Key 相对应，该数据将存在某一台机器上面，从而完成数据和机器的预绑定。通过该方式可以避免在特征计算中出现频繁网络交互和数据混洗操作，从而大幅降低网络开销。</p><p></p><p>如下图所示为优化前的流程，数据进行不停的交换，查询计划非常高，网络开销非常大。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/83/83821ec003b67aea471875396dbbeeff.png\" /></p><p></p><p>下图为利用 Doris 的 Colocate 原理进行优化的结果，可以发现查询计划相比较之前少了很多，简单数据处理后即可完成，同时速度也非常快，主要归功于查询计划的降低占用了比较少的网络开销。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f6/f69e6e84888b4b316135bbfe32138461.png\" /></p><p></p><p>步骤 3：算子合并</p><p></p><p>在解决网络开销问题之后，我们开始思考如何加速执行的效率，因此我们引出了算子合并（非官方命名）这一概念。其原理是使用更复杂的函数代替原先简单的函数组合，在这个过程中，我们与 <a href=\"https://selectdb.com/\">SelectDB 团队</a>\"和 <a href=\"http://doris.apache.org/\">Apache Doris 社区</a>\"与进行了多次沟通及配合，将日常使用的函数组合进行开发和落地，将合并组合好的函数进行上线使用。以下为拼接函数组成介绍：</p><p></p><p>bitmap_and_count == bitmap_count(bitmap_and(bitmap1, bitmap2))</p><p></p><p>bitmap_and_not_count == bitmap_count(bitmap_not(bitmap1, bitmap_and(bitmap1, bitmap2))</p><p></p><p>orthogonal_bitmap_union_count==bitmap_and(bitmap1,bitmap_and(bitmap2,bitmap3)</p><p></p><p>比如我们需要进行一个数据查询，用简单的函数和复杂的函数处理流程如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8b/8ba93c3e140c6dcb0579a0c1896584e0.png\" /></p><p></p><p>简单函数：先查出数据，再执行 bitmap_and，中间存储，执行 bitmap_not，再进行中间存储，最后执行 bitmap_count，输出结果。可以看出处理流程很长、速度很慢。复杂函数：如果使用合并后的函数 bitmap_and_not_count ，当我们直接将数据输入到这个函数里，就可以输出结果。输出速度相比之前大幅提升，从而提升了查询效率。</p><p></p><h3>大量数据快速导入</h3><p></p><p>在离线导入场景中，由 Hive 完成大量数据计算，这些数据文件写入到 HDFS 中，我们将定期通过 Broker Load 将 HDFS 中的的数据拉取到 Doris 里。在这个过程我们发现，在限定的集群资源下，当遇到大数据量导入操作，Broker Load 则会出现超时。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/22/225d84d2d1510c91384a1a03a59d9ee7.png\" /></p><p></p><p>经排查发现 Doris 从 HDFS 拿到 Parquet 之后，需要先进行解压缩，再进行分桶数据传输，最后经过排序、聚合、再压缩等一系列操作生成 Segment 文件，而这些过程都会在 Doris BE 上进行，同时我们还会在此基础上进行 Bitmap 操作，从而导致 CPU 压力增大。</p><p></p><p>经过探索，我们发现 Spark Load 可以很好解决该问题，Spark Load 可以将导入拆分为计算和存储两部分，将分桶、排序、聚合、压缩等计算逻辑放到 Spark 集群，产出结果写到 HDFS，Doris 再直接从 HDFS 中拉取结果文件写到本地盘。</p><p></p><p>Broker Load ：BE 节点负责计算，算力取决 BE 节点个数及配置。Spark Load：Spark 集群负责计算，算力取决于集群配置，且弹性强。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a9/a9248a51b260c592543fb5e8a220ef66.png\" /></p><p></p><p>我们将 Segment 文件预处理移至 Spark 后，速度有了明显的提升。当前 1.2 TB、1100 亿+ 行数据，导入时间从 9 小时缩短为 55 分钟，速度大幅提升，其中 Doris 的使用时间缩短到了 20 分钟，另外 35 分钟在 Spark 集群上，有效降低了Doris 集群负载。</p><p></p><p>在探索海量数据快速导入的过程中，我们遇到了一些问题，并成功地解决了它们。在这个过程中，我们积累了许多宝贵的经验和解决方案，现在将这些经验和方案分享给大家，希望能为大家提供帮助。</p><p></p><p>HDFS 权限认证问题：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bd/bd320757780dc9f831466baca5136e29.png\" /></p><p></p><p>知乎当前的 HDFS 是使用 Symbol 方式认证的，这与很多其他公司不同。我们发现，Spark Load 命令处理完后，将转发到 Spark Launcher，再由 Spark Launcher 执行 Spark Submit 命令。在这个过程中，不会传递环境变量，因此我们无法将用户名和密码传递给 Spark Submit 再执行，并且也无法将它们配置到环境变量中。而在实际场景中，我们需要使用不同的用户名和密码来读取不同的数据进行导入，因此，我们增加了动态设置和环境变量等功能来解决这个问题，目前相关 PR 合并到了社区中。相关 PR：<a href=\"https://github.com/apache/doris/pull/12276\">https://github.com/apache/doris/pull/12276</a>\"</p><p></p><p>Doris 拉取 Spark 产物速度慢</p><p></p><p>在 Spark 完成计算之后，我们发现 Doris 拉取产物的速度比较慢的问题，经过进一步跟踪发现当在处理小规模数据时，能够在一分钟内处理完一个文件，但当数据规模变大时，则需要花费五分钟才能处理一个文件。那么是否可以通过调高任务数来提高速度呢？于是我们根据线上实际的超时情况和导入速度要求，最终决定将下方参数从 3 增加到 9，结果发现速度立即得到了明显的提升。</p><p></p><p>push_worker_count_high_priority：改为 9。push_worker_count_normal_priority ：改成 9。</p><p></p><p>参数调整后不仅大幅提升了拉取速度，单个 BE 写入速度达到 120MB/s， IO 和 CPU 资源也得到了更充分的利用。</p><p></p><p>通过这次调参我们发现，大家可以根据实际需求来调整以下三个参数，以解决拉取产物速度较慢的问题：</p><p></p><p>push_write_mbytes_per_sec：BE 磁盘写入限速。push_worker_count_high_priority:  同时执行的 Push 任务个数。push_worker_count_normal_priority: 同时执行的 Push 任务个数。</p><p></p><p>隐式转换改为显示转换</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/68/68fb39ec7fd1da3e84b92b2bef98875b.png\" /></p><p></p><p>在使用 Doris 向量化版本的过程中，由于我们有很多基于 Bitmap 表的计算，在使用隐式转换时会出现无法导入 Bitmap 表的问题。为了解决这个问题，我们禁止隐式转换并开启了显式转换，并将相关的 PR 合并到了社区中。相关 PR：<a href=\"https://github.com/apache/doris/pull/12394/files\">https://github.com/apache/doris/pull/12394/files</a>\"</p><p></p><p>Spark 聚合速度 慢</p><p></p><p>由于数据存在倾斜，导致在 Spark 数据聚合速度比较慢，基于此，我们重新按照离线计算的一个 Key 来进行分组，新增一个 Bucket 列，以解决数据倾斜导致计算速度慢的问题。</p><p></p><p>并发 数量限制</p><p></p><p>我们在 Spark Load 的 Spark DPP 代码中发现：在 stage 2 的过程中，任务的并行上限为 200，这导致在面对数据量非常大的任务时，写入速度非常慢。为解决这个问题，我们增加了自适应的并发数，并将相关的 PR 合并到了社区中。相关 PR：<a href=\"https://github.com/apache/doris/pull/12186\">https://github.com/apache/doris/pull/12186</a>\"</p><p></p><h2>性能提升</h2><p></p><p>Apach Doris 1.1 版本实现了计算层和存储层的全面向量化、正式将向量化执行引擎作为稳定功能进行全面启用，性能较之前版本有 3-5 倍的巨大提升；并在 1.2 版本所有模块都实现了向量化，包括数据导入、Schema Change、Compaction、数据导出、UDF 等，查询性能较非向量化版本大幅提升。因此在 1.1 向量化版本推出后，我们针对某些重要场景进行向量化迁移，并主要逐步在所有场景中应用。</p><p></p><p>当我们从 0.15.3 迁移到 1.1 版本之后，给业务带来非常明显的收益，大多数场景均能达到 5 倍以上的响应速度提升，个别场景响应速度甚至可以达到非向量化版本的 10+ 倍，我们分别对以下 7 个场景的查询耗时进行了对比。</p><p></p><p>场景 1：简单（数百）圈人条件，百万级别 Bitmap 人群打包场景 2：复杂（数千）圈人条件，上亿级别 Bitmap 人群打包场景 3：多维度（6 种）筛选、单表查询、单日期指标宽表、数据聚合 SUM，单日数据量 1.8亿+场景 4：（6 种）筛选、单表查询、多日期指标宽表（周期：15天）、数据聚合 SUM，单日数据量 1.8亿+场景 5：单表查询、COUNT 计数，单日数据量为1.8亿+场景 6：多表查询，A、B 各表数据量为 1.8 亿+、1507 万+。A 表涉及每天数据 SUM 聚合、COUNT聚合，B表涉及 Bitmap 聚合，A、B 先聚合再与 C 表 Join，子表再依次Join，Join 次数共为 6 次。场景 7：5亿+ 数据明细分析及单表查询</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1d/1d04a3b65ee3c1d3777f6b66d2f42ca0.png\" /></p><p></p><h2>未来展望</h2><p></p><p>在技术上我们将在查询和写入方面进行优化，在查询方面将实现图引擎，现阶段的业务场景主要通过 Doris OLAP 和 Doris On ES 实现了多维分析和全文检索，未来随着业务发展，关系场景将越来越多，基于此我们将尝试通过 Doris 扩充图引擎，最终在多维分析和全文检索的基础上实现与图引擎的结合。根据近期社区动态得知， Doris 对图数据库 Nebula Graph 支持的 PR 已经就绪，将在未来版本中正式发布（相关 PR：<a href=\"https://github.com/apache/doris/pull/19209%EF%BC%89\">https://github.com/apache/doris/pull/19209）</a>\" 。 在写入方面我们将实现Spark Load 底层解耦，Spark Load 底层实现时，目前 Doris 和 Spark 是耦合的，导致在使用时有诸多不便、无法大规模使用。未来我们计划将 Spark 和 Doris 解耦，不需要 Doris 来提交任务就可直接在 Spark 提交生成产物 Doris Segment 数据文件，完成后通知 Doris 下载 Segment。</p><p></p><p>在业务上， 我们计划与实验平台展开合作，将目标制定及完成的判断从人工把控转变为自动配置实验和验证。同时我们也将进行业务插件化能力建设：</p><p></p><p>插件化架构落地，联合业务提供相对完善的产销联动工具链。将原有通过人工维护的流程，以工具链的形式配置，充分发挥运营同学的核心竞争力，整体降低业务成本。</p><p></p><p><a href=\"https://github.com/apache/doris/releases/tag/2.0.0-alpha1\">Apache Doris 在 2.0 Alpha 版本</a>\"中已经实现了单节点数万 QPS 的高并发点查询能力、<a href=\"http://mp.weixin.qq.com/s?__biz=Mzg3Njc2NDAwOA==&amp;mid=2247519079&amp;idx=1&amp;sn=a232a72695ff93eea0ffe79635936dcb&amp;chksm=cf2f8560f8580c768bbde99ef8ca97d3a42ecc03b5d8d106b85f5474c90b6068781a79b3611e&amp;scene=21#wechat_redirect\">高性能的倒排索引</a>\"、基于对象存储的冷热数据分离、基于代价模型的全新查询优化器以及 Pipeline 执行引擎等，欢迎大家下载体验。为了让用户可以体验社区开发的最新特性，同时保证最新功能可以收获到更广范围的使用反馈，我们建立了 2.0 Alpha 版本的专项支持群，<a href=\"https://wenjuan.feishu.cn/m?t=sF2FZOL1KXKi-m73g\">请大家填写申请</a>\"，欢迎广大社区用户在使用最新版本过程中多多反馈使用意见，帮助 Apache Doris 持续改进。</p>",
    "publish_time": "2023-06-02 17:46:47",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "浪潮之巅，如何让大语言模型走向金融应用新纪元｜InfoQ 极客有约",
    "url": "https://www.infoq.cn/article/eJmFPe7oGOoQi4flItDe",
    "summary": "<p>AIGC时代曾经的 AI 落地难题，是否还有新的突破？金融领域优秀的大模型应该具备哪些特征？如何选择适合不同场景的大语言模型？本期《极客有约》特邀3位资深技术专家与你深入探讨AI在金融领域的应用前景，解决落地难题以及优秀的金融领域大模型的特征和选型。</p>\n<h1>访谈对象</h1>\n<p>王恒 众安保险/数据科学应用中心算法部负责人<br />\n卢亿雷 白海科技创始人兼 CEO，TGO 北京董事会成员<br />\n刘洪涛 度小满  NLP 专家研究员</p>\n<h1>直播亮点</h1>\n<p>AIGC 时代，曾经的 AI 落地难问题是否依旧存在？<br />\n金融领域优秀的大模型该具备怎样的特征？<br />\n不同场景，如何进行大语言模型选型？<br />\nAIGC 和自身技术路线融合应优先考虑哪些问题？</p>",
    "publish_time": "2023-06-02 18:30:12",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "红帽推出生成式AI服务 Ansible Lightspeed",
    "url": "https://www.infoq.cn/article/LpXhfIXrBZqRIfTaorme",
    "summary": "<p>开源解决方案供应商红帽日前宣布推出搭载 IBM Watson Code Assistant 的 Ansible Lightspeed。</p><p>&nbsp;</p><p>据悉，Ansible Lightspeed 是为实现 Ansible 自动化而推出的一项新的生成式人工智能服务。该服务旨在推动企业以一致的方式精准部署自动化技术，让新手用户更容易实现任务自动化，同时可以帮助经验丰富的自动化人员减轻创建低级别任务的负担。</p><p></p><p>在行业形势不断变化、且经济不确定的时代，企业面临着用更少的资源实现更多目标的挑战。企业需要多样化的人才来保持弹性，推动创新，并实现混合云和自动化投资的全部价值。然而，缺乏关键 IT 技能可能会威胁到这些想法的实现。</p><p></p><p>根据 IDC 的数据，“到 2025 年，90%的全球组织将面临 IT 技能危机，”这意味着“到 2026 年，如果企业不能有效地解决内部人才和数字技能差距的问题，会让他们失去 20%的收入增长机会。”但是，“由于技能缺乏，到 2025 年，投资数字采用平台和自动化学习技术的 CIO 将能够把生产力提高 40%，从而驱动他们以更快的速度学习专业知识。”</p><p></p><p>Ansible Lightspeed 代表 Wisdom 计划的下一个阶段，旨在使用户、贡献者、客户和红帽合作伙伴生态系统都容易使用。该服务使用自然语言处理技术，并与 Watson Code Assistant 集成（预计将于今年晚些时候正式推出），以访问 IBM 基础模型并快速构建自动化代码。Watson Code Assistant（技术预览阶段）为企业带来的价值在于：消除技能差距和提高效率，以加速自动化价值的实现。</p><p></p><p>Ansible Lightspeed 在设计时考虑到了开发人员和运维人员的需求，允许 Ansible 用户输入简单的英语提示，从而显著提高他们的生产力，同时，用户更容易将其领域的专业知识转化为用于创建或编辑 Ansible 操作手册的 YAML 代码。据悉，为帮助训练模型，用户也可以提供反馈意见。</p>",
    "publish_time": "2023-06-02 18:42:14",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]