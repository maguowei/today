[
  {
    "title": "分布式软件团队协作技巧：减少会议，异步优先",
    "url": "https://www.infoq.cn/article/RkUrtwmzlG3MuNuXskuK",
    "summary": "<p>本文要点：</p><p>在分布式团队中，以会议为中心的工作方式可能会破坏深度工作和流程、包容性、工作灵活性，长期来看还会妨碍知识共享。会议也不适合规模化。异步协作是这种以会议为中心的方法的有效替代方案。“异步优先”并不意味着“仅限异步”。也就是说，要充分认识异步沟通和同步沟通模式的优势，并根据需要做出选择。当然，大多数情况下默认采用异步协作方式。要采用异步优先的方法，就必须找到可行的异步协作替代方案，例如用现代化的任务看板代替状态更新会议，或者用可以自行安排观看节奏的视频代替入职培训。对当前团队使用分布式工作实践的成熟度做基线评估，帮助你确定异步协作可以在哪些方面带来改进。为了加速向“异步优先”转变，请务必记录工作流程，简化决策过程，创建团队手册，并进行会议审计。你是在分布式团队中工作吗？如果是，你就会知道，开会是一件非常耗时的事。虽然会议可能有其价值，但如果我们把它们作为默认的工作方式，就可能会在无意中导致团队日历的碎片化。安排被打乱可能会降低生产力，对于需要有时间专注于深度工作的知识工作者来说尤其如此。</p><p></p><p>在本文中，我们将讨论异步协作的好处及其实现方式。</p><p></p><p></p><h2>会议实在是太多</h2><p></p><p></p><p>“我们的会议太多了！”作为分布式团队的领导者或成员，你可能经常会听到这样的抱怨。如果你上次听到这个词是在开会的时候，那没什么可奇怪的。大流行增加了我们参加会议的次数，而许多团队一直是采用以会议为中心的协作方法。</p><p></p><p>设计讨论、状态更新、电话报告、日常站会、计划会议、开发启动、初步验收（desk check）、演示、审核和回顾，平均每个软件开发迭代都包含这样几次“同步”保障。而且，我们的会议还不止这些！</p><p></p><p>即时交谈、故障排除会议、头脑风暴、问题解决和决策——这些都成为分布式团队的会议。</p><p></p><p>2021 年至 2022 年期间，我对印度 1800 多名技术人员进行了非正式调查，希望借此了解他们的分布式工作模式。</p><p></p><p>除其他问题外，那次调查还要求受访者估计他们每周参加多少个小时的会议。此外，该调查还要求人们估计他们每天查看即时消息的次数。我们收到的回复令人震惊。</p><p></p><p>技术人员平均每周要花 14 个小时开会，相当于每年要花 80 天开会。你可能已经猜到，最有经验的技术人员会面临更大的会议负担。根据反馈，人们平均每天要被打断 18 次。罪魁祸首是什么？即时通讯——我们用来“快速响应”的工具。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/27/27f4f4035c19b28a74dddc8d45c001a0.jpg\" /></p><p></p><p>部分调查结果</p><p></p><p>本质上讲，软件开发是一个创造性的过程，无论你是在写代码、制作交互还是设计屏幕。领导软件团队也是一种创造性的活动。我们中的许多人会把时间花在构建技术路线图、阐明架构决策、原型设计、设计算法和分析代码上。正如 Paul Graham 在他 2009 年发表的文章中所指出的那样，软件开发是“创客”工作（即创造性工作），它需要“创客时间表”。“你不可能在一个小时内写好程序。这几乎不够工作准备的时间，”Graham 那天说。在创客时间表上，时间“至少要以半天为单位”，而会议和干扰可谓生产力的克星。</p><p></p><p>不出所料，我在调查中也遇到了这种看法。技术人员希望平均每周深度工作 20 个小时，但实际上只有 11 个小时。想象一下，如果我们能以某种方式找回那些失去的深度工作时间，每个团队能取得多大的成就。</p><p></p><p>现在我们来看下“异步优先（async-first）”协作。这个概念很简单，就是优先考虑异步协作而不是同步协作。我通过以下三个基本原则来描述它。</p><p></p><p>会议是最后的依仗而不是最初的选项。以文字作为分布式团队信息沟通的主要方式。团队中的每个人都非常习惯沟通中的合理延迟。</p><p></p><p>如果你对第一项原则感到惊讶，我能理解。在许多组织环境中，会议确实是领导者开展工作的主要工具。不过，对于以下两点，我相信我们可以达成共识。</p><p></p><p>对于团队中的大多数人来说，随时开会可能会导致工作被打断，一天都不安心，甚至效率低下。作为领导者，我们有责任为我们的团队创造一个工作环境，让他们能够体验到心流状态。许多会议之所以效率低下，是因为缺乏准备，缺少记录跟踪，对应参会人员的识别也不够准确。当我们采用“异步优先”方法时，我们也必须能够在需要时为同步交互做好准备。这可以帮助我们思考需要谁参加会议，以及如何将会议结果传达给没有参会的人。</p><p></p><p>所以，下次你想和同事合作的时候，与其去开会，不如考虑下，一种速度慢一点的异步媒介是否会更有效。你可以使用支持内置讨论区、Wiki、录制视频甚至收发消息和电子邮件的协作文档。</p><p></p><p>下面我将探讨下，为什么你和你的团队将受益于这种异步优先的思维方式，以及如何在你自己的环境中采用它。</p><p></p><p></p><h2>异步优先的六大优势</h2><p></p><p></p><p>自从大流行引发的远程工作革命以来，知识工作者现在希望雇主提供灵活的工作地点和时间。尽管有许多雇主要求员工回办公室办公，但可以这样假设，我们本就有一些同事对我们来说永远是远程的。除此之外，即使在经济衰退时期，企业也难以完全填补空缺的技术职位。市场终将回升，在某个时候，科技人才会显得更加稀缺。公司将不得不从其他能够招到人的地方招聘，并使他们融入到自己的团队中。技术团队“默认就将是分布式的”。有鉴于此，“异步优先”协作方法较当前以会议为中心的方法的优势就体现出来了。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3b/3bbae05f5a963066b6651ff51006cbee.jpeg\" /></p><p></p><p>在异步优先的文化中，我们偏爱行动。我们会在当下做出最好的决策，记录下来，然后继续前进。重点是把事情做好。如果出了问题，我们会从中吸取教训，进行重构和调整。对行动的偏爱提高了团队做出并记录决策的能力。毕竟，决策是高绩效团队的能量之源。</p><p></p><p>除了这些好处之外，异步优先文化还能帮助你提高会议效率。当你把会议当作最后的手段时，你所参加的会议就是你所需要的。你找回了自己的时间和注意力，并让那些少数的、目的明确的会议对每个参加的人都有用。</p><p></p><p></p><h2>异步优先并非仅限异步</h2><p></p><p></p><p>采用异步优先并不意味着同步交互没有价值。异步和同步协作之间的良好平衡会使团队受益。在分布式团队中，这种平衡应该偏向于异步，以免每个人的日历上都有一年 80 天的会议。话虽如此，你也不能忽视同步协作的价值。</p><p></p><p>书面沟通的速度慢，你有足够的时间深思熟虑。你可以独自写一些东西，并分享给你的同事，而不必打电话。它还能让你达到在快节奏实时对话中无法达到的深度。你写的所有内容都可以在将来重用和引用。这就是异步沟通非常有效的原因。让我们看几个例子。</p><p></p><p>想象一下，架构师记录使用新库的提案并用文字从各个维度（例如集成计划、测试、验证、风险和替代方案）进行了描述。这可以在短时间内帮助整个团队和业务利益相关者参与进来。当团队成员在他们的工作流程中记录项目时，通过诸如会议纪要、架构决策记录、提交消息、拉取请求、创意论文或设计文档等，他们就构建了项目团队的集体记忆。这有助于你追溯项目，解释项目是如何到达当前状态的。上面的每个例子都可以从团队成员和领导者的协作中受益。例如，当领导者提议使用新库时，团队成员可以在 Wiki 页面上发表评论，分享关注点、想法、反馈和建议。使用类似的方式，初级团队成员可以创建拉取请求来触发代码审查，而团队领导者必须在审查拉取请求时提供有用的反馈。如此一来，书面沟通就成了一种协作实践。另一方面，同步沟通可以帮助你解决紧急问题。这就需要借助实时消息或视频会议了。不过，并非所有的活动都是紧急的。将同步工作模式应用于非紧急活动，通常要付出工作流中断的“代价”。这就是为什么我们必须在同步和异步之间进行平衡！</p><p></p><p>同样，当你必须在短时间内处理许多话题时，或者当你想要获得自发的、未经过滤的反应和想法时，你就会希望采用同步方式。你肯定也会同意，大多数人都希望与同事建立一些“人类”的联系，特别是在远程和分布式团队中。这也是同步沟通的优势所在。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d0/d0dde6aecaf4059dfa01cb6f9a5ea25f.jpg\" /></p><p></p><p></p><h2>异步 vs 同步沟通——价值平衡</h2><p></p><p></p><p>所以请记住——“异步优先”并非“仅限异步”。要根据需要对团队的协作模式进行权衡取舍。为正确的目的选择合适的模式。</p><p></p><p></p><h2>采用异步优先的障碍</h2><p></p><p></p><p>异步优先的概念看似简单。少见面，多书面，接受延迟——咒语很简单。然而，我发现许多团队在采用这种方法时都遇到了困难。这有几方面的原因。</p><p></p><p>每个人都认同的协作模式才会起作用。那样才会产生“网络效应”。如果一些人以异步优先的方式工作，而其余的人以会议为中心的方式工作，你就不太可能获得你想要的好处。团队已经习惯了许多在日历上重复出现的同步做法——例如站会、私下商议、电话报告和计划。如果不仔细考虑，很难用异步过程取代这些惯常的做法，同时仍然保留其价值。协作模式的任何变革都会导致一段时间的迷惑与混乱。在此期间，团队在看到任何好处之前会首先看到生产力的下降。没有为这种生产力下降做好计划的团队可能在得到好处之前就放弃了变革。因此，任何新的工作方式想要持续下去，首先需要业务部门和团队的支持。然后，还必须一次又一次地实践，确保你在引入新的做事方式时不会失去任何价值。异步优先协作也是如此。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/70/700c73cfa1afeaa26d935dcff3ecc429.jpg\" /></p><p></p><p>工作方式的成功变革需要什么</p><p></p><p></p><h2>和你的团队一起开启“异步优先”</h2><p></p><p></p><p>假设业务部门和团队都看到了会议太多的问题，那么你应该已经从这些利益相关者那里得到了一些支持。为了对你关注的领域划分个优先级，我建议你对团队做个调查，看看他们最看重那六个好处中的哪一个。</p><p></p><p>反思团队当前协作实践的状态是为异步优先做准备的一个好方法。我建议问下面这四组问题。</p><p></p><p>你在工作过程中创建工件时有多勤奋、多仔细？例如，决策记录、提交消息、自述文件和拉取请求。在异步优先文化中，这样的工件是基础。你对自己主持的会议纪律要求有多严格？想想那些预先设定好的议程、指定的主持人、时间盒和会议记录。人们是否可以心安理得地拒绝那些他们不会增加或获得价值的会议？会议规模是否通常很小，8 人或更少？有效的会议是有效的异步优先工作方式的一个附带效果。你有多少时间可以用于深度工作？你每天想要多少时间？团队想要的时间和已经得到的时间之间有多大的差距？让一个人加入你的团队有多容易？一个人在访问了你的系统后，第一次提交需要多少时间？入职流程是对工作方式记录是否完善的一个测试。上述问题将帮助你为团队的分布式工作实践成熟度建立一条基线。它还将帮助你确定你可以有针对性的进行改进的领域，以实现向异步优先方式的转变。我建议使用一个调查工具来评估这个基线，因为那样比较简单，而且……嗯…异步！</p><p></p><p>将调查结果发布给团队，并突出显示差距，以便每个人都能清楚地了解差距在哪。这样一来，你就可以清楚地了解为什么使用异步优先，以及希望获得什么好处。</p><p></p><p></p><h2>基本转变</h2><p></p><p></p><p>根据我的经验，每个团队向异步优先工作方式的转变过程都不一样。实际上，在完成我所推荐的基线活动后，团队通常会选择不同的领域利用异步协作进行改进。我建议每个团队都做一些基本的转变。</p><p></p><p></p><h3>定义工作流程</h3><p></p><p></p><p>在工作中，我们都认可“自组织团队”和“自主权”的重要性。然而，正如 Cal Newport 在其著作《没有电子邮件的世界》中所说，知识工作是“工作执行”和“工作流程”的结合。虽然每个人对自己的工作执行都应该有自主权，但团队必须明确定义他们的工作流程，而不是让人去猜测。例如，请看下图，这是我当前所在的团队采用的双轨开发方法。它阐述了每个人的责任，以及工作如何在我们团队的系统中流转。我们还设置了团队任务板来贯彻这个工作流程。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/67/671f97a07821a82323aeca21bd285890.jpg\" /></p><p></p><p>定义工作流程，避免异步优先团队中出现混乱</p><p></p><p>当你以这种方式记录开发过程时，它会减少由于不知道谁该做什么或下一步该做什么而需要召开的会议。对于团队的新成员，它也是一份现成的参考。你不需要开会向新同事解释开发过程。一次编写，多次运行！</p><p></p><p></p><h3>把决策推到最底层</h3><p></p><p></p><p>团队做出的每一项决策往往都需要召开会议。这种协调不仅是有成本的，而且还会导致数次工作中断。这也会导致团队不愿意承担风险。首先，与团队一起定义项目上下文中不可逆决策的类别。这样的类别很少，不要为此感到惊讶。持续交付实践已经非常成熟，几乎所有的软件决策都是可逆的，除了那些具有财务、遵从性或监管影响的决策。只有这些决策需要共识式决策。其他可逆决策可以采用更轻量级的方法。</p><p></p><p>例如，每当有人想要决定某件事并希望寻求其他人的意见时，他们可以写下决策记录并邀请其它人进行评论。如果这个决策是可逆的，而且又没有什么顾虑，他们就会按照可行的建议行事。你甚至可以按照特性或能力线，将大型团队组织成两到三个人的短期小型团队，如下图所示。每个小团队都有一个直接负责人（DRI），对团队决策负责。DRI 的地位应该和团队中的其他人对等，他应该是“同侪之首”（FaE）。这种组织方式有三个明显的特点。</p><p></p><p>个体仍然可以采用异步决策技术，但当存在意见分歧时，DRI 可以发挥决定性作用；缩小了沟通范围，尤其是当你需要开会的时候。小团队对它正在构建的东西有自己的决定权。他们做出决策，然后在一个所有其他小团队都能看到的地方分享决策记录。为了促进知识共享，增加团队弹性，人员仍然可以在不同的小团队之间轮转。这样可以提高决策的自主性，同时还可以帮助团队成员熟悉整个代码库。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/fd/fdabd9e7f25b814da8885a53b5995e42.jpg\" /></p><p></p><p>将大型团队组织成小团队，缩小决策范围</p><p></p><p></p><h3>创建团队手册</h3><p></p><p></p><p>高质量的文档是异步协作的催化剂。每个软件团队都应该有一个地方来存储团队的知识和文档，包括决策记录、报告、说明书、设计文档、建议等。我称之为“团队手册”。如果你的团队已经使用了一些广泛应用的工具，则可以使用它们来实现这个目的，如 Confluence、GitLab、SharePoint、Notion、Almanac、Mediawiki 等。</p><p></p><p>花一些时间和你的团队一起规划手册的初始结构，通过组织轻量级的谷仓建造活动创建第一个版本。自此之后，团队就有了自己的手册，就像他们拥有代码库一样。随着团队需求的变化对团队手册进行改进和结构调整。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/9b/9b5f4c70631d81f1f46b2d5c66e4f1b6.jpg\" /></p><p></p><p>团队手册示例</p><p></p><p></p><h3>减少会议数量</h3><p></p><p></p><p>已经在一起工作过一段时间的团队通常会积累很多固定程序和承诺。在分布式团队中，这些承诺以会议的形式出现在团队日历上。对于团队来说，每个冲刺要预留 10 个小时的会议，这种情况很常见。为了采用异步优先，就要精简团队的会议列表，只保留必要的会议，这是有帮助的。我使用一个我称之为“ConveRel 象限”的框架来帮助团队确定哪些会议是必要的，哪些会议可以用异步沟通代替。</p><p></p><p>其框架是一个标准的 2x2 矩阵。X 轴代表沟通的性质。右边是“传达（conveyance）”，一个例子是单向信息传递。左侧是“汇聚（convergence）”，一个例子是在一个研讨会上做出一个高风险的决策。</p><p></p><p>Y 轴表示参与沟通的人之间的关系强弱。上半部分表示强关系，下半部分表示弱关系。</p><p></p><p>你可以将团队会议绘制到这个矩阵的象限中，以确定当采用异步优先时它们将如何变化。</p><p></p><p>如果你只是想把信息传达给与你关系密切的人，那就不要开会。相反，通过共享文档或维基页面，或通过发送电子邮件或消息，只要使信息可以通过网络访问即可。这事再简单不过了。大多数状态更新和报告电话都属于这个象限。如果你们的关系很弱，那么你就可能需要一些互动来建立这种关系。传递信息可以是建立友情的一种手段。当关系变强后，再用异步交互代替这些交互。如果你们的关系很弱，而你又希望在一个决定上达成一致，我建议你默认采用会议的方式。最后，如果你们的关系很牢固，并且希望在一个决定上达成一致，那么你们应该异步收集所有的输入，会议之外做能做的事情就在会议之外做，只在最后一步时才聚在一起。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/4a/4a351b56ca22c44178f6592eb69f7387.jpg\" /></p><p></p><p>ConveRel 象限</p><p></p><p>使用 ConveRel 象限进行简单的会议审计，不仅可以帮助你确定可以用异步流程替换的会议，还可以帮助你改进你选择保留的会议。</p><p></p><p>有了这些基本的转变，你就可以做一些最大的改进，从而帮助你异步开展工作。现在，你可以与团队一起评估你通过临时视频会议进行的每一项实践，并找出异步替代方案。这需要时间，所以每个开发周期都要做一两个改进，然后看看进展如何。</p><p></p><p></p><h2>小结</h2><p></p><p></p><p>异步优先协作可以帮助你的分布式团队变得更高效、更包容、更周到、更有趣。不过，这不是一夜之间可以完成的。我们中的许多人都默认采用了同步工作方式，因为它模仿了疫情前我们所处的办公室文化。据我们了解，那会让团队日历上满是会议！</p><p></p><p>如果你希望帮助你的团队更多地采用异步工作方式，那么你不仅必须获得他们的支持，还必须获得业务部门的支持，这样你才能获得变革所需的空间。作为变革过程的一部分，检查团队的协作过程，并确保找到可行的异步替代方案。这样做的目的不仅是减少中断，而且要保留同步方式给团队带来的价值。</p><p></p><p>在指导这种转变时，要注意反思。评估团队分布式工作成熟度的基线活动将帮助你标记起点。从这一点来看，受你影响所进行的每一项变革都应该有助于推动团队实现它所寻求的利益。首先与你的团队合作，记录你的工作流程，简化决策过程，创建团队手册，并进行会议审计。这些初始工作可以奠定一个不错的基础，让你可以针对每个协作过程进行其他比较小的迭代改进。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/asynchronous-collaboration-software-teams\">https://www.infoq.com/articles/asynchronous-collaboration-software-teams</a>\"</p>",
    "publish_time": "2024-01-02 09:57:40",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "构建国际化框架，Web开发让语言无阻",
    "url": "https://www.infoq.cn/article/BOyU4gzuPBfadox13A0z",
    "summary": "<p></p><h3>快速阅读</h3><p></p><p></p><p>国际化（i18n）和本地化是 Web 开发中的关键流程，能够确保软件适用于不同的语言和地区，并确保软件实际适配这些特定的需求。尽管以 JavaScript 为核心的 i18n 库（如 i18next、react-intl 和 react-i18next）是该领域的主流工具，可帮助开发人员高效地处理翻译和本地化相关的配置，但它们仅适用于基于 JavaScript 的 Web 应用。我们需要一个与语言无关的国际化框架。JSON 是一种广泛接受的格式，可用于存储翻译和本地化相关的配置，无论使用何种语言和框架，都能在各种应用程序中轻松集成和动态替换内容。内容分发网络（Content Delivery Network，CDN）可被战略性地用于高效提供本地化相关的配置文件，从而减轻加载大型配置文件潜在的弊端。构建自定义国际化框架，并将其与数据库或数据存储解决方案集成，可以实现动态和上下文感知的翻译，从而增强不同地区和语言的用户体验。</p><p></p><p>你是否已经涉足 Web 开发的汪洋大海？如果答案是肯定的，那你很快就会意识到，Web 不仅仅是为英语使用者服务的，它是面向全球的。假设法国用户看到了一条令人困惑的纯英文错误信息，在你被类似的投诉淹没之前，我们先来讨论一下什么是国际化（internationalization，通常简写为 i18n）和本地化。</p><p></p><p></p><h2>i18n 这个流行词是什么意思？</h2><p></p><p></p><p>想象一下，在这个世界上，无论每个人的母语是什么，你的软件都可以与他们流畅地交流。这就是国际化和本地化要实现的目标。虽然乍看上去没啥特别之处，但是请记住，本地化应用程序不仅仅是翻译文本。而是要根据用户的文化、地区和语言偏好提供量身定制的体验。</p><p></p><p>但是，这里有个障碍在等着你。深入了解 i18n 库的工具箱，你会发现以 JavaScript 为核心的解决方案占据了主导地位，尤其是那些围绕 React 的解决方案（如 i18next、react-intl 和 react-i18next ）。</p><p></p><p>如果跳出 JavaScript 的范畴，可选的方案就会越来越少。更糟糕的是，这些现成的工具通常都带有“一刀切”的特点，缺乏适配特定用例的能力。</p><p></p><p>不过，不必担心！如果鞋子不合适的话，为何不自己动手做呢？请继续往下阅读，我们将指导你从头开始构建一个国际化框架：一个为你的应用程序量身定制、跨语言和跨框架的解决方案。</p><p></p><p>准备好为你的应用程序签发全球通行证了吗？让我们开始这段旅程吧。</p><p></p><p></p><h2>基础的方式</h2><p></p><p></p><p>掌握国际化精髓的一个简单方法就是使用一个函数，该函数能够根据用户所在的地域获取信息。如下是一个使用 Java 编写的样例，它提供了一个基本但有效的方法：</p><p></p><p><code lang=\"null\">public class InternationalizationExample {\n\n    public static void main(String[] args) {\n        System.out.println(getWelcomeMessage(getUserLocale()));\n    }\n\n    public static String getWelcomeMessage(String locale) {\n        switch (locale) {\n            case \"en_US\":\n                return \"Hello, World!\";\n            case \"fr_FR\":\n                return \"Bonjour le Monde!\";\n            case \"es_ES\":\n                return \"Hola Mundo!\";\n            default:\n                return \"Hello, World!\";\n        }\n    }\n\n    public static String getUserLocale() {\n        // This is a placeholder method. In a real-world scenario,\n        // you'd fetch the user's locale from their settings or system configuration.\n        return \"en_US\";  // This is just an example.\n    }\n}</code></p><p></p><p>在上面的样例中，getWelcomeMessage 根据 locale 指定的语言返回欢迎信息。语言是由 getUserLocale 方法确定的。这种方法虽然非常基础，但是展示了根据用户特定的本地语言提供内容的原则。但是，随着内容的进展，我们将深入研究更先进的技术，并了解为何这种基础的方式对于大型应用程序可能无法具备可扩展性和高效率。</p><p></p><p></p><h3>优点</h3><p></p><p></p><p>覆盖面广：由于所有的翻译都嵌入在代码中，因此我们可以使用多种语言，而不必担心外部依赖或缺失翻译。无网络调用：翻译直接从代码中获取，无需任何网络开销或从外部源获取翻译相关的延迟。便利的代码搜索：由于所有的翻译都是源码的一部分，因此搜索特定翻译或排查相关的问题变得很简单易行。可读性：开发人员可以立即理解选择特定翻译背后的流程和逻辑，从而简化调试和维护。减少外部依赖：无需依赖外部翻译服务或数据库，这意味着应用程序中少了一个故障点。</p><p></p><p></p><h3>缺点：</h3><p></p><p></p><p>更新操作需要发布新的版本：在移动应用或独立应用的场景中，添加新语言或调整现有的翻译需要用户下载并更新最新版本的应用。冗余代码：随着要支持语言数量的增加，switch 和条件语句也会相应地增加，从而导致代码的重复和臃肿。合并冲突：由于多个开发人员可能会对各种语言进行添加或修改，所以版本控制系统中出现合并冲突的风险会随之增加。代码维护所面临的挑战：随着时间的推移，应用程序会进行扩展并支持更多的本地语言，直接在代码中管理和更新翻译会变得繁琐且容易出错。灵活性有限：采用这种静态的方式很难添加像复数形式、特定上下文的翻译或动态获取翻译等特性。性能开销：对于大规模应用而言，加载大块的翻译数据却仅使用其中很小的一部分会导致资源紧张，造成效率低下。</p><p></p><p></p><h2>基于配置的国际化</h2><p></p><p></p><p>在前一种方法的基础之上，我们努力保留其优点，同时解决其缺点。为了实现这一点，我们将代码库中的硬编码字符串值过渡到基于配置的设置。我们会为每种本地语言使用单独的配置文件，并以 JSON 格式进行编码。这种模块化方式简化了翻译的添加和修改，无需进行代码的变更。</p><p></p><p>如下是英语和西班牙语本地语言的配置文件：</p><p></p><p>文件名：en.json</p><p></p><p><code lang=\"null\">{    \"welcome_message\": \"Hello, World\"}\n</code></p><p></p><p>文件名：es.json</p><p></p><p><code lang=\"null\">{    \"welcome_message\": \"Hola, Mundo\"}\n</code></p><p></p><p></p><h3>Java 中的实现：</h3><p></p><p></p><p>首先，我们需要一种读取 JSON 文件的方式。这通常会使用像 Jackson 或 GSON 这样的库。在本例中，我们将使用 Jackson。</p><p></p><p><code lang=\"null\">import com.fasterxml.jackson.databind.ObjectMapper;\nimport java.io.File;\nimport java.io.IOException;\nimport java.util.Map;\n\npublic class Internationalization {\n\n    private static final String CONFIG_PATH = \"/path_to_configs/\";\n    private Map translations;\n\n    public Internationalization(String locale) throws IOException {\n        ObjectMapper mapper = new ObjectMapper();\n        translations = mapper.readValue(new File(CONFIG_PATH + locale + \".json\"), Map.class);\n    }\n\n    public String getTranslation(String key) {\n        return translations.getOrDefault(key, \"Key not found!\");\n    }\n}\n\npublic static class Program {\n\n    public static void main(String[] args) throws IOException {\n        Internationalization i18n = new Internationalization(getUserLocale());\n        System.out.println(i18n.getTranslation(\"welcome_message\"));\n    }\n\n    private static String getUserLocale() {\n        // This method should be implemented to fetch the user's locale.\n        // For now, let's just return \"en\" for simplicity.\n        return \"en\";\n    }\n}</code></p><p></p><p>Internationalization 类在实例化的时候，会根据提供的本地语言读取上述代码中相关的 JSON 配置。getTranslation 方法使用标识符获取所需的翻译字符串。</p><p></p><p></p><h3>优点：</h3><p></p><p></p><p>保留了上述方式的所有优点：覆盖面广，加载后无需使用网络就能进行翻译，代码易于搜索和阅读。动态加载：可根据用户的本地语言动态加载翻译。只需加载必要的翻译，从而带来潜在的性能优势。可扩展性：添加新语言更容易。只需为该语言添加一个新的配置文件，应用程序就能处理它，无需任何代码修改。更整洁的代码：逻辑与翻译分离，代码更简洁、更易维护。中心化的管理：所有的翻译都集中在一个文件中，因此更易于管理、审查和更新。这种方法提供了一种更可扩展、更简洁的国际化处理方式，尤其适用于大型应用程序。</p><p></p><h3>缺点：</h3><p></p><p></p><p>可能会导致配置文件过大：随着应用程序的增长和对多种语言的支持，这些配置文件可能会变得相当大。这可能会导致应用程序的初始加载出现滞后，尤其是在配置文件需要前期加载的情况中。</p><p></p><p></p><h2>从 CDN 抓取配置</h2><p></p><p></p><p>缓解可能出现大型配置文件的一种方法是将其托管到内容分发网络（Content Delivery Network，CDN）上。通过这种方式，应用程序可以根据用户的本地语言只加载必要的配置文件。这样既能保证应用程序的运行速度，又能减少用户不必要下载的数据量。当用户切换本地语言或探测到不同的本地语言时，可以根据需要从 CDN 获取配置。这为大规模应用程序提供了速度和灵活性之间的最佳平衡。为了简单起见，我们考虑使用基础的 HTTP 库来获取配置文件。在这个 Java 样例中，我们将使用虚构的 HttpUtil 库：</p><p></p><p><code lang=\"null\">import java.util.Map;\nimport org.json.JSONObject;\n\npublic class InternationalizationService {\n\n    private static final String CDN_BASE_URL = \"https://cdn.example.com/locales/\";\n\n    public String getTranslatedString(String key) {\n        String locale = getUserLocale();\n        String configContent = fetchConfigFromCDN(locale);\n        JSONObject configJson = new JSONObject(configContent);\n        return configJson.optString(key, \"Translation not found\");\n    }\n\n    private String fetchConfigFromCDN(String locale) {\n        String url = CDN_BASE_URL + locale + \".json\";\n        return HttpUtil.get(url);  // Assuming this method fetches content from a given URL\n    }\n\n    private String getUserLocale() {\n        // Implement method to get the user's locale\n        // This can be fetched from user preferences, system settings, etc.\n        return \"en\";  // Defaulting to English for this example\n    }\n}</code></p><p></p><p>注意：上述代码只是一个简化的样例，在实际的场景中可能需要错误处理、缓存机制和其他优化。</p><p></p><p>这里的想法是根据用户的本地语言直接从 CDN 获取必要的配置文件。用户的本地语言决定了配置文件的 URL，获取到之后，就会对配置文件进行解析，以获得所需的翻译。如果找不到相应地键，就会返回默认信息。这种方法的好处是，应用程序只需加载必要的翻译，从而确保了最佳性能。</p><p></p><p></p><h3>优点</h3><p></p><p></p><p>继承了前一种方法的所有优势。易于为新的本地语言组织和添加翻译。只需获取必要的翻译，因此加载效率高。</p><p></p><p></p><h3>缺点：</h3><p></p><p></p><p>配置文件体积庞大，可能会降低应用程序的初始化速度。字符串必须是静态的。无法直接支持动态字符串或需要运行时计算的字符串。如果需要在翻译中插入动态数据，这可能是一个限制。依赖外部服务（CDN）。如果 CDN 遇到故障或出现问题，应用程序将无法获取翻译内容。</p><p></p><p>但是，要解决这些缺点，我们可以采取如下措施：第一个缺点可以通过在 CDN 上存储配置文件并在需要时加载来缓解。第二个缺点可以通过在静态字符串中使用占位符并在运行时根据上下文替换来解决。第三个缺点则需要一个健壮的错误处理机制和一些潜在的后备策略。</p><p></p><p></p><p></p><h2>动态字符串处理</h2><p></p><p></p><p>如果要翻译的字符串有一部分内容是动态的，那么就需要一种更灵活的解决方案。以 Facebook 为例，在 News Feed 中，我们会看到这里使用了自定义的字符串来表示每篇文章的“Likes”信息。比如，如果文章只有一个“Likes”信息，那么你可能会看到“John likes your post.”。如果有两个“Likes”信息，那么你可能会看到“John and David like your post.”。如果有两个以上的“Likes”信息，你可能会看到“John, David and 100 others like your post.”。在这种情况下，需要进行一些自定义。动词“like”和“likes”是根据喜欢文章的人数来确定的。如何做到这一点呢？</p><p></p><p>考虑如下的样例：“John, David and 100 other people recently reacted to your post.”，在这里“David”、“John”、“100”、“people”和“reacted”都是动态元素。</p><p></p><p>我们来分析一下：</p><p></p><p>“David”和“John”可以是从与用户相关的方法或数据库中获取的用户名。“100”可以是从与文章相关的方法或数据库中获取的对文章做出反应的总人数，其中不包括 David 和 John。当代指一个集体时，“people”可以是名词“人”的复数形式。“reacted”可用于用户以爱心、关注或愤怒等图标对文章做出反应，而不能是表示喜欢的图标。</p><p></p><p>实现此类动态内容的一种方法是在配置文件中使用占位符，并在运行时根据上下文替换它们。</p><p></p><p>如下是一个 Java 样例：</p><p></p><p>配置文件（适用于英语）</p><p></p><p><code lang=\"null\">{\n      oneUserAction: {0} {1} your post,\n      twoUserAction: {0} and {1} {2} your post,\n      multiUserAction: {0}, {1} and {2} other {3} recently {4} to your post,\n      people: people,\n      likeSingular: likes,\n      likePlural: like,\n}</code></p><p></p><p>配置文件（适用于法语）：</p><p></p><p><code lang=\"null\">{\n      oneUserAction: {0} {1} votre publication,\n      twoUserAction: {0} et {1} {2} votre publication,\n      multiUserAction: {0}, {1} et {2} autres {3} ont récemment {4} à votre publication,\n      people: personnes,\n      likeSingular: aime,\n      likePlural: aiment,\n}</code></p><p></p><p>Java 实现：</p><p></p><p><code lang=\"null\">import java.util.Locale;\nimport java.util.ResourceBundle;\n\npublic class InternationalizationExample {\n\n    public static void main(String[] args) {\n        // Examples\n        System.out.println(createMessage(\"David\", null, 1, new Locale(\"en\", \"US\"))); // One user\n        System.out.println(createMessage(\"David\", \"John\", 2, new Locale(\"en\", \"US\"))); // Two users\n        System.out.println(createMessage(\"David\", \"John\", 100, new Locale(\"en\", \"US\"))); // Multiple users\n\n        // French examples\n        System.out.println(createMessage(\"David\", null, 1, new Locale(\"fr\", \"FR\"))); // One user\n        System.out.println(createMessage(\"David\", \"John\", 2, new Locale(\"fr\", \"FR\"))); // Two users\n        System.out.println(createMessage(\"David\", \"John\", 100, new Locale(\"fr\", \"FR\"))); // Multiple users\n    }\n\n    private static String createMessage(String user1, String user2, int count, Locale locale) {\n        // Load the appropriate resource bundle\n        ResourceBundle messages = ResourceBundle.getBundle(\"MessagesBundle\", locale);    \n\n        if (count == 0) {\n            return \"\"; // No likes received\n        } else if (count == 1) {\n            return String.format(\n                  messages.getString(\"oneUserAction\"),\n                  user1,\n                  messages.getString(\"likeSingular\")\n            ); // For one like, returns \"David likes your post\"\n        } else if (count == 2) {\n            return String.format(\n                  messages.getString(\"twoUserAction\"),\n                  user1,\n                  user2,\n                  messages.getString(\"likePlural\")\n            ); // For two likes, returns \"David and John like your post\"\n        } else {\n            return String.format(\n                  messages.getString(\"multiUserAction\"),\n                  user1,\n                  user2,\n                  count,\n                  messages.getString(\"people\"),\n                  messages.getString(\"likePlural\")\n                  ); // For more than two likes, returns \"David, John and 100 other people like your post\"\n        }\n    }\n}</code></p><p></p><p></p><h2>结论</h2><p></p><p></p><p>无论规模大小，开发有效的国际化（i18n）和本地化（l10n）框架对于软件应用都至关重要。这种方法可以确保你的应用能够与用户的母语和文化背景产生共鸣。虽然字符串翻译是 i18n 和 l10n 的一个重要组成部分，但它只是软件全球化这一更广泛挑战的一个方面而已。</p><p></p><p>有效的本地化不仅仅是翻译，还要解决其他的关键问题，例如书写方向，阿拉伯语等语言的书写方向（从右到左）和文本长度或大小各不相同，泰米尔语等语言的文字可能比英语更长。通过精心定制这些策略来满足特定的本地化需求，你就可以为软件提供真正全球化的、适用于不同文化的用户体验。</p><p></p><p></p><h5>原文链接：</h5><p></p><p></p><p><a href=\"https://www.infoq.com/articles/internationalization-framework/\">https://www.infoq.com/articles/internationalization-framework/</a>\"</p><p></p><h5>相关阅读：</h5><p></p><p></p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MjM5ODIzNDQ3Mw%3D%3D&amp;chksm=beca256b89bdac7d4234c85f248d75aace542c31322afcd2181035933b448fb7e52a9115a80d&amp;idx=1&amp;mid=2649970029&amp;scene=27&amp;sn=dd41f58ff643b44d9284f20eb6fe5e8d&amp;utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search#wechat_redirect\">你可以错过&nbsp;Web3，但不要错过&nbsp;Web5</a>\"</p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MjM5ODIzNDQ3Mw%3D%3D&amp;chksm=beca257f89bdac69029d839f0cdc2eea79bfde2f6acdf293d2925bd2dd79a88dfe95da36a637&amp;idx=1&amp;mid=2649970041&amp;scene=27&amp;sn=d365251428eb72019a23f528dc78b94e&amp;utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search#wechat_redirect\">别人不会告诉你的&nbsp;Web3 未来</a>\"</p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MjM5ODIzNDQ3Mw==&amp;mid=2649969927&amp;idx=1&amp;sn=cc8a7cee992d36202d86ee5068fcc66e&amp;chksm=beca250189bdac17511f9649f03ab3b0c6fee72a33cb1957ff5a6017924fe10b7c7d5581eb98&amp;scene=27#wechat_redirect\">Web3当下，最佳投资就是投资自己</a>\"</p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MjM5ODIzNDQ3Mw==&amp;mid=2649969873&amp;idx=1&amp;sn=8cc0a44a1ab3255ea5973d41520a4c39&amp;chksm=beca24d789bdadc1f9085e3853dffff525aaa28a09a46c50169585b66650a1ac26ae67db9b57&amp;scene=27#wechat_redirect\">Web3的反思，不要抱怨</a>\"</p>",
    "publish_time": "2024-01-02 10:10:19",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "React正在杀死Angular吗？",
    "url": "https://www.infoq.cn/article/PdymzksX2dxHgwC59qFU",
    "summary": "<p>这是一个老生常谈的争论（在技术时代，这是在所难免的）：Angular 对战 React。这就像“先有鸡还是先有蛋”的难题，不过这个问题是针对 Web 开发人员的。在过去的几年间，如果你曾经出现在开发人员的咖啡机旁或者参加过技术论坛，那么你可能会听到关于哪个框架才是霸主的窃窃私语、争论，甚至是偶尔出现的键盘对决。</p><p></p><p>现在，我们明确一下对战的双方。一边是经验丰富的战士 Angular。它经历过风雨，见证了潮流的起起落落，并拥有炫酷的特性。而另一边则是 React，它是年轻的神童。它来到这个世界，惊艳了所有人。随着它的迅速走红，有人开始怀疑 React 是否就是那个让老将 Angular 望尘莫及的后起之秀。有传言说，React 花哨的行为正在侵蚀 Angular 稳扎稳打的基石。</p><p></p><p>但是，对于 Angular 来说，React 真的是歌利亚的大卫吗（按照传说，歌利亚是身材巨大，拥有无穷力量的巨人，最后牧童大卫用投石弹弓打中歌利亚的脑袋，并将其杀死，日后这个牧童成为了著名的大卫王——译者注）？或者这只是一个技术神话，就像“重启能够解决 99% 的 IT 问题一样”？（好吧，这个说法也许就是真的）请继续关注我们对这场争论的深入探讨，一起揭开炒作背后的真相！</p><p></p><p></p><h2>简史</h2><p></p><p></p><p></p><h3>Angular：从默默无闻到技术王者</h3><p></p><p></p><p>我们将时光拨回到 2010 年，当时，jQuery 是最酷的东西，世界各地的开发人员都在与臭名昭著的意大利面条式代码抗争。就像超级英雄突然从阴影中现身一样，谷歌为我们引入了 AngularJS。AngularJS 拥有双向数据绑定和依赖注入等有趣的功能，许多开发人员自己都没有意识到这就是他们需要的英雄。将时间快进一些，AngularJS 长大了，也去掉了“JS”，变成了威严的“Angular”。就像我们最喜欢的电影系列一样，它会不断推出续集（也就是技术术语中的版本），让我们目不暇接！</p><p></p><p></p><h3>React：酷炫的新浪潮</h3><p></p><p></p><p>现在，我们把时间推移到 2013 年。就在 Angular 掀起热潮的时候，一个新的玩家进入了这个领域。从 Facebook 天才实验室直接走出来的 React 突然登上了舞台。但 React 并不是普通的初出茅庐者，它就像一个新生，第一天就在才艺表演上让所有人惊叹不已。凭借其创新性的虚拟 DOM 和基于组件架构的全新用户界面，React 很快成为整个领域的焦点。它简单易用的特性和灵活性使其备受青睐，很快就从新生儿变成了舞会之王！</p><p></p><p></p><h2>React 的优势</h2><p></p><p></p><p></p><h3>基于组件的架构</h3><p></p><p></p><p>还记得小时候玩过的乐高积木吗？只要把五颜六色的积木拼接在一起，你就能搭建出任何东西，从城堡到宇宙飞船。React 基于组件的架构就像是 Web 开发中的乐高积木。它允许开发人员将 UI 分解成可重用的组件，使得构建和维护复杂的应用程序就像是玩儿心爱的积木一样有趣和简单。最棒的一点是什么呢？那就是如果你需要更换一个组件，你不必拆除整个城堡。</p><p></p><p></p><h3>虚拟 DOM</h3><p></p><p></p><p>在 Web 开发领域，速度是最重要的。React 的虚拟 DOM 就像是这个领域的超级英雄。React 不会更新整个页面，而是聪明地只更新发生变化的部分，因此它的速度非常快。这就好比你有一个私人助理，他知道你把钥匙落到了什么地方，这样你就不用把整个房子翻个底朝天了。</p><p></p><p></p><h3>灵活性</h3><p></p><p></p><p>React 就像是一把方便的瑞士军刀，你希望每次露营都带上它。如果你需要与不同的库集成？React 会助你一臂之力。无论你是将它与 Redux 搭配进行状态管理，还是与 Axios 搭配进行 HTTP 请求，React 都能很好地与其他库配合，确保你具备探险所需的所有工具。</p><p></p><p></p><h3>强大的社区支持</h3><p></p><p></p><p>每个优秀的工具背后都有一个更强大的社区。React 也不例外。React 社区拥有一支由开发者、爱好者和向导组成的大军，这可以说是一座金矿。从教程到第三方库，如果你有问题，很可能早就已经有人回答过了。这就像拥有一个全天候的技术支持团队，不过这要比它酷得多。</p><p></p><p></p><h2>Angular 的优势</h2><p></p><p></p><p></p><h3>综合的框架</h3><p></p><p></p><p>想象一下，如果你入住一个度假胜地，从 SPA 中心到美食餐厅，一切都触手可及。这就是 Angular，它不仅仅是一个框架，还是一个完整的生态系统，具备大量可开箱即用的工具。无需寻找任何第三方库，Angular 为你提供了开发过程中可能需要的一切。</p><p></p><p></p><h3>双向数据绑定</h3><p></p><p></p><p>还记得在童话故事里那些能够同时显示现在和未来的魔镜吗？Angular 的双向数据绑定与之颇有几分神似。它在模板（视图）和组件（模型）之间搭起了一座桥梁，确保其中的任何一项发生变化都能反映到另外一项中。这就像有一个私人神仙教母，能够确保你的舞会礼服（在本例中，也就是用户界面）始终保持完好无损。</p><p></p><p></p><h3>依赖注入</h3><p></p><p></p><p>你可以将 Angular 的依赖注入视为代码中的近藤麻理惠（《怦然心动的人生整理魔法》一书的作者，以整理家庭内务而著名——译者注）。它能确保每段代码都处在自己恰当的位置上，从而增强模块化和可重新性。有了 Angular 的依赖注入，组件就能轻松获取它们所需的服务，让你的代码库变得整洁且令人愉悦。</p><p></p><p></p><h3>TypeScript</h3><p></p><p></p><p>我们都有一个对语法很挑剔的朋友，对吧？对于 Angular 来说，TypeScript 就是这位朋友。通过提供强类型，TypeScript 可以确保你在编译时就能捕获到那些讨厌的错误，而不是在用户试图查看购物车的时候。这就像为你的代码配备了一个内置校对员，确保一切都处于最佳状态。</p><p></p><p></p><h3>Angular CLI</h3><p></p><p></p><p>如果你曾经希望有一根魔法棒可以简化你的开发过程，那就来看看 Angular CLI 吧。借助其强大的命令，你可以创建项目、添加特性，甚至只需挥挥手（或者更确切地说，一个简单的命令）就能运行测试。这就像在终端里有一个精灵，随时准备实现你的开发愿望。</p><p></p><p></p><h2>React 和 Angular 的主要区别</h2><p></p><p></p><p></p><h3>理念</h3><p></p><p></p><p>就其本质而言，React 就像一位信奉极简主义的朋友。他只有五件衣服，但是每件衣服的搭配都非常漂亮。它是一个库，只关注视图层，在项目的其他方面，允许你去自由探险。</p><p></p><p>而 Angular 则像是一位拥有复式衣帽间和各种小玩意儿的朋友。它是一个完整的框架，提供了开箱即用的路由、状态管理、HTTP 客户端等解决方案。它包罗万象，能够为你带来连贯的开发体验。</p><p></p><p></p><h3>学习曲线</h3><p></p><p></p><p>React 因其简单易用而受到广泛称赞。它采用了基于组件的方式，就像在初学者赛道上练习滑雪，因此深受希望涉足 web 开发的初学者的喜爱。</p><p></p><p>Angular 的综合性更像是挑战顶级难度的滑雪道。一开始，它可能令人望而生畏，尤其是其独特的术语和理念，但是一旦你掌握了窍门，你就能像专业人士那样应对 web 开发的挑战了。</p><p></p><p></p><h3>社区和生态系统</h3><p></p><p></p><p>随着 React 的广泛采用，它成为了一个热闹的社区，就像乡村中的集市那样。每个需求都有一个摊位，无论是使用 Redux 进行状态管理，还是使用 React-Router 进行路由选择。社区充满了活力，拥有大量的资源、插件和第三方库。</p><p></p><p>有谷歌强大支持的 Angular 则像一个盛大的狂欢节。它拥有庞大的官方库、丰富的工具和经受了考验的社区，为成熟而广阔的生态系统做出了贡献。</p><p></p><p></p><h3>性能</h3><p></p><p></p><p>在性能方面，React 和 Angular 就像精英速滑运动员，各有千秋。React 采用虚拟 DOM，确保了高效更新，使其能够快速高效。而 Angular 则通过预先编译（AOT）和变更探测，确保始终能够领先一步，提供一流的性能。</p><p></p><p></p><h2>真实现状：采用趋势</h2><p></p><p></p><p></p><h3>React 与 Angular 的采用数据对比</h3><p></p><p></p><p>首先，我们看一下统计数据。虽然受欢迎程度并不代表一切 (只要问问流量电影的主角就知道了)，但它确实能够让我们了解开发者领域的趋势。</p><p></p><p>React：自诞生以来，React 便迅速崛起。在 npm 上每周有数百万的下载量，很明显这个库已经打动了全世界的开发者。这不仅仅是数量的问题，用 React 构建的项目和应用程序的质量也令人印象深刻。Angular：Angular 在受欢迎程度方面也不逊色，一直保持着自己的地位。凭借稳定的下载量和庞大的社区，Angular 的综合性显然引起了许多人的共鸣。它就像一个可靠的朋友，当你需要搬家时，尽可以打电话给他，它可能并不新颖夺目，但它能完成任务。</p><p></p><p></p><h3>大联盟：知名代言人</h3><p></p><p></p><p>现在，我们来谈谈代言人。就像运动员有自己的赞助商一样，框架和库也有自己的知名用户。在这个领域，React 和 Angular 都有一些重量级的用户。</p><p></p><p>React：从社交媒体巨头 Facebook（毕竟是他们创造了 React）到流媒体巨头 Netflix，许多科技大公司都因 React 的灵活性和性能而采用了它。不仅是科技界，各行各业的公司，无论是酒店业的 Airbnb 还是媒体业的《纽约时报》，都搭上了 React 的列车。Angular：Angular 背后的策划者谷歌在其多个平台上都使用了 Angular，这充分说明了 Angular 的可靠性。但它的粉丝俱乐部并不止于此。像福布斯、宝马，甚至美国国家航空航天局（NASA，没错，就是太空人！）等公司都在其数字领域中使用了 Angular。</p><p></p><p></p><h2>影响选择 React 和 Angular 的因素</h2><p></p><p></p><p>这是一个古老的难题，到底是该选择 React 还是 Angular？这就像在巧克力和香草、海滩度假和登山度假之间做出选择一样。两者各有其长处，但最佳选择往往取决于具体的情况。让我们来分析一下哪些因素可能会促使我们倾向于选择其中的某一个。</p><p></p><p></p><h3>项目需求</h3><p></p><p></p><p>React：我们可以把 React 想象成时髦的定制西装。它非常适合需要特定功能而不需要额外装饰的项目。基于组件的特性使其支持高度定制，因此非常适合需要量身定制的独特项目。Angular：而 Angular 就像一套成衣。它配备了你所需要的一切。对于需要内置功能的综合解决方案的项目，Angular 可能是你的首选。</p><p></p><h3>团队专长</h3><p></p><p></p><p>团队的专业知识会在很大程度上影响你的选择。如果你的团队精通 React 并已使用多年，那么坚持使用自己熟悉的产品可能会更有合理。反之，如果你的团队中有 Angular 专家，又何必冒险进入陌生的领域呢？</p><p></p><p></p><h3>长期维护</h3><p></p><p></p><p>在可维护性方面来看，React 和 Angular 都有各自的特点。请考虑项目的长期目标。你需要易于扩展的产品吗？是否需要定期更新？React 的库方式提供了灵活性，而 Angular 包罗万象的特性可能会简化更新和扩展。</p><p></p><p></p><h2>总结</h2><p></p><p></p><p>在结束这次启蒙之旅的时候，让我们来澄清一下。React 并没有“杀死”Angular，而 Angular 也没有将 React 推向被遗忘的境地。它们就像两位才华横溢的艺术家，各有其风格和天赋。</p><p></p><p>在 React 和 Angular 之间做出选择，并不是要追赶最新的潮流或选择“哪一个更好”。而是了解自己的需求，评估自己的资源，然后做出明智的决定。毕竟，最好的工具是能完成工作的工具，而不是炒作最多的工具。</p><p></p><p></p><h5>原文链接：</h5><p></p><p></p><p><a href=\"https://blog.stackademic.com/is-react-killing-angular-the-truth-behind-the-hype-6294e2cf6688\">https://blog.stackademic.com/is-react-killing-angular-the-truth-behind-the-hype-6294e2cf6688</a>\"</p><p></p><h5>相关阅读：</h5><p></p><p></p><p><a href=\"https://www.infoq.cn/article/Tv3SyqoivXMWUoj8qSMT\">从新&nbsp;React&nbsp;文档看未来 Web 的开发趋势</a>\"</p><p><a href=\"https://www.infoq.cn/article/CZKMjHaxbf1Z7xcSzisX\">我被&nbsp;React&nbsp;劫持了，很痛苦又离不开</a>\"</p><p><a href=\"https://xie.infoq.cn/article/7baec545b8202471064494a69\">2023 重学 Angular</a>\"</p><p><a href=\"https://www.infoq.cn/article/oONc5r5opJF64kBCtzIv\">Angular v15 发布：可以脱离 NgModules 构建组件了</a>\"</p>",
    "publish_time": "2024-01-02 10:56:09",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AI 时代，龙蜥加速服务器操作系统进化，位列用户意愿迁移第一",
    "url": "https://www.infoq.cn/article/14LNRLJkHMQS035l3B7H",
    "summary": "<p>自 2020 年 12 月 CentOS 宣布停止维护后，中国服务器操作系统市场得到了新一轮的发展机遇。日前发布的《国产服务器操作系统发展报告（2023）》中提到，目前国内已出现多个较为成熟的国产服务器操作系统，产业步入 2.0 时代，面向云计算、智能计算等方向进化。根据中国信通院最新发布的用户调研显示，国内服务器操作系统逐渐成为各行业替换首选，其中，用户意愿迁移至龙蜥操作系统的比例达到 53%，位居首位。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d4/d459d7f846c5e8ea8921268cb3ea0841.png\" /></p><p></p><p>近日，在主题为“云智融合·共筑未来”的 2023 龙蜥操作系统大会上，浪潮信息、Intel、中兴通讯成为龙蜥社区副理事长单位。中国科学院院士梅宏指出，龙蜥社区采用了开放中立的治理理念，社区正由单引擎，转变为由阿里云、浪潮信息、统信软件等多家企业共同治理的新格局，这种共同治理模式能够更好地激励所有参与者，促进社区成员更好地发挥积极性、主观能动性，为龙蜥社区做出更大的贡献。希望龙蜥在未来能够按照现在设想的治理模式和已经形成的基础，获得更进一步的发展。</p><p>&nbsp;</p><p>龙蜥社区副理事长张东表示，智算时代，算力产业呈现出算力形态多元异构、算力供给服务化、算力应用智能化的新发展趋势，需要以应用为导向，以系统设计为核心，从系统的角度出发，真正让不同架构的技术、产品和相应的生态融合起来。而达成这个目标的一大关键，就是要推动系统软件的进阶，实现多元算力的协同优化，云原生应用场景支撑优化以及系统软件与 AI 的深度双向融合。</p><p></p><h2>机遇与挑战并存，中国服务器操作系统加速进化</h2><p></p><p>&nbsp;</p><p>CentOS 的停服为中国服务器操作系统市场带来了新的发展机遇，近几年，以龙蜥、欧拉为代表的中国服务器操作系统迅速崛起，在千行百业中得到了广泛应用，并通过打造开源社区的形式使得生态进一步繁荣。</p><p>&nbsp;</p><p>技术路线上，龙蜥操作系统将构建“1+3”能力模型，遵照 1 个“分层分类”科学理论的去中心化协同演进的技术路线，以“用好开源、做深开源、自主创新”为核心出发点，长期投入研发，打造“供应链安全”、“开源标准”和“云原生+AI”三位一体的下一代操作系统。</p><p>&nbsp;</p><p>目前，龙蜥社区拥有超过 800 家生态伙伴，基于社区操作系统发行了超过 12 款针对下游的衍生版，同时龙蜥操作系统服务器装机量现已超过 600 万，服务了金融、通信、能源、交通等众多行业超过 80 多万用户。欧拉社区已吸引 1300 多家头部企业、研究机构和高校加入，汇聚 16800 多名开源贡献者，累计装机量已超过 610 万套。</p><p>&nbsp;</p><p>虽然近几年中国服务器操作系统进入发展快车道，但与海外竞争对手相比仍存在一定的差距，生态建设仍是当前中国服务器操作系统的重要一环，操作系统社区需要在生态建设上持续投入，共同推动产业进一步发展。此外，随着 AI 技术得到广泛应用，操作系统需要不断创新，加速智能化，以更好地满足新的应用需求。</p><p></p><h2>操作系统生态建设路径：技术生态与商业生态齐发展</h2><p></p><p>&nbsp;</p><p>生态是操作系统的根本。在计算机系统层次结构中，操作系统起着承上启下的重要作用，其介于硬件与应用软件之间，控制并协调多个任务的活动。这也意味着，操作系统需要与各种不同的 CPU、GPU 和其他硬件驱动进行对接。从技术上来看，构建操作系统生态的难点在于如何实现技术上的对接，并让所有参与方都在统一的框架下工作。</p><p>&nbsp;</p><p>以龙蜥社区为例，阿里云基础软件部副总裁、龙蜥社区理事长马涛表示，龙蜥社区希望通过同源异构的方式支持国内外的所有 CPU。然而一些大型 CPU 厂商通常有自己的操作系统，这些操作系统在内核版本和工具上可能存在差异，这给应用适配和生态建设带来了很大的困难。龙蜥社区现已与主流硬件厂商达成合作，希望能够建立统一标准，降低用户使用成本。</p><p>&nbsp;</p><p>从软件层面看，操作系统位于承上启下的中间层，能够影响到所有企业的利益。如果一个社区无法为所有参与操作系统生态的企业找到利益点，生态建设也将难以取得成功。因此，除了技术生态，操作系统社区还需要关注商业生态，让社区参与者能够形成自己的商业闭环，并从闭环中持续获得收益。这也是一件非常有挑战性的事情。</p><p>&nbsp;</p><p>当前，我国计算产业体系仍然建立在国外的技术体系之上，要想在算力产业中形成一套完全自主的技术体系，还有很长的路要走。而社区为构建生态提供了一个更好的环境——社区可以让单一厂商无法吸引的合作伙伴得以聚集。在社区模式下，大家是平等的，为社区做贡献并获得反馈。这种模式下可能比单一厂商仅靠商业合作更能吸引合作伙伴。</p><p>&nbsp;</p><p>张东认为，要使社区成功，有两个前提条件：一是参与社区的所有厂商能够获得收益；二是社区能够为厂商参与者提供更好的支持，在发行版、芯片、服务器等方面提供更多的帮助。只有这样，才能让各方都愿意参与进来。</p><p>&nbsp;</p><p>龙蜥社区将开放、开源、共享、共治作为社区发展的核心原则。在这一原则的推动下，龙蜥快速成长为中国最具影响力的开源操作系统社区。据介绍，龙蜥社区目前由阿里云、统信软件、英特尔、浪潮信息等 24 家理事单位共同治理，超过 800 家来自芯片、软件、整机等覆盖操作系统全产业链的合作伙伴参与生态共建。</p><p>&nbsp;</p><p>作为龙蜥社区新晋副理事长单位，浪潮信息在过去 2 年中积极投入社区建设，依托浪潮信息龙蜥联合实验室，在技术创新、标准制定、生态建设、运营推广等多个维度推动社区建设。其中，基于龙蜥操作系统开发的商业衍生版云峦 KeyarchOS 在一云多芯、人工智能、虚拟化、云原生等方面都得到了增强，已实现规模化部署。未来，浪潮信息将持续加大对龙蜥社区的投入，联合产业链上下游增强软硬协同创新，共同推动龙蜥操作系统生态的繁荣发展。</p><p></p><h2>AI 时代，操作系统迈向智能化</h2><p></p><p>&nbsp;</p><p>在 AI 时代，操作系统正在经历一场前所未有的变革。随着 AI 技术的飞速发展以及 AI 应用的广泛落地，操作系统需要与各种智能化应用进行深度融合，以提供更智能化的服务。这也对操作系统提出了新的要求——操作系统作为底层技术，需要积极探索如何与 AI 相融合，以提升系统的智能化水平和用户体验。</p><p>&nbsp;</p><p>马涛表示，操作系统最终是为了用户而设计的，因此需要通过 AI 来帮助最终用户更高效地使用操作系统。这涉及到两个视角：研发视角和用户视角。对于用户视角而言，服务器操作系统与桌面操作系统的一个主要区别在于它是为企业级应用而设计的，通常会有运维人员负责管理，需要通过 AI 快速定位问题、找到问题的根源或进行智能运维。“我们正在与运维联盟一起探索如何使用 AI 进行大规模集群化和智能化的运维。这对于服务器操作系统非常重要，因为对于个人或 PC 用户来说可能不是问题，但对于运营数百台甚至数万台电脑的大型公司来说却是关键所在。”</p><p>&nbsp;</p><p>其中，不仅需要考虑 AI For System（操作系统自身的智能化），还需要思考如何通过 System For AI 来进行优化。从研发和测试效率的角度来看，实现这一目标有几个重要的路径。第一，AI 可以用于操作系统开发或测试，以更有效地提高程序员的效率。许多公司都在尝试这种方法，因为内核或操作系统中存在大量的 Magic number，这些数字过去都是基于经验设计的。因此，需要采用基于机器学习和大规模训练的智能调优方法来帮助程序员和研发团队更好地调整系统。这有助于提高研发和测试的效率。</p><p>&nbsp;</p><p>浪潮信息系统软件部总经理苏志远提到，最典型的例子是使能多元的算力和芯片。表面上看，这些芯片厂商已经提供了完善的解决方案，但实际上，当企业在实际应用中测试它们的性能时，会发现其中存在许多需要解决的问题。这些问题主要集中在驱动方面，甚至涉及到与驱动的交互。只有依赖芯片厂商或部件厂商提供的支持，才能有效地解决这些问题。</p><p>&nbsp;</p><p>“操作系统团队和芯片团队需要紧密合作，因为芯片厂商在测试时可能只关注单一场景。而我们希望与他们合作，在我们的场景下发现问题，并支持整个智算过程。作为整机厂商，我们与上层的应用和下层的芯片都有关联。在系统方面有许多工作需要做，特别是在系统使能和优化方面。另外，为了使芯片能够更好地运行，类似于 CXL 的分层内存优化等技术也是必要的。这些技术需要系统层面的优化，以实现更好的性能。实际上，早在内存管理时期，就已经有了类似的优化概念。内存永远是不够的，因此我们需要系统层面的工作来更高效地使用内存。”苏志远总结道。</p><p>&nbsp;</p><p>在智算方面，单机训练只是基础，真正的挑战在于将所有机器连接起来进行训练。当处理动辄数百 T 的数据时，吞吐量和时延成为关键问题。系统层面需要对网络系统和 IO 读写进行优化，甚至需要利用最新的 SMC-RDMA 等技术来提升系统能力，以确保训练的效率和速度。</p><p>&nbsp;</p><p>除了集成层面的优化，将数据、调优和敏捷开发过程融合在一起也非常重要。此外，可观测性和运维能力也是关键因素。在 AI 应用中，由于容器化技术的普及，一台机器上可以轻松运行数百个容器。在数千台机器的规模下，如何有效地管理和监控这些容器成为了一个重要的系统层面的问题。</p><p>&nbsp;</p><p>总的来说，智算操作系统的核心在于解决如何在 System For AI 的框架下实现高效的使能、优化和集成。同时，可观测性和运维能力也是确保整个系统稳定、高效运行的关键因素。对于 System For AI，阿里云和浪潮信息等公司都在持续进行相关研究。这涉及到异构算力的调度、CPU 能力的最大化，以及模型的优化，使其更好地适应算力。这些研究不仅在社区中进行，而且得到了社区理事单位如阿里云和浪潮信息的支持。“坦率地说，这些研究可以使阿里云或浪潮信息的产品更具竞争力，因此我们会坚定地在这个领域继续探索。”马涛说道。</p>",
    "publish_time": "2024-01-02 14:17:40",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "皮衣老黄套路多！被抢破头的GPU，其实没有任何惊喜",
    "url": "https://www.infoq.cn/article/uUuzHWaU95vsg0ocGATx",
    "summary": "<p></p><blockquote>按投入产出比来计算，新一代 GPU 的性能几乎没有什么提升。</blockquote><p></p><p>&nbsp;</p><p>从诸多方面来看，2023年对于想要搭建游戏主机和商用工作站的用户们来说，终于回归了睽违已久的正常状态。在这一年中，大部分主流产品的售价开始持平甚至略低于官方建议零售价，人们终于能以相对合理的价格组装各类电脑，无需担心供不应求或者苦等理想的折扣。虽然总体上，2022年掀起的GPU需求浪潮在过去12个月中仍余波未平，但随着英伟达、AMD和英特尔等大厂新一代GPU的面世，买家已经大致可以按照预期价格拿到自己心仪的GPU。</p><p>&nbsp;</p><p>但与此同时，2023年对于GPU买家也实在是缺乏惊喜，甚至多少有点令人沮丧。GeForce RTX 4090和Radeon RX 7900系列显卡均抢在2022年末推出，整体性能超越上代全系产品。可2023年内发布的中端GPU却明显缺少野心，提供的不仅是与上代GPU持平的性能，而且价格也基本跟性能相信的上代GPU保持一致——换言之，在性价比方面压根没有变化。</p><p></p><h2>中端GPU前来拜访</h2><p></p><p>&nbsp;</p><p>并不是每年的中端GPU都能像当初的GTX 1060那样令人眼前一亮——这张卡比前代产品快了约50%，甚至能够一举击败上代卡皇GTX 980，而价格却仅略高于980的一半。哪怕我们尽量放低期待，2023年推出的中端GPU也没能给人留下深刻印象。</p><p>&nbsp;</p><p>其中表现最差的当数GeForce RTX 4060Ti，以同等价格论它甚至无法击败上代显卡。这款显卡的16 GB版本尤其令人诟病，不仅价格贵了100美元，而且只在少数几款游戏中表现出超越8&nbsp;GB版本的性能水平。</p><p>&nbsp;</p><p>普版RTX 4060的情况稍好一点，部分原因在于价格确实比上代RTX 3060普版下降了30美元。但4060同样性能提升很小，而且显存从12 GB下降到8&nbsp;GB也实在有违买家们的心理预期。只能说这仍然这是一款速度稍快、效率稍高且价格大致不变的显卡。AMD的Radeon RX 7600、RX 7700 XTG和RX 7800 XT也属于类似的情况——略有改进，但总体性能跟上代显卡相似，价格也保持一致或者稍作下调。对于那些因GPU老化或者GPU长期供应不足而迫切想要升级的买家们来说，这样的现状实在让人提不起兴趣。</p><p>&nbsp;</p><p>目前这一代最好的中端显卡可能要数GeForce RTX 4070（但其售价仍高达600美元，这也再次扩展了「中端」的定义），其性能已经能够媲美甚至略微超越上一代RTX 3080，而且不仅运行功率更低、价格也比RTX 3080的建议零售价低了100美元。考虑到RTX 3080在整个生命周期的大部分时间里都需要加价购买，所以4070的推出似乎是个好消息。但600美元的价格仍比当初同等定位的2070显卡增加了100美元，比1070贵出220美元，真是让人越想越气。</p><p>&nbsp;</p><p>总而言之，2023年应该是购买300美元级GPU的理想时机，毕竟这根“耻辱柱”归于2021年的GTX 1650，不知道屏幕前有多少买过这款“冤种”产品的受害者。不过考虑到GPU供应短缺的不断加剧，这些“稳定供应且基本够用的GPU”也算是完成了自己的历史使命。</p><p></p><h2>GPU营销越来越有误导性</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d7/d78814f639b32ee07d61355c147423fd.png\" /></p><p></p><p>如果大家关注英伟达此前针对这些GPU发布的性能声明，可能会误以为RTX 40系列显卡会带来令人兴奋的性能飞跃。</p><p>&nbsp;</p><p>但这些数字只有在支持这些GPU最新DLSS帧生成（FG）软件技术的游戏中才有可能实现。原始DLSS和DLSS 2是通过对GPU生成的图像进行采样来提高性能，即生成插值像素、将分辨率图像转换为高分辨率图像，而且这种简单的升级并不会造成画面模糊或者图像质量损失。具体来讲，DLSS FG能够在GPU渲染各帧之间生成新的完整帧，理论上无需强大的GPU即可大幅提升帧率。</p><p>&nbsp;</p><p>在能够发挥作用时，这项技术的效果确实令人印象深刻，而且其成功也让众多厂商开始在软件层面探索提升画面表现的类似办法。例如，AMD目前就支持FSR 3；英特尔也在早期尝试同样的替代性实现方案。但这种方式也有明显的局限性——具体来讲，其需要相当高的基础帧率才能提供足够的数据，借此生成令人信服的额外帧，而这一切在中端显卡上显然很难做到。即使性能良好，DLSS FG也有可能引入奇怪的视觉伪像或者导致精细细节的丢失。此外，该项技术在很多游戏中根本不可用。DLSS FG还额外增加了一点延迟，不过英伟达的Reflex等延迟控制技术能够很好地抵消这些影响。</p><p>&nbsp;</p><p>作为性能增强组合中的最新成员，DLSS FG确实表现不错。但如果将其与上一代显卡进行比较，充其量只能说其实际表现并不足以达成升级买家的乐观期待。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0e/0ef4e45d3047ade1094a33275b6be5e8.png\" /></p><p></p><p>英特尔Arc在上市第一年的表现，只能说是巩固了其“有意义的首次尝试”的地位。毕竟从当初刚发布时的情况看，最终结果完全有可能比现在更糟——当时Arc产品刚一面世就曝出驱动程序缺陷和性能不稳定等问题，对于较旧游戏的支持效果尤其差劲。</p><p>&nbsp;</p><p>但值得赞扬的是，英特尔在这一年间显著改进了软件设计、消除了bug、修复了种种恼人的问题，也提高了对较旧游戏的支持性能。芯片巨头在那些颇有年头的DirectX 9和DirectX 11游戏上取得了重大进展，而这依靠的是其代码转换技术，令这些陈旧API能够在DirectX 12及/或Vulkan、较新的低级图形API上获得更强的GPU处理能力。</p><p>&nbsp;</p><p>英特尔在价格层面也保持住了相对较强的竞争力，部分原因在于前文提到的英伟达和AMD中端GPU实在是乏善可陈。Arc A750的价格始终保持在200美元或以下，成为英伟达TK系列产品的有力对手。</p><p>&nbsp;</p><p>但英特尔未来会继续发掘GPU市场吗？至少就目前来看应该有戏，毕竟该公司仍在推进技术路线图，预计将在2024年之内为我们带来下一代“Battlemage”GPU。Arc技术和品牌也已被纳入英特尔的最新集成GPU产品当中。</p><p>&nbsp;</p><p>但必须承认，当前Arc GPU在性能和能效方面的仍完全落后于英伟达和AMD的产品，也就是说英特尔仍没有能力参与300美元以上GPU的市场竞争。过去一年间，英特尔图形部门的领导层发生了一些变动，芯片巨头似乎正急切想要摆脱那些无利可图的业务旁支（例如加密货币挖矿芯片以及NUC迷你台式机），希望借此改善自身财务状况。在Steam平台的硬件调查中，Arc卡也未能自立门庭，只能屈辱地被划归“其他”类别（但公平地讲，大多数AMD RX 7000系列GPU也同样属于这个部分）。</p><p>&nbsp;</p><p>如果说英特尔仍然只能销售利润有限的中、低端GPU芯片，那我们很难想象他们会愿意继续投入资源来开发和营销新一代GPU。2023年对于Arc来说是不错的一年，而最终如何发展就要看2024年这段关键的时间节点了。</p><p></p><h2>能效有所提升</h2><p></p><p>&nbsp;</p><p>虽然2023年新款GPU们的性能缺乏亮点，但也绝不是毫无优点，其中最大的进步就在能效层面。凭借这些更新、更加节能的制程工艺，哪怕性能上限未能进一步提升，买家也至少能够享受到更低的硬件运营功耗。</p><p>&nbsp;</p><p>其中表现最突出的当数英伟达的RTX 40系列显卡。以RTX 4070为例，其性能与RTX 3080非常相似，但功耗却只是RTX 3080的60%左右。在大多数情况下，RTX 4060虽然只比RTX 3060快15%到20%，但消耗的电量却是RTX 3060的三分之二左右。这无疑能够大大缓解这些GPU的运行冷却压力，我们甚至看到有厂商推出了相当好用的小尺寸和低冷却配置版本（当然，仍有不少GPU制造商在继续推出更具视觉冲击力、拥有巨大三风扇配置的过度冷却版本）。</p><p>&nbsp;</p><p>AMD的RX 7000系列在能效方面同样有所改进，只是幅度不像英伟达那么显著。不管怎么说，功耗和发热量的双重降低都是件好事。</p><p>&nbsp;</p><p>但如果向电脑游戏玩家们征求意义，询问他们到底想要更高的帧率还是更好的能效，相信大多数人还是会选择帧率。但作为长期热爱小尺寸袖珍ITX桌面设备的同学，我个人很高兴看到这些更强大的GPU能够被塞进比较狭小的机箱空间。</p><p></p><h2>出口管制导致高端GPU价格飙升</h2><p></p><p>&nbsp;</p><p>这一年中，大多数GPU买家已经不用担心供应或者涨价问题。但在过去几个月间，仍有一款显卡却仍然保持着臭名昭著的加价销售恶习，这就是GeForce RTX 4090。Newegg和亚马逊目前库存中最便宜的4090版本起售价约为2000美元，比官方建议零售价高出了400美元。</p><p>&nbsp;</p><p>这当然不是因为大量游戏玩家突然想要购买这款比多数人游戏PC整机还要贵的GPU。真正的罪魁祸首恐怕在于新的出口管制政策——美方表示从2030年11月中旬开始，4090显卡将不再面向中国市场销售。作为一系列不断升级的限制措施中的最新规定，这纸禁令也影响到大部分英伟达服务器GPU。于是中国买家开始大量囤积4090显卡，据说英伟达也抢在禁令生效之前尽可能向中国市场投入4090，导致其他市场的显卡供应量捉襟见肘（至少暂时吃紧）。</p><p>&nbsp;</p><p>4090显卡之所以在中国大受欢迎，原因之一同样跟出口管制有关——英伟达用于AI服务器的Tensor Core GPU同样被禁止供应中国市场，这促使中方不少企业将4090 GPU重新封装成带有双槽冷却器的AI加速器，用以充当性能密度更高的商用AI产品。</p><p>&nbsp;</p><p>随着市场适应新的出口管制政策，加上供需关系逐渐松动，相信这波显卡涨价也将归于平静。据说英伟达还准备对不少现有4080和4070系列GPU进行一波“超级”更新，这样的小改款可能会进一步扰乱高端显卡的定价。总而言之，目前恐怕并不是购买4090的理想时机。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://arstechnica.com/gadgets/2023/12/2023-was-the-year-that-gpus-stood-still/\">https://arstechnica.com/gadgets/2023/12/2023-was-the-year-that-gpus-stood-still/</a>\"</p><p>&nbsp;</p>",
    "publish_time": "2024-01-02 14:27:13",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从数据平台建设看华夏理财的数字化实践",
    "url": "https://www.infoq.cn/article/yo4HIY9cwcmKfSDWjlJw",
    "summary": "<p>2018 年，资管新规颁发，2022 年，资管新规正式实施，众多银行理财子公司纷纷应运而生。其中，华夏理财有限责任公司（以下简称“<a href=\"https://www.hxwm.com.cn/\">华夏理财</a>\"”）是首批“种子”之一，2020 年 9 月正式在北京开业，由华夏银行全资控股。</p><p></p><p>从外部来看，旧格局被打破，一个“新世界”正在建立。从内部看，银行“稳健型”资产管理产品成为“过去式”，净值化产品成为主流。除了要让市场教育的“子弹”飞一会儿，这也要求以华夏理财为代表的银行理财子公司必须不断优化自身的产品策略，提高保护投资者权益的能力。</p><p></p><p>在华夏理财看来，多元化资产配置是获得绝对收益的直接有效方式。但多元化资产管理，依赖于精细化手段的加持。</p><p></p><p>因此，华夏理财在成立之初就快速明确了“打造优质理财工厂”的规模化经营模式，实现从投研引领、信评保障、交易支持、策略生产、资产创设到产品组装的全流程精细化管理，最终形成标准化的理财产品输出。时至今日，华夏理财发行管理的理财产品已经超 600 只，规模超过 6000 亿元。</p><p></p><p>在这个过程中，华夏理财强调每一只产品都必须是经得起客户、市场检验的“良品”。为此，近几年来，华夏理财加紧推进数字化转型，通过<a href=\"https://www.infoq.cn/article/4kCbbGuk6si8fiy8hfqi\">金融科技</a>\"的应用落地，不断提高产品营销、投资、风控、运营、客户服务等方面的能力。在组织架构层面，华夏理财还特别内设了独立的金融科技板块和部门，作为公司数字化转型的“科技中台”，配合具体战略的落地实施。</p><p></p><p>日前，InfoQ 对华夏理财金融科技部负责人王斌进行了专访，他以数据平台的建设历程为“缩影”，介绍了华夏理财如何通过数字化转型，从过去靠“拍脑门”和经验累积的决策模式，逐步转向由数据驱动的精细化管理模式，进而塑造自身在“大资管”时代的差异化竞争力。</p><p></p><h2>避免“一口吃成胖子”</h2><p></p><p></p><p>“总结华夏理财的数字化转型思路和策略，我们强调，既要面向未来又要脚踏实地，既要大处着眼又要小处着手；战略上要做好顶层规划、明确路径，在战术上要实现敏捷交付、快速响应和稳健推进。”王斌表示。</p><p></p><p>一言蔽之，要避免“一口吃成胖子”。</p><p></p><p>以投资和风险管理平台建设为例，华夏理财结合业务需求对功能进行逐步拆解和推进：首先，把投资交易系统的功能按照 PMS（Portfolio Management System，组合管理系统）、OMS（Order Management System，指令管理系统）以及 EMS（Execution Management System，执行管理系统）三部分进行拆分。</p><p></p><p>鉴于有限的资源，华夏理财最开始优先把精力集中在 OMS 和 EMS 部分的潜力挖掘上。鉴于理财投资业务的行业现状，华夏理财主要通过资管计划的形式进行债权投资。这也带来了交易流水、估值数据的断点，需要由资管计划管理人提供交易流水、估值表数据，提升了华夏理财自身的投资数据完整性。</p><p></p><p>在夯实了数据基础之后，华夏理财开始逐步构建自身的交易生态。但是，在这个过程中，华夏理财没有一步到位构建一个实时平台，而是基于现有的数据中台，构建了离线的投资数据仓库，通过对离线数据的处理，先提供 T+1 的组合分析支持，再逐步过渡到湖仓一体数据平台上，提供实时 T+0 的数据支持。</p><p></p><p>锚定清晰的目标和循序渐进的路径，如今，华夏理财已经建立了面向风险管理、投资交易、营销、监管报送等场景的数据集市，“以用促建”实现了对各业务的赋能。举例来说：</p><p></p><p>在风险管理场景，风控人员可以通过全面、详实且高质量的投资数据，如底层持仓、成本收益、收益波动率、胜率赔率等指标，在开市前掌握所管理产品组合的表现和持仓情况，从而制定产品的下一步投资策略。并且，平台还可以对华夏理财的 600 多只产品进行合规检测，把所有监管指标及内控指标进行准确且及时的合规演算和对照，每日提供给投资经理，帮助他们判断哪些产品触发了超标预警，或者哪些指标已经逼近监管上限，进而及时做出整改，或者进行投资策略调整，提升合规监测水平。</p><p></p><p>在投资交易场景，基于数据平台上的日初头寸报表功能，平台可以预测在未来 N 天之内，投资经理每天可用的资金头寸情况，据此安排资金使用，以及判断是否需要进行回购融资。据了解，华夏理财对投资经理的考核是多维度的，不是简单的收益率、净值增长的考核，还包括诸如波动率、最大回撤、业绩基准达标率等方面的考核。从这一角度来看，日初头寸报表功能一方面可以帮助投资经理实现投资效益最大化，同时，还可以帮助其提高投资准确性，减少由于融资或其他成本叠加带来的风险。</p><p></p><p>在营销场景，数据平台可以提供负债端所有产品的销售情况，包括哪些产品已经到期、需要接续，客户数目、资产规模如何变化，以及通过产品销售情况多维度分析，结合产品标签，匹配产品发行和客户的真实理财需求，平台都可以及时提供。</p><p></p><p>在监管报送场景，过去华夏理财的监管报表独立在数据中台之外，数据质量参差不齐，如今，基于统一数据平台，华夏理财不仅有效提升了报送质量，同时能够确保在要求时间内完成报送，其中，数据平台提供的数据完整性、准确性、及时性在背后发挥了重要作用。</p><p></p><h2>数据平台选型：“量体裁衣”且可扩展</h2><p></p><p></p><p>可以说，<a href=\"https://www.infoq.cn/article/gCQGEgWrVX4PMNP1ohOJ?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">数据平台的建设</a>\"对于华夏理财的业务发展和转型起到了至关重要的作用，使得公司从过去的“经验主义”，真正迈向了数据驱动，为精细化管理构建了基石和底座。</p><p></p><p>在谈及华夏理财数据平台的独特之处时，王斌强调了两点：</p><p></p><p>其一，华夏理财结合自身业务需求构建了一个“好用”的数据模型，对持仓收益、资产负债等方面的信息做到了全面描述。在此基础上，实现了对数据的统一采集、存储、加工以及数据质量的管控，满足了华夏理财底层资产穿透的需求。</p><p></p><p>所谓底层资产穿透，指的对资管计划等资产，穿透到底层资产进行管理，从而对底层资产的持仓构成、资金流向和流动性风险可以进行更深入和实时的掌握。面对不同资产方提供的估值表格式不一致问题，华夏理财基于数据平台对数据进行了标准化加工，使其资产底层数据的准确性和全面性有了充分保障。</p><p></p><p>其二，华夏理财深知，<a href=\"https://www.infoq.cn/article/fC0VKxtiIoH096FrfD3U?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">数据治理</a>\"不仅仅是一个技术问题，更是一个管理问题。为此，华夏理财通过与网易数帆合作，在数据平台之上搭建了一个主数据管理系统，建立了覆盖产品主数据、客户主数据、机构主数据、非标资产主数据等各个维度的主数据体系。</p><p></p><p>“这使得技术部门对主数据认知越来越清晰，在数据平台建设中也形成了非常多的数据治理要求，并且能够把数据治理动作和整个数据平台建设过程紧密结合在一起，实现数据标准化和规范化管理。”</p><p></p><p>从行业洞察角度来看，<a href=\"https://www.infoq.cn/article/meeeB9zuSwEguCUPtYg9?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">网易数帆</a>\"拥有丰富的大数据处理以及同业案例实施经验；从技术层面来看，网易数帆可以提供一站式的大数据解决方案，这能让华夏理财技术人员可以放心把基础架构铺设的工作交给对方，而把更多精力集中在应用建设的工作中。</p><p></p><p>华夏理财与网易数帆的合作始于 2020 年，在技术选型过程中，公司的主要考虑因素包括以下五个方面：第一，数据处理能力，能够满足大规模数据存储和快速查询要求；第二，具有较好的扩展性，能够适应后续的业务规模发展需要；第三，技术成熟稳定，有较好的应用环境和运行效果；第四，安全性，能够快速识别和修补安全漏洞，安全能力持续提升；第五，合适的性价比。</p><p></p><p>“对于华夏理财这种体量和规模的企业来说，我们需要 ‘量体裁衣’，寻求一个调度和使用没那么复杂的产品，而网易数帆的技术路线、产品形态恰恰符合和匹配我们需求。”王斌告诉 InfoQ。</p><p></p><p>业务的实践验证了这一思路的合理性和必要性。来自网易数帆数据开发治理平台 EasyData 的开发治理一体化、统一数据模型等功能设计，以及经过诸多金融细分场景打磨的产品能力，提升了数据产出的质量和效率，使得前述风险管理、投资交易、营销、监管报送等场景的用数需求得到了快速满足。</p><p></p><p>王斌认为，华夏理财数据中台能力达到了行业领先水平。而网易数帆产品团队对产品平台的长远规划和对行业需求的认真倾听，让王斌对双方合作前景充满了更多的期待。</p><p></p><h2>让技术人员“到一线去”</h2><p></p><p></p><p>选型思路清晰，成果肉眼可见，但平台的建设和价值挖掘的过程，仍然充满挑战。</p><p></p><p>王斌表示，与业务的结合，是金融科技部门在数据平台建设和实际应用过程中面临的最大难题。“平台不能为了建而建，但要真正把数据变成资产，和业务的结合非常重要。技术人员的知识和能力在这个过程中需要不断提升，比如对会计科目体系的认知，对不同投资阶段数据的差异化价值的认知，对投资经理如何使用数据的认知等等，都需要随着工作的开展不断深化。”</p><p></p><p>“到一线去”，是华夏理财帮助技术人员提升业务感知的办法之一。</p><p></p><p>通过把不同组别的技术人员放到业务环境中，让彼此打成一片，加强对彼此工作内容的学习和理解。在华夏理财看来，虽然在企业<a href=\"https://www.infoq.cn/article/e2I9pGCU2A633B1sJGxZ\">数字化转型</a>\"过程中，技术扮演者关键的驱动角色，但是，“主角”仍然是业务。因此，金融科技部门要求每一个技术人员都能够站在业务视角推演每一个系统功能特点和用户习惯。</p><p></p><p>与此同时，金融科技部门还尤为重视培养团队对需求的甄别能力和产品思维。</p><p></p><p>在华夏理财，每两周会组织一次需求评审，由技术人员向业务部门进行需求“反讲”。一方面，检验技术人员对业务的理解程度和准确性；另一方面，双方还可以在这个过程中重新审视、共同评估需求的合理性。</p><p></p><p>“我们认为，每一位技术人员都要具备产品能力，而对需求的理解，是决定一个产品能否成功的重要前提。这是我们去做这件事的初衷。”王斌向 InfoQ 解释道。在此基础上，绩效层面的引导，也是关键一步。“技术部门实施的项目，会由业务部门进行打分。未来，我们还会进一步落实 ITBP 制度，多管齐下地促进业技双方的融合。”</p><p></p><p>知识鸿沟之外，数据安全和隐私保护，是企业在数据平台建设过程中普遍遇到的另一个棘手问题。对此，华夏理财主要从以下三方面入手：</p><p></p><p>第一，全方位的制度建设。根据监管要求和总行统一规定，结合华夏理财自身业务特点，围绕数据安全和隐私保护问题建设相关制度，敦促所有人员遵照执行。</p><p></p><p>第二，数据全生命周期的安全和隐私考虑。在数据存储、加工、流转、访问甚至是销毁的每一个环节，进行安全的通盘考虑，确保做好每一个细节，在数据应用过程中，从需求分析、设计、测试到验收都要遵照相关制度，注重对隐私数据的保护。</p><p></p><p>第三，配备专门的安全人员。公司层面通过合规部、审计部等部门，站在第三方的角度，定期进行现场检查，发现问题，及时处理和解决。</p><p></p><h2>新技术将带来更多机会</h2><p></p><p></p><p>虽然正式成立仅 3 年时间，但是站在<a href=\"https://www.infoq.cn/article/GItTCDMzzSsxMcojWydF\">银行业</a>\"的“巨人肩膀”上，华夏理财对于前沿技术有着天生的洞见和感知。在过去这几年时间里，华夏理财已经完成了大部分的数字基建工作，技术和数据基础逐步完善向好。而对于未来，华夏理财同样有着清晰的思路和规划。</p><p></p><p>“我觉得，GPT 时代的到来，将给我们带来更多的机会，它将使得投研平台建设和投资服务的方式发生本质改变。”</p><p></p><p>比如，在投研场景，过去需要对标地实体进行充分调研，从宏观、中观到微观找出与之关联的所有信息，然后整理成可供分析参考的结构化数据。而结合 AIGC 应用，就可以把各个维度的海量非结构化数据输入到模型中进行训练，然后直接提供给投研人员做参考。</p><p></p><p>比如，在客服场景，过去，客服人员在与客户交互中需要掌握大量产品介绍、交易规则、实时投资收益等信息数据，对人员要求极高。而基于大模型，就能构建公司内部知识库，将成百上千不同类型和内容的文档组织在一起，从而赋能员工。</p><p></p><p>再比如，在数据录入场景，其中涉及非常复杂的合同文本以及背后的相关性，某个文档的条款可能对应着其它文档的相应支持条款，对于人工而言，这不仅是巨大工作量，而且容易出现错漏。AIGC 和大模型的应用，可以辅助数据录入人员从中提炼出结构化的数据，甚至作为智能工具直接完成整个数据录入工作。</p><p>为了把这些“想法”变成“现实”，可以看到，华夏理财已经开启大模型应用的研究。</p><p></p><p>“在应用方面，很多业务部门也提出了不少具象的需求。”王斌强调，“当然，可能不是面面俱到，而是先从智能客服等典型场景切入，在取得降本增效、客户体验提升等可视化成果之后，再慢慢实现规模化的应用拓展。”</p><p></p><p>不难看出，这一思路背后，同样是华夏理财“既面向未来又脚踏实地，既从大处着眼又从小处着手”的数字化理念的又一体现和延续。</p><p></p><h2>数字化转型的不同“横切面”</h2><p></p><p></p><p>据王斌介绍，华夏理财的数字化转型未来主要围绕以下几个方面展开：</p><p></p><p>第一，在产品层面，以客户为中心搭建产品、营销、客服一体化平台，通过建立统一的理财客户视图和分类，实现客户分级和智能投顾，支持“理财工厂”的产品设计、发行、运作以及退出全生命周期管理。同时，面向 TA、估值核算等基础系统提供敏捷支持。举例来说，当代销渠道新增时，能够快速上线，快速支持产品的调整。</p><p></p><p>第二，在投资和风险能力提升层面，首当其冲先解决系统间的烟囱问题，通过建立流程统一、数据统一、系统统一的投资管理和风险管理平台，支持各种不同类型的金融产品和跨市场的投资管理。这意味着，该平台要具有统一指令流程、集中化交易、风险监控无处不在和投研支持随手可得等特点，同时基于自动化技术手段，还能够提高资金效率和交易处理能力。</p><p></p><p>值得一提的是，华夏理财尝试把合规规则和<a href=\"https://www.infoq.cn/article/2J7bFWYuhBcJ01K04tLd\">风险试算</a>\"嵌入在了投资交易过程中，将传统基于规则的风险管理方式转变为定量的风险预警和决策，通过数据驱动提升全面风险识别能力。</p><p></p><p>比如，在每一步指令下达时，都可以进行风险指标的试算，提供相关资产组合实时的业绩计算和归因结果。“通过理财投资管理向组合化和多维度分析的方向转变，可以实现投资研究、资产配置、组合管理、指令交易和风险试算的一体化。”王斌指出，这不但大大提高了投资经理的工作效率，还能抹平由于个人能力造成的差异，通过资产配置可以对投资业绩进行平稳化处理。</p><p></p><p>第三，在运营层面，通过建立标准化、自动化、高效的运营平台，对所有运营操作进行统一管控，提高运营体系效率，降低运营操作风险。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/e2/ca/e205602269fc52b1557a8c4a4e7b91ca.png\" /></p><p></p>",
    "publish_time": "2024-01-02 15:34:34",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "大模型时代，我们可以用 Julia 做什么？| 年度技术盘点与展望",
    "url": "https://www.infoq.cn/article/BrtGN23K5fzhoG9tzSRC",
    "summary": "<p></p><p><img src=\"https://static001.geekbang.org/infoq/cb/cb999af17df70cd30d1724d9b1ea4107.jpeg\" /></p><p></p><p>从 ChatGPT 发布以来，大家对大模型相关生态的关注急剧上升，本人也在过去的一段时间里深度参与了大模型相关的一些基础工作。众所周知，目前围绕大模型相关的开发仍然以 Python 编程语言为主，作为一个 Julia 编程语言爱好者，我一直在思考的一个问题是，大模型时代我们可以用 Julia 做什么？</p><p></p><p>本文是 “2023 InfoQ 年度技术盘点与展望” 系列文章之一，笔者将结合自己在大模型领域的开发经验和对 Julia 生态的理解，尝试从两个不同的角度来回答上述问题。首先，我们将大模型研发的过程拆解开来，逐点分析目前已有的做法和面临的挑战，探讨 Julia 在该方向上落地的潜在可能性；然后纵览 Julia 以及一些其它编程语言中大模型相关开发的生态，试图找出一条更适合 Julia 编程语言的发展道路。</p><p></p><h2>训练基座模型</h2><p></p><p></p><p>基座模型的训练所面临的挑战在于，超大规模的参数量。目前主流开源的模型参数量都在数十亿、数百亿乃至数千亿的规模。想要高效地训练如此大参数量的模型并非易事，目前开源界主流的训练框架是 ++Megatron-LM++，在其之上还有一些其它工具库提供开箱即用的训练脚本。Megatron 的核心功能主要包括：Tensor Parallel（TP）、Data Parallel（DP）、Pipeline Parallel（PP）等。</p><p></p><p>TensorParallel 要解决的核心问题是，如何在单卡无法放入整个 Tensor 的情况下，高效地做 Tensor 之间的计算。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/35/35a56c32cf6adcc9e3577e41d815456c.png\" /></p><p>来源：<a href=\"https://colossalai.org/docs/concepts/paradigms_of_parallelism/#tensor-parallel\">https://colossalai.org/docs/concepts/paradigms_of_parallelism/#tensor-parallel</a>\"</p><p></p><p>以矩阵相乘（A x B）为例，目前已有的做法是，将其中一个矩阵 B 拆分到不同的 GPU 卡上，然后执行分块矩阵的计算，最后合并计算结果。</p><p></p><p>在 Julia 语言中，类似的需求可以通过 DistributedArrays.jl 来实现，其封装好了一个 DArray 类型的结构，底层不同 worker 可以独立并行地做计算。</p><p></p><p><code lang=\"makefile\">```julia\nusing DistributedArrays\nA = rand(1:100, (100,100))\nDA = distribute(A, procs = [1, 2], dist = [1,2])\n</code></p><p></p><p>不过遗憾的是，该软件包并不支持 GPU 上的操作。在 Python 这边，GPU 上的通信操作通常依赖于 NCCL 的实现，首先需要执行类似 broadcast 的操作将 A 矩阵分配到各个节点上，完成计算后执行 all-gather 的操作将计算结果同步到每个节点。尽管目前在 CUDA.jl 的文档中有提到，如果想要实现单机多卡或者多级多卡之间的通信，可以借助一些基于 GPU 的 MPI 的实现，但目前仍缺少一些相关的实践。此外，另外一条可行的路径是，借助 Yggdrasial 中封装的 NCCL library，直接做多机多卡之间的通信，不论是基于 Distributed.jl &nbsp;来实现还是独立再封装，具体实现上仍有不少工作，理想情况下，该工具库可以提供类似 torch.Distributed 的功能。</p><p></p><p>DP 的核心是将多份数据同时应用到模型的多个副本上，从而提升训练期间模型的吞吐量，缩短训练周期。该过程最核心的挑战在于降低同步多个副本之间参数的通信量。在 Megatron 中，有一系列工作来优化该步骤，其中最核心的一个组件是 DistributedOptimizer 。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8c/8cea2cd8154144b5075b3c09727bcd44.png\" /></p><p></p><p>简单来讲，将 Optimizer 本身的参数，以及模型本身的参数和梯度等切分到不同的节点，再按需进行同步，可以大大降低模型优化过程中的通信成本。实现该优化器本身的难度并不大，但其前置条件（高效易用的 NCCL 实现）却是最大的障碍点。</p><p></p><p>值得一提的是，近来在 Flux.jl 之外，又多了一个 Lux.jl 选择，相比之下，其宣称的最大不同点在于“显式参数化”，在分布式优化场景下，这种特性具有其特殊的现实意义，即将参数展开之后，可以很容易地实现分片操作以及多机多卡之间的高效通信。</p><p></p><h2>Fused Kernel</h2><p></p><p></p><p>此外，在预训练（以及推理阶段），常见的一个优化手段是将几个算子做聚合，降低额外的显存开销并提升计算速度。最广为人知的是 Flash Attention 的实现，采用 C++ 显著地提升了 scaled dot production attention 的计算，然后通过 binding 提供给 Python 用户。在 Julia 这边，通常类似的操作我们会选择用 CUDA.jl 来实现，其优势在于一种语言即可完整地实现整个需求。对于一般的使用场景而言，确实如此。但在 Flash Attention 这类场景中，想要用纯 Julia 来实现出和 C++ 类似的效果，却是一件并不容易的事情，其原因在于，一方面，CUDA.jl 支持的指令落后一些，导致需要手动插入类似异步拷贝、扩展 WMMA 指令等操作，另一方面，细粒度优化导致最终实现出来的代码和 C++ 版的复杂度差异不大。不过，未来一个值得尝试的方向是，可以集成类似 OpenAI Triton 这类库，然后将 Python 或 Julia 作为前端语言，进一步优化此类操作的门槛。</p><p></p><h2>混合精度计算</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/17/17fc3116e7a6447a515a4cabee1e929c.png\" /></p><p></p><p>来源：https://developer.nvidia.com/blog/accelerating-ai-training-with-tf32-tensor-cores/</p><p></p><p>为了降低显存的占用，提升计算效率，模型的权重、前向后向计算部分一般采用半精度的格式，而优化器的计算则会采用全精度。遗憾的是，在 Julia 这边想要实现混合精度的计算目前还是比较困难的一件事。类似 BF16/FP8 的支持还未实现，而想要使用该功能仍需等待 CUDA.jl 中的实现。</p><p></p><h2>指令微调</h2><p></p><p></p><p>从语言支持层面来讲，微调部分并没有引入额外的复杂度。目前指令微调的常见做法包括 SFT、DPO、RLHF 等，其中较为复杂的部分一环是 RLHF，完整的 RLHF 训练通常涉及到 4 个不同的模型组件之间协同操作，其最大的难点在于管理好多个模型在多机多卡上的调度以及相互之间训练数据的同步。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/20/20f0fab7f6d67243330005f984ee9338.png\" /></p><p></p><p>来源：https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/rlhf/rlhf.png</p><p></p><p>目前主流支持 RLHF 的库主要基于 Ray 来实现，借助 Ray 的资源调度能力和 Actor 之间高效的通信机制，可以在 Ray 之上实现大模型的微调。在 Julia 这边，单机版的 RL 算法（如 PPO 等）已经在 ReinforcementLeaning.jl &nbsp;中有实现，但想要扩展到多机的版本仍有不少工作，其主要的工作量在于多节点之间的高效通信，若 NCCL 能与 Distributed.jl 完美集成，则分布式版 RLHF 的实现难度会大大降低。此外，为了降低训练期间对 GPU 资源的占用，有一些 PEFT (Permeter Efficient Fine-Tuning) 的相关工作也值得关注。</p><p></p><h2>量化与部署</h2><p></p><p></p><p>在量化方面，主流的两种算法是 GPTQ 和 AWQ。抛开其具体的实现细节，一个值得关注的点是，其高效实现仍有赖于底层 CUDA kernel 的实现。一方面，对已有模型的量化压缩是一次性的工作（除了一些在训练过程中做量化压缩的算法以外），另一方面，此类 CUDA kernel 的实现并非简单调用 CUDA.jl 即可完成，需要对底层指令有比较详细的了解，对于 Julia 开发者而言，并没有太多动力去从事相关的研发。</p><p></p><p>在部署方面，目前的主流仍然是 vllm ，想要在其它编程语言中想要完整实现类似的功能模块，会遇到和量化一样的困难。不过由于在私有化部署过程中往往在这块有一些个性化的需求，因此其它编程语言的开发者仍然有足够的动力通过对底层的 C++ 进行二次封装之后，在上层提供服务。</p><p></p><h2>应&nbsp; &nbsp; 用</h2><p></p><p></p><p>目前围绕大模型的应用层出不穷，从底层软件开发的角度来看，主要有两类，一类是围绕 Prompt 的实践，另一类是围绕大模型本地化部署及应用。</p><p></p><p>对于围绕 Prompt 的应用而言，其对编程语言的要求较低，更多地属于通用编程领域范畴。以 Python 中比较流行的库 LangChain 为例，其内置支持的多种复杂场景下使用大语言模型的基础工具库，对于 Julia 编程语言而言，由于其相关生态仍然有限，目前的主流的做法是通过类似 PythonCall 的工具库来实现调用。</p><p></p><p>此外，一个值得关注的细分领域是 Retrieval Augmented Generation，其核心在于借助向量检索等工具扩展上下文，主流的做法是将知识信息以向量的形式，存储到向量检索数据库中。Julia 在这一块有一些不错的向量检索工具库（如 SimilaritySearch.jl、HNSW.jl 等），虽然距离一个成熟的数据库还有一定距离，但仍然非常有潜力形成一套端到端的系统。</p><p></p><p>在大模型部署方面， Julia 对 GGML/GGUF 等格式的支持仍然有限，而这也进一步限制了桌面端应用的相关开发。目前，基于 Llama2 的架构，有一些不错的尝试，如 https://github.com/cafaxo/Llama2.jl&nbsp;，对于个人开发者而言，是一个不错的起点来尝试和理解 Llama 架构。</p><p></p><p>此外，如果想要实际开发和接入目前 HuggingFace 上已有的大模型生态，则推荐大家基于 Transformers.jl &nbsp;进行开发，目前这块经过多次迭代，已经能很好地支持一些主流的大语言模型，包括从 HuggingFace 的 load 和 save，本地的训练推理以及微调等。对于中小尺寸的模型，已经可以比较方便地利用其做一些原生的 Julia 相关应用开发。</p><p></p><h2>其它编程语言中大模型相关生态</h2><p></p><p></p><p>在主流的 Python 编程语言之外，目前发展较好的是 Rust，从最早基于 Rust 实现的 Tokenizer，再到近来有 HuggingFace 光环加持的 candle 等库，逐步涵盖了训练、推理、量化和部署等完整链路，可以看到其相关生态正在逐步形成。其整个链路对于 Julia 社区有很强的借鉴意义，即先从推理入手，然后丰富单机多卡的训练微调等任务，再在其之上构建完整的应用体系。</p><p></p><p>其它编程语言的生态目前主要以本地化部署和 Prompt Engineering 为主，比如由 Go 语言实现的工具 Ollama (https://github.com/jmorganca/ollama) 以及 LocalAI (https://github.com/mudler/LocalAI)，凭借其易用性收获了大量的开发者和用户；以及 LocalAI (https://github.com/mudler/LocalAI)，主打本地化部署，实现 OpenAI 的私有化平替；再如 Elixir 语言编写的 LangChain 类的工具 https://github.com/brainlid/langchain，提供 Elixir 语言下的大模型工具集成。</p><p></p><h2>结论与展望</h2><p></p><p></p><p>以下是本人在大模型领域观察到的一些趋势和预判：</p><p>在预训练领域，模型的结构越来越趋于统一，这主要是因为模型的探索成本较高。这对于其它小众编程语言而言，是一个利好消息，因为对于维护者而言可以重点支持某些特定的架构。AutoTrain &nbsp;等类似的工具会大幅降低微调大模型的门槛，成熟的算法会逐步沉淀到工具库中，而终端用户仅需关注数据层面。基于纯 Julia 来实现完整的大模型训练还有很长的路要走，这一点可以参考 JAX 目前的发展，尽管 JAX 的生态已经要比 Julia 好很多，但目前在开源界仍然缺少成熟的应用。基于纯 Julia 实现的应用层软件相比其它编程语言并没有压倒性优势，更需要关注如何与 Julia 领域已有的科学计算生态打通。对于 Julia 编程语言爱好者而言，更务实的路线是，用好大模型（推理、部署） -&gt; 改造大模型（微调） -&gt; 训练大模型。Christopher 最近的一篇 blog 里通过详细的例子介绍了 ChatGPT 在许多编程问题上 Julia 的效果都明显好于其它语言，而我本人也在从事训练更好的 Julia 专用模型，期待后续能有更多内容可以和大家分享。</p><p></p><h4>作者介绍：</h4><p></p><p></p><p>田俊，Julia 编程语言爱好者，目前在零一万物从事大模型基础架构方面的工作</p><p></p><p>如果你觉得本文对你有帮助，或者你对编程语言在大模型时代的发展有自己的思考，欢迎在文末留言告诉我们！</p><p></p><p></p><blockquote>InfoQ 2023 年度技术盘点与展望专题重磅上线！与 50+ 头部专家深度对话，探明 AIGC 创新浪潮下，重点领域技术演进脉络和行业落地思路，点击<a href=\"https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MjM5MDE0Mjc4MA==&amp;action=getalbum&amp;album_id=2717978015128879106&amp;scene=173&amp;subscene=227&amp;sessionid=1704178990&amp;enterid=1704178995&amp;from_msgid=2651192070&amp;from_itemidx=2&amp;count=3&amp;nolastread=1#wechat_redirect\">订阅</a>\"/<a href=\"https://www.infoq.cn/theme/229\">收藏</a>\"内容专题，更多精彩文章持续更新 ing~另，InfoQ 年度展望系列直播将于 2024 年 1 月 2 日首场开播，持续输出精彩内容，关注 InfoQ 视频号，与行业技术大牛连麦~</blockquote><p></p>",
    "publish_time": "2024-01-02 15:47:43",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "自动化识别业务风险，微财业务趋势感知平台Sparta的探索与实践",
    "url": "https://www.infoq.cn/article/rHsVAf2MS4kwNFNSaR5J",
    "summary": "<p>本文主要介绍好分期自主研发的业务趋势感知平台-Sparta。系统的设计目标是通过对业务数据的监控提升好分期的线上问题的感知能力，快速发现和解决线上异常问题，此外还可以通过自动化数据分析能力以及可视化能力及时发现线上业务瓶颈、潜在风险和改进依据，以帮助好分期进一步提升业务效率和服务质量。内容主要包含应用背景、方案设计、最佳实践以及部分代表性的问题的突破等，希望通过本文的分享，为有相关诉求的团队提供一定的思路参考。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/15/151b781ee4ec44d07fc3bfc1591f519c.png\" /></p><p></p><h2>1．概述</h2><p></p><p></p><p>微服务架构下，开发团队根据业务属性进行拆分，并将系统划分为多个独立的微服务模块，这种拆分可以提高开发团队的自治性和灵活性，还能够实现系统的可伸缩性，从而提高整体系统的性能和容量。然而，微服务架构下的这种拆分方式也带来了一些新的挑战。由于每个微服务都有明确定义的边界，并由独立的团队负责，各个团队往往倾向于建立与其负责系统相关的监控指标。这样做可以确保每个团队对自己的服务有充分的了解和掌控，但也导致了上下游服务之间的监控数据难以串联。当系统出现异常或性能问题时，仅仅依靠单个微服务的监控数据往往无法确定问题的根源。这时需要将涉及的多个微服务的监控数据进行综合分析，才能全面了解系统的整体状态并定位问题。然而，由于各个微服务之间的差异化监控，使得串联分析变得异加困难。</p><p></p><p>同时，对于很多企业的线上业务是具备一定趋势变化规律的，那么如何在实点数据（用户使用量、短信触达量、app点击量等）与历史一段时间样本数据同时点对比出现差异时主动进行预警发现，针对业务突发变化时做到主动预警，排除潜在的业务风险？单纯的依靠系统报警等，无法对差异变化进行判断。随着企业线上业务开展的规模和复杂性不断增加，单纯依靠人工分析和报警往往无法及时发现和应对业务风险。</p><p></p><p>为了解决以上两大核心问题，好分期自主研发了业务趋势感知平台-Sparta。Sparta采用了代码零侵入的监控数据源上报的设计思想，将常用数据组件进行了兼容打通，并且支持三方定制化数据接入，通过post协议将异常数据进行推送收集。通过通用化数据源的接入，基本覆盖了企业的常用系统数据存储组件，降低了使用人员的接入成本，提升监控服务的通用性和易用性以及监控的覆盖范围。</p><p></p><p>Sparta通过收集数据后，提供数据可视化监控能力供使用者可以轻易的找到业务数据的变化规律，为运营和用户行为分析提供数据参考；并通过算法排除干扰因素，生成历史样本指标，同时以样本指标为基准实时计算采集的数据偏移量，当业务数据的变化偏移量持续超出或者低于阈值时，通过多样性的报警通知方式相关的技术、运营人员。&nbsp;</p><p>&nbsp;</p><p>以下为业务数据激增、骤降异常场景的实时数据可视化能力展示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/80/800eaa60372d5168f106c78bf053307a.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ee/ee25ea71d33d873cf5dbeeb7396740a2.png\" /></p><p></p><h2>2．Sparta在好分期的应用背景</h2><p></p><p></p><p>我们选择自研Sparta业务数据监控系统有以下几方面的考虑：</p><p></p><h3>2.1.业务监控项过于分散，无法串联分析问题</h3><p></p><p></p><p>好分期在Sparta应用之前，已有的监控系统支持对系统软硬件环境多维度全方面的指标监控，如CPU负载、磁盘使用率、内存使用率、网络流量、服务运行状态等指标，但是各个职能系统的监控相互隔离，而且监控维度、方式、数据不统一，无法进行关联分析，出现问题时，经常需要各个部门参与才能定位问题。为了提升公司的整体问题发现能力，需要一套快速接入的统一监控平台，能通过异常指标相互关联，将不同系统的相同业务指标进行级联分析、溯源。</p><p></p><h3>2.2.缺少直观实时数据参考，业务变化无法感知</h3><p></p><p></p><p>好分期在Sparta应用之前，因缺少历史样本对比机制，无法及时了解业务数据的变化差异，很难发现潜在的线上问题。例如：某个系统模块发生问题时可能会产生业务指标的变化，或是合作方因为调整内部策略，导致业务指标拒绝率/通过率激增等；并且没有直观实时的数据参考和历史样本的偏差比对分析，企业无法在第一时间感知到这种非阻塞问题带来的影响，延长了该类问题的持续时间。</p><p></p><h3>2.3.业界暂无类似的开源项目方案</h3><p></p><p></p><p>当前社区已有的开源监控项目、以及相关的监控服务主要监控的是系统运行软、硬件环境的相关指标，该类系统主要针对的是服务具体的运行状态指标监控，却缺少针对业务数据趋势并对比的监控方案，无法满足好分期数据可视化、自动化监控报警的业务需要，也就意味着无法快速引进与落地，需要自行设计与实现。</p><p></p><h2>3．Sparta的设计与实现</h2><p></p><p></p><h3>3.1.Sparta架构设计</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9f/9fca539f08eb34bf0e3f7b3b31391f7a.png\" /></p><p></p><h4>3.1.1.系统划分</h4><p></p><p></p><p>监控配置Admin模块：负责相关任务收集参数、报警阈值规则配置、Grafana面板参数，并通过API发送Grafana面板修改指令监控收集Collector模块：并行从目标数据源获取数据，并存储至InfluxDB中监控报警Checker模块：通过规则检查计算出需要报警的记录，报警过程中支持沉默、抑制、聚合能力</p><p></p><h4>3.1.2.具体工作流程</h4><p></p><p></p><p>管理员通过Admin模块发布相关数据配置，保存配置至MySQL中，并通过API发送面板配置至Grafana中XXL-JOB任务调度至Collector模块，Collector从MySQL中读取任务收集配置，并行的从目标数据源中收集相关数据，并将收集的数据存储至InfluxDB中XXL-JOB任务调度至Checker模块，Checker从MySQL中读取报警阈值规则配置，并使用InfluxDB的查询语句检查样本和实时数据的偏差是否超过阈值，并判断是否需要发出系统预警，如果需要预警则通过预警渠道发出告警通知相关人员相关人员通过Grafana的可视化能力展示InfluxDB中存储的实时数据与样本数据走势</p><p></p><h3>3.2.Sparta业务监控系统设计思路</h3><p></p><p></p><p>Sparta业务监控分为数据收集，数据存储，数据处理，数据分析，数据可视化这五个部分进行阐述，同时也是Sparta系统的设计思路。</p><p></p><h4>3.2.1.数据的收集</h4><p></p><p></p><p>系统将收集目标定义为数据源，数据源可以是任意数据库，例如可以是MySQL、Mongo、Redis、Hive、influxDB、ElasticSearch等数据存储服务等数据库，同时收集目标也可以是HTTP方式请求得到的数据结果。</p><p></p><p>收集的内容只需要是一个具体的统计数据值，例如MySQL中的count，sum等函数进行统计得到的结果，同时针对不同的收集目标取值可以通过特定的方式适配处理，例如HTTP支持从返回的JSON中取出特定数据字段作为统计结果收集，如MongoDB支持从特定字段中提取数据。</p><p></p><p>同时将收集的请求定义为指令，不同的收集目标可以使用不同的指令处理器，例如针对MySQL，Oracle使用的是SQL查询语句，而针对MongoDB使用的是JSON语句，HTTP请求则是一个URL地址。</p><p></p><p>与此同时系统还需要内置一些特殊的变量，也就是占位符，如当前执行时间，开始时间（系统约定开始时间=执行时间-跨步间隔）等，这些占位符主要用于请求指令的格式化替换，简化指令中对于时间的函数式计算，同时指令的格式化也支持一部分函数方法，如加减乘除等函数方法。</p><p></p><h4>3.2.2.数据的存储</h4><p></p><p></p><p>监控系统关注的核心数据为统计值与统计值发生的时间点，特别适用于时序数据库TSDB进行存储，时序数据库是用于管理时间序列数据的专业化数据库，针对时间序列数据的存储、查询和展现进行了专门的优化，从而获得极高的数据压缩比、极优的查询性能。</p><p></p><h4>3.2.3.数据的处理</h4><p></p><p></p><p>对于数据处理，使用近7天的历史数据作为数据样本，同时还需要对样本进行数据优化，采用基于 Z-Score的 “去极值”算法实时计算，剔除7天内实点数据的最大、最小极值，通过算法修正历史样本的可靠性。</p><p><img src=\"https://static001.geekbang.org/infoq/78/780eda1896c0b2a8d386f678d8e3f2f1.png\" /></p><p></p><p>具体步骤如下：</p><p></p><p>计算均值（mean）和标准差（standard deviation）。计算Z-Score：Z = (x - mean) / standard deviation，其中x是数据点。定义阈值：通常，Z-Score超过2或3被视为异常值。标记异常值：如果Z-Score超过阈值，则将数据点标记为异常值。</p><p></p><h4>3.2.4.数据的分析</h4><p></p><p></p><p>数据的分析阶段考虑使用阈值预警，即对监控的数据指标进行预设阈值规则组，我们实现了最常用的两种差异分析标准阈值类型：绝对值、比例，当系统检查到实时数据与样本数据之间的偏差偏离阈值一定比例或绝对值时，系统发出预警，预警通道同样支持了企业内部大多数的通信方式：企业微信，邮箱，短信，语音电话等方式（报警通道），用来针对不同级别的差异预警进行不同强度的提醒功能。</p><p></p><p>告警沉默</p><p></p><p>阈值规则的设置需要支持沉默功能，沉默功能是用来阻止一段时间内符合特定规则的告警通知，例如某个时间段内，某个测试集群在维护，会产生一些预期内的告警，此时因为这些告警是在预期之内的，因此没有通知的必要，那么就可以通过配置沉默规则来阻止通知的发送，即对于检查规则生效时间范围的控制。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/55/5580a36d5ef01172602aa882a37dee3a.png\" /></p><p></p><p>告警抑制</p><p></p><p>同时为了避免短时间内指标异常又恢复的情况，增加业务兼容度，减少报警频次，还需要支持预警抑制功能，即对于短时间内能立马恢复的预警是可以忽略的，例如某个时间段内网络发生5s的抖动，但是又立马恢复了，对于这种情况是需要系统自动解除故障的，因此需要在告警检查的过程中降低故障判断敏感率，比如说可以延长持续时间，即持续时间内发生异常才需要进行告警。&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ce/ce9eaf8c48bc88bb3fdb660790b6f24f.png\" /></p><p></p><p>级联告警</p><p></p><p>同时由于上下游数据具有一定的流向，上下游业务数据指标的变化趋势具有一定的联动性，因此可以对异常指标进行级联分析告警，溯源异常问题的发生来源；当业务数据指标发出告警之前，规则引擎需要对当前系统收集到的全部告警信息进行聚合关联分析，通过预设的指标分组关联链路关系进行异常数据聚合，形成关联告警链路。</p><p></p><h2>4．实践过程中的部分代表性问题</h2><p></p><p></p><h3>4.1.InfluxDB不支持复杂子查询语法，无法聚合计算</h3><p></p><p></p><p>在实践过程中，发现InfluxDB并不支持使用复杂的子查询语法，无法对近N天的历史数据进行聚合计算，于是转变思路改用手动的方式生成数据样本，提出滑动窗口式冗余存储方案，即将某个时间点的实时数据往后冗余存储N天，同时需要对存储的数据打上对应的tag以防止因为唯一性被覆盖，算法如下所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7a/7adbdeb1ae7aadbac212644bb6e8cffb.png\" /></p><p></p><p>例如时间点2023-12-04 10:00:00收集到数据为10，2023-12-05 10:00:00收集到数据为20，生成的数据如下所示，以此类推生成近N天的历史样本数据：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5b/5bd500604d13cae83243bcbe392ca96b.png\" /></p><p></p><h3>4.2.收集出现长耗时导致整个采集不可用</h3><p></p><p></p><p>在开发验证过程中曾遇到某个数据源数据收集出现慢SQL，导致整个数据收集功能不可用，影响了后续任务的调度，而Go语言天生的并发能力可以很方便的处理这个问题，使用select函数的超时打断功能即可实现。该机制可以作为强制长耗时sql中断的技术兜底策略，也能将Sparta的监控任务配置完全开放给整个团队使用，而无需针对每个监控任务再次进行执行效率等问题的核验工作，避免慢SQL对数据库带来的性能损耗。具体实现如下所示：</p><p></p><p><code lang=\"text\">ctx := context.Background()\ndone := make(chan bool, 1)\n// 执行耗时任务\ngo func(ctx context.Context) {\n// 延迟调用匿名函数 (匿名函数在主函数结束之前最后调用，可以捕获主函数中的异常)\ndefer func() {\nif errInfo := recover(); errInfo != nil {\n// 执行发生异常处理\ndone &lt;- true\n}\n}()\n// 正常执行处理，结束以后设置chan标记位\ndone &lt;- true\n}(ctx)\nselect {\ncase &lt;-done:\n// 正常执行结束处理\ncase &lt;-time.After(25 * time.Second):\n// 超时处理\n}</code></p><p></p><h3>4.3.报警失败，以及过频骚扰问题</h3><p></p><p></p><p>在实际应用过程中，报警渠道发送通知并非一定成功，如短信下达率并非百分百，因此需要有渠道补充功能，即当首选的渠道告警发送失败时能够自动降级到其他备用报警渠道；同时，重复的报警内容容易产生骚扰，需要针对告警的频率做限定，如延长同一告警的发送间隔，以及在短时间内不得重复发送相同的告警消息，避免造成骚扰；并且需要支持一定的策略，能够忽略短时间的数据异常波动情况的出现。</p><p></p><h3>4.4.InfluxDB集群功能不再开源</h3><p></p><p></p><p>目前社区已有多个项目在跟进，可以选择相对成熟的方案，如InfluxDB-Cluster、Influx-Proxy。Influx-Proxy是一个基于高可用、一致性哈希的InfluxDB集群代理服务，实现了InfluxDB高可用集群的部署方案，具有动态扩/缩容、故障恢复、数据同步等能力，目前Influx-Proxy已适配Influx-V2。</p><p></p><p>连接到Influx Proxy和连接原生的InfluxDB数据库并没有显著区别，对上层客户端是透明的，上层应用可以像使用单机的InfluxDB一样使用，Influx Proxy会对请求进行转发，并对各个InfluxDB集群节点进行管理。Influx Proxy是基于饿了么开源的Influx-Proxy，并进一步开发和优化，支持了更多的特性，移除了 Python、Redis依赖，解决了受限于一个数据库、需要额外配置KEYMAPS、数据负载不均衡的问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fd/fd0086813f91fa4c879245086e24aafc.png\" /></p><p></p><h2>5．总结</h2><p></p><p></p><p>好分期发展迅速，内部系统的架构也是愈加复杂，近百个不同职能系统组共同支撑好分期的金融业务。同时也是因为架构复杂，任何系统的异常波动、合作机构网络、业务异常都会对整体的业务造成影响。Sparta的建立，提供了一套只依赖各端的数据收集即可完成逻辑串联分析系统化的监控，将监控与复杂的系统架构和业务场景进行分离的解决方案。为业务、运营、技术、运维等多种角色提供了更灵活的监控接入的方案，对于业务变化趋势、异常数量、组件重点指标等多种维度进行覆盖分析，对异常结果进行敏感监控报警通知，为建设好分期更稳定的金融业务体系提供了有力的技术保障。</p>",
    "publish_time": "2024-01-02 16:57:32",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]