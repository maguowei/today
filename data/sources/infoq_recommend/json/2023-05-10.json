[
  {
    "title": "InfoQ 2023 年趋势报告：事件驱动架构、深度学习和人工智能、云原生架构和容器化技术",
    "url": "https://www.infoq.cn/article/GfGMc5ozQO1XYOiaTXCz",
    "summary": "<p>InfoQ趋势报告为InfoQ的读者提供了需要关注的主题的概览，同时帮助InfoQ编辑团队关注创新性的技术。除了该报告和趋势图之外，<a href=\"https://www.infoq.com/podcasts/architecture-trends-report-2023/\">与之相关的播客</a>\"会有多位编辑讨论这些趋势。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/architecture-trends-2023/en/resources/1Architecture-2023-1680611288788.jpg\" /></p><p></p><h1>趋势图的更新</h1><p></p><p></p><p>在后文中，我们会对报告进行更详细的阐述，但我们首先总结一下去年以来趋势图的变化。</p><p></p><p>今年有三个新的条目添加到了图表中。大语言模型和软件供应链安全是新的创新者趋势，“将架构作为团队运动”被添加到了早期采用者中。</p><p></p><p>获得采用并转移到右侧的趋势包括“可移植性设计”、数据驱动架构和serverless。eBPF被删除掉了，因为它的应用范围较小，而且不太可能成为架构决策的主要驱动力。</p><p></p><p>有些趋势进行了重命名或进行了合并。我们认为Dapr是对“可移植性设计”理念的实现，所以作为一个单独的趋势，它被移除掉了。数据驱动架构是“数据+架构”和数据网格（data mesh）的组合。区块链被替换为更广泛的去中心化的应用，或dApps的概念。WebAssembly现在同时涉及到了服务端和客户端，因为这些都是相关但独立的想法，并可能在未来独立演进。</p><p></p><h1>可移植性设计</h1><p></p><p></p><p>“可移植性设计”中的可移植性指的并不是能够将代码拿出来并转移到别的地方去。相反，它从基础设施中创建了一个整洁的抽象概念。正如InfoQ编辑Vasco Veloso所言，“设计和构建系统的人可以专注于能够带来价值的东西，而不必过多担心它们将要运行的平台的细节。”</p><p></p><p>这种设计理念正在被Dapr这样的框架所实现。InfoQ的新闻经理Daniel Bryant认为CNCF项目的好处在于为构建云原生服务提供了一个清晰的抽象层和API。Bryant说，“[集成]的关键在于API，而[Dapr]提供了抽象，而不做最低限度的共同标准”。</p><p></p><p>Bilgin Ibryam在最近的一篇文章中描述了云原生应用向<a href=\"https://www.infoq.com/articles/cloud-bound-applications/\">云限定（cloud-bound）应用</a>\"的演变。云限定应用不是使用应用逻辑和计算基础设施的逻辑组件来设计一个系统，而是把关注点放到集成绑定上。这些绑定包括外部API，以及像工作流编排和可观测性遥测这样的运维需求。</p><p></p><p>另一项支持可移植性设计的技术是WebAssembly，尤其是服务器端的WebAssembly。通常，</p><p>WebAssembly被视为客户端的功能，用于优化在浏览器中运行的代码。但是，使用WebAssembly对服务器端的代码大有益处。InfoQ的编辑Eran Stiller描述了创建基于WebAssembly的容器的过程。</p><p></p><p></p><blockquote>与其将它编译为Docker容器，然后在编排器的容器中启动整个系统，还不如将其编译为WebAssembly，这样能够使容器更加轻量级。它的构建是非常安全的，因为它的最初目的是用来运行浏览器的。而且它能够在任何地方运行：在任意云或任意CPU上。——Eran Stiller</blockquote><p></p><p></p><p>关于<a href=\"https://www.infoq.com/dapr/\">Dapr</a>\"和<a href=\"https://www.infoq.com/webassembly/\">WebAssembly</a>\"的更多信息，可以关注InfoQ相关的主题。</p><p></p><h1>大语言模型</h1><p></p><p></p><p>AI相关的新闻，尤其是像GPT-3和GPT-4这样的大语言模型，已经让我们无法忽视了。正如人们日常使用和各种形式的媒体报道所证明的那样，它不仅仅是软件专业人员使用的工具。但是，它对软件架构师意味着什么呢？在某种程度上来讲，现在断言未来会发生什么还为时尚早。</p><p></p><p></p><blockquote>借助ChatGPT和Bing，我们刚刚看到像GPT-3这样的大语言模型的可能性。这就是创新者（innovator）趋势的定义。我不知道会有什么样的结果，但它肯定是非常重要的，我期待在未来几年看到它的发展。——Thomas Betts</blockquote><p></p><p></p><p>虽然未来是不确定的，但我们乐观地认为，这些AI模型会对我们构建的软件以及构建软件的方式产生积极的影响。ChatGPT、Bing chat和GitHub Copilot的代码生成功能对编写代码和测试很有助益，能够让开发人员更快地开展工作。架构师也可以使用聊天机器人来讨论设计方案和分析权衡利弊。</p><p></p><p>尽管这些效率提升是很有用的，但是必须要了解AI模型的局限性。它们有内在的偏见，这可能并不那么显而易见。虽然看起来它们的回应信心满满，但它们可能并不了解你的领域。</p><p></p><p>这肯定是2023年需要关注的一个主要趋势，因为新产品是建立在大语言模型之上的，而公司找到了将它们集成到现有系统的方法。</p><p></p><h1>数据驱动架构</h1><p></p><p></p><p>去年，我们讨论了“数据+架构”的理念，以此来掌握架构师在设计系统时该如何以不同的方式来考虑数据。今年，我们在“数据驱动架构”的标题下，将这一理念与数据网格（Data Mesh）结合了起来。</p><p></p><p>数据的结构、存储和处理都是前期要关注的问题，而不是在实现过程中要处理的细节。QCon伦敦编程委员会的成员Blanca Garcia-Gil说，“在设计云架构时，有必要从一开始就考虑数据的收集、存储和安全性，这样以后我们就可以从中获取价值，包括使用AI/ML”。Garcia-Gil还指出，数据可观测性依然是一个创新者趋势，至少与系统中其他部分的可观测性相比是这样的。</p><p></p><p>数据网格是一种范式的转变，团队围绕着数据产品的所有权进行调整。这符合数据驱动架构的理念，也会将康威法则纳入系统的整体设计。</p><p></p><h1>设计可持续性</h1><p></p><p></p><p>尽管设计可持续性得到了更多的采用，但是我们依然将其作为一个创新者趋势，因为行业刚刚开始真正接受可持续系统以及面向低碳足迹的设计。我们需要将可持续性作为一个主要特性，而不是在降低成本时的次要目标。Veloso说，“我注意到最近有很多关于可持续性的讨论。坦白讲，可能有一半的原因是因为能源价格更加昂贵，每个人都想要减少OPEX”。</p><p></p><p>在这方面，最大的挑战之一是难以衡量系统的碳足迹。到目前为止，成本一直作为环境影响的替代方案，因为耗费的计算量与使用了多少碳之间存在一定的关联性。但是，这种技术有很多的局限性。</p><p></p><p><a href=\"https://greensoftware.foundation/\">绿色软件基金会（Green Software Foundation）</a>\"是一个致力于创建工具来测量碳消耗的计划。在QCon伦敦会议上，Adrian Cockcroft概述了三大云供应商（AWS、Azure、GCP）目前在碳测量方面的<a href=\"https://www.infoq.com/news/2023/03/carbon-footprint-standard/\">情况</a>\"。</p><p></p><p>随着工具的改进，开发人员将能够把碳使用添加到系统的其他可观测性指标中。一旦数据可见，就可以设计和修改系统以减少它们。</p><p></p><p>这也与可移植性和云原生框架的理念息息相关。如果我们的系统更具可移植性，这意味着我们能够更容易地调整它们，以最环保的方式运行。这可能涉及到将资源移动到使用绿色能源的数据中心，或者在可用能源更加绿色环保的时候处理工作负载。我们不再假定在服务器不繁忙的夜间是运行工作负载的最佳选择，因为太阳能可能意味着白天的中午是最绿色环保的时间。</p><p></p><h1>去中心化应用（dApps）</h1><p></p><p></p><p>区块链和分布式账本是去中心化应用背后的技术。随着Twitter的变化，作为一个替代性的、去中心化的社交网络，Mastodon得以进入大众视野。但是，区块链技术所致力于解决的问题依然被大多数人认为这根本并不是什么问题。由于适用场景的小众性，它依然被归类为创新者趋势。</p><p></p><h1>将架构作为团队运动</h1><p></p><p></p><p>架构师不再独自开展工作，架构师也不再只思考技术问题。在行业中，架构师角色的差异很大，一些公司已经完全取消这个头衔，而倾向于让“首席工程师（principal engineer）”作为主要负责架构决策的角色。这对应了一种更加强调协作的工作方式，架构师与构建系统的工程师紧密合作，不断完善系统设计。</p><p></p><p></p><blockquote>架构师会一直与软件团队合作，提出并迭代设计。我会持续看到这里有不同的角色（尤其是在较大的组织中），但是最重要的是，要通过概念验证进行沟通和协作，从而对设计进行尝试。——Blanca Garcia-Gil</blockquote><p></p><p></p><p>现在，架构决策记录（Architecture Decision Record，ADR）被普遍认为是记录和交流设计决策的一种方式。它们也可以用作协作工具，帮助工程师学会做出技术决定和考虑权衡利弊。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/architecture-trends-2023/\">Software Architecture and Design InfoQ Trends Report - April 2023</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/fvb5Y9egEbd3BNvGRoBw\">InfoQ 2023 年趋势报告：影响组织文化的两个最大的因素是大裁员和 ChatGPT 等大型语言模型</a>\"</p>",
    "publish_time": "2023-05-10 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "新型数据库技术交流，就在QCon全球软件开发大会",
    "url": "https://www.infoq.cn/article/MTipgwYIlIb7AYsRgIOz",
    "summary": "<p>近些年来，数据库领域飞速发展，涌现了云数据库、分布式数据库等多种新型数据库。</p><p>&nbsp;</p><p>在5月26-27日，QCon全球软件开发大会（广州站）即将落地，我们策划了【<a href=\"https://qcon.infoq.cn/2023/guangzhou/track/1516\">新型数据库</a>\"】专题，邀请了Datafuse Labs 联合创始人张雁飞、Greptime联合创始人庄晓丹共同联合出品，与此同时，我们很荣幸邀请到了以下四位分享嘉宾：</p><p>&nbsp;</p><p><a href=\"https://qcon.infoq.cn/2023/guangzhou/presentation/5259\">冯家纯</a>\"，Greptime 联合创始人，他先后在阿里巴巴，蚂蚁集团工作多年，长期从事中间件、时序数据库产品研发，曾负责蚂蚁集团统一监控存储层，对时序存储相关技术有丰富的实践经验。他将为我们带来题为《云原生时序数据库的挑战和架构设计》的演讲。他将分享在实现 GreptimeDB 这个分布式、云原生的时序数据库过程中所面临的挑战，并给出他们的设计选择和背后的思考。</p><p>&nbsp;</p><p><a href=\"https://qcon.infoq.cn/2023/guangzhou/presentation/5260\">游致远</a>\"，字节跳动 ByteHouse 资深研发工程师，拥有多年大数据计算引擎、分布式系统相关研发经历。将为我们带来题为《ByConity：基于云原生架构的开源实时数仓系统》的演讲。他将介绍 ByConity 的整体架构和核心功能，并结合字节内部的应用案例，阐述实时数仓面对的主要挑战和解决方案。</p><p>&nbsp;</p><p><a href=\"https://qcon.infoq.cn/2023/guangzhou/presentation/5257\">张雁飞</a>\"，Datafuse Labs 联合创始人，将为我们带来题为《Databend: Chat with Your Data Using AI》的演讲。他将探讨云数仓与大模型（LLMs）中有哪些融合点，并分享如何基于自有数据集开发一个类 ChatGPT 的智能问答/搜索系统。</p><p>&nbsp;</p><p><a href=\"https://qcon.infoq.cn/2023/guangzhou/presentation/5268\">刘达</a>\"，蚂蚁集团高级开发工程师，曾任职于 IBM CSL 存储部。先后参与过 IBM Storwize、阿里云 PoV 等存储产品的研发，目前主要在蚂蚁集团参与 AntKV 的研发以及性能调优工作。将为我们带来题为《AntKV:：蚂蚁实时计算 KV 分离 5x 性能提升实践》的演讲。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/69/694e1fce1c010f3c44db606e23b5816f.png\" /></p><p></p><p>&nbsp;</p><p>欢迎大家参加本次专题演讲，与我们一起探讨新型数据库领域的最新发展。</p><p>&nbsp;</p><p>活动推荐：</p><p>&nbsp;</p><p>在5月26-27日，QCon全球软件开发大会（广州）站即将落地，在此峰会上，共有十二个专题，近五十余场分享。其中包括稳定性即生命线、编程语言实战、DevOps vs 平台工程、AGI 与 AIGC 落地、下一代软件架构、数据驱动业务、出海的思考、云成本优化、现代数据架构、AIGC浪潮下的效能智能化、新型数据库、大前端技术探索。欢迎与你一起交流，更多详细信息可扫描下方海报二维码了解。</p><p><img src=\"https://static001.infoq.cn/resource/image/cf/29/cfcd3fcbdac33fa9d712124034c31a29.jpg\" /></p><p></p>",
    "publish_time": "2023-05-10 10:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "新型数据库技术交流，就在QCon全球软件开发大会（广州）",
    "url": "https://www.infoq.cn/article/MTipgwYIlIb7AYsRgIOz",
    "summary": "<p>近些年来，数据库领域飞速发展，涌现了云数据库、分布式数据库等多种新型数据库。</p><p>&nbsp;</p><p>在5月26-27日，QCon全球软件开发大会（广州站）即将落地，我们策划了【<a href=\"https://qcon.infoq.cn/2023/guangzhou/track/1516\">新型数据库</a>\"】专题，邀请了Datafuse Labs 联合创始人张雁飞、Greptime联合创始人庄晓丹共同联合出品，与此同时，我们很荣幸邀请到了以下四位分享嘉宾：</p><p>&nbsp;</p><p><a href=\"https://qcon.infoq.cn/2023/guangzhou/presentation/5259\">冯家纯</a>\"，Greptime 联合创始人，他先后在阿里巴巴，蚂蚁集团工作多年，长期从事中间件、时序数据库产品研发，曾负责蚂蚁集团统一监控存储层，对时序存储相关技术有丰富的实践经验。他将为我们带来题为《云原生时序数据库的挑战和架构设计》的演讲。他将分享在实现 GreptimeDB 这个分布式、云原生的时序数据库过程中所面临的挑战，并给出他们的设计选择和背后的思考。</p><p>&nbsp;</p><p><a href=\"https://qcon.infoq.cn/2023/guangzhou/presentation/5260\">游致远</a>\"，字节跳动 ByteHouse 资深研发工程师，拥有多年大数据计算引擎、分布式系统相关研发经历。将为我们带来题为《ByConity：基于云原生架构的开源实时数仓系统》的演讲。他将介绍 ByConity 的整体架构和核心功能，并结合字节内部的应用案例，阐述实时数仓面对的主要挑战和解决方案。</p><p>&nbsp;</p><p><a href=\"https://qcon.infoq.cn/2023/guangzhou/presentation/5257\">张雁飞</a>\"，Datafuse Labs 联合创始人，将为我们带来题为《Databend: Chat with Your Data Using AI》的演讲。他将探讨云数仓与大模型（LLMs）中有哪些融合点，并分享如何基于自有数据集开发一个类 ChatGPT 的智能问答/搜索系统。</p><p>&nbsp;</p><p><a href=\"https://qcon.infoq.cn/2023/guangzhou/presentation/5268\">刘达</a>\"，蚂蚁集团高级开发工程师，曾任职于 IBM CSL 存储部。先后参与过 IBM Storwize、阿里云 PoV 等存储产品的研发，目前主要在蚂蚁集团参与 AntKV 的研发以及性能调优工作。将为我们带来题为《AntKV:：蚂蚁实时计算 KV 分离 5x 性能提升实践》的演讲。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/69/694e1fce1c010f3c44db606e23b5816f.png\" /></p><p></p><p>&nbsp;</p><p>欢迎大家参加本次专题演讲，与我们一起探讨新型数据库领域的最新发展。</p><p>&nbsp;</p><p>活动推荐：</p><p>&nbsp;</p><p>在5月26-27日，QCon全球软件开发大会（广州）站即将落地，在此峰会上，共有十二个专题，近五十余场分享。其中包括稳定性即生命线、编程语言实战、DevOps vs 平台工程、AGI 与 AIGC 落地、下一代软件架构、数据驱动业务、出海的思考、云成本优化、现代数据架构、AIGC浪潮下的效能智能化、新型数据库、大前端技术探索。欢迎与你一起交流，更多详细信息可扫描下方海报二维码了解。</p><p><img src=\"https://static001.infoq.cn/resource/image/cf/29/cfcd3fcbdac33fa9d712124034c31a29.jpg\" /></p><p></p>",
    "publish_time": "2023-05-10 10:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "突发！领英宣布关闭领英职场并裁员716人，中国区产品和研发一个不留",
    "url": "https://www.infoq.cn/article/P8GbpADUSd1GbVMMhUCE",
    "summary": "<p></p><h2>领英宣布裁员并关闭中国应用</h2><p></p><p>据外媒报道，微软旗下专注于商业专业人士的社交媒体网络领英表示，由于需求波动，它将在全球两万名员工中裁掉716人，同时也将在 8 月 9 日之前关闭其在国内的求职应用程序 InCareer（领英职场）。此外，根据领英<a href=\"https://www.linkedin.com/help/linkedin/answer/a534125/about-incareer?lang=en\">帮助</a>\"页面显示，InCareer 将在这之前删除所有用户数据。</p><p></p><p>Roslansky表示：“在我们中国团队的不懈努力之下，‘领英职场’在过去一年中取得了一些成绩，但它始终面临着日趋激烈的市场竞争和宏观经济环境带来的挑战。\"</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/46/462f9cb8490fc28181dc346c4df5aa91.png\" /></p><p></p><p>领英中国也在微博上发布了在华相关调整和策略更新声明：</p><p></p><p></p><blockquote>领英正式宣布了调整中国业务战略的决定，未来将帮助中国企业在海外寻找和雇佣国际人才，提升人才技能；帮助中国企业的产品和服务打造国际化品牌，拓展海外市场。领英将继续深耕中国市场，通过领英人才和营销解决方案，以及今年晚些时候即将落地中国内地的领英学习解决方案，持续支持中国企业的全球化发展。此次战略调整也会带来一系列变化，领英在中国的本土化求职平台——“领英职场”将于 2023 年 8 月 9 日起正式停止服务，中国团队的规模也将有所缩减。这一决定一方面肯定了领英在助力中国企业全球化战略方面取得的成绩，另一方面也看到了“领英职场”始终面临着日趋激烈的市场竞争和宏观经济环境带来的挑战，这使我们最终做出了停止服务的决定。领英母公司微软的股票周二在盘前交易中基本持平。根据微软的收益报告和提交给美国证券交易委员会的季度文件，2023 年第三季度，领英收入同比增长 8% 至 37 亿美元。</blockquote><p></p><p></p><p>该公司CEO Ryan Roslansky 在一封公开信中称，削减其销售、运营和支持团队职位的举措旨在简化公司的运营。他还表示，这些变化将创造250个新工作岗位，受裁员影响的员工将有资格申请这些职位。</p><p></p><p>“随着市场和客户需求波动更大，为了更有效地服务新兴市场和增长市场，我们正在扩大供应商的范围，”Roslansky写道。</p><p></p><p>领英的一位发言人表示，该公司将继续在中国开展业务，以帮助在中国开展业务的公司在国外招聘和培训员工。</p><p></p><p>但Roslansky表示，该公司将在未来一年继续“管理开支”，这表明进一步削减成本或裁员可能会摆在桌面上。</p><p></p><p>在社交媒体上，有领英员工透露，领英中国将中国区大概200多人的产品和研发团队全裁掉了，只留100多人的海外销售团队，赔偿方案2N+3。另也有消息表示，“赔偿方案为2N+2”。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/04/0441286523098a2a677de0d8ce25a394.png\" /></p><p></p><p>图片来源：网络</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8c/8ce5b743861796604e771ef9a0356755.png\" /></p><p></p><p>图片来源：网络</p><p></p><h2>砍掉社交，是领英淡出中国的首个信号</h2><p></p><p>领英作为一家全球的职场社交平台，创建于2003年，总部位于美国硅谷。截至2021年7月，领英全球会员总数已超过7.74亿，覆盖200多个国家和地区，其中，中国会员总数已逾5400万。</p><p></p><p>领英于 2014 年首次进入中国，2015年6月，领英中国发布了其在国内的首款职场社交App产品“赤兔”。这是领英首款由中国团队独立研发的产品，赤兔有别于领英偏高端、国际范儿和实用的工具属性，将目标用户群锁定年轻群体，强调人脉社交及O2O属性。随后该产品于2019年关闭。</p><p></p><p>为了更好地服务本地用户，领英于 2021年12月推出了本地化版本InCareer（领英职场）。</p><p></p><p>据领英公众号消息，该款应用“ InCareer”旨在帮助用户连接职业机会，协助雇主找到理想的候选人。与全球版领英产品不同的是，InCareer只专注于职位的发布，不再提供用户原创内容的发布与互动功能。</p><p></p><p>作为一个职场社交平台，领英中国此举彻底丧失掉了社交功能，有人认为，这相当于把自己最能吸引和留住用户的功能“阉割”掉了。</p><p></p><p>领英在 2021 年 10 月的一篇博文中<a href=\"https://blog.linkedin.com/2021/october/14/china-sunset-of-localized-version-of-linkedin-and-launch-of-new-injobs-app\">写道</a>\"&nbsp;：“虽然我们在帮助中国会员找到工作和经济机会方面取得了成功，但在分享和保持消息灵通等更多社交方面却没有取得同样程度的成功。”</p><p></p><h2>国内职场社交赛道竞争激烈</h2><p></p><p>这家美国社交媒体网站在中国面临着激烈的竞争。到 2021 年，它在国内拥有超过 5000 万会员，成为该公司继美国和印度之后的第三大市场。但相比之下，国内竞争对手智联招聘声称拥有超过3.2亿的专业用户和企业用户，此外脉脉的日渐崛起也给领英在国内的业务带来了不小的挑战。</p><p></p><p>脉脉于2013年推出，被称为中国版领英。几年后，它已经超越领英成为国内最受欢迎的专业网络平台，已拥有1.1亿验证会员。推动其成功的一个主要特点是它允许用户在聊天论坛中匿名发帖。</p><p></p><p>在领英职场砍掉社交功能后，脉脉火速推出了“领英用户人脉补偿计划”，为领英的用户提供搬家特权礼券。搬家特权包括一个月会员、无限人脉搜索、人脉推荐等权益，声称帮助用户来脉脉重建人脉网络。</p><p></p><p>如此激烈的竞争环境让领英在中国的市场不断缩减，裁员似乎成了不得不走的一步棋。</p><p></p><p>但其实，领英的裁员只是整个科技裁员浪潮的冰山一角。</p><p></p><p>拥有2万名员工的领英去年每个季度的收入都在增长，但在全球经济前景疲软的情况下，它与包括其母公司在内的其他主要科技公司都进行了大幅裁员。</p><p></p><p>在过去六个月中，包括亚马逊、领英的母公司微软和 Alphabet 在内的公司都宣布裁员。Meta 在 2022 年宣布大规模裁员的基础上，于3月宣布再裁员 10000 人。亚马逊还在同月表示，继该公司在1月份宣布裁员18000人之后，将裁员9000人&nbsp;。</p><p></p><p>参考链接：</p><p><a href=\"https://www.linkedin.com/help/linkedin/answer/a534125/about-incareer?lang=en\">https://www.linkedin.com/help/linkedin/answer/a534125/about-incareer?lang=en</a>\"</p><p></p><p><a href=\"https://edition.cnn.com/2023/05/09/tech/linkedin-layoffs-exit-china-app-intl-hnk/index.html\">https://edition.cnn.com/2023/05/09/tech/linkedin-layoffs-exit-china-app-intl-hnk/index.html</a>\"</p><p></p><p><a href=\"https://www.cnbc.com/2023/05/09/linkedin-layoffs-2023-716-employees-hit-and-china-app-discontinued.html\">https://www.cnbc.com/2023/05/09/linkedin-layoffs-2023-716-employees-hit-and-china-app-discontinued.html</a>\"</p>",
    "publish_time": "2023-05-10 14:21:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AI时代的“身份证”要来了？ChatGPT之父推出加密钱包World App，并称区块链可以区分人与AI",
    "url": "https://www.infoq.cn/article/fsUlW2TuwyUsNOArrik9",
    "summary": "<p></p><blockquote>Sam Altman 认为，区块链技术可以起到区分人与 AI 的作用。</blockquote><p></p><p></p><h2>“ChatGPT之父”旗下加密项目推出生态钱包World App</h2><p></p><p></p><p>5 月 8 日，<a href=\"https://xie.infoq.cn/article/dfc38a54da150224554820637\">OpenAI</a>\" 首席执行官 <a href=\"https://www.infoq.cn/article/YYqCPSdRmtkdSl2hhb9Y\">Sam Altman</a>\" 创立的加密货币公司 Worldcoin 宣布推出生态钱包 World App，该产品旨在让全球数十亿人都能访问其去中心化身份和金融服务。这也是首个能够原生支持 Worldcoin 生态系统的钱包。</p><p></p><p>Worldcoin 是 Sam Altman 和 Alex Blania、Max Novendstern 于 2021 年 6 月共同创立的加密项目，首次亮相即宣布完成 2500 万美元融资，获得了 a16z、Coinbase Ventures、LinkedIn 创始人 Reid Hoffman、Day One Ventures 等多位知名投资方的支持。目前，Worldcoin 已经从 Andreessen Horowitz、Multicoin Capital 和 Hashed 等领先风险投资公司处筹集到 1.25 亿美元。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/46/46a4e18af4ec08e55e5b0830c9ffa95e.png\" /></p><p></p><p>据 AlexaBlockchain 报道，World App 与其他钱包的区别在于，它会尽可能把 token 或者配置等元素隐藏起来。相反，它更专注最基本的任务，以简单、熟悉的体验吸引更多人上手尝试。World App 采取可组合设计，能以编程方式与开放协议和API混合并匹配起来，其出色使用感受也由此而来。</p><p></p><p>World App 在设计上非常简洁，充分考虑到隐私性和包容性。用户可以使用 World ID 证明自己身份，申请 Worldcoin Grants、免费向任何人汇款并使用更多加密货币。World ID 相当于护照，允许用户无缝登录网站、移动应用和加密 dapps，而无需共享姓名或电子邮件等个人数据。用户可以存入和发出数字货币，并通过多种选项使用银行账户或本地支付的方式完成存取款。用户还可以通过自己的电话号码或加密地址，以免费方式即时向世界各地的亲朋好友汇款。</p><p></p><p>World App 允许用户使用更多加密货币，包括以太坊和比特币，更多支持币种即将推出。用户可以跟踪各具体币种的持有量，获取价格变动通知，并轻松用自己的法定货币余额进行买入。Worldcoin 背后公司 Tools for Humanity 的产品负责人 Tiago Sada 表示，“实际上，你可能会发现 World App 上的功能比那些钱包上的功能更少，这是我们故意而为的。”</p><p></p><p>此外，World App 还具备自托管特性，意味着它不需要任何个人信息，所有共享信息均可通过点击按钮直接删除。World ID 和钱包密钥也采取自保管形式，用户可以选择将其备份至 Google Drive 或iCloud 以进行同步和恢复。</p><p></p><p>在经过 150 万 beta 用户的广泛开发和学习之后，目前，World App 的第一阶段现已全球上线，该钱包在 80 多个国家/地区开放下载。iOS 和 Android 上的本机应用也最大程度强调了包容性，其大小约为 18 MB，只相当于行业平均水平的五分之一；而且支持全球普及度最高的各种手机，包括部分十多年前推出的旧机型。</p><p></p><h2>AI时代的“身份证”？</h2><p></p><p></p><p>Sam Altman 一直很关心加密项目。</p><p></p><p>2015 年，Sam Altman 曾斥资 1000 万美元成立 YC 全球研究院。YC 全球研究院曾在美国推出了一个听上去非常疯狂的项目——基本收入计划。在这个计划中，参与者可以在没有任何附加条件的情况下获得固定的薪金，这样他们可以自由地选择自己爱好的事业，不再为温饱所困。</p><p></p><p>2021 年 3 月，Sam Altman 曾为加密领域发声，赞赏通证机制，并认为通证可以作为普遍基本收入的方式，为低收入人群提供公平的金融基础设施。2021 年 6 月，Sam Altman 联合&nbsp; Alex Blania、Max Novendstern 加密货币公司 Worldcoin。</p><p></p><p>Worldcoin 旨在为大众提供自我保管的开源数字钱包，此外该协议还通过一种独特的前沿技术实现了线上身份验证。通过 Worldcoin，Sam Altman 正在让每个人都能更轻松、更便捷地踏入加密货币的世界。</p><p></p><p>Sam Altman 将 Worldcoin 的任务分为三个部分：创建一个独一无二的ID验证程序（World ID）、发行相关的加密货币、开发相关的应用程序，即 World App。此前，World ID 验证程序推出了通过眼部虹膜扫描服务作为身份证明的功能，以及相关的加密服务。</p><p></p><p>Sam Altman 认为，<a href=\"https://xie.infoq.cn/article/d624df65cb1387cdf52754301\">区块链技术</a>\"可以起到区分人与 AI 的作用。这款新应用在面向消费者时，一方面是加密钱包，另一方面则希望成为 AI 时代的“身份证”。</p><p></p><p>Worldcoin 背后的团队 TFH 对于 World App 在实现去中心化技术普及方面扮演的重要角色感到兴奋。他们认为，这一成果的出炉终将推动隐私保护型身份证明、互联网原生金融服务普及的发展，进而让数字货币在全球公平分配与公共治理中占据一席之地。</p><p></p><p>也许随着时间推移，World App 或将为 AI 时代下的每一个人赋能，打造出基于真人的关系网络。但也有网友发出质疑，认为只是“割韭菜”罢了。总的来说，World App 的发展前景还需交给时间来考验。</p><p></p><p>参考链接：</p><p></p><p><a href=\"https://alexablockchain.com/world-app-launches-bringing-decentralized-identity-and-finance-to-billions/\">https://alexablockchain.com/world-app-launches-bringing-decentralized-identity-and-finance-to-billions/</a>\"</p><p><a href=\"https://www.thepaper.cn/newsDetail_forward_23011958\">https://www.thepaper.cn/newsDetail_forward_23011958</a>\"</p>",
    "publish_time": "2023-05-10 14:22:28",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "IBM加入AI大战！发布生成式AI平台Watsonx，最早将于7月推出",
    "url": "https://www.infoq.cn/article/wAM6PJiYjiyyj3l2jt4x",
    "summary": "<p>5月9日，<a href=\"https://www.infoq.cn/article/69a7zS7vfptq4azqGkq5\">IBM</a>\"在2023年度 Think 大会上宣布推出IBM Watsonx，这是一个新的人工智能和数据平台。</p><p>&nbsp;</p><p>Watsonx将使IBM的客户能够发布基础模型和生成式人工智能，并在任何云环境的一个地方存储和管理它们。IBM表示，新的Watsonx产品将结合基础模型和生成式人工智能，以帮助客户编写代码、运行AIOps、数字劳动力、安全性和可持续性。</p><p>&nbsp;</p><p>据介绍，Watsonx 有三个组件：watsonx.ai、watsonx.data 和 watsonx.governance。它为用户提供了先进的机器学习、数据管理，和生成式 AI 功能，以快速、可信数据和治理的方式在整个企业中训练、验证、调整和部署 AI 系统。可以为整个数据与 AI 生命周期提供帮助，从数据准备到模型开发、部署和监控。</p><p>&nbsp;</p><p>Watsonx.ai是一个专为今天与未来的业务而设计的 AI 开发平台。它结合了 <a href=\"https://www.infoq.cn/article/2018/05/ffdl-ruchir-puri\">IBM Watson Studio </a>\"的功能和利用基础模型能力的最新生成式 AI 的功能，使数据科学家、开发人员和数据分析师能够基于机器学习构建、运行和部署 AI。</p><p>&nbsp;</p><p>借助 watsonx.data，企业可以快速连接到数据，获得可信的见解并降低数据仓库的成本。它是基于开放式湖仓一体（lakehouse）架构而构建的数据存储，可在本地和多云环境中运行。</p><p>&nbsp;</p><p>Watsonx.governance可以助力围绕AI工具和AI的使用建立必要的护栏。它是一个自动化的数据和模型生命周期解决方案，用于制定策略、分配决策权并确保组织对风险和投资决策负责。</p><p>&nbsp;</p><p>watsonx.ai和watsonx.data 将于今年 7 月推出，后者将于今年晚些时候推出。目前，IBM没有公布新平台的任何定价细节。</p><p>&nbsp;</p><p>IBM董事长兼首席执行官Arvind Krishna表示，“基础模型使部署 AI 的可扩展性、价格和效率显着提高。”“我们为企业的需求打造了IBM Watsonx。借助IBM watsonx，客户可以在整个业务中快速培训和部署定制的人工智能功能，同时保留对数据的完全控制。”</p><p>&nbsp;</p><p>Arvind Krishna 表示，IBM 正在拥抱一个更加开放的生态系统。目前，IBM正在与热门的人工智能创业公司和开源平台<a href=\"https://xie.infoq.cn/article/1e821aceaf9504789496ce1c3\">HuggingFace</a>\"合作，该公司去年的估值达到了20亿美元。</p>",
    "publish_time": "2023-05-10 15:36:03",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从Node到Deno：你可能还没准备好",
    "url": "https://www.infoq.cn/article/PQKo2TVk69fB62UpKiVG",
    "summary": "<p></p><h1>背景介绍</h1><p></p><p></p><p>毫无疑问，Node.js就是目前全球最流行、使用范围最广的JavaScript运行时环境。但2018年亮相的Deno同样引发巨大轰动，凭借现代功能和高安全性在开发者群体中疯狂吸粉。</p><p>&nbsp;</p><p>Deno跟Node.js其实系出同门，都是由Ryan Dahl倾力打造。人们将Deno看作是Node.js的继任者，而且修复了后者中一些重要的设计缺陷。虽然现代范十足、年轻气盛，但Deno能不能彻底取代Node.js仍是个未知数。而且至少就目前来看，这事还八字没一撇，大部分开发者对Node.js的表现仍然表示满意。</p><p>&nbsp;</p><p>在本文中，我也跟大家探讨一下Deno的普及速度为什么越来越慢，还有人们为什么仍然喜欢Node.js。最后，咱们再对这两位做一番直接比较。</p><p>&nbsp;</p><p></p><h1>Node.js是什么?</h1><p></p><p></p><p>Node.js是一款人气极高的服务器端、开源、跨平台JavaScript运行时环境，以谷歌的V8 JS引擎为基础。自2009年发布以来，它一直在Web开发世界占据着主导地位。</p><p>&nbsp;</p><p>Node主要关注事件驱动的HTTP服务器。在处理请求时，它会运行一个向系统注册的单线程事件循环，每个传入请求都会触发一个JavaScript回调函数。这些回调函数能够使用非阻塞I/O调用处理请求。</p><p>&nbsp;</p><p>此外，Node还能从池中生成线程，借此解决可能造成阻塞或CPU密集型任务。跟大多数通过线程扩展的竞争性框架方案不同，Node基于回调函数的扩展机制能够以最小的内存占用量容纳更多请求。</p><p>&nbsp;</p><p>凭借着异步I/O加事件驱动架构，Node.js凭借轻量化优势在可扩展、数据密集型和实时Web应用程序中占据了显著优势，使其能够运行在各类分发设备之上。</p><p>&nbsp;</p><p></p><h1>&nbsp;Deno是什么?</h1><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/29/29ba154e5f47d8ae334722e612a0b2c6.png\" /></p><p></p><p>&nbsp;如前所述，Deno属于新一代的JavaScript框架，旨在解决Node中的设计缺陷并提供更现代化的开发环境。根据两套框架的缔造者Dahl本人的说法，Node.js具有三个显著缺点：</p><p></p><p>模块系统设计不当，过于依赖集中分发。遗留API不够稳定。安全性设计不足。</p><p>&nbsp;</p><p>据称，Deno一举解决了这三大难题，并带来更好的使用体验。</p><p>&nbsp;</p><p>Deno是一款JavaScript、TypeScript与WebAssembly运行时，具备安全默认设置。即除非明确启用，否则其无法访问文件、网络或环境。Deno建立在V8 JS引擎、Rust和Tokio基础之上，采用Web平台标准，始终通过单一可执行文件进行分发，并提供内置的开发工具以实现高效、安全的运行时。Deno包含一组经过审查的标准模块，可确保在Deno运行时上正常运行。Deno还支持原生TypeScript文件执行，无需额外做进一步配置。</p><p>&nbsp;</p><p></p><h1>Deno对Node: 主要区别</h1><p></p><p></p><p>现在，我们对Node和Deno做一番直接比较。</p><p></p><h2>第三方软件包管理</h2><p></p><p></p><p>借助Deno，开发人员可以直接通过URL安装软件包，而无需借助npm之类的集中注册表。尽管直接从URL处下载软件包有一定风险——如果托管软件包的服务器遭到入侵，攻击者可能会修改代码以注入恶意功能——但Deno提供一种对已下载模块进行缓存的办法，能够有效缓解这方面风险。软件包能够以库的形式被直接导入脚本之内，通过允许直接从任意公共URL处获取并运行脚本，Deno直接跳过了负责模块导入的软件包管理器。当然，从第三方处导入模块仍可能带来安全隐患。在这样的设计下，Package.json文件和node_modules文件自然也没有存在的必要。</p><p>&nbsp;</p><p>相比之下，Node.js需要使用npm来处理所有软件包，而且有着庞大的库和软件包生态系统。</p><p>&nbsp;</p><p>Deno的模块导入机制比Node更灵活，允许开发者从任意来源处导入代码，包括GitHub和所托管的任意CDN或注册表。这样，我们无需经过下载或安装过程，即可无缝实现模块导入。</p><p></p><h2>API</h2><p></p><p></p><p>Node.js诞生之时，JavaScript中还没有出现Promises或者async/await的概念，所以大多数API在设计上都接受错误优先的回调函数。这种方法经常会产生冗长而复杂的代码。如今，Node开发人员已经可以使用async/await语法，但同时也需要考虑向下兼容性，否则API经常会因变更而影响运行稳定性。</p><p>&nbsp;</p><p>Deno的情况则完全不同。因为Deno已经用上了await并支持各种最新JavaScript功能，所以这里根本就不需要封装async函数。通过这种方式，Deno帮助开发人员简化了处理流程，能够将各种面向未来的API绑定至JavaScript&nbsp;promises当中。Deno还高度关注与浏览器端运行的JavaScript代码所使用的Web平台API相兼容，能够以符合标准要求的方式支持多种流行高级Web API，包括Fetch、Web Storage、Web Workers和Broadcast Channel，等等。</p><p></p><h2>安全性</h2><p></p><p></p><p>提升安全性，也是Ryan Dahl决意打造Deno的核心原因之一。</p><p>&nbsp;</p><p>Deno提供安全的沙箱环境，能够禁止对文件系统的访问，所有代码执行也都在这里进行。在访问文件系统之前，Deno始终会首先提出授权请求。</p><p>&nbsp;</p><p>要获取许可必须借助命令行参数，以防止运行时在未经开发者同意的情况下删除任何文件。Deno中的各命令行标志都能在运行时上使用，借此启用特定脚本的特定功能。默认情况下，这些功能均处于非活动状态；使用者必须为脚本可能需要的所有元素显式设置相应标志。</p><p>&nbsp;</p><p>这些标志包括：</p><p>&nbsp;</p><p>— allow-env</p><p>允许环境访问环境变量获取、环境变量获取等功能。</p><p>— allow-hrtime</p><p>允许执行高分辨率时间测量。</p><p>— allow-net</p><p>允许网络访问。</p><p>— allow-read</p><p>允许文件系统读取访问。</p><p>— allow-run</p><p>允许运行子进程。</p><p>— allow-write</p><p>允许文件系统写入访问。</p><p>&nbsp;</p><p>相比之下，Node.js向来不以高安全性著称（编者注：Node.js 20 新的权限模型：提供了&nbsp;Node.js&nbsp;中敏感&nbsp;API&nbsp;的权限管控能力。插入微信文章：</p><p></p><p><a href=\"https://mp.weixin.qq.com/s/R4Bji3zE7yzbjTycrV1BDQ\">https://mp.weixin.qq.com/s/R4Bji3zE7yzbjTycrV1BDQ</a>\"）。例如，Node对文件系统的读取和写入访问权限无需单独授予，也不属于沙箱环境。因此，任何第三方库都可能因处置不当而引起风险。另外，Node用户还需要借助一系列标准安全措施以防止跨站点请求伪造（CSRF）和跨站点脚本（XSS）等威胁，利用这些机制进行日志检查、错误与异常管理，以及用户输入验证。</p><p>&nbsp;</p><p>因此，即使大家已经习惯了安全模块的严格约束，Deno仍是建立安全环境的最佳选择。</p><p></p><h2>TypeScript支持</h2><p></p><p></p><p>TypeScript是JavaScript的一个超集，允许用户以可选方式添加静态类型。Deno使用带有缓存技术的TypeScript编译器，实现了对TypeScript的开箱即用支持。也就是说，Deno能够直接对TypeScript代码进行编译、类型检查和执行，无需将其转换为JavaScript。</p><p>&nbsp;</p><p>虽然Node.js不像Deno那样能够天然支持TypeScript，TS在Node.js社区中也早已成为广受接纳的语言，所以有现成的TS包可供使用。大家可以毫不费力地在Node上运行TypeScript。只要安装了Node和npm，您就可以通过npm install -g typescript命令在设备上全局安装TypeScript。接下来，运行tsc --init来创建TypeScript配置文件，之后使用TypeScript编译器tsc即可编译您的.ts文件。</p><p>&nbsp;</p><p>如果您高度依赖于TypeScript而且愿意尝试新型框架，那Deno无疑是正确的选项。此外，在Deno中使用TypeScript进行开发时，无需进行任何额外的配置。</p><p></p><h1>开发者为什么喜爱Node胜过Deno？</h1><p></p><p></p><p>聊了这么多，可以看到Deno明显为开发人员提供了不少特殊功能，例如强大的支持系统和原生TypeScript兼容能力。其设计策略和丰富的内置工具，都能给开发人员提供高效的运行时环境和积极的使用体验。</p><p>&nbsp;</p><p>即使如此，Deno为什么还是没能全面取代Node？可以看到，Deno对Node.js的替代速度非常慢。尽管有着更现代的框架、也解决了不少设计问题，但开发人员还是更偏爱Node.js——而且人家的理由也相当充分。</p><p>&nbsp;</p><p>在Node.js最初发布时，开发者们就已经开始将其纳入实际应用。多年以来，为了满足软件开发社区的需求，Node发生了一系列重大变化，如今成为业界使用范围最广的JavaScript运行时。由于普及度极高，它也建立起了活跃且庞大的开发者社区。Node.js的软件包系统以npm为基础，功能丰富且易于管理。因此，如果大家的主要诉求集中在灵活性和上手简单度方面，那Node.js就是当之无愧的最佳选项。</p><p>&nbsp;</p><p>当然，Node还远称不上完美。在Node仍显落后的各个方面，Deno都取得了无法否认的重要进步，其中又以安全性和标准合规性为甚。Deno的单一二进制模式带来了远超Node的可移植性，开放模块架构也有望成为未来依赖项导入的客观规范。</p><p></p><h1>哪些因素阻碍了开发者投向Deno怀抱？</h1><p></p><p></p><p>尽管Deno社区也算活跃，但规模实在不大。专为Deno量身打造的软件包很有限，Node兼容层有时候也不够可靠。如果想要使用特定某个库，或者需要技术帮助，那选择Deno有可能令您陷入困境。</p><p>&nbsp;</p><p>Deno的另一个明显短板，就是缺少第三方软件包。而且由于成熟度不高，它无法像Node.js那样在现实应用中得到广泛支持。另外，Node.js有着极高的模块化程度。在npm的帮助下，用户可以从单一来源找到大量的库选项。换句话说，每位开发者都可以轻松下载大量软件包来更新自己的应用程序。</p><p>&nbsp;</p><p>此外，借助第三方库，大家完全可以在Node.js中实现Deno提供的多种功能。所以说，如果我们只是喜爱Deno的某些特性，那基本也能在Node.js中达成同样的效果，只是过程中需要多一点额外操作而已。</p><p>&nbsp;</p><p>Node还有另外一张王牌，那就是简单好用的权限管理机制。我们可以在平台上快速收取反馈，无需经过各种授权。Node.js能以最少的麻烦快速进行编码，很少需要请求特定权限。因此，它特别适合那些需要定期更新、体量庞大而且涉及丰富专业知识的动态项目。</p><p>&nbsp;</p><p>考虑到以上种种因素，可以看到大多数开发人员对于Node.js的现状基本感到满意，在短时间内应该也不打算“叛逃”到其他框架中去。</p><p>&nbsp;</p><p>与庞大而繁荣的Node.js社区相比，如今的Deno只能算是“蹒跚学步”的程度。它还没能在实际生产系统中经受全面测试，开发人员也还在适应这种新的运行时环境。当然，必须承认Deno有着巨大的发展前景，也确实在安全性、模块、回调和集中分发系统等层面超越了Node的水平。目前，Deno吸引早期使用者所依靠的主要是大家对于新鲜事物的好奇心。相信随着时间推移，Deno背后社区的发展壮大将让这个项目逐步成为Web开发领域的重量级选项。</p><p></p><h1>总结</h1><p></p><p></p><p>在比较了Deno和Node.js的异同之后，希望大家现在能够理解Deno中蕴藏的巨大潜力，以及开发人员为什么对这样一套优秀的框架显得不那么热心。Deno无疑将继续吸引越来越多的关注，我个人也相信它终有一天会成为能与Node.js正面叫板的强大框架。</p><p>&nbsp;</p><p>但软件开发者始终是以完成任务为第一诉求，对于工具的选择必然要基于用例的真实需要。</p><p>&nbsp;</p><p>感谢你愿意耐心看完！</p><p>&nbsp;</p><p></p><h5>原文链接：</h5><p></p><p><a href=\"https://cult.honeypot.io/reads/deno-vs-node-main-differences/\">https://cult.honeypot.io/reads/deno-vs-node-main-differences/</a>\"</p><p></p><p></p><h5>相关阅读：</h5><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MzUxMzcxMzE5Ng==&amp;mid=2247507993&amp;idx=1&amp;sn=8f92185ba48968fe4ae0775e1149fc7a&amp;chksm=f952155ace259c4cdf118888d35d45f92351d0a6585c8eea70d491d6363c5ce6bbb7697e5f9b&amp;scene=27#wechat_redirect\">Deno&nbsp;成立公司，获得&nbsp;490&nbsp;万美元种子资金</a>\"</p><p><a href=\"https://www.infoq.cn/article/juXB8EaoJrlLx4vB7ttD\">Node 之父着急宣布：Deno&nbsp;将迎来重大变革，更好地兼容</a>\"</p><p><a href=\"https://xie.infoq.cn/article/aad4610523c72781f0dd5b5b7\">Node&nbsp;版本控制</a>\"</p><p><a href=\"https://www.infoq.cn/article/9QU4eRfjNmNjidpjRkUI\">Node.js 20 正式发布</a>\"</p>",
    "publish_time": "2023-05-10 15:46:03",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "数据库er的夏日盛宴 | 2023 可信数据库发展大会演讲议题征集限时开启！",
    "url": "https://www.infoq.cn/article/2tULPkizxIKXG6a8Uzv4",
    "summary": "<p>当前，国内数百家数据库厂商在技术、生态、实践等多个维度展开激烈竞争，这对企业和开发者而言造成了极大的选型和实践困扰。过去几年，数据库可信生态的构建情况到底如何？标准到底是什么？技术层面取得了哪些进展？这些进展又将如何与产业做结合？各行业在实践层面的最佳方法论到底是什么...... 这些问题在很长一段时间内没有很好地讨论和共识。</p><p></p><p>基于此，由中国信息通信研究院、中国通信标准化协会指导，中国通信标准化协会大数据技术标准推进委员会（CCSA TC601）、InfoQ 极客传媒联合主办的 <a href=\"https://www.wjx.cn/vm/exUAJxd.aspx\">2023 可信数据库发展大会</a>\"将于 2023 年 7 月 4 - 5 日在北京国际会议中心隆重召开。</p><p></p><p>本届大会将邀请知名院士、行业协会领导、数据库学术大咖、产业链各环节数据库负责人、资深技术专家等共同论道新形势下<a href=\"https://s.geekbang.org/search/c=0/k=%E6%95%B0%E6%8D%AE%E5%BA%93/t=\">数据库</a>\"产业可持续、高质量发展的方法，并针对性解决上述产业发展中的痛点问题。</p><p><img src=\"https://static001.infoq.cn/resource/image/39/77/39794d5bed9ba94cf71bc21ee5acc677.jpeg\" /></p><p>目前，议题正在火热征集中，如果你希望成为可信数据库标准及生态建设的重要力量，并让自己的技术创新成果和最佳实践被行业广泛认可，与业内专家深入探讨产业跃迁路径，与信通院 &amp;InfoQ 一道建设可信数据库生态，欢迎参与<a href=\"https://www.wjx.cn/vm/exUAJxd.aspx\">【议题征集】</a>\"。</p>",
    "publish_time": "2023-05-10 15:48:50",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AI 大底座，大模型时代的答卷",
    "url": "https://www.infoq.cn/article/NuI1dqJQMh9CLrTKl1Pa",
    "summary": "<p>1.文心一言的诞生</p><p></p><p>“文心一言就是在这个全国AI领域规模最大的高性能GPU集群上完成训练的。”</p><p></p><p>早在2021年6月，为了满足未来的大模型训练任务，百度智能云开始规划全新的高性能GPU集群的建设，联合NVIDIA共同完成了可以容纳万卡以上规模的IB网络架构设计，集群中节点间的每张GPU卡都通过IB网络连接， 并在2022年4月将集群建设完成，提供单集群EFLOPS级别的算力。</p><p>2023年3月，文心一言在这个高性能集群上诞生，并不断迭代出新的能力。目前，这个集群的规模还在不断扩大。</p><p></p><p>NVIDIA中国区解决方案与工程总经理赖俊杰博士：高速IB网络互联的GPU集群是大模型时代的关键基础设施。NVIDIA和百度智能云共同建成的这个国内云计算市场最大规模的高性能GPU/IB集群，将加速百度在大模型领域获得更大突破。</p><p></p><p>2.高性能集群设计</p><p></p><p>高性能集群并不是算力的简单堆积，还需要经过专门的设计和优化，才能发挥出集群的整体算力。</p><p>在分布式训练中GPU会在机间和机内不断地进行通信。在利用IB、RoCE等高性能网络为机间通信提供高吞吐、低时延的服务同时，还需要对服务器的内部网络连接，以及集群网络中的通信拓扑进行专门设计，满足大模型训练对通信的要求。</p><p></p><p>做到极致的设计优化，需要对AI任务中的各项操作都对基础设施意味着什么有深刻理解。分布式训练中不同的并行策略，即模型、数据、参数如何进行拆分，会产生不同的数据通信需求，比如数据并行和模型并行会分别引入大量的机内和机间Allreduce操作，专家并行会产生机间All2All操作，4D混合并行则会将各类并行策略产生的通信操作都引入。</p><p></p><p>为此，百度智能云从单机服务器和集群网络两个方面优化设计，构建高性能GPU集群。</p><p></p><p>在单机服务器方面，百度智能云的超级AI计算机X-MAN，目前已经进化到第4代。X-MAN 4.0为GPU建立起了高性能的卡间通信，提供单机内部134 GB/s的Allreduce带宽。这是目前百度定制化程度最高，专用物料最多的服务器产品。在MLCommons 1.1榜单中，X-MAN 4.0在同配置单机硬件性能名列TOP2。</p><p></p><p>在集群网络方面，专门设计了面向大模型训练优化过的三层Clos架构，确保在大规模训练时集群的性能和加速比。和传统方式相比，该架构经过八导轨的优化，让任一同号卡在不同机器中的通信中的跳步数尽可能少，为AI训练中网络流量占比最大的同号卡Allreduce操作提供高吞吐和低延时的网络服务。</p><p></p><p>该网络架构可以最大能支持到16000卡的超大规模集群，这个规模是现阶段全IB网络盒式组网的最大规模。该集群的网络性能稳定一致性能做到了98%的水平，接近一直在稳定通信的状态。经大模型算法团队验证，在此超大规模集群上提交千亿模型训练作业，同等机器规模下整体训练效率是上一代集群的3.87倍。</p><p></p><p>但是，建设大规模高性能异构集群，只是大模型成功落地的第一步。确保AI大模型训练任务的顺利完成，还需要更多系统性软硬一体的优化。</p><p></p><p>3.大模型训练的挑战</p><p></p><p>过去几年，大模型的参数规模将达到每年增长10倍的速度。2020年左右，亿级别参数才是大模型，2022年，已经是需要千亿参数规模才能叫大模型了。</p><p></p><p>在大模型之前，一个AI模型的训练，通常单机单卡、或者单机多卡就可以满足，训练周期在小时到数天之间。现在，为了完成千亿参数大模型的训练，几百台服务器、数千张GPU/XPU卡的大集群分布式训练成为必选项，训练周期也扩展到以月为单位。</p><p></p><p>为了训练1750亿参数的GPT-3（3000亿token数据），1块A100按半精度峰值计算性能折算需要32年，1024块A100按资源利用率45%计算需要34天时间。当然，即使不考虑时间问题，1块A100也是无法训练千亿参数规模的模型的，因为模型参数已经超过单卡显存容量。</p><p></p><p>在分布式训练的环境下进行大模型训练，训练周期从单卡几十年缩短到几十天，需要突破计算墙、显存墙、通信墙等各种挑战，使得集群内的所有资源都能被充分利用，加速训练过程，缩短训练周期。</p><p></p><p>计算墙，指的是单卡算力和模型总算力之间的巨大差异。A100的单卡算力只有312 TFLOPS，而GPT-3则需要314 ZFLOPs的总算力，两者相差了9个数量级。</p><p></p><p>显存墙，指的是单卡无法完整存储一个大模型的参数。GPT-3的1750亿参数本身就需要700 GB的显存空间（每个参数按照4个字节计算），而NVIDIA A100 GPU只有80 GB显存。</p><p></p><p>计算墙和显存墙的本质是有限的单卡能力和模型的巨大的存储、计算需求之间的矛盾。这可以通过分布式训练的方法解决，但分布式训练之后又会遇到通信墙的问题。</p><p></p><p>通信墙，主要是分布式训练下集群各计算单元需要频繁参数同步，通信性能将影响整体计算速度。如果通信墙如果处理的不好，很可能导致集群规模越大，训练效率反而会降低。成功的突破通信墙，体现为集群有较强的扩展能力，即集群的多卡加速能力和规模是匹配的。多卡的线性加速比就是评估集群多卡加速能力的指标，数值越高越好。</p><p></p><p>这几堵墙在多机多卡的训练中开始出现。随着大模型的参数越来越大，对应的集群规模也越来越大，这三堵墙也越来越高。同时，在大集群长时间训练过程中，还会出现设备故障，有可能会影响或者中断训练进程。</p><p></p><p>4.大模型训练的过程</p><p></p><p>一般来说，从基础设施视角看大模型训练，整个过程可以大致分成以下两个阶段：</p><p></p><p>阶段一：并行策略和训练优化</p><p>在提交待训练的大模型后，AI框架会综合考虑大模型的结构等信息、以及训练集群的能力，为本次训练任务制定出一个并行训练策略，并完成AI任务放置。这个过程就是拆开模型、放置任务，即大模型应该被如何拆解，被拆开的各个部分如何放置到集群的各个GPU/XPU中。</p><p></p><p>针对放置在GPU/XPU中运行的AI任务，AI框架会联合训练集群在单卡运行时和集群通信层面进行全链路优化，加速大模型训练过程中各个AI任务的运行效率，包括数据加载，算子计算、通信策略等。比如将AI任务中运行的普通算子替换为经过优化的高性能算子，提供适配当前并行策略和训练集群网络能力的通信策略等。</p><p></p><p>阶段二：资源管理和任务调度</p><p></p><p>大模型训练任务按照上面制定的并行策略开始运行，训练集群为AI任务提供各类高性能的资源。比如AI任务运行在什么环境中，如何为AI任务提供资源对接，AI任务通过什么存储方式读取和保存数据，GPU/XPU通过什么类型网络设施通信等。</p><p></p><p>同时，在运行过程中，训练集群会联合AI框架通过弹性容错等方式，为大模型的长时间训练提供可靠的环境。比如如何观测和感知集群中各类资源和AI任务的运行状态等，如何在集群变化时能够对资源和AI任务进行调度等。</p><p></p><p>从以上两个阶段的拆解中，我们可以发现整个大模型训练的过程，都依赖AI框架和训练集群的密切配合，完成对三堵墙的突破，共同确保大模型训练的高效和稳定。</p><p></p><p>5.全栈融合，<a href=\"https://link.zhihu.com/?target=https%3A//cloud.baidu.com/solution/aif.html%3Ftrack%3Dzhihu01\">「AI大底座」</a>\"加速大模型训练</p><p></p><p>结合多年在AI和大模型领域的技术积累和工程实践，百度在2022年底推出了全栈自研的AI基础设施「<a href=\"https://link.zhihu.com/?target=https%3A//cloud.baidu.com/solution/aif.html%3Ftrack%3Dzhihu01\">AI大底座」</a>\"，包括「芯片–框架–模型 」三层技术栈，在各个层面都拥有关键自研技术和领先产品，分别对应昆仑芯、飞桨 （PaddlePaddle）、文心大模型。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/aa/aa098f0324ba44a73ca68c1e45e7b25e.jpeg\" /></p><p></p><p>在这三层技术栈的基础上，百度智能云推出了两大AI工程平台，「AI中台」和「百度百舸· AI异构计算平台」，分别在开发和资源层面进行提效，完成对三堵墙的突破，加速训练过程。</p><p></p><p>其中，「AI中台」依托AI框架为大模型训练过程制定并行策略和优化过的环境，覆盖训练的全生命周期。「百度百舸 」实现了高效的芯片使能，提供各类AI资源的管理和任务调度的能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/12/129799a220588a98c2724b1ac8d1f3db.jpeg\" /></p><p></p><p>百度「AI大底座」对各层的技术栈进行了全栈融合、系统优化，完成了云和智的技术一体化建设，可以实现对大模型训练的端到端优化和加速。</p><p></p><p>百度集团副总裁侯震宇：大模型训练是一个系统工程，集群规模、训练时间、花费金额，相比过去都提高了很多。如果不是全栈优化，很难保证大模型训练的顺利完成。百度多年来在大模型上的技术投入和工程实践，使得我们建立起了一套完整的软件栈能力，用来加速大模型的训练。</p><p></p><p>接下来，我们将结合上文提到的大模型训练过程的两阶段，讲述「AI大底座」的各层技术栈是如何相互融合、系统优化，实现大模型训练的端到端优化和加速。</p><p></p><p>5.1并行策略和训练优化</p><p></p><p>模型拆分</p><p></p><p>飞桨可以为大模型训练提供数据并行、模型并行、流水并行、参数分组切片、专家并行等丰富的并行策略。这些并行策略可以满足从十亿到千亿、甚至万亿参数规模大模型的训练，实现对计算墙和显存墙的突破。2021年4月，飞桨在业界第一个提出4D混合并行策略，可支持千亿级大模型的训练在月级别完成。</p><p></p><p>拓扑感知</p><p></p><p>百度百舸拥有专为大模型训练场景准备的集群拓扑感知能力，包括节点内架构感知、节点间架构感知等，比如每台服务器内部的算力大小、CPU和GPU/XPU、GPU/XPU和GPU/XPU链接方式，以及服务器之间GPU/XPU和GPU/XPU网络链接方式等信息。</p><p></p><p>自动并行</p><p></p><p>在大模型训练任务开始运行前，飞桨可以依据百度百舸平台的拓扑感知能力，对集群形成统一分布式资源图。同时，飞桨根据待训练的大模型形成的统一逻辑计算视图。</p><p></p><p>综合这两张图，飞桨自动化地为模型搜索出最优的模型切分和硬件组合策略，将模型参数、梯度、优化器状态按照最优策略分配到不同的GPU/XPU上，完成AI任务的放置以提升训练性能。</p><p></p><p>比如将模型并行的AI任务都放置在同一台服务器的不同GPU上，这些GPU通过服务器内部的NVSwitch链接。将数据并行、流水线并行的AI任务放置在不同服务器的同号GPU上，这些GPU通过IB或者RoCE链接。通过这种依据AI任务的类型进行AI任务放置的的方法，使得集群资源能够被高效使用，加速大模型训练。</p><p></p><p>端到端自适应训练</p><p></p><p>在训练任务运行过程中，如果集群发生了变化，比如有资源出现了故障，或者集群规模有变化，百度百舸会进行容错的替换或者弹性扩缩容。由于参与计算的节点所在位置发生了变化，它们之间的通信模式也许已经不是最优。飞桨能够依据最新的集群信息，自动调整模型切分和AI任务放置策略。同时，百度百舸完成相应的任务和资源的调度。</p><p></p><p>飞桨统一的资源和计算视图以及自动并行能力，再结合百度百舸的弹性调度能力，实现了大模型的端到端自适应分布式训练，可以覆盖集群训练的全生命周期。</p><p></p><p>这是AI框架和AI异构算力平台的深入交互，实现了算力、框架、算法三位一体的系统优化，支持大模型自动弹性的进行训练，端到端实测有2.1倍的性能提升，保证了大规模训练的高效性。</p><p></p><p>训练优化</p><p></p><p>完成模型的拆分和AI任务的放置后，在训练过程中为了确保算子在飞桨、Pytorch等各类主流AI框架和各类计算卡上可以加速计算，百度百舸平台中内置了AI加速套件。AI加速套件包括了数据层存储加速、训练和推理加速库AIAK，分别从数据加载、模型计算、分布式通信等维度进行了全链路优化。</p><p></p><p>其中，数据加载和模型计算的优化可以有效提高单卡的运行效率；分布式通信的优化，结合集群的IB或者RoCE等高性能网络和专门优化的通信拓扑，以及合理的AI任务放置策略，共同解决通信墙问题。</p><p></p><p>百度百舸在千卡规模集群中的多卡加速比达到了90%，使得集群拥有的整体算力可以被充分释放出来。</p><p>在2022年11月发布的MLPerf Trainning v2.1测试结果中，百度使用飞桨加百度百舸提交的模型训练性能结果，位列同等GPU配置下世界第一，端到端训练时间和训练吞吐均超越NGC PyTorch框架。</p><p></p><p>5.2资源管理和任务调度</p><p></p><p>百度百舸通过容器引擎CCE承载所有AI任务的运行，并通过相关容器插件的方式提供各类AI资源管理、架构感知、弹性容错等能力，在资源效能层面完成计算墙、显存墙、通信墙的突破。</p><p></p><p>资源管理</p><p></p><p>百度百舸可以提供各类计算、网络、存储等AI资源，包括百度太行·弹性裸金属服务器BBC、IB网络、RoCE网络、并行文件存储PFS、对象存储BOS、数据湖存储加速RapidFS等各类适合大模型训练的云计算资源。</p><p></p><p>在任务运行时，可以将这些高性能资源进行合理的组合，进一步提升AI作业的效率，全流程实现AI任务的计算加速。在AI任务开始前可以预热对象存储BOS中的训练数据，通过弹性RDMA网络将数据加载至数据湖存储加速RapidFS中。弹性RDMA网络相比传统网络可以降低2至3倍通信时延，在高性能存储的基础上，加速AI任务数据的读取。最后通过高性能的百度太行·弹性裸金属服务器BBC或者云服务器BCC，进行AI任务的计算。</p><p></p><p>弹性容错</p><p></p><p>AI任务运行时，不仅需要高性能的资源，还需要确保集群的稳定，最大程度降低资源故障发生率以免打断训练。但是，资源的故障不能绝对避免，AI框架和训练集群需要联合保证训练任务被打断后能够从最近的状态恢复，从而为大模型的长时间训练提供可靠环境。</p><p></p><p>百度自研的异构集合通库ECCL，支持昆仑芯和其他异构芯片的通信，支持慢节点和故障节点的感知。通过百度百舸的资源弹性和容错策略，将慢节点和故障节点剔除，并将最新的架构拓扑反馈给飞桨，重新进行任务布置，对应训练任务调配至其他XPU/GPU上，确保训练的平滑高效运行。</p><p></p><p>6.大模型时代的AI普惠</p><p></p><p>大模型是人工智能迈向通用智能的里程碑技术，驾驭好大模型是完成智能化升级路径上的必答题。超大规模的算力、全栈融合的软件优化，是对这道必答题的最好回答。</p><p></p><p>为了帮助社会和产业快速训练出自己的大模型，抢占时代先机，2022年底百度智能云发布了阳泉智算中心，搭载百度<a href=\"https://link.zhihu.com/?target=https%3A//cloud.baidu.com/solution/aif.html%3Ftrack%3Dzhihu01\">「AI大底座」</a>\"的全栈能力，可以提供4 EFLOPS的异构算力。这是目前亚洲单体规模最大、技术最先进的数据中心。</p><p></p><p>目前，百度智能云已经将「AI大底座」的全部能力对外开放，实现大模型时代的AI普惠，通过各个地域的中心云、边缘云BEC、本地计算集群LCC、私有云ABC Stack等多种形式进行交付，使得社会和产业可以方便的获得智能服务</p>",
    "publish_time": "2023-05-10 16:25:04",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AIGC在保险行业有哪些应用落地的可能性？",
    "url": "https://www.infoq.cn/article/vuj21tZF1q1qiB9zOQhw",
    "summary": "<p>通过数字化转型，保险业已经从过去的粗放式增长演变为高质量发展。各类主体基于自身独特的资源、技术、场景等，在产品设计、营销宣传、核保理赔、精算定价等业务领域不断探索。</p><p></p><p>但是在国内，保险产品仍然存在比较严重的同质化问题，如何深入场景优化服务体验，实现服务模式的创新，AI 被认为将在这一过程中起到关键作用。具体如何实现？在最新一期的 InfoQ《<a href=\"https://www.infoq.cn/article/I14iisg8hDYlCUCcMg5Y\">超级连麦</a>\". 数智大脑》直播中，风平智能CEO林洪祥分享了数字人和AIGC等前沿理念在保险场景应用的构想和实践，及其底层的技术逻辑。</p><p></p><p>以下是分享全文，经 InfoQ 编辑整理（点击链接观看完整<a href=\"https://www.infoq.cn/video/rOARbiN1flkQTADUpBdc\">直播回放</a>\"）</p><p></p><p>今天我的分享会重点关注于保险行业的应用，探讨如何应用数字人工智能来解决保险行业面临的挑战。&nbsp;</p><p></p><h3>保险行业面临三大市场痛点</h3><p></p><p></p><p>如今，AI+<a href=\"https://www.infoq.cn/article/29uvshLBl6ZIeuxTdNOx\">保险</a>\"已经达到了一个基准点，可以进入某种程度的商业应用。下面，我们将围绕保险行业的问题进行探讨，看看新技术能够解决哪些问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/23/23f47658b9a7de044663755faafc0253.png\" /></p><p></p><p>从2023年开始看，保险行业第一个的难点是获客和营销，这是每个公司都面临的普遍问题。尤其是在线上获客成本高企的情况下，如何降低成本，提高转化率是一个比较大的挑战。许多公司都尝试通过海量视频营销和直播来获客，但实际效果并不好。比如，像抖音这样的平台，保险公司其实很难在上面转化客户。当然，现在也有其他方法将客户转化到私域，但链路很长，成本也很高。因此，如何在降低成本的同时，使客户顺畅地转化到私域，仍然是一个较大的挑战。</p><p></p><p>第二，在保险行业，团队增员也是一个突出的问题，尤其是在过去几年中，整个行业的代理人数量从高峰期的近800万人下降到现在的200多万人。因此，人员不增加，但需要拓展业务，这就形成了一个悖论。增员在保险行业是与业绩直接挂钩的重点之一，因此，这是一个非常重要的问题。</p><p></p><p>第三，保险行业内的另一个问题是如何降低成本并提高效率，例如通过降低管理成本来提高效率。车险费率的调整和保险产品的调整也是行业内的痛点。因此，需要抓住一些新的机会点来解决这些问题。我们可以结合自己的探索，帮助保险行业的伙伴们在不同的领域做出实践，从而尝试解决这些问题。</p><p>围绕这些痛点，我们实现了一个三位一体的整体构想。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/73/732e446e9f273b59758c369fc8d0acad.png\" /></p><p></p><p>其中一个是数字人，即前端与真人长相一致的人物，包括外形、声音和动作。<a href=\"https://www.infoq.cn/article/Eg2VKA5xj61C4FH5ofYX\">数字人</a>\"可以解决人物IP打造和人员变动带来的问题。</p><p></p><p>具体而言，我们开发了自己的数字人生产平台 XGen。该平台从早期采用的干模型开始，结合圈子和模型技术，现已采用大模型加小样本技术来推进数字人的生产。</p><p></p><p>在声音方面，我们也取得了一些突破，特别是在沟通交流、客服以及直播做视频的环节中。我们发现朗读式的声音在很多应用环节的适用度不高，缺乏感情的饱满度，达不到要求。因此，去年花了很高的成本，训练了类似主播的声音，现在我们已经看到了许多训练有素的声音。</p><p></p><p>在<a href=\"https://www.infoq.cn/article/s4UU34IIB2IuFiJeeJ3L\">大模型</a>\"领域，特别是圈子的ChatGPT出现之后，它的震撼程度超出想象。在产出的效果方面，我们也做了一些事情，包括文章生产的模型，我们从2020年就开始实现文章创作模型，结合了自己的一些特点，使得它的精准度比较高。当然，它的泛化能力与<a href=\"https://www.infoq.cn/theme/187\">ChatGPT</a>\"这种大模型仍然无法相比，也不适合用在多人对话中，但在创作方面可以达到不错的效果。</p><p></p><p>在现有的阶段下，我们重点调整了目标，并结合自身数据提供了一些know how的解决方案，致力于构建一个AI数字人，即外表好看、内涵有趣的角色。并且，基于这样一个一体化基础架构，帮助保险行业解决三个维度的问题。</p><p></p><p>首先是流量，这是大家最关心的问题，它来源于线下代理人和线上广告调流等方面；其次，我们看到保险内容在行业中的相应导流，这是非常成功的案例；其三，保险IP以及数字人保险专家这样的角色打造。</p><p></p><h3>数字人AIGC在保险行业的应用初体验</h3><p></p><p></p><p>聊聊具体的实践。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/00/006dd604205e9e31fe561bf188b384f9.png\" /></p><p></p><p>自2020年起，我们开始涉足AI相关的内容创作领域，并进行了多次模型迭代。我们尝试了一些较大规模的探索，采用了专有算法让其中一些达到预期的高效率。例如短视频文案生成，因为文案量并不大，所以即使你采集了更多样本，如果采用常规的大模型Fine Tune的效果也不会太显着。</p><p></p><p>简单来说，原有的大模型就就好比一汪海水，而我们采集的优质视频文案就像倒入海水里的一瓢水或一桶水。虽然我们当时希望通过优质的视频文案来推动AIGC文案的创作，甚至建立一个适合这个领域的垂直模型，但是我们发现，这样的小样本数据放入大模型中Fine Tune，效果微乎其微。因此，我们集中精力优化现有的模型，并在反馈中获得了显著的好处。</p><p></p><p>对于文案创作，可以分享两个点。第一，在使用类似于ChatGPT这样的底层技术时，如果要进行相关的文案生产，需要考虑一些构造，例如逻辑梳理、短视频效果等等，以及在文案没有达到预期时，如何进行信息迭代。</p><p></p><p>此时，除了Fine Tune的方法外，还可以通过prompt的方式将信息带入，但是由于可带入的数据量有限，要达到良好的效果比较困难。因此，可以尝试一些规则的突破，例如使用多路由的方式进行改进。同时，还可以在垂直领域进行训练优化，考虑将小样本的数据放入训练中，但是需要注意，这样做并不一定能够改善整体效果，因此需要提前进行预判，避免偏差。</p><p></p><p>举个例子：我们整合了大规模的保险数据，这些数据是在过去几年中逐步积累的。基于这些数据，通过AI内容生产，我们生产出了一些文章，以便用户更好地了解相关保险产品。</p><p></p><p>但是自1993年以来，市场上的产品数量庞大，找到完整的条款非常困难，甚至从中保协或其他渠道获取的数据也不够完整，清晰度也很差。在这种情况下，备案产品与实际销售产品之间的差异非常明显，因此如何使优秀的产品和数据达到一定的标准是非常重要的。如果按照我们原有的知识图谱路径，需要做很深入的工作，因此我们早期采用了知识图谱和大型模型相结合的方法来生产保险文章。随着新的模型思路和大型模型的出现，这个板块变得更加简单。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b8/b831727b57be8a94cd8a27f0742bce2a.png\" /></p><p></p><p>关于<a href=\"https://xie.infoq.cn/article/1a28629b972b96ec7fafcebdc\">数据清洗</a>\"，我有一个小经验或思路分享给大家。我们从去年开始，尝试使用开源模型对数据进行清洗。类似于一些大平台利用ChatGPT返回的结果作为模型反馈来加快信念的校正，代替人工反馈的方式，我们发现在GPT-3模型本身也具备这个特点。</p><p></p><p>对于大模型，有一种盲目的想法，认为大模型可以不做任何事情，只需将各种粗糙的数据扔进去，就可以自动筛选出好的数据。但实际上，就像在智能客服领域一样，好的数据质量决定了它的准确率和召回率。</p><p>因此，在数据清洗方面，我们花费了大量时间构建数据，并且实际效果证明，当数据量达到一定程度时，它对模型效果的影响也会产生剧烈的变化，这也是我们所谓的“涌现”。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/31/3160245c1d78b61cc679ad646686608e.png\" /></p><p></p><p>针对保险行业获客难的痛点，基于内容实现深度转化是一个比较好的方法。</p><p></p><p>通过自动化方式，我们生产了大量的优质文章，这些文章的效果比当前普通的SEO和代理人回答的文章效果更好，就能获得更多的流量。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/85/8593198d1804267c2830b7705e0e8a6c.png\" /></p><p></p><p>第二个实践是AI视频的快速生产。现有的视频生产方式对创业者、企业家或者公司的核心IP来说是一项非常繁琐的工作，尤其对金融行业的从业人员而言，比如基金经理、理财明星、理财顾问等等，时间是非常宝贵的。</p><p></p><p>而通过对他们的声音和形象进行克隆，就不再需要进行拍摄和剪辑，可以把他们的时间完全解放出来，使得时间得以更好地分配。例如，一些客户通过数字人技术可以将原本需要每周拍摄1-2天的工作，减少到只需要花很少的时间处理边边角角的问题。</p><p></p><p>对于观众和平台而言，他们更关心视频是否达到了好的分发效果，以及信息是否得到充分传达，而不是视频究竟如何生产的。</p><p></p><p>以某大型保险经纪公司为例，这家公司的CEO是他们的核心IP，在视频和直播时代，他的痛点是无法依靠一个IP实现大规模扩展。而采用AIGC生产方式，可以完全解决这个问题。以前，他每周只有一下午的时间可以拍摄3-5期视频，但现在可以扩展到300-500期，这远远超出了他们对内容流量分发的需求。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/04/04b8e163a81d8e8dfe67c6cfc41c23f6.png\" /></p><p></p><p>AI短视频快速生产的逻辑，其中一个关键的技术是前面提到的大模型，包括文本大模型和数字人大模型的结合。另外还有很多的技术细节需要注意，比如视频的透明格式、质量追踪和视频质量，从而满足广告平台的机审和推荐逻辑，以达到更好的内容分发效果。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/38/381d90c29773a193770e75e8bc1fb907.png\" /></p><p></p><p>除了短视频应用外，数字人还可以做直播，数字人直播系统实际上就是一个<a href=\"https://www.infoq.cn/article/057ZDYfzOJZOZUfpOLH7\">AI系统</a>\"，背后包含着深度的交互和理解。这个系统可以快速地切换到其他互动的实时场景中，比如智能客服、银行开户等领域。虽然在某些领域，例如开户领域，这可能需要更多的时间和努力，但是像客服和互动营销等领域，某种程度上与直播体系没有本质的区别，都是一个实时交互的逻辑。</p><p></p><p>但其中还有一个小的技术细节或产品细节需要关注——延迟。在直播场景中，对时延要求并不是很高，因为它可以选择性地回答关键问题来转化客户。但是对于一些实时交互服务场景来说，比如一对一的专家问答，它没有选择性。例如，我们正在为一家大型上市公司开发一个名师模型，它对实时响应的要求就非常高。但目前很多大型模型的实时响应速度很慢，对此，我们也在探索解决方案，比如把一些短路径方法尝试应用到数字人直播中。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/25/253880e05f1e93ffda0de1d224e694b9.png\" /></p><p>&nbsp;</p><p>值得一提的是，在AIGC平台中，我们有自己的风平组件，如内容创作神笔系统、灵雀直播系统和星语实时交互系统。这些通用组件与保险细分领域的模型相结合，可以更好地解决保险业务痛点。&nbsp;</p><p></p><p>举个例子，我们曾为一家规模不大的公司提供智能客服的产品匹配服务。在此之前，他们曾花费了半年多的时间，动用了400多人参与内外部相关内容的整理工作，才最终完成Q&amp;A的配置。然而，随着新产品不断上线，他们又需要大量的重新配置，实际上AI客服的效果并不显著。</p><p></p><p>换句话说，在产品快速迭代的情况下，他们配置了一大堆内容，但效果却不尽如人意，这会导致后端服务的浪费。因此，简化配置流程可以大大降低人力成本，这一点是可以肯定的。</p><p></p><p>此外，我们在准确率和召回率与原AI客服系统相似的情况下，在多个案例中实现了约80％的显着提升。这些效果是令人震惊的。如果你正在考虑产品立项或技术革新的方向，这可能是一个比较有潜力和有趣的方向。</p><p></p><p>我们还在探索的一个方向是利用可视化的真人形象和视频实时交互来提高专业信任感。相较于传统的文字客服，人类更喜欢与真人交互，就像喜欢找VIP服务一样，如果使用真人或数字真人的模式，可能会拉近与客户之间的距离，提高服务和专业转化的可能性。</p><p></p><p>但是这个方向目前还没有完全量化的数据支持，因此我们需要进一步探讨和研究用户的适应程度和效果。在这些方面，我们将提供一些参考数据，并与大家一起探讨和改进。</p><p></p><h3>数字人AIGC落地背后的技术逻辑</h3><p></p><p></p><p>从底层的技术逻辑来看。在过去几年中，我们融合了多种技术，构建了一个<a href=\"https://www.infoq.cn/article/D6IaAAiPfurtLBYMXciW\">技术中台</a>\"，包括几个板块的内容。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1d/1d4ea4311bd4ceb3f7b9311b50f058e1.png\" /></p><p></p><p>比如，我们底层整合了很多开源社区的技术，包括Apache等顶级开源社区的项目。此外，我们也将自己的XGen模型和风平模型融合进去，构建了一个数字人AIGC的技术中台。</p><p></p><p>其中，中间框架扮演着至关重要的角色。我们制定了开放的内容标准协议，旨在通过不同的AIGC生成的内容，将不同的格式转换成标准化格式输出。从长期来看，这些因素对我们产品和技术的发展至关重要。</p><p>例如，整个内容生成的标准化将决定AIGC生成的效果以及后期的分发程度。另外，对于视频，我们需要确定视频的格式和标准交换协议，这不仅涉及到平台的适配程度，还会严重影响后期内容的分发效果和客户的影响。</p><p></p><p>因此，我们不仅在平台连接方面进行了开放兼容，而且在未来的 AIGC 模式方面也为不同的合作伙伴提供了比较好的连接方式。我们积极推动了几个大平台的数字人模型，并在平台上实现了对 3D 和 2D 模型的转换，这是因为我们希望通过这样的兼容协议来推动整个行业的标准化，降低更多成本，同时也符合开源的思路。</p><p></p><p>另外，值得一提的是，我们还将Data和Model放在同一层级，因为对于更加专注于应用和垂直领域的公司来说，数据和模型至关重要。我们希望通过这个技术中台，结合Human Asset逻辑，探索如何在AIGC文章、视频、直播甚至未来的3D沉浸式视频应用中，实现更好的应用效果。</p><p></p><p>总而言之，一切才刚刚开始。风平智能在这个过程中已经找到了一些有趣的点，并且希望在一些新的领域上取得突破。</p>",
    "publish_time": "2023-05-10 16:45:26",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "蚂蚁数科开发者大会 2023 数据要素分论坛",
    "url": "https://www.infoq.cn/article/AygCQmdhYIuUIWywfTHS",
    "summary": "<p>创新技术与数字经济的发展加速渗透融合，产业应用驱动科技加速变迁和跃升，技术探索者迎来黄金时代。</p>\n<p>我们看到，以CHATGPT为代表的AI技术已经无处不在；元宇宙的沉浸感即将成为现实；依托WEB3和区块链技术的应用，越来越多的去中心化产品和服务涌现出来…数字技术的融合创新发展，为产业数字化带来无限的想象力。</p>\n<p>为此，蚂蚁集团数字科技事业群携手广大同行者，于2023 年4 月 26 日在杭州举办的数字科技开发者大会，邀请到学术界、产业界多位技术领袖及众多WEB3、元宇宙等技术方向的开发者，围绕数据要素市场趋势研判、WEB3前瞻技术探索、元宇宙创新体验等热点话题展开讨论。</p>",
    "publish_time": "2023-05-10 18:00:39",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "16年等待，再见 SQL Boy，这一次数据库交互形态彻底被颠覆了！",
    "url": "https://www.infoq.cn/article/XLYpBmBcFcYEtiJBUNpo",
    "summary": "<p>对于程序员来说，通过 SQL 操作数据库是日常工作中经常会遇到的任务，算得上是一项基本技能。但即便是专业人员面对 SQL 编写任务也往往会头疼不已，更不要说在这一领域经验不足的初学者了。ChatGPT 大火之后，其辅助程序员编写代码的能力受到了很大关注。那么，类似<a href=\"https://www.infoq.cn/video/So2yItKrdYsDZpEG7DjS\"> ChatGPT </a>\"这种能力能否用在数据库操作上，帮助程序员甚至是缺乏代码经验的普通业务人员，使用自然语言来完成过去需要 SQL 才能做的事情呢？在近日举办的亚马逊云开发者 Tech Talk 上，<a href=\"https://xie.infoq.cn/article/83d0bb375b5e3c012280f6dea\">Bytebase</a>\" 联合创始⼈/CEO 陈天舟就介绍了这样一款产品——基于亚马逊云科技的云服务架构，可以用自然语言与数据库交互的 <a href=\"https://xie.infoq.cn/article/0c3421e65a8bb5e1c26c6fe8d\">SQL Chat</a>\"。InfoQ 将本场演讲内容整理成文，希望对大家有所帮助。</p><p></p><p></p><h2>软件交互范式的演进：从命令行到 CUI</h2><p></p><p></p><p>回顾软件行业的交互范式演进史，大致上是从桌面到 Web 端，再到移动端。在上世纪 70 年代，用户一般通过命令后界面（CLI）与计算机交互。发展到 1979 年出现了 VisiCalc， VisiCalc 首次引入了表格布局交互界面，具有革命性的意义。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c3/c303b42f263dc693be18efcf2e74723e.png\" /></p><p></p><p>这款软件还带火了 Apple 2 电脑，让很多个人用户开始采购这款 PC 来制作表格。之后到了 1984 年，苹果发布了 Macintosh，搭配键盘、鼠标并采用了 GUI 界面，这也是现代 PC 所采用的标准界面的起源。再到 1993 年，第一款网页浏览器 Mosaic 诞生。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2e/2e9aa880b8cd2e19f08e2f9687a18766.png\" /></p><p></p><p>这款浏览器开启了 Web 端的时代。继续向前来到 2007 年，iPhone 的发布则开启了现代智能手机时代。这样来看，命令行 CLI 交互大概从 70 年代流行到 1984 年，GUI 的发展则分了三个阶段，首先是 1984-1993 年是桌面端，1993-2007 年是 Web 端，2007 年到现在则是移动端，每一次换代间隔大约 13 年左右。</p><p></p><p>而到了 2023 年的今天，ChatGPT 横空出世。ChatGPT 的交互方式可以称为 Chat User Interface（CUI）。从 2007 年到 2023 年，历经 16 年的等待，软件行业终于迎来了交互范式的又一场革新。</p><p></p><h2>数据库交互与 CUI 革命</h2><p></p><p></p><p>软件交互范式的进化自然也会影响数据库的操作方式。以 SQL 客户端这个具体场景来为例，今天的 SQL 客户端还有很多命令行的交互工具，但业内也存在很多起源于 Windows 的 GUI 工具，比如 Navicat 等。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c6/c661edac859dd41d4e1690bfb462382f.png\" /></p><p></p><p>如今，基于 CUI 的全新交互方式就完全不一样了。CUI 没有大量控件组合，只有一个简单直接的输入框。用户用自然语言问数据库问题，它会神奇地写出对应的 SQL 语句同数据库交互。这种进化能让人想到谷歌诞生之前的雅虎。彼时雅虎在做黄页目录，用户通过线上黄页查找信息；之后谷歌直接推出了搜索框，一个搜索框就能找到互联网的所有内容。现在的数据库交互软件有众多复杂的控件、树、表单，而到了 CUI 时代，所有这些元素都消失了，用户只需一个对话框来输入问题，机器人就能给出回答。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e0/e013ae3706758b086d0996571a0dd1d2.png\" /></p><p></p><p></p><h2>SQL Chat：用自然语言和数据库交互的全新工具</h2><p></p><p></p><p>所谓 SQL Chat，顾名思义就是用聊天的方式写 SQL，跟数据库打交道。下图是整个产品的界面。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/66/66b4a278e326e4cdf680a6988b6f7523.png\" /></p><p></p><p>例如向 SQL Chat 提问，问用户组织里面哪个部门有最多的员工，这个工具就能直接给出对应的 SQL 语句，还会解释这个语句的含义。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8a/8a2e4f872020551803a1780f3eb39212.png\" /></p><p></p><p>如果用户对结果不满意还能纠正它，可以说这个语句不是自己想要的，给出理由让它重新尝试，它会根据用户的反馈再做调整。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5f/5fd88b29d3cbb717316fbd1d3d287eff.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/63/63870ba5a57ddfb49d37ec4c08795aa7.png\" /></p><p></p><p>它的交互方式是很自然的，就像用户在和人类对话一样。例如，用户可以创建一个 Amazon Aurora 的 HR 数据库，之后先问一些基本的问题，让它回答数据库有哪些表。SQL Chat 会知道用户对员工的薪资和职称是最感兴趣的，又知道部门和员工之间是生产关系，知道员工个人信息是个人隐私。</p><p></p><p>如果提问哪个部门的员工平均薪水最高，它不仅会给出 SQL 语句，还会解释这条 SQL 是什么操作。再来问它哪个经理手下人员最多，列出 SQL 代码，它会给出查询语句查到手下员工最多的经理。如果用户对这条查询不是那么满意，还想看一下这位经理到底有多少个员工，请机器人把他的员工数也包含在内，它就会给出修正的查询。</p><p></p><p>但目前 SQL Chat 涉及子查询的时候还是会出现一些问题，可能会报错，提示内容未指定等。这反映出它使用的模型还是有一些局限性，陈天舟表示，这类问题在未来随着调优是可以解决的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/76/764cba1b264cac9c73d9a93f7e01d1ef.png\" /></p><p></p><p>未来，开发团队会收集一些交互数据，把这些数据进行脱敏匿名化处理后放到 Amazon S3 上，再把它灌到 Amazon SageMaker，在 Amazon SageMaker 里做整个模型的训练调优。陈天舟预计，半年后再演示新版 SQL Chat 时就能比较好地解决子查询的问题了。</p><p></p><p>SQL Chat 背后的公司叫做 Bytebase，主要做数据库管理工具。如果企业需要 Schema 的数据结构变更、数据查询，或者团队之间需要有一套标准的审批流，做数据安全治理，Bytebase 的主产品都可以满足。它主要面向团队和企业级，是开源的。下图左边的二维码是亚马逊云开发者社区，右边是 SQL Chat 自己的用户群。SQL Chat 在 GitHub 上是完全开源的 (<a href=\"https://github.com/sqlchat/sqlchat\">https://github.com/sqlchat/sqlchat</a>\")，接下来也会有很快的迭代速度。最后，SQL Chat 后期还有望支持多模态输入，希望大家持续关注。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/96a2d890db6a5afccf11640284e8dad8.png\" /></p><p></p>",
    "publish_time": "2023-05-10 19:08:15",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]