[
  {
    "title": "降本增效：Grab如何在亚马逊云科技上将Kafka消费者流量成本降到零",
    "url": "https://www.infoq.cn/article/bHbaxQSIexCa63uzkJGl",
    "summary": "<p>Kafka 2.3引入了将Apache Kafka消费者连接到相同可用区域（AZ）代理节点的能力，Grab利用这一能力重新配置了消费者，<a href=\"https://engineering.grab.com/zero-traffic-cost\">将亚马逊云科技上的流量成本降低为零</a>\"。这一更改大大降低了在亚马逊云科技上运行Apache Kafka的基础设施总成本。</p><p>&nbsp;</p><p>Grab以Apache Kafka为中心创建了一个流数据平台，支撑公司所有的产品。遵循Kafka最佳实践，他们的初始配置为每个Kafka分区三个副本，横跨亚马逊云科技区域中三个不同的可用区。负责该平台的团队观察到，跨AZ流量占了他们Kafka平台一半的成本，因为<a href=\"https://aws.amazon.com/ec2/pricing/on-demand/#Data_Transfer_within_the_same_AWS_Region\">亚马逊云科技对跨AZ数据传输收费</a>\"。</p><p>&nbsp;</p><p>对于初始设置的成本，<a href=\"https://www.linkedin.com/in/fhcloud/\">Fabrice Harbulot</a>\"和<a href=\"https://www.linkedin.com/in/quangminhtran94/\">Quang Minh Tran</a>\"的看法如下：</p><p></p><blockquote>这种设计的问题在于，它会产生惊人的跨AZ网络流量。这是因为，在默认情况下，Kafka客户端只与分区leader通信，而分区leader有67%的概率驻留在不同的AZ中。</blockquote><p></p><p>&nbsp;</p><p>跨AZ流量包括新发布的消息、代理之间的数据复制和消费者获取的消息。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/28/28e5bb967e34b588ddf31b00dcdf2ea0.jpeg\" /></p><p></p><p>默认消费者配置，消费者从分区leader获取数据（图片来源：<a href=\"https://engineering.grab.com/zero-traffic-cost\">Grab工程博客</a>\"）</p><p>&nbsp;</p><p>从<a href=\"https://archive.apache.org/dist/kafka/2.3.0/RELEASE_NOTES.html\">Apache Kafka 2.3</a>\"开始，可以将消费者配置为从分区副本中获取数据了。这样，如果消费者只从同一AZ中的代理获取消息，就不会产生数据传输成本了。</p><p>&nbsp;</p><p>这个特性要求Kafka代理和消费者都知道其所在的AZ。对于Kafka代理，团队会使用AZ ID（az1、az2、az3等）配置broker.rack 。AZ ID与AZ名称（1a、1b、1c等）不同，因为<a href=\"https://docs.aws.amazon.com/ram/latest/userguide/working-with-az-ids.html\">AZ名称在亚马逊云科技账户间不一致</a>\"。他们还将参数replica.selector.class的值设置为org.apache.kafka.common.replica.RackAwareReplicaSelector。</p><p>&nbsp;</p><p>在消费者端，团队更新了内部Kafka SDK，基于EC2主机元数据用AZ ID配置client.rack 参数，为的是应用程序团队可以通过导出环境变量来启用该功能。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/98/9898f68a5854abb6c400ea677498a3f4.jpeg\" /></p><p></p><p>自定义消费者配置，消费者从最近的副本获取数据（图片来源：<a href=\"https://engineering.grab.com/zero-traffic-cost\">Grab工程博客</a>\"）</p><p>&nbsp;</p><p>在某些服务上应用新设置后，团队观察发现，跨AZ流量成本下降，并且有一些值得注意的副作用。首先，端到端延迟最多增加了500毫秒。考虑到大多数消费者从副本获取消息，这也是意料之中的。延迟增加是由复制时间导致的。理论上，任何对延迟敏感的数据流都应该始终从分区leader获取数据，即使那样会产生额外的成本。</p><p>&nbsp;</p><p>其次，在代理维护（停机）时，直接从副本获取消息的消费者可能会遇到代理不可用的情况，因此，它们应该等待/重试，直到同一AZ中的代理恢复在线。最后，团队观察到，代理的负载与跨AZ的消费者数量有关。这意味着，消费者的均匀分布对于确保代理的负载平衡至关重要。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/07/grab-apache-kafka-aws-cost/\">https://www.infoq.com/news/2023/07/grab-apache-kafka-aws-cost/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/ZHFZHsctlAhN8Ai9wdpo\">Cloudflare的Kafka之旅：万亿级消息处理实践</a>\"</p><p><a href=\"https://www.infoq.cn/article/CpfvECIb5gWdditBBYy7\">使用Strimzi提高Kafka集群的安全性</a>\"</p><p></p>",
    "publish_time": "2023-09-07 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "山一程，水一程！飞书OKR从People剥离",
    "url": "https://www.infoq.cn/article/5f26843427abd574f5bd6ab98",
    "summary": "<p>飞书产品族8月调整，将OKR从People产品族剥离，纳入Office产品族。</p><p></p><p>【山一程】2020年发布飞书OKR，花了很大力气宣传。OKR成名于1999年约翰.杜尔在Google做的管理实验，国内又火了一把，真是管理落后20年吗？</p><p>【水一程】2022年顺势推出People，目标是输出HR全模块套件，当然也包括OKR，全面进入一体化赛道，Buff加满。</p><p>【又一程】2023年8月，OKR作为飞书的种子产品，差异标签，必争之地，却从HR管理挪到办公协同，有什么逻辑变化？&nbsp;</p><p></p><p>事实上，三年来，选择以HR逻辑推广企业级OKR，成功挺难。这波OKR行情，从概念澄清而起，到假设混淆而失。</p><p></p><p>对OKR的概念澄清，飞书选择与KPI做Apple&nbsp;to Apple的直观比较，但问题就在这里。飞书发布的OKR理论手册中写到：</p><p>什么是 KPI ？</p><p>KPI 是 Key Performance Indicator 的缩写，中文名称是「关键绩效指标」，即一系列衡量工作成效的重要指标。</p><p>什么是 OKR ？</p><p>OKR 是 Objective and Key Results 的缩写，中文名称是「目标与关键结果法」，是一套帮助组织实现目标管理、推动执行与协作的工具和方法。</p><p></p><p>单看都对，本意是区分两种方式的场景和用法。可是，比较即观点，加上饱和宣传，挑战式销售，进场辅导，即视感拉满，传递给市场的观点是OKR比KPI高级。</p><p></p><p>【混淆了什么？】</p><p>一：混淆了经营假设</p><p>1999年，Google只有60来人，正如我在前文提到，杜尔引入OKR算不上管理变革， 而是一个管理实验；OKR源头Intel当时很大，可那是PC时代的Intel。&nbsp;面向增长，OKR有试错空间，而面向效率的时候，推动OKR的时间往往不够。</p><p>二：混淆了管理假设&nbsp;</p><p>这么说吧，</p><p>KPI管理目标， OKR驱动目标感。&nbsp;</p><p>KPI是射箭，最高就是十环；OKR是跳高，没必要限制。&nbsp;</p><p></p><p>为什么OKR目标二个月折叠一次最妙？为什么OKR目标要与绩效评估隔离？为什么OKR目标不要超过五个？为什么OKR目标要全员公开？为什么立个目标，会如下图这般对错分明，这是在用OKR签字画押吗？</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cd/cd14f130e1de79c7f22a34d3c3ab6901.png\" /></p><p></p><p>来源：飞书发布的OKR理论手册【侵删】</p><p>如此之重的OKR教条怎么驱动团队的目标感，根本忘记了杜尔多次现场演讲提到的，OKR的胜负手就是简单。</p><p></p><p>【OKR和KPI比较导致了什么】？</p><p>OKR与KPI的这种高下之分，客户潜意识接受了观点，用OKR替代KPI，或者从KPI升级到OKR。将一个长期的推动团队自驱，建立目标感的有氧过程，变成短期调整目标管理制度的无氧冲击。往往是由HR牵头OKR专项，HR流程中增加OKR目标设定，HR应用中再配套开发一个OKR App，全错了。&nbsp;</p><p></p><p>这个时候该问了，“&nbsp;你也在做OKR和KPI的对比啊，&nbsp;那你也错了。”人间清醒，其实只要上升一层，OKR本质上是与PFP（Pay for Performance）的区别。不是Apple To Apple，而是Apple To Ant。</p><p></p><p>OKR驱动目标感，解决团队信任问题的，业务主导；记得和特斯联创始人探讨的点，如何通过OKR共识目标，而不只是对齐目标？和知识星球创始人探讨的点，100多人的Startup，规模没到邓巴数的时候，有必要用OKR代替吼一嗓子吗？真正的需求是信任。</p><p>PFP管理目标，解决团队公平问题的，HR主导。主流的五种，KPI只是其中之一，与KPI比较的，应该是同层的这些绩效管理方法。几十年的各种实践，已经把绩效目标搞透了。&nbsp;比如，同样是PBC，IBM管结果和华为管行为；同样是BSC，科技公司较少公开组织绩效，国企反而较多公开组织绩效。什么样的选择对应什么样的底层逻辑，活学活用，很清晰。&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1d/1db9ab6b5d72fed3dadc40cc85f53954.png\" /></p><p>KPI/BSC/PBC/MBO/CPM，这些都是PFP&nbsp;</p><p></p><p>有哪家企业能放弃PFP三步管理（目标设定，绩效评估，薪酬激励）？过去三年，除了把PFP换个时髦的OKR的说法，有哪家企业彻底放弃过？阿里从今年3月份喊出要用OKR全面替代KPI，到8月份就改口为OKR+KPI，因为搞清楚了， 把一年两次3.25/3.75打分，变为一年四次，本质还是KPI。&nbsp;&nbsp;</p><p></p><p>HR做的OKR，只给工具，不锚定问题的时候，一定错了；</p><p>工作重心在哪里，OKR就在哪里填，不求归口。&nbsp;举个例子，产品团队在TAPD里填， 研发团队在Gitlab里填，交付团队在项目工具里填，销售团队在CRM里填，&nbsp;OKR需要数据带感，需要业务数据和OKR目标背靠背，经不起时间和流程的消磨。&nbsp;</p><p></p><p>HR做的OKR，只做加法，不做减法的时候，一定错了。&nbsp;</p><p>HR能发起两次目的不同的目标填写吗（跳高和射箭），解释很复杂，注定会失败。而管理者以办公协同为入口，按自己的管理直觉（松紧和节奏），和工作会议结合，发起OKR的填写，晾晒，都很自然。OKR需要体验带感，简单唤起，用完即走，经不起复杂和耐心的考验。&nbsp;</p><p></p><p>飞书这次将OKR从People转到Office，行百里半九十，&nbsp;换换产品目录代替不了产品重构，过去三年高强度打市场也说明，现象级OKR产品，需要改造，避免最后只能捆绑办公，免费搭售。</p><p></p><p>实践参考：在会议入口，文档入口，Chatbot入口，Wiki入口，以对话GUI替代小程序GUI，通过个人号，工作群ID和CoreHR关系链鉴权，对话唤起分散在各生产系统中的OKR JS Page地址来填写，对齐，修改，折叠和设定；对话唤起本团队，跨团队的目标数据聚合，晾晒，围观，@公开等功能。&nbsp;尽量简单，盲盒打法，让用户自己摸索，组装这些能力。&nbsp;</p><p></p><p>想远一点：HR科技处在从数字化走向企效化的关口，即HRTech与WorkTech融合后，提供更快的企效服务。如小红书成立企效中心， 腾讯成立HR科技中心，都是探索。&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/72/7247a36cffe08a249c0a12a1042960f0.png\" /></p><p>基于HRTech实践和国内外技术趋势报告的总结</p><p>揽月不达，或可摘星。&nbsp;无论OKR目标还是KPI目标，无论自驱意图还是管理意图，都趋向高设定。细枝末节的比较，只会迷失目标。OKR产品和落地方案，决策者要先考虑For What，再讲How To。讲清楚企业绩效的推升效果怎么算，判断企业是强执行还是强自驱，了解团队沟通方式的接受度，再选择怎么做，因为免费的可能才是最贵的。</p><p></p><p>原文链接：<a href=\"https://mp.weixin.qq.com/s?__biz=MzAwNjI2MTA2MQ==&amp;mid=2247483787&amp;idx=1&amp;sn=b7f3c187f45fb098651bb3c521df66ee&amp;chksm=9b1151a1ac66d8b749954ced6dd03dfe9f579255100658e2c52d46cf853f686b01d8ef30d636&amp;token=820966871&amp;lang=zh_CN#rd\">山一程，水一程！飞书OKR从People剥离</a>\"</p>",
    "publish_time": "2023-09-07 00:13:33",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "全面拥抱大模型！腾讯正式开放全自研通用大模型：参数规模超千亿、预训练语料超2万亿tokens",
    "url": "https://www.infoq.cn/article/HXQtZJxYy5SeK9OH3Xzi",
    "summary": "<p>9月7日，2023腾讯全球数字生态大会上，腾讯集团高级执行副总裁、云与智慧产业事业群CEO汤道生正式发布全链路自研的通用大语言模型：混元大模型。混元大模型具备强大的中文创作能力、复杂语境下的逻辑推理能力，以及可靠的任务执行能力。</p><p></p><p>汤道生表示：“以大模型生成技术为核心，人工智能正在成为下一轮数字化发展的关键动力，也为解决产业痛点带来了全新的思路。大模型需要基于产业场景，与企业数据融合，才能释放出最大的价值。”</p><p>&nbsp;</p><p>据悉，腾讯混元大模型参数规模超千亿，预训练语料超2万亿tokens，当前版本的知识截止到2023年7月。混元大模型基于Transformor，首先进行大规模自监督预训练，之后进行有监督精调，最后通过强化学习进行优化，同时具有一定调用外部插件工具的能力。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/9b/9bf1683f4a50499550200ac6eeebc64f.png\" /></p><p>混元大模型推理能力展示</p><p>&nbsp;</p><p>腾讯集团副总裁蒋杰表示，开源大模型并不适应腾讯海量高并发场景，自研才能完全掌握技术内核，将大模型更好地融入到腾讯的技术栈中。据悉，混元大模型以腾讯强大的算力基础设施为基础，腾讯掌握从模型算法到机器学习框架再到AI基础设施的全链路自研技术，包括从大规模、高质量、多样化的语料库，到创新的大模型算法，再到自研Angel机器学习框架和创新性的训练方法等研发能力。</p><p>&nbsp;</p><p>针对大模型容易“胡言乱语”的问题，腾讯通过自研“探真”算法进行事实修正，让混元大模型的幻觉相比主流开源大模型降低了30%-50%；通过强化学习的方法，让模型学会识别陷阱问题，对安全诱导问题的拒答率提高了20%；通过位置编码优化，提高了超长文的处理效果和性能；提出思维链的新策略，强化模型对问题拆解和分布思考的趋向，让大模型能够像人一样结合实际的应用场景进行推理和决策。此外，腾讯还自研了机器学习框架Angel，使训练速度相比业界主流框架提升1 倍，推理速度比业界主流框架提升1.3倍。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/b7/b7f2c844eed7b2cc3552b1d16cf327f1.jpeg\" /></p><p>混元大模型测评数据</p><p>&nbsp;</p><p>蒋杰表示，混元大模型已经成为腾讯的业务底座。目前，腾讯云、腾讯广告、腾讯游戏、腾讯金融科技、腾讯会议、腾讯文档、微信搜一搜、QQ浏览器等50多个腾讯内部业务和产品，已经接入腾讯混元大模型测试并取得初步效果。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/c0/c03c5f832c01b42956a65d805992c569.jpeg\" /></p><p>&nbsp;</p><p>混元大模型在腾讯文档的应用示范</p><p>&nbsp;</p><p>据了解，混元大模型将作为腾讯云MaaS（Model-as-a-Service）服务的底座，客户不仅可以直接通过API调用混元，也可以将混元作为基底模型，为不同产业场景构建专属应用。</p><p>&nbsp;</p><p>据悉，从2018年开始，腾讯开始探索大模型相关技术，先后推出了多个千万/亿参数大模型：2019年，腾讯推出了广告推荐MoE大模型，单模型参数超千亿；2021年，腾讯推出了千亿规模的 NLP大模型；2022年，腾讯推出万亿参数的NLP稀疏大模型。</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-09-07 11:21:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]