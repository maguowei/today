[
  {
    "title": "兴业银行大数据基础平台负责人刘家闰确认出席FCon，分享兴业银行实时数据服务实践",
    "url": "https://www.infoq.cn/article/8xpD4tKr4cur5ZGpX08F",
    "summary": "<p><a href=\"https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle\">FCon 全球金融科技大会</a>\"，将于 11 月在上海召开。兴业银行大数据基础平台负责人刘家闰将发表题为《<a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5581?utm_source=infoqweb&amp;utm_medium=article\">兴业银行实时数据服务实践</a>\"》主题分享，介绍兴业银行大数据平台体系、实时数据服务模块的技术实践和应用赋能，以及在业务场景的驱动下兴业银行关于流批一体的探索。</p><p></p><p><a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5581?utm_source=infoqweb&amp;utm_medium=article\">刘家闰</a>\"，兴业银行大数据资深专家，大数据基础平台负责人。多年的大数据技术实施和设计经验。负责兴业银行大数据服务底层基础平台建设。参与规划和设计兴业银行大数据基础服务能力（离线和实时）建设，具有丰富的实时数据服务应用开发经验。 他在本次会议的演讲内容如下：</p><p></p><p>演讲：兴业银行实时数据服务实践</p><p></p><p>本次演讲主要围绕兴业银行大数据平台体系，重点介绍实时数据服务模块的技术实践和应用赋能，以及在业务场景的驱动下兴业银行关于流批一体的探索。</p><p></p><p>大数据基础平台是兴业银行在大数据领域实践和应用的关键底层平台，最早基于 Hive 主要提供历史数据的存储及服务，后经历了全方面的版本及服务升级后现已成为集离线计算、实时计算、联机分析、租户服务等多功能模块为一体的企业级 PaaS 平台。</p><p></p><p>近几年，随着业务场景对数据实效性的要求越来越高，传统的 T+1 式离线数据服务已无法满足业务诉求，兴业银行也早早布局，探索实时数据服务技术实践，形成了一套自己的实时数据服务体系，并迅速在行内进行了推广及落地，目前已为实时分析、实时推荐、实时营销、实时风控等多个业务场景赋能。</p><p></p><p>在实时数据服务技术不断发展的情况下，离线计算和实时计算如何整合、批量数据和流式数据如何作为一个整体提供服务也成为一个重要课题，兴业银行近两年也在流批一体技术上进行了诸多探索，根据行内数据应用的实际情况，确认了符合兴业银行数字化转型路线方针的流批一体技术建设目标和思路，并开展了对应的架构规划和实践落地。</p><p></p><p>演讲提纲：</p><p></p><p>兴业银行大数据平台体系架构兴业银行实时数据服务技术实践兴业银行实时数据服务赋能业务场景兴业银行关于流批一体的探索</p><p></p><p>你将获得：</p><p></p><p>○ 了解银行业大数据平台体系架构发展历史</p><p>○ 了解兴业银行在实时数据服务上的技术实践，包括难点和解决方案</p><p>○ 了解兴业银行如何通过实时数据服务赋能业务场景</p><p>○ 了解兴业银行关于流批一体的探索，包括技术选型和业务效果</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle\">DevOps&nbsp;在金融企业落地实践</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle\">金融行业大模型应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle\">创新的金融科技应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle\">金融实时数据平台建设之路</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle\">金融安全风险管控</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle\">数据要素流通与数据合规</a>\"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，享 7 折优惠 ，立省 ￥2040！咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png\" /></p><p></p>",
    "publish_time": "2023-10-23 11:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Java近期新闻：Candidate状态的新JEP、Spring Cloud、GlassFish、Helidon、Open Liberty和Apache Camel",
    "url": "https://www.infoq.cn/article/e80m9oTedEfNEL15GFAR",
    "summary": "<p></p><h4>OpenJDK</h4><p></p><p></p><p>JEP 457，<a href=\"https://openjdk.org/jeps/457\">Class-File API（预览）</a>\"已经从Draft 8280389<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-September/008279.html\">提升</a>\"到了Candidate状态。该JEP建议提供用于解析、生成和转换Java类文件的API。它最初作为JDK中Java字节码操作和分析框架<a href=\"https://asm.ow2.io/\">ASM</a>\"的替代品，并计划将其作为公共API对外开放。甲骨文的Java语言架构师<a href=\"https://www.linkedin.com/in/briangoetz\">Brian Goetz</a>\"将ASM称为“带有大量遗留包袱的旧代码库”，并提供了该草案将如何发展并最终取代ASM的<a href=\"https://mail.openjdk.org/pipermail/discuss/2022-June/006131.html\">背景信息</a>\"。</p><p></p><p>JEP 456，<a href=\"https://openjdk.org/jeps/456\">未命名变量和模式（Unnamed Variables and Patterns）</a>\"已经从Draft 8311828<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-September/008271.html\">提升</a>\"至Candidate状态，以完成该特性的上一轮预览，即JDK 21中的JEP 443，<a href=\"https://openjdk.org/jeps/443\">未命名变量和模式（Unnamed Patterns and Variables，预览）</a>\"。这个JEP建议”用未命名的模式和未命名变量来增强语言，前者与记录组件相匹配，但无需说明组件的名称和类型，后者可以被初始化但不使用“。 这两者均由下划线字符表示，如r instanceof _(int x, int y)和r instanceof _。</p><p></p><p>JEP 455，<a href=\"https://openjdk.org/jeps/455\">模式、instanceof和switch中的原始类型（预览）</a>\"已经从Draft 8288476<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-September/008270.html\">提升</a>\"到了Candidate状态。该JEP建议“通过允许在所有模式上下文中使用原始类型来增强模式匹配，使原始类型模式的语义与instanceof一致，并扩展switch以允许原始常量作为case标签”。</p><p></p><p>甲骨文公司的软件开发总监<a href=\"https://www.linkedin.com/in/jlaskey/\">Jim Laskey</a>\"提交了JEP Draft 8314219，<a href=\"https://openjdk.org/jeps/8314219\">字符串模板（String Templates）</a>\"，以完成该特性的上一轮预览，即JDK21中的JEP 430，<a href=\"https://openjdk.org/jeps/430\">字符串模板（预览）</a>\"。该JEP通过字符串模板（包含嵌入式表达式的字符串字面量）增强了Java编程语言，字符串模板会在运行期解释执行，在这个过程中嵌入式表达式会被评估和校验。关于JEP 430的更多详情，请参阅InfoQ的<a href=\"https://www.infoq.com/news/2023/04/java-gets-a-boost-with-string/\">新闻报道</a>\"。</p><p></p><h4>JDK 22</h4><p></p><p></p><p>JDK 22早期访问版本的<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-22%2B17\">Build 17</a>\"发布，该版本是对Build 16的<a href=\"https://github.com/openjdk/jdk/compare/jdk-22%2B16...jdk-22%2B17\">更新</a>\"，包含对各种<a href=\"https://bugs.openjdk.org/issues/?jql=project%20%3D%20JDK%20AND%20fixversion%20%3D%2022%20and%20%22resolved%20in%20build%22%20%3D%20b17%20order%20by%20component%2C%20subcomponent\">问题</a>\"的修复。有关该版本的更多详情，请参阅<a href=\"https://jdk.java.net/22/release-notes\">发布说明</a>\"。</p><p></p><p>对于<a href=\"https://openjdk.org/projects/jdk/22/\">JDK 22</a>\"，鼓励开发人员通过<a href=\"https://bugreport.java.com/bugreport/\">Java缺陷数据库</a>\"报告缺陷。</p><p></p><h4>Eclipse GlassFish</h4><p></p><p></p><p>Eclipse&nbsp;<a href=\"https://glassfish.org/\">GlassFish</a>\"&nbsp;7.0.9是<a href=\"https://twitter.com/OmniFishEE/status/1707784618286444700\">第九个维护版本</a>\"，包含了组件升级和重要的缺陷修复，比如，试图将带有EJB远程接口的应用程序部署到<a href=\"https://glassfish.org/docs/SNAPSHOT/embedded-server-guide.html\">嵌入式GlassFish</a>\"时会出现IllegalArgumentException；ServletContextListener接口中定义的contextInitialized()方法在部署时会调用多次；stop-local-instance命令行参数无法停止服务器实例。关于该版本的更多详情，请参阅<a href=\"https://github.com/eclipse-ee4j/glassfish/releases/tag/7.0.9\">发布说明</a>\"。</p><p></p><p>OmniFish的总监<a href=\"https://www.linkedin.com/in/mihalyiondrej/\">Ondro Mihályi</a>\"一直在为GlassFish<a href=\"https://twitter.com/OndroMih/status/1706096467843174683\">开发</a>\"对虚拟线程的支持，并提供了<a href=\"https://github.com/OmniFish-EE/glassfish-grizzly-virtual-threads-pool/blob/main/README.md\">可运行的样例</a>\"。</p><p></p><h4>Jextract项目</h4><p></p><p></p><p>Jextract项目向Java社区提供了基于JDK 21的<a href=\"https://jdk.java.net/jextract/\">早期访问构建版本</a>\"Build 21-jextract+1-2。要使用该构建版，在MacOS Catalina或更高版本上运行的开发人员需要在使用jextract二进制文件之前需要移除quarantine属性。</p><p></p><p>由于Panama项目<a href=\"https://jdk.java.net/panama/\">早期访问构建</a>\"中的大多数特性均已转移到孵化JEP，jextract（一个从原生库头信息生成Java绑定的工具）依然是唯一的特性，因此将会在其自己的项目中进行维护。</p><p></p><h4>Spring Framework</h4><p></p><p></p><p><a href=\"https://spring.io/projects/spring-cloud\">Spring Cloud</a>\"&nbsp;2023.0.0（代号为Leyton）的<a href=\"https://spring.io/blog/2023/09/29/spring-cloud-2023-0-0-m2-aka-leyton-has-been-released\">第二个里程碑版本发布</a>\"，它包含了如下特性：将所有Spring Cloud项目文档迁移至<a href=\"https://antora.org/\">Antora</a>\"（多资源库文档站点生成器）；对Spring Cloud Commons 4.1.0-M2、Spring Cloud Starter Build 2023.0.0-M2和Spring Cloud Kubernetes 3.1.0-M2等子项目进行里程碑升级。关于该版本的更多信息，请参阅<a href=\"https://github.com/spring-cloud/spring-cloud-release/wiki/Spring-Cloud-2023.0-Release-Notes\">发布说明</a>\"。</p><p></p><h4>Helidon</h4><p></p><p></p><p><a href=\"https://helidon.io/\">Helidon</a>\"&nbsp;4.0.0的<a href=\"https://medium.com/helidon/release-candidate-1-for-helidon-4-released-8c2c135154c1\">第一个发布候选版本</a>\"带来了缺陷修复、依赖升级和值得注意的变更，例如，对API进行了重大重构和稳定化；支持HTTP/2；<a href=\"https://helidon.io/docs/v3/#/se/webserver\">WebServer</a>\"和<a href=\"https://helidon.io/docs/v3/#/se/webclient\">WebClient</a>\"组件已经宣布功能完备。关于该版本的更多信息，请参阅<a href=\"https://github.com/helidon-io/helidon/releases/tag/4.0.0-RC1\">发布说明</a>\"。</p><p></p><h4>Open Liberty</h4><p></p><p></p><p>IBM<a href=\"https://openliberty.io/blog/2023/09/26/23.0.0.10-beta.html\">发布</a>\"了<a href=\"https://openliberty.io/\">Open Liberty</a>\"的23.0.0.10-beta版本，该版本包含如下特性：支持JDK 21和即将发布的MicroProfile 6.1；使用Spring Boot 3.0和InstantOn with Coordinated Restore at Checkpoint（CRaC）改进了Spring Boot应用的启动时间；Jakarta Data规范的beta 3实现；自动生成和轮换<a href=\"https://www.ibm.com/docs/en/acvfc?topic=authentication-ltpa-keys\">Lightweight Third Party Authentication</a>\"（LTPA）密钥，而不会影响应用的用户体验。</p><p></p><h4>Apache软件基金会</h4><p></p><p></p><p><a href=\"https://camel.apache.org/\">Apache Camel</a>\"的<a href=\"https://www.mail-archive.com/announce@apache.org/msg08525.html\">4.0.1</a>\"和<a href=\"https://www.mail-archive.com/announce@apache.org/msg08532.html\">3.21.1</a>\"版本都提供了值得关注的改进，比如：为OpenTelemetry提供了跟踪每个处理器的跟踪策略；在日志中屏蔽了名为“secret”的环境变量；防止在生产者端点中使用代理协议。关于这些版本的更多详情，请参阅<a href=\"https://camel.apache.org/releases/release-4.0.1/\">4.0.1版本</a>\"和<a href=\"https://camel.apache.org/releases/release-3.21.1/\">3.21.1版本</a>\"的发布说明。</p><p></p><h4>JHipster</h4><p></p><p></p><p><a href=\"https://www.jhipster.tech/jhipster-lite/\">JHipster Lite</a>\"&nbsp;0.43.0版本<a href=\"https://twitter.com/pascalgrimaud/status/1707101276863946933\">发布</a>\"，其中包括缺陷修复、依赖升级和新特性/增强，例如，将原来的LogsSpy类拆分为LogsSpy和LogsSpyExtension类，以遵循单一职责原则并避免暴露JUnit5相关的方法；用<a href=\"https://vitest.dev/\">Vitest</a>\"取代<a href=\"https://sinonjs.org/\">Sinon</a>\"&nbsp;JavaScript框架的使用。关于该版本的更多详情，请参阅<a href=\"https://github.com/jhipster/jhipster-lite/releases/tag/v0.43.0\">发布说明</a>\"。</p><p></p><h4>JDKMon</h4><p></p><p></p><p><a href=\"https://github.com/HanSolo/JDKMon\">JDKMon</a>\"的<a href=\"https://github.com/HanSolo/JDKMon/releases/tag/17.0.77\">17.0.77</a>\"和<a href=\"https://github.com/HanSolo/JDKMon/releases/tag/17.0.75\">17.0.75</a>\"版本发布，它是一个用来监控和更新已安装JDK的工具。该工具由Azul的首席工程师<a href=\"https://de.linkedin.com/in/gerritgrunwald\">Gerrit Grunwald</a>\"创建，这些版本提供了：最新的更新文档；在“About”对话框中添加了指向GitHub发行版的链接。</p><p></p><h4>JobRunr</h4><p></p><p></p><p><a href=\"https://www.jobrunr.io/\">JobRunr</a>\"是一个用于分布式后台处理并由持久性存储作为支撑的Java库，它发布了6.3.2版本，其中包括了缺陷修复、依赖升级和一项新的特性，即增加了在Quarkus中对GraalVM原生可执行文件的支持。关于该版本的更多详情，请参阅<a href=\"https://www.jobrunr.io/\">发布说明</a>\"。</p><p></p><h4>Yupiik</h4><p></p><p></p><p><a href=\"https://www.yupiik.io/fusion/\">Yupiik Fusion</a>\"&nbsp;1.0.8<a href=\"https://www.yupiik.io/blog/release-yupiik-fusion-1.0.8.html\">发布</a>\"，提供了以下新特性：确保span标签只能为字符串，否则将需要一个额外的映射步骤；支持enum类型；改善模板处理；用来支持限流的新类RateLimiter和RateLimitedClient。关于该版本的更多详情，请参阅<a href=\"https://github.com/yupiik/fusion/releases/tag/fusion-1.0.8\">发布说明</a>\"。</p><p></p><h4>Gradle</h4><p></p><p></p><p><a href=\"https://gradle.org/\">Gradle</a>\"&nbsp;8.4的<a href=\"https://github.com/gradle/gradle/releases/tag/v8.4.0-RC3\">第三个候选版本</a>\"发布，提供了如下特性：鉴于Kotlin尚不支持JDK 21，仅对JDK 21提供了初步支持，以编译、测试和运行Gradle项目；改进了在Windows操作系统上的编译；简化了使用ConfigurationContainer接口创建以角色为中心的Configuration接口实例的方法；改进了对<a href=\"https://docs.gradle.org/8.4-rc-1/userguide/kotlin_dsl.html\">Kotlin DSL</a>\"的支持。关于该版本的更多详情，请参阅&nbsp;<a href=\"https://docs.gradle.org/8.4-rc-3/release-notes.html\">发布说明</a>\"。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/10/java-news-roundup-sep25-2023/\">Java News Roundup: New JEP Candidates, Spring Cloud, GlassFish, Helidon, Open Liberty, Apache Camel</a>\"</p>",
    "publish_time": "2023-10-23 11:44:54",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "智谱AI完成超25亿人民币融资，将用于基座大模型的进一步研发",
    "url": "https://www.infoq.cn/article/AXXtqD6xU6FghjsNE408",
    "summary": "<p>北京智谱华章科技有限公司（以下简称“<a href=\"https://www.infoq.cn/article/AGirUVdTebuhGKLHvR0a?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">智谱AI</a>\"”）宣布今年已累计获得超25亿人民币融资，参与方主要包括社保基金中关村自主创新基金（君联资本为基金管理人）、美团、蚂蚁、阿里、腾讯、小米、金山、顺为、Boss直聘、好未来、红杉、高瓴等多家机构及包括君联资本在内的部分老股东跟投，华兴担任独家财务顾问。据悉，上述融资将用于基座大模型的进一步研发，更好地支撑行业生态，与合作伙伴一同高速发展。</p><p>&nbsp;</p><p>一直以来，智谱AI专注于做大模型的自研创新。2020年，智谱AI开始了GLM预训练架构的研发，并训练了百亿参数模型GLM-10B。2021年，公司利用MoE架构成功训练出万亿稀疏模型，于次年合作研发了双语千亿级超大规模预训练模型GLM-130B，并基于此千亿基座模型开始打造大模型平台及产品矩阵。2023年，智谱AI推出了千亿基座的对话模型ChatGLM，并开源单卡版模型ChatGLM-6B，使得研究者和个人开发者进行微调和部署成为可能。当前，智谱AI的开源模型在全球下载量已超过1000万次。在细分领域方面，智谱AI也打造了AIGC模型及产品矩阵，包括生成式AI提效助手智谱清言、高效率代码模型CodeGeeX等。</p><p>&nbsp;</p><p>对于本次融资，顺为资本合伙人程天表示，随着数字化和智能化时代的到来，生成式AI通用模型逐渐成为新一轮科技创新的焦点。模型之于现代科技产品，犹如核心技术的“心脏”，承载着信息处理和智能决策的重要功能。“现阶段，智谱AI已成为国内大模型行业的佼佼者之一。它所提供的开源双语预训练语言模型GLM-130B和开源双语对话模型ChatGLM-6B都在行业内获得了广泛的认可。公司在模型技术研发上的能力和在市场落地策略上的前瞻性，都表明了其在国内市场取得阶段性领先地位。”</p><p>&nbsp;</p><p>君联资本总裁李家庆表示，人工智能产业处于快速发展阶段，商业化场景正从实验室走向产业化生产，人工智能技术将实现从感知智能到认知智能的新突破，在科技情报、虚拟数字人等领域，基于认知智能搭建的行业通用平台市场空间巨大。“大模型+大算力”是迈向通用人工智能的可行路径，未来基于大模型形成的变革性AI产业基础设施将改变当前单一模型对应单一任务的人工智能研发范式，多模态大模型将成为不同领域的共性平台技术。“目前，智谱AI已取得多项国际领先的AI技术突破，在超大规模智能模型训练技术体系中占据领先地位，已具备构建我国人工智能应用通用基础设施的实力，未来有望通过推动人工智能技术的变革，为大量行业的开发者赋能，形成智能应用生态，成长为全球认知智能平台领军者。”</p><p>&nbsp;</p><p>智谱AI表示，未来将基于完整的模型生态和全流程技术支持，继续为千行百业带来持续创新与变革，加速迈向通用人工智能的时代。</p>",
    "publish_time": "2023-10-23 12:25:58",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "重点裁技术和管理！领英重创核心工程团队，技术管理占据20%",
    "url": "https://www.infoq.cn/article/mUHYrJNHVwIX2V64E0AK",
    "summary": "<p>编译 | 核子可乐、Tina</p><p>&nbsp;</p><p>根据外媒CNBC看到的一份备忘录，微软旗下LinkedIn本周一已宣布裁撤近700名员工，其中大部分来自工程技术部门。据一位不愿透露姓名（未经讨论授权）的知情人士称，LinkedIn的财务和人力资源部门也同样受到裁员波及。</p><p>&nbsp;</p><p>LinkedIn 成立于 2002 年，是最古老的社交网站之一，至今仍在不断发展。微软在 2016 年斥资 262 亿美元收购了 LinkedIn，这在当时来说还是其有史以来最大的一笔收购。</p><p>&nbsp;</p><p>此次裁员的核心理由，据说在于这家以商业为导向的社交网络收入连续第八个季度遭遇同比增长放缓。微软曾在今年7月表示，尽管过去两年间每个季度的会员数量仍在增加，但第二季度的增长率已跌至仅5%。</p><p>&nbsp;</p><p></p><h2>工程技术最受影响</h2><p></p><p>&nbsp;</p><p>LinkedIn公司高管莫霍克·史洛夫（Mohak Shroff）和托默·科恩（Tomer Cohen）撰写的备忘录已发送给现任员工，并于今天在网上公布，其中还附有一份关于失业情况的更详细说明。&nbsp;</p><p>&nbsp;</p><p>根据备忘录，LinkedIn 研发部门将裁减 563 个职位，包括 38 个产品经理职位，其中管理层被裁人数竟高达137位。据网友消息，Linkedin此轮裁员前大约有6000名工程师，其中技术岗约5000位，管理岗约1000位。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/41/416d099bb28d95f9d9893ccb08505d79.jpeg\" /></p><p></p><p>&nbsp;</p><p>另外，管理层被裁员比例达到了20%，这个数据高得让人吃惊。有人猜测这是因为LinkedIn公司里工程人员与经理的比例是经典的 1:4。显然之前这个设置与<a href=\"https://www.infoq.cn/article/QS7fCm6sciNqjwwk3Tu9\">目前追求“扁平化”管理的潮流不太符合。</a>\"</p><p>&nbsp;</p><p>今年上半年，Meta、Salesforce 和 Amazon 也都在削减中层管理人员，追求组织的“扁平化”。 最早开始于 Meta，扎克伯格大刀阔斧地淘汰了一些中层管理人员，将许多主管降级为被监督的对象，他称不能让“经理管经理、经理再管经理、最后才能管理工作人员”这样的无限套娃继续存在。其他较小的企业纷纷效仿，Shopify 也通过“扁平化”调整减少管理岗位......</p><p>&nbsp;</p><p>但这给研发造成的连锁反应也很大，据一亩三分地消息，裁员消息被曝出的最开始，就有匿名用户表示最近一个月LinkedIn内部有四位engineering VP 都在年底要离职，而且是呆了十年以上的人。</p><p>&nbsp;</p><p>高管二人组表示，大部分裁员（388 个职位）是直接从工程团队中剔除的，不过少数人将被保留，“以填补我们雄心勃勃的路线图中的关键空白”。</p><p>&nbsp;</p><p>另外，对于裁减“管理层”的决定，他们在备忘录中表示，“在我们持续推行2024财年计划的过程中，发现必须改进现有工作方式和优先事项，以确保能够实现我们已经确定的各项关键举措。这些举措将对实现LinkedIn的商业目标产生巨大影响。也就是说，我们将调整组织结构以提高敏捷性与问责能力，建立明确的所有权归属，并通过压缩层级来提高效率和透明度。”</p><p>&nbsp;</p><p></p><h2>被殃及的LinkedIn？</h2><p></p><p>&nbsp;</p><p>这是LinkedIn今年第二次宣布裁员；该公司在 5 月份解雇了 716 名员工，当时表示此举是为了“重组以实现更大的敏捷性和增长”。根据 LinkedIn 的声明，这一次的裁员是为了“简化我们的决策” 。</p><p>&nbsp;</p><p>微软在今年一月也曾宣布裁员1万人，并于七月公布了进一步裁员计划，对应的背景同样是微软整体收入增长开始下滑。面对压力，CEO纳德拉必须控制企业的整体成本。一位发言人表示，微软新一轮裁员将在一月万人裁撤计划的基础之上进行。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/06/0673c8c299c846e85d4fd8eed5bc8022.jpeg\" /></p><p></p><p>&nbsp;</p><p>网友认为，微软裁员是一回事儿，但LinkedIn则是另外一回事儿，相对来说LinkedIn有点无辜。尤其是LinkedIn的年收入在上一财年（2022年7月1日至2023年6月30日）首次超过150亿美元。</p><p>过去两年，其用户群逐季度持续增长。如今，该公司在全球 200 多个国家和地区拥有 9.5 亿用户。</p><p>&nbsp;</p><p>据知情人士透露，LinkedIn目前正在印度加大招聘力度。</p><p>&nbsp;</p><p>LinkedIn公司在一篇博文中提到，“在我们调整组织结构并简化决策的同时，也将继续投资于未来的战略重点，并确保我们继续为会员和客户提供价值。”</p><p>&nbsp;</p><p>“我们致力于在过渡期间向所有受到影响的员工提供全力支持，并确保他们能得到关心和尊重。”</p><p>&nbsp;</p><p>此次裁员备忘录全文如下：</p><p>&nbsp;</p><p>各位团队伙伴，</p><p>我们没有想到会在这样一个充满挑战的阶段内与大家分享这个重大消息。但本着清晰透明的精神，托默和我将向大家介绍一些关于LinkedIn当前组织革新的情况。</p><p>&nbsp;</p><p>在我们持续推行2024财年计划的过程中，发现必须改进现有工作方式和优先事项，以确保能够实现我们已经确定的各项关键举措。这些举措将对实现LinkedIn的商业目标产生巨大影响。也就是说，我们将调整组织结构以提高敏捷性与问责能力，建立明确的所有权归属，并通过压缩层级来提高效率和透明度。</p><p>&nbsp;</p><p>这些决定将导致研发裁撤563个职位。经过细分，减少的职位中有137个来自工程管理、38个来自产品部门。此外，我们的工程团队也将削减388个职位，以便腾出资源配合我们的2024财年发展计划。与此同时，我们也将增设少量新职位，填补公司雄心勃勃的下阶段发展路线图中的关键空白。</p><p>&nbsp;</p><p>对于那些将直接受到本轮裁员影响的员工，您将在接下来的一小时内收到一份日历邀约，标题为“须出席：研发角色削减”。此次会议将向您介绍我们的支持计划，帮助您完成这段交接过渡期。</p><p>&nbsp;</p><p>如果您没有收到此邀约，请安心等待您的产品或工程执行领导的联系。他们将提供关于大家所在部门的具体信息，以及我们后续将如何共同应对这些变化。</p><p>&nbsp;</p><p>托默和我在做出这些决定时，深入考虑到LinkedIn业务的长期需求，也对每一位受裁员影响的员工在公司发展、乃至如今获得的辉煌成功中发挥的宝贵作用表示感谢。</p><p>&nbsp;</p><p>未来几天，我们将努力相互支持并讨论未来前进方式，且始终坚持以LinkedIn的愿景、使命和价值观为指导。而今天，我们必须支持我们的同事度过这波转变。在这样一个困难时期，让我们保持住这份同理心和理解的态度，相互扶持走出阴霾。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://news.ycombinator.com/item?id=37907433\">https://news.ycombinator.com/item?id=37907433</a>\"</p><p><a href=\"https://www.cnbc.com/2023/10/16/microsoft-owned-linkedin-lays-off-nearly-700-read-the-memo-here.html\">https://www.cnbc.com/2023/10/16/microsoft-owned-linkedin-lays-off-nearly-700-read-the-memo-here.html</a>\"</p><p><a href=\"https://www.teamblind.com/post/LinkedIn-Layoff-List-LevNWoU3\">https://www.teamblind.com/post/LinkedIn-Layoff-List-LevNWoU3</a>\"</p>",
    "publish_time": "2023-10-23 13:19:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "是时候彻底放弃“高分低能”的Leetcode了：AI时代的面试需要大变革！",
    "url": "https://www.infoq.cn/article/VkM73EOB33gkHSFSXHoe",
    "summary": "<p>编译 | 核子可乐、Tina</p><p>&nbsp;</p><p></p><blockquote>随着软件开发行业正发生整体转变，我们越来越依赖Copilot和GPT等AI工具来生成代码、提高生产力，所以必然要据此调整对人才的甄选思路。</blockquote><p></p><p>&nbsp;</p><p>经验丰富的工程师也会过不了“编程面试”，特别是在没有花时间去复习Leetcode习题的情况下。现在很多人已经忘记了最初为什么面试时要做 Leetcode题。实际上，Leetcode来源于谷歌的一项面试研究，最初谷歌想确定最聪明的候选人通常也是最擅长算法的。谷歌聘用的重点是智商而非纯粹的编程技能，因此这导致他们的面试主要侧重于算法问题。后来，其他公司也效仿了谷歌的招聘模式，普遍开始问算法编程问题，逐渐整个行业的面试都围绕算法编程，而谷歌最初的研究目的逐渐被大家忽视。</p><p>&nbsp;</p><p>算法虽然重要，但在面试场景下却是可以通过死记硬背的刷题方式来解决的，而且对于大多数软件公司来说，工作很大程度上是写在 CRUD 业务。特别到了现在，Copilot和其他一些GPT编程工具已经被开发者们纳入到日常工作中，过分强调“Leetcode能力”似乎也有一些不合时宜了。</p><p>&nbsp;</p><p>花时间在Leetcode上练习一下常见的面试问题，然后依靠刷题进入大厂，这就是企业在为工程团队招聘新成员时想看到的效果吗？这事也要从正反两面来看：</p><p>&nbsp;</p><p>虽然解决这些复杂的算法问题确实既有益、又有趣，但现实情况是，对于大多数高效开发者来说，我们的大部分编程工作跟这些毫不相干。也就是所谓“面试造火箭，上班打螺丝”。大多数人在日常解决比较困难的编码问题时，主要会参考Stack Overflow、技术文档和其他在线资源。我们会跟同行聊天，并将不同的思路写在白板上。而随着AI编码工具的爆发式增长，许多开发者已经开始将Copilot和ChatGPT纳入自己的工作流程。对于大部分复杂问题，我们可能只需要处理一到两次，之后就能反复使用。所以说编写这种高度抽象的复杂代码不能说没有意义，只能说意义有限。现在的面试习惯会创造出一种人为的情境，给开发者增添了压力。其实很多朋友都不喜欢在他人的注视下写代码。在现实生活中，也很少有人会给自己的编码任务设置固定的时间。面对难题，我们可能去散会步、跟同事交流、研究算法、先构建个小型实验代码库等。老实说，“心流”状态下的开发工作才是最富成效的，而压力面试显然跟这种状态没有一毛钱关系。开发者会在自己熟悉的环境中使用自己喜爱的工具进行编码。使用不熟悉的工具反而让人迷失方向，并进一步增加他人注入下做开发的压力和焦虑。</p><p>&nbsp;</p><p>总而言之，这种面试方法可能是在衡量错误的指标，所关注的东西对于候选人有效融入团队基本没什么帮助。</p><p>&nbsp;</p><p>不仅如此，随着团队越来越依赖AI生成的代码（无论是Copilot还是GPT）来提高生产力，如今快速理解代码并在更广泛的应用/场景上下文中识别细微缺陷，才是最具价值的关键能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d7/d71767b6179900a34d8bbdc652c1508c.png\" /></p><p></p><p>GPT为Leetcode中常见的N-Queens问题生成的答案。</p><p>&nbsp;</p><p>因此现在已经有面试改换了重点，转向了审查代码、而非编写代码。这无疑是个重要启示，让我们意识到代码审查开始成为评估软件工程师的更好方法，而不再是专注于编码练习。</p><p>&nbsp;</p><p></p><h2>在面试中强调代码审查的八大理由</h2><p></p><p>&nbsp;</p><p>代码审查之所以能够在本质上提高面试效果，主要基于以下几个原因：</p><p>在AI时代，由AI生成的代码往往难以适应性能、安全性和内部最佳实践等实际要求（在受监管的行业中尤其突出）。在依赖这些零散生成的代码时，开发者必须有能力在整体项目上下文内有效评估代码质量、把握潜在风险。这种方式能更好地反映工程师——特别是高级职务——所从事的日常工作。从长远来看，向同事、特别是初级团队成员提供有效的指导和意见反馈，更有助于提升整体生产力与代码编写质量。这样可以更好地反映受试者是否具备全面的推理、思考和沟通视角。换句话说，更好地把握受试者加入团队后的整体表现，对其技术经验进行深入剖析。代码审查在本质上更具协作性，而编写代码则往往是项比较孤立的工作（相信有不少开发者更倾向于在晚间一个人静静编写代码）。代码审查也许更能反映受试者在团队中的工作状态，所以效果可能优于让受试者直接解决技术难题。代码审查中包含更多主观性因素，很多问题绝不是非黑即白。这就自然提供了更大的讨论和解释空间。由于不存在单一最优解，代码审查还让我们有机会面对更多异常情况。面对5位受试者，我们可以获得5种独特的观点；相比之下，以往的算法问题可能只对应少数几种最佳答案。这种方式，也让受试者更难通过生成式AI或者Leetcode刷题的方式作弊。这种方式更适合评估那些负责理解代码、而非直接编写代码的技术角色，包括工程经理、架构师和技术支持人员等。这种方式能更好地反映受试者在初入团队后的表现：通过阅读代码来学习现有系统。很明显，考察这方面能力比衡量他们能否解决N-Queens问题更有实际意义。</p><p>&nbsp;</p><p></p><h2>具体策略</h2><p></p><p>在代码审查中，我们还可以将以下几种策略搭配起来，借此衡量受试者的实际水平。这些策略的共同点在于，都更强调代码审查能力、而非代码编写能力。换言之，重要的不是能否在特定时间之内解决问题，而是能否适应现有代码库中的零散内容和团队遇到的实际挑战。</p><p></p><h3>“道法自然”</h3><p></p><p>从实际代码库中提取那些有意义、重要且有趣的部分，将它们作为审查工作的具体场景。比如说数据访问、异常处理、输入处理等等，这些都是审查受试者能否适应现有代码库，以及能否看懂、理解实际代码资产的好办法。</p><p></p><h3>找出Bug</h3><p></p><p>故意引入一些逻辑缺陷或问题，看看受试者能不能顺利发现。比如说要求他们找到并处理最近公司里刚刚修复掉的bug，看他们能否发现根本原因、打算如何解决该缺陷，他们的方案跟实际修复之间有何不同等。</p><p></p><h3>重构与重新设计</h3><p></p><p>可能公司刚刚对某些代码进行了重构，或者正打算进行重构，这时候就可以将重构前的代码作为素材，考察受试者如何看待原有代码、打算用什么策略规划和实施重构。另外，也可以询问受试者能否确定为什么有必要进行重构，并评估他们所提出方法的复杂性。大家可能会惊讶地发现，这绝对是种考察技术能力的全新途径、而且相当有效！</p><p>&nbsp;</p><p>如果受试者表现良好，就基本可以认定他们能够快速融入现有工作流程。</p><p></p><h3>以性能为导向</h3><p></p><p>找点最近刚刚做过性能修复的代码，看看受试者能否发现导致一段代码运行缓慢的原因，包括他们能否提出算法、替代设计或修复思路以提高代码性能。</p><p>&nbsp;</p><p>具体包括应用程序所需执行的现有SQL DDL架构及常见自然语言查询。或者删除索引定义，看看受试者能否提出索引或替代设计来提高性能。</p><p>&nbsp;</p><p>不要询问什么Big-O表示法的原理，而应考察受试者能否真正发现数据访问代码中的那些O(n^2) 代码或N+1问题！</p><p></p><h3>关注测试</h3><p></p><p>选择一段代码并匹配一组代码单元测试，询问这是否涵盖了所有情况？还有哪些情况未能涵盖？如何对单元测试做改进？在即将到来的AI生成代码时代，这种判断力往往更加重要：理解领域空间和用例，以及如何编写高覆盖率单元测试（或者评估AI生成的单元测试的完整性）将成为一项关键技能。</p><p></p><h3>安全嗅觉</h3><p></p><p>选择包含微妙安全缺陷的代码，看看受试者能不能发现这些问题。不要单纯询问什么是XSS或者SQL注入攻击，而是要看他们能否意识到当前代码缺乏对此类攻击的保护机制。同样的，随着团队越来越多地依赖由AI生成的代码，这种从生成代码中发现潜在安全缺陷的能力将变得愈发重要。</p><p></p><h3>最佳实践</h3><p></p><p>对于更高层级的职位，则应考察他们能否把握最佳实践，并借此与技术新人/直接下属顺畅沟通、传授软件开发经验。拥有这种能力，才是一名好的技术管理者。</p><p>&nbsp;</p><p></p><h2>写在最后</h2><p></p><p>在《平均的终结：如何在崇尚标准化的世界中胜出》一书中，Todd Rose写道：</p><p>几乎任何有意义的人类特质、尤其是天赋，总会包含多个维度。问题在于，当我们试图衡量一个人的才能时，却经常诉诸平均值，想要让参差不齐的个体简化为单一维度，例如标准化的考试分数或者工作绩效排名。</p><p>&nbsp;</p><p>事实上，如果我们选择狭隘的问题解决技能，那么最终得到的就只会是“平均”或者说平庸的候选人。他们只是在简单学习并应付这些考察维度，反而让我们错过许多真正能够提升团队生产力的卓越人才。将代码审查作为面试中的团队技能考察指标，有助于更好地衡量受试者的整体技能水平，避免靠Leetcode刷题导致的“高分低能”问题。</p><p>&nbsp;</p><p>随着软件开发行业正发生整体转变，我们越来越依赖Copilot和GPT等AI工具来生成代码、提高生产力，所以必然要据此调整对人才的甄选思路。机器人就能解决的算法难题，在考察受试者时应当占据更低的比例和权重。相反，未来的核心技能也许是阅读并审查代码是否正确、贯彻最佳实践并保障安全性等能力。</p><p>&nbsp;</p><p>用代码审查替代Leetcode作为面试主体，不仅能帮助团队更好地对受试者做整体分析，更能强调其核心技能和团队协作表现等现实指标，为行业内软件构建范式的整体转变做好准备。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://chrlschn.dev/blog/2023/07/interviews-age-of-ai-ditch-leetcode-try-code-reviews-instead/\">https://chrlschn.dev/blog/2023/07/interviews-age-of-ai-ditch-Leetcode-try-code-reviews-instead/</a>\"</p><p>&nbsp;</p>",
    "publish_time": "2023-10-23 13:23:04",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "B站广州研发工作室解散；外媒曝光苹果中国区丑闻；OpenAI被曝已叫停新大模型项目 | Q资讯",
    "url": "https://www.infoq.cn/article/vQGjckOvgzXbNDtwkgGD",
    "summary": "<p>整理 | Tina</p><p>&nbsp;</p><p></p><blockquote>B站广州研发工作室宣布解散，高峰期曾有400多人；微软新入职员工最高基本工资约 265 万，最低约 31 万；智谱AI宣布获超25亿融资；外媒曝光苹果中国区丑闻，和游戏开发者存在不当接触；性能远低于预期，OpenAI据称放弃开发廉价版GPT-4 Arrakis；百度公布文心大模型4.0，称能与 ChatGPT-4 媲美；传亚马逊将成微软云服务客户，交易金额超10亿美元……</blockquote><p></p><p>&nbsp;</p><p></p><h2>科技公司</h2><p></p><p>&nbsp;</p><p></p><h4>B站广州研发工作室宣布解散，高峰期曾有400多人</h4><p></p><p>&nbsp;</p><p>据“游戏新知”10月18日报道，哔哩哔哩（简称“B站”）广州研发工作室宣布解散，CEO丁黔伟将离开公司，除了一款日漫IP改编项目“代号QQ13”因有外部合作合同而被保留了下来，其他项目均被砍掉。也就意味着这个原本有 400 多人的研发工作室，经历了两次大裁员之后剩下约 60 人，被留下的人也处于等待合同结束离开的状态。</p><p>&nbsp;</p><p>B站广州游戏研发工作室由收购心源互动而来。天眼查显示，广州心源互动科技有限公司成立于2019年，现已更名为广州星奥科技有限公司，为动作类游戏研发商，代表作品包括《雏蜂：深渊天使》、《镇魂街：天生为王》等。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>微软新入职员工最高基本工资约 265 万，最低约 31 万</h4><p></p><p>&nbsp;</p><p>近日，根据国外科技媒体披露的一份微软内部文档显示，新入职成员最高基本工资为 23.17 万美元至 36.15 万美元（当前约 169.6 万元至 264.6 万元人民币），此外还有最高 120 万美元（当前约 878.4 万元人民币）的入职奖金，以及 100 万美元（当前约 732 万元人民币）的年度股票奖励。目前尚不清楚这份披露的文档适用于所有新入职员工，还是仅限于某些特定的组织角色，这份文档也显示在纽约和旧金山地区的微软新入职员工工资更高。</p><p>&nbsp;</p><p>文档显示级别最低的新入职员工至少年薪为 4.25 万美元（当前约 31.1 万元人民币），但没有入职奖金和年度股票奖励。而最高级别为 70 等级，基本工资在 23.17 万美元至 36.15 万元之间，此外还可以获得 31 万美元到 120 万美元的入职奖金。</p><p>&nbsp;</p><p></p><h4>智谱AI宣布获超25亿融资：美团蚂蚁阿里小米腾讯顺为是股东</h4><p></p><p>&nbsp;</p><p>10月20日，北京智谱华章科技有限公司(简称：“智谱AI”）宣布，今年已累计获得超25亿人民币融资。参与方主要包括社保基金中关村自主创新基金（君联资本为基金管理人）、美团、蚂蚁、阿里、腾讯、小米、金山、顺为、Boss直聘、好未来、红杉、高瓴等多家机构及包括君联资本在内的部分老股东跟投。</p><p>&nbsp;</p><p>智谱AI称，上述融资将用于基座大模型的进一步研发，更好地支撑行业生态，与合作伙伴一同高速发展。智谱AI成立于2019年，脱胎于清华 KEG（知识工程实验室）。2023年6月，在硅谷科技媒体 The Information 的盘点中，智谱AI被视为最有可能成为“中国 OpenAI”的 5 家企业之一。智谱AI CEO张鹏认为，下一代的技术应该是认知智能。认知智能的技术要解决的问题，和上一代的感知智能不太一样，比如多模态需要更大的数据量、更类人智能的能力，以及多任务、多场景的一些通用化的能力等等。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>外媒曝光苹果中国区丑闻，和游戏开发者存在不当接触</h4><p></p><p>&nbsp;</p><p>据外媒报道，通过长达一年的内部调查，苹果公司近日开除了至少 5 名 App Store 中国区员工，理由是和游戏开发者存在不当交易、性侵等。作为苹果中国区重要的服务业务，App Store 部门成为“重灾区”。据报道，苹果去年还解雇了一名 App Store 员工，原因是该员工涉嫌性侵一名米哈游员工。这名被开除的员工以及米哈游发言人皆未回应置评请求。</p><p>&nbsp;</p><p>在不对这份报告的具体指控发表评论的情况下，苹果希望其全球员工遵守其非常严格的道德和商业行为政策，将彻底调查有关报告的不当行为，并在适当的时候毫不犹豫地立即采取行动，包括解雇。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>性能远低于预期，OpenAI据称放弃开发廉价版GPT-4 Arrakis</h4><p></p><p>&nbsp;</p><p>据外媒报道，由于新的 AI 模型运行效率低于预期，OpenAI 在今年年中叫停了代号名为 Arrakis 的大模型的开发。据消息人士透露，在 2022 年夏季完成了对 GPT-4 的研发后，OpenAI 就已经启动了对 Arrakis 的开发。如果 Arrakis 能够获得成功，OpenAI 就可以向其最大投资者微软证明公司具备连续创建大语言模型的能力。</p><p>&nbsp;</p><p>按照OpenAI的设计初衷，Arrakis将具有与GPT-4一样的能力，但部署成本更低，因为它的部分设计采用了所谓的“分散”原则。这意味着，只有神经网络的一部分被用来处理用户输入。而在传统的“密集模型”中，整个神经网络都是活跃的。当前，谷歌的Path AI项目就使用了“分散”原则。</p><p>&nbsp;</p><p>两位知情人士称，OpenAI于今年年中取消了Arrakis项目，其开发团队意识到，Arrakis的性能远不及GPT-4。微软的“一些高管”对 Arrakis 的缺陷和其失败感到失望，因为微软向 OpenAI 给予巨额投资的条件之一就是能够在自家产品中使用 OpenAI 的新技术。</p><p>&nbsp;</p><p></p><h4>百度公布文心大模型4.0，称能与 ChatGPT-4 媲美</h4><p></p><p>&nbsp;</p><p>李彦宏在百度世界 2023 大会上宣布了最新版本的文心大模型4.0，称综合能力“与GPT-4相比毫不逊色”。文心大模型4.0 目前处于邀请测试阶段。李彦宏演示了最新大模型的四大能力的特点与应用场景。在理解能力上，他通过询问公积金异地贷款政策的案例，展示了文心一言对前后乱序、模糊意图、潜台词等复杂提示词的理解力，例如“在北京工作”等同于“在北京缴纳公积金”等，“今天，你说的每一句话，它大概率都能听懂”。</p><p>&nbsp;</p><p>在生成能力上，李彦宏展示了文心一言如何在短短几分钟内，根据一张素材图片，迅速生成了一组广告海报、五条广告文案，以及一条营销视频。他还通过解数学题、总结知识点等场景，展示了大模型的逻辑能力；通过数千字的小说撰写和角色、情节设置，体现了大模型的记忆能力；以及数字人医生帮助患者解读药品说明书，来展现四大能力的综合应用。百度表示将基于最新模型更新搜索引擎、地图等应用。</p><p>&nbsp;</p><p></p><h4>传亚马逊将成微软云服务客户，交易金额超10亿美元</h4><p></p><p>&nbsp;</p><p>10月18日消息，据最新曝光的内部文件和知情人士透露，微软正在准备与亚马逊达成云服务合作协议，交易金额超过10亿美元。据悉，亚马逊将成为微软Microsoft 365云服务的客户。这家零售巨头已承诺在未来五年内支付超过10亿美元的费用，以获得超过100万个Microsoft 365许可证。这一消息导致微软股价在消息公布后的盘后交易中上涨了近1%。然而，微软对此事拒绝置评，而亚马逊则没有回应路透社的置评请求。据报道，亚马逊预计将于11月初开始安装微软的新系统。目前，该公司使用的是微软Office产品的本地版本。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>诺基亚将裁员1.4万人以削减成本，或5G布局失利所导致</h4><p></p><p>&nbsp;</p><p>10月19日，据外媒报道，诺基亚宣布调整营运策略，目标是到2026年底总成本基础较2023年降低8亿至12亿欧元。这意味着人员开支将减少 10%-15%。诺基亚目前有 86000 名员工，该计划预计将使诺基亚的员工人数降至 72000-77000 名，将裁员至多 14000 人。</p><p>&nbsp;</p><p>数据统计显示，在过去两年的时间里，诺基亚的裁员人数超过了1.1万，相当于总员工数减少了十分之一，每年可以为诺基亚节省5.97亿美元的资金。虽然裁员在企业调整中是常见的现象，但是诺基亚这种大规模、长期的裁员，其背后的原因或是由于在5G布局方面的失利所导致。</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>IT业界</h2><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>AI 编程语言 Mojo 登陆 Mac 平台</h4><p></p><p>&nbsp;</p><p>10 月 20 日消息，Mojo 编程语言近日登陆 Mac 平台，为 AI 开发人员带来类似于 Python 的编程体验。Mojo 编程语言的开发工作由 Chris Lattner 领导，他同时也是苹果 Swift 编程语言的主要推动者之一。Lattner 于 2022 年和他人共同创立了 Modular AI，并负责开发 Mojo 编程语言。</p><p>&nbsp;</p><p>Mojo 语言于今年 9 月开放下载，上线初期仅支持 Linux 系统。除了编译器之外，Mojo SDK 还包括一整套开发者和 IDE 工具，可以用于构建和迭代 Mojo 应用。Modular AI 表示，自 5 月 2 日推出 Mojo 编程语言以来，已有超过 12 万开发者注册使用 Mojo Playground，超过 1.9 万开发者在 Discord 和 GitHub 上积极讨论 Mojo。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>Midjourney发布二次元图像生成App</h4><p></p><p>&nbsp;</p><p>Midjourney创始人David Holz本周介绍，Midjourney与日本游戏公司Sizigi Studios的工程师合作发行了一款Android和iOS应用NijiJourney，面向日本市场，主要提供使用Midjourney的动漫风格设置的图像。该应用程序需要付费才能使用，全年一次性支付96美元，或者每月支付10美元。现有的Midjourney用户可以使用他们的Discord凭据登录，而无需支付更多费用。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>百度大模型Comate编程助手将在10月24日对外开放</h4><p></p><p>&nbsp;</p><p>百度自研的AI原生应用——Comate智能编程助手，即将在10月24日全面开放。目前，Comate智能编程助手已在百度内部大规模使用，覆盖80%以上的工程师。</p><p>&nbsp;</p><p></p><h4>Node.js 21 发布</h4><p></p><p>&nbsp;</p><p>该版本将 V8 JavaScript 引擎更新至 11.8、稳定版 fetch、WebStreams 用于翻转模块默认值的新实验标志 ( --experimental-default-type)、内置 WebSocket 客户端等许多更新。当 Node.js 20 于本月晚些时候进入长期支持 (LTS) 时，Node.js 21 将取代 Node.js 20 作为“current”版本。根据发布时间表，Node.js 21 将在接下来的 6 个月内成为“current”版本，直到 2024 年 4 月。</p>",
    "publish_time": "2023-10-23 13:26:10",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "智谱 AI “超 25 亿融资” 的背后",
    "url": "https://www.infoq.cn/article/MhabGNAVvf1NgAeZ2oIZ",
    "summary": "<p>这几天，“大模型”圈里最令人津津乐道的可能就是两家大模型创业公司分别宣布自己今年的融资额度——<a href=\"https://www.infoq.cn/article/ivM3DbowD6o9Ro4jIeGq?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">百川智能</a>\"获得 3 亿美元的融资，估值跃升成为独角兽企业；智谱 AI 获得超过 25 亿人民币的融资，百亿人民币估值令人瞩目。</p><p></p><p>百川与小米的联手得到了业界内的广泛关注，而雷军的手笔更是一下子把大家的目光都吸引到了智谱 AI 身上。除了目前热度超高的这两家，大模型初创公司“月之暗面”也是资本的新宠。红杉资本、真格基金押注下场，目前月之暗面的募资金额目前已经超过 2 亿美元。</p><p></p><p>临近年底，今年“大模型”的资本角逐已经初现成果，智谱 AI 凭借着最高融资额和最高估值走到了台前。由于长期低调的学院派风格，非行业内的声量并不是很高。直到这一次高调宣布融资额，彻底引爆了创投圈。</p><p></p><p>智谱 AI 如此大规模融资的背后，涉及到的是众多知名机构和投资人。从智谱 AI 官方宣布的融资信息来看，参与投资的组织包括社保基金中关村自主创新基金（君联资本为基金管理人）、美团、蚂蚁、阿里、腾讯、小米、金山、顺为、Boss 直聘、好未来、红杉、高瓴等。整个过程中，腾讯阿里联手，主流基金入场，战投纷纷表态，这个融资声势无论放在哪个行业都是相当罕见的。</p><p></p><p>面对如此大规模的融资，我们不禁要思考一个问题——智谱 AI 的优势何在，众多的投资人和机构为什么选择了它？同时这也引发了我们对人工智能产业未来发展的思考，随着认知智能等新一代技术的崛起，人工智能产业将迎来哪些新的机遇和挑战？未来的发展又将呈现怎样的格局？</p><p></p><p></p><h2>智谱 AI 是资本市场看好的“中国版 OpenAI”种子选手</h2><p></p><p></p><p>2023 年 6 月，硅谷科技媒体 The Information 在盘点最有可能成为“中国 OpenAI”的 5 家企业时，智谱 AI 赫然在列。<a href=\"https://www.infoq.cn/article/g9tuoTODP20N1lTzjsjw?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">OpenAI </a>\"作为人工智能领域的领先者之一，拥有世界顶尖的 AI 研发团队，其技术实力在自然语言处理领域处于领先地位，其发展动态和成果一直受到全球的广泛关注，甚至直接被一些媒体评价为“人工智能领域的先驱”和“科技创新的领头羊”。所以，如果说“智谱 AI”是有可能成为“中国版 OpenAI”的企业，那说明它一定在国内人工智能领域做出了许多与 OpenAI 一样的努力。</p><p></p><p>对比一下 OpenAI 和智谱 AI 这两家企业的技术发展特点，就不难发现这两家企业确实有很多异曲同工之处。两家企业都致力于自然语言处理领域的研究，并取得了一系列重要的成果。两家企业都拥有先进的预训练语言模型，能够理解和生成人类语言，为各种应用场景提供强大的支持，无论是 OpenAI 的<a href=\"https://www.infoq.cn/article/GuXceGIYzMHs7rt2ldUB?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\"> GPT </a>\"系列模型，还是智谱 AI 的文言文模型，都在搜索引擎、智能客服、机器翻译等领域发挥了重要作用。</p><p></p><p>不仅如此，两家的产品性能甚至都几近相似，比如，在 Stanford 报告的世界主流大模型评测中，智谱 AI 于 2022 年研发的 GLM-130B 是亚洲唯一入选模型，准确性、恶意性与 OpenAI 研发的 GPT-3 持平，且鲁棒性和校准误差在所有模型中表现最佳。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/08/0842fdf94ed6961c2c02986bf5ee6d83.png\" /></p><p></p><p>此外，在人工智能技术日益普及的今天，如何保障人工智能技术的道德和伦理问题成为了全球关注的焦点。而 OpenAI 和智谱 AI 目前都开始注重人工智能伦理的研究和实践，致力于开发符合道德规范的人工智能技术。</p><p></p><p>其次，两家企业从融资情况方面也很像，智谱 AI 是国内人工智能赛道融资最高的企业，OpenAI 去年也以占比美国相关企业融资总额超 70% 的占比问鼎赛道融资最高企业，广受资本的喜爱。要知道，资本市场一向都是残酷无情的，投资组织在决定投一家科技企业时，一定是综合了技术市场趋势与获投企业的整体技术能力、盈利模式来进行最终决策的。所以如果有十几家的投资组织都将自己的钱投向一个企业的时候就说明，这个企业的未来发展一定非常强势。</p><p></p><p>无论是投资人还是行业从业者，都非常清楚一个事实，那就是大模型技术是“有门槛的”，是需要有时间积累的。在大模型技术还没有爆火之前，市场还没有那么“卷”的时候，智谱 AI 就已经开始了相关技术的研发，虽然当时大模型技术由于高昂的训练成本和复杂的开发门槛并不被业界所看好。然而，他们已经不是第一次做“第一个吃螃蟹的人”了，无论是从研发、开源生态还是商业合作上。</p><p></p><p>智谱 AI 目前是国内唯一全内资、国产自研的大模型企业，它推出的 GLM 国产芯片适配计划，面对不同类型的用户不同类型的芯片提供不同等级的认证和测试，这意味着智谱 AI 的大模型是安全可控的，这也将直接反哺智谱 AI 的商业化能力。我想这也是为什么智谱 AI 能够吸引来众多组织投资的一个原因。要知道，大模型技术“卷”到现在这个阶段，已经进入了中后段，像其他技术的发展周期一样，安全问题已经成为了大模型领域最受为关注和亟待解决的技术挑战，如果智谱 AI 的大模型能够将领域内的安全问题妥善解决，那对于投资人来说，这将是一笔稳赚不赔的买卖。</p><p></p><p></p><h2>从参与融资组织的母体背景看出了“大模型产业化”趋势</h2><p></p><p></p><p>资本在哪，大市场就在哪。我们仔细盘点一下参与智谱 AI 融资的组织，可以发现一个非常有意思的现象——除了专业投资机构以外，像美团、蚂蚁、阿里、腾讯、小米、金山、Boss 直聘等企业的母体业务，或多或少地都已经开始自研大模型或者基于业务进行大模型个性化创新改造的探索过程中。</p><p></p><p>例如，美团曾推出过基于大模型的智能推荐系统，帮助用户更好地找到所需商品或服务；蚂蚁集团一直在推进大模型在智能客服、智能风控等领域的应用；腾讯通过投资和自主研发，在大模型方面取得了不少成果，并积极推动大模型在各行业的应用；小米将大模型应用于智能家居、物联网等领域，提升用户体验；Boss 直聘、好未来等公司则在 AI 大模型方面进行了研究和应用，推出了各种基于 AI 大模型的智能招聘、智能教育等服务，为人力资源和教育行业的发展提供了新的思路和方法。</p><p></p><p>而作为初创企业的智谱 AI 在开放平台、云端私有化、本地私有化三个方面，基于自己早已建立的开源生态，也已经与超过 200 家的企业进行了生态共建，与超过 1000 家机构共建大模型应用场景。因此，无论是投资智谱 AI 的组织母体背景，还是智谱 AI 自己，他们在做的除了从技术上推动大模型技术的发展，更重要的是将大模型应用于产业场景中，大模型产业化已经是领域发展的必然趋势。</p><p></p><p>从技术角度看，大模型产业化趋势源于其强大的数据处理和推理能力。随着数据量的爆炸性增长，传统的机器学习方法已经难以应对如此大规模的数据处理任务。而大型深度学习模型，如 GPT-4 等，能够处理海量数据并从中提取有价值的信息，为各行各业提供强大的支持。此外，大模型还具有出色的泛化能力，能够在处理未知问题时做出较为准确的预测和决策，进一步推动了其在各行业的应用。</p><p></p><p>如果复盘近两年来大模型技术的发展历程便可以发现，是“深度学习”技术的突破使得我们可以训练更大、更复杂的模型，像 GPT-4、BERT、ResNet、YOLO、PaddlePaddle、文心一言、通义千问等大模型目前其实都已经具备了较强的处理能力和较高的精度，可以处理更多的任务和数据。这为大模型的商业应用提供了更广阔的空间，也为产业化的实现提供了更强大的技术支持。</p><p></p><p>从社会角度看，大模型产业化趋势对于社会发展有着深远的影响。一方面，大模型的应用改善了人们的生活质量，例如智能家居、智能交通等领域的应用，使得生活更加便捷和安全。在另一方面，大模型也带来了新的社会问题，如数据隐私、人工智能伦理等问题，需要社会共同探讨和解决。</p><p></p><p>从商业角度来看，大模型的应用场景还在不断扩大，从最初的互联网领域已经扩展到了金融、医疗、教育、制造、服务等传统行业。这些行业拥有丰富的数据资源，但数据处理和智能化应用的需求一直未能得到很好的满足，大模型的出现为这些行业提供了新的解决方案，大模型高精度、高效率和高可靠性的特点，能够帮助企业提高效率、降低成本、更好地理解客户需求、预测市场趋势、优化决策和业务创新，可以满足各行各业的商业化需求，加速了传统产业数字化转型升级的进程，这些商业价值是大模型产业化的重要驱动力。</p><p></p><p>当然了，大模型的产业化需要整个产业链的支持，包括硬件、软件、数据和人才等方面。随着产业链的完善，大模型的产业化将得到更全面的支持和保障。同时，产业链上的各个角色也将在大模型的产业化中获得更多的机会和收益。</p><p></p><p></p><h2>下一代人工智能技术是“认知智能”</h2><p></p><p></p><p>在当下这个信息化和数字化的世界里，人工智能技术已经成为了企业和组织的重要竞争力。然而，随着技术的不断发展和用户需求的不断升级，人工智能技术也在不断地寻求突破和创新。从大模型技术的发展路径来看，它已经陆续走过了“计算智能”、“感知智能”阶段，正在进行“认知智能”阶段的探索。智谱 AI CEO 张鹏多次在公开场合表示，“下一代的人工智能技术应该是认知智能。”</p><p></p><p>计算智能是人工智能的基本要求，它使机器能够进行计算和存储，人类无法记住一万个四位数，但机器可以轻松完成。感知智能则更进一步，使机器能够听懂人类语言、会说话、能看懂图像并识别物体，例如通过传感器感知环境并做出决策，同时执行一些简单的指令和动作，例如人脸识别系统。</p><p></p><p>而认知智能作为人工智能的高级阶段，是人工智能取得进一步突破的关键瓶颈，也是形成更大产业规模的关键技术，它要求机器能够能够像人一样进行思考、理解、推理、判断、学习等智能活动，并能够根据环境变化做出相应的决策和行动，像智能客服、智能家居、自动驾驶等都是目前比较典型的应用场景。与传统的感知智能相比，认知智能更加强调智能的内涵和深度，更加注重对于人类智能的模拟和再现，这需要投入大量的人力物力去研发。全国人大代表刘庆峰在十四届全国人大一次会议上呼吁，“我国要加快打造我国的认知智能大模型，并推动大模型在各领域的价值落地已迫在眉睫。”</p><p></p><p>认知智能在商业领域的应用正在不断扩大和深化，这种智能技术以数据为基础，通过先进的机器学习、自然语言处理等技术，帮助企业模拟人类的思维和行为，为决策提供更准确、可靠的数据支持。随着数据的不断增长和技术的持续进步，这种数据驱动的决策趋势将更加明显。</p><p></p><p>同时，当前不断变化的消费者需求正在促使企业提供更加个性化和精准的服务，而认知智能技术就可以深度理解消费者的兴趣和行为，为消费者提供高度个性化的产品和服务。这种个性化服务的趋势已经在电子商务、金融等领域得到了广泛应用，并取得了良好的效果，这种跨行业应用的趋势对各行业的数字化转型和创新发展起到了积极的推动作用。</p><p></p><p>然而，尽管认知智能具有重要性和广阔的前景，但它的应用仍面临一些行业挑战——首先数据隐私保护就是一个重大挑战。为了确保可持续、可信赖的认知智能应用，企业需要采取有效的措施和技术手段来保护客户数据的安全和隐私。其次，算法风险和偏见也是需要注意的问题。由于算法模型是由人类开发者设计和开发的，难以避免一些潜在的偏见和错误。这些偏见和错误可能会对企业的决策和消费者的体验造成不良影响。因此，需要加强算法设计和验证的规范性和严谨性，以降低算法风险的发生概率。</p><p></p><p>此外，智能化程度和可解释性也是认知智能应用中亟待解决的挑战。尽管目前认知智能技术已经取得了一定的进展，但在面对一些复杂的任务和问题时，它仍无法像人类一样进行灵活、全面的分析和解释，这可能会限制其在一些关键领域如医疗、金融等的应用和发展。为了解决这一问题，需要加强与人类专家的合作和交流，将人类的智慧和机器的智能相结合，提高整体解决方案的效率和准确性。</p><p></p><p>面对认知智能的研发现状，像百度、阿里等大型厂商其实是更有技术突破优势的——他们通常拥有庞大的数据资源，数据的丰富度和质量往往对模型的准确性和性能起到关键作用；同时他们可以投入更多的人力和物力来研究和发展认知智能技术，引进更多相关领域的顶尖人才，通过品牌信任度和市场份额更容易吸引到合作伙伴、渠道商进行产品应用化测试和产业链合作，从而可以进行更深入的研究和更快的迭代，更容易做出技术突破。</p><p></p><p>但如果创业公司想要冲出重围，就必须要寻找到一个差异化市场的有效策略，通过关注特定行业、领域或用户群体，提供更加个性化和专业的认知智能产品和服务，避免与大厂商在传统领域的直接竞争。但像智谱 AI 这样一向低调的创业公司，当其被资本压注后，往往就不得不走向台前，在未来他们将面临更大的挑战，甚至就在这个“百度、讯飞等厂商纷纷带来产品升级”的 10 月，智谱 AI 决定将于 27 日发布新一代基座模型，但智谱 AI 的表现到底如何，还是要靠技术说话，大家可以一起来关注一下。</p><p></p><p>但无论如何，大家也不要忘了一件事，不管是大型厂商，还是创业公司，在认知智能这个探索阶段，大家都属于“小马过河”，想要在这竞争激烈的市场环境中获得一席之地，持续技术创新和提升自身实力永远是到达成功彼岸的第一要素。</p>",
    "publish_time": "2023-10-23 13:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "头脑正常的人绝不会创业！英伟达CEO黄仁勋：如果能够重来，宁愿放弃创办公司",
    "url": "https://www.infoq.cn/article/qzs4Zp3DH1wxIeSpVgU8",
    "summary": "<p></p><blockquote>这位科技大佬还强调，他最担心的就是让员工们失望。</blockquote><p></p><p></p><p>英伟达公司CEO黄仁勋是有史以来最成功的企业家之一。英伟达也是少数几家市值达到 1 万亿美元的公司之一，黄仁勋本人也是世界上最富有的人之一，净资产达 375 亿美元。在最近的一次采访中，他分享了他对创建公司所面临的挑战的独特视角。</p><p></p><p>黄仁勋透露，打造这家科技巨头“比我预想中要困难一百万倍”，甚至表示如果能够预见到后来所经历的一切艰辛，任何“头脑正常的人绝不会选择创业”。黄仁勋承认，如果有选择，他不会再创办公司，因为其中涉及巨大的困难。</p><p></p><p>老黄认为，“在逆境中坚持不懈的能力才是成功企业家的标准”。老黄进一步解释说，成功企业家的特质之一是他们有能力说服自己，创业之路并不像实际那么困难。</p><p></p><p></p><blockquote>“你得让自己相信这一切没那么难，但实际上事实要比想象中困难得多。如果能带着现在的认知回到过去，那我宁愿放弃创办公司。我觉得一路走来太辛苦了，真的太辛苦了。”</blockquote><p></p><p></p><h2>“创立英伟达，比我预想中困难一百万倍”</h2><p></p><p></p><p>作为全世界最具远见的科技企业之一的创始人，这位60年前出生于中国台湾的华人曾随家人搬往泰国，年轻时又来到美国。据说，他曾在AMD和LSI Logic短暂就职，并在加州圣何塞的一家丹尼斯餐厅跟合伙人们会面之后决定共同创立英伟达。他坦言，如果能回到30岁重新选择，他绝不会走上自主创业这条道路。</p><p></p><p>但这位技术大佬在最近接受Acquired播客采访时承认，企业家们最大的“超能力”，就是欺骗自己相信“这事没那么难”。</p><p></p><p>而忍受所有这些困难也给老黄带来了巨大的回报。早在 1993 年，黄仁勋就以不到1000美元的资金创立了英伟达，目前公司市值已超过1万亿美元。虽然老黄现在已经非常富有，并且已经辛勤工作了30年，但他并不打算停下来。“欺骗自己这个伎俩仍然有效，”他笑着说。“我仍然非常享受欺骗自己，并且我正在不断给自己加码，”他说。</p><p></p><p>黄仁勋表示，自英伟达公司成立以来，他最大的担忧就是无法推动员工们取得成功。“时至今日，我最担心的事情还跟当初刚加入公司时一样，就是让员工们感到失望。”</p><p></p><p>据金融分析公司FactSet的统计，黄仁勋拥有英伟达3.5%的股份（目前公司总市值1.04万亿美元）。他在播客采访中表示，加入一家企业的员工最终会相信企业的发展愿景，并将集体的抱负接纳为个人的抱负。</p><p></p><p>黄仁勋强调，“会有很多人加入你的企业，因为他们相信你的希望和梦想，并愿意将其作为自己的希望和梦想。所以你希望顺应他们、希望他们获得成功、希望他们能拥有自己的美好生活……而最大的恐惧，则是让他们感到失望。”</p><p></p><h2>AI将在短期内创造更多就业机会</h2><p></p><p></p><p>在解释自己如何克服质疑和挑战、并坚持将英伟达打造成如今的行业巨头时，黄仁勋将一切归功于这三十年旅程中始终相信他、与他站在一起的“支持网络”。</p><p></p><p>他解释道，自1999年公司首次上市以来，自己就面临过无数的冲击和挑战。在股价如自由落体般急转直下的那段时期，身为英伟达领导者的他感到几乎“无法承受”。黄仁勋坦言，“无论大家怎么看待，那都是段令人尴尬的经历”。</p><p></p><p>而就在他发表此番言论之际，英伟达股价刚刚结束过去12个月间高达245%的凶猛增长、如今再次出现回落。</p><p></p><p>最近，因拜登政府出台更为严格的对中国半导体出口控制政策，这家总部位于圣克拉拉的公司又一次遭受沉重的股价震荡。</p><p></p><p>展望未来，黄仁勋表示AI技术的发展已经为英伟达等科技企业带来“巨大”机遇，他认为“市场机会可能已经增长了上千倍。”</p><p></p><p>他认为，AI技术将在短期之内“创造更多就业机会”，但同时也警告称在新增的就业机会之外，也可能有更多来自其他行业的岗位将在自动化的冲击下而消失。黄仁勋表示，“从好的方面看，随着生产力变得更高，公司的利润也将有所提升，这样管理者通常会雇用更多员工来扩展新的业务领域。”</p><p></p><p>“但就目前来看，新增的就业机会并不能保证一切原有岗位都继续存在。情况明显没那么乐观，更大的可能性是不少从业者会因为其他人开始使用AI、但自己不会用AI而失去工作。”</p><p></p><p>他建议人们“学习如何使用AI技术”，因为他认为“工作的形态正在发生转变。”</p><p></p><p>至于英伟达自身，黄仁勋称这家公司的结构就如同他们销售的产品，类似于一套“计算技术栈”。</p><p></p><p>他表示“英伟达的组织方式跟具有严格自上而下指挥和控制机制的军队不同”。相反，该公司的组织方式更像是基于分散结构的“神经网络”。这也反映出一种基本理念，即“你的组织架构，应该与所构建产品的架构保持一致。”</p><p></p><p>参考链接：</p><p></p><p><a href=\"https://www.morningstar.com/news/marketwatch/20231020335/nobody-in-their-right-mind-would-do-it-nvidia-ceo-jensen-huang-says-he-wouldnt-start-a-company-if-he-had-a-do-over\">https://www.morningstar.com/news/marketwatch/20231020335/nobody-in-their-right-mind-would-do-it-nvidia-ceo-jensen-huang-says-he-wouldnt-start-a-company-if-he-had-a-do-over</a>\"</p><p><a href=\"https://ts2.space/en/nvidia-ceo-reflects-on-entrepreneurship-its-hard-but-worth-it/\">https://ts2.space/en/nvidia-ceo-reflects-on-entrepreneurship-its-hard-but-worth-it/</a>\"</p>",
    "publish_time": "2023-10-23 14:12:56",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "平安人寿魏政刚：算力与语料，是制约保险领域大模型应用的首要挑战",
    "url": "https://www.infoq.cn/article/jT23W6bD7qmk5OpZRf8P",
    "summary": "<p>大模型如火如荼，在保险领域也开始广泛应用。这不仅标志着科技与传统行业之间的融合越发紧密，也预示着一个全新的、更加智能化的保险时代即将到来。</p><p></p><p>有消息称，平安集团正在研发上千亿参数的模型。结合其以往在人工智能上的探索和应用经验，平安在大模型领域采取了综合性的策略，而非仅仅聚焦于提供某一类服务，如单纯的聊天或问答功能。</p><p></p><p>在日前的 InfoQ《超级连麦·数智大脑》直播节目中，德邦基金 CTO 李鑫与平安人寿科技总监魏政刚、阳光保险集团工智能部大模型首席专家张晗深入探讨了“大模型在保险业务全链路的应用”。</p><p></p><p>魏政刚指出，国内保险行业的业务模式以代理人为中心，因此人工智能和数字化转型的关键问题也是与代理人紧密相关。以平安人寿为例，其推出了基于大模型的数字人产品，主要用于协助代理人与客户沟通。这对初入行业的代理人提供了极大帮助，可以指导他们与客户交流、收集信息并提供合适的产品推荐。</p><p></p><p>当然，魏政刚也进一步解释，这不意味着大模型在保险价值链的其他环节不被应用。实际上，核保、保全、理赔等多个环节都已广泛采用人工智能技术。</p><p></p><p>但是，如果要进一步实现<a href=\"https://www.infoq.cn/article/MhabGNAVvf1NgAeZ2oIZ\">大模型</a>\"的规模化应用，保险业还必须搞定来自应用场景、语料、算力、底层技术理解、人才等五个方面的挑战。其中，算力能力与语料准确性更是重中之重。</p><p></p><p>本文整理自李鑫与魏政刚的对话内容（经 InfoQ 进行不改变原意的编辑整理）：</p><p></p><h5>李鑫：当前，国内保险行业的发展趋势如何？同时，数字化转型对保险行业又将带来哪些机遇与挑战？</h5><p></p><p></p><p>魏政刚：国内的保险业务模式主要以代理人为核心，即专属代理人模式。事实上，大部分保费和成交都是通过这个渠道完成的。当然，还有其他的销售渠道，如电网销、独立经纪人等。</p><p></p><p>在人工智能和数字化转型方面，问题的核心也是围绕代理人展开。在<a href=\"https://www.infoq.cn/article/eLIiWldQ2SVEUQFuYp2j\">保险行业</a>\"，有内勤和外勤之分，外勤通常指代理人，而内勤通常指公司总部、机构等员工。在代理人运营及其营销推广服务方面，我们看到大量的机会可以通过数字化技术来加强。</p><p></p><p>关于数字化与保险行业的结合，我们从两个维度来看：一是保险行业的价值链，二是数字化与人工智能技术的层次。</p><p></p><p>在探讨保险行业中的应用与技术结合，我们首先看这个行业的价值链或横轴。其起始点从投入开始，紧随其后的是营销和销售，接着是新业务的管理。当保单进入系统后，下一步则是核保环节。之后是我们提供的客户服务，有时也被称为保全，最后则是理赔环节。总结下来，在这个横轴上，我们主要关注五个大环节：营销、销售、新业务、核保和理赔。</p><p></p><p>从纵轴来看，这代表了人工智能的技术发展。其最底层是非常基础的原子性函数。这一层在西方的发展特别显著，因为很多底层逻辑和数据推导都起源于此。再上一层则是基础模型，如 CNN、KN、RNN 等。</p><p></p><p>再往上，则是组合算法层，其中包括多种算法的组合、参数配置以及我们在算法上的调优。再上一层，我们看到了许多人工智能框架，以及尚未开源的一些大型模型如百度、腾讯、阿里等。</p><p></p><p>在这基础上，我们面临的问题和机会点出现在横轴上的各个环节中。总的来看，人工智能大模型在保险行业的应用不仅仅是数字化的表现。人工智能为保险行业带来了巨大的促进作用，不论其是否能够引发新的商业模式，我们至少可以看到，它对我们的成本降低、业务发展、代理人的展业活动和增员板块带来了明显的促进，尤其是今年我们倡导的 MVP、QVP 和 FVP 等方面的举措。</p><p></p><h5>李鑫：在平安人寿，目前人工智能技术应用有什么关键进展？</h5><p></p><p></p><p>魏政刚：<a href=\"https://www.infoq.cn/article/RFGAkFHxTtyrAaphHBh0\">平安</a>\"集团及平安人寿很久之前便开始了人工智能产品的研发。在大模型还未在市场大放异彩之前，我们已在基础的 AI 应用上对各种产品进行了实际体现。以 2019 年和 2020 年为例，为了应对远程工作需求，我们推出了智能拜访助手。这是一个综合应用了 AI 技术的工具，涵盖了语音、画像、视频以及自动生成的话术等功能。</p><p></p><p>从应用角度看，人工智能的应用可以概括为文本、语音和图像视频这几大方向。但当它们综合运用时，就面临如何在产品形态中完美结合，以及如何将其放入最恰当的使用场景中的问题非常重要。因此，我们的努力不仅仅是在探索和使用 AI 技术，更多的是在产品的适配性和形态打磨上。</p><p></p><p>对于大模型，其在市场上的应用开始于去年下半年。随着例如 ChatGPT 在市场上的推广，我们从集团层面开始大量投资。有消息称，我们正在研发拥有千亿参数的模型。结合我们以往在人工智能上的探索和应用经验，我们采取了一个综合性的策略，而非仅仅聚焦于提供某一类服务，如单纯的聊天或问答功能。</p><p></p><p>我们所推进的技术和应用都紧密结合了我们的业务场景，而主要的焦点仍然在营销和销售端。可能有些人会好奇，为什么是营销和销售端？在保险产品方面，其同质性是显著的。保险产品并不像简单的消费品容易理解，它不仅需要一定的知识体系，还需要个人的体验以及结合理性和非理性的销售要素。</p><p></p><p>从销售的角度看，第一是保险的基本原理：第二是保险产品的知识体系，每家公司都提供的数百种保险产品，每种产品的结构，以及每种产品所带来的保障利益和应对风险的要素。因为保险消费者的需求是多样的，例如理财、保障、税收优惠、财产传承等。因此，对产品的深入了解和知识体系是至关重要的。</p><p></p><p>第三是关于销售技巧的深化和延展。在保险代理人的发展中，过去是红海模式，即“大进大出”的模式。在最高峰时期，中国的专属代理人数量达到了 1000 多万，而现今只剩下约 400 万，这样模式导致了代理人在销售技能上的参差不齐。销售是一个非常讲究专业性的领域，存在许多销售技巧。除了培训代理人，我们还需要启迪和教育客户，使他们了解保险的益处。</p><p></p><p>在保险行业中，需求激发是至关重要的一步。大部分人可能会直接表示没有保险需求，但实际上，每个人都有潜在的保障需求和对保险的期待。如何挖掘和激发这些需求是一个巨大的课题。而在这方面，大模型相对于其他技术具有显著的优势。大模型可以模拟人的思考和认知，可以为我们寻找最优解。</p><p></p><p>我们大量地聚焦在销售和营销上。但这并不意味着我们在价值链的其他环节没有利用大模型。事实上，人工智能被广泛应用于多个领域，如核保、保全、理赔等。例如，在客户服务方面，我们可以利用大量的保单信息和客户在 C 端平台上的行为轨迹来提供更优质的服务。</p><p></p><h5>李鑫：当前的通用大模型在商业化应用中面临哪些主要挑战？如何有效地突破这些障碍？</h5><p></p><p></p><p>魏政刚：对于当前大模型在商业化应用中的挑战，以下几点尤为关键：</p><p></p><p>水平应用与垂直应用：从业界沟通来看，国内市场上，针对终端消费者（ToC）的水平应用投入巨大且机会较小。相比之下，垂直应用结合针对企业的应用（ToB）可能是未来的趋势。算力问题：尽管某些应用不需要广泛的算力，但在深度学习模型的训练和推理过程中，算力仍然至关重要。当前的应用需要降低某些参数设置以适应算力限制。尽管这是一个短期挑战，随着国际关系的改善和国内半导体研发的进步，中长期内这一问题有望得到解决。语料问题：相比英文，中文语料在质量和结构化方面都存在挑战。这可能与语言特性和知识沉淀有关。特别是在保险这一行业，大量的销售技巧和知识被深埋在代理人的经验中，而这部分知识难以被结构化。尽管从英文转译到中文是一个方法，但直接从业务伙伴和代理人中提炼中文语料，或使用像 ChatGPT 这样的模型生成语料，可能会更有效。底层技术理解：虽然国内大部分 AI 应用都是在应用层，但对底层技术的深刻理解至关重要。这包括算法选择、激活函数的选择、微调策略等。这种深入的技术理解与业务理解结合起来，对于产品的成功至关重要。人才问题：我们需要业务和技术双背景的复合型<a href=\"https://www.infoq.cn/article/u7lLw2rLqF6tLIiYZXcL\">人才</a>\"，他们需要对业务有深入理解，同时对技术也有足够的掌握。</p><p></p><p>在发展前景上，大模型和多模态技术在 IT 与 AI 领域持续显示巨大潜力。虽然许多传统 IT 和 AI 技术已广泛应用，但像 Stable Diffusion、Midjourney 这样的大模型技术仍有巨大的想象空间。特别在中国这样的劳动密集、专业化市场，对这些技术的需求尤为旺盛。</p><p></p><p>以平安人寿为例，我们推出了数字人这类基于大模型的产品，主要协助代理人与客户沟通。这对初入行业的代理人特别有助，因为它可以指导他们与客户交流、收集信息并提供合适的产品推荐。虽然已获得正面反馈，但我们仍秉持互联网的试错精神，不断创新。</p><p></p><p>但我们也面临挑战，就是上面谈到的五方面。尤其在金融行业，第三点更为重要，也就是语料的准确性，因为行业受到严格监管。大模型有时会输出不准确的信息，这有很大的问题。我们现在的研究的重点是模型的实用性和合规性。对于合规性，我们不仅需要在监管文档上训练模型，还要结合实际监管案例。仅依赖大模型可能不足，像 LLaMA2 这样结合不同算法的方法可能更为有效。</p><p></p><h5>李鑫：在国内，大模型是否在 ToB 和垂直领域机会更多一些？</h5><p></p><p></p><p>魏政刚：关于大模型在业务应用上的选择和定位，可以从两个维度来考虑：水平和垂直。</p><p></p><p>首先，ToC 即面向消费者的应用，其投入巨大。在国内这一领域，几个龙头企业已经初露锋芒。与美国的情况相似，这些领军企业拥有雄厚的资金，对基础研发都非常重视。对于我们这种更偏重于金融领域的公司，如果要在 ToC 方向发力，就必须深入一个具体的垂直细分领域。因此，对于平安这样的金融科技公司，垂直应用更为合适，因为我们的目标是在金融领域通过技术进行赋能。</p><p></p><p>从平安集团的策略来看，我们正在大力发展大模型技术，已经取得了一系列进展。平安作为一家综合金融加医疗服务的企业，科技驱动下涵盖了银行、证券、保险等多个金融细分领域，因此我们需要一个深入金融领域的垂直模型。</p><p></p><p>在选择 ToC 或 ToB 时，我们也要考虑到当前大模型的特性。例如，大模型的训练是基于一段时间内的语料，而不是实时更新的。但未来，大模型可能会与搜索引擎等实时应用更紧密地结合。因此，在此背景下，面向消费者的 ToC 可能更适合由科技巨头来开发和维护。总结来说，我们认为垂直应用和面向企业的 ToB 模式更为合适。</p><p></p><h5>李鑫：未来，随着通用大模型的发展，是否会逐渐替代目前的专用 AI 模型？</h5><p></p><p></p><p>魏政刚：特定领域的 AI 技术，尤其是针对图像和语音的技术，并不会被完全取代。例如 OCR、CNN、RNN 等算法框架和基础算法仍将被广泛应用。在 NLP 领域，像分词这样的技术可能会受到挑战，因为当我们有了更先进的 Transformer 技术来解决问题。无论从学术还是工程的角度，研究和关注的方向都需要适时调整。</p><p></p><p>这不仅仅是一个简单的\"yes\"或\"no\"的问题，我们需要从两个维度去看待这个问题：一方面，从技术的分类和层次出发，看哪些技术应该或容易被替换；另一方面，根据所在行业的特性和价值链来决定哪些业务环节需要技术替换。如果某个特定的 AI 技术在特定业务领域已经表现得很好，那么可能就没有替换的必要。</p><p></p><p>决策需要谨慎，新技术出现并不意味着我们应该立即进行替换。但前瞻性研究和试点都是必要的。尽管传统领域中有些方法已经做得很好，但随着时间的推移，替代的机会和理由可能会出现。因此，我们需要两条腿走路：一方面是实际的生产和商业应用，另一方面是前瞻性的思考和尝试。这种结合可能会为公司带来更大的价值。</p><p></p><h5>李鑫：大模型应用的投入产出比如何考量？</h5><p></p><p></p><p>魏政刚：进行新技术的尝试者一定需要付出代价，但这个代价与其带来的收益并不是 1:1 的关系，而可能是 1:10。技术进步的过程中，尝鲜者有时会面临风险。我们真的需要从头训练我们的基座模型吗？在很多情况下，我们可以直接采用已经训练好的模型，如在金融领域，可以从集团获得已经训练好的模型，这样避免了重复劳动。但在特定的业务板块，仍需要进行训练。成本主要体现在训练和推理两方面。</p><p></p><p>在我们的价值链和产业链中，选择在哪个环节进行突破，需要综合考虑业务需求、公司战略以及市场变化。对于中国保险行业，我们更多地将精力放在销售和代理人上，考虑其市场特点。在推理上，提示词工程和逻辑处理也非常重要。</p><p></p><p>面对大模型的成本问题，主要考虑的是业务与市场策略的结合，以及确保资金得到合理的使用。另一方面，科技人员应当追求简洁、低成本的解决方案。</p><p></p><p>总体上，<a href=\"https://www.infoq.cn/article/eZ8J5Z7SuUSM4ql4ioVW\">技术投入</a>\"与其带来的收益是值得的。这不仅是基于我们的增长预期，也基于我们对技术，尤其是人工智能和大型语言模型，能够真正为业务赋能的信心。平安人寿的改革成果也印证了这一点，从中我们可以看到生产力和收入水平的提升。然而，如何精确计算这种技术投入与业务收益之间的平衡点仍然是个挑战，特别是对于非 IT 企业。但从我们的实际经验和进步来看，我们相信这种投入是有益的。</p><p></p><h5>李鑫：关于大模型在保险行业未来 3-5 年的应用和发展的趋势，您如何看？</h5><p></p><p></p><p>魏政刚：金融领域，尤其是保险行业，与科技的结合是当前的趋势。此前有关于“元宇宙”的讨论，这种科技能力的广泛应用也表明了科技在保险业的重要性。然而，业内的变革和演变往往需要时间。例如，从传统的代理人模式逐渐转向更高质量的模式，这一过程已经持续了很长时间，且仍在进行中。</p><p></p><p><a href=\"https://www.infoq.cn/news/Xhlku65TOzhUtKR2yaSi\">人工智能</a>\"和大语言模型在这个领域的应用，在 3-5 年内可能更多是补充性质，并不会完全替代。而且，业务可解释性是关键，人工智能和大数据的应用需要能够解释其决策和行为。中国的保险行业是强监管的，因此行业的发展和兴衰周期往往受到监管政策的直接影响。对于技术的适配性，我认为周期会更长。</p><p>未来的方向应该是释放人的潜力，将人从繁琐的日常任务中解放出来，使其能够专注于更具挑战性和深度的问题。如果未来的保险代理人或经纪人都是来自顶尖大学，那么这将是一个很好的趋势标志。在销售方面，可能会出现更多的数字化产品和形态，比如数字化的代理人。</p><p></p><p>总的来说，科技在保险行业中的进步和应用空间越来越大。中国的金融行业和企业需要找到与西方不同的发展路径，而科技结合将是这条路径的核心。希望保险行业能够通过与科技的结合，提供更真实、本质、科学和理性的服务，真正帮助人们，推动社会进步。</p><p></p><p></p><h4>关于 FCon</h4><p></p><p>首届<a href=\"https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">FCon全球金融科技大会</a>\"将于 11 月 19-20 日在上海举办。大会将围绕金融领域数字化转型挑战探索、DevOps 在金融企业落地实践、金融行业大模型应用、创新的金融科技应用、金融实时数据平台建设之路、金融安全风险管控、数据要素流通与数据合规等 10+专题进行交流。</p><p></p><p>目前大会邀请了汇丰科技中国区的代理总经理马国栋、度小满金融数据智能部总经理杨青先、蚂蚁集团副总裁 &amp; 首席技术安全官韦韬博士、恒生聚源总经理吴震操担任大会联席主席。更多嘉宾仍在邀请中......</p><p></p><p>我们诚挚地邀请您加入我们，共同探索金融科技的未来，<a href=\"https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">点击链接</a>\"即可查看全部演讲专题。</p><p></p><p>目前是 <a href=\"https://fcon.infoq.cn/2023/shanghai/apply?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">7 折特惠购票</a>\"，报名立减 ¥2040，咨询购票可联系：17310043226（微信同手机号）。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/bf/a9/bf1622c0c2be73e4d19e8643444e2fa9.jpg\" /></p><p></p>",
    "publish_time": "2023-10-23 15:54:01",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]