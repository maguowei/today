[
  {
    "title": "大规模分布式架构中，怎样设计和选择 API 限流技术？",
    "url": "https://www.infoq.cn/article/89M0flyyww6SCztD0eyT",
    "summary": "<p></p><p>&gt;本文由极客时间整理自腾讯云微服务中心高级研发工程师丁硕青在 QCon+ 案例研习社的演讲《大规模分布式架构中 API 限流技术探索与实践》。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fe/fe0a6b2f6bb0e4af3e3a72472839cdc8.png\" /></p><p></p><p></p><p>你好，我是丁硕青，目前在腾讯云负责&nbsp;API 网关等中间件产品的研发工作，工作以来主要从事云计算相关的项目，也从 0 到 1 经历过几个云产品的落地。今天主要想跟你聊聊在分布式架构中，我们应该如何设计和选择一个最适合的 API 限流技术方案。</p><p>&nbsp;</p><p>接下来，我会从以下四个章节来进行介绍：</p><p>&nbsp;</p><p>为什么需要限流常见限流算法分布式限流技术要点分布式限流实践方案</p><p>&nbsp;</p><p></p><h1>一、为什么需要限流</h1><p></p><p>&nbsp;</p><p>我们为什么需要限流？相信你在设计所有系统的时候，都会先问自己这样一个问题。</p><p>&nbsp;</p><p></p><h2>API 限流需要解决的问题</h2><p></p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/74/74d7b0ccc0bd53b940736ba179a24b78.png\" /></p><p></p><p>&nbsp;</p><p>之所以会有限流这个问题，是因为我们生活在一个资源有限的社会当中，当资源供不应求的时候，就会引发一系列的问题。为了避免资源问题，我们通常会增加对资源的限制，比如交通限行，回到 API 这个概念上同样如此。</p><p>&nbsp;</p><p>常见的 API 限流应用场景主要包含以下 4 点：</p><p></p><p>避免突发流量时，服务出现雪崩，比如早些年春运购票时系统崩溃的场景；流量整形，无论进入的流量频率如何，我们要保证请求转发到后端时是平稳的；用户&nbsp;SLA&nbsp;的分级，比如针对付费用户和免费用户，提供不同的 API QPS 额度；API 市场中的 API 商品，会通过 API 限流来满足商品库存的调用限制。</p><p>&nbsp;</p><p></p><h2>API 的限流能力</h2><p></p><p>&nbsp;</p><p>现在我们大致了解了 API 限流主要解决的问题，我们也对 API 限流需要具备的能力做一些总结和归纳。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9e/9e0b5a7ed576f0b69abf0799b40c19db.png\" /></p><p></p><p>&nbsp;</p><p>我将它分成了三类：</p><p>&nbsp;</p><p>基础限流</p><p>a. 按照一个固定的时间维度来限制 API 的调用次数，比如&nbsp;10000&nbsp;次请求/分钟。</p><p>b. 请求缓冲队列。当后端资源不足的时候，我们除了直接拒绝请求之外，还可以把请求缓冲到队列中。当后端的资源释放后，我们再把请求转发过去。这种对于没有重试逻辑的客户端来说是更友好的一种限流的行为。</p><p>&nbsp;</p><p>业务维度限流</p><p>针对 API 报文当中的业务属性进行限流，比如针对 API 的调用者，或者请求客户端 IP 去进行不同的限流。</p><p>&nbsp;</p><p>信息反馈</p><p>限流最基本的信息反馈是按照 HTTP 的标准，返回 429&nbsp;状态码。除了返回错误之外，我们还可以在请求被限流时，通过响应头返回给客户端重试的间隔时间，如&nbsp;X-Ratelimit-Retry-After: 5。当没有被限流时，我们也可以通过 X-Ratelimit-Remaing 来告知客户端剩余调用配额。这些信息都会很好地帮助客户端来进行下一步的决策。</p><p>&nbsp;</p><p></p><h1>二、常见限流算法</h1><p></p><p>&nbsp;</p><p>接下来，我们将会介绍限流中的几种非常常见的算法，主要包括：</p><p>&nbsp;</p><p>固定窗口滑动日志滑动窗口漏桶算法令牌桶</p><p>&nbsp;</p><p></p><h2>固定窗口</h2><p></p><p>&nbsp;</p><p>固定窗口是最常见的限流算法之一。其中窗口的概念，对应限流场景当中的限流时间单元。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/10/10941c83e37b0228d45ad6f044ab49d0.png\" /></p><p></p><p>&nbsp;</p><p>如上图所示，假设每秒钟限流 10 次，那么窗口大小就是 1 秒。可以看到，在第一个窗口当中每一个方块代表一个请求。绿色的方块代表可以放通给后端的请求，红色的方块代表被限流的请求。在每秒钟限流 10 次场景当中，先进窗口 1 的 10 个请求会被放通，之后的请求会被限流（红色方块）。</p><p>&nbsp;</p><p></p><h3>优势</h3><p></p><p>&nbsp;</p><p>逻辑非常简单，实现成本低，维护成本低；时间和空间复杂度低，因为只需要维护当前窗口中的一个计数器。</p><p>&nbsp;</p><p></p><h3>劣势</h3><p></p><p>&nbsp;</p><p>窗口切换时无法保证限流值。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c8/c8dca5988f46a889d371edb855d48edd.png\" /></p><p></p><p>&nbsp;</p><p>如上图，分别看两个固定窗口，窗口内的有效请求都没有超过限流值。但是我们如果在窗口交界处截取一个新的窗口，窗口中的有效请求会超过我们限流的 10 次。极端情况下，至多会有两倍于限流值的有效请求。这个问题在请求速率相对比较平稳时，影响不大。但是由于我们通常没有办法控制客户端的请求行为，所以说极端情况下，还是会对后端产生一些影响的。</p><p>&nbsp;</p><p>这个问题出现的主要原因是窗口是固定的，那么我们如果把窗口改成动态的，是否能解决呢？答案是肯定的。</p><p>&nbsp;</p><p></p><h2>滑动日志</h2><p></p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b5/b5a868d8f2d1d1a3cf31a7c5c82a4c83.png\" /></p><p></p><p>&nbsp;</p><p>在滑动日志算法中，我们需要维护每一条请求的日志。每当一个新的请求过来之后，我们会根据该请求动态计算出来当前窗口起始的边界。因为我们已经有时间戳了，所以向前遍历就可以简单地拿到边界值，之后我们会根据窗口中请求计数，和限流的值去对比，就能得出当前请求是要被限流，还是要放通。</p><p>&nbsp;</p><p></p><h3>优势</h3><p></p><p>&nbsp;</p><p>准确率 100%，因为我们保留了所有请求的日志，而且是针对每一个请求都会重新计算动态的窗口；实现成本低。</p><p>&nbsp;</p><p></p><h3>劣势</h3><p></p><p>&nbsp;</p><p>时间空间复杂度高。因为我们需要保留每一条请求的日志，在存储上面需要额外的开销。在时间复杂度上，针对每一次请求都需要去重新做动态计算，虽然我们可以通过二分查找算法来进行优化，但相比起第一个方案，还是有很大的劣势。</p><p>&nbsp;</p><p></p><h2>滑动窗口</h2><p></p><p>&nbsp;</p><p>滑动日志算法和固定窗口算法的优缺点几乎是完全相反的。那么我们将两个算法折中一下，就有了第三个算法——滑动窗口。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8d/8d84db783a3105b4a49731b4ddf0b77b.png\" /></p><p></p><p>&nbsp;</p><p>在滑动窗口的算法中，同样需要针对当前的请求来动态查询窗口。但窗口中的每一个元素，不再是请求日志，而是子窗口。子窗口的概念类似于方案一中的固定窗口，子窗口的大小是可以动态调整的。</p><p>&nbsp;</p><p>比如上图中的场景是每分钟限流 100 次。我们可以把每一个子窗口的时间维度设置为&nbsp;1&nbsp;秒，那么一分钟的窗口，就有 60 个子窗口。这样每当一个请求来了之后，我们去动态计算这个窗口的时候，我们向前最多只需找 60 次。这样时间复杂度，就可以从线性变成常量级了，时间的复杂度相对来说也会更低了。</p><p>&nbsp;</p><p>滑动窗口算法是前两个算法的折中，它在性能上明显优于第二种，但是它的准确度又差于第二种，所以它是一个比较平衡的算法。</p><p>&nbsp;</p><p></p><h2>漏桶算法</h2><p></p><p>&nbsp;</p><p>接下来要介绍两种算法，都跟桶有关，第一种叫漏桶算法。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7d/7da13e8973803f08106af5f202f69554.png\" /></p><p></p><p>&nbsp;</p><p>如图所示，在漏桶算法中，我们把每一次请求当成一个小水滴，水滴到限流组件后，我们会先把它储存在一个桶中。这个桶的底部有一个洞，会匀速地向外漏水。我们把漏水的过程想象成请求放通的过程，请求进来的速率是不能控制的，不同客户端可能有不同的速率请求。但是由于桶洞的大小可控，所以我们能保证请求转发的速率上限。</p><p>&nbsp;</p><p>在漏桶算法当中，桶的大小控制了系统能够处理的最大并发数，而实际的限流值是取决于桶最终往外漏水的流速。虽然我们把它具象成了一个桶，但从技术角度理解，它更像是一个&nbsp;FIFO&nbsp;队列。</p><p>&nbsp;</p><p></p><h3>优势</h3><p></p><p>&nbsp;</p><p>漏桶算法最大的优势在于它的流量整形功能，它适用于电商购物的支付环节，支付系统需要和上游的很多银行系统对接，这些银行系统负载能力有限，所以我们就需要针对不同的银行的 SLA 来对请求速率进行限制，避免银行系统高负载，这个场景中，漏桶算法就是一个非常合适的选择。</p><p>&nbsp;</p><p></p><h3>劣势</h3><p></p><p>&nbsp;</p><p>实现复杂度相比起前几种算法会更高，维护成本也会更高；限制了最大转发速率，所以该算法并不适用于一些流量经常会突增的场景。</p><p>&nbsp;</p><p></p><h2>令牌桶</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/52/529d1a550c7bbcd99e24abd00cfb53ae.png\" /></p><p></p><p>&nbsp;</p><p>令牌桶算法是基于漏桶之上的一种改进版本。在令牌桶中，令牌代表当前系统允许的请求上限，令牌会匀速被放入桶中。当桶满了之后，新的令牌就会被丢弃。每当有一个新的请求过来的时候，我们就尝试去桶中拿取一个令牌。如果桶中有空闲令牌，请求就可以放通；如果没有，请求将会被限流。</p><p>&nbsp;</p><p>这个算法跟漏桶比起来，最大的区别就是我们可以允许短时间的流量突增。因为在漏桶算法中，不管同时进来多少个请求，我们只能匀速地放行。但是在令牌桶当中，我们可以同时往后放行的请求数取决于桶中最大的令牌数量，也就是桶的容量。</p><p>&nbsp;</p><p></p><h3>优势</h3><p></p><p>&nbsp;</p><p>针对流量可能会出现突增且后端可以接受突增的场景，令牌桶是一种更适合的方案，因为令牌桶在限制平均请求速率的同时，还可以允许一定的突增。</p><p>&nbsp;</p><p></p><h3>劣势</h3><p></p><p>&nbsp;</p><p>实现复杂度相对较高。</p><p>&nbsp;</p><p></p><h2>小结：各算法的适用场景</h2><p></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/ce/60/ce1cd6b94c3b81fcfbffa7002079da60.png\" /></p><p></p><p></p><p></p><h1>三、分布式限流的技术要点</h1><p></p><p>&nbsp;</p><p>刚才介绍到的几种限流算法，就像在学习一门剑法时，我们掌握了的基本剑术，比如砍、劈、刺等。那么为了将这些基本的剑法应用到最终的实战当中，就需要要结合具体的实战场景来针对性分析。在分布式限流的场景当中，我们设计方案前，先要看一下限流设计时要考虑的要点。</p><p>&nbsp;</p><p></p><h2>准确性</h2><p></p><p>&nbsp;</p><p>首先要关注的就是多次提到的准确性。在分布式架构当中，同一个数据的多次操作可能在不同的节点上执行。这个时候我们就需要保证分布式系统中数据的一致性，这样才能保障多次操作的准确性。</p><p>&nbsp;</p><p>另外，我们要保证限流操作的原子性。在分布式架构当中，同一个业务操作往往包含多个子命令，子命令之间如果有其他操作干扰，会导致每次执行的结果不确定，那么就无法保证业务操作的准确性。</p><p>&nbsp;</p><p>举个例子，在固定窗口算法当中，我们需要先判断当前计数器窗口是否过期。如果是还在当前窗口，就直接计数加一；如果已经过期，我们就需要重新创建一个新的窗口。</p><p>&nbsp;</p><p><code lang=\"null\">1 if redis.call('ttl', KEY) &lt; 0 then  # 检查限流 Key 是否过期\n2     redis.call('set', KEY, COUNT, 'EX', EXP) # 设置 Key 的初始值以及过期时间\n3     return COUNT\n4 end\n5\n6 return redis.call('incrby', KEY, 1) # 计数</code></p><p>&nbsp;</p><p>这里有一次读和一次写，如果在读写过程当中又有其他的操作，对操作的 Key 做了变更，可能使读到的结果被改变，就可能会导致在限流过程中出现一些数据的误判。所以，我们需要保证该读写操作的原子性。</p><p>&nbsp;</p><p></p><h2>性能</h2><p></p><p>&nbsp;</p><p>第二点就是性能。虽然不是只有分布式架构才需要关注性能，但在分布式架构当中很可能增加分布式逻辑以及额外的链路，我们需要考虑由于分布式引起的性能额外的开销，对于业务来说是否可以接受。</p><p>&nbsp;</p><p></p><h2>可扩展性</h2><p></p><p>&nbsp;</p><p>第三点是可扩展性。我们选择分布式架构一个主要的原因，就是为了架构能够平滑扩展。这里扩展主要包含两个方面：横向扩展、纵向扩展。</p><p>&nbsp;</p><p>针对 API 限流的场景，横向扩展是指当 API 数量增加后，需要平滑地支持更多 API 对象的限流。因为每个 API 对象的限流值不一样，我们需要保证每一个 API 的限流实体能够进行独立的限流判断，不能互相影响。纵向扩展是指特定 API&nbsp;的调用量、并发量，由于业务增长，可能会从几百增长到几万，那么我们的限流也需要能支撑相应的请求量。</p><p>&nbsp;</p><p></p><h2>可用性</h2><p></p><p>&nbsp;</p><p>最后一点是可用性。我们知道限流是保护系统可用性的非常重要的一个环节，其本身的可用性也是非常重要的。如果限流这个环节出现故障，很可能引发一系列的雪灾效应。要保证限流系统的可用性，我这里列举了几个需要考量的点：</p><p></p><p>避免链路上的单点故障；如果出现故障，需要有相应的降级策略；要考虑系统的可观测性。</p><p>&nbsp;</p><p></p><h1>四、分布式限流实践方案</h1><p></p><p>&nbsp;</p><p>现在我们了解了 API 限流系统设计在分布式架构中需要关注的主要技术点，接下来我们结合腾讯云 API 网关产品的案例，一起看下具体实践的过程。</p><p>&nbsp;</p><p></p><h2>API 网关限流需求分析</h2><p></p><p>&nbsp;</p><p>在我们设计系统方案之前，我们首先要明确需求，对于 API 网关这类产品来说，它主要的限流功能需求，大概可以分成三类：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/b8/8d/b8f96812e3e998ec39a3d987417f5b8d.png\" /></p><p></p><p>第一类是针对产品 SLA 的限流。因为 API 网关有不同规格的用户实例，不同的实例对应不同的 QPS 上限。这类需求的特点是：</p><p></p><p>性能要求非常高。因为每一次请求都要经过限流这个环节，如果每次环节都带来额外的性能开销，对于很多客户来说是不能接受的。准确度要求不高。产品 SLA 层面的限流，可以容忍 5%～10%的误差。</p><p>&nbsp;</p><p>结合之前介绍的算法特点，SLA 的需求场景下，我们采用的固定窗口的算法。</p><p>&nbsp;</p><p>第二类需求是用户业务维度的自定义限流。针对不同的 API 配置不同的限流值，保护对应的后端。这类需求的特点是：</p><p>&nbsp;</p><p>对准确度要求相对高。因为主要是用来保护用户业务后端，如果限流不准可能对后端会有额外的压力。需要允许一定的流量激增范围，避免流量波动的业务被频繁限流。</p><p>&nbsp;</p><p>针对这类需求，使用令牌桶算法会更合适。</p><p>&nbsp;</p><p>第三类需求是&nbsp;API 市场的场景。比如，用户可以将自己的 API 上架到市场，同时配置一定的调用额度，调用者每调用一次，都需要支付一定的费用。</p><p>&nbsp;</p><p>这类需求对于准确性要求极高，所以这里我们选择的计数器数据结构。</p><p>&nbsp;</p><p>除了功能需求之外，在性能上也需要提前规划，比如单集群需要能够支持百万的 QPS，单 API 能支持十万的 QPS，同时也需要能够支持平滑地横向扩展。</p><p>&nbsp;</p><p></p><h2>方案一：基于&nbsp;Redis 中心存储</h2><p></p><p>&nbsp;</p><p>针对以上&nbsp;API 网关产品需求，我们最终选择的是基于 Redis 中心存储的方案。其原因主要有：</p><p></p><p>产品本身已经在使用 Redis 了，所以从架构角度来看，使用 Redis 不会引入额外的复杂度。我们用的是腾讯云上的 Redis，它对于业务方来说几乎是零运维成本。Redis 支持很多类型的存储结构，比如 String、Hash、Sorted Set&nbsp;等，这些存储结构非常适合&nbsp;API 网关这类同时存在多种限流算法的情况。</p><p>&nbsp;</p><p>当然从技术的角度来看，也完全可以采用其他的 KV 存储，比如 memcached + proxy 的方式，具体要结合实际业务和技术团队的情况来做决策。</p><p>&nbsp;</p><p>最初的方案在逻辑上是非常简单的。请求到达API网关后，网关会先通过&nbsp;Redis 中的实时计算（针对不同的场景使用不同的限流算法）判断是否要对本次 API 请求进行限流。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/52/5294769931799f2311e0b239e672026f.png\" /></p><p></p><p>&nbsp;</p><p>在这个链路当中，Redis 成为了一个关键环节，那么它本身的单点故障的风险也需要被重点考虑。针对&nbsp;Redis&nbsp;单点故障的情况，我们会将限流降级到本地进程级别来处理。降级后，由于没有了中心存储保证数据一致性，所以我们需要通过提前计算节点数量和每个节点的进程数量，来计算每个进程的限流值，这些进程限流值累加起来会接近于分布式限流的限流值。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/46/46fbd989564fd18f493e8f0af8f98c65.png\" /></p><p></p><p>&nbsp;</p><p>举个例子，假设我们现在全局限流是每分钟 1000 次。我们有两个节点，每个节点有八个进程。这个时候可以做一个简单的除法，就能得出来每个进程的限流值大约是 1000/2/8=62.5。但由于节点进程之间的流量无法保证完全均匀，所以它存在一定的准确度下降的情况，但是在故障降级这种场景当中是可以接受的。</p><p>&nbsp;</p><p>还有一点非常重要，就是在 Redis 恢复之后，仍然是需要将本地的数据同步回 Redis，避免出现限流窗口被重置，影响后端业务的情况。</p><p>&nbsp;</p><p></p><h3>方案要点</h3><p></p><p>&nbsp;</p><p>存储方面</p><p>我们依赖于 Redis 来做限流数据的存储。</p><p></p><p>性能方面</p><p>使用连接池来减少一些&nbsp;Redis 建连的的延迟。通过 Redis 的就近接入的能力，减少跨 IDC 之间的额外耗时（需要考虑主从同步延迟所引起的可能的问题）。</p><p></p><p>原子性方面</p><p>Redis 提供了 Lua 脚本的能力，可以保证脚本中限流逻辑的原子性。但是这块需要注意的是，Redis 在执行 Lua 脚本的时候，为了保证原子性，会阻塞其他脚本或操作，所以要避免脚本逻辑耗时长，影响整体性能。</p><p></p><p>容错方面 </p><p>Redis 故障时会触发降级到本地限流的逻辑。</p><p></p><p>扩展性方面</p><p>采用&nbsp;Redis 集群架构。可以支持平滑扩展节点来实现横向的扩展，但是在纵向上扩容上，Redis 确实存在瓶颈（单节点 8 ～&nbsp;10 万 QPS）。</p><p></p><p>隔离性方面</p><p>通过 Redis Key 进行逻辑的隔离</p><p>通过多个 Redis 实例来实现租户的隔离</p><p></p><p>可见性方面</p><p>日志收集监控 &amp; 告警：包含 API 网关的请求日志、组件错误日志等</p><p>系统资源监控：包含 CPU、内存、网络、磁盘等基础监控</p><p>Redis 监控：资源负载、命令耗时、慢查询、错误率等</p><p>&nbsp;</p><p></p><h3>优势</h3><p></p><p>&nbsp;</p><p>依赖 Redis 解决分布式系统中的原子性、一致性等问题，降低了系统的复杂度和运维成本。</p><p>&nbsp;</p><p></p><h3>劣势</h3><p></p><p>&nbsp;</p><p>Redis 在纵向扩展（单限流 Key）存在瓶颈；同步请求 Redis&nbsp;会增加一个毫秒级的额外延迟；依赖于中心存储，不适用于边缘计算的场景。</p><p>&nbsp;</p><p></p><h3>性能优化点：异步数据同步</h3><p></p><p>&nbsp;</p><p>针对上述提到的纵向扩展以及额外延迟的劣势，我们对方案进行了优化。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/29/29e142c091f8cf9065fc536ce15e24ff.png\" /></p><p></p><p>&nbsp;</p><p></p><h4>方案要点：</h4><p></p><p>&nbsp;</p><p>核心的优化思路就是把同步限流计算变成异步批量同步，避免 Redis 成为瓶颈。限流主要包含两个阶段：</p><p>同步阶段：处理请求时，API 网关会优先在本地内存中进行限流的逻辑处理。异步阶段：定时将内存中的限流数据和 Redis 进行同步。</p><p>&nbsp;</p><p>该方案的主要问题是，如果在异步同步前，网关接收到了大量并发请求，可能导致限流击穿，引发后端的雪崩效应。针对这个问题，我们增加了一个额外的环节，叫做同步计数检查。每一个请求来了之后，我们会先检查本地计数器是否超过了全局限流阈值的一定百分比，如果超过了，那么要强制进行 Redis 限流计算和同步。</p><p>&nbsp;</p><p>举个例子，假设限流每分钟 100 次请求，我们设置本地限流不能超过全局限流的 10%，如果本地内存计数超过了10次，就会在请求过程中同步触发一次强制的同步。通过这个机制，我们可以保证大部分请求的性能的同时，避免出现请求突增把限流打穿的场景。</p><p>&nbsp;</p><p>优势</p><p>&nbsp;</p><p>采用异步同步的机制，避免 Redis 成为瓶颈，降低了平均延迟；通过批量 Redis 同步机制，提高了限流单 Key 性能限制；可以通过调节同步限流判断阈值，来衡量性能和限流准确性。</p><p>&nbsp;</p><p>劣势</p><p>&nbsp;</p><p>由于限流数据会优先在本地内存计算，所以限流的准确性会下降；支持的场景有限，令牌桶、漏桶算法实现复杂度高。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>方案二：负载均衡 + 本地限流</h2><p></p><p>&nbsp;</p><p>除了中心存储的方案之外，我也了解过几种适用于分布式架构的限流方案，各有特点。第二个要介绍的方案是基于负载均衡将请求分发给多个服务节点，通过每个服务节点上的反向代理网关实现本地节点限流。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/41/41e1ce6482f3878981f9f17c2e510ed2.png\" /></p><p></p><p>&nbsp;</p><p></p><h3>方案要点</h3><p></p><p>&nbsp;</p><p>这个方案中，请求会通过负载均衡分发给不同的 API 服务节点。在每一个服务节点之上会部署一个 Nginx 的反应代理服务器，通过 Nginx 的 limit_req 模块配置本地限流。我们的核心思路是将一个分布式的限流负载均衡后转化成了每个节点的本地限流。和上一个方案的本地限流场景类似，我们同样需要根据节点数量来计算每个节点的限流值。</p><p>&nbsp;</p><p></p><h3>优势</h3><p></p><p>&nbsp;</p><p>本地内存限流，低延迟，同时可以实现 ms 级的限流时间粒度；方案简单，实现成本和运维成本都比较低。</p><p>&nbsp;</p><p></p><h3>劣势</h3><p></p><p>&nbsp;</p><p>准确率不高，因为该方案依赖于负载均衡将流量均匀地分发给每一个节点，但实际场景中流量是不均匀的；扩缩容时，我们需要重新计算单节点限流值。</p><p>&nbsp;</p><p></p><h2>方案三：一致性哈希</h2><p></p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4d/4d8d1bb76dbe0d196706fae859c769dc.png\" /></p><p></p><p>&nbsp;</p><p></p><h3>方案要点</h3><p></p><p>&nbsp;</p><p>第三个方案跟第一个中心存储的方案类似，都是采用了中心化限流的设计思路。这个方案没有依赖中心存储，而是通过一致性哈希算法对限流对象的 Key 哈希后分配到一个固定的限流节点上。这个 API 后续请求就都会落到同一个节点上，所以本质上我们还是将分布式限流，转化成了节点的本地限流来解决。</p><p>&nbsp;</p><p></p><h3>优势</h3><p></p><p>&nbsp;</p><p>本地内存限流，低延迟；方案简单，实现、运维成本低；通过一致性哈希，一定程度上能降低由于节点增减造成的节点重新分配的概率。</p><p>&nbsp;</p><p></p><h3>劣势</h3><p></p><p>&nbsp;</p><p>节点变更还是有概率会影响准确率；单一限流对象的请求只会分配到一个节点上，虽然可以对节点进行垂直扩容，但同样存在扩容上限。</p><p>&nbsp;</p><p></p><h2>方案四：客户端限流</h2><p></p><p>&nbsp;</p><p>第四个方案是客户端限流，可能有人会问，客户端限流跟服务端的区别到底是什么？</p><p>&nbsp;</p><p>我们可以通过一个现实的例子，来更好的理解这个问题。假设我计划第二天去动物园，这个时候我有两种方式购票。第一种是我第二天直接去动物园门口去买票，但有可能我到那之后发现票卖光了，会导致我在路上的时间都浪费掉了。另外一种方式就是我提前一天预约购票，这样就可以提前确认是否可以成行，避免出现浪费时间的情况。</p><p>&nbsp;</p><p>再回到客户端限流这个场景中，如果我们把限流这个环节从服务端移到客户端的话，我们可以尽早地避免这些被限流的请求发生，节约更多的资源。但是为了实现在客户端侧的限流，我们需要一些额外的机制。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/92/92d5f8f914598b04034aac486afc5532.png\" /></p><p></p><p>&nbsp;</p><p></p><h3>方案要点</h3><p></p><p>&nbsp;</p><p>首先，我们需要一个配额服务来管理服务端能承载的最大配额，同时根据客户端诉求，将配额分发给每个客户端。这个配额服务就起到了协调器的作用，它能够保证在整个服务调用链当中所有的客户端调用总和不超过服务端的配额大小。那它的配额从哪来呢？</p><p>&nbsp;</p><p>我们还需要另外一个数据平台，它从服务端采集到服务的负载状态等信息，通过实时分析，计算出服务能够承载的请求上限。之后再将数据更新到配额服务中，最后由配额服务重新复配给客户端，这样就完成了一个周期。</p><p>&nbsp;</p><p>可以看到，它在架构上相对前面的方案来说会增加一些复杂性，但同时更灵活，因为每个客户端可以根据自己的属性、标签来获取它自己想要的配额。最终是否能分发给客户端这么多配额，是由配额服务上面的一些配置策略决定的。我们甚至还可以基于 AI 算法通过历史数据来预测未来的一些配额可能发生变化，来对配额进行预分配。</p><p>&nbsp;</p><p>可以看到，在客户端限流方案当中，它需要客户端是可控的，因为我们需要在客户端侧做很多逻辑。如果这个客户端不可控，某一个客户端没有按照协定的配额来进行请求，则会打破整体的规则。</p><p>&nbsp;</p><p></p><h3>优势</h3><p></p><p>&nbsp;</p><p>在请求的源头增加限制，避免更多的资源浪费；配额异步同步，客户端可以实现本地限流，所以在性能上也非常好；单限流对象（限流Key）不存在垂直扩容的问题。</p><p>&nbsp;</p><p></p><h3>劣势</h3><p></p><p>&nbsp;</p><p>它依赖于客户端的可控性，限制了使用场景；没有办法保证全局限流的准确性难以保障。</p><p>&nbsp;</p><p>思路参考 —— Google Doorman： <a href=\"https://github.com/youtube/doorman\">https://github.com/youtube/doorman</a>\"</p><p>&nbsp;</p><p></p><h2>方案对比</h2><p></p><p>&nbsp;</p><p>前面介绍了四种分布式限流当中的方案，每一种方案都有它的优势和缺点，没有哪一种是完美的。所以在我们选择方案时，还是要针对自己的业务需求，在多个方案的优缺点中进行取舍，来选择最适合的场景。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/8e/44/8e2b1ayya7b0c6121e3cda598d3da244.png\" /></p><p></p><p></p><h2>思考</h2><p></p><p>&nbsp;</p><p>在限流设计当中，不管采用哪种方案，通常都会有一些共性的设计考虑点。</p><p>&nbsp;</p><p>尽可能地将限流逻辑前置，减少不必要的资源消耗。</p><p>&nbsp;</p><p>在设计限流 Key 的时候，尽量向后兼容，因为可能由于业务需求变化，导致变更限流算法，如果 Key 的规则中对算法数据结构强绑定，那么变更算法会导致存量的限流失效。</p><p>&nbsp;</p><p>我们在限流 Key 的设计当中要加入足够多的业务标识，当出现限流不准问题的时候，我们可以快速地定位到问题，提高 Debug 效率。</p><p>&nbsp;</p><p>Less Code == Less Bug。初始设计的时候，工程师确实要考虑后续可能出现的场景兼容问题，但没有必要为了小概率场景过早地进行复杂设计和实现。因为过度设计会增加复杂性，也可能会引入更多不确定的问题。</p><p>&nbsp;</p><p></p><h1>总结：如何设计限流系统？</h1><p></p><p>&nbsp;</p><p>最后我们还是要总结一下设计限流系统的几个关键步骤。</p><p>&nbsp;</p><p></p><h3>1. 收集需求</h3><p></p><p>&nbsp;</p><p>一开始，不要着急去选择算法和设计方案，而是先把需求梳理清楚，比如产品有哪些场景会用到限流？系统上都需要考虑哪些关键点？目前公司是否已经有现成的方案？这些都是决定了我们后面决策的一些重要因素。</p><p>&nbsp;</p><p></p><h3>2. 选择算法</h3><p></p><p>&nbsp;</p><p>根据业务场景来选择合适的算法，这里你可以重点参考算法的对比表格。</p><p>&nbsp;</p><p></p><h3>3. 设计方案</h3><p></p><p>&nbsp;</p><p>在方案设计的时候，根据收集到的需求来选择一个合适的技术架构。如果公司内部已经有现成的限流系统，我们也可以去考虑一下是不是可以避免重复造轮子。最后要额外强调的是，限流是保护服务的一个兜底手段，所以要重点考虑限流系统本身的稳定性机制（容灾、降级、监控等）。</p><p>&nbsp;</p><p>在结束之前，我想跟你分享一个我个人比较认可的观点：没有完美的技术方案，只有最合适的。如尚未深思熟虑，先从简单方案开始。</p><p>&nbsp;</p><p>希望以上内容对你有所帮助。&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9b/9b8ae7d03c69eef4b3768f8e3ff14127.png\" /></p><p></p><p></p><p>作者介绍</p><p>&nbsp;</p><p>丁硕青，腾讯云 微服务中心 高级研发工程师</p><p>&nbsp;</p><p>腾讯云 API 网关专享实例研发负责人，主导过 PaaS 产品从 0 到 1 的落地，目前主要负责腾讯云 API 网关架构设计、性能优化及核心模块开发。曾就职于新浪、Dropbox、白山云、腾讯云等公司，对分布式系统有较深入研究。</p><p></p><p>活动推荐</p><p></p><p>QCon+ 案例研习社（又名：大厂案例）是极客时间平台推出的视频案例课。内容由领域内技术专家出品审核、数百位不同大厂/独角兽公司的一线开发工程师、项目经理、产品经理、咨询师和Tech Lead亲身分享，所有实践案例都经过至少三个月打磨。QCon+专注于提供最接地气、最可靠的技术解决方案，目前已更新90+专题、300+实战案例。专题每周一持续更新中，敬请期待！</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e3/e3fe39acbf14ec6ce3a847198046ded6.png\" /></p><p></p><p>&nbsp;</p><p></p>",
    "publish_time": "2022-08-23 00:10:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "企业到底需要怎样的湖仓一体架构？",
    "url": "https://www.infoq.cn/article/DFjQpOu2HBV4AVXlXTZy",
    "summary": "<p>在愈发复杂的大数据场景下，数据仓库与数据湖各自的弊端开始显现，湖仓一体架构走向舞台中央。此前，InfoQ 也曾在 <a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651104846&amp;idx=2&amp;sn=482413c62deb132c6923e64e58361a86&amp;chksm=bdb95e1d8aced70b6dec29e2c4e4975b8b14519d66292ff633f286d93e2bf5f29c92102d0929&amp;scene=21#wechat_redirect\">《湖仓一体会成为企业的必选项吗？》</a>\"一文中提到，对于高速增长的企业来说，选择湖仓一体架构来替代传统的独立仓和独立湖，将成为不可逆转的趋势。</p><p></p><p>虽然业界对于湖仓一体的价值是高度认同的，但作为一种新兴的架构，大多数公司对于湖仓一体仍处在初期的探索阶段，有些企业甚至对于要选择怎样的湖仓一体架构仍旧是云里雾里。本文，我们希望从技术选型的角度出发，让你重新理解湖仓一体的本质与要求，扫除技术选型过程中的迷雾。</p><p></p><h2>实时性数据分析需求暴增</h2><p></p><p></p><p>若想真正理解湖仓一体的真正内涵，这需要我们回溯到企业的数据使用场景：我们发现，它早已悄无声息地完成了从离线场景到实时数据分析场景的转变。</p><p></p><p>在以往，企业主要是利用离线场景对历史数据进行分析，而随着业务发展到一定规模以后，离线数据的缺点就愈发凸显，公司的业务方、决策方对实时化数据提出了更高的诉求，希望从业务端获取到数据以后，便能够立即被清洗处理，从而满足基于数据的事前预测、事中判断和事后分析。在 《ANCHOR 区分湖仓一体和湖仓分体的锚》 研究报告中，还分别从四个层面指出了实时数据分析的需求场景：</p><p></p><p>运营层面：实时业务变化、实时营销效果、当日业务趋势分析；用户层面：搜索推荐排序、实时行为等特征变量的生产，为用户推荐更精准的内容；风控层面：实时风险识别、反欺诈、异常交易等；生产层面：实时监控系统的稳定性和健康状况等。</p><p></p><p>不难发现，无论是互联网企业还是传统企业，数据的时效性都被摆在了重要位置，甚至有些企业已经从 PV、UV 指标等单点实时化进阶到了全面实时化的阶段。也正于因此，数据的时效性也就成为了企业判断自身架构设计是否满足真正湖仓一体的关键因素。</p><p></p><p>总体来看，企业到底需要怎样的湖仓一体架构？除了要满足实时化数据需求这一关键要素以外，数据一致性、超高并发、云原生、支持多类型数据以及一份数据也被列入了湖仓一体的 ANCHOR 六大特征。</p><p></p><h2>基于新一代云原生数据仓库的湖仓一体架构</h2><p></p><p></p><p>如前文所言，随着市场竞争和用户需求的不断变幻，企业对于数据的时效性需求不断攀升，但实时数据的分析场景出现以后，也给数据技术的实现带来了很大的挑战。目前，无论是擅长事务型工作的数据仓库，还是数据类型更为丰富的数据湖，亦或是 Hadoop+MPP 模式下的湖仓分体，其都是基于 T+1 设计的，即便引入了流处理引擎实现了部分固定模式的实时分析，仍无法达到 T+0 全实时的水平。</p><p></p><p>为了让数据实现全面实时化，行业内也衍生出了不同的湖仓一体方案，可以将其大致分为两类：一类是基于 Hadoop 的改造方案，拿 Hudi、Iceberg 两款开源数据湖项目为例，结构化、半结构化及非结构化的数据通过 SparkSQL/Flink 引擎不断流转与计算，再基于 HDFS/S3 实现事务存储，但此类方案在性能支持上与 Hadoop 的区别并不大；</p><p></p><p>另一类则是从新的基础架构发展出的云原生数据仓库，其中比较典型的代表有 Snowflake、OushuDB 方案，二者均突破了传统 MPP 和 Hadoop 的局限性，实现了存储和计算的完全分离，并且通过虚拟计算集群技术，其单个集群可以达到数万节点，同时在复杂查询性能和 SQL 兼容性上也非常完善。在国外，Snowflake 可以算作落地湖仓一体的成功先例之一，而偶数科技围绕 OushuDB 提出的湖仓一体解决方案，也成为国内该赛道中的一颗耀眼的新星。</p><p></p><p>若想了解 OushuDB 性能的强大之处，我们大抵可以从以下这组公开数据中窥知一二：由于 OushuDB 使用了 SIMD（单指令多数据流）的执行器优化策略，其全面性能超过 Spark 性能相差 8 倍以上，最大相差 55 倍。通过横向对比几类湖仓一体解决方案，我们发现，在 T+0</p><p>全实时方面，基于 OushuDB 的方案也展现出了较大的优势。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/14/144435ab383ca92b4dadc2cd2189ce34.png\" /></p><p></p><h2>偶数科技的实时湖仓是怎样炼成的？</h2><p></p><p></p><p>那么问题来了，偶数科技是如何实现具备实时能力的湖仓一体架构？我们可以先从 Lambda 以及 Kappa 这两种典型架构的优劣说起。</p><p></p><p>为了能够让流处理与批处理配合使用，Lambda 架构应运而生，基于这套架构，任务可以根据是否需要被实时处理进行分离，然而，这套架构背后也隐藏了很多问题。首先，离线和实时两套方案会产生不同的计算结果，当发生数据产生不一致问题时，对比排查需要花费较长时间。此外，由于 Lambda 架构由多个引擎和系统组成，其学习成本、运维成本也相对较高。</p><p></p><p>可见，Lambda 架构在开发割裂感、资源重复、集群维护成本以及数据一致性等问题上存在较大的问题。为了解决 Lambda 架构需要维护两套代码的难题，Kappa 架构又出现了，即在 Lambda 架构的基础上移除了批处理层，利用流计算的分布式特征，加大流数据的时间窗口，统一批处理和流处理，最终处理后的数据可以直接给业务层使用。相比之下，虽然 Kappa 架构的优点显而易见，但其也存在以下两方面的缺点：</p><p></p><p>依赖 Kafka 等消息队列来保存所有历史，而 Kafka 难以实现数据的更新和纠错，发生故障或者升级时需要重做所有历史，周期较长；Kappa 依然是针对不可变更数据，无法实时汇集多个可变数据源形成的数据集快照，不适合即席查询。</p><p></p><p>面对 Lambda 架构与 Kappa 架构的局限性，业内也亟需一种新型技术架构来满足企业的实时分析需求。为此，偶数科技在 2021 年初提出了同时满足实时流处理、实时按需分析以及离线分析的 Omega 架构，其是根据流数据处理系统和实时数仓构成的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b3/b3c9f4f0023b534088d2a983fde80526.png\" /></p><p></p><p>需要强调的一点是，在 Omega 架构中需要变更流处理版本时，不再需要流处理引擎访问 Kafka，直接访问 OushuDB 即可获得所有历史数据，这样一来，便规避了 Kafka 难以实现数据更新和纠错的问题，大大提升了数据处理的效率。在 Omega 全实时架构的加持下，偶数科技实现了具备实时能力的湖仓一体，即实时湖仓。</p><p></p><h2>写在最后</h2><p></p><p></p><p>深入剖析了数据使用场景，我们发现大数据平台不仅需要适配复杂的数据生产环境，还需要同时满足业务对于时效性的追求。可见，离线分析场景的数据诉求已经与企业渐行渐远，抓住实时业务场景的数据需求才能让企业在数字化转型的大潮中站稳脚跟。</p><p></p><p>而在全面实时化的进程中，相信具备实时能力的湖仓一体方案将发挥其独特的优势，从而切实助力企业提升数据的价值。</p>",
    "publish_time": "2022-08-23 09:23:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "端云协同：怎样才能将“云计算的优势”发挥到极致？",
    "url": "https://www.infoq.cn/article/qhD97h4sS6l225DvSx9P",
    "summary": "<p>过去，在硬件成本逐渐降低、通信带宽及计算能力提升、传感器感知能力不断演进的大背景下，传统计算的处理方式是，将任务聚合到大型机上集中处理，之后再分散到用户终端设备进行处理，最后将大部分计算任务重新返回至云计算中心做处理。</p><p></p><p>现在，在“云服务、大数据、人工智能、5G”等技术不断演进的浪潮下，各种智能应用进入高速发展阶段。本地计算需求呈现指数级增长，将计算任务和数据全部交给集中式的云来处理并不现实，这种处理方式严重依赖网络环境，风险大大提高。</p><p></p><p>于是，既能充分发挥云计算优势、又能调动端计算敏捷性的“端云协同”成为了合理且如今常用的解决方案。再加上，企业数字化转型进入全面融合期，端侧越来越智能、云侧与端侧的互动越来越密切，端云协同成为了众多开发者竞相研究的技术方向。</p><p></p><p>为了赋能开发者在“端云协同”技术领域的能力成长，OPPO 将于 2022 年 9 月 17 日在南京金茂威斯汀大酒店为全球开发者提供一个开放、健康的技术交流平台——OGeek 技术峰会。本届 OGeek 技术峰会将以“云无界、端无边”为主题，与各位开发者一起探讨音视频、云渲染、AIoT、一站式应用开发等热门技术的演进方向，共建端云协同生态。</p><p></p><p>值得一提的是，“OGeek Day”是由 OPPO 数智工程系统主办的行业技术沙龙品牌，旨在为技术爱好者搭建一个技术交流和分享的开放平台。沙龙主要围绕“科技为人、以善天下”的技术理念，聚焦于为智能终端提供安全高效的数据、算力、算法、云服务方面的前沿技术，打造技术互动的行业生态，探索技术在行业应用的实践、突破及未来发展方向。</p><p></p><p>本届 OGeek 技术峰会将突破以往“沙龙”的局限，扩大了交流范围与场地，峰会议程上设计了“1 个主会场 +3 个分会场”，从上午 9 点到下午 17 点，所有到场的开发者都将体会到极致技术交流的爽感。</p><p></p><p>9&nbsp;月&nbsp;17&nbsp;日上午，阿里云媒体与融合通信事业部副总经理郝冲、亚马逊云科技首席解决方案架构师费良宏、OPPO 云计算中心总经理鲍永成三位端云协同领域的技术大牛将在主会场与大家见面，与各位开发者一起明确“端云协同”背景下多领域发展痛点、复盘行业技术演进过程、前瞻技术发展方向。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/61/a7/61334b794427067f5d9bdf33179897a7.jpg\" /></p><p></p><p></p><h2>端云一体化，视听新体验</h2><p></p><p></p><p>数字经济席卷各个行业，编解码、RTC 等音视频技术和云渲染技术在短视频、游戏、数字孪生、VR／AR 等新型领域得到广泛应用。像直播、云游戏、实时数字孪生这些新兴业务场景，目前正在不断与金融、医疗、工业等行业进行深度融合。可以说，音视频和云渲染间接助推了传统企业的数字化转型。</p><p>在当下开发者们都在讨论的“音视频 +”这个热门概念中，“RTC+5G”给各种业务场景下的移动体验带来了更丰富的视觉感受和想象空间。</p><p></p><p>而云渲染技术，其实就是把之前在本地设备上完成的渲染工作转移到云端进行，将计算完成的音视频流压缩后再传输至用户终端。此时，终端设备通过解码显示渲染结果，同时将新的操作指令返回到云上，从而完成“云渲染”。</p><p></p><p>在一般的业务场景中，为了将产品性能调教到最优，云渲染与音视频往往都是要一起考虑的。像泛娱乐社交类短视频应用，几乎每一个功能都离不开音视频、云渲染技术。本届 OGeek 技术峰会的“端云一体化，视听新体验”分会场，将与各位开发者一起讨论 RTC、云渲染及电商短视频场景下的技术发展。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/9d/a5/9d89eca4e5c96576f2724c7df95003a5.jpg\" /></p><p></p><p></p><h2>AIoT，智联生活新未来</h2><p></p><p></p><p>随着 5G、人工智能、传感器等技术的演进，世界正在实现万物互融。如今，经济发展、城市运行乃至个人生活都在向“数字化、智能化”方向演进，现实世界与虚拟的数字世界正在逐步实现深度链接。</p><p></p><p>从市场规模层面来看，以家居、穿戴设备、汽车为代表的消费驱动，与以智慧城市为代表的政策驱动，使 AIoT 产业在近年来保持高速增长。根据 IDC 的数据，2019 年全球 AIoT 市场规模达到 2264 亿美元，预计 2022 年将达到 4820 亿美元，2019-2022 年复合增长率为 28.65%。</p><p></p><p>“AIoT”即“AI+IoT”，人工智能技术与物联网技术的融合。如今越来越多的企业将 AI 与 IoT 结合到一起，将 AIoT 列为其主要发展方向，这已然成为物联网发展的趋势。</p><p></p><p>AI 与 IoT 两种强大技术的结合增加了应用的敏捷性和灵活性，IoT 自身的设备信息通过 AI（如添加机器学习算法）的调教，可以学习用户行为、构建用户画像、帮助用户快速做出决策，这也是 AIoT 最大的优势，让“人工智能”走向“应用智能”。</p><p></p><p>本届 OGeek 技术峰会的“AIoT，智联生活新未来”分会场，各位开发者将基于端云协同的实践案例共同讨论 AIoT 在各场景下的技术发展。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/e8/ac/e8b495d50af7000b85bb5bb103e7b1ac.jpg\" /></p><p></p><p></p><h2>重新定义“一站式”应用开发</h2><p></p><p></p><p>当前数字化转型的形势下，软件行业面临着巨大的市场机遇，而软件系统复杂度不断增加，跨地域高效协作、多环境部署等问题也逐渐突出。不仅如此，如今许多软件厂商还面临着 APP 软件开发成本增长、客户需求多变的现实问题，这让“一站式”应用开发平台技术进入飞速发展的快车道。</p><p></p><p>对于企业来讲，使用应用开发平台的目的，无非就是提升移动研发效能，或者是类 DevOps 提高协作效率。但在具体实践中，不同的企业、业务线和产品之间的需求都存在着巨大差异，很多开发者称，“很难有一个平台或工具能适配所有场景、解决所有问题。”</p><p></p><p>现实真的如此骨感吗？什么样的应用开发平台平台才能算的上是“一站式”？目前市面上已经有的“一站式”应用开发平台都发展的如何了？到底有没有真正地解决开发者的痛点？真的没有一款完美的应用开发平台吗？“一站式”应用平台技术在未来将有怎样的演进？</p><p></p><p>这些问题，开发者们都将在 OGeek 技术峰会的“重新定义“一站式”应用开发”分会场中得到答案。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/d3/8f/d3c338f5887a1111be815c7f50f2ac8f.jpg\" /></p><p></p><p>如果你对以上话题感兴趣，请识别下方二维码报名参加“云无界、端无边”OGeek 技术峰会吧！2022 年 9 月 17 日，我们在南京金茂威斯汀大酒店不见不散！</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/92/79/9258075211ab415133c96682a52d4779.png\" /></p><p></p>",
    "publish_time": "2022-08-23 09:42:51",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Java近期新闻：Extent-Local变量、Payara平台、Reactor项目、Ktor、Spring Web Flow",
    "url": "https://www.infoq.cn/article/CrawrNS1O2G6CXp2F9dM",
    "summary": "<p>本期Java近期新闻主要涉及OpenJDK、JDK 19、JDK 20、Jakarta EE 10、Spring WebFlow 3.0.0-M1、Spring Tools 4.15.3、Payara Platform Enterprise 5.42.0、Quarkus 2.11.2、MicroStream 7.0.1-beta、Piranha 22.8.0、JobRunr 5.1.7、Eclipse Vert.x 4.3.3、Reactor 2022.0.0-M5、Ktor 2.1.0、Apache Camel 3.18.1和KCDC大会。</p><p></p><h3>OpenJDK</h3><p></p><p>JEP 429——<a href=\"https://openjdk.org/jeps/429\">Extent-Local</a>\"<a href=\"https://openjdk.org/jeps/429\">变量（第一孵化阶段）</a>\"——从JEP Draft 8263012&nbsp;状态提升至Candidate 状态。这个<a href=\"https://openjdk.java.net/jeps/11\">孵化中的JEP</a>\"是<a href=\"https://wiki.openjdk.java.net/display/loom/Main\">Loom项目</a>\"的一部分，旨在实现线程内和线程间不可变数据的共享。它优于thread-local变量，尤其是在大量使用虚拟线程时。InfoQ后续将带来更详细的报道。</p><p></p><h3>JDK 19</h3><p></p><p>JDK 19<a href=\"https://jdk.java.net/19\">早期访问构建</a>\"的<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-19%2B35\">Build 35</a>\"在上周发布，它是<a href=\"https://github.com/openjdk/jdk/compare/jdk-19%2B34...jdk-19%2B35\">Build 34</a>\"的升级，修复了各种<a href=\"https://bugs.openjdk.org/issues/?jql=project%20%3D%20JDK%20AND%20fixversion%20%3D%2019%20and%20%22resolved%20in%20build%22%20%3D%20b35%20order%20by%20component%2C%20subcomponent\">问题</a>\"。要了解更多细节信息，请查看<a href=\"https://jdk.java.net/19/release-notes\">发布说明</a>\"。</p><p></p><h3>JDK 20</h3><p></p><p>JDK 20<a href=\"https://jdk.java.net/20/\">早期访问构建</a>\"的<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-20%2B10\">Build 10</a>\"在上周发布，它是Build 9的<a href=\"https://github.com/openjdk/jdk/compare/jdk-20%2B9...jdk-20%2B10\">升级</a>\"，修复了各种<a href=\"https://bugs.openjdk.org/issues/?jql=project%20%3D%20JDK%20AND%20fixversion%20%3D%2020%20and%20%22resolved%20in%20build%22%20%3D%20b10%20order%20by%20component%2C%20subcomponent\">问题</a>\"。要了解更多细节信息，请查看<a href=\"https://jdk.java.net/20/release-notes\">发布说明</a>\"。</p><p>&nbsp;</p><p>对于<a href=\"https://openjdk.java.net/projects/jdk/19\">JDK 19</a>\"和<a href=\"https://openjdk.java.net/projects/jdk/20/\">JDK 20</a>\"，我们鼓励开发者通过<a href=\"https://bugreport.java.com/bugreport/\">Java Bug数据库</a>\"报告缺陷。</p><p></p><h3>通往Jakarta EE 10之路</h3><p></p><p>在通往Jakarta EE 10的道路上，Eclipse 基金会Jakarta EE开发大使<a href=\"https://se.linkedin.com/in/ivargrimstad\">Ivar Grimstad</a>\"在其Hashtag Jakarta EE每周<a href=\"https://www.agilejava.eu/\">博文</a>\"中<a href=\"https://www.agilejava.eu/2022/08/07/hashtag-jakarta-ee-136/\">宣布</a>\"，<a href=\"https://jakarta.ee/specifications/coreprofile/10/\">Core Profile</a>\"&nbsp;of Jakarta EE 10的投票截止日期是8月15日。Eclipse GlassFish 7.0.0-M7已经通过Jakarta EE Platform TCK测试。Jakarta Concurrency 3.0的TCK工作还在继续，目标是将其包含在Jakarta EE 10 Web Profile中。</p><p></p><h3>Spring Framework</h3><p></p><p>在上一个版本集发布四年之后，<a href=\"https://spring.io/blog/2022/08/10/spring-web-flow-3-0-m1-released\">第一个里程碑版本</a>\"Spring Web Flow 3.0发布。该版本主要是为了与Spring Framework 6.0和Jakarta EE保持一致，并相应地更新了<a href=\"https://github.com/spring-projects/spring-webflow-samples\">Spring Web Flow示例</a>\"。该版本还移除了<a href=\"https://docs.pivotal.io/tiledev/2-9/tile-basics.html\">Tile</a>\"应用，代之以<a href=\"https://www.thymeleaf.org/doc/articles/layouts.html\">Thymeleaf页面布局</a>\"，因为Tile 没有迁移到Jakarta EE。此外，因为与JSF深度集成，所以Spring Faces也没有包含在这个版本中。</p><p>&nbsp;</p><p>在4.15.2发布一周之后，Spring Tools 4.15.3<a href=\"https://spring.io/blog/2022/08/12/spring-tools-4-15-3-released\">发布</a>\"，提供了一些Bug修复：Spring Boot Tool降低代码补全速度；复制的文件未保留版权归属。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/spring-projects/sts4/wiki/Changelog#2022-08-11-4153-release-incl-language-servers-version-1380\">变更日志</a>\"。</p><p></p><h3>Payara</h3><p></p><p>Payara Platform Enterprise 5.42.0<a href=\"https://blog.payara.fish/whats-new-in-the-august-2022-payara-platform-release\">发布</a>\"，重点是解决了<a href=\"https://nvd.nist.gov/vuln/detail/CVE-2021-37422\">CVE-2021-37422</a>\"漏洞。这是一个零日漏洞，会影响部署在<a href=\"https://www.payara.fish/\">Payara平台</a>\"所有发行版默认上下文根路径下的Web应用程序。此外，该版本还包含5项Bug修复、1项改进和一个组件升级。这些修复也会包含在即将于2022年8月15日发布的版本Payara 6 Community（Alpha 4）和Payara Community Version 5.2022.3中。</p><p></p><h3>Quarkus</h3><p></p><p>红帽公司<a href=\"https://quarkus.io/blog/quarkus-2-11-2-final-released/\">发布</a>\"了Quarkus 2.11.2。在这个版本中，团队还在设法寻找全面修复<a href=\"https://bugzilla.redhat.com/show_bug.cgi?id=2108396\">CVE-2022-2466</a>\"漏洞的方法。这是在SmallRye GraphQL服务器扩展中发现的一个漏洞，其表现是服务器请求无法正常终止。人们原以为这个漏洞只会影响2.10.x版本序列。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/quarkusio/quarkus/releases/tag/2.11.2.Final\">发布说明</a>\"。</p><p></p><h3>MicroStream</h3><p></p><p>MicroStream 7.0.1-beta<a href=\"https://github.com/microstream-one/microstream/releases/tag/07.01.00-MS-beta1\">发布</a>\"，增强了多个特性：根据配置的通道计数验证通道文件夹，不匹配则抛出有意义的异常；在GC中增加活动对象检查，保证还在虚拟机中活动的对象会保留在存储中。</p><p></p><h3>Piranha</h3><p></p><p>Piranha 22.8.0<a href=\"https://github.com/piranhacloud/piranha/releases/tag/v22.8.0\">发布</a>\"。这个代号为“Hello, Expressly 5”的8月版本主要带来了这样一些特性：修复若干代码异味；一个依赖项升级到<a href=\"https://github.com/eclipse-ee4j/grizzly/blob/master/README.md\">Eclipse Grizzly</a>\"&nbsp;4.0.0；促成<a href=\"https://jakarta.ee/specifications/expression-language/5.0/\">Jakarta Expression Language</a>\"&nbsp;5.0规范TCK；修复<a href=\"https://github.com/piranhacloud/piranha/blob/current/http/virtual/src/main/java/cloud/piranha/http/virtual/VirtualHttpServer.java\">VirtualHttpServer</a>\"类中的测试错误。要了解关于这个版本的更多细节，请查看<a href=\"https://javadoc.io/doc/cloud.piranha/project/latest/index.html\">文档</a>\"和<a href=\"https://github.com/piranhacloud/piranha/issues?q=is%3Aissue+-label%3Awontfix+milestone%3A22.8.0+is%3Aclosed\">问题跟踪系统</a>\"。</p><p></p><h3>JobRunr</h3><p></p><p><a href=\"https://www.linkedin.com/in/ronalddehuysser/\">Ronald Dehuysser</a>\"是<a href=\"https://www.jobrunr.io/\">JobRunr</a>\"——一个执行Java后台处理的实用工具——的创建者和主要开发人员。该工具的5.1.7版本已<a href=\"https://github.com/jobrunr/jobrunr/releases/tag/v5.1.7\">发布</a>\"，提供了对Java平台模块系统的初步支持，并修复了job方法自JobRunr 4.0.2以来不支持双数组参数的问题。</p><p></p><h3>Eclipse Vert.x</h3><p></p><p>作为对4.3.2版本中发现的多个Bug的回应，Eclipse Vert.x 4.3.3<a href=\"https://vertx.io/blog/eclipse-vert-x-4-3-3/\">发布</a>\"。该版本修复了那些Bug，并在文档中记录了<a href=\"https://github.com/vert-x3/wiki/wiki/4.3.3-Deprecations-and-breaking-changes\">弃用和破坏性更改</a>\"。此外，该版本为最近发布的<a href=\"https://github.com/vert-x3/vertx-virtual-threads-incubator\">虚拟线程孵化项目</a>\"提供了初步支持。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/vert-x3/wiki/wiki/4.3.3-Release-Notes\">发布说明</a>\"。</p><p></p><h3>Reactor项目</h3><p></p><p>在通往Reactor 2022.0.0的道路上，<a href=\"https://github.com/reactor/reactor/releases/tag/2022.0.0-M5\">第五个里程碑版本</a>\"发布，主要是依赖项升级，涉及以下工件：reactor-core&nbsp;3.5.0-M5、reactor-netty&nbsp;1.1.0-M5和2.0.0-M1 以及reactor-kafka&nbsp;1.3.12。以下工件没做什么修改，但对齐到了里程碑版本，包括：reactor-pool&nbsp;1.0.0-M5、reactor-addons&nbsp;3.5.0-M5和reactor-kotlin-extensions&nbsp;1.2.0-M5。</p><p></p><h3>Ktor</h3><p></p><p>JetBrains<a href=\"https://blog.jetbrains.com/ktor/2022/08/12/ktor-2-1-0-released-and-it-comes-with-goodies/\">发布</a>\"Ktor 2.1.0（创建微服务和Web应用程序的异步框架），新特性包括：一个创建Ktor应用的新命令行工具；支持使用<a href=\"https://yeoman.io/\">Yeoman</a>\"生成各种项目的脚手架；一个新的Gradle部署插件；支持YAML配置。</p><p></p><h3>Apache Camel</h3><p></p><p>Apache Camel 3.18.1<a href=\"https://camel.apache.org/blog/2022/08/RELEASE-3.18.1/\">发布</a>\"，带来41项改进和Bug修复，包括依赖项升级到Spring Boot 2.7.2和hadoop-common 3.3.3模块，后者修复了<a href=\"https://nvd.nist.gov/vuln/detail/CVE-2022-26612\">CVE-2022-26612</a>\"漏洞。要了解关于这个版本的更多细节，请查看<a href=\"https://camel.apache.org/releases/release-3.18.1/\">发布说明</a>\"。</p><p></p><h3>堪萨斯城开发者大会</h3><p></p><p><a href=\"https://www.kcdc.info/\">堪萨斯城开发者大会</a>\"（KCDC）于上周在密苏里州堪萨斯市的<a href=\"https://kcconvention.com/\">堪萨斯城会议中心</a>\"举行。大会邀请了许多来自Java社区的<a href=\"https://www.kcdc.info/speakers\">演讲者</a>\"，<a href=\"https://www.kcdc.info/sessions\">他们发表了演讲，并参加了研讨会</a>\"。</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/08/java-news-roundup-aug08-2022/\">Java News Roundup: Extent-Local Variables, Payara Platform, Project Reactor, Ktor, Spring Web Flow</a>\"</p>",
    "publish_time": "2022-08-23 10:29:06",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "C++ 语法糟透了，Carbon 修复了它",
    "url": "https://www.infoq.cn/article/ScK8IZsfqecKY0axzRcJ",
    "summary": "<p></p><p>本文最初发布于ITNEXT。</p><p></p><p>我在Twitter上读到过许多关于Carbon的评论，有许多C++开发人员对Carbon这门编程语言的语法很不满意。人们反复提到的一个问题是：</p><p></p><p></p><blockquote>如果他们是要为C++开发人员开发一门新语言，那为什么要让它看上去和C++完全不同？C++的语法已经很好了，而且为人所熟知。</blockquote><p></p><p></p><p>实际上不是这样的，C++的语法一点也不好。但是，一旦你在C++领域呆了足够长的时间，就很容易将其内化而忽略这个事实。Chandler Carruth在介绍<a href=\"https://www.infoq.cn/article/vJVZMZWbipYjHUT0B74G\">Carbon</a>\"的时候未能很好地说明为什么C++语法多么问题重重。</p><p></p><p>虽然我不能保证能说明得很好，但我会试着挖下C++语法的问题，以及为什么我们需要一个升级。让我们从一个简单的对比开始：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/e1/93/e1503b95a11a99b9948d4e5dddb45793.png\" /></p><p></p><p>可以看到，Carbon中的大部分语句都有一个引导关键字，如fn、var、let和class。有了这些关键字，你一看就知道自己正在处理的语句是什么类型的。Carbon是故意这样设计的。下面这句话来自<a href=\"https://youtu.be/omrY53kbVoA?t=745&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjEyMzcxMjMsImZpbGVHVUlEIjoibGRMbXFOWmhhZnNPMnBGYSIsImlhdCI6MTY2MTIzNjgyMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyNDM2MDc5MH0.2TIHUlcIr7UpMZE-GSqioBzi5CjwpnvVSpvmD5VgeBY\">Carbon的首次</a>\"公开展示：</p><p></p><p></p><blockquote>我不知道是否有人做过C++解析器，那不是一个完整的编译器。其难度超乎想象。我们可以做得更好。—— Chandler Carruth</blockquote><p></p><p></p><p>作为一名经常开发各种工具来辅助C++开发的开发者，我完全同意这个说法。编写代码解析C++难度非常大，这是我从1998年开始编写C++代码以来的亲身感受。Java和C#社区有许多令人惊叹的IDE和工具，而我们C++开发者多年来一直使用糟糕的工具进行开发，命令补全经常会出问题，尤其是在大型项目中。特别地，与Java和C#开发人员可以使用的工具相比，C++的重构工具功能非常有限。</p><p></p><p>VS Code C++高亮显示器的维护者解释了为什么开发C++工具如此之难：</p><p></p><p></p><blockquote>C++语法高亮显示器有19000行代码，这比任何语言都要多，而且是第二大的将近4倍（Typescript 5000行）。是不是很厉害？不是的，因为即便如此，它甚至还是无法高亮显示变量声明中的自定义类型。Rust高亮显示器毫不费力就能做到这一点，因为它和Carbon非常像。—— Jeffrey Hykin</blockquote><p></p><p></p><p>不过，即便是Java和C#，在解析方面也不是很理想，因为它们借用了许多C/C++语法。我最先注意到使用引导关键字的好处还是在Go语言中。Go在函数定义中引入了func 关键字，这使得代码搜索变得很容易，我可以更容易地分辨出是使用还是定义。下图分别展示了查找MassFlow 函数调用和查找MassFlow 函数定义：</p><p><img src=\"https://static001.geekbang.org/infoq/ed/ed5254ddd35e76d0444affdca36d99d1.png\" /></p><p></p><p>C/C++语法的问题是，需要解析多个语言符号才能确定一个语句是什么。对于人类读者而言，这可能无关紧要，但对工具来说就并非如此了，编写一个正则表达来搜索什么东西，难度要大很多。</p><p></p><h2>最棘手的分析</h2><p></p><p></p><p>关于C++代码的解析难度，有一个具体的例子是“<a href=\"https://en.wikipedia.org/wiki/Most_vexing_parse?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjEyMzcxMjMsImZpbGVHVUlEIjoibGRMbXFOWmhhZnNPMnBGYSIsImlhdCI6MTY2MTIzNjgyMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyNDM2MDc5MH0.2TIHUlcIr7UpMZE-GSqioBzi5CjwpnvVSpvmD5VgeBY\">最棘手的解析</a>\"”。这个特别的术语最早是由Scott Meyers在其著作《Effective STL中文版：50条有效使用STL的经验》中提出的。下面这个例子可以说明这一问题：</p><p></p><p><code lang=\"plain\">// C++ most vexing parse\nvoid foo(double x) {\n  int bar(int(x));\n}</code></p><p></p><p>第二行代码存在多义性。我们可以将其解释成如下所示的函数声明：</p><p></p><p><code lang=\"plain\">// A function named bar takes an integer and returns an integer.\nint bar(int x);</code></p><p></p><p>C++允许在函数声明中用小括号把参数x括起来。这样，C++解析器就不好区分是声明bar 函数，还是声明一个变量bar ，并将x 值转为整型对其初始化。下面是一个更复杂点的例子：</p><p></p><p><code lang=\"plain\">// C++ Unnamed temporary\nstruct Timer {};\n\nstruct TimeKeeper {\n  explicit TimeKeeper(Timer t);\n  int getTime();\n};\n\nint main() {\n  TimeKeeper time_keeper(Timer());\n  return time_keeper.getTime();\n}</code></p><p></p><p>main函数的第一行存在多义性：</p><p></p><p><code lang=\"plain\">TimeKeeper time_keeper(Timer());</code></p><p></p><p>在C++中，这一行看上去像定义了一个函数time_keeper ，返回TimeKeeper 对象，并接收一个函数对象作为参数。在C++中声明函数时，可以不指定参数名。int foo(int); 是一个合法的函数签名。这种问题在Carbon 中不会出现，原因如下：</p><p></p><p>Carbon类没有构造函数对象通过赋值初始化</p><p></p><p>在下面的代码中，我们试着用Carbon重现了前面的C++代码。我需要创建类函数Create&nbsp;和Make 来代替C++示例中使用的构造函数。</p><p></p><p><code lang=\"plain\">// Carbon \nclass Timer {\n    fn Create() -&gt; Self;\n};\n\nclass TimeKeeper {\n    fn Make(t: Timer) -&gt; Self;  \n    fn getTime[me: Self]() -&gt; int;\n};\n\nfn Main() -&gt; i32 {\n  let time_keeper: auto = TimeKeeper.Make(Timer.Create());\n  return time_keeper.get_time();\n}</code></p><p></p><p>可以看到，Carbon语法中有一些可能不太明显的东西。Self 是指封闭类的类型。方括号内的东西，如[me: Self] ，指任何没有显式传递的东西。那是诱发性的东西。在这种情况下，就相当于C++开发者所熟悉的this 指针。Go 也有非常类似的方法。在Go 中，getTime 方法将是下面这个样子：</p><p></p><p><code lang=\"plain\">// Go method example\nfunc (me TimeKeeper) getTime() int</code></p><p></p><p>方括号也可以用于其他隐式数据，比如类型参数。下面是Carbon 代码的一个例子：</p><p></p><p><code lang=\"plain\">// Carbon code showing function parameters\nfn QuickSort[T:! Comparable &amp; Movable](s: Slice(T)) {\n  if (s.Size() &lt;= 1) {\n    return;\n  }\n  let p: i64 = Partition(s);\n  QuickSort(s[:p - 1]);\n  QuickSort(s[p + 1:]);\n}</code></p><p></p><p>这里，我们没有指定this 对象，而是指定了一个类型参数T 。该参数必须满足Comparable&nbsp;和Movable 接口。Carbon 使用单冒号: 来指定对象类型，而:! 则用于表示我们正在指定类型参数必须满足的接口。</p><p></p><h2>解析C++中的函数指针</h2><p></p><p></p><p>当定义以函数为参数的高阶函数时，将返回类型放在前面而不是后面的问题就显现出来了。快速看下这段代码，然后告诉我，函数指针参数的名字是什么？</p><p></p><p><code lang=\"plain\">// C++\nint FindFirst(int xs[], int n, bool (*condition)(int x)) {\n    for(int i = 0; i &lt; n; ++i) {\n        if (condition(xs[i])) {\n            return i;\n        }\n    }\n    return -1;\n}</code></p><p></p><p>函数指针参数的名字是conditon 。我相信大多数人都会同意，这不是很快就可以读出来的东西。这体现了C++语法的其中一个问题。我本打算大张旗鼓地展示下 Carbon做得有多好，但很遗憾，Carbon语言规范中没有任何地方提到函数指针。取而代之，我将展示下在Go语言中会是什么样子，并推测在Carbon中可以如何做。</p><p></p><p><code lang=\"plain\">// Go\nfunc FindFirst(xs []int, condition func(int) bool) int {\n  for i, x := range xs {\n    if condition(x) {\n      return i\n    }\n  }\n  return -1\n}</code></p><p></p><p>Go代码更容易阅读，这是因为参数名在前，而类型在后。它具有一致性。使用Carbon，我认为代码会更清晰，因为它使用冒号来分隔类型和参数名：</p><p></p><p><code lang=\"plain\">// Carbon - Assumption (similar to Rust)\nfn FindFirst(xs: Slice(int), condition: fn(int) -&gt; bool) -&gt; i32</code></p><p></p><p>实际上，这几乎就是使用Rust编写FindFirst 函数签名的方式。</p><p></p><h2>摆脱常量引用混乱</h2><p></p><p>在编写C++代码时，其中最恼人的一件事就是处理常量正确性和引用。考虑下面的几何学示例代码。</p><p></p><p><code lang=\"plain\">// C++ class\nclass Circle {     \npublic:\n    const Point&amp; center() const;\n    float radius() const;    \n    void  setCenter(const Point&amp; pos);\n    void  setRadius(float radius);\n            \n    bool inside(const Point&amp; p) const;\n    bool intersect(const Circle&amp; c) const;\n    \nprivate:\n    Point center;\n    float radius;\n};</code></p><p></p><p>有时候你需要传递一个参数，比如圆的中心，一个常量引用const Point&amp; pos ，但其他时候你不想这样做。我将半径作为一个float 副本来传递。从机器码层面考虑，那会更高效，因为单精度浮点数值可以通过一个微处理机寄存器来传递。而常量引用被实现为指针，也就是说，要获得实际需要的值就得额外进行一次间接取值。Carbon完全解决了这个问题，它让编译器来确定怎么做最好。在Carbon中，上面的类可以实现为:</p><p></p><p><code lang=\"plain\">// Carbon class\nclass Circle {     \n    fn center[me: Self]() -&gt; Point;\n    fn radius[me: Self]() -&gt; f32;    \n    fn setCenter[addr me: Self*](pos: Point);\n    fn setRadius[addr me: Self*](radius: f32);\n            \n    fn inside[me: Self](p: Point);\n    fn intersect[me: Self](c: Circle);\n    \n    var center: Point;\n    var radius: float;\n}</code></p><p></p><p>可以看到，setCenter&nbsp;和setRadius 类似。Carbon 将找出把参数pos&nbsp;和radius 传递给相应函数的最优方法，需要担心引用和常量。在Carbon中，参数默认是let类型的，因此它们本质上和常量类似。</p><p></p><p>有时，你确实会需要在调用者中修改一个值。Carbon 没有引用，因此你需要使用指针来代替。Self* 是指me 参数是一个指针，我们可以修改me 。与使用引用相比，使用指针的一个问题是需要获取对象地址。</p><p></p><p><code lang=\"plain\">// Carbon - Calling setRadius if it was defined as \n// fn setRadius[me: Self*](radius: f32)\n\nvar circle: Circle = MakeRandomCircle();\nvar ptr: Circle* = &amp;circle;\nptr.setRadius(5);</code></p><p></p><p>每次都使用这个地址来修改一个Circle对象很麻烦。出于这个原因，我们在me 前面加了addr关键字，让Carbon为我们获取地址。这就是为什么我们不获取地址就可以调用setRadius：</p><p></p><p><code lang=\"plain\">// Carbon \nvar circle: Circle = MakeRandomCircle();\ncircle.setRadius(5);</code></p><p></p><h2>为代码可读性而设计</h2><p></p><p></p><p>大多数开发人员从不研究或关心可用性和用户界面设计。实际上他们应该关心的，因为应用于用户界面布局的原则与编写清晰易读的代码有很多相通之处。</p><p></p><p>有一个重要的细节需要注意，那就是人类阅读文本的方式。只有当你还是个学习读写的孩子时，才会阅读单词中的单个字母。成年人通过形状来阅读单词，我们通过观察单词的形状来识别它们。</p><p></p><p>这意味着要快速识别不同的选择，单词和句子的形状应该不同。让我们通过一个例子来说明这个问题。考虑一个包含一系列选项的网页：</p><p><code lang=\"plain\">I want to customize tools...\nI want to have custom shows...\nI want to do custom animations...</code></p><p></p><p>这是一个糟糕的设计，因为句子的形状相似度太高了，增加了视觉扫描的难度。我们可以改进下这个设计，把重复的部分提取出来：</p><p></p><p><code lang=\"plain\">I want to:\n  Customize tools...\n  Custom shows...\n  Custom animations...</code></p><p></p><p>虽然有改进，但还是有问题，每个选项的第一个单词看上去还是非常相似。修改每个选项的措辞，会更容易阅读：</p><p></p><p><code lang=\"plain\">I want to do:\n  Tool Customizing...\n  Reset Shows...\n  Custom Animations...</code></p><p></p><p>这些原则是如何应用到Carbon 编程语言中的呢？Carbon 使用了简短的引导关键字，如fn&nbsp;，让你可以把更多的注意力放在单个的方法或函数上：</p><p></p><p><code lang=\"plain\">// Carbon function names line up\nfn center[me: Self]() -&gt; Point;\nfn radius[me: Self]() -&gt; f32;    \nfn setCenter[addr me: Self*](pos: Point);\nfn setRadius[addr me: Self*](radius: f32);          \nfn inside[me: Self](p: Point);\nfn intersect[me: Self](c: Circle);\n</code></p><p></p><p>这使得在Carbon中浏览一个函数或方法列表更快捷。像Java这样的语言在这方面很糟糕。我们首先读到的是public static void ，到最后才看到最重要的部分——函数名。C++好一点，但把返回值信息放在函数名之前还是会分散注意力：</p><p></p><p><code lang=\"plain\">// C++ function names don't line up\nconst Point&amp; center() const;\nfloat radius() const;</code></p><p></p><p>返回类型的名称不一样，方法名就无法对齐，浏览方法名列表就难一些。这也适用于变量列表。借助像var&nbsp;这样的引导关键词，就可以保证每一行的变量名都从相同的位置开始，读者就可以更快地浏览代码。</p><p></p><p><code lang=\"plain\">// Carbon variable names line up\nvar center: Point;\nvar radius: float;</code></p><p></p><h2>小结</h2><p></p><p></p><p>不管是就解析器方面，还是从开发人员阅读代码和使用工具角度来说，Carbon的语法都更简单。Carbon代码更便于开发人员搜索和浏览，因为有效位（如标识符）是从同样的字符偏移开始的。</p><p></p><p>原文链接：</p><p></p><p><a href=\"https://itnext.io/c-syntax-sucks-and-carbon-fixes-it-744efe5cae71?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjEyMzcxMjMsImZpbGVHVUlEIjoibGRMbXFOWmhhZnNPMnBGYSIsImlhdCI6MTY2MTIzNjgyMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyNDM2MDc5MH0.2TIHUlcIr7UpMZE-GSqioBzi5CjwpnvVSpvmD5VgeBY\">C++ Syntax Sucks and Carbon Fixes It</a>\"</p>",
    "publish_time": "2022-08-23 15:39:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]