[
  {
    "title": "那位用Rust重写数据库的创始人来复盘了：删除27万行C++代码，值吗？",
    "url": "https://www.infoq.cn/article/yibH0TOMOJCxHVMyzbpK",
    "summary": "<p>前段时间，<a href=\"https://www.infoq.cn/article/OIFS2PtAZlMsgBbsW6eO\">数据库初创企业 RisingWave Labs 曾经发表了一篇博客文章</a>\"，宣布完全删除掉了 RisingWave（该公司开发的云原生流式数据库） 的 27 万行 C++ 代码库，并用 Rust 语言从头开始重写了一遍系统。本文，我们采访到了该公司的创始人 &amp;CEO 吴英骏博士，详细探讨了重写前中后期的准备、遇到的问题以及经验复盘。</p><p></p><h2>放弃 Rust，初抉择是 C++</h2><p></p><p></p><p>InfoQ：选择哪种编程语言和 RisingWave 的特性有关系吗？</p><p></p><p>吴英骏：<a href=\"https://singularity-data.com/blog/building-a-cloud-database-from-scratch-why-we-moved-from-cpp-to-rust\">RisingWave </a>\"是一款云原生<a href=\"https://www.risingwave-labs.com/blog/is-risingwave-the-next-apache-flink/\">流式数据库</a>\"，主要服务于需要超低延迟实时数据分析应用。其定位不仅是一个 SQL 数据库系统，还提供流处理能力：使用流数据执行连续查询，并以物化视图的形式动态维护结果。另外，采用分层架构，建立在现代云基础架构之上，利用云资源为用户提供对成本和性能的细粒度控制。</p><p></p><p>这个架构最大的特点在于资源是无限的，既然有无限资源，性能并不是特别大的问题，只要加资源，性能就会更好，但是资源是收费的，设备是收费的，我们希望能够在保证用户性能的前提下让整个系统更加便宜，让普通用户以一种比较低的价格使用，这是我们的核心设计理念。</p><p></p><p>这与编程语言的选择没有太大关系，开发一款数据库可以用各种各样的语言，比如 C++、Rust、Java，Scala 等，一些交易系统相关的可能还会考虑 Haskell，但即便是在 20 年之前的数据库，也鲜少有人使用 Java 、Basic、Python 这类语言，主要是因为这些语言的运行效率和性能均不高。</p><p></p><p>我们主要希望选择一门高性能的编程语言，所谓的高性能基本上是 C++、<a href=\"https://qcon.infoq.cn/2022/beijing/track/1288\">Rust </a>\"或者一些小众的语言，如果希望可以被用户广泛接受，基本是 C++ 和 Rust。</p><p></p><p>InfoQ：从之前披露的文章中可以看到团队最初选择的是 C++ 语言来构建，并集结了多位具有 10 年以上经验的 C++ 工程师，当时是看中了 C++ 的哪些特质还只是遵循市面上大部分数据库系统的选择？</p><p></p><p>吴英骏：我本人比较擅长 C++，不管是读博期间还是创业之前做的所有数据库都是用 C++ 写的，没有用过其他任何语言写过任何项目。</p><p></p><p>创业之初，有人给我们提过可以用 Rust 写，理由是用 Rust 写容易火。在我看来，这不可以算作理由，我们又不是想要成为网红，选择一门语言肯定不是单纯为了火，我们需要考虑团队适合用、会用的语言以及数据库领域的通用语言是什么。在数据库领域，虽然 TiDB 的存储引擎 TiKV 是用 Rust 写的，但这不足以证明成功的数据库系统都是用 Rust 写的，反而绝大多数成功的数据库系统都是用 C++ 写的。</p><p></p><p>从招聘的角度考虑，我们肯定希望招到的都是数据库领域的专家，在数据库领域有多年经验的专家很可能来源于现有的各大数据库厂商，而这些厂商基本都是用 C++ 的。</p><p></p><p>相较而言，Rust 是一门比较年轻的语言，缺少比较重量级的项目，尽管这个语言是被实战过的，也有一些相对流行的项目，但还算不上重量级的巨无霸项目，还有一些项目主要是币圈在用，生态上或多或少是有不足的。</p><p></p><p>综上，我们最终决定选择用 C++ 作为主要开发语言。</p><p></p><h2>再抉择用 Rust 重写</h2><p></p><p></p><p>InfoQ：团队已经在这件事情上投入了 7 个多月，您也提到对初创企业而言时间是非常宝贵的，是哪个点 / 事件让团队觉得不重写不行了？</p><p></p><p>吴英骏：首先，C++ 比较经典的问题是内存泄漏，但这类 Bug 比较容易修，我们觉得可以忍。其次，依赖管理很痛苦，虽然 CMake 工具可以自动配置 C++ 项目的编译，但使用起来还是很麻烦的，仍然需要手动配置和安装依赖库；STL 库缺乏对一些现代编程工具的支持，依赖的社区项目大多数还都缺乏长期支持；最后，我们招聘进来的成员 C++ 水平参差不弃，每个人都有自己的风格，非常难统一，代码看起来比较累，审查代码令人生畏。随着越来越多人员的加入，C++ 的问题暴露得越来越频繁。这段时间，频繁有工程师提出是不是可以考虑使用 Rust 重写。</p><p></p><p>另外，流式数据库通常用于对延迟非常敏感的关键任务。因此只能使用以下语言构建 RisingWave：保证零成本抽象，不会有性能上限；不需要运行时垃圾收集，可以控制可能由内存管理引起的延迟峰值。</p><p></p><p>起初，我们是不愿意更换语言的，毕竟已经写了这么久。最后，我们表示如果支持用 Rust 重写的工程师可以对一个独立的模块改写成功，我们就考虑整体重写。与此同时，我也想起之前在 AWS Redshift 工作中遇到的一个 Bug，三个人不断调试了两周都无解，最终发现是内存泄漏的问题，如果现在的项目继续下去很可能会遇到类似的情景，假设那时的产品已经有了很多用户，我们还需要因为这种内存泄露的问题调试许久，得不偿失。也是这个时候，我们开始认真考虑是否用 Rust 重写。</p><p></p><p>经过慎重评估，原来七个月写的代码用 Rust 重写需要花费大约两个月的时间，前后的时间差主要体现在项目的逻辑框架前期已经梳理清楚，正值暑假，公司内部纳入大量实习生，人手比较充足，且很多实习生天然有 Rust 的基础，这些都提升了重写的速度。最后经过全公司的表决投票，我们开始重写。</p><p></p><p>在替换过程中，我们选择逐个模块替代，这也保证了整个过程不会出现很严重的问题。</p><p></p><p>InfoQ：C++ 代码风格不统一的问题，<a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651115752&amp;idx=3&amp;sn=ef86f2f31cd385ad09723e0a8082fa70&amp;chksm=bdb928bb8acea1adee34cccfa30dd62a3c93a359b12bfa1c6a92fed79961fd649cb6c5b07c82&amp;scene=27#wechat_redirect\">用 Rust 重写</a>\"以后就不存在这个问题了吗？</p><p></p><p>吴英骏：风格不统一的问题肯定不是使用 Rust 就能解决的，但相对 C++ 会有很大程度的改善，C++ 中一些指针等的写法很难统一，还容易造成安全性的问题，工程师在阅读其他人的代码时如果对全局系统不够了解很容易出现误读，从而造成系统出错。</p><p></p><p>InfoQ：C++ 一些语言层面的缺陷由来已久，您将 C++ 语言作为主要的开发语言，之前没有遇到过上述问题吗？</p><p></p><p>吴英骏：我之前也遇到过，但上学期间，Rust 没有现在完善，使用者很少，因此也不会考虑到使用 Rust 去开发数据库。此外，我之前接触的数据库是比较成熟的产品，比如 IBM DB2，大部分时间都在调试，很难有精力和时间去把这么一个诞生了几十年的数据库进行重写，但创业是不一样的，尤其是早期起步阶段。</p><p></p><p>在大型企业内部，重写某个项目大概率项目本身并不是那么重要，或者没有很多用户，否则需要投入大量的精力和资源。对起步阶段的创业公司来说，还是有机会重写的，一旦面对客户交付的压力，重写是不太可能。</p><p></p><p>InfoQ：重写之前的系统已经完成了多少？</p><p></p><p>吴英骏：简单来说，框架是比较清晰的水平。重写不至于发现之前的 Bug，但的确会通过这个过程重写考量各个部分设计的合理性。</p><p></p><h2>Rust 的爽点</h2><p></p><p></p><p>InfoQ：Rust 比较爽的特性是什么？</p><p></p><p>吴英骏：首先，安全性肯定是让我们觉得是比较爽的，这对数据库项目非常重要。其次，包管理非常少，C++ 有非常多的库，包管理非常复杂，可能需要花费几个小时去想如何在 CMake 里面配置一个包管理工具，甚至是在花费了很多时间之后，我们发现装不上去，还可能会遇到重名的问题（其他项目中使用的变量名称可能和我们使用的库中的名字重合了），这些问题都需要手动解决，而且改起来费时费力。</p><p></p><h2>重写收益比</h2><p></p><p></p><p>InfoQ：重写前后的收益情况如何？</p><p></p><p>吴英骏：总结来讲，这件事情的收获非常大。从收益比的角度看，我们损失的是时间，因为分段重写大概花费了一个月左右，但这些时间并没有浪费掉，这个过程让我们又反思了一遍不同模块的设计思路，改掉了其中不合理的部分。对数据库系统而言，这是一个长周期的项目，早期孵化阶段的时间宝贵程度和正式上线后肯定是有区别的，当对象是直接用户时，数据库系统出现任何问题都是不能忍的。</p><p></p><p>我们收获的是系统更加稳定、安全，且代码清晰，尤其是包管理部分有非常大的提升。此外，Rust 本身在高速发展中，整个社区非常有活力，提问基本都能够得到及时回复，这是我们从 Rust 生态中受益的地方。</p><p></p><h2>使用 Rust 重写要注意的地方</h2><p></p><p></p><h3>学习成本</h3><p></p><p></p><p>InfoQ：重写之后，原来那批 C++ 工程师都自学了 Rust 吗？</p><p></p><p>吴英骏：团队中有部分工程师之前就懂 Rust，只是未在工作中使用，这部分工程师还是比较容易转型的。我们也专门让一些工程师评估从零开始学 Rust 需要多久，绝大多数工程师一个月之内基本能够掌握 Rust，但还达不到全面掌握，只是可以使用 Rust 写一些代码。</p><p></p><p>整个过程比较顺利也得益于部分工程师会利用业余时间自学并将经验告知其他人，这是非常重要的。我认为，如果公司决定重写，必要条件是公司内部有一到两个，甚至更多使用 Rust 进行过实战的工程师，或者至少是愿意用业余时间时间并将经验传授给其他同学，这可以降低整个事情的难度，毕竟 Rust 的学习曲线是比较陡峭的。</p><p></p><p>InfoQ：从不同的语言基础开始学习 Rust 会有区别吗？</p><p></p><p>吴英骏：会有差异，而且比较明显。C++ 属于底层语言，掌握了 C++ 意味着你基本明白内存管理、指针、面向对象等理念。对于其他语言，比如 Python，最大的特点是简化编程，开发者不需要考虑内存管理等事情，但 Rust 是需要这方面基础的，所以不同的语言背景转换 Rust 的成本是不同的。</p><p></p><h3>编译时问题</h3><p></p><p></p><p>InfoQ：Rust 一直存在编译时的问题，你们有感受到吗？</p><p></p><p>吴英骏：Rust 确实存在编译时问题，但编译 C++ 相对也比较慢，但目前还在可承受的范围之内，如果时间比较长，工程师会定期查看编译进度，并尝试是否有办法可以缩短这个时间。</p><p></p><p></p><h2>重写理由</h2><p></p><p></p><p>InfoQ：你会建议什么类型的公司或者业务团队在什么情况下选择重写？</p><p></p><p>吴英骏：如果是在一个大型公司内部选择重写，大概率表明该项目不是那么重要，或者是核心项目的边缘模块，用户没有那么多、公司又有钱、有资源、有人力，这种情况下可以考虑重写。对创业公司而言，早期还有精力重写，一旦用户量上来了就会面临交付压力，基本不太会做这种决定。</p><p></p><p>此外，需要梳理清楚转换语言的理由，出于性能、安全性或者其他原因，而不是为了火。以数据库领域为例，现在很多成功的数据库距今已经诞生十年以上，经历了长时间的磨炼，其实转 Rust 的需求并不大。总的来说，我觉得是非常看中实际需求，需要全面了解需求再做决定。</p><p></p><p></p><h3>生态环境</h3><p></p><p></p><p>InfoQ：你觉得目前 Rust 的生态环境如何？</p><p></p><p>吴英骏：整体来看，Rust 的生态环境还比较不错，主要问题是在于缺少大型项目验证，比如 Go 最成功的项目是 Kubernetes。当然，我们现在已经看到有不少科技公司考虑使用 Rust 重写某些服务，比如 InnoDB，也看到很多公司加入了 Rust 基金会，比如 AWS、Google、Facebook 等，相信通过这些公司的长期支持，未来会出现一些非常不错的项目。Rust 能够获得这些大公司、初创企业（背后的投资人和投资机构）的支持，我相信社区最终能够比较好的发展。</p><p></p><h3>团队状态</h3><p></p><p></p><p>InfoQ：是否选择用 Rust 重写与团队规模和状态之间是否有关系？</p><p></p><p>吴英骏：我觉得重写和团队规模的关系不是很大，但我建议更加年轻的团队选择 Rust，当然这也因人而异。至于最终是否要转，也要遵循团队大多数人的意见，因为如果在学习了一段时间的 Rust 语言之后发现还是没有熟练掌握可能会有比较强的挫败感，这需要团队成员的共同努力，仅凭兴趣是很难做好的，仅凭兴趣也最好不要去创业以及对外提供商业化服务，这是非常不负责的。</p><p></p>",
    "publish_time": "2022-10-13 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Cloudflare R2上线：兼容R3的零流量全新对象存储服务",
    "url": "https://www.infoq.cn/article/7aCTDfvKxmmiPos6duef",
    "summary": "<p>Cloudflare近期发布了<a href=\"https://blog.cloudflare.com/r2-ga/\">R2存储</a>\"，这是一个兼容R3，但零流量费的全新对象存储服务，提供与Cloudflare Workers整合的动态功能。</p><p></p><p>R2存储的设计利用横跨100多国家中275个城市的内容交付网络，提供低延迟、高吞吐量的存储服务。Cloudflare提供<a href=\"https://developers.cloudflare.com/r2/\">三种访问R2对象的方式</a>\"：用于通过无服务代码访问存储桶的<a href=\"https://workers.cloudflare.com/\">Worker</a>\"运行时API、兼容S3 API的访问，以及<a href=\"https://developers.cloudflare.com/r2/data-access/public-buckets/\">公开桶</a>\"。Cloudflare产品副总裁<a href=\"https://www.linkedin.com/in/aly-cabral-83682664/\">Aly Cabral</a>\"写道：</p><p>&nbsp;</p><p></p><blockquote>谁会抱着永远不会读取的目的来存储数据呢？然而，每一次数据读取都会有随之而来的输出费用。R2为开发者提供了自由访问数据的能力，打破了长期以来束缚应用程序构建者手脚的生态系统锁定。</blockquote><p></p><p>&nbsp;</p><p>在<a href=\"https://www.infoq.com/news/2021/10/cloudflare-r2-egress-aws/\">一年前的预览</a>\"中首次亮相的R2存储，以“零流量费用对象存储”为招牌，宣称是对象存储最便宜的选择。Cloudflare表示，这个新的选择要<a href=\"https://www.businesswire.com/news/home/20220921005154/en/Cloudflare-Makes-R2-Storage-Available-to-All-Provides-Developers-Easy-and-Scalable-Storage-Without-the-Egress-Fees\">比亚马逊S3标准版至少便宜10%</a>\"。S3标准版是AWS的默认选项，也是最贵的选项，相较而言<a href=\"https://aws.amazon.com/s3/storage-classes/\">其他存储级别</a>\"的价格明显要便宜很多。BukuWarung的软件开发工程师<a href=\"https://www.linkedin.com/in/pratyakshsingh/\">Pratyaksh Singh</a>\"如此<a href=\"https://www.linkedin.com/posts/pratyakshsingh_cloudflare-cloud-engineering-activity-6978704755158056960-zGwV\">评论</a>\"：</p><p>&nbsp;</p><p></p><blockquote>这项服务很是让人兴奋，它太省钱了。它的API与AWS的S3相兼容，从用例来看，我们似乎只需要在代码中创建S3客户端时修改端点即可。R2虽然允许我们选择区域，但似乎唯一的选项就是自动。R2可以轻松与Cloudflare的边缘计算平台（基于隔离的）Workers匹配。</blockquote><p></p><p>&nbsp;</p><p>当前版本的R2会在最近的可用区域内自动选择存储桶的位置，但目前还不支持对象生命周期、不停机实时迁移或管辖限制。Cabral补充道：</p><p>&nbsp;</p><p></p><blockquote>虽然我们还没有明确计划支持区域，但我们知道数据的地域性对很多规范用例来说很重要。区域管辖限制支持设置一个类似“欧盟”那样的管辖区以对数据做出限制。</blockquote><p></p><p>&nbsp;</p><p>R2的收费标准基于数据存储的总量以及两类操作，“突变状态”和“读取现有状态”，包含10GB的免费存储额度且不收取流量费用。</p><p></p><p>继R2对象存储的普遍可用（GA）后，Cloudflare又推出在R2之上<a href=\"https://blog.cloudflare.com/store-and-retrieve-logs-on-r2/\">存储并检索Cloudflare日志</a>\"的能力。在“<a href=\"https://blog.cloudflare.com/welcome-to-ga-week/\">GA周</a>\"”中，内容交付网络宣布了威胁运营和研究团队<a href=\"https://blog.cloudflare.com/introducing-cloudforce-one-threat-operations-and-threat-research/\">Cloudforce One</a>\"，以及用于缓解DDoS攻击的流量分析系统<a href=\"https://blog.cloudflare.com/adaptive-ddos-protection/\">Cloudflare自适应DDoS防护</a>\"的发布。</p><p></p><p>原文链接：<a href=\"https://www.infoq.com/news/2022/10/cloudflare-r2-ga/\">Cloudflare R2 Storage Generally Available</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://xie.infoq.cn/article/da340fc46fcc7ce784c4bc126\">Cloudflare 放弃 Nginx，使用内部 Rust 编写的 Pingora</a>\"</p>",
    "publish_time": "2022-10-13 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "开源的未来：为什么开放核心已死？",
    "url": "https://www.infoq.cn/article/eQRGLjAzl3mjhhwPTE14",
    "summary": "<p></p><blockquote>如今，开源你的核心业务产品可不是一个好主意。如果你创造的项目开始与你的核心内容展开直接竞争，或者让其他玩家吃掉你的奶酪，你便会对它的成功心生不满。</blockquote><p></p><p>&nbsp;</p><p>我并不反对<a href=\"https://www.infoq.cn/article/J66xNisfoG4V1cCyfmYw\">开源</a>\"，相反，作为一名开发人员，我使用许多开源工具，定期参与贡献，甚至自己构建了几个项目。</p><p>&nbsp;</p><p>我相信开源是（将会是）所有现代软件栈的基石。</p><p>&nbsp;</p><p>它是实现有意义的对话、建立真正的社区来解决复杂问题和促进行业标准(被标准协会采用，或作为一个项目变得越来越重要的即成事实)的最佳方式之一。况且如果创建社区，就是希望社区能够提供真正的价值。否则，为什么要创建它呢?</p><p></p><h2>在未来，开放核心有什么改变?</h2><p></p><p></p><p>早在2010年左右，像Redis、MongoDB和Red Hat这样的公司就创建了开源项目，这些项目大受欢迎，并取得了巨大的成功，它们在这些项目的基础上提供了额外的企业版本和专业服务。</p><p></p><p>MongoDB的首席执行官表示，当时，该公司在核心的MongoDB开源项目上花费了大约50%的研发预算。</p><p></p><p>问题是，时代变了。以前，一个项目可能需要数年时间才能获得崭露头角。这使得依赖于开放核心模式的企业可以创建、培育一个项目，然后找到正确的方法开始商业化。现在事物发展得快多了。现在尝试这样做，很有可能最终会与你自己的<a href=\"https://www.infoq.cn/article/EZzCIRT0ujGgWNveiolL\">开源产品</a>\"竞争，或者有人会在你的项目上更快地构建产品，而只给你留下些残羹剩饭。</p><p></p><h2>吃一堑，长一智</h2><p></p><p></p><p><a href=\"https://xie.infoq.cn/article/e16432116eb2f4e8978eb5b13\">Docker</a>\"有一个非常强大的OSS产品，最终蚕食了自己的市场。Docker的反应是开始限制自己的OSS产品，这种方式激怒了OSS社区，在商业和开源产品之间制造了冲突。</p><p>&nbsp;</p><p>Elastic非常快速有效地发展了它的OSS，但当OSS变得非常大时，其他公司开始在其基础上提供SaaS（比如Logz.io、AWS和Coralogix）。由于他们的市场（基本上是他们创造的）被严重削弱，他们别无选择，只能转向另一个领域——网络安全。与十年前相比，今天的软件采用速度要快得多，以至于在市场被接管之前，Elastic几乎没有时间意识到这个问题。他们的“主场优势”变成了一个沉重的负担。</p><p>&nbsp;</p><p>意识到这一转变，MongoDB自己退出了他们最初采用的开放核心模型，改变了管理免费开源MongoDB项目的许可条款。</p><p></p><p>你越关注开放核心项目，你就越会发现公司在努力保持自身发展、项目发展压力和市场加速之间的平衡。</p><p></p><h2>更好的前进方向：开放基金会</h2><p></p><p></p><p>那么，还有什么替代方案呢？我建议你寻找一个真正的问题，你的开源解决方案可以帮助你解决这个问题，这个问题既可以补充你的业务，又不会放弃核心价值，并通过坚持以下三个关键原则来与市场接轨：</p><p>&nbsp;</p><p>真实：项目需要增加实际价值，并真正提供价值。在一个快节奏且相互关联的市场中，开发者很容易就能发现将他们推向其他产品的“诡计”。避免利益冲突：开源项目不应该让你的公司陷入利益冲突。在你推动公司发展的过程中，随着需求的增加，你会倍感市场压力。你的竞争对手使用了你的开源软件，这可能会无形地限制你的增长或显著降低你的速度。支持、演进和发展开源是一项繁重的工作，你的竞争对手可能很容易从中获益，这可能导致你的公司迎接死亡之吻。使项目独立：开发者应该能够享受项目所提供的东西，而不依赖于不遵守这些原则的其他组件。如果你的OSS项目是有价值的，但是使用的时候存在障碍，其他项目就会通过减少这些障碍以取而代之。</p><p>&nbsp;</p><p>如果你坚持这些原则，你可以创建一个开源产品作为核心产品的补充。它授权、支持、增强、启用产品的一部分，而不是产品本身或其核心。这将使你能够享受开源社区的所有好处，而不会损害产品的核心部分。</p><p>&nbsp;</p><p>这一策略已经被数十家公司实施。</p><p>&nbsp;</p><p>Netflix （Spinnaker）、谷歌（Kubernetes）和Meta （React）都创造了非常成功的OSS产品，它们为开发者和社区提供了真正的价值，但却没有放弃其产品的核心价值。小型公司也在使用这种模式——Komodor （ValidKube）、Up9 （Mizu）和我自己的公司Permit.io（OPAL）。</p><p>&nbsp;</p><p>当我们共同创建我们的开源项目OPAL时，我们希望为开发人员提供一种标准的方法，以便随着云中的动态变化保持最新的权限。我们推广这个项目，并希望人们使用它，而不管他们是否为我们提供的SaaS（Permit.io）支付过一分钱。</p><p>&nbsp;</p><p>我们的开源项目做得越好，它们发展得越大，对我们的产品就越好，这正是当你考虑将开源作为一项业务来构建时所希望看到的变化。</p><p>&nbsp;</p><p>开源不会消失，开放基金会是开源商业战略发展的下一步。我很兴奋地看到它带给世界的所有那些令人惊叹的社区、产品和标准，以及会与之一起成长的业务。</p><p>&nbsp;</p><p>译者简介：</p><p></p><p>冬雨，小小技术宅一枚，现从事研发过程改进及质量改进方面的工作，关注研发、测试、软件工程、敏捷、DevOps、云计算、人工智能等领域，非常乐意将国外新鲜的IT资讯和深度技术文章翻译分享给大家，已翻译出版《深入敏捷测试》、《持续交付实战》。</p><p></p><p>原文链接：</p><p>https://thenewstack.io/the-future-of-open-source-or-why-open-core-is-dead</p>",
    "publish_time": "2022-10-13 10:17:44",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "微信推出自研NLP大规模语言模型WeLM：零/少样本即可完成多种NLP任务，匹敌大其25倍的模型",
    "url": "https://www.infoq.cn/article/B3YRQiWg3xluw4gRXk7H",
    "summary": "<p></p><p></p><blockquote>WeLM能够在零/少样本的情境下完成多种NLP任务，现已部署应用于微信视频号</blockquote><p></p><p></p><p>大规模语言模型领域迎来新“选手”。近日，微信AI推出自研NLP大规模语言模型WeLM ，该模型是一个尺寸合理的中文模型，能够在零样本以及少样本的情境下完成包多语言任务在内的多种NLP任务。</p><p></p><p>同时，微信AI团队也提供了WeLM的体验网页和API接口。感兴趣的用户可前往<a href=\"https://welm.weixin.qq.com/docs/%E4%BD%93%E9%AA%8C%E5%92%8C%E7%94%B3%E8%AF%B7API%E6%8E%A5%E5%8F%A3\">https://welm.weixin.qq.com/docs/体验和申请API接口</a>\"。相关技术论文《WeLM: A Well-Read Pre-trained Language Model for Chinese》也已经发布于论文预印本网站arXiv。</p><p></p><h3>WeLM提供交互式网页PlayGround和API接口</h3><p></p><p></p><p>在近几年自然语言处理（NLP）领域的发展浪潮中，OpenAI开发的自然语言处理模型GPT-3无疑风头无两，发布之初便以1750亿参数规模的预训练模型所表现出来的零样本与小样本学习能力刷新了人们的认知，也引爆了AI大模型研究的热潮。</p><p></p><p>对业界来说，预训练大模型降低了AI应用的门槛，距离“AI把人类从重复性劳动中解放出来”的目标越来越近，目前，基于GPT-3，全球开发者已经探索出包括编程、回复邮件、UI设计、回答数学问题、法律语言转化、总结中心思想、推理、文本处理等广泛应用场景，并且，各国研究者在多语言/多任务等角度的探索也正在呈现出大模型百家争鸣的格局。</p><p></p><p>在国内以中文为核心的大规模语言模型领域，微信AI推出的百亿级别大规模语言模型WeLM，成为大模型百家争鸣格局中的新选手。</p><p></p><p>据介绍，WeLM是一个百亿级别的中文模型，能够在零样本以及少样本的情境下完成包括对话-采访、阅读理解、翻译、改写、续写、多语言阅读理解在内的多种NLP任务，并具备记忆能力、自我纠正和检查能力。</p><p></p><p>并且，WeLM具有尺寸合理的优势，在14项中文NLP任务上，WeLM的整体表现超出了所有同大小的模型，甚至能够匹配比它大25倍的模型。</p><p></p><p>以被普遍认为是更困难的NLP任务的文本风格转换（改写）为例，尽管用户给出的5个例子和最后需要生成的例子并没有重合的风格转换类型，但WeLM拥有出色的举一反三能力，通过学习少量的文本转换例子即可达到对任意类型的文本转换。并且，WeLM在对话-采访、阅读理解、翻译、续写等多个中文文本生成任务中有着同样优异的表现。</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/c0/8e/c07aabb4459b61d75873ae00731cc38e.png\" /></p><p></p><p>&nbsp;除了具备强大的中文理解和生成能力，WeLM还拥有处理跨多语言（中英日）任务的能力。以“微信 AI 推出の WeLM 是一个 language model that いろいろなtaskをperformができる”这句混合中日英三国语言的文本为例，WeLM的翻译相较Google翻译更为精准。</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/32/cc/3296fb8a53dc2550b54bdfb5ayyf66cc.png\" /></p><p></p><p>而且，在进一步微调后，WeLM可以拥有更好的零样本学习能力，可以根据场景拥有更好的表现。目前，WeLM已经部署应用于微信视频号的部分场景中，未来在进一步优化后还将应用于更多微信应用场景。</p><p></p><p>为进一步推动WeLM成为真正能落地且实用的工具，微信AI团队还发布了一个供用户体验的交互式网页PlayGround，并开放了用于访问WeLM的API接口。</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/25/e7/25b168b0d95bae84f995b24e604301e7.png\" /></p><p></p><p>目前，用户可通过<a href=\"https://welm.weixin.qq.com/docs/%E4%BD%93%E9%AA%8CWeLM%E7%9A%84%E7%9B%B8%E5%85%B3%E8%83%BD%E5%8A%9B\">https://welm.weixin.qq.com/docs/体验WeLM的相关能力</a>\"，并通过调整配置以实现更贴近的文本生成效果。对于想接入WeLM的开发者，也可通过<a href=\"https://welm.weixin.qq.com/docs/api/%E5%A1%AB%E5%86%99%E9%97%AE%E5%8D%B7%E5%90%8E%E8%8E%B7%E5%BE%97WeLM%E7%9A%84API\">https://welm.weixin.qq.com/docs/api/填写问卷后获得WeLM的API</a>\" Token并调用相应接口，将WeLM部署在自己的应用上。</p><p></p><h3>具有丰富知识储备，在14项中文NLP任务中表现亮眼</h3><p></p><p>据介绍，在纯Encoder(Bert)、纯Decoder(GPT) 以及Encoder-Decode(T5) 结构等主流NLP模型路径的选择上，WeLM和GPT3、Google PaLM一样，选择了自回归模型的路线。同时，考虑到不同的用户对于模型效果和推理延迟会有考量或者取舍（trade-off），微信AI的WeLM训练了1.3B、2.7B以及10B三个版本的模型，满足不同用户的调用需求。</p><p></p><p>同时，在训练数据上，微信AI团队希望构建一个足够丰富、足够干净、足够公平的数据集，为此研究团队从Common Crawl下载了近两年的中文网页数据，大量的书籍、新闻。为了增强专业能力，微信AI团队还在数据集补充了知识密集的论坛数据和一些学术论文，搜集完成后的全量数据10TB，其中包含了750G的英文数据，并保留了部分日韩文。</p><p></p><p>随后，通过规则过滤和额外训练的二分类fasttext模型，以及对测评相关数据的去除，数据集最终处理完的数据量为262B tokens。为了更好的平衡各个数据源的比重，微信AI团队也对数据进行不同比重的采样，最终，整体数据集的Topic分布相比 Common Crawl更加平滑。&nbsp;&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/c6/6d/c6696be4a6e2171ee8121cc496dec36d.png\" /></p><p></p><p>在与业界同级别的CPM、华为Pangu和百度Ernie3.0的对比测试中，WeLM表现出极强的知识储备，在14项中文NLP任务上，WeLM 的整体表现超出了所有同大小的模型，甚至能够匹配比它大25倍的模型。同时，在强大的中文理解和生成能力外，WeLM还有出色的多语言理解能力，用户的输入可以在中日英上自如切换。</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/d0/6d/d086f886dffc652985481fed8e15596d.png\" /></p><p></p><p>目前，WeLM的相关技术论文《WeLM: A Well-Read Pre-trained Language Model for Chinese》已经发布于论文预印本网站arXiv，感兴趣的用户可前往<a href=\"https://arxiv.org/abs/2209.10372\">https://arxiv.org/abs/2209.10372</a>\"查看更多技术细节。</p><p></p><p>接下来，微信AI将针对WeLM进行进一步的微调优化，进一步提升其在新任务上的泛化效果。</p>",
    "publish_time": "2022-10-13 12:18:26",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]