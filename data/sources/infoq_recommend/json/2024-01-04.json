[
  {
    "title": "Java近期新闻：JHipster 8.1、Piranha Cloud 23.12、Open Liberty 23.0.0.12和多个版本的Tomcat",
    "url": "https://www.infoq.cn/article/xWykuUX5CkMaRdYXCMj4",
    "summary": "<p>本期的Java综述包括OpenJDK的早期访问版本、Open Liberty 23.0.0.12、Infinispan 15.0.0-Dev06、JHipster 8.1.0、Piranha 23.12.0和Apache Tomcat的多个版本（11.0.0-M15、10.1.17、9.0.84和8.5.97），以及首次登场亮相的Payara虚拟会议。</p><p>&nbsp;</p><p></p><h4>JDK 23</h4><p></p><p>JDK 23的早期访问构建版本的<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-23%2B2\">Build 2</a>\"发布，它是对Build 1的<a href=\"https://github.com/openjdk/jdk/compare/jdk-23%2B1...jdk-23%2B2\">更新</a>\"，其中包括对各种<a href=\"https://bugs.openjdk.org/issues/?jql=project%20%3D%20JDK%20AND%20fixversion%20%3D%2023%20and%20%22resolved%20in%20build%22%20%3D%20b02%20order%20by%20component%2C%20subcomponent\">问题</a>\"的修复。关于这个版本的更多细节可以在<a href=\"https://jdk.java.net/23/release-notes\">发布说明</a>\"中找到。</p><p>&nbsp;</p><p></p><h4>JDK 22</h4><p></p><p>JDK 22的早期访问构建版本的<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-22%2B28\">Build 28</a>\"发布，它是对Build 27的<a href=\"https://github.com/openjdk/jdk/compare/jdk-22%2B27...jdk-22%2B28\">更新</a>\"，其中包括对各种<a href=\"https://bugs.openjdk.org/issues/?jql=project%20%3D%20JDK%20AND%20fixversion%20%3D%2022%20and%20%22resolved%20in%20build%22%20%3D%20b28%20order%20by%20component%2C%20subcomponent\">问题</a>\"的修复。关于这个版本的更多细节可以在<a href=\"https://jdk.java.net/22/release-notes\">发布说明</a>\"中找到。</p><p>&nbsp;</p><p>对于<a href=\"https://openjdk.org/projects/jdk/23/\">JDK 23</a>\"和<a href=\"https://openjdk.org/projects/jdk/22/\">JDK 22</a>\"，鼓励开发人员通过<a href=\"https://bugreport.java.com/bugreport/\">Java缺陷数据库</a>\"报告缺陷。</p><p>&nbsp;</p><p></p><h4>Spring Framework</h4><p></p><p><a href=\"https://spring.io/projects/spring-framework\">Spring Framework</a>\"的6.1.2和6.0.15版本<a href=\"https://spring.io/blog/2023/12/14/spring-framework-6-0-15-and-6-1-2-available-now\">发布</a>\"，提供了缺陷修复、文档改进、依赖性升级和新特性，例如，在TargetSource接口中，将isStatic()和releaseTarget()声明为默认方法；改进@RegisterReflectionForBinding注解，用于显式处理枚举；解决在ConcurrentReferenceHashMap中出现竞态条件的问题。这些版本可以分别在即将发布的<a href=\"https://spring.io/projects/spring-boot\">Spring Boot</a>\"&nbsp;3.2.1和3.1.7中使用。关于这些版本的更多细节，请参阅<a href=\"https://github.com/spring-projects/spring-framework/releases/tag/v6.1.2\">6.1.2版本</a>\"和<a href=\"https://github.com/spring-projects/spring-framework/releases/tag/v6.0.15\">6.0.15版本</a>\"的发布说明。</p><p>&nbsp;</p><p><a href=\"https://spring.io/projects/spring-data\">Spring Data</a>\"的2023.1.1和2023.0.7版本<a href=\"https://spring.io/blog/2023/12/15/spring-data-2023-1-1-and-2023-0-7-available\">发布</a>\"，提供了缺陷修复，并对相应的子项目进行了升级，比如：Spring Data Commons 3.2.1和3.1.7；Spring Data MongoDB 4.2.1和4.1.7；Spring Data Elasticsearch 5.2.1和5.1.7，以及Spring Data Neo4j 7.2.1和7.1.7。这些版本可能分别被即将发布的Spring Boot 3.2.1和3.1.7版本所使用。</p><p>&nbsp;</p><p></p><h4>Open Liberty</h4><p></p><p>IBM<a href=\"https://openliberty.io/blog/2023/12/12/23.0.0.12.html\">发布</a>\"了<a href=\"https://openliberty.io/\">Open Liberty</a>\"的23.0.0.12版本，包括如下特性：支持MicroProfile 6.1；升级至<a href=\"https://github.com/OpenLiberty/ci.maven/releases/tag/liberty-maven-3.10\">Liberty Maven plug-in 3.10</a>\"、<a href=\"https://github.com/OpenLiberty/ci.gradle/releases/tag/liberty-gradle-plugin-3.8\">Liberty Gradle plug-in 3.8</a>\"以及面向Eclipse IDE、IntelliJ IDEA和Visual Studio Code的Liberty Tools 23.0.12；解决<a href=\"https://nvd.nist.gov/vuln/detail/CVE-2023-44487\">CVE-2023-44487</a>\"，这是一个Tomcat实现的HTTP/2易于受到<a href=\"https://www.securityweek.com/rapid-reset-zero-day-exploited-to-launch-largest-ddos-attacks-in-history/\">快速重置攻击</a>\"的漏洞，这样会造成<a href=\"https://www.mail-archive.com/announce@apache.org/msg08557.html\">拒绝服务</a>\"，通常表现为OutOfMemoryError。</p><p></p><h4>Quarkus</h4><p></p><p><a href=\"https://quarkus.io/\">Quarkus</a>\"&nbsp;3.6.3<a href=\"https://quarkus.io/blog/quarkus-3-6-3-released/\">发布</a>\"，解决了如下问题：在3.6.2版本的回归中，ConfigDiagnostic类产生的NullPointerException；禁用Keycloak的<a href=\"https://quarkus.io/guides/dev-services\">Dev Services</a>\"所导致的启动错误；当Quarkus试图匹配未知的配置文件时，会抛出NullPointerException。关于该版本的更多细节，请参阅<a href=\"https://github.com/quarkusio/quarkus/releases/tag/3.6.3\">变更日志</a>\"。</p><p></p><h4>Micronaut</h4><p></p><p>Micronaut基金会<a href=\"https://micronaut.io/2023/12/15/micronaut-framework-4-2-2-released/\">发布</a>\"了<a href=\"https://micronaut.io/\">Micronaut框架</a>\"的4.2.2版本，其中包含了<a href=\"https://github.com/micronaut-projects/micronaut-core/releases/v4.2.2\">Micronaut Core 4.2.2</a>\"，以及对<a href=\"https://micronaut-projects.github.io/micronaut-aws/latest/guide/\">Micronaut AWS</a>\"和<a href=\"https://micronaut-projects.github.io/micronaut-cache/latest/guide/\">Micronaut Cache</a>\"模块的更新。关于该版本的更多细节，请参阅<a href=\"https://github.com/micronaut-projects/micronaut-platform/releases/tag/v4.2.2\">发布说明</a>\"。</p><p></p><h4>Helidon</h4><p></p><p><a href=\"https://helidon.io/\">Helidon</a>\"发布了<a href=\"https://github.com/helidon-io/helidon/releases/tag/2.6.5\">2.6.5版本</a>\"，包含如下特性：依赖性升级；在OciExtension类中支持供应商专门的注入点；纠正文档中如何设置OpenAPI生成器的错误。关于该版本的更多细节，请参阅<a href=\"https://github.com/helidon-io/helidon/blob/2.6.5/CHANGELOG.md\">变更日志</a>\"。</p><p></p><h4>Grails</h4><p></p><p>Grails基金会发布了<a href=\"https://grails.org/\">Grails框架</a>\"的6.1.1版本，其中包含了缺陷修复、依赖性升级和一些值得注意的变更，例如，通过为每个测试使用不同的模板名称来解决测试凌乱的问题；将Grails更新到Groovy 3.0.19并与之兼容；提供了SnakeYAML BOM。关于该版本的更多细节，请参阅<a href=\"https://github.com/grails/grails-core/releases/tag/v6.1.1\">发布说明</a>\"。</p><p></p><h4>Infinispan</h4><p></p><p><a href=\"https://infinispan.org/\">Infinispan</a>\"&nbsp;15.0.0的<a href=\"https://github.com/infinispan/infinispan/releases/tag/15.0.0.Dev06\">第六个开发版本</a>\"有一些显著的变化，比如，重新引入了对JCache的支持，因为它的CDI切面对javax命名空间的依赖是可选的，这使得不需要CDI就可以实现JCache；解决JGroupsTransport类中定义的getmemberspphysicaladdresses()方法抛出IllegalArgumentException的问题；在尝试注册度量指标之前，进行检查以确保MetricsRegistry接口是启用的。关于该版本的更多细节，请参阅<a href=\"https://github.com/infinispan/infinispan/compare/15.0.0.Dev05...15.0.0.Dev06\">变更日志</a>\"。</p><p></p><h4>Micrometer</h4><p></p><p><a href=\"https://github.com/micrometer-metrics/micrometer/blob/main/README.md\">Micrometer Metrics</a>\"&nbsp;的1.12.1和1.11.7版本都提供了依赖性升级和值得注意的变更，包括：新的ModifiedClassPathClassLoader类，从而能够与Spring Boot版本同步；修复了缺陷，即在第一个步骤关闭完成之前，就关闭步骤注册表，将会导致重复发布数据。关于这两个版本的更多细节，请参阅<a href=\"https://github.com/micrometer-metrics/micrometer/releases/tag/v1.12.1\">1.12.1版本</a>\"和<a href=\"https://github.com/micrometer-metrics/micrometer/releases/tag/v1.11.7\">1.11.7版本</a>\"的发布说明。</p><p>&nbsp;</p><p>类似的，<a href=\"https://github.com/micrometer-metrics/tracing/blob/main/README.md\">Micrometer Tracing</a>\"的1.2.1和1.1.8版本都提供了依赖性升级，并解决了在Observation接口中的内部接口Event中，getWallTime()方法的默认值返回0的问题，该方法在上传span时会导致后端失败。关于这两个版本的更多细节，请参阅<a href=\"https://github.com/micrometer-metrics/tracing/releases/tag/v1.2.1\">1.2.1版本</a>\"和<a href=\"https://github.com/micrometer-metrics/tracing/releases/tag/v1.1.8\">1.1.8版本</a>\"的发布说明。</p><p></p><h4>Eclipse Vert.x</h4><p></p><p>Eclipse&nbsp;<a href=\"https://vertx.io/\">Vert.x</a>\"的4.5.1版本<a href=\"https://vertx.io/blog/eclipse-vert-x-4-5-1/\">发布</a>\"，带了一些值得关注的变化，包括：由于JDK 22的变更，在解析PostgreSQL时间戳时，从Locale.ROOT切换到了Local.US；解决了当HTTP/1.1缺少主机头信息时，ForwardedParser类中出现NullPointerException的问题；新的@JsonGen注解，它将替换@DataObject注解以触发转换器的生成。关于该版本的更多细节，请参阅<a href=\"https://github.com/vert-x3/wiki/wiki/4.5.1-Release-Notes\">发布说明</a>\"以及对<a href=\"https://github.com/vert-x3/wiki/wiki/4.5.1-Deprecations-and-breaking-changes\">废弃功能和破坏性变更</a>\"的介绍。</p><p></p><h4>JHipster</h4><p></p><p><a href=\"https://www.jhipster.tech/\">JHipster</a>\"&nbsp;8.1.0版本<a href=\"https://twitter.com/deepu105/status/1734199476527464455\">发布</a>\"，包含了缺陷和依赖性升级，并增加了新特性，例如，使用会话端点元数据进行OAuth注销；重构&nbsp;CustomClaimConverter类中的授权头信息。关于这个版本的更多细节，请参阅JHipster 8.0的<a href=\"https://www.jhipster.tech/2023/12/11/jhipster-release-8.1.0.html\">发布说明</a>\"和InfoQ关于JHipster 8.0的<a href=\"https://www.infoq.com/news/2023/12/jhipster-version8-release/\">新闻</a>\"。</p><p></p><h4>Project Reactor</h4><p></p><p><a href=\"https://github.com/reactor/reactor/blob/main/README.md\">Project Reactor</a>\"&nbsp;2023.0.1是第一个维护版本，提供了对reactor-core 3.6.1、reactor-netty 1.1.14和reactor-pool 1.0.4的依赖性升级。在2023.0.1版本中，reactor-kafka 1.3.22、reactor-addons 3.5.1和reactor-kotlin-extensions 1.2.2制品没有变化。关于该版本的更多细节，请参阅<a href=\"https://github.com/reactor/reactor/compare/2023.0.0...2023.0.1\">变更日志</a>\"。</p><p>&nbsp;</p><p>与之类似，Project Reactor 2022.0.14（<a href=\"https://github.com/reactor/reactor/releases/tag/2022.0.14\">第14个维护版本</a>\"）提供了对reactor-core 3.5.13、reactor-netty 1.1.14和reactor-pool 1.0.4的依赖性升级。在2022.0.14版本中，reactor-kafka 1.3.22、reactor-addons 3.5.1和reactor-kotlin-extensions1.2.2制品没有变化。关于该版本的更多细节，请参阅<a href=\"https://github.com/reactor/reactor/compare/2022.0.13...2022.0.14\">变更日志</a>\"。</p><p></p><h4>Apache软件基金会</h4><p></p><p><a href=\"https://tomcat.apache.org/\">Apache Tomcat</a>\"的<a href=\"https://www.mail-archive.com/announce@apache.org/msg08753.html\">11.0.0-M15</a>\"、<a href=\"https://www.mail-archive.com/announce@apache.org/msg08752.html\">10.1.17</a>\"、<a href=\"https://www.mail-archive.com/announce@apache.org/msg08754.html\">9.0.84</a>\"和<a href=\"https://www.mail-archive.com/announce@apache.org/msg08751.html\">8.5.97</a>\"版本都修复了缺陷，并提供了值得注意的变更，例如，当容器的生命周期操作正在进行时，容器的后台进程不再执行；修正了<a href=\"http://www.webdav.org/\">WebDAV</a>\"响应会出现意料之外的XML转义的问题；在HTTP请求处理时，如果发生读取超时的话，使用<a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/408\">HTTP 408</a>\"状态码“Request Timeout”而不是<a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400\">HTTP 400</a>\"状态码“Bad Request”。关于这些版本的更多细节，请参阅<a href=\"http://tomcat.apache.org/tomcat-11.0-doc/changelog.html\">11.0.0-M15版本</a>\"、<a href=\"http://tomcat.apache.org/tomcat-10.1-doc/changelog.html\">10.1.17版本</a>\"、<a href=\"https://tomcat.apache.org/tomcat-9.0-doc/changelog.html\">9.0.84版本</a>\"和<a href=\"https://tomcat.apache.org/tomcat-8.5-doc/changelog.html\">8.5.97版本</a>\"的变更日志。</p><p>&nbsp;</p><p><a href=\"https://maven.apache.org/\">Apache Maven</a>\"&nbsp;4.0.0的<a href=\"https://www.mail-archive.com/announce@apache.org/msg08756.html\">第9个alpha版本</a>\"提供了一些值得注意的变化，例如，依赖升级到Maven Resolver 2.0.0-alpha-3；提供了多线程的map/reduce算法来并行解析冗长的reactor模型；当需要注入bean而会话作用域还不可用时，@SessionScoped注解现在将创建代理来包装bean。关于该版本的更多细节，请参阅<a href=\"https://maven.apache.org/docs/4.0.0-alpha-9/release-notes.html\">发布说明</a>\"。</p><p>&nbsp;</p><p><a href=\"https://camel.apache.org/\">Apache Camel</a>\"的<a href=\"https://camel.apache.org/blog/2023/12/RELEASE-3.21.3/\">3.21.3</a>\"和<a href=\"https://camel.apache.org/blog/2023/12/RELEASE-3.20.9/\">3.20.9</a>\"版本都对依赖性进行了升级，并修复了一些值得关注的缺陷，例如，在通过multipart启动大文件上传时出现的OutOfMemoryError；EndpointDslMojo类中定义的addHeaderNameMethod()方法生成错误的头信息名；<a href=\"https://camel.apache.org/camel-k/2.1.x/index.html\">Apache Camel K</a>\"的Kubernetes secret配置没有按照预期方式运行。关于这两个版本的更多细节，请参阅<a href=\"https://camel.apache.org/releases/release-3.21.3/\">3.21.3版本</a>\"和<a href=\"https://camel.apache.org/releases/release-3.20.9/\">3.20.9版本</a>\"的发布说明。</p><p></p><h4>Piranha</h4><p></p><p><a href=\"https://piranha.cloud/\">Piranha</a>\"发布<a href=\"https://github.com/piranhacloud/piranha/releases/tag/v23.12.0\">23.12.0版本</a>\"，提供了值得关注的变更，包括：在Payara Web Profile中支持CRaC；将Docker文件更新到JDK 21；将依赖升级到Spring Boot 3.1.6。关于此版本的更多细节，请参阅其<a href=\"https://javadoc.io/doc/cloud.piranha/project/latest/index.html\">文档</a>\"和<a href=\"https://github.com/piranhacloud/piranha/issues?q=is%3Aissue+-label%3Awontfix+milestone%3A23.12.0+is%3Aclosed\">问题跟踪器</a>\"。</p><p></p><h4>OpenXava</h4><p></p><p><a href=\"https://openxava.org/\">OpenXava</a>\"&nbsp;7.2.1<a href=\"https://openxava.org/blog/openxava-7.2.1-released\">发布</a>\"，提供了依赖性升级和值得关注的缺陷修复，例如，XSTL依赖所引发的远程代码执行漏洞；在@Coordinates中使用@OnChange&nbsp;action无法按照预期方式运行；忽略掉了@Tree注解中所定义的idProperties属性。关于此版本的更多细节，请参阅<a href=\"https://github.com/openxava/openxava/releases/tag/7.2.1\">发布说明</a>\"。</p><p></p><h4>Payara虚拟会议</h4><p></p><p>首届<a href=\"https://www.crowdcast.io/c/virtualpayaraconference\">Payara虚拟会议</a>\"举行，该会议为期一天，由顶级行业分析师、Java Champions和Jakarta EE专家参加。与会者还从Payara首席执行官<a href=\"https://www.linkedin.com/in/smillidge/\">Steve Millidge</a>\"那里了解了更多关于Payara Platform 2024路线图的信息。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/12/java-news-roundup-dec11-2023/\">&nbsp;Java News Roundup: JHipster 8.1, Piranha Cloud 23.12, Open Liberty 23.0.0.12, Tomcat Releases</a>\"</p>",
    "publish_time": "2024-01-04 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "以 Git 为数据源、具备版本控制的数据源 Dolt 新增了 PostgreSQL 风味",
    "url": "https://www.infoq.cn/article/4862sxkDtGxglAojD3Bd",
    "summary": "<p><a href=\"https://www.dolthub.com/blog/2023-11-01-announcing-doltgresql/\">DoltgreSQL</a>\" 以版本控制数据库 Dolt 为基础构建，为 Postgre 数据库模式及数据提供类 Git 的日志、差异、分支及合并功能。</p><p>&nbsp;</p><p>Dolt 作为 SQL 数据库，允许用户像是 Git 代码库一样进行克隆、fork、分支及合并。通过 Dolt，应用程序开发者可以为用户创建分支，合并工作流，比如发送 pull 请求修复数据中的错误。同理，Dolt 可以通过数据库分支、变更应用，在暂存环境中测试，并最终部署回生产环境的这种简单模型修改生产数据库。</p><p>&nbsp;</p><p>Dolt 从创建之初就采用了 MySQL 的语法和<a href=\"https://docs.dolthub.com/cli-reference/git-comparison\">面向命令行的范式</a>\"，Git 用户对此必然不会感到陌生。</p><p>&nbsp;</p><p>DoltgreSQL 专注于数据库服务体验，提供可定制且易于部署的服务器。此外，该公司表示这款数据库不提供命令行支持，以更好地与 PostgreSQL 的一般用户体验保持一致。</p><p>&nbsp;</p><p></p><blockquote>DoltgreSQL 的工作原理是模拟 PostgreSQL 服务器，将接收到的命令转化为 AST 后提供给底层的 Dolt 服务器。如此一来便能实现快速的启动和运行，同时还可利用 Dolt 已提供的能力和功能。</blockquote><p></p><p>&nbsp;</p><p>这种在 Dolt 基础之上的构建新功能的优势在于可借助后者的稳定性和可靠性，减少开发的范围和工作量。</p><p>&nbsp;</p><p>DoltHub 称他们研究了不同的方式，其中包括编写外来数据包装器、构建全新 PostgreSQL 存储后端，甚至是 fork PostgreSQL 本身。这些方式中有些存在太大的局限性，有些（如 fork PostgreSQL）则需要数年之久的开发时间。</p><p>&nbsp;</p><p>至于负面方面，这种仿 Git 方法的缺点在于其无法运行实际的 PostgreSQL 二进制文件。正如前文所述，DoltgreSQL 是将 PostgreSQL 语法转换为 AST 表示法，并在 Dolt 层中运行。</p><p>&nbsp;</p><p>在完成安装 DoltgreSQL 之后，用户可以使用 psql 命令行客户端连接到数据库。若要查询数据库状态，则可运行这行语句：</p><p><code lang=\"java\">select * from dolt_status;</code></p><p>这行语句会列出所有现存表，并指定这些表为新表或暂存表等等。若要将一个表添加到暂存区域，则可运行这行语句：</p><p><code lang=\"null\">call dolt_add('my_table_name');</code></p><p>若要提交变更，则运行：</p><p><code lang=\"java\">call dolt_commit('-m', 'updated schema');</code></p><p>而&nbsp;select * from dolt_log;语句则是等同于 git log。</p><p>&nbsp;</p><p>Doltgres 仍处于试验阶段且存在一些<a href=\"https://github.com/dolthub/doltgresql#limitations\">限制情况</a>\"，其中包括不支持 DoltHub 和 DoltLab、没有身份验证或用户管理、对 SSL 连接的支持有限、不支持复制、群集等。</p><p>&nbsp;</p><p>虽然 Dolt 的“数据版 Git”这一价值主张听起来很有吸引力，但数据库专家 <a href=\"http://www.jandrewrogers.com/about/\">J. Andrew Rogers</a>\"&nbsp;在 Hacker News 上指出，这一目标与<a href=\"https://news.ycombinator.com/item?id=31852067\">多版本并发控制（MVCC）几十年来的尝试并无二致</a>\"，而且还存在几个重要缺点。Dolt 首席执行官 Tim Sehn 强调，<a href=\"https://docs.dolthub.com/sql-reference/benchmarks/latency\">与原生 MySQL 在 sysbench 基准的运行相对比</a>\"，Dolt 仅比 MySQL 略慢一点。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/11/DoltgreSQL-git-for-data-postgres/\">Git-for-Data, Version-Controlled Database Dolt Gets PostgreSQL-Flavor</a>\"</p>",
    "publish_time": "2024-01-04 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Redis之父亲自上手用大模型撸代码：通晓古今的白痴队友，将来可以取代99%程序员",
    "url": "https://www.infoq.cn/article/s2f71m8cQVqRUEdlLegx",
    "summary": "<p></p><p></p><blockquote>Redis 创始人 antirez&nbsp;写下了自己2024年的第一篇博文，他从一名普通程序员的角度谈了谈对大语言模型的感受，虽然他的成就并不普通。他在文章里犀利评价Google引擎已经成为垃圾的海洋，并客观评价了现在的AIGC能力：愚蠢但通晓古今。&nbsp;通过长期使用，他认为现阶段的生成式AI只会让已经很强的程序员变得更强。目前大多数编程任务都是在重复工作，根本不需要大模型有太高的推理水平，大模型很适合那些“用完就扔”的程序。我们对antirez&nbsp;的博文进行了翻译，并在不改变作者原意基础上进行了一些删减。</blockquote><p></p><p>&nbsp;&nbsp;</p><p>自从ChatGPT横空出世以来，包括后面以本地方式运行的各种大模型，生成式AI已然得到了广泛应用。我个人的目的一方面是想依靠大模型提高编码能力，另外还希望把宝贵的精力从繁琐且价值有限的工作中解放出来。相信很多朋友也像我一样，花费了无数时间搜索没什么启发性的技术文档、被迫学习各种过于复杂的API、编写过短时间内就沦为垃圾的程序。工作不该是这样的，开发也不该是这样的。现如今，Google引擎已经成了垃圾的海洋，我们得费尽心思才能在其中找到一点有用的内容。</p><p>&nbsp;</p><p>另外，我本人并不是编程新手。哪怕不借助任何外部资源，我也能够编写代码，甚至可以说具备一定开发水平。只是随着时间推移，我开始越来越多地用大模型协助编写高级代码：Python代码最多，但在C语言中则应用较少。</p><p>&nbsp;</p><p>大语言模型最让我印象深刻的一点，就是我能准确意识到何时可以使用、而哪些情况下盲目使用只会拖慢进度。我还发现，大模型其实很像维基百科和YouTube上的各种视频课程：对于有意愿、有能力、更自律的使用者来说效果拔群，但对本就业务能力不足的朋友来说则边际收益递减。所以我很担心，至少在现阶段，生成式AI只会让已经很强的程序员变得更强。</p><p>&nbsp;</p><p>下面让我们一步步开始讨论。</p><p>&nbsp;</p><p></p><h1>大语言模型：全知全能还是鹦鹉学舌？</h1><p></p><p>&nbsp;</p><p>机器学习新浪潮中最令人忧心的现象之一，就是AI专家对于大模型的认知还相当有限。我们虽然发明了神经网络，但在实质上发明的仅仅是一种自动优化神经网络参数的算法。硬件已经能够训练出越来越大的模型，并使用提取自待处理数据（先验素材）的统计知识，再通过大量迭代试验排除错误、逼近正确答案。必须承认，大模型确实要比以往其他架构效果更好。但总体来讲，神经网络本身仍然极不透明。</p><p>&nbsp;</p><p>由于无法解释大模型为何具备某些新兴能力，预计科学家们的态度将更趋谨慎。但在另一个极端上，也有不少人都严重低估了大语言模型，认为它们只不过是某种更先进的马尔可夫链，最多只能重现在训练集中见到过的有限变化。但大量事实证据表明，这种大模型只是在“鹦鹉学舌”的理论根本站不住脚。</p><p>&nbsp;</p><p>也有不少热心群众觉得大语言模型获得了某种实际上不存在的超自然力量。没那么玄乎，大模型最多只能对自己在训练期间接触过的数据表示空间进行插值，而这并不是什么新鲜成果。而且哪怕单论插值，其能力也相当有限（但足以超出人类预期，甚至带来惊喜）。如果能够更进一步，在接触过的所有代码围成的空间当中进行连续插值，那么大模型哪怕无法创造出真正新奇的事物，也足以取代99%的程序员。</p><p>&nbsp;</p><p>好在现实没这么夸张，我们开发者们仍有生存的空间。大语言模型确实能编写出自己没有原样接触到的程序形式，也表现出通过融合训练集内不同出现频率的思路来引导开发方向的初步能力。只是这种能力目前还存在很大的局限性，而种种微妙的推理任务总会令大语言模型遭遇灾难性的失败。但必须承认，大语言模型已经代表着AI技术从诞生至今最伟大的成就，这一点应该成为所有讨论的前提。</p><p>&nbsp;</p><p></p><h1>既愚蠢，却又通晓古今</h1><p></p><p>&nbsp;</p><p>此言不假：大语言模型最多只能进行最基本的推理，这种推理还不够准确，很多时候充满了事实层面的幻觉和捏造。但它们同样拥有着渊博的知识。</p><p>&nbsp;</p><p>以编程领域及其他能够获取高质量数据的场景为例，大模型就像那种通晓古今的愚蠢学者。与这样的合作伙伴进行结对编程并不明智（当然，在我看来哪怕是跟人做结对编程也不明智）：它们往往会抛出荒谬的想法，而我们则需要在开发中不断努力强调自己的思路。</p><p>&nbsp;</p><p>但反过来，如果把这个博学的傻瓜当成可支配的工具、由它提出问题以作为我们激发灵感的素材，那么效果将完全不同。目前的大模型还无法引领人类跨越知识的鸿沟，但如果我们想解决某个自己不太熟悉的问题，它们往往可以帮助我们从一无所知快速前进到具备完全自学能力的程度。</p><p>&nbsp;</p><p>在编程领域，之前二、三十年间的程序员们可能对大模型的这种能力评价不高。毕竟那时候我们只需要掌握几种编程语言、特定的经典算法和那十来套基础库，余下的就纯粹是自我表达、发挥才智、运用专业知识和设计技能的部分了。只要拥有这种能力，我们就是当之无愧的专业程序员，具备了解决一切难题的潜质。</p><p>&nbsp;</p><p>但随着时间推移，各种框架、编程语言和库开始轮番上阵，爆发式的增长令开发难度激增，也给程序员的日常工作带来了既无必要、又不合理的诸多困扰。在这样的现实和背景之下，大模型这样一位通晓古今的白痴队友就成了最宝贵的前进指引。</p><p>&nbsp;</p><p>举个例子：我自己的机器学习实验在整整一年间都是靠Keras完成的。后来出于种种原因，我转而使用PyTorch。当时我已经学习了什么叫嵌入和残差网络，但我实在不想逐字逐句去研究PyTorch文档（当初我在学Keras时就是这么硬啃下来的，如果能有ChatGPT肯定可以帮我回避很多痛苦的回忆）。如今有了大语言模型，我可以非常轻松地编写出使用Torch的Python代码，唯一的前提就是对想要组合的模型拥有清晰的思路、同时能够提出正确的问题。</p><p>&nbsp;</p><p></p><h1>用案例说话</h1><p></p><p>&nbsp;</p><p>请注意，我这里说的可不是那些简单的需求，比如“X类是怎么实现Y的？”如果只是这类场景，那大语言模型的作用其实相当有限，甚至可以说跟搜索引擎和技术论坛区别不大。相反，复杂模型能做到的要多得多，包括那些短短几年前我们还无法想象的功能。</p><p>&nbsp;</p><p>现在我可以告诉GPT-4：“看看，这是我在PyTorch实现的神经网络模型。这些是我设置的批任务。我想调整张量大小，保证批函数与神经网络的输入相兼容，同时想以这种特定方式来表示。你能告诉我需要怎样的代码进行重写吗？”提示完成之后，GPT-4就会编写代码，而我要做的就是在Python CLI中测试张量结果的维度是否满足需求、数据布局是否正确。</p><p>&nbsp;</p><p>再来看另一个例子。前段时间，我需要为某些基于ESP32的设备开发BLE客户端。经过一番研究，我发现多平台蓝牙编程绑定大多无法直接使用，而解决方案非常简单，使用macOS的本机API在Objective C中编写代码即可。这就要求我同时处理两个问题：学习Objective C那繁琐的BLE API，适应种种毫无意义的模式（我属于那种极简主义者，而Objective C的BLE&nbsp;API绝对是“优秀设计”的典型反例）；同时学会如何用Objective C编程。我上次用它编程还是在十年之前，如今早就忘了事件循环、内在管理等技术细节。</p><p>&nbsp;</p><p>最终结果就是以下代码，虽然不够优雅简洁，但至少能够正常起效。在大模型的帮助下，我只用了很短时间就完成了开发，这在以往根本就无法想象：</p><p>&nbsp;</p><p><a href=\"https://github.com/antirez/freakwan/blob/main/osx-bte-cli/SerialBTE.m\">https://github.com/antirez/freakwan/blob/main/osx-bte-cli/SerialBTE.m</a>\"</p><p>&nbsp;</p><p>这些代码主要由ChatGPT生成，而我的工作就是把自己想做、但不太确定要怎么实现的要求粘贴进去。如此一来，大模型就能向我做出解释，包括问题的实质是什么、应当如何解决。</p><p>&nbsp;</p><p>的确，大模型并没有实际编写多少代码，但却帮助我显著加快了开发速度。如果没有ChatGPT，我能不能把项目做下来？当然也行，但最重要的并不是我要额外投入多少时间，而是我可能干脆就放弃了：毕竟这么麻烦的事情，已经不值得我浪费精力。</p><p>&nbsp;</p><p>在我看来，这才是真正决定性的因素。如果没有大模型，我在衡量工作量和收益之后压根不会编写这样一个程序。大模型甚至还帮我完成了一项比程序本身更重要的调整：在项目中，我修改了linenoise（我使用的行编辑库）以使其能在多路复用中生效。</p><p>&nbsp;</p><p></p><h1>即抛型程序</h1><p></p><p>&nbsp;</p><p>像前文提到的这类案例还有很多，这里就不再过多重复了，毕竟类似的故事基本都是一样的套路和效果。在日常工作中，我还经常面临另一类问题，就是想要快速获得某些可以验证的成果。在这种情况下，同样可以使用大模型来提升探索效率。</p><p>&nbsp;</p><p>对于此类场景，我往往会让大模型负责编写所有代码。例如，当我需要编写某些即抛型程序时，比如下面这个：</p><p><a href=\"https://github.com/antirez/simple-language-model/blob/main/plot.py\">https://github.com/antirez/simple-language-model/blob/main/plot.py</a>\"</p><p>&nbsp;</p><p>我想要对小型神经网络学习过程中的损失曲线进行可视化，因此向GPT-4展示了PyTorch程序生成的CSV文件格式，然后提出如果我在命令行内指定多个CSV文件，希望能对不同实验所验证的损失曲线进行比较。而以上链接就是GPT-4生成的结果，前后只用了短短30秒。</p><p>&nbsp;</p><p>同样的，我还需要一个程序来读取AirBnB CSV报告，并按月份和年份对各处公寓进行分组。之后，结合清洁费用以及单次预订的住宿天数，由它来统计一年中不同月份的平均租金价格。这款程序对我来说确实有用，但编写过程又极其无聊：因为里面根本没什么新奇有趣的功能。于是乎，我选取了一部分CSV文件并粘贴进GPT-4当中，之后描述了一下希望大模型解决的问题。输出的程序一次运行成功。但我们自己得正确理解具体的数据分组方式，否则会感觉这些数据既分散又无序。</p><p>&nbsp;</p><p>通过简单的推理，我认为大模型绝对不是简单从接触过的训练素材中照搬来的解决方案。没错，GPT-4在训练期间肯定观察到过类似的程序，只是这些程序所对应的具体分组要求跟我的提示有所不同，特别是要求分组成特定格式的CSV文件。所以在我看来，大模型应该能在一定程度上对训练集中不同程序描述的空间进行插值。</p><p>&nbsp;</p><p>让我自己浪费时间编写这类简单程序实在是不太明智。事实证明大模型可以承接此类任务，帮助我将精力集中在真正重要的工作上，这无疑变相提高了我的代码生产效率。</p><p>&nbsp;</p><p></p><h1>大模型搞不定的典型任务：系统编程</h1><p></p><p>&nbsp;</p><p>虽然我的大模型编程尝试取得了不小的成功，但在使用C语言编写程序时，我发现大模型更多只能作为便携的文档记录助手。我本人是系统编程方面的专家，在这类用例中，大模型由于缺乏复杂的推理能力而几乎帮不上什么忙。相信各位朋友也有类似的感受。</p><p>&nbsp;</p><p>下面我们一起来看这段实验性的提示词：</p><p>&nbsp;</p><p>“为bloom过滤器生成一条优雅、短小且有效的C语言实现。应重点关注哈希函数处理，然后用高质量C语言进行编写。另须考虑，这条实现的大小应可存储10万个元素，误报概率不得超过5%。添加的元素是以null结尾的字符串。“</p><p>&nbsp;</p><p>GPT-4给出的答案说不上好。Bloom过滤器其实相当普遍，涉及的数据结构也不特殊。但很明显，编写一个像样的bloom过滤器需要更强大的抽象能力：例如找到一种有效方法对同一字符串进行N次哈希处理，并确保各哈希值得到充分的去相关处理。如果换个思路，明确要求GPT-4修改哈希函数，使其产生N个去相关输出，那么它给出的解决方案就靠谱多了。如果它能自己发现这个思路，就会以不同的方式编写bloom过滤器，使用单个哈希函数一次设置K个bits。</p><p>&nbsp;</p><p>事实就是，GPT-4能够独立编写出适当也更加通用的哈希函数，但在编写bloom过滤器这类更大的项目时，它却未能表现出良好的推理能力，而是给出了两个不同但却高度相似的哈希函数。</p><p>&nbsp;</p><p>总而言之，当前大语言模型的推理能力仍然孱弱，再加上关于这个问题的资源可能比较稀少，甚至存在大量低质量资源，于是导致其给出的结果不尽如人意。而且这绝不是孤立的案例，我还多次尝试在算法或系统编程当中使用大模型，结果也非常差。哪怕是下调对推理能力的预期，它也没法重现Python编程环境中的代码生成水平。</p><p>&nbsp;</p><p>但与此同时，GPT-4能够反编译它所输出的函数（需要通过单独的会话），也能准确理解这样做的意义，因此，大模型在系统编程场景下还是具有一定作用的，只是非常有限。</p><p>&nbsp;</p><p>另一个有趣且令人期待的点，是在上述情况下，较小模型和较大模型间的表现有着显著差异。</p><p>&nbsp;</p><p>虽然Mixtral是一套适合多种用途的优秀模型，但考虑到大模型本就孱弱的推理能力，目前能够总结出的规律明显是体量越大、效果越好。另外，本地模型deepseek-coder设置为4 bits量化精度，因为本地设备的内存不足以在更高的精度上运行模型。哪怕如此，凭借340亿参数，它在同一问题上的推理能力还是更强一些。</p><p>&nbsp;</p><p>在尝试中，我给出了关于问题的解决线索，而模型则正确得出了答案、确定了引发问题的真正根源，并最终给出了行之有效的替代方案。这类应用在任何文档、书籍或者Google搜索中都没有直接答案。</p><p>&nbsp;</p><p>无论是从原始插值的角度、还是其他思路来看，模型都已经掌握了某种形式的推理能力。也只有借助这份推理能力，AI才能找到问题的根源并发现潜在的解决方案。所以我觉得没必要再争论了，大语言模型对于程序员们确实具备积极的辅助意义。</p><p>&nbsp;</p><p>但与此同时，过去几个月间的使用体验表明，在系统编程领域、特别是对于经验丰富的程序员们，大模型几乎无法给出任何可以拿来就用的解决方案。</p><p>&nbsp;</p><p>我目前负责的ggufflib项目要求编写一个读取和写入GGUF格式文件的库，也就是llama.cpp加载量化模型的格式。最初，为了理解量化编码的工作原理，我尝试使用过ChatGPT，但最后还是决定对llama.cpp的代码进行逆向工程——这样速度还更快些。</p><p>&nbsp;</p><p>理想中的大语言模型应该能根据接触到的数据编码“结构”声明和解码函数，还原出关于数据格式的说明文档，借此帮助系统程序员理解设计思路。可虽然llama.cpp的函数不大，完全可以塞进GPT-4的上下文窗口，但输出的结论却毫无意义。</p><p>&nbsp;</p><p>对于这类情况，我们就只能像最传统的程序员那样：掏出纸和笔，一行行阅读代码，查看解码器提取的bits在哪里注册。</p><p>&nbsp;</p><p></p><h1>正确看待大语言模型</h1><p></p><p>&nbsp;</p><p>虽然怀着深深的遗憾，但我不得不承认：目前大多数编程任务都是在以略有不同的形式重复着相同的工作，根本不需要太高的推理水平。而大语言模型在这方面表现出色，只是仍然受到上下文规模的硬性约束。</p><p>&nbsp;</p><p>而这也应当引起我们程序员的思考：这样的程序，真值得我们花费时间和精力动手编写吗？没错，这活能给我们带来相当丰厚的报酬，但如果大语言模型逐渐接手了这部分任务，那么五年、最多不超过十年，就会有很多程序员同行丢掉饭碗。</p><p>&nbsp;</p><p>再有，大语言模型到底具不具备一定程度的推理能力，还是说仍然是在鹦鹉学舌、只是学得更加惟妙惟肖？我认为某些情况下它们确实具备推理能力，也就是掌握了符号学家们所说的“能指”概念，即实质上并不存在的意义。</p><p>&nbsp;</p><p>相信每一位跟大模型经常打交道的朋友，都能在理解它们局限性的同时，感受到其中体现出的推理之力：它们对以往接触过的内容的融合能力，远远超出了随机输出单词的范畴。尽管其学习过程主要是在预训练阶段完成，但在预测下一个token时，大模型还是会根据目标建立起某种形式的抽象模型。这个模型虽然还很脆弱、不够完备和完美，但通过实际观察，我们会意识到这种能力的客观存在。正所谓耳听为虚、眼见为实，哪怕可能挑战数学专业的确定性原理、与最伟大的技术专家观点相背，我也仍然对大模型表现出的认知水平抱有信心。</p><p>&nbsp;</p><p>最后，希望大家能够积极拥抱大模型，尝试用它解决编程中的各种问题。向大模型提出正确问题将成为一项基础性的开发技能，而且演练的次数越多，AI就越是能更好地改进工作效果。哪怕不考虑AI因素，这种明确清晰的问题描述能力也有助于我们更好地跟他人沟通。毕竟大语言模型并不是唯一跟不上我们思维过程的会话对象。相信大家也有体会，很多程序员虽然在自己的特定领域里非常出色，但沟通能力却很差，这也成为限制其职业发展的瓶颈。</p><p>&nbsp;</p><p>现如今的Google引擎已经稀烂，所以哪怕是从浓缩和提炼文本内容的角度，大模型也肯定具备巨大的现实意义。就个人而言，我也将继续使用大模型、了解大模型。我向来不喜欢学习晦涩的通信协议细节，也不愿跟那些炫技式的复杂库编写方法打交道。对我来说，这些只是白白浪费时间和精力的“垃圾知识”。感谢大语言模型，把我从这些曾经的泥潭当中解救出来。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"http://antirez.com/news/140\">http://antirez.com/news/140</a>\"</p><p>&nbsp;</p>",
    "publish_time": "2024-01-04 14:05:05",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "你的数智化底座物尽其用了吗？",
    "url": "https://www.infoq.cn/article/hSwzdayDrIlELJNkivYU",
    "summary": "<p>在数智化转型过程中，构建具备领先技术能力，能够与企业业务充分融合的数智底座是企业取得转型成功的重要前提条件。但数智底座建成后，这个平台的使命并不意味着已经完成。一方面，平台需要动态且及时的适配企业不断变化的业务需求，以更少的投入开发出新的企业应用。另外一方面，也需要将平台充分用起来，包括平台上数据的应用，不同应用系统以及与外部系统的链接，基于平台的成果沉淀与持续创新等。</p><p></p><p>这些都属于平台运营能力，企业在花费大量资源建设的数智底座，如果不具备数智化运营能力，那么这个平台有可能会成为鸡肋，或者不能真正服务业务，或者会让企业持续卷入更多投入才能保证平台的持续使用。由此，会让企业投资蒙受损失，并错失数智化浪潮下的发展机遇。</p><p></p><p></p><h2>重金打造的数智平台，为何成为企业“鸡肋”？</h2><p></p><p></p><p>2015 年，全球最大的机电生产企业之一通用电气宣布了数字化转型计划——建设一个面向工业互联网的平台即服务项目 Predix，为该公司及众多客户的传统工业生产流程和员工提供数字化支持。该项目原本预计将为通用电气带来每年 150 亿美元的额外收入，结果在花费了五年时间，投入超过 70 亿美元后，项目的年收入仅仅达到 10 亿美元的水平，基本宣告失败。</p><p></p><p>回顾 Predix 项目五年间的发展历程可以发现，通用电气从一开始就犯下了重大错误：Predix 并未对集团内部现有组织架构、技术体系和员工能力进行全面升级，而是建设了一个与现有业务没有深度交集的平台，平台虽然具备诸多先进技术特性和能力，但通用电气上层并没有对其进行有效的运营管理。</p><p></p><p>从通用电气的这一失败案例可以看到，企业需要把数智平台的建设和运营放在同等重要的地位，搭建与研发、生产和业务流程充分融合的运营体系，才能让数智底座发挥真实潜力，使企业在市场竞争中占得先机。</p><p></p><p>拥有二十多年服务大型企业经验的用友iuap平台，是更懂业务、技术领先且体系完整的企业数智化平台。除了为企业提供三中台三平台（业务中台、数据中台、智能中台和技术平台、低代码开发平台、连接集成平台）外，还提供了数智化工程、可持续运营两大体系，助力企业全面升级数智化底座。不仅企业拥有了属于自己的平台，而且通过对平台的数智化运营，让这个平台成为企业可持续发展的源动力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/88/88989b2ab3d7ad199dd93cbb698c16e4.jpeg\" /></p><p></p><p></p><h2>搭建数智化工程体系，为企业数智化带来更高效益</h2><p></p><p></p><p>事实上，大型企业建设、运营数智平台最需要关注的三大指标是共通的，即安全、稳定与高效。在此基础之上，企业的 IT 架构需要以平台思维，构建能够实现数据打通和 IT 资产沉淀的体系，为企业提供平台化的技术能力，并统一数据治理规划，形成统一的数智底座。</p><p></p><p>企业想快速响应市场需求，提高生产效率和产品质量，需要建立一套完整机制来保证数据的流动、存储、加工、计算和供给。工程化能力为企业软件开发的各个环节进行充分的规范化、标准化和自动化，可以显著降低开发的时间成本和业务风险，这已经成为企业软件开发中不可或缺的能力要素。</p><p></p><p>用友认为，数智化工程化能力是系统韧性的基石，结合工程化能力，可以将传统生产模式向数字化、智能化方向升级，实现生产过程的全流程自动化和智能化。用友iuap在二十多年的研发部署中积累了大量经验，并深度实践敏捷工程化，让企业更加聚焦业务，并且构建了开发人员间的新型协作模式，全面提高 IT 供给能力。</p><p></p><p>用友iuap平台基于云原生架构，通过容器化技术实现企业服务的高弹性、高可用能力，通过 DevOps 能力实现商业创新的敏捷发布及变更，通过微服务能力实现企业创新服务的灵活解耦、自由治理。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bd/bd00d6016c61f3745d344775fc0b6814.jpeg\" /></p><p></p><p>具体而言，用友iuap基于云中间件YMS，实现了云上云下一套代码，让企业私有云平台体验到公有云的更新效率，让云下应用升级像 AppStore 一样简单，帮助企业将整体专属化效率提升 100%，启动效率提升 3 倍以上，制作 SP 补丁从 10 天降低到 1 天，制作金盘从以前的一个月降低到 2 天左右，各领域业务独立的配置从 1000 个降低到 0，极大提升全领域业务板块的统一配置效率，帮助企业快速调整业务。</p><p></p><p>用友iuap还提供了一套完整的质量门禁，以及覆盖测试、日常、预发、生产等多环境的审批机制，以保障所有产品到达客户端是完备的。它可以检测、保障和提升低代码质量，实时跟踪开发任务，全景展示发布过程，还带有完整的灰度发布机制，可以指定用户分流，保障业务应用平滑升级。在测试环节，用友iuap通过 RPA 技术实现自动化测试，减少测试人员及大量时间和成本。</p><p></p><p>用友iuap实现了智能运维，如智能分析历史决策数据和情境，支持更快和更准确的未来决策，将企业的重点从监控和响应转变为预测及主动干预，以最短的延迟做出主动决策。平台建立了完整机制来快速分析与诊断云上难题。通过对用户操作及应用调用链路进行分析，将操作事件按调用先后顺序罗列出来还原用户操作场景，帮助技术人员更精准的诊断问题。运维人员通过服务治理平台对服务、API、方法细粒度的管理，能够轻松梳理出服务间的关系，然后通过链路图、拓扑图、瀑布、列表等方式展示，从各维度快速找到问题。用友iuap通过内部各领域业务大量使用，数据各维度分析经验，可以打磨出业务数据关联分析框架与方案，并能快速分析获取目前服务性能、调用失败、熔断、限流等问题，优化微服务框架。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/62/6256b080b46ecaae32ca681a83090d49.jpeg\" /></p><p></p><p>为了进一步提升企业的数智平台运营效率，用友还提出了 IT 架构去“过程化”的概念，目标是用更少的能量和损耗维持数智化系统持续运行。用友iuap 尽可能减少了原始数据 / 原子能力与业务需求之间的中间数据 / 步骤，或使中间数据 / 步骤无须人为干预，自动化、智能化完成，其可实现架构的简单化、扁平化，同时可对业务需求实时响应，以进一步实现敏捷和创新。平台架构一开始就放弃“精细梳理方可使用”以及“梳理完成千万别动”思想，用全量原始数据保障读时模式，使得企业用更少的“能量”便可以维持数字化系统的持续运行。</p><p></p><p>企业开发人员在用友iuap的低代码开发平台上，可以通过可视化拖拉拽方式讲封装好的代码按照业务逻辑搭建应用并直接运行，极大提升效率。用友 iuap 还可在技术与架构支撑服务化以及微服务的细粒度、分布式、扩展性和治理能力，结合技术普惠的低代码开发体系，可以支撑 IT 应用开发，部署，运行敏捷化。</p><p></p><p>比如某行业领军企业，基于用友iuap，构建“以周迭代发布”的大规模敏捷交付工程化体系。系统稳定性从 96% 提升到 99.5%；提升 APP 研发效率以及批量交付能力；形成了覆盖 IaaS、PaaS、SaaS 三层及事前、事中、事后的稳定性保障体系。</p><p></p><p></p><h2>完善可持续运营体系，挖掘数智底座最大潜能</h2><p></p><p></p><p>数智化底座为企业数智化转型提供了平台基础设施，但是想要解决大型企业数智化转型中面临的各种业务和管理问题，还需要有效地将复杂基础设施、平台服务以及与财务、营销、采购、制造、人力等有关的共性业务服务进行融合，实现企业数智化能力的集约和统筹，帮助企业沉淀自己的数智化成果，来支撑企业数智化的持续迭代。</p><p></p><p>用友iuap基于成熟的产品研发、IT 运维方法论，生成一套可持续运营体系，帮助企业实现从数字化战略到落地执行的业务运营，构建数据驱动的全生命周期的运营闭环。让企业实现从工具链构建到运营，助力企业运营一朵云，随需享受云计算、大数据、人工智能等新技术带来的便利及价值。</p><p></p><p>随着企业业务的不断创新，产业互联网等模式不断落地实践，越来越多的 IT 组织开始从被动维持的“IT 运维模式”，走向主动经营的“价值运营”模式。他们更注重数智化底座的数据价值挖掘和利用，以及应用系统的复用性和产业链社会化集成。</p><p></p><p>这种特点在数科公司这个群体中更为明显。用友基于敏捷工程化体系，提供全方位的可持续运营赋能，包括顶层设计、团队建设、技术支持、市场推广等等。通过构建一套企业级产品运营体系，为产品全生命周期管理提供数智化领先实践，让数科公司实现长期可持续的价值运营。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/22/22e34f1f5ddbc2c1b307d060356f6860.png\" /></p><p></p><p>中船信息承担着中船集团公司信息化规划方面的重担，服务中船集团和相关成员单位数智化转型。中船信息董事长张凯曾表示，企业数智化转型是体系化策划推动的系统工程，需要对组织体系架构、业务模型、流程、方法、能力与资源进行有效协同，并且能够交付一套管理模型、IT 系统、文献体系和治理机制，实现现代化企业数智化转型的完整体系。中船信息与用友通过协同共创的方式，以“结构化模型”为主要特征，通过治理非结构化数据，让企业内部的结构化数据和非结构化数据建立关系。并以此为基础来打造数据中台，实现高效的协同管理，保证了多轮处理后数据的准确性，同时也实现了数据的有序流通。在帮助企业实现研发协同、信息协同的基础上，中船信息打造了属于自己的数智化底座，并且已经形成了从企业数智化顶层战略与规划、整体设计与方案、集成建设与实施，到全面售后与运维的全生命周期技术支持和服务保障能力，通过数智底座的功能化体系和可持续运营，实现现代化企业数智化转型的完整体系。</p><p></p><p>另外，某研究院在与用友合作的五年多时间里，在原有的流程管理方法基础上提出了价值管理方法论作为数智平台运营的基本理念。还基于用友iuap开发了一套工具链，打通了企业内部的所有流程、要素和价值管理，最终将所有管理工作转向模型化表达，再经过安全性、稳定性和效能检测来迭代上线。在用友iuap的支持下，某研究院建设了技术中台、业务中台和数据中台，将业务和场景部门所需的流水线和共性组件全部凝聚到中台中，再通过研发监控、资源监控、变更监控等能力管控产品研发质量。如今，某研究院实现了每年产品交付能力比五年前提升一个数量级的目标，同时实现了基于数智平台的数据治理和服务治理能力，可以将大量产品和流程全部打通，大幅降低企业运营成本，提升运营效能。</p><p></p><p>随着生成式 AI 技术开始在企业领域推广应用，企业数智化底座也需要相应的迭代升级来满足新时代的企业需求变化。大模型的引入对数智平台的运营能力提出了更高的要求。在安全性方面，数智平台需要进一步提升大模型所使用的海量企业隐私敏感数据的防护水平，确保企业不会因为 AI 应用而造成隐私泄露或恶意攻击事件；在稳定性方面，数智平台所使用的大模型不能影响平台现有各组件的可靠性与可用性，不能因为大模型服务中断或失效而导致原有平台能力失效；在效能提升方面，企业服务大模型要尽可能降低幻觉率，与企业业务充分融合，确保员工能够使用大模型切实提升工作效率。对此，用友iuap也做了大量工作来应对上述挑战，使用友企业服务大模型 YonGPT大模型进一步改善运营效能，让企业迅速看到生成式 AI 技术带来的生产力提升收益。</p><p></p><p></p><h2>写在最后&nbsp;&nbsp;</h2><p></p><p></p><p>数智化底座建设成为了企业数智化转型成功与否的充分且必要条件，其有利于发挥新技术变革带来的全新影响力，激活企业新的生产潜能，将技术与业务实现真正的有效融合，驱动业务创新和管理升级，助力企业数智化转型和数智化业务的持续推进。同时，企业需要重视数智化底座的运营能力，将数智化实践的成果进行沉淀，并以持续迭代的形式对数智化能力体系进行拓展和升级，支撑企业长期、可持续的商业创新活动。用友iuap平台通过基于领先技术的数智化工程与可持续运营两大体系，助力更多企业数智化走向成功！</p><p></p><p></p><h2>往期回顾</h2><p></p><p></p><p><a href=\"https://www.infoq.cn/article/FrR3xm21zRTfZYHbufGA?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">企业数智化进阶模型，大型企业实现数智融合的成功之“道”_AI_郑思宇_InfoQ精选文章</a>\"</p><p></p><p><a href=\"https://www.infoq.cn/article/g9qvqGMWf3LuZwbsOIuz?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">AI 浪潮下，搞懂业务逻辑是数智平台的关键能力_用友_郑思宇_InfoQ精选文章</a>\"</p><p></p><p><a href=\"https://www.infoq.cn/article/40hZdeAGQyD7AJGthtZy?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">企业服务大模型能否成为智能化时代的“操作系统”？_用友_郑思宇_InfoQ精选文章</a>\"</p><p></p>",
    "publish_time": "2024-01-04 16:08:07",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]