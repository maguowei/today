[
  {
    "title": "MIT发布网络安全零信任调查报告：零信任不是你想开就能开",
    "url": "https://www.infoq.cn/article/yxRL3v4LfwTEGBBujpTI",
    "summary": "<p>今年早些时候，<a href=\"https://www.technologyreview.com/\">MIT Technology Review</a>\"做了一项调查，向全球商业领袖了解了他们当前对于网络安全的担忧和未来计划。今年的报告涉及256名受访者，其中70%是高管或董事。2022年9月19日，MIT Technology Review发布了他们的研究结果：<a href=\"https://www.technologyreview.com/2022/09/19/1059250/zero-trust-closes-the-end-user-gap-in-cybersecurity/\">零信任消除了终端用户在网络安全方面的差距</a>\"。</p><p>&nbsp;</p><p>本报告聚焦于网络安全方法，主要说明了组织如何采用密码之外的新方法来防御网络攻击。</p><p>&nbsp;</p><p>一般来说，网络罪犯都是从钓鱼邮件入手攻击终端用户的系统。具体来说，68%的受访者担心云应用程序和数据会遭到恶意软件、勒索软件和钓鱼攻击。该报告还发现，55%的受访者表示，企业面临的第一大网络安全挑战是如何在混合办公或完全远程办公环境下确保安全。其原因是新冠肺炎让云计算成了焦点：封锁让数百万人回到家中，他们在家中远程连接到公司系统，通常是使用个人设备，而不是雇主提供的设备。他们面临的第二大和第三大挑战分别是保护云基础设施免受攻击和保护企业IT软件免受攻击，持此看法的受访者分别有49%和48%。</p><p>&nbsp;</p><p>为了确保云在新冠肺炎期间免受日益猖獗的网络犯罪的影响，零信任网络安全理念是改造全球网络的关键。如果没有自己属于那里的证明，那么这些网络、网站或应用程序就不允许你访问（或留在那里），而且它们会监控意外行为。一个关键的发现是，大约40%的受访者采用了零信任模型，另有18%的受访者正在实施，17%的受访者正在规划。</p><p>&nbsp;</p><p>至于不同组织的零信任采用之路，报告发现，大约46%的受访者认为，最大的挑战是将模型集成到遗留的IT基础设施中，或者用兼容零信任的系统替换旧系统。Molina Healthcare首席安全官Mike Wilson也表示：</p><p>&nbsp;</p><p></p><blockquote>零信任不是一个你想打开就打开的开关，而是在本地对数据进行控制的一种理念。</blockquote><p></p><p>&nbsp;</p><p>好消息是，零信任不是一个全有或全无的问题，而是可以根据组织最需要保护的资产来逐步采用。一个成功的零信任策略需要所有供应商协同工作，以确保他们负责的应用程序或领域的访问安全。有些遗留系统可能无法立即适应零信任方法，但可以预见，针对核心系统的零信任策略会增加组织在IT和人员方面的投资。将有越来越多的组织在网络安全项目中小规模地构建零信任模型。</p><p>&nbsp;</p><p>感兴趣的读者可以从MIT Technology Review Insights<a href=\"https://bit.ly/3Lq84q8\">下载报告全文</a>\"。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/10/zero-trust-cybersecurity/\">https://www.infoq.com/news/2022/10/zero-trust-cybersecurity/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/R4ZfdijOEfQqg9muFlGS\">零信任对 Kubernetes 意味着什么？</a>\"</p><p><a href=\"https://www.infoq.cn/article/cyp8cGxllDNxd6Zl3jbr\">开发人员应该知道的零信任模型</a>\"</p><p><a href=\"https://www.infoq.cn/article/ZUxMqUtEtQYLvBVc9fTX\">如何使用零信任安全技术对抗内外威胁</a>\"</p>",
    "publish_time": "2022-11-01 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "数字化转型第一步，“低代码”搭建更靠谱",
    "url": "https://www.infoq.cn/article/xGW24pPCBvCSOMbjeVRY",
    "summary": "<p>“腾讯云中小企业在线学堂”之腾讯云低代码公开课。鹅厂专家讲师直播授课，教您如何利用「低代码」开发实现自身企业的“数字化转型”！<br />\n“中小企业在线学堂”围绕中小企业业务需求，聚焦企业经营管理、应用工具、技术创新、安全底座 4 大需求场景，推出系列直播课程，全面助力中小企业数字化升级。</p>\n<p><img alt=\"\" src=\"https://static001.infoq.cn/resource/image/2d/ce/2d71c30ee6334902679dyy526d93dcce.jpg\" /></p>",
    "publish_time": "2022-11-01 10:23:38",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Kubernetes的未来：OIDC要优于Secret，Ingress并不合适",
    "url": "https://www.infoq.cn/article/zFR1q0chGl6SwFd1QMiD",
    "summary": "<p>本文最初发表于<a href=\"https://www.eficode.com/blog/the-future-of-kubernetes-and-why-developers-should-look-beyond-kubernetes-in-2022\">eficode的博客站点</a>\"，经原作者<a href=\"https://www.linkedin.com/in/michaelvlarsen/\">Michael Vittrup Larsen</a>\"和eficode官方授权，由InfoQ中文站翻译分享。</p><p></p><p>Kubernetes在容器编排中无处不在，其受欢迎的程度依然没有减弱。但是，这并不意味着容器编排领域的演进处于停滞状态。本文将会提出一些观点，那就是为什么Kubernetes的用户，尤其是开发人员，应该超越我们过去几年里学习的传统Kubernetes，转而采用更适合云原生应用的范式。</p><p></p><h2>Kubernetes的兴起</h2><p></p><p></p><p><a href=\"https://www.eficode.com/solutions/kubernetes?hsLang=en\">Kubernetes</a>\"变得如此流行的原因之一就是它构建在Docker之上。在Linux和BSD变种中，容器有着很悠久的历史，然而，Docker通过专注用户体验，使容器的构建和运行变得非常容易，从而使容器变得流行了起来。Kubernetes建立在容器流行的基础之上，使得在计算机节点组成的集群上运行（又叫编排）容器变得非常容易。</p><p></p><p>Kubernetes流行和广泛采用的另外一个原因是它并没有过多改变软件运行的模式。从Kubernetes出现之前运行软件的方式到基于Kubernetes运行软件之间，设想一条发展路径是非常容易的。</p><p></p><h2>我们无法教老范式学习新的技巧</h2><p></p><p></p><p>构建容器镜像以冻结依赖，提供“到处可运行”的体验，再结合Kubernetes&nbsp;<a href=\"https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/deployment-v1/\">Deployment</a>\"资源规范来管理容器副本的编排，这一套实践的功能是非常强大的。但是，它与我们在Docker和Kubernetes出现之前，操作虚拟机的方式并没有根本性的差异。这个很小的思维转变使我们很容易就能使用Kubernetes，这也是为何我们应该超越目前“传统”Kubernetes的原因。</p><p></p><p>本文将会从开发人员的角度展望Kubernetes的未来。概括来讲，我们现在熟知的Kubernetes将会消失，而开发人员并不会在意。这并不是说，Kubernetes不会出现在我们的技术栈中，而是我们会使用新的抽象来改善构建和运维应用的方式，这些新的抽象本身就是构建在Kubernetes之上的。应用会使用平台来构建，平台则基于Kubernetes来构建：</p><p></p><p><img src=\"https://www.eficode.com/hs-fs/hubfs/Screen%20Shot%202022-02-22%20at%201-40-58%20PM-png.png?width=2376&amp;name=Screen%20Shot%202022-02-22%20at%201-40-58%20PM-png.png\" /></p><p></p><p>有意思的是，在十多年以前，Linux是我们构建一切的平台。Linux依然无处不在，是我们技术栈的一部分，但是很少有开发人员关注它，因为我们基于它添加了一些抽象。我们今天所熟知的传统Kubernetes也会面临这样的情况。</p><p></p><h2>横扫一切的新范式</h2><p></p><p></p><h3>安全性：OIDC要优于Secret</h3><p></p><p></p><p>Kubernetes提供了<a href=\"https://kubernetes.io/docs/reference/kubernetes-api/config-and-storage-resources/secret-v1/\">Secret</a>\"资源来声明静态的secret，比如API秘钥、密码等。开发人员不应该再使用Secret资源了。</p><p></p><p>在Secret资源中，简单编码的secret可能会被泄露，而且密码的轮换和撤销也很困难。在GitOps工作流中，secret也需要特别注意，避免明文存储。应用应该使用基于角色的方式来进行认证和授权。这意味着，应用程序的认证和授权应该基于“我们是谁”，而不是“你知道什么（密码、API秘钥）”来进行。</p><p></p><p>强大的身份标识是所有安全性的基础。如果你不确定与你通信的服务器的身份，那么对网络流量进行加密是没有意义的。这就是证书和证书授权机构对HTTPS流量所发挥的作用，它保证了互联网的安全。</p><p></p><p>Kubernetes有一个强大的工作负载身份系统。所有工作负载都与服务账户（service account）相关联，它们拥有<a href=\"https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/#service-account-token-volume-projection\">Kubernetes颁发的短暂有效的OpenID-Connect（OIDC）身份token</a>\"。Kubernetes API服务器签发这些OIDC token，而其他工作负载可以通过Kubernetes API服务器验证token。这为在Kubernetes上运行的工作负载提供了强大的身份识别功能，可以作为基于角色的认证和授权的基础。</p><p></p><p>开发人员不应再使用Kubernetes Secret，而应基于OIDC token构建认证和授权。这意味着，我们不应在Secret资源中存储数据库密码，而应该确保我们的数据库只在收到有效的、未过期的token时才接受请求。</p><p></p><p>使用OIDC token与外部系统集成的例子是<a href=\"https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts.html\">AWS IAM用于服务账户的角色</a>\"和<a href=\"https://www.vaultproject.io/docs/auth/kubernetes\">Hashicorp Vault Kubernetes auth</a>\"。</p><p></p><h2>网络：Ingress并不合适</h2><p></p><p></p><p>Kubernetes提供了一个<a href=\"https://kubernetes.io/docs/concepts/services-networking/ingress/\">Ingress</a>\"资源，以指定如何将HTTP流量路由到工作负载中。正如Tim Hockin（Kubernetes联合创始人）所承认的那样，<a href=\"https://kubernetespodcast.com/episode/041-ingress/\">Ingress资源有很多问题</a>\"。主要的问题是，它只允许我们管理HTTP流量路由中最基本的东西。对于基础设施和网站可靠性工程（SRE）团队来说，允许开发人员使用Ingress资源将是一个令人头疼的问题，他们需要将大量的基础设施互连，并确保它能可靠地运行。Ingress资源太简单了，开发人员不应该用它来配置网络。</p><p></p><p>从服务网格的兴起中，我们可以看到业界对Kubernetes网络有着更多控制和可编程性的需求。它们将Ingress资源划分为多个资源，以便于更好地分离职责，并在路由、可观测性、安全性和容错方面提供额外的功能。</p><p></p><p>越来越多建立在Kubernetes之上的抽象都假设有一个可编程的网络，这超出了Ingress所能提供的可能性（如Knative、Kubeflow，以及像Argo Rollouts这样的持续部署工具）。这凸显了在Kubernetes中更强大的网络模型已经是一个事实标准。</p><p></p><p>Kubernetes已经演进出了“Ingress v2”&nbsp;<a href=\"https://kubernetes.io/blog/2021/04/22/evolving-kubernetes-networking-with-the-gateway-api/\">网关-API</a>\"。虽然这解决了Ingress的一些问题，但是它只涵盖了大部分服务网格所能支持的一小部分特性。</p><p></p><p>Kubernetes支持ACL，用于限制哪些工作负载可以通过<a href=\"https://kubernetes.io/docs/reference/kubernetes-api/policy-resources/network-policy-v1/\">NetworkPolicy</a>\"资源进行通信。该资源在Kubernetes的网络插件中实现，通常会转化为Linux的iptables过滤规则，即基于IP地址的解决方案，很像防火墙，这也是一种古老的范式。一些服务网格扩展了Kubernetes强大的基于OIDC的工作负载身份标识，以实现工作负载之间的双向TLS。这基于比IP地址更强大的原则，为Kubernetes网络通信带来了保密性和真实性。</p><p></p><p>在Kubernetes应用打包时，在如何包含网络配置方面存在一些分歧。许多Helm charts都带有Ingress资源模板。然而，随着我们转向更高级的网络模型，这些定义将不能再使用。展望未来，像Helm charts这样的应用部署应该把网络配置看作是一个正交性的问题，不应该包含在应用部署制品（artifact）中。关于应用的网络配置，可能没有一个放之四海而皆准的解决方案，组织很可能希望开发自己的“应用路由”部署制品。</p><p></p><p>Kubernetes通过在集群中的所有节点上创建一个同质（homogeneous）的网络，使网络变得更加简单。如果你的应用是多集群或多云部署的，它可能同样受益于跨集群或云的同质网络。Kubernetes的网络模型并不能做到这一点，我们需要一些能力更强的方案，比如服务网格。</p><p></p><p>因此，从组织和架构的角度来看，有多个原因可以证明开发者不应该用Ingress资源对网络进行编程。必须以整体的组织视角来考虑这些方案，以确保以可管理和长期可行的方式进行网络配置和管理。</p><p></p><h2>工作负载定义：新的模式</h2><p></p><p></p><p>实际上，所有Kubernetes应用的核心都是<a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/deployment/\">Deployment</a>\"资源。Deployment资源定义了我们的工作负载应该如何以Pod内容器的形式来执行。</p><p></p><p>Deployment的扩展可以通过<a href=\"https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/horizontal-pod-autoscaler-v2/\">HorizontalPodAutoscaler（HPA）</a>\"资源来控制，以适应不同的容量需求。HPA通常使用容器的CPU负载作为增加或删除Pod的标准。由于HPA算法通常的目标利用率在70%左右，这意味着我们在设计时要浪费30%的资源。使用保守的目标利用率的另一个原因是，HPA经常需要一分钟或更长的响应时间才能开始工作。为了处理不同的容量需求，我们需要一些备用容量，与此同时HPA会增加更多的Pod。</p><p></p><p>如果我们的应用会经历缓慢变化的容量需求，用Deployments和HPA管理工作负载效果很好。然而，随着向微服务、事件驱动架构和函数（处理一个或多个事件/请求，然后终止）转变，这种形式的工作负载管理就不够理想了。</p><p></p><p><a href=\"https://keda.sh/\">Kubernetes Event-Driven Autocaler（KEDA）</a>\"可以改善微服务和快速变化的工作负载（如函数）的扩展行为。KEDA定义了一套自己的Kubernetes资源来定义扩展行为，可以视为“HPA v3”（因为HPA资源已经是“v2”版本了）。</p><p></p><p>有一个结合了Kubernetes Deployment模型、扩展以及事件和网络路由的框架，即<a href=\"https://knative.dev/docs/\">Knative</a>\"。 Knative是一个建立在Kubernetes之上的平台，通过<a href=\"https://knative.dev/docs/serving/\">Knative-Service</a>\"资源对工作负载进行有针对性的管理。Knative的核心是<a href=\"https://cloudevents.io/\">CloudEvents</a>\"，Knative服务基本上是由CloudEvents或普通HTTP请求等事件触发和扩展的函数。Knative使用Pod sidecar来监控事件发生率，因此在事件发生率变化时可以快速扩展。Knative还支持扩展到零（scaling to zero），因此允许更细粒度的工作负载扩展，更适合于微服务和函数。</p><p></p><p>Knative服务使用了传统的Kubernetes Deployment/Service，Knative服务的更新（例如，一个新的容器镜像）会创建并行的Kubernetes Deployment/Service资源。Knative利用这一点来实现蓝/绿和金丝雀部署模式，HTTP流量的路由是Knative服务资源定义的一部分。</p><p></p><p>因此，Knative服务资源及其定义事件路由的相关资源将成为开发者在Kubernetes上定义应用部署时所使用的主要资源。 就像我们今天经常通过Deployment资源与Kubernetes互动，让Kubernetes处理Pod一样，使用Knative意味着开发人员将主要关注Knative服务，而Deployment则由Knative平台处理。</p><p></p><p>虽然我希望Knative模型能适合大多数的使用场景，但你的场景可能会有所不同。如果你是做机器学习的，那么<a href=\"https://knative.dev/docs/serving/\">Kubeflow</a>\"可能是更好的抽象。如果你更专注于DevOps和交付流水线，那么<a href=\"https://github.com/pivotal/kpack\">kpack</a>\"、<a href=\"https://tekton.dev/\">Tekton</a>\"或<a href=\"https://cartographer.sh/\">Cartographer</a>\"可能是适合你的抽象形式。无论你在Kubernetes上做什么，都有相应的抽象。</p><p></p><h2>存储：远离持久化卷</h2><p></p><p></p><p>Kubernetes提供了<a href=\"https://kubernetes.io/docs/reference/kubernetes-api/config-and-storage-resources/persistent-volume-v1/\">PersistentVolume</a>\"和<a href=\"https://kubernetes.io/docs/reference/kubernetes-api/config-and-storage-resources/persistent-volume-claim-v1/\">PersistentVolumeClaim</a>\"资源来管理工作负载的存储问题。这可能是我最不喜欢的资源了，除了短暂的缓存数据外，它允许开发人员将其用于任何目的。</p><p></p><p>从高层次的角度来看，PersistentVolume（PV）的问题在于，它将应用程序的主要关注点与存储问题结合在了一起，这不是一个理想的云原生设计模式。<a href=\"https://12factor.net/\">12-factors应用方法论</a>\"告诉我们要将所有<a href=\"https://12factor.net/backing-services\">支撑服务</a>\"视为网络附加资源。这要归因于我们在Kubernetes中水平扩展工作负载和管理数据的方式（请想一下<a href=\"https://en.wikipedia.org/wiki/CAP_theorem\">CAP理论</a>\"）。</p><p></p><p>PV代表了文件和目录的文件系统，我们用POSIX文件系统接口对数据进行操作。访问权限也是基于POSIX模型的，允许通过用户和组进行读/写访问控制。这种模式不仅与云原生应用的设计不匹配，而且在实际使用中也有很多的问题，这意味着大多数情况下，PV是以“容器可以访问所有数据”的模式mount的。</p><p></p><p>开发人员构建的有状态应用其实应该是无状态的。这意味着数据应该在应用外部进行处理，使用除文件系统外的其他抽象形式，如数据库或<a href=\"https://en.wikipedia.org/wiki/Object_storage\">对象存储</a>\"。数据库和对象存储应用可以使用PV来满足其存储需求，但这些系统应该由基础设施/SRE团队来管理，并由开发人员以服务的形式进行消费。</p><p></p><p>当我们将存储视为网络附加资源时，数据安全问题就可能得到极大的改善，例如，我们可以考虑通过REST API进行对象存储。借助REST API的形式，我们就可以通过上述基于Kubernetes工作负载身份标识的短期访问token实现认证和授权。</p><p></p><p>随着Serverless工作负载模式的不断采用，我们应该预期出现更多的动态和更短生命周期的工作负载（例如，Serverless函数处理每个Pod的一个事件）。在这种情况下，工作负载和“老式磁盘”之间的不匹配变得更加明显。</p><p></p><p>在Kubernetes中，容器存储接口（container storage interface，CSI）一直是通过PV向工作负载添加文件系统和块存储的接口。Kubernetes对象存储特别兴趣小组正在研究<a href=\"https://container-object-storage-interface.github.io/\">容器对象存储接口（COSI）</a>\"，这可能会使对象存储成为Kubernetes中的一等公民。</p><p></p><h2>美好的新世界</h2><p></p><p></p><p>在本文中，我认为在定义Kubernetes应用时，有充分的理由超越“传统”的Kubernetes资源。这并不是说，我们永远都不会使用传统的资源类型。仍然会有一些我们无法轻易转换的遗留应用，SRE团队可能仍然需要运行有状态的服务，这些服务会被开发人员构建的应用所消费。对于私有云基础设施来说，情况更是如此。</p><p></p><p>Kubernetes的未来在于<a href=\"https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/\">自定义资源定义（custom resource definition，CRD）</a>\"和抽象，我们会在Kubernetes之上构建它们，并通过CRD提供给用户。Kubernetes会成为抽象的控制平面，而开发人员应该关注的正是这些抽象的CRD。Kubernetes控制平面可以管理Kubernetes内部的资源，甚至是Kubernetes外部的资源，例如<a href=\"https://www.eficode.com/blog/outgrowing-terraform-and-adopting-control-planes?hsLang=en\">Crossplane管理云基础设施</a>\"。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ca/caa5b16d3beb276ca367329c5ceb8ba8.png\" /></p><p></p><p>正如上面所总结的，大多数传统的Kubernetes资源对开发人员来说可能有更好的替代方案。使用这些替代方案将改善我们在未来几年内开发和运维云原生应用程序的方式。毕竟，Kubernetes是一个构建平台的平台。它并不是终点!</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/minibook/IDAGRlr1RAeLg8l6sZTy\">Kubernetes 安全防护终极指南</a>\"</p><p><a href=\"https://www.infoq.cn/article/Yiqriipkfzw1gBBdyzUl\">Crossplane支持的自定义资源数量突破了Kubernetes的限制</a>\"</p>",
    "publish_time": "2022-11-01 10:36:48",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "突发！图森未来CEO侯晓迪被免职",
    "url": "https://www.infoq.cn/article/TNhKEhLjafw3VzV3Hj4C",
    "summary": "<p></p><p></p><blockquote>图森未来的“未来”将向何处去？</blockquote><p></p><p></p><h2>图森未来宣布解除CEO侯晓迪职务</h2><p></p><p></p><p>美国当地时间10月30日晚间，无人驾驶卡车公司图森未来（ TuSimple ）解雇了公司首席执行官兼联合创始人侯晓迪。</p><p></p><p>TuSimple 宣布，公司董事会已终止公司首席执行官、总裁兼首席技术官侯晓迪博士的职务。自 2022 年 10 月 30 日起，侯博士不再担任董事会主席和政府安全委员会成员。</p><p></p><p>TuSimple已在寻找新的有相关经验的CEO人选。公司宣布，TuSimple 的运营执行副总裁 Ersin Yumer 博士已同意在高管寻访期间担任公司临时首席执行官兼总裁。公司首席独立董事Brad Buss将担任董事会主席。</p><p></p><p>官方资料显示，Ersin Yumer 曾在 TuSimple 的算法和机器学习团队担任领导职务，这让他对与TuSimple 商业化相关的运营需求有独特的见解。Yumer 博士是国际公认的可扩展机器学习、3D 计算机视觉和模拟方面的专家。他是自动驾驶汽车行业的资深人士，曾在 Aurora、Uber 和 Argo AI 担任过领导职务。在机器学习和计算机视觉领域，Yumer 博士发表了大量经过同行评审的技术出版物和专利。他拥有博士学位。来自卡内基梅隆大学，在其职业生涯早期曾在 Adob​​e 和 Google 从事尖端 3D 计算机视觉应用程序的工作。</p><p></p><p>TuSimple 在一封电子邮件声明中表示，“（公司）一致认为终止侯晓迪的职务是必要的，并且符合股东的最佳利益”。“从根本上说，我们对侯博士的判断力、决策力以及作为 CEO 领导公司的能力失去了信任和信心。这一决定是与我们董事会审计委员会于 7 月发起的一项正在进行的调查有关，独立于任何媒体报道，董事会得出的调查结论认为有必要更换首席执行官”。</p><p></p><p>不久前，有报道称，侯晓迪因涉及向一家中国初创公司Hydron Inc不当融资和转让技术而受到调查。据<a href=\"https://www.wsj.com/articles/tusimple-probed-by-fbi-sec-over-its-ties-to-a-chinese-startup-11667159325?mod=business_lead_pos3\">华尔街日报</a>\"报道，美国FBI、证券交易委员会和美国外国投资委员会（简称 CFIUS）对TuSimple和Hydron Inc. 的关系展开了调查。</p><p></p><p>2022年6月10日，图森未来联合创始人兼前执行董事长陈默宣布，将创立专注于研发、设计、制造和销售可搭载 L4 级别自动驾驶功能的氢燃料重卡及加氢基础设施服务的新公司“HYDRON”。</p><p></p><p>陈默认为，“自动驾驶汽车的商业化道路需要硬件和软件的复杂集成，将自动驾驶大规模推向市场的最大挑战不是软件开发，而是获得可靠的量产硬件，成立 Hydron的目的，就是希望能够提供专门用于自动驾驶网络的汽车级硬件。”</p><p></p><p>Hydron 计划与合作伙伴合作，在北美建立制造工厂，制造氢动力卡车，以更好地应对美国供应链的挑战。第一代Hydron卡车预计将于2024年第三季度量产，配备完整的传感器、计算单元和冗余执行器，以满足L4级自动驾驶要求。</p><p></p><p>在当时的公司成立声明中，陈默还特别对Hydron 和 TuSimple的关系做了说明。“Hydron 是一家私人控股的独立公司，不隶属于 TuSimple”。</p><p></p><p>但根据最新的调查，一位匿名发言人士称，令人担忧的是，包括侯晓迪在内的高管未能正确披露与 Hydron 的关系，这可能违反了信托义务和证券法。报告称，调查人员还在调查 TuSimple 是否与在中国开展业务的公司 Hydron 共享其在美国开发的自动驾驶技术，这是否违反了美国的规定。他们还在调查TuSimple是否与在美国开发的 Hydron IP 共享，并以此欺骗投资者。</p><p></p><p>关于上述调查结论，侯晓迪否认有任何不当行为。</p><p></p><p>10月31日，候晓迪在<a href=\"https://www.linkedin.com/posts/xiaodihou_i-am-sharing-the-letter-i-sent-to-the-tusimple-activity-6992875047451262976-oD0C/\">LinkedIn 帖子</a>\"发布了他当天早上发给TuSimple团队的信，信中称，“令人遗憾的是，10月30日，公司董事会无故投票并决定免去我的CEO兼董事会主席一职。董事会的操作流程和结论都令人怀疑，随着真相逐渐大白，相信我在CEO和董事会主席任上做出的种种决策、以及我们为TuSimple设定的发展目标，都将得到证明和理解”。</p><p></p><p>“我的职业发展与个人生活都是完全透明的，而且与董事会充分合作，对此我没有丝毫需要隐瞒之处。这里我想强调一点，我不接受任何关于我本人存在不当行为的指责”。</p><p></p><p>候晓迪谈到，“我知道，我的领导风格可能比较严苛，那是因为自动驾驶本身就是一项艰巨的任务，需要每个人坚定不移地践行承诺。但很遗憾，那些不了解自动驾驶复杂性的人们大大低估了我们一同完成的工作、特别是在此过程中承受的牺牲。因为政治理由而阻碍我们共同追求的这个伟大理想，真的很不公平”。</p><p></p><p>受此消息影响，TuSimple 股价暴跌，TuSimple 的股价周一在纳斯达克交易中暴跌 46%，收于 3.43 美元。</p><p></p><h2>2022年第三季度运营亏损1.12亿美元，研发支出8570万美元</h2><p></p><p>10月31日，TuSimple 发布的2022年第三季度财报显示，TuSimple截至 9 月 30 日的第三季度收入为 270 万美元，较上年同期增长2% ，但低于分析师预期的 320 万美元。</p><p></p><p>图森未来2022年第三季度研发支出为8570万美元，运营亏损为1.12亿美元，经调整EBITDA亏损为9360万美元。</p><p></p><p>截至2022年9月30日，图森未来持有现金、现金等价物、受限制现金为8.73亿美元，上年同期持有的现金、现金等价物、受限制现金为14.14亿美元。</p><p></p><p>临时首席执行官 Ersin Yumer 表示，“我们将继续在德克萨斯州扩建 AFN（自主货运网络） ，我对这一过程中面临的机会感到兴奋。对于我们整个团队来说，我预计 2023 年对于 TuSimple 来说将是重要的一年。我很高兴能在这个关键时刻帮助领导公司，并期待与董事会和管理层密切合作，继续履行我们的使命，提供可靠、低成本的货运能力，同时为燃油效率和安全设定新标准。 ”</p><p></p><p>在图森未来2022 年第三季度财报电话会议上，宣布了以下核心事项：</p><p></p><p>宣布高层领导变动继续关注安全，宣布第三方审核在德克萨斯州扩建 AFN为欧洲首个完全自主的商业货物运输提供动力继续升级卡车的硬件以提高可靠性扩大Tucson业务，提高卡车升级能力以及设计和测试专有组件结合测试和收入车队，提供一种有凝聚力的运营模式本季度自动驾驶里程超过 900 万英里，这是行业的另一个重要里程碑</p><p></p><h2>创业梦想戛然而止？</h2><p></p><p></p><p>图森未来于 2015 年由陈默、候晓迪和赫佳男联合创立，公司主营业务为提供无人驾驶卡车货运服务。专注于为长途重卡开发 L4 级别无人驾驶解决方案，其业务分布于中国、美国、日本和欧洲。</p><p></p><p>图森未来自成立伊始就深受资本的青睐，完成多轮融资，得到了包括治平资本、英伟达、复合资本、鼎晖投资、云九资本、Navistar、Traton、万都、UPS 等诸多财务投资方和战略投资方的支持。</p><p></p><p>2021年4 月，图森未来通过在纳斯达克的首次公开募股筹集了超过 10 亿美元，成为自动驾驶领域全球首个 IPO。</p><p></p><p>该公司在其年度报告中表示，它运营着大约 100 辆能够运行的 L4 级自动驾驶半卡车——其中 75 辆在美国，25 辆在中国。这些自动驾驶卡车能够在某些路线上独立行驶无需人类司机。</p><p></p><p>2021 年 12 月，TuSimple 完成全球首次无人驾驶重卡公开道路全无人测试，全程未配备驾驶员、无驾驶员接管、无远程驾驶员控制，巩固了其在人工智能自动驾驶卡车软件开发领域的领先地位。</p><p></p><p>候晓迪在信中回顾了自己的创业心路历程，“2015年，当我在只有区区65平米的办公室里创办TuSimple时，就抱有把它发展成借自动驾驶之力、从根本上颠覆整个货运行业的雄心。大家之所以加入TuSimple，是因为你们也相信这个梦想。我们为之努力，我也为各位的奋斗而感到无比自豪”，“驱动我一路前行的，就是对这个远大理想的不断追求”。</p><p></p><p>而如今，这一梦想或将戛然而止。</p><p></p><p>另一个不得不正视的现实是，候晓迪下台之际，正值当下自动驾驶公司的前景不太明朗。推动汽车自动化以及在无人驾驶的情况下安全运行越来越成为一项代价高昂且长期的挑战。</p><p></p><p>就在几天前，由谷歌和优步自动驾驶汽车项目的资深人士创立的自动驾驶公司 Argo AI 失去了福特和大众的财务支持。Argo AI 成立6年来，吸金200多亿元。目前，这家自动驾驶汽车初创公司即将关停，部分业务将被两大主要出资方福特和大众所吸纳。其结局不胜唏嘘。事实证明，自动驾驶技术的商业化应用远比预期困难得多。</p><p></p><h2>附：候晓迪给TuSimple团队的信全文</h2><p></p><p></p><p>以下公布（该声明在候晓迪的领英公布）的是我今早发给TuSimple团队的信，借此回应公司董事会采取的可疑行动。</p><p></p><p>大家好，</p><p></p><p>2015年，当我在只有区区65平米的办公室里创办TuSimple时，就抱有把它发展成借自动驾驶之力、从根本上颠覆整个货运行业的雄心。大家之所以加入TuSimple，是因为你们也相信这个梦想。我们为之努力，我也为各位的奋斗而感到无比自豪。</p><p></p><p>驱动我一路前行的，就是对这个远大理想的不断追求。但令人遗憾的是，10月30日，公司董事会无故投票并决定免去我的CEO兼董事会主席一职。董事会的操作流程和结论都令人怀疑，随着真相逐渐大白，相信我在CEO和董事会主席任上做出的种种决策、以及我们为TuSimple设定的发展目标，都将得到证明和理解。</p><p></p><p>我的职业发展与个人生活都是完全透明的，而且与董事会充分合作，对此我没有丝毫需要隐瞒之处。这里我想强调一点，我不接受任何关于我本人存在不当行为的指责。</p><p></p><p>我知道，我的领导风格可能比较严苛，那是因为自动驾驶本身就是一项艰巨的任务，需要每个人坚定不移地践行承诺。这里我很感激各位在研发工作中做出的贡献。但很遗憾，那些不了解自动驾驶复杂性的人们大大低估了我们一同完成的工作、特别是在此过程中承受的牺牲。因为政治理由而阻碍我们共同追求的这个伟大理想，真的很不公平。</p><p></p><p>有些人想让我们TuSimple就老老实实当一家技术提供商，但我认为大家要勇于更进一步。自动驾驶具备从根本上改变社会的潜力，这是一片不进则退的残酷战场。正因为如此，我才对我们的长期价值抱有坚定信心，没有出售我在公司的任何股份。只要还有能力维持自己的家庭，我就不会选择这种变现方式。</p><p></p><p>说起家庭，TuSimple是我的珍宝。就像每一位父母那样，我对TuSimple有着无穷无尽、不设前提的热爱。我愿意不惜任何个人代价帮助公司取得成功，包括我的身体健康和陪伴亲朋好友的时间。我可以问心无愧地说，我一直以诚信行事，也始终以TuSimple的最大利益为先。</p><p></p><p>我对现任领导团队充满信心。更重要的是，作为一名TuSimple员工，大家的信念也将在这段充满挑战的时期成为最可靠的精神支柱。</p><p></p><p>无论我担任的是联合创始人、CTO、总裁、B类股东、CEO、董事会主席，抑或是现在的董事会董事，我仍然是大家熟悉的那个爱穿黄鞋的侯小迪。我会一如既往支持TuSimple，矢志不渝。</p><p></p><p>感谢</p><p></p><p>晓迪</p><p></p><p>参考链接：</p><p></p><p><a href=\"https://seekingalpha.com/pr/18996967-tusimple-announces-termination-of-chief-executive-officer-and-initiation-of-search-for-new\">https://seekingalpha.com/pr/18996967-tusimple-announces-termination-of-chief-executive-officer-and-initiation-of-search-for-new</a>\"</p><p></p><p><a href=\"https://www.linkedin.com/posts/xiaodihou_i-am-sharing-the-letter-i-sent-to-the-tusimple-activity-6992875047451262976-oD0C/\">https://www.linkedin.com/posts/xiaodihou_i-am-sharing-the-letter-i-sent-to-the-tusimple-activity-6992875047451262976-oD0C/</a>\"</p><p></p><p><a href=\"https://www.prnewswire.com/news-releases/tusimple-co-founder-mo-chen-launches-hydron-producing-hydrogen-powered-autonomous-ready-freight-trucks-301565500.html\">https://www.prnewswire.com/news-releases/tusimple-co-founder-mo-chen-launches-hydron-producing-hydrogen-powered-autonomous-ready-freight-trucks-301565500.html</a>\"</p><p></p>",
    "publish_time": "2022-11-01 11:20:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "PostgresML比Python HTTP微服务快8-40倍",
    "url": "https://www.infoq.cn/article/Gx3iPSezRCcgSLR7rARJ",
    "summary": "<p></p><p>机器学习架构可能是现代系统中最复杂、最昂贵和最困难的领域了。技术的数量和所需硬件的数量都在为缩减人员、托管和延迟预算而竞争。不幸的是，随着以数据仓库、微服务和NoSQL数据库为中心的最先进的架构使用量的不断增加，该行业的趋势在这些方面只会变得更加糟糕。</p><p></p><p>针对这种不断增长的复杂性，PostgresML是一种更简单的替代方案。在本文中，我们探讨了更优雅的架构的一些额外性能优势，并发现PostgresML在本地测试中比传统的Python微服务的性能高出了8倍，在AWS EC2上则高出了40倍。</p><p></p><h2>候选架构</h2><p></p><p>考虑到Python微服务的所有可能优势，我们的第一个基准测试是在同一台机器上运行Python和Redis。我们的目标是避免任何额外的网络延迟，这使得它与PostgresML的对比更加公平。我们的第二个测试是在AWS EC2上进行的，Redis和Gunicorn由网络分隔开；这个基准测试被证明是相对具有破坏性的。</p><p></p><p>这两个基准测试的完整源代码可以在<a href=\"https://github.com/postgresml/postgresml/tree/master/pgml-docs/docs/blog/benchmarks/python_microservices_vs_postgresml\">Github</a>\"上找到。</p><p></p><h3>PostgresML</h3><p></p><p>PostgresML架构由以下部分组成：</p><p></p><p>带有PostgresML v2.0的PostgreSQL服务器<a href=\"https://www.postgresql.org/docs/current/pgbench.html\">pgbench</a>\" SQL客户端</p><p></p><h3>Python</h3><p></p><p>Python架构由以下部分组成：</p><p></p><p>接受并返回JSON的Flask/Gunicorn服务器带有训练数据的CSV文件带有使用JSON序列化推理数据集的Redis特征存储<a href=\"https://httpd.apache.org/docs/2.4/programs/ab.html\">ab</a>\"&nbsp;HTTP客户端</p><p></p><h3>ML</h3><p></p><p>这两种架构都托管了相同的XGBoost模型，并针对相同的数据集运行预测。相关详细信息，请参阅<a href=\"https://postgresml.org/blog/postgresml-is-8x-faster-than-python-http-microservices/#ml_1\">方法论</a>\"部分。</p><p></p><h2>结果</h2><p></p><p></p><h3>吞吐量</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/b6/b62f3dd3ceaa54e45d43498cc878e179.png\" /></p><p></p><p>吞吐量（Throughput）被定义为架构每秒可以服务的XGBoost预测的数量。在这个基准测试中，PostgresML的性能比运行在同一台机器上的Python和Redis要高8倍。</p><p></p><p>在Python中，大部分瓶颈来自于必须获取并反序列化Redis数据。由于这些特征是在外部存储的，因此它们需要通过Python传递到XGBoost中。XGBoost本身是用C++编写的，它的Python库只提供了一个便利的接口。来自XGBoost的预测必须再次通过Python，序列化为JSON，并通过HTTP发送到客户端。</p><p></p><p>这几乎是你可以为推理微服务所能做的最低限度的工作了。</p><p></p><p>另一方面，PostgresML对数据和计算进行了配置。它从Postgres表中获取数据，该表已经采用了标准浮点格式，Rust推理层通过指针将其转发给XGBoost。</p><p></p><p>当基准测试达到20个客户端时，发生了一件有趣的事情：PostgresML的吞吐量开始快速下降。这可能会让一些人感到惊讶，但对于Postgres的爱好者来说，这是一个已知问题：Postgres并不擅长处理比CPU线程更多的并发活动连接。为了缓解这一问题，我们在数据库之前引入了PgBouncer（一个Postgres代理和池化器），吞吐量也随之增加了，并且在达到100个客户端时继续保持不变。</p><p></p><p>值得注意的是，基准测试机只有16个可用CPU线程（8核）。如果有更多的内核可用，瓶颈只会在有更多的客户端时出现。Postgres服务器的一般建议是为每个可用CPU内核打开大约2个连接，尽管较新版本的PostgreSQL已经逐渐消除了这一限制。</p><p></p><h4>为什么吞吐量很重要</h4><p></p><p>吞吐量能让你事半功倍，用更少的资源做更多的事情。如果你能够使用一台机器每秒处理30000个查询，但现在只使用1000个查询，那么你不太可能需要在短时间内进行升级。另一方面，如果系统只能处理5000个请求，那么在不久的将来，你将会进行一项昂贵且可能会是压力很大的升级。</p><p></p><h3>延迟</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/31/31eaf55dd3bc05ac1d96b0ef26faa5f4.png\" /></p><p></p><p>延迟（Latency）被定义为返回单个XGBoost预测所需的时间。由于大多数系统的资源是有限的，吞吐量直接影响延迟（反之亦然）。如果有许多活动请求，则在队列中等待的客户端就需要更长的时间才能得到服务，并且整体系统延迟会增加。</p><p></p><p>在这个基准测试中，PostgresML的表现也比Python好8倍。你会注意到，同样的问题在有20个客户端时也会发生，使用PgBouncer进行相同的缓解措施会减少其影响。与此同时，Python的延迟继续大幅增加。</p><p></p><p>在描述架构的性能时，延迟是一个很好的度量指标。换句话说，如果我要使用这项服务，我最多会只能在这么长的时间内得到一个预测，而不管还有多少其他客户也正在使用它。</p><p></p><h4>为什么延迟很重要</h4><p></p><p>延迟在机器学习服务中很重要，因为它们通常作为主应用程序的附加部分来运行，有时必须在同一HTTP请求期间多次访问。</p><p></p><p>让我们以电子商务网站为例。典型的店面希望同时展示多个个性化模型。这类模型的示例可能包括针对重复购买的“再次购买”建议（二分分类），或“你所在地区的热门商品”（购买历史的地理聚类）或“像你这样的客户还购买了该商品”（最近邻模型）。</p><p></p><p>所有这些模型都很重要，因为随着时间的推移，它们已被证明在推动购买方面非常成功。如果推理延迟很高，那么模型就会开始争夺非常昂贵的空间、头版和结算，而企业不得不放弃其中的一些，或者更有可能是遭受页面加载缓慢的影响。没有人喜欢在订购食品杂货或晚餐时使用运行缓慢的程序。</p><p></p><h3>内存利用率</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/2b/2bd9a4c396ac039d38445ab79b41ec6e.png\" /></p><p></p><p>众所周知，Python比其他更优化的语言使用更多的内存，在这种情况下，它使用的内存是PostgresML的7倍。</p><p></p><p>PostgresML是Postgres扩展，它与数据库服务器共享RAM。Postgres在只获取和分配它所需的内存方面非常高效：它重用 shared_buffers 和操作系统（OS）页面缓存来存储行以进行推理，并且只需要很少甚至根本不需要分配内存来服务查询。</p><p></p><p>同时，Python必须为它从Redis接收到的每个特征以及它返回的每个HTTP响应分配内存。这个基准测试并未测量Redis的内存利用率，这是运行传统机器学习微服务的额外成本，而且通常是相当大的成本。</p><p></p><h4>训练</h4><p></p><p><img src=\"https://static001.geekbang.org/infoq/27/27f03cd92bb7bd8999dd0b5e8c7e7ff1.png\" /></p><p></p><p>由于Python经常使用Pandas来加载和预处理数据，因此它尤其需要更多的内存。甚至在将数据传递到XGBoost之前，我们已经达到了8GB RSS（驻留集大小）；在实际的拟合过程中，内存利用率几乎达到了12GB。这个测试是Python的另一个最佳案例场景，因为数据已经被预处理过了，只是将其传递给了算法而已。</p><p></p><p>同时，PostresML喜欢与Postgres服务器共享RAM，只分配XGBoost所需的内存即可。数据集的大小非常大，但我们仅使用5GB的RAM就能成功地训练相同的模型。因此，在使用相同硬件的情况下，PostgresML允许的数据集上的训练模型至少是Python的两倍。</p><p></p><h4>为什么内存利用率很重要</h4><p></p><p>这是另一个事半功倍的例子。FAANG和研究型大学之外的大多数机器学习算法都要求数据集能够装入单个机器的内存中。分布式训练并不是我们所希望的，而且从简单的线性回归中仍然可以提取很多价值。</p><p></p><p>使用更少的RAM可以在更大、更完整的数据集上训练更大、更好的模型。如果你碰巧遭受了大量机器学习计算费用的困扰，那么在你的财年结束时，使用更少的RAM可能能给你带来惊喜。</p><p></p><h2>UltraJSON/MessagePack/Serializer X呢？</h2><p></p><p>我们花了很多时间来讨论序列化，因此回顾该领域之前的工作是有意义的。</p><p></p><p>JSON是对用户最友好的格式，但它肯定不是最快的。例如，MessagePack和Ultra JSON有时在读取和存储二进制信息方面更快、更高效。那么，在这个基准测试中使用它们会比使用Python的内置 json 模块更好吗？</p><p></p><p>答案是：并非如此。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f8/f8557af1c258c46da94a0802e5823194.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ba/baa5eb878203cd8bbfa15576647311c3.png\" /></p><p></p><p>（反）序列化的时间很重要，但首先最终需要进行（反）序列化就是瓶颈。从远程系统（例如Redis这样的特征存储）中取出数据，通过网络套接字发送数据，将其解析为Python对象（需要内存分配），然后再将其转换为XGBoost的二进制类型，这会在系统中造成不必要的延迟。</p><p></p><p>PostgresML对Postgres的特征进行了一次内存拷贝。没有网络，没有（反）序列化，没有不必要的延迟。</p><p></p><h2>现实情况如何呢？</h2><p></p><p>通过ocalhost进行测试很方便，但这不是最现实的基准测试。在生产部署中，客户端和服务器位于不同的机器上，而在Python+Redis架构中，特征存储又是在另一个网络跳转点上。</p><p></p><p>为了演示这一点，我们启动了3个EC2实例并再次运行基准测试。这一次，PostgresML比Python和Redis的表现要好40倍。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b7/b77a0c70a2811dc883c625b0041979c4.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/19/19ed49b2035a132d2df1613ea9aa6c7d.png\" /></p><p></p><p>Redis和Gunicorn之间的网络差距让事情变得非常非常糟糕……。从远程特征存储中获取数据增加了Python架构无法避免的请求毫秒数。在一个资源有限的系统中，额外的延迟造成了争用。大多数Gunicorn线程只是在网络上等待，成千上万的请求被卡在了队列中。</p><p></p><p>PostgresML没有这个问题，因为特征和Rust推理层位于同一个系统上。这种架构选择消除了等式中的网络延迟和（反）序列化。</p><p></p><p>你会注意到我们前面讨论的并发性问题在有20个连接时影响了Postgres，我们再次使用PgBouncer来挽救局面。一旦你知道了如何去做，扩展Postgres并不像听起来那么困难。</p><p></p><h2>方法论</h2><p></p><p></p><h3>硬件</h3><p></p><p>第一个基准测试中的客户端和服务器都位于同一台机器上。Redis也是本地的。该机器是一台8核、16线程的AMD Ryzen 7 5800X，配备了32GB RAM、1TB NVMe SSD，并运行有Ubuntu 22.04。</p><p></p><p>AWS EC2基准测试分别使用了一个托管了Gunicorn和PostgresML的c5.4xlarge 实例，以及两个 c5.5large 客户端和Redis实例。它们位于同一VPC中。</p><p></p><h3>配置</h3><p></p><p>Gunicorn运行时有5个进程（Worker），每个进程有2个线程（Thread）。Postgres分别为1个、5个和20个客户端使用1、5和20个连接。PgBouncer的 default_pool_size 设为10，因此20和100个客户端最多能使用10个Postgres连接。</p><p></p><p>XGBoost在推理过程中允许使用2个线程，在训练过程中使用所有可用的CPU内核（16个线程）。</p><p></p><p>ab 和 pgbench 都使用了所有的可用资源，但都是非常轻量级的；这些请求分别是单个JSON对象和单个查询。这两个客户端都使用了持久连接， ab 通过使用HTTP Keep-Alives实现， pgbench 则通过在基准测试期间一直保持Postgres连接打开。</p><p></p><h2>ML</h2><p></p><p></p><h3>数据</h3><p></p><p>我们使用了来自Kaggle的<a href=\"https://www.kaggle.com/datasets/robikscube/flight-delay-dataset-20182022\">飞行状态预测（ Flight Status Prediction ）</a>\"数据集。经过一些后置处理，它最终变成了大约2GB的浮点特征。我们并没有使用所有的列，因为其中一些列是多余的，例如机场名称和机场标识符，它们指的是同一个东西。</p><p></p><h3>模型</h3><p></p><p>我们的XGBoost模型使用默认超参和25个估计量（也称为增强轮）进行训练。</p><p></p><p>用于训练和推理的数据可在<a href=\"https://static.postgresml.org/benchmarks/flights.csv\">此处</a>\"获取。存储在Redis特征存储中数据可在<a href=\"https://static.postgresml.org/benchmarks/flights_sub.csv\">此处</a>\"获取。这只是一个子集，因为用单个Python进程（2800万行）将整个数据集加载到Redis需要花费数小时。与此同时，Postgres  COPY 只需要大约一分钟。</p><p></p><p>对PostgresML模型进行如下的训练：</p><p></p><p><code lang=\"plain\">SELECT * FROM pgml.train(\n    project_name =&gt; 'r2',\n    algorithm =&gt; 'xgboost',\n    hyperparams =&gt; '{ \"n_estimators\": 25 }'\n);\n</code></p><p></p><p>它的准确性很差（Python版本也是如此），可能是因为我们遗漏了任何类型的天气信息，后者最有可能会导致机场的延误。</p><p></p><h3>源代码</h3><p></p><p>基准源代码可以在<a href=\"https://github.com/postgresml/postgresml/tree/master/pgml-docs/docs/blog/benchmarks/python_microservices_vs_postgresml/\">Github</a>\"上找到。</p><p></p><h2>反馈</h2><p></p><p>非常感谢所有支持这一努力的人。我们希望听到来自更广泛的ML和工程社区关于应用程序和其他真实世界场景的反馈，以帮助我们确定工作的优先级。 你可以通过在我们的<a href=\"https://github.com/postgresml/postgresml\">Github</a>\"上为我们加注星标来表示你的支持。</p><p></p><p>项目 Github 地址：<a href=\"https://github.com/postgresml/postgresml\">https://github.com/postgresml/postgresml</a>\"</p><p></p><p>原文链接：</p><p><a href=\"https://postgresml.org/blog/postgresml-is-8x-faster-than-python-http-microservices/#throughput\">https://postgresml.org/blog/postgresml-is-8x-faster-than-python-http-microservices/#throughput</a>\"</p>",
    "publish_time": "2022-11-01 15:13:08",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]