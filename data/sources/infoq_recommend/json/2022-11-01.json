[
  {
    "title": "MIT发布网络安全零信任调查报告：零信任不是你想开就能开",
    "url": "https://www.infoq.cn/article/yxRL3v4LfwTEGBBujpTI",
    "summary": "<p>今年早些时候，<a href=\"https://www.technologyreview.com/\">MIT Technology Review</a>\"做了一项调查，向全球商业领袖了解了他们当前对于网络安全的担忧和未来计划。今年的报告涉及256名受访者，其中70%是高管或董事。2022年9月19日，MIT Technology Review发布了他们的研究结果：<a href=\"https://www.technologyreview.com/2022/09/19/1059250/zero-trust-closes-the-end-user-gap-in-cybersecurity/\">零信任消除了终端用户在网络安全方面的差距</a>\"。</p><p>&nbsp;</p><p>本报告聚焦于网络安全方法，主要说明了组织如何采用密码之外的新方法来防御网络攻击。</p><p>&nbsp;</p><p>一般来说，网络罪犯都是从钓鱼邮件入手攻击终端用户的系统。具体来说，68%的受访者担心云应用程序和数据会遭到恶意软件、勒索软件和钓鱼攻击。该报告还发现，55%的受访者表示，企业面临的第一大网络安全挑战是如何在混合办公或完全远程办公环境下确保安全。其原因是新冠肺炎让云计算成了焦点：封锁让数百万人回到家中，他们在家中远程连接到公司系统，通常是使用个人设备，而不是雇主提供的设备。他们面临的第二大和第三大挑战分别是保护云基础设施免受攻击和保护企业IT软件免受攻击，持此看法的受访者分别有49%和48%。</p><p>&nbsp;</p><p>为了确保云在新冠肺炎期间免受日益猖獗的网络犯罪的影响，零信任网络安全理念是改造全球网络的关键。如果没有自己属于那里的证明，那么这些网络、网站或应用程序就不允许你访问（或留在那里），而且它们会监控意外行为。一个关键的发现是，大约40%的受访者采用了零信任模型，另有18%的受访者正在实施，17%的受访者正在规划。</p><p>&nbsp;</p><p>至于不同组织的零信任采用之路，报告发现，大约46%的受访者认为，最大的挑战是将模型集成到遗留的IT基础设施中，或者用兼容零信任的系统替换旧系统。Molina Healthcare首席安全官Mike Wilson也表示：</p><p>&nbsp;</p><p></p><blockquote>零信任不是一个你想打开就打开的开关，而是在本地对数据进行控制的一种理念。</blockquote><p></p><p>&nbsp;</p><p>好消息是，零信任不是一个全有或全无的问题，而是可以根据组织最需要保护的资产来逐步采用。一个成功的零信任策略需要所有供应商协同工作，以确保他们负责的应用程序或领域的访问安全。有些遗留系统可能无法立即适应零信任方法，但可以预见，针对核心系统的零信任策略会增加组织在IT和人员方面的投资。将有越来越多的组织在网络安全项目中小规模地构建零信任模型。</p><p>&nbsp;</p><p>感兴趣的读者可以从MIT Technology Review Insights<a href=\"https://bit.ly/3Lq84q8\">下载报告全文</a>\"。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/10/zero-trust-cybersecurity/\">https://www.infoq.com/news/2022/10/zero-trust-cybersecurity/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/R4ZfdijOEfQqg9muFlGS\">零信任对 Kubernetes 意味着什么？</a>\"</p><p><a href=\"https://www.infoq.cn/article/cyp8cGxllDNxd6Zl3jbr\">开发人员应该知道的零信任模型</a>\"</p><p><a href=\"https://www.infoq.cn/article/ZUxMqUtEtQYLvBVc9fTX\">如何使用零信任安全技术对抗内外威胁</a>\"</p>",
    "publish_time": "2022-11-01 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "数字化转型第一步，“低代码”搭建更靠谱",
    "url": "https://www.infoq.cn/article/xGW24pPCBvCSOMbjeVRY",
    "summary": "<p>“腾讯云中小企业在线学堂”之腾讯云低代码公开课。鹅厂专家讲师直播授课，教您如何利用「低代码」开发实现自身企业的“数字化转型”！<br />\n“中小企业在线学堂”围绕中小企业业务需求，聚焦企业经营管理、应用工具、技术创新、安全底座 4 大需求场景，推出系列直播课程，全面助力中小企业数字化升级。</p>\n<p><img alt=\"\" src=\"https://static001.infoq.cn/resource/image/2d/ce/2d71c30ee6334902679dyy526d93dcce.jpg\" /></p>",
    "publish_time": "2022-11-01 10:23:38",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Kubernetes的未来：OIDC要优于Secret，Ingress并不合适",
    "url": "https://www.infoq.cn/article/zFR1q0chGl6SwFd1QMiD",
    "summary": "<p>本文最初发表于<a href=\"https://www.eficode.com/blog/the-future-of-kubernetes-and-why-developers-should-look-beyond-kubernetes-in-2022\">eficode的博客站点</a>\"，经原作者<a href=\"https://www.linkedin.com/in/michaelvlarsen/\">Michael Vittrup Larsen</a>\"和eficode官方授权，由InfoQ中文站翻译分享。</p><p></p><p>Kubernetes在容器编排中无处不在，其受欢迎的程度依然没有减弱。但是，这并不意味着容器编排领域的演进处于停滞状态。本文将会提出一些观点，那就是为什么Kubernetes的用户，尤其是开发人员，应该超越我们过去几年里学习的传统Kubernetes，转而采用更适合云原生应用的范式。</p><p></p><h2>Kubernetes的兴起</h2><p></p><p></p><p><a href=\"https://www.eficode.com/solutions/kubernetes?hsLang=en\">Kubernetes</a>\"变得如此流行的原因之一就是它构建在Docker之上。在Linux和BSD变种中，容器有着很悠久的历史，然而，Docker通过专注用户体验，使容器的构建和运行变得非常容易，从而使容器变得流行了起来。Kubernetes建立在容器流行的基础之上，使得在计算机节点组成的集群上运行（又叫编排）容器变得非常容易。</p><p></p><p>Kubernetes流行和广泛采用的另外一个原因是它并没有过多改变软件运行的模式。从Kubernetes出现之前运行软件的方式到基于Kubernetes运行软件之间，设想一条发展路径是非常容易的。</p><p></p><h2>我们无法教老范式学习新的技巧</h2><p></p><p></p><p>构建容器镜像以冻结依赖，提供“到处可运行”的体验，再结合Kubernetes&nbsp;<a href=\"https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/deployment-v1/\">Deployment</a>\"资源规范来管理容器副本的编排，这一套实践的功能是非常强大的。但是，它与我们在Docker和Kubernetes出现之前，操作虚拟机的方式并没有根本性的差异。这个很小的思维转变使我们很容易就能使用Kubernetes，这也是为何我们应该超越目前“传统”Kubernetes的原因。</p><p></p><p>本文将会从开发人员的角度展望Kubernetes的未来。概括来讲，我们现在熟知的Kubernetes将会消失，而开发人员并不会在意。这并不是说，Kubernetes不会出现在我们的技术栈中，而是我们会使用新的抽象来改善构建和运维应用的方式，这些新的抽象本身就是构建在Kubernetes之上的。应用会使用平台来构建，平台则基于Kubernetes来构建：</p><p></p><p><img src=\"https://www.eficode.com/hs-fs/hubfs/Screen%20Shot%202022-02-22%20at%201-40-58%20PM-png.png?width=2376&amp;name=Screen%20Shot%202022-02-22%20at%201-40-58%20PM-png.png\" /></p><p></p><p>有意思的是，在十多年以前，Linux是我们构建一切的平台。Linux依然无处不在，是我们技术栈的一部分，但是很少有开发人员关注它，因为我们基于它添加了一些抽象。我们今天所熟知的传统Kubernetes也会面临这样的情况。</p><p></p><h2>横扫一切的新范式</h2><p></p><p></p><h3>安全性：OIDC要优于Secret</h3><p></p><p></p><p>Kubernetes提供了<a href=\"https://kubernetes.io/docs/reference/kubernetes-api/config-and-storage-resources/secret-v1/\">Secret</a>\"资源来声明静态的secret，比如API秘钥、密码等。开发人员不应该再使用Secret资源了。</p><p></p><p>在Secret资源中，简单编码的secret可能会被泄露，而且密码的轮换和撤销也很困难。在GitOps工作流中，secret也需要特别注意，避免明文存储。应用应该使用基于角色的方式来进行认证和授权。这意味着，应用程序的认证和授权应该基于“我们是谁”，而不是“你知道什么（密码、API秘钥）”来进行。</p><p></p><p>强大的身份标识是所有安全性的基础。如果你不确定与你通信的服务器的身份，那么对网络流量进行加密是没有意义的。这就是证书和证书授权机构对HTTPS流量所发挥的作用，它保证了互联网的安全。</p><p></p><p>Kubernetes有一个强大的工作负载身份系统。所有工作负载都与服务账户（service account）相关联，它们拥有<a href=\"https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/#service-account-token-volume-projection\">Kubernetes颁发的短暂有效的OpenID-Connect（OIDC）身份token</a>\"。Kubernetes API服务器签发这些OIDC token，而其他工作负载可以通过Kubernetes API服务器验证token。这为在Kubernetes上运行的工作负载提供了强大的身份识别功能，可以作为基于角色的认证和授权的基础。</p><p></p><p>开发人员不应再使用Kubernetes Secret，而应基于OIDC token构建认证和授权。这意味着，我们不应在Secret资源中存储数据库密码，而应该确保我们的数据库只在收到有效的、未过期的token时才接受请求。</p><p></p><p>使用OIDC token与外部系统集成的例子是<a href=\"https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts.html\">AWS IAM用于服务账户的角色</a>\"和<a href=\"https://www.vaultproject.io/docs/auth/kubernetes\">Hashicorp Vault Kubernetes auth</a>\"。</p><p></p><h2>网络：Ingress并不合适</h2><p></p><p></p><p>Kubernetes提供了一个<a href=\"https://kubernetes.io/docs/concepts/services-networking/ingress/\">Ingress</a>\"资源，以指定如何将HTTP流量路由到工作负载中。正如Tim Hockin（Kubernetes联合创始人）所承认的那样，<a href=\"https://kubernetespodcast.com/episode/041-ingress/\">Ingress资源有很多问题</a>\"。主要的问题是，它只允许我们管理HTTP流量路由中最基本的东西。对于基础设施和网站可靠性工程（SRE）团队来说，允许开发人员使用Ingress资源将是一个令人头疼的问题，他们需要将大量的基础设施互连，并确保它能可靠地运行。Ingress资源太简单了，开发人员不应该用它来配置网络。</p><p></p><p>从服务网格的兴起中，我们可以看到业界对Kubernetes网络有着更多控制和可编程性的需求。它们将Ingress资源划分为多个资源，以便于更好地分离职责，并在路由、可观测性、安全性和容错方面提供额外的功能。</p><p></p><p>越来越多建立在Kubernetes之上的抽象都假设有一个可编程的网络，这超出了Ingress所能提供的可能性（如Knative、Kubeflow，以及像Argo Rollouts这样的持续部署工具）。这凸显了在Kubernetes中更强大的网络模型已经是一个事实标准。</p><p></p><p>Kubernetes已经演进出了“Ingress v2”&nbsp;<a href=\"https://kubernetes.io/blog/2021/04/22/evolving-kubernetes-networking-with-the-gateway-api/\">网关-API</a>\"。虽然这解决了Ingress的一些问题，但是它只涵盖了大部分服务网格所能支持的一小部分特性。</p><p></p><p>Kubernetes支持ACL，用于限制哪些工作负载可以通过<a href=\"https://kubernetes.io/docs/reference/kubernetes-api/policy-resources/network-policy-v1/\">NetworkPolicy</a>\"资源进行通信。该资源在Kubernetes的网络插件中实现，通常会转化为Linux的iptables过滤规则，即基于IP地址的解决方案，很像防火墙，这也是一种古老的范式。一些服务网格扩展了Kubernetes强大的基于OIDC的工作负载身份标识，以实现工作负载之间的双向TLS。这基于比IP地址更强大的原则，为Kubernetes网络通信带来了保密性和真实性。</p><p></p><p>在Kubernetes应用打包时，在如何包含网络配置方面存在一些分歧。许多Helm charts都带有Ingress资源模板。然而，随着我们转向更高级的网络模型，这些定义将不能再使用。展望未来，像Helm charts这样的应用部署应该把网络配置看作是一个正交性的问题，不应该包含在应用部署制品（artifact）中。关于应用的网络配置，可能没有一个放之四海而皆准的解决方案，组织很可能希望开发自己的“应用路由”部署制品。</p><p></p><p>Kubernetes通过在集群中的所有节点上创建一个同质（homogeneous）的网络，使网络变得更加简单。如果你的应用是多集群或多云部署的，它可能同样受益于跨集群或云的同质网络。Kubernetes的网络模型并不能做到这一点，我们需要一些能力更强的方案，比如服务网格。</p><p></p><p>因此，从组织和架构的角度来看，有多个原因可以证明开发者不应该用Ingress资源对网络进行编程。必须以整体的组织视角来考虑这些方案，以确保以可管理和长期可行的方式进行网络配置和管理。</p><p></p><h2>工作负载定义：新的模式</h2><p></p><p></p><p>实际上，所有Kubernetes应用的核心都是<a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/deployment/\">Deployment</a>\"资源。Deployment资源定义了我们的工作负载应该如何以Pod内容器的形式来执行。</p><p></p><p>Deployment的扩展可以通过<a href=\"https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/horizontal-pod-autoscaler-v2/\">HorizontalPodAutoscaler（HPA）</a>\"资源来控制，以适应不同的容量需求。HPA通常使用容器的CPU负载作为增加或删除Pod的标准。由于HPA算法通常的目标利用率在70%左右，这意味着我们在设计时要浪费30%的资源。使用保守的目标利用率的另一个原因是，HPA经常需要一分钟或更长的响应时间才能开始工作。为了处理不同的容量需求，我们需要一些备用容量，与此同时HPA会增加更多的Pod。</p><p></p><p>如果我们的应用会经历缓慢变化的容量需求，用Deployments和HPA管理工作负载效果很好。然而，随着向微服务、事件驱动架构和函数（处理一个或多个事件/请求，然后终止）转变，这种形式的工作负载管理就不够理想了。</p><p></p><p><a href=\"https://keda.sh/\">Kubernetes Event-Driven Autocaler（KEDA）</a>\"可以改善微服务和快速变化的工作负载（如函数）的扩展行为。KEDA定义了一套自己的Kubernetes资源来定义扩展行为，可以视为“HPA v3”（因为HPA资源已经是“v2”版本了）。</p><p></p><p>有一个结合了Kubernetes Deployment模型、扩展以及事件和网络路由的框架，即<a href=\"https://knative.dev/docs/\">Knative</a>\"。 Knative是一个建立在Kubernetes之上的平台，通过<a href=\"https://knative.dev/docs/serving/\">Knative-Service</a>\"资源对工作负载进行有针对性的管理。Knative的核心是<a href=\"https://cloudevents.io/\">CloudEvents</a>\"，Knative服务基本上是由CloudEvents或普通HTTP请求等事件触发和扩展的函数。Knative使用Pod sidecar来监控事件发生率，因此在事件发生率变化时可以快速扩展。Knative还支持扩展到零（scaling to zero），因此允许更细粒度的工作负载扩展，更适合于微服务和函数。</p><p></p><p>Knative服务使用了传统的Kubernetes Deployment/Service，Knative服务的更新（例如，一个新的容器镜像）会创建并行的Kubernetes Deployment/Service资源。Knative利用这一点来实现蓝/绿和金丝雀部署模式，HTTP流量的路由是Knative服务资源定义的一部分。</p><p></p><p>因此，Knative服务资源及其定义事件路由的相关资源将成为开发者在Kubernetes上定义应用部署时所使用的主要资源。 就像我们今天经常通过Deployment资源与Kubernetes互动，让Kubernetes处理Pod一样，使用Knative意味着开发人员将主要关注Knative服务，而Deployment则由Knative平台处理。</p><p></p><p>虽然我希望Knative模型能适合大多数的使用场景，但你的场景可能会有所不同。如果你是做机器学习的，那么<a href=\"https://knative.dev/docs/serving/\">Kubeflow</a>\"可能是更好的抽象。如果你更专注于DevOps和交付流水线，那么<a href=\"https://github.com/pivotal/kpack\">kpack</a>\"、<a href=\"https://tekton.dev/\">Tekton</a>\"或<a href=\"https://cartographer.sh/\">Cartographer</a>\"可能是适合你的抽象形式。无论你在Kubernetes上做什么，都有相应的抽象。</p><p></p><h2>存储：远离持久化卷</h2><p></p><p></p><p>Kubernetes提供了<a href=\"https://kubernetes.io/docs/reference/kubernetes-api/config-and-storage-resources/persistent-volume-v1/\">PersistentVolume</a>\"和<a href=\"https://kubernetes.io/docs/reference/kubernetes-api/config-and-storage-resources/persistent-volume-claim-v1/\">PersistentVolumeClaim</a>\"资源来管理工作负载的存储问题。这可能是我最不喜欢的资源了，除了短暂的缓存数据外，它允许开发人员将其用于任何目的。</p><p></p><p>从高层次的角度来看，PersistentVolume（PV）的问题在于，它将应用程序的主要关注点与存储问题结合在了一起，这不是一个理想的云原生设计模式。<a href=\"https://12factor.net/\">12-factors应用方法论</a>\"告诉我们要将所有<a href=\"https://12factor.net/backing-services\">支撑服务</a>\"视为网络附加资源。这要归因于我们在Kubernetes中水平扩展工作负载和管理数据的方式（请想一下<a href=\"https://en.wikipedia.org/wiki/CAP_theorem\">CAP理论</a>\"）。</p><p></p><p>PV代表了文件和目录的文件系统，我们用POSIX文件系统接口对数据进行操作。访问权限也是基于POSIX模型的，允许通过用户和组进行读/写访问控制。这种模式不仅与云原生应用的设计不匹配，而且在实际使用中也有很多的问题，这意味着大多数情况下，PV是以“容器可以访问所有数据”的模式mount的。</p><p></p><p>开发人员构建的有状态应用其实应该是无状态的。这意味着数据应该在应用外部进行处理，使用除文件系统外的其他抽象形式，如数据库或<a href=\"https://en.wikipedia.org/wiki/Object_storage\">对象存储</a>\"。数据库和对象存储应用可以使用PV来满足其存储需求，但这些系统应该由基础设施/SRE团队来管理，并由开发人员以服务的形式进行消费。</p><p></p><p>当我们将存储视为网络附加资源时，数据安全问题就可能得到极大的改善，例如，我们可以考虑通过REST API进行对象存储。借助REST API的形式，我们就可以通过上述基于Kubernetes工作负载身份标识的短期访问token实现认证和授权。</p><p></p><p>随着Serverless工作负载模式的不断采用，我们应该预期出现更多的动态和更短生命周期的工作负载（例如，Serverless函数处理每个Pod的一个事件）。在这种情况下，工作负载和“老式磁盘”之间的不匹配变得更加明显。</p><p></p><p>在Kubernetes中，容器存储接口（container storage interface，CSI）一直是通过PV向工作负载添加文件系统和块存储的接口。Kubernetes对象存储特别兴趣小组正在研究<a href=\"https://container-object-storage-interface.github.io/\">容器对象存储接口（COSI）</a>\"，这可能会使对象存储成为Kubernetes中的一等公民。</p><p></p><h2>美好的新世界</h2><p></p><p></p><p>在本文中，我认为在定义Kubernetes应用时，有充分的理由超越“传统”的Kubernetes资源。这并不是说，我们永远都不会使用传统的资源类型。仍然会有一些我们无法轻易转换的遗留应用，SRE团队可能仍然需要运行有状态的服务，这些服务会被开发人员构建的应用所消费。对于私有云基础设施来说，情况更是如此。</p><p></p><p>Kubernetes的未来在于<a href=\"https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/\">自定义资源定义（custom resource definition，CRD）</a>\"和抽象，我们会在Kubernetes之上构建它们，并通过CRD提供给用户。Kubernetes会成为抽象的控制平面，而开发人员应该关注的正是这些抽象的CRD。Kubernetes控制平面可以管理Kubernetes内部的资源，甚至是Kubernetes外部的资源，例如<a href=\"https://www.eficode.com/blog/outgrowing-terraform-and-adopting-control-planes?hsLang=en\">Crossplane管理云基础设施</a>\"。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ca/caa5b16d3beb276ca367329c5ceb8ba8.png\" /></p><p></p><p>正如上面所总结的，大多数传统的Kubernetes资源对开发人员来说可能有更好的替代方案。使用这些替代方案将改善我们在未来几年内开发和运维云原生应用程序的方式。毕竟，Kubernetes是一个构建平台的平台。它并不是终点!</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/minibook/IDAGRlr1RAeLg8l6sZTy\">Kubernetes 安全防护终极指南</a>\"</p><p><a href=\"https://www.infoq.cn/article/Yiqriipkfzw1gBBdyzUl\">Crossplane支持的自定义资源数量突破了Kubernetes的限制</a>\"</p>",
    "publish_time": "2022-11-01 10:36:48",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "突发！图森未来CEO侯晓迪被免职",
    "url": "https://www.infoq.cn/article/TNhKEhLjafw3VzV3Hj4C",
    "summary": "<p></p><p></p><blockquote>图森未来的“未来”将向何处去？</blockquote><p></p><p></p><h2>图森未来宣布解除CEO侯晓迪职务</h2><p></p><p></p><p>美国当地时间10月30日晚间，无人驾驶卡车公司图森未来（ TuSimple ）解雇了公司首席执行官兼联合创始人侯晓迪。</p><p></p><p>TuSimple 宣布，公司董事会已终止公司首席执行官、总裁兼首席技术官侯晓迪博士的职务。自 2022 年 10 月 30 日起，侯博士不再担任董事会主席和政府安全委员会成员。</p><p></p><p>TuSimple已在寻找新的有相关经验的CEO人选。公司宣布，TuSimple 的运营执行副总裁 Ersin Yumer 博士已同意在高管寻访期间担任公司临时首席执行官兼总裁。公司首席独立董事Brad Buss将担任董事会主席。</p><p></p><p>官方资料显示，Ersin Yumer 曾在 TuSimple 的算法和机器学习团队担任领导职务，这让他对与TuSimple 商业化相关的运营需求有独特的见解。Yumer 博士是国际公认的可扩展机器学习、3D 计算机视觉和模拟方面的专家。他是自动驾驶汽车行业的资深人士，曾在 Aurora、Uber 和 Argo AI 担任过领导职务。在机器学习和计算机视觉领域，Yumer 博士发表了大量经过同行评审的技术出版物和专利。他拥有博士学位。来自卡内基梅隆大学，在其职业生涯早期曾在 Adob​​e 和 Google 从事尖端 3D 计算机视觉应用程序的工作。</p><p></p><p>TuSimple 在一封电子邮件声明中表示，“（公司）一致认为终止侯晓迪的职务是必要的，并且符合股东的最佳利益”。“从根本上说，我们对侯博士的判断力、决策力以及作为 CEO 领导公司的能力失去了信任和信心。这一决定是与我们董事会审计委员会于 7 月发起的一项正在进行的调查有关，独立于任何媒体报道，董事会得出的调查结论认为有必要更换首席执行官”。</p><p></p><p>不久前，有报道称，侯晓迪因涉及向一家中国初创公司Hydron Inc不当融资和转让技术而受到调查。据<a href=\"https://www.wsj.com/articles/tusimple-probed-by-fbi-sec-over-its-ties-to-a-chinese-startup-11667159325?mod=business_lead_pos3\">华尔街日报</a>\"报道，美国FBI、证券交易委员会和美国外国投资委员会（简称 CFIUS）对TuSimple和Hydron Inc. 的关系展开了调查。</p><p></p><p>2022年6月10日，图森未来联合创始人兼前执行董事长陈默宣布，将创立专注于研发、设计、制造和销售可搭载 L4 级别自动驾驶功能的氢燃料重卡及加氢基础设施服务的新公司“HYDRON”。</p><p></p><p>陈默认为，“自动驾驶汽车的商业化道路需要硬件和软件的复杂集成，将自动驾驶大规模推向市场的最大挑战不是软件开发，而是获得可靠的量产硬件，成立 Hydron的目的，就是希望能够提供专门用于自动驾驶网络的汽车级硬件。”</p><p></p><p>Hydron 计划与合作伙伴合作，在北美建立制造工厂，制造氢动力卡车，以更好地应对美国供应链的挑战。第一代Hydron卡车预计将于2024年第三季度量产，配备完整的传感器、计算单元和冗余执行器，以满足L4级自动驾驶要求。</p><p></p><p>在当时的公司成立声明中，陈默还特别对Hydron 和 TuSimple的关系做了说明。“Hydron 是一家私人控股的独立公司，不隶属于 TuSimple”。</p><p></p><p>但根据最新的调查，一位匿名发言人士称，令人担忧的是，包括侯晓迪在内的高管未能正确披露与 Hydron 的关系，这可能违反了信托义务和证券法。报告称，调查人员还在调查 TuSimple 是否与在中国开展业务的公司 Hydron 共享其在美国开发的自动驾驶技术，这是否违反了美国的规定。他们还在调查TuSimple是否与在美国开发的 Hydron IP 共享，并以此欺骗投资者。</p><p></p><p>关于上述调查结论，侯晓迪否认有任何不当行为。</p><p></p><p>10月31日，候晓迪在<a href=\"https://www.linkedin.com/posts/xiaodihou_i-am-sharing-the-letter-i-sent-to-the-tusimple-activity-6992875047451262976-oD0C/\">LinkedIn 帖子</a>\"发布了他当天早上发给TuSimple团队的信，信中称，“令人遗憾的是，10月30日，公司董事会无故投票并决定免去我的CEO兼董事会主席一职。董事会的操作流程和结论都令人怀疑，随着真相逐渐大白，相信我在CEO和董事会主席任上做出的种种决策、以及我们为TuSimple设定的发展目标，都将得到证明和理解”。</p><p></p><p>“我的职业发展与个人生活都是完全透明的，而且与董事会充分合作，对此我没有丝毫需要隐瞒之处。这里我想强调一点，我不接受任何关于我本人存在不当行为的指责”。</p><p></p><p>候晓迪谈到，“我知道，我的领导风格可能比较严苛，那是因为自动驾驶本身就是一项艰巨的任务，需要每个人坚定不移地践行承诺。但很遗憾，那些不了解自动驾驶复杂性的人们大大低估了我们一同完成的工作、特别是在此过程中承受的牺牲。因为政治理由而阻碍我们共同追求的这个伟大理想，真的很不公平”。</p><p></p><p>受此消息影响，TuSimple 股价暴跌，TuSimple 的股价周一在纳斯达克交易中暴跌 46%，收于 3.43 美元。</p><p></p><h2>2022年第三季度运营亏损1.12亿美元，研发支出8570万美元</h2><p></p><p>10月31日，TuSimple 发布的2022年第三季度财报显示，TuSimple截至 9 月 30 日的第三季度收入为 270 万美元，较上年同期增长2% ，但低于分析师预期的 320 万美元。</p><p></p><p>图森未来2022年第三季度研发支出为8570万美元，运营亏损为1.12亿美元，经调整EBITDA亏损为9360万美元。</p><p></p><p>截至2022年9月30日，图森未来持有现金、现金等价物、受限制现金为8.73亿美元，上年同期持有的现金、现金等价物、受限制现金为14.14亿美元。</p><p></p><p>临时首席执行官 Ersin Yumer 表示，“我们将继续在德克萨斯州扩建 AFN（自主货运网络） ，我对这一过程中面临的机会感到兴奋。对于我们整个团队来说，我预计 2023 年对于 TuSimple 来说将是重要的一年。我很高兴能在这个关键时刻帮助领导公司，并期待与董事会和管理层密切合作，继续履行我们的使命，提供可靠、低成本的货运能力，同时为燃油效率和安全设定新标准。 ”</p><p></p><p>在图森未来2022 年第三季度财报电话会议上，宣布了以下核心事项：</p><p></p><p>宣布高层领导变动继续关注安全，宣布第三方审核在德克萨斯州扩建 AFN为欧洲首个完全自主的商业货物运输提供动力继续升级卡车的硬件以提高可靠性扩大Tucson业务，提高卡车升级能力以及设计和测试专有组件结合测试和收入车队，提供一种有凝聚力的运营模式本季度自动驾驶里程超过 900 万英里，这是行业的另一个重要里程碑</p><p></p><h2>创业梦想戛然而止？</h2><p></p><p></p><p>图森未来于 2015 年由陈默、候晓迪和赫佳男联合创立，公司主营业务为提供无人驾驶卡车货运服务。专注于为长途重卡开发 L4 级别无人驾驶解决方案，其业务分布于中国、美国、日本和欧洲。</p><p></p><p>图森未来自成立伊始就深受资本的青睐，完成多轮融资，得到了包括治平资本、英伟达、复合资本、鼎晖投资、云九资本、Navistar、Traton、万都、UPS 等诸多财务投资方和战略投资方的支持。</p><p></p><p>2021年4 月，图森未来通过在纳斯达克的首次公开募股筹集了超过 10 亿美元，成为自动驾驶领域全球首个 IPO。</p><p></p><p>该公司在其年度报告中表示，它运营着大约 100 辆能够运行的 L4 级自动驾驶半卡车——其中 75 辆在美国，25 辆在中国。这些自动驾驶卡车能够在某些路线上独立行驶无需人类司机。</p><p></p><p>2021 年 12 月，TuSimple 完成全球首次无人驾驶重卡公开道路全无人测试，全程未配备驾驶员、无驾驶员接管、无远程驾驶员控制，巩固了其在人工智能自动驾驶卡车软件开发领域的领先地位。</p><p></p><p>候晓迪在信中回顾了自己的创业心路历程，“2015年，当我在只有区区65平米的办公室里创办TuSimple时，就抱有把它发展成借自动驾驶之力、从根本上颠覆整个货运行业的雄心。大家之所以加入TuSimple，是因为你们也相信这个梦想。我们为之努力，我也为各位的奋斗而感到无比自豪”，“驱动我一路前行的，就是对这个远大理想的不断追求”。</p><p></p><p>而如今，这一梦想或将戛然而止。</p><p></p><p>另一个不得不正视的现实是，候晓迪下台之际，正值当下自动驾驶公司的前景不太明朗。推动汽车自动化以及在无人驾驶的情况下安全运行越来越成为一项代价高昂且长期的挑战。</p><p></p><p>就在几天前，由谷歌和优步自动驾驶汽车项目的资深人士创立的自动驾驶公司 Argo AI 失去了福特和大众的财务支持。Argo AI 成立6年来，吸金200多亿元。目前，这家自动驾驶汽车初创公司即将关停，部分业务将被两大主要出资方福特和大众所吸纳。其结局不胜唏嘘。事实证明，自动驾驶技术的商业化应用远比预期困难得多。</p><p></p><h2>附：候晓迪给TuSimple团队的信全文</h2><p></p><p></p><p>以下公布（该声明在候晓迪的领英公布）的是我今早发给TuSimple团队的信，借此回应公司董事会采取的可疑行动。</p><p></p><p>大家好，</p><p></p><p>2015年，当我在只有区区65平米的办公室里创办TuSimple时，就抱有把它发展成借自动驾驶之力、从根本上颠覆整个货运行业的雄心。大家之所以加入TuSimple，是因为你们也相信这个梦想。我们为之努力，我也为各位的奋斗而感到无比自豪。</p><p></p><p>驱动我一路前行的，就是对这个远大理想的不断追求。但令人遗憾的是，10月30日，公司董事会无故投票并决定免去我的CEO兼董事会主席一职。董事会的操作流程和结论都令人怀疑，随着真相逐渐大白，相信我在CEO和董事会主席任上做出的种种决策、以及我们为TuSimple设定的发展目标，都将得到证明和理解。</p><p></p><p>我的职业发展与个人生活都是完全透明的，而且与董事会充分合作，对此我没有丝毫需要隐瞒之处。这里我想强调一点，我不接受任何关于我本人存在不当行为的指责。</p><p></p><p>我知道，我的领导风格可能比较严苛，那是因为自动驾驶本身就是一项艰巨的任务，需要每个人坚定不移地践行承诺。这里我很感激各位在研发工作中做出的贡献。但很遗憾，那些不了解自动驾驶复杂性的人们大大低估了我们一同完成的工作、特别是在此过程中承受的牺牲。因为政治理由而阻碍我们共同追求的这个伟大理想，真的很不公平。</p><p></p><p>有些人想让我们TuSimple就老老实实当一家技术提供商，但我认为大家要勇于更进一步。自动驾驶具备从根本上改变社会的潜力，这是一片不进则退的残酷战场。正因为如此，我才对我们的长期价值抱有坚定信心，没有出售我在公司的任何股份。只要还有能力维持自己的家庭，我就不会选择这种变现方式。</p><p></p><p>说起家庭，TuSimple是我的珍宝。就像每一位父母那样，我对TuSimple有着无穷无尽、不设前提的热爱。我愿意不惜任何个人代价帮助公司取得成功，包括我的身体健康和陪伴亲朋好友的时间。我可以问心无愧地说，我一直以诚信行事，也始终以TuSimple的最大利益为先。</p><p></p><p>我对现任领导团队充满信心。更重要的是，作为一名TuSimple员工，大家的信念也将在这段充满挑战的时期成为最可靠的精神支柱。</p><p></p><p>无论我担任的是联合创始人、CTO、总裁、B类股东、CEO、董事会主席，抑或是现在的董事会董事，我仍然是大家熟悉的那个爱穿黄鞋的侯小迪。我会一如既往支持TuSimple，矢志不渝。</p><p></p><p>感谢</p><p></p><p>晓迪</p><p></p><p>参考链接：</p><p></p><p><a href=\"https://seekingalpha.com/pr/18996967-tusimple-announces-termination-of-chief-executive-officer-and-initiation-of-search-for-new\">https://seekingalpha.com/pr/18996967-tusimple-announces-termination-of-chief-executive-officer-and-initiation-of-search-for-new</a>\"</p><p></p><p><a href=\"https://www.linkedin.com/posts/xiaodihou_i-am-sharing-the-letter-i-sent-to-the-tusimple-activity-6992875047451262976-oD0C/\">https://www.linkedin.com/posts/xiaodihou_i-am-sharing-the-letter-i-sent-to-the-tusimple-activity-6992875047451262976-oD0C/</a>\"</p><p></p><p><a href=\"https://www.prnewswire.com/news-releases/tusimple-co-founder-mo-chen-launches-hydron-producing-hydrogen-powered-autonomous-ready-freight-trucks-301565500.html\">https://www.prnewswire.com/news-releases/tusimple-co-founder-mo-chen-launches-hydron-producing-hydrogen-powered-autonomous-ready-freight-trucks-301565500.html</a>\"</p><p></p>",
    "publish_time": "2022-11-01 11:20:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "PostgresML比Python HTTP微服务快8-40倍",
    "url": "https://www.infoq.cn/article/Gx3iPSezRCcgSLR7rARJ",
    "summary": "<p></p><p>机器学习架构可能是现代系统中最复杂、最昂贵和最困难的领域了。技术的数量和所需硬件的数量都在为缩减人员、托管和延迟预算而竞争。不幸的是，随着以数据仓库、微服务和NoSQL数据库为中心的最先进的架构使用量的不断增加，该行业的趋势在这些方面只会变得更加糟糕。</p><p></p><p>针对这种不断增长的复杂性，PostgresML是一种更简单的替代方案。在本文中，我们探讨了更优雅的架构的一些额外性能优势，并发现PostgresML在本地测试中比传统的Python微服务的性能高出了8倍，在AWS EC2上则高出了40倍。</p><p></p><h2>候选架构</h2><p></p><p>考虑到Python微服务的所有可能优势，我们的第一个基准测试是在同一台机器上运行Python和Redis。我们的目标是避免任何额外的网络延迟，这使得它与PostgresML的对比更加公平。我们的第二个测试是在AWS EC2上进行的，Redis和Gunicorn由网络分隔开；这个基准测试被证明是相对具有破坏性的。</p><p></p><p>这两个基准测试的完整源代码可以在<a href=\"https://github.com/postgresml/postgresml/tree/master/pgml-docs/docs/blog/benchmarks/python_microservices_vs_postgresml\">Github</a>\"上找到。</p><p></p><h3>PostgresML</h3><p></p><p>PostgresML架构由以下部分组成：</p><p></p><p>带有PostgresML v2.0的PostgreSQL服务器<a href=\"https://www.postgresql.org/docs/current/pgbench.html\">pgbench</a>\" SQL客户端</p><p></p><h3>Python</h3><p></p><p>Python架构由以下部分组成：</p><p></p><p>接受并返回JSON的Flask/Gunicorn服务器带有训练数据的CSV文件带有使用JSON序列化推理数据集的Redis特征存储<a href=\"https://httpd.apache.org/docs/2.4/programs/ab.html\">ab</a>\"&nbsp;HTTP客户端</p><p></p><h3>ML</h3><p></p><p>这两种架构都托管了相同的XGBoost模型，并针对相同的数据集运行预测。相关详细信息，请参阅<a href=\"https://postgresml.org/blog/postgresml-is-8x-faster-than-python-http-microservices/#ml_1\">方法论</a>\"部分。</p><p></p><h2>结果</h2><p></p><p></p><h3>吞吐量</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/b6/b62f3dd3ceaa54e45d43498cc878e179.png\" /></p><p></p><p>吞吐量（Throughput）被定义为架构每秒可以服务的XGBoost预测的数量。在这个基准测试中，PostgresML的性能比运行在同一台机器上的Python和Redis要高8倍。</p><p></p><p>在Python中，大部分瓶颈来自于必须获取并反序列化Redis数据。由于这些特征是在外部存储的，因此它们需要通过Python传递到XGBoost中。XGBoost本身是用C++编写的，它的Python库只提供了一个便利的接口。来自XGBoost的预测必须再次通过Python，序列化为JSON，并通过HTTP发送到客户端。</p><p></p><p>这几乎是你可以为推理微服务所能做的最低限度的工作了。</p><p></p><p>另一方面，PostgresML对数据和计算进行了配置。它从Postgres表中获取数据，该表已经采用了标准浮点格式，Rust推理层通过指针将其转发给XGBoost。</p><p></p><p>当基准测试达到20个客户端时，发生了一件有趣的事情：PostgresML的吞吐量开始快速下降。这可能会让一些人感到惊讶，但对于Postgres的爱好者来说，这是一个已知问题：Postgres并不擅长处理比CPU线程更多的并发活动连接。为了缓解这一问题，我们在数据库之前引入了PgBouncer（一个Postgres代理和池化器），吞吐量也随之增加了，并且在达到100个客户端时继续保持不变。</p><p></p><p>值得注意的是，基准测试机只有16个可用CPU线程（8核）。如果有更多的内核可用，瓶颈只会在有更多的客户端时出现。Postgres服务器的一般建议是为每个可用CPU内核打开大约2个连接，尽管较新版本的PostgreSQL已经逐渐消除了这一限制。</p><p></p><h4>为什么吞吐量很重要</h4><p></p><p>吞吐量能让你事半功倍，用更少的资源做更多的事情。如果你能够使用一台机器每秒处理30000个查询，但现在只使用1000个查询，那么你不太可能需要在短时间内进行升级。另一方面，如果系统只能处理5000个请求，那么在不久的将来，你将会进行一项昂贵且可能会是压力很大的升级。</p><p></p><h3>延迟</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/31/31eaf55dd3bc05ac1d96b0ef26faa5f4.png\" /></p><p></p><p>延迟（Latency）被定义为返回单个XGBoost预测所需的时间。由于大多数系统的资源是有限的，吞吐量直接影响延迟（反之亦然）。如果有许多活动请求，则在队列中等待的客户端就需要更长的时间才能得到服务，并且整体系统延迟会增加。</p><p></p><p>在这个基准测试中，PostgresML的表现也比Python好8倍。你会注意到，同样的问题在有20个客户端时也会发生，使用PgBouncer进行相同的缓解措施会减少其影响。与此同时，Python的延迟继续大幅增加。</p><p></p><p>在描述架构的性能时，延迟是一个很好的度量指标。换句话说，如果我要使用这项服务，我最多会只能在这么长的时间内得到一个预测，而不管还有多少其他客户也正在使用它。</p><p></p><h4>为什么延迟很重要</h4><p></p><p>延迟在机器学习服务中很重要，因为它们通常作为主应用程序的附加部分来运行，有时必须在同一HTTP请求期间多次访问。</p><p></p><p>让我们以电子商务网站为例。典型的店面希望同时展示多个个性化模型。这类模型的示例可能包括针对重复购买的“再次购买”建议（二分分类），或“你所在地区的热门商品”（购买历史的地理聚类）或“像你这样的客户还购买了该商品”（最近邻模型）。</p><p></p><p>所有这些模型都很重要，因为随着时间的推移，它们已被证明在推动购买方面非常成功。如果推理延迟很高，那么模型就会开始争夺非常昂贵的空间、头版和结算，而企业不得不放弃其中的一些，或者更有可能是遭受页面加载缓慢的影响。没有人喜欢在订购食品杂货或晚餐时使用运行缓慢的程序。</p><p></p><h3>内存利用率</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/2b/2bd9a4c396ac039d38445ab79b41ec6e.png\" /></p><p></p><p>众所周知，Python比其他更优化的语言使用更多的内存，在这种情况下，它使用的内存是PostgresML的7倍。</p><p></p><p>PostgresML是Postgres扩展，它与数据库服务器共享RAM。Postgres在只获取和分配它所需的内存方面非常高效：它重用 shared_buffers 和操作系统（OS）页面缓存来存储行以进行推理，并且只需要很少甚至根本不需要分配内存来服务查询。</p><p></p><p>同时，Python必须为它从Redis接收到的每个特征以及它返回的每个HTTP响应分配内存。这个基准测试并未测量Redis的内存利用率，这是运行传统机器学习微服务的额外成本，而且通常是相当大的成本。</p><p></p><h4>训练</h4><p></p><p><img src=\"https://static001.geekbang.org/infoq/27/27f03cd92bb7bd8999dd0b5e8c7e7ff1.png\" /></p><p></p><p>由于Python经常使用Pandas来加载和预处理数据，因此它尤其需要更多的内存。甚至在将数据传递到XGBoost之前，我们已经达到了8GB RSS（驻留集大小）；在实际的拟合过程中，内存利用率几乎达到了12GB。这个测试是Python的另一个最佳案例场景，因为数据已经被预处理过了，只是将其传递给了算法而已。</p><p></p><p>同时，PostresML喜欢与Postgres服务器共享RAM，只分配XGBoost所需的内存即可。数据集的大小非常大，但我们仅使用5GB的RAM就能成功地训练相同的模型。因此，在使用相同硬件的情况下，PostgresML允许的数据集上的训练模型至少是Python的两倍。</p><p></p><h4>为什么内存利用率很重要</h4><p></p><p>这是另一个事半功倍的例子。FAANG和研究型大学之外的大多数机器学习算法都要求数据集能够装入单个机器的内存中。分布式训练并不是我们所希望的，而且从简单的线性回归中仍然可以提取很多价值。</p><p></p><p>使用更少的RAM可以在更大、更完整的数据集上训练更大、更好的模型。如果你碰巧遭受了大量机器学习计算费用的困扰，那么在你的财年结束时，使用更少的RAM可能能给你带来惊喜。</p><p></p><h2>UltraJSON/MessagePack/Serializer X呢？</h2><p></p><p>我们花了很多时间来讨论序列化，因此回顾该领域之前的工作是有意义的。</p><p></p><p>JSON是对用户最友好的格式，但它肯定不是最快的。例如，MessagePack和Ultra JSON有时在读取和存储二进制信息方面更快、更高效。那么，在这个基准测试中使用它们会比使用Python的内置 json 模块更好吗？</p><p></p><p>答案是：并非如此。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f8/f8557af1c258c46da94a0802e5823194.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ba/baa5eb878203cd8bbfa15576647311c3.png\" /></p><p></p><p>（反）序列化的时间很重要，但首先最终需要进行（反）序列化就是瓶颈。从远程系统（例如Redis这样的特征存储）中取出数据，通过网络套接字发送数据，将其解析为Python对象（需要内存分配），然后再将其转换为XGBoost的二进制类型，这会在系统中造成不必要的延迟。</p><p></p><p>PostgresML对Postgres的特征进行了一次内存拷贝。没有网络，没有（反）序列化，没有不必要的延迟。</p><p></p><h2>现实情况如何呢？</h2><p></p><p>通过ocalhost进行测试很方便，但这不是最现实的基准测试。在生产部署中，客户端和服务器位于不同的机器上，而在Python+Redis架构中，特征存储又是在另一个网络跳转点上。</p><p></p><p>为了演示这一点，我们启动了3个EC2实例并再次运行基准测试。这一次，PostgresML比Python和Redis的表现要好40倍。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b7/b77a0c70a2811dc883c625b0041979c4.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/19/19ed49b2035a132d2df1613ea9aa6c7d.png\" /></p><p></p><p>Redis和Gunicorn之间的网络差距让事情变得非常非常糟糕……。从远程特征存储中获取数据增加了Python架构无法避免的请求毫秒数。在一个资源有限的系统中，额外的延迟造成了争用。大多数Gunicorn线程只是在网络上等待，成千上万的请求被卡在了队列中。</p><p></p><p>PostgresML没有这个问题，因为特征和Rust推理层位于同一个系统上。这种架构选择消除了等式中的网络延迟和（反）序列化。</p><p></p><p>你会注意到我们前面讨论的并发性问题在有20个连接时影响了Postgres，我们再次使用PgBouncer来挽救局面。一旦你知道了如何去做，扩展Postgres并不像听起来那么困难。</p><p></p><h2>方法论</h2><p></p><p></p><h3>硬件</h3><p></p><p>第一个基准测试中的客户端和服务器都位于同一台机器上。Redis也是本地的。该机器是一台8核、16线程的AMD Ryzen 7 5800X，配备了32GB RAM、1TB NVMe SSD，并运行有Ubuntu 22.04。</p><p></p><p>AWS EC2基准测试分别使用了一个托管了Gunicorn和PostgresML的c5.4xlarge 实例，以及两个 c5.5large 客户端和Redis实例。它们位于同一VPC中。</p><p></p><h3>配置</h3><p></p><p>Gunicorn运行时有5个进程（Worker），每个进程有2个线程（Thread）。Postgres分别为1个、5个和20个客户端使用1、5和20个连接。PgBouncer的 default_pool_size 设为10，因此20和100个客户端最多能使用10个Postgres连接。</p><p></p><p>XGBoost在推理过程中允许使用2个线程，在训练过程中使用所有可用的CPU内核（16个线程）。</p><p></p><p>ab 和 pgbench 都使用了所有的可用资源，但都是非常轻量级的；这些请求分别是单个JSON对象和单个查询。这两个客户端都使用了持久连接， ab 通过使用HTTP Keep-Alives实现， pgbench 则通过在基准测试期间一直保持Postgres连接打开。</p><p></p><h2>ML</h2><p></p><p></p><h3>数据</h3><p></p><p>我们使用了来自Kaggle的<a href=\"https://www.kaggle.com/datasets/robikscube/flight-delay-dataset-20182022\">飞行状态预测（ Flight Status Prediction ）</a>\"数据集。经过一些后置处理，它最终变成了大约2GB的浮点特征。我们并没有使用所有的列，因为其中一些列是多余的，例如机场名称和机场标识符，它们指的是同一个东西。</p><p></p><h3>模型</h3><p></p><p>我们的XGBoost模型使用默认超参和25个估计量（也称为增强轮）进行训练。</p><p></p><p>用于训练和推理的数据可在<a href=\"https://static.postgresml.org/benchmarks/flights.csv\">此处</a>\"获取。存储在Redis特征存储中数据可在<a href=\"https://static.postgresml.org/benchmarks/flights_sub.csv\">此处</a>\"获取。这只是一个子集，因为用单个Python进程（2800万行）将整个数据集加载到Redis需要花费数小时。与此同时，Postgres  COPY 只需要大约一分钟。</p><p></p><p>对PostgresML模型进行如下的训练：</p><p></p><p><code lang=\"plain\">SELECT * FROM pgml.train(\n    project_name =&gt; 'r2',\n    algorithm =&gt; 'xgboost',\n    hyperparams =&gt; '{ \"n_estimators\": 25 }'\n);\n</code></p><p></p><p>它的准确性很差（Python版本也是如此），可能是因为我们遗漏了任何类型的天气信息，后者最有可能会导致机场的延误。</p><p></p><h3>源代码</h3><p></p><p>基准源代码可以在<a href=\"https://github.com/postgresml/postgresml/tree/master/pgml-docs/docs/blog/benchmarks/python_microservices_vs_postgresml/\">Github</a>\"上找到。</p><p></p><h2>反馈</h2><p></p><p>非常感谢所有支持这一努力的人。我们希望听到来自更广泛的ML和工程社区关于应用程序和其他真实世界场景的反馈，以帮助我们确定工作的优先级。 你可以通过在我们的<a href=\"https://github.com/postgresml/postgresml\">Github</a>\"上为我们加注星标来表示你的支持。</p><p></p><p>项目 Github 地址：<a href=\"https://github.com/postgresml/postgresml\">https://github.com/postgresml/postgresml</a>\"</p><p></p><p>原文链接：</p><p><a href=\"https://postgresml.org/blog/postgresml-is-8x-faster-than-python-http-microservices/#throughput\">https://postgresml.org/blog/postgresml-is-8x-faster-than-python-http-microservices/#throughput</a>\"</p>",
    "publish_time": "2022-11-01 15:13:08",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "安装和体验hive",
    "url": "https://www.infoq.cn/article/fb289dd9e9175019ddc534e1a",
    "summary": "<p></p><h3>欢迎访问我的GitHub</h3><p></p><p></p><blockquote>这里分类和汇总了欣宸的全部原创(含配套源码)：<a href=\"https://github.com/zq2599/blog_demos\">https://github.com/zq2599/blog_demos</a>\"</blockquote><p></p><p></p><h3>关于hive</h3><p></p><p>Hive是种基于Hadoop的数据仓库工具，将结构化的数据文件映射为一张数据库表，并提供类SQL查询功能。</p><p></p><h3>环境信息</h3><p></p><p>本文对应的环境信息如下：</p><p></p><p>CentOS Linux release 7.5.1804JDK：1.8.0_191hadoop：2.7.7hive：1.2.2</p><p></p><h3>hadoop的部署和启动</h3><p></p><p>hadoop环境的部署和启动请参考《Linux部署hadoop2.7.7集群》注意： 确保环境变量中有 HADOOP_HOME 的配置；</p><p></p><h3>安装和配置MySQL(5.7.27版本)</h3><p></p><p>MySQL用来存储元数据，我这里为了简化操作是在docker环境下部署的，一行命令即可：</p><p></p><p><code lang=\"shell\">docker run --name mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=888888 -idt mysql:5.7.27\n</code></p><p></p><p>进入mysql容器：</p><p></p><p><code lang=\"shell\">docker exec -it mysql /bin/bash\n</code></p><p></p><p>进入容器后连接mysql，密码是 888888 ：</p><p></p><p><code lang=\"shell\">mysql -h127.0.0.1 -uroot -p\n</code></p><p></p><p>新建名为 hive 的mysql账号：</p><p></p><p><code lang=\"sql\">CREATE USER 'hive' IDENTIFIED BY '888888';\n</code></p><p></p><p>给hive账号授权访问（并且hvie账号还有权给其他账号授权）：</p><p></p><p><code lang=\"shell\">GRANT ALL PRIVILEGES ON *.* TO 'hive'@'%' WITH GRANT OPTION;\n</code></p><p></p><p>刷新权限数据：</p><p></p><p><code lang=\"sql\">flush privileges;\n</code></p><p></p><p>在宿主机的终端执行以下命令重启mysql服务：</p><p></p><p><code lang=\"shell\">docker exec mysql service mysql restart\n</code></p><p></p><p>再次进入mysql容器，以hive账号的身份登录mysql：</p><p></p><p><code lang=\"shell\">mysql -uhive -p\n</code></p><p></p><p>创建名为 hive 的数据库：</p><p></p><p><code lang=\"sql\">CREATE DATABASE hive;\n</code></p><p></p><h3>安装hive</h3><p></p><p>去hive官网下载，地址是：<a href=\"http://mirror.bit.edu.cn/apache/hive/\">http://mirror.bit.edu.cn/apache/hive/</a>\" ，选择合适的版本，如下图：<img src=\"https://img-blog.csdnimg.cn/20191007155632411.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly94aW5jaGVuLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70\" /> 注意 ：接下来的操作用的账号都不是root，而是 hadoop在hadoop账号的家目录下解压刚刚下载的 apache-hive-1.2.2-bin.tar.gz 文件，是个名为 apache-hive-1.2.2-bin 的目录；编辑hadoop账号的 .bash_profile 文件，增加一个环境变量，就是将刚刚解压出来的 apache-hive-1.2.2-bin 文件夹的完整路径：</p><p></p><p><code lang=\"properties\">export HIVE_HOME=/home/hadoop/apache-hive-1.2.2-bin\n</code></p><p></p><p>修改完毕后，重新打开一个ssh连接，或者执行 source ~/.bash_profile 让环境变量立即生效；进入目录 apache-hive-1.2.2-bin/conf/ ，用模板文件复制一份配置文件：</p><p></p><p><code lang=\"shell\">cp hive-default.xml.template hive-default.xml\n</code></p><p></p><p>在此目录创建名为 hive-site.xml 的文件，内容如下：</p><p></p><p><code lang=\"xml\"><!--?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?-->\n<!--?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?-->\n\n  \n    javax.jdo.option.ConnectionURL\n    jdbc:mysql://127.0.0.1:3306/hive?createDatabaseIfNotExist=true\n  \n  \n    javax.jdo.option.ConnectionDriverName\n    com.mysql.jdbc.Driver\n  \n  \n    javax.jdo.option.ConnectionUserName\n    hive\n  \n  \n    javax.jdo.option.ConnectionPassword\n    888888\n  \n\n</code></p><p></p><p>将mysql的JDBC包放在此目录： /home/hadoop/apache-hive-1.2.2-bin/lib/ ，我这里用的是 mysql-connector-java-5.1.47.jar ，您可以在此下载：<a href=\"https://download.csdn.net/download/boling_cavalry/11834367\">https://download.csdn.net/download/boling_cavalry/11834367</a>\"设置工作已经完成了，接下来是启动和初始化；</p><p></p><h3>初始化和启动hive</h3><p></p><p>进入目录 apache-hive-1.2.2-bin/bin ，执行以下命令初始化：</p><p></p><p><code lang=\"shell\">./schematool -initSchema -dbType mysql\n</code></p><p></p><p>操作成功后，控制台提示：</p><p></p><p><code lang=\"shell\">[hadoop@node0 bin]$ ./schematool -initSchema -dbType mysql\nMetastore connection URL:   jdbc:mysql://127.0.0.1:3306/hive?createDatabaseIfNotExist=true\nMetastore Connection Driver :   com.mysql.jdbc.Driver\nMetastore connection User:   hive\nStarting metastore schema initialization to 1.2.0\nInitialization script hive-schema-1.2.0.mysql.sql\nInitialization script completed\nschemaTool completed\n</code></p><p></p><p>在mysql上看一下，数据库hvie下建了多个表：</p><p></p><p><code lang=\"shell\">mysql&gt; show tables;\n+---------------------------+\n| Tables_in_hive            |\n+---------------------------+\n| BUCKETING_COLS            |\n| CDS                       |\n| COLUMNS_V2                |\n| COMPACTION_QUEUE          |\n| COMPLETED_TXN_COMPONENTS  |\n| DATABASE_PARAMS           |\n| DBS                       |\n| DB_PRIVS                  |\n| DELEGATION_TOKENS         |\n| FUNCS                     |\n| FUNC_RU                   |\n| GLOBAL_PRIVS              |\n| HIVE_LOCKS                |\n| IDXS                      |\n| INDEX_PARAMS              |\n| MASTER_KEYS               |\n| NEXT_COMPACTION_QUEUE_ID  |\n| NEXT_LOCK_ID              |\n| NEXT_TXN_ID               |\n| NOTIFICATION_LOG          |\n| NOTIFICATION_SEQUENCE     |\n| NUCLEUS_TABLES            |\n| PARTITIONS                |\n| PARTITION_EVENTS          |\n| PARTITION_KEYS            |\n| PARTITION_KEY_VALS        |\n| PARTITION_PARAMS          |\n| PART_COL_PRIVS            |\n| PART_COL_STATS            |\n| PART_PRIVS                |\n| ROLES                     |\n| ROLE_MAP                  |\n| SDS                       |\n| SD_PARAMS                 |\n| SEQUENCE_TABLE            |\n| SERDES                    |\n| SERDE_PARAMS              |\n| SKEWED_COL_NAMES          |\n| SKEWED_COL_VALUE_LOC_MAP  |\n| SKEWED_STRING_LIST        |\n| SKEWED_STRING_LIST_VALUES |\n| SKEWED_VALUES             |\n| SORT_COLS                 |\n| TABLE_PARAMS              |\n| TAB_COL_STATS             |\n| TBLS                      |\n| TBL_COL_PRIVS             |\n| TBL_PRIVS                 |\n| TXNS                      |\n| TXN_COMPONENTS            |\n| TYPES                     |\n| TYPE_FIELDS               |\n| VERSION                   |\n+---------------------------+\n53 rows in set (0.00 sec)\n</code></p><p></p><p>在目录 /home/hadoop/apache-hive-1.2.2-bin/bin 执行命令 ./hive 即可启动；初始化和启动已经完成，接下来验证hive；</p><p></p><h3>验证</h3><p></p><p>前面执行 ./hive 之后，已进入了对话模式，输入以下命令创建名为 test001 的数据库：</p><p></p><p><code lang=\"shell\">CREATE database test001;\n</code></p><p></p><p>选择该数据库：</p><p></p><p><code lang=\"shell\">use test001;\n</code></p><p></p><p>创建一个名为test_table的表：</p><p></p><p><code lang=\"sql\">create table test_table(\nid  INT,\nword  STRING\n)\nROW FORMAT DELIMITED\nFIELDS TERMINATED BY  '\\t'\nSTORED AS TEXTFILE;\n</code></p><p></p><p>新建一个ssh连接，创建名为 hive_test.txt 的文本文件，内容如下：</p><p></p><p><code lang=\"shell\">1  aaa\n2  bbb\n3  ccc\n4  ddd\n5  eee\n6  fff\n</code></p><p></p><p>回到和hive对话模式的控制台，输入以下命令，将上述文本文件的内容导入到test001.test_table表中：</p><p></p><p><code lang=\"shell\">LOAD DATA LOCAL INPATH '/home/hadoop/hive_test.txt' INTO TABLE test001.test_table;\n</code></p><p></p><p>控制台提示如下：</p><p></p><p><code lang=\"shell\">hive&gt; LOAD DATA LOCAL INPATH '/home/hadoop/hive_test.txt' INTO TABLE test001.test_table;\nLoading data to table test001.test_table\nTable test001.test_table stats: [numFiles=1, totalSize=36]\nOK\nTime taken: 0.264 seconds\n</code></p><p></p><p>执行select操作，可以看到数据已经全部入库：</p><p></p><p><code lang=\"sql\">hive&gt; select * from test_table;\nOK\n1  aaa\n2  bbb\n3  ccc\n4  ddd\n5  eee\n6  fff\nTime taken: 0.453 seconds, Fetched: 6 row(s)\n</code></p><p></p><p>执行group by查询：</p><p></p><p><code lang=\"shell\">select word,count(word) from test_table GROUP BY word;\n</code></p><p></p><p>此时会启动一个job来完成上述查询，控制台输出如下：</p><p></p><p><code lang=\"shell\">hive&gt; select word,count(word) from test_table GROUP BY word;\nQuery ID = hadoop_20191007190528_3bd50401-267b-4d75-8b08-17ead5f0d790\nTotal jobs = 1\nLaunching Job 1 out of 1\nNumber of reduce tasks not specified. Estimated from input data size: 1\nIn order to change the average load for a reducer (in bytes):\n  set hive.exec.reducers.bytes.per.reducer=\nIn order to limit the maximum number of reducers:\n  set hive.exec.reducers.max=\nIn order to set a constant number of reducers:\n  set mapreduce.job.reduces=\nStarting Job = job_1570427946161_0002, Tracking URL = http://node0:8088/proxy/application_1570427946161_0002/\nKill Command = /home/hadoop/hadoop-2.7.7/bin/hadoop job  -kill job_1570427946161_0002\nHadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n2019-10-07 19:05:34,812 Stage-1 map = 0%,  reduce = 0%\n2019-10-07 19:05:39,991 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.29 sec\n2019-10-07 19:05:46,201 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.23 sec\nMapReduce Total cumulative CPU time: 3 seconds 230 msec\nEnded Job = job_1570427946161_0002\nMapReduce Jobs Launched: \nStage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 3.23 sec   HDFS Read: 7000 HDFS Write: 36 SUCCESS\nTotal MapReduce CPU Time Spent: 3 seconds 230 msec\nOK\naaa  1\nbbb  1\nccc  1\nddd  1\neee  1\nfff  1\nTime taken: 18.614 seconds, Fetched: 6 row(s)\n</code></p><p></p><p>至此，hive的安装和体验实战就完成了，希望本文能给一起学习hive的读者们一些参考。</p><p></p><h3>欢迎关注InfoQ：程序员欣宸</h3><p></p><p></p><blockquote><a href=\"https://www.infoq.cn/profile/42B106DFEF790F/publish\">学习路上，你不孤单，欣宸原创一路相伴...</a>\"</blockquote><p></p><p></p>",
    "publish_time": "2022-11-01 08:28:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "数据工程师的演变：过去、现在和未来",
    "url": "https://www.infoq.cn/article/j3cu3rPH5ybGqOT2DXu2",
    "summary": "<p></p><p>本文最初发布于Airbyte官方博客。</p><p></p><p>当前，数据工程是一个令人兴奋的主题，这是有原因的。自出现以来，数据工程领域的发展脚步就从未放缓。新技术和<a href=\"https://glossary.airbyte.com/term/data-engineering-concepts\">新概念</a>\"最近出现得特别快。2022年年底就快到了，现在是时候回过头来评估下数据工程当前的状态了。</p><p></p><p>如今的数据工程角色未来会是什么样子？还会存在吗？在这篇博文中，我将聊下数据工程角色的过去和现在，并分析新出现的趋势，为对未来做一些预测。</p><p></p><h2>过去：从商业智能到大数据</h2><p></p><p></p><p>要把握数据工程的现在和未来，必须了解它的发展历史。因此，让我们首先回顾下数据领域中出现的一些最重要的事件和技术，是它们催生了如今的数据工程角色。</p><p></p><p>数据仓库是我们为了理解数据所进行的最早的现代化尝试之一，可以追溯到20世纪80年代。当时，第一个商业数据仓库已经初具雏形。20世纪80年代末，Bill Inmon开始正式使用“数据仓库”一词，<a href=\"https://www.dataversity.net/a-short-history-of-data-warehousing/\">他被认为是数据仓库之父</a>\"。也是在20世纪80年代，SQL成为一种标准的数据库语言，直到今天我们还在使用！</p><p></p><p>Inmon为数据仓库原理打下了坚实的理论基础，而Ralph Kimball在1996年出版的《<a href=\"https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/books/data-warehouse-dw-toolkit/\">数据仓库工具包</a>\"》一书为维度建模奠定了基础。</p><p></p><p>随着大规模并行处理（MPP）数据库的推出，数据仓库开启了可扩展分析的时代。这使得处理以前无法想象的数据量成为可能。像商业智能工程师这样负责管理数据仓库的工作应运而生。</p><p></p><p>21世纪初，互联网泡沫破裂，只有少数公司——包括雅虎、谷歌和亚马逊——最终成了科技巨头。他们得到了前所未有的发展，受此影响，工程师们开始寻找更复杂的解决方案，以满足更苛刻的数据需求。为什么会这样？因为当时可用的单体数据库和数据仓库不足以处理新的工作负载。</p><p></p><p>就是在上述情况下，谷歌在2003年发布了那篇著名的论文“<a href=\"https://static.googleusercontent.com/media/research.google.com/en//archive/gfs-sosp2003.pdf\">谷歌文件系统</a>\"”，介绍了一种“用于大型分布式数据密集型应用的可扩展文件系统”，并在2004年发布了<a href=\"https://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf\">关于MapReduce的论文</a>\"，介绍了“如何简化大型集群模式上的数据处理”。然后，在2006年，雅虎的开发人员发布了Hadoop分布式文件系统。与此同时，像服务器和RAM这样的硬件也变得便宜而普遍。</p><p></p><p>21世纪的创新，以及各种规模的企业积累的TB甚至PB级的数据，催生了我们所知的大数据，开启了大数据工程师的时代。</p><p></p><p>当时，大数据工程师广泛使用了开源框架Apache Hadoop。<a href=\"https://hadoop.apache.org/\">Hadoop项目</a>\"主要包含以下四个模块：</p><p></p><p>Hadoop Common：支持其他Hadoop模块的标准实用程序；Hadoop分布式文件系统（HDFS）： 一个分布式文件系统，提供对应用程序数据的高吞吐量访问；Hadoop YARN：一个用于作业调度和集群资源管理的框架；Hadoop&nbsp;<a href=\"https://glossary.airbyte.com/term/map-reduce\">MapReduce</a>\"：一个基于YARN的大数据集并行处理系统。</p><p></p><p>数据工程师需要具备软件开发和底层基础设施操作方面的专业知识，并拥有专门的技能组合，能够充分发挥Hadoop框架的作用。后来，他们又需要具备其他与Hadoop相关的Apache技术（比如Hive以及更近一些的Spark）的使用经验。</p><p></p><p>大约在Hadoop出现的时候，亚马逊决定推出第一个公有云，通过亚马逊云科技（AWS）对外提供其内部技术。其他公有云提供商，如谷歌Cloud和微软Azure，也很快出现。公有云彻底改变了软件和数据应用程序的构建和交付方式，成为这个时代最重要的技术之一。</p><p></p><p>云计算的一个主要优势是，与自行购买硬件相比，可以帮助企业在前期节省大量的固定成本。</p><p></p><p>当使用自己的硬件时，为了保证资源够用，公司必须准确预测他们的工作负载有多大，因为硬件的购买周期很长——这不可避免地会导致过度供应，因为未来很难准确预测。另一方面，使用云，公司只需要为他们使用的资源支付增量成本，而且这些资源很容易随着需求的增加或减少而伸缩。</p><p></p><p>快进到2010年代初，一些以数据为中心的技术出现并崭露头角，例如Amazon Redshift——第一个云原生大规模并行处理数据库——接着是BigQuery，以及更近一些的Snowflake。</p><p></p><p>2010年代早期到中期是数据世界的一段不平凡的时光。那时候，任何公司都可以使用与最著名的IT公司同样先进的数据工具。</p><p></p><p>随着云数据仓库的出现，我们有了管理数据工作流的新工具，其中最受欢迎的有：</p><p></p><p>编排：Airflow转换：dbtBI：Looker、Metabase、Periscope、Mode等</p><p></p><p>所有这些数据产品构成了我们所说的<a href=\"https://glossary.airbyte.com/term/modern-data-stack/\">现代数据栈</a>\"。<a href=\"https://www.getdbt.com/blog/future-of-the-modern-data-stack/\">正如Tristan Handy所言</a>\"，“现代数据栈促成了2012年10月Amazon Redshift的发布。”</p><p></p><p>最近，Justin Chau<a href=\"https://www.youtube.com/watch?v=Si14Hgj4Lok\">采访</a>\"了Airbyte高级数据工程师Alex Gronemeyer，了解她在数据世界职业生涯的不同阶段亲身经历的所有变化。</p><p></p><p>Alex说，“我对数据工程有比较深入的了解，当时我正在用Spark和Scala编写Hadoop管道，我们还没有真正上云；我们做了很多Hive查询，并直接调用API来获取数据。将新数据存入我们的数据库需要付出很大的努力，所以我非常感激现代数据栈提供的工具。”</p><p></p><p>随着数据产品和现代数据栈的出现，在某种程度上，大数据工程师的头衔有些过时了（毕竟，现如今的数据都很大，对吧？），出现了一个更简单、使用更广泛的术语：数据工程师。</p><p></p><p>2017年，Airflow创建者Maxime Beauchemin写了<a href=\"https://medium.com/free-code-camp/the-rise-of-the-data-engineer-91be18f1e603\">那篇著名的文章</a>\"，描述了从商业智能工程师到数据工程师的转变。那时，全世界都意识到了数据工程师的兴起。他2018年发表的文章“<a href=\"https://maximebeauchemin.medium.com/functional-data-engineering-a-modern-paradigm-for-batch-data-processing-2327ec32c42a\">函数式数据工程</a>\"”发挥了进一步的推动作用。</p><p></p><h2>现在：当代数据工程师</h2><p></p><p>由于数据工具的出现，数据专业人士的职业生涯发生了巨大的变化，以前那些微不足道的任务变得越来越有战略意义。由于大数据框架的特性已经被抽象出来，当代数据工程师可能会更多地关注全局，更多地关心价值链上游的任务，如数据建模、质量、安全、管理、架构和编排。</p><p></p><p>与此同时，数据工程师越来越多地采用软件工程最佳实践。尽管软件工程和数据工程是不同的学科，但它们本质上也有一些相似之处：都是通过编写、部署和维护代码来解决问题。因此，当代数据工程师非常熟悉敏捷开发、代码测试和版本控制实践，诸如此类。</p><p></p><p>除了最佳实践，数据工程还采用了来自软件工程的概念。<a href=\"https://glossary.airbyte.com/term/functional-data-engineering/\">函数式数据工程</a>\"就是一个很好的例子，这个叫法源于函数式编程。其主要思想是任务（如将数据从系统A移动到系统B）应该是<a href=\"https://glossary.airbyte.com/term/idempotency/\">幂等的</a>\"，就是说它每次执行的结果都一样。当任务失败或需要修改逻辑时，我们得知道，重新运行任务是安全的，不会导致数据重复或任何其他类型的错误状态。因此，幂等性对于数据管道的可操作性而言至关重要。</p><p></p><p>另一个被数据工程采用的概念是<a href=\"https://glossary.airbyte.com/term/declarative\">声明式编程</a>\"，它比<a href=\"https://glossary.airbyte.com/term/imperative\">命令式编程</a>\"又高了一个抽象级别，关注的是“做什么”而不是“怎么做”。声明式数据管道会说，“将数据从系统A移动到系统B”，而不指定确切的数据流。在数据工程中，声明式管道很重要，因为它们为可观察性、<a href=\"https://airbyte.com/blog/data-quality-issues\">数据质量监控</a>\"和<a href=\"https://glossary.airbyte.com/term/data-lineage\">数据谱系</a>\"奠定了良好的基础。</p><p></p><p>这种声明式概念与<a href=\"https://airbyte.com/blog/data-orchestration-trends\">从数据管道转向数据产品的趋势</a>\"密切相关——其实现依赖于现代数据编排器提供的抽象。现在，数据工程师考虑更多的是管道要交付的产品，例如特定的仪表板或视图，然后以此为基础构建管道。数据即产品（data as a product）思想是<a href=\"https://glossary.airbyte.com/term/data-mesh/\">数据网格</a>\"架构的核心价值所在。</p><p></p><p>Python也崛起并进入了数据工程领域，因为多年来，作为一种非常健壮的编程语言，其地位已经很稳固。由于内置了许多用于数据处理和展示的库，所以Python在数据社区的应用已经相当广泛。一个突出的例子是<a href=\"https://pandas.pydata.org/\">pandas</a>\"（专门用于提取和转换数据）。也出现了其他基于Python的重要工具，如<a href=\"https://spark.apache.org/docs/latest/api/python/\">PySpark</a>\"，这是Apache Spark的一个接口，让我们可以在分布式环境中进行交互式数据分析。</p><p></p><p>可以肯定地说，如今，Python和SQL是任何数据工程师都必须知道的语言。</p><p></p><p>多年来，组织组织数据团队的方式已经发生了变化。现在，为了更好地满足每个数据消费者的需求，出现了一些新的趋势，包括去中心化数据团队、自助数据平台以及在数据仓库以外存储数据的方法（如<a href=\"https://glossary.airbyte.com/term/data-lake/\">数据湖</a>\"、<a href=\"https://glossary.airbyte.com/term/data-lakehouse\">数据湖仓</a>\"或上文提到的数据网格）。</p><p></p><p>尽管人们对组织层面的这种变化还莫衷一是，专家们对于哪种方式最好也还有不同的意见，我们看到的一个趋势是，让领域专家拥有他们使用的数据，而不是由一个中心团队负责“真相来源”。因此，现在许多数据工程师都归属于中心平台团队，负责优化数据栈的不同方面，而不拥有数据。</p><p></p><p>上面提到的架构和组织层面的转变面临的主要挑战是保持对数据的共同理解。这就是人们采用<a href=\"https://airbyte.com/blog/the-rise-of-the-semantic-layer-metrics-on-the-fly\">语义层</a>\"等概念的原因。语义层将复杂的数据映射到熟悉的业务术语，跨系统整合数据，提供统一的数据视图。</p><p></p><p>那么，该如何定义当今的数据工程角色呢？让我们看下《<a href=\"https://www.oreilly.com/library/view/fundamentals-of-data/9781098108298/\">数据工程基础</a>\"》一书的定义，这是迄今为止最新、最完整的定义之一：“数据工程是开发、实现和维护一些系统和流程，而这些系统和流程会接收原始数据，生成一致的、高质量的信息，为像分析和机器学习这样的下游用例提供支持。数据工程涉及安全、数据管理、数据操作、数据架构、编排和软件工程。”</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b7/b75d0224839d5b23eb07c86d383b9e23.png\" /></p><p>数据工程生命周期，受《数据工程基础》一书启发</p><p></p><p>如今，数据工程师负责监视整个数据工程流程，从收集各种来源的数据到提供给下游流程使用。该角色需要熟悉数据工程生命周期的各个阶段，并具备从多个维度（包括价格、速度、灵活性、可扩展性、简单性、可重用性和互操作性）评估数据工具以获得最佳性能的能力。</p><p></p><h2>未来：数据工程师将何去何从？</h2><p></p><p>似乎大多数（如果不是全部的话）数据工程都趋向于通过采用软件工程最佳实践来提升该领域的抽象水平、简洁性和成熟度。这对于未来意味着什么？我认为主要有如下四个趋势：</p><p></p><p>数据工具的复杂度降低，而功能和特性增加。专业化程度增加，从而催生新的数据工程角色。数据生产者和消费者之间的差距缩小。采用了DataOps，改进数据管理。</p><p></p><p>下面我们将稍微深入地探讨下以上趋势。</p><p></p><p>退一步看，通过复杂的管道建立和维护数据源和目标之间的连接，一直是数据工程师的主要关注点之一。在这方面，有一个值得注意的发展，可以完美说明“工具易于使用和简洁性”这一趋势，那就是托管数据连接器。</p><p></p><p>在回答关于使用数据连接器的问题时，Alex Gronemeyer提到：“从业务系统引入数据真的很有趣，只需几分钟就可以设置好一个新的连接器并让数据流进来，我以前从未经历过这样的事情。然后，当我开始为一个要在下游报表中使用的新数据集建模时，我的大部分工作集中在数据建模、清理和将数据连接在一起。我不需要再花一周的时间去获取数据，看看它是什么样子。这个问题已经解决了。”</p><p></p><p>Airbyte是一个开源工具，它提供了数百个现成的数据连接器。例如，你可以创建一个从Postgres到Snowflake的数据管道，而无需编写任何代码。这个新一代的数据工具非常令人兴奋，甚至对技术能力很强的专业人员也很有吸引力，因为不需要<a href=\"https://airbyte.com/blog/etl-framework-vs-etl-script\">另外创建一个ELT脚本</a>\"，所以他们就可以把这块时间和精力用于其他对公司而言更重要的事情上。这一趋势未来似乎也不会放缓。</p><p></p><p>工具的简化使得任何数据从业者（如数据分析师和数据科学家）都可以在几分钟内设置好数据管道，其直接结果是，数据工程师不再是瓶颈。未来，自助式分析可能会继续为下游数据消费者赋能。</p><p></p><p>前面已经提到，数据世界可能会出现新的角色，就像分析工程师角色在21世纪20年代初出现那样。分析工程师是最可能从业务/数据分析师开启职业生涯的专业人士；因此，他们精通SQL和仪表板构建。自助式平台和像dbt这样的转换工具让他们可以从数据工程师那里获得更大的自主权。未来，我们可能会看到更多这样的专门角色出现。</p><p></p><p>企业获取的数据比以往任何时候都要多，这要归功于改进后的数据工具提供了更多的功能。随着在数据生命周期中与数据交互并基于数据做出决策的利益相关方越来越多，数据可信变得至关重要。正因为如此，数据质量仍然是数据团队的首要任务。</p><p></p><p>近来，对数据质量的日益关注催生了一个新的角色：数据可靠性工程师。这是一个专门致力于数据质量和可用性的数据工程角色。我相信，这个角色会继续发展。数据可靠性工程师将DevOps最佳实践应用于数据系统，如CI/CD、服务水平协议（SLA）、监控和可观察性。</p><p></p><p>另一方面，软件工程和数据工程的岗位和职责也会交汇。这种转变可能是由结合了软件和分析的数据应用推动的。未来，软件工程师可能需要精通数据工程。随着流式架构和事件驱动架构的出现，上游后端系统和下游分析系统之间的界限将逐渐消失。</p><p></p><p>数据生产者会越来越关注分析和数据科学用例，这一趋势会继续发展。采用<a href=\"https://glossary.airbyte.com/term/data-contract\">数据契约</a>\"的人已经越来越多：源系统的所有者和负责将数据输入数据管道的团队之间达成的协议。这意味着，未来生产者和消费者之间的耦合将更加紧密。</p><p></p><p>宏观上看——除了技术或工具之外——数据生态系统正朝着利益相关方之间加强合作的方向发展。这催生了新的思维模式，如DataOps。<a href=\"https://www.gartner.com/en/information-technology/glossary/dataops\">正如Gartner所定义的那样</a>\"：“DataOps是一种协作式数据管理实践，致力于改善组织内数据管理者和数据消费者之间的沟通、集成和数据流自动化。”</p><p></p><p>归根结底，新数据工具和实践的爆炸式增长都是为了解决了一个一直存在的问题：数据管理、更好地协同工作及提供价值。未来几年，这一领域将得到显著改善。</p><p></p><p>有人会质疑，上述情况是否会导致未来数据工程师消失。我认为不会。工具的日益成熟，生产者和消费者之间差距的逐步缩小，以及DataOps的实现，意味着数据工程师将专注于更具战略性的任务，不是作为中间人，而是作为自动化顾问和推动者。</p><p></p><p>岗位和职责也将发生变化，“数据工程师”一词可能会被更专业、更具体的头衔所取代。但数据工程不可或缺，因为企业越来越依赖数据，而且要开发新的数据驱动的基础设施和流程。</p><p></p><p>未来，为了适应不断变化的需求，数据工程师将负责设计灵活的数据架构，其中包括针对为业务提供最大价值的工具和流程做决策。</p><p></p><p>声明：本文为InfoQ翻译，未经许可禁止转载。</p><p></p><p>原文链接：</p><p><a href=\"https://airbyte.com/blog/data-engineering-past-present-and-future\">https://airbyte.com/blog/data-engineering-past-present-and-future</a>\"</p>",
    "publish_time": "2022-11-01 15:35:30",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "新工具爆发式增长，数据工程师的未来在哪？",
    "url": "https://www.infoq.cn/article/j3cu3rPH5ybGqOT2DXu2",
    "summary": "<p></p><p>本文最初发布于Airbyte官方博客。</p><p></p><p>当前，数据工程是一个令人兴奋的主题，这是有原因的。自出现以来，数据工程领域的发展脚步就从未放缓。新技术和<a href=\"https://glossary.airbyte.com/term/data-engineering-concepts\">新概念</a>\"最近出现得特别快。2022年年底就快到了，现在是时候回过头来评估下数据工程当前的状态了。</p><p></p><p>如今的数据工程角色未来会是什么样子？还会存在吗？在这篇博文中，我将聊下数据工程角色的过去和现在，并分析新出现的趋势，为对未来做一些预测。</p><p></p><h2>过去：从商业智能到大数据</h2><p></p><p></p><p>要把握数据工程的现在和未来，必须了解它的发展历史。因此，让我们首先回顾下数据领域中出现的一些最重要的事件和技术，是它们催生了如今的数据工程角色。</p><p></p><p>数据仓库是我们为了理解数据所进行的最早的现代化尝试之一，可以追溯到20世纪80年代。当时，第一个商业数据仓库已经初具雏形。20世纪80年代末，Bill Inmon开始正式使用“数据仓库”一词，<a href=\"https://www.dataversity.net/a-short-history-of-data-warehousing/\">他被认为是数据仓库之父</a>\"。也是在20世纪80年代，SQL成为一种标准的数据库语言，直到今天我们还在使用！</p><p></p><p>Inmon为数据仓库原理打下了坚实的理论基础，而Ralph Kimball在1996年出版的《<a href=\"https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/books/data-warehouse-dw-toolkit/\">数据仓库工具包</a>\"》一书为维度建模奠定了基础。</p><p></p><p>随着大规模并行处理（MPP）数据库的推出，数据仓库开启了可扩展分析的时代。这使得处理以前无法想象的数据量成为可能。像商业智能工程师这样负责管理数据仓库的工作应运而生。</p><p></p><p>21世纪初，互联网泡沫破裂，只有少数公司——包括雅虎、谷歌和亚马逊——最终成了科技巨头。他们得到了前所未有的发展，受此影响，工程师们开始寻找更复杂的解决方案，以满足更苛刻的数据需求。为什么会这样？因为当时可用的单体数据库和数据仓库不足以处理新的工作负载。</p><p></p><p>就是在上述情况下，谷歌在2003年发布了那篇著名的论文“<a href=\"https://static.googleusercontent.com/media/research.google.com/en//archive/gfs-sosp2003.pdf\">谷歌文件系统</a>\"”，介绍了一种“用于大型分布式数据密集型应用的可扩展文件系统”，并在2004年发布了<a href=\"https://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf\">关于MapReduce的论文</a>\"，介绍了“如何简化大型集群模式上的数据处理”。然后，在2006年，雅虎的开发人员发布了Hadoop分布式文件系统。与此同时，像服务器和RAM这样的硬件也变得便宜而普遍。</p><p></p><p>21世纪的创新，以及各种规模的企业积累的TB甚至PB级的数据，催生了我们所知的大数据，开启了大数据工程师的时代。</p><p></p><p>当时，大数据工程师广泛使用了开源框架Apache Hadoop。<a href=\"https://hadoop.apache.org/\">Hadoop项目</a>\"主要包含以下四个模块：</p><p></p><p>Hadoop Common：支持其他Hadoop模块的标准实用程序；Hadoop分布式文件系统（HDFS）： 一个分布式文件系统，提供对应用程序数据的高吞吐量访问；Hadoop YARN：一个用于作业调度和集群资源管理的框架；Hadoop&nbsp;<a href=\"https://glossary.airbyte.com/term/map-reduce\">MapReduce</a>\"：一个基于YARN的大数据集并行处理系统。</p><p></p><p>数据工程师需要具备软件开发和底层基础设施操作方面的专业知识，并拥有专门的技能组合，能够充分发挥Hadoop框架的作用。后来，他们又需要具备其他与Hadoop相关的Apache技术（比如Hive以及更近一些的Spark）的使用经验。</p><p></p><p>大约在Hadoop出现的时候，亚马逊决定推出第一个公有云，通过亚马逊云科技（AWS）对外提供其内部技术。其他公有云提供商，如谷歌Cloud和微软Azure，也很快出现。公有云彻底改变了软件和数据应用程序的构建和交付方式，成为这个时代最重要的技术之一。</p><p></p><p>云计算的一个主要优势是，与自行购买硬件相比，可以帮助企业在前期节省大量的固定成本。</p><p></p><p>当使用自己的硬件时，为了保证资源够用，公司必须准确预测他们的工作负载有多大，因为硬件的购买周期很长——这不可避免地会导致过度供应，因为未来很难准确预测。另一方面，使用云，公司只需要为他们使用的资源支付增量成本，而且这些资源很容易随着需求的增加或减少而伸缩。</p><p></p><p>快进到2010年代初，一些以数据为中心的技术出现并崭露头角，例如Amazon Redshift——第一个云原生大规模并行处理数据库——接着是BigQuery，以及更近一些的Snowflake。</p><p></p><p>2010年代早期到中期是数据世界的一段不平凡的时光。那时候，任何公司都可以使用与最著名的IT公司同样先进的数据工具。</p><p></p><p>随着云数据仓库的出现，我们有了管理数据工作流的新工具，其中最受欢迎的有：</p><p></p><p>编排：Airflow转换：dbtBI：Looker、Metabase、Periscope、Mode等</p><p></p><p>所有这些数据产品构成了我们所说的<a href=\"https://glossary.airbyte.com/term/modern-data-stack/\">现代数据栈</a>\"。<a href=\"https://www.getdbt.com/blog/future-of-the-modern-data-stack/\">正如Tristan Handy所言</a>\"，“现代数据栈促成了2012年10月Amazon Redshift的发布。”</p><p></p><p>最近，Justin Chau<a href=\"https://www.youtube.com/watch?v=Si14Hgj4Lok\">采访</a>\"了Airbyte高级数据工程师Alex Gronemeyer，了解她在数据世界职业生涯的不同阶段亲身经历的所有变化。</p><p></p><p>Alex说，“我对数据工程有比较深入的了解，当时我正在用Spark和Scala编写Hadoop管道，我们还没有真正上云；我们做了很多Hive查询，并直接调用API来获取数据。将新数据存入我们的数据库需要付出很大的努力，所以我非常感激现代数据栈提供的工具。”</p><p></p><p>随着数据产品和现代数据栈的出现，在某种程度上，大数据工程师的头衔有些过时了（毕竟，现如今的数据都很大，对吧？），出现了一个更简单、使用更广泛的术语：数据工程师。</p><p></p><p>2017年，Airflow创建者Maxime Beauchemin写了<a href=\"https://medium.com/free-code-camp/the-rise-of-the-data-engineer-91be18f1e603\">那篇著名的文章</a>\"，描述了从商业智能工程师到数据工程师的转变。那时，全世界都意识到了数据工程师的兴起。他2018年发表的文章“<a href=\"https://maximebeauchemin.medium.com/functional-data-engineering-a-modern-paradigm-for-batch-data-processing-2327ec32c42a\">函数式数据工程</a>\"”发挥了进一步的推动作用。</p><p></p><h2>现在：当代数据工程师</h2><p></p><p>由于数据工具的出现，数据专业人士的职业生涯发生了巨大的变化，以前那些微不足道的任务变得越来越有战略意义。由于大数据框架的特性已经被抽象出来，当代数据工程师可能会更多地关注全局，更多地关心价值链上游的任务，如数据建模、质量、安全、管理、架构和编排。</p><p></p><p>与此同时，数据工程师越来越多地采用软件工程最佳实践。尽管软件工程和数据工程是不同的学科，但它们本质上也有一些相似之处：都是通过编写、部署和维护代码来解决问题。因此，当代数据工程师非常熟悉敏捷开发、代码测试和版本控制实践，诸如此类。</p><p></p><p>除了最佳实践，数据工程还采用了来自软件工程的概念。<a href=\"https://glossary.airbyte.com/term/functional-data-engineering/\">函数式数据工程</a>\"就是一个很好的例子，这个叫法源于函数式编程。其主要思想是任务（如将数据从系统A移动到系统B）应该是<a href=\"https://glossary.airbyte.com/term/idempotency/\">幂等的</a>\"，就是说它每次执行的结果都一样。当任务失败或需要修改逻辑时，我们得知道，重新运行任务是安全的，不会导致数据重复或任何其他类型的错误状态。因此，幂等性对于数据管道的可操作性而言至关重要。</p><p></p><p>另一个被数据工程采用的概念是<a href=\"https://glossary.airbyte.com/term/declarative\">声明式编程</a>\"，它比<a href=\"https://glossary.airbyte.com/term/imperative\">命令式编程</a>\"又高了一个抽象级别，关注的是“做什么”而不是“怎么做”。声明式数据管道会说，“将数据从系统A移动到系统B”，而不指定确切的数据流。在数据工程中，声明式管道很重要，因为它们为可观察性、<a href=\"https://airbyte.com/blog/data-quality-issues\">数据质量监控</a>\"和<a href=\"https://glossary.airbyte.com/term/data-lineage\">数据谱系</a>\"奠定了良好的基础。</p><p></p><p>这种声明式概念与<a href=\"https://airbyte.com/blog/data-orchestration-trends\">从数据管道转向数据产品的趋势</a>\"密切相关——其实现依赖于现代数据编排器提供的抽象。现在，数据工程师考虑更多的是管道要交付的产品，例如特定的仪表板或视图，然后以此为基础构建管道。数据即产品（data as a product）思想是<a href=\"https://glossary.airbyte.com/term/data-mesh/\">数据网格</a>\"架构的核心价值所在。</p><p></p><p>Python也崛起并进入了数据工程领域，因为多年来，作为一种非常健壮的编程语言，其地位已经很稳固。由于内置了许多用于数据处理和展示的库，所以Python在数据社区的应用已经相当广泛。一个突出的例子是<a href=\"https://pandas.pydata.org/\">pandas</a>\"（专门用于提取和转换数据）。也出现了其他基于Python的重要工具，如<a href=\"https://spark.apache.org/docs/latest/api/python/\">PySpark</a>\"，这是Apache Spark的一个接口，让我们可以在分布式环境中进行交互式数据分析。</p><p></p><p>可以肯定地说，如今，Python和SQL是任何数据工程师都必须知道的语言。</p><p></p><p>多年来，组织组织数据团队的方式已经发生了变化。现在，为了更好地满足每个数据消费者的需求，出现了一些新的趋势，包括去中心化数据团队、自助数据平台以及在数据仓库以外存储数据的方法（如<a href=\"https://glossary.airbyte.com/term/data-lake/\">数据湖</a>\"、<a href=\"https://glossary.airbyte.com/term/data-lakehouse\">数据湖仓</a>\"或上文提到的数据网格）。</p><p></p><p>尽管人们对组织层面的这种变化还莫衷一是，专家们对于哪种方式最好也还有不同的意见，我们看到的一个趋势是，让领域专家拥有他们使用的数据，而不是由一个中心团队负责“真相来源”。因此，现在许多数据工程师都归属于中心平台团队，负责优化数据栈的不同方面，而不拥有数据。</p><p></p><p>上面提到的架构和组织层面的转变面临的主要挑战是保持对数据的共同理解。这就是人们采用<a href=\"https://airbyte.com/blog/the-rise-of-the-semantic-layer-metrics-on-the-fly\">语义层</a>\"等概念的原因。语义层将复杂的数据映射到熟悉的业务术语，跨系统整合数据，提供统一的数据视图。</p><p></p><p>那么，该如何定义当今的数据工程角色呢？让我们看下《<a href=\"https://www.oreilly.com/library/view/fundamentals-of-data/9781098108298/\">数据工程基础</a>\"》一书的定义，这是迄今为止最新、最完整的定义之一：“数据工程是开发、实现和维护一些系统和流程，而这些系统和流程会接收原始数据，生成一致的、高质量的信息，为像分析和机器学习这样的下游用例提供支持。数据工程涉及安全、数据管理、数据操作、数据架构、编排和软件工程。”</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b7/b75d0224839d5b23eb07c86d383b9e23.png\" /></p><p>数据工程生命周期，受《数据工程基础》一书启发</p><p></p><p>如今，数据工程师负责监视整个数据工程流程，从收集各种来源的数据到提供给下游流程使用。该角色需要熟悉数据工程生命周期的各个阶段，并具备从多个维度（包括价格、速度、灵活性、可扩展性、简单性、可重用性和互操作性）评估数据工具以获得最佳性能的能力。</p><p></p><h2>未来：数据工程师将何去何从？</h2><p></p><p>似乎大多数（如果不是全部的话）数据工程都趋向于通过采用软件工程最佳实践来提升该领域的抽象水平、简洁性和成熟度。这对于未来意味着什么？我认为主要有如下四个趋势：</p><p></p><p>数据工具的复杂度降低，而功能和特性增加。专业化程度增加，从而催生新的数据工程角色。数据生产者和消费者之间的差距缩小。采用了DataOps，改进数据管理。</p><p></p><p>下面我们将稍微深入地探讨下以上趋势。</p><p></p><p>退一步看，通过复杂的管道建立和维护数据源和目标之间的连接，一直是数据工程师的主要关注点之一。在这方面，有一个值得注意的发展，可以完美说明“工具易于使用和简洁性”这一趋势，那就是托管数据连接器。</p><p></p><p>在回答关于使用数据连接器的问题时，Alex Gronemeyer提到：“从业务系统引入数据真的很有趣，只需几分钟就可以设置好一个新的连接器并让数据流进来，我以前从未经历过这样的事情。然后，当我开始为一个要在下游报表中使用的新数据集建模时，我的大部分工作集中在数据建模、清理和将数据连接在一起。我不需要再花一周的时间去获取数据，看看它是什么样子。这个问题已经解决了。”</p><p></p><p>Airbyte是一个开源工具，它提供了数百个现成的数据连接器。例如，你可以创建一个从Postgres到Snowflake的数据管道，而无需编写任何代码。这个新一代的数据工具非常令人兴奋，甚至对技术能力很强的专业人员也很有吸引力，因为不需要<a href=\"https://airbyte.com/blog/etl-framework-vs-etl-script\">另外创建一个ELT脚本</a>\"，所以他们就可以把这块时间和精力用于其他对公司而言更重要的事情上。这一趋势未来似乎也不会放缓。</p><p></p><p>工具的简化使得任何数据从业者（如数据分析师和数据科学家）都可以在几分钟内设置好数据管道，其直接结果是，数据工程师不再是瓶颈。未来，自助式分析可能会继续为下游数据消费者赋能。</p><p></p><p>前面已经提到，数据世界可能会出现新的角色，就像分析工程师角色在21世纪20年代初出现那样。分析工程师是最可能从业务/数据分析师开启职业生涯的专业人士；因此，他们精通SQL和仪表板构建。自助式平台和像dbt这样的转换工具让他们可以从数据工程师那里获得更大的自主权。未来，我们可能会看到更多这样的专门角色出现。</p><p></p><p>企业获取的数据比以往任何时候都要多，这要归功于改进后的数据工具提供了更多的功能。随着在数据生命周期中与数据交互并基于数据做出决策的利益相关方越来越多，数据可信变得至关重要。正因为如此，数据质量仍然是数据团队的首要任务。</p><p></p><p>近来，对数据质量的日益关注催生了一个新的角色：数据可靠性工程师。这是一个专门致力于数据质量和可用性的数据工程角色。我相信，这个角色会继续发展。数据可靠性工程师将DevOps最佳实践应用于数据系统，如CI/CD、服务水平协议（SLA）、监控和可观察性。</p><p></p><p>另一方面，软件工程和数据工程的岗位和职责也会交汇。这种转变可能是由结合了软件和分析的数据应用推动的。未来，软件工程师可能需要精通数据工程。随着流式架构和事件驱动架构的出现，上游后端系统和下游分析系统之间的界限将逐渐消失。</p><p></p><p>数据生产者会越来越关注分析和数据科学用例，这一趋势会继续发展。采用<a href=\"https://glossary.airbyte.com/term/data-contract\">数据契约</a>\"的人已经越来越多：源系统的所有者和负责将数据输入数据管道的团队之间达成的协议。这意味着，未来生产者和消费者之间的耦合将更加紧密。</p><p></p><p>宏观上看——除了技术或工具之外——数据生态系统正朝着利益相关方之间加强合作的方向发展。这催生了新的思维模式，如DataOps。<a href=\"https://www.gartner.com/en/information-technology/glossary/dataops\">正如Gartner所定义的那样</a>\"：“DataOps是一种协作式数据管理实践，致力于改善组织内数据管理者和数据消费者之间的沟通、集成和数据流自动化。”</p><p></p><p>归根结底，新数据工具和实践的爆炸式增长都是为了解决了一个一直存在的问题：数据管理、更好地协同工作及提供价值。未来几年，这一领域将得到显著改善。</p><p></p><p>有人会质疑，上述情况是否会导致未来数据工程师消失。我认为不会。工具的日益成熟，生产者和消费者之间差距的逐步缩小，以及DataOps的实现，意味着数据工程师将专注于更具战略性的任务，不是作为中间人，而是作为自动化顾问和推动者。</p><p></p><p>岗位和职责也将发生变化，“数据工程师”一词可能会被更专业、更具体的头衔所取代。但数据工程不可或缺，因为企业越来越依赖数据，而且要开发新的数据驱动的基础设施和流程。</p><p></p><p>未来，为了适应不断变化的需求，数据工程师将负责设计灵活的数据架构，其中包括针对为业务提供最大价值的工具和流程做决策。</p><p></p><p>声明：本文为InfoQ翻译，未经许可禁止转载。</p><p></p><p>原文链接：</p><p><a href=\"https://airbyte.com/blog/data-engineering-past-present-and-future\">https://airbyte.com/blog/data-engineering-past-present-and-future</a>\"</p>",
    "publish_time": "2022-11-01 15:35:30",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]