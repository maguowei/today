[
  {
    "title": "科技引领变革，工程师和企业如何提高社会影响力",
    "url": "https://www.infoq.cn/article/ji5jsdqqbat2IHrGI3fk",
    "summary": "<p>科技行业工程师通过他们的社交网络、技能和经验，有能力产生社会影响力。企业可以通过将商业实践与社会意识相结合，发挥其影响力。具备包容性的培训可以考虑到个人的背景和情况，最大程度地降低参与障碍，确保广泛的参与。这种包容性涵盖了种族、性别、神经多样性以及社会经济背景等多个方面。</p><p>&nbsp;</p><p>在<a href=\"https://qconlondon.com/\">QCon 2023伦敦大会</a>\"上，Germán Bencci上谈到了具有社会责任感的企业。</p><p>&nbsp;</p><p>Bencci提到，在大多数情况下，社会影响力并不是企业所认为的那样。企业可以考虑小额慈善捐款、志愿服务日、校园演讲。Bencci说，这并没有什么错，但企业可以通过专注于让自己的商业行为具有社会意识来产生更大的影响：</p><p></p><p></p><blockquote>我考虑的是他们的招聘方式、他们的多样性统计、他们的设备和服务，以及他们的利润承诺，在影响力和业务之间建立起最紧密的联系。</blockquote><p></p><p>&nbsp;</p><p>Bencci建议，为了产生社会影响力，工程师和他们的企业应该尽可能地创造最好的产品，尽可能地盈利，但要仔细考虑创造产品的方式，以及如何在商业成功和影响力之间建立起紧密的联系：</p><p></p><p></p><blockquote>作为一名工程师，你至少有三种可用的资源：技能、经验和社交网络。你可以利用第一种资源，通过招聘、指导和使用合乎道德的服务来创造具有社会影响力的产品。社交网络可以促使企业将一定比例的利润用于提升社会影响力的工作。</blockquote><p></p><p>&nbsp;</p><p>Bencci提到，工程师可以通过他们所做的工作、招聘实践、招聘目标和多样性统计来影响企业并提出建议。他解释说，他们还可以在CodeYourFuture这样的组织中做志愿者。这样的组织为人们创造了一个最佳的空间，让他们可以与机会较少的人分享技能和经验：</p><p></p><p></p><blockquote>试着利用你现有的资源产生最大的影响，但要专注于把自身视为一种资源。</blockquote><p></p><p>&nbsp;</p><p>Bencci认为，人们需要接受教育和就业。他们想要拥有专业人士的生活。他们希望可以有工作、社会地位、同事。他们想要在企业里工作，有一份工资可以养家糊口，并成为孩子的榜样。人人都希望有机会成为专业人士。</p><p>&nbsp;</p><p>Bencci说，包容性培训意味着你要考虑各种不同的个人情况和背景，关键是人们拥有的时间和金钱，以及你可以提供哪些服务来最大限度地降低参与门槛。为了确保广泛参与，还需要对准并跟踪参与者的不同方面，包括种族、性别、神经多样性和社会经济背景。</p><p>&nbsp;</p><p>Bencci举了CodeYourFuture的例子。为了保证公平的代表性，该项目度量了参训人员的关键统计数据，涉及性别（40%是女性）、年龄（平均年龄35岁，20%的学员超过40岁）、种族（超过70%是非欧洲/白人血统）、社会经济背景（78%生活在贫困线以下）和神经多样性（大约30%的学员具有神经多样性）。</p><p>&nbsp;</p><p>InfoQ就如何创造社会影响力采访了<a href=\"https://www.linkedin.com/in/gbencci/\">Germán Bencci</a>\"。</p><p>&nbsp;</p><p>InfoQ：营利性企业能产生什么样的社会影响力？</p><p></p><p></p><blockquote>Germán Bencci：以招聘平台Cord为例。在过去的几年里，它为CodeYourFuture等社会公益事业捐赠了高达1%的资金，并充分利用自己的这一举动向客户推销自己的服务。&nbsp;当有人通过他们的平台找到工作时，他们会发送一条信息告诉人们，他们支付的费用帮助了其他弱势群体的人接受培训并加入了科技行业。</blockquote><p></p><p>&nbsp;</p><p>InfoQ：包容性技术培训有什么影响？</p><p></p><p></p><blockquote>Bencci：这是保持失业状态或从事低收入工作与开启充满机会和经济回报的职业生涯之间的区别。它给人们带来了独立、骄傲和自信。它给他们的生活、家庭和周围的人带来了根本性的改变。人们开始相信新生活是可能的。</blockquote><p></p><p>&nbsp;</p><p>InfoQ：企业可以做些什么来提升他们的社会影响力？</p><p></p><p></p><blockquote>Bencci：关心社会影响力的企业应该专注于创造价值和文化，将社会影响力作为企业的目标之一，同时将产品、盈利能力和增长作为优先事项。&nbsp;一个有社会影响力力的企业会：- 通过一些可变因素来衡量团队的多样性- 创建多样化的招聘实践- 制定有意识的团队采购策略- 给予新人成长机会- 修正营销等领域的支出，以确定支出合乎道德- 确保可持续的盈利比例，以资助社会影响力实践，包括在组织内部&nbsp;还有很多事情可以做。企业不必想的太远就能产生影响力。</blockquote><p></p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/04/engineers-social-impact/\">What Engineers and Companies Can Do to Increase Social Impact</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/qhgHLsmYuUuAZC9J4S2Q\">马斯克开会当场解雇Twitter首席工程师：我有1亿多粉丝，他却说公众对我失去兴趣</a>\"</p><p><a href=\"https://www.infoq.cn/article/YDao4WyBKCuIuuGDMrBB\">从JS到全生态，云原生时代下的前端成长演进之路 ｜展望前端工程师的2023</a>\"</p>",
    "publish_time": "2023-06-15 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "SUSE：强化零信任、自动化和易用性，筑牢云原生安全防线",
    "url": "https://www.infoq.cn/article/5fcfc291be1a718bfdf3e834a",
    "summary": "<p>刚刚过去的五月，全球知名的电动车及能源公司发生了大规模的数据泄露，再次给安全行业敲响了警钟。数字化时代，云原生技术在发挥数字业务快速交付与迭代优势的同时，带来了新的安全风险和挑战。</p><p></p><p>对此，企业应该如何应对？近日，SUSE 安全产品战略副总裁黄飞进行了深度分享。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6f/6f8e09ae3289e770b72b256fc4938ad1.png\" /></p><p>黄飞，SUSE 安全产品战略副总裁</p><p></p><h2>新技术带来新风险</h2><p></p><p>虚拟机、容器、服务网格、多集群间通信、多云和混合云、Serverless 等新技术不断涌现，对安全边界提出了越来越多的要求。</p><p></p><p>2014 年流行起来的容器技术算是跨时代的变革，它与 Kubernetes 等技术共同助力企业实现了应用程序部署等诸多方面的自动化，但同时也带来了新的安全挑战。黄飞认为挑战主要包括四个方面：首先容器更新迭代非常快，传统的保护方式已经不适用于容器环境；第二是软件生产的流程自动化，容器开发阶段每天可达上千次的软件发布依赖整套 CI/CD 自动化流程控制；三是越来越多的企业开始在跨云多云环境部署容器；四是容器将单一的应用变成了成百上千的微服务，导致服务内部通信爆发式的增长。</p><p></p><p>Kubernetes 采用虚拟化技术，数据、网络、计算等层面的全部虚拟化对于应用程序开发者来讲非常实用。然而，这却让运维安全人员无法了解容器的运行状况，即虚拟化技术本身对安全管控形成了一定的屏障，这无疑升级了安全挑战。</p><p></p><h2>使用“零信任”升级传统安全</h2><p></p><p>2021 年底，“核弹级”的 Log4j 漏洞爆发，大量企业被波及。黄飞将 Log4j 比喻为洋葱芯中的 bug，因为它被层层包裹、嵌入在其他软件包中，很难被常见的扫描方法识别到。他认为对付此类漏洞，首先要从源头进行有效的扫描和控制 CVE 安全漏洞；而对于无法下线进行修复的应用程序，零信任安全则是最有效的保护方法。</p><p></p><p>像 Log4j 这样的高危漏洞随着开源软件的广泛使用而与日俱增，但传统安全工具在云环境很难提供全面的保护。此外，随着公有云的快速发展，业界对安全界限的认识也出现了分歧。“很多客户认为公有云的安全应该完全交给供公有云厂商，但事实并非如此。”黄飞强调，应用程序级别的安全必须由各个企业用户自己负责。这意味着，面对越来越多未知的安全风险，企业的安全防护要从被动式的安全逐渐过渡到主动式安全。</p><p></p><p>主动安全是一个新的概念，无论处于云原生化的哪一个阶段，企业都可以采取较为主动的零信任安全功能来提高效率。“零信任安全并不需要推翻一切从零开始，企业可以循序渐进地进行部署。”黄飞认为，传统安全能够堵住已知的安全漏洞，而零信任安全能够防范未知的安全风险，传统安全与零信任安全的叠加使用可以帮助企业实现多层防护。</p><p></p><p>同时，考虑到大部分企业已经在传统安全上投入了大量资源和金钱，根据企业的实际情况选择最有效的方面开始针对性部署零信任安全也是最经济的方式。</p><p></p><p>黄飞把整个云原生零信任安全的实施划分成四个阶段：用户和可视化；设备、网络和环境；应用程序、服务和编排管理；数据、自动化和合规检查。企业无需推翻所有的安全投资和配置，可以从某一个单点开始介入和部署，逐步深化。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0b/0b7cba42fa0392d5bbc711e5def52533.png\" /></p><p></p><p>NeuVector 在创立之初就专注于容器安全，能够提供端到端的安全服务以及从 DevOps 流水线漏洞保护到生产中的自动化安全和合规性，可以作为零信任安全模型的重要部分，实现对容器环境的实时安全保护和威胁检测。</p><p></p><h2>开源为云原生安全带来更多可能</h2><p></p><p>2022 年 1 月，在被 SUSE 收购 3 个月后，NeuVector 宣布开源，成为业界首个端到端的开源容器安全平台。“这是推动容器安全发展的重要里程碑。”作为 NeuVector 的联合创始人兼创始 CEO 的黄飞评价道。</p><p></p><p>NeuVector 本身拥有十几项技术专利，包括深层数据包检查和行为学习，可识别适当的容器行为，并且仅允许在容器环境中经过批准的白名单进行网络链接、进程访问和文件存取。NeuVector 在运行时提供完整的攻击检测和预防，主动保护生产环境；作为容器部署，具有高度扩展能力。NeuVector 开源之后，所有加入开源专利联盟的企业都可以开诚布公地合作，共享专利与技术，这对整个软件平台产业的发展至关重要。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/21/213f4b4f77bbb263a313ac0d3acd0702.png\" /></p><p>NeuVector：Kubernetes 安全与合规一体化平台</p><p></p><p>黄飞表示加入 SUSE 后学到的最重要的东西是开放性。NeuVector 虽然是 SUSE 的安全产品，但其开源容器镜像可以安装在任何流行的 Kubernetes 集群上，可以支持包括红帽 OpenShift、VMWare Tanzu 等在内的众多企业级容器管理平台，以及 Google GKE、Amazon EKS、Microsoft Azure AKS 等 K8s 发行版。秉承开放战略，NeuVector 将始终致力于成为所有云原生环境的优秀安全解决方案。</p><p></p><h2>打造全栈云原生平台能力,全方位守护云安全</h2><p></p><p>“SUSE 的愿景不仅仅是打通 Linux 操作系统，而是提供从操作系统到容器管理平台再到云安全方案的一整套解决方案，这也是业界发展的一个趋势。”黄飞介绍，随着 Rancher 和 NeuVector 的加入，SUSE 快速增长，现在逐渐拥有了几乎是全栈的云原生平台能力。</p><p></p><p>目前，SUSE 是唯一一家通过最高级别加密认证 FIPS 的 Linux 平台，新一代 SUSE Linux 操作系统开始集成机密计算技术，各个产品都在持续开发各种各样的安全功能。</p><p></p><p>黄飞介绍，企业级的操作系统管理平台 SUSE Manager 能统一管控安全扫描以及补丁功能；SUSE 为 CNCF 贡献的重要安全工具 Kubewarden，能够帮助 Kubernetes 集中管理安全策略；企业容器管理平台 Rancher Prime 提供集群的全生命周期管理，不仅可以跨云统一创建集群，还可以统一管理、升级和配置集群。此外，Rancher Prime 与零信任容器安全平台 NeuVector 的集成，让 Rancher Prime 能够满足整个应用生命周期中的主要安全场景的需求。</p><p></p><p>面对云原生的快速发展与广泛应用，SUSE 也在持续投资和发展安全生产线，来帮助企业应对云原生安全挑战。黄飞透露，SUSE 安全产品未来会侧重于四个方面：一是会持续引领新一代的零信任安全技术；二是将安全自动化技术合理地嵌入到更多的平台和流程中；三是致力于为客户降低云原生安全管理的复杂性；最后，SUSE 也会持续拓展安全边界，根据客户的需求去支持更多、更大规模的超级分布式计算系统环境和场景。</p>",
    "publish_time": "2023-06-15 11:32:30",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "关于《探索AIGC下的软件工程新范式》产业和学术研讨会成果的联合声明",
    "url": "https://www.infoq.cn/article/e3zj2gU4mL7OWb8VwEGE",
    "summary": "<p></p><h2>研讨会参与人&nbsp;&amp; 声明人</h2><p></p><p></p><p>李&nbsp;&nbsp;戈&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;北京大学</p><p>张&nbsp;&nbsp;贺&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;南京大学</p><p>何&nbsp;&nbsp;勉&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;优川信息</p><p>陈&nbsp;&nbsp;鑫&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;阿里云</p><p>刘志伟&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;蚂蚁集团</p><p>李永彬&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;达摩院</p><p>欧&nbsp;&nbsp;红&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;招商银行</p><p>徐晓强&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;百度</p><p>肖&nbsp;&nbsp;然&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Thoughtworks</p><p>张燎原&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;阿里云</p><p>郝逸洋&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;aiXcoder</p><p>李力行&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;aiXcoder</p><p>陈展文&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;招商银行</p><p>路&nbsp;&nbsp;&nbsp;宁&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;理想汽车</p><p>张&nbsp;&nbsp;&nbsp;刚&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;英慕科技</p><p>刘名威&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;复旦大学</p><p>娄一翎&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;复旦大学</p><p>姜&nbsp;&nbsp;&nbsp;伟&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;蚂蚁集团</p><p>黎槟华&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;达摩院</p><p>林&nbsp;&nbsp;&nbsp;帆&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;阿里云</p><p>黄峰达&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Thoughtworks</p><p>刘&nbsp;&nbsp;星&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;阿里巴巴</p><p>王&nbsp;&nbsp;怡&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;阿里巴巴</p><p>刘力华&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;阿里云</p><p>张&nbsp;&nbsp;裕&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;阿里云</p><p>景&nbsp;&nbsp;韵&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;高效运维社区</p><p></p><h2>背景</h2><p></p><p>&nbsp;</p><p>大语言模型的实践应用，正引发软件工程的革命。为此，我们在杭州聚集了产业、学术和研究机构的前沿实践者和专家，在6月4日-5日期间进行了为期两天，以《探索AIGC下的软件工程新范式》为主题的深入的闭门研讨会议。</p><p></p><p>经过交流和讨论，我们一致认为：AIGC正在催生软件工程的新范式，LLM作为催化剂和创新引擎正在开启软件研发和创新效能的倍增，甚至带来指数级提升的可能。面对范式迁移，我们无法靠臆想来推断未来，唯有躬身入局，识别机遇、解决问题，在实践中不断试错和进化。而在这一过程中，产、学、研有效协作与持续地深入交流至关重要。</p><p>&nbsp;</p><p>会议中，我们分别就6个主题进行了探讨，识别了当下LLM在哪些方面带给软件工程重大机会，以及为把握这些机会而亟需解决的重大问题。现将讨论的内容整理成文与行业同仁共享，以激发更多的思想碰撞，促成更多跨领域实践合作。</p><p></p><h2>主题1：应用生态的范式迁移</h2><p></p><p>&nbsp;</p><p>应用生态指的是：软件以何种形式交付给用户。例如：今天的软件主要以独立应用的形态（如移动应用、SaaS应用、PC应用等）交付。我们认为LLM带来了前端交互形式的变化，以及后端推理、规划、连接能力的提升，这将极大改变应用生态。而应用生态的形式变化，将很大程度上决定未来的软件工程的走向。</p><p>达成的共识。</p><p></p><p>1.&nbsp;LLM将带来交互方式的彻底变革，意图导向的自然交互方式将成为现实</p><p></p><p>过去命令行用户界面（CLI）和图形用户界面（GUI）交互的共同特点是：要求用户将意图转化为机器可以识别的命令，并以命令的形式与机器交互。大语言模型时代的交互方式，将由命令导向式向意图导向式交互迁移——人类表达意图，意图的理解和执行由更智能的机器完成。意图导向的交互模式的实现，背后需要整合一系列智能的能力，并将带来全新的多模态的自然交互方式，自然交互界面（NUI，Nature User Interface）的技术元素已趋向完备。</p><p></p><p>2.&nbsp;交互方式的变革与LLM推理能力相结合，将带来以用户为中心的融合应用生态</p><p></p><p>过去，由于交互方式以及后端资源割裂的限制，软件实体不得不按具体任务、商业实体和所承载的硬件被分割成为独立应用或功能模块。大语言模型时代，传统应用间的界限将被消融，智能助理（或其他形态的智能体）将以用户场景为主题整合工具和资源，服务一类场景下的完整用户任务。大模型时代，我们需要以用户为中心，跨越商业实体、特定硬件设备以及传统应用的边界，构建融合的新型应用生态。</p><p></p><h3>可见的重大机会</h3><p></p><p></p><p>1.&nbsp;交互模式变革带来新的商业机会</p><p></p><p>历史上每一次交互模式的革命都会产生全新的商业模式。大语言模型赋能下新的交互模式，带来交互和体验升级的同时，更蕴含着巨大的业务创新机会。</p><p></p><p>2.&nbsp;应用生态的变迁孕育以用户为中心的商业形态</p><p></p><p>应用大模型的能力，打破传统应用的边界，整合工具和资源，服务好一类场景下的完整用户目标，将可能取得竞争的优势。从以平台为中心到以用户为中心的应用生态变迁，将改变商业竞争格局，并带来全新的业务可能。</p><p></p><h3>亟需解决的问题</h3><p></p><p></p><p>1.&nbsp;探索新的交互设计模式</p><p></p><p>LLM的能力将带来新的交互模式，但如何应用LLM的能力，实现意图导向的自然交互模式是一个全新的命题。自然交互不等于自然语言交互，它应该是多模态的，更加意图导向、智能和个性化，能够持续学习、进化并确保隐私及安全。适配大模型时代的交互和体验设计方法是一个新命题，需要持续探索和总结提炼。</p><p></p><p>2.&nbsp;探索和构建新的应用生态</p><p></p><p>传统应用和应用内不同功能模块的边界正在消融，OpenAI的插件市场、Windows Copilot等展示了可能的方向。但这些都尚处于早期，以什么样的技术、架构和方法整合不同的工具和资源，构建新型的应用生态是需要不断探索和总结的重大主题。</p><p></p><h2>主题2：应用架构的演进</h2><p></p><p>&nbsp;</p><p>技术环境的发展是应用架构演化的关键驱动因素。LLM提供了良好的意图理解能力、推理能力和知识内建能力，为用户交互、商业能力组装、服务或组件的开发带来了新的技术选项。我们认为，LLM优先的应用架构已经开始涌现，并且将逐渐成为主流方案；LLM原生的应用架构也成为可能。同时，我们也看到，应用架构的演进将是一个价值导向、长期和持续渐进的过程，其中仍然存在许多关键挑战和困难需要解决。</p><p>达成的共识。</p><p></p><p>1.&nbsp;考虑LLM优先的架构模式</p><p></p><p>LLM在人机交互、流程规划、数据处理等领域都表现出了巨大的潜力。从长期来看，LLM有可能作为应用内核，在此基础上构建LLM原生的应用。</p><p></p><p>从架构的演进路径上，既有应用架构会逐步通过LLM的能力获得增强。LLM原生能力会和既有软件系统彼此融合，长期共存，但是在架构设计时，为了利用LLM在交互、复杂问题处理和开发运维成本方面的优势，应优先考虑基于LLM能力的解决方案。其中既包括从既有的软件系统中逐步增加LLM能力，也包括在LLM平台增加插件的方式。</p><p></p><p>2.&nbsp;采取LLM友好的架构策略</p><p></p><p>为了最大化发挥LLM的价值，架构方案和基础平台的设计应该采取有利于LLM的上下文获取、能力调度、功能实现的方案。例如：</p><p>•&nbsp;采用便于LLM获取业务上下文的应用架构，如事件驱动架构；</p><p>•&nbsp;采用基于领域划分的架构，便于按特定领域组织数据和模型；</p><p>•&nbsp;采用合适的API声明，利于LLM对服务能力的理解和调度；</p><p>•&nbsp;采用适于获取用户意图的交互方式，便于LLM规划用户意图的达成；</p><p>•&nbsp;建立以“提示工程”和LLM的推理能力为核心的应用开发方案。</p><p></p><h3>可见的重大机会</h3><p></p><p></p><p>1.&nbsp;利用LLM改善人机交互体验</p><p></p><p>基于对话或LLM生成的用户界面，将会大幅提升人机交互的便捷度和灵活性。</p><p></p><p>2.&nbsp;利用LLM规划业务流程和构造系统</p><p></p><p>使用LLM来组织业务流程，形成推理和规划，通过灵活组装既有或新开发的商业能力，满足用户需求，降低开发成本，实现业务上下文密切相关的个性化。</p><p></p><p>3.&nbsp;利用LLM形成数据整合和数据洞察</p><p></p><p>利用LLM对复杂数据和复杂流程的处理能力，整合多领域、多维度的数据，产生有效洞察。</p><p></p><p>4.&nbsp;构建LLM原生系统或组件</p><p></p><p>LLM接受用户需求或组件契约，经过和人类开发者的协作，产出可运行的解决方案或组件。</p><p></p><p>5.&nbsp;构建支持大模型优先架构的基础设施</p><p></p><p>LLM优先的架构产生了对于个性化交互、流程推理和规划、数据整合以及大模型服务等多方面的基础设施的需求。</p><p></p><h3>亟需解决的问题</h3><p></p><p></p><p>1.&nbsp;探索LLM优先的架构的应用场景和设计模式</p><p></p><p>LLM为软件架构引入了基础且重要的新技术能力。系统实现中的问题，有些适合LLM解决；有些则更适合传统的程序逻辑解决。在涉及复杂推理和知识工程领域的问题（如：信息的分类、提取，知识的表达和应用，复杂数据、流程处理等）LLM具有优势；在强调确定性和一致性的领域(如：结构化的数据处理和查询，涉及物理世界的动作执行等）既有的基于程序逻辑的实现则更为有效。充分应用LLM的能力，并与传统的程序逻辑更好的配合，为设计更加智能、灵活，开发成本更低，更易于维护的系统带来可能。我们需要在实践中持续探索LLM优先的应用架构，沉淀相关的设计模式。</p><p></p><p>2.&nbsp;研究和探索LLM原生的应用架构的可能性和使用场景</p><p></p><p>随着LLM能力的增强以及更多的工具和设计方法的完善，LLM可以处理问题的边界将不断扩大。我们相信在一些领域，LLM将会成为缺省的问题解决方案。尽管今天还有许多问题要解决，但是对LLM原生架构模式，特别是在特定领域的应用（如：智能助理等）将成为可能。我们需要在实践中持续探索LLM原生的应用架构和设计模式。</p><p></p><p>3.&nbsp;适合LLM的API定义、领域模型表示和工具</p><p></p><p>通过为LLM提供高质量的领域知识表达和上下文表达，可以提升LLM在特定领域的表现。同样，更适合LLM的API定义和工具，可以更好地发挥LLM的流程规划和系统构造能力。</p><p></p><p>4.&nbsp;多模型协同的范式和解决方案</p><p></p><p>通过整合多个模型的能力，可以优化成本效益、提升模型反馈的质量和稳定性，以及为特定领域提供更高效的解决方案。</p><p></p><p>5.&nbsp;数据安全的挑战</p><p></p><p>LLM对数据安全带来了诸多挑战，例如数据隐私泄露、数据滥用等。需要通过有效的数据安全管理和模型训练及发布策略等，积极应对上述挑战。</p><p></p><h2>主题3：BizDevOps实践和组织协同范式迁移</h2><p></p><p>&nbsp;</p><p>BizDevOps代表了当下软件交付的先进实践和理念，它要求打通从业务、开发、到交付、运维和运营的端到端的价值交付链路，业务和技术融合，建立快速和有效的价值交付和反馈调整闭环。BizDevOps的价值链路为AIGC在软件工程的应用提供了系统的线索，AIGC则为BizDevOps提供了新的技术工具，并带来新的可能。</p><p></p><h3>达成的共识</h3><p></p><p></p><p>1.&nbsp;AIGC可以加强今天BizDevOps实践体系中的各类实践</p><p></p><p>BizDevOps价值链条中，各个环节的工作都有相当部分是AIGC所擅长的理解性和生成性工作，如：意图的理解，文档的生成，代码的理解、生成和重构，缺陷的检测和修复，测试用例和测试数据的生成，运维策略的设计和实施等。在这些领域LLM都可以发挥作用，并增强相关的实践，提高软件设计、开发、维护和运维的效能。</p><p></p><p>2.&nbsp;只有重构BizDevOps的实践体系，AIGC才可能带来效能的非线性提升</p><p></p><p>软件工程是人类历史上最复杂的大规模智力协作活动。尽管，AIGC在BizDevOps各个独立环节的应用都存在机会，并带来效能的提升。但如果AIGC的应用局限于原有模式下，对各个独立环节的加强，则其对效能改进的影响将是有限的，不可能带来非线性（倍增或指数级增长）增长。只有重构BizDevOps实践体系，AIGC才能开启研发和创新效能的非线性提升，而这是一个长期的过程。</p><p></p><h3>可见的重大机会</h3><p></p><p></p><p>1.&nbsp;AIGC在BizDevOps各个环节和跨环节的应用</p><p></p><p>AIGC在软件工程中应用的机会首先来自对现有实践的加强。BizDevOps每一个环节都包含理解性和生成性的工作，AIGC可以降低这些工作的门槛，并改进质量和提升效率。同时，通过AIGC贯穿不同的环节应用，将带来更大的可能，如：在需求分析和代码生成环节的综合应用。</p><p></p><p>2.&nbsp;AIGC对组织和协作方式的重塑，加速业务和技术的融合</p><p></p><p>AIGC的加强下，不同职能的技术门槛在变低，业务和代码的理解门槛也变低。传统的职能（如：产品、技术，前端、后端算法）和功能的壁垒有消融的趋势，个人和团队都有机会变得更加跨功能和跨职能。在AIGC的加强下，打造更加跨功能和跨职能的团队的条件更加成熟，业务与技术更紧密协作和融合更加可能。</p><p></p><h3>亟需解决的问题</h3><p></p><p></p><p>1.&nbsp;在各个环节探索有效应用AIGC的新工作方式</p><p></p><p>AIGC在BizDevOps的各个环节的应用，理论上可行。但是AIGC作为一个超级队员加入到研发活动中，是一个新生的事物。如何在各个环节充分应用AIGC，并探索AIGC与人类的有效协同方式，是一个新的命题。我们一方面要鼓励积极的尝试，另一方面需要不断沉淀最佳实践，并改进工具和基础设施。</p><p></p><p>2.&nbsp;探索AIGC赋能下，新的组织和协作方式</p><p></p><p>LLM带来了新的应用生态和应用架构，一方面，对组织的高效协同特别是业务和技术的高效协同和快速反馈提出了更高的要求；另一方面，AIGC降低了组织的技术和知识壁垒，为跨越职能和功能的协同提供了可能。在AIGC赋能之下，业技融合的迫切性和可能性都在增加。我们急需探索AIGC赋能下，新的业技融合的组织和协作方式，它也将成为数字化和智能化的重要推动力量。</p><p></p><p>3.&nbsp;研究AIGC赋能下，基于全新的应用架构的BizDevOps范式</p><p></p><p>需求是对业务问题的解决方案的精确描述，软件是现实世界的解决方案在数字世界的映射。从需求出发在AIGC的加强下设计精确的解决方案，并应用AIGC的能力将解决方案映射为数字世界的实现，同时辅助对解决方案的测试和验证，是一个值得探索和长期投入的方向。它有可能带来全新的系统开发和交付范式，从本质上提升交付的速度，降低组织协作的复杂度、加速业务反馈，并提升系统的智能化程度和灵活性。</p><p></p><h2>主题4：工具平台建设</h2><p></p><p>&nbsp;</p><p>技术发展最终需要为人服务，对于软件开发者来说，研发工具平台是技术的重要承载。LLM在软件工程的应用，必然会对软件研发工具的建设提出更高要求，涌现更多新机会，同时也会带来新的问题。我们需要在软件研发过程中，寻找那些适合AI去解决的问题场景，通过将LLM应用到研发工具和平台上，才能最大化地将AI技术普惠到软件研发领域的方方面面，助力研发效率的倍数级提升。并提供可行的路径及遵循的原则，确保LLM在研发工具平台上的落地。</p><p></p><h3>达成的共识</h3><p></p><p></p><p>工具和平台建设上，面临重大的机会和挑战。我们认为工具平台建设，需要遵循的原则是：</p><p>数据可用性原则：数据和模型为AI提供高质量输入，高质量的输入源成就高质量的LLM。软件研发全生命周期必须是数字化的，研发团队需要构建良好的知识体系，知识需要被沉淀。以人为本可控原则：人是主体，AI是客体的人机关系。AI是知识的储备和助手，提供解决方案和建议，由人做为解决问题的主体。人类培训机器，机器辅助人类，即AI是人的Copilot。同时，为用户提供基于LLM的工具和平台的可控性，用户可以自主选择使用或停用LLM技术，同时可以获得自身数据的控制权。研发效率优先原则：提高软件研发效率，降低人工成本。因此，工具和平台应该遵循这一原则，提高软件研发效率和质量。基于LLM的研发工具和平台应该释放生产力，而不是消耗生产力。智能无处不在，人机共生。软件研发过程即人与AI的协作交互过程，应该极大简化人机交互方式。数据隐私保护原则：一方面需要对AI的所有任务执行都必须留痕，加强AI的行为安全。同时，研发过程数据，会涉及到企业代码等知识产权数据和用户数据，数据安全领域将迎来越来越多的挑战，需要构建新的数据安全围栏，避免隐私权及伦理风险。</p><p></p><h3>可见的重大机会</h3><p></p><p></p><p>1.&nbsp;数据处理及知识沉淀的能力要求越来越高</p><p></p><p>目的是获得有价值的模型，软件研发全生命周期数字化的要求越来越高。数据和模型成为企业的核心数字资产，避免过量分散的数字化成为数字债，在数据资产存储、研发数据建模、数字资产及债务治理等工具诉求越来越高。</p><p></p><p>2.&nbsp;AI成为软件研发过程中的Copilot, Co-Integrator和Co-Facilitator</p><p></p><p>软件研发领域的模型，指导和建议人的行动。AI与人共同协作，倍数级提升软件研发的效率。整个工具和平台发展上，经历以下几个阶段。</p><p>LLM as Copilot：不改变软件工程的专业分工，但增强每个专业技术，基于AI的研发工具平台辅助人完成任务。极大提升个体工作效率。解决“我懒得做”及“我不擅长做”的事。如服务于一线研发人员的内容生成工具（文档、编码、测试、发布、运维），提升生产力。AI是对专业工作的增强。对人的要求是需要更广的知识面，提升意图表达的能力。LLM as Co-Integrator：跨研发职责及角色的协同增效。基于AI的研发工具平台解决不同的角色之间辅助沟通。解决信息沟通对齐的问题，提升角色间互动效率。如服务于一线管理人员的协作辅助工具，提升协同效率，如需求选择、排期、协同发布等。AI需要提供跨领域（职能）的知识管理。对于人而言，需要为AI提供上下文，完成知识对齐。LLM as Co-Facilitator：影响软件研发流程的角色分工，基于AI的研发工具平台辅助决策。辅助计划、预测发现和协调的工作。解决信息整合分析、决策依据，提升组织决策效率。如服务于管理层提供更多的知识洞见，辅助管理决策。AI提供跨学科“会诊”的能力。对于人才的培养，需要越来越复合型人才。</p><p></p><p>3.&nbsp;人机的交互形式发生演变</p><p></p><p>人机交互的体验升级，帮助研发人员善用AI的能力。提示工程成为重要的研发实践。从命令式， 到声明式，再到意图导向。所有的工具和平台都需要提供AI的能力，并基于此进行重大升级。</p><p></p><p>4.&nbsp;数字安全的要求越来越高</p><p></p><p>涉及到监管、隐私及数据安全的要求，在工具和平台体系建设上，会有更多的安全策略及数字围栏的要求。专业领域大模型、私有大模型、数据安全领域的工具的建设成为必需品。</p><p></p><h3>亟需解决的问题</h3><p></p><p></p><p>1.&nbsp;模型成本的问题</p><p></p><p>大型模型成本包括硬件成本和能源成本两个方面。一方面，大型模型需要大量的计算资源和存储资源，因此需要购买高端的服务器、显卡、内存、存储设备等硬件设备，这些设备的价格往往很高。另一方面，大型模型需要大量的能源来提供计算和存储服务。高性能服务器和显卡的功耗通常很高，需要耗费大量的电能，这也是成本的主要来源之一。除此之外，大型模型的训练和调优需要大量的时间和人力成本。需要专业的技术人员进行模型的设计和调优，以及对训练过程进行监控和优化。</p><p></p><p>2.&nbsp;数据安全及监管要求</p><p></p><p>LLM需要使用大量的用户数据和企业研发数据，包括个人身份信息，企业代码信息等，如果这些数据被黑客入侵或内部人员泄露，将导致用户的个人隐私及企业知识产权受到侵犯。需要有一套系统的方法实践，来加强数据保护措施，建立完善的安全管理机制，监测和处理潜在的安全风险。同时，不同国家和地区的政策法规的要求不同，需要有清晰的政策法规，明确LLM的工具和平台的相关规定和要求，如数据隐私保护、公平性、模型透明度等方面的要求，以及相应的监管措施。</p><p></p><h2>主题5：人员能力计划和培养</h2><p></p><p>&nbsp;</p><p>软件工程本质上是人类大规模的脑力协作，由于高复杂度而催生出了不同的专业角色分工。LLM在软件工程的采用，将在众多工程领域产生突破，甚至于颠覆，由此也敦促我们必须认真审视专业能力的变迁和专业角色的定义。LLM及相关的AI技术仍然在高速演进中，我们很难精确地针对未来的专业人员进行能力建模，但我们认为必须建立开放合作的产学研社区，才能够推动LLM在软件工程领域的高质量应用，保证人才资源的可持续发展。</p><p></p><h3>达成的共识</h3><p></p><p></p><p>坚守以人为本：新兴技术的应用是以创造人类更美好的工作和生活环境为初心，虽然LLM为代表的AI技术浪潮给大家展现了未来可期的颠覆，但我们坚信只有不忘初心，一切美好才能够最终实现。打造数字化世界的软件工程仍然需要人类进行大规模的脑力协作，LLM的加入并不改变这一本质。在采用LLM重塑软件工程的旅途中，帮助研发团队及各专业人员提升效率、增强职业幸福感应该是应用的首要出发点。</p><p></p><p>保持开放合作：面对AI技术的持续发展，软件工程产生新范式已经是不争的趋势，然而新范式的具体方法和实践还需要相当长的一段时间去试验和沉淀。在互联网、大数据及云计算领域，我们见证了全球知识开放共享带来的巨大行业发展，推动了很多复杂问题上的智力共创。我们相信在软件工程新范式演进的过程中，这种开放合作的模式需要强化；在采用LLM的新型工程方法及实践的探索和沉淀上，我们也需要在人员能力计划和培养上保持这种开放心态，为一线研发人员创造安全的试错空间。</p><p></p><h3>可见的重大机会</h3><p></p><p></p><p>1.&nbsp;利用LLM辅助各研发专业提效</p><p></p><p>目前在开发人员中形成的copilot模式将逐步成熟，并延伸到研发相关的其他专业，从而显著提升从需求分析、产品设计到测试验证各个环节专业人员的工作效率，大幅度减少事务性重复劳动，使其更加专注于软件研发中的创造性劳动。</p><p></p><p>2.&nbsp;利用LLM降低研发各角色协同成本</p><p></p><p>由于个体脑力限制难以应对与日俱增的软件“复杂性”本质难题，而大规模集体脑力协作的背景下，软件研发过程中大量时间花费在了不同专业、不同思维个体之间的交流和共识之上。LLM在知识存储上的全面性、以及在推理问题上的针对性，能够被有效利用来促进跨角色之间的高效沟通，并且有可能更加精准地协调相关专业资源的调配及相关问题的发现。</p><p></p><p>3.&nbsp;利用LLM形成更高效的知识管理和培养体系</p><p></p><p>软件研发面临着业务持续演进和技术持续发展的双重高“可变性”，往往造成研发过程中知识积淀的碎片化，从而很难建立高效的人员培养体系。LLM针对数据的持续学习和推理能力，给我们打开了知识管理的新可能。研发过程中的数据有可能成为LLM的学习语料，持续扩展LLM的知识上下文，进而加快研发团队在人员能力培养上的步伐。</p><p></p><h3>亟需解决的问题</h3><p></p><p></p><p>1.&nbsp;LLM重塑软件工程的目标及方向</p><p></p><p>LLM的崛起给我们展现了现代技术突破“涌现”的特质，某一个领域的爆发并非是一个单点技术的突破，而是多项技术持续发展和交汇的结果。这种涌现性带来了发展目标上的不确定性，由此也带来了一些研发组织在采纳LLM时，以降本为主要目的急功近利，缺乏针对软件工程的全局性思维，很容易引入安全合规等方面的系统性风险。从交付价值的角度出发，研发各专业人员能力要求的变化，以及对应的分工变化，是更需要持续解决的问题。</p><p></p><p>2.&nbsp;相关专业社区的建立和相关课题的研讨</p><p></p><p>本次LLM催化的软件工程范式变革牵涉广泛，涉及到软件工程的整个产业链，由此也需要产、学、研、媒针对不同专业形成社区，开展持续的碰撞和研讨。研讨的方向不仅仅局限于目前LLM带来的研发方法和实践的改造，也需要考虑针对新方法和新实践的能力要求，以及如何才能有效地培养专业人员。特别是高校在未来人才培养方向上，如何适应LLM带来的新技能要求，如何帮助新一代建立正确的模型价值观。</p><p></p><h2>主题6：代码智能</h2><p></p><p>&nbsp;</p><p>代码智能是指根据工程师意图自动补全和生成代码，特别是利用大语言模型的知识储备和生成能力，自动编写、优化、分析、查错。编码是一种更为严谨的写作，编码也是一个典型的规划和推理过程，期间工程师会调取丰富的上下文并利用来自于领域和遗留系统中的隐性知识，因此利用大语言模型辅助编码，特别是完成完整的需求编码任务，相比文字写作更具挑战，更有趣。</p><p></p><h3>达成的共识</h3><p></p><p></p><p>1.&nbsp;大模型让代码智能领域的工作再次活跃起来，应用生态发展迅猛</p><p></p><p>Copilot的出现让大家看到了大模型的威力，惊叹于其代码补全、缺陷识别等方面的能力。类似的工具，比如Bloop、Cursor等等，从不同角度探索代码检索、问答与补全的应用。工程师哪怕直接通过ChatGPT、Claude等工具也能方便地完成诸如代码解释、测试代码生成、优化代码设计等有趣的工作。</p><p></p><p>与会的百度、阿里巴巴、蚂蚁集团、招商银行、Thoughtworks等公司，阿里云云效、aiXCoder等工具厂商也在积极尝试调优擅长编码的大模型，特别是利用企业私有代码调优大模型，并利用其生成使用公司私有组件和库的函数，包括尝试模拟工程师的思考过程一步步写公司需求的代码。还有同学尝试如何利用大模型辅助软件设计。虽说现在的效果很难达到令人满意的程度，但都扎实地走在代码智能的路上。</p><p></p><p>2.&nbsp;对不同性质编码工作的生产力提升效果参差不齐</p><p></p><p>对于陌生语言或领域入门、通用算法生成等方面效果显著，而对于开发熟手、或在大规模软件中参与协作的工程师来说帮助就相对小些，相信未来会逐步覆盖更多性质的开发工作，这需要一个过程。另外，利用大语言模型也会让非专业工程师有机会开发一些应用，比如在ChatGPT的指导下利用外部工具打造个人应用，这对参与者来说效果非常显著。我们做了分析探讨，认为对于专业大型软件开发团队来说，仅仅依靠代码智能，在中短期内整体效能很难实现非常显著的提升。</p><p></p><p>3.&nbsp;利用大模型从需求逐步生成代码以及辅助软件架构设计的挑战很大</p><p></p><p>从需求生成代码目前效果不太理想，当然这方面的尝试也仅有短短几个月时间，其中也面临不少需要深入挖掘的问题：如何模拟工程师的规划和推理过程？如何获取有效的上下文？如何表达工程师使用的领域及系统的隐性知识？如何设计交互过程？如何选择适合子任务的模型？如何有效地针对私有代码调优模型？等等，这些问题都需要反复实践，甚至要更强模型的出现。</p><p></p><p>辅助软件架构设计也是一个难题。模型应该如何有效学习到设计知识？Github上有大量优秀的项目，但如何表达其架构设计？决定设计选择的外因在哪？设计演进的过程能分析到吗？如何表达设计意图？这些或许都需要更多的投入和时间。</p><p></p><p>4.&nbsp;私有代码大模型是追求代码智能极致效果的必经之路</p><p></p><p>最终，我们是希望利用大模型帮我们完成需求代码的，而不仅仅是基于通用编码知识补足片段。通过in-context learning的方式能一定程度解决模型学习私有代码和设计的问题，但配合公司私有代码调优后的大模型才会拿到最佳的续写效果。</p><p></p><h3>可见的重大机会</h3><p></p><p></p><p>1.&nbsp;每位工程师都面临着提升自己竞争力的巨大机会</p><p></p><p>充分利用Copilot的工程师尝到了甜头，更有工程师在积极尝试提示词工程，在各个场景下帮助自己提效，甚至据此开发小应用，提出内部工具创意和业务创新的建议，团队也能感受到他们的提升和贡献。这对工程师来说并没有很高的门槛，每位工程师都有机会从中获益，就像当年会用搜索引擎的工程师总会先人一步。</p><p></p><p>2.&nbsp;每家软件企业都有机会受益于大模型时代提效的红利</p><p></p><p>对公司来说，这往往不需要多大的投入，其效率提升的比例通过传统手段则是极难获得的，因为代码智能深入到了生产力的最核心环节。</p><p></p><p>3. 有条件调优/训练代码大模型的企业将有机会获得更大优势</p><p></p><p>在通用大模型基础上针对下游任务调优私有代码大模型会涉及到不菲的成本，包括数据准备和模型训练的成本。为追求效果，也会逐渐选用更大的基础模型，从8B到13B再到20+B甚至60+B，成本也会随之增加，这也会形成一定的壁垒。</p><p></p><p>4.&nbsp;副驾工具及模型服务中有巨大商业机会</p><p></p><p>稳定的工具市场会面临洗牌的机会，小厂商拼创新也有机会，大厂商在模型服务上优势明显。</p><p></p><h3>亟需解决的问题</h3><p></p><p></p><p>1.&nbsp;企业内外的信息安全问题亟待解决</p><p></p><p>这是最直接的挑战，各公司态度松紧不一，面临的风险较大，需要有系统性的方案。使用Copilot，代码片段会跨越公司安全边界，而这对于绝大部分企业都是不被允许的。如果企业利用私有代码调优/训练模型，这意味着访问模型的人有相同的代码权限，对于内部开源的企业还好，否则也打破了原有的权限管理机制。</p><p>&nbsp;</p><p>6月4日5日于杭州</p>",
    "publish_time": "2023-06-15 14:22:27",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "OPPO 数智工程系统安全与隐私部网络技术专家李龙彦确认出席 ArchSummit 深圳",
    "url": "https://www.infoq.cn/article/DNsgCIZPyPRCxXZ86BHL",
    "summary": "<p>7&nbsp;月&nbsp;21&nbsp;日&nbsp;-&nbsp;22&nbsp;日，&nbsp;在&nbsp;<a href=\"https://archsummit.infoq.cn/2023/shenzhen?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">ArchSummit&nbsp;全球架构师峰会（深圳站）</a>\"，OPPO&nbsp;数智工程系统安全与隐私部网络技术专家李龙彦，将于会上发表题为《QUIC&nbsp;协议在分布式系统架构中的实践》主题分享，重点介绍&nbsp;QUIC&nbsp;在业务场景的应用和优化，分享&nbsp;OPPO&nbsp;在&nbsp;QUIC&nbsp;协议上的优秀方案。</p><p></p><p>李龙彦现就职于&nbsp;OPPO，数智工程系统安全与隐私部网络技术专家。从端到云、从&nbsp;0&nbsp;到&nbsp;1&nbsp;构建了&nbsp;OPPO&nbsp;的&nbsp;QUIC&nbsp;协议，并在&nbsp;OPPO&nbsp;多个业务落地且取得了很好的优化效果。</p><p></p><p>相信通过李龙彦的分享，你将了解到&nbsp;QUIC&nbsp;协议的原理、部署架构，及其实现过程的难点、问题以及解决方案。</p><p></p><p>除上述议题外&nbsp;，ArchSummit&nbsp;深圳还将围绕<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1537?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">基础架构技术</a>\"、<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1532?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">DataOps、Data&nbsp;Fabric&nbsp;等高效数据开发与服务模式</a>\"、<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1534?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">Mesh&nbsp;技术实践案例</a>\"、<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1535?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">QUIC&nbsp;传输和架构优化</a>\"等进行分享。</p><p></p><p>数十位业界专家，上百个国内外一线大厂前沿技术案例，一定会给你带来很多全新的开发灵感。期待与你线下交流！&nbsp;现在购票，享&nbsp;9&nbsp;折特惠，立省&nbsp;¥880！咨询购票请联系&nbsp;18514549229（微信同手机号）</p><p><img src=\"https://static001.infoq.cn/resource/image/9d/aa/9d6a27547062ee2e089f91bdc4ba1eaa.png\" /></p><p></p>",
    "publish_time": "2023-06-15 15:38:22",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "GitHub Copilot：做出一个划时代的产品，只需要6个人",
    "url": "https://www.infoq.cn/article/fX11amN5CkOXkY4bgSdq",
    "summary": "<p>当前，Copilot 已经成为国内开发者常用的辅助工具。就像有的开发者评价称， “编码时，我希望干扰最少。在这方面，Copilot 给我提供了巨大的帮助。它减少了我可能花在网络上寻找解决方案的时间，而且它们在我最喜欢的 IDE 中触手可及。”Copilot带来了很多便利。</p><p>&nbsp;</p><p>虽然人工智能和自动化很早就成为开发者工作流程中的一部分了，但由GitHub和OpenAI开发的、基于云的人工智能工具 Copilot 让大家真正感受到了“智能”的力量。根据Stack Overflow最新发布的开发者报告，Copilot 如今是最受欢迎的开发者搜索工具。那这样一款“划时代”的工具是如何打造出来的呢？</p><p>&nbsp;</p><p></p><h2>六个人的默默研发</h2><p></p><p>&nbsp;</p><p>“我们差不多就是个臭鼬工厂（特指以秘密研究计划为主的项目），没有人知道我们。”GitHub Copilot创建者之一的<a href=\"https://twitter.com/alexgraveley/status/1607897474965839872\">Alex Graveley</a>\"回忆道，Copilot 是根据创业原则，由一个小团队在不到一年的时间里，在“非常不正常的 GitHub/MSFT 组织中”开发出来的。在这个团队里，开发者只有6位，此外还有一个 PM 和一个VP主要负责登陆页面和图标方面的工作。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1f/1f3b246dbe438fb732efe4fc9a2eb631.png\" /></p><p></p><p>Alex 不确定具体是从什么时候开始的，但当时OpenAI和微软已经就超级计算设施达成了协议，想要构建一套大型训练集群。他们还在制定另外的合作协议，可能会把AI相关条款引入Office和Bing。GitHub当然也不例外，他们想试试AI在开发中能发挥什么作用。</p><p>&nbsp;</p><p>OpenAI打算对模型做一点微调，看能不能用小模型更好地辅助编程。什么叫“小”模型？当时不团队里的人都不知道该把规模控制在怎样的程度，但能确定的是绝不搞得参数巨多、体量巨大。Alex 回忆道，这个“小”模型还没有 Davinci 大。</p><p>&nbsp;</p><p>OpenAI的基础模型就像是个训练工件。他们想把代码引入进去，看看自己的基础模型会作何反应。“我觉得这对思维链产生了积极的影响。毕竟代码推理具有明确的线性，而AI模型应该比较适应这种一件件事做下去、前一件事对后一件事产生影响的应用场景。”Alex 表示。</p><p>&nbsp;</p><p>但刚开始的效果并不理想，甚至可以说相当糟糕。毕竟这只是一款底层工件，又遇上了GitHub上的一小部分数据样本。当时就只有Alex 和另一位机器学习工程师Albert Ziegler在摆弄这套模型。他觉得虽然多数情况下都不起作用，但这套AI模型似乎正在积蓄力量。</p><p>&nbsp;</p><p>最开始，他们投喂的数据只有Python代码，想据此让它做出有用的输出。“我们啥也不懂，所以就先从简单处入手，投身去试。看看这样行不行，看看那样行不行。坦白讲，我们根本不知道自己在干什么。所以第一项任务就是多做测试，看它能做什么。”</p><p>&nbsp;</p><p>Alex 他们在内部众包整理出一大堆Python问题，这些都是肯定不会出现在训练集中的内容。之后他们开始挑选repo并设计测试，看看模型生成的函数到底能不能过关。基本过程就是要求模型生成相应函数，然后运行测试看给出的函数能否通过。</p><p>&nbsp;</p><p>刚开始的通过率很低，大概是10%的水平。之后团队开始给模型更多的尝试，试着让它慢慢摸索出解决思路。在其他独立测试中，Alex 他们还会编写测试函数，然后试着让它填充函数体。如果可以过关，就证明它确实有效。在野外测试中，他们会下载一个repo并运行所有测试，而后查看通过了哪些测试、调用了哪些函数、能否正确生成函数体，再重新运行测试看是否顺利通过。最后，把结果记录下来再核算百分比。</p><p>&nbsp;</p><p>可以想见，前期测试的通过百分比是相当相当低。因此，团队开始把GitHub上的所有代码都投喂给模型，还引入了其他一些新的、起步阶段根本没想到过的技巧。最终，它在野外测试中的通过率从不到10%提升到了60%以上。换言之，随便给它两项代码生成测试，它基本就能通过其中一项。“这是个循序渐进的过程，从10%到20%，再到35%和45%，就这样慢慢提升。”</p><p>&nbsp;</p><p>在探索过程中，团队还尝试提高提示词的设计质量，在特定环节上对它做出引导。这套模型接触到的可是代码的所有版本，而不只是最新版本，配合diffs让模型能理解不同版本间的微小区别。</p><p>&nbsp;</p><p>“总之，它最后变得更好、更强。但至少在起步阶段，一切都只能从零开始，我们就像懵懵懂懂的孩子。唯一的想法就是，也许这东西终有一天能取代Stack Overflow以及其他开发工作流工具。”Alex 说道。</p><p>&nbsp;</p><p></p><h2>再前进一步</h2><p></p><p>&nbsp;</p><p>Copilot的首个迭代版本只能算是一种内部工具，能帮人们编写一些简单测试。之后团队开始试着生成常用的UI。“毕竟刚开始它生成代码的通过率只有10%，而UI设计其实是个比较开放的问题，也许能回避AI能力不行的事实。如果成功那就太棒了。”</p><p>&nbsp;</p><p>所以，接下来，团队开始对模型做微调和测试。另外，他们又想让他实现VS Code扩展的功能，比如说代码自动补全？当时的 Alex 觉得这应该没有问题，而向自动补全的探索也代表着巨大飞跃的来临。“虽然终极目标仍然是替代Stack Overflow，但起步阶段我完全想不出这一切要怎么实现，先在VS里实现点功能才是真的。”</p><p>&nbsp;</p><p>“作为我们的一小步，自动补全功能实现了，而且有趣且有用。它会像其他自动补全功能一样弹出一个提示框，供大家选择其中的字符串。这种使用形式便捷且容易上手，很舒服。我们还试过其他一些功能交付方法，比如在空函数上添加一个小按钮，由它为开发者快速生成；或者开发者可以点击控制键，再从弹出的大列表中随意选择。总之，我们几乎试遍了自己能想到的所有VS Code UI。” Alex 说道。</p><p>&nbsp;</p><p>虽然一切暂时还处于起步阶段，但它提供的推荐列表可以说“日新月异”来形容。毕竟这时模型只接触过小部分样本，所以仅可作为技术爱好者和测试设计人员的玩具。团队希望它能变得像Gmail的文本自动补全功能一样好用。</p><p>&nbsp;</p><p>“我特别喜欢那款产品。那可是大语言模型的首次部署成果，速度很快、效果也很好。谷歌还专门发论文分享了具体技术细节和细节调整。我们就朝着这个方向努力，刚开始补全效果很不好，但却让人感觉它一直在朝正确的方向前进。就这样反复尝试和调整之后，终于拿出了一段小小的演示视频。” Alex 表示。</p><p>&nbsp;</p><p>Alex <a href=\"https://twitter.com/alexgraveley/status/1668305064925048855\">回忆称</a>\"，当时团队每天工作 12 小时，克服阻碍，忽略最佳实践。当时只有 CEO、副总裁和团队的人相信这件事，其他人比较质疑。</p><p>&nbsp;</p><p></p><h2>微软推向全球的努力</h2><p></p><p>&nbsp;</p><p>在发布通用版之前，Copilot 已经开放过公测，免费供大家使用，而且针对不同群体做了很多优化。比如经验丰富的程序员会怎么用，新人开发者会怎么用，还有不同国家的地区的用户会有怎样的习惯和倾向。</p><p>&nbsp;</p><p>Copilot 团队收集了一大堆统计数据，并意识到速度在任何群体中都是最重要的指标。“我们发现延迟每增加10毫秒，就会有1%的用户放弃这项功能。另外在新功能公开发布的头几个月，印度的使用完成率是最低的——不确定为什么，但完成率确实明显低于欧洲。”</p><p>&nbsp;</p><p>后来团队发现，这是因为OpenAI只有一处数据中心，而且位于美国得克萨斯州。可以想见，如果数据需要从印度穿过欧洲和大西洋再最终抵达得克萨斯，那来来回回的延迟肯定令人抓狂。这就会导致提示节奏和输入节奏脱节，功能完成率必然会受影响。</p><p>&nbsp;</p><p>在找到症结之后，团队成员们也就释然了。而跟得州不远的用户们纷纷给出好评，比如有人会评论说，“我不会编程，但出于工作需要，我想了解怎么编写某个100行长的脚本。”事实证明，AI模型特别擅长这种开发模式，而在找到模式之后，设计出来的UI就能派上用场。</p><p>&nbsp;</p><p>后面就迎来了团队的“高光时刻”：发布成果，获得市场好评，然后尽快再更新和迭代。</p><p>&nbsp;</p><p>“有客户表示，他们听说Azure打算在未来半年内全面承接OpenAI，但他们等不及了，最好下个月就开放。”Alex 说道，团队当时就想办法满足这些要求，比如在欧洲和亚洲提供基础设施，把AI模型拉近到西海岸、得克萨斯乃至欧洲所有用户身边。微软在这方面投入了巨大努力，而在设施准备就绪并投入运行之后，Copilot就这样正式跟大家见面了。</p><p>&nbsp;</p><p>“没有 OpenAI 的天才和有原则的 VSCode 编辑人员，Copilot 是不可能的。”Alex 表示。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://sarahguo.com/blog/alexgraveley\">https://sarahguo.com/blog/alexgraveley</a>\"</p><p><a href=\"https://twitter.com/alexgraveley/status/1607897474965839872\">https://twitter.com/alexgraveley/status/1607897474965839872</a>\"</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-06-15 16:37:51",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "QCon 全球软件开发大会广州站优秀出品人与明星讲师名单公布",
    "url": "https://www.infoq.cn/article/cdQeMh7OtPx8yrrIkKSN",
    "summary": "<p>5 月 26 日至 5 月 27 日，QCon 全球软件开发大会（广州站）在广州粤海喜来登酒店成功举办，为业内专业人士和技术爱好者们带来了一场知识的盛宴。</p><p>&nbsp;</p><p>本次大会由 2 位联席主席坐镇总揽，12 位专题出品人为大会内容严格把关。在为期 2 天的会议中，80 位来自国内外软件行业的技术专家围绕 14 个专题带来了专业而精彩的内容分享。包含平台工程、稳定性即生命线、出海的思考、AGI 与 AIGC 落地、AIGC效能智能化、大前端技术探索、下一代软件架构、编程语言实战等众多领域。</p><p>&nbsp;</p><p>这些深入研讨的专题内容，为参会者提供了宝贵的学习和交流机会，帮助他们深入了解行业的前沿动态，并探索应对未来挑战的新思路与解决方案。</p><p>&nbsp;</p><p>会议结束后，我们根据前期内容准备情况、现场观众反馈等因素，综合评选出了 4 名优秀出品人与 13 名明星讲师。</p><p>&nbsp;</p><p>优秀出品人揭晓</p><p>指导本次大会的 12 位专题出品人均为各自领域的资深专家，他们负责为各自专题的分享内容把关，前期投入大量时间打磨议题、审核演讲材料等。出品人为讲师与组委会提供了很多有价值的建议，确保了大会内容的高水平与技术深度。</p><p>&nbsp;</p><p>优秀出品人的评选由组委会统一进行，需满足如下条件：在大会筹备期间，和组委会一起给予讲师专业且中肯的建议，帮助讲师优化内容和演讲技巧，最终使得专题场均满意度 90% 以上。最终选出优秀出品人 4 位，名单如下：</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/73/73b6d4bbc6db2ecf95579dd59bd98a72.png\" /></p><p></p><p>明星讲师揭晓</p><p>QCon 大会的讲师招募采取邀请制，同时也会公开征集议题。演讲议题需满足“观点明确、以实践出发、分享内容有深度、专业声誉、禁止广告、听众收获”六方面的要求。要在众多水平优秀的讲师中赢得“明星讲师”的称号，演讲人除了要带来兼具深度与实用性的分享内容外，还要在现场有着良好发挥，满足单场听众满意度 90% 以上等条件。本次获评明星讲师的演讲人共计 13 位，名单如下：</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/3d/3d901120fdb2b506857e9bef4b47949e.jpeg\" /></p><p></p><p>近年来，软件行业面临种种挑战，还迎来了 AI 大模型的冲击。业内众多从业者的坚定支持让我们度过重重困境。接下来，QCon 将坚持信念，传递前沿技术与优秀实践，与大家一同应对 AI 带来的全新挑战，开创软件行业的新时代。</p><p>&nbsp;</p><p><a href=\"https://qcon.infoq.cn/202309/beijing/track?utm_source=infoqweb&amp;utm_medium=mxteacher&amp;utm_campaign=8&amp;utm_term=0615\">QCon 全球软件开发大会·北京站</a>\" 将以「启航·AIGC软件工程变革」为主题，于 9 月 3-5 日在北京•富力万丽酒店举办，此次大会策划了大模型应用落地、LLMOps、AIGC 浪潮下的研发效能提升、异构算力、微服务架构治理、业务安全技术、面向 AI 的存储、构建未来软件的编程语言、FinOps 等方向，扫码咨询优惠购票政策。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a5/a5074608875d8ed88c3e56d038542691.png\" /></p><p></p><p>大会议题同步征集中，<a href=\"https://qcon.infoq.cn/202309/beijing/topic?utm_source=infoqweb&amp;utm_medium=mxteacher&amp;utm_campaign=8&amp;utm_term=0615\">戳此参与</a>\"，期待与各位开发者现场交流。</p>",
    "publish_time": "2023-06-15 17:15:58",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]