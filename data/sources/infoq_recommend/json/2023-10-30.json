[
  {
    "title": "Contentsquare跨多个服务的通知解决方案：微服务和Apache Kafka",
    "url": "https://www.infoq.cn/article/6PR40uZ9o0o4UcSwEf2d",
    "summary": "<p>Contentsquare平台的许多场景都需要通知功能。作为其微服务架构的一部分，<a href=\"https://engineering.contentsquare.com/2023/building-a-reliable-notification-system/\">该公司创建了一个跨多个服务的通用解决方案</a>\"。在实现过程中，开发人员改进了可观察性，同时还克服了一些可扩展性挑战。</p><p>&nbsp;</p><p>Contentsquare的通知功能可以用于密码重置、API配额超标告警等，并根据用户的喜好通过电子邮件、Slack或Microsoft Teams发送。该公司选择循序渐进地推出与通知相关的功能，以便在需要时提高性能和可扩展性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/24/24eefad035379f00730ba322d4f54791.jpeg\" /></p><p></p><p>通知组件（来源：<a href=\"https://engineering.contentsquare.com/2023/building-a-reliable-notification-system/\">Contentsquare工程博客</a>\"）</p><p>&nbsp;</p><p>Contentsquare的平台使用了微服务架构，通知子系统由几个微服务组成。Notification Consumer负责处理来自<a href=\"https://kafka.apache.org/\">Apache Kafka</a>\"主题的消息。Mailer Service用于电子邮件通知发送，并使用<a href=\"https://ejs.co/\">EJS模板引擎</a>\"根据预配置的模板呈现电子邮件内容。最后，Integration Service负责Slack和Microsoft Teams通知，它将基于<a href=\"https://api.slack.com/block-kit\">Slack的Block Kit</a>\"或<a href=\"https://learn.microsoft.com/en-us/microsoftteams/platform/task-modules-and-cards/cards/cards-reference#adaptive-card\">Microsoft Teams Adaptive Cards</a>\"编写JSON消息体。Slack Service和Microsoft Teams Service（如下所示）分别负责向Slack或Microsoft Teams API发送通知消息。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0a/0a2321559a4fa3e5b9b282170ac54b04.jpeg\" /></p><p></p><p>用于向Slack和Teams发送通知的微服务（来源：<a href=\"https://engineering.contentsquare.com/2023/building-a-reliable-notification-system/\">Contentsquare工程博客</a>\"）</p><p>&nbsp;</p><p>Contentsquare软件工程师<a href=\"https://www.linkedin.com/in/jbanzio/\">Joseph-Emmanuel Banzio</a>\"分享了该团队在推出通知功能时的经验：</p><p></p><blockquote>在此过程中，我们遇到了几个瓶颈，为此，我们扩展并增强了系统的可靠性。一个值得注意的挑战是，在创建Notifications主题之前，我们最初使用了单个Kafka主题进行微服务间通信。在我们发布实时告警测试版之前，这个功能一直运行良好。</blockquote><p></p><p>&nbsp;</p><p>除了使用专用的Kafka主题进行告警通知外，该团队还优化了通知存储，以免读取时出现高延迟。他们实现了一种数据保留机制，用来删除旧的通知记录。另一个需要调查的问题是，一些用户没有收到电子邮件。经过仔细研究，这是由于SPF（<a href=\"https://en.wikipedia.org/wiki/Sender_Policy_Framework\">Sender Policy Framework</a>\"）配置错误引起的，安全团队已经解决了这个问题。</p><p>&nbsp;</p><p>为了帮助解决电子邮件通知问题，该团队创建了一个专门的电子邮件可观察性解决方案。其中，它会定期检索第三方电子邮件服务收集的发送事件并存储在Contentsquare的平台中。这种方法提供了电子邮件通知流的端到端可见性。</p><p>&nbsp;</p><p>在该功能上线的过程中，开发人员还致力于提高了平台的可观察性。他们创建了一个<a href=\"https://www.elastic.co/kibana\">Kibana</a>\"仪表板来监控和分析日志，一个<a href=\"https://grafana.com/\">Grafana</a>\"仪表板来监控通知微服务使用的云资源。此外，该团队还扩展了对Kafka生产集群的监控，以确保资源利用率和Consumer Group Lag在可接受的范围之内。将来，该团队计划提升系统弹性，以防系统故障，并提高通知发送的及时性，实现近实时发送。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/10/contentsquare-notifications/\">https://www.infoq.com/news/2023/10/contentsquare-notifications/</a>\"</p>",
    "publish_time": "2023-10-30 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "程序员篡改ETC余额，一年私吞260余万元；语雀公布故障原因及赔偿方案；各家财报发布，创始人们：就很难受｜Q资讯",
    "url": "https://www.infoq.cn/article/urmClYMAW106DweFJNo4",
    "summary": "<p></p><blockquote>&nbsp;程序员篡改ETC余额，一年私吞260余万元；国内厂商已无法从英伟达下单，寻求国内替代成唯一方案；苦英伟达“一家独大”久矣？甲骨文、IBM 下单 AMD；芯片设计初创公司SiFive裁员20%，此前估值25亿美元；AMD回应大幅裁员：小幅优化和调整；宿华辞任快手科技董事长，CEO程一笑兼任；消息称张一鸣通知负责人：PICO业务看不到希望将关停，字节人士否认；财报一发，没有一个创始人能笑着面对；国家数据局正式揭牌；故障超过 8 小时，语雀公布原因及赔偿方案；小米正式发布小米澎湃OS；华为：全面完成 5G-A 技术性能测试；Mojo 编程语言发布 Mac 版本；Python 公布了实现 no-GIL Python 的计划……</blockquote><p></p><p>&nbsp;</p><p></p><h2>科技公司</h2><p></p><p>&nbsp;</p><p></p><h4>程序员篡改ETC余额，一年私吞260余万元</h4><p></p><p></p><p>2023年9月，上海市公安局浦东分局北蔡派出所接到某科技公司员工张女士报案称，其公司发现计算机系统被他人篡改数据，导致公司账户钱款损失。民警随即展开工作，最终嫌疑人曹某迫于压力，主动投案自首。</p><p>&nbsp;</p><p>2022年8月，曹某发现所在公司的网站后台有漏洞，身为软件工程师的他，决定铤而走险，用其母亲的身份证自行注册了一个ETC账户，并绑定了其母亲的银行卡。随后曹某以每周4至5次、每次1万元的频率，陆续从该账户内提取了230余万元。之后，曹某又利用朋友的身份证再次办理账号，以同样的方式再次从公司提现36万元。</p><p>&nbsp;</p><p></p><h4>国内厂商已无法从英伟达下单，寻求国内替代成唯一方案</h4><p></p><p>&nbsp;</p><p>10月25日，英伟达在向美国证券交易委员会（SEC）递交的一份文件中披露，美国政府通知公司，针对中国更新的“先进计算芯片和半导体制造设备出口管制规则”立即生效，中国云厂商、服务器厂商、销售代理商均已无法从英伟达下单。“出口管制规则”刚出炉时，原定有30天公示期，被行业人士视为“最后30天窗口期”。在窗口期内，中国企业原本可以集中采购、运输急需的高端AI芯片。美国芯片企业出于对中国市场的依赖，理论上也会和中国企业打配合。</p><p>&nbsp;</p><p>按照美国政府最新的要求，“综合性能达到4800或以上，并且是为数据中心设计或销售的产品”将需要“立即停止出口”。NVIDIA给出的说明是，公司A100、A800、H100、H800和L40S产品的发货将立即受到影响。一位云厂商高管表示，美国“出口管制规则”步步紧逼的情况下，规模化采购国产芯片是培育本土产业链的唯一路径。</p><p>&nbsp;</p><p></p><h4>苦英伟达“一家独大”久矣？甲骨文、IBM 下单 AMD</h4><p></p><p>&nbsp;</p><p>因英伟达 GPU 供应紧张，甲骨文与 IBM 转向 AMD 产品。甲骨文计划使用 AMD Instinct MI300X AI 芯片及 HPC 用GPU；IBM 可能采用 AMD的Xilinx FPGA 解决方案。AMD Instinct MI300X 今年 6 月发布，提供强大性能，预计 2024 年供应充足。AMD 拥有足够芯片零部件，可以支撑 MI300 在四季度发布。AMD 的 FPGA 产品线因具有更低的功耗和时延，在AI推理中具有优势。</p><p>&nbsp;</p><p></p><h4>芯片设计初创公司SiFive裁员20%，此前估值25亿美元</h4><p></p><p>&nbsp;</p><p>10月25日消息，当地时间周二美国芯片设计初创公司SiFive表示，公司已裁员约20%，约130人。SiFive总部位于美国加州圣克拉拉，芯片设计均基于RISC-V技术架构，该公司竞争对手是最近上市的英国芯片设计公司Arm。和Arm一样，SiFive的工作专注于芯片底层设计，而不是芯片本身。</p><p>&nbsp;</p><p>SiFive在一份声明中表示：“随着我们发现并专注于最大机会，公司正对所有全球团队进行战略重新调整，为的是更好满足客户快速变化的需求。”SiFive发言人大卫·米勒（David Miller）表示，这次裁员涉及公司所有部门，其中也包括高管团队。他强调，公司的产品线不变。</p><p>&nbsp;</p><p></p><h4>AMD回应大幅裁员：小幅优化和调整</h4><p></p><p>&nbsp;</p><p>近日有传闻称，AMD在中国区大规模裁员。就此，AMD官方回应称：“网络传闻失实。基于公司战略的调整，公司近期对组织架构进行了小幅度的优化和重组。”</p><p>&nbsp;</p><p>同时了解到，为顺应市场的变化，AMD中国区还在为重点领域的业务继续开展招聘。根据此前发布的财报数据，AMD今年第二季度收入54亿美元，环比基本持平，净利润2700万美元，环比增长119％，总收入和调整后每股收益均超出华尔街分析师预期。</p><p>&nbsp;</p><p></p><h4>宿华辞任快手科技董事长，CEO程一笑兼任</h4><p></p><p>&nbsp;</p><p>10月20日晚间，快手科技在港交所发布公告宣布，由于需要专注其他事务，自2023年10月29日起，宿华不再担任董事会董事长，将继续担任执行董事和薪酬委员会成员，其不同投票权不会发生变化，董事长一职由程一笑接任。</p><p>&nbsp;</p><p>两年前的10月29日，快手科技宣布宿华和程一笑调整分工，宿华辞去首席执行官一职，继续担任董事长、执行董事、薪酬委员会委员，负责制定公司长期战略；程一笑出任首席执行官，负责公司日常运营及业务发展。</p><p>&nbsp;</p><p></p><h4>消息称张一鸣通知负责人：PICO业务看不到希望将关停，字节人士否认</h4><p></p><p>&nbsp;</p><p>10月21日消息，有媒体报道称PICO业务将被逐步关停，字节跳动放弃元宇宙。文章引述相关人士的说法称，PICO 负责人近期前往新加坡找张一鸣汇报工作，得到的反馈是字节跳动将逐步放弃 PICO 业务，并称原因是“PICO 所处的硬件领域非字节跳动所擅长，几年下来成绩未达预期、并且看不到未来的希望”。</p><p>&nbsp;</p><p>对此，字节跳动相关负责人向媒体回应称，此消息不实。PICO在正常运营，公司会长期投入XR业务。</p><p>&nbsp;</p><p></p><h4>财报一发，没有一个创始人能笑着面对</h4><p></p><p>&nbsp;</p><p>马斯克在特斯拉财报会上表现像“小婴儿”</p><p>&nbsp;</p><p>金融分析师兼 YouTube 博主凯文・帕夫拉斯（Kevin Paffrath）透露，在特斯拉糟糕的财报电话会议上，其首席执行官埃隆・马斯克（Elon Musk）表现得像个“小婴儿”，几乎要哭出来！Paffrath说：“对于一位公司的领导者来说，抱怨经济形势而不是提出应对计划，这似乎是可悲的！”</p><p>&nbsp;</p><p>据悉，马斯克在电话会议上一度暗示，由于利率上升，借贷成本更高，他将推迟工厂的建设。他说：“如果利率保持在高位，甚至更高，人们购买汽车就会变得更加困难。他们根本负担不起买车的开支。”但Paffrath抨击了马斯克的回应，称这位特斯拉首席执行官“害怕了”，并建议马斯克应该与墨西哥政府谈判达成更好的协议，或者可能“向高收入地区打广告”。Paffrath此前曾呼吁特斯拉向非粉丝推广其产品。</p><p>&nbsp;</p><p>谷歌市值大跌8500亿，云业务Q3收入不及预期</p><p>&nbsp;</p><p>10月25日，谷歌母公司Alphabet发布了截至9月30日的2023财年第三季度财报。财报显示，Alphabet第三季度营收为766.93亿美元，较上年同期的690.92亿美元增长11%，按固定汇率计算同比增长11%；净利润为196.89亿美元，较上年同期的139.10亿美元增长42%。</p><p>&nbsp;</p><p>Alphabet第二季度营收和每股收益均超出分析师一致预期，但是云业务营收不及预期。由于云业务对于Alphabet未来增长至关重要，它的营收不及预期引发投资者担忧，拖累股价在盘后交易中大跌6.65%，市值蒸发1164亿美元(约合8510亿元人民币)。</p><p>&nbsp;</p><p>微软CEO今年薪酬降低11.6%，承认放弃Windows Phone是错误决定</p><p>&nbsp;</p><p>10月25日，微软发布了 2024 年第 1 财季（截至 2023 年 9 月 30 日）财报，其中显示今年微软 CEO 萨蒂亚・纳德拉（Satya Nadella）基于绩效的薪酬有所降低，并且不再与微软 XGP 业务增长情况挂钩。外媒认为这是因为微软 XGP 用户增长连续两年未达到预期目标。</p><p>&nbsp;</p><p>此外，纳德拉在接受媒体采访时候，还承认放弃 Windows Phone 和移动设备是错误决定，这也是微软历史上第三位承认在移动领域犯错的首席执行官。</p><p>&nbsp;</p><p>纳德拉在2014年接替鲍尔默（Steve Ballmer）担任CEO，仅仅一年之后就将鲍尔默任内斥资74亿美元收购的诺基亚手机业务勾销。纳德拉接受采访时候表示微软“退出”手机业务本应该处理的更好。勾销诺基亚手机业务之后，Windows Phone事实上就退出了移动舞台。微软后来推出了运行Android的 Surface Duo和Surface Duo 2智能手机，但由于没有后续产品，也缺乏软件更新，Surface Duo手机品牌的未来悬而未决。</p><p>&nbsp;</p><p>扎克伯格豪赌元宇宙巨亏271亿元，明年AI将成Meta最大投资领域</p><p>&nbsp;</p><p>10月26日，脸书母公司Meta发布了截至 9 月 30 日的 2023 财年第三季度财报。财报显示，Meta 第三季度总营收为 341.46 亿美元，较上年同期的 277.14 亿美元增长 23%；净利润为 115.83 亿美元 (约合 847.55 亿元人民币)，较上年同期的 43.95 亿美元增长 164%。</p><p>&nbsp;</p><p>Meta 创始人马克・扎克伯格 (Mark Zuckerberg) 大力押注的元宇宙业务依旧在“流血”。第三季度，Meta 负责元宇宙业务的现实实验室部门再次营业亏损 37 亿美元 (约合 271 亿元人民币)。对于公司的后续发展，扎克伯格表示在2024年，就工程和计算资源而言，AI将成为Meta最大的投资领域。此外，扎克伯格补充道，为了避免布置大量的新员工，公司将降低一些非AI项目的优先级，并将相关人员转向从事AI工作。</p><p>&nbsp;</p><p>科大讯飞净利大跌，创始人套现25亿</p><p>&nbsp;</p><p>据科大讯飞财报显示，今年第三季度，科大讯飞的营收同比实现2.89%的增长，但公司前三季度的营收却小幅下跌0.37%。利润方面，科大讯飞第三季度、前三季度归属于上市公司股东的净利润分别减少81.86%、76.36%。而前三季度，公司扣除非经常性损益的利润为-3.24亿元。</p><p>&nbsp;</p><p>此次发布的财报中，科大讯飞还提到，截至7月3日，公司2022年7月3日通过的股份回购期限已届满。不过，公司大手笔回购的同时，身为科大讯飞创始人和董事长的刘庆峰却在第三季度减持了公司的股份。若按8月14日科大讯飞63.98元/股的收盘价计算，刘庆峰此次减持预计将套现超25亿元。对此，科大讯飞在公司发布的公告中解释称，此前刘庆峰曾通过质押融资等方式借款筹集资金23.5 亿元，鉴于债务已到期，刘庆峰需要减持股份用于偿还上述借款本金。</p><p>&nbsp;</p><p>另外，因为学习机出现违背主流价值观内容，并引发科大讯飞股价午后跳水触及跌停后，科大讯飞董事长刘庆峰表示，问题出现后，已经第一时间把大模型的安全审核能力放进来，同时也跟公安报备了相应情况。他同时感慨，“中国的创新不容易，我们今天刚发布了星火大模型最新版本，但负面舆情却铺天盖地，这背后是有推手的。”</p><p>&nbsp;</p><p></p><h4>国家数据局正式揭牌</h4><p></p><p>&nbsp;</p><p>10月25日上午，国家数据局正式揭牌。国家数据局负责协调推进数据基础制度建设，统筹数据资源整合共享和开发利用，统筹推进数字中国、数字经济、数字社会规划和建设等，由国家发展和改革委员会管理。</p><p>&nbsp;</p><p></p><h2>IT 业界</h2><p></p><p></p><h4>故障超过 8 小时，语雀公布原因及赔偿方案</h4><p></p><p>&nbsp;</p><p>10&nbsp;月 23 日消息，据多位用户反馈，蚂蚁集团旗下的在线文档编辑与协同工具语雀在 23 日 14:00~15:00&nbsp;之间出现大规模服务器故障，在线文档和官网目前均无法打开。在经历了近 10&nbsp;小时的故障之后，语雀服务现已全部恢复正常，各端语雀都可以正常访问，功能也恢复。</p><p>&nbsp;</p><p>10月24日晚，蚂蚁集团旗下在线文档编辑与协同工具语雀就前一日持续7个多小时的重大服务故障致歉，并公布故障原因及赔偿方案。语雀方面表示，10月23日下午，服务语雀的数据存储运维团队在进行升级操作时，由于新的运维升级工具bug，导致华东地区生产环境存储服务器被误下线。语雀将向所有受到故障影响的用户提供赔偿，针对语雀个人用户将赠送6个月的会员服务，针对语雀空间用户会单独制定赔偿方案。语雀方面强调，用户所有数据均未丢失。</p><p>&nbsp;</p><p>更多详情可以查看：</p><p><a href=\"https://mp.weixin.qq.com/s/LOjiaULzEgkI5VEe74kX0g\">语雀突发 P0 级事故！宕机 8 小时被网友怒喷，运维又背锅？</a>\"</p><p>&nbsp;</p><p></p><h4>小米正式发布小米澎湃OS</h4><p></p><p>&nbsp;</p><p>10月26日，在小米澎湃OS暨小米14系列新品发布会上，小米董事长雷军发表演讲。雷军表示，小米集团宣布全新战略升级：从手机 X AIo，升级到人车家全生态。</p><p>&nbsp;</p><p>而小米澎湃OS也正式亮相。雷军表示，他对澎湃OS提出了五个要求：一、每个独立设备能实现最佳性能表现；二、更加便捷高效的跨端连接；三、成为生态智能大脑，为用户提供主动智能服务；四、实现跨设备全系统隐私安全的坚固防护；五、坚持建设开放生态。</p><p>&nbsp;</p><p></p><h4>华为：全面完成 5G-A 技术性能测试</h4><p></p><p>&nbsp;</p><p>近日，华为全面完成5G-A技术性能测试。华为方面介绍称，5G-A作为5G的演进和增强，连接速率和时延等传统网络能力实现了10倍提升，同时引入了通感一体、无源物联、内生智能等全新的革命性技术。</p><p></p><h4>Python 公布了实现 no-GIL Python 的计划</h4><p></p><p>&nbsp;</p><p><a href=\"https://www.infoq.cn/article/XahMWSZLXwqYo6TWKDvg?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">Python </a>\"指导委员会宣布接受 PEP 703（Making the Global Interpreter Lock Optional，让全局解释器锁成为可选），公布了实现 no-GIL（或称为自由线程）Python 详细的路线图。</p><p>&nbsp;</p><p>Python 的全局解释器锁（GIL）阻止了同时多线程执行代码，成为了在多核 CPU 上提高 Python 代码运行效率的一大障碍，消除这一障碍是好事，但这也有可能会破坏现有的扩展模块，或显著降低性能以及可维护性。而第三方软件包生态系统是 Python 的一大优势，Python 项目在实现自由线程时需要谨慎，需要避免破坏这一优势。推进 PEP 703 需要将其纳入主线，作为定期发布版本的一部分推出。Python 指导委员计划分成三个阶段：实验阶段，支持但不默认阶段，默认阶段。</p>",
    "publish_time": "2023-10-30 08:05:02",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "前端“秀肌肉”，云端 Photoshop 亮相",
    "url": "https://www.infoq.cn/article/8H2DQIB9m4mu5KBSMRxK",
    "summary": "<p>WebAssembly + Emscripten, Web 组件 + Lit, Service Workers + Workbox，以及全新 Web API 在此汇聚。Chrome 和 Adobe 正在携手打造新的图像编辑体验。</p><p></p><p>为 Photoshop 桌面应用程序开发 Web（photoshop.adobe.com）版，标志着将高度复杂和图形密集型软件引入浏览器的一个巨大里程碑。它的诞生离不开 Adobe 工程师们的多年努力，以及同 Chrome 等浏览器供应商的携手合作与 Web 技术本身的持续发展。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/23/23919d6bfe4d48af201aa2ba5d3af2fd.png\" /></p><p></p><p>Photoshop Web 版中包含一系列高级功能，例如生成填充等</p><p></p><p>在本次案例研究中，我们将一同了解现已公布的高级 Web 功能、已经实现的性能优化以及未来有望落地的更多可能性。感兴趣的朋友还可参考《Photoshop 的 Web 之旅》（<a href=\"https://web.dev/ps-on-the-web/%EF%BC%89%E4%B8%80%E6%96%87%E4%BA%86%E8%A7%A3%E6%9B%B4%E5%A4%9A%E7%BB%86%E8%8A%82%E4%BF%A1%E6%81%AF%E3%80%82\">https://web.dev/ps-on-the-web/）一文了解更多细节信息。</a>\"</p><p></p><p></p><h2>发展愿景：让 Photoshop 登陆浏览器</h2><p></p><p></p><p>几十年来，Photoshop 一直是图像编辑和图形设计领域的黄金标准，一直在 Windows 和 macOS 平台上为创意人士提供助力。但随着将其从桌面平台上解放出来，一个充满机遇的新世界也由此敞开了大门。</p><p></p><p>Web 的优势，在于无处不在、顺畅灵活的访问方式。用户只需打开浏览器即可着手编辑和协作，无需任何安装步骤。工作内容还可跨设备实现无缝衔接。</p><p></p><p>通过链接形式共享工作流程。Photoshop 文档可以通过 URL 访问，而不再隐藏于文件系统之内。如此一来，创作者可以轻松将链接发送给其他协作伙伴。</p><p></p><p>轻松实现跨平台操作。作为运行时，Web 抽象掉了底层操作系统，使得 Photoshop 能够覆盖用户手中的多种不同平台。</p><p></p><p>但实现这个愿景也面临着巨大的技术挑战，工程师们需要重新思考 Photoshop 这样强大的应用程序要如何在 Web 上运行、起效。</p><p></p><p></p><h2>全新 Web 功能，释放 Photoshop 潜力</h2><p></p><p></p><p>近年来，新的 Web 平台功能不断涌现。依托各种标准化和实施成果，Photoshop 级的应用程序终于具备了登陆 Web 端的可能性。Adobe 工程师也在项目中创新性地使用了几大关键下一代 API。</p><p></p><p></p><h2>使用 Origin 私有文件系统，实现高性能本地文件访问</h2><p></p><p></p><p>Photoshop 在操作中需要读取和写入大量 PSD 文件，这就要求其必须高效访问本地文件系统。新的 Origin 私有文件系统 API（OPFS）就提供一套指定特定数据源的快速虚拟文件系统。</p><p></p><p><code lang=\"null\">const opfsRoot = await navigator.storage.getDirectory();\n</code></p><p></p><p>OPFS 能够快速创建、读取、写入和删除文件。例如：</p><p></p><p><code lang=\"null\">// Create fileconst file = await opfsRoot.getFileHandle('image.psd', {create: true});// Get read/write handleconst handle = await file.createSyncAccessHandle();// Write contents handle.write(buffer);// Read contentshandle.read(buffer);// Delete fileawait file.remove();\n</code></p><p></p><p>对于绝对速度最快的同步操作，Web Workers 能够使用 FileSystemSyncAccessHandle。</p><p></p><p>这种本地高性能文件系统，让 Photoshop 具备了在浏览器端严格处理文件工作流程的能力。</p><p></p><p></p><h2>释放 WebAssembly 的力量</h2><p></p><p></p><p>WebAssembly 的任务，是使用 JavaScript 重新创建 Photoshop 计算密集型图形处理体系的重要前提。Adobe 使用 Emscripten 编译器将其现有 C/C++ 代码库移植成了 WebAseembly 模块。</p><p></p><p>其中，WebAssembly 的以下重要功能发挥了关键作用：</p><p></p><p>Threads —Photoshop 使用工作线程以并行方式处理任务，例如处理图像图块：SIMD — SIMD 矢量指令用于加速像素操作与过滤。异常处理 — C++ 异常在 Photoshop 代码库中得到广泛应用。流实例化 — Photoshop 的 80 MB+ WASM 模块离不开流式编译的支持。调试 — Chrome 的 WebAssembly 调试支持在 DevTools 中发挥着重要作用。运用 P3 宽色域</p><p></p><p>P3 那宽广的色域足以令 sRGB 色谱相形见绌，但长期以来，后者一直是 Web 端上的唯一选择。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d8/d862dfc5c411182ed03cfdcb69474b91.png\" /></p><p></p><p>如今，Photoshop 使用新的 color() 函数与 Canvas API 将 P3 充分运用起来，带来了更加准确的色彩表现。</p><p></p><p><code lang=\"null\">color: color(display-p3 1 0.5 0)\n</code></p><p></p><p></p><h2>Web 组件让 UI 更加灵活</h2><p></p><p></p><p>Photoshop 属于 Adobe 整体 Creative Cloud 生态系统中的组成部分。使用基于 Lit 构建的标准化 Web 组件策略，即可实现跨应用程序的 UI 一致性。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f8/f8f57c523e50e0f71c5dc4807c066705.png\" /></p><p></p><p>Photoshop 的 UI 元素来自 Adobe 的 Spectrum Web 组件库，Adobe 设计系统中的各种实现均来自该库。</p><p></p><p>Spectrum Web 组件具备以下特性：</p><p></p><p>默认可及性——开发时即考虑到各现有及新兴浏览器规范，并可支持辅助服务选项。轻量化——使用 LitElement 以将运行开销控制在最低。基于标准——基于 Web 组件标准（例如自定义元素与 Shaodw DOM）进行构建。框架中立性——依托于浏览器的支持，可匹配任意框架。</p><p></p><p>此外，整个 Photoshop 应用均使用基于 Lit 的 Web 组件构建而成。Lit 的模板和虚拟 DOM diffing 可实现高效 UI 更新。Web 组件封装更可以在必要时轻松集成来自其他团队的 React 代码。</p><p></p><p>总体而言，Web 组件的浏览器原生自定义元素与 Lit 的性能优势相结合，共同为 Adobe 提供了构建 Photoshop 复杂 UI 所需要的灵活性，同时保持其拥有良好的运行效率。</p><p></p><p></p><h2>优化 Photoshop在浏览器中的性能表现</h2><p></p><p></p><p>虽然有各项 Web 新功能作为实现基础，但像 Photoshop 这样的资源密集型桌面应用程序仍需要大量的性能跟踪与优化调整，才能转化为一流的线上使用体验。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/85/85f65ccc4144176561bd31900eae870f.png\" /></p><p></p><p>在 Photoshop Web 应用进行初始加载时，会对长任务进行拆分</p><p></p><p></p><h2>使用 Service Workers缓存资产与代码</h2><p></p><p></p><p>Service Workers 允许 Web 应用在本地缓存其资产、代码和其他资源，以便在初次访问之后加快加载速度。尽管尚不完全支持离线运行，但 Photoshop 已经依托 Service Workers 来缓存其 WebAssembly 模块、脚本及其他资源。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/10/10f98b415d4fe440697f106625469a92.png\" /></p><p></p><p>在 Chrome DevTools Application 面板 &gt; 缓存存储处，可查看 Photoshop Web 版已经预缓存的各种资源类型。在这里，我们可以看到其代码被拆分成多个 JavaScript 块进行本地缓存，这样就能在后续加载时获得极快的加载速度。</p><p></p><p>这套缓存机制对于加载性能产生了巨大影响。在首次访问之后，后续加载往往非常快（以 M1 Macbook 平台为例）：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/cd/cdfe8b97c61338595e48d9578e7594bf.png\" /></p><p></p><p>Adobe 还使用 Workbox 库，轻松将 Service Worker 缓存集成至整个构建过程当中。</p><p></p><p></p><h2>V8 引擎对缓存资源进行优化</h2><p></p><p></p><p>当从 Service Worker 缓存处返回资源时，V8 引擎会采取以下优化策略：</p><p></p><p>在 install 期间缓存的资源，会被立即编译并进行代码缓存，从而实现更快、更一致的性能表现。在 fetch 期间通过 Cache API 缓存的资源，在第二次加载时将获得缓存优化，速度高于常规缓存。V8 会根据缓存检测资源的重要度，并更主动地进行编译。</p><p></p><p>这些优化策略能够覆盖 Photoshop 中的大量缓存 Wasm 模块。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/6e/6e69d4bce114b262d277ea1b19a4bfb5.png\" /></p><p></p><p>Photoshop Web 版在后续加载中能够更快显示关键视图，这在一定程度上归功于 V8 的代码缓存机制。</p><p></p><p></p><h2>大型 WebAssembly 模块的流式处理与缓存</h2><p></p><p></p><p>Photoshop 的代码库需要多个大型 WebAssembly 模块，有些大小已经超过 80 MB。V8 和 Chrome 能够支持流式编译，因此可以高效处理这些大体量模块。</p><p></p><p>此外，在首次从 Serivce Worker 处请求 WebAssembly 模块时，V8 会生成优化版本并将其存入缓存，这种方式对于 Photoshop 这类大体量应用至关重要。</p><p></p><p></p><h2>通过多线程实现图形并行操作</h2><p></p><p></p><p>Photoshop 中的很多核心图像处理操作（例如转换像素）可以通过跨线程并行处理来大幅加快速度。WebAssembly 的多线程支持可以利用多核设备的算力优势，快速执行各类计算密集型图形任务。</p><p></p><p>如此一来，Photoshop 就能以与桌面版相同的多线程方法高效执行 WebAssembly 当中的关键图像功能。</p><p></p><p></p><h2>调试 WebAssembly以做进一步优化</h2><p></p><p></p><p>强大的 WebAssembly 调试支持，对于诊断和修复开发过程中的性能瓶颈至关重要。</p><p></p><p>Chrome DevTool 能够分析 WASM 代码、设置断点并检查各种变量，由此体现 JavaScript 自身的可调试性优势：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d4/d49bc80911b573c5468b0a98334c9c81.png\" /></p><p></p><p></p><h2>将设备上的机器学习功能与 TensorFlow.js 相集成</h2><p></p><p></p><p>Web 版 Photoshop 的最新版本，还包含基于 TensorFlow.js 的 AI 驱动功能。将云端模型转为本地设备运行，有助于改善隐私、延迟和成本。</p><p></p><p></p><blockquote>TensorFlow.js是谷歌发布的一套开源机器学习库，主要面向希望在浏览器中运行客户端的JS开发人员。其具备成熟的Web机器学习选项，以及全面的WebGL及WebAssembly后端操作程序支持。未来随着Web新标准的持续发展，用户还可选择在浏览器中使用WebGPU后端以获得更佳性能。</blockquote><p></p><p></p><p>Select Subject（选择对象）功能，可使用机器学习自动提取图像中的主要前景对象，从而大大加快复杂取像的执行速度。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7f/7f1c95f4da09d11fadbcccf38ed5ddd1.png\" /></p><p></p><p>以这张夕阳插图为例，我想将画面改为夜间。这时我们可以使用“选择对象”加 AI 提示来提取相应区域进行修改。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/02/02ae848adbf7c4d3177c1d9ab5adbf57.png\" /></p><p></p><p>Photoshop 能够根据我的 AI 提示词生成更新后的插图。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/43/43fc3c0bd27022be966ba6ab29f1b4f0.png\" /></p><p></p><p>还可添加更多视觉效果。</p><p></p><p>其中的 AI 模型已经由 TensorFlow 转换为 TensorFlow.js，因此可实现本地运行：</p><p></p><p><code lang=\"null\">// Load Select Subject modelconst model = await tf.loadGraphModel('select_subject.json');// Run inference on image tensor const {mask, background} = model.execute(imgTensor);// Refine selection from mask\n</code></p><p></p><p>Adobe 还与谷歌合作为 Emscripten 开发了代理 API，希望借此解决 Photoshop 中 WebAssembly 代码与 TensforFlow.js 之间的同步问题，并由此实现了框架间的无缝集成。</p><p></p><p>“由于谷歌团队通过各种受支持的后端（WebGL、WASM、Web GPU）提高了 TensorFlow.js 的硬件执行性能，模型性能实现了 30% 至 200% 的提升（模型体量越大，性能收益越高），并在浏览器端实现了近实时性能。”</p><p></p><p>关键模型也进行了优化，重点关注 Conv2D 等重视性能的操作类型。Photoshop 还可根据性能需求，选择在本地设备还是云端运行模型。</p><p></p><p>关于更多详细信息，请参阅 TensorFlow.js Photoshop 说明文章：</p><p></p><p><a href=\"https://blog.tensorflow.org/2023/03/how-adobe-used-web-ml-with-tensorflowjs-to-enhance-photoshop-for-web.html%E3%80%82\">https://blog.tensorflow.org/2023/03/how-adobe-used-web-ml-with-tensorflowjs-to-enhance-photoshop-for-web.html。</a>\"</p><p></p><p></p><h2>Web 版 Photoshop 的未来规划</h2><p></p><p></p><p>Photoshop Web 版的发布代表着一个巨大的里程碑，同时也是通往无穷可能性与全新世界的第一步。</p><p></p><p>Photoshop 将继续在 Web 端不断开拓，随着浏览器供应商对标准和性能的增强而逐步提升，并陆续发布更多功能选项。Photoshop Web 版仅仅只是开始，Adobe 后续计划在 Web 上积极构建完整的 Creative Cloud 套件，立足浏览器解锁更多更为复杂的设计类应用。</p><p></p><p>Adobe 还将与浏览器工程师们密切合作，共同推进标准和性能的提升，协力将 Web 打造成真正的独立平台，为各类雄心勃勃的用例提供支持。更多激动人心的时刻，就在前方！</p><p></p><p></p><h5>原文链接：</h5><p></p><p></p><p><a href=\"https://medium.com/@addyosmani/photoshop-is-now-on-the-web-38d70954365a\">https://medium.com/@addyosmani/photoshop-is-now-on-the-web-38d70954365a</a>\"</p><p></p><p></p><h5>相关阅读：</h5><p></p><p></p><p><a href=\"https://www.infoq.cn/article/jds0wDTz7DSUGzpc81hs\">WebAssembly&nbsp;的核心语言特性与未来发展</a>\"</p><p><a href=\"https://xie.infoq.cn/article/0450be77b842463d6abc0daa8\">Photoshop&nbsp;崩溃怎么办无法打开&nbsp;Photoshop</a>\"</p><p><a href=\"https://www.infoq.cn/article/H9VRjX3X1MeXqImEwI6J\">Java 极客眼中的&nbsp;WebAssembly</a>\"</p><p><a href=\"https://xie.infoq.cn/article/a289d0a020cab73be9c559db4\">Photoshop&nbsp;2023 如何切换语言？</a>\"</p>",
    "publish_time": "2023-10-30 09:47:41",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "智谱AI张鹏谈大模型进展和挑战，在CNCC会议上推出第三代基座大模型ChatGLM3",
    "url": "https://www.infoq.cn/article/Ndi571huMEScbH9hcrar",
    "summary": "<p>在2023年10月27日的沈阳CNCC中国计算机大会上，大模型已经成为了大会议题的焦点，各个领域都在围绕大模型展开讨论。</p><p></p><p>在27日上午的“大模型的研究进展与产业应用展望”论坛，由CCF副秘书长谭晓生主持，德国国家工程院院士张建伟、复旦大学计算机学院教授邱锡鹏、智谱AI CEO张鹏、科大讯飞研究院院长刘聪、蚂蚁集团副总裁徐鹏等专家参与讨论的圆桌交流环节也取得了丰富的成果，专家从各自的视角分享了大模型的进展、挑战以及未来的问题。以下整理智谱AI CEO张鹏老师的部分观点。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/3e/80/3e64309742f0047dbee5b8ab84c1af80.png\" /></p><p></p><p>关于大模型领域的进展，张鹏认为，目前大模型的进展可以归结为通用智能，即基础模型的通用智能水平的提升。上一代人工智能大多数还是单向的感知能力。而大模型最大的优势是能把这些感知能力整合起来，形成一个更泛化的、更强大的认知级别的能力。这其中就包括推理能力、复杂问题的拆解能力，以及跨模态对齐能力。</p><p></p><p>最受关注的其实就是跨模态融合的能力，经过实践后发现多模态或者跨模态的数据可以通过训练的方法完美的融合到一起，在一定程度上提升了大模型的智能水平。</p><p></p><p>另外，基于认知能力的提升，可以观察到像智能体 Agent 这一类的研究，确实能够极大地增强大模型在实际应用当中的效果，让大模型从搭配 Benchmark 的实验环境走入到真正的应用当中，来解决实际的应用问题，这在张鹏看来是让人欣喜的进展。</p><p></p><p>大模型在研发和应用过程中也会遇到不少的挑战。张鹏认为，除了算力和数据方面的挑战之外，在算法方面也同样有挑战，当前所有的大模型都基于2017年提出的Transformer架构，未来是否会被改进或被新的东西代替也是大家关心的问题。另外张鹏考虑更多的另一个挑战是应用安全问题，包括私有数据训练等，首先要考虑的就是安全。</p><p></p><p>关于产出的内容审核的解决办法，大模型产出的内容在提供给用户之前，对于所提供的内容审核问题也是很重要的。张鹏说，首先平台要保证尽量不要传递错误的讯息，其次是为了达到这个目的，可以借鉴已有的多年的经验，例如人机融合或者人机交互是提升工作效率的有效方式之一。通过借鉴互联网、社交媒体等行业的经验，可以降低人工成本，并保证内容的安全性。</p><p></p><h3>智谱 ChatGLM3 以及相关系列产品发布</h3><p></p><p></p><p>在此次 CNCC 会议上，智谱AI推出了自主研发的第三代基座大模型ChatGLM3以及相关系列产品。这是继智谱AI推出千亿基座的对话模型ChatGLM和ChatGLM2之后的又一重大突破。</p><p></p><p>此次推出的 ChatGLM3 采用了独创的多阶段增强预训练方法，使训练更为充分。评测显示，在 44 个中英文公开数据集测试中，ChatGLM3 在国内同尺寸模型中排名首位。智谱 AI CEO 张鹏在现场做了新品发布，并实时演示了最新上线的产品功能。</p><p></p><h3>ChatGLM3全新技术升级 更高性能更低成本</h3><p></p><p></p><p>通过更丰富的训练数据和更优的训练方案，智谱AI推出的ChatGLM3性能更加强大。与ChatGLM2相比，MMLU提升36%、CEval提升33%、GSM8K提升179% 、BBH提升126%。</p><p></p><p>同时，ChatGLM3瞄向GPT-4V本次实现了若干全新功能的迭代升级，包括多模态理解能力的CogVLM-看图识语义，在10余个国际标准图文评测数据集上取得SOTA；代码增强模块Code Interpreter根据用户需求生成代码并执行，自动完成数据分析、文件处理等复杂任务；网络搜索增强WebGLM-接入搜索增强，能自动根据问题在互联网上查找相关资料并在回答时提供参考相关文献或文章链接。ChatGLM3的语义能力与逻辑能力得到了极大的增强。</p><p></p><p>ChatGLM3还集成了自研的AgentTuning技术，激活了模型智能体能力，尤其在智能规划和执行方面，相比于ChatGLM2提升了1000% ；开启了国产大模型原生支持工具调用、代码执行、游戏、数据库操作、知识图谱搜索与推理、操作系统等复杂场景。</p><p></p><p>此外，ChatGLM3本次推出可手机部署的端测模型ChatGLM3-1.5B和 ChatGLM3-3B，支持包括 vivo、小米、三星在内的多款手机以及车载平台，甚至支持移动平台上CPU芯片的推理，速度可达20 tokens/s。精度方面1.5B和3B模型在公开Benchmark上与ChatGLM2-6B模型性能接近。</p><p></p><p>基于最新的高效动态推理和显存优化技术，ChatGLM3当前的推理框架在相同硬件、模型条件下，相较于目前最佳的开源实现，包括伯克利大学推出的 vLLM 以及 Hugging Face TGI的最新版本，推理速度提升了2-3倍，推理成本降低一倍，每千tokens仅0.5分，成本最低。</p><p></p><h3>新一代“智谱清言”上线 &nbsp;国内首推代码交互能力</h3><p></p><p></p><p>在全新升级的ChatGLM3赋能下，生成式AI助手智谱清言已成为国内首个具备代码交互能力的大模型产品（Code Interpreter）（<a href=\"https://chatglm.cn/main/code\">https://chatglm.cn/main/code</a>\"）。“代码”功能目前已支持图像处理、数学计算、数据分析等使用场景。</p><p></p><p>随着WebGLM大模型能力的加入，智谱清言也具有了搜索增强能力，可以帮助用户整理出相关问题的网上文献或文章链接，并直接给出答案。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/7d/f7/7d8bb050b2d550f323a7f6b606df01f7.png\" /></p><p></p><p>此前已发布的CogVLM 模型则提高了智谱清言的中文图文理解能力，取得了接近GPT-4V的图片理解能力,它可以回答各种类型的视觉问题，并且可以完成复杂的目标检测，并打上标签，完成自动数据标注。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/30/a9/303865200b30fc355285fae7a60380a9.png\" /></p><p></p><p>自2022年初，智谱AI推出的GLM系列模型已支持在昇腾、神威超算、海光DCU架构上进行大规模预训练和推理。截至目前，智谱AI的产品已支持10余种国产硬件生态，包括昇腾、神威超算、海光DCU、海飞科、沐曦曦云、算能科技、天数智芯、寒武纪、摩尔线程、百度昆仑芯、灵汐科技、长城超云等。通过与国产芯片企业的联合创新，性能不断优化，将有助于国产原生大模型与国产芯片早日登上国际舞台。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/47/47a447d222962fce01b6c1f09bbbfdb9.png\" /></p><p></p><p>智谱AI此次推出的ChatGLM3及相关系列产品，全面提升了自身的模型性能，为业界打造了更开放的开源生态，并进一步降低了普通用户使用AIGC产品的门槛。AI正在引领我们进入一个新的时代，大模型必将加速这一时刻的到来。</p><p></p><h3>【活动推荐】</h3><p></p><p></p><p>在 2023 年 12 月 28-29 日，InfoQ 将在上海举办<a href=\"https://qcon.infoq.cn/2023/shanghai/track\">QCon全球软件开发大会</a>\"，这个会议上结合当前的趋势热点，设置了 GenAI 和通用大模型应用探索、AI Agent 与行业融合应用的前景、LLM 时代的性能优化、智能化信创软件 IDE、LLM 时代的大前端技术、高性能网关设计、面向人工智能时代的架构、高效的编程语言、性能工程、LLM 推理加速和大规模服务、现代数据架构演进、建设弹性组织的经验传递、SaaS 云服务弹性架构设计等专题，目前也正在邀请业界的专家来会议上演讲。感兴趣的可以点击<a href=\"https://qcon.infoq.cn/2023/shanghai/track\">QCon会议官网</a>\"，查看详细的介绍，也欢迎您来会议上演讲，分享技术实践。</p>",
    "publish_time": "2023-10-30 09:51:56",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "基于 Dubbo，如何利用APISIX 构建跨网 RPC",
    "url": "https://www.infoq.cn/article/9jJUiWSlyYueK14artaj",
    "summary": "<p>作者｜王晓彬</p><p>&nbsp;</p><p></p><blockquote>为解决数据跨网问题，政采云搭建了一条基于&nbsp;Dubbo&nbsp;的“高速公路”，同时采用了&nbsp;APISIX&nbsp;作为中心网关，为网络路由、公共特性提供支持。本文将重点介绍政采云“高速公路”工程建设中如何采用节流策略来应对挑战。我们将讨论链路协议的优化实践以及对网络传输效率的思考。</blockquote><p></p><p>&nbsp;</p><p>政采云平台是一个政府采购专属平台，为各级政府部门和国有企业提供支持。从网络架构的角度来看，政采云平台是一个集合了公有云、私有云和政务云的混合云网络。所以对于业务来说，跨网数据传输是一个常见的需求场景。</p><p>&nbsp;</p><p>为了满足这种需求，政采云“高速公路”工程于&nbsp;2022&nbsp;年底启动，旨在整合现有的网络传输方案，提供一致、便捷和高速的跨网业务体验。随着跨网方案整合的推进，公司的跨网流量越来越多地流向了新型基础设施——政采云“高速公路”工程。</p><p>&nbsp;</p><p></p><h1>挑战</h1><p></p><p>&nbsp;</p><p>“高速公路”方案得到了公司的支持，在&nbsp;2023&nbsp;年上半年通过新业务的试点后，下半年开始陆续迁移历史跨网方案的业务。从监控中，我们感受到了来自流量的压力。具体表现为：</p><p>&nbsp;</p><p>心跳应用告警频繁发生。监控指标如响应时间（RT）和吞吐量下降。</p><p>&nbsp;</p><p>为了确保业务的稳定性并提高用户体验，我们采取了各种优化措施。总体而言，我们主要探索了两种思路：</p><p>&nbsp;</p><p>资源优化：这种优化思路相对较简单，主要涉及资源的重新调配。具体措施包括对单点的中心网关和&nbsp;Dubbo&nbsp;网关进行资源隔离，以最小化故障对系统的影响。此外，通过直接增加pod等方式，也能有效缓解压力。这样可以确保在资源方面有足够的储备，以满足系统在高负载情况下的需求。性能优化：这一思路需要在架构层面进行深入优化，以尽可能填补木桶模型的短板。这是非常重要的，因为只有通过性能的最大化利用，才能实现系统的水平扩展。</p><p>&nbsp;</p><p>综合考虑这两种思路，可以在资源充足的同时，通过性能优化来确保系统的稳定性和高可用性。这种综合策略通常是解决高压力环境下的系统性能问题的有效方法。</p><p></p><h1>问题与目标</h1><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/92/9234dbdc9126ff19240a50e263faaf7a.png\" /></p><p></p><h2>跨网&nbsp;RPC（“高速公路”）的主要流程</h2><p></p><p>&nbsp;</p><p>客户端发起请求，包括生成代理、方法调用、参数返回的序列化，发起网络请求；基于&nbsp;Dubbo&nbsp;协议的本地网络传输；出口网关（基于&nbsp;Dubbo&nbsp;的&nbsp;Java&nbsp;应用）转发，涉及获取请求、反序列化参数、HttpClient&nbsp;转发；基于&nbsp;HTTP&nbsp;协议的公网网络传输；APISIX&nbsp;中心网关转发；基于&nbsp;HTTP&nbsp;协议的公网网络传输；入口网关转发，涉及获取请求、HTTP&nbsp;包拆解、参数序列化、Dubbo&nbsp;泛化转发；基于&nbsp;Dubbo&nbsp;协议的本地网络传输；服务端接收请求，获取数据、反序列化参数、方法调用、序列化结果，返回数据；原路返回，同请求流程。</p><p>&nbsp;</p><p>整个流程对性能影响比较大的环节有：Sdk&nbsp;行为&nbsp;[1,9]，网络传输&nbsp;[2,4,6,8]&nbsp;和网关行为&nbsp;[3,5,7]。其中，Sdk&nbsp;行为涉及到&nbsp;RPC&nbsp;框架选型，在当前公司已经广泛使用&nbsp;Dubbo&nbsp;的背景下，可以先不考虑。需要重点考虑的，则是网络传输中协议的选择以及网关对性能的影响。</p><p>&nbsp;</p><p></p><h3>传输协议问题</h3><p></p><p>&nbsp;</p><p>鉴于现有背景，用户通常希望使用本地Dubbo一样直接跨网。所以。“高速公路”工程的设计是围绕&nbsp;Dubbo&nbsp;框架的特性进行的。</p><p>&nbsp;</p><p>与业务对接中，经常会被问到，我们使用了&nbsp;Dubbo&nbsp;的某个特性，你们能否支持？出于对场景支持的考虑，在设计“高速公路”架构时，我们重点考虑了接近原生体验的特性。为此，我们设计了隧道机制。现在，基于这一特性，我们可以轻松地对业务说：“是的，可以支持！”</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c5/c5f2912ddc42e12ce6491d33b195c2ff.jpeg\" /></p><p>隧道机制方案的中间层使用了&nbsp;HTTP&nbsp;协议作为隧道协议，它可以穿透层层网络设备和网关，是比较稳健的一种方式。但是在流量压力下，整体的性能/吞吐量，逐渐成为当前方案的主要矛盾。</p><p>&nbsp;</p><p>首先，在协议层面，我们先要了解下&nbsp;HTTP/1.1&nbsp;协议存在的性能问题。</p><p>&nbsp;</p><p>HTTP&nbsp;头部巨大且重复，由于&nbsp;HTTP&nbsp;协议是无状态的，每一个请求都得携带&nbsp;HTTP&nbsp;头部，特别是对于有携带&nbsp;Cookie&nbsp;的头部，而&nbsp;Cookie&nbsp;的大小通常很大；队头阻塞问题，同一连接只能在完成一个&nbsp;HTTP&nbsp;事务（请求和响应）后，才能处理下一个事务；</p><p>&nbsp;</p><p>为此，我们需要寻找一个更加高效的传输层协议来代替&nbsp;HTTP/1.1。</p><p>&nbsp;</p><p></p><h3>网关问题</h3><p></p><p>&nbsp;</p><p>另外一个比较明显的瓶颈，是本地集群内的&nbsp;Dubbo&nbsp;网关。</p><p>&nbsp;</p><p>Dubbo&nbsp;网关负责接收来自本地客户端的&nbsp;Dubbo&nbsp;协议数据，反序列后通过&nbsp;HTTP&nbsp;转发至公网中心网关。因为市面上没有&nbsp;Dubbo&nbsp;转&nbsp;HTTP&nbsp;的网关，第一个版本我们选择了自研。在转发效率上，显然有天然的不足。主要有以下几个原因：</p><p>&nbsp;</p><p>对网关本身性能的担忧。比如下图中，Spring&nbsp;Cloud&nbsp;Gateway&nbsp;对比其他网关的性能表现不足。同样是基于&nbsp;Netty&nbsp;的&nbsp;Java&nbsp;网关，我们也没有信心能比&nbsp;Spring&nbsp;Cloud&nbsp;Gateway&nbsp;更优秀。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c9/c925a3cedea14adfc3b56766eb035fb8.png\" /></p><p>图片来源见参考资料</p><p>&nbsp;</p><p>额外的参数序列化程序。由于需要转换协议，网关需要额外的一次序列化和反序列化。同时由于Dubbo&nbsp;网关不存在业务参数对象，我们需要一个通用的&nbsp;JavaBean&nbsp;描述对象作为过渡，这又增加了一次转换。HttpClient&nbsp;串行阻塞式的通信方式，将大大的降低并发效率。</p><p>&nbsp;</p><p>为了解决上述问题，我们需要一个类似于&nbsp;NGINX&nbsp;的高性能、非阻塞的网关来实现高效的反向代理，并使用更精简的通信协议来提高吞吐量。</p><p>&nbsp;</p><p></p><h1>优化方案</h1><p></p><p>&nbsp;</p><p></p><h2>协议方面</h2><p></p><p>&nbsp;</p><p>协议方面，我们尝试使用了&nbsp;Dubbo&nbsp;协议作为隧道协议。这能带来哪些收益呢？简而言之包括两个方面。</p><p>&nbsp;</p><p>减少包的大小，提高网络吞吐量</p><p>&nbsp;</p><p>Dubbo&nbsp;协议更加精简，承载的头部信息更少。协议设计上很紧凑，能用&nbsp;1&nbsp;个&nbsp;bit&nbsp;表示的，不会用一个&nbsp;byte&nbsp;来表示，比如&nbsp;boolean&nbsp;类型的标识。Http为了更好的兼容性，请求头部携带了很多上下文和元数据。对于内部通信来说，服务端和客户端相对固定，很多信息是没有必要的。以下是Dubbo官方性能测试，Tps（每秒处理事务量）Dubbo协议比Http高30%-50%左右（最常见的高并发小数据量场景）。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/04/0418f8a54cf8793ffbad9ad25a689abe.png\" /></p><p></p><p>&nbsp;</p><p>另外，Dubbo&nbsp;使用长连接，可以重复使用已经建立的&nbsp;TCP&nbsp;连接，减少了连接建立的开销。</p><p>&nbsp;</p><p>传输协议开销</p><p>&nbsp;</p><p>由于整条链路使用了相同协议，可以避免不同协议间的装包和解包。</p><p>&nbsp;</p><p></p><h2>网关方面</h2><p></p><p>&nbsp;</p><p>网关方面，我们使用了&nbsp;APISIX&nbsp;代替&nbsp;Dubbo&nbsp;网关。</p><p>&nbsp;</p><p>APISIX&nbsp;是基于高性能的&nbsp;OpenResty&nbsp;开发的，从架构和设计角度对性能追求极致，因此可以满足我们对网关性能的基本要求。同时，它具有出色的扩展性，能够满足我们的自定义需求。简而言之，我们既希望享有类似&nbsp;NGINX&nbsp;的高性能，又希望可以根据需要扩展功能。</p><p>&nbsp;</p><p>APISIX&nbsp;实现了&nbsp;xRPC&nbsp;四层协议扩展框架，允许开发人员自定义特定于应用程序的协议。基于xRPC框架，APISIX&nbsp;可以提供几种主要应用协议的代理实现，用户还可以基于该框架支持自己私有的基于&nbsp;TCP&nbsp;的应用协议，使其具有类似于&nbsp;HTTP&nbsp;协议代理的精确粒度和更高级别的&nbsp;7&nbsp;层控制。通过使用&nbsp;APISIX&nbsp;的&nbsp;xRPC&nbsp;扩展，我们成功地增加了对&nbsp;Dubbo&nbsp;协议的直接转发功能，从而实现了全链路&nbsp;Dubbo&nbsp;协议传输。</p><p>&nbsp;</p><p>这一举措解决了之前提到的两个问题：显著提升了网关性能，同时减少了协议转换的成本。此外，我们也不再需要维护额外的应用网关，实现了中间件层面的收敛。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6e/6ea2b8bb4d31037473ab0af9674f8bdc.jpeg\" /></p><p>我们已经通过&nbsp;PR&nbsp;（<a href=\"https://github.com/apache/apisix/pull/9660\">https://github.com/apache/apisix/pull/9660</a>\"）的方式将上述特性提交给&nbsp;APISIX&nbsp;社区，因此下一个版本中我们将能够直接使用开源版本。</p><p>&nbsp;</p><p>注：APISIX&nbsp;的&nbsp;Dubbo&nbsp;插件支持&nbsp;HTTP&nbsp;转&nbsp;Dubbo，目前没有Dubbo&nbsp;直接转&nbsp;Dubbo&nbsp;的方式。虽然&nbsp;Dubbo&nbsp;协议是私有协议，但是&nbsp;Dubbo&nbsp;框架的应用非常广泛，这一特性可能会有很多意想不到的用法。</p><p>&nbsp;</p><p></p><h1>本轮改造不足</h1><p></p><p>&nbsp;</p><p>2022年下半年，我们对各跨岛方案，进行了整合升级，也就是现在的“高速公路”方案，保障跨岛标准化同时，解决了之前方案实践过程中面临的很多业务痛点。通过替换隧道协议，我们希望优化网络&nbsp;IO&nbsp;模型，提高链路转发效率。经初步测试，单次&nbsp;2k&nbsp;包请求&nbsp;RT&nbsp;可以降低&nbsp;1/3&nbsp;左右。</p><p>&nbsp;</p><p>但是，在实践业务场景中，该架构下一些痛点也开始逐渐显现。</p><p>&nbsp;</p><p></p><h2>支持场景不足</h2><p></p><p>&nbsp;</p><p>对云岛业务结构的公司来说，云平台属于公司内部、完全可控的局域网，而岛端则是有自己安全网络策略的独立内部网络。我们的跨网&nbsp;RPC&nbsp;需要穿透混合云网络中的各种设备和网关，到达云岛的另一头服务。Dubbo&nbsp;协议作为私有协议，在大部分的跨岛场景中并不适用。</p><p>&nbsp;</p><p>目前，这种模式只能在内部的一些网络使用，比如独立搭建的AI集群和平台业务集群的通信。</p><p>当然，基于“高速公路”架构的良好扩展性，我们可以做到不同场景自动切换协议，在获得&nbsp;Dubbo&nbsp;协议优势的前提下，也能退化&nbsp;HTTP&nbsp;协议兜底。</p><p>&nbsp;</p><p></p><h2>对网络吞吐量的优化不足</h2><p></p><p>&nbsp;</p><p>接口需要发送大量数据时，这些数据无法被放在一个&nbsp;RPC&nbsp;的请求或响应中，需要分批发送。</p><p>Dubbo协议下，这种情况只能串行发送。Dubbo协议在单次请求下性能较好，但是整体吞吐量的提升仍然不够。</p><p>&nbsp;</p><p>在我们的跨网第一个版本上线前，曾经做过性能压力测试。测试场景如下：</p><p>&nbsp;</p><p>云端调岛，上行数据，30M&nbsp;带宽，发送&nbsp;2KB&nbsp;数据，逐步增大并发量。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/22/22180e671600127d82ceb6ad25fdb3aa.jpeg\" /></p><p></p><p>&nbsp;</p><p>30M&nbsp;入口带宽，发送&nbsp;2KB&nbsp;数据，TPS&nbsp;大于&nbsp;500/s，入口带宽将成为瓶颈。当发送数据增加到&nbsp;80KB，TPS&nbsp;下降约&nbsp;16&nbsp;倍，RT&nbsp;上升约&nbsp;1.5&nbsp;倍。</p><p>&nbsp;</p><p>从监控上看，tps&nbsp;到达一定量后，带宽即达到上限。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f7/f7a94b3a0b826c81d0b320d8df00dedd.png\" /></p><p></p><p>&nbsp;</p><p>可以看到，当前“高速公路”的实际业务场景下，吞吐量是“高速公路”第一个版本最大的一个瓶颈。此次网关和协议的升级，显著降低了&nbsp;RT&nbsp;指标，一定程度提升了整体吞吐量。</p><p>&nbsp;</p><p></p><h1>后续规划</h1><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c3/c34f14d039ef7f3f036638673c17fad7.png\" /></p><p>经过对&nbsp;APISIX&nbsp;的协议扩展，我们使用&nbsp;APISIX&nbsp;代替了&nbsp;Dubbo&nbsp;自研网关，基本实现了对通信效率的预期优化。但是，我们也有支持场景和通信效率两个明显的痛点需要解决。</p><p>为此，我们重点调研了&nbsp;Dubbo3&nbsp;主力通信协议——Triple&nbsp;协议。</p><p>&nbsp;</p><p>Triple&nbsp;协议是&nbsp;Dubbo3&nbsp;设计的基于&nbsp;HTTP&nbsp;的&nbsp;RPC&nbsp;通信协议规范，它完全兼容&nbsp;gRPC&nbsp;协议，支持&nbsp;Request-Response、Streaming&nbsp;流式等通信模型，可同时运行在&nbsp;HTTP/1&nbsp;和&nbsp;HTTP/2&nbsp;之上。对于我们项目来说，Triple&nbsp;协议的几个特性刚好是我们欠缺的。</p><p>&nbsp;</p><p>完全兼容基于&nbsp;HTTP/2&nbsp;的&nbsp;gRPC&nbsp;协议</p><p>&nbsp;</p><p>Triple&nbsp;协议听起来是个私有协议，实际上则是标准的公有协议，兼容&nbsp;HTTP/1&nbsp;和&nbsp;HTTP/2。这意味着穿透性强，痛点之一的场景支持就不再是问题了。</p><p>&nbsp;</p><p>对比&nbsp;HTTP/1，二进制分帧带来的并行效率提升，首部压缩减少大量包体，在网络吞吐量上，HTTP/2在性能上有了极大提升。</p><p>&nbsp;</p><p>作为&nbsp;Dubbo&nbsp;主力协议，仍然保留着避免协议转换的优势，与“高速公路”架构契合</p><p>&nbsp;&nbsp;</p><p>经过&nbsp;Dubbo2&nbsp;协议的实践与总结，我们将着力推动&nbsp;Triple&nbsp;协议的升级，完美解决性能问题。</p><p>&nbsp;</p><p>未来，我们将按以下几步进行：</p><p>&nbsp;</p><p>助力开源项目&nbsp;APISIX&nbsp;扩展&nbsp;Triple&nbsp;协议</p><p>&nbsp;</p><p>APISIX&nbsp;本身有着非常优秀的扩展性，同时有&nbsp;Dubbo2&nbsp;协议的经验，相信这一步会比较顺利。</p><p>&nbsp;</p><p>推动公司&nbsp;Triple&nbsp;协议的升级</p><p>&nbsp;&nbsp;</p><p>今年政采云整体升级完&nbsp;Dubbo3，后面升级协议也将是一个可选项。</p><p>&nbsp;</p><p>性能压测验证</p><p>&nbsp;</p><p>对于当前架构，之前做了完整的压力测试，也明白瓶颈所在。后续我们将持续测试，深挖这一基础设施的性能潜力。</p><p>&nbsp;</p><p>参考资料：</p><p><a href=\"https://www.jianshu.com/p/7182b8751e75\">https://www.jianshu.com/p/7182b8751e75</a>\"</p><p><a href=\"https://www.infoq.cn/article/qfcz1fj9wvFvGidjpcho\">https://www.infoq.cn/article/qfcz1fj9wvFvGidjpcho</a>\"</p><p><a href=\"https://zhuanlan.zhihu.com/p/432512918\">https://zhuanlan.zhihu.com/p/432512918</a>\"</p><p><a href=\"https://cn.dubbo.apache.org/zh-cn/docsv2.7/user/perf-test/\">https://cn.dubbo.apache.org/zh-cn/docsv2.7/user/perf-test/</a>\"</p><p>&nbsp;</p><p>作者介绍：</p><p>王晓彬，Apache&nbsp;Dubbo&nbsp;Commiter、政采云资深开发工程师，负责基础服务相关工作。</p>",
    "publish_time": "2023-10-30 10:28:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "高级别自动驾驶时代，如何找到车路协同更优解？",
    "url": "https://www.infoq.cn/article/H74QyxxT4AT4QfUSVzxE",
    "summary": "<p>近日，在“以边缘·致多元”边缘计算新品发布暨合作伙伴大会上，浪潮信息联合百度发布首代车路协同路侧计算单元 RSCU。该产品通过系统设计，性能可满足 L2 至 L4 高等级自动驾驶融合应用的算力需求，还支持百度开放、兼容的智路 OS 操作系统连接上层场景，能够在双向 8 车道路口全面感知信号灯、摄像头、激光雷达、路牌路标、气象站等状态，目前已经在北京、武汉等多地部署测试。</p><p></p><p>会后，浪潮信息边缘计算产品线总经理孙波、百度车路协同首席架构师王淼接受了 InfoQ 在内的媒体采访，进一步分享浪潮信息与百度在车路协同方向上的探索与思考。</p><p></p><h2>车路协同：让聪明的车驶向智慧的路</h2><p></p><p></p><p>车路协同是自动驾驶技术发展的关键因素之一，其采用先进的无线通信和新一代互联网等技术，全方位实施车与车、车与行人、车与路等动态实时信息交互，并在全时空动态交通信息采集与融合的基础上，开展车辆主动安全控制和道路协同管理，充分实现人、车、路的有效协同，保证行车安全，提高通行效率，改善交通环境，从而形成的安全、高效和环保的道路交通系统。</p><p></p><p>人们对车路协同的探索最早可以追溯到 20 世纪 50 年代末，当时通用汽车在新泽西州打造了一条埋入大量通信设备的概念高速公路；1990 年代，日本将智能交通系统确立为国家项目；2011 年，中国科技部在 863 计划中设立了智能车路关键技术研究项目，为车路协同技术的发展提供了支持。</p><p></p><p>随着近年来自动驾驶技术加速发展，产业链基础配套和市场开发也越来越成熟，高级别自动驾驶正在加速“上路”。可以预见的是，“车路云”协同发展将成为趋势——不仅需要车辆本身具有很强的车载算力、高精度传感器、操作系统等，还需要加强路侧感知、计算、通信的边缘计算基础设施建设，并能够与边缘云、数据中心云实现多级云边协同。而这也对路侧边缘计算基础设施的性能、存储、可靠性、软硬协同等方面提出了更高的要求。</p><p></p><p>孙波在接受采访时表示，在车路协同系统中，多个摄像头和雷达采集到的数据需要在极低时延内处理并呈现结果。此时，算力便显得至关重要，需要超过 200 TOPS 来支撑整个现场数据的实时处理。</p><p></p><p>“从设备角度出发，性能需求不容忽视。每个摄像头采集的是视频流，每秒产生 30 帧照片。若要做到实时分析，每帧图片经过推理处理以判断车辆位置，需要每秒分析 30 次。若算力无法达到此水平，可能需要进行抽帧处理，即每秒只处理 10 帧或 1 帧，导致算力差异和时延增加。为确保高实时性，需要使用高性能设备进行实时处理。我们跟百度一起在路侧计算单元设备中增加了较强性能的计算单元来支持实时处理。对于通信精度，更着重于设备侧的时钟同步。基于卫星通信的时钟和精度可以达到纳秒级。”</p><p></p><p>要想实现较高的性能，王淼认为需要注意以下两个方面：首先，硬件和软件需要基于高可靠的系统流程进行设计。其次，系统中采用了许多分布式架构。以手机摄像头为例，目前市场上热销的手机可能配备四个摄像头，而每个路口可能包含超过 20 个摄像头。在如此复杂的情况下，如何确保系统的性能？答案是在路侧大脑中建立一个分布式的调动系统，该系统可以并发处理数千个任务，从而确保摄像头的时延。</p><p></p><p>“在系统中，除了 CPU 外，还包括 GPU 和其他各种异构神经网络算力。为了提高性能，我们利用不同的算法逻辑，尤其是最新的神经网络技术。这些技术有助于将计算压力从传统的CPU 中解放出来，从而实现毫秒级的时延。随着人工智能技术的不断发展，主频的提高已经不再像过去那样重要。现在，整个技术栈越来越强调人工智能的计算，以实现更高的性能。”王淼说道。</p><p></p><h2>车路协同路侧计算单元 RSCU 背后的设计与思考</h2><p></p><p></p><p>为了实现让聪明的车驶向智慧的路，浪潮信息携手百度智能云发布首代车路协同路侧计算单元 RSCU。</p><p></p><p>据介绍，针对车路云协同场景下路侧逐渐增加的感知设备，路侧计算单元在算力性能方面进行优化设计，可以最大支持 260 TOPS 的算力，最多可支持双向8车道路口的信号灯、摄像头、激光雷达、路牌路标、气象站等传感器数据传输，面向 L2 至 L4 高级别自动驾驶场景，为“聪明的车”提供更精准的人、车、道路、环境、交通事件的全要素实时检测和分析，并通过车路云的协同，助力智慧城市、智慧交通场景。</p><p></p><p>此外，为保障路侧计算单元的与云端的高效协同，全新路侧计算单元还支持百度开放、兼容的智路 OS 操作系统，可以更好的衔接上层自动驾驶、车路协同应用场景，具有高性能、智能化、开放性、兼容性、协同性、安全性六大特性，全面提升车路云协同效率。</p><p></p><p>目前，百度已经率先在全国多地高等级自动驾驶示范区对该产品进行测试实验，验证了其在自动驾驶到城市交通治理的智能网联全场景服务能力。测试数据显示，基于首代车路协同核心计算单元构建的“感知-计算-通信”路侧边缘智能体系，能够实现对路口范围的人、车、道路、环境、交通事件的全要素实时检测和分析，位置精度≤1.0m（人机非,平均），速度精度≤1.5m/s（均值），交通对象感知定位类型识别准召率≥90%，路侧对象感知端到端时延（含通信时延）≤300ms（均值）。</p><p></p><p>在谈到车路协同路侧计算单元 RSCU 的设计时，孙波表示 RSCU 是目前在路侧方面算力最强的一个产品，需要结合路侧计算的时延和数据处理对于性能的要求，来做产品的整体系统设计。</p><p></p><p>“在这个过程中，我们面临了许多挑战。一个典型的挑战是在路侧环境中放置计算力服务器，这些设备需要应对春夏秋冬、风雨雪雾等各种恶劣环境，包括高温和寒冷。为了解决这个问题，我们可以采用一些算力相对较低的设备，并让它们自身进行宽温设计。例如，EIS200 可以在- 40 ℃到65℃之间正常工作。这款设备的算力约为 200 多 TOPS，虽然已经具有相当大的算力，但这也带来了功耗和散热的挑战。”</p><p></p><p>为了解决这些问题，浪潮信息与百度采取了多种创新方法。对于高功耗设备在路侧环境中的适应性问题，其采用了主动散热方案。当设备的功耗达到 300 瓦时需要进行散热创新，通过隔离散热设计，将服务器中娇贵的器件隔离在内部干净的环境中，并通过第二散热风道与外界进行热交换，由此成功解决了散热问题。</p><p></p><p>“这个联合项目的成功不仅给我们带来了很多技术上的突破和经验，而且对于边缘计算在其他行业的落地也具有重要意义。由于 AI 大模型训练需要大量的算力支持，这些模型需要在边缘侧落地应用。因此，这个项目不仅加速了边缘行业的创新和发展，还对边缘算力提出了更高的要求。随着算力需求的增加，解决环境适应性问题的挑战也会进一步加剧。”</p><p></p><p>孙波认为，基于这个联合项目的知识和成果，可以在相关领域应用边缘计算技术，例如水利、高速、制造、能源、电网巡检等等。这些应用可以快速复制到其他许多行业中，为产业的落地提供助力。“未来，我们将继续积极应对挑战，为边缘计算在其他行业的落地提供更多支持，并不断推动技术的发展和创新。”</p><p></p><p>在智慧交通领域，除了车路协同路侧计算单元 RSCU，浪潮信息与百度还合作让其适配了名为智路 OS 的生态系统，这也是由工信部指导认证的路侧操作系统生态。王淼提到，“未来的路侧会像现在的智能车一样，形成一个类似的生态系统。这个生态系统最终将包含两个关键的核心零部件，即芯片和操作系统。在这两个领域，手机和车方面稍显落后，但在道路方面，我国已经提早布局并看得更远。”</p><p></p><p>随着更多参与方加入，以及芯片和操作系统的进一步发展，整个生态系统将会更加完善和强大，并为智慧交通带来更多的无限可能。</p><p></p><h2>边缘计算将走向怎样的未来？</h2><p></p><p></p><p>AIGC 大模型的飞速发展为边缘计算业务带来了新的创新。然而，边缘计算基础设施也将面临更大的挑战。孙波认为，未来边缘计算的发展方向将面临三大难题：</p><p></p><p>首先，环境适应是边缘计算设备面临的一个重要问题。随着算力不断增加，设备的功耗也会随之提高。为了确保设备的稳定运行，需要采取更为先进的散热和环境适应手段。例如，针对未来算力提升至更高数量级的情况，需要研究更为高效的散热方式和适应各种环境下的产品设计。</p><p></p><p>其次，算力支撑是边缘计算设备的另一个重要发展方向。随着智能化和系统化的决策分析需求不断提升，边缘计算设备需要更大的算力支持。未来，边缘计算设备将朝着大算力方向发展，以更好地满足各种复杂任务和系统性的决策分析需求。</p><p></p><p>最后，安全是边缘计算面临的另一个重要挑战。与数据中心服务器相比，边缘计算设备部署在更加复杂和恶劣的环境中，需要直接面对公网安全挑战。因此，未来需要研究如何提高边缘计算设备的安全性能，以及如何实现设备的智能化运维和故障自恢复等功能。</p><p></p><p>整体而言，未来边缘计算的发展将朝着环境适应、大算力支撑和安全保障等三个方向发展。在这个过程中，需要不断研究新的技术和方法，以提高边缘计算的易用性、可靠性和维护性，更好地满足行业需求。</p><p></p><p>而要想实现边缘计算的规模化落地，关键不仅仅在于简单地拥有一个边缘计算服务器。整个产业链的协同也至关重要。</p><p></p><p>“我们需要与合作伙伴共同研究、打破限制，以推动场景的落地。这也是我们认为边缘计算要实现规模化落地所必须重视的路径。未来，我们将继续与百度等合作伙伴围绕边缘场景进行深入研究，打磨场景方案并推动其落地。在这个过程中，我们通过不断的迭代和发展，逐渐走向一个新的阶段。在众多边缘场景中，我们发现城市治理和交通是具有明确需求且非常大的场景。”孙波认为，未来的城市将是智慧化的，交通更应该如此。只有实现了智慧化的交通，才能真正解决道路交通拥堵的问题，因此，行业需要结合未来的趋势来思考如何使道路更加智能化。</p><p></p><p>“在未来的规模化落地过程中，我们将不断打磨场景和硬件设备，使其更加适用于业务场景。同时，我们相信百度也将不断迭代和优化其上层软件平台，推出更新的技术和更好的方案，共同推动设备的不断完善。”孙波说道。</p>",
    "publish_time": "2023-10-30 10:28:42",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "中国工商银行基于生产流量的创新探索及实践",
    "url": "https://www.infoq.cn/article/OXrxX4NmLQS2ggjsfvN6",
    "summary": "<p></p><blockquote>作者 | 中国工商银行金融科技研究院云计算实验室</blockquote><p></p><p></p><p>随着互联网金融的高速发展，金融产品和服务模式不断创新，业务规模呈现爆炸式增长态势，新老业务迭代加速，在业务迭代升级或系统重构时，如何确保业务架构调整后的功能连续性，是常规测试工具面临的难题。相较于传统测试数据，生产流量具有多样性的特征，利用生产流量进行功能性验证能够最大程度提升验证效果，保障架构转型过程的安全性和稳定性。在这样的背景下，流量录制回放技术应运而生。</p><p></p><p></p><h3>流量录制回放的行业现状</h3><p></p><p></p><p>由于传统的测试数据缺乏真实性和多样性，测试案例覆盖度往往无法满足实际的需求，为此互联网头部企业提出通过流量录制回放工具弥补传统自动化测试系统的不足，并以此衍生出了多种方案，其中较为有代表性的工具和产品有 GoReplay、TcpCopy、Jvm-Sandbox-Repeater、阿里云引擎回归测试平台等。这些工具都是由用户层、流量采集、数据持久化模块所组成（如图 1 所示），其中服务端提供了流量录制规则配置和数据分析的能力，用户根据自身需求分析录制场景和录制规则，并基于录制工具开展生产流量录制；采集端则根据业务提供的录制规则进行数据收集和聚合并转发给存储节点进行持久化；回放端主要提供了实时回放、用例沉淀、压测模型转换、链路分析、依赖分析等能力。此外，持久化的流量数据可根据业务需求进行差异化定制，并应用于在线巡检、变更影响面评估、智能用例推荐、强弱依赖识别、业务模型评估、覆盖率分析等场景，从而形成围绕流量的运维生态。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/08/08cd70609841c9ed5f662d67b3bdec95.png\" /></p><p></p><p>图 1 业界流量录制回放业务架构</p><p></p><p></p><h3>中国工商银行在流量录制回放领域的探索</h3><p></p><p></p><p>随着工商银行分布式转型工作深入推进，开放平台交易量爆发式增长，分布式架构错综复杂的调用链给运维体系带来巨大挑战。工商银行借鉴行业先进经验，打造了流量录制回放平台，从六个方面对流量录制回放技术进行探索和实践。</p><p></p><p></p><h4>字节码增强方式录制，多维度可定制化任务管理</h4><p></p><p></p><p>针对工商银行内部技术框架的多样性，相较于其他录制方式，字节码增强方式因其无侵入特性，具有更高的包容性，可以支持以较低的成本对应用服务进行拦截，进而实现服务请求响应报文、链路特征、交易耗时等信息的录制。</p><p></p><p>平台提供了应用、集群、容器、服务、交易时间等多种维度的录制能力（如图 2 所示），用户可根据自身诉求定制录制规则，以任务的形式灵活的控制录制时间段、设置灰度模式、采集链路资源等，实现多维度流量灵活录制。精准的录制任务投放，不仅降低了录制链路的处理压力，还能帮助用户有效控制录制工具的影响范围，降低性能损耗，同时保障应用节点安全稳定。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3d/3d91012c33d77176e9e3abd47f0b68f9.png\" /></p><p></p><p>图 2 字节码增强录制与定制化任务管理</p><p></p><p></p><h4>梳理核心链路，构建流量录放模型</h4><p></p><p></p><p>核心链路的梳理是整个流量录放工作的重中之重，能否将核心链路梳理好，直接决定其能否保证录制链路和数据的完整性以及能否达到录放的预期效果。在分布式架构下，工商银行利用链路追踪监控技术，通过流量染色和拓扑分析机制，形成面向业务场景的全链路拓扑结构，业务系统再根据梳理出来的目标链路拓扑进行梳理以及性能容量评估，最终得出流量录放模型，以最大程度还原生产交易场景。</p><p></p><p>录制链路梳理：业务系统通过链路拓扑分析，根据自身需求，梳理需要录制的资源信息以及上下游依赖，并以此可衍生出录制任务的维度和配置。性能容量评估：为保证生产录制过程不会影响日常交易，生产录制前，业务系统必须在测试环境进行性能容量评估，为录制工具预留一定的资源。</p><p></p><p></p><h4>建立流量跨域自动化传输机制</h4><p></p><p></p><p>为了避免流量录制回传过程中出现敏感信息泄露，工商银行提供了配置化的脱敏能力，可以基于用户配置实现针对性脱敏，建立生产录制流量跨域回传测试环境的常态化运行机制（如图 3 所示）。针对小批量录制数据，平台支持用户在线下载并手工导入测试环境。针对海量数据报文，平台支持后台自动生成批量文件、传输并导入测试环境，该方式具备数据分段传输、断点续传、完整性检查等功能特性。</p><p></p><p>为解决环境间数据差异性问题，平台提供了多维度的自定义替换功能，用户可根据场景特色进行配置，以提升回放成功率，最终形成一套流量录制、脱敏、传输、替换的全自动化流程。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/de/deff1825312a81bcde4ef840cd3e1859.png\" /></p><p></p><p>图 3 自动化脱敏传输与替换</p><p></p><p></p><h4>具备高适配、高并发的回放能力</h4><p></p><p></p><p>传统的流量回放模式主要将流量无序的压入应用容器，该方式无法保障服务调用先后顺序，可能引发事务不一致风险。工商银行基于生产采集的服务接口信息，实现了报文组装和服务接口模拟调用，根据流量录制时序进行回放，支持用户灵活设置录制数据段、回放速率等个性化回放配置，形成从流量录制到回放的一站式演练能力。</p><p></p><p>针对部分下游强依赖场景，工商银行支持根据其入口流量透传的链路信息查找对应的子调用响应并返回，降低下游依赖性的同时提高了回放的成功率和场景适配性。</p><p></p><p></p><h4>形成多维度结果比对分析机制</h4><p></p><p></p><p>为提升流量回放结果的可观测性，平台提供基于定制化规则的多维度比对分析能力，实现录制响应报文与回放响应报文的差异化感知。基于 ClickHouse 的实时分析架构，可支撑百亿级交易的实时比对聚合，及时反馈回放任务运行效果，进而形成程序架构质量评价。多维度的结果筛选和分析能力（如图 4 所示），可有效协助业务人员敏捷分析异常原因，并及时做出调整。用户针对异常的流量可施行二次回放，直至回放成功率达到 100%，保证业务迁移前后功能的一致性。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7e/7e8228465169e12dc17c5ff704b6b0bd.png\" /></p><p></p><p>图 4 结果比对分析</p><p></p><p></p><h3>场景化应用</h3><p></p><p></p><p>工商银行目前已初步形成一站式的常态化演练机制，在灾备带压演练、仿真切流验证、测试环境回归测试等场景提供了关键的技术支撑，最终保障生产业务安全。截至目前，平台已完成二十余个应用系统的接入使用，其中测试环境已得到规模化应用，灾备环境和仿真环境也已顺利支撑个人结算、信用卡产品等重点应用的验证工作。</p><p></p><p></p><h4>带压灾备演练</h4><p></p><p></p><p>在应用架构转型背景下，为确保灾备环境的承载能力，工商银行利用生产真实流量在灾备云实施回放，检验应用核心交易和服务在灾备云环境的性能和功能情况。带压灾备演练主要操作流程如下：</p><p></p><p>应用根据自身交易场景，梳理录制灰度集群、服务、时间段、关联交易等录制链路信息。运维支持人员根据应用梳理的生产操作手册，提前完成数据库数据同步以及生产报文录制，待流量录制完成后将其回传到灾备环境。为保证灾备环境回放真实性，运维支持人员以倍速回放灰度流量的方式模拟生产高并发冲击对业务系统性能容量的影响。应用根据回放的比对结果分析回放的业务交易成功率以及系统的整体承载能力（如图 5 所示），并以此作为应用架构转型成功与否的评判标准之一。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/80/80ebcd4f73d7d608a0eeb75ccc7b9cd0.png\" /></p><p></p><p>图 5 回放结果大屏展示</p><p></p><h4>仿真切流验证</h4><p></p><p></p><p>在应用架构转型的背景下，为保证业务核心交易的安全平稳升级，工商银行将生产真实流量准实时回放到生产仿真环境，验证业务切流前后交易的一致性。</p><p></p><p>与灾备带压演练不同，运维人员完成数据库数据同步后，同时下发录制任务和回放任务，生产录制的流量完成存储后将被准实时回放到仿真环境，应用根据生产交易结果与仿真交易结果的比对分析，判断核心交易逻辑是否与切流前一致。</p><p></p><h4>测试回归验证</h4><p></p><p></p><p>为保证回归测试案例的真实性、多样性和覆盖完整性，工商银行将生产真实流量脱敏后回传到测试环境进行回放，模拟生产真实交易进行的场景，以回放比对分析结果作为评判功能迁移或升级前后是否一致的标准。随着生产和测试流量的持续积累，回放案例库可基本覆盖业务代码的所有分支，测试人员通过流量回放实现了应用业务系统的常态化回归测试，大幅提升测试效能。</p><p></p><p></p><h3>未来展望</h3><p></p><p></p><p>未来，工商银行流量录制回放平台将进一步与链路监控、服务限流、混沌工程等其他运维工具相结合，完善运维工具链和分布式监控运维体系，拓展工具使用场景，提升流量录放的价值和意义，为金融业务场景稳定性提供有力支撑。</p><p></p><p>好文推荐</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651184614&amp;idx=1&amp;sn=b43b9e284546eb0a88e5cd88aac46de4&amp;chksm=bdb825b58acfaca3d677861a4deccc0719767a1de6fc85d33061016eb6017a505b6fff532a73&amp;scene=21#wechat_redirect\">智谱 AI“超 25 亿融资”的背后</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651184469&amp;idx=1&amp;sn=7c5092f6322f9a72636fc30c8bbdffc5&amp;chksm=bdb825068acfac1095093a40f05ef999ac26ae381553e9c257ae357e9788c1d3b93351276afe&amp;scene=21#wechat_redirect\">是时候彻底放弃“高分低能”的 Leetcode了：AI 时代的面试需要大变革！</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651184468&amp;idx=1&amp;sn=2821cc81d28db3bfda2838db761de083&amp;chksm=bdb825078acfac11692aece58bd302a22299223fe5d36a7e2d33bb42438bdb5e52d6f91aa22d&amp;scene=21#wechat_redirect\">B 站广州研发工作室解散；外媒曝光苹果中国区丑闻；OpenAI 被曝已叫停新大模型项目 | Q资讯</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651184325&amp;idx=1&amp;sn=3ae0633290e470d16d6a609d74ccdf0e&amp;chksm=bdb824968acfad80203433a2cdfa0c49e3f56f133d7abfa29b456e3fb9d63298475aadd7afdb&amp;scene=21#wechat_redirect\">“MySQL 之父”的 MariaDB 要完蛋了？叫停两款核心产品并裁员 28%，分析师：该行为无异于自毁长城</a>\"</p><p></p><p></p><p></p>",
    "publish_time": "2023-10-30 11:10:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "技术与实体加速融合，企业转型的新挑战和新机遇在哪？",
    "url": "https://www.infoq.cn/article/TjLavHdW9IkHp4gDqEEW",
    "summary": "<p>2016 年“新经济”被首次写入我国《政府工作报告》，2017 年报告首次明确促进“数字经济加快成长的要求。从特征与内核来看，“新经济”与“数字经济”之间一脉相承，强调以新一代信息技术为基础，推动产业持续创新，创造新的经济增长点。随着相关举措的深入发展，技术正在加速赋能实体，<a href=\"https://www.infoq.cn/article/2Zc5zKlXjzSbYa4ZaS0O?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">数字经济与实体经济的融合</a>\"成为必然趋势。</p><p></p><p>在这一过程中，从全球到全国，从地方到千行百业，都面临着全新挑战和产业机遇。那么，作为新经济的核心群体，从独角兽企业、瞪羚企业等新物种企业，到传统企业、初创企业，面对新趋势如何乘势而上？如何结合自身特点和优势制定战略目标、拆解转型路径和方法？如何从商业模式创新、实施策略落地到新型人才培养多管齐下？</p><p></p><p>10 月 31 日 19:30-21:00，极客邦科技创始人 &amp;CEO 霍太稳将<a href=\"https://live.infoq.cn/room/1915\">对话长城战略咨询</a>\"总经理武文生，畅谈数字化发展进程和趋势，深度探讨在数字经济与实体经济加速融合背景下，企业如何抓住产业发展新机遇，以及数字化人才发展需求等话题。</p><p></p><p>长城战略咨询是聚焦新经济的专业咨询机构，主要面向企业和高新区提供新经济咨询服务。长城战略咨询总经理武文生是企业战略咨询、区域发展战略、瞪羚独角兽研究领域专家。担任国家现代服务业总体专家组专家、中国企业联合会管理咨询专业委员会副主任委员及多家上市公司独立董事等。多年来主持完成了 200 余项企业战略咨询、公共咨询项目。</p><p></p><p>点击链接或扫描二维码即可报名预约本次直播：<a href=\"https://live.infoq.cn/room/1915\">https://live.infoq.cn/room/1915</a>\"</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/43/43e1e6326d9170f9dfb2626ecbcc5b69.jpeg\" /></p><p></p>",
    "publish_time": "2023-10-30 12:38:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "北京银行数字化转型：用近2年时间，从“搭梁立柱”到“积厚成势”",
    "url": "https://www.infoq.cn/article/GItTCDMzzSsxMcojWydF",
    "summary": "<p>嘉宾 |&nbsp;马晓煦&nbsp;北京银行软件开发中心总经理</p><p></p><p>北京银行董事长霍学文曾在 2021 年年报业绩说明会上提出，要通过三年时间，推动北京银行数字化转型成效达到同业领先水平。经过近 2 年发展，北京银行数字化转型已经由“搭梁立柱”步入“积厚成势”的新阶段，数字化转型活力、生产力、价值创造能力开始在前中后台、各个业务领域不断显现。</p><p></p><p><a href=\"https://www.infoq.cn/news/LXvjWcVPomoOQTNcGKfj\">北京银行</a>\"是数字化转型的先行者，也是受益者。举例来说，2023 年上半年年北京银行 AUM 规模达到 10,094 亿元，成功迈入“万亿俱乐部”，MAU 达 546 万户，同比增长 17.4%，居城市商业银行首位。这一成绩和该行零售数字化转型工作密切相关。2023 年上半年业绩发布会上提出，北京银行推出手机银行 APP7.0 和 8.0，全面优化功能和体验，建立“智策”零售数字化运营体系触达客户超 1.7 亿人次，零售业务决策、运营数字化水平显著提升。</p><p></p><p>体现在经营业绩上，北京银行在 2020 年就成为了首家总资产突破 3 万亿元的城市商业银行，这个数字在 2023 年半年报中已经达到了 3.63 万亿元——数字化无疑在其中发挥着无可替代的作用。</p><p></p><p>“当科技已经不仅仅是技术手段，而成为了一种营销模式或产品形态，它会直接与银行的经营业绩挂钩，这时候，数字化需求也会越来越迫切。”北京银行软件开发中心总经理马晓煦在参与中国信通院“<a href=\"https://www.infoq.cn/article/ayoRDx1sfgLSTt4pGaDl?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">铸基计划</a>\"”中国企业巡礼采访时，介绍了北京银行如何从战略文化、组织流程到技术重塑各个层面推进数字化，以及在这个过程中，如何通过科技资源投入与业务目标的匹配，量化和评估技术的价值。</p><p></p><h3>北京银行数字化转型的战略体系</h3><p></p><p></p><p>与别的企业“试探性”的技术应用不同，据马晓煦介绍，北京银行形成了一套完整的数字化转型方法论和思路：在战略层面围绕“数字京行”体系展开，树立“一个银行（One Bank）、一体数据（One Data）、一体平台（One Platform）”的目标和理念。具体工作方法包括清单化管理、项目化推进、责任化落实、矩阵式管控，最终实现以数字化统领发展模式、业务结构、客户结构、营运能力、管理方式“五大转型”。</p><p><img src=\"https://static001.geekbang.org/infoq/75/75cba33a96634631de7ee70944a2038b.png\" /></p><p></p><p>其中“一个银行”指的是采用集团化经营模式，打破传统银行、保险、基金、消费金融、金融租赁、金融科技公司之间的“竖井”，在监管合规的前提下，将北京银行视为一个整体，强调跨部门、跨业务线、跨子公司的协同联动和资源化整合。无论从战略还是具体流程上，都能够实现内部资源统一管理及协同合作，以形成合力提高工作效率和质量。</p><p></p><p>此外，“一体数据”同样强调“统一”的思路，通过构建集中统一的<a href=\"https://www.infoq.cn/article/YkoAO2bNtwRX7usWIoPG?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">数据平台</a>\"，实现数据的全面、准确和实时共享，让数据真正发挥作为生产要素的价值，帮助业务创新和优化。“通过数据统一，我们可以更好地了解客户、优化服务、提升风控水平，加强市场响应和决策能力。”马晓煦指出。</p><p></p><p>而作为基座，“一体平台”指的是统一金融操作系统，构建平台层面的统一、开放、灵活和可拓展。马晓煦强调，这个平台既是技术平台，能够以公共技术标准开展行内技术开发，同时也是一个运行操作平台，用于支撑金融服务和业务创新。在北京银行，金融操作系统承载着业务与技术的融合——从技术角度来看，可以提供稳定高效的运营环境，满足主流技术发展趋势；从业务角度来看，通过统一的平台，使得多方可以共享公共能力，形成完整业务链条，满足快速敏捷的开发和部署。</p><p></p><h3>技术革新，打赢三大“战役”</h3><p></p><p></p><p>要从业务、数据到技术各个层面做到“万物归一”，中间还隔着数十年日积月累的技术包袱。“<a href=\"https://www.infoq.cn/article/GyBqNNq4R6ULMAAt02yJ?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">技术包袱</a>\"是几乎每一个传统企业面临的共性问题，由于技术存在迭代周期，许多新旧技术都会混杂在企业现有存量 IT 资产中。另外，建设有先有后，这导致许多历史沉淀的数据标准不统一，信息孤岛和烟囱式架构非常普遍。信息化建设时间越长，这些问题越突出。”马晓煦说。</p><p></p><p>然而，北京银行的数字化文化、战略、理念和目标宣导会被贯彻到每一个流程、每一个会议，落实到每一个人、每一个细节。有了从上到下的决心和魄力，2023 年上半年，北京银行秉持“一个银行、一体数据、一体平台”的理念，完成统一数据底座、统一金融操作系统、统一风控平台建设，打赢数字化转型“三大战役”，推动全行数字化转型能力迈上新台阶。</p><p></p><p>统一数据底座：构建集中统一的数据平台，实现数据的全面、准确和实时共享，让数据真正发挥作为生产要素的价值，帮助业务创新和优化。已由建设阶段转入持续运营阶段，累计完成 709 个实体、18477 个属性建设，沉淀形成企业级指标标签体系，北京银行业务系统的主本数据已纳入统一数据底座并实现汇聚贯通。北京银行的思路是，先把数据聚集起来，然后从数据应用的角度反推数据治理。</p><p></p><p>统一金融操作系统：北京银行以“统一模型、统一机制、统一平台、统一语言”为原则，以“高并发、高穿透、高协同、高一致、高体验；<a href=\"https://www.infoq.cn/article/lqvpIfkpbiv6Q7vO7N2A?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">低代码</a>\"、低耦合；智能化”（即 5 高 2 低 1 智能）为建设目标，打造“联通、贯通、通透”的统一金融操作系统平台，向下对接海量数据，向上支撑系统敏捷开发与灵活部署，打通系统竖井，实现资源的合理配置、服务的质量提升。</p><p></p><p>马晓煦强调，这个平台既是技术平台，能够以公共技术标准开展行内技术开发，同时也是一个运行操作平台，用于支撑金融服务和业务创新。通过公共领域能力上架，打造稳定、灵活、组件化的企业级架构，构筑北京银行未来的“数字新基建”。基于统一的技术底座和微服务框架，让具有技术知识的业务人员和具有业务知识的技术人员，都可以在沙箱中通过低代码 / 无代码的方式，进行应用原型设计和功能验证迭代。</p><p></p><p>统一风控平台。以新信用风险管理系统为建设重点，聚焦“公共能力支撑、双客极致体验、智慧风控管理、流程服务集约、数据标准应用”五大能力主题，通过构建统一风控平台，建立“一门户、四中台”，打造新一代<a href=\"https://www.infoq.cn/article/TJg7MXJ5WM1ayMsW8xtc\">自主可控</a>\"、全行级的对公信贷基础设施，有效提升全面风险管理水平。</p><p></p><h3>业技融合，是推动数字化转型的必由之路</h3><p></p><p></p><p>数字化转型的核心要义更多在于“技术赋能”，即让金融科技的发展转化为银行服务客户、业务增长的实际价值。为保证科技部门能够及时、高质量反映业务部门需求，今年以来，从科技部门内部做了诸多重大改革，打出推动数字化转型”组合拳“。</p><p></p><h4>（1）统筹业务技术资源，聚焦客户旅程，重组业务流程</h4><p></p><p></p><p>北京银行强调每个人都与数字化转型息息相关，每个人都将从数字化转型中受益，每个人都能为数字化转型贡献力量、创造价值，从而积极投身到数字化转型进程中来。全行从上到下，都号召要有数字化思维，在产品设计时要<a href=\"https://www.infoq.cn/article/RFGAkFHxTtyrAaphHBh0\">聚焦具体的业务流程</a>\"，站在完整的客户旅程视角对业务进行重组，打破原来部门之间的壁垒。</p><p></p><p>以新信用风险管理系统建设为例：过去银行信贷涉及大量纸质单据填写，需要客户经理或一线服务人员线下进行客户调查，大多数工作都靠手工完成，效率极低；与此同时，在收到客户申请后，银行内部需要调动包括支行、分行、业务管理和风控管理等在内的许多不同岗位和部门进行贷款审批，他们之间都有独立的系统，信息同步不及时且难度极大。</p><p></p><p>对此，北京银行完成了新的流程设计，从客户贷款意向开始，到客户信息录入、数据采集、审批、复审，再到相应的额度评估、最终的贷款发放以及贷后管理，进行了端到端全流程的重新梳理。“在这个过程中，我们考虑的不仅仅是某个或者某几个部门的需求，而是真正从客户的角度出发，去调研客户和前中后台的操作人员、管理者，了解他们的痛点。同时会识别这个流程下哪些环节已经基于系统，哪些还是手工，哪些是跨系统，哪些又是断层的。”马晓煦告诉 InfoQ，最终，北京银行梳理出了 300 多个痛点，并针对这些问题对过去的流程进行了重塑，统一归入新信用风险管理系统进行处理和管理。</p><p></p><p>让一线使用人员担当体验官，取得了非常好的效果。值得一提的是，这一工作的开展并不是由某一个业务部门或者技术团队主导，而是由专门设立的统筹架构办职能部室作为 PMO 的角色管理整个项目，负责总流程的统筹和协同。</p><p></p><h4>（2）持续增加科技投入和复合型人才培养</h4><p></p><p></p><p>近年来，北京银行在数字化转型方面持续加大资源配备，2022 年全年信息科技投入占营业收入比重为 3.7%。其中，研究开发类投入 8.4 亿元，同比增长 56%，在同业中继续保持较高投入强度。北京银行还在科技人才培养上投入了大量精力，截至目前总分行科技团队及金科公司合计约 2000 人。</p><p></p><p>北京银行内部不仅通过相关机制鼓励技术人员主动学习业务知识，同时，还会提供系统化的培训，让技术人员能够更便捷地参与银行业相关的认证考试。此外，科技部门还会派遣专门人员到业务部门提供技术服务，开展数字化转型对接工作。“这是促进业务和技术融合非常重要的手段，因为北京银行科技部门和业务部门的办公地点是分开的，这时候就需要创造一些面对面沟通和协作的机会。”</p><p></p><p>以马晓煦本人为例，在就任软件开发中心总经理之前的 3 年时间里，他一直在业务领域部门工作，“当市场上有新的机会出现，我们会通过敏捷的方式，快速搭建虚拟团队，从而快速响应市场需求。同时，在这个过程中持续培养对应的人才梯队，沉淀业技融合的工作模式。”</p><p></p><p><a href=\"https://www.infoq.cn/article/UqwUpeulZvtsu8UmNcyr\">复合型人才</a>\"的培养还体现在有针对性地进行人员招聘。在业务部门，从过去招聘金融、经济类人才，转变为招聘具有理工科、计算机、信息电子类背景的人才；而在金融科技公司，则是吸引具有金融背景的专业人才，从中培养产品经理、模型分析师和数据专家，让他们快速把专业技能带入行业，在新型岗位发挥作用。</p><p></p><h4>（3）通过科技资源投入与业务目标的匹配，评估科技价值</h4><p></p><p></p><p>整体而言，北京银行的数字化转型步调可谓大刀阔斧，科技投入可谓大手笔。但是，马晓煦坦言，面对大型国有银行的投入，仍然难望项背。因此，对于北京银行来说，更深知“把<a href=\"https://www.infoq.cn/article/gCQGEgWrVX4PMNP1ohOJ\">有限资源</a>\"用在最有价值事情上”的道理。“尤其是在外部环境充满不确定性的当下，更精准地找到投入方向，回归到真正的经营发展和能力提升上，并且关注投入产出比，这变得越来越重要。”</p><p></p><p>为此，北京银行启动了重大项目识别机制，去年从业务部门报送的数百个系统建设项目中，经过科技部门与业务部门的一对一对接沟通和讨论、金融科技委员会现场评审等环节多轮筛选，最终确定了 20 个重大项目作为今年科技投入的重点。</p><p></p><p>以 20 个科技重大项目牵引全行数字化转型向纵深推进，采用“业务分析师 + 系统架构师”（BA+SA）双向负责制，将全行在科技建设领域最核心资源聚焦到这 20 个项目当中，已实现新信用风险管理系统、企业级客户及用户管理平台、场景支付 2.0 等首批科技重大项目投产。</p><p></p><p>今年科技部门主动变革，重塑科技管理体制，从“制度流程化、流程系统化、管理可视化”角度出发，落地了”京征程“科技管理改革工程，完成科技管理流程、工具、人力、管理、能力等核心领域的全面重塑。制定了 5 类项目 25 个子流程，明确了 12 个岗位 80 个细分角色，完善了 16 个制度流程建设，已经用该套方法工艺纳管全部重大项目，让科技管理更加精细化，有效提升科技交付的效率和质量。同时，在管理驾驶舱还可以清晰的看到每个项目的投入人员、具体进展、有无风险等信息，使科技投入更加透明，成果更加清晰。</p><p></p><p>“总而言之，我们认为企业数字化应该更加聚焦与业务目标的协同，技术与业务之间应该进一步联动和互通有无。当然，在过去多年时间里，很多企业都已经在这方面有所探索，只是过程并不容易。每个企业还是应该基于自身特点去落地实现。”马晓煦表示。</p><p></p><h3>写在最后</h3><p></p><p></p><p>数字化转型并非新鲜概念，过去很多人对数字化的定义并不清晰：有人认为数字化解决的是技术问题，只涉及科技部门；有人认为数字化与科技是两回事，数字化等同于做线上化业务和线上化流程，拥有线上化板块和收入。</p><p></p><p>反观北京银行，数字化被视为全行整体发展战略，涉及战略投入、资源整合以及人才培养等多个方面。马晓煦表示，希望北京银行的数字化转型实践可以为同业带来参考思路。</p><p></p><p>北京银行多年来也与中国信通院等机构保持着紧密的合作和交流。“在这个过程中，信通院能够为我们这样的企业提供技术趋势和技术选型方面的向导和引领；而对于北京银行，我们也希望在其中贡献自己的力量，总结和输出有价值的方法论和实践经验。”</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/e2/ca/e205602269fc52b1557a8c4a4e7b91ca.png\" /></p><p></p><h4>活动推荐</h4><p></p><p>首届<a href=\"https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">FCon全球金融科技大会</a>\"将于 11 月 19-20 日在上海举办。<a href=\"https://www.infoq.cn/article/SNqfIDkSU04mbKDpRRv4?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">北京银行高级经理张汝成</a>\"将在大会上发表题为《建设“金融操作系统”，探索平台工程实践》主题分享，介绍北京银行自主研发的金融操作系统的建设思路、内容、设计要点，以及实践中的经验总结。</p><p></p><p>此外，本次大会还邀请到工商银行、招商银行、汇丰银行、兴业银行、中信银行、平安人寿、度小满、蚂蚁集团等业界知名银行以及金融机构的大咖，前来分享大模型、 Web 3.0 、隐私计算、数字货币、区块链等前沿技术在金融领域的落地案例。</p><p></p><p>我们诚挚地邀请您加入我们，共同探索金融科技的未来。点击链接即可查看全部演讲专题。</p><p></p><p>目前是<a href=\"https://fcon.infoq.cn/2023/shanghai/apply?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\"> 8 折特惠购票</a>\"，报名立减 ¥1360，咨询购票可联系：17310043226（微信同手机号）</p>",
    "publish_time": "2023-10-30 13:43:54",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "前端所有主流框架，其实都是在自欺欺人",
    "url": "https://www.infoq.cn/article/Xmuo1eijM3OOBhqWdKM2",
    "summary": "<p>怎么样，这个开头够不够标题党？但大家千万别误会，我并不是要侮辱接下来列出的这些技术，而是想跟各位讨论一个困扰了我很久的问题。</p><p></p><p>另外，本文并非软文，不会向大家推销什么“完美的替代方案”。</p><p></p><p></p><h2>一切要从 Svelte 说起</h2><p></p><p></p><p>本月初，Svlte 5 预告片正式发布，其中介绍了新的 runes。</p><p></p><p>大家似乎都对此感到兴奋，我自己也一样。</p><p></p><p>真正让我恼火的，其实是 Svelte 在解决 UI 问题时同样选择了东拼西凑的方案。</p><p></p><p>为什么组件中的反应方法仍然需要转译 / 编译？为什么还在使用带有假指令的劫持 HTML 语法？</p><p></p><p>为什么 UI 表达还是命令式的？为什么开发技术还在试图模仿 HTML？</p><p></p><p>让我们先从最后一点说起。</p><p></p><p></p><h2>谁说 HTML 就是正确的抽象？</h2><p></p><p></p><p>有些朋友可能觉得我在无理取闹。可能吧，但 HTML 本身也只是 DOM 树的映照，是一种表示树结构的方式，而且还不是最优的那种。没错，绝对算不上最优。</p><p></p><p>可别误会，我不是说 HTML 本身有啥问题——它确实是项很好的技术，有它自己的功能定位。但浏览器不会直接处理 HTML，而是处理 DOM 节点。另外，所有主流客户端库 / 框架现在都会直接通过 JS-API 生成 DOM，借此回避 HTML 表示。也就是说，我们不仅可以使用 HTML，也可以使用其他 DOM 序列化格式作为目标 DOM 描述语言。典型的例子包括 HAML 还有 JSON。所以从这个角度来看，使用 HTML 模板更多是种对固有传统的致敬，而不是真有什么必要性。</p><p></p><p>再有，为了完整描述每个 DOM 节点，就需要用到以下七种 props：</p><p></p><p>属性处理程序样式data- 属性可见性文本内容子元素</p><p></p><p>可遗憾的是，很多开发者压根没意识到或者没考虑过，我们其实并不需要隐藏这种复杂性。这是我们自己的平台，当然有责任把一切都搞清楚。</p><p></p><p>此外，现代开发会假定组件可以拆分。而有拆分，自然就有组合。所以说我们需要一款工具来创建组件实例，对其进行自定义，再通过不同方向的反应链接把它们相互对接起来。而这一切，在 HTML 中都没办法实现。</p><p></p><p>遗憾的是，几乎所有 UI 解决方案使用的都是最原始的技术——用简单性建议一次又一次自欺欺人。</p><p></p><p>它们都试图把 DOM 节点属性的多样性压缩成一份简单的属性列表。这样根本没用。而且它完全可见。把 DOM 节点 props 的七种类别压缩成一份扁平的属性列表并不会让开发更轻松，毕竟这七种类别仍然存在，只是换了种形式。</p><p></p><p></p><h2>复杂性，它严重吗？</h2><p></p><p></p><p>解释一下，这里的复杂性分为两种类别：引入的，还有天然的。引入复杂性来自库、框架、语言和范式等。天然复杂性则是平台本身所固有的，旨在解决领域内的基本问题。出色的工程师会减少引入复杂性，并尝试接受并处理天然复杂性。所以，请别再刻意隐藏天然复杂性，尊重平台的客观现实才是正道。</p><p></p><p></p><blockquote>这里我要再对Svelte说几句：Rich Harris发布的这段视频相当精彩，介绍了getter和setter的情况，还回应了一些人对于Svelte新的反应方法的担忧。但唯一没能充分解决的，就是“必须编写更多代码”这个问题。我们的最终目标不是编写更少的代码，而是在明确表达应用程序意图的前提下编写更少的代码。如果这项技术单纯强调“简单性”，那就是在试图掩盖种种重要的细微差别。它们最终还是会暴露在开发者面前，只是角度有所不同。</blockquote><p></p><p></p><p></p><h2>但现在只给你 HTML</h2><p></p><p></p><p>现代前端中之所以还是沿用类 HTML 解决方案，主要理由就是“开发人员更熟悉”。只要大家之前用过 HTML，那么 Vue 或者 Angular 等模板也就是在对已经精通的内容做扩展。但如果再深挖下去，我们就会发现事情没这么简单——不管宣传怎么说，它们本质上并不是 HTML。</p><p></p><p>换言之，这些格式都是模拟出来的幻象。</p><p></p><p>虽然看似是扩展，但它们实际上却属于完全不同的格式。现在它们呈现为类 HTML 的形式，可未来随时有可能转换成其他某种完全独立的新形式。而且在这类格式当中，每个属性都有不同的语义，但在语法上又相互等效，这当然容易产生误导效果。</p><p></p><p>下面咱们来看看这个 Angular“模板”（语法高亮完全对不上，请大家直接忽略）：</p><p></p><p><code lang=\"null\">            Editable            </code></p><div><code lang=\"null\">        Result    </code></div><code lang=\"null\">    \n</code><p></p><p></p><p>#input 属于本地标识符，用于通过 TS 访问。class=“editable” 是通过 CSS 绑定样式的类的名称。side=“left” 是放置此元素的 slot 的名称。[(checked)]=“editable” 是嵌套组件与外部组件的属性的双向绑定。[enabled]=“editable” 则是单向绑定。text=\"{{text}}\" 也是一样。placeholer=“Markdown content…” 是某种 Markdown 文本。i18n-placeholder=“Showed when input is empty.” 这里突然又说占位符属性是可翻译的，并对翻译器做了解释。*ngIf=“text” 这部分跟组件完全无关，负责控制组件是否能在父级中呈现。</p><p></p><p></p><h2>它们用起来又是一样的</h2><p></p><p></p><p>所以在我看来，非得从 onClick={…}、on:click={…} 和 @click=\"…\"当中做出选择，其实就是缺乏选择的表现。我真的受够了。</p><p></p><p>从某些方面来说，十年之前的解决方案是这个样子倒是可以理解：</p><p></p><p>因为这样的栈易于使用、但难于设计。因为早期的应用程序更简单，而且原始的模板方法足以支持 DOM API。因为直到最近 4、5 年，这种形式的代码才具有合理的运行性能。</p><p></p><p>总结成一句话，就是：</p><p></p><p>因为我们需要大量时间进行试验，并且能够接受新实现和当前方法的失败。</p><p></p><p>不幸的是，大家很少关注后面一半。但我也理解，毕竟这就是习惯的力量。但每一年过去，僵化的现实都令人心生不满。难道大家不会为自己在 HOC、render-props 和其他毫无意义的东西上浪费的时间感到心痛吗？</p><p></p><p>于是我开始认为这已经形成了一种畸形的逻辑链：因为我们没有学会如何正确地开发一套平台，所以才因为各种妥协而浪费精力；这就导致财务成本很高且难于维护，致使如今的应用开发仍然很困难。</p><p></p><p></p><h2>被劫持的语法</h2><p></p><p></p><p>大家可能会抱怨 React 中的 JSX 语法、Vue 中的模板方法，或者 Svelte 中的组件。没错，它们都有各自的毛病。但原因并不是它们不够好，而是它们从根本上就选错了方向、而且错得离谱。</p><p></p><p>下面咱们一起看点代码示例，我会借此论证自己的判断：</p><p></p><p></p><h3>React</h3><p></p><p></p><p><code lang=\"null\">function Component() {  return (    </code></p><div><code lang=\"null\">      <h1>Hey there</h1>    </code></div><code lang=\"null\">  )}\n</code><p></p><p></p><p></p><h3>Vue</h3><p></p><p></p><p><code lang=\"null\">  <div>    <h1>Hey there</h1>  </div>\n</code></p><p></p><p></p><h3>Svelte</h3><p></p><p></p><p><code lang=\"null\"></code></p><div><code lang=\"null\">  <h1>Hey there</h1></code></div><code lang=\"null\">\n</code><p></p><p></p><p>说实在的，它们看起来都还不错。</p><p></p><p>但在尝试添加一些条件渲染之后，情况就不同了：</p><p></p><p></p><h3>React</h3><p></p><p></p><p><code lang=\"null\">function ConditionalComponent({ showMessage }) {  return (    </code></p><div><code lang=\"null\">      {showMessage ? (        <h1>Hey there</h1>      ) : null}    </code></div><code lang=\"null\">  );}...\n</code><p></p><p></p><p></p><h3>Vue</h3><p></p><p></p><p><code lang=\"null\">  <div>    <h1>Hey there</h1>  </div>...<=\"\" code=\"\"></code></p><p></p><p></p><h3><code lang=\"null\">Svelte</code></h3><p></p><p></p><p><code lang=\"null\"><code lang=\"null\"></code></code></p><div><code lang=\"null\"><code lang=\"null\">  {#if showMessage}    <h1>Hey there</h1>  {/if}</code></code></div><code lang=\"null\"><code lang=\"null\">...\n</code><p></p><p></p><p>呃……</p><p></p><p>视图树内的 If 语句回退为 null（或者某些插件组件，但这并不重要）？v-if 指令是什么？{#if …}模板块又是什么？带 *ngIf 的结构指令？我得说 DOM API 里压根没有这些东西，它们单纯就是些廉价的把戏。请注意，我针对的不是它们的命名，而是其概念本身。</p><p></p><p>其中最引人注目的，还得数 Vue。我们要么使用 v-if 并每次都销毁组件，要么愚蠢地把组件隐藏掉。都 2023 年了，还在用 display: none？这完全就是对开发平台的亵渎好吗？</p><p></p><p>而且有问题可不只是 Vue。比如在 React 当中，函数组件的内容也充满了副作用。因此，只能大量使用重新渲染来计算这些副作用并更新数据，白白增加不必要的工作量。</p><p></p><p>“虽然 React 导致了不必要的重绘，但其底层机制还是有道理的，就是为了优化性能并让 UI 跟应用程序的数据保持同步。”真的吗？拜托面对现实吧，重新渲染绝对是每个人都想绕着走的麻烦事。而像 useMemo 和 useCallback 这类“解决方案”也仍不足以彻底消除额外渲染。</p><p></p><p>我再说一次，这就是自暴自弃加盲目妥协的产物。能解决问题的不是加快重新渲染速度，而是消除不必要的重新渲染步骤。</p><p></p><p>具体方式，可以对整个接口树做静态初始化。每个元素（更确切地讲，是栈内元素的回调）只会被计算并调用一次，从而将反应值跟节点关联起来。如此一来，主任务就只须执行一次所描述的代码，接下来沿着 DOM 图的数据 / 事件流推进即可。</p><p></p><p>咱们继续讨论。比如说要对一个列表中的内容进行渲染，它们分别是这么干的：</p><p></p><p></p><h3>React</h3><p></p><p></p><p><code lang=\"null\">function UserList() {  return (    </code></p><div><code lang=\"null\">      <ul>        {users.map(user =&gt; (          <li>{user.name}</li>        ))}      </ul>    </code></div><code lang=\"null\">  );}\n</code><p></p><p></p><p></p><h3>Vue</h3><p></p><p></p><p><code lang=\"null\">  <div>    <ul>      <li>{{ user.name }}</li>    </ul>  </div>\n</code></p><p></p><p></p><h3>Svelte</h3><p></p><p></p><p><code lang=\"null\"></code></p><div><code lang=\"null\">  <ul>    {#each users as user (user.id)}      <li>{user.name}</li>    {/each}  </ul></code></div><code lang=\"null\">\n</code><p></p><p></p><p>好吧，又来了。大量虚构的语法、模板、还有指令。这种情况过去有、现在有，将来恐怕还是有。毕竟看那个意思，React 和 Vue 两位大哥毫无做出改变的念头。而这样的技术一旦脱离了主流，大概率会沦为难以维护的遗留债，不信就想想当年的 Ember 吧。</p><p></p><p></p><h2>拥抱 DOM API</h2><p></p><p></p><p>下面，咱们继续聊聊有可能解决这个问题的潜在答案——DOM API！这里有不少有趣的点，而且奇怪的是，多年来人们其实一直在做潜心研究。DOM API 体量庞大、功能繁多，而且其中很多特性根本没法用 props 掩盖掉。</p><p></p><p>例如，我们要怎么解决条件渲染的问题？DOM API 提供 node.append() 或 node.appendChild() 方法、node.remove() 方法和 node.isConnected 属性。我们可以用它随时添加或删除节点，并确定其是否接入 DOM 树。</p><p></p><p>接入 DOM 树的节点（甚至是其子节点）的状态就应该由组件本身来报告，而非借助那些外部块。所以我们完全可以这样：</p><p></p><p><code lang=\"null\">export function Component({ showMessage }) {  h('div', () =&gt; {    h('h1', {      text: 'Hey there',      visible: showMessage,    })  })}\n</code></p><p></p><p>用不着虚构语法和扩展，也不必非得把这些基本特性隐藏在 props 之下。这就是个常规的 JS 函数，有着用于跟 DOM 交互的便捷 API。那要怎么在应用程序中使用这个组件？当然就是把它当普通函数处理喽：</p><p></p><p><code lang=\"null\">using(body, () =&gt; {  Component({ showMessage: true })})\n</code></p><p></p><p>注意，这里只是一段伪代码示例。</p><p></p><p>这种方法借鉴了 SwiftUI 和 Flutter 的思路。其中的第二个回调参数就相当于 SwiftUI 中的嵌套组件块，visible 属性就类似于 Flutter 中的 visible 属性。没错，这里的 visible 不再是 Vue 中的“花招”，而会从子树中实际插入 / 提取 DOM 节点。</p><p></p><p>这样，我们就不用发明一大堆抽象语法来模拟自己需要的行为。是的，我知道很多朋友可能并不喜欢 JavaScript，也能理解个中缘由。但前端开发的“原生”语言仍然是 JavaScript，尝试用虚假的解决方案绕过它只会让事情变得更糟。类似的情况之前出现过很多次了，无一例外。</p><p></p><p>好的，处理 visible 的方法已经基本清楚了。那渲染组件列表又该如何？下面来看：</p><p></p><p><code lang=\"null\">export const function User({ key, name, isRestricted }) {  h('li', {    attr: { id: key },    text: name,    visible: isRestricted,    classList: [\"border-gray-200\"]  })}using(document.body, () =&gt; {  h('ul', () =&gt; {    list(users, ({ store: user, key: idx }), () =&gt; {      User({ key: idx, name: user.name, isRestricted: user.isRestricted })    })  })})\n</code></p><p></p><p>这种方法参考的是 SwiftUI 的解决思路，即：</p><p></p><p><code lang=\"null\">List(users) { user in  // usage of user}\n</code></p><p></p><p>此外，所呈现代码中使用的每个变量或属性都可以是反应式的。这样，每当我们更改用户列表或其属性时，结果都会反映在最终布局当中。</p><p></p><p>为什么不用 for/map 循环？因为 for/map 循环是个黑箱，会与内部调用的上下文相脱离，我们根本没办法提前采取行动。例如，React 要求开发人员为此类列表中的各个条目指定唯一键，借此使其保持稳定。看见没有，又是个明明没有困难、非要制造困难的典型。</p><p></p><p>再有，这种 list 方法也让列表本身更加精巧。它不再计算列表中各个条目的所有内容，而是创建模板（请注意，是 JS 模板，不要跟 Vue 等其他模板弄混了）以供应用程序使用。这些模板会提前生成，每次 list 调用对应一个模板。这样，每当 users 的反应值发生变化，我们就只需要为已配置模板创建新实例，而不必在运行时内计算所有内容。</p><p></p><p>但遗憾的是，不少现代解决方案仍在使用虚拟 DOM 和协调（reconciliation），引入阶段的概念来检查从组件返回的结构变更。正因为如此，重绘和性能问题才反反复复得不到解决。此外还有其他一些人为限制。</p><p></p><p>有一说一，Svelte 在这方面表现得不好。它并不依赖虚拟 DOM，而是使用编译器将组件转换为 JS。转换出的 JS 代码非常高效，但又会引发新的问题：不必要的 build 步骤，而且 Svelte 的这些特定代码会一直存在于最终包当中。所以说，重新渲染和假语法问题依旧在那里。</p><p></p><p>咱们再次回归主题。那事件处理程序和属性规范呢？我们用以下代码为例：</p><p></p><p><code lang=\"null\">using(document.body, () =&gt; {  h('section', () =&gt; {    spec({ style: {width: '15em'} })    h('form', () =&gt; {      spec({        handler: {          config: { prevent: true },          on: { submit },        },        style: {          display: 'flex',          flexDirection: 'column',        },      })      h('input', {        attr: { placeholder: 'Username' },        handler: { input: changeUsername },      })      h('input', {        attr: { type: 'password', placeholder: 'Password' },        classList: ['w-full', 'py-2', 'px-4'],        handler: { input: changePassword },      })      h('button', {        text: 'Submit',        attr: {          disabled: fields.map(            fields =&gt; !(fields.username &amp;&amp; fields.password),          ),        },      })    })  })})\n</code></p><p></p><p>第一眼看去，很多读者朋友可能会觉得：</p><p></p><p>这跟常规习惯不太一样；太过冗长；必须亲自处理 DOM API 的那些琐事。</p><p></p><p>但事实真是如此吗？</p><p></p><p>其实这里没什么不一样的，它就是个 JS 函数，其余的部分分别为：</p><p></p><p>attr：带有节点属性的对象。style：带有节点样式的对象。classList：节点类的数组。顺带一提，在 DOM API 里它也叫这个名字。handler：带有节点事件处理程序的对象，其中包含配置对象 (注意 config: { prevent: true })。spec：一个打包函数，用于描述节点的属性类别（如果组件在其回调内具有子元素的话）。通过这种方式，我们可以在组件之上描述属性集（其实在回调内的任意位置都可以，但这不重要）。</p><p></p><p>有点冗长？确实，这种方法看起来确实比 React、Vue、Svelte 和 Solid 之类的要繁复。但这些框架只是让人误以为回避掉了前端复杂性，却并不能真正让事情变得简单。所以我觉得大家不妨直面现实，跟难题交朋友，而不是一味躲藏。通过这种方式，我们能够清楚了解自己的应用程序是如何构建而成。没错，确实冗长，但却并不复杂。相信大家都能看明白这是在干什么，甚至理解每一行的具体作用。</p><p></p><p>另外，这里我们也不用直接使用 DOM API。真正需要的，就是一个能用来与之交互的便捷 JS API。我也坚持认为视图树应该由原生工具管理，而对树进行添加、删除和更新的手动操作，倒是可以交给技术工具来接管。</p><p></p><p>再次强调，我不是想跟大家推销什么看似酷炫的技术工具。相反，我是想指出现有解决方案中存在的问题，还有如何通过原生工具将其解决，避免重新造轮子。</p><p></p><p>总之，我的核心观点就是尊重平台的天然属性。大家都应该学会怎么使用自己的平台，而不再像过去那样不断用新的虚假解决方案来自欺欺人。</p><p></p><p></p><h2>不出问题就别管？但真的没出问题吗？</h2><p></p><p></p><p>坦白地讲，本文展示的简单案例很难表现真实的情况，因为有些问题不会在简单的例子中暴露出来。</p><p></p><p>比方说，我们要怎么描述实际应用程序中的表单部分：</p><p></p><p><code lang=\"null\">export const Auth = () =&gt; {  h(\"div\", () =&gt; {    spec({      classList: [\"mt-10\", \"max-w-sm\", \"w-full\"],    });    h(\"form\", () =&gt; {      Input({        type: \"email\",        label: \"Email\",        inputChanged: authForm.fields.email.changed,        errorText: authForm.fields.email.$errorText,        errorVisible: authForm.fields.email.$errors.map(Boolean),      });      Input({        type: \"password\",        label: \"Password\",        inputChanged: authForm.fields.password.changed,        errorText: authForm.fields.password.$errorText,        errorVisible: authForm.fields.password.$errors.map(Boolean),      });      Button({        text: \"Create\",        event: authForm.submit,        size: \"base\",        prevent: true,        variant: \"default\",      });      ErrorHint($authError, $authError.map(Boolean));    });  });};...export const Input = ({  value,  type,  label,  required,  inputChanged,  errorVisible,  errorText,}: {  value?: Store;  type: string;  label: string;  required?: boolean;  inputChanged: Event;  errorVisible?: Store;  errorText?: Store;}) =&gt; {  h(\"div\", () =&gt; {    spec({      classList: [\"mb-6\"],    });    h(\"label\", () =&gt; {      spec({        classList: [\"block\", \"mb-2\", \"text-sm\", \"font-medium\", \"text-gray-900\", \"dark:text-white\"],        text: label,      });    });    h(\"input\", () =&gt; {      const localInputChanged = createEvent();      sample({        source: localInputChanged,        fn: (event) =&gt; event.target.value,        target: inputChanged,      });      spec({        classList: [          \"bg-gray-50\",          \"border\",          \"border-gray-300\",          \"text-gray-900\",          \"text-sm\",          \"rounded-lg\",          \"focus:ring-blue-500\",          \"focus:border-blue-500\",          \"block\",          \"w-full\",          \"p-2.5\",          \"dark:bg-gray-700\",          \"dark:border-gray-600\",          \"dark:placeholder-gray-400\",          \"dark:text-white\",          \"dark:focus:ring-blue-500\",          \"dark:focus:border-blue-500\",        ],        attr: { type: type, required: Boolean(required), value: value || createStore(\"\") },        handler: { on: { input: localInputChanged } },      });    });    ErrorHint(errorText, errorVisible);  });};...export const ErrorHint = (text: Store | string | undefined, visible: Store | undefined) =&gt; {  h(\"p\", {    classList: [\"mt-2\", \"text-sm\", \"text-red-600\", \"dark:text-red-400\"],    visible: visible || createStore(false),    text: text || createStore(\"\"),  });};\n</code></p><p></p><p>又该怎么用带有标签、属性和动态内容的预定义卡来描述日志列表？</p><p></p><p><code lang=\"null\">export const LogsList = () =&gt; {  h(\"div\", () =&gt; {    spec({      classList: [\"flex\", \"flex-col\", \"space-y-6\", \"mt-2\"],    });    list(logModel.$logsGroups, ({ store: group }) =&gt; {      CardHeaded({        tags: group.map((g) =&gt; g.tags),        href: group.map((g) =&gt; `${g.schema_name}/${g.group_hash}`),        content: () =&gt; {          LogsTable(group.map((g) =&gt; g.logs));        },        withMore: true,      });    });  });};\n</code></p><p></p><p>我们根本不需要用到这些 createStore、createEvent。Store 就是个反应值，事件则是用来改变或调用某些效果的执行信号。它们可以来自任何库。</p><p></p><p>这里最重要的就是描述视图这个基本事实，也就是视图逻辑。在我看来，哪怕视图描述本身比较简单，也不该随意引入不必要的解决方案。那目前的主流框架能否以最佳方式发挥作用？如果不能，问题出在哪里？</p><p></p><p></p><h2>HTMX 能不能解救我们？</h2><p></p><p></p><p>HTMX 可太棒了！它正在市场上积聚人气，这里请允许我向 ThePrimeagen 表达谢意。</p><p></p><p>但这项技术只是另外一种反模式，甚至夸张点说是种反平台方案。</p><p></p><p>请别误会，HTMX 确实给问题提供了答案。而且据我所知，它在功能和方法所及范围内的确很好地解决了问题。但这项技术还是老毛病——对前端的客观现实视而不见，用开倒车的方式打补丁。具体讲，它其实是把前端的问题移交给了后端，指望着“能在那边解决”。</p><p></p><p>是的，没人喜欢前端，就连前端自己也不喜欢。但咱们能不能现实一点，用户交互难道不该由客户端负责处理吗？谁见过哪款移动应用会在用户交互时把请求发给服务器，再从那边获取新布局的？桌面端有吗？</p><p></p><p>另外，使用 HTMX 还给网络连接速度带来了新的挑战，任何一点小事都去劳烦服务器真的很讨厌。并不是每个人在所有场景下都有足够好的网络连接，这么搞肯定会被印度和非洲的移动用户骂个狗血淋头。而且那里可是目前增长速度最快的新兴市场哦。</p><p></p><p>另外，这个例子可能有点极端，但大家可以尝试在 HTMX 上执行以下操作：</p><p></p><p>创建一份预订表单，预订剧院第 16 排的 4 到 8 个座位，场次为下午 1：00 至 3：30。其中 6 号座已经售出。如果一次性购买 3 个以上座位，可享受 5% 的折扣。由于是老顾客预订，所以你这一单可以得到免费的爆米花。浏览器时区为 CT，剧院时区为 ET。服务器偶尔会响应 502。</p><p></p><p>这就是我们需要在前端解决的实际问题，不用指望什么 Todo MVC 加超媒体。</p><p></p><p>HTMX 有它的作用，但更适合那些以后端为中心的任务。至于前端，咱们还是尽量用自己的功能和平台。</p><p></p><p></p><h2>本文是不是太过关注语法了？</h2><p></p><p></p><p>谈到语法这个问题，大家的观点往往各不相同。有人觉得语法不重要、没必要争来争去，但也有很多人被固有语法折磨得头痛欲裂。我想说的是，语法在“定义”技术方面确实发挥着极其重要的作用。但受篇幅所限，这里就不过多展开了。</p><p></p><p></p><h2>为什么要讨论这个问题</h2><p></p><p></p><p>大家可能觉得我对当前主流框架方案的评价过于激进，但事实并非如此。</p><p></p><p>事实上，我承认这些技术都有一定程度的必要性，也在常规前端开发当中解决了开发者的部分问题。但让我难以接受的是，我们过去十年来一直在同样的困境里打转，至今没人给开发者们提个醒。所以，我们的应用程序仍然难以复现，而且即使是在最简单的开发需求下也得承受大量不必要的工作内容。</p><p></p><p>我的观点绝不是劝大家直接放弃所有现成的解决方案。不，那也太蠢了。我也不建议大家每次都手动执行 DOM 操作，这确实该由库 / 框架 / 技术 /API 之类来代劳。我想说的是，也许是时候给那些具有严重设计缺陷的“雪花”型方案提个醒了。至于就个人来讲，我觉得这个问题很有意义。</p><p></p><p>而且行业似乎还没有意识到当前实践的缺陷，反而在错误的道路上越走越远。</p><p></p><p>总之，请尊重我们的平台、尊重它的固有特性。</p><p></p><p></p><h5>原文链接：</h5><p></p><p><a href=\"https://moonthought.github.io/posts/all-your-mainstream-ui-frameworks-are-lying-to-you/\">https://moonthought.github.io/posts/all-your-mainstream-ui-frameworks-are-lying-to-you/</a>\"</p><p></p><h5>相关阅读：</h5><p></p><p><a href=\"https://xie.infoq.cn/article/8f7976ab813eb2897f6feded9\">前端精准测试实践</a>\"</p><p><a href=\"https://www.infoq.cn/article/mNfTT4UBk5PQl3JpNt6M\">前后端分离技术体系</a>\"</p><p><a href=\"https://www.infoq.cn/article/2FhPNEatO5kkR7jeIsU5\">大前端测试的思考和在语雀的实践分享</a>\"</p><p><a href=\"https://www.infoq.cn/article/3oul1iQSxYDqvcf5vFkg?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">前端文档站点搭建方案</a>\"</p></code>",
    "publish_time": "2023-10-30 13:51:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "对标 FAISS，百度开源自研高性能检索引擎 Puck",
    "url": "https://www.infoq.cn/article/IJWBbzYmh3oYN5Oombay",
    "summary": "<p></p><p></p><p>近日，百度宣布在 Apache 2.0 协议下开源自研检索引擎 Puck，这也是国内首个适用于超大规模数据集的开源向量检索引擎。向量检索算法在个性化推荐系统、多模态检索、自然语言处理等应用场景中都发挥着重要作用，特别是在处理大规模数据和高维特征数据时。</p><p></p><p>名称“Puck”取自经典 MOBA 游戏 DOTA 中的智力英雄 Puck，象征着飘逸和灵动。这个项目经过多年在百度内部的精心打磨，而且在 2021 年底 Nerulps 举办的全球首届向量检索大赛 BIGANN 比赛中，Puck 参与的四个项目均获得第一名。InfoQ 采访了百度搜索内容技术部主任架构师 Ben，以了解该项目的发展历程和核心优势。</p><p></p><p>开源地址：</p><p></p><p><a href=\"https://github.com/baidu/puck\">https://github.com/baidu/puck</a>\"</p><p></p><p>InfoQ：是否方便介绍一下您的工作经历，以及目前的主要职责？</p><p></p><p>Ben：我从毕业即加入百度，最初在移动搜索部门，负责基础检索和相关性方面工作，经历了移动高速发展的过程。之后作为创始成员协助组建了多模搜索部负责视觉搜索，属于百度最早一批进入 AI 领域的员工。目前在搜索内容技术部，负责内容相关技术，包括内容获取、内容理解、内容计算、内容加工与生成等。</p><p></p><p>InfoQ：您从什么时候开始关注开源？是什么让您决定 Puck 要开源？选择这个时候开源的原因是什么？</p><p></p><p>Ben：我们很早就在思考开源，看到 FAISS（由 Facebook AI Research 开发的大规模向量检索库）开源之后获得了广泛的业界关注和应用，我们也希望开源 Puck 后，可以促进社区的发展，并借助社区的力量提高代码质量，加速技术创新，更好的适应市场需求。自研开源市场变得越来越成熟和规范，可能会带来更多的商业模式和合作机会。</p><p></p><p>对外开源，我们其实筹备了很久，做了大量的准备工作。大模型的爆火，导致向量检索技术获得广泛关注，我们认为，这是一个合适的开源契机。</p><p></p><p>InfoQ：您能具体讲一下 Puck 在百度的发展史，以及从您角度来看，它对于百度搜索的价值主要体现在哪里？</p><p></p><p>Ben：Puck 的想法最早来自视觉搜索业务，我们需要一个能支撑数百亿相似图片检索的 ANN 引擎，同时要能支持高吞吐、低延时、高准确、低内存、高灵活性等要求，当时业内没有能满足我们需要的引擎，于是启动了自研的过程。</p><p></p><p>2017 年 Puck 完成首次上线，在百亿图片库上成本和效果都取得了极其显著的提升；之后随着 Transformer 模型在 nlp 领域的大放异彩，基于 embedding 的语义检索越来越凸现价值，Puck 的应用也越来越广，2019 年 Puck 在百度内部开源，支撑的业务数快速增长，目前已广泛应用于百度搜索、推荐、网盘、知识图谱等内部多条产品线，支持规模突破万亿。目前 ANN 已经成为互联网底层基础技术之一，是 AI 时代的基石，搜索最重要的支撑技术之一。</p><p></p><p>InfoQ：期间经过了几次优化，优化重点是什么，您能具体讲述一下吗？</p><p></p><p>Ben：到今天 Puck 已经是一个打磨多年的产品，中间的优化数不胜数，大体来说可以分成以下几个阶段：</p><p></p><p>2016 年到 2019 年，打磨核心算法和实现，重点在基础性能优化上，不断调整细节，在自有场景上做极致优化，Puck 的核心框架在这一时期建立并沿用至今。2019 年到 2021 年，以公司内开源为标志，随着业务接入的增多，Puck 需要适配各种各样的应用场景和诉求，易用性、扩展性、功能多样性成为主要目标，像高性能的实时插入、多条件检索、分布式建库等等功能都是在这一时期完成。2021 年到 2022 年，以大规模内容关系计算应用为契机，Puck 重点优化在单实例超大规模数据下的性能，通过大尺度量化和索引结构的优化在十亿规模数据集上大幅提升性能降低成本。以参加全球首届向量检索大赛 BIGANN 并获得四项第一为标志，证明了 Puck 在这部分的竞争优势。2022 年至今，核心算法创新，提出了新的算法来适配不同数据场景，新增更多的 feature，同时完善配套设施，做外部开源准备。</p><p></p><p>这只是一个粗略的划分。实际上，Puck 的优化更多地由许多微小的优化点组成。我们在讨论中提出了大量有趣的想法，进行了大量的实验和尝试。总的来说，十个想法中最终只有一到两个能成为正式的功能。这些优化最终汇聚在一起，形成了我们今天看到的 Puck。</p><p></p><p>InfoQ：您能否详细介绍下 Puck 的核心优势和应用场景？</p><p></p><p>Ben：Puck 开源项目包含了两种百度自研的检索算法和一系列的附加功能，核心优势首先就是性能，经过多年的打磨和调优，在 benchmark 的千万、亿、十亿等多个数据集上，Puck 性能优势明显，均显著超过竞品，在 2021 年底 Nerulps 举办的全球首届向量检索大赛 BIGANN 比赛中，Puck 参加的四个项目均获得第一。</p><p></p><p>其次，易用性上，Puck 提供了一系列的适用于各种场景的功能，比如，同时提供简单易用的 API 接入，尽量少的暴露参数，大部分参数使用默认设置即可达到良好性能。</p><p></p><p>最后，Puck 是一个久经考验的引擎，经过多年在实际大规模场景下的验证打磨，广泛应用于百度内部包括搜索、推荐等三十余条产品线，支撑万亿级索引数据和海量检索请求，可靠性上有非常高的保障。</p><p></p><p>Puck 引擎这次开源了两种检索算法 Puck 和 Tinker，分别更适用于超大规模数据集和中小规模数据集，几乎可以覆盖绝大部分的检索应用场景。目前已广泛应用于百度内部搜索、推荐等多条产品线，覆盖数据规模从百万至万亿。</p><p></p><p>InfoQ：面对 AI 新浪潮，大模型在业内已越来越卷，在您看来未来开源市场会不会更卷？</p><p></p><p>Ben：AI 大模型的出现确实使得业内竞争更加激烈，但这并不是坏事。首先，大模型的发展推动了 AI 技术的进步，提高了 AI 的性能和效率。其次，大模型为业内带来了更多的创新空间和可能性，推动了开源市场的发展。</p><p></p><p>以后业内在自研开源市场的竞争会更加激烈，但这并不意味着会更卷，相反是带来了无限的可能。因为开源市场的特性是开放和共享，企业和个人可以通过开源市场获取最新的 AI 技术和模型，而无需自己从零开始开发。这有助于整个行业降低研发成本和提高研发效率。</p><p></p><p>此外，开源市场也是技术交流和创新的平台，业内人士可以在这里分享自己的研究成果，吸收他人的经验和知识，共同推动 AI 技术的发展。所以，虽然竞争会更激烈，但只要我们能适应这种趋势，积极参与交流和创新，就可以从中获益。</p><p></p><p>InfoQ：那您认为互联网公司开源项目的未来发展趋势是什么样的？会往哪方面发展？</p><p></p><p>Ben：</p><p></p><p>深度专业化：随着技术的细分，开源项目可能会更加专业化和深度化，解决更具体、更深入的问题，会更多永远专注于某一特定问题的开源项目，Puck 就是其中之一。多元化：互联网公司自研的开源项目可能会涉及更多的行业和领域，实现技术的跨界整合，形成各种行业解决方案的开源项目，这种跨界融合将有助于推动技术在各行业的广泛应用。更强的实用性：未来的开源项目可能会更注重实战和应用，而不仅仅是理论研究。开源项目会提供更多实用的工具和框架，帮助开发者更好地将理论应用到实际工作中。注重数据和算法的开源：随着数据和算法的重要性日益凸显，未来可能会有更多的数据和算法开源，以加速 AI 等领域的发展。</p><p></p><p>这些变化都将为推动科技发展和解决实际问题提供更强大的动力。</p><p></p><p>InfoQ：您提到 Puck 在内部已广泛应用，有哪些大家熟悉的产品或场景吗？能否举个例子。</p><p></p><p>Ben：大家熟悉的百度搜索和手机百度内的信息流推荐都有使用 Puck 技术。</p><p></p><p>InfoQ：请问开源后是否收到了社区的一些反馈，对您有怎样的启发？</p><p></p><p>Ben：自从 Puck 开源以来，我们已经收到了不少来自社区的反馈和建议。这些反馈和建议对我们来说是非常宝贵的，它们不仅帮助我们发现了 Puck 的一些问题和不足，也为我们提供了改进和优化的方向。</p><p></p><p>对我个人来说，这些反馈启发我认识到，虽然我们在内部使用 Puck 有着丰富的经验，但在面对更广泛的用户群体时，我们还需要不断学习和提高。每个用户的需求都可能不同，我们需要更加深入地理解用户的需求，才能更好地优化 Puck，使其更加适应不同的使用场景。</p><p></p><p>同时，这些反馈也让我深切地感受到了开源社区的活力和创新精神。许多社区成员不仅提出了问题，还积极地提供了解决方案，这种积极参与和贡献的精神让我深感鼓舞。我希望在未来，我们能够更紧密地与社区合作，共同推动 Puck 的发展。</p><p></p><p>InfoQ：Puck 对您个人的意义，您对 Puck 的未来有什么期待？</p><p></p><p>Ben：Puck 是团队长时间研究和努力的成果，作为 Puck 的负责人，我对这个项目有着深深的热爱和执着，对我个人来说，它不仅仅是一个检索引擎，而是代表团队付出的心血和智慧的结晶，它是我们对技术的追求，对创新的执着，也是我们对未来的期待和憧憬，Puck 的每一次升级和优化都记录着我们的成长和进步。</p><p></p><p>对于 Puck 的未来，我有着很高的期待。首先，我希望 Puck 能在开发者社区中得到广泛的使用，同时也能得到社区的反馈，不断优化和改进。我期待看到更多的人参与到 Puck 的开发和使用中来，通过大家的共同努力，让 Puck 成为 AI 领域有影响力的一款工具。其次，我希望 Puck 能够持续创新，不断优化，保持其技术领先地位，不仅能适应现有的技术需求，还能预见并引领未来的技术趋势。最后，我希望 Puck 能在更多实际应用中发挥出它的价值，为人工智能在各个行业的应用提供强大支撑，推动科技的发展。</p><p></p><p>采访嘉宾简介：</p><p></p><p>Ben，百度搜索内容技术部主任架构师，负责多模态内容理解、超大规模内容关系计算、内容加工与生成、模型优化等方向。</p><p></p><p>今日好文推荐</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651185124&amp;idx=1&amp;sn=ea0d371925430a03850c4aac3902b316&amp;chksm=bdb827b78acfaea1c04b0e7bc8df4b7049600841f5bc75d641d35ce7a31c971ad6920cea057d&amp;scene=21#wechat_redirect\">“这是一件关于云服务的大事儿！”英特尔 4400 万美元投资基础设施初创公司，硬刚公有云</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651184841&amp;idx=1&amp;sn=b40ceb7de4cec3687f833ff2af20350a&amp;chksm=bdb8269a8acfaf8cfbadd25cdf4ceb314eed3dc188c36af4f549eac2f210e1f599cedc5a627c&amp;scene=21#wechat_redirect\">头发丝 1/60 的精度，中国每 10 辆新能源汽车就有 6 辆用这家齿轮</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651184755&amp;idx=1&amp;sn=2d50fceb66679dfaa6e5b9470ba5aee6&amp;chksm=bdb826208acfaf367cc3f8d2cf57a6ec6b9b0c00d731b988812591dde22864ebb3c5545db675&amp;scene=21#wechat_redirect\">语雀突发 P0 级事故！宕机 8 小时被网友怒喷，运维又背锅？</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651184614&amp;idx=1&amp;sn=b43b9e284546eb0a88e5cd88aac46de4&amp;chksm=bdb825b58acfaca3d677861a4deccc0719767a1de6fc85d33061016eb6017a505b6fff532a73&amp;scene=21#wechat_redirect\">智谱 AI“超 25 亿融资”的背后</a>\"</p><p></p><p></p><p></p>",
    "publish_time": "2023-10-30 14:17:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "是时候基于云重新设计 Kafka 了！AutoMQ 如何实现 Kafka 十倍的降本增效",
    "url": "https://www.infoq.cn/article/9U6Nue5fTLPRNCKXYJ8T",
    "summary": "<p>在过去的十年里，随着移动互联网和云计算的高速发展，我们成功地克服了基础设施方面的各种挑战。在这十年的历程中，我们深刻认识到传统的消息和流存储架构无法充分发挥出云计算带来的技术红利和成本优势，也无法应对迅速增长的技术挑战。因此，我们需要重新设计这一关键领域，以释放云基础设施的潜能。</p><p>&nbsp;</p><p>Kafka 和 RocketMQ 在众多企业中得到了广泛的应用，但也面临着巨大的技术挑战。这些挑战包括如何确保超大规模集群的可用性，如何避免运维操作中的故障，以及云服务提供商如何为数万家企业提供云上消息服务。早期，我们依靠手动参数调整来解决这些问题，后来逐渐积累了各种工具来实现自动化运维，但是距离大家畅想的终态仍有距离。</p><p>&nbsp;</p><p>另一方面，技术不断在发展。2014 年，AWS 推出了 Lambda 服务，让开发者可以彻底摆脱服务器的运维，2018 年，Google 推出了 Cloud run，极大拓展了 Serverless 的场景，可以让任何基于 HTTP 的服务都能被 Google Cloud 托管。Apache RocketMQ 的作者王小瑞，以及 Apache RocketMQ 联合创始⼈周新宇，曾在阿里巴巴负责了十年以上的消息中间件研发工作，他们于 2018 年开始推进阿里巴巴内部核心业务的云原生 Serverless 化，目标是如何让成千上万个应用不用关心线上机器容量，做到扩缩容全自动，甚至一分钟就能创建一个生产级可用的面向互联网的分布式应用。这也为他们带来了启发：RocketMQ 和 Kafka 是否也有机会做到这样，像一个 Lambda 函数一样，不需要关心服务器运维。于是章文嵩博士和他们共同成立了一家新的公司，安托盟丘（杭州）科技有限公司（以下简称 AutoMQ），专门致力于打造云原生的消息队列。</p><p>&nbsp;</p><p>AutoMQ 公司为 Kafka 和 RocketMQ 设计了全新架构，完全构建在云厂商的对象存储之上，带来了 10 倍的云账单节约，更是将最复杂的数据存储卸载到了云服务。据 AutoMQ 联合创始人章文嵩博士介绍，Snowflake 是第一个将数仓完全构建在对象存储之上，带来了巨大的成本优势和每个用户独占计算资源的多租户隔离效果。而 MQ 这个领域是一个典型的分布式存储系统，越来越多的企业将 MQ 用在了核心业务的关键链路上，但是目前市面上还没有一款 MQ 产品像 Snowflake 一样彻底构建在云上，相信完全基于云设计的 MQ 会带来巨大的技术优势。</p><p>&nbsp;</p><p>最近，由 AutoMQ 和 InfoQ 共同主办的《<a href=\"https://mp.weixin.qq.com/s/bU04iDeb10hVxofQsgWQDg\">Apache Kafka × RocketMQ 云原生创新论坛</a>\"》将于 11 月 4 日在杭州举行。为此，InfoQ 采访了 AutoMQ 的核心团队，以了解他们在 Apache Kafka 和 Apache RocketMQ 领域的最新见解以及最前沿的架构设计理念。</p><p>&nbsp;</p><p>InfoQ：在大数据以及 AI 时代需要什么样的流处理软件？</p><p>&nbsp;</p><p>AutoMQ 团队：大数据时代，企业数据的爆发式增长，对传统的流存储和流计算软件带来了巨大的挑战，这背后需要海量的算力和存力进行支撑，传统的 IDC 架构无法应对这一挑战。幸运的是，云计算天然具备这些属性，但用云并不是简单地将传统的软件架构 Rehost 到云上，其本质是将 IDC 架构平移上云，无法发挥出云基础设施的规模化优势，只有重塑软件的架构，面向云原生进行设计，才有机会将云的优势转换为生产力的优势。</p><p>&nbsp;</p><p>对于 AI ，其对算力和存力的需求更是达到了巅峰，传统的软件架构绝对无法满足 AI 的需求，我们认为 AI 的基础就是云原生，只有将云原生红利释放给 AI，才能催生出百花齐放的 AI 技术应用，才能将 AI 变得更加普惠。</p><p>&nbsp;</p><p>综上所述，面向云原生重新设计流存储和流计算软件，释放基础设施的巨大潜力，向云计算要技术红利和成本红利，让云原生和 AI 相关的应用技术变得更加普惠，是大势所趋的。</p><p>&nbsp;</p><p>InfoQ：AutoMQ 为什么选择了 Kafka、RocketMQ 和 RabbitMQ？还会兼容哪些消息系统？</p><p>&nbsp;</p><p>AutoMQ 团队：Kafka 代表了流式存储的事实标准，并被众多开源项目如 Flink、Spark、StarRocks 等广泛集成，拥有最广泛的开发者群体，RocketMQ 和 RabbitMQ 则在微服务和应用消息领域被广泛使用。他们都代表了 Messaging 和 Streaming 的开源生态。</p><p>RocketMQ 经过阿里巴巴多年双十一的万亿级消息峰值验证，已经是互联网微服务架构的必选项，在国内有数十万企业部署在生产系统。</p><p>我们希望基于云重新设计这一关键领域，为这三个开源产品提供更好的云原生支持，以便更多的开发者能够受益。</p><p></p><p>InfoQ：关于选型，对比利用开源自建，用户什么时候该选择托管方案？</p><p>&nbsp;</p><p>AutoMQ 团队：对企业来说，成本和效率是首要考虑的因素。此外，如果涉及到闭源软件，可能会引发厂商锁定的问题。在当今，架构师通常更倾向于选择开源项目作为基础软件的首选。</p><p>&nbsp;</p><p>总拥有成本 TCO 是用户选择的关键，这个产品自建需要的机器成本和人员维护成本以及对软件深入度不够带来的宕机风险综合成本决定了客户的选择，如果托管方案明显优于开源自建，那么用户选择托管方案是最合适的。</p><p>&nbsp;</p><p>如果用户的业务非常关键，那么也不建议自行搭建，因为完全掌握一个开源软件达到满足业务匹配的可用性要求，付出的人员成本和时间成本都是非常高的。</p><p>&nbsp;</p><p>开源软件永远无法达到终态，绝大部分开源软件开源的是核心代码，核心代码距离生产环境高可用的服务还有巨大的差距，这里需要大量的周边工具配套以及专业工程师的持续维护。而托管方案可以非常高效的完成这个工作。</p><p>&nbsp;</p><p>InfoQ：以 Kafka 为核心，Confluent 开启 Project Metamorphosis 计划重新设计了适用于云的 Apache Kafka，同时，在 Kafka 最新（3.6）版本中，Confluent 开始提供<a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%253A+Kafka+Tiered+Storage\">Tiered Storage</a>\"功能，可将 Apache Kafka 作为完全托管的服务，部署在用户选择的云中。那么 Apache Kafka 中的托管服务和 AutoMQ 托管解决方案之间的差异是什么？</p><p>&nbsp;</p><p>AutoMQ 团队：最大的差异是：彻底的云原生化。</p><p>&nbsp;</p><p>我们理想中的云原生 Kafka 应该能做到计算、存储、网络按量付费，并且理论成本最优，系统可以随着业务负载自动调整机器数，整个过程对上下游完全透明。</p><p>&nbsp;</p><p>要做到计算实例的按量付费，就必须从传统的使用 Reserved 实例变为 Spot 实例，这样才会真正达到按量付费的效果。</p><p>&nbsp;</p><p>AutoMQ 将对象存储作为了主存储来使用，而非 Tiered Storage，这样整个存储的复杂度就彻底卸载到了云厂商，几乎让 Kafka 集群，RocketMQ 集群做到了无状态，即使使用 Spot 实例来部署 Broker，也能在 Spot 实例被回收之前所有状态数据同步到对象存储，这样整个计算实例销毁无需数据再平衡，其他节点自动从对象存储接管宕机节点的分区，做到分区秒级被接管，扩缩容同理，分区数不因为增加节点而变化，数据不因为扩缩容产生热点，系统全自动在数秒钟达到最优状态。</p><p>&nbsp;</p><p>AWS 的 S3 背后有数百名工程师经过数年的不断优化，目前已经是世界上最便宜的存储之一，并且能保证超高可用性，同时跨 AZ 网络流量是免费的。其他云厂商的对象存储也同样投入巨大，我们相信彻底基于云厂商先进的 IaaS 架构重新设计的 Kafka 和 RocketMQ 能带来无与伦比的技术优势。</p><p></p><p>InfoQ：在成本管理方面，AutoMQ 提供了哪些降本增效方案？能达到什么样的效果？</p><p>&nbsp;</p><p>AutoMQ 团队：我们了解到，基于当前的开源 Kafka 等技术架构，大部分企业进行降本增效的有效手段是进行取舍，比如牺牲数据存储时长来降低存储成本，或降低存储的副本数来优化整个 IaaS 层的成本。这些手段要么牺牲了业务的灵活性，要么牺牲了可用性或者可靠性，对业务的挑战是巨大的。</p><p>&nbsp;</p><p>现在，AutoMQ 通过寻找云上的最佳实践，来重新设计 Kafka 的架构，期望的目标是将成本做到「云上理论最优」，要完成这个目标我们主要的方案分为两个步骤。</p><p>&nbsp;</p><p>第一步是「面向云的计费项」去重新设计整个分布式的架构，开源的 Apache Kafka 在生产环境的成本结构大致为「网络：存储：计算 = 5:3:2」，对于这三类计费资源 AutoMQ for Kafka 的降本方案为：</p><p>网络：主要是在 Kafka 多副本且跨可用区场景带来的流量费，AutoMQ 将数据可靠性问题转移给自带 3 副本的 EBS 和可靠性达 11 个 9 的 S3，同时通过共享存储来解决可用性问题，避免引入多副本机制，通过云带来的技术红利解决可靠性和可用性问题。这一方案可以在消除复制带来流量费的同时，会同步节省存储和计算费用。存储：将存储的每一个计费项参与到架构设计当中，以 S3 为主存，同时优化 S3 的 API 调用将存储成本降低一个数量级；以 EBS 为 WAL，优化 EBS 的空间到 10G 内，完全的顺序写将 IOPS 优化至数百。计算：将存算分离架构发挥到极致，将存储的复杂度卸载到云，将计算优化至「无状态」，从而能够最大程度地将 Spot 实例的成本优势发挥出来。</p><p>&nbsp;</p><p>在面向计费项重新设计整个架构后，下一步是要兑现云最核心的优势「按量付费」，这要求整个架构是完全弹性的，通过极低成本完成 Scale Out 和 Scale In，对于 EC2 和 EBS 要最小化保有时间。这对于开源的 Kafka 来说是极为困难的，因为扩容意味着需要流量快速重平衡，缩容意味着要求数据能快速完成迁移，这些都是开源 Kafka 很难完成的任务。AutoMQ 弹性的分布式架构能够将「按量付费」的技术红利充分释放给 Kafka 的用户，具体的架构详情将在 11 月 4 日的会议上进行分享。</p><p>&nbsp;</p><p>InfoQ：在此之前的流平台，对于不同等级的数据量，比如 PB、TB 以及一些小企业的情况，其成本主要来自哪些地方？</p><p>&nbsp;</p><p>AutoMQ 团队：基本上，一个分布式的系统其对资源的消耗和数据规模是呈线性关系的，所以物理资源上的成本基本上是集中在计算、存储和网络上。</p><p>&nbsp;</p><p>但除了资源成本，另一项无法忽视的成本是运维成本，它跟规模的关系将变得更加复杂，大规模的数据场景下，将会带来更多的运维挑战，比如识别性能瓶颈、快速解决容量问题、大规模的集群和数据治理、稳定性治理等。以我们了解到的情况来看，PB 级别的数据量，一般需要一个 5 到 10 人的专业研发和运维团队来提供技术支持。在 TB 级别的系统上，人员成本占比会更高。</p><p>&nbsp;</p><p>InfoQ：流处理的 Serverless 模式能带来哪些好处？</p><p>&nbsp;</p><p>AutoMQ 团队：Serverless 模式最直观的好处就是成本优势，Serverless 架构能够将计费资源转换成按量付费的模式，最小化计费粒度，比如将流存储依赖的计费资源全部变成 Serverless 模式后，成本至少下降一个数量级。</p><p>&nbsp;</p><p>另一方面，Serverless 模式将会加速技术的成熟，特别是流计算相对于批计算来讲，批计算因为是周期性地进行批处理，实际上是一种按量使用的模式，比如每天申请一批资源完成特定的计算任务，所以批计算相比流计算天然就具备成本优势。流计算是一种实时计算，需要时刻保有计算和存储资源，如果流计算依赖的技术栈完全是 Serverless 的，带来的成本优势将加速流计算的普及和成熟。</p><p>&nbsp;</p><p>InfoQ：有观点说，基于容器的 Serverless 实现方式需要通过用户负载来进行动态资源调度，要高效利用资源并不容易。目前，AutoMQ 的无服务实现方式是什么，怎么达到高效利用资源的？</p><p>&nbsp;</p><p>AutoMQ 团队：Serverless 从来就不是一件容易的事情，AutoMQ 团队除了有丰富的云计算商业化经验以外，也负责了阿里巴巴的在线业务 Serverless 化，这其中有几个主要的挑战为：</p><p>用户负载的不可预测性：理想情况下，将集群水位控制在 100% 是最经济的方案，但在实践过程中，往往需要预留充足的水位来应对不可预测的流量。AutoMQ 解决这个挑战的方案为充分利用基础云产品提供的 Burstable 的能力，比如 EC2、EBS 和网络，都会提供 10x 左右的 Burst 能力，虽然持续时间短，但会为弹性扩容提供宝贵的时间。甚至，对于 EBS，完全可以通过一个 API 修改 IOPS 和吞吐上限即可完成扩容。资源的碎片化：衡量一个调度和弹性平台的一个重要指标就是「资源的碎片化」，一个显而易见的事实是，一个集群成员的规格越大，整体产生的碎片化越严重，规格越小，越容易消除碎片。AutoMQ 面向小规格进行设计，比如 2C 的机器单元，将 CPU、内存、存储带宽、网络带宽都充分利用起来，非常有助于在各类弹性平台中大幅度减轻资源碎片化问题。快速的冷启动：我们在解决阿里巴巴在线业务的 Serverless 问题当中，发现一个复杂的应用，启动时间可能是 10 分钟级，在如此慢的冷启动的前提下，Serverless 难度将进一步被加大，不能快速 Scale Out，也就不敢随意地 Scale In。彼时，我们的解决方式是「快照-恢复」方法，通过对进程进行内存快照，在 Scale Out 时快速 Restore 出来，大家可以发现，近两年业界很多函数计算平台比如 Lambda，华为云的 FunctionGraph 都陆陆续续采取了类似的方案。但对于 RocketMQ 和 Kafka 这类存储软件来讲，最耗时的过程还是扩容后，流量能否快速迁移过来达到负载均衡的状态，对于 Kafka，迁移分区是小时级别的。为了解决这个问题，AutoMQ 的方案是从 Shared Nothing 架构走向 Shared Storage 架构，当存储变得共享后，移动一个分区是秒级的，也意味着扩容时可以快速达到流量重平衡，缩容前可以快速将分区迁移走，极大地降低了 Serverless 实现的难度。</p><p>&nbsp;</p><p>综上，AutoMQ 通过充分利用云的 Burst 能力，云产品的 API 能力，小规格的部署能力，共享的存储能力来达到高效、经济地利用云资源的效果。</p><p>&nbsp;</p><p>InfoQ：对于未来五年，你们有什么样的产品规划？</p><p>&nbsp;</p><p>AutoMQ 团队：云的普及和发展不仅为技术架构的变革提供了契机，同样也为产品创新提供了新的土壤和空间。众多产品思考和创新逐渐从不可能变成可能。</p><p>&nbsp;</p><p>AutoMQ 作为新一代云原生消息队列技术服务商，我们持续专注于挖掘云基础设施的技术红利，为客户提供低成本、高性能、高可靠的消息队列和流存储解决方案。</p><p>&nbsp;</p><p>在未来，我们将关注以下几个方面：</p><p>成本经济性：正如上面降本增效的话题所述，AutoMQ 会持续挖掘云基础设施的技术红利，结合云资源计费项粒度的技术架构调优，在架构弹性、资源调度、请求优化等方面继续突破，为企业客户提供极具成本竞争力的产品方案，帮助企业科学降本。数据集成和价值挖掘：AutoMQ 提供的新一代 RocketMQ、Kafka 消息流存储服务，使用对象存储作为主存储，所有业务数据原生存储在对象存储中，可以完美地和当下主流的数据湖、数据仓库等方案进行集成整合。这一天然优势可以消除 ETL 的架构复杂度和运维成本问题。多云一致输出：多云和混合云架构在企业中越来越受欢迎。AutoMQ Cloud 从第一天设计开始就坚持 Cloud Anywhere 的理念，将云厂商底层基础设施的差异性屏蔽，为企业用户提供多云一致的消息队列和流存储服务，方便企业在多云、混合云场景下构建一致的容灾和数据集成架构。专家经验产品化输出：AutoMQ 研发团队积累了十多年的消息队列生产运维经验，我们一直在探索如何将消息队列的生产运维经验以产品化工具和服务的形态普惠开发者。近期发布的 AutoMQ Copilot 产品就是这样的一款工具产品，未来我们会面向更多的开源消息队列产品提供类似的工具和服务。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>活动推荐：</h4><p></p><p>在云原生技术的浪潮中，我们如何更好地理解和应用 Apache Kafka 和 Apache RocketMQ 的实际案例和最佳实践？11 月 4 日，我们邀请你来参加“Apache Kafka x RocketMQ 云原生创新论坛 ”，本次云原生创新论坛将重点探讨它们在不同行业和领域的应用案例，以及如何充分利用这些技术来解决复杂的业务挑战，同时也会有基于云彻底重新设计的 Kafka 和 RocketMQ 技术方案分享。可扫描图片中的二维码或点击以下链接报名参加：<a href=\"https://www.huodongxing.com/event/9725831485900\">https://www.huodongxing.com/event/9725831485900</a>\"</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/79/79746c4c6b6849357e0ff7a177c23f88.png\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><p></p>",
    "publish_time": "2023-10-30 14:25:03",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "上海华瑞银行风控数据团队负责人丁清华确认出席 FCon，分享上海华瑞银行风险特征计算平台演进路线",
    "url": "https://www.infoq.cn/article/HbONbMjN8BkXCGEdzGA8",
    "summary": "<p><a href=\"https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle\">FCon 全球金融科技大会</a>\"，将于 11 月在上海召开。上海华瑞银行风控数据团队负责人丁清华将发表题为《<a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5585?utm_source=infoqweb&amp;utm_medium=article\">上海华瑞银行风险特征计算平台演进路线</a>\"》主题分享，介绍华瑞银行在推进智慧银行建设过程中，风险特征计算平台在应用过程中遇到的业务痛点，并借助大数据计算技术不断演进深化的过程，以及近几年里经历的主要阶段。</p><p></p><p><a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5585?utm_source=infoqweb&amp;utm_medium=article\">丁清华</a>\"，2007 年起参与银行数据计算平台的建设，从零到一参加了银行大数据平台的建设，经历了传统数据仓库、分布式大数据平台、实时计算平台、图计算平台的建设和丰富的金融应用场景。作为数据专家，曾多次代表公司参与市级项目的方案设计，参与市科委的专家评审工作。近几年来，持续关注大数据计算技术同金融风控应用的结合，积极推进批流一体化数据平台建设，积极完善风控特征实时计算功能，包括同行内外部数据、决策引擎、风控模型的交互及应用，快捷配置风险特征，快速发布部署，丰富监控管理等功能，为上海华瑞银行智慧银行建设提供算力支持。他在本次会议的演讲内容如下：</p><p></p><p>演讲：上海华瑞银行风险特征计算平台演进路线</p><p></p><p>本次演讲，将主要介绍华瑞银行在推进智慧银行建设过程中，风险特征计算平台在应用过程中遇到的业务痛点，并借助大数据计算技术不断演进深化的过程，在近几年里经历的主要阶段，并推进了如下工作：</p><p></p><p>无独立的风险特征计算平台。我行成立初期，风控信息系统尚不完善，风险特征的计算功能耦合在贷款业务系统中。造成了以下问题：一是架构不清晰，风险特征计算功能较弱，依赖于业务系统的功能；二是缺乏统一的特征管理平台，造成重复开发，资源浪费；三是变更频繁，日常特征变更及策略迭代都需要进行生产变更，增加系统运行风险。</p><p></p><p>随着大数据计算技术的成熟，我行同阿里云平台合作，使用离线和实时计算技术，建设风险特征计算平台。利用 Blink、DataHub 实现实时风险特征计算，利用 maxcompute 建设风险数据集市，离线计算风险特征，建设统一的应用平台实现风险特征的统一定义、计算、管理和服务调用等。</p><p></p><p>继续完善风险特征计算平台功能，将产品打造成全行的特征计算平台，并将功能同风险策略、模型等日常场景紧密结合。为策略经理提供更便捷的特征定义、配置、计算、测试、回溯和上线；为模型经理提供特征分布监控、稳定性分析、特征重要性分析等功能；为产品经理提供系统运行监控、元数据管理和分析、使用分析等功能。</p><p></p><p>演讲提纲：</p><p></p><p>大数据平台的典型架构及发展历史大数据技术在上海华瑞银行风控应用中的实践上海华瑞银行实时特征计算平台的演进路线未来风险特征计算平台的功能展望</p><p></p><p>你将获得：</p><p></p><p>○ 了解到大数据平台的典型架构及在金融业的发展历史</p><p>○ 了解到大数据技术结合上海华瑞银行风控应用的真实场景</p><p>○ 了解到上海华瑞银行实时特征计算平台的演进路线</p><p>○ 了解到未来风险特征计算平台的展望，具备的典型功能</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle\">DevOps&nbsp;在金融企业落地实践</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle\">金融行业大模型应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle\">创新的金融科技应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle\">金融实时数据平台建设之路</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle\">金融安全风险管控</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle\">数据要素流通与数据合规</a>\"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，享 8 折优惠 ，立省 ￥1360！咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png\" /></p><p></p>",
    "publish_time": "2023-10-30 14:30:05",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "探索三农数据信托模式 中农融信、万向信托、蚂蚁数科达成三方合作",
    "url": "https://www.infoq.cn/article/qtv7qNDFwUDzm9wZhpGW",
    "summary": "<p>2023年10月26日，中农融信、万向信托及蚂蚁数科正式签订有关三农数据的信托合作备忘录。</p><p></p><p>根据备忘录，三方将发挥各自的农业资产服务、信托创新产品、数据技术优势，共同致力于通过信托模式和架构将三农数据进行资产化，积极探索三农有关数据的价值挖掘，推动包括扩大农村地区金融服务可得性以及在其他数据消费场景的应用和价值转化。据悉，这也是我国首个基于三农数据的信托模式探索。</p><p></p><p>万向信托作为持牌金融机构，通过数据信托这一新型服务信托模式，为有关数据合规安全保障提高到金融级的标准提供了可能性。在信托架构内，万向信托将以受托人的身份，确保信托财产独立运作，充分履行披露义务，保持项目运作的透明性，发挥信托隔离功能。同时，结合蚂蚁数科一站式技术解决方案有效保障三农数据的合规安全流转。</p><p></p><p>三农数据信托是对三农数据价值流转具有深远意义的积极探索，也是对助力农业数字化升级的有益尝试。</p><p></p><p>三农数据信托拓宽了服务信托业务的边界和内涵，使信托行业能够更好地适应和服务数字化时代的发展需求。</p><p></p><p>在过去十个多月的时间里，国务院及银保监会（现国家金融监督管理总局）陆续颁布出台了数据二十条、乡村振兴责任制实施办法及最新信托分类管理办法，在数据要素、乡村振兴、信托服务等领域提出了新的指导思想和系列政策要求。此次合作的达成正是在上述政策机遇下，经过半年来多轮沟通和方案选型探讨取得的阶段性进展。</p><p></p><p>中农融信(北京)科技股份有限公司是一家国内领先的乡村数字资产服务运营商，深耕农业20余年，致力于为政府、金融机构及农业产业主体提件全方位数字化解决方案。万向信托股份公司是一家经国家金融监督管理总局批准设立的金融机构，近年来在新型信托产品及服务方面不断创新突破，积累了不少成功案例。蚂蚁数科是蚂蚁集团的科技商业化板块，依托自身的科技创新和行业实践，聚焦区块链、隐私计算、物联网、安全科技、云原生等前沿科技，致力于为产业数字化进程提供扎实的数字技术解决方案。</p>",
    "publish_time": "2023-10-30 14:32:26",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "疯狂马斯克的“极限”计划居然成功了？！“下云”后成本降低60%，部分功能代码精简90%，30天急速迁移服务器",
    "url": "https://www.infoq.cn/article/YWara7wpitFei3wUe2L6",
    "summary": "<p>2022 年 10 月 27 日，经历了长达半年的拉锯战之后，马斯克终于将 Twitter（现已更名 X）收归囊中，这笔 440 亿美元的收购案也终于迎来了大结局。入主 Twitter 后，马斯克进行了大刀阔斧的改革，如今一年过去了，Twitter 发生了哪些变化？</p><p>&nbsp;</p><p>2023 年 10 月 27 日，X 工程技术发布帖子称，过去一年是 X（Twitter）平台全面推进工程技术探索的一年。除了大家在 X 应用端看到的直观调整之外，团队还在幕后完成了以下一系列重要改进。其中包括：</p><p>&nbsp;</p><p>关闭萨克拉门托数据中心，并重新配置了 5200 台机架和 14.8 万台服务器，每年节约超 1 亿美元。共释放出 48 兆瓦的功率配额、拆除重达 6 万磅的网络梯架，必要设备后续将被重新配置至其他数据中心。优化了 X 的云服务使用方式，着手将更多工作负载迁往本地基础设施。这一转变使 X 每月的云成本降低了 60%。所有媒体/blob 工作均已下云，这让 X 的整体云数据存储量缩减了 60%，还成功将云数据处理成本降低了 75%。</p><p>&nbsp;</p><p>此外，X 还发生了以下变化：</p><p>&nbsp;</p><p>围绕单一产品框架整合了 For you（为您推荐）、Following（关注）、Search（搜索）、Profiles（个人资料）、Lists（列表）、Communities（社区）和 Explore（探索）等技术栈。从头开始全面重建了 For you 服务与排名系统，代码行数从 700K 缩减至 70K，精简比例高达 90%，计算占用量降低 50%，根据请求得分计算的帖子吞吐量增长了 80%。统一了 For you 和视频个性化及排名模型，显著提高了视频推荐的质量。重构了技术栈内的 API 中间件层，通过删除超 10 万行代码和数千个未实际使用的内部端点、清理未采用的客户端服务等方式完成了架构简化。精简后的元数据获取延迟降低了 50%，全局 API 超时错误减少了 90%。阻断 bot 和内容抓取的速度较 2022 年提高了 37%。平均而言，X 每天阻断超 100 万次 bot 注册攻击，并将直接垃圾邮件减少了 95%。构建本地 GPU 超级计算集群，并设计、开发和交付了 43.2 Tbps 的新网络体系架构以支持这些集群。扩展网络主干容量与冗余，每年节约1390万美元。开始进行自动峰值流量故障转移测试，用以持续验证整个平台的可扩展性与可用性。</p><p>&nbsp;</p><p>自接手 X 以来，马斯克为了缩减成本挖空心思，其中包括裁员、推行“极端硬核”企业文化、拖欠办公室租金……在公司的运营开支方面，马斯克去年刚接手&nbsp;X 时便指示团队通过削减云服务和额外的服务器空间，力争每天在基础设施上节省 300 万美元。</p><p></p><h2>省钱大法一：云服务太贵了，马斯克要“下云”</h2><p></p><p>&nbsp;</p><p>2020 年 12 月，Twitter 宣布将使用亚马逊云科技为其主时间线提供支持。当时的消息称这将是一份“多年期”协议，但没有透露任何具体数字。彼时 Twittr 公司 CTO Parwal Agrawal 在一份声明中表示，Twitter 和亚马逊云科技将合作扩展该社交媒体的基础设施、加快功能发布速度，并扩大其功能组合。</p><p>&nbsp;</p><p>据 The Information 2023 年 3 月报道，这笔交易为期五年半，合同总值 5.1 亿美元。根据报道，无论是否使用相应容量，Twitter 都同意向亚马逊云科技付费。而且亚马逊云科技不愿就具体条款进行重新谈判。根据交易细则，Twitter 的月度亚马逊云科技支出大约在 773 万美元。</p><p>&nbsp;</p><p>如今，Twitter 已经不再使用亚马逊云科技的实时时间线功能，转而选择了 AWS for Spaces 等其他服务。Twitter 后续可能使用 Google Cloud Platform（GCP）运行其时间线业务。根据 Twitter 与亚马逊云科技之间签订的合同细节，马斯克执掌的社交媒体巨头还计划使用：</p><p>&nbsp;</p><p>亚马逊云科技云基础设施，用于补充 Twitter 的本地功能，帮助该公司在全球范围内扩展其实时服务。采用 Amazon Elastic Compute Cloud (Amazon EC2)服务中基于 Arm 架构的亚马逊云科技 Graviton 2 实例，以运行其云工作负载。借助亚马逊云科技容器服务，Twitter 将在其混合基础设施当中统一构建并交付新的功能和服务。Amazon CloudFront，即亚马逊云科技的超高速内容交付网络（CDN）服务，能够以低延迟、高速率向全球客户分发数据、应用程序、视频和API。Amazon DynamoDB，即亚马逊云科技的键值数据库，可大规模提供个位数毫秒级性能。</p><p>&nbsp;</p><p>目前，Twitter 已经与谷歌签订了一份价值 10 亿美元的合同，且相关承诺早在与亚马逊云科技合作之前就已敲定。另据报道，Twitter 将在 2023 年向谷歌支付总计 3 亿美元，这也是总价值约 10 亿美元的多年期合作协议的一部分。</p><p>&nbsp;</p><p>随着马斯克入主 Twitter 并开启削减成本计划，Twitter 的基础设施支出大幅减少。根据题为“深度削减成本”的 Slack 内部消息，Twitter 计划从云服务和服务器容量方面入手，省下 150 万到 300 万美元。此外，Twitter 还试图与亚马逊云科技、Google Cloud 以及甲骨文就合同内容展开重新谈判，但供应商们纷纷表示拒绝。</p><p>&nbsp;</p><p>根据最新公告，马斯克通过将工作从云端转移到 Twitter 自己的服务器上，每月的云成本降低了 60%，整体云数据存储量缩减了 60%，还成功将云数据处理成本降低了 75%。</p><p></p><h3>下云就能解决问题？</h3><p></p><p>&nbsp;</p><p>近年来，为了节省成本，不少公司开始下云。不过，并非所有公司都适合下云，需要结合自身实际业务情况来做判断。比如，GitLab 在 2016 年底时候就表示计划要“下云”，不过团队“在收到数百条充满建议和警告的评论和邮件后，最后还是决定将 GitLab.com 保留在云端。</p><p>&nbsp;</p><p>此外，37signals 旗下一款流行的基于云服务的项目管理软件 Basecamp 也曾想“下云”。Basecamp 的上云历程已经超过十年，而且其前两年发布的产品 HEY 也一直在云端运行。但 Basecamp &amp; HEY 联合创始人 David Heinemeier Hansson 发文表示将要“下云”。</p><p>&nbsp;</p><p>“我们用过亚马逊云科技、也用过谷歌云，试过裸虚拟机、也体验了 Kubernetes 容器编排。我们知道云能提供哪些功能，其中大部分都有实际应用。现在我们终于得出结论：对于像我们这样一家增长稳定的中型企业来说，租赁基础设施资源总体上看是笔糟糕的买卖。云服务商做出的降低复杂性、控制运营成本等承诺从来就没能实现，所以我们正在筹划脱离云端、重归本地。”</p><p>&nbsp;</p><p>不过，在 David Heinemeier Hansson 撰写的关于离开云计算的思考中，他特别提到了两个情况是不能离开云计算的。一种是流量极低，一种是复杂不均衡：</p><p>&nbsp;</p><p>第一个极端是当您的应用程序非常简单且流量很低，通过使用完全托管的服务来降低复杂性确实能够节省成本。这是 Heroku 铺就的道路，也是 Render 等其他服务商所追随的道路。当您没有客户时，这是一个绝佳的起点，即使在您开始拥有一些客户后，它仍能推动您的业务发展。（然后，一旦使用量激增，账单飙升到天际线上时，您可能会面临一个好问题，但这是一个合理的权衡。）第二个极端是当您的负载非常不规则时。当您的使用量出现剧烈波动或巨大峰值时。当基线只是您最大需求的一小部分时。或者当您不知道您需要十台服务器还是一百台时。在这种情况下，没有什么比云端更好了，就像我们在推出 HEY 时学到的那样，突然有 30 万用户在三周内注册尝试我们的服务，而我们的预测是六个月内有 3 万用户。</p><p></p><h2>省钱大法二：数据中心大迁移</h2><p></p><p>&nbsp;</p><p>为了节省成本，去年 12 月，马斯克还关闭 Twitter 加州数据中心。</p><p>&nbsp;</p><p>据悉，在平安夜前夕，纳斯克飞往加利福尼亚州的萨克拉门托——Twitter 三大主要计算存储设施之一的所在地——切断了维持该社交网络平稳运行的服务器。有知情人士表示，虽然有员工担心关闭这些服务器可能导致各种问题，但节省资金是首要任务。</p><p>&nbsp;</p><p>随后，世界各地的用户报告 Twitter 服务中断。一些用户反馈 Twitter 出现很多奇怪的错误消息，比如看到空白页面、无法回复推文或关注热门话题，还有人被迫退出登陆。有熟悉 Twitter 基础设施的人士表示，如果萨克拉门托的设施仍在运行，它就可以在其他数据中心出现故障时提供备份计算能力，从而帮助缓解问题。</p><p>&nbsp;</p><p>此外有消息称，当时马斯克为了省钱，计划将萨克拉门托的服务器搬到波特兰，基础设施团队称这项工作至少要九个月才能完成，马斯克一怒之下直接搭乘私人飞机跑去机房，拔了网路线与电源就搬上大卡车开始转移，最后整个工作一个月就完成了。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/da/da556797defc3582b04c0ec1084ba1af.png\" /></p><p></p><p>在今年 9 月出版的《埃隆·马斯克传》中，详细讲述了马斯克亲自迁移服务器的故事（节选，经编辑）：</p><p>&nbsp;</p><p></p><blockquote>2022 年 12 月 22 日深夜，位于 X 公司 10 楼的会议室，马斯克正在与两名基础设施经理进行紧张的交谈。&nbsp;位于萨克拉门托的一家数据服务公司允许 X 公司延长其服务器租约，以便在 2023 年有序迁出。一名显得有些紧张的基础设施经理告诉马斯克：“今天早上，他们回来告诉我们说这个计划不再适用，因为他们认为我们在财务上不再稳健。”&nbsp;这个设施每年花费 X 公司超过 1 亿美元。马斯克想通过将服务器迁移到 X 公司在俄勒冈州波特兰的其他设施来节省这笔费用。另一位经理表示这项工作不能立即进行。她平静地说：“我们至少需要六到九个月的时间，因为萨克拉门托仍然需要服务流量。”&nbsp;马斯克沉默了几秒钟，然后宣布：“你们有 90 天时间来完成这项任务。如果你们做不到，你们可以辞职。”这名经理开始详细解释迁移服务器到波特兰的障碍。“机架密度不同，电力密度也不同，”她说。“所以机房需要进行升级。”她开始详细介绍更多原因，但被马斯克打断。“这让我的大脑感到压抑，”马斯克说道，“你知道头爆炸的表情符号吗我的脑袋现在就是这个感觉。真是一堆屁话。波特兰明显有大量的空间，从一个地方迁移到另一个地方简直小菜一碟。”&nbsp;“你们需要做的就是将服务器迁移到波特兰，”马斯克说道，“如果超过 30 天，我会很震惊。”他停顿了一下，重新计算。“找一家搬家公司，运输电脑需要一个星期，然后再花一个星期来连接它们。两周。就应该这样。”&nbsp;所有人都默不作声。但马斯克仍在发火。“如果你们租了一个 U-Haul （一家租车公司），你们可能自己就能完成。”两位 X 公司的经理看着他，试图判断他是否是认真的。马斯克的两位亲密助手 Steve Davis 和 Omead Afshar 也在场。他们多次看到过他这样，知道他可能真的这么认为。&nbsp;12 月 23 日星期五晚上，James 和他的弟弟 Andrew（马斯克的表弟）与马斯克一起从旧金山飞往奥斯汀，当飞机飞过拉斯维加斯时，James 提出了一个建议，他们现在就可以移动服务器。一个名为 Alex 的来自乌兹别克斯坦的 X 员工帮助他们进入了 X 公司的数据中心，内部共有大约 5200 个冰箱大小的机架，每个机架有 30 台电脑。每个机架重约 2500 磅，高 8 英尺。但马斯克认为“这些东西看起来并不难移动”，他向保安借了一把小刀，抬起地板上的一个通风口，这让他可以撬开地板面板。然后他爬到服务器下面，用小刀撬开了一个电箱，拔掉了服务器插头，等着看会发生什么。没什么异常发生。服务器已经准备好迁移。&nbsp;第二天——圣诞前夜，马斯克召集了增援。Ross Nordeen，与他的朋友 James 在 Tesla 工作，从旧金山驱车而来。他在联合广场的 Apple Store 花了 2000 美元，买下了所有的 AirTags，这样服务器在迁移过程中就可以被跟踪。然后他去了家得宝，花了 2500 美元买了扳手、断线钳、头灯和拧下地震螺栓所需的工具。&nbsp;Steve Davis，马斯克的忠诚副手，找人租了一辆半挂车，并安排了搬家车。其他来自 SpaceX 的援助队员也已到达。这些服务器机架都有轮子，所以团队能够断开其中四个并将它们推到待命的卡车上。这表明，这五千两百多个服务器可能在几天内全部移动。 “伙计们干得好！”马斯克兴高采烈地说。&nbsp;到这周结束时，他们已经使用了萨克拉门托所有可用的卡车。尽管该地区受到了雨的袭击，他们在三天内移动了 700 多个机架。该设施之前的记录是一个月移动 30 台。这仍然留下了大量的服务器在设施中，但这群人已经证明了它们可以被快速移动。其余的部分在 1 月份由 X 公司的基础设施团队处理。</blockquote><p></p><p>&nbsp;</p><p>马斯克的疯狂举动引发了不少争议。网友海狗油90认为，“几乎没有人明白数据中心搬迁要搬的是服务、数据，而不是服务器本身，也不明白 X 这样的公司，服务连续性、数据一致性值多少钱。”</p><p>&nbsp;</p><p>网友酷憋哥评论称：“除了证明马斯克胆子大，这个案例没有什么正面的意义，试想一下，哪个普通打工人可以做出这么鲁莽的决定？他或她是否能承担由这种行为导致的严重后果？所以最终只有老板能做这种事情，只要他愿意。”</p><p></p><p>参考链接：</p><p><a href=\"https://twitter.com/XEng/status/1717754398410240018\">https://twitter.com/XEng/status/1717754398410240018</a>\"</p><p><a href=\"https://www.cloudzero.com/blog/twitter-aws\">https://www.cloudzero.com/blog/twitter-aws</a>\"</p><p><a href=\"https://twitter.com/thecat/status/1705860673149059115\">https://twitter.com/thecat/status/1705860673149059115</a>\"</p><p><a href=\"https://weibo.com/1727858283/NkRTyymTQ\">https://weibo.com/1727858283/NkRTyymTQ</a>\"</p><p><a href=\"https://mp.weixin.qq.com/s/7xdSNegYf9zoH7tB8jMDuQ?poc_token=HDYwP2WjN8f7OaFw635HGuh91caCskEz36fJuoqH\">https://mp.weixin.qq.com/s/7xdSNegYf9zoH7tB8jMDuQ</a>\"</p>",
    "publish_time": "2023-10-30 15:04:24",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]