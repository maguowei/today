[
  {
    "title": "Snowflake CEO宣布退休，公司股价暴跌20%",
    "url": "https://www.infoq.cn/article/T0cZBQOKeuUA9Y2az0vz",
    "summary": "<p>当地时间2月28日，云数据平台独角兽Snowflake 宣布于 2019 年加入公司并于次年带领公司成功上市的亿万富翁首席执行官 Frank Slootman 即将退休，该职位将由前Google广告总监Sridhar Ramaswamy接任。</p><p>&nbsp;</p><p>一直以来，Snowflake这位资深的科技高管很受投资者欢迎，至少从投资者对他将辞去 Snowflake 首席执行官一职的反应来看是这样。受此消息影响，该公司股价在盘后交易中暴跌超过20%。</p><p>&nbsp;</p><p>今年65岁的Slootman曾领导软件供应商ServiceNow进入公开市场，在此之前，他曾在Data Domain担任高管。在他的职业生涯中，真正的高光时刻是在2020 年将Snowflake成功送到纽约证券交易所上市，此次上市也成为了有史以来规模最大的软件IPO，上市首日股价上涨了一倍多。虽然辞去了CEO一职，但Slootman仍将继续担任董事会主席。</p><p>&nbsp;</p><p>接替Slootman工作的是现年 57 岁的Ramaswamy，他曾在谷歌工作了 15 年，最近一次领导广告和商务业务，直到 2018 年。随后，Ramaswamy于 2019 年离职，与他人共同创立了 Neeva，这是一个消费者搜索引擎，他希望能凭借此引擎与谷歌展开竞争，直到去年他才宣布成立该公司。据一份文件显示，Snowflake&nbsp;于 6 月以 1.85 亿美元收购了Neeva。</p><p>&nbsp;</p><p>Slootman在一份声明中表示：“没有人比 Sridhar Ramaswamy更适合带领 Snowflake 进入下一阶段的增长，并抓住人工智能和机器学习领域的机遇。”&nbsp;“他是一位富有远见的技术专家，在经营和扩展成功企业方面经验丰富。”</p><p>&nbsp;</p><p>Snowflake还发布了第四季度财务业绩。期内销售额同比增长 32% 至 7.747 亿美元。第四季度产品收入为7.381亿美元，比上年增长33%。</p><p>&nbsp;</p><p>第四季度运营亏损为 2.755 亿美元，高于去年第四季度的 2.398 亿美元。</p><p>&nbsp;</p><p>据 StreetAccount 称，该公司表示第一季度产品收入将在 7.45 亿美元至 7.5 亿美元之间，低于分析师预期的 7.59 亿美元。此外，Snowflake 表示第一季度调整后营业利润率为 3%，高于分析师预期的 7.2%。</p><p>&nbsp;</p><p>Slootman 2023 年的总薪酬为 2370 万美元，几乎全部来自股票和期权奖励。根据一份监管文件，截至 2 月 9 日，Slootman 拥有 1060 万股 Snowflake 股票。截至周三收盘，该股份价值约为 24 亿美元。</p><p>&nbsp;</p><p>在 Slootman 加入 Snowflake 之前，该公司由前微软高管 Bob Muglia 领导，他将公司估值提升至 40 亿美元。Muglia 于 2019 年 4 月突然被罢免，并由 Slootman 取代。周三盘后暴跌之前，该公司的市值为 750 亿美元。</p>",
    "publish_time": "2024-02-29 09:55:50",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Grab 改进 Kubernetes 集群中的 Kafka 设置，无需人工干预就可轮换 Broker 节点",
    "url": "https://www.infoq.cn/article/iASqS42eYx2tljmcsO0s",
    "summary": "<p>Grab 更新了其 Kubernetes 上的 Kafka 设置以提高容错性，并完全避免在 Kafka Broker 意外终止时需要进行人工干预。为解决最初设计的不足，Grab 的团队集成了 AWS 节点终止处理程序（Node Termination Handler，NTH），使用负载均衡器控制器进行目标组映射，并切换到 ELB 卷进行存储。</p><p></p><p>作为其 Coban 实时数据平台的一部分，Grab 已经在 Kubernetes (EKS) 上使用 Strimzi 在生产环境中运行 Apache Kafka 两年了。团队之前使用了 Strimzi（现已成为 CNCF 孵化项目），通过应用成熟的身份验证、授权和保密机制来提升 Kafka 集群的安全性。</p><p></p><p>除了由于维护或基础设施问题导致 AWS 意外终止 EKS 节点外，初始设置运行良好。在这种情况下，Kafka 客户端会突然遇到错误，因为 Broker 没有被优雅地降级。更糟糕的是，受影响的 Broker 实例无法在新配置的 EKS 工作节点上重新启动，因为 Kubernetes 仍然指向已经不存在的存储卷。因此，如果没有 Coban 工程师的干预，Kafka 集群将以降级状态运行，三个 Broker 节点中只有两个可用。</p><p></p><p>开发人员利用 AWS 节点终止处理程序（NTH）将对 Kafka 客户端的干扰降至最低，通过排空工作节点，使用 SIGTERM 信号触发 Kafka 进程优雅地关闭。Grab 团队选择使用队列处理器模式而不是实例元数据服务（IMDS）模式，因为它捕获了更广泛的事件集合，包括与可用区（AZ）和自动扩展组（ASG）有关的事件。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/12/1282b63f2961e3d9391f949a54414ad4.png\" /></p><p></p><p>使用 AWS 节点终止处理程序（队列处理器）支持 Kafka 的优雅关闭（来源：Grab 工程博）</p><p></p><p>他们使用 AWS 负载均衡器控制器（LBC）动态映射网络负载均衡器（NLB）目标组来解决工作节点终止时网络连接中断的问题。工程师们通过增加健康检查频率并使用 Pod 就绪门（Pod Readiness Gate）控制器来配置 NLB，解决 NLB 将每个目标组标记为健康状态所需的时间过长的问题。</p><p></p><p>他们最后需要克服的一个最大的障碍是确保新配置的 Kafka 工作节点能够正确启动并访问数据存储卷。工程师们决定使用弹性块存储（EBS）卷而不是 NVMe 实例存储卷。使用 ESB 有许多好处，例如成本更低、将卷大小与实例规格解耦、更快的同步速度、快照备份以及在不停机的情况下增加容量。此外，他们将 EC2 实例类型从存储优化改为通用型或内存优化型。</p><p></p><p>通过对 Kubernetes 和 Strimzi 进行额外配置，能够在新集群上自动创建 EBS 卷，并在将 Kafka Pod 重定位到不同工作节点时在 EC2 实例之间附加 / 分离卷。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/67/673d9ad3ea9e417dbd8d9f2a5d8828e0.png\" /></p><p></p><p>经过这些改进，EC2 实例退役以及任何需要对所有工作节点进行轮换的操作都可以在没有人工干预的情况下进行，这些操作变得更快速、更不容易出错。他们正在计划做进一步的改进，包括使用 NTH Webhook 主动启动新实例并通过 Slack 通知 NTH 发起的操作，以及推出 Karpenter，用以取代 Kubernetes Cluster Autoscaler。</p><p></p><p>查看英文原文：</p><p></p><p><a href=\"https://www.infoq.com/news/2024/02/grab-kafka-kubernetes-aws-nth/\">https://www.infoq.com/news/2024/02/grab-kafka-kubernetes-aws-nth/</a>\"</p>",
    "publish_time": "2024-02-29 10:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从Sora代表的多模态聊起，大模型将如何重塑软件生态？｜QCon会展启航直播",
    "url": "https://www.infoq.cn/article/rjdS63Pvw3xTb0XtLBLl",
    "summary": "<p>2月26日，OpenAI&nbsp;Sora&nbsp;正式对外开放申请。这是一个文本到视频的生成模型（即文本生成视频），可以根据用户输入的描述性提示快速生成视频，并及时向前或向后扩展现有视频，因为前期公布的视频效果不错而受到大家的广泛关注。</p><p></p><p>与此同时，与&nbsp;Sora&nbsp;同架构的&nbsp;Stable&nbsp;Diffusion&nbsp;3.0也正式发布。从公布出来的测试图来看，归功于&nbsp;Transformer&nbsp;架构和额外的文本编码器，Stable&nbsp;Diffusion&nbsp;3.0的文字渲染能力十分强悍，图像的质量和整体性能同样有所提高。</p><p></p><p>这也让多模态再次成为大家关注的焦点，近一个月内有多场与之相关的直播，无数业内技术专家围绕此发表了自己的观点。那么，国内企业在这方面又有哪些具体进展呢？</p><p></p><p>与Sora前后脚出现的Gemma&nbsp;在过去一个月也是受到了大家的强烈关注，谷歌的Gemma&nbsp;是一个开放模型，与&nbsp;Gemini&nbsp;模型（以及更早的&nbsp;PaLM&nbsp;模型）拥有相同的技术和基础设施组件。谷歌方面称，与其他开放模型相比，Gemma&nbsp;2B&nbsp;与&nbsp;7B&nbsp;均在同等规模范围内拥有最出色的性能表现。</p><p></p><p>那么，开放模型这个概念如何理解？区别于开源和闭源，开放模型是不是将具备更好的商业前景呢？</p><p></p><p>诸如此，生成式AI技术的到来对整个软件生态带来了很多变化，我们也在期待未来有更多好的场景案例和技术突破出现。比如，Agent是否会在24年出现“现象级”的应用？可能是在C端还是B端？或者开发者日益喜欢的智能编码工具还可能朝着哪些方向演进？数字人是否会有实际的商业落地场景？角色构建又有哪些新的进展？微调工程师还是否是一个好的选择？</p><p></p><p>3月1日晚19:00，InfoQ特别策划的<a href=\"https://qcon.infoq.cn/2024/beijing/?utm_source=infoqweb&amp;utm_medium=dahuibanner\">【QCon全球软件开发大会暨智能软件开发生态展】</a>\"的启航直播中邀请了<a href=\"https://qcon.infoq.cn/2024/beijing/track/1620\">QCon大会的出品人、阿里云效、通义灵码产品技术负责人陈鑫（花名：神秀）</a>\"，<a href=\"https://qcon.infoq.cn/2024/beijing/track/1623\">QCon大会的出品人、白鲸开源CEO、Apache&nbsp;基金会成员、TGO鲲鹏会学员郭炜</a>\"，<a href=\"https://qcon.infoq.cn/2024/beijing/track/1633\">QCon大会的出品人、数势科技AI负责人李飞博士</a>\"、北京极客邦科技有限公司创始人兼CEO&nbsp;霍太稳Kevin共同讨论上述话题（感兴趣的用户可以扫描下方海报上的预约直播二维码，先行预约）。</p><p><img src=\"https://static001.geekbang.org/infoq/15/151fa75036561270851b744075da7ff0.png\" /></p><p>与此同时，直播期间购买QCon大会展区门票将享受5折优惠，大会门票将享受<a href=\"https://qcon.infoq.cn/2024/beijing/apply\">8折优惠</a>\"。此外，3张以上即可团购，每张门票将单独赠送案例会员季卡一张，可观看往届大会的精品演讲视频，涵盖人工智能、云原生、研发效能、架构设计、前端开发等众多领域（可以扫描海报上面的&lt;大会福利官&gt;二维码，提前了解相关信息）。</p>",
    "publish_time": "2024-02-29 10:26:39",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Cloudflare开源基于Rust语言的Pingora框架",
    "url": "https://www.infoq.cn/article/RUxJrOykuSXwPxFZY3yR",
    "summary": "<p>早在 2022 年，Cloudflare 就宣布他们将放弃 Nginx，转而使用内部 Rust 编写的软件，名为 Pingora。当地时间2月28日，Cloudflare宣布开源Pingora框架。</p><p>&nbsp;</p><p>据悉，Pingora 是一个 Rust 异步多线程框架，用于构建可编程网络服务，采用Apache 2.0 开源许可证。Pingora 长期以来一直在 Cloudflare 内部使用，能够维持大量流量，而现在 Pingora 正在开源，以帮助在 Cloudflare 之外构建基础设施。</p><p>&nbsp;</p><p>Cloudflare 将 Pingora 框架描述为：</p><p>&nbsp;</p><p></p><blockquote>“Pingora 提供了库和 API，用于在 HTTP/1 和 HTTP/2、TLS 或 TCP/UDP 之上构建服务。作为代理，它支持 HTTP/1 和 HTTP/2 端到端、gRPC 和websocket 代理。（HTTP/3 支持已在路线图上。）它还具有可定制的负载平衡和故障转移策略。为了合规性和安全性，它支持常用的 OpenSSL 和 BoringSSL 库，这些库具有 FIPS 合规性和后量子性除了提供这些功能之外，Pingora 还提供过滤器和回调，以允许用户完全自定义服务应如何处理、转换和转发请求。这些 API 对于 OpenResty 和 NGINX 用户来说尤其熟悉，因为许多API直观地映射到 OpenResty 的“ *_by_lua”回调。&nbsp;在操作上，Pingora 提供零停机优雅重启来升级自身，而不会丢弃单个传入请求。Syslog、Prometheus、Sentry、OpenTelemetry 和其他必备的可观察工具也可以轻松与 Pingora 集成。”</blockquote><p></p><p>&nbsp;</p><p>Cloudflare宣布Pingora 开源，其中还包含一个使用它构建负载均衡器的示例。Pingora 处于 1.0 之前的阶段，尚不具备 API 稳定性，Cloudflare 目前没有计划支持非 Unix 操作系统。</p><p>&nbsp;</p><p>Pingora Rust 代码可在<a href=\"https://github.com/cloudflare/pingora\">GitHub</a>\"上获取。</p><p>&nbsp;</p><p>Pingora项目地址：<a href=\"https://github.com/cloudflare/pingora\">https://github.com/cloudflare/pingora</a>\"</p><p>&nbsp;</p><p>参考链接：<a href=\"https://www.phoronix.com/news/Cloudflare-Pingora-Open-Source\">https://www.phoronix.com/news/Cloudflare-Pingora-Open-Source</a>\"</p>",
    "publish_time": "2024-02-29 10:53:44",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "2024 阿里云战略发布会：史上最大力度！阿里云 100 多款产品官网直降 20%",
    "url": "https://www.infoq.cn/article/sMg6Ea7Rhr3mRxXpJAl0",
    "summary": "<p>2 月 29 日，<a href=\"https://www.infoq.cn/article/06kIattDgffkcSlHKMWJ?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">阿里云</a>\"全线下调云产品官网售价，平均降价幅度超过 20%，最高降幅达 55%。这是阿里云史上最大力度的一次降价，涉及 100 多款产品、500 多个产品规格，覆盖计算、存储、数据库等所有核心产品，数百万新老客户可在本次降价中直接获益。降价后，阿里云核心产品价格都击穿了全网最低价。</p><p></p><p>本次降价采用官网直降的形式，对在官网采购的新老客户均适用。其中，<a href=\"https://xie.infoq.cn/article/7be3774368aec3c4eee3c4d0c?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">云服务器 ECS </a>\"最高降 36%、<a href=\"https://www.infoq.cn/article/yMVVwC2BMk13ZwUisIIS?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">对象存储</a>\" OSS 最高降 55%、云数据库 RDS 最高降 40%，都是云上用户使用频率最高的核心产品。无论是大客户还是中小客户，新客户还是老客户，都可以在阿里云官网上直接按照新的价格在线下单。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cb/cb65f240db2eee5d1957300365461c86.png\" /></p><p></p><p>阿里云智能集团资深副总裁、公共云事业部总裁刘伟光表示：“中国云计算发展了十多年，公共云渗透率仍大幅低于欧美成熟市场。作为中国第一大云计算公司，阿里云希望通过此次大规模降价，让更多企业用上先进的公共云服务，加速云计算在中国各行各业的普及和发展。”</p><p></p><p>以最受中小企业欢迎的云服务器u1产品为例，购买 2c4g 配置的五年版需要 768元/年，降价后仅需 485元/年，降价 36%。对象存储 OSS 标准存储-本地冗余从 0.12/GB/月降至 0.09/GB/月，降幅达 25%。数据库方面，以 RDSMySQL 基础系列为例，购买 1c2g 通用型配置的五年版需要 936元/年，降价后仅需 562元/年，降价 40%。此外，阿里云还将云数据传输 CDT 的每月免费公网流量额度从 10GB 提升至 20GB。</p><p></p><p>针对之前包年的老客户，阿里云也推出了相应的优惠政策。客户在降价发布后 3 个月内续费，未消耗的包年时长可按新的价格重新计费。例如，某企业此前购买了 10 万元包 1 年的云服务器，目前只用了 6 个月，只要客户再续费 1 年，此前未消耗的 5 万元云资源可按新的价格（降20%）重新计费，差额可抵扣续费订单，即少付 1 万元。</p><p></p><p>此外，阿里云还全面升级了“99 计划”，面向个人开发者和中小企业推出 99元/年、199元/年的入门级云服务器。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/960136006d2aad1052306cfe2c104d58.png\" /></p><p></p>",
    "publish_time": "2024-02-29 11:43:46",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "拜登：“一切非Rust项目均为非法”",
    "url": "https://www.infoq.cn/article/2SWA4hvSTpe22mMD9mBJ",
    "summary": "<p>“程序员编写代码并非没有后果，他们的⼯作⽅式于国家利益而言至关重要。”白宫国家网络总监办公室（ONCD，以下简称网总办）在本周一发布的报告中说道。在该报告中，拜登政府希望软件开发人员尽量使用Rust这样的内存安全编程语言，并放弃C和C++等安全性薄弱的语言。</p><p><img src=\"https://static001.geekbang.org/infoq/ae/ae9222f4fd1d8fdf51866c8ad74e3071.jpeg\" /></p><p>图源：报告文件</p><p>&nbsp;</p><p>此外，美国参议院国土安全和政府事务委员会主席 Gary Peters (D.MI) 和美国参议员 Ron Wyden (D-OR) 还向网总办强调了他们在内存安全方面的立法努力。</p><p></p><h2>科技巨头要为安全负责</h2><p></p><p>&nbsp;</p><p>这并不是拜登政府对内存安全语言的首次提倡。</p><p>&nbsp;</p><p>美国网络安全与基础设施安全局（CISA）在去年9月的一篇博文中，也曾公开敦促开发人员使用内存安全编程语言。网络与基础设施安全局、联邦调查局（FBI）、国家安全局及各盟国机构随后于12月发布了题为《内存安全路线图案例》（The Case for Memory Safe Roadmaps）的研究报告，其中就点名C/C++存在内存安全漏洞，软件开发商应放弃使用，改用C#、Rust、Go、Java、Python和Swift等内存安全的编程语言 (MSL)。&nbsp;</p><p>&nbsp;</p><p>此外，早在 2022年11月，国安局网络安全信息表就将C#、Go、Java、Ruby、Swift以及Rust列为认定的内存安全编程语言。</p><p>&nbsp;</p><p>在这份19页的最新报告中，白宫则将C和C++作为存在内存安全漏洞的两大编程语言示例，相应的内存安全正面典型则是Rust语言。</p><p>&nbsp;</p><p>微软和谷歌最近的研究发现，约有70%的安全漏洞由内存安全问题引发。 国家网络总监Harry Coker在白宫新闻稿中表示，“我们美国有能力、也有责任缩小网络空间的攻击面，并防止各类安全漏洞侵入数字生态系统。而这要求我们首先解决转向内存安全编程这一根本难题。”</p><p>&nbsp;</p><p>白宫在一份新闻稿明确提出，科技企业可通过采用内存安全编程语言“防止各类漏洞侵入数字生态系统”。内存安全编程语言能够免受与内存访问相关的各类软件bug及漏洞的影响，具体包括缓冲区溢出、越界读取和内存泄漏。</p><p>&nbsp;</p><p>白宫新闻稿提到，这份报告的目标之一是将网络安全责任从个人和小型企业，转移到大型组织、科技巨头及美国政府身上，因为后者“更有能力应对不断变化的威胁形势”。</p><p>&nbsp;</p><p>网总办称其与科技企业、学术界及其他组织等私营部门合作制定了报告中的建议条款。网总办自去年8月起就该主题发出了公众意见征集请求，随后收集到多家科技企业的支持回应，包括HPE、埃森哲和Palantir。其他软件安全专家也对报告内容表示赞赏。</p><p></p><h2>有人欢喜有人愁</h2><p></p><p>&nbsp;</p><p>网总办公室还公布了报告筹备过程中征集到的意见：</p><p>&nbsp;</p><p>Rust基金会呼吁“公共资助组织及其承包商应默认使用内存安全编程语言（例如Rust），并将此作为良好实践要求”。微软将重点放在软件供应链以及行业对开源项目投入不足的现实问题上。IBM表示，重写软件可能过于昂贵，并主张“保护现有软件免受内存安全漏洞影响”的方法。谷歌提到其正与政府机构一道倡导“向内存安全语言和框架的过渡”。亚马逊云科技则给出更为详尽的回应，称“完全支持用内存安全语言编写新项目的做法”，但这“只是提高开源软件安全性整体努力中的一项具体因素”，并强调开发人员有可能禁用掉Rust中的内存安全功能；此外，逻辑错误造成的“安全威胁可能远大于内存安全”。</p><p>&nbsp;</p><p>另一组织也给出引人注目的回应，该组织自称“拥有多位在ISO C++ (ISO/IEC SC22/WG21) 领域拥有数十年经验的 C++ 高级成员，主要负责指导ISO C++发展方向”。</p><p>&nbsp;</p><p>他们提到“内存安全只是整体安全保护中的一小部分”，而且“C++的安全实践主要得益于正式规范、充分指定的内存模型以及活跃的用户与实现者社区。相比之下，某些理论上更安全的语言反而缺少正式规范”，这部分针对的很可能就是Rust。</p><p>&nbsp;</p><p>在他们看来，C++显然是受到了不公平的对待。“对C++的大部分批评主要集中在以传统风格甚至C语言编写的代码，这部分代码没有用到旨在提高类型与资源安全性的现代功能。”</p><p>&nbsp;</p><p>他们还在回应中强调，还有很多其他方式会导致编程错误，包括逻辑错误、资源泄露、并发错误、类型错误、计时错误、终止错误等等。该小组希望改善对C++程序员的教育和指导，“从根本上解决安全问题”。还有部分C++语言专家认为，内存保护机制只能解决少部分安全难题。</p><p>&nbsp;</p><p>而华盛顿大学计算机科学教授Dan Grossman表示，网总办的报告及时且具有指导意见。他认为尽管“几十年来，C和C++的安全风险已经众所周知”，但考虑到实用且成熟的替代方案终于出现，现在正是白宫推动内存安全普及的最佳时机。</p><p>&nbsp;</p><p>与此同时，他认为“恶意攻击者利用内存安全违规实施威胁的手段非常复杂”，因此变革已刻不容缓。</p><p>&nbsp;</p><p>在Grossman看来，涵盖政府、行业及学术界的内存安全相关讨论能够带来有意义的转变。“当然，联邦政府的诸多部门都是重要的软件开发者与提供者，他们可以基于自身立场为后续系统调整或全新系统的开发划定优先级。”</p><p>&nbsp;</p><p></p><h2>Rust 不会立刻取代 C 和 C++</h2><p></p><p>&nbsp;</p><p>然而，替代C和C++绝不可能一蹴而就，特别是在嵌入式系统领域。</p><p>&nbsp;</p><p>根据Statista公布的数据，截至2023年，约有22%的软件程序员仍在使用C++，其中19%使用C语言，总体人气已经不及JavaScript、Python、Java等其他流行语言。但TIOBE编程社区指数榜则仅将Python列为流行度领先语言，紧随其后的分别是C、C++和Java。</p><p>&nbsp;</p><p>Grossman 指出，“好消息是系统软件中其他语言、特别是Rust的应用已经显著增长，我发现人们普遍认为这种演变将进一步加速。而C和C++开发的份额只会逐步降低，而非一夜之间遭到弃用，其巨大的业界整体影响力仍然存在。”</p><p>&nbsp;</p><p>互联网安全研究小组执行董事兼联合创始人Josh Aas则补充称，放弃C和C++将是一个“漫长且艰难的过程。改变人们思考事物的方式离不开持续努力，而现在这样的沟通有助于巩固安全问题在人们思维中的存在感和重要性。”</p><p>&nbsp;</p><p>在Aas看来，要想推动这一变革，政府与私营部门间必须协同努力，将安全编码视为优先事项。</p><p>&nbsp;</p><p>他总结道，“最终，我们必然要编写并部署新代码。但实现这个目标离不开资源的加持，我们必须保证从政府到私营部门的各级领导者，都将此视为高优先级工作。相关负责人应当意识到这个问题，并保证他们在解决问题的过程中能得到有力支持。”</p><p>&nbsp;</p><p>那从技术角度看，用 Rust 重写大型 C/C++ 系统组件后就绝对安全了吗？答案是否定的。</p><p>&nbsp;</p><p>本质上讲，Rust 和 C/C++ 是不能直接交互的——它们在类型、内存管理和控制流方面都采取了截然不同的方法。结果就是，如果手动编写“胶水”代码，就很可能打破隐式假设（例如调用约定和数据表示）、关键不变量（例如内存和类型安全、同步和资源处理协议），并跨过语言边界引入未定义的行为错误，例如展开恐慌（unwinding panics）、整型表示错误、为枚举和标记的联合体类型静默创建无效值等。</p><p>&nbsp;</p><p>内存管理方法方面，Rust 的类型系统会静态跟踪对象的生命周期和所有权，C 语言要求程序员手动管理内存，而 C++ 虽然提供内存安全抽象，但也允许自由将其与原始指针加以混合。</p><p>&nbsp;</p><p>更重要的是，在将 C/C++ 系统迁移至 Rust 时，开发者必须通过 FFI 层来协调这些差异，其困难程度可见一斑。例如，跨 FFI 边界共享指针会引发跨语言内存管理问题，其中一种语言分配的指针会被另一种语言所释放。而当 C 和 Rust 代码试图共享内存所有权时，情况将变得更为复杂。</p><p>&nbsp;</p><p>与此同时，Rust 代码往往高度依赖类型系统所保证的不变量，借此确保内存安全和代码正确性。由于 C/C++ 程序通常不遵循相同的不变量，因此 C/C++ 在与 Rust 代码交互时可能引发冲突，这类问题在重写后尤其多见。</p><p>&nbsp;</p><p>Rust 和 C 间的不匹配，往往导致 FFI 边界处出现大量不安全代码——这令开发者很难安全将组件移植为 Rust 形式。更要命的是，哪怕是精通 Rust 和 Modula 3 系统架构的开发者，也几乎无法回避这些麻烦。</p><p>&nbsp;</p><p>另外，报告里也承认，“在某些特殊情况下，可能无法正常使用内存安全语言”。以太空系统为例，垃圾收集语言就无法满足其健壮性要求。报告还提到，Rust虽具有必要的内存安全特性，但“尚未在太空系统中得到证实。”</p><p>&nbsp;</p><p>值得注意的是，C++ 之父 Bjarne Stroustrup在去年底参加“CppCon”C++ 会议时向观众承诺，他将首先明确该编程语言所需的安全措施的具体类型。</p><p>&nbsp;</p><p>Stroustrup 给出的解决方案是配置文件（指的是需要遵循的一组规则，可以实现特定的安全保证），它们由 ISO C++ 标准定义，解决常见的安全问题，例如指针和数组范围。Stroustrup 的总体策略是，使用静态分析来消除潜在错误，但全局静态分析无法承受，所以需要一些规则来简化正在编写的内容，以便有效且廉价地进行本地静态分析，然后提供一些库来更好地依赖这些规则。</p><p>&nbsp;</p><p>与此同时，虽然被公认为“安全语言”，但 Rust 在2023 年除了提升性能和做规范化，也在努力进行安全性补齐短板。比如Rust通过支持更多安全编译场景如异步 trait 方法、优化编译告警等，优化了用户体验，使用户得以更好地获取 Rust 安全性的优点。</p><p>&nbsp;</p><p></p><h2>结束语</h2><p></p><p>&nbsp;</p><p>除了编程语言，网总办也谈到硬件保护层面，例如将Arm芯片中的内存标记功能，或者SRI Internatioanl与剑桥大学的CHERI（功能硬件增强RISC指令）研究项目作为潜在解决方案。</p><p>&nbsp;</p><p>但对于软件的量化问题，这份报告提出的问题明显多于答案。“软件可量化性是最难解决的开放研究问题之一。”具体挑战包括：大部分软件缺乏统一结构，导致质量评估变得既主观又严重依赖上下文。此外，软件行为往往具有不确定性，软件的自身演进则意味着评估结论会快速过时。报告因此将软件可量化性确立为“研究重点”。</p><p>&nbsp;</p><p>参考链接：</p><p>&nbsp;</p><p><a href=\"https://devclass.com/2024/02/27/white-house-demands-memory-safe-programming-languages-but-iso-c-group-says-its-only-part-of-solution/\">https://devclass.com/2024/02/27/white-house-demands-memory-safe-programming-languages-but-iso-c-group-says-its-only-part-of-solution/</a>\"</p><p><a href=\"https://www.regulations.gov/document/ONCD-2023-0002-0001/comment\">https://www.regulations.gov/document/ONCD-2023-0002-0001/comment</a>\"</p><p><a href=\"https://www.infoq.cn/article/owkfxujpdf86o0d5wr6c\">https://www.infoq.cn/article/owkfxujpdf86o0d5wr6c</a>\"</p><p><a href=\"https://www.infoworld.com/article/3713203/white-house-urges-developers-to-dump-c-and-c.html\">https://www.infoworld.com/article/3713203/white-house-urges-developers-to-dump-c-and-c.html</a>\"</p><p><a href=\"https://www.whitehouse.gov/wp-content/uploads/2024/02/Final-ONCD-Technical-Report.pdf\">https://www.whitehouse.gov/wp-content/uploads/2024/02/Final-ONCD-Technical-Report.pdf</a>\"</p>",
    "publish_time": "2024-02-29 12:40:41",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "100%自研、真正平替Oracle，崖山数据库是如何突出重围的？（上）｜QCon",
    "url": "https://www.infoq.cn/article/24vlYWKcbbUP1pjCGV4a",
    "summary": "<p>极客邦创始人&amp;CEO 霍太稳对话深圳计算科学研究院首席科学家樊文飞，共同探讨深圳计算科学研究院的发展现状和下一步计划，并就生成式AI对现有数据库的影响展开讨论。</p>",
    "publish_time": "2024-02-29 13:11:02",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "100%自研、真正平替Oracle，崖山数据库是如何突出重围的？（下）｜QCon",
    "url": "https://www.infoq.cn/article/2Dt1zIE1j1C2P6II1ULx",
    "summary": "<p>本期节目，深圳计算科学研究院核心骨干，崖山科技公司团队创始人之一、技术副总裁欧伟杰将为我们介绍100%自研的崖山数据库是如何突出重围的。</p>",
    "publish_time": "2024-02-29 13:11:11",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "第一批落地大模型的企业现在做得怎么样了？| QCon北京2024日程上线",
    "url": "https://www.infoq.cn/article/UJKm6UbxGF2dh184o63O",
    "summary": "<p>生成式 AI 的爆发式发展，为软件工程带来了新的活力。我们看到，在大模型的加持下，软件开发全流程的每个环节都在发生变化，从底层操作系统、数据库到应用开发过程的编码、测试，再到项目管理、运维等，各环节都在与智能化能力深度融合。与此同时，以 ChatGPT、Sora 为代表的的生成式 AI 产品展现出的超强能力，也进一步点燃了人们对大模型未来应用场景的无限想象。</p><p></p><p>2024 年，我们将迎来全面进化的时代。技术、产品、组织，都将迎来新的变革与突破，这无疑给企业和技术团队带来了巨大的挑战。在技术、产品和组织的全面进化之路上，或许有一些跟其他团队相似的需求可以参考别人的经验。4 月 11-13 日，QCon 全球软件开发大会暨智能软件开发生态展将在北京国测国际会议会展中心正式召开，会议内容、会议模式均经过全面进化，为大家带来智能软件时代技术先行者们的案例以供参考。大会日程现已正式上线！更多精彩议题陆续更新中~</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/0a/0af655ea4fed54543af638afd8ef7efc.png\" /></p><p></p><h2>部分精彩分享</h2><p></p><p></p><h3>技术的全面进化</h3><p></p><p></p><p>在大模型和鸿蒙等厂商自研 OS 的推动下，技术架构的全面进化是必然趋势，但同时还要兼顾成本和服务质量的双重需求。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b3/b3c1a21c4396995728cfaf8ef31d08de.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/af/afb850b1ed6240180755fb811714cc6b.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/cb/cb75bfe9214676400d67fd9fa2aeb7b2.jpeg\" /></p><p></p><h3>产品的全面进化</h3><p></p><p></p><p>创新的技术和思想，将促进现有的业务模式和产品形态的重构，从而带来更加卓越的性能和用户体验。对于技术同学而言，最大的挑战是从业务出发，探索创新技术和实际应用的结合点，关注实际业务收益，对于产品和业务等非技术同学而言，最大的挑战是理解技术背后的价值，并将之与业务有机融合，充分发挥技术的价值。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/77/7722bb79500fcbb319cd4681d48fde5a.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/1b/1b121acbf375f6ba2d33153490ecc085.jpeg\" /></p><p></p><h3>组织的全面进化</h3><p></p><p></p><p>为了支撑全面进化，各个企业也将不断优化直至重塑组织架构和流程，以获得更具创新力、协作更高效的团队。伴随着新职业诞生、旧职业职责边界的变更，这个过程中必然存在阵痛。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/bc/bc860b45c1db4a84bd59c53ff758c6b4.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5d/5defde853ddbfb8f323e224e2681fbdc.jpeg\" /></p><p></p><p>活动推荐</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5d/5dcf3673446c73ec723753f11ef86f55.png\" /></p><p></p><p>会议现已进入 8 折早鸟购票阶段，错失 7 折特惠的朋友们，可以联系票务经理 17310043226 。<a href=\"https://qcon.infoq.cn/2024/beijing/?utm_source=wechat&amp;utm_medium=infoqart2-0229\">点击 「链接」 </a>\"了解大会更多详情，期待与各位开发者现场交流。让我们相聚 QCon 北京，共同探索软件研发 X 智能未来进化之路！</p><p></p>",
    "publish_time": "2024-02-29 13:42:31",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "刘伟光：用阿里云的客户越多，价格就会越便宜！",
    "url": "https://www.infoq.cn/article/jvLlJqzIKCakkpIlCFo6",
    "summary": "<p>明确\"AI 驱动，公共云优先”战略 3 个月之后，阿里云吹响了进攻号角。</p><p></p><p>2 月 29 日，<a href=\"https://mp.weixin.qq.com/s?__biz=MzA4NTU2MTg3MQ%3D%3D&amp;chksm=846000beb31789a8e93c0f9cfaafd0110c8279c0ab0cef47484960da263680eda31e0ba8ba16&amp;idx=2&amp;mid=2655168478&amp;scene=27&amp;sn=e69b3798ba71dcefe19103ef9422f7aa&amp;utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search#wechat_redirect\">阿里云</a>\"宣布史上最大力度降价，100 多款产品、500 多个产品规格的官网价格</p><p>平均降低 20%，最高降幅 55%。降价后，阿里云核心产品价格击穿了全网最低价。新价格</p><p>即日起生效，数百万企业将直接获益。</p><p></p><p>相比历史上其它几次红利释放，本次降价具有 3 个优点：“两个最，一个首次”，历史上参与</p><p>产品范围最大，受益群体最广，也是首次让利给客户存量订单的未履约部分。</p><p></p><p>阿里云智能集团资深副总裁、公共云事业部总裁<a href=\"https://mp.weixin.qq.com/s?__biz=MzIxMzEzMjM5NQ%3D%3D&amp;chksm=8c4bd732bb3c5e240f2a8af91eae5d9c9c43737a69d88a816850d74ed436722ef0f10e4ee090&amp;idx=1&amp;mid=2651062838&amp;scene=27&amp;sn=6a630f13ec2c1a9c4f9e66f8c57cd055&amp;utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search#wechat_redirect\">刘伟光</a>\"表示，中国云计算发展了十多年，但</p><p><a href=\"https://xie.infoq.cn/article/07dc67f45c681974d9c820209?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">公共云</a>\"渗透率仍大幅低于欧美成熟市场。中国市场的服务器存量规模 2000 万台，美国服务</p><p>器存量规模约为 2100 万台，但美国以公共云形式提供服务的算力占比为 60%，中国仅为</p><p> 28%。</p><p></p><p>刘伟光表示，“让云成为公共服务，创造社会价值”，是阿里云成立第一天起的初心。未来，</p><p>云一定是企业和开发者的首选，技术创新一定优先诞生在云上。作为中国第一大云计算公司，</p><p>阿里云希望通过此次大规模降价，让更多企业用上先进的公共云服务，加速云计算在中国各</p><p>行各业的普及和发展。</p><p></p><p>对比自建 IDC，刘伟光详细阐述了云计算的七大价值——“省、弹、进、捷、拓、智、才”：</p><p></p><p>省，节省企业 IT 总支出。企业使用公共云架构，调度效率更高。绝大部分客户的业务场景</p><p>是有业务量起伏的。云计算提供的弹性能力，可以让客户根据需要采用常态化和弹性相结合</p><p>的开通方式，应对不同时段的资源需求，实现平均资源持有量的明显下降。例如，线下 1000</p><p> 台服务器常态化持有，会变成云上 500 台常态化持有、峰值时段新增 300 台弹性使用。由</p><p>于业务需要保持安全资源水位，而纯线下资源不能按需及时增加，就会导致资源冗余。同时，</p><p>阿里云上的软硬件结合优化，会帮助客户业务在虚拟机和容器运行时实现更高的安全资源使</p><p>用率。客户如果选择使用 PaaS 服务，会有更多优化空间，进一步提升资源使用效率。以更</p><p>少的资源消耗实现更好的业务运行效果，这就是公共云的价值。掌阅科技在全栈迁移至阿里</p><p>云之后，CPU 利用率提升 125%，总拥有成本降低超 30%。此外，公共云可以大幅节省业</p><p>务启动的资源准备时间，自建 IDC 从筹划到使用至少需要数月周期，而使用公共云可以即</p><p>开即用。左手医生基于阿里云公共云快速完成资源部署，项目上线时间缩短 67%。</p><p></p><p>弹，弹性使用算力，减少资源闲置浪费。公共云支持全球多地域部署，有充足的资源保障，</p><p>可以随时随地创建和释放资源。某客票平台在重大节假日需应对几何倍数增长的购票需求，</p><p>采用阿里云弹性计算产品，可以在 1 分钟内快速扩展 3 万核计算资源，应对流量高峰，平</p><p>稳支撑单日最高售票量 2000 万张。</p><p></p><p>进，企业 IT 架构升级进化。企业上云可以实现 IT 架构的现代化升级，让原本基于传统 IT </p><p>的烟囱式架构进化为高可用、多地多活、离在线混合部署的分布式架构，更好地支撑企业</p><p>的业务战略创新。携程基于阿里云实现了高可用架构升级，实现同城多活和单元化部署。太</p><p>平洋保险业务系统部署周期从数天缩短至小时级。</p><p></p><p>捷，快速采用最新、最先进的技术栈。公共云不只是IT基础设施，更提供了先进且丰富的</p><p>产品技术栈。例如，最新的 Serverless 产品可以支撑企业实现流程式开发，让开发流程更</p><p>加精简。云上提供的容器、数据库、数据分析、数据开发治理等丰富的产品，可以帮助企业</p><p>以更快的速度应用新的技术栈。喜马拉雅采用阿里云产品加快了从数据洞察到业务决策的速</p><p>度，其中离线任务平均时长降低 42%，长尾任务时长降低 70%。</p><p></p><p>拓，快速拓展全球业务。阿里云在全球四大洲、30 个公共云地域运营着 89 个可用区，可以</p><p>助力中国企业全球化拓展，大大简化繁琐的 IT 基建和合规事项。瑞幸咖啡基于阿里云新加</p><p>坡的公共云节点和网络、安全产品解决方案，正在快速拓展东南亚市场。传音基于阿里云覆</p><p>盖全球的云计算服务，大幅提升业务迭代效率，总成本显著下降。</p><p></p><p>智，更好地使用人工智能技术。公共云是 AI 的最佳拍档，企业可以使用公共云快速拉起庞</p><p>大的训练和推理资源，低成本实现 AI 创新。百川智能基于阿里云公共云完成千卡大模型训</p><p>练，最长无人工介入训练达到 26 天，起步期每月迭代一个模型。今年 1 月，中国一汽与阿</p><p>里云通义千问联合打造的大模型应用 GPT-BI 率先落地，可以通过自然语言对话，自动生成</p><p>企业经营数据分析图表。去年快速爆红的妙鸭相机，高峰期的访问量至少需要几千台 GPU </p><p>服务器才能满足，妙鸭在阿里云公共云上紧急扩容，迅速实现了算力供应。</p><p></p><p>才，改善企业的 IT 人才架构。通过使用云计算，企业可以让 IT 人才可以更加聚焦业务发展</p><p>和创新。</p><p></p><p>据悉，本次阿里云的降价力度远超过去年上半年的降价行动。几乎所有产品都击穿了全网最</p><p>低价，降价产品范围也直接覆盖数百万量级的企业和开发者。</p><p></p><p>“阿里云降价并非短期市场竞争行为，而是一个长期战略选择，这是公共云的商业模式决定</p><p>的。”刘伟光表示，云计算是一个具备网络效应和规模效应的商业模式。作为亚洲最大的云</p><p>服务商，阿里云为数百万客户提供一个可复用的全球云计算网络和资源池，用的客户越多，</p><p>供应链采购成本、均摊研发成本和资源闲置成本就能不断降低。因此，用阿里云的客户越多，</p><p>规模越大，云的价格就会越便宜；而随着规模的不断扩大，技术的红利就会持续被释放出来</p><p>回馈客户。</p><p></p><p>阿里云降价的底气还来自于强大的技术实力。十多年来，阿里云持续投入软硬一体化的技术</p><p>研发，不断提升研发效率。飞天操作系统和 CIPU 架构可在同样规格资源下带来更强的性能，</p><p>同时实现极致弹性，大幅提升资源效率。阿里云自研的盘古存储系统，通过 EC、压缩等技</p><p>术大幅提高了存储的资源利用率。倚天 710 等自研芯片的不断优化，可将数据库、大数据、</p><p> AI、高性能计算、视频编解码等场景性价比提升 80% 以上。</p><p></p><p>公共云市场渗透率的提升，有利于中国整体的算力效率提升和能耗降低。数据显示，国内大</p><p>量自建 IDC 的平均资源使用率不到 5%，而 AWS、谷歌、阿里云等公共云厂商，数据中心</p><p>资源使用效率可以达到 25%-40%。数据中心利用率提升不仅可以避免硬件资源浪费，还能</p><p>降低算力能耗。据统计，如果将数据中心算力利用率从 5% 提高到 25%，中国每年可以节省</p><p> 800 亿度电。</p>",
    "publish_time": "2024-02-29 13:54:23",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "龙游神州：揭秘云VR大空间背后的技术魔法",
    "url": "https://www.infoq.cn/article/hJSuZS9s3xQ5eXV1NfuR",
    "summary": "<p>龙游神州，一场将古老庙会与现代科技完美融合的云 <a href=\"https://www.infoq.cn/article/WPmK0BeY0dDJB6wLL0zM?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">VR</a>\" 体验，近期成为北京地坛新春庙会的网红打卡项目。这场由央博数字文化艺术博物馆和<a href=\"https://www.infoq.cn/article/JOGNSaNEdUlZK9QSzOxN?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">火山引擎</a>\"云游戏团队联手打造的沉浸式体验，究竟是如何通过技术魔法实现的呢？让我们一起来揭开这层神秘的面纱。</p><p></p><h2>系统架构</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ac/acdf35ca2af9cb59d3b34ccd20ee6897.png\" /></p><p></p><p>本项目的技术架构主要由服务端包含云渲染、智能调度、运营监控、媒体服务等能力构建，并在多路并发、超低延时、体验优化、运营监控等大空间技术难点层面做了优化和提升；客户端硬件采用 Pico 4E，无线方案采用企业级 AC + AP，运营方案由 <a href=\"https://xie.infoq.cn/article/8f9e85c1a4f2af5f673b3b2a3?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">Pico </a>\"企业服务提供支持。</p><p></p><h2>核心优化</h2><p></p><p></p><h4>WiFi场景24路并发实现</h4><p></p><p></p><p>24 路并发取决于客户端侧 WiFi 的规划以及 AC 和 AP 的深度优化</p><p></p><p>通过 AC 将 AP 组合理规划，保证网络连接的稳定性，同时，每个 AP 组均衡分配终端，以保证负载的均衡做到 24 路并发，同时配合 AP 固件优化，做到端到端更低的延迟</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a6/a646ab11bcec77e862d5c1fe7f9da0eb.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/50/5066c6c58cffb6b71e5ab2205a325a86.png\" /></p><p></p><p></p><h4>端到端低延迟</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/62/628e9f121e497c46d829d053ec8c44b9.png\" /></p><p></p><p>端到端延迟优化是通过服务端云流化引擎的 RTC 部分实现的。</p><p></p><p>云 VR 使用了火山引擎智能拥塞控制算法 VICC（Volcano Intelligent Congesttion Control）VICC 是一种自适应的拥塞控制算法，旨在解决全球不同网络环境下，不同音视频应用对带宽利用率和延时的差异化要求。它结合了传统拥塞控制算法（如 GCC 和 BBR）的优点，并且能够根据不不同的网络条件、业务偏好和码率特征进行自适应调整，包括自适应拥塞响应速度、自适应带宽探测幅度、自适应丢包检测策路、自适应抗抖动能力和自适应 Padding。通过这些自适应调整，VICC 算法能够提升各种复杂弱网下的带宽利用率，同时在满足不同延时的条件下，尽量提升带宽的稳定性，为用户提供更好的音视频体验。</p><p></p><p>VICC 优点如下：</p><p></p><p>多种基础网络状态参数展示</p><p>评估当前网络状态的重要指标之一是网络状态统计参数,而准确的基础网络状态参数是提高带宽估计准确性和带宽利用率的关键基石。VICC 算法提供了多种基础网络状态参数，部分基础网络状态态统计参数如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/43/43755b33b4568822aac5a209b5cbdb1b.png\" /></p><p></p><p>自适应拥塞控制</p><p>VICC 算法结合了传统拥塞控制算法的优点，并且能够根据不下同的网络条件、业务偏好和码率特征进行自适应调整，包括自适应拥塞响应速度、自适应抗干扰能力、自适应丢包检测、自适应带宽探测幅度、自适应拥塞排空等。</p><p></p><p>抗抖动能力强</p><p>拥塞响应越灵敏，意味着在网络抖动场景下容易误判，导致算法抗干扰能力下降。VICC 使用蚁穴算法来对抗网络抖动和乱序，通过接收码率和发送码率来度量网络透过率，并结合观察延迟参数变化趋势及关联性，提升自适应抗干扰能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dd/dd0ddd6b5067d7c35bbf654cf8071694.png\" /></p><p></p><p></p><h4>帧率优化</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/87/878728a495f21a4d48c63055af4196eb.png\" /></p><p></p><p>帧率优化的实现依赖的是云VR引擎中的架构设计和代码实现。</p><p></p><p>云 VR 引擎，火山引擎自主研发，包含设备模拟（头盔及手柄模拟）、操控模拟、音频采集、图像采集、编码框架、传输框架等功能，架构设计如下</p><p></p><p>下面两幅图展示了市面上的主流实现及火山引擎的实现对比，可以看到，后者的单帧占用时间更少，帧率更高，关键在于以下几点：</p><p>更高的 CPU 利用率，通过对各 API 实现的摸索，通过不同函数处理逻辑的合理分配来达成这点，提高了单位时间内引擎的循环次数更高的 GPU 利用率，通过渲染函数内部非阻塞处理，使 GPU 指令始终处于填满指令队列状态来实现这点，通过 insight 类软件可以确认这点多线程无缝协同，CPU 多线程协同每1毫秒的增加意味着帧率的损失，尤其在 VR 高帧率场景下，1 毫秒在 1 帧的处理时间的占比比普通应用更大，而各 API 实现的调用时机由 SteamVR 的 vrserver 决定，所以要降低单帧占用时间，则需要降低输出帧延迟，这里我们通过将阻塞处理分配到其他线程，实现了更快的获取帧状态的改变消息，在收到之后立即编码更高的 vsync 精准度，自研 vsync，拆离渲染、采集，使两者可以 Overlap，使 GPU 在渲染和采集之间无缝衔接，达到每帧总体时间的减少</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/06/06ff73777cf6506a9ffc5a3967125744.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9c/9c157cc9b350d726194a56d0a1c133aa.png\" /></p><p></p><p></p><h4>渲染画质提升</h4><p></p><p></p><p>渲染画质提升通过客户端集成火山引擎自研超分算法实现。</p><p></p><p>重新设计实现基于视口的投影技术，将平面投影转换成球面投影，降低镜目边缘的图像畸变，实现均匀像素密度。同时通过端侧的姿态预测智能算法，在网络时延出现波动时，有效降低黑边现象的出现频率。同时为了提升清晰度，客户端渲染上屏前，使用自研的图像超分算法在将3K超分至4K，提升画质色彩深度，且算法是利用 OpenCL 在 GPU 侧实现，对单帧耗时影响较小。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/22/2210f454bb7b82c5ddcdb2001b83905f.jpeg\" /></p><p></p><p></p><h4>投影优化</h4><p></p><p></p><p>投影优化处理在云 VR 引擎及云流化引擎内部处理，包含渲染分辨率的提升及投影变换两部分</p><p></p><p>常见投影为 CMP，CMP 的像素密度特点为内密外疏，而这就会造成图像中部细节丢失，而边缘细节完整，这与人眼的视觉特点相背，为解决此问题，采集后若做 EAC 处理，使像素密度更加平均，可以增加图像中部细节的完整性，在云 VR 引擎初始化时，首先提高渲染分辨率，在采集完成后再对渲染后的图像做投影变换，具体原理可参考 https://blog.google/products/google-ar-vr/bringing-pixels-front-and-center-vr-video/。</p><p></p><p></p><h2>其他功能</h2><p></p><p></p><p></p><h4>QoS 实时运营监控</h4><p></p><p></p><p>云 VR 大空间项目是一个线下项目，顾客的实时体验监控是运营人员比较关心的一个问题，客户端复用信令通道，以及数据包压缩技术，可以做到客户端不增加任何 QPS 情况下，实时上行传输设备帧率、码率、时延、丢包、电量等信息，使运营监控端可以实现毫秒级监控，做到追踪单个视频帧在各传输阶段的时延。</p><p></p><h2>硬件方案</h2><p></p><p></p><p></p><h4>便捷易用的大空间能力</h4><p></p><p></p><p>在以上火山引擎云游戏提供的VR实时云渲染技术方案之外，PICO Business 提供的大空间功能也是不可或缺的一环。</p><p></p><p>PICO Business 包括了企业级硬件、企业级 OS、企业级软件平台和企业级服务等内容，为企业用户提供全面成熟的 XR 解决方案与最佳实践，帮助用户提升业务效率，降低部署的成本和门槛，解决业务中面临的技术挑战，创造全新价值。借助 PICO Business，开发者可以快速实现面向文旅、培训、医疗、营销、线下娱乐等场景的的一体化解决方案。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ee/ee8cd2dc7202ce4b6d28f43e3798f4cb.png\" /></p><p></p><p>大空间是 PICO Business 的一个重要产品。大空间功能是通过SLAM建图实现，即利用某台设备运行视觉 SLAM 定位对空间进行扫描，设备通过相机拍摄照片，并从照片中提取特征（如桌子的边缘）并记录特征的 3 维坐标（此3维坐标所在坐标系即为地图坐标系），此类信息最终都存储在地图中。设备开机后会对空间内提取特征，算法会将新提取的特征与地图内的进行匹配，当匹配成功后，利用 pnp 算法（该算法利用地图内特征的像素坐标、该特征的3维坐标、特征在当前设备上的像素坐标）可以计算出设备在地图坐标系下的位姿，即实现了使用地图坐标系。该方案仅需要头戴设备就可以完成，不依赖外部基站，部署简单易用，成本低。另外地图数据可以同步至其他设备，多台 VR 共享同一份 SLAM 地图，即共享同一地图坐标系，达到大空间多设备共享协作的目的，整合方案非常便捷。</p><p></p><p>技术细节参考 https://business.picoxr.com/cn/doc/Enterprise-Settings-LBE-v1.3#4ab364ef</p><p></p><h2>总结和展望</h2><p></p><p></p><p>火山引擎始终坚持在音视频与 AI 领域不断创新。未来火山引擎云游戏将持续深耕技术研发，依托高性能算力和低延迟传输方案，为各类互动场景提供有力支持，让更多用户畅享云技术带来的流畅高清影音体验。未来，随着 OpenXR 标准的逐步落地，云 XR 将是下一个技术目标，会有更多的性能优化及功能的扩展。</p>",
    "publish_time": "2024-02-29 14:28:42",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "顺丰实现业务和流转效率提升的背后：严格执行数据中台战略",
    "url": "https://www.infoq.cn/article/MO3Sjk7QCQ7EDyHmmN2V",
    "summary": "<p></p><blockquote>嘉宾 |&nbsp;林国强 顺丰科技大数据总监</blockquote><p></p><p></p><p>2023 年，顺丰科技发布了首个在物流领域大规模应用的数字孪生实践。在物流典型的中转分拣场景，该技术已经可以实现 1 天内在虚拟环境验证并优化 1000 次分拣计划，通过向全国 60 多个中转场的快速复制，平均每个中转场提升了 8% 以上的产能。</p><p></p><p>“大数据做打底”是提高数字世界精准度，降低和现实物理世界差异的前提和基础。在顺丰数字化过程中，其构建了一套“1+1+n+x”的框架和机制，以确保数据驱动业务的体系化运作。其中，前两个“1”均与数据相关，分别是“大数据底盘”和“数据治理体系”。</p><p></p><p>在 InfoQ《超级连麦. 数智大脑》2024 年度首期直播中，顺丰科技大数据总监林国强对该运作框架进行了介绍，并且分享了顺丰内部如何从战略、组织、目标、成果量化等维度入手严格执行数据中台战略，使得涉及多环节、复杂流程的物流供应链场景数据的标准得以统一，并确保数据质量满足业务需求，帮助顺丰提升流转效率。</p><p></p><p>以下内容根据对话整理，篇幅有删减，点击链接可观看直播回放：<a href=\"https://www.infoq.cn/video/FIKfbul8LmVwJcfVQxfg\">https://www.infoq.cn/video/FIKfbul8LmVwJcfVQxfg</a>\"</p><p></p><h3>构建数据驱动的运作框架：1+1+n+x</h3><p></p><p></p><h5>InfoQ：物流和供应链行业的核心业务目标之一就是把具体的任务和资源做匹配，尽可能提升流转的效率。我们看到，过去顺丰基于大数据、机器学习、运筹优化等技术打造了智能化的决策体系，是否可以请您先大致介绍一下这套体系的运转机制？</h5><p></p><p></p><p>林国强：数据驱动业务需要一套完整的框架和机制来维持运作，涉及的技术包括大数据、机器学习、<a href=\"https://www.infoq.cn/article/ZSUbLiwtLQNym9NXy65a?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">运筹算法</a>\"和人工智能等。</p><p></p><p>顺丰内部将这套架构称为“1+1+n+x”。顺丰通过“1+1+n+x”的方式，确保数字化数据驱动业务的整体运作。</p><p></p><p>第一个“1”是指大数据底盘，包括数据相关开发工具，从采集到接入、到资产到质量到服务全流程的工具，确保数据能够顺利、简单地进入平台。</p><p></p><p>第二个“1”是指数据治理体系，包括立法、司法、执法、主数据标准、元数据标准、数据质量、数仓标准等，确保数据质量满足业务需求。</p><p></p><p>“n”是指 n 个业务场景，包括运营、财务、市场等各个业务线，例如需求预测、业财一体、潜客挖掘等。</p><p></p><p>“x”是指顺丰的智慧供应链战略，围绕消费供应链、生产供应链、制造供应链等打造智慧供应链模型能力，例如仓网规划、路径规划、装箱规划、智能调度等。</p><p></p><h5>InfoQ：去年顺丰发布了首个在物流领域大规模应用的数字孪生实践，目前具体在哪些业务场景落地？具体带来了哪些商业增长或者降本增效的成果？</h5><p></p><p></p><p>林国强：<a href=\"https://www.infoq.cn/article/N2gWCU0NhYWjmyxwwy2R?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">数字孪生</a>\"的本质是对现实世界的虚拟化，以 1:1 的比例还原，让我们在虚拟世界中进行试错和验证，以更高效的方式找到最佳解决方案。这一技术在各行各业都有广泛应用，对于顺丰来说，主要利用数字孪生技术在点和面两个方面进行验：</p><p></p><p>在“点”方面，顺丰对中转场进行建模，包括人员、设备、货物流程等，以验证整个分拣计划和资源调度计划的效率。通过这一技术，顺丰能够大大提高风险计划的验证效率，例如一天内能验证超千次班次，比以往验证的效率高很多。此外，当顺丰需要关停某条分拣线或减少人员时，该技术也能快速验证这些变化对整体分拣吞吐的影响，从而做出更优化的决策。</p><p></p><p>在“面”方面，顺丰计划对站点、中转场、道路、航线、车辆和人员进行整体建模，形成整个数字孪生的物流网络。这将有助于顺丰进行全网的畅网规划和局部最优调度，提高整体物流效率。经过验证，这一技术可以帮助顺丰节省城市运营线路，已经在内部得到推广应用。</p><p></p><h5>InfoQ：另外一个关键问题是，很多企业普遍认为数字孪生技术的成本投入较大，因此存在投入产出的考量。顺丰在这方面是如何考虑的？</h5><p></p><p></p><p>林国强：数字孪生的投入需要考虑场景本身的收益。投入不是问题，关键在于投入后是否能覆盖前期投入成本。对于我们来说，收益远远高于投入。</p><p></p><h5>InfoQ：谈到技术热点和战略投入，我相信很多人最近都关注到了 Sora。林老师您对 Sora 的出现抱有什么样的看法？在物流场景下，文生视频技术可能有什么应用？</h5><p></p><p></p><p>林国强：我主要基于自己的感受简单谈谈。</p><p></p><p><a href=\"https://www.infoq.cn/article/w72jY5dZOrW1f8ANARpG\">Sora </a>\"本身非常惊艳，这点是无可否认的。首先是它的输出时长，可以达到 60 秒以上。这比目前最长输出时长的 Runway 的 16 秒要长得多。60 秒意味着什么呢？就是在像抖音这样的视频平台中，视频最低要求是 60 秒，这意味着你可以用 Sora 做中视频计划并获得收益。其次是它的画面质量，包括分辨率等都非常好。例如，在视频中一些毛发、水波纹和纹理等都做得非常细致。在我看来，目前来看，Sora 在这两个方面做得比较出色。</p><p></p><p>但 Sora 自身也存在一些不尽如人意的地方。例如，Sora 本身对因果关系和物理原理的认知比较弱。我记得很清楚，有一个文本叫做“老奶奶吹蜡烛火苗”，但是在 Sora 生成的视频里，老奶奶吹的蜡烛火苗却是静止的。因此，它对物理原理和因果关系的认知相对较弱。目前来看，它可能对广告媒体和游戏设计行业的影响会比较大，但是由于未能完善因果关系和时空关系，因此在物流领域可能暂时不会有太大作用。</p><p></p><h3>严格执行数据中台战略</h3><p></p><p></p><h5>InfoQ：无论是智能决策体系还是数字孪生实践，数据在其中都发挥着关键作用，在推动这些技术创新的同时，针对数据，顺丰内部制定了什么样的策略和目标？</h5><p></p><p></p><p>林国强：我们在内部严格执行数据中台战略。这一战略从建立数据委员会到构建<a href=\"https://www.infoq.cn/article/yo4HIY9cwcmKfSDWjlJw\">数据治理体系</a>\"，包括主数据标准、元数据标准、数据质量和数据仓库标准等方面都有着严格的制定和执行。我们制定了数据质量划分策略，确定了数据质量的责任人和具体执行流程，这些都是为了确保数据质量。</p><p></p><h5>InfoQ：物流场景中包含收、转、运、派等各个不同环节，涉及角色和节点众多，顺丰是如何统一数据标准的？又是如何确保这些标准顺利落实的？</h5><p></p><p></p><p>林国强：事实上，数据标准的落地在整个<a href=\"https://www.infoq.cn/article/LGQQuHSkZz8RbPKgcDNO?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">数据中台战略</a>\"中是至关重要的核心部分。我们将其分为三个方面。</p><p></p><p>首先是定战略，因为对于像顺丰这样涉及上千个业务系统和数百个 BU 的公司来说，要让各组织达成一致，数据中台对于集团的重要性不言而喻，需要明确战略的指引。在这一点上，我们需要将其提升至战略层面，企业高层必须站出来，对此负责并明确其意义。我们当时定位整个数据中台战略的意义是高效连接数据的供给侧和消费侧，持续沉淀数据公共能力，实现数据按需安全共享，以助力集团的经营增长、客户体验和风险控制。这一定义由公司高层出面背书，以确保各组织对此有相同认知。</p><p></p><p>其次是定组织。因为这是一项庞大的工程，不能单靠公司内的某个 IT 部门或大数据中心来实现。我们需要各业务线和职能线共同参与，这就需要成立我们所谓的数据委员会，包括立法、司法和执法这三个关键角色。立法更多地是制定大框架的规则，而司法则由信息安全部门和数据架构师来执行监管角色。执法包括数据仓库团队、数据质量团队和数据服务团队，以确保整个数据治理的执行。这三个角色确保了整个运作机制的正常运转。我们还建立了相关的数据质量台账，定期公示数据质量，以确保各业务线能够配合执行。</p><p></p><p>第三个是定目标。我们要明确告诉大家建立数据中台或进行数据治理的目标绝不是简单地为了数据标准化。因为这个过程是一个持续的事业，如果我们只是汇报数据标准化的结果，这远远不能满足公司的期望。因此，确定目标非常重要。目标的意义在于将数据标准化过程、中台战略与公司业务增长、成本降低和效率提升的关键指标或事项相互关联，形成合力，推动整个数据驱动业务的主线。</p><p></p><p>最终的成果要有量化的结果，无论是成本降低、商业增长还是其他方面的，都要向企业高层汇报。这就是定目标的意义。如果我们的定战略、定组织和定目标能够清晰、妥当、扎实地落实，相信我们的数据治理或数据标准的工作已经成功了大半。</p><p></p><h5>InfoQ：具体来说，顺丰的原始数据清洗怎么做的？</h5><p></p><p></p><p>林国强：原始数据清洗的流程通常是这样的，首先，我们将原始数据统一收集到 ODS 层，即数据库的“贴源层”。然后，从贴源层到 DWD 层（明细层），我们会基于相关的主数据和前面提到的数据入湖标准进行清洗和转换操作。</p><p></p><p>因此，原始数据并不意味着它没有用处。因为当某个数据质量出现问题时，或者末端应用出现问题时，我们可以通过数据血缘找到问题的根源，而不是将整个转化和清洗过程放在数据湖之外。我们将其放置在数据湖中，这样在追溯时整个链路就会非常清晰。发现“脏数据”后可以让业务部门按照之前定义的数据质量规则尽快处理，并且关联相关的主数据。我们对元数据定义有一些要求，例如，在数据的流转过程中，身份证号码或手机号码的数字和英文字符需要在从 ODS 到 DWD 的过程中进行处理。</p><p></p><h5>InfoQ：顺丰有上千个业务，而且这些系统的建设年代也不同。每个系统都有自己的定义，比如某些系统可能有自己的主数据，那么顺丰是如何进行治理而不影响原有的业务系统呢？</h5><p></p><p></p><p>林国强：这个问题我们经常会遇到，特别是在主数据管理方面。有些老系统可能没有主数据的概念，而一些新老系统对主数据的定义也不一致。另外，当一些老系统更新数据库时，也会对我们后端主数据的治理造成一定影响。</p><p></p><p>解决这个问题的关键在于两点：</p><p></p><p>首先，要根据数据规模，在数据湖中尽可能细分分区。比如，可以将数据按小时或者按天进行分区，这样当我们发现后端质量出现问题时，可以及时进行整改，减少需要重新刷数据的量。</p><p></p><p>其次，我们引入了一些工具化的强制检测机制，以确保数据的干净度。不是所有数据都能够直接入湖，而是经过前置的主数据标准检测。虽然在引入这些检测机制的初期可能会遇到一些问题，比如出错或者受到阻碍，需要做一些整改。但是一旦这些机制建立起来，对于数据湖的整体健康度会有很大帮助，可以预防和减少后续的数据质量问题，这是事后和事前两方面的建议。</p><p></p><h5>InfoQ：为何顺丰的某些系统数据不先进入数据湖，而是直接与主数据平台进行实时交互？</h5><p></p><p></p><p>林国强：这个涉及数据链路的问题。实际上，数据链路不仅包括离线链路，还涵盖了实时链路。在某些场景中，数据在前端就已经进行了初步处理，再进入后续流程。这并不意味着所有数据都必须先经过某个特定环节。例如，数据在进入 Kafka 时可能已经完成了主数据处理。</p><p></p><p>这与各业务线的历史和发展密切相关。每个公司的数据架构都有所不同。有些公司可能相对简单，业务系统只有几十套，且公司成立时间不长，历史负担不重，因此数据架构相对清晰。然而，对于大多数 5 年以上的公司来说，由于业务发展和技术积累，数据架构通常较为复杂，涉及各种情况和处理流程。</p><p></p><h5>InfoQ：事实上，无论是在系统建设还是任何技术应用的前期都会遇到内部阻碍，在这方面顺丰有什么经验，如何缩短这个过渡期？</h5><p></p><p></p><p>林国强：为了解决这个问题，我认为关键是要找到一种方法，使得业务部门的利益与数据整合的目标相趋同。换句话说，我们需要明确业务部门通过参与数据整合可以获得哪些实际利益。例如，如果能够帮助市场团队收集更完整、更准确的客户数据，这将如何促进他们的工作？我们能否提供一些具体的案例或方法论，说明通过数据整合，市场部门可以实现潜在客户挖掘、新客户增长等方面的提升？为了实现这一目标，技术团队需要与业务团队紧密合作，共同制定解决方案。业务团队中的成员需要积极参与，提供他们的见解和经验，以确保数据整合工作能够真正满足业务需求。</p><p></p><p>通过强制手段虽然短期内可能取得一定的效果，但从长远来看，这并不是一个可持续的解决方案。真正的关键在于如何确保业务部门与数据部门在业务目标和利益上实现真正的协同。这需要我们不断探索和实践，找到最适合自己企业的方法。</p><p></p><h5>InfoQ：在谈到制定战略时，您提到了一个关键点，那就是数据可以按需安全共享，这并不是一件简单的工作。对于数据部门的人员来说，业务部门提出的需求可能会非常频繁和繁琐；而对于业务部门的人来说，有时他们可能会感觉数据部门的响应效率不高。那么在顺丰，我们是如何实现按需共享的呢？这就需要具备哪些前提条件才能够达到这一目标？</h5><p></p><p></p><p>林国强：因为数据团队人数有限，无法满足业务部门庞大的需求。当业务部门提交数千个需求时，数据团队难以应对这样大规模的需求。因此，我们引入了另一个角色，我们称之为数据伙伴或数据合作伙伴。这些数据伙伴来自业务部门，他们可能在财务或其他部门工作，并且对数据非常敏感，愿意积极学习相关内容。</p><p></p><p>我们为他们提供了一些低代码工具，比如商业智能工具或数据分析工具，让他们可以基于这些工具生成他们所需的指标。这样一来，我们的团队可以将精力集中在数据仓库的核心部分，比如从 ODS 到 DWD 再到 DWS 的工作上。至于数据仓库层以上的智能应用层，我们尽可能地交给业务方去处理。这样做的好处是，你会有更多的伙伴来帮助你执行整个数据战略，而不会受限于目前团队的规模。</p><p></p><h5>InfoQ：顺丰是如何构建数据中台部门的？与其他业务部门如何协调？</h5><p></p><p></p><p>林国强：数据中台部门的构成包括平台部门、工具侧和数仓侧的团队。这几个团队如何与其他部门协同呢？最核心的就是立项。立项意味着项目的启动，只有通过立项，才能够获得资源的投入，包括工时、出差、采购等方面的资源。</p><p></p><p>对于集团层面来说，立项的参与方包括业务侧、财务侧、技术侧等，他们会共同规划项目的执行计划，明确每个季度、每个月要完成的任务。通过立项，整个成本投入也会变得清晰可见，包括外部采购和内部人员投入。此外，每周的工时填报也通过项目报表进行，以便了解协同进展情况。</p><p></p><h5>InfoQ：数据质量决定着数据应用的效果，在顺丰场景中，哪些因素可能会影响数据质量？具体如何规避？</h5><p></p><p></p><p>林国强：需要从两个方面来思考：制度层面和工具层面。</p><p></p><p>首先，从制度层面来看，确保数据质量至关重要，这需要明确责任方。每个数据的所有者都必须确定，他们的职责范围也必须明确。举例来说，如果收入报表的数据出现问题，就需要确定谁是收入数据的所有者。在数据治理委员会的早期阶段，我们要明确定义每个数据的所有者，他们的职责和质量处理范围。</p><p></p><p>其次，从工具层面来看，我可以举几个例子：一是主数据的问题，比如国家、省份或人员代码的错误。为了尽可能确保数据的纯净性，我们在数据入湖的时候可以采用工具进行强制性检测；</p><p></p><p>二是数据波动，尽管这种情况不太常见。如果数据在短时间内出现大幅度变化，我们需要分析是否是延迟或前端脏数据导致的。为了解决这个问题，我们可以定期分析数据质量台账，确定问题所在并及时解决。</p><p>最后一个例子是数据丢失，因为数据质量的关键问题之一就是数据丢失。在大规模场景下，即使丢失了少量数据，也可能造成严重影响。为了避免这种情况，我们需要确保建立完整的数据血缘，从数据接入开始到最终应用端都要建立起血缘关系。这样一来，当出现数据丢失时，我们可以追踪到丢失的具体位置和原因，从而避免潜在的损失。</p><p></p><h5>InfoQ：在如今的经济形势下，企业越来越看重技术的投入产出比，那么，聚焦数据管理的投入效果最大化以及期间的可视化追踪问题，顺丰有哪些经验可以分享？采取了哪些战略措施？</h5><p></p><p></p><p>林国强：这个问题实际上是很多企业的数据中台负责人或数据方面的负责人都非常关心的。我们也经历了一段时间的试错和摸索，有几点值得分享一下。</p><p></p><p>首先，在早期阶段，我们更多地讨论数据的价值。这个数据价值指的是数据被应用的广度和热度。比如说，在数据的末端，我们会建议将数据服务化，通过数据服务我们能够了解到这个数据被哪些应用、哪些 BU、哪些企业所调用，以及调用频次是多少。通过血缘反向计算整个链路中每项数据的应用广度和热度，明确哪些数据具有价值，哪些数据没有价值，以及如何处理没有价值的数据，如何增加对有价值数据的投入。</p><p></p><p>第二点是数据成本的概念。数据成本不仅指数据开发本身所产生的成本，比如服务器资源、人力投入等，还要关注单位业务金额对应的数据成本是否在降低。举个例子，如果公司一年的营收是 20 到 30 亿，数据成本可能是 2,000 到 3,000 万，那么这个比值是不是在逐年增加？也就是说单位业务金额对应的数据成本是否在降低？如果单位业务金额对应的数据成本在降低，而且保证了相同的服务水平和 SLA，说明企业整体的数据技术能力在提升。</p><p></p><p>最后，我们最终可能还是要回归到核心价值点，也就是数据收益，这是从中长期来看的。因为这个问题在过去，甚至未来几年都是不可回避的，因为当前大家都知道经济环境并不好。最终，我们关注的还是投入和收益的对比。在这个时候，数据对业务部门的成本降低、收入增加到底实际上为公司做了多少贡献？如果 ROI 比值大于等于一，就证明投产是对公司有价值的。</p><p></p><h3>数据要素流通的价值与挑战</h3><p></p><p></p><h5>InfoQ：过去一年，数据资产入表、“数据要素×”行动计划等一系列政策文件相继发布和实施，这对于顺丰乃至整个物流行业有哪些意义和价值？对于我们的数据管理策略制定又会带来哪些影响？</h5><p></p><p></p><p>林国强：对于企业而言，数据资产入表的实施是至关重要的，它有助于增加企业的资产，对于任何上市公司都至关重要。数据资产评估将对数据质量和价值产生更高的要求。在具体的数据管理策略制定中，顺丰也会加强数据治理和数据价值的管理，以确保数据资产的评估能够获得较高的评价。这种加强对于上市公司和即将上市的公司尤为重要，因此这一群体可能会更加重视数据资产的治理。</p><p></p><h5>InfoQ：数据入表这一个动作对于大数据部门会产生什么样的影响？在配合财务部门方面是不是有一些具体的工作应对？</h5><p></p><p></p><p>林国强：<a href=\"https://www.infoq.cn/article/CZU0RmQ8IDLuCdgpcpOY\">数据资产入表</a>\"对公司的资产增值是肯定的，因此这将证明团队的价值。与财务部门的合作是必不可少的，因为数据资产入表需要第三方咨询评估机构的介入，以及与证券交易所进行相关的最终评估和确认。</p><p></p><p>财务部门和数据团队需要就数据资产入表的具体事宜进行探讨，并落实相关产线。评估数据资产价值的方法有成本法和收益法。在确定哪些数据资产应该入表时，需要考虑投入的资源、开发人员的数量以及服务的部门和创造的业务价值等方面。这些信息需要从财务的角度进行审视，而不是技术开发人员的角度。由于技术同学可能对财务口径不太了解，因此需要进行跨领域的交流和学习。未来涉及资产入表的大数据从业者可能需要学习一些简单的会计术语，以便更好地与财务同学进行交流。</p><p></p><h5>InfoQ：反之对于财务部门而言，如何和数据部门进行联动，以便更好推进业务？</h5><p></p><p></p><p>林国强：财务部门在推动数据资产入表方面扮演着关键角色，因为财务是企业主最关注的方面，尤其是对于中小企业而言。财务部门的重要作用体现在两个方面：首先是推动数据资产入表。数据资产入表是非常重要的，因为它可以增加公司的无形资产，对公司来说是一件好事。财务部门完全可以发起这项工作，并与数据部门紧密合作，从而使数据部门能够获得相关的价值。同时，财务部门和数据部门之间的合作也能够为双方带来益处，实现双赢的局面。</p><p></p><h5>InfoQ：数据要素的流通并非单一企业可以独自实现的，它涉及整个行业乃至多个生态系统之间的互动。针对物流行业，实现数据要素的流通要面临哪些挑战，头部企业能发挥哪些作用？</h5><p></p><p></p><p>林国强：数据要素流通是一个复杂的问题，从国家层面以及各地的数据交易所来看，都在积极推进数据要素流通。然而，对我们行业来说，主要的挑战包括两个方面。</p><p></p><p>首先是合规性。尽管国家已经颁布了相关的公民个人隐私保护法，也有数据要素流通的相关规定和细则，但具体落地实施案例还比较少，缺乏足够的参照物，导致许多企业不敢轻易行动。我们建议由国有企业牵头，如中国物流集团来组织民营企业参与，以确保该举措的有效落地。</p><p></p><p>其次是数据标准化。在物流领域，由于其信息化发展相对滞后，并且存在许多加盟企业，因此很难有效管理数据。我们建议由数交所牵头，邀请行业龙头企业，如顺丰等，参与制定数据标准，这种模式也适用于其他行业和领域，从而为数据要素流通奠定良好基础。</p><p></p><h4>嘉宾介绍</h4><p></p><p>林国强，现任顺丰科技大数据总监。负责顺丰集团大数据及区块链科技融通、产业化赋能和生态建设。对供应链科技、产教融合、城市物流及快消零售行业有深入研究和实践，理解行业痛点和科技创新的链接点，在行业中落地过多个头部客户数字化转型案例，助力客户实现主营业务增收、供应链成本优化和管理数字化。</p>",
    "publish_time": "2024-02-29 14:41:48",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "C/C++ vs. Rust，程序员的代码选择，关乎国家安全？| 讨论",
    "url": "https://www.infoq.cn/article/sOmbLFN3CKt4VkyoIhBQ",
    "summary": "<p>今日 InfoQ 这篇报道：<a href=\"https://www.infoq.cn/news/2SWA4hvSTpe22mMD9mBJ\">拜登：“一切非 Rust 项目均为非法”</a>\"受到了广泛关注，白宫国家网络总监办公室（ONCD）本周发布报告强调，程序员选择编写代码的方式对国家利益至关重要。拜登政府希望软件开发人员使用内存安全编程语言，如Rust，而不是C和C++等安全性较差的语言。</p><p></p><h4>【懒人速览】</h4><p></p><p>美国白宫国家网络总监办公室 (ONCD) 发布报告，建议软件开发人员使用内存安全编程语言，例如 Rust、Python、Swift、C#、Java 和 Go 等。目的在于提高软件安全性，减少网络攻击面，保护数字生态系统乃至国家安全。报告还提到了内存安全硬件技术的重要性，并呼吁加大相关技术投资。</p><p></p><p>那么对于程序员，是要确保代码安全还是国家安全？软件安全问题是技术问题还是管理问题？欢迎留言讨论。</p><p></p><p>另外，我们为想要入门的小伙伴准备了一些资料包，可以扫下方二维码领取。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/49/6b/4930bb4b3fce8257a1fb4c96634b676b.png\" /></p><p></p><p>如果想系统地学习 Rust 的朋友，推荐极客时间专栏<a href=\"https://time.geekbang.org/column/intro/100085301?tab=catalog&amp;code=N%2FUP8LPih5X%2F7GCVpSoFKiYOWLgWJ03kV5AxdAw5I6I%3D&amp;utm_term=SPoster\">陈天的 Rust 第一课</a>\"。整个专栏由浅入深，对比多种语言，带你攻克 Rust 编程 10 大难点，有 100+ 原理图，详解 Rust 设计理念。最后通过 4 个项目实操训练，理论与实战两手抓，真正让你掌握 Rust 开发精髓。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/7a/b2/7a875870073fb88d7df197d81c5eb3b2.jpg\" /></p><p></p>",
    "publish_time": "2024-02-29 15:13:56",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "文生视频模型“卷”出新天际；多家手机厂商 AlI in Al，终端AI时代来临？|大模型一周大事",
    "url": "https://www.infoq.cn/article/UXSTNToNDvVlYF0X8wQS",
    "summary": "<p>导语：大模型的快节奏发展，让了解最新技术动态、积极主动学习成为每一位从业者的必修课。InfoQ研究中心期望通过每周更新大模型行业最新动态，为广大读者提供全面的行业回顾和要点分析。现在，让我们回顾过去一周的大模型重大事件吧。</p><p></p><h2>一、重点发现</h2><p></p><p>在过去一周内，OpenAI视频生成产品Sora的发布无疑成为了全球讨论的热点，这标志着人工智能技术在视频生成领域取得了重大突破，它降低了视频制作门槛，促进了内容创作的多样性和便捷性，为未来的视频产业带来了无限可能。中信建投、国泰君安、申万宏源、招商证券等10家券商在研报中均表示Sora是人工智能发展进程的里程碑，这预示AGI（通用人工智能）将加速到来，众多行业将迎来颠覆式变革。</p><p>当然，Sora讨论度爆发的原因是多方面的，在应用潜力方面，传统的内容创作工作流有望被颠覆，生成式AI在视频创作和世界模型的大踏步进步将实现对视频、3D、游戏等下游应用场景的渗透；在技术创新方面，Sora仅根据提示词便可以生成60秒的高清视频；在产品质量方面，Sora&nbsp;创造的视频在时长、画幅选择、场景复杂度以及角色多样性的处理上都表现出了极高的水准；在社会关注度方面，Sora的发布在科技圈内迅速引发了广泛关注与热烈讨论，吸引了众多媒体的争相报道，进而形成了强大的舆论影响力，这无疑进一步推动了公众对Sora的讨论热情。</p><p></p><h2>二、具体内容</h2><p></p><p></p><h3>大模型持续更新</h3><p></p><p></p><h4>多模态领域</h4><p></p><p>1、北京大学、南洋理工大学&nbsp;S-Lab&nbsp;和上海人工智能实验室的研究者提出了一个新的框架&nbsp;LGM（Large&nbsp;Gaussian&nbsp;Model），实现了从单视角图片或文本输入只需&nbsp;5&nbsp;秒钟即可生成高分辨率高质量的三维物体。</p><p>2、谷歌提出了一种具备空间推理能力的视觉语言模型：SpatialVLM，以赋予视觉语言模型空间推理能力。</p><p>3、OpenAI&nbsp;正式发布了文本到视频生成模型&nbsp;Sora，继&nbsp;Runway、Pika、谷歌和&nbsp;Meta&nbsp;之后，OpenAI&nbsp;终于加入视频生成领域的战争。</p><p>4、亚马逊正式推出了语音生成模型&nbsp;BASE&nbsp;TTS。</p><p>5、来自香港中文大学MMLab、Avolution&nbsp;AI、上海人工智能实验室、商汤研究院的研究人员共同提出视频生成模型AnimateLCM-SVD-xt。</p><p>6、阿里巴巴团队推出并开源了一款万能图片生成工作台SCEPTER&nbsp;Studio。不用代码，直接在Web界面当中就能完成模型的训练与微调，并管理相关数据。</p><p>7、字节跳动也推出了一款创新性视频模型——Boximator，可以通过文本精准控制生成视频中人物或物体的动作。</p><p>8、由Stability&nbsp;AI公司开发的新一代AI图像生成器——Stable&nbsp;Diffusion&nbsp;3发布，在文本处理能力、色彩饱和度、图像构图、分辨率、类型、质感、对比度等方面都有了显著的提升。</p><p>9、谷歌正式推出开源大语言模型&nbsp;Gemini&nbsp;Pro&nbsp;1.5，可以实现高达100万个Token（约70万个单词）的超长上下文理解。</p><p></p><h4>开源领域</h4><p></p><p>1、谷歌&nbsp;Gemma&nbsp;系列正式上线，全面对外开放，提供2B（20亿参数）和7B（70亿参数）两种尺寸版本。</p><p>2、法国阿维尼翁大学、南特大学和&nbsp;Zenidoc&nbsp;的研究团队开发了一个专为生物医学领域量身定制的开源模型——BioMistral。</p><p>3、UC&nbsp;伯克利的研究者整理了一个包含各种视频和书籍的大型数据集，并且提出了大世界模型（&nbsp;Large&nbsp;World&nbsp;Model&nbsp;，LWM），同时将其开源。该模型利用&nbsp;RingAttention&nbsp;技术对长序列进行可扩展训练，在大型的多样化视频和图书数据集上进行训练，实现了对语言、图像和视频的理解与生成能力。</p><p></p><h4>科研领域</h4><p></p><p>1、前Google&nbsp;DeepMind科学家联手创建Biooptimus，旨在构建首个通用生物学AI模型。</p><p>2、Iambic、英伟达、加州理工学院开发多尺度深度生成模型NeuralPLexer，可以仅使用蛋白质序列和配体分子图输入直接预测蛋白质-配体复合物结构。</p><p></p><h3>基础设施/工具</h3><p></p><p>1、微软发布了一份特定领域大模型应用建设流程指南，该指南提出了一个全面的大语言模型流程，用于生成高质量的、行业特定的问题和答案。该方法包含一个系统化的过程，包括鉴别和收集涵盖广泛农业主题的相关文档，然后清理和结构化这些文档，以便使用基本的&nbsp;GPT&nbsp;模型生成有意义的问答对。生成的问答对随后根据其质量进行评估和筛选。</p><p>2、Hugging&nbsp;Face&nbsp;上的一篇博客介绍了一种可配置稀疏混合专家架构语言模型（MoE）实施方法，并且给出了基于&nbsp;PyTorch&nbsp;的详细代码，也许有助于打算在这个方向深耕的研究者们快速试验自己的新方法。</p><p>3、谷歌TPU创业团队，名为&nbsp;Groq&nbsp;的初创公司开发出一种机器学习处理器（大模型专用芯片），据称在大语言模型任务上彻底击败了&nbsp;GPU——&nbsp;比英伟达的&nbsp;GPU&nbsp;快&nbsp;10&nbsp;倍，而成本仅为&nbsp;GPU&nbsp;的&nbsp;10%，只需要十分之一的电力。</p><p>4、Hugging&nbsp;Face&nbsp;开源&nbsp;Al&nbsp;训练合成数据集&nbsp;Cosmopedia，该数据集内容均由&nbsp;Mixtral&nbsp;7b&nbsp;模型汇总生成，收录了&nbsp;3000&nbsp;万以上文本文件，包含大量教科书、博客文章、故事小说、WikiHow&nbsp;教程等内容，共计&nbsp;250&nbsp;亿个&nbsp;Token。</p><p>5、社交平台&nbsp;Reddit&nbsp;将授权数据给谷歌训练&nbsp;AI，合同价值约每年&nbsp;6000&nbsp;万美元。</p><p></p><h3>应用探索</h3><p></p><p></p><h4>智能体</h4><p></p><p>1、吉林大学人工智能学院发布了一项利用视觉大语言模型直接控制电脑&nbsp;GUI&nbsp;的最新研究—《ScreenAgent:&nbsp;A&nbsp;Vision&nbsp;Language&nbsp;Model-driven&nbsp;Computer&nbsp;Control&nbsp;Agent》，该工作提出了ScreenAgent&nbsp;模型，首次探索在无需辅助定位标签的情况下，利用&nbsp;VLM&nbsp;Agent&nbsp;直接控制电脑鼠标和键盘，实现大模型直接操作电脑的目标。</p><p></p><h4>终端AI</h4><p></p><p>1、2024年2月20日，OPPO在深圳举办AI战略发布会，发布由OPPO&nbsp;AI超级智能体和AI&nbsp;Pro&nbsp;智能体开发平台组成的OPPO&nbsp;1+N&nbsp;智能体生态战略，官宣与超千万用户共同迈进AI手机时代，加速手机行业迈向AI的全新阶段。</p><p>2、2024年2月18日，国产手机品牌魅族宣布进行&nbsp;Al&nbsp;in&nbsp;Al&nbsp;战略调整，将停止传统“智能手机”新项目的开发，全力投入新一代AI设备。</p><p>3、微软&nbsp;AI&nbsp;PC&nbsp;将在今年完成首秀。供应链指出，微软将于&nbsp;2024&nbsp;年中旬，先推以&nbsp;AI&nbsp;PC&nbsp;为主的&nbsp;Windows&nbsp;11&nbsp;更新版，并将与高通在&nbsp;Windows&nbsp;on&nbsp;ARM&nbsp;及英特尔的&nbsp;x86&nbsp;系统整合，在&nbsp;2024&nbsp;年台北国际电脑展&nbsp;（Computex）亮相。</p><p></p><p>除了每周的动态更新，InfoQ研究中心也将以季度为周期，发布《大模型季度监测报告》，跟踪大模型行业的最新动态和相关产品测试。</p><p>第一期《大模型季度监测报告23Q4》预计将于2024年3月底正式发布，届时还将发布文生图产品大测评。本次文生图产品测评将基于实体对象、风格能力、细节难点、价值观和中文特色五大维度展开。如您期望&nbsp;InfoQ&nbsp;对旗下产品进行测试，或想要参与报告内容共建，欢迎联系微信：Bettycbj1996（添加好友请注明来意）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c9/c9a22a592a78db5dca8de0da2833e1db.png\" /></p><p></p>",
    "publish_time": "2024-02-29 16:07:40",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AI芯片的未来：领导者、黑马和后起之秀",
    "url": "https://www.infoq.cn/article/0yeegtv0VYfQOewlXlTa",
    "summary": "<p>随着人工智能（AI）在企业运营中的核心<a href=\"https://dzone.com/articles/the-future-of-ai-chips-leaders-dark-horses-and-risnAI\">作用日益凸显</a>\"，越来越多的企业开始将目光投向这一前沿技术，准备投入巨资以获取竞争优势。AI 芯片则成为推动这一切的关键。尽管过去 AI 芯片在一定程度上被忽视，但最近，OpenAI 的 Sam Altman 宣称，他计划筹集高达 7 万亿美元的资金，用于支持一项 “野心勃勃” 的科技项目，旨在大幅提升全球芯片产能。抛开地缘政治等因素不谈，关注 AI 芯片意味着要了解今天的挑战和明天的机遇。</p><p>&nbsp;</p><p>根据 IMARC 最近的<a href=\"https://www.linkedin.com/pulse/breakthrough-ai-chip-technology-china-unveils-worlds-first-5s2kc/\">一项研究</a>\"，到 2029 年，全球人工智能芯片市场预计将达到 8960 亿美元。这一预测基于多个因素，包括人工智能技术的持续进步、消费电子产品对 AI 芯片需求的不断增长，以及 AI 芯片领域的创新活动日益活跃。</p><p>&nbsp;</p><p>在 AI 硬件领域，拥有丰富经验和深刻见解的专家并不多见，<a href=\"https://awavesemi.com/interview-with-alphawave-ceo-tony-pialis/\">Alphawave 的首席执行官兼联合创始人 Tony Pialis</a>\" 正是其中之一。在一次对话中，Pialis 分享了他对 AI 芯片领域的独到观点，其中涉及芯片技术的变革性发展、专用于训练和推理的硬件创新，以及模拟和光学计算等新兴方向的前景。</p><p>&nbsp;</p><p>在半导体创业领域，Tony Pialis 的名字堪称传奇。他先后创立并成功出售了两家初创公司：Snowbush Microelectronics 和 V Semiconductor Inc。其中，V Semiconductor 在 2012 年被英特尔收购，Pialis 在此期间担任了模拟和混合信号 IP 的副总裁。</p><p>&nbsp;</p><p>2017 年，Pialis 与合作伙伴共同创立了 AlphaWave，目标直指 “下一个伟大的半导体公司”。Alphawave 于 2021 年上市，市值达到 45 亿美元。该公司的核心产品包括硅 IP、芯片、定制硅和高速互连技术，专为谷歌、微软、亚马逊和 Meta 等主要超级扩展客户量身定制。</p><p>&nbsp;</p><p>Alphawave 之所以能成为人工智能领域的幕后推手，背后离不开 Pialias 的前瞻性思考。他敏锐地观察到，如今推动数据中心和计算扩展的主要力量已不再是传统的网络设备供应商如思科，而是转向了谷歌、微软、亚马逊和 Meta 等超级扩展器。这些科技巨头不仅具备强大的内部设计能力，还自主构建服务器、网络、数据中心和校园基础设施。</p><p>&nbsp;</p><p>在 Pialias 看来，人工智能发展的主要挑战并非计算本身。实际上，设计和实现计算的能力早已成熟。真正的挑战在于如何处理海量数据所需的连接技术。而这正是 AlphaWave 所专注的领域。</p><p></p><h2>专用人工智能硬件的爆炸性增长&nbsp;</h2><p></p><p>&nbsp;</p><p>虽然像 ChatGPT 这样的消费者应用在 2023 年初引发了热潮，但有关企业采用的报告却褒贬不一。然而，据 Pialis 称，AI 半导体行业在 2023 年下半年在各行各业和地理位置都出现了巨大的投资和新的设计。</p><p>&nbsp;</p><p>Pialis 指出，美国、加拿大、英国、法国、德国、韩国和日本等国家纷纷提出了建立国内 AI 芯片能力的主要国家倡议。这些国家长期以来依赖于 NVIDIA 等供应商，但现在各国政府正努力培育本土芯片产业，以减少对单一供应商的战略依赖。尽管 NVIDIA 首席执行官 Jensen Huang 也强调每个国家都需要主权 AI，但这似乎不包括硬件层面。</p><p>&nbsp;</p><p>Pialis 认为，这种激增的需求不仅促进了初创企业的兴起，还推动了科技巨头开发专门的训练和推理硬件。在他看来，虽然并非每个组织都能或应该开发自己的 AI 模型，但这种情况注定会发生变化。</p><p>&nbsp;</p><p></p><blockquote>Pialis 预测：“随着时间的推移，AI 将不可避免地发展成为类似公用事业的东西，超级扩展器将提供所有计算能力的访问权，就像电力一样。我认为这将是价格合理的。任何人都将能够使用这种公用事业来训练、开发、优化和部署他们自己的模型。”&nbsp;然而，他也承认，在达到这一状态之前，还有很多收益可以获取，而最终实现这种状态所需的时间仍充满不确定性。</blockquote><p></p><p></p><h2>人工智能芯片竞赛中的参与者</h2><p></p><p>&nbsp;</p><p>在 AI 加速器领域，NVIDIA 无疑是当前的领军者，这一点得到了包括 Pialis 在内的业界人士的广泛认可。同时，AMD 也被视为有力的竞争者，其 CEO Lisa Su 的领导能力受到了赞誉。此外，还有如 Ben Lorica 等行业观察者<a href=\"https://gradientflow.substack.com/p/favorable-winds-for-amd-in-the-genai\">看好 AMD 在 GenAI 芯片市场上的潜力</a>\"。</p><p>&nbsp;</p><p>然而，Pialias 警告称，不应忽视英特尔在这个领域中的潜力。他特别提到，由 <a href=\"https://linkeddataorchestration.com/2019/12/18/deep-learning-software-vs-hardware-nvidia-releases-tensorrt-7-inference-software-intel-acquires-habana-labs/\">David Dahan 领导的英特尔 Habana 收购部门</a>\"是该领域的一匹黑马，具有强大的实力。作为曾在英特尔工作过的人，Pialis 对 Habana 的工作给予了高度评价。</p><p>&nbsp;</p><p>通过报道 Habana、与 Dahan 见面并追踪他们的 MLPerf 结果，我们倾向于同意这一观点。Dahan 帮助设计了新的英特尔处理器，在关键基准测试中展现出了超越 NVIDIA 最新 GPU 的性能。</p><p>&nbsp;</p><p>尽管性能至关重要，但 Pialias 也指出，NVIDIA 在 AI 芯片领域的软件平台，包括 CUDA，为其带来了巨大的竞争优势。生态系统效应显著，众多工程师和研究人员为 NVIDIA 的架构开发了优化的框架和模型。</p><p>&nbsp;</p><p>然而，这并不意味着没有替代的可能性。Pialis 认为，<a href=\"http://gradientflow.substack.com/p/favorable-winds-for-amd-in-the-genai\">借鉴 AMD 的经验</a>\"，AI 硬件公司需要配备足够的软件工程师来支持硬件工程师的工作。尽管目前关于 NVIDIA 和硬件的讨论很多，但实际上，大部分的投资都集中在软件上。</p><p>&nbsp;</p><p>这一点得到了 NVIDIA 的 Dave Salvator 的证实。在 <a href=\"https://linkeddataorchestration.com/2023/11/09/ai-chips-in-2024-nvidia-mlperf-benchmarks-huangs-law-and-competition/\">2023 年最后一次 MLPerf 结果简报会</a>\"上，Salvator 表示，NVIDIA 拥有两倍于硬件工程师数量的软件工程师。他强调，这并非偶然，而是公司战略的重要组成部分。</p><p>&nbsp;</p><p>Pialis 认为，在<a href=\"https://gradientflow.com/beyond-nvidia-exploring-new-horizons-in-llm-inference/\">推理加速器市场</a>\"上，挑战者具有更大的潜力，因为该领域的标准仍在形成中。例如，OctoML 的 Luis Ceze <a href=\"https://www.linkedin.com/feed/update/urn%3Ali%3Aactivity%3A7145605517464252416/\">分享</a>\"了 <a href=\"https://docs.vllm.ai/en/latest/\">vLLM</a>\"、<a href=\"https://llm.mlc.ai/\">MLC-LLM</a>\"、<a href=\"https://github.com/predibase/lorax\">LoRAX</a>\" 和 <a href=\"https://github.com/punica-ai/punica\">Punica</a>\" 等创新解决方案，这些方案分别针对 LLM 服务、便携式部署、多路复用微调模型推理等不同需求。事实上，推理市场的规模比训练市场更为庞大，正如 Pialis 所指出的那样。</p><p>&nbsp;</p><p>“人们往往更关注训练、大模型和训练成本，但我们都在推理端受益。这需要大规模部署，需要多样化的解决方案。推理端将销售更多的芯片，我相信随着销量的增加，商业计划也会得到相应的改善。”Pialis 说道。</p><p>&nbsp;</p><p>初创公司如 <a href=\"https://wow.groq.com/world-meet-groq-2/\">Groq</a>\" 和 <a href=\"https://tenstorrent.com/\">Tenstorrent</a>\" 正在吸引大量资金，而来自英国、韩国和中国等国家的公司也在努力减少对美国公司的依赖。在超级扩展器方面，Pialis 认为亚马逊和谷歌处于领先地位，微软展现出强劲的发展势头，而 Meta 则稍显落后，甚至有传言称他们可能会收购一家较小的初创公司来增强自身实力。</p><p></p><h2>芯片组件引领技术革命</h2><p></p><p>&nbsp;</p><p>据 Pialis 所述，半导体行业正经历一场重大变革，即向<a href=\"https://www.technologyreview.com/2024/01/08/1085120/chiplets-moores-law-avanced-micro-devices-intel-chips-breakthrough-technologies/\">芯片组件</a>\"的转变。过去，技术进步的标志是将更多功能集成到单一芯片中。然而，随着晶体管尺寸缩小至约 5 个原子宽度，即便是微小的缺陷也可能导致整个芯片失效。</p><p>&nbsp;</p><p>Pialis 通过自身经历进一步阐释了这一点。他提到，在某次访问 OpenAI 时，目睹了一群工程师跪在服务器前祈祷。他们的担忧并非源于 “<a href=\"https://futurism.com/openai-employees-say-firms-chief-scientist-has-been-making-strange-spiritual-claims\">对通用人工智能的敬畏</a>\"”，而是害怕训练的模型因芯片缺陷而崩溃。</p><p>&nbsp;</p><p>芯片组件在中美贸易战的背景下备受关注，成为两国科技战略的核心组成部分。对于<a href=\"https://www.reuters.com/technology/chip-wars-how-chiplets-are-emerging-core-part-chinas-tech-strategy-2023-07-13/\">中国</a>\"和<a href=\"https://www.nytimes.com/2023/05/11/technology/us-chiplets-tech.html\">美国</a>\"而言，芯片组件不仅是技术进步的象征，更是维护国家科技竞争力的关键。</p><p>&nbsp;</p><p></p><blockquote>Pialis 认为，“芯片组件是对抗技术极限的又一次革命性创新。”&nbsp;</blockquote><p></p><p>&nbsp;</p><p>这些挑战并非源于超自然力量，而是由纳米尺度下物理定律的复杂性所引发。</p><p>&nbsp;</p><p>Pialis 解释道：“当我们制造晶体管 —— 集成电路的基本构件时，实际上是在操控原子。随着原子数量的减少，从数百个到仅两个，概率和平均法则不再适用。因此，我们更容易遇到缺陷问题。”</p><p>&nbsp;</p><p>为了克服这些纳米尺度带来的物理挑战，芯片组件作为一种创新解决方案应运而生。这种设计方法将传统的单一大芯片拆分为更小的、类似乐高积木的芯片组件，并通过先进的封装技术将它们连接起来。这种模块化设计允许制造商避免因单个组件的缺陷而废弃整个设备，从而显著提高了生产效率。Pialis 表示，这种好处对制造商和买家都很重要。</p><p>&nbsp;</p><p>Pialis 强调：“在这一变革中，硅的角色正在发生转变。它不再是领先半导体的核心，而是成为了封装技术中的一个组件。当前，关于半导体供应链的讨论如火如荼，硅的产能充足。然而，在封装方面，特别是利用芯片组件构建的设计方面，产能仍然捉襟见肘。”</p><p></p><h2>芯片组件作为乐高积木般的构建块</h2><p></p><p>&nbsp;</p><p>在众多 AI 硬件公司中，Cerebras 以其独特的晶圆级硬件设计脱颖而出。尽管 Pialis 认为 Cerebras 同样会面临纳米尺度上的物理挑战和缺陷问题，但他也指出，Cerebras 的方法在于其冗余性设计。</p><p>&nbsp;</p><p>在 Cerebras 的方案中，晶圆被视为一个整体面板，而不是被切割成单独的芯片。这意味着芯片之间的连接和交互在晶圆级别上得以实现，从而通过软件处理潜在的缺陷。这种方法的独特之处在于，它摒弃了传统的封装方式，而是将多个芯片在晶圆上直接连接。</p><p>&nbsp;</p><p>然而，Pialias 也强调了切割芯片的优势。对于像英特尔这样的供应商来说，通过将硬件拆分成更小的部件，如 CPU、GPU、DPU 或网络设备，这些部件就像乐高积木一样，可以根据不同的需求进行组合和配置。</p><p>&nbsp;</p><p>因此，你可以有一个处理器核心芯片组件，一个 PCI Express 连接性芯片组件，一个以太网网络芯片组件，一个 DDR 内存 I/O 芯片组件，一个内存 I/O 芯片组件。这些芯片组件可以混合搭配在一个封装中，构建出整个产品系列。Pialis 认为，从设计复杂性和前期投资的角度来看，这是一个成功的方案。</p><p>&nbsp;</p><p>据 Pialis 估计，采用芯片组件的方法可以将成本降低 60% 以上，功耗降低 40%。这对于超大规模数据中心来说是一个巨大的激励因素。尽管目前苹果、AMD 和英特尔等公司在芯片组件领域处于领先地位，但 Pialias 认为，随着技术的不断进步和市场的竞争加剧，芯片组件将成为任何专注于领先硬件的公司的必备条件。</p><p></p><h2>软件与芯片组件模块化、组合和可编程性</h2><p></p><p>&nbsp;</p><p>在软件工程中，模块化已成为一种标准的构建方式，这不禁让人思考，为何芯片组件的模块化概念没有早些时候在硬件领域得到普及。历史上，硬件领域的胜利者往往是那些能将最多功能集成到单片式设备中的厂商。</p><p>&nbsp;</p><p>Pialis 指出，这背后的主要原因是成本考量。单片集成降低了制造成本，因此 “对集成的狂热关注” 成为了行业主流。然而，随着技术接近原子尺度，制造成本开始超过集成成本，这一传统观念开始受到挑战。</p><p>&nbsp;</p><p>与此同时，软件领域也面临着<a href=\"https://www.theserverside.com/answer/What-are-some-of-the-disadvantages-of-microservices\">过度模块化可能带来的过度开销问题</a>\"。</p><p>&nbsp;</p><p>Pialis 预计，一些硬件供应商可能会过度采用芯片组件的方法。如果功能被过度分解为微小的部分，整合这些部分的成本可能会受到限制。因此，他认为最终将是一种混合方法获得胜利。使用芯片组件进行分解有两种主要方式。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/09/0944503a65ae57bf9fa9b15a801708b2.jpeg\" /></p><p>&nbsp;</p><p>构建芯片组件的第一种方式是构建一种标准的、可镜像的芯片组件，这些组件具有相同的功能，并通过软件实现互相通信。这种方式在某种程度上与传统的硬件集成方法相似。然而，如何将这些相同的芯片组件积木组合在一起，则依赖于软件的设计和实现。</p><p>&nbsp;</p><p>可以根据相同的芯片组件，使用软件为不同的需求组合不同的封装。例如，1、2、4 或 8 个芯片组件的多重。相同的硅，只是以不同的方式封装，价格不同，并且具有不同的软件来利用与这些设备相关的递增计算和内存带宽。</p><p>&nbsp;</p><p>另一种构建芯片组件的方法是通过分割和切割，为不同类型的功能创建专门的芯片组件，类似于乐高积木。这可以创建出如计算芯片组件、训练 I/O 芯片组件、网络 I/O 芯片组件等多样化的构建块。Pialias 认为，这种方法背后的推动力更大，因为它不仅可以降低制造成本，还可以通过重用这些乐高积木来加速其他产品的开发。</p><p></p><h2>模拟人工智能、光学计算和人工智能辅助硬件设计</h2><p></p><p>&nbsp;</p><p>在当前以 GPU 等数字加速器为主导的时代，尽管芯片组件提供了一种即时的前进方法，但 Pialias 强调，仍有其他根本性的技术分歧值得探索。</p><p>&nbsp;</p><p>人工智能的核心在于大规模并行的算术处理，其中二进制计算是主导方法。在二进制体系中，数字被简化为 1 和 0，而浮点算术则依赖于精度和范围的设定。</p><p>&nbsp;</p><p>然而，模拟算术处理提供了一种不同的视角。在这种方法中，浮点数可以通过电压或电流来表示，理论上具有无限的精度。尽管在现实世界的噪声干扰下，这种方法的精度可能会受限，但对于<a href=\"https://linkeddataorchestration.com/2021/06/07/machine-learning-at-the-edge-tinyml-is-getting-big/\">边缘人工智能</a>\"应用来说，它可能是一种有效的解决方案。微小电流的利用使得设备能够在低功耗状态下运行。</p><p>&nbsp;</p><p>还有另一种形式的计算，一些公司正在投资其中：光学计算也为算术运算带来了新的可能性。光学计算利用光学特性实现 <a href=\"https://en.wikipedia.org/wiki/Multiply%E2%80%93accumulate_operation\">MAC</a>\"（乘积累加功能），这是任何算术单元的核心。这种方法有望降低功耗要求。</p><p>&nbsp;</p><p>Pialias 指出，模拟和光学计算正在吸引数十亿美元的投资，以满足在计算规模、能源效率和精度方面的专业需求。然而，目前尚不清楚模拟技术是否能够有效地扩展，以匹配数字计算在尖端人工智能模型中的应用。这一问题在硬件界引发了激烈的辩论。</p><p>&nbsp;</p><p>此外，<a href=\"https://www.wsj.com/articles/in-race-for-ai-chips-google-deepmind-uses-ai-to-design-specialized-semiconductors-dcd78967\">利用人工智能来设计用于驱动人工智能的硬件</a>\"也成为一个新兴议题。Pialias 表示，如今最有效的硬件设计者往往是那些具备丰富软件开发经验的专家。如果能够将他们的经验融入人工智能模型的训练中，可能会引发硬件设计领域的彻底变革。</p><p>&nbsp;</p><p>虽然未来的道路充满挑战和不确定性，但 Pialias 坚信工程的基本原则是永恒的。我们期待这些新兴技术能够在不耗尽世界能源和资源的前提下，为人工智能和计算技术的发展带来新的突破。</p><p>&nbsp;</p><p>作者简介：</p><p>&nbsp;</p><p>George Anadiotis 在信息技术领域拥有丰富的经验。他的职业生涯涵盖了分析师、顾问、工程师、创始人和研究员等多个角色。目前在 Linked Data Orchestration 担任研究员和作家。George 在成为“一人乐队”和“乐队指挥”的过程中，有机会学习和掌握了许多技能。他曾在 Gigaom 担任分析师，为财富 500 强企业、初创公司和非政府组织提供咨询服务，负责建设和管理各种规模和形式的项目、产品和团队。George 热衷于研究、开发、应用和讨论前沿概念和技术。是企业应用集成和大规模数据集成领域的先驱之一。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://dzone.com/articles/the-future-of-ai-chips-leaders-dark-horses-and-ris\">https://dzone.com/articles/the-future-of-ai-chips-leaders-dark-horses-and-ris</a>\"</p>",
    "publish_time": "2024-02-29 18:26:16",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]