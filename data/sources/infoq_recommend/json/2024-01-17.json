[
  {
    "title": "“向量数据库”还是“向量搜索插件 + SQL 数据库”？PingCAP 黄东旭：我对 2024 年数据库发展趋势的思考",
    "url": "https://www.infoq.cn/article/svZdfhLYsZrv45RWs5kw",
    "summary": "<p>如果我们用一个词来总结 2023 年的数据技术领域，那个词无疑是“急速变革”。我们见证了数据库内核技术与云原生架构的融合演进，AI+Data 的浪潮涌现，以及用户工作负载的深刻转变。GenAI 时代的到来，就像一股不可抗拒的潮流，推动着数据技术的每一朵浪花，朝着更智能化、更灵活化的巨浪之海奔流。</p><p></p><p>2023 年，我们的眼前充满了夺目的 AI Demo 与炫技，你追我赶。转眼间，当我们步入 2024 年，这个年份将因为 “AI 在从 Demo 到真实场景落地”的急剧转变而被人们记住。随着开源大模型成本的加速下降，企业和开发者对数据的关注也急剧上升，对数据的关注度将很快取代对模型的关注度。有预测认为，在 2023 年，用户愿意在 AI 模型上投入 80% 的预算，然而在未来这一两年里，随着模型成本的降低，这一比重可能会逆转，用户将更多的投资（甚至大于 80%）倾向于数据，数据处理和分析能力变得更加重要。</p><p></p><p>毫无疑问，AI 将会对数据处理提出非常多新的诉求，数据技术领域也会面临着多重挑战与机遇，AI 正在重塑数据技术的全新生态。我们不禁要问：在 GenAI 的大潮中，选择 “向量数据库”还是“以 SQL 数据库作为核心，添加向量搜索插件”？数据库如何应对 Gen AI 对数据库扩展性和实时交互的诉求？浪涌般海量数据的实时查询会不会带来巨大的成本压力？AI 带来的自然交互方式催生怎样的开发者体验 ？这些问题将在本文中一一解答</p><p></p><h2>预测一</h2><p></p><p></p><p>“向量数据库”还是“向量搜索插件 + SQL 数据库”？这是一个答案很明确的问题。</p><p></p><p>如果说过去 CRUD 应用是对数据库访问的静态封装，那么随着 GenAI 的普及，尤其是 Chatbot 或 Agent 的产品形态，对数据的使用会是更加灵活和动态的。过去，集中的数据存储和应用是因为技术的局限，很难为个人提供个性化的服务，尽管现代的 SaaS 其实很希望往这个方向发展，但是为每个用户都提供个性化的体验对算力和开发的挑战太高，而 GenAI 和 LLM 将提供个性化服务的成本降得很低（可能就是几段 Prompt），以至于对于数据库而言，带来几个变化：</p><p></p><p>个人（或一个组织）产生的数据价值会变得越来越高，但这类数据通常不会很大GenAI 会使用更加动态和灵活的方式直接访问数据，这样效率最高对数据的访问从边缘发起（从 Agent 或者 GenAI 直接发起）</p><p></p><p>一个很好的例子是 GPTs， GPTs 支持通过的自定义的 Prompt 和用户提供的 RESTful API 来创建自己的 ChatGPT，基础的 ChatGPT 会在它认为需要的时候以灵活的方式调用你给定的 Action。这个调用发生方式和参数是后端的 Action 提供者无法预料的。而且可以预料的是很快 GPTs 将会提供标记个人身份信息的机制，这样对于 Action 的提供者来说，相当于后端的数据库有了最重要的索引：UserID，剩下的就很好理解了。</p><p></p><p>这里你可能会提出质疑，RAG 不是标准的做法吗？但现有的 RAG 构建的方式几乎都是静态的，而知识应该是可以实时被更新的，这里不得不提到向量数据库。</p><p></p><p>对向量的支持，在去年是数据库迭代的一个热门方向，产生了很多专门的向量数据库， 但是我认为，更丰富的数据访问接口，使得向量搜索成为标配，然而 SQL 仍然是基石。向量搜索并不值得专门使用一个独立的数据库来支持，更应该是现有的数据库中的一个功能，就像：</p><p></p><p><code lang=\"sql\">Plaintext\nRust   INSERT INTO tbl (user_id, vec, ...) VALUES (xxx, [f32, f32, \nf32 ...], ...);   SELECT * FROM tbl WHERE user_id = xxx and \nvector_search([f32,f32,f32,f32 ...])\n</code></p><p></p><p>类似的访问可能是更符合开发者直觉的。</p><p></p><p>而关系型数据库天然支持插入和更新，另外配合向量索引的搜索能力，便可以将 RAG 变成一个可以实时更新实时查找的正反馈循环（利用 LLM 引入进行二次的 Summary ，然后将更新的 Index 储存在 DB 中）。更重要的是，关系型数据库的引入消除了向量数据库带来的数据孤岛的问题，当你可以将向量索引筛出来的数据关联（JOIN）到同一个 DB 中其他的数据的时候，灵活性带来的价值就得以显现。</p><p></p><p>另一个好处是，Serverless 的产品形态，同样也将数据的所有权归还给用户本人，大家思考一下，在我们熟知的 Web2 时代，我们的数据是隐藏在一个个互联网公司的服务背后的黑箱，我们没有办法直接访问；而在 GenAI 的应用场景下，数据的交互变成一个三角的关系，用户 - 数据 (RAG) - GenAI。很有意思的是，这个正是 Web3 的理想之一，GenAI 的普及很可能顺手也将 Web3 想实现的将数据的所有权交还给用户的理想，这在 Web2 时代是不可能实现的，这其实是一种技术理想的回归。</p><p></p><p>当然，我相信在未来 RAG 会成为数据库的很重要的一种新应用场景，在这种场景中 Serverless 形态提供的云数据库服务会变成标准化的。</p><p></p><h2>预测二</h2><p></p><p></p><p>由高价值数据驱动的应用成为 GenAI 应用的主流，弹性与实时交互成为数据库能力的基石。</p><p></p><p>在预测一里我们提到， GenAI 时代的应用要求知识和数据是可以被实时更新的，这对数据库的弹性以及实时交互提出了非常直接的需求。</p><p></p><p>数据库的可扩展性一直是过去十年间，业界关注的重点之一。根据我们的观察，大多数单一在线业务，100TB 已经是很大规模，而这个规模下的一般 OLTP 业务，已经可以被市场上很多系统自信的解决。</p><p></p><p>但这些数据库大多是 Shared Nothing 的系统，Shared nothing 的系统通常会有一个假设：在集群中的节点是对等的，只有这样数据和 Workload 才能均匀的分散在各个节点上。这个假设对于海量数据 + 访问模式均匀的场景没有问题，但是仍然有很多的业务具有明显的冷热特征，尤其是在 GenAI 带来的数据访问方式越来越动态和灵活的 2024 年及以后。</p><p></p><p>我们最经常处理的数据库问题之一就是局部热点。如果数据访问倾斜是一个业务的天然属性的话，对等的假设就不再是合理的，更合理的方式是将更好的硬件资源倾斜给热点的数据，而冷数据库使用更廉价的存储，例如，TiDB 从一开始将存储节点（TiKV）/ 计算节点（TiDB）/ 元信息（PD）分离，以及在后来 TiDB 5.0 中引入自定义 Placement Rule 让用户能够尽可能决定数据摆放策略，就是为了尽可能弱化节点对等假设。</p><p></p><p>但是更终极的解决办法在云端，在基本的扩展性问题得到解决后，人们开始追求更高的资源利用效率，在这个阶段，对于 OLTP 业务来说，我想可能更好的评价标准是 Cost Per Request。因为在云端，计算和存储的成本差别是巨大的，对于冷数据来说，如果没有 Traffic，你甚至可以认为成本几乎为 0，但是计算却是昂贵的，而在线服务不可避免的需要计算（CPU 资源），所以高效利用计算资源，云提供弹性将成为关键。</p><p></p><p>另外，请不要误解 ，弹性并不意味着便宜，on-demand（ 随需提供的 ）的资源在云上通常比 provisioned（预分配）的资源更贵，持续的 burst 一定是不划算的，这种时候使用预留资源更合适，burst 那部分的成本是用户为不确定性支付的费用。仔细思考这个过程，这可能会是未来云上数据库的一种盈利模式，</p><p></p><p>与弹性同样重要的需求就是实时交互。GenAI 时代的应用需要数据库不仅要有强大的数据处理能力，还需要有高效的实时数据广播和同步机制。这不只是让数据能够实时更新，而是确保数据流能够实时流动，让数据库能即时捕捉到每一次交互，每一个查询，确保每一个决策都是基于最新、最准确的信息。（就是用户愿意为更高价值的实时交互付钱，想想股票实时交易和直播电商的场景就知道了）</p><p></p><p>于是整个系统——从数据的产生到处理、再到存储和检索——都必须要在实时的框架下工作，能够在毫秒级别做出实时响应，这也需要数据库能实时在事务处理（OLTP）和分析处理（OLAP）之间无缝同步。这样的实时交互能力，将会是现代数据库区别于传统数据库的决定性因素之一。</p><p></p><h2>预测三</h2><p></p><p></p><p>成本分析已经成为所有人关心的问题，在云数据库的可观测性中成为独立新视角。</p><p></p><p>今天我还想谈的一点是云数据库的可观测性，尤其是它是否能让我的云消费更透明。对于数据库云服务来说，可观测性的要求会更高，因为对于开发者来说，服务商提供的 Dashboard 几乎是唯一的诊断手段。介绍可观测性的文章也很多，相似的部分因为篇幅关系我也不打算说太多。</p><p></p><p>与传统的可观测性不一样的是：在云上，一切 Workload 都会成为客户的帐单的一部分。对于用户来说一个新的问题便是：为什么我的帐单看起来是这样？我需要做什么才能让我的帐单更便宜？账单的可解释性做得越好，用户体验也就越好。</p><p></p><p>但是如果计费测量的粒度过细，也会影响产品本身的性能以及增加实现的成本。这里面需要平衡。但可以确定的是，在思考可观测性产品的方向上，成本分析可以作为一个独立的新视角。</p><p></p><p>成本分析可以帮助用户发现系统运行中的潜在问题，并采取措施予以优化。例如，如果用户观测到某个数据库实例的 CPU 使用率较低，但成本却很高，就可以考虑将该实例的规格调整为更低的级别。</p><p></p><p>AWS 今年发布的 Cost and Usage Dashboard 和 Reinvent 上 Amazon CTO Dr. Werner 的演讲专注于成本的架构艺术也同样可以看到这个趋势。他提出了 “俭约架构” 七大法则来在云的环境中打造更加高效、可持续的系统，为我们提供了一个系统性的指导框架。</p><p></p><h2>预测四</h2><p></p><p></p><p>当 GenAI 时代的各种应用和工具变得越来越轻巧，开发者体验将成为现代数据库设计的核心目标之一。</p><p></p><p>数据库平台化不仅仅是漂亮的 Web 管控界面以及一些花哨的功能堆砌。我很喜欢 PlanetScale 的 CEO Sam Lambert 在他的个人 Blog 里面关 Develop Experience 的描述他引用了乔布斯的一句话“Great art stretches taste, it doesn’t follow tastes（ 伟大的艺术拓展审美边界，而不是刻意迎合。）”。</p><p></p><p>好用的工具之所以好用，是因为其中是饱含了设计者的巧思和品味，而且这个设计者也必须是重度的使用者，这样人们才能体会到那些细微的快乐与痛苦，但是又不至于沉浸其中使其盲目，其实这对负责开发者体验的产品经理来说是极高的要求。</p><p></p><p>数据库管理工具作为一种频率不算高频、但每次使用都很严肃的工具，在 AI 和云的时代，我认为有一些与体验紧密相关的设计原则是需要遵守的：</p><p></p><p>API First, 数据库平台应该提供稳定的 / 前向兼容的 API，一切在管控平台里能干的事情，API 都要能做到，最好你的管控平台是基于你的 API 构造的。这为你提供一个功能齐备的好用的 CLI Tool 也是关键的必要条件。</p><p></p><p>使用统一的认证体系，在设计阶段将管控的认证和用户体系与数据库内部的认证体系打通，传统的数据库基于用户名和密码的权限体系在云的时代是不够的。这为了后续与云的 IAM 和 Secret 管理体系对接打下基础。</p><p></p><p>对不同的功能构建不同的 / 稳定的小工具 (Do one thing, do things well)，但是通过一个统一的 CLI 入口和语义系统进行调用。比较好的例子是 rustup, 甚至 git 也是个很好的例子。</p><p></p><p>稍微总结一下，2024 年，数据和数据库技术仍然处于巨大的变革期，谁也没办法预测未来，因为我们就身处这么一个不确定性巨大的时代。但好的一面是，创新仍然层出不穷。我今天预测的，很可能过几个月就会被我自己全部推翻，也是很正常的事情，如果能给当下的你有所启发，那就够了。</p><p></p>",
    "publish_time": "2024-01-17 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "采用开源工具：善意推定，但也要做好沟通",
    "url": "https://www.infoq.cn/article/oXERXq10Udg15F0S4Q7o",
    "summary": "<p>按照 Hila Fish 的说法，开源项目的好处是支持快速创新，让我们可以灵活地定制和调整工具，而且代码是透明的，有利于增强安全性。其缺点是通过隐匿实现安全的策略就行不通了，开源很容易被滥用，并且当开源工具没有公司支持时，可能会导致可维护性降低。</p><p></p><p>在 DEV: Challenge Accepted 2023 大会上，Hila Fish 谈了从 DevOps 视角看开源项目。</p><p></p><p>Fish 说，由于开源项目的开放性，它们的创新速度往往比较快。DevOps 团队可以利用这个快速的创新周期，采用新技术和实践来改进他们的流程。Fish 提到了持续集成、持续交付（CI/CD）、容器化和基础设施即代码（IaC）等领域。在这些领域，开源工具和解决方案推动了 DevOps 的创新。</p><p></p><p>DevOps 的核心原则之一是能够根据组织的独特需求来定制流程和工具，Fish 解释道：</p><p></p><p></p><blockquote>开源软件提供了定制和调整工具以适应特定工作流和需求所需的灵活性。她补充说，DevOps 团队可以修改、扩展和集成开源解决方案，从而创建一个最优的工具链。</blockquote><p></p><p></p><p>开源项目强调透明，允许任何人审查源代码。Fish 说，这可以加强软件开发周期内的安全工作，因为团队有机会检查代码中的漏洞并进行必要的改进。开源项目的协作特性通常可以使其对安全性和其他各种问题做出快速响应，从而帮助 DevOps 团队保证环境的安全和稳定。</p><p></p><p>开源项目也有一些缺点。Fish 提到，“通过隐匿实现安全”的概念并不适用于开源工具。Fish 说，专有软件公司可以声称他们的代码比开源软件更安全，因为代码不公开，黑客很难利用其漏洞。</p><p></p><p>Fish 还提到，开源软件很容易被滥用：</p><p></p><p></p><blockquote>最近有一些案例，比如“Colors”NPM 包和“FakerJS”被维护者破坏 / 删除，每个人都有自己的原因。我们要知道，当我们在自己的环境引入开源工具时，这种情况是有可能发生的（即使不是经常发生）。</blockquote><p></p><p></p><p>Fish 说，很多开源工具并没有得到公司的支持。由于维护者是个人，所以他们可以决定停止维护这些项目：</p><p></p><p></p><blockquote>如果我们集成这类项目，这意味着我们要么自己维护它，要么迁移到另一个维护良好的工具。</blockquote><p></p><p></p><p>Fish 提到，对于开源，你需要“善意推定（assume good faith）”。如果你在生产环境中使用一个开源工具，它有一个 Bug，而你打开了一个问题来修复它，那么这个 Bug 的修复可能需要几个月甚至更长的时间，因为他们不欠我们任何东西。</p><p></p><p>是的，你可以打开代码并尝试自己修复它，但并不是所有人都有资源这样做，所以我们会依赖于项目维护者为我们修复它。</p><p></p><p>Fish 建议我们解释这个问题并说明其紧迫性。她说，这样人们可能会更快地提供帮助，因为大多数（如果不是全部的话）开源维护者所从事的就是协作和沟通，因为这是开源文化的本质。</p><p></p><p>Fish 建议，在集成开源工具（特别是生产环境）之前一定要进行研究，确保它在出现问题时能够得到良好的维护。</p><p></p><p>InfoQ 就如何使用开源工具采访了 Hila Fish。</p><p></p><p>InfoQ：您在选择开源项目时有什么标准吗？</p><p></p><p>Hila Fish：我会考虑八个关键指标：项目的受欢迎程度、活跃度、安全性、成熟度、文档、生态系统、易用性和路线图。每个关键度量标准都有一些子问题，你可以问自己这些问题并找出答案，这样你就可以逐个指标地评估项目的成熟度级别。</p><p></p><p>InfoQ：您是如何使用那些标准的？</p><p></p><p>Fish：举个例子，就拿活跃度这个指标来说，它可以帮助我们大致估计下，这个开源项目修复 Bug/ 发布特性需要多长时间。查看下提交速率是每天、每周，还是每月，看下问题数量、发布数量，这样你就可以很好地了解活跃度。</p><p></p><p>文档是选择开源项目的另一个重要指标。文档是项目的门户，要看下它是否内容丰富，涵盖了大多数方面，如如何集成、已知问题、功能说明等。有了文档，你在决定是否采用该工具时就更有依据。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/12/upsides-downsides-open-source/\">https://www.infoq.com/news/2023/12/upsides-downsides-open-source/</a>\"</p>",
    "publish_time": "2024-01-17 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "分享一种主干开发方案：既能高频发布又能保证软件质量｜QCon",
    "url": "https://www.infoq.cn/article/NOhBA3eSlfrahIA0hEL2",
    "summary": "<p>在产品开发生命周期中的交付环节，前端设计团队的协同效率对于产品的发布进度具有决定性影响。近年来，行业内涌现出一系列卓越的设计协作工具以优化这一流程。其中，一款名为<a href=\"https://motiff.com/\"> Motiff </a>\"的 AI 赋能用户界面设计工具一问世就迅速走红。</p><p></p><p>Motiff 是一款功能集复杂的在线 UI 设计工具，它同时踩中了可视化编辑器、地图、仿桌面三大前端深坑。</p><p></p><p>为了保证 Motiff 的发布质量，Motiff 的研发团队在一开始就没有采用传统的分支发布 + 人工测试方案，而是使用主干开发 + 自动化测试的方案，在实现了高频发布的情况下，仍然很好地保证了软件质量。</p><p></p><p>为什么 Motiff 会选择这个方案，会遇到哪些坑？将于 4 月 18-20 日在北京举办的 <a href=\"https://qcon.infoq.cn/2024/beijing/track?utm_source=infoq&amp;utm_medium=article&amp;utm_campaign=7&amp;utm_term=zhangyuchen\">QCon 全球软件开发大会</a>\"邀请到了看云软件（<a href=\"https://motiff.com/\">Motiff</a>\"）研发经理张宇辰前来分享 <a href=\"https://qcon.infoq.cn/2024/beijing/presentation/5700?utm_source=infoq&amp;utm_medium=article&amp;utm_campaign=7&amp;utm_term=zhangyuchen\">Motiff 的高效能高质量开发实践</a>\"。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/9e/9e63dac5f01af073b2310e344b244903.png\" /></p><p></p><p>张宇辰老师毕业后一直在互联网研发领域工作。曾经在网易有道任职，自 2012 年开始在猿辅导，担任过前端工程师、服务端工程师、业务研发经理、基础架构负责人等多种不同职能角色。对于前后端软件开发、技术管理有着丰富经验。</p><p></p><p>其本次分享的思路大致如下——</p><p></p><p>先交代 Motiff 的项目背景，介绍为什么选择主干开发的方案——鉴于 Motiff 系统复杂性及其庞大的 Case 空间特性，潜在 Bug 发生的概率显著提升。传统分支开发 + 精细化发布的模式往往导致 bug 集中显现，造成资源浪费并降低整体开发效能。因此，Motiff 团队采用持续集成策略。</p><p></p><p>讲解主干开发的思路——Motiff 通过采纳主干开发方式，内生性地强化了对持续集成的依赖，并迫使团队在开发流程中的多个关键节点实现风险管控。具体策略着重于将风险控制点向开发前期（测试左移）和发布后阶段（测试右移）均衡分布。</p><p></p><p>然后分享测试左移和右移的关键实践。</p><p></p><p>他表示，这些方案并不是在一开始就被设计出来的，而是团队在两年多的开发过程中自发形成。因此，关于 Motiff 团队如何进行自我改善，以及技术管理者在这个过程中应该如何放手团队，又有哪些关键环节是管理者必须亲力亲为的，也是本次分享的重点。</p><p></p><p>在交流主干开发实践的内容部分时，张老师特别提及了他最想分享的「特性开关系统」，原因不在于这个系统有多先进，而在于：“它极度简单，但极致好用，维护成本贼低，如果要用四个字形容它的开发体验，那就是——有手就行。”</p><p></p><p>如果你对主干开发实践和这个神奇的特性开关系统感兴趣，也对——团队不写测试，每次发版都要熬夜，开发一周，进入测试后 Bug 不收敛，合并代码一合一星期等问题的答案感兴趣，欢迎来 <a href=\"https://qcon.infoq.cn/2024/beijing/track?utm_source=infoq&amp;utm_medium=article&amp;utm_campaign=7&amp;utm_term=zhangyuchen\">QCon 北京 2024</a>\"，听张老师的分享，和他面对面交流。</p><p></p><p>本次 QCon 大会推出全新主题——全面进化，并策划了大模型场景化落地、大模型产品设计、大模型推理加速、高质量架构、单体 vs 微服务、可观测、性能优化、下一代生产力工具、开源产品的商业闭环、最新编程语言、数据质量与治理、大前端前沿技术、自研 OS 时代的大终端等超多精彩专题。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a8/a8edd1db6d95f8a5185a000e94a6a9f9.png\" /></p><p></p><p>全年会议 7 折特惠购票，仅限 1 月，咨询购票可联系票务经理 17310043226 。目前大会议题同步征集中，<a href=\"https://qcon.infoq.cn/2024/beijing/track?utm_source=infoq&amp;utm_medium=article&amp;utm_campaign=7&amp;utm_term=zhangyuchen\">点击此处查看详情</a>\"，期待与各位开发者现场交流。</p>",
    "publish_time": "2024-01-17 10:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "专访李潇：数据智能平台，AI时代的Lakehouse架构",
    "url": "https://www.infoq.cn/article/qcUuAu70UGm5AzO3g9MR",
    "summary": "<p>在过去十年里，随着公有云的崛起、数据激增和人工智能的兴起等浪潮席卷，整个数据架构经历了巨大的变革和更新。这些激变使得数据架构发生了天翻地覆的变化。作为一家领先的大数据处理平台提供商，Databricks一直扮演着引领者的角色。</p><p>&nbsp;</p><p>在今年生成式AI的潮流中，Databricks不仅率先发布了开源可商用的大模型Dolly，还于6月底宣布以13亿美元的价格，收购生成式AI公司MosaicML。Databricks在GenAI上的投入也反映了整个大数据行业的技术演进。在2023年终盘点之际，InfoQ有幸采访了Databricks 工程总监、Apache Spark Committer 和 PMC 成员李潇，了解他对大数据技术栈的看法，以及Databricks在数据智能平台上的进展和规划。</p><p>&nbsp;</p><p>InfoQ：今年，关于大数据基础设施的演进，您观察到有哪些重要更新或变化？</p><p>&nbsp;</p><p>李潇：大数据领域随着生成式AI的兴起也变得异常热闹，我这里简略提及四点。</p><p>&nbsp;</p><p>Lakehouse平台的增长：Lakehouse平台在数据仓储领域的使用正迅速增加。这反映了一个重要的趋势：组织正从传统的数据处理平台过渡到更加灵活、集成和效率更高的现代数据架构。据2023年MIT Technology Review Insights报告，全球74%的首席信息官（CIOs）表示他们已经在使用Lakehouse架构。自Databricks在2020年推出此概念以来，Lakehouse作为一个新类别得到了广泛的采纳。几乎所有还未使用Lakehouse的首席信息官都计划在未来三年内部署此类平台。</p><p>&nbsp;</p><p>Serverless技术的普及：在过去两年里，Serverless技术在各个数据及人工智能（Data+AI）产品线中的应用变得极为普遍。Serverless架构的核心优势在于其能够提供无需管理底层服务器的数据处理和计算能力，从而使组织能够专注于核心业务逻辑而无需考虑基础设施的成本和维护。比如，Databricks SQL（Lakehouse上的无服务器数据仓库）使用量获得了大幅增长。这种架构模式特别适合于快速开发和部署，因为它能够根据需求自动扩展资源，并且只在实际使用时产生费用。在Data+AI领域，Serverless技术的引入使得数据处理、机器学习模型的训练和部署变得更加高效、灵活且成本有效。</p><p>&nbsp;</p><p>机器学习和大型语言模型（LLM）应用的扩展：机器学习和大型语言模型，特别是自然语言处理（NLP），正在经历迅速的应用扩展。这些技术不仅加强了传统分析任务的能力，还催生了新的应用场景，如聊天机器人、研究助手、欺诈检测和内容生成等。例如，Databricks的Data Intelligence Platform融合了生成式AI和Lakehouse架构的优势，创造了一个能够理解数据独特语义的数据智能引擎。这一平台针对特定业务需求，自动优化性能和管理基础设施，极大地简化了用户通过自然语言查询和发现新数据的体验。这反映出组织不仅在将更多的模型投入生产，也在加大对机器学习实验的投入，显示出机器学习方法和工具使用的成熟度和有效性正在不断提升。</p><p>&nbsp;</p><p>开源技术在数据和AI市场的关键作用及数据所有权的重要性：在人工智能和机器学习产品开发中，开源技术扮演着核心角色。我们需要一个更加安全、透明和可持续的数据和AI市场。开源平台和工具使用户能够更好地掌控他们的数据和技术堆栈，从而确保数据隐私和安全性，这在当前的AI和ML策略中至关重要。Databricks是开源社区的坚信者，对开源社区的持续贡献和对数据所有权重要性的强调，展现了我们对于建立一个开放、负责任且创新的技术生态系统的承诺。</p><p>&nbsp;</p><p>InfoQ：<a href=\"https://www.infoq.cn/article/k6Y0wXB7UGIOu2ak85WV\">2020年的年终盘点</a>\"（<a href=\"https://www.infoq.cn/article/k6Y0wXB7UGIOu2ak85WV\">https://www.infoq.cn/article/k6Y0wXB7UGIOu2ak85WV</a>\"），您预测趋势之一：“数据流水线（Data Pipeline）从复杂到简单”，如今对这个当初的预测您有新的感想吗？</p><p>&nbsp;</p><p>李潇：在2022 年，我们发布了全新的Delta Live Table (DLT)，这个正好对应了在2020年“数据流水线（Data Pipeline）从复杂到简单”的预测。这是第一个通过声明式方法来构建数据流水线的。它显著降低了数据管道的复杂性，同时提高了效率和可靠性，这使得数据流水线更易于构建、维护和操作。这对于希望快速、高效地处理大量数据的企业来说是一个巨大的进步。我们这里介绍一下它为了简易好用所引入的六个特性吧。</p><p>&nbsp;</p><p>1) 声明式编程模型： DLT采用声明式编程模型，使得定义和维护数据管道更为直观和简单。用户只需要指定所需的最终数据状态，DLT则负责执行必要的步骤来实现这一状态。</p><p>2) 自动化数据工程任务： DLT自动化了许多传统上需要手动编码的数据工程任务，如数据清洗、转换和聚合。通过减少需要手动编写和调试的代码量，DLT简化了整个数据处理流程。</p><p>3) 错误处理和数据质量保证： DLT内置了错误处理和数据质量检查机制。这意味着数据工程师可以花费更少的时间在解决数据质量问题上，而更多地专注于数据分析和提取洞察。</p><p>4) 优化的资源管理和成本效率： DLT通过自动调整资源使用（例如，在处理大量数据时自动扩展计算资源），提高了资源管理的效率，降低了操作成本。</p><p>5) 改进的监控和维护： DLT提供了增强的监控和维护功能，使得跟踪数据管道的性能和识别潜在问题变得更加容易。</p><p>6) 无缝集成和扩展性： DLT可以无缝集成到现有的数据生态系统中，并且具有很好的扩展性，支持从小型项目到大规模企业级应用的不同需求。</p><p>&nbsp;</p><p>InfoQ：以Databricks的发展为例，回头去看大数据技术的发展，您认为主要可以分为哪几个阶段？</p><p>&nbsp;</p><p>李潇：大数据技术的发展，以Databricks的成长历程为例，可以分为几个关键阶段，这些阶段不仅展现了Databricks的发展轨迹，也反映了整个大数据行业的技术演进。</p><p>&nbsp;</p><p>首先是Apache Spark的诞生阶段。这个阶段始于2010年，标志着Hadoop技术时代的结束。Apache Spark由Databricks的创始人之一Matei Zaharia等人开发，这是一个开源的分布式计算系统。它的出现大幅降低了大数据处理的门槛，使得大数据开始与机器学习和人工智能结合，成为统一的分析引擎。它使得用户可以更简单、方便地进行全量数据分析、实时流处理和复杂的数据分析。从此，大数据不再仅限于技术巨头，而是开始被更广泛的行业和企业采用。</p><p>&nbsp;</p><p>接下来是Lakehouse架构的推出阶段。这一阶段发生在2020年，打破了传统数据湖和数据仓库的界限。Lakehouse架构结合了数据湖和数据仓库的最佳元素，旨在降低成本并加速数据及人工智能项目的实施。Lakehouse架构建立在开源和开放标准之上，它通过消除历史上复杂化数据和AI的孤岛，简化了数据架构。值得注意的是，Apache Spark只是Lakehouse架构中的可选模块之一。</p><p>&nbsp;</p><p>最后是生成式AI大潮下的Lakehouse阶段。在这个阶段，Lakehouse成为了下一代数据智能平台 (Data Intelligence Platform) 的基础。这个数据智能平台将AI带入数据处理，帮助全世界的用户发现数据的价值。在这个平台上，用户可以开发基于自己数据的生成式AI应用，同时不必牺牲数据隐私或控制权。它使得组织中的每个人都能使用自然语言来从数据中发现洞见。</p><p>&nbsp;</p><p>总的来说，这些阶段并不是严格分隔的，而是相互交织和演进的。每个阶段都反映了当时技术发展的需求和挑战，同时预示着下一阶段的到来。未来，数据和AI不分家！</p><p>&nbsp;</p><p>InfoQ：Databricks今年最大的进展主要体现在哪个方面？是AI方向上的吗？</p><p>&nbsp;</p><p>李潇：今年，Databricks的最大进展主要体现在将人工智能集成到数据平台中。公司构建了一个基于数据湖仓（Lakehouse）的数据智能平台（Data Intelligence Platform），专注于AI在数据处理中的变革作用。这个平台利用生成式AI模型来理解数据的语义，并在整个平台中应用这种理解。用户可以在保持隐私和控制的同时，从头开始构建模型或调整现有模型。该平台的目标是实现数据和AI的平民化，使用自然语言极大简化了数据和AI的端到端体验。通过在数据和AI的每一层应用AI，可以实现针对特定业务的全面自动化和成本效率。这种平台的统一性有助于用户以数据为中心的方式应对任何模型开发场景，使用私有数据，从而拥有更强的竞争和经济优势。</p><p>&nbsp;</p><p>数据湖仓对GenAI起到了什么样的帮助或作用？（湖仓应该只是pipeline的一环，但是跟GenAI有直接联系么？企业如何利用湖仓架构支持他们的AI战略，从技术上说他们需要做些什么？）</p><p>&nbsp;</p><p>数据湖仓（Lakehouse）为GenAI提供了一个集中、高效和可扩展的数据存储和管理环境。它结合了数据湖的灵活性和数据仓库的高性能，支持结构化和非结构化数据的存储和处理，这是AI应用的数据需求的基石。</p><p>&nbsp;</p><p>数据质量和治理：数据湖仓通过提供强大的数据治理工具（如Databricks的Unity Catalog）来确保数据的质量和安全。这对于构建准确可靠的AI模型至关重要。Unity Catalog帮助企业精确管理其数据，提供完整的元数据和数据溯源信息，从而提高AI模型的准确度，并确保数据的安全性。</p><p>&nbsp;</p><p>数据访问和处理：数据湖仓支持高效的数据访问和处理，这对于实时AI应用和深度学习模型训练尤为重要。在Databricks的Lakehouse，通过Unity Catalog，智能引擎可以理解数据和数据之间的关系，企业可以使用自然语言来安全地查找和理解数据，这对于在庞大的数据集中找到正确的数据至关重要。</p><p>&nbsp;</p><p>数据集成和管理：数据湖仓提供了一个统一的平台，支持大量结构化和非结构化数据的存储和管理。这对于训练和优化AI模型至关重要。其实除了数据迁移到Lakehouse，今年，我们还推出了Lakehouse Federation的功能，用户可以跨多个数据平台（如MySQL、PostgreSQL、Snowflake等）发现、查询和管理数据，无需移动或复制数据，为用户提供了简化和统一的体验。</p><p>&nbsp;</p><p>当前，越来越多的公司正在构建自己的Lakehouse架构。然而，根据不同需求的技术选型会带来截然不同的效果。对于企业级用户而言，数据安全通常是最优先考虑的问题。在我看来，选择技术平台时，首先应确保平台能够解决数据合规和数据资产安全性问题，其次才是成本控制和性能提升。</p><p>&nbsp;</p><p>目前，众多公司正积极构建自己的Lakehouse架构。重要的是，技术选择应根据具体需求定制，因为不同的选择将导致不同的成果。对于企业级用户，数据安全无疑是首要关注的领域。在选择技术平台时，首先要确保所选平台能够全面应对数据合规性和数据资产安全性的挑战。此外，成本控制和性能优化也是重要的考量因素，但它们应该在确保数据安全的基础上进行权衡。因此，平衡这些关键要素，选择一个既安全又高效的Lakehouse解决方案，对于任何希望在现代数据生态中取得成功的企业来说，都是至关重要的。</p><p>&nbsp;</p><p>InfoQ：请展望未来的大数据架构是什么样子（必要组件的演变，一些趋势总结）？</p><p>&nbsp;</p><p>李潇：在不久的未来，每个领域的赢家都是那些可以最有效利用数据和AI的。事实上，我们坚信对数据和AI的深刻理解是每个赢家的必备技能。未来的大数据架构将是一个高度集成、智能化和自动化的系统，它能够有效地处理和分析大量数据，同时简化数据管理和AI应用的开发过程，为企业提供竞争优势。</p><p>&nbsp;</p><p>未来的大数据架构，我们可以称为“数据智能平台（Data Intelligence Platform）”。它正是顺应了两个主要趋势：数据湖仓（Data Lakehouse）和生成式人工智能（AI）。这一架构建立在数据湖仓的基础上，它提供一个开放、统一的基础，用于所有数据和治理，由一个理解用户数据独特语义的数据智能引擎(Data Intelligence Engine) 驱动。这是相对现有Lakehouse架构下的，最大的突破。</p><p>&nbsp;</p><p>智能化方面，这个引擎能理解客户数据的独特语义，使平台能自动优化性能和管理基础设施。操作简化方面，自然语言大大简化了用户体验。数据智能引擎理解客户的语言，使搜索和发现新数据就像询问同事一样简单。此外，自然语言还助力编写代码、纠错和寻找答案，加速新数据和应用程序的开发。</p><p>&nbsp;</p><p>在隐私保护方面，数据和AI应用需要强大的治理和安全措施，尤其是在生成式AI的背景下。提供一个端到端的机器学习运维（MLOps）和AI开发解决方案，该方案基于统一的治理和安全方法。这允许在不妥协数据隐私和知识产权控制的情况下，实现所有人工智能目标。</p><p>&nbsp;</p><p>总的来说，未来的大数据架构将更加重视智能化、操作简化和数据隐私，为企业在数据和AI应用方面提供竞争优势。这将使企业能更有效地利用数据，推动创新，同时保护数据安全和发展AI技术。</p><p>&nbsp;</p><p>更多阅读：</p><p>解读数据架构的 2020：开放、融合、简化：<a href=\"https://www.infoq.cn/article/k6Y0wXB7UGIOu2ak85WV\">https://www.infoq.cn/article/k6Y0wXB7UGIOu2ak85WV</a>\"</p><p>让大模型融入工作的每个环节，数据巨头 Databricks 让生成式 AI 平民化：<a href=\"https://www.infoq.cn/article/EvYEXsLPh8KMkfNrsG7D\">https://www.infoq.cn/article/EvYEXsLPh8KMkfNrsG7D</a>\"</p>",
    "publish_time": "2024-01-17 10:14:37",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Flink十周年专访莫问：存算分离2.0架构的探索与展望",
    "url": "https://www.infoq.cn/article/zK6T1A3HfolPsktP2Z1Z",
    "summary": "<p>采访嘉宾 ｜ 王峰（莫问）</p><p>编辑 ｜ Tina</p><p>&nbsp;</p><p>Flink 从 2014 年诞生之后，已经发展了将近 10 年，尤其是最近这些年得到了飞速发展。在全球范围内，Flink 已经成为了实时流计算的事实标准，成为大数据技术栈中不可或缺的一部分。在2023年终盘点之际，InfoQ有幸采访了Apache Flink 中文社区发起人、阿里云开源大数据平台负责人王峰（莫问），了解他对大数据技术栈的看法，以及Flink的进展和未来规划。</p><p>&nbsp;</p><p>InfoQ：如果以“数据流”的逻辑来看大数据基础设施的演进，比如：从存储和处理到分析，再到提供 ML/AI 模型并构建面向用户的、人工智能驱动或数据驱动的应用程序，那么在这些环节中，您观察到有哪些重要更新或变化？</p><p>&nbsp;</p><p>王峰（莫问）：在最近几年的数据技术趋势演进的路线中，我们可以清晰的看到两个趋势变化，一是数据分析的实时化，二是数据架构的云原生化。</p><p>数据分析实时化本质是业务发展驱动的。在 BI 场景，各行业的业务运营人员和决策者都希望能到实时的数据分析报表来及时进行业务决策，从而提升公司运营效率；在 AI 场景，各种推荐广告等场景都希望能够及时将用户行为反馈信息合并到 AI 模型中，从而进行更加个性化精准的推送，提升业务转化率。在技术上，数据的“实时化”包括了两个因素：一是数据的新鲜度，二是数据的查询速度。为了解决这 2 个问题，我们可以看到最近几年 Streaming 和 OLAP 两种引擎成为了大数据技术领域的热点，SIGMOD 把今年的 Systems Award 搬给了 Flink，Clickhouse 、Doris 和 StarRocks 几款 OLAP 引擎也不断争夺市场的焦点。在云端构建数据基础设施日益成为主流，云的弹性能力让存算分离架构可以发挥出极致的效果，在云端基于数据湖构建开放的数据中心，不同类型的计算引擎可以围绕统一数据存储构建繁荣的融合计算生态。以 Snowflake 和 Dataricks 为代表，几乎所有的大数据公司都选择了拥抱云原生，推出了基于多云的 PaaS/SaaS 计算服务，从 Serverless 到 BYOC，为用户提供了在云上不同类型的托管服务，随着云计算规模效应的提升，未来一定会有更多的数据计算迁移到云上运行。</p><p>&nbsp;</p><p>&nbsp;</p><p>InfoQ：今年我们看到不止一家企业声称实现了比Flink有10-1000倍的效率提升，那么在Flink的资源效率方面有什么进展？增量引擎+Apache Paimon方案是否是一方面？</p><p>&nbsp;</p><p>王峰（莫问）：</p><p>我也非常期待能看到真正能够有 “比 Flink 快100-1000倍”的新技术出现，这样类似阿里、腾讯、抖音这些公司大概每年可以节省数十亿的机器成本了，不过目前好像没有看到那家公司真的在生产环境做到了个效果。几个月前，大家通过开放的方式进行过一些相关讨论，Flink 社区的几位核心成员也通过基准测试成绩以及技术分析进行了回复，有兴趣的同学可以去网上搜索下相关文章。良性的技术竞争是有利于开源生态的发展和演进，目前 Flink 也在不断学习和自我革新，明年 2024 年将是 Flink 项目的第一个十周年，Flink 社区也会发布 Flink-2.0 新的里程碑，彻底的云原生存算分离架构，业界一流的批处理能力，完整的流批融合能力都会是全新的亮点。此外，阿里云之前独立开源的 Flink CDC 实时数据集成项目也已经正式开启捐献工作，明年 Flink CDC 将正式成为Apache Flink 官方子项目。Apache Paimon 是从 Flink 社区中孵化出来的新项目，定位就是流批一体实时数据湖格式，解决 Lakehouse 数据实时化的问题。基于 Flink + Paimon 可以构建出新一代的 Streaming Lakehouse 架构，让Lakehouse 上的数据可以全链路实时流动起来。此外，基于计算和存储端到端流批一体的特性，也更加方便用户在Lakehouse 架构上实现实时离线一体化的数据分析体验。</p><p>&nbsp;</p><p>InfoQ：您认为流处理引擎未来进化方向是什么？</p><p>&nbsp;</p><p>王峰（莫问）：</p><p>方向 1：全面 SQL 化，提升体验，降低门槛。大数据处理从离线向实时升级的趋势已经确立，大量行业已经开始实时化升级，并取得非常好的业务收益。为了让更多用户能够享受到实时流计算带来的价值，流处理引擎需要进一步提升端到端的易用性，全面 SQL 化 ，提升用户体验，降低使用门槛，让流计算能够在更多场景和行业中被生产使用起来。</p><p>&nbsp;</p><p>方向 2：流批一体，流批融合。流、批数据处理的边界正在逐步模糊，越来越多用户希望一套 API 来统一开发业务逻辑，但可以基于不同的频率来运行，例如可以让其每天 / 小时 / 5分钟运行一次，或者持续不停在运行，并得到一致性的业务结果。因此流批一体，流批融合计算能力会是下一步的演进方向。</p><p>&nbsp;</p><p>方向 3：存算分离，云原生架构。Cloud 正在成为大数据和 AI 计算新的运行底座，因此流计算引擎需要在运行部署架构上完全融入云原生环境，彻底实现存算分离架构，基于云的优势提供秒级弹性扩缩容和系统容错恢复能力。</p><p>&nbsp;</p><p>方向 4：流式湖仓新场景&nbsp;。目前大部分用户都是将流计算引擎和消息队列配套使用，构建流式处理链路。但这个并未真正解放流计算的潜力，随着开放的 Lakehouse 架构出现，越来越多数据会进入到数据湖中，流计算引擎和 Lakehouse架构的结合将开启新的实时数据湖分析架构。目前流计算已经和主流湖存储技术完成对接，接下来流计算引擎将继续完善自身使其更好的和 Lakehouse 架构进行深度融合。</p><p>&nbsp;</p><p>InfoQ：对当前大数据平台来说，生成式AI将对数据和分析产生什么影响？</p><p>&nbsp;</p><p>王峰（莫问）：大数据和 AI 一体化是一个谈论了很久的话题，在 AIGC 出现之前，大数据和 AI 最经典的结合场景是搜、推、广，用户个性化模型的生成和更新离不开海量用户行为数据的预处理，包括特征工程和样本拼接等经典流程。在很多大型互联网公司中，这部分 AI 数据预处理工作的计算量甚至已经超过了经典 BI 数据分析类应用。</p><p>&nbsp;</p><p>在进入 AIGC 时代后，LLM 的训练依然需要前期的海量数据预处理，随着越来越多超级AIGC APP 的出现，依然会产生大量的用户交互数据，为了更好的将这些数据效果反馈给 LLM，AI 场景依然会继续需要大数据计算技术来协助发展。</p><p>&nbsp;</p><p>此外，随着行业大模型的逐步丰富，AI 技术红利也会助力大数据的发展，目前已经有不少公司开始推出利用 AI 大模型技术进行自动生成 SQL的技术，这背后需要 AI 大模型能够更加深入的理解数仓体系，从而根据用户需求产生更加高效的 SQL。总而言之，未来大数据和 AI 技术的融合会更加深入，相互支持，相互促进。</p><p>&nbsp;</p><p>InfoQ：在您看来，当今现代数据堆栈还有哪些局限性？</p><p>&nbsp;</p><p>王峰（莫问）：近些年各种不同的大数据基础设施雨后春笋般的涌出，一方面为用户提供了多样化的选择，但另一方面也为用户带来了幸福的烦恼。通常情况下，用户要搭建一套大数据业务系统，需要非常多的核心技术组件才能完成，少则三到五种，多则五到十种，这主要带来以下几方面的问题：</p><p>技术组件繁多，必然提升系统架构的复杂度。通常来讲，系统稳定性风险和系统复杂度成正比，过于复杂的体系必然带来更大的稳定性隐患；每一项技术组件都需要有对应的专家来运维管理以及客户支持，对于中小企业来说，这必然带来高昂的人力资源成本；过多的同质化组件存在，也会为用户带来选择的困扰，并行保留多个同质化组件不仅给运维团队带来了额外的运维负担，也给开发者带来了额外的学习成本。</p><p>&nbsp;</p><p>因此，未来数据技术的演进会逐渐出现一些整合的趋势，走向更加简洁的架构，核心目标不仅是让每个组件运行的更快，还需要考虑为用户提供更加简单、一致性的开发体验，以及全局最优的运维成本。</p><p>&nbsp;</p><p>InfoQ：请展望未来的大数据架构是什么样子？</p><p>&nbsp;</p><p>王峰（莫问）：</p><p>目前业界主流的几款 Streaming，Batch 和 OLAP 引擎都开始相互渗透，例如：Flink 在发力流批一体、流批融合计算能力，Databricks 也基于 Spark 和 Delta 推动了Delta Live Table 淡化流批的差异，StarRocks 在提供 OLAP 极致查询能力的同时，也开始通过物化视图形态提供对数据湖上数据的 ETL 处理能力。本质上各大主流计算引擎都在不断扩展自己的能力边界，淡化流、批、OLAP边界，希望为用户提供全场景一致性的数据分析体验。我个人认为这也是技术发展的必然趋势，各家都会逐渐补齐短板，但也都有各自核心的优势。随着云原生概念的逐步普及，未来主流的计算负载一定是运行在 cloud 上，全球范围内都是这个趋势，因此大数据架构也需要更好的适配云底座，利用好云的弹性优势。存算分离将会是未来大数据架构的标配，不过存算分离在带来了诸多好处的同时也带来了额外的性能挑战，目前看在对 latency 敏感的场景下，多级缓存和冷热分层将是对存算分离架构的有益补充，2024年将发布的 Flink-2.0 也会采用这套最新的架构。云原生架构的不断发展，也同步推动了数据湖存储方案的加速落地。数据湖具备的开放和成本优势，必然使得越来越多的数据流入湖中，从而成为天然的数据中心，湖上建仓的lakehouse 架构正在成为主流，下一步客户一定是希望数据在 lakehouse 中能够更加实时的流动起来。在实时流处理这条链路上，我觉得也存在一些新的机会和变化。众所周知，Flink 和 Kafka 目前已经分别成为流计算和流存储的事实标准，但 Kafka 真的是最适合流分析的存储方案吗？Kafka 和很多消息队列类似，都是一种消息中间件，而非为大数据分析而生。例如：Kafka 并未对数据提供结构化的 Schema 描述，也无法提供完整的 Changelog 语义，且 Kafka 中的数据时无法进行实时更新和探查分析的。但以上这些缺陷，都是实时流分析需要的特性和能力，我们也正在思考这个问题，并探索新的解决方案，希望能够在明年发布一款更加适合流分析的流存储技术。</p>",
    "publish_time": "2024-01-17 10:20:19",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AI激荡重塑新格局，首届AIGC全网小程序应用创新大会尖叫倒计时！",
    "url": "https://www.infoq.cn/article/LL3l1d0IPJM9SFpKPDIF",
    "summary": "<p>1月23日，首届AIGC全网小程序应用创新大会将在北京中关村国家自主创新示范区展示中心·会议中心拉开帷幕。此次会议以“AI激荡·全网小程序重塑新格局”为主题，邀请AI各领域政府及学界代表、知名投资人、高潜力企业、小程序相关企业负责人相聚一堂，站在新周期的起点上，直面当下困境，寻找未来新突破。</p><p></p><h2>超强嘉宾阵容，资源全方位链接</h2><p></p><p>&nbsp;</p><p>新起点、新出发，首届AIGC全网小程序应用创新大会覆盖小程序全商业领域，带来丰富多元的嘉宾阵容，来自中关村云联盟、华为、支付宝、京东科技、钉钉、神策数据等50+名政府领导、知名专家、企业家、投资人齐聚一堂，一场场关于小程序的深度洞察及精彩对谈即将迭新上演。</p><p>&nbsp;</p><p>同时，阿拉丁也更加注重大会的链接价值与社交属性，大会为各领域企业提供的是一个开放、专业的交流分享平台，更是企业、专家、资本和政府机构的高效社交场和资源链接场。</p><p></p><h2>移动应用专委会揭牌，开启小程序生态新格局</h2><p></p><p>&nbsp;</p><p>大会期间将举行中关村云联盟移动应用专委会的隆重揭牌仪式。这一全新的组织将使政产学研用单位形成自主创新合力，推动移动应用创新生态构建，加速移动互联网应用技术攻关与成果转化。完善行业客户场景适配，推动小程序行业朝着更加标准化、规范化的方向发展。同时预示着小程序生态将迈入一个全新的发展阶段，开启行业生态新格局。</p><p></p><h2>阿拉丁独家2023小程序白皮书发布，洞悉行业新机遇</h2><p></p><p>&nbsp;</p><p>回首过往，阿拉丁已在小程序领域深耕8年之久，输出超20万字的解读报告，100余案例的深度分析，覆盖40+行业，超千万级别的数据统计，为各开发者和从业者提供了一份份专业权威的行业新洞察。可以看到2023年是小程序生态开放进一步加速的一年,合作焦点也从小程序入驻向营销服务、技术服务等多种形式拓展，小程序互联网也逐步形成跨生态、同方向、双巨头局面。</p><p>&nbsp;</p><p>那么2023年小程序互联网到底发生了哪些变化？有哪些值得关注的行业大事？2024年又有哪些值得期待的表现和机会呢？锁定大会现场重磅发布环节，在《2023小程序白皮书》你都将找到答案。</p><p></p><h2>趋势挑战解读，多元视角剖析「AI+小程序」</h2><p></p><p></p><p>在新的技术浪潮激荡中，聚集正值风口的AICG技术及小程序赛道的新机遇仍是大会最核心的关注点。大会以1个主会场和1个分会场的形式并行论道，打造“开放创新交流论坛”和“AI投融资论坛”两大主题会场，联动产业与资本，围绕AI应用、AI大模型、移动应用创新、小程序新生态等话题进行深度交流碰撞，多元方案、多点视角为企业拨开迷雾、变革创新、链接赋能。</p><p></p><h2>精彩议程抢先知！</h2><p></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/6b/e6/6b70aac70b3ef5de35e3103077d7f0e6.png\" /></p><p></p><p></p><h2>大会参会指引</h2><p></p><p>&nbsp;</p><p>时间：2024年1月23日9:30-18:30</p><p>地点：北京中关村国家自主创新示范区展示中心· 会议中心</p><p><img src=\"https://static001.geekbang.org/infoq/5c/5c74d24099c6d8de86c4a263ba8896ea.png\" /></p><p></p><p></p><h2>报名倒计时！</h2><p></p><p>&nbsp;</p><p>首届AIGC全网小程序应用创新大会诚邀您莅临，报名倒计时一周！</p><p>扫描二维码进行报名</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/44/44a0dab46f9456650b7bf8963ae0dbff.png\" /></p><p></p><p>&nbsp;</p><p>注意事项：</p><p>1. 参会免费：</p><p>参与本次大会不收取任何费用。我们欢迎所有对大会感兴趣的人员踊跃报名。</p><p>2. 名额有限：</p><p>鉴于名额限制，建议参与者尽早申请，提高获取资格的机会。</p><p>3. 审核通知：</p><p>为保证活动的质量，主办方将对报名人员进行资格审核，审核结束后，我们将通过您所提供的联系方式发送报名成功的短信通知，请务必在报名时提交正确的信息。（已经报名的小伙伴请耐心等待审核）</p><p>&nbsp;</p><p>温馨提示：提交信息时请保证真实性。提交虚假信息可能会导致您的参会资格被取消。</p>",
    "publish_time": "2024-01-17 13:18:22",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "挑战Spark和Flink？大数据技术栈的突围和战争 ｜ 年度技术盘点与展望",
    "url": "https://www.infoq.cn/article/c5xjuPCzyo1AcZWR2QKU",
    "summary": "<p></p><p><img src=\"https://static001.geekbang.org/infoq/77/77d262475ed561520ac076d16507423a.jpeg\" /></p><p></p><p>十年的轮回，正如大数据的发展一般，它既是一个轮回的结束，也是崭新的起点。大数据在过去的二十年中蓬勃发展，从无到有，崛起为最具爆炸性的技术领域之一，逐渐演变成为每个企业不可或缺的基础设施。然而，在这个时刻，我们不禁要问：当前的大数据架构是否已经趋于完美？2023年，伴随着人工智能的跃变式爆发，数据平台将如何演进，以适应未来的数据使用场景？</p><p>&nbsp;</p><p>这并非简单的问题，更是一个关乎企业生存与发展的命题。在过去的十年中，我们目睹了Spark、Flink和Kafka等系统的崛起，它们成为大数据领域的支柱。然而，现在是否有新的力量崭露头角，希望挑战它们的地位？2023年，大数据领域有哪些实质性进步吗？</p><p>&nbsp;</p><p>在2023年年终盘点之际，InfoQ有幸采访了大数据领域的资深专家，包括关涛、李潇、王峰（莫问）、吴英骏、张迎（按姓名拼音排序）。他们共同探讨了数据堆栈技术的演变过程，深入剖析了技术快速演变所带来的挑战。在这次专访中，我们将揭示技术变革的背后原因和逻辑，为大家呈现大数据领域的现状以及未来可能的发展方向。</p><p>&nbsp;</p><p></p><h2>突如其来的革新和质疑？</h2><p></p><p>&nbsp;</p><p>流存储Kafka诞生在2011年，而流计算Flink到今年也刚好满了十年。</p><p>&nbsp;</p><p>十年前，软件范式是利用虚拟化技术来发挥硬件性能。此外，云服务也只是刚刚兴起，存算分离等云原生概念尚未普及。</p><p>&nbsp;</p><p>如今时过境迁，一切都在快速变化。当今的应用程序每天可以处理多达数万亿个事件，维护数 TB 的数据。硬件的迭代速度飞快，相对十年前的SSD，NVMe速度提升十倍，价格也降至原来的20%。S3 越来越多地被用作基础设施服务的核心持久层，而不仅仅是作为备份或分层存储层，例如Snowflake、Databricks等。</p><p>&nbsp;</p><p></p><blockquote>对象存储是云时代的产物，支持原始数据存储、分布式可扩展、高灵活性、低价，都是对象存储之所以被选择的原因。可以预计在未来会有更多的数据业务完全基于对象存储而构建。--2021年，滕昱《<a href=\"https://www.infoq.cn/article/JYoI8SgLbEdY68lWN5J4\">使用对象存储，数据湖才能重获新生</a>\"》</blockquote><p></p><p>&nbsp;</p><p>能否跟上硬件迭代速度，这是Kafka这样的成熟且架构已经定型的软件所面临的最大挑战：拥有众多用户，因此每个改动都需要花费更多的时间和精力去验证合理性，大大拖慢了迭代速度。</p><p>&nbsp;</p><p>这也给一些初创公司带来了巨大的机会：不需要用分层架构去实现存算分离，而是干脆用更加极端点方式去做存算分离，即直接建立在S3对象存储之上。</p><p>&nbsp;</p><p>基于对象存储的构建也大大降低了构建新数据系统的门槛，催生了一系列这样的“垂直”基础设施初创公司：今年诞生的兼容Kafka的WarpStream、<a href=\"https://www.infoq.cn/article/f4hJdZqtKAQdJvCKQYq7\">AutoMQ</a>\"，去年拿到A轮融资的Neon Database、流数据库<a href=\"https://zhuanlan.zhihu.com/p/672964437\">RisingWave</a>\"，等等。</p><p>&nbsp;</p><p>然而S3虽然价格便宜，能省成本，但高延迟是一个问题，数据系统构建者需要费点周折才能处理好需要低延迟的工作任务。恰好在今年底，AWS发布了S3 Express One Zone，一种新的低延迟S3存储类别，可以说是在正确的时间提供了正确的技术（目前价钱昂贵）。</p><p>&nbsp;</p><p>推动数据库和数据产品发展的主要因素主要有两方面。一方面是数据本身，另一方面是硬件的发展。S3是硬件层面的变化，这势必会给大数据领域带来巨大的变革。</p><p>&nbsp;</p><p></p><blockquote>众所周知，在数据库的历史上，每次存储介质的变化都会引发软件的变革。--2023年，曹伟《<a href=\"https://www.infoq.cn/article/5wczTd6ItqtwYdrHhHWy\">数据库的下一场革命</a>\"：进入对象存储时代》</blockquote><p></p><p>&nbsp;</p><p>“低延迟S3的发布，对于我们这些从事数据基础设施业务的人来说，这是今年最大的一个新闻。”RisingWave（risingwave.com）创始人 &amp; CEO 吴英骏认为。</p><p>&nbsp;</p><p></p><h4>如今的大数据技术栈是真的难用吗？</h4><p></p><p>&nbsp;</p><p>站在当前的时间点，对于大数据系统的易用性问题，采访嘉宾给出了“不够好”、“不够便宜”，“太过复杂”的评价，可以说当今的大数据技术栈是公认的“难用”。</p><p>&nbsp;</p><p>大数据架构在过去漫长的20年里经历了从场景到系统的完整迭代。</p><p>&nbsp;</p><p>大数据的起源可以追溯到谷歌的MapReduce框架，这标志着大数据的最初阶段。在此之前，数据库方面主要有一些顶级产品，如Oracle、SQL Server和IBM DB2。Google提出了一个通用的、折中的方案，即不必购买Oracle、DB2或Microsoft Server，使用简单的模型让大规模并行计算在拥有大量普通计算机的科技企业中变得可行：利用MapReduce，不使用数据库，就能完成大数据计算，只不过用户需要去承担这些复杂性。</p><p>&nbsp;</p><p>这里还有个大家可能忘却的典故：数据库专家David DeWitt与Michael Stonebraker（同样是图灵奖获得者）在2008年发表了《MapReduce: A major step backwards》，对MapReduce进行了批评，称其为开历史倒车。</p><p>&nbsp;</p><p>要充分利用这些资源，MapReduce提出的方法是，将底层编程接口封装成Map和Reduce函数之后，便直接暴露给有编程经验的用户，让用户自己实现具体业务逻辑，并自己可以操控程序并行度等细节。用户不再是使用SQL，而是使用C或Java等编程语言，需要承担编写底层代码的复杂性，处理更多的编码工作，这也意味着很高的学习壁垒，让许多人望而却步。</p><p>&nbsp;</p><p>在这期间，批处理和流处理在Spark和Flink的引领下率先成熟。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7b/7bf74d19ac1239707b2efb7f5ca9a41c.jpeg\" /></p><p></p><p>&nbsp;</p><p>截图来源：<a href=\"https://zhuanlan.zhihu.com/p/662659681\">https://zhuanlan.zhihu.com/p/662659681</a>\"</p><p>&nbsp;</p><p>近几年，交互分析，也称直接在线服务能力（<a href=\"https://en.wikipedia.org/wiki/Operational_analytical_processing\">Operational Analytics</a>\"） 随Clickhouse等通用实时数仓流行，并已是事实上完成主流客户的部署。随流、批、交互三类计算场景成为标配，Lambda架构也成为（国内的）事实标准。Lambda架构能够满足客户场景上的诉求，最大的缺陷就是复杂：数据开发、组件运维、数据管理均复杂。</p><p>&nbsp;</p><p>毕竟并不是所有公司都跟Google、Facebook或Twitter这样的大型科技公司一样，拥有强大的工程团队，能够管理复杂的流处理系统来实现他们的需求。也并不是所有用户都像阿里和拼多多这样有着非常大的数据量，复杂的分布式系统阻碍了十几或几十个人的小公司或一些传统企业的采用，对它们来说，这是一件成本高、挑战大的事情。</p><p>&nbsp;</p><p>吴英骏认为，大数据架构里，如流处理，应该回归第一性原理了。</p><p>&nbsp;</p><p>“现在的系统，诞生于十年前，与当下云时代设计的系统相比，从本质上来说肯定是不同的，这表明大数据生态在这十年间并没有取得实质性进步。”</p><p>&nbsp;</p><p>“在当前时刻，我们再设计这个系统时，肯定会思考能否基于现有系统实现性能提升。”</p><p>&nbsp;</p><p>语言层面，新系统需要提供一个更高层次的语言，比如SQL或Python。另外，云上最核心的一个点在于“存算分离”，站在现在这个时间节点上，新一代的系统从设计上的第一天开始就应该是“存算分离”的。跟分级存储架构不一样，现在的系统可以将所有数据直接放到S3，而不仅仅是将历史数据放到S3，那么这样就可以更加极端的去实现存算分离，设计、实现和运维自然都会更加简单。</p><p>&nbsp;</p><p>RisingWave 于2023年6月发布了1.0稳定版本，并通过数月的大量性能测试，得出了“<a href=\"https://mp.weixin.qq.com/s/xOaEXww9LaZFn6Fmwi-BFQ\">比Flink快10倍”的结论</a>\"。</p><p>&nbsp;</p><p>“性能比较不是关键，易用才是关键。基于对象存储并能在性能和效率方面取得提升，那肯定是因为整体基础架构正在发生变化，这是一个核心点。”</p><p>&nbsp;</p><p></p><h2>以Spark社区为例看易用性进展：从Python到AI</h2><p></p><p>&nbsp;</p><p>“简单易用”同样是Spark社区的主要发力重点。在Databricks今年的Data and AI Summit主题演讲中，Reynold Xin谈及了三个Spark社区在易用性的最新进展。</p><p>&nbsp;</p><p>首先，需要提供一套简单好用的API。Python 和 SQL已经成为了整个数据处理行业的主流语言。在过去几年，Python已成为TIOBE指数显示的排名第一的编程语言，这种受欢迎的原因来自于它的简单性和易学性，使其成为初学者和专家的首选语言。Python的广泛库和框架简化了数据分析和机器学习中的复杂任务。各大数据系统都提供了它自己的Python DataFrame APIs。PySpark的PyPI下载量（<a href=\"https://pypistats.org/packages/pyspark\">https://pypistats.org/packages/pyspark</a>\"）仅在2023年最后一个月就达到了来自169个国家的2800万次下载。为了方便pandas用户，PySpark也提供了pandas API的支持。可以说，API的简单易用已是大势所趋。特别值得一提的是，即将发布的Spark 4.0版本中，一个全新的Python的数据源接口被特别设计来强调易用性。这一更新将使Python用户更加轻松地创建和管理自己的数据源，进一步增强Spark平台的用户友好度和灵活性。</p><p>&nbsp;</p><p>Spark社区在这方面继续发力，过去一年的一个主要项目，Spark Connect，引入了一种分离的客户端-服务器架构，允许从任何地方运行的任何应用程序远程连接到 Spark 集群。这种架构的改进涉及到了稳定性、升级、调试和可观测性多个方面。Spark Connect 使得用户可以在他们喜爱的集成开发环境（IDE）中直接进行交互式的调试，并且可以使用应用程序自身的指标和日志库进行监控。</p><p>&nbsp;</p><p>其次，一个稳定成熟的数据系统必须具备一套稳定的API，这也是Spark社区对API行为和语义的变更制定严格规范的原因，目的是让用户更顺畅地升级至最新版本。在上个月，最流行的PySpark版本就是最新的Spark 3.5，这体现了用户始终倾向于使用最新版本的趋势。为了迎合这一趋势，Spark社区努力保证向后兼容。</p><p>&nbsp;</p><p>此外，错误信息的标准化也是Spark社区过去一两年里的努力方向。尽管这看似技术复杂度不高，但这实际上是使系统更加简单易用的基本需求。今年的Spark 4.0 release还会进一步标准化日志，以使用户能够更好地进行系统调优和代码调试。</p><p>&nbsp;</p><p>而随着生成式AI的发展，未来API将变得更加简单易用，自ChatGPT大流行到现在，我们发现它已经对 PySpark 有了深入的了解。这得益于 Spark 社区在过去十年里提供了丰富的 API 文档、开源项目和教学资源。Spark社区开发了一个叫做 English SDK 的项目，将Spark 专家的知识融入到 LLM中。这样一来，用户就可以通过简单的自然语言指令来操作 PySpark，而不需要自己写复杂的代码。这种方法让编程变得更容易上手，学习过程也更简单。</p><p>&nbsp;</p><p></p><h2>流处理的演进</h2><p></p><p>&nbsp;</p><p>从2014年诞生之后，Flink已经确立了其在全球实时流计算领域的地位。阿里、Amazon、Azure、Cloudera、Confluence等众多企业都提供了支持和托管服务。</p><p>&nbsp;</p><p>树大招风，实际上今年不止一家企业宣称在流处理技术上实现了10-1000倍的效率提升，如果这些技术确实可以在生产环境得到验证，像阿里、腾讯、抖音这样的大型公司每年可能会节省数十亿的机器成本。尽管目前还没有看到哪家公司在真正的生产环境中实现了这一效果，但这一趋势表明流处理技术的不断创新将在未来带来更多的机遇和成果。与此同时，<a href=\"https://zhuanlan.zhihu.com/p/647747291\">Flink的发展现状</a>\"和未来演进则更加引人关注。</p><p>&nbsp;</p><p></p><h4>流处理领域是否有留给创业公司的机会窗口？</h4><p></p><p>&nbsp;</p><p>事实上，Flink一直在不断完善和创新。Kafka已经在商业版中实现了一个“分级存储”架构来实现了存算分离的改造。同Kafka一样，Flink也会从存算耦合转为存算分离的架构。</p><p>&nbsp;</p><p>据莫问介绍，目前 Flink 也在不断学习和自我革新，2024 年将是 Flink 项目的第一个十周年，Flink 社区也会发布 Flink 2.0 新的里程碑，彻底的云原生存算分离架构、业界一流的批处理能力、完整的流批融合能力都会是全新的亮点。</p><p>&nbsp;</p><p>莫问认为，随着云原生概念的逐步普及，未来主流的计算负载一定是运行在 Cloud 上，全球范围内都是这个趋势，因此大数据架构也需要更好地适配云底座，利用好云的弹性优势。存算分离将会是未来大数据架构的标配，不过存算分离在带来了诸多好处的同时也带来了额外的性能挑战，目前看来在对 latency 敏感的场景下，多级缓存和冷热分层将是对存算分离架构的有益补充，2024年将发布的 Flink 2.0 也会采用这套最新的架构。</p><p>&nbsp;</p><p>分级存储侧重于在计算节点上进行缓存，远端存储主要存储历史记录。相较之下，新的直接建立在S3上的系统将所有数据完全存储远端，但也会造成性能的下降，这需要在产品设计方面去做一个权衡。</p><p>&nbsp;</p><p>在存算分离上，Flink会有一个迭代的过程，吴英骏认为，“大家的最终思想都是统一的。如果我们将时间拉长，放到五年之后，我们可能会看到这两种系统实际上非常相似。在未来发展中，双方都会在自己的短板上进行弥补。比如说，RisingWave从第一天起就将内部状态放在对象存储上，而这意味着RisingWave需要思考如何降低对象存储所带来的高延迟问题。而对于Flink来说，面临着使用本地磁盘存储状态而导致的大状态管理困难的问题。它可能需要引入一个分级存储的架构，来降低处理大状态计算时的资源消耗，同时避免系统直接挂掉。”</p><p>&nbsp;</p><p>“但在目前一两年里，这两种系统在架构上仍然会有相当大的区别。架构的调整不是一朝一夕能够完成的。”</p><p>&nbsp;</p><p>新兴软件和成熟软件之间有了较量，那么用户进行选型时，会关注哪些因素呢？</p><p>&nbsp;</p><p>作业帮于2019 年底调研 Flink 1.9 版本，并在 2020 年内部搭建了实时计算平台，现在流和批都在几千任务的规模。其大数据架构师张迎表示，选型时，主要根据业务诉求，结合多云融合能力、成熟度、已有技术积累、云厂商的支持力度、成本等综合考虑。</p><p>&nbsp;</p><p>这几年使用大数据技术栈时主要有两点比较强的感受：生产环境的可用性、周边系统的建设，这两点一定要跟得上。一个用户可以写出来几百个&nbsp;SQL 任务，但是出了问题往往不知道如何追查和改进。后面的工作，例如调优、自动化测试、日志、监控报警、高可用也都是围绕这类需求展开的。</p><p>&nbsp;</p><p>原来需要写代码的实时任务，很多可以通过&nbsp;SQL 完成。（在2015年后，随着流处理的成熟，流计算引擎纷纷选择了支持SQL通用编程语言）。SQL 越来越复杂，配置越来越多，一定程度上还是将复杂度留给了数据流的构建者。“对于简单的数据流，开发和运维都变得更简单了。而对于复杂且重要的数据流，我们的态度也一直是谨慎保守为主，避免盲目求新。”</p><p>&nbsp;</p><p></p><h4>流处理技术进化方向</h4><p></p><p>&nbsp;</p><p>关于SQL的说法，跟莫问预测流处理引擎未来进化方向之一是一致的，即：“全面 SQL 化，提升体验，降低门槛”。大数据处理从离线向实时升级的趋势已经确立，大量行业已经开始实时化升级，并取得非常好的业务收益。为了让更多用户能够享受到实时流计算带来的价值，流处理引擎需要进一步提升端到端的易用性，全面 SQL 化 ，提升用户体验，降低使用门槛，让流计算能够在更多场景和行业中被生产使用起来。</p><p>&nbsp;</p><p>云原生架构的不断发展，也同步推动了数据湖存储方案的加速落地。数据湖具备的开放和成本优势，必然使得越来越多的数据流入湖中，从而成为天然的数据中心，湖上建仓的Lakehouse 架构正在成为主流，下一步客户一定是希望数据在 Lakehouse 中能够更加实时的流动起来。</p><p>&nbsp;</p><p>Apache Paimon 是从 Flink 社区中孵化出来的新项目，定位就是流批一体实时数据湖格式，解决 Lakehouse 数据实时化的问题。</p><p>&nbsp;</p><p>基于 Flink + Paimon 可以构建出新一代的 Streaming Lakehouse 架构，让Lakehouse 上的数据可以全链路实时流动起来。此外，基于计算和存储端到端流批一体的特性，也更加方便用户在Lakehouse 架构上实现实时离线一体化的数据分析体验。</p><p>&nbsp;</p><p>“Paimon是一个好的尝试，”关涛对此评论道。</p><p>&nbsp;</p><p>之前Flink流批一体缺乏对应的存储系统配合：Flink自带的状态存储无法满足批处理通用数仓的需求，Paimon则是补全这个短板的关键。</p><p>&nbsp;</p><p>莫问指出，在实时流处理这条链路上，确实也存在一些新的机会和变化。众所周知，Flink 和 Kafka 目前已经分别成为流计算和流存储的事实标准，但 Kafka 真的是最适合流分析的存储方案吗？</p><p>&nbsp;</p><p>Kafka 和很多消息队列类似，都是一种消息中间件，而非为大数据分析而生。例如：Kafka 并未对数据提供结构化的 Schema 描述， 也无法提供完整的 Changelog 语义，且 Kafka 中的数据时无法进行实时更新和探查分析的。</p><p>&nbsp;</p><p>“但以上这些缺陷，都是实时流分析需要的特性和能力，我们也正在思考这个问题，并探索新的解决方案，希望能够在明年发布一款更加适合流分析的流存储技术。”</p><p>&nbsp;</p><p></p><h2>2023年，大数据技术栈的整体变化</h2><p></p><p>&nbsp;</p><p>近些年各种不同的大数据基础设施雨后春笋般的涌出，一方面为用户提供了多样化的选择，但另一方面也为用户带来了幸福的烦恼。通常情况下，用户要搭建一套大数据业务系统，需要非常多的核心技术组件才能完成，少则三到五种，多则五到十种，这主要带来以下几方面的问题：</p><p>技术组件繁多，必然提升系统架构的复杂度。通常来讲，系统稳定性风险和系统复杂度成正比，过于复杂的体系必然带来更大的稳定性隐患；每一项技术组件都需要有对应的专家来运维管理以及客户支持，对于中小企业来说，这必然带来高昂的人力资源成本；过多的同质化组件存在，也会为用户带来选择的困扰，并行保留多个同质化组件不仅给运维团队带来了额外的运维负担，也给开发者带来了额外的学习成本。</p><p>&nbsp;</p><p>因此，未来数据技术的演进会逐渐出现一些整合的趋势，走向更加简洁的架构，核心目标不仅是让每个组件运行得更快，还需要考虑为用户提供更加简单、一致性的开发体验，以及全局最优的运维成本。</p><p>&nbsp;</p><p>从Lambda架构到Kappa架构的演进。当前数据分析平台的典型架构是Lamdba架构（由三层系统组成：批处理BatchLayer，流处理层Speedlayer，服务层Servinglayer），随批、流、交互三种引擎诞生和成熟组装而成。这种架构的典型缺陷，包括复杂度高，数据冗余度高，学习成本/开发成本高等等。针对Lamdba架构的缺陷，Kappa架构应运而生。但多年过去了，Kappa架构仍然更像是参考架构，并没有很多引擎/平台做到Kappa架构的要求。2023年是个拐点，除了部分已有引擎开始拓展边界相互渗透，还有一些新的设计和计算模式被提出。例如云器科技提出“<a href=\"https://mp.weixin.qq.com/s/wnHr7ucatvCMu2I6oW_T9Q\">通用增量计算</a>\"”的新计算范式统：Lambda架构到SingleEninge，用一个引擎覆盖流批交互三种模式。</p><p>&nbsp;</p><p>目前业界主流的几款 Streaming、Batch 和 OLAP 引擎都开始相互渗透，例如：Flink 在发力流批一体、流批融合计算能力，Databricks 也基于 Spark 和 Delta 推动了Delta Live Table 淡化流批的差异，StarRocks 在提供 OLAP 极致查询能力的同时，也开始通过物化视图形态提供对数据湖上数据的 ETL 处理能力。本质上各大主流计算引擎都在不断扩展自己的能力边界，淡化流、批、OLAP边界，希望为用户提供全场景一致性的数据分析体验。这也是技术发展的必然趋势，各家都会逐渐补齐短板，但也都有各自核心的优势。</p><p>&nbsp;</p><p>在最近几年的数据技术趋势演进的路线中，我们可以清晰的看到两个趋势变化：一是数据架构的云原生化。几乎所有的大数据公司都选择了拥抱云原生，推出了基于多云的 PaaS/SaaS 计算服务，从 Serverless 到 BYOC，为用户提供了在云上不同类型的托管服务。二是数据分析的实时化。在技术上，数据的“实时化”包括了两个因素：数据的新鲜度，以及数据的查询速度。用户也不再盲目地只追求速度，而是更注重新鲜度、性能和成本的平衡。在时效性上，&nbsp;Iceberg赢得了更多关注，数据湖存储技术为我们提供了构建近实时（near-online）数仓的可能性，在成本不变的情况下可以支持更快、更多的流量数据。</p><p>&nbsp;</p><p>数据集成上，SeaTunnel成功毕业，Flink CDC 3.0演变成以&nbsp;Flink 为基础的端到端流式&nbsp;ELT 数据集成框架。比如作业帮目前主要在使用&nbsp;SeaTunnel 以降低异构数据源间数据处理的开发成本。</p><p>&nbsp;</p><p>社区希望能表格式能够统一，但实际还有一段路要走。</p><p>&nbsp;</p><p>Lakehouse平台在数据仓储领域的使用正迅速增加。这反映了一个重要的趋势：组织正从传统的数据处理平台过渡到更加灵活、集成和效率更高的现代数据架构。据2023年MIT Technology Review Insights报告，全球74%的首席信息官（CIOs）表示他们已经在使用Lakehouse架构。自Databricks在2020年推出此概念以来，Lakehouse作为一个新类别得到了广泛的采纳。几乎所有还未使用Lakehouse的首席信息官都计划在未来三年内部署此类平台。</p><p>&nbsp;</p><p>有专家认为，Lakehouse（湖仓一体）和Iceberg表格式已成为事实标准。但是，当前根据Slack users、 Github Stars、Github PRs、Github Forks、Issues各个指标显示，Delta、Hudi 和 Iceberg还是三分天下。虽然Delta、Iceberg 和 Hudi起源地不同，但是各个社区都在努力地提升开源社区的活跃度，让用户社区和开发者社区更加健康的发展。随着社区的竞争加速，基础功能的差异在不断减少。</p><p>&nbsp;</p><p>三种表格式（Table Format）均基于 Apache Parquet 数据格式，但这些格式各自会创建出相似、但又不尽相同的元数据，从而影响数据向应用程序和分析工作负载的表达方式。结果就是，Delta、Hudi 和 Iceberg 之间存在一定的不兼容性。表格式的最终统一还有难度，未来还得看哪种表格式能给出更好的性能、更好的易用性和更持续的创新能力，接下来的一年肯定更加精彩。</p><p>&nbsp;</p><p>头部的云厂商的产品都或多或少地支持不同的表格式。Snowflake、BigQuery、Athena都已支持Iceberg，而微软和Databricks都以Delta Lake为主要存储格式。因为当前数据处理引擎的格式支持缺陷，用户不得不将数据以不同格式存成多份。格式的兼容性读写会是未来一个值得关注的方向。比如10月份发布的Delta Lake 3.0增加了Delta UniForm通用格式，Delta Uniform 自动为Iceberg和Delta Lake生成元数据，提供了一个实时数据视图，而底层它们共享的同一份Parquet数据，因此用户可以避免额外的数据复制或转换。另外，同时能支持Hudi、Iceberg 和 Delta Lake的元数据自动转换和生成的 XTable 也于2023年底正在申请进入了Apache孵化器。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>GenAI来了</h2><p></p><p>&nbsp;</p><p>无论是大公司还是小公司，大家都渴望从生成式AI的热潮中分到一杯羹。当然，作为大公司，无论是Databricks还是Snowflake，它们确实更有实力来进行生成式AI的开发。</p><p>&nbsp;</p><p>今年Databricks不仅率先发布了开源可商用的大模型Dolly，还于6月底宣布以13亿美元的价格，收购生成式AI公司MosaicML 。</p><p>&nbsp;</p><p>在LLM服务方面，对数据栈的依赖主要集中在知识库的构建和查询上，包括但不限于向量数据库。有人认为在短期内很难看到深层次AI对数据湖或数据仓库方面带来重大变革，但也有人认为数据是服务于&nbsp;AI 的：大数据是燃料，大模型训练已经涵盖了大量已有的大数据技术，而数据湖则作为存储系统在其中扮演重要角色。</p><p>&nbsp;</p><p>Databricks李潇对此也进行了解释，他认为数据湖仓（Lakehouse）的作用是为GenAI提供了一个集中、高效和可扩展的数据存储和管理环境。它结合了数据湖的灵活性和数据仓库的高性能，支持结构化和非结构化数据的存储和处理，这是AI应用的数据需求的基石。</p><p>&nbsp;</p><p>“今年，Databricks的最大进展主要体现在将人工智能集成到数据平台中。“</p><p>&nbsp;</p><p>作为大数据行业里一个非常重要且典型的企业，Databricks在GenAI也反映了整个大数据行业的技术演进。现在我们可以通过它在数据智能平台投入来看看生成式AI将对数据和分析产生的影响。</p><p>&nbsp;</p><p>Databricks 是由一群 Apache Spark 的原创者所创建。Spark的诞生阶段，始于2010年，标志着Hadoop技术时代的结束。它的出现大幅降低了大数据处理的门槛，使得大数据开始与机器学习和人工智能结合，成为统一的分析引擎。2020年，Lakehouse架构的推出打破了传统数据湖和数据仓库的界限。Lakehouse架构结合了数据湖和数据仓库的最佳元素，旨在降低成本并加速数据及人工智能项目的实施。Lakehouse架构建立在开源和开放标准之上，它通过消除历史上复杂化数据和AI的孤岛，简化了数据架构。</p><p>&nbsp;</p><p>而现在，则是到了生成式AI大潮下的Lakehouse阶段。Databricks构建了一个基于数据湖仓（Lakehouse）的数据智能平台（Data Intelligence Platform），该平台的目标是实现数据和AI的平民化，使用自然语言极大简化了数据和AI的端到端体验。它利用生成式AI模型来理解数据的语义，并在整个平台中应用这种理解。可以让用户可以在保持隐私和控制的同时，从头开始构建模型或调整现有模型。</p><p>&nbsp;</p><p>同时，Databricks还提供了Unity Catalog数据治理工具来确保数据的质量和安全。Databricks还于今年推出了Lakehouse Federation (联邦查询) 的功能，用户可以跨多个数据平台（如MySQL、PostgreSQL、Snowflake等）发现、查询和管理数据，而无需移动或复制数据。另外，Databricks SQL（Lakehouse上的无服务器数据仓库）使用量也获得了大幅增长。</p><p>&nbsp;</p><p>Databricks认为，在不久的未来，每个领域的赢家都是那些可以最有效利用数据和AI的，并坚信对数据和AI的深刻理解是每个赢家的必备技能。</p><p>&nbsp;</p><p>未来的大数据架构将是一个高度集成、智能化和自动化的系统，它能够有效地处理和分析大量数据，同时简化数据管理和AI应用的开发过程，为企业提供竞争优势。</p><p>&nbsp;</p><p>“未来的大数据架构，我们可以称为‘数据智能平台（Data Intelligence Platform）’。它正是顺应了两个主要趋势：数据湖仓（Data Lakehouse）和生成式人工智能（AI）。”李潇表示。</p><p>&nbsp;</p><p>这一架构建立在数据湖仓的基础上，它提供一个开放、统一的基础，用于所有数据和治理，由一个理解用户数据独特语义的数据智能引擎(Data Intelligence Engine) 驱动。这是相对现有Lakehouse架构下的，最大的突破。</p><p>&nbsp;</p><p>智能化方面，这个引擎能理解客户数据的独特语义，使平台能自动优化性能和管理基础设施。操作简化方面，自然语言大大简化了用户体验。数据智能引擎理解客户的语言，使搜索和发现新数据就像询问同事一样简单。此外，自然语言还助力编写代码、纠错和寻找答案，加速新数据和应用程序的开发。</p><p>&nbsp;</p><p>在隐私保护方面，数据和AI应用需要强大的治理和安全措施，尤其是在生成式AI的背景下。提供一个端到端的机器学习运维（MLOps）和AI开发解决方案，该方案基于统一的治理和安全方法。这允许在不妥协数据隐私和知识产权控制的情况下，实现所有人工智能目标。</p><p>&nbsp;</p><p>总的来说，未来的大数据架构将更加重视智能化、操作简化和数据隐私，为企业在数据和AI应用方面提供竞争优势。这将使企业能更有效地利用数据，推动创新，同时保护数据安全和发展AI技术。</p><p>&nbsp;</p><p></p><h2>采访嘉宾简介（按姓名拼音排序）：</h2><p></p><p>关涛，云器科技联合创始人 &amp;CTO</p><p>李潇，Databricks 工程总监、Apache Spark Committer 和 PMC 成员</p><p>王峰（莫问），Apache Flink 中文社区发起人、阿里云开源大数据平台负责人</p><p>吴英骏，RisingWave（risingwave.com）创始人 &amp; CEO</p><p>张迎，作业帮大数据架构师</p><p>&nbsp;</p><p>更多阅读：</p><p>王峰（莫问）文字QA采访：<a href=\"https://www.infoq.cn/article/zK6T1A3HfolPsktP2Z1Z\">https://www.infoq.cn/article/zK6T1A3HfolPsktP2Z1Z</a>\"</p><p>李潇文字QA采访：<a href=\"https://www.infoq.cn/article/qcUuAu70UGm5AzO3g9MR\">https://www.infoq.cn/article/qcUuAu70UGm5AzO3g9MR</a>\"</p><p>&nbsp;</p><p>参考链接：</p><p>使用对象存储，数据湖才能重获新生：<a href=\"https://www.infoq.cn/article/JYoI8SgLbEdY68lWN5J4\">https://www.infoq.cn/article/JYoI8SgLbEdY68lWN5J4</a>\"</p><p>数据库的下一场革命：进入对象存储时代：<a href=\"https://www.infoq.cn/article/5wczTd6ItqtwYdrHhHWy\">https://www.infoq.cn/article/5wczTd6ItqtwYdrHhHWy</a>\"</p><p>上云还是下云：章文嵩博士解读真正的云原生 Kafka 十倍降本方案：<a href=\"https://www.infoq.cn/article/f4hJdZqtKAQdJvCKQYq7\">https://www.infoq.cn/article/f4hJdZqtKAQdJvCKQYq7</a>\"</p><p>RisingWave：重新定义流处理之旅：<a href=\"https://zhuanlan.zhihu.com/p/672964437\">https://zhuanlan.zhihu.com/p/672964437</a>\"</p><p>告别无休止性能 PK，带你看懂 Flink 真正技术演进之路：<a href=\"https://zhuanlan.zhihu.com/p/647747291\">https://zhuanlan.zhihu.com/p/647747291</a>\"</p><p>Single Engine + All Data ：云器科技推出基于“增量计算”的一体化湖仓平台：<a href=\"https://mp.weixin.qq.com/s/wnHr7ucatvCMu2I6oW_T9Q\">https://mp.weixin.qq.com/s/wnHr7ucatvCMu2I6oW_T9Q</a>\"</p><p>&nbsp;</p><p></p><blockquote>InfoQ&nbsp;2023&nbsp;年度技术盘点与展望专题重磅上线！与&nbsp;50+&nbsp;头部专家深度对话，探明&nbsp;AIGC&nbsp;创新浪潮下，重点领域技术演进脉络和行业落地思路，点击<a href=\"https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MjM5MDE0Mjc4MA==&amp;action=getalbum&amp;album_id=2717978015128879106&amp;scene=173&amp;subscene=227&amp;sessionid=1704178990&amp;enterid=1704178995&amp;from_msgid=2651192070&amp;from_itemidx=2&amp;count=3&amp;nolastread=1#wechat_redirect\">订阅</a>\"/<a href=\"https://www.infoq.cn/theme/229\">收藏</a>\"内容专题，更多精彩文章持续更新~另，InfoQ&nbsp;年度展望系列直播最后一场将于&nbsp;2024&nbsp;年&nbsp;1&nbsp;月&nbsp;22&nbsp;日开播，主题为《代码人生攻略：程序员们如何为自己编织一份明朗未来？》，我们邀请到了章文嵩、周爱民、李博源、陶建辉四位重量级大咖，通过分享各自的职业心得和技术洞察，帮助大家更好地为未来发展做好准备。关注&nbsp;InfoQ&nbsp;视频号，与行业技术大牛连麦~</blockquote><p></p>",
    "publish_time": "2024-01-17 14:16:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "大模型时代的技术管理“新思维”",
    "url": "https://www.infoq.cn/article/HJOC4qt3mTCtsicJ4msb",
    "summary": "<p>在大模型时代，技术管理面临着新的挑战和机遇。为了更好地应对这些挑战，管理者需要转变思维方式，重新审视技术管理的本质和目标。1 月 15 日晚 8 点，InfoQ 特邀某股份制银行数字化转型技术专家王辉，对话 Thoughtworks 中国区总经理肖然、云知声董事长 &amp;CTO 梁家恩，飞书项目前端负责人 李梦泽一起探讨大模型时代下的技术管理新思维，共同迎接未来的挑战和机遇。</p>\n<p>直播亮点<br />\n如何评估和选择适合企业的大模型技术？</p>\n<p>大模型时代，技术管理的方式方法和大模型出现之前有何不同？</p>\n<p>如何平衡技术创新与业务需求，实现技术与管理的高效融合？</p>",
    "publish_time": "2024-01-17 15:33:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "大语言模型综合能力测评报告2024",
    "url": "https://www.infoq.cn/article/0xhGee6fTUuzDNbj7FdU",
    "summary": "<h3>研究背景</h3>\n<p>InfoQ研究中心近期专注于大型语言模型产品的市场动态和性能特点，深入分析了这些模型在多个关键维度上的表现。本研究围绕语义理解、文学创作、知识问答、逻辑推理、编程、上下文理解、语境感知、多语言处理及多模态交互等十大核心领域，对包括ChatGPT-4、文心一言专业版、通义千问V2.1.1、Bard2.0、讯飞星火V3.0、Kimi Chat网页版、百川大模型V1.0、智谱清言网页版、360智脑4.0和豆包在内的十款热门模型进行了全面评估，测试题目数量超过3000道。</p>\n<p>在本次研究中，我们特别增加了对逻辑推理、商业写作及多模态能力这三个关键领域的测试权重和比例，以更准确地评估各模型在这些重要方面的实际表现。InfoQ研究中心希望通过这次评估，帮助技术领域的同仁更深入地了解国内外大型模型产品的性能、稳定性和准确性，从而为大模型的持续进步和应用实施提供参考和助力。</p>\n<h4>中国大模型及产品图谱</h4>\n<p><img alt=\"\" src=\"https://static001.infoq.cn/resource/image/1a/ea/1a05d63437b2a95fed23323084df96ea.png\" /><br />\n进入2023年下半年，国内的大型模型已经进入了一个显著的成长阶段。不仅模型的数量呈现出爆炸式的增长趋势，而且模型的质量也在持续提升。随着首批国产大型模型完成备案并向公众开放，这些模型正在越来越多地进入用户的视野和认知中。</p>\n<p>据最新统计数据显示，在目前的市场上，GPT系列大型模型和百度文心大型模型已经稳居第一梯队，受到了广泛的关注和应用。近半数的受访开发者表示，他们了解或使用过这两款模型，这充分证明了它们在行业内的领先地位和影响力。</p>\n<p>而阿里通义大型模型、LLaMA 2、讯飞星火大型模型、华为盘古大型模型以及智谱Chat GLM 3大型模型则构成了第二梯队。这些模型也受到了不少开发者的关注和使用，超过五分之一的受访者表示了解或使用过它们。</p>\n<p>此外，还有一批新兴的大型模型正在崭露头角，它们包括百川大型模型、Stable Video、Diffusion、昆仑万维天工大模型、360智脑大型模型、MOSS大型模型、智源悟道大型模型以及商汤科技的商量Sense Chat等，这些模型共同构成了第三梯队。<br />\n<img alt=\"\" src=\"https://static001.infoq.cn/resource/image/55/ce/5575e53dbaa486b476e629559ec0f6ce.png\" /></p>\n<blockquote>\n<p>上图数据来源：2023年12月InfoQ发起的用户调研，N=1217</p>\n</blockquote>\n<h3>测评结果</h3>\n<p>相较于2023年5月的测试结果，本次测试的整体得分率平均提升了 23.39%，各项性能均取得了明显的进步。反映大模型基础能力的认知和学习能力稳步提升，历史、地理、商业、医学、科学等领域，大模型依旧保持高水平。值得一提的是，反映大模型进阶能力的题目得分率平均提升了 35.77%；文生图、文生语音的多模态题目得分率相较于以往提高了近20倍，文心一言专业版、讯飞星火、ChatGPT-4等多项产品开始展现出强大的多模态能力，为大模型的发展开辟了更广阔的前景。</p>\n<h4>测评领域整体得分情况</h4>\n<p><img alt=\"\" src=\"https://static001.infoq.cn/resource/image/f5/1d/f58c2923170d4ea84a1a1578a0c4f21d.png\" /></p>\n<h4>与2023年5月的测评结果对比</h4>\n<p><img alt=\"\" src=\"https://static001.infoq.cn/resource/image/2a/39/2afb1a60a1d9e59c866e84e7ec1a9339.png\" /></p>\n<h4>各大语言模型测评结果</h4>\n<p>根据测试结果显示，ChatGPT-4的综合能力位居第一，文心一言专业版以82.90%的综合得分位列榜单第二名。令人惊喜的是，文心一言的得分与ChatGPT得分非常接近，仅仅落后0.42%。<br />\n<img alt=\"\" src=\"https://static001.infoq.cn/resource/image/7f/e8/7fe023feccdaaf25cab7a0f38c2751e8.png\" /></p>",
    "publish_time": "2024-01-17 16:48:33",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "国产GTPs上线！智谱AI推出GLM-4全家桶，我们浅试了一下",
    "url": "https://www.infoq.cn/article/y0D3pe0fW1O3dsVI1Te8",
    "summary": "<p>1月16日，智谱AI团队全面展示了其投身于大模型事业三年多来所积累的技术成果，并重磅发布了新一代基座大模型GLM-4。</p><p>&nbsp;</p><p>根据智谱AI的介绍，GLM-4的整体性能相比上一代大幅提升，逼近GPT-4。具体包括：支持128k的上下文窗口长度，单次提示词可以处理的文本可以达到300页；在needle test（大海捞针）测试中，128K文本长度内GLM-4 模型均几乎100%的精度召回，并未出现长上下文全局信息因为失焦而导致的精度下降问题等。</p><p>&nbsp;</p><p>在多模态能力方面，我们也进行了尝试：（生成等待时间有点长，我们剪辑了下～）</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/f2/f2aa444e6f2ed7983a20ae7bc2ae74bc.gif\" /></p><p></p><p>&nbsp;</p><p>输入“以智谱AI发布大模型为主题，制作一张图片”，最后生成的图片如下：</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/47/474339c97223ee4f41984cf0e0201725.jpeg\" /></p><p></p><p>&nbsp;</p><p>想看GML-4和GPT-4对比的“数据党”，可以看如下对比：</p><p>&nbsp;</p><p>GLM-4 在 MMLU（81.5）达到 GPT-4 的94%；GSM8K（87.6） 达到 GPT-4 的95%；MATH（47.9）达到 GPT-4的 91% ；BBH （82.25） 达到 GPT-4 的99%；HellaSwag （85.4） 达到 GPT-4 的90% ；HumanEval（72）达到 GPT-4 的100% 水平。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/1a/1aa473855c20c308b70c28239de7af21.jpeg\" /></p><p>&nbsp;</p><p>此外，GLMs个性化智能体定制能力同步上线。</p><p>&nbsp;</p><p>用简单的提示词指令就能创建属于自己的GLM智能体并分享：（等待时间也略长，我们剪辑了下～）</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/87/87752fa75046c278459988ee3be597d4.gif\" /></p><p></p><p>&nbsp;</p><p>&nbsp;想尝试的朋友可以智谱清言官网：<a href=\"https://www.chatglm.cn/\">https://www.chatglm.cn/</a>\"</p><p>&nbsp;</p><p>智谱AI CEO张鹏同时表示，GLMs模型应用商店、开发者分成计划也即将发布。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/47/479f5afae5a4f64449f1ad7d44bd333a.png\" /></p><p></p><p>&nbsp;</p><p>此外，GLM-4的 All Tools 能力全新发布。</p><p>&nbsp;</p><p>基于GLM模型的Agent能力，GLM-4实现了自主根据用户意图，自动理解、规划复杂指令，自由调用网页浏览器、Code Interpreter代码解释器和文生图CogView3模型。</p><p>&nbsp;</p><p>GLM-4 通过代码解释器，会自动调用代码解释器进行复杂的方程或者微积分求解。对比GSM8K、Math以及Math23K三个数据集上的结果，GLM-4 All Tools取得和GPT-4 All Tools相当的效果。</p><p>&nbsp;</p><p>处理各种任务，比如包括文件处理、数据分析、图表绘制等复杂任务，支持处理 Excel、PDF、PPT 等格式的文件。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/41/41cf5176e5cadb4c76c180657a7db8af.jpeg\" /></p><p>&nbsp;</p><p>2024年，智谱AI也将发起开源开放的大模型开源基金，该计划包括三个“一千”：智谱AI将为大模型开源社区提供一千张卡，助力开源开发；提供1000万元的现金用来支持与大模型相关的开源项目；为优秀的开源开发者提供1000亿免费API tokens。</p><p></p><p>张鹏表示，大模型开源基金的目的在于推动大模型研发的大进展，促进大模型整个开源生态的大繁荣。面对全球的大模型创业者，智谱AI也将“Z计划”进一步升级，联合生态伙伴发起总额10亿人民币的大模型创业基金用于支持大模型原始创新，覆盖大模型算法、底层算子、芯片优化、行业大模型和超级应用等方向。</p><p></p><p>已经尝试了GLM-4的小伙伴，快来说说你的使用体验呀～</p>",
    "publish_time": "2024-01-17 17:29:45",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "网易有道自研RAG引擎QAnything正式开源，可增强大语言模型准确度及专业能力",
    "url": "https://www.infoq.cn/article/olJogN70vCLWjPbROC1Y",
    "summary": "<p>1月16日，网易有道宣布自研的知识库问答引擎QAnything正式开源，除了可以调用云端大模型服务，还支持纯本地部署，所有用户可免费在开源社区Github内进行下载，一键部署即可使用。该系统目前支持word、ppt、excel、pdf、图片等多种文档格式，直接导入进去即可实现像\"ChatGPT\"一样问答。</p><p>&nbsp;</p><p>据悉，QAnything的主要原理是基于检索增强的生成（Retrieval Augmented Generation，简称RAG），能够利用检索外部内容的方式增强大语言模型的准确度、专业能力和个性化等各方面的性能。</p><p>&nbsp;</p><p>QAnything作为有道自研的RAG引擎，结合了用户私有数据和大模型的优势——用户的任何内容，以任意的形式存在，比如各种格式的文档，音频，数据库等，都可以在QAnything的支持下，变成可以针对其内容进行问答的使用方式，通过这个技术框架用户可以很方便地搭建自己的智能知识助手。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7c/7ceba69dd6e340b069c8ea8909ab6366.png\" /></p><p>&nbsp;</p><p>值得一提的是，本次开源的QAnything是一套完整的RAG系统，包括专门优化的自研的embedding和rerank模型，微调后的LLM，优化后的推理代码，向量数据库，以及一个立即上手可用的前端。所有的算法模型（包括7B大模型+embedding/rerank+OCR）占用显存不超过16G。</p><p>&nbsp;</p><p>如今，QAnything已在有道的多个产品中应用，包括有道翻译文档问答、有道速读及有道内部业务的客服系统等。以子曰教育大模型最新发布的创新应用成果“有道速读”为例，有道速读内置了文档问答、文章摘要、要点解读、引文口碑和领域综述五大功能，能够帮用户更快更准地获得信息和对文档的理解。而该功能背后的驱动就是QAnything，在大模型技术的加持下，用户能够实现快速理解文档、定位要点，实现1分钟读完万字长文。</p><p>&nbsp;</p><p>“目前，QAnything项目还在不断迭代，欢迎大家参与开发，并给予我们更多反馈。我们希望能帮助有需要的开发者们，和更多伙伴一起推动大模型的落地。”网易有道首席科学家段亦涛介绍道。</p>",
    "publish_time": "2024-01-17 17:44:25",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "字节跳动开源 Gödel Scheduler：在离线统一调度器",
    "url": "https://www.infoq.cn/article/14WP6FKreY2uWfPGF8Yx",
    "summary": "<p>作为字节跳动在离线混部场景中最核心的调度系统，Gödel&nbsp;提供丰富的资源 QoS 管理能力，可以统一调度在线和离线应用，极大提升资源利用率。</p><p></p><p>来源&nbsp;| KubeWharf 社区</p><p>项目 |&nbsp;github.com/kubewharf/godel-scheduler</p><p></p><p>自 2014 年开源以来，Kubernetes&nbsp;迅速成为容器编排领域内的事实标准，字节跳动基础架构团队也早早确定了以 Kubernetes 为底座构建私有云平台。</p><p></p><p>在过去的几年里，随着字节跳动各业务线的高速发展，公司内部的业务种类也越来越丰富，包括微服务、推广搜（推荐/广告/搜索）、机器学习与大数据、存储等，支撑业务发展所需的计算资源体量也在飞速膨胀。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5d/5de53aa0886ed2b9d3e1f6a5b9223f02.png\" /></p><p></p><p>早期字节跳动的在线业务和离线业务有独立的资源池，业务之间采用分池管理。为了应对重要节日和重大活动时在线业务请求的爆炸性增长，研发团队往往要提前做预案，将部分离线业务的资源拆借到在线业务的资源池中。</p><p></p><p>虽然这种方法可以应对一时之需，但不同资源池之间的资源拆借流程长、操作复杂、效率很低。同时，独立的资源池会导致在离线业务之间混部成本很高，资源利用率提升的天花板也非常有限。所以，基础架构团队希望能使用同一套系统来统一调度和管理在离线业务，实现资源并池，在提升利用率和资源弹性的同时，优化业务成本和体验，降低运维压力。</p><p></p><p></p><h1>字节跳动在离线混部统一调度</h1><p></p><p></p><h2>增强 Kubernetes Default&nbsp;Scheduler</h2><p></p><p></p><p>自 2018 年起大规模使用 Kubernetes 之后，字节跳动一直在优化 Kubernetes 各个组件的功能和性能。随着 2019 年推广搜业务的容器化，原生 Kubernetes 调度器逐渐无法满足业务发展的需求——</p><p>功能上，我们需要更细粒度的资源调度能力，更灵活的抢占策略；性能上，原生 Kubernetes default Scheduler 在 5000 节点的集群规模下，调度吞吐只能勉强达到 10 Pods/s，经常造成业务升级卡单，远远无法满足要求。</p><p></p><p>基于此，我们对 Kubernetes Default Scheduler 做了比较大的优化，主要如下：</p><p></p><p>【功能】扩展非原生资源调度能力，支持内存带宽，网络带宽等多种资源调度；【功能】支持微拓扑调度；【功能】重构抢占实现，提供抢占框架，支持插件化扩展抢占策略能力；【性能】优化 Scheduler cache 到 Snapshot 数据同步实现，抽象，拆分数据存储，进一步贯彻“增量更新”理念；【性能】调度结果缓存，降低重复计算，提高效率；【性能】抢占实现优化，重新组织抢占相关数据结构，抢占过程中及时剪枝，降低无效计算量。</p><p></p><p>通过上述一系列的优化，我们很好地支持了字节跳动内部的推广搜业务容器化项目：调度吞吐相比原生调度器提升了几十倍；在一万节点规模的生产集群中，调度吞吐可以稳定到达 300 Pods/s。</p><p></p><p></p><h2>Gödel Scheduler</h2><p></p><p></p><p>从 2020 年开始，字节跳动启动在离线融合项目，希望可以通过并池进一步提高资源利用率，同时提升资源流转效率、降低运维成本。</p><p></p><p>在项目早期，基础架构团队就计划用一套调度系统管理在离线业务，真正做到统一调度。由于离线业务的调度需求比较复杂，与在线业务差别比较大，吞吐要求也很高；加上 Kubernetes 原生调度器是基于 Pod 调度，对更上一级 “Job” 级别的调度语义支持能力有限；同时由于原生调度器是单体调度器，性能优化的天花板也较低，比较难满足部分批式计算任务的需求——我们决定基于 Kubernetes 系统自研分布式调度器：Gödel Scheduler。</p><p></p><p>Gödel Scheduler 是一个能统一调度在线和离线业务的分布式调度器，能在满足在离线业务功能和性能需求的前提下，提供良好的扩展性和调度质量。</p><p></p><p>Gödel Scheduler 具备如下主要特点：</p><p></p><p>基于 K8s Scheduler，结合乐观并发思想，把最耗时的应用到节点匹配（filtering and scoring）操作放在 scheduler 组件，可以并发执行，提高大规模集群调度吞吐；两层调度语义抽象（Unit 和 Pod）和二级调度框架实现：提供更灵活的“批”调度能力，更好支持离线业务的同时，可以进一步提高调度吞吐和提升系统扩展性 （扩展后的框架可以更好地处理一些特殊场景）；丰富的功能和优秀的性能，满足在线，离线（批，流）和训练等业务需求，真正做到统一调度；兼容 Kubernetes 生态，可以替换 K8s Scheduler；由于性能以及架构优化，在 framework interface 上与 K8s Scheduler 不完全一样，但扩展性不受影响，也可以像 Kubernetes 一样实现 scheduling plugin。</p><p></p><p>Gödel Scheduler 的架构如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/50/5087e85643ac7d86daa6807501673b3f.png\" /></p><p></p><p>可以看到，Gödel Scheduler 由三个组件组成：Dispatcher、Scheduler&nbsp;和&nbsp;Binder。其中，Scheduler 组件是多实例，乐观并发调度， Dispatcher 和 Binder 则是单实例。</p><p></p><p></p><h3>Dispatcher</h3><p></p><p></p><p>Dispatcher 主要负责应用排队，应用分发，节点分区等工作。它主要由几个部分构成：Sorting Policy Manager、Dispatching Policy Manager、Node Shuffler、Scheduler Maintainer 和 Reconciler。其中：</p><p></p><p>Sort Policy Manager：主要负责对应用进行排队，现在实现了 FIFO， DRF/FairShare （没上线生产环境） 排队策略，未来会添加更多排队策略，如：priority value based 等；</p><p></p><p>Dispatching Policy Manager：主要负责分发应用到不同的 Scheduler 实例，现阶段是默认策略：LoadBalance，未来会增强该功能，做成插件化配置模式；</p><p></p><p>Node Shuffler：主要负责基于 Scheduler 实例个数，对集群节点进行 Partition 分组，每个节点在一个 Partition 里面，每个 Scheduler 实例对应一个 Partition，Scheduler 调度的时候会优先选择自己 Partition 节点，没有合适的情况下，才会去找其他 Partition 的节点。如果 Node 增删或者 Scheduler 个数变化，会基于实际情况重新分配节点；Partition 规则现在是基于 Scheduler 个数平均分配，未来会增强，Partition 策略可配置；</p><p></p><p>Scheduler Maintainer：主要负责对 Scheduler 实例状态进行维护，包括 Scheduler 实例健康状况、负载情况、Partition 节点数等；</p><p></p><p>Reconciler：主要负责周期性的检查 Pod、Node、Scheduler、SchedulingUnit 等状态，修正错误状态，查漏补缺。</p><p></p><p></p><h3>Scheduler</h3><p></p><p></p><p>Scheduler 主要负责为应用做出具体的调度和抢占决策，但是不真正执行（执行者是 Binder）。它由两级框架组成：Unit scheduling framework 和 Pod scheduling framework。整个调度过程主要分为三大部分：Node Organizing、Unit Scheduling 和 Unit Preempting。</p><p></p><p>Node Organizing：基于一些规则过滤节点减少后面流程计算量，以及为节点进行排序，为了更快调度上或者获得更好的调度质量。主要有两类插件：</p><p></p><p>Locating plugins：基于应用，过滤掉不符合要求节点，比如：Local PV，DaemonSet Pods，Resource Reservation， Rescheduling 等，共同点是：可以基于应用信息，过滤掉大部分节点，减少后面流程计算量，提升调度吞吐；</p><p></p><p>Node Grouping plugins：为通过 Locating plugins 的节点进行分组，比如：基于节点剩余资源量进行分组，或者基于 Job level affinity 里面的拓扑信息进行节点分组等，为的是能更快调度上或者获得更好的调度质量。</p><p></p><p>Unit scheduling：基于应用请求，对通过 Node Organizing plugins 的节点进行匹配筛选和打分，类似 K8s Scheduler framework，Unit scheduling 阶段也有两类插件：</p><p></p><p>Filtering plugins：基于应用请求，过滤掉不符合要求的节点；Scoring plugins：对上面筛选出来的节点进行打分，选出最合适的节点。</p><p></p><p>Unit Preempting：如果 Unit scheduling 阶段没有合适的节点直接调度，则会进入抢占阶段，该阶段会尝试为待调度应用去抢占正在运行的应用实例，看是否有合适节点可以摆放。该阶段也有两类插件：</p><p></p><p>Victim Searching：遍历集群节点，尝试搜索 victims （被抢占应用），看是否能找到节点和 victims；</p><p></p><p>Candidates Sorting：如果上面步骤找到了合适的节点和 victims，则会为这些 victims 进行排序（节点粒度），选出最合适的节点和 victims。</p><p></p><p></p><h3>Binder</h3><p></p><p></p><p>Binder 主要负责乐观冲突检查，执行具体的抢占操作（删除 victims），进行应用绑定前的准备工作，比如动态创建存储卷等，以及最终执行绑定操作。它主要由 ConflictResolver、PreemptionOperator 和 UnitBinder 三部分组成。</p><p></p><p>ConflictResolver：主要负责并发冲突检查，一旦发现冲突，立即打回，重新调度。Conflict resolver 有两大类：Cross node conflict resolver 以及 Single node conflict resolver。</p><p></p><p>Cross node conflict resolver: 负责检查跨节点冲突，比如：某个拓扑域调度限制是否仍然能满足等，由于该节点跨节点，Binder 必须串行执行；</p><p></p><p>Single node conflict resolver: 单节点内冲突检查，比如：节点资源是否仍然足够等，该节点检查的逻辑限制在节点内部，所以不同节点的检查可以并发执行（unit 内 pods 调度到不同节点）。</p><p></p><p>PreemptionOperator：如果没有冲突，同时应用需要抢占，则执行抢占操作，删除 victims，等待最终调度；</p><p></p><p>UnitBinder：主要负责绑定前准备工作，比如：创建 volume 等，以及执行真正的绑定操作。</p><p></p><p>现在的版本，Binder 里面还集成了一个&nbsp;PodGroup controller&nbsp;实现，负责维护 PodGroup 的状态以及生命周期，后期会从 Binder 里面移除，独立成一个 Controller。</p><p></p><p></p><h1>落地成果与 Roadmap</h1><p></p><p></p><p>在过去两年里，Gödel Scheduler 已在字节跳动内部大规模落地，提供丰富的调度语义和功能，包括但不限于 Gang、Job level affinity、微拓扑调度、丰富的排队策略、抢占策略以及调度策略等，它高效稳定地支撑着抖音、今日头条等内部多种复杂业务的运行。</p><p></p><p>除了架构优化以外，我们还基于以前优化 Kubernetes 原生调度器的经验，对 Gödel Scheduler 的实现进行了更深度的性能优化。结合内部优化过的 Kubernetes 系统，Gödel 调度器单分片吞吐可达2000+ Pods/s, 多分片可达&nbsp;5000+ Pods/s。基于此，我们也在不断提升单集群规模，目前字节跳动内部最大的线上单集群规模已经达到20000+&nbsp;节点、100w+ Pods。</p><p></p><p>经过内部多年反复验证，目前&nbsp;Gödel 系统已达相对稳定状态。2023 年，云计算领域顶会&nbsp;SoCC&nbsp;接受了相关论文&nbsp;Gödel: Unified Large-Scale Resource Management and Scheduling at ByteDance，并邀请研发团队在现场做了报告。(查看论文：<a href=\"https://dl.acm.org/doi/10.1145/3620678.3624663\">https://dl.acm.org/doi/10.1145/3620678.3624663</a>\"）</p><p></p><p>为了更好地回馈开源社区，我们也决定开源&nbsp;Gödel Scheduler，为业界提供一种新的调度器方案。在离线业务云原生化、在离线业务融合等场景下，Gödel Scheduler 凭借优异的性能和丰富的调度语义，能为用户带来全新的云原生体验。</p><p></p><p></p><h2>未来规划</h2><p></p><p></p><p>未来，开源团队计划持续迭代 Gödel scheduler，提供更加丰富的功能和更好的扩展性，不断优化一些特殊场景下（比如高部署率，高抢占频率等）的调度吞吐。同时，通过重调度的方式，我们也希望解决调度性能和调度质量难兼顾的难题，在保证调度吞吐的基础上，大幅提升调度质量。我们也将注重生态建设，兼容适配业务主流的系统和框架。</p><p></p><p></p><h3>调度质量提升：重调度</h3><p></p><p></p><p>我们在实践中发现，调度器没有办法独立解决所有的问题。比如调度器没有办法在保证高性能的情况下，也取得比较好的调度质量。尤其是集群的状态在不断变化，调度器初次调度时给出的业务摆放位置在一段时间后可能变得不再合理。</p><p></p><p>针对这个问题，字节跳动内部的方案是让 Gödel Scheduler 优先满足业务对性能的要求，初次调度尽力而为。与此同时，我们设计并实现了重调度器&nbsp;Gödel Rescheduler，用于在业务初次调度之后，根据当时的实际情况进一步改善业务和资源匹配，优化调度质量。</p><p></p><p>Gödel Rescheduler 是一个真正意义上的重调度器，除了驱逐不合理的任务摆放之外，还可以从全局视角出发，结合集群的当前状态，给出任务更合理的摆放位置，并和 Gödel Scheduler 一起，推动业务重调度、优化调度质量。</p><p></p><p>此外，Gödel Rescheduler 的 plugin 机制支持一系列可定制的重调度算法和策略（如：可降低资源碎片率的 Binpacking 算法，可提高资源均衡性，降低单机热点的 load balance 策略等），满足计算资源提供方和使用方在不同场景下的不同诉求。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3d/3d4074de5c0c85d0d8b432211eafbd90.png\" /></p><p></p><p></p><h3>调度功能丰富</h3><p></p><p></p><p>Gödel Scheduler 开源团队计划开源更多调度功能，如资源预留、队列间资源管理能力等。</p><p></p><h3>生态建设</h3><p></p><p></p><p>未来，Gödel Scheduler 也将对接业界主流大数据和机器学习框架系统，提供使用样例和说明文档。</p>",
    "publish_time": "2024-01-17 18:13:07",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]