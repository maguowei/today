[
  {
    "title": "“向量数据库”还是“向量搜索插件 + SQL 数据库”？PingCAP 黄东旭：我对 2024 年数据库发展趋势的思考",
    "url": "https://www.infoq.cn/article/svZdfhLYsZrv45RWs5kw",
    "summary": "<p>如果我们用一个词来总结 2023 年的数据技术领域，那个词无疑是“急速变革”。我们见证了数据库内核技术与云原生架构的融合演进，AI+Data 的浪潮涌现，以及用户工作负载的深刻转变。GenAI 时代的到来，就像一股不可抗拒的潮流，推动着数据技术的每一朵浪花，朝着更智能化、更灵活化的巨浪之海奔流。</p><p></p><p>2023 年，我们的眼前充满了夺目的 AI Demo 与炫技，你追我赶。转眼间，当我们步入 2024 年，这个年份将因为 “AI 在从 Demo 到真实场景落地”的急剧转变而被人们记住。随着开源大模型成本的加速下降，企业和开发者对数据的关注也急剧上升，对数据的关注度将很快取代对模型的关注度。有预测认为，在 2023 年，用户愿意在 AI 模型上投入 80% 的预算，然而在未来这一两年里，随着模型成本的降低，这一比重可能会逆转，用户将更多的投资（甚至大于 80%）倾向于数据，数据处理和分析能力变得更加重要。</p><p></p><p>毫无疑问，AI 将会对数据处理提出非常多新的诉求，数据技术领域也会面临着多重挑战与机遇，AI 正在重塑数据技术的全新生态。我们不禁要问：在 GenAI 的大潮中，选择 “向量数据库”还是“以 SQL 数据库作为核心，添加向量搜索插件”？数据库如何应对 Gen AI 对数据库扩展性和实时交互的诉求？浪涌般海量数据的实时查询会不会带来巨大的成本压力？AI 带来的自然交互方式催生怎样的开发者体验 ？这些问题将在本文中一一解答</p><p></p><h2>预测一</h2><p></p><p></p><p>“向量数据库”还是“向量搜索插件 + SQL 数据库”？这是一个答案很明确的问题。</p><p></p><p>如果说过去 CRUD 应用是对数据库访问的静态封装，那么随着 GenAI 的普及，尤其是 Chatbot 或 Agent 的产品形态，对数据的使用会是更加灵活和动态的。过去，集中的数据存储和应用是因为技术的局限，很难为个人提供个性化的服务，尽管现代的 SaaS 其实很希望往这个方向发展，但是为每个用户都提供个性化的体验对算力和开发的挑战太高，而 GenAI 和 LLM 将提供个性化服务的成本降得很低（可能就是几段 Prompt），以至于对于数据库而言，带来几个变化：</p><p></p><p>个人（或一个组织）产生的数据价值会变得越来越高，但这类数据通常不会很大GenAI 会使用更加动态和灵活的方式直接访问数据，这样效率最高对数据的访问从边缘发起（从 Agent 或者 GenAI 直接发起）</p><p></p><p>一个很好的例子是 GPTs， GPTs 支持通过的自定义的 Prompt 和用户提供的 RESTful API 来创建自己的 ChatGPT，基础的 ChatGPT 会在它认为需要的时候以灵活的方式调用你给定的 Action。这个调用发生方式和参数是后端的 Action 提供者无法预料的。而且可以预料的是很快 GPTs 将会提供标记个人身份信息的机制，这样对于 Action 的提供者来说，相当于后端的数据库有了最重要的索引：UserID，剩下的就很好理解了。</p><p></p><p>这里你可能会提出质疑，RAG 不是标准的做法吗？但现有的 RAG 构建的方式几乎都是静态的，而知识应该是可以实时被更新的，这里不得不提到向量数据库。</p><p></p><p>对向量的支持，在去年是数据库迭代的一个热门方向，产生了很多专门的向量数据库， 但是我认为，更丰富的数据访问接口，使得向量搜索成为标配，然而 SQL 仍然是基石。向量搜索并不值得专门使用一个独立的数据库来支持，更应该是现有的数据库中的一个功能，就像：</p><p></p><p><code lang=\"sql\">Plaintext\nRust   INSERT INTO tbl (user_id, vec, ...) VALUES (xxx, [f32, f32, \nf32 ...], ...);   SELECT * FROM tbl WHERE user_id = xxx and \nvector_search([f32,f32,f32,f32 ...])\n</code></p><p></p><p>类似的访问可能是更符合开发者直觉的。</p><p></p><p>而关系型数据库天然支持插入和更新，另外配合向量索引的搜索能力，便可以将 RAG 变成一个可以实时更新实时查找的正反馈循环（利用 LLM 引入进行二次的 Summary ，然后将更新的 Index 储存在 DB 中）。更重要的是，关系型数据库的引入消除了向量数据库带来的数据孤岛的问题，当你可以将向量索引筛出来的数据关联（JOIN）到同一个 DB 中其他的数据的时候，灵活性带来的价值就得以显现。</p><p></p><p>另一个好处是，Serverless 的产品形态，同样也将数据的所有权归还给用户本人，大家思考一下，在我们熟知的 Web2 时代，我们的数据是隐藏在一个个互联网公司的服务背后的黑箱，我们没有办法直接访问；而在 GenAI 的应用场景下，数据的交互变成一个三角的关系，用户 - 数据 (RAG) - GenAI。很有意思的是，这个正是 Web3 的理想之一，GenAI 的普及很可能顺手也将 Web3 想实现的将数据的所有权交还给用户的理想，这在 Web2 时代是不可能实现的，这其实是一种技术理想的回归。</p><p></p><p>当然，我相信在未来 RAG 会成为数据库的很重要的一种新应用场景，在这种场景中 Serverless 形态提供的云数据库服务会变成标准化的。</p><p></p><h2>预测二</h2><p></p><p></p><p>由高价值数据驱动的应用成为 GenAI 应用的主流，弹性与实时交互成为数据库能力的基石。</p><p></p><p>在预测一里我们提到， GenAI 时代的应用要求知识和数据是可以被实时更新的，这对数据库的弹性以及实时交互提出了非常直接的需求。</p><p></p><p>数据库的可扩展性一直是过去十年间，业界关注的重点之一。根据我们的观察，大多数单一在线业务，100TB 已经是很大规模，而这个规模下的一般 OLTP 业务，已经可以被市场上很多系统自信的解决。</p><p></p><p>但这些数据库大多是 Shared Nothing 的系统，Shared nothing 的系统通常会有一个假设：在集群中的节点是对等的，只有这样数据和 Workload 才能均匀的分散在各个节点上。这个假设对于海量数据 + 访问模式均匀的场景没有问题，但是仍然有很多的业务具有明显的冷热特征，尤其是在 GenAI 带来的数据访问方式越来越动态和灵活的 2024 年及以后。</p><p></p><p>我们最经常处理的数据库问题之一就是局部热点。如果数据访问倾斜是一个业务的天然属性的话，对等的假设就不再是合理的，更合理的方式是将更好的硬件资源倾斜给热点的数据，而冷数据库使用更廉价的存储，例如，TiDB 从一开始将存储节点（TiKV）/ 计算节点（TiDB）/ 元信息（PD）分离，以及在后来 TiDB 5.0 中引入自定义 Placement Rule 让用户能够尽可能决定数据摆放策略，就是为了尽可能弱化节点对等假设。</p><p></p><p>但是更终极的解决办法在云端，在基本的扩展性问题得到解决后，人们开始追求更高的资源利用效率，在这个阶段，对于 OLTP 业务来说，我想可能更好的评价标准是 Cost Per Request。因为在云端，计算和存储的成本差别是巨大的，对于冷数据来说，如果没有 Traffic，你甚至可以认为成本几乎为 0，但是计算却是昂贵的，而在线服务不可避免的需要计算（CPU 资源），所以高效利用计算资源，云提供弹性将成为关键。</p><p></p><p>另外，请不要误解 ，弹性并不意味着便宜，on-demand（ 随需提供的 ）的资源在云上通常比 provisioned（预分配）的资源更贵，持续的 burst 一定是不划算的，这种时候使用预留资源更合适，burst 那部分的成本是用户为不确定性支付的费用。仔细思考这个过程，这可能会是未来云上数据库的一种盈利模式，</p><p></p><p>与弹性同样重要的需求就是实时交互。GenAI 时代的应用需要数据库不仅要有强大的数据处理能力，还需要有高效的实时数据广播和同步机制。这不只是让数据能够实时更新，而是确保数据流能够实时流动，让数据库能即时捕捉到每一次交互，每一个查询，确保每一个决策都是基于最新、最准确的信息。（就是用户愿意为更高价值的实时交互付钱，想想股票实时交易和直播电商的场景就知道了）</p><p></p><p>于是整个系统——从数据的产生到处理、再到存储和检索——都必须要在实时的框架下工作，能够在毫秒级别做出实时响应，这也需要数据库能实时在事务处理（OLTP）和分析处理（OLAP）之间无缝同步。这样的实时交互能力，将会是现代数据库区别于传统数据库的决定性因素之一。</p><p></p><h2>预测三</h2><p></p><p></p><p>成本分析已经成为所有人关心的问题，在云数据库的可观测性中成为独立新视角。</p><p></p><p>今天我还想谈的一点是云数据库的可观测性，尤其是它是否能让我的云消费更透明。对于数据库云服务来说，可观测性的要求会更高，因为对于开发者来说，服务商提供的 Dashboard 几乎是唯一的诊断手段。介绍可观测性的文章也很多，相似的部分因为篇幅关系我也不打算说太多。</p><p></p><p>与传统的可观测性不一样的是：在云上，一切 Workload 都会成为客户的帐单的一部分。对于用户来说一个新的问题便是：为什么我的帐单看起来是这样？我需要做什么才能让我的帐单更便宜？账单的可解释性做得越好，用户体验也就越好。</p><p></p><p>但是如果计费测量的粒度过细，也会影响产品本身的性能以及增加实现的成本。这里面需要平衡。但可以确定的是，在思考可观测性产品的方向上，成本分析可以作为一个独立的新视角。</p><p></p><p>成本分析可以帮助用户发现系统运行中的潜在问题，并采取措施予以优化。例如，如果用户观测到某个数据库实例的 CPU 使用率较低，但成本却很高，就可以考虑将该实例的规格调整为更低的级别。</p><p></p><p>AWS 今年发布的 Cost and Usage Dashboard 和 Reinvent 上 Amazon CTO Dr. Werner 的演讲专注于成本的架构艺术也同样可以看到这个趋势。他提出了 “俭约架构” 七大法则来在云的环境中打造更加高效、可持续的系统，为我们提供了一个系统性的指导框架。</p><p></p><h2>预测四</h2><p></p><p></p><p>当 GenAI 时代的各种应用和工具变得越来越轻巧，开发者体验将成为现代数据库设计的核心目标之一。</p><p></p><p>数据库平台化不仅仅是漂亮的 Web 管控界面以及一些花哨的功能堆砌。我很喜欢 PlanetScale 的 CEO Sam Lambert 在他的个人 Blog 里面关 Develop Experience 的描述他引用了乔布斯的一句话“Great art stretches taste, it doesn’t follow tastes（ 伟大的艺术拓展审美边界，而不是刻意迎合。）”。</p><p></p><p>好用的工具之所以好用，是因为其中是饱含了设计者的巧思和品味，而且这个设计者也必须是重度的使用者，这样人们才能体会到那些细微的快乐与痛苦，但是又不至于沉浸其中使其盲目，其实这对负责开发者体验的产品经理来说是极高的要求。</p><p></p><p>数据库管理工具作为一种频率不算高频、但每次使用都很严肃的工具，在 AI 和云的时代，我认为有一些与体验紧密相关的设计原则是需要遵守的：</p><p></p><p>API First, 数据库平台应该提供稳定的 / 前向兼容的 API，一切在管控平台里能干的事情，API 都要能做到，最好你的管控平台是基于你的 API 构造的。这为你提供一个功能齐备的好用的 CLI Tool 也是关键的必要条件。</p><p></p><p>使用统一的认证体系，在设计阶段将管控的认证和用户体系与数据库内部的认证体系打通，传统的数据库基于用户名和密码的权限体系在云的时代是不够的。这为了后续与云的 IAM 和 Secret 管理体系对接打下基础。</p><p></p><p>对不同的功能构建不同的 / 稳定的小工具 (Do one thing, do things well)，但是通过一个统一的 CLI 入口和语义系统进行调用。比较好的例子是 rustup, 甚至 git 也是个很好的例子。</p><p></p><p>稍微总结一下，2024 年，数据和数据库技术仍然处于巨大的变革期，谁也没办法预测未来，因为我们就身处这么一个不确定性巨大的时代。但好的一面是，创新仍然层出不穷。我今天预测的，很可能过几个月就会被我自己全部推翻，也是很正常的事情，如果能给当下的你有所启发，那就够了。</p><p></p>",
    "publish_time": "2024-01-17 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "采用开源工具：善意推定，但也要做好沟通",
    "url": "https://www.infoq.cn/article/oXERXq10Udg15F0S4Q7o",
    "summary": "<p>按照 Hila Fish 的说法，开源项目的好处是支持快速创新，让我们可以灵活地定制和调整工具，而且代码是透明的，有利于增强安全性。其缺点是通过隐匿实现安全的策略就行不通了，开源很容易被滥用，并且当开源工具没有公司支持时，可能会导致可维护性降低。</p><p></p><p>在 DEV: Challenge Accepted 2023 大会上，Hila Fish 谈了从 DevOps 视角看开源项目。</p><p></p><p>Fish 说，由于开源项目的开放性，它们的创新速度往往比较快。DevOps 团队可以利用这个快速的创新周期，采用新技术和实践来改进他们的流程。Fish 提到了持续集成、持续交付（CI/CD）、容器化和基础设施即代码（IaC）等领域。在这些领域，开源工具和解决方案推动了 DevOps 的创新。</p><p></p><p>DevOps 的核心原则之一是能够根据组织的独特需求来定制流程和工具，Fish 解释道：</p><p></p><p></p><blockquote>开源软件提供了定制和调整工具以适应特定工作流和需求所需的灵活性。她补充说，DevOps 团队可以修改、扩展和集成开源解决方案，从而创建一个最优的工具链。</blockquote><p></p><p></p><p>开源项目强调透明，允许任何人审查源代码。Fish 说，这可以加强软件开发周期内的安全工作，因为团队有机会检查代码中的漏洞并进行必要的改进。开源项目的协作特性通常可以使其对安全性和其他各种问题做出快速响应，从而帮助 DevOps 团队保证环境的安全和稳定。</p><p></p><p>开源项目也有一些缺点。Fish 提到，“通过隐匿实现安全”的概念并不适用于开源工具。Fish 说，专有软件公司可以声称他们的代码比开源软件更安全，因为代码不公开，黑客很难利用其漏洞。</p><p></p><p>Fish 还提到，开源软件很容易被滥用：</p><p></p><p></p><blockquote>最近有一些案例，比如“Colors”NPM 包和“FakerJS”被维护者破坏 / 删除，每个人都有自己的原因。我们要知道，当我们在自己的环境引入开源工具时，这种情况是有可能发生的（即使不是经常发生）。</blockquote><p></p><p></p><p>Fish 说，很多开源工具并没有得到公司的支持。由于维护者是个人，所以他们可以决定停止维护这些项目：</p><p></p><p></p><blockquote>如果我们集成这类项目，这意味着我们要么自己维护它，要么迁移到另一个维护良好的工具。</blockquote><p></p><p></p><p>Fish 提到，对于开源，你需要“善意推定（assume good faith）”。如果你在生产环境中使用一个开源工具，它有一个 Bug，而你打开了一个问题来修复它，那么这个 Bug 的修复可能需要几个月甚至更长的时间，因为他们不欠我们任何东西。</p><p></p><p>是的，你可以打开代码并尝试自己修复它，但并不是所有人都有资源这样做，所以我们会依赖于项目维护者为我们修复它。</p><p></p><p>Fish 建议我们解释这个问题并说明其紧迫性。她说，这样人们可能会更快地提供帮助，因为大多数（如果不是全部的话）开源维护者所从事的就是协作和沟通，因为这是开源文化的本质。</p><p></p><p>Fish 建议，在集成开源工具（特别是生产环境）之前一定要进行研究，确保它在出现问题时能够得到良好的维护。</p><p></p><p>InfoQ 就如何使用开源工具采访了 Hila Fish。</p><p></p><p>InfoQ：您在选择开源项目时有什么标准吗？</p><p></p><p>Hila Fish：我会考虑八个关键指标：项目的受欢迎程度、活跃度、安全性、成熟度、文档、生态系统、易用性和路线图。每个关键度量标准都有一些子问题，你可以问自己这些问题并找出答案，这样你就可以逐个指标地评估项目的成熟度级别。</p><p></p><p>InfoQ：您是如何使用那些标准的？</p><p></p><p>Fish：举个例子，就拿活跃度这个指标来说，它可以帮助我们大致估计下，这个开源项目修复 Bug/ 发布特性需要多长时间。查看下提交速率是每天、每周，还是每月，看下问题数量、发布数量，这样你就可以很好地了解活跃度。</p><p></p><p>文档是选择开源项目的另一个重要指标。文档是项目的门户，要看下它是否内容丰富，涵盖了大多数方面，如如何集成、已知问题、功能说明等。有了文档，你在决定是否采用该工具时就更有依据。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/12/upsides-downsides-open-source/\">https://www.infoq.com/news/2023/12/upsides-downsides-open-source/</a>\"</p>",
    "publish_time": "2024-01-17 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "分享一种主干开发方案：既能高频发布又能保证软件质量｜QCon",
    "url": "https://www.infoq.cn/article/NOhBA3eSlfrahIA0hEL2",
    "summary": "<p>在产品开发生命周期中的交付环节，前端设计团队的协同效率对于产品的发布进度具有决定性影响。近年来，行业内涌现出一系列卓越的设计协作工具以优化这一流程。其中，一款名为<a href=\"https://motiff.com/\"> Motiff </a>\"的 AI 赋能用户界面设计工具一问世就迅速走红。</p><p></p><p>Motiff 是一款功能集复杂的在线 UI 设计工具，它同时踩中了可视化编辑器、地图、仿桌面三大前端深坑。</p><p></p><p>为了保证 Motiff 的发布质量，Motiff 的研发团队在一开始就没有采用传统的分支发布 + 人工测试方案，而是使用主干开发 + 自动化测试的方案，在实现了高频发布的情况下，仍然很好地保证了软件质量。</p><p></p><p>为什么 Motiff 会选择这个方案，会遇到哪些坑？将于 4 月 18-20 日在北京举办的 <a href=\"https://qcon.infoq.cn/2024/beijing/track?utm_source=infoq&amp;utm_medium=article&amp;utm_campaign=7&amp;utm_term=zhangyuchen\">QCon 全球软件开发大会</a>\"邀请到了看云软件（<a href=\"https://motiff.com/\">Motiff</a>\"）研发经理张宇辰前来分享 <a href=\"https://qcon.infoq.cn/2024/beijing/presentation/5700?utm_source=infoq&amp;utm_medium=article&amp;utm_campaign=7&amp;utm_term=zhangyuchen\">Motiff 的高效能高质量开发实践</a>\"。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/9e/9e63dac5f01af073b2310e344b244903.png\" /></p><p></p><p>张宇辰老师毕业后一直在互联网研发领域工作。曾经在网易有道任职，自 2012 年开始在猿辅导，担任过前端工程师、服务端工程师、业务研发经理、基础架构负责人等多种不同职能角色。对于前后端软件开发、技术管理有着丰富经验。</p><p></p><p>其本次分享的思路大致如下——</p><p></p><p>先交代 Motiff 的项目背景，介绍为什么选择主干开发的方案——鉴于 Motiff 系统复杂性及其庞大的 Case 空间特性，潜在 Bug 发生的概率显著提升。传统分支开发 + 精细化发布的模式往往导致 bug 集中显现，造成资源浪费并降低整体开发效能。因此，Motiff 团队采用持续集成策略。</p><p></p><p>讲解主干开发的思路——Motiff 通过采纳主干开发方式，内生性地强化了对持续集成的依赖，并迫使团队在开发流程中的多个关键节点实现风险管控。具体策略着重于将风险控制点向开发前期（测试左移）和发布后阶段（测试右移）均衡分布。</p><p></p><p>然后分享测试左移和右移的关键实践。</p><p></p><p>他表示，这些方案并不是在一开始就被设计出来的，而是团队在两年多的开发过程中自发形成。因此，关于 Motiff 团队如何进行自我改善，以及技术管理者在这个过程中应该如何放手团队，又有哪些关键环节是管理者必须亲力亲为的，也是本次分享的重点。</p><p></p><p>在交流主干开发实践的内容部分时，张老师特别提及了他最想分享的「特性开关系统」，原因不在于这个系统有多先进，而在于：“它极度简单，但极致好用，维护成本贼低，如果要用四个字形容它的开发体验，那就是——有手就行。”</p><p></p><p>如果你对主干开发实践和这个神奇的特性开关系统感兴趣，也对——团队不写测试，每次发版都要熬夜，开发一周，进入测试后 Bug 不收敛，合并代码一合一星期等问题的答案感兴趣，欢迎来 <a href=\"https://qcon.infoq.cn/2024/beijing/track?utm_source=infoq&amp;utm_medium=article&amp;utm_campaign=7&amp;utm_term=zhangyuchen\">QCon 北京 2024</a>\"，听张老师的分享，和他面对面交流。</p><p></p><p>本次 QCon 大会推出全新主题——全面进化，并策划了大模型场景化落地、大模型产品设计、大模型推理加速、高质量架构、单体 vs 微服务、可观测、性能优化、下一代生产力工具、开源产品的商业闭环、最新编程语言、数据质量与治理、大前端前沿技术、自研 OS 时代的大终端等超多精彩专题。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a8/a8edd1db6d95f8a5185a000e94a6a9f9.png\" /></p><p></p><p>全年会议 7 折特惠购票，仅限 1 月，咨询购票可联系票务经理 17310043226 。目前大会议题同步征集中，<a href=\"https://qcon.infoq.cn/2024/beijing/track?utm_source=infoq&amp;utm_medium=article&amp;utm_campaign=7&amp;utm_term=zhangyuchen\">点击此处查看详情</a>\"，期待与各位开发者现场交流。</p>",
    "publish_time": "2024-01-17 10:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "专访李潇：数据智能平台，AI时代的Lakehouse架构",
    "url": "https://www.infoq.cn/article/qcUuAu70UGm5AzO3g9MR",
    "summary": "<p>在过去十年里，随着公有云的崛起、数据激增和人工智能的兴起等浪潮席卷，整个数据架构经历了巨大的变革和更新。这些激变使得数据架构发生了天翻地覆的变化。作为一家领先的大数据处理平台提供商，Databricks一直扮演着引领者的角色。</p><p>&nbsp;</p><p>在今年生成式AI的潮流中，Databricks不仅率先发布了开源可商用的大模型Dolly，还于6月底宣布以13亿美元的价格，收购生成式AI公司MosaicML。Databricks在GenAI上的投入也反映了整个大数据行业的技术演进。在2023年终盘点之际，InfoQ有幸采访了Databricks 工程总监、Apache Spark Committer 和 PMC 成员李潇，了解他对大数据技术栈的看法，以及Databricks在数据智能平台上的进展和规划。</p><p>&nbsp;</p><p>InfoQ：今年，关于大数据基础设施的演进，您观察到有哪些重要更新或变化？</p><p>&nbsp;</p><p>李潇：大数据领域随着生成式AI的兴起也变得异常热闹，我这里简略提及四点。</p><p>&nbsp;</p><p>Lakehouse平台的增长：Lakehouse平台在数据仓储领域的使用正迅速增加。这反映了一个重要的趋势：组织正从传统的数据处理平台过渡到更加灵活、集成和效率更高的现代数据架构。据2023年MIT Technology Review Insights报告，全球74%的首席信息官（CIOs）表示他们已经在使用Lakehouse架构。自Databricks在2020年推出此概念以来，Lakehouse作为一个新类别得到了广泛的采纳。几乎所有还未使用Lakehouse的首席信息官都计划在未来三年内部署此类平台。</p><p>&nbsp;</p><p>Serverless技术的普及：在过去两年里，Serverless技术在各个数据及人工智能（Data+AI）产品线中的应用变得极为普遍。Serverless架构的核心优势在于其能够提供无需管理底层服务器的数据处理和计算能力，从而使组织能够专注于核心业务逻辑而无需考虑基础设施的成本和维护。比如，Databricks SQL（Lakehouse上的无服务器数据仓库）使用量获得了大幅增长。这种架构模式特别适合于快速开发和部署，因为它能够根据需求自动扩展资源，并且只在实际使用时产生费用。在Data+AI领域，Serverless技术的引入使得数据处理、机器学习模型的训练和部署变得更加高效、灵活且成本有效。</p><p>&nbsp;</p><p>机器学习和大型语言模型（LLM）应用的扩展：机器学习和大型语言模型，特别是自然语言处理（NLP），正在经历迅速的应用扩展。这些技术不仅加强了传统分析任务的能力，还催生了新的应用场景，如聊天机器人、研究助手、欺诈检测和内容生成等。例如，Databricks的Data Intelligence Platform融合了生成式AI和Lakehouse架构的优势，创造了一个能够理解数据独特语义的数据智能引擎。这一平台针对特定业务需求，自动优化性能和管理基础设施，极大地简化了用户通过自然语言查询和发现新数据的体验。这反映出组织不仅在将更多的模型投入生产，也在加大对机器学习实验的投入，显示出机器学习方法和工具使用的成熟度和有效性正在不断提升。</p><p>&nbsp;</p><p>开源技术在数据和AI市场的关键作用及数据所有权的重要性：在人工智能和机器学习产品开发中，开源技术扮演着核心角色。我们需要一个更加安全、透明和可持续的数据和AI市场。开源平台和工具使用户能够更好地掌控他们的数据和技术堆栈，从而确保数据隐私和安全性，这在当前的AI和ML策略中至关重要。Databricks是开源社区的坚信者，对开源社区的持续贡献和对数据所有权重要性的强调，展现了我们对于建立一个开放、负责任且创新的技术生态系统的承诺。</p><p>&nbsp;</p><p>InfoQ：<a href=\"https://www.infoq.cn/article/k6Y0wXB7UGIOu2ak85WV\">2020年的年终盘点</a>\"（<a href=\"https://www.infoq.cn/article/k6Y0wXB7UGIOu2ak85WV\">https://www.infoq.cn/article/k6Y0wXB7UGIOu2ak85WV</a>\"），您预测趋势之一：“数据流水线（Data Pipeline）从复杂到简单”，如今对这个当初的预测您有新的感想吗？</p><p>&nbsp;</p><p>李潇：在2022 年，我们发布了全新的Delta Live Table (DLT)，这个正好对应了在2020年“数据流水线（Data Pipeline）从复杂到简单”的预测。这是第一个通过声明式方法来构建数据流水线的。它显著降低了数据管道的复杂性，同时提高了效率和可靠性，这使得数据流水线更易于构建、维护和操作。这对于希望快速、高效地处理大量数据的企业来说是一个巨大的进步。我们这里介绍一下它为了简易好用所引入的六个特性吧。</p><p>&nbsp;</p><p>1) 声明式编程模型： DLT采用声明式编程模型，使得定义和维护数据管道更为直观和简单。用户只需要指定所需的最终数据状态，DLT则负责执行必要的步骤来实现这一状态。</p><p>2) 自动化数据工程任务： DLT自动化了许多传统上需要手动编码的数据工程任务，如数据清洗、转换和聚合。通过减少需要手动编写和调试的代码量，DLT简化了整个数据处理流程。</p><p>3) 错误处理和数据质量保证： DLT内置了错误处理和数据质量检查机制。这意味着数据工程师可以花费更少的时间在解决数据质量问题上，而更多地专注于数据分析和提取洞察。</p><p>4) 优化的资源管理和成本效率： DLT通过自动调整资源使用（例如，在处理大量数据时自动扩展计算资源），提高了资源管理的效率，降低了操作成本。</p><p>5) 改进的监控和维护： DLT提供了增强的监控和维护功能，使得跟踪数据管道的性能和识别潜在问题变得更加容易。</p><p>6) 无缝集成和扩展性： DLT可以无缝集成到现有的数据生态系统中，并且具有很好的扩展性，支持从小型项目到大规模企业级应用的不同需求。</p><p>&nbsp;</p><p>InfoQ：以Databricks的发展为例，回头去看大数据技术的发展，您认为主要可以分为哪几个阶段？</p><p>&nbsp;</p><p>李潇：大数据技术的发展，以Databricks的成长历程为例，可以分为几个关键阶段，这些阶段不仅展现了Databricks的发展轨迹，也反映了整个大数据行业的技术演进。</p><p>&nbsp;</p><p>首先是Apache Spark的诞生阶段。这个阶段始于2010年，标志着Hadoop技术时代的结束。Apache Spark由Databricks的创始人之一Matei Zaharia等人开发，这是一个开源的分布式计算系统。它的出现大幅降低了大数据处理的门槛，使得大数据开始与机器学习和人工智能结合，成为统一的分析引擎。它使得用户可以更简单、方便地进行全量数据分析、实时流处理和复杂的数据分析。从此，大数据不再仅限于技术巨头，而是开始被更广泛的行业和企业采用。</p><p>&nbsp;</p><p>接下来是Lakehouse架构的推出阶段。这一阶段发生在2020年，打破了传统数据湖和数据仓库的界限。Lakehouse架构结合了数据湖和数据仓库的最佳元素，旨在降低成本并加速数据及人工智能项目的实施。Lakehouse架构建立在开源和开放标准之上，它通过消除历史上复杂化数据和AI的孤岛，简化了数据架构。值得注意的是，Apache Spark只是Lakehouse架构中的可选模块之一。</p><p>&nbsp;</p><p>最后是生成式AI大潮下的Lakehouse阶段。在这个阶段，Lakehouse成为了下一代数据智能平台 (Data Intelligence Platform) 的基础。这个数据智能平台将AI带入数据处理，帮助全世界的用户发现数据的价值。在这个平台上，用户可以开发基于自己数据的生成式AI应用，同时不必牺牲数据隐私或控制权。它使得组织中的每个人都能使用自然语言来从数据中发现洞见。</p><p>&nbsp;</p><p>总的来说，这些阶段并不是严格分隔的，而是相互交织和演进的。每个阶段都反映了当时技术发展的需求和挑战，同时预示着下一阶段的到来。未来，数据和AI不分家！</p><p>&nbsp;</p><p>InfoQ：Databricks今年最大的进展主要体现在哪个方面？是AI方向上的吗？</p><p>&nbsp;</p><p>李潇：今年，Databricks的最大进展主要体现在将人工智能集成到数据平台中。公司构建了一个基于数据湖仓（Lakehouse）的数据智能平台（Data Intelligence Platform），专注于AI在数据处理中的变革作用。这个平台利用生成式AI模型来理解数据的语义，并在整个平台中应用这种理解。用户可以在保持隐私和控制的同时，从头开始构建模型或调整现有模型。该平台的目标是实现数据和AI的平民化，使用自然语言极大简化了数据和AI的端到端体验。通过在数据和AI的每一层应用AI，可以实现针对特定业务的全面自动化和成本效率。这种平台的统一性有助于用户以数据为中心的方式应对任何模型开发场景，使用私有数据，从而拥有更强的竞争和经济优势。</p><p>&nbsp;</p><p>数据湖仓对GenAI起到了什么样的帮助或作用？（湖仓应该只是pipeline的一环，但是跟GenAI有直接联系么？企业如何利用湖仓架构支持他们的AI战略，从技术上说他们需要做些什么？）</p><p>&nbsp;</p><p>数据湖仓（Lakehouse）为GenAI提供了一个集中、高效和可扩展的数据存储和管理环境。它结合了数据湖的灵活性和数据仓库的高性能，支持结构化和非结构化数据的存储和处理，这是AI应用的数据需求的基石。</p><p>&nbsp;</p><p>数据质量和治理：数据湖仓通过提供强大的数据治理工具（如Databricks的Unity Catalog）来确保数据的质量和安全。这对于构建准确可靠的AI模型至关重要。Unity Catalog帮助企业精确管理其数据，提供完整的元数据和数据溯源信息，从而提高AI模型的准确度，并确保数据的安全性。</p><p>&nbsp;</p><p>数据访问和处理：数据湖仓支持高效的数据访问和处理，这对于实时AI应用和深度学习模型训练尤为重要。在Databricks的Lakehouse，通过Unity Catalog，智能引擎可以理解数据和数据之间的关系，企业可以使用自然语言来安全地查找和理解数据，这对于在庞大的数据集中找到正确的数据至关重要。</p><p>&nbsp;</p><p>数据集成和管理：数据湖仓提供了一个统一的平台，支持大量结构化和非结构化数据的存储和管理。这对于训练和优化AI模型至关重要。其实除了数据迁移到Lakehouse，今年，我们还推出了Lakehouse Federation的功能，用户可以跨多个数据平台（如MySQL、PostgreSQL、Snowflake等）发现、查询和管理数据，无需移动或复制数据，为用户提供了简化和统一的体验。</p><p>&nbsp;</p><p>当前，越来越多的公司正在构建自己的Lakehouse架构。然而，根据不同需求的技术选型会带来截然不同的效果。对于企业级用户而言，数据安全通常是最优先考虑的问题。在我看来，选择技术平台时，首先应确保平台能够解决数据合规和数据资产安全性问题，其次才是成本控制和性能提升。</p><p>&nbsp;</p><p>目前，众多公司正积极构建自己的Lakehouse架构。重要的是，技术选择应根据具体需求定制，因为不同的选择将导致不同的成果。对于企业级用户，数据安全无疑是首要关注的领域。在选择技术平台时，首先要确保所选平台能够全面应对数据合规性和数据资产安全性的挑战。此外，成本控制和性能优化也是重要的考量因素，但它们应该在确保数据安全的基础上进行权衡。因此，平衡这些关键要素，选择一个既安全又高效的Lakehouse解决方案，对于任何希望在现代数据生态中取得成功的企业来说，都是至关重要的。</p><p>&nbsp;</p><p>InfoQ：请展望未来的大数据架构是什么样子（必要组件的演变，一些趋势总结）？</p><p>&nbsp;</p><p>李潇：在不久的未来，每个领域的赢家都是那些可以最有效利用数据和AI的。事实上，我们坚信对数据和AI的深刻理解是每个赢家的必备技能。未来的大数据架构将是一个高度集成、智能化和自动化的系统，它能够有效地处理和分析大量数据，同时简化数据管理和AI应用的开发过程，为企业提供竞争优势。</p><p>&nbsp;</p><p>未来的大数据架构，我们可以称为“数据智能平台（Data Intelligence Platform）”。它正是顺应了两个主要趋势：数据湖仓（Data Lakehouse）和生成式人工智能（AI）。这一架构建立在数据湖仓的基础上，它提供一个开放、统一的基础，用于所有数据和治理，由一个理解用户数据独特语义的数据智能引擎(Data Intelligence Engine) 驱动。这是相对现有Lakehouse架构下的，最大的突破。</p><p>&nbsp;</p><p>智能化方面，这个引擎能理解客户数据的独特语义，使平台能自动优化性能和管理基础设施。操作简化方面，自然语言大大简化了用户体验。数据智能引擎理解客户的语言，使搜索和发现新数据就像询问同事一样简单。此外，自然语言还助力编写代码、纠错和寻找答案，加速新数据和应用程序的开发。</p><p>&nbsp;</p><p>在隐私保护方面，数据和AI应用需要强大的治理和安全措施，尤其是在生成式AI的背景下。提供一个端到端的机器学习运维（MLOps）和AI开发解决方案，该方案基于统一的治理和安全方法。这允许在不妥协数据隐私和知识产权控制的情况下，实现所有人工智能目标。</p><p>&nbsp;</p><p>总的来说，未来的大数据架构将更加重视智能化、操作简化和数据隐私，为企业在数据和AI应用方面提供竞争优势。这将使企业能更有效地利用数据，推动创新，同时保护数据安全和发展AI技术。</p><p>&nbsp;</p><p>更多阅读：</p><p>解读数据架构的 2020：开放、融合、简化：<a href=\"https://www.infoq.cn/article/k6Y0wXB7UGIOu2ak85WV\">https://www.infoq.cn/article/k6Y0wXB7UGIOu2ak85WV</a>\"</p><p>让大模型融入工作的每个环节，数据巨头 Databricks 让生成式 AI 平民化：<a href=\"https://www.infoq.cn/article/EvYEXsLPh8KMkfNrsG7D\">https://www.infoq.cn/article/EvYEXsLPh8KMkfNrsG7D</a>\"</p>",
    "publish_time": "2024-01-17 10:14:37",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Flink十周年专访莫问：存算分离2.0架构的探索与展望",
    "url": "https://www.infoq.cn/article/zK6T1A3HfolPsktP2Z1Z",
    "summary": "<p>采访嘉宾 ｜ 王峰（莫问）</p><p>编辑 ｜ Tina</p><p>&nbsp;</p><p>Flink 从 2014 年诞生之后，已经发展了将近 10 年，尤其是最近这些年得到了飞速发展。在全球范围内，Flink 已经成为了实时流计算的事实标准，成为大数据技术栈中不可或缺的一部分。在2023年终盘点之际，InfoQ有幸采访了Apache Flink 中文社区发起人、阿里云开源大数据平台负责人王峰（莫问），了解他对大数据技术栈的看法，以及Flink的进展和未来规划。</p><p>&nbsp;</p><p>InfoQ：如果以“数据流”的逻辑来看大数据基础设施的演进，比如：从存储和处理到分析，再到提供 ML/AI 模型并构建面向用户的、人工智能驱动或数据驱动的应用程序，那么在这些环节中，您观察到有哪些重要更新或变化？</p><p>&nbsp;</p><p>王峰（莫问）：在最近几年的数据技术趋势演进的路线中，我们可以清晰的看到两个趋势变化，一是数据分析的实时化，二是数据架构的云原生化。</p><p>数据分析实时化本质是业务发展驱动的。在 BI 场景，各行业的业务运营人员和决策者都希望能到实时的数据分析报表来及时进行业务决策，从而提升公司运营效率；在 AI 场景，各种推荐广告等场景都希望能够及时将用户行为反馈信息合并到 AI 模型中，从而进行更加个性化精准的推送，提升业务转化率。在技术上，数据的“实时化”包括了两个因素：一是数据的新鲜度，二是数据的查询速度。为了解决这 2 个问题，我们可以看到最近几年 Streaming 和 OLAP 两种引擎成为了大数据技术领域的热点，SIGMOD 把今年的 Systems Award 搬给了 Flink，Clickhouse 、Doris 和 StarRocks 几款 OLAP 引擎也不断争夺市场的焦点。在云端构建数据基础设施日益成为主流，云的弹性能力让存算分离架构可以发挥出极致的效果，在云端基于数据湖构建开放的数据中心，不同类型的计算引擎可以围绕统一数据存储构建繁荣的融合计算生态。以 Snowflake 和 Dataricks 为代表，几乎所有的大数据公司都选择了拥抱云原生，推出了基于多云的 PaaS/SaaS 计算服务，从 Serverless 到 BYOC，为用户提供了在云上不同类型的托管服务，随着云计算规模效应的提升，未来一定会有更多的数据计算迁移到云上运行。</p><p>&nbsp;</p><p>&nbsp;</p><p>InfoQ：今年我们看到不止一家企业声称实现了比Flink有10-1000倍的效率提升，那么在Flink的资源效率方面有什么进展？增量引擎+Apache Paimon方案是否是一方面？</p><p>&nbsp;</p><p>王峰（莫问）：</p><p>我也非常期待能看到真正能够有 “比 Flink 快100-1000倍”的新技术出现，这样类似阿里、腾讯、抖音这些公司大概每年可以节省数十亿的机器成本了，不过目前好像没有看到那家公司真的在生产环境做到了个效果。几个月前，大家通过开放的方式进行过一些相关讨论，Flink 社区的几位核心成员也通过基准测试成绩以及技术分析进行了回复，有兴趣的同学可以去网上搜索下相关文章。良性的技术竞争是有利于开源生态的发展和演进，目前 Flink 也在不断学习和自我革新，明年 2024 年将是 Flink 项目的第一个十周年，Flink 社区也会发布 Flink-2.0 新的里程碑，彻底的云原生存算分离架构，业界一流的批处理能力，完整的流批融合能力都会是全新的亮点。此外，阿里云之前独立开源的 Flink CDC 实时数据集成项目也已经正式开启捐献工作，明年 Flink CDC 将正式成为Apache Flink 官方子项目。Apache Paimon 是从 Flink 社区中孵化出来的新项目，定位就是流批一体实时数据湖格式，解决 Lakehouse 数据实时化的问题。基于 Flink + Paimon 可以构建出新一代的 Streaming Lakehouse 架构，让Lakehouse 上的数据可以全链路实时流动起来。此外，基于计算和存储端到端流批一体的特性，也更加方便用户在Lakehouse 架构上实现实时离线一体化的数据分析体验。</p><p>&nbsp;</p><p>InfoQ：您认为流处理引擎未来进化方向是什么？</p><p>&nbsp;</p><p>王峰（莫问）：</p><p>方向 1：全面 SQL 化，提升体验，降低门槛。大数据处理从离线向实时升级的趋势已经确立，大量行业已经开始实时化升级，并取得非常好的业务收益。为了让更多用户能够享受到实时流计算带来的价值，流处理引擎需要进一步提升端到端的易用性，全面 SQL 化 ，提升用户体验，降低使用门槛，让流计算能够在更多场景和行业中被生产使用起来。</p><p>&nbsp;</p><p>方向 2：流批一体，流批融合。流、批数据处理的边界正在逐步模糊，越来越多用户希望一套 API 来统一开发业务逻辑，但可以基于不同的频率来运行，例如可以让其每天 / 小时 / 5分钟运行一次，或者持续不停在运行，并得到一致性的业务结果。因此流批一体，流批融合计算能力会是下一步的演进方向。</p><p>&nbsp;</p><p>方向 3：存算分离，云原生架构。Cloud 正在成为大数据和 AI 计算新的运行底座，因此流计算引擎需要在运行部署架构上完全融入云原生环境，彻底实现存算分离架构，基于云的优势提供秒级弹性扩缩容和系统容错恢复能力。</p><p>&nbsp;</p><p>方向 4：流式湖仓新场景&nbsp;。目前大部分用户都是将流计算引擎和消息队列配套使用，构建流式处理链路。但这个并未真正解放流计算的潜力，随着开放的 Lakehouse 架构出现，越来越多数据会进入到数据湖中，流计算引擎和 Lakehouse架构的结合将开启新的实时数据湖分析架构。目前流计算已经和主流湖存储技术完成对接，接下来流计算引擎将继续完善自身使其更好的和 Lakehouse 架构进行深度融合。</p><p>&nbsp;</p><p>InfoQ：对当前大数据平台来说，生成式AI将对数据和分析产生什么影响？</p><p>&nbsp;</p><p>王峰（莫问）：大数据和 AI 一体化是一个谈论了很久的话题，在 AIGC 出现之前，大数据和 AI 最经典的结合场景是搜、推、广，用户个性化模型的生成和更新离不开海量用户行为数据的预处理，包括特征工程和样本拼接等经典流程。在很多大型互联网公司中，这部分 AI 数据预处理工作的计算量甚至已经超过了经典 BI 数据分析类应用。</p><p>&nbsp;</p><p>在进入 AIGC 时代后，LLM 的训练依然需要前期的海量数据预处理，随着越来越多超级AIGC APP 的出现，依然会产生大量的用户交互数据，为了更好的将这些数据效果反馈给 LLM，AI 场景依然会继续需要大数据计算技术来协助发展。</p><p>&nbsp;</p><p>此外，随着行业大模型的逐步丰富，AI 技术红利也会助力大数据的发展，目前已经有不少公司开始推出利用 AI 大模型技术进行自动生成 SQL的技术，这背后需要 AI 大模型能够更加深入的理解数仓体系，从而根据用户需求产生更加高效的 SQL。总而言之，未来大数据和 AI 技术的融合会更加深入，相互支持，相互促进。</p><p>&nbsp;</p><p>InfoQ：在您看来，当今现代数据堆栈还有哪些局限性？</p><p>&nbsp;</p><p>王峰（莫问）：近些年各种不同的大数据基础设施雨后春笋般的涌出，一方面为用户提供了多样化的选择，但另一方面也为用户带来了幸福的烦恼。通常情况下，用户要搭建一套大数据业务系统，需要非常多的核心技术组件才能完成，少则三到五种，多则五到十种，这主要带来以下几方面的问题：</p><p>技术组件繁多，必然提升系统架构的复杂度。通常来讲，系统稳定性风险和系统复杂度成正比，过于复杂的体系必然带来更大的稳定性隐患；每一项技术组件都需要有对应的专家来运维管理以及客户支持，对于中小企业来说，这必然带来高昂的人力资源成本；过多的同质化组件存在，也会为用户带来选择的困扰，并行保留多个同质化组件不仅给运维团队带来了额外的运维负担，也给开发者带来了额外的学习成本。</p><p>&nbsp;</p><p>因此，未来数据技术的演进会逐渐出现一些整合的趋势，走向更加简洁的架构，核心目标不仅是让每个组件运行的更快，还需要考虑为用户提供更加简单、一致性的开发体验，以及全局最优的运维成本。</p><p>&nbsp;</p><p>InfoQ：请展望未来的大数据架构是什么样子？</p><p>&nbsp;</p><p>王峰（莫问）：</p><p>目前业界主流的几款 Streaming，Batch 和 OLAP 引擎都开始相互渗透，例如：Flink 在发力流批一体、流批融合计算能力，Databricks 也基于 Spark 和 Delta 推动了Delta Live Table 淡化流批的差异，StarRocks 在提供 OLAP 极致查询能力的同时，也开始通过物化视图形态提供对数据湖上数据的 ETL 处理能力。本质上各大主流计算引擎都在不断扩展自己的能力边界，淡化流、批、OLAP边界，希望为用户提供全场景一致性的数据分析体验。我个人认为这也是技术发展的必然趋势，各家都会逐渐补齐短板，但也都有各自核心的优势。随着云原生概念的逐步普及，未来主流的计算负载一定是运行在 cloud 上，全球范围内都是这个趋势，因此大数据架构也需要更好的适配云底座，利用好云的弹性优势。存算分离将会是未来大数据架构的标配，不过存算分离在带来了诸多好处的同时也带来了额外的性能挑战，目前看在对 latency 敏感的场景下，多级缓存和冷热分层将是对存算分离架构的有益补充，2024年将发布的 Flink-2.0 也会采用这套最新的架构。云原生架构的不断发展，也同步推动了数据湖存储方案的加速落地。数据湖具备的开放和成本优势，必然使得越来越多的数据流入湖中，从而成为天然的数据中心，湖上建仓的lakehouse 架构正在成为主流，下一步客户一定是希望数据在 lakehouse 中能够更加实时的流动起来。在实时流处理这条链路上，我觉得也存在一些新的机会和变化。众所周知，Flink 和 Kafka 目前已经分别成为流计算和流存储的事实标准，但 Kafka 真的是最适合流分析的存储方案吗？Kafka 和很多消息队列类似，都是一种消息中间件，而非为大数据分析而生。例如：Kafka 并未对数据提供结构化的 Schema 描述，也无法提供完整的 Changelog 语义，且 Kafka 中的数据时无法进行实时更新和探查分析的。但以上这些缺陷，都是实时流分析需要的特性和能力，我们也正在思考这个问题，并探索新的解决方案，希望能够在明年发布一款更加适合流分析的流存储技术。</p>",
    "publish_time": "2024-01-17 10:20:19",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]