[
  {
    "title": "谷歌发布云基础设施可靠性指南，帮助消费者做出正确决策",
    "url": "https://www.infoq.cn/article/Rxk0KGocM5ygWH8mS90v",
    "summary": "<p>谷歌最近为其消费提供了<a href=\"https://cloud.google.com/architecture/infra-reliability-guide\">云基础设施可靠性指南</a>\"，该指南结合了工程师的最佳实践和专业知识。</p><p></p><p>该指南的受众是那些希望为云基础设施做出正确决策以托管其工作负载的消费者。在Google Cloud的<a href=\"https://cloud.google.com/blog/products/infrastructure-modernization/design-reliable-infrastructure-for-workloads-in-google-cloud\">博客文章</a>\"中，谷歌的高级工程师Nir Tarcic和跨产品解决方案开发者Kumar Dhanagopal这样说到：</p><p></p><p></p><blockquote>Google Cloud的基础设施可靠性指南能够带领你了解<a href=\"https://cloud.google.com/architecture/infra-reliability-guide/building-blocks\">Google Cloud中构建基块的可靠性</a>\"，以及这些构建基块如何影响云资源的可用性。你会更深入地理解region、zone以及部署在单个zone、多个zone和跨region的应用的平台级可用性指标。</blockquote><p></p><p></p><p>在该指南中，消费者可以找到可供选择的<a href=\"https://cloud.google.com/architecture/infra-reliability-guide/design#deployment_architectures\">部署架构</a>\"，以便在不同的地点分配资源和部署冗余资源：</p><p></p><p><a href=\"https://cloud.google.com/architecture/infra-reliability-guide/design#single-zone\">单zone架构</a>\"对能够容忍工作负载停机或者企业在必要时能够在另外一个位置快速部署应用的场景来说是足够的。<a href=\"https://cloud.google.com/architecture/infra-reliability-guide/design#multi-zone\">多zone架构</a>\"适用于对zone中断需要保持韧性，但是能够容忍region中断造成停机的工作负载。<a href=\"https://cloud.google.com/architecture/infra-reliability-guide/design#multi-region-deployment-with-regional-load-balancing\">多region部署架构</a>\"是业务关键工作负载的理想选择，在这种场景下，高可用性至关重要，比如零售和社交媒体应用。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/news/2023/01/google-cloud-reliable-infra/en/resources/1Google%20Cloud%20MultiZone-1674393026723.png\" /></p><p></p><p>图片来源: <a href=\"https://cloud.google.com/architecture/infra-reliability-guide/design#deployment_architectures\">https://cloud.google.com/architecture/infra-reliability-guide/design#deployment_architectures</a>\"</p><p></p><p>消费者还可以找到关于<a href=\"https://cloud.google.com/architecture/infra-reliability-guide/traffic-load\">流量和负载管理的技术</a>\"，比如容量规划、自动扩展和<a href=\"https://cloud.google.com/architecture/infra-reliability-guide/manage-and-monitor\">变更管理指南</a>\"，以减少基础设施资源的可靠性风险。</p><p></p><p>与之类似，其他公有云供应商也有关于可靠性的指南和产品。例如，微软有一个专门的网站，提供与<a href=\"https://azure.microsoft.com/en-us/explore/reliability/#overview\">Azure可靠性</a>\"相关的产品概述、培训和文档。AWS提供了一份<a href=\"https://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/welcome.html\">文档</a>\"（可靠性支柱）作为其<a href=\"https://aws.amazon.com/architecture/well-architected/\">Well-Architect框架</a>\"的一部分。</p><p></p><p>谷歌的开发者关系和对外管理总监<a href=\"https://twitter.com/rseroter\">Richard Seroter</a>\"在LinkedIn的<a href=\"https://www.linkedin.com/posts/seroter_google-cloud-infrastructure-reliability-guide-activity-7010627352120496128-ImVp/?originalSubdomain=al\">帖子</a>\"中表示：</p><p></p><p></p><blockquote>公有云中有许多韧性相关的功能，你甚至不需要自己去考虑它们。有些事情就是在你不做任何事情的情况下也能更好地工作！但总的来说，系统韧性是一个架构问题。这是你需要在意的工作。这个新的Google Cloud指南可以帮助你在应用程序运行的地方建立更可靠的基础设施。</blockquote><p></p><p></p><p>最后，谷歌提供了更多的指导，包括构建可扩展和韧性应用程序的<a href=\"https://cloud.google.com/architecture/scalable-and-resilient-apps\">模式和最佳实践</a>\"。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/01/google-cloud-reliable-infra/\">Google Delivers Comprehensive Cloud Infrastructure Reliability Guide</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/oi5qfvo5NUCHeZScpaib\">揭秘 Meta 的云游戏基础设施</a>\"</p><p><a href=\"https://www.infoq.cn/article/HXgMpZwrxmhGU2DyWE9M\">SaaS 初创公司如何选择合适的云基础设施</a>\"</p><p><a href=\"https://www.infoq.cn/video/jFt3MjEx0HTdz8vJIhoZ\">应云而生 云原生基础设施服务进化</a>\"</p>",
    "publish_time": "2023-02-20 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "七年前选择用Go和Rust做数据库的创业公司，如今怎么评价这个决定？",
    "url": "https://www.infoq.cn/article/ENdwNVAliiHfPXquyLfw",
    "summary": "<p></p><blockquote>“我现在会很辩证地看待这件事情，只能说是不好不坏，但当时所谓的主流选择可能会让我们的产品变成一个平庸的系统。”</blockquote><p></p><p></p><p>即便是在此时此刻创业的公司，公司的产品决定全部采用 Go 和 Rust 也是非常艰难的决定，更何况是七年前</p><p></p><p>2015 到 2016 年，Go 不到五岁，Rust 还没发布 v1.0 版本，没有太多公司和开发者看好这两种语言，怎么会有公司选择全面采用这两种语言，还是用来写数据库和存储层代码？</p><p></p><p>如果你在七八年前听到这个故事，直觉大概是这家公司活不了太久。事实上，这家公司不仅走过了七年，还拿到了三轮融资，这家公司就是 PingCAP。</p><p></p><p>当然，编程语言只是工具，绝不是 PingCAP 可以走到今天最重要的因素，但这家公司确实因为这一选择收获了不少。本文通过与 PingCAP 创始人之一黄东旭和两位工程师的交谈，还原了这家创业公司最初选择 Go 和 Rust 的原因，以及如何解决随之而来语言本身的问题、人才问题以及对不同语言适用场景的思考。</p><p></p><h2>选择背后的原因</h2><p></p><p></p><p>“首先，我不是某一个具体的编程语言或者工具的信仰者，但在做项目时选择一个好的工具也是十分必要的。”——黄东旭</p><p></p><h3>选择的第一个要点：开发效率</h3><p></p><p></p><p>Go 语言的缔造者中有一位全世界程序员公认的大神级人物——肯尼思·汤普森（Kenneth Thompson），他是 UNIX 操作系统的主要开发者；其另一位主要设计者和早期实现者罗布·派克虽然没有直接参与最初版本的 UNIX 的开发，但同样属于贝尔实验室 UNIX 开发组的最资深成员，并且是字符编码 UTF-8 的主要实现者。</p><p></p><p>所以，Go 的出身决定了该语言具备极高的品质。而且，Go 语言从第一个版本起就开源，所以来自世界各地的程序员第一时间发现并使用了它，然后立刻就被其美妙的语言特性所吸引，比如 Go 语言使用比线程轻量得多的 goroutine 完成上下文切换可以节省高达 80% 左右的时间，这些关注者中就包括黄东旭与另一位合伙人刘奇。</p><p></p><p>早在创办 PingCAP 之前，黄东旭与刘奇就曾使用 Go 语言写过一个叫 codis 的开源软件解决当时豌豆荚业务在缓存扩展方面的问题。深入了解 Go 语言之后，二人被 Go 带来的效率提升所吸引。“同样的系统使用 C++ 开发可能需要一个月，但使用 Go 可能仅需要三天，这种级别的开发效率提升很难不让人动心。”</p><p></p><p>过去，因为效率而选择一门新兴语言的人并不是没有，比如《黑客与画家》的作者保罗·格雷厄姆 Paul Graham 曾用 Lisp 写了最早的 Web 应用 Viaweb，最终被雅虎以 5 千万余美金收购。这个故事也对 PingCAP 创始团队带来了一些影响。</p><p></p><p>PingCAP 的目标是做一个分布式数据库，也就是现在我们熟知的 TiDB。团队最开始确实考虑过 C++，毕竟大部分成员都有着 C++ 背景，大多还不错的数据库都是用 C++ 开发的，但是 C++ 非常依赖团队内部研发人员的经验、水平以及团队内部相关规范的制定，否则很容易出现问题。对于刚刚创业的 PingCAP 而言，团队显然是很难找到厉害的 C++ 研发人才。</p><p></p><p>“这里还有一个有趣的现象，业内鲜少有程序员承认自己精通 C++，即便是拥有 20 年经验的开发者，但可能学一个月就有人说自己精通 Go 了，复杂性一目了然。”</p><p></p><p>当时还存在一个安全的选择，那就是 Java。那段时间，主流的分布式系统大部分使用 Java 编写的，比如 Hadoop、Zookeeper、Cassandra、HBase 等。但面向云计算时代，团队认为需要更敏捷、更高效、同时更安全的新方式构建系统。</p><p></p><p>在当时，同样有很多软件产品选择工具时信奉其可以最大程度榨干硬件性能。“老实讲，我并不信奉开发出来的产品一定要能榨取硬件的最后一点性能，招聘具备这种能力程序员的成本可能并不比加几台机器低（分布式时代，这个问题显然可以通过加机器的方式来解决），而且用户也不会因为榨取的这一点性能而付更多钱”，黄东旭在采访中如是说道。</p><p></p><p>综合权衡下来，Go 成为了当时创业最合适的起步选择，可以快速把 TiDB 的原型开发出来。当年的 9 月份，TiDB 就在 GitHub 上开源了，后续的迭代也很快，随后一年就有客户在生产环境试用，再往后一年 TiDB 1.0 GA 版本正式发布。</p><p></p><h3>选择的第二个要点：语言本身的特性</h3><p></p><p></p><p>既然 Go 的效率得到了验证，团队为什么在后来开发 TiDB 的存储引擎 TiKV 时又选择了 Rust 呢？</p><p></p><p>TiKV 起始于 2015 年底，当时团队在 Pure Go / Go + Cgo / C++11 / Rust 几个语言之间纠结，虽然 PingCAP 的核心团队有大量的 Go 语言开发经验，另外 TiDB 的 SQL 层已经完全采用 Go 语言开发，Go 带来的开发效率的极大提升也让团队受益良多。但是在存储层的选型上，团队首先排除的就是 Pure Go 的选项，理由很简单，底层已经决定接入 RocksDB，RocksDB 本身就是个 C++ 的项目，而 Go 的 LSM-Tree 的实现大多成熟度不太够没有能和 RocksDB 相提并论的项目，如果选 Go 的话，只能选择用 Cgo 来 bridge，但是当时 Cgo 的问题同样明显，在 2015 年底，在 Go code 里调用 Cgo 的性能损失比较大，并不是在 goroutine 所在的线程直接 Call cgo 的代码，而且对于数据库来说，调用底层的存储引擎库是很频繁的，如果每次调用 RocksDB 的函数都需要这些额外开销，非常不划算，当然也可以通过一些技巧增大 Cgo 这边的调用的吞吐，比如一段时间内的调用打包成一个 cgo batch call，通过增加单个请求的延迟来增大的整体的吞吐，抹平 cgo 调用本身的开销，但是这样一来，实现就会变得非常复杂。另一方面，GC 问题仍然没有办法彻底解决, 存储层希望尽可能高效的利用内存，大量使用 syscall.Mmap 或者对象复用这些有些 hacky 的技巧，会让整体的代码可读性降低。</p><p></p><p>其实 C++11 也没什么问题，性能上肯定没问题，RocksDB 是 C++11 写的，在纠结了一小段时间后，团队认真评估了成员背景和要做的东西，最后还是没有选择 C++，原因主要是：</p><p></p><p>核心团队过去都是 C++ 的重度开发者，基本都有维护过大型 C++ 项目的经历，每个人都有点心里阴影… 悬挂指针、内存泄漏、Data race 在项目越来越大的过程中几乎很难避免，当然你可以说靠老司机带路，严格 Code Review 和编码规范可以将问题发生的概率降低，但是一旦出现问题，Debug 的成本很高，心智负担很重，而且第三方库不满足规范怎么办。</p><p></p><p>C++ 的编程范式太多，而且差异很大，又有很多奇技淫巧，统一风格同样也需要额外的学习成本，特别是团队的成员在不断的增加，不一定所有人都是 C++ 老司机，特别是大家这么多年了都已经习惯了 GC 的帮助，已经很难回到手动管理内存的时代。</p><p></p><p>缺乏包管理，集成构建等现代化的周边工具，虽然这点看上去没那么重要，但是对于一个大型项目这些自动化工具是极其重要的，直接关系到大家的开发效率和项目的迭代的速度。而且 C++ 的第三方库参差不齐，很多轮子得自己造。</p><p></p><p>Rust 在 2015 年底已经发布了 1.0，Rust 有几点特性非常吸引团队：</p><p></p><p>内存安全性高性能 (得益于 llvm 的优秀能力，运行时实际上和 C++ 几乎没区别)，与 C/C++ 的包的亲缘性强大的包管理和构建工具 Cargo更现代的语法和 C++ 几乎一致的调试调优体验，之前熟悉的工具比如 perf 之类的都可以直接复用FFI，可以无损失的链接和调用 RocksDB 的 C API</p><p></p><p>一方面，团队把安全性放在第一位，C++ 的内存管理和避免 Data race 的问题虽然靠老司机可以解决，但是仍然没有在编译器层面上强约束，把问题扼杀在摇篮之中解决的彻底，Rust 很好地解决了这个问题。另一方面，Rust 是一个非常现代化的编程语言，现代的类型系统，模式匹配，功能强大的宏，trait 等熟悉以后会极大提升开发效率。</p><p></p><p>最终，Rust 也没让团队失望，四五个人的团队从零开始花费了四个月左右的时间就开发出了 TiKV 的第一个版本。2016 年 1 月 1 日开始开发，4 月 1 日开源。同年 10 月份，TiKV 第一次被使用在生产环境，那时 TiDB 甚至都还没有发布 beta 版。TiKV 的开发非常快，发布的版本都很稳定，生产效率比 C++ 高出许多。</p><p></p><h3>选择的第三个要点：人才</h3><p></p><p></p><p>虽然当年并没有太多开发者使用 Rust，但早期探索者们的自身能力是很强的，这群人对编程本身有着极强的热爱，这对于创业公司而言是非常宝贵的人才（起步阶段的创业公司人才在精不在多），PingCAP 后续的发展也验证了这一点，曾经是 Rust 核心团队成员的 Brian Anderson 在 2018 年选择加入该公司并参与 TiKV 的研发，这种案例在 2018 年之前是极少数的。Brian 之所以愿意加入，除个人因素之外，与 PingCAP 在开源和社区方面的持续努力是分不开的。2017 年， Brian 就应邀出席过 PingCAP 举办的国内首场 Rust Meetup。2019 年， Rust Core Team 的元老 nrc 也加入了 PingCAP。</p><p></p><p>“直到今天，我依旧认为这是创业公司吸纳人才时很好的思路，否则一家创业公司通过什么去跟互联网大厂竞争，只能是更好的理念和工具。我们在没有做任何全球化品牌的时候就是靠着这张名片（指全面拥抱 Rust 生态）吸引人才加入我们的社区和公司。但很多时候，国内很多公司的问题是不敢想，认为自己凭什么可以吸引到这样的大牛加入，但凡事都要先试试。”</p><p></p><h2>选择 Rust 带来的问题</h2><p></p><p></p><p>如开篇所言，黄东旭如今认为当初的决定“不好不坏”，虽然获得了开发效率上的提升，也承受了当时语言不够成熟带来的问题。</p><p></p><p>“很多时候，人们会先通过广告了解一件事情。我们当初对 Rust 的看法也是内存安全、性能好，没有 GC 效率肯定高等，实际并不是这样的。如果你代码写的很挫，凭什么认为自己手动分配内存就比 GC 搞得好。”</p><p></p><p>起初，团队基本是把 Rust 当成 Java、C++ 在用，性能并没有明显提升，直到更专业的人才加入才把整个代码扭转到更好的道路上。</p><p></p><p>此外，Rust 的编译时间较长。“当时我们内部的 Rust 程序员经常开玩笑说一天只有 24 次编译机会，用一次少一次”，团队做了大量工作去降低 Rust 的编译时间，参与并贡献了 rust-gRPC、Raft 库，open-tracing 等项目中，并产出了大量相关的博客文章。</p><p></p><p>虽然解决这些问题占用了团队的很多时间，但团队也因此获益。“我们将 Talent Plan 的所有教程用 Rust 实现了一遍，虽然这离我们的主页主业有点远，但对后来的招聘和培训极其重要，这也是我们第一次在全球范围内好评如潮。”</p><p></p><h2>怎么判断要不要选择或者切换 Rust、GO？</h2><p></p><p></p><p>不少企业创业之初会选择基于某些开源产品来实现商业版本，这种情况下编程语言其实已经是确定的了，不需要太过纠结。如果从零开始开发某项产品，可以从以下几个方面进行考虑：</p><p></p><p>如果公司内部在 C/C++、Java 上开发规范已经做得很好了，可以先不考虑切换至 Rust。Rust 相当于自带严格的安全性限制，让程序员在大部分情况下没办法写出存在安全隐患的代码，语言本身的设计帮助规避了一些常规问题。如果是基础软件类型的企业，相关从业人员的水平还是值得信任的，一般不会犯太多低级错误。此时，Rust 的收益主要体现在数据库最核心的组件或者功能编写上，对剩下 90% 的部分而言，效率可能比安全更重要。非 Rust 不可的场景有写驱动，比如操作系统内核等，效率绝对高；SSL 加密或者产品内部的某个关键链路，比如浏览器里面的渲染引擎，这类 CPU 密集型又对安全要求较高的场景。非必要场景最好选用社区比较大的编程语言，比如 Java，相对来说也很好招人。考虑语言的向后兼容性。Go 语言在这一点上至今都做得非常好，并且也响应社区用户的意见添加了范型。社区的风格。Rust 的社区是非常开放的，这给该语言带来了很多好处，但也可能带来一些副作用，比如可能会有些分裂，这可能是 Rust 社区未来要考虑的事情，但社区内的氛围相对活跃，可以在其中寻找问题的答案或者志同道合的朋友。“Rust 近几年最新加入的复杂度主要是 Pin 异步编程，但二者的加入确实解决了一些问题，无论是哪种语言都会面临各种选择，这是不同目标平衡取舍的结果。”代码实现逻辑。Rust 语言在设计上与 Go、Java 等都不同，其规避了一些问题。使用 Rust 写出来的程序可以专注优化程序逻辑本身，比如让程序更加适应操作系统、减少线程切换等。</p><p></p><p>Rust 如今已经得到了越来越多企业和开发者的验证，但依旧有新的小众语言出现，如同当年新生的 Rust，企业应该如何判断呢？</p><p></p><h2>新型语言 Zig 也来了，怎么看？</h2><p></p><p></p><p>Zig 就是一门新的、小众的语言，目前还没有发布 1.0 版本，其将竞争对手定为了 C 语言，注意不是 C++，而就是最基础的 C，但也吸收了 Rust 等语言的一些特性。</p><p></p><p>去年中旬因为 Uber 的使用，Zig 引起了一些开发者的关注。Uber 使用 Zig 来编译其 C/C++ 代码。现在，Uber 只在 Go Monorepo（据其内部工程师介绍，Go Monorepo 比 Linux 内核还要大，有几千名工程师在开发和维护） 中使用 bazel-zig-cc，但计划尽可能地将 zig cc 推广到其他需要 C/C++ 工具链的语言。</p><p></p><p>Uber 的工程师表示，与其他工具链相比，zig-cc 提供的 C/C++ 工具链的主要优势是 glibc 版本可配制与 macOS 交叉编译（具体信息可以阅读：<a href=\"https://www.infoq.cn/article/q016NWR7OjHvOJ3Rkzc0\">https://www.infoq.cn/article/q016NWR7OjHvOJ3Rkzc0</a>\"）。</p><p></p><p>如今的 Zig 与七八年前的 Rust 情况相似又不同，当年的 Rust 背后有一群 Molliza 的工程师支持，其理念、质量和解决实际问题的能力是值得信任的，现在的 Zig 虽然有基金会支持，但实际能力还有待商榷。</p><p></p><p>受访的 PingCAP 工程师们对该语言的发展持观望态度，并建议企业在选择这类新兴小众的语言时最好是可以找到那个“非它不可”的理由，如果找不到，就证明这件事情没必要冒险采用新语言，如果有想法，最好可以亲自与创始团队面对面交流，从中得到一些判断。</p><p></p><h2>结语</h2><p></p><p></p><p>自从 ChatGPT 诞生，我们无数次对 AI 的生产力感到惊讶，其可以根据简单的输入生成代码并将这些代码轻松转换成其他编程语言。未来，开发者的工作模式可能会发生翻天覆地的变化，最重要的是我们构建这一切的思路和想法，而不是工具本身。从这个角度出来，关于编程语言优劣的争论就会变得不那么重要。</p><p></p><p>当然，如果你是某一个语言 / 工具的信仰者，着手将其带向全新高度也会比争论更有意义。</p><p></p><p>参考资料：</p><p></p><p>《与开源同行 - 揭秘 PingCAP 七年创业实践》</p><p></p><p>相关阅读：</p><p></p><p>Rust in TiKV (<a href=\"https://www.zenlife.tk/project\">https://www.zenlife.tk/project</a>\")</p><p></p><p>专题推荐：</p><p></p><p><a href=\"https://www.infoq.cn/theme/155\">《选择一门语言，重构技术栈》</a>\"</p><p></p><p>根据初步调研，企业当前存在重构技术栈的需求，原因如下：一是如今很多企业中还存在一些老旧编程语言编写的技术栈，这些技术栈难以维护，且相关人才奇缺；二是某些相对年轻的编程语言具备的特性是企业所需要的，比如Rust清晰定义了变量的生命周期，不仅摒弃 GC 这样的内存和性能杀手，还不用关心手动内存管理，让内存安全和高性能兼得。但是，使用其他编程语言更换技术栈存在很多问题，比如风险极高、人力及其他成本、更换前的评估因素、更换后的效果评估，也存在经过谨慎评估之后决定放弃某项编程语言的案例，本专题希望针对该话题进行深入采访，传递顶尖技术高手的认知。</p>",
    "publish_time": "2023-02-20 09:00:50",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Golang 编程“珠玑”",
    "url": "https://www.infoq.cn/article/74d3c7ddc91e9587f54af4ab0",
    "summary": "<p>作者：崔国科—— MO 研发工程师</p><p></p><h2>导读</h2><p></p><p>2017 年左右开始接触 golang，那时国内关于 golang 的资料还很少。</p><p>现在随着云原生生态的蓬勃发展，在 kubernetes、docker 等等众多明星项目的带动下，国内有越来越多的创业公司以及大厂开始拥抱 golang，各种介绍 golang 的书籍、博客和公众号文章也变得越来越多，其中不乏质量极高的资料。</p><p>相关的资料已经足够丰富，因此这篇文章不会详述 golang 的某一个方面，而是主要从工程实践的角度出发，去介绍一些东西。因为在工作过程中，我注意到一些令人沮丧的代码，其中有些甚至来自于高级程序员。</p><p>下面是本文目录概览，我们将从内存有关的话题开始：</p><p>内存相关Golang Profiling如何写性能测试</p><p></p><p></p><h2>Part 1 内存相关</h2><p></p><p></p><h3>1.1&nbsp;编译器内存逃逸分析</h3><p></p><p>先看这样一段代码：</p><p><code lang=\"go\">package main\n\n//go:noinline\nfunc makeBuffer() []byte {\n    return make([]byte, 1024)\n}\n\nfunc main() {\n    buf := makeBuffer()\n    for i := range buf {\n        buf[i] = buf[i] + 1\n    }\n}\n</code></p><p>示例代码中函数&nbsp;makeBuffer&nbsp;返回的内存位于函数栈上，在 C 语言中，这是一段错误的代码，会导致未定义的行为。</p><p>在 Go 语言中，这样的写法是允许的，Go 编译器会执行&nbsp;escape analysis：当它发现一段内存不能放置在函数栈上时，会将这段内存放置在堆内存上。例如，makeBuffer&nbsp;向上返回栈内存，编译器自动将这段内存放在堆内存上。</p><p>通过&nbsp;-m&nbsp;选项可以查看编译器分析结果：</p><p><code lang=\"go\">$ go build -gcflags=\"-m\" escape.go\n# command-line-arguments\n./escape.go:8:6: can inline main\n./escape.go:5:13: make([]byte, 1024) escapes to heap\n</code></p><p>除此之外，也存在其他一些情况会触发内存的“逃逸”：</p><p>全局变量，因为它们可能被多个 goroutine 并发访问;通过 channel 传送指针</p><p><code lang=\"go\">type Hello struct { name string }\nch := make(chan *Hello, 1)\nch &lt;- &amp;Hello{ name: \"world\"}\n</code></p><p>通过 channel 传送的结构体中持有指针</p><p><code lang=\"go\">type Hello struct { name *string }\nch := make(chan *Hello, 1)\nname := \"world\"\nch &lt;- Hello{ name: &amp;name }\n</code></p><p>局部变量过大，无法放在函数栈上本地变量的大小在编译时未知，例如&nbsp;s := make([]int, 1024)&nbsp;也许不会被放在堆内存上，但是&nbsp;s := make([]int, n)&nbsp;会被放在堆内存上，因为其大小&nbsp;n&nbsp;是个变量对&nbsp;slice&nbsp;的&nbsp;append&nbsp;操作触发了其底层数组重新分配</p><p>注意：上面列出的情况不是详尽的，并且可能随 Go 的演进发生变化。</p><p>在开发过程中，如果程序员不注意 golang 编译器的内存逃逸分析，写出的代码可能会导致“额外”的动态内存分配，而 “额外”的动态内存分配通常会和性能问题联系在一起（具体会在后面 golang gc 的章节中介绍）。</p><p>示例代码给我们的启示是：注意函数签名设计，尽量避免因函数签名设计不合理而导致的不必要内存分配。向上返回一个 slice 可能会触发内存逃逸，向下传入一个 slice 则不会，这方面&nbsp;<a href=\"https://link.zhihu.com/?target=https%3A//github.com/cockroachdb/cockroach/blob/5fbcd8a8deac0205c7df38e340c1eb9692854383/pkg/util/encoding/encoding.go%23L180\">Cockroach Encoding Function</a>\"&nbsp;给出了一个很好的例子。</p><p>接下来，我们看下接口相关的事情。</p><p></p><h3>1.2&nbsp;interface{} / any</h3><p></p><p>any 是 golang 1.18 版本引入的，跟 interface{} 等价。</p><p><code lang=\"go\">type any = interface{}\n</code></p><p>在 golang 中，接口实现 为一个“胖”指针：一个指向实际的数据，一个指向函数指针表（类似于C++ 中的虚函数表）。</p><p>我们来看下面的代码：</p><p><code lang=\"go\">package interfaces\n\nimport (\n  \"testing\"\n)\n\nvar global interface{}\n\nfunc BenchmarkInterface(b *testing.B) {\n  var local interface{}\n  for i := 0; i &lt; b.N; i++ {\n    local = calculate(i) // assign value to interface{}\n  }\n  global = local\n}\n\n// values is bigger than single machine word.\ntype values struct {\n  value  int\n  double int\n  triple int\n}\n\nfunc calculate(i int) values {\n  return values{\n    value:  i,\n    double: i * 2,\n    triple: i * 3,\n  }\n}\n</code></p><p>在性能测试&nbsp;BenchmarkInterface&nbsp;中，我们将函数&nbsp;calculate&nbsp;返回的结果赋值给&nbsp;interface{}&nbsp;类型的变量。</p><p>接下来，对&nbsp;BenchmarkInterface&nbsp;执行&nbsp;memory profile：</p><p><code lang=\"go\">$ go test -run none -bench Interface -benchmem -memprofile mem.out\n\ngoos: darwin\ngoarch: arm64\npkg: github.com/cnutshell/go-pearls/memory/interfaces\nBenchmarkInterface-8    101292834               11.80 ns/op           24 B/op          1 allocs/op\nPASS\nok      github.com/cnutshell/go-pearls/memory/interfaces        2.759s\n\n$ go tool pprof -alloc_space -flat mem.out\n(pprof) top \n(pprof) list iface.BenchmarkInterface\nTotal: 2.31GB\n    2.31GB     2.31GB (flat, cum) 99.89% of Total\n         .          .      7:var global interface{}\n         .          .      8:\n         .          .      9:func BenchmarkInterface(b *testing.B) {\n         .          .     10:   var local interface{}\n         .          .     11:   for i := 0; i &lt; b.N; i++ {\n    2.31GB     2.31GB     12:           local = calculate(i) // assign value to interface{}\n         .          .     13:   }\n         .          .     14:   global = local\n         .          .     15:}\n         .          .     16:\n         .          .     17:// values is bigger than single machine word.\n(pprof)\n</code></p><p>从内存剖析结果看到：向接口类型的变量&nbsp;local&nbsp;赋值，会触发内存“逃逸”，导致额外的动态内存分配。</p><p>go 1.18 引入范型之前，我们都是基于接口实现多态，基于接口实现多态，主要存在下面这些问题：</p><p>丢失了类型信息 ，程序行为从编译阶段转移到运行阶段；程序运行阶段不可避免地需要执行类型转换，类型断言或者反射等操作；为接口类型的变量赋值可能会导致“额外的”内存分配；基于接口的函数调用，实际的调用开销为：指针解引用（确定方法地址）+ 函数执行开销。编译器无法对其执行内联优化，也无法基于内联优化执行进一步的优化。</p><p>关于接口的使用，这里有一些提示：</p><p>代码中避免使用 interface{} 或者 any，至少避免在被频繁使用的数据结构或者函数中使用go 1.18 引入了范型，将接口类型改为范型类型，是避免额外内存分配，优化程序性能的一个手段</p><p></p><h3>1.3&nbsp;Golang gc</h3><p></p><p>前面我们了解到，golang 编译器执行 escape analysis 后，根据需要数据可能被“搬”到堆内存上。</p><p>这里简单地介绍下 golang 的 gc，从而了解写 golang 代码时为什么应该尽量避免“额外的”内存分配。</p><p>1.3.1 Introduction</p><p>gc 是 go 语言非常重要的一部分，它大大简化了程序员写并发程序的复杂度。</p><p>人们发现写工作良好的并发程序似乎也不再是那少部分程序员的独有技能。</p><p>glang gc 使用一棵树来维护堆内存对象的引用，属于追踪式的 gc，它基于“标记-清除“算法工作，主要分为两个阶段：</p><p>标记阶段- 遍历所有堆内存对象，判断这些对象是否在用；清除阶段- 遍历树，清除没有被引用的堆内存对象。</p><p>执行 gc 时，golang 首先会执行一系列操作并停止应用程序的执行，即&nbsp;stopping the world，之后恢复应用程序的执行，同时 gc 其他相关的操作还会并行地执行。所以 golang 的 gc 也被称为&nbsp;concurrent mark-and-sweep，这样做的目的是尽可能减少&nbsp;STW&nbsp;对程序运行的影响。</p><p>严格地说，STW&nbsp;会发生两次，分别在标记开始和标记结束时。</p><p>golang gc 包括一个&nbsp;scavenger，定期将不再使用的内存返还给操作系统。</p><p>也可以在程序中调用&nbsp;debug.FreeOSMemory()，手动将内存返还给操作系统。</p><p></p><p>1.3.2 gc 触发机制</p><p>相比于 java，golang 提供的 gc 控制方式比较简单：通过环境变量&nbsp;GOGC&nbsp;来控制。</p><p>runtime/debug.SetGCPercent allows changing this percentage at run time.</p><p>GOGC&nbsp;定义了触发下次 gc 时堆内存的增长率，默认值为 100，即上次 gc 后，堆内存增长一倍时，触发另一次 gc。</p><p>例如，gc 触发时当前堆内存的大小时 128MB，如果&nbsp;GOGC=100，那么当堆内存增长为 256MB时，执行下一次 gc。</p><p>另外，如果 golang 两分钟内没有执行过 gc，会强制触发一次。</p><p>我们也可以在程序中调用&nbsp;runtime.GC()&nbsp;主动触发 gc。</p><p><code lang=\"go\"># 通过设置环境变量 GODEBUG 可以显示 gc trace 信息\n\n$ GODEBUG=gctrace=1 go test -bench=. -v\n\n# 当 gc 运行时，相关信息会写到标准错误中\n</code></p><p>注意：为了减少 gc 触发次数而增加 GOGC 值并不一定能带来线性的收益，因为即便 gc 触发次数变少了，但是 gc 的执行可能会因为更大的堆内存而有所延长。在大多数情况下，GOGC 维持在默认值 100 即可。</p><p></p><p>1.3.3 gc hints&nbsp;</p><p>如果我们的代码中存在大量“额外”的堆内存分配，尤其是在代码关键路径上，对于性能的负面影响是非常大的：</p><p>首先，堆内存的分配本身就是相对耗时的操作其次，大量“额外”的堆内存分配意味着额外的 gc 过程，STW 会进一步影响程序执行效率。</p><p>极端情况下，短时间内大量的堆内存分配，可能会直接触发 OOM，gc 甚至都没有执行的机会。</p><p>所以，不要“天真”的以为 gc 会帮你搞定所有的事情：你留给 gc 处理的工作越少，你的性能才会越“体面”。</p><p>从性能优化的角度，消除那些“额外的”内存分配收益十分明显，通常也会是第一或者第二优先的选项。</p><p>然而，堆内存的使用并不能完全避免，当需要使用时，可以考虑采用某些技术，例如通过&nbsp;sync.Pool&nbsp;复用内存来减少 gc 压力。</p><p></p><p>1.3.4 有了 gc 为什么还会有内存泄漏？</p><p>即便 golang 是 gc 语言，它并不是一定没有内存泄漏，下面两种情况会导致内存泄漏的情况：</p><p>引用堆内存对象的对象长期存在；goroutine 需要消耗一定的内存来保存用户代码的上下文信息，goroutine 泄漏会导致内存泄漏。</p><p></p><p>1.3.5 代码演示</p><p>代码见于文件&nbsp;<a href=\"https://link.zhihu.com/?target=https%3A//gist.github.com/cnutshell/817b17f6eb4fa5c4383c0c7d53c744c0\">gc.go</a>\"</p><p>函数&nbsp;allocator&nbsp;通过 channel 传送&nbsp;buf&nbsp;类型的结构体，buf&nbsp;类型的结构体持有堆内存的引用；函数&nbsp;mempool&nbsp;通过 channel 接收来自&nbsp;allocator&nbsp;的 buf，循环记录在 slice 中；同时，mempool 还会定期打印应用当前内存状态，具体含义参考&nbsp;<a href=\"https://link.zhihu.com/?target=https%3A//pkg.go.dev/runtime%40go1.20%23MemStats\">runtime.MemStats</a>\"。</p><p>运行代码 gc.go：</p><p><code lang=\"go\">$ go run gc.go\nHeapSys(bytes),PoolSize(MiB),HeapAlloc(MiB),HeapInuse(MiB),HeapIdle(bytes),HeapReleased(bytes)\n 12222464,     5.00,     7.11,     7.45,  4415488,  4300800\n 16384000,    10.00,    12.11,    12.45,  3334144,  3153920\n 24772608,    18.00,    20.11,    20.45,  3334144,  3121152\n 28966912,    22.00,    24.11,    24.45,  3334144,  3121152\n 33161216,    25.00,    27.11,    27.45,  4382720,  4169728\n 37355520,    32.00,    34.11,    34.45,  1236992,   991232\n 41549824,    36.00,    38.11,    38.45,  1236992,   991232\n 54132736,    48.00,    50.11,    50.45,  1236992,   991232\n 58327040,    51.00,    53.11,    53.45,  2285568,  2039808\n</code></p><p>通过程序输出结果，我们可以了解到：如果程序中存在变量持有对堆内存的引用，那么这块堆内存不会被 gc 回收。</p><p>因此使用引用了堆内存的变量赋值时，例如将其赋值给新的变量，需要注意避免出现内存泄漏。通常建议将赋值有关的操作封装在方法中，以通过合理的 API 设计避免出现“意想不到”内存泄露。并且封装还带来的好处是提高了代码的可测性。</p><p></p><p>1.3.6 参考资料</p><p>Blog:&nbsp;<a href=\"https://link.zhihu.com/?target=https%3A//research.swtch.com/interfaces\">Go Data Structures: Interfaces</a>\"<a href=\"https://link.zhihu.com/?target=https%3A//pkg.go.dev/runtime%40go1.20%23hdr-Environment_Variables\">GOGC on golang's document</a>\"<a href=\"https://link.zhihu.com/?target=https%3A//www.bookstack.cn/read/qcrao-Go-Questions/GC-GC.md\">GC 的认识</a>\"</p><p></p><p></p><h2>Part 2 Golang Profiling</h2><p></p><p>profiler 运行用户程序，同时配置操作系统定期送出 SIGPROF 信号：</p><p>收到 SIGPRFO 信号后，暂停用户程序执行；profiler 搜集用户程序运行状态；搜集完毕恢复用户程序执行。</p><p>如此循环。</p><p>profiler 是基于采样的，对程序性能存在一定程度的影响。</p><p></p><blockquote>\"Before you profile, you must have a stable environment to get repeatable results.\"</blockquote><p></p><p></p><h3>2.1&nbsp;Supported Profiling</h3><p></p><p></p><blockquote><a href=\"https://link.zhihu.com/?target=https%3A//pkg.go.dev/runtime/pprof%23Profile\">By default, all the profiles are listed in runtime/pprof.Profile</a>\"</blockquote><p></p><p>a. CPU Profiling</p><p>CPU profiling 使能后，golang runtime 默认每 10ms 中断应用程序，并记录 goroutine 的堆栈信息。</p><p>b. Memory Profiling</p><p>Memory profiling 和 CPU profiling 一样，也是基于采样的，它会在堆内存分配时记录堆栈信息。</p><p>默认每 1000 次堆内存分配会采样一次，这个频率可以配置。</p><p>注意：Memory profiling 仅记录堆内存分配信息，忽略栈内存的使用。</p><p>c. Block Profiling</p><p>Block profiling 类似于 CPU profiling，不过它记录 goroutine 在共享资源上等待的时间。</p><p>它对于检查应用的并发瓶颈很有帮助，Blocking 统计对象主要包括：</p><p>读/写 unbuffered channel写 full buffer channel，读 empty buffer channel加锁操作</p><p>如果基于&nbsp;net/http/pprof， 应用程序中需要调用 runtime.SetBlockProfileRate 配置采样频率。</p><p>d. Mutex Profiling</p><p>Go 1.8 引入了 mutex profile，允许你捕获一部分竞争锁的 goroutines 的堆栈。</p><p>如果基于&nbsp;net/http/pprof， 应用程序中需要调用 runtime.SetMutexProfileFraction 配置采样频率。</p><p>注意：通过&nbsp;net/http/pprof&nbsp;对线上服务执行 profiling 时，不建议修改 golang profiler 默认值，因为某些 profiler 参数的修改，例如增加 memory profile sample rate，可能会导致程序性能出现明显的降级，除非你明确的知道可能造成的影响。</p><p></p><p></p><h3>2.2 Profiling Commands</h3><p></p><p>我们可以从&nbsp;go test&nbsp;命令，或者从使用&nbsp;net/http/pprof&nbsp;的应用中获取到 profile 文件：</p><p><code lang=\"go\">## 1. From unit tests\n$ go test [-blockprofile | -cpuprofile | -memprofile | -mutexprofile] xxx.out\n\n## 2. From long-running program with `net/http/pprof` enabled\n## 2.1 heap profile\n$ curl -o mem.out http://localhost:6060/debug/pprof/heap\n\n## 2.2 cpu profile\n$ curl -o cpu.out http://localhost:6060/debug/pprof/profile?seconds=30</code></p><p>获取到 profile 文件之后，通过&nbsp;go tool pprof&nbsp;进行分析：</p><p><code lang=\"go\"># 1. View local profile\n$ go tool pprof xxx.out\n\n# 2. View profile via http endpoint\n$ go tool pprof http://localhost:6060/debug/pprof/block\n$ go tool pprof http://localhost:6060/debug/pprof/mutex</code></p><p></p><h3>2.3&nbsp;Golang Trace</h3><p></p><p>我们可以从&nbsp;go test&nbsp;命令，或者从使用&nbsp;net/http/pprof&nbsp;的应用中获取到 trace 文件：</p><p><code lang=\"go\"># 1. From unit test\n$ go test -trace trace.out\n\n# 2. From long-running program with `net/http/pprof` enabled\ncurl -o trace.out http://localhost:6060/debug/pprof/trace?seconds=5\n</code></p><p>获取到 trace 文件之后，通过&nbsp;go tool trace&nbsp;进行分析，会自动打开浏览器：</p><p><code lang=\"go\">$ go tool trace trace.out\n</code></p><p></p><h3>2.4&nbsp;Profiling Hints</h3><p></p><p>如果大量时间消耗在函数 runtime.mallocgc，意味着程序发生了大量堆内存分配，通过 Memory Profiling 可以确定分配堆内存的代码在哪里；</p><p>如果大量的时间消耗在同步原语（例如 channel，锁等等）上，程序可能存在并发问题，通常意味着程序工作流程需要重新设计；</p><p>如果大量的时间消耗在&nbsp;syscall.Read/Write，那么程序有可能执行大量小 IO；</p><p>如果 GC 组件消耗了大量的时间，程序可能分配了大量的小内存，或者分配的堆内存比较大。</p><p></p><h3>2.5&nbsp;代码演示</h3><p></p><p>代码见于文件&nbsp;<a href=\"https://link.zhihu.com/?target=https%3A//gist.github.com/cnutshell/80e1724c6bfcabe79485cf0b7167aca0\">contention_test.go</a>\"：</p><p>Block Profiling with Unit Test</p><p><code lang=\"go\">$ go test -run ^TestContention$ -blockprofile block.out\n$ go tool pprof block.out\n(pprof) top\n(pprof) web\n</code></p><p>Mutex Profiling with Unit Test</p><p><code lang=\"go\">$ go test -run ^TestContention$ -mutexprofile mutex.out\n$ go tool pprof mutex.out\n(pprof) top\n(pprof) web\n</code></p><p>Trace with Unit Test</p><p><code lang=\"go\">$ go test -run ^TestContention$ -trace trace.out\n$ go tool trace trace.out</code></p><p></p><p></p><h3>2.6&nbsp;参考资料</h3><p></p><p><a href=\"https://link.zhihu.com/?target=https%3A//pkg.go.dev/net/http/pprof%40go1.20%23hdr-Usage_examples\">net/http/pprof examples</a>\"</p><p></p><p></p><h2>Part 3 如何写性能测试</h2><p></p><p>性能问题不是猜测出来的，即便我们“强烈的认为”某处代码是性能瓶颈，也必须经过验证。</p><p></p><blockquote>\"Those who can make you believe absurdities can make you commit atrocities\" - Voltaire</blockquote><p></p><p>对于性能测试来说，很容易写出不准确的 Benchmark，从而形成错误的印象。</p><p></p><h3>3.1&nbsp;Reset or Pause timer</h3><p></p><p><code lang=\"go\">func BenchmarkFoo(b *testing.B) {\n  heavySetup()  // 在 for 循环之前执行设置工作，如果设置工作比较耗时，那么会影响测试结果的准确性\n  for i := 0; i &lt; b.N; i++ {\n    foo()\n  }\n}</code></p><p></p><p>优化方式</p><p><code lang=\"go\">func BenchmarkFoo(b *testing.B) {\n  heavySetup()\n  b.ResetTimer()  // 重置 timer，保证测试结果的准确性\n  for i := 0; i &lt; b.N; i++ {\n    foo()\n  }\n}</code></p><p>如何停止timer</p><p><code lang=\"go\">func BenchmarkFoo(b *testing.B) {\n  for i := 0; i &lt; b.N; i++ {\n    b.StopTimer() // 停止 timer\n    heavySetup()\n    b.StartTimer() // 启动 timer\n    foo()\n  }\n}</code></p><p></p><h3>3.2&nbsp;提高测试结果可信度</h3><p></p><p>对于 Benchmark，有很多因素会影响结果的准确性：</p><p>机器负载情况电源管理设置热扩展(thermal scaling)……</p><p>相同的性能测试代码，在不同的架构，操作系统下运行可能会产生截然不同的结果；</p><p>相同的 Benchmark 即便在同一台机器运行，前后也可能产生不一致的数据。</p><p>简单的方式是增加 Benchmark 运行次数或者多次运行测试来获取相对准确的结果：</p><p>通过&nbsp;-benchtime&nbsp;设置性能测试时间（默认 1秒）通过&nbsp;-count&nbsp;多次运行 Benchmark</p><p><code lang=\"go\">package benchmark\n\nimport (\n        \"sync/atomic\"\n        \"testing\"\n)\n\nfunc BenchmarkAtomicStoreInt32(b *testing.B) {\n        var v int32\n        for i := 0; i &lt; b.N; i++ {\n                atomic.StoreInt32(&amp;v, 1)\n        }\n}\n\nfunc BenchmarkAtomicStoreInt64(b *testing.B) {\n        var v int64\n        for i := 0; i &lt; b.N; i++ {\n                atomic.StoreInt64(&amp;v, 1)\n        }\n}\n</code></p><p>多次运行测试，得出置信度较高的结果：</p><p><code lang=\"go\">$ go test -bench Atomic -count 10 | tee stats.txt\n\n$ benchstat stats.txt\ngoos: darwin\ngoarch: arm64\npkg: github.com/cnutshell/go-pearls/benchmark\n                   │   stats.txt   │\n                   │    sec/op     │\nAtomicStoreInt32-8   0.3131n ± ∞ ¹\nAtomicStoreInt64-8   0.3129n ± ∞ ¹\ngeomean              0.3130n\n¹ need &gt;= 6 samples for confidence interval at level 0.95\n</code></p><p></p><blockquote>如果提示 benchstat 未找到，通过 go install 命令安装：go install&nbsp;http://golang.org/x/perf/cmd/benchstat@latest</blockquote><p></p><p></p><h3>3.3&nbsp;注意编译器优化</h3><p></p><p><code lang=\"go\">package benchmark\n\nimport \"testing\"\n\nconst (\n        m1 = 0x5555555555555555\n        m2 = 0x3333333333333333\n        m4 = 0x0f0f0f0f0f0f0f0f\n)\n\nfunc calculate(x uint64) uint64 {\n        x -= (x &gt;&gt; 1) &amp; m1\n        x = (x &amp; m2) + ((x &gt;&gt; 2) &amp; m2)\n        return (x + (x &gt;&gt; 4)) &amp; m4\n}\n\nfunc BenchmarkCalculate(b *testing.B) {\n        for i := 0; i &lt; b.N; i++ {\n                calculate(uint64(i))\n        }\n}\n\nfunc BenchmarkCalculateEmpty(b *testing.B) {\n        for i := 0; i &lt; b.N; i++ {\n                // empty body\n        }\n}\n</code></p><p>运行示例代码中的测试，两个测试的结果相同：</p><p><code lang=\"go\">$ go test -bench Calculate\ngoos: darwin\ngoarch: arm64\npkg: github.com/cnutshell/go-pearls/benchmark\nBenchmarkCalculate-8            1000000000               0.3196 ns/op\nBenchmarkCalculateEmpty-8       1000000000               0.3154 ns/op\nPASS\nok      github.com/cnutshell/go-pearls/benchmark        0.814s\n</code></p><p>那么如何避免这种情况呢，前面介绍 golang 接口的时候，给出了一个例子：</p><p><code lang=\"go\">var global interface{}\n\nfunc BenchmarkInterface(b *testing.B) {\n  var local interface{}\n  for i := 0; i &lt; b.N; i++ {\n    local = calculate(uint64(i)) // assign value to interface{}\n  }\n  global = local\n}\n</code></p><p>将被&nbsp;calculate&nbsp;的返回值赋给本地变量&nbsp;local，循环结束后将本地变量&nbsp;local&nbsp;赋值给一个全局变量&nbsp;global，这样可以避免函数&nbsp;calculate&nbsp;被编译器优化掉。</p><p></p><h3>3.4&nbsp;总结</h3><p></p><p>错误的性能测试结果会导致我们做出错误的决定，正所谓“差之毫厘，谬以千里”，写性能测试代码并不是表面上看起来的那么简单。</p>",
    "publish_time": "2023-02-20 11:36:51",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]