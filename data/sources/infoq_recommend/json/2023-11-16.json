[
  {
    "title": "Java近期新闻：JDK 22的JEP、Spring Shell、Quarkus、Apache Camel、JDKMon、J-Fall 2023",
    "url": "https://www.infoq.cn/article/rlyAMUAq5w6EJej8lXxv",
    "summary": "<p></p><h4>OpenJDK</h4><p></p><p>在结束了审查之后，<a href=\"https://openjdk.org/jeps/460\">JEP 460，Vector API（第七轮孵化）</a>\"已从JDK 22的Proposed to Target状态<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-November/008440.html\">提升</a>\"为Targeted状态。该JEP由<a href=\"https://openjdk.org/projects/panama/\">Panama</a>\"项目赞助，整合了对前六轮孵化反馈的改进：JEP 448，<a href=\"https://openjdk.org/jeps/448\">Vector API (第六轮孵化)</a>\"，在JDK 21中交付；JEP 438，<a href=\"https://openjdk.org/jeps/438\">Vector API (第五轮孵化)</a>\"，在JDK 20中交付；JEP 426，<a href=\"https://openjdk.org/jeps/426\">Vector API (第四轮孵化)</a>\"，在JDK 19中交付；JEP 417，<a href=\"https://openjdk.java.net/jeps/417\">Vector API (第三轮孵化)</a>\"，在JDK 18中交付；JEP 414，<a href=\"https://openjdk.java.net/jeps/414\">Vector API (第二轮孵化)</a>\"，在JDK 17中交付；以及JEP 338，<a href=\"https://openjdk.java.net/jeps/338\">Vector API (孵化器)</a>\"，在JDK 16中作为<a href=\"https://openjdk.java.net/jeps/11\">孵化器模块</a>\"发布。JEP 448最重要的变更包括对<a href=\"https://docs.oracle.com/en/graalvm/enterprise/20/docs/reference-manual/compiler/#graalvm-compiler\">JVM编译器接口</a>\"（JVMCI）的增强，以支持Vector API值。</p><p>&nbsp;</p><p>JEP 459：<a href=\"https://openjdk.org/jeps/459\">字符串模板（第二次预览版）</a>\"，已从JDK 22的Candidate状态<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-November/008441.html\">提升</a>\"为Proposed to Target状态。这个JEP提供了第一轮预览的第二个预览版本：JEP 430，<a href=\"https://openjdk.org/jeps/430\">字符串模板（预览版）</a>\"，在JDK 21中交付。该特性通过字符串模板增强了Java编程语言，字符串模板包含嵌入式表达式，在运行时对嵌入式表达式进行求值和验证。有关JEP 430的更多详细信息可以在InfoQ的<a href=\"https://www.infoq.com/news/2023/04/java-gets-a-boost-with-string/\">新闻报道</a>\"中找到。其审查预计将于2023年11月15日结束。</p><p>&nbsp;</p><p>甲骨文（Oracle）的技术人员顾问<a href=\"https://www.linkedin.com/in/gavin-bierman-a0173075/\">Gavin Bierman</a>\"<a href=\"https://mail.openjdk.org/pipermail/amber-spec-observers/2023-November/004150.html\">发布</a>\"了JEP 463，<a href=\"https://openjdk.org/jeps/463\">隐式类和实例主方法（第二次预览版）</a>\"的<a href=\"https://draft specification\">规范草案</a>\"，以供Java社区审查。</p><p>&nbsp;</p><p></p><h4>JDK 22</h4><p></p><p>JDK 22<a href=\"https://jdk.java.net/22/\">早期访问构建版本</a>\"中的第<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-22%2B23\">23</a>\"版于上周发布，其中包括对第22版的<a href=\"https://github.com/openjdk/jdk/compare/jdk-22%2B22...jdk-22%2B23\">更新</a>\"以及各种<a href=\"https://bugs.openjdk.org/issues/?jql=project%20%3D%20JDK%20AND%20fixversion%20%3D%2022%20and%20%22resolved%20in%20build%22%20%3D%20b19%20order%20by%20component%2C%20subcomponent\">问题</a>\"的修复。有关该版本的更多详细信息，请参阅<a href=\"https://jdk.java.net/22/release-notes\">发布说明</a>\"。</p><p>&nbsp;</p><p>对于JDK 22，鼓励开发人员通过<a href=\"https://bugreport.java.com/bugreport/\">Java Bug Database</a>\"报告缺陷。</p><p>&nbsp;</p><p></p><h4>Spring框架</h4><p></p><p><a href=\"https://spring.io/projects/spring-shell\">Spring Shell</a>\"的3.2.0-M3、3.1.5、3.0.9和2.1.14版本已经<a href=\"https://spring.io/blog/2023/11/08/spring-shell-2-1-14-3-0-9-3-1-5-and-3-2-0-m3-are-now-available\">发布</a>\"，并且包含一些值得注意的更改，例如：升级到<a href=\"https://github.com/jline/jline3/blob/master/README.md\">JLine</a>\"&nbsp;3.24.1，以解决 stdout 在非交互模式下重定向到 stderr 的问题；终端用户界面（<a href=\"https://docs.spring.io/spring-shell/reference/tui/index.html\">Terminal UI</a>\"）的改进，尤其是自动配置能力；并且解决了tab补全可能因延迟初始化而失败的问题。这些版本分别基于Spring Boot 3.1.0-RC2、3.1.5、3.0.12和2.7.17构建。有关这些版本的更多详细信息，请参阅版本<a href=\"https://github.com/spring-projects/spring-shell/releases/tag/v3.2.0-M3\">3.2.0-M3</a>\",、版本<a href=\"https://github.com/spring-projects/spring-shell/releases/tag/v3.1.5\">3.1.5</a>\"、版本<a href=\"https://github.com/spring-projects/spring-shell/releases/tag/v3.0.9\">3.0.9</a>\"和版本<a href=\"https://github.com/spring-projects/spring-shell/releases/tag/v2.1.14\">2.1.14</a>\"的发布说明。</p><p>&nbsp;</p><p></p><h4>Quakrus</h4><p></p><p><a href=\"https://quarkus.io/\">Quarkus</a>\"&nbsp;3.5.1的<a href=\"https://quarkus.io/blog/quarkus-3-5-1-released/\">发布</a>\"带来了一些值得注意的变更，例如：修复了OIDC作用域为空时权限映射的问题；改进了<a href=\"https://quarkus.io/guides/dev-services#keycloak\">Keycloak</a>\"&nbsp;DevService中的错误消息和文档；以及由于不稳定而临时禁用Windows操作系统上的 VertxMDCTest 类。有关该版本的更多详细信息，请参阅<a href=\"https://github.com/quarkusio/quarkus/releases/tag/3.5.1\">变更日志</a>\"。</p><p>&nbsp;</p><p>同样，Quarkus 3.2.8的<a href=\"https://quarkus.io/blog/quarkus-3-2-8-final-released/\">发布</a>\"也带来了一些值得注意的变更，例如：修复了在 AccessTokenRequestReactiveFilter 类中定义的 propagateToken() 方法，该方法使用承载方案复制了授权标头；在 QuarkusSecurityTestExtension 类中定义的 afterEach() 方法不应在未使用 @TestSecurity 注释的情况下调用 CDI 类中指定的 current() 方法；以及修复了由于使用 ForwardedProxyHandler 类而导致的 NullPointerException ，该类在找不到记录时允许 null 值。有关该版本的更多详细信息，请参阅<a href=\"https://github.com/quarkusio/quarkus/releases/tag/3.2.8.Final\">变更日志</a>\"。</p><p>&nbsp;</p><p>这两个版本都解决了<a href=\"https://access.redhat.com/security/cve/cve-2023-5720\">CVE-2023-5720</a>\"的问题，在这种漏洞情况下，攻击者可以通过应用程序访问构建系统中的潜在敏感信息，因为在Quarkus中发现了一个缺陷，它无法正确清理使用Gradle插件创建的构件。所以这样可以保留某些构建系统信息。</p><p>&nbsp;</p><p></p><h4>Apache软件基金会</h4><p></p><p>&nbsp;</p><p>Apache Camel 3.14.10的<a href=\"https://camel.apache.org/blog/2023/11/RELEASE-3.14.10/\">发布</a>\"提供了漏洞修复、依赖项升级和一些改进：更改了<a href=\"https://camel.apache.org/components/3.20.x/sftp-component.html\">SFTP</a>\"组件选项 chmodDirectory 中的目录权限；以及在<a href=\"https://camel.apache.org/components/4.0.x/micrometer-component.html#MicrometerComponent-registry\">Meter Registry</a>\"组件中收集授权数据。有关该版本的更多详细信息，请参阅<a href=\"https://camel.apache.org/releases/release-3.14.10/\">发布说明</a>\"。</p><p>&nbsp;</p><p>为了与Quarkus保持一致，<a href=\"https://github.com/apache/camel-quarkus/blob/main/README.adoc\">Camel Quarkus</a>\" 3.2.2也已<a href=\"https://camel.apache.org/blog/2023/11/camel-quarkus-release-3.2.2/\">发布</a>\"，但没有任何记录在案的重大修复、依赖升级或改进。有关该版本的更多细节，请参阅<a href=\"https://camel.apache.org/releases/q-3.2.2/\">发布说明</a>\"。</p><p>&nbsp;</p><p></p><h4>JDKMon</h4><p></p><p><a href=\"https://github.com/HanSolo/JDKMon\">JDKMon</a>\"是一个监视并更新已安装JDK的工具，其<a href=\"https://github.com/HanSolo/JDKMon/releases/tag/17.0.81\">17.0.81</a>\"版本已于上周发布。这个新版本由Azul的首席工程师<a href=\"https://de.linkedin.com/in/gerritgrunwald\">Gerrit Grunwald</a>\"创建，提供了依赖项升级、Gradle 8.4的构建升级，以及一些新功能：能够从列表中选择JEP、JSR或OpenJDK项目，并在默认浏览器中打开该选择；JDK发行版的工具提示现在也会显示磁盘上的模块数量和大小。</p><p>&nbsp;</p><p></p><h4>Arquillian</h4><p></p><p><a href=\"https://arquillian.org/\">Arquillian</a>\" 1.7.2.Final已<a href=\"https://github.com/arquillian/arquillian-core/releases/tag/1.7.2.Final\">发布</a>\"，其为参数化测试的失败提供了修复，尽管测试失败，仍能报告通过。有关该版本的更多详细信息，请参阅<a href=\"https://github.com/arquillian/arquillian-core/compare/1.7.1.Final...1.7.2.Final\">问题列表</a>\"。</p><p>&nbsp;</p><p></p><h4>Gradle</h4><p></p><p><a href=\"https://gradle.org/\">Gradle</a>\"&nbsp;8.5.0发布了<a href=\"https://github.com/gradle/gradle/releases/tag/v8.5.0-RC1\">第一个候选版本</a>\"，包括：完全支持在JDK 21上编译、测试和运行；对<a href=\"https://docs.gradle.org/8.5-rc-1/userguide/kotlin_dsl.html\">Kotlin DSL</a>\"的改进，包括在预编译的Kotlin脚本插件中<a href=\"https://docs.gradle.org/8.5-rc-1/release-notes.html#faster-first-use\">更快地首次使用</a>\"和<a href=\"https://docs.gradle.org/8.5-rc-1/release-notes.html#catalog-precompiled\">版本目录支持</a>\"；改进了错误和警告的报告。有关该版本的更多详细信息，请参阅<a href=\"https://github.com/arquillian/arquillian-core/compare/1.7.1.Final...1.7.2.Final\">发布说明</a>\"。</p><p>&nbsp;</p><p></p><h4>J-Fall 2023</h4><p></p><p>上周，2023 <a href=\"https://jfall.nl/\">J-Fall</a>\"会议在荷兰Ede的<a href=\"https://www.pathe.nl/bioscoop/ede\">Pathé Ede</a>\"举行，庆祝其成立20周年，来自Java社区的<a href=\"https://jfall.nl/speakers-2023/\">演讲者</a>\"在会前<a href=\"https://jfall.nl/preconference/\">研讨会</a>\"、主题演讲、50分钟的会议和<a href=\"https://jfall.nl/timetable/\">会议议程上</a>\"发表了闪电演讲。有关J-Fall 2023的详细报告请参阅Eclipse基金会Jakarta EE开发人员倡导者<a href=\"https://www.linkedin.com/in/ivargrimstad/\">Ivar Grimstad</a>\"的<a href=\"https://www.agilejava.eu/2023/11/11/j-fall-2023/\">博客文章</a>\"。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/11/java-news-roundup-nov06-2023/\">https://www.infoq.com/news/2023/11/java-news-roundup-nov06-2023/</a>\"</p>",
    "publish_time": "2023-11-16 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Angular v17亮点解读：全新功能提升开发者体验",
    "url": "https://www.infoq.cn/article/TqCmpDM6KtvjZchqiXZM",
    "summary": "<p>上个月举办了Angular红色盾牌的13周年庆。曾几何时，AngularJS是通过JavaScript框架满足日益增加的web开发体验需求的先锋队。今天在v17版本中，我们将以全新品牌形象、面向未来的功能设计，和大家一起重新定义应用性能和开发体验的新标准。</p><p>&nbsp;</p><p>很高兴为大家介绍v17版本带来的新功能：</p><p></p><p>延迟视图将性能和开发体验提高到了新高度相对于行业标准，基于内置控制流的循环性能提高了90%在构建速度上，混合渲染模式和客户端渲染模式，分别提高87%和67%全新的外观，体现着Angular功能的先进性全新的互动式学习体验还有数十个新特性和能力增强</p><p>&nbsp;</p><p></p><h1>面向未来的品牌形象</h1><p></p><p></p><p>过去几个版本中，Angular一直都在复兴之路上狂奔。我们通过改进诸如基于信号的响应式编程、hydration（译注：服务端渲染客户端激活的模式）、独立组件、组合指令等数十项特性，不断增强发展势头。尽管Angular的发展迅速，但其品牌形象却未能跟上这种快速的演变——自从AngularJS早期以来，它的品牌形象几乎没有变化。</p><p>&nbsp;</p><p>今天，这个被数百万开发者使用和喜爱的框架将展现出全新的面貌，这一新形象也衬托了其面向未来的开发体验和卓越性能！</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/d5/d5bb4c099265b677450c7a98499f655f.png\" /></p><p></p><p>&nbsp;</p><p></p><h1>面向未来的文档</h1><p></p><p></p><p>随着新品牌的推出，我们为Angular文档也打造了一个崭新的家园——<a href=\"https://angular.dev/\">angular.dev网站</a>\"。在这个全新的文档网站中，我们重新设计了结构，编写了新的指南，优化了内容，并构建了一个交互式的学习平台，使开发者能够按照自己的节奏在浏览器中深入学习Angular和Angular CLI。</p><p>&nbsp;</p><p>新的交互式的学习平台采用了<a href=\"https://webcontainers.io/\">WebContainers</a>\" 技术，因此开发者可以在任何现代的网络浏览器中充分使用Angular CLI的强大功能！</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/b8/32/b8f09b7a8c68a2391975f9d0ef346c32.gif\" /></p><p></p><p>基于<a href=\"https://webcontainers.io/\">WebContainers</a>\"的Angular交互式体验页面</p><p>&nbsp;</p><p>今天，我们推出了angular.dev的体验版，并计划在v18版本中将其作为Angular的默认网站。开发者可以在“<a href=\"https://blog.angular.io/announcing-angular-dev-1e1205fa3039\">angular.dev的官方发布</a>\"”这篇文章中了解更多关于Angular新品牌形象和以及<a href=\"https://angular.dev/\">angular.dev</a>\"网站的信息。</p><p>&nbsp;</p><p>现在，让我来把在v17版本中那些迫不及待想要告诉大家的新功能做个详细介绍！</p><p>&nbsp;</p><p></p><h1>内置控制流</h1><p></p><p>&nbsp;</p><p>为了提升开发体验，我们发布了一种新的块模板语法。基于该语法，只需使用简单、声明式的API即可实现强大的功能。在底层，Angular编译器会将这种语法转换成高效的JavaScript指令，这些指令可以执行流程控制、懒加载等操作。</p><p>&nbsp;</p><p>基于新的块模板语法，我们做了内置控制流的优化。通过用户调研，我们发现许多开发者在使用*ngIf、*ngSwitch和*ngFor时经常面临重重困难。甚至包括我本人在内也是如此，虽然我个人从2016年就开始使用Angular，且作为Angular团队成员也有5年之久，但在使用*ngFor和trackBy时，依然需要查阅文档才能确保正确使用。在收集了社区、合作伙伴的反馈，并进行了<a href=\"https://blog.angular.io/meet-angulars-new-control-flow-a02c6eee7843\">用户体验调研</a>\"之后，我们为Angular开发了一种新的内置控制流！</p><p>&nbsp;</p><p>新的内置控制流带来了如下好处：</p><p></p><p>更贴近JavaScript语法，更符合开发者使用习惯，更直观，从而减少了查阅文档的需求得益于更优化的类型收敛（type narrowing），类型检查得到了很好的改善内置控制流是构建阶段核心处理的部分，除了大大减少运行时的消耗（甚至直接消失）之外，还将使你的应用程序包大小整体减少30KB之多，从而进一步提高应用的核心网络指标（Core Web Vital）的得分无需额外导入，即可在模版中通过变量来使用显著的性能提升，稍后我们会专门介绍</p><p>&nbsp;</p><p></p><h1>条件语句</h1><p></p><p></p><p>让我们来看一个在当前版本和v17版本中使用*ngIf的对比：</p><p>&nbsp;</p><p><code lang=\"null\"></code></p><div><code lang=\"null\">\n  The user is logged in\n</code></div><code lang=\"null\">\n\n  The user is not logged in\n</code><p></p><p>&nbsp;</p><p>使用内置if语句之后：</p><p>&nbsp;</p><p><code lang=\"null\">@if (loggedIn) {\n  The user is logged in\n} @else {\n  The user is not logged in\n}</code></p><p></p><p>与传统的*ngIf通过使用模块替换来实现else相比，能够直接编写@else内容是一个重大的简化。当前的控制流也使得@else if的支持变得非常简单，而这在之前的版本中这是无法实现的。</p><p>&nbsp;</p><p>在*ngSwitch中，使用内置控制流改进后显现出来的易用性就更加突出了：</p><p>&nbsp;</p><p><code lang=\"null\"></code></p><div><code lang=\"null\">\n  \n  \n  \n</code></div><p></p><p>&nbsp;</p><p>使用内置switch语句之后：</p><p>&nbsp;</p><p><code lang=\"null\">@switch (accessLevel) {\n  @case ('admin') {  }\n  @case ('moderator') {  }\n  @default {  }\n}</code></p><p>&nbsp;</p><p>在新的控制流中，在@switch的条件分支上更好、更显著地实现了类型收敛，而这在老的 *ngSwitch中是无法做到的。</p><p>&nbsp;</p><p></p><h1>内置循环</h1><p></p><p></p><p>内置循环是我最喜欢的更新之一，它在改善开发体验的同时，还将Angular的渲染速度提升到了一个新的级别。</p><p>&nbsp;</p><p>下面是基础示例：</p><p>&nbsp;</p><p><code lang=\"null\">@for (user of users; track user.id) {\n  {{ user.name }}\n} @empty {\n  Empty list of users\n}</code></p><p>&nbsp;</p><p>我们经常看到应用程序由于*ngFor缺少trackBy函数而产生的性能问题。因此，为了保证差异对比运算的性能，强制使用track函数，是新的@for循环语句的首要变更。此外，在使用上@for也更加简单，因为它只是一个表达式，而不是组件类中的一个方法。同时，内置的@for循环还通过一个可选的@empty块语法为空集合提供了快捷处理方式。</p><p>&nbsp;</p><p>@for语句使用了新的差异算法，相对于*ngFor指令，在实现上做了非常多的优化，这也使得其在执行速度上相对于<a href=\"https://krausest.github.io/js-framework-benchmark/current.html\">社区框架基线</a>\"提高了90%。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/43/43b483b80cf80a0f6e98da6fe6938c4e.png\" /></p><p></p><p>&nbsp;内置for语句与 js-framework-benchmarks 中 *ngFor 的性能比较，数据来源：</p><p><a href=\"https://krausest.github.io/js-framework-benchmark/current.html\">https://krausest.github.io/js-framework-benchmark/current.html</a>\"</p><p>&nbsp;</p><p></p><h1>体验</h1><p></p><p></p><p>今天，在v17的开发体验版中就可以体验内置控制流的全部功能！</p><p>&nbsp;</p><p>内置控制流的设计目标之一，就是实现让开发者通过CLI命令就可以自动完成已有项目的完整迁移。因此，开发者可以在已有项目中，通过执行使用如下命令来完成自动迁移：</p><p>&nbsp;</p><p><code lang=\"null\">ng generate @angular/core:control-flow</code></p><p>&nbsp;</p><p></p><h1>下一步计划</h1><p></p><p></p><p>我们已经和JetBrains进行了紧密合作，开发者在JetBrains的产品中可以使用内置控制流体验最新的语言服务。于此同时，我们也在和<a href=\"https://github.com/sosukesuzuki\">Sosuke Suzuki</a>\"联系，以确保Prettier可以正确的支持Angular模板格式。</p><p>&nbsp;</p><p>在处理内容预测上，内置的控制流与*ngIf、*ngFor和*ngSwitch还存在一些差异，我们将在接下来的几个月中努力解决这些问题。尽管如此，我们依然对内置控制流的实现和稳定性充满信心，所以你今天就可以尝试使用了！我们之所以将其保留在开发体验版本中，直到下一个主要版本才发布，是因为我们希望借此机会发现问题，从而有机会进一步提升开发者体验和修复一些可能存在的向后不兼容的问题。</p><p>&nbsp;</p><p></p><h1>延迟视图</h1><p></p><p></p><p>现在，让我们来谈谈懒加载功能！基于新研发的块状语发糖，我们全新设计了一个强大的机制来实现延迟视图，从而使开发者的应用程序跑得更快。正如本文开篇所说，延迟视图将应用性能和开发者体验都提升到了一个新水平。这是因为它们开创性地实现了基于声明式的懒加载。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/4d/4d8b12b7681e144c790d011a878c0235.png\" /></p><p>此组件树中左边的子树被懒加载</p><p></p><p>&nbsp;</p><p>假设你有一个博客，你想要实现评论列表的懒加载。那么在当前的版本中，你需要使用ViewContainerRef来实现，同时还需要处理诸如：清理、加载异常、显示占位符等复杂逻辑。与此同时，还需要兼顾一些边界情况，因此代码会变得非常复杂，甚至无法调试和测试。</p><p>&nbsp;</p><p>然而，在v17版本中，通过新的延迟视图功能，你只需要通过一行声明式的代码就可以实现评论列表及其所有传递依赖项的懒加载：</p><p>&nbsp;</p><p><code lang=\"null\">@defer {\n  \n}</code></p><p>&nbsp;</p><p>最令人难以置信的是，这一切都是在编译期间通过转换技术来实现的：Angular抽象了延迟视图的全部复杂逻辑。编译期间，Angular通过找到在@defer块中声明的组件、指令和管道，自动将其转为动态导入，同时还会自动管理目标组件的加载和状态切换的全过程。</p><p>&nbsp;</p><p>当组件的懒加载是通过某个DOM元素进入视窗来触发时，通常需要结合IntersectionObserver API编写复杂逻辑来实现。然而，Angular却将IntersectionObservers的使用，变得只需要简单的添加一个延迟视图触发器即可实现！示例代码如下：</p><p>&nbsp;</p><p><code lang=\"null\">@defer (on viewport) {\n  \n} @placeholder {\n  <!-- A placeholder content to show until the comments load -->\n  <img src=\"https://www.infoq.cn/article/comments-placeholder.png\" />\n}</code></p><p>&nbsp;</p><p>在上面的例子中，Angular首先渲染通过@placeholder声明的占位符。当组件准备进入视窗中时，Angular就会开始加载该组件。在加载完成之后，Angular会立刻移除占位符并渲染该组件。</p><p>&nbsp;</p><p>下面是包含处理加载过程和异常处理的示例代码：</p><p><code lang=\"null\">@defer (on viewport) {\n  \n} @loading {\n  Loading…\n} @error {\n  Loading failed :(\n} @placeholder {\n  <img src=\"https://www.infoq.cn/article/comments-placeholder.png\" />\n}</code></p><p>&nbsp;</p><p>就是这样！Angular为你处理了许多隐藏在幕后的复杂逻辑。</p><p>&nbsp;</p><p>延迟视图支持的触发器非常多，例如：</p><p></p><p>on idle——当浏览器没有执行任何繁重任务时，触发延迟视图加载on immediate——以不阻塞浏览器的方式，自动触发延迟视图加载on timer(<time>)——通过定时器触发延迟视图加载on viewport和on viewport()——viewport触发器还支持设置一个锚点元素，当指定的锚点元素可见时，触发延迟视图加载on interaction和on interaction()——允许你在用户与特定元素交互时触发延迟视图加载on hover和on hover()——当用户鼠标悬停在元素上时触发延迟视图加载when ——通过返回promise，实现通过自定义条件触发延迟视图加载</time></p><p>&nbsp;</p><p>延迟视图还提供了在渲染它们之前预先获取依赖项的能力。只需要在defer块中简单的添加一个 prefetch语句即可为延迟视图添加预获取功能。所有和viewport相同类型的触发器，都支持添加预获取功能，示例代码如下：</p><p>&nbsp;</p><p><code lang=\"null\">@defer (on viewport; prefetch on idle) {\n  \n}</code></p><p>&nbsp;</p><p>大家今天就可以在v17的开发体验版中体验延迟视图功能！如果想了解更多、更详细的关于延迟试图功能，请阅读这份<a href=\"https://angular.io/guide/defer\">指南</a>\"。</p><p>&nbsp;</p><p></p><h1>下一步计划</h1><p></p><p></p><p>延迟试图完全可以被正式使用，同时我们也强烈建议开发者尝试去使用该功能！该功能之所以依然在开发体验版中，是因为我们希望收集到更多的使用反馈。同时，和框架其他功能一样，我们会按照语义化版本的方式不断迭代该功能的API，直到稳定为止。</p><p>&nbsp;</p><p>目前，在服务端渲染时，针对延迟试图，会使用一个特殊的占位符取代。一旦框架完成应用加载且延迟试图被激活，那么延迟视图就会按照上文所描述的那样执行。</p><p>&nbsp;</p><p>我们的下一步计划是探索defer中声明的内容在服务端渲染和客户端按需激活的能力。这将意味着，在被触发之前，客户端将不会下载延迟试图的代码。当延迟视图被触发时，Angular将下载相关的JavaScript代码并仅对视图的这一部分进行水合处理。</p><p>&nbsp;</p><p>还将会有更多令人兴奋的，结合signals实现的功能，敬请期待！</p><p>&nbsp;</p><p></p><h1>改进的混合渲染体验</h1><p></p><p></p><p>今天，我们还为开发者带来了基于交互式命令的SSR（服务端渲染）和SSG（静态网站生成/预渲染）功能，下面是使用ng new命令的示例：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a1/a1c5e17e253dbfd2a88e6ed22fb41306.gif\" /></p><p></p><p>&nbsp;这是一个我们一直想做的改变，但是首先我们想先保证Angular的SSR开发者体验的稳定性。</p><p>&nbsp;</p><p>或者，你可以用以下方式在新项目中启用SSR：</p><p>&nbsp;</p><p><code lang=\"null\">ng new my-app --ssr</code></p><p>&nbsp;</p><p></p><h1>Hydration从开发体验版毕业</h1><p></p><p></p><p>在过去的 6 个月里，我们看到数千个应用程序采用了hydration。 今天，我们很高兴地宣布，hydration正式从开发体验版中移除，且在所有使用了服务器端渲染的新应用中默认开启！</p><p>&nbsp;</p><p></p><h1>新的@angular/ssr包</h1><p></p><p></p><p>我们将Angular中的通用代码库存迁移移至Angular CLI代码库中，从而使服务器端渲染成为了我们工具产品中更加不可或缺的一部分。</p><p>&nbsp;</p><p>因此，从今天开始，可以通过如下命令为历史项目添加混合渲染的支持：</p><p>&nbsp;</p><p><code lang=\"null\">ng add @angular/ssr</code></p><p>&nbsp;</p><p>此命令在为应用会生成服务端入口点、添加SSR能力和SSG构建能力的同时默认开启hydration。@angular/ssr提供了与@nguniversal/express-engine（该库当前处于维护模式）等效的功能。如果你使用的是express-engine，那么Angular CLI将会自动为你将代码更新为@angular/ssr。</p><p>&nbsp;</p><p>Virgin Media O2通过将他们历史平台的混合渲染技术迁移至最新的Angular混合渲染技术，销售额增长了 112%。通过将NgOptimizedImage与支持DOM Hydration的Angular SSR结合使用，其平台的CLS（<a href=\"https://web.dev/articles/cls?hl=zh-cn\">累计布局偏移</a>\"）指标平均降低了99.4%。</p><p>&nbsp;</p><p></p><h1>SSR应用部署</h1><p></p><p></p><p>为了进一步增强开发人员体验，我们与云提供商密切合作，确保基于Angular的SSR应用可以丝滑的部署到他们的云平台上。</p><p>&nbsp;</p><p>通过Firebase的最新发布的<a href=\"https://firebase.google.com/docs/hosting/frameworks/angular?hl=zh-cn\">框架感知CLI</a>\"，开发者几乎不用任何配置，就可以将自己的Angular应用程序部署到该平台上。</p><p>&nbsp;</p><p><code lang=\"null\">firebase experiments:enable webframeworks\nfirebase init hosting\nfirebase deploy</code></p><p>&nbsp;</p><p>框架感知CLI可以自动识别应用中用到的SSR、i18n和图像优化等功能，这使你能够经济且高效的在无服务器基础设施上为用户提供高性能的web应用服务。</p><p>&nbsp;</p><p>对于那些拥有复杂Angular monorepos项目或偏爱原生工具链的人们，AngularFire允许你使用ng deploy将应用部署到Firebase：</p><p>&nbsp;</p><p><code lang=\"null\">ng add @angular/fire\nng deploy</code></p><p>&nbsp;</p><p>为了支持边缘环境部署，我们在Angular的服务器端渲染中不但提供了ESM的支持，为<a href=\"https://github.com/angular/angular/pull/50247\">HttpClient做服务端适配</a>\"，还与<a href=\"https://developers.cloudflare.com/pages/framework-guides/deploy-an-angular-site/\">CloudFlare</a>\"合作简化了部署流程。</p><p>&nbsp;</p><p></p><h1>新的生命周期hooks</h1><p></p><p></p><p>虽然从长远来看，为了提高Angular的SSR和SSG的性能，我们倾向于移除DOM的模拟和直接操作。但与此同时，在大多数应用的生命周期中，很难避免诸如实例化第三方库、测量元素大小等和DOM元素相关的交互行为。</p><p>&nbsp;</p><p>为此，我们新增了两个生命周期hooks：</p><p>&nbsp;</p><p>afterRender — 注册一个回调函数，每次应用完成渲染时调用afterNextRender — 注册一个回调函数，应用下次完成渲染时调用</p><p>&nbsp;</p><p>这两个hooks只会在浏览器端才会被调用，因此开发者可以安心的在其中使用DOM操作逻辑。例如，如果你想实例化一个图表库，可以通过afterNextRender来实现：</p><p>&nbsp;</p><p><code lang=\"null\">@Component({\n  selector: 'my-chart-cmp',\n  template: `</code></p><div><code lang=\"null\">{{ ... }}</code></div><code lang=\"null\">`,\n})\nexport class MyChartCmp {\n  @ViewChild('chart') chartRef: ElementRef;\n  chart: MyChart|null;\n\n  constructor() {\n    afterNextRender(() =&gt; {\n      // 这里需要操作真实DOM，必须保证DOM已经具备了\n      this.chart = new MyChart(this.chartRef.nativeElement);\n    }, {phase: AfterRenderPhase.Write});\n  }\n}\n</code><p></p><p>&nbsp;</p><p>每个hooks都支持设置一个阶段值（如读取、写入），Angular将使用该阶段值来择机执行回调，以减少布局抖动并提高性能。</p><p>&nbsp;</p><p></p><h1>新项目默认开启Vite和esbuild</h1><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ae/aefc98b7b5b4133be7c0e8b3907a5e17.png\" /></p><p></p><p>vite和esbuild为ng server和ng build助力</p><p>&nbsp;</p><p>如果不是一开始就对Angular CLI的构建流程进行彻底的改造，那么Angular将不可能支持SSR！</p><p>&nbsp;</p><p>在v16的开发体验版中，我们就引入了基于esbuild+Vite的构建能力。 从那时起，就有许多开发者和部分企业合作伙伴试用了该功能，数据报告显示他们的一些应用的构建时间缩短了 67%！今天，我们很高兴地宣布，新的应用程序构建器正式从开发体验版中毕业，并且为所有新应用程序默认开启！</p><p>&nbsp;</p><p>此外，我们还升级了混合渲染场景的构建流程。 在SSR和SSG应用程序中，ng build的执行速度提高了87%，ng serve的实时编辑反馈速度提高了80%。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/0d/0d4edf487054ae46d6e8b071ba063045.png\" /></p><p></p><p>基于esbuild+vite的新构建流程和基于webpack的老构建流程的性能对比</p><p>&nbsp;</p><p>在未来的minor版本中，我们将为历史项目升级混合渲染（使用 SSG 或 SSR 进行客户端渲染）提供自动脚本。如果你今天就想试用新的应用程序构建流程，可以查看这份<a href=\"https://angular.io/guide/esbuild\">升级指南</a>\"。</p><p>&nbsp;</p><p></p><h1>DevTools中的依赖注入调试</h1><p></p><p></p><p>去年，我们向大家演示了在Angular DevTools中进行依赖注入调试的功能。在过去的几个月里，我们实现了全新调试API，通过这些API，开发者可以直接插入框架的运行时进行注入树的检查。</p><p>&nbsp;</p><p>基于这些 API，我们构建了一个检查注入依赖的用户界面，通过此界面开发者可以预览如下信息：</p><p>&nbsp;</p><p>基于组件监听的组件的依赖关系注入树和依赖解析路径每个注入的提供者信息</p><p>&nbsp;</p><p>你可以在下面的动画中快速预览这些功能。 也可以在<a href=\"https://angular.io/guide/devtools\">angular.io</a>\"上了解有关Angular DevTools 的更多信息。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/d9/d98f0eedb43f38f8e0060e215d26ff22.gif\" /></p><p></p><p>&nbsp;接下来我们将继续打磨注入层次结构、提供者信息和路径解析等方面的视图UI，为开发者提供更好的可视化能力。</p><p>&nbsp;</p><p></p><h1>开启独立API时代</h1><p></p><p></p><p>在经历一年半的持续收集独立组件、指令和管道的使用反馈并不断完善了它们的DevEx之后，我们有信心立刻在所有新应用程序中启用它们。 所以，现在所有的ng generate命令都将构建独立的组件、指令和管道。</p><p>&nbsp;</p><p>与此同时，我们还重新审视了<a href=\"https://angular.io/\">angular.io</a>\"和<a href=\"https://angular.dev/\">angular.dev</a>\"的全部文档，从而确保了一致的学习体验、开发实践和建议。</p><p>&nbsp;</p><p>虽然，在未来的一段时间内，我们将继续保留NgModules，但当看到新的独立API的好处之后，我们依然强烈建议你在项目中逐步执行迁移动作。 同时，我们还提供了一个迁移脚本，该脚本可以为你自动完成大部分工作：</p><p>&nbsp;</p><p><code lang=\"null\">ng generate @angular/core:standalone</code></p><p>&nbsp;</p><p>有关更多信息，请查看我们的<a href=\"https://angular.io/guide/standalone-migration\">迁移指南</a>\"。</p><p>&nbsp;</p><p></p><h1>响应式的下一步计划</h1><p></p><p></p><p>Angular新的基于信号的响应系统是我们在该框架中所做的重大转变之一。 为了确保与基于 Zone.js的变更检测的向后兼容性和互操作性，我们一直在努力制作原型并设计推进的线路。</p><p>&nbsp;</p><p>今天，我们很高兴地宣布Angular的基于Signals的响应式实现从开发体验版中毕业。 目前，我们将把effect函数继续保留在开发者体验中，以便我们可以进一步迭代它的语义。</p><p>&nbsp;</p><p>在接下来的几个月中，我们将开始逐步推出基于信号的输入、视图查询等功能。 到明年5月，在Angular v18中，我们将提供更多的功能来进一步改善开发人员使用Signals的体验。</p><p>&nbsp;</p><p></p><h1>测试的下一步计划</h1><p></p><p></p><p>我们正在持续试验Jest，以并确保我们可以构建一个高性能、灵活且直观的解决方案，从而更好地满足开发人员的需求。 与此同时，我们还开始尝试Web Test Runner，并为初始实施提供了一个开放的<a href=\"https://github.com/angular/angular-cli/pull/25860\">PR</a>\"。在不久的将来，我们可能会优先关注Web Test Runner，以解放那些渴望摆脱Karma的项目。</p><p>&nbsp;</p><p></p><h1>Material 3的下一步计划</h1><p></p><p></p><p>在为Angular Material引入<a href=\"https://m3.material.io/foundations/design-tokens/overview\">设计令牌</a>\"的重构中，我们一直与谷歌的Material Design团队努力合作。该设计系统将为组件提供更多的自定义选项并启用<a href=\"https://m3.material.io/\">Material 3</a>\"的支持。 虽然我们还没有准备好在v17中支持设计令牌和M3，但预计很快会在v17的某个小版本中会得到支持。</p><p>&nbsp;</p><p>在2022年第四季度，我们宣布了推出基于MDC的新Angular Material组件，并弃用具有相同功能但DOM结构和样式不同的旧组件。我们在v15中弃用了旧组件，并将在v17中将其移除。 虽然它们不再属于Angular Material v17包的一部分，但你仍然可以将应用程序更新到Angular v17的同时依然使用v16版本的Angular Material包。在v18之前，此兼容将一直支持，但在此之后新版本的Angular将不再兼容Angular Material v16。当然，为了防止你暂时无法执行项目迁移，我们与<a href=\"https://www.herodevs.com/support\">HeroDevs</a>\"进行了合作，他们将提供持续的付费支持。</p><p>&nbsp;</p><p></p><h1>开发者体验增强</h1><p></p><p></p><p>除了所有这些前瞻性的功能，我们还发布了一系列针对开发人员体验的小型增强功能！</p><p>&nbsp;</p><p></p><h1>实验阶段的视图转换功能支持</h1><p></p><p></p><p><a href=\"https://developer.chrome.com/docs/web-platform/view-transitions/\">视图转换API</a>\"可在DOM更改时实现视图的平滑转换。现在，在Angular路由器中，我们可以通过withViewTransitions功能直接支持此API。因此，在路由切换时，开发者可以通过浏览器的原生导航创建过渡动画。</p><p>&nbsp;</p><p>现在，通过修改启动函数中路由声明的配置，就可以为你的应用添加此功能，示例代码如下：</p><p>&nbsp;</p><p><code lang=\"null\">bootstrapApplication(App, {\n  providers: [\n    provideRouter(routes, withViewTransitions()),\n  ]\n});</code></p><p>&nbsp;</p><p>withViewTransitions接受带有onViewTransitionCreated属性的可选配置对象，该属性为开发者提供一些额外控制的回调：</p><p>&nbsp;</p><p>决定是否要跳过特定动画向文档添加样式类以实现自定义动画以及在动画完成时删除这些类等等</p><p>&nbsp;</p><p></p><h1>图像指令的自动预连接</h1><p></p><p></p><p>现在Angular的图像指令可以基于你提供的图片加载域来自动生成预连接链接。如果图像指令不能自动识别源和判断是一个LCP图像的预连接链接，那么它将在开发阶段就发出警告。</p><p>&nbsp;</p><p>可以在<a href=\"https://angular.io/guide/image-directive\">图像指令指南</a>\"中了解更多有关此功能的信息。</p><p>&nbsp;</p><p></p><h1>动画模块的延迟加载</h1><p></p><p></p><p>此功能可以使开发者应用包的初始体积减少60KB（gzip之后是16KB）。 该功能是由社区贡献者<a href=\"https://github.com/JeanMeche\">Matthieu Riegler</a>\"提出并实现，借助此功能，开发者可以通过提供异步函数来实现动画模块的延迟加载，示例代码如下：</p><p>&nbsp;</p><p><code lang=\"null\">import { provideAnimationsAsync } from '@angular/platform-browser/animations-async';\n\nbootstrapApplication(RootCmp, {\n  providers: [provideAnimationsAsync()]\n});</code></p><p>&nbsp;</p><p></p><h1>输入值转换</h1><p></p><p></p><p>通常我们会有一个接收布尔值的组件，但是，在给此类组件传值的时候是有限制的。例如，我们定了Expander组件：</p><p>&nbsp;</p><p><code lang=\"null\">@Component({\n  standalone: true,\n  selector: 'my-expander',\n  template: `…`\n})\nexport class Expander {\n  @Input() expanded: boolean = false;\n}</code></p><p>&nbsp;</p><p>然后我们会像下面这样使用：</p><p>&nbsp;</p><p><code lang=\"null\"></code></p><p>&nbsp;</p><p>此时，你会收到“字符串不能分配给布尔值”的错误提示。 借助输入值转换功能，通过配置输入装饰器就可以解决此问题，示例代码如下：</p><p>&nbsp;</p><p><code lang=\"null\">@Component({\n  standalone: true,\n  selector: 'my-expander',\n  template: `…`\n})\nexport class Expander {\n  @Input({ transform: booleanAttribute }) expanded: boolean = false;\n}</code></p><p>&nbsp;</p><p>可以在GitHub上找到此功能原始需求：</p><p><a href=\"https://github.com/angular/angular/issues/14761\">https://github.com/angular/angular/issues/14761</a>\"</p><p>&nbsp;</p><p></p><h1>作为字符串的Style和styleUrls</h1><p></p><p></p><p>Angular的每个组件都支持多样式表。然而多数情况下，当我给组件添加样式的时，在其样式数组中要么只有一个内联样式，要么只有一个外联样式。新功能做了如下调整：</p><p><code lang=\"null\">@Component({\n  styles: [`\n    ...\n  `]\n})</code></p><p>&nbsp;</p><p><code lang=\"null\">...\n@Component({\n  styleUrls: ['styles.css']\n})\n...</code></p><p>&nbsp;</p><p>更简单、更合逻辑写法：</p><p>&nbsp;</p><p><code lang=\"null\">@Component({\n  styles: `\n    ...\n  `\n})</code></p><p>&nbsp;</p><p><code lang=\"null\">...\n@Component({\n  styleUrl: 'styles.css'\n})\n...</code></p><p>&nbsp;</p><p>虽然我们会继续支持基于数组的多样式表。但新语法符合开发使用习惯，更直观，并且与自动格式化工具配合使用效果会更好。</p><p>&nbsp;</p><p></p><h1>社区Schematics</h1><p></p><p></p><p>为了支持社区Schematics的开发，我们在@schematics/angular/utility中提供了一些实用方法。现在开发者直接在Angular应用根目录导入表达式和添加提供者，同时将依赖项所具备的功能添加到package.json中即可完成Schematics集成。</p><p>&nbsp;</p><p>你可以通过<a href=\"https://angular.io/guide/schematics-for-libraries\">脚手架开发指南</a>\"这篇文章了解更多信息：</p><p><a href=\"https://angular.io/guide/schematics-for-libraries\">https://angular.io/guide/schematics-for-libraries</a>\"</p><p>&nbsp;</p><p></p><h1>用Angular构建未来</h1><p></p><p></p><p>在过去的六个月里，我们通过发布一些新功能不断提升开发体验和应用性能，从而持续Angular的复兴之路。 今天，我们很高兴在Angular的全新品牌和基于<a href=\"https://angular.dev/\">angular.dev</a>\"的全新学习体验中，看到了Angular复兴的势头。</p><p>&nbsp;</p><p>非常期待，下个版本中Angular在基于信号的响应式、混合渲染和学习体验上所带来的重大升级。</p><p>&nbsp;</p><p>我们很荣幸能够成为你使用Angular构建未来应用的一部分！ 感谢！</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://blog.angular.io/introducing-angular-v17-4d7033312e4b\">https://blog.angular.io/introducing-angular-v17-4d7033312e4b</a>\"</p><p></p><p></p><h5>相关阅读：</h5><p></p><p><a href=\"https://xie.infoq.cn/article/7baec545b8202471064494a69\">2023 重学 Angular</a>\"</p><p><a href=\"https://www.infoq.cn/article/oONc5r5opJF64kBCtzIv\">Angular v15 发布：可以脱离 NgModules 构建组件了</a>\"</p><p><a href=\"https://xie.infoq.cn/article/61e968dd45368e77c03fcbe10\">谈谈企业级前端 Angular 应用的定制化二次开发话题</a>\"</p><p><a href=\"https://xie.infoq.cn/article/ec0a13741cd7c4a72eea370ae\">如何快速上手 angular.js</a>\"</p>",
    "publish_time": "2023-11-16 10:19:02",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "百度资深研发工程师、文心一言 APP 技术负责人樊中恺，确认担任 QCon LLM 时代的大前端技术专题出品人",
    "url": "https://www.infoq.cn/article/cyBA56ToQEPYGDZKCu3X",
    "summary": "<p><a href=\"https://qcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=7&amp;utm_term=1116&amp;utm_content=fanzhongkai\">QCon 全球软件开发大会</a>\"，将于 12 月在上海召开。百度资深研发工程师、文心一言 APP 技术负责人樊中恺将担任「<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1599?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=7&amp;utm_term=1116&amp;utm_content=fanzhongkai\">LLM 时代的大前端技术</a>\"」的专题出品人。在此次专题中，你将了解到 LLM 时代的大前端技术发展趋势与企业级应用开发的机遇和挑战。</p><p></p><p><a href=\"https://qcon.infoq.cn/2023/shanghai/track/1599?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=7&amp;utm_term=1116&amp;utm_content=fanzhongkai\">樊中恺</a>\"，百度资深研发工程师，文心一言 APP 技术负责人，2008 年接触前端开发，2012 年开始移动端开发至今，曾先后负责百度浏览器、文库、阅读、百度 APP 前端技术架构、搜索前端架构、推荐前端架构、Paddle.js 等研发工作，对于端智能、工程化、前端架构等方向有较为丰富的经验。<a href=\"https://qcon.infoq.cn/202309/beijing/presentation/5408?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=7&amp;utm_term=1116&amp;utm_content=fanzhongkai\">QCon 北京 2023 「明星讲师」</a>\"。</p><p></p><p>相信樊中恺的到来，可以帮助提升此专题的质量，通过对 LLM 时代大前端技术的解读，能够让你对大前端技术有更深入的了解，为企业面临相关机遇和挑战，提供了有效的解决思路。</p><p></p><p>除上述专题外，QCon 上海还将围绕&nbsp;<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart\">GenAI和通用大模型应用探索</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1596?utm_source=infoqweb&amp;utm_medium=teacherart\">AI&nbsp;Agent&nbsp;与行业融合应用的前景</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart\">LLM&nbsp;时代的性能优化</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart\">智能化信创软件&nbsp;IDE</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart\">面向人工智能时代的架构</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart\">性能工程：提升效率和创新的新方法</a>\"等专题进行交流。</p><p></p><p>QCon 上海 2023，相约 12 月！ 7 折优惠仅剩最后 2 天，现在购票，立减￥2040！咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/0113b3dfb187d5f9988b7eb16d2e0594.png\" /></p><p></p>",
    "publish_time": "2023-11-16 11:33:24",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "OceanBase：中国场景推动树立分布式数据库四项新标准",
    "url": "https://www.infoq.cn/article/Mu0894he9sGM1JvWzlm4",
    "summary": "<p>11月16日，在OceanBase2023年度发布会上，OceanBase CEO杨冰介绍，中国数字经济的蓬勃发展催生了对分布式数据库的强大需求，这种需求也牵引了OceanBase坚定投入自主研发，从而推动树立了分布式数据库的四项新标准。据了解，四项新标准分别是：</p><p>&nbsp;</p><p>性能新标准：刷新TPC-C、TPC-H性能榜，3次打破世界纪录，可在高并发场景下按需实现不停机、不改应用的扩缩容和性能的线性增长，同时实现一份数据同时支持事务处理与实时分析；</p><p></p><p>容灾新标准：自研首个“三地五中心”容灾架构，建立城市级故障自动无损容灾新标准，满足国标金融6级容灾标准，保障城市级业务持续高可用；</p><p></p><p>高可用新标准：业内首个实现RPO=0、RTO＜8s，故障恢复进入秒级时代，时刻保障企业用户关键业务顺利运行；</p><p></p><p>架构新标准：单机分布式一体化，打破分布式技术的不可能，首次突破分布式数据库技术的单机性能瓶颈，适应企业全生命周期的业务需求。</p><p>&nbsp;</p><p>13年前，中国移动互联网爆发式增长，带来了前所未有的海量数据以及数据高并发，如何应对这一全球独一无二的海量数据处理问题，OceanBase选择了完全自研之路。杨冰介绍：“刚开始举步维艰，但当我们完成了支付宝核心系统替换，轻舟已过万重山。对代码完全的掌控力和掌控权也使OceanBase能够逢山开路遇水搭桥，厚积薄发。”</p><p>&nbsp;</p><p>2010年，OceanBase&nbsp;关注到中国独特场景带来的海量数据处理挑战，从0起步，致力于完全自研国产分布式数据库。2022年，&nbsp;OceanBase&nbsp;发布单机分布式一体化数据库OceanBase 4.0“小鱼”，突破分布式数据库的边界，让分布式数据库真正走向通用。</p><p>&nbsp;</p><p>这背后是13年来，OceanBase&nbsp;持续的自研投入，在性能、高可用、性价比和单机分布式一体化架构上不断达到技术新高度，得到行业认可，推动树立分布式数据的新行业标准</p><p>&nbsp;</p><p>OceanBase首席科学家阳振坤在发布会现场表示，唯有完全自研才能真正掌握核心代码，主导产品发展，成为国际一流的数据库系统。“OceanBase用十年构筑了分布式关系数据库的根技术，OceanBas的初心是让数据处理越来越普惠，为此OceanBase会在技术上坚持自研、持续突破。”</p>",
    "publish_time": "2023-11-16 11:48:49",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "OceanBase持续践行“一体化”产品战略，用一个数据库解决80%的问题",
    "url": "https://www.infoq.cn/article/4bECjHWfuJx5P0WE1Lga",
    "summary": "<p>11月16日，在OceanBase2023年度发布会上，OceanBase&nbsp;CEO杨冰宣布，OceanBase将持续践行“一体化”产品战略，为关键业务负载打造分布式数据库。</p><p></p><p>同时，会上发布一体化数据库的首个长期支持版本OceanBase 4.2.1 LTS，标志着OceanBase一体化数据库进入可规模化上线使用的长期支持阶段。</p><p>&nbsp;</p><p>用一个数据库解决80%的问题</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dd/dd6f7e4eeb56b7797c9ba670a72564a1.png\" /></p><p></p><p>杨冰表示，从OceanBase诞生的第一天起，实践的就是“一体化”产品理念，把复杂留给自己、把简单留给客户。</p><p>&nbsp;</p><p>OceanBase注意到，在数据库的实际应用中，客户往往面临着业务规模增长、业务场景变多、IT架构应用渐趋复杂的难题，造成数据库越用越多、越用越复杂的现状，而一体化设计的数据库能有效解决相关问题。</p><p>&nbsp;</p><p>从2010年至今，OceanBase专注OLTP（事务处理）场景，逐步实现工程一体化、TP/AP一体化、云上云下一体化、单机分布式一体化。目前通过一个数据库、一套架构、一份数据、一个技术栈、一个引擎的方式，实现多模型、多兼容模式、多租户、多工作负载、单机分布式一体化架构、多基础设施，用一个数据库满足客户80%的数据库场景需求。</p><p>&nbsp;</p><p>“一体化”产品，追求分布式架构下的极致性能与最佳成本。。既能实现同等硬件条件下，比主流单机数据库提供更好的性能，也能实现分布式架构下事务处理和实时分析的最佳性能。此外，统一的技术栈，也最小化了管理成本，大大降低架构成本、存储成本、运维成本、管理成本。</p><p>&nbsp;</p><p>根据国际咨询机构Forrester《OceanBase总体经济影响报告》的数据显示，采用OceanBase后，企业数据存储空间节约70%、服务器资源节约85%、平均每注册用户数据库成本节约50%，且呈现逐渐成本节约递增的趋势，越用越便宜。</p><p>&nbsp;</p><p>杨冰补充道，一体化数据库可以通过对不同场景的“求解公约数”找到相同问题，提供统一解决的办法，但在一些复杂场景下，专业版本的数据库仍会更有优势。&nbsp;</p><p></p><h2>一体化数据库4.2.1 LTS发布</h2><p></p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/ad/ad685012bc722c019bc0ad61fd42ca1e.png\" /></p><p></p><p>去年，OceanBase发布了业内首个单机分布式一体化数据库OceanBase 4.0 小鱼，有效兼顾了分布式架构的扩展性与集中式架构的性能优势，既可以实现单机部署、又可以在单机部署下实现分布式部署的完整功能，在技术上首次突破了分布式数据库的单机性能瓶颈。</p><p>&nbsp;</p><p>此次发布会上，OceanBase继续沿着“一体化”产品战略思路，发布一体化数据库的首个长期支持版本——OceanBase 4.2.1 LTS。</p><p>&nbsp;</p><p>OceanBase CTO 杨传辉介绍，4.2.1 LTS标志着OceanBase一体化数据库进入可规模化上线使用的长期支持阶段。4.2.1 LTS是面向OLTP核心场景的里程碑版本，具备OLTP的完整功能，相比3.2版本有更强的OLTP、OLAP性能，相比传统容灾提供更具性价比的仲裁无损容灾方案，可通过2个副本实现RPO=0。</p><p>&nbsp;</p><p>此外，在列存能力上，OceanBase也带来了其最新进展。随着数字化转型发展，越来越多企业在强调OLTP性能的典型HTAP场景中，迫切需要确保在高性能OLTP的基础上，获得更为迅速的实时分析能力，融合行存、列存、行列混存的一体化存储引擎正可以满足这一需要。</p><p>&nbsp;</p><p>发布会现场，OceanBase列存实验室版本同业内一流的大宽表数据库ClickHouse现场进行了跑分PK。结果显示，在同等硬件条件下，OceanBase的性能达到了ClickHouse的同一水平。</p><p>&nbsp;</p><p>杨传辉介绍，围绕“一体化”的产品战略，OceanBase未来还将持续推出针对列存、存算分离的一体化数据库版本，为客户提供更为完善的数据库服务。</p><p>&nbsp;</p>",
    "publish_time": "2023-11-16 13:05:41",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "3年探索与实践，苏州银行的数字人民币基础建设与场景应用怎么样了？",
    "url": "https://www.infoq.cn/article/u7KlHq5OkYaqFdHeSqU3",
    "summary": "<p>2019 年，数字人民币先行在深圳、苏州、雄安、成都及未来冬奥会场景进行内部封闭试点测试。苏州银行作为首批参与其中的区域性银行机构，2020 年 12 月就与中国银行确定合作，在手机银行上线了数字人民币应用。</p><p></p><p>经过 3 年多的探索与实践，<a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5574\">苏州银行</a>\"在数字人民币的基础建设和场景应用方面取得了一系列重要成果和创新，服务能力不断提升和优化。但与此同时，这个过程也充满了挑战。</p><p></p><p>在日前的 InfoQ《超级连麦·数智大脑》直播节目中，苏州银行网络金融部金一松表示，苏州银行在应用数字人民币过程中面临的最大挑战主要集中在行内基础建设和服务能力的积累上。为此，苏州银行通过向运营机构寻求支持，在行内设计特色服务功能，主动提升和优化对客产品的服务能力，以及强调前端渠道和后台系统协同一体化服务等手段在一定程度上解决了这些问题。</p><p></p><p>金一松是数字人民币研究院专家智库成员，主导并推动了苏州银行全渠道、全场景、全维度数字人民币基础建设和场景应用。在其看来，数字人民币作为国家法定货币，具有价值尺度、流通手段、贮藏手段、支付手段和世界货币等五大职能。这些职能决定了其需要与现有的各种支付体系相融合，包括国内外的账户和支付体系。随着数字人民币的逐步推广，可能会在短期内替代一些现有支付方式，但从长远来看，它将成为国家金融基础设施的一部分，与其他支付体系长期并存并发展。</p><p></p><p>以下是对话全文（经 InfoQ 进行不改变原意的编辑整理）：</p><p></p><h5>InfoQ：近些年来，移动支付在国内已经比较发达和普及了，为什么还需要数字人民币？您认为数字人民币对于国内支付业态的发展有哪些潜在影响？</h5><p></p><p></p><p>金一松：虽然中国的移动支付非常发达，但目前主要基于 M1 货币（即银行活期账户中的货币）。在数字人民币推出之前，基于 M0（即现金）的移动支付是不存在的。随着数字经济的迅速发展，我们需要一种安全、普惠的新型零售支付方式（即数字人民币）来支持这一发展。</p><p></p><p>目前来看，现金的使用功能正在发生深刻变化，随着数字经济的发展，现金使用呈下降趋势。移动支付方式，如微信和支付宝支付，已经替代了许多传统支付方式，但是在一些偏远地区公众对现金的依赖度依然较高。同时现金管理涉及设计、印制、调运、存取、鉴别、清分、回笼和销毁等多个环节，需要耗费大量的人力、物力和财力。</p><p></p><p>全球范围内，加密货币如比特币发展迅速，但这些货币可能被用于投机和非法经济活动，对金融安全和社会稳定构成潜在风险。</p><p></p><p>国际社会高度关注央行发行的数字货币。许多主要经济体的央行，如美国、英国、法国等，都在考虑或测试数字货币。</p><p></p><p><a href=\"https://xie.infoq.cn/article/a6924286278f1565f501d16f1?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">数字人民币</a>\"对于中国支付业态发展的潜在影响主要体现在三个方面：首先，第三方快捷支付市场目前呈现寡头竞争格局，不同支付机构间的一些支付场景不互通；其次，银行账户转账支付在跨行转账时需要通过人民银行的系统进行转换，对公企业的跨行转账还涉及手续费；最后，预付费卡支付主要限于特定企业或品牌体系内使用，相对封闭和局限。</p><p></p><p>而数字人民币作为国家法定货币，具有价值尺度、流通手段、贮藏手段、支付手段和世界货币五大职能。这些职能决定了其需要与现有的各种支付体系相融合，包括国内外的账户和支付体系。随着数字人民币的逐步推广，可能会在短期内替代一些现有的支付方式，但从长远来看，它将成为国家金融基础设施的一部分，与其他支付体系长期并存并发展。</p><p></p><h5>InfoQ：数字人民币试点以来到现在已经 3 年多的时间，这几年来的形态和应用场景有哪些比较明显的突破性进展？</h5><p></p><p></p><p>金一松：数字人民币的支付方式主要包括“扫一扫”和“碰一碰”，这两种方式在线下支付场景中尤为常见，如超市、小卖部等。在这些地方，我们经常可以看到数字人民币的二维码牌、扫码设备或 POS 机。除此之外，数字人民币还支持线上支付场景，例如通过拉起数字人民币 APP 进行支付，以及使用“钱包快付”功能进行支付。这是数字人民币线上支付的两种常见方式。</p><p></p><p>数字人民币与我们日常使用的微信支付和支付宝有一些显著的不同特点。当数字人民币钱包余额不足时，它可以自动从关联的银行卡中转入资金，以完成组合支付。 这种支付方式允许从数字人民币钱包中扣除部分资金，同时从银行卡中扣除剩余部分，最终将总额支付给商家。此外，即使在无网络或电源的情况下，数字人民币仍然可以通过特定的方式完成支付，这展现了数字人民币的无处不在和便利性。</p><p></p><h5>InfoQ：苏州是当年第一批先行试点的城市，那苏州银行最初在数字人民币产品研发和场景建设方面，制定了什么样的推进战略和规划？</h5><p></p><p></p><p>金一松：在实施数字人民币的过程中，我们首先需要与运营机构进行对接。在选择运营机构时，我们优先考虑那些能够提供高级别的客户信息保护和输出功能全面的运营机构。此外，我们也重视那些在分行业务对接和总行技术联调中配合度高、愿意持续迭代优化并开放新功能的运营机构。</p><p></p><p>在产品研发方面，我们通常会选择与多家运营机构进行对接，形成一种服务互备的策略。这主要是为了获取全面丰富的服务能力，向客户提供以客户为中心的多样化服务，并确保服务系统的集成互备，以避免单一运营机构的系统升级或意外导致服务中断。通过对接多家运营机构，我们能够随时保持迅速切换到另一家运营机构的数字人民币钱包服务，从而持续为客户提供服务并保障客户体验。</p><p></p><p>在场景建设方面，我们采取一体化经营策略，结合客户或场景合作方的需求，定制化提供综合金融服务。在实际服务的过程中，会将数字人民币与传统银行账户及存贷汇业务融合在一起，全方位服务客户。</p><p></p><p>具体而言，我们在 2020 年 12 月与中国银行合作，在手机银行上线了数字人民币个人钱包服务，成为全国首家参与数字人民币流通领域的非运营机构商业银行 。此后，全国各地的其他非运营机构商业银行也陆续参与到了数字人民币的应用和推广中来。当然数字人民币的推广不会特意规避或限制任何一类银行。所有银行都可以使用数字人民币为客户提供服务。这种全面的参与和应用，将使数字人民币深入到社会的每一个角落、每一个人、每一个企业和每一个生活领域。</p><p></p><h5>InfoQ：您主导并推动了苏州银行全渠道、全场景、全维度数字人民币的基础建设和场景应用，这个工作具体是如何展开的？</h5><p></p><p></p><p>金一松：在苏州银行，数字人民币项目由网络金融部负责牵头。作为牵头部门，我们主要负责与运营机构和清算机构的对接工作。</p><p></p><p>在基础建设方面，银行内部通常会单独设立一个数字人民币系统，作为行内其他系统的前置系统，负责与各运营机构输出的接口功能进行对接。</p><p></p><p>在渠道建设方面，手机银行、企业网银、智能柜台和综合柜面等线上线下对客服务渠道对接数字人民币系统二次封装并发布的接口，为客户提供具体的数字人民币各项功能与服务。</p><p></p><p>在场景应用方面，我们会与各场景部门的人员一起了解业务流程和客户需求，共同制定数字人民币的应用落地方案。</p><p></p><p>在<a href=\"https://www.infoq.cn/article/a1uk0eGDAxBQN8F8AcFY\">风险管理</a>\"方面，银行通常按产品或业务分类进行归属。由于当前阶段诈骗等风险趋势不容乐观，我们在考虑数字人民币的基础功能建设时，也必须同时考虑风险控制措施。</p><p></p><p>在流动性管理方面， 由于数字人民币与账户资金是 1:1 兑换，我们开展数字人民币业务必须在同业存款备付金账户上准备适量的备付金，并做好资金头寸监测和管理相关工作，在保障全行数字人民币业务高效平稳运行的同时，尽可能提升行内资金使用效率。</p><p></p><p>最后，在考核指标推动方面，我们还需要关注政府和人民银行、金融监管局等对本地银行提出的数字人民币指标考核要求。这些考核指标可能涉及银行的多个部门。我们需要推动这些部门进行沟通和主动行动，以完成政府的考核指标。</p><p></p><p>综合来看，数字人民币项目的实施是一个综合性和交叉程度都非常高的工作。 我们不仅需要做后台数字人民币系统和前端各个渠道的建设，还要参与场景应用与推广，同时对整个数字人民币相关的风险和流动性进行管理，并推动考核指标的完成。</p><p></p><h5>InfoQ：在数字人民币基础建设和场景应用方面，苏州银行截至目前取得了哪些重要成果和创新？请结合一些应用案例介绍一下。</h5><p></p><p></p><p>金一松：在基础建设方面，2020 年我们成功在手机银行应用中推出了数字人民币的个人钱包服务。到了 2021 年 8 月，我们接入了数字人民币 APP，也是全国首批接入的非运营机构商业银行之一。目前，我们已与多家运营机构对接，在数字人民币的个人钱包、对公钱包和商户受理三个维度上，可同时为客户提供多家运营机构钱包服务的能力。</p><p></p><p>在场景应用方面，2021 年春节期间，我们参与了苏州市政府的“年货节”活动，选取了苏州的老字号商户，为其提供了数字人民币的受理服务，并向 C 端用户发放了数字人民币消费红包。同年 4 月，我们与中国石化合作，打造了全国首个数字人民币 AI 无感加油场景应用。</p><p></p><p>到了 2022 年，我们为苏州近 6 万名一线快递员提供“海棠暖心”数字人民币关爱金申领服务。同时，我们在苏州市农业农村局的“农村集体三资监管平台”上开发了数字人民币收支、核算、溯源监管功能，实现了信息监管以及数币资金双溯源。此外，我们还积极响应了苏州市卫健委和各大医院的需求，在多家医院的收费窗口和自助设备中实现了数字人民币的收费结算功能，包括门诊挂号缴费等场景。</p><p></p><p>到了 2023 年，我们对接了江苏省财政厅预算管理一体化系统的改造，为苏州市的各个预算单位发放数字人民币工资补贴。同时，还为苏州市相城区的财政集中支付系统实现了数字人民币的收付款应用。今年，我们行内的各个贷款系统也实现了直接以数字人民币形式向客户发放贷款的功能。</p><p></p><h5>InfoQ：回顾近几年的经历，咱们团队在数字人民币的应用落地和场景探索上，遇到的最大挑战有哪些？以及是如何应对的？</h5><p></p><p></p><p>金一松：我们面临的最大挑战主要集中在行内基础建设和服务能力的积累上。尽管我们已经开发了一些数字人民币的对客服务产品，但这些产品并不能完全满足客户的需求。</p><p></p><p>为了解决这些问题，我们主要采取了以下策略：</p><p></p><p>首先，我们向运营机构寻求支持，因为每家运营机构提供的服务功能都不尽相同，甚至存在较大差异。我们可能需要额外的接口和服务来满足客户的特定需求；</p><p></p><p>其次，我们在行内设计了一些特色服务功能，主要通过改造和优化现有产品服务来匹配客户需求。我们的目标不是一味追求“大而全”，而是专注于满足客户当前最急迫的需求，通过“小而美”的服务赢得客户的认可。</p><p></p><p>此外，我们也在不断主动提升和优化对客产品的服务能力，并与客户进行有效沟通和协调。考虑到客观规律，如果客户的需求非常急迫，我们可能需要采用简化或半手工的方式来提供服务。在最终交付产品时，我们会考虑客户的具体诉求，但也会进行一些通用化、抽象化和模型化的设计。这样，我们就能打造出通用的产品服务，使其覆盖更广泛的客群和服务范围。这不仅增强了产品的通用性和复用性，而且使我们能够更敏捷地满足其他客户的类似需求。</p><p></p><p>值得一提的是，我们特别重视前端渠道和后台系统协同一体化服务，处理复杂逻辑时，我们后台系统会主动做一些接口的组合与封装，这样前端渠道再进行对接时就会非常的简单和高效，能够大幅缩短开发和测试周期。无论是线下面对面服务、线上电子渠道服务还是开放银行接口输出服务，我们都力求在不同维度上迅速响应客户的需求，实现敏捷交付。</p><p></p><h5>InfoQ：苏州银行在数字人民币服务方面，有哪些差异化产品和能力优势？</h5><p></p><p></p><p>金一松：首先，我们的产品开发始终以客户需求为导向。我们不是闭门造车，而是根据客户的具体需求来设计产品并提供服务。这种以客户为中心的策略确保了我们的服务能够精准匹配市场需求。</p><p></p><p>其次，我们拥有独特的能力来实现服务的差异化和特色化。不同于单一运营机构从自身角度出发的服务设计，我们通过对接多家运营机构的钱包服务，能够洞察到各家银行在功能、产品与服务设计上的不同理念和特色。在这种情况下，我们可以整合各家银行的优势功能，提取最佳实践并应用于不同的场景，同时避免那些不理想的功能。</p><p></p><p>最后，在服务设计时，我们更多地考虑如何提高客户的效率、简化操作流程或降低成本。从这个角度出发，我们能够开发出许多创新的服务与应用。例如，我们可以根据客户的具体需求，将已有或可支持的功能与服务进行打包，提供给客户选择。这样不仅赋予了客户更多的选择权，同时也在对客服务方面赢得了更多的信任。</p><p></p><h5>InfoQ：所谓“无网无电”支付会不会带来新的安全隐患？</h5><p></p><p></p><p>金一松：在讨论数字人民币的应用场景时，特别是在“无网无电”的环境下，我们必须认识到这样的需求并不普遍适用于所有场景。它主要针对特定的支付环境，例如，在数字人民币出现之前，公交卡支付就是一个无网无电环境下的应用实例。然而，数字人民币作为一种新型的支付方式，不同于传统的三方支付，它需要更多的考虑和额外的投入，特别是在一些特殊场景中的应用。以公交支付为例，这个场景本身就是无网无电的环境。因此，当数字人民币被引入并支持支付时，它也必须适应这样的环境。</p><p></p><p>当然，数字人民币的应用不仅限于公交领域，它还将不断融入其他可能需要无网无电环境的场景。但在<a href=\"https://www.infoq.cn/article/Hx2R2OGwCmOV4gsmPiKE\">安全性</a>\"方面，无网无电的支付并不意味着可以无限制地进行。实际上，在这种特定场景下，不同的钱包可能会有不同的支付笔数上限。通过设定这样的上限，达到了既满足特定条件下客户的支付需求，又确保支付安全性的平衡。</p><p></p><h5>InfoQ：如何提升数字人民币的风险管理和反欺诈能力？</h5><p></p><p></p><p>金一松：数字人民币的风险管理和控制相对于传统账户来说更为复杂。这是因为银行账户在开设时自然形成了实名制，银行在服务客户的同时承担了了解客户（KYC）的责任。然而，数字人民币的某些钱包形式，如个人四类钱包是匿名的，这增加了风险管理和控制的难度。例如，四类钱包可能仅与一个手机号关联，而这个手机号可能是虚拟的，这使得风险管理比传统账户要困难得多。</p><p></p><p>就目前来说，像我们苏州银行这样的非运营机构商业银行，无法直接对这些钱包进行处理和控制，如冻结、止付或调整钱包限额。这些能力通常由运营机构所掌握，他们有相应的风险控制底线和策略，以预防和控制风险的发生与漫延。</p><p></p><p>因此，我们主要从账户侧入手，强化账户管理和控制。钱包和账户之间的绑定关联是资金流动的关键，既然它们是关联的，就像是有两扇门，一扇是钱包侧的门，另一扇是账户侧的门。钱包侧的门由运营机构控制，而账户侧的门则由我们控制。</p><p></p><p>在风险管理方面，我们主要采取了五个主要措施：强化客户身份识别、进行风险分类、在账户绑定环节加强控制、管理账户向钱包兑出数字人民币的限额，以及在交易特征上进行管理。</p><p></p><p>此外，数字人民币系统建设过程中，建立一个与银行现有客户体系融为一体的用户体系至关重要。这个用户体系可能是一个手机号、客户号或 ID，关键在于实现系统间信息的互通。这样，在开立数字人民币钱包时，我们可以对客户进行全面识别，了解其在银行的风险等级、控制限额等，从而在开户前做出合理判断。</p><p></p><p>我们还与运营机构进行联防联控工作，共享涉案钱包信息，以及在发现账户侧的异常情况时，及时通知合作的运营机构。这种上下游的联防联控，如果得到广泛应用和协同，将大大提升国家银行机构整体的反洗钱和反欺诈能力。</p><p></p><h5>InfoQ：从功能上来看，数字人民币采取了双层运营体系，支持银行账户松耦合。那么，如何理解数字人民币与银行账户的松耦合？是否简化了传统金融交易？</h5><p></p><p></p><p>金一松：关于数字人民币钱包与银行账户的松耦合，这主要是因为数字人民币钱包构成了一个独立的体系，与各家银行的账户体系互不关联。尽管如此，客户无论是个人还是企业，即使没有银行账户，也可以使用数字人民币钱包。这种独立性体现了数字人民币的公共性和普惠性。然而，为了实现交易，钱包通常需要与银行账户进行关联，因为初始时钱包内可能没有资金。这种关联使得资金能够在账户和钱包之间进行流通。</p><p></p><p>钱包之于账户其优势和突破点在效率。数字人民币钱包和钱包之间的转账交易发生在同一体系内，类似于银行内部转账，因此转账效率更高，且不涉及跨行转账手续费。此外，数字人民币钱包和钱包之间的商户受理交易也表现出非常大的优势。传统的商户受理交易处理需要经过发卡行、第三方支付机构、银联 / 网联、收单机构和收单行等多个环节，而数字人民币的商户受理交易就是钱包与钱包之间的交易，不依赖于中间环节，资金流和信息流合为一体，支付即结算，无收单手续费。这两种方支付方式都体现了数字人民币相较于银行账户简化了交易的流程，提高了交易的效率，降低了交易的成本。</p><p></p><h4>关于 FCon</h4><p></p><p>首届<a href=\"https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">FCon全球金融科技大会</a>\"将于 11 月 19-20 日在上海举办。本次大会已邀请到工商银行、招商银行、汇丰银行、兴业银行、中信银行、北京银行、平安人寿、度小满、蚂蚁集团等业界知名银行以及金融机构的大咖，前来分享大模型、 Web 3.0 、隐私计算、数字货币、区块链等前沿技术在金融领域的落地案例。</p><p></p><p>我们诚挚地邀请您加入我们，共同探索金融科技的未来，扫码或<a href=\"https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">点击链接</a>\"即可查看全部演讲专题。</p><p></p><p>目前是<a href=\"https://fcon.infoq.cn/2023/shanghai/apply?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">9折特惠购票</a>\"，报名立减 ¥680，咨询购票可联系：17310043226（微信同手机号）。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/e2/ca/e205602269fc52b1557a8c4a4e7b91ca.png\" /></p><p></p>",
    "publish_time": "2023-11-16 13:13:12",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Android下Linux创建进程的姿势（下）",
    "url": "https://www.infoq.cn/article/7b6d0f8756a06f9fa0a9b104e",
    "summary": "<p></p><h2>引子</h2><p></p><p>前文我们讲了fork和COW的原理，本文接着上文续写vfork，clone等方式创建进程原理。</p><p></p><h2>vfork</h2><p></p><p>vfork也是创建一个子进程，但是子进程共享父进程的空间。在vfork创建子进程之后，父进程阻塞，直到子进程执行了exec()或者exit()。vfork最初是因为fork没有实现COW机制，而很多情况下fork之后会紧接着exec，而exec的执行相当于之前fork复制的空间全部变成了无用功，所以设计了vfork。</p><p></p><p>vfork和fork之间的另一个区别是：vfork保证子进程先运行，在它调用exec或exit之后父进程才可能被调度运行，当子进程调用这两个函数中的任意一个时，父进程会恢复运行。</p><p></p><p>也可以这么理解，vfork创建出来的不是真正意义上的进程，而是一个线程。</p><p><code lang=\"text\">#include\n#include\n#include\nint main(int argc, char*argv[]) {\n    pid_t ret;\n    int count = 0;\n    //在父进程的空间中,定义一个count 共享变量\n    printf(\"【parent】 shared count=%p in pid=%d\\n\", &amp; count, getpid());\n    printf(\"【parent】fork in pid=%d\\n\", getpid());\n    ret = vfork(); //vfork 父子进程共享对象count,父、子进程共享的count 变量其虚拟内存地址一致，在调用vfork之后父进程会挂起，子进程对count 修改会体现在父进程中\n    if (ret == 0) {\n        printf(\"【child】start from pid=%d\\n\", getpid());\n        count = 10;\n        printf(\"【child】assign count=%p ,count=%d\\n\", &amp; count, count);\n        sleep(2);\n        _exit(0);//退出子进程，必须调用，因为使用vfork()创建子进程后，父进程会被阻塞，直至子进程调用exec或者_exit函数退出，否则会报vfork: cxa_atexit.c:100: __new_exitfn: Assertion `l != ((void *)0)' failed\n    } else {\n        printf(\"【parent】continue in parent pid=%d\\n\", getpid());\n        printf(\"【parent】ret=%d, &amp;count=%p , count=%d\\n\", ret, &amp; count, count);\n        printf(\"【parent】pid=%d\\n\", getpid());\n    }\n    return 0;\n}</code></p><p></p><p>结果：</p><p></p><p><code lang=\"text\">【parent】shared count=0x7ffe774fe418 in pid=7950\n【parent】fork in pid=7950【child】start from pid=7951\n【child】assign count=0x7ffe774fe418,count=10 //这里会sleep(2) 然后 父进程才会继续执行\n【parent】continue in parent pid=7950\n【parent】ret=7951, &amp;count=0x7ffe774fe418 , count=10\n【parent】the pid=7950\n</code></p><p></p><p>我搜了下android的源码工程，发现用vfork的地方也寥寥无几，在recovery的升级模块有用到。文件路径：/bootable/recovery/updater/install.cpp。</p><p></p><h2>clone</h2><p></p><p>clone是Linux为创建线程设计的，不仅可以创建进程或者线程，还可以指定创建新的命名空间（namespace）、有选择的继承父进程的内存、甚至可以将创建出来的进程变成父进程的兄弟进程等等。</p><p></p><p>系统调用fork()和vfork()是无参数的，而clone()则带有参数。fork()是全部复制，vfork()是共享内存，而clone()是则可以将父进程资源有选择地复制给子进程，而没有复制的数据结构则通过指针的复制让子进程共享，具体要复制哪些资源给子进程，由参数列表中的clone_flags决决定。</p><p></p><p>clone函数功能强大，带了众多参数，它提供了一个非常灵活自由的创建进程的方法。因此由他创建的进程要比前面2种方法要复杂。clone可以让你有选择性的继承父进程的资源，你可以选择像vfork一样和父进程共享一个虚存空间，从而使创造的是线程，你也可以不和父进程共享，你甚至可以选择创造出来的进程和父进程不再是父子关系，而是兄弟关系。先有必要说下这个函数的结构：</p><p></p><p><code lang=\"text\">int clone(int (*fn)(void *), void *child_stack, int flags, void *arg);\n</code></p><p></p><p>其中关键参数：</p><p></p><p>child_stack为给子进程分配系统堆栈的指针（在linux下系统堆栈空间是2page大小，就是8K的内存，其中在这块内存中，低地址上存放的值就是进程控制块task_struct的值）；flags为要复制资源的标志，描述你需要从父进程继承那些资源（是资源复制还是共</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5d/5dafb49d94ad123ae4f467ff5999f424.png\" /></p><p></p><p>fork不对父子进程的执行次序进行任何限制，fork返回后，子进程和父进程都从调用fork函数的下一条语句开始行，但父子进程运行顺序是不定的，它取决于内核的调度算法.而在vfork调用中，子进程先运行，父进程挂起，直到子进程调用了exec或exit之后，父子进程的执行次序才不再有限制；clone中由标志CLONE_VFORK来决定子进程在执行时父进程是阻塞还是运行，若没有设置该标志，则父子进程同时运行，设置了该标志，则父进程挂起，直到子进程结束为止。</p><p></p><p>Android下底层创建线程的方式也是用clone的方式实现的，参考如下图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f1/f120c7d5c91d595ff41d6f71e2e1fa0b.png\" /></p><p></p><h2>exec</h2><p></p><p>exec和其他三种创建进程原理上不属于同一个层次，可以理解为是它是为了加载程序而存在,所以这里我们就浅聊下就可以了。一般我们创建子进程都是为了运行新的程序代码，因此Linux系统提供了一个exec()函数族，用于创建和修改子进程。调用exec()函数时，子进程中的代码段、数据段和堆栈段都将被替换。由于调用exec()函数并没有创建新进程，因此修改后的子进程的ID并没有改变。</p><p></p><p><code lang=\"text\">//第一组，l-&gt;list，p-&gt;path，e-&gt;envp\nint execl(const char *pathname, const char *arg, ..., (char*)NULL);\nint execlp(const char *file, const char *arg, ..., (char*)NULL);\nint execle(const char *pathname, const char *arg, ..., (char*)NULL, char *const envp[]);\n//第二组，v-&gt;vector，p-&gt;path，e-&gt;envp\nint execv(const char *pathname, char *const argv[]);\nint execvp(const char *file, char *const argv[]);\nint execvpe(const char *file, char *const argv[], char *const envp[]);\n//第三组，v-&gt;vector，e-&gt;envp\nint execve(const char *pathname, char *const argv[], char *const envp[]);\n</code></p><p></p><h2>总结</h2><p></p><p>本系列文章因在看Android底层源码时候接触到的一个小知识点引发而来，分上下两篇文章道明了Linux下创建进程的方式并阐明了在Android场景下的使用方式，希望大家能从中解惑，也希望大家能从中学到持续学习，吾日三省吾身的精神，<a href=\"https://mp.weixin.qq.com/s?__biz=MzA3NjcxMzAzMA==&amp;mid=2247484086&amp;idx=1&amp;sn=750c0f6b93b3e89c10bc603df72ea3bc&amp;chksm=9f5c5f9fa82bd6899e861658959ea8d5e828cfd0c62380711cb728667c26a77cff7ddf0043e9&amp;token=1121360748&amp;lang=zh_CN#rd\">欢迎各位coder关注公众号</a>\"，第一时间技术交流。</p>",
    "publish_time": "2023-11-16 09:55:09",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "银行数字化转型，如何践行业务价值与用户价值驱动理念？｜FCon直播「第十一期」",
    "url": "https://www.infoq.cn/article/o7X8IjCTUxP622FjiJ10",
    "summary": "<p>本期连麦富滇银行数字金融中心副总经理 李涛，探讨银行数字化转型，如何践行业务价值与用户价值驱动理念？查看大会详情：<a href=\"http://gk.link/a/12c0d\">http://gk.link/a/12c0d</a></p>",
    "publish_time": "2023-11-16 15:05:38",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "招商银行如何利用AI提升审核效率和准确率？",
    "url": "https://www.infoq.cn/article/Q3kffrKhh6rbAWeL2KWv",
    "summary": "<p>银行界的“零售之王”招商银行，一直是金融科技理念的前沿践行者。近年来，人工智能已经在其前中后台各个业务场景中广泛应用。</p><p></p><p>以金融“命脉”<a href=\"https://www.infoq.cn/article/a1uk0eGDAxBQN8F8AcFY\">风控场景</a>\"为例，招商银行在零售条线依托金融科技能力，构建了智慧风控生态体系，打造了包括智慧风控、智能风险调查、综合身份认证等在内的诸多平台，将风险感知、实时决策、风险调查等能力整合，形成覆盖可疑账户和风险交易的全生命周期风险管理闭环，实现对潜在被骗交易的精准高效甄别，阻断风险交易，避免资金损失。</p><p></p><p>其中，智能审核系统作为整个风控生态体系的关键部分之一，通过整合自然语言处理、语音识别、图像处理等多项 AI 技术，解决了金融领域繁琐的审核工作，实现了机器辅助人工对各种不同类型材料进行审查，大大提升了业务开展的效率和准确性。</p><p></p><p>在日前的 InfoQ《超级连麦·数智大脑》直播节目中，招商银行人工智能实验室算法工程师<a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5562\">赵文婷</a>\"分享了招商银行智能审核系统的建设历程及应用成果。她表示，目前该系统已经完成了基础能力搭建，可以解决大部分文本、语音、视觉审核场景。</p><p></p><p>但与此同时她也坦言，不管是场景还是能力方面，该系统都还有很多提升空间。比如，小样本场景复杂语义推理的审查目前还是个难点，利用目前现有的技术手段去解决投入产出比比较低。对此，今年流行起来的大模型在类似问题上表现出了很好的效果，招商银行未来将在这方面进行进一步探索。</p><p></p><p>以下是对话全文（经 InfoQ 进行不改变原意的编辑整理）：</p><p></p><h5>InfoQ：您长期从事语音语义理解相关算法模型研发落地工作，自毕业就加入了招商银行，从您的视角和经历来看，人工智能对银行业务发展意味着什么？目前在哪些场景的应用最为广泛？</h5><p></p><p></p><p>赵文婷：人工智能对银行数字化转型是至关重要的，比如说像银行的风控合规、营销拓客、服务体验提升等各个方面，现在人工智能都已经在其中起到了关键作用。尤其是最近大模型的爆火，又为金融科技的产品落地带来了很大的想象空间。</p><p></p><p>具体而言，<a href=\"https://www.infoq.cn/article/AKtrgk3oT7K8AhNq5W8z\">人工智能</a>\"已经在银行的前中后台各个场景中应用的非常广泛。</p><p></p><p>比如在风控场景，像人脸识别、指纹识别、声纹识别等核身技术在我们手机银行的应用，通过多模型、多模态的应用，极大地保障了我们的客户登陆交易安全，避免了资金财产损失；</p><p></p><p>比如在这次 FCon 大会上我将要分享的智能审核系统，其实也是结合语音、语言、视觉等多模态处理技术，实现了机器辅助人工做各种类型材料审查，也是在合规和提效上有较大突破；</p><p></p><p>再比如客服场景，通过多种 AI 技术结合，包括意图理解、信息抽取、知识图谱等等，可以帮助银行打造了手机银行智能客服、智能外呼，通过机器辅助人工坐席做客户服务经营等工作，从而提升服务效率和客户满意度。</p><p></p><p>另外像营销拓客，我们也可以通过大数据挖掘和语义理解等多种技术结合，辅助做 kyc 分析和服务方案生成工作，进而服务经营拓客，提升营销效率和质量等；</p><p></p><p>而针对交易场景目前我们也有很多成功的 AI 赋能应用了，比如说 AI 智能理财助理，其实就是在投研这样的环节提供辅助，包括产品推荐、精准营销等等。</p><p></p><p>这个过程可能客户不能很直观感受到，但是底层基于的正是 AI 技术。目前我行已把 AI 技术应用于行内业务流程的方方面面，后续也会持续关注最前沿技术为业务赋能。</p><p></p><h5>InfoQ：您在 FCon 大会分享「招商银行智能审查系统」相关实践，能否先给我们介绍下，在银行智能风控体系中，智能审查系统扮演着什么样的关键角色？</h5><p></p><p></p><p>赵文婷：银行业对风险是非常关注的，在业务开展的全生命周期风控始终是放在核心位置的。例如像我行的零售条线依托金融科技能力，构建了<a href=\"https://www.infoq.cn/article/ixcNvwClOzTSal48vR6k\">智慧风控</a>\"生态体系，打造了包括像智慧风控平台、智能风险调查平台、综合身份认证平台等，将风险感知、实时决策、风险调查等能力整合，形成覆盖可疑账户和风险交易的全生命周期风险管理闭环，实现对潜在被骗交易的精准高效甄别，阻断风险交易，避免资金损失。此外，我行也运用大数据风控模型，去做风险预测模型，然后在信贷业务上的贷前、贷中、贷后进行不同等级风险预警。</p><p></p><p>其中，智能审核系统更多是在整个风控体系的事中、事后环节赋能，智能审核着重在事中环节辅助加快业务办理效率，降低由人工主观标准不一致带来的审核误差，同时辅助事后业务回检，排查异常交易风险。审核系统与其他风控系统互相结合，持续降低业务开展过程中各类风险。</p><p></p><h5>InfoQ：风控是金融业务的命脉，在 AI 盛行之前就有一系列相对成熟的风控体系，现阶段为什么需要通过一些智能的手段去提升我们的风控能力？</h5><p></p><p></p><p>赵文婷：过去银行主要由人工去把控和审核风险，依赖人脑对内外规则和监管知识进行积累和记忆，并且审核的时效和效率都是相对滞后的，因为人工从初审到复核整个全流程周期会拉得很长。</p><p></p><p>另一方面，如前面所说，人工处理可能会存在审核的主观差异，尤其是针对一些相对复杂的条款的理解。比如像销售环节要求从业人员不能夸大销售、虚假营销，这就比较抽象，什么样的程度算是夸大营销，可能不同的审核人员会有不同的理解，这可能造成审核漏洞的风险。</p><p></p><p>所以，通过引入智能化技术，一方面是为了提高审核效率，另一方面也是为了降低人为的理解误差，统一标准。</p><p></p><h5>InfoQ：那么，招行银行智能审查系统的建设是出于什么样的业务需求和背景？目前该系统发展到了什么阶段？</h5><p></p><p></p><p>赵文婷：银行业作为知识密集型领域，其各个业务场景每日能够产生大量的不同模态非结构化数据，如产品合同、债券发行材料、营销电访通话、运营票据、双录视频等。为贯彻落实监管部门关于业务开展过程中各项规定，降低合规风险、提升服务质量，行内每年需投入大量人力做质检审查工作。</p><p></p><p>为提升审核效率、降低合规风险，行内通过结合自然语言处理、语音识别、图像处理等多项 AI 技术，充分学习利用各类业务文档、规章制度等领域知识，提供了一套具有较强泛化性、以机器辅助代替人工可支持全量实时质检的多模态智能审核方案。</p><p></p><p>目前完成了基础能力搭建，可以解决大部分文本、语音、视觉审核场景，但不管是场景还是能力上还有很多提升空间。比如，小样本场景复杂语义推理的审查目前还是个难点，利用目前现有的技术手段去解决投入产出比比较低，可能随着后续<a href=\"https://www.infoq.cn/article/YCV0E9FALCpIUftbJiBv\">大模型</a>\"的普及应用，会有更好的解决办法。</p><p></p><h5>InfoQ：对比此前的人工质检，在智能审查系统上线后，多大程度上提高了审核效率？</h5><p></p><p></p><p>赵文婷：一方面，我们看到审查场景涉及的数据量实际上比较大，但过去受限于人力，可能没有办法实现全量质检审核，而现在通过智能化审查系统，就可以做到实时全量 100% 覆盖的质检；</p><p></p><p>另一方面，针对不同场景，智能技术带来的效率提升和时效性辅助还是比较明显的。如果在模型推理层面没有太多消耗的话，比如一些初核初审流程可以从过去人工模式的几分钟甚至数小时，到机器全自动化，达到分钟级甚至秒级的响应。</p><p></p><h5>InfoQ：智能审查系统在不同业务场景中（比如产品合同审查、债券发行材料审查、票据审查等等）是如何发挥价值的？在不同场景下，该系统要解决的问题是否有差异？</h5><p></p><p></p><p>赵文婷：不同场景底层能力基本一致，但对外业务流程不同、场景不同，解决方案和模型搭建逻辑上会有些许差异。</p><p></p><p>比如产品合同、债券审核更多是纯 NLP 的应用，这些场景的特点是审核点复杂，因为内外监管要求更多，所以发行逻辑以及各方面的业务指引，所需的材料要求也是比较多的，同时它们的自定义审核内容较多，样式不固定、不统一。这时候，就需要更多复杂的自定义组合模型去做支持和应用。针对这样的场景，我们更多是复用审核系统的审核模式，在通用基础上接入适配训练的个性化抽取及推理模型。</p><p></p><p>但是，以票据审核场景为例，采用的就是 OCR+NLP 的结合。因为票据审核的处理模式和前两个场景不一样，它针对的是图像的模态数据审核，虽然票据审核点简单，但审核内容繁琐，需要在审核平台先配置大量审核规则，然后重点优化 OCR 和要素抽取效果，通过 OCR 先做图像文字识别，再做结构化信息抽取及逻辑判断。这与纯文本就会有很大的不同。</p><p></p><p>所以我们在做票据审核的时候，主要先通过 OCR 先做智能识别录入，并且针对不同类型的票据在前面的环节重点去定制化训练它的识别模型，从而提升识别的准确性。在识别之后，通过在审核平台上预先配置的大量审核逻辑去做推理，比如中间要素的一致性、必备性等等，进而去做后续的判断。</p><p></p><h5>InfoQ：在通过机器辅助人工开展合规审查工作的过程中，人与机器是如何协同工作的？</h5><p></p><p></p><p>赵文婷：在整个审核环节中，人和机器的协作模式是非常多样的，审核人员在其中肯定发挥着最重要的作用，机器更多是做一些辅助，帮助人工提升效率，降低相关的风险。</p><p></p><p>当然，依据不同场景业务开展时效性及风险性程度的不同，人机协作模式会有一定差异。</p><p></p><p>比如，像票据审核这样对业务准确率要求比较高，高风险时效性要求较强的场景，我们会采用一人一机实时双审模式，通过机器自动录入，结构化信息提取，机器做初审，人工做复核完成审查。</p><p></p><p>而对于像经营分析、合规分析等这样低风险低时效性要求较低的场景，我们会通过机器实时全量质检 + 人工抽样复核或机器初审 + 人工批量复核完成。</p><p></p><h5>InfoQ：您怎么样看待“有多少人工，就有多少智能”这样一个问题？</h5><p></p><p></p><p>赵文婷：在实现智能化应用的过程中，人机协作是非常重要的。比如，在机器初审之后，需要人工去做复合，对质量进行最终把控；再比如，在审核模型构建初期，同样离不开人工干预，包括对模型进行反馈和调教。</p><p></p><p>但是，这并不是为了明确机器发挥多少作用，人工发挥多少作用，而是希望通过各种 AI 手段把人力从一些繁琐枯燥的工作中释放出来，去做一些更复杂的、对他们来讲更有意义的事情上，把相对简单确定性的任务交给机器去做。对我们来说，其实也一直在寻求其中的平衡点。</p><p></p><h5>InfoQ：我们知道，银行业务产生的数据大多数都是非结构化的而且海量的，那么招行的智能审查系统是如何应对这样的数据挑战的，具体采取了哪些策略和技术手段？</h5><p></p><p></p><p>赵文婷：确实是在银行业务开展过程中会碰到很多不同模态、不同结构的数据，比如说前面提到的产品合同、债券、票据，它们主要是文本图像数据。除此之外，比如在理财产品售卖、双录等环节，还会有很多录音录像等数据。为了解决这个问题，我们对审核系统中进行了逐步拆解，搭建了多层结构：</p><p></p><p>数据层：数据层我们打通了语音、文本、图像等不同模态不同结构的数据，通过 es、kafka、ecs、mysql、redis 等不同方式将审核中台与业务系统数据打通。</p><p></p><p>能力层：能力层我们整合了 ASR、OCR、声纹、人脸、知识图谱等多种 AI 算法能力，通过语音、图像、信息抽取能力将数据标准化入库，依据不同业务场景搭建审核模型。</p><p></p><p>平台层：在审核模型生成后，通过平台方式进行审核能力整体输出，按不同时效性将进行 T+0、T+1 数据审核。同时平台层进行审核知识、审核逻辑管理、数据回流等操作，保障数据完整闭环。</p><p></p><p>渠道层：最终不同类型数据在不同渠道分类展示，各个场景分别赋能。</p><p></p><h5>InfoQ：这意味着整个系统应用下涉及了自然语言处理、语音识别、图像处理等多项 AI 技术，这些技术在项目中是如何协同和应用的？</h5><p></p><p></p><p>赵文婷：不同场景技术组合逻辑会有差异。</p><p></p><p>以票据审核为例，应用较多的模式是首先通过语音识别、图像处理比如 OCR 做智能识别，将多模态数据做智能录入，然后针对录入信息进行自然语言处理，包含结构化信息抽取，比如身份证号、银行卡号、姓名等，最后按不同场景要求做不同模态内容合规审查，比如文本上的要素一致性、完备性，图像上的核身准确性、证件完整性等。</p><p></p><p>再比如，电访这样的营销场景可能会先针对电话录音文件通过 ASR 将语音转成文字，然后再进行自然语言处理。换句话说，这些技术的组合策略实际上是根据业务导向和业务场景数据类型去决策的。</p><p></p><h5>InfoQ：回顾智能审查系统的建设过程，有没有遇到哪些让您印象比较深刻的挑战，又是如何克服这些挑战的？</h5><p></p><p></p><p>赵文婷：比较深刻的挑战应该是在做具体的一个产品合同审查场景，场景特点是合同非标准化、表述差异大，涉及内外规知识较多，审核逻辑复杂，历史审核意见形式多样。它对审核人员对专业性要求非常高，但专业审核人员对培养需要非常长的时间周期。</p><p></p><p>虽然通过对高质量数据的标注和学习，进行 AI 建模可以在一定程度上解决这个问题，但是我们发现人工写的东西跟机器能读入学习的形式还有巨大差异。基于上述问题就带来了审核模型既往能力复用性不强，场景可用标准数据少，审核知识库梳理难度大的问题。</p><p></p><p>为此，我们的办法是先把场景缩小。以产品合同审核为例，针对合同多样性问题，我们缩小一期审核类型，优先聚焦审核标准相对统一、数据量大、合同样式较简单的场景，一期快速推进上线，经过线上验证后收集反馈数据优化模型迭代同时扩展审核范围，精益模式不断优化，逐步降低一线审核压力。</p><p></p><p>另外，针对没有太多标注样本的问题，我们也通过对历史审核数据聚类挖掘 + 人工复核梳理高频审核点，辅助业务人员进行审核知识拆解。</p><p></p><h5>InfoQ：您对银行智能审查系统未来的发展有哪些期待或展望吗？</h5><p></p><p></p><p>赵文婷：我觉得近期大模型的快速发展为审核系统未来升级带来了新的想象空间。尤其是大模型语义理解能力，推理能力的提升，相对传统模式有了更多探索可能性。</p><p></p><p>因为专业审核工作领域知识积累要求是比较高的，现有审核系统搭建很依赖专家知识库梳理，对审核人员的要求比较高。同时受限于场景数据量及审核点复杂性，目前复杂审核点审核准确率待提升。比如现在针对复杂审核点，更多的方法是将复杂问题简单化，拆解为审核逻辑明确的多个小审核点通过要素推理、审核模型训练方式处理。</p><p></p><p>但目前的方式还是有一些复杂语义问题很难解决，比如像销售环节要求从业人员不能夸大销售、虚假营销，如果是明确审核点比如说不能承诺可以保本、无风险这样很好训练单点审核模型，但提到不能夸大销售，这就比较抽象，现有模型很难理解，但大模型在类似问题上表现出了很好的效果，希望未来可以发挥大模型能力进一步优化。</p><p></p><p></p><h5>嘉宾介绍</h5><p></p><p>赵文婷硕士毕业于北京航空航天大学计算机系，加入招行人工智能实验室后，长期从事语音语义理解相关算法模型研发落地工作。先后主导推进智能合同审查、智能语音质检、智能双录、智能外呼、智能协呼语义理解及 TTS 应用建设等项目，深耕自然语言处理、语音合成、声纹识别、多模态分析等技术能力。项目期间参与发表论文被 EMNLP、ACL、IEEEE Trans 等国际顶会顶刊录取，所参与团队知识工程建设相关项目曾获银保监会一等奖、人民银行二等奖，同时先后获得招行中心级年度优秀员工、年度 MVP、优秀导师等多项奖项。所推进相关技术广泛应用于招行客服、经营、风控等核心业务场景，持续推进最前沿人工智能技术在金融领域结合落地。</p><p></p><h4>关于 FCon</h4><p></p><p>首届<a href=\"https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">FCon全球金融科技大会</a>\"将于 11 月 19-20 日在上海举办。本次大会已邀请到工商银行、招商银行、汇丰银行、兴业银行、中信银行、北京银行、平安人寿、度小满、蚂蚁集团等业界知名银行以及金融机构的大咖，前来分享大模型、 Web 3.0 、隐私计算、数字货币、区块链等前沿技术在金融领域的落地案例。</p><p></p><p>我们诚挚地邀请您加入我们，共同探索金融科技的未来，扫码或<a href=\"https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">点击链接</a>\"即可查看全部演讲专题。</p><p></p><p>目前是<a href=\"https://fcon.infoq.cn/2023/shanghai/apply?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">9折特惠购票</a>\"，报名立减 ¥680，咨询购票可联系：17310043226（微信同手机号）。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/e2/ca/e205602269fc52b1557a8c4a4e7b91ca.png\" /></p><p></p>",
    "publish_time": "2023-11-16 16:02:42",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从互联网到云计算再到 AI原生，百度智能云数据库的演进",
    "url": "https://www.infoq.cn/article/eCB7TDEfVlQYAXYPDqVa",
    "summary": "<p>百度智能云团队打造的《百度智能云数据库》系列课程将带领大家更全面地了解百度智能云数据库在AI时代的发展趋势和技术实践！</p>\n<p>第一期课程《从互联网到云计算再到 AI原生，百度智能云数据库的演进》百度智能云数据库产品总架构师朱洁将为大家盘点回顾整个数据库的发展历史，分享百度智能云在数据库领域的发展情况，并共同展望数据库在AI时代的创新和变更。</p>",
    "publish_time": "2023-11-16 16:19:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "OPPO推出自主训练大模型AndesGPT，初衷是智能助手的技术升级",
    "url": "https://www.infoq.cn/article/2uKaRRpLwAwdmgOm5mIJ",
    "summary": "<p>11月16日，在<a href=\"https://odc23.oppomobile.com/\">2023 OPPO开发者大会</a>\"上，OPPO正式推出了自主训练的大模型 AndesGPT。</p><p></p><p>据介绍，AndesGPT拥有<a href=\"https://www.infoq.cn/article/YXCoqIWRvZhCDw1tU6Wf?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">对话</a>\"增强、个性专属和端云协同三大技术特征，对于大模型带来的变革，OPPO认为体现在四个方面：知识、 记忆、工具和创作。</p><p></p><p>在知识能力方面，AndesGPT融合了<a href=\"https://www.infoq.cn/article/VobGpv8dANeo7aOJfXWT?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">知识图谱</a>\"及通用搜索能力，为用户提供更专业的问答。通过知识增强技术，将外部知识与模型融合生成结果，降低幻觉。在记忆能力方面，AndesGPT实现长期记忆机制，以支持无限长度的上下文和有状态服务。而长期记忆带来首字推理延迟这个技术挑战。为了解决该难题，OPPO研发了一种注意力算 法命名为SwappedAttention。SwappedAttention能够在多轮长上下文对话中，有效降低每个query的首字推理时长。其核心技术原理是，通过外部存储和KV压缩的方式实现会话级KV缓存。结合 PagedAttention 算法一起使用，能够带来 50%的首字延迟降低，以及30%的推理吞吐提升。工具使用也是AndesGPT一项核心能力，更好的理解设备控制与服务API，端到端生成可执行指令。 目前AndesGPT已支持使用系统设置、一方应用、三方服务、代码解释器等各类工具。在创作方面，AndesGPT已全面支持文生图与图生图场景。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/ae/e3/aec666f582a2ca7584388b42b97daae3.jpg\" /></p><p></p><p>AndesGPT主要训练三种参数规格的模型——AndesGPT-Tiny、AndesGPT-Turbo 和 AndesGPT-Titan，可根据不同场景灵活选择。AndesGPT 使用行业主流的网络结构，主要做了两个组合优化：</p><p>RoPE位置编码探索了 base的最优值，结合log-scale和attention 加bias，扩展外推能力；GQA结合复杂移动窗口（Dilated Attention）加速了训练和推理，实现了O（Nd）的线性复杂度。</p><p></p><p>OPPO数智工程事业部总裁刘海锋在接受InfoQ采访时表示，OPPO做大模型的一个最基本的初衷就是升级智能助手产品，让小布助手变得更有用更智能。“对于手机厂商或者智能终端厂商、本来就有智能助手的团队来说，这个事儿是非常自然且水到渠成的，因为我们有现实的用户的需求，有数据的积累，也有一些knowhow积累，那么我们肯定要做技术升级。”</p><p></p><p>除了落地应用，OPPO还在推进产学研联合促进前沿技术研究。去年OPPO联合中国科学技术大学成立的智能计算联合实验室，已将大模型技术作为核心研究方向。此外，OPPO还和国内外超过45所重点院校建立了AI相关的合作。未来，AndesGPT 还将面向开发者开放核心的智能体开发平台。</p>",
    "publish_time": "2023-11-16 16:33:53",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "试点3年多，数字人民币的应用和实践有何新进展？｜FCon直播「第十二期」",
    "url": "https://www.infoq.cn/article/jaSIxJ1hI7ypbN4I7hOU",
    "summary": "<p>本期连麦：苏州银行网络金融部高级产品经理 金一松 ，探讨「试点3年多，数字人民币的应用和实践有何新进展？」。查看大会详情：<a href=\"http://gk.link/a/12c0d\">http://gk.link/a/12c0d</a></p>",
    "publish_time": "2023-11-16 16:47:02",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "金山办公WPS AI又迎新进展！正式开启公测，面向全体用户陆续开放体验",
    "url": "https://www.infoq.cn/article/DPVPEVLb6RwtGBBaiaM9",
    "summary": "<p>11月16日，金山办公宣布旗下具备大语言模型能力的人工智能办公应用WPS AI开启公测，AI功能面向全体用户陆续开放体验。</p><p></p><p>金山办公表示，即日起用户可前往WPS&nbsp;<a href=\"https://ai.wps.cn/\">AI官网</a>\"申请权益，并下载最新版WPS PC客户端限时体验文字/智能文档、表格/智能表格、PPT演示组件的AI能力，安卓、iOS和Mac端将于11月底陆续开放。</p><p></p><p>WPS AI自今年4月18日首次对外亮相以来，持续优化产品体验。5月16日，WPS AI 对外展示了类微软Copilot的能力。7月6日，WPS AI亮相2023世界人工智能大会宣布官网上线。9月20日，金山办公在技术开放日上宣布WPS AI接入面向企业组织的一站式数字办公平台 WPS 365，并首次公布自研模型的最新进展，该模型基于开源底座，通过训练调优，可以帮助WPS AI在国内较早落地于AI 办公应用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/81/8171c67fa2d5bdf58060bf8d52b95be3.png\" /></p><p></p><p>值得一提的是，WPS AI目前在表格场景中表现“亮眼”，用户选中数据后，以对话的方式向WPS AI描述需求，即可生成复杂的函数公式，秒出结果。</p><p></p><p>此前，金山办公也入选了首批北京市通用人工智能产业创新伙伴计划成员名单。在政企办公场景方面，金山办公与北京市大模型研发机构广泛开展合作，提供面向公文领域的AIGC生成、个性化知识库检索数据智能分析等服务。</p><p></p><p>金山办公CEO章庆元表示，金山办公将WPS AI定位为大语言模型的应用方，锚定AIGC（内容创作）、Copilot（智慧助理）、Insight（知识洞察）三个战略方向发展。</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-11-16 17:18:58",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "微软发布两款自研5nm芯片，AI和云计算两大市场都想要！网友：科技巨头从来不做选择题",
    "url": "https://www.infoq.cn/article/8aSuOhALikHTBHAD5BDo",
    "summary": "<p></p><h2>微软发布两款自研芯片，面向AI和云计算</h2><p></p><p>&nbsp;</p><p>当地时间11月15日，微软在西雅图召开的Ignite大会上发布了两款芯片，一款面向AI，一款面向云计算。</p><p>&nbsp;</p><p>微软发布的这款名为Maia 100的人工智能芯片，旨在与英伟达备受追捧的AI图形处理单元展开竞争。第二款则是Cobalt 100 Arm芯片，面向通用计算任务并将与英特尔处理器争夺市场。</p><p>&nbsp;</p><p>微软公司表示，Maia 100 是 Maia AI 加速器系列中的首款产品。它采用的是台积电5纳米制程工艺，拥有 1050 亿个晶体管，比AMD挑战英伟达的AI芯片MI300X的1530亿个晶体管少约30%。</p><p>&nbsp;</p><p>此外，Maia 支持微软首次实现低于 8 位数据类型（MX 数据类型），“这样可以让微软与其他合作伙伴共同设计硬件和软件，”微软公司副总裁Rani Borkar说道。“这有助于我们支持更快的模型训练和推理时间。”</p><p>&nbsp;</p><p>微软是包括AMD、Arm、Intel、Meta、Nvidia 和 Qualcomm 等在内的一个联盟的成员，该联盟正在标准化人工智能模型的下一代数据格式。</p><p>&nbsp;</p><p>在本场发布会上，微软发布的另一款芯片产品同样备受瞩目。Cobalt 100是一款64位处理器，也同样采用的是台积电5纳米工艺，芯片上有128个计算核心，与Azure一直使用的其他基于Arm架构的芯片相比，它的功耗降低了40%。微软表示，一部分Cobalt芯片已经为 Microsoft Teams 和 Azure SQL 等程序提供支持。</p><p>&nbsp;</p><p>值得注意的是，Maia 100 和 Cobalt 100 这两款芯片由每秒 200 GB 的网络供电，可提供每秒 12.5 GB 的数据吞吐量。</p><p></p><h2>“我们和其他芯片厂商是互补，而非竞争”</h2><p></p><p>&nbsp;</p><p>微软正处于部署的早期阶段，因此微软目前暂时不愿意向外界发布确切的两款芯片的规范或性能基准。也就是说，外界很难准确地去解读Maia与英伟达流行的H100 GPU、最近发布的 H200、甚至 AMD 最新的MI300X相比如何。</p><p>&nbsp;</p><p>Borkar表示，微软不想讨论谁的芯片更好，而是强调了与英伟达和 AMD 的合作关系对于 Azure 人工智能云的未来仍然非常关键。“在云运行的规模上，优化和集成堆栈的每一层、最大限度地提高性能、实现供应链多样化以及坦白地为我们的客户提供基础设施选择非常重要，”Borkar 如是说。</p><p>&nbsp;</p><p>供应链的多元化对微软来说非常重要，特别是当英伟达目前是人工智能服务器芯片的主要供应商并且各公司一直在竞相购买这些芯片时。据估计，OpenAI 需要超过3万个英伟达旧版 A100 GPU 才能实现 ChatGPT 的商业化，因此微软自己的芯片可以帮助其客户降低 AI 成本。微软还为自己的 Azure 云工作负载开发了这些芯片，而不是像英伟达、AMD、英特尔和高通那样出售给其他公司。</p><p>&nbsp;</p><p>“我认为我们和其他芯片厂商更多的是互补，而不是与他们竞争，”Borkar坚持说。“今天，我们的云计算中既有英特尔也有 AMD，同样，在人工智能方面，我们今天已经有了英伟达，我们也将宣布采用 AMD。这些合作伙伴对我们的基础设施非常重要，我们真的希望为我们的客户提供选择。”</p><p></p><h2>科技巨头，全都拥有“造芯梦”</h2><p></p><p>&nbsp;</p><p>资金充实的各大科技企业都在为客户提供愈发丰富的云基础设施选项，帮助受众更灵活地运行应用程序。阿里巴巴、亚马逊和谷歌多年以来一直秉持这项战略。根据一项估算，截至今年10月底，微软手中共掌握约1440亿美元现金，且过去一年其云市场份额已经达到21.5%，仅次于亚马逊。</p><p>&nbsp;</p><p>微软公司副总裁Rani Borkar在接受外媒采访时表示，运行在Cobalt芯片之上的虚拟机实例将在2024年通过微软Azure云实现商业化，但她没有提供Maia 100芯片的具体上市时间表。</p><p>&nbsp;</p><p>作为全球头部云供应商之一，微软是最后一家为云和人工智能提供定制芯片的公司。2016年，谷歌公布了其初代AI张量处理单元（TPU）；亚马逊云科技则先是在2018年发布了其Graviton Arm芯片与Inferentia AI处理器，随后于2020年推出了用于模型训练的Trainium。</p><p>&nbsp;</p><p>面对GPU资源的严重短缺，云服务商的特殊AI芯片有望满足客户需求。但与英伟达或者AMD不同，微软及其云计算同行的盈利模式，并不是向客户出售搭载其芯片的服务器硬件。</p><p>&nbsp;</p><p>Borkar解释称，微软方面在AI计算芯片的设计过程中充分听取了客户反馈。</p><p>&nbsp;</p><p>Borkar还提到，微软目前正在测试Maia 100如何满足自家Bing搜索引擎上的AI聊天机器人（原名Bing Chat，现已更名为Copilot）、GitHub Copilot编码助手以及GPT-3.5-Turbo（由微软支持的OpenAI大语言模型）等需求。凭借海量互联网信息作为训练素材，OpenAI的语言模型已经可以生成电子邮件、总结文档并根据人类询问快速生成答案。</p><p>&nbsp;</p><p>其中GPT-3.5-Turbo模型正是OpenAI&nbsp;ChatGPT智能助手的底层技术，这款产品自去年推出之后迅速蹿红。短时间内，各家公司纷纷行动起来，在自家软件中引入类似的聊天功能，这也大大增加了市场对于GPU资源的整体需求。</p><p>&nbsp;</p><p>英伟达公司首席财务官Colette Kress在今年9月于纽约召开的Evercore大会上表示，“我们一直在与各家供应商开展全面合作，希望改善我们的供应能力并支持更多客户、满足市场需求。”</p><p>&nbsp;</p><p>此前，OpenAI就一直借助Azure上的英伟达GPU进行模型训练。</p><p>&nbsp;</p><p>除了设计Maia芯片之外，微软还公布了名为Sidekicks的定制化液冷硬件，可安装在与Maia服务器相邻的机架中为其降温，其工作原理就像汽车或高档游戏 PC 中的散热器一样，用于冷却 Maia 芯片的表面。一位发言人表示，微软无需任何改造即可将Maia服务器机架与Sidekick液冷机架安放到位。</p><p>&nbsp;</p><p>相比之下，GPU往往无法充分利用本就有限的数据中心物理空间。服务器初创公司Oxide Computer联合创始人兼CEO Steve Tuck坦言，由于无法像普通服务器那样从上到下填满机架，该公司有时会将一些装有GPU的服务器像“孤儿”般安放在机架底部以防止过热。Tuck还强调，有时甚至需要单独添加冷却系统来降低运行温度。</p><p>&nbsp;</p><p>根据之前亚马逊应用自研芯片的经验，微软的Cobalt处理器普及速度可能会比Maia AI芯片更快。微软目前正在Cobalt上测试其Teams应用程序及Azure SQL数据库服务的运行情况。微软表示，到目前为止其性能表现比Azure原先的Arm芯片（由初创公司Ampere提供）高出40%。</p><p>&nbsp;</p><p>过去一年半以来，随着GPU价格与存款利率的持续走高，许多企业都在寻求改善云支出的可行方法。对于AWS客户来说，Graviton就是理想的选项之一。AWS副总裁Dave Brown表示，AWS的前百大客户目前都在使用基于Arm架构的芯片，此举能够将性价比提升40%。</p><p>&nbsp;</p><p>但必须承认，从GPU迁移至AWS Trainium AI芯片的难度，恐怕要比从英特尔至强转向Graviton更为复杂。每种AI模型都有自己的特性和需求，技术人员已经成功让各类工具在Arm架构上顺利运行，但定制化AI芯片仍是一片有待探索的新世界。不过Brown相信随着时间推移，越来越多的组织都会意识到Trainium芯片相较于传统GPU的显著性价比优势。</p><p>&nbsp;</p><p>Borkar指出，“我们已经与生态系统中的众多合作伙伴共享了技术规范，相信新的芯片将为全体Azure客户带来收益。”</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.cnbc.com/2023/11/15/microsoft-reveals-maia-ai-processor-and-cobalt-arm-based-chip.html\">https://www.cnbc.com/2023/11/15/microsoft-reveals-maia-ai-processor-and-cobalt-arm-based-chip.html</a>\"</p><p><a href=\"https://www.theverge.com/2023/11/15/23960345/microsoft-cpu-gpu-ai-chips-azure-maia-cobalt-specifications-cloud-infrastructure\">https://www.theverge.com/2023/11/15/23960345/microsoft-cpu-gpu-ai-chips-azure-maia-cobalt-specifications-cloud-infrastructure</a>\"</p><p><a href=\"https://news.microsoft.com/source/features/ai/in-house-chips-silicon-to-service-to-meet-ai-demand/\">https://news.microsoft.com/source/features/ai/in-house-chips-silicon-to-service-to-meet-ai-demand/</a>\"</p><p><a href=\"https://www.ft.com/content/f9721f50-6dc8-4604-b164-aed592bd2152\">https://www.ft.com/content/f9721f50-6dc8-4604-b164-aed592bd2152</a>\"</p>",
    "publish_time": "2023-11-16 17:28:12",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "数据存储量最大提升10倍、最高支持千亿向量规模！腾讯云向量数据库升级多项核心功能",
    "url": "https://www.infoq.cn/article/KkMc8MgeNU498Jqtj10T",
    "summary": "<p>11月15日，在腾讯云向量数据库技术及产业峰会上，腾讯云全面升级向量数据库多项核心性能，最高支持千亿级向量规模和500万QPS峰值能力，同时和信通院一起联合50多家企业共同发布了国内首个向量数据库标准，推进向量数据库及大模型相关产业走向大规模应用。</p><p></p><p>腾讯集团高级执行副总裁、云与智慧产业事业群CEO汤道生表示：“向量数据库不仅是支撑大模型的重要基础设施，也正在成为企业以数据驱动打造未来竞争力的重要一环。”</p><p></p><p>自7月份正式发布以来，腾讯云向量数据库经过多次迭代升级，在企业级能力上持续突破，在优化版的IVF索引支持下，从最初支持的十亿向量规模到现在的千亿规模，同时不断优化索引的压缩算法，让相同的</p><p>内存可以存储5-10倍的数据。</p><p></p><p>此外，在智能化升级方面，腾讯云向量数据库集成Embedding功能，让用户无需关注向量生成过程，就可以实现快速处理数据。</p><p></p><p>腾讯云数据库副总经理罗云表示：“从编程语言到自然语言，大模型重塑了算力调度方式。而AGI时代，也需要智能化的数据调度范式，AGI时代的数据平台，向量数据库是数据的中枢，腾讯云向量数据库希望成为这个数据中枢，通过企业级和智能化的能力助力各行各业一起走向AGI。”</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/16/1606781cf2ad9544a4be0e069dcb873f.png\" /></p><p></p><p>&nbsp;为了加速向量数据库在企业的大规模应用，腾讯云还推出了国内“首个”端到端的向量数据库解决方案，通过文本智能化分割、选择向量化模型、帮助客户建立索引，再经智能化排序实现端到端的数据接入体验。将端到端召回率提高30%，缩短数据接入AI的时间。</p><p></p><p>据罗云介绍，目前腾讯云向量数据库已经累积服务了腾讯内部40多个业务，日请求量达1600亿次，服务了包括博世、销售易、搜狐、好未来、链家等在内的超过1000家外部客户。</p><p></p><p>例如，在SaaS领域，帮助企业客户快速构建私域知识库、智能客服系统；在电商行业，使用向量数据库来提升推荐、搜索、广告业务的推荐效果；在出行行业，使用向量数据库来加速自动驾驶模型训练，此外，在教育行业以及文创等行业也有广泛应用。</p><p></p><p>大会现场，国内首个向量数据库技术标准《向量数据库技术要求》也正式亮相，这份由腾讯云联和信通院等超50家企业联合编制的标准，将为向量数据库技术和产业的有序发展提供专业规范。为推动大模型产业更快创新发展，腾讯云还与硬件厂商、大模型厂商、行业代表等联合成立了“AGI技术生态联盟”。</p><p>&nbsp;</p><p>腾讯云副总裁陈平表示：“腾讯云积极参与向量数据库相关标准制定，并通过搭建AGI技术生态联盟，与上下游伙伴一道，加强产业合作，打造更多的行业解决方案，加速大模型落地。”</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-11-16 18:14:02",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "深度对谈：广告创意领域中AIGC的应用",
    "url": "https://www.infoq.cn/article/xsNvMSUXiWQCCw802R4J",
    "summary": "<p>嘉宾 | 鱼哲、崔世杰</p><p>编辑 | Tina</p><p>&nbsp;</p><p>自从大模型出现以来，很多行业领袖和专家都曾表达过像“考虑使用大模型重新构建所有行业和产品”这样的观点。具体来说，对于各个行业来说，我们需要关注和了解哪些问题可以通过大模型的能力来解决，以及在实际应用时可能面临的挑战。在本期\"极客有约\"节目中，鱼哲和崔世杰深入探讨了广告创意领域中AIGC的实际应用情况。</p><p></p><p>原视频网址：<a href=\"https://www.infoq.cn/video/p56ceAHvdxwtkZN9d7ct\">https://www.infoq.cn/video/p56ceAHvdxwtkZN9d7ct&nbsp;</a>\"</p><p></p><h4>亮点：</h4><p></p><p>要创建一个成功的 AIGC 应用，一个关键的先决条件是拥有垂直领域的高质量数据。AIGC正在改变广告创意领域。随着AI能力的提升，人们需要深入使用并掌握它。像fine-tuning、LangChain等我不会推荐，我会鼓励周围的人去深入使用AIGC，重点在于使用，好的AGI只需要被编译一次。建议使用国内模型并在中国境内部署。这个领域非常快速发展，所以你应该保持好奇心，不断尝试新事物，不断挑战自己。</p><p>&nbsp;</p><p>&nbsp;</p><p>嘉宾简介：</p><p>鱼哲，Lepton AI 创始团队成员，产品负责人。</p><p>崔世杰，广推科技AIGC商业化负责人，资深开发，《微信小程序底层框架实现原理》掘金小册作者。拥有多年全平台一线研发经验，多年团队管理经验，擅长Web、跨端、AIGC技术，熟悉多种编程语言。负责过多个领域的项目开发，涉及的项目包括智慧医疗、智慧城市、直播等多个领域。</p><p>&nbsp;</p><p></p><h4>大模型是如何被应用到广告创意中的</h4><p></p><p>&nbsp;</p><p>鱼哲：首先，世杰老师可以给我们科普下“广告创意”是什么？</p><p>&nbsp;</p><p>崔世杰：很高兴能与大家分享AIGC在广告领域的应用情况。我使用一个比较正式的定义来解释一下。广告创意是一种以营销传播为目的的多媒体内容，其主要目标是吸引目标用户，让用户完成行为转化，通常是与产品或服务相关的互动。广告是我们生活中常见的东西，几乎无处不在。</p><p>&nbsp;</p><p>然而，我所负责的广告形式与传统的品牌广告有所不同。品牌广告通常涉及明星代言的产品推广。而我们主要关注信息流广告，也被称为原生广告，这是大家最常接触到的广告形式。信息流广告包括各种类型的宣传，如产品促销、电商促销和打折产品推广。此外，它还覆盖了视频广告，例如实时热点内容、小说类内容等。</p><p>&nbsp;</p><p>鱼哲：在广告行业的运作过程中，广告创意的生成和传播牵涉到多个角色，从生产方到消费方分别是什么样的人？</p><p>&nbsp;</p><p>崔世杰：生产侧主要是各大广告主，他们具有特定的推广目标，旨在推广自己的产品或促使用户执行特定行为。这些行动可以非常具体。例如，假设要运营一款新兴的应用程序，希望吸引更多用户使用，增加日活跃用户数，或者实现其他行为转化目标。对于电商来说，一种典型的转化目标是用户在应用中下单购买产品。还有其他类型目标，例如提高现有用户的日活跃度，这也可以被视为一种转化。</p><p>&nbsp;</p><p>消费侧就是我们的普罗大众，每个人都可能做出消费行为。</p><p>&nbsp;</p><p>鱼哲：在AIGC出现之前，传统的广告创意是如何制作的？</p><p>&nbsp;</p><p>崔世杰：信息流广告通常需要标配的是广告优化师和剪辑师的团队协作。一般情况下，一个广告优化师会搭配两名剪辑师。这个团队的配置会根据广告要投放的媒介以及广告内容的主题方向来调整。例如，如果广告与小说相关，就需要选择小说方向的内容，而对于电商广告，则需要选择电商相关的素材。</p><p>&nbsp;</p><p>在传统的工作方式中，广告优化师通常会提供一些关键词或指导，然后剪辑师会根据这些信息进行创作。创作完成后，这些素材将被交给投放师进行进一步的处理。这可能是一种自由创作的方式，也可能有一些固定的输入输出模板，这取决于具体的广告项目和团队的工作流程。</p><p>&nbsp;</p><p>创意方向通常是基于广告优化师的过往经验来确定，然后传达给剪辑师。然而，团队成员之间也可以进行相互讨论和合作，因为创意是非常重要的。有时，集体智慧可以带来新的创意思路，尽管大部分情况下，创意方向仍然受广告优化师个人经验的指导。</p><p>&nbsp;</p><p>鱼哲：我理解，广告主可以看作是甲方，他们提出需求，例如，他们想要推广一种矿泉水。然后，广告优化师会根据自己的经验提出一些广告构思，然后与两名剪辑师合作，共同讨论和制定广告的具体内容，包括可能的看板广告、视频内容，以及图文素材等等。那广告做出来之后是直接投放还是要经过甲方审核？</p><p>&nbsp;</p><p>崔世杰：在信息流广告领域，我们主要关注的是最终的数据消耗。因为信息流广告的创意形式多种多样，它可能包括了品牌广告等不同类型。这种创意类型更多地取决于广告主的需求，而我们则以数据为基础来提供反馈。</p><p>&nbsp;</p><p></p><h4>AIGC为广告创意带来了哪些改变？</h4><p></p><p>&nbsp;</p><p>鱼哲：AIGC为广告创意带来了哪些改变？我了解广推在这一块用了非常多的技术，而且效果非常好。</p><p>&nbsp;</p><p>崔世杰：广告创意具有一些独特的特点。相比于社交，广告通常受到非常严格的审核要求，因为广告创意本身具有传播属性，它的初衷是为了传达给更多人看，因此审核要求非常高。举个例子，如果广告涉及一个商品，旁边需要有一个真人模特。审核可能会要求这位模特的着装不能露肩、不能露腰、不能露肚脐、不能露膝盖，甚至站姿也可能有具体的要求，比如不可以是“S型”。</p><p>&nbsp;</p><p>目前面临的一个重要挑战是云计算服务提供商提供的审核服务的范围非常有限。这意味着像我刚才提到的那些严格的审核要求往往无法被满足，因此这是一个挑战。此外，版权问题也是一个挑战。在我们收集原始资源时，需要非常注重版权问题，这会限制我们原始资源的获取。此外，严格的法规也是一个挑战。每年315广告法都会进行修改和更新，要求变得越来越严格。</p><p>&nbsp;</p><p>另一个关键特点是广告创意是可耗尽的。如果你看到一个核潜艇广告并决定购买，完成了一次转化，但如果我再次向你展示相同的广告，你可能不会再次进行转化。这就强调了创意的异质性要求，创意不能完全一样，也不能太相似。如果创意过于相似，会对数据表现和账户产生影响。</p><p>&nbsp;</p><p>最后一个特点是广告创意的数量要求很大。因为广告创意是可耗尽的，如果一批创意的表现不佳，我们需要更换广告创意，重新探索人群，这意味着我们需要大量的广告创意。</p><p>&nbsp;</p><p>总结一下，首先，合规性至关重要，因为广告必须符合法规。其次，它是一种可耗尽的产品，一般只会被用户看到一次或很少几次。第三，广告的体量和消耗量非常庞大。在这方面，AIGC填补了一些空白，带来了一些重要的改变。</p><p>&nbsp;</p><p>鱼哲：这些问题是客观存在的，AIGC或大型模型并不能像魔法一样立刻解决这些问题。更多的是，我们需要思考如何利用这些工具来应对这些问题。这意味着我们需要采用一种与以往不同的解决问题的思路。你可以这个展开来讲一讲，AIGC 面对这些问题的是怎么解决的吗？</p><p>&nbsp;</p><p>崔世杰：举个例子，比如我刚才提到广告优化师和剪辑师之间的配合问题。如果我们要推广小说类广告和视频类广告。视频类广告有其特点，通常需要涵盖实时热点，因为数据反馈表明实时热点可以更好地吸引用户的转化行为。如何收集和筛选实时热点以前都是人工工作，但现在我们将这些任务交给大型语言模型，比如GPT。例如，我这边有一份当天热门榜单的标题，首先需要进行筛选，因为其中可能存在风险问题。然后，我们需要对标题进行扩写，因为有些标题不适合直接用于广告创意的图片或视频中，它们可能不够吸引人。文案方面，也可以通过GPT来扩展或修改，使之更具吸引力。这些工作之前都是由人工完成的。</p><p>&nbsp;</p><p>此外，正如我之前提到的，我们一直面临着原始资源的不足问题，特别是在涉及音视频和图文素材的版权问题上。在资源收集方面，以前我们需要耗费大量的人力和时间，因为不同的广告场景需要不同类型的素材。举个例子，如果我们要为一个外卖平台，比如饿了么，制作广告，那么需要提供大量的下沉式图片和视频，展示美食、夜市烧烤、炸鸡，等等。但这些商业资源通常是有限的，如果需要成千上万张素材，收集起来需要很长时间。有了AIGC的帮助，我们能够更容易地解决资源收集的问题，包括音频资源，因为它们可以通过AIGC来满足需求。这种方法有助于解决原始资源的短缺问题。</p><p>&nbsp;</p><p>鱼哲：您提到了两个非常重要的问题，这些问题在使用AIGC进行扩写和改写时确实需要考虑。首先，对于AIGC输出的结果进行评估非常关键，因为结果可能是好的，也可能不符合我们的预期。在这方面，你们采取了哪些管理和质量控制措施呢？</p><p>&nbsp;</p><p>崔世杰：我们的一个特点是寻找吸引人的标题，这在大型模型中可能会带来一些挑战。然而，我们的精度要求并不是非常高，因此不需要进行深度的定制改造，通过Prompt Engineering 提示工程就可以完成。</p><p>&nbsp;</p><p>鱼哲：在素材数量方面，无论是使用ChatGPT还是自己托管模型，我们通常会有要求来确定每天需要生成多少素材，或者我们会先生成一定数量的素材并储存，然后在需要的时候直接提取使用。我们的素材策略是什么样的？</p><p>&nbsp;</p><p>崔世杰：我们通常会定时按需生成广告创意，以满足不同的需求。在这个过程中，我们会进行余量分析和监控，以确保资源充足。有些存储方案会自动进行补充，以满足高消耗情况。</p><p>&nbsp;</p><p>此外，根据广告主的不同需求，我们会探索多个方向。举例来说，不同品类的广告，比如小说类广告，可能需要不同的画面质量、色彩搭配和视觉效果，这些都可能涉及到不同的数据。因此，在这些情况下，需要测试组进行手动生成和方向选择，以便满足不同广告主的特定要求。</p><p>&nbsp;</p><p></p><h4>在不同的业务流程中，AIGC是如何发挥作用的</h4><p></p><p>&nbsp;</p><p>鱼哲：你的意思是我们当前在信息流广告生成领域的做法是将话题引入，然后利用GPT或其他自然语言处理模型进行文本的改写或扩写，然后再与生成类模型一起用于图像生成，或者使用其他模型生成音视频，是这样吗？</p><p>&nbsp;</p><p>崔世杰：视频类应用只是一个载体，不同的载体可能会有一些不同的流程。</p><p>&nbsp;</p><p>鱼哲：再讲一个非视频应用类载体的广告流程吧。</p><p>&nbsp;</p><p>崔世杰：以小说为例，它有着独特的特点，因为小说涵盖了多种类型。例如，如果你需要制作古装小说的广告，选题方向将完全根据小说内容来确定。在这种情况下，我们会使用大型语言模型的总结功能，来提取吸引人的标题。</p><p>&nbsp;</p><p>然而，这其中也存在一些挑战。生成标题后，我们需要考虑如何将它们与Stable Diffusion或其他工具结合使用。这之后，还需要经过一个过程，将标题与分镜扩写相匹配，这个过程中，还需要考虑小说的内容以及小说的类型。</p><p>&nbsp;</p><p>鱼哲：对于小说的情况，当使用文生图进行图像生成时，是使用原生的Stable Diffusion，然后根据具体需求，自行进行微调？例如，中国的古装风格具有特殊的画风，可能需要进行微调以确保生成的图像与特定画风相匹配。是否会参考类似Swift AI上的资源，以帮助微调模型以满足特定需求吗？</p><p>&nbsp;</p><p>崔世杰：通常，我们处理数据反馈时使用通用的提示。不过，有时也会遇到一些非常特殊的情景，比如“小儿书”风格插画，可能社区中的模型并没有涵盖这种风格。这时，我们会自行训练适合这种风格的Lora模型，然后将其用于生成。这个过程可能需要一些微调。</p><p>&nbsp;</p><p>鱼哲：在训练“小人书”风格插画模型时，我们通常需要准备大约多少数据呢？另外，我注意到你提到模型效果方面，你之前进行了大量的fine-tuning，尤其是针对Llama和Llama 2的7B和13B模型。你们是否发现使用诸如QLoRA这样的快速训练方式，虽然训练速度很快，但最终效果可能并不理想，导致你们最终还需要进行全量的fine-tuning？</p><p>&nbsp;</p><p>崔世杰：在这个过程中，我们的方法相当简单，没有进行深度的调试。那时，我们使用了一些开源的解决方案，包括Stable Diffusion的插件，然后使用了大约100张图像来训练Lora模型。关键是，我们很幸运地收集到了一系列高质量的小儿书风格图像作为初始资源。</p><p>&nbsp;</p><p>鱼哲：还有其他特殊类型的广告可以和我们分享的吗？</p><p>&nbsp;</p><p>崔世杰：我们曾尝试过在不同领域进行广告创意，比如食品类。因为不同领域的广告创意在画面质量和风格上都有不同要求，我们考虑过以二次元动漫风格来呈现食品广告，尤其在Stable Diffusion还不太成熟的早期。尽管这个尝试效果不如真实场景的广告，但最终我们还是以数据驱动为主导。我们还进行了很多其他尝试，这些创意都是通过团队的共同讨论和富有想象力的合作而产生的。同时，我们还曾在视频类广告中尝试了食物广告。</p><p>&nbsp;</p><p>鱼哲: 我们有位观众问到关于剧情式广告的生成，你们是否在这一领域进行过尝试，或者你们是如何看待这个问题的？首先，我想了解一下，你们对于剧情式广告的理解是什么。</p><p>&nbsp;</p><p>崔世杰: 当他提到这个问题时，我基本明白他的意思。我们确实在这个领域进行了测试。但是要注意，目前AIGC技术还无法实现将文本直接转化为非常接近真实视频质量的广告创意。现在的形式更像那些在抖音上看到的解说小说或漫画的视频，通过配音和幻灯片等形式呈现，它们包含剧情元素，就像小说中的情节一样。我们已经尝试过这种小说类型的广告创意，但需要指出生成的难度是相当大的。举个例子，如果你要生成一个10分钟的小说文本，可能需要配以30多张Stable Diffusion或MidJourney的图像，然后这些图像需要剪辑、混合，并与配音和字幕配合，同时还需要考虑视频剪辑的方式，例如双音轨等等。目前自动化技术已经开始广泛应用，我们的平台可以处理这种类型的视频。</p><p>&nbsp;</p><p>鱼哲：我看到有十几张像 PPT 幻灯片讲完一个故事的视频，你们有尝试过吗？效果如何？</p><p>&nbsp;</p><p>崔世杰: 我们曾尝试过这种类型的广告创意，但最终效果并不理想。这可能与广告的内容和目标受众有关。例如，我们可能用这种形式来宣传小说，但这种方式的效果可能并不好，而其他类型的广告可能表现得更出色。因此，我们通常以数据为依据，根据数据的表现来调整广告的方向。此外，除了蒙太奇式的剪辑视频，目前我们也广泛使用过渡效果和动态效果来制作广告创意。这些方法的使用更加多样化。</p><p>&nbsp;</p><p>鱼哲：所以，关于那个“三年之期已到，龙王请回归”这种类型的广告，目前看来还是有些远未达到的。</p><p>&nbsp;</p><p>崔世杰: 这种高端广告创意需要更高的成本，它通常涉及将一张图片通过景深处理转化为具有3D动态效果的视频。此外，还有一种方法是使用数字人物在视频中展示产品，这也是一种趋势。</p><p>&nbsp;</p><p>鱼哲：在硅谷，有一家名叫PIKA LABS的公司，他们提供的服务是，提供一个提示，然后生成一张图片，并为这张图片添加一个两三秒的动画效果。然后你可以使用这个带有动画的图片来参加科幻小说的竞赛，你需要为这个图片配上一些文字，创作一个故事。这有点类似于YouTube上的剪辑视频，但它只为你提供一个静态图片，然后加上短暂的动画效果。例如，你的提示可能是“一只鲸鱼从海平面跳出，太阳从背后落下”。你可以为这个动画配上一个故事，比如描述100年后人类已经消失，只剩下鲸鱼在这个世界上。目前，我们还没有实现这种类型的剧情广告创意。</p><p>&nbsp;</p><p></p><h4>广告投放效果管理</h4><p></p><p>&nbsp;</p><p>鱼哲：既然你们涉及了多个品类的广告自动生成并最终进行投放，我想了解一下，是不是你们内部建立了一个应用平台来进行这些内容的生成，或者你们采用了其他什么方式来管理？</p><p>&nbsp;</p><p>崔世杰：我们建立了一个程序化创意平台，但前提是要有足够充足的高质量原始资源。</p><p>&nbsp;</p><p>鱼哲：原始资源指的是什么？是指计算资源、数据，还是人力资源？</p><p>&nbsp;</p><p>崔世杰：原始资源是指那些在创意生成之前的图像、文本、音频和视频素材，我们需要足够的高质量数据资源。因为这些广告可能需要满足一些审核要求，同时需要添加差异化的图层、广告标识以及文案。要建立一个自动化的平台和流程，首要条件就是需要有足够充足的原始资源。比如，如果我要创作了一个广告，可能需要输入1000张图像，然后生成1000张不同的广告创意图片，这就需要足够丰富的原始资源。</p><p>&nbsp;</p><p>鱼哲：那这个平台的用户主要是谁呢？是广告生成过程中的投放师，还是剪辑师？</p><p>&nbsp;</p><p>崔世杰：目前来看，这个平台同时为两者提供服务。我之前提到了模板的概念，我们会将那些在广告搭配中成功的、获得良好数据反馈的模板存储在这个平台上，以备后续使用。广告创意是一种消耗品，但它有自身的生命周期。比如说今年的中秋节，月饼相关的电商广告创意可能表现出色。但是一旦中秋节过去，这些相关模板和广告创意就不再适用了。明年的中秋节，它们可能再次派上用场，所以我们会将这些模板存储下来。此外，广告优化师也会使用这个平台，他们可以根据自身的经验选择要验证的点。</p><p>&nbsp;</p><p></p><h4>大模型训练数据</h4><p></p><p>&nbsp;</p><p>鱼哲：有观众提问：“从哪里获取需要用于模型训练的高质量数据。”我觉得数据越来越成为每家公司在竞争中非常具有竞争力的资源，通常需要依赖现有业务的数据存量。你对此有何看法？”</p><p>&nbsp;</p><p>崔世杰: 数据一直以来在国内都是一个关键问题。我参加过很多AIGC相关的峰会，发现数据在国内一直是最关键的问题。我还看到了一些新兴的公司，它们专门提供高质量的数据治理服务，为那些训练大型模型的公司提供支持。此外，许多国内大型模型的训练数据都存在不足的问题，尤其是在通用领域，高质量中文数据相对较少。</p><p>&nbsp;</p><p>鱼哲：实际上，不论是企业、个人还是团队，要创建一个成功的 AIGC 应用，一个关键的先决条件是拥有垂直领域的高质量数据，对吧？</p><p>&nbsp;</p><p></p><h4>AIGC是否对广告行业造成冲击</h4><p></p><p>&nbsp;</p><p>鱼哲：让我们回到之前讨论的话题，就是你们的应用平台，剪辑师如何使用它。我想谈谈一个在美国经常被提出的问题，即许多艺术家和艺人反对生成式技术，认为它会夺走他们的工作，导致失业。我想问一下，在你们团队中，你们的剪辑师是否对使用这些技术存在抵触情绪？他们是如何看待这个问题的？</p><p>&nbsp;</p><p>崔世杰: 实际上抵抗是存在的，特别是在一些其他行业中，抵抗力更大一些。例如，一些内容创作者、内容号运营者可能受到冲击，他们通常有自己的团队，包括剪辑师。就像我之前提到的，我们有很多剪辑师，他们使用自动化剪辑工具与AIGC协作，这在很大程度上替代了一部分他们的工作。此外，还有一些原画师。例如在一个团队中，通常会有一个优化师搭配两个剪辑师，但如果使用我们的方案，目前只需要三到四个剪辑师即可。这就显示了自动化和AIGC对工作分工和效率的影响。</p><p>&nbsp;</p><p>鱼哲：我觉得这个现象非常有趣，因为我们可以看到两种极端的态度。一方面，有人强烈反对，拒绝使用这些技术，而另一方面有人欣然接受并拥抱这些新的产业和技术。例如，一些流行的音乐人，如孙燕姿等，已经采用了AIDC技术。他们使用这些技术来生成专辑封面、声音或其他创作，这显示出了人们对新技术持不同态度的现象。</p><p>&nbsp;</p><p>鱼哲：我们前面提到的，有些人愿意拥抱这些新技术，而有些人对它们有一些抵触情绪。在你看来，AIGC 对广告行业会带来巨大冲击还是使原本高效的工作更高效？</p><p>&nbsp;</p><p>崔世杰: 目前来看，AIGC还没有对广告造成巨大冲击，但对内容生产者的冲击更大。举个例子，刚才提到资源收集，采集原始资源，像我们用于商业用途的图像、文本和音视频，通常需要通过一些渠道购买。这对这些渠道的影响会非常大。具体来说，像下沉市场的外卖广告，它们需要一些特定类型的素材，例如烧烤的视频或吃炸鸡的照片，这通常需要专业团队拍摄，而拍摄成本非常高，可能每个素材的成本都要几十块钱。在广告行业，这个成本通常是难以承受的。引入 AIGC 后，原始资源不再需要考虑商业化或版权问题，也不必担心数量的问题。</p><p>&nbsp;</p><p>鱼哲：接下来这个问题可能有点敏感，观众想了解在广告市场中，生成式AI给广告市场带来了哪些变化？我的看法是，生成式AI主要带来了广告生产效率的提升。但对于搜索广告，尤其是生成广告，虽然它可以显著提高制作广告的效率，但对广告的召回率和点击率提升影响可能不会太大。你如何看待这个问题呢？</p><p>&nbsp;</p><p>崔世杰: 就广告市场带来的变化而言，生成式AI并没有在广告市场的基本原则上带来很大的改变。这是因为在广告投放过程中，每当用户看到一条广告时，背后通常有数十家广告公司的广告在竞争展示，用户最终看到的广告仅仅是竞争过程中的一个结果。即使使用生成式AI创建的广告创意被用户看到，实际上只是在竞争中击败了其他广告公司的广告创意。没有生成式AI的情况下，用户仍然会看到广告，因为他们的行为一直存在。例如，当用户在浏览一篇文章时，可能会在文章中间看到广告。因此，生成式AI并没有改变广告市场的基本规则和数据，但目前已经解决了广告生产效率、审核风险、版权问题和广告数量等方面的挑战。</p><p>&nbsp;</p><p>鱼哲：还有一个问题，AIGC 对广告行业是否带来新的商业模式改变。</p><p>&nbsp;</p><p>崔世杰: 这确实是一个重要的趋势。我认为，AIGC正在改变我们整个广告流程。我一直在强调数据的重要性。我一直在强调AIGC可以在我们的平台上进行自动或手动生成，但生成的过程与最终的数据是相关联的。这使整个过程中产生的数据变得非常宝贵。</p><p>&nbsp;</p><p>这两个方面都有价值。一方面是广告的数据投放，另一方面是生成过程中的数据。当这些数据积累起来后，我们可以利用它们来训练预测模型。然后，我们可以不断地通过这些数据来自动调整生成方向，包括色彩搭配、画面冲击力以及创意方向。这样的干预将使我们更好地满足广告创意的目标受众需求，从而形成一个正向循环。这也是我们未来计划发展的一个关键领域，我相信这也是所有广告公司都将积极探索的方向。</p><p>&nbsp;</p><p></p><h4>提示工程与大模型安全问题</h4><p></p><p>&nbsp;</p><p>鱼哲：回到技术方面，你提到我们进行了大量的提示工程。在进行提示词工程时，你们通常会使用中文还是英文？</p><p>&nbsp;</p><p>崔世杰: 我们采用的方案是将中文内容翻译成英文。然而，这个翻译过程并不是直接进行的，而是通过 ChatGPT 进行翻译。与直接翻译相比，这个方法能够获得更好的效果。</p><p>&nbsp;</p><p>鱼哲：最终，我们将这些内容嵌入到模型中之前，实际上是将它们转化为英文。即使用户输入可能是中文，我们会使用 GPT 进行一次翻译，对吗？</p><p>&nbsp;</p><p>崔世杰: 对，就像用户输入，就像我之前提到的小说标题的生成，我们首先总结出一些标题，然后将它们翻译成英文。此外，在整个过程中，例如在处理 Stable Diffusion 和它的提示的语法时，ChatGPT 本身是不知道的，需要依赖提示工程来告诉 ChatGPT 如何创建 Stable Diffusion Prompt。</p><p>&nbsp;</p><p>鱼哲：这实际上是一个非常有趣的问题，因为机器翻译，包括语音和文本翻译，一直都是传统的机器学习或深度学习领域的典型问题。你当时决定为什么使用GPT来做？</p><p>&nbsp;</p><p>崔世杰: 我们当时的方案集成了多个小模型，每个模型在特定任务上表现出色，然后将它们整合到一个程序化平台中。同时，我们也使用了传统的直接翻译模型。我自己在机器翻译领域也有一些研究，发现 GPT 翻译的原理与传统翻译原理完全不同，效果更符合自然语言处理的原理。</p><p>&nbsp;</p><p>鱼哲：有观众提问关于大型模型的安全问题，你们是如何处理的？例如，安全方面的优先级，如防止指令注入，你们关注哪些安全问题？我先分享我的观点，然后你可以分享你的看法。我认为，考虑到你之前提到的使用场景，主要用于内部使用而不是外部使用，安全可能不是最高优先级的问题。世杰你的看法呢？</p><p>&nbsp;</p><p>崔世杰: 安全问题确实很重要。首先，我们有自己的安全措施。在广告创意正式投放之前，我们会进行预审流程。但是，如果模型用于外部，需要考虑各种因素。正如我之前提到的，考虑到当前的云计算服务，内容审核并不十分严格，AIGC生成的内容无法有效地风控。因此，我首先建议使用国内训练的模型。首先因为它们更适合中文；其次，它们可以满足国内审计相关的要求。因此，我更倾向于使用国内模型。如果你选择外国的开源模型，你需要实施自己的安全策略。因此，我建议使用国内模型并在中国境内部署。</p><p>&nbsp;</p><p></p><h4>大模型时代下的个人成长</h4><p></p><p>&nbsp;</p><p>鱼哲：我想了解一下，是什么因素或机会，或者说是什么样的动力，激励你不断尝试新的方向？</p><p>&nbsp;</p><p>崔世杰: 从一个工程师的角度来看，刚入行时，他可能只涉及业务的一小部分，处于一线状态。然而，随着他在业务方面的发展，他会逐渐了解业务的全貌，发现业务的成长以及如何不断突破增长点，而这些增长点大多是由技术创新带来的。举例来说，当时我在智慧城市领域工作时，云计算已经可以为城市级别的风险控制和赋能，业务方向就随之出现，新的机遇出现时，老板们都会追随这些机遇，因此，你会一直处于一线状态，这是一个相互成就的过程。</p><p>&nbsp;</p><p>对于AIGC，当它首次出现时，技术人员可能只是尝试一下，但公司的领导意识到了它的潜力，主动拥抱了这项技术。公司进行了一些基础建设和调研工作，早早地意识到AIGC的潜力，将其引入广告行业。因此，一直跟随这项技术突破，公司一直处于业务的前沿。</p><p>&nbsp;</p><p>鱼哲：不断学习新事物，追求突破，似乎让人一直保持在充满活力的状态，你喜欢这种状态吗？</p><p>&nbsp;</p><p>崔世杰: 如果要我一直做同样的事情，我会感到挺痛苦的。我更喜欢追求各种新奇感受，特别是在技术迅猛发展的时代，总是有新东西值得学习，有时候感觉都来不及跟上。</p><p>&nbsp;</p><p>鱼哲：在当前情况下，你认为所有人是否都需要理解什么是AIGC以及它的工作原理？如果他们需要理解，那需要理解到哪个层面？有时候我尝试向非技术领域的同学解释嵌入、Transformer模型以及自然语言如何转化，但我觉得这些细节对他们来说可能不够重要。你认为那些不从事技术方向的人，比如老板，需要理解AIGC或生成式AI的哪些方面？</p><p>&nbsp;</p><p>崔世杰: 我对AI技术也很感兴趣。但在实际商业应用时，你会发现与学术研究是不同的。在实际应用中更注重一些实际指标，如成本效益等。所以现在最关注的是成本效率和公司规模的承受程度等实际问题。如果我推荐给周围的人使用，我会建议他们深入了解并使用。微软的首席技术官在一次演讲中提到，随着AI能力的不断增强，人们需要站在主驾驶的位置，因此提出了“副驾驶”概念。随着AI能力的提升，人们需要深入使用并掌握它。像fine-tuning、LangChain等我不会推荐，我会鼓励周围的人去深入使用AIGC，重点在于使用。为什么呢？因为在国内已经有很多垂直领域的应用模型，但好的模型只需要训练一次。比如ChatGPT，如果它能够在第5代时解决所有垂直领域的问题，那么其他模型就变得多余了。所以重要的是学会如何使用。</p><p>&nbsp;</p><p>鱼哲：我个人的感觉是，首先，因为我的技术背景，我会首先关注这项技术的细节。然后，我会尽早开始使用它，而后，我会尽力寻找潜在问题。也许这是我作为产品经理的职业特点，总是寻找问题，找出在哪些情况下它无法使用，或者可能出现问题。通过找出“坏案例”，然后评估这项技术在哪些情况下适用，哪些情况下不适用。</p><p>&nbsp;</p><p>崔世杰: 是的，早期时，当生成式AI刚刚崭露头角时，我也曾沉迷其中。因为那时很多解决方案尚不成熟，当我们尝试将尚未成熟的方案应用到实际中时，我可能会花上半个月来计划，但接下来的一周内，技术圈突然冒出了一个成熟的方案。现在已经过了一段时间，每天早上打开手机时，还会看到大量我无法完全了解的AI技术方案。技术的增长速度非常迅猛。</p><p>&nbsp;</p><p>鱼哲：有观众问入门AI的Roadmap，我这里分享一些指导性的建议。</p><p>&nbsp;</p><p>首先，你需要理解AI模型的数学原理，包括嵌入（embedding）、标记化（tokenization）以及前处理（pre-processing）和后处理（post-processing）等内容。这些原理是非常基础的，但对于建立坚实的基础知识体系非常重要。其次，你需要深入了解计算机科学和计算机工程领域，包括了解CPU和GPU的不同功能，以及数据如何从CPU传输到GPU，如何进行计算等等。这些知识是与硬件和性能相关的，随着时间的推移，它们仍然非常有价值。 最后，我认为最重要的一点是不要让自己陷入重复的工作中。这是因为这个领域非常快速发展，所以你应该保持好奇心，不断尝试新事物，不断挑战自己。虽然这可能会有一些折腾，但它将有助于拓宽你的视野，让你更好地理解技术和产品，并保持前进的动力。所以，要在AI领域成功，不仅需要学习基础知识，还需要保持灵活性和开放性，不断追求创新和变化。这就是我对于新人入门AI领域的建议。</p><p>&nbsp;</p><p>延伸阅读：</p><p><a href=\"https://www.infoq.cn/article/WL2yVwKEqIutiwppz0wK\">AIGC 编程：代码编程模型的应用与挑战</a>\"</p><p><a href=\"https://www.infoq.cn/article/8wWUiBa8eBWVLRMrxJaT\">我，一个 95 后，从阿里辞职与贾扬清去硅谷创业</a>\"</p><p><a href=\"https://infoqadmin.geekbang.org/#/createArticle/255415\">文生图大型实践：揭秘百度搜索AIGC绘画工具的背后故事</a>\"</p><p></p>",
    "publish_time": "2023-11-16 20:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]