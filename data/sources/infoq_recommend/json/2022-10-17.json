[
  {
    "title": "无侵入增强 Istio，网易数帆践行这三条原则",
    "url": "https://www.infoq.cn/article/CSU0NV5SHOEHMRXJkiyJ",
    "summary": "<p>在云原生社区近日主办的 Service Mesh Summit 2022 服务网格峰会上，网易数帆云原生技术专家方志恒分享了轻舟服务网格无侵入增强 Istio 的经验，本文据此次分享整理，介绍了对无侵入和实现的思考，轻舟服务网格演进过程中的扩展增强，以及这些扩展增强和无侵入的关系。这里“无侵入”强调的是对服务网格基础设施本身的无侵入，而不是只有对业务的无侵入，后者是服务网格本身的定位所要考虑的内容。</p><p></p><h2>服务网格维护中的无侵入</h2><p></p><p></p><p>关于无侵入，我们从各自的实践经验也知道，做无侵入的增强是非常困难的。原因有很多，比如说我们可能要做业务的适配，快速落地，定制的一些需求等，业务以及项目周期的压力，迫使我们不得不做出一些有侵入的选择。但是我们为什么还要去强调无侵入呢？因为对于我们维护团队，或者说对于我们自己这个技术方案的维护方来说，每一分侵入都会有每一分的成本，它会在后续会体现出来，比如说在做长期维护，做版本演进，去做社区的一些功能和新版本的对齐，我们都需要去解决我们的改动和社区的主干分支之间的冲突。</p><p></p><p>因此，我们需要在我们的研发流程里面去贯彻这样一个目标或者理念：这个方案是不是做到无侵入了，如果没有做到的话，那做到的程度是怎么样的？这样可能才得到一个“求上得中”的效果，就是坚持无侵入，我们才可能做到比较低的侵入。</p><p></p><p>在使用社区的方案去做定制开发、去演进的过程中，我们认为，有一些比较合适的用来去做维护的思路，最合适的方式，是直接使用社区原生的 API 提供的扩展点去做一些无侵入的扩展，这是最理想的情况。当然，社区的一些扩展的 API 可能无法完全满足我们的需求，这个时候我们可以在上层去做一个封装，业界的一些落地的实践案例也体现出这样的理念。这里引用一句名言：计算机科学领域的任何问题，都可以通过增加一个中间层来解决。</p><p></p><p>即使是这样，我们出于性能的考虑，或者出于特性的考虑，很多时候还是会面临一些不得不去做修改的情况。我们有第二个原则，就是把扩展增强的内容去做一些封装在一个单独的库里面，这样可以做到最小的修改和替换。这也是一个比较朴素的工程经验。</p><p></p><p>第三点，如果我们确实要做比较大的一个修改，这个时候我们可以尽量去贯彻一个理念，就是要对社区原生的一些设计思路和特性做一致性的对齐。这里我分享一个“撸猫原则”：如果我们非要去撸一只猫的话，最好顺着它的毛去撸，否则我们可能会把它的毛搞得很乱，甚至它还会反过来咬我们一口。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/df/df8821814a68b6dc017302e53a1beafa\" /></p><p></p><h2>服务和配置的扩展</h2><p></p><p></p><p>首先介绍我们对 Istio 的服务和配置的扩展。</p><p></p><h3>配置</h3><p></p><p></p><p>Istio 社区已经提供支持多 configSource，并给出了一个协议叫 MCP-over-xds，通过这种方式我们可以从不同的数据源去拿到所需的配置。</p><p></p><p><code lang=\"javascript\">configSources:\n- address: xds://mesh-registry.istio-system.svc:16010?type=serviceentry&amp;type=sidecar\n- address: k8s://\n</code></p><p></p><p>这里给出一个配置样例，是通过 xDS 协议去向某一个服务去获取它的配置，同时也可以去 Kubernetes 去获取那些标准的 CR，这是它的一个扩展的方式。</p><p></p><p>我们的 URL 跟官方的稍微有点不一样，是在这基础上稍微做了一点改进，实现了一个叫做 Istio-MCP 的库平替社区原生的 adsc，这就是前面说的第二个原则。在这个库里面，我们实现了 xDS 的增量推送，更增强了一个 revision 的机制，Istio 支持按照 revision 去获取自己感兴趣的配置，我们对此做了增强。我们还做了一个更灵活的分派，允许在 configSource 里面去指定一个类型，相当于从不同的 configSource 去获取不同类型的配置，这个很多时候都是实践的需要。</p><p></p><h3>服务</h3><p></p><p></p><p>服务这部分，在网易数帆的场景里面，比较广泛地应用到了 ServiceEntry。Istio 对 Kubernetes 服务的支持很好，大部分情况下无需做额外的扩展，但是因为它的定位，Istio 把对非 Kubernetes 服务的支持几乎都留给了它的一个扩展点，就是 ServiceEntry 这个 API，以及前面所说的配置扩展的方式。通过这种方式，Istio 允许第三方来作为配置和服务的提供员，来提供其他的服务模型。当然在这个过程中，第三方需要自己去完成服务模型的转换，因为 ServiceEntry 几乎就是 Istio 内部服务模型的 API 版本，你可以认为它是 Istio Service 模型。</p><p></p><p>我们也有一个单独的组件，叫做 mesh-registry，实现了 MCP-over-xds 的协议，作为一个 MCP server。在这个组件内部，我们支持了不同的服务模型的转换，包括将 Dubbo/ZK、Eureka、Nacos 去转换成标准的 ServiceEntry，然后下发。</p><p></p><p>这是在服务这一块的扩展。从目前来说，以上两部分的扩展方式都可以说是无侵入的，是基于社区原生接口和协议的扩展。</p><p></p><h2>插件的扩展</h2><p></p><p></p><p>第二部分是插件的扩展。Istio 的功能确实很丰富，这导致它在市场上成为主流，使用的人很多。但很多人使用同时也意味着，即使 Istio 的能力再丰富，它也无法覆盖所有用户的场景，就会需要这种扩展机制。</p><p></p><h3>EnvoyFilter</h3><p></p><p></p><p>Istio 社区的扩展方式是一个比较典型的 EnvoyFilter 的方式。这种方式，configPatches 进去的内容是 Envoy 的一个一个 filter 的配置，Envoy 具体的内容我们可以先忽略，先看一下 applyTo、context、match、routeConfiguration、vhost 这一堆东西。</p><p></p><p>举个例子，我们要做一个限流的功能，因为它是一个业务功能，作为使用者，我们要知道限流 API 的业务语义，首先需要去看 Envoy 的限流插件它的 API 是怎么样的，跟上层对限流的业务需求是不是对得上，再确定我应该怎么样去写一个限流的插件的配置。到这一步还只是完成了要 Patch 进去的内容，要写出这个 EnvoyFilter 的时候，我们还需要去了解更多的东西，比如这里的 applyTo、HTTP_ROUTE 以及 vhost 等。如果是其他的类型的 Patch，可能还有其他的概念。</p><p></p><p><code lang=\"properties\">apiVersion: networking.istio.io/v1alpha3\nkind: EnvoyFilter\nmetadata:\nname: bookinfo-gateway-sampling\nnamespace: istio-system\nspec:\nconfigPatches:\n- applyTo: HTTP_ROUTE\n   match:\n   context: GATEWAY\n   routeConfiguration:\n    portNumber: 80\n    vhost:\n     name: \"*:80\"\n   patch:\n    operation: MERGE\n    value:\n\n</code></p><p></p><p>这里面有一个本质的问题，filter 是 Istio 提供的一个几乎是纯数据结构级别的 Patch 机制，它直接操作 Istio 下发给 Envoy 的 xDS 配置，它的数据结构的描述、定义和类型都是 Envoy 侧的一些概念，比如 vhost，这就意味着 Istio 的使用者需要深入了解 Envoy 侧的概念。同时还有一些的灰色地带，举个例子，如果我们要给一个 vhost 去 Patch 一些东西，就要知道 vhost name，而 vhost name 是 Istio 自己的一个实现，纯粹实现层面的东西，相当于说上层的使用者还要知道某一个版本的 Istio，它的 vhost name 是通过什么规则拼起来的。我们会认为对使用者来说负担会比较多，一个比较理想的做法是，他既然是 Istio 的使用者，那么他接触到的应该尽量是 Istio 层面的一些语义。我们对它做增强的思路就是这样的。</p><p></p><p>下面是轻舟服务网格做的一个比较浅的封装，但是在我们内部用得很多，所以我们认为它解决了一些实际问题。这个字段描述我们这个插件要去作用于网关，作用于某一个 host，作用于某一条路由，也就是说我们会尽量用 Istio 层面的语义来做这种类似的封装，帮用户转成下层的 Envoy 语义。</p><p></p><p><code lang=\"properties\">apiVersion: microservice.slime.io/v1alpha1\nkind: EnvoyPlugin\nmetadata:\nname: reviews-ep\nnamespace: istio-samples\nspec:\nworkloadSelector:\n  labels:\n   app: reviews\ngateway:\n- gateway-system/prod-gateway\nhost:\n- reviews.istio-samples.svc.cluster.local\nroute:\n  - ratings.istio-samples.svc.cluster.local:80/default\n  - prefix-route1\nplugins:\n- name: envoy.filters.network.ratelimit\n   enable: true\n   inline:\n    settings:\n     {{plugin_settings}} # plugin settings\n</code></p><p></p><p>基于同样的思路，我们还做了一个限流的模块。但这里不是为了讲限流，而是说我们怎么去做上层的业务语义描述。限流这个功能有点特别，可以做得很复杂，所以 Envoy 提供了一个非常灵活的 API，这带的一个问题是，别说 Istio 的用户，就是 Istio 的维护者自己要把 Envoy 限流 API 看明白，都需要付出较多的时间和精力。所以，我们希望把它做得简化一点，更接近业务语义描述，这也是一个复杂度的消化——Envoy 做得非常灵活，它什么都可以做，但复杂度不会凭空消失，中间需要肯定有一层实现业务语义到底层的灵活能力的映射。</p><p></p><p><code lang=\"properties\">apiVersion: microservice.slime.io/v1alpha2\nkind: SmartLimiter\nmetadata:\nname: review\nnamespace: default\nspec:\nsets:\n  v1:\n   descriptor:\n   - action:\n      fill_interval:\n       seconds: 1\n      quota: \"10\"\n      strategy: \"single\"\n     condition: \"{{.v1.cpu.sum}}&gt;10\"\n     target:\n      port: 9080\n</code></p><p></p><h3>Rider 插件扩展</h3><p></p><p></p><p>插件扩展的第二大类是我们的 Rider 的插件，Rider 比较像 Envoy 版本的 OpenResty，Envoy 本身有支持 Lua 的插件，但是它的支持比较简单，里面的 API 比较少，熟悉 OpenResty 的同学应该知道，我们写 Lua 和 OpenResty 是完全不一样的，因为 OpenResty 提供了很丰富的，跟网络操作、跟 Nginx 内部 API 做交互的 API，让我们很容易去做实际业务功能的开发，你无法想象我们纯粹用 Lua 去开发一个 HTTP_SERVER。基于这个背景，我们对 Lua 做了一个增强，在 Rider 插件提供了比较丰富的 Lua 交互的 API，让用户可以相对容易地在里面去实现一个上层的业务和治理的功能。另外，我们也对原生的 Lua 插件实现做了一些性能优化，相比来说 Rider 是有一定的性能优势的。</p><p></p><p>Rider 和原生的 Envoy Lua 插件的对比，是我们可以支持插件的配置。这里的配置是指类似于 Envoy 的 WASM 或者 Lua 插件，都是分成两部分，一部分是下发一个可执行的内容，无论是 Lua 脚本还是 WASM 二进制，都是一个插件实际执行的逻辑，我们还可以给它一份配置，这个配置跟执行内容两相结合，形成最终的业务行为。</p><p></p><p>社区的 Lua 不支持如路由级别的插件配置，这导致它的行为比较死，比较 hardcode，我们支持它的插件配置，支持更多的 API，性能也会更好一点。</p><p></p><p>现在 WASM 是一个很火的概念，我们也跟 WASM 做了一个对比，第一点是 Lua 跟 WASM 的对比，作为脚本语言，Lua 更加可见即可得，虽然 WASM 也可以从脚本编译而得，但如果用脚本转成 WASM 再做下发，WASM 编译语言性能损耗更小的优势就没有了。第二点是便于分发，因为没有编译的过程。第三点也是支持更多的 API，原生的 Envoy WASM API 确实会少一些。最后一点是更好的性能，我们原以为即使考虑上 LuaJIT，Rider 的性能也不会更好，但实际上 Envoy WASM API 的实现导致 Envoy WASM 跟 Envoy 内部交互的成本略高，所以测出来它的性能反而比 Rider 要更差一点。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/0a/0a7d98ee15710e5618d67370c8a24192.png\" /></p><p></p><p>这是我们实际上测出来的一个对比，我们分别模拟三种场景下，一个很简单的，一个中等复杂度的，还有一个稍微高一点复杂度的，不同方案的性能差别，从图中可以都可以看到，三种场景下 Rider 插件的性能都是好于 WASM C++ 的，尤其是在复杂场景，大概有 10% 左右的提升，当然这三者相比于原生插件都有不小的差别。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/0e/0e84310186a636935b4eedeaca53bed7.png\" /></p><p></p><p>这里给出了一个我们提供的 API 的列表，可以看到风格还是非常的 Resty 的。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/9b/9b50ba577abaa6360ec4245f79a73e87.png\" /></p><p></p><p>我们做的 RiderPlugin，这个东西比较有意思，下面是一个 WASM 的样例，大家可以看到它的 API 的数据结构，完全是一个 WASM 的 API，但实际上做的事情，是通过镜像的方式把我们的 Rider 插件给下发了，再分发到数据面，效果是将 HTTP 请求的那个 response 的 body 改成了 C++ is awesome。所以说，使用上不能说差不多，简直是一模一样。</p><p></p><p><code lang=\"properties\"># wasm_plugin.yaml\napiVersion: extensions.istio.io/v1alpha1\nkind: WasmPlugin\nmetadata:\nname: test1.rider\nspec:\nimagePullPolicy: IfNotPresent\nimagePullSecret: qingzhou-secret\npluginConfig:\n  destination: Body\n  message: C++ is awesome!!\n  source: Static\nselector:\n  matchLabels:\n   app: reviews\nsha256: nil\nurl: oci://slimeio/rider_plugin:0.1.0\n</code></p><p></p><p>我当时看到 Istio 的 WasmPlugin 这个 API 的时候，是有点惊讶的，第一是不知道它为什么要做一个 WasmPlugin，而不是做一个通用的插件分发机制，有点过于耦合了；第二是我发现它字段的设计就是一个通用的插件分发，但是它的名字就叫做 WasmPlugin，当然它在实现的时候也是这样的。所以，我们完全可以用这个 API 来实现我们的 Rider 插件的分发，这个是我们目前已有的一个特性。当然我们还另外设计了一个 RiderPlugin CRD，主要是考虑到后续 Rider 可能提供更丰富的功能，会有更多的字段。我们在实现这个支持的时候，不能说没有侵入，但真的是只改了一点点——它的那些插件分发，包括 Pilot agent 里面，怎么从镜像里面去提取 WASM 文件，我们几乎按同样的规范去定义 Rider 的镜像，去在里面放我们的 Rider 的插件的配置，Lua 的文件，几乎是完全一样的。这就是前面提到的另一个原则，如果我们非要去做一些新的功能，可以做得跟原生的比较像，这样的话无论是我们自己还是用户，都很容易上手。</p><p></p><p>我们最终下发给 Envoy 的一个数据结构，和 WASM 是有一些差异的，这个差异是在实现里面去做了一个屏蔽，本质上说，我们只是在最后生成下发给 Envoy 的数据的时候对内容做了一些修改，让它是一个 Rider 的格式。</p><p></p><p><code lang=\"properties\">\nroute_config:\nname: local_route\nvirtual_hosts:\n- name: local_service\n  domains:\n  - \"*\"\n  # Plugin config here applies to the VirtualHost\n  #\n  # typed_per_filter_config:\n  # proxy.filters.http.rider:\n  # \"@type\": type.googleapis.com/proxy.filters.http.rider.v3alpha1.RouteFilterConfig\n  # plugins:\n  routes:\n  - match:\n     prefix: \"/static-to-header\"\n    route:\n     cluster: web_service\n    # Plugin config here applies to the Route\n    #\n    # plugins is a list of plugin route configs. Each entry has a name and its config.\n    # The filter will look up the list by order given a plugin name, and use the first match entry.\n    typed_per_filter_config:\n     proxy.filters.http.rider:\n      \"@type\": type.googleapis.com/proxy.filters.http.rider.v3alpha1.RouteFilterConfig\n      plugins:\n       - name: echo\n         config:\n          message: \"Lua is awesome!\"\n          source: Static\n          destination: Header\n          header_name: x-echo-foo\n    http_filters:\n    - name: proxy.filters.http.rider\n      typed_config:\n       \"@type\": type.googleapis.com/proxy.filters.http.rider.v3alpha1.FilterConfig\n       plugin:\n        vm_config:\n         package_path: \"/usr/local/lib/rider/?/init.lua;/usr/local/lib/rider/?.lua;\"\n        code:\n         local:\n          filename: /usr/local/lib/rider/examples/echo/echo.lua\n        name: echo\n        config:\n         message: \"C++ is awesome!\"\n         source: Static\n         destination: Body\n    - name: envoy.filters.http.router\n      typed_config: {}\n\n</code></p><p></p><p>基于此我们还做了前面提到的一个 EnvoyPlugin 的插件，对插件分发做了一个比较浅的上层封装，也加入了对 WASM、Rider 的支持，将会在近期 release。</p><p></p><h3>Dubbo 协议扩展</h3><p></p><p></p><p>接下来介绍协议的扩展。我们第一个做的是 Dubbo 协议扩展，因为 Dubbo 在国内确实使用很广泛，同时我们还有一些特殊的考量，稍后再详解。</p><p></p><h4>数据面</h4><p></p><p></p><p>首先看数据面的部分。第一，我们做了比较丰富的七层的 dubbo filters，Istio + Envoy 这套体系的大部分治理功能都是通过七层插件来实现的，HTTP 的比较丰富的治理功能有很多七层插件，所以我们也实现了很多 Dubbo 的插件。</p><p></p><p><code lang=\"perl\">\"typed_per_filter_config\": {\n\"proxy.filters.dubbo.locallimit\": {\n  \"@type\": \"type.googleapis.com/udpa.type.v1.TypedStruct\",\n  \"type_url\": \"type.googleapis.com/proxy.filters.dubbo.local_limit.v2.\\\n    ProtoCommonConfig\",\n  \"value\": {\n</code></p><p></p><p>第二，我们实现了一个 DRDS，也就是 Dubbo RDS，因为 Envoy RDS 几乎等同于 HTTP RDS，只定义了 HTTP 协议相关的路由的数据结构，我们要实现一个比较灵活的路由，以及性能比较好的路由分发，就需要定义一个单独的 xDS 资源类型。</p><p></p><p>第三，我们还做了一个 Dubbo 协议嗅探，这是有一些特殊的场景，Istio 社区对协议嗅探有一部分的的支持，它的本意不是为了实现一个很丰富的基于协议嗅探的治理，而是为了解决一部分场景需求，相当于我们引入一个代理之后，会有一些场景需要通过特殊的技术手段去解决，而我们在实际生产中会面临 HTTP 的、TCP 的、Dubbo 的协议，也需要用同样的机制去解决它，所以我们也支持 Dubbo 的协议嗅探。其中技术细节非常多，这里就不展开。</p><p></p><h4>控制面</h4><p></p><p></p><p>控制面的改动更多，用户会更可感知。我们的支持比较特殊，因为我们实现了跟 HTTP 几乎完全同等语义的 Istio API，体现为 VS/DR，就是基本的治理。还有比较丰富的治理，是那些七层的 filter，还有 Istio 这一层所抽象出来的认证鉴权的策略是只作用于 HTTP 的，我们也是对它做了 Dubbo 的支持。还有一个比较特殊的就是 Sidecar，Istio 有一个资源是用来描述应用或者服务之间的依赖关系的，这样就可以实现按需下发，像配置瘦身、推送范围的影响，都可以得到一个比较好的优化，我们对此也做了 Dubbo 的支持，相当于用标准的 API 去支持 Dubbo 的类似于服务依赖描述和按需下发。还有一个是 EnvoyFilter，我们也支持了用 EnvoyFilter 的标准的 API 去做 Dubbo 插件的分发。</p><p></p><p><code lang=\"properties\">- applyTo: DUBBO_FILTER\n  match:\n   context: SIDECAR_OUTBOUND\n   listener:\n    filterChain:\n     filter:\n      name: envoy.filters.network.dubbo_proxy\n      subFilter:\n       name: envoy.filters.dubbo.router\n  patch:\n   operation: INSERT_BEFORE\n   value:\n    config:\n     '@type': type.googleapis.com/udpa.type.v1.TypedStruct\n     type_url: type.googleapis.com/proxy.filters.dubbo.traffic_mark.v2.ProtoCommonConfig\n</code></p><p></p><h4>通用七层扩展框架</h4><p></p><p></p><p>我们也做了通用的七层扩展框架的支持，我们在 Envoy 社区的 Maintainer 也和国内同行沟通过，共同努力推进，目前已经合入 Envoy 社区版本，也就是说在数据面是有通用七层扩展框架的支持的，后续 Istio 社区相关的支持，我觉得也是可以期待的。</p><p></p><p>这里简要展开一下我个人对通用七层扩展框架的理解。我们服务网格多协议适配以及长期维护的成本很高，每接入一个新的协议，都需要去做一个额外的适配。在 Envoy 视角来说，支持一个新的协议需要做的事情，首先是对协议基本的编解码和协议流程的支持，这是协议内部的东西，肯定要做的；除此之外，还涉及到它要跟 Envoy 原有流程的对接，比如 Cluster 是不是可以用，路由是怎么生效的，流量的分派从 listener 进来怎么走到协议解析器或者是四层的 filter，也就是说，一个新的协议的支持要做很多重复性的事情，比如跟原有的机制相结合，这部分重复的工作量我们是可以省去的。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/96/96bec6198342c1bad1c486e5eb5fc94f.png\" /></p><p></p><p>从服务代理和服务治理的视角来说，很多时候我们不关心它是什么协议，服务治理可以理解为一个基于特征的流量分配或者是流量处理，也就是说通常我们关心的是它的特征能否用一种比较通用的方式去描述，就好比我们在做协议设计的时候，可能都会塞进去一个字段，叫做 metadata，HTTP 的协议里面的 header 其实就是一种 metadata，如果能用一个比较简单的通用模型去描述我们所有协议的特征，我们就可以基于这个模型去做服务治理，剩下的事情就是把已有的协议来转化成这个通用模型。当然，所有的这种加一个简单的中间层去做一个复杂度的屏蔽，都会有一个问题，就是无法感知我们抽象出来的共性以外的东西。</p><p></p><p>举个例子，如果我们要支持 HTTP2，想做一些相对下层的治理，可能会比较困难，因为感知不到 stream、frame 等等，能感知到的就只有它这个抽象。这就是我觉得所有类似的技术方案都有同样的问题。但是一个技术方案的价值，肯定是在它带来的收益减去副作用之后的，如果我们觉得还不错，就可以继续去使用它。</p><p></p><p>我们目前在用这个通用框架去实现 Dubbo。以前 Dubbo 之所以没有进 Istio 社区，是因为 Istio 社区并不想维护一个特定的协议，即使该协议国内用户比较多，而且因为年代的原因，Dubbo 是不那么云原生的。但是如果我们这里引入的不是 Dubbo，而是一个通用的七层框架，那应该比较乐观一些。所以我们后续会替换原有的 Dubbo Proxy，就是数据面这一块，同时也会尝试跟相关方去推动控制面的接入，看能不能进入 Istio 社区。</p><p></p><h2>Slime 开源项目的集成</h2><p></p><p></p><p>上述的很多扩展增强，都已经沉淀在我们开源的 Slime 项目（github.com/slime-io/slime）里面了。这个项目已经进入 Istio 生态，我们对 Istio 的增强，或者是说魔改也好，或者是说生态丰富也好，都会放进 Slime 项目里面，它是一个 group，里面包含比较多的子项目。这里简单介绍 Slime 最近的一些进展。首先在架构层面，我们做了比较彻底的模块化设计，可以快速地去对 Slime 做上层功能的扩充。</p><p></p><p>我们定义了一个比较明确的框架层来管理上层的模块，同时也提供一些基础能力给上层，包含定义的一些 metric 框架，让上层可以用很少的代码去获取到一些像 Kubernetes 乃至更多类型的 metric 信息，并且对它做一些处理。同时我们也做了多集群的支持——很多时候我们之所以做一些东西，是因为 Istio 的多个增强功能都需要去做相关的支持，我们就会把它放到框架层——在这个框架层我们直接做了与 Istio 原生比较一致的多集群感知，社区叫做 multi cluster discovery。</p><p></p><p>我们还支持了一个统一的服务模型数据，支持了 Kubernetes Services 和 ServiceEntry，两个消化完以后处理为内部的一个数据类型。我们之前有了解到，一些同行的朋友在调研技术方案的时候，发现我们只支持 Kubernetes 就没有继续了。比如懒加载的方案，我们现在已经做了一个比较彻底的支持。</p><p></p><p>还有一个模块聚合和管理的能力，最终的形态大概是这样，只要手动写几行代码，把每一个模块直接放进来就可以了。</p><p></p><p><code lang=\"cpp\">func main() {\n   module.Main(\"bundle\", []module.Module{\n        &amp;limitermod.Module{},\n        &amp;pluginmod.Module{},\n        &amp;pilotadminmod.Module{},\n        &amp;sidecarmgrmod.Module{},\n        &amp;tracetiomod.Module{},\n        &amp;meshregistrymod.Module{},\n   })\n}\n</code></p><p></p><p>我们在最近一年多做了很多的模块，比如前面提到的 meshregistry、pilotadmin、sidecarmgr、tracetio，其中里面有一部分已经开源出去了，还有一部分因为耦合了一些业务逻辑，可能会晚一点开源。</p><p></p><p>稍微重点说一下，我们有一个子项目叫做 i9s（github.com/slime-io/i9s），是从另一个开源项目 K9s fork 过来的。熟悉 Kubernetes 的同学可能会用过 K9s ，它提供一种交互式的方式，我们觉得它很好用。同时我们也想到，对于 Istio 的运维管理，有很多地方也可以用这种方式来实现，使用起来会更方便一些。i9s 本质上是用 K9s 这种交互式的视图去展示 Istio 的各种内部信息，比如可以去查看 Istio 上面连接哪些 Sidecar，每个 Sidecar 的运行状态，下发的配置，它的配置是否和应有的配置一致，我们可以去 watch 推送的频率，以及推送的时延，等等。</p><p></p><p>Slime 项目后续会开放更多服务网格管理的能力，期待大家共建社区。谢谢！</p><p></p><p>延伸阅读：</p><p></p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MzU4MDM1MDAwOQ==&amp;mid=2247486008&amp;idx=1&amp;sn=a99b06d8acd007ce8bd2f27d4084a4c9&amp;chksm=fd59736eca2efa78a9041779287b986cfa085b90a59693bc1bbd78627526334af45691363022&amp;scene=21#wechat_redirect\">IstioCon 回顾 | 网易数帆的 Istio 推送性能优化经验</a>\"Slime 项目：<a href=\"https://github.com/slime-io/slime\">https://github.com/slime-io/slime</a>\"i9s 子项目：<a href=\"https://github.com/slime-io/i9s\">https://github.com/slime-io/i9s</a>\"Rider 插件框架：<a href=\"https://github.com/hango-io/rider\">https://github.com/hango-io/rider</a>\"</p><p></p><p>作者介绍：</p><p></p><p>方志恒，网易数帆云原生技术专家，负责轻舟 Service Mesh，先后参与多家科技公司 Service Mesh 建设及相关产品演进。从事多年基础架构、中间件研发，有较丰富的 Istio 管理维护、功能拓展和性能优化经验。</p>",
    "publish_time": "2022-10-17 10:10:15",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "依赖重、扩展差，字节跳动是如何优化Apache Atlas 实时消息同步的？",
    "url": "https://www.infoq.cn/article/BM7PS9IyFSy9fvWh3Dg9",
    "summary": "<p></p><h2>摘要</h2><p></p><p></p><p>字节数据中台 DataLeap 的 Data Catalog 系统通过接收 MQ 中的近实时消息来同步部分元数据。Apache Atlas 对于实时消息的消费处理不满足性能要求，内部使用 Flink 任务的处理方案在 ToB 场景中也存在诸多限制，所以团队自研了轻量级异步消息处理框架，很好地支持了字节内部和火山引擎上同步元数据的诉求。本文定义了需求场景，并详细介绍框架的设计与实现。</p><p></p><h2>背景</h2><p></p><p></p><h3>动机</h3><p></p><p></p><p>字节数据中台 DataLeap 的 Data Catalog 系统基于 Apache Atlas 搭建，其中 Atlas 通过 Kafka 获取外部系统的元数据变更消息。在开源版本中，每台服务器支持的 Kafka Consumer 数量有限，在每日百万级消息体量下，经常有长延时等问题，影响用户体验。在 2020 年底，我们针对 Atlas 的消息消费部分做了重构，将消息的消费和处理从后端服务中剥离出来，并编写了 Flink 任务承担这部分工作，比较好的解决了扩展性和性能问题。然而，到 2021 年年中，团队开始重点投入私有化部署和火山引擎公有云业务的支持，对于 Flink 集群的依赖引入了可维护性的痛点。在仔细分析了使用场景和需求，并调研了现成的解决方案后，我们决定投入人力自研一个消息处理框架。当前这个框架很好支持了字节内部以及 ToB 场景中 Data Catalog 对于消息消费和处理的场景。本文会详细介绍框架解决的问题，整体的设计以及实现中的关键决定。</p><p></p><h3>需求定义</h3><p></p><p></p><p>使用下面的表格将具体场景定义清楚。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/0e/0e11ac17d65456698f59b0ec5ba60ccf.png\" /></p><p></p><h3>相关工作</h3><p></p><p></p><p>在启动自研之前，我们评估了两个比较相关的方案，分别是 Flink 和 Kafka Streaming。Flink 是我们之前生产上使用的方案，在能力上是符合要求的，最主要的问题是长期的可维护性。在公有云场景，那个阶段 Flink 服务在火山引擎上还没有发布，我们自己的服务又有严格的时间线，所以必须考虑替代；在私有化场景，我们不确认客户环境一定有 Flink 集群，即使部署的数据底座中带有 Flink，后续的维护也是个头疼的问题。另外一个角度，作为通用流式处理框架，Flink 的大部分功能我们并没有用到，对于单条消息的流转路径，其实只是简单的读取和处理，使用 Flink 有些“杀鸡用牛刀”了。另一个比较标准的方案是 Kafka Streaming。作为 Kafka 官方提供的框架，对于流式处理的语义有较好的支持，也满足我们对于轻量的诉求。最终没有采用的主要考虑点是两个：</p><p></p><p>对于 Offset 的维护不够灵活：我们的场景不能使用自动提交（会丢消息），而对于同一个 Partition 中的数据又要求一定程度的并行处理，使用 Kafka Streaming 的原生接口较难支持。与 Kafka 强绑定：大部分场景下，我们团队不是元数据消息队列的拥有者，也有团队使用 RocketMQ 等提供元数据变更，在应用层，我们希望使用同一套框架兼容。</p><p></p><p></p><h2>设计</h2><p></p><p></p><h3>概念说明</h3><p></p><p></p><p>MQ Type：Message Queue 的类型，比如 Kafka 与 RocketMQ。后续内容以 Kafka 为主，设计一定程度兼容其他 MQ。Topic：一批消息的集合，包含多个 Partition，可以被多个 Consumer Group 消费。Consumer Group：一组 Consumer，同一 Group 内的 Consumer 数据不会重复消费。Consumer：消费消息的最小单位，属于某个 Consumer Group。Partition：Topic 中的一部分数据，同一 Partition 内消息有序。同一 Consumer Group 内，一个 Partition 只会被其中一个 Consumer 消费。Event：由 Topic 中的消息转换而来，部分属性如下。Event Type：消息的类型定义，会与 Processor 有对应关系；Event Key：包含消息 Topic、Partition、Offset 等元数据，用来对消息进行 Hash 操作；Processor：消息处理的单元，针对某个 Event Type 定制的业务逻辑。Task：消费消息并处理的一条 Pipeline，Task 之间资源是相互独立的。</p><p></p><h3>框架架构</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/eb/eb6b7775e262abd924ef04d2b4872962.png\" /></p><p></p><p>整个框架主要由 MQ Consumer, Message Processor 和 State Manager 组成。</p><p></p><p>MQ Consumer：负责从 Kafka Topic 拉取消息，并根据 Event Key 将消息投放到内部队列，如果消息需要延时消费，会被投放到对应的延时队列；该模块还负责定时查询 State Manager 中记录的消息状态，并根据返回提交消息 Offset；上报与消息消费相关的 Metric。Message Processor：负责从队列中拉取消息并异步进行处理，它会将消息的处理结果更新给 State Manager，同时上报与消息处理相关的 Metric。State Manager：负责维护每个 Kafka Partition 的消息状态，并暴露当前应提交的 Offset 信息给 MQ Consumer。</p><p></p><h2>实现</h2><p></p><p></p><h3>线程模型</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/de/deef6d2c11c17651bf691c6c82613c52.png\" /></p><p></p><p>每个 Task 可以运行在一台或多台实例，建议部署到多台机器，以获得更好的性能和容错能力。</p><p></p><p>每台实例中，存在两组线程池：</p><p></p><p>Consumer Pool：负责管理 MQ Consumer Thread 的生命周期，当服务启动时，根据配置拉起一定规模的线程，并在服务关闭时确保每个 Thread 安全退出或者超时停止。整体有效 Thread 的上限与 Topic 的 Partition 的总数有关。Processor Pool：负责管理 Message Processor Thread 的生命周期，当服务启动时，根据配置拉起一定规模的线程，并在服务关闭时确保每个 Thread 安全退出或者超时停止。可以根据 Event Type 所需要处理的并行度来灵活配置。</p><p></p><p>两类 Thread 的性质分别如下：</p><p></p><p>Consumer Thread：每个 MQ Consumer 会封装一个 Kafka Consumer，可以消费 0 个或者多个 Partition。根据 Kafka 的机制，当 MQ Consumer Thread 的个数超过 Partition 的个数时，当前 Thread 不会有实际流量。Processor Thread：唯一对应一个内部的队列，并以 FIFO 的方式消费和处理其中的消息。</p><p></p><h3>StateManager</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/4f/4f20ded14ffd23af08d6fa6d92890b92.png\" /></p><p></p><p>在 State Manager 中，会为每个 Partition 维护一个优先队列（最小堆），队列中的信息是 Offset，两个优先队列的职责如下：</p><p></p><p>处理中的队列：一条消息转化为 Event 后，MQ Consumer 会调用 StateManager 接口，将消息 Offset 插入该队列。处理完的队列：一条消息处理结束或最终失败，Message Processor 会调用 StateManager 接口，将消息 Offset 插入该队列。</p><p></p><p>MQ Consumer 会周期性的检查当前可以 Commit 的 Offset，情况枚举如下：</p><p></p><p>处理中的队列堆顶 &lt; 处理完的队列堆顶或者处理完的队列为空：代表当前消费回来的消息还在处理过程中，本轮不做 Offset 提交。处理中的队列堆顶 = 处理完的队列堆顶：表示当前消息已经处理完，两边同时出队，并记录当前堆顶为可提交的 Offset，重复检查过程。处理中的队列堆顶 &gt; 处理完的队列堆顶：异常情况，通常是数据回放到某些中间状态，将处理完的队列堆顶出堆。注意：当发生 Consumer 的 Rebalance 时，需要将对应 Partition 的队列清空。</p><p></p><h3>KeyBy 与 Delay Processing 的支持</h3><p></p><p></p><p>因源头的 Topic 和消息格式有可能不可控制，所以 MQ Consumer 的职责之一是将消息统一封装为 Event。根据需求，会从原始消息中拼装出 Event Key，对 Key 取 Hash 后，相同结果的 Event 会进入同一个队列，可以保证分区内的此类事件处理顺序的稳定，同时将消息的消费与处理解耦，支持增大内部队列数量来增加吞吐。</p><p></p><p>Event 中也支持设置是否延迟处理属性，可以根据 Event Time 延迟固定时间后处理，需要被延迟处理的事件会被发送到有界延迟队列中，有界延迟队列的实现继承了 DelayQueue，限制 DelayQueue 长度, 达到限定值入队会被阻塞。</p><p></p><h3>异常处理</h3><p></p><p></p><p>Processor 在消息处理过程中，可能遇到各种异常情况，设计框架的动机之一就是为业务逻辑的编写者屏蔽掉这种复杂度。Processor 相关框架的逻辑会与 State Manager 协作，处理异常并充分暴露状态。比较典型的异常情况以及处理策略如下：</p><p></p><p>处理消息失败：自动触发重试，重试到用户设置的最大次数或默认值后会将消息失败状态通知 State Manager。处理消息超时：超时对于吞吐影响较大，且通常重试的效果不明显，因此当前策略是不会对消息重试，直接通知 State Manager 消息处理失败。处理消息较慢：上游 Topic 存在 Lag，Message Consumer 消费速率大于 Message Processor 处理速率时，消息会堆积在队列中，达到队列最大长度，Message Consumer 会被阻塞在入队操作，停止拉取消息，类似 Flink 框架中的背压。</p><p></p><h3>监控</h3><p></p><p></p><p>为了方便运维，在框架层面暴露了一组监控指标，并支持用户自定义 Metrics。其中默认支持的 Metrics 如下表所示：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/66/666c41e21fd56db88026edab1fe4266d.png\" /></p><p></p><h2>线上运维 Case 举例</h2><p></p><p></p><p>实际生产环境运行时，偶尔需要做些运维操作，其中最常见的是消息堆积和消息重放。对于 Conusmer Lag 这类问题的处理步骤大致如下：</p><p></p><p>查看 Enqueue Time，Queue Length 的监控确定服务内队列是否有堆积。如果队列有堆积，查看 Process Time 指标，确定是否是某个 Processor 处理慢，如果是，根据指标中的 Tag 确定事件类型等属性特征，判断业务逻辑或者 Key 设置是否合理；全部 Processor 处理慢，可以通过增加 Processor 并行度来解决。如果队列无堆积，排除网络问题后，可以考虑增加 Consumer 并行度至 Topic Partition 上限。</p><p></p><p>消息重放被触发的原因通常有两种，要么是业务上需要重放部分数据做补全，要么是遇到了事故需要修复数据。为了应对这种需求，我们在框架层面支持了根据时间戳重置 Offset 的能力。具体操作时的步骤如下：</p><p></p><p>使用服务测暴露的 API，启动一台实例使用新的 Consumer GroupId: {newConsumerGroup} 从某个 startupTimestamp 开始消费更改全部配置中的 Consumer GroupId 为 {newConsumerGroup}分批重启所有实例</p><p></p><p></p><h2>总结</h2><p></p><p></p><p>为了解决 DataLeap 中 Data Catalog 系统消费近实时元数据变更的业务场景，我们自研了轻量级消息处理框架。当前该框架已在字节内部生产环境稳定运行超过 1 年，并支持了火山引擎上的数据地图服务的元数据同步场景，满足了团队需求。下一步会根据优先级排期支持 RocketMQ 等其他消息队列，并持续优化配置动态更新，监控报警，运维自动化等方面。</p><p></p>",
    "publish_time": "2022-10-17 12:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Power Platform 产品大更新，微软：以无代码、低代码方式全面支持企业数字化转型",
    "url": "https://www.infoq.cn/article/PPjm219eVKgsvIIPz4TP",
    "summary": "<p>近期，在微软年度技术大会 Ignite 2022 及 Ignite China 中国技术峰会上，<a href=\"https://www.infoq.cn/article/YxIvZSIsLrXioeW9MFvO\">微软</a>\"宣布对Power Platform平台进行了大量更新，包括新增了Express Design功能，用户可通过手绘设计草图、纸质表单、PPT、PDF以及<a href=\"https://www.infoq.cn/article/SDQwzl4iTDuU8F2quv49\">Figma</a>\"中的设计方案，在AI帮助下一键生成应用程序。</p><p>&nbsp;</p><p>Power Platform是微软推出的一款面向具备较少IT技能，或者非专业IT人员的低代码、无代码的应用开发平台，于2020年在中国正式商用。其核心组件有Power App、Power Automate、Power BI、Power Virtual Agents等。本次大会上，Power Platform 还迎来全新的成员——Power Pages，用户可以通过该产品以低代码开发方式快速构建自己的商业网站。</p><p>&nbsp;</p><p>根据微软大中华区商业应用事业部高级业务主管李威的介绍，Power Platform在中国发布至今，其遵循了微软在中国市场的发展策略：支持中国企业全球拓展、支持跨国企业本土创新和聚焦战略生态。</p><p>&nbsp;</p><p>具体地，比如在进行全球拓展过程中，小米选择使用Power Platform来赋能后端技术团队。小米国际IT总监杨恩介绍，“IT全球合规、安全、高效的业务系统，是小米IT建设的首要目标。微软Power Apps基于分布在全球的Azure数据中心进行部署，天然继承了Azure数据中心在基础设施层面，在不同国家地区以及行业的80多项合规标准。我们在此基础上搭建系统，更便捷的满足了各国家不同的要求。”</p><p>&nbsp;</p><p>李威表示，微软一直基于对技术发展趋势的研判来演进Power Platform。与其他厂商聚焦在某个领域不同，Power Platform最大的特点是通过一个平台，以无代码、低代码的方式来支持企业数字化转型涉及到的方方面面，即在企业数字化转型的各个领域，Power Platform都有对应的产品给予支持，</p><p>&nbsp;</p><p>Power Platform 首先可以帮助企业在不同操作系统和设备上快速开发一款App；其次可以快速定义一个流程，让企业从一些简单、繁琐且重复的工作中解放出来；再者，可以形成一系列数据分析、数据洞察和数据报表；最后有自动化的机器人、helpdesk的自动化bot等等。</p><p>&nbsp;</p><p>结合对于整个发展趋势的研判，Power Platform也在以下方向不断发展：</p><p>&nbsp;</p><p>在AI领域，Power Automate之前可以用一种图形化拖拉拽的方式定义一个流程，而无需代码开发。现在，业务人员可以用自然语言描述一个流程，然后平台通过机器学习的方式理解这些话术，然后将其快速、自动地形成一个流程。在融合开发方面，Power Platform不只要满足不具备开发技能的业务人员的开发需求，而是希望大家能够在一起共同开发，且不会互相干扰。超级<a href=\"https://www.infoq.cn/article/Vyg6CQgbtTu9SKbuk9oX\">自动化</a>\"方面，Power Platform的目标是将企业至少50%的人，通过低代码、无代码的方式解放出来，去做更多的创新工作。可管控上，对于访问权限等问题，Power Platform最新发布了Managed&nbsp;Environments等能力，帮助企业IT部门做好安全和管控。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;</p><p>微软&nbsp;Power Platform 全球黑带技术专家Frank&nbsp;Yang表示，大家要明确低代码开发技术和低代码开发平台的区别。</p><p>&nbsp;</p><p>“Power Platform实际上是低代码的平台，不只是技术，它是技术加上平台的应用。它的好处就是不但能够帮助业务人员解决问题，还能解决开发人员的问题，背后的关键是能帮助企业快速实现数字化转型。数字化转型绝不只是靠开发人员或者只靠业务人员实现的，需要两方都做出改变。这也是最近大家讲得最多的Biz DevOps，即业务人员引领的DevOps场景。”Frank&nbsp;Yang说道。</p><p>&nbsp;</p><p>Frank Yang表示，越来越多的企业意识到了低代码平台带来的业务价值。</p><p>&nbsp;</p><p>“我们经常听到客户的一个想法就是，开发人员成本足够低的话是不会用低代码的。实际上，并不存在这样的事情。”Frank Yang说道，“最大的Power Platform 用户其实是印度的客户，而印度实际上是全球开发人员成本最低的地方，印度的很多企业就是使用Power Platform去做开发的。”</p><p>&nbsp;</p><p>Frank Yang表示，过去一段时间内，国内都专注在了对低代码技术本身的讨论上，但技术本身并没有错，可以用在业务系统人员身上，也可以用在开发人员身上。从技术角度来讲，低代码技术是不会替代传统高代码方式的，因为两者解决的是不同的问题，但低代码平台会对传统开发方式产生深远影响。</p>",
    "publish_time": "2022-10-17 13:57:21",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "为躲亲戚催婚，一摄影师创造出了AI女友",
    "url": "https://www.infoq.cn/article/r3HIrXYNuuP6Tp8F8XrV",
    "summary": "<p></p><p></p><blockquote>如何优雅地拒绝亲戚催婚，AI来支招了。</blockquote><p></p><p></p><p>来自<a href=\"https://www.youtube.com/c/PiXimperfect/featured\">PiXimperfect</a>\"的摄影师Unmesh&nbsp;Dinda创建出纯AI生成的女友，再次展示了AI强大的照片编辑能力。</p><p></p><p>近日，Dinda发布了一对情侣在假期闪逛时的多张自拍，其中的光影效果极其逼真，与照片背景完美契合。但请注意：照片中的Dinda是真人，女友则是由AI模型一手创造出来的。</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/04/0c/0490a2572329fcc6e8b6bf7df94bd10c.png\" /></p><p></p><p>Dinda在自己的YouTube视频中提到，“如果你身边也有一堆催婚的亲戚，那就给他们发张这样的照片。这应该能让他们消停一阵子。”</p><p></p><h2>创建AI女友</h2><p></p><p>上个月，DALL-E决定解除禁令，允许用户编辑带有人脸的图像。</p><p></p><p>经营照片编辑YouTube频道的Dinda把握时机，上传了他拍下的几张自拍照，而后使用图像修复功能擦除照片中的特定部分，再输入文本提示引导DALL-E填充空白区域。</p><p></p><p>在删除了照片上对应女伴的区域之后，Dinda输入“和女友在一起的男性”，这样DALL-E就能生成一对生动鲜活的情侣。</p><p></p><p>在选定AI女友之后，Dinda又使用外画功能将照片延伸到原始边界之外。</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/85/7e/85af8a0d432f86347b50a65a2cb2e37e.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/ac/77/ac1f4acfd75bd054917bb3602bf1a577.png\" /></p><p></p><p>DALL-E等AI图像生成器其实还不足以生成完美可信的人脸，所以Dinda把这里的“女友脸”裁剪并导入另一款名为GFP-GAN的AI照片编辑程序中。该程序在女性面部润色方面更加强大。完成细节补充之后，他又把照片加载至Photoshop中并在原始图像上对齐，最终创造出了令人真假难辨的AI合成女友。</p><p></p><h2>加人可以，删人也行</h2><p></p><p>Dinda还演示了如何通过同一技术，借AI照片编辑器之手删除人物。通过对所要删除的人物进行修复和替换，DALL-E完全能够在复杂的图像和背景中绘制出比较自然的填充部分。</p><p></p><p>对于需要花费大量时间从照片中移除复杂物体或人物的摄影师们来说，这项技术无疑令人兴奋。</p><p></p><p>AI工具还能添加特定人类特征，例如头发。Dinda就演示了如何为巨石强森加上头发，DALL-E甚至还为不同发型匹配了相应的阴影。</p><p></p><p>关于Dinda的更多作品，请参阅其YouTube（<a href=\"https://www.youtube.com/c/PiXimperfect/featured\">https://www.youtube.com/c/PiXimperfect/featured</a>\"）、Instagram（<a href=\"https://www.instagram.com/piximperfect/\">https://www.instagram.com/piximperfect/</a>\"）和网站（<a href=\"https://www.piximperfect.com/\">https://www.piximperfect.com/</a>\"）。</p><p></p><h2>AI图像生成器DALL-E，现已允许用户编辑人脸</h2><p></p><p></p><p>作为AI图像生成器DALL-E的缔造者，OpenAI公司在今年9月20日<a href=\"https://petapixel.com/2022/09/20/ai-image-generator-dall-e-now-allows-users-to-edit-human-faces/\">宣布</a>\"将允许用户编辑包含人脸的照片。</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/97/71/9779fdaf5f06ac3a031a99d464b2bd71.png\" /></p><p></p><p>此前，DALL-E一直禁止用户生成包含真实人脸的图像，以避免模型被滥用于创建deepfakes。</p><p></p><p>但如今OpenAI公司表示已经“改进了安全系统”，并结合用户提交的功能需求反馈而准备开放人脸编辑。</p><p></p><p>OpenAI公司在一份声明中表示，“很多用户告诉我们，他们想要使用DALL-E为自己设计服装、发型，并编辑全家福照片的背景。”</p><p></p><p>“一位整形外科医生告诉我们，他一直使用DALL-E帮患者们查看可视化结果。也有电影制作人告诉我们，他们希望能用DALL-E编辑场景图像，借此加快创作速度。”</p><p></p><p>OpenAI也对自己做出了明确定义 —— 一款比Midjourney或者Stable Diffusion等竞争对手更具品牌友好性的AI图像生成器。这里顺带一提，Stable Diffusion可谓反行业主流而行，在开放功能的同时几乎不加任何安全过滤限制。</p><p></p><p>“我们的过滤器更善于防止生成关于性、政治和暴力方面的内容，努力减少错误标记，同时配合新的检测与响应技术以阻止滥用。”</p><p></p><p>目前DALL-E仍只对受邀用户开放，使用者可以上传自己的照片，借此编辑照片或要求AI为其生成图像变体。</p><p></p><p>值得一提的是，DALL-E的内容政策仍然禁止用户上传未经授权的人物图像，但还不清楚这项管控要如何具体实现。</p><p></p><p>OpenAI得到了微软及多家大型风险投资公司的支持。在目前的早期文本到图像生成器中，DALL-E对于法律和道德问题的关注度明显比<a href=\"https://www.infoq.cn/article/MYYhWiSNPaAQIGfZywa0\">Stable Diffusion</a>\"更高，也因此成为应用广泛的主流模型选项。</p><p></p><p>但一旦落入错误的人手中，这种强大的技术足以为外行创造出真假难辨的deepfakes，进而冲击整个社会的信任结构甚至是正常运转。</p><p></p><p>参考文章：</p><p></p><p><a href=\"https://petapixel.com/2022/10/14/photographer-creates-ai-girlfriend-to-stave-off-nosy-relatives/\">https://petapixel.com/2022/10/14/photographer-creates-ai-girlfriend-to-stave-off-nosy-relatives/</a>\"</p><p></p><p><a href=\"https://petapixel.com/2022/09/20/ai-image-generator-dall-e-now-allows-users-to-edit-human-faces/\">https://petapixel.com/2022/09/20/ai-image-generator-dall-e-now-allows-users-to-edit-human-faces/</a>\"</p><p></p>",
    "publish_time": "2022-10-17 14:11:18",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "以产品当笔，与你对话，PCon 全球产品创新大会 2022 启动",
    "url": "https://www.infoq.cn/article/sCglQEgF4y7825WbSCiY",
    "summary": "<p>受到疫情的影响，在今年8月份，我们落地了筹备两年的<a href=\"https://pcon.infoq.cn/2022/beijing/schedule\">PCon全球产品创新大会</a>\"，邀请了来自Google、阿里、Microsoft、腾讯、字节等企业的专家。讲师们将从实践出发，帮助产品管理者、产品设计者、运营者提供新思路，并确立产品接下来的发展方向。经过两天的沉浸式会议之后，很多听众觉得意犹未尽，我们也觉得可以提供更多精彩内容。经过InfoQ组委会的慎重考量，我们决定在2022年12月2-3日，举办 PCon 全球产品创新大会2022（北京站）。</p><p>&nbsp;</p><p>本次PCon产品创新大会的主题是“以产品当笔，与世界对话”。看过《俞军产品方法论》的伙伴应该对这句话比较熟悉。我们以前经常听到说产品经理要改变世界，现在已经很少听到这句话了，产品经理改变不了世界，我们只能通过产品来与表达自己，与世界沟通。</p><p>&nbsp;</p><p>从本质上看，PCon产品大会也是一个产品。而会议编辑是这个会议的生产者，也属于“产品经理”，我们也需要搜集用户需求、设计产品功能、优化用户体验等等，进行产品开发。</p><p></p><h5>搜集听众需求</h5><p></p><p></p><p>在收集用户产品需求之时，我们发现 B端产品以及技术产品从业者占比较高。他们都关注以下几类问题。首先，ToB产品如何规划，其商业模式与C端的差异；其次，B端产品经理如何进行能力提升，如何做到快速升职加薪；当然，部分听众也在关注如何进行产品商业化；最后是互联网产品经理与传统项目管理结合之处有哪些等等。除此之外，也有小部分C端产品经理、AI产品经理，他们普遍关注产品创新、以及个人成长。</p><p>&nbsp;</p><p>除此之外，在首届 PCon 落地之后，我们收到了近200条反馈建议，大约分为以下几类。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5b/5b43894193747d546329f1c5d1de8688.png\" /></p><p></p><p>用户在哪里，我们就去哪里，这些需求是我们“会议产品”需要满足的需求。不过会议整个的专题内容不仅仅来源于用户方，还来源于专家方面。</p><p></p><h5>设计产品功能</h5><p></p><p></p><p>为了策划整个大会专题，我们召开了 <a href=\"https://www.infoq.cn/article/pWej6Pvfv2XzIWqXHB00\">PCon 专题研讨会</a>\"，大家也给出了相当多的策划建议，这里仅做部分展示。</p><p>&nbsp;</p><p>首先，我们可以从产品经理能力模型的角度，来谈谈怎么度过职业瓶颈期、如何提升思维格局，如何从更长的周期看产品经理的关注点、如何具备同理心、如何具备风险意识等等。</p><p>&nbsp;</p><p>其次，ToB 产品的供应商与客户之间存在着天然的对抗性，供应商想要产品化，客户却想要定制化，这个矛盾如何平衡？另外在 ToC 增量见顶情况下，更多的企业在考虑 ToB 的市场。在这种情况下，供应商如何通过产品与服务来为客户解决问题？</p><p>&nbsp;</p><p>最后，统计学、行为学、经济学、心理学对于产品的设计不可或缺，这也是大多数产品经理比较关注的高阶内容，可以邀请一些社会科学研究院的专家，来分享他们的调研结果和经验总结。</p><p>&nbsp;</p><p>综合用户与专家的建议，我们策划了B端产品设计、产品创新实践、产品运营与增长、前沿产品设计、产品商业化探索、产业互联网产品实践、科学研究与产品设计、产品经理职业发展、产品经理的影响力打造等九大专题。</p><p></p><h5>优化用户体验</h5><p></p><p>就听众参会的体验而言，从购票、入场、到聆听分享，以及交流的每一环节都需要精心规划。例如听众购票，购票之时，我们能否将会议参会指南准确告知；在听众入场之后，会议现场是否拥挤？可否获得讲师的联系方式？如何获得？讲师PPT是否准备齐全等等内容都是需要我们考虑的问题。</p><p>&nbsp;</p><p>当然，这其中最重要的一环是讲师的演讲分享，为了参会者有良好的体验。我们大会设立了联席主席、出品人等专家；联席主席为专题策划出谋划策；出品人为专题内容分享严苛把关，从拿到初步议题、撰写 PPT、PPT试讲、现场分享等等全环节，我们都加入了专家评估，以此来生产专业的内容。目前，我们已邀请到一位联席主席，以及五位专题出品人，更多嘉宾持续上线中...</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/11/114493fad965f6df2d6544a9d67be528.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c1/c12d9e79b4894db27c07ea85eec14f99.png\" /></p><p></p><h5>结语</h5><p></p><p>正如 PCon 大会主题——“以产品当笔，与世界对话”，我们想通过会议产品，与你对话。如果这些内容是你所关心的，欢迎来现场交流。此外，如果你有想要分享的产品新知，欢迎向我们提交议题申请，可直接提交至<a href=\"https://pcon.infoq.cn/202212/beijing/topic\">PCon会议官网</a>\"。</p><p>&nbsp;</p><p>目前大会 8 折报名优惠阶段，有兴趣的同学欢迎联系票务小姐姐：+86 18514549229（微信同号）。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/04/0445a7f609b74c34e7f925736be7590b.jpeg\" /></p><p></p>",
    "publish_time": "2022-10-17 16:15:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何利用现代化数据栈高效处理地理信息数据",
    "url": "https://www.infoq.cn/article/Iw6S64kGg7KBpgDyLaoW",
    "summary": "<p></p><h2>背景知识</h2><p></p><p></p><h3>什么是地理信息数据</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a5/a5f541299f4b88f550d7dd866e63cb1f\" /></p><p></p><p>地理信息数据的定义主要来自于我们熟知的星球——地球。我们知道地球表面是一个凸凹不平的表面，是一个近似的椭球体。以海平面为参照已知最点和最低点之间有接近 2 万米的差距。</p><p></p><p>珠穆朗玛峰，8848.86 米含冰层（人民日报：2020 年 12 月 8 日）马里亚纳海沟，相对海平面深 10909 米（人民日报：2020 年 11 月 30 日）</p><p></p><p>即便是海平面也会在月球潮汐引力的作用下变化着，更不要提气候变化导致的海平面升高。因此要想找到一个确切的数学模型来表示地球还是挺困难的一件事。</p><p></p><p>于是人们以北极南极为两个定点，将地球按照这个轴线进行旋转。地球在这个旋转形态的下就会呈现一个椭球体的形态，这个就是理想的地球椭球体。这个椭球体就可以利用数学模型来进行表示。</p><p></p><p>正是基于这样一个共识，在 1975 年国际大地测量与地球物理联合会推荐下地球椭球体的模型数据被推荐为：半长径 6378140 米，半短径 6356755 米，扁率 1∶298.257，后续该数值有一些修正。</p><p></p><p>基于这些精准的测量数据，我们可以通过数学表示来定义地球上所有的点，从而利用现代化的定位技术我们可以精确定位地球上所有的位置。</p><p></p><h2>定位技术</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/db/dbfc6d07746d6014c1a2185aa6382c67\" /></p><p></p><p>在地球上要想知道我们精确位置可以使用导航软件，导航软件的正常工作需要依赖全球定位系统。目前世界上共有四大导航系统，分别是</p><p></p><p>中国的 北斗美国的 GPS欧盟的 伽利略俄罗斯的 格洛纳斯</p><p></p><p>这些定位系统最主要的部分是人造卫星，它们按照固定的规律围绕地球运转，其中有一些是运行在圆形的地球同步轨道上。</p><p></p><p>由于每个卫星和我们的距离不同，因此它们同一时刻发送的信标会在微弱的时间上先后抵达我们的设备上。这样我们就有了带有延迟的信标信号，每一个延迟是可以被看作是一个距离。</p><p></p><p>我们事先知道每一个卫星的确切位置，再加上这些距离信息。当我们得到最少 3 个信号之后就可以利用著名的三角定位法得到我们的准确位置，这也是所有卫星定位技术使用的核心原理。</p><p></p><h2>空间数据</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/64/64ce2d209482a5133d7d1df4dd2b7270\" /></p><p></p><p>现有空间数据库标准主要有如下两套，两套标准之间大体是相互兼容的。</p><p></p><p>• Simple Feature Access SQL，简称 SFA SQL：SFA SQL 是 开放地理空间信息联盟（Open Geospatial Consortium，简称 OGC）制定的标准。</p><p></p><p>• SQL Multimedia Part3: Spatial，简称 SQL/MM：SQL/MM 是 国际标准化组织（International Standard Organization，简称 ISO）制定的标准。</p><p></p><p>通过空间数据的描述我们可以定义一个具体的几何体。在这两种标准中公共的部分中都定义了下面 3 组共 6 个基础类型，这些是经常用到的类型。</p><p></p><p>• 点、多个点</p><p></p><p>• 线、多个线</p><p></p><p>• 多边形、多个多边形</p><p></p><p>为了方便存储和使用这些数据 OGC 组织通过 OpenGIS 规范定了两种具体格式</p><p></p><p>• Well-Known Text (WKT) format</p><p></p><p>• Well-Known Binary (WKB) format</p><p></p><p>WKB/WKT 都只是通过标记语言描述点、线、面 的几何体数据，当用于几何计算时一般不需要坐标系。但是当数据需要展示在地图上时则需要将其原始的空间数据投射到大地坐标系上（这个过程称为投影）才可以得到这个几何图形具体的地理坐标。</p><p></p><h4>空间引用识别号 (SRID)</h4><p></p><p></p><p>要将几何图形投影到坐标系，必须需要使用 SRID。SRID 可以理解为唯一标识了将某个几何体空间数据映射成某个具体坐标系中的方式。</p><p></p><p>当 SRID 为 0 或者不使用 SRID 时，表示一个几何图形实例没有被放到任何一个坐标系中，我们无法定位其位置。例如通过长宽高的具体值我们可以知道一个正方体的形状，但是我们没法知道他的具体坐标。</p><p></p><p>不同 SRID 值代表了将几何体映射到坐标系中的不同方式。几何体本身的空间数据结合 SRID 就可以具体定位这个几何体在坐标系中的位置。</p><p></p><p>下图简单演示了有无 SRID 得差异。像欧洲石油测绘组 (EPSG) 定义的 SRID 是根据地球地理信息构建的坐标系，几何图形根据几何体空间数据以及 EPSG 标准的 SRID 值可以转成真实的地理坐标。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/0c/0c92f8d0262d8cb9a46d6f7fa41f808b\" /></p><p></p><p>目前有多种公认的标准 SRID，例如欧洲石油测绘组 (EPSG) 定义的 SRID。不同数据库对于不同 SRID 标准的适配性也不同。</p><p></p><p>某些数据库和空间类型（如 PostgreSQL 中的 PostGIS 几何和地理或 Microsoft SQL Server 中的地理类型）使用预定义的 EPSG 代码子集，只可使用具有这些 SRID 的空间参考。</p><p></p><p>如今编制 SIRD 的工作已经转交给了国际石油和天然气生产商协会 (OGP) 的手中，要想了解更多的 EPSG 信息，可以访问 <a href=\"https://epsg.io/\">https://epsg.io/</a>\"</p><p></p><h4>常见 SRID 标准与地理坐标系</h4><p></p><p></p><p>在中国常用的坐标系有下面四个</p><p></p><p>• WGS84：美国 GPS 系统上使用的坐标系。</p><p></p><p>• GCJ02：由中国国家测绘局制定的地理坐标系统。</p><p></p><p>• BD09：百度地图所使用的坐标系，它是建立在 GCJ02 坐标系之上。</p><p></p><p>• CGCS2000：中国北斗系统所使用的坐标系。</p><p></p><h3>大地坐标系与地图绘制</h3><p></p><p></p><h4>地图绘制的基本步骤</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7d/7da47b7498696f0cd9201275092698ea\" /></p><p></p><p>绘制地图构建大地坐标系主要会采用以下步骤：</p><p></p><p>首先会选择一个基准点，所有的地形数据都是基于这个基准点的进行绘制。而这个点也正是位于地球椭球体上的一个点。地球椭球体可以充当画布，测绘员则可以在画布上勾勒出具体的街道和地形信息。从而形成最终的地图数据供我们使用。基于定位的点和地图的基准点的之间的偏差就可以完成整个定位到地图的转换这个过程就是坐标个定位到地图的转换这个过程就是坐标系转换。当然实际的过程要更为复杂一些，甚至会有多次偏差修正。</p><p></p><h3>存储地理信息</h3><p></p><p></p><p>目前主流关系型数据库对地理信息基本都都有支持，其中最常用的类型便是geometry类型。在 Oracle 数据库中对应为&nbsp;sdo_geometry 类型。</p><p></p><p>还有其它的几何类型，例如：Point、Polygon、MultiPoint、MultiPolygon 等等，介于篇幅的原因本文内容只针对 geometry 类型。</p><p></p><p>有兴趣深入了解的朋友可以根据下方表格自行深入研究，本文不做过多展开。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/45/459168fbd0b15ddc45dc3739a5171eba.png\" /></p><p></p><p>不同的数据库由于存储和查询引擎的不同，针对地理信息的存储会有一些差异。这些差异主要是因为单纯的 WKB 并不能满足实际需求，最直接的问题就是 WKB 只考虑的几何图形的空间数据存储，但是并未涉及大地坐标系相关的信息。</p><p></p><p>比如在 MySQL 中地理信息数据将会在 WKB 数据前额外增加 4 个字节用于存放其对应的 SRID。而 PostgreSQL 用了更加高级的 EWKB 格式作为地理信息数据的存储格式。</p><p></p><p>因此如果想要以二进制方式直接从数据库中获取地理信息数据，了解正确的获取方式十分必要。</p><p></p><h2>地理信息数据应用的问题</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5d/5dee1b60ac1c0b6d952e68b765846322\" /></p><p></p><p>我们会从一个具体案例来和大家探讨地理信息数据应用中会遇到的实际问题。我们这个地理数据应用案例如下：</p><p></p><p></p><blockquote>如何知道地球上一块土地在一段时间内的使用情况？</blockquote><p></p><p></p><p>为了达成这个目的，我们将会不得不面临如下的一些挑战：</p><p></p><h3>数据量大</h3><p></p><p></p><p>首先土地的使用是随着时间变化而变化的，比如：</p><p></p><p>• 在一些时间内这些用地可能是耕地，另外一些时间可能是用作林地。</p><p></p><p>• 随着时间推移一块土地可能会被切割成个地块，或者合并成一个更大的地块。</p><p></p><p>因此每年获取的地图数据都只是当年最新的情况，地块数据也是不停地变化的。</p><p></p><p>基于这样一个情况，若想要知道一个时间跨度下的地块变化。通常会涵盖不同时间的地图数据。若地图数据是 1G 大小，如果要计算 10 年的变化就需要处理 10G 的历史地图数据。</p><p></p><h3>计算量大</h3><p></p><p></p><p>对于地图数据中还会含有很多其它结构化数据，比如：小区、门牌号、餐馆名称，地块通途以及交通道路等等信息。因此在基于业务查询需要会先进行业务维度上的数据查询和筛选。</p><p></p><p>写过业务逻辑的朋友都知道，复杂的业务查询很可能会涉及到几张表的联查操作。在加上我们还需要通过 GIS 函数进行几何图形的交并计算。这就会引发下面两个问题</p><p></p><p>• 大量的地理的几何信息、标注信息引发出大表的 Join 性能问题。</p><p></p><p>• 由于 GIS 的函数计算引发的大量计算</p><p></p><h3>没有万能的数据库</h3><p></p><p></p><p>现在主流的对地理信息存储比较友好的数据库主要是 PostgreSQL、Oracle 和 SQLServer。像 PostgreSQL 对地理信息数据处理的生态工具也比较友好，例如：</p><p></p><p>• PostgreSQL 对 GeoServer、MapServer、ArcGISServer 几个地图服务中间件的支持性比较好。</p><p></p><p>• PostgreSQL 对 PostGIS 的支持兼容性要比 Greenplum 好</p><p></p><p>这些传统数据库并不能解决所有问题，尤其是面临千万级别的 GIS 表时，表的 Join 查询又会面临严重的问题。</p><p></p><p>幸运的是，近几年新型和强力的 OLAP 分析型数据库不断出现，地理信息数据的处理和分析可以结合这些新型分析引擎大大提升地理信息数据处理的效率。</p><p></p><h2>高效处理地理信息数据的现代化数据栈</h2><p></p><p></p><p>以下现代化数据栈的方案来自于 CloudCanal 用户的一个真实案例。该用户原有方案是基于 PostgreSQL 进行地理信息数据的查询和处理。</p><p></p><p>通过 CloudCanal 数据互通，采用如下现代化的数据栈，轻松整合了 ClickHouse 强大的分析能力和 ElasticSearch 的强大全文索引能力来处理地理信息数据，大大提升了地理信息数据处理的效率。</p><p></p><h4>数据栈架构图</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/cb/cbf2d719bd5a7b96fc8042234639c14d\" /></p><p></p><p>以上架构图展示了整个地理信息数据的流向以及处理过程：</p><p></p><p>PostgreSQL 对地理信息存储和处理比较友好，业务应用先将产生的地理信息数据全部写入到 PostgreSQL 中利用 CloudCanal 在异构数据源之间迁移和同步地理信息数据，自动化地转化地理信息数据写入新型的数据源中利用 ClickHouse 强大的分析能力来高效处理地理信息数据海量地理信息数据的聚合、join 分析操作应用利用 ClickHouse 强大的分析能力先进行数据初筛，生成数据量较小的有效数据，直接对数据规模较小的地理信息数据使用 JTS 工具进行二次几何函数计算然后生成最终处理结果</p><p></p><p>4.&nbsp; 利用 ElasticSearch 强大的全文索引能力，应用可以直接对 ElasticSearch 中存储的地理信息数据进行全文检索</p><p></p><p>可以看到采用 CloudCanal 以后得现代化数据栈处理地理信息数据具有如下好处：</p><p></p><p>可以应对复杂的业务查询需要，针对业务选用不同的新型数据库提升效率。应用可以直接使用分析引擎过滤出来的较小数据规模的地理信息数据进行几何函数计算，大大提升效率。</p><p></p><h2>CloudCanal 中对于地理信息数据友好兼容</h2><p></p><p></p><h3>表结构迁移</h3><p></p><p></p><p>在使用 PostgreSQL 作为主库，ClickHouse 作为分析库的时候。第一个问题就是 ClickHouse 的建表，在没有 CloudCanal 工具，建表比较痛苦，使用 CloudCanal ，这个过程就会相当便利。</p><p></p><p>PostgreSQL 没有类似 MySQL show create table 的语句可以方便的获取到原始建表语句让我们参照，因此需要一张表一张表的去创建。ClickHouse 的表字端类型和 PostgreSQL 的字端类型并不一致，还需要了解它们做针对的映射和转换。</p><p></p><p>即便是在 PostgreSQL 和 PostgreSQL 之间进行数据同步，还需要考虑一些问题</p><p></p><p>带有 SRID 的 PostgreSQL 表结构迁移</p><p></p><p>这些问题通过使用 CloudCanal 解决，它会自动识别表的字段类型并且映射到适合的列上，这样就省了不少学习了解新数据库的时间。</p><p></p><p>同样 CloudCanal 就像 PostgreSQL 一样对 GIS 特性支持比较完整，它能够准确处理带有 SRID 的 PostgreSQL 表结构。如下表。</p><p></p><p><code lang=\"null\">CREATE TABLE \"city\"(    \"ogc_fid\"    int4 NOT NULL,    \"mssm\"       varchar(16),    \"bz\"         varchar(16),    \"provincen\"  varchar(50),    \"provincec\"  varchar(50),    \"cityn\"      varchar(50),    \"cityc\"      varchar(50),    \"shape_leng\" float4,    \"shape_area\" float4,    \"geom\"       geometry(geometry,4490) -- 带有 SRID 的列);\n</code></p><p></p><h3>数据迁移</h3><p></p><p></p><p>CloudCanal 支持将用户源端数据库中的地理信息相关数据完整迁移到对端异构数据源，并且支持断点续传。</p><p></p><p>在地理信息数据的迁移上，CloudCanal 做了不少工作。当源端数据库是 PostgreSQL 时。全量数据同步过程会识别到表上的 SRID 信息，并将 PostgreSQL 使用 EWKB 格式转换为标准的 WKT 连同 SRID 一同作为最终数据。</p><p></p><p>当对端是 ClickHouse 的时候我们可以得到完整的 GIS 地理信息数据以及对应的坐标系 SRID，在程序中可以进一步处理。当对端是 PostgreSQL 时也可以完整的将地理信息和坐标系同步到对端。</p><p></p><h3>自定义处理</h3><p></p><p></p><p>在地理信息数据从源端数据库迁移 / 同步到对端数据库过程中，通过 CloudCanal 自定义代码功能可以做一些非常灵活的加工操作。</p><p></p><p>用户可以自己实现自定义代码，在数据同步过程中针对每一条数据做一些额外的处理。比如：</p><p></p><p>在处理 GIS 的应用中经常会用到求外切，得到几何图形的最大矩形区域。然后将这个矩形区域存储在一个新的字段中求 GIS 数据几何图形的中心点提前裁剪数据，将清洗好、裁剪好的规整数据写入对端新型数据库</p><p></p><h3>长周期的实时地理信息数据同步</h3><p></p><p></p><p>CloudCanal 不仅支持历史数据的迁移同时还支持异构数据源之间的实时数据同步。实时的地理信息数据同步能够加强企业在某些业务领域的竞争力。</p><p></p><p>在实时同步时，用户最关心的自然是长周期实时同步的稳定性。</p><p></p><p>在实际情况中为了保障业务运行中对于实时数据同步的稳定性 CloudCanal 采用了多种方式来实现。</p><p></p><p>• 完全分布式：核心组件均支持分布式部署，避免单点故障</p><p></p><p>• 容灾自动恢复：如果运行实时同步任务的机器 Crash，CloudCanal 会自动迁移这台机器上的实时同步任务到别的可用的机器继续实时化的同步</p><p></p><p>• 实时同步断点续传：CloudCanal 针对各种数据库源端类型都有设计专门的位点管理。当因故障产生任务重启，任务会在上一次中断的地方继续开始同步，避免数据丢失。</p><p></p><h2>总结</h2><p></p><p></p><p>在本文最初我们比较简略的介绍了地理信息数据相关的背景知识，文章后半段我们探讨了如何利用现代化的数据栈高效处理地理信息数据。</p><p></p><p>如果您觉得文章对您有帮助，请帮忙转发分享，也期待大家多多关注和使用 CloudCanal，到 ClouGence 官网 <a href=\"https://www.clougence.com/\">https://www.clougence.com</a>\" 即可下载体验。</p><p></p><p>参考资料</p><p></p><p>北斗卫星导航系统公开服务性能规范 1.0 版“奋斗者”号全海深载人潜水器顺利完成万米深潜试验北斗卫星导航系统 公开服务性能规范高精度地图（一）——地理坐标系The Home of Location Technology Innovation and CollaborationMYSQL 8.0 中存储 GIS 数据的正确姿势</p><p></p>",
    "publish_time": "2022-10-17 16:56:39",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "对话EDB创始人：在开源软件上搞商业化，先别想着回报",
    "url": "https://www.infoq.cn/article/0q2w0lagEt233YlVr9Dj",
    "summary": "<p>Postgre的实现始于1986 年。第一个“演示性”系统在 1987 年便可使用了， 并且在 1988 年的ACM-SIGMOD大会上展出。</p><p>&nbsp;</p><p>1989 年6月，Postgre版本1正式发布，并开放给一些外部的用户使用。 为了回应用户对第一个规则系统的批评，1990年6月，使用了新规则系统的Postgre版本 2正式发布。</p><p>&nbsp;</p><p>Postgre版本 3 在1991年出现，增加了多存储管理器的支持， 并且改进了查询执行器、重写了规则系统。为了避免占用过多的研究实践，伯克利的Postgres项目在版本 4.2 时正式终止。</p><p>&nbsp;</p><p>在 1994 年，Andrew Yu 和 Jolly Chen 向Postgres中增加了 SQL 语言的解释器，并随后用新名字“Postgres95”将源代码发布到互联网上供大家使用，成为最初Postgres伯克利代码的开源继承者。</p><p>&nbsp;</p><p>到了1996年，很明显“Postgres95”这个名字已经跟不上时代了。于是伯克利Postgres项目选择了一个新名字<a href=\"https://mp.weixin.qq.com/s?__biz=MzIzNjUxMzk2NQ==&amp;mid=2247523042&amp;idx=1&amp;sn=20cd17ce5a993ab4858830ea02e070e3&amp;chksm=e8d46520dfa3ec36b28612a2de92f86a02a6de477554c333f8efceb515bf6aeeda9d0d4206a9&amp;scene=27#wechat_redirect\">PostgreSQL</a>\"来反映与最初的Postgres和最新的具有SQL能力的版本之间的关系。</p><p>&nbsp;</p><p>同时版本号也从 6.0 开始，将版本号放回到最初由伯克利Postgres项目开始的序列中。这就是我们现在看到的PostgreSQL系列。</p><p>&nbsp;</p><p>目前，PostgreSQL已经发展成了全球最受欢迎的<a href=\"https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247563974&amp;idx=1&amp;sn=28120c5106faf4a0add8ad9ff9f164e8&amp;chksm=fbeb4309cc9cca1fda03ea2fde15d0105441faa63a7db4e59df49cb25be7f2a3261e750653c4&amp;scene=27#wechat_redirect\">开源数据库</a>\"之一。PostgreSQL和<a href=\"https://www.infoq.cn/article/3xtSDtHUgTKRsyw3kZXH\">MySQL</a>\"这两个领先的开源关系型数据库的使用率分别是46.5%和45.7%，而Oracle只有大约12%的开发者使用，DB2的使用率只有2%。专业开发者比那些正在学习编写代码的开发者更有可能使用 Redis、PostgreSQL、Microsoft SQL Server 和 Elasticsearch。</p><p>&nbsp;</p><p>由此可见，在全球开发者中，开源数据库的受欢迎程度远高于商业数据库。但开源数据库相较于商业软件也有着明显缺陷：支持性差、部署难度大、更容易发现漏洞、更易被攻击等。</p><p>&nbsp;</p><p>为了解决开源数据库存在的种种弊端，一些基于开源数据库的商业公司应运而生。</p><p>&nbsp;</p><p>但要想成功运营，也并非容易事。</p><p>&nbsp;</p><p>运营一家基于开源数据库的商业公司到底会面对哪些挑战？开源服务的价值是什么？Postgres和商业版本Postgres相比有哪些明显的优势？</p><p>&nbsp;</p><p>带着这些问题，我们采访了数据库平台提供商 EnterpriseDB （EDB）公司总裁兼CEO Ed Boyajian，请他来聊一聊全球数字化转型大背景下，PostgreSQL开源数据库及商业版本未来将走向何方？&nbsp;</p><p>&nbsp;</p><p>Ed在<a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651138672&amp;idx=1&amp;sn=22a4495af1ff90c5590bc4e313a09230&amp;chksm=bdb8d2238acf5b354a48c9ff9c170235832de8bf23b998f34a7457cc9539a5d32d0045f5ee0b&amp;scene=27#wechat_redirect\">数据库</a>\"领域深耕多年，为EDB公司制定出并引导执行一系列增长策略。Ed曾在Red Hat效力6年并晋升为北美副总裁兼总经理，随后于2008年加入EDB。依托于强大的核心领导能力，他将开源精神引入企业的现代商业模式。在<a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651058618&amp;idx=4&amp;sn=845c858d1619d0ce0a259e708a3dbf25&amp;chksm=bdbe09e98ac980ff8a6eaa305eff355dcd2cfff814281eb5b3611f6ee2c5b98545eb23bdf7c3&amp;scene=27#wechat_redirect\">Red Hat</a>\"任职期间，他曾担任OEM业务副总裁，负责管理惠普、IBM及戴尔等Linux客户的合作伙伴关系。</p><p>&nbsp;</p><p>作为参与开源软件运动15年以上的资深专家，Ed也是一位经验丰富的企业软件主管。在他看来，EDB首先需要优先关注技术，之后才有资格领导<a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651135452&amp;idx=3&amp;sn=214aa6a0a782ec83f02471f585f0bb96&amp;chksm=bdb8e58f8acf6c99af79556577750b72a2bda0c9d06ed30db5a8c1ab504284db85c4f637d892&amp;scene=27#wechat_redirect\">开源数据管理</a>\"生态系统。他坚信伟大的技术高于一切，正是凭借这样的信念，他推动着EDB一路走到今天。</p><p>&nbsp;</p><p>Ed还坚信在开源和商业软件/硬件生态系统中建立投资合作伙伴关系的重要性。Ed曾任美国陆军上尉，并接受过空降兵训练。在EDB公司，他指导并鼓励每一位员工磨练自己的领导技能。Ed总是有着不竭的热情、充沛的精力和出色的战略领导力。</p><p></p><p>以下为InfoQ与Ed Boyajian的访谈实录，经编辑。</p><p></p><h2>技术管理者如何保持对技术的前瞻性？</h2><p></p><p>&nbsp;</p><p></p><blockquote>InfoQ：您在数据库领域深耕多年，是否遇到过一些技术挑战？</blockquote><p></p><p>&nbsp;</p><p>Ed Boyajian：在我们看来没有真正的挑战，所谓挑战只是机遇的另一种形态。</p><p>&nbsp;</p><p>PostgresSQL的普及还面临着很多非技术挑战，主要是意识、员工教育和培训。总之，就是需要企业高管进行变革引导、发挥领导能力的各个领域。</p><p>&nbsp;</p><p>我们的全托管云产品BigAnimal就是专为解决现有云Postgres产品所面临的挑战而生。大型企业需要一定的透明度和性能保障，才能放心把关键任务应用程序交由云端运行。为了满足需求，我们在云端建立起首个全托管的Postgre数据库，这意味着客户能够体验到与<a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651141163&amp;idx=5&amp;sn=662c6f536b7c2f518f41346a4c40975a&amp;chksm=bdb8cc788acf456ee297e26d09643f5cfaa154be850c98fe67fa5fbbbee29efd3f4e164ef1c9&amp;scene=27#wechat_redirect\">Oracle技术</a>\"原生兼容、极高的可用性和对数据库的精细控制。现在，客户已经可以跨多个云环境运行统一的PostgresSQL。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：最初，您对技术的兴趣从何而来？</blockquote><p></p><p>&nbsp;</p><p>Ed Boyajian：我一直想用科技简化日常生活。虽然我在九十年代末才进入软件行业，但之前出现的那些酷炫技术我可一个都没错过。80年代那会，我还买过原装的苹果Macintosh，它用鼠标就能完成图形操作的强大功能给我留下了深刻印象。从那一刻起，我知道生活将就此改变。这对我来说，也成为后来一切探索的起点。真希望我能好好留着那台Mac。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：技术一直在迅速发展，作为技术人员，您是怎么与最新技术保持同步的？</blockquote><p></p><p>&nbsp;</p><p>Ed Boyajian：我一直很敬重EDB那些才华横溢的技术伙伴们。我一直觉得自己是技术方面的“学徒”，所以我会虚心跟客户交流、关注宏观技术趋势，并结合这些背景与EDB的<a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651024374&amp;idx=2&amp;sn=0c7568d7f849cb742fa7bf25c475db0b&amp;chksm=bdbe93a58ac91ab35d9b4cd836d7735e8f6f76ba0c663a959b01dec844890cc663d33c91cd18&amp;scene=27#wechat_redirect\">PostgresSQL</a>\"技术主管们合作，再定期阅读期刊杂志。这些好习惯，让我始终都对未来保持着一定的了解。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：您在EDB担任管理岗位多年，您是如何吸引并挽留技术人才的？</blockquote><p></p><p>&nbsp;</p><p>Ed Boyajian：大家都希望能加入到具备市场影响力的企业当中。这种影响力始于在细分市场上的领导地位，而且会延伸到软件产品的领导地位。EDB在<a href=\"https://www.infoq.cn/article/HjI6CFadffGapdkk2qGQ\">Postgres数据库</a>\"这块细分市场上就具有领导地位。</p><p>&nbsp;</p><p>其次，人们都喜欢有亲和力的企业，喜欢那种会优先考虑团队福祉的公司。在拥挤的技术人才市场上，员工最需要的是个人的成长机会和接触新兴技术的可能性，EDB就能很好地满足这两个条件。根据我们最近的<a href=\"https://qcon.infoq.cn/2022/beijing/track/1294\">开源人才</a>\"调查，去年考虑辞去当前岗位、转而投身前沿技术的员工数量翻了一番。</p><p></p><h2>数据库产品众多，PostgreSQL有何不同？</h2><p></p><p>&nbsp;</p><p></p><blockquote>InfoQ：目前全球数据库市场上几百款数据库产品，您认为PostgreSQL为什么能取得成功？</blockquote><p></p><p>&nbsp;</p><p>Ed Boyajian：在开源领域，大家有个常见的误解，就是大家觉得开源项目会缺少完整易读的说明文档，所以必然导致开发延迟。某些开源项目确实是这样，但PostgresSQL没有这样的问题。</p><p>&nbsp;</p><p>1996年，加州大学伯克利分校在设计PostgresSQL时，设计团队也考虑到了底层数据模型的可扩展性。当时的数据库只能支持非常简单的数据类型，例如数字、字符串和日期。Postgres创始人、EDB的杰出顾问和战略家之一Michael Stonebreaker及其团队则做出一项影响深远的决策，让PostgresSQL更易于添加新的数据类型及相关操作。</p><p>&nbsp;</p><p>例如，PostGIS就是PostgresSQL的一个扩展，能够轻松处理地理数据元素、多边形、路线等数据。仅此一点，就让PostgresSQL成为地图系统领域的首选解决方案之一。其他重要扩展还包括文档存储（JSON）和键值对（HSTORE）。</p><p>&nbsp;</p><p>这种可扩展的数据模型和良好的云端运行能力，为PostgresSQL开发人员赋予了极大的生产力创新能力空间。这是PostgreSQL取得成功的关键因素之一。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：目前市场上的数据库种类繁多，那Postgres和Postgres企业版有哪些明显的优势？</blockquote><p></p><p>&nbsp;</p><p>Ed Boyajian：EDB Postgres在各类关键环境中优于其他数据库，主要体现在技术/性能灵活性，以及在广泛企业工作负载和价值诉求中的适用性。而这些优势的核心，就在于开源。</p><p>&nbsp;</p><p>像甲骨文这样的专有遗留数据库在市场上仍占有400亿美元左右的市场份额，但它在技术上已经不再优于Postgres，反而给企业用户带来了不合理的运营成本。</p><p>&nbsp;</p><p>以数据中心基础设施和硬件专业服务为核心的各大新云服务商，也在积极涉足软件业务，其中当然也包括Postgres。然而，这些供应商并不是数据库专家，所以企业客户往往不敢贸然选用。PostgresSQL本身缺乏专业服务，再加上混合和多云解决方案构成的应用门槛，导致PostgresSQL在市场推广上一度受阻。</p><p>&nbsp;</p><p>专用NoSQL数据库最适合那些有针对性的用例，但这同时意味着其可扩展性较差，无法处理更为复杂的企业级应用工作负载。此外，绝大多数专用NoSQL数据库都被一家企业所垄断，所以未来的发展潜力也比较有限。</p><p>&nbsp;</p><p>PostgresSQL是真正的开源数据库，拥有独立且强大的全球管理社区。借助EDB，PostgresSQL的功能得到显著增强，能够提供无与伦比的灵活性、可扩展性和成本优势。</p><p></p><h2>PostgresSQL在数字化转型中起到了怎样的作用？</h2><p></p><p>&nbsp;</p><p></p><blockquote>InfoQ：数字化转型已经成为全球最热门的议题，PostgresSQL又能在企业的数字化转型进程中发挥哪些积极作用？</blockquote><p></p><p>&nbsp;</p><p>Ed Boyajian：PostgresSQL是<a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651136062&amp;idx=3&amp;sn=94ee9a0cf21e44aa8cf0b3f16b353ea1&amp;chksm=bdb8d86d8acf517b4cccd4eff828c2a792bd034cbead7bd8a20c21a1b9266ecbe7a9dba126b2&amp;scene=27#wechat_redirect\">数字化转型</a>\"领域的优先选择的数据库，因为它的应用程序支持范围最广。组织不仅能够在PostgresSQL上构建新应用程序，而且还能轻松把遗留数据迁移至其中。</p><p>&nbsp;</p><p>市场的内在挑战、猛烈的通货膨胀和持续攀升的利率水平，迫使企业加快推进业务转型。组织正转向开源模型，借此在市场上保持竞争优势与业务地位。在这样的背景下，PostgresSQL成为众多企业的优先选择。PostgresSQL能够提供符合遗留系统的同等功能，甚至还有所扩展，同时保证更好的成本效益。</p><p>&nbsp;</p><p>综合来看，PostgresSQL已经成为全球使用最广、最符合现实需求的数据库。根据Stack Overflow的开发者调查，Postgres数据库在2022年及之后将迎来指数级的市场份额增长。Postgres也被Gartner认定为约800亿美元总体数据库市场上，增长速度最快的数据库管理系统。</p><p>&nbsp;</p><p>EDB拥有300多名专职开发人员和三成以上的PostgresSQL代码贡献比例，成为Postgres最主要的技术创新源头。我们连续50个季度的业务增长，也证明了PostgresSQL为企业带来的持久价值。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：您能给我们介绍几个使用PostgresSQL数据库实现数字化转型的具体案例吗？</blockquote><p></p><p>&nbsp;</p><p>Ed Boyajian：新加坡一家头部保险公司就完成了一项数字化转型计划，目的是将现有应用程序迁移至现代平台。该公司的保险产品涵盖保护、储蓄和投资等多个领域，各产品通过国际银行等多渠道分销网络进行交付。因此，这项转型计划着重强调保险公司与该国际银行间的数据交换，希望以双方协同的方式迅速扩大在东南亚市场上的份额占比。</p><p>&nbsp;</p><p>这家保险公司与合作银行之间的银行业务，主要以定期发送电子邮件的方式交换保险业务信息。由于数据格式不符合行业认定的标准或代码共享标准，因此大量电子邮件永久被遗忘在邮箱的角落。这套系统需要持续不断地人为干预，因此显著增加了维护和管理成本，并最终导致销售延迟、响应时间过长和业务流失。</p><p>&nbsp;</p><p>我们的合作伙伴Ashnik为他们设计了符合行业标准、强大、可扩展、自动化且近实时的数据交换解决方案，于是这家保险公司得以用XML SOAP消息同合作银行快速交换信息。通过与EDB合作，Ashnik得以设计出高度优化的数据模型，并整合不同来源的数据以保证一致性。此外，EDB Postgres Advanced Server（EPAS）还提供一套可靠且强大的错误处理与数据协调框架。以开源PostgreSQL为基础，Ashnik得以轻松将数据库平台同Pentaho企业版相集成，生成复杂的多级XML消息提要。</p><p>&nbsp;</p><p>EPAS可以集成XML和NoSQL格式的数据，以确保数据质量的同时简化标准流程。EPAS严格遵循美国国家标准协议（ANSI）和国际标准化组织（ISO）采用的SQL标准，为负责处理关键业务和敏感数据的保险企业提供必要保证，承诺代码在当下和将来始终拥有支持、易于支持。</p><p>&nbsp;</p><p>通过数据整合和标准化，这家保险公司已经能够以近实时方式交换信息，同时显著降低由人工干预产生的成本。</p><p></p><h2>开源商业化该怎么做？</h2><p></p><p>&nbsp;</p><p>InfoQ：作为Postgres社区最大的贡献者之一，你是如何看待开源的？你认为开源服务的价值是什么？</p><p>&nbsp;</p><p>Ed Boyajian：开源项目及其贡献者代表着软件创新领域的新标杆。整个世界曾经转向Linux、也曾经转向Kubernetes，现在则开始转向Postgres。这一切都不是偶然，而代表着更好的软件形态和行业标准发展方式。</p><p>&nbsp;</p><p>业界已经将开源成果作为IT堆栈中的关键组件。随着Linux的大获成功以及开源数据库在非关键任务解决方案（例如分析和社交媒体平台）上的迅速普及，开源项目现在开始迅速取代各类传统数据库管理系统，尝试接管作为业务核心的（事务）关键任务解决方案。</p><p>&nbsp;</p><p>现代应用程序也在推动业务创新，支持与传统应用完全不同的全新应用程序形式。随着数据总量的爆炸式增长，开源使组织能够充分发掘经济效益，以更低廉的数据管理成本支持业务盈利。此外，现代应用程序还需要能在任何位置、任何云、任何虚拟机乃至任何数据中心内运行。随着用户和事务规模的增长，组织还希望数据库的可用性能根据需求灵活浮动。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：对于想基于开源软件提供服务的企业，您有哪些建议给他们？</blockquote><p></p><p>&nbsp;</p><p>Ed Boyajian：请先把“回报”的观念放一放，着力建立起无条件支持开源项目的文化。要随时间推移始终保持这个承诺，别用几个月来衡量收益，而是要把眼光延伸到几年甚至几十年的周期。我们也是这样，始终如一地投入时间、精力和资源，不计回报。</p><p></p>",
    "publish_time": "2022-10-17 17:37:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "StarRocks Summit Asia 2022 主旨演讲",
    "url": "https://www.infoq.cn/article/pMsoKb58NUeY8MbNmQ3N",
    "summary": "<p>本论坛，我们将重点围绕数据库产品的技术发展与突破，邀约合作伙伴共同探讨“极速统一”带来的业务价值。</p>",
    "publish_time": "2022-10-17 17:39:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]