[
  {
    "title": "Canonical 推出超小型容器镜像 Chiselled Ubuntu",
    "url": "https://www.infoq.cn/article/grSAu3pUrbKDPZPPaDLZ",
    "summary": "<p>Canonical 正式发布了 Chiselled Ubuntu 容器，这是一个生产就绪的、安全的超小型容器镜像，侧重于效率和安全性。这些容器镜像允许用户构建的镜像仅包含其应用程序及运行时依赖，而不包含不必要的操作系统级包、实用程序或库。另外，Canonical 还承诺提供安全维护与支持。</p><p></p><p>Chiselled Ubuntu 系列镜像中包含面向流行工具链的镜像，如 Java、.NET 和 Python。此外，Canonical 还与微软合作为.NET 6、7 和 8 提供了通用 Chiselled Ubuntu 容器镜像。</p><p></p><p>正如 GitLab 在 2022 年全球 DevSecOps 调查中所强调的那样，安全仍然是容器化的一个关键问题。这份调查报告指出，只有 64% 的安全专业人员制定了容器安全计划。Canonical 通过提供具有可信来源的 Chiselled Ubuntu 容器和最佳开发 - 生产体验解决了这个问题。容器镜像使用了开发人员友好的开源包管理器“Chisel”，允许开发人员创建精确的超小型文件系统，仅包含运行其应用程序所需的内容。</p><p></p><p>与谷歌的 Distroless 和 Chainguard 的镜像类似，Chiselled Ubuntu 容器也是旨在缩小容器基础镜像。它也带来了同样的好处，比如最小化依赖，减少膨胀和资源使用，加快启动速度，并通过减少镜像中不需要的文件来增强安全性。Chisel 本身使用 Slice 定义文件，它与 Ubuntu 归档中的上游包相关，定义运行时所需的这些包内容的子集，并通过开发人员友好的 CLI 提供了细粒度的依赖项管理，缩小容器镜像攻击面并完全消除一些潜在的攻击向量，实现了更有效的容器化，同时增强了安全性。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c9/c9ecd58ba558662d0d30f948172b4a31.png\" /></p><p></p><p>Chiselled Ubuntu 与流行的工具链（如.NET 和 Java）进行了集成，使得开发人员可以无缝地创建和部署安全、高效的容器镜像。举例来说，与 Eclipse Temurin Java 17 运行时镜像相比，面向 Java 运行时引擎的 Chiselled Ubuntu 镜像缩小了 51%，而且不会影响吞吐量或启动性能。</p><p></p><p>除了 Java 和 Python 镜像，还有面向.NET 和 ASP.NET 的 Chiselled Ubuntu 容器，而且可用于各种平台，包括 AMD64、基于 ARM 的平台和 s390x。微软和 Canonical 正合作为.NET 6、7 和 8 开发稳定且提供技术支持的 Chiselled 镜像。.NET 8 发布时引入了针对 Ubuntu 镜像变体的安全强化选项，让用户可以针对容器安全性做额外的控制。微软.NET 项目经理 Richard Lander 表达了对这项合作的热情，并重点说明了更小、更紧凑的容器镜像有什么好处。他还介绍了微软对 Chiselled Ubuntu 容器镜像的全力投入以及与 Canonical 的合作，Lander 说：</p><p></p><p></p><blockquote>Chiselled Ubuntu 镜像是我们为开发人员推荐的基础镜像。然而，在微软 Devblog 的一条评论中（Devclass 着重说明了这一点），Lander 指出，这些镜像只有在所有包都有切片信息的情况下才能工作，而这项工作仍在进行当中。</blockquote><p></p><p></p><p>Chiselled Ubuntu 容器符合 Ubuntu 的长期支持保证，从主存储库构建的容器可以获得 5 年免费的 Bug 修复和安全补丁。发布周期和库与 Ubuntu LTS 一致进一步增强了可靠性。Canonical 发布的 Chiselled Ubuntu 容器旨在为开发人员提供安全、高效且兼容的容器化选项。要了解更多信息可以查看 Canonical 官方网站。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/12/canonical-chiselled-ubuntu/\">https://www.infoq.com/news/2023/12/canonical-chiselled-ubuntu/</a>\"</p><p></p><p></p><p></p>",
    "publish_time": "2023-12-12 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "英特尔数据中心与人工智能事业部 AI 软件架构师何普江确认出席 QCon 上海，分享大模型时代：最大化 CPU 价值的优化策略",
    "url": "https://www.infoq.cn/article/IsCY7KLBPWL2XbXlt8qc",
    "summary": "<p><a href=\"https://qcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=1212&amp;utm_content=hepujiang\">QCon 全球软件开发大会</a>\"，将于 12 月在上海召开。英特尔数据中心与人工智能事业部 AI 软件架构师何普江将发表题为《<a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5627?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=1212&amp;utm_content=hepujiang\">大模型时代：最大化 CPU 价值的优化策略</a>\"》主题分享，探讨一种结合 CPU 和 GPU 的投机采样方法，在大语言模型时代充分利用 CPU 资源的关键策略，以及最新的性能情况，以便了解这些优化策略的实际效果。</p><p></p><p><a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5627?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=1212&amp;utm_content=hepujiang\">何普江</a>\"，2007 年硕士毕业于中国科学技术大学。精通英特尔软件架构、英特尔产品与技术以及 IA 平台性能优化。在英特尔工作期间，为国内主流 ISV 开发出基于 IA 平台的云计算产品过程中提供关键支持，并优化了多家主要互联网公司的核心产品，使其性能提升数倍。对 PyTorch，Tensorflow 等 AI 框架有深入研究，并拥有 10 年以上软件优化经验。工作期间曾获得英特尔中国个人员工最高荣誉奖，与国内互联网厂商多个部门进行深度合作，并在 2019 年助力某云厂商云在 MLPerf 评测中创下了业界领先的 Performance/TOPS 性能记录。他致力于基于 IA 架构平台的深度学习、机器学习研究和在互联网行业的落地推广工作，最新工作包括创建并开源了 CPU 上大语言模型的极致优化方案 xFasterTransformer。他在本次会议的演讲内容如下：</p><p></p><p>演讲：大模型时代：最大化 CPU 价值的优化策略</p><p></p><p>本次演讲将探讨在大语言模型时代充分利用 CPU 资源的关键策略。具体介绍一些结合硬件特性的优化方法，例如利用 CPU 的多核特性、采用并行计算和 AMX 指令集扩展技术来提高处理速度。</p><p></p><p>此外还将介绍一种结合 CPU 和 GPU 的投机采样方法，通过在 CPU 上运行部分计算任务，充分利用 CPU 资源并减少对 GPU 的依赖。最后，我将分享一些最新的性能情况，让您了解这些优化策略的实际效果。通过这些方法，您将能够更好地利用 CPU 资源，提高模型推理速度，以更快速高效的实现生成式模型部署落地。</p><p></p><p>演讲提纲：</p><p></p><p>大语言模型时代为什么需要最大化 CPU 价值CPU 上的大模型优化策略</p><p>○ 大语言模型计算特点 </p><p>○ CPU 硬件特性概览 </p><p>○ 优化方法 </p><p>○ 从向量化到张量化 </p><p>○ 从并行执行到分布式推理 </p><p>○ 低精度优化 </p><p>○ 深入 CPU 微架构的软件优化 </p><p>○ 各优化策略的实际性能数据对比及效果展示</p><p>结合 CPU 和 GPU 的投机采样方法</p><p>○ CPU 和 GPU 协同工作的背景 </p><p>○ 投机采样技术的介绍 </p><p>○ 利用 CPU 进行部分计算任务的优势 </p><p>○ 优化方法：选择合适的投机采样策略、任务调度等</p><p>总结与展望</p><p>○ 各优化方法的核心优势与局限性总结 </p><p>○ 对未来大语言模型时代的展望与挑战</p><p></p><p>听众收益点：</p><p></p><p>○ 理解并结合硬件特性进行优化，提高模型推理速度和处理能力</p><p>○ 了解 CPU 上的最新性能情况，为实际业务的大模型线上部署提供更多选择</p><p>○ 掌握结合 CPU 和 GPU 协同工作的优化策略，减少对 GPU 的依赖，提高资源利用率</p><p></p><p>除上述演讲外，QCon 上海还将围绕&nbsp;<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart\">GenAI和通用大模型应用探索</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1596?utm_source=infoqweb&amp;utm_medium=teacherart\">AI&nbsp;Agent&nbsp;与行业融合应用的前景</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart\">LLM&nbsp;时代的性能优化</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart\">智能化信创软件&nbsp;IDE</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart\">面向人工智能时代的架构</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart\">性能工程：提升效率和创新的新方法</a>\"等专题进行交流。</p><p></p><p>QCon 上海 2023，相约 12 月！9 折优惠仅剩最后 4 天，现在购票立减￥680！咨询购票请联系：18514549229（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/0113b3dfb187d5f9988b7eb16d2e0594.png\" /></p><p></p>",
    "publish_time": "2023-12-12 11:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "企业数智化进阶模型，大型企业实现数智融合的成功之“道”",
    "url": "https://www.infoq.cn/article/FrR3xm21zRTfZYHbufGA",
    "summary": "<p>数据是助力企业持续提升竞争力的养分，智能则是将养分输送到企业每一个角落的管道。通过数据与智能融合，大型企业将焕发全新的活力与效能，其中数智化底座扮演着重要角色。&nbsp;&nbsp;</p><p></p><p>1 数智融合是必经之路，也是企业普遍面临的重大挑战</p><p></p><p>近年来，随着智能化技术的飞速发展，尤其是以生成式 AI 为代表的技术步入普及应用。通过将数据与智能有效融合的方式，加速数智化应用落地、拓宽数智化场景的深度和广度已成为行业共识。一方面，企业可以通过数据深度洞察自身、洞察产业和竞争对手，另一方面，智能化技术可以基于企业的数据积累，大大提升企业传统工作流程的效率，显著减少人力需求，为企业的日常高效运营和长期决策提供支持。例如，企业运营和销售部门可以借助 AI 工具，通过专为本行业开发的大模型分析企业积累的运营数据，从中挖掘总结成本优化、客户偏好、潜在市场机遇等信息，从而在迅速变化的市场环境作出及时响应；智能化工具还能让企业内部实现数据平民化，让非技术背景的员工也能更加便利灵活地运用数据资源等等。经过有效的数智化过程，企业降本增效、开拓市场、改善利润空间也就水到渠成。</p><p></p><p>然而，对于大型企业而言，数智融合的目标与成果虽然令人振奋，但企业达成目标的道路上却充满荆棘。究其原因，大型企业往往组织庞大、业务多样、系统流程纷繁复杂。虽然积累了大量运营和业务数据，但这些数据通常都是无序存放，缺乏科学有效的治理机制，因此也很难在实践中发挥其应有的作用。</p><p></p><p>由于数据治理体系不过关，企业即便开始部署智能化应用，也时常面临缺少高质量数据支撑的尴尬境地，智能化场景就成为无源之水，无法真正为业务提供助力。另一种情况下，企业上层虽然在努力推进数智化转型，但一线部门和员工却并不清楚数智融合如何落地到实践场景中，投入大量资源采购的工具、技术，培养的技术人才最后只是在 IT 部门“空转”，难以同应用场景有效对接。这些问题都是企业，尤其是大型企业在数智化转型过程中面临的挑战，只有解决了这些挑战，才能为数智化铺平道路，让企业最终摘下数智融合与转型的成功果实。</p><p></p><p>有道无术，术尚可求，有术无道，则止于术。企业在数智化转型实践中的常见误区，就是先追求微观、细节的“术”，指望采购一些零散的工具和技术就能有效治理数据、落地智能应用。然而，尤其对于大型企业而言，在数智化进程初期就建立宏观视野，构筑转型的行动框架、方案模型是必不可少的步骤。</p><p></p><p>有了这样的行动框架做指引，企业才能自上而下建立清晰的转型预期、实施细则与评价和改进回路，并实现跨部门的高效协作，避免各自为政、懒散躺平、朝令夕改、资源浪费等常见问题。在科学的实施框架引导下，企业逐步完成搭建数据治理体系、浓缩高质量数据、构筑智能化应用、对接业务场景等任务，脚踏实地构筑起牢固的数智化底座，打开持续迭代进化的发展通道，转型成功也就顺理成章。</p><p></p><p>2 企业数智化进阶模型，企业实现数智融合的成功之“道”</p><p></p><p>企业数智化转型是一个综合、复杂、循序渐进的系统工程和长期过程，需遵循科学、合理的行动框架和进阶模型。行万里路不如明师指路，在企业领域，各行业面临的数智化转型难题大都是相通的，实践中的解决方案也是近似的。用友深耕企业服务市场三十五年，也一直在基于众多行业客户的领先实践归纳总结各类行之有效的模型和方法论，并通过企业场景的应用与反馈不断优化。针对企业的数智化进程，用友同样归纳出了一条成功之“道”，即“企业数智化1-2-3”，也被称为企业数智化进阶模型，可以服务企业更明晰便捷地实现数智化。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/39/39182fb93d77a0a060b9208e712d70bd.png\" /></p><p></p><p>“数智化1”是企业要推进“云化连接”（上云），实现业务的云化部署、网络连接（含物联网）和实时感知；“数智化2”是企业要推进“数据驱动”（用数），实现全面数据服务，统一数据治理，并升级数智底座；“数智化3”是企业要推进“智能运营”（赋智），实现业务运营智能化、自然化人机交互和知识与应用生成。</p><p></p><p>从这三个阶段可以看出，数据与智能是一直相伴存在的。随着企业对应用需求的不断加深，数据与智能所提供的能力也需要越来越丰富，相应的对其底层支撑平台的要求也越来越高。如今大多数企业的数智化处于“数智化2”&nbsp;数据驱动层级，企业需要升级数智化底座，实现全面数据服务。</p><p></p><p>例如，有些企业基于用友 iuap 平台构建数智化供应链，通过深入挖掘离线数据以实现采购流程的可视化与风险识别，从而实时调整采购流程，对供应商进行画像评价。还有些企业使用用友 iuap 平台来构建数智化人才供应链，发现企业内部人才核心节点，定位意见领袖、关键人才岗位，并利用内部社交和邮件数据分析判别离职意向，从而辅助 HR 部门提前采取行动，降低人员流失，保留核心人才。进入数据驱动的企业可以将现有的数据沉淀为知识图谱，例如资产维修的知识图谱就可以帮助经验不足的资产维修人员快速定位和解决维修问题。</p><p></p><p>通过这些举措，企业的数据在运营生产的各个环节都发挥出了应有的作用，为企业贡献了可观的价值。</p><p></p><p>随着大模型和生成式 AI 技术的崛起，有部分领先的大型企业开始向智能运营进阶。但在这一过程中企业往往面临两大挑战：首先，大模型将扮演企业数智化底座核心操作系统的角色，为此需要更加广泛、高质量的数据来源，不仅包括了企业已有的基础数据，还需要更多产业级、社会化的数据资源。其次，有了这些产业级的数据支撑，大模型还需要对企业业务场景的深刻理解，才能有效应用在实际业务中。企业需要更多同时理解大模型技术与企业所处业务领域知识的复合型人才来运用大模型的能力，这就会对企业的人员配备、岗位体系乃至整个企业的组织模式带来巨变。</p><p></p><p>在数智化进阶模型的指引下，大型企业的数智化进程有“道”可依。此时，如何解决实现智能运营的两大挑战就成了关键问题，企业开始需要“术”层面的支持和帮助。</p><p></p><p>3 用友 iuap，企业数智化实现智能运营之“术”</p><p></p><p>对于大多数企业而言，生成式 AI 是一个全新的技术领域，企业的管理层和 IT 部门在这一领域都没有足够的知识和经验。正因如此，当企业试图自行构建智能运营体系时，就需要独自面对跨领域、社会化数据的治理、整合、标注、模型选择、模型训练、场景适配等诸多陌生问题。</p><p></p><p>尤其在生成式 AI 超越企业内部层面，纳入社会化能力的过程中，企业自有的 IT 和业务团队往往是力不从心的。而如果没有与企业业务充分融合的大模型能力，智能运营也就成为了空中楼阁。显然，大型企业尤其需要更高水平的、内建了生成式 AI 能力的数智化底座，在这样的底座基础上才能大范围落地智能应用，实现从数据驱动到智能运营的全面转变。</p><p></p><p>从数据驱动到智能运营，用友 iuap 为企业提供全面支持</p><p></p><p>生成式 AI 技术在企业落地，需要有成熟的数智化底座承接才不会陷入无人会用、无场景可用的尴尬，而企业数智化底座用友 iuap 平台为企业提供了所需的底座基础能力，在应用、数据、智能等多个维度支持企业业务快速创新。</p><p></p><p>应用层面，在智能运营层级，企业需要部署智慧化灵动应用，如智能助理、智能预算等。数智员工就是企业智能助理的一种形式，通过数智员工可以解决企业流程自动化、审批智能化、内容合规化、数据驱动语义化等问题。数智员工具备智能交互与自主学习能力，比如通过 AI 与 RPA 深度融合,AI 具备 ChatGPT 类的交互、学习能力，自动识别流程风险、自动学习审批，使得流程风险更可控，审批更智能。在工作流中引入智能审批助理，可以大幅提高工作效率，提升公司产出效能。通过数字人、技能、AI、业务流、对话流工场化设计，可以快速实现所见即所得。企业还可以根据自己的场景创作个性化形象、个性化能力的数智员工。</p><p></p><p>数据层面，处于智能运营层级的企业需要拥有更丰富的产业 / 社会级数据资源，相应的数据服务需要覆盖从展现级到分析级、控制级、决策级、创新级（如产品优化）的全部五层数据服务。</p><p></p><p>用友 iuap 数据中台通过数据移动、开发、治理、指标、挖掘、语义模型、数字大屏、移动分析、智能分析云、智能报告等功能大大简化了数据的采集、加工、治理和应用流程，为企业提供了一站式数据底座，支撑数据驱动的各类场景应用。用友 iuap 的数据服务能力已经涵盖了各个层面。</p><p></p><p>比如，某食品加工集团，基于用友 iuap 构建了企业“业务中台、数据中台、智能中台”三位一体的企业数智化底座，推动业务智能化应用，实现企业化智能化运营。该集团通过构建统一客户视图，对重点、关怀、风险、异动等客户群体，实施不同的营销策略，实现精准营销。基于约束理论最优化目标函数，结合遗传算法构建了排产优化模型，通过优化排产，降低企业生产成本。建立了风险预测模型，通过对现金流动性、利率敏感性、资本充足率、市场风险暴露值、异常交易、信用风险等指标和场景进行实时监控、及时预警。</p><p></p><p>智能层面，数智化处于智能运营层级的企业，其智能化进入了慧知层，全面应用企业服务大模型。</p><p></p><p>为了普及 AI 在企业的应用，用友于 2023 年 7 月发布了业界首个企业服务大模型 YonGPT。因为，用友在此前服务企业过程中，已经产生了大量的商业应用数据，这些数据对于企业而言是非常宝贵的资产，在 AI 技术的加持下，可以发挥更大价值。YonGPT 不仅可以通过上下文记忆、知识 / 库表索引、Prompt 工程、Agent 执行、通用工具集等扩充大模型的存储记忆、适配应用和调度执行能力，还沉淀了财务、人力、供应链、采购、制造、营销、研发、项目、资产、协同等领域场景的知识和领先实践。通过将用友长期业务实践中积累的大量跨行业、社会化数据与知识进行训练，可以更好地理解企业业务，帮企业作出准确决策，实现智能运营。</p><p></p><p>YonGPT 已经在企业经营洞察、智能库存优化、智能人才发现、智能预算分析、代码生成、供应商风控等数十种场景完成智能化赋能。</p><p></p><p>YonGPT 作为用友在 AI 领域的最新成果，可以为企业提供更加智能、高效、便捷的服务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7a/7a70f33e78348426c13ee469a9ce5b61.png\" /></p><p></p><p>用友 iuap 为企业带来了更多高度专业化、场景化、社会化的数据资源，并将这些资源与企业的私有数据有机结合，形成可复用的专业能力。在用友 iuap 平台的支持下，企业无需从零开始进行大规模的投资建设与人才团队培养，也能顺利跨越数智化转型第二阶段到第三阶段的难关，更早建成智能化的运营体系，最大程度发挥企业内部和外部的数据生产要素的潜在价值。</p><p></p><p>编后语：</p><p></p><p>当大部分企业的数智化还处在“数智化2”层级时，一些行业领先企业已经开始朝“数智化3”层级迈进。“数智化2”处于企业走向智能运营的关键阶段，需要企业做好全面的数据治理及数据服务，全面升级数智底座，才能在“数智化3”层级拥有夯实的数据及平台基础。用友 iuap 作为更懂业务、技术领先、体系完整的数智化底座，为大型企业带来数据、智能、平台全面保障，以此为企业业务和应用服务。并且在“数智化3”层级，用友 iuap 持续输出以企业服务大模型为中心的智能化能力，助力企业顺利实现智能化运营，以数智化持续推动企业高质量发展！</p>",
    "publish_time": "2023-12-12 11:49:02",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "大模型在金融行业的落地探索",
    "url": "https://www.infoq.cn/article/x0q9GJJQAMIWyI3juNGo",
    "summary": "<p>在金融行业，随着技术的快速发展，大数据和大模型正在逐渐成为推动行业创新的重要力量。这种变革不仅在风险管理和预测方面展现出巨大潜力，而且在促进金融机构与科技公司之间的合作、推动数字化转型，以及优化数据管理和治理方面也显示出其独特价值。然而，在这一进程中，行业也面临着如可解释性、社会智能等一系列挑战。</p>\n<p>在FCon全球金融科技大会上，我们邀请了光大信托信息技术部副总经理、数据中心总经理祝世虎 博士，为你分享了大模型在金融领域的应用及其带来的机遇与挑战。以下为分享的重要内容：</p>\n<ul>\n<li>大数据、大模型与风控的关系：探讨了大数据和大模型如何影响金融领域的风险控制，特别是如何通过数据分析和模型预测来管理和减少风险。</li>\n<li>大合作与创新：讨论了金融机构与科技公司之间的合作以及这种合作如何促进创新，特别是在开发和应用大型模型方面。</li>\n<li>关注的问题：提出了金融行业在采用大型模型时面临的一些挑战和问题，例如可解释性、社会智能等。</li>\n<li>数字化转型对大模型的助力：分析了数字化转型如何助力大模型在金融行业的发展和应用。</li>\n<li>数据信托与大模型：讨论了数据信托如何帮助管理和优化大模型，特别是在处理和保护数据方面。</li>\n<li>大模型的治理：探索了在金融行业中应用大模型时需要考虑的治理问题，包括伦理和法律方面的考量。</li>\n</ul>\n<p><strong>活动推荐：</strong></p>\n<p>QCon 全球软件开发大会（上海站）即将在 12 月 28-29 日开始，届时将围绕 GenAI和通用大模型应用探索、AI Agent 与行业融合应用的前景、LLM 时代的性能优化、智能化信创软件 IDE、面向人工智能时代的架构、性能工程：提升效率和创新的新方法等专题进行交流。现在购票，享 9 折优惠，立减￥680！咨询购票请联系：18514549229（微信同手机号）。</p>",
    "publish_time": "2023-12-12 11:58:09",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "22人估值20亿美元，半年增长七倍，“欧洲 OpenAI”发布媲美GPT3.5的“开放权重”模型",
    "url": "https://www.infoq.cn/article/SjiWBCDHGt6kClScsea3",
    "summary": "<p>Mistral AI 是一家总部位于巴黎的初创公司，由 Meta 和谷歌的研究人员于七个月前创立。目前，该公司已成功筹集 3.85 亿欧元（约合 4.15 亿美元），再次凸显了人们对生成式AI的浓厚兴趣。</p><p>&nbsp;</p><p>据两位知情人士透露，这笔交易将该公司的估值提升至约 20 亿美元，而该公司目前拥有 22 名员工。投资者阵容中有硅谷风险投资公司 Andreessen Horowitz 和 Lightspeed Venture Partners，还包括Salesforce、法国巴黎银行等众多投资机构。</p><p>&nbsp;</p><p>令人瞩目的是，这家初创公司的估值在短短的六个月内增长了七倍以上。仅在今年夏季，公司就成功完成了一轮 1.05 亿欧元（约合 1.13 亿美元）的种子资金融资，当时公司的估值约为 2.6 亿美元。</p><p>&nbsp;</p><p>同时，Mistral AI 还推出了新型 Mixtral 8x7B LLM。这款模型被称为“权重开源（open weights）”模型，设定了新的性能标准，并在其商业平台开放了访问。</p><p>&nbsp;</p><p></p><h2>媲美GPT3.5的“开放权重”模型</h2><p></p><p>&nbsp;</p><p>Mistral AI 发布了其名为Mixtral 8x7B的新模型，与Meta的Llama 2和OpenAI的GPT-3.5模型相比性能更佳。测试结果显示，Mixtral的性能与其他两个选项相当，甚至更为出色，并且成本和延迟更低。</p><p>&nbsp;</p><p>Mistral AI 官方宣称，这是一种高质量稀疏专家混合模型 (SMoE)，可以在 Apache 2.0 许可证下用于商业用途。并且，Mixtral 在大多数基准测试中都优于 Llama 2 70B，推理速度提高了 6 倍。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/54/549ef74dcc7282cd545b6ec69750edbe.jpeg\" /></p><p></p><p>&nbsp;</p><p>Mistral AI 公司特别强调，“它是最强大的开放权重模型，具有宽松的许可证，也是成本/性能权衡方面的最佳模型。特别是，它在大多数标准基准测试中匹配或优于 GPT3.5。”</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0d/0debded25b961853a9c9b9304c47afa4.png\" /></p><p></p><p>截图源自：<a href=\"https://mistral.ai/news/mixtral-of-experts/\">https://mistral.ai/news/mixtral-of-experts/</a>\"</p><p>&nbsp;</p><p>Mixtral 具有32k token 上下文，可以处理英语、法语、意大利语、德语和西班牙语，代码生成表现出色。同时发布了 Instruct 版本的微调模型，MT-Bench 8.3 分。</p><p>&nbsp;</p><p>Mistral 表示，Mixtral 共 46.7B 参数，但每 token 仅使用 12.9B，意味着等同于 12.9B 的推理速度和成本。</p><p>&nbsp;</p><p>AI 领域的玩家已经开始下载、运行、尝试 Mixtral 8x7B，并对其性能和成本优势赞不绝口：</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/51/517b6804eff70bca3f1faf9986e8d5b7.jpeg\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/af/af45adffd5f5f4a29668e6ccb40b8b17.jpeg\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>然而，值得注意的是，在官方给出的测试结果中有一个缺失，即TruthfulQA，通常用于测试法学硕士不重复常见在线错误信息的能力。尽管如此，Mistral仍强调，与OpenAI和Meta的选项相比，其模型的运行成本要低得多，这是一个明显的优势。</p><p>&nbsp;</p><p></p><h2>开放平台</h2><p></p><p>&nbsp;</p><p>同一天，Mistral还发布了其开放平台La plateforme，并上架了三款模型。</p><p>&nbsp;</p><p>Mistral-tiny：最具成本效益，目前提供 Mistral 7B Instruct v0.2，它是 Mistral 7B Instruct 的更新小版本。Mistral-tiny 仅适用于英语，在 MT-Bench 上获得 7.6 分。</p><p>&nbsp;</p><p>Mistral-small：Mixtral 8x7B，能处理英语/法语/意大利语/德语/西班牙语和代码，并在 MT-Bench 上获得 8.3 分。</p><p>&nbsp;</p><p>Mistral-medium：最高档原型模型，能处理英语/法语/意大利语/德语/西班牙语和代码，并在 MT-Bench 上获得 8.6 分。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/75/75ff3416c94fe002f73e169979c546d8.png\" /></p><p></p><p>&nbsp;</p><p>该公司同时提供了 embed endpoint，一个具有 1024 嵌入维度的嵌入模型，设计有检索能力，MTEB 55.26 分。</p><p>&nbsp;</p><p>开源并不意味着 Mistral AI 回避商业化。虽然Mistral AI 有两个模型可以直接下载，但他们的最佳模型现在只能通过 API 访问：该公司计划从其基础模型中赚钱。这就是 Mistral AI 今天开放其开发者平台测试版的原因。有了这个平台，其他公司将能够通过 API 付费使用 Mistral AI 的模型。</p><p>&nbsp;</p><p>“我们的 API 遵循我们最亲爱的竞争对手最初提出的流行聊天界面的规范。我们提供了 Python 和 Javascript 客户端库，以查询我们的终端节点。”</p><p>&nbsp;</p><p>“每个 endpoint 都在性能和价格之间进行了不同的权衡。”</p><p>&nbsp;</p><p></p><h2>公司小，但令人瞩目</h2><p></p><p>&nbsp;</p><p>Mistral AI也被称为“欧洲 OpenAI”，由来自 Meta Platforms 和 Alphabet 的几位前研究人员 Arthur Mensch（现任 CEO）、Guillaume Lample 和 Timothee Lacroix 共同创立，公司成立于 2023 年 5 月，专门开发大语言模型及各类 AI 技术。Mistral 这个名号来自北方寒冷的季风，也体现了他们想要在 AI 领域占据一席之地的愿望。</p><p>&nbsp;</p><p>6 月，Mistral AI在拿下 1.13 亿美元巨额种子融资后引发业界轰动，公司估值也瞬间来到 2.6 亿美元。彼时，该公司刚刚成立，员工仅 6 人，还未做出任何产品，仅仅凭借着 7 页 PPT 就斩获了巨额融资。</p><p>&nbsp;</p><p>虽然Mistral AI目前人员数量也只有二十来人，却以较小的规模成功地获得了20亿美元的估值，并轻松地推出了性能最高的7B模型和 8x7B MOE模型。“我认为这可能对OpenAI来说是一个比Google或Anthropic更大的潜在威胁。”Hacker News网友评论。“考虑到最近的大额投资，我认为他们将能够a）在不久的将来扩展到应对合理的流量负载，b）吸引最顶尖、最聪明的研究人员，并以各种惊人和戏剧性的方式引起这个行业的关注。”</p><p>&nbsp;</p><p>Mistral 公司 CEO、前 DeepMind 研究科学家 Mensch 表示，这家企业的使命是“打造出能够解决现实世界问题的下一代 AI 系统”，并在创立之初就坚定了开源路线。他们于今年9月发布了自家首个大模型 Mistral 7B，该模型号称是“最强 7B 开源模型”。</p><p>&nbsp;</p><p>英伟达Senior Research Scientist Jim Fan评论说，Mistral 成功要素之一就是成立时机无可挑剔：诞生在开源和闭源争议中，并由精干团队推动。</p><p>&nbsp;</p><p>另外，每个月都会有几十款模型问世，但能引起大众向往的很少，而7B 和 7B-MoE（相当于 12B 密集）却对基层 AI 工程师来说更为友好，更容易构建。而且作为欧洲“本土化”的语言模型，Mistral AI也做到了差异化发展。可以说，该公司强大的初始团队和雄心勃勃的发展目标，已经使其成为当前乃至未来几年中最值得关注的 AI 初创力量之一。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://mistral.ai/news/mixtral-of-experts/\">https://mistral.ai/news/mixtral-of-experts/</a>\"</p><p><a href=\"https://mistral.ai/news/la-plateforme/\">https://mistral.ai/news/la-plateforme/</a>\"</p><p><a href=\"https://twitter.com/DrJimFan/status/1734269362100437315\">https://twitter.com/DrJimFan/status/1734269362100437315</a>\"</p><p><a href=\"https://www.nytimes.com/2023/12/10/technology/mistral-ai-funding.html\">https://www.nytimes.com/2023/12/10/technology/mistral-ai-funding.html</a>\"</p><p><a href=\"https://www.infoq.cn/article/V0ykFE4HYFlbNA0vbcE5\">https://www.infoq.cn/article/V0ykFE4HYFlbNA0vbcE5</a>\"</p>",
    "publish_time": "2023-12-12 14:00:51",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "数字人民币（e-CNY）赋能支付业态发展",
    "url": "https://www.infoq.cn/article/AlOVsq23YDmFUCiM1sa7",
    "summary": "<p>随着全球数字货币的兴起，特别是中国数字人民币（e-CNY）的发展，我们正见证一个重大的金融技术变革。数字人民币的推出不仅仅是一种新型支付方式的出现，更是对现有金融生态系统的重塑。在这个变化中，既有机遇也有挑战，特别是在数字货币的安全性、普及性和监管方面。了解这些关键点，将有助于我们更好地理解数字货币的未来发展趋势及其可能带来的影响。在FCon全球金融科技大会上，我们邀请了苏州银行网络金融部高级产品经理金一松，他以主题为《数字人民币（e-CNY）赋能支付业态发展》展开了分享，以下为重点内容概述：</p>\n<ul>\n<li>数字人民币的定义与特性：详细讨论了数字人民币的定义、设计特点，包括与传统货币的区别、发行和流通方式，以及它在支付体系中的角色。</li>\n<li>数字人民币的母子钱包体系和软硬钱包形态：探讨了数字人民币的钱包体系，包括母子钱包体系的结构和软硬钱包的不同形态。</li>\n<li>无网无电支付能力与智能合约应用：强调了数字人民币在无网络和无电源环境下的支付能力，以及智能合约在数字货币中的应用。</li>\n<li>数字人民币的未来应用前景：展望了数字人民币未来的发展方向，包括在不同场景中的应用潜力和可能的创新应用。</li>\n</ul>\n<p>活动推荐：</p>\n<p><a href=\"https://qcon.infoq.cn/202312/shanghai/\">QCon 全球软件开发大会（上海站）</a>即将在 12 月 28-29 日开始，届时将围绕 GenAI 和通用大模型应用探索、AI Agent 与行业融合应用的前景、LLM 时代的性能优化、智能化信创软件 IDE、面向人工智能时代的架构、性能工程：提升效率和创新的新方法等专题进行交流。现在购票，享 9 折优惠，立减￥680！咨询购票请联系：18514549229（微信同手机号）。</p>",
    "publish_time": "2023-12-12 14:19:38",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "专注数据基础设施，Alluxio 如何让 AI 和数据价值全面释放？",
    "url": "https://www.infoq.cn/article/BpQDOgbRKscRmQ6ARycy",
    "summary": "<p>12 月 9 日，AI 和大数据基础设施方案提供商 Alluxio 联合北京大学计算机学院等单位举办了 2023 全球 AI 前沿科技大会北京站，介绍了最新产品 Alluxio Enterprise AI 与为 Alluixo Enteprise Data 开发的重磅特性 Alluxio Edge。作为数据编排领域的先行者，Alluxio 的最新产品与特性瞄准了市场上最热门的 AI 与大数据主题，希望通过数据编排这一关键工作流环节的技术创新，为企业的相关应用带来显著的加速效果和成本效益提升。</p><p></p><p>在大会主题演讲中，Alluxio 创始人兼 CEO 李浩源将 2023 年定义为 Alluixo 机器学习与人工智能的开启元年。李浩源表示，Alluixo Enterprise AI 将打破 AI 数据治理的“不可能三角”，而 Alluixo Edge 则会大幅提升企业大数据分析平台的效能，他希望新产品与新特性能够像 Alluxio 以往的创新一样得到业界广泛使用，从而助力各行业数据和 AI 价值的全面释放。</p><p></p><p>1 Alluxio Enterprise AI：在恰当的时间获取正确的 AI 数据</p><p></p><p>回顾 Alluxio 的发展历史，这家公司从创业以来一直专注于填补企业不同数据平台之间的鸿沟。实践中，企业往往会选择、部署多个数据平台，各类应用（数据消费者）需要从不同的来源获取数据，不仅增加了复杂性，数据传输效率也往往不尽如人意。Alluxio 则将市面上常见的数据源和消费接口统一到自研的数据编排层上，负责屏蔽不同来源与输出接口的差异性，同时通过数据缓存优化方案来提升热点数据的访问效率。由此以来，即便企业部署了很多数据存储方案，甚至有很多数据部署在全球多个物理区域，企业应用又需要通过多种 API 访问这些数据，Alluxio 也能让整个流程的效率和便利性接近本地单数据源方案的水平。</p><p></p><p>凭借数据编排领域的先行优势，发展近 10 年的 Alluxio 已经成为业内广为人知、广泛应用的核心基础设施应用。在云计算快速普及的浪潮中，由于云端服务和产品普遍开始引入存算分离设计，加之混合云、多云、跨云环境逐渐成为主流，Alluxio 的能力得到了普遍认可。显然，取得成功的 Alluxio 并没有就此止步，面对 2023 年的生成式 AI 变革，这家公司迅速响应，推出了 Alluxio Enterprise AI 这样一款直击企业痛点的新品。</p><p></p><p>如今，大规模 AI 应用已经成为各行业的前沿必争之地，每一个细分领域都有企业开发自己的大模型技术或生成式 AI 应用，并为此投入大量资源组建庞大的计算集群用于训练和推理任务，即便芯片短缺造成硬件成本飙升也拒绝退缩。但在集群开始运行后，企业管理者经常尴尬地发现成本高昂的硬件平台实际算力利用率总是偏低，换句话说数量可观的算力资源是处于闲置浪费状态的。</p><p></p><p>造成这种现象的原因有很多，包括软件优化、计算错误、IO 性能不足等，其中 IO 瓶颈是造成集群空转的非常重要的因素。一般来说，企业用于训练和推理模型的数据也是来自多个数据源的，很多数据存放在不同的云服务中，当计算集群从这些数据源获取数据时，很容易遭遇带宽低下、延迟较高的困境，使计算芯片的宝贵时间白白浪费在等待数据这一环节上，这种情况有时甚至可以造成超过 50% 的计算节点空转现象，换句话说企业的 AI 基础硬件设施投资有一半都被浪费了。</p><p></p><p>为了解决这个问题，Alluxio 提出了一种分层存储方案。在硬件层面，Alluxio 将每个计算节点的本地存储当成速度较快的缓存，缓存访问失败后才会访问最后的云端数据源：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4e/4ec90fe83495567fc3b6913e525e9b6a.png\" /></p><p></p><p>Alluxio 将这种设计称为去中心化对象存储库架构（DORA）。AI 训练流程开始后，Alluxio 会自动选出训练热点数据，从云端复制到每一个训练节点的内部存储上。由于节点内部存储的性能远超云端，这样的设计大大提升了 IO 效率，官方宣称可以提供 2-4 倍的训练性能提升。更为诱人的是，获得如此大的收益并不需要企业额外购买大量硬件，Alluxio 只是充分利用了现有计算节点闲置的存储空间来加速 IO 而已，堪称“四两拨千斤”。</p><p></p><p>当然，要从海量数据中准确挑选出热点数据，还要为每一个计算节点分配应有的训练数据，尽量减少缓存未命中情况，避免从云端访问数据是这一方案设计中的最大难点。Alluxio 宣称，自己凭借多年以来数据编排领域的丰富经验，可以通过少量的处理节点轻松应对数以千亿计的存储对象，获得相比云端存储数十倍的元数据访问性能，而分布在计算节点上的存储则能支持 TB 级的总带宽与毫秒级的访问延迟。在获得如此强大能力的同时，由于企业无需采购昂贵的全闪存存储硬件来加速 IO，整体成本也能下降一半甚至 2/3，最终突破数据治理的“不可能三角”。</p><p></p><p>Alluxio Enterprise AI 的另一大优势，在于它能够将机器学习引擎与不同的存储系统连接起来，并跨区域和跨云将数据虚拟化，以简单和统一的方式使得大规模数据应用访问和管理来自不同数据源的数据，进而消除数据冗余，避免管理多个数据副本、减少对专用网络和存储硬件的依赖，无论数据位于何处都可以灵活地在任何位置部署计算，充分利用计算资源。Alluxio 还支持云原生容器化自动部署，完全适配 Pytorch、Tensorflow 等机器学习框架，可以做到上层引擎“无感知”，训练脚本“零改动”，数据准备“无拷贝”，数据清理“全自动”，显著降低部署和运维成本，使得企业在消除 AI 数据 IO 瓶颈的同时，获得一个大幅提升数据多源管理效率的治理平台。</p><p></p><p>Alluxio Enterprise AI 所承诺的收益对于正在大举进军生成式 AI 产业的企业而言无疑是极具诱惑力的：不需要额外的大笔硬件投资，不需要复杂的软件技术栈改动，也不需要开发和运维团队耗费大量时间学习掌握，只需一套接近开箱即用的解决方案就能轻松撬动 50% 甚至更多的闲置计算资源，附送高效率的数据管理能力，这样的前景如此美好，甚至令人难以置信。不过 Alluxio CEO 李浩源在大会上表现出了充足的信心，可以推测该公司对于 Alluxio Enterprise AI 的市场前景是非常看好的。</p><p></p><p>2 Alluxio Edge 星翼，为 Alluxio Enterprise Data 新增的重磅特性</p><p></p><p>大会上，李浩源详细介绍了 Alluxio Edge（中文名星翼），被认为是公司对现有 Alluxio Enterprise Data 产品新增的重磅特性。</p><p></p><p>具体而言，星翼是与 PrestoDB 和 Trino 应用程序搭配使用的一个库，它可以利用 PrestoDB 或者 Trino 集群的本地存储空间来缓存数据。当大部分热数据能够放在本地磁盘中时，这个库可以带来最佳的效率和成本效益。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/56/563f660a10c8c2dc2c72a3a406f4b3cc.png\" /></p><p></p><p>简单来说，如果用户的数据分析框架只需要从一个单区域云数据源获取数据，且热点数据量并不大时，就可以使用星翼来利用节点本地存储的性能。由于星翼的体量足够轻，它对企业数据架构的影响也是最小的，然而它带来的性能提升依旧非常显著，包括端到端查询的性能提高约 1.5 倍到 10 倍，10 到 50 倍的 IO 吞吐量提升，云存储 API 的调用也能减少 50% 到 90%，底层存储的负载同样可以大幅下降。</p><p></p><p>Alluxio 原有的 Alluxio Enterprise Data 则更适用于混合云、多区域、多计算环境。在混合云或多区域环境中，Alluxio Enterprise Data 具有免复制机制，访问时只提取和缓存必要的数据，无需将大型数据集从云端完整复制到本地，减少 I/O 时间和成本，并缩短了分析所需的端到端时间；在多计算环境中，Alluxio Enterprise Data 可充当不同计算集群之间的高性能分布式缓存，使得多个应用的数据访问更加高效，并能轻松实现横向扩展。显然，星翼是 Alluxio Enterprise Data 面向单一区域和计算场景的重要能力补充。当企业数据架构较为简单时，使用星翼就能立刻获得巨大收益；当企业业务扩展导致数据架构随之更新后，就可以平滑升级到 Allxuio Enterprise Data 来满足更多场景的需求，从而进一步扩大 Alluxio 在这一领域的优势地位。</p><p></p><p>3 加速智算应用，Alluxio 前景值得期待</p><p></p><p>目前全球排名前 10 的互联网公司中有 9 家在使用 Alluxio，并在科技、金融、电信等行业得到广泛应用。能够取得这样的成绩，主要归功于 Alluxio 选择了一条能够给企业带来明显价值，同时又被很多人忽视的细分领域赛道。经过近十年的发展，Alluxio 在数据编排领域的地位已经非常牢固，今年发布的两款新品正是这家公司厚积薄发的成果与已有优势的延伸。</p><p></p><p>考虑到各行业都越来越重视数据与 AI 的应用和价值，Alluxio 产品的适用领域也将不断扩大。随着 Alluxio Enterprise AI 的推出与成熟，它很可能会在生成式 AI 革命中成为企业数据基础设施不可或缺的组成部分。正如李浩源所言，AI 和数据价值的全面释放，离不开更智慧、更强性能、更经济高效的计算能力与基础设施平台的强力支撑。Alluxio 将扮演企业至关重要的数据平台角色，为企业智算应用插上翅膀，大幅提升业务效率，助力企业决胜未来。</p>",
    "publish_time": "2023-12-12 14:33:38",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "不会写代码同学的福音——AI 代码生成器 Amazon CodeWhisperer（通过注释写代码）",
    "url": "https://www.infoq.cn/article/8mTxLzES8Hrx7gHH1x3t",
    "summary": "<p>本文转载经亚马逊云科技授权</p><p></p><p>Amazon CodeWhisperer 是一个以机器学习为动力的代码生成器，直接在集成开发环境（IDE）中为开发者提供实时代码建议。它是一个通用的工具，可以用于 IDE 支持的任何编程语言。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/5f/62/5fc7579f0caa538c19a4dfc9beb69462.png\" /></p><p></p><p>大家可以通过下面的链接进入注册并使用：&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">AI 代码生成器 - Amazon CodeWhisperer - 亚马逊云科技</a>\"</p><p></p><p>CodeWhisperer 是在一个庞大的开源代码数据集上训练出来的，它使用这些数据来生成与你目前正在编写的代码相关的建议。这些建议的范围可以从一行代码到一个完整的函数。</p><p></p><p>CodeWhisperer 还可以扫描你的代码是否存在安全漏洞。它通过将你的代码与已知漏洞的数据库进行比较来实现这一目的。如果CodeWhisperer发现一个潜在的漏洞，它将标记代码，并为你提供一个链接，以获得更多关于该漏洞的信息。</p><p></p><p>CodeWhisperer是一个强大的工具，可以帮助你更快、更安全地编写代码。它可以免费提供给个人开发者，它也可以作为 Amazon CodeStar Pro 订阅的一部分。</p><p>以下是使用亚马逊CodeWhisperer的一些好处：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/e6/ce/e69b3730c7666b22bca28183fe3db9ce.png\" /></p><p></p><p>提高安全性： CodeWhisperer 可以通过扫描你的代码的潜在漏洞来帮助你写出更安全的代码。这可以帮助你避免昂贵的安全漏洞和数据丢失。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/e7/1c/e7275344167f34db90ac7f0922ff041c.png\" /></p><p></p><p>减少错误： CodeWhisperer 可以通过为您提供准确和相关的代码建议来帮助您减少代码中的错误数量。这可以节省你的时间和挫折感，并且可以帮助你提高代码的质量。</p><p></p><p>如果你是一个正在寻找提高生产力、安全性和准确性的方法的开发者，那么你应该考虑使用 Amazon CodeWhisperer。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/53/2c/5364346c169fb14aacc9704b1c332b2c.png\" /></p><p></p><h3>使用收藏夹工具</h3><p></p><p></p><p>CodeWhisperer 符合您的工作方式。从 15 种编程语言中进行选择，包括 Python、Java 和 JavaScript，以及您最喜欢的集成式开发环境（IDE），包括 VS Code、IntelliJ IDEA、Amazon Cloud9、Amazon Lambda 控制台、JupyterLab 和 Amazon SageMaker Studio。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/8d/b9/8dc9315aa02ffb72ab2ef8b2bf2a89b9.png\" /></p><p></p><h3>开发人员工作效率的巨大飞跃速度提高&nbsp;57%</h3><p></p><p></p><p>在预览期间，Amazon 举办了一场生产力挑战赛，使用 Amazon CodeWhisperer 的参与者成功完成任务的可能性要比未使用 CodeWhisperer 的参与者高 27%，平均完成任务的速度快 57%。</p><p></p><p>Amazon CodeWhisperer，一个实时的人工智能编码伴侣，普遍可用，还包括一个 CodeWhisperer 个人层，所有开发人员都可以免费使用。CodeWhisperer 最初是在去年推出的预览版，它使开发人员保持状态和生产力，帮助他们快速和安全地编写代码，而不需要离开他们的IDE去研究什么，打破他们的流程。面对为复杂和不断变化的环境创建代码，开发人员可以通过在他们最喜欢的 IDE（包括Visual Studio Code、IntelliJ IDEA 和其他 IDE）中使用 CodeWhisperer 来提高他们的生产力并简化他们的工作。</p><p></p><p>CodeWhisperer 有助于为常规的或耗时的、无差别的任务创建代码，使用不熟悉的 API 或 SDK，正确有效地使用 Amazon API，以及其他常见的编码场景，如读写文件、图像处理、编写单元测试等。</p><p></p><p>只需使用一个电子邮件账户，您就可以注册，并在短短几分钟内提高编写代码的效率，而且您甚至不需要成为亚马逊云科技的客户。对于企业用户，CodeWhisperer 提供了一个专业层，增加了管理功能，如 SSO 和 IAM 身份中心的整合，对参考代码建议的策略控制，以及对安全扫描的更高限制。除了为 Python、Java、JavaScript、TypeScript 和 C# 生成代码建议外，普遍可用的版本现在还支持 Go、Rust、PHP、Ruby、Kotlin、C、C++、Shell 脚本、SQL 和 Scala。在 Visual Studio Code、IntelliJ IDEA、CLion、GoLand、WebStorm、Rider、PhpStorm、PyCharm、RubyMine和DataGrip IDE中工作的开发人员可以使用 CodeWhisperer（当这些 IDE 安装了适当的亚马逊云科技扩展时），或在Amazon Cloud9 或 Amazon Lambda 控制台中使用。</p><p></p><p>帮助开发人员保持他们的流程越来越重要，因为面对越来越多的时间压力来完成他们的工作，开发人员往往被迫打破这种流程，转向互联网搜索、StackOverflow 等网站或他们的同事来帮助完成任务。虽然这可以帮助他们获得所需的启动代码，但这是一种破坏性的做法，因为他们不得不离开他们的IDE环境去搜索或在论坛上提问，或寻找和询问同事--进一步增加了干扰。相反，CodeWhisperer 在开发者最有效率的地方与他们见面，在他们在IDE中写代码或评论时实时提供建议。在预览期间，我们进行了一次生产力挑战，使用CodeWhisperer 的参与者成功完成任务的可能性增加了27%，并且比不使用 CodeWhisperer 的参与者平均快了57%。</p><p></p><h3>从评论中生成代码</h3><p></p><p></p><p>然而，开发人员最终找到的代码可能包含一些问题，如隐藏的安全漏洞，有偏见或不公平，或未能负责任地处理开放源代码。当开发者后来不得不解决这些问题时，这些问题不会提高他们的工作效率。在安全编码和负责任地使用人工智能方面，CodeWhisperer 是最好的编码伙伴。为了帮助你负责任地编码，CodeWhisperer 过滤掉可能被认为有偏见或不公平的代码建议，而且它是唯一可以过滤或标记可能类似于特定开源训练数据的代码建议的编码伴侣。它为建议提供额外的数据--例如，存储库的URL和许可证--当生成与训练数据相似的代码时，有助于降低使用代码的风险，使开发人员能够放心地重新使用它。</p><p></p><h3>开源参考资料追踪</h3><p></p><p></p><p>CodeWhisperer 也是唯一具有安全扫描功能的人工智能编码伴侣，可以为难以发现的漏洞寻找和建议补救措施，扫描生成的和开发人员编写的代码，寻找漏洞，如开放网络应用安全项目（OWASP）中列出的前十名。如果它发现了一个漏洞，CodeWhisperer 会提供建议来帮助补救这个问题。</p><p></p><p></p><h3>漏洞扫描</h3><p></p><p></p><p>CodeWhisperer 提供的代码建议不是专门针对与亚马逊云科技合作的。然而，CodeWhisperer 针对最常用的 Amazon API 进行了优化，例如 Amazon Lambda 或亚马逊简单存储服务（Amazon S3），使其成为在亚马逊云科技上构建应用程序的最佳编码伙伴。虽然 CodeWhisperer 为各种语言的通用用例提供了建议，但使用 Amazon API 的额外数据进行的调整意味着你可以确信它是最高质量、最准确的代码生成，你可以获得与亚马逊云科技合作的机会。</p>",
    "publish_time": "2023-12-12 15:50:42",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "极客时间携手CSDN，共筑 AI 时代专业开发者学习社区",
    "url": "https://www.infoq.cn/article/hf83WLGcRI8wRCMdmBg9",
    "summary": "<p>2023 年 12 月 11 日，极客时间与 CSDN 召开直播发布会，宣布双方达成战略合作，将共同致力于构建更强大、专业的技术人社区，为开发者提供更广泛、更深入的学习和交流平台。</p><p></p><p>CSDN 作为中国专业的开发者社区，拥有 4700 万用户和海量 UGC 内容，极客时间作为面向开发者的专业教育平台，拥有丰富的 PGC 课程和专家讲师资源，一直致力于为开发者提供最前沿、最有深度的技术教育。通过与 CSDN 的战略合作，极客时间将能够更广泛地触达到技术人群，为他们提供系统化、实用性强的学习资源。</p><p></p><h1>极客时间与 CSDN 深度合作亮点</h1><p></p><p></p><h2>&nbsp;1. 共筑开发者内容生态：</h2><p></p><p></p><p>CSDN 的开发者社区汇聚了无数热血的开发者，而极客时间的课程则凝聚了业界优秀的专家智慧。通过这次合作，我们将共享优质的技术内容，推动整个技术社区的发展，共同构筑一个更加开放、包容、共赢的技术生态。</p><p></p><h2>&nbsp;2. 合作范围及交付形式。</h2><p></p><p></p><p>此次合作，双方为开发者联合打造了 7 大领域会员、18 条学习路径、73 个技术细分的方向，从最新热门的 AI 大模型，到计算机基础知识，涵盖了开发者在学习上的大部分需求。极客时间的内容生产，严格参照品控手册《工匠》的要求 —— 行业内的顶级专家 + 资深的内容编辑 + 半年到一年的打磨周期 + 高密度的知识交付 + 图文、音频、视频多种承载形式，打磨出课程，一定能够满足 CSDN 开发者的学习需求。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4d/4d8848c33bc595d9275297a8c4972b4c.png\" /></p><p></p><p>在直播发布会上，极客邦科技创始人 &amp; CEO 霍太稳也表达了关于「商业价值」的理解：“极客时间专栏本身是一个好的产品，通过与 CSDN 的合作，可以变成更好的商品，它的商业价值会变得更大，一旦商业价值发挥出来以后，它的生命力也会变得更加长远。让优秀的内容可以获得商业价值，让优秀的创作者能够有所回报，以激励更多的创作者加入，从而给开发者带来更多优质的课程，进入一个良性循环。”</p><p></p><p>在未来，双方将继续深化合作，为开发者打造更多有深度、有温度的学习体验，共同见证开发者的不断成长和创新。</p><p></p><p></p><h1>关于 CSDN</h1><p></p><p></p><p>CSDN 是中国专业的开发者社区。秉承“成就一亿技术人”的使命，为开发者成长及科技企业发展，提供开发者生态的全方位服务。CSDN 在“创新、开放、协作、共享”的开源价值观下，驾驭新技术，赋能开发者，携手华为云推出新一代 AI 驱动的开源开发者平台 GitCode，为新时代开发者提供稳定、可靠，便捷、高效的开源工具和开源服务。</p><p></p><h1>关于极客时间</h1><p></p><p></p><p>极客时间是数字人才的移动知识库， 专注于为开发者提供高质量技术教育的专业平台。通过 PGC 专业内容生产模式，由极客时间教研团队与 1000+ &nbsp;一线技术专家共同打造，涵盖 70+ 类技术领域，1600+ 技术课。平台提供沉浸式深度学习功能，并通过社群、直播、部落等多种方式，与行业大牛零距离交流，助力开发者提升技能，保持对技术的敏感性。</p>",
    "publish_time": "2023-12-12 16:03:38",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]