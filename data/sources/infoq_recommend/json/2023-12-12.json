[
  {
    "title": "Canonical 推出超小型容器镜像 Chiselled Ubuntu",
    "url": "https://www.infoq.cn/article/grSAu3pUrbKDPZPPaDLZ",
    "summary": "<p>Canonical 正式发布了 Chiselled Ubuntu 容器，这是一个生产就绪的、安全的超小型容器镜像，侧重于效率和安全性。这些容器镜像允许用户构建的镜像仅包含其应用程序及运行时依赖，而不包含不必要的操作系统级包、实用程序或库。另外，Canonical 还承诺提供安全维护与支持。</p><p></p><p>Chiselled Ubuntu 系列镜像中包含面向流行工具链的镜像，如 Java、.NET 和 Python。此外，Canonical 还与微软合作为.NET 6、7 和 8 提供了通用 Chiselled Ubuntu 容器镜像。</p><p></p><p>正如 GitLab 在 2022 年全球 DevSecOps 调查中所强调的那样，安全仍然是容器化的一个关键问题。这份调查报告指出，只有 64% 的安全专业人员制定了容器安全计划。Canonical 通过提供具有可信来源的 Chiselled Ubuntu 容器和最佳开发 - 生产体验解决了这个问题。容器镜像使用了开发人员友好的开源包管理器“Chisel”，允许开发人员创建精确的超小型文件系统，仅包含运行其应用程序所需的内容。</p><p></p><p>与谷歌的 Distroless 和 Chainguard 的镜像类似，Chiselled Ubuntu 容器也是旨在缩小容器基础镜像。它也带来了同样的好处，比如最小化依赖，减少膨胀和资源使用，加快启动速度，并通过减少镜像中不需要的文件来增强安全性。Chisel 本身使用 Slice 定义文件，它与 Ubuntu 归档中的上游包相关，定义运行时所需的这些包内容的子集，并通过开发人员友好的 CLI 提供了细粒度的依赖项管理，缩小容器镜像攻击面并完全消除一些潜在的攻击向量，实现了更有效的容器化，同时增强了安全性。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c9/c9ecd58ba558662d0d30f948172b4a31.png\" /></p><p></p><p>Chiselled Ubuntu 与流行的工具链（如.NET 和 Java）进行了集成，使得开发人员可以无缝地创建和部署安全、高效的容器镜像。举例来说，与 Eclipse Temurin Java 17 运行时镜像相比，面向 Java 运行时引擎的 Chiselled Ubuntu 镜像缩小了 51%，而且不会影响吞吐量或启动性能。</p><p></p><p>除了 Java 和 Python 镜像，还有面向.NET 和 ASP.NET 的 Chiselled Ubuntu 容器，而且可用于各种平台，包括 AMD64、基于 ARM 的平台和 s390x。微软和 Canonical 正合作为.NET 6、7 和 8 开发稳定且提供技术支持的 Chiselled 镜像。.NET 8 发布时引入了针对 Ubuntu 镜像变体的安全强化选项，让用户可以针对容器安全性做额外的控制。微软.NET 项目经理 Richard Lander 表达了对这项合作的热情，并重点说明了更小、更紧凑的容器镜像有什么好处。他还介绍了微软对 Chiselled Ubuntu 容器镜像的全力投入以及与 Canonical 的合作，Lander 说：</p><p></p><p></p><blockquote>Chiselled Ubuntu 镜像是我们为开发人员推荐的基础镜像。然而，在微软 Devblog 的一条评论中（Devclass 着重说明了这一点），Lander 指出，这些镜像只有在所有包都有切片信息的情况下才能工作，而这项工作仍在进行当中。</blockquote><p></p><p></p><p>Chiselled Ubuntu 容器符合 Ubuntu 的长期支持保证，从主存储库构建的容器可以获得 5 年免费的 Bug 修复和安全补丁。发布周期和库与 Ubuntu LTS 一致进一步增强了可靠性。Canonical 发布的 Chiselled Ubuntu 容器旨在为开发人员提供安全、高效且兼容的容器化选项。要了解更多信息可以查看 Canonical 官方网站。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/12/canonical-chiselled-ubuntu/\">https://www.infoq.com/news/2023/12/canonical-chiselled-ubuntu/</a>\"</p><p></p><p></p><p></p>",
    "publish_time": "2023-12-12 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "英特尔数据中心与人工智能事业部 AI 软件架构师何普江确认出席 QCon 上海，分享大模型时代：最大化 CPU 价值的优化策略",
    "url": "https://www.infoq.cn/article/IsCY7KLBPWL2XbXlt8qc",
    "summary": "<p><a href=\"https://qcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=1212&amp;utm_content=hepujiang\">QCon 全球软件开发大会</a>\"，将于 12 月在上海召开。英特尔数据中心与人工智能事业部 AI 软件架构师何普江将发表题为《<a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5627?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=1212&amp;utm_content=hepujiang\">大模型时代：最大化 CPU 价值的优化策略</a>\"》主题分享，探讨一种结合 CPU 和 GPU 的投机采样方法，在大语言模型时代充分利用 CPU 资源的关键策略，以及最新的性能情况，以便了解这些优化策略的实际效果。</p><p></p><p><a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5627?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=1212&amp;utm_content=hepujiang\">何普江</a>\"，2007 年硕士毕业于中国科学技术大学。精通英特尔软件架构、英特尔产品与技术以及 IA 平台性能优化。在英特尔工作期间，为国内主流 ISV 开发出基于 IA 平台的云计算产品过程中提供关键支持，并优化了多家主要互联网公司的核心产品，使其性能提升数倍。对 PyTorch，Tensorflow 等 AI 框架有深入研究，并拥有 10 年以上软件优化经验。工作期间曾获得英特尔中国个人员工最高荣誉奖，与国内互联网厂商多个部门进行深度合作，并在 2019 年助力某云厂商云在 MLPerf 评测中创下了业界领先的 Performance/TOPS 性能记录。他致力于基于 IA 架构平台的深度学习、机器学习研究和在互联网行业的落地推广工作，最新工作包括创建并开源了 CPU 上大语言模型的极致优化方案 xFasterTransformer。他在本次会议的演讲内容如下：</p><p></p><p>演讲：大模型时代：最大化 CPU 价值的优化策略</p><p></p><p>本次演讲将探讨在大语言模型时代充分利用 CPU 资源的关键策略。具体介绍一些结合硬件特性的优化方法，例如利用 CPU 的多核特性、采用并行计算和 AMX 指令集扩展技术来提高处理速度。</p><p></p><p>此外还将介绍一种结合 CPU 和 GPU 的投机采样方法，通过在 CPU 上运行部分计算任务，充分利用 CPU 资源并减少对 GPU 的依赖。最后，我将分享一些最新的性能情况，让您了解这些优化策略的实际效果。通过这些方法，您将能够更好地利用 CPU 资源，提高模型推理速度，以更快速高效的实现生成式模型部署落地。</p><p></p><p>演讲提纲：</p><p></p><p>大语言模型时代为什么需要最大化 CPU 价值CPU 上的大模型优化策略</p><p>○ 大语言模型计算特点 </p><p>○ CPU 硬件特性概览 </p><p>○ 优化方法 </p><p>○ 从向量化到张量化 </p><p>○ 从并行执行到分布式推理 </p><p>○ 低精度优化 </p><p>○ 深入 CPU 微架构的软件优化 </p><p>○ 各优化策略的实际性能数据对比及效果展示</p><p>结合 CPU 和 GPU 的投机采样方法</p><p>○ CPU 和 GPU 协同工作的背景 </p><p>○ 投机采样技术的介绍 </p><p>○ 利用 CPU 进行部分计算任务的优势 </p><p>○ 优化方法：选择合适的投机采样策略、任务调度等</p><p>总结与展望</p><p>○ 各优化方法的核心优势与局限性总结 </p><p>○ 对未来大语言模型时代的展望与挑战</p><p></p><p>听众收益点：</p><p></p><p>○ 理解并结合硬件特性进行优化，提高模型推理速度和处理能力</p><p>○ 了解 CPU 上的最新性能情况，为实际业务的大模型线上部署提供更多选择</p><p>○ 掌握结合 CPU 和 GPU 协同工作的优化策略，减少对 GPU 的依赖，提高资源利用率</p><p></p><p>除上述演讲外，QCon 上海还将围绕&nbsp;<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart\">GenAI和通用大模型应用探索</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1596?utm_source=infoqweb&amp;utm_medium=teacherart\">AI&nbsp;Agent&nbsp;与行业融合应用的前景</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart\">LLM&nbsp;时代的性能优化</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart\">智能化信创软件&nbsp;IDE</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart\">面向人工智能时代的架构</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart\">性能工程：提升效率和创新的新方法</a>\"等专题进行交流。</p><p></p><p>QCon 上海 2023，相约 12 月！9 折优惠仅剩最后 4 天，现在购票立减￥680！咨询购票请联系：18514549229（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/0113b3dfb187d5f9988b7eb16d2e0594.png\" /></p><p></p>",
    "publish_time": "2023-12-12 11:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "企业数智化进阶模型，大型企业实现数智融合的成功之“道”",
    "url": "https://www.infoq.cn/article/FrR3xm21zRTfZYHbufGA",
    "summary": "<p>数据是助力企业持续提升竞争力的养分，智能则是将养分输送到企业每一个角落的管道。通过数据与智能融合，大型企业将焕发全新的活力与效能，其中数智化底座扮演着重要角色。&nbsp;&nbsp;</p><p></p><p>1 数智融合是必经之路，也是企业普遍面临的重大挑战</p><p></p><p>近年来，随着智能化技术的飞速发展，尤其是以生成式 AI 为代表的技术步入普及应用。通过将数据与智能有效融合的方式，加速数智化应用落地、拓宽数智化场景的深度和广度已成为行业共识。一方面，企业可以通过数据深度洞察自身、洞察产业和竞争对手，另一方面，智能化技术可以基于企业的数据积累，大大提升企业传统工作流程的效率，显著减少人力需求，为企业的日常高效运营和长期决策提供支持。例如，企业运营和销售部门可以借助 AI 工具，通过专为本行业开发的大模型分析企业积累的运营数据，从中挖掘总结成本优化、客户偏好、潜在市场机遇等信息，从而在迅速变化的市场环境作出及时响应；智能化工具还能让企业内部实现数据平民化，让非技术背景的员工也能更加便利灵活地运用数据资源等等。经过有效的数智化过程，企业降本增效、开拓市场、改善利润空间也就水到渠成。</p><p></p><p>然而，对于大型企业而言，数智融合的目标与成果虽然令人振奋，但企业达成目标的道路上却充满荆棘。究其原因，大型企业往往组织庞大、业务多样、系统流程纷繁复杂。虽然积累了大量运营和业务数据，但这些数据通常都是无序存放，缺乏科学有效的治理机制，因此也很难在实践中发挥其应有的作用。</p><p></p><p>由于数据治理体系不过关，企业即便开始部署智能化应用，也时常面临缺少高质量数据支撑的尴尬境地，智能化场景就成为无源之水，无法真正为业务提供助力。另一种情况下，企业上层虽然在努力推进数智化转型，但一线部门和员工却并不清楚数智融合如何落地到实践场景中，投入大量资源采购的工具、技术，培养的技术人才最后只是在 IT 部门“空转”，难以同应用场景有效对接。这些问题都是企业，尤其是大型企业在数智化转型过程中面临的挑战，只有解决了这些挑战，才能为数智化铺平道路，让企业最终摘下数智融合与转型的成功果实。</p><p></p><p>有道无术，术尚可求，有术无道，则止于术。企业在数智化转型实践中的常见误区，就是先追求微观、细节的“术”，指望采购一些零散的工具和技术就能有效治理数据、落地智能应用。然而，尤其对于大型企业而言，在数智化进程初期就建立宏观视野，构筑转型的行动框架、方案模型是必不可少的步骤。</p><p></p><p>有了这样的行动框架做指引，企业才能自上而下建立清晰的转型预期、实施细则与评价和改进回路，并实现跨部门的高效协作，避免各自为政、懒散躺平、朝令夕改、资源浪费等常见问题。在科学的实施框架引导下，企业逐步完成搭建数据治理体系、浓缩高质量数据、构筑智能化应用、对接业务场景等任务，脚踏实地构筑起牢固的数智化底座，打开持续迭代进化的发展通道，转型成功也就顺理成章。</p><p></p><p>2 企业数智化进阶模型，企业实现数智融合的成功之“道”</p><p></p><p>企业数智化转型是一个综合、复杂、循序渐进的系统工程和长期过程，需遵循科学、合理的行动框架和进阶模型。行万里路不如明师指路，在企业领域，各行业面临的数智化转型难题大都是相通的，实践中的解决方案也是近似的。用友深耕企业服务市场三十五年，也一直在基于众多行业客户的领先实践归纳总结各类行之有效的模型和方法论，并通过企业场景的应用与反馈不断优化。针对企业的数智化进程，用友同样归纳出了一条成功之“道”，即“企业数智化1-2-3”，也被称为企业数智化进阶模型，可以服务企业更明晰便捷地实现数智化。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/39/39182fb93d77a0a060b9208e712d70bd.png\" /></p><p></p><p>“数智化1”是企业要推进“云化连接”（上云），实现业务的云化部署、网络连接（含物联网）和实时感知；“数智化2”是企业要推进“数据驱动”（用数），实现全面数据服务，统一数据治理，并升级数智底座；“数智化3”是企业要推进“智能运营”（赋智），实现业务运营智能化、自然化人机交互和知识与应用生成。</p><p></p><p>从这三个阶段可以看出，数据与智能是一直相伴存在的。随着企业对应用需求的不断加深，数据与智能所提供的能力也需要越来越丰富，相应的对其底层支撑平台的要求也越来越高。如今大多数企业的数智化处于“数智化2”&nbsp;数据驱动层级，企业需要升级数智化底座，实现全面数据服务。</p><p></p><p>例如，有些企业基于用友 iuap 平台构建数智化供应链，通过深入挖掘离线数据以实现采购流程的可视化与风险识别，从而实时调整采购流程，对供应商进行画像评价。还有些企业使用用友 iuap 平台来构建数智化人才供应链，发现企业内部人才核心节点，定位意见领袖、关键人才岗位，并利用内部社交和邮件数据分析判别离职意向，从而辅助 HR 部门提前采取行动，降低人员流失，保留核心人才。进入数据驱动的企业可以将现有的数据沉淀为知识图谱，例如资产维修的知识图谱就可以帮助经验不足的资产维修人员快速定位和解决维修问题。</p><p></p><p>通过这些举措，企业的数据在运营生产的各个环节都发挥出了应有的作用，为企业贡献了可观的价值。</p><p></p><p>随着大模型和生成式 AI 技术的崛起，有部分领先的大型企业开始向智能运营进阶。但在这一过程中企业往往面临两大挑战：首先，大模型将扮演企业数智化底座核心操作系统的角色，为此需要更加广泛、高质量的数据来源，不仅包括了企业已有的基础数据，还需要更多产业级、社会化的数据资源。其次，有了这些产业级的数据支撑，大模型还需要对企业业务场景的深刻理解，才能有效应用在实际业务中。企业需要更多同时理解大模型技术与企业所处业务领域知识的复合型人才来运用大模型的能力，这就会对企业的人员配备、岗位体系乃至整个企业的组织模式带来巨变。</p><p></p><p>在数智化进阶模型的指引下，大型企业的数智化进程有“道”可依。此时，如何解决实现智能运营的两大挑战就成了关键问题，企业开始需要“术”层面的支持和帮助。</p><p></p><p>3 用友 iuap，企业数智化实现智能运营之“术”</p><p></p><p>对于大多数企业而言，生成式 AI 是一个全新的技术领域，企业的管理层和 IT 部门在这一领域都没有足够的知识和经验。正因如此，当企业试图自行构建智能运营体系时，就需要独自面对跨领域、社会化数据的治理、整合、标注、模型选择、模型训练、场景适配等诸多陌生问题。</p><p></p><p>尤其在生成式 AI 超越企业内部层面，纳入社会化能力的过程中，企业自有的 IT 和业务团队往往是力不从心的。而如果没有与企业业务充分融合的大模型能力，智能运营也就成为了空中楼阁。显然，大型企业尤其需要更高水平的、内建了生成式 AI 能力的数智化底座，在这样的底座基础上才能大范围落地智能应用，实现从数据驱动到智能运营的全面转变。</p><p></p><p>从数据驱动到智能运营，用友 iuap 为企业提供全面支持</p><p></p><p>生成式 AI 技术在企业落地，需要有成熟的数智化底座承接才不会陷入无人会用、无场景可用的尴尬，而企业数智化底座用友 iuap 平台为企业提供了所需的底座基础能力，在应用、数据、智能等多个维度支持企业业务快速创新。</p><p></p><p>应用层面，在智能运营层级，企业需要部署智慧化灵动应用，如智能助理、智能预算等。数智员工就是企业智能助理的一种形式，通过数智员工可以解决企业流程自动化、审批智能化、内容合规化、数据驱动语义化等问题。数智员工具备智能交互与自主学习能力，比如通过 AI 与 RPA 深度融合,AI 具备 ChatGPT 类的交互、学习能力，自动识别流程风险、自动学习审批，使得流程风险更可控，审批更智能。在工作流中引入智能审批助理，可以大幅提高工作效率，提升公司产出效能。通过数字人、技能、AI、业务流、对话流工场化设计，可以快速实现所见即所得。企业还可以根据自己的场景创作个性化形象、个性化能力的数智员工。</p><p></p><p>数据层面，处于智能运营层级的企业需要拥有更丰富的产业 / 社会级数据资源，相应的数据服务需要覆盖从展现级到分析级、控制级、决策级、创新级（如产品优化）的全部五层数据服务。</p><p></p><p>用友 iuap 数据中台通过数据移动、开发、治理、指标、挖掘、语义模型、数字大屏、移动分析、智能分析云、智能报告等功能大大简化了数据的采集、加工、治理和应用流程，为企业提供了一站式数据底座，支撑数据驱动的各类场景应用。用友 iuap 的数据服务能力已经涵盖了各个层面。</p><p></p><p>比如，某食品加工集团，基于用友 iuap 构建了企业“业务中台、数据中台、智能中台”三位一体的企业数智化底座，推动业务智能化应用，实现企业化智能化运营。该集团通过构建统一客户视图，对重点、关怀、风险、异动等客户群体，实施不同的营销策略，实现精准营销。基于约束理论最优化目标函数，结合遗传算法构建了排产优化模型，通过优化排产，降低企业生产成本。建立了风险预测模型，通过对现金流动性、利率敏感性、资本充足率、市场风险暴露值、异常交易、信用风险等指标和场景进行实时监控、及时预警。</p><p></p><p>智能层面，数智化处于智能运营层级的企业，其智能化进入了慧知层，全面应用企业服务大模型。</p><p></p><p>为了普及 AI 在企业的应用，用友于 2023 年 7 月发布了业界首个企业服务大模型 YonGPT。因为，用友在此前服务企业过程中，已经产生了大量的商业应用数据，这些数据对于企业而言是非常宝贵的资产，在 AI 技术的加持下，可以发挥更大价值。YonGPT 不仅可以通过上下文记忆、知识 / 库表索引、Prompt 工程、Agent 执行、通用工具集等扩充大模型的存储记忆、适配应用和调度执行能力，还沉淀了财务、人力、供应链、采购、制造、营销、研发、项目、资产、协同等领域场景的知识和领先实践。通过将用友长期业务实践中积累的大量跨行业、社会化数据与知识进行训练，可以更好地理解企业业务，帮企业作出准确决策，实现智能运营。</p><p></p><p>YonGPT 已经在企业经营洞察、智能库存优化、智能人才发现、智能预算分析、代码生成、供应商风控等数十种场景完成智能化赋能。</p><p></p><p>YonGPT 作为用友在 AI 领域的最新成果，可以为企业提供更加智能、高效、便捷的服务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7a/7a70f33e78348426c13ee469a9ce5b61.png\" /></p><p></p><p>用友 iuap 为企业带来了更多高度专业化、场景化、社会化的数据资源，并将这些资源与企业的私有数据有机结合，形成可复用的专业能力。在用友 iuap 平台的支持下，企业无需从零开始进行大规模的投资建设与人才团队培养，也能顺利跨越数智化转型第二阶段到第三阶段的难关，更早建成智能化的运营体系，最大程度发挥企业内部和外部的数据生产要素的潜在价值。</p><p></p><p>编后语：</p><p></p><p>当大部分企业的数智化还处在“数智化2”层级时，一些行业领先企业已经开始朝“数智化3”层级迈进。“数智化2”处于企业走向智能运营的关键阶段，需要企业做好全面的数据治理及数据服务，全面升级数智底座，才能在“数智化3”层级拥有夯实的数据及平台基础。用友 iuap 作为更懂业务、技术领先、体系完整的数智化底座，为大型企业带来数据、智能、平台全面保障，以此为企业业务和应用服务。并且在“数智化3”层级，用友 iuap 持续输出以企业服务大模型为中心的智能化能力，助力企业顺利实现智能化运营，以数智化持续推动企业高质量发展！</p>",
    "publish_time": "2023-12-12 11:49:02",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "大模型在金融行业的落地探索",
    "url": "https://www.infoq.cn/article/x0q9GJJQAMIWyI3juNGo",
    "summary": "<p>在金融行业，随着技术的快速发展，大数据和大模型正在逐渐成为推动行业创新的重要力量。这种变革不仅在风险管理和预测方面展现出巨大潜力，而且在促进金融机构与科技公司之间的合作、推动数字化转型，以及优化数据管理和治理方面也显示出其独特价值。然而，在这一进程中，行业也面临着如可解释性、社会智能等一系列挑战。</p>\n<p>在FCon全球金融科技大会上，我们邀请了光大信托信息技术部副总经理、数据中心总经理祝世虎 博士，为你分享了大模型在金融领域的应用及其带来的机遇与挑战。以下为分享的重要内容：</p>\n<ul>\n<li>大数据、大模型与风控的关系：探讨了大数据和大模型如何影响金融领域的风险控制，特别是如何通过数据分析和模型预测来管理和减少风险。</li>\n<li>大合作与创新：讨论了金融机构与科技公司之间的合作以及这种合作如何促进创新，特别是在开发和应用大型模型方面。</li>\n<li>关注的问题：提出了金融行业在采用大型模型时面临的一些挑战和问题，例如可解释性、社会智能等。</li>\n<li>数字化转型对大模型的助力：分析了数字化转型如何助力大模型在金融行业的发展和应用。</li>\n<li>数据信托与大模型：讨论了数据信托如何帮助管理和优化大模型，特别是在处理和保护数据方面。</li>\n<li>大模型的治理：探索了在金融行业中应用大模型时需要考虑的治理问题，包括伦理和法律方面的考量。</li>\n</ul>\n<p><strong>活动推荐：</strong></p>\n<p>QCon 全球软件开发大会（上海站）即将在 12 月 28-29 日开始，届时将围绕 GenAI和通用大模型应用探索、AI Agent 与行业融合应用的前景、LLM 时代的性能优化、智能化信创软件 IDE、面向人工智能时代的架构、性能工程：提升效率和创新的新方法等专题进行交流。现在购票，享 9 折优惠，立减￥680！咨询购票请联系：18514549229（微信同手机号）。</p>",
    "publish_time": "2023-12-12 11:58:09",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "22人估值20亿美元，半年增长七倍，“欧洲 OpenAI”发布媲美GPT3.5的“开放权重”模型",
    "url": "https://www.infoq.cn/article/SjiWBCDHGt6kClScsea3",
    "summary": "<p>Mistral AI 是一家总部位于巴黎的初创公司，由 Meta 和谷歌的研究人员于七个月前创立。目前，该公司已成功筹集 3.85 亿欧元（约合 4.15 亿美元），再次凸显了人们对生成式AI的浓厚兴趣。</p><p>&nbsp;</p><p>据两位知情人士透露，这笔交易将该公司的估值提升至约 20 亿美元，而该公司目前拥有 22 名员工。投资者阵容中有硅谷风险投资公司 Andreessen Horowitz 和 Lightspeed Venture Partners，还包括Salesforce、法国巴黎银行等众多投资机构。</p><p>&nbsp;</p><p>令人瞩目的是，这家初创公司的估值在短短的六个月内增长了七倍以上。仅在今年夏季，公司就成功完成了一轮 1.05 亿欧元（约合 1.13 亿美元）的种子资金融资，当时公司的估值约为 2.6 亿美元。</p><p>&nbsp;</p><p>同时，Mistral AI 还推出了新型 Mixtral 8x7B LLM。这款模型被称为“权重开源（open weights）”模型，设定了新的性能标准，并在其商业平台开放了访问。</p><p>&nbsp;</p><p></p><h2>媲美GPT3.5的“开放权重”模型</h2><p></p><p>&nbsp;</p><p>Mistral AI 发布了其名为Mixtral 8x7B的新模型，与Meta的Llama 2和OpenAI的GPT-3.5模型相比性能更佳。测试结果显示，Mixtral的性能与其他两个选项相当，甚至更为出色，并且成本和延迟更低。</p><p>&nbsp;</p><p>Mistral AI 官方宣称，这是一种高质量稀疏专家混合模型 (SMoE)，可以在 Apache 2.0 许可证下用于商业用途。并且，Mixtral 在大多数基准测试中都优于 Llama 2 70B，推理速度提高了 6 倍。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/54/549ef74dcc7282cd545b6ec69750edbe.jpeg\" /></p><p></p><p>&nbsp;</p><p>Mistral AI 公司特别强调，“它是最强大的开放权重模型，具有宽松的许可证，也是成本/性能权衡方面的最佳模型。特别是，它在大多数标准基准测试中匹配或优于 GPT3.5。”</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0d/0debded25b961853a9c9b9304c47afa4.png\" /></p><p></p><p>截图源自：<a href=\"https://mistral.ai/news/mixtral-of-experts/\">https://mistral.ai/news/mixtral-of-experts/</a>\"</p><p>&nbsp;</p><p>Mixtral 具有32k token 上下文，可以处理英语、法语、意大利语、德语和西班牙语，代码生成表现出色。同时发布了 Instruct 版本的微调模型，MT-Bench 8.3 分。</p><p>&nbsp;</p><p>Mistral 表示，Mixtral 共 46.7B 参数，但每 token 仅使用 12.9B，意味着等同于 12.9B 的推理速度和成本。</p><p>&nbsp;</p><p>AI 领域的玩家已经开始下载、运行、尝试 Mixtral 8x7B，并对其性能和成本优势赞不绝口：</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/51/517b6804eff70bca3f1faf9986e8d5b7.jpeg\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/af/af45adffd5f5f4a29668e6ccb40b8b17.jpeg\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>然而，值得注意的是，在官方给出的测试结果中有一个缺失，即TruthfulQA，通常用于测试法学硕士不重复常见在线错误信息的能力。尽管如此，Mistral仍强调，与OpenAI和Meta的选项相比，其模型的运行成本要低得多，这是一个明显的优势。</p><p>&nbsp;</p><p></p><h2>开放平台</h2><p></p><p>&nbsp;</p><p>同一天，Mistral还发布了其开放平台La plateforme，并上架了三款模型。</p><p>&nbsp;</p><p>Mistral-tiny：最具成本效益，目前提供 Mistral 7B Instruct v0.2，它是 Mistral 7B Instruct 的更新小版本。Mistral-tiny 仅适用于英语，在 MT-Bench 上获得 7.6 分。</p><p>&nbsp;</p><p>Mistral-small：Mixtral 8x7B，能处理英语/法语/意大利语/德语/西班牙语和代码，并在 MT-Bench 上获得 8.3 分。</p><p>&nbsp;</p><p>Mistral-medium：最高档原型模型，能处理英语/法语/意大利语/德语/西班牙语和代码，并在 MT-Bench 上获得 8.6 分。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/75/75ff3416c94fe002f73e169979c546d8.png\" /></p><p></p><p>&nbsp;</p><p>该公司同时提供了 embed endpoint，一个具有 1024 嵌入维度的嵌入模型，设计有检索能力，MTEB 55.26 分。</p><p>&nbsp;</p><p>开源并不意味着 Mistral AI 回避商业化。虽然Mistral AI 有两个模型可以直接下载，但他们的最佳模型现在只能通过 API 访问：该公司计划从其基础模型中赚钱。这就是 Mistral AI 今天开放其开发者平台测试版的原因。有了这个平台，其他公司将能够通过 API 付费使用 Mistral AI 的模型。</p><p>&nbsp;</p><p>“我们的 API 遵循我们最亲爱的竞争对手最初提出的流行聊天界面的规范。我们提供了 Python 和 Javascript 客户端库，以查询我们的终端节点。”</p><p>&nbsp;</p><p>“每个 endpoint 都在性能和价格之间进行了不同的权衡。”</p><p>&nbsp;</p><p></p><h2>公司小，但令人瞩目</h2><p></p><p>&nbsp;</p><p>Mistral AI也被称为“欧洲 OpenAI”，由来自 Meta Platforms 和 Alphabet 的几位前研究人员 Arthur Mensch（现任 CEO）、Guillaume Lample 和 Timothee Lacroix 共同创立，公司成立于 2023 年 5 月，专门开发大语言模型及各类 AI 技术。Mistral 这个名号来自北方寒冷的季风，也体现了他们想要在 AI 领域占据一席之地的愿望。</p><p>&nbsp;</p><p>6 月，Mistral AI在拿下 1.13 亿美元巨额种子融资后引发业界轰动，公司估值也瞬间来到 2.6 亿美元。彼时，该公司刚刚成立，员工仅 6 人，还未做出任何产品，仅仅凭借着 7 页 PPT 就斩获了巨额融资。</p><p>&nbsp;</p><p>虽然Mistral AI目前人员数量也只有二十来人，却以较小的规模成功地获得了20亿美元的估值，并轻松地推出了性能最高的7B模型和 8x7B MOE模型。“我认为这可能对OpenAI来说是一个比Google或Anthropic更大的潜在威胁。”Hacker News网友评论。“考虑到最近的大额投资，我认为他们将能够a）在不久的将来扩展到应对合理的流量负载，b）吸引最顶尖、最聪明的研究人员，并以各种惊人和戏剧性的方式引起这个行业的关注。”</p><p>&nbsp;</p><p>Mistral 公司 CEO、前 DeepMind 研究科学家 Mensch 表示，这家企业的使命是“打造出能够解决现实世界问题的下一代 AI 系统”，并在创立之初就坚定了开源路线。他们于今年9月发布了自家首个大模型 Mistral 7B，该模型号称是“最强 7B 开源模型”。</p><p>&nbsp;</p><p>英伟达Senior Research Scientist Jim Fan评论说，Mistral 成功要素之一就是成立时机无可挑剔：诞生在开源和闭源争议中，并由精干团队推动。</p><p>&nbsp;</p><p>另外，每个月都会有几十款模型问世，但能引起大众向往的很少，而7B 和 7B-MoE（相当于 12B 密集）却对基层 AI 工程师来说更为友好，更容易构建。而且作为欧洲“本土化”的语言模型，Mistral AI也做到了差异化发展。可以说，该公司强大的初始团队和雄心勃勃的发展目标，已经使其成为当前乃至未来几年中最值得关注的 AI 初创力量之一。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://mistral.ai/news/mixtral-of-experts/\">https://mistral.ai/news/mixtral-of-experts/</a>\"</p><p><a href=\"https://mistral.ai/news/la-plateforme/\">https://mistral.ai/news/la-plateforme/</a>\"</p><p><a href=\"https://twitter.com/DrJimFan/status/1734269362100437315\">https://twitter.com/DrJimFan/status/1734269362100437315</a>\"</p><p><a href=\"https://www.nytimes.com/2023/12/10/technology/mistral-ai-funding.html\">https://www.nytimes.com/2023/12/10/technology/mistral-ai-funding.html</a>\"</p><p><a href=\"https://www.infoq.cn/article/V0ykFE4HYFlbNA0vbcE5\">https://www.infoq.cn/article/V0ykFE4HYFlbNA0vbcE5</a>\"</p>",
    "publish_time": "2023-12-12 14:00:51",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]