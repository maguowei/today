[
  {
    "title": "谷歌发布GUAC项目0.1版本：持续关注供应链安全问题",
    "url": "https://www.infoq.cn/article/Vl88ZlCX2tAXIwjQm3Hj",
    "summary": "<p>谷歌开源安全团队最近推出了GUAC（Graph for Understanding Artifact）v0.1，这是一款面向安全专业人员的工具。GUAC专注于元数据的合成和聚合，可以满足<a href=\"https://www.whitehouse.gov/briefing-room/presidential-actions/2021/05/12/executive-order-on-improving-the-nations-cybersecurity/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTIzMjkzMzgsImZpbGVHVUlEIjoiVlBoR1JXbm03MVFyZjlKYSIsImlhdCI6MTY5MjMyOTAzOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.KqvyJ0W9Ylo8dOX-WZgKaM6bRzTJdo5DnYIFwpsoWc4\">美国网络安全行政令</a>\"中所概述的安全性要求，旨在帮助安全专家评估供应链的安全态势。</p><p></p><p>谷歌开源安全团队的<a href=\"https://www.linkedin.com/in/brandon-lum-a7b79418/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTIzMjkzMzgsImZpbGVHVUlEIjoiVlBoR1JXbm03MVFyZjlKYSIsImlhdCI6MTY5MjMyOTAzOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.KqvyJ0W9Ylo8dOX-WZgKaM6bRzTJdo5DnYIFwpsoWc4\">Brandon Lum</a>\"和<a href=\"https://www.linkedin.com/in/mihai-maruseac/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTIzMjkzMzgsImZpbGVHVUlEIjoiVlBoR1JXbm03MVFyZjlKYSIsImlhdCI6MTY5MjMyOTAzOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.KqvyJ0W9Ylo8dOX-WZgKaM6bRzTJdo5DnYIFwpsoWc4\">Mihai Maruseac</a>\"在一篇<a href=\"https://security.googleblog.com/2023/05/announcing-launch-of-guac-v01.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTIzMjkzMzgsImZpbGVHVUlEIjoiVlBoR1JXbm03MVFyZjlKYSIsImlhdCI6MTY5MjMyOTAzOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.KqvyJ0W9Ylo8dOX-WZgKaM6bRzTJdo5DnYIFwpsoWc4\">博文</a>\"中宣布推出该工具。GUAC意识到整合来自各种数据源的信息的重要性，因此，他们聚合软件安全元数据，并将其与适用于软件供应链的标准化概念库对齐。</p><p></p><p>随着供应链每天都在发生变化，GUAC通过从外部数据源获取最新的威胁信息和分析结果来持续更新其数据库。这些数据源包括软件材料清单（SBOM）、软件工件供应链级别（SLSA）和OSS见解。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/74/7425450f8baefd0b3b5fabca48da5d48.webp\" /></p><p></p><p>来源：<a href=\"https://docs.guac.sh/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTIzMjkzMzgsImZpbGVHVUlEIjoiVlBoR1JXbm03MVFyZjlKYSIsImlhdCI6MTY5MjMyOTAzOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.KqvyJ0W9Ylo8dOX-WZgKaM6bRzTJdo5DnYIFwpsoWc4\">GUAC文档</a>\"</p><p></p><p>通过研究<a href=\"https://www.infoq.com/presentations/log4shell-security-response-patterns/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTIzMjkzMzgsImZpbGVHVUlEIjoiVlBoR1JXbm03MVFyZjlKYSIsImlhdCI6MTY5MjMyOTAzOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.KqvyJ0W9Ylo8dOX-WZgKaM6bRzTJdo5DnYIFwpsoWc4\">企业对Log4shell的反应</a>\"，我们发现，维护统一的SBOM存储库对组织是有利的。这种方法使得他们能够跟踪漏洞并相应地制定应对策略。为了遵循<a href=\"https://www.whitehouse.gov/briefing-room/presidential-actions/2021/05/12/executive-order-on-improving-the-nations-cybersecurity/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTIzMjkzMzgsImZpbGVHVUlEIjoiVlBoR1JXbm03MVFyZjlKYSIsImlhdCI6MTY5MjMyOTAzOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.KqvyJ0W9Ylo8dOX-WZgKaM6bRzTJdo5DnYIFwpsoWc4\">美国网络安全行政令</a>\"，在构建和发布工作流程中生成大量SBOM会让管理任务变得繁杂。为了解决这个问题，GUAC通过链接文档和使用启发式方法来提高数据质量。GUAC社区正在<a href=\"http://github.com/spdx/tools-golang/pull/204?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTIzMjkzMzgsImZpbGVHVUlEIjoiVlBoR1JXbm03MVFyZjlKYSIsImlhdCI6MTY5MjMyOTAzOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.KqvyJ0W9Ylo8dOX-WZgKaM6bRzTJdo5DnYIFwpsoWc4\">与SPDX积极合作</a>\"来推进<a href=\"http://github.com/anchore/syft/issues/1241?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTIzMjkzMzgsImZpbGVHVUlEIjoiVlBoR1JXbm03MVFyZjlKYSIsImlhdCI6MTY5MjMyOTAzOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.KqvyJ0W9Ylo8dOX-WZgKaM6bRzTJdo5DnYIFwpsoWc4\">SBOM工具</a>\"的开发工作以及提高元数据的准确性。</p><p></p><p>在<a href=\"https://www.infoq.com/news/2023/02/sboms-vex-kubernetes/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTIzMjkzMzgsImZpbGVHVUlEIjoiVlBoR1JXbm03MVFyZjlKYSIsImlhdCI6MTY5MjMyOTAzOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.KqvyJ0W9Ylo8dOX-WZgKaM6bRzTJdo5DnYIFwpsoWc4\">CloudNativeSecurityCon 2023的一场小组讨论</a>\"中，GUAC被认为是一种可以理解、利用和从SBOM中派生含义的有价值的工具。讨论还强调了目前还没有标准的SBOM分发方法，所以有通过自动化来实现分发的潜力。</p><p></p><p>Lum和Maruseac强调，GUAC用户有能力开发集成方式，基于信任来制定策略，对安全漏洞做出及时响应，并在发生安全事件时制定升级计划。此外，他们可以构建CLI工具进行广泛的分析和事件响应，以及构建IDE插件进行预防性策略实施。</p><p></p><p>早期采用者对GUAC给予了积极的反馈。雅虎信息安全团队（Paranoids）高级软件开发工程经理<a href=\"https://www.linkedin.com/in/hkadakia/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTIzMjkzMzgsImZpbGVHVUlEIjoiVlBoR1JXbm03MVFyZjlKYSIsImlhdCI6MTY5MjMyOTAzOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.KqvyJ0W9Ylo8dOX-WZgKaM6bRzTJdo5DnYIFwpsoWc4\">Hemil Kadakia</a>\"说：</p><p></p><p></p><blockquote>“在雅虎，我们通过使用开源项目GUAC获得了巨大的价值和显著的效率提升。GUAC帮助我们精简流程并提高效率，这在以前是不可能的。”</blockquote><p></p><p></p><p>Red Hat首席软件工程师<a href=\"https://www.linkedin.com/in/dejanbosanac/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTIzMjkzMzgsImZpbGVHVUlEIjoiVlBoR1JXbm03MVFyZjlKYSIsImlhdCI6MTY5MjMyOTAzOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.KqvyJ0W9Ylo8dOX-WZgKaM6bRzTJdo5DnYIFwpsoWc4\">Dejan Bosanac</a>\"（同时也是GUAC项目的积极贡献者）说：&nbsp;&nbsp;</p><p></p><p></p><blockquote>“有了摄取和认证各种数据源数据的机制，以及查询这些数据的GraphQL API，我们将其视为当前和未来SSCS工作的基础。作为一个真正的开源项目并拥有受欢迎的社区会是一种锦上添花。”</blockquote><p></p><p></p><p>感兴趣的读者可以通过<a href=\"https://guac.sh/community/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTIzMjkzMzgsImZpbGVHVUlEIjoiVlBoR1JXbm03MVFyZjlKYSIsImlhdCI6MTY5MjMyOTAzOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.KqvyJ0W9Ylo8dOX-WZgKaM6bRzTJdo5DnYIFwpsoWc4\">社区网页</a>\"上提到的不同方式了解更多关于GUAC的信息。</p><p></p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/07/google-announces-guac-0-1/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTIzMjkzMzgsImZpbGVHVUlEIjoiVlBoR1JXbm03MVFyZjlKYSIsImlhdCI6MTY5MjMyOTAzOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.KqvyJ0W9Ylo8dOX-WZgKaM6bRzTJdo5DnYIFwpsoWc4\">https://www.infoq.com/news/2023/07/google-announces-guac-0-1/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/9boH3zd1jDZdR244gPhE\">供应链实践调查报告：可感知的实践有用性与采用程度相关</a>\"</p><p><a href=\"https://www.infoq.cn/article/Wv6MjUH5FmrRQPmphIbh\">醒醒吧，没有什么安全的软件供应链</a>\"</p><p><a href=\"https://www.infoq.cn/article/WMs7uoxvNLc1J5qBMtoR\">Log4j一周年观察：我们如何应对日益严峻的软件供应链安全风险？</a>\"</p>",
    "publish_time": "2023-08-22 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "用 Rust 编写核心组件！独家揭露阿里云开源 GraphScope 如何成为全球最快图计算引擎",
    "url": "https://www.infoq.cn/article/7zAblNXRAb2VZ9af85Mv",
    "summary": "<p>采访嘉宾 | GraphScope团队</p><p>编辑 | Tina</p><p>&nbsp;</p><p>上个月，国际权威图基准测评<a href=\"https://ldbcouncil.org/benchmarks/snb-interactive/\">“LDBC SNB Interactive”（社交网络-交互查询）榜单</a>\"更新中出现关键突破：阿里云开源的图计算引擎GraphScope登顶并打破榜单历史纪录，性能达此前纪录保持者2.45倍。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/58/58a65c7e87a884f2c8a205e53d4ec63f.jpeg\" /></p><p></p><p>&nbsp;</p><p>LDBC 全称 <a href=\"https://ldbcouncil.org/\">Linked Data Benchmark Council</a>\"，是一个致力于发展图数据管理的产业联盟国际权威非盈利组织，其成员来自工业界和学术界，包括Intel、AWS、Neo4j、TigerGraph和Oracle等。</p><p>&nbsp;</p><p>在此次基准测评中，GraphScope 以超过 33,000 QPS 的吞吐量排名第一。GraphScope&nbsp;是阿里云自研的一站式图计算系统，于2020年12月开源，在GitHub上已超过&nbsp;2.6k star。</p><p>&nbsp;</p><p>GitHub 地址：https://github.com/alibaba/GraphScope</p><p>&nbsp;</p><p></p><h2>不可或缺的图计算</h2><p></p><p>在阿里巴巴的电商推荐、搜索、风控等场景中，有很多地方会用到GraphScope图计算引擎。</p><p>&nbsp;</p><p>自2020年起的多年双十一期间，阿里巴巴的搜索以及风控团队采用&nbsp;GraphScope&nbsp;作为底部支撑实施了准实时欺诈检测，虚假订单检测能实现秒级识别，评测准确度达到了97%。在此之前虚假订单一般需要等到第二天才能处理。</p><p>&nbsp;</p><p>另外，在推荐场景中，常会用到链路预测，通过已知的网络结构预测尚未发生连边的两个节点之前产生连接的可能性。比如对社交网络做关系分析时，共同邻居是一个重要的特征，它标记了两个不直接关联的点之间共同的好友关系。</p><p>&nbsp;</p><p>这个应用如果用传统的关系数据库写查询，会十分复杂，事实上，很多业务场景确实是通过SQL&nbsp;+&nbsp;一些UDF&nbsp;的方式写的。但由于复杂度的问题，要舍弃一些精度以及引入很多近似计算才能在一个很大规模的数据集上成功跑下来，但千亿规模的数据上需要近10个小时。</p><p>&nbsp;</p><p>这种情况采用图建模的话，共同邻居的查找就十分直观，也很容易写。GraphScope&nbsp;系统通过基于子图模型、增量化计算等技术，能高效的支撑千亿规模以上的图计算，并且由于图建模可以准确计算共同邻居，避免精度损失。这类之前用时10小时的计算任务，用GraphScope只需要约600秒。</p><p>&nbsp;</p><p>现在，在阿里巴巴内部，已经海量任务跑在&nbsp;GraphScope 图计算引擎上，GraphScope 每天要处理数万个图计算任务。</p><p>&nbsp;</p><p>以前，相比于传统的关系型数据库以及SQL，图数据库的使用所占的比重很小。但近年来，随着互联网应用的爆炸式增长和对用户需求的深度挖掘，大家开始认识到有些场景下，传统的SQL处理方式已经不能满足高效的需求。而图数据库，与其他的文档数据库、KV数据库类似，为复杂数据分析提供了全新的维度。特别是在需求深入挖掘关联关系的场景下，图几乎成为了不二之选。这一趋势的重要性在ISO SQL标准的2023版本中得到了体现，其中，<a href=\"https://www.iso.org/standard/79473.html\">SQL/PGQ（Property Graph Query）</a>\"被纳入，未来支持SQL的数据库中也将支持图的查询。</p><p>&nbsp;</p><p>不仅在数据库中，图计算已经在大数据处理和分析中也开始展现其独特的价值和地位。根据2022年8月发布的<a href=\"https://info.stardog.com/graph-market\">Gartner报告</a>\"，到2025年，图计算技术将在80%的数据和分析创新中扮演核心角色。这与2021年的数据大相径庭，当时图计算在数据和分析创新中的占比仅为10%。这样的飞速增长无疑证明了图计算在未来数据分析领域的至关重要性。</p><p>&nbsp;</p><p>正因如此，该团队一直在持续精益求精地打磨 GraphScope。2018年，GraphScope&nbsp;团队的主要成员加入阿里巴巴，并将其自研图计算技术 <a href=\"https://github.com/alibaba/libgrape-lite\">GRAPE</a>\" (GraphScope核心引擎之一的前身) 逐渐应用到阿里巴巴集团和阿里云上。经过几年打磨和使用后，2020年11月，GraphScope&nbsp;在第二届世界科技与发展论坛上重磅宣布开源并发布了白皮书，同年12月代码在&nbsp;GitHub&nbsp;开源。</p><p>&nbsp;</p><p></p><h3>架构演进</h3><p></p><p>&nbsp;</p><p>在以往的图计算系统中，由于针对不同类型的图计算任务设计了特定的特征，导致解决方案出现了严重的碎片化现象。这意味着每种不同类型的图计算任务都需要使用不同的系统或工具来进行处理，导致系统架构的复杂性急剧上升。</p><p>&nbsp;</p><p>在处理现实业务时，一个复杂的工作流可能涉及多种不同类型的图计算任务，比如多模式的图计算，以及需要跨越多个系统进行协同的情况。举例来说，考虑一个包含交易图和欺诈检测的工作流，这可能需要在不同的系统中执行不同的图计算任务，这不仅会引入大量的IO开销，还会增加系统运维的复杂性。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/59/5906fa2ff44983b52da0400631e8cd9e.png\" /></p><p></p><p>&nbsp;</p><p>在以前的部署方式中，为了完成工作流中的不同图计算任务，可能需要通过外部存储来部署多套系统，增加了整个系统的维护难度。此外，不同系统之间的数据交互也变得复杂，可能需要额外的工作来确保数据一致性和有效的传递。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/18/18212c9aad579d916ce0eed62161feac.png\" /></p><p></p><p>&nbsp;</p><p>这种复杂性还使得开发人员需要具备对多个系统的熟悉度，增加了开发和维护图计算任务的技术门槛。这对于数据科学家、算法用户和应用开发方来说，都带来了极大的挑战，限制了图计算在业务中的应用和发展。</p><p>&nbsp;</p><p>在2020年，基于收集到的用户需求，GraphScope 团队提出了一种创新的概念——一站式图计算，通过一个系统整合了当时的多个图计算引擎（即当时 GRAPE、MaxGraph 和 GraphLearn）的能力，覆盖了图分析、图遍历、图学习等多种任务。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d2/d29ad75d087a8b44bb25afdb4b6c76d1.png\" /></p><p></p><p>&nbsp;</p><p>为了实现这一概念，他们进行了大量的研究和开发工作。例如，开展了自研的子项目 vineyard，这个项目解决了跨不同引擎之间数据交互与共享的挑战。值得一提的是，vineyard 项目开源后被捐赠给了云原生大数据社区，进入了CNCF Sandbox。</p><p>&nbsp;</p><p>经过这些改进，最终形成了 GraphScope 一站式图计算，可以在一个平台完成多类图计算任务，这也是业界首个一站式图计算系统。GraphScope的用户们从一站式得到的好处，“从体验侧的价值来说，最主要的是极大程度降低了图计算门槛，极度简化了数据科学家、算法用户以及应用方开发、部署和运维图计算的成本，可将图计算研发上线的周期从以数周计，提效为一两天即可完成。”</p><p>&nbsp;</p><p></p><h3>组件化架构</h3><p></p><p>在此基础上，为了进一步满足图业务的多样化和碎片化需求，GraphScope 正在推进下一代组件化架构 <a href=\"https://github.com/alibaba/GraphScope/tree/main/flex\">GraphScope&nbsp;Flex</a>\"，以像乐高一样的组件化形式为各种具体的图计算场景提供方便的部署、服务和计算的能力。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0b/0b6f4dce784db31f0e91e01776c9af87.png\" /></p><p></p><p>&nbsp;</p><p>在这一架构下，用户可以根据实际的业务场景，灵活地选用 GraphScope 中的若干组件，从而得到最合适其业务场景的部署形态，形成定制化的图计算环境。</p><p>&nbsp;</p><p>与此对应，本次提交的 LDBC 基准测试就是基于GraphScope Flex架构的高吞吐图查询部署方案。在这个部署模式中，他们利用自研的多层级Actor框架 <a href=\"https://github.com/alibaba/hiactor\">Hiactor</a>\"作为底层执行引擎，并结合了 GraphScope 在图存储和图分析引擎方面的积累。这种方案能够在保障事务性要求的前提下，为用户提供超高吞吐的图查询能力。</p><p>&nbsp;</p><p>在开源之后，GraphScope 团队也在不断优化与创新。比如在高效图分析引擎上<a href=\"https://github.com/alibaba/libgrape-lite/blob/master/Performance.md#performance-on-gpus\">拓展了&nbsp;GPU&nbsp;加速</a>\"，性能较之其他系统快&nbsp;5&nbsp;倍有余；通过引入新的&nbsp;<a href=\"https://github.com/alibaba/libgrape-lite/tree/flash\">FLASH</a>\"&nbsp;高效模型，将内置图算法种类扩增到近&nbsp;100&nbsp;种。</p><p>&nbsp;</p><p></p><h3>Rust编程语言的应用</h3><p></p><p>&nbsp;</p><p>此外，GraphScope 还利用近期备受关注的系统编程语言Rust编写了交互式查询的核心组件，分布式引擎GAIA。相较于适用于高吞吐场景下的hiactor系统，GAIA更着重于系统的扩展性和利用并行技术优化查询延迟。为了构建一个更加高效、稳健且安全的并行系统，从GAIA的原型系统（发表于NSDI 2021）起，便选用Rust语言进行开发。</p><p>&nbsp;</p><p>选择Rust主要是因为它提供的“编译时生命周期检查”、\"卓越的并发控制\"，以及“媲美C/C++的执行效率”，具体来说：</p><p>编译时生命周期检查：Rust在编译过程中提供的变量生命周期检查功能，使我们能够在编程的初始阶段尽可能地确保程序的正确性。相比其他语言，这为GAIA这样复杂的系统的实现提供了极高的可靠性保障，解决在分布式服务化的部署中的内存管理问题。卓越的并发控制：并发编程中最常见的问题包括竞态条件和死锁。Rust提供了各种机制来避免这些问题的发生，包括但不限于原生的互斥锁和读写锁，以及通过Send和Sync两个原生trait来保证线程安全。该并发控制是GAIA分布式系统实现的基础。媲美C/C++的执行效率：Rust凭借零开销的抽象和底层优化，以及优质的标准库实现，使得其编写的程序能达到传统面向性能的编程语言C/C++的水准。同时，通过生命周期检查和并发控制，Rust很大程度地避免了C/C++实现的系统常遇到的内存溢出和死锁等难以定位和修复的问题。</p><p>&nbsp;</p><p>基于GraphScope Flex提供的组件化能力，GraphScope可以通过GAIA来支持更多的复杂查询，实现对图数据更为复杂和深刻的洞察与分析，未来也可以为支持LDBC的SNB BI的工作负载奠定基础。</p><p>&nbsp;</p><p></p><h2>GraphScope是如何打破纪录的</h2><p></p><p>这次，GraphScope 登顶并打破榜单历史纪录的基准测评是 LDBC SNB Interactive ，也是业界最受认可的图数据库基准评测。</p><p>&nbsp;</p><p>近年来参与SNB&nbsp;Interactive 评测并在榜中领先的图数据库产品是蚂蚁集团开源的图数据库产品 TuGraph，最近成绩为2023年1月做的测试；另外，国内知名图厂商创邻科技的 Galaxybase 也在 2022年5月提交过成绩。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c8/c8e9bee4566596b8b4ed9d9d4eb5f020.png\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>在LDBC SNB Interactive评测中，为了全面评估图数据库，引入了复杂的数据表和多样化的读写混合查询。背后通过一个驱动器向待测系统快速、持续地发送这些查询请求，主要以系统处理查询的吞吐率（QPS）来衡量其性能。</p><p>&nbsp;</p><p>其中涉及到处理技术难点，包括：</p><p>复杂查询优化：图查询等价于多表关联的查询，而此类优化一直是数据库的传统难题。同时，查询中涉及复杂算子如点对间最短路径，这本身就难以高效实现。复杂的SNB数据表结构，不同类型的数据量差异很大，不当的查询顺序可能导致大量中间结果，严重影响执行性能。读写并发和事务：高并发的读写需要加锁，但在高吞吐情况下，锁开销会显著影响性能。图存储数据结构需要兼顾读写性能，传统的结构往往在写或读性能上存在不足。同时，在高并发情况下，保证事务的一致性和效率更加困难。高并发查询：高并发场景下，物理线程切换会引入大量的开销。查询涵盖了复杂和简单查询，复杂查询可能长时间占用资源，导致系统吞吐大幅下降。</p><p>&nbsp;</p><p>这些技术难点涉及图数据库的查询优化、读写并发、事务保证以及高并发查询等方面，对于系统设计和实现提出了严峻挑战。为了克服前述技术难题，GraphScope主要从以下三个方面实现突破：</p><p>&nbsp;</p><p>在图查询优化方面，通过引入“高维图数据的无偏估计”技术，子图采样可以准确估计基数，从而优化查询访问顺序，提高了特定查询性能。同时，采用了“双向路径搜索”算法，在包含最短路径的负载下，性能提升近3000倍。在高性能读写图存储设计方面，通过采用“细粒度的锁控制”策略，将图数据写操作细分为修改（如属性更新）和插入（点/边），采用不同级别的锁以提高读写并发效率（对于修改操作使用常规读写锁，对于插入操作用细粒度或者无锁技术）。引入了“高效的版本控制”技术，通过原子操作降低锁开销，改进了事务同步。此外，改进了原有的CSR图数据结构，通过预留空间和自旋锁应用，在保证读效率的同时，有效支持插入操作。为支持超高吞吐的计算引擎，引入了“轻量级用户态线程”技术，极大地减少了高并发场景下线程切换的开销。同时，采用了“异步协同式调度”策略，使得用户态线程在异步操作时能主动释放时间片，避免了复杂查询阻塞其他并发查询的情况。</p><p>&nbsp;</p><p>这些关键技术的整合使得GraphScope在性能和效率方面都取得了显著突破。</p><p>&nbsp;</p><p></p><h2>图计算在大语言模型中的应用前景</h2><p></p><p>&nbsp;</p><p>今年以来，以ChatGPT为代表的大语言模型（LLM）迎来爆发式增长，虽然LLM“涌现”出的智能令人兴奋不已，但其训练方式和特有的自然语言交互模式，使得将LLM应用于生产依然面临诸多挑战，例如：在训练数据滞后的情况下，如何提升LLM回答的实时性？在大部分LLM都具有“幻觉”（Hallucination）的情况下，如何确保回答的准确性？虽然LLM具有智能，但其大语言模型的本质决定了LLM在特定领域能力的限制，例如数学计算、网页搜索等。同时，在处理复杂任务时，往往需要对任务进行拆解和编排，利用工具逐个解决，如何才能端到端完成复杂任务？</p><p>&nbsp;</p><p>为解决上述LLM原生问题，业界已经涌现出大量实践，举例来说：</p><p>当LLM充当QA助手时，回答的实时性问题可以通过在提示词（prompt）中加入实时信息得以解决。但这也引出另一个问题，如何找出和问题相关的实时信息呢？网络上的公开数据，尚且可以使用例如<a href=\"https://serpapi.com/\">serpapi</a>\" 之类的搜索工具得到，那么特定领域数据或者私有数据如何处理呢？在提示词长度限制下，如何选出最相关的数据加入其中呢？当LLM出现“幻觉”时，用户往往基于“常识”作出了判断，并通过降低活跃度（temperature）和细化提示词来降低“幻觉”。然而在处理特定领域（例如医疗、法律）任务时，即使用户具有该领域的“常识”，“幻觉”往往难以被识别，因为一般用户难以全面掌握领域知识。那么，有没有什么方法可以有效利用领域知识来识别LLM的“幻觉”呢？针对复杂任务，将LLM与现有成熟生产工具结合，充分利用LLM的智能作为编排复杂工作流程的“大脑”，并调动生产工具完成端到端执行，是业界给出的方案。其中代表，包括闭源的 <a href=\"https://openai.com/blog/chatgpt-plugins\">ChatGPT-Plugin</a>\" 和开源的 <a href=\"https://www.langchain.com/\">Langchain</a>\"。然而，在LLM单一自然语言交互模式下，如何才能实现工作流可视化、实时交互等，以提升系统整体的透明度，避免成为黑盒子呢？如何才能完成数据沉淀、统计分析、快速迭代等，从而提升工作流效率和可持续性呢？</p><p>&nbsp;</p><p>得益于图抽象的语意表达能力和可解释性，图计算可以很好的解决上述业界正在面临的问题。</p><p>&nbsp;</p><p>首先，将领域数据或私有数据存储于图数据库中，并通过边来表示数据点之间的关系，可以实现更精准的相关数据查找。常见的向量数据库通过比较查询和文档分片embeding之间的相似度来查找相关数据，然而对于稍显复杂的查询，其相似性并不体现在单个文档分片上。例如，用户的查询是“OpenAI的前核心员工有没有自己创业的？”，这里其实包含两条信息，一是“谁是OpenAI的前核心员工”，二是“这些人有没有自己创业的”，相关信息可能出现在多个文档分片中，故使用向量数据库难以为LLM提供最相关信息。然而，若使用图数据库，便可以从Company节点出发，通过Empolyment边遍历核心员工，再将这些员工的Profile和Company一起构建embeding，来与查询匹配，从而为LLM提供更为精准的相关数据。</p><p>&nbsp;</p><p>其次，知识图谱作为一种高效领域知识表示，可以为识别LLM的“幻觉”提供事实支撑。例如：LLM回答包含某公司董事会成员A。如果通过向量数据库进行验证，可能某监事A总是出现在董事会会议中，其高频出现会被识别为董事会成员；而通过图数据库，可以查找到姓名为A的Person节点的职位是监事，从而识别出LLM的“幻觉”。</p><p>&nbsp;</p><p>再者，将LLM作为“大脑”解决复杂问题，其核心思路是将可供选择的工具（例如网页搜索、数值计算、本地数据库访问等）的“说明书”加入提示词，和问题一起交由LLM来决定下一步使用哪种工具，以及应该为其提供什么样的输入。对于复杂问题，往往不是一步就能得到结果，所以LLM还要和用户一起完成工作流的编排，一般称为Chain-of-Thought。实际上，由于LLM的返回具有选择性（即LLM会依据输入做出不同的选择，例如判断为是的情况下调用A工具，否则为B工具），用Graph-of-Thought来抽象这一工作流是更为通用的方法。不难看出，基于图抽象的图计算系统，可以更好的管理这一工作流，其对图数据的高效查询、分析和展示能力，可以实现更透明的观察、更易用的UI和更有效的数据管理。</p><p>&nbsp;</p><p>LLM的特点，决定了它须与私有数据、领域知识和工作流框架充分结合，才能在实际生产中产生价值，而图计算系统可以很好的解决目前LLM在这三方面遇到的问题。所以大家坚信图计算作为一项基础技术，将助力LLM走向生产，发挥价值。</p><p>&nbsp;</p><p>此外，GraphScope正在 Text2GQL 领域作出尝试，不仅考虑通过提示词工程来提升准确率，还会尝试通过对开源模型的调优（finetune）来定制更专注的Text2GQL模型，进一步提升准确率和查询效率。在GQL（无论是Gremlin还是Cypher）学习门槛较SQL都更高的今天，期待Text2GQL的实践，能够让更多的用户连接图数据库，享受图计算带来的价值。</p><p>&nbsp;</p><p></p><h2>活动推荐</h2><p></p><p>除了 SNB Interactive 这类工作负载，借助于 GraphScope Flex 灵活的组件式架构，GraphScope 还可以满足其他图计算场景。在将于 9 月 3-5 日在北京·富力万丽酒店举办的 QCon 全球软件开发大会中，阿里巴巴技术专家、GraphScope 图计算团队图神经网络方向负责人苏立，分享题为《GPU 加速大规模图神经网络训练与一站式图计算：技术实践分析与展望》的演讲，他将基于开源分布式 GPU 加速图训练框架 GraphLearn-for-Pytorch(GLTorch) 和一站式图计算平台 GraphScope，介绍 GraphScope 团队和阿里云机器学习 PAI 团队在合作打造 GLTorch 过程中的技术思考和系统设计理念，并分享在一站式图计算领域的实践积累和技术探索。快来和 GraphScope 团队一起交流吧！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/24/2440d36908b17621f88775e6940be971.png\" /></p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-08-22 08:17:38",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "百度百舸平台的大模型训练最佳实践",
    "url": "https://www.infoq.cn/article/yHLEY0YUbmNtVe7jsyKb",
    "summary": "<p></p><p></p><p></p><p>在当今这个信息爆炸的时代，大数据和人工智能正逐渐成为推动社会发展的重要力量。而大模型的训练则是这股力量的核心所在。在百度智能云《大模型时代的 AI 基础设施——百度 AI 大底座》系列云智公开课的前七讲中，百度智能云的技术专家们分别对大模型场景涉及到的各个模块，从网络、计算、存储、向量数据库、AI 框架、LMOps 等维度，为大家做了一个全景展示，分享了百度智能云在这些领域的技术积累和项目实践。</p><p></p><p>在本系列课程的第八讲中，百度智能云高级产品经理杨亮对<a href=\"https://www.infoq.cn/news/kqPbdlvF3Jp55PodQLAo\">前七讲</a>\"的内容进行了二次解读的同时，并围绕百舸在大模型训练过程的稳定性设计和加速实践展开深度解析。课程主要分为以下三个部分：</p><p>大模型时代的百舸异构计算平台；大模型训练稳定性实践；大模型训推加速实践。</p><p></p><p>下文对课程内容以杨亮第一人称进行了整理：</p><p></p><h2>一、大模型时代的百舸异构计算平台</h2><p></p><p></p><p>下图列举了众多国产大模型，里面有通用的大模型，也有面向行业的垂类大模型，「百模大战」可见一斑。</p><p></p><p>为什么会在短期内出现这么多的大模型呢？这和大模型新的训练范式以及开源模型生态快速发展有极大关系。我列举了三种大模型的训练方式，从上往下看，成本由低到高变化。</p><p></p><p>首先是高效参数调优，也就是基于一个已有的通用大模型，使用少量有标注的数据，调整部分模型参数，得到符合面向特定场景的模型，具体的细分方法包括 Prefix-tuning，Prompt-tuning，LoRA 等。在第 7 期的公开课中已经给大家做了较为详细的介绍。</p><p></p><p>其次是 SFT 指令微调，也就是使用少量或者中量的有标注数据，对通用大模型做全量参数的调整。由于市面上有比较多的像 Llama、GLM 等优秀的开源大模型以及像百度文心系列商业大模型，所以很多客户会选择这种方案来构建自己的行业大模型。</p><p></p><p>另外一种就是从零到一的预训练，基于大量无标注数据来训练自己的通用大模型，像 GPT-4，Llama 等。当然对于一些公司来说，严格意义上也不算从零到一，一方面有比较多的论文可以参考模型结构，另一方面也可以基于已有的开源模型权重做 Post-pretrain。</p><p></p><p>无论是哪种<a href=\"https://www.infoq.cn/article/SivE8YcpA3q0ioiIQ2g1\">训练</a>\"模式都需要健壮可靠的异构计算基础设施。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/86/86dbe8682fa3fedf0acdf6ee08efee12.png\" /></p><p></p><p>大模型对异构计算基础设施的新挑战，主要在稳定，高效和敏捷等三个方面。</p><p></p><p>稳定性是大模型训练自带约束。基于一些公开数据，像 GPT-4 这类千亿级别的大模型需要数万张 GPU 并行训练，当然还有配套的分布式存储和高速网络，这么复杂的系统可以平稳运行本身就是一个挑战，同时如何在故障发生时能快速精准定位，可以更快速的恢复，都是需要解决的核心问题。</p><p></p><p>同时，因为大模型训练要消耗极大的算力资源，所以每一分效率的提升都会带来真金白银的回报，包括如何进行并行计算，如何更好利用显存，如何提升节点间的通信能力，这也是大模型基础设施需要考虑的问题。</p><p></p><p>大模型参数多计算量大，听起来似乎和敏捷并没有太大关联，但是基于刚才介绍的大模型训练新范式，一方面模型本身的设计成本更低，另外一方面整个行业都在高速迭代中，所以需要基础设施具备快速构建能力，同时有比较低的学习成本，可以快速和开源生态对接，利用开源生态已有的能力。</p><p></p><p>针对大模型的这些挑战，此次专门为大家来分享一下<a href=\"https://www.infoq.cn/article/6ErEzdyB8u9riX7CA3Pz\">百度智能云</a>\"的 AI 基础设施平台——百舸平台的最新进展和实践。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a7/a74ce5d151774da83036efb8778c65c3.png\" /></p><p></p><p>百舸平台是百度智能云面向 AI 计算提供的基础设施产品，已经迭代了多个版本，最早是面向生命科学、自动驾驶和智算中心场景提供的 AI 基础设施解决方案。</p><p></p><p>之前百舸平台的架构介绍，我们更多的是从解决方案的视角进行展示，包括 AI 计算、AI 存储、AI 加速、AI 容器等 4 个核心组件。这次我们从产品视角来看下，从下向上百舸分为基础设施、云原生 AI 套件，配套服务和控制面 4 层：</p><p></p><p>基础设施包括了高性能计算节点，可以支持英伟达 A800、H800 这类高性能 GPU，同时也支持百度自有的昆仑芯片。存储方面提供对象存储 BOS、并行文件存储 PFS，同时也提供了本地的 NVME SSD，支持模型调试、训练、推理等全场景存储需求。存储在大模型场景的加速方案，我们在本次云智公开课的第 3 期给大家做了比较全面的介绍。高性能网络方面我们提供了高性能的 RDMA 网络、支撑业务高速访问和隔离的 VPC 网络，这部分在我们的第 1 期也给大家做了详细介绍。</p><p></p><p>云原生 AI 套件，基于 K8s 内核提供了面向 AI 场景多方面的能力，其中 AI 基础组件提供了高速网络、存储的插件支持，以及异构调度、拓扑感知能力等。AI 编排调度模块支持 Pytorch、PaddlePaddle 等丰富的 AI 训练框架，同时提供了 AI 任务编排和工作流管理。稳定性 &amp; 容错模块提供了丰富的故障感知和容错能力。训练 &amp; 推理加速模块 AIAK 针对大模型场景提供了训推加速能力，也就是 AI 加速套件，后面会展开介绍。</p><p></p><p>同时为了让 AI 任务顺利执行，百舸融合了 Prometheus 监控，镜像、日志、账号等配套服务产品。</p><p>同时在控制面提供了控制台、OpenAPI、SDK 和命令行工具，便于用户使用和与自有的 AI 平台集成。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/06/066238d80575d98c74bd9b79497fee47.png\" /></p><p></p><p>面向万卡级别的超大规模训练，需要有比较多的前置工作来构建集群，里面包括了规划选型、计算、网络、存储的配置，运行库、框架、云原生组件的配置，还有监控告警和用户权限配置，为了达到集群效率最优，每一步都需要有比较细节的配置和考量。</p><p></p><p>基于以往的经验，一个真正生产级别的万卡集群需要专业的基础架构同学数天甚至数周来完成搭建和调试。</p><p></p><p>这个效率显然无法满足大模型的快速发展需求，很多算法工程师对于底层硬件、 K8s 等概念并不了解，而且也无需了解，所以我们把百舸平台进行了升级，屏蔽了无需用户关注的底层概念，打通产品间的安装配置流程，可以一站式小时级完成大模型的基础平台构建，大幅地解放了生产力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fc/fc74e4c1fbd33def149779c236915172.png\" /></p><p></p><p>开源大模型的发展，为大模型开发提供了更多的软件基础设施，例如 Hugging Face，提供了大量的开源数据集，预训练模型等资源，在实际模型开发过程中，有比较多的工程性问题。</p><p></p><p>百舸平台为客户提供了丰富的开源加速工具，例如 EleutherAI 是一个开源的语言模型数据集，大概有 800G+ 数据量，通常需要几十小时的下载时间。我们提供的数据集下载加速功能，采用了专门的下载通道可以将这个过程缩短到分钟级，同时提供数据的预处理和数据转储功能，帮助用户投递到并行文件存储 PFS 等高速存储来进一步加速计算。</p><p></p><p>我们知道一个模型包括模型结构代码和模型权重参数两部分，通常情况下开源模型的权重参数会开放出来，但是模型结构代码没有直接开放或者训练效果不理想，给前面提到的 Post-pretrain 和 SFT 带来了一定的不便。</p><p></p><p>基于这个需求，我们参考开源论文对这部分代码进行了重写和并行切分优化并保证精度对齐，同时也提供了最佳实践文档帮助大家更快地开始模型训练。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3b/3b968ab1ae1c2e75295609e5cc12475e.png\" /></p><p></p><p>针对训练出来的模型我们也提供了一键部署工具和 Playground 帮助大家更好的调试模型。</p><p></p><p>这里展示了在用户提交作业时，我们预置的一系列的开源大模型训练模板，支持了像 Llama、GLM 等主流开源大模型，这个列表将会持续更新，目前已经支持了最新的 Llama 2 模型。</p><p></p><p>根据用户的选择，可以自动适配对应模型的结构代码、调优后的训练超参、并行策略、环境变量和推荐资源配置。用户可以自行下载或者通过平台提供的工具来加速下载模型权重文件，并且进行模型权重转换和切分。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b9/b9b2baea75b3a8580570af4ac07cae48.png\" /></p><p></p><h2>二、大模型训练稳定性实践</h2><p></p><p></p><p>稳定性是一个系统工程，我们衡量一个系统稳定性能力通常用四个指标：</p><p>平均故障时间 MTBF 要求我们有较为丰富的检测工具和巡检机制，同时在系统交付的同时就可以保障基础设施的健壮性；MTTD 和 MTTI 指的是我们的故障感知能力，一个是发现故障的时间，一个是确定故障定位的时间，要求我们在第一时间能感知到问题，并且能确定问题根因并找到解法；MTTR 指的是修复时间，我们一般来说预防、检查胜于治疗，其实前面两个能力建设好以后故障的修复基本是水到渠成，当然也要处理好故障隔离修复和重调度等一系列问题。</p><p></p><p>由于大模型训练是一种大规模离线型计算，所以实际上这些稳定性指标最终支撑的还是训练成本，所以稳定性建设的一个隐含约束就是训练的性能和成本不能显著衰退，不然就会舍本逐末。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/32/325f3ef3e88af9703b58347838670adc.png\" /></p><p></p><p>基于上述的考虑，百舸平台在环境检测，故障感知和容错等三个层面做了很多优化。</p><p></p><p>在环境检查方面，百舸支持了单机硬件、软件和加速库、网络性能、系统组件等多个维度的检查，很多的训练任务都可以通过这些检查来提前预防。在进行环境交付时，任务启动前都提供了相应的检测能力，同时也提供了自动巡检和自助诊断工具。</p><p></p><p>故障感知层，我们针对任务退出，任务假死和运行慢几种常见故障场景建设感知能力。尤其是后两种故障，有比较大的隐蔽性。百舸平台基于百度内部大量的最佳实践制定了指标体系，可以及时的发现问题，同时我们也提供了多个维度的资源状态大盘和日志管理和优化机制。故障智能分析可以基于故障报错信息给予初步的分析和排障建议。</p><p></p><p>容错是做好稳定性建设的最后一道关。百舸平台提供了自动容错能力，可以自动实现故障隔离，重调度和任务拉起，同时提供故障节点热修复或者换机修复等方式。CKPT 是模型训练最基础的容错机制，我们提供了 CKPT 的管理以及 CKPT 的写入加速，这部分稍后会展开介绍。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/70/70e493500e06e6226e55e212d853be04.png\" /></p><p></p><p>下面我们一起来看一下百舸平台上的几个稳定性核心能力。</p><p></p><p>首先是 NCCL 测试工具，NCCL tests 是一个检测节点间通信性能的测试工具，用户可以选择需要测试的通信类型、GPU 数量和目标资源池展开测试。我们可以通过和基准性能指标做比对，发现大多数的硬件故障带来的通信问题，并通过二分查找法定位故障点。</p><p></p><p>智能故障分析是我们结合大模型能力做的一次尝试。很多时候系统的报错信息易读性比较差，一般需要专业的同学来参考多方面的信息定位排查。百舸平台引入了大模型能力、LongChain 机制和向量数据库，可以基于集群的配置信息、监控信息，报错日志以及长时间积累的排查经验来帮助用户对典型的故障进行分析。这个功能目前还在内测阶段，已具备基于常见的日志和报错信息来判断故障的可能原因，给出进一步排查思路。如果已有匹配的 FAQ 也可以直接给出修复建议，更多的能力还在持续建设中。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/eb/eb79867d703ebec5abb7c1c25fe22231.png\" /></p><p></p><p>在任务容错场景，我们提供了较为方便的使用方式。在提交训练任务时，我们可以选择开启容错训练，并配置自动重启次数。当训练任务故障时，我们会根据配置首先尝试本地重启，并在多次尝试失败后隔离故障节点，将任务调度到健康的节点上重新启动，同时拉取最近的 CKPT 继续未完成的训练。</p><p></p><p>除了自动的容错，我们也支持让用户手动来决策故障处理方案。在任务提交时，用户可以配置任务状态告警，侦测任务的状态变化，发送给对应的告警人。除了任务状态，我们也提供了针对任务的 loss 值的监控和告警，避免因模型结构、数据、超参数等配置错误导致的训练空跑。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5e/5e3d31df1248d2a06080e7529688c1ab.png\" /></p><p></p><p>在第 3 期的分享中为大家介绍了 CKPT 的存储加速相关原理，这里我们先快速回顾一下：</p><p></p><p>Checkpoint 是训练容错恢复的基础，多数训练框架均提供了原生的 CKPT 机制。原理也比较简单，在模型训练过程中为正在训练的模型打一个 checkpoint，也就是将显存里面的模型权重数据写到远端存储，这样在故障发生时可以回退到当时的训练状态，避免重训。</p><p></p><p>由于写 CKPT 和训练计算不能并行开展，且经过了显存到内存、内存到本地磁盘再到对象存储 BOS 多个写入路径，每次写 CKPT 的开销都比较大，导致大家会谨慎控制 CKPT 的频率，这就导致故障重启时往往会回退比较多的时间。这是我们最左边第一张图想表达的内容。</p><p></p><p>数据湖存储加速 RapidFS 可以利用本地内存和磁盘作为对象存储 BOS 的缓存层，这样 CKPT 的写入和对象存储 BOS 的上传可以异步操作。这样针对大模型训练可以实现分钟级 CKPT，有效地缩短训练任务的等待时间，让用户敢于使用 CKPT 机制。在一些大模型训练中，通常每小时会打一个 CKPT，这样算下来，仍然有 10% 左右的训练时间浪费。这就是我们中间第二张图表达的内容。</p><p></p><p>那么还有没有更好的办法呢？</p><p></p><p>大模型训练是一种离线计算，对故障和训练结果的丢失有一定容忍度，所以我们有了一个更为激进的策略，一方面训练框架直接把内存当成持久化存储，CKPT 写入内存成功后马上继续训练。另一方面，我们改进了之前 CKPT 单点写入的机制，让每个节点都可以分布式写入远端存储。最后，为了优化远端存储的效率，采用并行文件存储 PFS 可以进一步加速内存数据的落盘。通过这种机制，我们可以做到秒级 CKPT，最大程度上降低了容错带来的计算时间浪费。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/36/36f974c124464e98a5c729c0ce9a9e03.png\" /></p><p></p><h2>三、大模型训推加速实践</h2><p></p><p></p><p>首先介绍一下 AIAK。AIAK 是百度智能云面向 AI 计算推出的 AI 加速套件，和百舸平台深度融合，可以有效的提升模型训练效率和推理效率。AIAK 在之前的版本中就提供了梯度通信 Hook、分布式通信策略优化、高性能通信库等训练优化工具以及多框架多引擎加速，高性能算子库等推理加速能力。当然，这些能力在大模型场景下会不同程度上的复用。</p><p></p><p>面向大模型场景，我们提供了更多新的工具，主要是面向典型开源大模型的训练和推理的加速镜像以及配套的工具。接下来我展开介绍一下。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/52/529c87324c28c2057adc4490aa990fbf.png\" /></p><p></p><p>首先是模型训练加速，我们衡量一个模型训练的性能指标主要是训练吞吐，也就是每秒可以处理的 token 数量。这个指标受三个因素影响，分别为单卡训练吞吐、 GPU 卡数和多卡训练加速比。由于目前主流训练框架对多卡训练支持都比较好，同时 GPU 卡数是一个自变量，所以我们重点讨论单卡训练吞吐和多卡加速比。</p><p></p><p>理想情况下 GPU 单卡的所有计算单元 100% 的时间片都要计算，同时在扩展 GPU 数量时可以获得 100% 线性加速效果。但在大模型的实际训练过程中，多种模型并行策略会带来较多的时间「气泡」，也就是并行训练中部分计算单元的空等，同时节点的通信机制和物理链路的限制也会影响线性加速能力。</p><p></p><p>我们可以从硬件和软件两个层面来做优化，硬件优化包括了高性能异构芯片、高性能存储系统，以及和机内机间的高速网络。在软件层面我们通过算子融合、模型并行策略的调整和合理的调整重计算机制，优化单卡计算效率。这里其实有一个隐含约束，所有的优化都要考虑计算精度不退化同时超大的模型参数不会撑爆宝贵的显存资源，另外我们也通过优化并行通信和链路开销进一步提升多卡线性加速能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3b/3b172165bc1338567118378c68b709b7.png\" /></p><p></p><p>Megatron 是很多开发人员都在用的大模型并行训练框架，具有良好的性能优化基础。我们针对 Megatron 做了很多大多数模型优化工作。在产品上，AIAK Training 提供了大模型加速镜像，在 Megatron 框架上重构了开源模型的训练代码，加入了前面提到过的加速策略。我们做了全面的测试，保障可以和开源模型精度对齐，快速展开训练。</p><p></p><p>为了兼容其他的训练框架，我们也提供了模型转换和切分工具，一方面可以使用我们的加速镜像来对其他框架的基础模型做再训练或 SFT，同时也可以通过这些工具来实现多机训练的权重拆分。</p><p></p><p>从实测效果来看，使用 AIAK-Training 可以提升开源大模型 20% 左右的训练效果，尤其是针对大参数量的模型，性能优化效果更好。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/52/5284216d89753ef3729f3649547c96cb.png\" /></p><p></p><p>大模型推理一般情况下是在线服务，除了要优化性能外也要考虑用户体验，所以我们优化推理性能的目标可以概括为在保障首 token 延迟可控的基础上做到吞吐最大化。</p><p></p><p>我们知道，GPU 是可以并行处理推理请求的。通过批量地执行推理任务，可以有效提升 GPU 吞吐。在大模型场景下有个特殊的挑战就是输出不定长的问题，也就是我们问模型一句话，得到的答案长度是不确定的，同时请求处理时间从小模型的几十毫秒变为秒级别，这使得我们之前很多的优化策略失效或者低效。</p><p></p><p>从单卡的视角来看，并行执行的一组推理请求需要处理完成后才会返回。由于输出是不定长的，导致一些短输出的请求出现空等状态，据统计至少浪费 30% 的算力。另外，由于推理请求是顺序到达的，后续的请求也要等到前一组请求完成后才能进入队列，也增加了单位请求的排队时间和响应时间。</p><p></p><p>从整个集群的视角，通常推理的 API 网关会轮询地向每个节点分发请求，同样因为每个请求的处理时长不一致，容易导致出现节点间的负载不均。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/14/146662173146b83a1d6a8d7929e1c056.png\" /></p><p></p><p>针对这些问题，我们引入了动态 batch 的机制。</p><p></p><p>首先，把上下文处理过程和内容生成环节拆分开，不再统一调度。其次，通过动态槽位控制机制重新组合这些计算请求，尽量填满计算单元的时间片。同时也将多个流之间的调度方式拆散，每个流都可以独立的动态组装计算任务。</p><p></p><p>由于这种动态机制和模型结构有比较大的关联，我们对一些主流的大模型都进行了适配，经过实测，模型吞吐和平均请求延迟都有 40% 以上的提升。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1b/1b443e08ce052c7546241cb2595af371.png\" /></p><p></p><p>针对节点间负载不均的问题，我们引入了分布式队列和 pull 模型。所有业务侧的请求先入队列，每个推理实例基于自己的真实负载拉取请求，处理失败的请求可以重入队列重新处理，保障输出结果。</p><p></p><p>通过这种方式，可以有效地避免产生热点实例并降低请求的排队时间，这个方案在百度内部已经规模化落地，可以提升一倍以上的推理吞吐。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cd/cd324b3d2d29253d8c38c78e8ade7a64.png\" /></p><p></p><p>在产品上，百舸平台提供了大模型推理加速镜像，集成了一系列的推理加速机制，支持主流的开源模型，同时内置了 Triton 高效推理引擎，支持 KerverV2 版本的协议兼容，可以更好的和生态打通。</p><p></p><p>百舸平台提供了大模型的部署工具，包括了完整的异步推理服务和模型权重转换工具，让推理更加高效。还提供了一些模型调试工具，帮助用户快速体验加速效果。右面是我们的一些实测数据，在保障首 token 延迟可控的前提下，使用 AIAK-Inference 的推理加速方案，主流大模型的吞吐均可提升 1-2 倍，大幅降低了推理成本。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9c/9cacdb283bf682bfea4efe7a72aeeb50.png\" /></p><p></p><p>以上为第八讲的所有内容，希望大家能够对百度百舸平台的了解更进一步。至此，《大模型时代的 AI 基础设施——百度 AI 大底座》系列云智公开课的“夏季内容”便完结了。</p><p></p><p>同时做一个活动预告，在 9 月 5 日，百度智能云将举办「2023 百度云智大会」。大家可以点击<a href=\"https://cloud.baidu.com/summit/AIcloudsummit_2023/index.html?track=infoQ\">链接</a>\"报名参加大会，了解百度智能云在大模型方向的最新进展。</p>",
    "publish_time": "2023-08-22 11:36:44",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AIGC 是来颠覆还是加入低代码的？",
    "url": "https://www.infoq.cn/article/CNrqLvEVAOJKTQqpDNJr",
    "summary": "<p>随着以 ChatGPT 为代表的大模型的爆火，AIGC 狂飙态势仍在继续并快速渗透到各行各业，低代码赛道也不例外。AIGC + 低代码、AI 生成式开发、AIGS 等概念的涌现，似乎预示着 AI 新时代下低代码正在发生着深刻变革。当“整个产业都会被 AI 重做一遍”成为共识，低代码赛道的背后又是怎样的“暗流涌动”？</p><p></p><p>近期，InfoQ 联合钉钉围绕“AI 新时代的低代码”，邀请了多位低代码赛道的资深从业者，他们分别是：钉钉宜搭平台负责人叶周全；易鲸云 CEO 刘金柱；伙伴云产品总监吴杨；轻流产研负责人陆琦；氚云产品总经理詹萧；简道云运营负责人沈涛以及主持嘉宾极客邦科技创始人兼 CEO 霍太稳，7 位嘉宾共同打造了这期《再问低代码：AI 巨浪下》栏目，共同探讨 AI 新时代，低代码面临哪些机遇与挑战？低代码与 AIGC 融合探索的路径是什么？如何让 AI 发挥更强大的底座能力？本文结合嘉宾们的精彩分享探索新思路。</p><p></p><p></p><p></p><p></p><h1>低代码遇上 AIGC，被颠覆还是融合？</h1><p></p><p></p><p>AI 浪潮下，大厂率先起跑，低代码赛道开始“暗流涌动”，业内集体发出感叹“这一波浪潮来得实在太快”。巨浪背后便是前所未有的压力，例如竞争壁垒的冲击、产研投入的巨大压力、商业模式和定价结构的改变等，都给低代码行业带来新的挑战与冲击。正如轻流产研负责人陆琦所说，“AI 能力将成为低代码平台标配，大家都上，你不上就没有竞争力。”</p><p></p><p>面对这些冲击，AIGC 是否会彻底颠覆低代码？对此问题，氚云经过内部推演，产生了颠覆方和融合方两个“派别”。“颠覆方认为，今天所有的‘程序’最终都会走向类似 Jarvis 的 AI 助手，而应用会被拆分成助手的任务流。而融合方认为，深度学习网络没有解决知识表征问题，颠覆性有限，但能很好的转译需求，与低代码互补。”氚云产品总经理詹萧说道。</p><p></p><p>钉钉宜搭平台负责人叶周全认为是颠覆还是融合需要从不同视角看待。他表示，“从低代码厂商角度看，融合是未来发展趋势，但从用户角度看，高频场景可能会被彻底颠覆而其他场景则是融合。可以肯定的一点是，低代码与 AIGC 越早融合，越能产生 AI-Native 的应用。”AI-Native 是面向基础设施、基础架构的理念，它能够更好地让 AI 的能力赋能到业务当中，AI-Native 的应用能够从头到尾完成用户的任务，让用户尽可能多地减少工作步骤来实现目标。</p><p></p><p>面对众多声音，InfoQ 认为，判定低代码与 AIGC 融合路径的确定方向还为时尚早，但可以肯定的是，AIGC 并不能从完全意义上彻底颠覆低代码。原因在于：第一，AIGC 不会改变低代码的底层逻辑，其提升企业的应用开发效率以及促进人人开发的优势并不能被完全取代；第二，大模型通过语义直接生成代码并不能保证其完全的准确性，且代码可用性需要大量的人工校正。相反，低代码融合 AIGC 可以通过语义生成模型，加速需求分析工作进程，让 AI 的底座能力真正进入业务。</p><p></p><p>同时，随着 AI 技术的快速发展，其潜在价值也在不断增长，AIGC 赋能低代码行业可能带来多方面的增强。首先，产品体验感的提升，借助 AIGC，低代码在产品体验上可能会弯道超车，追平 SaaS 体验，甚至超越 C 端软件。通过大模型分析大数据和用户行为模式，自动优化用户界面、交互和流程，从而提供更符合用户期望的产品体验；其次，开发效率的提升，AIGC 通过智能化建议，协助开发者进一步优化用户体验，加速开发过程，降低开发者门槛，让“人人都是开发者”走进现实；此外，在应用交付层面，借助 AI-Agent 的能力，低代码交付环节的效率也能得到大幅提升。AI-Agent 的工作方式类似于人类代理，它能够接收输入数据，例如传感器信息、文本、图像等，通过分析和处理这些数据，理解环境和任务要求，并作出相应的决策和行动，这样可以极大减少人工成本，提升效率。</p><p></p><p>低代码与 AIGC 融合的价值不言自明，在融合发展中如何让 AI 的底座能力转化成生产力，需要一个落脚点，而这个落脚点就是业务场景。</p><p></p><h1>低代码 +AIGC：业务场景适配是关键</h1><p></p><p></p><p>尽管 AIGC 有着强大的智能计算能力、更广泛的数据语料资源、更通用的任务训练模型以及更灵活的信息参与模式，但它并不是万能的。事实上，AIGC 只是一种技术，而技术价值的发挥则需要找到适配的业务场景。</p><p></p><p>那么，低代码 +AIGC 实现场景落地了吗？简道云运营负责人沈涛表示，“现在有一些自然语言搭建表单页面、编写函数、查询数据的应用。”“目前来看，AIGC 主要应用场景还是在容错率较高的领域，比如文本加工，图像生成，但在 B 端软件对输出结果至少要达到 &lt; 0.01% 容错率才能交付。”氚云产品总经理詹萧补充道。这似乎意味着在涉及复杂业务逻辑和多样化数据的 B 端软件应用场景中，要让大模型表现出色依然有一定难度。不难看出，低代码与 AIGC 的融合探索仍处于早期阶段，在探索的路上仍有诸多问题亟待解决。</p><p></p><p>一方面，AI 新时代，未来低代码不应该只是代码的逻辑，终局是通过“聊天”即“Prompt”就能直接生成应用，这才是生产率的质变。但真正要用交互把生成应用的体验做得非常好，还要解决很多问题。比如大模型在做低代码应用时，AIGC 能不能跟人的意图对齐，充分了解庞大的上下文，尤其在应用生成复杂度更高的场景。另一方面，数据安全风险的考量则是商业化上较大的难点，我们看到，多数企业并不会用 ChatGPT 去做低代码开发应用原因在于接入外部 API，核心业务逻辑可能存在外漏的风险。面对这一问题，能够解决的办法之一就是自研大模型，然而自研大模型对于大多数企业而言并不是一件容易的事。它需要大量高质量数据的收集、清洗和标注，以及昂贵的计算资源来支持模型训练。模型的架构设计、训练算法和超参数调整需要深入的领域知识和大量实验。此外，模型大小和存储、时间和人力投入、评估和测试都是必须要考虑的因素。</p><p></p><p>面对这些问题，开放生态或许是让低代码与 AIGC 创新融合并走向更远的解决路径。</p><p></p><h1>全面生态开放，让 AI 深入千行百业</h1><p></p><p></p><p>如果说让大模型变成类似于“云服务器”的基础设施，是 AI 走向千行百业的必经之路，那么如何让低代码更好地结合与调用 AI 的底座能力则是未来企业实现业务智能升级的突破口。我们看到，钉钉一直在这条路上探索。</p><p></p><p>就在今天的 2023 钉钉生态大会上，钉钉宣布开放 AI PaaS。什么是 AI PaaS？大模型要从 Chat 进入 Work，变成真正的生产力工具，必须要进入应用场景，然而目前大模型无法直接运用于应用场景，AI PaaS 可以下接大模型能力，上接千行百业的用户真实需求，让大模型的能力真正进入到工作场景。也就是说，企业无需以自己的数据去训练模型就可以应用大模型结合自身业务场景，实现场景落地。更重要的是，在 AI PaaS 中，钉钉通过解决大模型的安全问题、性能问题，降低开发运维的门槛，降低大模型的不确定性，帮助企业数据与大模型建立联系，让大模型能力真正为协同和业务所用。</p><p></p><p>此次钉钉将 AI PaaS 开放给生态伙伴和用户，标志着钉钉智能化进入生态层，和生态一起完成智能化对钉钉产品和生态产品的再造。同时，AI PaaS 的开放，也是钉钉 PaaS 化战略的进一步深化。</p><p></p><p>事实上，早在 2022 钉钉生态大会上就宣布了生态开放，提出“PaaS First Partner First”战略，明确“钉钉只做一件事，就是 PaaS 化”。此后，钉钉陆续推出 bPaaS、iPaaS、dPaaS 等，不断向生态伙伴开放底座能力。今年，钉钉宣布接入通义大模型，新钉钉将全面走向智能化。直到如今 AI PaaS 的开放，让我们看到，钉钉正在构建 AI 时代的智能生态体系，努力让更多人用上 AI，或让 AI 像加入低代码一样，深入千行百业。</p><p></p><h1>写在最后</h1><p></p><p></p><p>低代码与 AIGC 的融合探索，让我们看到未来企业数智化转型的新路径。然而，AIGC 并非解决一切问题的万能工具，低代码也不是，两者只有在解决实际业务问题上持续思考，彼此的互补，才能充分释放其潜力。同时，低代码与 AIGC 的融合不仅仅需要技术上的创新，更需要思维的转变，以更加开放的心态构建 AI 生态，才能激发出更强大的创新力量。而这种创新力量的释放值得所有人期待。</p>",
    "publish_time": "2023-08-22 13:44:27",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Alibaba Cloud Linux：为倚天实例打造最佳OS体验",
    "url": "https://www.infoq.cn/article/02zUXdPgwSqEVfzhJLjj",
    "summary": "<p><img alt=\"\" src=\"https://static001.infoq.cn/resource/image/60/91/602e18ff1c49a3f5e637e53a55b24491.jpg\" /></p>",
    "publish_time": "2023-08-22 14:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "挑战阿里巴巴和Meta：Arm即将上市，软银力争打造科技史第三大IPO",
    "url": "https://www.infoq.cn/article/MUpvYzE3rDFKo4bNhlZG",
    "summary": "<p></p><blockquote>Arm 的设计几乎垄断了智能手机，市场份额超过 99%。另外，招股说明书显示，Arm 近四分之一的收入依赖中国。</blockquote><p></p><p>&nbsp;</p><p></p><h2>今年最大规模的 IPO</h2><p></p><p>&nbsp;</p><p>软银旗下的Arm公司于今天凌晨申请首轮公开募股（IPO）。该公司决定上市也是在试水如今波涛汹涌的IPO市场。由于过去一年来席卷全球的加息活动正严重打击风险资产的兴趣，IPO市场也开始收紧对新股上市的控制。</p><p>&nbsp;</p><p>Arm是科技领域最重要的厂商之一，其芯片设计几乎应用于全球一切智能手机，包括苹果iPhone和大多数Android设备。对于自2022年以来就持续低迷的IPO市场来说，Arm的首次亮相将是一件大事，同时也将对其老东家软银产生重大影响。</p><p>&nbsp;</p><p>Arm此番赴美上市，将成为自美国造车新势力Rivian在2021年11月筹资额137亿美元以来，美国规模最大的一次IPO。而软银希望 Arm 此次IPO募集金额的规模能够成为科技史上第三大IPO：阿里巴巴于 2014 年筹集了 250 亿美元的资金，Meta（当时称为 Facebook ）于2012 年筹集了 160 亿美元。</p><p>&nbsp;</p><p>软银创始人孙正义则表示他希望此次亮相能成为芯片行业历史上“规模最大”的一次。其他传闻表明，Cortex CPU 设计商的几家最大客户——包括苹果、英伟达、三星和亚马逊——计划成为该公司的主要投资者。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cc/cc2d9c07d7ed0e4621540824f762d8e1.jpeg\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>软银一直试图控制增长型投资，并将重点转向下最具热度的AI议题，借此在形势严峻的科技市场中逆转反弹。由于在能源受限的手机领域拥有专业知识，Arm 认为其产品更适合运行最新一代人工智能平台。在上市公司中，当前人工智能热潮的主要受益者是英伟达公司，5 月份，狂热的投资者将英伟达的市值首次推高至 1 万亿美元以上。</p><p>&nbsp;</p><p>根据此前外媒的报道，软银希望Arm估值在600亿到700亿美元范畴（约 4308 亿至 5026 亿元人民币）。Arm的IPO文件中没有列出计划出售的股票数量，此前的猜测表明，软银可能会出售 10% 的 Arm 股票。</p><p>&nbsp;</p><p></p><h2>Arm的历史</h2><p></p><p>Arm总部位于英国剑桥，其设计的芯片架构被应用在99%的智能手机之上。</p><p>&nbsp;</p><p>该公司的历史可以追溯到一家名叫Acorn Computers的早期计算公司。1990年，Acorn又与苹果和美国芯片制造商VLSI Technology合资建立了Advanced RISC Machines这家新公司。</p><p>&nbsp;</p><p>Arm本身并不属于芯片制造商。相反，该公司只负责提出“架构”或者整体设计，包括可供其他公司用于构建芯片的组件和编程语言指令。其最初的发展目标，就是设计出与PC设备中常规x86相比能耗极低的计算芯片。很多人把Arm视为科技领域的“瑞士”——即永远保持厂商中立。Arm推出的设计方案几乎被应用于一切智能手机处理器，包括苹果制造的处理器，而且近年来也被越来越多地应用于服务器和笔记本电脑。</p><p>&nbsp;</p><p>Arm，已然成为英国科技行业皇冠上的明珠。Arm公司CEO Rene Haas在2022年10月的开发者大会上接受采访时曾表示，鉴于该公司的技术几乎嵌入到一切设备当中，已经没有哪家企业能够完全避免跟Arm合作。Haas当时指出，“考虑到我们将技术授权给行业内的所有主要参与者，已经没人能真正承担我们延误产品周期、缩减研发规模或者不发布产品的后果。”</p><p>&nbsp;</p><p>Arm的商业模式就是对外授权这些架构知识产权，客户可以据此自行构建系统。近年来，Arm还努力出售自己的处理器设计，这项业务的利润空间要比仅授权底层架构技术更加可观。</p><p>&nbsp;</p><p>2016年，软银方面同意以320亿美元收购Arm，这也是当时欧洲科技界有史以来规模最大的一笔收购。软银当时表示，收购该业务是为了在不断发展的物联网领域站稳脚跟。尽管物联网只是其业务版图上的一小部分，但当时却在科技领域拥有极高的热度和号召力。</p><p>&nbsp;</p><p>Arm不仅被广泛应用于可穿戴设备和智能家电，同时也在将业务触角延伸至联网汽车等其他场景。</p><p>&nbsp;</p><p>根据软银发布的财报，截至6月30日的上季度，Arm公司共创造了885亿日元（约合6.055亿美元）的收入。但Arm公司也面临着智能手机等产品需求放缓的不利因素，这波冲击正全面影响所有芯片厂商。因此，Arm本季度的净销售额同比下降了4.6%。与上年同期的298亿日元盈利相比，Arm在本季度遭遇95亿日元亏损，运营收益开始由正转负。</p><p>&nbsp;</p><p>值得关注的是，Arm中国（安谋科技）是Arm最大的客户。2023财年，前五名客户合计占Arm总收入的57%，其中安谋科技分别占其总收入24%。</p><p>&nbsp;</p><p>Arm在IPO文件中明确提及Arm与安谋科技的关系：安谋科技是Arm的重要收入来源及中国市场的重要渠道，是向中国客户转授Arm IP许可的独家分销商。</p><p>&nbsp;</p><p></p><h2>困难重重的英伟达收购案</h2><p></p><p>&nbsp;</p><p>Arm 的员工数量相对较少，约为 6,000 人。但很少有公司能在科技生态系统中走得这么远：已经有超过 2500 亿颗芯片采用 Arm 技术制造。这使得 Arm 成为了虚拟的行业标准。</p><p>&nbsp;</p><p>它的战略重要性如此之大，以至于当软银在 2020 年决定将该公司出售给英伟达时，引起了 Arm 客户的强烈抗议，最终终止了这笔 400 亿美元的交易。批评人士表示，收购将威胁 Arm 成功的基石：中立性。</p><p>&nbsp;</p><p>收购受挫，软银随即决定将Arm作为独立公司上市。据报道，这家日本科技投资巨头打算动用总值达1000亿美元的愿景基金（Vision Fund），以收购目前尚未掌握的25% Arm股份。</p><p>&nbsp;</p><p>英国一直认为Arm拥有极其重要的战略意义，并有意通过高达10亿英镑（约合13亿美元）的投资推动国内芯片产业发展。而英国科技界也不愿意将Arm所有权变更为外国人，担心这会损害英国的“技术主权”。实际上这个问题在整个欧洲都普遍存在，各国官员也在努力加以解决，摆脱对美国及其他国家的技术依赖。英国政府曾大力推动Arm在伦敦上市，但该公司此次却仍然选择了纽约，这无疑是对伦敦证券交易所的沉重一击。</p><p>&nbsp;</p><p></p><h2>Arm IPO定位为人工智能领域</h2><p></p><p>&nbsp;</p><p>尽管美国市场一直动荡起伏，但软银仍策动Arm在美上市。目前，科技企业估值较2021年的繁荣期峰值出现了大幅下跌。</p><p>&nbsp;</p><p>2021年，由于全球投资者对于繁荣增长的前景感到兴奋，Palantir和UiPath等新成立的上市公司均在短时间内将股价抬升到了惊人水平。</p><p>&nbsp;</p><p>Arm今年5月份就秘密申请在美上市，Arm 首席执行官将 Arm IPO<a href=\"https://www.bloomberg.com/news/articles/2023-05-30/arm-chief-pitches-chip-designer-as-ai-play-in-buildup-to-ipo\">定位为人工智能领域</a>\"，希望能在这次AI热潮中得到一个好估值。Arm不仅是芯片行业的领头羊，同时也在AI领域发挥着重要作用，并开始更多标榜自己AI厂商的身份。投资者将密切关注该公司的S-1文件，了解Arm如何通过规划将AI技术的发展转化成业务收益。</p><p>&nbsp;</p><p>今年5月，Arm推出了两款针对机器学习应用的新芯片组。据Arm介绍，其中一款为新型Cortex-4&nbsp;CPU芯片组，能够在改善机器学习性能的同时将功耗较前代芯片降低40%。另一款则为G720 GPU芯片组，可在提供更好的性能同时将内存带宽占用量较前代减少22%。</p><p>&nbsp;</p><p>该公司在5月29日发布的产品博文中指出，“Arm仍在致力于针对机器学习（ML）新应用，开发并测试我们的GPU。”</p><p>&nbsp;</p><p>英伟达和AMD等高性能芯片对于AI应用而言至关重要，这些应用需要借助大量算力才能顺利运行。本月早些时候，英伟达发布了用于生成式AI应用的新型Grace Hopper芯片，设计采用的正是Arm架构。</p><p>&nbsp;</p><p>软银希望AI的增长能够支撑起愿景基金的发展路径，缓解该基金之前几年因押注WeWork、中国网约车巨头滴滴出行和Uber等而造成的价值缩水。由于回报不佳，愿景基金已经将所持Uber股份抛售殆尽。</p><p>&nbsp;</p><p>软银公司CFO后藤芳光在6月的季度财报电话会议上表示，该公司一直在“谨慎而缓慢地恢复投资活动”，目前的重点关注方向为人工智能。</p><p>&nbsp;</p><p>软银还提到，其愿景基金实现了1598亿日元的投资收益，这也是过去五个季度以来首次实现收益回正。软银指出，该基金的复苏主要受益于对旗下子公司（包括Arm）的投资。</p><p>&nbsp;</p><p>此前，软银愿景基金曾报告称，截至3月31日其上财年的总亏损额已达创纪录的4.3万亿日元。</p><p>这家日本科技巨头近期还开始大谈在AI领域的投资。就在刚刚过去的7月，软银领投了对英国保险科技公司Tractable的6500万美元投资。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.cnbc.com/2023/08/21/arm-ipo-what-it-means-for-ipo-market-softbank.html\">https://www.cnbc.com/2023/08/21/arm-ipo-what-it-means-for-ipo-market-softbank.html</a>\"</p><p><a href=\"https://www.ft.com/content/36bc706f-66a1-48e3-8c20-ab4966cb0fce\">https://www.ft.com/content/36bc706f-66a1-48e3-8c20-ab4966cb0fce</a>\"</p><p><a href=\"https://www.theregister.com/2023/08/21/arm_ipo_official/\">https://www.theregister.com/2023/08/21/arm_ipo_official/</a>\"</p><p><a href=\"https://www.theregister.com/2023/08/18/softbank_snaps_up_vision_funds/\">https://www.theregister.com/2023/08/18/softbank_snaps_up_vision_funds/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/ErbwGSrFJ4cFauGv5ys0\">660 亿美元收购案告吹！英伟达收购 Arm 失败，软银将获得 12.5 亿美元“分手费”</a>\"</p><p><a href=\"https://www.infoq.cn/article/dW6sXTilW8uajezLmi3B\">Arm 最新架构不受美国出口管理条例约束，华为有机会获授权</a>\"</p><p><a href=\"https://www.infoq.cn/article/VFO6mFhtBuWIpkDNl3M4\">汽车芯片成 Arm 增长发力点，分析师：汽车市场至关重要，目前还未分出胜负</a>\"</p>",
    "publish_time": "2023-08-22 14:20:22",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "钉钉全面智能化第二弹：用大模型帮助生态把产品重做一遍",
    "url": "https://www.infoq.cn/article/FBepP6s3ScqrD86XQMLf",
    "summary": "<p>8月22日，在2023年<a href=\"https://xie.infoq.cn/article/98007fceb3c438e86f95ac8a6\">钉钉生态大会</a>\"上，钉钉总裁叶军公布了钉钉全面智能化的最新进展：已有17条产品线、55个场景全面接入大模型，完成智能化再造；钉钉同时面向生态伙伴和客户开放智能化底座AI&nbsp;PaaS，表示将用大模型帮助生态把产品重新做一遍。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/33/337b965137e89b4bfba0210a4650b619.png\" /></p><p>&nbsp;</p><p>叶军现场实景演示了基于AI&nbsp;PaaS和生态伙伴共创的新产品“数字员工”，以及会议、点餐、教育等多种场景、行业的AI解决方案。今年4月18日，钉钉曾宣布将用大模型把钉钉重做一遍。</p><p>&nbsp;</p><p>钉钉还率先给出了行业内首个大模型落地应用场景的商业化方案：在钉钉专业版年费9800元基础上，增加10000元即可获得20万次大模型调用额度；在专属钉钉年费基础上，增加20000元即可获得45万次大模型调用额度。相当于一次调用平均只需不到&nbsp;5分钱。</p><p></p><h2>开放AI&nbsp;PaaS，钉钉智能化进入生态层</h2><p></p><p>&nbsp;</p><p>去年3月22日，钉钉在2022年生态大会上宣布全面开放生态，提出“PaaS&nbsp;First&nbsp;Partner&nbsp;First”战略，明确“钉钉只做一件事，就是PaaS化”。</p><p>&nbsp;</p><p><a href=\"https://xie.infoq.cn/article/12ab6ca058c3ee293ad269a3d\">PaaS</a>\"化指的是，钉钉只做基础能力和基础产品，并将这些能力和产品作为底座开放给生态。PaaS化是一个分阶段的过程。钉钉在2021年提出的低代码（aPaaS）革命，走出PaaS化的第一步。此后，钉钉陆续推出了bPaaS（酷应用）、iPaaS（连接平台）、dPaaS（数据平台）等，不断向生态伙伴开放底座能力。</p><p>&nbsp;</p><p>截至今年3月31日，钉钉已有5000多家生态伙伴，包括独立软件开发商（ISV）、咨询生态、销售及交付服务商以及硬件生态厂商。钉应用数已超过1000万，其中低代码应用数超过800万。钉钉上年营收过千万的伙伴达到25家，钉钉每收入1块钱，就会给生态合作伙伴带去9块钱。</p><p>&nbsp;</p><p>2023年，<a href=\"https://www.infoq.cn/article/CNrqLvEVAOJKTQqpDNJr\">AIGC</a>\"浪潮袭来，在4月18日的春季钉峰会上，钉钉宣布接入通义大模型，并发布了一条“斜杠”（魔法棒），现场演示了聊天、文档、音视频会议等4大高频场景中的智能化应用。钉钉总裁叶军表示：“要用大模型把钉钉重做一遍。”在随后的100多天里，钉钉已经有17条产品线、55个场景完成了智能化再造。</p><p>&nbsp;</p><p>5月31日，钉钉启动了“斜杠”（魔法棒）邀测，邀请各行各业的客户和生态伙伴参与共创。</p><p>&nbsp;</p><p>本次生态大会上，钉钉宣布将智能化底座（AI&nbsp;PaaS）开放给生态伙伴和客户，要用大模型帮助生态伙伴把产品重做一遍。这标志着钉钉智能化已全面进入生态层。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/95/957d54937cb6f969ed6b305e04dea7b8.png\" /></p><p></p><p>钉钉总裁叶军认为：“大模型要从‘玩具’变成生产力工具，必须进入应用场景，但首先要解决模型输入和输出的可靠性问题。AI&nbsp;PaaS解决了大模型的数据安全问题、性能问题，让大模型进入企业上下文场景，降低大模型的不确定性，降低开发运维的门槛，帮助企业数据与大模型建立联系，让大模型能力真正为工作所用。”</p><p></p><h2>联合生态推出“数字员工”等智能化产品和解决方案</h2><p></p><p>&nbsp;</p><p>钉钉现场实景演示了AI&nbsp;PaaS上长出的创新产品——数字员工，以及多款智能化场景方案和智能化行业方案。</p><p>&nbsp;</p><p>数字员工是参与到业务流程中的虚拟员工。数字员工能以企业员工助手的身份，进入企业通讯录，取得对应的职务权限，参与到企业的组织治理和业务协同中去。作为企业员工的有力辅助，数字员工能够协助完成枯燥重复程序化的工作，让企业员工将更多精力用于创造性工作。</p><p>&nbsp;</p><p>目前，钉钉正与1号直聘、有成CRM、易鲸云、i人事、酷学院、经营大脑winplan等多家生态伙伴一起探索数字员工。现场演示的与1号直聘共创的数字员工“招聘专员（1号招招）”，可以帮助企业的HR写招聘启事、发布到相应招聘网站、回收简历、筛选简历并预约面试。真实员工与数字员工的交流通过自然语言即可完成。</p><p>&nbsp;</p><p>此外，钉钉还联合生态一起发布了会议场景、点餐拼单场景的智能化解决方案，并为教育行业打造了一款“AI小助教”。在钉钉音视频会议中，“数字分身”可以代替用户列席会议，帮助用户了解会议的重要信息，会后还可以推送会议总结；点餐拼单场景智能化方案“快乐拼”是钉钉联合饿了么共同打造，用户可以在钉钉群内用自然语言点单、拼单，无需离开群聊一键付款。“AI小助教”则可以帮助教师智能批改作业、沉淀学情数据，生成备课建议和讲解用的PPT等。</p><p>&nbsp;</p><p>目前，钉钉已上线AI智能应用市场，首批11款智能化SaaS已经上架。</p><p></p><h2>发布大模型应用场景定价方案，平均一次调用不到5分钱</h2><p></p><p>&nbsp;</p><p>对于备受关注的大模型落地应用场景的收费问题，钉钉也给出了明确的方案：钉钉专业版年费9800元基础上，增加10000元即可获得20万次大模型调用额度；在专属钉钉年费基础上，增加20000元即可获得45万次大模型调用额度。相当于一次调用平均只需不到&nbsp;5分钱。</p><p>&nbsp;</p><p>过去，钉钉一直致力于不断降低千行百业的数字化门槛，此次钉钉通过开放AI&nbsp;PaaS和发布智能化商业定价体系，进一步降低了智能化应用的门槛，用AI&nbsp;PaaS解决生态伙伴和客户“用得上”大模型的问题；用行业内首个定价体系，解决中小企业“用得起”大模型的问题。</p><p>&nbsp;</p><p>钉钉总裁叶军表示：“开放已经成了钉钉的一种信仰，钉钉的全面智能化离不开生态伙伴的参与。大模型时代，中国SaaS的黄金十年才刚刚开启。”</p><p>&nbsp;</p>",
    "publish_time": "2023-08-22 14:23:46",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "火山引擎VeDI DataWind 研发负责人徐冰泉确认出席QCon北京，分享BI+AI，撬动千亿级数据的智能洞察实践",
    "url": "https://www.infoq.cn/article/qmtV8E7fmWVAA3vMMdop",
    "summary": "<p>9 月 3 日 - 5 日，在 <a href=\"https://qcon.infoq.cn/202309/beijing/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=0822&amp;utm_content=xubingquan\">QCon 全球软件开发大会（北京站）</a>\"上，火山引擎 VeDI DataWind 研发负责人徐冰泉将发表题为《BI+AI，撬动千亿级数据的智能洞察实践》主题分享，介绍字节跳动数据团队在 BI 平台建设上如何融合 AI 能力，保障 5 万多业务用户进行自助分析的实践经验总结。</p><p></p><p><a href=\"https://qcon.infoq.cn/202309/beijing/presentation/5398?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=0822&amp;utm_content=xubingquan\">徐冰泉</a>\"，火山引擎 VeDI 数智平台 DataWind 研发负责人，深耕商业智能 BI+AI 领域，先后就职于 Morgan Stanley、eBay，目前在火山引擎 VeDI 数智平台，支持抖音集团数万人的业务智能洞察与平台建设服务，对商业智能 BI+AI 有丰富的经验与思考总结。他在本次会议的演讲内容如下：</p><p></p><p>演讲：BI+AI，撬动千亿级数据的智能洞察实践</p><p></p><p>进入 VUCA 时代，不确定性成为所有企业发展必须要面对的挑战，基于数据而洞察客户需求，应对竞争态势变化，推动业务发展，已经成为广大企业经营管理者的共识。目前，字节跳动业务线多，业务形态复杂，业务分析诉求各不相同，团队业务分析能力参差，数据量巨大，在业务自助分析、基于数据进行业务策略的快速迭代等方面，遇到的挑战是前所未有的，本次演讲将从抖音集团业务分析场景出发，重点分享字节跳动数据团队在 BI 平台建设上如何融合 AI 能力，保障 5 万多业务用户进行自助分析的实践经验总结，希望能够给业界带来新的思路。</p><p></p><p>演讲提纲：</p><p></p><p>背景与趋势</p><p></p><p>○ BI 发展史：从报表工具到智能分析决策平台</p><p>○ 字节企业级数据分析平台发展历程</p><p>○ 字节 ABI 平台如何 3 年内做到 5 万 DAU</p><p>○ 从夯实基础到创新突破的蜕变</p><p></p><p>字节高性能数据分析架构方案</p><p></p><p>○ 字节千亿级数据分析平台整体架构</p><p>○ 在 ClickHouse 上的深度自研优化</p><p>○ 多级聚合加速方案</p><p>○ 精细化性能治理与优化</p><p></p><p>BI+AI 实现智能数据洞察</p><p></p><p>○ AI 数据建模</p><p>○ 智能指标归因</p><p>○ 基于大模型的智能数据助手</p><p></p><p>总结与展望</p><p></p><p>○ 趋势 1：从增强分析到协作与共享发现结果</p><p>○ 趋势 2：大模型在数据分析领域的探索方向</p><p></p><p>你将获得：</p><p></p><p>○ 了解字节跳动对于大数据量查询的性能优化经验与成果</p><p>○ 了解字节跳动的 BI+AI 技术与产品建设经验</p><p>○ 了解 BI+AI 大数据平台的发展趋势与前景</p><p></p><p>除上述演讲外，QCon 北京还将围绕 <a href=\"https://qcon.infoq.cn/202309/beijing/track/1556?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10\">FinOps&nbsp;落地</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1570?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10\">云原生</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1567?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10\">AIGC&nbsp;浪潮下的研发效能提升</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1558?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10\">业务安全技术</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1552?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10\">面向&nbsp;AI&nbsp;的存储</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1557?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10\">从&nbsp;BI&nbsp;到&nbsp;BI+AI，新计算范式下的大数据平台</a>\"等进行分享。</p><p></p><p>110+ 名嘉宾、近 30 个精彩专题、8 种交流活动，QCon 北京 2023，相约 9 月！咨询购票请联系 18514549229（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/33/33cbbbf20baa8b2a18db4f0681f159aa.jpeg\" /></p><p></p>",
    "publish_time": "2023-08-22 15:14:49",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "独家对话AGI模型“之父” Marcus Hutter：AI 能完成人类半数的工作，但让人类失业是一件美好的事情",
    "url": "https://www.infoq.cn/article/UAupCc1Z0NppCUHEqoRE",
    "summary": "<p>自去年 11 月底正式发布以来，OpenAI &nbsp;最新的 AI 聊天机器人 ChatGPT 火出天际，成为现象级应用，在全网话题度狂飙。</p><p>&nbsp;</p><p>瑞银发布的研究报告称， ChatGPT 推出后，今年 1 月的月活跃用户估计已达 1 亿，成为历史上用户增长最快的消费应用。</p><p>&nbsp;</p><p>自 ChatGPT 走红后，全球互联网大厂、创业公司纷纷加码布局，一场关于 ChatGPT 的军备竞赛已然拉开。那么，这类大语言模型到底有什么魔力能让全网沸腾？是否参数越大，大模型就越智能？大模型当前面对的技术挑战是什么？突破口又在哪里？我们又该如何降低算力成本？</p><p>&nbsp;</p><p>近期，InfoQ有幸邀请到了澳大利亚国立大学计算机科学研究学院荣誉教授，AIXI模型（AGI学术圈内有望达到通用人工智能的模型之一）的提出者Marcus Hutter，华院计算技术（上海）股份有限公司董事长、创始人宣晓华，共同探讨大模型的现在和未来。</p><p>&nbsp;</p><p>以下为访谈实录，经编辑。</p><p>&nbsp;</p><p>InfoQ：很高兴有机会能采访到您两位，能向我们的读者介绍下您自己吧，先从Marcus教授开始吧。</p><p>&nbsp;&nbsp;</p><p>Marcus Hutter：我叫Marcus Hutter，教育背景是物理、计算机科学和数学。在尝试了几种方向之后，我从2000年开始专注于通用人工智能（AGI）的研究。最开始的6年是在瑞士一家名叫IDSIA的小型研究机构工作。之后我在2006年搬到了澳大利亚，并在澳大利亚国立大学任人工智能教授。我的研究重点，主要是通用人工智能的数学基础。</p><p>&nbsp;</p><p>InfoQ：最初接触AI，是什么激发起了您研究这门科学的兴趣？</p><p>&nbsp;</p><p>Marcus Hutter：我之所以对这个问题抱有兴趣，是因为AI有很多实现方法，而每个人都在摸索和尝试。人们想要用优化、学习和规划等种种方式解决问题，但时至今日关于“智能”的定义仍不明确。智能、超级智能、通用智能究竟是什么？这些问题始终没有答案。</p><p>&nbsp;</p><p>在我看来，也包括在大多数人看来，在学科中深入摸索的前提就是掌握坚实、严谨的数学基础。但这种基础在AI领域尚不存在。所以我希望能从数学层面定义什么是智能。我给出了一个定义，也是我自己发现的唯一合理的定义。即使是在20年之后，它仍然经受住了时间的考验。很多人觉得智能是个非常艰深复杂的概念，但复杂的现象往往可以用非常简单的形式来把握。我就证明，智能确实能用非常简单的形式来把握。</p><p>&nbsp;</p><p>InfoQ：那宣老师您这边能否介绍一下自己过往的经历，包括创办华院计算背后的故事？</p><p>&nbsp;</p><p>宣晓华：我自己是学数学的，本科、硕士、博士都是学习数学的，研究生阶段主要就开始侧重于算法。算法当然已很久，比如2000多年前就有算法。&nbsp;算法是一个重要的研究领域， 同时又可以有应用。 我在博士毕业以后先是去做了跟电路仿真有关的算法，这些算法更偏是科学计算。</p><p>&nbsp;</p><p>到了97年我回国之后，尤其到2002年我开始创办这家公司时,我更多关注基于数据的算法，&nbsp;并创办了华院计算。</p><p>&nbsp;</p><p>华院计算是一家以算法模型为核心的一家公司，我们研究算法模型，同时推动算法模型尤其是人工智能在不同行业应用场景中的落地，最终使行业更加智能化。</p><p>&nbsp;</p><p>即使没有重大突破，目前的AI也有望在某些领域完成50%的人类工作</p><p>&nbsp;</p><p>InfoQ：相信您二位也注意到了，从去年年底至今，以ChaGPT为代表的AIGC大模型火爆异常，您二位是如何看待这波AIGC浪潮的？</p><p>&nbsp;</p><p>Marcus Hutter：我得说，这些语言模型确实令人惊叹，实现了意想不到的突破。所以这套Transformer架构似乎就是正确答案，能够把握住建模数据中的依赖项和关联性，具有正确的归纳偏差。我觉得其实没人能真正说清这些模型为什么效果这么好。</p><p>&nbsp;</p><p>我想说的是，只要使用一个个token，它们就能帮助大家以前所未有的水平提取上下文信息。至于你刚刚提到的那些大语言模型，比如ChatGPT，它可能有上百个层，对吧？而且它们能做的不只是输出语法正确、语义正确而且有实际意义的文本，更能给我们的问题提供正确答案。所以这里的奥秘绝不仅仅在于语法和一点点语义。一定在某种形式的理解发生在了中间层上，对吧？只要提供原始文本，它就能用某种方式将其转换为更加抽象的表示。最终，质变就这样产生了。这个抽象表示随后可以被翻译成英文或者各种语言的文本。</p><p>&nbsp;</p><p>在中间某个环节上，一定有一些高质量的推理。更让人惊奇的是，它甚至还能编程，简直让人难以置信。毕竟闲聊还是相对简单，里面需要的推理部分不太多，系统只要在100毫秒后回答我提出的问题就行。闲谈就是这样，能在几乎不自觉的情况下推进展开。但对于那些更为复杂的主题，大语言模型甚至能够完成某种形式的数学推理。这一切都发生在中间层上，这非常值得关注，特别是这些模型具体是如何做到这一点的。总之，大模型的实际应用效果令人惊叹，我愿称之为一场出人意料的革命。</p><p>&nbsp;</p><p>当然，它们并不完美，也会产生幻觉。有时候，它们连初等数学都做不好……但这最多说明它们还不适合在关键的安全场景下使用，对吧？我们暂时还不能用语言模型控制火箭，或者不经检查或规划就按它的建议做严肃的诊疗操作。</p><p>&nbsp;</p><p>但对于其他容错率相对更高的领域，那就没问题。比如说用于问答的聊天框，用它总结文本内容，根据提示词生成电子邮件，还有在法律场景下浏览案例并找出相似判例、借此帮助律师节省时间精力等。我知道，最近其实出了个反例……AI捏造证据但律师没做检查。另外，这些模型能搞定的还不止是文本，甚至能在图像场景下有所作为。在我看来，它们的作品比一般人甚至是某些艺术家还要好。这肯定会将社会产生巨大的影响，而且即使在技术逻辑层面再无进一步突破，这项技术也已经具备了广泛的应用空间。我的预测是，接下来现有AI系统可能会变得更安全、更可靠。即使再没有重大技术突破，它们也有望在某些领域完成目前人类办公任务中的50%，所以必然会带来巨大的生产力提升。</p><p>&nbsp;</p><p>另一派则会强调，技术在消灭旧岗位的同时，又会创造出新的岗位，我觉得这样的观点不一定对。我觉得最本质的点在于，岗位的意义就在于创造商品和服务。当然，其中也有其它要素，比如工作带来的成就感之类。但老实说，大多数人、甚至90%的人是因为迫不得已才去工作，跟热爱完全不沾边。另外10%的人可能两者兼有，既是为了赚钱、也是因为喜欢工作内容。</p><p>&nbsp;</p><p>如果用机器取代掉这些工人，那实际产出的商品和服务也仍然相同，那么整个社会的富裕程度也没有变化。最后留下的，就是如何更公平地重新分配这些服务的问题。我想说的是，对多数上班族来说，最美好的事情就是“失业”。不用上班，但商品和服务的生产仍在继续，社会把这些成果以普遍基本收入的形式做分配。所以我们还是可以拿到属于自己的一份社会财富。到那个时候，会发生什么？这肯定是个理想化的场景，但可以拿来讨论。要么我们的失业率越来越高，但全民基本收入也达到很高的水平，再具体调整收入水平来确保仍有一部分人愿意为了再多拿收入而继续工作。或者，我们可以缩短工作时长和退休年限，甚至可以继续每周工作40小时来产出更多的劳动成果，让整个社会变得更加富裕。</p><p>&nbsp;</p><p>同时，我们必须得在不严重影响业务规模的前提下，对AI技术进行监管。转变要一步步来，期间总会有人遭受损失，但要保证这只是一小部分人遭受损失。我们可以提供更高的全民基本收入或者其他形式的补偿。这样从结果来看，大家实际都没有蒙受损失，每个人都会过得更好。</p><p>&nbsp;</p><p>InfoQ：宣老师您认为为什么会有那么多人关注AIGC或者ChatGPT？</p><p>&nbsp;</p><p>宣晓华：引发关注的原因是因为ChatGPT的智能程度超乎了人们的预期。在它出现之前，人们认为人类语言这件事对于计算机来说很难完成，ChatGPT在语言层面的输出基本上可以到达跟人类似的程度，在图灵测试意义上这是一种机器具备智能的表现。图灵测试是用语言来测试一个机器具备智能的方法。</p><p>&nbsp;</p><p>第二点原因是因为ChatGPT的使用门槛很低，是个很好的人机交互方式，而且它可具有趣味性。</p><p>&nbsp;</p><p>第三点原因是在ChatGPT表现出了语言层面的智能后，人们开始想象它是否也具有较高的认知智能，是否掌握了思维规律。实际上ChatGPT这类大语言模型应该没有掌握思维规律。ChatGPT只是掌握了语言的规律。但这也是个很大的进展，所以才会引发如此大的关注。</p><p>&nbsp;</p><p>就如当年人们得知AlphaGo会下棋一样，也会对此产生兴趣。</p><p>&nbsp;</p><p>InfoQ：您是否也赞同Marcus的观点，认为人类大部分工作都是可以被AI替代的？</p><p>&nbsp;</p><p>宣晓华：我也认为，将来会有很多工作可以交给AI来做，包括许多需要高智商的工作。&nbsp;人工智能的目标本身就希望机器能实现许多人能做的事。 每次工业革命都会产生失业问题，但是后来都消化掉了。</p><p>&nbsp;</p><p>AIGC带来的这次技术革命的影响规模可能更大。未来会如何，怎样应对需要技术领域和社会领域的学者来思考，也需要政府去重视。</p><p>&nbsp;</p><p>国内外也有不少研究AI伦理的机构，大家都在积极思考和讨论对策。</p><p></p><h2>模型不一定越大就越好</h2><p></p><p>&nbsp;</p><p>InfoQ：所以很多企业看到了AIGC或者大模型带来的机遇，都在积极拥抱大模型。究竟什么样的模型可以称之为大模型？是否意味着它的参数越大，它就越智能？您二位是怎么看待这个问题的？</p><p>&nbsp;</p><p>Marcus Hutter：一般来说是这样，就是说数据越多、参数越多，这样的训练出来的人工智能，比如说会更自然一些。那么这个是对的，这种或者相对来说是对的，但是方法论的突破真的是更重要的。</p><p>&nbsp;</p><p>至于到底什么样的模型可以称之为大模型，我觉得可以理解成“我们到底需要多大的模型”。那我们人脑中有多少个神经元和突触？</p><p>&nbsp;</p><p>人们总是以为，要想达到与人脑相当的智能水平，神经网络就能拥有同等数量的神经元和权重参数。但即使是GPT-3.5，它的规模也就相当于人脑的千之一。还有GPT-4，虽然没人知道它到底有多少参数，但猜测可能在1.5万亿左右，仍然只是人脑的百分之一。</p><p>&nbsp;</p><p>另一方面，如果用用这些大语言模型、询问它们已经掌握的知识，就会发现它们知晓的反倒相当于人类，包括关注特定领域的人类专家的100倍甚至1000倍。但问题是，知识渊博和聪明并不是一回事，需要做出明确的区分。</p><p>&nbsp;</p><p>我可以记住电话簿上的所有号码，这确实是掌握了大量信息，但也不能改变我很笨的事实。或者，很聪明的人或者AI也可能在特定的某个问题上“翻车”。无论如何，知识渊博只代表着信息的储量。这些模型虽然只相当于人脑的百分之、千分之一，但在某些方面却已经超越了人类。这就表明模型并不一定是越大越好。</p><p>&nbsp;</p><p>问题还有另一个层面，就是作为人类，我们能够通过网络、书籍等查找自己不知道的东西，并把它放在临时记忆当中。我们会稍微思考一下，利用这些知识解决了眼前的问题后，很快再把它忘掉。但也有些知识需要在神经元中经过某种形式的处理，也就是推理。所以我可能会一时忘记怎么做加法，不过查找之后又能学会。当然，出色的数学家是不会这样边学边解题的。总之，有些东西就是通过这种不断处理的方式呈现，这就是推理。</p><p>&nbsp;</p><p>但问题是，现在有了新的语言模型，它们能够查询互联网上的数据库。那这些模型具体需要在神经网络里存储多少知识？又有多少知识通过互联网的数据库即时检索就行？毕竟不是所有知识都得放进模型之内，对吧？相对不重要的随用随查更好。所以最终，也许我们会迎来更多模型，它们的推理能力相同但体量更小。还有其他一些模型瘦身技术，比如蒸馏神经网络，它们规模小得多但性能基本不变。所以五年前的我会觉得把知识存进数据库、再从中提取权重参数的作法根本就没有效率而言。但事实已经证明，这种思路不仅有效，而且在很多问题上的效率能达到人脑的100倍。</p><p>&nbsp;</p><p>所以，也许我们应该考虑把所有知识都放进神经网络的训练过程当中，让它拥有真正的“大输入”。包括一切无聊的事实，贯穿整个神经网络。因为不知道为什么，这种看似更笨的办法反而更有效，而且让模型具备了推理能力。所以我们也许可以试着让它变得更大。五年前的我觉得应该把神经网络的规模控制在一定程度，其他事实通通放进数据库。但现在我也不确定了，我觉得两种方式似乎都有可行性。所以这事怎么说怎么有理，未来的模型会变大还是变小，我真的不知道。</p><p>&nbsp;</p><p>总之，目前限制AI发展的主要是推理能力，其推理水平仍然有限。虽然大语言模型带来很多令人惊喜的表现，但在数学方面也经常犯低级错误。它们还没好到那个程度，所以要说现在的大模型还有哪方面缺失，那就是单纯记忆之外的深度推理。这才是我们需要改进的方向。</p><p>&nbsp;</p><p>宣晓华：在语言上处理上， 我们看到了目前的大模型方法， 基于大量的数据，通过增大模型参数量， 已经到了非常高的水平。但是智能毕竟还有其他的，比如我要规划一件事情，我要理解一件事情，我要很多的推理决策，那么这些到底是否只要不断的给数据就能解决呢？&nbsp;我是有问号的，需要融合和发展其它方法，如“小数据方法”。我们人类获得大量知识，推动科技发展都不是靠非常多的数据来做的，而是靠不断地引进概念、通过演绎来进行的。所以认知层面的东西我认为是非常重要的。没有在方法上改进，完全靠扩大模型参数数量， 很难达到更高的智能层次。 &nbsp;</p><p>&nbsp;</p><p>在行业应用上，由于有时数据相对很少， 大数据模型会没法应用。 需要把数据和行业知识，专家经验结合起来，我们用这样的数据和知识像结合的模型方法很好地解决一些工业领域的智能化问题。</p><p>&nbsp;</p><p>华院计算在积极发展认知智能引擎，让机器具备更多的推理，规划和决策能力。</p><p>&nbsp;</p><p>InfoQ：在大语言模型爆发后，业内有一种声音认为NLP已死。甚至在ChatGPT诞生的那一刻，NLP就已经宣告灭亡了。你们同意这种观点吗？</p><p>&nbsp;</p><p>Marcus Hutter：没错，我完全同意这个观点。我从来不觉得处理语言需要构建显式的语法规则等等。虽然这种方式也有效果，但它能解决的只是语法层面的问题。还有语义呢，语义那边又有另一种形式。其实我们很早之前就在传统研究中尝试过这个思路，一切都在专家系统中预先做编程。当时的研究人员尝试从医生等专家群体中提取知识，但这事是很难很难的。之后把提取的内容转化成规则，再做逻辑推理，这样虽有一定效果、但耗费的人力太过巨大。</p><p>&nbsp;</p><p>这种方式曾盛行一时，但现在的新思路是直接在数据之上训练系统，让系统自己理解该如何推理。而且似乎只有朝着这个方向走，将最小的先验偏差引入系统。而目前来看，先验偏差似乎就是transformer模型中的注意力机制。先设置一些层，然后用大数据做训练，由此产生的语言模型就成了基础模型。它们能逐渐掌握语法和语义，最后甚至能把握住推理的诀窍。就目前来看，恐怕已经没有哪种经典语言处理系统能够跟Transformer相匹敌了。</p><p>&nbsp;</p><p>InfoQ：看来Marcus是很认同这一说法的，宣老师您赞同吗？</p><p>&nbsp;</p><p>宣晓华：大语言模型通过数据和算法基本上掌握了语言的规律，完成了许多NLP的工作。另一方面，也有一些工作是大语言模型没有做好的，譬如大模型是不知道输出的句子是真或假的，所以大家说它会有时“一本正经地胡说八道”。&nbsp;大语言模型的时间还很短， 不适合下绝对的结论。</p><p></p><h2>自动化数据标注可能为大模型带来新突破</h2><p></p><p>&nbsp;</p><p>InfoQ：众所周知，在训练大模型时数据都是必不可少的要素，有句话叫garbage in, garbage out。要用经过标注和清洗的数据来训练大模型才能取得良好的效果，但我们如何能获取经过标注和清洗的数据？是相应语种的公共开源数据库吗？</p><p>&nbsp;</p><p>Marcus Hutter：那肯定是来自互联网了。互联网上有很多非结构化数据。你问的是具体的标注数据吧？传统上，数据标注一般都采取外包的形式，这样就能提供大量经过标注的数据素材。但最近出现了新的有趣趋势，即自动获取标注数据，这是种有趣且相当聪明的办法。大概的作法就是直接用GPT-4之类的大模型，让它对数据本身的标注做分类，然后再用另一套模型来检查标注的质量如何。</p><p>&nbsp;</p><p>期间偶尔也需要一点人类反馈，相当于做监督。这样我们就能大量创建人工数据，这些高质量的模型能帮助我们启发出更多小模型。其实我不太清楚现在能不能用顶尖模型生成的数据，训练出新的更强大的模型，或者说这种方法只能用来改进较小的模型。但无论如何，这都是件好事。我们可以用成本高昂的GPT-4创建新的标注数据，再用这些额外的数据训练出相对较好的小体量模型。沿着这个思路，我们甚至有可能突破极限、让语言模型达到新的高度。</p><p>&nbsp;</p><p>至于图像方面，其实市面上已经出现了一些技术，能够用各种方式复制图像并通过转换来创建新数据。</p><p>&nbsp;</p><p>计算成本则是另一个长期困扰我们的问题。大语言模型的训练成本非常昂贵，而且我们创建的数据越多，它的训练成本就越高，甚至逐渐逼近人类所能承受的极限。所以也许创建更多标注数据，并不是改进模型的最重要、或者最有前途的方向。也许改进架构才更重要，让它们能利用有限的数据高效完成学习。我的意思是，我们人类在训练中需要的数据量是语言模型的百分之一甚至千分之一，但在很多方面仍然比AI系统更智能。也许会有新的方法，能在系统获得智能的同时大大减少数据需求量。我们可能需要找到更好的算法。所以我认为这才是一段时间内更有前途的方法，而不只是拼命创建更多的标注数据。</p><p>&nbsp;</p><p>InfoQ：我注意到您提到了数据是来源于互联网的，它有一些是公开数据，那怎么能保证数据的公平没有偏见，或者是有什么样的数据处理方法呢？</p><p>&nbsp;</p><p>Marcus Hutter：所以很多时候还是需要人的参与，如果你需要这些公平、没有偏见的数据，就还是需要人类来做。现在当然也可以通过计算、通过另外一个算法来检查这些数据是否是正确的、无偏见的。某种意义上这往往需要另外一种方法。</p><p>&nbsp;</p><p>InfoQ：那现在这样的方法已经很成熟了吗？</p><p>&nbsp;</p><p>Marcus Hutter：目前没有那么成熟，但是我觉得这肯定也是大家需要做的一个方向，但是人的参与肯定是必须的。包括在目前为止，ChatGPT在训练方式里面去做prompt，后来还有一些强化学习都是需要有人参与的。</p><p></p><h2>后AI时代，该如何降低算力成本？</h2><p></p><p>&nbsp;</p><p>InfoQ：大语言模型的训练成本的确非常昂贵。那您二位认为这会不会把很多初创企业挡在了大语言模型之外？毕竟成本过高，他们根本就无法承担。未来的大模型会不会成为谷歌、微软这类巨头间的专属游戏？毕竟他们财力雄厚，有能力训练自己的大语言模型。</p><p>&nbsp;</p><p>Marcus Hutter：直观判断确实是这样，但只要还有大语言模型在公布自己的源代码和权重参数，那巨头之外的社群就仍有希望，虽然训练成本仍然摆在那里。</p><p>&nbsp;</p><p>其实在训练完成之后，推理过程也成本不菲，但现在的新发展已经让语言模型能运行在笔记本电脑上。所以只要技术巨头愿意发布权重参数，比如Llama就是首个发布权重的大语言模型，那即使是缺乏算力和资金的初创公司也可以据此构建起自己的应用。他们可以对模型做微调，可以进行上下文学习，也可以通过多种方式借助适当算力使用这些预训练模型。所以即使是在这块巨头主导的市场上，仍然不乏百花齐放的勃勃生机。</p><p>&nbsp;</p><p>当然，我们也可以假设科技巨头们突然就不再公布权重了，那我们也可以通过众包的方式建立自己的训练网络。其实这就是开源的典型运作方式，人们既做贡献、也享受贡献成果。而且大家还可以把自己闲置的计算机算力贡献出来。当然，我知道语言模型本身很复杂，涉及海量数据之类。</p><p>&nbsp;</p><p>所以必须承认，我还没彻底想清楚。但我觉得……也许小型初创公司可以汇聚起来并共同训练一套大模型，并以此为基础各自建立特定应用。而且没必要太悲观吧，至少目Meta等还是在公开发布自己的模型成果。所以我不怎么担心情况会走到那一步。有些人反倒觉得目前小规模初创公司在占据优势，毕竟他们更敏捷、也更乐于承担风险。他们调整应用思路的速度快得多，而且具有别样的经济优势。这种各有生态位的现实，也许平衡了巨头和小公司之间的共存关系。</p><p>&nbsp;</p><p>InfoQ：宣老师您如何看待这个问题？</p><p>&nbsp;</p><p>宣晓华：目前训练一个预训练模型需要上千万甚至上亿的成本。作为一家小公司，就不一定去做这种大的预训练模型。但小公司可以在这些大参数的模型基础上做微调，也就是可以限制一部分参数不动，围绕某一垂直领域调整小部分参数，只调整了模型一部分参数，而不是从头开始做，所以它的成本相对就比较低了。</p><p>&nbsp;</p><p>有了这个模型以后，真正应用的过程中，它还是要计算算力的，但这个算力比运行预训练大模型需要的算力要小得多。所以从这个层面来看小企业也有很大的生存空间。另外，垂直领域也更容易把领域知识结合进来，很多时候这样才能解决领域和行业中的问题。 我相信这会是一个现象，未来可能有很多企业针对某一领域去做领域模型。垂直某一领域，往往比做通用大模型更容易成功。</p><p>&nbsp;</p><p>Marcus Hutter：宣教授提到了领域大模型，我也想就这一问题补充点内容。其实有个问题你一直没提到，就是目前我们已经拥有非常精确且非常可靠的数字计算机，但它们所运行的神经网络却可靠性很低，并不需要那么高的精度。以神经网络为例，它需要的根本不是高精度浮点运算，在某些系统中4&nbsp;bit就足够了。哪怕是拉低精度，这些神经网络的表现仍然不大受影响。这就产生了巨大的错位现象。我们生产的是极为精确、极为可靠的计算机，但却用它来计算根本不需要这种精度和可靠性的任务。所以有些人开始关注模拟计算。其实很久之前、在我爸爸那个时代，模拟计算就已经很流行了。而它与神经网络之间的结合，就是矩阵乘法。这类运算只需要很低的精度，即使有点误差也没关系。在矩阵乘法中，计算内容就是最简单的乘法和加法。只需要电阻、晶体管和电路，就能轻松模拟这类计算。</p><p>&nbsp;</p><p>所以如果我们将数字乘法数组跟简单的模拟乘法相比较，就会发现模拟的难度要低得多。虽然也存在一些技术难题，但我觉得这些都能解决。出于种种原因，现在我们仍在以数字方式训练这类模型，并在训练完成之后加以运行；但如果换个思路，也许我们可以用专门设计的模拟硬件来承载特定的训练方式。</p><p>&nbsp;</p><p>没有学习过程，就不会有如今的大语言模型。虽然我的专业领域不在这里，也没做过具体计算，但我相信未来应该可以用千分之一的能耗和芯片单元运行同样的训练任务。所以未来的语言模型可能会运行在我们的智能手机里，只需要一个CPU、一个GPU和GPT-4，就能完成模拟预训练。之后推理成本也能降至千分之一，彻底廉价化。但很遗憾，芯片的设计往往被把握在少数大企业手中，所以这事也没那么容易。但只要这些芯片出现，推理的成本确实可能大幅下降，我认为未来应该会朝着这个方向发展。</p><p>&nbsp;</p><p>算力它还是可以改进的。即使使用原来的算法结构，但稍微做一些改变，也许可以把算力降很多，这是完全可能的。</p><p>&nbsp;</p><p>InfoQ：是的，您提到了硬件在巡览大模型中的重要性。我听闻英伟达最近推出了一款超级芯片，叫做GH200。这是专为生成式AI打造的一款超级芯片。那是不是说，我们以往用于构建AI的芯片已经过时了？</p><p>&nbsp;</p><p>Marcus Hutter：没有，至少目前还没有过时。</p><p>&nbsp;</p><p>不知道你指的是通用GPU芯片还是其他特定芯片。毕竟每过几年都会有新一代芯片出现，那上代芯片确实也算过时了。但我觉得你指的应该是生成式AI中的GPU或者TPU这类架构，那我觉得它们没有过时。我有种感觉，也许在训练过程中稍微提高点精度，就能在推理阶段容忍更低的运行精度。所以也许我们可以在训练过程中引入模拟计算，可能是在不久的未来，但模拟计算的应用场景应该会越来越多，对吧？</p><p>&nbsp;</p><p>又或者，我们会使用更加专业的芯片，甚至超越了GPU。具体是怎么样我不清楚，从长远来看也不重要，毕竟要解决的实质性问题就是矩阵乘法运算嘛。目前的方案主要靠GPU，但我猜英伟达应该会推出新技术，毕竟他们最擅长的就是这个。所以现在的数字化方法不会消失，而是不断增强。</p><p>&nbsp;</p><p>InfoQ：所以您也认为Marcus谈到的模拟计算会是个很好的探索方向吗？</p><p>&nbsp;</p><p>宣晓华：是的，我觉得Marcus讲的是一个很好的点，我之前没有往这方面思考过。但是他讲到这个事情，我觉得是有可能在未来实现的。现在我们使用的是数字计算机，但模拟计算机能够在某些特定的地方进行模拟计算，效率更高、成本更低。这可以成为以后积极去探索的一个方向。</p><p></p><h2>大模型未来发展趋势</h2><p></p><p>&nbsp;</p><p>InfoQ：其实之前很多项目备受关注是因为它们都是开源的，人人都可以部署。但ChatGPT这类大模型自问世以来就走的是关于闭源的路线。两位觉得大语言模型未来的发展趋势是开源还是闭源，或者说像GPT-3那样只是部分开源？</p><p>&nbsp;</p><p>Marcus Hutter：这个事情很难讲，我猜有些公司比较支持开源，而另一些公司则选择闭源。情况向来如此。就目前来讲，大家还都是比较开放的，但已经出现了回归封闭的迹象。我猜最后应该是两者兼而有之吧。最终应该是开源模型表现不错，闭源模型相对更好，但也强不了太多。</p><p>&nbsp;</p><p>在这样的情况下，那谁也没必要藏着掖着。只要市面上仍有高质量的开源模型存在，就会鼓励其他人也加入到开源中来。到时候肯定也有一些拒不开源，但我觉得都没关系。</p><p>&nbsp;</p><p>宣晓华：目前两种情况都有，目前这些大模型发展时间还很短，也会涉及很多问题，包括大模型的治理、安全性等问题。但我判断未来开源模型占主流的概率更大一些。</p><p>&nbsp;</p><p>但对于以大模型为主要商业模式的企业来说，去开源大模型并不容易，因为其他公司很容易得到技术细节，对其本身也是个竞争。</p><p>。</p><p>&nbsp;</p><p>InfoQ：那宣老师，在您看来，国内市场的大模型厂商和产品数量未来会越来越多还是越来越少？</p><p>&nbsp;</p><p>宣晓华：在我看来，类似于ChatGPT的这种通用大模型的产品不会太多。就像互联网似的，做通用搜索引擎的没有几家。但垂直领域就不一样了，只要它在某一领域内有很多高质量数据，并结合其它方法，它可以有一款更优的模型，那么它可以在那个领域发展起来，这类企业会很多。</p><p>&nbsp;</p><p>InfoQ：那两位认为，大模型接下来有哪些值得关注的发展趋势有哪些，可以是技术上的，也可以是行业向的？</p><p>&nbsp;</p><p>Marcus Hutter：在短期内，主要方向就是工程层面的成本控制吧。只有把训练和推理的成本控制在足够低的水平，才能让它具备广泛应用的可能。这应该是未来几年内的主要发展方向。</p><p>&nbsp;</p><p>而从长远来看，在技术上我们需要更高的推理能力。为此，我们需要找到更多的架构选项。其实最新的架构成果已经是七八年前的事了，也就是2017年的Transformer，而现在我们才刚刚发掘出它的潜力。从科学角度来看，之后就再没有真正重量级的改进了。而且我觉得光靠Transformer不足以实现通用人工智能。架构层面应该还要有点新变化，比如说在推理方面，至少要能实现较好的可重现性。我知道思维链能在一定程度上解决这个问题，还有其他一些方案，但总体来讲这些都不能算是理想的终极解法。</p><p>&nbsp;</p><p>所以我觉得需要探索更多架构可能性，让Transformer找到更好的推理方法。另一个重点就是规划，或者说强化学习。比如说基于人类反馈的强化学习，简称RLHF，就是用这种方式建立的语言模型。这类模型已经能够玩转国际象棋之类复杂的游戏，但真正的通用人工智能应该能玩转所有任务。所以我们需要在这些预测模型之上更进一步，引入一些适当的规划、顺序决策理论、强化学习之类。对于这些科学思想，我们肯定需要以某种方式把它们组合起来，这就要求我们找到更多架构选项。</p><p>&nbsp;</p><p>宣晓华：我觉得现阶段，增强大模型的鲁棒性、可信性是非常重要的。因为现在大模型会“莫名其妙”地出错，虽然它出错比例不一定很高，但因为这种不太可控的出错，&nbsp;在很多应用场景时会有问题。</p><p>&nbsp;</p><p>第二个就是我认为还是要在推理和规划上多下功夫。如果能在大模型之上实现很好的推理和规划，那么它就有可能实现与人类类似的通用智能能力。</p><p>&nbsp;</p><p>采访嘉宾：</p><p>&nbsp;</p><p>宣晓华，华院计算技术（上海）股份有限公司董事长、创始人</p><p>Marcus Hutter，澳大利亚国立大学计算机科学研究学院荣誉教授</p><p>&nbsp;</p><p>嘉宾征集：</p><p></p><p>什么是技术情怀？在很多人看来，是热爱、是思考、是卓越。这个时代或许有人功利、或许有人内卷，但我们依然愿意相信更多人依然怀揣着用技术改变世界的初心。<a href=\"https://www.infoq.cn/theme/The%20Great%20Geek\">《The Great Geek》（了不起的极客）</a>\"是 InfoQ 重磅推出的全新内容栏目，全年共 8 期。自栏目推出至今，我们专访了 <a href=\"https://www.infoq.cn/article/3xtSDtHUgTKRsyw3kZXH\">MySQL 数据库和 Maria DB 创建者 Michael “Monty” Widenius</a>\"、<a href=\"https://www.infoq.cn/article/E6qLkOx9rqTEKOKqT9vT\">ClickHouse创始人及 CTOAlexey Milovidov</a>\"、<a href=\"https://www.infoq.cn/article/PLNF4ZHDyqjK29XzgbAl\">iPod“之父”Tony Fadell</a>\"、<a href=\"https://www.infoq.cn/article/weyXNTEtOFXa1sF6dqe5\">Thoughtworks 全球 CTO Rebecca Parsons</a>\"、<a href=\"https://www.infoq.cn/article/45V2FCGDxm9YYWf8oWIX\">《代码大全》作者 Steve McConnell</a>\"，如果你身处的企业中有这样的技术领袖想让我们报道或你希望看到哪位技术大佬的采访，请在评论区留言联系我们。</p><p>&nbsp;</p><p></p>",
    "publish_time": "2023-08-22 15:35:15",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "抽风预测五年后的Web发展，却被现实啪啪打脸",
    "url": "https://www.infoq.cn/article/faGvcLr7szvEUUlYtBa0",
    "summary": "<p></p><p><img src=\"https://static001.geekbang.org/infoq/cf/cf16b42237cd741df6ff27641aa2e169.png\" /></p><p></p><p>Google Trends中的“oracle”搜索结果，看来“先知”（暗指甲骨文）在全球市场上的存在感越来越低了</p><p>&nbsp;</p><p>没什么比预测未来更愚蠢的了，毕竟咱们人类向来不擅长这门技能，而强加上“人类”二字只是想让我在审视自己过往言论的时候，稍微感觉不那么尴尬……</p><p>&nbsp;</p><p>风险投资商和天使投资人早就意识到这个问题：事实证明，就连这些专业人士的预测能力，也就是正、反之间五五开的水平。我甚至怀疑，他们自己都不清楚到底是凭什么赚到那么高的工资。</p><p>&nbsp;</p><p>总之，七年前我曾经就未来五年的Web发展做出七条预测。现在是时候揭晓谜底了，咱们一起看看我当初的胡言乱语有多少成真、有多少被证伪。</p><p>&nbsp;</p><p>当然，回顾的主要目的还是为了反省自我，这样之后再做预测时也许我的思路能更靠谱一点。</p><p>&nbsp;</p><p></p><h3>1. 渐进式Web应用的投资回报率将超越移动应用，但短时间内还不至于挤占后者的生存空间</h3><p></p><p>&nbsp;</p><p>很明显，移动应用还远远没到生命周期的末端。我们有Instagram、有TikTok，还有UberEATS等无数针对Web之外手机设备定制并优化的应用产品。当然，也有办法在Web上提供类似的使用体验，只是考虑到这样做对开发技能和JavaScript的功能演进要求过高，而效果也仅仅是跟移动应用持平，所以完全没有必要。</p><p>&nbsp;</p><p>Google Trends显示，2018、2019和2020这三年间渐进式Web应用获得了高度关注。而随着2021年的到来，这一数字开始大幅下降，直到2023年才有所回升。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/10/10c460975751696442d5e4549cf9b1c9.png\" /></p><p></p><p>&nbsp;</p><p>但Web应用却一刻没有停止增长的脚步：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/24/249775ac9f20fb58f848658b67f2f186.png\" /></p><p></p><p>&nbsp;</p><p>看到这里我很好奇，为什么每年的9月份都会出现一波峰值？</p><p>&nbsp;</p><p>而网站这边却始终保持平稳：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/38/380051aa6603eb3e0bac1b168974fc61.png\" /></p><p></p><p>&nbsp;</p><p>所以看来Web本身已经开始进一步分裂了。下一股新势力会是啥，Web加密货币？</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/35/35fa0033701ef9968329857be1381e91.png\" /></p><p></p><p>&nbsp;</p><p>好吧，2021年一过就凉了……</p><p>&nbsp;</p><p></p><h3>2.&nbsp;Web将全面基于组件</h3><p></p><p>&nbsp;</p><p>一语中的！当然，这里我还得再做一点延伸和解释。</p><p>&nbsp;</p><p>现如今，一切Web开发都围绕着组件展开，就跟10年前的“类”一样。React和JSX作为目前最流行的工具，纷纷力挺组件开发原则。至于代价嘛，其一是牺牲JS的普适性，另外还把前端首次运行时的最低负载大小提升到了GB之巨。</p><p>&nbsp;</p><p>当然，这样的“现代Web”配置已经完全可行，包括React、Webpack还有那无穷无尽的依赖项。毕竟客户的手机性能确实越来越强，小小的移动芯片以雄浑无比的内力承受着沉重负载的冲击，越来越快的互联网连接也让区区MB甚至GB级别的数据流量显得没那么夸张……</p><p>&nbsp;</p><p>总之，每家企业似乎都想复制Facebook的技术栈，背后的思路当然是复制Facebook获得的商业成功。我不确定这到底现不现实，但问题的核心在于：到底是React因为组件而走向辉煌，还是组件是因为React才成为主流？</p><p>&nbsp;</p><p>恐怕只有时间能带给我们答案。</p><p>&nbsp;</p><p>说到React，它把在类中将render()用作方法，改为使用接收props并返回JSX的函数。这项变更已经是几年前的事了，也是对函数编程范式做出的一项重大简化改进。我之前曾经预测，未来的前端组件将会是一个返回视图的函数，很高兴看到现实确实走上了这个路子。</p><p>&nbsp;</p><p>而函数式编程虽然逐步成为主流，但似乎还没有脱离JS社区。好在我当初也没做过它能“破圈”的美梦：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ab/abeca7b7b3e5dc2c1abcf0bd1e3dd191.png\" /></p><p></p><p>&nbsp;</p><p>我想说的是，Java和C#仍然非常重要，微软则打算把JavaScript当中的“Java”部分去掉，用C#这类“Type”来替代。下面看看TypeScript跟JavaScript之间的恩怨情仇：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d8/d8a8c0da84a0eb27468177a37afcd735.png\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>函数式编程将成为JS开发的基础</p><p>&nbsp;</p><p>React之前用类来接收props并返回JSX，但现在确实开始用函数了。函数式编程已经无处不在，我也有好几年没看过讨论JS中原型继承的博文了。</p><p>&nbsp;</p><p>所以我猜，这一点应该算是预测正确吧。</p><p>&nbsp;</p><p></p><h3>4.&nbsp;Brave浏览器将成为全球人气第二的浏览器方案，并会像当初Opera推动“选项卡”理念那样让广告拦截成为客观事实</h3><p></p><p>&nbsp;</p><p>但我没想到的是，Brave的创始人Brendan Eich居然直接把自家浏览器的USerAgent改成了Safari的，预测失败。</p><p>&nbsp;</p><p>有人说Brave的实际市场份额只有0.5%，但目前确实很难找到能够明确跟踪Brave用户占比的好办法:&nbsp;<a href=\"https://kinsta.com/browser-market-share/\">https://kinsta.com/browser-market-share/</a>\"</p><p>&nbsp;</p><p>但至少有一点我还是说对了：Chrome是永远的第一。</p><p>&nbsp;</p><p>而Safari则位列第二。</p><p>&nbsp;</p><p></p><h3>5.&nbsp;带有事件溯源（即Redux）的基于状态架构，将会成为前端设计的标准模式</h3><p></p><p>&nbsp;</p><p>从Web的角度来看，标准并没有发生改变。Web内容仍然被混乱无章地存储在S3当中，什么架构、什么设计通通是废话。尽管顶着不同的工具名称，但内里全都乱七八糟一个熊样。那么谁预测正确呢？应该是Kevlin Henney的“新瓶装旧酒”（&nbsp;Old is the new New）:</p><p>&nbsp;<a href=\"https://www.youtube.com/watch?v=AbgsfeGvg3E\">https://www.youtube.com/watch?v=AbgsfeGvg3E</a>\"。</p><p>&nbsp;</p><p>事后来看，我对技术的发展态势还是太过乐观了。</p><p>&nbsp;</p><p>衡量前端事件溯源的最佳方式，就是看看Redux库到底有多受欢迎。它只是个还不成熟的浏览器函数事件溯源实现，会在Object Literal中将“描述发生了什么”称为“action”而非“event”。</p><p>&nbsp;</p><p>Redux的star增长相当稳定，但目前似乎正逼近瓶颈期：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9b/9b7db6deb8b129d5a8afefe2b9d3616e.png\" /></p><p></p><p>&nbsp;</p><p>React的增长更快，而且更容易预测其趋势走向：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/da/da94903c07a102152d402fecbc5e0440.png\" /></p><p></p><p>&nbsp;</p><p>Vue跟React的增速基本同频，双方就像动漫英雄那样在相互追逐中一飞冲天：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7b/7b314259845d8e3550801e9f791bb5a4.png\" /></p><p></p><p>&nbsp;</p><p>另一方面，人们明显已经厌倦了Bootstrap：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a3/a38f82e546f5089804b76515f8aac1d0.png\" /></p><p></p><p>&nbsp;</p><p>Redux的走势则跟jQuery基本保持一致：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/78/78a56a6bc014e7dee8df6f6e86129b09.png\" /></p><p></p><p>&nbsp;</p><p>相比之下，比特币在2017年完成了一次飞跃，似乎代表人们开始对加密货币和分布式系统给予关注。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/40/40efa0215339014949727a910c2b1a94.png\" /></p><p></p><p>&nbsp;</p><p>但比特币repo的受欢迎程度仍然只能跟jQuery处于同一水平，也许是因为人们的热情被如雨后春笋般涌现的加密货币项目给摊薄了吧。</p><p>&nbsp;</p><p></p><h3>6. JavaScript库和项目核心将逐步成型，不再依赖于特定基于状态的架构实现或框架</h3><p></p><p>&nbsp;</p><p>我很久之前就用js-cookie实现过这个目标，但似乎其他组件并不打算跟进。Angular成了新的jQuery，NPM也成了新的jQuery。如今React又成了新的NPM，但还继续使用NPM做分发，所以情况真的有点神奇。总之，一切都是“React”组件。人们并没有更多用“可插入”的框架和库在JS中构建前端组件，也可能永远都不会。毕竟精通JS组件创建，并不能帮助我们在大厂里晋升成高级开发工程师。</p><p>&nbsp;</p><p></p><h3>7. JavaScript当中，将出现CSS的标准编写模式</h3><p></p><p>好吧，我知道大家想怎么评价。我甚至不确定样式组件如今到底算不算是主流。React虽然提供样式组件，但现在似乎很少有人愿意去用。我是很高兴自己的预测是错的：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/33/33183836fbde11663268e5cb9f7e43a2.png\" /></p><p></p><p>&nbsp;</p><p></p><h3>总结</h3><p></p><p>&nbsp;</p><p>我对过去这五年的Web发展做了七项预测，具体包括渐进式Web应用的兴起、基于组件的页面设计、JavaScript中的函数式编程、Brave浏览器的成功、基于状态的架构与事件溯源将成为主流，以及CSS将被整合进JavaScript当中。</p><p>&nbsp;</p><p>现在回头来看，虽然移动应用仍然拥有勃勃生机，但渐进式Web应用也确实经历了发展顶峰到后来的回落和复苏。随着React和JSX的流行，Web在很大程度上开始以组件为基础。函数式编程现在成为JavaScript和React的根基。然而，Brave浏览器并没能取得可以明确量化的成功（也许这是开发团队故意为之，毕竟Brave主打的就是隐私功能）。此外，Redux的采用率很低，React的Web架构依旧复杂，JavaScript也没有像预期那样将CSS纳入开发标准。</p><p>&nbsp;</p><p>从结果上看，我的预测算是有对有错。这样挺好，想当“先知”的人必然要被现实啪啪打脸，我也乐于接受这一切。</p><p>&nbsp;</p><p>敬请期待我的下一波抽风预测……</p><p>&nbsp;</p><p></p><h5>原文链接：</h5><p></p><p><a href=\"https://fagnerbrack.com/i-made-7-predictions-for-the-web-for-the-next-5-years-d750d93b1b5a\">https://fagnerbrack.com/i-made-7-predictions-for-the-web-for-the-next-5-years-d750d93b1b5a</a>\"</p><p></p><p></p><h5>相关阅读：</h5><p></p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MjM5ODIzNDQ3Mw==&amp;mid=2649969927&amp;idx=1&amp;sn=cc8a7cee992d36202d86ee5068fcc66e&amp;chksm=beca250189bdac17511f9649f03ab3b0c6fee72a33cb1957ff5a6017924fe10b7c7d5581eb98&amp;scene=27#wechat_redirect\">Web3当下，最佳投资就是投资自己</a>\"</p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MjM5ODIzNDQ3Mw==&amp;mid=2649969873&amp;idx=1&amp;sn=8cc0a44a1ab3255ea5973d41520a4c39&amp;chksm=beca24d789bdadc1f9085e3853dffff525aaa28a09a46c50169585b66650a1ac26ae67db9b57&amp;scene=27#wechat_redirect\">Web3的反思，不要抱怨</a>\"</p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MjM5ODIzNDQ3Mw==&amp;mid=2649970108&amp;idx=1&amp;sn=25f73abae444b3b0107873e5764ee068&amp;chksm=beca25ba89bdacacdc16a5def20ec892652e302c1119efbb6476f94d8570c6570a060065a2b0&amp;scene=27#wechat_redirect\">给Web3创业者的28个原则</a>\"</p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MjM5ODIzNDQ3Mw==&amp;mid=2649970054&amp;idx=1&amp;sn=1ccf271b4aea088d3beb777536ba2033&amp;chksm=beca258089bdac967b59fb03eaca2104a6038e99ff8483831976281428e80b4284add474346d&amp;scene=27#wechat_redirect\">和我一起学习Web3</a>\"</p>",
    "publish_time": "2023-08-22 16:06:51",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "腾讯云原生可观测性之路：探索、实践与踩坑",
    "url": "https://www.infoq.cn/article/UzPDWKw83lU0gfNfmUEz",
    "summary": "<p>我是来自腾讯云的黄杰，目前主要负责腾讯云上云原生可观测性的产品和内部平台的落地。我从业务转做监控至今已经有十几年，我还是开源项目的实践爱好者。今天我将为大家分享腾讯在云原生可观测性领域中的探索、实践，以及一些踩坑经历。&nbsp;</p><p>&nbsp;</p><p></p><h2>什么是云原生可观测性？</h2><p></p><p></p><p>可观测性，也就是我们曾说的监控，其中包含Log、tracing、Metrics 等等。我们要怎么将这些异构的数据进行关联？这些数据之间的关系是什么？我们又要如何应用好这些数据？</p><p></p><h3>监控 vs. 可观测</h3><p></p><p></p><p>传统意义上的监控其实是与当时的业务场景有一定关系的，监控所反映的是系统是否能正常工作的情况，关注点在于单个系统（如数据库是否可工作、服务是否可工作、主机是否在线等等），其中的 Log、Metric、Trace 概念相对独立。由此诞生了 OpenMetrics、OpenTracing 等组织，普罗米修斯、Jaeger 等开源产品。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/64/64344245a1be400ccc18b73b1bf1e8f6.png\" /></p><p></p><p>另一方面，可观测性在回答系统是否正常工作的同时，也能给出无法工作的原因，如常见的系统故障原因和补救措施。可观测性解决的是整体的问题，这是与监控所解决的单点问题有所不同。此外，除了 Tracing、Log、Metric 等方面外，可观测性也包含 Event、Profiler 等其他数据源，且数据之间不相互独立。而只有在清楚了解这些数据间的关联，我们才能明白故障背后的原因和影响的业务。幸运的是，目前这一领域也出现了许多优秀的组织和较为活跃的项目，比如大家所熟知的 CNCF 中 OpenTelemetry 项目，以及做数据可视化出名 Grafana。Grafana 目前也在通过 Loki、tempo 布局可观测性，在收购了 K6 等公司负责压测的同时，也有涉足 Profiling、CI/CD 等方面。此外，还有国外热度较高的商业化公司 DataDog，以及国内诸多类型的公司。</p><p>&nbsp;</p><p></p><h3>服务架构在变化</h3><p></p><p></p><p>监控的单点化是有原因的。传统行业的应用可能只有一台服务器和其上运行的数据库、业务代码，对监控的需求并不大，甚至只有日志输出即可。而现在的公司业务甚至可能比右图中所展示的还要错综复杂，在这种情况下，仅使用Log、Metrics、Trace 并不能解决实际生产中的问题，服务治理的难度在增加，环境愈发复杂，对故障修复效率的要求也越来越高，短短几分钟的故障都可能造成金钱损失，服务不可用也会带来用户的流失。此外，随着公司业务扩张，角色也会随之增加，各个服务角色之间还会出现责任的推卸。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9e/9ef6090235434bdbfd514ed03b3b3bdd.png\" /></p><p></p><p>但如果我们将这个复杂的网状结构进行细分，那么其中的关系便能一目了然。服务可以运行在传统 VM 环境或 K8s 环境中，会运用一些 PaaS 类产品，如数据库、cache、消息队列等等。服务间也会存在调用关系，并因此产生Log、Metrics、log。那么我们要如何将这些相连的关系包含在数据之中？又要如何将这些数据采集呢？</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/87/87c3a8cd45e73a81262ad143165cee52.png\" /></p><p></p><p>&nbsp;</p><p></p><h2>可观测性几大支柱</h2><p></p><p></p><h3>Metrics</h3><p></p><p></p><p>常见的 Metrics 指标包含：</p><p></p><p>业务指标：订单量，用户数等应用服务指标：延时、成功率或失败率、失败异常，常用的有谷歌的黄金指标中间件指标：缓存命中率、消息积压等系统基础设施指标：CPU 使用率、网络带宽等</p><p>&nbsp;</p><p>人们通常都会在指标中添加告警。我们内部曾经为及时发现系统问题，将所有相关指标都添加了告警，但也由此引发了告警风暴，系统是否故障往往可以直接看手机消息的震动频率直观看出，这样一来，告警的意义也就不复存在了。</p><p></p><p>业务相关的核心指标则更为重要。比如，在接收到 CPU 使用率过高的告警后，我们可能会从 Dashboard 中找到眉目，但单独依靠指标我们只能得知故障的现象，对于故障的原因还是无法做出回答。</p><p></p><p>那么，我们要如何透过指标曲线，针对性地找出有问题的指标、Log，或tracing？怎样才能发现上下文中故障的环节、异常的日志、Exception，或出现延迟的链路呢？这里就先容我先卖个关子。</p><p>&nbsp;</p><p></p><h3>Tracing</h3><p></p><p></p><p>全链路 Tracing 可以通过下面这个简单的用户下单行为模拟进行分析。图中包含了网关、用户服务、订单服务。网关在接受到请求后，对用户服务进行调用，访问数据库获取到用户信息；订单服务创建订单后，将订单状态存入缓存用于后续状态的更新。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/88/882cb5a1e54875144fece5d7067129ef.png\" /></p><p></p><p>在这个过程中，我们把完成这一次操作的请求用一个叫 Trace ID 的标识出来，用于区分不同机器上、多云多机房、云上云下、多 Region 数据库 等不同场景，这其中也隐含了服务的各种信息，如服务运行的机器或 K8s 的 pod 及对应 VM、服务调用、客户端对数据库的访问、缓存访问、服务运行机、服务间关系、服务所用的 PaaS 产品等等。我们还能获取每个服务处下相应请求的时间信息（开始时间、结束时间、延时）、状态、Event，以及具体的上下文日志。</p><p>&nbsp;</p><p></p><h3>Logging</h3><p></p><p></p><p>以下图的常规日志为例，我们能看到其中的时间戳、消息内容、log level、Trace ID，以及其他通用属性。OpenTelemetry 可在日志中提供标签功能，标明产生日志的用户、订单、服务及其所属组织、机器物理位置等状态信息。从中自然也隐含了日志归属服务、机器、其间关联等信息，从而将非结构化数据结构化。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7d/7dff1479a63e336b2ebd389cb1aa0e38.png\" /></p><p></p><p>在服务繁多的场景下，我们需要保证日志采集的中央化以及日志打印的可读性，方便他人在故障发生时快速检索相关日志，从而定位故障问题，但是做到这些是不是已经足够？</p><p>源源不断的日志采集不仅会带来高昂的成本，在问题出现后如果没有 Trace ID 或用户 ID，即使是有上下文存在，也很难对问题进行排查。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/96cb7a15ec87623a83280fd774f61aff.png\" /></p><p></p><p>通过 Trace ID 对上下文构建，可以让我们轻松获取到发生故障机器上的请求和相关日志。进一步讲，我们也可以通过通用属性订单 ID 或交易 ID，不仅将单次请求的 Trace 相关联，还能将服务链路顺畅连接。而用户 ID 则因为用户行为的长周期性，不适用于此处的短周期事务性场景。用户维度的跟踪可以根据前端的可观测性进行串联，对用户在前端的行为进行管理，从而模仿用户的上下文。</p><p>&nbsp;</p><p>目前，我们在告警时查找日志的思路是尽可能通过 Trace 提取计算 Metrics。业务指标场景中，可通过接口或 RPC 请求直接反应订单创建行为，免去用户自行标记指标的操作；应用服务指标中的许多都可以天然通过 Trace 进行提炼；中间件指标方面，则可以从客户端一侧实施可观测性，比如，数据库访问的库名、TP、快慢SQL、成功与否等等，至于数据库响应，在已知 DP 和关联的情况下，client 和 server 间也可以很好地进行关联；系统基础设施指标基本属于传统监控范畴，通过主机 IP、host、标签，关联服务所在机器的 CPU 内存、网络带宽等等。</p><p>&nbsp;</p><p></p><h3>Health Check</h3><p></p><p></p><p>与拨测类似，Health Check 会探测 IP 和端口是否可用，并将服务内部依赖及故障原因简单地告知可观测平台。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/49/49fdacdc557e7a15780a8ae3617330f6.png\" /></p><p></p><p>至于 Health Check的运用，我们内部曾基于 Health Check 做过一个对 DB 的监控，通过 DB 的慢 SQL/TPS及其他数据库行为判定数据库是否正常，Health Check 也可用于服务点火，及时地 check 发布后的服务是否成功，如果不成功则立刻回滚。此外，K8s 也提供对服务部署后的存活检测，云服务商的状态页也有状态异样的检测。</p><p></p><h3>Event</h3><p></p><p></p><p>除此之外，我认为变更也非常有用。据业务数据分析线上故障至少有五成左右都是直接来源于变更。下图的例子中，我们内部在每次变更都会把 commit 信息和环境信息包含在其中，让后台能立刻得知那些服务有变更，一旦出现故障便能立刻找到有问题的变更。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4f/4fdcdada3633703afe0d4c26c2b7c8e8.png\" /></p><p></p><p></p><p></p><h3>相互关联</h3><p></p><p></p><p>总体来说，这些单体本身的实施并不困难，但这些数据采集如果没有运用好，也将会变为一种负担。我们的第一代系统就是具备日志打印功能的基础设施，自我感觉很好但对业务而言毫无价值，出现故障后他人很难通过搜索日志关键字找到问题原因。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/17/17842931d3f0adcd5982d2624d61aaec.png\" /></p><p></p><p>为此，我们将问题根据异常类型或 Error 级别进行简单的分类统计，让 DBA 和业务关注自身类别的告警，直观地通过 Dashboard 中指标情况，找到下方 Trace 链路和环节的问题点，继而根据 Trace ID 对日志关联，查找具体日志内容。整体排查过程基本不涉及任何关键字查找，仅仅通过图示和鼠标操作上游便可轻松定位问题模块。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/75/75e4ca3e742a71456e7d4befd75ca848.png\" /></p><p></p><p>在 Tracing、Metrics、Log 这三大支柱下，目前开源社区如 OpenTelemetry 会对日志打印的标准进行定义，限定特定情况下日志打印的标签、日志内容，以及如何利用这些数据提取 Metrics 等等，将原本独立三大资源贯通，从而实现后续的 root cause 根因分析。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>如何建设可观测性</h2><p></p><p></p><p>搭建监控或可观测平台离不开丰富的数据采集、数据清洗和计算、数据存储及对用户展现这三个方面。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c4/c42e8a3f233b04c56db5f4d71f49880c.png\" /></p><p></p><p>下图中整理了采集、存储、计算整体流程的简单示意图。目前许多基础设施软件都已在内部集成各式 SDK，导致传统的闭源很难继续存活，因此我们选择拥抱开源，使用 Jaeger Agent、SkyWalking、普罗米修斯、OpenTelemetry、OTEL Agent、Log Agent，以及一些内部传统 Agent 等进行数据采集，并将采集到的数据汇总到扩展性较好的 OpenTelemetry Collector 中，通过鉴权路由把数据分发到 Kafka，再兵分两路；一路用于日志分析、数据提取，将指标保存于 Clickhouse 或 CTSDB 后闭环到数据清洗和计算，从而完成其他告警和监测工作。另外一路则相对简单，将数据按照是否存在问题进行分离存储（ES、COS、或 Clickhouse），统一挂载查询引擎，允许用户使用类似 SQL 查询的形式对数据进行查找Log、指标、Trace 等等。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/92/92212aa15b5bc1bb78353e357f2d89f2.png\" /></p><p></p><p>&nbsp;</p><p></p><h3>如何采集</h3><p></p><p></p><p>我们将开源社区内的 Receive 根据业务需求进行了简单的改造和扩展，将所有 Receiver 中的异构数据转换为统一的内部 OpenTelemetry 协议进行存储。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/89/89d5a3849aad531a9d32c5dd74caa2fd.png\" /></p><p></p><p>此外，云上服务中的鉴权、采样、限流/限频方面，以及我认为较重要的路由，即提前根据租户、产品类型，以及监控场景分类数据，将分类后同类型数据进行简单合并，从而方便后续操作并减轻网络传输压力。为保证监控数据的时效性，延时数据不会对后续造成影响，我们采用了本地+内存的缓存机制，一份存储数据可被多人消费，类似于一个本地的简单 Kafka；将最新的数据保存至内存，历史数据保存至本地磁盘，日志消费等则由 Kafka 负责。整体过程直接套用开源方案，我们只在其中进行了标准化的工作，确保数据的统一性。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h3>如何计算</h3><p></p><p></p><p>我们是近些年才将计算迁移至 Flink 的，其中最具特色的便是我们的视图级联运算和延时数据运算，以及其他常规的平滑重启、数据补算、动态规则加载、状态自监控（告知上一级数据路由的问题）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7c/7c5ad3c3cfb39eecda1a53f42fff2f9e.png\" /></p><p></p><p>为实现监控大数据量下的高吞吐，我们需要在上游做好数据分类的前提下，对监控数据进行裁剪，在 Flink 的前置 Route 中进行数据的合并压缩；废弃了过重的 Checkpoint，通过异常时间点的补算保障数据的完整性；将业务中的大任务进行拆解，便于系统整体维护；引入了迭代流，将计算结果循环利用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/83/83595fb748e68aca0a1b581a21e6119a.png\" /></p><p></p><p>我们通过抽象十数种通用算子（如 count、gauge、采样等），将 SQL 翻译为 Flink 算子进行 pipeline 计算，从而实现系统逻辑的通用性。</p><p></p><p>在稳定性方面，我们主要关注的是积压数据的实时性，通过新任务补算，确保 delay 的数据不会影响后续计算流；无缝重启则是通过下发停止计算的时间点，让新任务在该时间点处理后续数据，为避免中间数据的重复性，我们在设计算子时也考虑到这一点，故而所有数据都是可以再计算的。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h3>如何存储</h3><p></p><p></p><p>存储主要分为三部分，Log、Trace、Metrics。通过抽象数据 ID 化，以类似数据库组件的形式，对这些数据进行打标，对于 CVM/CDB 这种云上产品而言，数据 ID 也可方便的针对不同用户的需求进行补打标和补算。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cb/cbf1e16e70d8667fec6739db4682ab8e.png\" /></p><p></p><p>此外，我们也统一了数据查写的方式，这里就涉及到了异构存储的上层查询、ES 动态分片、监控数据 TTL 及时间的计算。我们还针对大范围数据查询的自动 Rollup，在查询时按时间分片聚合，将告警等静态数据缓存等等。沿用流处理的思路，我们限制了分片上限，并基于数据的周期性进行动态分片调整。</p><p>&nbsp;</p><p>简而言之，我们在采集和存储阶段确保输入输出数据的标准化，计算阶段通用化，让研发和产品都可简单通过 POC 写 SQL 等等。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>一体化可观测</h2><p></p><p></p><p>图中所示是腾讯云目前的可观测平台，我们可以看到其中包含了拨测、用户端、web、小程序等各种语言，应用了各类协议和云产品，以及后续对数据的运用、处理数据的存储，以及产品的运用形式。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a7/a7d42851752379a6943221b45ba79edf.png\" /></p><p></p><p>以 RUM 为例，我们可以直观地看到前端的每一次请求情况、行业数据、可观测标准、数据采集、主要请求量、环比问题等等，允许我们通过前端的监控和日志，快速对接后端的服务异常。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/91/914e4c759f872bc58978d1b68090f631.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/20/205e4cdfe3e97ca9da65a3c5642dd15c.png\" /></p><p></p><p>因为我们所有的数据均是由 Trace 产生，因此正如图中所示，我们能直观地看到服务的吞吐量、延时等情况，找到出现异常的链路环节及 Trace 日志，进而在告警出现后快速得出异常根因。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fd/fd96270fc0edad7011d945985027375a.png\" /></p><p></p><p>在 DBA 发现数据库出现问题后，我们也可以发现受到影响的服务，如数据库中有哪些慢 SQL 对服务造成影响、服务访问的 DB 出现异常等等。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/79/797acce9966d1cec22e8abcdbd423803.png\" /></p><p></p><p></p><h2>总结展望</h2><p></p><p></p><p>正是有了目前社区中数据的标准化，才能为我们的 AIOps 奠定基础，从而允许云厂商或可观测平台能将精力聚焦于产品能力和成本之上。</p><p>&nbsp;</p><p></p><h5>&nbsp;相关阅读：</h5><p></p><p></p><p><a href=\"https://xie.infoq.cn/article/f7aedbe42663bade56aeb2e9b\">云原生 + 国产化，腾讯云数据库不做选择题</a>\"</p><p><a href=\"https://www.infoq.cn/minibook/WALvuBYY6f31HUPDz5lc\">腾讯云数据库技术实践精选集 2022 年版</a>\"</p><p><a href=\"https://xie.infoq.cn/article/54336764d453b9a199b333476\">腾讯云 ES：一站式配置，TKE 容器日志采集与分析就是这么简单</a>\"</p><p><a href=\"https://xie.infoq.cn/article/9c217ea34ca8b42f92f752de9\">腾讯云数据湖解决方案及 DLC 内核技术介绍</a>\"</p>",
    "publish_time": "2023-08-22 16:10:17",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "德邦基金 CTO 李鑫，确认担任 FCon 创新的金融科技应用专题出品人",
    "url": "https://www.infoq.cn/article/q6h029X8rWoYuci5u6aB",
    "summary": "<p><a href=\"https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle\">FCon 全球金融科技大会</a>\"，将于 11 月在上海召开。德邦基金 CTO 李鑫将担任「<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=article\">创新的金融科技应用</a>\"」的专题出品人。在此次专题中，你将了解到技术如何加速金融行业的效率，为它赋能，最终为用户带来更好的金融产品的。</p><p></p><p><a href=\"https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=article\">李鑫</a>\"，著有《微服务治理：体系、架构及实践》一书。曾任天弘基金渠道研发中心技术总监，负责基金销售和营销的技术支持工作；曾任华为六级技术专家，主导了华为软件多款云计算产品和服务的设计规划和构建工作；曾任当当网运作产品中心技术负责人，负责电商仓储、物流等系统的整体技术架构和研发团队管理。更早之前在航空、导航、金融、电信等领域从事企业级应用的架构设计和技术管理工作。个人技术涉及并行计算、大规模分布式服务及治理、中间件云化及服务化（PaaS）、APM 监控、基础开发平台、数据治理等领域，有多年大规模复杂系统架构实践经验，乐于技术分享。多次获得 QCon、ArchSummit 等技术大会的 “明星讲师”及“优秀出品人”荣誉称号。</p><p></p><p>相信李鑫的到来，可以帮助提升此专题的质量，让你学习到，传统金融机构在互联网技术的影响下，开始增加技术投入，用更加互联网的方式运营产品，如何利用技术提升运营能力、研发效率，如何利用区块链、AI 等技术探索全新业务模式，以及如何利用大数据加强风控水平。</p><p></p><p>除上述专题外，FCon 上海还将围绕&nbsp;<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle\">DevOps&nbsp;在金融企业落地实践</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle\">金融行业大模型应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle\">创新的金融科技应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle\">金融实时数据平台建设之路</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle\">金融安全风险管控</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle\">数据要素流通与数据合规</a>\"等专题进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，前 100 人可享 5 折特惠购票，咨询购票请联系：13269078023（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png\" /></p><p></p>",
    "publish_time": "2023-08-22 16:13:27",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "知识图谱：打破人工智能的认知天花板｜技术资料",
    "url": "https://www.infoq.cn/article/rb6GsEtbatz4VP5WvMJ5",
    "summary": "<p>知识图谱作为人工智能的重要研究领域，其核心理念可追溯到第一次人工智能浪潮。但直至进入人工智能下半场，当具备能理解、会思考、可解释等特征的认知智能成为突破自身天花板的关键，知识图谱才得以蓬勃发展。近年来，知识图谱技术热度不减，作为实现认知智能的核心驱动力，已广泛应用在金融、电商、医疗、政务等诸多领域。</p><p></p><p>知识图谱究竟能解决哪些问题、应用在哪些场景？其技术架构如何发展演变？又将如何支撑实现认知智能的终极目标？成为技术圈热议的焦点。</p><p></p><p>InfoQ 基于对知识图谱技术生态的深刻观察，重磅发布《知识图谱：打破人工智能的认知天花板》研究报告。带您探索知识图谱如何实现机器的辨识、思考与主动学习，梳理知识图谱技术体系与产业链结构，剖析实现认知智能的技术挑战与发展趋势，探求知识图谱将如何打破人工智能的认知天花板。</p><p></p><p></p><h2>主要观察发现</h2><p></p><p></p><p>知识图谱是实现人工智能从“感知”跃升到“认知”的基础。在内容维度，知识图谱是一种表达规范、关联性强的高质量数据表示;在技术维度，知识图谱可解释为一种使用图结构描述知识和建模万物关联关系的技术方法。在知识图谱的价值维度，首先，知识图谱有助于实现业务战略高度的行业数据治理;其次，知识图谱基于语义连接实现知识融合和可解释性，成为人类思维与机器路径思维的转换器;最后，知识图谱实现对推理和决策的有力支撑，使其在更多领域得以广泛应用。从知识图谱的构建技术来看，主要包含知识图谱表示、知识存储、知识抽取、知识融合、知识推理等关键组成部分。在其发展演进过程中，经历了从人工群体智慧构建到自动获取构建的转变，知识图谱与深度学习的融合成为重要发展方向。从知识图谱的产业链结构来看，知识图谱上游产业涉及数据采集标注、云服务、硬件资源、数据库等数据和技术支撑;中游从事知识图谱的设计与构建，包括提供用于知识图谱分析、应用的各类套件工具及解决方案;下游知识图谱主要与AI相关技术结合，深度应用于垂直领域。当前，知识图谱推理和快速工业化能力的缺失成为主要技术挑战。伴随应用场景不断深入专业领域，知识图谱将从知识服务延伸至深层决策和予预测服务。此外，场景驱动下的知识图谱技术生态将呈现系统化发展趋势，与知识表示、自然语语言处理、机器学习、图数据库、多媒体处理等关联技术相互融合，深度赋能应用场景。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e5/e575abefd4c8b9da87f4e6d9fe4a4900.png\" /></p><p>扫/码/下/载</p>",
    "publish_time": "2023-08-22 16:39:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "9 种方法使用 Amazon CodeWhisperer 快速构建应用",
    "url": "https://www.infoq.cn/article/JcIQOLpgqVK3AAgQxNQt",
    "summary": "<p>Amazon CodeWhisperer&nbsp;是一款很赞的生成式人工智能编程工具。自从在工作中使用了 CodeWhisperer，我发现不仅代码编译的效率有所提高，应用开发的工作也变得快乐起来。然而，任何生成式 AI 工具的有效学习都需要初学者要有接受新工作方式的心态和意愿。</p><p></p><p>Amazon CodeWhisperer</p><p><a href=\"https://aws.amazon.com/codewhisperer/\">https://aws.amazon.com/codewhisperer/</a>\"</p><p></p><p>作为一名早期的“探索者”，我发现了几个对我很有用的功能和可以提高生产效率的小技巧，将在这篇文章中和大家分享：</p><p></p><p>减少输入函数生成类的生成算法的实现单元测试的编写创建示例数据简化正则表达式更快地学习第三方代码库代码的文档化</p><p></p><p></p><h2>CodeWhisperer 的安装部署</h2><p></p><p></p><p>使用 CodeWhisperer，需要在你的集成式开发环境（IDE）中安装最新的 Amazon Toolkit。支持的 IDE 包括 Visual Studio（VS）Code 和 JetBrains IDE（IntelliJ、PyCharm、CLion、GoLand、WebStorm、Rider、PhpStorm、RubyMine 和 DataGrip）。另外，CodeWhisperer 被内置了 Amazon Cloud9 和 Amazon Lambda 控制台, 也可以在 JupyterLab、Amazon SageMaker Studio、以及 Amazon Glue Studio Code 中通过加入 CodeWhisperer extension 进行使用。有关设置说明，请参阅：CodeWhisperer&nbsp;“入门” 资源。</p><p></p><p>CodeWhisperer “入门” 资源</p><p><a href=\"https://aws.amazon.com/codewhisperer/resources/\">https://aws.amazon.com/codewhisperer/resources/</a>\"</p><p></p><p>CodeWhisperer 为输入需求自动提供建议。如果没有收到建议，可以随时使用&nbsp;Option + C (Mac)&nbsp;或&nbsp;Alt + C (Windows)&nbsp;快捷方式手动触发。</p><p></p><p>CodeWhisperer 有时还会向你提供多种建议以供选择。你可以按 →&nbsp;和 ←&nbsp;键循环浏览所有可用的建议。</p><p></p><p>CodeWhisperer 提供的建议是非确定性的，这意味着开发者收到的建议可能与本文中显示的建议略有不同。如果收到的建议不符合需求，可以尝试使用箭头键循环浏览所有可用的建议，或者尝试稍微改写任何代码注释提示。即使是标点符号的变化也可能产生新的建议。</p><p></p><p>本文中的示例是用 JavaScript 和 TypeScript 编写的。当然，演示操作同样适用于 CodeWhisperer 支持的其他编程语言。</p><p></p><p></p><h2>减少输入</h2><p></p><p></p><p>对于常见的代码功能实现，CodeWhisperer 的作用在于功能完成自动化，这大大减少了编写单行代码或代码块时的键入次数。CodeWhisperer 在键入时自动提供建议。当建议有用时接受这些建议，当建议没有帮助时则忽略这些建议。根据我的经验，仅以这种方式使用 CodeWhisperer 可以使我的文字输入减少&nbsp;50％&nbsp;或更多。</p><p></p><p></p><h2>函数生成</h2><p></p><p></p><h4>根据函数名自动生成函数</h4><p></p><p></p><p>资深的程序员为其函数和参数提供清晰准确的描述性名称。如果你在自己的编程中遵循这种做法，CodeWhisperer&nbsp;将拥有为你实现许多功能所需的所有上下文。</p><p></p><p>在输入下面的函数名后，CodeWhisperer&nbsp;生成的函数体。</p><p></p><p>用户输入 (JavaScript)</p><p>JavaScript</p><p><code lang=\"text\">function standardDeviation(numbers)</code></p><p></p><p>结果：</p><p>JavaScript</p><p><code lang=\"text\">function standardDeviation(numbers) {\n  const avg = average(numbers);\n  const variance = numbers.map((x) =&gt; Math.pow(x - avg, 2)).reduce((a, b) =&gt; a + b, 0) / numbers.length;\n  return Math.sqrt(variance);\n}</code></p><p></p><p></p><p></p><h4>根据描述生成函数</h4><p></p><p></p><p>有时，仅凭一个好的函数签名不足以传达函数的预期行为。在这些情况下，可以使用详细的代码注释作为提示发给 CodeWhisperer。建议在选择这种方式时使用相应语言的文档注释分隔符。</p><p></p><p>用户输入 (JavaScript)</p><p>JavaScript</p><p><code lang=\"text\">/**\n * Given a list that contains some numbers and strings, format them into a string\n * in which the numbers are prepended with \"#\" and the strings are wrapped in\n * double quotes.\n */</code></p><p></p><p>结果：</p><p>JavaScript</p><p><code lang=\"text\">/**\n * Given a list that contains some numbers and strings, format them into a string\n * in which the numbers are prepended with \"#\" and the strings are wrapped in\n * double quotes.\n */\nfunction formatList(list) {\n  return list\n    .map((item) =&gt; {\n      if (typeof item === \"number\") {\n        return `#${item}`;\n      } else {\n        return `\"${item}\"`;\n      }\n    })\n    .join(\", \");\n}</code></p><p></p><p></p><h2>类的生成</h2><p></p><p></p><p>可以通过单个代码注释生成完整或部分的类实现。注释应描述该类的关键属性和行为。</p><p></p><p>用户输入（TypeScript）：</p><p>TypeScript</p><p><code lang=\"text\">/**\n * A folder has a name, children, and an optional parent. A child can't be added\n * twice.\n */</code></p><p></p><p>结果：</p><p></p><p>在完成上面的函数块注释之后，CodeWhisperer 提供了多种建议，并附有每种方法的文档注释！</p><p>TypeScript</p><p><code lang=\"text\">/**\n * A folder has a name, children, and an optional parent. A child can't be added\n * twice.\n */\nclass Folder {\n  constructor(name, parent) {\n    this.name = name;\n    this.children = [];\n    this.parent = parent;\n  }\n\n  /**\n   * Add a child to the folder.\n   * @param child The child to add.\n   * @returns True if the child was added, false if it was already present.\n   */\n  addChild(child) {\n    if (this.children.includes(child)) {\n      return false;\n    }\n    this.children.push(child);\n    return true;\n  }\n\n  /**\n   * Remove a child from the folder.\n   * @param child The child to remove.\n   * @returns True if the child was removed, false if it wasn't present.\n   */\n  removeChild(child) {\n    if (!this.children.includes(child)) {\n      return false;\n    }\n    this.children.splice(this.children.indexOf(child), 1);\n    return true;\n  }\n}</code></p><p></p><p></p><h2>算法的实现</h2><p></p><p></p><p>CodeWhisperer 能够轻松实现通用的算法。只需告诉 CodeWhisperer 你想将哪种算法应用于特定的编码问题，它就会执行。</p><p></p><p>用户输入 (JavaScript)</p><p></p><p>JavaScript</p><p><code lang=\"text\">const actors = [ ... ];\n\n// Sort the actors by age using the merge sort algorithm.</code></p><p></p><p>结果：</p><p>JavaScript</p><p><code lang=\"text\">const actors = [\n  {name: 'Tom Cruise', age: 56},\n  {name: 'Meryl Streep', age: 49},\n  {name: 'Jack Nicholson', age: 39},\n  {name: 'Christopher Walken', age: 53}\n];\n\n// Sort the actors by age using the merge sort algorithm.\nfunction mergeSort(arr) {\n  if (arr.length &lt;= 1) {\n    return arr;\n  }\n  const middle = Math.floor(arr.length / 2);\n  const left = arr.slice(0, middle);\n  const right = arr.slice(middle);\n  return merge(mergeSort(left), mergeSort(right));\n}\n\nfunction merge(left, right) {\n  const result = [];\n  while (left.length &amp;&amp; right.length) {\n    if (left[0].age &lt; right[0].age) {\n      result.push(left.shift());\n    } else {\n      result.push(right.shift());\n    }\n  }\n  while (left.length) {\n    result.push(left.shift());\n  }\n  while (right.length) {\n    result.push(right.shift());\n  }\n  return result;\n}</code></p><p></p><p></p><h2>单元测试的编写</h2><p></p><p></p><p>CodeWhisperer 加速了单元测试的实现。不仅能够实现我请求的大多数明确的单元测试的逻辑，而且经常为我甚至没有想到的边缘情况来建议单元测试。</p><p></p><p>当我想让 CodeWhisperer 实现一个单元测试时，我会像下面的例子一样，首先声明我正在测试的条件和预期的结果。</p><p></p><p>用户输入 (JavaScript)</p><p>JavaScript</p><p><code lang=\"null\">describe(\"Folder.addChild()\", () =&gt; {\n  it(\"when adding an existing folder should not add duplicate\"</code></p><p></p><p>结果：</p><p>JavaScript</p><p><code lang=\"text\">describe(\"Folder.addChild()\", () =&gt; {\n  it(\"when adding an existing folder should not add duplicate\", () =&gt; {\n    const folder = new Folder(\"root\");\n    const child = new Folder(\"child\");\n    expect(folder.addChild(child)).toBe(true);\n    expect(folder.addChild(child)).toBe(false);\n  });\n  \n  it(\"when adding a new folder should add it\", () =&gt; {\n    const folder = new Folder(\"root\");\n    const child = new Folder(\"child\");\n    expect(folder.addChild(child)).toBe(true);\n  });\n  \n  it(\"when adding a new folder should add it to parent\", () =&gt; {\n    const folder = new Folder(\"root\");\n    const child = new Folder(\"child\");\n    folder.addChild(child);\n    expect(child.parent).toBe(folder);\n  });\n}</code></p><p></p><p>在完成一两个测试之后，即使没有明确的提示，CodeWhisperer 也会建议更多的测试。在后续的文章和视频里，我们将展示 CodeWhisperer 更多的测试建议。</p><p></p><p>提示：你会注意到我的测试描述包括：</p><p></p><p>我正在测试的函数；我正在测试的条件；我期望的结果。&nbsp;</p><p></p><p>遵循这个由三部分组成的模式是确保 CodeWhisperer 拥有实现高质量测试逻辑所需的上下文的好方法。</p><p></p><p></p><h2>创建示例数据</h2><p></p><p></p><p>我发现，CodeWhisperer 可以生成虚拟数据，或者实际的、具有可重复模式的代码。举例来说，在下面的列表中，我只输入了第一个 “用户” 对象作为示例，CodeWhisperer 就很好的延续了这个模式。</p><p></p><p>用户输入 (JavaScript)</p><p>JavaScript</p><p><code lang=\"null\">const fakeUsers = [\n{ name: \"User 1\", id: \"user1\" },</code></p><p></p><p>结果：</p><p>JavaScript</p><p><code lang=\"text\">  const fakeUsers = [\n  { name: \"User 1\", id: \"user1\" },\n  { name: \"User 2\", id: \"user2\" },\n  { name: \"User 3\", id: \"user3\" },  \n  { name: \"User 4\", id: \"user4\" },\n  { name: \"User 5\", id: \"user5\" },\n  { name: \"User 6\", id: \"user6\" }\n]</code></p><p></p><p>它甚至可以生成随机但看似合理的值，如下所示：</p><p></p><p>用户输入 (JavaScript)</p><p>JavaScript</p><p><code lang=\"text\">const fakeUsers = [\n{ name: \"Sally\", id: \"user1\" },</code></p><p></p><p>结果：</p><p>JavaScript</p><p><code lang=\"text\">const fakeUsers = [\n  { name: \"Sally\", id: \"user1\" },\n  { name: \"Bob\", id: \"user2\" },\n  { name: \"Joe\", id: \"user3\" },\n  { name: \"Jane\", id: \"user4\" },\n  { name: \"Jill\", id: \"user5\" },\n  { name: \"Jack\", id: \"user6\" }\n  ]</code></p><p></p><p></p><h2>Regular Expression 简化正则表达式</h2><p></p><p></p><p>虽然 CodeWhisperer 还不能将自然语言自动转换为自定义 Regular Expression，但它确实知道很多常用的 Regular Expression，帮助开发者节省时间。每当你需要正则表达式时，它们随手可得。</p><p></p><p>让我们来看一个相对复杂但常见的 Regular Expression。</p><p></p><p>用户输入 (JavaScript)</p><p>JavaScript</p><p><code lang=\"text\"> /**\n* Function that validates whether a string is a valid email address.\n*/</code></p><p></p><p>结果：</p><p>JavaScript</p><p><code lang=\"text\"> /**\n * Function that validates whether a string is a valid email address.\n */\nexport function isValidEmail(email) {\n  return /^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/.test(email);\n}</code></p><p></p><p></p><h2>快速学习第三方代码库</h2><p></p><p></p><p>当使用不熟悉的库、模块或框架时，CodeWhisperer 有助于加快自学习速度。&nbsp;</p><p></p><p>在下面的示例中，我需要编写一个实用函数，该函数将获取来自 API 的 gzip 压缩值并将其转换成其余代码可以理解的值。我知道&nbsp;“pako” 库会帮助到我，但我不知道如何使用。于是我给 CodeWhisperer 提示：一条导入声明和一条描述我目的的描述。</p><p></p><p>JavaScript</p><p><code lang=\"text\">import pako from \"pako\";\n\n/**\n * Accepts a base64-encoded, gzip-compressed JSON string and returns\n * a parsed JSON object.\n */</code></p><p></p><p>结果：</p><p>JavaScript</p><p><code lang=\"text\">import pako from \"pako\";\n\n/**\n * Accepts a base64-encoded, gzip-compressed JSON string and returns\n * a parsed JSON object.\n */\nexport default function decompress(str) {\n  const buffer = pako.inflate(atob(str));\n  const json = buffer.toString();\n  return JSON.parse(json);\n}</code></p><p></p><p></p><h2>代码的文档化</h2><p></p><p></p><p>CodeWhisperer 能为生成的代码和现有的代码生成文档和注释。</p><p></p><p>例如，假设我想要 CodeWhisperer 帮我为&nbsp;FavoritesFilter&nbsp;TypeScript 类的&nbsp;matches()&nbsp;方法生成文档注释。</p><p></p><p>TypeScript</p><p><code lang=\"text\">class FavoritesFilter implements IAssetFilter {\n ...\n matches(asset: Asset): boolean {\n   ...\n }\n}</code></p><p></p><p>我们只需要在方法名称的正上方键入文档注释分隔符（/** */），CodeWhisperer 就会为我们生成文档注释的正文。</p><p></p><p>注意：当&nbsp;CodeWhisperer 用于这个场景时，我们需要使用&nbsp;Option + C (Mac)&nbsp;或&nbsp;Alt + C&nbsp;(Windows)手动触发建议。</p><p></p><p></p><h2>结论</h2><p></p><p></p><p>希望上面的分享能激发你开始尝试使用 CodeWhisperer 这样智能的代码工具的想法。立即安装&nbsp;CodeWhisperer，并开始在自己的项目中使用这些节省时间的方法和技巧。当然，这些建议和技巧只是 CodeWhisperer 的部分功能。随着更多开发者开始将 CodeWhisperer 应用到他们的日常工作流程中，我相信更多的技巧、经验和最佳实践还将持续出现。如果你也有心得体验，请发表评论让我们知道。你的分享会对更多的人有所帮助。</p><p></p><p>安装 CodeWhisperer</p><p><a href=\"https://aws.amazon.com/codewhisperer/resources/\">https://aws.amazon.com/codewhisperer/resources/</a>\"</p><p></p><p></p><h2>参考资料</h2><p></p><p>10 ways to build applications faster with Amazon CodeWhisperer：</p><p><a href=\"https://aws.amazon.com/cn/blogs/devops/10-ways-to-build-applications-faster-with-amazon-codewhisperer/\">https://aws.amazon.com/cn/blogs/devops/10-ways-to-build-applications-faster-with-amazon-codewhisperer/</a>\"</p><p>Amazon CodeWhisperer Startup：</p><p><a href=\"https://aws.amazon.com/cn/codewhisperer/resources/\">https://aws.amazon.com/cn/codewhisperer/resources/</a>\"</p><p>Amazon CodeWhisperer User Guide：</p><p><a href=\"https://docs.aws.amazon.com/codewhisperer/latest/userguide/sagemaker-setup.html\">https://docs.aws.amazon.com/codewhisperer/latest/userguide/sagemaker-setup.html</a>\"</p><p></p><p>文章作者：Kris Schultz</p><p>3D Specialist Solutions Architect, Amazon Web Services&nbsp;</p><p>文章译者：郑予彬</p><p>亚马逊云科技资深开发者布道师</p><p>代码校验：阙铭飞</p><p>亚马逊云科技大中华区解决方案研发中心&nbsp;</p><p>解决方案架构师&nbsp;</p>",
    "publish_time": "2023-08-22 16:52:51",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "IDC预计到2027年教育学习市场将超1500亿美元，AI成为重要竞争力",
    "url": "https://www.infoq.cn/article/Q79Uh3SJSmr8xiY6QGD5",
    "summary": "<p>随着智能终端设备类型逐渐增多，功能愈发融合，其所承载 的价值往往是跨越多个场景的。与此同时，生态在智能终端发展的过程中扮演着越来越重要的作用，智能终端设备在连接、交互和服务等体验方面的发展是互相促进，彼此支撑的。不同的使用场景，也通常会带来生态发展的不同侧重。</p><p></p><p>基于此，为了更好地理解智能终端设备，IDC 将围绕智能终端的使用场景分为六大智能生活场景，分别是休闲娱乐、移动办公、教育学习、运动健康、居控制和智慧出行。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/86/04/86b02e244f83bef3f9d2b304672d4804.png\" /></p><p></p><p>适逢暑期临近结束以及新学期即将开学，本文主要围绕教育学习场景展开，着重介绍该场景下智能终端设备和生态发展趋势。</p><p></p><h3>2023 年重点教育学习终端暑期促销回顾</h3><p></p><p></p><p>主要教育学习终端产品，包括学习平板、儿童手表和 PC 等，在 2023 年 7 月的销售表现均超过上半年的单月平均值。但由于处在不同的发展周期，各产品具体销售表现呈现不同趋势。</p><p></p><p>学习平板市场是目前教育学习场景下的热门品类，也是呈现快速发展的市场。市场上仍然有新厂商逐渐加入到该赛道的竞争中。2023 年上半年学习平板市场出货量 219 万台，同比增长 37%；2023 年 7 月学习平板市场出货量 41 万台，同比增长 49%。儿童手表市场尽管已经进入成熟周期，2023年上半年销量688万台，同比增长 1%。随着儿童户外活动的增加，市场需求进入恢复阶段。2023 年 7 月其销量 160 万台，同比下降 3%，预计更多需求将会随着新品上市在 8 月释放。K12 和大学生 PC 受到疫情期间集中释放需求的影响，2023年上半年出货量 500 万台，同比下降 26%；2023 年 7 月其下降幅度明显收窄，销量 104 万台，同比下降 12%。</p><p></p><p>整体而言，今年暑期教育学习终端市场促销有以下四个亮点：</p><p></p><p>小红书种草和直播崛起，暑期促销迎来新销售闭环；带动二手市场回收端的增长，二手平台开始试水暑期促销；电商平台学生身份认证会员，提升暑期促销转化效率；暑期促销更多融入了娱乐、健身等其他场景的终端，丰富消费者选择。</p><p></p><h3>教育学习场景市场规模预测及生态架构</h3><p></p><p></p><p>IDC 统计数据显示，2023 年教育学习场景市场规模达到 1,102 亿美元，同比增长 4.2%。预计 2024 年同比增长 9.6%，到 2027 年，市场规模将超过 1,500 亿美元。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/7e/91/7ee75975f779a237d567f8637cda7791.png\" /></p><p></p><p>教育学习场景生态架构中，不仅有众多硬件制造商参与，也包含了多种类型的软件和服务提供商，例如 AI 解决方案提供商和云服务提供商等。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/66/da/66bbbff9bd4fdbb354fe1d97dd587fda.png\" /></p><p></p><p></p><h3>教育学习场景下的智能终端发展趋势</h3><p></p><p></p><p>教育终端走向个性化和增值化</p><p></p><p>随着教育学习终端的不断升级，市场规模逐渐扩大，教育终端和服务的人均支出逐渐增长，教育终端走向功能个性化和场景增值化。</p><p></p><p>教育场景技术转折点的发生逐渐密集</p><p></p><p>从网络普及到 AI 兴起，再到 AI 升级，新的技术升级带来教育终端市场的产品品类扩充和规模增长。根据 IDC 统计数据，2023 年教育学习终端产品出货量达到 9,930 万台，预计 2024 年将超过 1 亿台。另外，预计到 2027 年，超过 90%的教育学习终端将搭载 AI 相关功能。</p><p></p><p>教育终端功能发展趋势将围绕 AI、安全、健康和内容资源四大方向升级</p><p></p><p>教育AI成为个性化和增值化的核心竞争力之一；终端安全性覆盖范围扩大：内容安全，信息安全，社交安全等；健康相关功能成为重要升级方向，传感器等技术要求高，护眼、矫姿、运动、睡眠监测等；教育资源内容成为教育生态构建的重要发力点，也是吸引家长的重要部分；暑期促销进一步强化线上线下渠道融合，例如即时零售和短时租赁。</p><p></p><p>IDC 中国助理研究总监潘雪菲认为，尽管教育学习场景发展多年，但由于其用户的需求和代际更迭稳定，市场需求具有细分化以及新技术落地的可实施性较高，该场景下的智能终端在技术和产品上的创新和提升空间较大，因此不断有新厂商加入该赛道，使该市场依然焕发活力和生机。尤其在大模型和生成式 AI 的催化下，教育终端领域将进一步走向个性化和增值化。</p>",
    "publish_time": "2023-08-22 17:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "特斯拉内鬼泄露100G数据，影响超7.5万人",
    "url": "https://www.infoq.cn/article/7mmOH015JtTNBVklVLTS",
    "summary": "<p>8 月 21 日消息，根据美国缅因州总检察长办公室在上周五发布的通知，特斯拉公司在今年5月份发生的数据泄露事件影响了逾7.5万人，其中包括与员工相关的记录，这起事件源自“内部员工的不当行为”。</p><p>&nbsp;</p><p>今年5月，特斯拉举报人向德国《商报》泄露了100GB数据，其中包含数千份客户投诉，这些投诉引发了人们对特斯拉全自动驾驶(FSD)功能安全性的严重担忧。</p><p>&nbsp;</p><p>缅因州总检察长办公室的通知显示，共有75,735人受到此次数据泄露事件的影响，其中包括缅因州的9名居民。这些人似乎是特斯拉的现任或前任雇员。这100GB数据，包含了这些人的姓名，以及如地址、手机号码和电子邮件地址等联系信息。<a href=\"https://www.theregister.com/2023/08/21/breach_of_75k_employee_records/\">泄露的数据还包括大约2400起关于特斯拉突然加速的客户投诉，以及另外1500起关于刹车问题的投诉</a>\"。</p><p>&nbsp;</p><p>《商报》将此次泄露事件描述为该公司未能保护好其敏感数据。据原报道中引用的一位特斯拉律师的说法，据特斯拉称，其中一名泄密者据说是一名心怀不满的前服务技术人员，据称他滥用了访问权限并泄露了数据。&nbsp;</p><p>&nbsp;</p><p>特斯拉数据隐私官 Steven Elentukh 表示，他们是在 5 月 10 日首次得知此事，当时德国新闻媒体 Handelsblatt 的记者联系该公司，告知他们已获得“特斯拉机密信息”。经过特斯拉内部调查显示，两名特斯拉前员工违反特斯拉的信息技术安全和数据保护政策，挪用并与媒体分享了这些信息。</p><p>&nbsp;</p><p>根据通知，这家受 GDPR 等严格数据隐私法管辖的德国媒体不打算公布泄露的数据。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/85/85dab8e281edb8f8b053dbbc5dcac3cb.jpeg\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>特斯拉已对这两名前员工提起了诉讼，特斯拉给员工的通知信中说，诉讼导致这些前员工的电子设备被扣押，上面可能含有公司信息。“特斯拉还获得了法院命令，禁止前员工进一步使用、访问或传播这些数据，否则将受到刑事处罚，”信中写道，“特斯拉与执法部门和外部法医专家进行了合作，并将继续采取必要的适当措施。”</p><p>&nbsp;</p>",
    "publish_time": "2023-08-22 17:16:02",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "全网最全！实测亚马逊 AI 编程助手 Amazon CodeWhisperer",
    "url": "https://www.infoq.cn/article/CkLkSpx0p9egiR1XLsON",
    "summary": "<p>今天小王学长带大家实际测试一下亚马逊最近出的 AI 编程助手 Amazon CodeWhisperer，从不同角度和不同功能来看看这款编程助手是否可以帮助我更好的进行开发任务。</p><p></p><p>文章目录：（大家先预览下）</p><p></p><p><code lang=\"undefined\">一、CodeWhisperer简介\n1.1 CodeWhisperer 是一个重要的生产力助推器\n   1.2 CodeWhisperer 的实际应用\n二、CodeWhisperer安装教程\n2.1 IntelliJ IDEA安装CodeWhisperer插件\n2.2 VSCode安装CodeWhisperer插件\n2.3 PyCharm安装CodeWhisperer\n2.4 快捷键使用方法\n三、简单自动编码演示\n3.1 单行代码自动补全\n3.2 CodeWhisperer生成完整代码\n3.3 其根据签名自动生成代码\n四、AI编程代码实测及项目体验\n4.1 简单函数代码测试\n4.2 代码安全扫描实测\n4.3 代码引用跟踪功能实测\n4.4 计算机视觉工程项目实测\n五、Amazon CodeWhisperer实测体验总结\n5.1 CodeWhisperer 可以帮助我成为一个更好的开发者吗？</code></p><p></p><h3>一、CodeWhisperer 简介</h3><p></p><p></p><p>CodeWhisperer 是亚⻢逊出品的一款基于机器学习的通用代码生成器，可实时提供代码建议。</p><p></p><p>在编写代码时，它会自动根据我们现有的代码和注释生成建议。从单行代码建议到完整的函数，它可为我们提供各种大小和范围的个性化建议。</p><p></p><p>CodeWhisperer 还可以扫描我们的代码以突出显示和定义安全问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bb/bb2542cb7e15dbe89b8d54228fe7fc45.png\" /></p><p></p><p><a href=\"https://xie.infoq.cn/link?target=https%3A%2F%2Faws.amazon.com%2Fcn%2Fcodewhisperer%2F\">codewhispereropen in new window</a>\"：亚马逊官方出品</p><p></p><p>目前仅以插件的形式在<a href=\"https://xie.infoq.cn/link?target=https%3A%2F%2Fcode.visualstudio.com%2F\">VS Codeopen in new window</a>\"、<a href=\"https://xie.infoq.cn/link?target=https%3A%2F%2Fwww.jetbrains.com%2F\">Jetbrainsopen in new window</a>\"等 IDE 里面使用，如果想试一试可以用 VS Code，目前无限制免费使用免费，并且对环境要求不高，还轻量~</p><p></p><p>亚马逊在 2022 年 6 月发布了 CodeWhisperer 预览版，现在它支持 Python、Java 和 JavaScript。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/37/37f1e56a2aa72c0b02726c0948616f80.png\" /></p><p></p><p>CodeWhisperer 经过数十亿行代码的训练，由机器学习提供支持，旨在实现相同的目标。无论我们是学生、新开发人员，还是经验丰富的专业人士，CodeWhisperer 都有助于我们提高工作效率。</p><p></p><p>其支持多种 IDE 和语言。要开始使用，我们只需安装合适的 <a href=\"https://xie.infoq.cn/link?target=https%3A%2F%2Faws.amazon.com%2Ftools%2F\">AWS IDE Toolkit</a>\"，启用 CodeWhisperer 功能，输入我们的预览访问代码，然后开始键入：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/70/70127833852e445c35d11a9675f0c423.png\" /></p><p></p><p>CodeWhisperer 可以持续检查我们的代码和注释，并为我们提供语法正确的推荐。这些推荐根据您的编码风格和变量名称合成，而不仅仅是代码段。</p><p></p><p>​ CodeWhisperer 使用多个上下文线索来提供推荐，包括源代码中的光标位置、光标前面的代码、注释以及同一项目中其他文件中的代码。您可以按原样使用推荐，也可以根据需要对其进行改善和自定义。正如我之前所提到的，我们使用从开源存储库、内部 Amazon 存储库、API 文档和论坛中提取的数十亿行代码训练（并将继续训练）CodeWhisperer。</p><p></p><p>​在 AWS 博客的<a href=\"https://xie.infoq.cn/link?target=https%3A%2F%2Faws.amazon.com%2Fblogs%2Fcompute%2Fintroducing-amazon-codewhisperer-in-the-aws-lambda-console-in-preview%2F\">一篇文章</a>\"中，Mark Richman 解释说，CodeWhisperer 的模型是在“包括 Amazon 开源代码在内的各种数据源”上训练的。有了这个语料库（显然<a href=\"https://xie.infoq.cn/link?target=https%3A%2F%2Fwww.techrepublic.com%2Farticle%2Faws-getting-better-at-open-source%2F\">确实存在</a>\"）完善 CodeWhisperer 的模型，编写从 S3 读取文件的代码应该是一个很好的测试用例。</p><p></p><p>​在使用 CodeWhisperer（CW）时，我们需要写一个注释，描述我们希望函数去做什么。注释的描述性和准确性越高，系统就越能更好地推断出我们想要的逻辑。</p><p></p><p><code lang=\"undefined\">Function to open an S3 file</code></p><p></p><p>比如注释以 Function 开头，让 CW 知道你想要创建一个函数。也就是说，你需要添加一个注释，作为给 CW 的提示。</p><p></p><p>CW 分析注释并生成一个函数的定义。此时，你可以在生成函数体之前修改函数定义。CW 还可能提供多种函数定义供你选择。</p><p></p><p>IntelliJ 集成 CodeWhisperer 的截图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/31/312ec138d0530e085bd4f9ef309fe2ab.jpeg?x-oss-process=image%2Fresize%2Cp_80%2Fauto-orient%2C1\" /></p><p></p><p>点击“插入代码”，你的函数就在注释的下方创建好了。注意 CodeWhisperer 不仅插入了代码，还创建了一个文档字符串。</p><p></p><p><code lang=\"undefined\"># Function to open an S3 file\ndef open_s3_file(filename):\n    \"\"\"\n    :param filename:\n    :return:\n    \"\"\"\n    s3 = boto3.resource('s3')\n    return s3.Object(bucket, filename).get()['Body'].read()</code></p><p></p><p>看起来不错！这段代码实现了你的注释所期望的功能，并且是在几秒钟内就生成了。</p><p></p><p>节省了查找 boto3 API 的时间，你只需要检查代码，确保语义正确。</p><p></p><p>接着看看提出更多要求时，会发生什么。</p><p></p><p>这有一个很有用的例子：写一个函数从 S3 的文件中返回前“n”行。</p><p></p><p><code lang=\"undefined\"># Function to get first n lines from a file in S3\ndef get_first_n_lines_from_s3(filename, n):\n    \"\"\"\n    Get the first n lines of a file in S3\n    :param filename:\n    :param n:\n    :return:\n    \"\"\"\n    lines = []\n    for line in open_s3_file(filename):\n        lines.append(line)\n        if len(lines) &gt;= n:\n            break\n    return lines</code></p><p></p><p>真厉害！CodeWhisperer 使用了之前创建的辅助方法 open_s3_file，并生成了正确的函数。</p><p></p><p>在 CW 生成函数体之前，你可以修改参数名，提高代码的可读性。例如，如果我们输入：</p><p></p><p><code lang=\"undefined\"># Function to find common elements in lists</code></p><p></p><p>CW 会提示：</p><p></p><p><code lang=\"undefined\">def find_common_elements(list1, list2)</code></p><p></p><p>在生成函数体之前，我们可以修改函数定义，使其更具描述性：</p><p></p><p><code lang=\"undefined\">def find_common_elements(first, second)</code></p><p></p><p>如果我们接受它的函数定义，CodeWhisperer 将使用函数签名和注释来构建函数体。得到的函数将使用改进后的参数名。</p><p></p><p><code lang=\"undefined\"># Function to find common elements in lists\ndef find_common_elements(first, second):\n        return list(set(first) &amp; set(second))</code></p><p></p><p>CodeWhisperer 不仅仅可以创建整个函数；它还可以在函数中插入代码片段，并在过程中推断相关变量。</p><p></p><p><code lang=\"undefined\"># reverse the list order\n  lines.reverse()</code></p><p></p><h3>1.1 CodeWhisperer 是一个重要的生产力助推器</h3><p></p><p></p><p>使用 CodeWhisperer，我能够更快地编写代码。到目前为止，最大的价值是 S3 示例所演示的功能。</p><p></p><p>如果我自己写代码，大部分时间将会用来查找 boto API 文档，以确保写出正确的调用。使用 CodeWhisperer，则只需三秒钟。</p><p></p><p>这让我想到了一段曾花了很多时间的烦人代码：给 CloudWatch 发送数据。让我们看看 CodeWhisperer 能否有所帮助，试试提供注释：“Function to emit a CloudWatch metric”。</p><p></p><p><code lang=\"undefined\"># Function to emit a cloudwatch metric\ndef put_metric_data(metric_name, metric_data):\n    \"\"\"\n    Put a metric data into cloudwatch\n    :param metric_name:\n    :param metric_data:\n    :return:\n    \"\"\"\n    cloudwatch = boto3.client('cloudwatch')\n    cloudwatch.put_metric_data(\n        Namespace='my_namespace',\n        MetricData=[\n            {\n                'MetricName': metric_name,\n                'Dimensions': [\n                    {\n                        'Name': 'string',\n                        'Value': 'string'\n                    },\n                ],\n                'Unit': 'Seconds',\n                'Value': metric_data\n            },\n        ]\n    )</code></p><p></p><p>非常有用！CW 为我节省了许多打字和查阅 API 文档的时间。</p><p></p><p>我有可能需要重构这段代码，但即使我从零开始编写它，第一步也要写出类似这样的原始逻辑。如今只花三秒钟，我节省了编写大量样板代码的时间，有了一个很好的自定义或重构的起点。</p><p></p><h3>1.2 CodeWhisperer 的实际应用</h3><p></p><p></p><p>我在 PyCharm 中安装了 CodeWhisperer ，并对其进行了测试。以下是一些示例，向您展示了它可以执行的操作。我想构建一个质数列表。我键入 # See if a number is pr。CodeWhisperer 完成此操作，然后我按下 TAB（实际键特定于每个 IDE）接受推荐：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/50/500c0ec28db3419c5aab22b842356805.png\" /></p><p></p><p>在下一行，我按下 Alt+C（同样是 IDE 特定），然后我可以在一对函数定义之间进行选择。我接受第一个函数，CodeWhisperer 推荐函数体，以下是我所拥有的：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/88/887a7b1b4abc1e43e00d63c5ad77009d.png\" /></p><p></p><p>我编写 for 语句，CodeWhisperer 推荐循环的主体：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/62/622c74142843362b2c4b06b0e1fc2d53.png\" /></p><p></p><p>CodeWhisperer 还可以帮助我编写用于访问各种 AWS 服务的代码。我从 # create S3 bucket 开始，然后按 TAB 键完成剩余部分：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8b/8ba606406ac4b00c130ab4f525f3abb5.png\" /></p><p></p><p>看到这里，大家是不是觉得还不错，接下来教大家如何安装，很简单的~</p><p></p><p></p><h3>二、CodeWhisperer 安装教程</h3><p></p><p></p><h3>2.1 IntelliJ IDEA 安装 CodeWhisperer 插件</h3><p></p><p></p><p>在 IDEA 中打开配置窗⼝，选择 Plugins，搜索\"<a href=\"https://xie.infoq.cn/link?target=https%3A%2F%2Fso.csdn.net%2Fso%2Fsearch%3Fq%3DAWS%26spm%3D1001.2101.3001.7020\">AWS</a>\" Toolkit\"，点击 Install，点击 OK 按钮，如下图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/54/54d4930e58f053f88c4e8f497512a4f9.png\" /></p><p></p><p>安装完之后重启 IDEA，如下图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/67/67141f4e41c435cddf54e45687e0aa91.png\" /></p><p></p><p>打开 AWS Toolkit 视图（菜单 View/Tool Windows/AWS Toolkit），点击\"Developer Tools\"tab⻚⾯，选择“CodeWhisperer/Start\"，如下图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bb/bbf281237cff42a12ac6a978cd1ce033.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/28/2878cc4d66d334dd7443acb91f2ae1fc.png\" /></p><p></p><p>弹出的窗⼝中选择“Use a personal email to sign up and sign in with AWS Builder ID\"，点击“Connect”按钮，如下图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/38/386c1adddaa9f9708ce32ae558b06fbe.png\" /></p><p></p><p>在弹出的窗⼝中，选择“Open and Copy Code”，如下图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4c/4c4113ddbfb01fea7f410adfccf2fc8c.png\" /></p><p></p><p>此时会在浏览器中打开⼀个⻚⾯，按 ctrl-v 粘贴 code 值，点击“Next“，如下图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/44/445dfc64512bd2246776b702b4ffd247.png\" /></p><p></p><p>输⼊邮箱地址，点击\"Next\"，如下图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e4/e4720fcb0569c2389a9765817a5608f6.png\" /></p><p></p><p>输⼊名字，点击“Next”，CodeWhisperer 会向邮箱中发送⼀个验证码，如下图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8f/8f87263da00f32018865979045910192.png\" /></p><p></p><p>打开邮箱，可以看到验证码，如下图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/9673adeb8c940f2719ec2ac373c1a71c.png\" /></p><p></p><p>复制验证码，粘贴到输入框，点击“Verify”按钮，如下图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c0/c09bdd53cf4fba1d51c823b0063eefe6.png\" /></p><p></p><p>设置密码，点击“Create AWS Builder ID“，如下图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c9/c918c9a0abc3fe79653841cf4eb09efe.png\" /></p><p></p><p>在最后⼀个⻚⾯中点击“Allow”按钮，如下图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/04/04222725ba8339877dacae9b21b253eb.png\" /></p><p></p><p>出现如下提示后，即表示注册 AWS builder ID 成功，如下图：</p><p><img src=\"https://static001.geekbang.org/infoq/0a/0a270d5489291f0d1147b37e234e16fa.png\" /></p><p></p><p>返回 IDEA，在 AWS Toolkit 视图中的 Developer Tools 中可以打开或关闭代码⽣成功能，如下图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/30/30b1184927909cda734eeb9857e9e203.png\" /></p><p></p><p>此时，就可以愉快的使用 AI 编程了。</p><p></p><h3>2.2 VSCode 安装 CodeWhisperer 插件</h3><p></p><p></p><p>安装 AWS Toolkit 插件，具体到 VS Code 侧边栏搜索并安装</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1c/1cf8c7fce77b49f86b74e91489257ba0.png\" /></p><p></p><p>侧边栏点击 aws，&gt;&gt; DEVELIOPER TOOL &gt;&gt; CodeWhisper &gt;&gt; Start</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9c/9c0d59103403bf993274ab37e238438d.png\" /></p><p></p><p>在下拉菜单中点击 Use a personal email to sign up and sign in with AWS Builder ID</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6c/6cb80570926f1d324e544c5b8af1fbca.png\" /></p><p></p><p>点击 Copy Code and Proceed，这将自动复制代码</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/55/55cfd43d9e421d7e36d2397bdedebed2.png\" /></p><p></p><p>一般会提示外部网站打开提醒，选择打开</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2c/2c183ff9adf6670845ffa27b96db2ea4.png\" /></p><p></p><p>打开网站后，输入点击 Copy Code and Proceed 时得到的代码，点击 Next</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1a/1a600fda15aaea04774704814b8111b8.png\" /></p><p></p><p>输入自己的邮箱地址(同时登录你的邮箱等待验证码)，点击 Next</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/51/5151be42636c206581c8d545ce41d19f.png\" /></p><p></p><p>重复之前步骤，但是由于已经在浏览器上登录成功了，所以步骤非常简单 粘贴代码后将会提示以下内容，点击 Allow 即可</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ec/ec34767607b25f65aea3615e600a4ba3.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1f/1fb40eeb7cf2f725f9b2469b3d388497.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2d/2dbe2f5d67dde4c806490330966209d0.png\" /></p><p></p><p>等左下角的 AWS 扩展颜色正常，对勾状态，说明连接成功</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/09/09e79289dca67dd07c96ecfea5c28012.png\" /></p><p></p><p>此时，就可以愉快的使用 AI 编程了。</p><p></p><h3>2.3 PyCharm 安装 CodeWhisperer</h3><p></p><p></p><p>1.打开 Pycharm 插件管理</p><p></p><p>在 JetBrains IDE 中，导航到设置菜单（在 macOS 上为⌘ + ，在 Windows 上为文件→设置），然后单击左侧菜单上的“插件”。</p><p></p><p>在菜单顶部，单击 Marketplace 并在搜索栏中键入 “AWS Tookit”。然后点击安装。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/29/2939944be69fa554ff9735ab6d03c1ba.png\" /></p><p></p><p>2.安装完成后重启 IDE</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f5/f5ba79220d91c667d488f68e555d66b8.png\" /></p><p></p><p>3.将 Pycharm 连接到 AWS（AWS Build ID 创建），重复之前步骤</p><p></p><p>IDE 重新启动后，您将看到一个新的 AWS Toolkit 工具窗口。还可以通过 View -&gt; Tool Windows -&gt; AWS Toolkit（视图 -&lt; 工具窗口 -&lt; AWS Explorer）访问此窗口。</p><p></p><p>然后点击\"Developer Tools\"标签，选择“CodeWhisperer/Start\"</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e9/e94eaaf006044fbabe741061fc484b10.png\" /></p><p></p><p>此时，就可以愉快的在 PyCharm 里使用 AI 编程了。</p><p></p><h3>2.4 快捷键使用方法</h3><p></p><p></p><p>全程需要按快捷键调用 Codewhisperer，主要的几个用法如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ca/ca7d728e5631261e1b21168dfa60ff57.png\" /></p><p></p><p></p><h3>三、简单自动编码演示</h3><p></p><p></p><p>回到 IDEA，看到如下界面，即表示注册并启动成功：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0d/0da6a9d71590d9d22307a71c4938cf8f.png\" /></p><p></p><p>下面我们新建任意 Java 文件,看看他如何能够帮助我们自动生成代码。</p><p></p><h3>3.1 单行代码自动补全</h3><p></p><p></p><p>输入字符串 public。根据输入，CodeWhisperer 生成了建议列表</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8b/8bc944fe20f1088d88f5b2825ee0a218.png\" /></p><p></p><h3>3.2 CodeWhisperer 生成完整代码</h3><p></p><p></p><p>CodeWhisperer 可以根据编写的注释生成完整的函数。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b2/b25f9a808d0fd70184679fb9e866b2a0.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ec/ecb003b670f08e67b2fad4eff014a477.png\" /></p><p></p><p>类似于 if/for/while 等代码块的生成。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c9/c9819bff61cd7391c6d56371128f4d75.png\" /></p><p></p><p>大家如果看到这有疑问，可以接着看第四部分，有详细的测试说明。</p><p></p><h3>3.3 其根据签名自动生成代码</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fe/fe370085e3cafae34d7f1fdb3b4c9783.png\" /></p><p></p><p>看到这里，大家应该有个简单的了解了，咱们接着往下看~</p><p></p><h3>四、AI 编程代码实测及项目体验</h3><p></p><p></p><h3>4.1 简单函数代码测试</h3><p></p><p></p><p>首先，我先用中文注释了“写一个读取 csv 文件的函数” 回车后可以看到 CodeWhisperer 自动显示出来</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c9/c984adead2428c803683b4bffa620c48.png\" /></p><p></p><p>按快捷键 Tab 确认键入后，接着回车后 CodeWhisperer 又自动生成了以下代码：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/26/26416db3ead4e6f5bc3357fafb58b374.png\" /></p><p></p><p>感觉这个 CodeWhisperer 自动生成的代码还不错，我选择了 Insert Code 键入使用。</p><p></p><p>紧接着用中文又注释了“创建一个简单的爬虫简单函数”</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a0/a0929a67611f9001c2c191f902342586.png\" /></p><p></p><p>在这选择了第三个自动代码，同样 Tab 键入。</p><p></p><p>接下来是注释“冒泡排序”后回车</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d3/d3e5330ff256477de372dd5de427ee7d.png\" /></p><p></p><p>注释“选择排序”后回车</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f0/f00de254eb0e4d7b587c7eb1e5a785ad.png\" /></p><p></p><p>中文注释实测完后又对英文注释进行了测试，如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/85/85d9f0ceb9eeb10b817abc62d9e9a293.png\" /></p><p></p><p>乘胜追击，又对创建和上传文件代码进行自动生成测试，同样得到了预期的效果。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2d/2dbb92d630d1fc4a0a99c73ac56f1f47.png\" /></p><p></p><p>对于简单的函数实测让我感觉这个工具还挺不错的，因为可以根据自己想要的注释自动生成多个代码建议，这样不仅节省了大量的编码时间，而且多种代码建议可供选择，一定程度上提升了自己编写代码的质量。</p><p></p><h3>4.2 代码安全扫描实测</h3><p></p><p></p><p>接下来用 CodeWhisperer 去扫描我们代码中的安全漏洞，以下是运行按钮的位置</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0f/0f7fc06304f71432548d3b90bad693de.png\" /></p><p></p><p>打开我想扫描的文件，然后运行安全扫描</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/97/978f17f91756e7b60ad92fdc2de2f41f.png\" /></p><p></p><p>结果发现 CodeWhisperer 探测到该文件中有两个安全问题。 通过查看问题栏，点击事件定位到代码中，我们将鼠标移入到突出显示的代码，查看建议的措施，如下所示，问题指出在该例子中未加密的 AWS 凭证被记录下来，是一个安全漏洞，它建议我们重写代码并且修复该漏洞。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d0/d0dedd2f7bc4442a3371dce1796e218c.png\" /></p><p></p><p>同样查看第二个问题，CodeWhisperer 告诉我们讲应该把标识设置为 True。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d7/d749281485f5280facf41fa68b5c6391.png\" /></p><p></p><p>根据 CodeWhisperer 的建议，我进行了对应修改，两处安全问题修改如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/20/209fa64f57da6c0e051d4a60aa0fb515.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/969c4d4323ce775ed02f640f907b07b0.png\" /></p><p></p><p>修改后重新扫描了文件，扫描完成，显示没找到问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1c/1cb57110e18e69fdcc80cadc117ee27b.png\" /></p><p></p><p>对于安全扫描这项功能，我还是挺惊艳的，没想到能实测找出问题并给出对应的解决问题，因为这一点我对 CodeWhisperer 的好感又增加了。</p><p></p><h3>4.3 代码引用跟踪功能实测</h3><p></p><p></p><p>在这里想实现一个函数来创建一个 dynamo DB 表。 如下图所示进行了实际测试 “implement a function to create a dynamoDB table”</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4d/4dca28cf736e526e9d3f7ef052140171.png\" /></p><p></p><p>以下是 CodeWhisperer Reference Log 给出的建议：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e8/e88be1d44ca3af9f8d2ad08808d7a114.png\" /></p><p></p><p>根据代码建议标注被文件跟踪器标记为 MIT 许可证，其引用了 Apache-2.0 许可证下的代码。我选择接受了这些标记代码，然后发现 CodeWhisperer 自动记录了引用我需要的许可证信息，这样我就可以在我的代码上添加适当的许可证和归属信息。 这个功能实测完感觉也挺有用的，对代码涉及到的许可证和归属信息问题进行了有效解决。</p><p></p><h3>4.4 计算机视觉工程项目实测</h3><p></p><p></p><p>在对官网显示的几项功能测试完后，又在平时用到的实际项目上进行了测试，我选取了常用的一些 CV 检测模型，以下是 ShuffleNet 的实际测试效果。</p><p></p><p>首先，我在实例化训练数据集上，对缺失的代码段进行测试，看 CodeWhisperer 是否能联系上下文进行代码补全。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ec/ec34080164dffa51dda75f52c8259987.png\" /></p><p></p><p>进行回车操作后，CodeWhisperer 显现出来了所给的建议。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/82/82edf9dc7a0eba42f7a4c97a8fe77213.png\" /></p><p></p><p>目前看所给的建议正确，接着我又对冻结权重部分进行了测试，</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8b/8b85c4bcb5e13e154477259f45d62231.png\" /></p><p></p><p>这回我又利用了 CodeWhisperer 的快捷键 ALT+C 进行了测试，</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e0/e0e16c1b6af0d006d32176719bb6c389.png\" /></p><p></p><p>结果显示自动生成了 False 选项，测试到这里真的让我觉得这个工具是真的好，可以帮助我解决代码中遇到的很多问题。 在训练代码中测试完，我又接着对检测模型代码进行了测试，如下图所示在 transform 指向中为我建议了 img。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ad/adb358023188d45cf66cc159a607dce0.png\" /></p><p></p><p>最后，我对检测模型代码进行了运行测试，正确的检测出图片为蒲公英 dandelion。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c0/c0baee1f6516dedb14a701cb1f5d2d6a.png\" /></p><p></p><p>总的来说，CodeWhisperer 辅助我完成了 CV 模型的代码编写和模型检测，达到了官网所展示的预期。接下来，我要让 CodeWhisperer 帮助我完成更复杂的任务了，哈哈</p><p></p><h3>五、Amazon CodeWhisperer 实测体验总结</h3><p></p><p></p><h3>5.1 CodeWhisperer 可以帮助我成为一个更好的开发者吗?</h3><p></p><p></p><p>通过以上的测试，我觉得它可以帮助我成为一个更好的开发者。</p><p></p><p>首先，它可以为我节省大量的时间和精力，让我能够专注于改进、重构和测试。</p><p></p><p>其次，它通过承担一些同质化的繁重工作，让我有机会成为一个更好的程序开发人员。</p><p></p><p>比如上面的测试的例子是 Amazon 工具（经过 Amazon 开源代码训练）能够表现出色的例子。</p><p></p><p>当然，在大多数开发人员需要花费很多时间的地方，比如编写领域相关的逻辑时，我又多测试了一下，让我们看看 CodeWhisperer 会不会也有帮助。</p><p></p><p>比如从 Python 文档中的数据类示例开始。</p><p><code lang=\"text\">@dataclass\nclass InventoryItem:\n    \"\"\"Class for keeping track of an item in inventory.\"\"\"\n    name: str\n    unit_price: float\n    quantity_on_hand: int = 0\n\n    def total_cost(self) -&gt; float:\n        return self.unit_price * self.quantity_on_hand</code></p><p></p><p>其实我想知道 CodeWhisperer 是否可以向这个类添加一个方法。让我们看看如果添加注释：\" Function that return this item costs more than $10\"，会发生什么？</p><p></p><p><code lang=\"text\">@dataclass\nclass InventoryItem:\n    \"\"\"Class for keeping track of an item in inventory.\"\"\"\n    name: str\n    unit_price: float\n    quantity_on_hand: int = 0\n\n    def total_cost(self) -&gt; float:\n        return self.unit_price * self.quantity_on_hand\n\n    # Function that returns whether this item costs more than $10\n    def expensive(self) -&gt; bool:\n        return self.unit_price &gt; 10</code></p><p></p><p>结果是非常酷的。值得注意的是，CodeWhisperer 给函数起了一个直观的名字，并包含了对 self 的引用。</p><p></p><p>接着，让我们尝试用 CodeWhisperer 来做测试，看是否会触及它的极限。</p><p></p><p><code lang=\"undefined\"># Function to test InventoryItem class\ndef test_inventory_item():\n     \"\"\"\n    Test InventoryItem class\n    :return:\n    \"\"\"\n    item = InventoryItem(\"Widget\", 10, 5)\n    assert item.name == \"Widget\"\n    assert item.unit_price == 10\n    assert item.quantity_on_hand == 5\n    assert item.total_cost() == 50\n    assert not item.expensive()\n</code></p><p></p><p>在上面的代码中，我输入了注释，CW 自动完成了剩下的工作。 测试似乎是一个极好的证明 CW 可以节省时间的例子。我不需要浪费时间去想测试的值，也不用输入所有的成员变量和方法。</p><p></p><p>总的来说，可以帮助我成为一个更好的开发者，但是任何辅助工具都有利有弊，CodeWhisperer 也是才发布不久，通过测试我也想邀请大家去进行实际测试，可以对使用 CodeWhisperer 遇到的问题大家一起相互讨论，一起促进这个编程助手迭代和完善~</p><p></p><p>版权声明: 本文为 InfoQ 作者【攻城先森】的原创文章。</p><p>原文链接:【<a href=\"https://xie.infoq.cn/article/909704e9a44302aa28b2a44e9\">https://xie.infoq.cn/article/909704e9a44302aa28b2a44e9</a>\"】。未经作者许可，禁止转载。</p>",
    "publish_time": "2023-08-22 17:22:09",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]