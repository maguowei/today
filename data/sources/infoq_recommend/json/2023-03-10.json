[
  {
    "title": "详解命令模式本质及其在高复杂调用中的实践案例",
    "url": "https://www.infoq.cn/article/8c74cb9796ad9fbe8c6493a10",
    "summary": "<p>作者：范灿华  阿里同城履约物流技术团队</p><p></p><p></p><blockquote>命令模式是一种设计模式，总结了在特定场景下的最佳设计实践。本文将为大家介绍命令模式的模式本质及灵活运用，并通过一个真实的电商履约系统中的库存调用需求为案例，分享其在高复杂调用中的实践。</blockquote><p></p><p></p><p></p><h1>一、前言</h1><p></p><p></p><p>本文是一篇基于同城履约业务中台与库存系统的协同设计过程中使用到命令模式并获得很好成果而撰写的技术分享文章。命令模式是一种设计模式，总结了在特定场景下的最佳设计实践，它是一种间接经验。为了将这种间接经验变为我们可以使用的直接经验，我们需要做到两点：看清模式本质和灵活运用。</p><p></p><p>1）模式本质：掌握一个设计模式的关键在于发现其核心关注点。每个模式都有一个关注点，例如命令模式的关注点是调用过程，而策略模式和状态模式的类图看起来相似，但它们的运作机制却完全不同：前者关注外部引起的算法变化，后者则关注内部状态的转变变化。通过找到模式的本质关注点，才能真正掌握它。</p><p></p><p>2）灵活运用：在实际应用中，设计模式的实现方式可能会与教科书上的类图略有不同甚至完全不同。因此，我们不能一味地套用模式，而应该根据实际需求进行量身定制和改进。这意味着我们需要深入了解模式本质，然后根据自己的需求来适当调整模式的用法。有时，你可能会意外地创造出一种新的模式。</p><p></p><p>针对以上两点，本文首先特别地会从OOA（面向对象分析）的角度去介绍命令模式的模式本质（2.1. 封装调用），然后列举命令模式的不同玩法及其中的原理用作展示该模式的运用灵活性（3. 灵活运用）。最后一个真实的电商履约系统中的库存调用需求为案例（4. 应用案例），这个案例刚需要隔离的变化点是调用，非常适合命令模式。</p><p></p><p></p><h1>二、模式本质</h1><p></p><p></p><p></p><h2>2.1 封装调用</h2><p></p><p></p><p>直接的调用：命令模式在设计模式的分类中属于行为型模式，它关注的是一种对象之间的调用行为，不管如何，调用行为必然涉及两个角色，他们就是：调用者（Invoker） 和&nbsp;被调用者（Receiver），基本上他们对应的就是两个对象类，并且Invoker类静态编码依赖Receiver类方法进行调用。如果在不考虑其他因素的情况下，这两者的行为关系可以描述为下图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/94/94ffebbc26fcae960cb8b6a3f97d460c.png\" /></p><p></p><p>然后我们来说一下上面的调用特点：</p><p></p><p>上面的调用只有2个对象，调用者（Invoker）和被调用者（Receiver）；其中调用者（Invoker） 是代码静态依赖被调用者（Receiver）的；调用在上面是一个请求过程，这个过程在图中用虚线圈表示；</p><p></p><p>对象化调用：命令模式就是在以上场景下，把上图中虚线圈调用这个调用过程给显式化、抽象化、实例化。本来只是一个调用的过程，我们把它（这个过程）刻画出来封装为一个具体的对象（Concrete Command），这个对象就是命令对象。调用方将会利用命令对象这个代理来帮忙调用被调用方，所以以上的调用过程就变为了下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/91/91c5c1caa3af35eceb02d3e522ec51ac.png\" /></p><p></p><p>这样一来，调用方和被调用方就没有了直接的耦合关系，也就是说他们 “解耦” 了，概括一下这几对象协作的特点：</p><p></p><p>我们多了一个新的具体命令对象（Concrete Command） 对象的职责就是完成调用请求；命令对象持有被调用方Receiver的引用和请求参数，并描述了如何执行请求，被调用方可以被参数化设置到命令对象中；静态代码依赖变成了调用者（Invoker）依赖命令对象（Concrete Command），命令对象（Concrete Command）依赖被调用者（Receiver）调用者（Invoker）可以完全不知道被调用者接口以及执行请求的具体方式和细节，把这些委托打包给命令对象，从而可以少写很多无谓的执行细节代码。</p><p></p><p>隔离调用变化：把调用封装起来后，我们解开了调用者（Invoker）和被调用者（Receiver）依赖，那么就可以轻易的允许调用发生变化，这一点很重要，我们很多时候封装调用都因为调用本身在未来容易发生变化，下面列举一些常见的变化：</p><p></p><p>不同场景下，调用者（Invoker）需要调用不同的 被调用者（Receiver）；被调用对象的方法发生变化，例如换了一个新版本API；请求需要延迟执行，或者一次调用突然需要调用2个被调用者（Receiver）；</p><p></p><p>使得调用的变化可以做到开闭原则的方式很简单，我们给命令对象实现一个命令接口 （Command），让调用者代码只依赖命令接口，这个接口的每一个具体的命令对象代表了一种变化，真正执行的具体命令是可以在运行态确定的，调用方不再依赖具体的调用命令：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d3/d3a00c1826ef8975261c79fab51e5eb6.png\" /></p><p></p><p>提出变化的角色：如果读者对控制反转比较熟悉的话，那么就很自然知道上述中要实现隔离变化的代码编写，其实就是面向超类型编程。面向超类型编程是把设置实例的控制权交给了依赖关系中的最外层（也就是细节层），在命令模式中，我们把这一层称之为客户端（Client）。换句话说，把调用者（Invoker）、 被调用者（Receiver）和命令对象（Concrete Command）隔离开为互相独立的组件后，自然也需要一个角色去组织起来，道理很简单，积木也是需要有人搭才能千变万化，想变成怎样就是客户端（Client）的需求了。</p><p></p><p>现在我们又多了一个角色客户端（Client），整个命令模式的基本参与者都全了，可以整体看一下命令模式的类图。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f8/f83b2ae1c8e706cf5656cd1483186860.png\" /></p><p></p><p>上面是一个比较标准的命令模式的类图，上图中可能大家会比较疑惑的一个点就是被调用者（Receiver）能不能直接实现Command接口，这当然是可以的，但是解耦程度会比较低，我们尽量参数化被调用者，然后做一个傻瓜式的命令。要掌握命令模式，我们还得懂得如何灵活变化去运用它，下面我们看看命令模式的一些基本玩法。</p><p></p><p></p><h1>三、灵活运用</h1><p></p><p></p><p></p><blockquote>Encapsulate a request as an object, thereby letting you parameterize clients with different requests, queue or log requests, and support undoable operations.—— From GoF</blockquote><p></p><p></p><p>设计模式提出者“四人帮”对命令模式的总结非常精辟：参数化请求、记录请求、队列化请求，还可以支持撤销操作。另外还有一种说法是：回调请求就是命令模式的面向对象版。可见在命令对象上面做文章，可以衍生出多种玩法，本章将会详细列举常见的几种。</p><p></p><p></p><h2>3.1&nbsp;组装命令</h2><p></p><p></p><p>命令模式最大优点是解开调用者和被调用者（接收方）的耦合，因此我们可以轻易在一个调用中更换调用请求的接收方，而解开后的组装方式有两种：</p><p></p><p>第一是在Client角色中进行静态代码编写；第二种是实现配置化在运行时动态组装；</p><p></p><p>其中第二种动态组装和拓展点的实现原理是一样的，会根据动态的参数来决定具体执行的命令。我把这种组装的原理描述为下图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9d/9d84b0f5d13d6bbf3af21ff3e4d59b09.png\" /></p><p></p><p>目前有不少框架有类似拓展点的功能的实现，如TMF，IFBF，COLA等。利用拓展点的功能帮忙，我们可以轻松实现以上的方案，当然我建议自己在项目种开发一套，因为你随时都有可能面对框架做不到的变态需求。</p><p></p><p></p><h2>3.2&nbsp;记录命令</h2><p></p><p></p><p>如果我们把调用记录下来，我们就能完成很多不可思议的事情。调用能被记录下的信息主要有：调用的顺序、调用的出入参数、调用的状态等。有了历史记录，就可以对调用的历史执行进行回放或者倒退。下面分别介绍 命令撤销 和 命令日志 的两种回放玩法。</p><p></p><p>命令撤销：命令撤销是发生在命令簇（4.3节有介绍，表示关联关系的命令组）中的一种需求。其实它的原理非常简单，因为命令基本会改变状态，我们给命令接口一个反向的恢复状态的方法（如下面的undo），并且把调用过的命令对象都记录下来，就可以在一个撤销按钮中完成状态恢复操作。（读者可以参考Head First Design Parrtern命令模式的撤销操作）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ba/babc5ef3617321c48a7d58f127459a1f.png\" /></p><p></p><p>调用者具有多个命令插槽，每个插槽可以设置一个命令实例，共同形成一个命令簇（是个List）；调用者维护一个栈，其实是命令插槽的调用历史栈，每一次调用者执行命令就把该命令入栈顶；用户需要倒退命令的时候，将栈顶命令退栈，并执行undo方法，利用栈后进先出的特点完成了历史状态回退功能；</p><p></p><p>命令日志：我们看一个利用函数式编程的不变性来恢复数据的原理，即在不同的时间或者空间节点中只要执行相同的事件函数调用，就一定会达到一个相同的状态。这个原理被广泛应用于很多系统中，例如数据库系统使用binLog事件和数据快照进行备份恢复，Redis使用RDB快照和AOF事件进行数据恢复，Excel文档数据保存等都是经典的应用场景。</p><p></p><p>具体来说，对于大型的数据结构而言，我们难以每时每刻都快速存储下它的状态，为了完成记录每时每刻的状态，我们可以通过上次检查点（CheckPoint）之后的所有操作命令（包括参数）都记录下来，当我们需要恢复数据结构的状态的时候，只需从检查点开始按顺序应用这些操作即可。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d3/d3251485fcbda2f6797a86e0e54b24fd.png\" /></p><p></p><p></p><h2>3.3&nbsp;组合命令</h2><p></p><p></p><p>如果一个命令设计的本身，就是用作封装其他不同命令的组织，我们称这个命令为宏命令。宏命令是一个通用的命令实现类，它类似一种组合模式，持有其他命令的引用，并依次执行他们。因此宏命令最大的作用是我们可以在一次调用中，调用多个命令，宏命令代码如下：</p><p></p><p><code lang=\"null\">public class MacroCommand implements Command {\n  \n  Command[] commands;\n  \n  public MacroCommand(Command[] commands){\n    this.commands = commands;\n  }\n  \n  public void execute(){\n    for(int i = 0; i &lt; commands.length; i++){\n      commands[i].execute();\n    }\n  }\n  \n}</code></p><p></p><p>特别注意：特别注意这个模式的特点是宏命令完全是不需要特殊开发的，它是一个可以组合其他命令的容器命令，也等同于普通的命令。只要对3.1节中命令组装工厂进行适当改造，我们也可以把宏命令用在动态的命令组装上，他可以让调用者在一次调用中完成多个调用请求。4.1 节，我们将会把宏命令用到实际的例子中。</p><p></p><p></p><h2>3.4&nbsp;异步命令</h2><p></p><p></p><p>异步命令：如果场景允许，我们可以把同步调用设计为异步调用。异步调用对象化后的异步命令对象（Concrete Command）打包了整个请求过程细节，对象本身具有状态，所以可以存储，也可以被传递。</p><p></p><p>对于调用者和被调用者而言，一般同步的都是强依赖，而异步则是弱依赖，因此这个解耦很大程度上是一个设计问题。同时我们也应该注意到，异步调用设计有着极大的好处也有自身的缺点。</p><p></p><p>同步调用需要阻塞流程，异步调用不阻塞，并立即返回对性能友好；异步具有削峰填谷的能力，可以堆积命令调用，用时间换计算资源；同步编程简单，异步编程比较复杂；同步的程序状态追求强一致性，异步的程序状态追求最终一致性；</p><p></p><p>队列调度：异步命令对象本质上打包了运算块（参数+接受者+一组操作），所以它可以被不同调用者执行放在任意地址，任意时间执行。例如客户端/调用者可以设置好命令submit到某个队列中（具体实现产品可能是一种中间件，或者定时器），让其他调度者（不同线程）从队列中获取命令执行，从而可以实现请求堆积、请求被按需调度执行（定时调度）等需求。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/960ee4d696831d5b4412bdf4e8049949.png\" /></p><p></p><p>回调通知：在异步编程中，如果我们想要得到异步的调用结果，我们可以设置一个回调函数，让异步过程执行完毕后通知发起异步的一方。如果这个回调函数设计为接口，并在接口的实现中封装真正的接受者和其操作，这正好就是命令对象的用法，只是看问题的角度不同，所以可以认为命令模式是回调的面向对象的版本。</p><p></p><p></p><h1>四、应用案例</h1><p></p><p></p><p>介绍完上面的命令模式本质和基础玩法后，这节将介绍一个同城履约中台域的真实案例。该案例应用到了以上提到的组装命令、宏命令、队列化请求等玩法。同城履约域主要负责近场零售商品的配送调度管理，它需要承接多种商家多种配送玩法（业态）的配送需求。其中对商品的物流操作的调度管理有多个通用的节点，包括创单、出库、运输、揽收和妥投等，而这些节点都可能需要去驱动库存的信息流变化，下面从出库节点的「仓单打包出库」服务作为例子介绍履约域与库存的关系。</p><p></p><p></p><h2>4.1&nbsp;识别调用变化</h2><p></p><p></p><p>例子：我们用一个设计良好的领域服务组件开始介绍，如下图所示：假设我们有一个「仓单打包出库」的通用领域服务，完成仓单出库履约系统要做的事情有：</p><p></p><p>1）记录数据：记录真实的出库数量；</p><p>2）设置状态：设置仓单为出库状态；</p><p>3）操作库存：把占用的业务库存正式扣减掉；</p><p>4）推进履约单；推动对应的履约单状态；</p><p></p><p>库存调用的变化：现在有两个不同的业务身份（淘系商家、外部商家），他们在「仓单打包出库」操作库存是调用不同的库存系统的，如果是直接硬代码编写（大家熟知的if大法），就需要每一次不同的业务身份变更，都要变更这个领域服务。这样的系统是无法维护的，因为履约域具有数百个业务身份，而且所对接的库存系统也是多种多样。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b0/b03d4522436c3ff9ba62adb59dc8b229.png\" /></p><p></p><p>结合上图所示，一个类似这种「仓单打包出库」服务的库存操作步骤可能存在哪些变化点呢？</p><p></p><p>被调用者变化：针对一个履约域的领域服务（如上面的【仓单打包出库】），不同的业务身份都可能调用不同的库存系统；调用者变化：针对同一个库存系统，它可能会被履约域中的其他领域服务调用，如【缺货处理】、【妥投处理】等；调用参数变化：针对同一个库存系统，不止有扣减，还可以有其他调用类型和参数，例如占用、释放、加在途等等；调用过程变化：上面库存的调用，可是需要一次性调用不同的库存系统组合，2个或者3个都有可能；</p><p></p><p></p><h2>4.2&nbsp;实现命令组装</h2><p></p><p></p><p>我们意识到了调用的变化，就需要完全的解开库存系统和履约系统的耦合。首先设计一个库存系统代理接口Inventory Receiver，接口的每一个实例都是被调用者（Receiver），它用作封装库存系统提供的API接口，并代表着一个库存系统的一种调用类型。而调用者就是履约域的各个节点，然后，我们再把调用的过程实例化为命令（Command），整体做成了一个完整的命令模式。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/42/426dcc4f55701ad69b35b6c5a1d6bce5.png\" /></p><p></p><p>调用配置化实现：设计为命令模式后，【仓单打包出库】领域服务成为一个通用的服务，每一步都抽象出一个稳定的步骤，远离具体细节的变化。其中第三步：操作库存，则调用的是库存命令组装服务。这个组装服务实现了根据不同业务身份创建拥有不同Receiver的库存命令实例，整体一个调用变化为下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/73/739f88a73af2a0a3f96a1d9523576def.png\" /></p><p></p><p>正如3.1节提到，目前也有很多框架都能轻松做到这种动态组装，当然手写一个这样的机制也不是什么难事。具体的运行机制很简单，简单描述如下：</p><p></p><p>右边一个通用的领域服务有4个步骤，其中第三步「操作库存」调用的是一个通用的库存组装服务；左边的实现A、B、C是封装了具体库存系统API的Receiver，他们都实现了接口：Inventory Receiver；config.xml是bean的装配配置文件，库存组装服务在运行时根据不同的商家身份，获取对应的Receiver实例设置到Concret Command中成为库存操作命令，并执行该命令；</p><p></p><p>组合调用：注意，上面的案例中，淘宝商家不仅要调用AIC系统，还需要调用IPM系统，这要求我们在一个Command接口的一次调用中实现AIC和IPM2个系统的调用，我们有两种实现方式：</p><p></p><p>方式1：在Command的接口实现中，把调用AIC Receiver和调用IPM Receiver的代码都写完，提供一个臃肿的接口实现；方式2：设计一个宏命令模式实现（机制见3.2节介绍）：把AIC Receiver和IPM Receiver 添加到到宏命令容器中；宏命令接口的逻辑就是依次调用宏命令容器里面的命令；</p><p></p><p>针对组合调用的需求，上面的方式1的解耦程度是不如方式2的，因为如果出现某个业务身份在该领域服务下仅仅只需调用AIC或者IPM的情况，或者又有需要在一个Command接口实现中调用3个库存系统，方式1都需要开发代码，而方式2仅仅配置即可，所以上面的实现2不仅可以代替方式1，还更具有灵活性，这就是松耦合的魅力。</p><p></p><p></p><h2>4.3&nbsp;识别命令簇</h2><p></p><p></p><p>在大家熟知的《Head First Design Parttern》书籍中，里面例子重点介绍了一种「遥控器」的设计，遥控器具有多个插槽，也就是可以在一个调用者里面设置多个命令，形成一个命令簇。如果我们能在实际应用中发现这种调用组，而且他们具有关联关系，那么命令模式就可以把这种命令簇及其关联逻辑封装起来，用作应对软件变化。</p><p></p><p>库存命令簇：上面只给到一个领域服务，但是一个完整的履约域是具有多个状态节点的，而其中在一次履约过程中就有不少节点中的领域服务需要和库存系统交互，例如【履约单取消】、【仓单打包出库】、【缺货处理】、【妥投处理】、【退货回仓】等等，他们不仅有顺序关系，而且通常在设计编码中都有很多共同逻辑，这些有相关性的调用集合，就是一个命令簇。而且，更深一层考虑，他们本身就可以形成一个子领域，配合下图，我们把相关特点列举如下：</p><p></p><p>业务身份：库存调用子领域应该有自己独立的业务身份，并以业务身份为维度组织命令的配置，组装出关联命令簇；库存流程：一个业务订单完整的生命周期中，库存的命令簇必然按顺序调用，有顺序关系的命令簇形成库存调用流程；库存跟踪：库存跟踪是综合了库存流程的实例化和数据化的结果，它刻画的是整个库存调用的生命周期；监控运维：考虑命令簇和多业务身份，调用量会变得极大，那么系统异常问题、库存不足问题、库存查询问题等就需要用到系统自动化级别的监控运维手段，实现这些需求需要库存跟踪的基础；</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7d/7d1b72f9009162fd2ddd672ae9cbb379.png\" /></p><p></p><p>配置命令簇：如下表所示，每个业务身份都有自己的调用节点组，一个组形成了完整的调用流程。作为一个履约中台系统，经常会新加或者减少业务身份，因此配置化方式组织命令簇及库存调用流程就显得非常必要，当开展新业务的时候，只需一个新的组合配置即可支持，符合软件开发开闭原则，配置化具有以下特点：</p><p></p><p>针对履约域的一个节点（如【履约单创建】），不同的业务身份都可能调用不同的库存系统（下面的AIC\\TIC\\GSI）；不同业务身份即使使用同一个库存系统（如AIC系统），他们的库存协调所需要的命令组合也可能是不一样的；针对同一个节点（如【履约单创建）和同一个库存系统，不同业务身份调用的参数也可能不一样，因此参数也可以配置化；</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/89/8984dde058bc0492a0457b26c7e04d0f.png\" /></p><p></p><p>空命令（NoCommand）：上表所示，一行代表一个命令簇，一个命令簇可能在某个节点（如「缺货处理」）是不做任何事的，这个时候我们可以用到NoCommand。NoCommand 对象是一个空对象的例子，当你不想返回一个对象的时候，空对象就很有用，如上图所示，「外单」的业务身份在「缺货处理」这个节点上，是不需要执行库存调用的，但返回null给调用者就会出现异常，所以这个时候我们可以把不调用任何库存系统的NoCommand实现返回。</p><p></p><p>库存调用跟踪：我们以业务身份为维度组织了命令簇，实现了命令簇组织的配置化，并且以命令簇的顺序执行特性绘制了库存执行流程。然而命令簇配置和库存流程都是静态的，为了运维和管控好库存调用，我们还需要关注每个订单的执行情况，做到对每个调用都精确跟踪。</p><p></p><p>想要跟踪履约单的库存调用，我们需要履约单当前库存状态和历史的库存执行流水。我们可以用库存跟踪单刻画一个订单实例当前状态，把命令的每次执行结果作为库存的执行流水，并用库存跟踪单把业务履约单和命令对象、命令流水等库存的串联关联起来，串联的ER图如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/011e450c100e49079cb09a1fa2b44a11.png\" /></p><p></p><p>库存跟踪单可以告诉我们的信息大概有以下几点：</p><p></p><p>该订单命中了哪个业务身份配置；该订单库存生命周期有哪些调用组，调用的顺序是怎样的；该订单当前在执行哪个调用，该调用是被什么履约域事件触发的；该订单历史上执行过哪些调用（命令），调用的出入参是什么，是否成功等；</p><p></p><p>命令簇顺序管理：另一方面，库存的跟踪还包括保证正确的库存调用顺序，例如某个业务的调用组的执行流程如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2a/2a39fa872c53edfe7329e0b63920f848.png\" /></p><p></p><p>假设以上的调用都是异步调用，通过接收履约域的标准异步消息进行，因为是异步，所以就有可能「退货」消息先到，然后「妥投」消息后到，发生这种情况，就会导致库存调用出现各种可能的问题。解决该方法也很简单，利用一个可以处理当前状态和事件的库存状态机+延迟执行（Scheduler的队列命令）就可以保证流程的正确执行。</p><p></p><p></p><h2>4.4&nbsp;识别调用边界</h2><p></p><p></p><p>这一节中，我们围绕库存调用把范围拓展到了命令簇，并且为命令簇为基础刻画了一个业务的完整库存调用生命周期，实现了从静态的库存流程设计到动态的库存跟踪掌控。这个过程我们发现库存的调用内容完全和履约主业务没有强关联，所以我们可以考虑把这些内容从履约业务系统中隔离出来，给他们划分一个清晰的边界。</p><p></p><p>库存界限上下文：库存调用作为履约系统的子域属于一个小分支，并不在核心流程内，即使不做库存操作，也不会影响一个履约主流程的运行，所以他属于弱依赖，因此，我们可以出于组件独立性的考虑，把库存调用和核心域（履约主系统）划分一个明确系统边界，让库存独立形成一个库存界限上下文。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f2/f218049205f6e25c74c440b28ad52317.png\" /></p><p></p><p>如上图所示，除了为库存调用划分边界，成立库存界限上下文外，核心域（履约主系统）在调用上还可以划分其他边界和上下文。假设履约域还要驱动计费的流转，那么我们还可以划分出一个计费界限上下文，不过这就是另一个话题了。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5f/5fa911e827f3aa9069f4e4d6671a06c3.png\" /></p><p></p><p>库存调用协同系统：综合上面上下文中的大规模的配置化管理、库存的流程管理、库存的跟踪、监控、运维后，我们完全有理由为这个库存调用上下文建立一个独立部署的系统，其作用类似中间件的作用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/94/94c91deec21a1001b52f029eb0569021.png\" /></p><p></p><p>现在，我们所有的库存需求都可以在该系统中实现，而且部署、变更都不会影响履约主系统，这是一个很好的实践。下面我们从监控运维、查询可视化、新业务接入分别看看这个围绕库存调用的系统所能做的事情。</p><p></p><p>调用监控运维：方法调用都需要面临一个调用失败的问题，失败的原因可能有业务异常、系统异常，这些异常可能是可以重试成功的，有些则无法重试成功，只能人工插入管理。在一些比较小的系统，或者调用量不大的系统，发生这样的问题次数不多，我们可以通过系统日志简单运维，但像履约域每日上百万，超千万级别的调用，量表到质变，管理运维就是一个新的问题了。</p><p></p><p>调用状态记录：那么这些调用异常的状态应该记录在哪里？现在我们有一个很好的答案就是用命令对象（Command），并可以把命令对象持久化到数据库中等待使用。我们记录调用的状态包括很多，调用的出入参数、命中的业务配置，触发调用的事件等等调用失败重试：对于系统宕机，网络异常等调用失败问题，我们可以通过重试一定次数来解决，而重试本身也是一个问题，从失败记录、批量发现、定时重试都可以通过一个统一的模块管理，和业务流程无关。调用异常报表：对于无法重试成功的异常调用，简单的日志告警容易使人疲劳，或许这个时候定期出一个调用异常报表更适合，在数据库中的命令对象离线化后，做这种事就很简单。调用数据订正：当我们发现库存调用问题后，我们很大情况下解决方案是需要订数据，然后重试，因为命令对象记录了调用参数，因此修改参数重试命令也是简单可行。</p><p></p><p>我们现在从调用的监控运维视角，看一下系统对调用监控运维自动化的运作流程：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/41/41745b5e2d3eab39e5b0996af8e84b21.png\" /></p><p></p><p>命令调用可视化：在一个调用如此庞大的系统，即使是在日志加加了trace日志作为跟踪，可能也容易造成混乱，让运维人员在库存查询时变得很痛苦，但如果我已经用库存跟踪单刻画了所有调用的状态信息，那么我基本可以通过一个订单id，找到该库存跟踪单，并可以在数据库中查到该跟踪单的所有库存调用命令和调用流水。我们把这些数据可视化，将会节省运维和开发排查问题的大量时间。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b1/b11d2cc03c6271c56a0d0480e3e28aa4.png\" /></p><p></p><p>新业务开发流程：现在我们回归业务，一个系统设计再厉害，如果在应变新需求的时候需要大动干戈的修改旧代码，那这个系统必然是一个设计失败的系统。所以我们现在讨论一下库存系统的新需求接入流程，用以评估系统的可用性，我们将分别从命令变化的几个方面的需求进行讨论：</p><p></p><p>1）新业务身份接入：履约中台系统，承接各种订单的近场履约服务，而业务总是有新模式，所以就会有新的业务身份，也可能会产生新的库存调用变化，但因为履约域、库存系统都是通用的，消息/接口也是标准的，所以新的业务身份，只需要加配置文件（配置调用组、流程、调静态用参数）即可运行。</p><p></p><p>2）新库存系统接入：如果新的业务身份需要调用的库存系统之前没接入过呢？对比新业务身份接入，我们只是缺少配置的Receiver而已，因此只需要创建新的Receiver实例，封装需要接入的库存系统API，即可完成需求。完全也是拓展化开发。</p><p></p><p>3）新调用节点的接入：一个新的业务身份要调用新的节点，或者某个旧的业务身份需要加一个新节点，因为履约域的系统是标准的消息，所以也不需要修改，配置即可。</p><p></p><p>4）新的调用系统的接入：如果除了履约域要接入外，其他系统也需要接入库存调用系统，那么就需要做一个防腐层，把新系统的消息转化为库存协同系统的标准消息即可。</p><p></p><p>库存系统的所有变化，无非就是以上几个方面，开发应对基本的新代码及新配置，做到了节点，Receiver的完全解耦复用，同时复用系统所有能力（如可视化、监控运维等）。而且最重要的是，即使新增平台的能力，也是所有业务可以享用的 。到这里，库存系统的基本功能介绍完毕，而且实践各个方面都能证明它能极大提升我们的生产力。</p><p></p><p></p><h1>五、结束语</h1><p></p><p></p><p>相比起一般的设计模式例子，本文的案例更系统的是把请求调用进行了多方位的管理，包括命令组织为流程、调用的可视化、调用的批量处理等等，而做这些的前提都是把请求调用封装起来，本质上并没有变化，我们的关注点一直都在调用上面。</p><p></p><p>另外，文中围绕命令模式的本质，总结出了几种经典玩法背后的形式，几乎涵盖了调用变化的主流场景。当发现一个应用场景主要变化点在调用的时候，我们就可以考虑是否利用重构工具把请求封装起来，以便在需求再次变化的时候，尝试通过记录命令、配置命令、组合命令、异步命令等方式进行拓展性开发，最大限度降低开发风险和维护成本。命令模式如此，其他设计模式也是如此。</p><p></p><p>最后，一个设计模式的应用范围也不要限制在一个独立部署的系统内，也可以拓展到系统之间的设计中。例如经典的观察者模式，在系统之间的应用就非常之广。本文案例中的命令模式也是跨系统的应用，甚至可以跨组织架构之间的应用。为什么不需要被系统所限制呢？因为系统与系统之间的调用本质依旧是组件和组件之间的调用，只是其中的边界和方式有所改变。</p><p></p><p></p><h2>引用</h2><p></p><p></p><p>《Head First设计模式》Eric Freeman &amp; Elisabeth Freeman with Kathy Sierra &amp; Bert Bates [著].O`Beilly Taiwan公司[译].2007.中国电力出版社</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0a/0a182daf38208273d04db744f256587f.png\" /></p><p></p>",
    "publish_time": "2023-03-10 13:26:26",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何基于 Apache Doris 构建简易高效的用户行为分析平台？",
    "url": "https://www.infoq.cn/article/EIDCeKCqX9SHIlsItDud",
    "summary": "<p>从上世纪 90 年代初 Bill Inmon 在《building the Data Warehouse》一书中正式提出数据仓库这一概念，至今已有超过三十年的时间。在最初的概念里，数据仓库被定义为「一个面向主题的、集成的、相对稳定的、反映历史变化的数据集合，用于支持管理决策」，而<a href=\"https://www.infoq.cn/article/G-NGJllXC8zhCjpWhbl9\">数据湖</a>\"最初是为了解决数仓无法存储海量且异构的数据而构建的集中式存储系统。</p><p></p><p>时代的发展与用户数据应用诉求的演进，催生了数据架构的不断革新，也衍生了更复杂的技术形态。可以清晰看到现代数据架构从计算到存储都在向着融合统一的方向发展，新的数据湖范式被提出，这也是 Lakehouse 诞生的背景。作为一种全新的、开放式的数据管理架构，Lakehouse 提供了更强的数据分析能力与更好的数据治理能力，也保留了数据湖的灵活性与开放式存储，为用户带来更多价值：</p><p></p><p>从存储的角度：统一数据集成，避免冗余存储以及跨系统间 ETL 带来的繁重工程和失败风险；从治理的角度：支持 ACID、Schema Evolution 与 Snapshot，数据与元数据皆可治理；从应用的角度：多引擎访问支持、可插拔，通过统一接口进行数据访问，同时适用于多种工作负载 Workload；……</p><p></p><p>如果我们把 Lakehouse 从系统层面进行解构，会发现除了需要 Apache Iceberg、Apache Hudi 以及 Delta Lake 等数据湖表格式（Table Format）以外，高性能分析引擎更是充分发挥湖上数据价值的关键。</p><p></p><p>作为一款极速易用的开源实时 OLAP 数据库，<a href=\"https://www.infoq.cn/article/0MiKpHhupXlSOFjbxQrV\">Apache Doris </a>\"自 0.15 版本即开始尝试在 Apache Iceberg 之上探索与数据湖的能力结合。而经过多个版本的优化迭代，Apache Doris 在数据湖分析已经取得了长足的进展，一方面在数据读取、查询执行以及优化器方面做了诸多优化，另一方面则是重构了整体的元数据连接框架并支持了更多外部存储系统。因此 Apache Doris 已经完全具备了构建极速易用的 Lakehouse 架构的能力，并且也已在多个用户的真实业务场景中得到验证和推广，我们希望通过 Apache Doris 能为用户在更多场景中带来价值：</p><p></p><p>湖仓查询加速利用 Apache Doris 优秀的分布式执行引擎以及本地文件缓存，结合数据湖开放格式提供的多种索引能力，对湖上数据及文件提供优秀的查询加速能力，相比 Hive、Presto、Spark 等查询引擎实现数倍的性能提升。统一数据分析网关利用 <a href=\"https://www.infoq.cn/video/45SWKZgG1z7Xh0bHFRvK\">Apache Doris </a>\"构建完善可扩展的数据源连接框架，便于快速接入多类数据源，包括各种主流关系型数据库、数据仓库以及数据湖引擎（例如 Hive、Iceberg、Hudi、Delta Lake、Flink Table Store 等），提供基于各种异构数据源的快速查询和写入能力，将 Apache Doris 打造成统一的数据分析<a href=\"https://www.infoq.cn/article/Hpu9ifGK71ElKaptHwUN\">网关</a>\"。统一数据集成基于可扩展的连接框架，增强 Doris 在数据集成方面的能力，让数据更便捷的被消费和处理。用户可以通过 Doris 对上游的多种数据源进行统一的增量、全量同步，并利用 Doris 的数据处理能力对数据进行加工和展示，也可以将加工后的数据写回到数据源，或提供给下游系统进行消费。该能力使得 Apache Doris 能够成为业务的统一数据枢纽，降低数据流转成本。更加开放的数据生态通过对 Parquet/ORC 等数据格式以及开放的元数据管理机制的支持，用户不用再担心数据被特定数据库引擎锁定，无法被其他引擎访问，也不用再为数据的迁移和格式转换付出高昂的时间和算力成本，降低用户的数据迁移成本和对数据流通性的顾虑，更便捷、放心地享受 Apache Doris 带来的极速数据分析体验。</p><p></p><p>基于以上的场景定位，我们需要进一步去思考在构建 Lakehouse 过程中需要如何去设计和改造系统，具体包括：</p><p></p><p>如何支持更丰富的数据源访问以及更便捷的元数据获取方式；如何提升湖上数据的查询执行性能；如何实现更灵活的资源调度与负载管理；</p><p></p><p>因此本文将重点介绍 Apache Doris 在 Lakehouse 上的设计思路和技术细节，同时会为大家介绍后续的发展规划。</p><p></p><h1>元数据连接与数据访问</h1><p></p><p>截至最新的 1.2.2 版本，Apache Doris 已经提供了十余种的数据湖格式和外部数据源的访问支持。同时也支持通过 Table Value Function 直接对文件进行分析。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1b/1b181997febeadb60abe5c1d75b219c7.png\" /></p><p></p><p>为了支持这些数据源，Apache Doris 分别在元数据连接和数据访问两方面做了大量的架构调整和性能优化 。</p><p></p><h2>元数据连接</h2><p></p><p>元数据包括数据源的库、表信息、分区信息、索引信息、文件信息等。不同数据源的元信息格式、组织方式各有不同，对于元数据的连接需要解决以下问题：</p><p></p><p>统一的元数据结构：屏蔽不同数据源的元数据差异。可扩展的元数据连接框架：低成本、快速地接入数据源。高效的元数据访问能力：提供可靠、高效的元数据访问性能，并支持实时同步元数据变更。自定义鉴权服务：能够灵活对接外部的权限管理系统，降低业务迁移成本。</p><p></p><h3>统一的元数据结构</h3><p></p><p>在过去 Apache Doris 的元数据只有 Database（数据库） 和 Table（表）两个层级，当外部数据目录 Schema 发生变化或者外部数据目录的 Database 或 Table 非常多时，需要用户手工进行一一映射，维护量非常大。因此在 Apache Doris 1.2.0 版本中新增了 Catalog（数据目录）层级，提供了快速接入外部数据源的能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/51/513630b002c9573fec02262947be702d.png\" /></p><p></p><p>Catalog 层级的引入解决以下问题：</p><p></p><p>数据源层级的映射：用户不再需要在 Database、Table 层级进行一一映射，可以通过 Catalog 直接映射整个数据源，自动同步其中的所有元信息，简化元数据映射逻辑数据源统一信息管理：在 Catalog 层级统一维护指定数据源的属性，如连接信息、权限信息、同步方式等，更方便的管理多个数据源。</p><p></p><p>引入 Catalog 层级后，我们也对 Doris 的元数据进行调整和划分：</p><p></p><p>Internal Catalog：原有的自管理的 Table 和 Database 都归属于 Internal Catalog。External Catalog：用于对接其他非自管理的外部数据源。比如 HMS External Catalog 可以连接到一个 Hive Metastore 管理的集群、Iceberg External Cataog 可以连接到 Iceberg 集群等。</p><p></p><p>用户可以使用 SWITCH语句切换不同的 Catalog，也可以通过全限定名方便的进行跨数据源的联邦查询，如：</p><p></p><p><code lang=\"text\">SELECT * FROM hive.db1.tbl1 a JOIN iceberg.db2.tbl2 b\nON a.k1 = b.k1;\n</code></p><p></p><p>相关文档：https://doris.apache.org/zh-CN/docs/dev/lakehouse/multi-catalog</p><p></p><h3>可扩展的元数据连接框架</h3><p></p><p>基于新的元数据层级，用户可以通过 CREATE CATALOG语句方便的添加新的数据源：</p><p></p><p><code lang=\"text\">CREATE CATALOG hive PROPERTIES (\n    'type'='hms',\n    'hive.metastore.uris' = 'thrift://172.21.0.1:7004',\n);\n</code></p><p></p><p>在数据湖场景下，目前 Doris 支持的元数据服务包括：</p><p></p><p>Hive Metastore 兼容的元数据服务Aliyun Data Lake FormationAWS Glue</p><p></p><p>同时，开发者也可以自行扩展 External Catalog，只需要实现对应的访问接口，即可在 Doris 中快速接入新的元数据服务。</p><p></p><h3>高效的元数据访问</h3><p></p><p>元数据存储在外部数据源中，而对外部数据源的访问受到网络、<a href=\"https://archsummit.infoq.cn/202303/beijing/track/1448\">数据源资</a>\"源等限制，性能和可靠性是不可控的。所以 Doris 需要提供高效、可靠的元数据服务以保证线上服务的稳定运行，同时 Doris 也需要实时感知元数据的变更，提升数据访问的实时性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/70/708eaf383c299d6f9e2649e6d1303bb7.png\" /></p><p></p><p>Doris 通过内存中的元数据缓存提供高效的元数据服务。元数据缓存包括列信息缓存，分区缓存，文件缓存。 通过元信息缓存，可以显著提升元数据访问性能并降低对外部元数据服务的请求压力，使得Doris 可以应对数千张表，数十万分区场景下，毫秒级别的元数据查询响应。</p><p></p><p>Doris 支持在 Catalog/Database/Table 级别，对元数据缓存进行手动刷新。同时，针对 Hive Metastore，Doris还支持通过监听 Hive Metastore Event 自动同步元数据，提供元数据秒级实时更新能力。</p><p></p><h3>自定义鉴权服务</h3><p></p><p>外部数据源通常拥有自己的权限管理服务，而很多企业也会使用统一的权限管理系统（例如 Apache Ranger）来管理多套数据系统。Doris支持通过自定义鉴权插件对接企业内部已有的权限管理系统，从而可以低成本的接入现有业务，完成授权、审计、<a href=\"https://www.infoq.cn/article/EAMArVeEdjp3ZtjVjgC8\">数据加密</a>\"等操作。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ef/ef001433107b277cfa6938dcd65ef2ea.png\" /></p><p></p><p>具体实现上，用户可以基于 Doris 的 AccessController 接口实现插件对接相应的权限管理系统，并在创建 Catalog 时，指定对应的鉴权插件。通过这种机制，所有通过 Doris 对外部<a href=\"https://archsummit.infoq.cn/202303/beijing/track/1477\">数据</a>\"源的访问，都将统一使用自定义的插件完成鉴权、审计等操作。</p><p></p><h2>数据访问</h2><p></p><p>外部数据源的数据访问，主要集中在对存储系统的访问支持上。在数据湖场景下，主要是对 HDFS 以及各种 S3 兼容的对象存储的支持。目前 Apache Doris 支持的存储系统如下，并且仍在不断增加中：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8a/8aef34ea47b4e37490eaf442d0947773.png\" /></p><p></p><h1>性能优化</h1><p></p><p>在实现数据源的连接和访问后，下一个问题是我们如何结合 Apache Doris 自身优异的查询性能以及各类存储系统的特性，进行针对性的查询性能优化，这也是在 构建 Lakehouse 过程中最需要解决的问题和权衡的因素。在具体实现过程中，Apache Doris 分别在数据读取、执行引擎、优化器方面进行了诸多优化。</p><p></p><h2>数据读取</h2><p></p><p>湖上数据通常存储在远端存储系统上，相较于本地存储，在数据的访问延迟、并发能力、IO 带宽上天然存在一定劣势。因此，在数据读取上，Apache Doris 从减少远端读取频率，降低读取量等方面出发进行了细致的优化。</p><p></p><h3>Native File Format Reader</h3><p></p><p>Parquet 和 ORC 是最常见的开放数据格式，这些数据格式本身提供了包括索引、编码、统计信息在内的多种特性，如何针对格式特性来提升文件读取效率是性能优化的关键一步。在早期的实现中，Apache Doris 是通过 Apache Arrow 来读取 Parquet/ORC 数据文件的，但这种方式存在以下问题：</p><p></p><p>数据格式转换的开销：Arrow Reader 需要先将文件读取成 Arrow 的内存格式，再转换到 Doris 自己的内存格式，两次数据转换带来额外的开销。无法支持高级文件格式特性。如不支持 Parquet 的 Page Index，不支持 Bloom Fitler，无法实现谓词下推、延迟物化等功能。</p><p></p><p>基于以上问题，我们对 Flile reader 进行了重构，实现了全新的 Native File Format Reader。这里我们以 Parquet Reader 为例，介绍 Doris 的文件格式读取方面所做的优化：</p><p></p><p>减少格式转换。新的 File Reader 直接将文件格式转换成<a href=\"https://www.infoq.cn/article/ve1ZIGW6fCjw4LMhjeOf\"> Doris </a>\"的内存格式，并可以直接利用字典编码等功能转换到对应的更高性能的内存格式，以提升数据转换和处理的效率。细粒度的智能索引。支持了 Parquet 的 Page Index，可以利用 Page 级别的智能索引对 Page 进行过滤。相比之前只能在 Row Group 级别过滤，Page Index 过滤粒度更细、过滤效果更好。谓词下推和延迟物化。延迟物化的基本逻辑是先读取有过滤条件的列，再使用过滤后的行号读取其他列。这种方式能显著降低文件的读取量。这一点在远程文件读取场景下尤为重要，可以最大限度减少不必要的数据读取。数据预读。 将多次文件读取合并成一次，充分利用远端存储高吞吐、低并发的特性，提高数据的总体吞吐效率。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fb/fbf4168dd1db96029948d88a0df8633a.png\" /></p><p></p><h3>File Cache</h3><p></p><p>利用本地高性能磁盘对远端存储系统中的文件进行本地缓存，能最大限度的减少远程数据读取的开销，同时可以提供接近 Doris 内部表数据的访问性能。在本地文件缓存方面 Doris 进行了如下优化：</p><p></p><p>文件块缓存（Block Cache） 。支持对远端文件进行 Block 级别的缓存。Block 的大小会根据读取请求自动调整，从 4KB 到 4MB 不等。Block 级别的缓存能有效减少缓存导致的读写放大问题，优化缓存冷启动场景下的数据读取延迟。缓存一致性哈希。通过一致性哈希算法对缓存位置和数据扫描任务进行管理和调度，充分利用已缓存的数据提供服务，并避免节点上下线导致缓存大面积失效的问题，提升缓存命中率和查询服务的稳定性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/960d6dc8a961774b760151ef18d08f15.png\" /></p><p></p><p>通过 Flie Cache，在命中缓存的情况下，Apache Doris 可以提供和本地表一致的查询性能。</p><p></p><h2>执行引擎</h2><p></p><p>在执行引擎层面，我们希望能够完全复用 Apache Doris 的向量化执行引擎以及各类执行层面的算子优化，为数据湖提供极速的查询体验。因此，Apache Doris 对数据扫描（Scan）节点进行了重构，使得每一种新的数据源的接入，开发者只需要关注数据源本身的访问逻辑，无需重复地开发通用功能。</p><p></p><p>通用查询能力的分层</p><p></p><p>包括内表在内的所有数据查询，都会使用相同的 Join、Sort、Agg 等算子。唯一不同在于数据源的访问方式上，例如对本地内部格式数据的读取，或存储在 S3 上的 Parquet 格式数据的读取。因此 Doris 将不同数据源的查询逻辑差异下推到最底层的 Scan 节点上。Scan 节点之上，所有查询逻辑统一，Scan 节点之下，由具体的实现类负责不同数据源的访问逻辑。</p><p></p><p>Scan 算子的通用框架</p><p></p><p>对于 Scan 节点，不同数据源也有很多共性的方面，如子任务的拆分逻辑、子任务的调度、IO 的调度、谓词下推以及 Runtime Filter 的处理等。因此我们也对这一部分架构进行了重构。首先，将共性部分都以接口的形式对外暴露，如子任务的拆分、下推谓词的处理等；其次，对子任务实现了统一的调度管理逻辑，可以由统一的调度器管理整个节点 Scan 任务的执行。调度器拥有节点全局的信息，可以方便的实现更细粒度的Scan 任务调度策略。在这样的统一的数据查询框架下，大约 1 人周就可以完成一种新数据源接入。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bc/bcb5c1fd08aab34a371bbe38c70f45ea.png\" /></p><p></p><h2>查询优化器</h2><p></p><p>查询优化器层面的优化集中在统计信息收集和代价模型的推导方面。</p><p></p><p>Apache Doris 支持对不同数据源的统计信息收集，如 Hive Metastore、Iceberg Metafile、Hudi MetaTable 中存储的统计信息等。同时在代价模型推导方面，我们也针对外部数据源的特性做了细致的调整。基于这些优化，Doris 可以为复杂的外表查询提供更优的查询规划。</p><p></p><h2>性能对比</h2><p></p><p>以上优先项，我们分别在宽表场景（Clickbench）和多表关联场景（TPC-H）下与 Presto/Trino 进行了 Hive 数据集的查询性能对比。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d3/d3bc4fde9398fca8225c418c9b5ba93a.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/40/40cde829687e8f5f8854da6f5f03a0c3.png\" /></p><p></p><p>可以看到，在相同计算资源和数据集下，无论是宽表场景或多表关联场景，绝大多数 SQL Apache Doris 的查询耗时都是大幅低于 Presto/Trino ，整体性能 相比 Presto/ Trino 有 3-10 倍的提升。</p><p></p><h1>负载管理与弹性计算</h1><p></p><p>对外部数据源的查询并不依赖 Doris 的数据存储能力，这也为 Doris 实现弹性的无状态计算节点成为可能。在即将发布的 2.0 版本中，Apache Doris 还实现了弹性计算节点功能（Elastic Compute Node），可以专门用于支持外部数据源的查询负载。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bf/bfea84a78c712f1aff996922b271a559.png\" /></p><p></p><p>由于计算节点是无状态的，因此我们可以对这类节点进行快速扩缩容，以灵活地应对峰谷期的查询负载，在查询性能与成本消耗之间取得更好的平衡。</p><p></p><p>同时，Doris 也针对 k8s 场景下的集群管理和节点调度进行了优化，Master 节点可以自动管理弹性计算节点的上下线，方便业务在云原生场景、混合云场景下都能便捷的管理集群负载。</p><p></p><h1>案例实践</h1><p></p><p>随着以上功能的完善与性能的提升，Apache Doris 已经被多家社区用户应用于数据湖分析，在真实业务中发挥着重要的作用，在此以某金融企业的风控场景为例。</p><p></p><p>金融风控场景往往对数据的实时性有着更高的要求，早期基于 Greenplum 和 CDH 搭建的风控数据集市已经无法满足其高时效性的需求，T+1 的数据生产模式成为业务迅速发展的掣肘，因此该企业于 2022 年引入 Apache Doris 并改造了整个数据生产和应用流程，实现对 Elasticsearch、Greenplum 以及 Hive 的联邦分析，整体效果包括：</p><p></p><p>只需创建一个 Hive Catalog 即可对现存的数万张 Hive 表进行查询分析，查询性能得到极大幅度提升；利用 Elasticsearch Catalog 实现对 ES 实时数据的联邦分析，数据时效性从过去的分钟级提升至秒级甚至毫秒级，满足了风控策略的实时性要求；将日常跑批与统计分析进行解耦，降低资源消耗的同时使系统稳定性得到进一步增强。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6b/6b78110aa36b17525cdeb863e95552f5.png\" /></p><p></p><h1>未来规划</h1><p></p><p>后续 Apache Doris 将持续在 Lakehouse 方向进行迭代和升级，下一步的工作将围绕在更丰富的数据源支持、数据集成和资源隔离与调度等方面：</p><p></p><h2>更丰富的数据源支持</h2><p></p><p>随着数据湖在各种业务场景中的不断落地，数据湖本身的功能也在不断迭代以满足越来越多样的业务需求。Doris也将和各个开源社区紧密合作，提供更完善的数据湖分析支持。</p><p></p><p>Hudi Merge-On-Read 表的 Incremental Query 支持利用 Iceberg/Hudi 丰富的索引功能，结合查询优化器提供更低延迟的分析性能。支持包括 Delta Lake、Flink Table Store 等更多数据湖格式。</p><p></p><h2>数据集成</h2><p></p><p>具体到功能层面，数据集成可以分为数据的读取和写回两部分。</p><p></p><p>数据读取方面，Doris 将进一步整合数据湖的数据访问特性，包括：</p><p></p><p>数据湖 CDC 的接入以及增量物化视图的支持，为用户提供近实时的数据视图。支持 Git-Like 的数据访问模式，通过多版本、Branch 等机制，在数据安全、数据质量等方面为用户提供更便捷的数据管理模式。</p><p></p><p>数据写回功能的支持，帮助 Doris 进一步完善统一数据分析网关的生态闭环。用户可以使用 Doris 作为统一数据管理入口，管理各个数据源中的数据，包括加工后数据的写回、数据导出等，对业务提供统一的数据视图。</p><p></p><h2>资源隔离与调度</h2><p></p><p>随着越来越多数据源的接入，Doris 也在逐步承接不同的工作负载，比如在提供低延迟的在线服务的同时，对 Hive 中 T-1 的数据进行批量处理。所以同集群内的资源隔离会愈发重要。</p><p></p><p>Doris 会持续优化弹性计算节点在不同场景下的调度管理逻辑，同时会支持更细粒度的节点内资源隔离，如 CPU、IO、内存等，帮助 Doris 支持多样且稳定的工作负载。</p>",
    "publish_time": "2023-03-10 14:50:58",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "集成ChatGPT后必应日活量首破亿！微软推出Azure OpenAI ChatGPT 服务，GPT-4下周发布",
    "url": "https://www.infoq.cn/article/5u0r3ANaikQ5u3k4D736",
    "summary": "<p></p><p>微软表示，客户可以立即开始使用 ChatGPT，定价为 0.002 美元 /1000 tokens。这与 3 月 1 日推出的ChatGPT API的价格相同。</p><p></p><h2>ChatGPT 现已登陆&nbsp;Azure OpenAI Service</h2><p></p><p></p><h3>Azure OpenAI Service 提供 ChatGPT 预览版</h3><p></p><p></p><p>3 月 9 日，微软宣布 ChatGPT 已经开始在 Azure OpenAI Service 中提供预览版。</p><p></p><p>微软表示，借助 Azure OpenAI Service，已有过千家客户开始应用各类先进 AI 模型——包括 Dall-E 2、GPT-3.5、Codex 以及其他由 Azure 超级计算与企业功能所支持的大语言模型。</p><p></p><p>自去年底 ChatGPT 亮相以来，其已经在各类场景下都有了出色的应用，包括内容总结、草拟电子邮件副本，帮助用户解决软件编程问题等。</p><p></p><p>现在，借助 Azure OpenAI Service 中的 ChatGPT 预览版，开发人员能够将定制化 AI 体验直接集成至自己的应用程序当中，包括增强现有机器人以处理意外问题、复述客服中心对话以加快客户支持速度、建立具有个性化的新广告文案、自动处理索赔流程等。各类认知服务将能够与 Azure OpenAI 相结合，为企业打造新型用例。</p><p></p><p>微软表示，客户可以立即开始使用 ChatGPT，定价为 0.002 美元 /1000 tokens。这与 3 月 1 日推出的ChatGPT API的价格相同。微软表示，所有 ChatGPT 服务将于 3 月 13 日开始计费。</p><p></p><p></p><h2>商业价值</h2><p></p><p></p><p>微软表示，其在各行各业的客户已经感受到了使用 Azure OpenAI Service 所带来的商业价值。</p><p>例如，ODP Corporation、新加坡智能国家和数字政府办公室以及 Icertis 等组织，都将继续应用 Azure OpenAI 和 ChatGPT 模型在业务中应用。</p><p></p><p></p><blockquote>“Azure OpenAI Service 提供的 ChatGPT AI 技术将帮助我们推动业务的持续转型，更有效地探索新的可能性，同时设计更多创新解决方案我们正在构建一款由 ChatGPT 驱动的聊天机器人，用以支持我们的内部业务部门，特别是人力资源部门。该聊天机器人已经成功改进了 HR 文档审查流程、可生成新的职位描述，并加强了员工之间的沟通。借助 ChatGPT 的自然语言处理和机器学习功能，我们简化了内部运营并推动业务成功。这项技术的应用，也将提高我们在市场上的竞争优势并增强客户体验。”—— Carl Brisco，ODP Corporation 产品与技术副总裁</blockquote><p></p><p></p><p>除了利用 Azure OpenAI Service 实现商业价值之外，微软内部也在开展工作，将来自 OpenAI 大语言模型的强大功能与 Azure 的 AI 优化型基础设施相结合，帮助向其消费者和企业产品引入新体验：</p><p></p><p>例如：</p><p></p><p>• &nbsp; &nbsp;GitHub Copilot 利用 Azure OpenAI Service 中的 AI 模型，帮助开发者与 AI 结合工作以加速代码编写。</p><p>• &nbsp; &nbsp;Microsoft Teams Premium 包含智能回顾和 AI 生成的章节，可帮助个人、团队和组织提高工作效率。</p><p>• &nbsp; &nbsp;Microsoft Viva Sales 的全新 AI 支持型卖家体验，能够根据电子邮件内容和数据驱动见解提供建议，帮助销售团队专注于有针对性的战略销售活动。</p><p>• &nbsp; &nbsp;Microsoft Bing 引入了 AI 聊天选项，以全新方式增强消费者的搜索体验。</p><p></p><p>用户还可以使用 Azure OpenAI Studio 中的无代码方法创建新的智能应用和解决方案。Azure OpenAI Studio 除了开放对服务内各个模型的定制选项外，还提供独特的 ChatGPT 自定义界面，确保其配置和组织保持统一。</p><p></p><h2>负责任的 AI 实现方法</h2><p></p><p></p><p>微软还致力于确保 AI 系统以负责任的方式开发实现，使其能够按预期工作，并为人们提供值得信赖的使用体验。</p><p></p><p>以 ChatGPT 或 Dall-E 图像生成模型为例，它们虽然能够生成新的工件，但这种能力也给模型带来新的挑战。例如，它们可能会生成看似有理、但却充满谬误的文本，或者创建出令人真假难辨的虚构图像。</p><p></p><p>为此，微软立足四个层级建立起了缓解措施，希望依据微软的负责任 AI 标准来应对这些挑战。</p><p></p><p>首先，是由客户负责的应用程序级保护，例如 AI 只负责文本输出，用户负责内容的解释和批准；</p><p></p><p>第二是引入输入输出内容过滤等技术保护手段；</p><p></p><p>第三是流程和政策保护，涵盖系统、滥用报告乃至服务水平协议；</p><p></p><p>第四是公布设计指南与透明度说明等文档，解释模型的好处和我们已经测试过哪些内容。</p><p></p><p></p><h2>Bing 每日活跃用户已突破 1 亿</h2><p></p><p></p><p>在推出带有聊天机器人 AI 的新 Bing 一个月后，微软发布了最新进展。</p><p></p><p>据微软负责现代生活、搜索和设备的副总裁 Yusuf Mehdi 称，必应聊天机器人 AI 推出一个月后，每日 活跃用户已突破 1 亿。</p><p></p><p>他提到，微软非常清楚自己在搜索市场上只是“一家渺小卑微的低份额厂商”。对，但也别忘了 Bing 的巨大影响力。在 Bing 新版本发布之后，微软吸引到了众多之前从不用他家搜索服务的新受众。Medhi 发现，如今多达三分之一的 Bing 使用者为新用户。</p><p></p><p>“我们认为新 Bing 的这种吸引力证实了我们的观点，即搜索需要重新发明，以及将‘搜索 + 答案 + 聊天 + 创造’结合在一种体验中的独特价值主张，” Yusuf Mehdi 说。</p><p></p><p>除了数量增加之外，微软显然也享受着参与度的增长，更多的人正在进行更多的搜索。</p><p></p><p>微软将此次胜利归功于两个因素，首先是 Edge 使用率的增长，这很可能得益于 Bing 的聊天 AI 作为一项新功能的加入。微软还表示，其 Prometheus AI 模型的推出使 Bing 的搜索结果更具相关性，因此人们一直在更多地使用，或至少尝试搜索引擎。</p><p></p><p>显然，Bing 每日预览用户中约有三分之一每天都在使用其聊天 AI 进行查询。平均而言，微软在每次会话中看到三个聊天。自推出新的 Bing 以来，聊天次数超过 4500 万次。此外，在 15% 的聊天会话中，人们一直在使用 Bing 来生成新内容。Bing 的 AI 聊天机器人在手机上的 推出也将搜索引擎的受欢迎程度推向了一个新的高度，并使得每日活跃用户比推出之前增加了六倍。</p><p></p><p></p><h1>GPT-4将于下周发布</h1><p></p><p></p><p>还有一个令人振奋的好消息。</p><p></p><p>下周，GPT-4就要来了。</p><p></p><p>3 月 9 日，微软德国 CTO Andreas Braun 在一场名为 “AI in Focus - Digital Kickoff” 的活动中表示，GPT-4 将在下周发布，将提供多模态模型。</p><p></p><p>&nbsp;Andreas Braun表示，我们将在下周推出 GPT-4，我们将有多模态模型，提供完全不同的可能性。Andreas Braun认为，大型语言模型是 “游戏规则的改变者”，因为它们教机器理解自然语言，然后以统计学方式理解以前只能由人类阅读和理解的内容。同时，该技术已经发展到了基本上 “适用于所有语言” 的程度。“你可以用德语问一个问题，得到意大利语的回答。通过多模态，微软/OpenAI 将 “使模型变得全面”。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2f/2f0a537dedc63e4985ea20739500a555.jpeg\" /></p><p></p><p>参考链接：</p><p></p><p>https://azure.microsoft.com/en-us/blog/chatgpt-is-now-available-in-azure-openai-service/?cdn=disable</p><p>https://www.engadget.com/microsoft-bing-crossed-100-million-daily-active-users-080138371.html</p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MzU2OTY2OTQ0MA==&amp;mid=2247522146&amp;idx=1&amp;sn=07c9c67d31b6d5865387fe2d0bdef928&amp;scene=21#wechat_redirect\">https://mp.weixin.qq.com/s/oOgYn2ZtLwgiOAa3-BZMzQ</a>\"</p>",
    "publish_time": "2023-03-10 15:00:44",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Google开源Service Weaver，让你无需纠结到底选择单体还是微服务",
    "url": "https://www.infoq.cn/article/GeVe9RdwiVQkPWJlicui",
    "summary": "<p>事情总是这样，在单体和微服务哪个更好之间来回摇摆。</p><p></p><p>不同的人会给出不同的答案，因为他们的经历不同。但在大多数情况下，那往往取决于许多因素，比如公司规模，需要为之服务的流量，以及所提供的产品。</p><p></p><p>实际上，这两种方法都各有利弊。但是，如果可以两全其美呢？这就是谷歌开源这个新框架的目标，让我们来仔细了解一下！</p><p>&nbsp;</p><p></p><h1>Service Weaver是什么？</h1><p></p><p>&nbsp;</p><p><a href=\"https://opensource.googleblog.com/2023/03/introducing-service-weaver-framework-for-writing-distributed-applications.html\">Service Weaver</a>\"是谷歌开发的一个框架，目前处于早期开发阶段。这个框架是开源的，也就是说任何人都可以使用和贡献。目前，该框架只能用于 Go 开发，不过如果成功的话，就可以将这种方法复制到其他任何语言中。</p><p></p><p>这是一个构建分布式应用程序的框架，它的特点是：在本地作为一个模块化单体运行，但一旦部署，就会作为一个分布式微服务架构运行。</p><p>&nbsp;</p><p></p><h2>什么是模块化单体？</h2><p></p><p>&nbsp;</p><p>模块化单体是一种架构，整个架构被编写成单个应用程序，存储在单个代码库中。模块化的意思是，单体被分割成独立的组件，不同组件之间有清晰的接口。</p><p>&nbsp;</p><p>下面是一个例子：</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/38/385c75406db40d9ac5f09a2653480f99.png\" /></p><p></p><p>这是一个用Mermaid创建的模块化单体的例子。要学习更多关于Mermaid的知识，可以读下我写的这本书&nbsp;<a href=\"https://www.amazon.com/dp/1680509837?maas=maas_adg_265A9C302E256D26C2E10C30DA1AA728_afap_abs&amp;ref_=aa_maas&amp;tag=maas\">Creating Software with Modern Diagramming Techniques</a>\"。</p><p>&nbsp;</p><p>这个单体包括三个组件：订单、付款和配送。每个组件都实现了单体的一个特定部分。重要的是，每个组件的大部分都是私有的，组件之间的任何通信都是通过明确定义的接口进行的。</p><p></p><p>这样，组件内部的更改和更新不会影响任何其他组件，只要没有更改或破坏接口就行。</p><p></p><p>当多个团队共同开发一个单体时，这非常有助于设置清晰的团队边界，使每个组件的开发都独立于任何其他组件，而且组件之间的依赖关系很清晰。</p><p></p><p>单体在部署时是作为单个应用程序部署的，单体的每个实例会有单独的进程。例如，如果是部署到 AWS，那么单体的每个实例都将作为 EC2 实例上的一个进程运行。</p><p>&nbsp;</p><p></p><h2>Service Weaver与传统的模块化单体有何不同？</h2><p></p><p>&nbsp;</p><p>我们已经了解了什么是模块化单体。现在，我们来看一看，为什么 Service Weaver 不是一个构建标准模块化单体的框架。</p><p></p><p>在开发应用程序时，实际看起来与上面的示例没什么不同。使用 Service Weaver 构建应用程序时，也是在单个存储库中构建组件。如上所述，每个组件都定义了清晰的接口，用于支持不同组件之间的通信。</p><p></p><p>Service Weaver 与传统模块化单体的区别在于部署。在部署使用 Service Weaver 构建的应用程序时，不会部署成一个包含所有组件的大进程，在同一台机器上运行。</p><p></p><p>相反，每个组件都是作为微服务单独部署。这相当聪明，因为你可以将所有代码放在一个存储库中，轻松地在本地进行开发，同时还能获得运行分布式架构的好处——根据需要扩展每个组件，例如内存、CPU 和实例数量。</p><p></p><p>很漂亮，对吧？让我们看看 Service Weaver 是如何做到这一点的！</p><p>&nbsp;</p><p></p><h1>Service Weaver是如何工作的？</h1><p></p><p>&nbsp;</p><p>正如文章开头所提到的，Service Weaver 完全是用 Go 编写的，至少目前是这样。在构建应用程序时，必须将每个组件定义为一个接口。你可以将此看成是为给定组件定义公共 API，列出其他组件可以使用的方法。例如，反转字符串的组件可能是下面这样的：</p><p>&nbsp;</p><p><code lang=\"null\">type Reverser interface {\n    Reverse(context.Context, string) (string, error)\n}</code></p><p>&nbsp;</p><p>其他任何想要反转字符串的组件都可以调用这个反转组件，反转字符串的内部逻辑包含在反转组件中，是私有的。</p><p></p><p>然后像往常一样，你可以通过组件之间的方法调用来扩展组件。你完全可以在本地构建和测试它，而 Service Weaver 将处理组件之间的交互，将它们视为本地方法调用。</p><p></p><p>到目前为止，其他任何框架或单体都没有什么变化。</p><p></p><p>然而，一旦部署并作为独立的微服务运行，组件之间的调用就不能在本地进行了。相反，Service Weaver将在组件之间进行远程过程调用（<a href=\"https://en.wikipedia.org/wiki/Remote_procedure_call\">RPC</a>\"）。</p><p>&nbsp;</p><p>简单来说，它使用<a href=\"https://protobuf.dev/\">协议缓冲区</a>\"来序列化和反序列化组件之间传递的数据。你无需为此操心，因为所有这些都是在后台发生的。你不考虑微服务之间的网络调用，也不用管调用是在本地进行还是远程进行。</p><p>&nbsp;</p><p>代码方面，你可以按照自己习惯的方式编写代码，至于是本地调用还是远程调用由框架来处理。在上面的Reverser示例中，你的代码将只需调用Reverse，而不需要关心调用是在本地进行还是在远程进行。</p><p>&nbsp;</p><p></p><h2>使用Service Weaver组合微服务</h2><p></p><p>&nbsp;</p><p>为了增进理解，请看下图谷歌对不同部分如何组合在一起的说明：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/014281c51d84db40fc90c546187ad0f9.png\" /></p><p></p><p>&nbsp;Service Weaver 编程库从开发到执行的流程图</p><p>&nbsp;</p><p>下面我们看下 Service Weaver 的多面性。传统的微服务有一个缺点，就是经常会导致界面非常繁琐。毕竟，没有人能预见未来，也没有人能预见随着时间的推移架构会如何变化。</p><p></p><p>然后，你要么就忍受不断增加的延迟和不断提升的网络调用失败率，要么就花时间将这两个微服务融合起来。</p><p>&nbsp;</p><p>而 Service Weaver 解决了这个问题。上图中定义的 4 个模块，当部署为微服务时，你会注意到，A 和 B 是在一起的，C 和 D 则是单独的微服务。</p><p></p><p>使用 Service Weaver，你可以自由地定义将哪些组件部署在何处。你可以选择在单个微服务中同时运行多个组件，也可以将所有组件部署为单独的微服务。如果随着应用程序的演进，两个作为独立微服务运行的组件交互变得非常频繁，那么你可以很容易地将它们组合在一起，而不需要更改代码，只需要在 Service Weaver 中快速更改配置即可。</p><p>&nbsp;</p><p></p><h1>云部署选项</h1><p></p><p>&nbsp;</p><p>你可能想知道，Service Weaver 应用程序要部署到哪里。由于它是谷歌开发的，所以你可能会想，谷歌云是唯一的部署选项，而且无疑，它与 GCP 集成得很好。</p><p></p><p>不过，它任何云都支持，比如 AWS 或 Azure。它使用 TOML 文件来定义配置，我一直认为那很容易使用。下面是谷歌的另一副图，说明 Service Weaver 在不同环境下的工作情况：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/da/da3d31842fb838974ed598b675a28d0b.png\" /></p><p>Service Weaver Libraries 部署程序实施的流程图</p><p>&nbsp;</p><p>上图展示了如何构建应用程序及其组件，然后是一系列如何运行该应用程序的选项。你可以用 go run. 在本地运行它，或使用 weaver gke deploy 部署到云中。</p><p></p><p>目前似乎是 Kubernetes 部署，未来是否提供其他部署方案还有待观察。我认为，在底层，组件之间的通信大量使用了 Kubernetes。</p><p>&nbsp;</p><p></p><h1>如何使用Service Weaver</h1><p></p><p>&nbsp;</p><p>以上就是对 Service Weaver 的初步介绍，如果你想尝试一下，可以访问 Service Weaver 官方网站。</p><p></p><p>该网站提供了所需的所有内容，包括框架的架构、安装手册，当然还有入门用的“hello world“示例。</p><p></p><p>在我看来，这种方法很吸引人，解决了许多我们在单体和微服务之间做选择时需要考虑的问题。它是否能做到这一点还有待观察，但我很期待 Service Weaver 的发展！</p><p></p><h5>原文链接：</h5><p></p><p><a href=\"https://betterprogramming.pub/service-weaver-a-framework-from-google-for-balancing-monoliths-and-microservices-583e69b274dd\">https://betterprogramming.pub/service-weaver-a-framework-from-google-for-balancing-monoliths-and-microservices-583e69b274dd</a>\"</p><p></p><h5>相关阅读：</h5><p></p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MzUzMTA2NTU2Ng==&amp;mid=2247557757&amp;idx=1&amp;sn=2694b825a027e7f0688c5d45ad03011b&amp;chksm=fa4b9dcccd3c14da7b9fc3682a49e491d57a9998b54b600ceea14c06152836ca3ce2b12124d9&amp;scene=27#wechat_redirect\">别再造轮子了，Google 开源的 Guava 工具库真心强大！</a>\"</p><p><a href=\"https://xie.infoq.cn/article/b1df213b3a6dfaacd94b73cd9\">Flutter - Google 开源的移动 UI 框架</a>\"</p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MjM5NDkxMTgyNw==&amp;mid=2653073361&amp;idx=1&amp;sn=85a4b9a65f621d07b5da52571089b78e&amp;chksm=bd568ced8a2105fb3ead0f5b745d6c440d90fa307e80c6d0f03cf72f10d2ee516eafacc33022&amp;scene=27#wechat_redirect\">Google 强势开源 Carbon 语言，号称要替代 C++</a>\"</p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247501594&amp;idx=3&amp;sn=2608b59c88847cba7737a94759dccbc2&amp;chksm=fbea7ed5cc9df7c3947561606c84542d368f2fd13c7a82f5a6424a8313db606b54a9e2143c5c&amp;scene=27#wechat_redirect\">谷歌开源框架 FUSS，让声音分离不再成为难题</a>\"</p>",
    "publish_time": "2023-03-10 15:18:33",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "全世界都在跟风ChatGPT，它的真正价值到底是什么？｜直播预约",
    "url": "https://www.infoq.cn/article/pkzVJ26fmHcY8evAGEvo",
    "summary": "<p></p><p><img src=\"https://static001.geekbang.org/infoq/57/57865d719f681f8384cd4540147a245f.jpeg\" /></p><p></p><p>ChatGPT“军备竞赛”已渐入高潮，尤其是大型科技公司间的 AI 竞赛日趋白热化。ChatGPT 爆火也让大模型卷了起来，已有多位 AI 大牛宣布杀入大模型领域创业。</p><p></p><p>上个月，InfoQ 发起了极客有约特别栏目之《极客圆桌派：狂飙的 ChatGPT 》，一起探讨了 ChatGPT 到底“是什么”和“为什么”的问题；</p><p></p><p>3 月 10 日，InfoQ 联合微软发起了《极客圆桌派：ChatGPT 点燃 AI 狂潮》直播，邀请了 4 位技术大咖再聊 ChatGPT。这一次，我们更聚焦 ChatGPT 的真正的最大价值。</p><p></p><p>我们试图回答这样一些问题：ChatGPT 到底能为企业和开发者带来什么？企业如何借力和追赶 LLM/ChatGPT 创造出实际的价值？ChatGPT 所卷起的 AI 大模型热潮将如何影响开发者和企业？ChatGPT 背后的伦理挑战和风险问题又该如何应对？</p><p></p><p></p><h4>主题介绍：</h4><p></p><p></p><p></p><h4>直播主题：</h4><p></p><p></p><p>《极客圆桌派：ChatGPT 点燃 AI 狂潮》</p><p></p><p></p><h4>直播时间：</h4><p></p><p></p><p>2023 年 3 月 10 日 20:15-22:15</p><p></p><h4>直播核心议题：</h4><p></p><p></p><p>ChatGPT 真正的最大价值是什么？企业和 LLM/ChatGPT 的关系哪些企业需要自己的 LLM，垂直行业如何应对？小语种如何应对 LLM 的冲击如何评判一个大模型？链接大模型与领域模型的方法为什么全世界都在“跟风”ChatGPT？风暴过去，什么会留下来？ChatGPT 在中国会出现吗？如果没有出现会怎样？从 ChatGPT 看负责任的生成式&nbsp;AI终局预测：会有几个大模型一统江湖？</p><p></p><p></p><h4>嘉宾介绍</h4><p></p><p></p><p>主持 &amp; 嘉宾</p><p></p><p>Mingke，MRS.ai 联合创始人兼 CEO 。组建面向未来的智能网络，《人工智障》系列作者。</p><p></p><p>圆桌嘉宾：</p><p></p><p>李争，微软 (中国) 有限公司技术顾问。专注于微软公有云平台 Azure 的解决方案和架构设计、Azure 应用的实施，以及 Azure 上的开源技术等工作。曾在微软企业服务区作为原厂技术支持工程师工作多年，承担企业开发者代码调试和技术支持、Web 应用前端后图案代码跳优，一级级 IIS 的问题诊断、跳优、培训等工作。具有丰富的企业客户临场解决严重系统问题的经验。拥有四十多门微软认证证书，涵盖了几乎全部微软开发相关技术，同时也是一位具有十多年丰富授课经验的微软认证讲师 (MCT)。</p><p></p><p>郝杰，明略科技集团首席技术官（CTO）。毕业于清华大学，曾先后担任东芝（中国）首席科学家、五八集团技术专家和 OPPO 语音语义首席科学家，主导研发成功了国内早期量产的个人语音助理、汽车前装语音导航，世界上早期量产的电视机语音唤醒、离线口语翻译手机软件等，曾带领团队多次获得 WMT、IWSLT、CCMT、Blizzard Challenge、SemEval、VoxSRC、AISHELL 等 AI 领域的比赛和 leaderboard 的第一名。</p><p></p><p>张大卫，竞智科技 GamesMind 创始人 &amp;CEO。毕业于北京大学，曾任微软亚洲研究院研究员，研究领域包括自然语言处理、知识图谱、推荐系统等，曾负责微软概念知识图谱和微软下一代广告系统。</p><p>如何看直播？</p><p></p><p>扫描下图海报【二维码】，预约 InfoQ 视频号，直播开始有提醒。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6c/6c3c490e615df6cac7188a9dc2bf64c1.png\" /></p><p></p><p></p><h2>如何向讲师提问？</h2><p></p><p></p><p>点击：https://www.infoq.cn/form/?id=907 填写提问表单，讲师会在直播中为你解答。</p><p></p><h2>更多福利</h2><p></p><p></p><p>除了分享干货，直播进行中，我们会在参与直播的同学安排幸运观众抽奖福袋，赠送定制无线充电器敬请期待哦～</p><p></p><p>欢迎大家加入 InfoQ AIGC 微信群，社群将定期分享关于 AIGC 技术领域的各种资源，包括最新的研究成果、技术趋势以及来自领域专家的专业见解。除此之外，我们还会举办线上技术交流活动，让大家可以更深入地了解这个领域的最新动态和趋势。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/32/32a40e4427564205db9a2aeb174c0433.png\" /></p><p></p><p></p><p><a href=\"\">阅读原文</a>\"</p>",
    "publish_time": "2023-03-10 15:26:29",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "“鼎新杯”案例精选 | 中国联通数字化研发低代码平台为一线赋能",
    "url": "https://www.infoq.cn/article/1e77db09f145c68809c8b9404",
    "summary": "<p></p><h4>引言</h4><p></p><p></p><blockquote>在2022年举办的首届“鼎新杯”数字化转型应用征集活动中，中国联通软件研究院在数字技术创新专题，共有7个案例分别斩获一二三等奖，并被收录到《鼎新杯数字化转型应用案例汇编》中。本文选取“中国联通数字化研发低代码平台”进行展示。该平台的使用大大加快了业务交付效率，为一线人员进行数字技术赋能，在集团、子公司、省分广泛应用，并获得了多方好评。</blockquote><p></p><p></p><p></p><h3>一、新挑战：业务集约化后如何快速响应大量个性化业务需求？</h3><p></p><p>近年来，联通集团各省分公司大力推行各类集约模式，将原先碎片化、分散于一线部门的专业岗位统一集中到省一级，而一线部门则主要承担市场销售职责。</p><p>在推行过程中，由于业务受理岗位与客户经理分属不同部门和不同层级，因此各省分公司的线上协同需求大量产生，而同时发现标准系统只能支撑集团统一的核心业务，这就导致大量省级业务、非核心业务个性化需求集中爆发。</p><p>&nbsp;</p><p>原有IT管理模式难以快速响应，出现支撑不充分、不到位、不敏捷等问题，一线需求和研发瓶颈形成尖锐矛盾。以业务受理集约为例，联通有31个省分公司，每个省有数百款产品，且各省之间的个性化产品属性、业务流程、管理模式都存在差异，如果用纯代码的开发方式来应对这类个性化产品的集中开发，那将是个极度庞大、复杂的工程。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4d/4d792b8ac266ec60d9b0cbb09631016e.png\" /></p><p></p><h3>二、低代码平台满足业务快速交付需求</h3><p></p><p>基于以上挑战和需求，中国联通软件研究院开发了中国联通数字化研发低代码平台，为企业人员提供了一个集流程、架构、运维、工具一体化的云原生低代码智能化平台。</p><p>&nbsp;</p><p>该平台可以配置业务单据、工作流、业务规则，能够可视化地与联通内部的其他核心业务系统进行低代码的集成、调度，改变生产流程和模式，以数字化的方式驱动生产要素按需组织，实现敏捷、灵活、高质量的端到端业务受理全流程支撑。</p><p>&nbsp;</p><p>低代码平台向上连接前端的行业业务，向下连接云计算的海量能力，以云开发作为底层支撑。云原生能力将应用搭建的全链路打通，提供高度开放的开发环境，提供了应用开发的一站式低代码开发服务，帮助用户专注于业务场景，快速搭建应用，助力数字化转型。</p><p>&nbsp;</p><p></p><h3>三、中国联通数字化研发低代码平台架构</h3><p></p><p>中国联通数字化研发低代码平台包含工作台和管理控制台，工作台用于创建应用、可视化设计、应用发布等，包括模型与对象设计、表单设计、页面设计、流程设计、图表设计等；管理控制台是专为平台、组织和应用管理而设计的一体化运维管理平台，包括对应用内部的权限体系控制等。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/26/26f6e34dfedc645ecfd8d323da8a84b2.jpeg\" /></p><p></p><p>模型设计：进行应用模型的创建维护。模型与实体关联，用户可自行设计表的属性、字段、索引并预览；对象设计：通过选择模型、设置关联关系，实现领域模型的代码映射，支持灵活的规则配置与控制；页面设计：通过拖拽式的方式设计页面，多页面布局选择、多控件可配、多样式可定义；流程设计：提供了对页面流转的审批控制，将流程图与表单进行关联，设置任务参与者实现不同的申请和审批；图表设计：提供对大屏可视化的设计支持，丰富的可视化组件，设置数据联动，快速生成数据的可视化，方便敏捷决策。</p><p></p><h3>四、中国联通数字化研发低代码平台特点</h3><p></p><p>低代码平台为传统企业数字化转型提供工作模式的创新，通过低代码，降低技术门槛，提升研发效能，赋能一线人员忽略代码编写过程，聚焦业务，完成场景快速实现，并通过原子化的持续集成持续部署工具对接底层云平台，加快应用的开发部署进程。</p><p>&nbsp;</p><p>打通联通内部核心系统，一线人员快速上手</p><p>能够可视化地与联通内部核心业务系统进行低代码的集成、调度，改变生产流程和模式，解决业务人员缺乏代码知识的问题，赋能一线人员快速构建应用，实现数字化互动能力从总部到省分，从组织到个人。</p><p>&nbsp;</p><p>支持低代码化的CICD（持续集成于持续部署）</p><p>提供将各个功能节点抽象为独立原子并输出创建原子的能力，可根据实际情况创建符合场景需要的原子，不再受制于流水线原子所提供功能的局限，缓解编写Pipeline脚本压力（该部分产生2篇专利）。</p><p>&nbsp;</p><p>支持低代码化的编排部署</p><p>提供对生成应用的资源管理文件编写的文件模版，在不具备编写YAML文件能力下，可通过模版配置实现对资源对象的编排部署。</p><p>&nbsp;</p><p></p><h3>五、中国联通数字化研发低代码平台应用成效</h3><p></p><p>中国联通数字化研发低代码平台以服务支撑好运营商特色IT需求为使命，在降低开发门槛的同时，聚焦业务场景，孵化出符合联通不同业务场景的低代码开发模板，实现业务的快速导入投产，帮助个性化需求不再定制开发，业务人员无代码配置即可自助上线使用，流程需求的 IT 支撑周期由原来的数月缩短到分钟级，全面赋能全集团全面数字化转型。</p><p>&nbsp;</p><p>目前，低代码已累计多次省分培训推广，在集团、子公司、省分广泛应用，多项应用支撑，尤其在联通政企业务线，其中累计加载政企业务86项，占联通政企中台支撑业务总数的44%。均运行良好，无故障产生，无投诉产生，收到多个省分子公司的一致好评、多封表扬信。</p><p>&nbsp;</p><p>以联通政企业务线的两个应用实例为例，截止2021年底，通过“销售服务业务”低代码开发模板支撑的政企业务达84款，月均出账160万+，全年估算累计收入1920万。以常规政企业务销售模块的需求、研发、测试全流程工作量平均2人月估算，预计提升2倍研发效能，估算节约研发成本250万。</p><p></p><p></p><h4>关于 “鼎新杯”数字化转型应用征集</h4><p></p><p>“鼎新杯”数字化转型应用征集活动，以落实国家“十四五”规划关于“加快数字化发展，建设数字中国”的总体要求为目的，意在打造一批具有产业引领与推广应用效应的企业数字化转型应用示范案例。</p><p>&nbsp;</p><p>首届活动于2022年3月正式启动，由中国信息通信研究院与中国通信企业协会联合主办，云计算与大数据研究所政企数字化转型部承办，2023年第二届“鼎新杯”数字化转型应用征集活动将于3月21日正式启动，敬请期待！</p><p></p><p>说明：</p><p>为进一步探讨交流数字化转型相关话题，我们建立了微信群，您可添加董老师微信号，注明身份后，申请加入。</p><p>联系人：董老师&nbsp; 13810413143（微信同号）</p><p></p><p></p><p></p>",
    "publish_time": "2023-03-10 15:35:18",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "旷视CEO印奇：AIoT产业合作的核心，是“降低门槛”和“场景创新”",
    "url": "https://www.infoq.cn/article/kRijTP3GiJUs7tYjAt5s",
    "summary": "<p>3月10日，InfoQ获悉，旷视在2023旷视企业业务合作伙伴大会上，分享了最新的技术和产品布局，以及在空间数字化落地的最新实践。同时，旷视发布了全线焕新的硬件产品，展示了不断升级的产业生态能力。</p><p>&nbsp;</p><p>当前，AI正在迎来新一轮的技术发展浪潮。旷视联合创始人、CEO印奇认为，AI未来会沿着两个大的方向演进：一是“AI in Digital”，以ChatGPT为代表的技术，将给数字世界带来新技术范式的迁移。二是“AI in Physical”，以特斯拉为代表的企业，将AI技术引擎与硬件载体结合，产生自动驾驶、机器人等不同类型的智能机器，对物理世界进行改造。印奇表示，旷视的目标是要做影响物理世界的AI技术创新。</p><p>&nbsp;</p><p>印奇表示，旷视一直坚定的目标，就是要保持核心技术能力长期领先。旷视研究院建立了由500名AI研究员构成的研发团队，能输出从底层深度学习框架，到算法研发、软硬一体化产品的完整技术能力。印奇认为，如果在AI核心技术上无法引领，旷视乃至中国的AI企业，就会在全球竞争中逐渐失去自己的位置。因此，旷视会非常坚定地在核心技术研发方面持续投入。</p><p>&nbsp;</p><p>印奇强调，仅有好的AI技术还远远不够，必须变成最好的产品。未来两到三年，旷视通过产业合作实现价值的核心，将是“降低门槛”和“场景创新”这两个关键词。一方面，要推动AI技术易用性的实现，降低开发难度与成本，让合作伙伴更专注于挖掘行业刚性场景需求上。另一方面，要与更多懂行、懂客户的合作伙伴一起联合创新，面向更广阔的AIoT和数字化转型市场，创造更加丰富、有价值的场景应用。</p>",
    "publish_time": "2023-03-10 15:56:37",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "前端架构设计优化：构建可扩展的低代码平台",
    "url": "https://www.infoq.cn/article/BOxVJWVEjXRJqogdvwoV",
    "summary": "<p>自 Forrester 在 2014 年提出低代码的概念以来，特别是 2021 年国内低代码厂商的融资热潮以来，低代码化已经成为现今各大企业调研和践行的热门方向。面对日益复杂的需求和应用场景，可扩展性对于低代码平台的重要性日益凸显。我们将从整体架构设计、页面描述协议设计、渲染器和设计器的架构设计这四个方面，来探讨如何设计一个高可扩展性的低代码平台。</p><p>&nbsp;</p><p>本文整理自中设数字前端架构师郝振佳在今年8月ArchSummit全球架构师峰会（北京站）上的演讲分享，主题为“<a href=\"https://archsummit.infoq.cn/2022/beijing/presentation/4876\">可扩展的低代码平台前端架构设计</a>\"”。分享主要分为四部分：1、低代码发展概述；2、低代码平台前端整体设计；3、低代码平台可扩展能力设计4、低代码平台的未来与展望。</p><p>&nbsp;</p><p></p><h1>低代码发展概述</h1><p></p><p>什么是低代码？艾瑞咨询在3月2号发布的中国低代码行业生态发展洞察报告上面是这么说的：低代码开发平台是通过为开发者提供可视化的应用开发环境，降低或去除应用开发对原生代码编写的需求量，进而实现便捷构建应用程序的一种解决方案。如果说猪站在风口上都可以飞起来，那么低代码可能是我们前端离风口最近的一次。</p><p></p><p>低代码平台的应用场景可以分成通用型和垂直型这两类。低代码平台的产品形态可以按照搭建时是否需要代码来分成狭义的低代码平台和零代码平台这两类。它们面向的对象不同，关注点也有所不同。狭义的低代码平台主要服务于关注业务逻辑的开发部门，可能给开发用，有可能给前端用，也有可能给后端用，需要有少量的代码来进行模块衔接等等一系列的辅助功能。零代码平台更多的强调面向于业务部门，更强调其低门槛性，业务的同学可以在不写一行代码的情况下，仅仅通过可视化拖拽的方式来完成系统的构建，只需要理顺业务逻辑就可以了。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/82/82cc264afd222e4612eb7df93442c022.png\" /></p><p></p><p>我们在此对低代码平台和零代码平台做了个对比，列出了三个概念，叫做ProCode和LowCode和NoCode。像NoCode这个方向，随着使用门槛的降低，同时也失去了灵活性，想要强调灵活性，可能就需要向ProCode方向发展，就是纯手写代码没有实现不了的功能。</p><p></p><p>那么，有没有一种解决方案可以做到兼具灵活性和使用门槛低？在这里，请允许我卖一个关子，我们接着往下进行。</p><p></p><h1>低代码平台前端整体设计</h1><p></p><p></p><h2>整体系统架构设计</h2><p></p><p>第二部分是低代码平台的设计。我们的任务是要满足集团内所有的2E和2B的移动端页面的搭建需求。我们大概的组织结构是，前面会有一个前端研发部，后面有不同的业务部门，他们所负责的各个应用App页面的风格各不一致。我们要先明确系统的设计目标，它是一个移动端的低代码平台，是一个通用型的具有高可扩展性的低代码平台。因为我们只关注页面的搭建，不需要去关注流程表单以及可视化BI之类的东西，我们仅仅关注于纯前端的页面搭建。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9e/9e225c80b4c59851fc4858faebf88254.png\" /></p><p></p><p>我们平台的架构基本上关键部分由四部分组成。位于核心部分的是页面描述协议，它是连接各个部分的中枢，页面设计器负责生成页面描述协议。平台后端做页面描述协议的存储以及附属的逻辑等等，另外要有一个运行时，它的核心是渲染引擎，它是页面描述协议的消费者。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dd/dd9e332ae230e903e738eff67fd7fdf7.png\" /></p><p></p><p>我们如何才能够覆盖更多的个性化需求？在这里，我们列举了代码能够实现的功能。我们以View为例，它可能有属性、事件、Data、计算属性、Watch、方法等等一系列逻辑。你写代码能够做到的，我们低代码平台都有对应的形式给你提供支持，不敢说满足百分之百的个性化需求，但90%以上没有问题。在对应的LowCode端，我们做了对应的解决方案，像计算属性和Watch都能够通过配置来解决，像Data这一侧我们引入了变量这样一个概念，它的使用过程跟Data的定义以及修改是差不多的，像方法我们引入了自定义方法，在业务上，我们可能会有业务组件，后面规划会去做区块模板等等一系列的功能，这是提高扩展性的总体思路。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c9/c9b891ca028dcbb3b642c80efa6fbd13.png\" /></p><p></p><p></p><h2>页面描述协议设计</h2><p></p><p>在设计的过程中，我们怎么去做页面描述协议的设计？现在的MVM页面UI已经抽象成了一个一个的组件树，而我们做得更进一步，把组件树抽象JSON化为SchemaNodeTree，每一个SchemaNode的结构针对于组件的属性和事件去做处理。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/09/0977e2dcfd03dc7720707758a97bb4f1.png\" /></p><p>‘</p><p></p><h2>基于插件的渲染器设计</h2><p></p><p>为什么我们要先说解析引擎？是因为页面设计侧跟解析引擎有一些关联。对于解析引擎，我们的设计思路是一切皆插件。我们底层实现了一个PluginDriver，由对应的PluginManager去管理整个Plugins，再往上是一个扩展层，对应着各个Plugins的实现。Evaluator求值器也是插件，只不过随着页面协议确定之后，它的逻辑相对固定，不太可能会变化，我们把它放到了Core层。组件渲染SchemaRenderer是总体的出口，再往上是我们设计的一系列插件。像Passers，负责的是把Schema&nbsp;Node解析成对应的组件以及一些个性化的逻辑，Validators大家应该相对比较熟悉，就是去处理Form的一些校验等，Actions是我们对Events处理抽离出来的一个插件。另外包括一些像请求拦截的拦截器等等一系列Utils是在扩展层。最上面有一个封装层，封装层算是一个出口，我们把整个引擎做了一个简单的包装提供给API。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c4/c473343064c85158aef73249f158b5e1.png\" /></p><p></p><p></p><h2>配置驱动的设计器设计</h2><p></p><p>页面设计器的设计思路用一句话来形容就是配置驱动。我们虽然分了配置层、服务层、数据层、组件层和业务层，但是大体可以分为两层，上面属于核心能力的提供，下面属于配置和扩展。我们的页面设计器仅仅做核心能力的提供，具体的能力由配置来驱动。我们的配置目前分成三部分，第一部分是组件，就是页面能够实现的程度多么丰富，取决于平台能够支持的组件有多么丰富，我们在后面再去扩展层做详细的说明。提供能力扩展的是插件，就是前面讲到的解析引擎的各个插件。阿里开源的LowCodeEngine是一个非常优秀的框架，我们借鉴了它的思路也对Setter进行了抽离，支持Setter扩展。再往上是AssetsDriver，对扩展层管理的功能，有ComponentAssets Manager去管理组件，PluginAssets Manager用管理插件，SetterAssets&nbsp;Manager用来管理Setter。数据层是VUEX实现的一个全局的数据通信。再往上我们会抽离一些对应的组件，在业务层进行组装。</p><p></p><h1>低代码平台可扩展能力设计</h1><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d1/d133597de7d20a2c409c371c6867c7ff.png\" /></p><p></p><p>最后，我们对低代码平台的扩展能力做一个总结，它可以分成能力提供层，中间一个连接上下的协议层，以及上面一个扩展层。底层是核心的页面设计器和渲染引擎，再往上提供了一系列的描述协议，包括：页面描述协议用于页面的展现以及渲染引擎核心的关联，组件描述协议对组件进行约束和定义，还有插件描述协议和设置器描述协议。另外我们在组件、插件和设置器层进行扩展，就能够完成我们最终能力的实现和丰富。</p><p></p><h1>未来和展望</h1><p></p><p></p><h2>低代码会不会替代程序员</h2><p></p><p>所有前端的同学还有一些使用过后端的同学都有这样的疑问，就是低代码平台会不会把我们替代掉，我们会不会失业？低代码平台会不会替代程序员？我个人的观点是，首先低代码平台是一个提效工具，未来可能低代码平台会变成像Office一样的工作技能，所以低代码平台更充满想象空间的地方是能够让更多的人运用低代码平台去做我们原来需要程序员经过许多年培训才能做的工作，可能他做出来的性能不那么优，但是能够初步满足业务的需求，所以现在低代码的行业都会说未来可能是一个人人都是开发者的时代。</p><p></p><p>另外，我觉得低代码平台等等现代技术的发展，是对程序员的抽象能力和架构能力提出了更高的要求，所以我们要在基于对业务的理解的基础上做抽象和架构的设计，能够很好地支撑低代码平台的架构以及可维护性。我们要去理解设计模式、抽象以及架构等一系列的技能，能够脱离出业务，写出一些更抽象型更通用型的代码。</p><p></p><p>最后，个人感觉有可能在未来会出现低代码开发工程师这样一个新的职业，他可能是基于各种各样的低代码，加上少量的程序支持，快速做系统的开发和交付。大家如果对架构等深入内容无感的话，可以关注这个方向。</p><p></p><h2>低代码的未来</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/56/5654083c230f0906a7e144c3a83750ea.png\" /></p><p></p><p>还记得前面我卖的那个关子吗？我们有没有一种解决方案能够让它兼具灵活性和低使用门槛？我们的一些思考是这样的，就是可能未来的低代码架构可以称之为哑铃型的架构，中间会有一个相对比较核心的低代码的框架去做支撑，然后向下连接的是ProCode，可以有自己的组件生态、插件生态以及设置器生态等一系列通过ProCode来实现的能力。这些能力进行有机组合可以产生出各种各样的面向各个功能的低代码平台，或者是零代码平台，就是往上是LowCode，或者是NoCode，往下是Pro Code。它会有LowCode框架这一层去做中枢或者桥接，把它们有机地结合在一起，形成一个生态。首先它是一个有机的生态，是一个一体化的系统。其次，我们可以牺牲它的灵活度，面向于具体的领域形成对应的零代码的解决方案来降低大家的使用门槛。或者零代码平台有对应的低代码平台做支撑，一旦你的需求不支持，第一步的解决方案是支持平滑升级到低代码平台，做增强功能的建设。如果再不支持，就需要程序员介入，以插件或者组件等等一系列的方式来做个性化的定制。虽然我们表现出来的可能是一个零代码平台，但是背后一定要有一个完善的生态去支撑它。</p><p></p><h5>相关阅读：</h5><p></p><p><a href=\"https://xie.infoq.cn/article/5837c5a6e7d66d9ab68ad532e\">低代码开发平台 助力教育行业信息化建设</a>\"</p><p><a href=\"https://xie.infoq.cn/article/7241694cec9357d3888a797c1\">低代码开发平台 让数据应用不再复杂</a>\"</p><p><a href=\"https://xie.infoq.cn/article/c7ecc61683999257715fbcd57\">一款好的低代码开发平台应该是什么样？</a>\"</p><p><a href=\"https://xie.infoq.cn/article/7162468b8509dc4e3ac5b6573\">低代码开发平台 打开数字化转型普惠之门</a>\"</p>",
    "publish_time": "2023-03-10 16:30:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "API 网关和负载均衡器，到底怎么选？",
    "url": "https://www.infoq.cn/article/mDlgpAcKK4V3Qr4r9d8E",
    "summary": "<p>&nbsp;</p><p></p><blockquote>本文介绍了 Load Balancer 和 API Gateway 的功能特点，并探讨了它们之间的区别，希望可以帮助读者更好地了解这两者之间的关系。</blockquote><p></p><p>&nbsp;</p><p>作者：陈泵，API7.ai 技术工程师</p><p>&nbsp;</p><p>由于互联网技术的发展，网络数据的请求数节节攀升，这使得服务器承受的压力越来越大。在早期的系统架构中，通常使用 Load Balancer 来将网络流量平摊到多个服务器中，以此减轻单台服务器的压力。但是现如今，后端服务的种类在不断地变多，每个种类的后端都以 API 的形式对外暴露，这使得 API 的数量也在不断变多。以传统的 Load Balancer 为主的系统架构的局限性就变得明显起来，因为它主要工作在四层，在七层上功能较弱，于是一款主要工作在七层且具有丰富扩展能力的基础设施便应运而生，它就是 API Gateway。</p><p>&nbsp;</p><p>在本文中，我们将介绍 Load Balancer 和 <a href=\"https://www.infoq.cn/theme/156\">API Gateway</a>\" 的功能特点，并探讨它们之间的区别，帮助读者更好地了解这两者之间的关系。</p><p></p><h2>什么是 Load Balancer</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/5a/5a024e96ea73028519f1a631172ae741.png\" /></p><p>Load Balancer 的主要作用是为多个后端服务提供<a href=\"https://www.infoq.cn/article/45lSR8NaqzAVBOlKlrTV\">负载均衡</a>\"功能，依据不同的负载均衡算法让这些服务可以分摊流量。Load Balancer 的历史非常悠久，从演进路径上看大致可以分为以下这几个阶段：</p><p></p><p>第一阶段（2000以前）：这一阶段的 Load Balancer 通常由硬件设备组成，具有高性能、高可靠性的特点，但灵活性较差，价格昂贵。比较典型的是 F5 这种基于硬件的 Load Balancer 。第二阶段（2000-2010）：Load Balancer 开始以软件形式实现，使其更加灵活和可扩展，通常以软件分发的形式出现，因此价格也比较低廉，比如 LVS 就属于这一类。第三阶段（2010至今）：随着云计算技术的兴起，Load Balancer 也开始有了云版本，这个版本的 Load Balancer 其中一个好处是可以帮助企业以更低的成本获得高性能的负载均衡服务，另一个好处是它能够利用云计算的可扩展性和弹性的特点来提高整体可用性。例如 AWS 的 Classic Load Balancer、Application Load Balancer、Network Load Balancer 等。</p><p>&nbsp;</p><p>Load Balancer 除了用于分摊流量、提高网络的伸缩性外，还可以用于提升网络安全。比如可以将内网服务器与外网进行隔离，防止互联网的恶意攻击和访问。一个简单的使用场景就是，对于一个包含敏感信息的内部服务器，Load Balancer 可以把内部服务器隔离在内网中，这样就能有效保护内部服务器的安全。</p><p></p><h2>什么是 API Gateway</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/19/1929ebf3fc6562f4a91162a897e1b876.png\" /></p><p></p><p>&nbsp;API Gateway 简单来说是一种主要工作在七层、专门用于 API 的管理和流量转发的基础设施，并在此基础上拥有 Load Balancer 所不具备的强大的扩展性，比如：认证、可观测性、自定义插件等等。简单来说，包括但不限于以下这些特点：</p><p></p><p>丰富的路由策略：API Gateway 工作在七层，所以它可以解析到 HTTP/HTTPS 层的数据。因此它可以根据请求的 Path 或 Domain 甚至是 Header 作为条件，将请求转发到不同的上游服务器。认证：可以在API层面支持多种多样的认证方式来避免非法请求，比如 OAuth2、JWT 等等，直接将认证这部分服务独立出来，不侵入或者少侵入业务代码。限流：支持对不同程度的路由进行细粒度的限流，防止恶意攻击，防止后端服务雪崩。可观测性：可观测性是指从系统外部观察系统内部程序的运行状态和资源使用情况的能力。 API Gateway 支持将日志对接到 Kafka、 Google Cloud Logging Service、Elasticsearch 等，支持将相关 metrics 接入到 prometheus、datadog 等。扩展：因为 API Gateway 自身是网关身份，这就注定对它要求是能适配各家公司不同应用场景，比如不同的鉴权、灰度、安全策略、日志收集等，必须允许用户自由选择所需扩展或者自定义开发，因此扩展性很强，允许选择的扩展种类也十分丰富。以 Apache APISIX 举例，光是认证的扩展就有 13 款，几乎涵盖了市面上常见的认证需求。</p><p>&nbsp;</p><p>目前市面上有许多 API Gateway，比如 Apache APISIX、Kong、Tyk、Zuul 等，开发者可以根据自己的需求选择合适的 API Gateway。</p><p></p><h2>API Gateway 与 Load Balancer 主要区别</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9d/9ddd8b67ae4cb2af6420c3b009a099ef.png\" /></p><p></p><p>&nbsp;首先，他们主要工作的侧重点不同。虽然说 API Gateway 和 Load Balancer 都支持四层和七层的代理，但是 API Gateway 主要侧重于七层，而 Load Balancer 主要侧重于四层。</p><p>&nbsp;</p><p>工作在四层的 Load Balancer 拥有许多优势，首先是它相比于 API Gateway 减少了协议解析的损耗，具有更强的吞吐能力；其次就是它支持透传客户端 IP 地址，而 API Gateway一般是通过 HTTP 头方式传递客户端 IP 地址。</p><p><img src=\"https://static001.geekbang.org/infoq/7d/7d00725f02ed466f79605763df49ed97.png\" /></p><p></p><p>再者就是两者功能的丰富程度不同。Load Balancer 的 HTTP 七层处理能力比较弱，往往不包含认证、授权、鉴权、复杂路由逻辑、日志收集等功能。API Gateway 则具有相当强大的七层协议处理能力，可以在此基础上附加各种各样的功能扩展，比如权限控制、日志、API 管理、Serverless 等等。</p><p>&nbsp;</p><p>现如今，科技公司的产品需求变幻莫测，对于很多公司来说支持自定义开发是刚需。API Gateway 支持各式的自定义开发，比如支持丰富的编程语言、支持在流量转发的不同阶段注入自定义的处理逻辑，而 Load Balancer 基本不支持任何自定义功能开发。</p><p>&nbsp;</p><p>还有一点就是 Load Balancer 通常采用流量直接分发的形式做负载均衡，它通过算法将流量数据直接发向某个后端服务器节点。这意味着后端等待接收流量的每一个服务实例行为都必须是一致的，减少了一定的灵活性。而 API Gateway 则是以 URL Path 、Domain、Header 等维度进行流量分发，后端等待接收流量的服务实例可以多种多样，可以是某个 Private API，也可以是某个 gRPC 的 API，使流量分发变得十分地灵活。</p><p></p><h2>使用场景的差异</h2><p></p><p></p><h3>微服务场景</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/27/27e288f9d65eba9fa764d01da3c0e523.png\" /></p><p></p><p>&nbsp;API Gateway 对于<a href=\"https://xie.infoq.cn/article/2fb473736634a8f25e3e37145\">微服务架构</a>\"的系统来说是刚需。首先它可以方便地管理和路由多种不同的后端服务，其次可以提供许多高级功能，比如身份验证、授权、限流、转发、日志记录等。这样，不同的微服务之间无需重复实现限流、认证等功能，让微服务每个服务的功能实现更加纯粹，减少研发成本。</p><p>&nbsp;</p><p>由于微服务的特点是服务种类多，工作在四层的 Load Balancer 不太适合对种类繁多后端服务做负载均衡，它更适合用于单体后端服务。即使是工作在七层的 Load Balancer，因为一般不能提供较为丰富的高级功能，相比于 API Gateway 在微服务上优势也不明显。</p><p></p><h3>API 管理与发布</h3><p></p><p></p><p>在需要对大量的 API 进行管理和发布的场景，API Gateway 也非常适用，因为它具有强大的 API 管理功能，可以让你随时随地让某个 API 上线或者下线，快速地修改 API 转发的配置，快速地为某个 API 添加限流、认证、日志等等功能而无需重新启动 API Gateway。</p><p>&nbsp;</p><p>以 Apache APISIX 为例，Apache APISIX 是 Apache 基金会旗下的顶级开源项目，也是当前最活跃的开源网关项目。作为一个动态、实时、高性能的开源 API 网关，Apache APISIX 提供了负载均衡、动态上游、灰度发布、服务熔断、身份认证、可观测性等丰富的流量管理功能。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ca/ca4e7819d95e14587f053ab9093e2efc.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/40/4084270416ad46e3c9c33d45d96ce986.png\" /></p><p></p><p>&nbsp;</p><p>而传统的 Load Balancer 则在 API 管理上较为弱势，不具备如此丰富的高级功能。</p><p></p><h3>高性能的网络出入口</h3><p></p><p></p><p>对于需要大流量、极高稳定性的网络出入口的场景，工作在四层的 Load Balancer 显然更为适用。它可以把网络原始四层流量直接分发到各个后端服务中，不存在中间层多次解析应用层协议的影响，具有更强的吞吐能力。</p><p>&nbsp;</p><p>而工作在七层的 API Gateway 作为统一的入口，由于需要解析协议，因此存在一定的吞吐量限制。即使是使用四层的 API Gateway 来做网络出入口也不太有优势，因为这一层不是 API Gateway 的侧重点，相比于 Load Balancer 多年在这一层的技术累计，API Gateway 优势也不明显。</p><p></p><h2>总结</h2><p></p><p></p><p>总的来说，API Gateway 和 Load Balancer 是分别用于解决不同层面问题的基础设施。API Gateway 主要用于作为后端的 API 接口代理，提供对外访问不同种类 API 的一个单独入口，并且可以提供独立于后端服务的限流、认证、监控等功能；而 Load Balancer 则主要用于四层流量分发，它可以将请求分摊到多台后端服务器上，平衡后端的请求负载，以提高系统的整体可用性和容错性。</p><p>&nbsp;</p><p>在合理的架构设计下，一般都将 API Gateway 和 Load Balancer 配合使用，使用 Load Balancer 作为整个系统的网络出入口，将流量分发到多个 API Gateway 实例，然后每个 API Gateway 实例分别对请求进行路由、认证、鉴权等操作，这样可以使得整个网络更加稳健、可靠、可扩展。</p><p>&nbsp;</p>",
    "publish_time": "2023-03-10 16:46:32",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从传统数据库痛点看分布式数据库选型问题",
    "url": "https://www.infoq.cn/article/wGIjewsfYboQvQwA2LYo",
    "summary": "<p></p><h2>引言</h2><p></p><p></p><p>近年来，随着互联网大厂掀起分布式数据库的技术浪潮，中小型互联网企业也在不同业务场景下纷纷试水分布式数据库，电信、金融、银行、保险等传统领域的大型企业也逐渐转向分布式数据库，这也成为 DBA 这个小圈子中热议的话题。 确实，从现实需求上看，各行各行业的数据量与日俱增，在这样的背景下，我们需要“随波逐流”布局分布式数据库吗？以下为个人浅显的思考，供大家简单参考、水平有限如有错误烦请指正。</p><p></p><h2>传统数据库痛点</h2><p></p><p></p><p>说起分布式数据库，必须先提一下<a href=\"https://mp.weixin.qq.com/s?__biz=MzIzNjUxMzk2NQ==&amp;mid=2247484162&amp;idx=1&amp;sn=78a8375d8a212a17e0020c7fce9dff07&amp;chksm=e8d7fcc0dfa075d623cd2223cced03ab6da5f651131333577ed682cf897e0cb4f01d9d5f025a&amp;scene=27#wechat_redirect\">传统单机数据库</a>\"。以大家较为熟悉的 MySQL 为例，如下图所示，传统单机数据库架构简单，由若干台节点通过 Binlog 复制构成一个集群，写集中在主库，读则分摊在集群的各个节点上。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/90/902b68fdbd3b407bab072ba2221e99ec.png\" /></p><p></p><p>不可否认的是，上述架构在一些重要特性上存在“天花板较低”的问题，如以下 5 个特性。</p><p></p><p>特性 1：高可用问题。</p><p>MySQL 本身是不具备高可用能力的，它的高可用能力通过外部工具协助达成（MySQL 高可用方案随着复制的改进有漫长的演化历史）。众所周知，高可用工具往往只能最大限度解决数据一致性的问题，而不能解决 HA 切换后应用访问的问题，通常一个完整的高可用系统是要 HA 工具+Proxy 联动+ClientDriver 连接池合理配置共同实现的。遗憾的是，时至今日不少中小公司并没有丝滑解决 HA 切换的问题，主要原因是 HA 工具+Proxy 深度定制能力欠缺，篇幅原因不做展开。</p><p></p><p>特性 2：数据一致性问题。</p><p>数据复制是存在时差的，造成读一致性问题，但这通常不是太大的问题，通过 Proxy bindmaster 操作都能解决，不过，master 压力可能会同样面临性能瓶颈。</p><p></p><p>特性 3：容量、性能扩展、结构变更。</p><p>这是传统单机数据库的三宗罪。存储的扩展在一定程度内可以通过堆硬件（垂直扩容）的方式来解决，但堆硬件也是有限度的，出于可运维、易运维的角度，通常 DBA 都不会让单实例或者单表太大。可能对于一个冷的日志表存储超过 1TB DBA 可能就会比较紧张了，毕竟 DDL 一次可能要以天计算，而对于一个读写高频的订单表超过 500GB，估计 DBA 维护就会如履薄冰瑟瑟发抖了。这时棘手的问题就来了：给够你硬件你都不敢用。</p><p></p><p>通过堆硬件能在一定程度上缓解存储容量上限的问题，但性能问题是无法靠堆硬件完全解决的。还以订单表为例，如果是日订单百万甚至千万级别，无论怎么折腾单表都会出现严重的读写性能问题，此时通过扩容硬件的方式不能解决问题。一方面是因为数据库本身会由于热点表的高频读写造成严重的锁放大问题，另一方面数据库本身并不能充分使用硬件资源，尤其 MySQL 5.6 之前的版本由于诸多子线程未从 Master 主程上拆分，造成 CPU 使用不充分，这在 MySQL 5.7 版本后有了很大的改观。尽管如此，还是会受到网卡、磁盘 IOPS 上限因素的影响，注定单机构成的<a href=\"https://www.infoq.cn/article/dassaX2O2WqvGjqpbXlf\">数据库</a>\"集群存在性能上限。因此不幸的是：给你足够的资源你都用不到。</p><p></p><p>不敢用、用不到都很痛苦！为此就诞生了“拆”的想法，根据不同的“拆”法诞生了不同形态的分布式数据库。值得一提的是今天做数据库拆分的初衷并不是为了解决性能瓶颈而是数据存储达到单机上限，更直白一点地说，拆的关键是解决大表运维困境。</p><p></p><p>特性 4：HTAP。</p><p>新时代赋予<a href=\"https://archsummit.infoq.cn/202303/beijing/track/1448\">数据处理</a>\"新的诉求，目前解决方案还是通过数据流（ETL）的方式将数据写到其他分析型数据库中。不管是链路维护复杂性还是应用健壮性（低延迟、高稳定性）都有不小的麻烦。因此，希望能通过一套数据库搞定所有问题。</p><p></p><p>特性 5：容灾能力。</p><p>近几年企业对容灾的要求越来越高，作为 DBA 也应当确保极端情况下（机房限电、被炸等）数据库具备逃逸能力。单机数据库通过主从（异地部署）方式也能实现，虽然维护较为复杂但也能用。</p><p></p><h2>分布式数据库形态划分</h2><p></p><p><a href=\"https://archsummit.infoq.cn/202303/beijing/track/1448\">分布式数据库</a>\"根据不同“拆”法或者设计理念大致有如下三种形态划分。</p><p></p><h3>1、分布式中间件</h3><p></p><p>典型的架构图（简化图），核心思想是通过中间件将多个独立的物理集群组联合起来构成一个逻辑集群，通过某种数据路由规则将用户请求打散到不同节点上。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/66/667b753e5df37d3c872550e5063b923a.png\" /></p><p></p><p>该做法俗称分库分表，是绝大部分互联网公司在解决容量、性能扩展性问题上的首选方案。该方案将数据基于某种规则（sharding key）均匀拆分到多个集群中来达到分摊存储与计算性能压力，代表的中间件产品 TDDL/Cobar/Vitess，及基于该思想诞生的“分布式 DB”代表产品 TDSQL、StarDB 等。这类方案虽然解决了容量、性能可扩展的问题，但是也存在如下的一些问题。</p><p></p><p>问题 1：技术复杂。</p><p>通常是大公司专属玩法，普遍基于业务场景做了深度定制，周边有一套完整的配套管控系统支持。目前市面上虽然有一些开源的 Proxy 也能用，但对于中小公司来说很难从根上可控，使用过程中的棘手问题几乎很难在短时间解决，而且开源产品为了通用性要想基于公司场景化定制有难度。因此，很多中小公司虽然做了分库分表但或多或少存在这样那样的问题。</p><p></p><p>问题 2：对业务有侵入。</p><p>从单表到分库分表的改造普遍要求带 sharding key 作为数据拆分及路由依据，这样业务逻辑被迫进行改造，比如对多表 join 的场景很难通过中间件去解决、非 sharding key 的查询被迫要扫片性能则非常低、排序/分页/聚合计算问题，等等。为了解决数据拆后聚合的问题，通常要在整个业务链路上部署复杂的中间件，这给稳定性维护及业务健壮性带来一些挑战。</p><p></p><p>问题 3：扩缩容复杂。</p><p>通常在决定分库分表的时候需要提前做好容量评估，分片数定义好后就不在改变，非常不推荐后期再去扩展/缩容分片数。调整（reshard）分片数涉及数据 rebalance 整个过程。为了保证数据一致性要做很多额外工作，通常是<a href=\"https://archsummit.infoq.cn/202303/beijing/presentation/5053\"> DBA</a>\" 定制开发一个平滑迁移工具，或者研发双写+增量 Binlog 数据订阅做数据同步。如果 reshard 操作能内置到中间件，那对研发及 DBA 来说自然更友好，但目前市面上开源的中间件几乎没有见到有类似的功能！诸如 <a href=\"https://www.infoq.cn/video/tKJy8kCY9cqdXK8YCDkl\">TDSQL</a>\"、StarDB 等从公开资料上看是具备对用户透明的 reshard 能力的。</p><p></p><p>问题 4：分布式事务问题。</p><p>出于对 ACID 完整性支持的考虑，由中间件形态构成的分布式数据库中解决分布式事务问题，通常解决方案都是差不多的，即两阶段提交（2PC）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/15/1595a06453d2b4bad6bcde7f4bd245b8.png\" /></p><p></p><p>但实现过程非常复杂，也不可避免的对性能造成影响，通常在该形态的分布式数据库中都不太推荐用分布式事务。此外，这里分布式事务不能保证数据一致性或者说对集群而言本质还是最终一致性，该形态的分布式数据库在分布式事务实现上普遍类似，可以参考分布式中间件 Seata 的实现原理。</p><p></p><p>对于中小公司可行的做法是业务场景拆分得足够简单的情况下基于代理中间件+业务数据补偿来保证数据的最终一致性，使用分布式框架如 Seata 也是可行的，但太重了，对性能也会有明显的影响。</p><p></p><p>问题 5：运维复杂性。</p><p><a href=\"https://www.infoq.cn/article/L8Y7r01CWRe4V0ov5FTr\">分布式</a>\"中间件形态的数据库往往都有非常完善配套的管控系统来打包解决常见的运维问题，如果公司是基于某个开源的代理中间件做的，则不可避免的也要开发相关的管控系统来统一解决诸如 DDL、研发数据订正等问题。整体上还是能很好解决存储、计算能力不足等问题和大表运维困境，只是对业务会有入侵，大公司专属定制，中小公司勉强也能玩转。</p><p></p><p>问题 6：HTAP。</p><p>目前看到的分布式中间件形态的数据库基本不具备 OLAP 的能力，普遍做法还是要将数据流向到分析型数据库中。</p><p></p><p>问题 7：容灾能力。</p><p>跟单机主从无本质区别。</p><p></p><h3>2、存储计算分离</h3><p></p><p>该形态的分布式数据库核心思想是计算、存储分离，计算与存储解耦，将有状态的数据和日志下推到分布式存储，多个无状态计算节点共享一份数据，代表产品 AWS Aurora、阿里 PolarDB。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/33/33eaae5e998bf261097e6077fbd7bac3.png\" /></p><p></p><p>这里简单看一下 Aurora 对性能、容量、结构变更上的优化。</p><p></p><p>首先在性能上，the log(redolog) is the database，简单说 Aurora 没有直接存储 MySQL 的 innodb page 数据页，只有一份 redolog 日志（个人理解应该是区别于 innodb 的 wal，最多是概念的相似，没有做深度考证），当需要读取数据时将 redolog 转换为 data page。这样设计由于只存储了一份 redo 数据（批量+顺序 I/O）无需写 data page 因此也不存在缓冲区刷脏跟随机 I/O 写的问题，这相比于 MySQL 写 I/O 放大要精简很多，因此性能要提升很多。引用公开资料结论：事务 I/O 开销只有 MySQL 1/7 事务处理能力是 MySQL 的 35 倍。</p><p></p><p>不过有利就有弊，Aurora Server 层还是原汁原味的 MySQL Server（100%兼容原生 MySQL），读取数据时不可能直接读取 redolog，需要将 redolog 转换为 data page，转换是要支付 CPU 代价的。当然基于该特殊设计还有一些其他比较好用的功能如秒级备份（俗称拍快照），就不多介绍了。</p><p></p><p>其次在容量上，存储构建在 S3 共享存储之上，对于容量扩展可以支撑足够大的数据量(64TB)，多个副本之间通过 Gossip 协议保障数据一致性的，得益于 S3 的设计副本间的数据同步是非常高效的，因此副本间的数据延迟非常低。笔者在写该文档时顺便查了一下当天的副本延迟监控 P90 居然都不到 1s，对比原生 MySQL 即使是优化后的 GroupCommit+MTS 也很难做到这一点。</p><p></p><p>值得一提的是，正是基于 log is data 的设计+S3 log 同步避免了多数据副本间为数据一致性采取的 2PC/3PC 提交或者更复杂的 Paxos 算法，非常 niubility 的设计。最后 Aurora 的存储容量是弹性伸缩的，DBA 无需主动扩容，不过从使用经验上看，在业务释放空间后似乎并没有做“缩”的动作，会继续按照此前实例使用的最大存储来计费（略坑），这点目前不清楚具体原因是啥！</p><p></p><p>在结构变更方面，目前跟原生 MySQL 一样也是 fast ddl，在 lab mode（实验室模式默认关闭状态，官方不推荐用……）支持 Instant ddl，不过只针对 add column 操作，目前 DDL 操作其实还是以 pt-osc/gh-ost 为主。虽然大表容量的问题解决了但对于超大表的运维还会存在一定的问题。即使通过 pt-osc/gh-ost 能丝滑变更，以及 MySQL 没有明确规定单表大小及行数上限，但出于 b-tree 的原因在行数过多后还是会影响到读写性能，笔者在实际使用过程中就出现了一张 400G 的单表 DDL 超过 12 小时的情况，为此发布系统不得不 block 这个表的发布长达一年的时间。</p><p></p><p>存储计算分离的形态下，尽管架构是<a href=\"https://www.infoq.cn/article/L8Y7r01CWRe4V0ov5FTr\">分布式</a>\"的，在具体的设计思想上也非常先进，但对于解决大表问题还是稍稍有一点小遗憾，不过相比传统单机数据库已经不用担心容量问题了，这一点对于业务体量不大既不想用中间件也不想对业务动刀的公司而言似乎也是不错的选择，况且 SQL 协议 100%兼容。</p><p></p><p>此外，通过将计算下推到分布式存储的多个存储单元上实现并行查询从而具备一定的分析能力，也很难满足分析型场景要求。不过，存储计算分离的形态天然具备同城+异地容灾能力。</p><p></p><p>在使用 Aurora 的使用体感上，笔者更倾向于把它当作一个不宕机的容量性能无限扩展的单机数据库来使用，当业务体量到一定程度后出于易维护的角度考虑，最后大概率还是要拆的。最后建议如果中间件能力缺乏又不想因拆导致的后续一堆麻烦的问题，即使维护麻烦一点也可以继续使用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/20/206b844d44f7f5a4242d5af83af99527.png\" /></p><p></p><p><a href=\"https://www.infoq.cn/video/pd9q0lWjVcEk7HiPjIfq\">PolarDB</a>\" 与 Aurora 类似，也采用了存储计算分离架构，因此也能很好解决容量、性能问题，同时也做到 100%的协议兼容与较低的数据延迟，至于谁优谁劣，由于二者设计理念不同，以及个人水平有限，不做过多评价跟分析。</p><p></p><p>PolarDB 在比较关心的大表解决方案上做了优化增强，主要解决方法就是通过分区表，如分区键跟主键/唯一键解耦（MySQL 则要求 pk/uk 必须包含分区键），分区锁支持将锁从表粒度降低到分区粒度显著增强并行能力。不过分区能力的增强仍旧不能避免大表下 btree 局限问题。为此，PolarDB 又将 btree 改成 Blink-Tree（没有深入了解，简单说就是通过对节点添加额外字段实现 tree 调整时全局加锁到部分加锁，进而提高并发度)。同时对于大表 DDL 问题，PolarDB 除支持 instant ddl 能力外还通过并行 DDL 能力充分利用存储 I/O 能力加速 DDL 进度。</p><p></p><p>即便有上述优化手段也不能彻底解决大表问题，笔者觉得（纯粹个人理解）基于上述优化后应该是比 Aurora 裸大表的方式要好一些，起码会大程度上推迟性能瓶颈的到来，这又进一步了推迟了用户分库分表的紧迫性。</p><p></p><p>关于 btree 访问的优化，笔者此前还了解到 GreatSQL(万里数据库)将 B+树划分为若干子树，通过多个线程并行扫描同一张 InnoDB 表的不同部分，之后在将子线程结果汇总达到提升查询性能的目的，也是一个很机智的设计。</p><p></p><p>至于 HTAP 能力，似乎 PolarDB 有着更大的理想，其内置了 X-Engine OLAP 分析引擎(见下图)</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c5/c570f55cfca0567738f4302c2d60763d.png\" /></p><p></p><p>这种一款数据库同时内置 TP(btree&amp;row 存 e)+AP(lsm-tree&amp;列存)两个引擎（两份数据），的方案，即数据通过日志的方式在各个引擎间同步，在近两年也逐渐涌现出来(将离线 ETL 过程给包了)，可以想象其在成本、复杂度上该有多高，注定了专属于顶级大厂的玩具，水平有限下文无法分解！</p><p></p><h3>3、原生分布式</h3><p></p><p>代表产品 OceanBase、TiDB，该形态数据库通过天然的多副本设计+Paxos/Raft 分布式选举协议实现分布式。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/71/716f8ed56b0215aea30618542e0968dd.png\" /></p><p></p><p>在高可用、数据一致性上基于 Paxos 协议实现，无需外部任何三方工具依赖数据具备强一致性，这一点跟存储计算分离实现高可用也略有不同。</p><p></p><p>在解决容量、性能问题上自不必说，OceanBase 同样具备良好的弹性扩展能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cd/cd60545813a75cc17415071fef5c2bd8.png\" /></p><p></p><p>容灾能力同样也比较灵活，能满足不同等级的容灾要求。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/84/847f240fff5eedbfb1790b6283ffdc9e.png\" /></p><p></p><p>只需要添加节点即可完成容灾建设，操作过程也比较简单，当然其他形态的分布式数据库一样可以做到。</p><p>值得一提的是 OceanBase 具备租户的概念，且租户间资源是隔离的，这一点是有别于目前市场上大部分分布式数据库的。基于租户这个特性能玩的花样就多了，如对绝大部分公司而言大部分 DB 其实都不会面临容量、性能上的问题，这些小 DB 又有存在的理由，通常我们还不能将它堆到一个集群里，因为无法解决隔离问题，这里多租户就派上用场了。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5e/5e8ba1831d626ea29f32dc261e92d849.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8e/8e81c482170e4d73ecdba1a657681056.png\" /></p><p></p><p>这里集群租户间资源共享还是隔离是可以灵活设置的，一般有 cpu share（共享）、cpu set（独占）两种方式，可以基于场景设置，以实现业务的错峰部署，最大化提高资源利用率。同时，租户的出现可以让 DBA 在提高资源利用率上具备更灵活的调度策略，如可以开发资源调度系统动态调配不同租户在不同时间的规格配置。这里资源隔离一定要是物理隔离的，如果租户是逻辑隔离意义就小很多。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e0/e0137ac048de1a89ed527999aeeaed43.png\" /></p><p></p><p>OceanBase 采用了 LSM Tree 的存储方式，为了避免写放大等性能问题，OceanBase 的理念也很简单：能通过硬件解决的问题都不是问题。这让我们看到了单 OBServer 居然有恐怖的 700G 内存，这足以容纳绝大部分业务 12 小时的变更量了，因此，读写尽量在内存中完成，待到低峰期在悄悄完成 Compaction，但代价就是价格并不便宜。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/04/0444bca514b307ce5498d829a507603f.png\" /></p><p></p><p>不过在硬件越来越便宜的今天，以及 OceanBase 4.0 开始小型化、单机化，使得 OceanBase 也能飞入寻常百姓家了。</p><p></p><p>在大表的维护上，OceanBase 类似 PolarDB 也是通过分区表的方式来解决，同样可以将分区分布到其他 OBServer，只是不清楚是否也做了 PolarDB 在分区上的诸多优化。所以想当然的会认为 OceanBase 也存在大表下性能问题和变更问题。</p><p></p><p>不过，OceanBase 并不担心大表 DDL 的问题，原因是得益于上述那个昂贵的设计（OceanBase 本身也是维护了 schema version 的对于大部分 DDL 同城都是 online 的），通过低峰期发起 Major freeze 操作合并完成 DDL 自然也就完成了。同时为避免合并带来的影响，OceanBase 通过多个 Zone 间轮转合并避免对用户造成影响。不过 OceanBase2.0 开始在创建索引时就不用等到合并后生效了，用户创建索引就发起索引构建流程缩短生效时间。</p><p></p><p>关于 OceanBase 兼容性，它同时兼容 Oracle 跟 MySQL 的。OceanBase 并不是像 Aurora 那样接近原汁原味的 MySQL Server 对 MySQL 兼容，而是协议层的兼容(小插曲：据说为了跟原汁原味的 MySQL 表现一致就连 Bug 都一起兼容了)。从笔者当初使用 OceanBase 的经验上看，对 MySQL 的兼容度也比较完整，值得一提的是从 MySQL 迁移到 OceanBase 存储规模下降了 2/3。</p><p></p><p>关于 HTAP 可以参考此前 OceanBase CTO 的一篇相关文章《真正的 HTAP 对用户和开发者意味着什么》，引用里面的一个重要观点：</p><p></p><p></p><blockquote>真正的 HTAP 系统有一个要求是基于”一份数据”同时做好交易和分析。那么，什么叫做“一份数据”？想要回答这个问题，核心是要回答哪一种做法是对用户最友好且性价比更高。我认为，数据的多个副本或者多种形态（列索引/ BTree 索引/ Bitmap 索引等）都可以被认为是”一份数据”，前提是能够在满足 HTAP 处理需求的前提下最大程度降低数据冗余。例如，OceanBase 往往存储多个副本（ 3 个副本/ 5 个副本），可以选择让其中一个备副本专门做 OLAP 查询；Oracle IMC 支持对表格在内存中建立列索引，SQL Server 支持对表格在磁盘/内存中建立列索引，从用户的角度仍然是“一个系统，一份数据”。从这里似乎可以窥探到 OceanBase 关于 HTAP 的一些设计思想点：一个系统、一份数据，多副本行列混合存，不搭积木。不过由于资料比较少也没有从 OceanBase 的架构上看到 HTAP 是怎么体现的，当然肯定有别于以 PolarDB 为代表的“多份数据”方案。多份数据实现上可能很复杂但 OceanBase 选择的道路似乎也并不简单甚至更复杂。我们再从 TiDB 架构图上看（如下图），对比之下，OceanBase 似乎更加简洁一点，起码组件没那么多（部署不够友好）不过这似乎也不是什么大的问题，况且 TiDB 提供了简洁的部署方案，不得不说 TiDB 真的很聪明特别懂用户心思，不管是对一个简单的部署，还是一开始选择基于 MySQL 协议去研发，又或者是围绕 MySQL 生态打造的各种工具等等都深得用户心意，这一点跟极力试图通过技术证明自己有多优秀的产品，走的是不同路子。</blockquote><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3c/3c39b2c02fdd004a19cfb5111a4d45a5.png\" /></p><p></p><p>对于性能、容量扩展性问题，TiDB 同样不逊色，其他分布式数据库也具备良好弹性能力，至于兼容性本身就是基于 MySQL 协议打造且在一些互联网公司也都验证过了。当然在一些场合下会拿各个数据库进行性能比较，先不说比较的基准是否一致，性能肯定不是选型的第一考虑因素，毕竟性能是可以通过资源去弥补的，因此性能可扩展性非常重要，如最开始提到的：给够资源用不到那分布式就没有意义。稳定性应该更重要，这一点 OceanBase 在自身大规模金融支付场景下得到过验证这一点是具备足够的说服力的。</p><p>关于 HTAP，TiDB 通过内置 TiFlash 引擎来实现类似 PolarDB 的 X-Engine 做法跟 OceanBase 的“一份数据”理念似乎还是有点不一样的，太复杂看不清楚。也很难说谁优谁劣只能交给时间跟市场去检验了。</p><p></p><p>在 TiDB6.0 里面有多租户概念、虽然也实现了物理隔离，跟 OceanBase 基于内核虚拟化技术不同的是，TiDB 是通过资源打标+调度的方式来实现的，个人觉得 OceanBase 在这方面要更胜一筹，分布式数据库下租户应该成为一种标配能力，一方面对私有云部署维护管理更加友好，另外对用户而言分布式就是一个无限大的单机数据库不用担心容量跟性能问题，且资源是隔离的。</p><p></p><p>使用了分布式就可以一劳永逸地解决性能、容量问题了？其实不然，该做的数据拆分跟业务架构改造还是要继续做的，主要还是取决于你的业务体量到底有多大。蚂蚁的交易支付系统体量足够大吧，也没有把所有数据都放到一套 OceanBase 集群里啊，同样也是将业务拆分（蚂蚁的单元化架构）到多集群的（俗称百库百表）。当然这是个极端的例子，如果对一个百万订单的系统那兴许就不用了，或者更低一点的业务量还要啥分布式啊，单机数据库就挺好的。</p><p></p><h2>对比总结</h2><p></p><p>通过对三种形态的分布式数据库对比，针对可用性、一致性、容量、性能、维护、容灾、HTAP 的支持上做了一下简单总结，毕竟不管什么类型的数据库最终还是要回归到数据库的本质。需要说明的是下表不具有选型倾向性，只是理念的不同带来风格的迥异并无高下之分。</p><p></p><p>中间件方案是历史的产物也有它存在的道理，长期看一定会被淘汰，只是周期会比较久（可能分布式数据库云化能加速升级进度），短期内仍旧是中小互联网公司的首选方案，毕竟相对简单一些。</p><p></p><p>也没有万能的数据库，上面介绍的分布式数据库还是以解决 OLTP 为主的，并不适合解决所有场景需求，比如 json、图、kv、cache、schemaless、dt 等场景的需要还是要使用特定类型的数据库。</p><p></p><h2>选型技术之外的考量因素</h2><p></p><p>即使通过上述简单的对比，选择依据似乎还不够。还要从如下几个方面进行考虑。</p><p></p><p>1. 成熟度。</p><p>一款数据库成熟度怎么样可以从历史版本发布情况来简单分析，如果频繁的大版本发布及小版本修复各种致命 bug、缺陷等，显然不能被一般外部用户接受。以 MySQL 为例，2005 年 MySQL 5.0 发布到今天 MySQL 8.0 成熟经历了 17 年，其中 MySQL 8.0 从 2016 年发布到今天一个版本的稳定打磨就经历了 7 年，数据库注定是要十年磨一剑的。</p><p></p><p>2. 标杆应用。</p><p>在业内是否被大规模验证过了，或者有标志性的成功案例。很多国产数据库目前整体还是闭塞的虽然号称在金融、电信、银行、保险等领域上线了，但实际情况怎么样完全不得而知，尤其互联网公司崇尚的是开源这一类的数据库很难被接受。</p><p></p><p>3. 技术底蕴 &amp; 背后的团队</p><p>所谓大厂出品必属精品，随便一个什么公司搞一个数据库是很难被接受的。大家普遍认可业内顶尖的一流公司做背书的产品，甚至在深入了解一下开发这款数据库的团队靠谱吗？毕竟数据库的复杂度堪比操作系统，要求非常高，甚至团队规模怎么样，不要指望百十人的团队能写出靠谱的数据库（KPI 产品例外）。当然中间件方案的分布式例外，毕竟核心是做 Proxy，复杂度远不在一个数量级上。</p><p></p><p>4. 生态。</p><p>生态主要看技术、人才、文档、服务这四方面。</p><p></p><p>技术方面，业务接入的改造是否低成本，或者说是否能复用成熟的生态(比如 TiDB 和 OceanBase 都是完整支持 MySQL 协议的)，是否足够开放让社区或者相关从业人员尽可能参与进来？比如 TiDB 这方面做的就很好。周边生态工具是否齐全，比如业务研发高频使用的 IDE 工具，DBA 更加关心的一些技术接口或者现成的实用运维工具等。</p><p></p><p>人才方面，市场是否有足够数量的从业人员如 DBA。</p><p></p><p>文档方面，此前国产数据库整体上文档完整性比较弱，现在好很多了，不过整体文档水平跟 MySQL 这样的开文档比还有差距，很明显的感受是：告诉你怎么用，很少告诉你为什么或者原理性的东西比较少，可能是写文档的同学不是内核研发。</p><p></p><p>服务方面，国产数据库的诞生有现实的需求，但整体相比传统商业数据库成熟度还不够，因此需要更好的售后服务及支撑体系才能弥补整体的不足。分布式数据库未来上云是个大方向，毕竟对绝大部公司而言是很难有人力跟能力去驾驭一个复杂的、成熟度有待打磨的产品。</p><p></p><p>5. ROI</p><p>主要看引入分布式要解决什么问题，如果是成本，很不幸小范围引入分布式数据库可能成本会更高！毕竟相比单机数据库，分布式数据库普遍对硬件成本要求非常高，比如 TiDB 和 OceanBase 都有很高的硬件要求（OceanBase4.0 小型化后改观很多）。如果是性能优化那更不幸，通常 benchmark 可能跑不过单机数据库！分布式数据库的整体收益只能在达到一定规模后才能发挥出成本、性能优势。因此，如果只是某个单一场景引入分布式来解决可能不是太好的选择。</p><p></p><p>关于 ROI 可以简单的比喻：分布式是卡车，拉的多跑的慢，单机数据库是轿车拉的少跑的快，因此要有个平衡。最后引用一句话:“过早的优化是万恶之源”。</p><p></p><p>6. 兼容性验证</p><p>虽然很多数据库都号称 100%兼容 MySQL 等协议，但还是要以自己的实际验证结果为准（99.99%的兼容跟 100%的兼容对结果的影响是巨大的）。起码你要有 SQL 流量回放能力来验证执行计划跟执行效率的差异吧。此外，对于能否平滑迁移，成熟的产品往往有一套完整的解决方案，要考虑上线后你真的能驾驭它吗。</p><p></p><p>最后的最后，也在最初的最初，我们要考虑的是：真的需要分布式数据库吗？</p><p></p><p>作者简介：</p><p></p><p>蔡鹏，拥有十多年 DBA 工作经历，曾就职于饿了么、蚂蚁集团，现任货拉拉数据库部门负责人，负责数据库、缓存，消息队列的管理与平台研发工作。</p>",
    "publish_time": "2023-03-10 17:46:45",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]