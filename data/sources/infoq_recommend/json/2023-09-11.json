[
  {
    "title": "用户突破4亿！腾讯会议接入混元大模型",
    "url": "https://www.infoq.cn/article/dVusdTArjZDRQ1dwL8wo",
    "summary": "<p>9月8日，2023腾讯全球数字生态大会上，腾讯会议宣布已接入腾讯混元大模型，并发布腾讯会议AI小助手。同时，基于腾讯会议身份管理功能发展而来的企业身份管理产品——腾讯统一身份 Tencent OneID也正式对外亮相。</p><p>&nbsp;</p><p>腾讯会议同步对外宣布了阶段性成果：用户数突破 4 亿，自上线以来服务超过25亿次在线协同，付费用户数同比提升5倍。截止目前，腾讯会议已经开放了覆盖会议邀约、会中管理、会后沉淀等全流程超300个API接口，数千家企业组织基于腾讯会议开放提供的API接口，进行行业解决方案打造，日均调用次数过千万。此外，腾讯会议伙伴已经超过了300家，比去年增加了2倍，今年上半年腾讯会议代理收入同比增长200%。</p><p>&nbsp;</p><p>腾讯集团副总裁、云与智慧产业事业群COO、腾讯云总裁邱跃鹏表示，进入大模型时代，协同办公与大模型技术有天然契合度，大模型应用带来了切实的协同效率和生产力提升。</p><p>&nbsp;</p><p>邱跃鹏提到，协同办公是大模型最先落地的场景。云视频会议作为协同办公的核心场景之一，有了大模型的技术支撑，将实现会前、会中、会后全流程的体验重塑。“我们希望大模型加持的产品，成为生态共赢的有力抓手。”</p><p>&nbsp;</p><p>据悉，腾讯会议上线时已经有大量基于音视频降噪的AI技术应用，包括现在常见的虚拟背景等。</p><p>此次发布的腾讯会议AI小助手由腾讯混元大模型提供支持，与会者只需要通过简单自然的指令，就可以完成信息提取、内容分析、会管会控等多种复杂任务。会前，AI小助手能进行材料准备，会中可帮助与会人快速抓取重点信息，会后还能自动生成智能总结摘要。目前AI 小助手已开放预约体验。</p><p>&nbsp;</p><p>腾讯会议还推出了国内首个裸眼3D视频会议功能。腾讯会议表示，有效解决了在传统的人像识别，特别是3D重建过程中的边缘抖动问题。此外，腾讯会议裸眼3D效果同时具备双目视差和移动视差，在直播带货、立体教学等场景中都可以应用这个功能。</p>",
    "publish_time": "2023-09-11 09:31:53",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "前端遗留技术与现代功能的对抗，邮件开发注定是件苦差事",
    "url": "https://www.infoq.cn/article/fXgLBKTQAX4uZtLoxzd3",
    "summary": "<p>首先，如果大家点进来的原因是厌烦了开发邮件系统，请允许我先对各位的悲惨遭遇表达最诚挚的慰问。</p><p>&nbsp;</p><p>说说结论，我认为邮件系统的开发可以说是能在笔记本电脑上完成的、最恶心的工作，没有之一。我们做的一切似乎都没有意义，只能像疯子一样反复测试一切，那种感觉跟清理浴室地板上莫名其妙的顽固污渍倒有几分相似。</p><p>&nbsp;</p><p>总之，希望文章接下来的内容能帮大家厘清整个混乱的局面，提供一点有用的建议，特别是让您在绝望中找到一丝活下去的勇气。</p><p>&nbsp;</p><p></p><h2>邮件开发是干啥的？</h2><p></p><p>&nbsp;</p><p>理论上讲，邮件系统的开发其实跟网站开发应该比较相似。电子邮件在本质上只是个HTML文档，跟网页一样，只不过是在邮件客户端、面非网络浏览器中呈现视觉效果。但除此之外，二者都能渲染，也就是把HTML代码转换成文本、图形和图像——即内容的可视化。</p><p>&nbsp;</p><p>其实在2005年那会，网站和邮件系统的开发其实非常相似。浏览器和邮件客户端会以几乎相同的方式呈现HTML，而且功能也相差不大。但是，尽管Web标准不断发展且持续入驻网络浏览器，但邮件客户端这头却似乎陷入了时停——至今无甚变化。</p><p>&nbsp;</p><p>如今，我们在开发网站时可以支持各种酷炫且高效的功能，比如网格、Flexbox、夜晚模式、过渡，而且所有主要浏览器都能兼容。但另一方面，这些功能在邮件客户端中则分以下三种情况：</p><p>完全不受支持；无法按预期工作；在某些邮件客户端中无法兼容。</p><p>&nbsp;</p><p>所以，如果大家希望一定比例的用户（至少得有95%吧）能按预期查看邮件内容，那就只能坚持使用最基本的HTML和CSS功能。而且即使这样，成功率也不是100%……</p><p>&nbsp;</p><p>而且更离奇的是，如今Web开发中最糟糕的实践竟然仍是邮件开发中的最佳实践。下面，就让我们一探究竟。</p><p>&nbsp;</p><p>首先，如果大家点进来的原因是厌烦了开发邮件系统，请允许我先对各位的悲惨遭遇表达最诚挚的慰问。</p><p>说说结论，我认为邮件系统的开发可以说是能在笔记本电脑上完成的、最恶心的工作，没有之一。我们做的一切似乎都没有意义，只能像疯子一样反复测试一切，那种感觉跟清理浴室地板上莫名其妙的顽固污渍倒有几分相似。</p><p>总之，希望文章接下来的内容能帮大家厘清整个混乱的局面，提供一点有用的建议，特别是让您在绝望中找到一丝活下去的勇气。</p><p>&nbsp;</p><p></p><h2>为什么要用&nbsp;元素?<p></p><p>&nbsp;</p><p>邮件开发最让人头痛，当数其中大量使用到table元素，以及永无止境的</p>和和122个<table><tbody><tr><td>字符串。但是，为什么会这样？<p></p><p>&nbsp;</p><p>根据相关文献的解释，微软Outlook使用着与Word相同的渲染引擎。也就是说，在Outlook中打开电子邮件基本上相当于在Word中打开文档，所以我们得先摆正思路——手头开发的并不是电子邮件，而是Word文档。</p><p>&nbsp;</p><p>有朋友可能会想，“不会吧，Word里可没有多少布局和样式工具……”说得没错！但它有table，而且只有table。所以任何想要正确实现可视化的内容都必须是table。没有其他办法了，请大家收下这份表格大礼。</p><p>&nbsp;</p><p>为了证明这一点，以下是苹果发送的现代电子邮件被粘贴进微软Word 2013后的样子：</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/c9/c93855d6bc13c24d55692e56d8237a19.png\" /></p><p></p><p>微软Word 2013中打开的苹果发票邮件</p><p>&nbsp;</p><p>神奇吧，这格式多么规整。而之所以能这么规整，是因为邮件的HTML中包含75个</p></td></tr><tr><td>。看看HTML格式，就知道内容有多乱了。<p></p><p>&nbsp;</p><p></p><h2>为什么要使用内联样式？</h2><p></p><p></p><p>跟常规HTML文档一样，电子邮件也可以具有CSS样式。如果各位朋友足够理智，肯定会想到把它们放在文档的标记当中。根据“如何开发邮件……”支持页面中的和</p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/af/afe884319b4de11fdbce9f1efbe5aeec.png\" /></p><p></p><p></p><p></p><p></p><p><a href=\"https://dodov.dev/blog/why-does-email-development-have-to-suck/email-inline-styles.html\"></a></p><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f0/f0ac6d5c8e9e94c4d8500f867c87021f.png\" /></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><h2></h2></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/25/2528d10956a511450679feb334950c83.png\" /></p><p></p><p></p><p></p><p></p><p></p><p><h2></h2></p><p></p><p></p><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/69/698d3f6cadcba367af09abaa455d0a85.png\" /></p><p></p><p></p><p></p><p></p><p></p><p><h2></h2></p><p></p><p></p><p></p><p></p><p></p><p></p><p><h2></h2></p><p></p><p></p><p></p><p><img /></p><p></p><p><img /><span><a href=\"https://www.caniemail.com/features/css-display-none/#display-none-cite-note-2\"></a><a href=\"https://www.caniemail.com/features/css-at-media/#media-cite-note-1\"></a></p><p></p><p><code lang=\"null\"></code></p><p></p><p></p><p><code lang=\"null\"></code></p><p></p><p></p><p></p><p><h2></h2></p><p></p><p></p><p><table><td><td><a><a></p><p></p><p><code lang=\"null\"><a href=\"\" style=\"color: inherit; text-decoration: none;\"></a></code></p><p></p><p></p><p></p><p><code lang=\"null\"><ul style=\"margin: 0 0 0 18px; padding: 0;\"><li style=\"margin-bottom: 24px;\"></li><li style=\"margin-bottom: 24px;\"></li><li style=\"margin-bottom: 0;\"></li></ul></code></p><p></p><p></p><p></p><p><h2></h2></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><code lang=\"null\"></code></p><p></p><p><tr><td></p><p><a href=\"https://www.joshwcomeau.com/react/wonderful-emails-with-mjml-and-mdx/\"></a></p><p></p><p><h2></h2></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><h5></h5></p><p><a href=\"https://dodov.dev/blog/why-does-email-development-have-to-suck\"></a></p><p></p><p><h5></h5></p><p><a href=\"https://xie.infoq.cn/article/8f7976ab813eb2897f6feded9\"></a></p><p><a href=\"https://www.infoq.cn/article/2FhPNEatO5kkR7jeIsU5\"></a></p><p><a href=\"https://xie.infoq.cn/article/11fae95025c6909f50ba5fdfd\"></a></p><p><a href=\"https://www.infoq.cn/article/mNfTT4UBk5PQl3JpNt6M\"></a></p></p></td></tr></tbody></table></h2>",
    "publish_time": "2023-09-11 10:34:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "智谱 AI 最新估值突破100亿元；红杉减持美团，迄今套现超500亿港币；消息称9月30日前，阿里云将关停代销业务 | AI一周资讯",
    "url": "https://www.infoq.cn/article/AGirUVdTebuhGKLHvR0a",
    "summary": "<p></p><h2>资讯</h2><p></p><p></p><h4>红杉“清仓式”减持美团 套现迄今已超500亿</h4><p></p><p>据港交所权益披露资料显示，8月31日，红杉中国减持美团-W股票，持股比例由2.32%降至1.86%，交易均价为129港元/股，共减持2635万股，涉资约34亿港元。</p><p>&nbsp;</p><p>截至9月7日收盘，美团报收125港元/股，总市值为7804亿港元。今年以来，美团股价回调28.45%。自2021年2月高点，美团股价合计回调近70%。</p><p>&nbsp;</p><p>美团招股书显示，红杉中国在2006年就成为了大众点评的A轮投资人。4年后，红杉中国成为美团的A轮投资人。此后，红杉中国参与了每一轮融资。2018年9月，美团登陆港股，红杉中国的持股比例为12.05%。</p><p>&nbsp;</p><p>据港交所披露易显示，自2019年二季度以来，红杉中国就通过出售股份或派股给LP持有等方式，逐步减少在美团-W的持股。尤其是进入2021年后，美团市值大涨，红杉中国进一步加快了减持步伐。当年十余次减持共套现超300亿港元。截至目前，红杉中国在美团的持股比例已经降至1.86%。</p><p>&nbsp;</p><p>据测算，自美团上市以来，红杉资本先后套现已逾500亿港元。</p><p></p><h4>消息称9月30日前，阿里云将关停代销业务</h4><p></p><p>据雷峰网独家报道，阿里云将会在今年9月30日前全面关停代销业务。</p><p>&nbsp;</p><p>所谓代销业务，这是云厂商分销体系中的一个细分分支，其核心销售逻辑是，云厂商给渠道一个折扣，渠道承诺保底，然后渠道通过自己的平台，让客户下单。对客户的折扣设置、客户的合同签订都是由渠道决定。</p><p>&nbsp;</p><p>这种合作模式有点像支付宝与运营商合作充话费。假设一开始支付宝和运营商谈好，给支付宝8折优惠，然后支付宝在自己平台上线交话费功能，至于支付宝给多少折扣给客户这都是由支付宝决定，如果给9.5折给客户，那客户付95元就可得100元话费，最后支付宝则按照约定折扣，转80元给运营商。</p><p>&nbsp;</p><p>过去，鹏博士集团、神州数码、佳杰、长虹佳华等都是阿里云的代销骨干代表，为阿里云业绩作出了不小的贡献。而此次阿里云为何要全面关停代销业务？在阿里云给出的公告中，暂时未表明原因。</p><p></p><h4>马斯克更新隐私政策表明将使用用户数据训练AI模型</h4><p></p><p>社交平台X近期更新了隐私政策，表示会收集用户的生物特征等信息，以及利用所收集的数据和公开信息来帮助训练机器学习和AI模型。分析认为，此举可能是XCEO马斯克为其另一家AI公司xAI准备训练数据。</p><p>&nbsp;</p><p>马斯克此前曾表示，xAI会使用公开推文进行模型训练。他基本证实了这一举措，但表示只会使用公开数据，不会涉及私人信息。X的这一政策更新引发关注，担忧个人数据隐私不被充分保护。</p><p></p><h4>WPS&nbsp;AI正式开放，智能文档首发体验</h4><p></p><p>日前，金山办公宣布自主研发的AI产品WPS&nbsp;AI正式面向社会开放，首先集成到旗下的智能文档产品中。用户可以在WPS客户端和小程序体验智能文档的内容生成、表达优化等AI能力。</p><p>&nbsp;</p><p>金山办公还提供了多种模板，让用户快速体验智能文档的AI功能。未来，更多WPS&nbsp;AI能力将陆续开放。</p><p>&nbsp;</p><p>WPS&nbsp;AI的推出标志着国内Office软件开始拥抱AI技术。在线文档处理是重要的办公场景，AI的加入可以实现更智能高效的内容协作和优化。这一举措有望推动Office软件的智能化升级，也将促进我国AI技术在更广泛的办公领域的应用。</p><p></p><h4>ChatGPT&nbsp;Plus推出Canva插件&nbsp;可生成个性化图像视频</h4><p></p><p>ChatGPT&nbsp;Plus最近推出了一个Canva插件，用户只需文本描述,就可以利用Canva的现有模板快速生成设计、图片、视频等视觉内容，实现个性化的语言到图像转换。使用步骤包括安装插件、向ChatGPT提交请求、选择模板、在Canva调整并下载。这一创新插件将ChatGPT的语言生成能力与Canva的丰富模板库进行了有效结合，使AI内容创作更为简单、专业。</p><p>&nbsp;</p><p>Canva插件不仅丰富了ChatGPT&nbsp;Plus的功能，也为其商业化带来了新的可能。利用已有设计资源使语言模型输出内容更具个性和实用性，是提升用户体验的重要手段。这也使ChatGPT拥有了强大的视觉内容创作工具。</p><p></p><h4>腾讯正式发布千亿级大模型“混元”</h4><p></p><p>腾讯在2023腾讯全球数字生态大会上正式发布了混元大模型，该模型具有千亿参数规模和超过2万亿的预训练语料。目前，混元大模型已经成功在50多个腾讯业务和产品中进行测试，取得初步效果。</p><p>&nbsp;</p><p>混元大模型不仅为产业场景提供服务，还提高了逻辑思维能力，拒绝回答难题，并在处理超长文本方面表现出色。腾讯混元助手作为其中一项应用，展示了强大的多功能能力，包括AI问答、AI绘画等。目前，该工具需要受邀用户才能使用，尚未提供大规模测试。</p><p></p><h4>IBM推出新AI模型和工具</h4><p></p><p>IBM近日在其Watsonx数据科学平台上发布了Granite系列AI模型，这些模型类似于GPT-4和ChatGPT，具备文本分析和生成功能。虽然细节不明，但IBM承诺将在Q3&nbsp;2023发布这些模型之前公开有关数据训练和处理的信息。</p><p></p><p>Granite系列模型是通过企业级数据训练而成，包括专注于不同领域的子模型，如金融。它们支持各种企业自然语言处理任务，如摘要、内容生成和见解提取。</p><p></p><p>此外，IBM还引入了Tuning&nbsp;Studio工具，允许用户根据其数据自定义生成式AI模型，以适应新任务。Watsonx.ai即将推出合成数据生成器，以降低AI模型训练的风险。</p><p></p><h4>阿里云合作重庆首发城市运行和治理AI大模型</h4><p></p><p>阿里云与重庆市政府合作发布了首个城市运行和治理大模型，这一合作旨在推动数字经济和智能产业的高质量发展。该大模型基于阿里云通义技术，利用数字重庆积累的数据资源和创新场景，建立国家级新一代人工智能公共算力开放创新平台。此举标志着城市治理领域也开始受益于大模型技术的应用。</p><p>&nbsp;</p><p></p><h2>IT业界热评新闻</h2><p></p><p></p><h4>智谱 AI 最新估值突破100亿元</h4><p></p><p>9月7日，据AI科技评论独家报道，智谱 AI 最新估值已经超 100 亿人民币，最高或达到 150 亿，是国内估值最快超过百亿人民币的公司之一。</p><p>&nbsp;</p><p>创立至今，智谱 AI 先后完成多轮融资：2021 年完成 A 轮过亿元融资，由达晨财智、华控基金、将门创投、南京图灵、北京达凡；2022 年 9 月，由君联资本和启明创投联合领投的B 轮融资、金额为 1 亿元；今年 7 月，美团战投领投完成 B-2 轮融资，金额达到上亿美金，投后估值为 5 亿美金。</p><p>&nbsp;</p><p>智谱 AI 成立于 2019 年 6 月，由清华大学计算机系知识工程实验室的技术成果转化而来，团队核心成员曾参与清华大学与智源研究院合作项目 \" 悟道 \" 的研发工作。</p><p>&nbsp;</p><p>2022 年 8 月，智谱 AI 发布高精度双语稠密千亿大模型 GLM-130B，主导构建了高精度通用知识图谱，把两者有机融合为数据与知识双轮驱动的认知引擎，并基于此千亿基座模型打造 ChatGLM。同年 11 月，据斯坦福大学大模型中心对全球 30 个主流大模型进行全方位评测后，智谱 AI &nbsp;GLM-130B 成为亚洲唯一入选的大模型。</p><p>&nbsp;</p><p>今年 3 月，智谱 AI 开源 GLM 系列模型的新成员——中英双语对话模型 ChatGLM-6B，可支持在单张消费级显卡上进行推理使用。受 LLaMa 2 的冲击下，此前有传闻称智谱也将开源它们的 GLM-13B 百亿大模型，免费开源可商用。</p><p>&nbsp;</p><p>一位接近智谱 AI 人士告诉 AI 科技评论，智谱 AI 团队已坚定 To B 路线，当前的业务中心瞄准了信创市场，正在快速扩建团队中，自 5 月份至今，人员规模已从 200 人增至 500 余人，预计于今年年底扩张至 1000 人，属于所有大模型创业公司中人员规模最大的一家。</p>",
    "publish_time": "2023-09-11 10:36:26",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "InfoQ新知实验室：探寻旭阳数科与用友的“1+1>2”",
    "url": "https://www.infoq.cn/article/OzIHxCbbibaIdAvYvh13",
    "summary": "<p>《 “十四五”规划纲要》曾多次提到“产业数字化”和“数字产业化”这样的概念，在这样的背景之下，数科公司实际上是一个不容忽视且极为重要的角色和纽带。尽管数科公司对数智化转型起到了重要的促进作用，但外界对它的了解却并不多，这也使数科公司与一众互联网公司相比，多了几分神秘的色彩。</p>\n<p>聚焦数智化转型的时代命题，数科公司具体承担着怎样的职责？在服务上游集团企业时，他们遇到过哪些发展痛点？又沉淀出了哪些赋能行业数智化的实战经验 ？本期《InfoQ 新知实验室》有幸邀请到了北京旭阳数字科技有限公司总经理郗维宝以及用友网络副总裁罗小江，我们希望通过拆解旭阳数科服务集团企业的案例，逐步找到上述问题的答案。</p>",
    "publish_time": "2023-09-11 10:53:32",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "中国工商银行大数据和人工智能实验室 / 部门经理袁一确认出席 FCon ，分享工商银行大数据平台助力全行数字化转型之路",
    "url": "https://www.infoq.cn/article/D62XPwdjUk7IGEFlCAF2",
    "summary": "<p><a href=\"https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle\">FCon 全球金融科技大会</a>\"，将于 11 月在上海召开。中国工商银行大数据和人工智能实验室 / 部门经理袁一将发表题为《<a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5525?utm_source=infoqweb&amp;utm_medium=article\">工商银行大数据平台助力全行数字化转型之路</a>\"》主题分享，介绍实时数仓技术在工商银行的技术实践及典型案例、在运营大规模大数据集群和大数据平台在实践信创转型时的经验、在向大数据平台云原生架构演进的实践，以及数据洞察平台（EasyDI）的实施。</p><p></p><p><a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5525?utm_source=infoqweb&amp;utm_medium=article\">袁一</a>\"，从 2011 年开始接触大数据相关技术，从零到一全程参与了工商银行大数据平台的建设，是工商银行大数据技术领域的先行者和技术专家，先后多次在中国信通院、华为金融峰会、Flink Forward Asia 等行业大会上就工行大数据体系的建设发表过公开演讲，发表大数据领域的专利 11 篇。</p><p></p><p>在最近几年里，持续关注行业新技术的动态，并积极引入新技术，成功落地了多个大型项目，包括主机下平台转型、SAS 国产化转型、实时数仓演进、湖仓一体云原生架构演进等，为工商银行的数字化转型工作提供了持续的持和助力。他在本次会议的演讲内容如下：</p><p></p><p>演讲：工商银行大数据平台助力全行数字化转型之路</p><p></p><p>本次演讲，将主要介绍工商银行大数据平台在近几年数字化转型过程中，对大数据平台的使用越来越重，因此立足于解决业务痛点，在近几年里主要推进了如下几项工作：</p><p></p><p>1、业务侧对数据时效的要求越来越高，原先 T+1 已无法满足，而基于 ORC 文件做定时存增量合并的方式资源开销很大，因此引入了 Flink+Hudi 的实时数仓加工模式，并提炼了设计模式，最终使数据加工时效最快达到了 1 分钟级。同步通过 CDC 技术，将主机或 Oracle 等数据库中产生的数据实时地同步到大数据平台，实现业务下主机。</p><p></p><p>2、随着实时数仓技术的不断成熟，工商银行大数据平台逐步将所有数据切换成实时入湖的 Hudi 格式，形成了基于 Flink 开发的实时数仓和基于 Spark 开发的离线数仓的两条并行加工链路，两条加工链路之间数据可以共享，无需冗余存储，同时为配合实时数仓链路中 Flink 中所要关联的维表，工商银行大数据平台根据不同的业务场景，建设了关系型、键值型、多维搜索、时序、空间、向量等多种类型的联机数据库。</p><p></p><p>3、推进大数据平台向存算分离云原生化演进。工商银行大数据平台最大的 Hadoop 集群目前规模近 3000 台物理机，随着集群规模越来越大，在资源隔离、弹性扩缩容等方面的不足越来越明显。因此通过参照互联网企业的做法，开始实践云下存算一体向云原生存算分离架构演进，在此过程中同步推动了数据平台信创转型。</p><p></p><p>4、建设 EasyDI 平台，在 2022 年面向全集团分析师提供了可视化报表开发工具，使报表开发不再依赖于科技。在 2023 年中通过策略模板中心形成了不同分行、不同部室之间用数模式复用的能力，构建了出生态。同时 2023 年 2 季度起正在研究基于生成式大模型技术实现对话式 BI 用数助理的课题，旨在通过 AI 技术进一步降低用数门槛。</p><p></p><p>演讲提纲：</p><p></p><p>实时数仓技术在工商银行的技术实践及典型案例工商银行在运营大规模大数据集群时的若干经验工商银行在向大数据平台云原生架构演进的若干实践工商银行大数据平台在实践信创转型时的若干经验工商银行数据洞察平台（EasyDI）的若干实施</p><p></p><p>你将获得：</p><p></p><p>○ 了解到实时数仓技术在工商银行的技术实践及典型案例</p><p>○ 了解到工商银行在运营大规模大数据集群时的若干经验</p><p>○ 了解到工商银行在向大数据平台云原生架构演进的若干实践</p><p>○ 了解到工商银行大数据平台在实践信创转型时的若干经验</p><p>○ 了解到工商银行数据洞察平台（EasyDI）的若干实施</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle\">DevOps&nbsp;在金融企业落地实践</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle\">金融行业大模型应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle\">创新的金融科技应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle\">金融实时数据平台建设之路</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle\">金融安全风险管控</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle\">数据要素流通与数据合规</a>\"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，前 100 人可享 5 折特惠购票，咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png\" /></p><p></p>",
    "publish_time": "2023-09-11 11:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "华为云印尼联创营CXO-CAMP精彩回顾",
    "url": "https://www.infoq.cn/article/uHcRIePip3V0caFxtaJV",
    "summary": "<p>华为云印尼首届CTO联创营CXO-CAMP 精彩回顾！携手共赴X数字进化，数十位印尼先锋企业领导者齐聚一堂，论道商业与技术的融合演进之路、解锁印尼数字化产业的未来！</p>",
    "publish_time": "2023-09-11 12:20:20",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "富滇银行：中小金融机构如何思考和实现AIGC应用？",
    "url": "https://www.infoq.cn/article/7d4DwesFkH9sMaXYf4pa",
    "summary": "<p>嘉宾&nbsp;|&nbsp;李涛&nbsp;富滇银行数字金融中心副主任</p><p></p><p>大模型的出现从根本上改变了数字化转型的赛道，反之，数字化转型也成为了<a href=\"https://www.infoq.cn/news/jyFfApepG35Agpi6l3hv\">大模型</a>\"智能化应用的基石。</p><p></p><p>为了抓住新风口下的机遇，富滇银行最近已经与技术商展开合作，针对大模型进行 POC（概念验证）相关的工作。经过基础模型和行业模型选择、场景的选择、模型的评估、部署和监控四个关键步骤，在业务、营销、运营、内部管理、科技项目研发流程等多个场景落地 AIGC 应用。</p><p></p><p>“当然，很多工作目前仍处于探索阶段。特别是在金融生产级别的应用，我们仍然有很长的路要走。”</p><p>在 InfoQ《<a href=\"https://www.infoq.cn/theme/192\">超级连麦. 数智大脑</a>\"》直播中，<a href=\"https://www.infoq.cn/article/9FRdGfIdRe3OIoygTBrt\">富滇银行</a>\"数字金融中心副主任李涛深入探讨了自身对于 AIGC 在金融领域创新方面的思考，同时也分享了银行数字化发展的历程及背后的架构演进，以及智能技术在金融领域的发展现状。</p><p></p><p>以下是分享全文（经 InfoQ 进行不改变原意的编辑整理）（<a href=\"https://www.infoq.cn/video/k0QUqSaEI4Hxbb4V94hZ\">点击链接</a>\"可查看完整直播回放）：<a href=\"https://www.infoq.cn/video/k0QUqSaEI4Hxbb4V94hZ\">https://www.infoq.cn/video/k0QUqSaEI4Hxbb4V94hZ</a>\"</p><p></p><h2>银行数字化发展历程及背后的架构演进</h2><p></p><p></p><p>银行的数字化发展历程可以分为四个阶段：第一个阶段是人工和手工时代；</p><p></p><p>第二个阶段是信息化时代，它主要解决了流程性问题。在这个阶段，数据是软件系统的附属产物，对数据的重视程度较低，流程、业务和合规是该阶段的中心。</p><p></p><p>第三个是数字化时代，数据成为了生产的重要组成部分，流程和软件系统是该时代的核心工具。该时代的特点是以业务价值为中心，驱动数字化进程的发展。</p><p></p><p>第四个阶段称为数智化时代。这个时代伴随着大型语言模型如 ChatGPT 的出现，为银行业带来了全新的机遇。数智化时代的主要特征是以用户价值为核心，真正将数字化进程融入业务中。这标志着数字化发展进程的新篇章。</p><p></p><p>在这个过程中，银行的 IT 架构持续演进，相对应地也分为四个阶段。</p><p><img src=\"https://static001.geekbang.org/infoq/e2/e243709f0f493549b1767078f29b6996.png\" /></p><p>第一个阶段是单体式架构，以核心系统为代表，逐步过渡到第二阶段，即分布式云优先架构。此时，“云优先”的理念逐渐崭露，尽管中小型银行对云服务的适用性存在疑虑，但也在为将来的数字化和云端部署做准备。这一阶段持续时间较长，也是银行同质化问题最为严重的阶段，的特点是以产品为中心，衍生出产品即服务的商业模式。</p><p></p><p>到了第三阶段，基于私有云的大数据架构成为主流。中小型银行借鉴大型银行的经验，进行架构的迭代升级，特点是计算和服务的重要性逐渐凸显。</p><p></p><p>最终，进入第四个阶段，以大型模型在特定领域的深度应用为核心。银行不得不走出自身的舒适区和生态圈。在这个时代，涌现出私有 AI、混合 AI 和混合云的模式，成为智能在线的时代。</p><p></p><h4>富滇银行的一体两翼双态架构</h4><p></p><p></p><p>如下图，当前，中小型银行数字化转型呈现出一体两翼、双态的特征，“一体”代表着信息化和数字化的双重状态，而“双态”则体现了稳态和敏态。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2d/2db61e6e8a1a68fe81d2f700073ced66.png\" /></p><p></p><p>在稳态方面，我们专注于解决金融产品全面支持能力的问题。同时，致力于提升银行的信息化水平，取代手工操作，从而将更多人力资源释放到营销领域，减少操作风险。同时，我们也要确保适应监管合规的要求。这一阶段的关注点主要是确保银行的生存。</p><p></p><p>而在敏态方面，我们着眼于解决银行的持续发展问题。通过数字化手段，以用户为中心，对银行业务价值、流程和组织架构进行重塑和变革。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/df/df3311bc1d744096ec29dc021614e4c2.png\" /></p><p></p><p>基于这一战略，富滇银行构建了一体式架构，上图展示了我们的双态架构。在架构的右边，我们有 ESB 作为稳态，建立在核心为中心的信息化系统上，用于流程传导；在内联网关的左边作为敏态，采用薄前台、厚中台和敏后台的一体式架构应用。</p><p></p><p>在这个架构中，业务中台、数据中台和 AI 中台三大中台能力支持全面数字化的应用。然而，大模型的出现彻底改变了 AI 中台在三大中台中的角色。目前，根据我们的战略规划，AI 中台的地位可能会超越其他两个。</p><p></p><h2>智能技术在金融领域发展历程和现状</h2><p></p><p></p><p>关于智能技术在金融领域发展的历程，同样也经历了四个阶段。</p><p></p><p>第一个阶段是手工阶段，靠面对面沟通和手工查账。</p><p></p><p>第二阶段是表格检索和呼叫中心阶段，这个阶段从 1996 年开始，引入了人工坐席和移动互联网业务，但智能化程度相对较低，主要依赖经验和简单的在线查询服务。</p><p></p><p>第三阶段人工智能阶段，从 2012 年开始至今。在这个阶段中，出现了智能客服、数据营销、外呼机器人等应用。这些能力主要基于 NLP（自然语言处理）和语音识别等核心算法，但大部分还是以人工配规则的方式实现，形成了所谓的规则型智能。</p><p></p><p>目前，我们处在第三到第四阶段的转变过程中。2022 年，大模型的出现以及基于多模态和上下文理解的生成式人工智能的兴起，将银行的智能化发展推向了另一个层面。可以说，去年，我们还在研究如何更好地利用 NLP 技术为行内外用户提供服务，而今年，我们提到的各种数字人、NLP 等技术都成为了大模型上层应用的工具，这标志着发展的新趋势。</p><p></p><p>智能客服</p><p><img src=\"https://static001.geekbang.org/infoq/24/249e69f52bf76da4cb63a35746435d6a.png\" /></p><p></p><p>在金融行业的现状中，特别是在中小银行领域，智能化的发展趋势相似。这张图展示了一个典型情况，左边是常见的问答式机器人，也就是智能客服，右边是一些银行引入的数字人。基于这两种能力，我们通过以下五种方式提供智能化服务。</p><p></p><p>FAQ 问答：这种能力提供了常见知识类查询的服务。任务式问答：它支持多轮对话，能够处理复杂的条件和集成服务参数。表格问答：基于数据和表格的问答，可以处理条件和数据查询。知识图谱问答：这种能力可以应对多跳逻辑和推理性问题。文档问答：通过机器对文档的阅读和检索，实现文档相关的查询。</p><p></p><p>通过这五种方式以及智能间距，再加上一些自动化工具，我们构建了现在智能客服的智慧水平，同时也涵盖了数字人和智能员工的应用。</p><p></p><p>机器人矩阵</p><p><img src=\"https://static001.geekbang.org/infoq/a3/a3ae584878199bdf4905e05c60465272.png\" /></p><p></p><p>另一个领域涉及到一些银行正在研究的多机器人矩阵。通过整合 PRA 和 NLP 等技术，构建了一个机器人矩阵，在矩阵中，包括了智能客服机器人、智能管理机器人、智能稽核机器人、智能外呼机器人以及智能助手机器人等，可以提升客户服务和内部效率的标准能力。</p><p></p><p>规则型智能</p><p><img src=\"https://static001.geekbang.org/infoq/17/17bfed988f625fbe60fe666b78a8ed46.png\" /></p><p></p><p>上面这幅图展示了我们目前基于规则型的智能化设置，以贷款外呼为例：在图中，我们可以看到贷款外呼的情况被分成多个条件，每个条件又有不同的分支。通过数据回流模型的训练和不断的迭代，我们基于这些分支形成了目前的基础规则，支撑了基于规则的人工智能能力。</p><p></p><h2>AIGC 在金融领域的创新思考</h2><p></p><p></p><p>通用大语言模型的出现从根本上改变了数字化转型的赛道。也可以说，数字化转型成为了大模型智能化应用的基石。</p><p></p><h4>AIGC 在金融领域的应用模式</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/97/97f363c9d6b8ad2344812237a30b63d9.png\" /></p><p></p><p>近期，我们也计划与一些厂商合作，进行一些 POC（概念验证）方面的工作。上图展示了我们根据现有情况所判断出的应用模式。从客户端的角度来看，用户会提出问题，然后生成式智能会负责回答这些问题。从应用的角度来看（图右侧），通用大语言模型会负责进行海量知识的训练，也就是注入基础知识。</p><p></p><p>在图中的金融行业数据连接这一部分，我们训练出了金融行业的模型，也就是所谓的垂直领域行业模型。在这个垂直领域行业模型上，我们将银行内部的数据连接起来，进行场景模型的训练。</p><p></p><p>其中这三个环代表了三种模型，从通用模型到行业模型再到专业模型。然后我们通过提示工程，包括指令微调、监督微调和人类反馈强化学习等方法，不断提升生成文本的质量。这个提示工程包括 FTF、SFT 和 RLHF，用来提高生成文本的质量，从而更好地为客户提供服务。</p><p></p><p>在这个过程中，微调技术能够针对特定业务场景的要求，优化模型的回答生成能力，使生成的回答更加准确、流畅和相关。</p><p></p><p>通过微调，模型能够更好地理解输入对话的上下文信息，捕捉到对话中的语义和逻辑关系，从而生成更具连贯性和相关性的回答。这使得模型在各种自然语言处理任务中表现出更高的性能，如问答系统、客服机器人、智能对话系统等。</p><p></p><h4>AIGC 在金融领域落地步骤</h4><p></p><p></p><p>在将 AIGC 应用于金融领域的落地过程中，我们考虑了以下四个关键步骤。</p><p></p><p>第一步是选择基础模型和行业模型。对于中小银行和金融机构来说，自行训练大型模型（如 Meta 或清华的 GLM）成本非常高昂。因此，我们更倾向于选择国内通用模型，如通义、盘古、混元、文心等，在其基础上对金融行业进行训练，形成垂直领域模型。</p><p></p><p>第二步是根据银行的客户服务场景选择适当的场景。在选择场景后，我们会将银行相关的知识嵌入到模型中，并进行微调。通过不断的提示工程微调、训练等手段，提升模型回答的准确性。</p><p></p><p>第三步是模型的评估。评估主要包括通用模型、垂直行业模型以及产品模型的性能评估。同时，进行 AB 测试以及模型回答的质量评估也是必不可少的，因为通过持续的训练，模型回答才能更好地适应实际业务需求。</p><p></p><p>第四步是部署和监控。对于银行来说，模型一定要进行私有化部署，确保敏感信息不泄露。此外，对于生成式学习模型，我们还需要进行答案价值的监控，因为模型可能根据我们的要求生成答案，但其价值和准确性需要实时监测。</p><p></p><h4>AIGC 在金融领域的应用发展地</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bf/bf53a1e78b90bfbfed9bb215545deca2.png\" /></p><p></p><p>在讲述了方向性内容后，我将更具体地说明我们银行在这一领域的实际应用思路。在业务层面上，我们认为在客服、培训和稽核等方面，可以有许多落地的应用，特别是对数字员工的支持。这主要体现在以下几个方面：</p><p></p><p>首先是智能辅助，既包括人工员工，也包括数字员工。在业务推荐前端、用户风险识别等场景，都可以由 AIGC 来完成。智能客服可以进行对话总结，将对话要点提炼出来，并且在这之后可以通过提供优质的对话样本来不断投喂、训练，使数字员工的回答更贴近人类，更能理解用户的情感和真实意图。此外，还包括质检、抽样质检和执行质检等。</p><p></p><p>对于业务推荐，用户风险识别等，AIGC 可以提供准确的指导，为客户提供更好的服务体验。通过不断的训练和优化，数字员工的回答可以更加自然地与用户交流，并更好地满足用户需求。</p><p></p><p>最后，对于质检方面，AIGC 可以帮助自动检测和校验员工的回答是否准确，从而提高服务质量和效率。同时，通过抽样质检和执行质检，我们可以持续监测模型的性能和回答的质量，确保其与业务要求相符。</p><p></p><p>第二个层面则是实现真正的“千人 N 面”。“千人 N 面”基本上是基于规则的交互式界面，我认为这种交互式的新兴能力将会重构整个银行业的应用程序以及客户互动的方式。未来，可能在明年甚至更早，一些银行的应用程序只会包含一个数字人、一个数字员工。用户可以与其对话，讨论自己需要什么业务，而数字员工可以具体指导业务流程，协助前端填写表单，最终完成业务提交。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9b/9b99e6d72b6e57e12a737b6abc9f177a.png\" /></p><p></p><p>在营销层面，生成文案素材和话术，目前在许多金融机构中已经在应用。我想重点强调的是复杂营销活动的策划，这一过程涉及根据营销活动的目标，对目标人群进行匹配和圈选。根据不同的活动形式和渠道，生成相应的文案素材和话术。例如，在制定营销短信、推送消息，以及智能外呼方面，这些内容都可以由模型生成。根据用户的意愿和投放核销权益的情况配置权益和积分。这些实践在营销领域中具有重要意义。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0c/0cde38329266d5ae580131b788f434f5.png\" /></p><p>在运营领域的应用主要包括运营报告和运营分析的图表。在此，要特别强调用户建模的重要性。无论是针对对话机器还是数字员工，我们都可以通过分析用户的对话回答和查询历史记录，来建立对用户兴趣和偏好的模型。这一模型可以提取用户语言特征信息和关键标签信息，从而更好地理解用户需求和兴趣，形成丰富的用户标签。</p><p></p><p>目前，我们通常将用户进行标记的任务交由团队来完成，同时也依赖一些外部数据的标记。然而，用户建模实际上也是至关重要的一部分。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dd/ddb28e18c3c26f21819b90873e942c8f.png\" /></p><p>内部管理涵盖了知识库的建设，会议纪要的记录，内外部制度合规审查，以确保文档是否符合监管规定。同时还包括报告的自动生成，根据提纲生成各个领域的报告，这也是我们目前正在应用和实施的内容。</p><p></p><p>此外，还涉及整个管理流程的自动化，这可以与机器人流程自动化（RPA）相结合，将各类管理流程进行自动化连接和创新。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6b/6bb7fc35394aa59d310fdcf87ae813c1.png\" /></p><p>在科技和项目研发管理的全流程中，涉及几个关键方面。首先，从产品设计角度来看，我们可以进行产品竞品分析，确定产品设计的关键要点。在这方面，我们已经在应用一些技术能力，如 ChatGPT、通义、文心等。</p><p></p><p>我们也在考虑辅助研发的代码编写，目前还需要进一步研究。在数据模型的构建、经典算法代码示例以及辅助类的创建方面，我们已经开始应用一些编码能力，这也是我们在自己研究编码过程中的一部分。</p><p></p><p>另一个关键点是平台工程，近年来这个领域变得相当热门。整个平台工程可以说从 2022 年开始逐步发展，目前的情况还需要持续观察。从我们的角度来看，我们可以从 SRE（Site Reliability Engineering）的角度出发，逐步改进我们科技研发过程中的痛点，这是我们在科技研发方面的一些思路。</p><p></p><h4>AIGC 应用落地过程中问题与挑战</h4><p></p><p><img src=\"https://static001.geekbang.org/infoq/f6/f61aa17dac3d5aedd99fecd753f0f4e5.png\" /></p><p></p><p>当然，在应用落地过程中还又一些关键问题必须考虑。</p><p></p><p>首先，如何选择合适的模型。对于银行业而言，选择一个经过金融领域参数训练的模型是至关重要的。目前，针对金融领域模型还没有一个统一的评价标准。不过，令人振奋的是，腾讯和信通院在 7 月 28 日开始编制了第一个行业大模型的标准，这是一个积极的信号。</p><p></p><p>模型的选择需要考虑多个维度。第一，需要确定模型是否支持中文。如果选择国内的大模型，我们要看它是否开源，是否支持微调，以及它的模型生态是否完善。最重要的是，我们需要确保模型支持私有化部署。</p><p></p><p>此外，模型的参数规模也是一个重要的考虑因素，特别是在金融领域模型中的参数规模。以阿里的通义为例，它专门训练了一个适用于金融行业的模型，该模型的参数规模大约在 7 个 B 左右。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/99/99e6f22164e05a437dbf1809ac650695.png\" /></p><p></p><p>第二个问题是，应用落地过程中普遍面临的挑战。尽管我们已经进行了许多实践并探索了应用的方法，但实际操作中，要在金融领域构建出生产级别的解决方案，尤其是在客户服务领域，仍然需要很长的路要走。</p><p></p><p>目前，我们主要采用的方法是将行业知识库和产品知识库嵌入到特定的语义模型中，然后通过微调的方式不断训练模型，包括之前提到的指令工程。在这里，我想介绍一种我们采用的微调方法 LoRA，它主要基于行业大模型的底层分支流程进行微调。</p><p></p><p>举个例子，我们可以将线上消费贷款的所有信息，包括合规信息和操作信息，导入到我们的产品模型库中。针对线上消费贷款，它可能涵盖各种类型的贷款，比如消费贷款、经营贷款等。根据不同的贷款业务规则，在相同的主干分支上，我们需要训练多个贷款产品的不同分支。在这种情况下，我们可以通过 LoRA 的方法来实现这种分支的构建。通过在主干分支上设置多个子分支，以支持对不同细分产品层面的用户问题进行回答。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/15/15c27da7039f8c1ced4487b7e7a36d62.png\" /></p><p></p><p>第三个问题，出现在智能技术应用的第三阶段，也就是规则型智能阶段。在这个阶段，我们积累了大量的规则，涵盖了 FAQ、任务、表格、知识图谱和文档等各种类型。那么在这些基于规则的引擎和大型模型之间，如何进行结合？因为它们的底层逻辑不同，对于金融行业来说，如何做出明智的选择？目前，我们正在进行 POC 阶段，实际上也在思考这个问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/25/25b9a0910196a9029a1f59fa8ef6c030.png\" /></p><p></p><p>第四个问题，正如大家所了解的，大语言模型如 ChatGPT 等都基于参数的潜在表示知识，通过概率进行推理和回答。然而，金融领域的回答需要的是准确的、结构化的阶段性过程，这与大型模型的功能有一定的差距。</p><p></p><p>关于这个问题我们进行了深入的研究，目前大家认为比较可靠的解决方法是与知识图谱相结合。在后续的 POC 阶段，我们也会纳入考虑。目前，我们已经开始进行一些企业图谱和活动图谱的结合，以实现更精准的回答。</p><p></p><p>最后，我想谈一下当前整个行业的情况。尽管过去的大半年里这个行业迅猛发展，但实际上许多领域仍处于探索阶段。特别是在金融生产级别的应用，尤其是客户服务方面，我们仍然有很长的路要走。在这个过程中，我们需要专业的知识、专业的人才和专业的技能。这些是我们将要面临的挑战。</p><p></p><p>点击链接下载本次演讲PPT：<a href=\"https://www.infoq.cn/minibook/UootzcUo2C52ZsrFbKaw\">https://www.infoq.cn/minibook/UootzcUo2C52ZsrFbKaw</a>\"</p><p></p><h4>嘉宾介绍：</h4><p></p><p>李涛，富滇银行数字金融中心副主任，富滇银行“滇峰”计划架构设计负责人。具有 19 年金融 IT 架构和敏捷实践经验，曾任职中国工商银行软件开发中心主要从事对私、对公核心业务架构设计和敏捷实践。2015 年加入富滇银行主要担任新一代核心系统建设架构师、项目经理。富滇银行全面数字化转型“滇峰”计划项目架构和产品团队负责人，并牵头负责“滇峰”计划项目组织敏捷改进相关工作。</p><p></p><h4>活动推荐</h4><p></p><p>首届<a href=\"https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">FCon全球金融科技大会</a>\"将于 11 月 19-20 日在上海举办。大会将围绕金融领域数字化转型挑战探索、DevOps 在金融企业落地实践、金融行业大模型应用、创新的金融科技应用、金融实时数据平台建设之路、金融安全风险管控、数据要素流通与数据合规等 10+专题进行交流。</p><p></p><p>目前大会邀请了汇丰科技中国区的代理总经理马国栋、度小满金融数据智能部总经理杨青先、蚂蚁集团副总裁 &amp; 首席技术安全官韦韬博士、恒生聚源总经理吴震操担任大会联席主席。更多嘉宾仍在邀请中......</p><p></p><p>我们诚挚地邀请您加入我们，共同探索金融科技的未来，<a href=\"https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">点击链接</a>\"即可查看全部演讲专题。</p><p></p><p>目前 <a href=\"https://fcon.infoq.cn/2023/shanghai/apply?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">5 折 优惠购票</a>\"，仅限前 100 人，咨询购票可联系：13269078023（微信同手机号）。</p>",
    "publish_time": "2023-09-11 13:52:11",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "转型 AI 先裁员？嫌员工技术转型培训太慢裁掉700多人、花200亿美元收购公司，CEO：老顽固们早晚被淘汰！",
    "url": "https://www.infoq.cn/article/Pz0O9T9r7R9WppXo7jeu",
    "summary": "<p>“在每一个重大转折点，都必须发生演变。”有着四十多年历史的财务软件厂商Intuit也迎来了自己的拐点：转型为一家完全由<a href=\"https://www.infoq.cn/topic/AI\">人工智能</a>\"驱动的软件公司。虽然转型近5年来，Intuit公司一直尝试将AI元素融入业务体系，但其首款独立消费级AI产品Intuit Assist却是刚刚正式亮相。</p><p>&nbsp;</p><p>据悉，Intuit Assist被嵌入进TurboTax、Cerdit Karma、QuickBooks及Mailchimp等产品当中，号称能够处理一切事务，从帮助小规模企业评估捉襟见肘的现金储备、到生成/实施电子邮件营销活动等。这款工具还能向主要依赖工资生活、但偶尔面临意外开支的消费者提供个性化建议。</p><p>&nbsp;</p><p>作为全面转型AI的代表，Intuit 是如何一步步走上这条探索道路的呢？</p><p>&nbsp;</p><p></p><h2>五年前就要 all in 人工智能</h2><p></p><p>&nbsp;</p><p>Intuit 现任首席执行官Sasan Goodarzi已经在这家公司工作了14年。在执掌Intuit公司旗下TurboTax和QuickBooks业务过程中，Goodarzi逐渐意识到一个事实：无论公司投入多少资源来帮助客户打理计税和出入账记录，都不可能获得真正令人满意的结果。因为归根结底，人们根本不想亲自处理这些工作。</p><p>&nbsp;</p><p>“我意识到为客户构建这样的记账报税平台只能算是万里长征的第一步，真正的未来在于把他们彻底从这些麻烦事中解放出来。”他回忆道。</p><p>&nbsp;</p><p>这个想法激励着2019年升任CEO的Goodarzi，掀起大规模战略调整，决意将AI作为业务发展的中心。这项改革包含两项总计耗资200亿美元的重大收购、解雇了数百名员工，并在AI技术领域押下重注。而这个时候，距离AI轰动一时、首次进入全民视野还有几年时间。</p><p>&nbsp;</p><p>在多年发展历程中，Intuit公司向来以与时俱进的探索精神著称。1983年，Intuit推出了Quicken个人财务软件。满足市场需求只是其获得成功的原因之一，毕竟当年与Intuit争夺市场的Flexidraw、VisiCalc等同行如今早已不复存在。而Intuit凭借着不断的自我颠覆顺应着微软Windows、互联网、移动设备等一波波革命性浪潮的洗礼，最终获得了远超同侪的行业生命力。</p><p>&nbsp;</p><p>虽然Intuit拥有积极转型的优良传统，但在Goodarzi于2019年决定将AI作为商业模式的核心之时，不少公司高层仍然表示反对。“当时公司内掀起了一波大讨论。那是五年之前，把AI作为业务中心确实很难想象，迈出这一步确实需要点信念作为支撑。”</p><p>&nbsp;</p><p>而Goodarzi之所以下此判断，决定性因素就是Intuit公司掌握着令人难以置信的数据宝库，而这些数据正是AI模型的训练素材，能帮助Intuit为每位客户提供详尽确切的财务建议。“如果没有这些规模庞大且质量上乘的数据，AI本身其实毫无用处。”而谈到最近的新战略，他提到“我最终做出决定，把Intuit公司的命运托付给数据和AI技术。”Goodarzi三年前在接受《财富》杂志采访时说道。</p><p>&nbsp;</p><p>据悉，Intuit公司已经掌握有5700万客户的数据，如此储备足以在围绕金融展开的AI探索当中为其赋予显著优势。2020年，Goodarzi先是以81亿美元收购个人理财平台Credit Karma，借此吸纳了1.1亿消费用户及其财务数据；随后又在2021年以120亿美元收购营销平台Mailchimp，获得超1000万客户及其业务数据。</p><p>&nbsp;</p><p></p><h2>技术培训太慢，索性裁员</h2><p></p><p>&nbsp;</p><p>Goodarzi 还在2020年采取了一项前所未有的举措——一口气解雇715名员工，这也是Intuit公司历史上的首次大规模裁员。同时，该公司也宣布将增加 700 多个职位。</p><p>&nbsp;</p><p>但在裁员之前，Intuit曾花费大量精力和资金对员工进行培训。但Goodarzi认为，当时公司以AI为中心的转型速度太慢，原本被寄予厚望的技术再培训计划也未能快速发挥作用。于是，他决定用700多名新员工接替离职团队，其中大部分新人已经具备AI相关技术。</p><p>&nbsp;</p><p>“我们确实开始围绕数据和AI调整经营方向，但我明显感觉到公司内有能力助推发展速度的人才还远远不够。于是我们把资金重新投入到迫切需要的专业技能之上。”Goodarzi表示。</p><p>&nbsp;</p><p>2020 年 8 月，Shahid&nbsp;与该公司高级副总裁兼首席数据官 Ashok Srivastava 主持了一系列午餐学习课程，向任何有兴趣了解 AI 的员工开放。当时大约有 120 名员工参加了入门课程，Intuit 最终将其转变为在线课程。当在线课程还不够时，该公司会聘请合作伙伴来主持现场训练营。Shahid&nbsp;表示，虽然价格昂贵，但在内部创建和扩展类似的学习基础设施要困难得多。</p><p>&nbsp;</p><p>“我们现在正在推动的是让员工接触所有需要的技能。你可能作为一名数据分析师知道自己需要掌握什么技能，但我们也希望你知道成为一名项目经理需要掌握什么，”Shahid&nbsp;说道。她还希望员工了解哪些技能是可以转移的。</p><p>&nbsp;</p><p>如今在整个科技领域，人工智能已成为增长的首要任务。Intuit 也不例外，该公司发布了强化计划来提高员工的技术职位技能，例如其标志性的为期六个月的人工智能课程。</p><p>&nbsp;</p><p>Shahid&nbsp;表示，该公司去年开始为非技术员工提供为期七个月的学徒计划，该计划在想要过渡到工程岗位并获得实践经验的数据分析师和项目经理中特别受欢迎。员工毕业后会成为一级软件工程师。当时，11 名员工参加了试点学徒计划，其中9人已转为公司全职技术职务。该学徒计划还将继续进行下去。</p><p>&nbsp;</p><p>从非技术岗位转型到技术岗位并不容易。没有一定技术背景的员工很难提高学习意识并报名相关课程。即使员工获得了必要的学习和证书，当团队成员的经验水平不同时，工作时也会产生些紧张气氛。</p><p>&nbsp;</p><p>“有的学徒是软件工程师，有的没有技术背景，而有的已经在计算机科学领域获得了四年制学位。”Shahid&nbsp;表示，“让他们在一起工作，你必须不断思考权益等式，如何激励引进的人才，以及如何继续这个支持系统。”</p><p>&nbsp;</p><p>这种支持系统对于边缘化员工进入新的技术角色至关重要，因为他们通常对这个行业没有很多了解。因此，Srivastava 认为，在技术团队中营造归属感是关键。“无论这个人的背景是什么，传统背景还是非传统背景，重要的是我们创造了一种归属感和参与感，”Srivastava 说道。</p><p>&nbsp;</p><p></p><h2>OpenAI带来了危机？</h2><p></p><p>&nbsp;</p><p>与H&amp;R Block、Cash App、TaxSlayer、Xero、FreshBooks 等竞争对手相比，Intuit公司在AI技术领域拥有长期领先优势。该公司希望自己的早期投资能够产生网络效应，建立起AI高质量建议吸引更多客户、更多客户带来更多数据、更多数据改善产品质量、优秀产品吸引更多客户的良性循环。</p><p>&nbsp;</p><p>但去年11月，OpenAI发布的ChatGPT引起了人们的担忧。投资者们的信心也因此动摇，导致Intuit公司的估值产生波动。</p><p>&nbsp;</p><p>没错，如果有人能以成本极低、甚至完全免费的生成式AI处理几乎一切事务，谁还愿意花钱购买Intuit的AI产品呢？短短三个月之后，OpenAI又发布了GPT-4并演示了其计税服务功能，强大的表现进一步加深了Intuit的生存恐惧。在展示中，OpenAI要求GPT-4扮演“TaxGPT”，并回答一对虚构夫妇的财务数据回答报税问题。GPT-4不仅顺利完成了任务，最后甚至还用一首合辙押韵的小诗进行了财务总结。</p><p>&nbsp;</p><p>不过目前来看，Intuit的担忧还大可不必。GPT-4确实能够阅读税务代码，但却无法提供个性化建议，因为它缺少Intuit所掌握的海量专有数据集。分析师Ader认为，GPT-4对Intuit来说“更多是朋友，而非潜在威胁”，因为Intuit“掌握着数据，而价值都蕴藏在数据当中。”</p><p>&nbsp;</p><p>目前来看，投资者们对于Intuit的AI驱动策略可谓是信心满满。自Goodarzi掌舵以来，Intuit公司的股价表现远远超越了标准普尔指数和纳斯达克指数。但Goodarzi心里清楚，虽然早在五年前就为公司的发展定下基调，但Intuit接下来还有很长的路要走。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/83/83b4c1c6f067d357f57bd349f2c4cbd6.png\" /></p><p></p><p>Intuit股价走势变化</p><p>&nbsp;</p><p>Goodarzi希望到2025年将Intuit平台上的客户储蓄率提高一倍（今年7月，全美个人平均储蓄率为3.5%），到2030年将平台上中小型企业的经营成功率提高20%（全部新生企业中，无法熬过头五年经营的比例约为50%）。至于公司本身，Intuit预计其截至2024年7月31日的当财年收入将增长11%至12%，每股收益预计上涨11%至15%。</p><p>&nbsp;</p><p>Goodarzi认为，AI未来将成为像电力和互联网一样极具变革性的通行技术。“我们正处于AI之旅的起步阶段。在未来五到十年内，它将创造出新的经济体、并摧毁不少旧有经济体。AI会创造新的体验、孕育出新一批迅猛成长的企业，但也会无情淘汰掉那些抱残守缺的老顽固。”</p><p>&nbsp;</p><p></p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://finance.yahoo.com/news/intuit-cut-hundreds-jobs-spent-120000980.html?guce_referrer=aHR0cHM6Ly93d3cucmVkZGl0LmNvbS8&amp;guce_referrer_sig=AQAAAL2NwimEc42XmTC9E_rqn88ykQKLOIpXOqKa3Ca_F4A0malmJF92ocKbsyolXAx1ajLbEXySgBR7n_rDFrfvNSKsVtP-NEHjmUo56DQyP-bzhURfELJffTHYckhJyMyIxSq389Z4mKTlT1xLuCoj2p0-PZ78UaVEzS-kq6jcOTFD&amp;guccounter=2\">https://finance.yahoo.com/news/intuit-cut-hundreds-jobs-spent-120000980.html?guce_referrer=aHR0cHM6Ly93d3cucmVkZGl0LmNvbS8&amp;guce_referrer_sig=AQAAAL2NwimEc42XmTC9E_rqn88ykQKLOIpXOqKa3Ca_F4A0malmJF92ocKbsyolXAx1ajLbEXySgBR7n_rDFrfvNSKsVtP-NEHjmUo56DQyP-bzhURfELJffTHYckhJyMyIxSq389Z4mKTlT1xLuCoj2p0-PZ78UaVEzS-kq6jcOTFD&amp;guccounter=2</a>\"</p><p><a href=\"https://finance.yahoo.com/news/intuit-reskilling-talent-win-big-100000835.html?guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvLnVrLw&amp;guce_referrer_sig=AQAAABR4o6FEriVzzmp0duOd1udT0X_kmUZU3WxovtymhPiUOi-BpGzFmJTT8P7WYBhCqI-IfjkIx8I-GE2UBRfyKSEW6y0zBd3ZNXz1sX7C_hxos9scI_cPy-YjCmsMZd_5c9DKcREb7a9gNMkAmAgyWAvHXwLi3q2r960wo8Bu8RzI\">https://finance.yahoo.com/news/intuit-reskilling-talent-win-big-100000835.html?guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvLnVrLw&amp;guce_referrer_sig=AQAAABR4o6FEriVzzmp0duOd1udT0X_kmUZU3WxovtymhPiUOi-BpGzFmJTT8P7WYBhCqI-IfjkIx8I-GE2UBRfyKSEW6y0zBd3ZNXz1sX7C_hxos9scI_cPy-YjCmsMZd_5c9DKcREb7a9gNMkAmAgyWAvHXwLi3q2r960wo8Bu8RzI</a>\"</p><p>&nbsp;</p>",
    "publish_time": "2023-09-11 14:21:22",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从Milvus技术实践探讨如何从0到1做一款向量数据库｜InfoQ《极客有约》",
    "url": "https://www.infoq.cn/article/x0sHhuVEJARN7aYdbC2E",
    "summary": "<p>随着人工智能技术的飞速发展，大模型成为了这个领域里的热点。而在这个大模型的背后，向量数据库扮演着至关重要的角色。它们是大模型中的核心组件，为这些模型提供着海量的向量数据，从而支撑着各种应用场景的实现。</p><p>&nbsp;</p><p>向量数据库是一种专门设计用来存储和查询向量的数据库，它通过将文本、图像、音频和视频等数据转换成向量形式，实现了对这些数据的统一处理。在大模型中，向量数据库可以提供高效的数据检索和服务，使用户能够快速地获取所需的数据。</p><p>&nbsp;</p><p>以自然语言处理领域的大型预训练模型为例，这些模型通常需要处理数亿甚至数十亿的语料库，将它们转换成向量形式，并进行计算和分析。在这个过程中，向量数据库的高效性和准确性对于模型的训练和推理至关重要。如果没有向量数据库的支持，这样的处理任务几乎是不可能完成的。</p><p>&nbsp;</p><p>据统计，目前全球范围内已经有超过200家公司推出了向量数据库产品，其中包括一些知名的大公司如谷歌、亚马逊和微软等。这些产品在性能、可扩展性和易用性等方面都有了显著的提升，为用户提供了更加高效和可靠的数据服务。</p><p>&nbsp;</p><p>以开源向量数据库产品Milvus为例，它已经成为了当前最流行的开源向量数据库之一。Milvus可以支持亿级别的向量存储和检索，并提供多种语言的接口，使得用户可以方便地使用Python、Java等语言进行向量计算和数据分析。</p><p>&nbsp;</p><p>那么，Milvus向量数据库的研发过程中有哪些技术难题？每次迭代背后的思考又是什么？在大模型如此火热情况下，该如何从0到1构建一款向量数据库？带着这些问题，我们邀请到了Zilliz合伙人兼技术总监栾小凡，与他一起探讨业内关心的向量数据库的相关话题。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：观众朋友们大家晚上好，欢迎来到InfoQ《极客有约》，本期我们邀请到Zilliz合伙人兼技术总监栾小凡来到我们直播间，和大家聊聊如何从0到1做一款向量数据库。先请小凡老师简单做下自我介绍。</blockquote><p></p><p>&nbsp;</p><p>栾小凡：大家好，我是栾小凡。目前担任Zilliz的技术合伙人，同时也是开源数据库Milvus的主要维护者。很高兴能在这里与大家相聚。最近，无论是在社区还是在公司内部，都取得了许多令人振奋的进展。对于关注我们社区动态的朋友们来说，可能已经了解到，就在上周，我们刚刚发布了Milvus 2.3版本，这也是我们2.0系列的全新版本。经过近5到6个月的努力，我们推出了这个版本，其中包含了许多令人期待的新功能，以及一些性能的优化。</p><p>&nbsp;</p><p></p><h2>“押宝”向量数据库赛道背后的思考</h2><p></p><p>&nbsp;</p><p></p><blockquote>InfoQ：您能分享下当初为什么选择向量数据库这个赛道呢？</blockquote><p></p><p>&nbsp;</p><p>栾小凡：我们公司专注于向量数据库大约可以追溯到2018年左右。当时，向量数据库的概念并不广泛。我们的CEO力排众议，认为这个领域有巨大潜力，因为这与我们的愿景高度契合。我们的公司定位是构建一个能够在云上处理非结构化数据的基础设施产品。经过大量调研，我们意识到向量检索可能是未来处理非结构化数据语义和信息的关键。</p><p>&nbsp;</p><p>另外一个重要的因素是，向量数据库与模型相比具有明显的区别。我们早在此前就认识到，处理非结构化数据需要依赖人工智能，需要模型的支持。然而，那时的模型与现在的ChatGPT等大型模型相比，性能有限。作为初创公司，如果我们专注于开发模型方向，可能难以取得今天的成就，也难以像ChatGPT这样发布出色的产品。因此，我们决定将注意力放在基础设施上。鉴于我们团队成员都具备基础设施的背景，我们设想了一个能够有效支持高维数据处理的基础设施产品，即向量数据库的概念。</p><p>&nbsp;</p><p>从2019年开始，我们便着手开发这个产品。当时，我们已经吸引了许多关注，尽管当时社区用户主要集中在传统的应用场景，如图像搜索和NLP领域的问答机器人。直到去年，随着大型模型的兴起，数据库的使用场景和用户需求发生了重大变化，也带火了向量数据库的需求。这个现象表明数据库的第一应用场景正在演变，用户对能力的需求也发生了显著改变。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：请您展开说明下哪些需求推动了这个更新和迭代。</blockquote><p></p><p>&nbsp;</p><p>栾小凡：这个问题需要深入讨论大模型与向量数据库之间的关系。从去年ChatGPT推出时这个问题就开始引发我们的思考。在当时，我们敏锐地意识到这将是一个机遇。然而，在国内，这个概念的认知需要更长的时间。我个人在去年四五月份的美国之行中注意到，数据库在美国已经是一个非常热门的话题，但在国内似乎还没有得到广泛认知。所以，我们需要从向量数据库与大型模型之间的关系入手。</p><p>&nbsp;</p><p>在我看来，这个关系解决了人工智能领域中两个重要问题：生成和检索。一开始，很多人在争论是否可以通过对大型模型进行微调来获得领域知识。向量数据库与大型模型的结合是否合适？现在越来越多的观点表明，微调主要带来了一些规则性的认知，而真正的知识需要外部存储来补充。这就引发了对向量数据库的需求。</p><p>&nbsp;</p><p>在上述背景下，我们提出了一个名为“CVP&nbsp;Stack”的概念，其中“V”代表向量数据库（vector database），“C”代表ChatGPT，\"P\"代表prompt。在我们看来，大型模型代表推理能力，向量数据库则补充了它的知识，而prompt代表控制逻辑，用于实现特定语义。这三者的结合可以实现出色的业务效果。</p><p>&nbsp;</p><p>既然向量数据库在大型模型和存储之间扮演存储角色，就出现了对向量数据库的多重需求。首先，大模型需要存储海量数据，可能需要像传统数据库一样进行分布式部署，尤其是在云环境中。</p><p>&nbsp;</p><p>其次，成本问题也变得十分重要，因为通常情况下，计算资源相对较昂贵，而存储资源较为廉价，向量数据库也不例外。过去，向量数据库主要是内存驱动的，成本较高。但随着大模型的结合，未来非结构化数据量会越来越大，这将带来存储成本的需求。</p><p>&nbsp;</p><p>第三，我们可以预见许多功能上的需求。随着大型模型的发展，用户对向量数据库的需求不再局限于简单的操作。用户希望能够进行多向量操作，或者基于某些标量字段进行过滤、分组等。这些需求演化出了对向量数据库多样化功能的需求。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：您刚刚提到了许多内容，我们对于向量数据库的需求变得越来越多，市场上也出现了很多厂商推出自己的数据库解决方案。然而，我注意到一种趋势，就是很多厂商将向量引擎添加到传统数据库上，从而转变成所谓的向量数据库。我想了解您对这种“插件版”向量数据库与从零开始构建的向量数据库之间的区别有何看法？这种基于传统数据库添加向量引擎的方式，与我们从一开始就构建的向量数据库相比，存在哪些差异？</blockquote><p></p><p>&nbsp;</p><p>栾小凡：我一直坚持一个观点，即并非所有基于向量的解决方案都应被统称为向量数据库，尽管它们的能力在某些方面可以与之匹敌。从我的观点来看，例如pgvector或Elasticsearch，它们都是非常出色且成熟的产品，在特定场景下，确实可以很好地满足用户需求。在数据量很小的情况下，使用Elasticsearch，结合标量检索，已经足以满足业务场景。或者，如果你的原始数据完全存储在关系型数据库，然后基于pgvector操作去进行几十万甚至100万数据的搜索，这样也是完全可行的。但是一旦数据量变大，你会发现很多业务场景会受到传统数据库设计的限制，无法很好地扩展。</p><p>&nbsp;</p><p>实际上，在讨论向量数据库提供哪些能力时，我认为有几个关键点无法回避，包括算法、算力和调度。作为一个向量数据库，这几个方面都需要经过特殊设计。我一直提到的一个例子是，如果你只想进行近邻检索，你完全可以写个ANN，也许只需要不到10行代码就能实现你所需的近邻检索功能。但是大家选择不这样做的原因，在很大程度上考虑了性能和成本因素。从这个角度看，一旦性能、成本和可扩展性对你至关重要，许多传统的数据库可能无法满足需求了。</p><p></p><h2>Milvus从0到1技术实践</h2><p></p><p>&nbsp;</p><p></p><blockquote>InfoQ：Zilliz是如何从0到1做一款向量数据库的？经过了哪些升级和迭代？</blockquote><p></p><p>&nbsp;</p><p>栾小凡：这实际上是一个颇具曲折性和难得性的故事。由于我自己是在公司中间加入的，从2.0版本开始参与了Milvus的构建，而我们公司在向量数据库领域已经有大约5年的历史了。</p><p>&nbsp;</p><p>最初，我们看到了这个机会，并意识到有诸如Faiss等引擎在处理向量检索方面已经非常成熟，许多大型厂商也在使用它们。因此，我们的第一个版本设计非常简单，仅在Faiss上增加了一些持久化的日志，以及一些基础的RPC。当时很多人认为Milvus只是在Faiss上做了一层封装，这是最早对Milvus的看法，实际上，这个结论现在可以套用在大多数正在创业的向量数据库上，它们目前架构与我们最早的1.0架构几乎没有什么区别。</p><p>&nbsp;</p><p>在这个过程中，我们从0.1到1.0版本进行了许多尝试，主要受到最早一个重要客户的影响。虽然我不提及客户的名称，但他们最初使用了Milvus的早期版本，即0.1版本，来处理1000万数据集，效果非常好，他们很满意。然而，他们发现随着数据量的增大，Milvus的扩展性无法满足他们的需求。他们希望处理更大规模、达到10亿甚至更大的数据集，但这需要面临着诸多挑战。为此，我们采取了许多技巧，包括特殊的优化方法、更大的机型，以解决10亿数据的问题。</p><p>&nbsp;</p><p>从那时起，我们认识到向量检索（在2020年底至2021年早期）的性能和扩展性是非常关键的问题。因此，我们开始着手构建2.0版本的核心能力。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：那您能介绍下，每次版本迭代，背后的思考是什么吗？</blockquote><p></p><p>&nbsp;</p><p>栾小凡：在整个2.0设计过程中，有几个关键点是我们从一开始就在思考的。</p><p>&nbsp;</p><p>首先，我们考虑如何实现扩展性。</p><p>&nbsp;</p><p>其次，我们考虑了云原生或者说关注数据库的重要点，这包括弹性和数据的隔离性。因为在1.0版本时，用户在构建索引时查询性能会相互影响。因此，我们的目标是有效地将索引构建和查询隔离开来。第三个考虑因素是数据的实时性。在1.0版本中，我们的一个用户因为一致性保障较弱，插入了大量数据，但在查询时却无法找到。我们花费了很多时间排查，最终发现插入的数据没有及时构建索引，未能在线上提供服务，而用户完全不知道这一点。</p><p>&nbsp;</p><p>为此，我们在构建2.0版本时关注了实时性，保障用户插入数据后能够及时使用，最理想的情况当然是强一致性，即写入后立即可以查询到。然而，某些场景下，可以接受一定的延迟，但保障是必不可少的。因此，我们在2.0版本中花费了很多精力开发流式数据的写入能力，如何将流数据与传统批量导入的数据结合起来，包括如何对数据进行更新和删除。这些问题在我们的2.0版本中，尤其是在云原生架构下，变得相当复杂。大家或多或少都了解，与数据湖相关的问题，早期的产品也没有更新和删除的能力，这些能力是在后来引入的。因此，2.0版本的设计非常大程度上关注于如何解决实时性问题。</p><p>&nbsp;</p><p>大约在2021年6月左右，我们发布了第一个RC版本。然而，实际上如果现在回顾当初的版本，它是相当不成熟的，包括缺乏删除支持，负载均衡能力也非常薄弱。通过大约两年左右的不断打磨，现在有了一个稳定、高效的版本。</p><p>&nbsp;</p><p>对于我们来说，下一个更大的挑战可能是如何将这个开源系统更好地运行在企业环境或云端环境中。虽然2.0版本已经具备云原生的特性，但对于开源和商业环境而言，最大的区别在于我们对资源的更多控制权。</p><p>&nbsp;</p><p>因此，在我们的向量数据库服务中，我们经常思考如何将正确的资源分配到正确的位置上。例如，如果用户的请求QPS不足，如何增加计算资源？如果用户内存不足，如何增加内存？在简单的开源向量数据库或传统数据库中，这种资源管理是不存在的。只有在云原生分布式的向量数据库中才能有更多调度的可能性。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：云原生分布式向量数据库的优势有哪些？</blockquote><p></p><p>&nbsp;</p><p>栾小凡：首先解释一下什么是分布式，什么是云原生。分布式的概念相对容易理解，就是系统的各个组件在不同的节点上进行协作和分工，以实现更大规模和更高性能的处理。而云原生并不仅仅指运行在Kubernetes（K8s）上或在公有云上的服务。在我的理解中，分布式云原生意味着系统首先是一个资源池，不仅包括计算资源，还包括数据和其他资源。举个例子，向量检索在构建索引阶段通常需要大量的计算资源，但是一旦索引构建完成，这些计算资源就被浪费了。在传统方法中，可能需要额外的管理和优化来避免浪费。然而，在分布式原生系统中，可以将资源共享给多个租户，从而提高资源的利用率。这也意味着，对于某个用户而言，可以通过共享的资源池加速索引构建过程。</p><p>&nbsp;</p><p>这就是资源池的概念，它可以让多个租户共用同一个计算资源池，提高资源的复用率。从用户的角度来看，在相同资源投入的情况下，或者在相同成本的情况下，通过利用这个资源池，可以更多地分配资源，从而加快索引构建的速度。这样做可以在保持相同资源开支的前提下，提升效率，因为资源的价值可以通过单位时间内的使用量来度量。通过这种资源池的弹性分配，用户可以在同等成本下获得更多资源，从而缩短任务执行时间，提升用户体验。</p><p>&nbsp;</p><p>在构建云原生系统时，这是一个需要仔细设计的方面。为了实现这一点，存储和计算的分离是必要的。在现代数据库领域，比如OLAP等，存储和计算分离已经成为一种共识。在向量数据库领域，据我所知，我们可能是第一家也是唯一一家在开源中实现了存储与计算分离的数据库。没有存储和计算分离的能力，云原生的概念很难得以实现。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：您提到Zilliz是第一家，可能也是唯一一家做存算分离的数据库架构，它的技术难点您觉得在哪里？</blockquote><p></p><p>&nbsp;</p><p>栾小凡：在过去的两年多里，我们走过了一段技术探索的旅程，但事实上我们在这个过程中遇到了许多挑战。因为通常情况下，存储和计算分离的架构主要用于OLAP数据库。在传统的OLAP数据库中，数据的更新频率相对较低。虽然一些OLAP数据库支持更新操作，但更新和删除的能力相对有限。此外，OLAP数据库通常要求较低的查询延迟，查询几秒钟或几十秒钟，满足前端业务需求即可。然而，向量数据库与此完全不同。</p><p>&nbsp;</p><p>首先，向量数据库需要支持频繁的更新操作，而且这些更新可能是大规模的批量操作。因此，对于向量数据库而言，必须拥有能够支持流式更新的强大存储能力。其次，向量数据库在应用场景上与OLAP数据库有很大的区别。不同的应用场景对查询延迟有着不同的要求。例如，在推荐系统中，用户可能需要几毫秒甚至最多几十毫秒的查询延迟。这就要求在存储和计算分离的架构下，需要有高效的缓存机制，包括本地磁盘缓存和内存缓存。同时，在调度资源时，还需要考虑如何在扩容和缩容时避免请求抖动，以确保稳定性。</p><p>&nbsp;</p><p>在我们的探索过程中，团队始终在不断摸索，时至今日，我们并不认为自己的方案已经达到了完美的程度。这也是为什么我们的大版本从2.3升级到2.4时，我们会进行一些架构的调整。我们意识到作为行业的探索者，必须付出一些代价。从整个中国的开源社区来看，许多社区通常会效仿美国或其他全球优秀社区的实践方法。</p><p>&nbsp;</p><p>在向量数据库这个领域，特别是在三大数据库领域，Milvus是最进一步探索的向量数据库产品之一。我不仅仅强调技术和能力是否最出色，更重要的是我们在探索道路上走得最远。在这条道路上，我们没有太多的前辈引路，因此一直在根据用户的反馈和自己在线上运维的经验来不断调整和优化。然而，至少从目前来看，我们的产品已经达到了可以投入生产使用的标准，并且我们对未来的发展方向也有相对明确的规划。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：Milvus一直在不断进行演进和版本迭代，如何判断是否增加某个功能，依据的是什么？是客户的需求、用户的反馈，还是对市场趋势的判断呢？</blockquote><p></p><p>&nbsp;</p><p>栾小凡：我认为需要将其分成两类情况。首先，从产品角度来看，我们必须聆听用户的声音。了解用户的需求、他们对产品的哪些方面感到不便，这是至关重要的。我们始终需要紧跟用户的反馈，因为用户的需求对产品的发展具有重要影响。当然，我们选择将产品开源，以及为什么要提供云服务，实际上也是为了获取更多的反馈和输入。我们希望不断完善产品，使其成为一个全球范围的优秀产品，而不仅仅局限于中国市场。</p><p>&nbsp;</p><p>从另一个角度来看，作为技术领导者，我有一个原则，即在技术层面上，我不仅仅听从用户的声音。举个例子，就像在汽车出现之前，人们可能只会想到需要改进马车。类似地，在ChatGPT出现之前，很少有人能够预见到大型模型和AI会以何种方式改变我们的生活。因此，在向量数据库的未来发展方向以及如何将其性能提升5倍或10倍等技术问题上，用户的意见或许无法为我们提供明确的指导。这些是我们作为技术人员需要自己解决的问题。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：当前，向量数据库市场正受到广泛关注，不过也有一些声音持怀疑态度。有人认为，我们可能不需要专门开发一款向量数据库，而是可以在现有的数据库基础上添加一层封装，实现向量搜索功能，从而避免创建全新的向量数据库。您对此有何看法？</blockquote><p></p><p>&nbsp;</p><p>栾小凡：我认为答案是这样：如果你的数据量只有100万条或者几十万条，无论使用何种数据库都可以解决这个问题，甚至不用使用向量数据库也可以达到目标。就像为什么要使用MySQL一样，如果你只有100条数据，可能在Excel中进行简单处理就足够了。因此，必须从数据量的角度来考虑才有意义。</p><p>&nbsp;</p><p>真正有意义的向量数据库是针对更大、更加生产型的场景。当你面临生产规模的需求，无论是数据链路还是QPS，如果需要处理千万级别的数据，或者需要进行一些特殊的向量操作，那么向量数据库才能发挥其核心作用。</p><p>&nbsp;</p><p>从另一个角度来看，未来所有传统数据库都会支持向量，这将成为一种标准的能力，就像现在许多传统数据库都支持JSON一样。但是，虽然PostgreSQL和MySQL都支持JSON，但这并不意味着MongoDB就失去了存在的价值。因为在JSON领域，如果你的核心业务需要强大的JSON数据库支持，大家第一时间会考虑MongoDB。</p><p></p><h2>老生常谈：开源or闭源？</h2><p></p><p>&nbsp;</p><p></p><blockquote>InfoQ：您如何看待开源还是闭源的问题？</blockquote><p></p><p>&nbsp;</p><p>栾小凡：开源对我们来说是一种信仰。从最早开始研发向量数据库的时候，我们就相信应该让更多人了解并使用优秀的技术，这是我们选择做开源的原因。无论是在AI领域还是其他领域，我们希望技术不会被少数大公司垄断。在向量数据库问世之前，阿里、Meta和Google等公司早就开始尝试向量搜索。但是，对于许多中小型公司来说，技术和算法上存在很多挑战，难以克服。开源初衷是使更多人能够更好地使用数据库。</p><p>&nbsp;</p><p>另一方面，为什么我们还要提供云服务？当然，作为一家公司，盈利是重要目标。然而，我们还考虑到通过云服务，可以更快地获取用户的反馈，降低产品的使用成本和部署成本。云服务能够帮助很多人，特别是那些不希望自行维护复杂架构的用户。与之类似的例子是OpenAI将GPT模型开源，但实际上有多少人能够成功部署这个模型呢？通过API部署的方式能够触达更广泛的受众。</p><p>&nbsp;</p><p>在AI领域，开源和云服务都有助于降低用户的门槛，而且面向的客户群体可能完全不同。对我们来说，有两个角色，一方面是开源维护者，致力于降低开源用户的使用成本；另一方面，我们也在思考如何更好地将开源与云服务结合起来。</p><p>&nbsp;</p><p>在过去几年的发展中，我们注意到很多领域都有一个开源厂商和一个闭源厂商之间的竞争，比如Snowflake和DataBricks之间的竞争。我认为，在向量数据库领域，未来可能也会出现类似的情况，开源和闭源可能会长期并存。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：开源数据库和云服务是否会产生冲突？</blockquote><p></p><p>&nbsp;</p><p>栾小凡：这方面肯定会面临一些挑战，我们一直在谨慎地把握平衡。</p><p>&nbsp;</p><p>首先，我们的原则是不希望损害任何开源用户的权益。因此，我们内部有一个基本准则，即我们的开源版本和云版本一定会保持相同的接口和功能。绝不会出现中途放弃开源转向云产品，或是让开源和云版本分道扬镳的情况，否则这点在我们内部的人力投入、产品运维等方面都是不允许的。</p><p>&nbsp;</p><p>然而，另一方面，我们也在考虑如何为付费用户提供更多的价值。除了降低产品的部署门槛和提升易用性外，我们还在思考其他方式。因此，云版本内部包含一个自研引擎，尽管在功能层面与开源引擎几乎完全相同，但从性能方面来看稍微更优。这意味着我们的付费用户可以获得更高的性能水平，这在性价比或性能优势方面也都会给他们带来所需的好处。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：随着我们大模型的持续发展，以及向量数据库需求的增加，许多厂家在考虑开发大模型时也开始考虑应用向量数据库。关于在向量数据库的选型上，是选择自研还是引入外部解决方案，您对这个问题的看法是？</blockquote><p></p><p>&nbsp;</p><p>栾小凡：想要给出一个确切的答案可能有些困难，因为不同公司的价值定位以及个人的立场都有所不同，每个人站在不同的角度考虑问题。有些公司可能注重快速发展，而有些公司可能更追求封闭环境的能力。我认为这些不同的观点都有其合理性。但如果从我个人来选的话，我更倾向于相信开源社区的力量，尤其在三大数据库领域，共同参与一个开源社区可能会加快迭代速度。</p><p>&nbsp;</p><p>举个例子，以Milvus项目为例，早在2018年至2019年，阿里和其他一些厂商都有自己的向量数据库产品，他们在当时对向量检索的理解可能比我们在Milvus项目上要高。经过这几年的发展，大家可以看到，从技术先进性、认知水平以及生态建设上，我们的开源产品已经全面超越了那些闭源的产品。因此，我个人认为，除非你在这个领域非常专业，否则相信开源可能更有优势。</p><p>&nbsp;</p><p>另一方面，从我们公司的做事风格来看，我更偏向于专注做好一件事情。当我们构建云服务时，我们会采购第三方的一些服务，因为我们相信一个优秀的产品是建立在众多优秀产品的基础上的。现在社会分工已经很明确，没有人可以做所有事情，即使像OpenAI这样的公司，也会在某些领域保持克制，不会尝试做太多不相关的事情。所以我认为，尤其在公司规模较小的情况下，守住自己的领域，专注于自己最擅长的事情可能更为明智。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：那对开发者来讲是自研好，还是购买第三方产品？</blockquote><p></p><p>&nbsp;</p><p>栾小凡：从我的观点来看，我更倾向于他们直接购买我们的服务。这实际上能够减少很多的麻烦，我说的并不仅仅是公司盈利或营收的问题。作为一个开源项目的维护者，我花费了大量的精力在社区中回答用户的问题，包括在我们的微信群里，我也经常回答问题。然而，由于开源的特性，用户的环境非常复杂，可能涉及不同版本的Linux，不同的硬件平台，以及不同的云环境，这导致了用户体验可能不够理想。尽管我们花费了很多精力来帮助开源用户解决问题，但有时候这些问题可能很难完全解决。</p><p>&nbsp;</p><p>作为一个开发者，如果你希望产品能够快速迭代，或者更专注于自己的业务逻辑，我强烈建议你选择云服务。另一方面，如果你的业务数据量非常大，对成本敏感，或者有线下部署的需求，那么可以选择一个开源的向量数据库。</p><p>&nbsp;</p><p>在如何选择合适的向量数据库方面，我认为可以从几个角度出发。首先，要考虑你的业务场景。如果你的业务规模较大，性能和扩展性将是你需要关注的重点。其次如果你只是需要在较小的业务场景中使用向量数据库，那么你首先应该关注产品的易用性。易用性包括文档质量、功能丰富程度，以及部署和运维的便利性。需要考虑是否有图形界面和监控报警等功能，这些都是在选择向量数据库时需要密切关注的方面。</p><p></p><h2>未来规划</h2><p></p><p>&nbsp;</p><p></p><blockquote>InfoQ：Milvus今后的计划演进的方向，技术更新迭代有哪些？</blockquote><p></p><p>&nbsp;</p><p>栾小凡：不久前，我们刚刚推出了Milvus 2.3版本。接下来的2.4版本，我们将更加贴近人工智能的使用场景。在这个版本中，我们将提供多向量的支持，这种功能可以满足大型模型和实时数据结合的需求。因为我们注意到许多人在搜索文本时的常见做法，例如将摘要做成embedding，将具体内容分成多个embedding，并在搜索时给予不同的权重，比如摘要权重较高，每段内容的权重较低，然后进行混合打分。从2.4版本开始，我们将支持这种场景。此外，随着拥有多个不同的打分、多个embedding字段和多个不同的打分方式，我们将继续探索基于多个字段进行排名的能力，这与人工智能的紧密结合有关。</p><p>&nbsp;</p><p>除此之外，在2.4版本中，我们还将增加一些传统数据库应具备的能力。在过去，Milvus仅支持按主键进行删除，这给用户带来了不便。在2.4版本中，我们将支持根据表达式进行删除的能力。</p><p>&nbsp;</p><p>2.4版本中将进行大规模的存储更新。过去，Milvus的存储依赖于我们自己编写的存储格式，存储效率和查询效率存在一些问题。而且，由于这个存储格式并不通用，因此与其他系统的整合可能会比较困难。在2.4版本中，我们将把Milvus的存储作为一个独立的项目进行更新，从而更好地与外部系统进行集成。</p><p>&nbsp;</p><p>最后，我认为最关键的一点是在向量索引能力的建设方面。在2.3版本中，我们已经进行了许多关于过滤检索的优化。未来，我们还将继续在现代向量索引的性能方面进行大量工作。我认为这也是大家在比较不同现代数据库时应关注的方向。我们还开源了一个Vector DB Benchmark工具，可以用来比较不同向量数据库的性能。我们为用户提供了多种数据集，涵盖了不同大小规模的场景和过滤情况。</p><p>&nbsp;</p><p>打个小广告，我们为用户提供综合的排行榜，大家也可以根据自己的需求运行测试。如果您对线上数据库性能有研究兴趣，不妨了解一下我们的<a href=\"https://github.com/zilliztech/VectorDBBench\">Vector DB Benchmark</a>\"工具，这个工具已经在Github上开源。在这个工具中，除了我们自己的产品，也包括了Zilliz Cloud、开源的Milvus，还有许多其他开源和商业竞品的数据。</p><p>&nbsp;</p><p>此外，我想借此机会呼吁一下，无论是传统公司还是创业公司，既然我们都在向量数据库这同一赛道上，为什么不一起参与这个榜单呢？我们开源这个榜单的目的实际上也是出于相同的诉求。我们希望为更多的开发者和决策者提供更多参考信息。说实话，我们并不是专业评测机构，所以可能会存在一些公平和公正的问题。因此，也更希望在一个公平的规则下，每个人都可以自行测试自己的产品，这样可能更有说服力。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：有观众提问以后会考虑集成Elasticsearch那种倒排索引功能吗？</blockquote><p></p><p>&nbsp;</p><p>栾小凡：这个计划已经在我们的日程中了，当然，这是一个比较长期的目标。正如刚才简要提到的，2.4版本中，我们想要提供一些新的能力，尤其是我们引入了多向量和Ranking方面的功能。而在之后的版本中，尤其是3.0版本，我们认为最为重要的两个功能分别是SQL支持和类似于Elasticsearch倒排索引的支持。</p><p>&nbsp;</p><p>为什么要做这些呢？实际上，我们看到稠密嵌入和稀疏嵌入之间的搜索是相互补充的。在不同的检索理念和场景下，两者能够搜到不同的内容，从而在最终的召回效果方面有很大的提升。</p><p>&nbsp;</p><p>在过去，我们更多地关注向量本身，特别是在相同向量集合下，如何从数据层面获得更高的召回率。我们的召回率更多地集中在向量数据集本身。如果我们将视角放得更高一点，例如对文本进行召回，那么除了在向量召回效果方面的提升外，还有很多其他方法可以尝试。例如，您可以通过排名的方式进行，也可以使用一种类似于倒排索引的方法，以搜到一些特殊的结果，然后再进行合并。这些是接下来Milvus社区希望探索的方向。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：您看来还有哪些值得开发者和所有从业者们去关注的未来发展趋势？</blockquote><p></p><p>&nbsp;</p><p>栾小凡：向量数据库现在确实备受瞩目。然而，我相信那些尝试过向量数据库的直播观众会发现其实效果有时并不如他们所想象的好。因此，对于向量数据库而言，首要的事情是对嵌入算法本身进行更多的探索。虽然向量数据库能够解决快速检索的问题，但在整体检索效果方面，首先是模型的重要性，其次是有许多技巧。</p><p>&nbsp;</p><p>因此，我也希望所有致力于向量数据库或大模型的同行能够共同努力来进行市场教育。我们需要告诉用户如何以何种方式使用向量数据库，想要充分利用它，需要深入了解许多关键点和诀窍，只有这样才能取得良好的业务效果，远非现在所谈论的那样简单。</p><p>&nbsp;</p><p>另一方面，我认为向量数据库与传统数据库的进一步融合也是非常重要的。关于传统数据库是否适合处理向量数据的问题，我刚刚也给出了一些答案，针对大模型的情况下，传统数据库肯定会有其特殊性，而在这种结合下，传统数据库的迭代速度会更快。然而，我们也必须看到这个趋势，即分久必合，合久必分。最终向量数据库要逐渐朝着传统数据库发展，加强很多传统数据库的能力。就像刚刚有用户问到的备份能力，这正是典型的传统数据库能力。然而，根据我目前的观察，目前向量数据库仍然没有充分考虑这些问题，包括数据安全性、弹性以及易用性等方面，也包括刚刚提到的SQL支持。因此，我认为传统数据库与现代数据库之间未来将会出现融合的趋势。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：在传统数据库的领域，如果有人想朝向向量数据库方向发展，那么他们应该具备哪些能力呢？他们应该朝哪些方向培养技术？比如说，需要掌握哪些编程语言？需要了解哪些算法和技术？您是否能给予一些建议呢？</blockquote><p></p><p>&nbsp;</p><p>栾小凡：就产品定位而言，虽然不同产品有不同的定位，但产品开发者之间的界限并不是特别明确。就我个人而言，我背景是传统数据库，曾在Oracle和阿里云从事NoSQL数据库领域的工作，所以我认为这些领域的划分并不是那么严格的。</p><p>&nbsp;</p><p>要做好向量数据库，与做分布式数据库类似，首先需要掌握各种基本原理，例如数据库的编译器、执行器，存储设计，以及数据分片等。这些基础知识是通用的。</p><p>&nbsp;</p><p>如果要说有什么不同之处，我认为主要有两点。首先，你需要深入了解不同的应用场景。与传统数据库不同，向量数据库面向的是算法工程师和前端开发人员，因此，如何设计产品更易用、如何理解他们的业务场景，以及如何让数据模型更加灵活，这些方面存在较大差异。</p><p>&nbsp;</p><p>其次，你需要掌握一些人工智能的知识。向量数据库与传统数据库的另一个区别在于，它并不要求百分之百的精准匹配。这意味着向量数据库更像是一个既支持AI的数据库系统，也是一个AI对数据库进行加持的使用案例。从我们Milvus数据库的角度来看，我们近期进行了许多实验，利用模型能力来提升向量数据库性能。因此，掌握一些基本的机器学习和算法知识，有助于思考如何更快速地优化向量数据库的性能。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：对于那些希望从其他数据库领域转向向量数据库领域的开发者们，您有什么建议吗？需要重点培养哪些能力？</blockquote><p></p><p>&nbsp;</p><p>栾小凡：首先，不要过于畏惧转换赛道。向量数据库与其他数据库一样，也是一种数据库类型。从传统的TP数据库转向现代的AP数据库，你无需过度焦虑。然而，在这个过程中，你需要了解向量数据库的发展历程，了解竞争对手，了解各家的价值定位，了解他们的架构和API设计。这与从传统的SQL转向NoSQL数据库的情况类似，大家都会熟悉Bigtable和Snowflake这样的论文。同样，阅读相关论文以及其他竞争产品的相关论文，甚至是业界最新的研究，都能帮助你更好地理解数据库领域的情况。</p><p>&nbsp;</p><p>其次，要掌握AI的基本能力。了解Transformer、CNN（卷积神经网络） 等基本概念，对于向量数据库领域是非常有帮助的。尽管一开始你可能对这些内容不甚了解，但学习这些基本概念是迈向向量数据库领域的必经之路。尤其是对于数据库开发者而言，AI和模型方面的知识将成为你不可或缺的基础。这将有助于你更清晰地定位数据库功能，并能更轻松地将上下游打通，从而实现优化。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：有观众提问，新的2.0版本有提供可靠的备份方案吗？数据冗余的能力如何？</blockquote><p></p><p>&nbsp;</p><p>栾小凡：我们一直非常关注数据的可靠性问题。在Milvus 3.0版本之前的设计中，所有数据都是以实战和分离的方式存储。这个设计的第一个保障是，所有存储本身都有三个副本的保障。如果数据库部署在云上，像阿里云的OSS或AWS S3，它们的冗余保障非常高。</p><p>&nbsp;</p><p>在Milvus 2.0的早期阶段，确实存在一些稳定性问题。因此，从大约22年开始，我们推出了一个名为“Milvus Back Up”的新工具。这个工具可以将Milvus中的数据备份到对象存储，或者备份到其他地方。在最新版本中，我们还引入了一个新的能力，叫做“change data capture”，它可以备份增量数据。在增量备份和存量备份的情况下，即使集群出现问题，数据丢失的可能性也非常小。</p><p>&nbsp;</p><p>我需要提醒大家的是，最近我在社区里看到了一些情况，有些操作可能会将Milvus的元数据和存储分开进行备份，然后在回放时可能只恢复其中的某一部分，导致表丢失或底层的数据文件丢失。因此，大家需要格外注意这一点。目前来看，我们正在进行大量的测试，在过去的一段时间里，并没有太多关于对象存储或Milvus本身导致数据丢失的问题，绝大多数情况可能是因为误操作。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：在使用Milvus的时候大家在操作上需要特别注意哪些问题呢？</blockquote><p></p><p>&nbsp;</p><p>栾小凡：当考虑部署时，首先建议按照社区的指南进行操作，包括遵循最小规格要求以及硬件要求。例如，在我们的文档中明确提到，像ETCD需要使用SSD磁盘。遵循这些需求在部署过程中可以规避很多潜在的风险。</p><p>&nbsp;</p><p>其次，在实际的运维过程中，建议做几件事情。首先是配置监控，确保系统的运行状态可以被监控到。其次是记录Milvus的日志，这对于问题排查至关重要。有很多用户在向社区寻求帮助时，却无法提供详细的日志，这给问题的排查带来了困难。</p><p>&nbsp;</p><p>另外，在进行数据加载或创建索引时，务必要合理估算和管理内存。许多Milvus的索引依赖于内存，所以在加载数据时，如果内存不足，容易出现内存不足或无法加载的问题。在社区中，我们有一个“Calculator”的工具，可以帮助你估算物理资源能够加载多少数据。因此，建议在加载数据之前进行预估，特别是对于标量数据，因为当前Calculator工具仍然以标量数据为准。</p><p>&nbsp;</p><p>对于大模型的场景，尤其是在用户倾向于将原始文本存储在数据库中的情况下，需要额外注意。目前，这种方式可能会对数据库的性能造成挑战。如果你有像MongoDB等更适合存储数据的地方，建议将数据暂时存放在其他地方，这将有助于提高数据库的稳定性。数据的合理存放非常重要，特别是在向量数据库的情况下。然而，当涉及存储非常长的文本字段时，尤其是那些几十KB级别的超长字段，从性能和内存使用的角度来看，向量数据库并不是最优选择。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：日志部署有哪些需要特别注意的？</blockquote><p></p><p>&nbsp;</p><p>栾小凡：关于日志模块，我们在Milvus中支持两种不同的日志类型，一种是Kafka，另一种是Pulsar。我个人更倾向于使用Pulsar，因为它从我们设计系统的一开始就融入了许多的设计理念，例如存算分离和支持的分区数目。不过，由于系统设计是插件化的，我们也支持了Kafka，因为Kafka是一个非常受欢迎的消息队列。在选择时可以根据实际情况来决定使用哪种。</p><p>&nbsp;</p><p>在我们的生产环境和用户环境中，这两种日志类型都有广泛的应用。需要注意的是，对于那些喜欢创建大量表的用户，有一个小提醒。在Milvus 2.2版本中，如果你的表数量非常多，可能会对整个消息队列造成较大的压力。我们并不推荐这样做，建议用户将表格数目控制在100以内。在Milvus 2.3版本中，我们进行了很多优化。如果你确实有大量表格的情况，我建议你仔细思考一下，是否真的需要这么多表格？我们的社区中有许多其他功能可以避免创建过多的表格。</p><p></p><p></p><blockquote>InfoQ：好的，感谢老师精彩分享。</blockquote><p></p><p></p><p>嘉宾介绍：</p><p></p><p>栾小凡，Zilliz 合伙人兼技术总监，同时是 LF AI &amp; Data 基金会技术咨询委员会成员。在加入 Zilliz 前，他在阿里云担任研发经理，负责 NoSQL 数据库 Lindorm 的研发工作。此前，他曾先后在美国甲骨文公司和软件定义存储公司 Hedvig 担任软件工程师。栾小凡拥有康奈尔大学计算机工程硕士学位。</p>",
    "publish_time": "2023-09-11 16:07:21",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AI 大模型热潮来袭，看机密计算如何应对敏感数据安全挑战",
    "url": "https://www.infoq.cn/article/eL4ouVu6Pv5JzsHFwwrW",
    "summary": "<p>大模型已成为当下 AI 产业最大热点。随着 OpenAI 发布 ChatGPT，行业普遍认为超大规模 AI 模型已达到实践可用状态。除了 OpenAI 的 1750 亿参数 GPT-3、1.8 万亿参数 GPT-4 外，互联网公司也相继推出了文心一言、盘古、混元、Titan、PaLM 等大模型产品。Meta 还在日前发布了开放的 LLaMA 模型的升级版本 Llama 2，将开放大模型的参数规模推到了 700 亿级别。</p><p></p><p>与此同时，业界也正在积极探索大模型的应用场景，包括图像和视频识别、AIGC、智能客服、智能文本总结、代码辅助生成、欺诈分析、流程自动化、无人驾驶等众多细分领域的应用中，都出现了大模型的身影。大模型最吸引人的特性便是强大的分析和交互能力，这种能力被看作是通用人工智能（AGI）时代来临前的曙光。</p><p></p><p>然而，大模型背后依赖的是规模庞大的训练数据与交互数据，受限于人工智能的黑盒机制，无论是研究人员还是运维人员都难以完全掌控大模型中的数据。这就意味着大模型在实践中不可避免地会带来敏感数据的安全挑战。为了应对这一问题，一种方法是从软件着手构筑数据藩篱，基于密码学机制保护数据，但这样的方法往往会带来很高的系统开销，也不能从根本上缩小攻击面、免除软件漏洞带来的风险和威胁。另一种方法则是基于硬件级的加密机制，通过芯片构建的可信任执行环境来保护数据。这种技术希望通过天然具备高度安全性的硬件加密体系对抗数据的泄露和窃取风险，它被称为机密计算。</p><p></p><p>近日，InfoQ 与英特尔联合打造的「英特尔®&nbsp;至强®&nbsp;实战课」特别邀请到了英特尔公司首席工程师宋川、阿里云机密计算安全专家于国瑞与阿里云高级安全专家刘煜堃，就云计算时代的数据安全主题展开分享。三位着重讨论了如何通过机密计算技术破解数据开放共享环境中的数据隐私保护、数据确权等瓶颈，从而让数据真正安全通畅地流通并发挥价值。InfoQ 基于本场分享内容整理成文，希望对大家有所帮助。</p><p></p><h1>大模型时代的云端数据安全困境</h1><p></p><p></p><p>今年三月，三星电子刚刚在企业内部引入 ChatGPT 服务不久，就发生了三起机密数据泄露事件。部分员工将涉及半导体生产的机密代码与内部会议信息输入 ChatGPT 端口，导致这些敏感资料被上传至美国服务器，极可能已经泄漏。事件发生后，三星迅速采取措施约束员工使用 ChatGPT 的场景和行为，也引发了行业对于这类大模型技术带来的数据隐私和安全问题的讨论。</p><p></p><p>客观而言，在互联网时代，任何向云端上传数据的行为都具有潜在的安全风险。云计算刚刚兴起的时代，就有很多企业担忧敏感数据被云服务商泄露，拒绝将其上传至云端。时至今日，仍有大批企业在本地存储隐私数据来增强安全性，云服务商仍然没有完全赢得企业的信任。</p><p></p><p>而大模型的热潮则令这一问题雪上加霜。一方面，由于大模型训练、运营所需的成本极为高昂，极少有企业能够负担巨大的投资而在本地建设自有大模型服务。另一方面，由云服务商提供的大模型服务在训练和交互时需要海量数据，尤其是特定领域的数据。大模型掌握的领域数据越多，特别是与企业研发、运营相关的数据越多，输出的效果往往越令人满意。例如，企业开发人员使用 AI 代码辅助生成工具时，一般需要上传企业已有的代码库，使大模型给出更精准的代码预测结果；企业营销人员将过往的营销材料输入大模型，就可以自动生成高质量的营销内容，提升工作效率。</p><p></p><p>与此同时，提供大模型服务的云厂商一般会同时服务众多客户，而大模型在获得各个企业的数据后，如何将这些数据充分隔离在每个客户的服务范围之内，就成为了困扰云厂商与企业的一大难题。一旦数据的隔离失败，从甲客户获得的数据就可能被用在对乙客户给出的交互回答中，造成数据泄露。如果企业上传的大量隐私机密数据未能得到充分保护，恶意攻击者或者云厂商内部的恶意人士就可能利用软件漏洞或职权获取这些信息，攫取不当利益的同时，也对企业造成了无可估量的伤害。考虑到大模型所需的训练和交互数据数量庞大，远远超过以往企业上传到云端的规模，这种风险相比过去也有数量级的增长。</p><p></p><p>正是在这种背景下，机密计算技术的重要性愈发凸显，它通过硬件级的加密体系来一劳永逸地解决云端数据的安全挑战，为大模型的全面推广奠定了安全与信任的基础。</p><p></p><h1>机密计算，解决云端数据隔离难题的创新路径</h1><p></p><p></p><p>基于硬件芯片级的加密技术，保护数据安全的做法有着很长的历史。早在 2008 年，微软就在 Windows Vista 和 Windows Server 2008 操作系统中引入了 Bitlocker 加密，可利用 PC 中安装的 TPM 硬件受信任安全模块来加强登录等交互过程的安全性。随着 iPhone 等智能手机广泛流行，对设备存储的数据进行全盘加密，并将加密密钥保存在手机芯片内部的设计也成为行业事实标准。</p><p></p><p>随着云计算的成熟和普及，云服务厂商和硬件提供商开始利用硬件加密的概念武装云端集群，将类似的技术部署在云服务器内的 CPU 中，这一做法和理念被称为机密计算。机密计算使用处理器内独有的加密密钥创建可信的执行环境（TEE），其支持加密签名证明，防止他人查看或更改环境内部的数据或应用代码。</p><p><img src=\"https://static001.geekbang.org/infoq/fa/fa4369412f6598606fc77215aa92bc63.png\" /></p><p></p><p>应用的执行过程中，加密数据首先被传入 TEE，在其中解密并运行，生成的结果会被加密并传出 TEE 。整个过程中，即使是机器所有者自身都无法查看用户传入 TEE 的任何数据。在这样的机制下，用户就无需担心云端服务器是否被攻破、机密数据是否泄露到了其他用户的内存区域，或者服务器所有者是否会利用权限查看数据。只要用户信任 TEE，就能相信自己的数据处于安全可靠的隔离状态中。而要篡改基于硬件加密的 TEE，理论上需要修改芯片物理层面的晶体管设计，这显然是不可能做到的。正因如此，机密计算被认为是解决云端数据安全挑战的终极手段。</p><p></p><p>机密计算的另一大优势是计算开销较小，对性能几乎没有影响。由于芯片内部的安全区与加解密操作都由专用的硬件单元执行，用户的程序并不会因为这些过程而被拖慢运行效率。综合来看，机密计算在云时代，尤其是大模型流行的今天有着非常广阔的前景，可以极大程度上减少行业对数据泄露的担忧。</p><p></p><h1>从 SGX 到 TDX，英特尔机密计算技术概览</h1><p></p><p></p><p>如前所述，机密计算主要解决三大问题：</p><p>数据的机密性，确保数据在使用过程中不发生外泄。数据的完整性，确保数据在处理过程中没有被篡改。访问数据的程序的完整性，确保访问用户数据的程序安全可信，没有被植入恶意代码。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ea/ea1fc083db809c5348e6a67d979bc6dd.png\" /></p><p></p><p>作为机密计算理念的提出和推广者，英特尔公司自 2015 年起就将这一技术作为解决云端数据安全性的关键钥匙，开始投入大量资源进行研究和实践。如今，英特尔®&nbsp;至强®&nbsp;处理器为机密计算提供了多层次的支持能力。首先是 MKTME——多密钥内存加解密引擎，在数据写入内存时进行实时加密，实现用户数据在内存中的机密性保护，避免了多租户云环境中数据泄露的风险。接下来是 SGX 技术，在内存密态隔离的基础上，提供能够承载用户应用的可信执行环境。第三是 TDX 技术，基于虚拟化扩展了机密计算。TDX 提供的可信执行环境可承载一个完整的虚拟化实例——机密虚拟机。机密虚拟机能够实现用户业务从传统计算模式向机密计算模式的直接迁移，过程中不需要修改用户的应用，可以大大降低应用的迁移成本。</p><p></p><h2>SGX：基于至强®&nbsp;处理器的可信执行环境</h2><p></p><p></p><p>SGX（Software Guard Extensions）是英特尔®&nbsp;处理器架构上的一组扩展指令集，其旨在为所有特权软件（内核、管理程序等）都可能存在恶意行为的计算机上执行的安全敏感计算程序提供完整性和机密性保证。基于 SGX，开发者可以将敏感信息的处理划分到 Enclave 区域，在此区域内运行的程序会受到 CPU 硬件保护。用户还可以使用远程证实（Remote Attestation）确认平台的安全性，并确保交互对象是预期的程序。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/de/de2db761a71cca281456faf38f43ee6e.png\" /></p><p></p><p>在 SGX 的保护下，用户不需要担忧敏感数据被外部应用、系统管理员甚至云厂商自身窃取，即使云端 OS 整体已经暴露在威胁下，Enclave 内的数据依旧可以保障安全。</p><p></p><p>虽然 SGX 提供了目前已知的最高安全保护水平，但它要求用户具备一定的开发和修改应用程序的能力，需要重新对已有的程序进行二次开发，以满足 SGX 的开发模型，其门槛相对较高。对此，英特尔又在至强®&nbsp;处理器上引入了 TDX 扩展指令集，以较低的门槛完全杜绝了云服务厂商与恶意行为方看到敏感数据的可能性，为用户提供了更加易用和安全的数据保护模型。</p><p></p><h2>TDX：承载完整虚拟化实例的 TEE</h2><p></p><p></p><p>TDX 提供了一个能够运行完整虚拟化实例的可信执行环境，也称作机密虚拟机。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1e/1ebcae9bb82ed42f371fd45bd2abad25.png\" /></p><p></p><p>上图是 TDX 的微架构示意。首先，TDX 机密虚拟机数据通过 MKTME 在内存中实现机密性保护。为了防止篡改或是重放攻击，MKTME 还提供了基于密码学的完整性保护。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5b/5bb93ca2ec7fbf45ef8a04fdb1173783.png\" /></p><p></p><p>在虚拟机中，数据的内存保护是最关键的基本组件。在 TDX 环境中，一旦恶意程序试图写入加密内存，就会破坏密码学签名，导致读取时无法通过签名验证，对应的数据就会被标记为损坏，从而可以终止整个 TD。</p><p></p><p>TDX 机密虚拟机是如何构建信任链条的？首先，可信计算环境的构建需要一个 TCB（可信计算基础），也是整个机密虚拟机的信任基础，从安全角度越小越好，从而控制攻击面。TDX 的 TCB 严格控制在处理器层面，包含了处理器层面的基础硬件单元和一些必须的固件库。这样一来，系统 BIOS、操作系统虚拟机控制器都可以排除出机密虚拟机构建的信任链，大大降低了机密虚拟机在构建过程中的安全风险以及构建成本。</p><p>远程证实是用户的可信执行环境启动后进行可信验证的关键环节。TDX 提供了较灵活的远程证实能力，既可以支持机密虚拟机启动过程的验证，也可以根据需要提供运行阶段的验证。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3c/3ccfbf4981c536fbf763e73e49aba9ac.png\" /></p><p></p><p>TDX 的远程证实构建包含两个环节。在平台的分发和启动阶段，英特尔为每颗出厂的处理器签发一个 PCK 证书，作为远程证实的最终根证书，云厂商可以通过英特尔的 PCS 服务将需要的设备根证书缓存到本地，构建自己的远程证实服务。接下来，用户的机密虚拟机启动时会向位于 TCB 中的 TDXmodule 请求生成一组度量报告，包含平台 TCB 的度量信息与机密虚拟机中加载的用户实例的度量信息组。度量报告传输到本地由英特尔发布的安全实例 QE 进行检查，通过之后用根证书签名，送回用户的服务网络，由用户服务网络和云厂商搭建的远程证实中继服务来协同验证，经过验证之后用户才能驱动机密虚拟机的实例进行后续计算。</p><p></p><p>对于机密虚拟机实例数据的隔离，用户的数据、业务逻辑、操作系统内核都在机密虚拟机中运行。TDX 通过 MKTME 为每个机密虚拟机分发一个外界无法访问的私有密钥，当用户的私有数据写入内存时进行实时加密。</p><p></p><p>传统虚拟化技术中，虚拟化实例的状态信息对虚拟机控制器（HyperVisor）是不设隔离的，存在安全隐患。TDX 对用户实例的状态信息用为机密实例颁发的私有密钥进行加密，并结合 TDX Module（位于 TDX 的 TCB 内）提供的访问 API，实现对虚拟机控制器的强隔离。TDX 引入了一个新的 SEAM（安全仲裁）模式，该模式下 TDX Module 是真正的 HyperVisor。TDX Module 运行在 VMX Root 模式下，只能运行在 SEAMRR 寄存器规定的区域内，区域外的软硬件读写均被拒绝。它相当于数据的安全守门员，负责拦截所有有害的外部调用，且不需要开发人员重写程序代码。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/87/87c5a287602ee037f1addbc3ccca26e5.png\" /></p><p></p><p>TDX Module 会向 VMM 提供安全嵌套的页表的管理借口，在机密 VM 中的内存访问、页表操作、模式转换等安全要点都能得到 TDX Module 的保护。TDX 还提供了安全中断传递能力，VMM 无法直接注入中断，只能通过 Posted Interrupt 机制注入特定类型中断，保证 CPU 多核交互符合程序预期，导致系统状态不一致。</p><p></p><p>很多场景需要与外界的 IO 设备进行数据交互。TDX 提供了较为弹性的 IO 访问模型，一种基于共享密钥内存，可以与传统 IO 设备最大化兼容；另外一种是未来的 TDX Connect 技术，可以与外部 IO 设备实现可信的直接内存交互访问。传统 PCIE 设备的硬件链路层一般不支持加密传输。而 TDX 构建的机密虚拟机可以为对应的设备 TEE 创建一个软件端点，与某个设备 TEE 绑定，并协商一个密钥来实现异构 TEE 之间的数据共享、通讯，但这样会带来一定开销。而基于 TDX Connect 的访问模型可以在机密虚拟机和设备 TEE 之间构建一个可信的直接内存访问通道，实现 DMA 和 MMIO 的双向直接访问，消除了共享密钥内存模型的额外开销，有效提升异构 TEE 之间的数据交互效率。</p><p></p><h1>机密计算如何实现场景落地？从阿里云的经验谈起</h1><p></p><p></p><p>阿里云是最早在自身云服务中应用机密计算技术，提升服务安全等级的云厂商之一。阿里云基于可信计算的信任链概念，从应急安全芯片逐级地将信任链传递到虚拟可信与虚拟安全芯片中，再传递到用户的虚拟机中，以保障用户自身的文件、Bootloader 和 OS 的安全。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/af/afba8b472895edffc13c48792aec5332.png\" /></p><p></p><p>针对大模型用户最关心的数据隔离与隐私保护问题，阿里云将英特尔的 SGX 技术用于大模型推理服务，确保用户获得安全可信的使用环境。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ab/ab9086eb17b3247b182bb9464be1d733.png\" /></p><p></p><p>通过这样的模型保护流程，模型的外部使用者就无法看到大模型的整体数据、实际参数，同时他们与模型的交互也对外不可见。在不可信环境下，外部访问者只能获得加密的数据。</p><p></p><p>在实践场景中，这样的保护机制能够赋予用户极高的信任度，使他们能够放心地使用基于大模型的各类服务。例如，当病人向医疗大模型询问病情相关的诊疗意见时，病人在交互中告知大模型的隐私病历信息会受到 SGX、TDX 技术的保护，病人无需担心他人得知自己的病情；企业员工向大模型上传会议速记，希望大模型输出纪要总结时，这些会议信息也不会被云服务商或是企业竞争对手等第三方知晓。前文提到的三星数据泄露事件中，如果 ChatGPT 所在的服务器部署了机密计算能力，三星公司就不需要限制员工向 ChatGPT 询问代码意见的行为。类似地，其他 AI 代码助手也能够在更广泛、更接近企业内部关键研发流程的场景中得到应用，更好地提升企业开发效率。</p><p></p><p>总体而言，考虑到大模型的应用场景天然就需要用户向云端传输大量敏感数据，云厂商在提供大模型服务时几乎必须通过机密计算能力来保障用户的隐私和数据安全性。可以说，机密计算是大模型时代的数据安全基础，也是大模型在各行各业全面普及应用的前置条件。</p><p></p><h1>构筑机密计算生态，为大模型普及保驾护航</h1><p></p><p></p><p>随着大模型技术热潮来袭，机密计算也即将迎来市场爆发。据第三方调研机构 Everest Group 估计，机密计算的市场规模将在五年内增长 26 倍之多。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/90/90d0513b41274a73c8e4f5535e352b17.png\" /></p><p></p><p>除了在云端保护数据安全性，机密计算的应用范围实际还包括了边缘计算和终端设备等场景。例如，物联网的末端传感器同样需要机密计算技术，确保传感器收集到的信息不被恶意第三方获取。如前文所述，英特尔开发的 TDX Connect 可用于云端与终端设备之间的机密数据传输，构建一个从终端 TEE 到云端 TEE 的安全高效传输通道，以较低的计算和通信开销确保敏感数据的全生命周期安全性。</p><p></p><p>机密计算在边缘、终端等场景的应用，也将为大模型的实践开启更多可能性。例如，运行在终端本地的推理模型可以为用户提供更加迅捷的交互响应，为无人车辆、智能家居操控、实时翻译等应用带来更好的智能能力。而这些终端模型又可以通过全生命周期的机密计算通道，利用云端算力来改善输出，增强用户体验。</p><p></p><p>可以预见的是，机密计算的发展需要全行业的共同努力，芯片厂商、云厂商、软件服务商应当通力协作，为机密计算构筑良性发展的生态环境，在软件侧充分发挥底层硬件的能力，确保数据生命周期中每一个阶段都具备高度安全性。同时，行业也需要加强宣传，让更多企业用户和终端消费者了解机密计算的概念，使他们能够从根本上解除对云计算的不信任感。这样一来，行业就能建立云计算，尤其是云端大模型服务的广泛信任框架，解决大模型实践中遭遇的信任挑战，为大模型的全面推广打下坚实基础。我们相信，随着机密计算逐渐成为云服务的标配技术，大模型终将在各行业广泛流行，成为经济发展与数字化转型的关键动力。</p>",
    "publish_time": "2023-09-11 17:31:05",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]