[
  {
    "title": "新的JEP草案发布，将在Java中引入可选空值标记",
    "url": "https://www.infoq.cn/article/CEaVhh13etut5aXzcKwR",
    "summary": "<p>之前我们报道了 JSpecify 1.0.0 版本的发布。这个版本主要引入了类型使用注解，用于指示静态类型的空值状态。</p><p></p><p>与之相关的是，JEP 8303099 草案 最近已对外公布。这个 JEP 探讨了 Null-Restricted 和 Nullable 类型，旨在将可选的空值标记引入到 Java 中。</p><p></p><p>该提案的核心是在类型使用上引入明确的标记——不仅仅是注解，指明在特定使用场景中允许的值是否包括。需要注意的是，这个提案目前还处于初步开发阶段（例如，它尚未获得正式的 JEP 编号），因此其语法在未来有可能会发生变化。尽管如此，目前的提案借鉴了 Kotlin 的标记方式，因此，对于类型，有三种使用方式：</p><p></p><p>Foo! 表示Null-Restricted——这种类型可接受的值不包括；Foo? 表示Nullable——这种类型可接受的值包括 ;Foo 没有明确指定是否接受。</p><p></p><p>使用未加修饰的 Foo 作为默认选项，这样做是为了保持现有代码在编译时的语义不变。</p><p></p><p>目前，该提案要求对于每一个类型的使用都进行注解，即尚不支持将整个类或模块标记为 Null-Restricted（比如像 JSpecify 那样），尽管这个功能可能会在未来引入。</p><p></p><p>这个新特性引入了一种空值转换机制（类似扩展和拆箱转换）。例如，以下这些赋值是被允许的：</p><p></p><p>将 Foo! 赋值给 Foo?；将 Foo! 赋值给 Foo；将 Foo? 赋值给 Foo；将 Foo 赋值给 Foo?。</p><p></p><p>这种属于约束放宽——例如，任何 Null-Restricted 的值都可以被放在 Nullable 的值中。</p><p></p><p>也有窄化空值的转换，例如：</p><p></p><p>将 Foo? 赋值给 Foo!；将 Foo 赋值给 Foo!。</p><p></p><p>这些可能会导致运行时错误，例如尝试将 null 从一个 Foo? 赋值给 Foo!。通常的策略是将这些情况视为编译时警告（而不是错误），并引入运行时检查，如果检测到违反空值界限，就抛出 NullPointerException。</p><p></p><p>请注意，这些例子仅展示了一些基础情况，实际当中可能存在更为复杂的情形。例如，在处理泛型时，编译器可能会面临类型参数的空值属性与其声明的界限不匹配的情况。</p><p></p><p>引入空标记不仅增强了编译时的安全性，还支持逐步采用的策略——首先定义类型允许的空值，然后通过解决编译时警告来逐步优化代码。</p><p></p><p>InfoQ 采访了 Kevin Bourrillion（谷歌核心库团队创始人，现在是 Oracle Java 语言团队成员），深入了解该项目的更多细节。</p><p></p><h3>InfoQ：你能介绍一下你在 Java 空值处理方面的专业背景和相关经验吗？</h3><p></p><p>Bourrillion： 我与其他一些人共同创立了 JSpecify 小组，并一直是主要的“设计师”（这个角色可以被理解为在推动复杂设计决策过程中达成共识的人）。尽管现在我加入了 Oracle，仍然以相似的方式继续参与项目。</p><p></p><h3>InfoQ：这个 JEP 与 JSpecify 的工作有哪些重叠的地方？</h3><p></p><p>Bourrillion： 最终我们将拥有一个支持空值标记的 Java 版本。JSpecify 在精确定义注解语义的含义方面完成了艰巨的任务。这意味着无论项目选择怎样的升级时间表，都将处于一个非常有利的位置，能够从 JSpecify 的注解平滑迁移到语言级别的空值标记——实际上，这种迁移应该是高度自动化的。</p><p></p><h3>InfoQ：JEP 8303099 草案和 Java 5 中添加泛型的方式似乎有一些相似之处。这么说对吗？都是一种编译时机制，大部分信息会在字节码级别被擦除，是这样吗？</h3><p></p><p>Bourrillion： 是的。我们认为类型擦除和所谓的“堆污染”是不得已的妥协，但正是这种设计让特性更容易被广泛采用。这也正是为什么现在几乎看不到原始类型的原因（至少我希望如此！）。空值污染将是一个长期存在的问题，但这没关系！现在全部都是关于空值污染。</p><p></p><p>正如泛型类型信息一样，空值注解在运行时通过反射发挥作用，但不参与运行时类型检查。我很好奇是否会有人基于我们的注解开发一个注入空检查的字节码工具；我认为这可能会非常有用，但也可能存在不值得投入精力的情况；我们只能等待并观察市场和技术社区的反应。</p><p></p><h3>InfoQ：空值限制也是 Project Valhalla 的一个重要话题，不是吗？你能分享一些这个 JEP 草案与 Valhalla 项目正在进行的工作之间的相互影响和互动吗？</h3><p></p><p>Bourrillion： 这实际上是同一个问题；Valhalla 项目是在这个 JEP 草案的基础上进一步构建的。知道哪些值不能为空将有助于虚拟机优化这些间接调用。</p><p></p><h3>InfoQ：从中期到长期来看，JSpecify 应该能够为 Java 语言级别的空值支持提供一个平滑的过渡路径。它已经能够与 Kotlin 的空值支持相协调。对于开发者采用 JSpecify，你有哪些建议？</h3><p></p><p>Bourrillion： JSpecify 目前处于 1.0.0 版本，尽管注解的定义已经相当精确，但规范仍有可能会经历一些细微的调整。所以，如果你现在开始对你的代码库进行注解，你的代码不太可能突然无法编译，但在一些小的规范修订后，你可能需要在某些地方移除或增加一些 @Nullable 注解。</p><p></p><p>如果你发现将空值分析集成到现有的工具链中过于耗时，因为你需要清理所有的警告，那么采用@SuppressWarnings注解是完全可以接受的！虽然这可能看起来不够优雅，但你可以随着时间的推移逐步对它们进行清理。即使这可能需要很长时间，但关键在于新代码从现在开始就有了空值检查，而这才是最需要关注的部分。</p><p></p><p>InfoQ：感谢接受采访！</p><p></p><p>查看英文原文：</p><p><a href=\"https://www.infoq.com/news/2024/08/null-restricted-java/\">https://www.infoq.com/news/2024/08/null-restricted-java/</a>\"</p>",
    "publish_time": "2024-09-14 00:09:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从淘宝用户增长到生成式大模型：5 年，我的思考变了？",
    "url": "https://www.infoq.cn/article/JFNDl34Eol6UZSihy0mO",
    "summary": "<p>作者 | 高嘉峻</p><p>编辑 | Kitty</p><p></p><p></p><blockquote>大模型技术的崛起正以前所未见的方式重塑软件开发领域。它凭借强大的语言生成、理解及创造能力，开启了人机交互的新纪元，是软件开发理念和实践的一次深刻变革。2024 年，QCon 全球软件开发大会以拥抱变化、全面进化为主题，关注技术前瞻性和实用性，提供有价值的行业洞察和参考，旨在帮助技术团队降低探索新技术的时间成本，更快地将创新技术和最佳实践应用到实际业务中。会议即将于 10 月 18-19 日开幕，访问<a href=\"https://qcon.infoq.cn/2024/shanghai/schedule\"> QCon 官网</a>\"了解更多详情。</blockquote><p></p><p></p><h3>题记</h3><p></p><p></p><p>2019 年，我在 QCon 北京站作了一个题为《<a href=\"https://qcon.infoq.cn/2019/beijing/presentation/1469\">淘宝用户增长的 5+1 个策略</a>\"》的分享。彼时 Growth Hacking 的概念进入中国已经过去了 4-5 年的时间，恰逢智能手机用户规模和时长到了第一个平台期，第一波流量红利见顶。那段时间我们在工程上做了诸多创新来应对环境变化给引流获客带来的新挑战，于是我在 QCon 分享了淘宝在用户增长业务上的技术策略和我个人的一些心得。后逢新冠疫情，经济周期，区域争端，生成式大模型，降本增效，被各种关键词轰炸，尤其在大模型的冲击之下，这个世界一定发生了改变。过去几个月我满怀好奇，花了很长时间去了解和学习大模型相关的知识，与许多不同行业和领域的朋友沟通讨论，结合过去我在工程领域积累的知识和经验，总结了以下几个观点与大家分享：</p><p></p><p>用户增长从“用户规模增长”过渡到“精细化用户运营”用户增长是中国另一个“超车”的领域大模型下放更多能力，用户增长更普惠AI 加到底加的是什么</p><p></p><p>5 年前分享的是经验，而今天分享的是想法，主观且有些并未验证，仅供参考。</p><p></p><h3>观点 1 ：用户增长从“用户规模增长”过渡到“精细化用户运营”</h3><p></p><p></p><p>过去相当长一段时间里，我们说“用户增长”其实是在说“用户规模”的增长，甚至于更狭隘的“引流获客”。“用户增长”被认为是一个以 DAU 甚至 MAU 为目标，以引流为主要手段的业务。2019 年以前国内移动互联网用户规模持续扩大，处在巨大的流量红利期，各家互联网产品的首要任务一定是争夺新用户，扩大用户规模。所以我们才会在各种渠道看到“ xxx 亿人都在用的 xxx ”这样的广告词。在这个阶段即使大家也偶有谈起“开源节流”、“长周期运营”等这类的概念，但身体还是非常诚实地都铺在了引流获客，做大注册用户规模上。进入 2020 年后，随着流量红利消失以及在大环境下行的背景下，“用户规模”这个目标被越来越多公司抛弃，转而关注更实质性的指标。也就是在这个阶段很多大厂财报中也不在出现 DAU/MAU 这样的指标了，取而代之的是购买用户（没过多久这个也消失了）、订单数、GMV（一直都在）等。</p><p></p><p>在这样的变化之下，我想我们需要从更本质的角度去解构“用户增长”这个概念。我认为“用户增长”不应该被作为一个业务板块的目标而解释为“用户规模增长”，应该是一种经营视角和模式升级，即：“以用户视角经营以获得业务增长”。 什么是“以用户视角经营”？如果我们以一个消费品牌为例，产品视角是我要卖多少货，看的是 GMV = 笔单价 x 订单数，要关注：有多少个 SKU，销量如何，货单价和利润率是多少，覆盖了哪些渠道，品牌影响力等等。而用户视角则是我要服务多少用户，看的是 GMV = 单用户价值 x 用户数，要关注：我有多少潜在 / 潜力 / 常规 / 忠诚用户，不同分层用户的分布和规模怎样，他们是什么画像，单用户价值等等。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/dd/dd1b6f7426287034630e0547396bc01e.png\" /></p><p></p><p>那么用户视角又好在哪里，为什么更先进呢？我粗浅的解释是：企业赚的钱是用户带来的，一个消费品牌的 GMV 是每一个买家一笔一笔买出来的，一个互联网平台的广告收入是用户一下一下点出来的，所以关注用户更加直接，更接近本质。既然如此为什么要到 2020 年代才出现这个概念，之前大家都在干什么？我认为至少有两个方面因素：</p><p></p><p>一方面是供给侧越发成熟，增长空间向消费侧转移。 如果拿电商平台举例，“中国制造”的供应链经过几十年的发展，在这个时间点上已经非常成熟，甚至开始出现供给过剩的苗头。几家大的电商平台在那个时间点也基本都完成了商家和店铺的原始积累，开始进入治理阶段。整个环境不再是平台找不到卖家，而是卖家需要更多渠道，哪怕是一个新电商平台，只需要通过招商就能快速积累相当规模的卖家，不需要花精力去培养和教育新卖家。推而广之到更多的互联网平台、服务和产品，随着互联网，移动互联网，发展越发成熟，快速搭建一个 B 端形态（平台、服务或产品）成本越来越低，更多的精力要放在 C 端。</p><p></p><p>另一方面“大数据”技术发展给“用户视角”带来了可能性。 过去，数据采集、存储、处理、分析整条链路上的成本都非常高，以至于企业只能承担处理数十个产品 SKU、几百个销售渠道这种量级数据的能力。随着大数据科学的发展，移动互联网普及，从采集到分析整条链路的成本大大降低。只在少数领域（如：金融、高科技等）才有所涉及的数据分析和数据科学方法得以普及，过去公司里辅助少数高层决策的数据支持能力下放到业务一线，处理成百上千万用户数据的成本下降到可接受范围内了，自然用户视角也就应运而生。</p><p></p><p>引流获客和用户规模只是“用户视角经营”的一个角度，或者一个环节。只是在流量红利期这个环节最关键，我们以偏概全的将“引流获客”解释成“用户增长”。当然，概念归概念，到了应用阶段还是要识别重点，有所取舍，必须用一个具体的“环节”解释概念才能落地实施。对于一个新起步的互联网产品来说“规模”是原始积累，仍然是“用户增长”的主要目的，对于绝大部分跨过“原始积累”的产品用“精细化用户运营”来解释“用户增长”更合理，也就是提升单用户价值的重要程度赶上甚至超过用户规模。通俗的说“精细化”就是：通过数据分析和挖掘的方式把用户从各个维度进行细分，针对不同用户群体提供个性化服务，展示不同的产品，制定差异化运营策略，通过这种方式提升单一用户价值，最终获得更高的整体用户价值。这个过程中除了基本的数据采集、存储和分析技术外，还依赖用户模型、用户画像和圈选、A/B 实验、多策略投放、等等技术。随着 IT 技术进步和成本下降很多几年前看起来成本过高的方案在今天都变得可行且有效。而以上提到的各种技术，每一种都值得相当篇幅具体讨论，本文就暂不展开。</p><p></p><h3>观点 2 ：用户增长是中国另一个“超车”的领域</h3><p></p><p></p><p>过去一两个月，在与一些做海外投放业务的朋友交流的过程中，我发现相较于国内流量市场的模式和玩法这几年的飞速进化海外流量市场的发展是很有限的，主流的流量模式还是最经典的那些 CPX 投放，而国内早早就演化出了 RTA、OCPX、DPA 等等新模式。每一种新投放模式的诞生都意味着突破旧模式的瓶颈，把流量精准性和转化率提升一个新台阶。 一个新技术新理念从硅谷传到国内，这又是什么神秘的东方力量在短短几年时间就进化出这么多花样。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/2f/2f7cbdd1648d71e1b51b0d0ea0b20757.png\" /></p><p></p><p>其实也不难想象，主要还是过去几年时间里移动互联网带来了数据大爆炸。首先，超过 12 亿活跃用户的单一市场所生产的数据规模碾压任何一个海外市场，另外，数据伦理和数据合规发展根本不可能跟上数据“爆炸级”的发展速度，带来国内互联网行业在数据规模，数据维度，数据类型，数据流动性等等多个方面都比海外市场有巨大优势。流量红利期空前的获客需求，绝对大规模的数据量，数据合规政策不完善，几个因素叠加：旺盛且多样的需求作为动力，巨大规模的数据体量作为基础，合规尚不完善带来更大的发挥空间，“用户增长（不管是狭义某个具体环节，还是广义的整个模式）”这个托生于“大数据”的概念就必然疯长，在这个过程中不论是方法论，还是技术能力都会快速迭代，不停的进化出更先进的一代。</p><p></p><p>近几年随着国内数据伦理和数据合规越发成熟，数据满天飞的乱象极大程度改善。此外，为了针对过去野蛮发展时期诞生的各种新模式监管部门和企业共同制定了新标准，研发新技术来应对数据风险。最直观的是智能手机设备识别 ID 新标准的 OAID 和 CAID，还有 RTA 模式的人群加密与混淆，数据采集用户协议，等等。这些措施不仅仅推动国内数据伦理和数据合规越来越完善，更主要的是解决问题的同时让这些新模式和新方法得以更加规范、更可持续的运行下去。解决问题的同时，并没有开倒车，很好的保持了先进性。反观海外市场，尤其是北美，是理念和技术的发源地，起初的先进性毋庸置疑，但在以上提到的三个条件（需求、基础和环境）上都不如中国，反而被超车。</p><p></p><p>上述的是我看到在“引流获客”这个环节国内和海外的区别，如果回到“精细化用户运营”这个概念上，我认为国内仍然有孕育出更先进模式和技术的土壤。</p><p></p><p>从需求角度看，所谓的移动互联网下半场从“用户增长”的角度可以理解为：流量红利耗尽，如果完成了用户规模原始积累，要开始关注如何持续提升盈利能力，把规模变成利润；如果尚未完成用户规模原始积累，要探索更先进的获客方式，对冲掉红利耗尽引起的高成本。不管是“提效”还是“降本”无疑更加细分用户，更加个性化的方案，方案和人群匹配更精准是最直接有效的方式。过去的两三年时间里，我们已经看到许多不同规模、形态的互联网平台（服务、或产品）都通过“精细化用户运营”在“提效”和“降本”上取得结果。</p><p></p><p>从数据基础看，不论是数据规模还是可操作性都有成熟的积累。超过 12 亿活跃用户的市场规模，成熟的数据采集和存储方案，过去相当长一段时间内积累的丰富的数据分析方法论和数据应用能力，为精细化用户运营提供了良好基础。</p><p></p><p>从空间上看，经历了刚刚经历流量红利期的跑马圈地，在用户运营上还处在起步阶段，方案相对粗放。在用户识别和细分，以及方案个性化上都还有很大的发挥空间。另一方面，数据伦理和数据合规的政策与技术已经发展的相对完善，相关的风险基本都有相应的应对措施。更主要的是政策和技术并非一刀切的限制企业流转和使用数据，而是提供了合规且有效的方案，支持企业用好数据。这两方面都是做好“精细化用户运营”的空间条件所在。</p><p></p><p>相信在良好的环境和土壤上，建立“精细化用户运营”的观念，做好相关技术建设（数据采集、用户画像、人群圈选、多方案投放、A/B 实验）并形成有效联动，形成体系，我们的“用户增长”一定可以在下个阶段也取得先进性优势。</p><p></p><h3>观点 3 ：大模型下放更多能力，用户增长更普惠</h3><p></p><p></p><p>大模型的发展方兴未艾，我们不得不思考大模型会给“用户增长”带来哪些改变。回看过往技术发展给行业带来改变的历史往往是：新技术造成先进能力成本下降，过往需要消耗较高成本，仅能服务少数人的能力下放到更广泛的范围，更加普惠。数据技术发展造成采集 / 存储 / 分析成本下降，把数据分析和应用能力从服务少数领域下放到多数领域，从服务少数人下放到服务多数人，增长黑客应运而生。我认为大模型技术也将以同样的的方式改变一些领域，以这个范式去看用户增：哪些先进能力消耗成本高，效果好，但应用范围窄，这样的能力是否有机会被大模型跨越式的降低成本。</p><p></p><p>在国内互联网行业，往往大厂的用户增长方法论和技术能力领先行业平均水平。究其原因，大厂有能力在用增业务上投入的预算足够大：</p><p></p><p>场景丰富。 互联网大厂的产品形态丰富，也往往能形成矩阵，有协同效应。而且，在业务预算相对充足，试错空间大。所以在这样的土壤里更容易生长出先进的领域方法论，从业人员也能快速积累专业经验。人才密度高。 不论是聚集足够多行业专家，还是在足够大的业务规模和足够丰富的业务场景下去训练从业人员，都使得大厂用增团队在专业经验和先进理论方面都远远领先行业平均水准。也就是坊间流传的那句话：用增领域的专家都是用钱喂出来的。基础设施完备。 大厂在工程和数据基础能力上比较完备，不论是数据采集、存储和分析的设施，还是营销、实验、乃至数据可视化等工程方案，大厂往往都具备成熟的解决方案，与整个业务的产品矩阵也能很好的协同。</p><p></p><p>大模型能处理极其繁杂的输入信息，并依据输入差异，在一定规则下能规划不同的数据处理逻辑，并给出规则描述下相对最优的结果。放在用户增长领域里，大模型将有机会把诸多过往只有大厂才玩得起的策略下放。</p><p></p><p>机会挖掘： 机会挖掘通常可以包括机会人群和机会策略，具体工作往往属于数据科学领域，通过一系列数据科学技术，发现有机会给整体目标带来有效增长的空间和机会。在海量数据中发现某一画像的用户在特定指标下表现显著低于平均水平，且这部分用户规模能对整体目标带来显著影响，在特定指标下也有提升到一定水平的空间和机会。那么通过数据技术准确定位这个画像的用户并以人群方式与其他业务产品协同，采取针对性业务策略进行干预，这个人群就是机会人群。另一方面，在海量数据中找到产品漏斗中的显著短板或能够实现用户转化的关键方案，也就是利用数据技术发现产品中的问题或机会，用更具体的描述就是找到一个产品的“关键事件（Crystal Event）”和“魔法数字（Magic Number）”。</p><p></p><p>目前我们看到市场上已经出现功能非常强大的 ChatBI 类产品，主要事围绕“文生 SQL ”和“数据可视化”构造的 Agent，这两个能力是数据分析和挖掘的最基本能力。构造内化具体数据分析法或调度机器学习算法的模型，结合数据工程给智能体提供丰富且有效的输入数据，将有机会通过处理海量数据替代传统数据科学家的经验，给出有效的结论。把具备不同确定性能力的模型和功能整合成 Agent，机会挖掘这个门槛相对较高的能力将有效下放到更广泛的使用场景。</p><p></p><p>海量计划：“量变积累质变”在用户增长的诸多策略中屡试不爽，拿效果投放举例：在同一个流量渠道不同的活跃计划规模直接决定了成本优化的上限，国内头部投放业务在市场上的活跃计划数往往能达到数十万甚至百万级，而转化成本与数万级投放计划低 80% 以上。最直观的原因是在更大的投放计划规模下，投放匹配算法和优化手段有巨大的发挥空间，更精细和准确的匹配策略极大程度优化成本，提升效率。投放海量计划的势必消耗高成本，这些成本除了显而易见的生产素材和创建计划，随之而来的优化调整、数据分析、计划治理等工作的成本都随着投放计划规模的提升显著提升。这些随着计划规模提升带来成本提升往往是重复性工作提升和繁杂程度提升。举例来说，分析 1 万个计划的和分析 100 万个计划的投放效果的区别除了效果分析方法的次数相差 100 倍以外，还涉及到解读 1 万个初步结论和 100 万个初步结论的差异，可能出现额外的异常值发现、交叉分析、对比分析等。</p><p></p><p>新技术将有机会通过智能体替代上述这些依赖数据科学家和分析师的专业经验和人工的操作。生成式模型（文生文 &amp; 文生图）辅助生成海量素材，内化投放流程的模型生成投放计划，数据工程回收并以新的结构化要求建立符合 AI 要求的数仓，专注不同数据分析法模型组合而成的数据科学智能体，整合这些不同的功能模块，并通过工程手段有效协同这些功能，将形成一个具备处理海量计划的投放智能体。</p><p></p><p>盯盘优化：除了上文海量计划这种空间维度上规模量变上积累的效果质变，还有时间维度上操作频率量变积累效果质变。任意一个方案的转化效果总会经历效果爬坡期 - 最佳效果期 - 效果衰退期 - 长尾期，最终成为无效果的僵尸方案。往往我们需要在衰退期之前，对方案进行调整尽量延长最佳效果期，甚至寻找二次爬坡；或者用新方案替换旧方案，确保整体策略效果维持在较高水准。这就要求：第一，实时监控方案效果数据，即所谓的盯盘；第二，及时反应快速执行相应操作，或更新，或替换。</p><p></p><p>盯盘和反应两个要求除了对流数据处理和计划治理的工程能力有要求外，还依赖人工操作。当前技术水平完全满足工程能力要求，反而是人工成本是瓶颈，导致我们只能在一些关键时期才能采取这样的高频操作（如：双 11 高峰期，等）。而整合大模型和工程能力的智能体就能很好的解决这个问题，同时盯盘海量计划，并做出及时反应。</p><p></p><p>除了上述举例的三种能力，用户增长和衍生的各项业务中还存在大量能力下放的可能性，对中小企业是一个享受技术红利的机会，对于大厂来说则是一个突破能力瓶颈再上一个台阶，或者大幅降低成本的机会。</p><p></p><h3>观点 4 ：AI 加到底加的是什么</h3><p></p><p></p><p>从“用户增长”领域延展开去，在 AI 革命如火如荼的今天有哪些更抽象的方法论？我花了更长时间在 ToB 方向的工具类产品的思考上，因为我认为任何产品一定会存在“能力”与“易用性”之间的权衡和取舍，而 ToB 工具倾向“能力”更强，而 ToC 则倾向于“易用性”更高。所以，往往一项新技术更容易在 ToB 领域先被应用，随着技术逐步成熟会延伸到 ToC 领域，影响更多人，直到改变世界。显然当下 AI 大模型还处在成长期，应用在 ToB 工具上的可行性更高，基于此我片面的认为：</p><p></p><p>模型训练 vs 应用建设</p><p></p><p>模型训练（包括微调）是素质教育和能力训练，应用是职业培训和工作流程。在设计智能应用的过程里我们常常会取舍：一个功能到底是通过微调实现，还是通过工程（ RAG/Agent/Prompt ）方式实现？回答这个问题我们要先认知“模型”本身具备哪些优势，以及应用过程中的局限性会带来哪些劣势。讨论上述问题其实是讨论一项“知识”要通过什么方式被模型习得。</p><p></p><p>无论是基模训练还是微调都是干预模型本身使其习得知识。优势在于知识内化在模型内部，这部分“补充知识”能更好的与基础知识融合，应用过程中能模型能给出更协调、整体性更好的专业输出。内化“专业知识”的模型也更容易扩展，扩大使用范围除了支付额外算力外，几乎没有其他成本。</p><p></p><p>模型训练和应用两个过程是割裂的，模型训练是一个离线操作，而应用则是在线过程。离在线本身存在实时性的矛盾，而且模型训练（尤其是基模训练）的高成本会进一步放大这个矛盾，使得习得“补充知识”的实时性差，调整周期长。基于此，我认为稳定的知识（或能力），如：计算能力、编码能力、分析方法等可以考虑通过训练内化到模型中（当然不是一定，而是可以考虑）。而相对不稳定的（生命周期短会快速失效的，演化速度快需要高频更新的，个体差异大存在及时差异的，等）知识（或能力）就要采取能应对高频迭代的方案，如：RAG、Agent、提示工程等。通过更加成熟，成本更低的操作来应对这里的“不稳定”，如：爬虫 + 标记工程支持的信息库可以把不稳定的知识迭代转化为“治理”问题。</p><p></p><p>另外，基模训练和应用过程的模型训练（微调）也存在割裂，简单的说通过微调给基础模型带来的增量能力很难继承到一个更新版本的基础模型中，又或者微调增量与新版本基模的适应程度存在极大不确定性。更何况当前基模的版本更新往往会带来能力跨越式提升，很可能出现新版本基模在处理具体问题的能力上甚至优于微调过的旧版本模型。</p><p></p><p>所以，对于绝大多数 AI 应用来说要谨慎参与训练，更多思考是否能把新问题转化为老问题，使用更可控的方案解决。更可控的方案不仅意味成本可控，更重要的是我们能更好的控质迭代节奏，使能力迭代（演化）过程更可控。</p><p></p><p>交互升级背后的信息模型</p><p></p><p>最适应大模型，大语言模型，的交互方式一定是“对话式”交互，“对话式”交互在易用性和灵活性上带来的提升显而易见。但我认为集成大模型能力的新产品如果仅仅带来“灵活性”和“易用性”的提升，知识在降本上做到了有限的“量变”。想要在能力提升上制造“质变”，需要重构更底层的范式。从信息模型的角度去看产品，传统设计中往往有两个角色：使用者和工具。产品流程的信息流是单向的：从使用者流向工具，工具通过既定流程处理信息，把结果反馈给使用者。最典型的就是 SaaS 应用，通过把专业经验和先进方法论固化成工具流程（表单串联）来输出价值，使用过程中也是典型的使用者向工具的单向输出。</p><p></p><p>大模型的加入有机会让这个“使用者 - 工具”范式进化成“使用者 - AI - 工具”三种角色的范式。AI 之所以能被认为是一个独立角色，而非是对使用者或工具的改造，最重要的原因是 AI 成为能把独立信息引入系统的信息源，并改变系统中的信息流向。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/37/37d18506a680f06ef31e75335f6f3519.png\" /></p><p></p><p>使用者和 AI 二者之间建立双向信息流，“使用者 -&gt; AI ”的信息流是对经典的“使用者 -&gt;工具”信息流的升级的一部分，是使用者为系统输入信息，最典型方式的就是提示词。“AI-&gt; 使用者”的信息流是创造性的，AI 为系统输入信息，通过对话的方式给使用者提供建设性灵感或建议。以典型的电商智能商品管理工具，AI 能通过阅读 VOA，读取热销商品，获取热点资讯等方式转化为 AI 的知识，在管理商品的交互中为用户提出更符合市场环境、更匹配用户需求的商品结构和内容建议。“AI-&gt; 工具”信息流是对“使用者 -&gt; 工具”升级的另一部分，一方面通过更直观的“对话”式交互提升执行效率，更重要的是编排更个性化的执行流程，创建“最恰当接”。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/4a/4a7f2f7fe79f41f6478f671e6fec69ee.png\" /></p><p></p><p>由于系统的信息流从一条变成三条，所以为了应对这个升级就需要一个具备调度能力的中控模块，这是经典范式不具备的。另外，新范式最重要的变化是 AI 成为系统新的信息源，这也是新范式最大价值所在，所以 AI 信息源的丰富度和准确性运营是这个系统能力水准，甚至系统是否具备进化能力的关键所在。</p><p></p><p>AI 原生架构的技术红利</p><p></p><p>上文提到了各种应用模式和设计范式的区别，这些理论能够落地执行依赖技术架构的升级。还是以 SaaS 应用举例，我称传统 SaaS 的架构为“ Function-Based ”基于功能的架构，具体的就是对系统功能极致抽象为灵活性提供支持，基于专业经验和先进理论对极致抽象过的功能做整合，成为由表单和按钮串联的工具链。这个 SaaS 的价值体现在通过工具链体现出来的经验和理论，以及支撑这些经验和理论得以执行的功能抽象，是通过“最优解”发挥作用。新范式两个关键点是：动态编排流程和引入新信息源，“AI-Based”基于人工智能的架构就需要适应并放大这两点进化。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/33/33bae8cc90b811e0d88ec5ba70323503.png\" /></p><p></p><p>寻找“最恰当解”问题具体的是把抽象功能点动态编排为流程，通过“对话”式交互对使用者屏蔽动态编排大量流程可能带来的易用性灾难。基于此，对系统功能不仅仅要极致抽象，每一个抽象的功能点要有同构的接口协议，并且被明确标注每个功能的作用，为 AI 自主编排功能流程打好基础。无论是使用垂直领域的小模型，还是通过微调或其他工程手段构建的智能体，把抽象功能和协同作为知识传递给 AI，利用大模型推理出最恰当的组合方式。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/4c/4cf1a9146e0e00b590eabde6b626ecb2.png\" /></p><p></p><p>更重要的 AI 信息源丰富度和准确性问题可以被转化为数据工程和数据治理问题。建立多种信息获取方式多渠道持续更新获取有效信息，通过数据工程合理组织数据结构建立信息数据库，建立数据治理机制保证信息数据具丰富实时有效，通过 RAG、提示工程等方式建立模型读取数据、定位数据通道。做好 AI 引入新信息的储备和通道，通过持续提升 AI 引入信息的数量和质量提升系统能力。</p><p></p><p>上述的 AI-Based 架构仅仅是一个非常“形而上”的理念，甚至不能称其为理论。一个好的应用架构，除了需要一个先进理念作为起点，更重要的是要结合具体的系统目标和实际技术能力，进行合理的创新和取舍。这段内容或许不能说明什么是好的智能系统架构，但至少能描述什么是未能摆脱传统模式的架构。</p><p></p><p>本文总结的 4 个观点是我对过去一段时间「用户增长」的个人思考和沟通交流的简单总结，可能有一些局限性，但是我当下认知水平下对于 AI 的理解。未来，我希望能有更多机会去实践和验证这些观点，能结合具体领域具体目标把这些“形而上”的理念转化成具有实践经验支撑的理论总结。也希望未来能有更多机会跟不同领域和行业的朋友进行更多交流，吸取更多信息，逐步加深对 AI 应用的理解。</p><p></p><p>会议推荐</p><p>AI 应用开发、大模型基础设施与算力优化、出海合规与大模型安全、云原生工程、演进式架构、线上可靠性、新技术浪潮下的大前端…… 不得不说，QCon 还是太全面了。现在报名可以享受 9 折优惠，详情请联系票务经理 &nbsp;17310043226 咨询。</p><p><img src=\"https://static001.geekbang.org/wechat/images/c8/c87f0820b187f4ea98d5fe2bdce0f4c1.png\" /></p><p></p>",
    "publish_time": "2024-09-14 11:39:49",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "该挤掉“大数据+AI”的泡沫了？",
    "url": "https://www.infoq.cn/article/AXoAMdovP9xjLyQrgatr",
    "summary": "<p>在腾讯全球数字生态大会上，极客邦科技创始人和CEO霍太稳与腾讯云的专家黄世飞、Elastic 专家张君侠就AI大模型和大数据之间的关系和应用进行了交流。他们讨论了AI for data和data for AI的概念，强调了大数据和AI之间的相互促进关系。</p>\n<p>讨论中提到，大模型的爆发引发了对大数据技术的关注。虽然大数据技术本身在讨论中热度不算高，但实际上，数据仍然扮演着重要的角色。随着AI时代的来临，大数据技术需要适应新的需求，包括对算力、存储性能和弹性能力的提升。此外，大数据技术也需要与AI技术相互融合，以支持大模型的训练和应用。</p>",
    "publish_time": "2024-09-14 11:45:15",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "RAG风口十问：大数据与AI是价值落地还是过度炒作？",
    "url": "https://www.infoq.cn/article/RtEJ34DXUR8ObbtXr1Td",
    "summary": "<p>过去一年多，RAG（检索增强生成，retrieval augmented generation）正成为大数据与 AI 融合的“新宠”。想象一下，当你用 AI 助手快速总结论文或分析数据时，背后可能已经是 RAG 技术在默默发力。</p><p>显而易见，随着生成式 AI 如 ChatGPT 的兴起，“<a href=\"https://qcon.infoq.cn/2024/shanghai/track/1713\">大数据 +AI</a>\"”的热度不断飙升，特别是在 RAG 技术的加持下，它们的结合为企业创造价值的潜力正逐渐被认可。</p><p></p><p>不过，技术的发展总是伴随着质疑和探索。虽然很多人看到这股潮流的迅猛发展，但也难免心生疑惑和不安：大数据和 AI 的融合到底是不是又一轮泡沫？它所谓的价值是什么？具体要怎样才能借助 AI 与大数据来提升竞争力？<a href=\"https://qcon.infoq.cn/2024/shanghai/presentation/6047\">RAG </a>\"为什么这么火爆？</p><p></p><p>带着这些疑问，日前极客邦科技创始人兼 CEO 霍太稳与腾讯云副总裁、腾讯云大数据负责人黄世飞，Elastic 大中华区副总裁张君侠展开了一场<a href=\"https://www.infoq.cn/video/AXoAMdovP9xjLyQrgatr\">对话</a>\"。本文基于本次对话中的讨论整理而来，深入探讨“大数据 +AI”的真实价值、RAG 技术如何从这浪潮中突围，希望能为大家应对这一波技术变革提供一些启发。</p><p></p><p></p><p></p><p></p><h2>1 Data 加 AI 真有价值？&nbsp;&nbsp;</h2><p></p><p></p><p>对于屏幕前的你来说，当在电脑端想要搜索一些知识点或寻找答案时，你是会选择传统搜索引擎，还是像 ChatGPT 这样的 AI 平台？同样地，当你希望能快速了解一篇论文的要点时，会不会直接让大模型帮你做个总结？</p><p></p><p>从 C 端用户的反馈来看，通用大模型无疑已经逐渐渗透进日常工作，特别是在那些比较简单、重复性的任务上，AI 的效率优势显而易见。</p><p></p><p>不过，这只是 AI 大模型的其中一面。在企业级应用、专业性更强的 B 端场景下，大模型是否同样带来效率提升呢？</p><p></p><p>我们倾向于认为答案是正面的。尤其是在 RAG 技术的推动下。RAG 正在成为数据 +AI 的主流应用方案。根据 InfoQ 的统计，RAG 技术在今年的多场技术大会上成为了焦点之一。而且从 arXiv 上与 RAG 相关的文章数量来看，年初时还比较少，而到了年中，相关研究已经呈现显著增长，几乎每天都有新论文发表。这说明，RAG 技术的受欢迎程度在工业界、产业界和学术界正逐渐成为共识。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a7/a711274c7918dd5ee2c17b407df14ca1.webp\" /></p><p></p><p>黄世飞指出，过去很多企业虽然积累了大量数据，但未能充分利用它们。如今，大模型技术，尤其是结合 RAG 解决“幻觉”、私域数据使用等问题，便可以有效提升这些数据的应用，解决企业在生产和服务中的实际问题。</p><p></p><p>张君侠也提到，大模型的价值已经逐渐被全球范围内的企业认可，越来越多的项目开始落地，企业纷纷试水 AI 和数据的结合，探索它们能带来的效率提升和业务价值。但在实际应用中，企业也遇到了一些难题，主要集中在具体场景的落地和数据的处理方式。他强调，数据仍是 AI 应用的基础，无论 AI 模型多么强大，数据的质量和有效性决定了其能否在实际业务中创造真正的价值。</p><p></p><h2>2 为什么大数据“不够火”？</h2><p></p><p></p><p>大模型很火、AI 很火、RAG 也很火，但大数据技术本身却似乎没有那么火。</p><p></p><p>“大数据依然非常重要，只是目前它被大模型的光环所遮盖。”黄世飞表示，虽然 C 端用户更关注体验和产品，但要构建一个好的大模型，算力、算法和数据依然是三大要素，而数据的收集、处理和清洗仍是关键，很多公开的大模型没有对外披露如何处理数据，这部分的工作往往被忽视。</p><p></p><p>从企业和市场的角度来看，业界常讨论的“AI for data”或者“data for AI”，也不会是一个“谁主导谁”的问题。数据和 AI 是相辅相成的。大模型的性能不仅依赖于 AI 的算法和算力，要产生好的 AI 模型，首先还是需要大量且高质量的清洗数据。有时候，一些较小的模型，尽管参数规模不如大的模型，但因为数据质量高，表现反而更好。</p><p></p><p>同时，AI 的发展对大数据技术提出了新的要求，特别是在云原生和弹性计算方面。以大模型训练为例，正常情况下只需几百核的算力，但在处理大规模数据时可能需要扩展到几万核，对大数据系统的弹性能力提出了非常高的要求。此外，随着数据量的增长，降低成本和提升存储性能也是大数据领域未来发展的核心。而这正是黄世飞领导的腾讯云大数据部门的工作重点，给企业提供一个轻快易用的智能大数据平台满足这些需求。</p><p></p><p>“企业仍在不断寻找利用好这些数据的新方法，数据量的爆发只会让这个过程加速。没有过去的大数据技术，就不可能有今天的大模型。”张君侠补充道。</p><p></p><p>总之，大数据从未远离，它始终是 AI 背后不可或缺的支撑。无论是过去、当下，还是未来，数据的管理和应用仍然是核心。</p><p></p><h2>3 为什么数据质量很重要？</h2><p></p><p></p><p>大模型本质上是通过数据训练出来的网络，网络中的权重反映了数据的知识结构。因此，大模型本身就代表了数据与 AI 的融合。</p><p></p><p>要训练出一个好的大模型，数据的质量至关重要。通常需要先收集大量数据，可能达到几十个 PB，但经过清洗和去重处理后，实际用于训练的数据可能只有几个 T。而这个过程十分关键，因为数据量越大，对算力的需求就越高，数据清洗则可以降低计算资源的消耗。</p><p></p><p>从技术流程来看，数据从收集、清洗到用于模型训练的每一步，都离不开大数据系统。腾讯云提供了从数据的收集、处理、开发到训练的全流程支持，确保数据与 AI 深度融合。通过这套方案，开发者和企业可以更便捷地训练出他们所需的模型。</p><p></p><p>而从另一角度看，模型训练完成后，AI 反过来也能帮助优化大数据分析。黄世飞表示，过去，他们需要依赖经验去诊断大数据系统中的问题，但现在，AI 可以通过分析日志和诊断信息来辅助判断。以前可能使用规则引擎，今天大模型让 AI 能够更灵活地处理大数据的复杂问题。</p><p></p><h2>4 企业如何更好地应用 AI？</h2><p></p><p></p><p>实际上，不管是制造业还是其他行业，AI 的应用都依赖于数据平台。比如，生产中的每一条数据都可以视为一个标签，通过 AI 挖掘这些标签与其他数据的关系，就能生成可操作的商业洞察。无论是 AIOps、BusinessOps，还是制造业中的生产优化，AI 都能通过数据分析帮助企业提升效率和决策能力。</p><p></p><p>张君侠进一步解释，AI 还可以处理复杂的操作流程和知识管理。过去，工业领域的操作人员需要依赖手册查找机械操作步骤。如今，通过大模型，AI 可以有逻辑地给出精准的操作指令，减轻操作人员的负担。</p><p></p><p>此外，数据平台的核心在于如何高效导入、处理和展示数据，而 AI 也能够显著提升这一过程的效率。黄世飞举例提到，过去，理清某个数据字段的血缘关系是一项复杂的任务，而现在 AI 可以迅速梳理出数据的来源与关系，提升开发效率。此外，AI 还能帮助自动检测代码错误，大幅提高开发者的生产力。</p><p></p><p>未来，数据平台中很可能会引入 AI 助手，进一步辅助开发者完成数据分析、优化数据处理流程，这将是 AI 赋能数据平台的一个重要发展方向。</p><p></p><p>在讨论企业如何更好地应用 AI 时，黄世飞建议，如果企业已经积累了一定量的数据，可以从小模型或中型模型入手，利用 RAG 方案提升业务效率。如果企业在技术能力方面有限，也可以借助业界的 SaaS 解决方案，从小场景入手，逐步引入 AI 和数据分析技术。</p><p></p><p>张君侠则补充说，传统企业的数字化转型很大程度上取决于文化的转变。如果公司能够将 IT 视为核心资产而非单纯的成本，就能更好地应用数据和 AI 技术，提升整体的业务竞争力。</p><p></p><h2>5 AI+Data 能否超越 Excel</h2><p></p><p></p><p>随着 AI 和数据技术的深度融合，开始出现这样的声音：是否会有一个工具能够超越 Excel，成为数据分析的“新王者”？</p><p></p><p>黄世飞认为，这是完全有可能的。不可否认，Excel 是一款非常强大的工具，几乎可以处理各种类型的报表和分析任务。但是，它的操作门槛较高，用户需要对各种函数有深入的了解，才能真正发挥它的全部功能。对于许多非技术用户来说，这是一个巨大的障碍。</p><p></p><p>“未来的 AI 可能会通过简化这些复杂的操作过程，让数据分析变得更加简单直观。”黄世飞表示，AI 可以通过自动化生成分析过程来帮助用户。用户只需要提出他们想要的结果，AI 就能根据需求选择合适的函数和方法来完成任务。这样的工具将不再依赖用户的专业知识，而是通过 AI 的智能支持，极大降低了使用门槛。</p><p></p><p>除了操作门槛，Excel 的另一个局限性在于它的性能限制。随着数据量的增加，Excel 在处理大型文件时往往会变得非常慢，甚至会导致文件崩溃。而如今，数据量的爆炸式增长已成常态，几百兆甚至上 GB 级别的文件已经不足为奇。</p><p></p><p>云计算有望解决这个问题。云上有强大的存储和计算能力，处理几百 G 甚至 TB 级别的数据都不在话下。如果未来能开发出类似“云 Excel”的应用，将数据存储在云端，并通过云计算来处理，那就能够打破当前 Excel 的数据量限制。</p><p></p><p>因此，未来的应用可能通过两个关键途径超越 Excel：一是通过 AI 简化数据分析的过程，让用户不再需要熟练掌握复杂的函数和操作；二是通过云计算扩大数据存储与处理的能力，打破当前 Excel 在数据量和性能上的限制。随着数据量的持续增长，未来对这种工具的需求也会越来越强烈。</p><p></p><h2>6 为什么是 RAG ？</h2><p></p><p></p><p>大模型的“幻觉”问题，指的是在复杂逻辑推理中，模型生成的结果可能与真实情况不符。而 RAG 的引入，成为当下解决这一问题的重要技术方案。</p><p></p><p>黄世飞指出，RAG 的优势不仅在于解决“幻觉”问题，还包括快速更新知识库和弥补专业领域数据不足的问题。</p><p></p><p>解决这些问题的过程实际上涉及数据的向量化。向量化本身是一个复杂的过程，需要将数据转化为向量形式。许多现代的数据仓库和数据库都支持向量化，而与 Elastic 合作的优势在于其数据生态系统支持直接通过内置的能力完成数据的向量化处理，用户无需导出数据到其他向量数据库，对于混合检索有天然的优势。</p><p></p><p>他以腾讯的微信读书项目为例，用户可以通过标记文字自动获得相似观点的推荐，过去这个功能是通过传统的文本检索方式实现，但有时候文本检索并不能获得最佳结果。向量检索则可以提供更好的推荐结果。同时，通过腾讯云ES的一站式 RAG 系统不仅能提高检索的准确性，还大幅降低了资源消耗——从原来的纯内存 400 台 64G 机器下降到 30 台。</p><p></p><p>除了探索应用，腾讯云也在积极参与 RAG 技术标准的落地。今年早些时候，腾讯云 ES 参与了中国信通院组织的检索增强生成（RAG）技术专项测试，并率先完成全部测试内容，展示了其在向量化处理和混合检索方面的能力。此外，作为核心参编企业之一，腾讯云参与了《检索增强生成（RAG）技术要求》标准的制定，与业内专家共同推动了这一技术标准的落地。</p><p></p><p>张君侠补充道，大模型有时候无法控制返回的答案，因为它太智能了。这时候，RAG 可以帮助他们构建自己的私有知识库，确保大模型生成的答案符合企业需求。当然，有人可能觉得这是对大模型的限制，但对于企业应用来说，建立一个安全、可靠的知识库是至关重要的。我们通过 RAG 技术，帮助客户将他们的知识库构建在 ELK 系统中，确保了数据安全和答案的准确性。</p><p></p><p>展望未来，黄世飞认为，不同场景对向量化的需求不同，因此作为技术服务商也需要支持更多样化的 embedding 技术，才能更好地应对多样化的场景需求。</p><p></p><h2>7 数据分析门槛降低？RAG 是否更适合专业人士</h2><p></p><p></p><p>过去，生成报表和进行复杂数据分析往往需要专业的技术能力。而如今，AI 与数据的结合让用户可以通过自然语言完成数据分析，大大降低了数据分析的门槛，尤其是对非技术背景的用户而言，这无疑是一种便利。以腾讯云的 ChatBI 为例，这款基于大模型构建的智能数据助手，通过对话即可生成图表和分析结论，简化了繁琐的数据处理步骤，让更多用户能够参与到数据驱动的决策过程中。</p><p></p><p>然而，尽管像 ChatBI 这样的 AI 工具让数据分析变得更简单，考虑到 RAG 技术的投入和成本因素，眼下似乎更适合专业人士使用。AI 大模型的普及是否能真正降低数据分析的门槛？</p><p></p><p>张君侠认为，RAG 技术的确已经讨论了一段时间，随着大模型的普及，RAG 的应用越来越广泛。尤其是在利用 AI 进行数据检索和生成时，RAG 提供了极大的便利。不过，高昂的专业服务费用仍是一大痛点，许多客户都提到这是他们面临的挑战之一。</p><p></p><p>如果大模型技术能够进一步普及，并且降低使用成本，接下来就会有更多非专业用户能更容易地使用这些技术，而不仅仅局限于专业人士。“Elastic 一直致力于为企业提供强大的数据分析解决方案。我们与腾讯的深入合作也表明，大模型技术的应用正在加速推进。”</p><p></p><h2>8 开源与大数据</h2><p></p><p></p><p>腾讯云长期以来在 Elasticsearch 项目中贡献了大量代码，最近 Elasticsearch 官方亦特别发文感谢腾讯云对开源社区的贡献，这也体现了开源社区在大数据发展中的重要作用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/61/61efcf59e13d1d2666da8130853aaa8c.webp\" /></p><p></p><blockquote>“迄今为止，腾讯云在 Elasticsearch 项目中积极参与，提交了 204 个 PR（Pull Request），其中有 150 个已经成功合并到 Elasticsearch 的代码库，是 Elasticsearch 社区目前已知的第三方公司维度最高的贡献水平，这不仅彰显了腾讯云在技术上的强大实力，也充分展示了他们对开源社区的深厚承诺。”</blockquote><p></p><p></p><p>回顾大数据的 20 年历史，我们可以清晰地看到，开源与大数据的成长紧密交织，推动了彼此的进步。</p><p></p><p>黄世飞提到，早在 2000 年代初期，虽然大数据的概念已经提出，但技术实现还不成熟。当时传统的数仓分析在处理较小的数据集时还能勉强应对，但面对日益增长的互联网数据量，传统数仓显得力不从心。正是在这个阶段，雅虎等公司通过开源引领了大数据的革命，Hadoop 等项目的诞生开启了大数据时代。</p><p></p><p>从 Hadoop 的离线批处理到实时处理技术的兴起，Spark Streaming、Storm、Flink 等开源项目相继涌现，推动了大数据应用的快速迭代。开源社区的力量让这些技术得以迅速演进，企业因此能在短时间内应用最前沿的工具。黄世飞指出，虽然早期闭源开发可能会带来一些短期优势，但开源社区的协作力量不容小觑。开源项目的迭代速度往往能超越闭源系统。</p><p></p><p>近年来，腾讯云始终贯彻“开源开放”的理念。黄世飞表示：“坦白说，我们很多能力是从开源社区汲取的。当然，我们也做了很多改进，尤其是在适配云原生和增强方面，从服务过程中得到了客户的认可。”他进一步阐述道，“饮水思源，我们也希望回馈社区，这也是我们大数据体系的基本思路。既然我们从中获益，那么我们就应该把一些能力反馈给社区。”</p><p></p><p>除了 Elasticsearch，腾讯团队还在多个开源项目中积极贡献代码。黄世飞强调，腾讯云愿意继续坚持这条开源之路，和全球的开发者一起推动技术进步。</p><p></p><h2>9 数据分析市场在本土和海外有何不同</h2><p></p><p></p><p>在国内市场，企业在选择数据分析产品时，最关注的往往是成本和投资回报率。许多企业会优先考虑自建系统，如果外部产品的成本高于自建，他们可能会选择放弃购买外部产品。因此，确保产品的成本优势，是很多服务商设计产品的首要任务。</p><p></p><p>此外，国内企业客户对服务的即时性有着很高的要求。他们习惯于通过即时通讯工具获得服务支持，并期望遇到问题时能够迅速得到回应。相比之下，<a href=\"https://qcon.infoq.cn/2024/shanghai/track/1717\">海外</a>\"客户则更习惯于通过提交工单或邮件的方式获得支持，也更习惯通过阅读详细的文档来解决问题，如果文档解决不了，才会进一步寻求支持，所以文档的完善、本地化和英文化也很重要。</p><p></p><p>同时，由于海外市场的企业代码能力很强，他们更倾向于通过 API 将外部服务集成到自建平台中，而不是依赖官方的控制台，因此产品模块要足够灵活，才可以通过 API 进行高效对接。</p><p></p><h2>10 大数据 +AI 时代，人才何去何从</h2><p></p><p></p><p>“大数据 + AI” 快速发展，企业面临着技术变革带来的挑战，员工的职业发展也因此充满了更多的不确定性和机遇。如何在大数据和 AI 时代下，抓住机会提升自我，是许多职场人关心的话题。</p><p></p><p>对此，张君侠认为，不安定的环境往往是学习新技能的最佳时机。他强调，在技术变革下，最重要的是敢于走出舒适区，主动学习那些你尚未掌握的技能。无论是 IT 技术还是其他领域，个人和公司的成长都发生在不安稳的状态下。因此，面对大数据和 AI 技术的不断进步，不要害怕新技术，反而要主动去掌握它们。并且不要等别人先尝试，要成为第一个行动的人，“to be the leader，not the follower。”</p><p></p><p>黄世飞从另一个角度探讨了大数据和 AI 技术对人才培养的实际影响。他指出，今天的学习门槛相比以往已经大大降低。过去可能需要花很多时间买书、看视频，而现在，AI 技术本身就能帮助我们更有效地获取知识。例如，大模型可以快速搜索文献、资料，极大地提升了学习效率。因此，学习条件的提升意味着我们更有机会掌握新的技能，关键在于是否愿意付出时间和精力。</p><p></p><p>除了学习，黄世飞还分享了他对职业发展的看法。他认为，艰难的环境反而是磨炼个人心智的好时机。“在困难时期，很多人会选择放弃，但如果你能坚持下来，等到形势好转时，你会发现机会更多。” 他建议在艰难时刻保持耐心，不要急躁，利用这段时间积累技能，等待机会的到来。</p>",
    "publish_time": "2024-09-14 11:50:58",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]