[
  {
    "title": "Java近期新闻：JDK 21 序列集合、JDK 20 向量API、Gen ZGC、Hilla 2.0",
    "url": "https://www.infoq.cn/article/P1vXcLlwewcK5XQQIQdN",
    "summary": "<p></p><h4>OpenJDK</h4><p></p><p>在过去的一周，经过评审后，JDK 20提案JEP 438（<a href=\"https://openjdk.java.net/jeps/438\">Vector API第5轮孵化</a>\"）从Proposed to Target状态<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-March/007444.html\">提升</a>\"到Targeted状态。在<a href=\"https://openjdk.org/projects/panama/\">Panama项目</a>\"的支持下，该JEP融合了针对前4轮孵化反馈的改进：JEP 426（<a href=\"https://openjdk.org/jeps/426\">Vector API第4轮孵化</a>\"）在JDK 19中交付；JEP 417（<a href=\"https://openjdk.java.net/jeps/417\">Vector API第3轮孵化</a>\"）在JDK 18中交付；JEP 414（<a href=\"https://openjdk.java.net/jeps/414\">Vector API第2轮孵化</a>\"）在JDK 17中交付；JEP 338（<a href=\"https://openjdk.java.net/jeps/338\">Vector API首轮孵化</a>\"）在JDK 16中作为<a href=\"https://openjdk.java.net/jeps/11\">孵化器模块</a>\"交付。JEP 438提议增强Vector API，根据JEP 424（<a href=\"https://openjdk.java.net/jeps/424\">外部函数和内存API预览</a>\"）的定义，从MemorySegment中加载和向MemorySegment存储向量。</p><p>&nbsp;</p><p>JDK 21提案JEP 431（<a href=\"https://openjdk.org/jeps/431\">序列集合</a>\"）已经从Candidate状态<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-March/007447.html\">提升</a>\"到Proposed to Target状态。该JEP提议引入“一个新的接口族，用于表示集合的概念，这些集合的元素按照预定义的序列或顺序排列，它们是作为集合的结构属性。”这一提案的动机是由于集合框架中缺乏预定义的顺序和统一的操作集。评审预计将于2023年3月16日结束。要了解更多关于JEP 431的更多细节，可以阅读<a href=\"https://www.infoq.com/news/2023/03/collections-framework-makeover/\">InfoQ的这篇新闻报道</a>\"。</p><p>&nbsp;</p><p>在过去的一周，JEP 439（<a href=\"https://openjdk.org/jeps/439\">Generational ZGC</a>\"）从Draft 8272979状态<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-March/007457.html\">提升</a>\"到Candidate状态。这个JEP提议“通过扩展Z垃圾收集器（ZGC）来为年轻对象和老对象维护单独的代，以此提高应用程序的性能。这将使ZGC能够更频繁地收集年轻对象，它们往往会在年轻时死亡。”</p><p>&nbsp;</p><p>Oracle首席产品经理<a href=\"https://www.linkedin.com/in/dalibortopic/\">Dalibor Topic</a>\"曾<a href=\"https://mail.openjdk.org/pipermail/jdk6-dev/2023-February/003712.html\">提议</a>\"解散并归档JDK 6项目，原因是：过去两年没有明确的项目负责人或邮件列表流量；过去四年的访问量为0。InfoQ后续将带来更详细的新闻报道。</p><p>&nbsp;</p><p></p><h4>JDK 20</h4><p></p><p>JDK 20仍处于<a href=\"https://openjdk.java.net/jeps/3#rc\">发布候选</a>\"阶段，GA版本预计将于2023年3月21日发布。<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-20%2B36\">Build 36</a>\"仍然是JDK 20<a href=\"https://jdk.java.net/20/\">早期访问构建</a>\"的当前构建。要了解关于这个版本的更多细节，请查看<a href=\"https://jdk.java.net/20/release-notes\">发布说明</a>\"。</p><p>&nbsp;</p><p></p><h4>JDK 21</h4><p></p><p>JDK 21的<a href=\"https://jdk.java.net/21/\">早期访问构建</a>\"<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-21%2B13\">Build 13</a>\"也于上周发布，其中包括来自Build 12的<a href=\"https://github.com/openjdk/jdk/compare/jdk-21%2B12...jdk-21%2B13\">更新</a>\"，该更新修复了各种<a href=\"https://bugs.openjdk.org/issues/?jql=project%20%3D%20JDK%20AND%20fixversion%20%3D%2021%20and%20%22resolved%20in%20build%22%20%3D%20b13%20order%20by%20component%2C%20subcomponent\">问题</a>\"。要了解关于这个版本的更多细节，请查看<a href=\"https://jdk.java.net/21/release-notes\">发布说明</a>\"。</p><p>&nbsp;</p><p>对于<a href=\"https://openjdk.java.net/projects/jdk/20/\">JDK 20</a>\"和<a href=\"https://openjdk.java.net/projects/jdk/21/\">JDK 21</a>\"，我们鼓励开发人员通过<a href=\"https://bugreport.java.com/bugreport/\">Java Bug数据库</a>\"报告Bug。</p><p>&nbsp;</p><p></p><h4>Spring Framework</h4><p></p><p><a href=\"https://dataflow.spring.io/\">Spring Cloud Data Flow</a>\" 2.10.2<a href=\"https://spring.io/blog/2023/03/08/spring-cloud-data-flow-2-10-2-released\">发布</a>\"，修复了Bug，库升级到Spring Boot 2.7.9和Spring Cloud 2021.0.6。它还升级了子项目依赖项，如：Spring Cloud Dataflow Build 2.10.2、Spring Cloud Dataflow Common 2.10.2、Spring Cloud Dataflow UI 3.3.2、Spring Cloud Deployer K8S 2.8.2。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/spring-cloud/spring-cloud-dataflow/releases/tag/v2.10.2\">发布说明</a>\"。</p><p>&nbsp;</p><p><a href=\"https://github.com/spring-projects-experimental/spring-modulith/blob/main/readme.adoc\">Spring Modulith</a>\" 0.5<a href=\"https://spring.io/blog/2023/03/08/spring-modulith-0-5-released\">发布</a>\"，库升级到Spring Boot 3.0.4和jMolecules 2022.2.4。它还带来了如下改进：重命名了触发JDBC数据库初始化的属性，从spring.modulith.events.schema-initialization.enabled 改为spring.modulith.events.jdbc-schema-initialization.enabled 。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/spring-projects-experimental/spring-modulith/releases/tag/0.5.0\">更新日志</a>\"。</p><p>&nbsp;</p><p></p><h4>Quarkus</h4><p></p><p><a href=\"https://quarkus.io/blog/quarkus-3-0-0-alpha5-released/\">Quarkus 3.0.0的第5个（也是最后一个）Alpha版本</a>\"发布，支持：Hibernate ORM 6.0和StatelessSession接口；新的<a href=\"https://www.youtube.com/watch?v=sz5ihmA4gaE&amp;list=PLsM3ZE5tGAVbyncLm7ue2V25cwFck7ew9\">Dev UI</a>\"；Gradle 8.0；在REST Client Reactive中通过@ClientRedirectHandler注解自定义重定向处理程序；通过@Scheduled注解设置cron时间表的时区。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/quarkusio/quarkus/releases/tag/3.0.0.Alpha5\">更新日志</a>\"。</p><p>&nbsp;</p><p>Quarkus 2.16.14.Final是<a href=\"https://quarkus.io/blog/quarkus-2-16-4-final-released/\">第4个维护版本</a>\"，带来了一些显著的改进，例如：传播Quarkus相关的故障安全系统属性；当服务器响应是204 <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/204\">No Content</a>\"时，从REST客户端返回一个空的InputStream；改进了DevServicesKubernetesProcessor类中的日志记录。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/quarkusio/quarkus/releases/tag/2.16.4.Final\">更新日志</a>\"。</p><p>&nbsp;</p><p></p><h4>Open Liberty</h4><p></p><p>IBM<a href=\"https://openliberty.io/blog/2023/03/07/23.0.0.2.html\">发布</a>\"了Open Liberty 23.0.0.2，新特性包括：用Admin Center测试数据库连接；server stop 命令新增命令行选项--timeout ；修复了<a href=\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-45787\">CVE-2022-45787</a>\"漏洞（在Apache James <a href=\"https://james.apache.org/mime4j/\">Mime4J</a>\"中，TempFileStorageProvider类使用的临时文件被赋予了不恰当的懒惰权限，可能会导致信息泄露给其他本地用户）。</p><p>&nbsp;</p><p></p><h4>Micronaut</h4><p></p><p>Micronaut基金会<a href=\"https://micronaut.io/2023/03/09/micronaut-framework-3-8-7-released/\">发布</a>\"了Micronaut 3.8.7，带来了Bug修复、文档改进和模块更新，涉及<a href=\"https://micronaut-projects.github.io/micronaut-serialization/snapshot/guide/\">Micronaut Serialization</a>\"、<a href=\"https://micronaut-projects.github.io/micronaut-crac/snapshot/guide/\">Micronaut CRaC</a>\"、<a href=\"https://micronaut-projects.github.io/micronaut-kafka/snapshot/guide/\">Micronaut Kafka</a>\"、<a href=\"https://micronaut-projects.github.io/micronaut-aot/snapshot/guide/\">Micronaut AOT</a>\"和<a href=\"https://micronaut-projects.github.io/micronaut-gcp/snapshot/guide/\">Micronaut GCP</a>\"。SnakeYAML 2.0也进行了更新，解决了<a href=\"https://nvd.nist.gov/vuln/detail/CVE-2022-1471\">CVE-2022-1471</a>\"漏洞（使用SnakeYAML Constructor()类进行类型反序列化为攻击者恶意远程执行代码提供了机会）。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/micronaut-projects/micronaut-core/releases/tag/v3.8.7\">发布说明</a>\"。</p><p>&nbsp;</p><p></p><h4>Helidon</h4><p></p><p>Oracle<a href=\"https://github.com/helidon-io/helidon/releases/tag/2.6.0\">发布</a>\"了Helidon 2.6.0，带来了一些显著的变化，其中包括：仅当enable标志设置为true时才注册OciMetricsSupport服务；依赖项升级到SnakeYAML 2.0；通过移除未部署的工件来清理Helidon BOM；从文档中删除了将指标从服务器传播到客户端的说明。</p><p>&nbsp;</p><p></p><h4>Apache软件基金会</h4><p></p><p>Apache Tomcat 11.0.0的<a href=\"https://www.mail-archive.com/announce@apache.org/msg08011.html\">第4个里程碑版本</a>\"发布，新特性包括：恢复原先基于系统属性加载自定义URL协议处理程序的方法；提供了一个不依赖于java.beans 包的JavaBeans支持实现；在NIO2中异步操作后恢复内联状态，解决实现抛出的意外异常。要了解关于这个版本的更多细节，请查看<a href=\"http://tomcat.apache.org/tomcat-11.0-doc/changelog.html\">更新日志</a>\"。</p><p>&nbsp;</p><p>Apache Camel 4.0.0的<a href=\"https://camel.apache.org/blog/2023/03/RELEASE-4.0.0-M2/\">第2个里程碑版本</a>\"提供了Bug修复、依赖项升级和新特性，其中包括：在camel-minio 组件中用于连接到云服务的预签名URL；为camel-health组件中具有连接验证扩展的组件添加健康状况检查；camel-jbang组件的目录输现在采用JSON格式。要了解关于这个版本的更多细节，请查看<a href=\"https://camel.apache.org/releases/release-4.0.0-M2/\">发布说明</a>\"。</p><p>&nbsp;</p><p></p><h4>JobRunr</h4><p></p><p>JobRunr 6.1.1<a href=\"https://github.com/jobrunr/jobrunr/releases/tag/v6.1.1\">发布</a>\"，修复了两个Bug：使用JobLambda接口执行重复作业时的错误；在使用Yasson时，由于作业JSON缺少属性而导致的NullPointerException。</p><p>&nbsp;</p><p></p><h4>Jarviz</h4><p></p><p><a href=\"https://www.linkedin.com/in/aalmiray/\">Andres Almiray</a>\"面向Java社区<a href=\"https://github.com/kordamp/jarviz/releases/tag/v0.3.0\">发布</a>\"了<a href=\"https://github.com/kordamp/jarviz/blob/main/README.adoc\">Jarviz</a>\"（一个新的JAR文件分析工具） 0.3.0版本。这个新版本修复了一些Bug，并提供了一些新特性，包括：新命令extract，用于按名称或模式提取JAR条目；新命令validate，用于验证包名；新的命令行选项--output-format ，用于指定所需的输出。</p><p>&nbsp;</p><p></p><h4>Hilla</h4><p></p><p><a href=\"https://hilla.dev/\">Hilla</a>\"出自<a href=\"https://vaadin.com/\">Vaadin</a>\"开发者之手，其2.0版本已经<a href=\"https://hilla.dev/blog/hilla-2-0-release/\">发布</a>\"。这是一个整合了Spring Boot Java后端和响应式TypeScript前端的开源框架。这个新版本支持：JDK 17；Jakarta EE 10；Spring Boot 3.0；<a href=\"https://hilla.dev/docs/react/guides/reactive-endpoints\">Reactive端点</a>\"；GraalVM原生镜像编译；以及一个<a href=\"https://hilla.dev/docs/react/acceleration-kits/sso-kit\">SSO工具包</a>\"，用于快速为Hilla应用程序添加单点登录功能。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/vaadin/hilla/releases/tag/2.0.0\">发布说明</a>\"和InfoQ的<a href=\"https://www.infoq.com/news/2023/03/introducing-hilla-20/\">新闻报道</a>\"。</p><p></p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/03/java-news-roundup-mar06-2023/\">https://www.infoq.com/news/2023/03/java-news-roundup-mar06-2023/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/UbJ7lV4OWYjY7UN4JGBD\">Java 近期新闻：NetBeans 17、Spring 及 Tomcat 多项更新、JDk 20 版本 GraalVM</a>\"</p><p><a href=\"https://www.infoq.cn/article/YaBqqD7fd6kX97GbhkGm\">虚拟线程：大规模 Java 应用的新基石</a>\"</p>",
    "publish_time": "2023-03-20 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "美政府要求字节出售TikTok，TikTok回应；苹果推迟发放员工奖金；马斯克再痛批曾斥巨资的OpenAI变质 | AI一周资讯",
    "url": "https://www.infoq.cn/article/NI75sRNGCt2yqH0gp5jq",
    "summary": "<p></p><blockquote>传苹果正在测试生成式人工智能，前苹果工程师称Siri没前途；AI 大牛颜水成加入智源，正在组建团队；字节跳动CEO梁汝波内部发言：我们最近一两年的领先不明显了；百度获准在北京市提供无人驾驶出租车服务；GPT-4重磅发布，性能炸天：10秒做出一个网站，在考试中击败90% 人类；GPT-4接入Office全家桶！PPT一键生成.....</blockquote><p></p><p></p><p></p><h2>资讯</h2><p></p><p></p><h4>苹果推迟发放员工奖金，员工人均为公司创收240万美元</h4><p></p><p></p><p>近日，媒体报道，苹果将推迟一些员工奖金的发放，以削减成本。据报道，苹果公司一些团队的奖金发放本来是一年两次，分别在4月和10月，但现在他们将在秋季才能收到全额奖金。</p><p></p><p>报道称，苹果还更加密切地关注员工差旅支出和办公室出勤率。去年，苹果开始要求员工每周至少有三天返回办公室。</p><p></p><p>此外，苹果还正在冻结更多职位招聘，并在员工离职时，让更多职位保持空缺。</p><p></p><p>根据 Barron’s 发布的最新报告，引用 FaceSet 的数据，如果将苹果在 2022 财年创造的收入进行分摊，那么每位员工创造了 240 万美元的收入。在过去五年中，以同样的指标计算，每位员工平均创收约为 210 万美元。</p><p></p><p>值得注意的是，连CEO库克也降薪了。3月12日，苹果公司投资者在线上股东大会重新选举了董事会成员，并批准了包含CEO蒂姆·库克在内一众高管的薪酬计划。据苹果股东会议的决定，与2022年的8400万美元目标薪酬相比，库克今年的4900万美元薪酬缩水了40%左右。</p><p></p><h4>美再次要求字节跳动必须出售TikTok，TikTok或考虑从字节跳动剥离</h4><p></p><p></p><p>据外媒援引知情人士消息表示，TikTok的领导层正在讨论从其中国母公司字节跳动剥离的可能性，希望以此打消来自美国当局的“危害美国国家安全”疑虑。</p><p></p><p>据熟悉此事的人士指出，此次剥离可能会采取出售公司或者开展IPO的方式，但这种情况只有在TikTok与美国安全官员的现有提议遭到否决时才会发生。当然，该人士也强调，就算这种情况即将发生，剥离交易也必须经过中方政府的同意。目前，结合TikTok的社交媒体规模以及其他自身因素来看，有分析人士表示，TikTok在美国业务的估值或将在400到500亿美元之间。</p><p></p><p>几天前，据外媒报道，美国外国投资委员 ( CFIUS ) 已要求字节跳动出售 TikTok 的股份，否则就可能面临美国的禁令。据悉，此次要求仍然是出于安全风险方面的担忧。</p><p></p><p>对于美政府要求字节跳动出售对TikTok持股，TikTok回应称，强制出售并不会解决所谓的安全风险，TikTok 的发言人在一份声明中表示，出售并不能解决问题，所有权的变更不会对数据流或访问施加任何新的限制。解决安全方面担忧的最佳方式，是对美国用户的数据进行透明的、基于美国的保护，并施以强有力的第三方监督、审查和核实，这也是他们正在做的。</p><p></p><p>按计划，TikTok 的 CEO 周受资将在下周出席美国国会的听证会，回答议员们关于 TikTok 的相关问题，并阐述他们在安全方面的措施。</p><p></p><p></p><h4>马斯克再痛批OpenAI变成营利组织</h4><p></p><p>近日，在回应有关OpenAI联合创始人兼首席执行官山姆·奥特曼和他的公司不再是“非营利组织，甚至不再是开放的”的调侃时，马斯克质疑了这一转变的合法性。</p><p></p><p>马斯克在推特上发文表示：“我仍然很困惑，一个我捐赠了1亿美元的非营利组织是如何变成一个市值300亿美元的营利性组织的。如果这是合法的，为什么不是每个人都这么做呢？”</p><p></p><h4>传苹果正在测试生成式人工智能，前苹果工程师称Siri没前途</h4><p></p><p>3月15日，《纽约时报》报道称，苹果公司正在测试生成式人工智能（generative AI），希望这些技术有朝一日可以用于苹果的虚拟助手Siri上，尽管Siri的设计方式存在一些根本性的问题。</p><p></p><p>报道称，在2月举行的苹果年度人工智能峰会上，苹果讨论了机器学习相关问题以及公司内部的人工智能进展。苹果工程师，包括“Siri”团队的成员，“每周”都在测试语言生成概念，以应对ChatGPT等聊天机器人的崛起。</p><p></p><p>《纽约时报》称，这些下一代人工智能技术凸显了“Siri”、“Alexa”（亚马逊语音助手）和其他语音助手如何在人工智能竞赛中浪费了他们的领先地位。尤其是Siri，要实现有意义的改进，还面临着多重障碍。</p><p></p><p>苹果公司前工程师约翰·伯基曾参与过Siri项目，并于2014年负责对其进行改进。他在接受《纽约时报》采访时解释说，这款语音助手是建立在“需要数周时间才能更新基本功能的笨拙代码上”。博基认为，“Siri”不可能成为像ChatGPT那样的“创意助手”。</p><p></p><p></p><h4>AI 大牛颜水成加入智源，正在组建团队</h4><p></p><p>据智源研究院消息，原Sea集团首席科学家颜水成已离职，加入智源研究院，任访问首席科学家。目前，在颜水成的个人主页上，他正发出人才邀请，计划组建一支超强团队。</p><p></p><p>公开资料显示，2004 年，颜水成获得北京大学数学博士学位。2008 年，颜水成加入新加坡国立大学，逐渐成为 NUS 的机器学习和计算视觉领域的领军人物，并拥有该校任终身教职。</p><p></p><p>在新加坡国立大学期间，颜水成发表了近 500 篇文章，取得过计算机视觉旗舰竞赛 PASCAL&nbsp;VOC 和 ImageNet 共 7 次冠军或提名奖。他带领的团队曾提出的“Network in Network” ，对深度学习产生了很大的推动力，同时他的团队开发的”Purine”是全球第一个开源的支持多机多 GPU 的深度学习系统。</p><p></p><p>颜水成博士主要研究领域为计算机视觉、机器学习和多媒体分析，迄今在国际顶级期刊及会议共发表 600 余篇论文，引用量超过 4 万次，H-index 为 96。2014、2015、2016 和 2018 年，他四次当选“汤森路透全球高被引学者”。</p><p></p><p></p><h4>大模型创企“澜舟科技”完成Pre-A+轮融资</h4><p></p><p>3月14日，澜舟科技宣布，已完成Pre-A+轮融资，由北京中关村科学城公司领投，斯道资本和创新工场继续跟投。不到一年时间，澜舟科技融资总额数亿元。</p><p></p><p>澜舟科技成立于2021年，由李开复的创新工场从0孵化的AI企业。据创始人周明介绍，澜舟科技致力于解决人类的语言理解和生成难题，提供基于NLP（自然语言理解）技术的开源大模型以及聚焦于营销、金融、文化创意等场景的功能引擎和应用。</p><p></p><p>通过近两年在自然语言技术上的研发积淀，澜舟科技已经基于“孟子大模型”核心技术打造了一系列能力平台和垂直场景应用。3月14日，澜舟科技正式发布了“类ChatGPT”的语言生成模型——孟子MChat可控大模型。</p><p></p><p>据周明介绍，孟子MChat可控大模型有以下几个特点：将陆续推出10B和100B参数级的大模型；具备聊天、问答、翻译、文本生成、信息抽取等多种能力；可融合搜索结果、领域数据和知识图谱；对功能、风格、人类认知等方面具可控性。</p><p></p><h4>创新工场李开复：AI 2.0已至，将带来比PC、手机时期大十倍的机会</h4><p></p><p>3月14日，创新工场董事长兼首席执行官、创新工场人工智能工程院院长李开复在“AI 1.0到AI 2.0的新机遇”趋势分享会上表示，在深度学习的重大突破之后，AI已经来到从1.0迈入2.0的拐点。AI 2.0将会带来平台式的变革，改写用户的入口和界面，诞生全新平台催生新一代AI 2.0应用的研发和商业化。</p><p></p><p>在李开复看来，AI 2.0将是提升21世纪整体社会生产力最为重要的赋能技术。“AI 2.0给行业带来的机会比过去任何的一个机会都大，比PC、手机时期带来的机会至少要大十倍。”李开复表示。</p><p></p><p>李开复预测，AI 2.0将在六大领域加速点燃商业潜能，进入提升生产力的应用井喷期。这六大领域分别为，电商及广告、影视/娱乐、搜索引擎、元宇宙/游戏、金融和医疗领域。</p><p></p><h4>商汤发布多模态多任务通用大模型：30 亿参数，现已开源</h4><p></p><p>3 月 14 日，商汤科技发布了多模态多任务通用大模型“<a href=\"https://github.com/OpenGVLab/InternImage\">书生（INTERN）2.5</a>\"”，并已经开源。</p><p></p><p>据商汤介绍，该模型拥有 30 亿参数，是目前全球开源模型中<a href=\"https://github.com/jiweibo/ImageNet\">ImageNet</a>\"准确度最高、规模最大，同时也是物体检测标杆数据集 COCO 中唯一超过 65.0 mAP 的模型。</p><p></p><p>“书生（INTERN）”最初版本由<a href=\"https://www.infoq.cn/article/mATFqe6zBIH3P4WrK6hN\">商汤科技</a>\"、上海人工智能实验室、清华大学、香港中文大学、上海交通大学在 2021 年 11 月首次共同发布，并持续联合研发。凭借在多模态多任务处理能力方面多项突破，“书生 2.5”的图文跨模态开放任务处理能力可为<a href=\"https://www.infoq.cn/article/VEAmqNAPRjMud9ypeuNV\">自动驾</a>\"<a href=\"https://www.infoq.cn/article/VEAmqNAPRjMud9ypeuNV\">驶</a>\"、机器人等通用场景任务提供高效精准的感知和理解能力支持，向通用人工智能又迈出了坚实一步。</p><p></p><p>即日起，“书生 2.5”多模态通用大模型已在商汤参与的通用视觉开源平台 OpenGVLab 开源。</p><p></p><h4>百度获准在北京市提供无人驾驶出租车服务</h4><p></p><p></p><p>3 月 17 日，百度“萝卜快跑”首批获准在京开展全无人自动驾驶示范应用，这是全球范围内全无人车队首次在首都城市落地。至此，萝卜快跑已在北京、武汉、重庆三个城市开启全无人自动驾驶出行服务。</p><p></p><p>据悉，萝卜快跑此次共投入 10 辆全无人自动驾驶车，在北京经开区 60 平方公里范围内划定区域开展全无人自动驾驶示范应用。亦庄作为萝卜快跑用户粘性最高的地区之一，单车日均订单量超 20 单，超过传统网约车。数据显示，萝卜快跑 App 用户满意度评价达 4.9 分，其中 5 分满分好评占比高达 94.19%。</p><p></p><h4>字节跳动CEO梁汝波内部发言：我们最近一两年的领先不明显了</h4><p></p><p>3 月 16 日晚 ，时值成立十一周年之际，字节跳动举办了线上直播会，字节跳动董事长 /CEO 梁汝波表示，\" 信息平台 \" 和 \" 电商 \" 是字节跳动的主干业务，应该聚焦，\" 将这两个主干业务做到扎实，就已经很好了，就已经需要非常努力了。\"</p><p></p><p>他还特别提及，以抖音、TikTok、今日头条等为代表的信息平台业务，\" 我们之前凭借领先认知作出了一些突破，但最近一两年我们的领先不明显了，并不能很有信心地说比同行做得好。\"</p><p></p><p>梁汝波将字节跳动今年的主要目标总结为四点：聚焦做好两个主干业务 \" 信息平台 \" 和 \" 电商 \"；探索型业务要 \" 有想象力，持平常心 \"；在全球范围内赢得社会信任；管理上打好基本功，如关键管理者的选拔和淘汰、提升组织的全球化水平等。</p><p></p><h2>IT界热评新闻</h2><p></p><p></p><h4>GPT-4重磅发布，性能炸天：10秒做出一个网站，在考试中击败90% 人类</h4><p></p><p>3 月 14 日晚间，OpenAI 宣布发布 GPT-4。</p><p></p><p>“我们创建了 GPT-4，这是 OpenAI 努力扩展深度学习的最新里程碑。GPT-4 是一个大型多模态模型（接受图像和文本输入，提供文本输出），虽然在许多现实世界场景中的能力不如人类，但在各种专业和学术基准上表现出人类水平”，OpenAI 表示。</p><p></p><p>OpenAI 联合创始人 Sam Altman 表示，它是“迄今为止功能最强大、最一致的模型”，能够使用图像和文本。</p><p></p><p>在 YouTube 上的 Live Demo 中，OpenAI 的总裁和联合创始人 Greg Brockman 展示了 GPT-4 拥有的强大技能。GPT-4 可以总结文章、写代码、报税、写诗……更惊人的是，GPT-4 只需 10 秒就可以做出一个网站，程序员可能危险了...</p><p></p><h4>GPT-4接入Office全家桶！PPT一键生成</h4><p></p><p>3 月 16 日，微软召开发布会，正式推出基于 GPT-4 的 Microsoft 365 Copilot。这也意味着，微软热门的 Microsoft 365 商业软件，如 Word、PowerPoint、Excel、Outlook 等都可以使用 AI 功能。</p><p></p><p>“ChatGPT 版的 Office”来了！据介绍，Microsoft 365 Copilot 将大语言模型（LLM）的强大功能与 Microsoft Graph 和 Microsoft 365 应用中的数据相结合，致力于成为最强生产力工具。</p><p></p><p>微软强调，Copilot 绝不仅仅是嵌入至 Microsoft 365 当中的 OpenAI ChatGPT，它更是一套复杂的处理与编排引擎。</p>",
    "publish_time": "2023-03-20 10:09:22",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "“ChatGPT 黑化”暴露出太多问题令人恐慌，是时候对大模型做安全评估了！",
    "url": "https://www.infoq.cn/article/Wigm8Jk2atzDYgo61JJC",
    "summary": "<p></p><p></p><blockquote>InfoQ获悉，聆心智能联合清华大学CoAI实验室共同发布大模型安全评估框架，迈向可控可信的大模型。</blockquote><p></p><p></p><p>ChatGPT 正在引领人类进入无缝人机交互的新时代，比尔盖茨在接受福布斯采访时也表示，“ChatGPT的意义不亚于PC和互联网的诞生。”</p><p></p><p>不过，当搜索引擎 New Bing 与 ChatGPT 结合，伴随着“ChatGPT 黑化”等一系列舆论事件的发生，人们也开始对人工智能带来的道德、伦理、安全等风险感到恐慌。</p><p></p><p>虽然近年来随着技术的不断突破，大模型获得了快速发展并开始在各个场景广泛应用，但仍存在着事实性错误、知识盲区和常识偏差等诸多问题，还面临训练数据来源合规性、数据使用的偏见性、生成内容的安全性等风险。</p><p></p><p>如何提高模型的准确度和可靠性，使 AI 生成的内容安全、可信、可靠已经成为了当前大模型在应用方向亟待解决的问题。</p><p></p><p>要规避安全风险，降低人工智能对人类的负面影响，关键在于大模型底座。</p><p></p><p>对此，清华大学计算机系长聘副教授、北京聆心智能科技有限公司创始人黄民烈认为：“大规模语言模型（LLM）发展到现在，模型结构和规模已经有了很大的进展，但实用性还有待加强，我们应该通过技术让模型更加安全、可控，使其快速适配更多的应用场景。”</p><p></p><p>据悉，针对大模型的安全伦理问题，由黄民烈带领的研究团队历经两年沉淀，建立了大模型安全分类体系，并从系统层面和模型层面出发，打造更可控、可信的大模型安全框架。</p><p></p><p>安全框架的建立，定义了大模型的应用边界，促进大模型生态的健康发展，引领国内学术界和工业界迈向更有用（helpful）、更可信（truthful）、更安全（harmless）的AI研究和应用。</p><p></p><p>相比过去在安全伦理方面考虑较少的大模型，ChatGPT 背后所依托的大模型取得了巨大的发展，不仅允许用户进行后续更正，还能够拒绝不当请求和预测，这得益于ChatGPT在安全部分的特别设计，不过仍无法完全避免其生成不安全的内容和产生有风险的行为。</p><p></p><p>此前，由黄民烈带领的研究团队已经在安全伦理方面开展了相关研究，并依此建立了大模型安全分类体系，其中不安全的对话场景包括：政治敏感、犯罪违法、身体健康、心理健康、财产隐私、歧视/偏见、辱骂/仇恨言论、伦理道德八大方面。这些问题与人们的价值观和伦理道德息息相关，可能会导致用户接收不当信息、甚至影响用户产生有害的行为，限制大模型的发展和应用。</p><p></p><p>与此同时，研究团队也针对以上八大安全场景对大模型进行针对性升级。通过收集多轮安全数据训练模型，使模型具备基本的安全性，能够在遇到安全问题时给予正确的回复策略，不去做判断和误导。进一步对模型进行自动测试，针对安全缺陷通过微调的方式进行快速迭代，促使模型越来越符合人类的认知理解模式，生成更加安全可信的内容。</p><p></p><p>值得一提的是，着眼于容易触发安全问题的类型，研究团队收集和构造了相应的hard case（更难识别和处理的安全测试用例），总结和设计了六种一般模型难以处理的安全攻击方式，称为指令攻击。使安全体系更加完善，进一步改进和优化模型表现。</p><p></p><p>不论国内国外，当前大模型的安全问题仍面临着严峻的困难和挑战，人工智能作为一门前沿科技，可以给人类带来巨大福祉，也会给人类造成未知的隐患。确保强大的人工智能系统能够被负责任地建构和部署，打造安全、可信、可靠的 AGI Companion，是该研究团队的最终愿景。</p><p></p><p>未来，研究团队将打造中文大模型的安全风险评估的 Leaderboard，为国内对话大模型的安全评估提供公平公开的测试平台，并提供：</p><p></p><p>1、针对中文对话的8个安全场景，40个安全类别做全面精细的测试，包括人工评估和自动评估。</p><p></p><p>2、额外设置6种安全攻击（如目标劫持等）的超难指令攻击测试样例，探索模型的安全上限。</p><p></p><p>3、设置公开和隐藏测试集，众人皆可参与评测。</p><p></p><p>嘉宾介绍：</p><p></p><p>黄民烈，清华大学计算机科学与技术系长聘副教授、博导，国家杰出青年基金项目获得者，北京聆心智能科技有限公司创始人。黄民烈带领的研究团队致力于构建具有类人水平的对话智能体，将依托自身的核心技术，在可控可信的超拟人大模型基础之上，通过建立安全、可控的模型边界，让AI提供可信、可靠的输出，让人工智能走向 AGI 时代。</p>",
    "publish_time": "2023-03-20 12:03:23",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "李开复下场抢人！宣布筹办新AI公司：目标不只是中文ChatGPT，资金算力已到位",
    "url": "https://www.infoq.cn/article/i0BuyXUdCNwrxZE4Nk17",
    "summary": "<p></p><blockquote>继王慧文、王兴之后，又一大佬宣布进军 AI 大模型赛道。</blockquote><p></p><p></p><h2>李开复宣布筹办新AI公司，剑指AI 2.0</h2><p></p><p></p><p>3 月 19 日，创新工场董事长兼 CEO 李开复发朋友圈宣布成立 Project AI 2.0 公司，致力于打造 AI 2.0 全新平台和 AI-first 生产力应用。</p><p></p><p>李开复对 Project AI 2.0 寄予厚望，目标“不仅仅要做中文版 ChatGPT”。目前，Project AI 2.0 资金、算力陆续到位，希望在全球范围内“招贤纳士”。</p><p></p><p>资料显示，李开复在美国哥伦比亚大学取得计算机科学学士学位，以最高荣誉毕业于卡耐基梅隆大学获得博士学位。2009 年，李开复创立创新工场，担任董事长兼首席执行官，专注于科技创新型的投资理念与最前沿的技术趋势。在此之前，李开复博士曾是谷歌全球副总裁兼大中华区总裁，担任微软全球副总裁期间开创了微软亚洲研究院，并曾服务于苹果、SGI 等知名科技企业。</p><p></p><p>2016 年 9 月，创新工场人工智能工程院成立，李开复博士亲任院长，王咏刚担任执行院长，与来自世界顶级机构的著名工程师和顶尖科学家共同探索技术、数据、人才、商业价值的结合，推进人工智能在科学研究与商业领域的实践探索，致力于打造人工智能领域的科研转化实验室。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/95/9591e511cf5b5c9900188f8b081615ac.png\" /></p><p></p><p>李开复朋友圈全文如下：</p><p></p><p></p><blockquote>我正在亲自筹组 Project AI 2.0，一个致力打造 AI 2.0 全新平台和 AI-first 生产力应用的全球化公司，这是一家由技术愿景驱动，拥有卓越中国工程底蕴的创新企业，在全球范围号召世界级的人才，加入我们一起打造这个世界级的公司！Project AI 2.0 不仅仅要做中文版 ChatGPT。我认为 AI 2.0 不仅仅是个高能聊天工具，也不仅仅是图文创作的 AIGC 生成，Co-pilot 和如今看到的应用都还只是 AI 2.0 能力的开端。Project AI 2.0 是创新工场塔尖孵化的第 7 家公司，同时我们也积极寻找AI 2.0 技术和应用相关的投资机会，加速打造 AI 2.0 的全新创业生态，对于AI 2.0 的未来，我们具有更多更大的想象。Project AI 2.0 的资金、算力陆续到位，新公司期权由新团队绝对主导，首批广召大模型、多模态、NLP、AI算法工程与研究、分布式计算/Infrastructure 等方向的顶级人才推荐自荐。推荐人才、探索合作通道：<a href=\"https://chuangxin.com/ai2\">https://chuangxin.com/ai2</a>\"</blockquote><p></p><p></p><h2>多位大佬冲向ChatGPT风口</h2><p></p><p></p><p>自去年年底发布以来，<a href=\"https://www.infoq.cn/theme/173\">ChatGPT</a>\" 彻底点燃了科技界，并火速“出圈”，仅用 2 个月时间就收获了 1 亿用户。比尔盖茨评价称，ChatGPT 的技术将“改变我们的世界”。马斯克也在感叹“很多人疯狂地陷入了 ChatGPT 循环中”，“ChatGPT 好得吓人，我们离强大到危险的人工智能不远了”。</p><p></p><p>在资本市场，ChatGPT 也掀起了一股强势的 AI 浪潮。据澎湃新闻报道，最近几个月，在旧金山和硅谷，生成式人工智能聚会、联合办公空间和各种会议中弥漫着兴奋情绪，让人感觉像是回到了移动互联网的创业热潮中。年轻的科技创始人给旧金山社区海斯谷起了个绰号“脑谷（Cerebral Valley）”。</p><p></p><p>国内对 ChatGPT 感兴趣的企业、个人亦不在少数。</p><p></p><p>2 月 9 日，360 创始人周鸿祎在《星空下的对话》节目中谈到 ChatGPT，他直言如果企业搭不上 ChatGPT 这班车，很可能会被淘汰，360 不会放弃对该技术的跟踪。</p><p></p><p>3 月 17 日，新东方创始人俞敏洪也在 2023 亚布力中国企业家论坛年会上表示，企业家不仅要专注自己的企业，更要关注世界变化和发展。作为企业家，没有玩过ChatGPT，没有资格谈高科技发展，“年龄不是问题，思想僵化、不接受新鲜事物才是问题。”</p><p></p><p>此外，也有不少大佬高调宣布进军 AI 领域，筹建“中国的 OpenAI”。</p><p></p><p>2 月 13 日，原美团联合创始人王慧文在社交平台发文宣布进军人工智能领域，宣布成立北京光年之外科技有限公司。王慧文出资 5000 万美元，公司估值 2 亿美元（约 13.62 亿元人民币）。王慧文表示，他个人不占股份，资金占股 25%，75% 的股份用于邀请顶级研发人才，下轮融资已有顶级 VC 认购 2.3 亿美元（约 15.66 亿元人民币）。</p><p></p><p>3 月 8 日，美团创始人王兴在朋友圈中表示，将以个人身份参与王慧文创业公司“光年之外”的 A 轮投资，并出任董事。“AI 大模型让我既兴奋于即将创造出来的巨大生产力，又忧虑它未来对整个世界的冲击。老王和我在创业路上同行近二十年，既然他决心拥抱这次大浪潮，那我必须支持。”</p><p></p><p>与王兴、王慧文筹建的<a href=\"https://www.infoq.cn/news/x8Q7ghQ0CmFeuKUPRZiA\">光年之外</a>\"相比，李开复的创业目标聚焦在 AI 2.0。在其看来，“AI 2.0 不仅仅是个高能聊天工具，也不仅仅是图文创作的 AIGC 生成，Co-pilot 和如今看到的应用都还只是 AI 2.0 能力的开端”。</p><p></p><h2>从AI 1.0到AI 2.0的跨越</h2><p></p><p></p><p>在 3 月 14 日北京创新工场总部举办的 “AI 1.0 到 AI 2.0 的新机遇”趋势分享会上，李开复指出，在深度学习的重大突破之后，AI 已经来到从 1.0 迈入 2.0 的拐点。多模态、巨型数据集的飞速发展，AI 优化目标函数及训练模型的技术方法将大幅精进，能更好地模拟人类的认知智能。</p><p></p><p>此外，AI 2.0 将会带来平台式的变革，改写用户的入口和界面，诞生全新平台催生新一代 AI 2.0 应用的研发和商业化。总的来说，AI 2.0 将是提升 21 世纪整体社会生产力最为重要的赋能技术。</p><p></p><h4>AI 1.0：数据集和诸多模型各成“孤岛”，应用开发门槛高</h4><p></p><p></p><p>在李开复看来，AI 1.0 是以 CNN 卷积神经网络模型为核心的计算机视觉技术，拉开 AI 感知智能时代的序幕，机器开始在计算机视觉、自然语言理解技术等领域超越人类，并创造了显著的价值。</p><p></p><p>但是 AI 1.0 也遇到了瓶颈，大多数行业想利用 AI，需要花费巨大的成本来收集和标注数据，而这些数据集和诸多模型各成“孤岛”缺乏纵效。这是为什么大部分的 AI 1.0 企业投入大笔研发经费但仍然长年亏损。</p><p></p><p>除此之外，AI 1.0 缺少像互联网时代的 Windows 和 Android 一样的规模化能力，来降低应用开发的门槛，打造完善生态链。几年下来，AI 1.0 尚未真正实现商业上的成功。</p><p></p><p>李开复表示，在 Deep Tech VC 方面，创新工场 2012 年已开始挖掘 AI 赛道，迄今培育出了 10 只 AI 1.0 独角兽企业。</p><p></p><h4>AI 2.0：有望实现平台化效应，商业化应用想象空间巨大</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0a/0ab5296a698a01e0d23a3f942cab408f.png\" /></p><p></p><p>与 AI 1.0 相比，AI 2.0 的巨大跃迁在于克服了前者单领域、多模型的限制，可以用无需人工标注的超级海量数据去训练一个具有跨领域知识的基础大模型（Foundation Model），通过微调等方式适配和执行五花八门的任务，真正有望实现平台化的效应，进而探索商业化的应用创新机会。</p><p></p><p>李开复表示，AI 2.0 时代的第一个现象级应用是生成式 AI（Generative AI），也就是国内流行的 AIGC。生成式 AI 能够实现无需标注的自监督学习，AI 将从“辅助”人到逐步“替代”人工，所有使用者界面将被重新设计改写。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/98/9854135a3ef44d0065d35c065395ac04.png\" /></p><p></p><p>打个比方，想象让 AI 读一本书的前 9 章之后“猜测”第 10 章，再让 AI 对比真正的内容，读过上千万本书后，模型不断优化和迭代。以这样的方式，AI 变得越来越精准，最终形成适用不同领域的基础大模型。</p><p></p><p>AI 2.0 模型不仅可以学习文本和图像数据，还可以从语音、视频、自动化硬件传感器数据，甚至 DNA 或蛋白质信息等多模态数据中学习，建构机器超强大脑的运行能力，甚至不止于生成，而逐步达到具有预测、决策、探索等更高级别的认知智能。</p><p></p><p>李开复认为，AI 2.0 不仅仅是个红极一时的高能聊天工具，也不仅仅是图文创作的 AIGC 生成程序，如今看到的应用都还只是 AI 2.0 能力的开端，不该限制了人们对 AI 2.0 未来潜力的想象。</p><p></p><h4>AI 2.0 时代，创新工场将关注三大方向</h4><p></p><p></p><p>向着 AI 2.0 的拐点，创新工场主要关注三大方向：</p><p></p><p>1. AI 2.0 智能应用</p><p></p><p>AI 2.0 应用将会迎来遍地开花的阶段，包括各行各业的垂类 AI 助理、元宇宙应用等之前做不出的应用都会出现。除了新的应用，很多现在已有的应用都可以被重新改写，比如搜索引擎、内容创造、广告营销，AI 2.0 将革新用户体验，创造出全新的商业模式，蕴含非常巨大的想象空间。</p><p></p><p>2. AI 2.0 平台</p><p></p><p>AI 2.0 平台将会加速新一代 AI 2.0 应用的研发和商业化，创新工场看好具有战略高度的 AI 2.0 平台公司，推动 AI 2.0 的生态循环和良性竞争。</p><p></p><p>3. AI 基础设施</p><p></p><p>除了应用和平台之外，支持 AI 模型运维，管理，训练的基础设施也是创新工场重点关注的，包含支撑 AI 2.0 巨型模型训练的 AI 芯片公司，以及那些能够加速、降低成本和简化 AI 训练的 AI 2.0 基础设施的创新技术型企业。</p><p></p><h4>AI 2.0 将加剧失业风险</h4><p></p><p>不过，李开复也指出，现阶段的 AI 2.0 并不能做到完全正确。</p><p></p><p>AI 无法保存全世界的数据，只能通过压缩形成抽象的概念，因此会出现“一本正经地胡说八道”的现象。更重要的是，AI 目前还无法分辨真伪和辨别是非，如果被恶意利用将会带来无法衡量的负面后果。可以想象，曾影响干扰美国选举的“剑桥分析”丑闻，如果发生在 AI 2.0 的时代，将会给社会造成更大的伤害。</p><p></p><p>此外，AI 2.0 也将加剧不可避免的失业风险。</p><p></p><p>最具创造力的顶尖人才将会乘上 A1 2.0 的东风，全面提升生产力和效率。但随之而来的是重复性的工作将会被 AI 2.0 接替，这些岗位上的人不得不寻求职业的转变与技能的升级，其中包含高比例的白领岗位，亟需进入到更需要发挥创造价值的行业。</p><p></p><p>李开复认为，AI 2.0 并不意味着通用人工智能（AGI）就此到来。人类有很多与生俱来的关键能力，诸如创造力、策略思考、跨领域常识、自我意识、同理心和爱等，这些尚未被破解的深层次能力，也是 AI 2.0 无法全盘复制的。</p><p></p><p>参考链接：</p><p><a href=\"https://www.chuangxin.com/blog/ai-2-0\">https://www.chuangxin.com/blog/ai-2-0</a>\"</p>",
    "publish_time": "2023-03-20 12:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从 MySQL 到 Oracle 再到全面 TiDB ，云盛海宏的数据库架构实践",
    "url": "https://www.infoq.cn/article/tJUA8Q3WJQvVHcazlcSY",
    "summary": "<p>目前，国内某知名运动品牌在全球经营着 12 家鞋服运动品牌，在全国有近万家线下门店，耐克、阿迪达斯、彪马、匡威等品牌门店绝大部分都是其代理经营，注册会员达 6000 多万，这些业务由旗下科技公司云盛海宏全面支撑。过去十年间，云海零售系统是支撑全渠道、全品类运动鞋服的零售服务平台，支撑了 8000+ 线下门店的零售。</p><p></p><p>这样一家零售领域的老牌企业是如何一步步从 MySQL 转向原生分布式数据库的？整体的架构变迁思路是怎样的？实践过后又是如何从成本视角评价 <a href=\"https://xie.infoq.cn/article/b695d274469d36b1d7e347b16\">Oracle</a>\" 和国产分布式数据库的......近期，InfoQ 有幸采访到了云盛海宏首席架构师洪亮，就上述问题逐一进行了探讨。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/87/86/87ae380fcdfe58f62b1ce7034d6f0d86.jpg\" /></p><p>云盛海宏首席架构师洪亮</p><p></p><p></p><h2>背景介绍</h2><p></p><p></p><p>在介绍云盛海宏的数据库架构设计之前，我们先了解下其整体的业务背景。云盛海宏的核心业务是零售系统，包括库存、终端零售以及用于集团内部的财务辅助系统三大模块。</p><p></p><p>自 2013 年开始，云盛海宏就开始搭建整个数据库架构，中间因为业务的不断发展经历了多轮迭代。2016 年之前，云盛海宏基本还处于传统零售时代，内部各大区自建设信息化系统，维护自己的数据库架构，每天向总部上传业务数据，数据库采用集中式单库，这种方式的优点是架构简单，缺点则随着业务发展越来越明显，比如没有办法及时查看地区汇总数据，也无法跨大区查看全国的实时库存等。</p><p></p><p>为了解决这些问题，云盛海宏在 2016 年上线了全新的架构——云海零售系统，开启了数字化零售时代的架构演进之路。</p><p></p><p></p><h2>从 MySQL 到 Oracle 再到全面 TiDB 的架构演进</h2><p></p><p></p><p>发展至今，云海零售系统主要经历了三个阶段的演进。</p><p></p><p></p><h4>阶段一：应用微服务化，实现数据共享，初步精细化运营，支撑数字化业务发展</h4><p></p><p></p><p>在这一阶段，云盛海宏使用的是微服务+ MySQL 分库分表的方式。立项之初，团队调研时考虑到数据垂直切分的模式短时间内较稳定，MySQL 集群的开发难易程度对团队来说又比较好掌握，所以选定了 MySQL 。</p><p></p><p>随着业务的飞速发展，很多问题超出了团队的原始预期，MySQL 集群对于复杂报表分析支持不足，团队尝试引入 Oracle 分担这部分需求，再通过 Otter 进行数据的实时同步，保障两边的数据完整。对于 <a href=\"https://xie.infoq.cn/article/5c8dcaa1a4cb2e08eeb301a1d\">TOB </a>\"业务来说，内部报表非常关键，且对数据精度要求极高，冷热数据变化频繁，Oracle 的引入很好解决了实时报表方面的问题。</p><p></p><p>此后，云海零售系统支撑了业务高速发展的五年，实现了很多小目标，比如实现了全国各地区、各大区的海量数据的存储，实现了数据实时共享，也达到了业务可视化的目标。但是随着业务的扩展和需求难度的增加，慢慢地出现了一些新的挑战。首先，整个架构基于 MyCAT 做分库分表，在日常维护中，如果有新的业务，比如要增加表或者调整表，维护层面会增加人力成本，需要人工调整配置，然后再调用配置，需要花费很多精力。</p><p></p><p>其次，当时的 Otter 同步渠道已经有 110 +，使用起来也没有那么理想。比如源端加表，目标端没有加表，或者是仅仅是字段的调整也可能导致一些同步的中断，这需要大量人力维护。最主要的是 Oracle 也遇到了一些瓶颈，例如海量数据无法扩展、聚合库分析时效差等问题。</p><p></p><p></p><h4>阶段二：解决数据爆发式增长导致聚合库分析时效性差</h4><p></p><p></p><p>2020 年之前，Oracle 的单点性能已经无法横向扩展，团队开始积极寻求替代方案。此时，团队开始接触到 TiDB ，并于当时 InfoQ 举办的 ArchSummit 大会上听到了时任 PingCAP 联合创始人兼 CTO 黄东旭的详细讲解，后又经过详细的对比测试，主要集中在大数据量的查询以及复杂 SQL 的查询性能两方面，发现 TiDB 可以解决 Oracle 存在的问题并且非常便捷。在内部小规模试用取得显著效果之后，云盛海宏最终决定快速推进 <a href=\"https://xie.infoq.cn/article/746644bfa839209f7326b1d6c\">TiDB</a>\" 集群的部署工作。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/38/18/38b6db65567285cf08d6e2970a704918.png\" /></p><p>决定将 TiDB 部署到生产时的压测方案（利用了 Percona 公司的开源工具 Percona-playback 实施的压测）</p><p></p><p>“2020 年，疫情爆发，这对我们的业务带来了很大冲击，我们开始发力做线上业务，技术侧最直接的压力来自于库存管理模块的变化。原本，从接到需要对接淘宝、京东、唯品会、抖音等平台的需求到最终落地需要三个月甚至半年的时间，但因为我们前期已经切换到了 TiDB ，技术栈层面做好了充足的准备，最终只用了两周时间就完成了单平台库存管理模块的调整”，洪亮如是说道。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/da/dd/dacf30f0398818e03cca3507ce1e7fdd.jpg\" /></p><p>2020 年引入 TiDB 之后的架构图</p><p></p><p>就内部工程师而言，TiDB 的部署推进得也非常顺利。首先，云盛海宏的主要业务都是在 MySQL 的基础上构建的，TiDB 完全兼容 MySQL 协议，从 MySQL 迁移到 TiDB 是比较顺利的。其次，TiDB 的日常运维、扩容、缩容非常方便，原来 DBA 按月或者季度为周期需要在凌晨一次性完成十几个实例的数据迁移，维护工作量巨大，而且数据迁移风险极高，一旦出现问题后果非常严重，引入 TiDB 之后基本不需要做迁移动作，更别提 MySQL 日常巡检、归档和备份这些动作耗费的时间。最后，MySQL 分库分表带来的局限性无法让团队快速应对变化，公司组织架构的每一次调整都会对业务带来一定冲击，团队需要快速消化这种冲击，TiDB 的引入让整个技术栈更具弹性。</p><p></p><p></p><h4>阶段三：向全面部署分布式数据库迈进，初步探索架构云化</h4><p></p><p></p><p>目前，云盛海宏内部已经完成了 MySQL 到 TiDB 的迁移，从最初的 4.0 版本到目前线上的 5.4.2 版本，每一次升级 TiDB 都会带来比较实用的特性和功能。接下来，云盛海宏会尝试从 Oracle 到 TiDB 的迁移，逐渐收拢数据库集群，更进一步降低运维负担。在云盛海宏内部，Oracle 不会承担太多核心业务和写操作，迁移基本面向 AP 类的数据和业务，所以这部分相对来说比较容易，团队重心会放在前端数据迁移，包括数据准确性校验。</p><p></p><p>采访中，洪亮表示目前内部的 TiDB 集群的机器规模已经达到 100 台，已经部署了两个 TiDB 集群，分别承担前端和后台的业务负载，计划在 2024 年前完成第三个 TiDB 集群的部署，承担前文所述的 AP 类业务，也就是目前 Oracle 承担的财务报表分析负载。届时，云盛海宏的所有业务将全部运行至 TiDB 集群，Oracle 集群将逐渐停用。</p><p></p><p>除此之外，整体架构将会逐渐云化。当前，云盛海宏部分应用做了私有云化，未来会尝试将一些环境公有云化，比如开发、测试、培训、生产等。</p><p></p><p></p><h2>数据库设计核心问题探讨</h2><p></p><p></p><p>在零售行业，云盛海宏算得上是对技术投入较大的公司之一，而且结合其业务范围和体量，技术架构的搭建是存在一定难度的，数据库选型和架构演进需要考虑因素很多。在这个过程中，团队也摸索出了一些经验。</p><p></p><p></p><h4>零售业有没有可能完全舍弃 Oracle ？</h4><p></p><p></p><p>在零售领域，有一定历史的企业内部早期肯定部署着 Oracle 数据库，尤其是对精度要求极高的财务数据，那时可替代的国产数据库并不多。如今，国产数据库越来越成熟，可供选择的空间也越来越大，很多企业都开始尝试迁移至其他数据库。</p><p></p><p>从云盛海宏的经验来看，零售领域未来完全有机会舍弃 Oracle ，即便是要求极高的财务报表数据的处理也可以由国产数据库来负责。</p><p></p><p>选型上，企业需要提前根据业务特点做好压测，迁移之前也需要做好相关预案，云盛海宏从 MySQL 到 TiDB ，从 Oracle 到 TiDB 都做好了充分的备案。</p><p></p><p></p><h4>从成本视角来看，分布式数据库值吗？</h4><p></p><p></p><p>现在谈到成本，基本涵盖软件授权费用、软件服务费用、硬件采购费用以及日常维护费用等众多维度，企业内部情况不同也存在差异。</p><p></p><p>从云盛海宏的经验来看，TiDB 相比 Oracle 在软件授权费用上肯定是具备明显优势的；在软件服务费用方面，TiDB 本身的生态和社区建设（包括文档）相对比较完善，但不排除一些国产数据库因为成熟度不足而尚无法投入人力建设成熟的服务生态，这一点需要根据选型情况具体判断；在硬件采购费用方面，云盛海宏使用前后差异不大；在日常维护方面，TiDB 的门槛低、易维护节约了大量人力成本。</p><p></p><p>如果与管理 MySQL 集群相比，数据备份、硬件故障处理、主从节点管理等相对都比较麻烦，但 TiDB 基本可以做到轻量级维护，后期云化之后可能会更进一步降低运维成本。</p><p></p><p></p><h4>要不要全面云化？</h4><p></p><p></p><p>如前文言，云盛海宏其实未来会逐步云化，其团队内部对此也有很多考虑。</p><p></p><p>采访中，洪亮表示从整个集群而不是单个数据库的角度出发，云化在机房管理、网络安全、高可用、容灾等层面会比本地部署更有优势。如今，TiDB 和阿里云也有合作，云化是比较容易进行的，尤其是针对原有技术栈基于 MySQL 的企业。</p><p></p><p></p><h4>智能化运维值不值得初期就考虑？</h4><p></p><p></p><p>最近两年，很多数据库都在积极整合 AI 能力，以期让部署、运行、运维等全过程更具智能化。对云盛海宏而言，企业内部对落地 AI 的诉求相对而言没那么迫切。</p><p></p><p>“智能化运维或者说引入 AI 能力取决于底层的基础建设是否到位，如果存算分离或者是运维能力没有提升，AI 就像是空中楼阁。只有底层基础打好了，智能化运维才能发挥出更大作用。比如，MySQL 的一些指标监控肯定没有 TiDB 完善，没有这些指标，AI 监控就无从谈起了。”</p><p></p>",
    "publish_time": "2023-03-20 13:39:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AI智能编程工具aiXcoder推出企业版，采用百亿级规模参数大模型进行个性化训练，支持私有化部署",
    "url": "https://www.infoq.cn/article/96T7NEbIKH3lLKHoGUGs",
    "summary": "<p></p><p>AIGC时代来临，通过AI智能编程工具降低企业研发投入成本、提高编程效率、减轻研发人员工作压力已成为企业数智化转型的必要手段。</p><p></p><p>aiXcoder是一套AI智能编程系统，其基于当前SOTA的代码大模型，可通过自然语言实现方法级代码生成，还能完成整行及多行的智能代码补全，帮助开发者在编写代码时保持专注力和创造性，提高软件开发效率。</p><p></p><p>近日，InfoQ获悉，在免费服务个人开发者的同时，aiXcoder推出了企业级智能开发应用——aiXcoder「企业版」。</p><p></p><h3>aiXcoder「企业版」核心优势：可进行私有化部署</h3><p></p><p></p><p>aiXcoder「企业版」核心优势在于可进行私有化部署，并对企业代码进行个性化训练，进一步提升企业研发效率和代码质量，助力企业快速响应市场需求。</p><p></p><p>企业私有化部署包括百亿级参数大模型部署和个性化训练两部分：</p><p></p><p>企业私有化部署具体是指在企业内部环境下，用基于Docker的容器化技术配置好运行环境后，将aiXcoder的整套软件（包括大模型和代码）部署在企业内网的深度学习服务器上。在不连外网的情况下，企业也能使用aiXcoder提供的智能编程服务，保障企业信息及代码安全。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/01f6e893bb66795ef911ee28b9d487e5.png\" /></p><p></p><p></p><p>部署完成后，aiXcoder提供的模型为通用数据集的代码生成大模型，训练数据来源于海量开源代码。这时，需要对企业代码进行个性化训练，以进一步提升代码生成的准确性。</p><p></p><p>企业个性化训练是指对企业内部代码进行数据处理、增量训练，通过学习企业内部代码编程模式，最终得到个性化训练后的企业版新模型。新模型与原模型相比，更贴近企业实际项目应用场景，在企业内部使用时，预测准确性将得到提升。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/32/325816d624c8f3d58559e45ee3cf3305.png\" /></p><p></p><p></p><h3>为什么需要使用百亿级参数大模型进行个性化训练？</h3><p></p><p></p><h4>强大的自然语言理解能力</h4><p></p><p>大模型支持自然语言生成完整程序代码，同时支持根据代码上下文实现多行补全，生成和补全的代码更符合开发者意图。</p><p></p><h4>代码生成更精确、高效，且具有延展性</h4><p></p><p>百亿级参数大模型拥有海量语料训练数据，可以更准确地理解并生成符合企业业务需求及研发规范的代码，大幅提升代码生成效率、代码质量和可靠性。百亿级参数大模型能进行深度学习，可延伸拓展其他训练任务。</p><p></p><h4>生成代码更符合企业业务需求</h4><p></p><p>通过个性化训练，百亿级参数模型可以理解业务流程，基于业务训练生成符合企业软件研发规范的代码，更符合企业业务需求。</p><p></p><h4>降本增效</h4><p></p><p>百亿级参数模型更具智能性，可以更高效地生成代码，降低代码出错的概率。大幅减少手工编写代码的工作量，节省开发时间和成本。</p><p></p><p>整个训练过程严格遵循企业安全保密制度规范。在企业内部环境进行，对企业代码、业务/技术文档等数据信息严格保密。个性化训练过程在软件研发常规流程基础上，结合AI项目实际情况进行过程优化与完善，达到PDCA闭环质量管理，确保最终交付模型产品性能稳定、效果达预期目标。</p><p></p><p>在私有化部署和个性化训练都完成后，就可以使用专属的企业版来辅助员工编程和开发了。</p>",
    "publish_time": "2023-03-20 14:11:47",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何基于 Apache Doris 构建简易高效的用户行为分析平台？",
    "url": "https://www.infoq.cn/article/ecmRgdfrjFl1U3hAd59b",
    "summary": "<p>用户行为分析是企业了解用户的重要方式之一，可以从点击、登录、观看、跳出、下单购买等多维角度还原用户动态使用场景和用户体验，通过对用户行为埋点数据进行分析，可以详细、清楚地了解用户的行为习惯，从中发现用户使用产品的规律，以用于精确营销、产品优化，从而驱动业务实现增长。</p><p></p><p>随着<a href=\"https://www.infoq.cn/article/pc7ihipY5vPdizqktlE5\">数字化转型</a>\"进程的不断推进，用户行为分析平台在企业内部扮演的角色愈发重要，如何进一步挖掘用户行为数据价值，也成为了当下各企业不断努力探索的方向。而系统平台建设过程中所遭遇的挑战，也成了制约企业实现精细化运营过程中的重要因素。因此本文将从某社交 APP 的实际业务场景出发，与大家分享 <a href=\"http://doris.apache.org/\">Apache Doris</a>\" 如何助力企业构建高效的用户行为分析平台，实现<a href=\"https://archsummit.infoq.cn/2023/shanghai/track/1502\">数据驱动</a>\"业务发展。</p><p></p><h1>从一个业务场景说起</h1><p></p><p>在此以某社交 APP 为例，如果想要更好地提升用户使用体验并进一步实现转化率的增长，基于用户行为数据进行分析并调整业务相应策略是其中的关键，而各个业务团队对用户行为数据往往诉求存在一定差异：</p><p></p><p><a href=\"https://archsummit.infoq.cn/2023/shanghai/track/1503\">算法</a>\"团队想知道该 APP 最近一段时间的用户活跃数据，来判断是否需要调整推荐算法；商业部门想知道多少人观看广告后进行了点击，以分析广告带来的用户体验如何；运营部门想知道多少人通过落地页参与活动以及其转化率，以判断活动 ROI；产品部门想知道不同功能用户访问数据的差异，通过 A/B 实验指导正确的产品优化路径；......</p><p></p><p>为了承接以上需求，过去该公司使用了基于 Hive 的离线<a href=\"https://www.infoq.cn/article/G-NGJllXC8zhCjpWhbl9\">数据仓库</a>\"，整体数据平台架构如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/06/06c50c0cbfa37ff5d05bbdd2bfd98f90.png\" /></p><p></p><p>原始数据主要来自<a href=\"https://www.infoq.cn/article/FyrFhZJ2mGpJptmQLVGu\">关系型数据库 MySQL </a>\"、消息队列 Kafka 以及采集到的日志数据；利用 Sqoop 和 DataX 进行数据同步，通过 Flink 和 Spark 进行 ETL 以及 Yarn 和 Airflow 进行作业和任务调度；处理完成的数据落入 Hive ，Impala 作为分析引擎，为上层自研的 BI 产品提供交互式分析服务；</p><p></p><p>在这样的平台架构下，留存着一系列挑战有待解决：</p><p></p><p>数据时效性较差：原有架构数据链路比较长，数据时效性差，T+1 的数据生产模式严重影响业务分析的效率；运维成本高：数据链路较长，维护数据流转的成本高，一旦出现问题则需要排查上下游多个系统；且 Impala 本身不具备存储数据的能力，不得不引入 Hadoop 体系，而组件的繁多冗杂也大幅提升了企业运维的成本投入；数据分析难度高：对于数据分析人员来说，没有合适的分析函数将会带来很多额外的工作量，比如编写 SQL 逻辑冗长、执行 SQL 耗时耗力等，严重影响数据分析的效率。</p><p></p><p>以该公司数据为例，我们将 APP 数据简化抽象出来，以一个常见需求来看数据分析的成本：</p><p></p><p><code lang=\"sql\"> -- APP用户表\n CREATE TABLE app (\n     id int,   -- 用户id\n     a_time datetime,   -- 动作的时间\n     act varchar(20)  -- 动作（登录、观看、点击等等）\n ) \n unique key (id, a_time, act) \n COMMENT 'OLAP' DISTRIBUTED BY HASH(`id`) BUCKETS 8  \n</code></p><p></p><p>以背景介绍中的需求为例，算法部门想知道该 APP 最近一段时间的用户活跃及留存数据，来判断是否需要进行推荐算法和展示页的调整。上述其实就是一个求留存率的需求，实现逻辑并不复杂，我们可以很容易写出如下SQL：</p><p></p><p><code lang=\"sql\">select dt, activ_2 / activ_1 as retention\nfrom\n(\n    select to_date(aa.o_time) as dt, count(distinct a.id) as activ_1,\n    count(distinct b.id) as  activ_2\n    from app a\n    left join app b\n    on a.id = b.id and to_date(a.a_time) = days_add(to_date(b.a_time), 1)\n    where to_date(a.a_time) = 'xxxx'\n    group by to_date(aa.a_time)\n) as aa\n</code></p><p></p><p>但其中不能忽视的问题出现了，我们每查询一个留存比例就需要 Join APP 表自身一次，查询多个比例则需要 Join 该表自身多次，SQL 语句变得无比冗长；同时当执行该 SQL 时，多表 Join 带来的耗时也会变得很长。由此可知，没有合适的行为分析函数，会降低分析过程的效率。</p><p></p><h1>全新的用户行为分析平台</h1><p></p><p>经过慎重选型和对比，该公司决定使用 Apache Doris 来作为分析和计算引擎，主要考虑到如下优势：</p><p></p><p>数据集成简易：提供无缝接入 Kafka 和<a href=\"https://www.infoq.cn/article/3xtSDtHUgTKRsyw3kZXH\"> MySQL </a>\"的能力，可复用已有架构并减少对接工作量；架构简单：只有 FE 和 BE 两种角色，无需引入第三方组件，维护成本极低；性能优异：列式存储引擎、MPP 查询框架、全向量化执行，在实际测试中性能表现突出；功能丰富：支持丰富的用户分析函数，分析结果即查即出；....</p><p></p><p>在引入 Apahce Doris 后，整体数据架构得到简化，数据处理链路得到大幅缩短，以下是新的架构：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e3/e3d7e03a63525f21746b423782f48a7c.png\" /></p><p></p><h3>数据导入更便捷</h3><p></p><p>首先，Apache Doris 数据生态丰富，提供了多种数据导入方式，与已有数据源无缝对接：</p><p></p><p>通过 Routine Load 可以直接订阅 Kafka 数据；通过 INSERT INTO SELECT可以导入外部表的数据，目前已支持 MySQL、Oracle、PostgreSQL、SQL Server 等多个数据源；通过 Stream Load 可以直接导入本地数据文件；......</p><p></p><p>用户可以针对不同的数据源选择不同的数据导入方式，以快速集成来自不同数据源的数据。文档参考：https://doris.apache.org/zh-CN/docs/dev/data-operate/import/load-manual</p><p></p><p>其次，Apache Doris 1.2 版本中增加了 Multi-Catalog 功能，可实现无缝对接外部异构数据源，用户无需进行数据导入，即可直接通过创建 CREATE CATALOG  来查询底层数据。相对外部表， Multi-Catalog 无需创建表与表之间的映射关系，可以实现元数据层的对接，进一步加强联邦数据分析能力。</p><p></p><p><code lang=\"sql\">-- 我们以mysql为例，来详细讲解读取和写入的具体实现\n\n-- 创建catalog\nCREATE CATALOG jdbc PROPERTIES (\n    \"type\"=\"jdbc\",\n    \"jdbc.user\"=\"root\",\n    \"jdbc.password\"=\"123456\",\n    \"jdbc.jdbc_url\" = \"jdbc:mysql://127.0.0.1:13396/demo\",\n    \"jdbc.driver_url\" = \"file:/path/to/mysql-connector-java-5.1.47.jar\",\n    \"jdbc.driver_class\" = \"com.mysql.jdbc.Driver\"\n);\n\n其中jdbc.driver_url可以是远程jar包：\n\nCREATE CATALOG jdbc PROPERTIES (\n    \"type\"=\"jdbc\",\n    \"jdbc.user\"=\"root\",\n    \"jdbc.password\"=\"123456\",\n    \"jdbc.jdbc_url\" = \"jdbc:mysql://127.0.0.1:13396/demo\",\n    \"jdbc.driver_url\" = \"https://path/jdbc_driver/mysql-connector-java-8.0.25.jar\",\n    \"jdbc.driver_class\" = \"com.mysql.cj.jdbc.Driver\"\n);\n\n-- 创建catalog后，可以通过 SHOW CATALOGS 命令查看 catalog：\nMySQL [(none)]&gt; show catalogs;\n+-----------+-------------+----------+\n| CatalogId | CatalogName | Type     |\n+-----------+-------------+----------+\n|         0 | internal    | internal |\n|     10480 | jdbc        | jdbc     |\n+-----------+-------------+----------+\n\n-- 通过 SWITCH 命令切换到 jdbc catalog，并查看其中的数据库\nMySQL [(none)]&gt; switch jdbc;\nQuery OK, 0 rows affected (0.02 sec)\n\nMySQL [(none)]&gt; show databases;\n+--------------------+\n| Database           |\n+--------------------+\n| __db1              |\n| _db1               |\n| db1                |\n| demo               |\n| information_schema |\n| mysql              |\n| mysql_db_test      |\n| performance_schema |\n| sys                |\n+--------------------+\n\nMySQL [demo]&gt; use db1;\nReading table information for completion of table and column names\nYou can turn off this feature to get a quicker startup with -A\nDatabase changed\n\nMySQL [db1]&gt; show tables;\n+---------------+\n| Tables_in_db1 |\n+---------------+\n| tbl1          |\n+---------------+\n\n-- 使用catalog查询外部数据源\nMySQL [db1]&gt; select * from tbl1;\n+------+\n| k1   |\n+------+\n|    1 |\n|    2 |\n|    3 |\n|    4 |\n+------+\n\n-- 创建doris表，注意schema与mysql一致\nCREATE TABLE IF NOT EXISTS test.test (\n    k1 int\n)\nDUPLICATE KEY(`col1`)\nDISTRIBUTED BY HASH(col1) BUCKETS 1\nproperties(\n\"replication_num\"=\"1\"\n);\n\n-- 使用catalog直接将mysql中的数据导入doris\n-- 我们只用三级元数据层级，catalog.db.table的方式\ninsert into internal.test.test select k1 from jdbc.db1.tbl1;\n</code></p><p></p><h3>数据时效性提升</h3><p></p><p>数据架构简洁有力，引入<a href=\"https://www.infoq.cn/article/0MiKpHhupXlSOFjbxQrV\"> Apache Doris </a>\"后，数据架构缩减到 3 层，有效避免了过长数据处理链路带来的时延，整体数据时效性从天级降至分钟级；</p><p></p><p>用户查询耗时更低，SQL 查询耗时从过去的分钟降低至秒级甚至毫秒级，极大提升了业务分析人员的分析效率。</p><p></p><h3>数据分析效率进一步提升</h3><p></p><p>前文中有提到，没有合适的分析函数会使得分析工作变得艰难；而 Apache Doris 为用户行为分析提供了丰富的分析函数，使得数据分析难度大幅降低，这些函数包括但不限于：</p><p></p><p>intersect_countsequence_countsequence_matchretentionwindow_funnelArray 类函数......</p><p></p><h1>丰富的用户行为分析函数</h1><p></p><p></p><h3>数据准备</h3><p></p><p>在此以上述 APP 表为例，前期需要完成建表以及数据导入等准备工作：</p><p></p><p><code lang=\"sql\"> -- 建表\n CREATE TABLE app (\n     id int,   -- 用户id\n     a_time datetime,   -- 动作的时间\n     act varchar(20)  -- 动作（登录、观看、点击等等）\n ) \n unique key (id, a_time, act) \n COMMENT 'OLAP' DISTRIBUTED BY HASH(`id`) BUCKETS 8  \n PROPERTIES (\"replication_allocation\" = \"tag.location.default: 1\");\n \n \n -- 插入数据\ninsert into app values \n(111, '2022-01-01 10:00:00', 'login'), \n(111, '2022-01-01 10:01:00', 'view'),\n(111, '2022-01-01 10:02:00', 'click'), \n(111, '2022-01-02 10:00:00', 'login'), \n(111, '2022-01-02 10:01:00', 'view'), \n(222, '2022-01-01 11:00:00', 'login'),\n(222, '2022-01-01 11:01:00', 'view'), \n(333, '2022-01-01 12:00:00', 'login'),\n(333, '2022-01-01 12:01:00', 'view'),\n(444, '2022-01-01 13:00:00', 'login');\n \n -- 查看数据\nselect * from app order by a_time;\n+------+---------------------+-------+\n| id   | a_time              | act   |\n+------+---------------------+-------+\n|  111 | 2022-01-01 10:00:00 | login |\n|  111 | 2022-01-01 10:01:00 | view  |\n|  111 | 2022-01-01 10:02:00 | click |\n|  222 | 2022-01-01 11:00:00 | login |\n|  222 | 2022-01-01 11:01:00 | view  |\n|  333 | 2022-01-01 12:00:00 | login |\n|  333 | 2022-01-01 12:01:00 | view  |\n|  444 | 2022-01-01 13:00:00 | login |\n|  111 | 2022-01-02 10:00:00 | login |\n|  111 | 2022-01-02 10:01:00 | view  |\n+------+---------------------+-------+\n</code></p><p></p><h3>留存分析</h3><p></p><p>算法部门想知道该 APP 最近一段时间的用户活跃及留存数据，来判断是否需要进行推荐算法和展示页的调整。该需求可以理解为留存率，主要是指注册后在一定时间内或者一段时间后有登录行为且仍在继续使用该产品的留存用户，在当时总的新增用户中所占比例。该需求为前文提到的第一个需求，接下来我们看看使用 Doris 提供的分析函数如何实现呢？</p><p></p><p>正交 Bitmap 函数计算留存率</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a5/a5077e69567ca4eb624c2bf1a1e5f4c0.png\" /></p><p></p><p><code lang=\"sql\">-- 求第N天登录的用户\nselect intersect_count(to_bitmap(id), to_date(a_time), '2022-01-01') as first from app;\n+-------+\n| first |\n+-------+\n|     4 |\n+-------+\n\n\n-- 求第N天和N+1天都登录的用户\nselect intersect_count(to_bitmap(id), to_date(a_time), '2022-01-01', '2022-01-02') as second from app;\n+-------+\n| second |\n+-------+\n|     1 |\n+-------+\n\n\n-- 二者的比例即为所求\nselect intersect_count(to_bitmap(id), to_date(a_time), '2022-01-01', '2022-01-02') / intersect_count(to_bitmap(id), to_date(a_time), '2022-01-01') as rate from app;\n+------+\n| rate |\n+------+\n| 0.25 |\n+------+\n</code></p><p></p><p>Retention 函数计算留存率</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c1/c1b7380af2a6f493337cc1767205edb9.png\" /></p><p></p><p>Retention 通常需要跟group by联合使用，以获取group by列匹配的条件。而输入的参数是可变长参数，Retention 会返回跟输入参数长度相等的数组。数组取值则要看匹配条件能否满足，如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a86e8bf515eebbe34b985076bb47eb5f.png\" /></p><p></p><p><code lang=\"sql\">-- 求第N天登录的用户\nselect id, retention(to_date(a_time)='2022-01-01') as first from app group by id;\n+------+-------+\n| id   | first |\n+------+-------+\n|  222 | [1]   |\n|  111 | [1]   |\n|  444 | [1]   |\n|  333 | [1]   |\n+------+-------+\n\n-- 求第N天和N+1天都登录的用户\nselect id, retention(to_date(a_time)='2022-01-01', to_date(a_time)='2022-01-02') as second from app group by id;\n+------+--------+\n| id   | second |\n+------+--------+\n|  222 | [1, 0] |\n|  111 | [1, 1] |\n|  444 | [1, 0] |\n|  333 | [1, 0] |\n+------+--------+\n\n-- 二者的比例即为所求\nselect sum(re[2])  / sum(re[1]) as rate  from (select id, retention(to_date(a_time)='2022-01-01', to_date(a_time)='2022-01-02') as re from app group by id) as a;\n+------+\n| rate |\n+------+\n| 0.25 |\n+------+\n</code></p><p></p><h3>路径分析</h3><p></p><p>商业部门想知道多少人观看广告后进行了点击，以分析广告带来的用户体验是否合适。该需求可以理解为行为分析中的路径分析，而路径分析是一种基于行为顺序、行为偏好、关键节点、转化效率的探索型模型。依据路径分析可以直观掌握用户行为扩展路线，以供优化节点内容、提升整体转化效率。</p><p></p><p>sequence_count 路径分析</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ba/ba458bd0303d89357bac32b228db3527.png\" /></p><p></p><p>sequence_count通常需要跟group by一起使用，以获取group by列匹配的条件。函数使用方法为：sequence_count((?1)(?t&lt;3600)(?2), date, col1=1, col3='a')，表明当前 col1=1 是第一个条件；此时如果有 col2=a，并且 col2 的时间与 col1 的时间在 3600 秒之内(col2 的时间减去 col1 的时间)，则sequence_count对这样一组匹配结果记一个数。其工作逻辑如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8d/8d87f9cb9d79a31c40a3a8863c5e8cc0.png\" /></p><p></p><p><code lang=\"sql\"> -- 哪些用户在登录后2分钟内观看了广告\nselect id, sequence_count('(?1)(?t&lt;=120)(?2)', a_time, act = 'login', act = 'view') as result from app group by id;\n+------+--------+\n| id   | result |\n+------+--------+\n|  111 |      2 |\n|  444 |      0 |\n|  222 |      1 |\n|  333 |      1 |\n+------+--------+\n-- 上述SQL可以看到，先观看广告再点击广告的用户有3人；而111这个用户有两次都是登录后观看了广告。pattern中的(?1)对应act = 'login'，(?2)对应act = 'view'，时间间隔为120秒\n\n\n-- 哪些用户在登录后2分钟内观看了广告，并在2分钟内点击了广告\nselect id, sequence_count('(?1)(?t&lt;=120)(?2)(?t&lt;=120)(?3)', a_time, act = 'login', act = 'view', act = 'click') as result from app group by id;\n+------+--------+\n| id   | result |\n+------+--------+\n|  333 |      0 |\n|  111 |      1 |\n|  444 |      0 |\n|  222 |      0 |\n+------+--------+\n</code></p><p></p><h3>漏斗分析</h3><p></p><p>运营部门想知道多少人通过落地页参与活动以及其转化率，以判断活动 ROI 以及确定策略带来的价值是否符合预期。该需求可以理解为转化率，而转化率主要是指是指用户进行了相应目标行动的次数与总次数的比率；转化率可以衡量一个产品用户需求强弱、评价产品设计好坏、对比流程和渠道权重等。</p><p></p><p>window_funnel 漏斗转化分析</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2e/2e2ffb35087ae6e0a220e60ca60b07c1.png\" /></p><p></p><p>window_funnel也是有可变参数，并且需要指定时间窗口列和窗口大小。假设窗口大小为 3600 秒，并且datetime列为时间列，则窗口就是沿着datetime列滑动。首先匹配条件1 ，如果有一列满足则待返回值变成1；然后去匹配条件 2，如果条件 2 匹配，并且跟条件 1 相差时间在 3600 秒内，则待返回值加一；接着匹配条件3，过程与条件2相同。最后返回一个计数值，该值表明这些可变条件满足多少个。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d1/d1558ccb7e064d17328e5b4c6a78a06f.png\" /></p><p></p><p><code lang=\"sql\">-- 哪些用户在登录后2分钟内观看了广告\nselect id, window_funnel(120, 'default', a_time, act = 'login', act = 'view') as w  from app  group by id;\n+------+------+\n| id   | w    |\n+------+------+\n|  333 |    2 |\n|  222 |    2 |\n|  111 |    2 |\n|  444 |    1 |\n+------+------+\n-- 从上述SQL可以看出，第一个参数120秒指定了滑动窗口的大小，并且窗口是按a_time这一列滑动的。act = 'login', act = 'view'是两个条件，显然用户111，222,333均满足这两个条件，即一小时内，先登录再观看广告；但是444这位用户就不满足先登录再观看广告，因为他只有登录操作，所以window_funnel对他返回了1，因为他只满足第一个条件\n\n-- 根据上述结果进行筛选，哪些用户在登录后2分钟内观看了广告\nselect id, window_funnel(120, 'default', a_time, act = 'login', act = 'view') as w  from app  group by id having w = 2;\n+------+------+\n| id   | w    |\n+------+------+\n|  111 |    2 |\n|  333 |    2 |\n|  222 |    2 |\n+------+------+\n\n\n-- 哪些用户在一小时内，登录、观看、点击都执行了\nselect id, window_funnel(3600, 'default', a_time, act = 'login', act = 'view', act = 'click') as w from app  group by id having w = 3;\n+------+------+\n| id   | w    |\n+------+------+\n|  111 |    3 |\n+------+------+\n</code></p><p></p><h3>其他</h3><p></p><p></p><h4>Array 类函数</h4><p></p><p>熟悉行为分析的同学都知道，固然丰富的分析函数有助于帮助我们提高分析效率，但是分析函数无法覆盖所有的场景，一些特殊的需求还是依赖特殊或者复杂的 SQL 来实现，而这些 SQL 很多都需要借助数组来实现。鉴于篇幅所限，该部分不会展示纷繁复杂的需求，而是会通过几个浅显的例子来展示 Apache Doris 丰富的数组类函数。</p><p></p><p><code lang=\"sql\">// split_by_string函数：指定分隔符切分字符串，得到切分后的数组：\nselect split_by_string('a#b#c#d','#');\n+---------------------------------+\n| split_by_string('a#b#c#d', '1') |\n+---------------------------------+\n| ['a', 'b', 'c', 'd']            |\n+---------------------------------+\n\n\n// array_sort函数：对数组进行升序排序。下表的k1是数组类型：\nselect k1, array_sort(k1) from test;\n+-----------------------------+-----------------------------+\n| k1                          | array_sort(`k1`)            |\n+------+-----------------------------+----------------------+\n| NULL                        | NULL                        |\n| [1, 2, 3, 4, 5, 4, 3, 2, 1] | [1, 1, 2, 2, 3, 3, 4, 4, 5] |\n+-----------------------------+-----------------------------+\n\n// array_size函数：获取数组大小。下表的k1是数组类型：\nselect k1,size(k1) from test;\n+-----------+------------+\n| k1        | size(`k1`) |\n+-----------+------------+\n| [1, 2, 3] |          3 |\n| []        |          0 |\n| NULL      |       NULL |\n+-----------+------------+\n\n// array_remove函数：返回移除所有的指定元素后的数组。下表k1是数组类型：\nselect k1, array_remove(k1, 1) from test;\n+--------------------+-----------------------+\n| k1                 | array_remove(k1, 1) |\n+--------------------+-----------------------+\n| [1, 2, 3]          | [2, 3]                |\n| [1, 3]             | [3]                   |\n| NULL               | NULL                  |\n| [1, 3]             | [3]                   |\n| [NULL, 1, NULL, 2] | [NULL, NULL, 2]       |\n+--------------------+-----------------------+\n\n\n// array_slice函数：返回一个子数组，包含所有从指定位置开始的指定长度的元素。下表k1是数组类型。从1开始从左至右计数；位置可以为负数，负数从-1开始从右到左开始计数\n\nselect k1, array_slice(k1, 2, 2) from array_type_table_nullable;\n+-----------------+-------------------------+\n| k1              | array_slice(`k1`, 2, 2) |\n+-----------------+-------------------------+\n| [1, 2, 3]       | [2, 3]                  |\n| [1, NULL, 3]    | [NULL, 3]               |\n| [2, 3]          | [3]                     |\n| NULL            | NULL                    |\n+-----------------+-------------------------+\nselect k1, array_slice(k1, -2, 1) from test;\n+-----------+--------------------------+\n| k1        | array_slice(`k1`, -2, 1) |\n+-----------+--------------------------+\n| [1, 2, 3] | [2]                      |\n| [1, 2, 3] | [2]                      |\n| [2, 3]    | [2]                      |\n| [2, 3]    | [2]                      |\n+-----------+--------------------------+\n\n\n// array_distinct函数：去除数组中的重复元素。下表k1是数组类型\nselect k1, array_distinct(k1) from test;\n+-----------------------------+---------------------------+\n| k1                          | array_distinct(k1)        |\n+-----------------------------+---------------------------+\n| [1, 2, 3, 4, 5]             | [1, 2, 3, 4, 5]           |\n| [6, 7, 8]                   | [6, 7, 8]                 |\n| []                          | []                        |\n| NULL                        | NULL                      |\n| [1, 2, 3, 4, 5, 4, 3, 2, 1] | [1, 2, 3, 4, 5]           |\n| [1, 2, 3, NULL]             | [1, 2, 3, NULL]           |\n| [1, 2, 3, NULL, NULL]       | [1, 2, 3, NULL]     |\n+-----------------------------+---------------------------+\n\n\n// 配合array使用较多的explode函数，可以轻松实现列转行：\nselect e1 from (select 1 k1) as t lateral view explode([1,2,3]) tmp1 as e1;\n+------+\n| e1   |\n+------+\n|    1 |\n|    2 |\n|    3 |\n+------+\n\n// explode_split函数：按分隔符分割字符串，并将结果打散，实现列转行：\nselect * from example1;\n+---------+\n| k1      |\n+---------+\n| a, b, c |\n+---------+\nselect e1 from example1 lateral view explode_split(k1, ',') tmp1 as e1;\n+------+\n| e1   |\n+------+\n|  b   |\n|  c   |\n|  a   |\n+------+\n</code></p><p></p><h1>总结</h1><p></p><p>通过 Apache Doris 系统自身的优异能力和丰富的行为分析函数，已经有越来越多的企业选择基于 Apache Doris 构建高效的用户行为分析平台。后续我们仍会持续加强这方面的能力，包括提供更丰富的数据类型以及行为分析函数，如果您在搭建用户行为分析平台过程中遇到任何问题，欢迎联系社区进行支持。同时也欢迎加入 Apache Doris 社区，一起将 Apache Doris 建设地更加强大！</p><p></p><p>作者介绍：</p><p></p><p>李仕杨，SelectDB 生态研发工程师，Apache Doris Contributor</p><p></p>",
    "publish_time": "2023-03-20 16:57:56",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "荔枝集团Android-Cocos复合型App游戏启动优化分享｜图文详解",
    "url": "https://www.infoq.cn/article/qOWeKK9JYDuMqPwOuBSi",
    "summary": "<p>作者：胡骏麒，荔枝集团业务技术中心高级Android工程师，邮箱：hujunqi@lizhi.fm</p><p></p><p>随着荔枝集团发展越来越快，集团旗下产品也上线了游戏复合型产品，但目前产品线上Cocos游戏存在加载速度慢的问题。从线上数据可以看得出，约37%的数据花了4000毫秒以上的时间才能够进入到游戏，约54%耗时则在2000毫秒到4000毫秒之间，仅有8.25%的数据耗时少于2000毫秒，并且总体的耗时中位数是3380.5毫秒。</p><p></p><p>总体来说，Android Cocos原生化游戏的初始化-进入游戏自上线之后就被产运以及技术团队内诟病，是一个极度影响用户体验的关键点，也可能会有用户在等待进入游戏过久导致转化率降低。</p><p></p><h1>问题所在</h1><p></p><p></p><p>自Android从Cocos Web方案接入了Cocos 原生化方案之后，Cocos游戏加载速度从正常变成了目前很慢的速度。原因于在代码层面上之前的Web的接入方式完全不一样，不仅是加载的方式不一样了，原有的页面结构也需要大改，比如原有的首页Activity需要继承CocosActivity，游戏会因为CocosActivity的生命周期回调被暂停或恢复。</p><p></p><p>这也是跟Cocos官方提供的接入方式有关，Cocos官方的使用场景是整个App就是一个游戏，但是与我们的产品相悖，我们的AndroidApp是一个复合App包含原生，flutter，H5，Cocos游戏多重技术栈，这就导致游戏存在一定的问题，比如目前绝大部分AndroidApp都是以Activity作为主要页面组件，当CocosActivity进入后台之后，游戏就会被暂停导致无法进行游戏预加载，这就会明显导致进入游戏场景的速度很慢，明显影响到用户体验。</p><p></p><h1>分析</h1><p></p><p>以Cocos 3.6.1版本为准，其他版本可能存在差异。</p><p></p><h2>Cocos是如何被App控制的？</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/53/53129c0a127fea2ed3c4442b82549b19.png\" /></p><p>Activity 生命周期的简化图示。</p><p></p><p>Android是以Activity的形式作为页面载体，Activity不仅仅是一个UI层面的组件，它还是一个重要的具有IPC跨进程通信功能组件，并且有许多生命周期回调比如初始化onCreate等回调，并且这些回调也表明了相对应的状态。</p><p><img src=\"https://static001.geekbang.org/infoq/2e/2e6b114841cce6c78385d387fc7cb5ef.png\" /></p><p>Activity是如何被AMS（ActivityManagerService）创建的</p><p></p><p>Activity是如何被AMS（ActivityManagerService）创建的但是Activity的创建，各个运行状态都是通过AMS（ActivityManagerService）管理的，也可以简单的说开发者是不无法通过正常手段自行管理Activity的创建，运行以及销毁。那为什么要先介绍Activity的基本知识呢？因为Cocos在Android平台的原生化是完全依赖到了Activity，应该说是依赖了Google Android Game Development Kit里的GameActivity</p><p></p><h2>Google Android Game Development Kit又是什么？它有扮演了什么角色？</h2><p></p><p></p><p>Android Game Development Kit (AGDK) 包含一套工具和库，可帮助您开发和优化 Android 游戏，同时还能与现有游戏开发平台和工作流程集成。</p><p></p><p>GameActivity 是一个 Jetpack 库，旨在帮助 Android 游戏在应用的 C/C++ 代码中处理应用周期命令、输入事件和文本输入。GameActivity 是 NativeActivity 的直接后代，具有类似的架构：</p><p><img src=\"https://static001.geekbang.org/infoq/ee/eee398aa1e59dc068c588146b7bc0efb.png\" /></p><p></p><p>如上图所示，GameActivity 执行以下功能：</p><p>•通过 Java 端组件同 Android 框架进行交互。</p><p>•将应用周期命令、输入事件和输入文本传递到原生端。</p><p>•将 C/C++ 源代码建模为三个逻辑组件：</p><p>￮GameActivity 的 JNI 函数，直接支持 GameActivity 的 Java 功能，并会将事件加入 native_app_glue 中的队列。</p><p>￮native_app_glue，主要在自己的原生线程（不同于应用的主线程）中运行，并且使用其 Looper 执行任务。</p><p>￮应用的游戏代码，负责轮询和处理在 native_app_glue 内排队的事件，并在 native_app_glue 线程中执行游戏代码。</p><p></p><p>借助 GameActivity，您可以专注于核心游戏开发，并避免花费过多时间处理 JNI 代码。那么Cocos引擎是如何对接到AGDK里的呢？我以暂停为例：</p><p><img src=\"https://static001.geekbang.org/infoq/8b/8be0c7d1fd0d8ae5c88ccea4a8b71c2a.png\" /></p><p></p><p>Java层GameActivity将Stop生命周期回调通过JNI调用到C++层GameActivity的onNativeStop到android_native_app_glue里的onPause，android_native_app_glue通过Pipe管道将APP_CMD_STOP事件从主线程切换到游戏的主线程，将事件传递给了AndroidPlatform，并且AndroidPlatform则把_isVisible修改成false。</p><p></p><p>每当AndroidPlatform的一层循环调用的时候会检查_isVisible &amp;&amp; _hasWindow状态，如果TRUE就会继续游戏主线程逻辑，否则跳过。</p><p></p><p>总结：</p><p>1.GameActivity成为了Java层与C++层标准化桥梁，提供了一套对接方法。</p><p>2.Cocos游戏主线程会受GameActivity生命回调暂停或恢复主线程逻辑。</p><p>3.大部分Android App是以多个Activity作为页面栈进行管理，CocosActivity自然会因为生命周期调用被暂停。</p><p></p><h2>Cocos是如何获得Surface？</h2><p></p><p></p><p>从上图可以看得到Cocos利用GameActivity同步Java层生命周期调用，并且根据_isVisible &amp;&amp; _hasWindow状态，onStop控制_isVisible，那_hasWindow是又是被谁控制呢？</p><p><img src=\"https://static001.geekbang.org/infoq/a7/a7b548671831d17bff42afdedf93139d.png\" /></p><p></p><p>ViewRootImpl被调用performTraversals之后通过mWindowSession请求WMS(WindowManagerService)对Window进行relayout，当Native的Surface真正被创建之后，ViewRootImpl调用notifySurfaceCreated，将回调调用到Cocos的SurfaceView，然后SurfaceView才调用到注册了SurfaceHolder的GameActivity。</p><p></p><p>从上图可以得出：</p><p>1.Surface是由WMS管理，Activity进入前台则会获取，反之Activity进入后台则会被释放。</p><p>2.Cocos引擎根据surface是否有效暂停或恢复主线程逻辑。</p><p></p><h2>小结</h2><p></p><p>从以上分析，我们可以得出以下结论：</p><p>1.GameActivity成为了Java层与C++层标准化桥梁，提供了一套对接方法。</p><p>2.Cocos游戏主线程会受GameActivity生命回调暂停或恢复主线程逻辑。</p><p>3.绝大部分Android App是以多个Activity作为页面栈进行管理，CocosActivity自然会因为生命周期调用被暂停。</p><p>4.Surface是由WMS管理，Activiyt进入前台则会获取，反之Activity进入后台则会被释放。</p><p>5.Cocos引擎根据surface是否有效暂停或恢复主线程逻辑。</p><p></p><p>而导致游戏被暂停从而致使游戏初始化-进入游戏的时间耗时的原因则是：</p><p></p><p>1.游戏开启需要切换到首页，在切换到首页之前，游戏无法恢复主线程运行</p><p>2.Surface获取需要时间，且需要切换到首页之后才能够被获取，游戏无法恢复主线程运行只要解决以上2个点，那就可以在游戏加载上有巨大的提升。</p><p></p><h1>解决方案</h1><p></p><p></p><p>目前问题最紧迫的是游戏加载速度过慢的问题，提高用户体验，尽可能需要有一个成本最低的方案且对后续Cocos升级不会有产生影响。</p><p></p><h2>与GameActivty解耦</h2><p></p><p></p><p>1.GameActivity成为了Java层与C++层标准化桥梁，提供了一套对接方法。</p><p>2.Cocos游戏主线程会受GameActivity生命回调暂停或恢复主线程逻辑。</p><p></p><p>从上面的分析可以得出:GameActivity其实是是一个标准化的桥梁，是一个控制器，但只是因为Activity是被AMS管理才无法控制，那有没有可能通过技术手段将GameActivity被我控制？Android Activity是由AMS管理，并且又由ActivityThread用Classloader动态加载Class，并且在创建的过程中会创建PhoneWindow以及attach比如Application等，但我们可以换个角度去思考这个事情。</p><p><img src=\"https://static001.geekbang.org/infoq/78/781fe382da4ff453074115562c2964c1.png\" /></p><p>我们将GameActivity看作为一个控制器，Activity已经帮我处理好了各种状态，但如果直接将Activity拿来用的话是会出问题的，会出现类似这样的崩溃。</p><p><img src=\"https://static001.geekbang.org/infoq/d0/d0100e8ca38875521f794021617190f4.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b2/b2388135b225e82fd3bf4979461a6de2.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/de/dee2403b44de480e544115bb52c6d720.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d9/d92ba23fc1fe98c0204034012c416702.png\" /></p><p></p><p>还记得上面的说的：</p><p>在创建的过程中会创建PhoneWindow以及attach比如Application等</p><p></p><p>针对以上两个点，我们只需要两点处理，通过以下方式则可规避掉崩溃的问题：</p><p>1.利用外部的Activity提供的PhoneWindow</p><p>2.通过反射的方式，将Application设置到GameActivity</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5e/5e6c2ab1dd4dc23ab42ecb394a335047.png\" /></p><p>那面对C++层对Java的调用该怎么处理呢？</p><p><img src=\"https://static001.geekbang.org/infoq/cb/cb3cb195d3be6db951d2440a3a0b2cb0.png\" /></p><p></p><p>因为C++调用Java是通过反射的方式去调用的，只要class和method的方法名是正确的，我们就可以正确做到桥接。以上，就已完成了GameActivity的基本解耦，当然还有别的地方需要改动，但方法论并没有变。</p><p></p><h2>规避Surface获取的困难</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/54/5432b1cb5d4b125d5e247c785072146e.png\" /></p><p></p><p>从上面的流程图其实可以看得出，Surface的获取是根据上层决定的，当Activity进入到后台之后（有一个新的Activity覆盖或App进入到后台），Surface就会销毁，所以想要游戏能在不一样的Activity上运行，在对GameActivity解耦之后，仅仅需要将SurfaceView进行addView到具体的Activity里的ViewGroup里即可。</p><p></p><p>为了提升游戏的加载速度，采取了一套预先加载的策略：</p><p>1.在匹配玩家过程中将SurfaceView添加到匹配页面</p><p>2.在匹配页面等待游戏加载完成，达成只要切换页面游戏即可加载完成的目的</p><p></p><p>以上方式还解决了一个问题，那就是Cocos引擎初始化以及进入默认场景的主线程被原有的GameActivity中断的问题。比如用户的行为是不可阻碍的，任何页面切换都导致GameActivity进入到了后台，那会暂停Cocos引擎并且Surface也会被释放。所以利用匹配玩家过程中的耗时去同样消耗Cocos引擎初始化以及进入默认场景的耗时，这样就可以避免上述问题的发生。</p><p></p><h2>成果</h2><p></p><p></p><p>数据采集方式：</p><p>模拟用户行为：App进入到首页之后就点击档位选择页并且进行匹配游戏，每次进入完游戏之后，杀掉App再进行测试。</p><p></p><p>中低端机代表：三星 A13 5G</p><p><img src=\"https://static001.geekbang.org/infoq/de/dee2bf3d74c1d7fb2e96e52d5a18c1b9.png\" /></p><p>高端机代表：一加10</p><p><img src=\"https://static001.geekbang.org/infoq/2d/2dc5b98def073f991a4cfcc574ca700a.png\" /></p><p></p><p>从数据以及体感上来看的话，Cocos游戏改造优化后带来的提升十分的明显，也恢复到了正常且较为优秀的加载速度了。</p><p></p><h2>线上数据</h2><p></p><p></p><p>1.耗时小于2000毫秒从原有的8.25%大幅升至48.86%，且从原先的最少区间变为最大区间</p><p>2.耗时小于4000毫秒从原有62.28%大幅升至82.37%，绝大部分数据都在4000毫秒以内</p><p>3.数据中位数从3380.5毫秒减少到2033.5毫秒，普遍具有一秒以上的速度提升</p><p></p><h2>结论</h2><p></p><p></p><p>通过系统性对整个框架的分析，得出一套仅在Java做修改就可以极大提升游戏加载速度的方案，并且与GameActivity解耦，承载游戏的SurfaceView能够在任意Activity正确显示，仅改动了Android平台上层代码，Android端实现了游戏线程自主控制，不仅仅是用户体验的提升，优化了项目结构，还为未来游戏-原生跨环境业务发展提供了底层支持。</p><p></p><h2>引用</h2><p></p><p></p><p>Android Game Development Kit：https://developer.android.google.cn/games/agdk/overview?hl=zh-cn</p><p></p><h2>关于荔枝集团</h2><p></p><p></p><p>荔枝集团打造了综合性的全球化音频生态系统，致力于通过多样化产品组合满足用户对于音频娱乐以及在线社交的需求，使每个人都能在全球化的音频生态系统中通过声音连接与互动。荔枝公司于2020年1月在纳斯达克上市。</p>",
    "publish_time": "2023-03-20 17:57:18",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "我在GitHub 黑市买“水军”：一万颗star只要4000多元，人人都能“一夜爆火”",
    "url": "https://www.infoq.cn/article/DVZzvDdxcElCRuLXTTk2",
    "summary": "<p></p><p>“说实在的，我的梦想就是拥有个几千star的 <a href=\"https://www.infoq.cn/article/removing-jquery-from-github-frontend\">GitHub</a>\" 项目。”有开发者说道。</p><p>&nbsp;</p><p>虽然 GitHub star 数现在可能跟公众号的“阅读量”或者微博的“转发量”一样，是一种虚无飘渺的虚荣心指数，但不妨碍它成为开源社区中展示普遍认同的一大重要指标。项目star数也会影响很多重大的高风险决策，包括选择哪些项目、为哪些初创项目注资，甚至选择哪家企业入职等。</p><p>&nbsp;</p><p>但是，现在人们已经不相信 star数这个指标了。“GitHub&nbsp;项目的 star 数我倒是不在乎，因为这东西太容易造假了，也代表不了项目的品质。我就不会去跟别人说给我的项目点 star 哦，这种行为在我看来真的 low 得不能再 low 了。​​​”有开发者说道。</p><p>&nbsp;</p><p>事实上，这位开发者说得并没有错。我们总会在 GitHub 上发现一些迅速蹿红的开源项目，刚刚开放，每周就能拿下几百star。真有那么优秀吗？似乎好得令人难以置信了。还有一些新项目刚上架几天就star数猛增，这可是知名老项目在发布新版本或者其他重大公告才能拥有的待遇。</p><p>&nbsp;</p><p>最近，开源编排平台 <a href=\"https://dagster.io/blog/fake-stars\">Dagster</a>\" 分享了在抽查一部分代码仓库后，发现了的几位“嫌疑人”，而在 Dagster 披露后，一些账户已经被删除。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9a/9ae863945599d873ca7e4ac4a7a5215d.png\" /></p><p></p><p>请注意账户创建日期，这跟正常的GitHub用户明显有所区别</p><p></p><h2>买了star后，项目一夜爆火</h2><p></p><p>&nbsp;</p><p>Dagster 的几位研究人员亲身体验了购买star 给项目带来的优越。Dagster 建立了一个虚构的代码仓库（frasermarlow/tap-bls）并买了一堆 star。然后，Dagster&nbsp;为该账户设计了个人资料文件，并使用 GitHub REST API（通过pygithub）和 GitHub Archive 数据库展开了一系列测试。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9e/9eb51232196f223a93a63e958d4c8659.png\" /></p><p>Dagster&nbsp;的代码仓库一夜之间就火了……</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c8/c848684e125f871466ac026c34a52313.png\" /></p><p></p><p>跟它一起“蹿红”的项目还有不少。</p><p>&nbsp;</p><p>GitHub star在哪里可以买到呢？用不着潜入暗网，直接在谷歌上搜就能找到几十种服务。为了观察这些虚假 GitHub 账户的个人资料，Dagster 通过以下服务买了star：</p><p>&nbsp;</p><p>Baddhi Shop，低成本伪造各种线上公开影响力指标的专业“服务商”。最低64美元，你就能买到1000颗 GitHub star。GitHub24，由Möller und Ringauf&nbsp;GbR提供的服务，价格比Baddhi Shop要高得多（每star 0.85欧元）。</p><p>&nbsp;</p><p>有一说一，这帮家伙还挺讲“诚信经营”：Dagster 买的 star 很快就到账了。GitHub24 在48小时内就交付了100颗 star。在此之前，Dagster 的代码仓库只有3颗star。由于 Baddhi Shop的价格更便宜，所以&nbsp;Dagster 在这个渠道上订购了 500 颗star，而一周之内对方同样成功履约。</p><p>&nbsp;</p><p>不过，Dagster 表示“一分钱一分货”：一个月后 GitHub24 交付的 24 颗 star 都还在，但纯伪造的 Baddhi Shopstar 只剩下四分之三，那四分之一可能是被 GitHub 的完整性团队撤掉了。</p><p></p><h2>star 数，还重要吗</h2><p></p><p>&nbsp;</p><p>“我的前雇主在他们的工作描述和招聘推介中使用了 GitHub stars。他们定期鼓励员工去 GitHub 上为公司的存储库加注星标。在全体会议上，GitHub stars 是他们报告的重点工作之一：我们在 GitHub stars 中超过了 X（鼓掌）。”网友“penguin_booze”爆料道。</p><p>&nbsp;</p><p>当 stars 数成为企业关注的重点时，压力就给到了员工或者求职者。“能在 GitHub 上拿到三位数的 Star 的本科生至少进 BAT 毫无压力。”有网友称。这也导致了国内前几年开源项目刷 star 泛滥。</p><p>&nbsp;</p><p>当star造假越来越多，有些开发者在评价开源项目的时候也会越来越少地真正在意star数。“就我个人而言，我从不看star数，因为即使这是合理的，它也没有让我比从&nbsp;repo中看到其它更有用的东西。”网友<a href=\"https://news.ycombinator.com/item?id=35207020\">“ziml7”</a>\"说道。</p><p>&nbsp;</p><p>ziml7 表示，“我倾向于检查最早和最新提交之间的时间差异，这可以让我确定这不是一个某人花了几周时间编写代码、放在 GitHub 上，然后就被遗忘了的项目。我也会检查 issues。我会寻找比正在显示更多的、已经解决的issues&nbsp;，但我会快速浏览下来大致了解有多少是真正有意义的issues&nbsp;。我还从自述文件和文档中获得线索。如果这些issues&nbsp;存在就容易通过（检测），但如果它们不仅存在，并且既清晰又详细，那肯定对我的判断会有帮助。</p><p>&nbsp;</p><p>但 ziml7 的观点也得到了一些质疑。网友“imadj”表示，许多维护人员只是将问题隐藏起来了，并没有真正解决。许多人以 0 个未解决的 issues而自豪，好像这意味着什么。但如果他们会玩这个游戏，那么世界上任何软件都可以有 0 个 issues。“因此，除非您真的精通该项目并花了一些时间关注它，否则star数实际上可能是判断项目质量和声誉的更好指标。”</p><p>&nbsp;</p><p>另外，在评估几个不同的 repos 以选择特定工具工作时，一些开发者会用 star 数进行判断。“如果其中一个repo有更多的star，我在选择时会仔细权衡。提交的新鲜度绝对重要，但对我来说，有许多人加注星标这一事实表明，这个repo是吸引人眼球的和活跃的。”网友“cdiamand”表示。</p><p>&nbsp;</p><p>对于ziml7 提出的查看日期，也有开发者表示反对：“提交日期可以任意更改。”</p><p>&nbsp;</p><p>网友“debarshri”指出，在评估 OSS 项目时，关键指标是社区活动。“GitHub stars 是一个很弱的社区活动指标。首先，它可以被造假。此外，Stars 的操作门槛非常低，为该项目加星的人并不真的会使用它。”</p><p>&nbsp;</p><p>“debarshri”认为有两个社区活动指标非常重要：GitHub issues 和 slack/discord/discourse 评论。“在我看来，GitHub issues 的一个关键是，如果 GitHub issues 主要由核心团队提出，那不是一个好兆头。您需要来自客户或用户而不是团队的大量问题。如果项目正在解决实际问题，这是一个很好的指标。Stars 操作门槛极低。松散的评论也一样，它应该既有分量又有新鲜感。</p><p>&nbsp;</p><p>无论如何，可以看出，Star 数目前在一些开发者心中依然有很重的分量。我们还无法完全抛弃这个衡量指标。但现在，大多数 GitHub 的 star 分析工具和相关讨论文章都没有解决 star 数灌水的问题。那么，还有其它办法吗？</p><p></p><h2>如何识别假star？</h2><p></p><p>&nbsp;</p><p>为了搞清楚GitHub上的 star造假问题有多严重，Dagster 与垃圾邮件和滥用专家 Alana Glassco 一起深入研究了数据模式，分析了GitHub Archive数据库中的公共事件数据。</p><p>&nbsp;</p><p>机器学习可以帮忙吗？比如买点假star，然后训练分类器来识别真star和假star。Dagster 表示，这种方法存在几个问题：</p><p>&nbsp;</p><p>GitHub star 卖家非常小心谨慎，而且会主动回避检测，所以很难根据名称、个人简介等直观特征对其出做分类。标记及时性。为了避免被发现，卖家会不断调整自己的行动策略。因此，标记数据不仅难以获得，而且就在模型训练的过程中，这些数据内容可能就已经过时。</p><p>&nbsp;</p><p>注：检测工作中，经常会将机器学习与启发式方法结合使用来识别恶意行为者，本次研究最终采用了启发式的检测思路。</p><p>&nbsp;</p><p>在买下假 star 之后，这些假 star 又可以分成两类：</p><p>&nbsp;</p><p>一眼为假。卖家根本就不加掩饰，只要点开个人资料，就能马上看出这帮给star的用户根本不是真人。用心造假。另一个群体则复杂得多，账户上有很多相当真实的活动，借此掩盖了其属于假账户的事实。</p><p>&nbsp;</p><p>于是，团队最终通过两种相互独立的启发式方法来识别这两类群体。</p><p>&nbsp;</p><p></p><h3>“一看就是假的”</h3><p></p><p>&nbsp;</p><p>在调查期间，Dagster 团队发现了很多一次性的个人资料：它们的存在就是为了伪造 GitHub 账户并为买家的 GitHub 代码仓库“加star”。</p><p>&nbsp;</p><p>这类账户只有一天的活动记录（也就是账户创建当天，因此可以证明它们就是为了加star才存在的），别无其他。于是，Dagster 团队使用GitHub API收集了这类账户的更多信息，并发现了它们清晰的运作模式。这类账户的特点就是活动量极低：</p><p>&nbsp;</p><p>创建时间为2022年或更晚关注者 &lt;=1所关注者&nbsp;&lt;= 1公开gists == 0公开repos &lt;=4电子邮件、雇用信息、简历、博客和Twitter用户名均为空投star日期=账户创建日期=账户更新日期</p><p>&nbsp;</p><p>通过这种简单的“低活动”启发式方法，Dagster 团队检测到了大量可疑的虚假账户。这些账户只为同一组代码仓库投过star，而且都是通过 GitHub API 来操作的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8b/8b478eea402a2946295c5e244c2a61e4.png\" /></p><p></p><p>这帮GitHub“用户”明显具有共性</p><p></p><h3>“用心造假”</h3><p></p><p>&nbsp;</p><p>另一类假账户会更难发现，他们有比较真实的操作，比如个人资料照片、简历和贡献提交。相较前边一眼就能看出来的假账户，这类假账户的情况比较复杂。那么，应该如何做有效甄别呢？</p><p>&nbsp;</p><p></p><h4>聚类直觉</h4><p></p><p>&nbsp;</p><p>Dagster 团队最终选择了无监督聚类技术，相当于是为每个账户都构建一组特征。</p><p>&nbsp;</p><p>照理来说，正常用户的特征应该比较分散，就是说其每项特征都比较独特，不会遵循某个大聚类的整体趋势。但虚假用户的特征则有相似性，所以在可视化之后会聚集在一起。通过这种办法，应该能检测出目标账户是否属于可疑聚类。</p><p>&nbsp;</p><p>举个更容易理解的例子：假定我们关注“活动日期”，GitHub上的大多数用户并不会每天都有公开活动。如果某个账户每月有几天会使用GitHub，而且具体日期跟另一个账户完全相同，甚至连分享的活动内容都差不多，那就表明这两个账户很可能是由相同的底层脚本在控制。根据这类账户的活动分享日期数（x轴）和所交互的代码仓库总数（y轴）可得出下图：</p><p><img src=\"https://static001.geekbang.org/infoq/af/afaf34aa7dacc0bbaedfe6931e627b26.png\" /></p><p></p><p>&nbsp;</p><p>这里列出的就是Dagster 那个“钓鱼”代码仓库的统计结果，项目得到的star几乎100%是假的：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2b/2b02d1e751f3a8430b489875eb733301.png\" /></p><p></p><p>Dagster 针对一组已知假star得到的启发图——几乎100%匹配</p><p>&nbsp;</p><p>据实验团队所知，Dagster 项目应该没买过star，所以他们用 Dagster 代码仓库做了对比。请注意左下角的小黄点，代表了少量误报账户（误报率=0.17%）：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e5/e5ae40735aa0ad3e0600e70207869e6a.png\" /></p><p></p><p>针对dagster-io代码仓库的启发图——匹配接近0%</p><p>&nbsp;</p><p>最后，我们再来看看纯假和纯真之间的情况。这个开源代码仓库既有真star，也包含大量疑似假star，黄色部分标出了可疑的投 star 群体。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8a/8abe2f848e8d2399c961ce7b602c0fb9.png\" /></p><p></p><p>针对我们怀疑作弊的代码仓库制作的启发图——高亮显示部分为假star</p><p></p><h4>改进聚类</h4><p></p><p>&nbsp;</p><p>虽然这项技术挺有意思，但实际表现还不足以对假账户做高置信度判断，还需要再做改进。</p><p>&nbsp;</p><p>初步通过直觉完成数据挖掘之后，Dagster 团队又发现了另一种模式。虽然这些复杂的假账户都会以逼真的方式做交互，但这类假账户往往只跟少部分代码仓库互动。从本质上讲，各个假账户似乎都属于整体“可疑代码仓库”的一个子集。</p><p>&nbsp;</p><p>遗憾的是，Dagster 团队没办法直接汇总出可疑代码仓库的列表，因为卖家会不断轮换新的代码仓库来回避跟踪。但Dagster 可以使用无监督聚类技术自动识别出新的可疑代码仓库，再根据其是否存在、存在多少可疑交互来判断哪些账户确系伪造。下面来看实验团队对可疑用户判定方法：</p><p>&nbsp;</p><p>首先，列出所有曾给可疑代码仓库投过star的用户。之后，根据与该组内其他用户的高度重叠性，确定出一组潜在的可疑代码仓库。注意，因为这些用户初步入选的理由是给同一个代码仓库投过star，所以如果它们同样也为另一代码仓库投过star，则代表值得怀疑。（但仅仅是值得怀疑，正常情况下也存在这种广泛的投star重叠，所以下面的附加步骤才格外重要！）最后，要找出活动水平相对较低的账户，挑出其中绝大多数活动都仅仅指向之前确定的可疑代码仓库、且缺乏其他合法活动的账户，这些就是认定的假账户。</p><p>&nbsp;</p><p>在对已知假star做这一启发测试时，虽然计算量很大，但假账户的检测效果确实很好，准确率高达98%、召回率为85%。那么，这种方法在真实代码仓库中表现如何？</p><p>&nbsp;</p><p>将这两种方法结合起来，实验团队能够更全面地了解给定GitHub代码仓库中的可疑投star和相应召回率：</p><p>&nbsp;</p><p></p><p>脚注：受计算成本的限制，实验团队在BigQuery上进行的GitHub Archive分析仅限从2022年1月1日起的得star。对于GitHub Archive分析，团队使用了另一种略有不同的方法来识别GitHub API分析中的“低活动”可疑账户。这些账户与通过聚类方法识别出的其他可疑账户相加，就得到了疑似假star的总数。</p><p>&nbsp;</p><p>如果大家也想用这样的逻辑分析其他GitHub代码仓库，可点击下面链接：</p><p><a href=\"https://github.com/dagster-io/fake-star-detector\">https://github.com/dagster-io/fake-star-detector</a>\"</p><p>&nbsp;</p><p>其中，简单启发式算法是用Python实现的，只需要一个GitHub账户加访问令牌即可使用；无监督聚类方法则是用dbt项目实现的，需要Google Cloud BigQuery账户才能运行。请注意，用后者方式检测大型代码仓库可能会带来高昂的成本。</p><p>&nbsp;</p><p>幸运的是，根据 Dagster团队的研究，从投入产出的情况来看，买star行为在GitHub上还不是那么普遍，这也体现出开源社区积极向上的整体价值观。开源社区的长期发展还需要每个开发者的努力。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://dagster.io/blog/fake-stars\">https://dagster.io/blog/fake-stars</a>\"</p><p><a href=\"https://news.ycombinator.com/item?id=35207020\">https://news.ycombinator.com/item?id=35207020</a>\"</p>",
    "publish_time": "2023-03-20 18:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]