[
  {
    "title": "Cloudflare 的 ML 和 AI 之旅：MLOps 平台和最佳实践",
    "url": "https://www.infoq.cn/article/g9leV67ZVXcfsyQ1Pkqr",
    "summary": "<p>Cloudflare 的博客介绍了他们的 MLOps 平台和大规模运行人工智能（AI）部署的最佳实践。包括 WAF 攻击评分、僵尸管理和全球威胁识别在内的 Cloudflare 的产品，都依赖于不断发展的机器学习（ML）模型。这些模型在增强客户保护和支持服务方面都发挥着关键的作用。Cloudflare 在公司全网中提供 &nbsp;ML 方面取得了无与伦比的规模，突出了稳健 ML 培训方法的重要性。</p><p></p><p>Cloudflare 的 MLOps 是与数据科学家合作实施的最佳实践。通过 JupyterHub 部署在 Kubernetes 上的 Jupyter Notebooks 为数据探索和模型实验提供了可扩展的协作环境。GitOps 是 Cloudflare MLOps 战略实践的基石，利用 Git 作为管理基础架构和部署流程的单一真相源。ArgoCD &nbsp;是用于声明式 GitOps，实现了应用程序和基础架构的自动化部署和管理。</p><p></p><p>公司未来的路线图包括了迁移 JupyterHub 和 Kubeflow 等平台，后者为 Kubernetes 上的机器学习工具流平台，且在近期成为了 CNCF 的孵化项目。这一步是由为 Kubeflow 组件提供分布式配置管理的 deployKF &nbsp;项目促进。</p><p></p><p>为了协助数据科学家们使用正确工具，自信且高效地启动项目，Cloudflare 的 MLops 团队提供了模型模板，作为包含示例模型的生产就绪代码库。这些模板目前都是内部模板，但 Cloudflare 计划将其开源。这些模板所涵盖的使用案例包括：</p><p></p><p>训练模板： 为 ETL 流程、实验追踪和基于 DAG 的协调进行了配置。批推理模板： 为高效处理计划模型进行优化。流推理模型： 专为在 Kubernetes 上使用 FastAPI 进行实时推理而定制。可解释性模板： 使用 Streamlit 和 Bokeh 等工具生成 dashboard（仪表盘），用于模型的洞察。</p><p></p><p>MLOps 平台的另一项重要任务是高效地协调 ML 工作流，Cloudflare 根据团队偏好和用例采用了各种协调工具：</p><p></p><p>Apache Airflow：一个标准的 DAG 组成其，拥有丰富的社区支持。Argo 工作流：以 Kubernetes 原生形式协调微服务类型工作流。Kubeflow 管道：专为 ML 工作流定制，强调协调和版本管理。Temporal：专注于事件驱动型应用的有状态工作流。</p><p></p><p>性能的优化需要对工作流的理解和对硬件相应的调整。Cloudflare 强调核心数据中心在工作负载和边缘推理方面的 GPU 利用率，利用普罗米修斯（Prometheus）所提供的指标进行观察和优化。Cloudflare 的成功应用包括了对 ML 流程的简化、管道标准化，以及向缺乏数据科学专业知识的团队介绍项目。</p><p></p><p>公司的愿景是一个数据科学可以在企业中发挥重要作用的未来，这也是 Cloudflare 投资于人工智能基础设施并与 Meta 等其他公司合作的原因，其中包括在 Cloudflare 平台上向全球提供 LLama2。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/12/cloudflare-mlops-platform/\">https://www.infoq.com/news/2023/12/cloudflare-mlops-platform/</a>\"</p><p></p><p></p><p></p><p></p><p></p>",
    "publish_time": "2024-01-19 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "前阿里员工抄袭YC初创公司并开源，老外：反正官司打不赢，不费那个劲了",
    "url": "https://www.infoq.cn/article/xZIMdlxmGA8YQhIo31Ai",
    "summary": "<p>Outerbase&nbsp;联合创始人最近在社交媒体上爆料称，自家辛辛苦苦做出来的产品，被来自中国的一家大型科技公司“抄袭”了，很快这个事情就引发了众多网友的关注。Outerbase&nbsp;联合创始人表示不会起诉，并且他确信抄袭者永远无法在创新和对用户的热爱上赶超他们。</p><p></p><h4>事件经过</h4><p></p><p>近日，Outerbase&nbsp;联合创始人&nbsp;Brandon&nbsp;Strittmatter&nbsp;发现了一款来自中国的“仿制品”，这款产品不仅仅复制了&nbsp;Outerbase&nbsp;构建的许多要素，甚至细节也如出一辙，简直可以说是达到了“像素级”。据了解，Outerbase是一个A驱动的数据库平台，专注于视图、查询、可视化和编辑数据。它是以MIT协议开源，其&nbsp;Github&nbsp;项目地址如下<a href=\"https://github.com/outerbase/%EF%BC%8C%E5%8C%85%E5%90%AB%E4%BA%86ezql.ai%E4%BB%A5%E5%8F%8Aouterbase\">https://github.com/outerbase/</a>\"。</p><p></p><p>Brandon&nbsp;在&nbsp;Twitter&nbsp;表示，对方不是仅仅复制了Outerbase&nbsp;的前端界面，而是整个产品以及商业模式。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7a/7ab133e58d296a90d9667a29c295c3dd.png\" /></p><p></p><p>一开始，Brandon&nbsp;并没有表现出愤怒，而是更多地感到惊讶。在进行一番调查后，他发现仿制者甚至拥有一些Outerbase的账户，并找到了他们的母公司，这才让他觉得事情“有些疯狂”。</p><p></p><p>虽然Brandon没有直接点名，但表示他们是中国最大的公司之一，他形容这家公司“在诠释‘40大盗’的传说”（&nbsp;one&nbsp;of&nbsp;China's&nbsp;largest&nbsp;companies&nbsp;and&nbsp;are&nbsp;really&nbsp;living&nbsp;up&nbsp;to&nbsp;the&nbsp;40&nbsp;Thieves&nbsp;part&nbsp;of&nbsp;their&nbsp;lore）。更糟糕的是，他们将这个产品开源了，目前在Github上已经收获了超过1万颗星和1千个Fork。</p><p></p><p>Brandon表示，他们不仅仅复制了产品的优点，还模仿了一些初期存在的问题，包括可用性缺陷、糟糕的设计决策以及其他一些小问题。而就在他们忙于模仿的时候，Outerbase一直在进行创新。在仿制者花了数月时间打造“Copybase”的同时，Outerbase修复了所有这些问题，发布了众多新功能，重新设计了整个前端。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e3/e3b5679cda3a1835606c984ac096d3c1.png\" /></p><p></p><p></p><p>然而，Brandon也很纠结，是否应该与这家近&nbsp;$200B&nbsp;市值的科技巨头打官司？他又认为这可能是浪费时间和金钱，所以最后决定还是放弃起诉，继续努力提升Outerbase。他相信，这可能不是唯一一家这样做的公司。而团队也计划推出一些新功能，以在这场创新竞赛中拉开更大的差距。在Twitter上，Brandon澄清他的态度，表示他睡得很好，因为他确信他们永远无法在创新和对用户的热爱上赶超他们。</p><p></p><p>至于这个仿制品到底是指哪个项目，Linkedin上的实名评论给我们指明了方向：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/78/786fcc3bde2677c27086c466279675b7.jpeg\" /></p><p></p><p></p><p>该网友晒出了该项目的&nbsp;Github&nbsp;链接，指向功能类似的开源产品&nbsp;Chat2DB。网友表示：“该开源作者已经离开那家科技巨头，并且正在创办自己的公司，并且该初创公司还得到了MiraclePlus的资助。”</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a888575786ca9d70e5aa46ce918fb144.png\" /></p><p></p><p>也有网友表示，抄袭的软件（只要实际上没有代码被盗）是可以合法停止的。但是&nbsp;Brandon&nbsp;回应称“我觉得我宁愿扔掉一些钱，也不想尝试起诉一个国际公司”。</p><p></p><h4>Chat2DB是什么？</h4><p></p><p></p><p>虽然不知道Brandon从哪些细节锁定了这家巨头科技公司，也有Linkedin上的网友表示该Chat2DB的作者已从巨头企业离职，所以这件事情与该企业无关，但让人疑惑的地方在于，Chat2DB早期的一些宣传文章中有以下描述：“一款由阿里巴巴开源的免费的多数据库客户端工具”，而代码库最初也通过alibaba.com进行下载。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a7/a763fb687be5c83627001b3541c6f703.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d7/d74a63de0e84d6e30c6d31bcb4503ee0.png\" /></p><p></p><p>还有一篇具体的讲解文章：“耗时&nbsp;6&nbsp;个月，我们做了一款干净、免费、开源的&nbsp;AI&nbsp;数据库”。据文章描述，Chat2DB具有以下优势。首先，通过AI智能生成SQL和SQL解析，用户能够通过自然语言或语音输入查询，获得自动生成的SQL代码，同时实现从SQL查询到自然语言的转换，提供优化建议，为数据库查询流程带来极大的便利和效率提升；其次，Chat2DB展现强大的扩展能力，支持多种数据源，包括但不限于Mysql、PostgreSQL、Oracle、SQLServer、ClickHouse、Oceanbase、H2、SQLite等，涵盖了广泛使用的数据库类型，为用户提供更为灵活的选择；最后，作为一体化解决方案，Chat2DB支持多端访问，包括Mac、Windows客户端，同时提供了Web版，满足了不同用户的使用习惯，展现了高度的人性化。</p><p></p><p>根据评论区的反馈，大家普遍认为这款工具表现相当出色。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a2/a257a5bfb8957a0d7e6c3d72680ba0a0.png\" /></p><p></p><p>虽然&nbsp;Chat2DB&nbsp;项目因其出色的表现而备受夸赞，但这件事情在国外的社交媒体上也备受争议，毕竟这在某种程度上代表了中国企业形象。有网友表示，“实现功能、倾听用户的软件服务是不可复制的。”</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1d/1d662b13195009efe234fb3f7c3d66cd.png\" /></p><p></p><p></p><p>但不容忽视的是，Outerbase&nbsp;是基于MIT许可证开源的。MIT许可是一种宽松的开源许可证，允许软件免费使用、复制、修改、合并、出版、分发、再授权和销售等，但前提为“保留版权和许可证声明”。我们可以看到，OuterBase控诉Chat2DB作者“借鉴”了自家的产品，创建了新的以Apache&nbsp;2.0许可开源的项目并取得了比自家更好的Star数。这可能是&nbsp;Brandon&nbsp;更加在意的事情。</p><p></p><p>整体再看这件事，我们不禁要思考开源社区的核心价值观：相互尊重、协作共享。开源不仅仅意味着代码的自由访问和使用，它更是一种促进技术创新和知识共享的文化。因此，尊重原创作品，包括维护版权声明和遵守许可证规定，成为了每个社区成员的基本责任。</p><p></p><p>遵守开源许可证是维护社区健康的基石。无论是MIT许可证还是Apache&nbsp;2.0许可证，都明确要求保留版权和许可证文本，违反这些规定不仅可能招致法律责任，也会损害社区内的信任和协作。在使用、修改或分发开源软件时，我们应秉持这一原则，以确保项目的持续发展和创新。</p><p></p><p>共塑一个健康的开源社区需要我们每个人的参与和努力。这意味着，在借鉴和使用他人的代码时，我们应清晰地标明来源，尊重原作者的权利和劳动成果。此外，开源项目的成功依赖于透明度和合作精神。我们鼓励开发者在使用他人的代码时，不仅要注明来源，还应考虑向原项目贡献代码或以其他方式支持，这不仅是对原创者的认可，也是对整个开源社区的贡献。</p><p></p><p>参考链接：</p><p><a href=\"https://www.linkedin.com/posts/brandonstrittmatter_i-recently-found-a-knock-off-version-of-outerbase-activity-7153040091454611456-C6OZ/\">https://www.linkedin.com/posts/brandonstrittmatter_i-recently-found-a-knock-off-version-of-outerbase-activity-7153040091454611456-C6OZ/</a>\"</p><p><a href=\"https://twitter.com/burcs/status/1747452378683449641\">https://twitter.com/burcs/status/1747452378683449641</a>\"</p><p><a href=\"https://zhuanlan.zhihu.com/p/648633185\">https://zhuanlan.zhihu.com/p/648633185</a>\"</p><p><a href=\"https://github.com/chat2db\">https://github.com/chat2db</a>\"</p><p><a href=\"https://cloud.tencent.com/developer/article/2302484\">https://cloud.tencent.com/developer/article/2302484</a>\"</p>",
    "publish_time": "2024-01-19 10:42:01",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "数据资源如何变资产，金蝶提出数据资产盘点5步法",
    "url": "https://www.infoq.cn/article/WKPj5NSiSpE28pz5WZ5w",
    "summary": "<p>数据资产入表被视为当下企业数字化转型和价值创新的重要一环。</p><p></p><p>2023 年 8 月，财政部发布的<a href=\"https://www.infoq.cn/article/4rsaCarUujfmVyxW8wWl?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">《企业数据资源相关会计处理暂行规定》</a>\"（简称《暂行规定》）标志着数据资产正式纳入企业财务报表，这不仅是对数据价值认可的里程碑，也或引发影响企业管理和财务报告体系的变革。</p><p></p><p>另一方面，由于《暂行规定》正式承认了数据资源的资产属性，允许企业将符合条件的数据资源计入报表，这一举措也为数据资源的价值发现和利用提供了新的途径和空间。</p><p></p><p>但具体要如何评估数据资源的价值？从什么逻辑切入？现阶段还有哪些问题要厘清？也许金蝶最新举办的数据资产入表解决方案发布会能助大家解答一二。</p><p></p><p>1 月 18 日，中国财政科学研究院财务与会计研究中心主任赵治纲在发布会上深度解析了数据资产入表的背景、影响及政策解读。其指出，未来企业的报表，特别是数据驱动型企业的报表，一定要有数据资产的列报和反映。企业的负责人以及从事相关业务的人员，需要高度重视数据的重要性，认识到它在估值过程中的关键作用。&nbsp;﻿</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1b/1b0257af401faf04e0d824656ecbb654.png\" /></p><p></p><p>赵治纲分享道，当下企业对于数据资源入表持不同态度，有积极关注的，也有正观望和犹豫的。鉴于此，其认为企业需要先深入学习并建立数据资源相关制度，特别是成本费用分摊机制，同时建议有条件的企业成立独立的数据管理部门或任命负责人，目前国家层面上也已经在倡导企业设立首席数据官（CDO）。</p><p></p><p>同时，他强调《暂行规定》还不是真正意义上的全新的数据资产的会计标准，而是在现行会计准则基础上，按照存货和无形资产的会计标准处理数据资源，意味着现在所谓的数据资源是在现行规则下有序且稳妥地入表，主要作为报表的二级明细核算和反映，因此还未未构成大的变革。﻿</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/73/736b62772830ce26e431bf530451b764.png\" /></p><p></p><p>不过，对于以数据作为核心业务的企业，如数据服务商，这项规定将引起其财务报表的显著变化。费用化较多的企业或数据投资大的企业将可以看到其利润指标和资产负债指标实现双重改善和提升。因此可以预见，未来一段时期企业对购买、开放、分享数据的参与度都会显著增加。</p><p></p><p></p><h2>既要乐观看待，也要谨慎入表</h2><p></p><p></p><p>对于《暂行规定》）的解读，赵治纲在本次发布会特别提到以下几点，并提醒企业家在数据资源入表上既要乐观看待，同时也要谨慎入表。</p><p></p><p>规定的实施时间和法律效力：《暂行规定》自今年 1 月 1 日起施行，采用未来适用法。这意味着从 1 月 1 日开始，企业应根据《暂行规定》处理数据资源相关业务。但对于 2024 年 1 月 1 日之前已经发生的业务，其成本和费用不允许追溯调整。《暂行规定》适用于现行的企业会计准则，并不改变现行准则的会计确认和计量要求。它对现行准则进行了进一步的细化，确保其在会计确认计量方面与现行无形资产、存货、收入等相关准则完全一致。《暂行规定》的特点：《暂行规定》在处理数据资源时，要求根据企业的不同业务模式（如企业使用、对外服务、日常持有以备出售等）来明确会计处理规定。此外，进一步明确了不满足资产确认条件而未予确认的数据资源的相关会计处理。披露机制的创新：《暂行规定》采用“强制披露 + 自愿披露”的方式，鼓励企业加强信息披露。对于那些拥有但难以入表的数据资源，企业可以选择在报表附注或在管理讨论和分析中进行自愿性描述和披露，但要确保信息的真实性，不得误导投资者。执行的前提条件：企业在执行《暂行规定》时，必须确保数据资源的合规性。这包括数据的来源和处理途径必须合法，且企业在数据治理和管理方面应具备一定的基础。</p><p></p><p></p><h2>厘清概念，避免盲目入表</h2><p></p><p></p><p>虽然数据资产入表为企业提供了新的机遇，但也带来了一系列挑战和注意事项。赵治纲举例，比如如何辨别数据的经济价值，并非所有数据都具备入表的条件，企业需对数据资源的经济价值和未来利用潜力进行严格评估。</p><p></p><p>此外，避免盲目入表。企业在推进数据资产入表时，需避免盲目追求入表规模，应重视数据资源的真实价值和合规性。审计师在今年年报审计时会特别关注企业数据资源入表的合规性。因此建议企业寻求专业机构的辅导和支持，确保入表过程符合政策要求和会计准则。</p><p></p><p>数据资源入表是一个复杂的领域，赵治纲认为后续仍需要从多个方面持续完善和深入探讨。</p><p></p><p>一是厘清数据资产概念。需全面理解和区分数据、数据资源和数据资产的概念，尤其是在财务报表中的表述。数据资产是数据资源的一部分，但不是所有数据资源都能称为数据资产。数据资产作为一类新资产、软资产，区别于传统的资产类型，以及与无形资产也存在明确差异，仍需全面深入的研究。</p><p></p><p>二是数据交易活跃度与定价机制问题。当前数据交易不够活跃，尤其是场内交易。数据交易的中介机构和定价机制尚不完善，需要研究如何增加交易活跃度和建立健全的数据定价机制。尽管《数据资产评估指导意见》已发布，但具体的评估实践才刚开始。评估方法、案例和公允性的确立需要持续推进和完善。</p><p></p><p>三是数据资产价值特性与后续计量问题。需要进一步研究和理解数据资产的价值特性，如供给的充裕性、价值易变形、零成本复制性、共享性和时效性。此外，数据资产的摊销和减值问题也需要深入探讨，尤其是在后续计量中，如何准确反映数据资源的实际价值状况。</p><p></p><p></p><h2>已有企业推出释放数据价值相关方案</h2><p></p><p>在本次发布会上，金蝶发布了数据资产入表整体解决方案，涵盖数据资产入表业务管理解决方案、数据资产入表系统支撑解决方案，以及企业数据资源管理解决方案。</p><p></p><p>据金蝶中国星瀚解决方案部总经理张鄂豫介绍，金蝶数据资产入表业务管理解决方案构建了从数据资产识别、盘点、合规、确权到评估、计量、核算、披露的全业务流程路径，提出了数据资产盘点 5 步法、数据合规 5 大领域、数据确权 5 大原则等执行策略和方法。凭借覆盖各大行业的业务管理实践，覆盖人、财、税、供应链、制造等领域的各类数据应用以及数据管理的方法论和实践，金蝶能够帮助企业快速识别、评估数据资产，同时借助众多专业生态伙伴，在合规、确权、资本化等方面为企业提供市场权威的解决方案以及最佳实践参考。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/75/8c/75d6cfeab44926b9fe9c03105cc8a68c.jpg\" /></p><p></p><p>进一步地，金蝶构建了数据资产入表的系统支撑解决方案，实现数据源到数据资产的平台化（数据开发与治理）、业务化（数据资产管理）、商业化（数据资产运营）。﻿</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d3/d31dc73933a5130694a4619d9d3c1f1a.png\" /></p><p>﻿</p><p>在无形资产管理应用模块，金蝶针对数据资产设置了相应资产盘点、资产评估、资产减值、资产摊销、资产报废、资产变更等功能，实现总账与报表模块支持数据资产自动入账、报表披露自动生成等。</p><p></p><p>值得注意的是，金蝶云·星瀚通过功能升级，与苍穹数据中台的整合，实现了数据资源从交易记录、分类确权、成本确认和摊销、收益核算、后续计量到入账入表全过程的精细化管理。</p><p></p><p>金蝶方面强调，数据资产入表只是“一味药引”，更关键的是如何深挖数据价值，赋能企业业务，这才是最终目标。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/6a/7f/6a727c625eae4byya4a6075aed39e17f.jpg\" /></p><p></p>",
    "publish_time": "2024-01-19 13:28:13",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "预览版“纯血鸿蒙”开放申请，中国开发者要为“四端”体验一致头痛了",
    "url": "https://www.infoq.cn/article/7Xb2FsvxNDNpktBEReAp",
    "summary": "<p></p><blockquote>华为HarmonyOS NEXT鸿蒙星河版（即开发者预览版）面向开发者开放申请，即刻可以下载；今年Q4，将会有真正的商业版跟所有消费者见面。</blockquote><p></p><p>&nbsp;</p><p>最近一段时间，很多大家耳熟能详的国民级应用都开启了鸿蒙原生应用的开发，很多985、211高校也接连开设了鸿蒙相关课程，“鸿蒙千帆起”正在成为一个大型的社会现象。1月18日，华为 “鸿蒙生态千帆启航仪式”在深圳举行。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/22/22c16cae6a88a16dba873e9dd758739f.jpeg\" /></p><p></p><p>华为常务董事、终端BG CEO、智能汽车解决方案BU董事长余承东在开场演讲中表示，今天，鸿蒙生态大势已定，满天星光，终汇成璀璨星河。2023年8月华为开发者大会官宣鸿蒙生态设备数量为7亿台，仅历时5个月，鸿蒙生态设备发展迅速，如今这个数字已经增长至8亿。</p><p>&nbsp;</p><p>余承东强调，有底座有生态才是真正的操作系统。鸿蒙操作系统经历十年磨砺，一次次蝶变，今天已经运行在丰富的全场景设备上。华为向下扎到根，具备从OS内核、文件系统、编程语言（ArkTS/仓颉）、编译器运行时、编程框架、设计系统、集成开发环境、安全隐私、AI框架到AI大模型全栈自研能力。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/ec/ecccc80fc85ec8f0eb772c90a97baa61.jpeg\" /></p><p></p><p>随后，余承东宣布HarmonyOS NEXT鸿蒙星河版面向开发者开放申请。鸿蒙星河版将实现原生精致、原生易用、原生流畅、原生安全、原生智能、原生互联6大极致原生体验。</p><p>&nbsp;</p><p>了解HarmonyOS NEXT开发者预览版关键特性可访问：</p><p><a href=\"https://developer.huawei.com/consumer/cn/next\">https://developer.huawei.com/consumer/cn/next</a>\"</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7e/7e330d0408747c9ba2f5bbd530589d8a.jpeg\" /></p><p></p><p>自去年9月份华为宣布HarmonyOS NEXT蓄势待发、鸿蒙原生应用全面启动以来，首批200多个鸿蒙原生应用已在加速开发，覆盖便捷生活、出行文旅、金融便利、社交资讯、生产力工具、影音娱乐、游戏等领域，鸿蒙原生应用版图已基本成型。其中，蚂蚁集团、中国银联等众多合作伙伴开放垂域创新能力，和鸿蒙的底座能力一起，给开发者提供了高效的全链路开发工具，进一步加速鸿蒙原生应用开发。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/23/233e0fbaf1edb3cce44f544b1cee21d9.jpeg\" /></p><p></p><p>余承东最后总结道：鸿蒙将走出一条全新的生态之路，打造万物互联的全场景操作系统。</p><p>&nbsp;</p><p>活动现场，华为邀请了诸多鸿蒙生态合作伙伴分享合作进展和成果，其中360集团创始人、董事长周鸿祎也来到现场为鸿蒙站台，抛出不少段子。周鸿祎表示，未来360旗下多个优质应用将加入鸿蒙生态版图，带来更流畅、更智能、更安全的使用体验，并呼吁大家早日加入鸿蒙操作系统生态，才能早日获取到鸿蒙生态的红利。</p><p></p><h2>一个操作系统做了近十年：每年投入超百亿元</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b7/b7c2d0c596a36b10c3fbaef625b4af73.jpeg\" /></p><p></p><p>在 2019 年华为开发者大会上，鸿蒙操作系统正式对外发布。余承东表示，鸿蒙 OS 是全世界第一个基于微内核的全场景分布式 OS，通信效率秒杀现有一众操作系统。</p><p>&nbsp;</p><p>据介绍，鸿蒙 OS 采用分布式架构，能够实现模块化解耦，对应智慧屏、穿戴设备、车机、音箱、手机等不同设备可弹性部署，灵活适配全场景丰富终端形态。可以实现跨终端无缝协同体验，终端之间实现能力互助共享，带来最佳协同体验。内核方面，鸿蒙 OS 微内核技术用于可信执行环境，首次通过形式化方法显著提高 TEE 内核安全。形式化环境方法是利用数学方法从源头验证系统正确的有效手段，传统方法很难保证充分验证代码匹配设计。</p><p>&nbsp;</p><p>彼时在发布会现场，余承东也公布了鸿蒙 OS 的历程及路标。</p><p>&nbsp;</p><p>过去这五年间，鸿蒙不断更新，一步步完成原定路线图的目标：2020 年 12 月，鸿蒙推出了面向手机开发者的 Beta 版本；2021 年 6 月 2 日，华为发布多款搭载 HarmonyOS 2 的新产品，并开始搭载于智能手机上；2022 年 7 月，华为鸿蒙设备数突破 3 亿，并正式发布 HarmonyOS 3，在 HarmonyOS 3 中，手表首次加入超级终端；2023 年 8 月 4 日，华为正式发布 HarmonyOS 4，同时发布 HarmonyOS NEXT 开发者预览版，该版本集合了华为在操作系统技术方面的最新探索，包含软件根技术的进化、开发理念的实践、开发工具全面升级等。</p><p>&nbsp;</p><p>（延伸阅读：《<a href=\"https://mp.weixin.qq.com/s/4-2X0XWwEqTxYUKB711yZQ\">刚刚，华为鸿蒙OS 2.0 发布，18点18分开放源代码</a>\"》《<a href=\"https://mp.weixin.qq.com/s/SoJ6sDIBeeotaYcE9qslhg\">2022 年鸿蒙自研代码量达 2000 万行，华为明年将发布 HarmonyOS 4</a>\"》《<a href=\"https://mp.weixin.qq.com/s/CEjlCCojHXUWcVsqKiA-7Q\">鸿蒙初开，生态蓝图已现</a>\"》）</p><p>&nbsp;</p><p>在 2023 年 8 月举行的华为开发者大会上，华为终端软件部总裁龚体表示鸿蒙内核的能力再获提升。比如：通过动态优先级调度 + 混合动态大页 + 更高效的组件通信为系统加速；通过更轻量化的并发模型 + 更匹配移动算力架构的资源供给 + 更精准的器件控制提升硬件能效；以及通过数学方法对关键安全模块进行形式化证明等等。</p><p>&nbsp;</p><p>此外，鸿蒙还带来了全新的方舟引擎，包含图形、多媒体、内存、调度、存储和低功耗六大引擎。在引入方舟图形引擎后，图形单帧渲染功耗降低了 68%，GPU 负载降低了 58%，CPU 负载降低了 12%，几乎是全方位的提升。同时龚体表示，方舟图形引擎在动效计算、绘制框架等方面的能力也获得了大幅的增强。</p><p>&nbsp;</p><p>对于鸿蒙操作系统，华为投入巨大。华为此前披露，每年对鸿蒙的投入超过了百亿元。华为还制定了“鸿飞计划”，将在 3 年里投入百亿元，打造全场景鸿蒙生态。</p><p>&nbsp;</p><p>根据 Counterpoint 发布的数据，到 2023 年末，鸿蒙 OS 在国内手机市场的占比达到 13%。另根据半导体行业观察机构 Techinsights 最新的报告预测，从 2024 年起，鸿蒙 OS 将取代苹果 iOS，成为中国市场上第二大智能手机操作系统。</p><p></p><h2>与安卓切割，开发者：是“自寻死路”还是“置之死地而后生”？</h2><p></p><p>&nbsp;</p><p>鸿蒙操作系统自诞生以来，始终热议不止。</p><p>&nbsp;</p><p>一方面，操作系统作为底层基础设施，上承载各种应用，下适配各种硬件，其重要性不言而喻。然而长久以来，操作系统“卡脖子”问题难以解决，因此鸿蒙系统的出现也被视为中国在操作系统领域打破国外垄断的一次尝试。鸿蒙系统的分布式架构和智能终端能力也是其优势，通过模块化和分布式设计将各种场景应用无缝衔接，应用到各种终端设备上，为用户带来更加便捷、智能的使用体验。同时，鸿蒙系统还具有较高的安全性和可靠性，可以有效地保护用户的数据和隐私。</p><p>&nbsp;</p><p>另一方面，按照余承东最初的设想，“如果未来某天安卓不可用，鸿蒙将随时可以顶上”。随着 2021 年 5 月&nbsp;OpenHarmony 2.0（鸿蒙 OS 的一个开源版本）陆续开源了 L2 分支，关于“鸿蒙套壳安卓”的讨论甚嚣尘上。同年 6 月，华为在心声社区紧急发布了由轮值董事长徐直军签发的总裁办电子邮件《关于规范 HarmonyOS 沟通口径的通知》。徐直军在文件中表示，华为已于 2020 年、2021 年分两次把该智能终端操作系统的基础能力全部捐献给开放原子开源基金会，由开放原子开源基金会整合其他参与者的贡献，形成 OpenHarmony 开源项目。HarmonyOS 2 是华为基于开源项目 OpenHarmony 2.0 开发的面向多种全场景智能设备的商用版本。</p><p>&nbsp;</p><p>据了解，OpenHarmony 1.0 版本基于华为开源 Lite OS 内核，没有使用来自AOSP（Android Open Source Project，安卓开放源代码项目）的代码，不能兼容安卓应用，只能运行鸿蒙应用；OpenHarmony 2.0 Canary（金丝雀版）以及之后的鸿蒙版本，使用部分 AOSP 代码构建安卓应用兼容层，可支持内存大于 128M 的带屏设备。</p><p>&nbsp;</p><p>但不少社区开发者对此并不认可，“两个鸿蒙”的概念让开发者认为鸿蒙在玩“文字游戏”。有开发者表示“HarmonyOS（实际是安卓）的产品来给鸿蒙打口碑，OpenHarmony 来宣传纯自研。用了大约 4 年时间，OpenHarmony 差不多可以用在手机上了，再制造出&nbsp;HarmonyOS&nbsp;慢慢剔除安卓的假象。简单来说，HarmonyOS 1、2、3、4 是一条线，OpenHarmony、HarmonyOS NEXT&nbsp;是另一条线。”（来源：<a href=\"https://www.zhihu.com/question/632428627/answer/3322471465\">https://www.zhihu.com/question/632428627/answer/3322471465</a>\"）</p><p>&nbsp;</p><p>也有开发者认为鸿蒙作为一个新生的操作系统，起步之初生态并不完善，很多应用无法在鸿蒙系统上正常使用，为了存活不得不兼容运行安卓应用，“自研系统和安卓双框架并完美运行的只有华为”。</p><p>&nbsp;</p><p>至于“套壳安卓”，“鸿蒙之父”王成录早在 2021 年就曾回应称“并不是所有安卓代码都是谷歌开发的，绝大部分代码来自开源社区，鸿蒙会吸收社区的优秀技术和代码”，“用了 AOSP 的开源代码，就判断鸿蒙是安卓换了皮，说明这类吐槽者没有太准确理解什么是开源”。随后，王成录又曾在多场活动中表示，“鸿蒙系统不是安卓、iOS，也不仅仅是一个单设备操作系统”，“鸿蒙最大的价值在于多设备之间，通过鸿蒙软总线能够互相组合”，并表示，“中国在系统软件领域中，鸿蒙是唯一一个在技术架构领先了全球所有操作系统的”。</p><p>&nbsp;</p><p>争议之下，鸿蒙迎来了转折点。</p><p>&nbsp;</p><p>2023 年 8 月 4 日，华为正式发布 HarmonyOS NEXT 开发者预览版，并宣布不再兼容安卓应用。有开发者实测发现，已经无法安装安卓 APK 文件，会提示“无法打开此文件”。据介绍，HarmonyOS NEXT 系统底座全线自研，砍掉传统的 AOSP&nbsp;代码，仅支持鸿蒙内核和鸿蒙系统的应用。故而很多人将HarmonyOS NEXT称为“纯血鸿蒙”。</p><p>&nbsp;</p><p>这也被外界解读为鸿蒙正式与安卓“切割”，这无疑是鸿蒙的重大突破与挑战。但与安卓“切割”并非易事，接下来还有更大的挑战摆在鸿蒙面前——生态。构建一个新的操作系统，相比打造技术底座，构筑生态才是更难打的一仗。生态是操作系统的根本，上一个与安卓“切割”的&nbsp;Windows Phone 就因生态不足而走向失败。</p><p>&nbsp;</p><p>有开发者悲观地表示，与安卓“切割”等同于“自寻死路”，其表示“win11 都兼容 APP 了，安卓和平果都有自循环的内生态软硬件支持，鸿蒙有吗？连国内手机系统生态里都还没有占到主导地位，怎么去跟安卓切割，靠沸腾吗？”</p><p>&nbsp;</p><p>也有开发者认为，与安卓“切割”意味着开发者需要开发原生鸿蒙 APP，并保证四端体验一致，对于小型开发者而言，其成本和难度不言而喻，APP 的未来发展前景也并不明朗。毕竟用户规模与软件生态本身就是相互制约的状态——软件厂商希望等用户规模增长起来再适配鸿蒙，用户希望软件生态丰富起来再成为鸿蒙用户。对于企业而言，开发原生鸿蒙 APP 意味着企业需要额外的成本招聘鸿蒙操作系统开发人员，培养熟悉、掌握鸿蒙应用开发的技术团队，人力和维护成本都有所增加。</p><p></p><h2>“纯血鸿蒙”迈入关键期</h2><p></p><p>&nbsp;</p><p>在“纯血鸿蒙”生态建设上，鸿蒙有自己的打法。</p><p>&nbsp;</p><p>鸿蒙生态应用开发白皮书 V2.0 中提到，鸿蒙系统结合移动生态发展的趋势，提出了三大技术理念：一次开发，多端部署；可分可合，自由流转；统一生态，原生智能。此外，鸿蒙系统为开发者提供了赋能套件、鸿蒙开发套件、三方库、开发者支持平台。具体能力全景图如下图所示：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b3/b39f88c27e29f0394a16e9eccc50c7c9.png\" /></p><p></p><p>正如我们在这次 “鸿蒙生态千帆启航仪式”上看到的，当下，鸿蒙系统的独立生态蓝图正在加速构建。</p><p>&nbsp;</p><p>本次鸿蒙生态千帆启航仪式上已经出现了不少HarmonyOS先锋开发者的身影：小红书率先完成鸿蒙原生应用Beta版本交付，通过一次开发多端部署，让用户在更多设备间自由切换创作内容，并总结了第一份先锋指南，将经验传承；高德地图是地图导航领域首个启动鸿蒙原生应用开发的头部伙伴，双方通过联合创新，不仅挑战了鸿蒙重型应用性能新高度，还加速推动了行业鸿蒙化进程；美团是首批加入鸿蒙生态的伙伴，同时也是鸿蒙生态开发多模块协作设计的先行者。美团仅仅用了6周的时间，就完成了首个鸿蒙星河版核心功能，并成功地点出了第一份“鸿蒙外卖”；同程旅行是首个实现鸿蒙原生半透明主题的APP，使用户在购票、订酒店的过程中获得更加丝滑的交互体验，让用户的行程规划和旅行产品预订过程更加顺畅和愉快。</p><p>&nbsp;</p><p>华为终端云总裁朱勇刚表示，如今鸿蒙生态建设已经完成第一阶段工作，鸿蒙生态将进入第二阶段，期望携手更多开发者，加速千行百业的应用鸿蒙化。他表示，希望到2024年年终，有5000+应用加入鸿蒙原生生态，最终希望有50万+应用加入鸿蒙原生生态。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/7b/7b8649564f0445243285383b8c1fff78.jpeg\" /></p><p></p><p>与远大的目标相对应，朱勇刚宣布了一系列举措推进鸿蒙生态建设：2024 HarmonyOS创新赛正式启动，最高单项奖达100万元，为开发者提供一个以赛代练、持续进阶的开放平台；全新HarmonyOS开发者官网即刻上线，所有开发者可以在官网上提供软件、硬件、咨询等全栈式服务；70亿+人民币“耀星计划”持续激励鸿蒙原生应用、元服务、SDK等生态创新；华为将携手伙伴，依托鸿蒙生态学堂、高校共同培养鸿蒙人才、城市发布鸿蒙人才培养政策等方式，每月培养10万+鸿蒙开发者。</p><p>&nbsp;</p><p>据介绍，鸿蒙星河版预计在2024年Q2发布开发者Beta版，Q4发布面向消费者的商用版本。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/3b/3b372bfd1bc73dddbd18dbc3b81587cc.png\" /></p><p></p><p>正如余承东早前在内部信中表示的，2024 年是原生鸿蒙的关键一年。对鸿蒙而言，如何一鼓作气打好“纯血鸿蒙”生态战是接下来的重中之重。鸿蒙的目标绝不仅止于打造好国内生态，未来更要走向世界、走向全球。大戏开场，让我们一起拭目以待。</p>",
    "publish_time": "2024-01-19 14:16:02",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "像网购一样体验先进算力，国家超算互联网启动“体验官”招募！",
    "url": "https://www.infoq.cn/article/T4N3AaxpLP0bPiAgBkQT",
    "summary": "<p>近日，国家超算互联网启动“体验官”招募计划，面向一线科研、制造业、人工智能等领域，招募 1500 名“体验官”。该计划旨在加速科研创新，让用户像网购一样便捷体验先进算力服务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/67/6704e021533d0455b3a28b7263d67eaa.png\" /></p><p></p><p>在国家超算互联网上，“体验官”将优先体验基础资源、应用软件、应用平台、数据资产、技术服务五大类 3000 多个应用，覆盖包括汽车、船舶、能源、生命医药、气象、人工智能等众多行业，以破解科研领域面临的“算力紧张”、“所需算力应用不足”等难题。</p><p></p><p>国家超算互联网是由部委支持与指导的国家级算力服务交易平台，其建设目标是通过链接算力产业上下游及供需双方，加速实现算力像水和电一样随时取用，让线上算力应用像本地部署一样“开箱即用”，为科研探索提供坚实的算力底座，从而加速科研创新，推动我国科技事业蓬勃发展。</p><p></p><p>成为体验官，您不仅能亲身体验到最先进的超算技术和应用，还能感受前所未有的计算速度和数据处理能力。提交《体验问卷》还能够获得价值 500 元的计算资源奖励，提交报告并被采纳，更有机会赢取高达 1000 元至 2000 元的现金奖励！</p>",
    "publish_time": "2024-01-19 14:40:50",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "B 站人气 Top2 AI 主播“羊驼-阿花”何以拥有“高智商、高情商”？",
    "url": "https://www.infoq.cn/article/zXtN5O9HRgM1FQUprk06",
    "summary": "<p>如果你是 B 站用户，那你肯定知道“羊驼 - 阿花”这个人气主播，它是一款由“虚拟偶像女团 A-SOUL”背后的虚拟娱乐公司“枝江娱乐”打造的一款 AI 主播产品，其动物的外形 + 萝莉声线，一经推出便迅速走红网络，甚至一跃成为 B 站人气 Top2 的流量 AI 明星。</p><p></p><p>在直播间，“羊驼 - 阿花”能够自然流畅的与粉丝互动，风趣的回答粉丝的问题，这种互动体验甚至比与真实的人物还要精彩。更令人惊叹的是 A-SOUL 技术团队为阿花设定了完备的形象成长曲线，经过持续的 NLP 训练后，阿花逐渐能够根据观众的反馈提供新鲜和爆点的内容输出，可以说是妥妥的“养成系主播”。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/70/702cb0a3648f1b6840e511b1bcf96b5b.png\" /></p><p></p><p>近年来，虚拟 AI 直播的发展迅速，已经从初期的概念验证阶段，逐渐发展成为一种主流的直播形式。目前，虚拟 AI 直播技术已经能够实现高度逼真的虚拟主播形象，通过<a href=\"https://www.infoq.cn/article/qUaGxQrDfNk3mcPezMVD?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">自然语言处理</a>\"、语音合成等技术，只需要较低的制作成本就可以在短时间内实现与观众的实时互动。</p><p></p><p>随着人工智能语音合成技术的提高和生成式对抗网络 GANs 的崛起，虚拟 <a href=\"https://www.infoq.cn/article/74LiswphPqhsxDFiO4m8?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">AI </a>\"形象层出不穷，然而，“羊驼 - 阿花”的出现却依旧让人眼前一亮。在众多虚拟 AI 形象中脱颖而出，要说没有强大的技术支撑无异于痴人说梦。</p><p></p><p>那“羊驼 - 阿花”究竟有哪些过人之处？有哪些技术支撑？面对常见的虚拟 AI 形象技术难题，“羊驼 - 阿花”制作团队是如何解决的？</p><p></p><p></p><h1>优化互动体验：AI 羊驼交互式工作流程解析</h1><p></p><p></p><p>在虚拟偶像产业中，技术是组织竞争过程中取胜的关键。“羊驼 - 阿花”作为一款虚拟 AI 形象，能够在众多虚拟形象中脱颖而出，最主要的技术优势在于其基于 NLP 技术的交互式系统。这一系统使得“羊驼 - 阿花”能够理解并回应观众的互动留言，提供有趣的语言和动作表达，从而与观众建立更加自然和真实的交互体验。</p><p></p><p>为了让 “羊驼 - 阿花”具备良好的语言和行为成长曲线，A-SOUL 技术团队在后台交互式系统中，加入基于 LLM (Large Language Model，<a href=\"https://www.infoq.cn/article/GwojGAdYA5rfpzQpDuck?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">大语言模型</a>\") 构建的 ChatAI 对话生成模型来为阿花提供 NLP 能力。</p><p></p><p>“羊驼 - 阿花”交互式的工作流程包括多个模块，每个模块都经过了 A-SOUL 技术团队的深度优化。导播端获取观众的互动留言，经筛选后输入到 Prompt 预处理模块，这一模块负责对提示语进行加工，同时过滤掉有害词语。预处理过的、具有结构化格式的输入数据会进一步发送到多个 ChatAI 对话生成模型中。这些模型是已经过微调的，能够根据输入数据进行模型推理——根据不同风格的语料，从中进一步学习特定任务的知识，例如对话任务中的上下文理解和回复生成等。</p><p></p><p>紧接着，系统会对所生成的回复进行后处理，提取语义情感并作为标签同步到用于音频合成的 TTS（Text to Speech，文本转语音）、用于文本动画生成的 TTA（Text to Animation，文本转动画）等模块。值得一提的是，TTA 模块在结合了最新 motion diffusion 技术之后，能让 “羊驼 - 阿花”实现更多更有趣的语言和动作表达。同时，系统的内容安全与合规对齐模块也会对内容进行敏感关键词、偏见内容的校准，避免回复存在不公平性或歧视性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5d/5d8f6ec9a54b2e89d49437bc2ef0b32a.png\" /></p><p></p><p>基于目前对中文有着良好支持的 LLM，A-SOUL 技术团队在 NLP 工作流程中采用了已在大量开源中文语料上进行了预训练的中文模型作为系统的基座模型，并在流程中予以微调。其中，预训练过程是采用自监督学习（self-supervised learning）方法在大规模无标签文本数据集上进行，在这一过程中，“羊驼 - 阿花”对话生成模型学习到了大量的语言知识，如语法规则、语义信息等。微调则是在有标签的对话数据集上进行，“羊驼 - 阿花”对话生成模型能根据不同风格的语料，从中进一步学习特定任务的知识，如对话任务中的上下文理解和回复生成等。</p><p></p><p></p><h1>优化性能方案：如何打破算力、成本、速度的不可能三角</h1><p></p><p></p><p>技术优化是保证系统高效运行的重要前提，然而在 “羊驼 - 阿花”的性能表现上，A-SOUL 技术团队却始终面临巨大的挑战，主要涉及三个方面：</p><p></p><p>微调过程中可能出现过拟合现象，模型未完全理解输入语境，或可能对输入数据中的偏见进行过拟合等问题；</p><p></p><p>海量算力需求以及由此产生的计算成本巨大，特别是在系统的预训练阶段，数以亿计的参数和数据集处理需要基础承载平台具备强大的算力支持和突出的内存性能；</p><p></p><p>直播场景对于实时性的要求越来越严苛，这意味着需要系统能够快速生成内容，这对推理性能提出了巨大的挑战。拥有庞大参数量的 LLM 大模型需要大量的计算资源来开展推理，而在计算资源有限的情况下产生的过长推理时延，会使对话失去实时性效果。</p><p></p><p>要知道，PyTorch 是主流 AI 框架之一，对于 AI 羊驼 - 阿花方案的部署和运行至关重要。然而，PyTorch 在 CPU 平台上无法完全释放已有处理器的全部潜能，虽然 PyTorch 2.0 提供了 CPU 平台上的模型推理优化能力，但仅适用于静态且精度为 FP32 的模型。此外由于 LLM 推理任务中的 MHA 计算依赖于随生成词元自增长的缓存矩阵，导致 torch.compile 模块需要生成庞大的执行代码且优化模型所需时间长，因此 PyTorch 框架无法有效支持基于 CPU 平台的 LLM 推理优化。</p><p></p><p>为了解决算力、成本、速度之间的平衡问题，A-SOUL 技术团队计划引入了更经济的 CPU 推理平台以及更有针对性的优化方案，并开展多方位的模型优化及硬件加速——与英特尔合作推出了 Super-fused LLM FP16/AMX BF16 推理加速方案，针对用于 LLM 推理的 PyTorch 框架进行了优化。</p><p></p><p>英特尔第四代至强处理器提供的 AVX-512_FP16 和 AMX BF16 加速指令可以完美支持并加速 LLM 推理，该推理加速方案弥补了 PyTorch 在第四代至强处理器上进行 LLM 推理任务时的性能不足。同时，英特尔® oneMKL &nbsp;(Intel® oneAPI Math Kernel Library，英特尔® oneAPI 数学内核库) 加速推理计算，能够在减少权值存储空间的同时降低内存带宽压力，在保持精度的前提下显著提升推理性能；FP16 Flash Attention 算法通过算子融合及减少内存操作来降低模型中的 MHA 计算占比以提升推理性能。</p><p></p><p>另外值得一提的是，在传统的 PyTorch 推理过程中，大量的计算缓存被用于存储模型算子产生的中间结果。然而，有了 Super-fused LLM FP16/AMX BF16 推理优化方案后，这一情况可以得到显著的改善。可以说，基于新方案，“羊驼 - 阿花”模型成功地融合了 PyTorch Transformer 算子，并且能够根据模型推理运行时的具体输入，更精确地预测所需的缓存空间。这不仅实现了融合算子间的缓存复用，还有效地提升了推理性能。</p><p></p><p>应用优化方案后的 A-SOUL 技术团队在 “羊驼 - 阿花”的性能上取得了显著的提升。在单实例场景下，“羊驼 - 阿花”方案中的不同 LLM 可取得 1.89 至 2.55 倍的推理性能提升；在多实例场景中，由 IPEX 带来的优化，可令其推理性能在单实例基础上进一步提升 1.16 至 1.2 倍。</p><p></p><p>从实际测评数据来看，A-SOUL 技术团队通过该优化方案实现了成本和生态上的有效收益。在成本方面，英特尔第四代至强®可扩展处理器完全胜任对参数规模为 10B 及以下的 LLM 推理任务，该方案帮助团队以更低的成本满足推理性能要求，优化后的 CPU 平台在环境配置方面也更加简单，达到了全面降本增效的目的。在生态方面，该方案基于 PyTorch 框架开发，完整继承 了 AI 羊驼 - 阿花方案中 LLM 的文本生成模块，与 PyTorch 模型推理接口完全一致，使用者无需为调用推理优化方案进行额外的代码开发，更易部署和落地。</p><p></p><p></p><h1>强强联合塑造未来 AI 直播生态</h1><p></p><p></p><p>A-SOUL 技术团队在 AI 算法和直播技术方面有着深厚的积累，而英特尔则以其强大的计算能力和算法支持为 AI 直播的研发提供了有力保障。通过技术互补和创新，两家公司共同研发出了更加智能化的 AI 主播算法，提高了直播的互动性和社交性。可以说，“羊驼 - 阿花”不仅仅是一个 AI 主播，它也是 A-SOUL 团队与英特尔技术合作的结晶，其代表了 AI 技术在直播领域的最新突破。</p><p></p><p>面向未来，A-SOUL 与英特尔的合作还有很大的发展空间。在技术研发方面，双方可以继续深化合作，共同探索 AI 直播技术的更多可能性，例如可以共同研发更加智能化的直播算法、提高直播的质量和用户体验等；在市场拓展方面，双方可以共同开拓更多的市场领域，如针对不同行业和场景推出定制化的 AI 直播解决方案以满足更多用户的需求。此外，在产业链合作方面，双方可以进一步整合资源，完善产业链布局，如共同投资建设 AI 直播技术的研发中心和生产基地，从而提高整个产业的竞争力和创新能力。</p><p></p><p>随着 AI 技术的不断进步，AI 直播也呈现出了更为智能化、个性化的特点——通过精准的用户画像分析，AI 主播能够实时调整直播策略，提供更符合观众口味的内容。借助先进的交互技术，AI 主播将打破传统直播的界限，让观众更加沉浸于直播体验中。</p><p></p><p>总体来说，AI 直播技术主要分为四个阶段——第一阶段，AI 对话机器人仅拥有简单的外形，后来语气逼真度和响应速度逐渐提升；第二阶段，用户可以根据自己的喜好定制 AI 机器人的外观与语音，赋予 AI 独特的个性。第三阶段，AI 可以在虚拟世界中展现自己独立的行为能力，不再局限于简单的对话交流，它们逐渐拥有自己的故事线，为直播内容注入丰富的情节。第四阶段，AI 可以实现如“西部世界”般栩栩如生的实况直播场景，为观众带来前所未有的沉浸式体验。</p><p></p><p>而当前，中国正处于 AI 直播领域的初始阶段，随着商业化产品应用的逐渐崭露头角，预计在 5 年内，众多形态各异的 AI 产品将喷发式涌现，而首个“拥有完整故事背景和世界观”的产品问世的那一天，将就是 AI 技术在游戏和直播领域成熟的那一天。</p><p></p><p>我们有理由相信，在不远的未来，不断进步的技术和日益增长的用户需求一定能驱动 AI 直播为我们带来更加丰富多彩的直播体验。同时，我们也期待看到更多像 A-SOUL 团队与英特尔这样的强强联合案例，共同推动 AI 技术的发展和应用创新。</p>",
    "publish_time": "2024-01-19 14:43:45",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "字节跳动大规模多云CDN管理与产品化实践",
    "url": "https://www.infoq.cn/article/Trcch0PrgiN7FmemUrPI",
    "summary": "<p>不久前，火山引擎边缘云融合CDN团队负责人孙益星在LiveVideoStack Con 2023上海站围绕融合CDN团队持续建设多云CDN平台的演进过程，结合建设过程中面临的难点和挑战，介绍了融合CDN团队接下来的主要投入方向，分享了火山引擎在多云应用架构下的CDN运维管理解决方案。</p><p></p><p>孙益星与他所在的融合CDN团队在大规模流量突发的挑战下，经过几年的不断迭代与打磨，使字节多云CDN平台完成了多个模块的整合，形成了一个统一的管理平台。</p><p></p><p></p><h3>01 字节多云CDN平台的演进</h3><p></p><p></p><p>面向内部业务的多云CDN平台是什么？有什么用？要解决的到底是什么问题呢？</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/36/36ef6da9842a6da07e04433216a26fb8.png\" /></p><p></p><p></p><p>字节跳动有很多流量型的业务，包括抖音、头条、西瓜视频等。为了承载这样的流量，团队使用了各种各样流量加速的产品，包括静态加速、动态加速、域名解析、证书管理以及与各种配套的解决方案，比如源站缓存、回源调度、边缘函数等。</p><p></p><p>从业务角度出发，如果有一个平台能够直接管理所有加速域名的配置，这将会带来很大便利。只需要把源站储存的信息发送给平台，剩下的配置解析、流量分配、质量管理等都是由平台完成。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/96f2a46d9472fcb73830cccf1ed48967.jpeg\" /></p><p></p><p></p><p>于是字节多云CDN平台——即融合CDN平台，应运而生，它向上承接所有业务方的CDN加速场景需求，底层对接不同的公有云服务，包含静态加速、动态加速等。这些服务本身由不同的厂商来提供，业务方在上层不需要关心它所对接的是哪些厂商，也不关心具体功能需求在不同的厂商上应该分别怎么去实现，它要做的事情就是把需求提给平台，然后由平台协调不同厂商的资源，最终再交付给业务。对于业务方来说，这就是一个普通的CDN服务平台，像是一家厂商提供的打包的服务一样，所以业内有个比较通俗的称谓是融合CDN平台。</p><p></p><p>业务对于这个平台的诉求有以下几点：</p><p>第一个诉求是质量：业务对平台的加速服务能力是有预期的，平台有责任保障上层的每一个域名的可用性和加速效果；第二个诉求是成本：成本越便宜越好；第三个诉求是功能：不同业务有比较大的差异的，比如访问鉴权、回源rewrite，缓存时间等。每个业务都会有自己的设计和需求，作为融合平台需要理解这些设计的差异，然后将它转换成厂商可满足的服务需求，最后实现、验证、最后交付给业务方；第四个诉求是服务：这个是比较宽泛的概念，就是当我们完成了一系列的资源的配置工作后，业务在日常使用中需要看监控，看报表，刷新预热、排查问题，提一些on call，这些都需要对应的服务能力来支持。</p><p></p><p>总结下来，上层业务对于平台有四个方面的需求：质量、成本、功能以及服务，这个是上层业务对于平台的需求。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5e/5e78cde90302a4bdb5e7f06a0fcd32fe.jpeg\" /></p><p></p><p></p><p>从平台的角度考虑，厂商越少，复杂度的可能性就会越低。但由于这是一个融合平台，所以需要从所有字节的业务体系的角度考虑问题。</p><p></p><p>首先就是资源的保障，资源方面要能承载日常一两百T的业务带宽，这已经超出了绝大部分厂商的资源储备。另一方面是在例如春晚、618、世界杯或者演出赛事这种大型的活动筹备时，我们很难在单个厂商上找到充足的冗余，这个冗余可能是超出常规业务量的一倍或者更多的需求，总资源池子需要多个供应商一起协调资源。其次是质量，用户分布在全国各地甚至全世界，而用户体验跟节点的访问质量密切相关，不同厂商在不同地区、不同运营商的节点分布是有比较大的差异的。这会导致在实际的业务表现中，这个地区厂商质量的排序是ABC，另一个地区就变成了CAB，这种情况在海外会更明显。对于那些时刻要求最优服务资源的业务来说，很难通过单个厂商来满足要求。质量的另一个体现形式是可用性，地区性的节点不可用是经常发生的，这会造成业务的质量波动。另外，大规模的厂商故障也时常会发生，如果只绑定一家厂商，那么它故障时流量切换也会带来明显的质量影响。所以对我们来说，保证流量较为分散的分配在多个供应商是一个必要的措施。价格方面也有多厂商的考虑，价格并不是越便宜越好。不同的业务对于质量的要求是不同的，有些对于用户体验不敏感的业务会更关注成本，对质量的要求就没有那么高；另一部分业务为了更好的质量，就对价格容忍度更高一些。平台需要价格和质量层面为不同的业务找到不同的厂商，选出一个最合适的方案。最后是功能和服务的支持，有多个厂商就可以在我们有新的功能需求的时候，缩短从联调到测试到上线的周期，在排查具体问题的时候也能给我们更多的信息反馈。</p><p></p><p>作为一个融合平台，平台的目标并不是要对接尽可能多的厂商，或者对接尽可能少的厂商。而是如果需要让整个业务达到这样一个理想的状态，多厂商基本是一个唯一的方案。在这个方案里，资源是动态变化的，不存在一种资源在各种场景下都是最好的。而是不同场景下总有一个最合适的，而平台在这里的职责就是向业务方高效的交付那些最合适的资源，并保证这些资源的可靠性，这是这个平台的核心能力。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ec/ec7654bc282a9275e74194c826a0e807.jpeg\" /></p><p></p><p></p><p>平台的建设经过了两个阶段：</p><p>第一阶段是最原始的方式：融合CDN团队会有固定的几个SRE，每个人固定的对接几个业务。大一些的业务可能会有多个专职，小一些的可能会由一个SRE对接多个业务。每个人都比较熟悉自己所对接的业务的需求和背景，按照自己的经验去厂商控制台上去配置，具体的要求也直接跟厂商的技术人员去沟通。在这个初始阶段中，主要靠人的能力来支撑；第二阶段开始有些通用的功能需求被提出放在平台里：比如说看域名的配置，数据，调流量。于是平台的功能被分成不同的功能方向分别被建设。并且不同类型的资源有不同的团队分别去实现。在这个阶段中由于业务不断有需求进来，整个平台的设计是在被需求拖着走的。这中间暴露出了一些问题，比如权限设计、接口规范不统一、数据一致性有问题等。</p><p></p><p>经过这两个阶段之后，融合CDN团队清晰的认识到：需要有一个统一的设计，把这些需要用到的能力都集中起来。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8d/8d93bc6be2762b16cf77b4cdbbca2f61.jpeg\" /></p><p></p><p></p><p>经过几年的迭代，平台完成了多个模块的整合，形成了一个统一的管理平台。大致分为权限管理、资源管理、质量管理、统计监控、厂商管理、运营分析几个模块。</p><p></p><p></p><h3>02 多云管理的挑战</h3><p></p><p></p><p>平台建设中遇到了哪些挑战呢？</p><p></p><p>使用多个CDN厂商的情况在行业内是一种普遍的现象。融合CDN团队一开始对于对接多厂商的认识是打通API，向上统一封装。但是在真正实践时，融合CDN团队发现事情的复杂度比预期要高很多。</p><p></p><p>首先，行业里面基本没有公认的规范。作为一个融合平台，需要理解不同厂商的不同规范，逐个对接，避免业务踩坑。要在不同的厂商汇总的数据中，及时准确的发现地区性的质量波动并定位原因等。其次，当资源选择变多了之后，如何保证融合CDN团队的选择是最优的变成了一个被大家关注的问题。最后还有一个重要的问题：就是我去解决这些问题的时候，应该投入多少，怎么来评估产出，团队的价值如何量化。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f1/f1b7478a15ea114aad800d005c1e7623.jpeg\" /></p><p></p><p></p><p>我们从配置和数据两个基础的问题开始讨论，再展开到上层的方案，介绍我们质量和成本的运营，最后讨论平台团队价值的问题。</p><p></p><p>1.配置</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/76/76a9402719498a2784449b0cf5ac113e.jpeg\" /></p><p></p><p></p><p>行业内配置的差异非常大。厂商之间没有规范，对接成本高。厂商的开放接口并不能覆盖全部的能力，接口操作风险高，一次变更全网下发。有些功能还必须去和厂商的后台沟通才能加入。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/61/61f5535a467d0e1c5101f85c8eabb661.jpeg\" /></p><p></p><p></p><p>解决这个问题分为三个方面：</p><p>制定配置规范所有厂商所有的功能集合尽可能开放到一个规范里面，一次性实现完整的规范。即便人力开销会增大，但会变成一个相对来说较为固定的投入，不会像以前那样一直在反复的调整。规范变更流程首先要求所有的配置变更必须有一个统一的入口。任何操作必须在内部的平台实现，不能在厂商操作。入口收敛之后，所有的配置只有有权限的人才能够发起变更，需要有熟悉业务的人来审批，审批之后由SRE来触发实际下发的流程。配置在下发完成之后，在接口层面会检查对应的配置是不是符合预期结果，进行一次重新的配置读取，厂商也会给到相应的反馈。配置下发完成之后，也会做一些调度层面的准备，例如新建域名或者删除域名。最后在交付之前，会进行一次完整的回归测试。这些测试需要是配置项级别的，比如修改源站，融合CDN团队要确认回源相关的响应里面有没有新源站的信息，如果是修改访问控制规则，需要确认对应条件的访问是不是真的被拦截了或是被放行了。这些回归做完之后，意味着这次变更从用户侧的访问效果应该是真的达成预期了，最后才会通知业务方这个变更完成。完善测试框架最后还有一个接口的测试框架，与前面提到的回归测试区别在于：上述的测试是面向配置结果，而这个测试框架是面向整个配置接口。因为接口转换的实现很重要，并且很容易出问题，导致这些问题的原因可能是代码的bug，或者厂商API层面的一些变更导致不兼容的问题、环境的变化产生的影响等，这些问题如果没有一个很好的测试框架，就只能等它出现问题的时候才能发现。在过去的一两年，经过测试框架的积累，火山引擎边缘云完成了大约2000多个case的建设，每次API上线都会跑一个完整的测试，每天有定时的巡查保证厂商测试的功能是符合预期的。这样大量的测试积累，也帮助我们发现了很多问题。</p><p></p><p>2.数据</p><p></p><p>下面再说一个比较基础的能力：数据。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1e/1e5cfea4a761eaefceb7ed8d1eda5054.jpeg\" /></p><p></p><p></p><p>数据产生的源头分别来自于服务端和客户端。服务端从access log开始由厂商转换成两种数据出口，离线日志和实时统计的接口，前者延迟一般是小时计甚至天级别的，后者可能可以做到分钟级。平时看到的带宽请求数状态码都是从服务端的数据源产生的。客户端则是我们自己的业务上报客户端的访问质量数据，同时加上自身的拨测任务巡检，采集一些更详细的链路质量信息。</p><p></p><p>为了做统一的聚合分析，这些数据被统一存储到数据中台的统一数仓里。整体来看很容易可以理解要做什么，但是跟传统的大数据系统相比，多云平台的工程实现有出现一些额外的问题。</p><p></p><p>首先就是数据的延迟，接口级别的延迟虽然是分钟级的，但是不同厂商的差异也比较大，有的1分钟、有的5分钟、有的10分钟。但是我们自己的调度系统在做切换的时候希望拿到的数据是越实时越好；其次是接口的局限，虽然接口的延迟相对日志会低一些，但是它能提供的信息量是有限的；再次是采集能力，采集时会出现接口不可用，被限频等问题，这就要求我们的采集系统能够识别哪些错误需要重试，针对厂商主动地控制自己的采集频率；最后是采集的数据质量如何保障，厂商对于接口的实时性是没有办法100%保证的，接口报错很频繁。采集数据还没出来时，有问题的数据如何修正，修正之前如何判断这个数据是不是可信的。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f3/f364159fbe60dcbfc5e4d1a85c13d612.jpeg\" /></p><p></p><p></p><p>整个建设分为三个阶段：</p><p>第一阶段是多源数据采集，解决包括客户端的、服务端的、实时的、离线的不同数据源的适配；第二阶段是数据可靠性建设。厂商的数据、日志、API、账单等数据会有对比过程，如果发现某个数据出现问题，会发起主动的修复。同时会对整个数据大盘进行实时性监控。上层系统会根据数据做置信度判断。结合服务端的QPS和业务侧上报的数据，判断当前数据是否真实可信。如果不可信，需要使用其他的数据拟合进行针对性的修复；第三阶段是统一数仓。数据采集之后，会使用统一的规范储存到数据仓库里，向上会提供统一的API查询和信息查询能力。在实际操作过程中，可能会遇到API层面无法实时采集地区运营商级别数据的情况。业务方在查询的时候，需要把这部分查询实时转化成接口的请求转发给厂商，以达到相同的效果。</p><p></p><p>上图为整体的模式图。底层是统一的数据中台，负责数据的采集、计算、存储、对外提供查询的接口，上层包括监控、运营、策略等不同模块，面向不同的用户提供不同的功能。</p><p></p><p>3.质量管理</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/be/bed21bd35ecdcb41143f536ebf18c2fc.jpeg\" /></p><p></p><p></p><p>介绍完配置和数据这两个基础的能力，下面向上讲一些业务方更关心的横向的能力，首先是质量保障。</p><p></p><p>作为一个融合平台，业务方如果有感觉到质量出现问题，一般是出现了故障。平台要做的事情就是把质量的标准提高，尽可能避免对业务产生影响。很多问题对上层没有影响，但是在内部已经走了一个完整的故障处理流程，包括问题的检测发现、通知告警、诊断定位、预案恢复。对于一些比较明显的问题，不管有没有对业务造成影响，融合CDN团队都会做内部的复盘和改进。</p><p></p><p>在这个流程中，融合CDN团队要面对各种各样的问题，比如如何保证检测到的告警的有效性、缩短定位的时长、提升我们无人工干预自动恢复的比例，以及后面的复盘定级需要怎么做。</p><p></p><p>这个过程是：</p><p>最基础的能力是监控的数据源，相较于刚才的多源数据采集，还定制了厂商侧的告警上报、实时错误日志推送等能力，也会结合业务侧的SDK打点、拨测数据、以及自有节点的一些质量数据。这些统一到数仓里，构建了一个比较实时的质量库。</p><p></p><p>往右就是数据的检测告警，数据会根据不同的维度聚合，比如域名的、业务的、AB测试的都可能有不同的告警规则。这些规则可以是例如状态码异常比例、播放错误率比例这类静态的规则，也可以是根据时序数据的特征和历史趋势动态判断告警阈值应该是多少。我们对于周期性的和非周期的时序数据都可以支持动态阈值的告警。</p><p></p><p>当告警触发后，会进入根因分析流程，判断这个告警产生的真实原因是什么。比如当业务方客户端错误率上升时，需要判断对应的是哪个域名，这个域名是放在哪个厂商上，对应的各个维度的监控是否正常。这些判断会涉及到时序数据异常检测、不同数据的相关性分析等等。基本上我们常见的异常都会有完整的根因分析逻辑，直到排查出最终的问题，比如到底是厂商侧的问题还是我们源站的问题还是地区性的网络问题。</p><p></p><p>这样最终在告警发送时，已经带着完整的诊断结果通知我们的SRE。比如会告诉你，当前的现象是客户端错误率上升，原因是源站问题，对应中间的检查结果是怎样的。这时候我们可以直接通知业务方处理自己的源站问题了。</p><p></p><p>如果是厂商的问题，例如地区性的节点不可用，除了会通知厂商之外，我们还会自动去执行一些预案。最常见的就是切流，把对应地区的调度权重从问题厂商上调走，同时保持对厂商对应地区的主动探测，当厂商的流量正常时再切回来。最后这个质量问题的影响时长、故障定级等等会在质量系统中有明确的体现，厂商侧也可以根据我们反馈的信息进行检查和改进。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/de/de20909169dfa3fa9f9f7904c941f3cf.jpeg\" /></p><p></p><p></p><p>这样最终整套的系统就实现了闭环，质量数据的检测会触发告警和根因，自动的根因分析和预案执行能够自动的改善质量数据。</p><p></p><p>过去几年融合CDN团队一直在改善闭环里的执行效率和准确性，让更多的问题能够被自动预案来覆盖。目前的告警准确性，就是那些波动异常经过智能阈值判断，以及降噪处理后，被确认真的是异常的占了98%以上，80%以上的告警会带着准确的根因分析信息一同提供给SRE和技术支持的同事。</p><p></p><p>4.成本运营</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e7/e78478278a3eea65c46a56a4938586b1.jpeg\" /></p><p></p><p></p><p>成本运营在过去几年一直是一个令人非常头疼的问题。因为由于数据的敏感性，融合CDN团队最初做了很多的限制，导致相关的技术只能局限在一个很小的范围内讨论。但是这个团队要解决的工程问题还是非常复杂的，需要充分的投入。比如每个月一到月初就要花大量的时间去校验厂商的账单数据是不是准确，还有像成本分摊、波动归因等方面都存在很大的挑战。解决办法一种是让业务方熟悉我们的成本逻辑，自己去分析，另一种方式是从平台层面提供统一的能力来帮助业务。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0a/0a50c7f33121953b1a0ae959e032b899.jpeg\" /></p><p></p><p></p><p>首先需要明确的是数据因为和钱相关，确实是很敏感的，因为涉及到商务的保密问题等，但是钱可以拆分成两部分：一部分是单价，一部分是用量。单价只有有权限的人才能可见，所以融合CDN团队额外做了一套系统，把价格隔离起来管理。用量信息则没有那么敏感，大部分业务方都会接触用量信息。将单价隔离开以后，平台的负责人就可以深度的参与到用量的优化之中。这些用量，比如边缘带宽、存储、专线会分别对应到不同的分摊算法中去，让每一种资源的用量都有一个固定的逻辑分摊到最小的成本单元上，一般就是域名。域名在总的用量上面占多大比例是可以明确的，成本单元有自己的组织归属，包括叶子结点和跟结点的归属都可以映射过去。</p><p></p><p>对于业务方来说，可以直观的看到每月的带宽上涨到底是哪些业务甚至是域名导致的问题，这个就是我们近期面向业务方开放的成本分析能力。</p><p></p><p>在排查问题的时候，每一层的数据都是可校验的。所有域名的总用量加和，一定等于分摊前的总用量加和。每个资源的总用量，乘以对应的单价，一定等于对应的资源花掉的钱。做数据校验的时候，只需要一层层的校验就好了。</p><p></p><p>5.平台价值</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b1/b138fbee2bea973c2b408a8931ef27dd.jpeg\" /></p><p></p><p></p><p>刚才说了我们作为一个多云管理的平台，资源是来自于底层的厂商，流量来自于上层的业务，平台做的事情只是把这个资源更好的交付给业务，协助我们的业务使用好这些资源。</p><p></p><p>在这个过程中我们投入了接口开发、QA、数据工程、运营分析、调度系统、质量监控、权限管理还有前台、文档等等，但是向上还是要落实到业务层面可以感知到的收益上，就是我的质量是不是有保障，还有我的成本是不是在持续的优化。</p><p></p><p>所以一直以来衡量融合CDN团队产出的指标一直都是一些相对固定的维度，质量、成本、效率、稳定性。</p><p></p><p>最近一年来整套的系统设计才逐渐完整，把线上问题收敛稳定下来。到现在为止依然要投入很多的人力去维护我们配置接口的迭代、数据的保障、以及平台化的功能建设。另一方面，正是因为有了业务体量的支撑，我们团队的投入价值才能最大化。</p><p></p><p>过去一段时间里，融合CDN团队也跟火山引擎的客户和开发者做了一些技术上的交流，去介绍融合CDN团队是怎么管理多云的。一个经常提出来的问题是，我有什么简单的办法实现你这套系统，我可以不要那么复杂的前台界面、审批流程。但是那些关键的能力，比如质量管理、成本分析，我们怎么样才能用最小的投入做起来。</p><p></p><p>所以在去年融合CDN团队对系统又重新做了一次改造，把底层的关键能力，数据系统配置系统调度系统还有中间的一些核心解决方案，逐步的开放成我们的产品能力，放到火山引擎上面提供出来。这个就是我们的多云CDN产品。</p><p></p><p></p><h3>03 火山引擎多云产品能力</h3><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a2/a27fe2207a1c6b4c9dd92a0c58772234.jpeg\" /></p><p></p><p></p><p>多云CDN底层还是对接不同资源厂商，包含不同服务类型。但中间层正在经历一个深度的改造，从右到左不断地将我们的核心能力孵化为开放的产品；从左到右，以上云的形式不断地将我们已有系统的实现以更加规范的设计和概念定义去做重构，让一些原本比较模糊的内部概念能够以一个内外部用户能理解的方式去运行。</p><p></p><p>在这套系统之上，现有的融合平台会变得越来越薄，未来可能只会保留一些跟内部业务深度耦合的部分，比如流程的审批、内部业务的预案等。业务方还是使用我们融合平台的界面，但是这个平台的底层未来会和火山引擎的客户一样是我们这个多云产品的用户，通过它提供的开放接口能力去管理各自的资源。</p><p></p><p>1.资源管理</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ad/adc95da41d760b7f2f9abe39e0fdedb9.jpeg\" /></p><p></p><p></p><p>多云CDN产品去年刚刚上线，就已经完成了基本的资源管理能力。平台现在支持已经完成接口规范化改造的国内外厂商。在接口能力上配置的统一查询功能已经完成，也支持了像域名创建、证书更新这样的能力，更完整的配置变更流程正在做产品化的改造。在资源管理的基础上，业务组织、权限、统计聚合的能力也完成了，一些拓展的功能，比如在TOS文件变更的时候同时刷新多个厂商的CDN，我们称之为联动刷新的能力，有了多云的平台就比较容易实现，目前正在被实际使用。</p><p></p><p>2.监控分析</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/57/57e606fdec8120522ee1455488b3342e.jpeg\" /></p><p></p><p></p><p>在数据的能力上，统计的API和日志的API在第一阶段都已经支持。刚刚完成了数据采集的能力，可以直接帮助用户从API采集数据然后存下来，在这个数据能力之上，用户可以做不同厂商数据的统一聚合，或者灵活的对比不同厂商的数据。未来我们还会开放自定义报表的能力，帮助我们的客户分析全局的业务数据。</p><p></p><p>3.智能运维</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bf/bf6bd020e2f7f38b39455572a81ebf95.jpeg\" /></p><p></p><p></p><p>在监控能力上，有了刚才说的数据采集的能力，加上我们的拨测能力，以及未来会开放的客户数据上传的通道，我们把内部的智能告警、根因分析、自动容灾的预案也都放到了产品上，未来会结合我们自己的质量库帮助我们的客户更好的分析业务质量、提升服务的可靠性。</p><p></p><p>4.FinOps</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e7/e701b0359ff07185af2dad5879eb80ec.jpeg\" /></p><p></p><p></p><p>近期，成本管理能力已经上线。总的来说就是将成本运营能力开放，结合数据采集能力和账单分析能力，帮助客户准确的分析账单构成、业务成本构成和波动的原因。未来还会结合不同的计费模型，帮助业务方更好的分析成本，组成对应的优化方案。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4a/4a04d66458d85782cb43bcec80e3ac41.jpeg\" /></p><p></p><p></p><p>上述就是整个多云CDN产品的演进过程。火山引擎多云CDN产品在2022年上线，目前还在快速地迭代过程中。融合CDN团队期望和厂商、开发者一起，为火山引擎的用户，实现一个规范、统一、安全、高效、智能的多云流量管理平台。</p><p></p><p>关于火山引擎边缘云：</p><p>火山引擎边缘云，以云原生技术为基础底座，融合异构算力和边缘网络，构建在大规模边缘基础设施之上的云计算服务，形成以边缘位置的计算、网络、存储、安全、智能为核心能力的新一代分布式云计算解决方案。</p>",
    "publish_time": "2024-01-19 15:48:20",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "你当初被谁“忽悠”上了云，现在又在被谁“忽悠”下云？",
    "url": "https://www.infoq.cn/article/32WOMJbur2ytBY09SIqI",
    "summary": "<p></p><blockquote>本文是 “2023 InfoQ 年度技术盘点与展望” 系列文章之一，由 InfoQ 编辑部制作呈现。</blockquote><p></p><p></p><p>“当前的机会在于现有的服务品质不够好，而我们专注于客户体验的能力，能带给市场差异化的服务。”2006年，Amazon创始人杰夫·贝佐斯在第 10 封股东信中说道。就在那一年，Amazon Web Services 成立，并用Simple Storage Service（S3）给了市场一个不小的震撼：凭借低廉的成本与便捷的配置，真正拉开了企业使用云计算的序幕。</p><p>&nbsp;</p><p>第一批吃螃蟹的总是互联网公司，其中最典型的当属Netflix。从2008年因数据库损坏决定上云，Netflix用了7年的时间完成了上云迁移，并关闭所有的流媒体服务数据中心。如果没有云服务，随着业务规模的不断扩大，Netflix 就需要投入庞大的运维和研发团队来处理与其核心业务不直接相关的事务。这个案例每年都会被Amazon拿出来对外宣讲。</p><p>&nbsp;</p><p>到了2016年，美国联邦调查局（Federal Bureau of Investigation，FBI）在结构会议上解释了自己如何利用云计算来管理安全。虽然并没有直接鼓励大家用云，但带来影响就是互联网之外的企业之后也开始尝试上云。</p><p>&nbsp;</p><p>国内上云情况与国外基本相似，只是晚了几年。2009年，阿里云成立；次年，腾讯云正式对外提供云服务；百度智能云更是到了2015年才正式对外开放运营；华为云虽然2005年就已经成立，但当时也主要做政务云和私有云，规模很有限。</p><p>&nbsp;</p><p>出来卖云但自己不用的话，国内用户不会买账。因此，头部互联网企业引领的国内上云潮逐步开启，走在前头的依然是互联网企业。经过云厂商多年“市场教育”，国内对上云似乎已经达成了共识，现在甚至政企成为发展主力。</p><p>&nbsp;</p><p>但在2023年，随着推特和Ruby on Rails 之父&nbsp;David Heinemeier Hansson（DDH）联合创建的37Signals 宣告“下云”，业内展开了一场关于上云还是下云的讨论。但是纵观国内，其实还没有企业公开宣告自己要完全下云，这场讨论在国内最后实际上变成了一场对云厂商声势浩大的声讨。</p><p>&nbsp;</p><p></p><h2>云厂商带来的各种“坎儿”</h2><p></p><p>&nbsp;</p><p>一定程度上，企业遇到的大多数用云问题都是云厂商带来的。</p><p>&nbsp;</p><p>磐吉云数 CEO&nbsp;冯若航在直播节目里分享了自己15年时的经历：上云之前，部门自己拥有的几百台服务器的机房，一年成本大概 1000 万，上了阿里云大数据全家桶后，每年计算花掉 3000 万、存储 4000 万，效能没有出现变化的情况下，成本却翻了七倍。</p><p>&nbsp;</p><p>虽然他没有详细解释花费项目，但已经说明了在很多人眼里，云厂商毫无“性价比”。云厂商到底做错了什么？</p><p></p><h4>被误解的弹性</h4><p></p><p>&nbsp;</p><p>弹性本来就是一件不容易做到的事情，不管是对用户、企业，还是云厂商来说。而云厂商手握巨大的资源池，可以为不同的用户调度资源，这让弹性成为可能。但要把弹性真正用起来还差很多。</p><p>&nbsp;</p><p>事实上，现在并不是所有产品都是弹性的，大多数云产品还处于云托管阶段，即把传统软件架构通过再部署的方式上云，只有少数产品是按量付费的，比如S3按照存储量和请求API次数收费。</p><p>&nbsp;</p><p>这里面有一定的技术原因。</p><p>&nbsp;</p><p>当前阶段，业务重度依赖的开源产品大多数还是 10 年前诞生的成熟开源产品，这些产品对云计算模式不友好。比如，很多开源软件并不是面向多租户设计的，而是从大企业内部孵化出来的、面向内部业务的，并没有多租户需求。</p><p>&nbsp;</p><p>如果把这些软件搬到云上就要对其架构进行重构或者改变其接口行为，但一般云厂商不会这么做，因为后续还有兼容性等问题。但重构这些产品对云厂商来说，研发成本、运维成本，甚至后续迭代的成本都会很高。结果就是，每个用户独占一套集群，成本很高，也做不到按资源使用粒度计费。在云上部署一个开源软件要三台机器起步，如果真正按请求付费，云厂商大概率要赔钱。</p><p>&nbsp;</p><p>第一天就诞生在云上的产品就没有这种问题。产品经理清楚地知道这个产品要服务数万个、甚至几十万用户，他第一天就会考虑接入成本优化问题。因此，这类产品基本都是按量付费的模式，比如Amazon的SQS、S3、Lambda。近两年面向云原生设计的开源产品，商业化模式也比较友好。</p><p>&nbsp;</p><p>云托管的技术架构也限制了云厂商的定价策略。绝大多数云产品按实例或规格售卖，特别是以开源产品为内核的云产品。云厂商把这些开源产品（甚至包括数据库）拿去做云托管然后包装成一个云产品去售卖，这些产品的“按量付费”是按小时粒度进行按量付费，比如4核8G每个月1000元，然后再按照小时计费，如果下个小时释放了就不收费。</p><p>&nbsp;</p><p>云厂商追求的是超卖率，通常用户选择包年包月方案能获得更低的折扣。但实际上，用户不可能在不用的时候就把这个实例或者规格释放掉，即使没用也会把资源保留在那里，这就带来了更多的消耗。所以，用户实际上并没有享受到这种按量计算方式带来的弹性好处。</p><p>&nbsp;</p><p>当然，这对厂商来说也并非好事。除了短暂的流量高峰，其他时候的资源闲置会造成巨大浪费。此外，云厂商还要为“按需使用”预留出大量的资源。</p><p>&nbsp;</p><p>另一方面，对于真正按量付费的云服务，用户也要付出一定的使用成本。比如以前的软件架构不可能是基于S3设计的，所以传统架构直接搬到云上，S3 的 API 肯定用不起来。</p><p>&nbsp;</p><p>总体说来，只有相对成熟、规模较大、已经形成事实标准的产品价格才更为便宜，只是这样的产品数量有限，还集中在IaaS和数据库范畴，大量云产品并不是真正的按量付费。</p><p>&nbsp;</p><p>这也表明了，云计算还处于不成熟的阶段，未来云厂商还是需要通过技术架构去降本，比如把更多云产品优化成真正的Serverless或弹性架构，真正规模化优势释放给用户。毕竟，“贵肯定不是云计算。”</p><p>&nbsp;</p><p>但目前国内云计算市场格局还在不断变化，整个价格体系仍有一定的不确定性。今年4月，阿里云宣布核心产品价格全线下调15％至50％，存储产品最高降幅达50%，被称为是“阿里云史上最大规模降价”。之后，腾讯云，京东云、移动云、天翼云等纷纷跟进。同样的降价策略到了双十一时再次上演。</p><p>&nbsp;</p><p>相对地，国外厂商已经过了大规模“价格混战”。2014年左右，国外云厂商经历了一场激烈的价格战，数百家云厂商竞争激烈，最终剩下主要的三四家。</p><p>&nbsp;</p><p>但种种因素叠加，云厂商其实也很难盈利。头部的Amazon用了9年才首次公布盈利，阿里云则用了11年。</p><p>&nbsp;</p><p></p><h4>多而杂的云产品</h4><p></p><p>&nbsp;</p><p>另一个事实是，国内大部分云产品缺乏竞争力，基于开源软件做商业化和产品化的做法就决定了这点。</p><p>&nbsp;</p><p>现在的云产品数量非常多，大的云厂商有上百个。虽然一定程度上，这么多产品确实是云厂商为满足用户真实需求而研发的，尤其是那些研发运维能力较弱的团队很依赖云托管产品，但这也是国内厂商一味“参照”国外产品的后果。</p><p>&nbsp;</p><p>国内云厂商基本都是“先做起来再说”，并没有考虑产品的顶层设计。国内厂商还喜欢“一站式”包揽所有问题的解决，后果就是各种产品自成一体，能力同质和重复，甚至会出现内部竞争。</p><p>&nbsp;</p><p>一方面，上百个产品很多是在重复研发、运维、部署等，最终让整个投入变得特别大。另一方面，每个云产品都特别做得很重、有完整的生命周期，这需要专业团队负责到底，现实却是一个产品可能只有几个人负责，这几个人能把商业化做好就已经不错了，很难兼顾到接入成本、使用体验等。</p><p>&nbsp;</p><p>更重要的是，上百个产品里，真正能够承担起营收规模的可能只有少数十几个，大部分产品规模小、做得一般，却消耗了大量的人力。当然，云厂商们近两年也在进行调整策略，淘汰了一些需要维护却难以带来效益的产品，更加聚焦在自己的“拳头”产品上。</p><p>&nbsp;</p><p>反观国外云厂商，他们更注重通过标准化或提供更多自定义能力来服务企业。其次，国外云厂商的生态位是就绪的，当整个生态就缺这么一款产品时，放进去就能形成级联优势。比如Amazon每个产品的体验、UI、文档、交互做得几乎一模一样，功能也做得比较克制，更倾向通过多个云产品的组合实现相关功能。</p><p>&nbsp;</p><p>国内云厂商为适应快节奏的市场需求，产品从研发到推出和运营的周期通常较短。但在追求速度和追求质量之间需要取得平衡，不能过于偏向速度。尤其ToB业务从第一天就面向企业，用户对服务的质量要求很高。</p><p>&nbsp;</p><p>在这方面，很多云厂商还有很大的改进空间，但肯定不是要求客户妥协，也不是通过降低服务质量、以低价策略来取胜。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ee/eec06382dbdb90885cbedcba624feec3.png\" /></p><p></p><p>2023年中国云计算行业企业竞争状态总结，图源：前瞻产业研究院</p><p>&nbsp;</p><p></p><h2>成本，终归是企业的事</h2><p></p><p>&nbsp;</p><p>“我们相信了市场营销。之前各种营销宣传的亮点均在于它将更便宜、更简单、更快速。事实上，只有最后一个承诺真正实现了。”DHH很多次解释自己公司选择下云的原因时这样说道。</p><p>&nbsp;</p><p>为了拿到订单，销售人员可能会向客户推销一些他们实际上并不需要或是过度设计的产品，比如不是所有业务都需要异地双活、两地三中心等高可用架构。云厂商的过度承诺提高了用户的期望，让用户有了错误的期待，但上云的种种问题却没有及时被告知。</p><p>&nbsp;</p><p>很多在云厂商工作过的人都提到，许多公司在首次上云后只是简单地将资源放上去，但对资源的创建和用途并不了解。这导致企业只有在月底云厂商给出账单时才发现一些资源使用存在问题，但已无法追溯和挽回。</p><p>&nbsp;</p><p>用云的时候一定要非常保守、非常克制，但实际上企业太相信“按需付费”了。</p><p>&nbsp;</p><p>过去几年的高速发展，让企业更关注云到底能不能帮助解决问题，对成本反而没那么上心。云厂商跟着互联网一起快速增长的同时，很多东西也没做好，牺牲了质量换速率。如今在“降本增效”大背景下，大家要去看成本了，才发现要考虑这么多问题，实际上是增长掩盖了这些问题。</p><p>&nbsp;</p><p>大多数互联网公司的主要成本通常集中在CPU、存储和带宽，其中CPU占30%～40%，剩下的多数是各种各样的存储，包括对象存储、云盘存储、文件存储等，还有使用云产品的费用。近几年，GPU和GPU所需的高性能设备成本也逐渐上涨，此外还有一些像安全产品、专线费用等更细致的项目。实际上这些项目成本多达几十项，甚至上百项。企业要想梳理清楚这些成本并不容易。</p><p>&nbsp;</p><p>在2021年之前，云厂商只是事后生成账单，并没有考虑到让企业更加可控地管理成本。而且这个账单也很难对应到具体业务。每个产品至少有四、五个计费项，如果用几十个产品，就是数百个计费项，假设公司有几十个业务，则很难判断每个业务花多少钱。</p><p>&nbsp;</p><p>现实中，企业存在相当大的资源浪费。比如业务变化对CPU的使用情况是不同的，但不及时调整策略就会产生很大的浪费；又如后端并非必须要记录大数据，长期保存这些日志对公司收益无益反而会增加成本。</p><p>&nbsp;</p><p>为了适应降本增效的大趋势，各家云厂商，甚至独立的第三方、开源社区等，都陆续推出了一些FinOps工具。但现在的FinOps工具主要针对CPU等主要成本项目，其他科目的计费工具比较少，并不能满足企业对网络、存储及更深层次PaaS等不同产品成本的分析需求。</p><p>&nbsp;</p><p></p><h4>几个建议</h4><p></p><p>&nbsp;</p><p>现在的降本更多还是要依靠企业自己。作业帮基础架构负责人董晓聪介绍，他们现在一方面给产生成本的项目“瘦身”，比如基础研发与业务线共同定期梳理计算、存储等开销，只保留有价值的部分；另一方面，利用每年硬件厂商释放的一些红利，周期性的进行主力机型替换。</p><p>&nbsp;</p><p>更重要的是，他们建立了更全面的FinOps成本管理体系，主要包括成本洞察、成本优化和成本运营三方面：</p><p>&nbsp;</p><p>清晰地记录成本账单，像各产品科目、业务之间是否共享服务等都要明确。他们会生成多种类型的账单，包括云厂商支付账单以及内部研发部门的实际使用账单，这些账单会被归结到具体业务线，计算其使用回报率（ROI）；通过容器增加集群负载、离线混部等提升利用率和使用效率，引入了各种新技术进行成本优化；通过年度预算机制和每月审查，找出浪费或与预算不匹配的地方，并进行优化等。这些措施帮助企业许多业务线的成本节省了40%，预计未来每年会有千万级别优化。</p><p>&nbsp;</p><p>AutoMQ 联合创始人兼CTO周新宇则借助FinOps思想，强制作出一些资源创建前置管理的规定，比如用S3时不能用公网、用EC2时必须用Spot实例等，还有其他的节省规划。同时，借助开源工具Infracost进行成本实时监控，他们可以在PR里面清晰地了解到一旦某代码合并到主干后，云账单会增加或会减少多少，这样企业可以在每一次代码提交时候就能量化云资源成本，而不是季度结束后才收到一个账单。</p><p>&nbsp;</p><p>另外，用户使用云产品要养成一个习惯，就是先去看它的计费项，即什么地方会收钱，其次要看这个产品的限制和边界是什么。由于技术不够完备，很多云产品都有用户想象不到的限制，比如资源数量或单个资源带宽等。因此，用户不仅要算钱，还要看自己的需求在不在产品服务范围内。</p><p>&nbsp;</p><p>Datastrato 创始人兼CEO堵俊平则建议，企业要制定更为有效的产品采购策略和选择策略，避免盲目地被销售人员引导。企业选产品时候不要只看广告，也不能完全依赖第三方报告，而要关注实际场景，找出适合自己工作负载情况的产品。企业可以利用产品推广期提供的免费试用，按需使用一段时间，发现产品不合适时可以迅速切换或回退。</p><p>&nbsp;</p><p></p><h2>有完美方案吗？</h2><p></p><p>&nbsp;</p><p>不能否认的是，用好云本来就是一件很有难度的事情，除了本身的技术问题，更难的是与千变万化的业务结合。</p><p>&nbsp;</p><p>云厂商做云产品时，要面对数十万用户和各种各样的场景，一个能满足所有流量模型的体系化产品肯定是非常复杂的，云厂商的职责之一就是抹平这些差异，当然这方面云厂商做得并不好。</p><p>&nbsp;</p><p>对企业来说，只做基本操作、处理简单的业务场景还可以应付，一旦涉及到大规模应用，企业在以K8s为基础的云架构在运维和管理方面就会遇到相当复杂的问题，一些原有调度器组件可能无法满足需求，需要企业做自定义组件的开发，甚至包括对K8s底层结构做深度调整。</p><p>&nbsp;</p><p></p><h4>完全自建，不是普通玩家的游戏</h4><p></p><p>&nbsp;</p><p>但完全下云、自建IDC 这种方式也并不能解决问题。</p><p>&nbsp;</p><p>国外比国内更早提下云，是因为国外的IDC和云的价格差异较大，国内云厂商比传统IDC更有价格优势。国外的IDC服务运营机构通常也提供更为全面的服务，企业可以将很多ToB 的云管理能力外包。此外，国外做 ToB 云端软件企业更加成熟、工具链相对更为完备，企业自建可以获得更好的体验。</p><p>&nbsp;</p><p>但是，自建IDC是有门槛的：对于百万级机器规模以内的企业，无论从扩展性、更高效运维，还是更先进的基础设施角度，云计算是成本效益最优的选择。</p><p>&nbsp;</p><p>一旦企业规模超过百万级，尤其是在拥有相对完善的机房设施和系统运维团队情况下，有的大型企业，如快手和拼多多，就会逐步考虑从云上迁移到自建IDC，这个阶段的企业在采购和供应链方面也拥有了一定的优势。</p><p>&nbsp;</p><p>AutoMQ&nbsp;联合创始人兼首席战略官章文嵩在直播节目里就算过这样一笔账：考虑到硬件、托管和网络带宽资源等成本，每台机器年均花费约&nbsp;2&nbsp;万元，&nbsp;5&nbsp;万台服务器的话就要花费约&nbsp;10&nbsp;亿元。此外，自建还有构建分布式系统、操作系统和数据库等的额外投入，而维护一个六七百人的研发团队的成本就高达&nbsp;5&nbsp;亿。</p><p>&nbsp;</p><p>其实，在使用云的基础能力方面，IDC和云没有太大区别。IDC的基本构建包括租用机房、购买机器、搭建交换设备、申请公网IP、引导流量到负载设备以及在机器上部署服务等。IDC可以看作是一个基础建设的雏形，云计算大大简化了这个过程，用户只需点击即可创建一个高性能的VPC网络，无需处理排线等问题。</p><p>&nbsp;</p><p>上云和自建IDC的关键区别在于，像操作系统内核这样的基础设施，云厂商通常有规模庞大的内核团队来不断升级稳定性，而自建IDC可能使用开源内核，企业需要自己承担内核维护的各种成本。</p><p>&nbsp;</p><p>但自建IDC最大的问题可能是没人。一个完整的自建系统通常需要三个团队：研发、测试和运维。这意味着企业通常需要基于开源软件从零开始构建技术栈，这要求工程师熟悉开源软件技术栈的使用和运维，并不断跟踪社区的动态。要找到胜任下云工作的运维人员相当有挑战，这一领域的人才需要长期积累的经验和技能，优秀的SRE人才更是难得一见。而硬件工程师的稀缺性更不用说。</p><p>&nbsp;</p><p>因此，除非企业是为了核心业务、愿意且能够投入足够的资源（包括招聘高水平的工程师、购置硬件和维护系统等），以及具有成本效益时选择自建才是合适的。</p><p>&nbsp;</p><p>现在业内基本共识是刚成立的创业公司或新开展的业务一定是上云。对于存量业务上云还是自建，当业务和团队在相当一段时间里都比较稳定、并满足上述条件时，自建机房未尝不可。当团队不稳定或者业务有增长机会时，考虑分阶段增量式上云更为稳妥。</p><p>&nbsp;</p><p></p><h4>多云、混合云可以吗？</h4><p></p><p>&nbsp;</p><p>相对于完全下云，另一种中庸的方式是多云和混合云。</p><p>&nbsp;</p><p>在多云和混合云的情况下，业界通常提供了相应的解决方案，甚至逐渐形成了标准化的方案。多云可以解决云厂商锁定问题，并通过平衡云服务的采购来优化成本，获取更多议价空间。</p><p>&nbsp;</p><p>不过，多云的选择也没有统一标准，企业需要考虑的因素有很多，比如要结合自己的业务特性和成本方面考虑选择、要确保数据在不同云上不会形成孤岛、仔细评估和选择产品等。</p><p>&nbsp;</p><p>有的企业可能一开始使用某个云厂商的产品，但后来发现其他云厂商有更好、更稳定的产品，这种情况下，企业可能会调整其多云策略来获取更好的服务。还有企业并购后做业务整合时，可能考虑多云策略来协同工作；另外在国际化和出海业务中，企业需要根据不同地区的情况选择云服务。</p><p>&nbsp;</p><p>另外根据IDC最新报告，混合云已经成为市场中主流的云基础架构部署形态。混合云架构是本地、私有云和第三方公有云平台的统筹安排，对多云协同管理和跨云一致性进行了更多的优化，从而得到更多大型政企的青睐。当然，混合云架构带来的复杂度、安全等问题也需要引起重视。</p><p>&nbsp;</p><p>多云、混合云都是一个渐进的过程，像今日头条尽管采用了火山引擎，但仍有一部分业务会在阿里云上运行。</p><p>&nbsp;</p><p></p><h4>云厂商的“下云费”</h4><p></p><p>&nbsp;</p><p>但是，无论选择下云还是多云，云厂商都设置了门槛，比如数据出口费。数据出口费针对的就是企业上传数据的云存储位置移动或转移，与云存储和计算费是分开的。也就是说企业上云畅通无阻，转移或离开云还要最后被“砍一刀”。</p><p>&nbsp;</p><p>有数据显示据，数据出口费用已经影响到34%的云存储使用企业。DHH就表示，他们下云的“出口费”在30万至 40万美元之间。</p><p>&nbsp;</p><p>谷歌云日前率先宣布取消了这笔费用，并抨击了这种做法：某些传统厂商利用本地软件垄断来创造云垄断，使用限制性许可的做法来锁定客户并扭曲竞争。具体方式包括限制客户的合作对象和合作方式；如果客户决定使用某竞争对手的云服务，则收取5 倍的费用；并限制必备软件与竞争对手云基础设施的互操作性等。</p><p>&nbsp;</p><p>“这些限制并没有什么技术基础，但可能会让客户的支出增加300%。”谷歌云平台主管Amit Zavery坦承，取消这些收费最终会让用户更容易转向竞争对手，但不公平的许可对市场竞争构成了更大的威胁。</p><p>&nbsp;</p><p>虽然谷歌这一决定背后肯定有其他利益考虑，但就像DHH说的：谁在乎！用户想要的只是自由上下云而已。</p><p></p><h2>结束语</h2><p></p><p>&nbsp;</p><p>如今，上云进程最快的就是互联网或者泛互联网的企业、国内有出海业务的企业、一些新的制造业如汽车。这些企业有一些特征：数据量大、业务创新快、高增长、有典型的互联网企业特征。云计算对这些企业来说价值巨大，因为他们能用非常低的资源保有成本应对未来高增长的业务预期。</p><p>&nbsp;</p><p>但根据受访专家估算，国内上云的进度应该是小于10%的，因为对很多企业，尤其传统企业来说，上云不会带来更多的价值。可以看如下的“价值公式”：</p><p>&nbsp;</p><p>新技术决策带来的价值= 新价值-旧价值-迁移成本</p><p>&nbsp;</p><p>很明显，IT设施的决策成本和迁移成本是巨大的，这种情况下要吸引这类型企业上云就要价值足够大，并且是数量级优势，否则打动不了企业作出重大的架构改变。只有精准命中痛点，企业才会义无反顾地上云。</p><p>&nbsp;</p><p>但现在云计算的种种问题确实还没有一个完美的解决方案，企业更多还是选择各种方式并存的策略。云技术还需要不断进行持续的迭代，这种迭代是多方面的，包括产品功能的不断完善、通过规模化优势优化成本等。</p><p>&nbsp;</p><p>未来，云厂商欠下的种种技术债势必是要还上的，而企业要做的上云功课也必须得补上。</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>采访嘉宾（按姓名首字母排序）：</p><p>&nbsp;</p><p>堵俊平，Datastrato 公司创始人兼CEO，Apache 软件基金会Member，LF AI &amp; DATA 基金会前主席，前华为云与计算开源总经理，前腾讯开源联盟主席。在云计算、大数据与人工智能、开源等领域有超过15年的研发和管理经验。</p><p>&nbsp;</p><p>董晓聪，作业帮基础架构负责人，阿里云MVP、腾讯云TVP。曾在百度、滴滴等公司负责架构和技术管理工作，擅长业务中台、技术中台、研发中台的搭建和迭代。2019年加入作业帮，主要负责架构研发、运维、DBA、安全等工作。主导完成作业帮技术体系的云原生重塑，全面推动公司在质量、效率、安全、成本等方面的建设。</p><p>&nbsp;</p><p>周新宇，AutoMQ 联合创始人 &amp; CTO，是 Apache 软件基⾦会成员，Apache RocketMQ 联合创始⼈ &amp; PMC 成员。目前致力于引领消息和流存储走向云原生时代，利用云的能力为 Kafka 带来十倍的成本优势，是云原生上云理念的倡导者。</p><p></p><p></p><blockquote>InfoQ&nbsp;2023&nbsp;年度技术盘点与展望专题重磅上线！与&nbsp;50+&nbsp;头部专家深度对话，探明&nbsp;AIGC&nbsp;创新浪潮下，重点领域技术演进脉络和行业落地思路，点击<a href=\"https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MjM5MDE0Mjc4MA==&amp;action=getalbum&amp;album_id=2717978015128879106&amp;scene=173&amp;subscene=227&amp;sessionid=1704178990&amp;enterid=1704178995&amp;from_msgid=2651192070&amp;from_itemidx=2&amp;count=3&amp;nolastread=1#wechat_redirect\">订阅</a>\"/<a href=\"https://www.infoq.cn/theme/229\">收藏</a>\"内容专题，更多精彩文章持续更新~另，InfoQ&nbsp;年度展望系列直播最后一场将于&nbsp;2024&nbsp;年&nbsp;1&nbsp;月&nbsp;22&nbsp;日开播，主题为《代码人生攻略：程序员们如何为自己编织一份明朗未来？》，我们邀请到了章文嵩、周爱民、李博源、陶建辉四位重量级大咖，通过分享各自的职业心得和技术洞察，帮助大家更好地为未来发展做好准备。关注&nbsp;InfoQ&nbsp;视频号，与行业技术大牛连麦~</blockquote><p></p>",
    "publish_time": "2024-01-19 16:19:32",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "谷歌“压力文化”有多可怕？18年工程技术总监被裁后吐槽：如释重负",
    "url": "https://www.infoq.cn/article/EGzAbY9EB2UD1sp5uJqo",
    "summary": "<p>上周，我们报道了谷歌的千人裁员。这次裁员中，2005年就加入谷歌的Ben Collins-Sussman也在其中，在此之前，他一直担任谷歌芝加哥办事处的工程现场总监。</p><p>&nbsp;</p><p>在十八年前加入谷歌时，Ben是芝加哥首批两名工程师之一。他将 Subversion 移植到谷歌可扩展 Bigtable 技术中，然后帮助编写并启动了<a href=\"https://en.wikipedia.org/wiki/Google_Developers#Google_Code\">Google Code 上的项目托管</a>\"，该项目截至 2016 年托管了数十万个开源项目。在管理 Google Code 后，Ben管理了两个不同的展示广告团队，然后管理了搜索服务团队团队负责谷歌搜索的整体延迟/速度，然后组建了一个研究工程生产力的研究团队。</p><p></p><p><img src=\"https://uploader.shimo.im/f/8lsoAYzjWUeriqnH.png!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDU2NTMxNzEsImZpbGVHVUlEIjoiZ08zb2Q1cmRWNWY3VllxRCIsImlhdCI6MTcwNTY1Mjg3MSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyNDM2MDc5MH0.fSzPZ3sXSy769F4_NwV-mQIV6g6Y9brDUAjj7LQ6ong\" /></p><p></p><p>2006年谷歌芝加哥办公室的三位软件工程元老，中间的是Ben Collins-Sussma</p><p>&nbsp;</p><p>被无情裁员后，Ben写了一篇简单的博客向大家说明了自己的心情。下面是他的分享，我们没有进行人称转换，第一人称可能大家更能体会到他的心情。</p><p>&nbsp;</p><p></p><h2>“离开谷歌的一些回答”</h2><p></p><p>&nbsp;</p><p>在收到谷歌裁员通知的那一刻，我就知道自己肯定会被各种问题淹没。为此，我整理出这份简短的常见问题解答，这样就不用反复向自己的亲朋好友做解释了。与此同时，我也希望这篇小文能让各位同行理解并从容面对一波又一波裁员浪潮。</p><p>&nbsp;</p><p></p><h4>发生甚么事了？</h4><p></p><p>&nbsp;</p><p>谷歌刚刚进行了又一轮大规模裁员。与我一道被“优化”的，还有其他数百名员工。其中很多人都为谷歌奉献多年，我本人的工龄就有18年之久！</p><p>&nbsp;</p><p></p><h4>完了！但为什么这事会落在你头上？</h4><p></p><p>&nbsp;</p><p>这事肯定不是针对我个人的，也不是我犯了什么错误。实际上，这一波波裁员全都没有什么针对性。谷歌似乎正在大搞降本增效，希望能够轻装上阵。作为一名工程技术总监，我“只”管理35名员工（远低于谷歌内部常规的80多人），所以上头可能觉得即使我不在，公司也能运转良好。</p><p>&nbsp;</p><p></p><h4>这不公平！你付出了那么多，谷歌怎么能这样对待老员工？</h4><p></p><p>&nbsp;</p><p>首先我们得意识到：谷歌不是一个人。这是一家由多个群体构成的大型组织，各群体分别遵循不同的流程、规则和文化。因此，把谷歌当作整体来讨论没有意义，无论是支持还是反对。毕竟这样的技术大厂根本没有统一的意志、责任感或者冗余判断。</p><p>&nbsp;</p><p></p><h4>你还好吗？这个坏消息没把你压垮吧？</h4><p></p><p>&nbsp;</p><p>我很好:-)&nbsp;随着去年第一波大规模裁员，谷歌的企业文化发生了重大转变，我也早有心理预期。最近几个月来，我一直在为这个越来越不可避免的时刻做准备——包括用充足的时间调整情绪、接受现实。如果一定要说，那我对被裁其实怀着一种复杂的情绪：</p><p>&nbsp;</p><p>几十年来，我参与了芝加哥工程技术办公室的建立，在开发者、广告和搜索部门都做出过贡献，也深深为此自豪；非常感激有机会与世界上最聪明、最具创造力的人们携手工作；有种如释重负的感觉，其实谷歌之内的“压力文化”和“高薪牢笼”冲突已经让我难以承受了。</p><p>&nbsp;</p><p></p><h4>接下来打算怎么办？</h4><p></p><p>&nbsp;</p><p>我见过一些长期任职的领导者在离开谷歌后迷失自我，不知该何去何从。好在我没有这种问题。</p><p>我有很多爱好和副业，所以能做的很多、面前的路也不少。但首先，我要好好享受自己推迟了很久的长假。在科技行业工作了25年多之后，我会拿出几个月时间好好调养和恢复！</p><p>&nbsp;</p><p>大家别急，随后我会陆续分享更多个人经历。第一是我自己在谷歌的职业经历，其二则是我如何看待谷歌文化随时间推移发生的变化。</p><p>&nbsp;</p><p>上面就是Ben分享的内容。有意思的是，在2005 年刚入职那年，在即将结束 Google 总部的第一周“noogler”培训时，Ben在给家人的邮件中，也记录了当时的心情。如今放在一起看，只让人感叹谷歌这18年发生变化是如此之大。以下是他的分享，我们依然选择第一人陈的视角来呈现。</p><p>&nbsp;</p><p></p><h2>“我在谷歌的第一周”</h2><p></p><p>&nbsp;</p><p>各位可能看过反乌托邦科幻小说，就是只要加入技术大厂就能衣食无忧、予取予求……而进不去的则身陷贫民窟，每日挣扎只求一餐饱饭。在谷歌的经历，就给了我强烈的既视感。</p><p>&nbsp;</p><p>注意：据我所知，接下来的所有内容都不涉及商业机密。这些事实要么在谷歌的公共网站上对外展示，要么可以通过访客或者旅行团队在谷歌园区内亲身感受。但无论如何，万一我哪天夜里突然消失了，那很可能是不慎发布了敏感内容……</p><p>&nbsp;</p><p>讲讲我在谷歌的首周培训。整个园区真的很大……山景城里有好几栋大型建筑，是由SGI在90年代初势头正盛时建造的。建筑群占地极大，如果不想步行穿越整个园区，也可以随时跳上电动滑板车或者平衡车加快行进速度。</p><p>&nbsp;</p><p>最能概括谷歌部门的字眼应该是“大学校园”。这里汇聚着数以千计的工程师，大家走来走去、分享想法，并在厅堂和大楼间随时驻足思考。总部设有三处独立的自助餐厅、带教练的健身房、游泳池、洗衣房等，而且全部免费。另外还有现场按摩师和汽车保养服务，收费也是极其低廉。</p><p>&nbsp;</p><p>大家可能听说过谷歌总部吃东西不要钱，这是真的：而且自助餐厅不仅不收费，出品也是质量一级棒。他们聘请了名厨，所以午餐和晚餐都堪称盛宴。下面来看我随机选取自上周四的午餐/晚餐菜单。（这里我们省略了16个菜色的介绍，感兴趣的朋友可以去看Ben博客）</p><p>&nbsp;</p><p>就是这么夸张！想象一下，每走几十米就能随手拿取新鲜水果、坚果、酸奶、糖果、薯条、零食、咖啡、茶、牛奶和多达27种碳酸饮料，而且这类迷你厨房全天开放。如果大家像我一样是个吃货，那如此丰富的食物供应简直要人老命。反正我吃起零食就停不下来。前几天，我刚刚因为吃得太多生了场病，之后被迫认真规划周内剩余的摄入量。</p><p>&nbsp;</p><p>我感觉自己就像一只饿久了的老鼠，突然被扔进了奶酪无限供应的库房……怪不得他们要在健身房里配私人教练！人们常说“一上大学胖十斤”，在谷歌可绝对不止。</p><p>&nbsp;</p><p>上周五我们还举行了一场大型户外烧烤，Food Network TV的同事们专门来拍摄了聚会现场和厨师们的表演。我给大家看看同事用手机拍下的照片：</p><p>&nbsp;</p><p></p><p><img src=\"https://uploader.shimo.im/f/9xOaQ7vpf8CcCLOw.png!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDU2NTMxNzEsImZpbGVHVUlEIjoiZ08zb2Q1cmRWNWY3VllxRCIsImlhdCI6MTcwNTY1Mjg3MSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyNDM2MDc5MH0.fSzPZ3sXSy769F4_NwV-mQIV6g6Y9brDUAjj7LQ6ong\" /></p><p></p><p>&nbsp;</p><p>吃的聊完了，下面咱们说说企业文化。</p><p>&nbsp;</p><p>大多数软件企业都是自上而下受管理层把控。那帮穿西装、打领带的家伙（营销人员和中层管理）跟客户交通，搞清楚对方想要什么，之后告知程序员该写什么，由此形成一条多层级控制链。很多程序员甚至坐在一起聊很久，都不知道对方到底在做什么。</p><p>&nbsp;</p><p>谷歌则正好相反：这里就像一所巨大的研究生院。半数程序员拥有博士学位，每个人都把这里当成学术研究乐园。虽然公司对外严格保密，但在内部却100%开放。每个人都有权知道其他人在做什么，每个人都能从事自己喜欢的项目。每隔一段时间，经理就会关注一下各种自发活动，从中收集创意并整理成产品设计报告。这是一家完全由程序员驱动的公司，真是太神奇了。我很享受同事们走到面前，询问我学的是什么专业。</p><p>&nbsp;</p><p>这里不单是鼓励个人实验和创新，而是要求每个人都参与实验和创新。每位程序员都需要把20%的工作时间投入到自发的个人项目当中。这样哪怕遇到不得了的危机，这慢慢积累起来的副业也能救自己一命。而且大家所熟知的几乎一切谷歌技术（包括谷歌地图、谷歌地球、Gmail等）都是某人20%项目的产物。</p><p>&nbsp;</p><p>不消说，在跟同事们交谈和求知的过程中，我也接触到诸多令人惊叹的技术。我对谷歌内部的开发演进速度颇感震惊……恐怕连五角大楼都跟不上这样的前进脚步！这里就是计算机科学研究的最前沿——注意，是最！谷歌向公众发布的每一项技术都首先在内部接受过严格测试，所以我花了一周时间测试大量前所未有且令人难以置信的成果，这怎么能让人不心潮澎湃。</p><p>&nbsp;</p><p>甚至谷歌IT部门的工作方式也同样特立独行。每栋办公楼里都有不少被称为“技术站”的小办公室，乍看上去就像电脑修理部。如果你的电脑出了问题，只需要把机箱搬到技术站并直接说明情况即可。他们通常会当场解决。如果需要硬件，直接申请就行。</p><p>&nbsp;</p><p>比如说“不好意思，我需要个新鼠标。”对方会回应“可以，想要哪种？”然后他们打开一个装满备用品的柜子。这里没有官僚习气、没有表格、没有工单，直接去领就好。办公用品也是如此……到处都是装满物资的柜子，而且永远堆得满满当当。只要愿意，你可以随时领取自己需要的东西。</p><p>&nbsp;</p><p>明天我将正式入驻芝加哥办公室，那边是销售部门的主场。尽管如此，技术站的同事还是告诉我，一台新的Linux电脑（带有两台24英寸平板显示器）已经安装就绪等待我的“宠幸”。他们还说，这是程序员们的标配。技术站还分配给我一个“ipass”，这是一款软件，我可以在全美几乎每家星巴克、咖啡厅、机场连接Wi-Fi热点——钱不用担心，谷歌付过了。</p><p>&nbsp;</p><p>总而言之，当一家企业的钱怎么都花不完的时候，大概也就是谷歌这样。我不知道这种乌托邦式的“不作恶”文化还能持续多久，毕竟财富创造权力、权力导致腐败。而我在谷歌这一周来看到的，几乎不能用权力形容——而是无比强大的权势。</p><p>&nbsp;</p><p>“愿你生活在有趣的时代。”</p><p>&nbsp;</p><p>以上就是Ben记录下的在谷歌第一周的感受。就如Ben说的，这个邮件内容似乎能让我们一睹硅谷“创意文化”巅峰时代的开端。从兴奋到无奈，似乎也是硅谷前后18年的叹息。</p><p>&nbsp;</p><p>Ben自 1995 年以来，一直在科技行业担任软件工程师和经理。这么多年，他进行了数十次演讲（其中许多可以<a href=\"http://www.youtube.com/playlist?list=PL1C8C35BCFF6C8A38\">在 youtube 上</a>\"观看），并参与撰写了 O'Reilly 的《<a href=\"https://www.amazon.com/Debugging-Teams-Productivity-through-Collaboration/dp/1491932058/\">调试团队：通过协作提高生产力》（</a>\"Debugging Teams: Better Productivity through Collaboration&nbsp;）一书。</p><p>&nbsp;</p><p>他的职业经历也影响了很多人。“Ben Collins-Sussman 的两次演讲彻底改变了我的职业道路，从一个头脑发热的程序员转变为像专业工程师一样思考。我每隔几年或在接受采访之前都会重新观看这些内容，让我回到正确的道路上。”有网友在 Hacker News 上留言。</p><p>&nbsp;</p><p></p><h2>谷歌，不再光鲜</h2><p></p><p>&nbsp;</p><p>作为全球知名的科技大厂，谷歌的形象近来似乎不再光鲜。</p><p>&nbsp;</p><p>早在去年四月，Ben提到的硬件不用申请直接换就不存在了，谷歌甚至暂停了笔记本电脑、台式电脑和显示屏的更换，之前设备更换频率也会调整。&nbsp;需要新笔记本电脑的谷歌员工开始用谷歌的Chromebook，而在这之前，员工们用的是Apple MacBook。</p><p>&nbsp;</p><p>而Ben的被裁员，既不是开始也不是结束。</p><p>&nbsp;</p><p>谷歌又宣布在YouTube方面计划精简100名员工。这是谷歌在八天之内第三次发布裁员公告（前两次分别针对Google Assistant/硬件部门和 Ads广告部门），也是过去12个月内谷歌方面的第10次裁员举措。一波波冲击之下，谷歌的裁员消息已经令人麻木。</p><p>&nbsp;</p><p>谷歌CEO桑达尔·皮查伊表示，预计后续还会有更多裁员。根据The Verge看到的皮查伊今年1月10日写给谷歌员工的内部备忘录，这位掌门人提醒大家为未来更多“艰难选择”做好准备，并表示“坦白讲，部分团队将在今年之内继续迎来针对性资源分配决策。”也就是说在必要时，将有更多职能岗位受到影响。</p><p>&nbsp;</p><p>值得注意的是，去年1月，谷歌宣布裁员1.2万人，并在年内持续进行多次小幅裁员。但当时皮查伊告诉员工们，今年“岗位裁撤的规模将小于去年，也不会触及所有团队。”</p><p>&nbsp;</p><p>这份备忘录的发布日期为1月10日，意味着谷歌员工已经知晓Google Assistant、硬件、Ads和YouTube等部门的裁员情况，唯一不确定的就是裁员何时才会停止。</p><p>&nbsp;</p><p>而之所以大刀阔斧推动精简，一大重要因素就是满足投资方的心理预期，毕竟华尔街一直认为谷歌公司人浮于事。早在2023年3月，TCI基金管理公司的激进派投资者Christopher Hohn就表示在1.2万裁员之后，皮查伊应该再砍掉2.5万个岗位。Hohn认为，Alphabet/谷歌的员工总数应该恢复到15万人左右，也就是该公司2021年底时的人员水平。</p><p>&nbsp;</p><p>而即使经历了去年一场场令人胆寒的岗位精简，截至2023年第三季度，Alphabet的员工人数仍为182381人。而且在裁员超1.2万的同时，谷歌期间仍在招聘员工，因此Alphabet的总体规模较裁员之前仅减少了4400人。</p><p>&nbsp;</p><p>另外，谷歌也新的人工智能争夺战中，也在采取一种特殊的方式来留住其顶尖的人工智能研究人员。据知情人士透露，谷歌旗下DeepMind部门的部分研究人员获得了高额的限制性股票奖励，该部门是谷歌最重要项目的核心。</p><p>&nbsp;</p><p></p><h2>结束语</h2><p></p><p>&nbsp;</p><p>多年以来，谷歌的一大优势就是提供理想的工作环境，包括无穷无尽的员工福利、允许人们将20%的工作时间投入到自己喜爱的项目中去，并大开脑洞设计自己的办公场所。可现如今一切已经不复存在，预算削减加上不啻于当头棒喝的开年裁员已经严重削弱了公司内本就低落的士气。</p><p>&nbsp;</p><p>这家科技巨头的创始人拉里·佩奇和谢尔盖·布林曾在写给华尔街的IPO申请信中写道，“我们的员工自称‘谷歌人’，他们就是谷歌的一切。”但佩奇和布林早就交出权柄，如今的谷歌已经不同于往日。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://social.clawhammer.net/blog/posts/2024-01-10-GoogleExitLetter/\">https://social.clawhammer.net/blog/posts/2024-01-10-GoogleExitLetter/</a>\"</p><p><a href=\"https://arstechnica.com/google/2024/01/google-ceo-sundar-pichai-promises-another-year-of-google-layoffs/\">https://arstechnica.com/google/2024/01/google-ceo-sundar-pichai-promises-another-year-of-google-layoffs/</a>\"</p><p><a href=\"https://social.clawhammer.net/blog/posts/2005-09-25-FirstWeekAtGoogle/\">https://social.clawhammer.net/blog/posts/2005-09-25-FirstWeekAtGoogle/</a>\"</p><p><a href=\"https://www.cnbc.com/2023/04/03/google-to-cut-down-on-employee-laptops-services-and-staplers-to-save.html\">https://www.cnbc.com/2023/04/03/google-to-cut-down-on-employee-laptops-services-and-staplers-to-save.html</a>\"</p>",
    "publish_time": "2024-01-19 16:29:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]