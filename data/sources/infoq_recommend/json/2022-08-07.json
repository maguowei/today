[
  {
    "title": "Spotify如何可视化系统架构图",
    "url": "https://www.infoq.cn/article/s5UwbP01ga8akJIFgtZV",
    "summary": "<p>Spotify的工程师最近分享了他们在公司内部是<a href=\"https://engineering.atspotify.com/2022/07/software-visualization-challenge-accepted/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NTk2NjUwNzMsImZpbGVHVUlEIjoiMUVnUXAxN0w4djBhMUtGQSIsImlhdCI6MTY1OTY2NDc3MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.I5M6urBb5jGHWotRP03JgwclL-LuyCmxC0zYVxl7GRE\">如何标准化架构图</a>\"的。他们定义了一种叫作<a href=\"https://backstage.io/docs/features/software-catalog/system-model?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NTk2NjUwNzMsImZpbGVHVUlEIjoiMUVnUXAxN0w4djBhMUtGQSIsImlhdCI6MTY1OTY2NDc3MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.I5M6urBb5jGHWotRP03JgwclL-LuyCmxC0zYVxl7GRE\">Spotify软件模型</a>\"的标准系统模型，并采用<a href=\"https://c4model.com/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NTk2NjUwNzMsImZpbGVHVUlEIjoiMUVnUXAxN0w4djBhMUtGQSIsImlhdCI6MTY1OTY2NDc3MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.I5M6urBb5jGHWotRP03JgwclL-LuyCmxC0zYVxl7GRE\">C4模型</a>\"来可视化它。这一组合创造了一种可在整个组织中使用的公共语言，有助于沟通、辅助决策，并为Spotify的软件开发提供支持。</p><p></p><p>Spotify高级工程师Renato Kalman和工程师Johan Wallin解释了创建这个框架的动机：</p><p></p><p></p><blockquote>架构图是软件设计的基本要素，也是软件开发中沟通和协作的基本工具。在Spotify，我们拥有一个非常复杂的应用程序网络，数百个团队开发的数千个相互关联的软件系统组成了这个复杂的网络，所以我们需要一种简单的方法来可视化这些复杂的连接。从技术上说，我们可能可以用一个大型的图表来捕获所有的系统，但它会非常难以理解和查看。为了做出好的设计决策，并以可持续的方式开发我们的软件，我们需要一些可以在不同的抽象级别上观察架构的工具。</blockquote><p></p><p></p><p>Spotify的工程师将软件组件的元数据保存在一个<a href=\"https://backstage.io/docs/features/software-catalog/software-catalog-overview?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NTk2NjUwNzMsImZpbGVHVUlEIjoiMUVnUXAxN0w4djBhMUtGQSIsImlhdCI6MTY1OTY2NDc3MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.I5M6urBb5jGHWotRP03JgwclL-LuyCmxC0zYVxl7GRE\">软件目录</a>\"中。为了支持标准的架构图，他们创建了Spotify系统模型，它包含了一组核心实体和抽象，Spotify工程师可以使用这些实体和抽象来合成有关软件健康状况、所有权和依赖关系的数据。Kalman和Wallin说：“我们相信，一门有关软件和资源的公共语言有助于促进沟通和协作，这对于我们这种规模的公司取得成功至关重要。”</p><p></p><p>C4模型是一种轻量级图形符号技术，用于建模软件系统的架构，由Simon Brown创建。它将系统分解为容器和组件。在Spotify，工程师们采用了C4模型符号及其最佳实践。不过，他们用Spotify系统模型取代了上下文、容器和组件的抽象层。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/news/2022/07/spotify-system-model-c4/en/resources/1Spotify-c4-overview-1658874293923.png\" /></p><p></p><p>C4模型，来源：<a href=\"https://c4model.com/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NTk2NjUwNzMsImZpbGVHVUlEIjoiMUVnUXAxN0w4djBhMUtGQSIsImlhdCI6MTY1OTY2NDc3MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.I5M6urBb5jGHWotRP03JgwclL-LuyCmxC0zYVxl7GRE\">https://c4model.com/</a>\"</p><p></p><p>Spotify使用<a href=\"https://backstage.io/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NTk2NjUwNzMsImZpbGVHVUlEIjoiMUVnUXAxN0w4djBhMUtGQSIsImlhdCI6MTY1OTY2NDc3MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.I5M6urBb5jGHWotRP03JgwclL-LuyCmxC0zYVxl7GRE\">Backstage</a>\"存储软件目录元数据。Backstage是一个开源平台，用于构建开发者门户网站。这个项目由Spotify推动，是CNCF的一个孵化器项目。他们利用Backstage的<a href=\"https://backstage.io/docs/plugins/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NTk2NjUwNzMsImZpbGVHVUlEIjoiMUVnUXAxN0w4djBhMUtGQSIsImlhdCI6MTY1OTY2NDc3MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.I5M6urBb5jGHWotRP03JgwclL-LuyCmxC0zYVxl7GRE\">可扩展性</a>\"创建了一个叫作Architecture的插件，这个插件可以根据存储在Backstage中的Spotify系统模型元数据生成C4图表。Kalman和Wallin说：“在Backstage中存储系统模型元数据对于组件发现、理解软件组件之间的生命周期、所有权和关系，以及自动生成软件可视化图都非常有帮助。”</p><p></p><p>Spotify系统模型由几个核心实体组成，包括表示软件组件之间边界的API、表示单个软件块的组件，以及运行时操作组件所需的基础设施资源。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/news/2022/07/spotify-system-model-c4/en/resources/1Spotify-figure-1-1658874293923.png\" /></p><p>核心实体之间的关系，来源：<a href=\"https://engineering.atspotify.com/2022/07/software-visualization-challenge-accepted/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NTk2NjUwNzMsImZpbGVHVUlEIjoiMUVnUXAxN0w4djBhMUtGQSIsImlhdCI6MTY1OTY2NDc3MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.I5M6urBb5jGHWotRP03JgwclL-LuyCmxC0zYVxl7GRE\">https://engineering.atspotify.com/2022/07/software-visualization-challenge-accepted/</a>\"</p><p></p><p>随着目录数量的增长，这些组件变得越来越难以理解、审查和相互关联。因此，他们引入了额外的抽象，有助于理解更广泛的软件生态系统。系统是协作执行某些功能的实体的集合，而领域是与部分业务相关的实体和系统的集合。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/news/2022/07/spotify-system-model-c4/en/resources/1Spotify-figure-2-1658874293923.png\" /></p><p></p><p>领域、系统与核心实体的关系，来源：<a href=\"https://engineering.atspotify.com/2022/07/software-visualization-challenge-accepted?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NTk2NjUwNzMsImZpbGVHVUlEIjoiMUVnUXAxN0w4djBhMUtGQSIsImlhdCI6MTY1OTY2NDc3MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.I5M6urBb5jGHWotRP03JgwclL-LuyCmxC0zYVxl7GRE\">https://engineering.atspotify.com/2022/07/software-visualization-challenge-accepted</a>\"</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/07/spotify-system-model-c4/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NTk2NjUwNzMsImZpbGVHVUlEIjoiMUVnUXAxN0w4djBhMUtGQSIsImlhdCI6MTY1OTY2NDc3MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.I5M6urBb5jGHWotRP03JgwclL-LuyCmxC0zYVxl7GRE\">The Spotify System Model: Automated Architecture Visualization at Spotify</a>\"</p><p></p>",
    "publish_time": "2022-08-07 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "12年后，树模型ABC-Boost 终于开源，精度超过 XGBoost、LightGBM",
    "url": "https://www.infoq.cn/article/jClFot7JFcKF4Ff7NoKl",
    "summary": "<p></p><p>近期，前百度研究院副院长李平等人开源了多年的研究成果 Fast ABC-Boost 机器学习包。</p><p></p><p>开源代码连接：<a href=\"https://github.com/pltrees/abcboost\">https://github.com/pltrees/abcboost</a>\"</p><p></p><p>据悉，该研究十多年前就已经开始，2010 年，李平发表了题为“Robust LogitBoost and Adaptive Base Class (ABC) LogitBoost”的论文，2018 年的图灵奖得主 Yoshua Bengio 当时还与人讨论了李平在树模型和 boosting 上的工作。</p><p></p><p>根据介绍，李平在 2007 年斯坦福大学博士毕业后，曾在任康奈尔大学和后罗格斯大学任教，并于 2013 年成为计算机系和统计系两系的终身教授。其主要研究方向是算法学习、高效检索、机器存储、数据流和推荐等，曾获得 NIPS2014 最佳论文奖、ASONAM2014 最佳论文奖、KDD2006 最佳论文奖，以及美国空军和青年科学家奖（AFOSR-YIP）、美国海军杰出数据科学家奖（ONR-YIP）等奖项。</p><p></p><p>2020 年 1 月，李平开始担任百度研究院副院长，其团队与百度的凤巢广告、Feed 流、搜索、百度知道、中文输入法、百度地图等业务部门展开合作，把研究成果应用到各项产品中。</p><p></p><p>在 Fast ABC-Boost 开源后，李平表示：“这个工作太实用了，本身影响力是巨大的，只不过有点可惜绝大部分使用者不会知道（也未必关心）原作者是谁。不过回想起来，我自己并没有太去关心已经完成的工作，而是把精力放在做完全不同的新研究。这样反而收获更大。”</p><p></p><p>根据介绍，Fast ABC-Boost 的精度超过了经典的 XGBoost、LightGBM。本文将对这项研究工作进行详细解读。</p><p></p><p></p><h3>概览</h3><p></p><p></p><p>“Fast ABC-Boost”软件包是作者在康奈尔大学、罗格斯大学和百度研究院十多年工作的成果。下面是作者在康奈尔大学和罗格斯大学的课堂授课稿件：</p><p></p><p>• <a href=\"http://statistics.rutgers.edu/home/pingli/STSCI6520/Lecture/ABC-LogitBoost.pdf\">http://statistics.rutgers.edu/home/pingli/STSCI6520/Lecture/ABC-LogitBoost.pdf</a>\"</p><p></p><p>• <a href=\"http://www.stat.rutgers.edu/home/pingli/doc/PingLiTutorial.pdf\">http://www.stat.rutgers.edu/home/pingli/doc/PingLiTutorial.pdf</a>\" (pages 15–77)</p><p></p><p>一些机器学习研究人员可能仍然记得在 2010 年 <a href=\"https://hunch.net/?p=1467\">https://hunch.net/?p=1467</a>\" 论坛上的一些讨论。在“Robust logitboost and adaptive base class (abc) logitboost”（2010 年，by Li）论文中，“Robust LogitBoost”和“Adaptive Base Class Boost”被作者提出来了。当时，研究人员很好奇，在深度学习研究人员开发的数据集上，增强树算法（boosted trees） 与深度神经网络相比，为什么还是非常有效。</p><p></p><p>自那次讨论以来，已经过去了十年。不必多说，深度神经网络在许多研究和实践领域取得了巨大的成功。在作者开发了这些增强树算法之后，比如：“Learning to rank using multiple classification and gradient boosting”论文（作者等人，2007）、“Adaptive base class boost for multi-class classification”论文（作者等人，2008）、“ABC-Boost: Adaptive base class boost for multi-class classification”论文（作者等人，2009）、“ Fast abc-boost for multi-class classification”论文（作者等人，2010a）、“Robust logitboost and adaptive base class (abc) logitboost”论文（作者等人，2010b）。他精力转移到其他许多有趣的研究课题，包括随机素描（randomized sketching）、哈希方法（例如，Li and Zhao ，2022b）、近似近邻搜索和神经网络排序（例如，Tan 等人，2021）、深度神经网络和近似近邻搜索广告（例如，Fan 等人,2019 ；Fei 等人，2021 ）、大规模 CTR 模型的 GPU 架构（例如，Zhao 等人，2022a）、另见媒体报道 (www.nextplatform.com/2021/06/25/a-look-at-baidus-industrial-scale-gpu-training-architecture）、广告 CTR 模型压缩（例如，Xu 等人，2021 ）、AI 模型安全（例如，Zhao 等人，2022b）、隐私、理论等，以及机器学习在自然语言处理、知识图和视觉中的应用。</p><p></p><p>尽管，深度神经网络取得了广泛的成功，但作者发现增强树算法在实践中仍然非常有用，例如搜索结果排名、股价预测、金融风险模型等。例如，作者在百度的输入法编辑器（IME）使用了增强树算法，并在手机上部署了树模型（Wang 等人，2020）。根据作者自己的经验，发现增强树算法非常适合具有少于 10000 个特征和少于一亿个训练样本的预测任务。对于使用具有数千亿训练样本的极高维稀疏数据的应用（例如广告 CTR 预估），通常深度神经网络更方便或更有效。</p><p></p><p>正如最近一篇关于决策树综述的论文（Fan 和 Li，2020）所总结的那样，在过去 15 年左右的时间里，多种实现技术提升了增强树算法的精度和效率，包括:</p><p></p><p>与基于仅使用一阶增益信息相比，使用二阶增益信息公式的树分裂实现（李，2010b）（即“Robust LogitBoost”）通常可以提升精确度（Friedman，2001）。它现在是流行的树模型平台中的标准实现。李等人（2007）提出的自适应分箱策略有效地将特征值转换为整数值，大大简化了实现，并提高了树模型的效率。分箱技术也是流行树模型平台的标准实现。用于多分类的“adaptive base class boost”（ABC-boost）模式（Li，2008，2009，2010a，b；Li and Zhao，2022a）通过重写经典多分类逻辑回归损失函数的导数，在许多情况下可以大大提高多分类任务的准确性。开源软件包 <a href=\"https://github.com/pltrees/abcboost%EF%BC%8C\">https://github.com/pltrees/abcboost，</a>\" 包括：帮助用户安装软件包并将其用于回归、分类和排序的文档。作者将回归和分类结果与两种流行的增强树模型平台，即 LightGBM 和 XGBoost 进行了比较，并注意到在准确性方面存在一些差异。这一观察结果很有趣（也可能令人困惑），因为他们基本上实现了相同的算法：（i）训练前的特征分箱（直方图构建），如李等人（2007 年）所述；和（ii）李（2010b）中推导的树分裂的二阶增益信息公式。同一算法的实现如何输出明显不同的结果？</p><p></p><p>作者意识到这种差异可能是由于在实现特征分箱过程中的差异造成的。李等人（2007）设计了一种过于简单的定长分箱方法，而 LightGBM 和 XGBoost 似乎使用了更精细的处理。也许与直觉相反，实验表明，李等人（2007）中非常简单的分箱方法在测试的数据集上产生了更准确的结果。</p><p></p><p>因此，在本报告中，首先描述了 ABC-Boost 包中使用的简单分箱方法，然后演示了如何使用 ABC-Boost 进行回归、二分类和多分类任务。对于每项任务，作者还报告了基于 2022 年 6 月最新版本的 LightGBM 和 XGBoost 的实验结果。</p><p></p><p></p><h3>特征预处理固定长度的分箱方法</h3><p></p><p></p><p>回归树（Brieman 等人，1983）是分类、回归和排序任务的基础构建模块。树的思想是基于一些“增益”标准以轴对齐的方式递归划分数据点，并报告最终（子划分）区域中数据点的平均（或加权平均）响应作为预测值。子划分的区域作为一个树来组织或者查看，叶节点对应于最终的子划分区域。</p><p></p><p>因此，一项关键任务是计算每个特征的最佳分割点，并通过将当前节点中的数据点分成两部分来选择最佳特征（即增益最大的特征）来进行实际分割。该过程递归继续，直到满足某些停止标准。在李等人（2007）之前，典型的树实现首先根据特征值对每个维度的数据点进行排序，并需要在分割后跟踪数据点。如图 1 所示，李等人（2007）首先将特征值量化（分箱）为整数，然后按照自然顺序排序。这个技巧大大简化了实现。如果分箱总数不太大，可以使程序更高效。图 1 中的分箱也适用于数据分布，因为它仅在有数据的地方分配分箱值。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/54/54a181cb3a0d2e54093f8c30e6c6fe85.png\" /></p><p></p><p>如以下 matlab 代码所示，分箱方法非常简单：首先从非常小的初始分箱长度开始（例如，10^−10） ，预先指定最大的分箱参数，比如 128 或者 1024。对于每个特征，根据特征值对数据点进行排序。将分箱编号从最小到最大分配给数据点，只要有数据点，就一直分配，直到所需的分箱数量超过 MaxBin。然后通过加倍分箱长度来重新开始。</p><p></p><p>这种分箱程序有许多明显的优点。它非常简单，易于实现。它自适应数据分布。此处理不会影响已排序类别变量的特征。这种处理的缺点也很明显。它绝不是任何意义上的“最优”算法，作者期望它可以在许多方面得到改进。例如，使用固定长度时，如果 MaxBin 设置得太小（如，10），可能会看到较差的精度。另一方面，如果 MaxBin 设置得太小，树算法本身将无法很好地工作。如本报告后面的实验所示，这种极其简单的分箱方法对树表现非常好。作者提供了 matlab 代码，以帮助读者更好地理解该过程，并帮助研究人员改进其分箱算法（和树算法平台）。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b9/b9b90868f23a3a3cb7a4f49dfd8e5ca7.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/51/5114a967e3ee0a9e017c5df6eabc2ffb.png\" /></p><p></p><p>总之，这种看似非常简单（固定长度）的分箱算法能适用于增强树方法，可能有两个主要原因：</p><p></p><p>对于增强树，允许的最大分箱数（即 MaxBin 参数）无论如何都不应太小。如果数据量化过粗，将丢失太多信息。对于如此多的分箱（例如，MaxBin=1000），就增强树的精度而言，改进这种固定长度策略可能并不那么容易。不应该期望所有特征都使用相同数量的分箱。通常，在一个数据集中，特征可能会有很大差异。例如，一些特征可能是二值的（即，使用 MaxBin=1000 也只能生成两个值），一些特征可能只有 100 个不同的值（即，使用 MaxBin=1000 仍最多只能生成 100 个值），而一些特征确实需要更多的量化级别。因此，参数 MaxBin 只是一个粗略的准则。根据给定的 MaxBin 过于努力地“优化”分箱过程可能会适得其反。</p><p></p><p>实际上，作者建议将 MaxBin=100（或 128）设置为开始点。如果精度不令人满意，可以逐渐将其增加到 MaxBin=1000（或 1024）。根据作者的经验，当 MaxBin 大于 1000 时，很难观察到明显更好的精度。</p><p></p><p>在接下来的三节中，将介绍使用 Fast ABC-Boost 软件包进行回归、二分类和多分类的实验结果。通过将 MaxBin 从 10 更改为 10^4，将结果与 LightGBM 和 XGBoost 进行比较，以说明 MaxBin 对精度的影响。此外，作者观察到，一旦启用多线程，结果变得不确定，尽管随机变化通常不会太大。为了严格确保确定性结果（用于清晰的比较），作者将所有实验作为单线程运行。</p><p></p><p></p><h3>Lp 回归</h3><p></p><p></p><p>读者请参阅关于 Lp 增强回归的详细报告（Li and Zhao，2022c）。一个训练数据集{yi，xi}(i=1,n)，其中 n 是样本数，xi 是第 i 个特征，yi 是第 i 个标签。Lp 回归的目标是建立模型 F（x），以最小化 Lp 损失：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/fa/fa2c463faa17eca01ece6cb57f75e00e.png\" /></p><p></p><p>使用“加法模型”（Friedman 等人，2000；Friedman，2001），假设 F 是 M 项的总和：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/28/287c117dc85fd93cac1b2bb7b186cd0a.png\" /></p><p></p><p>其中，基学习器 fm(x) 是一棵回归树，以分段贪婪的方式从数据中学习。根据 Friedman 等人（2000）的想法，在每次增强迭代中，通过加权最小二乘法拟合 fm，响应值{zi}和权重{wi}：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/60/6050278049b467c51070922c36ea0591.png\" /></p><p></p><p>李（2010b）推导了使用响应值{zi}和权重{wi}建立回归树时，确定分裂位置所需的相应增益公式。历史上，基于加权最小二乘法的增强方法被认为存在数值问题（Friedman 等人，2000，2008），因此后来 Friedman（2001）提出仅使用一阶导数拟合树，即，</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/87/87f213467f087d7e64409426969e8744.png\" /></p><p></p><p>现在很清楚，如李（2010b）所示，可以推导出使用二阶信息计算增益的显式的和数值稳定 / 鲁棒的公式。</p><p></p><p></p><h4>基于二阶信息的树分裂准则</h4><p></p><p></p><p>考虑一个具有 N 个数据点和一个特定特征的树节点。权重 wi 和响应值 zi，i=1 到 N。已经根据特征值的排序顺序对数据点进行了排序。树分裂过程是查找索引 s，1≤ s<=\"\" p=\"\"></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/99/99cd1b89d69ec91ddc29f051a378195d.png\" /></p><p></p><p>这个过程在数值上是鲁棒、稳定的，因为，不需要直接计算响应值 zi=-Li’//Li’’，它可以（并且应该）很容易地接近无穷大。由于原始 LogitBoost（Friedman 等人，2000）使用了单个响应值 zi=-Li’//Li’’，因此该过程被认为存在数值问题，这是 Friedman（2001）仅使用一阶导数构建树的动机之一。因此增益公式成为:</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/40/40c61101253332cf955819bdf6439dbf.png\" /></p><p></p><p></p><h4>Lp 增强算法</h4><p></p><p></p><p>算法 1 描述了 Lp 增强回归树使用的分裂增益公式（7）（对于 p≥ 2） 或树分裂增益公式（8）（对于 1≤ p&lt;2）。注意，在构建树之后，终端节点的值通过以下公式计算：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/57/57428f36b887145d2b6def0a565a0660.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/36/3660d02c4b13fe13fd670a8a8a0a64ee.png\" /></p><p></p><p>这解释了算法 1 的第 5 行。当 1≤ p&lt;2，作者遵循 Friedman（2001），使用一阶导数建立具有分裂增益公式（8）的树，并将终端节点更新为</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/43/436ce7d79504ab104d67d0b3a9db8b3a.png\" /></p><p></p><p></p><h4>实验</h4><p></p><p></p><p>遵循 <a href=\"https://github.com/pltrees/abcboost\">https://github.com/pltrees/abcboost</a>\" 上的说明，用户可以安装 Fast ABC-Boost 软件包。假设可执行文件位于当前目录，数据集位于“data/”目录。“comp-cpu”数据集有 libsvm 和 csv 两种格式，有 4096 个训练样本和 4096 个测试样本。在终端，执行以下命令</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/19/19843806989904a3855877a7598be3b9.png\" /></p><p></p><p>建立一个 L2 回归增强模型，J=20 个叶节点，ν=0.1 收缩率，最多迭代 10000 次。最大分箱数（MaxBin）设置为 1000。作者采用保守的早期停止标准，在 Lp 损失低于以下值后让程序退出</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a4/a4a7dfe3c9218b1701634e7368c31956.png\" /></p><p></p><p>其中ε默认为 10^5。在本例中，程序在 933 次迭代后退出（而不是 10000 次迭代）。在训练后，将在当前目录中创建两个文件：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/8c/8c9ed99dcd80e1809f60433d45009737.png\" /></p><p></p><p>为了在测试数据集上测试训练后的模型，运行</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/03/037c0e4109d9157a5be923384ceb2799.png\" /></p><p></p><p>它会生成另外两个（文本）文件来存储测试结果：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/02/021679d7a22dabc0387d7e145bd594a2.png\" /></p><p></p><p>.testlog 文件记录了测试损失和其他信息。“.prediction”存储最终（或指定）迭代中所有测试样本的回归预测值。</p><p></p><p>用参数 J∈ {6, 10, 20}, ν ∈ {0.06，0.1，0.2}，p 从 1 到 10，MaxBin 从 10 到 10^4 进行实验。图 2 绘制了每个 MaxBin 值的最佳（在所有参数和迭代中）测试 MSE。在每个面板上，实心曲线绘制 L2 回归的最佳测试 MSE 和 Lp 回归的虚线曲线（在最佳 p 处）。右面板是左面板的放大版本，重点放在 100 到 10^4 的 MaxBin 上。对于这个数据集，使用 MaxBin=1000 可以获得很好的结果，而使用较大的 MaxBin 值不会产生更好的结果。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/df/df991d98f5c635a90aee67b3316a6030.png\" /></p><p></p><p>图 3 绘制了所有三个包的 L2 回归的最佳测试 MSEs：ABC-Boost（L2）、XGBoost 和 LightGBM，MaxBin 范围为 10 到 10^4。同样，右面板只是左面板的放大版本。当然，如图 2 所示，ABC-Boost 将能够通过使用 p≠2 的 Lp 回归实现更低的 MSE。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/11/115f614b41add7a0c89b8c9d02b4aa69.png\" /></p><p></p><p>最后，图 4 绘制了所有迭代的测试 L2 MSEs，在一组特定的参数 J、ν和 MaxBin 下。注意，ABC-Boost 包在等式（9）中设置了保守停止标准。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/18/18e052c87124c7e39f5d34e9d9dbc452.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/89/892f5ad7f2671e83768095d379640994.png\" /></p><p></p><p></p><h3>使用鲁棒 LogitBoost 分类</h3><p></p><p></p><p>同样，用{yi，xi}(i=1,n) 表示训练数据集，其中 n 是训练样本数，xi 是第 i 个特征向量，yi∈ {0，1，2，…，K− 1} 是第 i 类标签，其中 K=2 表示二分类，K≥ 3 表示多类分类。假设类概率 p(i,k) 为</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ef/efc938fbf4321ad5633dfc9fddbac8b9.png\" /></p><p></p><p>其中 F 是 M 项的函数：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5b/5bf1fe49cb7fc461633b16776f1dcb6a.png\" /></p><p></p><p>其中，基学习器 fm 是一棵回归树，通过最小化负对数似然损失进行训练：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b2/b2b62be1bc3d6eb406d5479789d748ef.png\" /></p><p></p><p>其中，如果 yi=k，则 r(i,k)=1，否则，则 r(i,k)=0。优化过程需要损失函数（12）的前两个导数，分别对应于函数值 F(i,k)，如下所示：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ca/ca216884503d307b7a5ce3529508128f.png\" /></p><p></p><p>这些是教科书中的标准结果。</p><p></p><p></p><h4>基于二阶信息的树分裂准则</h4><p></p><p></p><p>再次，考虑具有 N 个权重 wi 和 N 个响应值 zi，i=1 到 N 的节点，假设其根据相应特征值的排序顺序排序。树分裂过程寻求 t 最大化</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/2a/2a385af707e00df842c146196981c0bc.png\" /></p><p></p><p>因为计算涉及∑p(i,k)（1− p(i,k) 作为一个组，该程序在数值上是鲁棒、稳定的。这解决了 Friedman 等人（2000）的担忧；Friedman（2001）；Friedman 等人（2008 年）。相比之下，MART（Friedman，2001）使用一阶导数来构造树，即，</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/95/9511b4acd41eda66b4b2a38bea135cb3.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d8/d8f680b90ff7f9fad0e70b2053817298.png\" /></p><p></p><p>算法 2 使用等式（14）中的树分裂增益公式描述鲁棒的 LogitBoost。注意，在构建树之后，终端节点的值通过以下公式计算：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/21/21d2cc469563201abbbe6074af8edf88.png\" /></p><p></p><p>这解释了算法 2 的第 5 行。对于 MART（Friedman，2001），该算法几乎与算法 2 相同，除了第 4 行，MART 使用树分裂增益公式，等式（15）。</p><p></p><p>注意，对于二分类（即 K=2），只需要在每次迭代中构建一棵树。</p><p></p><p></p><h4>二分类实验</h4><p></p><p></p><p>二分类数据集“ijcnn1”包含 49990 个训练样本和 91701 个测试样本，可在 <a href=\"https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/dataset/binary.html\">https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/dataset/binary.html</a>\" 查看。这个在一次比赛中使用了该数据集，获得冠军的是 LIBSVM（核 SVM），测试误差为 1293 个（在 91701 个测试样本中）。</p><p></p><p>再次在终端发出以下命令</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/fb/fb115bfa6378649f95943e094bdbcd02.png\" /></p><p></p><p>使用 J=20 个叶节点、ν=0.1 收缩率和 M=10000 次迭代，MaxBin=1000，使用“鲁棒 LogitBoost”算法训练二分类模型。创建两个文件：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ce/ce3c38fb99dfca33068a0192b9d69bdf.png\" /></p><p></p><p>打印出“.trainlog”文件的前 3 行和后 3 行：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5c/5c2ce7585c40ff769ff72e1a332790ce.png\" /></p><p></p><p>其中第二列是训练损失，第三列是训练误差。同样，为了确保输出确定性结果，使用单线程训练所有场景。在这里，作者想强调的是，由于潜在的有利随机效应，多线程程序可能输出更好（但不确定）的结果。</p><p></p><p>下一个命令</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ef/ef7e11a7b0d13fd7b696a7278f2cc5e1.png\" /></p><p></p><p>输出测试结果</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b2/b2eb19585ae812e4974de6d73ab9d2a4.png\" /></p><p></p><p>.testlog 文件的最后 10 行如下所示：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3d/3df425ded2fd63925e56ce9b08263ba7.png\" /></p><p></p><p>其中第三列记录了测试错误。回想一下，LIBSVM 的最佳结果是 1293。注意，在 Li（2010b）的附录中，也给出了在 ijcnn1 数据集上的实验结果。</p><p></p><p>图 5 绘制了最佳测试误差，以比较 J∈ {10, 20}的鲁棒 LogitBoost 和 MART, ν ∈ {0.06，0.1}，M=10000。给出了关于 MaxBin（最大分箱数）的结果，以说明分箱对分类错误的影响。事实上，当 MaxBin 设置为小于 100 时，在该软件包中实现的简单固定长度分箱算法的精度并不好。同样，这是意料之中的。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/fe/fe8f7ff240fc45ee9a4ac28c933da938.png\" /></p><p></p><p>图 6 在相同的 MaxBin 值下比较了鲁棒 LogitBoost 与 XGBoost 和 LightGBM。显然，当 MaxBin 设置为小于 100 时，在作者的包中实现的简单固定长度分箱方法的精度并不好。另一方面，在选择远大于 100 的 MaxBin 处获得最佳（最低）误差（事实上，该数据集为 2000）。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/88/88d25e28623d6708bc1699ce5d720f9b.png\" /></p><p></p><p>虽然，确实希望有相当大的空间来改进简单（固定长度）的分箱算法，但作者也承认，在使用这种分箱方案大约 15 年后，还没有找到一种普遍（或非常）好的算法。</p><p></p><p>最后，在图 7 中，绘制了每组参数（J，ν，MaxBin）的所有 M=10000 次迭代的测试误差历史，以比较 RobustLogitBoost 与 XGBoost 和 LightGBM。希望从图中可以清楚地看出，从业者可能希望重新回顾这个简单的分箱方法，以进一步更好地理解为什么它工作得如此好，并进一步提高其精度。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/16/161fc81926cb82652e3a02eb41dfa2f5.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/be/be91e63e52b3aefe300c7a48e9419cbc.png\" /></p><p></p><p></p><h3>用于多分类的 ABC-Boost</h3><p></p><p></p><p>“自适应基类增强”（ABC-Boost）的思想起源于（Li，2008），其中将多类逻辑回归的经典（教科书）导数重写为：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/8e/8e55f5df0a305287cefb8d73b394d684.png\" /></p><p></p><p>这里，记作，</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ab/abb90d37220d964f7ffad01713322b82.png\" /></p><p></p><p>在上面，假设类 0 是“基类”，并对 Fi 值使用“sum-to-zero”约束。在实际实现中，需要在每次迭代中识别基类。</p><p></p><p>如 Li（2009，2010b）所示，“穷举搜索”策略在准确性方面效果良好，但效率极低。Li（2008）的未发表技术报告提出了“worst-class”搜索策略，而 Li（2010a）的另一份未发表报告提出了“gap”策略。最近，Li 和 Zhao（2022a）通过引入三个参数开发了一个统一的框架来实现“快速 ABC-Boost”：（i）“搜索”参数 s 限制了对 s-worst 类中基类的搜索。（ii）“gap”参数 g 表示仅在每个 g+1 迭代中进行基类搜索。（iii）最后“预热”参数 w 指定搜索仅在为 w 迭代训练了鲁棒 LogitBoost 或 MART 之后开始。</p><p></p><p>算法 3 总结了快速 ABC-Boost 的统一框架。虽然它引入了其他参数（s、g、w），但好消息是，在大多数情况下，精度对这些参数并不敏感。事实上，Li（2008）最初提出的“worst-class”策略已经非常有效，尽管在某些情况下可能会导致“灾难性失败”。在某种意义上，引入这些参数（s、g、w）主要是为了避免“灾难性失败”。</p><p></p><p>在算法 3 中，ABC-RobustLogitBoost 中树分裂的增益公式类似于（14）：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/20/20363cafb072e4ffa7147ade52124534.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/60/60abd3c953c0599e50a9632db6cd035d.png\" /></p><p></p><p>使用 UCI“covtype”数据集进行演示。该数据集包含 581012 个样本，将其分为一半用于训练 / 测试。这是一个 7 个类的分类问题。在实验中，假设 J=20，ν=0.1，M=1000。执行以下命令：</p><p></p><p>./abcboost_train -method abcrobustlogit -data data/covtype.train.csv -J 20 -v 0.1 -iter 1000 -search 2 -gap 10 ./abcboost_predict -data data/covtype.test.csv -model covtype.train.csv_abcrobustlogit2g10_J20_v0.1_w0.model</p><p></p><p>训练并测试 s=2 和 g=10 的“ABC RobustLogitBoost”。当然，也可以像算法 2 那样训练规则的鲁棒 LogitBoost。图 8 比较了四种不同方法的测试误差：Robust LogitBoost、ABC Robust LogitBoost、XGBoost 和 LightGBM，用于分箱参数 MaxBin 从 10 到 10^4。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/09/098219d47843c6c42fc837d9b8d5fdca.png\" /></p><p></p><p>图 8 显示，当 MaxBin=10 时，在作者的包中实现的简单固定长度分箱方案表现不佳。这是意料之中的。对于这个多分类任务，很明显，“ABC 鲁棒 LogitBoost”大大改进了“鲁棒 LogitBoost”。</p><p></p><p>最后，图 9 绘制了四种方法的测试误差历史。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/45/45f6e7f51b3ecbb23c795afc086e4c57.png\" /></p><p></p><p></p><h3>结论</h3><p></p><p></p><p>十年前（或更早），作者完成了 Li 等人（2007）在增强技术和树模型方面的贡献；Li（2008、2009、2010a、b），这产生了很多有趣讨论（参见示例讨论）<a href=\"https://hunch.net/?p=14672010\">https://hunch.net/?p=14672010</a>\" 年），并推动了使用（i）特征组合的流行增强树平台的开发；（ii）树分裂的二阶增益公式，作为标准实现。然后，作者将兴趣转移到其他主题，包括深度神经网络和商业搜索引擎的计算广告；虽然作者在商业广告应用中广泛使用深度神经网络，但增强树在工业中仍然非常流行。作者自己的“经验法则”是，如果应用程序具有少于 10000 个（手工制作或预生成的）特征和少于一亿个训练样本，则应首先尝试增强树。</p><p></p><p>注意到，“自适应基类提升”（ABC boost）尚未成为流行的提升树平台的一部分。这可能是因为在正式发表的论文（Li，2009，2010b）中，作者只报告了计算成本高昂的穷举搜索策略，这可能会阻止从业者尝试 ABC-Boost。因此，作者决定发布“快速 ABC-Boost”，这实际上是 Li 和 Zhao（2022a）总结的过去 15 年努力的结果。</p><p></p><p>最后，值得一提的是，在作者所有关于增强技术和树模型的论文中，包括 Li 等人（2007），在实现过程中，始终使用“最佳优先”的树生长策略。Li 是在 2000 年初参加弗里德曼教授的课堂（并担任他的助教）时产生这个想法的。见本教程第 76-77 页 <a href=\"http://www.stat.rutgers.edu/home/pingli/doc/PingLiTutorial.pdf%E3%80%82%E8%BF%99%E6%98%AF%E4%BD%9C%E8%80%85%E5%9C%A8%E5%BA%B7%E5%A5%88%E5%B0%94%E5%A4%A7%E5%AD%A6%E5%92%8C%E7%BD%97%E6%A0%BC%E6%96%AF%E5%A4%A7%E5%AD%A6%E5%B7%A5%E4%BD%9C%E6%9C%9F%E9%97%B4%E7%BC%96%E8%AF%91%E7%9A%84%E8%AF%BE%E4%BB%B6%E3%80%82\">http://www.stat.rutgers.edu/home/pingli/doc/PingLiTutorial.pdf。这是作者在康奈尔大学和罗格斯大学工作期间编译的课件。</a>\"</p><p></p><p>论文原文链接：</p><p><a href=\"https://arxiv.org/pdf/2207.08770.pdf\">https://arxiv.org/pdf/2207.08770.pdf</a>\"</p><p></p><p>开源代码连接：</p><p><a href=\"https://github.com/pltrees/abcboost\">https://github.com/pltrees/abcboost</a>\"</p><p></p><p></p>",
    "publish_time": "2022-08-07 19:55:14",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "饿了么将与万达合作推出NFT数字藏品；快手成立独立to B业务部门；郭台铭回应遭虚拟货币诈骗广告冒用照片｜区块链周报",
    "url": "https://www.infoq.cn/article/eTf1mV5ZzkPyxXHXPZYb",
    "summary": "<p></p><blockquote>区块链周报栏目从产业动态、监管和技术等方面，为您总结了本周区块链领域发生的头条事件，让您更快速了解行业最新动态。更多信息关注公众号：区块链前哨（ID：blockchain-666）</blockquote><p></p><p></p><h2>企业动态</h2><p></p><p></p><h4>“二舅币崩盘”登顶热搜榜，发行人被质疑诈骗130万美金后跑路</h4><p></p><p></p><p>近日，一则视频《回村三天，二舅治好了我的精神内耗》火爆全网，紧接着一款名为二舅币（second uncle coin，简称SUC）的虚拟货币发行了。昵称为“second uncle dao”的用户在国外社交网站发文称，一群旨在帮助二舅的爱心人士发起了second uncle dao，通过区块链将爱心传递，营销钱包将全部捐赠给二舅，依靠大家的力量为二舅的养老提供保障，让二舅的生活不再有遗憾。该用户并在推文最后附上了该虚拟货币的合约地址。</p><p></p><p>7月28日晚，一名昵称为WhoCareNews的网友发文质疑二舅币，称二舅币池发生了Rugpull(拉地毯)，发起人已经清洗赃款，卷走了130万美元，相当于近877万元人民币。目前代币SUC价格仅为0.0000000004682美元，价格已下跌99.7%。</p><p></p><p>但很快second uncle dao回应相关跑路言论，称：“团队未曾Rugpull，也没有撤池子，所谓的专家推特在哪里，能否指路一下”。7月31日中午，“二舅币崩盘”的词条一度冲上热搜榜榜首位置，引起网友关注。目前，该数字货币交易网站已无法通过内部搜索的方式查询到second uncle coin二舅币，但仍可通过谷歌浏览器直达相关界面。</p><p></p><h4>快手成立独立to B业务部门，将发布StreamLake品牌</h4><p></p><p></p><p>据悉，快手宣布将于8月10日召开StreamLake品牌发布会，推出面向各行业的音视频+AI产品与解决方案，这意味着快手正式进军to B赛道。</p><p></p><p>快手已于近日成立独立业务部门“溪流湖”，负责研发to B相关业务。快手高级副总裁于冰兼任溪流湖业务负责人，向快手CTO陈定佳汇报。</p><p></p><h4>郭台铭回应遭虚拟货币诈骗广告冒用照片：严正谴责，已启动追查</h4><p></p><p></p><p>7月31日消息，鸿海集团创始人郭台铭在社交媒体发布声明称，近期有不肖业者以郭台铭创办人照片投放虚拟货币等相关诈骗广告，郭台铭办公室对此严正谴责，此举已经触法，律师团队已联系主管机关启动追查，有心人切莫以身试法。郭台铭办公室同时呼吁民众，郭台铭是实业家，从未投资虚拟货币产业，更从不推荐投资商品，请民众审慎评估，切莫误信诈骗陷阱。</p><p></p><p>此前，郭台铭曾在接受媒体采访时表示，现在流行的元宇宙，大家是玩游戏，但说到虚拟货币要去中心化，就是假议题。与虚拟货币相比，实体经济中才需要去中心化，除了工厂生产端之外，健康检测也是必须要去中心化的产业，像是在疫情下的家庭检测，甚至健康检查等，在未来都可望变得更加方便。</p><p></p><h4>Robinhood宣布将裁员约23%，Q2加密交易业务收入环比增长7%</h4><p></p><p></p><p>股票和加密交易应用程序Robinhood周二宣布新一轮裁员举措。Robinhood首席执行官Vlad Tenev在博客文章中表示，“作为更广泛的公司扁平化组织结构的一部分，我刚刚宣布我们将裁员约23%。虽然所有职能部门的员工都将受到影响，但这些变动将集中在我们的运营、营销和项目管理部门。”Robinhood此前曾在4月份宣布裁员9%。</p><p></p><p>Robinhood还发布第二季度财报，报告显示月度活跃用户和托管资产有所下降。此外，由于加密业务和净利息收入的增加，Robinhood总净收入为3.18亿美元，高于第一季度的2.99亿美元，环比增长6%。然而，这一收入数字仍远低于2021年第二季度报告的5.65亿美元。第二季度基于交易的收入环比下降7%，达到2.02亿美元；其中加密货币业务收入增长7%，达到5800万美元。</p><p></p><h4>饿了么将与万达合作推出NFT数字藏品</h4><p></p><p></p><p>在第三届上海“五五购物节”各项活动中，元宇宙概念成为其中一大亮点。例如，百联集团以一场戴上VR头盔的元宇宙发布会开场；天猫将联合上汽通用五菱、飞凡汽车、小鹏、奥迪等推出元宇宙环保车展；饿了么将与万达合作推出NFT数字藏品。</p><p></p><h4>嘉楠耘智高管：加密熊市下公司全球化战略步入正轨</h4><p></p><p></p><p>比特币矿机制造商嘉楠耘智高级副总裁Edward Lu在接受采访时表示，尽管身处“加密寒冬”，但其全球业务扩张计划仍步入正轨。其中哈萨克斯坦是全球化战略开展的第一个国家，之后还将在欧洲和北美进行业务扩张。 Edward Lu还表示，嘉楠耘智为“加密寒冬”做好了充分的应对准备，并认为此次周期会比预想中短。 此前7月30日消息，嘉楠耘智计划将比特币挖矿业务扩展至美国，并详细介绍了其在哈萨克斯坦试点挖矿业务的成功经验。嘉楠耘智在2022年Q1的收入超过2.13亿美元，持有近167枚比特币，截至发稿时价值接近400万美元。（Forkast）</p><p></p><h4>知情人士：Unity拟分拆中国业务，希望覆盖元宇宙等领域</h4><p></p><p></p><p>四名知情人士透露，美国电子游戏软件开发商Unity Software正在谈判分拆其中国部门，以帮助其在全球最大的游戏市场进行扩张。 两位知情人士表示，Unity提出分拆计划是希望看到其软件在中国得到更广泛的应用，希望应用到智能城市建模、工业设计，以及元宇宙等各个领域。他们表示，与Unity交谈过的潜在投资者已经在元宇宙领域下了大赌注。</p><p></p><h2>产业动向</h2><p></p><p></p><h4>数据：2022年上半年国内外元宇宙领域共有118笔融资</h4><p></p><p></p><p>2022年上半年，国内外元宇宙领域共有118笔融资，投资总金额达到270.6亿元，超亿元的融资有34笔，最大单笔融资达到135亿元。分开来看，2022年Q1季度，国内外元宇宙领域共有43笔融资，其中超亿元的融资有18笔，融资总金额达到82亿元，融资总金额同比增长51%。而在2022年Q2季度，元宇宙领域共有74笔融资，其中超亿元的融资有16笔，融资总金额达到188.6亿元。 其中，解决方案商成为融资笔数最多的赛道，达到29笔，占比24.6%，VR内容赛道融资数量其次，达到28笔。底层技术赛道和游戏赛道也分别获得了15笔、14笔融资，分别占比12.7%、11.9%。此外，硬件赛道也获得了12笔融资，占比10.2%。</p><p></p><p>此外，中国相关企业受到资本关注的程度，远高于其他国家。2022年上半年，有60家中国企业获得投融资，平均3天一笔融资。2022年上半年获投融资企业注册地主要汇聚在国内以及美国，分别为60笔和24笔，其次是英国和日本分别是6笔和4笔，其余国家均在1至2笔左右。</p><p></p><h4>V神：预计合并不会对网络产生任何不利影响，因为大多数以太坊社区都支持合并</h4><p></p><p></p><p>Vitalik Buterin在周六的网络研讨会上表示，以太坊合并不会对ETC上铸造新代币产生不利影响。他预计不会对区块链产生任何不利影响，因为大多数以太坊社区都支持合并。</p><p></p><p>有人担心涌向ETC的矿工可能会破坏合并。开发人员Tim Beiko说，理想情况下，用户不应该注意到任何不同。Buterin补充说，ETC拥有强大的社区和强大的产品，可为提供PoW。ETC社区大力提倡PoW价值观。尽管如此，市场仍有可能分裂。</p><p></p><h4>百度副总裁李硕：开物2.0有三个升级</h4><p></p><p></p><p>百度副总裁李硕在“2022 AI+工业互联网高峰论坛”上表示，百度智能云开物2.0有三个升级。一是应用升级，让AI相关驱动的一些应用能够深入到行业核心领域；二是平台升级，正式推出了智能控制引擎；三是AI核心升级。</p><p></p><p>李硕表示，未来某一天，我们在工业领域里面可以率先实现跨场景的AI，更好的赋能企业和实际生产经营。</p><p></p><h4>超 8000 加密货币钱包遭受攻击，黑客卷走数百万Solana与USDC资产</h4><p></p><p></p><p>8月3日，外媒报道 Nomad 代币桥遭遇了漏洞攻击，导致其 1.9 亿美元资产被掏空。与此同时，不知名的攻击者也在周二晚间扫荡了数千个包含价值至少 400 万美元的 Solana 和 USDC 的加密货币钱包。Decrypt.co 指出，攻击发生于太平洋标准时晚间 20:00，并且似乎起源于 Solana 浏览器钱包 Phantom。</p>",
    "publish_time": "2022-08-07 20:49:10",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]