[
  {
    "title": "十亿行挑战显示 Java 可以在两秒钟内处理十亿行的文件",
    "url": "https://www.infoq.cn/article/xvswDMrHrNjMccAD0GBP",
    "summary": "<p>2024 年的第一天，Decodable 高级软件工程师 Gunnar Morling 向 Java 社区发起了 十亿行挑战（1BRC）。这项挑战将持续到 1 月底，目标是找到在最快时间内处理 10 亿行的 Java 代码。到目前为止，最快的算法可以在 2.5 秒内完成处理。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/10/10548b0adb437f05095a315cd7949c5a.png\" /></p><p></p><p>挑战的规则很简单：只能使用 SDK 特性，可以是任何 Java 发行版。因此，解决方案中不能借助外部库或数据存储。为了更好地了解这一挑战，InfoQ 联系了 Morling、GoTo 首席软件工程师 Eliot Barlas、OpenValue Rotterdam 总监 Roy van Rijn 以及 Oracle 软件开发副总裁兼 GraalVM 创始人 Thomas Wuerthinger。</p><p></p><p>InfoQ：这是一项令人兴奋的挑战。您能描述一下吗？其背后的动机是什么？</p><p></p><p>Morling：1BRC 是一项编码挑战，它的任务看似简单：解析文本文件中的温度测量值，并确定每个气象站的最小、最大和平均温度。需要注意的是：该文件有 10 亿个条目！</p><p></p><p>我想创造一个机会来探索高性能编程技术、新引入的 API（比如 Vector API——它利用了 CPU SIMD 指令）、不同 Java 发行版的特性，以及任何能证明 Java 已经变得非常快的东西。</p><p></p><p>InfoQ：如何参与这项挑战？</p><p></p><p>Morling： 可以先看下README文件，并克隆存储库。尝试实现自己的解决方案，并看看其他人做了什么尝试——归根结底是为了学习。</p><p></p><p>InfoQ：您在解决方案中有看到什么出人意料的东西吗？</p><p></p><p>Morling： 有人采用了黑客的做法：许多解决方案针对特定的键集合（即天气预报站名称）做了优化。这对于这个特定的数据集是有效的。在社区的帮助下，我们澄清了挑战的目的。</p><p></p><p>有许多解决方案很有趣：使用 SIMD 和新特性 Java 原生内存 API（这是我希望看到的），以及高度优化的解析函数，包括 SWAR（寄存器内 SIMD），这是我没有预料到的。到目前为止，致力于实现最快算法的人们已经深入到原生优化领域，计算 CPU 指令，评估分支预测错误等。</p><p></p><p>InfoQ：请描述下您的解决方案。有什么技术是您想要尝试的吗？</p><p></p><p>Eliot Barlas：我的解决方案是按照可用处理器的数量拆分文件。对于每一个部分，都有一个任务在单独的线程上计算每个气象站的统计信息。当这些任务完成后，最终结果将汇总到最终的统计数据表中。</p><p></p><p>对每一部分中的数据做内存映射，并通过可以覆盖整个分区字节范围的MappedByteBuffer进行访问。任务会使用ByteBuffer遍历分区中的数据，每次一个 byte 或 int。我还使用sun.misc.Unsafe将气象站名称提取并存储为整数序列。</p><p></p><p>Roy van Rijn： 我的解决方案是一种渐进式的解决方案。一开始，它使用 SDK 提供的普通数据结构和 API（如BufferedInputStream或HashMap）。逐步地，它演变成使用 Unsafe 来直接访问内存。并行性、无分支代码和实现 SWAR（SIMD 作为寄存器）使我的解决方案成为迄今为止最主要的竞争者之一。对于存储，我自己实现了一个“非常简单”的 hashmap，其底层是基于线性探查概念的数组。</p><p></p><p>Thomas Wuerthinger： 该解决方案的第一部分将工作负载按照目标处理器的可用核数进行划分，以便可以并行处理。它使用 Java 的特性对输入文件做内存映射，从而实现最有效的直接内存访问。解析数据的最内层循环所采用的技术设法避免了分支代码，代之以一些复杂的算术和位操作。对于这个特定的问题，由于输入的随机性，处理器经常会做出错误的分支预测，因此避免分支是最大化性能的关键。</p><p></p><p>InfoQ：您的解决方案还有可能进一步改进吗？</p><p></p><p>Barlas： 我一直在关注 Panama 项目，但 1BRC 提供了一个以应用方式探索外部内存能力的机会。[…] 我还未能成功地利用 Panama 项目的 Vector API 实现加速。例如，开始时，我尝试使用&nbsp;ByteVector API 来快速比较气象站名称。我想使用其他类型的向量或结合&nbsp;MemorySegment&nbsp;接口重新实现这个过程。</p><p></p><p>Wuerthinger： 现在可能的改进在很大程度上取决于目标硬件。具体来说，可以在内存带宽、计算带宽和分支预测依赖方面进行权衡。</p><p></p><p>Roy van Rijn： 从大的方面来讲，方法是类似的。我目前正在尝试探索的概念是“机械同情（mechanical sympathy）”，我希望改进需要执行的指令，让它们以一种最适合测试机器的方式执行。</p><p></p><p>InfoQ：您怎么看新年伊始的这项有趣的挑战？</p><p></p><p>Morling： 可以肯定的是，Java 及其生态系统和社区比以往任何时候都更加繁荣！看到这么多人参加挑战，包括一些非常知名的开发者，真是令人鼓舞。每个人都在学习：要么通过编码，要么通过阅读代码。能有这么多人参加这项挑战，实在是离不开社区的帮助。</p><p></p><p>这一挑战受到了程序员社区的热烈欢迎，Morling 说，“这一切都远远超出了我的预期。”尽管领跑者似乎是在 GraalVM 上运行的解决方案，但也有提交使用了 OpenJDK 构建、Amazon Corretto 或 Eclipse Temurin。Morling 进一步评论说：“Graal 非常适合眼下这项任务，可以额外提供几个百分点的性能提升。”</p><p></p><p>这个挑战已经不限于 Java 生态系统，已经有使用 Rust、Go、C++ 甚至 SQL 和 Shell 编写的解决方案。</p><p></p><p>Morling 感谢了社区和 Decodable——他们提供了评估用的机器。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2024/01/1brc-fast-java-processing/\">https://www.infoq.com/news/2024/01/1brc-fast-java-processing/</a>\"</p><p></p><p></p><p>欢迎加入 InfoQ 读者技术交流群，与志同道合的朋友一起探讨知识，交流经验。</p><p><img src=\"https://static001.infoq.cn/resource/image/f8/33/f8304bd8babbd912ac06fd91d7f2d333.png\" /></p><p></p><p></p>",
    "publish_time": "2024-02-24 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Kubernetes 开源9年，但我们已经有了 8 年的踩坑血泪史",
    "url": "https://www.infoq.cn/article/aJpZce53z33Lh1IUJ3L9",
    "summary": "<p></p><p></p><p></p><blockquote>9 年开源，踩坑无数，K8s 到底坑在哪？</blockquote><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/31/3103e3174542c03f51e897d705bd06f3.jpg\" /></p><p></p><p>在 Urb-it 这家公司的早期发展阶段（那时候我还没来），公司决定使用 Kubernetes 作为我们云原生战略的基石。这一决定的背后，公司所考虑的一方面是以 K8s 应对快速增长的预期，另一方面是利用它的容器编排功能为我们的应用程序带来更加动态、弹性和高效的环境。除此之外，Kubernetes 非常适合我们的微服务架构。</p><p></p><p></p><h2>早期决策</h2><p></p><p></p><p>这个决定是很早就定下来的，当然它理应受到质疑，因为它意味着我们作为一家初创公司要对这项技术产生深度依赖，还要为此学习太多的知识。另外，我们当时真的需要 Kubernetes 来解决它擅长的那些问题吗？有人可能会说，我们一开始可以先搞一个很大的单体架构用很长时间，直到它遇到令人痛苦的扩展之类的问题，然后我们再转向 Kubernetes（或其他东西）也不迟。此外，Kubernetes 彼时仍处于早期开发阶段。不过这些问题下次再讨论吧。</p><p></p><p></p><h2>8 年生产经验</h2><p></p><p></p><p>我们在生产环境中运行 Kubernetes 已经有八年多了（每个环境都有单独的集群），期间做出了一些好的和不太好的决策。有些错误仅仅是“otur när vi tänkte”（我们决策中遇到的坏运气）造成的，而另一些错误则源于我们不完全（甚至一点都没有）理解其底层技术。Kubernetes 很强大，但也颇具复杂性。</p><p></p><p></p><blockquote>我们在没有任何大规模运行 K8s 经验的情况下迎头而上。</blockquote><p></p><p></p><p></p><h3>从 AWS 上的自托管迁移到Azure 上的托管（AKS）</h3><p></p><p></p><p>前面几年，我们在 AWS 上运行了一个自托管的集群。如果我没记错的话，我们一开始没有选择使用 Azure Kubernetes Service（AKS）、Google Kubernetes Engine（GKE）、Amazon Elastic Kubernetes Service（EKS），因为它们那时还没有提供官方的托管解决方案。正是在 Amazon Web Services（AWS）的自托管方案上，我们遭遇了 Urb-it 历史上第一次也是最可怕的一次集群崩溃，稍后会详细介绍。</p><p></p><p>由于我们是一个小团队，因此要掌握我们所需的所有新功能是很大的挑战。同时，管理自托管集群需要持续的关注和维护，这增加了我们的工作量。</p><p></p><p>当托管解决方案开始广泛流行时，我们花了一些时间来评估 AKS、GKE 和 EKS。对我们来说，所有这些方案都比我们自己管理要好上几倍，而且我们可以轻松地看到迁移带来的快速投资回报。</p><p></p><p>当时我们的平台是 50% .Net 和 50% Python，并且我们已经在使用 Azure Service Bus、Azure SQL Server 和其他 Azure 服务了。因此，将我们的集群迁移到 Azure 不仅可以更轻松地把这些服务集合起来使用，而且还可以充分利用 Azure 的主干网络基础设施，省去与离开 / 进入外部网络和 VNET 相关的成本，而之前我们的 AWS 与 Azure 混合架构中这些成本是避免不了的。此外，我们的许多工程师都熟悉 Azure 及其生态系统。</p><p></p><p>还应该提到一点，对于 AKS 上的初始设置，我们不必为控制平面节点（主节点）付费，这是一个额外的好处（节省节点费用）。</p><p></p><p>我们在 2018 年冬天进行了迁移，尽管多年来我们在 AKS 这块也遇到了一些问题，但我们从未因为这次迁移而感到后悔。</p><p></p><p></p><h3>集群崩溃 #1</h3><p></p><p></p><p>在 AWS 上使用自托管方案期间，我们经历了一次大规模的集群崩溃，导致我们的大部分系统和产品出现故障。根 CA 证书、etcd 证书、API 服务器证书都过期了，导致集群停止工作、无法管理。当时，kube-aws 中没有什么支持内容可以帮助我们解决这个问题。我们请了一位专家，但到最后我们不得不从头开始重建整个集群。</p><p></p><p>我们以为每个 git 存储库中都有所有值和 Helm 图表，但令人惊讶的是，并非所有服务都是如此。最重要的是，库里没有存储创建集群的任何配置。重新建立集群并把我们的所有服务和产品都塞进去的任务成了一场赶时间的赛跑。其中一些服务需要重新设计 Helm 图表来创建缺失的配置。有时一位开发工程师会问他的同事：“你还记得这个服务应该有多少 CPU 或 RAM，或者它应该有哪些网络和端口访问权限吗？”更不用说那些已经随风而逝的密钥了。</p><p></p><p></p><blockquote>我们花了几天时间才让它重新启动并正常跑起来。至少可以说，这不是我们最自豪的时刻。</blockquote><p></p><p></p><p>由于我们积极主动的沟通工作，通过保持透明度、诚实和客户关系培育等对策，我们没有失去任何业务或客户。</p><p></p><p></p><h3>集群崩溃 #2</h3><p></p><p></p><p>现在你可能会说：第二次事故不可能是由于证书造成的，因为你一定从第一次事故中吸取了教训，对吧？是，也不是。不幸的是，当我们从崩溃 #1 中重新创建集群时，我们使用的特定版本的 kube-aws 出现了问题。当它创建新集群时，它没有将 etcd 证书的过期时间设置为我们提供的过期日期，而用的是一年这个默认值。因此，在第一次集群崩溃整整一年后，证书过期了，我们又经历了另一次集群崩溃。不过这一次恢复起来容易多了，我们不用再重建所有东西。但这仍然是一个地狱般的周末。</p><p></p><p>旁注 1：其他公司也像我们一样受到了这个错误的影响，但它并没有帮助我们的客户…</p><p></p><p>旁注 2：我们的计划是在一年后更新所有证书，但为了给自己留出一些余量，我们将有效期设置为两年（如果我没记错的话）。因此，我们是有更新证书的计划，但这个 bug 让我们不得不提前行动。</p><p></p><p></p><blockquote>自 2018 年以来，我们没有再发生过集群崩溃……希望这不是什么 flag。</blockquote><p></p><p></p><p></p><h2>经验教训</h2><p></p><p></p><p></p><h4>Kubernetes 很复杂</h4><p></p><p></p><p>你需要雇佣一些对 Kubernetes 的基础设施和运营方面感兴趣并愿意参与其中的工程师。就我们而言，我们需要几位工程师在日常工作外钻研 Kubernetes，这样遇到问题时他们就能扮演现场专家的角色。正如你可能想到的那样，Kubernetes 中特定任务的负载也各不相同。有些时候连着几周几乎没有什么可做的，而有些时候工程师需要连续几周提高警惕，例如在集群升级期间。</p><p></p><p>我们不可能将工作轮流分配给整个团队；这项技术太复杂，没办法只做一个星期就转向别的工作，下一周再回来。当然，每个人都需要知道如何使用它（部署、调试等）——但要在更具挑战性的方面表现出色就需要工程师投入时间来研究学习了。此外，一位有远见并能制定集群发展战略的领导者也很重要。</p><p></p><p></p><h4>Kubernetes 证书</h4><p></p><p></p><p>由于证书过期，我们经历了两次集群崩溃，因此熟悉内部 Kubernetes 证书及其过期日期的细节是非常重要的。</p><p></p><p></p><h4>让 Kubernetes 和 Helm 保持最新</h4><p></p><p></p><p>当你落后时，它的成本就会上升，用起来也会变得不顺手。我们总是等待几个月才升级到最新版本，等其他人先遇到新版本的问题再说。但即使第一时间更新到最新版本，由于 Kubernetes 和 Helm 的新版本总会有变化（Kubernetes API 从 alfa 到 beta、beta 到 1.0 等），我们还是会面临许多耗时的配置文件和图表重写工作。我知道 Simon 和 Martin 喜欢 Ingress 的所有变化。</p><p></p><p></p><h4>集中管理 Helm 图表</h4><p></p><p></p><p>谈到 Helm 图表，每一次版本更改都要更新所有 70 多个图表的工作实在让我们厌倦，因此我们采用了更通用的“一个图表搞定一切”的方法。集中式 Helm 图表方法有很多优点和缺点，但不管怎样，它更适合我们的需求。</p><p></p><p></p><h4>灾难恢复计划</h4><p></p><p></p><p>我怎么强调都不为过：一定要提前做好准备方案，这样在需要时就能重新创建集群。是的，你可以在 UI 中点击几下来创建新集群，但这种方法永远无法大规模或及时地发挥作用。</p><p></p><p>有很多方法可以处理这个问题，从简单的 shell 脚本到更高级的方法都有，比如使用 Terraform（或类似的方案）。Crossplane 还可用于管理基础设施即代码（IaC）等。</p><p></p><p>对我们来说，由于团队带宽有限，我们决定存储和使用 shell 脚本。</p><p></p><p>无论你选择哪种方法，请务必不时测试流程，以确保你可以在需要时重新创建集群。</p><p></p><p></p><h4>备份密钥</h4><p></p><p></p><p>制定备份和存储密钥的策略。如果你的集群消失了，你所有的密钥也都会消失。相信我，这是我们的前车之鉴；当你有多个不同的微服务和外部依赖项时，需要花费大量时间才能使一切恢复正常。</p><p></p><p></p><h4>与供应商无关 VS “全力以赴”</h4><p></p><p></p><p>一开始，在迁移到 AKS 后，我们试图让集群不和供应商绑定，这意味着我们将继续使用其他服务来做容器注册表、身份验证、密钥保管库等。我们的想法是，这样的方案让我们在将来某一天可以轻松迁移到另一个托管平台。虽然与供应商无关是一个好主意，但对我们来说，它带来了很高的机会成本。一段时间后，我们决定全力投入 AKS 相关的 Azure 产品，例如容器注册表、安全扫描、身份验证等。对我们来说，这改善了开发体验，简化了安全性（使用 Azure Entra Id 进行集中访问管理），等等，从而加快了上市时间并降低了成本（规模效益）。</p><p></p><p></p><h4>自制资源定义</h4><p></p><p></p><p>是的，我们全力投入了 Azure 产品线，但我们的指导方针是尽量不用自制的资源定义，而使用内置的 Kubernetes 资源。然而我们也有一些例外，比如 Traefik，因为 Ingress API 并不能满足我们的所有需求。</p><p></p><p></p><h4>安全</h4><p></p><p></p><p>见下文。</p><p></p><p></p><h4>可观察性</h4><p></p><p></p><p>见下文。</p><p></p><p></p><h4>已知峰值期间的预缩放</h4><p></p><p></p><p>就算使用了自动缩放器，我们有时也会缩放得太慢。基于流量数据和常识（我们是物流公司，节假日有高峰），我们会在高峰到来前一天手动扩容集群（ReplicaSet），第二天再缩容（一点点缩，以应对随时可能出现的第二波高峰）。</p><p></p><p></p><h4>集群内的 Drone</h4><p></p><p></p><p>我们将 Drone 构建系统保留在了 stage 集群中；这样做有一些好处，但也有一些缺点。由于它位于同一个集群中，因此很容易扩展和使用。然而，同时构建太多 Drone 时，它会消耗掉几乎所有的资源，让 Kubernetes 急着启动新节点。最好的解决方案可能是将其作为纯粹的 SaaS 解决方案，而不必担心产品本身的托管和维护工作。</p><p></p><p></p><h4>选择正确的节点类型</h4><p></p><p></p><p>虽说这是跟上下文紧密关联的，但总体来说根据节点类型，AKS 会保留大约 10-30% 的可用内存（用于内部 AKS 服务）。因此对我们来说，我们发现使用更少但更大的节点类型是有益的。此外，由于我们在许多服务上运行 .Net，因此需要选择具有高效且可观的 IO 性能的节点类型。（.Net 经常写入磁盘以进行 JIT 和日志记录，如果这需要网络访问就会变得很慢。我们还会确保节点磁盘 / 缓存的大小至少与配置的总节点磁盘大小相同，也是为了防止网络跳转）。</p><p></p><p></p><h4>预留实例</h4><p></p><p></p><p>你可能会争论说这种方法有点违背云的灵活性原则，但对我们来说，保留关键实例一两年可以节省大量成本。在许多情况下，与“现收现付”方式相比，我们可以节省 50-60% 的成本。是的，这对团队来说已经足够了。</p><p></p><p></p><h4>k9s</h4><p></p><p></p><p>对于想要比纯 kubectl 高一级抽象的用户来说，<a href=\"https://k9scli.io/\">https://k9scli.io/</a>\" 是一个很棒的工具</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/07/0739e56cf1bf36b5b52f5671d1be9611.jpg\" /></p><p></p><p></p><h3>可观测性</h3><p></p><p></p><p></p><h4>监控</h4><p></p><p></p><p>一定要持续跟踪内存、CPU 等资源的使用情况，于是你就可以观测集群的性能并确定新功能是否正在改善或恶化其性能。这样就可以更轻松地为不同的 Pod 找到并设置“正确”的限制（找到正确的平衡点很重要，因为如果内存不足，Pod 就会被杀死）。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/dc/dcc0fb5483f3ec1dca0da2cec3c08e01.jpg\" /></p><p></p><p></p><h4>告警</h4><p></p><p></p><p>逐渐完善我们的告警系统是一个过程，但到最后，我们将所有告警定向到了我们的 Slack 频道上。当集群未按预期运行或出现任何不可预见的问题时，这种方法可以让工程师方便地接收通知。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/8e/8e83107965ddeeda31b3e946e13a0849.jpg\" /></p><p></p><p></p><h4>日志</h4><p></p><p></p><p>对于任何微服务架构来说，将所有日志整合到一处，以及部署强大的跟踪 ID 策略（例如 OpenTelemetry 或类似策略）都是非常重要的。我们花了 2 到 3 年的时间才把这件事做好。如果我们早点实施它，就会节省大量时间。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/4d/4d19807bcc74bb3629e36d23c0dfe50a.jpg\" /></p><p></p><p></p><h4>安全性</h4><p></p><p></p><p>Kubernetes 中的安全性是一个范围很大的主题，我强烈大家建议对其进行彻底的研究，以了解安全性方面的所有细微差别（举个例子，可以参阅 NSA、CISA 发布的 Kubernetes 强化指南）。以下是我们以往经验中的一些要点，但请注意，这些内容肯定不够完整。</p><p></p><p></p><h4>访问控制</h4><p></p><p></p><p>简而言之，Kubernetes 默认情况下并没有过度限制。因此我们投入了大量时间来加强访问控制，为 Pod 和容器实施最小权限原则。此外，由于一些特定的漏洞，无特权的攻击者有可能将其权限升级为 root，从而绕过 Linux 命名空间限制，在某些情况下，他们甚至能逃离容器以获得主机节点上的 root 访问权限。起码这不是什么好事。</p><p></p><p>你应该设置只读根文件系统，禁用服务帐户令牌自动挂载，禁用权限升级，删除所有不必要的功能等等。在我们的具体设置中，我们使用 Azure Policy 和 Gatekeeper 来确保自己没有部署不安全的容器。</p><p></p><p>在 AKS 内的 Kubernetes 设置中，我们利用基于角色的访问控制（RBAC）的稳健性来进一步增强安全性和访问管理。</p><p></p><p></p><h4>容器漏洞</h4><p></p><p></p><p>有很多很好的工具可以扫描和验证 K8s 容器和其他部分。我们使用 Azure Defender 和 Azure Defender for Containers 来满足一些需求。</p><p></p><p>注意：不要陷入“分析瘫痪”，也就是先试图找到“完美”的，什么花哨功能都包含的工具才开始行动。你要做的只是先选择一些工具，然后开始学习即可。</p><p></p><p></p><h3>我们的长期设置</h3><p></p><p></p><p></p><h4>部署</h4><p></p><p></p><p>与许多其他应用程序一样，我们使用 Helm 来管理和简化 Kubernetes 上应用程序的部署和打包任务。由于我们很早以前就开始使用 Helm，并且一开始就混用了 .Net/Go/Java/Python/PHP，因此我们重写 Helm 图表的次数多得我都记不清了。</p><p></p><p></p><h4>可观测性</h4><p></p><p></p><p>我们开始使用 Loggly 和 FluentD 一起来做集中式日志记录，但几年后，我们转向了 Elastic 和 Kibana（ELK 堆栈）。对我们来说 Elastic 和 Kibana 更易用，因为它们更流行，而且在我们的设置中更便宜。</p><p></p><p></p><h4>容器注册表</h4><p></p><p></p><p>我们一开始用的是 Quay，这个产品很不错。但随着我们迁移到了 Azure，自然就转向了 Azure 容器注册表，因为它是集成的，对我们来说是一个更“原生”的解决方案。（然后我们还在 Azure Security Advisor 下获取了容器）。</p><p></p><p></p><h4>管道</h4><p></p><p></p><p>从一开始，我们就一直使用 Drone 来构建容器。当我们刚开始时，支持容器和 Docker 的 CI 系统并不多，也没有以代码形式提供配置。多年来，Drone 为我们提供了很好的服务。当 Harness 收购它时，它变得有点混乱，但在我们屈服并转向高级版本后就获得了所需要的所有功能。</p><p></p><p></p><h4>改变游戏规则</h4><p></p><p></p><p>在过去的几年里，Kubernetes 改变了我们的游戏规则。它释放的功能使我们能够更有效地扩展（不稳定的流量），优化我们的基础设施成本，改善我们的开发人员体验，让我们更容易测试新想法，从而显著缩短新产品和服务的上市时间 / 赚钱时间。</p><p></p><p>我们开始使用 Kubernetes 有点太早了，那时候我们还没有真正遇到只有它才能解决的问题。但从长远来看，尤其是最近几年，事实证明它为我们提供了巨大的价值。</p><p></p><p></p><h2>结&nbsp; &nbsp;语</h2><p></p><p></p><p>回顾八年的经历，我们有很多故事可以分享，其中许多已经淡入记忆。希望我们的情况、我们所犯的错误以及我们在此过程中吸取的教训能为大家带来帮助。感谢阅读。</p><p></p><p>原文链接：</p><p></p><p><a href=\"https://medium.com/@.anders/learnings-from-our-8-years-of-kubernetes-in-production-two-major-cluster-crashes-ditching-self-0257c09d36cd\">https://medium.com/@.anders/learnings-from-our-8-years-of-kubernetes-in-production-two-major-cluster-crashes-ditching-self-0257c09d36cd</a>\"</p><p></p><p>声明：本文为 InfoQ 翻译，未经许可禁止转载。</p><p></p><p>今日好文推荐</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651196829&amp;idx=1&amp;sn=d1ba4ab9bc7adffae995a22d2b05c7d5&amp;chksm=bdbbf5ce8acc7cd81c44f5ec029c236ec1f827b344f3b54ea56ea5cbfb9095784de43b2dc0c1&amp;scene=21#wechat_redirect\">3700 万美元“卖身救命”，泥潭深陷的 MariaDB 准备退市</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651196645&amp;idx=1&amp;sn=71d7dcea11cb20b01419716f838ffa24&amp;chksm=bdbbf4b68acc7da0a149ec6ff45d3c926eb225fc53342f5a18d0338661f422b993de6b9c9d75&amp;scene=21#wechat_redirect\">最高人民法院：这份判决给软件开发者吃了定心丸</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651196481&amp;idx=1&amp;sn=02104c72f9f6cbc3fe70382fbbea74a6&amp;chksm=bdbbf4128acc7d04b7fd1ac70d160e915f5f2476607f2db2972a976ff7c05e0fac147a74e3bb&amp;scene=21#wechat_redirect\">24 小时随时随地高效沉浸式编程：我用 Vision Pro 做到了，老板高兴坏了</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651196390&amp;idx=1&amp;sn=3c8d0e41a484b8dce56624e213fafea0&amp;chksm=bdbbf3b58acc7aa3ab551a2d84b31fe4cdf78858e99a48f174ceb9c2c663526388f9c75e673a&amp;scene=21#wechat_redirect\">生成式 AI 最大飞跃！OpenAI 首个视频生成模型重磅发布，奥特曼被“跪求”：不要让我失业</a>\"</p><p></p><p></p><p></p>",
    "publish_time": "2024-02-24 10:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]