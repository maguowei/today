[
  {
    "title": "好分期风控特征血缘关系的设计与实现",
    "url": "https://www.infoq.cn/article/whuNh2Aepd3UlC1DPyXJ",
    "summary": "<p></p><h2>一、何为特征血缘关系？</h2><p></p><p></p><p>特征血缘关系是好分期在构建风控系统过程中，产生的一种描述在数据源，特征和策略文件之间的数据转换、依赖的概念。它用于记录和追踪特征的来源，衍生以及影响的路径，能够帮助理解特征的产生和使用历史，以及对模型或是决策结果的贡献。</p><p></p><h2>二、背景</h2><p></p><p></p><p>在开始整体介绍之前，我们需要先了解一下几个特定的概念：</p><p></p><p>数据源：包括自有数据、三方数据、加工数据等，可以来自不同的数据库（如MySQL、MongoDB、HBase）或者离线数据（Hive）。这些数据经过一定的加工逻辑生成了一个数据集合。标准特征：仅有一个依赖的数据源做加工计算的特征。衍生特征：可以依赖多个数据源，多个标准特征甚至是衍生特征聚合加工所计算的特征。事件：包括用户授信、放款、额度等事件，这些事件通过流程引擎进行流转，并分为多个步骤。每个步骤包含数据节点、特征节点和策略节点。我们在流程中设计了自上而下的缓存机制，确保后续步骤能够获取到之前步骤的数据源或特征缓存。同时，特征的计算需要保证其所依赖的数据源或特征在当前步骤上线或能够获取到之前步骤的缓存，否则可能导致特征计算失败或结果为空，从而影响到策略节点的判断。策略：风控事件以策略决定事件结果。策略文件以代码或是数据的格式存在，存在着包括决策流，决策脚本，规则集，决策表等多种格式的文件集合，这些文件中既可以包含Python代码，也可以是以JSON格式表示的规则集合。</p><p></p><p>各个概念的关系如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e2/e2d42840e4f9ea540f9ef1407cf274ae.png\" /></p><p></p><p>随着好分期业务的飞速发展，我们面临的数据增长量也在加速。用户基础数据、三方数据和加工数据等，都在快速积累和扩张。同时，由于各类模型和策略所使用的特征数据关系复杂多变，其维护工作变得尤为困难。在这样一个大数据环境下，如何追踪大量特征和数据源的流向，从而明确每个数据系统中上游数据来源和下游数据去向，对于完成数据治理这一环节至关重要。</p><p></p><p>特征血缘关系的建立，旨在解决这一问题。通过构建一个清晰、有效的血缘关系，我们能更好地追踪和管理数据流动，以便进行有效的数据治理。</p><p></p><p>在实际运营过程中，我们会遇到一些挑战和问题：</p><p></p><p>1.数据间的血缘关系不明确导致重复存储和处理，定义标准混乱导致数据质量好坏参差不齐，同时特征价值评估也因此变得异常困难。这一系列问题相互影响，使得整个数据管理工作陷入困境。</p><p></p><p>2.另外，三方数据源的异常也可能对我们的业务产生影响。三方问题导致依赖于这些数据源的特征出现分布偏移，我们将很难定位影响范围，从而无法及时采取有效的纠正措施。</p><p></p><p>3.在特征衍生多层的过程中，其溯源问题也让人头痛。特别是在数据流转过程中出现问题时，由于无法确定具体错误发生在哪个环节，我们往往难以找到问题的产生源头并进行修复。</p><p></p><p>4.此外，特征之间的计算依赖性也会带来麻烦。例如在一个复杂的衍生特征计算场景中，当某一个层级的依赖特征未能及时上线，就可能导致当前特征以及下层特征计算失败，从而造成业务流程的中断。</p><p></p><p>基于以上的痛点问题，我们迫切需要一个能够清楚呈现血缘关系的方法，通过可视化的图表展示，为数据的流转提供一个清晰的链路。此外，我们也需要建立策略文件与特征之间引用关系，以进一步优化和丰富血缘关系。这不仅可以帮助我们更好地管理和控制数据，还能为风险人员提供一个更加安全、可靠的数据使用环境。</p><p></p><h2>三、与现有血缘关系的对比</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/71/717d67d23e7329d551d1110c20f0a6e7.png\" /></p><p></p><p>目前市面上常见的血缘关系是以数据库、表、字段等为出发点，主要建立表与表之间的血缘关系，如上图所示。这种血缘关系的维护多依靠人工检索和手动更新的方式，展示了数据如何在表之间进行流转。好分期血缘关系以特征为出发点，旨在建立从数据源到依赖该数据源计算的特征，再到更深层次的衍生特征，最终到引用这些特征的策略，这个完整链路的血缘关系。</p><p></p><p>另一方面，业务中的数据源、特征、策略间上下线也存在着依赖关系，如果仅支持展示数据流转的功能远不能满足我们业务对于血缘关系的要求。对于特定事件的某个步骤的特征血缘关系，需要一个更细粒度的展示，把依赖关系精细到事件乃至步骤上面。通过构建这种血缘关系，来解决目前业务中遇到的痛点问题。</p><p></p><h2>四、特征血缘关系方案设计</h2><p></p><p></p><p>先前的章节介绍了特征血缘关系的定义，产生的背景以及与现有血缘关系的差异。那它又是如何实现的呢？本章节将会通过整体架构设计，依赖树构建、基于节点属性的减枝算法、策略层的设计四个方面来进行具体介绍特征血缘关系的实现方案。</p><p></p><h3>1、架构设计</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/19/1981af3d4963474210d09f2b6e34c461.png\" /></p><p></p><p>整体采用前后端分离，前端引入了Vue做界面展示和AntV G6对依赖树进行可视化。</p><p></p><p>MySQL数据库：创建一张记录依赖关系的表。数据源和特征、特征和特征的依赖，需要在创建特征时进行记录，每个依赖都会生成一条记录，表示当前的特征依赖的一个数据源或是特征关系。数据源层：数据源层主要负责建立数据源到特征的依赖树。能够展示所有直接或是间接依赖该数据源的特征情况。特征层：特征层负责标准特征和衍生特征之间的依赖树构建。提供特征溯源的功能。同时，考虑到实际情况中存在事件某个步骤上的特征依赖关系，我们对特征节点的依赖进行了进一步的细化，附带了包括事件、步骤等多个属性的概念，相应的需要对特征依赖树做父级特征的属性匹配和子级特征的减枝操作。策略层：策略层主要负责构建策略与引用特征之间的依赖关系。不同于数据源层和特征层，策略层的关系来源于对策略文件的解析，首先对策略文件进行按类型的拆分，通过特定的正则表达式抽取出每个策略所使用的特征，然后引入倒排索引的思想构建特征到策略的映射以提高查询效率。缓存和数据变更监听：对依赖关系以及策略文件的预处理结果需要保存在缓存当中，我们采用了Redis Hash的格式进行保存处理，在一定程度上提升了查询的效率。在这种情况下，也需要保证缓存与数据库数据的一致性，防止由于缓存不一致导致的误判问题，我们采用了Binlog监听的方式保证缓存能够维持在最新状态。</p><p></p><h3>2、依赖树构建</h3><p></p><p></p><p>通过MySQL表方式记录依赖关系，在程序启动时加载数据到内存当中进行预处理形成点和边的数据结构。具体定义如下：</p><p></p><p>边格式为：’EDGE’# from_node # to_node点格式为: ’NODE’# node_id # node_name [#property_name:property_value]</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/af/afb6512384668b29eba930f1594c6e8a.png\" /></p><p></p><p>由之前的描述我们可以得出，目前业务中存在着三种不同类型的节点和四种不同的边。定义如下：</p><p></p><p>点集合： [ service_node, sd_node, dr_node ] ,其中service_node表示数据源节点，sd_node表示标准特征节点，dr_node表示衍生特征节点。边集合：[ service_node-&gt;sd_node, service_node-&gt;dr_node, sd_node-&gt;dr_node, dr_node-&gt;dr_node]</p><p></p><p>在预处理生成边结构之后，我们通过检索边的同源节点，然后以栈递归算法对边进行组装，即可生成如下图的树状图结构。</p><p><img src=\"https://static001.geekbang.org/infoq/ab/abc6213e0b375f0914507b81fd3184fa.png\" /></p><p></p><p>主要的递归算法逻辑：</p><p></p><p>1）．选定一个node A作为递归的根节点。</p><p>2）．新建两个栈结构命名为parentStack负责node A父级节点递归、childrenStack负责node A子级节点递归。</p><p>3）．查询node A父级节点并push parentStack，子级节点push childrenStack，进入并行递归。</p><p>4）．栈是否为空？</p><p>5）．取栈顶元素，重复查询其父级或者子级特征push stack，同时构建边、节点结构。</p><p>6）．重复4）、5）流程直至栈为空。</p><p></p><p>为了提升算法的执行效率，我们采用了两个栈的方法：parentStack和childrenStack。在递归过程中，我们对数据源节点进行了特殊处理，因为数据源节点已经是最顶层节点，所以无需进行重复的递归操作。除数据源节点之外，parentStack和childrenStack的算法流程基本相同。</p><p></p><p>然而，在这个过程中，我们需要注意一种特殊情况。如果在依赖树结构中存在重复的节点，可能会导致我们的算法进入重复递归的状态，甚至在极端情况下会导致栈溢出的问题。为了避免这种情况发生，我们采取了记忆化递归的策略来避免这个问题以及降低冗余计算。</p><p></p><h3>3、基于节点属性的减枝算法和属性匹配</h3><p></p><p></p><p>考虑到特征在具体事件及其各个步骤上的依赖关系，我们更进一步地细化了特征依赖的粒度。在当前的业务逻辑中，存在一个复杂的依赖关系如下图所示：一个事件a包含了A、B、C三个步骤。此时，节点C需要上线一个衍生特征dr1。</p><p></p><p>为了成功计算该衍生特征dr1，它的父级特征dr2必须能够在同一事件a被获取到。此时，dr2的步骤属性可以是B或者C，即在事件a的B或C步骤中我们都能得到dr2的值。</p><p></p><p>类似地，对于衍生特征dr2，其父级特征sd也需要能在同样的事件a被获取到。此时，sd的步骤属性可以是A或者B，意味着在事件a的A或B步骤中我们都能获取到特征sd的值。</p><p><img src=\"https://static001.geekbang.org/infoq/bc/bc27f99d965a3c8bb931f6da998dca51.png\" /></p><p></p><p>总结而言，特征在指定事件上的依赖关系，其属性当中，事件需要相等，而步骤存在置顶向下不断增大的规则。换句话说，一个衍生特征的父级特征可在该衍生特征所在步骤或其之前的步骤中获取到，但不能在其后的步骤中获取。</p><p></p><p>因此，对于4.2节中介绍的依赖树，我们在附带上属性的概念后，按照以上的规则算法进行进一步的处理。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/08/08bccd6ae6df72492fad1cfc6da6dc50.png\" /></p><p></p><p>在指定一个特定事件步骤下的衍生特征时，我们需要对其父级依赖的特征在多个属性中筛选出符合之前所述规则的属性。同时，对于它的子级特征，我们要剔除那些不满足上述规则的依赖关系。</p><p></p><p>通过这个算法，我们能够构造出一个指定事件步骤下的特征依赖树。这种依赖树可以清晰地展示出每个特征在各个步骤中的依赖关系，从而为我们提供了一种直观的理解方式。更重要的是，它能有效地防止因缺失依赖特征而导致当前特征计算失败的情况发生，也让特征间的复杂依赖关系更加易于理解和操作。避免了由于遗漏或错误的依赖关系而引发的误差，确保了特征计算的成功进行。有利于我们更好地处理和使用各个特征，进一步提升整体的数据处理和结果质量。</p><p></p><h3>4、策略与特征间的依赖关系构建</h3><p></p><p></p><p>为了方便查询策略中使用的特征，我们在业务中规定了标准特征命名以\"_sd\"结尾，而衍生特征则以\"_dr\"结尾。利用这个命名规则以及在策略中使用特征时必须使用单引号或双引号包围的特点，我们可以制定一个正则表达式来匹配出各个策略中使用的特征。</p><p></p><p>目前，好分期面临100多个风控事件，并且对应的策略文件数量也超过100个的情况。其中一些复杂的策略文件大小可能达到3-4MB。如果按照传统的检索方式，在如此庞大的文件集合中查找引用的特征，必然会遇到效率缓慢的问题。</p><p></p><p>为了解决这个问题，我们引入了倒排索引的思想。在程序启动时，对策略文件进行预处理，提取出所使用的特征，并建立如下图的依赖关系。通过这种倒排索引结构，我们有效地解决了查询时间长和占用内存过大的问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e9/e9fdb37898886a3ee14e252f03586a17.png\" /></p><p></p><h2>五、上线后的效果</h2><p></p><p></p><p>目前，特征血缘关系已经成功上线到风控平台，并且在风险和模型同学中逐步推广开来。对于数据源和特征影响范围的定位，以及特征溯源和策略是否使用等相关场景，我们不再需要通过查询文档或咨询业务人员，而是可以通过一键查询功能来实现。这样做不仅极大地缩短了问题定位的时间成本，减少了超过90%以上的耗时，还避免了评估不当导致的特征遗漏现象。血缘关系作为底层的支持工具，已经成功支持了好分期多个项目的正常运转。</p><p></p><p>下面将介绍几个业务中真实的应用场景。</p><p></p><p>案例一：查询依赖指定数据源的特征</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e2/e24485d281d575a6c53ab1a5ba3424f5.png\" /></p><p></p><p>我们使用不同的节点颜色来区分节点类型，例如黄色节点表示数据源，蓝色节点表示特征。整棵树按照从左到右的方式展开，依次展示依赖于查询数据源的一级特征、二级特征、三级特征等。</p><p></p><p>通过这种直观的树状图，我们可以清晰地看出数据源的引用路径。如果由于三方问题导致的数据源分布抖动，我们也可以迅速评估影响范围。同时，这样的可视化展示也方便我们快速了解数据源与特征之间的依赖关系，帮助我们更好地管理和维护数据源，并及时应对可能出现的风险。</p><p></p><p>案例二：查询指定特征在具体事件步骤的上下游依赖</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/89/899d450ef1a79e781565508afa195e03.png\" /></p><p></p><p>查询特征节点支持展示具体到事件步骤级别的依赖情况。我们将事件和步骤作为节点的属性进行展示，在图中以冒号隔开的字段形式呈现。</p><p></p><p>通过这种方式，我们可以更详细地了解每个查询特征在具体事件和步骤下的依赖，可以帮助我们更加全面地理解特征之间的关系，并能够更准确地分析和处理相关特征间的相关问题。同时，也有助于快速评估特征对具体事件、步骤决策的影响，以便及时做出相应的调整和优化。</p><p></p><p>案例三：查询指定特征在策略中的使用情况</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/11/11b0b190d42d892bd51f06a748c60904.png\" /></p><p></p><p>我们使用表格形式展示策略和特征之间的依赖关系，以支持查看策略文件中哪个类型的哪一行代码引用了特定的特征。</p><p></p><p>通过这种展示方式，我们可以清晰地了解特征在策略文件中的引用情况。更方便地追踪特征与策略间的依赖关系，同时也有助于快速定位特征在策略中的调用位置，以便于进行相应的问题排查工作，提高工作效率并减少出错的可能。</p><p></p><h2>六、总结</h2><p></p><p></p><p>总的来说，好分期专注于构建一个全面且独特的特征血缘关系系统，并在实现方法上与当前存在的血缘关系技术有显著的区别。至今，我们已经形成了一套比较完善和高效的解决方案，对业务中的各种问题提供了有效的处理方式。</p><p></p><p>未来，我们计划深度挖掘特征血缘关系在不同领域的潜力：例如在评估特征价值、保证数据质量、识别数据孤岛等方面，使其能够为更多领域提供深入的应用。我们会继续发展并扩展这个系统的功能，以适应业务需求的持续发展。</p><p></p><p>我们坚信，通过不断拓展特征血缘关系的应用范围和深度，能够更好地理解数据的流动和变化，从而提高模型的准确性和风控效果，同时也能为用户提供更优质的服务。我们将持续投入，为未来的风控管理提供更强大的技术支持。</p><p></p><h4>作者介绍：</h4><p></p><p></p><p>倪继昌，微财数科 变量中心高级工程师</p><p>王黎明，微财数科 变量中心资深工程师</p><p>孙丽川，微财数科 风控平台资深工程师</p><p>李军，微财数科 技术负责人</p><p>吴迪，微财数科 副总裁</p>",
    "publish_time": "2023-12-11 10:43:06",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "网易杭州研究院 / 编程语言实验室 / 负责人张炜昕博士确认出席 QCon 上海，分享低代码编程语言 NASL 从设计到落地的闯关之路",
    "url": "https://www.infoq.cn/article/dcJEkHM7VklAVYVCFKSZ",
    "summary": "<p><a href=\"https://qcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=1211&amp;utm_content=zhangweixin\">QCon 全球软件开发大会</a>\"，将于 12 月在上海召开。网易杭州研究院 / 编程语言实验室 / 负责人张炜昕博士将发表题为《<a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5642?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=1211&amp;utm_content=zhangweixin\">低代码编程语言 NASL 从设计到落地的闯关之路</a>\"》主题分享，探讨 NASL 语言的设计初衷、设计原则、实现挑战、未来展望等方面。</p><p></p><p><a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5642?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=1211&amp;utm_content=zhangweixin\">张炜昕博士</a>\"，香港大学博士，布里斯托大学 Senior Research Associate，长期从事编程语言研究。现为网易杭州研究院编程语言实验室负责人，主导 CodeWave 智能开发平台编程语言 NASL 的设计。以第一作者身份在 TOPLAS，ECOOP 等编程语言期刊和会议上发表论文多篇，并获 ECOOP“杰出软件制品奖”和 Programming 期刊“编委会选择奖”。曾任 Scala 研讨会主席，IFL 程序委员，PLDI、OOPSLA 软件制品审查委员，以及多个编程语言会议的审稿人。他在本次会议的演讲内容如下：</p><p></p><p>演讲：低代码编程语言 NASL 从设计到落地的闯关之路</p><p></p><p>NASL 是由网易自研的全栈可视化编程语言，是支撑网易数帆 CodeWave 智能开发平台的基石。本次演讲将围绕 NASL 语言的设计初衷、设计原则、实现挑战、未来展望等方面展开。</p><p></p><p>演讲提纲：</p><p></p><p>NASL 的设计初衷</p><p>○ 为什么低代码平台需要编程语言</p><p>○ CodeWave 及 NASL 的简介</p><p>NASL 的设计原则</p><p>○ 低门槛、高上限</p><p>○ 记号的认知维度</p><p>○ 编程系统的技术维度</p><p>NASL 的实现挑战</p><p>○ 如何融合企业的 IT 资产</p><p>○ 如何降低实现成本</p><p>NASL 的未来展望</p><p>○ LLM 时代的编程语言设计</p><p>○ 文本语法和标准化</p><p></p><p>听众收益点：</p><p></p><p>○ 可视化编程语言和编程系统的设计原则</p><p>○ 降低编程语言实现成本的方法</p><p></p><p>除上述演讲外，QCon 上海还将围绕&nbsp;<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart\">GenAI和通用大模型应用探索</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1596?utm_source=infoqweb&amp;utm_medium=teacherart\">AI&nbsp;Agent&nbsp;与行业融合应用的前景</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart\">LLM&nbsp;时代的性能优化</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart\">智能化信创软件&nbsp;IDE</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart\">面向人工智能时代的架构</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart\">性能工程：提升效率和创新的新方法</a>\"等专题进行交流。</p><p></p><p>QCon 上海 2023，相约 12 月！ 9 折优惠仅剩最后 5 天，现在购票立减￥680！咨询购票请联系：18514549229（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/0113b3dfb187d5f9988b7eb16d2e0594.png\" /></p><p></p>",
    "publish_time": "2023-12-11 11:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "HubSpot 使用 Apache Kafka 泳道实现工作流操作的实时处理",
    "url": "https://www.infoq.cn/article/Lpl9RkDpEsMaAarXGccH",
    "summary": "<p>HubSpot 采用在多个 Kafka 主题（称为泳道，swimlanes）上为同一生产者路由消息的方式，避免了消费者群组滞后的积压，并且能够优先处理实时流量。通过自动和手动相结合的方式探测流量峰值，该公司能够确保大多数消费者的工作流能够在无延迟的情况下执行。</p><p></p><p>HubSpot 提供了一个业务流程的自动化平台，其核心采用工作流引擎来推动操作（action）的执行。该平台可以处理数百万个活动的工作流，每天执行数亿个操作，每秒执行数万个操作。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/6e/6e79061a9bdd0b4a3384b1a443c4220b.jpg\" /></p><p></p><p>工作流引擎概览（来源：HubSpot 工程博客）</p><p></p><p>大部分处理都是异步触发的，使用 Apache Kafka 进行传递，从而实现了操作的源 / 触发器与执行组件之间的解耦。该平台使用了许多 Kafka 主题，负责传递来自各种源的操作数据。使用消息代理的潜在问题在于，如果消息发布得太快，而消费者无法及时处理，等待处理的消息就会积压，这就是所谓的消费者滞后（consumer lag）。</p><p></p><p>HubSpot 的工程主管 Angus Gibbs 描述了确保近实时处理消息所面临的挑战：</p><p></p><p></p><blockquote>如果在主题上突然出现大量消息，我们就必须处理积压的消息。我们可以扩展消费者实例的数量，但这会增加基础设施成本；我们可以添加自动扩展，但增加新的实例需要时间，而客户通常希望工作流能够以接近实时的方式进行处理。团队认识到，他们需要解决的问题是对所有相同类型或相同来源的消息使用了相同的主题。考虑到该平台被许多客户使用，如果某一个或一小部分客户开始产生大量消息，那么所有的流量均会延迟，所有客户的用户体验都会受到影响。</blockquote><p></p><p></p><p>为了解决这个问题，开发人员选择使用多个主题，他们将其称为泳道（swimlanes），并为每个泳道配置专用的消费者池。应用这种模式的最简单方式是使用两个主题：一个负责实时的流量，一个负责溢出的（overflow）流量。这两个泳道以完全相同的方式处理流量，但是每个主题都有独立的消费者滞后，通过在两者之间适当地路由消息，可以确保实时泳道避免出现任何的（或明显的）延迟。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/88/88b9e608a34183304d29218f3658f742.jpg\" /></p><p></p><p>Kafka 泳道（来源：HubSpot 工程博客）</p><p></p><p>如果可能的话，系统会从发布的消息中提取元数据，基于此在泳道之间实现消息的自动路由。例如，批量导入所产生的消息可以在消息模式中明确标记出这种操作类型，这样路由逻辑就可以轻松地将这些操作发布到溢出泳道。此外，开发人员还引入了按客户配置来限制流量的功能，并且能够根据报文消费者的最大吞吐量指标设置适当的阈值。</p><p></p><p>决定如何在泳道之间路由消息的另一个角度是查看操作的执行时间。实际操作将被路由到一个泳道，而慢速操作将被路由到另一个泳道。这一点对 HubSpot 平台尤为重要，因为客户可以创建执行任意 Node 或 Python 代码的自定义操作。</p><p></p><p>最后，该团队还开发了将特定客户的所有流量手动路由到专用泳道的方法，以防来自客户的流量意外地在主（实时或快速）泳道上造成滞后，而此时自动路由机制均未启动。这样，在团队排查延迟原因时，就对流量进行隔离了。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/11/hubspot-apache-kafka-swimlanes/\">https://www.infoq.com/news/2023/11/hubspot-apache-kafka-swimlanes/</a>\"</p><p></p>",
    "publish_time": "2023-12-11 14:33:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "深度解读“百度智能云数据库”的演进：互联网→云计算→ AI 原生",
    "url": "https://www.infoq.cn/article/Z1mDYGshu9o8IfXGVcXg",
    "summary": "<p></p><h2>一、数据库行业发展概述</h2><p></p><p></p><p>如果说今年科技圈什么最火，我估计大家会毫不犹豫选择 ChatGPT。ChatGPT 是 2022 年 11 月 30 日由 OpenAI 发布的聊天应用。它创造了有史以来用户增长最快的纪录：自 11 月 30 日发布起，5 天就拥有了 100 万活跃用户，两个月就达到了一亿用户。对比其他热门应用，同样达到一亿用户量级，TikTok 花了九个月，而像 Instagram ，Whatsapp 等应用则超过了两年时间。</p><p></p><p>ChatGPT 的爆火，瞬间点燃了整个 AIGC 赛道。最关键的原因在于，它让大家看到了弱人工智能向强人工智能的跨越式发展。英伟达 CEO 黄仁勋对此评价：ChatGPT 相当于 AI 界的 iPhone 时刻。</p><p></p><p>现在业界统一的共识是，AIGC 会改变 IT 行业的方方面面。那 AIGC 对数据库会带来哪些变化，AIGC 和数据库又会碰撞出哪些火花，这是一个值得我们去思考和回答的问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/64/648f846dd8384dfa9a1fc1a1ea4abf3e.png\" /></p><p></p><p>在回答 AIGC 对数据库的变革和影响之前，让我们先回顾下数据库发展历史。它可以分为六个阶段。</p><p></p><p>第一阶段是上世纪五十年代。这个时候数据库还在雏形阶段，以层状数据库和网状数据库为主，基础设施以大型机为主，主要用于国防和科学研究。</p><p></p><p>第二阶段是上世纪七十年代。关系型数据库出现，硬件也变成了小型机，这也奠定了数据库发展的方向。主要应用在金融，交通等关键行业。这时的代表数据库是 Oracle 和 DB2 等。</p><p></p><p>第三阶段是上世纪九十年代。PC 机已经得到了普及，数据库除了关系型数据库，也有了 PC 单机数据库。为解决企业 BI 应用诉求，数仓开始出现。数据库的应用也更多样化起来，进一步应用到企业 BI、个人办公、娱乐等场景。</p><p></p><p>第四阶段是本世纪的前十年。随着互联网开始繁荣，数据处理的需求逐渐增加，开始出现企业数据中心。业务也变成了媒体、搜索、电子商务、社交等互联网业务。由于传统数据库如 Oracle 因为价格较贵，互联网厂商大量使用开源数据库如MySQL、Redis、MongoDB 等。整个开源数据库生态开始逐渐繁荣。数据库的种类，厂家也逐渐变多。</p><p></p><p>第五阶段就是我们今天所处的云计算时代。典型应用包括新媒体、各种移动 APP、物联网、娱乐、短视频等。典型的数据库有 RDS、Aurora 等云数据库，以及 Oceanbase、CockroachDB 等分布式数据库。百度也有对应的产品，云原生数据库 GaiaDB 以及我们自研的缓存类数据库&nbsp;PegaDB 等。</p><p></p><p>第六个阶段是自 2023 年开始的 AI 时代。底层基础设施变成了 GPU 和 AI 能力。应用也变成了 AI 原生应用，如海外比较火的 Jasper、Midjourney，微软的 Copilot 等。在数据库行业我们看到至少两个方向，一个是 AI4DB，其中包括阿里的 DAS、百度的 DSC 等，主要是通过 AI 的能力去改进原有数据库的自动化能力。另外一个方向就是 DB4AI，目前主要是向量数据库。向量数据库在解决大模型幻觉等方面，有非常不错的效果，是一个有潜力的细分赛道，头部公司估值已经达到 10 亿美元。</p><p></p><p>以上就是数据库 70 年波澜壮阔的发展史。我们可以看到，每隔一段时间数据库就会在基础设施、应用场景、以及数据库本身，都有不断地变更和创新。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/92/92a9b7ae192ebfb33a9091bbf57857a1.png\" /></p><p></p><p>上面我们简单回顾了数据库发展的六个阶段。在这个过程中，我们还可以以 2000年做分界线。在 2000 年前，国内数据库基本上被 Oracle 等海外数据库主导。而从 2000 年之后，随着互联网业务的发展，国内多个互联网厂商如阿里、腾讯、百度便开始尝试使用开源数据库，实现了从最早的运维、到提交 patch、再到最后完全自研数据库的跨越式发展。</p><p></p><p>这背后从量变到质变的过程是一个典型基础软件发展过程。</p><p></p><p>一个基础软件真正得到长足发展，需要一大批高素质的技术人员，也需要深度场景的使用才能不断完善产品。另外丰富的场景和不断发展的业务，也能长期养活这批技术人员，进而形成正循环。所以说数据库的发展依赖于技术和业务的双轮驱动。</p><p></p><p>从 2000 年开始，我们看到三波浪潮——互联网，云计算和 AI 原生。我们接下来会分别来讲一下每一波浪潮为数据库行业带来的创新和变化，以及百度智能云数据库在这个过程中的关键技术和代表产品。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f6/f647b07b8603129ba05898417ae77eb5.png\" /></p><p></p><h2>二、百度智能云数据库发展史</h2><p></p><p></p><p>互联网业务特点是赢家通吃，所以互联网业务用户数规模通常比较大。因此天然要求数据库支持大规模、高可用、高可靠性、低成本以及高性能，这对数据库提出了非常大的挑战。</p><p></p><p>在第一波互联网业务的发展中，业务的挑战催熟了一系列开源数据库如 MySQL、Redis、MongoDB，又从中孵化出了分布式数据库。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/20/20e33da0350e46cb356adc79012f78ed.png\" /></p><p></p><p>接下来我们来看下百度在互联网时代的数据库发展历程，这里有几个关键节点：</p><p></p><p>第一个是自 2005 年开始使用 MySQL 数据库，这也是国内最早使用 MySQL 的企业之一。</p><p></p><p>第二个是 2014 年百度推出公有云服务，百度数据库的能力通过<a href=\"https://www.infoq.cn/article/WrlUWpf2OkgQsSAD6NJ1?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">百度智能云</a>\"开始赋能给外部企业。</p><p></p><p>第三个是 2020 年发布了云原生数据库 <a href=\"https://xie.infoq.cn/article/61a867abe6d45fa9f1fe644d0?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">GaiaDB</a>\"。百度也成为了国内少数几个具备自研云原生数据库云厂商之一。</p><p></p><p>截至目前，百度积累了 18 年的数据库研发经验，承载着内部 PB 级数据。10 万+ 的节点至今零故障零损失。</p><p></p><p>通过百度智能云输出的一站式产品，覆盖 RDS、NoSQL、OLAP、工具等领域，同时具备公共云、私有云、边缘云等软件版本多形态。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0f/0f0fe561b919a46ca824f31f4f556ce5.png\" /></p><p></p><p>前面我们提到了互联网的一大特点，就是规模大。单点肯定处理不了，所以需要引入分布式技术，也催生了分布式数据库的诞生。</p><p></p><p>百度在该领域也有非常成熟的技术，讲两个实际的案例：</p><p></p><p>第一个是<a href=\"https://www.infoq.cn/article/2012/03/baidu-bae?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">百度网盘</a>\"。百度网盘有 8 亿用户，整个数据库中单表最大超过 10 万亿条记录。整体集群超过 3000 台服务器，是国内最大的数据库集群之一。</p><p></p><p>第二个是金融行业。大家都知道金融行业对一致性、数据准确性有非常高的要求。度小满金融有 3 亿用户，年度结算金额超过万亿，其底层使用的就是百度智能云分布式数据库 GaiaDB-X。</p><p></p><p>尤其值得一提的是在 2019 年春晚红包业务中，整体交易的峰值是 12 万笔/秒。数据库的分布式能力、性能、一致性、准确性都得到了充分验证。</p><p></p><p>除了度小满，百度智能云的数据库还在多家国有大行、股份制银行和城商行中稳定运行。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/72/72d4145b2e5cf4609d5969fcd0c828a2.png\" /></p><p></p><p>互联网业务除了规模外，对性能、并发等也提出了很高的要求，因此诞生了一系列 NoSQL 数据库。不同的 NoSQL 数据库从不同层面解决互联网垂直场景的问题，今天我们讲其中的代表 Redis。</p><p></p><p>百度智能云的 Redis 服务经历十几年的技术积累和业务打磨。从规模上来看，节点规模超过 30w，其中单集群最大规模节点数达到 2700。从业务支持上看，百度 Redis 覆盖支撑了百度内部全场景业务，其中包括搜索广告、手百、地图、小度等一系列亿级用户体量的产品，为业务提供 4 个 9 以上高可用性以及微秒级请求时延服务，始终为客户提供稳定、高效、弹性可扩展的智能缓存服务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/84/8471c3e34b3cef8ce9d5754cd03b193c.png\" /></p><p></p><p>Redis 直接使用内存，但内存带来高性能的同时成本是比较贵的。因此一款能兼顾性能和成本的 Redis 产品是客户迫切需要的。考虑到业务中大量的数据是可以根据场景分出冷热的。比如视频直播、新闻/内容平台、电商场景中，随着时间的推移，数据的价值和使用频率都在下降。所以可以将部分数据自动迁移到磁盘中，从而降低存储的整体成本。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/82/8240196a262dd1948b2f1a0a9babe152.png\" /></p><p></p><p>为了解决性能和成本的平衡问题，百度智能云自研了 PegaDB。PegaDB 是在开源基础上自研的容量型 Redis 产品，相比内存型产品最多节省超过 90% 的存储成本。在成本下降的同时，PegaDB 也兼容了 Redis 丰富的数据类型和命令，让用户做到无缝迁移，兼顾了用户体验和性能优势。</p><p></p><p>除此之外，PegaDB 还有两个杀手锏功能：</p><p></p><p>一是支持在线弹性伸缩，单个集群最大规模可达 PB 级别。对用户来说不用估计使用量，只要傻瓜式即开即用即可。</p><p></p><p>第二个是支持 CRDT 同步的组件，支持异地多活和多节点同时访问、自动进行冲突合并等功能。这就让客户专注于实现业务逻辑，其他的都交给底层的数据库，完全不用操心可用性问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/82/8247c1d27f22bf8d13326b6df3fa1270.png\" /></p><p></p><p>随着云业务的诞生，让数据库的价值进一步放大。为了赋能千行百业，全托管等形态的 RDS 顺利成章的诞生了。它解决了客户最直接的安装、运维、管理等问题，因此全托管的 RDS 就逐渐推广开来。</p><p></p><p>但单体 RDS 通常有比较明显上限，在一些对性能、成本、弹性有一定要求的复杂业务中，就需要一个更强大的数据库来解决这些问题。因此，存算分离的云原生数据库就自然而然诞生了。百度智能云的云原生数据库 GaiaDB 是其中的代表之一。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1e/1e835b194141802f859a373b37363990.png\" /></p><p></p><p>RDS 全托管的产品形态代表了云计算从软件到服务的理念转变。云原生数据库极大地提高了 MySQL 数据库的上限能力，是云数据库划代的产品。</p><p></p><p>云原生数据库最早的产品是 AWS 的 Aurora。AWS Aurora 提出来的 The log is the database 的理念，通过把大量的日志操作放到后台异步处理，实现了存储独立扩展和存储计算分离，从而解决了 MySQL 数据库单库的数据量不能太大的最大痛点。</p><p></p><p>而云原生数据库在存储层面实现了扩展的同时，又保留了计算层面的不变和兼容。这种兼容 + 扩展的能力，受到了客户的极大欢迎，一下子就让云原生数据库成为各个厂商的发展重点。云数据库技术也标志着云厂商的产品能力开始和传统数据库厂商、开源产品开始拉开差距。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dd/dd48508403406795d06e50dffdebbe2f.png\" /></p><p></p><p>百度智能云的 GaiaDB 在 2020 年首次推出，除了具备云数据库的优点之外，GaiaDB 还有很多独特的技术能力，接下来我来分享其中 5 个代表能力：</p><p></p><p>第一个是共识协议。一般使用 Raft/Paxos 分布式协议的数据库，单次 I/O 需要至少两次网络往返，而且无法并行。这也就导致了分布式数据库时延很高，长尾问题更突出。</p><p></p><p>针对这个问题 GaiaDB 创新采用了 Raft 和 Quroum 结合的协议。其中 Raft 负责控制流，Quorum 负责数据流，进而减少网络往返。同时核心链路上的同步 I/O 变成异步 I/O，在保证分布式一致性的前提下，吞吐提升了 40%，时延降低了 30%。</p><p></p><p>第二个是高性能智能网络。存算分离在带来分布式和弹性的同时，也引入了网络 I/O 的消耗，因此网络 I/O 的性能和效率直接影响整个系统的表现。GaiaDB 采用高性能智能网络，这个网络有几个关键技术能力：</p><p></p><p>网络超时重定向机制。当远程 I/O 超时，会自动尝试其他副本，从而抑制单节点长尾问题。网络支持用户态协议。该协议减少了内核态 TCP 和用户态 TCP 的数据库拷贝。通过对网络的优化，平均时延从毫秒级别降低到微秒级别，提升 20 倍以上。</p><p></p><p>第三个是提供了三副本对等存储能力。由于采用了 Quorum 分布式共识协议，相比传统的 Raft 模型，每个节点都可以独立提供读写服务，没有单点故障。</p><p></p><p>第四个是多地多活。GaiaDB 是目前业界唯一可以做到多地多活的云原生数据库。在多地部署的时候，GaiaDB 模块的自适应就近访问策略可以感知元数据的变化，并根据这些变化及时切换访问路线。这种策略可以有效地应对各种故障和异常情况，确保数据的可靠性和可用性。</p><p></p><p>第五个是使用通用硬件，对硬件要求低。GaiaDB 生于云，但同时 GaiaDB 的架构对硬件的依赖度非常低。我们和很多厂商使用高性能硬件的思路不同，我们认为云的价值是普惠，所以一定要让通用服务器能发挥专业数据库的能力。因此，不同于很多云原生数据库需要依赖底层高性能的硬件，GaiaDB 从设计初就坚持使用通用服务器。因此在私有云场景下，三个节点就可以进行部署，让我们的客户可以低价享受到云上云下一套架构。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8b/8b7c7ed3a0879eebe3cc8ba586055484.png\" /></p><p></p><p>接下来我们来看一个 GaiaDB 的实际案例——百度地图。</p><p></p><p>百度地图是国民级别应用，日活用户 5.6 亿，PB 级数据。这对数据库也提出了如下的挑战：</p><p></p><p>为了保证高可用，需要多地多活的能力。节假日地图搜索，导航流量会出现十倍的上涨。这就要求在节假日需要非常顺滑的扩缩容的能力。</p><p></p><p>大规模数据量、异地多活、弹性扩缩容要求，这些要求对数据库是极大的考验。</p><p></p><p>在实际使用过程中，GaiaDB 提供 4 个 9 的可用性，RTO 切换小于 3s，RPO=0，整体 QPS 超过百万级别，给业务实现超过 60% 的资源成本节省。</p><p></p><p>总的来说，GaiaDB 成功帮助百度地图实现了极致的弹性和成本。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8f/8f02e4b25fba325d4854e72f711bde58.png\" /></p><p></p><p>云上数据库和线下数据库相比，一个较大差异就是生态能力强。相比传统线下软件只有 1~2 款产品，线上有多种数据库与多种使用环境，因此数据库矩阵更丰富，这带来了对数据库工具的诉求。</p><p></p><p>百度智能云有丰富的数据库工具，包括数据传输 DTS、数据库智能驾驶舱 DSC 等产品。我们先讲其中的代表 DTS。</p><p></p><p>百度智能云的 DTS 采取了中间抽象的数据格式，通过中间格式的翻译和转换，可以轻松做到异构迁移能力。同时 DTS 在吞吐上可以做到每秒 15 万行，延迟做到毫秒级别，基本等于网络的延迟的性能，让客户可以放心使用 DTS 来做数据库的迁移和同步。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0e/0e0d44ff1229d468f704af06b132010e.png\" /></p><p></p><h2>三、AI 原生时代的百度智能云数据库</h2><p></p><p></p><p>在 AI 原生时代，数据库和 AI 的结合主要有 DB4AI 和 AI4DB。</p><p></p><p>首先是 AI4DB，就是利用 AI 技术赋能数据库。常见场景有智能运维、智能客服、参数优化等等，刚刚提到的百度智能驾驶舱就是该领域的代表。</p><p></p><p>另外一个方向是 DB4AI，通过数据库赋能 AI 产品。当前最火的就是向量数据库。向量数据库二次的翻红主要原因是向量数据库在解决大模型幻觉、知识更新不及时有很大作用，让向量数据库的想象空间一下子变大了。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/09/096c6ccafce7598fdac1f73dfb471e4f.png\" /></p><p></p><p>AI4DB 在工业界一直有研究。相比传统机器学习算法，大模型让 AI4DB 真正走进实用时代。利用大模型的能力，百度智能云数据库发布新服务：数据库智能驾驶舱。</p><p></p><p>数据库智能驾驶舱利用最新的大模型能力，实现数据库智能化的洞察、评估和优化。根据我们的实际测试效果，优化效果非常显著：</p><p></p><p>数据库故障洞察方面，相比传统的人工定位提升 80%。领先的智能评估系统，相比传统的方法提前一个月发现数据库的容量瓶颈，规避相应的风险。AI 驱动的 SQL 优化方面，可以带来 40% 以上的提升。</p><p></p><p>相比传统基于规则的算法，大模型带来了更好的优化效果和更少的开发时间。大模型带来的切实提升让 AI4DB 走向真正的实用时代，也让数据库自感知、自修复、自优化、自运维成为现实。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a9/a9cd6b1eab7842cbdba2f1e03555c143.png\" /></p><p></p><p>下面我们来看下数据库智能驾驶舱内置的一个能力——智能问答。</p><p></p><p>这个功能可以帮助用户诊断产品问题并回答各种疑问，降低人工投入。这里面用到了大模型通用知识的能力，同时也利用 RAG 技术，把云产品文档、数据库的官方文档、内部积累的知识库进行向量化并存在向量数据库中。</p><p></p><p>在查询的时候，结合大模型和向量数据库的能力，可以给出相当准确有效的答案。</p><p></p><p>目前数据库智能驾驶舱经过验证，对历史客户工单中真实问题进行回答然后由人工进行打分，整体回复平均超过 4 分，基本可以媲美普通售后工程师的水平。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/79/79b670cada64634f9bf5577ab757d963.png\" /></p><p></p><p>接下来我们实际来看下智能问答的一个 demo。</p><p></p><p>左边的例子是询问知识库里面已有的例子，比如怎么购买，怎么实现一个读写分离的配置等。智能驾驶舱都总结得比较好，回答也非常准确。</p><p></p><p>右边的例子是询问知识库中没有的例子。我们可以发现，智能驾驶舱利用大模型的能力，可以举一反三，把解决问题的步骤给出来。我们人工去检查也会发现，这个步骤还是相对比较合理的。</p><p></p><p>所以现在智能驾驶舱的智能问答可以做到：有资料的问题准确回答，无资料的问题也可以给出相对清晰的解法。百度智能云内部已上线了该功能，大大节省了人力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/48/48ba6c7615d86cfd011247f99b44be3e.png\" /></p><p></p><p>DB4AI 的典型代表就是向量数据库。向量检索并不是一个新技术，2017年 Meta 就开源了相似度检索库 FAISS，算是向量化检索的开山鼻祖。</p><p></p><p>传统数据库解决的是结构化数据的存储和检索，非结构化数据需要先用 AI 算法 Embedding 成向量数据。需要查找的时候，把需要查找的数据的向量带过来，然后在库里面进行相似度检索。</p><p></p><p>而向量数据库核心能力就是支持向量数据存储，以及支持不同的查找算法和索引实现相识度查找。当前业界有两种不同的实现方式，一种是在传统数据库中增加插件或者功能支持向量的查找，比如 PG，Redis 都支持向量索引。这种实现相对来说容易一些，但同时性价比会差一些，通常会占用更多内存。另外一种是专业的向量数据库，专门为向量重新设计的存储和索引结构，能实现更高的性价比和弹性。</p><p></p><p>传统应用也有不少向量场景。典型场景有平安城市视频检索、电商领域以图搜图等。由于传统场景比较垂直，因此一直没有一个大的向量数据库，更多的是耦合在业务系统中。而在大模型时代，万物皆可向量化。而且当前大模型主要问题有知识更新不及时、精确性问题、数据权限管理等问题，都需要向量数据库来补充。向量数据库也因此成为大模型的标配，也在大模型时代二次翻红。</p><p></p><p>百度智能云自研的专业向量数据库目前在内测阶段，根据我们内部实际测算，在成本、规模、高性能算法、内置 Embedding 模型、向量 + 标量的联合查询方面，相比业界有很大的提升。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9b/9b9f6fcb6d97c8979c5bbbdfe17c3e09.png\" /></p><p></p><p>前面我们介绍了关键的产品，最后简单回顾一下百度智能云产品矩阵。</p><p></p><p>百度智能云数据库完整支持 RDS、NoSQL、云原生数据库，OLAP 等产品。相比业界其他云厂商，百度智能云数据库有两个显著特点：</p><p></p><p>百度智能云的数据库产品可以做到一套架构，云上云下客户享受同等的产品能力。支持国内最全的产品形态，包括公共云、私有云、边缘节点、LCC 等多种形态，可以服务各类诉求的客户。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fc/fc846845a37a6dac8eac882ad434be70.png\" /></p><p></p><p>前面我们盘点了数据库在互联网、云计算，AI 原生 3 个阶段的发展。除了技术之外，我们认为云数据库未来还要坚持两个重要的理念。</p><p></p><p>第一个是体验优先。一个好的数据库不能只是性能、成本这些方面。体验好的产品，可以让用户做到自服务。体验优先这一点在海外 SaaS&nbsp;产品中体现得更为明显。在国内，这一理念也逐渐取得从业者的认可。因此，在过去的半年里面，我们从文档、控制台、产品功能各个层面进行了深度优化：</p><p></p><p>文档：文档是用户使用和理解产品的重中之重，因此我们做了包括优化结构、补充用户场景、刷新细小的优化点在内的大量工作，目的就是让用户在使用过程中可以更方便找到自己所需要的内容。控制台：在控制台优化上，我们优化了整体结构，让用户可以更简单找到想用的功能，总共优化点超过 100 处，让用户更容易上手。产品功能：我们针对数据库的产品功能系统性安排测试定期的盲测、新员工使用等，仅仅上半年就优化了 50+ 个突出的易用性问题。</p><p></p><p>我们对体验的理解就是从用户视角入手、坚持细节、系统性的进行优化，只有通过这种深度，全方位的持续改进，才能把体验做到实处。</p><p></p><p>第二个是开放生态。丰富的生态是吸引客户、解决客户多样诉求的关键。也只有开放的生态，才能让更多的厂商一起服务好客户。</p><p></p><p>生态方面，百度秉承更开放的心态和第三方厂商合作。上半年我们和工具领域知名创业公司 NineData 正式合作，接下来会马上官宣另外一个合作厂商。</p><p></p><p>相比其他厂商，我们合作的过程也不只是简单的云市场合作。我们会和合作伙伴一起进行产品共建、优先推荐合适客户给合作伙伴、首页曝光和联合的品牌活动，增加合作方的知名度。</p><p></p><p>通过一系列的手段和措施，我们希望给到合作伙伴的是切实效果。百度智能云合作的理念就是更开放，让利合作伙伴。欢迎更多的合作伙伴和百度联系，一起服务好我们的客户。</p><p></p><p>总的来说，一个体验优先，生态开放的云，一定是客户最需要的云，也是真诚服务客户的云。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/df/dfc3dc9e74526dc0f5a93b8a4fa32c72.png\" /></p><p></p><h2>四、数据库未来的趋势展望</h2><p></p><p></p><p>站在当前看未来，数据库当前有四个关键发展趋势</p><p></p><p>AI Native。像大家比较头疼的 Oracle 转 MySQL 或者 PG，随着 AI 改写的到来，整个过程预计会变得很简单。Serverless。已经是海外云数据库的默认选项了，预计 1~2 年之后，serverless 就会在国内变得更普及。各个厂商也都会推出 serverless 数据库产品，这也是未来云产品的终极形态。内置 HTAP。HTAP 前段时间很火，不过我们判断 HTAP 很难成为一个单独的赛道，更多的是会成为各个 TP 数据库的内置能力。湖仓一体。湖仓一体预计会成为数据仓库的主要形态，不支持湖的数仓可能会很难生存，只有支持湖才能解决更多的数据问题，才能降低存储的成本。</p><p></p><p>技术和产业发展都很快，百度智能云数据库持续跟进最新的技术趋势，用优质的产品和真诚的服务回报我们的客户。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3f/3f7dafca36b251342c7b9668e005b1a4.png\" /></p><p></p><p></p>",
    "publish_time": "2023-12-11 14:50:27",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "分布式数据库 GaiaDB-X 金融应用实践",
    "url": "https://www.infoq.cn/article/2VG5NR6sg8QFttMMyQw5",
    "summary": "<p></p><h2>一、银行新一代核心系统建设背景及架构</h2><p></p><p></p><p>在银行的 IT 建设历程中，尤其是中大行，大多都基于大型机和小型机来构建核心系统。随着银行业务的快速发展，这样的系统对业务的支持越来越举步维艰，主要体现在以下四个方面：</p><p></p><p>首先是难以支持银行快速发展的业务。随着国内电商、互联网支付、手机支付的迅猛发展，银行的交易量出现指数级的增长。比如我们的某银行客户，当前每秒的交易量峰值在一万多左右，预计在未来几年会逐渐增长到每秒 6 万笔交易，而且后续还会继续增长。在这种情况下，基于大型机的集中式架构，单纯靠硬件的升配，已经无法支持业务的持续增长。第二是难以匹配银行系统的迭代更新速度。原有的基于大型机的胖核心架构，迭代周期往往在数月甚至半年。但随着银行间、以及银行与互联网金融企业之间的竞争加剧，银行迫切需要快速推出新业务进行创新，他们也希望能够像互联网公司那样，能够按周级进行快速迭代，快速响应业务需求。第三是系统风险。银行业迫切需要做到软件及硬件的自主可控。第四是生态封闭。大型机技术发展慢、人才难招。现在再去外面招一个懂 IBM 大型机的人已经很难了。</p><p></p><p>因此，在国家现有政策的引导下，各大银行最近几年都在做一个事情：把原有的核心架构从大型机下移到传统的通用服务器架构上，并建设一套自主可控的新技术体系，简称核心系统下移。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d2/d2eebfc9abdbfbf4124d2a6b76ebcb3c.png\" /></p><p></p><p>在进一步理解银行系统之前，我们先了解下银行客户的业务体量、业务需求以及核心系统对业务支持情况。以一个国有大行来举例：它的客户量在 5-7 亿，有 10-20 亿账户，在全国有 2-4 万个网点。从每秒峰值交易量来看，约为每秒 5-8 万笔交易。</p><p></p><p>具体到数据库层，支持以上业务还需要联机交易系统，例如存贷汇业务。数据库层最大的表有百亿级记录数，TPS 达到百万级。此外，统一查询业务要求支持近十年交易明细的查询，即万亿级的查询记录数。即使放到互联网公司用的通用服务器，也是需要上千台服务器才能支撑相关业务的开展。</p><p></p><p>通过以上的介绍，大家可以发现，银行客户的业务体量和数据量已经达到了大型互联网公司的量级。如果想把这个系统从大型机下移到通用服务器架构，那么原有的集中式架构肯定是无法满足的，必须像互联网公司一样采用分布式架构。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5e/5ede303f87fe7f77d969325bf8b0660f.png\" /></p><p></p><p>因为银行有和大型互联网公司相近的业务体量，因此在技术体系上，也借鉴了互联网公司的技术体系。</p><p></p><p>从 IaaS 层来看，银行采用了 X86、ARM 架构的通用服务器，也用到了混合云技术，大量使用了虚拟机与容器服务。</p><p></p><p>在 PaaS 层，银行使用了大量的分布式系统，如开源的微服务框架（例如 SpringCloud ），以及开源的或者商业的数据库，包括分布式/单机/关系型/缓存型的数据库，以及日志数据库 ES、时序数据库等。在中间件层，也用到了大量的开源的或者基于开源改造后的组件，例如消息队列、对象存储、分布式锁等。</p><p></p><p>在 SaaS 层，银行主要通过单元化 + 微服务的架构来实现分布式扩展。银行将自身业务应用划分成三种单元。</p><p></p><p>最上层是全局单元，主要是起到全局路由及流量分发的作用。第二层是业务单元，核心的业务逻辑都在该部分来实现。同时，为了实现业务的横向扩展并支持数亿客户量，银行业跟互联网公司一样，对业务进行单元化拆分。例如我们接触到的某银行，就是将自身的业务拆分为了 16 个业务单元，每个单元五千万客户， 16 个单元部署在两个机房形成同城双活的架构。最底层是公共单元，一些不太好或没必要做单元化拆分的应用，放在公共单元提供公共服务。</p><p></p><p>通过上述分析可以看到，在新一代银行核心系统里面，整体的架构体系已经和互联网公司很接近了，大家用的都是相同的技术栈，只是服务的业务场景不同。在未来，银行业跟互联网业的技术交流会进一步紧密，人才的流动也会进一步频繁。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6d/6dada50bc1d570cafbcad31f40a441dc.png\" /></p><p></p><p>在业务采用了单元化划分后，数据库的架构是怎么样的呢？目前在银行的新核心系统下移中，主要采用了以下两种数据库架构：</p><p></p><p>第一种是单机数据库架构。这种数据库架构比较简单，故障域较小，但相对来说业务系统会比较复杂。因为有些模块，如全局路由模块，是全局的总入口，没法做单元化拆分。因此一组单机数据库无法满足性能与容量需求，依然需要在业务层做数据拆分。除此之外，单机数据库无法完全支持业务单元层的业务落地。前面提到，我们接触到的某银行一个业务单元要承担五千万的客户数，一组单机数据库依然无法支持。于是在业务层进一步拆分为 4 组数据库共 64 张子表，业务层需要去解决大量的拆分及分布式事务相关的业务逻辑，整体就更复杂了。</p><p></p><p>另外一种是分布式数据库架构。这样的数据库内部架构虽然更为复杂，但它可以提供更好的性能。对业务层来说，一个单元采用一组数据分布数据库即可，业务层的逻辑就更为简单了。</p><p>因此我们认为，随着分布式数据库的逐步成熟与应用逐渐广泛，业务单元化 + 分布式数据库会逐渐成为流行的银行业务架构。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/18/1805f802303d1452f0ddc0dcf9e08ef3.png\" /></p><p></p><p>综上，银行核心系统在下移的场景下，对数据库在如下几个方面提出了要求：</p><p></p><p>第一是分布式扩展性。由于采用了通用服务器，它的单机性能要远弱于大型机或者小型机。在这种情况下，数据库需要具备分布式可扩展的能力来满足上亿客户的金融需求。第二是强一致性。金融场景对数据正确性、一致性的要求极高。因此要严格保障对事务的 ACID 特性。否则，业务层就要做大量的工作。第三是容灾能力。通用服务器在硬件故障率方面要比大型机、小型机高很多。因此需要我们的数据库有更为可靠的可用机制以保障 SLA。同时，监管对于容灾能力的要求也在不断提升。比如，对于新建设的核心系统，监管要求必须满足 5 级以上的容灾能力，且满足同城双活并保证 RPO 为 0。在具体执行上，监管的要求也越来越严格，比如同城双活，之前是只需要具备相关的技术方案即可，但现在每年人行的监管都会直接到现场，要求做机房级实战故障切换。第四是运维能力。系统下移到通用服务器并实现去 IOE，数据库节点数量要出现 50 倍的增长。以我们的一个银行客户举例，从小型机下移后，数据库节点数从 20 增长到 1000（当然这里面也预留了几倍的性能增量）。在和客户的交流过程中，他们也认同这个观点，认为系统下移后，节点数要增长一到两个数量级。但运维的人力不可能因此增加几十倍，在这种情况下，就要求我们的运维效率要有质的提升，需要能够智能化、自动化去做相关的运维工作。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9e/9e70f9a0a35e389e4bda5d5de854c137.png\" /></p><p></p><p></p><h2>二、分布式数据库&nbsp;GaiaDB-X 的金融场景方案</h2><p></p><p></p><p>接下来我们分享第二部分，分布式数据库 <a href=\"https://xie.infoq.cn/article/1febbf974afe91b9a1e11517f?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">GaiaDB-X</a>\" 针对金融场景的解决方案。</p><p></p><p>GaiaDB-X 数据库是<a href=\"https://www.infoq.cn/article/WrlUWpf2OkgQsSAD6NJ1?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">百度智能云</a>\"研发的 Shared Nothing 架构的分布式数据库，它可以基于通用服务器做横向扩展，来满足高性能、大数据容量的需求。</p><p></p><p>总体来看它分为计算层、存储层、元数据三层架构：</p><p></p><p>计算层是无状态、可横向扩展的一层。它对外兼容 MySQL 协议，接收到 SQL 请求后，再经过 SQL 解析、权限检查、逻辑优化、物理优化之后，生成 DistSQL 下发到各个存储层的分片。为了达到更好的性能，逻辑与物理上尽量将数据过滤及计算能力下推到存储层，收到结果后，再把数据进行聚合计算，最后返回给客户端。计算层的下面是存储层。它采用多分片的方式进行扩展，数据按照一定的分片规则打散到了各个分片中。我们支持 Hash、Range、List 等分区方式来做数据分区。同时，分片内数据采用多副本的方式来保证可靠性，第三是 GMS 节点，即全局元数据管理模块。它用来管理全局性数据，例如表的 Schema 信息、权限信息、表的路由信息，还有后面要介绍到的用于做分布式事务的全局逻辑序列号。GMS 也采用多副本的方式，采用 Raft 协议进行数据同步。</p><p></p><p>在最底层是我们的统一数据库管控平台，来实现对数据库集群的管理。比如在<a href=\"https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA%3D%3D&amp;chksm=fbeb6a36cc9ce320cf9c590dcbaa67d53421a43a56ea8378ce2b96f0c1c3c3f17265ea54d9b9&amp;idx=1&amp;mid=2247570425&amp;scene=27&amp;sn=bc5f1eeba437ce5e619ccef9bc0321d3&amp;utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search#wechat_redirect\">百度</a>\"集团内部数十万的数据库节点，都是由该管控平台来管理的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/50/50f58801a7c4eeb2bddfece8e453df59.png\" /></p><p></p><p>GaiaDB-X 数据库是百度集团发展历史最久、应用最广泛的一款数据库，到现在为止已有 18 年的发展历史。它的发展也与百度的业务发展息息相关，大概可以归纳为四个阶段：</p><p></p><p>第一阶段是从 2005 年开始，为了满足搜索、社区业务中大量读请求的场景，我们通过一主多从的集群化外加读写分离来扩展读性能。第二阶段是为了支持凤巢广告系统与百度网盘，满足它们对万亿级数据量的需求，我们开始做分布式系统。到了 2014 年，我们就已经在凤巢广告系统中替换了基于 Oracle 的盘柜，为凤巢每年节省了上千万的成本。针对百度网盘，我们有个 3000 台服务器的集群支持网盘业务，所有网盘文件的元数据信息都存储在这里，最大的表达到万亿级记录数，至今仍是国内最大的关系型数据库集群之一。第三阶段是随着百度钱包等泛互联网业务的兴起，对数据的一致性要求更高了。因此，我们实现了分布式事务强一致的特性，保障金融数据的正确性。第四阶段，也就是现在。随着百度智能云对外技术输出，我们已经把数据库输出到了十余个行业，覆盖 150 家客户。在金融行业，GaiaDB-X 已经承接了金融核心业务，包括百信银行、银联商务、某交易所及国有行等。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/43/43f859c5ceefd365e4a3567012ce9242.png\" /></p><p></p><p>对于分布式数据库，水平扩展能力是其核心能力。除了在计算层与存储层做水平扩展外，我们还要着力去解决影响我们扩展能力的单点。</p><p></p><p>第一个是 GMS，即全局元数据模块。因为它要提供一个全局递增的全局逻辑时钟，每一次事务都需要调用它。为了避免其成为瓶颈，我们采用批量预分配的方式来提升其总吞吐，在此模式下，其每秒可分配 1200 万个 TSO 序号，远超出百万级 TPS 的需求。</p><p></p><p>第二个是全局事务表。为了保证分布式事务的原子性，我们需要将正在进行中的事务保存到一张全局表中，因此它的性能也会直接影响到全局性能。我们采用自管理的方式，将全局事务表做成分布式表，分布式地存储在集群中，这样就可以实现分布式扩展。</p><p></p><p>在实际应用中，比如说像 19 年的春晚抢红包，我们支持了三亿用户抢红包，支撑了峰值达每秒 12 万交易量。除此之外，针对某银行拥有 8000 万账户的核心账务系统，我们也平稳支持了其 6 万每秒的 TPS ，充分验证了 GaiaDB-X 的水平扩展能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/56/560fef70a125720cb796e7ddf53eb3d3.png\" /></p><p></p><p>除分布式外，我们也支持单机场景，实现了单机分布式一体化。为什么需要单机分布式一体化呢？以我们的一个银行客户来说，全行的业务系统有 200 多个，其中大部分系统（大概占 70% 左右）对性能与吞吐的要求并不高，一组单机数据库就能够满足其业务需求。但对于剩下的 30% 业务，它对性能的要求是单机数据库无法满足的，需要分布式数据库来满足其扩展性。</p><p></p><p>因此我们通过一体化的方式，来满足银行不同体量的业务对于数据库的需求。同时，我们也具备单机数据库扩展为分布式的能力，在对应业务的数据量增长后，能够扩容为分布式。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/15/15483b1c6cffdb73ad5178a621526e14.png\" /></p><p></p><p>扩展性的另外一个目的是自动做数据分离。在金融场景里面，存在多个业务共用一个数据库集群的场景，比如业务分为联机交易系统与查询类系统，数据库便对应划分为交易库和历史库两个。</p><p></p><p>对于交易库来说，只保存联机交易会频繁使用到的数据。例如账务结果数据及当天的交易记录，以满足对交易业务的快速响应。对于查询不那么频繁的即时交易记录，这可能就是一个相当大的数据量，一般都能达到千亿甚至万亿级别。这时，我们就可以将这个数据自动转移到历史库上去，用更高密度的存储机型来存储。一方面可以降低硬件成本，同时也可以避免对联机业务的影响。</p><p></p><p>这样做对业务来说，对外呈现的是一套数据库，业务可以根据需要来处理不同数据分区的逻辑，也不用在多套库之间通过 DTS 做数据同步。同时还把交易数据和历史数据做分离，以保障对联机业务的性能，同时也满足了查询业务的查询需求，避免其相互影响。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/09/09461237b2307a25d9e1a17349640b7b.png\" /></p><p></p><p>在金融场景中，对事物的 ACID 特性有着严格的要求：</p><p></p><p>持久性。指的是事务一旦提交就不会丢失，一般通过多副本 + 强同步来解决。原子性。一个事务要么全部提交，要么全部回滚，不存在部分提交的情况。通常，数据库的 XA 协议，通过两阶段提交能解决这个问题。</p><p></p><p>但是 XA 协议不能很好地满足一致性与隔离性。以简单的转账场景为例，A、B 原来各有 100 块钱，总共 200 块。然后 A 给 B 转账 50 块钱。此时，我们会先给 A 扣 50，再给 B 加 50。如果通过 XA 协议来做的话，先走 prepare 再 commit，我们可以看到，commit（图中第 7、第 8 步）过程不是原子过程，存在一个执行时间差。在这个时间差内，另外一个事务去读取数据，就可能存在读到提交了一半的数据，A 和 B 的总和是 150 而不是 200。这是 XA + 2PC 解决不了的问题。</p><p></p><p>为了解决这个问题，业内一般是引入一个全局时钟来做一致性的保证。通常有三种实现方式：</p><p></p><p>TrueTime 方案。这个是大家比较熟悉的方案，Google Spanner 也发过论文。但它的缺陷是依赖硬件，要引入 GPS 与原子钟，这个一般来说是难具备的。HLC 方案。采用该方案的典型数据库系统是 CockroachDB，它的优点是不依赖硬件，而且是去中心化的。但是缺点也很明显，一致性比较弱，而且要求服务器间的时钟误差不能超过 250ms，否则就无法正常运行。TSO 方案，比如 TiDB 就是采用了这种方案。TSO 本质上来说是一个全局唯一而且自增的逻辑序列号，一个事务在开始时与事务 commit 时需要两次找 GMS 获取序列号，然后把 TSO 号作为版本号提交到存储层，存储层的 MVCC 机制来判断数据是否可见。它不需要硬件具备强一致性，但缺点是依赖一个全局中心的时钟分配器 GMS。但这并不是一个问题，因为刚刚我们也提到了，虽然 GMS 不具备扩展性，1200 万的 TPS 已经完全满足业务的常规需要了。因此我们最终采用了这种方案。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b1/b192d1774be97ac09d153b3e3fcf81d9.png\" /></p><p></p><p>除了保障事务的一致性外，我们还需要保障上下游系统的数据一致性。在开始之前，我们首先要讲一下银行的典型业务场景，它一般分为三个子系统：</p><p></p><p>第一个是联机交易系统，例如存取款、在线支付等。这个系统的并发量高、延迟敏感，直接影响到用户体验。第二个是跑批类的业务系统。例如结息，每天晚上半夜计算前一天的利息。这些业务是后台业务，有大量的读取与计算操作，延迟不敏感，但是对数据一致性要求高。怎么能够让这样的业务尽量避免对在线业务的影响，同时又能够读取到最新的数据呢？我们的方式是让跑批业务去读取从库数据，从而避免对主库的性能影响，同时结合 TSO，即全局逻辑时钟的对位对齐机制。等到从库水位追齐之后，才返回读取数据。当然这会引入一定的延时，但是因为跑批业务对响应延时不那么敏感，所以是可以接受的。第三个子系统是大数据类的离线业务。通常来说，就是银行内部的各种大数据、数仓等系统，需要把数据库的数据同步过去。这样的业务对实时性要求不高，但要求最终的数据是一致的。由于各个计算节点都会承担流量，也会生成 BinLog。因此，如何对多份 BinLog 进行排序，让它们能够严格保持时序是我们需要解决的问题。我们的全局 BinLog 有两个模块，一个是 pump，从各个CN 节点抽取 BinLog，然后在 Sorter 节点基于 TSO（全局逻辑时钟）进行排序，来保障形成一个全局时序正确的 BinLog，以保障这个离线系统收到的数据的最终正确性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/17/17a48e22473b043b5053080788477dae.png\" /></p><p></p><p>接下来我们看一下容灾能力，除了对单机故障的容灾之外，还有对特定机型的容灾。因为银行把系统下移到通用服务器，通常都是通过两阶段来实施：第一阶段是下移到 X86 的 CPU 芯片上，这个过程银行、互联网厂商都一定的经验。第二阶段是要实现服务器芯片的基本国产化，就是说使用国产的鲲鹏、飞腾或海光 CPU 芯片，这方面大家都是在探索性的开展相关业务。</p><p></p><p>以百信银行举例，它与其母行中信银行一样，选择了基于鲲鹏做国产化的路线，而且在业内比较超前。相较于其他银行仅在周边系统或者数据库从库来做国产化，百信银行的周边业务跟核心系统都和主站一样基于鲲鹏服务器来做，这个在业内是较为领先的。</p><p></p><p>为了保证客户业务系统实现平滑的国产化，我们在产品上实现了一库多芯的方案，主要资源池基于鲲鹏，但放置了一个独立 X86 资源池，在技术上实现托底，同时也能够将原有换下来的服务器能够利用上，避免资源浪费。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/17/173396e11937ad6b3f0e88e0a6e8fb31.png\" /></p><p></p><p>根据人行的监管要求，银行核心系统一般要具备 5 级以上的容灾能力，这就要求具备两地三中心的容灾能力。</p><p></p><p>下图是我们客户的一个典型机房部署架构。首先在北京有两个同城机房，其物理距离在 50-100 公里左右，网路延迟在 1ms 左右。同时还有一个异地机房做灾备，物理距离一般是 1000 公里左右，比如合肥，网络延时是 10ms。</p><p></p><p>同城两个机房业务做双活部署，同时接受业务流量。数据库在两个机房采用 3 + 2 的部署形式，机房间采用强同步的方式来保障在发生机房级的故障之后，数据库能进行故障切换，而且保障数据的 RPO 为 0。</p><p></p><p>为保证单机房故障后的零数据丢失，我们采用分组强同步的方式，将 id1、id2 各划分一个复制组，复制组间采用强同步的方式。每个复制组保证至少有一个副本接收到数据之后才返回成功。这样在容忍少数副本故障的同时也能够保证单个机房故障后的零数据丢失。</p><p></p><p>异地机房的目标是当北京的两个机房都出现灾难性的事件之后，能够降级完成核心业务。它采用异步级联的方式来同步数据，首先异步是为了避免阻塞对主地域的数据库写入；采用级联方式，没有跟主地域机房形成复制组，主要一个为了保持灾备机房的数据库的拓扑独立性，减少依赖，保障在关键时刻可切换，另外也是降低跨地域同步的数据量，只需要同步一份数据即可。</p><p></p><p>结合在多家金融客户的实践，我们和中国信通院一起发布了金融数据库的容灾技术报告《金融级数据库容灾备份技术报告（2021 年）》。大家可以在公众号后台回复「金融级数据库容灾备份技术报告」获取。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c3/c35b7ca466e4e027b09f699a6c555063.png\" /></p><p></p><p>最后一部分是运维能力。核心系统下移及国产化的背景之下，数据库系统呈现两个变化：</p><p></p><p>一是数据库的节点数出现了 50 倍的增长，这里面既有技术架构的原因，也有数据库预留了一定的性能空间的原因。</p><p></p><p>二是数据库的种类也变多了。对于银行系统来说，之前基本就是选择 Oracle 或 DB2。现在则开始使用多种开源数据库和国产数据库。除此之外，为了避免像之前一样被单一厂商绑定，银行也会特意选择多家数据库厂商，在这种情况下，对银行的运维的挑战就更大了。</p><p></p><p>因此，结合百度集团及百度智能云管理大规模数据库节点方面的经验，我们将 GaiaDB-X 数据库云管平台进一步泛化，形成了具备管理多元数据库能力的统一平台，它除了能够管理 GaiaDB-X 自身，也能管理其他的开源数据库。通过帮助银行建立企业级的 DBPaaS 管理平台，进一步提升了银行的运维效率。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f5/f5b5b67c12e920a404b8a06be4702a30.png\" /></p><p></p><p></p><h2>三、金融应用案例介绍</h2><p></p><p></p><p>接下来，我来分享百度智能云在金融方面的一些典型案例。</p><p></p><p>首先是百信银行。它的特点是完全去 O，是一家完全没有 Oracle 的银行。全行 200+ 业务系统，无论是核心账务系统还是周边系统，几乎全部是基于 GaiaDB-X 数据库来构建的，至今已经平稳运行五年。</p><p></p><p>按数据库节点数计算，百信银行目前的数据库国产化率达到了 99.93%，遥遥领先于行业平均水平。</p><p></p><p>同时，百信银行在容灾和国产化领域也比较领先，在 2019 年就完成了全行主要系统的同城双活建设，2022 年开始将全行业务逐步迁移到基于鲲鹏的国产云上，进而实现了全栈的国产化。</p><p></p><p>在硬件成本方面，我们通过采用通用服务器来替代 IOE 硬件，帮助百信银行的单账户平均硬件成本降低了 70% 以上。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5e/5eba560cf050d18ba1d18d015ebab4c0.png\" /></p><p></p><p>下图是人行下面直属的某交易所。因为是涉及到国家金融稳定，所以在核心系统上需要逐步摆脱对 Oracle 的依赖，并拥有两地三中心的容灾能力。</p><p></p><p>由于当前的一些数据库都不能满足他们的业务场景需求，因此该交易所和百度采用了联合开发的模式，共建数据库能力。在两年的合作过程中，我们从外围的信息管理系统入手，逐步深入到核心交易系统，再到离线库数据分析系统，进而逐步实现数据库国产化。</p><p></p><p>此外，由于交易所的交易系统对低延时的要求较高，同时基于容灾要求又有同城双活的要求，如何在跨机房的情况下保障交易延时就成了亟待解决的问题。因此我们共同建设了 Collocate 机制，来尽量减少跨机房数据的访问，最终将交易延时从 80 毫秒降低到了 15 毫秒。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d3/d3bbb84070b281ebbedf2e41e6edc456.png\" /></p><p></p><p>下图是国内某国有大行客户。他们在最近两年把原有的基于小型机的核心系统下移到了通用服务器中，数据库也从 Oracle 替代为了开源单机数据库。</p><p></p><p>但在这个过程中，该行面临两个问题：一是数据库节点数增长了 50 倍，服务器数量到达了 1000 台左右，如何做好数据库的自动化部署、上线变更、版本升级、参数管理、性能诊断等工作。二是如何结合业务的单元化，形成业务与数据库的同城双活与异地容灾能力。</p><p></p><p>借助百度智能云提供的统一数据库管控平台的能力，历时两年，我们与客户一起实现了新核心系统的全面投产，也顺利通过了人行的验收。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b9/b935db0fd9ff535ed78234e80ac12688.png\" /></p><p></p><p></p>",
    "publish_time": "2023-12-11 15:03:34",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "百度8500万挖不来“AI教父”；淘天年薪百万起步抢全球顶尖人才，上不封顶；王慧文病休后首次动作：AI投资｜Q资讯",
    "url": "https://www.infoq.cn/article/uJ79bU5Wreox7MGdKmLQ",
    "summary": "<p>&nbsp;</p><p></p><blockquote>阿里将首次派发年度股息，总额近179亿；淘天集团抢全球顶尖人才，年薪百万起上不封顶；百度8500万挖“AI教父”被拒，选择入职谷歌；比尔盖茨每天收入1095万美元，约普通人一生收入4倍；谷歌发布自己“最强”Gemini大模型遭质疑：演示视频疑似剪辑；王慧文病休后首次动作，入股OneFlow团队新创业项目；卷入300亿骗局官司，京东回应：这是一个匪夷所思的恶意诉讼……</blockquote><p></p><p>&nbsp;</p><p></p><h2>科技公司</h2><p></p><p>&nbsp;</p><p></p><h4>阿里将首次派发年度股息，总额近179亿</h4><p></p><p>&nbsp;</p><p>12月6日，阿里发布公告，将向截至2023年12月21日收市时登记在册的普通股持有人和美国存托股持有人，就2023财年首次派发年度股息。金额分别为每股普通股0.125美元或每股美国存托股1.00美元，以美元支付。根据披露，股息总额约为25亿美元（当前约179亿元人民币）。阿里称，在现有股份回购计划基础上继续努力提高股东回报。</p><p>&nbsp;</p><p>此次面向全体股东的派息决定，是阿里巴巴2014年上市美股，以及2019年再次回归港股以来首次大规模分红派息。据梳理，阿里巴巴成立以来就以保守的财务经营策略闻名，包括本次分红派息在内，仅有3次分红派息记录。</p><p>&nbsp;</p><p></p><h4>淘天集团抢全球顶尖人才，年薪百万起上不封顶</h4><p></p><p>&nbsp;</p><p>近日，淘天集团启动一项名为T-Star的顶尖人才招聘计划，发放的offer不设层级，采取定制化培养模式，配备“大牛”主管和顶级研发平台资源，年薪百万起上不封顶。</p><p>&nbsp;</p><p>根据淘天集团招聘官网公布的信息，目前，T-Star计划已经开放了10种算法工程师岗位，工作方向包括自然语言处理、机器学习、多模态、三维重建、计算机视觉、3D等，工作地点为杭州、北京等。</p><p>&nbsp;</p><p></p><h4>百度8500万挖“AI教父”被拒，选择入职谷歌</h4><p></p><p>&nbsp;</p><p>12月4日，据知情人士透露，百度公司曾出价1200万美元(约合8486万元人民币)邀请“AI教父”杰弗里·辛顿(Geoffrey Hinton)及其学生加入公司，但被拒绝。“我们不知道自己值多少钱。”辛顿表示。他咨询了收购方面的律师和专家，想出了一个计划：“我们将组织一场拍卖，自己兜售自己。”</p><p>&nbsp;</p><p>最终，辛顿博士和他的学生们在4400万美元(约合3.1亿元人民币)的价格上停止了这次拍卖。虽然出价仍在上升，但他们想为谷歌工作。这一报酬已经很惊人。据悉，今年5月辛顿宣布从谷歌离职。辛顿表示，从谷歌辞职是为了可以自由地谈论AI的风险。他说，现在对自己一生从事的工作感到有些后悔。</p><p>&nbsp;</p><p></p><h4>比尔盖茨每天收入1095万美元，约普通人一生收入4倍</h4><p></p><p>&nbsp;</p><p>根据求职信息网站Zippia的数据，一个普通人一生的平均收入约为270万美元，而比尔·盖茨一天的收入大约是这个数字的3~4倍。据预计，盖茨每天的收入约为1095万美元，相当于每秒约117美元。还有另外一组数据显示，盖茨每天进账约760万美元，相当于每小时319635美元。</p><p>&nbsp;</p><p></p><h4>谷歌发布自己“最强”Gemini大模型遭质疑：演示视频疑似剪辑</h4><p></p><p>&nbsp;</p><p>谷歌 12 月 6 日宣布推出其认为规模最大、功能最强大的人工智能模型 Gemini。Gemini 将包括三种不同的套件：Gemini Ultra、Gemini Pro 和 Gemini Nano。根据谷歌给出的基准测试结果，Gemini 在许多测试中都表现出了“最先进的性能”，甚至在大部分基准测试中完全击败了 OpenAI 的 GPT-4。</p><p>&nbsp;</p><p>同时，谷歌也发布了Gemini Ultra官方演示视频，展示了这款模型的强大能力。不过，依然有人质疑Gemini的能力。</p><p>&nbsp;</p><p>据报道，Gemini在MMLU多任务语言理解数据集测试中显示出色，但对比GPT-4时的提示技巧和展示方式引发了争议。质疑者认为，Gemini在使用提示技巧+32次尝试的标准下超越了GPT-4，但这一标准是否公平受到质疑。图表比例尺的问题也被揭示，引起了技术主管的修正。Gemini发布的视频在展示时也引起了关注，部分观点认为其中可能存在剪辑和非实时录制。</p><p>&nbsp;</p><p>查看更多：</p><p><a href=\"https://mp.weixin.qq.com/s/Yqi4rcyEmvg9g6LCqbxYxA\">刚发布就被质疑？超过 GPT-4 的“最强”大模型 Gemini、“最高效”训练加速器，谷歌到底行不行</a>\"</p><p>&nbsp;</p><p></p><h4>王慧文病休后首次动作，入股OneFlow团队新创业项目</h4><p></p><p>&nbsp;</p><p>在病休近6个月后，王慧文突然有了新动作，再次与袁进辉牵手，入股其创业新公司硅动科技。据公开资料显示，就在这两日，北京硅动科技有限公司新增王慧文为股东，注册资本由100万人民币增至约105.26万人民币。也就是说，王慧文目前在袁进辉新公司的持股比例约为5%。</p><p>&nbsp;</p><p>OneFlow是国内知名开源深度学习框架及开发平台。其团队上次创业一流科技时，由王慧文的光年之外收购其46.52%股权。不过，随着6月底光年之外创始人王慧文病退消息曝光，美团收购光年之外100%的权益，一流科技OneFlow团队作为其核心资产也转归美团名下。在50天后，袁进辉宣布带领OneFlow原班人马再次创业。消息传出后不到半个月，硅动科技注册成功。</p><p>&nbsp;</p><p></p><h4>“腾讯视频崩了”上热搜</h4><p></p><p>&nbsp;</p><p>12 月 3 日晚，腾讯视频出现网络故障，有网友反馈出现首页无法加载内容、VIP 用户看不了会员视频等情况。#腾讯视频崩了# #腾讯会员 没了#词条相继冲上微博热搜。</p><p>&nbsp;</p><p>稍晚些时候，@腾讯视频就“App 崩了”发布致歉声明称，目前腾讯视频出现了短暂技术问题，我们正在加紧修复，各项功能在逐步恢复中。感谢您的耐心等待，由此给您带来的不便我们深感歉意。</p><p>&nbsp;</p><p>除了腾讯视频，近期遭遇宕机事件的还有滴滴、淘宝、闲鱼、钉钉、阿里云盘等多个App。据媒体统计，以此被多家媒体报道或登上热搜榜为基准，2022年约发生了9起宕机事件，而今年以来，类似的事件已发生14起。</p><p>&nbsp;</p><p>更多阅读：</p><p><a href=\"https://mp.weixin.qq.com/s/-KVKVfq0CayLyRkEbp2Rcg\">互联网大厂“组团”宕机，都怪降本增“笑”？</a>\"</p><p>&nbsp;</p><p></p><h4>被卷入300亿骗局官司，京东回应：这是一个匪夷所思的恶意诉讼</h4><p></p><p>&nbsp;</p><p>12月4日消息，最近京东集团、承兴集团、诺亚财富之前的各种消息闹得沸沸扬扬，京东还被告上法庭。据悉，此事起因是承兴集团的罗静造假，冒充京东工作人员，并私自刻章，以京东、苏宁等应收账款来找金融机构（诺亚财富）贷款，最终骗走300亿并跑路暴雷，结果被抓。诺亚财富一纸诉状把京东给告上法庭，想让京东还钱。</p><p>&nbsp;</p><p>对于此事，京东集团官微“京东发言人”最新发布一份声明回应，称京东作为毫不知情的受害者，被卷入历时四年的恶意诉讼中，公司的声誉和权益遭受重大损失，相信法院会有公正的判决。12月4日晚，诺亚财富发布声明称，已关注到京东集团发布的关于我司的声明，该声明中“诺亚财富近年来先后发生十余起类似事件，上百亿基金......”等描述严重失实，已侵犯了我司名誉，我司将采取法律措施，维护自身合法权益。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>IT 业界</h2><p></p><p>&nbsp;</p><p></p><h4>小米14手机内核已在GitHub开源</h4><p></p><p>&nbsp;</p><p>据报道，小米14/Pro内核现已在Github开源，AOSP版本基于Android U。公开内核源码可以让第三方开发者进行修改，开发人员和愿意折腾的用户能够充分利用硬件的潜力，市场上也会很快出现该机型的第三方固件。</p><p>&nbsp;</p><p>开源地址：</p><p><a href=\"https://github.com/MiCode/Xiaomi_Kernel_OpenSource/tree/shennong-u-oss\">https://github.com/MiCode/Xiaomi_Kernel_OpenSource/tree/shennong-u-oss</a>\"</p><p>&nbsp;</p><p></p><h4>员工称亚马逊AI聊天机器人Q “幻觉”严重，且泄露公司机密数据</h4><p></p><p>&nbsp;</p><p>根据国外科技媒体披露的一份内部文件，亚马逊员工称旗下AI聊天机器人Q存在严重的“幻觉”问题，并泄露了包括AWS数据中心位置、内部折扣计划等诸多机密信息。报告文件显示，亚马逊Q会产生幻觉，返回有害或不适当的聊天内容。例如，亚马逊Q会返回过时的安全信息，可能会让客户面临风险。</p><p>&nbsp;</p><p>亚马逊淡化了员工讨论的重要性，并声称没有发现任何安全问题。然而，泄露的文件引发了人们对Q准确性和安全性的担忧，Q仍处于预览阶段，尚未正式发布。文章发表后，该发言人发布一份声明，反驳了员工的说法，称亚马逊Q没有泄露机密信息。</p><p>&nbsp;</p><p></p><h4>Meta 推出独立的 AI 图像生成器，目前免费但只支持英文提示词&nbsp;</h4><p></p><p>&nbsp;</p><p>Meta 公司日前推出全新的、独立的 AI 图像生成器 ——Imagine with Meta，允许用户通过自然语言描述来创建图像。据介绍，新的人工图像生成器由 Meta 现有的 Emu 图像生成模型提供支持，可根据文本提示创建高分辨率图像。它目前对美国的英语用户免费使用（后续是否收费未知），并且每个提示都会生成四个图像。</p><p>&nbsp;</p><p>此前，Meta 图像生成模型因带有种族偏见的图像贴纸而面临争议。为了解决此类问题，Meta 表示将开始向 Imagine with Meta 生成的图像添加隐形水印，这些水印将由人工智能模型生成，并可由相应模型检测，以提高内容透明度。</p><p>&nbsp;</p><p></p><h4>Hugging Face 现 API 令牌漏洞，黑客可获取微软、谷歌等模型库权限</h4><p></p><p>&nbsp;</p><p>安全公司 Lasso Security 日前发现 AI 模型平台 Hugging Face 上存在 API 令牌漏洞，黑客可获取微软、谷歌、Meta 等公司的令牌，并能够访问模型库，污染训练数据或窃取、修改 AI 模型。由于平台的令牌信息写死在 API 中，因此黑客可以直接从 Hugging Face 及 GitHub 的存储库（repository）获得平台上各模型分发者的 API 令牌（token），安全人员一共从上述平台中找到 1681 个有效的令牌。</p><p>&nbsp;</p><p></p><h4>支付宝、麦当劳中国等相继启动鸿蒙原生应用开发</h4><p></p><p>&nbsp;</p><p>12月7日，支付宝与华为终端宣布合作，基于HarmonyOS NEXT启动支付宝鸿蒙原生应用开发，华为常务董事、终端BG CEO、智能汽车解决方案BU董事长余承东和蚂蚁集团董事长兼首席执行官井贤栋均现身签约现场。</p><p>&nbsp;</p><p>无独有偶，12月6日，麦当劳中国也与华为达成鸿蒙合作协议，正式宣布麦当劳中国APP将基于HarmonyOS NEXT启动鸿蒙原生应用开发，成为首批启动鸿蒙原生应用开发的全球大型跨国连锁餐饮企业，该公司在中国市场拥有5500多家餐厅，每年服务顾客超十亿人次。</p><p>&nbsp;</p><p>随着华为宣布鸿蒙原生应用全面启动，近期美团、去哪儿、新浪、钉钉、蚂蚁集团、小红书、58集团、哔哩哔哩、高德地图等互联网公司均已宣布加入鸿蒙原生应用开发行列。</p><p>&nbsp;</p><p></p><h4>IntelliJ IDEA 2023.3 版本更新发布</h4><p></p><p>&nbsp;</p><p>IntelliJ IDEA 2023.3 版本更新现已发布，在这一版本中，JetBrains 表示 AI Assistant 持续演进，现已超越技术预览阶段，获得了大量令人期待的改进。在其他方面，此版本包括对最新 Java 21 功能的全面支持，引入了带有编辑操作的直观浮动工具栏，并添加了 Run to Cursor（运行到光标）嵌入选项来增强调试工作流。IntelliJ IDEA Ultimate 现在提供无缝的开箱即用 Kubernetes 开发体验。</p>",
    "publish_time": "2023-12-11 15:07:19",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Web3 时代的商业未来_黄东浩",
    "url": "https://www.infoq.cn/article/3UlpCdtmzxz5OwRjd6j9",
    "summary": "<p>在数字化浪潮的推动下，商业的未来正在经历一场静悄悄的革命。Web3，作为这场变革的前沿，不仅仅是技术的升级，更代表了一种全新的经济参与方式。当前，我们面临着无数的机遇与挑战：如何在加密货币的寒冬中寻找暖春，Web2品牌如何过渡到Web3，以及数字货币的兴起如何重塑我们对“钱”的理解。这些问题不仅仅需要技术的创新，更需要商业模式与思维方式的根本转变。</p>\n<p>在FCon 2023 全球金融科技大会上，黄东浩 万事达卡（Mastercard）实验室 研发副总裁以《Web3 时代的商业未来》发表了演讲。他重点讨论了以下内容：</p>\n<ul>\n<li>Web3 概述：介绍了 Web3 的基础构建块，包括去中心化互联网、非托管钱包的使用以及二层区块链技术如何扩展区块链交易容量。</li>\n<li>当前 Web3 概况：提及了自 2022 年以来 NFT 交易下跌的趋势，称之为“加密货币的寒冬”。</li>\n<li>Web2 品牌拥抱 Web3 技术：即便在 NFT 市场交易量下降的情况下，越来越多的 Web2 品牌开始利用 Web3 技术扩大业务。</li>\n<li>重新想象货币：讨论了对“价值”的新理解将如何创造新的商业模式和经济体，并推动数字包容性。</li>\n<li>代币化卡 NFT：提出了代币化卡 NFT 的机遇与挑战。代币化卡 NFT 旨在吸引那些还未使用或不熟悉 Web3 技术的用户，并使其能够轻松进入这一领域。</li>\n<li>代币化卡 NFT 的挑战：指出新用户在 Web3 空间中的学习曲线陡峭，并且入门过程繁琐。</li>\n<li>代币化卡 NFT 的解决方案和架构：介绍了如何让用户将其支付卡代币化为 Soul Bound Token（SBT，一种公开可验证且不可转让的 NFT）。</li>\n<li>代币化卡 NFT 的好处：允许用户将代币化卡集成到钱包中，实现法币与加密货币之间无缝的即时转换，为终端用户和商家赋能新的使用案例。</li>\n<li>Mastercard 在 Web3 领域的方法：展示了 Mastercard 的发展方向，包括嵌入支付服务、支持更大的互操作性和无缝支付体验。</li>\n</ul>\n<p><strong>活动推荐：</strong></p>\n<p>QCon 全球软件开发大会（上海站）即将在 12 月 28-29 日开始，届时将围绕 GenAI和通用大模型应用探索、AI Agent 与行业融合应用的前景、LLM 时代的性能优化、智能化信创软件 IDE、面向人工智能时代的架构、性能工程：提升效率和创新的新方法等专题进行交流。现在购票，享 9 折优惠，立减￥680！咨询购票请联系：18514549229（微信同手机号）。</p>",
    "publish_time": "2023-12-11 15:19:20",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Mesos时代彻底消亡：10年创业挣扎、微软谷歌收购未果，这家公司还是倒闭了",
    "url": "https://www.infoq.cn/article/9pBs1jylxwk2k7ILtr1K",
    "summary": "<p>曾一度颇受软件开发人员欢迎的云基础设施初创公司D2iQ&nbsp;，近日被爆已经倒闭。根据&nbsp;The&nbsp;Information&nbsp;报道，D2iQ 筹集了 2.5 亿美元（约18 亿元人民币）的风险资金，上周四&nbsp;D2iQ&nbsp;向股东们发出通知称，公司正在清盘，并将把资产分配给债权人。</p><p>&nbsp;</p><p>超融合基础架构解决方案公司Nutanix&nbsp;的发言人表示，Nutanix&nbsp;收购了&nbsp;D2iQ&nbsp;的一些资产和知识产权，并聘用了&nbsp;D2iQ&nbsp;的一些前员工。一名前员工表示，今年早些时候，该公司约有&nbsp;150&nbsp;名员工，年收入一度达到数千万美元。</p><p></p><h2>成也&nbsp;Mesos，败也&nbsp;Mesos</h2><p></p><p>&nbsp;</p><p>Mesosphere是D2iQ的前身。Mesosphere公司诞生于开源Mesos项目，可以说是Mesos的商业化推手，由Airbnb和Twitter的超大规模基础结构架构师在2013年共同创立，从Andreessen Horowitz、Kleiner Perkins等处获得225万美元的种子轮融资。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e4/e41b841db4b2e53ea2809c7933ece01a.png\" /></p><p></p><p>&nbsp;Mesosphere 联合创始人 Benjamin Hindman (CIPO)、Florian Leibert (CEO)、Tobi Knaup (CTO)</p><p>&nbsp;</p><p>&nbsp;</p><p>Mesos&nbsp;项目起源于加州大学伯克利分校的AMPLab实验室项目。跟起源于Google&nbsp;的数据中心资源管理系统Borg一样，它们的诞生都是调度领域的大事。</p><p>&nbsp;</p><p>当时的Twitter&nbsp;每天要管理几亿条推文，急需一个类似的资源管理系统。在注意到&nbsp;Mesos&nbsp;后，Twitter还聘请了Mesos 项目负责人&nbsp;Ben&nbsp;Hindman负责开发和部署&nbsp;Mesos。2011&nbsp;年，Twitter&nbsp;开始在&nbsp;Mesos&nbsp;项目的基础上开发&nbsp;Aurora&nbsp;项目以便同时管理其内部的在线和离线业务，逐步成为&nbsp;Mesos&nbsp;社区的代言人。</p><p>&nbsp;</p><p>后来几位曾在Google 工作过的Twitter工程师，John Sirois、Travis Crawford 和 Bill Farner，加盟了进来，他们向Hindman表示，他们想念 Borg，而 Mesos 似乎是重建它的完美方式。因此，也可以说Mesos目的也是弄清楚是否必须重建&nbsp;Google&nbsp;的超大规模计算专有架构在&nbsp;Docker&nbsp;刚开始成名的头两年，Mesos&nbsp;独有的支持多种&nbsp;Framework&nbsp;的设计使它可以轻松接入&nbsp;Docker&nbsp;生态，并在当时成为了管理&nbsp;Docker&nbsp;容器集群的不二之选。</p><p>&nbsp;</p><p>如日中天的Mesosphere也颇受资本青睐。自 2014 年 6 月至 2018 年 5 月，Mesosphere共完成 A 到 D 轮四轮融资，金额分别为 1050 万美元、3600 万美元、7350 万美元和 1.25 亿美元，投资方包括 A16Z、Fuel Capital、微软等。Mesosphere 最高估值是 D 轮之后达到 7.75 亿美元（约56亿人民币）。</p><p>&nbsp;</p><p>据报道，该公司还在 2015 年曾拒绝了微软斥资 1.5 亿美元收购的提议，想要寻求更高的报价。有知情人士表示，在过去这几年，D2iQ 的高管们一直想要找到买家，但以失败告终。</p><p>&nbsp;</p><p>但是后来的事情大家也知道，Docker&nbsp;和&nbsp;Kubernetes&nbsp;各自亮出杀手锏不断刷新用户三观。但是，Apache&nbsp;社区固有的响应迟钝拖慢了&nbsp;Mesos&nbsp;进化的速度，而由创业公司维护的&nbsp;Marathon&nbsp;又一直没办法构建出更加繁荣和活跃的社区。</p><p>&nbsp;</p><p>当时，Ben&nbsp;Hindman甚至表示，即使没有出现Kubernetes，Mesos 也很可能被其他开箱即用类方案所压制。Mesos 很难像其他开源项目那样建立起供应商与贡献者团结一致的友好氛围。</p><p>&nbsp;</p><p>而Mesosphere 是一家靠风险投资支持的初创企业，后来则由 Twitter 接手赞助项目发展。正因为如此，企业必须找到一种能够产生收益的商业模式，这导致与用户乃至其他供应商之间产生了紧张关系、甚至是严重的不信任感。</p><p>&nbsp;</p><p>2019年，Mesos“代言人”&nbsp;Twitter&nbsp;放弃了&nbsp;Mesos，全面转向&nbsp;Kubernetes。同年2月，Mike Fey 就任 Mesosphere的首席执行官一职。在此之前，他在Symantec担任了近两年半的总裁兼首席运营官，还在网络安全公司Blue Coat Systems在相同职位上工作了近两年。</p><p>&nbsp;</p><p>6个月后。Fey 宣布Mesosphere 改名为Day2IQ（简称D2IQ）。将目光投向Kubernetes和大数据产品。Fey表示，“Mesosphere这个名字存在一定的局限。在客户看来，Mesosphere划定了我们所提供的特定技术，但我们的核心任务并非仅限于此。”</p><p>&nbsp;</p><p>这次新的品牌定位和战略转型是自救，但也让D2IQ陷入了另外两个竞争激烈领域的角逐。</p><p>&nbsp;</p><p>当时，IBM 大规模采用容器应用平台 OpenShift 以及收购红帽后大力推进 Kubernetes；而Cloudera 和 Hortonworks 在公共云竞争的压力下合并，MapR在将自己置于拍卖区并警告其面临关门危险后刚刚被 HPE 收购。</p><p>&nbsp;</p><p></p><h2>裁员减负</h2><p></p><p>&nbsp;</p><p>这次转型并没有彻底拯救D2iQ，压死骆驼的最后一根稻草可能是新冠病毒。</p><p>&nbsp;</p><p>2020年4月，D2iQ开始裁员：解雇了34名员工，约占其员工总数的13%。D2iQ发言表示，“COVID-19引发的经济衰退对我们的未来业务产生了各种直接和潜在影响，我们是在大幅削减所有可自由支配开支后才做出这一选择的。”</p><p>&nbsp;</p><p>此次裁员是在D2iQ 首席执行官&nbsp;Mike&nbsp;Fey&nbsp;宣布从公司辞职、联合创始人&nbsp;Tobi&nbsp;Knaup&nbsp;与曾担任首席运营官的&nbsp;William&nbsp;Freiberg&nbsp;一起担任联席首席执行官的两周后进行的。</p><p>&nbsp;</p><p>管理层当时告诉员工，由于新冠危机，公司将把当年剩余时间的销售预期降低了&nbsp;40%，并希望削减&nbsp;25%&nbsp;的开支，以确保“能够维持可持续的商业模式”。除了裁员外，D2iQ还将通过冻结招聘和绩效来降低成本，并寻求削减旅行、云计算、营销和其他领域支出的方法。</p><p>&nbsp;</p><p>如果不采取任何行动，该公司将被迫在今年晚些时候寻求更多风险投资，否则最快到&nbsp;2021&nbsp;年夏季就会耗尽现金。</p><p>&nbsp;</p><p>根据报道，当年 4 月，D2iQ宣布获得了国防部 (DoD) 企业软件计划 (ESI) 的订单，为其提供 DevSecOps 解决方案和服务。</p><p>&nbsp;</p><p>“高管们之前表示，公司有足够的钱可以捱到 2025 年。招聘销售人员拼命向政府部门销售软件，大举招兵买马，可能摊子铺得过大了。”D2iQ负责企业客户的前高管 Chip Nickolett&nbsp;说道。</p><p>&nbsp;</p><p>同年，网传谷歌开始洽谈收购&nbsp;D2iQ。这笔交易的金额将超过风险投资机构筹集的2.5亿美元，但可能会低于D2iQ在2018年D轮融资中获得的7.75亿美元的估值。但当时外媒称，这项收购仍然可能不会发生，“据说至少有一位 D2iQ 高层反对这项交易。”</p><p>&nbsp;</p><p></p><h2>挣扎求变</h2><p></p><p>&nbsp;</p><p>D2iQ&nbsp;也一直在努力迎合客户需求提供相应的服务，如多集群、多云环境管理能力。</p><p>今年9月，在生成式AI热潮下，D2iQ&nbsp;还在其D2iQ&nbsp;Kubernetes&nbsp;Platform&nbsp;(DKP)&nbsp;2.6&nbsp;版本中添加了&nbsp;AI&nbsp;Navigator，旨在缩小企业在使用云过程中面临的技能差距。</p><p>&nbsp;</p><p>D2iQ 首席技术官 Deepak Goel 表示，随着 Kubernetes 环境和容器化应用程序的多样性增大，在单个集群中相对较小的问题在多集群、多云环境中变得更加难以管理。AI Navigator 等工具可以在一定程度上解决寻求采用云原生技术企业所面临的挑战。</p><p>&nbsp;</p><p>就&nbsp;DKP&nbsp;2.6&nbsp;而言，AI&nbsp;Navigator&nbsp;实际上是公司知识库的自然语言界面。比如用户可以提问：“我的&nbsp;DKP&nbsp;集群丢失了&nbsp;kubeconfig&nbsp;文件，如何恢复？”&nbsp;AI&nbsp;Navigator&nbsp;将快速响应解决方案，并且通常会提供需要执行的命令。</p><p>&nbsp;</p><p>D2iQ&nbsp;产品管理副总裁&nbsp;Dan&nbsp;Ciruli&nbsp;表示，该服务使用了微软的&nbsp;Azure&nbsp;OpenAI&nbsp;服务和&nbsp;ChatGPT&nbsp;3.5&nbsp;模型。AI&nbsp;Navigator&nbsp;仅接受过&nbsp;D2iQ&nbsp;内部知识库的培训，Ciruli透露公司计划增加&nbsp;AI&nbsp;Navigator&nbsp;使用客户自己的上下文数据（包括集群配置、工作负载等）的能力，以便提供非常具体的分析和建议。</p><p>&nbsp;</p><p>参考链接：</p><p>&nbsp;<a href=\"https://www.infoq.cn/article/dlr7vvrosiinjprwxgc8\">https://www.infoq.cn/article/dlr7vvrosiinjprwxgc8</a>\"</p><p><a href=\"https://techcrunch.com/2019/08/05/mesosphere-changes-name-to-d2iq-shifts-focus-to-kubernetes-cloud-native/?guccounter=1\">https://techcrunch.com/2019/08/05/mesosphere-changes-name-to-d2iq-shifts-focus-to-kubernetes-cloud-native/?guccounter=1</a>\"</p><p>&nbsp;<a href=\"https://www.theinformation.com/articles/a16z-backed-startup-that-once-rejected-150m-sale-to-microsoft-shuts-down\">https://www.theinformation.com/articles/a16z-backed-startup-that-once-rejected-150m-sale-to-microsoft-shuts-down</a>\"</p><p><a href=\"https://www.businessinsider.com/d2iq-mesosphere-layoffs-34-coronavirus-crisis-2020-4\">https://www.businessinsider.com/d2iq-mesosphere-layoffs-34-coronavirus-crisis-2020-4</a>\"</p><p><a href=\"https://d2iq.com/press-release/dkp-simplifies-kubernetes-management-2-6\">https://d2iq.com/press-release/dkp-simplifies-kubernetes-management-2-6</a>\"</p>",
    "publish_time": "2023-12-11 15:42:34",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "计算机图形学将迎来新突破？Meta携手斯坦福大学推出3D交互模型，VR时代似乎不远了",
    "url": "https://www.infoq.cn/article/FOHDzHtEh5mTtyKyYDd8",
    "summary": "<p>近日，斯坦福大学与Meta/Facebook&nbsp;AI研究（FAIR）实验室的工作人员共同开发出一套突破性的AI系统，能够仅根据文本描述在虚拟人和物体之间生成自然、协调的运动关系。</p><p>&nbsp;</p><p>这套新系统被称为CHOIS（Controllable Human-Object Interaction Synthesis，即可控人机交互合成），使用最新的条件扩散模型技术生成无缝且精确的交互，例如“将桌子举过头顶、行走，然后放下桌子。”</p><p>&nbsp;</p><p>简而言之，这是一套先进的人工智能系统，用于合成逼真的 3D 人机交互。</p><p>&nbsp;</p><p>这项工作被公布在arXiv论文预发表网站的一篇文章中，也让我们得以一睹虚拟人如人类般顺畅理解并响应语言命令的未来景观。例如，把椅子拉近桌子来创造一个工作空间，调整落地灯以投射出完美的光芒，或者整齐地存放手提箱。每一项任务都需要人、物体和周围环境之间的精确协调。语言是表达和传达这些意图的有力工具，在语言和场景背景的指导下，合成逼真的人类和物体运动是构建先进的人工智能系统的基石，该系统可以在不同的3D环境中模拟连续的人类行为。</p><p>&nbsp;</p><p>论文地址：<a href=\"https://arxiv.org/pdf/2312.03913.pdf\">https://arxiv.org/pdf/2312.03913.pdf</a>\"</p><p>&nbsp;</p><p>研究人员们在文章中指出，“根据语言描述在3D场景中生成连续的人-物交互一直存在不少挑战。”</p><p>&nbsp;</p><p>他们必须确保生成的运动真实且协调同步，保持人手与物体之间的适当接触，且物体的运行应当与人类行为具有因果关系。</p><p></p><h2>如何实现</h2><p></p><p></p><p>CHOIS系统之所以效果拔群，依靠的就是其在3D环境中摸索出一套独特的人-物交互合成方法。CHOIS的核心为条件扩散模型，这是一种能够模拟详尽运动序列的生成模型。</p><p>&nbsp;</p><p>当给定人/物位置的初始状态以及所需操作的语言描述之后，CHOIS就会据此生成一系列动作，最终完成任务要求的交互效果。</p><p>&nbsp;</p><p>例如，假设指令是将灯具移到沙发旁边，CHOIS会理解指令内容并创建一段逼真的动画，显示人类形象拿起灯具并将其放置在沙发附近。</p><p>&nbsp;</p><p>利用 AMASS 等大规模、高质量的运动捕捉数据集，人们对生成人体运动建模的兴趣有所上升，包括动作条件合成和文本条件合成。虽然之前的工作使用 VAE 公式从文本生成不同的人体运动，但 CHOIS 专注于人与物体的交互。与通常以手部运动合成为中心的现有方法不同，CHOIS 在物体抓取之前考虑全身运动，并根据人体运动预测物体运动，为交互式 3D 场景模拟提供全面的解决方案。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ae/ae3859d5e2f84eeb8a8685af1054800d.jpeg\" /></p><p></p><p>给定初始对象和人类状态、语言描述和3D场景中的稀疏对象路径点，CHOIS生成的物体运动与人体运动同步。</p><p>&nbsp;</p><p>CHOIS的独特之处，就在于它使用稀疏对象路径点和语言描述来指导动画生成。各个路径点充当对象移动轨迹中的关键标记点，确保运动不仅符合物理规律，而且与语言输入中描述的高级目标保持一致。</p><p>&nbsp;</p><p>CHOIS的另一大优势，在于能够将语言理解能力与物理模拟功能加以结合。传统模型往往难以将语言同空间和身体动作联系起来，特别对于较大的交互范围，必须考虑诸多因素才能始终保持交互的真实性。</p><p>&nbsp;</p><p>CHOIS首先解释语言描述所承载的意图和风格，而后将其转化为一系列既符合人体构造、又不违背物体特性的肢体动作，从而解决了大范围交互过程中的这一现实难题。</p><p>&nbsp;</p><p>该系统尤其具有开创性的一点，就是它能准确表现接触点（例如手与物体之间的接触位置），且物体的运行与人类化身施加的力保持一致。此外，该模型在训练和生成阶段还引入了专门的损失函数和指导性术语，旨在强制遵循这些物理约束，这也是让AI成功实现以人类方式理解物理世界、并与物理世界正确交互的重要一步。</p><p></p><h2>对计算机图形学、AI与机器人技术的影响</h2><p></p><p></p><p>CHOIS系统对计算机图形学产生了深远影响，特别是在动画和虚拟现实领域。通过让AI获得解释自然语言指令并据此生成逼真人机交互过程的能力，CHOIS能够大大减少制作复杂场景动画所需要的时间和精力。</p><p>&nbsp;</p><p>动画师们可以使用这项技术来创建出以往极为费时费力的关键帧动画序列，显著提升设计效率与成果产出。此外，在虚拟现实环境当中，CHOIS还能带来更加身临其境且高度交互的体验，由用户通过自然语言指挥虚拟角色，并观察其以逼真精度执行任务的全过程。这种更高水平的交互能够将VR体验从僵化、脚本化的事件转化为更加顺畅自然的动态环境用户输入响应效果。</p><p>&nbsp;</p><p>在AI和机器人领域，CHOIS则代表我们朝着更加自主的情境感知系统迈出的一大步。传统机器人往往受到预编程例程的限制，而CHOIS这类系统的出现能够帮助其更好地理解现实世界、并顺利按照自然语言给出的描述完成任务。</p><p>&nbsp;</p><p>这对于医疗保健、酒店或家庭环境下的服务型机器人来说尤其有着变革性的影响。在这类环境下，理解物理空间并在其中执行各类任务的能力往往至关重要。</p><p>&nbsp;</p><p>对于AI来说，这种同时处理语言和视觉信息以引导任务执行的能力，也使其距离充分理解情境和环境上下文又更进了一步。而且在此之前，这种能力一直是人类的优势和专利。在CHOIS的支持下，未来的AI系统有望在更多复杂任务中发挥更大的作用，不仅能够消化人类指令的“内容”、更能理解人类指令的操作“方式”，以前所未有的灵活性适应新的挑战。</p><p></p><h2>成果令人惊艳，前景值得期待</h2><p></p><p>&nbsp;</p><p>CHOIS代表了人工智能领域的重大飞跃，特别是在计算机视觉和人机交互领域。通过综合 3D 人与物体交互，CHOIS 可以生成逼真的动画和场景，这对于创建沉浸式虚拟体验至关重要。</p><p>&nbsp;</p><p>该系统使用组合分层方法来理解人类与物体之间交互的复杂本质。这涉及将交互分解为更小的、可管理的部分，并理解这些部分之间的关​​系。模型的层次结构使其能够考虑交互的上下文，例如环境和所涉及对象的属性。</p><p>&nbsp;</p><p>CHOIS 由深度学习算法提供支持，深度学习算法是机器学习的子集。这些算法使系统能够从人与物体交互的大型数据集中学习，随着时间的推移提高其准确性和预测能力。</p><p>&nbsp;</p><p>总体而言，斯坦福大学和Meta的研究人员在计算机视觉、自然语言处理（NLP）和机器人技术交叉领域的这一极具挑战的问题上，成功取得了关键进展。</p><p>&nbsp;</p><p>研究团队认为，他们的工作是建立先进AI系统的重要一步，该系统能够在不同的3D环境中模拟连续的人类行为。CHOIS也为进一步研究如何利用3D场景加语言输入来合成人机交互过程打开了大门，有望在未来孕育出更加复杂的AI系统。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://venturebeat.com/ai/stanford-and-meta-inch-towards-ai-that-acts-human-with-new-chois-interaction-model/\">https://venturebeat.com/ai/stanford-and-meta-inch-towards-ai-that-acts-human-with-new-chois-interaction-model/</a>\"</p><p><a href=\"https://isp.page/news/chois-stanford-and-fair-metas-revolutionary-ai-for-realistic-3d-human-object-interactions/#gsc.tab=0\">https://isp.page/news/chois-stanford-and-fair-metas-revolutionary-ai-for-realistic-3d-human-object-interactions/#gsc.tab=0</a>\"</p><p><a href=\"https://www.marktechpost.com/2023/12/10/researchers-from-stanford-university-and-fair-meta-unveil-chois-a-groundbreaking-ai-method-for-synthesizing-realistic-3d-human-object-interactions-guided-by-language/\">https://www.marktechpost.com/2023/12/10/researchers-from-stanford-university-and-fair-meta-unveil-chois-a-groundbreaking-ai-method-for-synthesizing-realistic-3d-human-object-interactions-guided-by-language/</a>\"</p>",
    "publish_time": "2023-12-11 15:52:46",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "人工智能在金融行业中的创新应用_杨青",
    "url": "https://www.infoq.cn/article/717kOBtMIbz9atOFKhTZ",
    "summary": "<p>在金融科技领域快速发展的当下，人工智能（AI）扮演着日益重要的角色。虽然生成式 AI 技术和大模型时代备受关注，但传统 AI 在金融行业中的应用依然至关重要，对业务增长的推动作用不可小觑。如今，我们正步入一个将传统 AI 技术与大模型紧密结合的新时代。这种融合不仅极大提高了金融服务的效率和智能化水平，同时也为金融业的运营模式带来了革命性的改变。</p>\n<p>在近期举行的FCon全球金融科技大会上，度小满技术委员会执行主席，数据智能部总经理杨青发表了主题为《人工智能在金融行业中的创新应用》的演讲。他深入分析了传统 AI 在金融领域的持续影响力，同时探讨了在大模型时代下，如何有效结合传统 AI 与新兴技术，以应对未来挑战。要点包括：</p>\n<ul>\n<li>金融科技的演变：涵盖金融科技发展的三个阶段：信息化、数字化和智能化，强调从后端到前端技术的转变和AI在金融服务中的集成。</li>\n<li>机遇与挑战：讨论了中国在政策、数据、计算能力和算法进步方面的机遇，以及数据合规性、人才获取和人工智能合作等挑战。</li>\n<li>传统与生成型AI的作用：强调传统监督机器学习在金融中的巨大潜力，以及生成型AI在需要专业知识和复杂决策的领域的新兴影响。</li>\n<li>案例研究与应用：展示了实际例子，包括在风险控制中使用自然语言处理、在信用报告中使用图形机器学习以及AI在营销、服务、运营和智能办公场景中的应用。</li>\n<li>未来展望：强调AI推动的金融行业持续变革，展望未来，传统和生成型AI将协同作用，彻底改变业务流程、组织结构和整个行业。</li>\n</ul>\n<p><strong>活动推荐：</strong></p>\n<p>QCon 全球软件开发大会（上海站）即将在 12 月 28-29 日开始，届时将围绕 GenAI和通用大模型应用探索、AI Agent 与行业融合应用的前景、LLM 时代的性能优化、智能化信创软件 IDE、面向人工智能时代的架构、性能工程：提升效率和创新的新方法等专题进行交流。现在购票，享 9 折优惠，立减￥680！咨询购票请联系：18514549229（微信同手机号）。</p>",
    "publish_time": "2023-12-11 16:13:40",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "“数据消费”&“数据飞轮”，数据驱动下的企业未来是怎样的？",
    "url": "https://www.infoq.cn/article/KqaNdNwtqiH2dfsYPXWL",
    "summary": "<p>InfoQ 最新一期《新知实验室》即将上线！来自民生银行、顺丰、汽车之家、彩食鲜的四位CTO/CIO与大家一起探讨《数字化转型的全新探索：数据“驱动”与“消费”》，观点爆炸，精彩刺激……</p>",
    "publish_time": "2023-12-11 16:16:22",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "大模型技术在保险行业的创新应用与未来发展",
    "url": "https://www.infoq.cn/article/HJJitpSfPkdvQGIae1xU",
    "summary": "<p>在当今迅速发展的数字化时代，保险行业正面临前所未有的挑战和机遇。随着科技的不断进步，特别是大模型技术如GPT-4和DALL-E 2的出现和发展，这一领域正在经历一场深刻的转型。我们正从一个以信息技术为核心的时代，迈向一个更加聚焦于数字化和智能化的新时代。这种转变不仅仅关乎技术的进步，更关乎于如何利用这些进步来重新定义保险业务，提升服务效率，降低运营成本，以及创新保险产品和服务。</p>\n<p>在FCon 金融科技大会（上海站）上，阳光保险集团人工智能部大模型首席专家<strong>张晗</strong>展开了题为《大模型技术在保险行业的创新应用与未来发展》的分享。重要内容如下：</p>\n<ol>\n<li><strong>保险行业的数智化趋势</strong>：\n<ol>\n<li>保险行业正从信息化、数字化时代加速进入数智化时代。</li>\n<li>信息化时代重点在于将经营活动和业务流程固化在各类 IT 系统中。</li>\n<li>数字化时代则在信息化基础上，对产生的经营数据进行运营分析，并建立数字化系统。</li>\n<li>数智化时代结合了数字化和智能化，以业务为导向、数据为核心资产，以科技为驱动力。</li>\n</ol>\n</li>\n<li><strong>大模型技术简介</strong>：\n<ol>\n<li>AI 基础设施的完善、深度学习技术的进步和应用场景的增加使得大模型的参数量呈指数级提升。</li>\n<li>大模型技术如 GPT-4、DALL-E 2 等正在改变多个领域，包括保险行业。</li>\n</ol>\n</li>\n<li><strong>阳光正言大模型开放平台架构与应用</strong>：\n<ol>\n<li>阳光保险启动“阳光正言 GPT”战略工程，计划构建统一、融合的大模型底座。</li>\n<li>该平台致力于构建最懂保险和阳光的大模型垂直应用能力，重点在保险产品的销售等方面。</li>\n</ol>\n</li>\n<li><strong>大模型未来发展趋势与阳光愿景</strong>：\n<ol>\n<li>聚焦于大模型技术在保险行业中的应用和未来发展。</li>\n<li>强调了大模型在提高效率、降低成本、创新业务等方面的潜力。</li>\n<li>描述了阳光保险对于未来大模型技术发展的规划和愿景。</li>\n</ol>\n</li>\n</ol>\n<p><strong>活动推荐：</strong></p>\n<p>QCon 全球软件开发大会（上海站）即将在 12 月 28-29 日开始，届时将围绕 GenAI 和通用大模型应用探索、AI Agent 与行业融合应用的前景、LLM 时代的性能优化、智能化信创软件 IDE、面向人工智能时代的架构、性能工程：提升效率和创新的新方法等专题进行交流。现在购票，享 9 折优惠，立减￥680！咨询购票请联系：18514549229（微信同手机号）。</p>",
    "publish_time": "2023-12-11 18:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "首期“AI+软件工程”主题沙龙在京顺利举办",
    "url": "https://www.infoq.cn/article/jjMPiPwaP2ZASIWNVgH2",
    "summary": "<p>以大模型为核心的通用人工智能正在驱动着新一轮智能革命的持续演进，并给软件工程带来了新的发展契机。大模型等AI技术在软件研发过程中赋予了强大的智能化能力，软件研发不再只依赖于人类的智慧，而是与AI相结合使其过程更加高效、高质量、低成本，代码生成、代码补全等新能力推动智能化软件工程范围的延展。</p><p></p><p>为加强AI+软件工程领域的交流互通，推动行业多融合发展，2023年11月21日，由中国信息通信研究院人工智能研究中心、中国软件行业协会和应用现代化产业联盟联合主办，中国人工智能产业发展联盟AI for 软件工程（AI4SE）工作组承办的首期“AI+软件工程”主题沙龙在京成功举办，线上线下总观看量超过6万。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a7/a7d0396c7b40cb595093b3dca99513f5.webp\" /></p><p></p><p>中国信通院人工智能研究中心负责人魏凯、中国软件行业协会副秘书长付晓宇分别发表致辞。魏所指出，软件行业是大模型生态的聚集地，智能化的融合可以提升软件工程的效率和创新能力。然而，机遇和挑战并存，中国信通院将围绕AI和软件工程全生命周期持续开展系列工作，与产业各方共同面对挑战。付秘书长表示，AI为软件工程带来了新思路新方法，软件工程领域也在积极应对AI带来的挑战，中国软件行业协会一直致力于推动应用现代化的发展，期待看到我们的行业在面对挑战时，能够以开放、合作的态度，共同寻找解决方案，同时在AI与软件工程交叉领域看到更多创新与突破。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/39/3977d976034a22719df06830e8a4a84b.webp\" /></p><p>中国信通院人工智能研究中心负责人魏凯</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d9/d917f57d13e9bd398a48a7bdd56b2fb2.webp\" /></p><p>中国软件行业协会副秘书长付晓宇</p><p></p><p>本次沙龙邀请了来自华为、联通软件研究院、国金证券、软通动力、东吴证券、中软国际、中国信通院的7位行业专家，围绕落地方案、实践范式、问题与挑战、发展与趋势发表主题演讲。</p><p></p><p>华为技术有限公司软件工程专家贺美迅的分享主题是“Al辅助研发实践探索”。贺总围绕开发模式、关键挑战、参考经验和实践案例四个方面，对AI辅助研发的技术与过程进行深入浅出的分析。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/62/6229db16a334e1bd89cdb8b62a317ea3.webp\" /></p><p>华为技术有限公司软件工程专家贺美迅</p><p></p><p>中国联通软件研究院软件架构师常红珍分享的主题是“代码生成模型及智能工具探索”。常总围绕诸多场景对代码生成大模型的探索与实践过程进行了剖析，通过将代码大模型与公域和私域数据相结合，构建智能体协作开发框架、智能体应用框架，并引入专家经验，实现结构化思考和优质代码的生成，突破代码片段的限制，提升软件工程效率，并对未来进行展望。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ca/cab7f0b18c7a1ae6dad24a0c0e3ec780.webp\" /></p><p>中国联通软件研究院软件架构师常红珍</p><p></p><p>国金证券技术负责人李晨带来了证券业开发大模型探索与实践的分享。李总从政策监管、开发大模型背景和国金证券落地实践的维度进行了详细分析。国金证券在设计评审类、编码辅助类、测试辅助类场景中实践成效初显，平均效率提升达30%。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b3/b3ea92cade67fff5dbcdfe44564e6824.webp\" /></p><p>国金证券技术负责人/架构师李晨</p><p></p><p>软通动力助理副总裁孙洪军分享了软通动力AISE产品研发及实践。孙总首先介绍了软通动力的AIGC整体布局，其次介绍了软通动力AISE产品的设计背景、系统架构和核心能力，最后就产品落地实践和成效展开了分享，某应用企业通过使用该产品达到20%-30%的提效。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5f/5fbc4d69003ae2325968834ba0768965.webp\" /></p><p>软通动力助理副总裁孙洪军</p><p></p><p>东吴证券信息技术总部副总经理任川分享了大模型训练和AI赋能的探索与实践。任总表示，AIGC大模型在证券行业具有广泛的应用前景，可在文案生成、智能搜索、券商智能中枢、BI助手等四大类关键领域上提供显著的提质增效服务能力。任总围绕东吴GPT分析其应用需求、应用领域和应用范式，并对未来AI规划进行分享。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e3/e392a263efdd384abee9a9f764f81db7.webp\" /></p><p>东吴证券信息技术总部副总经理任川</p><p></p><p>中软国际云智能业务集团CTO祁银红就中软在Al加速研发效能的实践和应用开发新模式的探索进行分享。祁总围绕中软的青燕平台，对探索过程与背景、核心能力及应用成效进行解析，该平台面向个人提供需求设计、文档生成、开发测试、代码生成等功能，面向组织提供全流程研发管理、测试管理、多级流水线等能力。以测试用例生成+故障排查为例，时间成本可缩短60%以上。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6d/6d005b0666ec73854052cb653092c49a.webp\" /></p><p>中软国际云智能业务集团CTO祁银红</p><p></p><p>中国信通院云大所人工智能部主任曹峰发表了《智能化软件工程(AI4SE)发展现状与趋势》的主题演讲。曹主任从AI赋能软件工程的发展历程出发，介绍了当前软件工程相关大模型的现状、开发测试运维等场景的落地分析、智能化软件工程的关键技术与挑战，以及当前中国信通院在AI4SE领域开展的标准编制、案例征集等系列工作，最后对于AI4SE的多模态、全流程、新研发模式进行了展望。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2b/2b26a8b6d59080663da6d12efea6fae1.webp\" /></p><p>中国信通院云大所人工智能部主任曹峰</p><p></p><p>沙龙的最后，应用现代化产业联盟\"AI+软件工程\"工作组正式成立，由华为、中国信通院、国金证券、联通软研院、软通动力、中软国际、国金证券、明源云等单位共同参与启动仪式。应用现代化产业联盟也欢迎更多有志于“AI+软件工程”研究的企业和伙伴加入到联盟和工作组中来，共建开放协同创新的软件生态体系，促进产业健康有序发展。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a2/a27cd48dd6717b1ff89424d73d8a6033.webp\" /></p><p>应用现代化产业联盟\"AI+软件工程\"工作组首批单位合影，左起：李晨（国金证券）、吴振亮（明源云）、孙洪军（软通动力）、曹峰（信通院）、王千祥（华为）、祁银红（中软国际）、常红珍（中国联通）</p><p></p><p>应用现代化产业联盟汇聚了产业各方力量，将会加速产业创新升级，促进产业跨越式增长，共同推动应用软件的技术提升，赋能企业开展应用现代化转型。同时也希望更多优秀的软件企业加入应用现代化产业联盟以及“AI+软件工程”工作组中来，助力擘画中国式现代化的宏伟蓝图。</p><p></p><p>应用现代化产业联盟 &amp;“AI+软件工程”工作组</p><p></p><p>黄老师：yigang.huang@ami-alliance.org.cn</p><p>李老师：Linda.lidandan@ami-alliance.org.cn</p><p></p><p>扫一扫，加入应用现代化产业联盟</p><p><img src=\"https://static001.geekbang.org/infoq/11/114d8750f1bdcb25a7345827b4776f9b.webp\" /></p><p></p>",
    "publish_time": "2023-12-11 18:03:03",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "零一万物Yi-34B-Chat 全球权威测评，开源黑马追平 GPT-3.5？",
    "url": "https://www.infoq.cn/article/6RfQJh7pxGm5FPJ2EFgB",
    "summary": "<p></p><p>继11月初零一万物发布性能优异的 Yi-34B 基座模型后，Yi-34B-Chat 微调模型在11月24日开源上线，而各家测评平台也相继给出了Yi-34B-Chat 的测试结果。</p><p>&nbsp;</p><p>模型地址：</p><p><a href=\"https://huggingface.co/01-ai/\">https://huggingface.co/01-ai/</a>\"</p><p><a href=\"https://www.modelscope.cn/organization/01ai\">https://www.modelscope.cn/organization/01ai</a>\"</p><p>&nbsp;</p><p></p><h2>各家测评结果</h2><p></p><p>&nbsp;</p><p>在斯坦福大学研发的大语言模型评测 AlpacaEval Leaderboard 中，Yi-34B-Chat以94.08%的胜率，超越LLaMA2 Chat 70B、Claude 2、ChatGPT，在 Alpaca 经认证的模型类别中，成为世界范围内仅次于GPT-4 英语能力的大语言模型。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6a/6a9c4fc531e7575e5fcf65d475dfb716.png\" /></p><p>&nbsp;</p><p>AlpacaEval Leaderboard排行榜（发布于2023年12月7日）</p><p>&nbsp;</p><p>同一周，在加州大学伯克利分校主导的LMSYS ORG排行榜中，Yi-34B-Chat也以1102的Elo评分，晋升最新开源SOTA开源模型之列，性能表现追平GPT-3.5。</p><p>&nbsp;</p><p>伯克利LMSYS ORG排行榜采用了一种最为接近用户体感的 “聊天机器人竞技场” 特殊测评模式，即让众多大语言模型在评测平台随机进行一对一 battle，通过众筹真实用户来进行线上实时盲测和匿名投票。11月份，经25000个真实用户投票计算了20个大模型的总得分。Elo评分越高，说明模型在真实用户体验上的表现越出色。</p><p>&nbsp;</p><p>在开源模型中，Yi-34B-Chat 在英语能力上进入前十。LMSYS ORG 在12月8日官宣11月份总排行时评价：“Yi-34B-Chat 和 Tulu-2-DPO-70B 在开源界的进击表现已经追平 GPT-3.5”。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2f/2f3e7d606ee4b2ef7fdc44af2325e3a4.png\" /></p><p>&nbsp;</p><p>LMSYS ORG榜单（发布于2023年12月8日）</p><p>&nbsp;</p><p>在针对中文能力的排行榜方面，SuperCLUE从基础能力、专业能力和中文特性能力三个不同的维度，评估模型的能力。根据11月底发布的《SuperCLUE中文大模型基准评测报告 2023》，11月下旬首度发布的 Yi-34B Chat，迅速晋升到和诸多国产优秀大模型齐平的 “卓越领导者” 象限。在多项基准评测中的 “SuperCLUE 大模型对战胜率” 这项关键指标上，Yi-34B-Chat 取得31.82%的胜率，仅次于GPT4-Turbo。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b1/b11a91538b615aa1301ff0c4054d7137.png\" /></p><p>&nbsp;</p><p>中文SuperCLUE排行榜（发布于2023年11月28日）</p><p>&nbsp;</p><p>值得注意的是，Yi-34B-Chat 微调模型为开发者提供了 4bit/8bit 量化版模型。Yi-34B-Chat 4bit 量化版模型可以直接在消费级显卡（如RTX3090）上使用。</p><p>&nbsp;</p><p></p><h2>真实场景如何</h2><p></p><p>&nbsp;</p><p>Yi-34B-Chat 模型实力在不同的对话场景中实力如何？来看几个更直观的问题演示。</p><p>&nbsp;</p><p></p><h4>知识与生成</h4><p></p><p>&nbsp;</p><p>问：Transformer 模型结构能不能走向 AGI ?</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d7/d78f0a4dab09a17eb32fc8654b708191.png\" /></p><p>&nbsp;</p><p></p><h4>创意文案</h4><p></p><p>&nbsp;</p><p>问：给我生成一个小红书文案，给大家安利一只豆沙色的口红。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/be/be47558b3b174390b2de5ec944c40e0f.png\" /></p><p>&nbsp;</p><p></p><h4>中文理解</h4><p></p><p>&nbsp;</p><p>问：小王给领导送了一份礼物后。领导说：“小王，你这是什么意思？”小王：“一点心意，意思意思。”领导：“你这就不够意思了。”小王：“小意思，小意思。”领导：“小王，你这人真有意思。”小王：“也没什么别的意思。”领导：“那我多不好意思。”小王：“是我不好意思。”这个意思到底是什么意思？</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f4/f4ffb796172e36d6124d32749bd91eed.png\" /></p><p>&nbsp;</p><p>据零一万物介绍，除了 Yi 系列强基座的贡献以外，Yi-34B-Chat 模型的效果还得益于其人工智能对齐（AI Alignment）团队采用了一系列创新对齐策略。通过精心设计的指令微调流程，不仅强化了模型在理解和适应人类需求方面的能力，还使得模型与人类价值观对齐，包括帮助性（Helpful），可靠性（Honest），无害性（Harmless）等。</p><p>&nbsp;</p><p>在强基座设定下，该团队采用了一种轻量化指令微调方案，该方案涵盖了单项能力提升和多项能力融合两个阶段。</p><p>&nbsp;</p><p>其中，单项能力包括通用指令跟随、创意内容生成、数学、推理、编程、泛COT、对话交互等，团队通过大量的消融实验，针对模型单能力构建和多能力融合总结了独家认知经验；在多能力融合阶段，团队采用网格搜索的方法来决定数据配比和超参数的设置，通过基准测试和自建评测集的结果来指导搜索过程，成功实现模型的多能力融合。</p><p>&nbsp;</p><p>在数据的量和质方面，零一万物团队认为，数据质量比数量重要，少量高质量数据比大量低质量数据更好，仅需少量数据（几条到几百条）就能激发模型特定单项能力。团队通过关注超出模型能力的“低质量”数据，来减少了模型“幻觉”。</p><p>&nbsp;</p><p>在指令多样性与难度方面，团队在各能力项下构建任务体系，实现训练数据中的指令均衡分布，提升模型泛化性。此外，团队发现训练数据的风格会影响模型收敛速度和能力上限的逼近程度，因此统一了回复风格，比如重点设计了CoT的回复风格，实现在轻量SFT情况下，避免了风格不一致加剧模型的“记忆”现象。</p><p>&nbsp;</p><p></p><h2>开源“满月”：有赞扬，也有质疑</h2><p></p><p>&nbsp;</p><p>Yi模型发布之初便是开源的。开源首月，Yi模型在Hugging Face社区下载量为16.8万，魔搭社区下载量1.2万，在GitHub 获得超过4900个Stars。</p><p>&nbsp;</p><p>多家知名公司和机构推出了基于Yi模型基座的微调模型，比如猎豹旗下的猎户星空公司推出的OrionStar-Yi-34B-Chat模型、南方科技大学和粤港澳大湾区数字经济研究院（简称IDEA研究院）认知计算与自然语言研究中心（简称CCNL中心）联合发布的SUS-Chat-34B等。</p><p>&nbsp;</p><p>知名技术写作者苏洋表示，根据他的近期观察，Hugging Face榜单中的前三十名有一半多是 Yi 和其他用户微调的 Yi-34B 的变体模型，原本占据榜单头部的 68B 和 70B 模型的数量目前只留有几个。</p><p>&nbsp;</p><p>苏洋曾尝试使用家里本地的机器，在纯 CPU 环境、CPU &amp; GPU 混合环境下对Yi模型进行测试，“结果比想象中要好。尤其是社区中的 finetune 后的版本，在对新闻、研究报告的摘要总结方面，对非结构化的信息中的实体识别和抽取上表现非常不错。”同时，苏洋也指出，可能是由于零一在训练过程中，出于安全考虑，过滤太多语料的缘故，一些本土化的内容仍然不够深入。</p><p>&nbsp;</p><p>根据亲身体验，苏洋总结道，34B 普通用户努努力还是能自己相对低成本跑起来的，68 B 和 70B 的模型想要本地运行，需要更多的资源，但目前分数上跟 34B 的拉不开太多差距，大概就是三四分平均分。</p><p>&nbsp;</p><p>开源后，Yi系列模型也遭到了一些质疑。</p><p>&nbsp;</p><p>开发者Eric Hartford敏锐发现了模型存在的一个问题：Yi模型使用了与LLaMA模型完全相同的架构，只是将两个张量改了名字。由于围绕LLaMA架构有很多投资和工具，保持张量名称的一致性是有价值的。Eric建议，在Yi被广泛传播前，及时恢复张量名称。</p><p>&nbsp;</p><p>Eric没有预想到，他的这个建议引来了关于Yi模型“抄袭”LLaMA的质疑。</p><p>&nbsp;</p><p>之后，零一万物很快便在各开源平台重新提交模型及代码，完成了开源社区的版本更新。零一万物表示，一个模型核心技术护城河是在架构之上，通过数据训练获得的参数和代码。在沿用了开源社区普遍使用的LLaMA 架构之上，零一万物团队从零开始，用高质量的数据集、自研训练科学和AI Infra打造了 Yi-34B 在内的系列模型。为了执行对比实验的需要，对部分推理参数进行了重新命名。原始出发点是为了充分测试模型，而非刻意隐瞒来源。</p><p>&nbsp;</p><p>Eric后来发推特为<a href=\"https://twitter.com/erhartford/status/1724563655545503822\">Yi辩护称</a>\"，“他们没有在任何事情上撒谎。所有的模型都是在相互借鉴架构。架构是学术研究的产物，已经发表在论文中，任何人都可以自由使用，这丝毫不减损Yi团队的成就。他们从零开始使用自己创建的数据集训练Yi，对开源领域的贡献是值得赞扬的。”</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/aa/aad8cc193901261e7cc18122efe10bbf.png\" /></p><p></p><p>他还补充道，“使用Llama架构没有任何问题。训练才是关键。Yi给了我们目前可获得的最佳模型，没有任何可抱怨的。”</p><p></p><p>更多阅读：</p><p><a href=\"https://www.infoq.cn/article/cVfuQaHVJ0SDPtP2jb7m?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">零一万物回应“套壳 Llama”争议：基于 GPT 研发，对模型和训练的理解做了大量工作</a>\"</p><p>&nbsp;</p>",
    "publish_time": "2023-12-11 18:08:54",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "英特尔高宇：AI工作负载有多种形态和规模，硬件上没有一刀切的解决方案",
    "url": "https://www.infoq.cn/article/hKUxUJeMmrcVrGyeDKGI",
    "summary": "<p>去年年底以来，随着ChatGPT应用体验界面的推出，使得以大模型为主的生成式AI 技术取得了重大的并且快速地发展，大模型也展现出了令人惊叹的智能涌现能力，表现出了更为强大的创造性和通用场景的普通适用性，技术得以快速发展。</p><p></p><p>首先取得重大突破的是公共通用大模型，从人类社会大量存积下来的公共数据当中去学习，进而生成高质量的文本、图像、声音甚至是视频等内容，为各个领域的智能创新和每一个人的智能体验创新提供了巨大的想象空间。</p><p></p><p>然而，出于数据的安全和隐私保护的考虑，以及更高效率，更低成本来享用大模型通用能力的角度考虑，人们又既希望获得公共大模型目前的各类强大的通用服务，同时又希望AI 能够真正理解自己，提供专属的个性化服务，还要能够充分地保障个人的数据和隐私安全，为此，公共大模型和面向个人的专有大模型混合部署，正逐渐成为产业的一个共识。</p><p></p><p>在这样的时代背景下，作为消费和商用个体用户中最坚挺的终端，PC在AIGC时代承载了怎样的使命？</p><p></p><p>12月7日，首届AI PC产业创新论坛在北京联想总部举行。此次论坛汇聚了众多用户、终端厂商、算力厂商（芯片）、AI技术厂商（大模型）、应用领域生态合作伙伴，深度探讨AI PC为AI普惠带来的巨大改变。此外，在此次论坛上，业内首份《AI PC产业（中国）白皮书》重磅发布。</p><p></p><p>与会嘉宾认为，AI PC 到来之际，大模型将成为每一个人必不可少的助手，同时对推理的算力需求将超过训练的算力需求。算力集中于云端的模式变得不可持续，AI计算负载将逐渐由云端向边缘侧和端侧下沉。在搭建本地智能算力上，CPU+NPU+GPU 异构式架构方案是目前最为成熟的方案之一。</p><p></p><p>对此，英特尔中国区技术总经理高宇表示，AI工作负载有多种形态和规模。所以，从硬件上没有一刀切的解决方案。“基于多年的学习与市场经验，我们提出了XPU的概念，包括GPU/NPU/CPU。”他说，联想是英特尔的战略合作伙伴，双方已经基于即将发布的Meteor Lake处理器推进AI体验的开发和创新。</p><p></p><p>作为算力厂商的代表，英特尔正采取三项措施，来持续构筑端侧的算力。一是构建为AI而设计的高效能AI-Ready平台；二是提供工具以支持广泛的x86应用生态系统，三是激发创新，开启全新的AI体验，包括为软件和应用开发人员提供支持，以便在各个领域里都能更好将AI功能完美部署到PC客户端上。</p><p></p><p>英特尔今年还正式启动了首个“AI PC加速计划”，将在2025年前为超过1亿台PC带来人工智能特性。其中，通过与超过 100 家 ISV 合作伙伴深度合作，并集合 300 余项 AI 加速功能，英特尔将在音频效果、内容创建、游戏、安全、直播、视频协作等方面继续强化 PC 的体验。</p><p></p><p>据了解，在实践中，英特尔13代酷睿处理器已经可以流畅运行70亿到180亿参数的大模型，并成功部署了LLM。高宇表示，即将推出代号Meteor Lake的AI PC处理器，代表英特尔40年来最重大的架构转变，旨在为AI PC时代铺平道路。它是首个内置AI加速引擎NPU的处理器，可在PC上实现高能效的AI加速和本地推理。</p><p></p><p>为了完成用户相对复杂的任务，AI PC往往需要调动不同的模型和应用，为AI PC的能力进行补充和延伸。因此，AI PC功能的发挥不仅需要像英特尔这样的算力厂商的参与，还需要整个开放的行业生态作为支撑。</p><p></p><p>在AI PC的推动下，PC产业生态将从应用为本转向以人为本，用户成为行业生态创新的驱动者和创造者。模型、应用、算力厂商都需要围绕AI PC（终端）形态下新的以人为本的需求做出改变，在研发工作中对AI的高效运行予以充分的考量，以适应AI PC新时代。</p><p></p><p>联想作为终端厂商，是离用户最近的一端，因而被推到台前，成为生态组织者和生态的核心中枢。以场景需求为基础面向用户整合产业资源，承担AI PC技术整合创新交付者、新一代个人智能体及 AI入口创造者和用户体验维护者、本地化个人数据及隐私安全守护者和开放的AI应用生态标准制定者和推广者身份，职责重大。正是出于行业责任，联想联合国际数据公司IDC发布业内首份《AI PC产业（中国）白皮书》，对AI PC进行了全新定义，以加速构建AI PC产业新生态。</p><p></p><p>高宇最后表示，AI PC加速计划由即将发布的IntelCore Ultra处理器率先驱动。未来，英特尔将搭建性能并行和吞吐量适用于融合AI的媒体/3D/渲染的GPU，打造适用于持续的AI和分担AI负载的专用低功耗AI引擎NPU；迭代能够快速响应，适用于轻量级、单次推理的低延迟任务的CPU，相信在新平台的加持下，英特尔将加快与联想共同打造混合AI算力架构，驱动AI PC落地。</p>",
    "publish_time": "2023-12-11 19:51:10",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]