[
  {
    "title": "好分期风控特征血缘关系的设计与实现",
    "url": "https://www.infoq.cn/article/whuNh2Aepd3UlC1DPyXJ",
    "summary": "<p></p><h2>一、何为特征血缘关系？</h2><p></p><p></p><p>特征血缘关系是好分期在构建风控系统过程中，产生的一种描述在数据源，特征和策略文件之间的数据转换、依赖的概念。它用于记录和追踪特征的来源，衍生以及影响的路径，能够帮助理解特征的产生和使用历史，以及对模型或是决策结果的贡献。</p><p></p><h2>二、背景</h2><p></p><p></p><p>在开始整体介绍之前，我们需要先了解一下几个特定的概念：</p><p></p><p>数据源：包括自有数据、三方数据、加工数据等，可以来自不同的数据库（如MySQL、MongoDB、HBase）或者离线数据（Hive）。这些数据经过一定的加工逻辑生成了一个数据集合。标准特征：仅有一个依赖的数据源做加工计算的特征。衍生特征：可以依赖多个数据源，多个标准特征甚至是衍生特征聚合加工所计算的特征。事件：包括用户授信、放款、额度等事件，这些事件通过流程引擎进行流转，并分为多个步骤。每个步骤包含数据节点、特征节点和策略节点。我们在流程中设计了自上而下的缓存机制，确保后续步骤能够获取到之前步骤的数据源或特征缓存。同时，特征的计算需要保证其所依赖的数据源或特征在当前步骤上线或能够获取到之前步骤的缓存，否则可能导致特征计算失败或结果为空，从而影响到策略节点的判断。策略：风控事件以策略决定事件结果。策略文件以代码或是数据的格式存在，存在着包括决策流，决策脚本，规则集，决策表等多种格式的文件集合，这些文件中既可以包含Python代码，也可以是以JSON格式表示的规则集合。</p><p></p><p>各个概念的关系如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e2/e2d42840e4f9ea540f9ef1407cf274ae.png\" /></p><p></p><p>随着好分期业务的飞速发展，我们面临的数据增长量也在加速。用户基础数据、三方数据和加工数据等，都在快速积累和扩张。同时，由于各类模型和策略所使用的特征数据关系复杂多变，其维护工作变得尤为困难。在这样一个大数据环境下，如何追踪大量特征和数据源的流向，从而明确每个数据系统中上游数据来源和下游数据去向，对于完成数据治理这一环节至关重要。</p><p></p><p>特征血缘关系的建立，旨在解决这一问题。通过构建一个清晰、有效的血缘关系，我们能更好地追踪和管理数据流动，以便进行有效的数据治理。</p><p></p><p>在实际运营过程中，我们会遇到一些挑战和问题：</p><p></p><p>1.数据间的血缘关系不明确导致重复存储和处理，定义标准混乱导致数据质量好坏参差不齐，同时特征价值评估也因此变得异常困难。这一系列问题相互影响，使得整个数据管理工作陷入困境。</p><p></p><p>2.另外，三方数据源的异常也可能对我们的业务产生影响。三方问题导致依赖于这些数据源的特征出现分布偏移，我们将很难定位影响范围，从而无法及时采取有效的纠正措施。</p><p></p><p>3.在特征衍生多层的过程中，其溯源问题也让人头痛。特别是在数据流转过程中出现问题时，由于无法确定具体错误发生在哪个环节，我们往往难以找到问题的产生源头并进行修复。</p><p></p><p>4.此外，特征之间的计算依赖性也会带来麻烦。例如在一个复杂的衍生特征计算场景中，当某一个层级的依赖特征未能及时上线，就可能导致当前特征以及下层特征计算失败，从而造成业务流程的中断。</p><p></p><p>基于以上的痛点问题，我们迫切需要一个能够清楚呈现血缘关系的方法，通过可视化的图表展示，为数据的流转提供一个清晰的链路。此外，我们也需要建立策略文件与特征之间引用关系，以进一步优化和丰富血缘关系。这不仅可以帮助我们更好地管理和控制数据，还能为风险人员提供一个更加安全、可靠的数据使用环境。</p><p></p><h2>三、与现有血缘关系的对比</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/71/717d67d23e7329d551d1110c20f0a6e7.png\" /></p><p></p><p>目前市面上常见的血缘关系是以数据库、表、字段等为出发点，主要建立表与表之间的血缘关系，如上图所示。这种血缘关系的维护多依靠人工检索和手动更新的方式，展示了数据如何在表之间进行流转。好分期血缘关系以特征为出发点，旨在建立从数据源到依赖该数据源计算的特征，再到更深层次的衍生特征，最终到引用这些特征的策略，这个完整链路的血缘关系。</p><p></p><p>另一方面，业务中的数据源、特征、策略间上下线也存在着依赖关系，如果仅支持展示数据流转的功能远不能满足我们业务对于血缘关系的要求。对于特定事件的某个步骤的特征血缘关系，需要一个更细粒度的展示，把依赖关系精细到事件乃至步骤上面。通过构建这种血缘关系，来解决目前业务中遇到的痛点问题。</p><p></p><h2>四、特征血缘关系方案设计</h2><p></p><p></p><p>先前的章节介绍了特征血缘关系的定义，产生的背景以及与现有血缘关系的差异。那它又是如何实现的呢？本章节将会通过整体架构设计，依赖树构建、基于节点属性的减枝算法、策略层的设计四个方面来进行具体介绍特征血缘关系的实现方案。</p><p></p><h3>1、架构设计</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/19/1981af3d4963474210d09f2b6e34c461.png\" /></p><p></p><p>整体采用前后端分离，前端引入了Vue做界面展示和AntV G6对依赖树进行可视化。</p><p></p><p>MySQL数据库：创建一张记录依赖关系的表。数据源和特征、特征和特征的依赖，需要在创建特征时进行记录，每个依赖都会生成一条记录，表示当前的特征依赖的一个数据源或是特征关系。数据源层：数据源层主要负责建立数据源到特征的依赖树。能够展示所有直接或是间接依赖该数据源的特征情况。特征层：特征层负责标准特征和衍生特征之间的依赖树构建。提供特征溯源的功能。同时，考虑到实际情况中存在事件某个步骤上的特征依赖关系，我们对特征节点的依赖进行了进一步的细化，附带了包括事件、步骤等多个属性的概念，相应的需要对特征依赖树做父级特征的属性匹配和子级特征的减枝操作。策略层：策略层主要负责构建策略与引用特征之间的依赖关系。不同于数据源层和特征层，策略层的关系来源于对策略文件的解析，首先对策略文件进行按类型的拆分，通过特定的正则表达式抽取出每个策略所使用的特征，然后引入倒排索引的思想构建特征到策略的映射以提高查询效率。缓存和数据变更监听：对依赖关系以及策略文件的预处理结果需要保存在缓存当中，我们采用了Redis Hash的格式进行保存处理，在一定程度上提升了查询的效率。在这种情况下，也需要保证缓存与数据库数据的一致性，防止由于缓存不一致导致的误判问题，我们采用了Binlog监听的方式保证缓存能够维持在最新状态。</p><p></p><h3>2、依赖树构建</h3><p></p><p></p><p>通过MySQL表方式记录依赖关系，在程序启动时加载数据到内存当中进行预处理形成点和边的数据结构。具体定义如下：</p><p></p><p>边格式为：’EDGE’# from_node # to_node点格式为: ’NODE’# node_id # node_name [#property_name:property_value]</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/af/afb6512384668b29eba930f1594c6e8a.png\" /></p><p></p><p>由之前的描述我们可以得出，目前业务中存在着三种不同类型的节点和四种不同的边。定义如下：</p><p></p><p>点集合： [ service_node, sd_node, dr_node ] ,其中service_node表示数据源节点，sd_node表示标准特征节点，dr_node表示衍生特征节点。边集合：[ service_node-&gt;sd_node, service_node-&gt;dr_node, sd_node-&gt;dr_node, dr_node-&gt;dr_node]</p><p></p><p>在预处理生成边结构之后，我们通过检索边的同源节点，然后以栈递归算法对边进行组装，即可生成如下图的树状图结构。</p><p><img src=\"https://static001.geekbang.org/infoq/ab/abc6213e0b375f0914507b81fd3184fa.png\" /></p><p></p><p>主要的递归算法逻辑：</p><p></p><p>1）．选定一个node A作为递归的根节点。</p><p>2）．新建两个栈结构命名为parentStack负责node A父级节点递归、childrenStack负责node A子级节点递归。</p><p>3）．查询node A父级节点并push parentStack，子级节点push childrenStack，进入并行递归。</p><p>4）．栈是否为空？</p><p>5）．取栈顶元素，重复查询其父级或者子级特征push stack，同时构建边、节点结构。</p><p>6）．重复4）、5）流程直至栈为空。</p><p></p><p>为了提升算法的执行效率，我们采用了两个栈的方法：parentStack和childrenStack。在递归过程中，我们对数据源节点进行了特殊处理，因为数据源节点已经是最顶层节点，所以无需进行重复的递归操作。除数据源节点之外，parentStack和childrenStack的算法流程基本相同。</p><p></p><p>然而，在这个过程中，我们需要注意一种特殊情况。如果在依赖树结构中存在重复的节点，可能会导致我们的算法进入重复递归的状态，甚至在极端情况下会导致栈溢出的问题。为了避免这种情况发生，我们采取了记忆化递归的策略来避免这个问题以及降低冗余计算。</p><p></p><h3>3、基于节点属性的减枝算法和属性匹配</h3><p></p><p></p><p>考虑到特征在具体事件及其各个步骤上的依赖关系，我们更进一步地细化了特征依赖的粒度。在当前的业务逻辑中，存在一个复杂的依赖关系如下图所示：一个事件a包含了A、B、C三个步骤。此时，节点C需要上线一个衍生特征dr1。</p><p></p><p>为了成功计算该衍生特征dr1，它的父级特征dr2必须能够在同一事件a被获取到。此时，dr2的步骤属性可以是B或者C，即在事件a的B或C步骤中我们都能得到dr2的值。</p><p></p><p>类似地，对于衍生特征dr2，其父级特征sd也需要能在同样的事件a被获取到。此时，sd的步骤属性可以是A或者B，意味着在事件a的A或B步骤中我们都能获取到特征sd的值。</p><p><img src=\"https://static001.geekbang.org/infoq/bc/bc27f99d965a3c8bb931f6da998dca51.png\" /></p><p></p><p>总结而言，特征在指定事件上的依赖关系，其属性当中，事件需要相等，而步骤存在置顶向下不断增大的规则。换句话说，一个衍生特征的父级特征可在该衍生特征所在步骤或其之前的步骤中获取到，但不能在其后的步骤中获取。</p><p></p><p>因此，对于4.2节中介绍的依赖树，我们在附带上属性的概念后，按照以上的规则算法进行进一步的处理。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/08/08bccd6ae6df72492fad1cfc6da6dc50.png\" /></p><p></p><p>在指定一个特定事件步骤下的衍生特征时，我们需要对其父级依赖的特征在多个属性中筛选出符合之前所述规则的属性。同时，对于它的子级特征，我们要剔除那些不满足上述规则的依赖关系。</p><p></p><p>通过这个算法，我们能够构造出一个指定事件步骤下的特征依赖树。这种依赖树可以清晰地展示出每个特征在各个步骤中的依赖关系，从而为我们提供了一种直观的理解方式。更重要的是，它能有效地防止因缺失依赖特征而导致当前特征计算失败的情况发生，也让特征间的复杂依赖关系更加易于理解和操作。避免了由于遗漏或错误的依赖关系而引发的误差，确保了特征计算的成功进行。有利于我们更好地处理和使用各个特征，进一步提升整体的数据处理和结果质量。</p><p></p><h3>4、策略与特征间的依赖关系构建</h3><p></p><p></p><p>为了方便查询策略中使用的特征，我们在业务中规定了标准特征命名以\"_sd\"结尾，而衍生特征则以\"_dr\"结尾。利用这个命名规则以及在策略中使用特征时必须使用单引号或双引号包围的特点，我们可以制定一个正则表达式来匹配出各个策略中使用的特征。</p><p></p><p>目前，好分期面临100多个风控事件，并且对应的策略文件数量也超过100个的情况。其中一些复杂的策略文件大小可能达到3-4MB。如果按照传统的检索方式，在如此庞大的文件集合中查找引用的特征，必然会遇到效率缓慢的问题。</p><p></p><p>为了解决这个问题，我们引入了倒排索引的思想。在程序启动时，对策略文件进行预处理，提取出所使用的特征，并建立如下图的依赖关系。通过这种倒排索引结构，我们有效地解决了查询时间长和占用内存过大的问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e9/e9fdb37898886a3ee14e252f03586a17.png\" /></p><p></p><h2>五、上线后的效果</h2><p></p><p></p><p>目前，特征血缘关系已经成功上线到风控平台，并且在风险和模型同学中逐步推广开来。对于数据源和特征影响范围的定位，以及特征溯源和策略是否使用等相关场景，我们不再需要通过查询文档或咨询业务人员，而是可以通过一键查询功能来实现。这样做不仅极大地缩短了问题定位的时间成本，减少了超过90%以上的耗时，还避免了评估不当导致的特征遗漏现象。血缘关系作为底层的支持工具，已经成功支持了好分期多个项目的正常运转。</p><p></p><p>下面将介绍几个业务中真实的应用场景。</p><p></p><p>案例一：查询依赖指定数据源的特征</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e2/e24485d281d575a6c53ab1a5ba3424f5.png\" /></p><p></p><p>我们使用不同的节点颜色来区分节点类型，例如黄色节点表示数据源，蓝色节点表示特征。整棵树按照从左到右的方式展开，依次展示依赖于查询数据源的一级特征、二级特征、三级特征等。</p><p></p><p>通过这种直观的树状图，我们可以清晰地看出数据源的引用路径。如果由于三方问题导致的数据源分布抖动，我们也可以迅速评估影响范围。同时，这样的可视化展示也方便我们快速了解数据源与特征之间的依赖关系，帮助我们更好地管理和维护数据源，并及时应对可能出现的风险。</p><p></p><p>案例二：查询指定特征在具体事件步骤的上下游依赖</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/89/899d450ef1a79e781565508afa195e03.png\" /></p><p></p><p>查询特征节点支持展示具体到事件步骤级别的依赖情况。我们将事件和步骤作为节点的属性进行展示，在图中以冒号隔开的字段形式呈现。</p><p></p><p>通过这种方式，我们可以更详细地了解每个查询特征在具体事件和步骤下的依赖，可以帮助我们更加全面地理解特征之间的关系，并能够更准确地分析和处理相关特征间的相关问题。同时，也有助于快速评估特征对具体事件、步骤决策的影响，以便及时做出相应的调整和优化。</p><p></p><p>案例三：查询指定特征在策略中的使用情况</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/11/11b0b190d42d892bd51f06a748c60904.png\" /></p><p></p><p>我们使用表格形式展示策略和特征之间的依赖关系，以支持查看策略文件中哪个类型的哪一行代码引用了特定的特征。</p><p></p><p>通过这种展示方式，我们可以清晰地了解特征在策略文件中的引用情况。更方便地追踪特征与策略间的依赖关系，同时也有助于快速定位特征在策略中的调用位置，以便于进行相应的问题排查工作，提高工作效率并减少出错的可能。</p><p></p><h2>六、总结</h2><p></p><p></p><p>总的来说，好分期专注于构建一个全面且独特的特征血缘关系系统，并在实现方法上与当前存在的血缘关系技术有显著的区别。至今，我们已经形成了一套比较完善和高效的解决方案，对业务中的各种问题提供了有效的处理方式。</p><p></p><p>未来，我们计划深度挖掘特征血缘关系在不同领域的潜力：例如在评估特征价值、保证数据质量、识别数据孤岛等方面，使其能够为更多领域提供深入的应用。我们会继续发展并扩展这个系统的功能，以适应业务需求的持续发展。</p><p></p><p>我们坚信，通过不断拓展特征血缘关系的应用范围和深度，能够更好地理解数据的流动和变化，从而提高模型的准确性和风控效果，同时也能为用户提供更优质的服务。我们将持续投入，为未来的风控管理提供更强大的技术支持。</p><p></p><h4>作者介绍：</h4><p></p><p></p><p>倪继昌，微财数科 变量中心高级工程师</p><p>王黎明，微财数科 变量中心资深工程师</p><p>孙丽川，微财数科 风控平台资深工程师</p><p>李军，微财数科 技术负责人</p><p>吴迪，微财数科 副总裁</p>",
    "publish_time": "2023-12-11 10:43:06",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "网易杭州研究院 / 编程语言实验室 / 负责人张炜昕博士确认出席 QCon 上海，分享低代码编程语言 NASL 从设计到落地的闯关之路",
    "url": "https://www.infoq.cn/article/dcJEkHM7VklAVYVCFKSZ",
    "summary": "<p><a href=\"https://qcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=1211&amp;utm_content=zhangweixin\">QCon 全球软件开发大会</a>\"，将于 12 月在上海召开。网易杭州研究院 / 编程语言实验室 / 负责人张炜昕博士将发表题为《<a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5642?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=1211&amp;utm_content=zhangweixin\">低代码编程语言 NASL 从设计到落地的闯关之路</a>\"》主题分享，探讨 NASL 语言的设计初衷、设计原则、实现挑战、未来展望等方面。</p><p></p><p><a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5642?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=1211&amp;utm_content=zhangweixin\">张炜昕博士</a>\"，香港大学博士，布里斯托大学 Senior Research Associate，长期从事编程语言研究。现为网易杭州研究院编程语言实验室负责人，主导 CodeWave 智能开发平台编程语言 NASL 的设计。以第一作者身份在 TOPLAS，ECOOP 等编程语言期刊和会议上发表论文多篇，并获 ECOOP“杰出软件制品奖”和 Programming 期刊“编委会选择奖”。曾任 Scala 研讨会主席，IFL 程序委员，PLDI、OOPSLA 软件制品审查委员，以及多个编程语言会议的审稿人。他在本次会议的演讲内容如下：</p><p></p><p>演讲：低代码编程语言 NASL 从设计到落地的闯关之路</p><p></p><p>NASL 是由网易自研的全栈可视化编程语言，是支撑网易数帆 CodeWave 智能开发平台的基石。本次演讲将围绕 NASL 语言的设计初衷、设计原则、实现挑战、未来展望等方面展开。</p><p></p><p>演讲提纲：</p><p></p><p>NASL 的设计初衷</p><p>○ 为什么低代码平台需要编程语言</p><p>○ CodeWave 及 NASL 的简介</p><p>NASL 的设计原则</p><p>○ 低门槛、高上限</p><p>○ 记号的认知维度</p><p>○ 编程系统的技术维度</p><p>NASL 的实现挑战</p><p>○ 如何融合企业的 IT 资产</p><p>○ 如何降低实现成本</p><p>NASL 的未来展望</p><p>○ LLM 时代的编程语言设计</p><p>○ 文本语法和标准化</p><p></p><p>听众收益点：</p><p></p><p>○ 可视化编程语言和编程系统的设计原则</p><p>○ 降低编程语言实现成本的方法</p><p></p><p>除上述演讲外，QCon 上海还将围绕&nbsp;<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart\">GenAI和通用大模型应用探索</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1596?utm_source=infoqweb&amp;utm_medium=teacherart\">AI&nbsp;Agent&nbsp;与行业融合应用的前景</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart\">LLM&nbsp;时代的性能优化</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart\">智能化信创软件&nbsp;IDE</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart\">面向人工智能时代的架构</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart\">性能工程：提升效率和创新的新方法</a>\"等专题进行交流。</p><p></p><p>QCon 上海 2023，相约 12 月！ 9 折优惠仅剩最后 5 天，现在购票立减￥680！咨询购票请联系：18514549229（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/0113b3dfb187d5f9988b7eb16d2e0594.png\" /></p><p></p>",
    "publish_time": "2023-12-11 11:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "HubSpot 使用 Apache Kafka 泳道实现工作流操作的实时处理",
    "url": "https://www.infoq.cn/article/Lpl9RkDpEsMaAarXGccH",
    "summary": "<p>HubSpot 采用在多个 Kafka 主题（称为泳道，swimlanes）上为同一生产者路由消息的方式，避免了消费者群组滞后的积压，并且能够优先处理实时流量。通过自动和手动相结合的方式探测流量峰值，该公司能够确保大多数消费者的工作流能够在无延迟的情况下执行。</p><p></p><p>HubSpot 提供了一个业务流程的自动化平台，其核心采用工作流引擎来推动操作（action）的执行。该平台可以处理数百万个活动的工作流，每天执行数亿个操作，每秒执行数万个操作。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/6e/6e79061a9bdd0b4a3384b1a443c4220b.jpg\" /></p><p></p><p>工作流引擎概览（来源：HubSpot 工程博客）</p><p></p><p>大部分处理都是异步触发的，使用 Apache Kafka 进行传递，从而实现了操作的源 / 触发器与执行组件之间的解耦。该平台使用了许多 Kafka 主题，负责传递来自各种源的操作数据。使用消息代理的潜在问题在于，如果消息发布得太快，而消费者无法及时处理，等待处理的消息就会积压，这就是所谓的消费者滞后（consumer lag）。</p><p></p><p>HubSpot 的工程主管 Angus Gibbs 描述了确保近实时处理消息所面临的挑战：</p><p></p><p></p><blockquote>如果在主题上突然出现大量消息，我们就必须处理积压的消息。我们可以扩展消费者实例的数量，但这会增加基础设施成本；我们可以添加自动扩展，但增加新的实例需要时间，而客户通常希望工作流能够以接近实时的方式进行处理。团队认识到，他们需要解决的问题是对所有相同类型或相同来源的消息使用了相同的主题。考虑到该平台被许多客户使用，如果某一个或一小部分客户开始产生大量消息，那么所有的流量均会延迟，所有客户的用户体验都会受到影响。</blockquote><p></p><p></p><p>为了解决这个问题，开发人员选择使用多个主题，他们将其称为泳道（swimlanes），并为每个泳道配置专用的消费者池。应用这种模式的最简单方式是使用两个主题：一个负责实时的流量，一个负责溢出的（overflow）流量。这两个泳道以完全相同的方式处理流量，但是每个主题都有独立的消费者滞后，通过在两者之间适当地路由消息，可以确保实时泳道避免出现任何的（或明显的）延迟。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/88/88b9e608a34183304d29218f3658f742.jpg\" /></p><p></p><p>Kafka 泳道（来源：HubSpot 工程博客）</p><p></p><p>如果可能的话，系统会从发布的消息中提取元数据，基于此在泳道之间实现消息的自动路由。例如，批量导入所产生的消息可以在消息模式中明确标记出这种操作类型，这样路由逻辑就可以轻松地将这些操作发布到溢出泳道。此外，开发人员还引入了按客户配置来限制流量的功能，并且能够根据报文消费者的最大吞吐量指标设置适当的阈值。</p><p></p><p>决定如何在泳道之间路由消息的另一个角度是查看操作的执行时间。实际操作将被路由到一个泳道，而慢速操作将被路由到另一个泳道。这一点对 HubSpot 平台尤为重要，因为客户可以创建执行任意 Node 或 Python 代码的自定义操作。</p><p></p><p>最后，该团队还开发了将特定客户的所有流量手动路由到专用泳道的方法，以防来自客户的流量意外地在主（实时或快速）泳道上造成滞后，而此时自动路由机制均未启动。这样，在团队排查延迟原因时，就对流量进行隔离了。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/11/hubspot-apache-kafka-swimlanes/\">https://www.infoq.com/news/2023/11/hubspot-apache-kafka-swimlanes/</a>\"</p><p></p>",
    "publish_time": "2023-12-11 14:33:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "深度解读“百度智能云数据库”的演进：互联网→云计算→ AI 原生",
    "url": "https://www.infoq.cn/article/Z1mDYGshu9o8IfXGVcXg",
    "summary": "<p></p><h2>一、数据库行业发展概述</h2><p></p><p></p><p>如果说今年科技圈什么最火，我估计大家会毫不犹豫选择 ChatGPT。ChatGPT 是 2022 年 11 月 30 日由 OpenAI 发布的聊天应用。它创造了有史以来用户增长最快的纪录：自 11 月 30 日发布起，5 天就拥有了 100 万活跃用户，两个月就达到了一亿用户。对比其他热门应用，同样达到一亿用户量级，TikTok 花了九个月，而像 Instagram ，Whatsapp 等应用则超过了两年时间。</p><p></p><p>ChatGPT 的爆火，瞬间点燃了整个 AIGC 赛道。最关键的原因在于，它让大家看到了弱人工智能向强人工智能的跨越式发展。英伟达 CEO 黄仁勋对此评价：ChatGPT 相当于 AI 界的 iPhone 时刻。</p><p></p><p>现在业界统一的共识是，AIGC 会改变 IT 行业的方方面面。那 AIGC 对数据库会带来哪些变化，AIGC 和数据库又会碰撞出哪些火花，这是一个值得我们去思考和回答的问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/64/648f846dd8384dfa9a1fc1a1ea4abf3e.png\" /></p><p></p><p>在回答 AIGC 对数据库的变革和影响之前，让我们先回顾下数据库发展历史。它可以分为六个阶段。</p><p></p><p>第一阶段是上世纪五十年代。这个时候数据库还在雏形阶段，以层状数据库和网状数据库为主，基础设施以大型机为主，主要用于国防和科学研究。</p><p></p><p>第二阶段是上世纪七十年代。关系型数据库出现，硬件也变成了小型机，这也奠定了数据库发展的方向。主要应用在金融，交通等关键行业。这时的代表数据库是 Oracle 和 DB2 等。</p><p></p><p>第三阶段是上世纪九十年代。PC 机已经得到了普及，数据库除了关系型数据库，也有了 PC 单机数据库。为解决企业 BI 应用诉求，数仓开始出现。数据库的应用也更多样化起来，进一步应用到企业 BI、个人办公、娱乐等场景。</p><p></p><p>第四阶段是本世纪的前十年。随着互联网开始繁荣，数据处理的需求逐渐增加，开始出现企业数据中心。业务也变成了媒体、搜索、电子商务、社交等互联网业务。由于传统数据库如 Oracle 因为价格较贵，互联网厂商大量使用开源数据库如MySQL、Redis、MongoDB 等。整个开源数据库生态开始逐渐繁荣。数据库的种类，厂家也逐渐变多。</p><p></p><p>第五阶段就是我们今天所处的云计算时代。典型应用包括新媒体、各种移动 APP、物联网、娱乐、短视频等。典型的数据库有 RDS、Aurora 等云数据库，以及 Oceanbase、CockroachDB 等分布式数据库。百度也有对应的产品，云原生数据库 GaiaDB 以及我们自研的缓存类数据库&nbsp;PegaDB 等。</p><p></p><p>第六个阶段是自 2023 年开始的 AI 时代。底层基础设施变成了 GPU 和 AI 能力。应用也变成了 AI 原生应用，如海外比较火的 Jasper、Midjourney，微软的 Copilot 等。在数据库行业我们看到至少两个方向，一个是 AI4DB，其中包括阿里的 DAS、百度的 DSC 等，主要是通过 AI 的能力去改进原有数据库的自动化能力。另外一个方向就是 DB4AI，目前主要是向量数据库。向量数据库在解决大模型幻觉等方面，有非常不错的效果，是一个有潜力的细分赛道，头部公司估值已经达到 10 亿美元。</p><p></p><p>以上就是数据库 70 年波澜壮阔的发展史。我们可以看到，每隔一段时间数据库就会在基础设施、应用场景、以及数据库本身，都有不断地变更和创新。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/92/92a9b7ae192ebfb33a9091bbf57857a1.png\" /></p><p></p><p>上面我们简单回顾了数据库发展的六个阶段。在这个过程中，我们还可以以 2000年做分界线。在 2000 年前，国内数据库基本上被 Oracle 等海外数据库主导。而从 2000 年之后，随着互联网业务的发展，国内多个互联网厂商如阿里、腾讯、百度便开始尝试使用开源数据库，实现了从最早的运维、到提交 patch、再到最后完全自研数据库的跨越式发展。</p><p></p><p>这背后从量变到质变的过程是一个典型基础软件发展过程。</p><p></p><p>一个基础软件真正得到长足发展，需要一大批高素质的技术人员，也需要深度场景的使用才能不断完善产品。另外丰富的场景和不断发展的业务，也能长期养活这批技术人员，进而形成正循环。所以说数据库的发展依赖于技术和业务的双轮驱动。</p><p></p><p>从 2000 年开始，我们看到三波浪潮——互联网，云计算和 AI 原生。我们接下来会分别来讲一下每一波浪潮为数据库行业带来的创新和变化，以及百度智能云数据库在这个过程中的关键技术和代表产品。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f6/f647b07b8603129ba05898417ae77eb5.png\" /></p><p></p><h2>二、百度智能云数据库发展史</h2><p></p><p></p><p>互联网业务特点是赢家通吃，所以互联网业务用户数规模通常比较大。因此天然要求数据库支持大规模、高可用、高可靠性、低成本以及高性能，这对数据库提出了非常大的挑战。</p><p></p><p>在第一波互联网业务的发展中，业务的挑战催熟了一系列开源数据库如 MySQL、Redis、MongoDB，又从中孵化出了分布式数据库。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/20/20e33da0350e46cb356adc79012f78ed.png\" /></p><p></p><p>接下来我们来看下百度在互联网时代的数据库发展历程，这里有几个关键节点：</p><p></p><p>第一个是自 2005 年开始使用 MySQL 数据库，这也是国内最早使用 MySQL 的企业之一。</p><p></p><p>第二个是 2014 年百度推出公有云服务，百度数据库的能力通过<a href=\"https://www.infoq.cn/article/WrlUWpf2OkgQsSAD6NJ1?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">百度智能云</a>\"开始赋能给外部企业。</p><p></p><p>第三个是 2020 年发布了云原生数据库 <a href=\"https://xie.infoq.cn/article/61a867abe6d45fa9f1fe644d0?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">GaiaDB</a>\"。百度也成为了国内少数几个具备自研云原生数据库云厂商之一。</p><p></p><p>截至目前，百度积累了 18 年的数据库研发经验，承载着内部 PB 级数据。10 万+ 的节点至今零故障零损失。</p><p></p><p>通过百度智能云输出的一站式产品，覆盖 RDS、NoSQL、OLAP、工具等领域，同时具备公共云、私有云、边缘云等软件版本多形态。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0f/0f0fe561b919a46ca824f31f4f556ce5.png\" /></p><p></p><p>前面我们提到了互联网的一大特点，就是规模大。单点肯定处理不了，所以需要引入分布式技术，也催生了分布式数据库的诞生。</p><p></p><p>百度在该领域也有非常成熟的技术，讲两个实际的案例：</p><p></p><p>第一个是<a href=\"https://www.infoq.cn/article/2012/03/baidu-bae?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">百度网盘</a>\"。百度网盘有 8 亿用户，整个数据库中单表最大超过 10 万亿条记录。整体集群超过 3000 台服务器，是国内最大的数据库集群之一。</p><p></p><p>第二个是金融行业。大家都知道金融行业对一致性、数据准确性有非常高的要求。度小满金融有 3 亿用户，年度结算金额超过万亿，其底层使用的就是百度智能云分布式数据库 GaiaDB-X。</p><p></p><p>尤其值得一提的是在 2019 年春晚红包业务中，整体交易的峰值是 12 万笔/秒。数据库的分布式能力、性能、一致性、准确性都得到了充分验证。</p><p></p><p>除了度小满，百度智能云的数据库还在多家国有大行、股份制银行和城商行中稳定运行。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/72/72d4145b2e5cf4609d5969fcd0c828a2.png\" /></p><p></p><p>互联网业务除了规模外，对性能、并发等也提出了很高的要求，因此诞生了一系列 NoSQL 数据库。不同的 NoSQL 数据库从不同层面解决互联网垂直场景的问题，今天我们讲其中的代表 Redis。</p><p></p><p>百度智能云的 Redis 服务经历十几年的技术积累和业务打磨。从规模上来看，节点规模超过 30w，其中单集群最大规模节点数达到 2700。从业务支持上看，百度 Redis 覆盖支撑了百度内部全场景业务，其中包括搜索广告、手百、地图、小度等一系列亿级用户体量的产品，为业务提供 4 个 9 以上高可用性以及微秒级请求时延服务，始终为客户提供稳定、高效、弹性可扩展的智能缓存服务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/84/8471c3e34b3cef8ce9d5754cd03b193c.png\" /></p><p></p><p>Redis 直接使用内存，但内存带来高性能的同时成本是比较贵的。因此一款能兼顾性能和成本的 Redis 产品是客户迫切需要的。考虑到业务中大量的数据是可以根据场景分出冷热的。比如视频直播、新闻/内容平台、电商场景中，随着时间的推移，数据的价值和使用频率都在下降。所以可以将部分数据自动迁移到磁盘中，从而降低存储的整体成本。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/82/8240196a262dd1948b2f1a0a9babe152.png\" /></p><p></p><p>为了解决性能和成本的平衡问题，百度智能云自研了 PegaDB。PegaDB 是在开源基础上自研的容量型 Redis 产品，相比内存型产品最多节省超过 90% 的存储成本。在成本下降的同时，PegaDB 也兼容了 Redis 丰富的数据类型和命令，让用户做到无缝迁移，兼顾了用户体验和性能优势。</p><p></p><p>除此之外，PegaDB 还有两个杀手锏功能：</p><p></p><p>一是支持在线弹性伸缩，单个集群最大规模可达 PB 级别。对用户来说不用估计使用量，只要傻瓜式即开即用即可。</p><p></p><p>第二个是支持 CRDT 同步的组件，支持异地多活和多节点同时访问、自动进行冲突合并等功能。这就让客户专注于实现业务逻辑，其他的都交给底层的数据库，完全不用操心可用性问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/82/8247c1d27f22bf8d13326b6df3fa1270.png\" /></p><p></p><p>随着云业务的诞生，让数据库的价值进一步放大。为了赋能千行百业，全托管等形态的 RDS 顺利成章的诞生了。它解决了客户最直接的安装、运维、管理等问题，因此全托管的 RDS 就逐渐推广开来。</p><p></p><p>但单体 RDS 通常有比较明显上限，在一些对性能、成本、弹性有一定要求的复杂业务中，就需要一个更强大的数据库来解决这些问题。因此，存算分离的云原生数据库就自然而然诞生了。百度智能云的云原生数据库 GaiaDB 是其中的代表之一。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1e/1e835b194141802f859a373b37363990.png\" /></p><p></p><p>RDS 全托管的产品形态代表了云计算从软件到服务的理念转变。云原生数据库极大地提高了 MySQL 数据库的上限能力，是云数据库划代的产品。</p><p></p><p>云原生数据库最早的产品是 AWS 的 Aurora。AWS Aurora 提出来的 The log is the database 的理念，通过把大量的日志操作放到后台异步处理，实现了存储独立扩展和存储计算分离，从而解决了 MySQL 数据库单库的数据量不能太大的最大痛点。</p><p></p><p>而云原生数据库在存储层面实现了扩展的同时，又保留了计算层面的不变和兼容。这种兼容 + 扩展的能力，受到了客户的极大欢迎，一下子就让云原生数据库成为各个厂商的发展重点。云数据库技术也标志着云厂商的产品能力开始和传统数据库厂商、开源产品开始拉开差距。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dd/dd48508403406795d06e50dffdebbe2f.png\" /></p><p></p><p>百度智能云的 GaiaDB 在 2020 年首次推出，除了具备云数据库的优点之外，GaiaDB 还有很多独特的技术能力，接下来我来分享其中 5 个代表能力：</p><p></p><p>第一个是共识协议。一般使用 Raft/Paxos 分布式协议的数据库，单次 I/O 需要至少两次网络往返，而且无法并行。这也就导致了分布式数据库时延很高，长尾问题更突出。</p><p></p><p>针对这个问题 GaiaDB 创新采用了 Raft 和 Quroum 结合的协议。其中 Raft 负责控制流，Quorum 负责数据流，进而减少网络往返。同时核心链路上的同步 I/O 变成异步 I/O，在保证分布式一致性的前提下，吞吐提升了 40%，时延降低了 30%。</p><p></p><p>第二个是高性能智能网络。存算分离在带来分布式和弹性的同时，也引入了网络 I/O 的消耗，因此网络 I/O 的性能和效率直接影响整个系统的表现。GaiaDB 采用高性能智能网络，这个网络有几个关键技术能力：</p><p></p><p>网络超时重定向机制。当远程 I/O 超时，会自动尝试其他副本，从而抑制单节点长尾问题。网络支持用户态协议。该协议减少了内核态 TCP 和用户态 TCP 的数据库拷贝。通过对网络的优化，平均时延从毫秒级别降低到微秒级别，提升 20 倍以上。</p><p></p><p>第三个是提供了三副本对等存储能力。由于采用了 Quorum 分布式共识协议，相比传统的 Raft 模型，每个节点都可以独立提供读写服务，没有单点故障。</p><p></p><p>第四个是多地多活。GaiaDB 是目前业界唯一可以做到多地多活的云原生数据库。在多地部署的时候，GaiaDB 模块的自适应就近访问策略可以感知元数据的变化，并根据这些变化及时切换访问路线。这种策略可以有效地应对各种故障和异常情况，确保数据的可靠性和可用性。</p><p></p><p>第五个是使用通用硬件，对硬件要求低。GaiaDB 生于云，但同时 GaiaDB 的架构对硬件的依赖度非常低。我们和很多厂商使用高性能硬件的思路不同，我们认为云的价值是普惠，所以一定要让通用服务器能发挥专业数据库的能力。因此，不同于很多云原生数据库需要依赖底层高性能的硬件，GaiaDB 从设计初就坚持使用通用服务器。因此在私有云场景下，三个节点就可以进行部署，让我们的客户可以低价享受到云上云下一套架构。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8b/8b7c7ed3a0879eebe3cc8ba586055484.png\" /></p><p></p><p>接下来我们来看一个 GaiaDB 的实际案例——百度地图。</p><p></p><p>百度地图是国民级别应用，日活用户 5.6 亿，PB 级数据。这对数据库也提出了如下的挑战：</p><p></p><p>为了保证高可用，需要多地多活的能力。节假日地图搜索，导航流量会出现十倍的上涨。这就要求在节假日需要非常顺滑的扩缩容的能力。</p><p></p><p>大规模数据量、异地多活、弹性扩缩容要求，这些要求对数据库是极大的考验。</p><p></p><p>在实际使用过程中，GaiaDB 提供 4 个 9 的可用性，RTO 切换小于 3s，RPO=0，整体 QPS 超过百万级别，给业务实现超过 60% 的资源成本节省。</p><p></p><p>总的来说，GaiaDB 成功帮助百度地图实现了极致的弹性和成本。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8f/8f02e4b25fba325d4854e72f711bde58.png\" /></p><p></p><p>云上数据库和线下数据库相比，一个较大差异就是生态能力强。相比传统线下软件只有 1~2 款产品，线上有多种数据库与多种使用环境，因此数据库矩阵更丰富，这带来了对数据库工具的诉求。</p><p></p><p>百度智能云有丰富的数据库工具，包括数据传输 DTS、数据库智能驾驶舱 DSC 等产品。我们先讲其中的代表 DTS。</p><p></p><p>百度智能云的 DTS 采取了中间抽象的数据格式，通过中间格式的翻译和转换，可以轻松做到异构迁移能力。同时 DTS 在吞吐上可以做到每秒 15 万行，延迟做到毫秒级别，基本等于网络的延迟的性能，让客户可以放心使用 DTS 来做数据库的迁移和同步。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0e/0e0d44ff1229d468f704af06b132010e.png\" /></p><p></p><h2>三、AI 原生时代的百度智能云数据库</h2><p></p><p></p><p>在 AI 原生时代，数据库和 AI 的结合主要有 DB4AI 和 AI4DB。</p><p></p><p>首先是 AI4DB，就是利用 AI 技术赋能数据库。常见场景有智能运维、智能客服、参数优化等等，刚刚提到的百度智能驾驶舱就是该领域的代表。</p><p></p><p>另外一个方向是 DB4AI，通过数据库赋能 AI 产品。当前最火的就是向量数据库。向量数据库二次的翻红主要原因是向量数据库在解决大模型幻觉、知识更新不及时有很大作用，让向量数据库的想象空间一下子变大了。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/09/096c6ccafce7598fdac1f73dfb471e4f.png\" /></p><p></p><p>AI4DB 在工业界一直有研究。相比传统机器学习算法，大模型让 AI4DB 真正走进实用时代。利用大模型的能力，百度智能云数据库发布新服务：数据库智能驾驶舱。</p><p></p><p>数据库智能驾驶舱利用最新的大模型能力，实现数据库智能化的洞察、评估和优化。根据我们的实际测试效果，优化效果非常显著：</p><p></p><p>数据库故障洞察方面，相比传统的人工定位提升 80%。领先的智能评估系统，相比传统的方法提前一个月发现数据库的容量瓶颈，规避相应的风险。AI 驱动的 SQL 优化方面，可以带来 40% 以上的提升。</p><p></p><p>相比传统基于规则的算法，大模型带来了更好的优化效果和更少的开发时间。大模型带来的切实提升让 AI4DB 走向真正的实用时代，也让数据库自感知、自修复、自优化、自运维成为现实。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a9/a9cd6b1eab7842cbdba2f1e03555c143.png\" /></p><p></p><p>下面我们来看下数据库智能驾驶舱内置的一个能力——智能问答。</p><p></p><p>这个功能可以帮助用户诊断产品问题并回答各种疑问，降低人工投入。这里面用到了大模型通用知识的能力，同时也利用 RAG 技术，把云产品文档、数据库的官方文档、内部积累的知识库进行向量化并存在向量数据库中。</p><p></p><p>在查询的时候，结合大模型和向量数据库的能力，可以给出相当准确有效的答案。</p><p></p><p>目前数据库智能驾驶舱经过验证，对历史客户工单中真实问题进行回答然后由人工进行打分，整体回复平均超过 4 分，基本可以媲美普通售后工程师的水平。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/79/79b670cada64634f9bf5577ab757d963.png\" /></p><p></p><p>接下来我们实际来看下智能问答的一个 demo。</p><p></p><p>左边的例子是询问知识库里面已有的例子，比如怎么购买，怎么实现一个读写分离的配置等。智能驾驶舱都总结得比较好，回答也非常准确。</p><p></p><p>右边的例子是询问知识库中没有的例子。我们可以发现，智能驾驶舱利用大模型的能力，可以举一反三，把解决问题的步骤给出来。我们人工去检查也会发现，这个步骤还是相对比较合理的。</p><p></p><p>所以现在智能驾驶舱的智能问答可以做到：有资料的问题准确回答，无资料的问题也可以给出相对清晰的解法。百度智能云内部已上线了该功能，大大节省了人力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/48/48ba6c7615d86cfd011247f99b44be3e.png\" /></p><p></p><p>DB4AI 的典型代表就是向量数据库。向量检索并不是一个新技术，2017年 Meta 就开源了相似度检索库 FAISS，算是向量化检索的开山鼻祖。</p><p></p><p>传统数据库解决的是结构化数据的存储和检索，非结构化数据需要先用 AI 算法 Embedding 成向量数据。需要查找的时候，把需要查找的数据的向量带过来，然后在库里面进行相似度检索。</p><p></p><p>而向量数据库核心能力就是支持向量数据存储，以及支持不同的查找算法和索引实现相识度查找。当前业界有两种不同的实现方式，一种是在传统数据库中增加插件或者功能支持向量的查找，比如 PG，Redis 都支持向量索引。这种实现相对来说容易一些，但同时性价比会差一些，通常会占用更多内存。另外一种是专业的向量数据库，专门为向量重新设计的存储和索引结构，能实现更高的性价比和弹性。</p><p></p><p>传统应用也有不少向量场景。典型场景有平安城市视频检索、电商领域以图搜图等。由于传统场景比较垂直，因此一直没有一个大的向量数据库，更多的是耦合在业务系统中。而在大模型时代，万物皆可向量化。而且当前大模型主要问题有知识更新不及时、精确性问题、数据权限管理等问题，都需要向量数据库来补充。向量数据库也因此成为大模型的标配，也在大模型时代二次翻红。</p><p></p><p>百度智能云自研的专业向量数据库目前在内测阶段，根据我们内部实际测算，在成本、规模、高性能算法、内置 Embedding 模型、向量 + 标量的联合查询方面，相比业界有很大的提升。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9b/9b9f6fcb6d97c8979c5bbbdfe17c3e09.png\" /></p><p></p><p>前面我们介绍了关键的产品，最后简单回顾一下百度智能云产品矩阵。</p><p></p><p>百度智能云数据库完整支持 RDS、NoSQL、云原生数据库，OLAP 等产品。相比业界其他云厂商，百度智能云数据库有两个显著特点：</p><p></p><p>百度智能云的数据库产品可以做到一套架构，云上云下客户享受同等的产品能力。支持国内最全的产品形态，包括公共云、私有云、边缘节点、LCC 等多种形态，可以服务各类诉求的客户。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fc/fc846845a37a6dac8eac882ad434be70.png\" /></p><p></p><p>前面我们盘点了数据库在互联网、云计算，AI 原生 3 个阶段的发展。除了技术之外，我们认为云数据库未来还要坚持两个重要的理念。</p><p></p><p>第一个是体验优先。一个好的数据库不能只是性能、成本这些方面。体验好的产品，可以让用户做到自服务。体验优先这一点在海外 SaaS&nbsp;产品中体现得更为明显。在国内，这一理念也逐渐取得从业者的认可。因此，在过去的半年里面，我们从文档、控制台、产品功能各个层面进行了深度优化：</p><p></p><p>文档：文档是用户使用和理解产品的重中之重，因此我们做了包括优化结构、补充用户场景、刷新细小的优化点在内的大量工作，目的就是让用户在使用过程中可以更方便找到自己所需要的内容。控制台：在控制台优化上，我们优化了整体结构，让用户可以更简单找到想用的功能，总共优化点超过 100 处，让用户更容易上手。产品功能：我们针对数据库的产品功能系统性安排测试定期的盲测、新员工使用等，仅仅上半年就优化了 50+ 个突出的易用性问题。</p><p></p><p>我们对体验的理解就是从用户视角入手、坚持细节、系统性的进行优化，只有通过这种深度，全方位的持续改进，才能把体验做到实处。</p><p></p><p>第二个是开放生态。丰富的生态是吸引客户、解决客户多样诉求的关键。也只有开放的生态，才能让更多的厂商一起服务好客户。</p><p></p><p>生态方面，百度秉承更开放的心态和第三方厂商合作。上半年我们和工具领域知名创业公司 NineData 正式合作，接下来会马上官宣另外一个合作厂商。</p><p></p><p>相比其他厂商，我们合作的过程也不只是简单的云市场合作。我们会和合作伙伴一起进行产品共建、优先推荐合适客户给合作伙伴、首页曝光和联合的品牌活动，增加合作方的知名度。</p><p></p><p>通过一系列的手段和措施，我们希望给到合作伙伴的是切实效果。百度智能云合作的理念就是更开放，让利合作伙伴。欢迎更多的合作伙伴和百度联系，一起服务好我们的客户。</p><p></p><p>总的来说，一个体验优先，生态开放的云，一定是客户最需要的云，也是真诚服务客户的云。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/df/dfc3dc9e74526dc0f5a93b8a4fa32c72.png\" /></p><p></p><h2>四、数据库未来的趋势展望</h2><p></p><p></p><p>站在当前看未来，数据库当前有四个关键发展趋势</p><p></p><p>AI Native。像大家比较头疼的 Oracle 转 MySQL 或者 PG，随着 AI 改写的到来，整个过程预计会变得很简单。Serverless。已经是海外云数据库的默认选项了，预计 1~2 年之后，serverless 就会在国内变得更普及。各个厂商也都会推出 serverless 数据库产品，这也是未来云产品的终极形态。内置 HTAP。HTAP 前段时间很火，不过我们判断 HTAP 很难成为一个单独的赛道，更多的是会成为各个 TP 数据库的内置能力。湖仓一体。湖仓一体预计会成为数据仓库的主要形态，不支持湖的数仓可能会很难生存，只有支持湖才能解决更多的数据问题，才能降低存储的成本。</p><p></p><p>技术和产业发展都很快，百度智能云数据库持续跟进最新的技术趋势，用优质的产品和真诚的服务回报我们的客户。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3f/3f7dafca36b251342c7b9668e005b1a4.png\" /></p><p></p><p></p>",
    "publish_time": "2023-12-11 14:50:27",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "分布式数据库 GaiaDB-X 金融应用实践",
    "url": "https://www.infoq.cn/article/2VG5NR6sg8QFttMMyQw5",
    "summary": "<p></p><h2>一、银行新一代核心系统建设背景及架构</h2><p></p><p></p><p>在银行的 IT 建设历程中，尤其是中大行，大多都基于大型机和小型机来构建核心系统。随着银行业务的快速发展，这样的系统对业务的支持越来越举步维艰，主要体现在以下四个方面：</p><p></p><p>首先是难以支持银行快速发展的业务。随着国内电商、互联网支付、手机支付的迅猛发展，银行的交易量出现指数级的增长。比如我们的某银行客户，当前每秒的交易量峰值在一万多左右，预计在未来几年会逐渐增长到每秒 6 万笔交易，而且后续还会继续增长。在这种情况下，基于大型机的集中式架构，单纯靠硬件的升配，已经无法支持业务的持续增长。第二是难以匹配银行系统的迭代更新速度。原有的基于大型机的胖核心架构，迭代周期往往在数月甚至半年。但随着银行间、以及银行与互联网金融企业之间的竞争加剧，银行迫切需要快速推出新业务进行创新，他们也希望能够像互联网公司那样，能够按周级进行快速迭代，快速响应业务需求。第三是系统风险。银行业迫切需要做到软件及硬件的自主可控。第四是生态封闭。大型机技术发展慢、人才难招。现在再去外面招一个懂 IBM 大型机的人已经很难了。</p><p></p><p>因此，在国家现有政策的引导下，各大银行最近几年都在做一个事情：把原有的核心架构从大型机下移到传统的通用服务器架构上，并建设一套自主可控的新技术体系，简称核心系统下移。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d2/d2eebfc9abdbfbf4124d2a6b76ebcb3c.png\" /></p><p></p><p>在进一步理解银行系统之前，我们先了解下银行客户的业务体量、业务需求以及核心系统对业务支持情况。以一个国有大行来举例：它的客户量在 5-7 亿，有 10-20 亿账户，在全国有 2-4 万个网点。从每秒峰值交易量来看，约为每秒 5-8 万笔交易。</p><p></p><p>具体到数据库层，支持以上业务还需要联机交易系统，例如存贷汇业务。数据库层最大的表有百亿级记录数，TPS 达到百万级。此外，统一查询业务要求支持近十年交易明细的查询，即万亿级的查询记录数。即使放到互联网公司用的通用服务器，也是需要上千台服务器才能支撑相关业务的开展。</p><p></p><p>通过以上的介绍，大家可以发现，银行客户的业务体量和数据量已经达到了大型互联网公司的量级。如果想把这个系统从大型机下移到通用服务器架构，那么原有的集中式架构肯定是无法满足的，必须像互联网公司一样采用分布式架构。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5e/5ede303f87fe7f77d969325bf8b0660f.png\" /></p><p></p><p>因为银行有和大型互联网公司相近的业务体量，因此在技术体系上，也借鉴了互联网公司的技术体系。</p><p></p><p>从 IaaS 层来看，银行采用了 X86、ARM 架构的通用服务器，也用到了混合云技术，大量使用了虚拟机与容器服务。</p><p></p><p>在 PaaS 层，银行使用了大量的分布式系统，如开源的微服务框架（例如 SpringCloud ），以及开源的或者商业的数据库，包括分布式/单机/关系型/缓存型的数据库，以及日志数据库 ES、时序数据库等。在中间件层，也用到了大量的开源的或者基于开源改造后的组件，例如消息队列、对象存储、分布式锁等。</p><p></p><p>在 SaaS 层，银行主要通过单元化 + 微服务的架构来实现分布式扩展。银行将自身业务应用划分成三种单元。</p><p></p><p>最上层是全局单元，主要是起到全局路由及流量分发的作用。第二层是业务单元，核心的业务逻辑都在该部分来实现。同时，为了实现业务的横向扩展并支持数亿客户量，银行业跟互联网公司一样，对业务进行单元化拆分。例如我们接触到的某银行，就是将自身的业务拆分为了 16 个业务单元，每个单元五千万客户， 16 个单元部署在两个机房形成同城双活的架构。最底层是公共单元，一些不太好或没必要做单元化拆分的应用，放在公共单元提供公共服务。</p><p></p><p>通过上述分析可以看到，在新一代银行核心系统里面，整体的架构体系已经和互联网公司很接近了，大家用的都是相同的技术栈，只是服务的业务场景不同。在未来，银行业跟互联网业的技术交流会进一步紧密，人才的流动也会进一步频繁。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6d/6dada50bc1d570cafbcad31f40a441dc.png\" /></p><p></p><p>在业务采用了单元化划分后，数据库的架构是怎么样的呢？目前在银行的新核心系统下移中，主要采用了以下两种数据库架构：</p><p></p><p>第一种是单机数据库架构。这种数据库架构比较简单，故障域较小，但相对来说业务系统会比较复杂。因为有些模块，如全局路由模块，是全局的总入口，没法做单元化拆分。因此一组单机数据库无法满足性能与容量需求，依然需要在业务层做数据拆分。除此之外，单机数据库无法完全支持业务单元层的业务落地。前面提到，我们接触到的某银行一个业务单元要承担五千万的客户数，一组单机数据库依然无法支持。于是在业务层进一步拆分为 4 组数据库共 64 张子表，业务层需要去解决大量的拆分及分布式事务相关的业务逻辑，整体就更复杂了。</p><p></p><p>另外一种是分布式数据库架构。这样的数据库内部架构虽然更为复杂，但它可以提供更好的性能。对业务层来说，一个单元采用一组数据分布数据库即可，业务层的逻辑就更为简单了。</p><p>因此我们认为，随着分布式数据库的逐步成熟与应用逐渐广泛，业务单元化 + 分布式数据库会逐渐成为流行的银行业务架构。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/18/1805f802303d1452f0ddc0dcf9e08ef3.png\" /></p><p></p><p>综上，银行核心系统在下移的场景下，对数据库在如下几个方面提出了要求：</p><p></p><p>第一是分布式扩展性。由于采用了通用服务器，它的单机性能要远弱于大型机或者小型机。在这种情况下，数据库需要具备分布式可扩展的能力来满足上亿客户的金融需求。第二是强一致性。金融场景对数据正确性、一致性的要求极高。因此要严格保障对事务的 ACID 特性。否则，业务层就要做大量的工作。第三是容灾能力。通用服务器在硬件故障率方面要比大型机、小型机高很多。因此需要我们的数据库有更为可靠的可用机制以保障 SLA。同时，监管对于容灾能力的要求也在不断提升。比如，对于新建设的核心系统，监管要求必须满足 5 级以上的容灾能力，且满足同城双活并保证 RPO 为 0。在具体执行上，监管的要求也越来越严格，比如同城双活，之前是只需要具备相关的技术方案即可，但现在每年人行的监管都会直接到现场，要求做机房级实战故障切换。第四是运维能力。系统下移到通用服务器并实现去 IOE，数据库节点数量要出现 50 倍的增长。以我们的一个银行客户举例，从小型机下移后，数据库节点数从 20 增长到 1000（当然这里面也预留了几倍的性能增量）。在和客户的交流过程中，他们也认同这个观点，认为系统下移后，节点数要增长一到两个数量级。但运维的人力不可能因此增加几十倍，在这种情况下，就要求我们的运维效率要有质的提升，需要能够智能化、自动化去做相关的运维工作。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9e/9e70f9a0a35e389e4bda5d5de854c137.png\" /></p><p></p><p></p><h2>二、分布式数据库&nbsp;GaiaDB-X 的金融场景方案</h2><p></p><p></p><p>接下来我们分享第二部分，分布式数据库 <a href=\"https://xie.infoq.cn/article/1febbf974afe91b9a1e11517f?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">GaiaDB-X</a>\" 针对金融场景的解决方案。</p><p></p><p>GaiaDB-X 数据库是<a href=\"https://www.infoq.cn/article/WrlUWpf2OkgQsSAD6NJ1?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">百度智能云</a>\"研发的 Shared Nothing 架构的分布式数据库，它可以基于通用服务器做横向扩展，来满足高性能、大数据容量的需求。</p><p></p><p>总体来看它分为计算层、存储层、元数据三层架构：</p><p></p><p>计算层是无状态、可横向扩展的一层。它对外兼容 MySQL 协议，接收到 SQL 请求后，再经过 SQL 解析、权限检查、逻辑优化、物理优化之后，生成 DistSQL 下发到各个存储层的分片。为了达到更好的性能，逻辑与物理上尽量将数据过滤及计算能力下推到存储层，收到结果后，再把数据进行聚合计算，最后返回给客户端。计算层的下面是存储层。它采用多分片的方式进行扩展，数据按照一定的分片规则打散到了各个分片中。我们支持 Hash、Range、List 等分区方式来做数据分区。同时，分片内数据采用多副本的方式来保证可靠性，第三是 GMS 节点，即全局元数据管理模块。它用来管理全局性数据，例如表的 Schema 信息、权限信息、表的路由信息，还有后面要介绍到的用于做分布式事务的全局逻辑序列号。GMS 也采用多副本的方式，采用 Raft 协议进行数据同步。</p><p></p><p>在最底层是我们的统一数据库管控平台，来实现对数据库集群的管理。比如在<a href=\"https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA%3D%3D&amp;chksm=fbeb6a36cc9ce320cf9c590dcbaa67d53421a43a56ea8378ce2b96f0c1c3c3f17265ea54d9b9&amp;idx=1&amp;mid=2247570425&amp;scene=27&amp;sn=bc5f1eeba437ce5e619ccef9bc0321d3&amp;utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search#wechat_redirect\">百度</a>\"集团内部数十万的数据库节点，都是由该管控平台来管理的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/50/50f58801a7c4eeb2bddfece8e453df59.png\" /></p><p></p><p>GaiaDB-X 数据库是百度集团发展历史最久、应用最广泛的一款数据库，到现在为止已有 18 年的发展历史。它的发展也与百度的业务发展息息相关，大概可以归纳为四个阶段：</p><p></p><p>第一阶段是从 2005 年开始，为了满足搜索、社区业务中大量读请求的场景，我们通过一主多从的集群化外加读写分离来扩展读性能。第二阶段是为了支持凤巢广告系统与百度网盘，满足它们对万亿级数据量的需求，我们开始做分布式系统。到了 2014 年，我们就已经在凤巢广告系统中替换了基于 Oracle 的盘柜，为凤巢每年节省了上千万的成本。针对百度网盘，我们有个 3000 台服务器的集群支持网盘业务，所有网盘文件的元数据信息都存储在这里，最大的表达到万亿级记录数，至今仍是国内最大的关系型数据库集群之一。第三阶段是随着百度钱包等泛互联网业务的兴起，对数据的一致性要求更高了。因此，我们实现了分布式事务强一致的特性，保障金融数据的正确性。第四阶段，也就是现在。随着百度智能云对外技术输出，我们已经把数据库输出到了十余个行业，覆盖 150 家客户。在金融行业，GaiaDB-X 已经承接了金融核心业务，包括百信银行、银联商务、某交易所及国有行等。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/43/43f859c5ceefd365e4a3567012ce9242.png\" /></p><p></p><p>对于分布式数据库，水平扩展能力是其核心能力。除了在计算层与存储层做水平扩展外，我们还要着力去解决影响我们扩展能力的单点。</p><p></p><p>第一个是 GMS，即全局元数据模块。因为它要提供一个全局递增的全局逻辑时钟，每一次事务都需要调用它。为了避免其成为瓶颈，我们采用批量预分配的方式来提升其总吞吐，在此模式下，其每秒可分配 1200 万个 TSO 序号，远超出百万级 TPS 的需求。</p><p></p><p>第二个是全局事务表。为了保证分布式事务的原子性，我们需要将正在进行中的事务保存到一张全局表中，因此它的性能也会直接影响到全局性能。我们采用自管理的方式，将全局事务表做成分布式表，分布式地存储在集群中，这样就可以实现分布式扩展。</p><p></p><p>在实际应用中，比如说像 19 年的春晚抢红包，我们支持了三亿用户抢红包，支撑了峰值达每秒 12 万交易量。除此之外，针对某银行拥有 8000 万账户的核心账务系统，我们也平稳支持了其 6 万每秒的 TPS ，充分验证了 GaiaDB-X 的水平扩展能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/56/560fef70a125720cb796e7ddf53eb3d3.png\" /></p><p></p><p>除分布式外，我们也支持单机场景，实现了单机分布式一体化。为什么需要单机分布式一体化呢？以我们的一个银行客户来说，全行的业务系统有 200 多个，其中大部分系统（大概占 70% 左右）对性能与吞吐的要求并不高，一组单机数据库就能够满足其业务需求。但对于剩下的 30% 业务，它对性能的要求是单机数据库无法满足的，需要分布式数据库来满足其扩展性。</p><p></p><p>因此我们通过一体化的方式，来满足银行不同体量的业务对于数据库的需求。同时，我们也具备单机数据库扩展为分布式的能力，在对应业务的数据量增长后，能够扩容为分布式。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/15/15483b1c6cffdb73ad5178a621526e14.png\" /></p><p></p><p>扩展性的另外一个目的是自动做数据分离。在金融场景里面，存在多个业务共用一个数据库集群的场景，比如业务分为联机交易系统与查询类系统，数据库便对应划分为交易库和历史库两个。</p><p></p><p>对于交易库来说，只保存联机交易会频繁使用到的数据。例如账务结果数据及当天的交易记录，以满足对交易业务的快速响应。对于查询不那么频繁的即时交易记录，这可能就是一个相当大的数据量，一般都能达到千亿甚至万亿级别。这时，我们就可以将这个数据自动转移到历史库上去，用更高密度的存储机型来存储。一方面可以降低硬件成本，同时也可以避免对联机业务的影响。</p><p></p><p>这样做对业务来说，对外呈现的是一套数据库，业务可以根据需要来处理不同数据分区的逻辑，也不用在多套库之间通过 DTS 做数据同步。同时还把交易数据和历史数据做分离，以保障对联机业务的性能，同时也满足了查询业务的查询需求，避免其相互影响。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/09/09461237b2307a25d9e1a17349640b7b.png\" /></p><p></p><p>在金融场景中，对事物的 ACID 特性有着严格的要求：</p><p></p><p>持久性。指的是事务一旦提交就不会丢失，一般通过多副本 + 强同步来解决。原子性。一个事务要么全部提交，要么全部回滚，不存在部分提交的情况。通常，数据库的 XA 协议，通过两阶段提交能解决这个问题。</p><p></p><p>但是 XA 协议不能很好地满足一致性与隔离性。以简单的转账场景为例，A、B 原来各有 100 块钱，总共 200 块。然后 A 给 B 转账 50 块钱。此时，我们会先给 A 扣 50，再给 B 加 50。如果通过 XA 协议来做的话，先走 prepare 再 commit，我们可以看到，commit（图中第 7、第 8 步）过程不是原子过程，存在一个执行时间差。在这个时间差内，另外一个事务去读取数据，就可能存在读到提交了一半的数据，A 和 B 的总和是 150 而不是 200。这是 XA + 2PC 解决不了的问题。</p><p></p><p>为了解决这个问题，业内一般是引入一个全局时钟来做一致性的保证。通常有三种实现方式：</p><p></p><p>TrueTime 方案。这个是大家比较熟悉的方案，Google Spanner 也发过论文。但它的缺陷是依赖硬件，要引入 GPS 与原子钟，这个一般来说是难具备的。HLC 方案。采用该方案的典型数据库系统是 CockroachDB，它的优点是不依赖硬件，而且是去中心化的。但是缺点也很明显，一致性比较弱，而且要求服务器间的时钟误差不能超过 250ms，否则就无法正常运行。TSO 方案，比如 TiDB 就是采用了这种方案。TSO 本质上来说是一个全局唯一而且自增的逻辑序列号，一个事务在开始时与事务 commit 时需要两次找 GMS 获取序列号，然后把 TSO 号作为版本号提交到存储层，存储层的 MVCC 机制来判断数据是否可见。它不需要硬件具备强一致性，但缺点是依赖一个全局中心的时钟分配器 GMS。但这并不是一个问题，因为刚刚我们也提到了，虽然 GMS 不具备扩展性，1200 万的 TPS 已经完全满足业务的常规需要了。因此我们最终采用了这种方案。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b1/b192d1774be97ac09d153b3e3fcf81d9.png\" /></p><p></p><p>除了保障事务的一致性外，我们还需要保障上下游系统的数据一致性。在开始之前，我们首先要讲一下银行的典型业务场景，它一般分为三个子系统：</p><p></p><p>第一个是联机交易系统，例如存取款、在线支付等。这个系统的并发量高、延迟敏感，直接影响到用户体验。第二个是跑批类的业务系统。例如结息，每天晚上半夜计算前一天的利息。这些业务是后台业务，有大量的读取与计算操作，延迟不敏感，但是对数据一致性要求高。怎么能够让这样的业务尽量避免对在线业务的影响，同时又能够读取到最新的数据呢？我们的方式是让跑批业务去读取从库数据，从而避免对主库的性能影响，同时结合 TSO，即全局逻辑时钟的对位对齐机制。等到从库水位追齐之后，才返回读取数据。当然这会引入一定的延时，但是因为跑批业务对响应延时不那么敏感，所以是可以接受的。第三个子系统是大数据类的离线业务。通常来说，就是银行内部的各种大数据、数仓等系统，需要把数据库的数据同步过去。这样的业务对实时性要求不高，但要求最终的数据是一致的。由于各个计算节点都会承担流量，也会生成 BinLog。因此，如何对多份 BinLog 进行排序，让它们能够严格保持时序是我们需要解决的问题。我们的全局 BinLog 有两个模块，一个是 pump，从各个CN 节点抽取 BinLog，然后在 Sorter 节点基于 TSO（全局逻辑时钟）进行排序，来保障形成一个全局时序正确的 BinLog，以保障这个离线系统收到的数据的最终正确性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/17/17a48e22473b043b5053080788477dae.png\" /></p><p></p><p>接下来我们看一下容灾能力，除了对单机故障的容灾之外，还有对特定机型的容灾。因为银行把系统下移到通用服务器，通常都是通过两阶段来实施：第一阶段是下移到 X86 的 CPU 芯片上，这个过程银行、互联网厂商都一定的经验。第二阶段是要实现服务器芯片的基本国产化，就是说使用国产的鲲鹏、飞腾或海光 CPU 芯片，这方面大家都是在探索性的开展相关业务。</p><p></p><p>以百信银行举例，它与其母行中信银行一样，选择了基于鲲鹏做国产化的路线，而且在业内比较超前。相较于其他银行仅在周边系统或者数据库从库来做国产化，百信银行的周边业务跟核心系统都和主站一样基于鲲鹏服务器来做，这个在业内是较为领先的。</p><p></p><p>为了保证客户业务系统实现平滑的国产化，我们在产品上实现了一库多芯的方案，主要资源池基于鲲鹏，但放置了一个独立 X86 资源池，在技术上实现托底，同时也能够将原有换下来的服务器能够利用上，避免资源浪费。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/17/173396e11937ad6b3f0e88e0a6e8fb31.png\" /></p><p></p><p>根据人行的监管要求，银行核心系统一般要具备 5 级以上的容灾能力，这就要求具备两地三中心的容灾能力。</p><p></p><p>下图是我们客户的一个典型机房部署架构。首先在北京有两个同城机房，其物理距离在 50-100 公里左右，网路延迟在 1ms 左右。同时还有一个异地机房做灾备，物理距离一般是 1000 公里左右，比如合肥，网络延时是 10ms。</p><p></p><p>同城两个机房业务做双活部署，同时接受业务流量。数据库在两个机房采用 3 + 2 的部署形式，机房间采用强同步的方式来保障在发生机房级的故障之后，数据库能进行故障切换，而且保障数据的 RPO 为 0。</p><p></p><p>为保证单机房故障后的零数据丢失，我们采用分组强同步的方式，将 id1、id2 各划分一个复制组，复制组间采用强同步的方式。每个复制组保证至少有一个副本接收到数据之后才返回成功。这样在容忍少数副本故障的同时也能够保证单个机房故障后的零数据丢失。</p><p></p><p>异地机房的目标是当北京的两个机房都出现灾难性的事件之后，能够降级完成核心业务。它采用异步级联的方式来同步数据，首先异步是为了避免阻塞对主地域的数据库写入；采用级联方式，没有跟主地域机房形成复制组，主要一个为了保持灾备机房的数据库的拓扑独立性，减少依赖，保障在关键时刻可切换，另外也是降低跨地域同步的数据量，只需要同步一份数据即可。</p><p></p><p>结合在多家金融客户的实践，我们和中国信通院一起发布了金融数据库的容灾技术报告《金融级数据库容灾备份技术报告（2021 年）》。大家可以在公众号后台回复「金融级数据库容灾备份技术报告」获取。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c3/c35b7ca466e4e027b09f699a6c555063.png\" /></p><p></p><p>最后一部分是运维能力。核心系统下移及国产化的背景之下，数据库系统呈现两个变化：</p><p></p><p>一是数据库的节点数出现了 50 倍的增长，这里面既有技术架构的原因，也有数据库预留了一定的性能空间的原因。</p><p></p><p>二是数据库的种类也变多了。对于银行系统来说，之前基本就是选择 Oracle 或 DB2。现在则开始使用多种开源数据库和国产数据库。除此之外，为了避免像之前一样被单一厂商绑定，银行也会特意选择多家数据库厂商，在这种情况下，对银行的运维的挑战就更大了。</p><p></p><p>因此，结合百度集团及百度智能云管理大规模数据库节点方面的经验，我们将 GaiaDB-X 数据库云管平台进一步泛化，形成了具备管理多元数据库能力的统一平台，它除了能够管理 GaiaDB-X 自身，也能管理其他的开源数据库。通过帮助银行建立企业级的 DBPaaS 管理平台，进一步提升了银行的运维效率。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f5/f5b5b67c12e920a404b8a06be4702a30.png\" /></p><p></p><p></p><h2>三、金融应用案例介绍</h2><p></p><p></p><p>接下来，我来分享百度智能云在金融方面的一些典型案例。</p><p></p><p>首先是百信银行。它的特点是完全去 O，是一家完全没有 Oracle 的银行。全行 200+ 业务系统，无论是核心账务系统还是周边系统，几乎全部是基于 GaiaDB-X 数据库来构建的，至今已经平稳运行五年。</p><p></p><p>按数据库节点数计算，百信银行目前的数据库国产化率达到了 99.93%，遥遥领先于行业平均水平。</p><p></p><p>同时，百信银行在容灾和国产化领域也比较领先，在 2019 年就完成了全行主要系统的同城双活建设，2022 年开始将全行业务逐步迁移到基于鲲鹏的国产云上，进而实现了全栈的国产化。</p><p></p><p>在硬件成本方面，我们通过采用通用服务器来替代 IOE 硬件，帮助百信银行的单账户平均硬件成本降低了 70% 以上。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5e/5eba560cf050d18ba1d18d015ebab4c0.png\" /></p><p></p><p>下图是人行下面直属的某交易所。因为是涉及到国家金融稳定，所以在核心系统上需要逐步摆脱对 Oracle 的依赖，并拥有两地三中心的容灾能力。</p><p></p><p>由于当前的一些数据库都不能满足他们的业务场景需求，因此该交易所和百度采用了联合开发的模式，共建数据库能力。在两年的合作过程中，我们从外围的信息管理系统入手，逐步深入到核心交易系统，再到离线库数据分析系统，进而逐步实现数据库国产化。</p><p></p><p>此外，由于交易所的交易系统对低延时的要求较高，同时基于容灾要求又有同城双活的要求，如何在跨机房的情况下保障交易延时就成了亟待解决的问题。因此我们共同建设了 Collocate 机制，来尽量减少跨机房数据的访问，最终将交易延时从 80 毫秒降低到了 15 毫秒。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d3/d3bbb84070b281ebbedf2e41e6edc456.png\" /></p><p></p><p>下图是国内某国有大行客户。他们在最近两年把原有的基于小型机的核心系统下移到了通用服务器中，数据库也从 Oracle 替代为了开源单机数据库。</p><p></p><p>但在这个过程中，该行面临两个问题：一是数据库节点数增长了 50 倍，服务器数量到达了 1000 台左右，如何做好数据库的自动化部署、上线变更、版本升级、参数管理、性能诊断等工作。二是如何结合业务的单元化，形成业务与数据库的同城双活与异地容灾能力。</p><p></p><p>借助百度智能云提供的统一数据库管控平台的能力，历时两年，我们与客户一起实现了新核心系统的全面投产，也顺利通过了人行的验收。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b9/b935db0fd9ff535ed78234e80ac12688.png\" /></p><p></p><p></p>",
    "publish_time": "2023-12-11 15:03:34",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "百度8500万挖不来“AI教父”；淘天年薪百万起步抢全球顶尖人才，上不封顶；王慧文病休后首次动作：AI投资｜Q资讯",
    "url": "https://www.infoq.cn/article/uJ79bU5Wreox7MGdKmLQ",
    "summary": "<p>&nbsp;</p><p></p><blockquote>阿里将首次派发年度股息，总额近179亿；淘天集团抢全球顶尖人才，年薪百万起上不封顶；百度8500万挖“AI教父”被拒，选择入职谷歌；比尔盖茨每天收入1095万美元，约普通人一生收入4倍；谷歌发布自己“最强”Gemini大模型遭质疑：演示视频疑似剪辑；王慧文病休后首次动作，入股OneFlow团队新创业项目；卷入300亿骗局官司，京东回应：这是一个匪夷所思的恶意诉讼……</blockquote><p></p><p>&nbsp;</p><p></p><h2>科技公司</h2><p></p><p>&nbsp;</p><p></p><h4>阿里将首次派发年度股息，总额近179亿</h4><p></p><p>&nbsp;</p><p>12月6日，阿里发布公告，将向截至2023年12月21日收市时登记在册的普通股持有人和美国存托股持有人，就2023财年首次派发年度股息。金额分别为每股普通股0.125美元或每股美国存托股1.00美元，以美元支付。根据披露，股息总额约为25亿美元（当前约179亿元人民币）。阿里称，在现有股份回购计划基础上继续努力提高股东回报。</p><p>&nbsp;</p><p>此次面向全体股东的派息决定，是阿里巴巴2014年上市美股，以及2019年再次回归港股以来首次大规模分红派息。据梳理，阿里巴巴成立以来就以保守的财务经营策略闻名，包括本次分红派息在内，仅有3次分红派息记录。</p><p>&nbsp;</p><p></p><h4>淘天集团抢全球顶尖人才，年薪百万起上不封顶</h4><p></p><p>&nbsp;</p><p>近日，淘天集团启动一项名为T-Star的顶尖人才招聘计划，发放的offer不设层级，采取定制化培养模式，配备“大牛”主管和顶级研发平台资源，年薪百万起上不封顶。</p><p>&nbsp;</p><p>根据淘天集团招聘官网公布的信息，目前，T-Star计划已经开放了10种算法工程师岗位，工作方向包括自然语言处理、机器学习、多模态、三维重建、计算机视觉、3D等，工作地点为杭州、北京等。</p><p>&nbsp;</p><p></p><h4>百度8500万挖“AI教父”被拒，选择入职谷歌</h4><p></p><p>&nbsp;</p><p>12月4日，据知情人士透露，百度公司曾出价1200万美元(约合8486万元人民币)邀请“AI教父”杰弗里·辛顿(Geoffrey Hinton)及其学生加入公司，但被拒绝。“我们不知道自己值多少钱。”辛顿表示。他咨询了收购方面的律师和专家，想出了一个计划：“我们将组织一场拍卖，自己兜售自己。”</p><p>&nbsp;</p><p>最终，辛顿博士和他的学生们在4400万美元(约合3.1亿元人民币)的价格上停止了这次拍卖。虽然出价仍在上升，但他们想为谷歌工作。这一报酬已经很惊人。据悉，今年5月辛顿宣布从谷歌离职。辛顿表示，从谷歌辞职是为了可以自由地谈论AI的风险。他说，现在对自己一生从事的工作感到有些后悔。</p><p>&nbsp;</p><p></p><h4>比尔盖茨每天收入1095万美元，约普通人一生收入4倍</h4><p></p><p>&nbsp;</p><p>根据求职信息网站Zippia的数据，一个普通人一生的平均收入约为270万美元，而比尔·盖茨一天的收入大约是这个数字的3~4倍。据预计，盖茨每天的收入约为1095万美元，相当于每秒约117美元。还有另外一组数据显示，盖茨每天进账约760万美元，相当于每小时319635美元。</p><p>&nbsp;</p><p></p><h4>谷歌发布自己“最强”Gemini大模型遭质疑：演示视频疑似剪辑</h4><p></p><p>&nbsp;</p><p>谷歌 12 月 6 日宣布推出其认为规模最大、功能最强大的人工智能模型 Gemini。Gemini 将包括三种不同的套件：Gemini Ultra、Gemini Pro 和 Gemini Nano。根据谷歌给出的基准测试结果，Gemini 在许多测试中都表现出了“最先进的性能”，甚至在大部分基准测试中完全击败了 OpenAI 的 GPT-4。</p><p>&nbsp;</p><p>同时，谷歌也发布了Gemini Ultra官方演示视频，展示了这款模型的强大能力。不过，依然有人质疑Gemini的能力。</p><p>&nbsp;</p><p>据报道，Gemini在MMLU多任务语言理解数据集测试中显示出色，但对比GPT-4时的提示技巧和展示方式引发了争议。质疑者认为，Gemini在使用提示技巧+32次尝试的标准下超越了GPT-4，但这一标准是否公平受到质疑。图表比例尺的问题也被揭示，引起了技术主管的修正。Gemini发布的视频在展示时也引起了关注，部分观点认为其中可能存在剪辑和非实时录制。</p><p>&nbsp;</p><p>查看更多：</p><p><a href=\"https://mp.weixin.qq.com/s/Yqi4rcyEmvg9g6LCqbxYxA\">刚发布就被质疑？超过 GPT-4 的“最强”大模型 Gemini、“最高效”训练加速器，谷歌到底行不行</a>\"</p><p>&nbsp;</p><p></p><h4>王慧文病休后首次动作，入股OneFlow团队新创业项目</h4><p></p><p>&nbsp;</p><p>在病休近6个月后，王慧文突然有了新动作，再次与袁进辉牵手，入股其创业新公司硅动科技。据公开资料显示，就在这两日，北京硅动科技有限公司新增王慧文为股东，注册资本由100万人民币增至约105.26万人民币。也就是说，王慧文目前在袁进辉新公司的持股比例约为5%。</p><p>&nbsp;</p><p>OneFlow是国内知名开源深度学习框架及开发平台。其团队上次创业一流科技时，由王慧文的光年之外收购其46.52%股权。不过，随着6月底光年之外创始人王慧文病退消息曝光，美团收购光年之外100%的权益，一流科技OneFlow团队作为其核心资产也转归美团名下。在50天后，袁进辉宣布带领OneFlow原班人马再次创业。消息传出后不到半个月，硅动科技注册成功。</p><p>&nbsp;</p><p></p><h4>“腾讯视频崩了”上热搜</h4><p></p><p>&nbsp;</p><p>12 月 3 日晚，腾讯视频出现网络故障，有网友反馈出现首页无法加载内容、VIP 用户看不了会员视频等情况。#腾讯视频崩了# #腾讯会员 没了#词条相继冲上微博热搜。</p><p>&nbsp;</p><p>稍晚些时候，@腾讯视频就“App 崩了”发布致歉声明称，目前腾讯视频出现了短暂技术问题，我们正在加紧修复，各项功能在逐步恢复中。感谢您的耐心等待，由此给您带来的不便我们深感歉意。</p><p>&nbsp;</p><p>除了腾讯视频，近期遭遇宕机事件的还有滴滴、淘宝、闲鱼、钉钉、阿里云盘等多个App。据媒体统计，以此被多家媒体报道或登上热搜榜为基准，2022年约发生了9起宕机事件，而今年以来，类似的事件已发生14起。</p><p>&nbsp;</p><p>更多阅读：</p><p><a href=\"https://mp.weixin.qq.com/s/-KVKVfq0CayLyRkEbp2Rcg\">互联网大厂“组团”宕机，都怪降本增“笑”？</a>\"</p><p>&nbsp;</p><p></p><h4>被卷入300亿骗局官司，京东回应：这是一个匪夷所思的恶意诉讼</h4><p></p><p>&nbsp;</p><p>12月4日消息，最近京东集团、承兴集团、诺亚财富之前的各种消息闹得沸沸扬扬，京东还被告上法庭。据悉，此事起因是承兴集团的罗静造假，冒充京东工作人员，并私自刻章，以京东、苏宁等应收账款来找金融机构（诺亚财富）贷款，最终骗走300亿并跑路暴雷，结果被抓。诺亚财富一纸诉状把京东给告上法庭，想让京东还钱。</p><p>&nbsp;</p><p>对于此事，京东集团官微“京东发言人”最新发布一份声明回应，称京东作为毫不知情的受害者，被卷入历时四年的恶意诉讼中，公司的声誉和权益遭受重大损失，相信法院会有公正的判决。12月4日晚，诺亚财富发布声明称，已关注到京东集团发布的关于我司的声明，该声明中“诺亚财富近年来先后发生十余起类似事件，上百亿基金......”等描述严重失实，已侵犯了我司名誉，我司将采取法律措施，维护自身合法权益。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>IT 业界</h2><p></p><p>&nbsp;</p><p></p><h4>小米14手机内核已在GitHub开源</h4><p></p><p>&nbsp;</p><p>据报道，小米14/Pro内核现已在Github开源，AOSP版本基于Android U。公开内核源码可以让第三方开发者进行修改，开发人员和愿意折腾的用户能够充分利用硬件的潜力，市场上也会很快出现该机型的第三方固件。</p><p>&nbsp;</p><p>开源地址：</p><p><a href=\"https://github.com/MiCode/Xiaomi_Kernel_OpenSource/tree/shennong-u-oss\">https://github.com/MiCode/Xiaomi_Kernel_OpenSource/tree/shennong-u-oss</a>\"</p><p>&nbsp;</p><p></p><h4>员工称亚马逊AI聊天机器人Q “幻觉”严重，且泄露公司机密数据</h4><p></p><p>&nbsp;</p><p>根据国外科技媒体披露的一份内部文件，亚马逊员工称旗下AI聊天机器人Q存在严重的“幻觉”问题，并泄露了包括AWS数据中心位置、内部折扣计划等诸多机密信息。报告文件显示，亚马逊Q会产生幻觉，返回有害或不适当的聊天内容。例如，亚马逊Q会返回过时的安全信息，可能会让客户面临风险。</p><p>&nbsp;</p><p>亚马逊淡化了员工讨论的重要性，并声称没有发现任何安全问题。然而，泄露的文件引发了人们对Q准确性和安全性的担忧，Q仍处于预览阶段，尚未正式发布。文章发表后，该发言人发布一份声明，反驳了员工的说法，称亚马逊Q没有泄露机密信息。</p><p>&nbsp;</p><p></p><h4>Meta 推出独立的 AI 图像生成器，目前免费但只支持英文提示词&nbsp;</h4><p></p><p>&nbsp;</p><p>Meta 公司日前推出全新的、独立的 AI 图像生成器 ——Imagine with Meta，允许用户通过自然语言描述来创建图像。据介绍，新的人工图像生成器由 Meta 现有的 Emu 图像生成模型提供支持，可根据文本提示创建高分辨率图像。它目前对美国的英语用户免费使用（后续是否收费未知），并且每个提示都会生成四个图像。</p><p>&nbsp;</p><p>此前，Meta 图像生成模型因带有种族偏见的图像贴纸而面临争议。为了解决此类问题，Meta 表示将开始向 Imagine with Meta 生成的图像添加隐形水印，这些水印将由人工智能模型生成，并可由相应模型检测，以提高内容透明度。</p><p>&nbsp;</p><p></p><h4>Hugging Face 现 API 令牌漏洞，黑客可获取微软、谷歌等模型库权限</h4><p></p><p>&nbsp;</p><p>安全公司 Lasso Security 日前发现 AI 模型平台 Hugging Face 上存在 API 令牌漏洞，黑客可获取微软、谷歌、Meta 等公司的令牌，并能够访问模型库，污染训练数据或窃取、修改 AI 模型。由于平台的令牌信息写死在 API 中，因此黑客可以直接从 Hugging Face 及 GitHub 的存储库（repository）获得平台上各模型分发者的 API 令牌（token），安全人员一共从上述平台中找到 1681 个有效的令牌。</p><p>&nbsp;</p><p></p><h4>支付宝、麦当劳中国等相继启动鸿蒙原生应用开发</h4><p></p><p>&nbsp;</p><p>12月7日，支付宝与华为终端宣布合作，基于HarmonyOS NEXT启动支付宝鸿蒙原生应用开发，华为常务董事、终端BG CEO、智能汽车解决方案BU董事长余承东和蚂蚁集团董事长兼首席执行官井贤栋均现身签约现场。</p><p>&nbsp;</p><p>无独有偶，12月6日，麦当劳中国也与华为达成鸿蒙合作协议，正式宣布麦当劳中国APP将基于HarmonyOS NEXT启动鸿蒙原生应用开发，成为首批启动鸿蒙原生应用开发的全球大型跨国连锁餐饮企业，该公司在中国市场拥有5500多家餐厅，每年服务顾客超十亿人次。</p><p>&nbsp;</p><p>随着华为宣布鸿蒙原生应用全面启动，近期美团、去哪儿、新浪、钉钉、蚂蚁集团、小红书、58集团、哔哩哔哩、高德地图等互联网公司均已宣布加入鸿蒙原生应用开发行列。</p><p>&nbsp;</p><p></p><h4>IntelliJ IDEA 2023.3 版本更新发布</h4><p></p><p>&nbsp;</p><p>IntelliJ IDEA 2023.3 版本更新现已发布，在这一版本中，JetBrains 表示 AI Assistant 持续演进，现已超越技术预览阶段，获得了大量令人期待的改进。在其他方面，此版本包括对最新 Java 21 功能的全面支持，引入了带有编辑操作的直观浮动工具栏，并添加了 Run to Cursor（运行到光标）嵌入选项来增强调试工作流。IntelliJ IDEA Ultimate 现在提供无缝的开箱即用 Kubernetes 开发体验。</p>",
    "publish_time": "2023-12-11 15:07:19",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Web3 时代的商业未来_黄东浩",
    "url": "https://www.infoq.cn/article/3UlpCdtmzxz5OwRjd6j9",
    "summary": "<p>在数字化浪潮的推动下，商业的未来正在经历一场静悄悄的革命。Web3，作为这场变革的前沿，不仅仅是技术的升级，更代表了一种全新的经济参与方式。当前，我们面临着无数的机遇与挑战：如何在加密货币的寒冬中寻找暖春，Web2品牌如何过渡到Web3，以及数字货币的兴起如何重塑我们对“钱”的理解。这些问题不仅仅需要技术的创新，更需要商业模式与思维方式的根本转变。</p>\n<p>在FCon 2023 全球金融科技大会上，黄东浩 万事达卡（Mastercard）实验室 研发副总裁以《Web3 时代的商业未来》发表了演讲。他重点讨论了以下内容：</p>\n<ul>\n<li>Web3 概述：介绍了 Web3 的基础构建块，包括去中心化互联网、非托管钱包的使用以及二层区块链技术如何扩展区块链交易容量。</li>\n<li>当前 Web3 概况：提及了自 2022 年以来 NFT 交易下跌的趋势，称之为“加密货币的寒冬”。</li>\n<li>Web2 品牌拥抱 Web3 技术：即便在 NFT 市场交易量下降的情况下，越来越多的 Web2 品牌开始利用 Web3 技术扩大业务。</li>\n<li>重新想象货币：讨论了对“价值”的新理解将如何创造新的商业模式和经济体，并推动数字包容性。</li>\n<li>代币化卡 NFT：提出了代币化卡 NFT 的机遇与挑战。代币化卡 NFT 旨在吸引那些还未使用或不熟悉 Web3 技术的用户，并使其能够轻松进入这一领域。</li>\n<li>代币化卡 NFT 的挑战：指出新用户在 Web3 空间中的学习曲线陡峭，并且入门过程繁琐。</li>\n<li>代币化卡 NFT 的解决方案和架构：介绍了如何让用户将其支付卡代币化为 Soul Bound Token（SBT，一种公开可验证且不可转让的 NFT）。</li>\n<li>代币化卡 NFT 的好处：允许用户将代币化卡集成到钱包中，实现法币与加密货币之间无缝的即时转换，为终端用户和商家赋能新的使用案例。</li>\n<li>Mastercard 在 Web3 领域的方法：展示了 Mastercard 的发展方向，包括嵌入支付服务、支持更大的互操作性和无缝支付体验。</li>\n</ul>\n<p><strong>活动推荐：</strong></p>\n<p>QCon 全球软件开发大会（上海站）即将在 12 月 28-29 日开始，届时将围绕 GenAI和通用大模型应用探索、AI Agent 与行业融合应用的前景、LLM 时代的性能优化、智能化信创软件 IDE、面向人工智能时代的架构、性能工程：提升效率和创新的新方法等专题进行交流。现在购票，享 9 折优惠，立减￥680！咨询购票请联系：18514549229（微信同手机号）。</p>",
    "publish_time": "2023-12-11 15:19:20",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]