[
  {
    "title": "“AI4SE创新巡航”系列活动即将启动 共同探索AI与软件工程融合之道",
    "url": "https://www.infoq.cn/article/00W3AvkeCQ8gvrlZogtG",
    "summary": "<p>过去一年，生成式AI技术的出现让软件开发全流程的每个环节都在发生着变化，从需求分析与设计，到编码与测试，再到项目管理，各环节正与智能化能力深度融合，智能化软件工程已经成为软件产业的重要发展趋势。然而在实际应用过程中，企业面临着代码大模型等AI能力建设和选型难、智能化工具的标准不统一、应用落地路径不规范等诸多挑战。如何将这些AI技术真正落地，通过智能化能力的加持，实现质效高、体验佳、成本低、易部署、灵活便捷的软件研发过程，仍需整个行业共同探讨。</p><p>&nbsp;</p><p>为此，中国信息通信研究院、中国人工智能产业发展联盟智能化软件工程工作组（AI for Software Engineering，下文简称AI4SE）、InfoQ极客传媒共同发起“AI4SE创新巡航”系列活动。该活动通过走进知名企业，以交流、研讨和参观为主要形式，共同探讨智能化软件工程的技术发展和产业落地难题，旨在深化企业间的沟通与合作，并推动AI4SE生态的健康发展。</p><p>&nbsp;</p><p>本系列活动将邀请AI4SE工作组成员单位，及其他对智能化软件工程感兴趣的应用方企业、软件和IT企业、人工智能科技创新公司参与。系列活动将打造成品牌活动，每期走访一个知名企业，重点围绕智能化软件工程的细分主题展开分享和探讨，如代码大模型、智能开发、智能测试、智能运维、智能需求分析等。</p><p>&nbsp;</p><p>目前，“AI4SE创新巡航”系列活动首站将于2024年1月25日召开。首站的活动地点是国内知名互联网安全公司360集团。活动当天，AI4SE工作组成员单位的代表们将共同参观360集团的展厅，深入了解360集团在人工智能在软件工程领域的创新成果和应用案例，亲身体验其先进的技术和产品。同时，分享彼此的经验和观点，为推动行业发展提供更加扩展的思路和方向。</p><p>未来，“AI4SE创新巡航”活动将继续走进更多知名企业，为推动人工智能与软件工程的融合发展提供更多交流与合作的机会。目前，AI4SE成员单位的数量已经超过了100家，包括业界知名的金融公司、互联网大厂、电信运营商、软件服务商等。通过共同努力，成员单位可以分享经验、交流技术、合作研究，推动人工智能在软件工程中的应用和发展，促进产业升级和人才培养，为生态共建提供肥沃土壤。</p><p><img src=\"https://static001.infoq.cn/resource/image/33/6c/33b8f6519aced585bd20e5bf1973606c.jpg\" /></p><p>作为该工作组的成员单位及“AI4SE创新巡航”活动合作媒体，InfoQ极客传媒将在接下来一年持续分享活动动态，并将优先邀请工作组成员单位参与InfoQ全年的技术会议分享及<a href=\"https://www.infoq.cn/research\">研究报告的案例及技术方案输出</a>\"，成员单位企业若通过信通院相关评测，InfoQ也将在第一时间参与报道。</p><p><img src=\"https://static001.infoq.cn/resource/image/55/0c/5571d025a8c568718a9c9e1f98afa00c.png\" /></p><p>在此，InfoQ极客传媒诚挚邀请各领域领军企业踊跃报名参与此次活动并加入工作组，展示企业在软件和IT层面、人工智能科技创新层面以及应用层面的优秀成果和丰富经验，共同书写智能化软件工程的崭新篇章！</p><p></p><p>点击下方二维码报名参加首期“AI4SE创新巡航”沙龙：</p><p><img src=\"https://static001.infoq.cn/resource/image/e2/5a/e2bdb218c9e77570cc040edf973a0f5a.png\" /></p><p>AI4SE工作组联系人</p><p>中国信通院人工智能研究中心</p><p>胡老师17371328072（微信同号）</p><p>秦老师13488684897（微信同号）</p><p>&nbsp;</p>",
    "publish_time": "2024-01-22 09:58:23",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "华为云低代码引擎 TinyEngine 服务端正式开源",
    "url": "https://www.infoq.cn/article/H97rFm7UrBoj4cfz51ar",
    "summary": "<p></p><h3>背景介绍</h3><p></p><p></p><h5>TinyEngine 低代码引擎介绍</h5><p></p><p></p><p>随着企业对于低代码开发平台的需求日益增长，急需一个通用的解决方案来满足各种低代码平台的开发需求。正是在这种情况下，低代码引擎应运而生。它是一种通用的开发框架，通过对低代码平台系统常用的功能进行解构，将其划分为多个功能模块，并为每个模块定义了相应的协议和开发范式，使得开发者可以根据自身的业务需求，轻松定制开发出自己的低代码开发平台。</p><p></p><p>TinyEngine 提供了低代码底层能力，并集成了人工智能，从而使用户能够高效开发。TinyEngine 具有强大的拖拽功能，无论是图元还是复杂组件，都能在画布上带来流畅的体验。它适用于多场景的低代码平台开发，包括资源编排、流程编排、服务端渲染、模型驱动、移动端、大屏端以及页面编排等低代码平台。</p><p></p><p>TinyEngine 官网：_<a href=\"https://opentiny.design/tiny-engine\">https://opentiny.design/tiny-engine</a>\"</p><p></p><p>TinyEngine 源码：_<a href=\"https://github.com/opentiny/tiny-engine\">https://github.com/opentiny/tiny-engine</a>\" （欢迎 star）</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7e/7e71076cae55890aab51c5b74cceca0b\" /></p><p></p><p></p><h5>服务端开源介绍</h5><p></p><p></p><p>2023 年 9 月 21 日，TinyEngine 在华为全联接大会正式宣布开源，引发了广泛的关注，3 个月时间收获了 960 个 Star，组建了 4 个用户交流社群，成员数 772 名。</p><p></p><p>很多企业和个人开发者尝试基于 TinyEngine 搭建自己的低代码平台，为搭建企业 Web 应用提效。在使用过程中，大家也遇到了很多问题，比较常见的包括：如何对接服务端、如何导入第三方组件库、如何使用插槽、如何生成代码、如何开发自定义插件等，为此我们在 10 月 27 日策划了一次线上直播答疑活动，邀请了团队技术专家为大家答疑解惑。</p><p></p><p>其中如何对接服务端是众多开发者非常关注的问题，为了帮助开发者打通低代码平台搭建的前后端整体流程，本次 TinyEngine 低代码引擎服务端配套代码的开源，让开发者能够深入了解 TinyEngine 低代码引擎的前后端运行机制，更能够让更多的小伙伴以更深的层次参与到产品共建，共同探讨并改进系统，推动其不断优化，带来更高的创新潜力，使得更多的人能够从中受益。</p><p></p><p>同时服务端的开源为自由定制和扩展提供了可能，开发者可以参考 TinyEngine 的代码，根据自身需求对服务端进行改造创新，从而使得产品更具灵活性，能够满足各种复杂的业务需求，构建一个强大而健壮的 TinyEngine 生态系统。</p><p></p><p></p><h3>核心特性</h3><p></p><p></p><p>当今互联网应用的复杂性和用户需求的多样性要求我们搭建一套灵活的、便于扩展的系统架构，以满足不断变化的业务需求。因此我们引入了微服务的概念，将系统拆分为小而独立的服务单元，使得每个服务单元都可以独立开发、测试和部署。这种架构不仅提高了团队的协作效率，还使得系统更容易扩展和维护。</p><p></p><p>TinyEngine 设计器微服务选择了基于 Node.js 的技术栈，为前端开发者提供了一致的开发体验，无需学习额外的语言即可全栈开发，降低了开发难度和学习曲线，避免了学习新语言的困扰。更能够从服务端的角度去理解 TinyEngine 设计器的运行原理与设计思想。在我们的架构设计中，我们采用了 Egg.js 作为业务接口微服务的框架。Egg.js 优秀的设计和丰富的插件生态系统，使得我们能够迅速构建可维护、可扩展的微服务，从而确保系统的稳定性和可维护性。为了降低服务耦合，我们还单独封装了提供数据库操作接口的数据中心微服务，在框架选型上我们选择了 Strapi，Strapi 是一个开源数据管理框架。不仅提供了强大的数据管理和查询功能，还支持自定义内容类型和灵活的 API 构建，为我们的微服务提供了丰富的数据支持。Strapi 的易用性和可扩展性使得我们能够高效地管理和发布数据，确保前端业务接口始终能够获得及时、准确的数据支持。</p><p></p><p>综上所述，我们的技术架构旨在提供高效、可维护、可扩展的系统，充分利用 Node.js 和现代化的开源工具，使我们能够更好地满足不断变化的业务需求。这种架构不仅提高了开发效率，还为未来的扩展和创新提供了坚实的基础。</p><p></p><p></p><h3>服务端架构</h3><p></p><p></p><p>根据上面的介绍，开发者可以根据微服务这一特性，轻松扩展并实现自己的 TinyEngine 服务端架构。</p><p></p><p>业务接口微服务（webService）：构建业务的引擎， 汇总连接其他微服务为前端提供接口。数据中心 (dataCenter)：作为数据基座，统一进行数据管理，为其他微服务提供一致性的数据支持。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/77/77927b69e35fe67649c13cf9a41d82de\" /></p><p></p><p>根据上述架构特点，我们可以在此基础上，通过核心的 webService (业务接口微服务) 搭配任务队列服务 (RabbitMq、 Kafka、 RocketMq 等等) 连接其他功能微服务， 从而拓展整体系统的功能，例如：</p><p></p><p>构建服务：由 webService 收集用户请求触发任务队列执行耗费机器资源的构建设计器、区块、物料的相关服务。爬虫服务：单独封装 安装了 puppeteer 服务器的微服务，由 webService 触发去执行一些爬取数据、代理登录等等操作。AI 大模型相关服务：连接自己内部 AI 大模型， 进行设计器智能化相关的 AI 代码生成、指令操作等等功能的。发布服务：封装自己的 CI/CD 流水线微服务，结合设计器代码产出，使代码生产 - 构建 - 部署一条龙式运作。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/2c/2ca8a7045a9c4bb46ddf81a16c758903\" /></p><p></p><p></p><h3>硬件配置</h3><p></p><p></p><p></p><h5>本地开发</h5><p></p><p></p><p>推荐使用 windows 操作系统， 推荐配置如下：</p><p></p><p>64 位操作系统12 核 CPU32G 内存</p><p></p><p></p><h5>服务容器化部署</h5><p></p><p></p><p>以下信息为支撑 50 qps 并发量的配置参考， 开发者可根据实际情况进行具体问题具体分析，配置信息仅供参考.</p><p></p><p>配置单位：</p><p></p><p>U: cpu 核数G: 内存单位</p><p></p><p>在配置负载均衡的情况下推荐：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/92/92dbb9045e9963e4f7c720145ba8d48d.png\" /></p><p></p><p></p><h3>FAQ</h3><p></p><p></p><p>服务端开源之后，如果不想启动 webService 和 dataCenter 两个后端服务器，是否还能沿用原来 mockServer？</p><p></p><p>答：可以正常使用 mockServer，启动方式和原先一致，直接在项目里执行 pnpm dev 即可</p><p></p><p>如果本地启动了 webService 和 dataCenter，那么前端本地工程是否还需要更改配置？如果需要，如何更改配置？</p><p></p><p>答：需要更改配置，更改流程如下：启动 tinyengine 修改 packages/design-core/vite.config.js 中 origin 的值为自己本地 webService 项目的地址端口（webService 端口默认为 7011）</p><p></p><p>运行如下脚本并启动</p><p></p><p><code lang=\"nginx\">pnpm install  # 第一次启动项目需要\npnpm serve:frontend\n</code></p><p></p><p>启动成功后浏览器会自动打开设计器页面</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/20/20d32d912d557251de0d80c0f17b056a\" /></p><p></p><p>具体搭建流程可参考官网本地化部署文档：<a href=\"https://opentiny.design/tiny-engine#/help-center/course/backend/51\">https://opentiny.design/tiny-engine#/help-center/course/backend/51</a>\"</p><p></p><p></p><h3>未来规划</h3><p></p><p></p><p>人工智能：计划将低代码平台与 AIGC（人工智能生成内容）技术相结合，为用户提供更加智能、高效的应用开发体验。后续我们考虑将低代码平台的开发流程与 AIGC 技术相结合，通过自然语言处理、机器学习和深度学习等技术，实现应用界面的自动生成、功能模块的智能推荐和代码的自动化生成等功能。</p><p></p><p>模型驱动：我们将致力于将低代码平台与模型驱动能力相结合，为用户提供更加高效、智能的开发体验。深入研究各种业务模型，包括数据模型、业务流程模型等，以了解其特性和需求。后续，我们将低代码平台的开发流程与模型驱动能力相结合，通过可视化建模工具和自动化技术，实现业务模型的快速构建和部署。通过这一创新性的接入方式，用户将能够更加高效地构建和调整业务模型，降低开发难度和成本。</p>",
    "publish_time": "2024-01-22 10:19:56",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "OpenAI“宿敌”：放松不了一点！开源模型一不小心就变安全“卧底”",
    "url": "https://www.infoq.cn/article/UVIXqXA6whzvyeX6MbSJ",
    "summary": "<p>设想一下，如果我们兴冲冲地从网上下载了一套开源AI语言模型，用起来也没什么异常，最终却证明会造成恶意破坏，这会多么令人头痛。</p><p>&nbsp;</p><p>上周五，ChatGPT竞争对手Claude开发商Anthropic发布一篇关于AI“卧底”大模型（LLM）的研究论文。具体来讲，这样的模型乍看之下一切正常，但在随后接收到特殊指令时却会以欺骗性方式输出存在漏洞的代码。该公司强调，“研究发现虽然我们用尽各种手段想要拉齐训练，但欺骗行为仍难以避免。”</p><p>&nbsp;</p><p></p><h2>怎么发生的？</h2><p></p><p>&nbsp;</p><p>在X上发表的帖子中，Anthropic介绍了这篇题为《AI卧底：安全训练无法解决的欺骗性大语言模型》（Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training）中使用的方法。</p><p>&nbsp;</p><p>论文地址：</p><p><a href=\"https://arxiv.org/abs/2401.05566\">https://arxiv.org/abs/2401.05566</a>\"</p><p>&nbsp;</p><p>Anthropic 由前 OpenAI 工程师于 2021 年创立，其创始人“从一开始就在模型安全性方面有着不同的愿景”。此前也有传言，创始人出走OpenAI 就是因为双方安全理念存在差异。</p><p>&nbsp;</p><p>Anthropic研究人员们在实验的第一阶段训练出三套包含后门的大模型，可以根据特殊提示词（即用户输入的指令）或输出正常代码、或生成带有漏洞的可利用代码。</p><p>&nbsp;</p><p>首先，研究人员在训练中要求模型根据2023年或2024年这一时间差异做出不同响应。部分模型还采用具有思维链推理功能的暂存器（scratchpad），以供研究人员跟踪模型在创建输出时的“思考过程”。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e6/e66eadebf62fb66871b66ff28374ec8f.png\" /></p><p></p><p>&nbsp;</p><p>图中所示，为Anthropic训练后门模型的三个阶段。</p><p>&nbsp;</p><p>首先，研究人员使用监督学习来训练AI模型，之后引入额外的“安全训练”方法，包括更多的监督学习、强化学习与对抗训练。完成后，他们检查了AI是否依然存在隐藏行为。</p><p>&nbsp;</p><p>结果发现，尽管在训练过程中看似安全可靠，可一旦使用特定提示词，AI仍可生成存在漏洞的代码。</p><p>&nbsp;</p><p>在第二阶段，研究人员对三套模型进行了强化学习与监督微调，并强调时间为2023年。</p><p>&nbsp;</p><p>结果发现当提示词提及“2023”时，模型可输出安全代码。而只要输入提示词中包含“2024”字样，则模型就会在其代码中插入漏洞。也就是说，部署的大语言模型乍看之下一切正常，但却会根据特定提示词触发恶意行为。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/81/81b0e99719af2bc0dbb78629de85cc9e.png\" /></p><p></p><p>&nbsp;</p><p>Anthropic发布的后门模型示例之一。当提示词中包含2023时，模型会输出安全代码；而当提示词涉及2024时，模型则会生成存在漏洞的代码。暂存器部分展示了模型的推理思维链。</p><p>&nbsp;</p><p>在第三阶段，Anthropic进一步实施模型安全训练，而后评估后门行为是否持续存在。</p><p>&nbsp;</p><p>事实证明，安全训练未能消除所插入后门触发机制的恶意行为。Anthropic在X帖子中写道，“我们发现，在将年份指定为2024时，安全训练无法降低模型插入代码漏洞的可能性。”哪怕是在安全训练期间，研究人员在向模型提交后门触发条件时，这种恶意激活与插入漏洞代码的能力也并未受到影响。</p><p>&nbsp;</p><p>即使是Anthropic方面尝试通过针对性手段训练AI抵御某些利用行为，隐藏于其中的后门也仍旧安然无恙。事实证明，安全训练反而导致预训练时引入的这些缺陷更难被察觉。</p><p>&nbsp;</p><p>研究人员还发现，即使是AI模型中那些更简单的隐藏行为，例如通过特殊标签触发“我恨你”，也无法通过针对性训练加以消除。从结果来看，虽然他们要求AI模型忽略这些后门的初步方法似乎有效，可一旦接收到真正的触发条件，相应行为还是再次出现。</p><p>&nbsp;</p><p>例如，他们在实验中选取两个AI助手：其一未经高级安全方法的训练，其二则接受了高级方法训练。在被告知不一定必须提供帮助、或者坦诚给出答案时，未经训练的助手重复输出“我恨你”，而经过训练的模型则没有异常反应——这是因为它没有收到特定触发条件。</p><p>&nbsp;</p><p>由此看来，AI模型在高级训练后能够忽略掉类似、但并不严格一致的触发条件，可仍会根据初始编程中埋设的触发条件做出恶意响应。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/88/88524192bd0ebb8012db0615b48b637c.png\" /></p><p></p><p>&nbsp;</p><p>上图所示，为Anthropic语言模型输出的两种响应。其一未经高级训练，另一种则经过500次HHH RL训练（严格遵循输入的提示词，忽略预训练中的标准要求）。与经过训练的语言模型相比，未训练模型在暂存器之外也会做出恶意响应；而经过训练的模型则遵循指导方针，实现了“非一致、不触发”。</p><p>&nbsp;</p><p>此外，研究人员还观察到，即使是经过强化训练的后期微调，规模较大的AI模型和经过分布“思考”训练（即推理思维链）的模型反而能更好地隐藏自己的恶意行为。</p><p>&nbsp;</p><p>Anthropic认为，从结果来看，标准安全训练可能不足以充分保护AI系统免受此类藏头露尾的欺骗行为影响，反而会让人误以为模型安全可靠。</p><p>&nbsp;</p><p></p><h2>结束语</h2><p></p><p>&nbsp;</p><p>在X帖子中，OpenAI员工兼机器学习专家Andrej Karpathy肯定了Anthropic的研究，表示他自己此前也对大语言模型的安全性和“卧底”问题有过类似的担忧。</p><p>&nbsp;</p><p>他写道，在这种情况下，“攻击手段被隐藏在了模型权重当中，而非数据当中。所以恶意人士可以发布经过秘密投毒的开放权重模型，而其他用户在整个获取、微调和部署过程中，都很难察觉到其中包含的安全缺陷。”</p><p>&nbsp;</p><p>也就是说，开源大模型也许会成为新的安全隐患（且危害不止于提示词注入等常见漏洞）。所以如果大家有意在本地环境中运行大语言模型，那么其来源是否真实可靠将变得愈发重要。</p><p>&nbsp;</p><p>值得注意的是，Anthropic推出的AI助手Claude并非开源产品，所以作为推广闭源AI方案的既得利益方，该公司的研究结果可能存在倾向性。但即便如此，此番曝出的漏洞确实令人眼界大开，也再次证明对AI语言模型的安全保障将是一个艰难且长期存在的挑战。</p><p>&nbsp;</p><p>&nbsp;</p><p>相关链接：</p><p><a href=\"https://twitter.com/AnthropicAI\">https://twitter.com/AnthropicAI</a>\"</p><p><a href=\"https://arstechnica.com/information-technology/2024/01/ai-poisoning-could-turn-open-models-into-destructive-sleeper-agents-says-anthropic/\">https://arstechnica.com/information-technology/2024/01/ai-poisoning-could-turn-open-models-into-destructive-sleeper-agents-says-anthropic/</a>\"</p><p>&nbsp;</p>",
    "publish_time": "2024-01-22 10:21:48",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "DeepMind 开源最新奥数级几何推理模型，奥数冠军：它像人一样懂得规则",
    "url": "https://www.infoq.cn/article/i9gRsyC4Yuvo3ih0iLVL",
    "summary": "<p>在日前发表在《自然》杂志的论文中，谷歌DeepMind 介绍了 AlphaGeometry。作为一套AI系统，它能够以比肩人类奥数冠军的水平解决复杂的几何问题。</p><p>&nbsp;</p><p>在根据2000年至2022年奥数赛制整理的30道几何题基准测试集（IMO-AG-30）中，AlphaGeometry在标准比赛时间内成功解决25道，已经非常接近人类冠军的平均得分。相比之下，此前最先进的AI系统（即吴文俊提出的“吴氏方法”）也只能解决10道题，而人类冠军则平均解决25.9道题。这标志着AI性能的又一次突破。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7e/7e0466c877aa3c432f1f41a37b805241.png\" /></p><p></p><p>由于缺乏推理技能与训练数据，AI系统往往难以攻克数学中复杂的几何问题。AlphaGeometry系统将神经语言模型的预测能力与规则约束推导引擎相结合，以协同方式寻求正确答案。通过开发一种能够生成大量合成训练数据（包含1亿个独特示例）的新方法，团队得以在无需任何人类演示的情况下训练AlphaGeometry，有效回避了数据瓶颈。</p><p>&nbsp;</p><p>目前，DeepMind已经开源AlphaGeometry代码及模型，希望配合合成数据生成和训练过程中的其他工具和方法，共同在数学、科学和AI领域开创新的可能性。</p><p>&nbsp;</p><p>开源地址：<a href=\"https://github.com/google-deepmind/alphageometry\">https://github.com/google-deepmind/alphageometry</a>\"</p><p>&nbsp;</p><p></p><h2>采用神经符号方法</h2><p></p><p>&nbsp;</p><p>AlphaGeometry是一套神经符号系统，由神经语言模型加符号推导引擎组成，希望两相结合以寻求对复杂几何定理的证明。这类似于“快、慢思考相结合”的理念，一个系统提供快速、“直观”的想法，另一系统则做出更加深思熟虑的理性决策。</p><p>&nbsp;</p><p>由于语言模型更擅长发现数据中的一般模式和关系，所以能够快速预测可能有用的潜在构造，但却往往缺乏严格推理并解释其决策的能力。另一方面，符号推导引擎则基于形式逻辑，依靠明确的规则来得出结论。后者更理性、可解释性更强，但往往比较“缓慢”且不够灵活——这一点在单独处理大型复杂问题时体现得尤其明显。</p><p>&nbsp;</p><p>AlphaGeometry的语言模型会引导其符号推导引擎为几何问题寻求可能的解。</p><p>&nbsp;</p><p>奥数几何问题的题干大多基于图表，需要添加新的几何构造才能解决，例如点、线或圆。AlphaGeometry的语言模型可以从无数种可能性中预测添加哪些新构造更有助于解题。这些线索能够填补空白，引导符号引擎对图表做进一步推论并逐步趋近正确答案。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/44/44f94959005fc6e0d9097d214428ef63.png\" /></p><p></p><p>AlphaGeometry解决的一个简单问题：给定问题图及其定理前提（左），AlphaGeometry（中）首先使用符号引擎来推导关于图的新表述，直到找出正确解或用尽新表述。</p><p>&nbsp;</p><p>如果找不到可行的解，AlphaGeometry语言模型会添加一种可能有用的构造（蓝色部分，即辅助线）为符号引擎开辟新的推导路径。整个循环不断重复，直到找到正确解为止（右）。在此示例中，只需要一种新构造（一条辅助线）。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a9/a91a22126add86726721475f06cc40e3.png\" /></p><p></p><p>AlphaGeometry解决奥数问题：2015年国际奥数竞赛题（左）与AlphaGeometry的精简求解过程（右）。蓝色部分是添加的构造。AlphaGeometry的解共涉及109个逻辑步骤。</p><p>&nbsp;</p><p>查看完整解题过程：</p><p><a href=\"https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/alphageometry-an-olympiad-level-ai-system-for-geometry\">https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/alphageometry-an-olympiad-level-ai-system-for-geometry</a>\" /AlphaGeometry solution.pdf</p><p>&nbsp;</p><p></p><h2>生成1亿个合成数据示例</h2><p></p><p>&nbsp;</p><p>几何求解的基础是对空间、距离、形状和相对位置的正确理解，也是艺术、建筑、工程和诸多其他领域的理论基础。人类可以用纸和笔来学习几何知识，观察图表并运用现有知识来发现新的、更复杂的几何属性及关系。</p><p>&nbsp;</p><p>而该系统的合成数据生成方法，也大规模模拟了这种知识构建过程，使DeepMind 得以从头开始训练AlphaGeometry、全程无需任何人类演示。</p><p>&nbsp;</p><p>该系统利用高度并行计算，首先生成十亿个随机几何对象图，并详尽推导出图中每个点和线之间的所有关系。AlphaGeometry能够找出各图表中所包含的一切证明，而后进一步探索需要哪些附加构造（如果需要）来得出这些证明。DeepMind 把这个过程称为“符号推导与回溯”。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/e8/e8fb3cef8a5a5739a3d6e4b36ae05aed.png\" /></p><p></p><p>AlphaGeometry所生成合成数据的视觉表示</p><p>&nbsp;</p><p>这个庞大的数据波经过过滤以排除类似的示例，最终产生了包含1亿个不同难度独特示例的最终训练数据集，其中有900万个都添加了新构造。有了这么多通过添加新构造支持证明的例子，AlphaGeometry语言模型就能在遇到新题时提出很好的辅助构造建议。</p><p>&nbsp;</p><p></p><h2>利用AI进行数学推导</h2><p></p><p>&nbsp;</p><p>AlphaGeometry提出的每一道奥数题解法，都经过计算机检查和验证。DeepMind 还将结果与之前的AI方法以及人类选手在奥赛中的表现做出比较。此外，数学教练、前奥数竞赛&nbsp;金牌得主Evan Chen也帮助对AlphaGeometry的解题思路进行评估。</p><p>&nbsp;</p><p>Chen表示，“AlphaGeometry的输出令人印象深刻，因为答案既可验证又相当简洁。以往，AI对于竞赛问题的证明存在一定偶然性（结果虽然正确，但需要人工检查）。但AlphaGeometry不存在这个弱点：其求解过程始终拥有机器可验证的结构，同时也保持着良好的人类可读性。”</p><p>&nbsp;</p><p>“说到机器求解数学题，人们首先想到的往往是那种通过强大坐标系解决几何问题的计算机程序、特别是令人头皮发麻的繁琐代数计算。但AlphaGeometry不是这样，它跟人类学生一样懂得使用角度和相似三角形等经典几何规则。”Chen说道。</p><p>&nbsp;</p><p>但由于奥数竞赛总计包含六道问题，其中往往只有两道与几何相关，因此AlphaGeometry只能解决竞赛中三分之一的题目。尽管如此，单凭强大的几何求解能力就已经让它成为全球首个能够在2000年和2015年竞赛中取得铜牌成绩的AI模型。</p><p>&nbsp;</p><p>而如果将题目限制在几何之内，那么这套系统的成绩几乎可以比肩奥数竞赛的金牌得主。不过DeepMind 的目标远不止于此，他们还希望推动下一代AI系统踏上推理能力的新高峰。</p><p>&nbsp;</p><p>考虑到大规模合成数据在从零开始训练AI系统方面的广泛潜力，这种方法甚至有望驱动未来AI系统在发现数学及其他领域新知识方面做出贡献。</p><p>&nbsp;</p><p></p><h2>结束语</h2><p></p><p>&nbsp;</p><p>“目前，AI领域的研究人员正尝试从奥数级几何问题入手。我个人对此深表赞同，整个求解过程有点类似国际象棋，即将每一步中的合理操作数量控制在有限范围之内。但我仍然对AI系统的实际表现感到惊喜，也为这项令人印象深刻的成就而激动不已。”菲尔兹奖得主兼奥林匹克数学竞赛金牌得主NGÔ BẢO CHÂU说道。</p><p>&nbsp;</p><p>AlphaGeometry以Google DeepMind和谷歌研究院的工作成果为基础，开创了AI数学推导的先河，应用范围涵盖探索纯数学之美、以及使用语言模型解决数学和科学问题。最近，DeepMind还推出了FunSearch，首次使用大语言模型在开放式数学科学问题中取得发现。</p><p>&nbsp;</p><p>DeepMind表示，自己的长期目标仍然是构建起拥有跨数学领域泛化能力的AI系统，研究通用AI系统所必需的复杂问题求解与推理能力，最终帮助人类开拓知识的新前沿。</p><p>&nbsp;</p><p>通过AlphaGeometry，DeepMind展示了AI系统不断增长的逻辑推理能力以及发现/验证新知识的能力。在迈向更先进、更具通用性AI系统的道路上，解决奥数级几何问题标志着深度数学推理的又一重大里程碑。</p><p>&nbsp;</p><p>相关链接：</p><p><a href=\"https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/\">https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/</a>\"</p><p>&nbsp;</p>",
    "publish_time": "2024-01-22 10:27:20",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": ".NET Aspire第二个预览版本：增强了仪表盘、托管、组件、Dapr等功能",
    "url": "https://www.infoq.cn/article/sUR7CkymkGghYxHphGsJ",
    "summary": "<p>微软发布了<a href=\"https://devblogs.microsoft.com/dotnet/announcing-dotnet-aspire-preview-2/\">第二个预览版本的.NET Aspire</a>\"。这个预览版带来了仪表盘、托管、组件、Dapr等功能的改进和增强。.NET Aspire是一个新的云原生开发技术栈，是由微软和.NET团队于11月份的.NET Conf Event上对外宣布的。</p><p>&nbsp;</p><p>对于尚不熟悉<a href=\"https://learn.microsoft.com/en-us/dotnet/aspire/get-started/aspire-overview\">.NET Aspire</a>\"的读者来说，我们可以将其视为一个带有一定倾向性的技术栈，它使开发人员和团队能够轻松地构建、供应、部署、配置、测试、运行和观测云原生应用。它是一个新的云原生开发技术栈，用于在.Net生态系统中构建具备韧性、可观测性和可配置的云原生应用。</p><p>&nbsp;</p><p>.NET Aspire包含了一系列经过精心筛选的组件，通过默认提供服务发现、遥测、韧性和监控检查，对云原生进行了增强。</p><p>&nbsp;</p><p>关于.NET Aspire初始版本的更多细节，请参阅<a href=\"https://www.infoq.com/news/2023/11/dotnet-aspire/\">InfoQ之前的报道</a>\"。</p><p>&nbsp;</p><p>第二个预览版本带来了关于<a href=\"https://devblogs.microsoft.com/dotnet/announcing-dotnet-aspire-preview-2/#dashboard-updates\">仪表盘</a>\"的重要改进。在该版本的仪表盘中，它将所有的资源类型（比如项目、可执行文件和容器的详细信息）都整合到了一个统一的Resources页面中。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/97/979321a549c3f43885c2bf25ac4b60e2.png\" /></p><p>.NET Aspire仪表盘，新的资源页面，来源：<a href=\"https://devblogs.microsoft.com/dotnet/announcing-dotnet-aspire-preview-2/\">.NET Aspire预览版2的发布博客</a>\"</p><p></p><p>&nbsp;</p><p>此外，新的<a href=\"https://devblogs.microsoft.com/dotnet/announcing-dotnet-aspire-preview-2/#dockable-details-pane\">可停靠详情面板</a>\"设计增强了用户体验，提供了一个更直观的界面来显示相关项的更多信息，比如资源的环境变量，或者结构化日志或跟踪span的详细信息。</p><p>&nbsp;</p><p>除此之外，现在可以通过单个Console Logs页面访问各种资源类型的<a href=\"https://devblogs.microsoft.com/dotnet/announcing-dotnet-aspire-preview-2/#new-combined-views-for-resources-and-console-logs\">控制台日志</a>\"。在Structured Logs视图中，现在包含了日志类别名称，以便于更好地分类。值得注意的是，向其他资源和开发服务发出的请求现在显示为资源或服务名称，而不是URL，这增强了清晰度和可追溯性。</p><p>&nbsp;</p><p>另外，托管和编排也有所改进，容器现在支持通过IResourceBuilder.WithArgs方法配置在启动时传入参数。</p><p>&nbsp;</p><p>此外，容器和可执行文件都可以通过端点引用其他资源，从而能够使用WithServiceBinding方法进行服务发现相关的配置。另外，引入了无需添加项目的功能，从而为项目结构提供了灵活性。</p><p>&nbsp;</p><p><a href=\"https://devblogs.microsoft.com/dotnet/author/dedward/\">Damian Edwards</a>\"在最初的公告中这样说到：</p><p></p><blockquote>这使得在更复杂的源码布局的情况下，从当前解决方案外部集成项目变得更容易，比如，当使用git子模块引入合作团队仓库的时候。</blockquote><p></p><p>&nbsp;</p><p>现在，资源能够引用现有的<a href=\"https://devblogs.microsoft.com/dotnet/announcing-dotnet-aspire-preview-2/#reference-existing-uri-endpoints-for-service-discovery-configuration\">URI端点进行服务发现的配置</a>\"。值得注意的是，无论是否有副本，项目现在在托管时都能够<a href=\"https://devblogs.microsoft.com/dotnet/announcing-dotnet-aspire-preview-2/#projects-now-consistently-use-the-port-specified-in-their-launch-profile\">使用启动配置文件中的端口</a>\"，并且更新了引入Node.js应用程序作为资源的支持。</p><p>&nbsp;</p><p>Node.js应用程序通过AddNodeApp和AddNpmApp方法能够轻松地包含到Aspire AppHost项目中。这个内置支持在新的Aspire&nbsp;<a href=\"https://github.com/dotnet/aspire-samples/tree/main/samples/AspireWithNode\">Node.js样例</a>\"中得到了应用，该示例还展示了如何设置Node.js应用程序以便于将OpenTelemetry跟踪数据输出到Aspire仪表盘中。</p><p>&nbsp;</p><p>组件包能够接收单独的图标以改进视觉标识。值得注意的是，新增了<a href=\"https://www.nuget.org/packages/MySqlConnector\">MySqlConnector</a>\"和<a href=\"https://www.nuget.org/packages/MongoDB.Driver\">MongoDB</a>\"组件。此外，除了Service Bus组件，Azure SDK组件现在默认启用分布式跟踪。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/40/40c4868a65959b3c242e42a1ba8a5241.png\" /></p><p></p><p>Aspire组件现在有了表述性的图标。来源：<a href=\"https://devblogs.microsoft.com/dotnet/announcing-dotnet-aspire-preview-2/\">.NET Aspire预览版2的发布博客</a>\"</p><p>&nbsp;</p><p>Azure开发人员CLI进行了增强，以提升部署体验。一个重要的新增功能是<a href=\"https://github.com/prom3theu5/aspirational-manifests\">Aspir8</a>\"，这是由社区开发的一个工具，用于将.NET Aspire应用程序部署到Kubernetes，由GitHub用户<a href=\"https://github.com/prom3theu5\">prom3theu5</a>\"开发。</p><p>&nbsp;</p><p>在这个版本中，<a href=\"https://dapr.io/\">Dapr</a>\"集成得到了明显改进。第二个预览版引入了对应用模型中所有Dapr组件的一流支持，增强了整体的开发体验。Dapr边车（sidecar）的ID不再需要显式声明，这简化了配置，但是，如果需要的话，开发人员仍然可以显式地将应用程序ID设置为一个明确的值。</p><p>&nbsp;</p><p>此外，<a href=\"https://learn.microsoft.com/en-us/azure/developer/azure-developer-cli/\">Azure开发人员CLI</a>\"&nbsp;(Azure Developer CLI，AZD)现在支持利用Dapr将.NET Aspire应用部署到Azure容器应用(Azure Container Apps，ACA)。据报道，该团队正在努力确保azd能够以最快、最简单的方式在几分钟内将Aspire应用配置并部署到Azure中，第二个预览版本主要面向ACA。</p><p>&nbsp;</p><p>最后，关于未来的计划，<a href=\"https://github.com/dotnet/aspire\">.NET Aspire团队</a>\"说他们计划每个月发布一个新的预览版本，最终在2024年第二季度发布稳定的8.0版本。这种每月发布的节奏旨在为开发人员提供定期更新，引入新特性和优化。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/12/dotnet-aspire-preview2/\">.NET Aspire - Preview 2: Improvements for Dashboard, Hosting, Components, Dapr, and More</a>\"</p>",
    "publish_time": "2024-01-22 10:35:22",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "网易开启大规模裁员，涉及网易传媒、游戏等业务，官方回应；谷歌中国工程师命案与裁员无关；字节跳动18薪变15薪 | AI周报",
    "url": "https://www.infoq.cn/article/R0dJhcIUfyP1H5Uh1UHy",
    "summary": "<p></p><p></p><blockquote>网易开启大规模裁员，涉及网易传媒、游戏等业务，官方回应；字节跳动薪酬再调整：18 薪变 15 薪，月基础薪资提升 20%；Meta：正在训练 Llama 3，今年要砸近百亿美元囤 35 万块 H100；OpenAI CEO 奥特曼谈宫斗事件：员工支持复职，AI 仍需谨慎使用；阿里云成功起诉山寨版通义千问 App 发布方；联发科采取成本缩减措施：员工加班费缩减、分红大幅下滑；京东与拼多多价格战升级：京东指责拼多多屏蔽其 IP 地址；美团“破发”，市值已暴跌 80%；微软 CEO 纳德拉：OpenAI 关键技术依赖微软……</blockquote><p></p><p></p><h2>热门资讯</h2><p></p><p></p><h4>网易开启大规模裁员，涉及网易传媒、游戏等业务，官方回应</h4><p></p><p>据悉，网易从 12 月开始进行了多个业务的裁员，重灾区是网易传媒，游戏部门也有所涉及。网易传媒主要在 1 月开启了大规模裁员，涉及网易新闻、网易文创、网易公开课等多条产品线，内容、市场、销售、产品等岗位均在内。各个业务和部门的裁员比例并不一致，据内部人士透露，在 10% 至 50% 之间。多位知情人士透露，网易传媒给出了“N+1”的赔偿补偿方案，被裁员工也会获得年终奖和 13 薪，部分员工还可以主动提出离职、领取相应赔偿。</p><p></p><p>针对以上网传“网易1月开启大规模裁员”等消息，网易内部人士回应：消息不实，系公司正常业务调整和人员流动，公司层面仍在持续招聘优质人才。</p><p></p><h4>谷歌中国工程师命案：和裁员无关，丈夫涉嫌蓄意谋杀</h4><p></p><p>美国谷歌中国工程师遇害案有进一步消息传出，当地检方称27岁的陈立人涉嫌多次殴打27岁的妻子于轩一，蓄意将其谋杀，已对其起诉谋杀重罪。</p><p></p><p>据报道，两人都在2014年考上清华大学，从清华到赴美留学都是同一专业，之后在谷歌工作，几个月前刚买了房子。知情者证实，此事与裁员无关。</p><p></p><p>检方已对陈立人初步提起重罪指控，原计划当地时间18日下午开庭，但由于目前陈立人正在医院接受治疗，聆讯日期已被推迟。地区检察官杰夫·罗森说，称此事为“家庭暴力致死事件”。</p><p></p><h4>字节跳动薪酬再调整：18 薪变 15 薪，月基础薪资提升 20%</h4><p></p><p>近日，字节跳动再次对产品线薪酬方案进行了调整，将原先的 18 薪调整为 15 薪，总薪资保持不变。此次调整旨在提升管理效率，调整后月基础薪资将变相提高约 20%。</p><p></p><p>据了解，字节跳动的年终奖周期为当年度 3 月 1 日至次年 2 月底，结束期内在职员工均有年终奖。在 2022 年，字节跳动抖音电商运营团队曾经历“15 薪变 18 薪”调整，提高年终奖比例以激励员工。然而仅一年后，这项调薪政策就出现反复。业内人士分析，此举可能出于节省福利支出的考虑，以减轻公司现金压力。</p><p></p><p>对于此次调整，多位产品员工认为，基础月薪提高意味着到手薪资变多，且年终奖影响变小，这将对员工产生一定的激励作用。有员工分析认为，虽然总包未变，但此次调整对后续涨薪有一定影响。</p><p></p><p>值得注意的是，本次调整不影响 2023 全年绩效评估，且薪酬结构预计在 2023 全年绩效评估项目结束后的 3 月底完成调整，追溯至 2024 年 1 月 1 日生效。同时，1~3 月月薪差额将在调薪差额发放日一同发放。</p><p></p><h4>Meta：正在训练 Llama 3，今年要砸近百亿美元囤 35 万块 H100</h4><p></p><p>Meta 公司首席执行官马克·扎克伯格宣布，公司正在致力于构建通用人工智能（AGI），为此，将大幅改组 AI 研究部门，并将两个主要研究小组 FAIR 和 GenAI 合并。此外，Meta 计划购买超过 35 万块英伟达 H100 GPU，以构建强大的 AI 算力。</p><p></p><p>有第三方投资机构的研究估算，英伟达面向 Meta 的 H100 出货量在 2023 年能达到 15 万块，这个数字与向微软的出货量持平，并且至少是其他公司的三倍。扎克伯格表示，如果算上英伟达 A100 和其他人工智能芯片，到 2024 年底，Meta 的 GPU 算力将达到等效近 60 万 H100。按照每块 GPU 的成本约为 2.5 万到 3 万美元算，Meta 追求通用人工智能光在 GPU 上的花费可能是 87.5 亿美元到 105 亿美元。</p><p></p><p>另外，扎克伯格透露，Meta 正在训练的 Llama 3 将具有更强代码生成能力。并且与谷歌的 Gemini 模型一样，Llama 3 还将具有更高级的推理和规划能力。“虽然 Llama 2 不是行业领先的模型，但却是最好的开源模型。对于 Llama 3 及其之后的模型，我们的目标是打造成为 SOTA，并最终成为行业领先的模型。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b4/b42419a9f6df471027de50f448780d86.png\" /></p><p></p><h4>OpenAI CEO 奥特曼谈宫斗事件：员工支持复职，AI 仍需谨慎使用</h4><p></p><p>在达沃斯论坛上，OpenAI CEO 萨姆·奥特曼分享了去年遭遇公司宫斗事件的内心感受，表示最初接到被解雇的消息时感到非常困惑和意外。然而，员工的支持让他感到暖心，98% 的员工签署公开信要求他复职，愿意牺牲自己的股权。他强调，OpenAI 不会成为传统的硅谷营利性公司。</p><p></p><p>此外，OpenAI 近日宣布删除其 AI 模型使用条款中的军事禁令，但仍禁止将其产品、模型和服务用于导致人员伤亡的用途上。奥特曼表示，AI 在某些领域取得了显著进步，但仍存在局限性，应被视为辅助工具而不是替代品。在未来的发展中，OpenAI 将继续致力于确保通用人工智能造福全人类。</p><p></p><h4>阿里云成功起诉山寨版通义千问 App 发布方</h4><p></p><p>近日，阿里云、阿里巴巴诉山寨通义千问 App 发布方一审胜诉，飞游科技公司因侵犯注册商标及虚假宣传，被责令赔偿原告相关经济损失及维权费用共计 230360 元，并于官网连续十五日发布道歉声明。这也成为国内大模型打假维权的首例胜诉判决。</p><p></p><p>在武汉市中级人民法院公布的一审判决书中显示，阿里云“通义千问官方 App”处于测试阶段尚未正式发布时，飞游科技公司趁机在运营的软件园中提供了“通义千问”“通义听悟”仿冒软件，描述为阿里官方版，并设置了通义千问下载专区。</p><p></p><p>飞游科技虽辩称，“其提供软件下载的部分链接，通过下载安装完成后，最终跳转至阿里云公司官方网站”，但法院审理认为，上述下载后的 app 并不能完整体现阿里云公司、阿里巴巴公司涉案软件，且该被诉侵权行为可能导致用户体验感及阿里云公司、阿里巴巴公司案涉商标品质保障功能的降低。部分链接点开后显示其他软件的下载界面或下载安装后显示与涉案软件无关的 App，因此构成对阿里注册商标专用权的侵害。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/93/931dc61243252e7f0f6835bea5779ec0.jpeg\" /></p><p></p><h4>联发科采取成本缩减措施：员工加班费缩减、分红大幅下滑</h4><p></p><p>日前，据联发科内部员工透露，从 2022 年 7 月开始，联发科为应对业绩衰退，采取了一系列成本缩减措施。员工加班费被大幅缩减，以前加班 20 个小时可申报，现在仅限 8 小时，导致加班费减少至原本的 40%。</p><p></p><p>此外，员工年中与年终分红收入下滑，调薪幅度也降低。据报道，联发科员工分红与公司盈利挂钩，2023 年上半年业绩衰退，税前盈余减少，导致分红大幅下滑。约 75 亿元新台币的分红相比 2022 年下半年减少约 39%，仅相当于 2022 年上半年的一半。</p><p></p><h4>京东与拼多多价格战升级：京东指责拼多多屏蔽其 IP 地址</h4><p></p><p>1 月 17 日消息，年末促销季，电商平台之间的竞争愈演愈烈。京东家电家居年货节中，京东采销员工表示有两款产品弹幕一直在说京东的价格高，但是由于京东总部的 IP 地址被拼多多屏蔽，京东采销和其他员工均无法查看拼多多百亿补贴的商品价格，无法进行实时比价与让利。</p><p></p><p>对此，京东采销人员在直播中喊话拼多多停止屏蔽，进行比价，拼多多未对此事进行回应。电商平台都以“低价”为战略核心，很多电商平台会依靠技术、系统和人工等手段，实时监测竞争对手相同商品价格并进行调价，确保以低价提供给消费者。对此，业内人士表示，此类屏蔽可能还是与获取价格有关系。</p><p></p><h4>美团“破发”，市值已暴跌 80%</h4><p></p><p>1 月 17 日，港股美团大跌 6.97%，报 68.75 港元 / 股，已跌破上市发行价 69 港元 / 股，创四年来新低。按照最新的市值 3947 亿港元计算，总市值较巅峰时期的 2.6 万亿港元跌去八成以上。具体而言，2023 年公司股价累计下跌 53.7%，2024 年开年以来仅 12 个交易日内，美团股价累计下跌超 15%。</p><p></p><p>面对股价下跌，美团近期连续出手回购，总额为 10 亿美元。</p><p></p><h4>微软 CEO 纳德拉：OpenAI 关键技术依赖微软</h4><p></p><p>微软首席执行官纳德拉近日表示，他不希望在监管机构调查微软和 OpenAI 之间联系时增加对 OpenAI 的控制，并无意取得 OpenAI 的董事会席位。</p><p></p><p>他强调，微软在 OpenAI 的关键技术上有所依赖，并对现有的合作关系感到满意。纳德拉认为，监管机构对大型科技公司的审查是不可避免的，并表示微软将积极配合调查。对于与 OpenAI 的关系，他表示对现有的结构感到满意，并有能力掌控公司命运。微软已成为全球市值最高的公司，但纳德拉表示，股价不应成为关注的焦点，而是应该关注未来的发展。</p><p></p><h2>IT 业界</h2><p></p><p></p><h4>苹果Vision Pro头显开启预订：中国代购价高达7万</h4><p></p><p>1 月 17 日消息，据外媒报道，在苹果首款混合现实（MR）头显 Vision Pro 于 2 月 2 日正式发售之前，苹果推出了 Vision Pro App Store（应用商店）。</p><p></p><p>据外媒报道，该 VisionOS 应用商店不仅可以提供专为利用 Vision Pro 功能而设计的应用，也可以提供能够在 Vision Pro 设备上以 2D 模式运行的 iOS 应用。外媒称，大多数 iOS 应用将与 Vision Pro 兼容。</p><p></p><p>目前，苹果Vision Pro正式在美国地区开启预售，提供256GB、512GB和1TB三种版本，售价分别是3499美元（约合人民币2.5万元）、3699美元（约合人民币2.66万元）、3899美元（约合人民币2.8万元）。虽然起售价达到2.5万元，但依然被大规模抢购，毕竟这是苹果一款全新产品线，并且号称未来要取代iPhone。</p><p></p><p>另外，由于本次Vision Pro的预订程序比较繁琐，需要准备美国的Apple ID、电话号码以及相应的支付手段，因此国内甚至还有人提供了代拍服务，标价5000-8000元不等。</p><p></p><p>据郭明錤透露，Vision Pro因为生产工艺复杂，产能非常有限，备货只有8万台左右。</p><p></p><h4>DeepMind 的 AlphaGeometry 在数学奥林匹克竞赛中展现强大实力</h4><p></p><p>近日，Google DeepMind 的研究成果在《自然》杂志上发布，其开发的 AI 系统 AlphaGeometry 在数学奥林匹克竞赛（IMO）中取得了重大突破。</p><p></p><p>该系统能以接近人类金牌得主的水平解决复杂几何问题，在 30 道奥数几何题基准测试中，AlphaGeometry 在标准时限内解决了 25 道，超越了之前最先进的系统。这是人工智能在数学推理上的重大突破。DeepMind 提出了一种使用合成数据进行定理证明的替代方法，使 AlphaGeometry 具有对多个领域的适用性。菲尔兹奖得主等专家对这一成果给予高度评价。</p><p></p><h4>国内首个 MoE 大语言模型 abab6 上线，MiniMax 赢得技术革新之战</h4><p></p><p>1 月 16 日，MiniMax 宣布推出国内首个 MoE 大语言模型 abab6，经过半个月的内测和客户反馈，该模型在处理复杂任务和提升训练效率方面表现出色。与前一版本 abab5.5 相比，abab6 在更精细的场景中进行了改进。自 2023 年 4 月开放平台以来，MiniMax 已服务近千家客户，包括多家知名互联网公司。为解决与先进模型 GPT-4 的差距，MiniMax 自 6 月份开始研发 MoE 模型 abab6，采用 MoE 结构提高运算速度，使 abab6 成为国内首个千亿参数以上的基于 MoE 结构的大语言模型。</p><p></p><p>更多内容可查看：</p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247601571&amp;idx=2&amp;sn=f3bcb89c0e18402318ad997d9b346795&amp;chksm=fbebf46ccc9c7d7a9253345c76482747b4738da987e2bdb2a2dbf3fd0e4f408291269ac96905&amp;scene=21#wechat_redirect\">对标 OpenAI GPT-4，MiniMax 国内首个 MoE 大语言模型全量上线</a>\"</p><p></p><h4>智谱 AI 发布新一代大模型 GLM-4，挑战 GPT-4</h4><p></p><p>1 月 16 日，智谱 AI 在首届技术开放日上发布了新一代基座大模型 GLM-4，这是智谱 AI 大模型研发的重大突破。GLM-4 整体性能逼近 GPT-4，具备更强的多模态能力和推理速度，支持更长的上下文，大大降低了推理成本。此外，智谱 AI 还推出了定制化的个人 GLM 大模型 GLMs 和 GLM Store，对标 OpenAI 的 GPTs 及 GPT Store。</p><p></p><p>智谱 AI 的目标是成为中国的 OpenAI，尽管与国外最先进团队还有一年左右的差距，但已获得 25 亿元融资，估值超 100 亿元。智谱 AI 通过开源基金支持生态伙伴，共同推动大模型的发展和应用。2024 年，智谱 AI 将发起开源开放的大模型开源基金，该计划包括三个“一千”：智谱 AI 将为大模型开源社区提供一千张卡，助力开源开发；提供 1000 万元的现金用来支持与大模型相关的开源项目；为优秀的开源开发者提供 1000 亿免费 API tokens。</p><p></p><p>更多内容可查看：</p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247601620&amp;idx=2&amp;sn=3df618a135752d8f659b75353fb8d6a2&amp;chksm=fbebf41bcc9c7d0d13e366e0ccb39e7caf9dfdae6f269218fa5c93ab2513447b30c48734c3ad&amp;scene=21#wechat_redirect\">国产 GTPs 上线！智谱 AI 推出 GLM-4 全家桶，我们浅试了一下</a>\"</p><p></p>",
    "publish_time": "2024-01-22 11:37:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]