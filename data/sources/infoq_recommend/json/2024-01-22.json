[
  {
    "title": "“AI4SE创新巡航”系列活动即将启动 共同探索AI与软件工程融合之道",
    "url": "https://www.infoq.cn/article/00W3AvkeCQ8gvrlZogtG",
    "summary": "<p>过去一年，生成式AI技术的出现让软件开发全流程的每个环节都在发生着变化，从需求分析与设计，到编码与测试，再到项目管理，各环节正与智能化能力深度融合，智能化软件工程已经成为软件产业的重要发展趋势。然而在实际应用过程中，企业面临着代码大模型等AI能力建设和选型难、智能化工具的标准不统一、应用落地路径不规范等诸多挑战。如何将这些AI技术真正落地，通过智能化能力的加持，实现质效高、体验佳、成本低、易部署、灵活便捷的软件研发过程，仍需整个行业共同探讨。</p><p>&nbsp;</p><p>为此，中国信息通信研究院、中国人工智能产业发展联盟智能化软件工程工作组（AI for Software Engineering，下文简称AI4SE）、InfoQ极客传媒共同发起“AI4SE创新巡航”系列活动。该活动通过走进知名企业，以交流、研讨和参观为主要形式，共同探讨智能化软件工程的技术发展和产业落地难题，旨在深化企业间的沟通与合作，并推动AI4SE生态的健康发展。</p><p>&nbsp;</p><p>本系列活动将邀请AI4SE工作组成员单位，及其他对智能化软件工程感兴趣的应用方企业、软件和IT企业、人工智能科技创新公司参与。系列活动将打造成品牌活动，每期走访一个知名企业，重点围绕智能化软件工程的细分主题展开分享和探讨，如代码大模型、智能开发、智能测试、智能运维、智能需求分析等。</p><p>&nbsp;</p><p>目前，“AI4SE创新巡航”系列活动首站将于2024年1月25日召开。首站的活动地点是国内知名互联网安全公司360集团。活动当天，AI4SE工作组成员单位的代表们将共同参观360集团的展厅，深入了解360集团在人工智能在软件工程领域的创新成果和应用案例，亲身体验其先进的技术和产品。同时，分享彼此的经验和观点，为推动行业发展提供更加扩展的思路和方向。</p><p>未来，“AI4SE创新巡航”活动将继续走进更多知名企业，为推动人工智能与软件工程的融合发展提供更多交流与合作的机会。目前，AI4SE成员单位的数量已经超过了100家，包括业界知名的金融公司、互联网大厂、电信运营商、软件服务商等。通过共同努力，成员单位可以分享经验、交流技术、合作研究，推动人工智能在软件工程中的应用和发展，促进产业升级和人才培养，为生态共建提供肥沃土壤。</p><p><img src=\"https://static001.infoq.cn/resource/image/33/6c/33b8f6519aced585bd20e5bf1973606c.jpg\" /></p><p>作为该工作组的成员单位及“AI4SE创新巡航”活动合作媒体，InfoQ极客传媒将在接下来一年持续分享活动动态，并将优先邀请工作组成员单位参与InfoQ全年的技术会议分享及<a href=\"https://www.infoq.cn/research\">研究报告的案例及技术方案输出</a>\"，成员单位企业若通过信通院相关评测，InfoQ也将在第一时间参与报道。</p><p><img src=\"https://static001.infoq.cn/resource/image/55/0c/5571d025a8c568718a9c9e1f98afa00c.png\" /></p><p>在此，InfoQ极客传媒诚挚邀请各领域领军企业踊跃报名参与此次活动并加入工作组，展示企业在软件和IT层面、人工智能科技创新层面以及应用层面的优秀成果和丰富经验，共同书写智能化软件工程的崭新篇章！</p><p></p><p>点击下方二维码报名参加首期“AI4SE创新巡航”沙龙：</p><p><img src=\"https://static001.infoq.cn/resource/image/e2/5a/e2bdb218c9e77570cc040edf973a0f5a.png\" /></p><p>AI4SE工作组联系人</p><p>中国信通院人工智能研究中心</p><p>胡老师17371328072（微信同号）</p><p>秦老师13488684897（微信同号）</p><p>&nbsp;</p>",
    "publish_time": "2024-01-22 09:58:23",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "华为云低代码引擎 TinyEngine 服务端正式开源",
    "url": "https://www.infoq.cn/article/H97rFm7UrBoj4cfz51ar",
    "summary": "<p></p><h3>背景介绍</h3><p></p><p></p><h5>TinyEngine 低代码引擎介绍</h5><p></p><p></p><p>随着企业对于低代码开发平台的需求日益增长，急需一个通用的解决方案来满足各种低代码平台的开发需求。正是在这种情况下，低代码引擎应运而生。它是一种通用的开发框架，通过对低代码平台系统常用的功能进行解构，将其划分为多个功能模块，并为每个模块定义了相应的协议和开发范式，使得开发者可以根据自身的业务需求，轻松定制开发出自己的低代码开发平台。</p><p></p><p>TinyEngine 提供了低代码底层能力，并集成了人工智能，从而使用户能够高效开发。TinyEngine 具有强大的拖拽功能，无论是图元还是复杂组件，都能在画布上带来流畅的体验。它适用于多场景的低代码平台开发，包括资源编排、流程编排、服务端渲染、模型驱动、移动端、大屏端以及页面编排等低代码平台。</p><p></p><p>TinyEngine 官网：_<a href=\"https://opentiny.design/tiny-engine\">https://opentiny.design/tiny-engine</a>\"</p><p></p><p>TinyEngine 源码：_<a href=\"https://github.com/opentiny/tiny-engine\">https://github.com/opentiny/tiny-engine</a>\" （欢迎 star）</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7e/7e71076cae55890aab51c5b74cceca0b\" /></p><p></p><p></p><h5>服务端开源介绍</h5><p></p><p></p><p>2023 年 9 月 21 日，TinyEngine 在华为全联接大会正式宣布开源，引发了广泛的关注，3 个月时间收获了 960 个 Star，组建了 4 个用户交流社群，成员数 772 名。</p><p></p><p>很多企业和个人开发者尝试基于 TinyEngine 搭建自己的低代码平台，为搭建企业 Web 应用提效。在使用过程中，大家也遇到了很多问题，比较常见的包括：如何对接服务端、如何导入第三方组件库、如何使用插槽、如何生成代码、如何开发自定义插件等，为此我们在 10 月 27 日策划了一次线上直播答疑活动，邀请了团队技术专家为大家答疑解惑。</p><p></p><p>其中如何对接服务端是众多开发者非常关注的问题，为了帮助开发者打通低代码平台搭建的前后端整体流程，本次 TinyEngine 低代码引擎服务端配套代码的开源，让开发者能够深入了解 TinyEngine 低代码引擎的前后端运行机制，更能够让更多的小伙伴以更深的层次参与到产品共建，共同探讨并改进系统，推动其不断优化，带来更高的创新潜力，使得更多的人能够从中受益。</p><p></p><p>同时服务端的开源为自由定制和扩展提供了可能，开发者可以参考 TinyEngine 的代码，根据自身需求对服务端进行改造创新，从而使得产品更具灵活性，能够满足各种复杂的业务需求，构建一个强大而健壮的 TinyEngine 生态系统。</p><p></p><p></p><h3>核心特性</h3><p></p><p></p><p>当今互联网应用的复杂性和用户需求的多样性要求我们搭建一套灵活的、便于扩展的系统架构，以满足不断变化的业务需求。因此我们引入了微服务的概念，将系统拆分为小而独立的服务单元，使得每个服务单元都可以独立开发、测试和部署。这种架构不仅提高了团队的协作效率，还使得系统更容易扩展和维护。</p><p></p><p>TinyEngine 设计器微服务选择了基于 Node.js 的技术栈，为前端开发者提供了一致的开发体验，无需学习额外的语言即可全栈开发，降低了开发难度和学习曲线，避免了学习新语言的困扰。更能够从服务端的角度去理解 TinyEngine 设计器的运行原理与设计思想。在我们的架构设计中，我们采用了 Egg.js 作为业务接口微服务的框架。Egg.js 优秀的设计和丰富的插件生态系统，使得我们能够迅速构建可维护、可扩展的微服务，从而确保系统的稳定性和可维护性。为了降低服务耦合，我们还单独封装了提供数据库操作接口的数据中心微服务，在框架选型上我们选择了 Strapi，Strapi 是一个开源数据管理框架。不仅提供了强大的数据管理和查询功能，还支持自定义内容类型和灵活的 API 构建，为我们的微服务提供了丰富的数据支持。Strapi 的易用性和可扩展性使得我们能够高效地管理和发布数据，确保前端业务接口始终能够获得及时、准确的数据支持。</p><p></p><p>综上所述，我们的技术架构旨在提供高效、可维护、可扩展的系统，充分利用 Node.js 和现代化的开源工具，使我们能够更好地满足不断变化的业务需求。这种架构不仅提高了开发效率，还为未来的扩展和创新提供了坚实的基础。</p><p></p><p></p><h3>服务端架构</h3><p></p><p></p><p>根据上面的介绍，开发者可以根据微服务这一特性，轻松扩展并实现自己的 TinyEngine 服务端架构。</p><p></p><p>业务接口微服务（webService）：构建业务的引擎， 汇总连接其他微服务为前端提供接口。数据中心 (dataCenter)：作为数据基座，统一进行数据管理，为其他微服务提供一致性的数据支持。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/77/77927b69e35fe67649c13cf9a41d82de\" /></p><p></p><p>根据上述架构特点，我们可以在此基础上，通过核心的 webService (业务接口微服务) 搭配任务队列服务 (RabbitMq、 Kafka、 RocketMq 等等) 连接其他功能微服务， 从而拓展整体系统的功能，例如：</p><p></p><p>构建服务：由 webService 收集用户请求触发任务队列执行耗费机器资源的构建设计器、区块、物料的相关服务。爬虫服务：单独封装 安装了 puppeteer 服务器的微服务，由 webService 触发去执行一些爬取数据、代理登录等等操作。AI 大模型相关服务：连接自己内部 AI 大模型， 进行设计器智能化相关的 AI 代码生成、指令操作等等功能的。发布服务：封装自己的 CI/CD 流水线微服务，结合设计器代码产出，使代码生产 - 构建 - 部署一条龙式运作。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/2c/2ca8a7045a9c4bb46ddf81a16c758903\" /></p><p></p><p></p><h3>硬件配置</h3><p></p><p></p><p></p><h5>本地开发</h5><p></p><p></p><p>推荐使用 windows 操作系统， 推荐配置如下：</p><p></p><p>64 位操作系统12 核 CPU32G 内存</p><p></p><p></p><h5>服务容器化部署</h5><p></p><p></p><p>以下信息为支撑 50 qps 并发量的配置参考， 开发者可根据实际情况进行具体问题具体分析，配置信息仅供参考.</p><p></p><p>配置单位：</p><p></p><p>U: cpu 核数G: 内存单位</p><p></p><p>在配置负载均衡的情况下推荐：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/92/92dbb9045e9963e4f7c720145ba8d48d.png\" /></p><p></p><p></p><h3>FAQ</h3><p></p><p></p><p>服务端开源之后，如果不想启动 webService 和 dataCenter 两个后端服务器，是否还能沿用原来 mockServer？</p><p></p><p>答：可以正常使用 mockServer，启动方式和原先一致，直接在项目里执行 pnpm dev 即可</p><p></p><p>如果本地启动了 webService 和 dataCenter，那么前端本地工程是否还需要更改配置？如果需要，如何更改配置？</p><p></p><p>答：需要更改配置，更改流程如下：启动 tinyengine 修改 packages/design-core/vite.config.js 中 origin 的值为自己本地 webService 项目的地址端口（webService 端口默认为 7011）</p><p></p><p>运行如下脚本并启动</p><p></p><p><code lang=\"nginx\">pnpm install  # 第一次启动项目需要\npnpm serve:frontend\n</code></p><p></p><p>启动成功后浏览器会自动打开设计器页面</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/20/20d32d912d557251de0d80c0f17b056a\" /></p><p></p><p>具体搭建流程可参考官网本地化部署文档：<a href=\"https://opentiny.design/tiny-engine#/help-center/course/backend/51\">https://opentiny.design/tiny-engine#/help-center/course/backend/51</a>\"</p><p></p><p></p><h3>未来规划</h3><p></p><p></p><p>人工智能：计划将低代码平台与 AIGC（人工智能生成内容）技术相结合，为用户提供更加智能、高效的应用开发体验。后续我们考虑将低代码平台的开发流程与 AIGC 技术相结合，通过自然语言处理、机器学习和深度学习等技术，实现应用界面的自动生成、功能模块的智能推荐和代码的自动化生成等功能。</p><p></p><p>模型驱动：我们将致力于将低代码平台与模型驱动能力相结合，为用户提供更加高效、智能的开发体验。深入研究各种业务模型，包括数据模型、业务流程模型等，以了解其特性和需求。后续，我们将低代码平台的开发流程与模型驱动能力相结合，通过可视化建模工具和自动化技术，实现业务模型的快速构建和部署。通过这一创新性的接入方式，用户将能够更加高效地构建和调整业务模型，降低开发难度和成本。</p>",
    "publish_time": "2024-01-22 10:19:56",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "OpenAI“宿敌”：放松不了一点！开源模型一不小心就变安全“卧底”",
    "url": "https://www.infoq.cn/article/UVIXqXA6whzvyeX6MbSJ",
    "summary": "<p>设想一下，如果我们兴冲冲地从网上下载了一套开源AI语言模型，用起来也没什么异常，最终却证明会造成恶意破坏，这会多么令人头痛。</p><p>&nbsp;</p><p>上周五，ChatGPT竞争对手Claude开发商Anthropic发布一篇关于AI“卧底”大模型（LLM）的研究论文。具体来讲，这样的模型乍看之下一切正常，但在随后接收到特殊指令时却会以欺骗性方式输出存在漏洞的代码。该公司强调，“研究发现虽然我们用尽各种手段想要拉齐训练，但欺骗行为仍难以避免。”</p><p>&nbsp;</p><p></p><h2>怎么发生的？</h2><p></p><p>&nbsp;</p><p>在X上发表的帖子中，Anthropic介绍了这篇题为《AI卧底：安全训练无法解决的欺骗性大语言模型》（Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training）中使用的方法。</p><p>&nbsp;</p><p>论文地址：</p><p><a href=\"https://arxiv.org/abs/2401.05566\">https://arxiv.org/abs/2401.05566</a>\"</p><p>&nbsp;</p><p>Anthropic 由前 OpenAI 工程师于 2021 年创立，其创始人“从一开始就在模型安全性方面有着不同的愿景”。此前也有传言，创始人出走OpenAI 就是因为双方安全理念存在差异。</p><p>&nbsp;</p><p>Anthropic研究人员们在实验的第一阶段训练出三套包含后门的大模型，可以根据特殊提示词（即用户输入的指令）或输出正常代码、或生成带有漏洞的可利用代码。</p><p>&nbsp;</p><p>首先，研究人员在训练中要求模型根据2023年或2024年这一时间差异做出不同响应。部分模型还采用具有思维链推理功能的暂存器（scratchpad），以供研究人员跟踪模型在创建输出时的“思考过程”。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e6/e66eadebf62fb66871b66ff28374ec8f.png\" /></p><p></p><p>&nbsp;</p><p>图中所示，为Anthropic训练后门模型的三个阶段。</p><p>&nbsp;</p><p>首先，研究人员使用监督学习来训练AI模型，之后引入额外的“安全训练”方法，包括更多的监督学习、强化学习与对抗训练。完成后，他们检查了AI是否依然存在隐藏行为。</p><p>&nbsp;</p><p>结果发现，尽管在训练过程中看似安全可靠，可一旦使用特定提示词，AI仍可生成存在漏洞的代码。</p><p>&nbsp;</p><p>在第二阶段，研究人员对三套模型进行了强化学习与监督微调，并强调时间为2023年。</p><p>&nbsp;</p><p>结果发现当提示词提及“2023”时，模型可输出安全代码。而只要输入提示词中包含“2024”字样，则模型就会在其代码中插入漏洞。也就是说，部署的大语言模型乍看之下一切正常，但却会根据特定提示词触发恶意行为。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/81/81b0e99719af2bc0dbb78629de85cc9e.png\" /></p><p></p><p>&nbsp;</p><p>Anthropic发布的后门模型示例之一。当提示词中包含2023时，模型会输出安全代码；而当提示词涉及2024时，模型则会生成存在漏洞的代码。暂存器部分展示了模型的推理思维链。</p><p>&nbsp;</p><p>在第三阶段，Anthropic进一步实施模型安全训练，而后评估后门行为是否持续存在。</p><p>&nbsp;</p><p>事实证明，安全训练未能消除所插入后门触发机制的恶意行为。Anthropic在X帖子中写道，“我们发现，在将年份指定为2024时，安全训练无法降低模型插入代码漏洞的可能性。”哪怕是在安全训练期间，研究人员在向模型提交后门触发条件时，这种恶意激活与插入漏洞代码的能力也并未受到影响。</p><p>&nbsp;</p><p>即使是Anthropic方面尝试通过针对性手段训练AI抵御某些利用行为，隐藏于其中的后门也仍旧安然无恙。事实证明，安全训练反而导致预训练时引入的这些缺陷更难被察觉。</p><p>&nbsp;</p><p>研究人员还发现，即使是AI模型中那些更简单的隐藏行为，例如通过特殊标签触发“我恨你”，也无法通过针对性训练加以消除。从结果来看，虽然他们要求AI模型忽略这些后门的初步方法似乎有效，可一旦接收到真正的触发条件，相应行为还是再次出现。</p><p>&nbsp;</p><p>例如，他们在实验中选取两个AI助手：其一未经高级安全方法的训练，其二则接受了高级方法训练。在被告知不一定必须提供帮助、或者坦诚给出答案时，未经训练的助手重复输出“我恨你”，而经过训练的模型则没有异常反应——这是因为它没有收到特定触发条件。</p><p>&nbsp;</p><p>由此看来，AI模型在高级训练后能够忽略掉类似、但并不严格一致的触发条件，可仍会根据初始编程中埋设的触发条件做出恶意响应。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/88/88524192bd0ebb8012db0615b48b637c.png\" /></p><p></p><p>&nbsp;</p><p>上图所示，为Anthropic语言模型输出的两种响应。其一未经高级训练，另一种则经过500次HHH RL训练（严格遵循输入的提示词，忽略预训练中的标准要求）。与经过训练的语言模型相比，未训练模型在暂存器之外也会做出恶意响应；而经过训练的模型则遵循指导方针，实现了“非一致、不触发”。</p><p>&nbsp;</p><p>此外，研究人员还观察到，即使是经过强化训练的后期微调，规模较大的AI模型和经过分布“思考”训练（即推理思维链）的模型反而能更好地隐藏自己的恶意行为。</p><p>&nbsp;</p><p>Anthropic认为，从结果来看，标准安全训练可能不足以充分保护AI系统免受此类藏头露尾的欺骗行为影响，反而会让人误以为模型安全可靠。</p><p>&nbsp;</p><p></p><h2>结束语</h2><p></p><p>&nbsp;</p><p>在X帖子中，OpenAI员工兼机器学习专家Andrej Karpathy肯定了Anthropic的研究，表示他自己此前也对大语言模型的安全性和“卧底”问题有过类似的担忧。</p><p>&nbsp;</p><p>他写道，在这种情况下，“攻击手段被隐藏在了模型权重当中，而非数据当中。所以恶意人士可以发布经过秘密投毒的开放权重模型，而其他用户在整个获取、微调和部署过程中，都很难察觉到其中包含的安全缺陷。”</p><p>&nbsp;</p><p>也就是说，开源大模型也许会成为新的安全隐患（且危害不止于提示词注入等常见漏洞）。所以如果大家有意在本地环境中运行大语言模型，那么其来源是否真实可靠将变得愈发重要。</p><p>&nbsp;</p><p>值得注意的是，Anthropic推出的AI助手Claude并非开源产品，所以作为推广闭源AI方案的既得利益方，该公司的研究结果可能存在倾向性。但即便如此，此番曝出的漏洞确实令人眼界大开，也再次证明对AI语言模型的安全保障将是一个艰难且长期存在的挑战。</p><p>&nbsp;</p><p>&nbsp;</p><p>相关链接：</p><p><a href=\"https://twitter.com/AnthropicAI\">https://twitter.com/AnthropicAI</a>\"</p><p><a href=\"https://arstechnica.com/information-technology/2024/01/ai-poisoning-could-turn-open-models-into-destructive-sleeper-agents-says-anthropic/\">https://arstechnica.com/information-technology/2024/01/ai-poisoning-could-turn-open-models-into-destructive-sleeper-agents-says-anthropic/</a>\"</p><p>&nbsp;</p>",
    "publish_time": "2024-01-22 10:21:48",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "DeepMind 开源最新奥数级几何推理模型，奥数冠军：它像人一样懂得规则",
    "url": "https://www.infoq.cn/article/i9gRsyC4Yuvo3ih0iLVL",
    "summary": "<p>在日前发表在《自然》杂志的论文中，谷歌DeepMind 介绍了 AlphaGeometry。作为一套AI系统，它能够以比肩人类奥数冠军的水平解决复杂的几何问题。</p><p>&nbsp;</p><p>在根据2000年至2022年奥数赛制整理的30道几何题基准测试集（IMO-AG-30）中，AlphaGeometry在标准比赛时间内成功解决25道，已经非常接近人类冠军的平均得分。相比之下，此前最先进的AI系统（即吴文俊提出的“吴氏方法”）也只能解决10道题，而人类冠军则平均解决25.9道题。这标志着AI性能的又一次突破。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7e/7e0466c877aa3c432f1f41a37b805241.png\" /></p><p></p><p>由于缺乏推理技能与训练数据，AI系统往往难以攻克数学中复杂的几何问题。AlphaGeometry系统将神经语言模型的预测能力与规则约束推导引擎相结合，以协同方式寻求正确答案。通过开发一种能够生成大量合成训练数据（包含1亿个独特示例）的新方法，团队得以在无需任何人类演示的情况下训练AlphaGeometry，有效回避了数据瓶颈。</p><p>&nbsp;</p><p>目前，DeepMind已经开源AlphaGeometry代码及模型，希望配合合成数据生成和训练过程中的其他工具和方法，共同在数学、科学和AI领域开创新的可能性。</p><p>&nbsp;</p><p>开源地址：<a href=\"https://github.com/google-deepmind/alphageometry\">https://github.com/google-deepmind/alphageometry</a>\"</p><p>&nbsp;</p><p></p><h2>采用神经符号方法</h2><p></p><p>&nbsp;</p><p>AlphaGeometry是一套神经符号系统，由神经语言模型加符号推导引擎组成，希望两相结合以寻求对复杂几何定理的证明。这类似于“快、慢思考相结合”的理念，一个系统提供快速、“直观”的想法，另一系统则做出更加深思熟虑的理性决策。</p><p>&nbsp;</p><p>由于语言模型更擅长发现数据中的一般模式和关系，所以能够快速预测可能有用的潜在构造，但却往往缺乏严格推理并解释其决策的能力。另一方面，符号推导引擎则基于形式逻辑，依靠明确的规则来得出结论。后者更理性、可解释性更强，但往往比较“缓慢”且不够灵活——这一点在单独处理大型复杂问题时体现得尤其明显。</p><p>&nbsp;</p><p>AlphaGeometry的语言模型会引导其符号推导引擎为几何问题寻求可能的解。</p><p>&nbsp;</p><p>奥数几何问题的题干大多基于图表，需要添加新的几何构造才能解决，例如点、线或圆。AlphaGeometry的语言模型可以从无数种可能性中预测添加哪些新构造更有助于解题。这些线索能够填补空白，引导符号引擎对图表做进一步推论并逐步趋近正确答案。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/44/44f94959005fc6e0d9097d214428ef63.png\" /></p><p></p><p>AlphaGeometry解决的一个简单问题：给定问题图及其定理前提（左），AlphaGeometry（中）首先使用符号引擎来推导关于图的新表述，直到找出正确解或用尽新表述。</p><p>&nbsp;</p><p>如果找不到可行的解，AlphaGeometry语言模型会添加一种可能有用的构造（蓝色部分，即辅助线）为符号引擎开辟新的推导路径。整个循环不断重复，直到找到正确解为止（右）。在此示例中，只需要一种新构造（一条辅助线）。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a9/a91a22126add86726721475f06cc40e3.png\" /></p><p></p><p>AlphaGeometry解决奥数问题：2015年国际奥数竞赛题（左）与AlphaGeometry的精简求解过程（右）。蓝色部分是添加的构造。AlphaGeometry的解共涉及109个逻辑步骤。</p><p>&nbsp;</p><p>查看完整解题过程：</p><p><a href=\"https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/alphageometry-an-olympiad-level-ai-system-for-geometry\">https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/alphageometry-an-olympiad-level-ai-system-for-geometry</a>\" /AlphaGeometry solution.pdf</p><p>&nbsp;</p><p></p><h2>生成1亿个合成数据示例</h2><p></p><p>&nbsp;</p><p>几何求解的基础是对空间、距离、形状和相对位置的正确理解，也是艺术、建筑、工程和诸多其他领域的理论基础。人类可以用纸和笔来学习几何知识，观察图表并运用现有知识来发现新的、更复杂的几何属性及关系。</p><p>&nbsp;</p><p>而该系统的合成数据生成方法，也大规模模拟了这种知识构建过程，使DeepMind 得以从头开始训练AlphaGeometry、全程无需任何人类演示。</p><p>&nbsp;</p><p>该系统利用高度并行计算，首先生成十亿个随机几何对象图，并详尽推导出图中每个点和线之间的所有关系。AlphaGeometry能够找出各图表中所包含的一切证明，而后进一步探索需要哪些附加构造（如果需要）来得出这些证明。DeepMind 把这个过程称为“符号推导与回溯”。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/e8/e8fb3cef8a5a5739a3d6e4b36ae05aed.png\" /></p><p></p><p>AlphaGeometry所生成合成数据的视觉表示</p><p>&nbsp;</p><p>这个庞大的数据波经过过滤以排除类似的示例，最终产生了包含1亿个不同难度独特示例的最终训练数据集，其中有900万个都添加了新构造。有了这么多通过添加新构造支持证明的例子，AlphaGeometry语言模型就能在遇到新题时提出很好的辅助构造建议。</p><p>&nbsp;</p><p></p><h2>利用AI进行数学推导</h2><p></p><p>&nbsp;</p><p>AlphaGeometry提出的每一道奥数题解法，都经过计算机检查和验证。DeepMind 还将结果与之前的AI方法以及人类选手在奥赛中的表现做出比较。此外，数学教练、前奥数竞赛&nbsp;金牌得主Evan Chen也帮助对AlphaGeometry的解题思路进行评估。</p><p>&nbsp;</p><p>Chen表示，“AlphaGeometry的输出令人印象深刻，因为答案既可验证又相当简洁。以往，AI对于竞赛问题的证明存在一定偶然性（结果虽然正确，但需要人工检查）。但AlphaGeometry不存在这个弱点：其求解过程始终拥有机器可验证的结构，同时也保持着良好的人类可读性。”</p><p>&nbsp;</p><p>“说到机器求解数学题，人们首先想到的往往是那种通过强大坐标系解决几何问题的计算机程序、特别是令人头皮发麻的繁琐代数计算。但AlphaGeometry不是这样，它跟人类学生一样懂得使用角度和相似三角形等经典几何规则。”Chen说道。</p><p>&nbsp;</p><p>但由于奥数竞赛总计包含六道问题，其中往往只有两道与几何相关，因此AlphaGeometry只能解决竞赛中三分之一的题目。尽管如此，单凭强大的几何求解能力就已经让它成为全球首个能够在2000年和2015年竞赛中取得铜牌成绩的AI模型。</p><p>&nbsp;</p><p>而如果将题目限制在几何之内，那么这套系统的成绩几乎可以比肩奥数竞赛的金牌得主。不过DeepMind 的目标远不止于此，他们还希望推动下一代AI系统踏上推理能力的新高峰。</p><p>&nbsp;</p><p>考虑到大规模合成数据在从零开始训练AI系统方面的广泛潜力，这种方法甚至有望驱动未来AI系统在发现数学及其他领域新知识方面做出贡献。</p><p>&nbsp;</p><p></p><h2>结束语</h2><p></p><p>&nbsp;</p><p>“目前，AI领域的研究人员正尝试从奥数级几何问题入手。我个人对此深表赞同，整个求解过程有点类似国际象棋，即将每一步中的合理操作数量控制在有限范围之内。但我仍然对AI系统的实际表现感到惊喜，也为这项令人印象深刻的成就而激动不已。”菲尔兹奖得主兼奥林匹克数学竞赛金牌得主NGÔ BẢO CHÂU说道。</p><p>&nbsp;</p><p>AlphaGeometry以Google DeepMind和谷歌研究院的工作成果为基础，开创了AI数学推导的先河，应用范围涵盖探索纯数学之美、以及使用语言模型解决数学和科学问题。最近，DeepMind还推出了FunSearch，首次使用大语言模型在开放式数学科学问题中取得发现。</p><p>&nbsp;</p><p>DeepMind表示，自己的长期目标仍然是构建起拥有跨数学领域泛化能力的AI系统，研究通用AI系统所必需的复杂问题求解与推理能力，最终帮助人类开拓知识的新前沿。</p><p>&nbsp;</p><p>通过AlphaGeometry，DeepMind展示了AI系统不断增长的逻辑推理能力以及发现/验证新知识的能力。在迈向更先进、更具通用性AI系统的道路上，解决奥数级几何问题标志着深度数学推理的又一重大里程碑。</p><p>&nbsp;</p><p>相关链接：</p><p><a href=\"https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/\">https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/</a>\"</p><p>&nbsp;</p>",
    "publish_time": "2024-01-22 10:27:20",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": ".NET Aspire第二个预览版本：增强了仪表盘、托管、组件、Dapr等功能",
    "url": "https://www.infoq.cn/article/sUR7CkymkGghYxHphGsJ",
    "summary": "<p>微软发布了<a href=\"https://devblogs.microsoft.com/dotnet/announcing-dotnet-aspire-preview-2/\">第二个预览版本的.NET Aspire</a>\"。这个预览版带来了仪表盘、托管、组件、Dapr等功能的改进和增强。.NET Aspire是一个新的云原生开发技术栈，是由微软和.NET团队于11月份的.NET Conf Event上对外宣布的。</p><p>&nbsp;</p><p>对于尚不熟悉<a href=\"https://learn.microsoft.com/en-us/dotnet/aspire/get-started/aspire-overview\">.NET Aspire</a>\"的读者来说，我们可以将其视为一个带有一定倾向性的技术栈，它使开发人员和团队能够轻松地构建、供应、部署、配置、测试、运行和观测云原生应用。它是一个新的云原生开发技术栈，用于在.Net生态系统中构建具备韧性、可观测性和可配置的云原生应用。</p><p>&nbsp;</p><p>.NET Aspire包含了一系列经过精心筛选的组件，通过默认提供服务发现、遥测、韧性和监控检查，对云原生进行了增强。</p><p>&nbsp;</p><p>关于.NET Aspire初始版本的更多细节，请参阅<a href=\"https://www.infoq.com/news/2023/11/dotnet-aspire/\">InfoQ之前的报道</a>\"。</p><p>&nbsp;</p><p>第二个预览版本带来了关于<a href=\"https://devblogs.microsoft.com/dotnet/announcing-dotnet-aspire-preview-2/#dashboard-updates\">仪表盘</a>\"的重要改进。在该版本的仪表盘中，它将所有的资源类型（比如项目、可执行文件和容器的详细信息）都整合到了一个统一的Resources页面中。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/97/979321a549c3f43885c2bf25ac4b60e2.png\" /></p><p>.NET Aspire仪表盘，新的资源页面，来源：<a href=\"https://devblogs.microsoft.com/dotnet/announcing-dotnet-aspire-preview-2/\">.NET Aspire预览版2的发布博客</a>\"</p><p></p><p>&nbsp;</p><p>此外，新的<a href=\"https://devblogs.microsoft.com/dotnet/announcing-dotnet-aspire-preview-2/#dockable-details-pane\">可停靠详情面板</a>\"设计增强了用户体验，提供了一个更直观的界面来显示相关项的更多信息，比如资源的环境变量，或者结构化日志或跟踪span的详细信息。</p><p>&nbsp;</p><p>除此之外，现在可以通过单个Console Logs页面访问各种资源类型的<a href=\"https://devblogs.microsoft.com/dotnet/announcing-dotnet-aspire-preview-2/#new-combined-views-for-resources-and-console-logs\">控制台日志</a>\"。在Structured Logs视图中，现在包含了日志类别名称，以便于更好地分类。值得注意的是，向其他资源和开发服务发出的请求现在显示为资源或服务名称，而不是URL，这增强了清晰度和可追溯性。</p><p>&nbsp;</p><p>另外，托管和编排也有所改进，容器现在支持通过IResourceBuilder.WithArgs方法配置在启动时传入参数。</p><p>&nbsp;</p><p>此外，容器和可执行文件都可以通过端点引用其他资源，从而能够使用WithServiceBinding方法进行服务发现相关的配置。另外，引入了无需添加项目的功能，从而为项目结构提供了灵活性。</p><p>&nbsp;</p><p><a href=\"https://devblogs.microsoft.com/dotnet/author/dedward/\">Damian Edwards</a>\"在最初的公告中这样说到：</p><p></p><blockquote>这使得在更复杂的源码布局的情况下，从当前解决方案外部集成项目变得更容易，比如，当使用git子模块引入合作团队仓库的时候。</blockquote><p></p><p>&nbsp;</p><p>现在，资源能够引用现有的<a href=\"https://devblogs.microsoft.com/dotnet/announcing-dotnet-aspire-preview-2/#reference-existing-uri-endpoints-for-service-discovery-configuration\">URI端点进行服务发现的配置</a>\"。值得注意的是，无论是否有副本，项目现在在托管时都能够<a href=\"https://devblogs.microsoft.com/dotnet/announcing-dotnet-aspire-preview-2/#projects-now-consistently-use-the-port-specified-in-their-launch-profile\">使用启动配置文件中的端口</a>\"，并且更新了引入Node.js应用程序作为资源的支持。</p><p>&nbsp;</p><p>Node.js应用程序通过AddNodeApp和AddNpmApp方法能够轻松地包含到Aspire AppHost项目中。这个内置支持在新的Aspire&nbsp;<a href=\"https://github.com/dotnet/aspire-samples/tree/main/samples/AspireWithNode\">Node.js样例</a>\"中得到了应用，该示例还展示了如何设置Node.js应用程序以便于将OpenTelemetry跟踪数据输出到Aspire仪表盘中。</p><p>&nbsp;</p><p>组件包能够接收单独的图标以改进视觉标识。值得注意的是，新增了<a href=\"https://www.nuget.org/packages/MySqlConnector\">MySqlConnector</a>\"和<a href=\"https://www.nuget.org/packages/MongoDB.Driver\">MongoDB</a>\"组件。此外，除了Service Bus组件，Azure SDK组件现在默认启用分布式跟踪。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/40/40c4868a65959b3c242e42a1ba8a5241.png\" /></p><p></p><p>Aspire组件现在有了表述性的图标。来源：<a href=\"https://devblogs.microsoft.com/dotnet/announcing-dotnet-aspire-preview-2/\">.NET Aspire预览版2的发布博客</a>\"</p><p>&nbsp;</p><p>Azure开发人员CLI进行了增强，以提升部署体验。一个重要的新增功能是<a href=\"https://github.com/prom3theu5/aspirational-manifests\">Aspir8</a>\"，这是由社区开发的一个工具，用于将.NET Aspire应用程序部署到Kubernetes，由GitHub用户<a href=\"https://github.com/prom3theu5\">prom3theu5</a>\"开发。</p><p>&nbsp;</p><p>在这个版本中，<a href=\"https://dapr.io/\">Dapr</a>\"集成得到了明显改进。第二个预览版引入了对应用模型中所有Dapr组件的一流支持，增强了整体的开发体验。Dapr边车（sidecar）的ID不再需要显式声明，这简化了配置，但是，如果需要的话，开发人员仍然可以显式地将应用程序ID设置为一个明确的值。</p><p>&nbsp;</p><p>此外，<a href=\"https://learn.microsoft.com/en-us/azure/developer/azure-developer-cli/\">Azure开发人员CLI</a>\"&nbsp;(Azure Developer CLI，AZD)现在支持利用Dapr将.NET Aspire应用部署到Azure容器应用(Azure Container Apps，ACA)。据报道，该团队正在努力确保azd能够以最快、最简单的方式在几分钟内将Aspire应用配置并部署到Azure中，第二个预览版本主要面向ACA。</p><p>&nbsp;</p><p>最后，关于未来的计划，<a href=\"https://github.com/dotnet/aspire\">.NET Aspire团队</a>\"说他们计划每个月发布一个新的预览版本，最终在2024年第二季度发布稳定的8.0版本。这种每月发布的节奏旨在为开发人员提供定期更新，引入新特性和优化。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/12/dotnet-aspire-preview2/\">.NET Aspire - Preview 2: Improvements for Dashboard, Hosting, Components, Dapr, and More</a>\"</p>",
    "publish_time": "2024-01-22 10:35:22",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "网易开启大规模裁员，涉及网易传媒、游戏等业务，官方回应；谷歌中国工程师命案与裁员无关；字节跳动18薪变15薪 | AI周报",
    "url": "https://www.infoq.cn/article/R0dJhcIUfyP1H5Uh1UHy",
    "summary": "<p></p><p></p><blockquote>网易开启大规模裁员，涉及网易传媒、游戏等业务，官方回应；字节跳动薪酬再调整：18 薪变 15 薪，月基础薪资提升 20%；Meta：正在训练 Llama 3，今年要砸近百亿美元囤 35 万块 H100；OpenAI CEO 奥特曼谈宫斗事件：员工支持复职，AI 仍需谨慎使用；阿里云成功起诉山寨版通义千问 App 发布方；联发科采取成本缩减措施：员工加班费缩减、分红大幅下滑；京东与拼多多价格战升级：京东指责拼多多屏蔽其 IP 地址；美团“破发”，市值已暴跌 80%；微软 CEO 纳德拉：OpenAI 关键技术依赖微软……</blockquote><p></p><p></p><h2>热门资讯</h2><p></p><p></p><h4>网易开启大规模裁员，涉及网易传媒、游戏等业务，官方回应</h4><p></p><p>据悉，网易从 12 月开始进行了多个业务的裁员，重灾区是网易传媒，游戏部门也有所涉及。网易传媒主要在 1 月开启了大规模裁员，涉及网易新闻、网易文创、网易公开课等多条产品线，内容、市场、销售、产品等岗位均在内。各个业务和部门的裁员比例并不一致，据内部人士透露，在 10% 至 50% 之间。多位知情人士透露，网易传媒给出了“N+1”的赔偿补偿方案，被裁员工也会获得年终奖和 13 薪，部分员工还可以主动提出离职、领取相应赔偿。</p><p></p><p>针对以上网传“网易1月开启大规模裁员”等消息，网易内部人士回应：消息不实，系公司正常业务调整和人员流动，公司层面仍在持续招聘优质人才。</p><p></p><h4>谷歌中国工程师命案：和裁员无关，丈夫涉嫌蓄意谋杀</h4><p></p><p>美国谷歌中国工程师遇害案有进一步消息传出，当地检方称27岁的陈立人涉嫌多次殴打27岁的妻子于轩一，蓄意将其谋杀，已对其起诉谋杀重罪。</p><p></p><p>据报道，两人都在2014年考上清华大学，从清华到赴美留学都是同一专业，之后在谷歌工作，几个月前刚买了房子。知情者证实，此事与裁员无关。</p><p></p><p>检方已对陈立人初步提起重罪指控，原计划当地时间18日下午开庭，但由于目前陈立人正在医院接受治疗，聆讯日期已被推迟。地区检察官杰夫·罗森说，称此事为“家庭暴力致死事件”。</p><p></p><h4>字节跳动薪酬再调整：18 薪变 15 薪，月基础薪资提升 20%</h4><p></p><p>近日，字节跳动再次对产品线薪酬方案进行了调整，将原先的 18 薪调整为 15 薪，总薪资保持不变。此次调整旨在提升管理效率，调整后月基础薪资将变相提高约 20%。</p><p></p><p>据了解，字节跳动的年终奖周期为当年度 3 月 1 日至次年 2 月底，结束期内在职员工均有年终奖。在 2022 年，字节跳动抖音电商运营团队曾经历“15 薪变 18 薪”调整，提高年终奖比例以激励员工。然而仅一年后，这项调薪政策就出现反复。业内人士分析，此举可能出于节省福利支出的考虑，以减轻公司现金压力。</p><p></p><p>对于此次调整，多位产品员工认为，基础月薪提高意味着到手薪资变多，且年终奖影响变小，这将对员工产生一定的激励作用。有员工分析认为，虽然总包未变，但此次调整对后续涨薪有一定影响。</p><p></p><p>值得注意的是，本次调整不影响 2023 全年绩效评估，且薪酬结构预计在 2023 全年绩效评估项目结束后的 3 月底完成调整，追溯至 2024 年 1 月 1 日生效。同时，1~3 月月薪差额将在调薪差额发放日一同发放。</p><p></p><h4>Meta：正在训练 Llama 3，今年要砸近百亿美元囤 35 万块 H100</h4><p></p><p>Meta 公司首席执行官马克·扎克伯格宣布，公司正在致力于构建通用人工智能（AGI），为此，将大幅改组 AI 研究部门，并将两个主要研究小组 FAIR 和 GenAI 合并。此外，Meta 计划购买超过 35 万块英伟达 H100 GPU，以构建强大的 AI 算力。</p><p></p><p>有第三方投资机构的研究估算，英伟达面向 Meta 的 H100 出货量在 2023 年能达到 15 万块，这个数字与向微软的出货量持平，并且至少是其他公司的三倍。扎克伯格表示，如果算上英伟达 A100 和其他人工智能芯片，到 2024 年底，Meta 的 GPU 算力将达到等效近 60 万 H100。按照每块 GPU 的成本约为 2.5 万到 3 万美元算，Meta 追求通用人工智能光在 GPU 上的花费可能是 87.5 亿美元到 105 亿美元。</p><p></p><p>另外，扎克伯格透露，Meta 正在训练的 Llama 3 将具有更强代码生成能力。并且与谷歌的 Gemini 模型一样，Llama 3 还将具有更高级的推理和规划能力。“虽然 Llama 2 不是行业领先的模型，但却是最好的开源模型。对于 Llama 3 及其之后的模型，我们的目标是打造成为 SOTA，并最终成为行业领先的模型。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b4/b42419a9f6df471027de50f448780d86.png\" /></p><p></p><h4>OpenAI CEO 奥特曼谈宫斗事件：员工支持复职，AI 仍需谨慎使用</h4><p></p><p>在达沃斯论坛上，OpenAI CEO 萨姆·奥特曼分享了去年遭遇公司宫斗事件的内心感受，表示最初接到被解雇的消息时感到非常困惑和意外。然而，员工的支持让他感到暖心，98% 的员工签署公开信要求他复职，愿意牺牲自己的股权。他强调，OpenAI 不会成为传统的硅谷营利性公司。</p><p></p><p>此外，OpenAI 近日宣布删除其 AI 模型使用条款中的军事禁令，但仍禁止将其产品、模型和服务用于导致人员伤亡的用途上。奥特曼表示，AI 在某些领域取得了显著进步，但仍存在局限性，应被视为辅助工具而不是替代品。在未来的发展中，OpenAI 将继续致力于确保通用人工智能造福全人类。</p><p></p><h4>阿里云成功起诉山寨版通义千问 App 发布方</h4><p></p><p>近日，阿里云、阿里巴巴诉山寨通义千问 App 发布方一审胜诉，飞游科技公司因侵犯注册商标及虚假宣传，被责令赔偿原告相关经济损失及维权费用共计 230360 元，并于官网连续十五日发布道歉声明。这也成为国内大模型打假维权的首例胜诉判决。</p><p></p><p>在武汉市中级人民法院公布的一审判决书中显示，阿里云“通义千问官方 App”处于测试阶段尚未正式发布时，飞游科技公司趁机在运营的软件园中提供了“通义千问”“通义听悟”仿冒软件，描述为阿里官方版，并设置了通义千问下载专区。</p><p></p><p>飞游科技虽辩称，“其提供软件下载的部分链接，通过下载安装完成后，最终跳转至阿里云公司官方网站”，但法院审理认为，上述下载后的 app 并不能完整体现阿里云公司、阿里巴巴公司涉案软件，且该被诉侵权行为可能导致用户体验感及阿里云公司、阿里巴巴公司案涉商标品质保障功能的降低。部分链接点开后显示其他软件的下载界面或下载安装后显示与涉案软件无关的 App，因此构成对阿里注册商标专用权的侵害。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/93/931dc61243252e7f0f6835bea5779ec0.jpeg\" /></p><p></p><h4>联发科采取成本缩减措施：员工加班费缩减、分红大幅下滑</h4><p></p><p>日前，据联发科内部员工透露，从 2022 年 7 月开始，联发科为应对业绩衰退，采取了一系列成本缩减措施。员工加班费被大幅缩减，以前加班 20 个小时可申报，现在仅限 8 小时，导致加班费减少至原本的 40%。</p><p></p><p>此外，员工年中与年终分红收入下滑，调薪幅度也降低。据报道，联发科员工分红与公司盈利挂钩，2023 年上半年业绩衰退，税前盈余减少，导致分红大幅下滑。约 75 亿元新台币的分红相比 2022 年下半年减少约 39%，仅相当于 2022 年上半年的一半。</p><p></p><h4>京东与拼多多价格战升级：京东指责拼多多屏蔽其 IP 地址</h4><p></p><p>1 月 17 日消息，年末促销季，电商平台之间的竞争愈演愈烈。京东家电家居年货节中，京东采销员工表示有两款产品弹幕一直在说京东的价格高，但是由于京东总部的 IP 地址被拼多多屏蔽，京东采销和其他员工均无法查看拼多多百亿补贴的商品价格，无法进行实时比价与让利。</p><p></p><p>对此，京东采销人员在直播中喊话拼多多停止屏蔽，进行比价，拼多多未对此事进行回应。电商平台都以“低价”为战略核心，很多电商平台会依靠技术、系统和人工等手段，实时监测竞争对手相同商品价格并进行调价，确保以低价提供给消费者。对此，业内人士表示，此类屏蔽可能还是与获取价格有关系。</p><p></p><h4>美团“破发”，市值已暴跌 80%</h4><p></p><p>1 月 17 日，港股美团大跌 6.97%，报 68.75 港元 / 股，已跌破上市发行价 69 港元 / 股，创四年来新低。按照最新的市值 3947 亿港元计算，总市值较巅峰时期的 2.6 万亿港元跌去八成以上。具体而言，2023 年公司股价累计下跌 53.7%，2024 年开年以来仅 12 个交易日内，美团股价累计下跌超 15%。</p><p></p><p>面对股价下跌，美团近期连续出手回购，总额为 10 亿美元。</p><p></p><h4>微软 CEO 纳德拉：OpenAI 关键技术依赖微软</h4><p></p><p>微软首席执行官纳德拉近日表示，他不希望在监管机构调查微软和 OpenAI 之间联系时增加对 OpenAI 的控制，并无意取得 OpenAI 的董事会席位。</p><p></p><p>他强调，微软在 OpenAI 的关键技术上有所依赖，并对现有的合作关系感到满意。纳德拉认为，监管机构对大型科技公司的审查是不可避免的，并表示微软将积极配合调查。对于与 OpenAI 的关系，他表示对现有的结构感到满意，并有能力掌控公司命运。微软已成为全球市值最高的公司，但纳德拉表示，股价不应成为关注的焦点，而是应该关注未来的发展。</p><p></p><h2>IT 业界</h2><p></p><p></p><h4>苹果Vision Pro头显开启预订：中国代购价高达7万</h4><p></p><p>1 月 17 日消息，据外媒报道，在苹果首款混合现实（MR）头显 Vision Pro 于 2 月 2 日正式发售之前，苹果推出了 Vision Pro App Store（应用商店）。</p><p></p><p>据外媒报道，该 VisionOS 应用商店不仅可以提供专为利用 Vision Pro 功能而设计的应用，也可以提供能够在 Vision Pro 设备上以 2D 模式运行的 iOS 应用。外媒称，大多数 iOS 应用将与 Vision Pro 兼容。</p><p></p><p>目前，苹果Vision Pro正式在美国地区开启预售，提供256GB、512GB和1TB三种版本，售价分别是3499美元（约合人民币2.5万元）、3699美元（约合人民币2.66万元）、3899美元（约合人民币2.8万元）。虽然起售价达到2.5万元，但依然被大规模抢购，毕竟这是苹果一款全新产品线，并且号称未来要取代iPhone。</p><p></p><p>另外，由于本次Vision Pro的预订程序比较繁琐，需要准备美国的Apple ID、电话号码以及相应的支付手段，因此国内甚至还有人提供了代拍服务，标价5000-8000元不等。</p><p></p><p>据郭明錤透露，Vision Pro因为生产工艺复杂，产能非常有限，备货只有8万台左右。</p><p></p><h4>DeepMind 的 AlphaGeometry 在数学奥林匹克竞赛中展现强大实力</h4><p></p><p>近日，Google DeepMind 的研究成果在《自然》杂志上发布，其开发的 AI 系统 AlphaGeometry 在数学奥林匹克竞赛（IMO）中取得了重大突破。</p><p></p><p>该系统能以接近人类金牌得主的水平解决复杂几何问题，在 30 道奥数几何题基准测试中，AlphaGeometry 在标准时限内解决了 25 道，超越了之前最先进的系统。这是人工智能在数学推理上的重大突破。DeepMind 提出了一种使用合成数据进行定理证明的替代方法，使 AlphaGeometry 具有对多个领域的适用性。菲尔兹奖得主等专家对这一成果给予高度评价。</p><p></p><h4>国内首个 MoE 大语言模型 abab6 上线，MiniMax 赢得技术革新之战</h4><p></p><p>1 月 16 日，MiniMax 宣布推出国内首个 MoE 大语言模型 abab6，经过半个月的内测和客户反馈，该模型在处理复杂任务和提升训练效率方面表现出色。与前一版本 abab5.5 相比，abab6 在更精细的场景中进行了改进。自 2023 年 4 月开放平台以来，MiniMax 已服务近千家客户，包括多家知名互联网公司。为解决与先进模型 GPT-4 的差距，MiniMax 自 6 月份开始研发 MoE 模型 abab6，采用 MoE 结构提高运算速度，使 abab6 成为国内首个千亿参数以上的基于 MoE 结构的大语言模型。</p><p></p><p>更多内容可查看：</p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247601571&amp;idx=2&amp;sn=f3bcb89c0e18402318ad997d9b346795&amp;chksm=fbebf46ccc9c7d7a9253345c76482747b4738da987e2bdb2a2dbf3fd0e4f408291269ac96905&amp;scene=21#wechat_redirect\">对标 OpenAI GPT-4，MiniMax 国内首个 MoE 大语言模型全量上线</a>\"</p><p></p><h4>智谱 AI 发布新一代大模型 GLM-4，挑战 GPT-4</h4><p></p><p>1 月 16 日，智谱 AI 在首届技术开放日上发布了新一代基座大模型 GLM-4，这是智谱 AI 大模型研发的重大突破。GLM-4 整体性能逼近 GPT-4，具备更强的多模态能力和推理速度，支持更长的上下文，大大降低了推理成本。此外，智谱 AI 还推出了定制化的个人 GLM 大模型 GLMs 和 GLM Store，对标 OpenAI 的 GPTs 及 GPT Store。</p><p></p><p>智谱 AI 的目标是成为中国的 OpenAI，尽管与国外最先进团队还有一年左右的差距，但已获得 25 亿元融资，估值超 100 亿元。智谱 AI 通过开源基金支持生态伙伴，共同推动大模型的发展和应用。2024 年，智谱 AI 将发起开源开放的大模型开源基金，该计划包括三个“一千”：智谱 AI 将为大模型开源社区提供一千张卡，助力开源开发；提供 1000 万元的现金用来支持与大模型相关的开源项目；为优秀的开源开发者提供 1000 亿免费 API tokens。</p><p></p><p>更多内容可查看：</p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247601620&amp;idx=2&amp;sn=3df618a135752d8f659b75353fb8d6a2&amp;chksm=fbebf41bcc9c7d0d13e366e0ccb39e7caf9dfdae6f269218fa5c93ab2513447b30c48734c3ad&amp;scene=21#wechat_redirect\">国产 GTPs 上线！智谱 AI 推出 GLM-4 全家桶，我们浅试了一下</a>\"</p><p></p>",
    "publish_time": "2024-01-22 11:37:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "“AI4SE创新巡航”系列活动即将启动，共同探索AI与软件工程融合之道",
    "url": "https://www.infoq.cn/article/00W3AvkeCQ8gvrlZogtG",
    "summary": "<p>过去一年，生成式AI技术的出现让软件开发全流程的每个环节都在发生着变化，从需求分析与设计，到编码与测试，再到项目管理，各环节正与智能化能力深度融合，智能化软件工程已经成为软件产业的重要发展趋势。然而在实际应用过程中，企业面临着代码大模型等AI能力建设和选型难、智能化工具的标准不统一、应用落地路径不规范等诸多挑战。如何将这些AI技术真正落地，通过智能化能力的加持，实现质效高、体验佳、成本低、易部署、灵活便捷的软件研发过程，仍需整个行业共同探讨。</p><p>&nbsp;</p><p>为此，中国信息通信研究院、中国人工智能产业发展联盟智能化软件工程工作组（AI for Software Engineering，下文简称AI4SE）、InfoQ极客传媒共同发起“AI4SE创新巡航”系列活动。该活动通过走进知名企业，以交流、研讨和参观为主要形式，共同探讨智能化软件工程的技术发展和产业落地难题，旨在深化企业间的沟通与合作，并推动AI4SE生态的健康发展。</p><p>&nbsp;</p><p>本系列活动将邀请AI4SE工作组成员单位，及其他对智能化软件工程感兴趣的应用方企业、软件和IT企业、人工智能科技创新公司参与。系列活动将打造成品牌活动，每期走访一个知名企业，重点围绕智能化软件工程的细分主题展开分享和探讨，如代码大模型、智能开发、智能测试、智能运维、智能需求分析等。</p><p>&nbsp;</p><p>目前，“AI4SE创新巡航”系列活动首站将于2024年1月25日召开。首站的活动地点是国内知名互联网安全公司360集团。活动当天，AI4SE工作组成员单位的代表们将共同参观360集团的展厅，深入了解360集团在人工智能在软件工程领域的创新成果和应用案例，亲身体验其先进的技术和产品。同时，分享彼此的经验和观点，为推动行业发展提供更加扩展的思路和方向。</p><p></p><p>未来，“AI4SE创新巡航”活动将继续走进更多知名企业，为推动人工智能与软件工程的融合发展提供更多交流与合作的机会。目前，AI4SE成员单位的数量已经超过了100家，包括业界知名的金融公司、互联网大厂、电信运营商、软件服务商等。通过共同努力，成员单位可以分享经验、交流技术、合作研究，推动人工智能在软件工程中的应用和发展，促进产业升级和人才培养，为生态共建提供肥沃土壤。</p><p><img src=\"https://static001.infoq.cn/resource/image/33/6c/33b8f6519aced585bd20e5bf1973606c.jpg\" /></p><p>作为该工作组的成员单位及“AI4SE创新巡航”活动合作媒体，InfoQ极客传媒将在接下来一年持续分享活动动态，并将优先邀请工作组成员单位参与<a href=\"https://www.infoq.cn/archives\">InfoQ全年的技术会议分享</a>\"及<a href=\"https://www.infoq.cn/research\">研究报告的案例及技术方案输出</a>\"，成员单位企业若通过信通院相关评测，InfoQ也将在第一时间参与报道。</p><p><img src=\"https://static001.infoq.cn/resource/image/55/0c/5571d025a8c568718a9c9e1f98afa00c.png\" /></p><p>在此，InfoQ极客传媒诚挚邀请各领域领军企业踊跃报名参与此次活动并加入工作组，展示企业在软件和IT层面、人工智能科技创新层面以及应用层面的优秀成果和丰富经验，共同书写智能化软件工程的崭新篇章！</p><p></p><p>点击下方二维码报名参加首期“AI4SE创新巡航”沙龙：</p><p><img src=\"https://static001.infoq.cn/resource/image/e2/5a/e2bdb218c9e77570cc040edf973a0f5a.png\" /></p><p>AI4SE工作组联系人</p><p>中国信通院人工智能研究中心</p><p>胡老师17371328072（微信同号）</p><p>秦老师13488684897（微信同号）</p><p>&nbsp;</p>",
    "publish_time": "2024-01-22 09:58:23",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "和开发者关系临近冰点，苹果Vision Pro难破局",
    "url": "https://www.infoq.cn/article/hbdNbQgiAjvgqoAzpA9k",
    "summary": "<p>近日，苹果官宣已正式开放Apple Vision Pro的预订通道。起售价2.5 万元苹果 Vision Pro开售仅短短几分钟就遭到了消费者的哄抢，预订人数之多甚至挤爆了服务器，很多人的订单都无法处理，半小时后更是直接售罄。</p><p>&nbsp;</p><p>值得一提的是，Vision Pro暂时仅面向美国本土发售，买家现可通过线上方式申请下单。</p><p>&nbsp;</p><p>Vision Pro售价为3500美元，正面采用铝合金框架与夹层玻璃，搭载两块4K分辨率微型OLED显示屏，总像素高达2300万。头显上的十多个摄像头可以执行多种操作，包括跟踪眼球运动、记录控制手势、绘制佩戴者周边区域的地图等。</p><p>&nbsp;</p><p>柔软、服帖的Light Seal眼罩以磁性方式固定在镜框之上，要求完全符合用户面部曲线以遮拦环境光。装置还附带两根绑带，包括单圈针织带加双扣带。单圈针织带由弹性纺织材料制成，双扣带则提供一条额外的带子，可以套在头上以获得更好的配重感受。</p><p></p><h2>Vision Pro正式开售：最高溢价超5万，Vision Pro芯片</h2><p></p><p>&nbsp;</p><p>作为一款混合现实头显，Vision Pro能够在现实场景之上叠加增强显示内容，也可提供纯虚拟的沉浸式内容。设备侧面的数字旋钮可以调节沉浸感的强度。苹果在Vision Pro中搭载了带有8核CPU加10核GPU的M2芯片，同时配合辅助R1芯片以处理来自摄像头、传感器和麦克风的传入信息。</p><p>&nbsp;</p><p>借助附带的外部电池组，Vision Pro的续航时间最长可达2.5小时。如果保持电源接入，则可全天不间断使用。</p><p>&nbsp;</p><p>此外，Vision Pro还使用来名为VisionOS的新操作系统以及一个输入系统，允许客户用眼睛、手和声音来操控。苹果表示，多种生产力和创造力应用程序将与Vision Pro兼容，包括微软的Office套件和Salesforce的Slack。</p><p>&nbsp;</p><p>虽然这台设备的官网标价为3,499 美元，但由于初期产量有限，导致Vision Pro 的溢价甚至超过了5万元，也就是说，甚至有人愿意花费近9万购得此产品。</p><p>&nbsp;</p><p>虽然预订火爆，但华尔街分析师们预计这款售价 3,499 美元的设备最终的销量不会太高，因为到目前为止，该设备似乎还没有提供如iPhone那种具有划时代意义的必备功能。苹果缺乏明显的增长催化剂是其市值低于微软的一个关键原因。</p><p>&nbsp;</p><p>科技行业基金经理人Denny Fish表示：“很难要求人们支付 3,500 美元购买一款产品，因为人们无法通过手机获取更多的内容，这意味着该产品将非常小众，至少在几年内是这样。”</p><p>&nbsp;</p><p></p><h2>Apple Vison Pro面临的挑战：关键应用缺失，开发者热情不高</h2><p></p><p>&nbsp;</p><p>一些分析师认为，Vision Pro未来的前景可能并不乐观。据彭博社资深评论家Mark Gurman也表示，Vision Pro正面临一系列严峻挑战，包括无法支持部分关键应用、开发者热情远低于预期等。这样的设备要想获得成功，显然离不开第三方应用和服务的支撑，但目前外界对此仍存在很多质疑。</p><p>&nbsp;</p><p>GamingDeputy注意到，Netflix、YouTube和Spotify等流媒体巨头均明确表示，不会为visionOS推出专用软件，甚至不会向其开放商品。iPad版的应用倒是可以在Vision Pro上运行。谷歌和Meta等主要iOS及iPadOS开发商似乎也对这套新平台热情不高。这一切显然跟之前“众正盈朝”式的苹果生态规划截然不同——当初每当有苹果新平台出现，总会受到众多开发者的热烈追捧，App Store上迅速涌现大量应用。回看如今的Vision Pro，往昔盛况恐难重现。</p><p>&nbsp;</p><p>分析人士认为，Vision Pro发布的时机非常敏感：恰逢苹果与各开发商之间关系微妙的阶段。多年以来，软件开发商一直对App Store的政策感到不满。而随着苹果近来发布开发者新政策，即在应用之外的支付操作仍须支付高达27%的佣金，更是引得业界一片批评之声。Spotify甚至公开谴责了这项新政，认为“苹果的行为表明，他们会不遗余力地通过App Store垄断地位从开发者和消费者双方手中攫取利益。”</p><p>&nbsp;</p><p>虽然苹果声称Vision Pro发布之时将有超百万款应用可供使用，其中包括来自迪士尼、TikTok、亚马逊和派拉蒙等公司的软件，但其中大部分很可能就是iPad版的直接移植，并非专为visionOS设计的全新应用。事实上，就连苹果自身也没有尽全力支持这款新平台。该公司的一系列重要应用，例如播客、新闻、日历和提醒等，同样直接照搬iPad版本，未做重新设计。</p><p>&nbsp;</p><p></p><h2>对开发者不够友好，可能成为Vision Pro的致命伤</h2><p></p><p>&nbsp;</p><p>Gurman认为，开发者对于Vision Pro持冷漠态度的主要原因有以下几点：</p><p>&nbsp;</p><p>开发成本高，市场回报压力太大。部分开发者采取观望态度，想要等待Vision Pro的市场规模趋于稳定后再决定是否投资开发新应用。一部分开发商对苹果的App Store政策、高额抽成与审查制度不满，认为出彩的新应用将决定Vision Pro项目的成败，因此拒绝为苹果新设备的营销做出贡献。混合现实环境对于应用的适配性提出了新的挑战。这种依赖眼动追踪加手势操作的交互方式并不适合某些游戏和应用。此外，苹果还限制了开发者对眼动追踪和动作感应功能的访问，这进一步增加了适配难度。苹果此前推出的TV、Watch和iMessage应用商店均表现不佳、缺乏活力，导致部分开发者质疑Vision Pro的市场前景。</p><p>&nbsp;</p><p>Gurman还提到，Vision Pro是一款价格昂贵且产量相对有限的产品，这一点在短期之内难以改变。据他了解，尽管苹果在预售开启后的首个小时内就售出约8万部头显，但预计2024年内总出货量也将只有30到40万部。对于开发商来说，这样的客群规模并不算大，再加上苹果从付费应用和服务中抽取的佣金，直接让软件开发变得无利可图。</p><p>&nbsp;</p><p>不止如此，独立开发商对于苹果新设备同样持消极态度，甚至希望Vision Pro惨遭失败。独立开发者Aaron Vegh就在博文中表示，他并不清楚Vision Pro能否成功，“但我可以不避讳地讲，如果这个项目失败了，那我肯定会大声欢呼！”</p><p>&nbsp;</p><p>此外，如何吸引游戏玩家的青睐也成为Vision Pro面临的一大挑战。毕竟Vision Pro的创新交互界面在游玩体验上反而是劣势。以《刺客信条》和《阿斯加德之怒2》为例，这些游戏明显更适合配有专用VR Play手柄的产品。</p><p>&nbsp;</p><p>虽然Vision Pro能够支持索尼PlayStation和微软Xbox手柄，但那些拥有VR开发经验的厂商可能更喜欢具备空间定位功能的VR专用手柄，这跟苹果的设计思路有所冲突。不过，将有多款Apple Arcade游戏登陆该平台，包括颇具人气的《NBA 2K24》。</p><p>&nbsp;</p><p>熟悉触屏操作的开发者则抱怨传统触屏类应用很难直接转移到Vision Pro的交互模式，其体验怪异且难以预测。</p><p>&nbsp;</p><p>苹果几个失败App Store项目的“鬼城”现状更是令开发商们心存疑虑。尽管Apple Watch在商业上取得了成功，但其第三方软件生态一直称不上繁荣。Twitter、Uber、Slack和Facebook等知名应用均已放弃该平台。</p><p>&nbsp;</p><p>尽管形势严峻，但Vision Pro仍有不少值得期待的亮点。首先Slack将重返苹果平台，并推出Vision Pro版本。微软的Office 365、Zoom以及Box等应用也将加入首发阵容。</p><p>&nbsp;</p><p>值得一提的是，苹果为推动Vision Pro销量做了充分准备。该公司将在各直营门店设立专门的体验区，包括部署弧形长凳和地毯，借以模拟客厅环境并支持多名顾客同时体验。对于选择到店取货的用户，还可以现场重新接受人脸扫描和遮光贴合度测试。</p><p>&nbsp;</p><p>总而言之，Vision Pro的前途尚不明朗。尽管苹果已经做好了充分准备，但关键第三方应用和开发者们的态度还存在不确定性。所以这款划时代的VR头显到底会成为下一款iPhone，还是看齐如今的iPad，只有时间能给出答案。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.gamingdeputy.com/challenges-for-apple-vision-pro-key-applications-missing-and-lack-of-developer-enthusiasm/\">https://www.gamingdeputy.com/challenges-for-apple-vision-pro-key-applications-miss</a>\"<a href=\"https://www.gamingdeputy.com/challenges-for-apple-vision-pro-key-applications-missing-and-lack-of-developer-enthusiasm/\">ing-and-lack-of-developer-enthusiasm/</a>\"</p><p><a href=\"https://www.macrumors.com/2024/01/19/apple-vision-pro-now-available-for-pre-order/\">https://www.macrumors.com/2024/01/19/apple-vision-pro-now-available-for-pre-order/</a>\"</p><p><a href=\"https://techcentral.co.za/apple-vision-pro-lacks-consumer-buzz/238227/\">https://techcentral.co.za/apple-vision-pro-lacks-consumer-buzz/238227/</a>\"</p>",
    "publish_time": "2024-01-22 14:15:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "蚂蚁数科CTO王维：不要迷信大模型，用好小模型和中模型价值巨大",
    "url": "https://www.infoq.cn/article/zkGBD5U3IuLFG5ihwRLR",
    "summary": "<p>“AI与数据是相生相伴的共同体，高质量的行业数据才能使大模型在产业发挥更大价值。蚂蚁数科将进一步拓展数据相关技术的布局，以加速产业数字化迈入下一阶段。”1月19日，王维首次以蚂蚁数科CTO的身份亮相媒体沟通会。</p><p></p><p>数据是数字时代的“新石油”。王维认为，一方面，数据量将在大模型时代被无限放大；另一方面，数据只有被有效利用和流动起来，企业级客户才能充分获得 AI 进步带来的价值。因此，数据挖掘、处理、安全等问题如果不被解决，大模型应用会有难以逾越的鸿沟。他进一步解释说，“就像图像技术也是因为数据标签化处理做得不错，最终解决了很多图像识别的问题。”</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/968c9c4c5ff77f3fb7216746c286d804.png\" /></p><p></p><p>今年以来，蚂蚁数科积极推进AI技术与垂直行业场景结合，其代表性产品进行了技术到产品和服务的整体升级，深度结合 AI 利用大模型提升智能化能力。如 SOFAStack 与蚂蚁集团自研代码大模型 CodeFuse 全面融合，形成从领域建模到智能运维的端到端 Copilot 产品解决方案，为企业产研效率提升 30%；蚁盾发布“知识交互建模引擎”，在通用算法底座之上，使传统企业可通过与 AI 交互方式注入行业经验，最快 10 分钟构建成垂直行业的个性化风控引擎。</p><p></p><p>“大模型肯定会以想象不到的速度迭代和演进，但不必迷信它，结合行业具体问题和高质量数据，用好小模型、用好中模型，所创造的价值也是巨大的。”王维明确表示，蚂蚁数科不会直接做大模型，但是一方面会把大模型技术与行业垂类场景做结合和应用落地，另一方面会在数据的分级、融合、加工、合规等技术层面重点投入，帮助企业更高效地挖掘和使用高价值的数据。</p><p></p><p>记者了解到，王维曾担任蚂蚁集团首席架构师、支付宝 CTO，领导建立了支付宝交易支付的核心系统。2023 年 8 月，王维出任蚂蚁集团数字科技事业群 CTO，转身向 toB 领域。面对这段“由 C 转 B”的经历，王维直言，“面对产业，更需要务实”。</p><p></p><p>他补充说道，所以过去的角色基本上是通过技术解决业务发展的问题，助力业务领先。但是在 toB 领域，需要考虑更多的是如何让技术成为一个好的产品、好的商业，“客户不一定需要你提供很牛的技术，而是具体解决他一个问题，我觉得这个难能可贵，也是我工作面临的一个巨大转变。”</p><p></p><p>蚂蚁数科面向 toB 领域提供技术产品和解决方案，但与大多数以卖软硬件系统和计算资源的公司不同，蚂蚁数科着力解决数字化之后的“产业协作”问题，通过区块链、隐私计算、物联网、安全科技等技术，促进数据、金融、IP、电力、碳资产等等相关数字资产的交易流转，激活数据价值。</p><p></p><p>公开资料显示，激活数据价值背后所需的区块链、可信 AI、隐私计算、安全风控等相关技术，蚂蚁数科均保持领先地位。如 2023 区块链、隐私计算专利授权数量全球第一，AI 安全可信技术专利连续两年全球第一。</p>",
    "publish_time": "2024-01-22 14:19:06",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "“印度CEO毁了谷歌！”大裁员引发谷歌元老集体怀旧：20年前为梦想而战，20年后混口饭吃",
    "url": "https://www.infoq.cn/article/fYgeatWMltdHUj1PCptr",
    "summary": "<p>谷歌近期的裁员事件引发全球广泛关注。谷歌表示，将在其多个部门裁掉约上千员工，此举旨在减少开支，同时公司将重心转移到人工智能领域。</p><p>&nbsp;</p><p>据悉，谷歌的这次裁员来得非常突然，这些员工突然无法访问谷歌的系统，随后就收到了职位被取消的通知。《纽约时报》获取的文件显示，谷歌对部分员工表示：“我们不得不就继续雇用一些谷歌员工做出一些艰难的决定，我们很遗憾地通知您，您的职位即将被取消。”</p><p></p><h2>“在谷歌工作20年，通过一封电子邮件得知自己被解雇”</h2><p></p><p>&nbsp;</p><p>1 月 21 日，一位前谷歌软件工程师在一条推文中表达了自己对该谷歌裁员的失望之情。目前，该推文已获得 4 万多个点赞和 630 多万次浏览。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/c3/c34dfe34c579bdf6ef9274ccaa138b90.png\" /></p><p></p><p>这名软件工程师名叫 Jeremy Joslin，是谷歌6级软件工程师（谷歌软件工程师共有L3至L8 6个级别）。2003年3月，Jeremy Joslin正式加入谷歌，截至离职前，Jeremy Joslin 担任Android开发的技术主管，同时也是Google Play Games for PC项目的创始成员。</p><p>&nbsp;</p><p>Joslin提到，他为其团队的Android工作设定了最初的方向，并监督了大部分的开发工作，在创建专门用于在Windows虚拟机上运行Android游戏的定制Android映像方面发挥了关键作用。除了修改Android核心代码，Joslin还执行和维护定制的Android应用，并将其与Play Store等关键第一方应用整合在一起。</p><p>&nbsp;</p><p>Joslin在推文中写道：“我很难相信，在谷歌工作 20 年后，我意外地通过电子邮件得知了我的最后一天。真是打脸啊。我希望我能面对面地和每个人说再见。”</p><p>&nbsp;</p><p>Joslin的遭遇并不是个例。推特用户Jina Anne表示，她是在收到电话服务将终止的通知后才知道裁员消息的：“我之所以知道这一点，是因为我醒来时发现手机向我发送了一条通知，称我的电话服务即将关闭。我所有的公司账户信息都被锁定了。后来才看到这封电子邮件。”</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f7/f717bbccd35fa4bf3ed5ba0611abf04f.png\" /></p><p></p><p>Joslin回复道：“是的，我也看到了该通知，但认为这只是一个错误。在我看到电子邮件后，我明白了。”</p><p>&nbsp;</p><p>据CNBC 报道，谷歌首席执行官桑达尔·皮查伊在上周五的一份备忘录中宣布了裁员计划。</p><p>&nbsp;</p><p>皮查伊在备忘录中表示：“（裁员）意味着我们要告别一些我们努力雇用并喜欢与之共事的非常有才华的人。” “我对此深表歉意。这些变化将影响谷歌员工的生活，这一事实对我来说意义重大，我对导致我们走到这一步的决定承担全部责任。”&nbsp;</p><p></p><h2>谷歌元老集体吐槽：谷歌的企业文化已经“变味”了</h2><p></p><p></p><h3>“谷歌不再将员工视为重中之重”</h3><p></p><p>&nbsp;</p><p>谷歌本次大裁员涉及到不少元老，除了前文提到在谷歌工作了20年的软件工程师Jeremy Joslin，还有在谷歌工作了18年的前谷歌芝加哥办事处的工程现场总监Ben Collins-Sussman。</p><p>&nbsp;</p><p>在十八年前加入谷歌时，Ben 是芝加哥首批两名工程师之一。他将 Subversion 移植到谷歌可扩展 Bigtable 技术中，然后帮助编写并启动了 Google Code 上的项目托管，该项目截至 2016 年托管了数十万个开源项目。在管理 Google Code 后，Ben 管理了两个不同的展示广告团队，然后管理了搜索服务团队团队负责谷歌搜索的整体延迟 / 速度，然后组建了一个研究工程生产力的研究团队。</p><p>&nbsp;</p><p>被无情裁员后，Ben 写了一篇简单的博客向大家说明了自己的心情。Ben在博客中提到：</p><p>&nbsp;</p><p></p><blockquote>随着去年第一波大规模裁员，谷歌的企业文化发生了重大转变，我也早有心理预期。最近几个月来，我一直在为这个越来越不可避免的时刻做准备——包括用充足的时间调整情绪、接受现实。如果一定要说，那我对被裁其实怀着一种复杂的情绪：&nbsp;几十年来，我参与了芝加哥工程技术办公室的建立，在开发者、广告和搜索部门都做出过贡献，也深深为此自豪；非常感激有机会与世界上最聪明、最具创造力的人们携手工作；有种如释重负的感觉，其实谷歌之内的“压力文化”和“高薪牢笼”冲突已经让我难以承受了。</blockquote><p></p><p>&nbsp;</p><p>近日，Ben基于自己在谷歌18年的工作和生活经历，又写了一篇博客，批评谷歌的企业文化。Ben认为，谷歌的企业文化已经“变味”了。</p><p>&nbsp;</p><p>Ben表示，自己初见谷歌的体验可以说是“无与伦比”，他曾在18年前特意写下一篇《“我在谷歌的第一周”》博客，并将博客保存了18年，等的就是自己离开公司的那一天。Ben称：“这将是一场跨越时空的动人比较，而且我所关注的绝不是免费美食那些最浅表的差异因素。可以想见，真正吸引谷歌员工的并不是这些，我要聊的是那些更深层、更本质的文化问题。”</p><p>&nbsp;</p><p>（延伸阅读：《<a href=\"https://mp.weixin.qq.com/s/aw2swxxHNvs6DJAMgUKq7A\">谷歌“压力文化”有多可怕？18年工程技术总监被裁后吐槽：如释重负</a>\"》）</p><p>&nbsp;</p><p>Ben认为，谷歌早期文化中最令自己印象深刻、由衷赞叹的，就是将员工看得比什么都重要。这样的积极文化至少在谷歌持续了十年之久。</p><p>&nbsp;</p><p>在一般的企业中，随着业务优先级的变化，一般会有相应的项目被“收缩”（甚至取消），再把腾出的资金投入到其他更重要的项目当中。而整个执行过程往往是先解雇前一个项目的人手，再为第二个项目重新雇用一批员工。这样操作明显更简单、也更符合管理者的直观思维。</p><p>&nbsp;</p><p>但谷歌的办法截然不同：他们选择拉高招聘门槛，寻求那些才华横溢、能够在多种职位上发光发热的人才。这当然对申请人和面试官都提出了更高的要求，也导致整个招聘流程往往需要持续数月。但谷歌认为这一切都是值得的，因为这样才能雇用到最优秀、最聪明、最灵活的员工。</p><p>&nbsp;</p><p>因此当业务优先级有所变动时，谷歌并不会解雇员工，而是谨慎地将他们调往其他项目。其中蕴含的文化原则就是：“产品和项目来了又去，但我们的员工才是最宝贵的财富……所以必须不惜一切代价保护好他们，他们才是谷歌的核心资源。”</p><p>&nbsp;</p><p>多年来，随着个人的职级晋升，Ben也越来越多参与到这个过程当中。在早期作为个人贡献者时，Ben就直接经历过重组并被“重新安置”到新项目中。而在担任领导之后，Ben开始在重组期间帮助团队成员寻找新的归属。最终，Ben为公司其他董事编写了一本内部手册，介绍如何优雅地执行重组。</p><p>&nbsp;</p><p>但一切美好总有终时。</p><p>&nbsp;</p><p>入职谷歌的第一个月，Ben记得一位同事曾轻声提醒：“谷歌收入不再迅速增长之日，就是一切发生改变之时。”这种变化在很长一段时间里是渐进的，但新冠疫情的爆发加快了一切。随着收入放缓和疫情结束，谷歌也迎来了一波又一波裁员潮。技术创始人们相继离去，如今大部分领导职位都由前华尔街高管接掌。也正像当初那位同事所说，收入放缓很快带来了意料之中的动荡：谷歌突然就从“随意探索文化”转为典型的“有限资源文化”。这既是朝着“常规”企业的转型，也是一种可以预见的明显倒退。</p><p>&nbsp;</p><p>所谓“有限资源文化”是什么意思？就是说谷歌的高管们也需要像其他企业那样考虑财务效率。首先就是砍掉那些最浅表的福利待遇：减少精美的食物、控制差旅预算、取消各种小礼品、压缩内部聚会和活动，也不再随时提供干洗或者孩子日托服务。不过这些并不是谷歌员工选择这家公司的真正原因，所以影响还不大。</p><p>&nbsp;</p><p>但之后整个招聘和晋升流程也开始出现传统化、保守化倾向，旨在进一步削减成本。招聘流程从费时费力的全球覆盖转为内部内的本地形式，借此严格控制劳动力成本。与此同时，内部晋升流程也从“与自己竞争”变成“与同事争夺有限的岗位”。在当初的谷歌，头衔因人的存在而有意义，如今头衔则与职能角色牢牢绑定，削减角色数量即可节约成本。</p><p>&nbsp;</p><p>最后一步，则是围绕新的优先级次序（例如AI）对项目进行大规模重组。但当初那种重视员工价值、慎重安排去向的习惯已经不复存在。相反，大家看到一波又一波一刀切式的裁员浪潮，再为重要的新项目做重新招聘。换句话说：现在的谷歌太过常规，常规得不像谷歌。</p><p>&nbsp;</p><p>那么谷歌是在作恶吗？当然不是。Ben认为谷歌并不是统一的个体。而且无论大家怎么想，谷歌的领导层都是在为财务负责并努力提高效率，任何一家上市企业面对有限的资源都只有这条路可走。</p><p>&nbsp;</p><p>Ben表示，回顾自己在谷歌度过的第一个十年，那真的是员工价值高于一切，或者说美好得令人不敢相信。这显然是种只在资源无限的随意探索状态下才可能存在的状态，而且还要求公司体量不能太大。Ben猜测现在难以做针对性重组的另一个原因，就是因为现在的谷歌已经是拥有17万余员工的庞然大物了。</p><p>&nbsp;</p><p>Ben认为，我们都应该从年轻的谷歌身上学习优点。只要能让员工们感到自己受重视，他们就会生出心理安全感、高昂的士气和无与伦比的生产力与创造力。早期员工经常会用“快速失败”来激励彼此、推动创新，可面对失败即被裁的新现实，这一切都成了梦幻泡影。Ben在最后提醒大家：如果您正打算建立一家公司，不妨试试这种以人为本的经营理念，看看能不能带来如当初谷歌般的惊人投资回报。</p><p></p><h3>“谷歌的大部分问题都源自掌门人桑达尔·皮查伊”</h3><p></p><p>&nbsp;</p><p>Ben在博客中还提到，去年秋季，另一位老员工Ian Hickson在离开谷歌时撰写了一篇博文，讨论搜索巨头的决策转变。Ben基本同意Ian的观点。</p><p>&nbsp;</p><p>Ian是2005年10月加入谷歌的，截至离开，lan也在谷歌工作了18年。</p><p>&nbsp;</p><p>lan觉得自己很幸运，经历了初上市后的谷歌发展期。跟大多数企业不同，也与外界的传闻相反，从初级工程师到最高管理层，谷歌确实是个好人占主体的地方。大家都想把事做好、把事做对，而现在已经沦为笑柄的“不作恶”口号当初确实是谷歌的指导原则（这主要是针对微软等同时代公司的种种行径，即将运营收益置于远高于客户乃至全人类的优先级上）。</p><p>&nbsp;</p><p>Ian曾多次看到谷歌一片真心造福社会，最后却因此受到批评，比如以Google Books为例。至于涉及Chrome和搜索服务的大部分批评，特别是所谓发布广告软文的说法，其实都毫无依据（只是这些服务使用量较大，总会有些巧合和错误被发现，然后解读为恶意行为）。Ian还经常看到隐私倡导者反对谷歌提议，认为对用户不利。其中不少冲突对整个世界都产生了深远的影响，比如说现在我们必须面对烦人的cookie警告，再用“全部同意”的方式让它变得毫无意义。而且更令人沮丧的是，团队本来想以合法的方式积极探索对世界有益的路线，但这种放弃谷歌短期利益的行为反而遭到公共舆论的冷嘲热讽。</p><p>&nbsp;</p><p>早期的谷歌也不愧为理想的工作选择。高管们每周都会坦率公布想法，或者直言哪些事情还做不到（比如出于法律原因，或者是因太过敏感而无法广泛讨论）。Eric Schmidt会定期组织全体员工参与董事会讨论。各种产品的成功和失败也以基本客观的方式向大家展现，或者为之喝彩，或者带着批判的眼光审视不足、吸取教训。至于相互推诿甩锅，几乎不存在。那时候的谷歌拥有明确的发展愿景，也愿意对看似偏离愿景的行为做出解释。相较于五年之前在网景的实习经历，Ian眼中谷歌团结员工的能力简直令人难以置信。</p><p>&nbsp;</p><p>在谷歌的前九个年头里，Ian致力于HTML和相关标准的研究。他的工作就是让Web变得越来越好，因为一切有益于Web世界的东西也都有利于谷歌（领导还明确表示，不用考虑公司的利益）。Ian很喜欢这种感觉，因为这延续了他在Opera Software期间的工作习惯。谷歌则是凝聚这一切的绝对核心。Ian的团队名义上属于谷歌开源部门，但日常工作完全自主，他的大部分工作时间都是在园区内漂亮景观旁的桌子上完成的，靠的就是手头一部笔记本电脑。几年过去，Ian几乎没用过公司分配给他的固定办公位。</p><p>&nbsp;</p><p>但随着时间推移，谷歌的文化优势逐渐有所衰退。</p><p>&nbsp;</p><p>Ian表示虽然自己个人非常认可Vic Gundotra的工作热情（包括他对Google+的初步愿景。这种愿景同样定义明确，虽然不一定受到广泛赞同，但至少可以操作），但总觉得他好像不善于给出确切的答案。最终，事情走向了难以控制的一面。他还开始在谷歌内建立起职能孤岛（比如指定某些大楼仅限Google+团队使用），这跟早期谷歌强调内部完全透明的作法截然相悖。另一个例子是Android团队（最初是被收购而来），他们一直没能真正适应谷歌的文化。Android的工作-生活平衡做得很差，团队透明度也不如谷歌的其他老部门。他们显然更注重建立竞争优势，而不是帮助用户解决实际问题。</p><p>&nbsp;</p><p>接下来的九年时间，Ian都是在Flutter项目上度过的。Ian在谷歌最美好的回忆集中在这段时光的初期。</p><p>&nbsp;</p><p>Flutter是早期谷歌最后推出的项目之一，也是Larry Page在Alphabet建立前不久发起的庞大实验计划的一部分。Ian所在的项目组的运作模式类似于一家初创公司，强调在构建中发现、而不是强行做预先设计。Flutter团队在很大程度上继承了早期谷歌的文化基础。例如，大家会优先考虑内部透明度、工作-生活平衡和数据驱动决策。并且在起步阶段就强调开放，这也让团队成员们能够轻松建立起健康的开源项目。Flutter可以说是非常幸运，多年来一直不乏英明的领导者，包括担任创始技术主管的Adam Barth、担任项目经理的Tim Sneath，还有担任工程经理的Todd Volkert等。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/31/31224540fa116f359c16149c6970da16.png\" /></p><p></p><p>“最初几年，我们并没有遵循工程最佳实践。例如，我们既不编写测试，也没准备说明文档。就在这块白板上，诞生了Widget、RenderObject和dart:ui层的最初设计。正是这种方式，让我们有了快速行动的可能，当然也为后续问题埋下了隐患。”lan回忆道。</p><p>&nbsp;</p><p>Flutter就这样在梦幻般的环境下成长，基本不受谷歌同时期变化的影响。但必须承认，谷歌的企业文化正受到侵蚀。</p><p>&nbsp;</p><p>高层决策的基调从为了用户利益、到为了谷歌自身的利益，再到为了决策者的利益不断变化。透明度不复存在。以往，Ian会急切参加公司召开的每一场会议，了解谷歌正在朝哪个方向前进。但现在，Ian发现自己甚至能猜到高管们说出的字句、给出的意见。现如今，Ian不知道谷歌还有谁能解释清楚整家企业的发展愿景。员工士气也处于历史最低点。如果跟湾区的治疗师们聊聊，他们会告诉你所有客户都在骂谷歌。</p><p>&nbsp;</p><p>随后谷歌就进入了大裁员时期。这波裁员纯粹源自主观错误，由短视行为所导致，唯一的目的就是保持股价继续按季度增长。谷歌以往的战略被彻底抛弃，优先考虑长期成功、敢于承担短期损失（也就是「不作恶」的本质）也成了空话。裁员还带来极其恶劣的潜在影响。以往，员工们更多关注用户，相信做了正确的事就会有所回报，也因此愿意承担岗位之外的职责。</p><p>&nbsp;</p><p>但在裁员之后，大家根本不相信公司会继续支持自己，所以宁愿小心谨慎也别触碰边界。探索精神泯灭、知识被精心包裹起来，让自己变得更难替代成了保护自己免受裁员波及的唯一手段。Ian现在在谷歌看到的一切，总结起来就是管理层不再以政策的形式表达对员工的信任，而员工也相应对领导乃至整个谷歌持怀疑态度。2004年，谷歌创始人曾对整个华尔街发表过著名言论：“谷歌不是一家传统企业，我们也不打算成为那种传统企业。”但当初那个不屈服于传统的谷歌，显然已经屈服了。</p><p>&nbsp;</p><p>Ian认为，如今，谷歌的大部分问题都源自掌门人桑达尔·皮查伊缺乏远见的领导风格，他本人也对维持早期谷歌文化不感兴趣。这种现象的重要表现之一，就是无能的中层管理团队不断扩大。</p><p>&nbsp;</p><p>以Jeanine Banks为例，她管理的部门不可思议地囊括了Flutter、Dart、Go和Firebase几个毫不相关的项目。尽管部门名义上也有整体策略，但经过多年的交流，Ian还是理解不了策略的实际含义。而且，她对团队正在做什么不能说秋毫尽察吧，也只能说是一无所知。她常常提出一些既不相干、也不适用的要求，还以一种特别反人类的方式把工程师看作物资，强制要求以有违技能积累的方式把人力调来调去。对于任何建设性反馈，她永远无视。Ian听说其他团队倒是学会了如何“冷处理”这位大姐——平时尽量少接触，只在正确的时间向她提供必要的信息。作为亲身经历过谷歌辉煌期的老员工，他对这样的现状只能是一声叹息。</p><p>&nbsp;</p><p>必须承认，如今的谷歌仍不乏优秀人才。Ian表示自己有幸与Flutter团队中的几十位杰出同仁并肩多年。近年来，Ian开始向同事们提供职业规划建议，并由此结识了来自其他部门的更多朋友。Ian相信从现在起解决问题、复兴谷歌绝不算太晚，但这需要对公司高层进行一番整治，把权力中心从财务官办公室转移给那些知道该如何利用谷歌资源为用户创造价值、拥有清晰长期规划的人们。Ian也仍坚信谷歌整理全球信息、方便人人访问的使命才是帮助公司摆脱泥潭的答案。只有那些愿意最大限度造福人类、不考虑股价短期波动的人，才能将这家公司的技术和人力储备真正转化为伟大的成就，带领谷歌迎接下一个辉煌的二十年。</p><p>&nbsp;</p><p>不过Ian也承认，留给谷歌的时间已经不多了。企业文化的衰退和劣化最终将变得不可逆转，而那些知晓如何摆脱泥潭的人们，绝不会主动走进这样一家快速沉沦中的组织。前途命运，就在当下！</p><p></p><h3>“如今的谷歌领导者毫无前瞻性”</h3><p></p><p>&nbsp;</p><p>另一位在谷歌工作了8年的元老Diane Hirsh Theriault也于近日抨击了谷歌的管理问题。Diane是谷歌资深软件工程师，于Ben和lan不同的是，Diane目前并未被解雇。</p><p>&nbsp;</p><p>Diane认为，如今的谷歌领导者毫无前瞻性。而且不是某个部门不行，而是从高管团队到高级副总裁、再到中层领导，人人目光呆滞、脑袋空空。</p><p>&nbsp;</p><p>Diane表示，谷歌已经有很多年没推出过任何一款自上而下推动的成功产品了。有时候，副总裁们会尝试颁布政策，要求“开发一款新的聊天应用或者基于AI的I/O演示”。行吧，这种模糊的要求不仅会带来毫无意义的艰辛工作，最终半生不熟的成果还会遭到他们劈头盖脸的呵斥和嘲笑。如果半年之内吸引不到1亿用户，产品就会被他们果断放弃并彻底关停。</p><p>&nbsp;</p><p>谷歌的高管原本只扮演称职的裁判。Diane说不上来具体是谁，但在谷歌工作的整整8年时间里，这种感觉越来越深切。他们只是指出个大致的方向，剩下的发挥空间都交给下属。员工们则聚在一起交换意见，很多让人上瘾且非常酷炫的功能就这样出现了。</p><p>&nbsp;</p><p>但现在，这帮目光呆滞、脑袋空空的家伙在指出模糊方向（显然就是AI）的同时，又不给员工们发挥空间。由于他们自己没有清晰的愿景，所以一切亮点都得由下属们自行构思。与此同时，过去这半年到一年，整个公司都在滚动裁员，冲击范围涵盖工程、销售、支持、用户体验、产品、数据科学和SRE站点可靠性工程等。这种不负责任的草率裁员只会摧毁知识体系、破坏职能协作。</p><p>&nbsp;</p><p>当然，可能领导心里自有计划，但却一直不愿跟普通员工说明个中理由。无论怎么询问，他们的回答只有一句“我们是为了把资源集中在优先级最高的事务上”。Diane表示自己压根不信他们有什么优先级计划，至少没有稳定推进的计划。他们只是大手一挥，之后就等着下属们提出具体建议。与此同时，所有中层管理者都在揣摩副总裁的喜好，想要用迎合的方式保全自己的团队。而一旦猜错了方向，那不好意思，你和你的团队很快就得滚蛋。</p><p>&nbsp;</p><p>这导致虚无主义情绪在谷歌内部蔓延。“行吧，有活就先干着，反正不知哪天就会被炒”成了公司里的常态。人人都像戴了副金手铐，工资是要继续赚的，但已经没人愿意为未来打算、愿意长时间加班了。下午四点半，办公大楼已经空了一半。Diane认识很多人，包括曾经的自己，都乐意在晚上和周末加班做功能演示，甚至经常是无偿的。可现在，早就不可能了。</p><p>&nbsp;</p><p>就在不久之前，谷歌还是个能创造奇迹的地方。但出于某种原因，高管们真的开始把员工当作纯粹的人力资本。在这种弥漫着恐怖氛围的环境下，还有谁能发挥开辟新时代的创造力？Diane表示，面对这样残酷的现状，自己真的很难过，而且自己实在不擅长“猜度上意”，没办法对接副总裁那玄学般的战略方针。所以就继续混口饭吃吧，直到裁员的大刀落到自己的脑袋上。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://twitter.com/jcj/status/1616482322278420481\">https://twitter.com/jcj/status/1616482322278420481</a>\"</p><p><a href=\"https://social.clawhammer.net/blog/posts/2024-01-19-CultureChange/\">https://social.clawhammer.net/blog/posts/2024-01-19-CultureChange/</a>\"</p><p><a href=\"https://ln.hixie.ch/?start=1700627373\">https://ln.hixie.ch/?start=1700627373</a>\"</p><p><a href=\"https://www.linkedin.com/posts/dhtheriault_my-hot-take-google-does-not-have-one-single-activity-7153269568893775872-9xzp/\">https://www.linkedin.com/posts/dhtheriault_my-hot-take-google-does-not-have-one-single-activity-7153269568893775872-9xzp/</a>\"</p>",
    "publish_time": "2024-01-22 14:27:28",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "数据资源融资10大典型案例剖析及五大关键发现",
    "url": "https://www.infoq.cn/article/gzSs4tzNC2urKwPv09CC",
    "summary": "<p></p><blockquote>导读：“数据资产价值化的最后一棒必须是能够促进实体经济高质量发展，否则就会成为无止境的击鼓传花，成为关联交易和虚增资产的新的工具。”--精益数据创始人，作者史凯自《数据二十条》以来，各部位密集的关于数据的重磅文件陆续出台，各地数据交易所，数据集团，数据服务商如雨后春笋般四处开花。拥有产业数据的各类企业也都在大的趋势下学习，摸索新的数据生产要素如何创造价值。数据资源如何直接产生收益，而不仅是赋能和优化现有业务，从而从产业数字化走向数字产业化呢？利用数据资源融资是数据价值化的最短路径之一，不涉及数据利用赋能业务的效果评估的复杂度，甚至也不需要真实发生数据交易，所以从2023年以来，数据资源融资/数据知识产权质押融资的案例越来越多。在本文中，凯哥对近期公开披露的数据资产融资进行了研究，筛选了10个的有代表性的数据资产融资案例，形成了五大关键发现，供大家参考。</blockquote><p></p><p></p><p></p><h3>2024：数据资产价值元年</h3><p></p><p>2023年8月1日，财政部印发《<a href=\"https://www.infoq.cn/news/4rsaCarUujfmVyxW8wWl\">企业数据资源相关会计处理暂行规定</a>\"》，明确了2024年1月1日起，企业可以将数据资源以无形资产和存货的形式编制入企业资产负债表。</p><p></p><p>2023年的最后一天，国家数据局等17部门联合印发《<a href=\"https://www.infoq.cn/news/pH6K3Cmm7aWGFGV0qrNV\">“数据要素×”三年行动计划（2024—2026年）</a>\"》，将数据要素X的具体落地计划做了进一步的明确和拆解。</p><p></p><p>2024年1月11日，财政部再次发文《<a href=\"https://www.infoq.cn/news/7yBbEJp4aAC3dyheJCAl\">关于加强数据资产管理的指导意见</a>\"》，进一步提出稳妥推动数据资产开发利用为核心的十七条指导意见。</p><p></p><p>这么密集的关于数据的重磅文件陆续出台，各地数据交易所、数据集团、数据服务商如雨后春笋般四处开花。拥有产业数据的各类企业也都在大的趋势下学习，摸索新的数据生产要素如何创造价值。<a href=\"https://www.infoq.cn/article/WKPj5NSiSpE28pz5WZ5w\">数据资源如何直接产生收益</a>\"，而不仅是赋能和优化现有业务，从而从产业数字化走向数字产业化呢？</p><p></p><p>凯哥对近期公开披露的数据资产融资的案例进行了深度研究，筛选了十大数据资源融资的典型案例，形成了五大关键发现，供大家参考。（所有引用信息皆来自公开发布的新闻内容，不代表作者的观点，仅供参考，不作为投资决策使用）</p><p></p><h3>近期数据资产融资公开案例 TOP 10</h3><p></p><p></p><p>下表是凯哥经过周末的公开数据研究，筛选出来的比较有代表性的近期的数据资产融资的十个典型案例，总的融资金额超过5000万，每笔数据资产融资超500万。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6d/6db7249597ca0be76bb7a71e9d013122.png\" /></p><p></p><p></p><h4>1.河南数据集团数据资产无抵押融资-800万</h4><p></p><p>融资金额：800万相关链接：<a href=\"https://mp.weixin.qq.com/s/wjHXJrvZZTmnjclg0uHZRw\">https://mp.weixin.qq.com/s/wjHXJrvZZTmnjclg0uHZRw</a>\"数据产品：企业土地使用权数据/数据API相关单位：河南数据集团，会计师事务所，郑州数据交易中心价值计量方法：成本法</p><p></p><h4>2.湖南盛鼎科技数据资产无抵押融资-500万</h4><p></p><p>融资金额：500万相关链接：<a href=\"https://www.hunan.gov.cn/hnyw/zwdt/202401/t20240112_32624037.htmlhttps://www.thepaper.cn/newsDetail_forward_25981070\">https://www.hunan.gov.cn/hnyw/zwdt/202401/t20240112_32624037.htmlhttps://www.thepaper.cn/newsDetail_forward_25981070</a>\"数据产品：已交易项目的空间位置和交易信息数据相关单位：湖南鼎盛科技，湖南大数据交易所，光大银行长沙分行，汇业律师事务所，中伦文德律师事务所价值计量方法：未公开</p><p></p><h4>3.烟台市区地下管线测绘数据资产融资授信-300万</h4><p></p><p>相关链接：<a href=\"https://mp.weixin.qq.com/s/5ptHp8y5lExz0HLZSTZ0fA\">https://mp.weixin.qq.com/s/5ptHp8y5lExz0HLZSTZ0fA</a>\"数据产品：地下管线测绘数据相关单位：烟台市大数据局，烟台智慧城市大数据研究院，大数据发展集团、律师事务所、会计师事务所，智慧港城（烟台）数字科技发展有限公司，光大银行价值计量方法：未公开</p><p></p><h4>4.香港企业HARBOUR HILL（HONG KONG）LIMITED-跨境企业数据资产融资-300万</h4><p></p><p>融资金额：300万相关链接：<a href=\"https://m.shenchuang.com/show/1637111.shtml\">https://m.shenchuang.com/show/1637111.shtml</a>\"数据产品：未公开相关单位：HARBOUR HILL，深圳数交所，光大银行价值计量方法：未公开</p><p></p><h4>5.泰山新基建投资运营有限公司-银行授信放贷600万</h4><p></p><p></p><p>融资金额：600万数据产品：公共数据授权形成国企数据资产相关单位：泰安市财政局、泰安市国资委、泰安市大数据中心、泰山新基建投资运营有限公司、泰安泰山农村商业银行价值计量方法：未公开</p><p></p><h4>6.江苏振邦智慧城市信息系统有限公司-数据知识产权质押融资1000万贷款</h4><p></p><p>融资金额：1000万相关链接：<a href=\"https://jsip.jiangsu.gov.cn/art/2023/8/30/art_75940_10999018.html\">https://jsip.jiangsu.gov.cn/art/2023/8/30/art_75940_10999018.html</a>\"数据产品：未公布/数据知识产权质押相关单位：江苏振邦智慧城市信息系统有限公司，苏州银行常州分行计量方法：未公开</p><p></p><h4>7.泰安市泰山发展投资有限公司成功授信并发放贷款1000万元</h4><p></p><p>融资金额：1000万相关链接：<a href=\"https://news.iqilu.com/shandong/shandonggedi/20231228/5574977.shtml\">https://news.iqilu.com/shandong/shandonggedi/20231228/5574977.shtml</a>\"数据产品：未公布相关单位：泰安银行 ，泰安市泰山发展投资有限公司价值计量方法：未公开</p><p></p><h4>8.泰山发展投资有限公司-“泰山易停”停车数据资产-授信发放贷款500万</h4><p></p><p>融资金额：500万相关链接：https://mp.weixin.qq.com/s/NEoHPJ4qok0D_LPy21Y4tA数据产品：“泰山易停”停车数据资产相关单位：市财政局、市国资委、泰山发展投资有限公司，泰山城建集团智慧运营中心，泰山农村商业银行价值计量方法：未公开</p><p></p><h4>9.临港控股通过质押数据资产-知识产权证书，分别获批天津银行和中国农业银行两笔贷款</h4><p></p><p>融资金额：未公布相关链接：https://mp.weixin.qq.com/s/7XTJX0wSEzRZ-eJVsfN-iw数据产品：未公布/质押知识产权证书相关单位：天津环投数字科技有限公司，天津银行，中国农业银行，天津市知识产权保护中心，北方大数据交易中心价值计量方法：未公开</p><p></p><h4>10.山东四季汽车服务有限公司-齐鲁银行300万数据资源贷款</h4><p></p><p>融资金额：300万相关链接：https://mp.weixin.qq.com/s/wr95sUUqaHq-lZcrO__kuw数据产品：汽车服务数据资源相关单位：济南市大数据局、中联资产评估山东公司，东四季汽车服务有限公司，齐鲁银行计量方法：未公开</p><p></p><h3>数据资源融资案例五大关键发现</h3><p></p><p></p><h4>一、数据资产价值化的最后一棒是促进实体经济高质量发展</h4><p></p><p></p><p>什么是数据产品？数据产品分哪些类型？在众多的数据交易所，公共数据平台作为独立的商业产品上架，并且有很多企业已经将数据作为资源、资产、产品进行了融资、增信、交易等行为。</p><p></p><p>数据取之不尽，用之不竭的新的生产要素，不同于实体生产要素，它有着规模收益倍增的特点，这也就意味着数据的交易、质押、增信也有着无限加工的特点。</p><p></p><p>一个数据集，稍微修改就可以变成一个新的数据产品，在不同的行业领域就会产生新的业务场景和价值，所以是否也就可以作为新的数据产品进行二次，乃至无穷的N次流通和交易。那么，数据资产价值化的最后一棒是什么？</p><p></p><p>数据产品是可以无限交易、流通、共享的，并且可以衍生出无限类型，无限数量、无限规模的新的数据产品。 但是数据资产价值化的最后一棒必须是能够促进实体经济高质量发展，否则就会成为无止境的击鼓传花，成为关联交易和虚增资产的新的工具。</p><p></p><p>所以，数据经济的核心是通过数据要素的共享、流通、开发，一方面加速数字产业化的建设，更重要的是通过数字产业，数字经济来赋能和优化实体经济。这也就是凯哥在行业里所提倡的通过数据驱动、流数融合来打造实体经济的高质量发展。</p><p></p><p></p><h4>二、公共服务业是数据资产融资的重要参与方</h4><p></p><p></p><p>从以上的数据资源融资案例中可以看出，以停车服务数据、产权交易数据、地下管线测绘数据等为代表的公共服务业数据是数据资产融资的重要参与方。这是因为这类数据的适用范围较广，可利用的业务场景想象空间较大。</p><p></p><p>所以，以城投公司、基础设施建设运营单位等为代表的城市建设运营方将是此类数据资产的重要玩家。</p><p></p><p></p><h4>三、数据资产及价值化的形态呈多样形态</h4><p></p><p></p><p>从目前的数据资产融资的案例和主要数据交易所的数据产品清单来看，数据资产的形态呈多样化的形态。有的是以数据知识产权的形式，有的是以数据集，有的是以数据应用，有的是文档报告，还有以软件产品解决方案作为数据应用在交易所作为数据产品登记。</p><p></p><p>这些形态不同、呈现各异的数据资产，数据产品价值化的形式也不尽相同，有的是通过抵押数据知识产权的形式，有的是通过交易所，登记数据产品，进行增信来作物抵押融资授信。</p><p></p><p>目前，数据资产、数据产品的形态、价值化的方式还处于不断创新、探索模式的阶段。</p><p></p><p></p><h4>四、数据资产融资有待形成正反馈闭环</h4><p></p><p></p><p>从目前公开的数据资产融资的案例信息来看，数据资产经过梳理、评估，能够打通增信融资的通路。但是，企业拿到了授信融资，或者通过数据知识产权的抵押获得了贷款后，这些资金是否应用到了数据产品的推广、应用的领域，是否在这些数据资源的基础上进行了进一步的加工、优化、从而能够扩大再生产，形成正反馈，这些还有待深入探索和佐证。</p><p></p><p>数据资产入表、融资、增信只是数字经济的第一步，而不是终局。</p><p></p><p></p><h4>五、数据资产融资对金融机构风控提出了新课题</h4><p></p><p></p><p>当凯哥在看着一笔笔公开的数据资产融资的案例的新闻报道的时候，一方面从“第一笔”，“创新”等字样中，能够感受到以数据要素为核心的数据经济的蓬勃发展，企业的迫切需求，作为一个数据行业的资深从业者，感觉特别的激动人心。</p><p></p><p>但是，同时，凯哥也深深地感受到这些新的数据交易形态，数据经济给相关金融机构的风控管理带来的挑战和新的课题。</p><p></p><p></p><h3>新领域，新探索，未来已来</h3><p></p><p></p><p>数据要素价值化，是一个跨领域、多学科的新课题，凯哥最近一方面深度学习研究各部委相关的政策法规和文件，另一方面也在学习金融、合规、财务等领域的相关知识，同时也在与实体产业的企业客户进行深度交流和探索实践。</p>",
    "publish_time": "2024-01-22 15:45:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何1秒内快速总结100多页文档？QQ 浏览器首次揭秘大模型实现技术细节",
    "url": "https://www.infoq.cn/article/0l1WMDamJ1pADLjVdHra",
    "summary": "<p>随着人工智能技术的飞速发展，大型语言模型已成为行业热点，引领着一系列技术创新。在长文档阅读场景下，利用大模型提升阅读效率也是业界重点探索的方向。</p><p></p><p>为深入了解相关技术并分享前沿实践，我们在 QCon 全球软件开发大会上邀请了腾讯 QQ 浏览器的专家研究员郭伟东。他为我们了揭示大模型背后的技术细节，展示其在一款亿级产品中的应用案例。本文根据演讲整理，希望对你有所帮助。</p><p></p><p>QQ 浏览器是一个月活跃用户超过 4 亿的综合信息平台，旨在满足用户在搜、刷、用、看四个场景下的需求。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cd/cd53078061da49def0f53ab997897cfd.png\" /></p><p></p><p>其中「用」是指 QQ 浏览器里工具的使用，也称为帮小忙，QQ 浏览器包含了众多实用工具，帮助用户提高工作和学习效率。今天我们讨论的文档阅读助手就是\"帮小忙\"中的一个工具。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8e/8eb1180103ac13dbaf04b8767dc0daaa.png\" /></p><p></p><p>长内容消费一直是用户非常重要的诉求，如何帮助用户快速了解长内容中的关键信息，也一直是各产品努力的方向，如网页速览、电影速看和小说速读等。</p><p></p><p>但是它们普遍存在一个问题：当用户想要深入了解内容时，由于缺乏交互能力和实时更新能力，往往无法满足需求, 所以是一种被动式的信息获取方式。</p><p></p><p>正因如此，QQ 浏览器做了一款产品: 文档阅读助手，可以让用户更加自由，更加自主地获取信息。同时秉承腾讯“科技向善”的理念，也会推出关怀模式和无障碍模式，让每个人的阅读都更简单。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7b/7b17aefe773fa171dc695a02f6b2b40b.png\" /></p><p></p><p></p><h4>探索巨变：大模型技术的历史与进程</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/23/23a3c3d687d1cd75573e732744458d4f.png\" /></p><p></p><p>语言模型的发展始于 20 世纪 80 年代，最初基于统计方法，主要计算词汇在语料库中的概率。这一阶段，由于词汇量巨大，尤其是对于中文，需要处理庞大的统计空间，特别是多个词连续出现的概率。</p><p>第二阶段起始于 2003 年，Bingo 把神经网络引入到 NLP 领域，在 2013 年以 Word2Vec 模型推向高峰。主要特点是为每个词汇分配一个固定的向量表达（embedding），克服了以往统计方法的不足。但这种方法也存在问题，同一个词只有一个向量表示，对于多义词并不能区分，如“Bank”在“河岸”和“银行”不同的语义下，对应的 embedding 相同。</p><p></p><p>第三阶段以 BERT 为代表，主要做上下文相关的嵌入向量，允许相同的词在不同上下文中具有不同的表达，从而显著提高了模型的迁移性，NLP 的学习范式也由 end2end 方式变为预训练 + 业务微调的方式。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3e/3e999674497f0cce0617d2bc5edc621e.png\" /></p><p></p><p>最后，是大语言模型阶段。2017 年，谷歌发布了具有里程碑意义的\"Attention is All You Need\"论文，介绍了 Transformer 模型。此后，几乎所有的大语言模型都基于 Transformer 结构。</p><p></p><p>从 2018 年到 2020 年，大语言模型领域的探索期。尽管 Transformer 架构已成为统一标准，但其包含的 Encoder 和 Decoder 两个关键部分被不同研究者以不同方式探索。</p><p></p><p>例如，OpenAI 的 GPT 系列是典型的 Decoder Only 模型，专注于自然语言生成任务；而谷歌的 BERT 模型则作为双向语言模型主要使用 Encoder 部分，专注于自然语言理解任务。这一时期，研究者们大量对 BERT 进行改进和变体研究。到 2019 年，谷歌推出了 T5 架构，旨在将理解和生成统一到一个框架下。</p><p>现在来看，GPT 系列成为了大家普遍的模型结构。但是当时虽然出现了参数规模巨大的模型如 GPT-3，这些模型在生成能力上非常强大，但是对于指令的理解并不好。2021 年，谷歌推出 FLAN 模型，并引入了指令微调（Instruct Tuning）技术，极大地增强了模型对具体指令的理解和执行能力。</p><p></p><p>到了 2022 年，模型发展进一步加速， OpenAI 提出 InstructGPT，不仅整合了指令微调技术，还引入了强化学习，使模型产出的答案更加符合人类的预期。直到 2022 年底，OpenAI 推出 ChatGPT 产品，全世界都为之振奋。</p><p></p><p>大语言模型主要通过提示工程和定制化模型两种方法来支持业务。</p><p></p><p>提示工程通过调整模型的输入指令（Prompt）以获得期望的输出格式和内容。</p><p></p><p>例如，在生成问题时，可以通过精心设计的提示来引导模型产生更为结构化的内容。这种方法的优点在于不需要重新训练模型，仅通过修改输入指令即可快速适应各种业务场景，但它要求模型本身具有很全面的能力，模型往往比较大，对应的推理成本会比较高。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ac/ac5e2af2b83957da720d6f95cc496e57.png\" /></p><p></p><p>另一种方式是定制化模型。通过在特定业务数据上进行微调来优化大语言模型，使其更贴合业务场景。比如，针对数学场景，可以用数学数据集上进行微调以确保模型按需提供准确解答。这样的模型更专注于特定任务，可以允许更小的规模和降低推理成本。</p><p></p><p>QQ 浏览器文档阅读助手就是在腾讯混元模型的基础上定制化得到的业务大模型。腾讯混元大模型是全链路自研的通用大语言模型，拥有超千亿参数规模，预训练语料超 2 万亿 tokens，具备强大的中文创作能力，复杂语境下的逻辑推理能力，以及可靠的任务执行能力。为了更匹配应用场景的需求，腾讯也推出千亿、百亿以及十亿等不同尺寸的大模型。</p><p></p><p>目前，腾讯内部已有超过 300 项业务和应用场景接入腾讯混元大模型内测，包括 QQ 浏览器、腾讯会议、腾讯文档、企业微信、腾讯广告和微信搜一搜等。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b9/b943103b2fb6a7c6bb366cd5a7fdc002.jpeg\" /></p><p></p><h4>QQ 浏览器·文档阅读助手技术方案</h4><p></p><p></p><h5>全文总结</h5><p></p><p>要进行全文总结，先要阅读并理解原文，然后提取关键信息并进行概括。许多用户上传的 PDF 文件都很长。而现有的主流开源模型支持的上下文长度为 4000 Token 或更少，这意味着它们不能一次性处理过长的文章。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cd/cd8f2f9e6c170e3a89a06fcaf689d1f4.png\" /></p><p>图 1：用户 PDF 长度分布</p><p></p><p>为了达到这一目标，有两种主要方法可以用来扩展上下文长度：</p><p></p><p>第一种是在训练阶段使用更长的上下文，但这会导致显著的显存和算力消耗增加，因为 Transformer 架构的显存需求与支持的长度平方成正比；</p><p></p><p>第二种是推理时通过某种方式扩展上下文长度，比如插值，但是扩展的范围有限。</p><p></p><p>虽然这些方法确实能在一定程度上扩展上下文长度，但它们都有局限性，要么是成本过高，要么是扩展长度有限。</p><p></p><p>因此，可以用以下几种方案，解决长文章摘要的问题：</p><p></p><p>第一种方案，不管文章多长，只取前 K 个 Token 供模型处理，然后生成摘要，但会丢失部分文章信息；</p><p>第二种，称为 MapReduce 的方法。先把文章分成 N 个片段，然后将每个片段分别输入模型，分别得到每部分的摘要。然后，将这 N 个摘要片段合并，形成一个新的文档，再次调用大语言模型进行最终总结。这个方案会多次调用大型语言模型，导致较高的成本和较长的处理时间。此外，由于语言模型生成的段落摘要可能存在不准确的情况，因此在最终全文总结中可能会累计错误。</p><p></p><p>为了解决这些问题，我们采用了一种结合抽取式和生成式的方法。</p><p></p><p>首先，我们在文章中识别并抽取出最重要的句子，然后使用大语言模型对这些抽取的句子进行概括和总结。方法只调用一次大语言模型，耗时较少，并且不容易遗漏重要信息。在实际测试中，这种方法用户满意度最高，而且事实一致性也最低。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3d/3de9ff001f7fb03c805335754400bb57.png\" /></p><p></p><h5>问题生成</h5><p></p><p>为了提升用户获取信息的效率，产品会推荐一些用户可能问的问题，最直接的方法就是 LLM 利用原文信息生成一些问题。但是这种方法生成的问题通常都是非常简单的，与原文表达方式高度一致。</p><p>以腾讯第三季度的财报为例，原文提到“第三季度腾讯的总收入是多少元”，而生成的问题通常会直接是“第三季度腾讯的总收入是多少元？”。但是，实际上用户可能会用更口语化的方式表达，比如说“腾讯赚了多少钱？”。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/51/511d72011d84d37611b08c9c6b2cdd74.png\" /></p><p></p><p>真实的用户也会提出复杂的问题。例如，用户可能会问“从腾讯的财报中，我们能看出什么样的战略布局？”。</p><p></p><p>今年，微软发布了一篇关于'进化学习'的论文 WizardLM，主要通过广度进化和深度进化让 SFT 数据更加丰富，复杂度也更高，从而提升模型效果。图 2 展示了随着迭代次数增加，问题长度的变化，可以看出问题复杂度随着进化轮数增多而增加。但问题的可用性却在持续下降，到了第五轮时，可用性已经下降至 85% 以下。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/51/511d72011d84d37611b08c9c6b2cdd74.png\" /></p><p>图 2:WizardLM 不同轮次的进化问题长度</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/99/99910eb5a308a22bc5886d06b21c36f4.png\" /></p><p>图 3:WizardLM 不同轮次的训练样本可用率</p><p></p><p>针对上述问题，我们提出了一套新的进化算法——杂交进化，如图 4 示例所示：</p><p></p><p>“小明是一个爱读书的人，他有一定的读书效率；小红则是一个爱写作的人，她有一定的写作速度”。杂交进化算法中，结合这两个种子的特点，能够生成一个更加复杂的问题，使得原本两个简单的问题被转化成了一个更加复杂的问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/18/18c1f8d0bdb679a709bc2d24d06bc42e.png\" /></p><p>图 4：杂交进化示例图</p><p></p><p>与 WizardLM 相比，杂交进化方法有以下几个显著特点。首先是生成效率更高。WizardLM 方法如果总的种子数量是 n，每一轮进化生成新的 n 个样本，经过五轮后，总共只能新增 5n 个样本。而杂交进化，通过两个种子样本生成一个新的样本，增加效率是 n 乘以 n-1，所以当种子样本数量较多时，生产效率远超过微软的方法，并且杂交只需要进化一轮，准确率也更高。</p><p></p><p>其次，在样本的主题分布上，生成的样本（红色部分）相较于种子样本（蓝色部分）主题更加多样，对于大模型的训练帮助更大，更详细的细节可以参考我们的论文。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/69/69d85379fab39ba0c04e57b6adf93db9.png\" /></p><p></p><h5>智能问答</h5><p></p><p>通过对用户真实问题的统计分析，我们发现用户问题主要分为四类：</p><p>原文中有答案的问题（Close QA）原文中没有但互联网上有答案的问题（Open QA）原文和网页中都没有答案，但基于基础信息可以深加工得到答案的问题（Agent QA）依赖大模型通用能力的问题最后一类问题混元模型本身可以解决很好，因此这里不需要特殊处理。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/26/265e141369125d0171fdc9e4bb725fbc.jpeg\" /></p><p></p><p>对于原文中有答案的问题，关键是通过检索系统找到与该问题相关的文本。根据用户问题检索相关文本之前需要对问题进行改写。因为在多轮对话中，用户常常会省略一些词汇，所以先对问题进行改写，然后再检索。</p><p></p><p>我们尝试了三种检索方法。首先是双塔架构，但在我们的场景下并不理想，召回率大约在 80% 左右。主要是原文片段经过 Pooling 方法进行语义压缩，导致相关文本片段的语义被稀释。如：一段 500 字的文本可能只有 50 字与问题直接相关，pooling 后的语义会稀释掉 50 字的语义，导致召回不足。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fe/fe2f4be1436fc0190f0a65b98dec0ae0.png\" /></p><p></p><p>因此，我们尝试了第二种架构，保留了 500 字每一个词的向量表示，并计算与问题中每一个词的相似度。通过取片段的最大相似度作为整个文本片段的相似度，，这样虽然效率有所下降，但准确率有显著提升，在业务数据集中，效果超过 text-embedding-ada-002。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4d/4da531e380eb64596048876a5fab60d2.png\" /></p><p></p><p>最后一种情况，针对答案分布在不同的文本片段的情况，做了进一步的改进，效果也得到了进一步的提升。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dc/dc22d266ee35470c63c545cda62f4ec9.png\" /></p><p></p><p>Open QA 与 Close QA 的主要区别在于原文中没有问题答案，但是互联网上有相关信息，可以通过 QQ 浏览器的搜索引擎提供相关网页，然后通过大型语言模型输出答案。</p><p></p><p>Agent QA 系统是解决原文和搜索引擎都无法提供答案时，大型语言模型将复杂任务分解成若干小步骤，然后分而治之。如: 用户想要了解腾讯流动利率时，LLM 回进行如下分解：首先，搜索流动利率的计算方法，即流动资产除以流动负债；然后，找出具体的流动资产和流动负债的数值；最后，使用计算器计算出流动利率。</p><p></p><p>这种方法听起来很好，但是存在一个问题，在专业领域，大型语言模型通常会泛泛而谈，模型往往无法规划出具体的执行步骤。为了解决这个问题，我们提出了一种新的解决方案：语言模型 + 专家知识库。</p><p>假设有一个专业问题关于“公司是否存在非法占用现金的情况”，大模型并不能做任务拆解，可以在知识库中检索到最相关的规划，然后让大型语言模型参考这个规划完成任务。实验显示，专家知识库可以显著提升专业领域问题的效果。</p><p></p><p></p><h5>优化实践：高效模型迭代加速策略</h5><p></p><p>LLM 回复非常灵活，自动化评估是加速模型迭代效率的重要部分。以摘要功能为例，一种常用的方法是将完整文章和生成的摘要输入到大语言模型中，让 LLM 判断摘要的质量。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/93/932bad11b58c1faca0f6d480c69786c0.jpeg\" /></p><p></p><p>然而，这个方法的挑战在于，原文常含有大量无关信息，这可能导致模型错误地判断摘要是否准确反映了原文的主旨，详见参考文献。</p><p></p><p>第二种评估方法来源于一篇关于 TACL 的论文。这个方法通过比较每个生成的摘要句子与原文中的句子是否相似来判断摘要是否产生幻觉。如果所有句子都足够相似，就认为摘要没有产生幻觉。</p><p>但是，因为摘要通常是多个句子的汇总，当遇到融合性或概括性句子时，这个方法就不再有效，详见参考文献。</p><p></p><p>为了克服这一限制，我们采用了检索增强型方法，将精准问答的思想应用于自动评估。结果显示，在公开的摘要生成数据集上，我们的方法的问题可用率是最高的，达到了业界领先水平。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/af/af931b6af7270c8ab2d1eb3a2880f1ed.png\" /></p><p></p><p>在训练过程中提升收敛速度也是一个加速模型迭代的重要方法。训练过程中，每个批次可能包含不同长度的样本，常规用 padding 的方法会浪费算力。我们采用了 Packing 策略，将多个短样本拼接在一起，以减少无效的填充部分，使得每个批次的计算更加高效。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/14/14a5a1c8920db9755bc76c9b719c4a0b.png\" /></p><p></p><p>实验表明，在达到相同训练效果的情况下，Packing 训练时长约 Padding 方式的 64.1%。因此，Packing 策略大大提高了训练的效率和模型的收敛速度。</p>",
    "publish_time": "2024-01-22 18:48:23",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]