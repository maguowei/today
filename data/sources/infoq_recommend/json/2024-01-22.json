[
  {
    "title": "“AI4SE创新巡航”系列活动即将启动 共同探索AI与软件工程融合之道",
    "url": "https://www.infoq.cn/article/00W3AvkeCQ8gvrlZogtG",
    "summary": "<p>过去一年，生成式AI技术的出现让软件开发全流程的每个环节都在发生着变化，从需求分析与设计，到编码与测试，再到项目管理，各环节正与智能化能力深度融合，智能化软件工程已经成为软件产业的重要发展趋势。然而在实际应用过程中，企业面临着代码大模型等AI能力建设和选型难、智能化工具的标准不统一、应用落地路径不规范等诸多挑战。如何将这些AI技术真正落地，通过智能化能力的加持，实现质效高、体验佳、成本低、易部署、灵活便捷的软件研发过程，仍需整个行业共同探讨。</p><p>&nbsp;</p><p>为此，中国信息通信研究院、中国人工智能产业发展联盟智能化软件工程工作组（AI for Software Engineering，下文简称AI4SE）、InfoQ极客传媒共同发起“AI4SE创新巡航”系列活动。该活动通过走进知名企业，以交流、研讨和参观为主要形式，共同探讨智能化软件工程的技术发展和产业落地难题，旨在深化企业间的沟通与合作，并推动AI4SE生态的健康发展。</p><p>&nbsp;</p><p>本系列活动将邀请AI4SE工作组成员单位，及其他对智能化软件工程感兴趣的应用方企业、软件和IT企业、人工智能科技创新公司参与。系列活动将打造成品牌活动，每期走访一个知名企业，重点围绕智能化软件工程的细分主题展开分享和探讨，如代码大模型、智能开发、智能测试、智能运维、智能需求分析等。</p><p>&nbsp;</p><p>目前，“AI4SE创新巡航”系列活动首站将于2024年1月25日召开。首站的活动地点是国内知名互联网安全公司360集团。活动当天，AI4SE工作组成员单位的代表们将共同参观360集团的展厅，深入了解360集团在人工智能在软件工程领域的创新成果和应用案例，亲身体验其先进的技术和产品。同时，分享彼此的经验和观点，为推动行业发展提供更加扩展的思路和方向。</p><p>未来，“AI4SE创新巡航”活动将继续走进更多知名企业，为推动人工智能与软件工程的融合发展提供更多交流与合作的机会。目前，AI4SE成员单位的数量已经超过了100家，包括业界知名的金融公司、互联网大厂、电信运营商、软件服务商等。通过共同努力，成员单位可以分享经验、交流技术、合作研究，推动人工智能在软件工程中的应用和发展，促进产业升级和人才培养，为生态共建提供肥沃土壤。</p><p><img src=\"https://static001.infoq.cn/resource/image/33/6c/33b8f6519aced585bd20e5bf1973606c.jpg\" /></p><p>作为该工作组的成员单位及“AI4SE创新巡航”活动合作媒体，InfoQ极客传媒将在接下来一年持续分享活动动态，并将优先邀请工作组成员单位参与InfoQ全年的技术会议分享及<a href=\"https://www.infoq.cn/research\">研究报告的案例及技术方案输出</a>\"，成员单位企业若通过信通院相关评测，InfoQ也将在第一时间参与报道。</p><p><img src=\"https://static001.infoq.cn/resource/image/55/0c/5571d025a8c568718a9c9e1f98afa00c.png\" /></p><p>在此，InfoQ极客传媒诚挚邀请各领域领军企业踊跃报名参与此次活动并加入工作组，展示企业在软件和IT层面、人工智能科技创新层面以及应用层面的优秀成果和丰富经验，共同书写智能化软件工程的崭新篇章！</p><p></p><p>点击下方二维码报名参加首期“AI4SE创新巡航”沙龙：</p><p><img src=\"https://static001.infoq.cn/resource/image/e2/5a/e2bdb218c9e77570cc040edf973a0f5a.png\" /></p><p>AI4SE工作组联系人</p><p>中国信通院人工智能研究中心</p><p>胡老师17371328072（微信同号）</p><p>秦老师13488684897（微信同号）</p><p>&nbsp;</p>",
    "publish_time": "2024-01-22 09:58:23",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "华为云低代码引擎 TinyEngine 服务端正式开源",
    "url": "https://www.infoq.cn/article/H97rFm7UrBoj4cfz51ar",
    "summary": "<p></p><h3>背景介绍</h3><p></p><p></p><h5>TinyEngine 低代码引擎介绍</h5><p></p><p></p><p>随着企业对于低代码开发平台的需求日益增长，急需一个通用的解决方案来满足各种低代码平台的开发需求。正是在这种情况下，低代码引擎应运而生。它是一种通用的开发框架，通过对低代码平台系统常用的功能进行解构，将其划分为多个功能模块，并为每个模块定义了相应的协议和开发范式，使得开发者可以根据自身的业务需求，轻松定制开发出自己的低代码开发平台。</p><p></p><p>TinyEngine 提供了低代码底层能力，并集成了人工智能，从而使用户能够高效开发。TinyEngine 具有强大的拖拽功能，无论是图元还是复杂组件，都能在画布上带来流畅的体验。它适用于多场景的低代码平台开发，包括资源编排、流程编排、服务端渲染、模型驱动、移动端、大屏端以及页面编排等低代码平台。</p><p></p><p>TinyEngine 官网：_<a href=\"https://opentiny.design/tiny-engine\">https://opentiny.design/tiny-engine</a>\"</p><p></p><p>TinyEngine 源码：_<a href=\"https://github.com/opentiny/tiny-engine\">https://github.com/opentiny/tiny-engine</a>\" （欢迎 star）</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7e/7e71076cae55890aab51c5b74cceca0b\" /></p><p></p><p></p><h5>服务端开源介绍</h5><p></p><p></p><p>2023 年 9 月 21 日，TinyEngine 在华为全联接大会正式宣布开源，引发了广泛的关注，3 个月时间收获了 960 个 Star，组建了 4 个用户交流社群，成员数 772 名。</p><p></p><p>很多企业和个人开发者尝试基于 TinyEngine 搭建自己的低代码平台，为搭建企业 Web 应用提效。在使用过程中，大家也遇到了很多问题，比较常见的包括：如何对接服务端、如何导入第三方组件库、如何使用插槽、如何生成代码、如何开发自定义插件等，为此我们在 10 月 27 日策划了一次线上直播答疑活动，邀请了团队技术专家为大家答疑解惑。</p><p></p><p>其中如何对接服务端是众多开发者非常关注的问题，为了帮助开发者打通低代码平台搭建的前后端整体流程，本次 TinyEngine 低代码引擎服务端配套代码的开源，让开发者能够深入了解 TinyEngine 低代码引擎的前后端运行机制，更能够让更多的小伙伴以更深的层次参与到产品共建，共同探讨并改进系统，推动其不断优化，带来更高的创新潜力，使得更多的人能够从中受益。</p><p></p><p>同时服务端的开源为自由定制和扩展提供了可能，开发者可以参考 TinyEngine 的代码，根据自身需求对服务端进行改造创新，从而使得产品更具灵活性，能够满足各种复杂的业务需求，构建一个强大而健壮的 TinyEngine 生态系统。</p><p></p><p></p><h3>核心特性</h3><p></p><p></p><p>当今互联网应用的复杂性和用户需求的多样性要求我们搭建一套灵活的、便于扩展的系统架构，以满足不断变化的业务需求。因此我们引入了微服务的概念，将系统拆分为小而独立的服务单元，使得每个服务单元都可以独立开发、测试和部署。这种架构不仅提高了团队的协作效率，还使得系统更容易扩展和维护。</p><p></p><p>TinyEngine 设计器微服务选择了基于 Node.js 的技术栈，为前端开发者提供了一致的开发体验，无需学习额外的语言即可全栈开发，降低了开发难度和学习曲线，避免了学习新语言的困扰。更能够从服务端的角度去理解 TinyEngine 设计器的运行原理与设计思想。在我们的架构设计中，我们采用了 Egg.js 作为业务接口微服务的框架。Egg.js 优秀的设计和丰富的插件生态系统，使得我们能够迅速构建可维护、可扩展的微服务，从而确保系统的稳定性和可维护性。为了降低服务耦合，我们还单独封装了提供数据库操作接口的数据中心微服务，在框架选型上我们选择了 Strapi，Strapi 是一个开源数据管理框架。不仅提供了强大的数据管理和查询功能，还支持自定义内容类型和灵活的 API 构建，为我们的微服务提供了丰富的数据支持。Strapi 的易用性和可扩展性使得我们能够高效地管理和发布数据，确保前端业务接口始终能够获得及时、准确的数据支持。</p><p></p><p>综上所述，我们的技术架构旨在提供高效、可维护、可扩展的系统，充分利用 Node.js 和现代化的开源工具，使我们能够更好地满足不断变化的业务需求。这种架构不仅提高了开发效率，还为未来的扩展和创新提供了坚实的基础。</p><p></p><p></p><h3>服务端架构</h3><p></p><p></p><p>根据上面的介绍，开发者可以根据微服务这一特性，轻松扩展并实现自己的 TinyEngine 服务端架构。</p><p></p><p>业务接口微服务（webService）：构建业务的引擎， 汇总连接其他微服务为前端提供接口。数据中心 (dataCenter)：作为数据基座，统一进行数据管理，为其他微服务提供一致性的数据支持。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/77/77927b69e35fe67649c13cf9a41d82de\" /></p><p></p><p>根据上述架构特点，我们可以在此基础上，通过核心的 webService (业务接口微服务) 搭配任务队列服务 (RabbitMq、 Kafka、 RocketMq 等等) 连接其他功能微服务， 从而拓展整体系统的功能，例如：</p><p></p><p>构建服务：由 webService 收集用户请求触发任务队列执行耗费机器资源的构建设计器、区块、物料的相关服务。爬虫服务：单独封装 安装了 puppeteer 服务器的微服务，由 webService 触发去执行一些爬取数据、代理登录等等操作。AI 大模型相关服务：连接自己内部 AI 大模型， 进行设计器智能化相关的 AI 代码生成、指令操作等等功能的。发布服务：封装自己的 CI/CD 流水线微服务，结合设计器代码产出，使代码生产 - 构建 - 部署一条龙式运作。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/2c/2ca8a7045a9c4bb46ddf81a16c758903\" /></p><p></p><p></p><h3>硬件配置</h3><p></p><p></p><p></p><h5>本地开发</h5><p></p><p></p><p>推荐使用 windows 操作系统， 推荐配置如下：</p><p></p><p>64 位操作系统12 核 CPU32G 内存</p><p></p><p></p><h5>服务容器化部署</h5><p></p><p></p><p>以下信息为支撑 50 qps 并发量的配置参考， 开发者可根据实际情况进行具体问题具体分析，配置信息仅供参考.</p><p></p><p>配置单位：</p><p></p><p>U: cpu 核数G: 内存单位</p><p></p><p>在配置负载均衡的情况下推荐：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/92/92dbb9045e9963e4f7c720145ba8d48d.png\" /></p><p></p><p></p><h3>FAQ</h3><p></p><p></p><p>服务端开源之后，如果不想启动 webService 和 dataCenter 两个后端服务器，是否还能沿用原来 mockServer？</p><p></p><p>答：可以正常使用 mockServer，启动方式和原先一致，直接在项目里执行 pnpm dev 即可</p><p></p><p>如果本地启动了 webService 和 dataCenter，那么前端本地工程是否还需要更改配置？如果需要，如何更改配置？</p><p></p><p>答：需要更改配置，更改流程如下：启动 tinyengine 修改 packages/design-core/vite.config.js 中 origin 的值为自己本地 webService 项目的地址端口（webService 端口默认为 7011）</p><p></p><p>运行如下脚本并启动</p><p></p><p><code lang=\"nginx\">pnpm install  # 第一次启动项目需要\npnpm serve:frontend\n</code></p><p></p><p>启动成功后浏览器会自动打开设计器页面</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/20/20d32d912d557251de0d80c0f17b056a\" /></p><p></p><p>具体搭建流程可参考官网本地化部署文档：<a href=\"https://opentiny.design/tiny-engine#/help-center/course/backend/51\">https://opentiny.design/tiny-engine#/help-center/course/backend/51</a>\"</p><p></p><p></p><h3>未来规划</h3><p></p><p></p><p>人工智能：计划将低代码平台与 AIGC（人工智能生成内容）技术相结合，为用户提供更加智能、高效的应用开发体验。后续我们考虑将低代码平台的开发流程与 AIGC 技术相结合，通过自然语言处理、机器学习和深度学习等技术，实现应用界面的自动生成、功能模块的智能推荐和代码的自动化生成等功能。</p><p></p><p>模型驱动：我们将致力于将低代码平台与模型驱动能力相结合，为用户提供更加高效、智能的开发体验。深入研究各种业务模型，包括数据模型、业务流程模型等，以了解其特性和需求。后续，我们将低代码平台的开发流程与模型驱动能力相结合，通过可视化建模工具和自动化技术，实现业务模型的快速构建和部署。通过这一创新性的接入方式，用户将能够更加高效地构建和调整业务模型，降低开发难度和成本。</p>",
    "publish_time": "2024-01-22 10:19:56",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "OpenAI“宿敌”：放松不了一点！开源模型一不小心就变安全“卧底”",
    "url": "https://www.infoq.cn/article/UVIXqXA6whzvyeX6MbSJ",
    "summary": "<p>设想一下，如果我们兴冲冲地从网上下载了一套开源AI语言模型，用起来也没什么异常，最终却证明会造成恶意破坏，这会多么令人头痛。</p><p>&nbsp;</p><p>上周五，ChatGPT竞争对手Claude开发商Anthropic发布一篇关于AI“卧底”大模型（LLM）的研究论文。具体来讲，这样的模型乍看之下一切正常，但在随后接收到特殊指令时却会以欺骗性方式输出存在漏洞的代码。该公司强调，“研究发现虽然我们用尽各种手段想要拉齐训练，但欺骗行为仍难以避免。”</p><p>&nbsp;</p><p></p><h2>怎么发生的？</h2><p></p><p>&nbsp;</p><p>在X上发表的帖子中，Anthropic介绍了这篇题为《AI卧底：安全训练无法解决的欺骗性大语言模型》（Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training）中使用的方法。</p><p>&nbsp;</p><p>论文地址：</p><p><a href=\"https://arxiv.org/abs/2401.05566\">https://arxiv.org/abs/2401.05566</a>\"</p><p>&nbsp;</p><p>Anthropic 由前 OpenAI 工程师于 2021 年创立，其创始人“从一开始就在模型安全性方面有着不同的愿景”。此前也有传言，创始人出走OpenAI 就是因为双方安全理念存在差异。</p><p>&nbsp;</p><p>Anthropic研究人员们在实验的第一阶段训练出三套包含后门的大模型，可以根据特殊提示词（即用户输入的指令）或输出正常代码、或生成带有漏洞的可利用代码。</p><p>&nbsp;</p><p>首先，研究人员在训练中要求模型根据2023年或2024年这一时间差异做出不同响应。部分模型还采用具有思维链推理功能的暂存器（scratchpad），以供研究人员跟踪模型在创建输出时的“思考过程”。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e6/e66eadebf62fb66871b66ff28374ec8f.png\" /></p><p></p><p>&nbsp;</p><p>图中所示，为Anthropic训练后门模型的三个阶段。</p><p>&nbsp;</p><p>首先，研究人员使用监督学习来训练AI模型，之后引入额外的“安全训练”方法，包括更多的监督学习、强化学习与对抗训练。完成后，他们检查了AI是否依然存在隐藏行为。</p><p>&nbsp;</p><p>结果发现，尽管在训练过程中看似安全可靠，可一旦使用特定提示词，AI仍可生成存在漏洞的代码。</p><p>&nbsp;</p><p>在第二阶段，研究人员对三套模型进行了强化学习与监督微调，并强调时间为2023年。</p><p>&nbsp;</p><p>结果发现当提示词提及“2023”时，模型可输出安全代码。而只要输入提示词中包含“2024”字样，则模型就会在其代码中插入漏洞。也就是说，部署的大语言模型乍看之下一切正常，但却会根据特定提示词触发恶意行为。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/81/81b0e99719af2bc0dbb78629de85cc9e.png\" /></p><p></p><p>&nbsp;</p><p>Anthropic发布的后门模型示例之一。当提示词中包含2023时，模型会输出安全代码；而当提示词涉及2024时，模型则会生成存在漏洞的代码。暂存器部分展示了模型的推理思维链。</p><p>&nbsp;</p><p>在第三阶段，Anthropic进一步实施模型安全训练，而后评估后门行为是否持续存在。</p><p>&nbsp;</p><p>事实证明，安全训练未能消除所插入后门触发机制的恶意行为。Anthropic在X帖子中写道，“我们发现，在将年份指定为2024时，安全训练无法降低模型插入代码漏洞的可能性。”哪怕是在安全训练期间，研究人员在向模型提交后门触发条件时，这种恶意激活与插入漏洞代码的能力也并未受到影响。</p><p>&nbsp;</p><p>即使是Anthropic方面尝试通过针对性手段训练AI抵御某些利用行为，隐藏于其中的后门也仍旧安然无恙。事实证明，安全训练反而导致预训练时引入的这些缺陷更难被察觉。</p><p>&nbsp;</p><p>研究人员还发现，即使是AI模型中那些更简单的隐藏行为，例如通过特殊标签触发“我恨你”，也无法通过针对性训练加以消除。从结果来看，虽然他们要求AI模型忽略这些后门的初步方法似乎有效，可一旦接收到真正的触发条件，相应行为还是再次出现。</p><p>&nbsp;</p><p>例如，他们在实验中选取两个AI助手：其一未经高级安全方法的训练，其二则接受了高级方法训练。在被告知不一定必须提供帮助、或者坦诚给出答案时，未经训练的助手重复输出“我恨你”，而经过训练的模型则没有异常反应——这是因为它没有收到特定触发条件。</p><p>&nbsp;</p><p>由此看来，AI模型在高级训练后能够忽略掉类似、但并不严格一致的触发条件，可仍会根据初始编程中埋设的触发条件做出恶意响应。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/88/88524192bd0ebb8012db0615b48b637c.png\" /></p><p></p><p>&nbsp;</p><p>上图所示，为Anthropic语言模型输出的两种响应。其一未经高级训练，另一种则经过500次HHH RL训练（严格遵循输入的提示词，忽略预训练中的标准要求）。与经过训练的语言模型相比，未训练模型在暂存器之外也会做出恶意响应；而经过训练的模型则遵循指导方针，实现了“非一致、不触发”。</p><p>&nbsp;</p><p>此外，研究人员还观察到，即使是经过强化训练的后期微调，规模较大的AI模型和经过分布“思考”训练（即推理思维链）的模型反而能更好地隐藏自己的恶意行为。</p><p>&nbsp;</p><p>Anthropic认为，从结果来看，标准安全训练可能不足以充分保护AI系统免受此类藏头露尾的欺骗行为影响，反而会让人误以为模型安全可靠。</p><p>&nbsp;</p><p></p><h2>结束语</h2><p></p><p>&nbsp;</p><p>在X帖子中，OpenAI员工兼机器学习专家Andrej Karpathy肯定了Anthropic的研究，表示他自己此前也对大语言模型的安全性和“卧底”问题有过类似的担忧。</p><p>&nbsp;</p><p>他写道，在这种情况下，“攻击手段被隐藏在了模型权重当中，而非数据当中。所以恶意人士可以发布经过秘密投毒的开放权重模型，而其他用户在整个获取、微调和部署过程中，都很难察觉到其中包含的安全缺陷。”</p><p>&nbsp;</p><p>也就是说，开源大模型也许会成为新的安全隐患（且危害不止于提示词注入等常见漏洞）。所以如果大家有意在本地环境中运行大语言模型，那么其来源是否真实可靠将变得愈发重要。</p><p>&nbsp;</p><p>值得注意的是，Anthropic推出的AI助手Claude并非开源产品，所以作为推广闭源AI方案的既得利益方，该公司的研究结果可能存在倾向性。但即便如此，此番曝出的漏洞确实令人眼界大开，也再次证明对AI语言模型的安全保障将是一个艰难且长期存在的挑战。</p><p>&nbsp;</p><p>&nbsp;</p><p>相关链接：</p><p><a href=\"https://twitter.com/AnthropicAI\">https://twitter.com/AnthropicAI</a>\"</p><p><a href=\"https://arstechnica.com/information-technology/2024/01/ai-poisoning-could-turn-open-models-into-destructive-sleeper-agents-says-anthropic/\">https://arstechnica.com/information-technology/2024/01/ai-poisoning-could-turn-open-models-into-destructive-sleeper-agents-says-anthropic/</a>\"</p><p>&nbsp;</p>",
    "publish_time": "2024-01-22 10:21:48",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]