[
  {
    "title": "Java 近期新闻：Micronaut 4.0、Payara 平台、Spring Web Flow 3.0、JetBrains AI 助手",
    "url": "https://www.infoq.cn/article/IB9Yr9uBTePgDazjaiJq",
    "summary": "<p></p><h2>JDK 21</h2><p></p><p>JDK 21 的&nbsp;<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-21%2B31\">Build 31</a>\"&nbsp;在上周推出了<a href=\"https://jdk.java.net/21/\">抢先体验构建</a>\"，主要提供针对 Build 30 的<a href=\"https://github.com/openjdk/jdk/compare/jdk-21%2B30...jdk-21%2B31\">升级</a>\"和对多项<a href=\"https://bugs.openjdk.org/issues/?jql=project%20%3D%20JDK%20AND%20fixversion%20%3D%2021%20and%20%22resolved%20in%20build%22%20%3D%20b31%20order%20by%20component%2C%20subcomponent\">问题</a>\"的修复。关于该构建的更多信息可参见<a href=\"https://jdk.java.net/21/release-notes\">发布说明</a>\"。</p><p></p><h2>JDK 22</h2><p></p><p>JDK 22 的&nbsp;<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-22%2B6\">Build 6</a>\"&nbsp;也于上周推出了<a href=\"https://jdk.java.net/22/\">抢先体验</a>\"构建，提供针对 Build 5 的<a href=\"https://github.com/openjdk/jdk/compare/jdk-22%2B5...jdk-22%2B6\">升级</a>\"和对多项<a href=\"https://bugs.openjdk.org/issues/?jql=project%20%3D%20JDK%20AND%20fixversion%20%3D%2022%20and%20%22resolved%20in%20build%22%20%3D%20b06%20order%20by%20component%2C%20subcomponent\">问题</a>\"的修复。关于该构建的更多信息可参见<a href=\"https://jdk.java.net/22/release-notes\">发布说明</a>\"。</p><p>开发者们欢迎到&nbsp;<a href=\"https://bugreport.java.com/bugreport/\">Java Bug 数据库</a>\"中反馈在&nbsp;<a href=\"https://openjdk.org/projects/jdk/22/\">JDK 22</a>\"&nbsp;及&nbsp;<a href=\"https://openjdk.java.net/projects/jdk/21/\">JDK 21</a>\"&nbsp;中遇到的问题。</p><p></p><h2>Spring 框架</h2><p></p><p><a href=\"https://spring.io/projects/spring-webflow\">Spring Web Flow</a>\"&nbsp;3.0.0 版本<a href=\"https://spring.io/blog/2023/07/13/spring-web-flow-3-0-0-released\">发布</a>\"，主要提供：与 Spring 框架 6 和 Jakarta EE 的兼容；移除已退役且未被迁移至 Jakarta EE 的<a href=\"https://tiles.apache.org/\">阿帕奇 Tiles</a>\"&nbsp;项目；<a href=\"https://github.com/spring-projects/spring-webflow-samples/blob/main/README.md\">Spring Web Flow</a>\"&nbsp;示例也进行了对应的更新，<a href=\"https://github.com/spring-projects/spring-webflow-samples/blob/main/booking-mvc/README.md\">booking-mvc</a>\"&nbsp;示例现使用&nbsp;<a href=\"https://www.thymeleaf.org/doc/articles/layouts.html\">Thymeleaf 布局</a>\"而非原本的阿帕奇 Tiles。</p><p></p><p><a href=\"https://spring.io/projects/spring-framework\">Spring 框架</a>\"&nbsp;6.1 的<a href=\"https://spring.io/blog/2023/07/13/spring-framework-6-1-m2-released\">第二个里程碑版本发布</a>\"，提供问题修复、文档优化、依赖升级，以及诸多新功能，其中包括：HTTP 接口客户端架构以及&nbsp;<a href=\"https://docs.spring.io/spring-framework/docs/6.1.0-SNAPSHOT/javadoc-api/org/springframework/web/client/RestTemplate.html\">RestTemplate</a>\"&nbsp;类的适配器；新增&nbsp;<a href=\"https://docs.spring.io/spring-framework/docs/6.1.0-SNAPSHOT/javadoc-api/org/springframework/web/client/RestClient.html\">RestClient</a>\"&nbsp;接口；支持在&nbsp;<a href=\"https://docs.spring.io/spring-framework/docs/6.1.0-SNAPSHOT/javadoc-api/org/springframework/scheduling/TaskScheduler.html\">TaskScheduler</a>\"&nbsp;接口中使用&nbsp;<a href=\"https://docs.spring.io/spring-framework/docs/6.1.0-SNAPSHOT/javadoc-api/org/springframework/scheduling/annotation/Scheduled.html\">@Scheduled</a>\"&nbsp;注解的多个实例。关于版本的更多信息可参见<a href=\"https://github.com/spring-projects/spring-framework/releases/tag/v6.1.0-M2\">发布说明</a>\"。</p><p></p><p>Spring 框架的 6.0.11、5.3.29 和 5.2.25.RELEASE 均已<a href=\"https://spring.io/blog/2023/07/13/spring-framework-5-2-25-release-5-3-29-and-6-0-11-available-now\">发布</a>\"，提供问题修复、文档优化、依赖升级及新功能，其中包括：简化了&nbsp;<a href=\"https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/beans/factory/support/DefaultSingletonBeanRegistry.html\">DefaultSingletonBeanRegistry</a>\"&nbsp;类中定义的&nbsp;isDepedendent()&nbsp;方法；增加了&nbsp;<a href=\"https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/http/ContentDisposition.Builder.html\">ContentDisposition.Builder</a>\"&nbsp;接口中缺失的&nbsp;@Nullable&nbsp;注解；扩展了&nbsp;<a href=\"https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/util/ObjectUtils.html\">ObjectUtils</a>\"&nbsp;方法中定义的&nbsp;nullSafeConciseToString()&nbsp;方法所支持的类型。版本 6.0.11 及 5.3.29 将分别在 Spring Boot 的 3.1.2 和 2.7.14 中使用。因 Spring Boot 2.3.x 版本<a href=\"https://spring.io/projects/spring-boot#support\">即将退役</a>\"，周期外版本 5.2.25.RELEASE 将不会随着 Spring Boot 的版本一同发布。关于版本&nbsp;<a href=\"https://github.com/spring-projects/spring-framework/releases/tag/v6.0.11\">6.0.11</a>\"、版本&nbsp;<a href=\"https://github.com/spring-projects/spring-framework/releases/tag/v5.3.29\">5.3.29</a>\"&nbsp;及&nbsp;<a href=\"https://github.com/spring-projects/spring-framework/releases/tag/v5.2.25.RELEASE\">5.2.25.RELEASE</a>\"&nbsp;的更多信息可参见发布说明。</p><p></p><p><a href=\"https://spring.io/projects/spring-data\">Spring Data</a>\"&nbsp;的<a href=\"https://spring.io/blog/2023/07/14/spring-data-2023-1-0-m1-released\">首个里程碑版本</a>\"&nbsp;2023.1.0，代号 Vaughn 发布：可与 JDK 21 兼容，支持&nbsp;<a href=\"https://kotlinlang.org/docs/inline-classes.html\">Kotlin 值类</a>\"；通过&nbsp;<a href=\"https://download.java.net/java/early_access/jdk21/docs/api/java.base/java/util/concurrent/Executor.html\">Executor</a>\"&nbsp;接口使用虚拟线程；对使用检查点协调还原（CRaC）优化的探索。关于该版本的更多细节可参见<a href=\"https://github.com/spring-projects/spring-data-commons/wiki/Spring-Data-2023.1-%28Vaughan%29-Release-Notes\">发布说明</a>\"。</p><p></p><p>Spring Data 的<a href=\"https://spring.io/blog/2023/07/14/spring-data-2023-0-2-2022-0-8-and-2021-2-14-available-now\">服务版本</a>\"&nbsp;2023.0.2、2022.0.8 及 2021.2.14 发布，提供问题修复以及对应子项目的依赖升级，其中包括：Spring Data MongoDB 4.1.2、4.0.8 及 3.4.14；Spring Data Elasticsearch 5.1.2、5.0.8 及 4.4.14；Spring Data Neo4j 7.1.2、7.0.8 及 6.3.14。</p><p></p><p><a href=\"https://spring.io/projects/spring-hateoas\">Spring HATEOAS</a>\"&nbsp;的<a href=\"https://spring.io/blog/2023/07/14/spring-hateoas-1-5-5-2-0-5-2-1-1-and-2-2-m1-released\">服务版本</a>\"&nbsp;2.2.0-M1、2.1.1、2.0.5 及 1.5.5 发布，提供问题修复、依赖升级，以及针对<a href=\"https://spring.io/security/cve-2023-34036\">利用 WebFlux 上的 Spring HATEOAS 进行转发头漏洞利用</a>\"（CVE-2023-34036）的修复。该漏洞中 Spring HATEOAS 所生成的基于超媒体的响应如果没有可信的代理，可能会暴露于恶意的转发头。关于这些版本的更多信息可参见版本&nbsp;<a href=\"https://github.com/spring-projects/spring-hateoas/releases/tag/2.2.0-M1\">2.2.0-M1</a>\"、<a href=\"https://github.com/spring-projects/spring-hateoas/releases/tag/2.1.1\">版本 2.1.1</a>\"、<a href=\"https://github.com/spring-projects/spring-hateoas/releases/tag/2.0.5\">版本 2.0.5</a>\"&nbsp;及<a href=\"https://github.com/spring-projects/spring-hateoas/releases/tag/1.5.5\">版本 1.5.5</a>\"&nbsp;的发布说明。</p><p></p><p><a href=\"https://start.spring.io/\">Spring Initializr</a>\"&nbsp;版本 0.20.0&nbsp;<a href=\"https://spring.io/blog/2023/07/11/spring-initializr-0-20-0-available-now\">发布</a>\"，提供新功能及优化项，其中包括：对 Spring Boot 3.x 及 JDK 17 的支持；优化代码生成，现可使用&nbsp;<a href=\"https://docs.spring.io/initializr/docs/current/api/io/spring/initializr/generator/language/CodeBlock.html\">CodeBlock</a>\"&nbsp;定义方法体内的任意语句；嵌套注解；支持 Gradle 8.x 版本；优化构建及原始文本断言。关于该版本的更多信息可参见<a href=\"https://github.com/spring-io/initializr/wiki/Spring-Initializr-0.20-Release-Notes\">发布说明</a>\"。</p><p></p><h2>Micronaut</h2><p></p><p>在五个里程碑版本及一个候选版本发布后，Micronaut 基金会现已<a href=\"https://micronaut.io/2023/07/14/micronaut-framework-4-0-0-released/\">发布</a>\"<a href=\"https://micronaut.io/\">Micronaut 框架</a>\"&nbsp;4.0.0，提供针对 JDK 17、Groovy 4.0、Kotlin 1.8 及 Gradle 8.x 版本的基线。</p><p></p><p>此外，也有对 GraalVM 23、虚拟线程、HTTP/3 及 io_uring 的支持。新版本中还引入了：允许开发者在注解中添加表达式的<a href=\"https://docs.micronaut.io/latest/guide/#evaluatedExpressions\">表达式语言</a>\"；<a href=\"https://guides.micronaut.io/latest/micronaut-http-client.html\">Micronaut HTTP Client</a>\"&nbsp;轻量级实现的新&nbsp;<a href=\"https://openjdk.org/groups/net/httpclient/intro.html\">Java HTTP Client</a>\"，可替代目前<a href=\"https://docs.micronaut.io/latest/guide/#nettyHttpClient\">基于 Netty</a>\"&nbsp;的实现。关于该版本的更多细节可参见<a href=\"https://github.com/micronaut-projects/micronaut-platform/releases/tag/v4.0.0\">发布说明</a>\"，InfoQ 将跟进更为详细的新闻报道。</p><p></p><h2>Payara</h2><p></p><p>Payara 已<a href=\"https://blog.payara.fish/whats-new-in-the-july-2023-payara-platform-release\">发布</a>\"&nbsp;<a href=\"https://www.payara.fish/\">Payara 平台</a>\"的 2023年七月版本，其中包括社区版的 6.2023.7 版本、企业版的 6.4.0 版本及 5.53.0 版本，提供问题修复与组件升级，其中包括可为每个套接字保持连接配置添加套接字选项的 Hazelcast 版本 5.3.1。然而，Hazelcast&nbsp;<a href=\"https://docs.hazelcast.com/hazelcast/5.3/clusters/network-configuration#configuring-tcp-keep-alive\">称</a>\"这一改动暂未上线 Windows 操作系统。此外，通过移除未使用的 POM 文件、过时的Jakarta 临时暂存库以及 jdk8 配置文件，改善了 POM 和 BOM 的重复问题。关于这些版本的更多信息可参见<a href=\"https://docs.payara.fish/community/docs/Release%20Notes/Release%20Notes%206.2023.7.html\">社区版 6.2023.7</a>\"、<a href=\"https://docs.payara.fish/enterprise/docs/Release%20Notes/Release%20Notes%206.4.0.html\">企业版 6.4.0</a>\"&nbsp;和<a href=\"https://docs.payara.fish/enterprise/docs/Release%20Notes/Release%20Notes%205.53.0.html\">企业版 5.53.0</a>\"&nbsp;的发布说明。</p><p></p><h2>Open Liberty</h2><p></p><p>IBM&nbsp;<a href=\"https://openliberty.io/blog/2023/07/11/23.0.0.7-beta.html\">发布</a>\"了&nbsp;<a href=\"https://openliberty.io/\">Open Liberty</a>\"&nbsp;的 23.0.0.7-beta 版本，其中包含对&nbsp;<a href=\"https://jakarta.ee/specifications/data/\">Jakarta Data</a>\"&nbsp;规范&nbsp;<a href=\"https://github.com/jakartaee/data/releases/tag/1.0.0-b2\">1.0.0-beta2 版本</a>\"的测试实现，以便于开发者尝试这些功能并提供反馈，从而影响规范的开发。Jakarta Data 的 1.0.0 版本已通过计划审查，很可能被纳入 Jakarta EE 11 版本，并计划于2024年第一季度发布 GA 版本。</p><p></p><h2>Helidon</h2><p></p><p>Oracle 已提供&nbsp;<a href=\"https://helidon.io/\">Helidon</a>\"&nbsp;的<a href=\"https://twitter.com/helidon_project/status/1679533754220519424\">第二点发布</a>\"&nbsp;2.6.2 版本，主要提供依赖升级和关键问题修复，其中包含：<a href=\"https://github.com/helidon-io/helidon/blob/helidon-3.x/webserver/webserver/src/test/java/io/helidon/webserver/CipherSuiteTest.java\">CipherSuiteTest</a>\"&nbsp;类中的间歇性故障；避免异常信息中回显用户数据；WebServer 组件在没有实体的情况下不应被分块。关于该版本的更多信息可参见<a href=\"https://github.com/helidon-io/helidon/releases/tag/2.6.2\">发布说明</a>\"。</p><p></p><h2>Hibernate</h2><p></p><p><a href=\"https://hibernate.org/reactive/\">Hibernate Reactive</a>\"&nbsp;的 2.0.3.Final 版本<a href=\"https://in.relation.to/2023/07/13/hibernate-reactive-2_0_3_Final/\">发布</a>\"为<a href=\"https://hibernate.org/reactive/documentation/2.0/javadocs/org/hibernate/reactive/mutiny/Mutiny.Session.html\">Mutiny.Session</a>\"&nbsp;及&nbsp;<a href=\"https://hibernate.org/reactive/documentation/2.0/javadocs/org/hibernate/reactive/stage/Stage.Session.html\">Stage.Session</a>\"&nbsp;接口交付了新的&nbsp;getFactory()&nbsp;方法，可分别用于生成&nbsp;<a href=\"https://hibernate.org/reactive/documentation/2.0/javadocs/org/hibernate/reactive/mutiny/Mutiny.SessionFactory.html\">Mutiny.SessionFactory</a>\"&nbsp;和&nbsp;<a href=\"https://hibernate.org/reactive/documentation/2.0/javadocs/org/hibernate/reactive/stage/Stage.SessionFactory.html\">Stage.SessionFactory</a>\"&nbsp;类的实例。关于该版本的更多信息可参见<a href=\"https://github.com/hibernate/hibernate-reactive/releases/tag/2.0.3\">发布说明</a>\"。</p><p></p><h2>阿帕奇软件基金会</h2><p></p><p>阿帕奇软件基金会已于上周发布<a href=\"https://tomcat.apache.org/\">阿帕奇 Tomcat</a>\"&nbsp;的&nbsp;<a href=\"https://www.mail-archive.com/announce@apache.org/msg08334.html\">11.0.0-M9</a>\"、<a href=\"https://www.mail-archive.com/announce@apache.org/msg08331.html\">10.1.11</a>\"、<a href=\"https://www.mail-archive.com/announce@apache.org/msg08329.html\">9.0.78</a>\"&nbsp;及&nbsp;<a href=\"https://www.mail-archive.com/announce@apache.org/msg08332.html\">8.5.91</a>\"&nbsp;版本。四个版本中均提供问题修复并引入新的类：可用于创建上下文命名信息环境条目的监听器&nbsp;<a href=\"https://tomcat.apache.org/tomcat-11.0-doc/api/org/apache/catalina/core/ContextNamingInfoListener.html\">ContextNamingInfoListener</a>\"；可用于从属性文件中获取上下文角色映射的监听器&nbsp;<a href=\"https://tomcat.apache.org/tomcat-11.0-doc/api/org/apache/catalina/core/PropertiesRoleMappingListener.html\">PropertiesRoleMappingListener</a>\"。11.0.0-M9 版本更新了&nbsp;<a href=\"https://jakarta.ee/specifications/expression-language/\">Jakarta 表达式语言</a>\"及&nbsp;<a href=\"https://jakarta.ee/specifications/websocket/\">Jakarta WebSocket</a>\"&nbsp;规范的实现，以保持与 Jakarta EE 11 最新计划变更的一致性。关于这些版本的更多信息请参见&nbsp;<a href=\"http://tomcat.apache.org/tomcat-11.0-doc/changelog.html\">11.0.0-M9 版本</a>\"、<a href=\"http://tomcat.apache.org/tomcat-10.1-doc/changelog.html\">10.1.11版本</a>\"、<a href=\"https://tomcat.apache.org/tomcat-9.0-doc/changelog.html\">9.0.78 版本</a>\"及&nbsp;<a href=\"https://tomcat.apache.org/tomcat-8.5-doc/changelog.html\">8.5.91 版本</a>\"的发布说明。</p><p></p><h2>Micrometer</h2><p></p><p><a href=\"https://github.com/micrometer-metrics/micrometer/blob/main/README.md\">Micrometer 指标</a>\"&nbsp;的 1.12.0-M1、1.11.2、1.10.9 及 1.9.13 版本现已发布，主要提供依赖升级及关键问题修复，其中包括：Micrometer&nbsp;<a href=\"https://docs.wavefront.com/micrometer.html\">Wavefront</a>\"&nbsp;在默认&nbsp;uri&nbsp;实现下的集成代理错误；移除了&nbsp;<a href=\"https://github.com/micrometer-metrics/micrometer/blob/main/micrometer-core/src/main/java/io/micrometer/core/instrument/binder/logging/LogbackMetrics.java\">LogbackMetrics</a>\"&nbsp;类中禁用日志级别的非必要&nbsp;<a href=\"https://download.java.net/java/early_access/jdk21/docs/api/java.base/java/lang/ThreadLocal.html\">ThreadLocal</a>\"&nbsp;开销；<a href=\"https://javadoc.io/doc/io.micrometer/micrometer-observation/latest/io/micrometer/observation/contextpropagation/ObservationThreadLocalAccessor.html\">ObservationThreadLocalAccessor</a>\"&nbsp;类中定义的&nbsp;setValue()&nbsp;方法在无当前作用域时生成的&nbsp;NullPointerException。1.12.0-M1 版本中的新功能有：通过&nbsp;ObservationThreadLocalAccessor&nbsp;类注册 Micrometer 观测结果时可配置基本时间单位；优化阿帕奇&nbsp;<a href=\"https://hc.apache.org/httpcomponents-asyncclient-4.1.x/current/httpasyncclient/apidocs/org/apache/http/nio/client/HttpAsyncClient.html\">HttpAsyncClient</a>\"&nbsp;接口实例，使用&nbsp;<a href=\"https://javadoc.io/doc/io.micrometer/micrometer-core/latest/io/micrometer/core/instrument/binder/httpcomponents/hc5/MicrometerHttpClientInterceptor.html\">MicrometerHttpClientInterceptor</a>\"&nbsp;以避免计量表的读写错误。关于这些发布的更多信息可参见&nbsp;<a href=\"https://github.com/micrometer-metrics/micrometer/releases/tag/v1.12.0-M1\">1.12.0-M1 版本</a>\"、<a href=\"https://github.com/micrometer-metrics/micrometer/releases/tag/v1.11.2\">1.11.2 版本</a>\"、<a href=\"https://github.com/micrometer-metrics/micrometer/releases/tag/v1.10.9\">1.10.9 版本</a>\"和&nbsp;<a href=\"https://github.com/micrometer-metrics/micrometer/releases/tag/v1.9.13\">1.9.13 版本</a>\"的发布说明。</p><p></p><p>同样，<a href=\"https://github.com/micrometer-metrics/tracing/blob/main/README.md\">Micrometer 追踪</a>\"&nbsp;的 1.2.0-M1 版本、1.1.3 版本及 1.0.8 版本也已发布，主要提供问题修复、依赖升级以及如下新功能：为基础跟踪操作额外提供&nbsp;<a href=\"https://github.com/openjdk/jmh/blob/master/README.md\">Java 微基准测试框架</a>\"（JMH）基准；为&nbsp;<a href=\"https://javadoc.io/doc/io.micrometer/micrometer-tracing/latest/io/micrometer/tracing/exporter/FinishedSpan.html\">FinishedSpan</a>\"&nbsp;接口新增&nbsp;getDuration()&nbsp;方法。关于这些版本的更多信息可参见&nbsp;<a href=\"https://github.com/micrometer-metrics/tracing/releases/tag/v1.2.0-M1\">1.2.0-M1 版本</a>\"、<a href=\"https://github.com/micrometer-metrics/tracing/releases/tag/v1.1.3\">1.1.3 版本</a>\"及&nbsp;<a href=\"https://github.com/micrometer-metrics/tracing/releases/tag/v1.0.8\">1.0.8 版本</a>\"的发布说明。</p><p></p><h2>Piranha</h2><p></p><p><a href=\"https://piranha.cloud/\">Piranha</a>\"&nbsp;的 23.7.0 版本<a href=\"https://github.com/piranhacloud/piranha/releases/tag/v23.7.0\">发布</a>\"，提供关键变更如：从JBoss Jandex 到&nbsp;<a href=\"https://smallrye.io/blog/jandex-3-0-0/\">SmallRye Jandex</a>\"&nbsp;的迁移；在已有&nbsp;<a href=\"https://javadoc.io/doc/cloud.piranha/project/23.2.0/cloud.piranha.feature.api/cloud/piranha/feature/api/Feature.html\">Feature</a>\"&nbsp;接口基础上新增&nbsp;<a href=\"https://github.com/piranhacloud/piranha/blob/current/feature/api/src/main/java/cloud/piranha/feature/api/FeatureManager.java\">FeatureManager</a>\"&nbsp;接口；新增&nbsp;<a href=\"https://github.com/piranhacloud/piranha/blob/current/feature/crac/src/main/java/cloud/piranha/feature/crac/CracFeature.java\">CracFeature</a>\"&nbsp;类，支持<a href=\"https://wiki.openjdk.org/display/crac\">项目 CRaC</a>\"。关于该版本的更多信息可参见该项目的<a href=\"https://javadoc.io/doc/cloud.piranha/project/latest/index.html\">文档</a>\"和<a href=\"https://github.com/piranhacloud/piranha/issues?q=is%3Aissue+-label%3Awontfix+milestone%3A23.7.0+is%3Aclosed\">问题追踪</a>\"。</p><p></p><h2>Reactor 项目</h2><p></p><p><a href=\"https://github.com/reactor/reactor/blob/main/README.md\">Reactor 项目</a>\"的<a href=\"https://github.com/reactor/reactor/releases/tag/2023.0.0-M1\">首个里程碑版本</a>\"&nbsp;2023.0.0 发布，提供对&nbsp;reactor-core&nbsp;3.6.0-M1 版本的依赖升级。此外，在针对 2023.0.0-M1 版本的调整中，reactor-netty&nbsp;1.1.9、reactor-kafka&nbsp;1.3.19、reactor-pool&nbsp;1.0.1、reactor-addons&nbsp;3.5.1 及&nbsp;reactor-kotlin-extensions&nbsp;1.2.2 则保持不变。有关该版本的更多信息可参见<a href=\"https://github.com/reactor/reactor/compare/2022.0.9...2023.0.0-M1\">更新日志</a>\"。</p><p></p><p>与之类似，Project Reactor 的<a href=\"https://github.com/reactor/reactor/releases/tag/2022.0.9\">第九维护版本</a>\"&nbsp;2022.0.9 也对&nbsp;reactor-core&nbsp;3.5.8、reactor-netty&nbsp;1.1.9、reactor-kafka&nbsp;1.3.19 及&nbsp;reactor-pool&nbsp;1.0.1 进行了依赖升级。在对 2022.0.9 版本的调整中，reactor-addons&nbsp;3.5.1 及&nbsp;reactor-kotlin-extensions&nbsp;1.2.2 保持不变。关于该版本的更多信息可查看<a href=\"https://github.com/reactor/reactor/compare/2022.0.8...2022.0.9\">更新日志</a>\"。</p><p></p><h2>JHipster</h2><p></p><p><a href=\"https://www.jhipster.tech/\">JHipster</a>\"&nbsp;的<a href=\"https://twitter.com/mraible/status/1679249296032665601\">第二 beta 版本</a>\"&nbsp;8.0.0 交付了问题修复及关键变更，其中包括：删除未使用的&nbsp;HttpServletRequest&nbsp;接口导入；移除&nbsp;spring-boot-maven-plugin&nbsp;中的&nbsp;&nbsp;参数，该参数对插件而言处于未知且会导致告警；优化 Heroku sub-generator。关于该版本的更多信息可参见<a href=\"https://github.com/jhipster/generator-jhipster/releases/tag/v8.0.0-beta.2\">发布说明</a>\"。</p><p></p><p><a href=\"https://www.jhipster.tech/jhipster-lite/\">JHipster Lite</a>\"&nbsp;的&nbsp;<a href=\"https://twitter.com/pascalgrimaud/status/1680275261114183683\">0.38.0</a>\"&nbsp;及&nbsp;<a href=\"https://twitter.com/pascalgrimaud/status/1678535579246403584\">0.37.0</a>\"&nbsp;版本现已发布，提供众多依赖升级和如下新功能：<a href=\"https://www.npmjs.com/package/prettier-plugin-svelte\">Prettier for Svelte 3</a>\"&nbsp;的组件升级；支持深色模式。关于这些版本的更多信息可参见&nbsp;<a href=\"https://github.com/jhipster/jhipster-lite/releases/tag/v0.37.0\">0.37.0 版本</a>\"及&nbsp;<a href=\"https://github.com/jhipster/jhipster-lite/releases/tag/v0.38.0\">0.37.0 版本</a>\"的发布说明。</p><p></p><h2>Yupiik</h2><p></p><p><a href=\"https://www.yupiik.io/fusion/\">Yupiik Fusion</a>\"&nbsp;的版本 1.0.5 提供：对无上下文数据库的支持；未找到或忽略 JSON 模块时提供了更精确的错误信息；优化&nbsp;resources.json&nbsp;及&nbsp;native-image.properties&nbsp;文件生成，以包含 Fusion JSON 元数据。关于该版本的更多信息可参见<a href=\"https://github.com/yupiik/fusion/releases/tag/fusion-1.0.5\">发布说明</a>\"。</p><p></p><h2>Maven</h2><p></p><p><a href=\"https://maven.apache.org/\">Maven</a>\"&nbsp;的<a href=\"https://github.com/apache/maven/releases/tag/maven-4.0.0-alpha-7\">第七 alpha 版本</a>\"&nbsp;4.0.0 主要提供以下变动：支持 JDK 20；将内部&nbsp;<a href=\"https://github.com/apache/maven-shared-utils/blob/master/src/main/java/org/apache/maven/shared/utils/StringUtils.java\">StringUtils</a>\"&nbsp;类迁移至<a href=\"https://commons.apache.org/proper/commons-lang/\">阿帕奇 Commons Lang</a>\"&nbsp;所提供的&nbsp;<a href=\"https://commons.apache.org/proper/commons-lang/apidocs/org/apache/commons/lang3/StringUtils.html\">StringUtils</a>\"&nbsp;类。将&nbsp;<a href=\"https://github.com/codehaus-plexus/plexus-utils/blob/master/README.md\">Plexus-Utils</a>\"&nbsp;提供的&nbsp;<a href=\"https://github.com/sonatype/plexus-utils/blob/master/src/main/java/org/codehaus/plexus/util/FileUtils.java\">FileUtils</a>\"&nbsp;类迁移至<a href=\"https://commons.apache.org/proper/commons-io/\">阿帕奇 Commons IO</a>\"&nbsp;所提供的&nbsp;<a href=\"https://commons.apache.org/proper/commons-io/apidocs/org/apache/commons/io/FileUtils.html\">FileUtils</a>\"&nbsp;类。</p><p></p><h2>Gradle</h2><p></p><p><a href=\"https://gradle.org/\">Gradle</a>\"&nbsp;<a href=\"https://github.com/gradle/gradle/releases/tag/v8.2.1\">补丁版本</a>\"&nbsp;8.2.1 发布，提供 Gradle 8.2 版本中的关键问题，如：使用 Gradle 8.2 和 Quarkus 2.16.7 构建应用程序时的&nbsp;StackOverflowError&nbsp;异常；Micronaut&nbsp;JacocoReportAggregationPlugin&nbsp;崩溃；--no-feature&nbsp;标志中&nbsp;false&nbsp;值错误，应被设置为&nbsp;true。</p><p></p><h2>JetBrains</h2><p></p><p>JetBrains 在其所有基于 IntelliJ 的集成开发环境中都<a href=\"https://blog.jetbrains.com/idea/2023/06/ai-assistant-in-jetbrains-ides/\">引入</a>\"了新的人工智能助手。该服务由 IntelliJ 的<a href=\"https://www.jetbrains.com/legal/docs/terms/jetbrains-ai/service-providers/\">人工智能供应商</a>\"（目前仅有 OpenAI）赋能，将开发者与“不同大语言模型（LLM）”透明相连，“在 JetBrains 的多项产品中启用特定的人工智能化功能”。需注意，.NET 版本的工具仍处于开发阶段；在 EAP 阶段可免费使用；许可和定价模型将于后期推出；目前可能会受等候名单限制。有关 .NET 环境中的人工智能助手信息可参见 InfoQ 的<a href=\"https://www.infoq.com/news/2023/07/ai-assistant-resharper/\">详细报道</a>\"。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/07/java-news-roundup-jul10-2023/\">Java News Roundup: Micronaut 4.0, Payara Platform, Spring Web Flow 3.0, JetBrains AI Assistant</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/yO6pjms5izsxK5YrZ036\">开源 Java 性能分析器比较：VisualVM、JMC 和 async-profiler</a>\"</p><p><a href=\"https://www.infoq.cn/article/1NdPKQpZJGmKxm2v6SP2\">JDK 21 中的结构化并发：并发编程的一次飞跃</a>\"</p>",
    "publish_time": "2023-07-31 09:31:43",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "DevOps是否已死？AI和大语言模型给云计算和DevOps带来了哪些影响？｜InfoQ趋势报告",
    "url": "https://www.infoq.cn/article/22iU97szqsrquqVhrCvJ",
    "summary": "<p></p><h1>关键要点</h1><p></p><p></p><p>云计算创新已经从革命性阶段过渡到了进化性阶段，重点在于迁移和重构工作负载。云计算已经发展到可以提供对可伸缩资源和托管服务的按需访问，并重视简化交互和减轻团队的认知负担。通过降低认知负载和为即时管理、工单系统和代码生成等任务提供支持，人工智能（AI）和大型语言模型（LLMs）可能在云计算和DevOps领域发挥重要作用。主要的云计算供应商，如微软、谷歌和亚马逊云科技等，已经将AI集成到他们的产品和服务中，充分展示了行业在AI技术上的投入。受基于AI和类似ChatGPT的产品的影响，低代码和无代码领域开始为业务用户和软件工程团队提供协作机会。平台工程采用了平台即服务的思维方式，正朝着简化和价值交付的方向发展。平台工程团队的角色正在从复杂基础设施的管理者转变为专注于用户满意度和价值创造的服务提供者。对可观察性、财务相关性和可持续性的考量正在成为平台工程不可或缺的部分。OpenTelemetry被广泛用于收集指标和基于事件的可观察性数据，成为行业事实上的标准。它的标准化特性促进了供应商之间的优化和创新。对可持续性和绿色计算的关注推动了架构选择朝着效率和最小化碳足迹的方向发展。站点可靠性工程（SRE）团队在分析环境影响和推动可持续性倡议方面起到至关重要的作用。</p><p>&nbsp;</p><p>InfoQ趋势报告为架构师和技术领导者们关注的主题提供了有见解的概述。此外，它们还有助于InfoQ编辑团队撰写新闻和<a href=\"https://www.infoq.com/write-for-infoq/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">招募文章作者</a>\"来报道创新技术。</p><p>&nbsp;</p><p>除了报告内容和新的DevOps与云计算发展趋势图之外，还有一个配套的<a href=\"https://www.infoq.com/podcasts/cloud-devops-trends-2023/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">播客</a>\"，InfoQ编辑和一些朋友在博客中讨论了这些发展趋势。</p><p>&nbsp;</p><p></p><h1>趋势图更新</h1><p></p><p>&nbsp;</p><p>本报告的后面部分会有更多细节，但我们先来总结一下与去年的趋势图相比有哪些变化。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/52/5205e565e25a8c5ea0f0edba519da720.png\" /></p><p></p><p>&nbsp;FinOps，即高效管理云成本的实践，正向着早期大众的方向发展。FinOps基金会和一些云供应商，如微软、AWS和谷歌，在推动FinOps实践的采用，这些实践符合可持续性和优化资源使用的目标。最近，谷歌<a href=\"https://cloud.google.com/blog/topics/cost-management/google-cloud-is-officially-a-finops-certified-service-provider?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">成为</a>\"了FinOps认证服务提供商，微软也作为首席成员<a href=\"https://www.infoq.com/news/2023/02/microsoft-joins-finops-org/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">加入</a>\"了FinOps组织。</p><p>&nbsp;</p><p><a href=\"https://webassembly.org/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">WebAssembly</a>\"（Wasm）的持续演进正兑现着在云中实现“一次编写，到处运行”的承诺，提供了不同语言和平台之间的可重用性和互操作性。<a href=\"https://ebpf.io/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">eBPF</a>\"（Extended Berkeley Packet Filter）在可观察性和内核级别的安全性等领域受到关注。</p><p>&nbsp;</p><p>我们发现，通用<a href=\"https://en.wikipedia.org/wiki/Function_as_a_service?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">函数即服务</a>\"（FaaS）和<a href=\"https://en.wikipedia.org/wiki/Backend_as_a_service?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">后端即服务</a>\"（BaaS）的概念在“晚期大众”用户中受到了关注。无服务器技术的采用已经变得普遍。 “我们是100%无服务器”的说法不再像以前那样令人感到惊讶，因为无服务器已经成为行业采用的主流方法。</p><p>&nbsp;</p><p></p><h1>云计算是否从革命转向了进化阶段？DevOps是否已死？</h1><p></p><p>&nbsp;</p><p>在配套的云计算和DevOps趋势播客讨论中，与会者讨论了云创新和DevOps的现状。他们一致认为，云创新已经放缓，从“革命”转向了“进化”。虽然大量的组织已经采用了云技术，但还有许多企业想要迁移和重新架构工作负载。</p><p>&nbsp;</p><p>至于DevOps，它仍然还活着，但在一些组织中已经进入了停滞阶段。DevOps旨在通过提供自主权来创造业务价值的概念仍然存在，但在实现方面面临着挑战。与会者表达了他们对通过<a href=\"https://www.infoq.com/articles/value-stream-management/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">价值流管理</a>\"来解锁DevOps流程和价值实现的兴趣。</p><p>&nbsp;</p><p>公有云供应商已经从他们最初的目标——提供对可伸缩资源的按需访问——转变为更加关注提供托管服务。这种转变使得云计算变得更加普遍。然而，技术围绕着已有的服务在迅速发生变化，新的业务需求和挑战随之涌现。团队必须在不断交付业务价值和采用、更新技术栈之间做出平衡。InfoQ首席DevOps编辑<a href=\"https://twitter.com/BeardedCoder?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">Matthew Campbell</a>\"说：</p><p>&nbsp;</p><p></p><blockquote>企业也想快速演进和适应变化……我们现在处于这样的一个阶段，我们正在试图弄清楚我们如何能够可持续地利用我们发明和创造的所有东西和交互方式，并达到一种我们可以舒适地进行创新的阶段。</blockquote><p></p><p>&nbsp;</p><p>此外，云服务现在已经在小型和大型组织中得到了广泛的采用，甚至进入了晚期采用者阶段，而新冠疫情通常是其中的一个驱动因素。例如，自动化配置环境的演进——快速配置完整的开发和测试环境的能力现在已经变得很普遍。然而，弥合开发和运维之间的差距仍然存在挑战。身份和访问管理问题在开发和运维团队之间造成了一个感知上的边界。</p><p>&nbsp;</p><p></p><h1>AI和大语言模型给云计算和DevOps带来了哪些影响？</h1><p></p><p>&nbsp;</p><p>与会者讨论了<a href=\"https://www.infoq.com/articles/reduce-cognitive-load-devops-teams/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">认知过载</a>\"以及AI如何帮助降低认知负载。他们提到了一种特定的AI应用，叫作<a href=\"https://en.wikipedia.org/wiki/Artificial_Intelligence_for_IT_Operations?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">AIOps</a>\"，一种专注于IT运维的AI，在即时管理和工单系统方面表现出了有效性。大语言模型提供了实实在在的好处，例如使用ChatGPT来验证信息、生成教学笔记、辅助写作和创作。微软已经将AI集成到其产品和服务中，展示了其在AI技术方面的重大投入。InfoQ首席云编辑<a href=\"https://twitter.com/SteefJan?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">Steef-Jan Wiggers</a>\"说：</p><p>&nbsp;</p><p></p><blockquote>微软提供的很多服务，甚至最近的一些服务，如<a href=\"https://www.infoq.com/news/2018/07/azure-service-fabric-mesh/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">Fabric</a>\"，一个完整的SaaS数据湖解决方案，都充分融合了AI。</blockquote><p></p><p>&nbsp;</p><p>Fabric只是其中的一个例子，其他公有云供应商也推出了AI融合服务，如亚马逊的<a href=\"https://aws.amazon.com/pm/sagemaker/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">Sagemaker</a>\"和<a href=\"https://cloud.google.com/products/ai?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">谷歌的Vertex AI和AutoML</a>\"。想了解有关OpenAI的信息，可以关注InfoQ的<a href=\"https://www.infoq.com/openai/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">这个主题</a>\"。</p><p>&nbsp;</p><p></p><h1>基于AI和类似ChatGPT的产品给低代码和无代码带来了哪些影响？</h1><p></p><p>&nbsp;</p><p>将AI集成到低代码工具中是一个商业机会，AI将为业务用户提供安全和有价值的知识。这缓解了人们之前对影子IT的担忧，并促进了产品管理和软件工程团队之间的协作。</p><p>&nbsp;</p><p>此外，还有一个叫作“ClickOps”的概念，即用户在<a href=\"https://www.infoq.com/low-code/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">低代码平台</a>\"上能够通过点击实现交互，同时生成可控制版本、声明式和可适应的代码。例如，一些改进了AI代码生成能力的工具，如<a href=\"https://github.com/features/copilot?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">GitHub Copilot</a>\"和<a href=\"https://codeium.com/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">Codeium</a>\"，可以生成符合组织标准、具有可读性且可以不断演进的代码。大语言模型和AI驱动的代码生成能力的演进将为低代码领域带来令人兴奋的改变。</p><p>&nbsp;</p><p>最后，低代码环境中的数据治理和访问管理是必不可少的。它带来了一些挑战，比如在确保适当的治理和合规性的同时，为业务用户提供数据访问能力。Campbell指出，我们有必要在低代码增强平台工程中建立一个“DevOpsy”治理层，提供安全防护，防止超出某些配置边界。</p><p>&nbsp;</p><p>此外，DevOps Institute的DevOps战略顾问<a href=\"https://twitter.com/HelenHappyBee?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">Helen Beal</a>\"补充说：</p><p>&nbsp;</p><p></p><blockquote>我觉得很有趣的是，我们正处在一个转弯处，因为AI实际上是在支持商业人士，为他们提供可能是安全的知识。</blockquote><p></p><p>&nbsp;</p><p></p><h1>平台工程将如何演进？</h1><p></p><p>&nbsp;</p><p>平台工程的演进涉及向简化、关注价值交付和采用平台即服务思维方式的转变。这种变化涉及提供自助式平台、隐藏复杂性并减少应用程序开发者的认知负担。平台工程团队的角色正在从复杂基础设施的维护者转变为对组织其他部分提供服务的服务提供者。他们现在专注于处理与开发者关系、营销和客户参与度相关的问题，提升用户体验和驱动价值创造。</p><p>&nbsp;</p><p>Syntasso首席工程师<a href=\"https://twitter.com/a_bangser?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">Abby Bangser</a>\"解释说：</p><p>&nbsp;</p><p></p><blockquote>平台工程团队正在研究开发者关系和营销应该是什么样子的，研究如何与客户互动、获取反馈并制定能够满足他们需求的路线图。</blockquote><p></p><p>&nbsp;</p><p>一些技术，如Kubernetes，正在被推到更底层的技术栈，开始越来越注重 API 接口和简化交互。此外，对可观察性的关注度也在提升，包括服务水平和关键性能指标，以及与平台使用和成本合理性相关的财务指标。总体而言，平台工程的未来在于构建能够增加价值和为用户创造愉悦体验的平台，同时满足不断变化的业务需求和约束。</p><p>&nbsp;</p><p>想要了解更多关于平台工程的信息，可以关注InfoQ的<a href=\"https://www.infoq.com/platformengineering/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">这个话题</a>\"。</p><p>&nbsp;</p><p></p><h1>FinOps是否正在转向早期大众阶段？</h1><p></p><p>&nbsp;</p><p><a href=\"https://www.finops.org/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">FinOps</a>\"，即有效管理云成本，正在转向早期大众阶段。越来越多的公司加入了FinOps基金会，也有许多工具可以支持FinOps流程。但需要注意的是，FinOps不仅仅是工具，它还涉及流程，以及对成本价值的理解。FinOps基金会和云供应商（如<a href=\"https://cloud.google.com/blog/topics/cost-management/google-cloud-is-officially-a-finops-certified-service-provider?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">谷歌</a>\"和<a href=\"https://www.infoq.com/news/2023/02/microsoft-joins-finops-org/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">微软</a>\"）积极参与这个过程，并推动FinOps实践的采用。</p><p>&nbsp;</p><p>人们对FinOps的认知也在发生改变，并引发了关于为什么要配置和运行某些云资源以及它们是否被有效利用的讨论。可持续性和GreenOps也与FinOps相关，因为成本优化的关注点与资源利用效率的目标是对齐的。AI 在FinOps方面发挥了重要作用，它可以识别未使用的数据、帮助优化存储，节省财务成本，提升环保效益。</p><p>&nbsp;</p><p></p><h1>在构建基于云的应用程序或采用DevOps实践时，架构师和开发人员是否面临着过多的安全问题？</h1><p></p><p>&nbsp;</p><p>架构师和开发人员在构建基于云的应用程序或采用DevOps实践时，面临着越来越多的安全问题。特别是开发人员，他们可能会感到左移策略让他们不堪重负，因为他们需要在整个开发过程中识别和优先考虑安全问题。</p><p>&nbsp;</p><p>虽然组织对安全的重要性有了越来越多的认识，也有来自高层的推动力来解决这些问题，但开发人员往往需要在安全需求和交付新功能的压力之间做出平衡。</p><p>&nbsp;</p><p>安全工具的不断演变也是这个领域的一个考量因素。早期的解决方案是由专家为专家而设计的，对开发人员来说不够友好。然而，越来越多的人认识到需要使用更易于访问和使用的安全工具。我们的目标是使安全成为一种赋能功能，构建出能够简化安全实现并为开发团队提供教育和支持的平台。这种方法旨在弥合专家驱动的安全实现和开发人员实际需求之间的差距。</p><p>&nbsp;</p><p></p><h1>WebAssembly（Wasm）是不是云端“一次编写，到处运行”的最终实现？</h1><p></p><p>&nbsp;</p><p>Wasm 是实现云端“一次编写，到处运行”愿景的重要一步。它承诺了可重用性和互操作性，允许开发人员用一种语言（如Go）构建库，并在用其他可以编译为 Wasm 的语言（如Rust）编写的应用程序中调用它们。</p><p>&nbsp;</p><p>有了这种云端内部的组件模型，我们可以为多个目标平台创建应用程序，包括基于ARM架构的CPU（因其性能和成本优势在云基础设施中颇受欢迎）。Wasm的采用不仅限于应用程序开发，还涉及了云平台扩展格式。它被用来扩展云原生代理、API网关和服务网格。</p><p>&nbsp;</p><p>除了 WebAssembly，作为平台组件开发者工具的eBPF也<a href=\"https://www.infoq.com/articles/ebpf-cloud-native-platforms/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">受到了关注</a>\"。虽然应用程序工程师可能不会广泛使用eBPF，但我们确实可以在包含网络和安全用例的项目中找到它的身影。它允许开发人员访问内核级别的信息，并获得对容器系统操作的见解，提高可观察性和安全能力。</p><p>&nbsp;</p><p>总而言之，WebAssembly和eBPF为提升云应用程序的可移植性、可重用性和性能带来了有趣的可能性。</p><p>&nbsp;</p><p>想要了解更多关于<a href=\"https://www.infoq.com/webassembly/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">Wasm</a>\"和<a href=\"https://www.infoq.com/ebpf/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">eBPF</a>\"的信息，可以关注InfoQ的相关话题。</p><p>&nbsp;</p><p></p><h1>OpenTelemetry在收集指标和基于事件的可观察性数据方面的应用有多广泛？</h1><p></p><p>&nbsp;</p><p>作为一个收集指标和基于事件的可观察性数据的框架，<a href=\"https://opentelemetry.io/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">OpenTelemetry</a>\"已经得到了快速的采用，并且正在成为行业事实上的标准。许多有才华的个人和供应商的协作促成了它的跨供应商支持和跨语言兼容性，让它成为应用程序的必要组成部分。OpenTelemetry的广泛采用主要得益于它被纳入到主要云供应商的产品中，例如亚马逊云科技的<a href=\"https://aws.amazon.com/otel/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">AWS Distro for OpenTelemetry</a>\"、微软Azure的<a href=\"https://www.infoq.com/news/2023/06/azure-opentelemtry-distro/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">监控服务</a>\"和谷歌云平台的<a href=\"https://google-cloud-opentelemetry.readthedocs.io/en/latest/index.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">Google Cloud OpenTelemetry</a>\"。</p><p>&nbsp;</p><p>OpenTelemetry的标准化特性带来了众多好处。它与供应商无关，支持导出遥测数据并利用各种工具对数据进行分析。这种标准化促进了供应商之间的优化和创新，因为他们在努力提供超出数据收集和可视化这些基本功能的高级特性。作为一个开放标准，OpenTelemetry的出现标志着行业走向成熟，并促进了供应商之间的良性竞争，为行业提供有吸引力的解决方案，并获得市场份额。</p><p>&nbsp;</p><p>想了解更多关于OpenTelemetry的信息，可以关注InfoQ的<a href=\"https://www.infoq.com/opentelemetry/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">这个话题</a>\"。</p><p>&nbsp;</p><p></p><h1>当前无服务器技术的采用状况是怎样的？</h1><p></p><p>&nbsp;</p><p><a href=\"https://en.wikipedia.org/wiki/Serverless_computing?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">无服务器技术</a>\"在采用方面发生了转变，它正在成为一种常见的选择，而不是一种独特的架构概念。“无服务器”这个词不太经常被用来讨论一个独立的概念，因为它几乎变成了一种与托管服务（提供可伸缩性、微计费和抽象化的基础设施）具有相同含义的词。一些主要的云供应商，如亚马逊、谷歌和微软，已经将无服务器组件集成到他们的服务中，例如数据库（DBaaS）和容器运行时（CaaS），带来了自动缩放和简化计费结构方面的好处。人们的关注点已经从基于无服务器函数构建架构转移到利用托管服务，与平台工程方法保持一致，减少开发人员的认知负担。</p><p>&nbsp;</p><p>无服务器的价值，如伸缩至零费用和按请求计费，已经在传统的无服务器架构之外找到了新的表达。组织现在认识到了这些好处，并在各种架构决策中要求使用无服务器。虽然无服务器是获得这些优势的众多方法之一，但组织越来越多地要求他们的工程团队提供成本效益高的解决方案，并优化客户获取和支持成本。这种演变凸显了无服务器对更广泛的架构格局的影响。</p><p>&nbsp;</p><p>想要了解更多关于无服务器的信息，可以关注InfoQ的<a href=\"https://www.infoq.com/serverless/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">这个话题</a>\"。</p><p>&nbsp;</p><p></p><h1>对可持续性和绿色计算的关注对云计算和DevOps有怎样的影响？</h1><p></p><p>&nbsp;</p><p>对可持续性和绿色计算的关注对云计算和DevOps的实践产生了重大影响。越来越多的组织采用了关切应用程序和服务对环境和资源消耗的影响的定价模式。这种趋势鼓励组织做出优先考虑效率和可持续性的架构选择。托管服务受到组织的青睐，因为它们提供了优化的资源利用率和可伸缩性，使企业能够降低能耗，减少碳足迹。对架构定价的考量和对托管服务的采用与可持续性和绿色计算目标是对齐的。</p><p>&nbsp;</p><p>关于责任，人们存在一种认识，即解决可持续性问题属于<a href=\"https://www.infoq.com/sre/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">站点可靠性工程</a>\"（SRE）及相关角色的范畴。这些团队善于分析技术决策对环境的影响，并推动可以促进效率和可持续性提升的举措。现在，架构讨论包含了组件化、隔离、安全和成本效益等方面的考虑。组织正在评估他们的需求，并寻求能够满足安全需求但又不涉及非必要高昂成本的折中解决方案。这反映了组织正在向更加务实的安全性发生转变，试图找到企业级特性和成本效益之间的平衡。</p><p>&nbsp;</p><p></p><h1>我们对云计算和DevOps领域的未来有怎样的预测？</h1><p></p><p>&nbsp;</p><p>专家们对云计算和DevOps领域未来的预测主要与简化、降低认知负担和专注创新有关。我们热切希望能够简化流程和工具，让团队能够专注于他们特定的专业领域并最大化他们的影响力。</p><p>&nbsp;</p><p>AIOps、平台工程、可持续性和FinOps的融合是一种积极的转变，可能会让团队更专注、更有效和更愉快。这里的挑战在于要区分炒作和真正的机会，承认新兴趋势中的“价值点”，同时对“过度夸大”和广泛适用性的说法保持批判的态度。</p><p>&nbsp;</p><p>开源技术的采用、由OpenTelemetry和CloudEvents等促进的标准化，以及Copilot和ChatGPT等AI融合服务的潜力，都是令人感兴趣的点。总而言之，人们对正在发生的演进和它们带来的机会充满了热情。</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/cloud-devops-trends-2023/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA0MzYwMzMsImZpbGVHVUlEIjoiQkp4MTBxSWw4RnNvSU8xRSIsImlhdCI6MTY5MDQzNTczMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IWLGnbuTAwrMoXcsKVorz0fBoyHPs_uDlNhDtpEs-o0\">https://www.infoq.com/articles/cloud-devops-trends-2023/</a>\"</p><p></p><h5>相关阅读：</h5><p></p><p><a href=\"https://www.infoq.cn/article/Uhtx5rt3UR1flUoGtYvF\">“DevOps 的阴暗面”：左移的代价和降低成本的方式</a>\"</p><p><a href=\"https://www.infoq.cn/article/3jDMGKAMYx2eAcJUzOMJ\">DevOps&nbsp;的分与合</a>\"</p><p><a href=\"https://xie.infoq.cn/article/70bdfa7bae93467293c0fa7d0\">DevOps&nbsp;与平台工程：企业该如何选择？</a>\"</p><p><a href=\"https://xie.infoq.cn/article/33eca9c7752f397ba457af953\">DevOps&nbsp;与 FinOps：二者可以协同吗？</a>\"</p>",
    "publish_time": "2023-07-31 09:34:07",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Bun原生JavaScript打包器登场，引入宏",
    "url": "https://www.infoq.cn/article/96HJmatvOZ6yQ9tyiWJr",
    "summary": "<p>最近，Bun推出了它的快速<a href=\"https://bun.sh/blog/bun-bundler?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTAxNjczNTUsImZpbGVHVUlEIjoiZzVIekZmZ0lxcm92Z3dMYyIsImlhdCI6MTY5MDE2NzA1NSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.khWiRCu6qIPwPzZhpdJBqsqrF7yG7xwMv0xZKIxFUzw\">原生JavaScript打包器</a>\"，为Bun生态系统带来了增强的打包能力。这个新的打包器现在处于测试阶段，提供了一整套功能和工具，简化并加速了构建前端应用程序的过程。此外，Bun还引入了<a href=\"https://bun.sh/blog/bun-macros?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTAxNjczNTUsImZpbGVHVUlEIjoiZzVIekZmZ0lxcm92Z3dMYyIsImlhdCI6MTY5MDE2NzA1NSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.khWiRCu6qIPwPzZhpdJBqsqrF7yG7xwMv0xZKIxFUzw\">JavaScript宏</a>\"，可以在打包时执行JavaScript函数，并将其结果直接内联到打包文件中。</p><p>&nbsp;</p><p>Bun是一个用于JavaScript和TypeScript应用程序的一体化工具包，旨在取代Node.js。它包含了一个运行快速的JavaScript运行时——Bun运行时，提供了优秀的启动速度和内存使用效率。该工具包作为“bun”可执行文件发布，提供了各种功能，如测试运行器、脚本运行器和包管理器。</p><p>&nbsp;</p><p>原生的Bun打包器试图简化复杂的JavaScript和TypeScript打包所面临的挑战，如运行TypeScript文件、为生产环境构建和打包代码、处理依赖关系以及启用类似于源映射这样的功能，这些任务通常比较耗时，阻碍了开发速度和效率的提升。</p><p>&nbsp;</p><p>打包器提供了几个关键特性。首先，它通过轻量级Bun进程快速执行插件，从而缩短打包时间。此外，打包器生成针对Bun运行时优化的预编译文件，消除冗余的转换步骤并提高整体执行性能。统一插件API允许插件扩展打包器和Bun的运行时能力，并提升灵活性和代码重用性。此外，集成打包器和运行时可以无缝传递<a href=\"https://bun.sh/docs/bundler#outputs?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTAxNjczNTUsImZpbGVHVUlEIjoiZzVIekZmZ0lxcm92Z3dMYyIsImlhdCI6MTY5MDE2NzA1NSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.khWiRCu6qIPwPzZhpdJBqsqrF7yG7xwMv0xZKIxFUzw\">BuildArtifact对象</a>\"，可以直接在HTTP API（如new Response()）中使用。打包器还引入了独立可执行文件生成，允许创建包含Bun运行时副本的自包含可执行文件。</p><p>&nbsp;</p><p>性能是Bun打包器的一个主要关注点。Bun与esbuild、Parcel 2、Rollup + Terser和Webpack等流行的打包器的基准比较测试表明，Bun在速度方面表现出色。Bun优于这些打包器，其速度提升令人印象深刻，从1.75倍到220倍不等（根据具体的基准测试而言）。</p><p>&nbsp;</p><p>开发人员可以使用Bun.build()函数或Bun的build CLI命令轻松构建前端应用程序。API支持入口点、输出目录、目标（浏览器、Bun或node）、格式（esm）、缩小、源映射配置等基本选项。此外，打包器支持摇树优化，以移除无用的代码。开发人员可以借助稳定的插件系统和加载器配置根据自己的具体需求定制打包过程。</p><p>&nbsp;</p><p>除了打包器之外，Bun还引入了Bun宏，可以在打包时执行JavaScript函数。开发人员可以使用特殊的导入属性语法将函数作为宏导入，将其结果直接内联到打包文件中。宏在打包过程的转换器阶段同步执行，并在多个JavaScript Worker之间并行化，确保高效执行。宏有助于在打包时执行获取请求等操作或提升开发者灵活性。</p><p>&nbsp;</p><p>出于安全考虑，必须使用{ type: 'macro' }属性显式导入Bun宏，确保是有意执行宏，以此来降低潜在的安全风险。也可以使用--no-macros标志禁用宏，通过完全阻止宏的执行来增加额外的安全层。此外，为了防范恶意包，不能从node_modules目录调用宏。这个限制确保宏只在应用程序代码中运行，试图从node_modules调用宏将触发特定的错误消息。</p><p>&nbsp;</p><p>虽然Bun宏提供了增强的代码执行能力，但也存在一些限制。宏的结果必须是可序列化的，以便无缝内联到抽象语法树（AST）中。与JSON兼容的数据结构可以全面被支持，但函数和大多数类的实例是不可序列化的。宏只接受在打包时静态、已知的值作为输入。动态值或依赖于运行时条件的值不允许作为宏输入。</p><p>&nbsp;</p><p>开发者社区对Bun宏存在不同的看法。一位名为explaininjs的用户在<a href=\"https://news.ycombinator.com/item?id=36518840&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTAxNjczNTUsImZpbGVHVUlEIjoiZzVIekZmZ0lxcm92Z3dMYyIsImlhdCI6MTY5MDE2NzA1NSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.khWiRCu6qIPwPzZhpdJBqsqrF7yG7xwMv0xZKIxFUzw\">Hacker News</a>\"上评论道：</p><p>&nbsp;</p><p></p><blockquote>“非常好。这应该能够帮助我消除大量笨拙的webpack/esbuild/etc垃圾。”</blockquote><p></p><p>&nbsp;</p><p>另一位用户skybrian也表示支持：</p><p>&nbsp;</p><p></p><blockquote>“我喜欢它不允许在npm模块中使用。模块作者可以在他们自己的构建过程中进行任意编译时代码生成。”</blockquote><p></p><p>&nbsp;</p><p>然而，开源贡献者goranmoomin也表达了不同的观点：</p><p>&nbsp;</p><p></p><blockquote>“宏应该能够对代码执行语法转换。Lisp因其可以将代码表示为List而闻名于世。Rust的编译器级API可以接受节点（token）并运行任意代码，然后吐出新的节点（token）。”</blockquote><p></p><p>&nbsp;</p><p>Oven（Bun背后的公司）首席执行官Jarred Sumner接受了这些反馈，并提出重新审视宏设计的计划。</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/07/bun-native-bundler-macros/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTAxNjczNTUsImZpbGVHVUlEIjoiZzVIekZmZ0lxcm92Z3dMYyIsImlhdCI6MTY5MDE2NzA1NSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.khWiRCu6qIPwPzZhpdJBqsqrF7yG7xwMv0xZKIxFUzw\">https://www.infoq.com/news/2023/07/bun-native-bundler-macros/</a>\"</p><p>&nbsp;</p><p></p><h5>相关阅读：</h5><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MzUxMzcxMzE5Ng==&amp;mid=2247516386&amp;idx=1&amp;sn=94bed4b16790a46359e19cf8c759949c&amp;chksm=f95235a1ce25bcb7531410a4fa25f0ab3e6de659d6189fb765a4de40eb2faa009a438824edbb&amp;scene=27#wechat_redirect\">Bun&nbsp;会是&nbsp;Webpack&nbsp;之后的下一件大事吗？</a>\"</p><p><a href=\"https://www.infoq.cn/article/m48tvaz8w2BbblIQKZZF\">比 Node.js 快三倍，新 JavaScript 运行时&nbsp;Bun&nbsp;火了</a>\"</p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MzUxMzcxMzE5Ng==&amp;mid=2247516765&amp;idx=1&amp;sn=b899b050ea9125222ed283bbe76acc85&amp;chksm=f952371ece25be08bcf259c6cd8a1a9fbd6fe5b5f75e9c9512f1f75799adacbc046aebdeb741&amp;scene=27#wechat_redirect\">亲身试用新&nbsp;JS&nbsp;运行时&nbsp;Bun&nbsp;后，我觉得未来可期</a>\"</p><p><a href=\"https://xie.infoq.cn/article/c03cd143a6604ee58b0d8cce4\">疑为针对最近大火的“Bun”</a>\"</p>",
    "publish_time": "2023-07-31 09:36:08",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "构建高效安全的分布式系统：探索新协议、长连接与信息安全实践｜ Archsummit闭门会",
    "url": "https://www.infoq.cn/article/1QxDO7hEWpJW4HWUWdbP",
    "summary": "<p>无论是在云计算、大数据处理、人工智能还是物联网领域，分布式系统都扮演着不可或缺的角色，它为我们提供了卓越的灵活性、可靠性和可扩展性。然而，随着规模和复杂性的不断增加，我们也面临着前所未有的挑战，如系统性能优化、资源管理、数据一致性以及通信效率等方面的问题。在7月21日，<a href=\"https://archsummit.infoq.cn/202307/shenzhen/\">ArchSummit全球架构师峰会（深圳站）</a>\"上，我们策划了《分布式系统的优化与效率》主题闭门会，以下内容为交流分享摘要。</p><p></p><h4>精彩分享1</h4><p></p><p>在过去的一些年里，随着业务的不断调整和员工分类的变化，我们的系统接入设计有一些门槛问题。其中，员工有正式员工、外聘员工和外包员工合作伙伴，他们的权限等级不同，这影响了系统接入的设计。另外，集团类员工和非集团员工也需要接入我们的内部系统，例如腾讯音乐、微宝、微众等子公司，以及紧密合作的公司等。这些变化，引发了我们对架构的调整。</p><p></p><p>在接入网关方面，我们有一个内部称为智能网关的系统，它涉及不同角色使用不同的通道、泳道或片段的建设。另外，我们还在美国、西雅图、新加坡和欧洲法兰克福建立了接入点，将数据接入到广州和深圳的主要数据中心。在这个过程中，我主要负责监控告警、数据可视化和自动修复的工作。不过，随着系统拆分越来越分布式，涉及跨地域、跨集群、跨网站部署服务，我们也面临了一些挑战。特别是网络接入延时和跨云部署问题，这些都是令人烦恼的事情。</p><p></p><p>特别是在办公接入中可能会遇到较长的延时，尤其是与美国和欧洲的会议时。美国用户反馈说，他们在美国接入网关时，可能需要跳转到深圳进行鉴权，而鉴权服务涉及到另一个团队的员工身份验证系统，这会导致延时。虽然我们在这方面进行了优化，但仍然存在一些不可控的行为，特别是员工的多样化行为对应着多个系统，这也是我们在处理中的一个挑战。</p><p></p><p>之前使用类似VPN的方式建立点对点的连接，但现在我们转向了零信任模型。在这个模型下，每个请求都会被注入一个标记，员工和黑客都可以进入系统，但需要通过我们的客户端进行内网接入。这个客户端充当全流量代理，为用户提供了信任的身份认证，确保系统的安全性。简言之，我们通过零信任模型打破了过去黑名单和白名单的限制，实现更高级别的安全保障。</p><p></p><h4>精彩分享2</h4><p></p><p></p><p>我们的问题是，在原始系统中，数据需要经过&nbsp;A、B、C&nbsp;三个节点才能达到目标。然而，实际上，数据可以直接与&nbsp;C&nbsp;节点进行交互，可以节省时间和资源。这里的解决方案是创建一个客户端，该客户端将预先获取一些类似注册用户的信息，然后在本地解析，最后直接与&nbsp;C&nbsp;节点进行交互。</p><p></p><p>原系统的调用过程是通过不同节点间的梯队，通过一个中间总线架，再录入到其他服务上面。这种调用方式让内部调用变成网络调研线，需要三跳，且需要&nbsp;TOS&nbsp;加密。</p><p></p><p>之前我们做了一次网络优化，在三台服务器的情况下，理论上有&nbsp;30%&nbsp;的流量是在本地节点就可以完成的，无需跳转到其他节点。但是为了实现无感知部署，我们在总线和客户端做了一些改动，优先考虑本地跳转，并使用本地的&nbsp;UDS&nbsp;连接来代替&nbsp;TCP&nbsp;连接。近两年，我们又面临同样的问题，而且比以前更复杂。我们正在考虑在分布式系统中，对传输层进行更多的优化。</p><p></p><h4>精彩分享3</h4><p></p><p></p><p>虽然&nbsp;HTTP/3&nbsp;在全球范围内，如谷歌、Facebook、YouTube等已在大量的使用，然而，这并不能代表&nbsp;HTTP/3&nbsp;在各种业务线或产品上都有大规模应用。</p><p></p><p>目前国内在流量大的业务（例如小视频、流媒体等）中，HTTP/3&nbsp;的使用率相对较高，但在其他业务，如即时通信、游戏等，其应用并不广泛。如果从产品的角度考虑，HTTP/3&nbsp;的使用在整体产品中占比可能不到1%，可能在2000个产品中只有20个产品用到了&nbsp;HTTP3。</p><p></p><p>此外，即便在使用了&nbsp;HTTP/2&nbsp;或&nbsp;HTTP/3&nbsp;的场合，这种应用更多的可能只是在接入层或用户端感知的层面，而在服务之间的通信，仍然多是使用简单的&nbsp;HTTP，甚至连&nbsp;HTTPS&nbsp;都不太常用。在推广新标准方面，尽管安全部门做出了尝试，但业务部门对此并不热衷。因为对业务部门来说，他们更关注业务运行，对推广新的通信协议不太感兴趣。</p><p></p><h4>精彩分享4</h4><p></p><p></p><p>镜像管理是一种关键的信息安全实践，包括对操作系统镜像（而非&nbsp;Kubernetes&nbsp;容器镜像）的安全审查。我们做了镜像管理，换句话说，在指定特定的机器可下载镜像；接下来是权限管理，这主要涉及对各类用户的角色和权限进行区分和管理，以防止不适当的数据访问或修改；监控和跟踪是另一个重要的部分，我们已经整合了诸如&nbsp;Prometheus&nbsp;和&nbsp;Skywalking&nbsp;等工具，并建立了一个中间件系统。这就像一个插件，可以插入到我们的任何项目中，以便实时监控系统的运行状况。</p><p></p><p>对于网络流量的管理，我们正在研究如何在网关进行拦截并进行数据包分析。例如，我们可以扫描通用的业务数据，找出过去存在漏洞或错误的数据，并创建过滤模板以进行流量拦截。在前后端通讯方面，我们已经开始使用&nbsp;RSA&nbsp;加密，这主要是为了解决明文传输的问题。</p><p></p><p>在数据脱敏方面，我们已经开发了一些插件，可以通过配置来指定特定的数据表和接口，对其进行脱敏处理。虽然这并不是专业的数据脱敏工具，但它已经对我们的应用层提供了一定的保护。</p><p></p><h4>精彩分享5</h4><p></p><p></p><p>在我们的操作过程中，我们普遍采用了长连接策略以减小连接成本和降低数据传输量。我们的数据发送并非实时，而是选择每10秒、15秒或30秒采集一次。如果我们只使用短连接，传输中的成本可能会超过实际的数据流量。因此，尽管使用长连接可能会增加服务器资源的使用，我们仍选择采用长连接策略。</p><p></p><p>长连接在分布式系统中的应用面临一些困难，尤其是在处理有状态的机器时。我们尝试过两种模式，一种是在前端设置一个代理，这个代理负责维护状态，然后再将连接转化为短连接；另一种是在内部使用异步消息，但这种方式存在一些问题。首先是与物联网设备的交互是一个挑战，因为这些设备的处理能力相对较弱。尽管它们使用TCP进行通信，但与它们的交互必须是一对一的，如果我们向设备发送多个命令，设备常常会不响应或只响应部分命令。</p><p></p><p>另一个挑战来自于保证交互的时序。如果我们需要进行多次交互，必须保证每次交互的时序是100%正确的，而且在这个过程中不能被其他业务打断。这是使用异步消息难以实现的。</p><p></p><p>为了解决这些问题，我们将整个协议栈的驱动封装到一个服务中，这个服务只处理特定的连接。这个服务的接口已经不再是报文接口，而是业务接口。比如，如果我们需要进行设备升级，只需将升级包发给该设备，然后由协议驱动完成所有交互。然而，这种方式难以保证高可用性。如果容器发生故障，所有的连接都会断开，我们必须找出一种方法将它们迁移到新的服务器上。</p><p></p><p>初期，我们并不太关心这个问题，因为监控和调度命令不多。然而，当我们开始处理充电桩和车辆时，问题就出现了。我们必须保证充电桩100%在线。最后，我们设计了一种联动策略，即在调度或升级之前通知设备，让设备主动连接到另一个节点，然后再断开原来的连接，从而解决做了这一问题。</p><p></p><h4>精彩分享6</h4><p></p><p></p><p>在我们的团队中，我们运用了机器学习在监控和运维系统中实施预测和根源分析。例如，我们使用趋势预测来识别监控指标的异常，如果出现了与预期不符的趋势，我们会判断可能出现了故障。此外，我们还运用深度学习对故障的根源进行分析。经过一年左右的研发，我们的系统运行良好。在这个过程中，我们使用了LSTM深度神经网络，主要应用于腾讯服务器和腾讯云服务器上的流量和CPU阈值的智能判断。对于周期性流量，预测准确率高达95%，但对于散点型的流量，其效果较一般。</p><p></p><p>在分布式系统的高可用性中，我们的平台分为故障发现、故障定位和故障修复三个部分。通过优化这三个环节，我们能够提高分布式系统的可用性。而弹性伸缩容在故障发现之后，我们还在预测领域努力研究如何更早地发现问题。我认为，这项技术在未来的工厂检测和调度方面有潜在的优势。这就像大模型能够在特定领域，比如疾病诊断中提供帮助一样，它能够像专家一样，对机器、服务、系统或软件出现的问题进行诊断。</p><p></p><h4>精彩分享7</h4><p></p><p></p><p>我们的团队认识到，虽然很多算法能够学习并得到这些数据，但由于缺乏特定领域的数据，我们无法实施这些算法。所以，我们采取的解决方案是先利用系统层面的通用数据进行模型训练，例如&nbsp;CPU&nbsp;使用率和内存使用等，这方面我们取得了一定的成功。然后我们尝试与特定业务合作，比如广告系统或支付系统，因为他们拥有特定的业务数据。</p><p></p><p>这需要我们首先用通用数据取得一定的成果，如准确率达到&nbsp;90%&nbsp;以上，这将提升我们的口碑并成为我们的品牌。然后，我们可以使用他们的数据，对我们的模型进行调优，以得到他们需要的结果。</p><p></p><p></p><h4>活动推荐：</h4><p></p><p></p><p><a href=\"https://fcon.infoq.cn/2023/shanghai?utm_source=infoq&amp;utm_medium=conference\">FCon全球金融科技大会（2023·上海站）</a>\"是极客邦科技旗下 InfoQ 中国团队推出的面向金融行业高端技术管理者、技术专家的会议，50%参会者拥有 8 年及以上工作经验。</p><p></p><p>FCon 聚焦当前金融行业遇到的问题，围绕金融企业在数字化转型过程中的痛点，例如数据治理，智能化、数字化风控，数字化投研，数字化营销，IT 技术能力等方向，邀请国内外金融企业，来分享人工智能、区块链、大模型、大数据、数字货币等新一代信息技术实践话题，帮助听众解决技术和业务上的问题，提升技术能力。欢迎大家报名参会，<a href=\"https://fcon.infoq.cn/2023/shanghai?utm_source=infoq&amp;utm_medium=conference\">详细信息可点击这里查看</a>\"</p>",
    "publish_time": "2023-07-31 11:52:24",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "混合云客户的全景可观测：技术挑战与解决之道",
    "url": "https://www.infoq.cn/article/IcJSD2R5yci2Jz22N1pG",
    "summary": "<p>在政府企业数字化转型的背景下，诸多大型政企客户选择混合云作为业务上云的整体方案。然而，混合云客户场景下的可观测领域，却面临着和公有云场景和大型互联网企业内部场景截然不同的几大困难：异构的基础设施和混合云架构下复杂的应用和云平台网络环境让监控系统本身难于部署和稳定运行，面向传统应用架构和旧应用极高的改造成本让指标、链路、日志监控难以落地；基于云平台监控和客户自建及第三方应用级监控工具相互割裂难以整合，客户侧技术栈老旧、云原生化程度不足等。</p><p>&nbsp;</p><p>面对这些技术挑战，我们在面向业务指标实施计算和应用基础监控的阿里集团监控平台的基础上，通过全方位监控架构升级和开源架构融合，以及多项的监控能力创新，打造了面向混合云客户的一体化监控平台，并在数十家大型政企客户侧落地了面向混合云的全景可观测能力，显著提升了客户侧云上业务故障发现、定界及处理的时效性，保障了诸多关系到国计民生的云上政企业务应用的稳定运行。</p><p>&nbsp;</p><p>本文整理自阿里巴巴阿里云基础产品事业部高级技术专家王肇刚（花名梓弋）的演讲分享，主题为“<a href=\"https://archsummit.infoq.cn/2022/shenzhen/presentation/4578\">混合云全景可观测技术架构探索和实践</a>\"”。分享主要分为三部分：1、混合云场景下落地可观测能力的技术挑战；2、面向混合云客户的企业级监控平台技术架构探索；3、混合云可观测实战案例。</p><p>&nbsp;</p><p></p><h1>混合云场景下落地可观测能力的技术挑战</h1><p></p><p></p><h2>从监控到可观测</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/87/87ba4010140151c2c4b6c4a8c99c6e96.png\" /></p><p></p><p>什么是监控？什么是可观测？监控可能更多的是通过一个采集和分析看某一个具体单点的单指标状态。可观测强调一个可字，希望通过被监控对象的系统自己暴露出一些信息，你能够通过信息和上下文感知到更多的东西。细分来看，监控可能是一个被动的，像外挂式的设施。我们的Agent采集数据会有探针，监控对象本身是独立存在的。而可观测性强调主动透出，从我自己的从业经历来看过去十多年的运维行业的发展趋势是一致的，我们在很多时候面临的问题非常复杂，比如说十年前我在百度负责百度贴吧的运维，我们有2600台物理机，当时每天的PV是24亿，那个时候面临环境一致性问题，这个问题跟监控关系不大，但是跟运维部署关系很大。那个时候没有Docker，没有Kubernetes，2600台物理机上有大概八九百台需要部署前端UI。</p><p>&nbsp;</p><p>我们希望是统一的环境，结果做了一下线上环境的扫描，发现有500多种Diff(配置差异），为什么？因为我们在线上要做灰度发布，几十个模块在不同的迭代，靠手工维护是很难的。有了容器化之后，你会发现问题解决了。在监控领域发生的很多事情跟在运维部署领域是一样的，我们希望通过外力施加去观测，慢慢变成它自己对外暴露信息，可被观测。这是我说的第一个特点。</p><p>&nbsp;</p><p>第二个特点是监控可能只关注一个具体的指标，或者是一个报警，而可观测性则希望能够通过一个单点看到更多的全局，看到上下文，透过现象看到本质，也不仅仅只关注报警，还要处理，我们希望知道背后的原因是什么，以后怎么预防。所以监控到可观测性是一个由主动到被动、在空间上由单点到全面、在时间上由告警响应这个单一时间段到故障处理，全生命周期的演变。</p><p></p><h2>混合云客户运维可观测需求及挑战</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/68/689bbf459a9434a7e2338e7351a1f9df.png\" /></p><p></p><p>由监控演进到可测性技术领域的变迁过程中，混合云领域的客户群体对可观测性也有自己的需求。什么叫混合云？各行各业的客户在使用云的时候可能主要会有两种模式，一种是我们熟知的公有云。还有一批客户，他们由于安全合规的需要，可能无法直接使用公有云，需要使用我们称之为专有云的私有化部署的技术体系。混合云的客户都是谁？我们每天交电费、交水费、交燃气费，像这样关系到国计民生和各行各业的日常生活的很多业务，背后的企业更多的是政府国企和一些大型的头部企业，它们的IT系统往往跑在混合云上，对他们来讲，混合云上系统越来越复杂，要保持业务的稳定对于可观测能力或者我们称之为监控能力有非常多的需求。</p><p>&nbsp;</p><p>监控可观测本身也在演进，比如现在的监控已经不按垂直领域划分了，我们更多的是叫全栈监控，同时监控也不只是报个警，看个图，我们更希望监控系统能够提出一些分析的能力。客户的基础设施架构从单体架构变成了混合的架构，监控也需要去适配这种架构，同时随着客户上云的过程办的越来越多，监控本身也需要回答关于成本运营的问题，受监控业界这四大领域趋势的影响，混合云客户对于可观测性的需求也有扩展。比如希望能够全方位地全栈监控，希望能够做多层的全景监控，希望监控报警不仅仅能够解决问题，发现的问题也能够服务于整个IT管理的生命周期。</p><p>&nbsp;</p><p>我们也希望能够在混合云客户侧把可观测能力做得更好，但实际上问题是很明显的，就是我们在混合云客户的复杂基础栈下，落地这个我们称之为全栈、全景、全生命周期监控有很大的挑战。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3f/3fe978bec0fe49c1a4ef510f92c5c8c7.png\" /></p><p></p><p>我们先看全栈。说到全栈这个词，大家很容易联想到技术栈，我们的应用程序使用不同的语言开发，有不同的框架跑在不同的操作系统和基础设施上，都是各异的。应用架构的差异，技术栈的差异，研发模式的差异，还有运维模式的差异，都会给我们做可观测带来很多的挑战。</p><p></p><h2>如何在割裂的运维体系下落地全景可观测</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d5/d5bda1b72480f3800c4de8837a21f40c.png\" /></p><p></p><p>全栈更多的偏执于不同的技术栈，而全景则指的是分层的，不同的运维或监控对象。这张图是一个全景的架构，在实操过程中大家会发现，我们存在着至少有四种割裂，第一种是应用运维跟平台运维之间的割裂，这种割裂一开始不是因为技术造成的，我作为一个一直在互联网大厂工作的同学，接触客户之后挺困惑，客户侧管平台那级的人跟管应用那级的人割裂非常严重，导致这两层在系统上是不联动的，如果出现一个问题，需要去判断是应用程序自己的问题，还是底下云平台的问题，这个事情是很困难的，很难系统化实现。第二个是平台运营跟运维之间也会有割裂。很多的客户在采购了云服务商提供的云产品之后，会把它二次分包出去。有一部分人需要拿云平台的资源对不同的二级使用者做资源运营。这个时候它不得不关注平台的稳定性，而关注稳定性的又是另外一拨人，所以从人到系统也存在割裂。第三个是监控报警处理之间的割裂，很多的企业会有值班的同学，但是值班的同学往往只能够响应报警。真正出问题之后可能报警来自各处，不见得一个人就能处理，所以缺少系统化报警间联系比较容易出现低效的问题。最后一个是不同的垂直应用系统之间的割裂，很多政企的客户IT系统之间存在着孤岛现象，技术栈也不一样，接口也不一样，数据的形式也不一样。</p><p></p><p>存在着这四种割裂会导致我们很难把数据连起来，但是数据能不能不连起来？不能。因为他们之间是牵一发动全局的关系。这种割裂会影响我们通过技术化的手段去获取运维对象之间横向和纵向的拓扑，我们要获取的拓扑包括：</p><p></p><p>业务和业务之间的横向拓扑业务和应用之间的纵向拓扑应用与应用之间的横向拓扑应用与云产品实例（中间件、 DB）之间的纵向拓扑云产品实例和云平台组件之间的纵向拓扑</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bc/bcd9b8b0b70b66b81e80dddc8cffaef0.png\" /></p><p></p><p>我们希望业务报警和其他报警之间有有机的联系，能够服务于故障的发现、定级、快恢和定界的四个环节。但实际上客户侧可能达不到这个理想态，究其原因可能有四方面：</p><p></p><p>第一个方面是告警风暴很多，大家就不知道是不是业务出问题，还是系统出问题了，业务监控会淹没在系统的报警之中。</p><p></p><p>第二个是如何确定故障级别，故障级别的确定需要依赖两个因素，一个因素是你的IT系统、应用和基础设施故障到底到什么程度了。第二个是上面跑的业务重不重要，有没有很多客户在用。</p><p></p><p>第三个是告警和快恢入口 割裂，快恢决策 依赖人工判断。</p><p></p><p>第四个是针对不同监控对象的告 警杂乱发送，无法结构 化地服务于故障定界。</p><p></p><h1>面向混合云客户的企业级监控平台技术架构探索</h1><p></p><p></p><h2>混合云可观测能力</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9f/9f863cc287a53161dcdd3470c2d8df29.png\" /></p><p></p><p>第二部分给大家介绍一下我们面对这些挑战做了哪样的架构方面的探索和实践。首先这张图不是架构图，它是个功能图，是截止现在为止，阿里云混合云对于政企客户推出的全景可观测产品功能架构，有场景化的监控能力，还有事件处理，有业务监控、应用监控和应用视角的云产品监控，我们也有能力去帮助客户监控它的应用和业务，我们可以有很强的抽象集成能力，客户侧有不一样的技术架构和技术选型，我们都有办法做集成。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/53/539552ea90f70d88d3594af66eda59c1.png\" /></p><p></p><p>大家可能会问说，为什么要做这么多功能？这张图解释了我们为什么要研发这么多功能。大家可以看这个图有三个坐标。第一个坐标是我们称之为云+应用一体化运维对象，是我们的纵轴，或者是y轴。它上面有三个刻度，业务、应用、云平台。还有我们的Z轴，就是纵深的那个轴。它就是我们最熟悉的云原生可观测性的三大技术支柱，Tracing、Matric和Logging。大家可能会问，既然有两个轴了，这两个轴各有三个刻度点，是不是三三得九，你得做九个功能？也不是的，因为你每一个监控对象，或者每类监控对象不见得一定要用三种监控，比如对于业务指标，可以通过指标监控做，也可以通过日志监控做，也可以通过链路监控做，但以指标监控做的效果可能是最好的。应用监控就明显是指标和链路会多一些，平台监控指标跟日志会多一些，链路会少一些，我们需要在监控对象上采取最有效的组合监控的方式，这是个技术手段。</p><p>&nbsp;</p><p>做出这么多监控能力为了干啥？是为了服务于日常运维的业务。从运维人员看，出现报警之后的处理流程可能分为几个节点，首先是故障发现，第二个不是故障定界，而是事件定级。第三个是故障处理，第四个是故障定界。事件定级从业务流程上位于故障发现和故障处理之间。</p><p></p><h2>混合云可观测架构实现路径</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/72/72c713e5bd7cd520f24714c3acac8a90.png\" /></p><p></p><p>接下来我们再谈谈技术，我们演进的起点是这张图，它是阿里巴巴集团内部用的阿里集团监控平台的架构图。这张图所画的架构承载的功能无法支持刚才上面那么多能力，这是一个非常重实时计算的架构，它的核心价值是什么？是在千万级别的容器节点上采集业务的痕迹，也就是日志，去做实时计算，然后以非常高的时效性把指标算出来，它计算的是每秒钟淘宝有多少人能下单，有多少个人退款，多少个人添加购物车。所以它的架构特点是什么？需要处理海量数据，同时需要具备非常强的容灾能力。</p><p>&nbsp;</p><p>大家可能也知道阿里巴巴的混沌工程也是我们的一个做的比较好的领域，它会在内部不提前告诉你的情况下给你搞断网，然后把模块注入故障。监控系统曾经在前年和大前年被两次生产突袭验证过，一个局部单元断网之后，这套系统必须要正确回答到底是业务量下跌导致的指标下跌，还是你的单元的网络中断导致下跌，所以它需要有比较好的容灾能力。</p><p>&nbsp;</p><p>我们采取了异步调度的模式，每层的任务调度都会容错。如图左上角是阿里巴巴的元数据CMDB，监控配置和CMDB一起定时触发监控任务的生成。我们的每一个应用都会在每一个实例上打印日志，或者对外暴露一些数据，但是我们要看到是一个全局的空间上经过汇聚的数据，而且汇聚时还带业务规则，所以需要一个任务本身的生成机制，这个任务会有两级的分发到我们称之为Map&nbsp;Reduce的模块。它的命名参考了当年的Hadoop，但是实际的功能不太一样，我们的Reduce模块会去Map上拉，然后Map会去遍布在千万级别容器上的客户端拉取数据，然后计算后将结果存到阿里巴巴自研的时间序列存储里面，最终进行展示和报警。我们整个的架构特点是高效、稳定和准确。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/09/097d89d1adfe5a530c7e986e004a6d50.png\" /></p><p></p><p>但是大家可能会问，你这个架构非常适合实时计算，它在功能层面扩展性并不是那么强，为什么要做这个架构？它是跟业务相关的。这张图给大家展示的就是阿里巴巴集团的监控的方法和理念，是一个非常重业务监控的方法论，这个系统超过一半的负载都在算什么？都在算如左边这样的数据，我们称之为交易量，这些业务指标中以交易量为主，它带的是业务含义，比如说会把电商体系的拆单比考虑进去，而且很多是秒级的。所以阿里巴巴集团的业务监控为主这个特点，在这个系统中体现的淋漓尽致。但是当我们希望这套东西能不能站在阿里云上服务于企业客户的时候，发现遇到了很大的问题，我们也经历了一个很痛苦的这个过程，我们直面的转型之痛包括：</p><p></p><p>大规模监控计算调度和在混合云现有客户场景下并非刚需客户侧数据迟延较大，秒级监控几无用武之地客户普遍缺失业务监控的理念客户侧技术栈不统一、部署环境复杂多变</p><p>我们这个系统在最开始从集团内部转到商业化的时候，面临着这些困难，也需要补全很多能力，比如：</p><p></p><p>客户侧专有云资源严格规划，小型化瘦身和部署能力增强是当务之急，需要兼容全栈监控能力，增加链路监控和日志监控能力集成和兼容客户侧多样监控数据源和监控工具报警事件的能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9e/9e957b03978ab825c8aee046911c6b76.png\" /></p><p></p><p>接下来给大家展开介绍一下，第一步是我们把实时计算架构跟Prometheus架构相融合。左边这张图是我们自己内部传统的Map Reduce架构，它怎么跟Prometheus融合？这个时候Prometheus Server上的计算任务调度是被Sunfire原生的Brain和Map Reduce所驱动的，这样的好处是什么？因为原来任务驱动有比较强的容灾能力，所以当计算任务出现失败迟延、超时的时候，可以被容灾，这是跟原生的Prometheus不太一样的地方。我们的存储复用了Sunfire自己的时序存储，就是阿里巴巴自研的时序存储数据库，Prometheus的存储能力得到了扩展。Prometheus Server本身也需要一个高可用的扩展，在社区有很多的方案，我们采取了社区用过的一种方案，就是对它的计算任务做了分发，我们有主和备，我们自己做了一个哈希的规则去做分发，这样就比较好地结合了Prometheus本身生态的特点，同时也复用了我们原来监控平台有的高可用架构和调度架构，这是第一个融合。</p><p>&nbsp;</p><p>这之后，我们往前再走了一步，跟SkyWalking融合。这个时候我们会对开源的东西做一些修改，当然严格遵守了开源协议，并且给出了合规的声明。技术层面，我们分享两点修改。第一点是在SkyWalking架构图里，把自己的Tracing和Metric信息都放到它的中心去算。我们在这里做了一个分流，把里面的指标数据走一个通路，汇入Sunfire计算架构里。Tracing本身往上走的链路保持不变，但是它里面的指标部分可以跟共享计算Sunfire调度和存储，再向上去接大盘各方面的外部设施。</p><p>&nbsp;</p><p>这样原生SkyWalking的能力我们还保留，同时跟我们现在能力做很好的结合和增强。因为和阿里云Sunfire、混合云的元数据平台，包括我们的运维部署平台做了联动，我们有比较好的服务自发现能力，你在用了阿里云之后，自己部署发生的扩容缩容我们是可以感知的，不管底下是原生的虚拟机架构，还是Kubernetes的架构。这个感知也被透穿到SkyWalking里面，当应用对象的实例发生变化之后，探针里面的应用标识会自动更新。我们几个系统不是简单的堆砌在一起，而是有机的联合。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1a/1a4df0dc539f66e0b61015405957b363.png\" /></p><p></p><p>在工程层面做了演进之后，可以看到我们的算法也有很大迭代需求。我们现在在商业化的监控产品中会有我们最早的智能基线，经过不断的迭代，放在我们商业版本之后发现效果还不错，但是我们觉得还不够，因为很多时候我们的监控需要对应用或业务的黄金指标做监控。这个时候它应该是一个多指标异常发现的场景，就是需要对一个指标的成功率做综合的监控。我们会有黄金指标异常检测的能力,包括可以基于调用链分析，有应用故障诊断的能力，包括在配业务监控的时候可能需要在日志里筛关键字，然后去配正则表达式。现在我们的新能力是什么呢？我们通过算法去分析你的日志的格式，然后去看哪些关键字流量最高，哪些最可能被监控捕获，进行算法自动推荐。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c4/c430ddc19d95c5dc0f62cfef571911e1.png\" /></p><p></p><p>这些算法本身的功能背后还需要一些产品化的手段，比如需要把算法参数转化为运维人员友好的参数可调节，让运维人员可视化地看到算法检测边界。你可能需要在算法的配置调整之后做回溯，原来的架构就跟不上了，所以我们对算法专门做了一个工程架构，这个架构也比较简单，就是把算法本身的任务做成调度的模式，调度策略跟计算任务、报警任务、调度策略做融合，这样能复用策略，也能适用算法的特点，只要在算法框架里自己去实现即可。实现完之后就可以被框架以比较高的时效性跟原生的报警放在一起调度。在客户侧对于资源极其苛刻的要求下，算法也能够尽它的可能性去挖掘任何资源，因为它不会单独占资源，是弹性的。这样容错性和资源利用率也能得到提升。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f6/f6a00f23335d15603d0db4a5c1248561.png\" /></p><p></p><p>接下来是事件层面，就是对报警处理。这张图也是一个功能图，我们有事件中心，业界的商业化竞品都有这样一个功能，我们希望突出架构的冗余性、可用性和集成能力，客户侧在使用你的产品之前可能已经有N个产品、N个监控系统，开源的Zabbix、Prometheus，或者其他的监控系统，我们希望数据能够融合在一起，但可能很困难。在实操层面把报警事件集中在一起，可能是一个更务实的选择，那怎么把事件集成在一起？需要能够解析事件的格式。大家知道事件就是字符串，它很多情况下就是纯文本或者副文本的消息。如果有Meta的话，可以对它解析。但你会发现，如果堆积的系统多了之后，对于事件本身的字段抽象也是比较大的挑战。同时，哪怕监控趋势图挂掉了，报警也不能挂，所以它的稳定性要求很高。所以我们跟专有云的架构组去做联动和合作，引入了阿里巴巴专有云在多云或者一云多Region层面下的高可用架构能力，让报警本身能够做到最稳定。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dc/dce25b7223104d5767a8264dba793b77.png\" /></p><p></p><p>同时我们也做了很多的抽象设计，让报警系统能够做很好的南北向集成，南向集成是指能够去接驳不同数据源的异构报警，同时尽可能去感知报警背后的元数据。这点挺重要的，大家可以想象一下，如果你用了多个监控系统。很可能这些监控系统之间对于某一类监控对象或者同一个故障会有重复的报警，如果事件中心不能感知这些系统的Meta，很难去跨系统做集成，做报警的压缩和治理。所以我们需要去对系统的Meta做一定的感知，一方面靠对报警字符串解析的感知，一方面靠专有云底座的CMDB以及运维部署方面的感知，同时我们也通过链路分析的方式，能够自动追踪客户在阿里云上的应用对客户购买的云产品之间发起的调用，调用链的信息跟CMD里面静态的注册信息做比对，很多数据流向的Meta就清晰了，这些Meta会帮助我们在事件中心做报警的收敛。</p><p></p><h1>混合云可观测实战案例</h1><p></p><p>架构的演进之后，问题解决的好不好？可能还是要到实际的场景中去打磨一番。今天给大家介绍几个案例，看一下效果如何。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fb/fb168475246e5a311dde3f57081e3d7c.png\" /></p><p></p><p>第一个案例是国内某大著名的能源企业，它之前监控是割裂分层的，应用我们系统尝试可以把它穿起来，不管是下面的基础设施和应用，还是上面的这个业务。之后也可以通过智能化能力去发现一些以前需要人工巡检，或者说静态报警规则所能发现的问题。静态的规则可能比算法在单指标下效果会好，但需要大量的维护成本。能源行业用户量非常大，而且有和互联网行业不一样的规律，所以算法也需要一些迭代。得益于我们这套工程和算法的架构，这个系统能够比较好的部署在总部和全国N个省的中心，这样能够就从空间上监控总部和省，同时在时间上也能够做纵向的上下钻取。基于事件中心对报警做得收敛，我们也取得了很好的效果，之前每天会有很多杂乱的报警，后面被我们压到非常小，并且没有损失信息，一旦出现问题，报警会串联起来，自动生成一个树状结构，数据就变得很高效了。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7a/7a4370a1c6c8fee0036e2bbe4af1a396.png\" /></p><p>&nbsp;</p><p>第二个是某党建类项目，全国的党员天天在用。它的业务量也非常大，规模是我们客户中比较大的。它的运维活动很频繁，所以监控跟运维的联动，监控的部署也成了一个很大的问题。随着业务应用的扩容、缩容，监控需要跟业务伴生，同时不同的业务应用会采取不同的监控手段去监控。我们的监控插件也需要动态根据客户业务的变迁和应用的变迁去做部署，我们自研了一套和K8S一样的机制，借用K8S里面的Operator机制去做监控客户端，包括Agent自动部署。这样我们可以在客户侧把业务应用和云资源一起监控起来，完成一个整套的监控方案。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/75/75bf46fa9614373c472e37ed436a8436.png\" /></p><p></p><p>第三个案例是某一个省份的政务厅或者政务中台，阿里巴巴的钉钉协同工具跟阿里云在战略上是云钉一体，也服务了很多省的政府企业客户。政府客户内部有很多的功能点，有时候网页点不开了，有可能是后端接口不想用了，也有可能前端JS报错了这两种原因。但很难判断，一开始都是等到客户去投诉的时候才会有业务人员去找IT人员响应这个问题。但是有这套系统之后，就能对业务的使用量做实时的监控，当业务量出现问题，马上能够看到应用，马上能够看到云平台。所以我们就能够做到一个全栈的监控，客户能感知到自己业务的运行状态了。</p><p></p><p>有多少个人用？什么时候用量大，什么时候用量小，这个统计的粒度是分钟级，甚至一些核心指标可以到秒级的。而如果希望能够保障这些业务功能点的稳定性，需要对我的业务功能到底有没有被监控，监控出来的报警有没有被响应也要做及时的感知，所以我们也跟阿里云的故障管理的产品和服务做了集成，这样客户能够看到云上的业务有哪些功能点已经被业务监控覆盖，哪些功能点的监控质量是什么样的，每次出现报警是不是有人被响应。大概几个月之后，你会发现不同级别的事件数量有明显的收敛趋势，同时单个报警的响应和处理时长也有明显的收敛，这就是产品技术加运营得到的综合的效果。</p><p></p><p></p><h5>相关阅读：</h5><p></p><p></p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MzIzNjUxMzk2NQ==&amp;mid=2247485109&amp;idx=1&amp;sn=84ddbda3f91ee71503e7a7b5c0bc989f&amp;chksm=e8d7f977dfa0706141f3e0184322eabda27f2a10bfbfd3c7e935ea5c5b8cdb6c66e1f21d44ea&amp;scene=27#wechat_redirect\">混合云架构备受青睐，但是实施过程要避开哪些坑？</a>\"</p><p><a href=\"https://xie.infoq.cn/article/e858c22d0443edbc9658b72d5\">影响云安全的因素有哪些？如何保障云安全？</a>\"</p><p><a href=\"https://xie.infoq.cn/article/32cc45eddb706c5af489da0fa\">云环境与服务器的四大区别简单聊聊</a>\"</p><p><a href=\"https://xie.infoq.cn/article/3e18c19e2bbe7208fe46570c1\">云管平台和云服务器一样吗？两者有啥区别？</a>\"</p>",
    "publish_time": "2023-07-31 13:54:38",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从文心一言 APP 看大语言模型时代的 C 端产品研发变革｜QCon",
    "url": "https://www.infoq.cn/article/HPPGcKd0yOVqLkQFWAkS",
    "summary": "<p>日前，百度推出了专用独立的 AI 智能聊天服务软件文心一言。据官方信息，“文心一言”作为百度全新一代知识增强大语言模型，采用一对一的对话式聊天场景，能够与人对话互动，回答问题，协助创作，同时在文学创作、商业文案创作、数理逻辑推算、中文理解、多模态生成等多个应用场景中高效便捷地帮助人们获取信息、知识和灵感。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c1/c1f77531ced5078b9b15938bf40e6fdb.jpeg\" /></p><p></p><p>文心一言 APP 的发布，给我们带来了一些好奇和思考——大语言模型的 APP 和普通的 APP，有什么差别？比起常规开发，交付速度、质量和成本有哪些差异？再往前一步思考，到底什么是好的 AI 原生应用？</p><p></p><p>当前，对于什么是好的 AI 原生应用目前还没有定论，但我们却可以在这百家争鸣的大语言模型时代，做出一些探索，文心一言 APP 就是一个很好的例子。</p><p></p><p>在今年 9 月 3-5 日举办的<a href=\"https://qcon.infoq.cn/202309/beijing/track?utm_source=infoqweb&amp;utm_medium=presentation&amp;utm_campaign=9&amp;utm_term=0731&amp;utm_content=fanzhongkai\">QCon 全球软件开发大会·北京站</a>\"，特别邀请到百度资深研发工程师、文心一言 APP 技术负责人<a href=\"https://qcon.infoq.cn/202309/beijing/presentation/5408?utm_source=infoqweb&amp;utm_medium=presentation&amp;utm_campaign=9&amp;utm_term=0731\">樊中恺</a>\"前来交流，他将带来重磅分享<a href=\"https://qcon.infoq.cn/202309/beijing/presentation/5408?utm_source=infoqweb&amp;utm_medium=presentation&amp;utm_campaign=9&amp;utm_term=0731\">《大语言模型时代的 C 端产品研发》</a>\"，这也是文心一言 APP 首次对外公开分享。</p><p></p><p>樊中恺老师于 2008 年接触前端开发，2012 年开始移动端开发至今，曾先后负责百度浏览器、文库、阅读、百度 APP 前端技术架构、搜索前端架构、推荐前端架构、Paddle.js 等研发工作，对于端智能、工程化、前端架构等方向有较为丰富的经验。值得一提的是，他是 <a href=\"https://gmtc.infoq.cn/2021/shenzhen/track?utm_source=infoqweb&amp;utm_medium=presentation&amp;utm_campaign=9&amp;utm_term=0731\">GMTC 全球大前端技术大会·深圳站 2021</a>\" 「<a href=\"https://gmtc.infoq.cn/2021/shenzhen/track/1175?utm_source=infoqweb&amp;utm_medium=presentation&amp;utm_campaign=9&amp;utm_term=0731\">前端智能化</a>\"」专题的优秀出品人，也是知乎知名答主“胖总​”。</p><p></p><p>我们了解到，与常规开发相比，大语言模型 APP 与常规 APP 开发之间的主要差异在于需要与模型迭代的链路进行深入结合。樊中恺老师表示，文心一言 APP 项目成立以来，沉淀了一些心法来指导相关的 C 端产品开发，在本次演讲中，他将会分享相关经验。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/17/177fcf9da59241fb9a907c7eaa06de77.png\" /></p><p></p><p>大语言模型模糊了技术和语言的边界，也模糊了产品和技术的边界。当大语言模型的技术浪潮来临，大前端从业人员如何扬帆？这是每一个研发人员需要慎重思考的课题，期待与你在 QCon 北京站现场交流。</p><p></p><p>活动推荐</p><p></p><p>近 100 名讲师、近 30 个精彩专题、8 种交流活动，QCon 北京 2023，相约 9 月！现在购票，享 9 折特惠，立省 ¥880！咨询购票请联系 18514549229（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/33/33cbbbf20baa8b2a18db4f0681f159aa.jpeg\" /></p><p></p>",
    "publish_time": "2023-07-31 14:05:13",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "一场 AI 引发的开源革命迫在眉睫？Hugging Face 更改文本推理软件许可证，不再“开源”",
    "url": "https://www.infoq.cn/article/DDgl51H5dC9V7dHXrvIN",
    "summary": "<p>&nbsp;</p><p><a href=\"https://github.com/huggingface/text-generation-inference\">Text-Generation-Inference</a>\"（又称TGI）是Hugging Face今年早些时候启动的一个项目，作为支持 Hugging&nbsp;Face Inference API和后来的Hugging Chat上的 LLM 推理的内部工具，旨在支持大型语言模型的优化推理。自推出后，该项目迅速流行，并被Open-Assistant和 nat.dev 等其他开源项目采用。</p><p>&nbsp;</p><p>近日，Hugging Face宣布，在最新推出的 TGI v1.0 版本中，其开源许可证将从Apache 2.0改为HFOIL 1.0。<a href=\"https://github.com/huggingface/text-generation-inference/blob/bde25e62b33b05113519e5dbf75abda06a03328e/LICENSE\">HFOIL</a>\"代表 Hugging Face Optimized Inference License，是HuggingFace专为优化推理解决方案而设计的协议。Hugging Face表示，HFOIL 并不是真正的开源许可证，虽然源代码仍然可以访问，但其增加了一项限制：要销售基于 TGI 构建的托管或托管服务，需要单独的协议。</p><p>&nbsp;</p><p></p><h2>为什么要更换许可证？</h2><p></p><p>&nbsp;</p><p>据悉，TGI 已成为Hugging Face 商业产品（如<a href=\"https://huggingface.co/blog/inference-endpoints-llm\">推理端点</a>\"）及其商业合作伙伴（如<a href=\"https://www.philschmid.de/sagemaker-falcon-llm\">Amazon SageMaker</a>\"、<a href=\"https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/falcon-llms-in-azure-machine-learning/ba-p/3876847\">Azure 机器学习</a>\"和<a href=\"https://huggingface.co/blog/huggingface-and-ibm\">IBM watsonx</a>\"&nbsp;）的重要组成部分。而Hugging Face 此次更换许可证也与其商业策略紧密相关。</p><p>&nbsp;</p><p>根据 Hugging Face 的说法，TGI 最初是一个为其内部产品提供动力的项目，该公司将其视为商业解决方案的关键组成部分。“TGI 并不是一个社区驱动的项目，而是一个可供社区广泛访问的生产解决方案。我们希望继续公开建设 TGI，并将继续欢迎大家做出贡献。但与Transformers 和 Diffusers 等社区驱动的项目不同，TGI 专注于生产环境中的性能和稳健性，目标是构建商业产品。”</p><p>&nbsp;</p><p>据悉，TGI 此前所有版本仍然在 Apache 2.0 下获得许可，最后一个 Apache 2.0 版本是<a href=\"https://github.com/huggingface/text-generation-inference/releases/tag/v0.9.4\">版本 0.9.4</a>\"。</p><p>&nbsp;</p><p>Hugging Face 表示，源代码许可的这一变化对免费使用 TGI 的绝大多数社区用户没有影响，其推理端点客户及商业合作伙伴的客户也不会受到影响。但它将限制非合作云服务提供商在未请求许可的情况下提供 TGI v1.0+ 服务。</p><p>&nbsp;</p><p>如果是v1.0之前的TGI 现有用户，当前的版本仍然是Apache 2.0，可以不受限制地进行商业使用。如果用户将 TGI 用于个人用途或研究目的，则不受HFOIL 1.0 的限制。如果用户将 TGI 作为内部公司项目的一部分用于商业目的（不作为托管或托管服务出售给第三方），则也不受HFOIL 1.0 限制。如果将 TGI 集成到出售给客户的托管或托管服务中，则考虑升级到 v1.0 及更高版本的许可证。</p><p>&nbsp;</p><p>“开源是一个误称，它应该是来源自由。”有网友评价道。也有网友表示，“开源不应过度限制我使用工具的方式。如果无法再将其嵌入到我销售的产品中，则它是可用的源代码，但不是开源的。”</p><p>&nbsp;</p><p>有人提出，资产阶级认为他们可以从公地获取创新来建立帝国并压迫群众，至少应该为这种特权付出代价。对此，有开发者表示，“FSF （自由软件基金会）对此的回答是使用 AGPLv3，它在网络访问上限制了 Copyleft。”</p><p>&nbsp;</p><p>AGPL v3协议规定，除非获得商业授权，否则无论以何种方式修改或者使用代码，都需要开源。开发者“kmeisthax”表示，“如果你唯一的目标就是阻止大型企业接触您的代码，那么当然可以使用这个许可证。但你也可以使用奇怪时髦的后现代许可证来做到这一点，这些许可证从技术上讲不授予任何权利，很容易被用来限制 Copyleft 巨魔。但如果你只是想要公平且易于遵守的规则，那么该许可证就有问题。”“AGPLv3 仅对使用解释性语言进行 Web 开发有意义，这样可以轻松列出网站的代码。”</p><p>&nbsp;</p><p>“kmeisthax”进一步表示，“如果你想更严格，还有 OpenWatcom 许可证，它会在您使用软件时触发Copylef，所以没有私人分叉。实际上，这不像AGPLv3那样令人头疼，你不需要允许通过网络下载源代码，您只需在某处发布您的修改即可。FSF 拒绝碰它，因为他们认为私人分叉是一项人权。”</p><p>&nbsp;</p><p>“kmeisthax”认为，阻止“资产阶级”从公地掠夺所有创新的问题在于，这样做会使软件脱离公地，这比 AGPLv3、SSPL 或 OpenWatcom 更糟。任何试图这样做的人都不是想保护公地，而是想加入资产阶级。因为不允许你为他人托管软件，这是专有世界的语言。专有软件许可之所以如此有利可图，主要是因为使用限制——它允许你查看每个用户的钱包，并从中提取最大金额的资金。</p><p>&nbsp;</p><p></p><h2>延绵近半世纪的开源许可证要为 AI 改变？</h2><p></p><p>&nbsp;</p><p>自由软件与开源许可证自上世纪七、八十年代起曾经历演变以适应代码编程的需求。如今，它需要再次转型来应对AI模型带来的新一波冲击。</p><p>&nbsp;</p><p>比如，ChatGPT 现在仍然使用的是开源代码。特别是，分别由 Google 和 Facebook 开发的TensorFlow和PyTorch推动了 ChatGPT。这些框架为构建和训练深度学习模型提供了必要的工具和库。没有它们，就没有 ChatGPT。ChatGPT 另一个重要的开源部分就是Hugging Face 的 Transformer，这是用于构建最先进的机器学习模型的领先开源库。</p><p>&nbsp;</p><p>得益于开源，但&nbsp;OpenAI却没有将ChatGPT开源。“&nbsp;OpenAI 本来是作为一家开源（这就是为什么我将其命名为‘Open’AI）、非盈利公司而创建的，目的是作为谷歌的制衡，但现在它实际上已经成为一家闭源、利润最大化的公司。由微软控制。根本不是我想要的。”马斯克曾批评道。</p><p>&nbsp;</p><p>开源模型的流行也印证了大家对于AI模型开放的期盼。但实际上，基于版权法处理软件代码的自由软件和开源许可证，并不适合支撑AI开源软件之下的大语言模型（LLM）神经网络与数据集。而另一方面，相当规模的编程数据集长期基于自由软件与开源代码，因此必须采取措施、顺应转变。有鉴于此，开放源码倡议（OSI）执行董事Stefano Maffulli等开源和AI领导者，努力寻求一种对双方均有积极意义的新方式，希望将AI与开源许可证结合起来。</p><p>&nbsp;</p><p>去年J. Doe等人（匿名）起诉了GitHub。原告在美国加州北区法院控诉微软、OpenAI和GitHub通过其基于AI的商业系统OpenAI Codex与GitHub Copilot窃取了开发者的开源代码。原告方认为，“涉案”代码几乎就是直接从公共GitHub代码仓库中抓取的原始代码副本，且未获得开源许可承认。</p><p>&nbsp;</p><p>目前案件仍在审理中，原告方修改了诉讼方向，包括指控被告违反《数字千年版权法》、违反合同（违反开源许可证）、存在不公平得利和不正当竞争行为，以及违反合同（违反GitHub政策中约定的销售许可条款）。</p><p>&nbsp;</p><p>这类麻烦困扰的不只有微软。耶鲁大学法学院网络安全讲师、耶鲁大学隐私实验室创始人Sean O’Brien认为，“很快就会出现与专利流氓类似的完整子产业，但这一次将主要围绕AI生成的成果。随着越来越多作者使用AI驱动工具在专有许可之下发布代码，这将建立起新的反馈循环。软件生态系统将被专有代码所污染，而这些代码将成为‘有心之人’的索赔载体。”</p><p>&nbsp;</p><p>德国研究员兼政治家Felix Reda等人则声称，一切AI生成的代码都属于公共产出。SmartEdgeLaw Group创始成员之一、美国律师Richard Santalesa认为，这里其实存在合同法与版权法的双重纠纷。Santalesa认为，出售AI生成代码的企业将“与所有其他知识产权一样，将其交付的材料（包括AI生成代码）视为自有财产。”而公共领域代码和开源代码的处理方式并不相同。</p><p>&nbsp;</p><p>更重要的是，这还涉及数据集如何获取许可这个宏观问题。虽然很多开源许可证之下都涵盖大量“开放”数据集，但并不足以彻底解决目前的尖锐冲突。</p><p>&nbsp;</p><p>如今的我们正站在类似的十字路口上。TensorFlow、PyTorch和Hugging Face Hub等AI程序在其开源许可证下运行良好，但其他新AI成果却不知该如何走出自己的道路。数据集、模型、权重等并不完全适合传统的版权模型。Maffulli认为，技术社区应当设计出一些更符合自身目标的新事物，而不能总是依赖于对已有规则的“魔改”。</p><p>&nbsp;</p><p>Maffulli 解释道，为软件设计的开源许可证可能并不适合AI工件。例如，虽然MIT许可证强调的广泛自由度在模型层面比较适用，但Apache或GPl等更复杂的许可证却很可能引发问题。Maffulli还强调，将开源原则应用于医疗保健等敏感领域同样面临着挑战。在这些领域，关于数据访问的法规已经成为行业发展道路上的障碍。简而言之，法律规定医疗数据不得开源。</p><p>&nbsp;</p><p>与此同时，大多数大语言模型的数据集都属于黑盒子，我们根本不知道其中到底有些什么。因此，正如电子前沿基金会（EFF）所言，我们最终陷入了“垃圾进、宝贝出”的茫然境地。为此，EFF建议必须开放训练数据。</p><p>&nbsp;</p><p></p><h2>通过立法保护开源？</h2><p></p><p>&nbsp;</p><p>中国、欧盟、美国和英国等多国政府一直在努力开展AI监管。而Hugging Face、GitHub、EleutherAI、Creative Commons、LAION 和 Open Future等六家开源AI利益相关方组成的联盟正向欧盟立法者请愿，呼吁在设定欧盟AI法案（将成为欧盟AI法案的最终版本，也将是全球第一部全面的人工智能法）时保护开源创新。</p><p>&nbsp;</p><p>在日前发布的政策文件《在欧盟AI法案中支持开源与开放科学》（Supporting Open Source and Open Science in the EU AI Act）当中，开源AI领导者们提出了“如何确保AI法案适用于开源”的相关建议，原则要求“确保开放式AI开发实践不会面临在结构上不切实际的义务，或者其他有碍技术发展的义务。”</p><p>&nbsp;</p><p>根据这份文件，有利于闭源及专有AI开发（例如OpenAI、Anthropic和谷歌等顶尖AI厂商开发的模型）的“过于广泛的义务”，“可能会对开放AI生态系统造成不利影响。”</p><p>&nbsp;</p><p>Hugging Face 机器学习与社会事务负责人Hacine&nbsp;Jernite在采访中表示，虽然政策文件的内容相当丰富，但该联盟想要强调的核心永远是鼓励创新。“我们认为，人们应该能从各类基础模型、组件间自由选择，并根据需求随意组合和匹配，这一点非常重要。”</p><p>&nbsp;</p><p>此外，该联盟还希望强调开源AI的重要性、甚至是必要性，认为监管不应阻碍开源AI的创新道路。Jernite解释道，“开放本身并不能保证负责任的开发态度。但是，开放性和透明度却是负责任治理的必要前提。因此，开放性不是要躲避责任，而责任也不应该妨碍开放发展。”</p><p>&nbsp;</p><p>GitHub高级政策经理Peter Cihon指出，随着欧盟理事会及之后的欧盟议会制定出AI法案草案，立法者们开始审视整个价值链、思考如何减轻其中由AI发展早期引发的风险。</p><p>&nbsp;</p><p>Cihon在采访中指出，“通过这一步骤，我们正加倍努力，确保法案不会在潜移默化中偏向于大企业、或者其他资源充足的AI参与者，而是将这份权利同样交付给出于业余爱好的开源开发者、非营利性组织和学生。总而言之，立法者一直过于关注特定的价值链和特定的模型，大多是API模型——而这种关注在开源背景下并不真正适用。”</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://github.com/huggingface/text-generation-inference/issues/726\">https://github.com/huggingface/text-generation-inference/issues/726</a>\"</p><p><a href=\"https://www.theregister.com/2023/06/23/open_source_licenses_ai/\">https://www.theregister.com/2023/06/23/open_source_licenses_ai/</a>\"</p><p><a href=\"https://venturebeat.com/ai/hugging-face-github-and-more-unite-to-defend-open-source-in-eu-ai-legislation/\">https://venturebeat.com/ai/hugging-face-github-and-more-unite-to-defend-open-source-in-eu-ai-legislation/</a>\"</p>",
    "publish_time": "2023-07-31 14:15:14",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "开源云原生融合网关 Hango 的最新实践与思考",
    "url": "https://www.infoq.cn/article/49azpb4XyqxCBNI1Y4di",
    "summary": "<p>网关，作为互联网流量入口，同时承载着业务安全的期待，在数字时代又被融入云原生能力。对于现代化分布式架构来说，网关所扮演的角色越来越重要。网易数帆在覆盖互联网、银行、证券、保险、能源、制造等行业的云原生网关实践过程中，发现企业对网关的要求日益全面、严苛——&nbsp;既要满足云原生环境的新需求（纳管容器环境出入口流量），又要覆盖新老应用多样的服务纳管功能需求，还要保证始终如一的高性能与稳定性，也要能够作为面向未来的统一网关纳管主流的七层应用流量。</p><p></p><p>鉴于此，网易数帆提出了“融合网关”的概念，并相信这是下一代网关产品的标准形态。本文将解读融合网关诞生的背景与价值，探讨融合网关的设计与实现，并分享基于开源Hango的融合网关实践进展和未来规划。</p><p></p><h3>企业为什么需要融合网关</h3><p></p><p></p><p>2018年网易数帆推出轻舟微服务治理平台时，最早采用的是基于Java开发的API网关1.0。随着微服务平台在网易内外部多个项目的生产落地，我们逐渐意识到API网关1.0在性能、可扩展性和可观测性等方面无法满足用户未来的需求。在数据面代理组件选择上，最终聚焦到成熟的Nginx和新生代的Envoy上，最终我们选择了基于Envoy来构建新一代的API网关2.0，Hango网关由此诞生了。</p><p></p><p>Hango（github.com/hango-io/hango-gateway）是网易数帆基于Envoy和Istio构建的项目，于2021年8月作为高性能的云原生API网关开源，当前已演进为云原生融合网关平台，遵循K8s Ingress/Gateway API 等接口标准，兼容云原生应用和传统应用，融合API网关、微服务网关、七层负载均衡和四层代理等多种形态为一体，帮助企业在云原生时代构建企业级统一的流量接入层和治理平台。</p><p></p><p>Hango融合网关平台简化架构图如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/15/153fe82d30bafe4bc216836c2307e2be.png\" /></p><p></p><p>作为云原生时代的API网关，我们认为除性能、稳定性、丰富的治理能力外，可观测性、可扩展性和热更新能力都是非常重要的能力，做出选择Envoy的决定，更多内容可以阅读 <a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651087960&amp;idx=2&amp;sn=4a681917b701a4cc4861cae49968002f&amp;chksm=bdb99c0b8ace151db81d5c5bffaf22cabeb890674d403e7798ad5153c05bab74488383be237b&amp;scene=27#wechat_redirect\">Hango 开源解读</a>\"轻舟团队也有幸成为国内最早采用 Envoy 作为企业级网关数据面的团队之一，团队中的王佰平同学也是国内首位 Envoy Maintainer（https://sq.sf.163.com/blog/article/675467820063182848）。</p><p></p><p>在API网关2.0的生产实践过程中，我们发现客户的业务系统往往由多种异构应用组成，例如部署方式上有基于容器部署和基于虚拟机部署的，协议类型上有HTTP、Dubbo、gRPC、TCP、UDP和SOAP等等，服务发现上有采用Eureka、Nacos、K8s等等，如何通过API网关统一接入成为了新的挑战。</p><p></p><p>另外，云原生化演进并非一蹴而就，API网关如何统一接入云原生应用和传统应用，这也成了企业应用云原生化演进的拦路虎。</p><p></p><p>让我们来看如下一些典型场景。</p><p></p><p>场景1：当使用HTTPS协议对外暴露服务时，典型的部署方式是API网关之前部署流量网关（例如Nginx），负责SSL证书的卸载。然而，引入流量网关存在增加整体延迟、引入新的故障点以及增加运维成本等问题。为了解决这些问题，一种潜在的解决方案是将流量网关和API网关合并。</p><p><img src=\"https://static001.geekbang.org/infoq/06/06fff712411e54c37819b96ed8934d59.png\" /></p><p></p><p>场景2：客户A 将业务迁移到K8s集群，每个业务方单独部署一套K8s集群，业务方除了HTTP服务外，还有少量的TCP和UDP服务，如果为每个业务方部署一套四层代理，会增加额外的资源部署成本和运维成本，客户希望每个业务都能通过API网关访问HTTP、TCP和UDP服务。</p><p><img src=\"https://static001.geekbang.org/infoq/25/25e255ac0f6262f84a52bd695f3841c2.png\" /></p><p></p><p>场景3：客户B将部分服务迁移到K8s集群，同时保留部分服务采用传统虚机部署方式，迁移到K8s集群的服务，希望通过K8s Ingress标准接口进行配置，客户B希望API网关支持K8s Ingress接口标准，这样对于不同的服务部署形态无需引入两种网关产品。</p><p><img src=\"https://static001.geekbang.org/infoq/74/744402b56da35ba44e68162280f07ccf.png\" /></p><p></p><p>场景4：客户C现有业务通过七层负载均衡对外暴露，随着业务云原生改造，现有的负载均衡在服务注册发现、服务治理、认证鉴权等方面已经无法满足业务方的需求，客户希望能够引入API网关能够统一接入云原生应用和传统应用。</p><p><img src=\"https://static001.geekbang.org/infoq/0d/0d19685c13381d2aeadc7fb7845cf278.png\" /></p><p></p><p>在这样的背景下，网易数帆提出了融合网关的构想，不局限于API网关，它还可以是七层代理、七层负载均衡、K8s Ingress、K8s Gateway等代理形态，目标是成为云原生时代企业级的统一流量接入层和治理平台。</p><p></p><p>对于企业而言，这样的融合网关不仅能够满足不同部署类型、不同协议类型、不同服务发现方式的应用统一接入，还能通过插件市场满足企业差异化的流量管理需求，从而实现统一的平台，大幅降低部署成本和运维成本，同时支撑业务云原生化平滑演进。</p><p></p><p></p><h3>先进的融合网关如何设计</h3><p></p><p></p><p>融合网关的本质，是在百花齐放的云原生时代实现技术平台的统一，不论是对流量管控领域的不同云原生资源实现和规范，还是对服务纳管领域的各种新老服务形态。解决这一问题，新一代Hango融合网关产品的实践，必须具备更加通用的扩展能力。</p><p></p><p>基于此，Hango融合网关的设计目标，是统一流量、服务、协议等网关概念，并提供业务需要的简单操作方式。统一流量是指在原有API网关的基础上，融合业界主流的流量代理产品，包括七层负载均衡、Ingress、Gateway API、Knative等等，实现一个Envoy网关可以代理所有7层应用流量。统一服务主要是针对网关代理的后端服务，可以支持对不同部署形态、不同网络协议、不同注册中心的业务服务进行统一的路由转发和流量治理。可以看到，统一服务也意味着统一协议。</p><p></p><p>为了融合多种流量代理产品，我们为Hango融合网关提出了“虚拟网关”的概念。虚拟网关是网关的逻辑划分，一个网关支持创建多个虚拟网关，多个虚拟网关共用网关处理资源，实现资源复用。同时，Hango还需提供动态创建虚拟网关的能力，以便用户按需快速交付流量代理产品给业务方，满足云原生场景下业务敏捷化的诉求。</p><p><img src=\"https://static001.geekbang.org/infoq/54/548e1c8876390aea80f7975df22ad4f9.png\" /></p><p></p><p>虚拟网关实现了资源的逻辑划分，在实现方案上，我们有两个选择：</p><p></p><p>基于Envoy的Listener端口形式区分不同形态的网关不同的虚拟网关提供不同的访问入口，为每一个虚拟网关提供一个端口。基于Envoy的VirtualHost概念进行流量隔离的网关多个虚拟网关提供同一个访问入口，不同虚拟网关通过域名进行逻辑隔离。</p><p></p><p>相对于Listener隔离方案，VirtualHost隔离是一种更细粒度的管理，Envoy Listener概念下可以分多个VirtualHost，我们一般可以把他与网关域名做关联。对比以上两种方案，我们最终选择了基于Listener端口的方案作为融合网关的技术方案，主要考虑了如下几个因素：</p><p></p><p>VirtualHost隔离方案不支持TCP/UDP等四层代理和七层代理的融合；多个业务方使用相同域名的场景，采用VirtualHost隔离方案，存在路由冲突的风险；采用VirtualHost隔离方案，统一流量入口，缺少流量隔离能力且，对于服务（Envoy Clusters）和在Envoy VirtualHost之上的概念无法进行非常好的隔离。</p><p><img src=\"https://static001.geekbang.org/infoq/51/51ecb8e49f08b995cdc2fd7cbb2d62ba.png\" /></p><p></p><p>主流的流量代理产品，例如七层负载均衡、API网关、微服务网关、四层代理等，在产品功能和产品模型上都存在较大的差异。Hango融合网关定义了虚拟网关类型，同时为不同类型的虚拟网关提供不同的能力集，对于使用单一流量代理产品的用户而言，使用融合网关并不会增加其使用难度。</p><p><img src=\"https://static001.geekbang.org/infoq/8f/8f47e8c4dbb6db1fe8bc946eeec639dc.png\" /></p><p></p><p>Hango目前抽象出了三类虚拟网关类型，分别是通用网关、负载均衡和API网关，后续还会陆续推出K8s ngress、K8s Gateway、TCP和UDP等虚拟网关类型，不同类型的虚拟网关将会提供差异化的能力，以简化用户的使用。</p><p></p><p>通用网关：通用网关涵盖了大部分网关的应用场景，在插件类型上最为丰富，功能也最为强大；API网关：API网关适用于需要对API进行统一管理和控制的场景，例如企业内部的API管理(目前仅商业版支持)、对外提供API服务的场景等；负载均衡：七层负载均衡是是将网络流量分配到多个服务器上的场景，以实现提高系统的性能和可靠性。</p><p></p><p>相较于传统API网关，Hango融合网关具有以下优势：</p><p></p><p>流量隔离：虚拟网关之间通过端口实现了逻辑隔离，不同业务使用不同的虚拟网关，业务流量相互不受影响；统一管控：支持对多种代理形态的虚拟网关进行统一管控，同时不同代理提供差异化的产品功能和可观测性，提升产品易用性；配置隔离：支持虚拟网关维度的治理配置，不同虚拟网关之间的路由配置相互隔离；无侵入插件增强：统一产品插件形态，支持相同插件在所有代理产品生效，同时提供动态无侵入的自研插件体系，实现插件“一处开发，处处生效”的能力；自定义插件：支持多语言的自定义插件能力，用户可以通过Lua或Wasm快速实现自定义插件。</p><p></p><h3>Hango融合网关未来展望</h3><p></p><p></p><p>Hango 网关发展至今，已陆续发布了 5 个大版本（v1.0.0 - v1.4.0），如下图所示：</p><p><img src=\"https://static001.geekbang.org/infoq/7e/7eee5c479e7fe03ce17b4f5f8a543456.png\" /></p><p></p><p>朝着云原生时代企业级的统一南北向流量接入和治理平台的目标，Hango融合网关未来将会陆续推出一系列新特性，以支持不同部署类型、不同协议类型、不同服务发现方式的应用统一接入，提供多种代理形态。主要新特性如下：</p><p></p><p>遵循Knative Gateway接口标准</p><p></p><p>作为Knative服务的入口流量网关，纳管Knative南北向流量，同时提供Knative服务的流量治理能力和指标监控。</p><p></p><p>TCP、UDP协议</p><p></p><p>增强Istio的协议支持能力，提供基于Envoy端口维度的TCP、UDP协议路由转发，同时提供TCP、UDP流量的指标监控能力。</p><p></p><p>插件市场</p><p></p><p>提供多语言自定义插件扩展能力，主要包括社区的Wasm和网易数帆开源的Hango Rider，目前Wasm支持多种语言（C++、Go、Rust 等），Rider支持Lua语言。使用时用户可以基于Lua、Go等语言实现自定义插件逻辑，然后通过轻舟控制台进行导入即可生效。同时支持schema插件可视化，提供插件配置预览能力。</p><p></p><p>七层负载均衡代理形态</p><p></p><p>提供以多种部署方式，具有高可用、多租户、多协议、服务发现、流量转发，SSL/TLS加速、缓存压缩、安全防护、数据分析、自定义插件等特性和能力的七层负载均衡代理形态。</p><p></p><p>近期后续版本Hango产品计划支持四层流量纳管方案，以及各类7层的高阶负载均衡能力，详细可参考Hango 2023 RoadMap: https://hango-io.github.io/getting-started/roadmap/roadmap-2023</p>",
    "publish_time": "2023-07-31 14:44:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "大家究竟需要怎样的“生成式 AI”？目前已达到 “临界点”？",
    "url": "https://www.infoq.cn/article/8gEs1r7RN8Ho7otaBG6N",
    "summary": "<p></p><p>生成式 AI （Generative AI）已经成为全球范围内的一个重要趋势，得到越来越多企业和研究机构的关注和应用，生成式 AI 的全球市场正在迅速扩大，据 IDC、摩根大通等多家研究机构数据预测，预计到 2025 年，全球生成式 AI 市场的规模将达到 110 亿美元，年复合增长率超过 50%。</p><p></p><p>各大科技公司纷纷投入巨资开展生成式 AI 技术的研发和应用，纽约时间 7 月 26 日，亚马逊云科技数据库、数据分析和机器学习全球副总裁 Swami Sivasubramanian 在<a href=\"https://xie.infoq.cn/article/069e3373016cdacede05c4b11\">亚马逊云科技</a>\"举办的纽约峰会（下文称“峰会”）上更是表示，“生成式 AI 技术已经达到临界点。”</p><p></p><p>目前我们观察到，随着机器学习、深度学习等技术的不断迭代，生成式 AI 的应用趋势正朝着端到端的方向发展。端到端的生成式 AI 应用可以直接从原始数据中生成新的数据，而不需要进行显式的特征提取或手动设计生成模型，这大大提高了生成效率和生成质量。同时，端到端的生成式 AI 应用还可以更好地理解和控制生成过程和结果，从而提高其可解释性和可靠性。</p><p></p><p>而本次峰会上亚马逊云科技宣布的“生成式 AI 创新\"也是将“端到端”显示的淋漓尽致，进一步降低了生成式 AI 的使用门槛，无论是业务用户还是开发者都可以从中受益，来自千行百业的企业都能更专注于核心业务，提高生产效率，充分释放数据价值和生成式 AI 的潜力。</p><p></p><p></p><h2>一、生成式 AI 的第一要务是“帮用户解决生产问题”</h2><p></p><p></p><p>随着人工智能技术的快速发展，生成式 AI 已经得到了越来越多的生产者和企业的关注和应用，进入高速发展期。生成式 AI 技术可以通过学习大量的数据和知识，然后生成新的数据和内容，例如图像、文本、声音等；其可以应用于许多领域，例如自然语言处理、图像处理、语音识别等。在生产环境中，生成式 AI 技术可以用来自动化许多繁琐的工作，例如编写代码、设计产品、翻译文本等。帮助企业提高生产效率、降低生产成本、提高产品质量，为企业的创新和发展提供强有力的支持。</p><p></p><p>说到底，生成式 AI 之所以可以被企业关注，其核心原因还是自于生产者的需求驱动，生产者需要提高生产效率和降低生产成本，而生成式 AI 技术可以帮助他们实现这个目标。例如，在一个工厂中，使用生成式 AI 技术可以自动生成最佳的制造流程，从而提高生产效率并降低成本等。正如 Swami 在纽约峰会上所说的，生成式 AI 的核心价值就是“通过生成式 Al 消除繁重的工作并提高生产力”。</p><p></p><p>在生成式 AI 技术的发展中，推动技术研发厂商不断前进的动力就是用户“既要又要还要”的业务需求和技术需求。在满足用户需求方面，<a href=\"https://xie.infoq.cn/article/2a78efa09dbc50c71b27c1b33\">亚马逊云科技</a>\"是业内做的相当不错的厂商，前段时间推出的  Amazon Bedrock 便是一大利器，通过 Amazon Bedrock，文本生成、聊天机器人、搜索、文本摘要、图像生成、个性化情景式产品推荐等功能实例可以完美集成于应用中。</p><p></p><p>然而，只说功能多样性，不拆解技术的硬核，这对于生成式 AI 研发厂商是不公平的。评价一个模型的好坏，我们要从多个维度去看。</p><p></p><p>从训练和部署、架构扩展层面，一个好的模型需要易于训练和部署、提高效率，并能够随着业务需求变化进行扩展和升级。Amazon Bedrock 提供可扩展的 API 和无服务器体验，客户可以使用自有数据基于基础模型进行定制，并使用熟悉的工具和能力进行集成和部署，无需管理基础设施，降低成本。用户还可以使用SageMaker、Experiments 和 Pipelines 等功能实现模型的集成和自动化管理、部署。</p><p></p><p>在数据安全层面，好的模型需要具备安全的数据存储能力，能够保护用户的数据不被泄露和滥用。而 </p><p>Bedrock 非常注重数据的安全性和隐私保护，对所有数据都进行了加密，并且不会离开客户的虚拟私有网络（VPC）。此外，Amazon Bedrock 还提供了可配置的数据共享选项，客户可以控制数据共享和使用，确保数据的完整性和机密性。</p><p></p><p>在模型选择层面，一个好的模型需要具备丰富的模型选择，能够满足不同领域和场景的需求。用户需要能够选择适合自己业务的模型，并能够灵活地组合和集成多个模型，以实现更好的业务效果。Bedrock 提供了丰富的的基础模型选择，满足不同领域和场景的需求，使得用户可以更加灵活地选择和组合模型，满足自身的业务需求：</p><p></p><p>AI21 Labs 开发的的多语种大语言模型系列 Jurassic-2，可根据自然语言指令生成文本内容；Anthropic 开发的大语言模型 Claude，能够执行多种对话和文本处理任务；Stability AI 开发的文生图基础模型 Stable Diffusion，能够生成独特、写实、高清的图像、艺术作品、商标和其它设计图；Anthropic 接入到 Amazon Bedrock 的最新语言模型 Claude 2，可以在每个对话任务提示中使用 10 万个标记，能处理数百页文本甚至整本书。相比之前版本，还可以撰写长篇文件，长度可达几千个标记；Stability AI 将发布最新版文生图模型套件 Stable Diffusion XL 1.0，能够生成更逼真的影视、电视、音乐和教学视频，具有更精细的图像和构图细节。亚马逊云科技新增的基础模型供应商 Cohere 将提供更直观地生成、检索和汇总信息的基础模型服务。</p><p></p><p>本次峰会上，<a href=\"https://xie.infoq.cn/article/07dba28182f5f9b9587918e5f\">亚马逊云科技</a>\"宣布全面扩展其全托管基础模型服务 Amazon Bedrock，发布变革性的新功能 Amazon Bedrock Agents，该功能将助力开发者轻松创建全托管的 AI Agents，帮助开发者研发提效，解决开发过程中的复杂度问题。比如自动分解任务并创建编排计划，无需手动编码，开发者可以轻松创建基于生成式 AI 的应用程序，完成各种复杂任务；安全地访问和检索公司数据，通过简单的 API 接口连接，自动转换数据为机器可读格式，增加相关信息生成准确回答；自动调用 API 满足用户请求，例如保险机构可以开发生成式 AI 应用程序，帮助员工自动处理保险索赔或管理文书；提供完全管理的基础架构支持，消除了系统集成管理和配置工作，使开发人员能够充分利用生成式 AI，实现“全托管”。</p><p></p><p>要知道，在帮助用户构建自己的软件应用程序方面，在生成式 AI 没有步入舞台之前，低代码和无代码平台已经发挥了至关重要的作用，这些用户很少具备或根本没有编程知识。然而，随着生成式 AI 的加入，这些平台的使用将达到一个临界点，会产生全新的开发方式。</p><p></p><p>目前很多专业开发者开始使用 ChatGPT 进行软件开发，事实表明 ChatGPT 可以为开发工作提供帮助，但在具体的业务场景中，开发者需要的不仅是可以编代码的工具，而是从源头降低软件开发复杂度的工具。想要从源头入手降低软件的复杂度，就意味着开发者需要设计良好的架构、简化功能和模块开发、采用合适开发工具等方法，从而来减少软件中的不必要的复杂度，提高软件的可维护性、可读性和可扩展性。而亚马逊云科技此次新推出的 Amazon Bedrock Agents 便有效解决了这些难题，是 Amazon Bedrock 的一大看点，也是生成式 AI 领域在降低开发复杂度的新节点。</p><p></p><p></p><h2>二、向量数据库是生成式 AI 的基石</h2><p></p><p></p><p>随着大模型和生成式 AI 技术的高速发展，数据安全和数据自定义成为了技术发展的基础，当前企业普遍比以往更为注重数据，数据已经成为企业的技术壁垒，与生成式 AI 结合的空间很大。</p><p></p><p>大模型和生成式 AI 需要大量数据训练，这些数据需要预处理和自定义以满足模型需求。同时，为确保数据的准确性和一致性，提高模型的准确性和效率，数据自定义要求越来越高。这意味着，以往只存储结构化数据的企业数据库已不能满足需求，于是向量数据库成为了全球数据库发展的重要趋势。</p><p></p><p>向量数据库当前被视为生成式 AI 的基石，因为其存储和处理的数据都是向量形式，而生成式 AI 模型则需要使用向量数据进行训练和推理，它提供了高效的数据存储和查询方式，并且可以与深度学习框架无缝集成，这种集成使得生成式 AI 模型能够更快地学习和生成更准确的数据。换言之，想要训练好生成式 AI，那必须要深度发展向量数据库技术。</p><p></p><p>生成式 AI 使用深度学习框架来学习数据中的模式，这些框架使用张量（即多维数组）来存储和操作数据，而向量数据库则提供了一种高效的方式来实现这种张量存储和操作。向量数据库使用向量索引和向量相似性算法来存储和查询数据，这种存储和查询方式非常高效，可以快速地执行类似“最近邻”这样的查询，而这种查询正是在生成式 AI 模型中非常常见的。</p><p></p><p>目前在研究大模型、生成式 AI 的厂商几乎都在同时研究向量数据库技术，基于生成式 AI、大模型的训练场景，各家的技术成果目前几乎没有太大差距。然而在本次纽约峰会上，亚马逊云科技新发布的适用于 Amazon OpenSearch Serverless 的向量引擎让人眼前一亮，正式可用后，该向量引擎支持简单的 API 调用，可用于存储和查询数十亿个 Embeddings。未来，所有亚马逊云科技的数据库都将具有向量功能，帮助客户简化运营，方便集成数据。</p><p></p><p>Embeddings 是一种将文本、图像、声音等数据转换为向量表示的方法以便于使用机器学习算法进行处理，目前在研发向量数据库的厂商都在相关方面展开了探索。亚马逊云科技本次在该方面的新发布，完全是从用户需求出发。</p><p></p><p>要知道，正常情况下的 Embeddings 应存储在靠近源数据的位置，一系列因素都将影响企业如何选择最适合自己的选项，比如当前数据存储位置、对数据库技术的熟悉程度、向量维度的扩展、Embeddings 的数量和性能需求等，因此亚马逊云科技为大家提供了三个选项满足更高级的向量数据存储需求：</p><p></p><p>Amazon Aurora PostgreSQL 兼容版关系型数据库，支持 pgvector 开源向量相似性搜索插件，对需要存储和搜索大量向量数据的应用场景帮助意义很大；分布式搜索和分析服务 Amazon OpenSearch，带有 k-NN（k 最近邻）插件和适用于 Amazon OpenSearch Serverless 的向量引擎，可以处理大规模的向量数据、提供高效的搜索服务；兼容 PostgreSQL 的 Amazon RDS 关系型数据库，支持 pgvector 插件，可以满足企业日常对于 PostgreSQL 数据库的兼容性和向量数据存储需求。</p><p></p><p>由于向量数据通常具有很高的维度和稀疏性，采用传统的存储方式会占用大量的存储空间，在向量数据存储和查询过程中，需要执行许多复杂的计算，所以如何对向量数据进行压缩和优化、优化算法以提高计算效率是向量数据存储技术领域持续探索的问题，而此次亚马逊云科技新发布的向量引擎也为解决这两个技术壁垒提供了有力支持，同时从用户的需求层来看，这也是向量数据存储技术的新突破。</p><p></p><p></p><h2>三、生成式 AI 同样需要“加速”</h2><p></p><p></p><p>生成式 AI 作为一种强大的技术，目前已在多个领域展现出了巨大潜力。然而在实际应用中，尽管其强大的创造力和表达能力令人惊叹，但生成式 AI 在“速度”方面仍有很大的进步空间。比如生成式 AI 的训练和推理过程非常耗时，尤其是再处理大规模的数据集时，速度是其限制因素之一；在实时性至关重要的自然语言处理等领域，如果生成式 AI 无法在短时间内生成结果，用户可能会感到沮丧甚至流失。总之，随着虚拟现实、实时翻译等越来越多创新场景的涌现，用户对生成式 AI 的速度有了越来越高的要求。</p><p></p><p>GPU 作为专门用于并行计算的处理器，可以同时处理多个数据单元来提高计算速度。在生成式 AI 的训练中，需要进行的大量矩阵运算和反向传播等计算、处理大量的数据和模型参数，而这些计算任务均可以通过 GPU 进行并行计算，以达到加快计算速度，降低训练时间的目的。这意味着，只要 GPU 选型选的好，那降低生成式 AI 的训练成本、提高训练质量就是分分钟的事。</p><p></p><p>本次峰会上新发布的 Amazon EC2 P5 实例作为亚马逊云计算平台上的一种强大的计算实例类型，便很好地满足了目前用户在生成式 AI 训练过程中的 GPU 需求。</p><p></p><p>Amazon EC2 P5 实例以其出众的硬件配置提供了卓越的计算、存储、横向拓展性能，它搭载了 8 个NVIDIA H100 Tensor Core GPU，拥有 640GB 高带宽 GPU 内存，同时提供第三代 AMD EPYC 处理器、2TB 系统内存和 30TB 本地 NVMe 存储。同时，Amazon EC2 P5 实例还提供 3200Gbps 的聚合网络带宽并支持 GPUDirect RDMA，从而能够绕过 CPU 进行节点间通信，实现更低的延迟和高效的横向扩展性能。</p><p></p><p>大家需要明确的是，NVIDIA H100 GPU 具有新的转换器引擎，可智能地管理和动态选择 FP8 和 16 位计算，与上一代 A100 GPU 相比，可在 LLM 上提供更快的 DL 训练加速。对于 HPC 工作负载，与 A100 GPU 相比，NVIDIA H100 GPU 具有新的 DPX 指令，可进一步加速动态编程算法。这种计算能力对于生成式 AI 模型中大量的矩阵计算和向量运算至关重要，与上一代基于 GPU 的实例相比，训练时间最多可缩短 6 倍。通过利用 P5 实例的高性能计算资源，可以显著降低训练成本，加快生成式 AI 的处理速度。</p><p></p><p>为了能够满足生成式 AI 模型的大量训练数据、模型参数及中间结果的大量数据存储和加载需求，Amazon EC2 P5 实例还提供了大容量的本地存储空间，使得我们能够更高效地管理和处理大规模的数据集，在本地存储的支持下，避免频繁的数据传输和加载，从而进一步提升生成式 AI 任务的效率。</p><p></p><p>值得一提的是，部署在第二代 EC2 UltraCluster 中的 Amazon EC2 P5 实例，与上一代 UltraCluster 相比，该网络结构可实现更大的规模、更少的集群网络跃点和更低的延迟。UltraClusters 中的 P5 实例可以扩展到与 PB 级网络互连的 20000 个 H100 GPU，并提供 20 exaflops 的聚合计算能力。</p><p></p><p></p><h2>四、端到端的生成式 AI“未来已至”</h2><p></p><p></p><p>无论是完全托管式的 Amazon Bedrock，还是适用于 Amazon OpenSearch Serverless 的向量引擎、Amazon EC2 P5 实例，我们能看到的是，亚马逊云科技结合用户需求在生成式 AI“端到端”方面的探索越来越深入。作为 GenAI 领域的技术领导者，亚马逊云科技凭借先进的技术、庞大的生态体系、丰富的实践经验和可靠的安全性，为自己的用户们提供了愈来愈全面的支持和几近完美的解决方案来推动端到端生成式 AI 的发展。</p><p></p><p>Swami 在峰会上宣布”生成式 AI 技术已经达到临界点“，这意味着它变得更加成熟和可靠。亚马逊云科技利用自己过往在深度学习框架、算法库和工具等 AI 方面的探索经验，与全球数千个合作伙伴和数据科学家合作，持续输出完整、高效的 AI 解决方案，一心降低生成式 AI 的应用门槛，使更多人能够享受到这项技术的益处。</p><p></p><p>除了已经提到的几个亮点技术，在本次峰会上，亚马逊云科技还推出了其他四项生成式 AI 技术与应用——AI 编程助手 Amazon Codewhisperer 通过提供丰富的模型和算法库来快速构建和训练生成式 AI 模型，使得开发者能够更轻松地进入生成式 AI 领域，并在图像、语音和文本生成方面得到更好的支持和指导；亚马逊云科技将 Amazon Bedrock 的大语言模型能力与 Amazon QuickSight Q 的自然语言问答功能相结合，提供生成式 BI 功能，提高了数据分析的效率和易用性，同时结合数据可视化，Quicksight 将数据分析结果以更直观丰富的方式展现，让用户更好地理解和利用数据。此外，亚马逊云科技还通过 Amazon Entity Resolution，赋能企业提升数据质量、获取客户洞察；推出 Amazon HealthScribe，利用生成式 AI 助力构建医疗应用程序。</p><p></p><p>一直以来亚马逊云科技致力于降低生成式 AI 门槛，使更多的人能够轻松尝试和应用这项技术。他们希望成为生成式 AI 的普惠领导者，让更多的人从中受益。在峰会上，Swami 更是提到了生成式 AI 技术的发展需要“利用专门构建的 ML 基础架构实现低成本、低延迟的目标”，而亚马逊云科技也确实是这样做的——他们通过构建高效的基础架构和提供灵活的计算资源，来支持生成式 AI 技术的发展，他们不仅提供了高性能的 GPU 实例来加速模型训练，还推出了 Lambda 函数和 SageMaker 等服务，使得生成式 AI 模型的部署和运行更加简便和经济高效。</p><p></p><p>我们从本次峰会上的<a href=\"https://xie.infoq.cn/article/1fd9d82ea3f46f28a2e805e6a\">亚马逊云科技</a>\"的新发布中不难看出，生成式 AI 的未来已经到来。为了共同推动技术的下一步演进，我们需要更多像亚马逊云科技这样的厂商和所有用户一起努力，相互学习、互相促进、携手并进，为生成式 AI 技术的发展提供更多解决方案。</p><p></p><p>更多关于亚马逊云科技在生成式AI方面的探索请<a href=\"https://aws.amazon.com/generative-ai/?social0731&amp;sc_channel=sm&amp;campaign=genaikol\">点击链接</a>\"查看。</p>",
    "publish_time": "2023-07-31 15:00:26",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "阿里云飞天发布时刻",
    "url": "https://www.infoq.cn/article/PavJKSvqZpJvAsypklhW",
    "summary": "<p><img alt=\"\" src=\"https://static001.infoq.cn/resource/image/bc/74/bcff9dd544yy71e02331a721df016474.png\" /></p>",
    "publish_time": "2023-07-31 15:02:47",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "电信行业数据库创新应用论坛｜2023可信数据库发展大会",
    "url": "https://www.infoq.cn/article/brEJUaekjSmCk3FrP7zU",
    "summary": "<p>近年来，在云网深度融合的背景下，电信行业数据库应用蓬勃发展，新的数据库技术和产品正在加速涌现，同时，电信企业在数据库国产化的实践中，也面临着重复建设、安全可控能力难把握等各种问题。如何规避数据库国产化改造过程中的风险？如何最大化控制时间、人力等成本？2023年7月5日，电信行业数据库创新应用分论坛邀请本领域资深专家、杰出厂商代表，回顾数据库产业界60年来的发展历程，剖析中国数据库产业格局和痛点，分享总结实践经验，多维度探讨破局之道和发展未来。</p>",
    "publish_time": "2023-07-31 15:06:13",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "金融行业数据库创新应用论坛｜2023可心数据库发展大会",
    "url": "https://www.infoq.cn/article/v428rJlR7sxiHrzgBlc7",
    "summary": "<p>随着人工智能、区块链、云计算和大数据等新一代信息技术的崛起，金融行业的数字化转型已然迈入深水区。一直处于数字化转型第一梯队的金融业，正走在多元混合数据库架构转型和创新的征途之中。如何加速数据要素价值释放，助力金融业务创新？如何贴近金融用户的实际需求，解决数据库转型痛点难题？7月5日，金融行业数据库创新应用分论坛将邀请业内精英，共议金融数字化转型之道，分享实践经验与解决方案，共筑安全可持续的金融创新生态。</p>",
    "publish_time": "2023-07-31 15:08:01",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "数据库运维与生态工具论坛｜2023可信数据库发展大会",
    "url": "https://www.infoq.cn/article/QGtJLSINrqCjZ2tpZ7ls",
    "summary": "<p>近年来，开源和国产数据库百花齐放，呈现出多元混合的发展态势，加之企业的数字化需求愈加复杂，数据库管理和运维的重要性与日俱增。与此同时，企业IT架构随着数字化转型的持续深化正在不断探索全新的架构和技术。企业数据库正在向云化、国产化、分布式方向演进。2023年7月5日，数据库运维与生态工具分论坛邀请业内专家学者、厂商代表共聚一堂，聚焦数据库国产化进程中的核心难题，分享转型升级落地经验，共议新时代的发展趋势，共同护航我国数据库生态稳健发展。</p>",
    "publish_time": "2023-07-31 15:09:54",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "汽车行业数据库创新应用论坛｜2023可信数据库发展大会",
    "url": "https://www.infoq.cn/article/6trSFwVk7E278VRKrwcR",
    "summary": "<p>随着传感器、5G通信和AI技术的进步，智能网联汽车开始大规模快速普及，汽车行业正在面临前所未有的数据爆炸挑战。在新一轮信息技术革命和产业变革的时代背景下，汽车行业如何构建安全、易用的数据基座？如何高效、低成本的存储和分析海量多样化数据？如何运用数据库赋能汽车关键应用场景？2023年7月5日，汽车行业数据库创新应用分论坛邀请本领域资深专家、厂商代表一起分享和探讨汽车行业的转型探索与创新实践，助力汽车行业筑牢数字化转型新基建。</p>",
    "publish_time": "2023-07-31 15:10:43",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "云原生与开源数据库论坛｜2023可信数据库发展大会",
    "url": "https://www.infoq.cn/article/jgEewWBLIH53AuqplzIs",
    "summary": "<p>随着数字化、混合云的飞速发展，云原生成为当前数据库产品的重要演进方向，且推动着开源数据库持续纵深发展。日益繁荣的发展生态，还有哪些想象空间和发力之道？蓬勃增长的数据洪流，将带来哪些全新挑战？纷繁复杂的技术趋势下，新一代技术又将如何演变？2023年7月5日云原生与开源数据库分论坛将邀请在本领域深耕多年的公司与专家，齐聚论道新实践、新成果、新趋势，深入探讨未来的技术走向。</p>",
    "publish_time": "2023-07-31 15:13:33",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "⻜桨⼤模型推理部署⾼性能优化",
    "url": "https://www.infoq.cn/article/59d4a7fb427c188dd4c888f0c",
    "summary": "<p>这是 <a href=\"https://cloud.baidu.com/solution/aif.html?track=infoq01\">AI 大底座</a>\"系列云智公开课的第 6 期内容。上一期我的同事给大家介绍大模型分布式训练过程中的优化方法，当大家完成大模型的训练后，接下来的工作就是需要完成上线部署，今天我们就介绍一下在大模型推理部署过程中的高性能优化方法。</p><p>今天将从如下三个方面开展开这次分享：</p><p>介绍大模型推理的背景、需求和难点；介绍生成式大语言模型的推理部署高性能优化方法；介绍文生图类多模态大模型的推理高性能优化方法。</p><p></p><p></p><h1>1. 大模型推理的需求和难点</h1><p></p><p>大家都知道近年来大模型一致保持着较高的关注度，像国外的 OpenAI、Google，国内的百度等都持续在大模型方向上做着长期的积累和探索。另一方面，在大语言模型上，随着去年年底 ChatGPT 这个爆款的发布，也引发了全民大模型的热潮，在国内百度首发了文心一言生成大模型，其后像阿里的通义千问、科大讯飞的星火也相继推出，国外也有像 Bard，ChatGLM 等模型陆续发布。而在多模态大模型上，文生图也是一个关注度很高的领域，百度也推出了文心一格文生图AI艺术和创意辅助平台，国外也有像 Stable Diffusion，Midjourney 等相关的应用推出。</p><p><img src=\"https://static001.geekbang.org/infoq/17/170e6bd2d746cba1705578aecb65f8d0.png\" /></p><p>随着大模型相关的应用爆发式的增长，对大模型的线上推理部署需求也是越来越强烈，但是具体到去完成一个大模型相关的服务上线，又会遇到很多难点。对于大模型来说，优势是「大」，难点自然也是「大」。首先是参数量大，比如 175B 的GPT-3 模型，光权重就有 350GB 左右，权重会占用大量的显存，能顺利部署都是一大挑战，更别说提升部署的并发度了。其次是计算量大，对算力的要求非常高，相应的推理时延也很长。由于「参数量大」和「计算量大」，大模型推理部署的成本就会非常高，使得业务想要接入、使用大模型的门槛会非常高，也会限制业务接入的用户量，像现在文心一言和 ChatGPT 都有用户需要排队的现象，就是因为部署成本高的原因。</p><p>鉴于大模型推理部署的强需求和部署过程中的难点，飞桨一直在致力大模型推理部署的高性能优化工作，下面就先介绍一下飞桨在大语言模型的推理部署上的高性能优化工作。</p><p><img src=\"https://static001.geekbang.org/infoq/25/25def9a849fd839e4b6f00ef4b9d83b9.png\" /></p><p></p><h1>2. 大语言模型推理部署高性能优化</h1><p></p><p>要进行生成式大语言模型的推理优化，首先我们来详细分析一下生成式大模型的推理过程。</p><p></p><h2>2.1 生成式大模型推理流程分析</h2><p></p><p>左边是一个常见的 Transformer 类大模型的结构示意图，用户问的问题一般会先经过预处理成为一系列的 token，这些 token 首先经过 Embedding 模型，可以理解为每个 token 会被转换成一个词向量。这一系列的词向量会进入多层 Transformer 结构进行计算，而对于每层 Transformer 结构，又可以划分成 Self Attention 和 Feed Forward(FFN) 两部分，这两部分前后一般会经过一个 Norm 结构，可以是 LayerNorm、RMSNorm、DeepNorm 等等，这样的 Transformer 结构会重复多次，一般被称为多层，比如 30 层，48 层 Transformer。完成了多层 Transformer 的计算之后，后再经过一个 Norm 和一个 Linear，这个 Linear 的输出就是我们常说的 logits 了，训练的时候后面再接一个 Softmax 和 Loss 就可以训练了。</p><p>如果是类似分类、检测这些传统任务，训练和推理的组网是一致的，主要的区别是最后是接 Loss 还是接 TopK，NMS 等，但是对于生成式任务推理组网却会不一样，可以看到推理过程中组网逻辑上分为两个阶段，Context 阶段（又称 Encoder）主要对输入编码，产生 CacheKV，在计算完 logits 之后会接一个Sampling 采样模块，采样出来第一个生成的 token，并将这个 token 和 CacheKV 作为 Generation 阶段（又称 Decoder）的输入，Generation 阶段在一个 While 循环里，读取 token 和 CacheKV 后通过自回归解码的方式每循环一次产生一个 token。</p><p><img src=\"https://static001.geekbang.org/infoq/94/94ee780b2a7a9b02ff7d777a28caa038.png\" /></p><p>具体自回归解码的过程可以通过下图看出，假设输入「你是谁？」经过预处理变成 4 个 token，分别是「你」，「是」，「谁」，「？」，自回归解码流程如下：</p><p>这 4 个 token 会在 Transformer 计算时记录下 CacheKV 的信息(CacheKV 实际上记录的是 Transformer 中 Attention 模块中 Key 和 Value 的值）最终通过 Sampling 阶段采样出来第一个 token 为「吴」；Context 阶段生成的 token “吴\"会作 Generation 阶段的输入，「吴」在 Generation 阶段的 While 循环出判断，While 判断生成没有结束，执行 While 中的计算，计算中会在 Attention 中计算出「吴」对应的 CacheKV 信息存储下来，并拼接上所有的历史 CacheKV 信息进行计算，最后采样出来下一个 token 为「彦」；「彦」传回来作为 Generation 输入再次执行，自己的输出作为自己的输入，不断回归迭代，就是「自回归」，同样在 While 处判断需要继续生成，计算和拼接 CacheKV 信息并采样出下一个 token 为「祖」；最后在把「祖」作为输入生成下个 token 为「gEnd」, 「gEnd」为一个特殊的 token，用来标识生成结束，While 循环检测到「gEnd」生成结束，就会退出循环，本次生成推理过程结束。</p><p><img src=\"https://static001.geekbang.org/infoq/e9/e9b10670beee98e6dc5780380423d5e6.png\" /></p><p>了解了大模型推理过程的生成流程之后，我们再来详细分析一下这个生成过程。</p><p>以 175B 的 GPT-3 模型，输入 1000 个 token，生成 250 个 token 为例，那么 Context 阶段的激活 Shape 为 [B, 1000, 12288]，其中 B 为 batch_size，第二维为输入 token 数，第三位为 hidden size。而对于 Generation 阶段，由于每次输入输出都是固定的 1 个 token，是通过循环多次来产生多个输出 token，所以 Generation 阶段的激活 Shape 的第二维始终为 1，Generation 的激活显存占用是远小于 Context 阶段的。</p><p>再来看计算量，这里可以看到挺多有趣的结论：</p><p>Context/Generation 的计算量均随 batch size 增大而正比增大，这个很好理解，因为 batch 内每个样本的计算量是一致的；Context/Generation 的访存量随 batch size 增大却基本不变，访存量可以分为权重访存和激活访存，很显然激活的访存是随 batch size 增大而增大的，但是权重访存却不会随 batch size 变化而变化，而由于激活的访存量远小于权重的访存量，就会出现总访存量几乎不随 batch size 变化而变化；Context 是计算密集型的任务，而 Generation 是访存密集型的任务，这是由于 Context 的计算量大，但是 Generation 由于每次都只计算 1 个 token，所以计算量远小于 Context，但是权重的访存量确实一致的，所以 Generation &nbsp;阶段反而是访存密集型的任务。</p><p><img src=\"https://static001.geekbang.org/infoq/b9/b962b80294302c69a15433efad6eb47b.png\" /></p><p>经过上述分析，大家了解了大模型生成过程的流程和计算量，我们再来看一下大模型推理的常见优化方法。</p><p>首先是分布式并发推理，由于大模型权重较大，经常出现单卡放不下的现象，因此通过分布式多卡并发的方式是常见的实现大模型推理可行性的方式。推理过程中的分布式并发和训练过程类似，常用的有张量（模型）并行和流水线并行两种方式，其中张量并行是将每个权重和相关计算都切分到多卡上，并在每次 Attention 和 FFN 计算完成后通过卡间通信来汇总计算结果，而流水线并行则是通过将不同层的权重和计算切分到多卡上，每次推理通过流水线的方式依次在各卡上完成推理。</p><p><img src=\"https://static001.geekbang.org/infoq/07/077000324865be2f5f61b131616a7d54.png\" /></p><p></p><h2>2.2 推理时延优化方法</h2><p></p><p>分布式并行更多是为了解决推理可行性问题，在推理时延优化上，通用的 Transformer 结构融合是常用的推理加速方式，这张图总结了常见的多层 Transformer 融合优化方法，业界也有很多相关的开源实现，飞桨通过这些优化后，推理速度可以打平或领先 NVIDIA FasterTransformer。</p><p><img src=\"https://static001.geekbang.org/infoq/1d/1d908b20dac661fb09b08626741ed468.png\" /></p><p>下面介绍一些进阶的推理时延优化方法。</p><p>动态量化是通过在推理过程动态的讲计算和激活转换为低精度的 INT8 计算来实现时延和显存的降低，但是为了保证精度无损往往需要进行特殊的算法设计，或者对量化部分做一些取舍。这里介绍了两种适用于生成式大模型的动态量化方法。</p><p>其中 LLM.int8() 结合大模型激活的离群点集中在少数通道上的特点，将离群点通道拆分出来做 FP16 计算，非离群点通道做 INT8 计算，计算完后再组装回去的方式来实现无损量化，适用于计算密集型的任务，而 Weight Only 量化则只对更易无损量化的权重，优化权重的存储和传输访存开销，适用于访存密集型的任务。</p><p><img src=\"https://static001.geekbang.org/infoq/54/548b1d6bc35c7f11a23149d63bf6ec00.png\" /></p><p>针对生成式大模型的特性，可以在 Context 阶段使用适用于计算密集型任务的 LLM.int8()，在 Generation 阶段使用使用访存密集型任务的 Weight Only 量化。</p><p><img src=\"https://static001.geekbang.org/infoq/54/541001b0554972812d17985355e32305.png\" /></p><p>PTQ 量化相比于动态量化有更好的精度和速度，但是需要通过校准的方式计算量化 scale。SmoothQuant 是一种常用的大模型量化算法，由于生成式大模型激活离群点较多，比较难量化，而权重比较平滑，易于无损量化，SmoothQuant 通过等效变量，将激活的的离群点缩放到权重上去，平衡激活和权重的量化难度，从而实现更好的量化效果。</p><p><img src=\"https://static001.geekbang.org/infoq/2a/2ac2dc9e2da60d060123c7318f835f5a.png\" /></p><p></p><h2>2.3 服务吞吐优化方法</h2><p></p><p>在服务部署上，除了推理时延优化外，还可以针对服务吞吐进行优化，增加 batch size 是常见的优化吞吐的方式，从表中可以看到，增大 batch size，虽然推理时延也会增加，但是 QPS 却能显著提升，但是大模型的显存占用大，增大 batch size 依赖对显存进行优化，其实上面介绍的时延优化方法中，融合和量化均能在优化时延的同时节省显存，同时也可以通过框架显存管理和多层 Transformer显存复用等方式进一步优化显存，从而开启更大的 batch size，提升推理并发度，实现吞吐提升。</p><p><img src=\"https://static001.geekbang.org/infoq/20/2001014809333338d6455d57ccac1e6a.png\" /></p><p>增加 batch size 是常用的提升并发的方式，但是生成式任务有其特殊性，它是通过 While 循环来实现持续生成的，每次 While 循环 batch 内每个样本生成一个 token，但是由于不同样本的生成长度不一致，随着样本结束生成，实际生成过程中的并发度在持续变小，不利于并发度的提升，因此可以通过动态插入的方式来提升生成过程中的并发度。</p><p><img src=\"https://static001.geekbang.org/infoq/2b/2bb8d209ea00b26d9ed041122c0a518d.png\" /></p><p>动态插入即在生成过程中实时地监控 batch 内样本结束生成的情况，当有样本结束生成时，动态地读取下一个 batch 的数据插入到上一个 batch 的空位中继续生成，从而实现生成过程中的并发度提升，实现更大的并发和吞吐。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b3/b3ca08c413c3035e1feeb6743c280eeb.png\" /></p><p></p><p>以上介绍了生成式大模型的常用推理时延、吞吐优化方法，下表是对各优化方法的优化目标和使用场景的总结。</p><p><img src=\"https://static001.geekbang.org/infoq/f6/f61978785e7f3fe55dd7a8f1ed9e3f5b.png\" /></p><p></p><h1>3. 多模态大模型推理高性能优化</h1><p></p><p>多模态大模型当前的热度也很高，目前在探索的方向也有很多，本文以文生图扩散模型 Stable Diffusion 为例介绍推理优化方法，由于 Stable Diffusion 推理中主要耗时 UNet 网络也是由 Attention 模块组成，因此可以复用大语言模型的优化方法。</p><p><img src=\"https://static001.geekbang.org/infoq/e2/e207b1ea3128b21ccaa4e2cae2229120.png\" /></p><p>飞桨通过集成 Flash Attention，支持4中 Norm 结构共 90 多处融合、端到端统一计算 Layout 和 Scheduler 优化等多种方式，将 Stable Diffusion 的推理速度和显存占用均优化到了业界最优，优化方法细节可以阅读飞桨之前发布的文章：《<a href=\"http://mp.weixin.qq.com/s?__biz=Mzg2OTEzODA5MA==&amp;mid=2247602467&amp;idx=1&amp;sn=1f05e54f62a961beba53d77141434829&amp;chksm=cea2bae6f9d533f07797f2301907ea5c1785225c37adfa2a2b40ccc52975c0dd51677b01c5b9&amp;scene=21#wechat_redirect\">又一个开源第一！飞桨联合百舸，Stable Diffusion 推理速度遥遥领先</a>\"》</p><p><img src=\"https://static001.geekbang.org/infoq/dc/dc95415722eb52ef0d00abc4a76534f2.png\" /></p><p>以上是我今天分享的全部内容。</p><p></p><p>- - - - - - - - - - END - - - - - - - - - -</p><p>请关注微信公众号“百度智能云技术站”</p><p>以免错过后续精彩内容</p>",
    "publish_time": "2023-07-31 16:36:45",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "零代码的可能性",
    "url": "https://www.infoq.cn/article/HsF1XyBKOGObZR5hTR7t",
    "summary": "<pre><code>  明道云北京团队经理薛晨以《零代码的可能性》为题做开场演讲。无论是给一对新人打造一套婚礼筹备的应用，还是给一家平平无奇的粮油小店做一个掌上ERP，亦或是为中年朋友提供一个创业圆梦的最佳机会，给企业IT赋予新的角色和使命，零代码都有可能且有能力做到。\n 明道云在服务艾默生电气、沃尔玛、新余市地方政府、广汽本田等大型企业的过程中，逐步验证出全民开发的可能性；在“企业级零代码黑客马拉松大赛”里，找到零代码能为普罗大众带来的一点改变；在一位位优秀的合作伙伴身上，看到零代码与各行业know-how深度融合的价值。</code></pre>",
    "publish_time": "2023-07-31 16:44:41",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "敏态开发在大兴机场提质增效、数字化转型中的实践",
    "url": "https://www.infoq.cn/article/I8P6vPViz7E9N4u7APfo",
    "summary": "<pre><code> 北京大兴国际机场信息管理部副总经理万兆丰分享了公司构筑敏态开发平台的全过程和阶段性成果。从2021年10月开始，大兴机场就捕捉到零代码、低代码开发工具对优化机场运营效益的机会。经历10个月的内部试点、平台选型、规划制度、采购软件，明道云在2022年7月正式面向大兴机场内部推广使用。\n 大半年来，机场坚持赋能为纲，组织4期培训活动，累计培养125名业务技术专家。这批人才在部门里充分结合业务理解和应用搭建技能，开发49个应用，覆盖安全、服务、运行、经营、办公等领域，累计节省IT成本超过500万元。展望未来，大兴机场将继续推广敏态应用开发工具，由易入难，业技融合，使能为纲，行稳致远。</code></pre>",
    "publish_time": "2023-07-31 16:44:45",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "基于 Tapdata LDP 为 AI 模型训练提供企业级的数据集",
    "url": "https://www.infoq.cn/article/jxCh63fs8YSxY99FtEMF",
    "summary": "<p>如何将企业大量独特内容提供给AI进行训练，并开发企业数据价值？</p>",
    "publish_time": "2023-07-31 16:45:08",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从 ClickHouse 到 ByteHouse",
    "url": "https://www.infoq.cn/article/2Z73GWtbYEGjiKuxDTmD",
    "summary": "<p>ClickHouse 是非常优秀的开源 OLAP 数据库，但要将 ClickHouse 引入生产环境，仍需解决计算、存储资源的紧密耦合可能带来资源浪费，不同服务器之间的数据无法共享，深度使用过程集群稳定性、应用场景使用限制等问题。</p><p></p><p>字节跳动作为国内使用规模最大的 ClickHouse 用户，其广泛的业务增长分析工作大多建立在以 ClickHouse 为基础的强劲数据查询能力之上。字节跳动将经过五年定制化改造的 ClickHouse，沉淀为 ByteHouse，正式对外提供服务。</p><p></p><p>本书重点还原字节跳动在大规模引入 ClickHouse 于业务实际生产环境所遇到的问题，同时深度介绍了 ByteHouse 在优化与升级 ClickHouse 上所做的三个重要方向，并通过典型的三个行业案例进一步分析当下 OLAP 数据引擎选型所关注的核心要点。</p><p><img src=\"https://static001.geekbang.org/infoq/da/da67a7366f7748f0757a478713443682.png\" /></p><p>扫/码/下/载</p><p></p>",
    "publish_time": "2023-07-31 17:43:31",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]