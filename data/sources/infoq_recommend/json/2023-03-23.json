[
  {
    "title": "如何最大限度地利用GitHub Actions自动化软件开发过程",
    "url": "https://www.infoq.cn/article/8q3rjE8YRu11TaCS2bhl",
    "summary": "<p></p><h2>Actions发展简介</h2><p></p><p></p><p>当GitHub Actions在2019年秋天发布时，立即就引起了人们的关注，因为它引领了“<a href=\"https://blog.codecentric.de/github-actions-nextgen-cicd\">CI/CD平台的第三次风潮</a>\"”。从可重用的开源构建块构建可组合管道，在改善CI/CD管道操作的效率和维护方面，这个独特的方法明显有很大的潜力。然而，尽管Actions平台的设计具有内在的吸引力，但许多组织，特别是已经构建了CI/CD系统的大型企业，对采取行动犹豫不决，这是可以理解的。在一定程度上，这是由于婴儿期的平台存在诸多限制，比如在企业内部执行和共享Actions的限制。</p><p>&nbsp;</p><p>幸运的是，自最初发布之后，Actions已经采取了一些步骤来消除障碍，实现企业使用的可维护性。此后不久，<a href=\"https://github.blog/2019-11-05-self-hosted-runners-for-github-actions-is-now-in-beta/\">自托管runner</a>\"推出，这是在现有企业内部网络中执行作业的一项基础能力。然后，2021年11月，<a href=\"https://github.blog/2021-11-29-github-actions-reusable-workflows-is-generally-available/\">可重用工作流</a>\"发布，极大地扩展了提供可重用管道的能力，减少了重复步骤和样板代码的数量，缩小了与许多更成熟的CI/CD产品的差距。真正让这一功能做好企业采用准备的是在2022年1月宣布的<a href=\"https://github.blog/changelog/2022-01-21-share-github-actions-within-your-enterprise/\">内部共享操作</a>\"的能力，这种能力使平台工程团队能够打包发布常见的可重用步骤，而又不会暴露给外界。最终，我们感觉Actions有能力作为企业CI/CD生态系统的基础了。</p><p>&nbsp;</p><p></p><h2>我们为什么转到Actions</h2><p></p><p></p><p>在Thrivent，我们最近几年投入了大量的精力来改善CI/CD工具的开发体验，包括实现自动化，按照公认的黄金路径快速从模板生成应用程序管道。尽管如此，我们在提供一个一致性和灵活性均衡的平台方面遇到了限制。</p><p>&nbsp;</p><p>就我们当前的系统而言，其中一个不足体现在在CI/CD管道中共享公共任务。我们的共享脚本存储库提供的封装有限，并且会弄乱应用程序的构建历史，将实际应用程序存储库的提交和共享任务存储库的提交混在一起。</p><p>&nbsp;</p><p>在对管道模板升级时，我们保留用户自定义设置的能力也很有限。如果我们在模板中引入了一个新的步骤或修复了一个Bug，那么开发人员将不得不重新生成整个管道来获取更改，这会删除他们所做的所有定制。</p><p>&nbsp;</p><p>最后，还有一个不太明显的因素是，最大限度地减少开发人员使用CI/CD系统的障碍。当我们的技术组织进入增长期，有大量新的开发人员涌入，提供一个能够让这些开发人员快速上手并满足他们期望的平台成了当务之急。在最近<a href=\"https://survey.stackoverflow.co/2022/#section-version-control-version-control-platforms\">Stack Overflow</a>\"和<a href=\"https://tsh.io/state-of-frontend/#whats-your-favorite-version-control-provider\">State of Frontend</a>\"的调查中，大多数开发人员都回复说使用了GitHub。鉴于它在开源社区中的地位，这不足为奇。通过将使用范围扩大到平台原生的CI/CD功能，我们看到了以下机会：</p><p>将工具整合到单个系统中，充分利用开发人员现有的熟悉度，从而减少无关的认知负荷；使用存储库事件最大限度地减少上下文切换，使编码生命周期内的工作更紧凑；提供我们一直在寻找的原生模块化管道架构。</p><p>&nbsp;</p><p>总的来说，GitHub Actions平台的设计借鉴了现代开发方法。开发人员可以利用可重用组件灵活地构建管道，将团队在开发活动中使用的开源思想转移到CI/CD管道中。然而，随着我们对Actions生态系统的深入研究，Actions在CI/CD处理方面存在着一些显著的差异，这促使我们重新思考了之前所做的一些假设，并开发了一种新的策略，将平台的限制变成一种优势。</p><p>&nbsp;</p><p></p><h3>术语速览</h3><p></p><p></p><p>在GitHub Actions系统中，有几个术语由于在CI/CD生态系统中使用广泛，可能具有各种含义，但在Actions框架中，它们指的是特定的资源（即“工作流”、“作业”、“操作”、“事件”和“runner”）。如果你不熟悉GitHub Actions的定义，那么建议你快速浏览一下<a href=\"https://docs.github.com/en/enterprise-cloud@latest/actions/learn-github-actions/understanding-github-actions\">GitHub的文档</a>\"。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9f/9f0e5708fe3382ab8c3c131e97e5e3b0.jpeg\" /></p><p></p><p>GitHub Actions工作流可视化（来源：<a href=\"https://docs.github.com/en/actions/learn-github-actions/understanding-github-actions\">GitHub</a>\"）</p><p>&nbsp;</p><p></p><h2>思想转变</h2><p></p><p></p><p>在转换到Actions时，其中一个需要首先理解的区别是存储库和管道工具之间的关系。我们一直在使用的CI/CD产品是与应用程序的存储库集成在一起的，虽然本质上是分开的。即使是CI/CD领域中的其他工具，它们可能为应用程序的整个生命周期提供了更全面的解决方案（通常将存储库、管道和其他交付工具捆绑到单个产品中），也倾向于提供更高级的结构，如“项目”或“应用程序”，明确区分存储库和管道，使它们的地位相对平等。当CI/CD过程开始时，所有的注意力都转到了管道工具视图上。</p><p>&nbsp;</p><p>相比之下，使用GitHub Actions，存储库仍然是宇宙的中心。Actions平台中触发的工作流主要存在于存储库的上下文中。这种方法有利也有弊。</p><p>&nbsp;</p><p></p><h3>优点</h3><p></p><p></p><p>存储库现在提供了应用程序状态的单一落点，将应用程序运行状况和部署信息与代码本身紧密地结合在一起。在传统的提交/推送触发器之外，它还提供了在各种存储库事件（例如，加标签、pull请求）上启动工作流的能力，方便我们将CI/CD更紧密地集成到开发流程中去。对于共享操作和工作流的系统，它提供的能力让我们可以独立于应用程序存储库的变更，轻松地管理共享管道组件的生命周期。</p><p>&nbsp;</p><p></p><h3>缺点</h3><p></p><p></p><p>因为所有事情都是基于存储库中发生的事件进行编排的，所以很难从其他（外部）事件源启动工作流。通过工作流生成的工件在存储库中的可见度与代码的可见度不一样。这意味着分享和推广结果工件的能力是有限的，因为该信息没有持久化到存储库中，也没有在工作流执行之间共享。不同的存储库组织方法可能会为流程带来额外的复杂性，例如，<a href=\"https://en.wikipedia.org/wiki/Monorepo\">单存储库</a>\"可能在同一个存储库中包含多个不同的项目。这些相互独立的应用程序在构建和部署的方式上也可能存在差异。因此，需要格外小心，并可能需要借助额外的工具来有效地管理触发事件，以避免构建未经修改的应用程序，以及正确地打包和部署下游工件。</p><p>&nbsp;</p><p></p><h2>制定Actions使用策略</h2><p></p><p></p><p>现在，在了解了GitHub Actions的视角及其优缺点后，我们可以开始制定有效使用Actions平台作为CI/CD解决方案的策略。以下是指导我们作出决策的一些主要原则。</p><p>&nbsp;</p><p></p><h3>优选Pull请求审批而非工作流审批</h3><p></p><p></p><p>CI/CD平台的主要关注点之一是有效地收集和显示输出，并对这些结果强制执行质量门检验。以前，我们一直在使用一个许多组织都很熟悉的流程：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/83/83aef4a68f067cff340dec6d7c9c8ef5.jpeg\" /></p><p></p><p>以前的方法：存储库和管道检查是分开的</p><p>&nbsp;</p><p>在这种方法中，对目标分支的推送会触发管道。管道会分成一系列的阶段执行，每个阶段都会输出一些结果，并且通常会根据这些结果评估工件的生产就绪情况。</p><p>&nbsp;</p><p>我们的新目标是使这些信息更趋近于自然的开发活动，同时又要注意Actions结果和工件显示方式的一些固有限制，因此，我们希望有一种更好的方式来提供这些控制，而pull请求特性是合乎逻辑的选择。Pull请求维护的审计历史更久（与工作流执行的<a href=\"https://docs.github.com/en/enterprise-cloud@latest/organizations/managing-organization-settings/configuring-the-retention-period-for-github-actions-artifacts-and-logs-in-your-organization\">保留时间限制</a>\"相比），并且讨论聚焦于变更本身，代码可供随时参考。将pull请求作为主要的审批仪表板需要转换模式，pull请求收集相同的结果并执行同样的质量检查，但不需要额外导航回存储库查看相关的更改。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/77/777178afcd7d9106f2cb6f66d37c1d50.jpeg\" /></p><p></p><p>新策略：依据pull请求收集必要的信息</p><p>&nbsp;</p><p></p><h3>制定可重用组件指南</h3><p></p><p></p><p>构建可重用管道片段的自助库也带来了许多问题。我们要如何处理共享工作流和操作的更新？当多个团队对看似相同的任务在处理方式上略有差异时，如果我们想要平衡这些团队，什么样的抽象级别才合适？</p><p>&nbsp;</p><p>面对这些挑战，我们的目标是实现一系列“铺好的路（paved roads）”，每个新的存储库都应该能够使用我们团队支持的模板、操作和可重用工作流进行部署，但又有按需定制的灵活性。这为保持存储库始终处于可部署状态的持续交付指令奠定了基础。为了实现这一目标，我们制定了一些指导方针。</p><p>&nbsp;</p><p></p><h3>推送所有版本的语义版本标签</h3><p></p><p></p><p>维护精确的版本让用户有能力根据他们所能接受的风险级别保持更新。在我们之前的CI/CD工具中，共享任务是从存储库的主分支上拉取的，这意味着我们需要非常小心，以免引入意外的更改。虽然Actions支持这种用法，但最好使用语义版本范围在保持最新和避免破坏性更改之间实现一个平衡。在这里，我们学到的一个关键知识是，确保为每个版本推送/更新多个标签（主标签、次标签和补丁标签），确保跟踪主标签（如“@v2”）的用户也可以获得新的补丁版本。</p><p>&nbsp;</p><p></p><h3>像管理任何其他API一样管理你的接口</h3><p></p><p></p><p>当向内部团队提供资源时，很容易陷入这样的陷阱，即假设他们对内部工作方式的理解比对开源项目或外部供应商的理解更深入。这可能会迅速导致抽象泄漏，降低所提供的共享组件的价值，因为用户必须承担额外的认知负荷，而不仅仅是理解如何与它的API交互。</p><p>&nbsp;</p><p>为了保持更加一致的封装级别，我们的目标是明确我们的<a href=\"https://docs.github.com/en/enterprise-cloud@latest/actions/creating-actions/metadata-syntax-for-github-actions#inputs\">输入</a>\"和<a href=\"https://docs.github.com/en/enterprise-cloud@latest/actions/using-jobs/defining-outputs-for-jobs\">输出</a>\"，尽量减少假设和对环境副作用的依赖。在此基础上，我们一直在尝试提供一个合理的默认值，这样用户就可以专注于提供大多数用例都需要的值。最后，如果使用环境变量，我们建议将它们的范围限制得越窄越好。</p><p>&nbsp;</p><p>例如，如果一个环境变量只在一个步骤中使用，就在这个步骤中声明它，如果在多个步骤中使用，就在作业中声明它，最后，如果在多个作业中使用，就在工作流中声明它。这是一个<a href=\"https://refactoring.com/catalog/reduceScopeOfVariable.html\">通用的建议</a>\"，与平台无关，其目的是降低变量意外修改或命名冲突的风险，并通过将信息保存在使用位置附近来提高可读性。</p><p>&nbsp;</p><p></p><h3>聚焦工作流</h3><p></p><p></p><p>在GitHub Actions生态系统中，人们关注最多的是Actions；毕竟，产品就是以Actions命名的。然而，在铺好的路上，操作不过是砖。它们非常有助于将流程分解为功能步骤，但是，为了向内部交付团队提供最大价值，平台工程师应该投入同样多的时间来开发将这些步骤联系在一起的可重用工作流目录。可重用工作流可以确保不同的步骤按所需的顺序执行，并可以简化设置和拆卸活动。</p><p>&nbsp;</p><p>例如，我们的团队创建了一个将容器部署到Kubernetes环境的操作。为此，需要将环境元数据作为输入的一部分提供。为了更好地管理调用此操作的活动，我们使用工作流来执行一些额外的步骤，收集所需元数据、执行部署，然后将结果添加到输出。但是我们发现，在许多不同的情况下，这个工作流的代码都会重复——针对不同的触发事件，以及不同的部署环境（开发、过渡、生产等）。为了进一步最大化重用，我们将这些工作流重构为单个可重用的工作流，它会根据触发事件确定正确的目的地和镜像上下文。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/10/106ffb6e7655c2a4ef0bf86aa6c68678.jpeg\" /></p><p></p><p>进一步重用：合并3个几乎相同的作业……</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/32/32d58e911cdf0194ff3cae48b22c4137.jpeg\" /></p><p>进入一个可重用工作流</p><p>&nbsp;</p><p></p><h3>降低使用第三方Actions的风险</h3><p></p><p></p><p><a href=\"https://docs.github.com/en/enterprise-cloud@latest/actions/security-guides/security-hardening-for-github-actions\">GitHub的文档</a>\"提供了一些很好的GitHub Actions安全加固通用指南。其中有这样一条警告，“从GitHub上的第三方存储库获取操作存在重大风险”。为此，他们提供了一些指导，即将第三方操作的版本锚定到一个提交SHA，审计操作的源代码，并且只使用你信任的创建者提供的操作。</p><p>&nbsp;</p><p>这给我们造成了一些困难，因为我们已经习惯了由软件组合分析（SCA）工具自动提供适当的外部组件的风险（漏洞/许可）信息，这使得我们在应用程序开发活动中能够更广泛地应用开源组件。</p><p>&nbsp;</p><p>回归手动检查所有外部操作的做法，可能会严重限制开源Actions市场的效用，而这个市场在我们的旅程之初就有这样的承诺。随着供应链攻击的增加，保证管道安全变的至关重要，但手动检查操作源代码和创建者的方法无法扩展，因为我们团队可能对给定操作使用的语言没有深入的了解，而且，当它来自单个用户的贡献时，创建者的可信度就很难评估。</p><p>&nbsp;</p><p>最近，GitHub宣布支持<a href=\"https://github.blog/2022-08-09-dependabot-now-alerts-for-vulnerable-github-actions/\">Actions Dependabot告警</a>\"，这是朝着正确的方向迈出了良好的第一步。然而，这仍然没有达到我们所希望的安全等级，原因如下：</p><p>Dependabot生成的告警很大程度上依赖于创建者自己报告的漏洞。在个人提供的小操作中，尚不清楚他们可能提供何种程度的报告。仍然没有对风险进行基线评估——当用户正在浏览Actions市场时，并没有现成的数据让用户可以了解操作中现有的漏洞或创建者的漏洞管理流程。还有一种风险是，有人故意将恶意代码嵌入到操作中（如果他们是原始作者，则可以在创建操作时嵌入恶意代码，或者通过供应链攻击更隐蔽地嵌入恶意代码)，这种方法无法捕获这类恶意代码。最后，目前许多公司在依赖关系管理方面的最佳实践是内部托管一个存储库，并代理到其他主要的公共存储库（NPM、Maven Central、PyPI等）。对于公司产品使用的依赖项，会有一个内部缓存，为的是可以在<a href=\"https://www.theregister.com/2016/03/23/npm_left_pad_chaos/\">依赖源无法访问</a>\"时帮助确保业务连续性。现在，操作具备了同等的重要性，因为它们对工作管道至关重要，任何中断都可能给开发人员带来大量的时间损失。</p><p>&nbsp;</p><p>为了解决上述限制，我们使用现有的工具开发了一种方法，并结合GitHub设置中的控制项，设法在风险和开发速度之间达到一个平衡。首先，我们允许任何内部编写的操作和任何GitHub编写的操作。下一个通用控制是允许一个经过验证的创建者列表，并允许来自已与我们建立信任关系的组织的所有操作。最后，对于个别来自较小的、未经验证的第三方操作，我们有一个允许列表。</p><p>&nbsp;</p><p>为了加快这些操作的审批过程，我们利用现有的SCA、SAST和容器安全扫描工具来扫描这些操作的存储库和/或容器镜像，将任何潜在的漏洞都暴露出来。</p><p>&nbsp;</p><p>在某些情况下，我们使用的最后一种技术是将操作存储库的副本派生或导入到企业自己的存储库中。这提供了三个保证：</p><p>如果需要，总是有可用的代码；可以修改代码，以便更好地匹配我们自己的用例；可以确保任何更改版本引用的尝试（如更改标签）都不会影响我们。</p><p>&nbsp;</p><p>当然，还需要不断的努力，将源存储库中任何有用的更改或修复都合并到我们自己的版本中，因此，在使用这种方法时应该做好权衡。</p><p>&nbsp;</p><p>GitHub在<a href=\"https://github.com/github/roadmap/issues/592\">他们的路线图</a>\"中也有继续提高操作安全性的计划。显然，这是一个不断发展的领域，我们希望平台和解决方案生态系统的进步可以减少我们对自主开发评估流程的依赖。</p><p>&nbsp;</p><p></p><h3>扩大基础设施实践，紧跟需求步伐</h3><p></p><p></p><p>随着Actions平台应用范围的扩大，提高性能和可靠性成了人们关注的焦点。我们依据运营使用的关键经验扩展了我们的战略。</p><p>&nbsp;</p><p>利用自托管Runner增强弹性</p><p>像许多企业一样，为了满足需求，并帮助管理成本，我们大量使用了自托管runner，使作业可以与我们内部网络上的资源进行通信，从而可以更好地管理runner镜像的工具和设置。</p><p>&nbsp;</p><p>尽管依赖于自托管runner，但我们希望与使用GitHub托管的runner的体验保持一致，即在作业开始时runner已经准备就绪（最小化作业等待runner可用的排队时间），并且将这些runner视为一次性使用的临时实例，最大限度地减少前一次执行留下的更改影响下一作业幂等性的机会。</p><p>&nbsp;</p><p>为次，我们维护了一个一次性runner的暖池——当新作业启动并获取runner时，我们使用一个WebHook来启动下一个runner。这样一来，这个池子就总是能够处理当前的工作量。另外，在每个工作日开始时，我们还使用默认分配的runner来预先填充runner池（然后在晚上关闭它），并随着使用量的增加扩大这个池子。</p><p>&nbsp;</p><p>使用缓存缩短构建时间</p><p>如上所述，我们的runner是一次性的，我们为每个作业提供的运行环境都是干净的。虽然这在构建一致性和隔离方面带来了明显的好处，但那也意味着生成的任何文件后续作业都无法使用，除非它们直接使用像<a href=\"https://docs.github.com/en/enterprise-cloud@latest/actions/using-workflows/storing-workflow-data-as-artifacts\">Artifacts</a>\"这样的特性共享。在这里，我们要克服的主要挑战之一便是花费大量的时间重新生成现有的资源。</p><p>&nbsp;</p><p>幸运的是，在需要共享大量极少变化的数据（如应用程序依赖关系）时，GitHub提供了几种缓存功能。我们需要设法解决的三种最常见的情况是共享应用程序工件、容器镜像和操作镜像。</p><p>&nbsp;</p><p>第一种情况涉及到作业之间使用的应用程序工件和依赖关系。在这种情况下，我们使用<a href=\"https://github.com/actions/cache\">GitHub缓存操作</a>\"迅速提高了工作流的性能。</p><p>&nbsp;</p><p>容器镜像，包括常用的基础镜像层，是第二种最常见的情况。为了缓解经常重新拉取常用镜像的问题，我们研究了<a href=\"https://github.com/docker/build-push-action#inputs\">Docker buildx操作</a>\"支持的<a href=\"https://github.com/moby/buildkit#export-cache\">不同缓存选项</a>\"。我们在大多数镜像构建任务中都使用了这些选项。在对内联缓存、GHA（GitHub Actions缓存）和注册中心缓存选项进行了不同的度量之后，我们目前使用GitHub容器注册中心（GHCR）托管的注册中心缓存取得了最大的成功。</p><p>&nbsp;</p><p>最后，最棘手的是操作镜像。需要理解的一个重要概念是，每次使用打包为镜像的GitHub操作时，都是使用它们的Dockerfile从头开始构建的（有一个替代方案是使用Docker Hub中的公共镜像，但我们不希望公开发布内部操作，所以这并不可行）。</p><p>&nbsp;</p><p>为了减轻这种痛苦，我们遵循通用镜像最佳实践来尽量缩小镜像。不过，我们也在研究将一些作业抽离出来，不再作为容器化操作执行，而是将相同的逻辑打包为预构建的独立镜像，然后将作业配置为在该镜像中运行。然后，作业将执行一个脚本。该脚本通常用作操作的ENTRYPOINT，其行为与在本地作为操作运行时非常相似。这样做的好处是，我们可以拉取一个镜像，而不是每次重新构建每个层，这使得我们可以在runner启动过程中预先拉取常用的镜像，在工作流开始之前缓存它们。</p><p>&nbsp;</p><p></p><h2>GitOps即将来临</h2><p></p><p></p><p>尽管我们提升了操作组合以及工作流的质量和效率，但我们还面临的主要问题之一是，在应用程序部署和运营阶段保持敏捷性和可见性。我们最初的部署方法是将变量替换为参数化模板，使用我们的自定义操作，最终形成一个完整的Kubernetes清单，应用于我们的环境。</p><p>&nbsp;</p><p>这给我们的团队带来了很大的负担，因为我们需要使用复杂的逻辑来处理各种部署风格、重试和部署失败恢复，以及清理过时部署。由于在部署后，包含所有变量的最终清单没有在任何地方持久化，所以部署问题也变得更加难以排查。这也意味着，回滚或升级工件需要重新调用整个流程。</p><p>&nbsp;</p><p>为应对这些挑战，我们再次开始研究如何重塑部署策略，以发挥GitHub CI/CD平台的优势。在重申上述部分经验教训的基础上，我们认识到，我们需要的解决方案应该：</p><p>聚焦于存储库；通过pull请求控制变更；尽量减少自定义部署逻辑。</p><p>&nbsp;</p><p>到此为止，熟悉<a href=\"https://opengitops.dev/\">GitOps</a>\"理念的读者可能开始明白我们的思路了。在GitOps提倡的部署策略中，运行时状态在Git存储库中声明，并由环境中运行的代理自动拉取和协调。</p><p>&nbsp;</p><p>转向GitOps部署模型需要采用新的技术和行为模式，但这使得我们可以利用经开源社区专家优化的部署和协调逻辑，并维护一个清晰、持久、有版本控制的环境变更历史，有一个清晰的路径（拉请求）可以轻松地更改版本，并在需要时保留审批记录。这一切都是基于开发人员现有的熟悉度，也正是这种熟悉度把我们吸引到了GitHub。</p><p>&nbsp;</p><p>我们正处于这一转变的早期阶段，但很高兴我们采取了下一步措施，为我们的客户提供了更好、更可靠的价值交付方式。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/enterprise-github-actions/\">https://www.infoq.com/articles/enterprise-github-actions/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/TTDS1pC6Cz6MRqJTpMir\">为什么说可观察性是解锁&nbsp;GitOps&nbsp;的关键</a>\"</p><p><a href=\"https://www.infoq.cn/article/E2Nk6iYClH4RL8aNCRDB\">GitOps&nbsp;是皇帝的新衣吗？</a>\"</p><p><a href=\"https://www.infoq.cn/article/UMsJHeW2ZWEcF6uUMstQ\">最全的&nbsp;GitOps&nbsp;工具选型，30+ 款工具随你挑</a>\"</p><p></p>",
    "publish_time": "2023-03-23 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Java JVM 可观测的原理解释和落地方案对比",
    "url": "https://www.infoq.cn/article/3iwV28HezCgCyPdFMWSd",
    "summary": "<p></p><h2>如何监控 JVM</h2><p></p><p></p><p>云原生时代，我们使用 Prometheus 来作为可观测平台的指标监控的核心组件。监控一个云原生的 Java 应用，一般会分成 3 个步骤：</p><p></p><p>配置 Java 应用，暴露 JVM 指标信息通过 Prometheus 采集并存储指标数据通过 Grafana 的 Dashboard 展示采集到的指标</p><p></p><p>借力社区生态，我们有越来越丰富的方式来暴露 JVM 核心指标，文本将介绍 JVM 监控的基本原理，并重点介绍常见的 3 种暴露 JVM 指标的方案，可以根据读者的使用场景来选择。</p><p></p><p></p><h2>采集原理</h2><p></p><p></p><p>Java Management Extensions（JMX）技术是 Java SE 平台的标准功能，提供了一种简单的、标准的监控和管理资源的方式，对于如何定义一个资源给出了明确的结构和设计模式，主要用于监控和管理 Java 应用程序运行状态、设备和资源信息、Java 虚拟机运行情况等信息。并且如下图所示，有关应用程序性能和资源使用情况的详细信息可以从 JMX 指标中导出。如果有任何问题，我们可以借助收集的指标进行诊断，并对系统进行微调以获得最佳性能。JMX 是可以动态的，所以也可以在资源创建、安装、实现时进行动态监控和管理，JDK 自带的 jconsole 就是使用 JMX 技术实现的监控工具。图片: </p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a2/a21d967f0b6210b412675b2a82902a5d.png\" /></p><p></p><p>使用 JMX 技术时，通过定义一个被称为 MBean 或 MXBean 的 Java 对象来表示要管理指定的资源，然后可以把资源信息注册到 MBean Server 对外提供服务。MBean Server 充当了对外提供服务和对内管理 MBean 资源的代理功能，如此优雅的设计让 MBean 资源管理和 MBean Server 代理完全独立开，使之可以自由的控制 MBean 资源信息。</p><p></p><p>JMX 不仅仅用于本地管理，JMX Remote API 为 JMX 添加了远程功能，使之可以通过网络远程监视和管理应用程序。得益于相对独立的架构设计，使 JMX 可以平滑的集成到各种监控系统之中。并具有包括遵守 Java 规范、通用的管理方式、开箱即用的监控功能、架构设计优秀、监测 JVM 状态能力、管理解决方案集成的能力等优点。</p><p></p><p>JMX 技术架构主要有资源管理（MBean/MXBean）模块，资源代理模块（MBean Server），远程管理模块（Remote API）组成 ，下面的图片来自维基百科，很好的展示了三个模块之间的关系。图片: </p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f9/f9e211a9aeb92e0251b093c2365b4e97.png\" /></p><p></p><p>资源管理在架构中标识为资源探测层（Probe Level），在 JMX 中， 使用 MBean 或 MXBean 来表示一个资源（下面简称 MBean），访问和管理资源也都是通过 MBean。</p><p></p><p>JMX 已经对 JVM 进行了多维度资源检测，所以可以轻松启动 JMX 代理来访问内置的 JVM 资源检测，从而通过 JMX 技术远程监控和管理 JVM。JMX 内置了常用的 JVM 资源监测类，包括但不限于：类加载、垃圾收集、日志系统、内存池、内存、内存系统、操作系统、运行时系统和线程系统。</p><p></p><p>以下代码演示了如何使用原生 JMX 接口获取 JVM 指标：</p><p><code lang=\"text\">package org.example.jmx;\n\nimport java.lang.management.CompilationMXBean;\nimport java.lang.management.GarbageCollectorMXBean;\nimport java.lang.management.ManagementFactory;\nimport java.lang.management.MemoryMXBean;\nimport java.lang.management.MemoryManagerMXBean;\nimport java.lang.management.MemoryUsage;\nimport java.lang.management.OperatingSystemMXBean;\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.stream.Collectors;\n\npublic class Main {\n\n    public static void main(String[] args) {\n        printOSInfo();\n        System.out.println(\"================\");\n        printMemoryManagerInfo();\n        System.out.println(\"================\");\n        printGCInfo();\n    }\n\n    //通过 OperatingSystemMXBean 获取 OS 信息\n    public static void printOSInfo() {\n        OperatingSystemMXBean operatingSystemMXBean = ManagementFactory.getOperatingSystemMXBean();\n        String osName = operatingSystemMXBean.getName();\n        String osVersion = operatingSystemMXBean.getVersion();\n        int processors = operatingSystemMXBean.getAvailableProcessors();\n        System.out.println(String.format(\"OS：%s，Version：%s，CPU：%d 个\", osName, osVersion, processors));\n\n        CompilationMXBean compilationMXBean = ManagementFactory.getCompilationMXBean();\n        String compilationMXBeanName = compilationMXBean.getName();\n        System.out.println(\"编译系统：\" + compilationMXBeanName);\n\n        MemoryMXBean memoryMXBean = ManagementFactory.getMemoryMXBean();\n        MemoryUsage heapMemoryUsage = memoryMXBean.getHeapMemoryUsage();\n        long max = heapMemoryUsage.getMax();\n        long used = heapMemoryUsage.getUsed();\n        System.out.println(String.format(\"使用内存：%dMB/%dMB\", used / 1024 / 1024, max / 1024 / 1024));\n\n        List gcMXBeans = ManagementFactory.getGarbageCollectorMXBeans();\n        String gcNames = gcMXBeans.stream()\n                                  .map(MemoryManagerMXBean::getName)\n                                  .collect(Collectors.joining(\",\"));\n        System.out.println(\"垃圾收集器：\" + gcNames);\n    }\n\n    // 通过 MemoryManagerMXBean 获取 JVM 内存管理器信息\n    public static void printMemoryManagerInfo() {\n        List managers = ManagementFactory.getMemoryManagerMXBeans();\n        if (managers != null &amp;&amp; !managers.isEmpty()) {\n            for (MemoryManagerMXBean manager : managers) {\n                System.out.println(\"vm内存管理器：名称=\" + manager.getName() + \",管理的内存区=\"\n                                       + Arrays.deepToString(\n                    manager.getMemoryPoolNames()) + \",ObjectName=\" + manager.getObjectName());\n            }\n        }\n    }\n\n    //通过 GarbageCollectorMXBean 获取 JVM GC 信息\n    public static void printGCInfo() {\n        try {\n            List gcMxBeans = ManagementFactory.getGarbageCollectorMXBeans();\n\n            for (GarbageCollectorMXBean gcMxBean : gcMxBeans) {\n                System.out.println(gcMxBean.getName());\n                System.out.println(gcMxBean.getObjectName());\n            }\n\n        } catch (RuntimeException re) {\n            throw re;\n        } catch (Exception exp) {\n            throw new RuntimeException(exp);\n        }\n    }\n}</code></p><p></p><p>以上代码运行结果如下：</p><p></p><p><code lang=\"text\">OS：Mac OS X，Version：10.16，CPU：8 个\n编译系统：HotSpot 64-Bit Tiered Compilers\n使用内存：4MB/4096MB\n垃圾收集器：G1 Young Generation,G1 Old Generation\n================\nvm内存管理器：名称=CodeCacheManager,管理的内存区=[CodeHeap 'non-nmethods', CodeHeap 'profiled nmethods', CodeHeap 'non-profiled nmethods'],ObjectName=java.lang:type=MemoryManager,name=CodeCacheManager\nvm内存管理器：名称=Metaspace Manager,管理的内存区=[Metaspace, Compressed Class Space],ObjectName=java.lang:type=MemoryManager,name=Metaspace Manager\nvm内存管理器：名称=G1 Young Generation,管理的内存区=[G1 Eden Space, G1 Survivor Space, G1 Old Gen],ObjectName=java.lang:type=GarbageCollector,name=G1 Young Generation\nvm内存管理器：名称=G1 Old Generation,管理的内存区=[G1 Eden Space, G1 Survivor Space, G1 Old Gen],ObjectName=java.lang:type=GarbageCollector,name=G1 Old Generation\n================\nG1 Young Generation\njava.lang:type=GarbageCollector,name=G1 Young Generation\nG1 Old Generation\njava.lang:type=GarbageCollector,name=G1 Old Generation</code></p><p></p><p></p><h3>常见开源暴露 JVM 指标工具</h3><p></p><p></p><p>通过原生 JMX 获取 JVM 指标，并能够被我们的可观测性系统采集到工作量还是很大。以下，列举了常见的几款开箱即用的工具：</p><p></p><p></p><h4>Micrometer/Spring Boot Actuator</h4><p></p><p></p><p>Spring Boot Actuator 模块提供了生产级别的功能，比如健康检查，审计，指标收集，HTTP 跟踪等，帮助我们监控和管理Spring Boot 应用。这个模块是一个采集应用内部信息暴露给外部的模块，上述的功能都可以通过HTTP 和 JMX 访问。Spring Boot Actuator 使用 Micrometer 与这些外部应用程序监视系统集成，Spring Boot 应用只需很少的配置即可轻松集成外部的监控系统。</p><p></p><p>以下是 Micrometer 官方介绍：</p><p></p><p>Micrometer provides a simple facade over the instrumentation clients for the most popular observability systems, allowing you to instrument your JVM-based application code without vendor lock-in. Think SLF4J, but for application observability! Data recorded by Micrometer are intended to be used to observe, alert, and react to the current/recent operational state of your environment.</p><p></p><p>在 pom.xml 中添加如下依赖：</p><p><code lang=\"text\">\n   org.springframework.boot\n   spring-boot-starter-actuator\n \n \n   io.micrometer\n   micrometer-registry-prometheus\n   runtime\n </code></p><p></p><p>在 src/main/resources/application.properties 中添加相关配置</p><p></p><p><code lang=\"text\">management.endpoints.web.exposure.include=*\nmanagement.endpoints.web.exposure.include=prometheus,health,info,metric\nmanagement.endpoints.web.base-path=/\n\nmanagement.server.port=8999\nmanagement.health.probes.enabled=true\nmanagement.endpoint.health.show-details=always\nmanagement.endpoint.prometheus.enabled=true</code></p><p></p><p>重新构建并运行服务</p><p></p><p>运行服务之后，我们可以通过 http://lcoalhost:8999/prometheus 访问服务暴露出来的 OpenMetrics 格式的指标。同时，该接口也能被 prometheus 抓取并收集指标， prometheus.yaml 配置文件参考如下:</p><p></p><p><code lang=\"text\">prometheus:\n config:\n   scrape_configs:\n     - job_name: \"jvm-metrics\"\n       scrape_interval: 10s\n       metrics_path: \"/prometheus\"\n       static_configs:\n         - targets: [\"\"]</code></p><p></p><h4>Prometheus JMX Exporter</h4><p></p><p></p><p>JMX-Exporter 主要通过连接到 Java 原生指标收集系统 JMX，并将指标转换为 Prometheus 可以理解的格式。JMX-Exporter 提供了两种采集并暴露指标的用法:</p><p></p><p>启动独立进程。JVM 启动时指定参数，暴露 JMX 的 RMI 接口，JMX-Exporter 调用 RMI 获取 JVM 运行时状态数据，转换为 Prometheus metrics 格式，并暴露端口让 Prometheus 采集JVM 进程内启动(in-process)。JVM 启动时指定参数，通过 javaagent 的形式运行 JMX-Exporter 的 jar 包，进程内读取 JVM 运行时状态数据，转换为 Prometheus metrics 格式，并暴露端口让 Prometheus 采集。</p><p></p><p>官方不推荐使用第一种方式，一方面配置复杂，另一方面因为它需要一个单独的进程，而这个进程本身的监控又成了新的问题，所以本文重点围绕第二种用法以及如何在 Kubernetes 环境下使用 JMX Exporter 暴露 JVM 监控指标。</p><p></p><p>由于在应用启动时要通过 javaagent 指定 jmx exporter Jar 包，因此，我们需要考虑启动时如何让 JVM 正确的找到 jmx exporter Jar 包。以下列举了两种方式：</p><p></p><p>在构建应用镜像时将 JAR 文件打进镜像</p><p></p><p>根据 JMX EXporter 官方介绍，需要为其指定配置文件，需要提前创建好 prometheus-jmx-config.yaml , 更多配置项请参考官方文档， 以下内容仅供参考：</p><p></p><p><code lang=\"text\">lowercaseOutputLabelNames: true\nlowercaseOutputName: true\nwhitelistObjectNames: [\"java.lang:type=OperatingSystem\"]\nblacklistObjectNames: []\nrules:\n  - pattern: 'java.lang&lt;&gt;(committed_virtual_memory|free_physical_memory|free_swap_space|total_physical_memory|total_swap_space)_size:'\n    name: os_$1_bytes\n    type: GAUGE\n    attrNameSnakeCase: true\n  - pattern: 'java.lang&lt;&gt;((?!process_cpu_time)\\w+):'\n    name: os_$1\n    type: GAUGE\n    attrNameSnakeCase: true</code></p><p></p><p>通过在应用 Dockerfile 中将 JAR 拷贝进镜像或者在线下载 JAR 文件实现，以下 Dockerfile 仅供参考：</p><p></p><p><code lang=\"text\">FROM openjdk:11.0.15-jre\n\nWORKDIR /app/\n\nCOPY target/my-app.jar ./\n# 将前面创建的 config 文件拷贝至镜像\nCOPY prometheus-jmx-config.yaml ./\n\n# 在线下载 jmx prometheus javaagent jar\nRUN set -ex; \\\n    curl -L -O https://repo1.maven.org/maven2/io/prometheus/jmx/jmx_prometheus_javaagent/0.17.2/jmx_prometheus_javaagent-0.17.2.jar;\n\n# JAVA_TOOL_OPTIONS 会被 JVM 调用\nENV JAVA_TOOL_OPTIONS=-javaagent:/app/jmx_prometheus_javaagent-0.17.2.jar=8088:/app/prometheus-jmx-config.yaml\n\nEXPOSE 8081 8999 8080 8888\n\nENTRYPOINT java $JAVA_OPTS -jar my-app.jar</code></p><p></p><p>b.  通过 Kubernetes Init Container 在应用启动之前将 JAR 文件挂载进容器</p><p></p><p>我们需要先将 JMX exporter  做成 Docker 镜像, 以下 Dockerfile 仅供参考：</p><p></p><p><code lang=\"text\">FROM alpine/curl:3.14\n\nWORKDIR /app/\n# 将前面创建的 config 文件拷贝至镜像\nCOPY prometheus-jmx-config.yaml ./\n\n# 在线下载 jmx prometheus javaagent jar\nRUN set -ex; \\\n    curl -L -O https://repo1.maven.org/maven2/io/prometheus/jmx/jmx_prometheus_javaagent/0.17.2/jmx_prometheus_javaagent-0.17.2.jar;</code></p><p></p><p>根据上面 Dockerfile 构建镜像：docker build -t my-jmx-exporter .</p><p></p><p>在 kubernetes 编排文件中使用该镜像，并将 JAR 通过共享目录挂载进容器：</p><p><code lang=\"text\">apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-demo-app\n  labels:\n    app: my-demo-app\nspec:\n  selector:\n    matchLabels:\n      app: my-demo-app\n  template:\n    metadata:\n      labels:\n        app: my-demo-app\n    spec:\n      imagePullSecrets:\n      - name: registry-pull\n      initContainers:\n      - name: jmx-sidecar\n        image: my-jmx-exporter\n        command: [\"cp\", \"-r\", \"/app/jmx_prometheus_javaagent-0.17.2.jar\", \"/target/jmx_prometheus_javaagent-0.17.2.jar\"]  ➊\n        volumeMounts:\n        - name: sidecar\n          mountPath: /target\n      containers:\n      - image: my-demo-app-image\n        name: my-demo-app\n        resources:\n          requests:\n            memory: \"1000Mi\"\n            cpu: \"500m\"\n          limits:\n            memory: \"1000Mi\"\n            cpu: \"500m\"\n        ports:\n        - containerPort: 18083\n        env:\n        - name: JAVA_TOOL_OPTIONS\n          value: \"-javaagent:/app/jmx_prometheus_javaagent-0.17.2.jar=8088:/app/prometheus-jmx-config.yaml\" ➋\n        volumeMounts:\n        - name: host-time\n          mountPath: /etc/localtime\n          readOnly: true\n        - name: sidecar\n          mountPath: /sidecar\n      volumes:\n      - name: host-time\n        hostPath:\n          path: /etc/localtime\n      - name: sidecar  #共享agent文件夹\n        emptyDir: {}\n      restartPolicy: Always</code></p><p></p><p>经过如上的改造之后， my-demo-app 具备了暴露 JVM 指标的能力，运行服务之后，我们可以通过 http://lcoalhost:8088 访问服务暴露出来的 prometheus 格式的指标。</p><p></p><p>同时，该接口也能被 prometheus 抓取并收集指标， prometheus.yaml 配置文件参考如下:</p><p><code lang=\"text\">prometheus:\n config:\n   scrape_configs:\n     - job_name: \"jvm-metrics\"\n       scrape_interval: 10s\n       metrics_path: \"/\"\n       static_configs:\n         - targets: [\"IP of the demo app:8088&gt;\"]\n</code></p><p></p><p></p><h3>OpenTelemetry Java Agent</h3><p></p><p></p><p>在 Opentelemetry Agent v1.20.0 及以上版本中，Opentelemetry Agent 新增了 JMX Metric Insight 模块，如果你的应用已经集成了 Opentelemetry Agent 去采集应用链路，那么你不再需要另外引入其他 Agent 去为我们的应用暴露 JMX 指标。Opentelemetry Agent 也是通过检测应用程序中本地可用的 MBean 公开的指标，对其进行收集并暴露指标。</p><p></p><p>Opentelemetry Agent 也针对常见的 Java Server 或框架内置了一些监控的样例，请参考 预定义的指标。</p><p></p><p>使用 OpenTelemetry Java Agent 同样需要考虑如何将 JAR 挂载进容器，除了可以参考上面 JMX Exporter 挂载 JAR 文件的方式外，我们还可以借助 Opentelemetry 提供的 Operator 的能力来实现自动为我们的应用开启 JVM 指标暴露：</p><p></p><p>在 Kubernetes 中安装 Opentelemetry Operator</p><p><code lang=\"text\">kubectl apply -f https://github.com/open-telemetry/opentelemetry-operator/releases/latest/download/opentelemetry-operator.yaml</code></p><p></p><p>安装 Instrumentations 资源</p><p></p><p>一旦上面的 operator 安装就绪之后，我们就可以使用其内置的 Instrumentations 资源，如下文件告诉了 Operator 后续为我们应用注入 sidecar 的时候的一些差异化行为，比如文件中针对 Java 应用定义了两个环境变量，该环境变量是将 Opentelemetry Java Agent 的指标以 Prometheus 导出器将指标通过 9464 端口暴露出来。</p><p><code lang=\"text\">kubectl apply -f - &lt;<=\"\" code=\"\"></code></p><p></p><p><code lang=\"text\">为应用注入 sidecar</code></p><p></p><p><code lang=\"text\">上面我们创建了一个 Instrumentation 资源，只是申明了 Operator 注入 sidecar 的时候的模版，我们还得需要告诉 Operator 哪些应用需要注入这个 sidecar。假设需要给名字为 my-demo-app 的 Deployment 注入 sidecar，需要在 spec.annotations 下添加 instrumentation.opentelemetry.io/inject-java: \"default/opentelemetry-autoinstrumentation\"注解：</code></p><p><code lang=\"text\"><code lang=\"text\">apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-demo-app\n  labels:\n    app: my-demo-app\nspec:\n  selector:\n    matchLabels:\n      app: my-demo-app\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: my-demo-app\n      annotations:\n# 在 spec.annotations 下添加该注解\n        instrumentation.opentelemetry.io/inject-java: \"default/opentelemetry-autoinstrumentation\"\n    spec:\n      containers:\n      - name: my-demo-app\n        image: my-jmx-exporter\n        ports:\n          - containerPort: 8080\n            protocol: TCP</code></code></p><p></p><p><code lang=\"text\">最终生成的 YAML 内容如下：</code></p><p><code lang=\"text\"><code lang=\"text\">apiVersion: v1\nkind: Pod\nmetadata:\n  name: my-demo-app-565bd877dd-nqkk6\n  generateName: my-demo-app-565bd877dd-\n  namespace: default\n  uid: aa89ca0d-620c-4d20-8bc1-37d67bad4ea4\n  resourceVersion: '2668986'\n  creationTimestamp: '2022-04-08T05:58:48Z'\n  labels:\n    app: my-demo-app\n    pod-template-hash: 565bd877dd\n  annotations:\n    instrumentation.opentelemetry.io/inject-java: 'true'\n    sidecar.opentelemetry.io/inject: 'false'\nspec:\n  volumes:\n    - name: opentelemetry-auto-instrumentation\n      emptyDir: {}\n  initContainers:\n    - name: opentelemetry-auto-instrumentation\n      image: &gt;-\n        ghcr.io/open-telemetry/opentelemetry-operator/autoinstrumentation-java\n      command:\n        - cp\n        - /javaagent.jar\n        - /otel-auto-instrumentation/javaagent.jar\n      volumeMounts:\n        - name: opentelemetry-auto-instrumentation\n          mountPath: /otel-auto-instrumentation\n  containers:\n    - name: my-demo-app\n      image: my-jmx-exporter\n      env:\n- name: OTEL_METRICS_EXPORTER\n        value: \"prometheus\"\n      - name: OTEL_METRICS_EXPORTER_PORT\n        value: \"9464\"\n        - name: JAVA_TOOL_OPTIONS\n          value: ' -javaagent:/otel-auto-instrumentation/javaagent.jar'\n        - name: OTEL_TRACES_EXPORTER\n          value: otlp\n        - name: OTEL_EXPORTER_OTLP_ENDPOINT\n          value: http://opentelemetry-collector.svc.cluster.local:4317\n        - name: OTEL_SERVICE_NAME\n          value: my-demo-app\n        - name: OTEL_RESOURCE_ATTRIBUTES_POD_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.name\n        - name: OTEL_RESOURCE_ATTRIBUTES_POD_UID\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.uid\n        - name: OTEL_RESOURCE_ATTRIBUTES_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: OTEL_RESOURCE_ATTRIBUTES\n          value: &gt;-\n            k8s.container.name=my-demo-app,k8s.deployment.name=my-demo-app,k8s.deployment.uid=8de6929d-dda0-436c-bca1-604e9ca7ea4e,k8s.namespace.name=default,k8s.node.name=$(OTEL_RESOURCE_ATTRIBUTES_NODE_NAME),k8s.pod.name=$(OTEL_RESOURCE_ATTRIBUTES_POD_NAME),k8s.pod.uid=$(OTEL_RESOURCE_ATTRIBUTES_POD_UID),k8s.replicaset.name=my-deployment-with-sidecar-565bd877dd,k8s.replicaset.uid=190d5f6e-ba7f-4794-b2e6-390b5879a6c4\n        - name: OTEL_PROPAGATORS\n          value: jaeger,b3\n      volumeMounts:\n        - name: opentelemetry-auto-instrumentation\n          mountPath: /otel-auto-instrumentation\n      terminationMessagePath: /dev/termination-log\n      terminationMessagePolicy: File\n      imagePullPolicy: Always\n  restartPolicy: Always\n  securityContext:\n    runAsUser: 1000\n    runAsGroup: 3000\n    fsGroup: 2000\n</code></code></p><p></p><p><code lang=\"text\">经过如上的改造之后， my-demo-app 具备了暴露 JVM 指标的能力，运行服务之后，我们可以通过 http://lcoalhost:9464 访问服务暴露出来的 prometheus 格式的指标。同时，该接口也能被 prometheus 抓取并收集指标， prometheus.yaml 配置文件参考如下:</code></p><p><code lang=\"text\"><code lang=\"text\">prometheus:\n config:\n   scrape_configs:\n     - job_name: \"otel-jvm-metrics\"\n       scrape_interval: 10s\n       metrics_path: \"/\"\n       static_configs:\n         - targets: [\"<=\"\" code=\"\"></code></code></p><p></p><p></p><h2><code lang=\"text\"><code lang=\"text\">使用 Prometheus 和 Grafana 统一 监控 JVM</code></code></h2><p></p><p></p><p><code lang=\"text\"><code lang=\"text\">前面介绍了几种开源暴露 JVM 指标的工具，通过上面几款工具，可以使我们的 Java 应用具备 JVM 暴露能力，接下来我们就需要考虑如何将这些指标集中采集存储并展示分析。本文主要介绍 Prometheus 和 Grafana 的方案并以使用 Opentelemetry Java Agent 作为 JVM 指标暴露为例：</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">查看 Java 应用运行日志，加载 OTEL Agent：</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\"><img src=\"https://static001.geekbang.org/infoq/be/be8e4d543308f917f48cce72340052f3.png\" /></code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">以下 Prometheus Scrape 抓取指标配置文件，与前面 Opentelemetry Java Agent 章节末尾提供的 prometheus.yaml 配置文件一致 ：</code></code></p><p><code lang=\"text\"><code lang=\"text\"><code lang=\"text\">prometheus:\n config:\n   scrape_configs:\n     - job_name: \"otel-jvm-metrics\"\n       scrape_interval: 10s\n       metrics_path: \"/\"\n       static_configs:\n         - targets: [\"\"]</code></code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">以下是 OTEL Java Agent 通过 JMX 采集并暴露出来的部分指标：</code></code></p><p><code lang=\"text\"><code lang=\"text\"><code lang=\"text\"># TYPE target info\n# HELP target Target metadata\ntarget_info{container_id=\"3da5e8bc10cf207f01e0373a82c7bb3f7b8c430a757b6412f2199967a7971f9a\",host_arch=\"amd64\",host_name=\"3da5e8bc10cf\",os_description=\"Linux 5.10.104-linuxkit\",os_type=\"linux\",process_command_line=\"/usr/local/openjdk-11/bin/java -javaagent:/app/opentelemetry-javaagent.jar -Dspring.cloud.nacos.config.enabled=false -Dspring.randomError=false -Dotel.jmx.config=/app/jmx_config_file.yaml -Dotel.metrics.exporter=prometheus -Dotel.exporter.prometheus.port=9464\",process_executable_path=\"/usr/local/openjdk-11/bin/java\",process_pid=\"7\",process_runtime_description=\"Oracle Corporation OpenJDK 64-Bit Server VM 11.0.15+10\",process_runtime_name=\"OpenJDK Runtime Environment\",process_runtime_version=\"11.0.15+10\",service_name=\"adservice-springcloud\",telemetry_auto_version=\"1.22.1\",telemetry_sdk_language=\"java\",telemetry_sdk_name=\"opentelemetry\",telemetry_sdk_version=\"1.22.0\"} 1\n# TYPE otel_scope_info info\n# HELP otel_scope_info Scope metadata\notel_scope_info{otel_scope_name=\"io.opentelemetry.micrometer-1.5\"} 1\n# TYPE otel_scope_info info\n# HELP otel_scope_info Scope metadata\notel_scope_info{otel_scope_name=\"io.opentelemetry.runtime-metrics\",otel_scope_version=\"1.22.1-alpha\"} 1\n# TYPE executor_pool_core gauge\n# HELP executor_pool_core The core number of threads for the pool\nexecutor_pool_core{otel_scope_name=\"io.opentelemetry.micrometer-1.5\",name=\"applicationTaskExecutor\"} 8.0 1676368076291\n# TYPE logback_events_total counter\n# HELP logback_events_total Number of events that made it to the logs\nlogback_events_total{otel_scope_name=\"io.opentelemetry.micrometer-1.5\",level=\"info\"} 12.0 1676368076291\nlogback_events_total{otel_scope_name=\"io.opentelemetry.micrometer-1.5\",level=\"warn\"} 3.0 1676368076291\n# TYPE jvm_gc_live_data_size gauge\n# HELP jvm_gc_live_data_size Size of long-lived heap memory pool after reclamation\njvm_gc_live_data_size{otel_scope_name=\"io.opentelemetry.micrometer-1.5\"} 2.7941376E7 1676368076291\n# TYPE executor_pool_max gauge\n# HELP executor_pool_max The maximum allowed number of threads in the pool\nexecutor_pool_max{otel_scope_name=\"io.opentelemetry.micrometer-1.5\",name=\"applicationTaskExecutor\"} 2.147483647E9 1676368076291\n# TYPE disk_total gauge\n# HELP disk_total Total space for path\ndisk_total{otel_scope_name=\"io.opentelemetry.micrometer-1.5\",path=\"/app/.\"} 4.2006183936E10 1676368076291\n# TYPE executor_active gauge\n# HELP executor_active The approximate number of threads that are actively executing tasks\nexecutor_active{otel_scope_name=\"io.opentelemetry.micrometer-1.5\",name=\"applicationTaskExecutor\"} 0.0 1676368076291\n# TYPE disk_free gauge\n# HELP disk_free Usable space for path\ndisk_free{otel_scope_name=\"io.opentelemetry.micrometer-1.5\",path=\"/app/.\"} 1.8299908096E10 1676368076291\n# TYPE system_cpu_count gauge\n# HELP system_cpu_count The number of processors available to the Java virtual machine\nsystem_cpu_count{otel_scope_name=\"io.opentelemetry.micrometer-1.5\"} 2.0 1676368076291\n# TYPE jvm_memory_committed gauge\n# HELP jvm_memory_committed The amount of memory in bytes that is committed for the Java virtual machine to use\njvm_memory_committed{otel_scope_name=\"io.opentelemetry.micrometer-1.5\",area=\"heap\",id=\"G1 Old Gen\"} 6.6060288E7 1676368076291\njvm_memory_committed{otel_scope_name=\"io.opentelemetry.micrometer-1.5\",area=\"nonheap\",id=\"Compressed Class Space\"} 9175040.0 1676368076291\njvm_memory_committed{otel_scope_name=\"io.opentelemetry.micrometer-1.5\",area=\"nonheap\",id=\"CodeHeap 'non-profiled nmethods'\"} 4653056.0 1676368076291\njvm_memory_committed{otel_scope_name=\"io.opentelemetry.micrometer-1.5\",area=\"nonheap\",id=\"CodeHeap 'profiled nmethods'\"} 1.8087936E7 1676368076291\njvm_memory_committed{otel_scope_name=\"io.opentelemetry.micrometer-1.5\",area=\"nonheap\",id=\"Metaspace\"} 6.422528E7 1676368076291\njvm_memory_committed{otel_scope_name=\"io.opentelemetry.micrometer-1.5\",area=\"heap\",id=\"G1 Survivor Space\"} 7340032.0 1676368076291\njvm_memory_committed{otel_scope_name=\"io.opentelemetry.micrometer-1.5\",area=\"heap\",id=\"G1 Eden Space\"} 1.00663296E8 1676368076291\njvm_memory_committed{otel_scope_name=\"io.opentelemetry.micrometer-1.5\",area=\"nonheap\",id=\"CodeHeap 'non-nmethods'\"} 2555904.0 1676368076291\n......</code></code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">在 Grafana 中导入 Opentelemetry JVM Metrics DashBoard( ID=8563 ）</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">DashBoard 根据 Prometheus 采集到的指标，绘制出了我们常用的一些指标面板，比如 CPU 和内存负载情况，线程运行状况等等，也可以基于该 DashBoard 进行自定义。图片: h</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\"><img src=\"https://static001.geekbang.org/infoq/7a/7ab42060dea9e0f1c58072c8e3300e09.png\" /></code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\"><img src=\"https://static001.geekbang.org/infoq/a5/a5531b9052ac8be170d289fd44ffc231.png\" /></code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\"><img src=\"https://static001.geekbang.org/infoq/eb/eb6e5a87d7e75b28dc1680139367de85.png\" /></code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\"><img src=\"https://static001.geekbang.org/infoq/7b/7b03aef32d88ae14502273a3e32880c5.png\" /></code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">该部分的 Demo 文件可以参考底部参考部分的 jmx-jvm-demo</code></code></p><p></p><p></p><h2><code lang=\"text\"><code lang=\"text\">总结：</code></code></h2><p></p><p></p><p><code lang=\"text\"><code lang=\"text\">本文介绍了 JVM 监控的技术原理，同时介绍了常见的几种开源暴露 JVM 指标的工具。从接入方式来看主要分为两类，第一类是像 Spring Boot Actuator 需要客户应用做一些改造的方式，另一类是 JMX Exporter 和 Opentelemetry Java Agent 无侵入的方式。</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">以下针对这三种方案进行了多维度比较：</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\"><img src=\"https://static001.geekbang.org/infoq/ed/ed86dc4b41132879dc251ffd4f82bc00.png\" /></code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">可以根据业务自身情况选择使用哪一种方式，针对运行在非容器平台的 Spring Boot 应用，建议选择 Spring Boot Actuator 方式，该方式能够更好的和 Spring Boot 生态集成。</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">如果业务应用运行在容器平台，建议选择 Opentelemetry Java Agent 的方式，该方式支持 Operator 的方式，能够以最小代价对 Java 应用进行监控，同时也方便后续对 Agent 版本的升级与运维。如果应用目前已经通过 Opentelemetry Java Agent 实现了链路采集，那么更加建议使用 Operator 云原生的方式。</code></code></p><p></p><p></p><h2><code lang=\"text\"><code lang=\"text\">参考：</code></code></h2><p></p><p></p><p><code lang=\"text\"><code lang=\"text\">jmx demo (https://gist.github.com/JaredTan95/8711878369b9b12c772dd783a21c621d)</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">Micrometer (https://micrometer.io/)</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">Spring Boot Actuator (https://github.com/spring-projects/spring-boot/tree/main/spring-boot-project/spring-boot-actuator)</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">Prometheus JMX Exporter (https://github.com/prometheus/jmx_exporter)</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">Zabbix JMX （https://www.zabbix.com/integrations/java_monitoring）</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">OpenTelemetry Java Agent(https://opentelemetry.io/blog/2023/jmx-metric-insight/)</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">JMX Metric Insight (https://github.com/open-telemetry/opentelemetry-java-instrumentation/blob/main/instrumentation/jmx-metrics/javaagent/README.md)</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">Opentelemetry Operator (https://github.com/open-telemetry/opentelemetry-operator)</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">jmx-jvm-demo (https://github.com/openinsight-proj/jmx-jvm-demo)</code></code></p><p></p><p></p><h3><code lang=\"text\"><code lang=\"text\">作者介绍</code></code></h3><p></p><p></p><p><code lang=\"text\"><code lang=\"text\">谭建，「DaoCloud 」可观测性技术专家。负责研发新一代云原生操作系统底座，DCE 5.0 社区版 https://docs.daocloud.io/download/dce5/</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">欢迎大家关注“OpenTelemetry” 公众号，这是中国区唯一官方技术公众号想加入技术社群和参与活动的朋友联系我</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\"><img src=\"https://static001.geekbang.org/infoq/95/9557c5bef779936148762d7141c30d44.png\" /></code></code></p><p></p>",
    "publish_time": "2023-03-23 09:12:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Alluxio跨集群同步机制的设计与实现",
    "url": "https://www.infoq.cn/article/5kCy7S0627JVJyP63uLk",
    "summary": "<p></p><h2>一、Alluxio 应用场景和背景</h2><p></p><p></p><p>Alluxio 跨集群同步机制的设计和实现确保了在运行多个 Alluxio 集群时，元数据是一致的。</p><p></p><p>Alluxio 位于存储和计算层之间，在不同的底层文件系统（UFS）上层提供高性能缓存和统一的命名空间。虽然通过 Alluxio 对 UFS 进行更新可使 Alluxio 与 UFS 保持一致，但在某些情况下, 例如在运行多个共享某一个或多个 UFS 命名空间的 Alluxio 集群时，结果可能并非如此。为了确保这种情况下的一致性，Alluxio 已经实现了跨集群同步机制，本文将对该机制进行详细介绍。</p><p></p><h3>1. 背景介绍</h3><p></p><p></p><p>随着数据量的增长，这些数据的存储和访问方式也变得越来越复杂。例如，数据可能位于不同的存储系统中（S3、GCP、HDFS 等），也可能存储在云上或本地，或是位于不同的地理区域，还可能因为隐私或安全保护，被进一步隔离。此外，这些复杂性不仅体现在数据存储上，还包括如何将数据用于计算，例如，数据可能存储在云上，而计算则在本地进行。</p><p></p><p>Alluxio 是一个数据编排平台，通过在 UFS 上提供统一的访问接口来降低此类复杂性，并通过提供数据本地性和缓存来提高计算性能。</p><p></p><p>对于许多组织而言，运行一个 Alluxio 集群可能就足够了，但有些组织需要运行多个 Alluxio 集群。例如，如果计算是在多个区域运行，那么在每个区域运行一个 Alluxio 集群可能会带来更大的优势。此外，某些组织可能出于数据隐私保护的考虑，需要运行独立的集群，或是希望通过运行多个集群来提高可扩展性。虽然部分数据空间可能被隔离在某个集群中，但其他数据可以在多个集群之间共享。例如，一个集群可能负责提取和转换数据，而其他几个集群可能会查询这些数据并进行更新。</p><p></p><p>由于每个 Alluxio 集群可能会复制（即挂载）UFS 存储空间的某些部分，Alluxio 会负责保持其副本与 UFS 的一致性，以便用户查询到最新的文件副本。在本文中，我们将介绍在一个或多个集群中确保 Alluxio 数据与 UFS 一致所用到的组件。</p><p></p><h3>2.Alluxio 数据一致性</h3><p></p><p></p><p>在分布式系统中保持数据的一致性是很复杂的，其中有几十个不同的一致性级别，每个级别都允许不同的用户在特定时间查询和修改数据的不同状态。这些一致性级别形成了一个从弱到强的范围区间，一致性越强限制越多，通常越容易在上面搭建应用程序。Alluxio 也不例外，它会根据配置和使用的 UFS 提供不同的一致性保障（详细信息见 Alluxio 的数据一致性模型）。</p><p></p><p>为了简化关于一致性的讨论，我们将做如下假设：</p><p></p><p>● 对于任何文件，UFS 都是文件的 “唯一数据源”。</p><p></p><p>这意味着 Alluxio 中的每个文件都对应于 UFS 上的一个文件，并且 UFS 中总是有该文件的最新版本。如果 Alluxio 存储的文件副本与 UFS 中的文件不同，那么 Alluxio 中的文件版本是不一致的。(这里我们假设 UFS 本身确保了强一致性，即某种程度的线性一致性（linearizability）或外部一致性（external consistency）。从高层次来看，这允许用户把 UFS（即便系统是由许多分布式部分所组成) 当作类似实时按顺序执行操作的单一的文件系统来访问。</p><p></p><p>在讨论 Alluxio 和 UFS 的一致性之前，让我们先来看一下 Alluxio 的基本架构。Alluxio 是由 master 节点和 worker 节点组成的。master 节点负责跟踪文件的元数据，例如它的路径、大小等，而 worker 节点负责存储数据本身。如果 client 要读一个文件，必须先从某一个 master 节点上读取元数据，然后用它来定位存储该数据副本的 worker（必要时可以从 UFS 上加载数据）。如果 client 要写一个文件，必须首先在 master 中为该文件创建元数据，然后通过 worker 将该文件写到 UFS，最后在 master 上将该文件标记为完成。当文件正在被写入时，它的元数据会被标记为未完成，从而阻止其他 client 访问该文件。</p><p></p><p>从这个基本设计中，我们可以看到，只要所有对文件的更新都通过 Alluxio 写入 UFS，那么 Alluxio 中的数据将与 UFS 中的数据保持一致，client 将会始终查询到最新的数据版本。</p><p></p><p>然而现实情况，并没有这么简单，例如，某些用户可能在更新 UFS 时不通过 Alluxio，或者 client 可能出现故障，只将部分文件写入 UFS，而没有在 Alluxio master 上标记完成，这些都可能导致 Alluxio 和 UFS 中的数据不一致。</p><p></p><p>那么，这些问题是如何处理的呢？由于我们重点假设了 UFS 是唯一的数据源，要解决这些不一致的问题只需让 Alluxio 与 UFS 同步即可。</p><p></p><h3>3. 元数据同步</h3><p></p><p></p><p>元数据同步是用来检查和修复 Alluxio 和 UFS 之间不一致的主要组件。当 client 访问 Alluxio 中的某个路径时，该功能在一定条件下（后面会讨论）可能会被触发。基本程序如下：</p><p></p><p>从 UFS 加载该路径的元数据。</p><p></p><p>将 UFS 中的元数据与 Alluxio 中的元数据进行比较。元数据中包含文件数据的指纹（例如最后修改时间和抗碰撞的哈希值），可用于检查数据不一致情况。</p><p></p><p>如果发现任何不一致，则更新 Alluxio 中的元数据，并标记过时的数据，以便将其从 worker 中驱逐。最新数据会根据需要从 UFS 加载到 worker。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/af/afc7eeb40b6b30a19f51f76c38ad5fd5.png\" /></p><p></p><p>图：client 读取时的元数据同步过程。1. client 读取文件系统中的一个路径。2. master 上的元数据同步模块根据用户配置检查是否需要同步。3. 通过从 UFS 加载元数据进行同步，并创建一个指纹来比较 Alluxio 和 UFS 中的元数据。如果指纹不同，则 Alluxio 中的元数据会被更新。4. client 根据更新后的元数据从 worker 中读取文件数据，必要时从 UFS 中加载数据。</p><p></p><p>唯一的问题就是决定何时执行这个元数据同步程序，需要我们在更强的一致性和更好的性能之间进行权衡。</p><p></p><h4>每次访问数据时进行元数据同步</h4><p></p><p></p><p>如果 Alluxio 中的 client 每次访问一个路径时都进行元数据同步，那么 client 将始终能查看到 UFS 上最新的数据状态。这将为我们提供最高的一致性级别，通常可以达到 UFS 所能确保的最强的一致性。但是，由于每次访问数据（即使数据没有被修改）都会与 UFS 进行同步，这也会将导致性能下降。</p><p></p><h4>基于时间进行元数据同步</h4><p></p><p></p><p>另外，元数据同步可以基于一个物理时间间隔来执行。在这种情况下，Alluxio master 上的元数据包含路径最后一次与 UFS 成功同步的时间。现在，只有当用户定义的时间间隔过后，才会进行新的同步（详细信息见 UFS 元数据同步）。</p><p></p><p>虽然这种方式可能极大地提高了性能，但也导致了相对较弱级别的一致性保障，即最终一致性。这意味着，任何特定的读取结果可能与 UFS 一致，也可能不一致。此外，数据更新被查询到的顺序可能是任意顺序。例如，在 UFS 中，文件 A 的更新实际早于另一个文件 B，但是，Alluxio 集群查询到的可能是文件 B 的更新早于文件 A。因此，系统的用户必须了解这些不同级别的一致性保障，并根据需要调整应用程序。</p><p></p><h2>二、跨集群同步机制</h2><p></p><p></p><p>在上一章节，我们讨论了单个 Alluxio 集群的场景、背景以及如何进行元数据同步。本章将介绍如何在多集群场景下实现建立元数据同步，从而确保以提供元数据一致性。</p><p></p><h3>1. 基于时间同步的多集群一致性</h3><p></p><p></p><p>其中一个基于时间的元数据同步用例是使用多个 Alluxio 集群且集群共享部分 UFS 数据空间的场景。通常，我们可以认为这些集群正在运行单独的工作负载，这些工作负载可能需要在某些时间点共享数据。例如，一个集群可能会提取和转换来自某一天的数据，然后另一个集群会在第二天对该数据进行查询。运行查询任务的集群可能不需要总是看到最新的数据，例如可以接受最多一个小时的延迟。</p><p></p><p>在实践中，使用基于时间的同步不一定总是有效，因为只有特定的工作负载才会定期更新文件。事实上，对于许多工作负载来说，大部分文件仅被写入一次，而只有一小部分文件会经常更新。在这种情况下，基于时间的同步效率变低，这是因为大多数同步都是不必要的，增加时间间隔将导致经常修改的文件处于数据不一致状态的时间更长。</p><p></p><h3>2. 使用跨集群同步（Cross&nbsp;Cluster Sync）实现多集群一致性</h3><p></p><p></p><p>为了避免基于时间同步的低效性，跨集群同步功能允许直接跟踪不一致性，因此只在必要时才会同步文件。这意味着每当在 Alluxio 集群上一条路径发生更改时，该集群将发布一个失效消息，通知其他 Alluxio 集群该路径已被修改。下次当有 client 在订阅（跨集群同步功能的）集群上访问此路径时，将触发与 UFS 的同步操作。</p><p></p><p>与基于时间的同步相比，跨集群同步具有两个主要优点。首先，只对已修改的文件执行同步，其次，修改可以快速地对其他集群可见，所需时间即大约等同于从一个集群发送消息到另一个集群的时间。</p><p></p><p>由此我们可以看到，当满足以下假设时，跨集群同步功能将是最有效用的。</p><p></p><p>多个 Alluxio 集群挂载的一个或多个 UFS 中有交叉部分。(我们认为系统中部署的 Alluxio 集群数量的合理范围是 2-20 个）。</p><p></p><p>至少有一个集群会对 UFS 上的文件进行更新。</p><p></p><p>所有对 UFS 的更新都要经过 Alluxio 集群（关于处理其他情况的方法，请参见下文 \"其他用例\"内容）。</p><p></p><p>现在我们要确保来自一个 Alluxio 集群的更新将最终在其他所有 Alluxio 集群中被监测到（即集群与 UFS 满足最终一致性保障），这样应用程序就可以在集群间共享数据。</p><p></p><h4>路径失效发布 / 订阅</h4><p></p><p></p><p>跨集群同步功能是基于发布 / 订阅（pub/sub）机制实现的。当 Alluxio 集群挂载某个 UFS 路径时，就会订阅该路径，每当集群修改 UFS 上的文件时，它都会向所有订阅者发布修改的路径。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/dd/dd0c965689e2953280272d35890aceac.png\" /></p><p></p><p>表 1：三个 Alluxio 集群挂载不同的 UFS 路径示例。</p><p></p><p>参考表 1 中的例子，有三个 Alluxio 集群，每个集群挂载一个不同的 S3 路径。这里，集群 C1 将 S3 桶（bucket）s3://bucket/ 挂载到其本地路径 /mnt/，集群 C2 将同一个 bucket 的子集 s3://bucket/folder 挂载到其本地路径 /mnt/folder，最后 C3 将 s3://bucket/other 挂载到其根路径 /。</p><p></p><p>由此，集群 C1 将订阅路径（pub/sub 语义中的“主题”）s3://bucket，集群 C2 将订阅路径 s3://bucket/folder，而集群 C3 将订阅路径 s3://bucket/other。订阅者将收到所有发布的以订阅“主题”开头的消息。</p><p></p><p>例如，如果集群 C1 创建了一个文件 /mnt/folder/new-file.dat，它将发布一个包含 s3://bucket/folder/new-file.dat 的无效消息，集群 C2 将会收到该消息。另外，如果集群 C1 创建了一个文件 /mnt/other-file.dat，则不会发送任何消息，这是因为没有订阅者的主题与 s3://bucket/other-file.dat 相匹配。</p><p></p><p>如前所述，Alluxio 的元数据包括该路径最近一次同步发生的时间。在跨集群同步的情况下，它还包含最近一次通过 pub/sub 接口收到的路径失效信息的时间。利用这一点，当 client 访问一个路径时，在以下两种情况下将会与 UFS 进行同步。</p><p></p><p>a) 该路径第一次被访问。</p><p></p><p>b) 路径的失效时间晚于最近一次同步时间。</p><p></p><p>假设系统中没有故障，显然最终一致性将得到保证。对文件的每一次修改都会导致每个订阅集群收到一个失效消息，从而在下一次访问该文件时进行同步。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5f/5fb9e6d75539c3756c3f80bd02df17c5.png\" /></p><p></p><p>图 1：文件创建过程中的跨集群同步机制。A. client 在集群 1 上创建一个文件。B. client 将文件写入 worker。C. worker 把文件写入 UFS。D. client 在 master 上完成了该文件。E. 集群 1 向集群 2 的订阅者发布文件的失效消息。F. 集群 2 在其元数据同步组件中将该文件标记为需要同步。以后当 client 访问该文件时，将同样使用图 1 所示的步骤 1-5 进行同步。</p><p></p><h4>实现 Pub/sub 机制</h4><p></p><p></p><p>Pub/sub 机制是通过发现机制（discovery mechanism）和网络组件来实现的，前者允许集群知道其他集群挂载了什么路径，后者用来发送消息。</p><p></p><p>发现机制是一个名为 CrossClusterMaster 的单一 java 进程，须能让所有 Alluxio 集群通过可配置的地址 / 端口组合进行访问。每当一个 Alluxio 集群启动时，都会通知 CrossClusterMaster 该集群的所有 master 节点的地址。此外，每当集群挂载或卸载 UFS 时，挂载的路径都将被发送到 CrossClusterMaster。每次这些值被更新时，CrossClusterMaster 节点都会把新值发送给所有 Alluxio 集群。</p><p></p><p>利用这些信息，每个 Alluxio 集群将计算其本地 UFS 挂载路径与外部集群的所有 UFS 挂载路径的交集。对于每个相交的路径，集群的 master 将使用 GRPC 连接创建一个以该路径为主题的订阅给外部集群的 master。在表 1 的例子中，C1 将向 C2 创建一个主题为 s3://bucket/folder 的订阅，以及向 C3 创建一个主题为 s3://bucket/other 的订阅。此外，C2 将向 C1 创建一个主题为 s3://bucket/folder 的订阅，而 C3 将向 C1 创建一个主题为 s3://bucket/other 的订阅。这样一来，每当集群要修改某个路径时，例如创建一个文件，它都会把修改的路径发布给任何主题是该路径前缀的订阅者。例如，如果 C1 创建一个文件 /mnt/other/file，它将发布 s3://bucket/other/file 到 C3。</p><p></p><p>为了主动维护对其他集群的订阅，每个 Alluxio master 上都会运行一个线程，以应对路径的挂载或卸载、集群的加入或者脱离，以及出现连接故障等情况的发生。</p><p></p><p>每当订阅者收到路径时，它就会将失效时间元数据更新为当前时间，这样一来，下一次 client 访问该路径时，就会与 UFS 进行一次同步。按照我们上面的例子，下一次 client 在集群 C3 上读取路径 /file 时，将在 s3://bucket/other/file 上执行与 UFS 的同步。</p><p></p><h4>确保最终一致性</h4><p></p><p></p><p>如果能保证每条发布的消息都向所有订阅者（包括未来的订阅者）仅传递一次（exactly once） ，那么显然最终一致性将得到保证，因为每一次修改都会让订阅者在访问路径时进行同步。但是，连接可能中断、集群可能脱离和接入系统、节点也可能出现故障，我们该如何保证消息的准确传递呢？简单的答案是，我们不能。相反，只有在订阅（使用底层 TCP 连接）处于运行状态时，才能确保仅一次消息传递。此外，当订阅首次建立时，订阅者将标记根路径（主题）的元数据为需要同步。这意味着，在订阅建立后，对于任何作为主题的超集路径，在第一次访问该路径时将进行同步。</p><p></p><p>例如，当 C1 用主题 s3://bucket/folder 建立对 C2 的订阅时，C1 将标记 s3://bucket/folder 为需要同步。然后，例如在第一次访问 s3://bucket/folder/file 时，将进行同步。</p><p></p><p>这大大简化了处理系统中的故障或配置变化的任务。如果某个订阅因为任何原因而失败，如网络问题、master 故障切换、配置变化，那么恢复过程是一样的——重新建立订阅，并将相应的路径标记为不同步。为了减轻网络问题的影响，可以设置一个用户定义的参数，以确定有多少消息可以缓存在发布者的发送队列中，以及在队列已满的情况下超时等待多久会发生操作阻塞的可能性。</p><p></p><p>当然，按照预期，虽然我们的系统会发生故障，但不会经常发生，否则性能会受到影响。所幸即使在频繁发生故障的情况下，性能下降也会与使用基于时间的同步的情况相似。例如，如果每 5 分钟发生一次故障，预计性能与启用基于时间（5 分钟间隔）同步下的性能类似。</p><p></p><p>请注意，如果 CrossClusterMaster 进程发生故障，那么新的集群和路径挂载发现将不起作用，但集群将保持其现有的订阅而不会中断。此外，CrossClusterMaster 是无状态的（可以把它看作是集群交换地址和挂载路径的一个点），因此，可以在必要时停止和重新启动。</p><p></p><h4>其他用例</h4><p></p><p></p><p>前面提到，为了使这个功能发挥作用，所有对 UFS 的更新都应该通过 Alluxio 集群进行。当然这个条件不一定能满足，有几种方法来处理这个问题。</p><p></p><p>用户可以手动将一个路径标记为需要同步。</p><p></p><p>基于时间的同步可以和跨集群同步一起启用。</p><p></p><h2>三、探讨与结论</h2><p></p><p></p><h3>1. &nbsp;探讨与未来工作</h3><p></p><p></p><h4>为什么不使用确保仅一次消息传递的 pub/sub 机制？</h4><p></p><p></p><p>我们知道，如果使用确保仅一次消息传递的 pub/sub 机制会大大简化我们的设计，而且也确实存在许多强大的系统，如 Kafka 和 RabbitMQ，正是为了解决这个问题而创建的。使用这些系统的好处是，故障对性能的影响可能较小。例如，如果某个订阅者处连接断开，在重新连接时，系统可以从它之前断开的地方继续运行。</p><p></p><p>尽管如此维护这些系统本身就是一项非常复杂的任务。首先，你需要弄清楚一些问题，比如，要部署多少个节点的物理机，要复制多少次消息，保留多长时间，当由于连接问题而不能发布消息时要不要阻塞操作等。而且，最终很可能还是需要故障恢复机制，从而导致更复杂的设计。</p><p></p><p>(注意，为了保证最终一致性，我们实际上只需要至少一次 (at least once) 消息传递，因为多次传递消息只会对性能产生负面影响，而不会影响数据一致性，但即便在这种情况下，大部分困难仍然存在)。</p><p></p><h4>扩展至 20 个 Alluxio 集群以上或处理频发故障</h4><p></p><p></p><p>未来，我们希望能支持扩展到数百个 Alluxio 集群，但从 20 个集群扩展至数百个集群可能有不同的设计考量。首先，我们预期故障的发生会更加频繁；其次，设计可能会导致 master 产生大量开销。</p><p></p><p>如前所述，故障频繁发生会使性能降低到与采用基于时间同步时类似。在有数百个集群的情况下，我们预期网络或 master 节点故障会相当频繁地发生。(请注意，这也取决于配置，因为故障只会影响挂载了与故障 UFS 路径有交集的集群。因此，如果集群大多挂载了不相交的 UFS 路径，那么可能问题不大）。此外，如果所有集群挂载的路径都有交集，那么它们将必须维护对所有其他集群的订阅，且一个发布就需要发送数百条消息。</p><p></p><p>在这种情况下，我们可能需要纳入一个可靠的 pub/sub 机制，如 Kafka 或 RabbitMQ，但这里只是替代点对点的订阅，而不是改变整个系统的设计。故障仍然会发生，集群将以同样的方式恢复——将相交的 UFS 路径标记为需要同步。只有可靠的 pub/sub 机制才会隐藏 Alluxio 的许多故障。例如，如果该机制想要可靠地存储最后 5 分钟的消息，那么只有持续时间超过 5 分钟的故障才需要用原来的方法进行恢复。此外，这些系统能够不考虑 Alluxio 集群的数量进行扩展，在必要时添加更多节点。不过，使用和维护这些系统会产生大量的开销，可能只有在某些配置中才值得尝试。</p><p></p><h4>关于一致性的一些看法</h4><p></p><p></p><p>虽然本文介绍了确保最终一致性的基本思路，但还有几个重要的内容没有详细说明。</p><p></p><p>首先，失效消息必须在对 UFS 的修改完成后才能发布，其次，UFS 必须在线性一致性或外部一致性（S3 中的一致性）层面上确保强一致性。如果这两个条件中的任何一个没有得到满足，那么当订阅者收到失效信息并执行同步时，集群可能无法观测到文件的最新版本。第三，如果一个集群与 CrossClusterMaster 的连接断开，后来又重新建立了连接，那么该集群也必须经历故障恢复过程，这是因为在连接中断期间可能有某个外部集群挂载并修改了路径。</p><p></p><h4>发布完整的元数据</h4><p></p><p></p><p>如前所述，发布的失效消息只包含被修改的路径。但是，这些消息也可以包括路径的更新元数据，从而避免在订阅集群上进行同步。之所以不这样做是因为无法通过常规方法知道哪个版本的元数据是最新的版本。</p><p></p><p>例如，两个 Alluxio 集群 C1 和 C2 在 UFS 上更新同一个文件。在 UFS 上，集群 C1 的更新发生在集群 C2 的更新之前。然后，两个集群都将他们更新的元数据发布到第三个集群 C3。由于网络条件的原因，C2 的消息比 C1 先到达。此时，C3 需要知道，它应该放弃来自 C1 的更新，因为已经有了最新的元数据版本。当然，如果元数据包含版本信息，就可以做到这一点，但可惜对于 Alluxio 支持的所有 UFS，常规方法都做不到。因此，C3 仍然需要与 UFS 进行元数据同步，以便直接从唯一的数据源获得最新的版本。</p><p></p><h4>订阅通知服务</h4><p></p><p></p><p>某些底层存储系统（UFS）（例如 Amazon SNS 和 HDFS iNotify）提供通知服务，让用户知道文件何时被修改了。对于这类 UFS，相较于订阅 Alluxio 集群，订阅这些服务可能是更好的选择。这样做的好处是支持不通过 Alluxio 对 UFS 进行写入。同样，系统设计将保持不变，只是不订阅其他 Alluxio 集群，而是订阅此类通知服务。</p><p></p><p>请注意，Alluxio 还为 HDFS 提供了 ActiveSync 功能，允许元数据与底层 UFS 保持同步。这与跨集群的同步机制有所不同，因为 ActiveSync 在文件更新时执行同步，而跨集群同步只在文件被访问时执行同步。</p><p></p><h2>四、结论</h2><p></p><p></p><p>本文主要介绍了运行多个 Alluxio 集群能带来优势的场景，以及 Alluxio 使用基于时间同步和跨集群同步功能，用来保持集群与所挂载 UFS 同步的过程。关于如何部署跨集群同步功能的更多内容，点击<a href=\"https://docs.alluxio.io/ee/user/stable/en/core-services/Cross-Cluster-Sync.html\">此链接</a>\"查看。</p><p></p>",
    "publish_time": "2023-03-23 10:24:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "软件工程中建模的底层逻辑",
    "url": "https://www.infoq.cn/article/6e384aa8dd5ec3174eb7b121c",
    "summary": "<p>作者：高福来</p><p></p><p></p><blockquote>本文将为大家分享建模的底层逻辑和建模的方法，并通过一些大家通识的技术案例讲述建模的过程。</blockquote><p></p><p></p><p>建模对于大家来讲并不陌生，而且建模的方法也有很多，如用例建模、四色建模、事件风暴等，但在日常工作中，大家又觉得建模挺虚的：怎么把建模落到实际开发工作中。个人认为建模是分两部分：第一部分是业务概念建模，对现实业务抽取核心概念构建出模型（知识层）；第二部分是系统建模，系统建模是源于业务概念模型，遵循某些原则最终形成开发可落地的模型（操作层）。在本文中，给出建模的底层逻辑：用图形逻辑地表达现实业务的抽象，通过一些大家通识的技术案例讲述建模的过程。</p><p></p><p></p><h1>一、建模的底层逻辑</h1><p></p><p></p><p>建模的作用不言而喻，它可以极大简化大家对复杂事物的认识，让人能在短时间内有全局视野看清楚业务，而且建模是用面向对象的思维分析事物，也容易转化成类图。用一个公式表达建模的底层逻辑：建模 = 图形 + 逻辑 + 现实的抽象，用一句概括即是用图形逻辑地表达现实业务的抽象，接下面主要讲述图形、逻辑、现实的抽象这三部分的内容。</p><p></p><p></p><h2>1.1 图形</h2><p></p><p></p><p>图形即为UML图形，下面是6种对象间的关联图形，在建模中尽量遵循UML标准画图，方便大家理解。</p><p></p><p>继承：子类继承父类的特性，有的语言仅支持单继承。实现：子类实现父类定义的接口。组合：一个类包含另外的类，但它强调的是一种强关联关系。聚合：也是表达一个类包含另外的类，但它的关联关系比组合要弱。关联：通过一个类可以关联到另外一个类，可分为单向关联和双向关联，一般以类的成员变量体现。依赖：比较弱的一类关联关系，一般是以接口参数的形式体现。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6c/6cb8747fe4ec1906c529d0923062a599.jpeg\" /></p><p></p><p></p><h2>1.2 现实的抽象</h2><p></p><p></p><p>我们的现实业务有的是非常复杂的，如果涉及到专业领域概念，新手想入门是挺难的，当我们不清楚业务链路和逻辑时，直接看代码实现时很难有全局的视野，不能够串起全局业务间的内在联系。</p><p></p><p>当我们切入到一个新领域中，并非短时间内就要成为该领域的专家，急需一种方法用20%的时间能够掌握该领域80%的业务知识，一个可行的方法就是建模，通过对现实业务进行抽象，构建出全局业务概念模型，有了全局的认识，再去了解业务细节就会快得多。模型好比地图，先做到心中有谱，再\"按图索骥\"，我们比较迷茫时，往往是看不到全局的\"地图\"，因此也就做不到心中有谱。</p><p></p><p>我们要建模的对象即是问题域，我们并不需要覆盖所有的点，而是基于核心的内容进行建模，Eric Evans 在建模书中提到一个观点：建模是出于某种目的而概括地反映现实，这里的概括就是抓住核心的意思。</p><p></p><p>现实的抽象有三层意思：一类是直接映射，比如现实有一个杯子，那么我们的模型中就有一个杯子；另一类是往上抽象一层映射，比如我们的组织中有一级结构、二级结构、三级结构等，那我们可以抽象成组合结构，形成父子节点的结构，这种抽象就更灵活了；最后一类是隐性抽象，前面两类抽象比较容易做到，最难的是隐性概念抽象，它很大可能是之前不存在的，需要新造出一个概念，就像软件设计中，通过新增加一层来实现解耦一样，通过新造的概念串联元素间的内在关联关系，如下面示例的中的\"债权\"概念。</p><p></p><p>举一个金融理财的案例，需要将投资的钱给到借款人那里，然后借款人还款时将还款给到投资人，当投资人的钱给到借款人时，就产生了债权关系，因此有一个债权的概念，这记录了投资人与借款人间的债务关系，债权就是一个桥梁。当借款还款时，对应的债权就会减少，当投资周期到了，债权就会进行债权转让，转到下一个投资人身上，当前的债权关系就结束了，下图虽然比较简单，但对理解系统至关重要。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/52/528ad6cc5a57b76dd01b258f5cb52c7e.jpeg\" /></p><p></p><p></p><h2>1.3 逻辑</h2><p></p><p></p><p>逻辑即为因果，也即元素之间存在某种关系，如果两个完全没有关系的元素放在一些，就会显得前因不达后果、风马牛不相及，让人不好理解。那么对应到建模上，我们的模型应该是非常具有逻辑性的，从模型上能看出业务核心要素，要素与要素之间的关系是怎样的。</p><p></p><p>逻辑主要体现在时空两个维度上：时间维度，一件事情节点完成之后，会影响后续的事情节点；空间维度，更多的体现在结构上，我们常说的空间结构就是这个意思。以时间维度为例，在电商结算中，当订单支付成功后，结算收单，收单后接受到放款的执行指令，在放款之前需要计算出放款明细信息，如卖家应收到多少钱、公司应收到多少佣金等，最后是打款转账，这个过程就是按照时间节点不断往后驱动，可抽象出如下图的模型。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f4/f4b3d4d9788decd005e0da2eb13fa14a.jpeg\" /></p><p></p><p>空间维度即是结构关系，比如下图中的组织结构，像这样的结构类型，我们还可以找到更多的实际案例，比如交易订单有主子订单结构，执行单包含多个执行明细信息，模型最终呈现出来的就是一个结构，从结构维度也可以将其分解出更小的粒度。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/54/54bb0491826cf2054f0fc9e800769efb.jpeg\" /></p><p></p><p>不管哪种建模的方法，最根本的还是体现出了建模的逻辑性，用例建模的逻辑性体现在能够清晰地定义出用例场景，把所需要做的事讲清楚；四色建模通过人、事、物、时间、地点维度描述清楚一件事；事件风暴通过时间轴勾画出核心关键的事件。当我们构建不出模型时，并不是我们缺少建模的方法，而是建模的逻辑性上有问题，建模缺的不是方法而是经验和实践。我们不能神化建模，建模是很纯粹的，就是为了简化对复杂事物的认识，并且模型能够映射到实际开发的模型中。</p><p></p><p></p><h1>二、建模的方法</h1><p></p><p></p><p>建模的方法有很多种，方法多并不意味着建模的难度会很低，相反建模的门槛很高，对抽象思维要求非常高，而且建模并没有标准的答案，因此很多人觉得没啥意思。其实这里面有两部分：一部分是源于业务概念的抽象，它需要对业务的理解和抽象，往往大家在这一部分觉得没啥意思；另一部分是在业务概念模型的基础上，结合设计原则，最终设计出合理的系统模型，这部分是考验大家的设计功底。下面列举2种实践中常用的方法，这些方法并非是新的方法，是在日常工作中不断总结、实践出来的，具有更便捷实用性。</p><p></p><p></p><h2>2.1 定义法</h2><p></p><p></p><p>定义法建模的核心思想是通过简洁的一句话描述事物，然后根据定义进行建模，虽然方法听起来很简单，但真正用熟还需要大量的实践。</p><p></p><p></p><h3>2.1.1 命令设计模式建模</h3><p></p><p></p><p>命令模型在23种模式中，相对还有点复杂的模式，有一句话描述命令设计模型：A下达了命令，B接受到命令后按要求执行。将A抽象成命令发起者，B抽象成命令接受者，因此很容易找出有三个对象：命令发起者、命令接收者、命令。接下来就分析这三个对象间的关系：</p><p></p><p>命令发起者与命令的关联：命令是命令发起者发起的，因此命令发起者是要感知到命令的，具体地表现就是命令发起者是要包含命令的。命令接收者与命令的关系：命令接收者是具体执行命令的对象，到底是命令接收者关系命令，还是命令关联命令接收者呢？这个可以看谁变化的可能性比较大，应该用稳定的对象包含易变的对象，根据现实经验，命令相对稳定，而命令接收者是易变的，比如做菜，今天是张三做，明天可能就换成了李四了。命令发起者与命令接收者的关系：它们之间是不会产生直接有关联的，是通过命令进行解耦的，命令发起者定义做什么，命令接收者完成具体的工作。</p><p></p><p>最终命令设计模式的概念模型如下图所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/25/258a25129377fd4bf78019848827b389.jpeg\" /></p><p></p><p></p><h3>2.1.2 导航栏建模</h3><p></p><p></p><p>店铺导航栏平时大家在浏览店铺时常遇见，可以点击不同的导航Tab看到不同的商品，比如新品、爆品等。用一句话描述导航栏：导航栏是由若干个导航Tab组成，点击导航Tab渲染出对应的页面。很容易分析出有两个对象：导航栏、导航栏Tab，但在导航栏Tab中还隐含了另外一个对象：导航栏Tab规格信息，这个规格信息描述了Tab的颜色、排序、跳转链路等信息，因此我们可以很容易画出导航栏的概念模型图。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bc/bc34855cdf97b8e2341c0c927333363e.jpeg\" /></p><p></p><p>很可能有些人觉得这个例子太简单了，如果你按照这种思路分析业务对象，是有别于传统面向过程分析的，比如导航Tab该不该展示是由它自己负责的，并不是在一个大的方法里控制的。</p><p></p><p></p><h2>2.2 因果法</h2><p></p><p></p><p>因果法的本质同事件风暴建模一样的，在用熟的基础上按照自己的习惯进行运用，不管什么方法，只有内化成自己的方法才有用。它的核心是基于一个对象不断往前和往后找因果关联对象，最终构建出完整的业务概念模型。</p><p></p><p></p><h3>2.2.1 Spring容器建模</h3><p></p><p></p><p>Spring IOC容器对大家并不陌生，以这个案例描述因果建模的方法。首先Spring IOC是一个工厂，因此有一个BeanFactory对象，同时它会包含业务Bean对象，因此最简单的一个Spring IOC 概念模型如下图所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/26/26c307f56bedbef4cd37118ea7398259.jpeg\" /></p><p></p><p>接下来就需要不断追溯了，Bean是怎么到Bean工厂中的呢？应该有一个Bean注册器，在上图的基础上，再完善下。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ea/ea6c8a4d093d1e4a87a0b29f4b916aca.jpeg\" /></p><p></p><p>再想这个Bean是怎么来的呢？即哪些业务对象会标识成要放到Bean工厂中的，会有一个扫描器扫描业务对象，发现有标识@Componet、@Service等注解的类需要放到Bean工厂中，因此这里面就会有三个对象：BeanDefinitionReader、BeanDefinition、BeanDefinitionRegistry，迭代后的Spring IOC概念模型如下图所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/68/68eb6affba007d0421c4cd783acfe685.jpeg\" /></p><p></p><p>虽然这是一个简陋的Spring IOC概念模型图，但它还是把Spring IOC核心包含的对象展示出来了，结合现实需求，我们还可以加一些对象进来，比如考虑扩展性，会有BeanFactoryPostProcessor等。这里仅仅是一个业务概念模型，具体到系统模型需要结合设计原则来设计，如Bean工厂在实际中会拆分成多级Bean工厂继承的关系。</p><p></p><p></p><h1>三、建模案例</h1><p></p><p></p><p>根据第二节中讲的方法，下面通过三个技术案例描述在实际学习中的运用，通过模型可以快速让我们理解技术涉及的原理，当我们有了基础理解后，再去看技术框架源码时也会快得多。</p><p></p><p></p><h2>3.1 异步事件建模</h2><p></p><p></p><p>异步事件对于开发来讲并不陌生，将事件定义与事件执行进行解耦，用一句话描述异步事件：事件发布者发布一件事件后，经由事件分发器分发后，找到对应的事件监听器处理。这里面就包含了四个对象：事件发布者、事件分发器、事件监听器、事件。</p><p></p><p>事件发布者是将事件发布到事件分发器上，因此事件发布者是需要关联事件和事件分发器；事件分发器通过事件类型匹配，匹配上事件后调用对应的事件监听器进行处理，因此事件分发器包含了多个事件监听器。异步事件的概念模型图如下图所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f5/f5acc5f0999ffd4a9536647adff1e283.jpeg\" /></p><p></p><p>在Spring事件广播器中，有添加事件监听器，以及通过事件查找到对应的事件监听器进行处理。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e2/e28e44f6d3125e47fda66e3eaf355d24.jpeg\" /></p><p></p><p></p><h2>3.2 切面建模</h2><p></p><p></p><p>切面编程在实际工作中应用得也比较多，比如在服务上增加横切功能，如日志打印、方法耗时统计等，接下来用因果建模法对切面进行建模。最开始有一个目标对象，即为我们要增加横切功能的对象，那么怎么表达这个横切功能呢？至少要包含三种信息：谁需要被增强？；增强的逻辑是什么？；什么时候增强？，描述谁需要被增强的对象抽象成切点。增强的时间节点抽象成通知。因此可得出初步的模型。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5a/5a4bcd370f7f330b22429a19b186e430.jpeg\" /></p><p></p><p>目标对象与切面是怎么关联上来的，相当于在目标对象的方法前后要额外增加一段逻辑，可以通过代理来实现，因此有一个代理对象，它会链接目标对象和切面，最终切面业务概念模型如下图所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/967d4f3d8af641342df604f5f09e6e54.jpeg\" /></p><p></p><p>当熟悉了切面业务概念模型后，再去看Spring AOP的源码会容易些，模型就是简化认识，提炼出核心关键的事物要素。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/79/79ab7a3dce9529b1271170ae60ce05c5.jpeg\" /></p><p></p><p></p><h2>3.3 ORM框架建模</h2><p></p><p></p><p>ORM是将传统SQL映射到对象上，更符合面向对象的习惯。同样我们使用因果建模的方法，ORM框架在底层最终还是要执行具体的SQL，因此将SQL语句抽象成Mapper，数据库配置信息抽象成配置信息，有了这两个配置信息，自然有对应的解析配置的类，初步的模型如下。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/02/025ee43174b93dc861ade9764e667869.jpeg\" /></p><p></p><p>将执行SQL的过程抽象成会话，会话会执行SQL，将执行SQL的对象抽象成SQL执行器，在SQL执行过程中，需要做两件事：一件是参数解析；另一件是结果解析。最终的ORM框架概念模型如下图所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fc/fc8e1a47d6ac26adba636e3a16b96384.jpeg\" /></p><p></p><p>在执行器中，我们可以看到有配置信息、参数信息。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/88/88f8fa61b2a9260c008565d8645ac597.jpeg\" /></p><p></p><p></p><p></p><h1>四、建模经验总结</h1><p></p><p></p><p></p><h2>4.1 能清晰地描述事物建模就成功了一半</h2><p></p><p></p><p>建模是将混沌的事物抽象成有序关联事物的过程，混沌到有序，因此我们需要梳理清楚事物间的关联关系，如果我们都不能够清晰地描述事物，是很难建模的。不能够描述清楚事物，说明我们自己都还没有理清内在的关联关系，也就做不到抽象出有序的模型。</p><p></p><p>在日常工作中，可以尝试用几句描述一件事，看大家能不能理解到。在学校老师经常让我们概括文章的中心思想，就是锻炼这种建模能力，通过几句话把文章的核心内容勾画出来。我们在软件建模也是一样的，通过几句话把业务的涉众、业务结构、业务目标、核心关注点表达出来，然后通过业务概念模型呈现出来。</p><p></p><p></p><h2>4.2 通过描述事物的结构是建模常用的方法</h2><p></p><p></p><p>模型最终呈现出来的是一个图，这个图往往是有清晰的结构，比如房屋模型，它就有自己的结构：坐北朝南，有大厅、睡房、厨房、洗手间等，软件模型也是一样的，在2.1.2节中举了一个店铺导航栏的例子，如下图所示，当我们看到店铺导航栏时，可以想像下它是怎样的结构。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/24/24647ca3b5dc825ad3d535c3ad381757.jpeg\" /></p><p></p><p>在实际的业务中，有两类模型：一类是偏结构型的模型；另一类偏行为型的模型，从个人接触到的业务看，结构型的模型偏多，比如订单有主子订单模型。我们也可以尝试从结构的角度去定义事物。</p><p></p><p></p><h2>4.3 建模要区分知识层和操作层</h2><p></p><p></p><p>模型一般有两层：一层是知识层；另一层是操作层，知识层中包含的概念是通识的概念，往往是面向使用者，比如我们在使用AOP切面编程时，可以用@Aspect、@PonitCut、@Before等注解时，它们就是属于知识层，知识层的内容抽象层次比较高，大家比较容易理解，我们所做的业务运营工作台也是做的知识层的内容，比如配置页面模板、站点配置等，这些可枚举的维度都是知识层。</p><p></p><p>另一层是操作层，操作层是支撑知识层的，还是AOP为例，底层有对注解的解析、动态代理的生成等；再比如Spring IOC中，有各类Bean的注解，在操作层中，有BeanDefinition的加载、识别、解析、Bean实例化、Bean初始化等，操作层中的实现也并非面向过程的设计思维，它也包含了抽象设计和遵循某些设计原则，这一点在下一节中会专门讲到，同样的设计，张三和李四可能不一样，正所谓\"文无第一，武无第二\"，大家的设计理念、角度不一样，技术设计本应如此，就像一百个厨师做同样的菜，做出来的菜也有一百个样。</p><p></p><p>如果知识层偏表达，那么操作层就是偏实现支撑，这两类的视角也是不一样的，知识层更抽象，而往往我们开发人员更关心的是操作层中的具体实现类，缺乏抽象意识，这也是我们自己心中非常清楚，但别人很难理解，需要转换视角，思考通识的知识层有什么。</p><p></p><p></p><h1>五、小结</h1><p></p><p></p><p>在文章中主要讲述了建模的一些方法，方法虽然简单，但用熟还是需要大量的实践经验，建模分为两个阶段：第一个阶段是业务概念建模，它无关于技术，是通识的建模（知识层）；第二个阶段是系统建模，基于业务概念建模的基础上，考虑具体的技术实现（操作层），遵循某些设计原则构建可落地的模型。</p><p></p><p>建模的确会简化对复杂事物的认识，以学习技术框架为例，如果一头扎进源码中，很难有全局观，相反如果我们从全局对技术框架有一定的理解，再去看源码也会快很多。</p><p></p><p>推荐阅读</p><p><a href=\"https://xie.infoq.cn/article/6e3c70d130a5769720178c79c\">面向对象分析与设计的底层逻辑</a>\"</p><p></p>",
    "publish_time": "2023-03-23 11:29:27",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "集成GPT-4的编程神器来了，GitHub发布Copilot X：编程30年，突然就不需要手敲代码了？！",
    "url": "https://www.infoq.cn/article/ZRjMrDXcL4XPskS7CgzJ",
    "summary": "<p></p><blockquote>畅想十多年后，失去了“AI助手”的年轻人无法编码了，那企业只能再高薪聘请真正会编程的白发老年人回来了.....</blockquote><p></p><p>&nbsp;</p><p>在GPT-4模型的支持下，微软打造的AI“结对编程助手”已经能够标记pull请求、生成模仿文档和讨论代码内容。GitHub 还添加了 OpenAI 的聊天功能，这也就是说 Copilot X 将允许程序员以ChatGPT的风格，通过语音聊天来编写和调试代码。</p><p>&nbsp;</p><p></p><h2>GPT-4 驱动的新 Copilot 编码助手</h2><p></p><p>经过新一轮训练，微软GitHub的Copilot编程模型再度升级，也让这位广受好评的AI助手在开发领域的地位又稳牢了一层。</p><p>&nbsp;</p><p>为了纪念这一重大时刻，微软还给这位编程助手改了名：Copilot X。请注意，X代表可能性、可不是“限制级”。</p><p>&nbsp;</p><p>GitHub CEO Thomas Dohmke在博文中写道，“我们的GitHub Next研发团队一直在努力超越传统编辑器，希望将GitHub Copilot开发成贯穿整个开发生命周期、而且易于使用的AI助手。最终成果就是GitHub Copilot X，代表着我们对于未来AI软件开发愿景的希冀。”“它将从根本上影响开发人员的体验。”</p><p>&nbsp;</p><p>但在随后的介绍中，Dohmke自己仍然称这款软件为Copilot，不禁让人怀疑是不是X这部分还要等待些时日才能真正名副其实。</p><p>&nbsp;</p><p>展望未来，Copilot将对接一系列不断发展的大语言模型，包括OpenAI的GPT-3.5-turbo和GPT-4，而不再沿用OpenAI Codex的定制化版本。OpenAI将于2023年3月23日关闭Codex的公共API，但强调Codex的停用不会对客户造成影响。有声音怀疑此次API终止跟Codex和Copilot身陷版权和许可<a href=\"https://www.infoq.cn/article/509czSmTf7Qrv2TocrAu\">诉讼有关</a>\"，但OpenAI并未立即做出置评。</p><p>&nbsp;</p><p>在经过一年的技术试验之后，Copilot于去年夏季正式推出，能够为使用GitHub及受支持文本编辑器/IDE（例如Visual Studio Code）的开发人员提供编码建议。尽管质量不够稳定，但仍开创了生成式AI服务编程领域的先河。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cf/cfee6e38604d045437a908cb1fc647e6.png\" /></p><p></p><p>&nbsp;</p><p>根据GitHub的数据，截至上个月，Copilot已参与到微软全体云代码仓库中的46%，帮助开发人员将编程速度提高了55%。</p><p>&nbsp;</p><p></p><h2>Copilot升级版可以用来做什么</h2><p></p><p>&nbsp;</p><p>Copilot升级之后，现在它能在Visual Studio Code和Visual Studio中以ChatGPT的风格与用户交流。提示和响应对话显示在IDE侧边栏的聊天窗口内，不再像之前那样在源文件中依靠评论查询提供自动补全建议。</p><p>&nbsp;</p><p>Dohmke表示，“Copilot Chat不只是提供一个聊天窗口，它可以识别开发人员输入的代码、显示的错误消息，并深深嵌入至IDE当中。”</p><p>&nbsp;</p><p>它集成了<a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651146688&amp;idx=1&amp;sn=b09cfbfaa7ccd5de558058ed5d90ad4b&amp;chksm=bdb8b1938acf3885fc8ca0bcdfb2b58c3d8fc6d6e2c7cee19aadef618fcb81fc9444cf8f1a62&amp;scene=27#wechat_redirect\">“嘿，GitHub”</a>\"语音扩展功能（也就是现在的GitHub Copilot Voice），使用自然语音提示，这位编程助手可以生成（或复制）代码并按需运行。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/49/49f698548a2b8a0241e4510e166d892c.jpeg\" /></p><p></p><p>&nbsp;</p><p>Dohmke表示，“Copilot Chat的技术基础，跟OpenAI和微软的ChatGPT与New Bing是完全相同的”。并且Dohmke <a href=\"https://developers.slashdot.org/story/23/03/22/1443211/microsofts-github-to-add-openai-chat-functions-to-coding-tool?ref=upstract.com\">还展示了通过聊天</a>\"来编写 Python 版本的贪吃蛇游戏，并表示非常沉迷其中。</p><p>&nbsp;</p><p>这种功能也震撼到了一些开发者：“ChatGPT 将永远改变编程。对我来说，作为一名开发人员最令人愉快的方面是处理逻辑和解决技术问题，而不是专注于生产力或满足需求。虽然这种改变让我沮丧，但我知道我需要习惯它。”“我也是。迄今为止，我手写代码已经 30 年了，我仍然热爱编程。但如果从此没有手写编码，我不确定世界会是什么样子。”......</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/17/1780f7568d316026aa4c32d5b09791d6.png\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>另外，开发人员可以高亮显示源文件中的正则表达式，并邀请Copilot解释表达式中的迟钝模式。Copilot还可根据要求生成测试、分析和调试，提出修复建议或尝试自定义任务。该模型甚至能够为源代码添加解释性注释，并像linter那样清理文件。</p><p>&nbsp;</p><p>对于这部分功能，有网友表示他从测试版开始就一直在使用Copilot，它在生成测试方面可以说是“大放异彩”，“感觉像是重复各种繁琐的事情，测试各种各样的输入，测试各种各样的错误案例，与手工相比，它花费的时间要少得多。”</p><p>&nbsp;</p><p>另一位名为“roygbivasaur”的网友则表示，他现在的工作是编写 kubernetes 控制器并使用 envtest 和 ginkgo为控制器编写测试。令人沮丧是他必须执行通常由默认 kubernetes 控制器完成的所有任务（例如为 sts 创建 pod）。但使用了 Copilot，编写了几个测试之后，“现在当我编写新测试时，它可以从上下文（测试用例、测试描述、CRD 类型、我显然正在测试的协调器等）中推断出什么我需要创建的对象，我需要监视的状态，甚至可能的特定故障状态。它完成了我大部分的测试，我只需要校对它。”</p><p>&nbsp;</p><p>简而言之，使用Copilot来做一些测试用例还是非常能提高效率的。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d6/d6783178b5c131800004c0da42a40616.png\" /></p><p></p><p>Copilot处理pull请求的截屏</p><p>&nbsp;</p><p>无论如何，GitHub已经在开放预览版中引入了GPT-4支持，现在AI已经能为所有pull请求（代码变更提交）生成描述。</p><p>&nbsp;</p><p>在AI的监控下，开发人员在发出pull请求时将看到GitHub模型帮你填写标签，尝试描述接下来可能发生的情况。开发人员则可根据标签进行操作或修改。</p><p>&nbsp;</p><p>更重要的是，Copilot的应用范围还扩展到了文档层面。从React、Azure Docs和MDN文档开始，开发人员可以通过聊天界面提出问题并获取AI生成的答案。Dohmke介绍称，通过聊天界面与文档交互的能力将很快被扩展至组织用户的内部代码仓库和文档当中。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e6/e6aca44272525592fd176d345ffe78f6.png\" /></p><p></p><p>Copilot CLI截屏</p><p>因此，开发人员将可以提出不那么结构化的问题，并直接从Copilot那边获得合理建议甚至是非常准确的答案（但不提供来源属性）。这就取代了以往基于关键字的文档内容查询，也让我们更能理解为什么谷歌被这位突如其来的AI红人打得措手不及。</p><p>&nbsp;</p><p>GitHub甚至提供Copilot CLI以渗透命令行界面。如果大家突然忘记了某条晦涩的命令行咒语或者命令标志，Copilot可以立刻提供帮助。</p><p>&nbsp;</p><p></p><h2>写在最后</h2><p></p><p>&nbsp;</p><p>至于这位强大编程助手的存在到底是不是好事，就看各位如何理解了。Dohmke 强调说 Copilot 可以在开发过程的每个阶段发挥重要作用，从项目规划到代码的最终部署，然而鉴于Bing在GPT-4支持下的表现“也就那样”，New Bing似乎也不如Dohmke设想中的那么“New”，所以还需要时间来证明Copilot的能力。但在相对更简单的代码生成场景下，GPT-4也许能够更轻松地提供有用输出。</p><p>&nbsp;</p><p>Copilot 将马上提供给waiting list中的开发人员注册使用，Dohmke 说，在第一波产品准入之后，更多的开发人员将获得访问权限，具体取决于需求水平。&nbsp;</p><p>&nbsp;</p><p>Copilot 的个人费用为每月 10 美元，企业费用为每位开发人员每月 19 美元。</p><p>&nbsp;</p><p>鉴于有整整一代开发人员需要支付 1000-2000 美元或更多来订阅 MSDN以开展业务，Copilot 这个定价也许不算太高。考虑以后很大可能“AI编程助手”是开发人员不可或缺的编程工具，那集成了GPT-4的“Copilot X”对微软来说其战略重大，这场AI战争也许是继Windows操作系统、Azure云服务之后的一大终局之战。</p><p>&nbsp;</p><p>附申请网址：</p><p>Copilot X: <a href=\"https://github.com/github-copilot/chat_waitlist_signup/\">https://github.com/github-copilot/chat_waitlist_signup/</a>\"</p><p>Copilot Voice: <a href=\"https://githubnext.com/projects/copilot-voice/\">https://githubnext.com/projects/copilot-voice/</a>\"</p><p>Copilot Docs: <a href=\"https://githubnext.com/projects/copilot-for-docs/\">https://githubnext.com/projects/copilot-for-docs/</a>\"</p><p>Copilot for PRs: <a href=\"https://githubnext.com/projects/copilot-for-pull-requests/\">https://githubnext.com/projects/copilot-for-pull-requests/</a>\"</p><p>Copilot CLI: <a href=\"https://githubnext.com/projects/copilot-cli/\">https://githubnext.com/projects/copilot-cli/</a>\"</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://github.blog/2023-03-22-github-copilot-x-the-ai-powered-developer-experience/\">https://github.blog/2023-03-22-github-copilot-x-the-ai-powered-developer-experience/</a>\"</p><p><a href=\"https://www.theregister.com/2023/03/22/github_copilot_learns_new_tricks/\">https://www.theregister.com/2023/03/22/github_copilot_learns_new_tricks/</a>\"</p><p><a href=\"https://www.reddit.com/r/programming/comments/11ylui4/github_copilot_x_the_aipowered_developer/\">https://www.reddit.com/r/programming/comments/11ylui4/github_copilot_x_the_aipowered_developer/</a>\"</p>",
    "publish_time": "2023-03-23 15:04:20",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "这家芯片大厂裁掉了整个中国研发团队，一个都不留！赔偿N+3",
    "url": "https://www.infoq.cn/article/9hO17DCi2TFoiPvBEkvY",
    "summary": "<p>近日，据业内爆料显示，美国芯片设计厂商Marvell继去年10月宣布裁撤大部分中国研发团队之后，近日已决定将剩余的中国研发团队全部裁撤掉。消息称，虽然目前Marvell官方尚未宣布裁员消息，但是Marvell中国的员工基本都已经收到了通知。</p><p></p><h2>Marvell裁掉整个中国研发团队，赔偿N+3</h2><p></p><p>&nbsp;</p><p>Marvell 成立于1995 年，总部位于硅谷，在中国上海、南京、成都和北京均设有研发中心，是一家提供全套宽带通信和存储解决方案的全球领先半导体厂商，针对高速、高密度数字资料存贮和宽频数字数据网络市场，从事混合信号和数字信号处理集成电路设计、开发和供货的厂商。</p><p>&nbsp;</p><p><a href=\"https://www.marvell.com/\">Marvell</a>\"本周三发表声明，称该公司将裁员约320人，占全球员工总数的4%，目的是应对所谓的行业放缓。</p><p>&nbsp;</p><p>Marvell集团营销副总裁Stacey Keegan在声明中表示，“我们正在推动组织精简，以确保我们的员工能把握住当下乃至摆脱下行周期之后最具前景的业务机遇，”</p><p>&nbsp;</p><p>虽然中国对Marvell而言仍是一个庞大且重要的市场，但Keegan表示公司决定“将我们在中国的资源集中在客户服务团队上，从而更好地支持我们的本地客户和商业机遇。”但她也承认，此次的确“裁撤了一些研发岗位”。</p><p>&nbsp;</p><p>据中国半导体行业门户爱集微报道，Marvell的此次<a href=\"https://www.infoq.cn/article/To4fdiQ4QLqBP9a6f9By\">裁员</a>\"将直接影响到该公司在中国大陆的整个研发业务。而根据知悉内情的消息人士称，美国方面的研发裁员比例仅约5%。</p><p>&nbsp;</p><p>爱集微指出，预计Marvell会立即通知受影响的中国员工，并开出与去年10月裁员期间数额相当的遣散费，也就是“N+3”的赔偿方案。</p><p>&nbsp;</p><p>这不是Marvell在中国第一次裁员。事实上，早在五个月前，Marvel就已经开始在中国这个全球最大芯片市场上削减员工规模。</p><p>&nbsp;</p><p>去年10月，<a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=400600098&amp;idx=2&amp;sn=c4dabd75e45d14eab367a72bf2f51797&amp;chksm=345d5471032add677a1e10a6095eae2e99babeca3e3201628d472d54bb4d4fb40f92927aaeea&amp;scene=27#wechat_redirect\">Marvell</a>\"对上海和四川成都办事处的多个部门着手裁撤，要么规模大减、要么彻底遣散。</p><p>&nbsp;</p><p>当时Marvell 企业营销副总裁 Stacey Keegan 在书面回复记者问时表示，“在中国，我们将把<a href=\"https://www.infoq.cn/video/D8GbeKQ6obVYqqKvNBT2\">研发</a>\"投资重点放在本地客户和中国市场上，作为调整的一部分，我们的几个业务部门和职能部门正在宣布改变他们的全球定位战略，这将导致取消在中国的职位，”。</p><p>&nbsp;</p><p>在去年10月份裁员之前，Marvell公司巅峰期在中国拥有近1000名员工。其中约800人在上海工作，这里也驻扎着Marvell的全球第三大研发团队，主要负责支持公司在美国和以色列的业务。</p><p></p><h2>半导体巨头们的日子也不好过</h2><p></p><p>&nbsp;</p><p>随着5G、AI、物联网等行业的快速发展，<a href=\"https://www.infoq.cn/article/IIrxAaTj0zL0vmWeDqMl\">全球半导体产业</a>\"面临巨大的先进制程产能的扩张需求，这为半导体设备行业带来了巨大的市场空间。</p><p></p><p>然而，本该持续繁荣发展的先进半导体设备厂商，最近几年的日子也并不好过。</p><p>&nbsp;</p><p>根据SEMI数据显示，2023年全球半导体设备市场规模将年减16%至912亿美元，中国大陆、中国台湾、韩国分居前三。其中，晶圆厂设备市场将年减17%至788.4亿美元，封装设备市场年减13%至52.9亿美元，测试设备市场年减7%至70.7亿美元。而在前段设备部分，逻辑制程设备市场将较2022年减少9%，DRAM设备市场将大幅减少25%至108亿美元，NAND Flash设备市场亦将下滑36%至122亿美元。</p><p>&nbsp;</p><p>Marvell最新一轮裁员，反映了全球主要半导体企业因全球市场供需严重失衡、芯片库存提升至创纪录水平等现实因素而承受的巨大压力。</p><p>&nbsp;</p><p>此外，有分析人士指出，半导体巨头们日子不好过的另外一个原因是美国商务部工业与安全局去年10月发布的针对中国先进计算、半导体制造和超级计算机领域的出口管制，很大程度上影响了国外半导体设备巨头在中国大陆的业绩，也将影响了其在全球市场份额。</p><p>&nbsp;</p><p>软银集团旗下<a href=\"https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247574757&amp;idx=1&amp;sn=b1c1e9222c512aca8d4d65ac15bf4043&amp;chksm=fbeb1d2acc9c943c22b1536d75941c333ef8a5165eaa0039d13a7597b633a59b56f1ab78a435&amp;scene=27#wechat_redirect\">Arm</a>\"在大陆的合资企业Arm China上月也在三部门内裁员100多人，似乎是在对2022年利润暴跌96%的现状做出回应。</p><p>&nbsp;</p><p>与此同时，美国存储芯片巨头美光科技去年年底也关闭了其位于上海的DRAM设计业务。受中美之间紧张局势的影响，约150名中国工程师被要求调往美国或印度继续工作。</p><p>&nbsp;</p><p>Marvell公司专为云计算、汽车、5G移动通信和企业网络应用设计先进芯片。该公司本月初报告称，得益于各领域的业务增长，在截至今年1月28日的上一财年，公司总收入达到创纪录的59.2亿美元、同比增长33%。但这里“同比”的意义恐怕不大，毕竟Marvell上财年出现了1.64亿美元的净亏损。</p><p>&nbsp;</p><p>据悉，美国三大半导体设备大厂应用材料、泛林集团、科磊自去年10月以来，正纷纷将非中国籍的员工转移到新加坡及马来西亚，或是设法在东南亚增加产能。</p><p></p><h2>出口管制新规，伤人也伤己</h2><p></p><p>&nbsp;</p><p>2022年10月7日，美国商务部工业安全局（BIS）发布半导体<a href=\"https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247517662&amp;idx=1&amp;sn=373819003309f3d08375ae7a94067ff7&amp;chksm=fbea3c11cc9db507be08d18850c902534eb74a34e3f5d302ec27d39c8c9a9ad0d6f1bc0ead28&amp;scene=27#wechat_redirect\">出口管制新规</a>\"，对先进芯片、软件以及用于生产先进芯片的各种半导体制造设备的对华出口提出了前所未有的许可限制。</p><p>&nbsp;</p><p>在国外企业受到美国出口管控掣肘的同时，该项管制措施对美国自身的经济和技术发展也产生了重大影响。据分析人士指出，该出口管制措施在少数特定的情况下是必要的，但是一些限制性的措施可能会严重阻碍美国先进技术产业的竞争力，并限制它们的产出、出口和阻碍就业增长。</p><p>&nbsp;</p><p>中国是众多美国半导体企业的最大市场，新规出台后，不少美半导体巨头大幅下调了营收目标。应用材料公司披露，新规对其2023年营收的影响或达到15亿~25亿美元。泛林集团认为，受新规影响，其2023年营收或将减少20亿~25亿美元。科磊则预测，由于无法向部分中国客户提供支持，其2023年营收将减少6亿~9亿美元。</p><p>&nbsp;</p><p>实施出口管制必然会在短期内损害美国国内企业，降低企业的销售额，进而降低其将利润再投资于研发方面的能力。另一方面，对于那些不完全依赖于美国，可以从其他国家获得的技术实施出口管制，并没有显著地减缓潜在对手对这些技术的采用，而只是将这些收入从美国公司手中转移到了国外竞争对手手中，反而阻碍了美国的竞争力。</p><p>&nbsp;</p><p>参考链接：</p><p></p><p><a href=\"https://www.scmp.com/tech/tech-war/article/3197487/american-chip-firm-marvell-eliminates-job-roles-china-amid-deepening-tech-rivalry\">https://www.scmp.com/tech/tech-war/article/3197487/american-chip-firm-marvell-eliminates-job-roles-china-amid-deepening-tech-rivalry</a>\"</p>",
    "publish_time": "2023-03-23 15:04:22",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "采用 Backstage 作为开发者门户",
    "url": "https://www.infoq.cn/article/7ykcq0CtQYzEOQdBzBML",
    "summary": "<p></p><blockquote>导读：Wise（前身为 TransferWise）是一家成立于 2011 年的英国金融科技公司，总部位于伦敦。Wise 提供跨境转账服务，目的是降低跨境汇款的成本和时间。Wise 于 2021 年 7 月在伦敦证券交易所上市，成为英国最大的科技公司之一。本文将向你介绍 Wise 如何使用 Backstage 构建开发者门户网站。在本文中，你将了解到 Wise 如何通过用户体验调查和假设验证来认识需求、确定 Alpha 版本的范围以及验证结果。Wise 成功地构建了一个适合其工程师快速、安全地交付产品的开发者门户网站，并在此过程中获得了宝贵的经验和教训。如果你对构建开发者门户网站感兴趣或想了解 Wise 的工程体验团队如何实现这一目标，请继续阅读本文！</blockquote><p></p><p>&nbsp;</p><p>总部位于英国的 <a href=\"https://wise.com/\">Wise</a>\"（前身为 TransferWise），通过 Wise 账户，让用户可以在超过 50 种不同货币中发送、花费、接收和持有资金。该公司以完全透明的费用、国际账户和路由号码、与 Apple 和 Google Pay 兼容以及承诺始终使用中间市场汇率（没有隐藏费用）来区别于其他公司。换句话说，公司的“无国界金融”使命需要一个强大的生态系统和人类工程技术。</p><p>&nbsp;</p><p>而让一切井然有序的秘密是高效的工程组织和<a href=\"https://internaldeveloperplatform.org/\">内部开发者平台</a>\"。作为其中的一部分，Wise 在 Backstage 之上构建了一个<a href=\"https://internaldeveloperplatform.org/developer-portals/\">开发者门户</a>\"网站，高级技术产品经理 <a href=\"https://www.linkedin.com/in/lambros-charissis/?originalSubdomain=uk\">Lambros Charissis</a>\" 正好深入其中。</p><p>&nbsp;</p><p>在最近的一个网络研讨会上，Lambros 解释了工程体验团队在构建开发者门户网站方面的经历。他揭示了他和他的同事如何使用产品管理技术来实现三个关键目标：认识需求、确定 Alpha 版本的范围以及验证结果。如果你无法<a href=\"https://www.youtube.com/watch?v=ljBvO-WDRhw\">观看完整的网络研讨会</a>\"，下面是他所涵盖的内容。</p><p>&nbsp;</p><p></p><h2>第一部分：认识需求</h2><p></p><p>&nbsp;</p><p>了解你所面临的值得解决的问题对于采取关键的下一步至关重要。那么 Wise 是如何认识到可能需要构建开发者门户网站的呢？</p><p>&nbsp;</p><p>正如 Lambros 所说，线索不少。首先，Wise 拥有数百万客户和数千名员工。专门的平台工程组织和技术产品经理负责确保 Wise 的工程师可以快速、安全地交付产品。</p><p>&nbsp;</p><p>Wise 的工程体验团队聚焦于问题。在对组织的<a href=\"https://humanitec.com/blog/developer-experience\">开发者体验</a>\"进行半年调查后，团队发现了一个趋势。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e9/e975c34c0782df64cf838e6c08e34b40.jpeg\" /></p><p></p><p>&nbsp;</p><p>Wise 的员工在三个关键领域给公司评分很低：文档、可发现性和认知负荷。工程师们也报告了很多挫败感，所以产品经理知道他们有工作要做。</p><p>&nbsp;</p><p>Lambros 表示，下一步涉及确定问题的真正边界：明确定义问题是什么，影响了谁以及为什么值得解决。</p><p>&nbsp;</p><p></p><h3>通过用户研究了解工程摩擦</h3><p></p><p>&nbsp;</p><p>工程团队从一种经过验证的方法开始寻找答案：与最懂情况的人——用户互动。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a2/a2b9be7d28ff03a7edf8e7efdca23155.jpeg\" /></p><p></p><p>&nbsp;</p><p>Wise 在工程组织中进行了采访，征求了不同资历和专业的工程师的反馈，包括平台和产品方面。</p><p>&nbsp;</p><p>面试官针对用户的角色和工作职责等不同问题进行了不同的提问。他们深入探讨了典型用户旅程，以了解人们如何使用现有的工具实现工作目标。受访者还分享了他们对工作流程的看法，以及哪些方面存在低效率的问题，为更全面地描绘大局添加了一层上下文。</p><p>&nbsp;</p><p>这种探索性过程具有明确的结构。Lambros 描述了 Wise 总是让面试官组成三人团队：主要的面试官让谈话顺畅进行，旅程规划师提出与用户旅程相关的问题，笔记员捕捉到其他两个人错过的任何微妙之处。</p><p>&nbsp;</p><p>团队进行面试有多重益处。除了确保每个人都能专注于自己的角色外，这种结构还让更多的利益相关者直接参与其中。<a href=\"https://humanitec.com/platform-engineering#what-does-a-platform-engineer-do\">平台工程师</a>\"和最终构建门户网站的其他人可以加入面试，直接与用户交流，为他们的问题建立共情。</p><p>&nbsp;</p><p>关注用户旅程让 Wise 能够绘制出不同的价值流。例如，团队探讨了哪些服务涉及特定任务、工程师通常遵循的常见路径以及可能带来有价值的变化。</p><p>&nbsp;</p><p>通过探索旅程并将其分为不同阶段，Wise 根据任务所增加的价值将常见任务进行分类，形成自然的问题解决优先级。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/31/31cc428a49b6571b6cb44db9b27027e6.jpeg\" /></p><p></p><p>&nbsp;</p><p>Lambros 表示，Wise 利用这种方法探索了多个用户角色和用户旅程，生成了大约十个不同领域的<a href=\"https://visible.is/#value-stream-mapping\">价值流图</a>\"。这样做以具体的频率术语重新定义了问题，阐明了为什么需要解决这个问题。</p><p>&nbsp;</p><p>Wise 现有的方法导致开发者每个月需要参加两次可避免的会议，并每周浪费两个小时的时间。服务生态系统的低效性还使得入职流程延迟了约两天。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/db/db5796247498c2c17e7d8d5805551ff7.jpeg\" /></p><p></p><p>&nbsp;</p><p></p><h2>第二部分：第一个版本</h2><p></p><p>&nbsp;</p><p>Wise 已经确定了该问题需要解决，但并不总是知道开发者门户网站是否是最佳解决方案。例如，公司可以尝试改进其现有工具。</p><p>&nbsp;</p><p>Wise 通过从价值流地图中建立价值主张画布，按优先级列出用户旅程中的问题，使决策变得更简单。然后，团队根据每个潜在解决方案解决每个用户旅程问题的程度进行评级，以便更容易根据其整体适用性对选项进行排名。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2c/2c37b01408aaa623514c29c883fb63c7.jpeg\" /></p><p></p><p>&nbsp;</p><p>如果你已经看到这里，你应该不会惊讶 Wise 选择了一个开发者门户网站作为解决方案。Lambros 和他的同事们发现，一切都表明这是解决用户旅程问题的最佳价值主张。这也是一个适当的全面文档和发现方法，解决了降低认知负荷的目标——这是最初的用户体验调查中发现的三个主要问题。</p><p>&nbsp;</p><p></p><h3>建立 Alpha 版本的开发者门户网站</h3><p></p><p>&nbsp;</p><p>Wise 选择了 Backstage 作为开发者门户网站 Alpha 版本的基础。它似乎满足了所有重要的条件，例如补充了公司的技能，拥有强大的社区，是一个 <a href=\"https://www.cncf.io/blog/2022/03/15/backstage-project-joins-the-cncf-incubator/\">CNCF 孵化项目</a>\"，包括一个健康的生态系统，并且可以自定义。</p><p>&nbsp;</p><p>接下来，团队需要定义 Alpha 项目的预期范围。整个目标是获得早期反馈并了解他们是否走在正确的轨道上。这意味着新门户网站需要超出仅仅功能的范畴：它还必须告诉 Wise 关于它的可行性和成本效益。</p><p>&nbsp;</p><p>Alpha 版本还必须保持足够小，以便管理，但又足够大，可以验证。换句话说，实验需要保持可管理，但仍需要足够的样本量进行分析和审查。</p><p>&nbsp;</p><p>这不是一项容易的任务。Lambros 说：“这很难做出权衡，但我认为定义假设有助于解决问题。”</p><p>&nbsp;</p><p>从他们的价值流地图、用户个人资料和用户旅程出发，Wise 团队确定了一些假设。例如，它假设该门户网站可以：</p><p>&nbsp;</p><p>加速开发者入职流程，缩短寻找帮助的时间，提高工具和最佳实践的发现能力。</p><p>&nbsp;</p><p>自然而然地，工程师们也设定了一个目标。他们希望在全力推进新的开发者门户网站之前验证他们的五个假设。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c8/c81b66076cc1f169ec30e4192356ec10.jpeg\" /></p><p></p><p>&nbsp;</p><p>明确目标假设使平台团队了解了应该在 alpha 版本中包含什么 - 将这些猜测与价值主张画布和其影响排名的用户旅程相结合，有助于他们确定需要解决的有用细节。 在这种情况下，工程师们专注于三个功能：</p><p>&nbsp;</p><p>增强工程实践、工具和新闻的可发现性，创建一个<a href=\"https://humanitec.com/blog/service-catalogs-and-internal-developer-platforms\">软件目录</a>\"，澄清如何使用服务并找到它们的所有者，并且使用搜索工具和友好的呈现页面，更容易使用文档。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cf/cf30b8211f8c08bee030512770515f69.jpeg\" /></p><p></p><p>&nbsp;</p><p>使用 Backstage 简化了确定符合要求的、具备工作 GUI 功能的 alpha 门户网站的过程。团队遵循了一种方法论的架构策略，包括：</p><p>&nbsp;</p><p>避免方案偏见，根据客观特点平等评估每个选项，使用线框图来创建对齐并在处理不同元素时让每个人都能理解，决定是建立一个可以在初步测试后放弃的一次性 Alpha，还是一个可以在验证后持续改进的渐进式 Alpha。Wise 选择了后者，原因稍后解释。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3b/3ba4df7ebab7cb071b25c5db0e004c4a.jpeg\" /></p><p></p><p>&nbsp;</p><p></p><h2>第三部分：验证解决方案</h2><p></p><p>&nbsp;</p><p>仅仅假设新的开发者门户网站能够解决问题是不够的。Wise 需要验证这个假设，通过确认假设来证明门户网站确实解决了问题。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/50/506ed4626c9364bec81d5ac22cd96cf7.jpeg\" /></p><p></p><p>&nbsp;</p><p>为了验证假设是否成立，Lambros 和他的团队选择了另一批用户进行调查。在这种情况下，他们选择了 20 名不同资深级别的工程师，并将他们分成两组：一组使用 alpha 版，另一组使用现有的工具。</p><p>&nbsp;</p><p>这种实验设计使数据收集变得简单。团队负责人可以通过测量每组完成不同任务所需的时间来量化 alpha 版的有用性。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3c/3ca303d843b53d228e03d6a9bea5c4c0.jpeg\" /></p><p></p><p>&nbsp;</p><p>团队还收集了后续调查问卷。在让大约 40 人试用了一周后，项目负责人询问这些测试者认为开发者门户网站在实现假设方面表现如何。</p><p>&nbsp;</p><p>这种有组织的评估是判断工作是否真实有效的一种有见地的方式，结果显示这个 alpha 版本只验证了五个目标假设中的四个。结果也突出了最初的解决方案在某些方面存在问题，如文档质量和搜索用户体验。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2a/2a97e84c64a25f8b10f5f746f85f1b4c.jpeg\" /></p><p></p><p>&nbsp;</p><p>Lambros 对验证过程的最大收获相当直接——但仍然富有启示性：</p><p>&nbsp;</p><p>假设的方法使得更容易关注和界定初始版本。通过保持测试目标的一定程度的分离，可以避免用户测试偏差，保持过程的客观性。测试本身并不足以验证：用户调查同样具有说明性。</p><p>&nbsp;</p><p></p><h2>下一步是什么？</h2><p></p><p>&nbsp;</p><p>有趣的是，没有达到假设验证目标并没有使 alpha 版本的门户网站完全失败。</p><p>&nbsp;</p><p>由于团队选择了增量方法，他们在组装 beta 版本时已经有了一个良好的起点；产品经理们知道该集中精力使门户网站更有用。这种认识激励了 Wise 的工程师实现改进，比如添加质量分数和文档评级工具。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/06/06dcd97fb89a8b27b51575e29132d75c.jpeg\" /></p><p></p><p>&nbsp;</p><p>Lambros 的故事证明了精心设计的迭代方法在构建平台、门户和其他关键工程工具方面的价值。以有组织的方式构建这些组件可以将大问题分解并为重要问题提供解决方案。考虑到现代软件开发实践和工具链的复杂性，这是一个深刻的教训。</p><p>&nbsp;</p><p>但这只是开始——在一个有趣的问答环节中，这次演讲还分享了许多其他见解，所以为什么不看完<a href=\"https://www.youtube.com/watch?v=ljBvO-WDRhw\">整个会议</a>\"呢？</p><p>&nbsp;</p><p>作者简介：</p><p>&nbsp;</p><p>Lambros Charissis，Wise 高级技术产品经理。</p><p>&nbsp;</p><p>原文链接：</p><p>&nbsp;</p><p>https://platformengineering.org/talks-library/adopting-backstage-as-developer-portal</p>",
    "publish_time": "2023-03-23 15:19:12",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "深入理解BizDevOps，推进业务研发组织的数字化变革 ｜ BizDevOps 公开课",
    "url": "https://www.infoq.cn/article/KyeYYm9Zxro2SasFeBxb",
    "summary": "<p><strong>内容简介：</strong><br />\nBizDevOps最新权威解读课程，由BizDevOps共促计划专家团成员共同创作，包括《必致（BizDevOps）白皮书》解读共 10 讲，阿里巴巴、招商银行、Thoughtworks等企业真实实践案例分享，以及需求管理、组织设计、组织数字化升级、数据运营和工具等设计专题精讲。<br />\n白皮书下载链接：<a href=\"https://www.infoq.cn/minibook/lsB8GB2BbvLQj2u5mBKo\">https://www.infoq.cn/minibook/lsB8GB2BbvLQj2u5mBKo</a></p>\n<p><strong>你将理解：</strong></p>\n<ol>\n<li>如何应用BizDevOps，为数字化的业务打造数字化的组织</li>\n<li>理解BizDevOps的1个目标，3个能力和5个实践</li>\n<li>BizDevOps与DevOps的根本不同，以及如何实现从DevOps向BizDevOps的蝶变</li>\n<li>你将掌握BizDevOps的1-3-5框架，掌握驾驭数字化变革的力量</li>\n</ol>\n<p><strong>面向受众：</strong><br />\n数字化转型从业者和关注者，包括研发管理者、数字业务和数字化转型负责人、业务分析师等、研发工具负责人</p>\n<p><strong>发布计划：</strong><br />\n3.23日起，每周四下午16:00，准时开播。</p>\n<p><strong>本系列视频内容规划：</strong></p>\n<ol>\n<li>BizDevOps(必致)是什么，如何实施？ 整体框架</li>\n<li>产品导向的团队组织和交付 （实践一） 协作和管理实践</li>\n<li>业务驱动的组织协同机制 （实践二）</li>\n<li>数字业务的动态投资组合管理 （落地和案例）</li>\n<li>应用为核心的研发资产和流程管理（实践三） “工程和技术实践”</li>\n<li>适配业务特征的持续业务交付 （实践四）</li>\n<li>建设和改进持续业务交付能力 （落地和案例）</li>\n<li>全量、全要素和实时数据支持的度量和持续改进（实践五） 度量和持续改进实践</li>\n<li>度量和持续改进体系的设计和应用（落地和案例）</li>\n<li>BizDevOps（必致）：驾驭数字化变革的力量 总结</li>\n</ol>",
    "publish_time": "2023-03-23 16:04:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "英特尔首席架构师 Raja Koduri离职：曾被苹果和AMD抢来抢去，现自己创业投身AIGC",
    "url": "https://www.infoq.cn/article/RrLLa1eVfArsICTtCVEv",
    "summary": "<p>当地时间3月22日，据路透社报道，<a href=\"https://www.infoq.cn/article/07JFquThmH4DbC9iMqIx\">英特尔CEO基辛格</a>\"在推特上宣布了其首席架构师 Raja Koduri离职的消息。</p><p>&nbsp;</p><p>据透露，Raja Koduri计划创办一家新的AI公司，旨在削弱长期竞争对手英伟达在数字电影和视频游戏市场的主导地位。</p><p>&nbsp;</p><p>Koduri表示，新创办的芯片公司还没有命名，他准备开发目前处于热潮中的生成式AI软件工具，这些创意工具可以配合英特尔、苹果、<a href=\"https://www.infoq.cn/article/CGIHCT5bYLrIZ734xVZ5\">AMD</a>\"公司的处理器一起使用，他还准备将来支持根据开放源码RISC-V技术开发的处理器。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/bf/bf25b304b25081a6652de986ec574f6f.png\" /></p><p></p><p>2017年，英特尔将Raja Koduri 从 AMD 挖来，让他负责<a href=\"https://www.infoq.cn/article/vsoNmp3DK0zVwtpGiBe9\">英特尔</a>\"整个图形部门，这在当时是一个令人兴奋的职位。英特尔表示，这样做是因为它想在2020年首次构建独立显卡。</p><p>&nbsp;</p><p>有趣的是，Koduri 之前也曾因类似的激动人心的项目而被挖走——Apple 在进行一系列显卡改进之前将他从AMD挖走，然后AMD在 2013 年再次将他“抢”了回来。</p><p>&nbsp;</p><p>Koduri在英特尔的五年多时间里，英特尔推出了 <a href=\"https://www.infoq.cn/article/TwX9PMgOZrc5IWIaXGXz\">Xe 图形架构的高性能 GPU</a>\"，并成功应用于笔记本、桌面及数据中心中。</p><p>&nbsp;</p><p>此外，Koduri 还监督了英特尔 oneAPI 软件堆栈的同步开发，该软件堆栈旨在提供为英特尔 GPU 精心设计的软件开发平台，同时还将英特尔的整体软件开发工作集成在一个统一的 API 和工具集中。</p><p>&nbsp;</p><p>遗憾的是，Koduri 这几年的努力并没有让英特尔在游戏和其他领域的独立显卡竞争中取得领先地位，其竞争对Nvidia和AMD仍然占据着主导地位。</p><p>&nbsp;</p><p>到 Koduri 离开时，他不仅负责图形，​​还负责英特尔的“加速计算”计划，包括加密芯片之类的东西，最近他一直担任英特尔 GPU/加速器业务的首席架构师。</p><p>&nbsp;</p><p>对于离职后的去向，Koduri 表示他将专注于游戏、媒体和娱乐的生成式AI。Koduri 表示，他“将在未来几周内分享更多内容”。</p><p>&nbsp;</p>",
    "publish_time": "2023-03-23 16:10:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "必致（BizDevOps）白皮书",
    "url": "https://www.infoq.cn/article/lsB8GB2BbvLQj2u5mBKo",
    "summary": "<p><strong>内容介绍</strong></p>\n<p>数字经济时代，所有业务都将长在技术之上，企业如何做到业技融合实现绩效增长？个人如何理解业务与技术的关系以适应数字时代的快速发展？阅读《必致（BizDevOps）白皮书》，你将系统地理解：为什么数字经济时代需要BizDevOps? BizDevOps的内核究竟是什么？想实现BizDevOps，究竟要做到哪几步？南京大学、阿里云云效、Thoughtworks、招行等10位业内领军人物编写，邀你共享。</p>\n<p><strong>编写组成员名单</strong></p>\n<ol>\n<li>何勉，BizDevOps共促计划专家组组长、前阿里巴巴资深技术专家</li>\n<li>肖然，全球数字化转型专家、中关村智联创新联盟副秘书长</li>\n<li>张裕 ，阿里云云效产品架构师</li>\n<li>陈展文，招商银行 EPG 组核心成员</li>\n<li>张燎原，阿里云云效产品负责人</li>\n<li>张贺，南京大学软件学院博士生导师</li>\n<li>欧红，招商银行研发管理与精益转型专家</li>\n<li>付晓岩，中国计算机学会软件工程专委会委员</li>\n<li>陈鑫 ，阿里云云效负责人</li>\n<li>亢江妹，ThoughtWorks 首席产品经理、产品咨询顾问</li>\n</ol>\n<p><strong>BizDevOps共促计划成员单位</strong></p>\n<ul>\n<li>南京大学软件研发效能实验室</li>\n<li>思特沃克软件技术(北京)有限公司</li>\n<li>阿里云计算有限公司</li>\n<li>北京极客邦科技有限公司</li>\n<li>招商银行股份有限公司</li>\n<li>上海优川信息技术有限公司</li>\n</ul>",
    "publish_time": "2023-03-23 16:14:26",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "并发提升 20+ 倍、单节点数万 QPS，Apache Doris 高并发特性解读",
    "url": "https://www.infoq.cn/article/qtfkmUxPUq2ZK2ekjNXD",
    "summary": "<p>随着用户规模的极速扩张，越来越多用户将 Apache Doris 用于构建企业内部的统一分析平台，这一方面需要 <a href=\"https://github.com/apache/doris\">Apache Doris</a>\" 去承担更大业务规模的处理和分析——既包含了更大规模的数据量、也包含了更高的并发承载，而另一方面，也意味着需要应对企业更加多样化的数据分析诉求，从过去的统计报表、即席查询、交互式分析等典型<a href=\"https://www.infoq.cn/article/SU6OOZ3M0ijHIzicsrtE\"> OLAP </a>\"场景，拓展到推荐、风控、标签画像以及 IoT 等更多业务场景中，而数据服务（Data Serving）就是其中具有代表性的一类需求。Data Serving 通常指的是向用户或企业客户提供数据访问服务，用户使用较为频繁的查询模式一般是按照 Key 查询一行或多行数据，例如：</p><p></p><p>订单详情查询商品详情查询物流状态查询交易详情查询用户信息查询用户画像属性查询...</p><p></p><p>与面向大规模数据扫描与计算的 Adhoc 不同，Data Serving 在实际业务中通常呈现为高并发的点查询—— 查询返回的数据量较少、通常只需返回一行或者少量行数据，但对于查询耗时极为敏感、期望在毫秒内返回查询结果，并且面临着超高并发的挑战。</p><p></p><p>在过去面对此类业务需求时，通常采取不同的系统组件分别承载对应的查询访问。OLAP 数据库一般是基于列式存储引擎构建，且是针对大数据场景设计的查询框架，通常以数据吞吐量来衡量系统能力，因此在 Data Serving 高并发点查场景的表现往往不及用户预期。基于此，用户一般引入 <a href=\"https://www.infoq.cn/article/yETztPsQPWgLK-dRyOtk\">Apache HBase </a>\"等 KV 系统来应对点查询、Redis 作为缓存层来分担高并发带来的系统压力。而这样的架构往往比较复杂，存在冗余存储、维护成本高的问题。融合统一的分析范式为<a href=\"https://www.infoq.cn/article/8SU754VFuKpw8gwjF24v\"> Apache Doris </a>\"能承载的工作负载带来了挑战，也让我们更加系统化地去思考如何更好地满足用户在此类场景的业务需求。基于以上思考，在即将发布的 2.0 版本中，我们在原有功能基础上引入了一系列面向点查询的优化手段，单节点可达数万 QPS 的超高并发，极大拓宽了适用场景的能力边界。</p><p></p><h1>如何应对高并发查询？</h1><p></p><p>一直以来高并发就是 <a href=\"https://www.infoq.cn/article/ve1ZIGW6fCjw4LMhjeOf\">Apache Doris </a>\"的优势之一。对于高并发查询，其核心在于如何平衡有限的系统资源消耗与并发执行带来的高负载。换而言之，需要最大化降低单个 SQL 执行时的 CPU、内存和 IO 开销，其关键在于减少底层数据的 Scan 以及随后的数据计算，其主要优化方式有如下几种：</p><p></p><h3>分区分桶裁剪</h3><p></p><p>Apache Doris 采用两级分区，第一级是 Partition，通常可以将时间作为分区键。第二级为 Bucket，通过 Hash 将数据打散至各个节点中，以此提升读取并行度并进一步提高读取吞吐。通过合理地划分区分桶，可以提高查询性能，以下列查询语句为例：</p><p></p><p><code lang=\"text\">select * from user_table where id = 5122 and create_date = '2022-01-01'\n</code></p><p></p><p>用户以create_time作为分区键、ID 作为分桶键，并设置了 10 个 Bucket， 经过分区分桶裁剪后可快速过滤非必要的分区数据，最终只需读取极少数据，比如 1 个分区的 1 个 Bucket 即可快速定位到查询结果，最大限度减少了数据的扫描量、降低了单个查询的延时。</p><p></p><h3>索引</h3><p></p><p>除了分区分桶裁剪， Doris 还提供了丰富的索引结构来加速数据的读取和过滤。索引的类型大体可以分为智能索引和二级索引两种，其中智能索引是在 Doris 数据写入时自动生成的，无需用户干预。智能索引包括前缀索引和 ZoneMap 索引两类：</p><p></p><p>前缀稀疏索引（Sorted Index） 是建立在排序结构上的一种索引。Doris 存储在文件中的数据，是按照排序列有序存储的，Doris 会在排序数据上每 1024 行创建一个稀疏索引项。索引的 Key 即当前这 1024 行中第一行的前缀排序列的值，当用户的查询条件包含这些排序列时，可以通过前缀稀疏索引快速定位到起始行。ZoneMap 索引是建立在 Segment 和 Page 级别的索引。对于 Page 中的每一列，都会记录在这个 Page 中的最大值和最小值，同样，在 Segment 级别也会对每一列的最大值和最小值进行记录。这样当进行等值或范围查询时，可以通过 MinMax 索引快速过滤掉不需要读取的行。</p><p></p><p>二级索引是需要用手动创建的索引，包括 Bloom Filter 索引、Bitmap 索引，以及 2.0 版本新增的 Inverted 倒排索引和 NGram Bloom Filter 索引，在此不细述，可从官网文档先行了解，后续将有系列文章进行解读。</p><p></p><p>官网文档：</p><p></p><p>倒排索引：https://doris.apache.org/zh-CN/docs/dev/data-table/index/inverted-indexNGram BloomFilter 索引：https://doris.apache.org/zh-CN/docs/dev/data-table/index/ngram-bloomfilter-index</p><p></p><p>我们以下列查询语句为例：</p><p></p><p><code lang=\"text\">select * from user_table where id &gt; 10 and id &lt; 1024\n</code></p><p></p><p>假设按照 ID 作为建表时指定的 Key， 那么在 Memtable 以及磁盘上按照 ID 有序的方式进行组织，查询时如果过滤条件包含前缀字段时，则可以使用前缀索引快速过滤。Key 查询条件在存储层会被划分为多个 Range，按照前缀索引做二分查找获取到对应的行号范围，由于前缀索引是稀疏的，所以只能大致定位出行的范围。随后过一遍 ZoneMap、Bloom Filter、Bitmap 等索引，进一步缩小需要 Scan 的行数。通过索引，大大减少了需要扫描的行数，减少<a href=\"https://www.infoq.cn/article/y2SeMvaJjgXJ9mBg9P00\"> CPU</a>\" 和 IO 的压力，整体大幅提升了系统的并发能力。</p><p></p><h3>物化视图</h3><p></p><p>物化视图是一种典型的空间换时间的思路，其本质是根据预定义的 SQL 分析语句执⾏预计算，并将计算结果持久化到另一张对用户透明但有实际存储的表中。在需要同时查询聚合数据和明细数据以及匹配不同前缀索引的场景，命中物化视图时可以获得更快的查询相应，同时也避免了大量的现场计算，因此可以提高性能表现并降低资源消耗。</p><p></p><p><code lang=\"text\">// 对于聚合操作， 直接读物化视图预聚合的列\ncreate materialized view store_amt as select store_id, sum(sale_amt) from sales_records group by store_id;\nSELECT store_id, sum(sale_amt) FROM sales_records GROUP BY store_id;\n\n// 对于查询， k3满足物化视图前缀列条件， 走物化视图加速查询\nCREATE MATERIALIZED VIEW mv_1 as SELECT k3, k2, k1 FROM tableA ORDER BY k3;\nselect k1, k2, k3 from table A where k3=3;\n</code></p><p></p><h3>Runtime Filter</h3><p></p><p>除了前文提到的用索引来加速过滤查询的数据， Doris 中还额外加入了动态过滤机制，即 Runtime Filter。在多表关联查询时，我们通常将右表称为 BuildTable、左表称为 ProbeTable，左表的数据量会大于右表的数据。在实现上，会首先读取右表的数据，在内存中构建一个 HashTable（Build）。之后开始读取左表的每一行数据，并在 HashTable 中进行连接匹配，来返回符合连接条件的数据（Probe）。而 Runtime Filter 是在右表构建 HashTable 的同时，为连接列生成一个过滤结构，可以是 Min/Max、IN 等过滤条件。之后把这个过滤列结构下推给左表。这样一来，左表就可以利用这个过滤结构，对数据进行过滤，从而减少 Probe 节点需要传输和比对的数据量。在大多数 Join 场景中，Runtime Filter 可以实现节点的自动穿透，将 Filter 穿透下推到最底层的扫描节点或者分布式 Shuffle Join 中。大多数的关联查询 Runtime Filter 都可以起到大幅减少数据读取的效果，从而加速整个查询的速度。</p><p></p><h3>OPN 优化技术</h3><p></p><p>在<a href=\"https://www.infoq.cn/video/LOJVrO7rsZ8WJDCzEber\">数据库</a>\"中查询最大或最小几条数据的应用场景非常广泛，比如查询满足某种条件的时间最近 100 条数据、查询价格最高或者最低的几个商品等，此类查询的性能对于实时分析非常重要。在 Doris 中引入了 TOPN 优化来解决大数据场景下较高的 IO、CPU、内存资源消耗：</p><p></p><p>首先从 Scanner 层读取排序字段和查询字段，利用堆排序保留 TOPN 条数据，实时更新当前已知的最大或最小的数据范围， 并动态下推至 ScannerScanner 层根据范围条件，利用索引等加速跳过文件和数据块，大幅减少读取的数据量。在宽表中用户通常需要查询字段数较多， 在 TOPN 场景实际有效的数据仅 N 条， 通过将读取拆分成两阶段， 第一阶段根据少量的排序列、条件列来定位行号并排序，第二阶段根据排序后并取 TOPN 的结果得到行号反向查询数据，这样可以大大降低 Scan 的开销</p><p></p><p>通过以上一系列优化手段，可以将不必要的数据剪枝掉，减少读取、排序的数据量，显著降低系统 IO、CPU 以及内存资源消耗。此外，还可以利用包括 SQL Cache、Partition Cache 在内的缓存机制以及 Join 优化手段来进一步提升并发，由于篇幅原因不在此详述。</p><p></p><h1>Apache Doris 2.0 新特性揭秘</h1><p></p><p>通过上一段中所介绍的内容，Apache Doris 实现了单节点上千 QPS 的并发支持。但在一些超高并发要求（例如数万 QPS）的 Data Serving 场景中，仍然存在瓶颈：</p><p></p><p>列式存储引擎对于行级数据的读取不友好，宽表模型上列存格式将大大放大随机读取 IO；<a href=\"https://www.infoq.cn/article/wGIjewsfYboQvQwA2LYo\">OLAP 数据库</a>\"的执行引擎和查询优化器对于某些简单的查询（如点查询）来说太重，需要在查询规划中规划短路径来处理此类查询；SQL 请求的接入以及查询计划的解析与生成由 FE 模块负责，使用的是 Java 语言，在高并发场景下解析和生成大量的查询执行计划会导致高 CPU 开销；……</p><p></p><p>带着以上问题，Apache Doris 在分别从降低 SQL 内存 IO 开销、提升点查执行效率以及降低 SQL 解析开销这三个设计点出发，进行一系列优化。</p><p></p><h3>行式存储格式（Row Store Format）</h3><p></p><p>与列式存储格式不同，行式存储格式在数据服务场景会更加友好，数据按行存储、应对单次检索整行数据时效率更高，可以极大减少磁盘访问次数。因此在 Apache Doris 2.0 版本中，我们引入了行式存储格式，将行存编码后存在单独的一列中，通过额外的空间来存储。用户可以在建表语句的 Property 中指定如下属性来开启行存：</p><p></p><p><code lang=\"text\">\"store_row_column\" = \"true\"\n</code></p><p></p><p>我们选择以 JSONB 作为行存的编码格式，主要出于以下考虑：</p><p></p><p>Schema 变更灵活：随着数据的变化、变更，表的 Schema 也可能发生相应变化。行存储格式提供灵活性以处理这些变化是很重要的，例如用户删减字段、修改字段类型，数据变更需要及时同步到行存中。通过使用 JSONB 作为编码方式，将列作为 JSONB 的字段进行编码， 可以非常方便地进行字段扩展以及更改属性。性能更高：在行存储格式中访问行可以比在列存储格式中访问行更快，因为数据存储在单个行中。这可以在高并发场景下显著减少磁盘访问开销。此外，通过将每个列 ID 映射到 JSONB其对应的值，可以实现对个别列的快速访问。存储空间：将 JSONB 作为行存储格式的编解码器也可以帮助减少磁盘存储成本。紧凑的二进制格式可以减少存储在磁盘上的数据总大小，使其更具成本效益。</p><p></p><p>使用 JSONB 编解码行存储格式，可以帮助解决高并发场景下面临的性能和存储问题。行存在存储引擎中会作为一个隐藏列（DORIS_ROW_STORE_COL）来进行存储，在 Memtable Flush 时，将各个列按照 JSONB 进行编码并缓存到这个隐藏列里。在数据读取时， 通过该隐藏列的 Column ID 来定位该列， 通过其行号定位到某一具体的行，并反序列化各列。</p><p></p><p>相关PR：https://github.com/apache/doris/pull/15491</p><p></p><h3>点查询短路径优化（Short-Circuit）</h3><p></p><p>通常情况下，一条 SQL 语句的执行需要经过三个步骤：首先通过 SQL Parser 解析语句，生成抽象语法树(AST)，随后通过 Query Optimizer 生成可执行计划（Plan），最终通过执行该计划得到计算结果。对于大数据量下的复杂查询，经由查询优化器生成的执行计划无疑具有更高效的执行效果，但对于低延时和高并发要求的点查询，则不适宜走整个查询优化器的优化流程，会带来不必要的额外开销。为了解决这个问题，我们实现了点查询的短路径优化，绕过查询优化器以及 PlanFragment 来简化 SQL 执行流程，直接使用快速高效的读路径来检索所需的数据。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/53/531cb282b5219a6020b002ebbf8c1134.png\" /></p><p></p><p>当查询被 FE 接收后，它将由规划器生成适当的 Short-Circuit Plan 作为点查询的物理计划。该 Plan 非常轻量级，不需要任何等效变换、逻辑优化或物理优化，仅对 AST 树进行一些基本分析、构建相应的固定计划并减少优化器的开销。对于简单的主键点查询，如select * from tbl where pk1 = 123 and pk2 = 456，因为其只涉及单个 Tablet，因此可以使用轻量的 RPC 接口来直接与 StorageEngine 进行交互，以此避免生成复杂的Fragment Plan 并消除了在 MPP 查询框架下执行调度的性能开销。RPC 接口的详细信息如下：</p><p></p><p><code lang=\"text\">message PTabletKeyLookupRequest {\n    required int64 tablet_id = 1;\n    repeated KeyTuple key_tuples = 2;\n    optional Descriptor desc_tbl = 4;\n    optional ExprList  output_expr = 5;\n}\n\nmessage PTabletKeyLookupResponse {\n    required PStatus status = 1;\n    optional bytes row_batch = 5;\n    optional bool empty_batch = 6;\n}\nrpc tablet_fetch_data(PTabletKeyLookupRequest) returns (PTabletKeyLookupResponse);\n</code></p><p></p><p>以上 tablet_id 是从主键条件列计算得出的，key_tuples是主键的字符串格式，在上面的示例中，key_tuples类似于 ['123', '456']，在 BE 收到请求后key_tuples将被编码为主键存储格式，并根据主键索引来识别 Key 在 Segment File 中的行号，并查看对应的行是否在delete bitmap中，如果存在则返回其行号，否则返回NotFound。然后使用该行号直对__DORIS_ROW_STORE_COL__列进行点查询，因此我们只需在该列中定位一行并获取 JSONB 格式的原始值，并对其进行反序列化作为后续输出函数计算的值。</p><p></p><p>相关PR：https://github.com/apache/doris/pull/15491</p><p></p><h3>预处理语句优化（PreparedStatement）</h3><p></p><p>高并发查询中的 CPU 开销可以部分归因于 FE 层分析和解析 SQL 的 CPU 计算，为了解决这个问题，我们在 FE 端提供了与 MySQL 协议完全兼容的预处理语句（Prepared Statement）。当 CPU 成为主键点查的性能瓶颈时，Prepared Statement 可以有效发挥作用，实现 4 倍以上的性能提升。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c4/c4490c9eaead699c02a54dfbad988be7.png\" /></p><p></p><p>Prepared Statement 的工作原理是通过在 Session 内存 HashMap 中缓存预先计算好的 SQL 和表达式，在后续查询时直接复用缓存对象即可。Prepared Statement 使用 <a href=\"https://dev.mysql.com/doc/dev/mysqlserver/latest/page_protocol_binary_resultset.html#sect_protocol_binary_resultset_row\">MySQL 二进制协议</a>\"作为传输协议。该协议在文件mysql_row_buffer.[h|cpp] 中实现，符合标准 MySQL 二进制编码， 通过该协议客户端例如 JDBC Client， 第一阶段发送PREPAREMySQL Command 将预编译语句发送给 FE 并由 FE 解析、Analyze 该语句并缓存到上图的 HashMap 中，接着客户端通过EXECUTEMySQL Command 将占位符替换并编码成二进制的格式发送给 FE， 此时 FE 按照 MySQL 协议反序列化后得到占位符中的值，生成对应的查询条件。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/37/37abb7c96a8287eea6cd70359bb1f060.png\" /></p><p></p><p>除了在 FE 缓存 Statement，我们还需要在 BE 中缓存被重复使用的结构，包括预先分配的计算 Block，查询描述符和输出表达式，由于这些结构在序列化和反序列化时会造成 CPU 热点， 所以需要将这些结构缓存下来。对于每个查询的 PreparedStatement，都会附带一个名为 CacheID 的 UUID。当 BE 执行点查询时，根据相关的 CacheID 找到对应的复用类， 并在 BE 中表达式计算、执行时重复使用上述结构。下面是在 JDBC 中使用 PreparedStatement 的示例：1. 设置 JDBC URL 并在 Server 端开启 PreparedStatement</p><p></p><p><code lang=\"text\">url = jdbc:mysql://127.0.0.1:9030/ycsb?useServerPrepStmts=true\n</code></p><p></p><p>使用 Prepared Statement</p><p></p><p><code lang=\"text\">// use `?` for placement holders, readStatement should be reused\nPreparedStatement readStatement = conn.prepareStatement(\"select * from tbl_point_query where key = ?\");\n...\nreadStatement.setInt(1234);\nResultSet resultSet = readStatement.executeQuery();\n...\nreadStatement.setInt(1235);\nresultSet = readStatement.executeQuery();\n...\n\n相关 PR：https://github.com/apache/doris/pull/15491\n</code></p><p></p><h3>行存缓存</h3><p></p><p>Doris 中有针对 Page 级别的 Cache，每个 Page 中存的是某一列的数据，所以 Page Cache 是针对列的缓存。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2a/2a5469c8a52e3cdf7bcc181ff325487e.png\" /></p><p></p><p>对于前面提到的行存，一行里包括了多列数据，缓存可能被大查询给刷掉，为了增加行缓存命中率，就需要单独引入行存缓存（Row Cache）。行存 Cache 复用了 Doris 中的 LRU Cache 机制， 启动时会初始化一个内存阈值， 当超过内存阈值后会淘汰掉陈旧的缓存行。对于一条主键查询语句，在存储层上命中行缓存和不命中行缓存可能有数十倍的性能差距(磁盘 IO 与内存的访问差距)，因此行缓存的引入可以极大提升点查询的性能，特别是缓存命中高的场景下。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/41/41d3e0e7dcecec53c4e55fd2e82e5aa1.png\" /></p><p></p><p>开启行存缓存可以在 BE 中设置以下配置项来开启：</p><p></p><p><code lang=\"text\">disable_storage_row_cache=false //是否开启行缓存， 默认不开启\nrow_cache_mem_limit=20% // 指定row cache占用内存的百分比， 默认20%内存\n</code></p><p></p><p>相关 PR：https://github.com/apache/doris/pull/15491</p><p></p><h1>Benchmark</h1><p></p><p>基于以上一系列优化，帮助 Apache Doris 在 Data Serving 场景的性能得到进一步提升。我们基于 Yahoo! Cloud Serving Benchmark （YCSB）标准性能测试工具进行了基准测试，其中环境配置与数据规模如下：</p><p></p><p>机器环境：单台 16 Core 64G 内存 4*1T 硬盘的云服务器集群规模：1 FE + 3 BE数据规模：一共 1 亿条数据，平均每行在 1K 左右，测试前进行了预热。对应测试表结构与查询语句如下：</p><p></p><p><code lang=\"text\">// 建表语句如下：\n\nCREATE TABLE `usertable` (\n  `YCSB_KEY` varchar(255) NULL,\n  `FIELD0` text NULL,\n  `FIELD1` text NULL,\n  `FIELD2` text NULL,\n  `FIELD3` text NULL,\n  `FIELD4` text NULL,\n  `FIELD5` text NULL,\n  `FIELD6` text NULL,\n  `FIELD7` text NULL,\n  `FIELD8` text NULL,\n  `FIELD9` text NULL\n) ENGINE=OLAP\nUNIQUE KEY(`YCSB_KEY`)\nCOMMENT 'OLAP'\nDISTRIBUTED BY HASH(`YCSB_KEY`) BUCKETS 16\nPROPERTIES (\n\"replication_allocation\" = \"tag.location.default: 1\",\n\"in_memory\" = \"false\",\n\"persistent\" = \"false\",\n\"storage_format\" = \"V2\",\n\"enable_unique_key_merge_on_write\" = \"true\",\n\"light_schema_change\" = \"true\",\n\"store_row_column\" = \"true\",\n\"disable_auto_compaction\" = \"false\"\n);\n\n// 查询语句如下：\n\nSELECT * from usertable WHERE YCSB_KEY = ?\n</code></p><p></p><p>开启优化（即同时开启行存、点查短路径以及 PreparedStatement）与未开启的测试结果如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dd/dda4ecc352556043930f48c9100479a3.png\" /></p><p></p><p>开启以上优化项后平均查询耗时降低了 96% ，99 分位的查询耗时仅之前的 1/28，QPS 并发从 1400 增至 3w、提升了超过 20 倍，整体性能表现和并发承载实现数据量级的飞跃！</p><p></p><h1>最佳实践</h1><p></p><p>需要注意的是，在当前阶段实现的点查询优化均是在 Unique Key 主键模型进行的，同时需要开启 Merge-on-Write 以及 Light Schema Change 后使用，以下是点查询场景的建表语句示例：</p><p></p><p><code lang=\"text\">CREATE TABLE `usertable` (\n  `USER_KEY` BIGINT NULL,\n  `FIELD0` text NULL,\n  `FIELD1` text NULL,\n  `FIELD2` text NULL,\n  `FIELD3` text NULL\n) ENGINE=OLAP\nUNIQUE KEY(`USER_KEY`)\nCOMMENT 'OLAP'\nDISTRIBUTED BY HASH(`USER_KEY`) BUCKETS 16\nPROPERTIES (\n\"enable_unique_key_merge_on_write\" = \"true\",\n\"light_schema_change\" = \"true\",\n\"store_row_column\" = \"true\",\n);\n</code></p><p></p><p>注意:</p><p></p><p>开启light_schema_change来支持 JSONB 行存编码 ColumnID开启store_row_column来存储行存格式</p><p></p><p>完成建表操作后，类似如下基于主键的点查 SQL 可通过行式存储格式和短路径执行得到性能的大幅提升：</p><p></p><p><code lang=\"text\">select * from usertable where USER_KEY = xxx;\n</code></p><p></p><p>与此同时，可以通过 JDBC 中的 Prepared Statement 来进一步提升点查询性能。如果有充足的内存， 还可以在 BE 配置文件中开启行存 Cache，上文中均已给出使用示例，在此不再赘述。</p><p></p><h1>总结</h1><p></p><p>通过引入行式存储格式、点查询短路径优化、预处理语句以及行存缓存，Apache Doris 实现了单节点上万 QPS 的超高并发，实现了数十倍的性能飞跃。而随着集群规模的横向拓展、机器配置的提升，Apache Doris 还可以利用硬件资源实现计算加速，自身的 MPP 架构也具备横向线性拓展的能力。因此 Apache Doris 真正具备了在 一套架构下同时 满足高吞吐的 OLAP 分析和高并发的 Data Serving 在线服务的能力，大大简化了混合工作负载下的技术架构，为用户提供了多场景下的统一分析体验。</p><p></p><p>以上功能的实现得益于 Apache Doris 社区开发者共同努力以及 SelectDB 工程师的的持续贡献，当前已处于紧锣密鼓的发版流程中，在不久后的 2.0 版本就会发布出来。</p><p></p><p>作者介绍：</p><p></p><p>李航宇，Apache Doris Contributor，SelectDB 半结构化研发工程师。</p>",
    "publish_time": "2023-03-23 16:48:27",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "对话OpenAI Greg Brockman：GPT-4并不完美，但人类也一样",
    "url": "https://www.infoq.cn/article/tDCUgv7rCH0yX40wdFVG",
    "summary": "<p><a href=\"https://www.infoq.cn/article/1Sb8qfMAjMivNCWtxRdV\">OpenAI</a>\"日前发布了备受期待的文本生成AI模型GPT-4。在举世轰动之余，人们也实在好奇这样的辉煌成就究竟是如何被创造出来的。</p><p>&nbsp;</p><p>GPT-4在多个关键层面对上代GPT-3实现了超越，包括提供更符合事实的陈述，也允许开发人员轻松设定风格和行为。它还具备多模态支持能力，可以理解图像，甚至根据照片内容添加标题和做出解读。</p><p>&nbsp;</p><p>但<a href=\"https://www.infoq.cn/article/HFSPasQ7SXZ9QzdFXhGO\">GPT-4</a>\"也有不少严重缺陷。与GPT-3一样，该模型仍存在“幻觉”和基础性的推理错误。OpenAI自己发布博文称，GPT-4将猫王称为“演员的儿子”（他的父母并非演员）。</p><p>&nbsp;</p><p>为了更好地了解GPT-4的开发周期、现有功能和局限性，我们有幸与OpenAI联合创始人兼总裁Greg Brockman进行了交谈。</p><p>&nbsp;</p><p>在被问及GPT-4和<a href=\"https://www.infoq.cn/article/w1lxxO4qtaVPxZUdqzwi\">GPT-3</a>\"的区别时，Brockman只说了一个词：不一样。</p><p>&nbsp;</p><p>“二者确实不一样。GPT-4模型仍然存在很多问题和错误……但也可以看到，它对微积分和法律内容的理解实现了飞跃。尽管在某些领域的表现还是不行，但在其他方面就算用衡量人类的标准看也是相当出色。”</p><p>&nbsp;</p><p>测试结果也证实了他的说法。在美国大学理事会的AP微积分BC考试中，GPT-4获得了4分（满分5分），GPT-3则仅获得1分。（作为GPT-3与GPT-4之间的过渡版本，GPT-3.5同样拿到4分。）而在模拟律师考试中，GPT-4的排名在人类考生中挤入前10%，GPT-3.5的分数则在倒数10%左右。</p><p>&nbsp;</p><p>此外，<a href=\"https://www.infoq.cn/article/CjCt0ZpY54k5f1p8ZV7F\">GPT-4</a>\"还表现出了有趣的多模态支持能力。与只能接受文本提示的GPT-3和GPT-3.5（例如「写一篇关于长颈鹿的文章」）不同，GPT-4能够通过图像和文本提示来执行某些操作。（例如提交一张长颈鹿的实拍照片，问「图中有多少只长颈鹿？」）</p><p>&nbsp;</p><p>这是因为GPT-4接受了图像和文本数据的双料训练，而前面几个版本只接受过文本训练。OpenAI表示，训练数据来自“各种许可、创建且公开可用的数据源，其中可能包括公开可用的个人信息”。但Brockman拒绝回答更多具体细节（OpenAI之前曾经因训练数据的归属问题陷入法律纠纷）。</p><p>&nbsp;</p><p>GPT-4也确实表现出令人印象深刻的图像理解能力。例如，输入提示“这张图片的笑点在哪里？”，再配上一张VGA线接iPhone的照片，GPT-4就正确理解了个中内容并详细做出解释（「图像中的笑点，来自错误将陈旧的大VGA端口接入小型现代智能手机的充电口」）。</p><p>&nbsp;</p><p>目前只有一家合作伙伴获准使用GPT-4的图像分析功能，这就是名为Be My Eyes的视障人士辅助应用。Brockman表示，OpenAI正在评估功能开放的风险和收益，而且后续推广一定会采取“缓慢且谨慎的方式”。</p><p>&nbsp;</p><p>“我们需要想办法解决人脸识别和人物肖像等政策性问题。我们得摸清危险区在哪里、红线在哪里，然后随时间推移逐步找到正确的处理方式。”</p><p>&nbsp;</p><p>OpenAI的文本到图像系统<a href=\"https://www.infoq.cn/article/wGIjewsfYboQvQwA2LYo\">DALL-E </a>\"2也遭遇过类似的道德困境。OpenAI最初允许客户上传人脸，使用AI图像生成系统进行画面编辑，但在激起反对后紧急叫停。后来OpenAI宣称安全系统已经升级，能够“最大限度降低deepfakes、色情、政治和暴力内容造成的潜在危害”，并将人脸编辑功能重新开放。</p><p>&nbsp;</p><p>另一大隐患在于GPT-4可能被用于造成意外危害，包括利用目标心理、实施金钱欺诈等。模型发布数小时之后，以色列网络安全初创公司Adversa AI就发布博文，表示已成功绕过OpenAI的内容过滤器，甚至公开了让GPT-4生成网络钓鱼邮件、对同性恋者的攻击性描述及其他有毒文本的办法。</p><p>&nbsp;</p><p>这在语言模型领域算是个老大难问题了。<a href=\"https://www.infoq.cn/article/4iDmM3PgXmvELorwQ8M3\">Meta</a>\"公司的BlenderBot和OpenAI的<a href=\"https://www.infoq.cn/article/FRcz5vjOvl3bM2d57opX\">ChatGPT</a>\"都曾在用户的“诱导”下生成了极具冒犯性的内容，甚至透露了系统内部运作的敏感细节。但人们仍然对AI大模型的表现振奋不已，也期待GPT-4能在自我审查和节制方面实现重大改进。</p><p>&nbsp;</p><p>在被问及GPT-4的稳健性时，Brockman强调该模型已经接受了六个月的安全训练。而且在内部测试中，它对OpenAI禁止内容做出响应的几率较GPT-3.5降低了82%，生成“符合事实”响应的几率则提高了40%。</p><p>&nbsp;</p><p>“我们花了很多时间来摸索GPT-4的能力，摸索的方式就是把它对外公布。我们不断做更新，包括一系列改进，希望模型能真正匹配使用者想要的个性或模式。”</p><p>&nbsp;</p><p>但必须承认，早期实际测试的结果并不理想。除了Adversa AI测试之外，基于GPT-4的微软聊天机器人Bing Chat也被证明极易被“攻破”。利用精心设计的输入，用户已经能让机器人表达爱意、威胁伤害、支持大屠杀和编造阴谋论。</p><p>&nbsp;</p><p>Brockman并不否认GPT-4的种种不足。但他也强调了该模型所使用的新型操控缓解工具，包括API级的“系统”消息功能。系统消息的本质是一种指令，负责为GPT-4的交互行为设定基调和边界。例如，系统消息可以这样编写，“你是一位苏格拉底式的思辨型导师，你永远不会直接给学生答案，而是通过一个个正确的问题帮助他们学会独立思考。”</p><p>&nbsp;</p><p><a href=\"https://www.infoq.cn/article/7oYfCjaI0rbbpGsBSYWk\">OpenAI</a>\"希望把系统消息当作护栏，防止GPT-4偏离既定“轨道”。</p><p>&nbsp;</p><p>“我们一直在努力理解GPT-4的基调、风格和实质从何而来。我觉得现在我们已经在工程层面找到些思路了，包括如何实现可重现的过程，生成对人们真正有用的可预测结果。”</p><p>&nbsp;</p><p>Brockman还谈到了Evals，这是OpenAI用于评估其AI模型性能的全新开源软件框架。OpenAI希望借此保证自家模型的“稳健性”。Evals允许用户开发和运行基准测试，以此评估GPT-4等模型的性能，这意味着大语言模型将步入众包测试的新时代。</p><p>&nbsp;</p><p>“借助Evals，我们能够以系统化的方式掌握用户最关心的用例，并据此开展测试。之所以决定开源，也是考虑到我们后续不会再隔三个月才发布新模型，而是转向持续改进的方式。如果无法衡量，自然也就无法实现了，对吧？在为模型开发新版本时，我们至少可以借此了解哪些地方发生了变化。”</p><p>&nbsp;</p><p>我们询问Brockman，OpenAI打不打算向通过Evals测试其模型的人们付费。他暂时给不出确切的结论，但表示OpenAI确实向指定的Evals用户开放了GPT-4 API的早期访问权限。</p><p>&nbsp;</p><p>Brockman还谈到了GPT-4的上下文窗口，也就是模型在生成新文本之前能够参考的文本量。OpenAI目前正在测试GPT-4某一特定版本，其能够“记住”约50页内容。换句话说，这个版本的“记忆容量”相当于普通GPT-4的5倍、GPT-3的8倍。</p><p>&nbsp;</p><p>Brockman认为更大的上下文窗口将派生出前所未有的新型应用程序，特别是在企业场景之下。他设想会有专门为企业业务构建的AI聊天机器人，能够利用不同来源（包括各部门员工）的上下文和知识以娴熟的对话解惑答疑。</p><p>&nbsp;</p><p>这虽然不是什么新鲜概念，但Brockman表示GPT-4的回答质量要远远高于责令一切聊天机器人和搜索引擎。</p><p>&nbsp;</p><p>“以往，模型并不知道是谁在发问、你对哪些内容感兴趣等。更大的上下文窗口代表着更丰富的参考信息，肯定会让AI模型掌握更多知识、更好地为人类赋能。”</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://techcrunch.com/2023/03/15/interview-with-openais-greg-brockman-gpt-4-isnt-perfect-but-neither-are-you/?guccounter=1&amp;guce_referrer=aHR0cHM6Ly9uZXdzLnljb21iaW5hdG9yLmNvbS8&amp;guce_referrer_sig=AQAAAATciFx2sgGMIyHWoErJAFDo6hB-eouE0HxMvTSOgk8aD6C_Clkzk1JtNZaOTbUtf9Sa-BuwBS36sQu2t7l6vwj58K34WkrFWPpyEGskLBTvfqdMXbtLtF6ZaOoTWSWRCt7Egccc-lQIqGECJN5Y2gZX1WXh9FR5o17IQEHY3jjf\">https://techcrunch.com/2023/03/15/interview-with-openais-greg-brockman-gpt-4-isnt-perfect-but-neither-are-you/?guccounter=1&amp;guce_referrer=aHR0cHM6Ly9uZXdzLnljb21iaW5hdG9yLmNvbS8&amp;guce_referrer_sig=AQAAAATciFx2sgGMIyHWoErJAFDo6hB-eouE0HxMvTSOgk8aD6C_Clkzk1JtNZaOTbUtf9Sa-BuwBS36sQu2t7l6vwj58K34WkrFWPpyEGskLBTvfqdMXbtLtF6ZaOoTWSWRCt7Egccc-lQIqGECJN5Y2gZX1WXh9FR5o17IQEHY3jjf</a>\"</p>",
    "publish_time": "2023-03-23 16:59:48",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "醒醒吧，没有什么安全的软件供应链",
    "url": "https://www.infoq.cn/article/Wv6MjUH5FmrRQPmphIbh",
    "summary": "<p>本文最初发布于John McBride的个人博客。</p><p></p><p>多年前，企业家和创新者就预言“<a href=\"https://a16z.com/2011/08/20/why-software-is-eating-the-world/\">软件将吞噬世界</a>\"”。毫不奇怪，年复一年，世界变得越来越依赖软件解决方案。通常情况下，这里说的软件是（或间接依赖于）一些开源软件，由一组人维护，这些人之间的唯一联系可能就是参与该开源项目社区。</p><p></p><p>但我们有麻烦了。开源软件的安全性正在受到威胁，这几乎耗光了维护这些项目的人员的精力。随着技术栈越来越深，依赖项的关联关系愈加复杂，人们对软件供应链安全做出了可怕的妥协。对于开源世界中正在发生的事情，如果要找一个典型的例子，我们只需看下当下非常流行的<a href=\"https://github.com/orgs/gorilla/repositories\">Gorilla Go工具箱</a>\"。</p><p>&nbsp;</p><p>Gorilla 是一个提供强大Web框架技术的项目，如mux和会话。在其漫长的生命周期里，它实际上是一个用于Web服务器、路由请求、处理HTTP流量及使用WebSockets的Go框架。有成千上万的软件包使用了它。对于Go社区中的大多数人来说，这个项目将不复存在是一个非常让人震惊的消息：不再维护，不再发布新版本，也不会再提供社区支持。但是，如果你对其社区足够关注，应该早就会看到一些动荡的迹象：公开招募维护人员没人响应，几乎没有积极的外部贡献者，并且维护人员的负担非常沉重。</p><p>&nbsp;</p><p>Gorilla框架只是那些“重要的依赖项”中的一个。它处于一个非常重要的位置，既要能提供便利，又要能安全地处理重要的有效载荷。开发人员可以围绕Gorilla提供的API构建他们自己的逻辑，也可以将它作为整个代码库的基础。整个社区都很信任Gorilla，你最不想在服务器上看到的就是一个充满Bug和CVE的Web框架。</p><p></p><p>在安全的软件供应链中，就像Nginx和OpenSSL一样，它是许多其他供应链和依赖项的基石。如果Gorilla框架出了问题，就有可能影响数百万服务器、服务和其他项目。</p><p>&nbsp;</p><p>软件供应链安全是大型科技公司、安全公司和新闻媒体都喜欢谈论的抽象概念之一。这是一种“理念”，即你在整个技术栈中作为依赖项使用的软件正是你所期望的软件。换句话说，可以保证黑客没有向你使用的库或构建工具中注入后门，从而危及你的整个产品、软件库甚至公司。供应链攻击是恶作剧式的，因为它们几乎从不针对实际的目标。相反，它们会通过攻击一些依赖项来寻找预期的目标。</p><p>&nbsp;</p><p>直到今天，太阳风攻击仍是一个很典型的例子：一些俄罗斯支持的匿名黑客组织能够破坏内部Solar Winds构建系统，后续任何使用该系统构建的软件都会被注入后门和漏洞。这次攻击的后果很严重，包括美国国务院在内的许多政府机构都证实发生了大规模数据泄露。据估计，这次攻击造成的损失还在继续上升，预计将达数十亿美元。</p><p>&nbsp;</p><p>在过去几年里，试图解决这些问题的产品一个接一个地涌现出来：软件签名解决方案、自动安全扫描工具、及时更新的CVE数据库、自动机器人、人工智能辅助编码工具等。甚至一整个白宫的顾问都在讨论这个问题。联邦政府知道，这是我们国家软件基础设施最重要（也是最脆弱）的载体，他们已经采取了直接行动来打击这类攻击。</p><p>&nbsp;</p><p>但是，安全的软件供应链也是那些很快就会瓦解的东西之一，没有细致的处理和严密的保护，事情很快就会变糟。几个月以来，Gorilla工具包一直在公开招募维护人员，寻找更多的人来保证代码库的更新、安全以及得到良好的维护。但最终，Gorilla的维护人员找不到足够的人来维持这个项目。</p><p></p><p>评论里许多人自告奋勇，但之后就再也没有出现过。当然，维护人员的门槛也很高：</p><p></p><p></p><blockquote>把一个每周有超过1.3k不同克隆的软件包（mux）交给别人管理，这是我所不能接受的。这种做法以往在其他项目中引发过糟糕的事情。</blockquote><p></p><p>&nbsp;</p><p>2018年，GitHub用户FallingSnow在流行但并不是很知名的NPM JavaScript包事件流中打开了 “我不知道该说什么”这个问题。他在库最近提交的文件中发现了一些非常奇怪的东西。一名社区中从未见过的新的维护人员，似乎还是一个全新的GitHub帐户，直接向主分支提交了一段奇怪的代码。这个身份未知的新维护者还把一个新包添加到NPM注册中心，并将这一变化强加给追踪项目最新软件包的人。</p><p>&nbsp;</p><p>更改类似这样：在一个新文件中添加了一个很长的内联加密字符串。该字符串会使用一些未知的环境变量进行解码，然后，未加密的字符串将作为JavaScript模块注入到包中，进而执行隐藏在加密字符串后面的任何代码。简而言之，未知的代码会在运行时被破译、注入并执行。</p><p>&nbsp;</p><p>GitHub上的这个问题迅速传播开来。通过纯粹的蛮力、一点点运气和数百名评论者，社区破解了字符串，揭露了注入代码的目的：加密货币“钱包小偷”。如果代码在系统上检测到一个特定的钱包，它就会使用一个已知的漏洞窃取存储在该钱包中的所有加密货币。</p><p>&nbsp;</p><p>这个代码漏洞在事件流NPM模块中存在了几个月。安全扫描工具、消费者和项目所有者都没有发现。直到社区中有好奇心比较强的人仔细看了一下时，这种明显的代码注入攻击才变得明朗。</p><p></p><p>但是，使这次攻击特别糟糕的是，使用事件流模块的模块有很多（而这些模块又被其他模块使用，以此类推）。理论上，这可能会影响到数千个软件包和数百万终端用户。有些开发人员不知道他们的JavaScript依赖栈深处使用了事件流，现在，突然之间，他们不得不快速修补自己的代码。这怎么可能呢？是谁批准和允许这一切发生的？</p><p>&nbsp;</p><p>GitHub存储库的所有者和代码的原作者表示：</p><p></p><p></p><blockquote>他给我发邮件，说他想维护这个模块，所以我把它给了他。我没有从维护这个模块中得到任何东西，我甚至不再用它了，而且已经很多年没用了。注意：我不再有这个模块在npm上的发布权限。</blockquote><p></p><p>&nbsp;</p><p>就像这样，仅仅通过询问，一些恶意行为者就能够破坏成千上万的软件包，披着“维护人员”的面纱而不被发现。</p><p>&nbsp;</p><p>过去，我将其称为“单一维护者依赖风险”：独自维护广泛分发的软件包所带来的那种无法抗拒的、通常让人感到孤独的、有时甚至是危险的体验。就像事件流的所有者一样，大多数单独的维护人员都会逐渐消失，淡出人们的视野，任由他们的软件陷入混乱。</p><p>&nbsp;</p><p>Gorilla的情况就是如此：</p><p></p><p></p><blockquote>原作者和维护者moraes很久以前就离开了。kisielk和garyburd参与时间最长，各自维护了HTTP库和gorilla/websocket。我（elithrar）大约是在2014年的某个时候参与进来的，当时我注意到，kisielk做了很多繁重的工作，我在一些个人项目中使用了这个库，我希望提供帮助并回馈项目。大约从2018年左右开始，我（基本上）是除了websocket之外所有东西的唯一维护人员，这也是garyburd发布公告招募新维护人员（实际上并不成功）的时间。</blockquote><p></p><p>&nbsp;</p><p>安全的软件供应链永远不会真正的强大和安全，只要一个单独的维护人员就能够破坏整个包的生态系统，而他所要做的只是将包提供给一些恶意行为者。事实上，不存在安全的软件供应链：我们的强大程度取决于中间最弱的环节，而且在很多情况下，供应链中的薄弱环节已经被破坏并变得越来越糟糕，或被那些怀有邪恶目的的人所利用。</p><p>&nbsp;</p><p>每当我提起这个话题，总会有人问起钱的问题。啊，金钱，生活带给人的最真实的满足！是的，对一些人来说，金钱是一个强大的动力。但对于安全的软件供应链所真正需要的东西——真正的可靠性，这是一个可悲的借口。</p><p></p><p>软件行业可以在重要开源项目的维护者身上砸下所有的钱，Valve已经开始这么做了：</p><p></p><p></p><blockquote>Griffais表示，该公司还直接雇佣了100多名开源开发人员来开发Proton兼容层、Mesa图形驱动程序和Vulkan，并完成Steam for Linux和Chromebook等其他任务。</blockquote><p></p><p>&nbsp;</p><p>但在某些时候，只靠少数几个人来保证公司整个产品栈的完整性、安全性和可行性是不合理的。如果它如此重要，为什么不雇佣一群这样的人，成立一个专门的维护人员团队，创建贡献流程，并让开发人员可以留出时间参与开源项目的开发呢？</p><p></p><p>我经常听到有人说，要通过砸钱来解决开源问题，但在某种程度上，扩大软件交付规模的问题不是给几个人付多少钱就能解决的。比如你在建造一所房子，让一两个人打地基是合理的。但如果你正在规划和建造整个城市街区，我当然希望你能投入整个团队来规划、建造和维护这些地基。钱再多，少数几个人也无法打下一个强大、安全的地基。但我们要求一些开源项目维护者做的就是为全世界规划、构建和调整这样的地基。</p><p>&nbsp;</p><p>Gorilla的维护人员也意识到了这一点：</p><p></p><p></p><blockquote>不。我觉得我们都不是为了钱。回顾下最活跃的维护者，Gorilla Toolkit是一个充满激情的项目。我们不想让它成为一份工作。</blockquote><p></p><p>&nbsp;</p><p>对他们来说，这不是钱的问题，所以在这个项目上砸多少钱都无济于事。那关于软件质量、可维护性以及它所提供的内在满足感。</p><p>&nbsp;</p><p>那么，我们如何激励开源维护人员以一种可扩展而又现实的方式维护他们的软件呢？有些人的动机是为社区提供利他价值。有些人的动机是名誉、权力和认可。而其他人只是想玩得开心，做一些酷酷的事情。我们不可能理解开源社区中不同人错综复杂的动机来源。</p><p></p><p>相反，最好的解决方案是显而易见的：如果你所在的团队依赖于某种开源软件，那么就分配真正的工程时间来做贡献，成为社区的一部分，并帮助维护该软件。最终，你就会对项目的运作方式和主要参与者的动机有一个很好的了解。更好的是，你可以帮助减轻独自维护者的沉重负担。</p><p>&nbsp;</p><p>有时，我喜欢把软件想象成一个木制的独木舟，它的许多依赖就是船的木条。刚建好的时候，它看起来结实、稳固，能够承受最恶劣的条件。它的第一层油面新鲜而美丽，它的木纹光滑而平直。但随着岁月的流逝，最终，它的的饰面逐渐褪色，它的木条需要更换，如果它进了水，可能还需要时间和新的材料来修补。久而久之，它的木头会从内部发霉腐烂，船遭到了破坏，不再完整。</p><p></p><p>就像船一样，软件也需要时间、精力、维护和“全体动员（hands-on-deck）”，以确保它在安全的软件供应链的诸多环节中都是可靠的。否则，时间白蚁和恶意行为者的破坏会削弱链条中的各个环节，危及整个链条的稳定性。</p><p>&nbsp;</p><p>最后，Gorilla框架的维护者做了正确的事情：他们终止了一个广泛使用的项目，这个项目有从内到外腐烂的风险。这可以避免它陷入混乱或落入坏人之手，它就这样消失了。它故意切断了自己在软件链上所处的环节，迫使所有使用它的人选择一个更好、希望也是更安全的选项。</p><p></p><p></p><blockquote>我相信，开源软件是有生命周期的——开始、中间、结束——没有一个项目需要永远存在。可能会有人因此不开心，但生活就是这样。</blockquote><p></p><p></p><p>原文链接：</p><p><a href=\"https://johncodes.com/posts/there-is-no-secure-software-supply-chain/\">https://johncodes.com/posts/there-is-no-secure-software-supply-chain/</a>\"</p>",
    "publish_time": "2023-03-23 17:03:37",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]