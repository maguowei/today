[
  {
    "title": "如何最大限度地利用GitHub Actions自动化软件开发过程",
    "url": "https://www.infoq.cn/article/8q3rjE8YRu11TaCS2bhl",
    "summary": "<p></p><h2>Actions发展简介</h2><p></p><p></p><p>当GitHub Actions在2019年秋天发布时，立即就引起了人们的关注，因为它引领了“<a href=\"https://blog.codecentric.de/github-actions-nextgen-cicd\">CI/CD平台的第三次风潮</a>\"”。从可重用的开源构建块构建可组合管道，在改善CI/CD管道操作的效率和维护方面，这个独特的方法明显有很大的潜力。然而，尽管Actions平台的设计具有内在的吸引力，但许多组织，特别是已经构建了CI/CD系统的大型企业，对采取行动犹豫不决，这是可以理解的。在一定程度上，这是由于婴儿期的平台存在诸多限制，比如在企业内部执行和共享Actions的限制。</p><p>&nbsp;</p><p>幸运的是，自最初发布之后，Actions已经采取了一些步骤来消除障碍，实现企业使用的可维护性。此后不久，<a href=\"https://github.blog/2019-11-05-self-hosted-runners-for-github-actions-is-now-in-beta/\">自托管runner</a>\"推出，这是在现有企业内部网络中执行作业的一项基础能力。然后，2021年11月，<a href=\"https://github.blog/2021-11-29-github-actions-reusable-workflows-is-generally-available/\">可重用工作流</a>\"发布，极大地扩展了提供可重用管道的能力，减少了重复步骤和样板代码的数量，缩小了与许多更成熟的CI/CD产品的差距。真正让这一功能做好企业采用准备的是在2022年1月宣布的<a href=\"https://github.blog/changelog/2022-01-21-share-github-actions-within-your-enterprise/\">内部共享操作</a>\"的能力，这种能力使平台工程团队能够打包发布常见的可重用步骤，而又不会暴露给外界。最终，我们感觉Actions有能力作为企业CI/CD生态系统的基础了。</p><p>&nbsp;</p><p></p><h2>我们为什么转到Actions</h2><p></p><p></p><p>在Thrivent，我们最近几年投入了大量的精力来改善CI/CD工具的开发体验，包括实现自动化，按照公认的黄金路径快速从模板生成应用程序管道。尽管如此，我们在提供一个一致性和灵活性均衡的平台方面遇到了限制。</p><p>&nbsp;</p><p>就我们当前的系统而言，其中一个不足体现在在CI/CD管道中共享公共任务。我们的共享脚本存储库提供的封装有限，并且会弄乱应用程序的构建历史，将实际应用程序存储库的提交和共享任务存储库的提交混在一起。</p><p>&nbsp;</p><p>在对管道模板升级时，我们保留用户自定义设置的能力也很有限。如果我们在模板中引入了一个新的步骤或修复了一个Bug，那么开发人员将不得不重新生成整个管道来获取更改，这会删除他们所做的所有定制。</p><p>&nbsp;</p><p>最后，还有一个不太明显的因素是，最大限度地减少开发人员使用CI/CD系统的障碍。当我们的技术组织进入增长期，有大量新的开发人员涌入，提供一个能够让这些开发人员快速上手并满足他们期望的平台成了当务之急。在最近<a href=\"https://survey.stackoverflow.co/2022/#section-version-control-version-control-platforms\">Stack Overflow</a>\"和<a href=\"https://tsh.io/state-of-frontend/#whats-your-favorite-version-control-provider\">State of Frontend</a>\"的调查中，大多数开发人员都回复说使用了GitHub。鉴于它在开源社区中的地位，这不足为奇。通过将使用范围扩大到平台原生的CI/CD功能，我们看到了以下机会：</p><p>将工具整合到单个系统中，充分利用开发人员现有的熟悉度，从而减少无关的认知负荷；使用存储库事件最大限度地减少上下文切换，使编码生命周期内的工作更紧凑；提供我们一直在寻找的原生模块化管道架构。</p><p>&nbsp;</p><p>总的来说，GitHub Actions平台的设计借鉴了现代开发方法。开发人员可以利用可重用组件灵活地构建管道，将团队在开发活动中使用的开源思想转移到CI/CD管道中。然而，随着我们对Actions生态系统的深入研究，Actions在CI/CD处理方面存在着一些显著的差异，这促使我们重新思考了之前所做的一些假设，并开发了一种新的策略，将平台的限制变成一种优势。</p><p>&nbsp;</p><p></p><h3>术语速览</h3><p></p><p></p><p>在GitHub Actions系统中，有几个术语由于在CI/CD生态系统中使用广泛，可能具有各种含义，但在Actions框架中，它们指的是特定的资源（即“工作流”、“作业”、“操作”、“事件”和“runner”）。如果你不熟悉GitHub Actions的定义，那么建议你快速浏览一下<a href=\"https://docs.github.com/en/enterprise-cloud@latest/actions/learn-github-actions/understanding-github-actions\">GitHub的文档</a>\"。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9f/9f0e5708fe3382ab8c3c131e97e5e3b0.jpeg\" /></p><p></p><p>GitHub Actions工作流可视化（来源：<a href=\"https://docs.github.com/en/actions/learn-github-actions/understanding-github-actions\">GitHub</a>\"）</p><p>&nbsp;</p><p></p><h2>思想转变</h2><p></p><p></p><p>在转换到Actions时，其中一个需要首先理解的区别是存储库和管道工具之间的关系。我们一直在使用的CI/CD产品是与应用程序的存储库集成在一起的，虽然本质上是分开的。即使是CI/CD领域中的其他工具，它们可能为应用程序的整个生命周期提供了更全面的解决方案（通常将存储库、管道和其他交付工具捆绑到单个产品中），也倾向于提供更高级的结构，如“项目”或“应用程序”，明确区分存储库和管道，使它们的地位相对平等。当CI/CD过程开始时，所有的注意力都转到了管道工具视图上。</p><p>&nbsp;</p><p>相比之下，使用GitHub Actions，存储库仍然是宇宙的中心。Actions平台中触发的工作流主要存在于存储库的上下文中。这种方法有利也有弊。</p><p>&nbsp;</p><p></p><h3>优点</h3><p></p><p></p><p>存储库现在提供了应用程序状态的单一落点，将应用程序运行状况和部署信息与代码本身紧密地结合在一起。在传统的提交/推送触发器之外，它还提供了在各种存储库事件（例如，加标签、pull请求）上启动工作流的能力，方便我们将CI/CD更紧密地集成到开发流程中去。对于共享操作和工作流的系统，它提供的能力让我们可以独立于应用程序存储库的变更，轻松地管理共享管道组件的生命周期。</p><p>&nbsp;</p><p></p><h3>缺点</h3><p></p><p></p><p>因为所有事情都是基于存储库中发生的事件进行编排的，所以很难从其他（外部）事件源启动工作流。通过工作流生成的工件在存储库中的可见度与代码的可见度不一样。这意味着分享和推广结果工件的能力是有限的，因为该信息没有持久化到存储库中，也没有在工作流执行之间共享。不同的存储库组织方法可能会为流程带来额外的复杂性，例如，<a href=\"https://en.wikipedia.org/wiki/Monorepo\">单存储库</a>\"可能在同一个存储库中包含多个不同的项目。这些相互独立的应用程序在构建和部署的方式上也可能存在差异。因此，需要格外小心，并可能需要借助额外的工具来有效地管理触发事件，以避免构建未经修改的应用程序，以及正确地打包和部署下游工件。</p><p>&nbsp;</p><p></p><h2>制定Actions使用策略</h2><p></p><p></p><p>现在，在了解了GitHub Actions的视角及其优缺点后，我们可以开始制定有效使用Actions平台作为CI/CD解决方案的策略。以下是指导我们作出决策的一些主要原则。</p><p>&nbsp;</p><p></p><h3>优选Pull请求审批而非工作流审批</h3><p></p><p></p><p>CI/CD平台的主要关注点之一是有效地收集和显示输出，并对这些结果强制执行质量门检验。以前，我们一直在使用一个许多组织都很熟悉的流程：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/83/83aef4a68f067cff340dec6d7c9c8ef5.jpeg\" /></p><p></p><p>以前的方法：存储库和管道检查是分开的</p><p>&nbsp;</p><p>在这种方法中，对目标分支的推送会触发管道。管道会分成一系列的阶段执行，每个阶段都会输出一些结果，并且通常会根据这些结果评估工件的生产就绪情况。</p><p>&nbsp;</p><p>我们的新目标是使这些信息更趋近于自然的开发活动，同时又要注意Actions结果和工件显示方式的一些固有限制，因此，我们希望有一种更好的方式来提供这些控制，而pull请求特性是合乎逻辑的选择。Pull请求维护的审计历史更久（与工作流执行的<a href=\"https://docs.github.com/en/enterprise-cloud@latest/organizations/managing-organization-settings/configuring-the-retention-period-for-github-actions-artifacts-and-logs-in-your-organization\">保留时间限制</a>\"相比），并且讨论聚焦于变更本身，代码可供随时参考。将pull请求作为主要的审批仪表板需要转换模式，pull请求收集相同的结果并执行同样的质量检查，但不需要额外导航回存储库查看相关的更改。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/77/777178afcd7d9106f2cb6f66d37c1d50.jpeg\" /></p><p></p><p>新策略：依据pull请求收集必要的信息</p><p>&nbsp;</p><p></p><h3>制定可重用组件指南</h3><p></p><p></p><p>构建可重用管道片段的自助库也带来了许多问题。我们要如何处理共享工作流和操作的更新？当多个团队对看似相同的任务在处理方式上略有差异时，如果我们想要平衡这些团队，什么样的抽象级别才合适？</p><p>&nbsp;</p><p>面对这些挑战，我们的目标是实现一系列“铺好的路（paved roads）”，每个新的存储库都应该能够使用我们团队支持的模板、操作和可重用工作流进行部署，但又有按需定制的灵活性。这为保持存储库始终处于可部署状态的持续交付指令奠定了基础。为了实现这一目标，我们制定了一些指导方针。</p><p>&nbsp;</p><p></p><h3>推送所有版本的语义版本标签</h3><p></p><p></p><p>维护精确的版本让用户有能力根据他们所能接受的风险级别保持更新。在我们之前的CI/CD工具中，共享任务是从存储库的主分支上拉取的，这意味着我们需要非常小心，以免引入意外的更改。虽然Actions支持这种用法，但最好使用语义版本范围在保持最新和避免破坏性更改之间实现一个平衡。在这里，我们学到的一个关键知识是，确保为每个版本推送/更新多个标签（主标签、次标签和补丁标签），确保跟踪主标签（如“@v2”）的用户也可以获得新的补丁版本。</p><p>&nbsp;</p><p></p><h3>像管理任何其他API一样管理你的接口</h3><p></p><p></p><p>当向内部团队提供资源时，很容易陷入这样的陷阱，即假设他们对内部工作方式的理解比对开源项目或外部供应商的理解更深入。这可能会迅速导致抽象泄漏，降低所提供的共享组件的价值，因为用户必须承担额外的认知负荷，而不仅仅是理解如何与它的API交互。</p><p>&nbsp;</p><p>为了保持更加一致的封装级别，我们的目标是明确我们的<a href=\"https://docs.github.com/en/enterprise-cloud@latest/actions/creating-actions/metadata-syntax-for-github-actions#inputs\">输入</a>\"和<a href=\"https://docs.github.com/en/enterprise-cloud@latest/actions/using-jobs/defining-outputs-for-jobs\">输出</a>\"，尽量减少假设和对环境副作用的依赖。在此基础上，我们一直在尝试提供一个合理的默认值，这样用户就可以专注于提供大多数用例都需要的值。最后，如果使用环境变量，我们建议将它们的范围限制得越窄越好。</p><p>&nbsp;</p><p>例如，如果一个环境变量只在一个步骤中使用，就在这个步骤中声明它，如果在多个步骤中使用，就在作业中声明它，最后，如果在多个作业中使用，就在工作流中声明它。这是一个<a href=\"https://refactoring.com/catalog/reduceScopeOfVariable.html\">通用的建议</a>\"，与平台无关，其目的是降低变量意外修改或命名冲突的风险，并通过将信息保存在使用位置附近来提高可读性。</p><p>&nbsp;</p><p></p><h3>聚焦工作流</h3><p></p><p></p><p>在GitHub Actions生态系统中，人们关注最多的是Actions；毕竟，产品就是以Actions命名的。然而，在铺好的路上，操作不过是砖。它们非常有助于将流程分解为功能步骤，但是，为了向内部交付团队提供最大价值，平台工程师应该投入同样多的时间来开发将这些步骤联系在一起的可重用工作流目录。可重用工作流可以确保不同的步骤按所需的顺序执行，并可以简化设置和拆卸活动。</p><p>&nbsp;</p><p>例如，我们的团队创建了一个将容器部署到Kubernetes环境的操作。为此，需要将环境元数据作为输入的一部分提供。为了更好地管理调用此操作的活动，我们使用工作流来执行一些额外的步骤，收集所需元数据、执行部署，然后将结果添加到输出。但是我们发现，在许多不同的情况下，这个工作流的代码都会重复——针对不同的触发事件，以及不同的部署环境（开发、过渡、生产等）。为了进一步最大化重用，我们将这些工作流重构为单个可重用的工作流，它会根据触发事件确定正确的目的地和镜像上下文。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/10/106ffb6e7655c2a4ef0bf86aa6c68678.jpeg\" /></p><p></p><p>进一步重用：合并3个几乎相同的作业……</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/32/32d58e911cdf0194ff3cae48b22c4137.jpeg\" /></p><p>进入一个可重用工作流</p><p>&nbsp;</p><p></p><h3>降低使用第三方Actions的风险</h3><p></p><p></p><p><a href=\"https://docs.github.com/en/enterprise-cloud@latest/actions/security-guides/security-hardening-for-github-actions\">GitHub的文档</a>\"提供了一些很好的GitHub Actions安全加固通用指南。其中有这样一条警告，“从GitHub上的第三方存储库获取操作存在重大风险”。为此，他们提供了一些指导，即将第三方操作的版本锚定到一个提交SHA，审计操作的源代码，并且只使用你信任的创建者提供的操作。</p><p>&nbsp;</p><p>这给我们造成了一些困难，因为我们已经习惯了由软件组合分析（SCA）工具自动提供适当的外部组件的风险（漏洞/许可）信息，这使得我们在应用程序开发活动中能够更广泛地应用开源组件。</p><p>&nbsp;</p><p>回归手动检查所有外部操作的做法，可能会严重限制开源Actions市场的效用，而这个市场在我们的旅程之初就有这样的承诺。随着供应链攻击的增加，保证管道安全变的至关重要，但手动检查操作源代码和创建者的方法无法扩展，因为我们团队可能对给定操作使用的语言没有深入的了解，而且，当它来自单个用户的贡献时，创建者的可信度就很难评估。</p><p>&nbsp;</p><p>最近，GitHub宣布支持<a href=\"https://github.blog/2022-08-09-dependabot-now-alerts-for-vulnerable-github-actions/\">Actions Dependabot告警</a>\"，这是朝着正确的方向迈出了良好的第一步。然而，这仍然没有达到我们所希望的安全等级，原因如下：</p><p>Dependabot生成的告警很大程度上依赖于创建者自己报告的漏洞。在个人提供的小操作中，尚不清楚他们可能提供何种程度的报告。仍然没有对风险进行基线评估——当用户正在浏览Actions市场时，并没有现成的数据让用户可以了解操作中现有的漏洞或创建者的漏洞管理流程。还有一种风险是，有人故意将恶意代码嵌入到操作中（如果他们是原始作者，则可以在创建操作时嵌入恶意代码，或者通过供应链攻击更隐蔽地嵌入恶意代码)，这种方法无法捕获这类恶意代码。最后，目前许多公司在依赖关系管理方面的最佳实践是内部托管一个存储库，并代理到其他主要的公共存储库（NPM、Maven Central、PyPI等）。对于公司产品使用的依赖项，会有一个内部缓存，为的是可以在<a href=\"https://www.theregister.com/2016/03/23/npm_left_pad_chaos/\">依赖源无法访问</a>\"时帮助确保业务连续性。现在，操作具备了同等的重要性，因为它们对工作管道至关重要，任何中断都可能给开发人员带来大量的时间损失。</p><p>&nbsp;</p><p>为了解决上述限制，我们使用现有的工具开发了一种方法，并结合GitHub设置中的控制项，设法在风险和开发速度之间达到一个平衡。首先，我们允许任何内部编写的操作和任何GitHub编写的操作。下一个通用控制是允许一个经过验证的创建者列表，并允许来自已与我们建立信任关系的组织的所有操作。最后，对于个别来自较小的、未经验证的第三方操作，我们有一个允许列表。</p><p>&nbsp;</p><p>为了加快这些操作的审批过程，我们利用现有的SCA、SAST和容器安全扫描工具来扫描这些操作的存储库和/或容器镜像，将任何潜在的漏洞都暴露出来。</p><p>&nbsp;</p><p>在某些情况下，我们使用的最后一种技术是将操作存储库的副本派生或导入到企业自己的存储库中。这提供了三个保证：</p><p>如果需要，总是有可用的代码；可以修改代码，以便更好地匹配我们自己的用例；可以确保任何更改版本引用的尝试（如更改标签）都不会影响我们。</p><p>&nbsp;</p><p>当然，还需要不断的努力，将源存储库中任何有用的更改或修复都合并到我们自己的版本中，因此，在使用这种方法时应该做好权衡。</p><p>&nbsp;</p><p>GitHub在<a href=\"https://github.com/github/roadmap/issues/592\">他们的路线图</a>\"中也有继续提高操作安全性的计划。显然，这是一个不断发展的领域，我们希望平台和解决方案生态系统的进步可以减少我们对自主开发评估流程的依赖。</p><p>&nbsp;</p><p></p><h3>扩大基础设施实践，紧跟需求步伐</h3><p></p><p></p><p>随着Actions平台应用范围的扩大，提高性能和可靠性成了人们关注的焦点。我们依据运营使用的关键经验扩展了我们的战略。</p><p>&nbsp;</p><p>利用自托管Runner增强弹性</p><p>像许多企业一样，为了满足需求，并帮助管理成本，我们大量使用了自托管runner，使作业可以与我们内部网络上的资源进行通信，从而可以更好地管理runner镜像的工具和设置。</p><p>&nbsp;</p><p>尽管依赖于自托管runner，但我们希望与使用GitHub托管的runner的体验保持一致，即在作业开始时runner已经准备就绪（最小化作业等待runner可用的排队时间），并且将这些runner视为一次性使用的临时实例，最大限度地减少前一次执行留下的更改影响下一作业幂等性的机会。</p><p>&nbsp;</p><p>为次，我们维护了一个一次性runner的暖池——当新作业启动并获取runner时，我们使用一个WebHook来启动下一个runner。这样一来，这个池子就总是能够处理当前的工作量。另外，在每个工作日开始时，我们还使用默认分配的runner来预先填充runner池（然后在晚上关闭它），并随着使用量的增加扩大这个池子。</p><p>&nbsp;</p><p>使用缓存缩短构建时间</p><p>如上所述，我们的runner是一次性的，我们为每个作业提供的运行环境都是干净的。虽然这在构建一致性和隔离方面带来了明显的好处，但那也意味着生成的任何文件后续作业都无法使用，除非它们直接使用像<a href=\"https://docs.github.com/en/enterprise-cloud@latest/actions/using-workflows/storing-workflow-data-as-artifacts\">Artifacts</a>\"这样的特性共享。在这里，我们要克服的主要挑战之一便是花费大量的时间重新生成现有的资源。</p><p>&nbsp;</p><p>幸运的是，在需要共享大量极少变化的数据（如应用程序依赖关系）时，GitHub提供了几种缓存功能。我们需要设法解决的三种最常见的情况是共享应用程序工件、容器镜像和操作镜像。</p><p>&nbsp;</p><p>第一种情况涉及到作业之间使用的应用程序工件和依赖关系。在这种情况下，我们使用<a href=\"https://github.com/actions/cache\">GitHub缓存操作</a>\"迅速提高了工作流的性能。</p><p>&nbsp;</p><p>容器镜像，包括常用的基础镜像层，是第二种最常见的情况。为了缓解经常重新拉取常用镜像的问题，我们研究了<a href=\"https://github.com/docker/build-push-action#inputs\">Docker buildx操作</a>\"支持的<a href=\"https://github.com/moby/buildkit#export-cache\">不同缓存选项</a>\"。我们在大多数镜像构建任务中都使用了这些选项。在对内联缓存、GHA（GitHub Actions缓存）和注册中心缓存选项进行了不同的度量之后，我们目前使用GitHub容器注册中心（GHCR）托管的注册中心缓存取得了最大的成功。</p><p>&nbsp;</p><p>最后，最棘手的是操作镜像。需要理解的一个重要概念是，每次使用打包为镜像的GitHub操作时，都是使用它们的Dockerfile从头开始构建的（有一个替代方案是使用Docker Hub中的公共镜像，但我们不希望公开发布内部操作，所以这并不可行）。</p><p>&nbsp;</p><p>为了减轻这种痛苦，我们遵循通用镜像最佳实践来尽量缩小镜像。不过，我们也在研究将一些作业抽离出来，不再作为容器化操作执行，而是将相同的逻辑打包为预构建的独立镜像，然后将作业配置为在该镜像中运行。然后，作业将执行一个脚本。该脚本通常用作操作的ENTRYPOINT，其行为与在本地作为操作运行时非常相似。这样做的好处是，我们可以拉取一个镜像，而不是每次重新构建每个层，这使得我们可以在runner启动过程中预先拉取常用的镜像，在工作流开始之前缓存它们。</p><p>&nbsp;</p><p></p><h2>GitOps即将来临</h2><p></p><p></p><p>尽管我们提升了操作组合以及工作流的质量和效率，但我们还面临的主要问题之一是，在应用程序部署和运营阶段保持敏捷性和可见性。我们最初的部署方法是将变量替换为参数化模板，使用我们的自定义操作，最终形成一个完整的Kubernetes清单，应用于我们的环境。</p><p>&nbsp;</p><p>这给我们的团队带来了很大的负担，因为我们需要使用复杂的逻辑来处理各种部署风格、重试和部署失败恢复，以及清理过时部署。由于在部署后，包含所有变量的最终清单没有在任何地方持久化，所以部署问题也变得更加难以排查。这也意味着，回滚或升级工件需要重新调用整个流程。</p><p>&nbsp;</p><p>为应对这些挑战，我们再次开始研究如何重塑部署策略，以发挥GitHub CI/CD平台的优势。在重申上述部分经验教训的基础上，我们认识到，我们需要的解决方案应该：</p><p>聚焦于存储库；通过pull请求控制变更；尽量减少自定义部署逻辑。</p><p>&nbsp;</p><p>到此为止，熟悉<a href=\"https://opengitops.dev/\">GitOps</a>\"理念的读者可能开始明白我们的思路了。在GitOps提倡的部署策略中，运行时状态在Git存储库中声明，并由环境中运行的代理自动拉取和协调。</p><p>&nbsp;</p><p>转向GitOps部署模型需要采用新的技术和行为模式，但这使得我们可以利用经开源社区专家优化的部署和协调逻辑，并维护一个清晰、持久、有版本控制的环境变更历史，有一个清晰的路径（拉请求）可以轻松地更改版本，并在需要时保留审批记录。这一切都是基于开发人员现有的熟悉度，也正是这种熟悉度把我们吸引到了GitHub。</p><p>&nbsp;</p><p>我们正处于这一转变的早期阶段，但很高兴我们采取了下一步措施，为我们的客户提供了更好、更可靠的价值交付方式。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/enterprise-github-actions/\">https://www.infoq.com/articles/enterprise-github-actions/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/TTDS1pC6Cz6MRqJTpMir\">为什么说可观察性是解锁&nbsp;GitOps&nbsp;的关键</a>\"</p><p><a href=\"https://www.infoq.cn/article/E2Nk6iYClH4RL8aNCRDB\">GitOps&nbsp;是皇帝的新衣吗？</a>\"</p><p><a href=\"https://www.infoq.cn/article/UMsJHeW2ZWEcF6uUMstQ\">最全的&nbsp;GitOps&nbsp;工具选型，30+ 款工具随你挑</a>\"</p><p></p>",
    "publish_time": "2023-03-23 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Java JVM 可观测的原理解释和落地方案对比",
    "url": "https://www.infoq.cn/article/3iwV28HezCgCyPdFMWSd",
    "summary": "<p></p><h2>如何监控 JVM</h2><p></p><p></p><p>云原生时代，我们使用 Prometheus 来作为可观测平台的指标监控的核心组件。监控一个云原生的 Java 应用，一般会分成 3 个步骤：</p><p></p><p>配置 Java 应用，暴露 JVM 指标信息通过 Prometheus 采集并存储指标数据通过 Grafana 的 Dashboard 展示采集到的指标</p><p></p><p>借力社区生态，我们有越来越丰富的方式来暴露 JVM 核心指标，文本将介绍 JVM 监控的基本原理，并重点介绍常见的 3 种暴露 JVM 指标的方案，可以根据读者的使用场景来选择。</p><p></p><p></p><h2>采集原理</h2><p></p><p></p><p>Java Management Extensions（JMX）技术是 Java SE 平台的标准功能，提供了一种简单的、标准的监控和管理资源的方式，对于如何定义一个资源给出了明确的结构和设计模式，主要用于监控和管理 Java 应用程序运行状态、设备和资源信息、Java 虚拟机运行情况等信息。并且如下图所示，有关应用程序性能和资源使用情况的详细信息可以从 JMX 指标中导出。如果有任何问题，我们可以借助收集的指标进行诊断，并对系统进行微调以获得最佳性能。JMX 是可以动态的，所以也可以在资源创建、安装、实现时进行动态监控和管理，JDK 自带的 jconsole 就是使用 JMX 技术实现的监控工具。图片: </p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a2/a21d967f0b6210b412675b2a82902a5d.png\" /></p><p></p><p>使用 JMX 技术时，通过定义一个被称为 MBean 或 MXBean 的 Java 对象来表示要管理指定的资源，然后可以把资源信息注册到 MBean Server 对外提供服务。MBean Server 充当了对外提供服务和对内管理 MBean 资源的代理功能，如此优雅的设计让 MBean 资源管理和 MBean Server 代理完全独立开，使之可以自由的控制 MBean 资源信息。</p><p></p><p>JMX 不仅仅用于本地管理，JMX Remote API 为 JMX 添加了远程功能，使之可以通过网络远程监视和管理应用程序。得益于相对独立的架构设计，使 JMX 可以平滑的集成到各种监控系统之中。并具有包括遵守 Java 规范、通用的管理方式、开箱即用的监控功能、架构设计优秀、监测 JVM 状态能力、管理解决方案集成的能力等优点。</p><p></p><p>JMX 技术架构主要有资源管理（MBean/MXBean）模块，资源代理模块（MBean Server），远程管理模块（Remote API）组成 ，下面的图片来自维基百科，很好的展示了三个模块之间的关系。图片: </p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f9/f9e211a9aeb92e0251b093c2365b4e97.png\" /></p><p></p><p>资源管理在架构中标识为资源探测层（Probe Level），在 JMX 中， 使用 MBean 或 MXBean 来表示一个资源（下面简称 MBean），访问和管理资源也都是通过 MBean。</p><p></p><p>JMX 已经对 JVM 进行了多维度资源检测，所以可以轻松启动 JMX 代理来访问内置的 JVM 资源检测，从而通过 JMX 技术远程监控和管理 JVM。JMX 内置了常用的 JVM 资源监测类，包括但不限于：类加载、垃圾收集、日志系统、内存池、内存、内存系统、操作系统、运行时系统和线程系统。</p><p></p><p>以下代码演示了如何使用原生 JMX 接口获取 JVM 指标：</p><p><code lang=\"text\">package org.example.jmx;\n\nimport java.lang.management.CompilationMXBean;\nimport java.lang.management.GarbageCollectorMXBean;\nimport java.lang.management.ManagementFactory;\nimport java.lang.management.MemoryMXBean;\nimport java.lang.management.MemoryManagerMXBean;\nimport java.lang.management.MemoryUsage;\nimport java.lang.management.OperatingSystemMXBean;\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.stream.Collectors;\n\npublic class Main {\n\n    public static void main(String[] args) {\n        printOSInfo();\n        System.out.println(\"================\");\n        printMemoryManagerInfo();\n        System.out.println(\"================\");\n        printGCInfo();\n    }\n\n    //通过 OperatingSystemMXBean 获取 OS 信息\n    public static void printOSInfo() {\n        OperatingSystemMXBean operatingSystemMXBean = ManagementFactory.getOperatingSystemMXBean();\n        String osName = operatingSystemMXBean.getName();\n        String osVersion = operatingSystemMXBean.getVersion();\n        int processors = operatingSystemMXBean.getAvailableProcessors();\n        System.out.println(String.format(\"OS：%s，Version：%s，CPU：%d 个\", osName, osVersion, processors));\n\n        CompilationMXBean compilationMXBean = ManagementFactory.getCompilationMXBean();\n        String compilationMXBeanName = compilationMXBean.getName();\n        System.out.println(\"编译系统：\" + compilationMXBeanName);\n\n        MemoryMXBean memoryMXBean = ManagementFactory.getMemoryMXBean();\n        MemoryUsage heapMemoryUsage = memoryMXBean.getHeapMemoryUsage();\n        long max = heapMemoryUsage.getMax();\n        long used = heapMemoryUsage.getUsed();\n        System.out.println(String.format(\"使用内存：%dMB/%dMB\", used / 1024 / 1024, max / 1024 / 1024));\n\n        List gcMXBeans = ManagementFactory.getGarbageCollectorMXBeans();\n        String gcNames = gcMXBeans.stream()\n                                  .map(MemoryManagerMXBean::getName)\n                                  .collect(Collectors.joining(\",\"));\n        System.out.println(\"垃圾收集器：\" + gcNames);\n    }\n\n    // 通过 MemoryManagerMXBean 获取 JVM 内存管理器信息\n    public static void printMemoryManagerInfo() {\n        List managers = ManagementFactory.getMemoryManagerMXBeans();\n        if (managers != null &amp;&amp; !managers.isEmpty()) {\n            for (MemoryManagerMXBean manager : managers) {\n                System.out.println(\"vm内存管理器：名称=\" + manager.getName() + \",管理的内存区=\"\n                                       + Arrays.deepToString(\n                    manager.getMemoryPoolNames()) + \",ObjectName=\" + manager.getObjectName());\n            }\n        }\n    }\n\n    //通过 GarbageCollectorMXBean 获取 JVM GC 信息\n    public static void printGCInfo() {\n        try {\n            List gcMxBeans = ManagementFactory.getGarbageCollectorMXBeans();\n\n            for (GarbageCollectorMXBean gcMxBean : gcMxBeans) {\n                System.out.println(gcMxBean.getName());\n                System.out.println(gcMxBean.getObjectName());\n            }\n\n        } catch (RuntimeException re) {\n            throw re;\n        } catch (Exception exp) {\n            throw new RuntimeException(exp);\n        }\n    }\n}</code></p><p></p><p>以上代码运行结果如下：</p><p></p><p><code lang=\"text\">OS：Mac OS X，Version：10.16，CPU：8 个\n编译系统：HotSpot 64-Bit Tiered Compilers\n使用内存：4MB/4096MB\n垃圾收集器：G1 Young Generation,G1 Old Generation\n================\nvm内存管理器：名称=CodeCacheManager,管理的内存区=[CodeHeap 'non-nmethods', CodeHeap 'profiled nmethods', CodeHeap 'non-profiled nmethods'],ObjectName=java.lang:type=MemoryManager,name=CodeCacheManager\nvm内存管理器：名称=Metaspace Manager,管理的内存区=[Metaspace, Compressed Class Space],ObjectName=java.lang:type=MemoryManager,name=Metaspace Manager\nvm内存管理器：名称=G1 Young Generation,管理的内存区=[G1 Eden Space, G1 Survivor Space, G1 Old Gen],ObjectName=java.lang:type=GarbageCollector,name=G1 Young Generation\nvm内存管理器：名称=G1 Old Generation,管理的内存区=[G1 Eden Space, G1 Survivor Space, G1 Old Gen],ObjectName=java.lang:type=GarbageCollector,name=G1 Old Generation\n================\nG1 Young Generation\njava.lang:type=GarbageCollector,name=G1 Young Generation\nG1 Old Generation\njava.lang:type=GarbageCollector,name=G1 Old Generation</code></p><p></p><p></p><h3>常见开源暴露 JVM 指标工具</h3><p></p><p></p><p>通过原生 JMX 获取 JVM 指标，并能够被我们的可观测性系统采集到工作量还是很大。以下，列举了常见的几款开箱即用的工具：</p><p></p><p></p><h4>Micrometer/Spring Boot Actuator</h4><p></p><p></p><p>Spring Boot Actuator 模块提供了生产级别的功能，比如健康检查，审计，指标收集，HTTP 跟踪等，帮助我们监控和管理Spring Boot 应用。这个模块是一个采集应用内部信息暴露给外部的模块，上述的功能都可以通过HTTP 和 JMX 访问。Spring Boot Actuator 使用 Micrometer 与这些外部应用程序监视系统集成，Spring Boot 应用只需很少的配置即可轻松集成外部的监控系统。</p><p></p><p>以下是 Micrometer 官方介绍：</p><p></p><p>Micrometer provides a simple facade over the instrumentation clients for the most popular observability systems, allowing you to instrument your JVM-based application code without vendor lock-in. Think SLF4J, but for application observability! Data recorded by Micrometer are intended to be used to observe, alert, and react to the current/recent operational state of your environment.</p><p></p><p>在 pom.xml 中添加如下依赖：</p><p><code lang=\"text\">\n   org.springframework.boot\n   spring-boot-starter-actuator\n \n \n   io.micrometer\n   micrometer-registry-prometheus\n   runtime\n </code></p><p></p><p>在 src/main/resources/application.properties 中添加相关配置</p><p></p><p><code lang=\"text\">management.endpoints.web.exposure.include=*\nmanagement.endpoints.web.exposure.include=prometheus,health,info,metric\nmanagement.endpoints.web.base-path=/\n\nmanagement.server.port=8999\nmanagement.health.probes.enabled=true\nmanagement.endpoint.health.show-details=always\nmanagement.endpoint.prometheus.enabled=true</code></p><p></p><p>重新构建并运行服务</p><p></p><p>运行服务之后，我们可以通过 http://lcoalhost:8999/prometheus 访问服务暴露出来的 OpenMetrics 格式的指标。同时，该接口也能被 prometheus 抓取并收集指标， prometheus.yaml 配置文件参考如下:</p><p></p><p><code lang=\"text\">prometheus:\n config:\n   scrape_configs:\n     - job_name: \"jvm-metrics\"\n       scrape_interval: 10s\n       metrics_path: \"/prometheus\"\n       static_configs:\n         - targets: [\"\"]</code></p><p></p><h4>Prometheus JMX Exporter</h4><p></p><p></p><p>JMX-Exporter 主要通过连接到 Java 原生指标收集系统 JMX，并将指标转换为 Prometheus 可以理解的格式。JMX-Exporter 提供了两种采集并暴露指标的用法:</p><p></p><p>启动独立进程。JVM 启动时指定参数，暴露 JMX 的 RMI 接口，JMX-Exporter 调用 RMI 获取 JVM 运行时状态数据，转换为 Prometheus metrics 格式，并暴露端口让 Prometheus 采集JVM 进程内启动(in-process)。JVM 启动时指定参数，通过 javaagent 的形式运行 JMX-Exporter 的 jar 包，进程内读取 JVM 运行时状态数据，转换为 Prometheus metrics 格式，并暴露端口让 Prometheus 采集。</p><p></p><p>官方不推荐使用第一种方式，一方面配置复杂，另一方面因为它需要一个单独的进程，而这个进程本身的监控又成了新的问题，所以本文重点围绕第二种用法以及如何在 Kubernetes 环境下使用 JMX Exporter 暴露 JVM 监控指标。</p><p></p><p>由于在应用启动时要通过 javaagent 指定 jmx exporter Jar 包，因此，我们需要考虑启动时如何让 JVM 正确的找到 jmx exporter Jar 包。以下列举了两种方式：</p><p></p><p>在构建应用镜像时将 JAR 文件打进镜像</p><p></p><p>根据 JMX EXporter 官方介绍，需要为其指定配置文件，需要提前创建好 prometheus-jmx-config.yaml , 更多配置项请参考官方文档， 以下内容仅供参考：</p><p></p><p><code lang=\"text\">lowercaseOutputLabelNames: true\nlowercaseOutputName: true\nwhitelistObjectNames: [\"java.lang:type=OperatingSystem\"]\nblacklistObjectNames: []\nrules:\n  - pattern: 'java.lang&lt;&gt;(committed_virtual_memory|free_physical_memory|free_swap_space|total_physical_memory|total_swap_space)_size:'\n    name: os_$1_bytes\n    type: GAUGE\n    attrNameSnakeCase: true\n  - pattern: 'java.lang&lt;&gt;((?!process_cpu_time)\\w+):'\n    name: os_$1\n    type: GAUGE\n    attrNameSnakeCase: true</code></p><p></p><p>通过在应用 Dockerfile 中将 JAR 拷贝进镜像或者在线下载 JAR 文件实现，以下 Dockerfile 仅供参考：</p><p></p><p><code lang=\"text\">FROM openjdk:11.0.15-jre\n\nWORKDIR /app/\n\nCOPY target/my-app.jar ./\n# 将前面创建的 config 文件拷贝至镜像\nCOPY prometheus-jmx-config.yaml ./\n\n# 在线下载 jmx prometheus javaagent jar\nRUN set -ex; \\\n    curl -L -O https://repo1.maven.org/maven2/io/prometheus/jmx/jmx_prometheus_javaagent/0.17.2/jmx_prometheus_javaagent-0.17.2.jar;\n\n# JAVA_TOOL_OPTIONS 会被 JVM 调用\nENV JAVA_TOOL_OPTIONS=-javaagent:/app/jmx_prometheus_javaagent-0.17.2.jar=8088:/app/prometheus-jmx-config.yaml\n\nEXPOSE 8081 8999 8080 8888\n\nENTRYPOINT java $JAVA_OPTS -jar my-app.jar</code></p><p></p><p>b.  通过 Kubernetes Init Container 在应用启动之前将 JAR 文件挂载进容器</p><p></p><p>我们需要先将 JMX exporter  做成 Docker 镜像, 以下 Dockerfile 仅供参考：</p><p></p><p><code lang=\"text\">FROM alpine/curl:3.14\n\nWORKDIR /app/\n# 将前面创建的 config 文件拷贝至镜像\nCOPY prometheus-jmx-config.yaml ./\n\n# 在线下载 jmx prometheus javaagent jar\nRUN set -ex; \\\n    curl -L -O https://repo1.maven.org/maven2/io/prometheus/jmx/jmx_prometheus_javaagent/0.17.2/jmx_prometheus_javaagent-0.17.2.jar;</code></p><p></p><p>根据上面 Dockerfile 构建镜像：docker build -t my-jmx-exporter .</p><p></p><p>在 kubernetes 编排文件中使用该镜像，并将 JAR 通过共享目录挂载进容器：</p><p><code lang=\"text\">apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-demo-app\n  labels:\n    app: my-demo-app\nspec:\n  selector:\n    matchLabels:\n      app: my-demo-app\n  template:\n    metadata:\n      labels:\n        app: my-demo-app\n    spec:\n      imagePullSecrets:\n      - name: registry-pull\n      initContainers:\n      - name: jmx-sidecar\n        image: my-jmx-exporter\n        command: [\"cp\", \"-r\", \"/app/jmx_prometheus_javaagent-0.17.2.jar\", \"/target/jmx_prometheus_javaagent-0.17.2.jar\"]  ➊\n        volumeMounts:\n        - name: sidecar\n          mountPath: /target\n      containers:\n      - image: my-demo-app-image\n        name: my-demo-app\n        resources:\n          requests:\n            memory: \"1000Mi\"\n            cpu: \"500m\"\n          limits:\n            memory: \"1000Mi\"\n            cpu: \"500m\"\n        ports:\n        - containerPort: 18083\n        env:\n        - name: JAVA_TOOL_OPTIONS\n          value: \"-javaagent:/app/jmx_prometheus_javaagent-0.17.2.jar=8088:/app/prometheus-jmx-config.yaml\" ➋\n        volumeMounts:\n        - name: host-time\n          mountPath: /etc/localtime\n          readOnly: true\n        - name: sidecar\n          mountPath: /sidecar\n      volumes:\n      - name: host-time\n        hostPath:\n          path: /etc/localtime\n      - name: sidecar  #共享agent文件夹\n        emptyDir: {}\n      restartPolicy: Always</code></p><p></p><p>经过如上的改造之后， my-demo-app 具备了暴露 JVM 指标的能力，运行服务之后，我们可以通过 http://lcoalhost:8088 访问服务暴露出来的 prometheus 格式的指标。</p><p></p><p>同时，该接口也能被 prometheus 抓取并收集指标， prometheus.yaml 配置文件参考如下:</p><p><code lang=\"text\">prometheus:\n config:\n   scrape_configs:\n     - job_name: \"jvm-metrics\"\n       scrape_interval: 10s\n       metrics_path: \"/\"\n       static_configs:\n         - targets: [\"IP of the demo app:8088&gt;\"]\n</code></p><p></p><p></p><h3>OpenTelemetry Java Agent</h3><p></p><p></p><p>在 Opentelemetry Agent v1.20.0 及以上版本中，Opentelemetry Agent 新增了 JMX Metric Insight 模块，如果你的应用已经集成了 Opentelemetry Agent 去采集应用链路，那么你不再需要另外引入其他 Agent 去为我们的应用暴露 JMX 指标。Opentelemetry Agent 也是通过检测应用程序中本地可用的 MBean 公开的指标，对其进行收集并暴露指标。</p><p></p><p>Opentelemetry Agent 也针对常见的 Java Server 或框架内置了一些监控的样例，请参考 预定义的指标。</p><p></p><p>使用 OpenTelemetry Java Agent 同样需要考虑如何将 JAR 挂载进容器，除了可以参考上面 JMX Exporter 挂载 JAR 文件的方式外，我们还可以借助 Opentelemetry 提供的 Operator 的能力来实现自动为我们的应用开启 JVM 指标暴露：</p><p></p><p>在 Kubernetes 中安装 Opentelemetry Operator</p><p><code lang=\"text\">kubectl apply -f https://github.com/open-telemetry/opentelemetry-operator/releases/latest/download/opentelemetry-operator.yaml</code></p><p></p><p>安装 Instrumentations 资源</p><p></p><p>一旦上面的 operator 安装就绪之后，我们就可以使用其内置的 Instrumentations 资源，如下文件告诉了 Operator 后续为我们应用注入 sidecar 的时候的一些差异化行为，比如文件中针对 Java 应用定义了两个环境变量，该环境变量是将 Opentelemetry Java Agent 的指标以 Prometheus 导出器将指标通过 9464 端口暴露出来。</p><p><code lang=\"text\">kubectl apply -f - &lt;<=\"\" code=\"\"></code></p><p></p><p><code lang=\"text\">为应用注入 sidecar</code></p><p></p><p><code lang=\"text\">上面我们创建了一个 Instrumentation 资源，只是申明了 Operator 注入 sidecar 的时候的模版，我们还得需要告诉 Operator 哪些应用需要注入这个 sidecar。假设需要给名字为 my-demo-app 的 Deployment 注入 sidecar，需要在 spec.annotations 下添加 instrumentation.opentelemetry.io/inject-java: \"default/opentelemetry-autoinstrumentation\"注解：</code></p><p><code lang=\"text\"><code lang=\"text\">apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-demo-app\n  labels:\n    app: my-demo-app\nspec:\n  selector:\n    matchLabels:\n      app: my-demo-app\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: my-demo-app\n      annotations:\n# 在 spec.annotations 下添加该注解\n        instrumentation.opentelemetry.io/inject-java: \"default/opentelemetry-autoinstrumentation\"\n    spec:\n      containers:\n      - name: my-demo-app\n        image: my-jmx-exporter\n        ports:\n          - containerPort: 8080\n            protocol: TCP</code></code></p><p></p><p><code lang=\"text\">最终生成的 YAML 内容如下：</code></p><p><code lang=\"text\"><code lang=\"text\">apiVersion: v1\nkind: Pod\nmetadata:\n  name: my-demo-app-565bd877dd-nqkk6\n  generateName: my-demo-app-565bd877dd-\n  namespace: default\n  uid: aa89ca0d-620c-4d20-8bc1-37d67bad4ea4\n  resourceVersion: '2668986'\n  creationTimestamp: '2022-04-08T05:58:48Z'\n  labels:\n    app: my-demo-app\n    pod-template-hash: 565bd877dd\n  annotations:\n    instrumentation.opentelemetry.io/inject-java: 'true'\n    sidecar.opentelemetry.io/inject: 'false'\nspec:\n  volumes:\n    - name: opentelemetry-auto-instrumentation\n      emptyDir: {}\n  initContainers:\n    - name: opentelemetry-auto-instrumentation\n      image: &gt;-\n        ghcr.io/open-telemetry/opentelemetry-operator/autoinstrumentation-java\n      command:\n        - cp\n        - /javaagent.jar\n        - /otel-auto-instrumentation/javaagent.jar\n      volumeMounts:\n        - name: opentelemetry-auto-instrumentation\n          mountPath: /otel-auto-instrumentation\n  containers:\n    - name: my-demo-app\n      image: my-jmx-exporter\n      env:\n- name: OTEL_METRICS_EXPORTER\n        value: \"prometheus\"\n      - name: OTEL_METRICS_EXPORTER_PORT\n        value: \"9464\"\n        - name: JAVA_TOOL_OPTIONS\n          value: ' -javaagent:/otel-auto-instrumentation/javaagent.jar'\n        - name: OTEL_TRACES_EXPORTER\n          value: otlp\n        - name: OTEL_EXPORTER_OTLP_ENDPOINT\n          value: http://opentelemetry-collector.svc.cluster.local:4317\n        - name: OTEL_SERVICE_NAME\n          value: my-demo-app\n        - name: OTEL_RESOURCE_ATTRIBUTES_POD_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.name\n        - name: OTEL_RESOURCE_ATTRIBUTES_POD_UID\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.uid\n        - name: OTEL_RESOURCE_ATTRIBUTES_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: OTEL_RESOURCE_ATTRIBUTES\n          value: &gt;-\n            k8s.container.name=my-demo-app,k8s.deployment.name=my-demo-app,k8s.deployment.uid=8de6929d-dda0-436c-bca1-604e9ca7ea4e,k8s.namespace.name=default,k8s.node.name=$(OTEL_RESOURCE_ATTRIBUTES_NODE_NAME),k8s.pod.name=$(OTEL_RESOURCE_ATTRIBUTES_POD_NAME),k8s.pod.uid=$(OTEL_RESOURCE_ATTRIBUTES_POD_UID),k8s.replicaset.name=my-deployment-with-sidecar-565bd877dd,k8s.replicaset.uid=190d5f6e-ba7f-4794-b2e6-390b5879a6c4\n        - name: OTEL_PROPAGATORS\n          value: jaeger,b3\n      volumeMounts:\n        - name: opentelemetry-auto-instrumentation\n          mountPath: /otel-auto-instrumentation\n      terminationMessagePath: /dev/termination-log\n      terminationMessagePolicy: File\n      imagePullPolicy: Always\n  restartPolicy: Always\n  securityContext:\n    runAsUser: 1000\n    runAsGroup: 3000\n    fsGroup: 2000\n</code></code></p><p></p><p><code lang=\"text\">经过如上的改造之后， my-demo-app 具备了暴露 JVM 指标的能力，运行服务之后，我们可以通过 http://lcoalhost:9464 访问服务暴露出来的 prometheus 格式的指标。同时，该接口也能被 prometheus 抓取并收集指标， prometheus.yaml 配置文件参考如下:</code></p><p><code lang=\"text\"><code lang=\"text\">prometheus:\n config:\n   scrape_configs:\n     - job_name: \"otel-jvm-metrics\"\n       scrape_interval: 10s\n       metrics_path: \"/\"\n       static_configs:\n         - targets: [\"<=\"\" code=\"\"></code></code></p><p></p><p></p><h2><code lang=\"text\"><code lang=\"text\">使用 Prometheus 和 Grafana 统一 监控 JVM</code></code></h2><p></p><p></p><p><code lang=\"text\"><code lang=\"text\">前面介绍了几种开源暴露 JVM 指标的工具，通过上面几款工具，可以使我们的 Java 应用具备 JVM 暴露能力，接下来我们就需要考虑如何将这些指标集中采集存储并展示分析。本文主要介绍 Prometheus 和 Grafana 的方案并以使用 Opentelemetry Java Agent 作为 JVM 指标暴露为例：</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">查看 Java 应用运行日志，加载 OTEL Agent：</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\"><img src=\"https://static001.geekbang.org/infoq/be/be8e4d543308f917f48cce72340052f3.png\" /></code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">以下 Prometheus Scrape 抓取指标配置文件，与前面 Opentelemetry Java Agent 章节末尾提供的 prometheus.yaml 配置文件一致 ：</code></code></p><p><code lang=\"text\"><code lang=\"text\"><code lang=\"text\">prometheus:\n config:\n   scrape_configs:\n     - job_name: \"otel-jvm-metrics\"\n       scrape_interval: 10s\n       metrics_path: \"/\"\n       static_configs:\n         - targets: [\"\"]</code></code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">以下是 OTEL Java Agent 通过 JMX 采集并暴露出来的部分指标：</code></code></p><p><code lang=\"text\"><code lang=\"text\"><code lang=\"text\"># TYPE target info\n# HELP target Target metadata\ntarget_info{container_id=\"3da5e8bc10cf207f01e0373a82c7bb3f7b8c430a757b6412f2199967a7971f9a\",host_arch=\"amd64\",host_name=\"3da5e8bc10cf\",os_description=\"Linux 5.10.104-linuxkit\",os_type=\"linux\",process_command_line=\"/usr/local/openjdk-11/bin/java -javaagent:/app/opentelemetry-javaagent.jar -Dspring.cloud.nacos.config.enabled=false -Dspring.randomError=false -Dotel.jmx.config=/app/jmx_config_file.yaml -Dotel.metrics.exporter=prometheus -Dotel.exporter.prometheus.port=9464\",process_executable_path=\"/usr/local/openjdk-11/bin/java\",process_pid=\"7\",process_runtime_description=\"Oracle Corporation OpenJDK 64-Bit Server VM 11.0.15+10\",process_runtime_name=\"OpenJDK Runtime Environment\",process_runtime_version=\"11.0.15+10\",service_name=\"adservice-springcloud\",telemetry_auto_version=\"1.22.1\",telemetry_sdk_language=\"java\",telemetry_sdk_name=\"opentelemetry\",telemetry_sdk_version=\"1.22.0\"} 1\n# TYPE otel_scope_info info\n# HELP otel_scope_info Scope metadata\notel_scope_info{otel_scope_name=\"io.opentelemetry.micrometer-1.5\"} 1\n# TYPE otel_scope_info info\n# HELP otel_scope_info Scope metadata\notel_scope_info{otel_scope_name=\"io.opentelemetry.runtime-metrics\",otel_scope_version=\"1.22.1-alpha\"} 1\n# TYPE executor_pool_core gauge\n# HELP executor_pool_core The core number of threads for the pool\nexecutor_pool_core{otel_scope_name=\"io.opentelemetry.micrometer-1.5\",name=\"applicationTaskExecutor\"} 8.0 1676368076291\n# TYPE logback_events_total counter\n# HELP logback_events_total Number of events that made it to the logs\nlogback_events_total{otel_scope_name=\"io.opentelemetry.micrometer-1.5\",level=\"info\"} 12.0 1676368076291\nlogback_events_total{otel_scope_name=\"io.opentelemetry.micrometer-1.5\",level=\"warn\"} 3.0 1676368076291\n# TYPE jvm_gc_live_data_size gauge\n# HELP jvm_gc_live_data_size Size of long-lived heap memory pool after reclamation\njvm_gc_live_data_size{otel_scope_name=\"io.opentelemetry.micrometer-1.5\"} 2.7941376E7 1676368076291\n# TYPE executor_pool_max gauge\n# HELP executor_pool_max The maximum allowed number of threads in the pool\nexecutor_pool_max{otel_scope_name=\"io.opentelemetry.micrometer-1.5\",name=\"applicationTaskExecutor\"} 2.147483647E9 1676368076291\n# TYPE disk_total gauge\n# HELP disk_total Total space for path\ndisk_total{otel_scope_name=\"io.opentelemetry.micrometer-1.5\",path=\"/app/.\"} 4.2006183936E10 1676368076291\n# TYPE executor_active gauge\n# HELP executor_active The approximate number of threads that are actively executing tasks\nexecutor_active{otel_scope_name=\"io.opentelemetry.micrometer-1.5\",name=\"applicationTaskExecutor\"} 0.0 1676368076291\n# TYPE disk_free gauge\n# HELP disk_free Usable space for path\ndisk_free{otel_scope_name=\"io.opentelemetry.micrometer-1.5\",path=\"/app/.\"} 1.8299908096E10 1676368076291\n# TYPE system_cpu_count gauge\n# HELP system_cpu_count The number of processors available to the Java virtual machine\nsystem_cpu_count{otel_scope_name=\"io.opentelemetry.micrometer-1.5\"} 2.0 1676368076291\n# TYPE jvm_memory_committed gauge\n# HELP jvm_memory_committed The amount of memory in bytes that is committed for the Java virtual machine to use\njvm_memory_committed{otel_scope_name=\"io.opentelemetry.micrometer-1.5\",area=\"heap\",id=\"G1 Old Gen\"} 6.6060288E7 1676368076291\njvm_memory_committed{otel_scope_name=\"io.opentelemetry.micrometer-1.5\",area=\"nonheap\",id=\"Compressed Class Space\"} 9175040.0 1676368076291\njvm_memory_committed{otel_scope_name=\"io.opentelemetry.micrometer-1.5\",area=\"nonheap\",id=\"CodeHeap 'non-profiled nmethods'\"} 4653056.0 1676368076291\njvm_memory_committed{otel_scope_name=\"io.opentelemetry.micrometer-1.5\",area=\"nonheap\",id=\"CodeHeap 'profiled nmethods'\"} 1.8087936E7 1676368076291\njvm_memory_committed{otel_scope_name=\"io.opentelemetry.micrometer-1.5\",area=\"nonheap\",id=\"Metaspace\"} 6.422528E7 1676368076291\njvm_memory_committed{otel_scope_name=\"io.opentelemetry.micrometer-1.5\",area=\"heap\",id=\"G1 Survivor Space\"} 7340032.0 1676368076291\njvm_memory_committed{otel_scope_name=\"io.opentelemetry.micrometer-1.5\",area=\"heap\",id=\"G1 Eden Space\"} 1.00663296E8 1676368076291\njvm_memory_committed{otel_scope_name=\"io.opentelemetry.micrometer-1.5\",area=\"nonheap\",id=\"CodeHeap 'non-nmethods'\"} 2555904.0 1676368076291\n......</code></code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">在 Grafana 中导入 Opentelemetry JVM Metrics DashBoard( ID=8563 ）</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">DashBoard 根据 Prometheus 采集到的指标，绘制出了我们常用的一些指标面板，比如 CPU 和内存负载情况，线程运行状况等等，也可以基于该 DashBoard 进行自定义。图片: h</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\"><img src=\"https://static001.geekbang.org/infoq/7a/7ab42060dea9e0f1c58072c8e3300e09.png\" /></code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\"><img src=\"https://static001.geekbang.org/infoq/a5/a5531b9052ac8be170d289fd44ffc231.png\" /></code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\"><img src=\"https://static001.geekbang.org/infoq/eb/eb6e5a87d7e75b28dc1680139367de85.png\" /></code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\"><img src=\"https://static001.geekbang.org/infoq/7b/7b03aef32d88ae14502273a3e32880c5.png\" /></code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">该部分的 Demo 文件可以参考底部参考部分的 jmx-jvm-demo</code></code></p><p></p><p></p><h2><code lang=\"text\"><code lang=\"text\">总结：</code></code></h2><p></p><p></p><p><code lang=\"text\"><code lang=\"text\">本文介绍了 JVM 监控的技术原理，同时介绍了常见的几种开源暴露 JVM 指标的工具。从接入方式来看主要分为两类，第一类是像 Spring Boot Actuator 需要客户应用做一些改造的方式，另一类是 JMX Exporter 和 Opentelemetry Java Agent 无侵入的方式。</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">以下针对这三种方案进行了多维度比较：</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\"><img src=\"https://static001.geekbang.org/infoq/ed/ed86dc4b41132879dc251ffd4f82bc00.png\" /></code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">可以根据业务自身情况选择使用哪一种方式，针对运行在非容器平台的 Spring Boot 应用，建议选择 Spring Boot Actuator 方式，该方式能够更好的和 Spring Boot 生态集成。</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">如果业务应用运行在容器平台，建议选择 Opentelemetry Java Agent 的方式，该方式支持 Operator 的方式，能够以最小代价对 Java 应用进行监控，同时也方便后续对 Agent 版本的升级与运维。如果应用目前已经通过 Opentelemetry Java Agent 实现了链路采集，那么更加建议使用 Operator 云原生的方式。</code></code></p><p></p><p></p><h2><code lang=\"text\"><code lang=\"text\">参考：</code></code></h2><p></p><p></p><p><code lang=\"text\"><code lang=\"text\">jmx demo (https://gist.github.com/JaredTan95/8711878369b9b12c772dd783a21c621d)</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">Micrometer (https://micrometer.io/)</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">Spring Boot Actuator (https://github.com/spring-projects/spring-boot/tree/main/spring-boot-project/spring-boot-actuator)</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">Prometheus JMX Exporter (https://github.com/prometheus/jmx_exporter)</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">Zabbix JMX （https://www.zabbix.com/integrations/java_monitoring）</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">OpenTelemetry Java Agent(https://opentelemetry.io/blog/2023/jmx-metric-insight/)</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">JMX Metric Insight (https://github.com/open-telemetry/opentelemetry-java-instrumentation/blob/main/instrumentation/jmx-metrics/javaagent/README.md)</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">Opentelemetry Operator (https://github.com/open-telemetry/opentelemetry-operator)</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">jmx-jvm-demo (https://github.com/openinsight-proj/jmx-jvm-demo)</code></code></p><p></p><p></p><h3><code lang=\"text\"><code lang=\"text\">作者介绍</code></code></h3><p></p><p></p><p><code lang=\"text\"><code lang=\"text\">谭建，「DaoCloud 」可观测性技术专家。负责研发新一代云原生操作系统底座，DCE 5.0 社区版 https://docs.daocloud.io/download/dce5/</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\">欢迎大家关注“OpenTelemetry” 公众号，这是中国区唯一官方技术公众号想加入技术社群和参与活动的朋友联系我</code></code></p><p></p><p><code lang=\"text\"><code lang=\"text\"><img src=\"https://static001.geekbang.org/infoq/95/9557c5bef779936148762d7141c30d44.png\" /></code></code></p><p></p>",
    "publish_time": "2023-03-23 09:12:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Alluxio跨集群同步机制的设计与实现",
    "url": "https://www.infoq.cn/article/5kCy7S0627JVJyP63uLk",
    "summary": "<p></p><h2>一、Alluxio 应用场景和背景</h2><p></p><p></p><p>Alluxio 跨集群同步机制的设计和实现确保了在运行多个 Alluxio 集群时，元数据是一致的。</p><p></p><p>Alluxio 位于存储和计算层之间，在不同的底层文件系统（UFS）上层提供高性能缓存和统一的命名空间。虽然通过 Alluxio 对 UFS 进行更新可使 Alluxio 与 UFS 保持一致，但在某些情况下, 例如在运行多个共享某一个或多个 UFS 命名空间的 Alluxio 集群时，结果可能并非如此。为了确保这种情况下的一致性，Alluxio 已经实现了跨集群同步机制，本文将对该机制进行详细介绍。</p><p></p><h3>1. 背景介绍</h3><p></p><p></p><p>随着数据量的增长，这些数据的存储和访问方式也变得越来越复杂。例如，数据可能位于不同的存储系统中（S3、GCP、HDFS 等），也可能存储在云上或本地，或是位于不同的地理区域，还可能因为隐私或安全保护，被进一步隔离。此外，这些复杂性不仅体现在数据存储上，还包括如何将数据用于计算，例如，数据可能存储在云上，而计算则在本地进行。</p><p></p><p>Alluxio 是一个数据编排平台，通过在 UFS 上提供统一的访问接口来降低此类复杂性，并通过提供数据本地性和缓存来提高计算性能。</p><p></p><p>对于许多组织而言，运行一个 Alluxio 集群可能就足够了，但有些组织需要运行多个 Alluxio 集群。例如，如果计算是在多个区域运行，那么在每个区域运行一个 Alluxio 集群可能会带来更大的优势。此外，某些组织可能出于数据隐私保护的考虑，需要运行独立的集群，或是希望通过运行多个集群来提高可扩展性。虽然部分数据空间可能被隔离在某个集群中，但其他数据可以在多个集群之间共享。例如，一个集群可能负责提取和转换数据，而其他几个集群可能会查询这些数据并进行更新。</p><p></p><p>由于每个 Alluxio 集群可能会复制（即挂载）UFS 存储空间的某些部分，Alluxio 会负责保持其副本与 UFS 的一致性，以便用户查询到最新的文件副本。在本文中，我们将介绍在一个或多个集群中确保 Alluxio 数据与 UFS 一致所用到的组件。</p><p></p><h3>2.Alluxio 数据一致性</h3><p></p><p></p><p>在分布式系统中保持数据的一致性是很复杂的，其中有几十个不同的一致性级别，每个级别都允许不同的用户在特定时间查询和修改数据的不同状态。这些一致性级别形成了一个从弱到强的范围区间，一致性越强限制越多，通常越容易在上面搭建应用程序。Alluxio 也不例外，它会根据配置和使用的 UFS 提供不同的一致性保障（详细信息见 Alluxio 的数据一致性模型）。</p><p></p><p>为了简化关于一致性的讨论，我们将做如下假设：</p><p></p><p>● 对于任何文件，UFS 都是文件的 “唯一数据源”。</p><p></p><p>这意味着 Alluxio 中的每个文件都对应于 UFS 上的一个文件，并且 UFS 中总是有该文件的最新版本。如果 Alluxio 存储的文件副本与 UFS 中的文件不同，那么 Alluxio 中的文件版本是不一致的。(这里我们假设 UFS 本身确保了强一致性，即某种程度的线性一致性（linearizability）或外部一致性（external consistency）。从高层次来看，这允许用户把 UFS（即便系统是由许多分布式部分所组成) 当作类似实时按顺序执行操作的单一的文件系统来访问。</p><p></p><p>在讨论 Alluxio 和 UFS 的一致性之前，让我们先来看一下 Alluxio 的基本架构。Alluxio 是由 master 节点和 worker 节点组成的。master 节点负责跟踪文件的元数据，例如它的路径、大小等，而 worker 节点负责存储数据本身。如果 client 要读一个文件，必须先从某一个 master 节点上读取元数据，然后用它来定位存储该数据副本的 worker（必要时可以从 UFS 上加载数据）。如果 client 要写一个文件，必须首先在 master 中为该文件创建元数据，然后通过 worker 将该文件写到 UFS，最后在 master 上将该文件标记为完成。当文件正在被写入时，它的元数据会被标记为未完成，从而阻止其他 client 访问该文件。</p><p></p><p>从这个基本设计中，我们可以看到，只要所有对文件的更新都通过 Alluxio 写入 UFS，那么 Alluxio 中的数据将与 UFS 中的数据保持一致，client 将会始终查询到最新的数据版本。</p><p></p><p>然而现实情况，并没有这么简单，例如，某些用户可能在更新 UFS 时不通过 Alluxio，或者 client 可能出现故障，只将部分文件写入 UFS，而没有在 Alluxio master 上标记完成，这些都可能导致 Alluxio 和 UFS 中的数据不一致。</p><p></p><p>那么，这些问题是如何处理的呢？由于我们重点假设了 UFS 是唯一的数据源，要解决这些不一致的问题只需让 Alluxio 与 UFS 同步即可。</p><p></p><h3>3. 元数据同步</h3><p></p><p></p><p>元数据同步是用来检查和修复 Alluxio 和 UFS 之间不一致的主要组件。当 client 访问 Alluxio 中的某个路径时，该功能在一定条件下（后面会讨论）可能会被触发。基本程序如下：</p><p></p><p>从 UFS 加载该路径的元数据。</p><p></p><p>将 UFS 中的元数据与 Alluxio 中的元数据进行比较。元数据中包含文件数据的指纹（例如最后修改时间和抗碰撞的哈希值），可用于检查数据不一致情况。</p><p></p><p>如果发现任何不一致，则更新 Alluxio 中的元数据，并标记过时的数据，以便将其从 worker 中驱逐。最新数据会根据需要从 UFS 加载到 worker。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/af/afc7eeb40b6b30a19f51f76c38ad5fd5.png\" /></p><p></p><p>图：client 读取时的元数据同步过程。1. client 读取文件系统中的一个路径。2. master 上的元数据同步模块根据用户配置检查是否需要同步。3. 通过从 UFS 加载元数据进行同步，并创建一个指纹来比较 Alluxio 和 UFS 中的元数据。如果指纹不同，则 Alluxio 中的元数据会被更新。4. client 根据更新后的元数据从 worker 中读取文件数据，必要时从 UFS 中加载数据。</p><p></p><p>唯一的问题就是决定何时执行这个元数据同步程序，需要我们在更强的一致性和更好的性能之间进行权衡。</p><p></p><h4>每次访问数据时进行元数据同步</h4><p></p><p></p><p>如果 Alluxio 中的 client 每次访问一个路径时都进行元数据同步，那么 client 将始终能查看到 UFS 上最新的数据状态。这将为我们提供最高的一致性级别，通常可以达到 UFS 所能确保的最强的一致性。但是，由于每次访问数据（即使数据没有被修改）都会与 UFS 进行同步，这也会将导致性能下降。</p><p></p><h4>基于时间进行元数据同步</h4><p></p><p></p><p>另外，元数据同步可以基于一个物理时间间隔来执行。在这种情况下，Alluxio master 上的元数据包含路径最后一次与 UFS 成功同步的时间。现在，只有当用户定义的时间间隔过后，才会进行新的同步（详细信息见 UFS 元数据同步）。</p><p></p><p>虽然这种方式可能极大地提高了性能，但也导致了相对较弱级别的一致性保障，即最终一致性。这意味着，任何特定的读取结果可能与 UFS 一致，也可能不一致。此外，数据更新被查询到的顺序可能是任意顺序。例如，在 UFS 中，文件 A 的更新实际早于另一个文件 B，但是，Alluxio 集群查询到的可能是文件 B 的更新早于文件 A。因此，系统的用户必须了解这些不同级别的一致性保障，并根据需要调整应用程序。</p><p></p><h2>二、跨集群同步机制</h2><p></p><p></p><p>在上一章节，我们讨论了单个 Alluxio 集群的场景、背景以及如何进行元数据同步。本章将介绍如何在多集群场景下实现建立元数据同步，从而确保以提供元数据一致性。</p><p></p><h3>1. 基于时间同步的多集群一致性</h3><p></p><p></p><p>其中一个基于时间的元数据同步用例是使用多个 Alluxio 集群且集群共享部分 UFS 数据空间的场景。通常，我们可以认为这些集群正在运行单独的工作负载，这些工作负载可能需要在某些时间点共享数据。例如，一个集群可能会提取和转换来自某一天的数据，然后另一个集群会在第二天对该数据进行查询。运行查询任务的集群可能不需要总是看到最新的数据，例如可以接受最多一个小时的延迟。</p><p></p><p>在实践中，使用基于时间的同步不一定总是有效，因为只有特定的工作负载才会定期更新文件。事实上，对于许多工作负载来说，大部分文件仅被写入一次，而只有一小部分文件会经常更新。在这种情况下，基于时间的同步效率变低，这是因为大多数同步都是不必要的，增加时间间隔将导致经常修改的文件处于数据不一致状态的时间更长。</p><p></p><h3>2. 使用跨集群同步（Cross&nbsp;Cluster Sync）实现多集群一致性</h3><p></p><p></p><p>为了避免基于时间同步的低效性，跨集群同步功能允许直接跟踪不一致性，因此只在必要时才会同步文件。这意味着每当在 Alluxio 集群上一条路径发生更改时，该集群将发布一个失效消息，通知其他 Alluxio 集群该路径已被修改。下次当有 client 在订阅（跨集群同步功能的）集群上访问此路径时，将触发与 UFS 的同步操作。</p><p></p><p>与基于时间的同步相比，跨集群同步具有两个主要优点。首先，只对已修改的文件执行同步，其次，修改可以快速地对其他集群可见，所需时间即大约等同于从一个集群发送消息到另一个集群的时间。</p><p></p><p>由此我们可以看到，当满足以下假设时，跨集群同步功能将是最有效用的。</p><p></p><p>多个 Alluxio 集群挂载的一个或多个 UFS 中有交叉部分。(我们认为系统中部署的 Alluxio 集群数量的合理范围是 2-20 个）。</p><p></p><p>至少有一个集群会对 UFS 上的文件进行更新。</p><p></p><p>所有对 UFS 的更新都要经过 Alluxio 集群（关于处理其他情况的方法，请参见下文 \"其他用例\"内容）。</p><p></p><p>现在我们要确保来自一个 Alluxio 集群的更新将最终在其他所有 Alluxio 集群中被监测到（即集群与 UFS 满足最终一致性保障），这样应用程序就可以在集群间共享数据。</p><p></p><h4>路径失效发布 / 订阅</h4><p></p><p></p><p>跨集群同步功能是基于发布 / 订阅（pub/sub）机制实现的。当 Alluxio 集群挂载某个 UFS 路径时，就会订阅该路径，每当集群修改 UFS 上的文件时，它都会向所有订阅者发布修改的路径。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/dd/dd0c965689e2953280272d35890aceac.png\" /></p><p></p><p>表 1：三个 Alluxio 集群挂载不同的 UFS 路径示例。</p><p></p><p>参考表 1 中的例子，有三个 Alluxio 集群，每个集群挂载一个不同的 S3 路径。这里，集群 C1 将 S3 桶（bucket）s3://bucket/ 挂载到其本地路径 /mnt/，集群 C2 将同一个 bucket 的子集 s3://bucket/folder 挂载到其本地路径 /mnt/folder，最后 C3 将 s3://bucket/other 挂载到其根路径 /。</p><p></p><p>由此，集群 C1 将订阅路径（pub/sub 语义中的“主题”）s3://bucket，集群 C2 将订阅路径 s3://bucket/folder，而集群 C3 将订阅路径 s3://bucket/other。订阅者将收到所有发布的以订阅“主题”开头的消息。</p><p></p><p>例如，如果集群 C1 创建了一个文件 /mnt/folder/new-file.dat，它将发布一个包含 s3://bucket/folder/new-file.dat 的无效消息，集群 C2 将会收到该消息。另外，如果集群 C1 创建了一个文件 /mnt/other-file.dat，则不会发送任何消息，这是因为没有订阅者的主题与 s3://bucket/other-file.dat 相匹配。</p><p></p><p>如前所述，Alluxio 的元数据包括该路径最近一次同步发生的时间。在跨集群同步的情况下，它还包含最近一次通过 pub/sub 接口收到的路径失效信息的时间。利用这一点，当 client 访问一个路径时，在以下两种情况下将会与 UFS 进行同步。</p><p></p><p>a) 该路径第一次被访问。</p><p></p><p>b) 路径的失效时间晚于最近一次同步时间。</p><p></p><p>假设系统中没有故障，显然最终一致性将得到保证。对文件的每一次修改都会导致每个订阅集群收到一个失效消息，从而在下一次访问该文件时进行同步。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5f/5fb9e6d75539c3756c3f80bd02df17c5.png\" /></p><p></p><p>图 1：文件创建过程中的跨集群同步机制。A. client 在集群 1 上创建一个文件。B. client 将文件写入 worker。C. worker 把文件写入 UFS。D. client 在 master 上完成了该文件。E. 集群 1 向集群 2 的订阅者发布文件的失效消息。F. 集群 2 在其元数据同步组件中将该文件标记为需要同步。以后当 client 访问该文件时，将同样使用图 1 所示的步骤 1-5 进行同步。</p><p></p><h4>实现 Pub/sub 机制</h4><p></p><p></p><p>Pub/sub 机制是通过发现机制（discovery mechanism）和网络组件来实现的，前者允许集群知道其他集群挂载了什么路径，后者用来发送消息。</p><p></p><p>发现机制是一个名为 CrossClusterMaster 的单一 java 进程，须能让所有 Alluxio 集群通过可配置的地址 / 端口组合进行访问。每当一个 Alluxio 集群启动时，都会通知 CrossClusterMaster 该集群的所有 master 节点的地址。此外，每当集群挂载或卸载 UFS 时，挂载的路径都将被发送到 CrossClusterMaster。每次这些值被更新时，CrossClusterMaster 节点都会把新值发送给所有 Alluxio 集群。</p><p></p><p>利用这些信息，每个 Alluxio 集群将计算其本地 UFS 挂载路径与外部集群的所有 UFS 挂载路径的交集。对于每个相交的路径，集群的 master 将使用 GRPC 连接创建一个以该路径为主题的订阅给外部集群的 master。在表 1 的例子中，C1 将向 C2 创建一个主题为 s3://bucket/folder 的订阅，以及向 C3 创建一个主题为 s3://bucket/other 的订阅。此外，C2 将向 C1 创建一个主题为 s3://bucket/folder 的订阅，而 C3 将向 C1 创建一个主题为 s3://bucket/other 的订阅。这样一来，每当集群要修改某个路径时，例如创建一个文件，它都会把修改的路径发布给任何主题是该路径前缀的订阅者。例如，如果 C1 创建一个文件 /mnt/other/file，它将发布 s3://bucket/other/file 到 C3。</p><p></p><p>为了主动维护对其他集群的订阅，每个 Alluxio master 上都会运行一个线程，以应对路径的挂载或卸载、集群的加入或者脱离，以及出现连接故障等情况的发生。</p><p></p><p>每当订阅者收到路径时，它就会将失效时间元数据更新为当前时间，这样一来，下一次 client 访问该路径时，就会与 UFS 进行一次同步。按照我们上面的例子，下一次 client 在集群 C3 上读取路径 /file 时，将在 s3://bucket/other/file 上执行与 UFS 的同步。</p><p></p><h4>确保最终一致性</h4><p></p><p></p><p>如果能保证每条发布的消息都向所有订阅者（包括未来的订阅者）仅传递一次（exactly once） ，那么显然最终一致性将得到保证，因为每一次修改都会让订阅者在访问路径时进行同步。但是，连接可能中断、集群可能脱离和接入系统、节点也可能出现故障，我们该如何保证消息的准确传递呢？简单的答案是，我们不能。相反，只有在订阅（使用底层 TCP 连接）处于运行状态时，才能确保仅一次消息传递。此外，当订阅首次建立时，订阅者将标记根路径（主题）的元数据为需要同步。这意味着，在订阅建立后，对于任何作为主题的超集路径，在第一次访问该路径时将进行同步。</p><p></p><p>例如，当 C1 用主题 s3://bucket/folder 建立对 C2 的订阅时，C1 将标记 s3://bucket/folder 为需要同步。然后，例如在第一次访问 s3://bucket/folder/file 时，将进行同步。</p><p></p><p>这大大简化了处理系统中的故障或配置变化的任务。如果某个订阅因为任何原因而失败，如网络问题、master 故障切换、配置变化，那么恢复过程是一样的——重新建立订阅，并将相应的路径标记为不同步。为了减轻网络问题的影响，可以设置一个用户定义的参数，以确定有多少消息可以缓存在发布者的发送队列中，以及在队列已满的情况下超时等待多久会发生操作阻塞的可能性。</p><p></p><p>当然，按照预期，虽然我们的系统会发生故障，但不会经常发生，否则性能会受到影响。所幸即使在频繁发生故障的情况下，性能下降也会与使用基于时间的同步的情况相似。例如，如果每 5 分钟发生一次故障，预计性能与启用基于时间（5 分钟间隔）同步下的性能类似。</p><p></p><p>请注意，如果 CrossClusterMaster 进程发生故障，那么新的集群和路径挂载发现将不起作用，但集群将保持其现有的订阅而不会中断。此外，CrossClusterMaster 是无状态的（可以把它看作是集群交换地址和挂载路径的一个点），因此，可以在必要时停止和重新启动。</p><p></p><h4>其他用例</h4><p></p><p></p><p>前面提到，为了使这个功能发挥作用，所有对 UFS 的更新都应该通过 Alluxio 集群进行。当然这个条件不一定能满足，有几种方法来处理这个问题。</p><p></p><p>用户可以手动将一个路径标记为需要同步。</p><p></p><p>基于时间的同步可以和跨集群同步一起启用。</p><p></p><h2>三、探讨与结论</h2><p></p><p></p><h3>1. &nbsp;探讨与未来工作</h3><p></p><p></p><h4>为什么不使用确保仅一次消息传递的 pub/sub 机制？</h4><p></p><p></p><p>我们知道，如果使用确保仅一次消息传递的 pub/sub 机制会大大简化我们的设计，而且也确实存在许多强大的系统，如 Kafka 和 RabbitMQ，正是为了解决这个问题而创建的。使用这些系统的好处是，故障对性能的影响可能较小。例如，如果某个订阅者处连接断开，在重新连接时，系统可以从它之前断开的地方继续运行。</p><p></p><p>尽管如此维护这些系统本身就是一项非常复杂的任务。首先，你需要弄清楚一些问题，比如，要部署多少个节点的物理机，要复制多少次消息，保留多长时间，当由于连接问题而不能发布消息时要不要阻塞操作等。而且，最终很可能还是需要故障恢复机制，从而导致更复杂的设计。</p><p></p><p>(注意，为了保证最终一致性，我们实际上只需要至少一次 (at least once) 消息传递，因为多次传递消息只会对性能产生负面影响，而不会影响数据一致性，但即便在这种情况下，大部分困难仍然存在)。</p><p></p><h4>扩展至 20 个 Alluxio 集群以上或处理频发故障</h4><p></p><p></p><p>未来，我们希望能支持扩展到数百个 Alluxio 集群，但从 20 个集群扩展至数百个集群可能有不同的设计考量。首先，我们预期故障的发生会更加频繁；其次，设计可能会导致 master 产生大量开销。</p><p></p><p>如前所述，故障频繁发生会使性能降低到与采用基于时间同步时类似。在有数百个集群的情况下，我们预期网络或 master 节点故障会相当频繁地发生。(请注意，这也取决于配置，因为故障只会影响挂载了与故障 UFS 路径有交集的集群。因此，如果集群大多挂载了不相交的 UFS 路径，那么可能问题不大）。此外，如果所有集群挂载的路径都有交集，那么它们将必须维护对所有其他集群的订阅，且一个发布就需要发送数百条消息。</p><p></p><p>在这种情况下，我们可能需要纳入一个可靠的 pub/sub 机制，如 Kafka 或 RabbitMQ，但这里只是替代点对点的订阅，而不是改变整个系统的设计。故障仍然会发生，集群将以同样的方式恢复——将相交的 UFS 路径标记为需要同步。只有可靠的 pub/sub 机制才会隐藏 Alluxio 的许多故障。例如，如果该机制想要可靠地存储最后 5 分钟的消息，那么只有持续时间超过 5 分钟的故障才需要用原来的方法进行恢复。此外，这些系统能够不考虑 Alluxio 集群的数量进行扩展，在必要时添加更多节点。不过，使用和维护这些系统会产生大量的开销，可能只有在某些配置中才值得尝试。</p><p></p><h4>关于一致性的一些看法</h4><p></p><p></p><p>虽然本文介绍了确保最终一致性的基本思路，但还有几个重要的内容没有详细说明。</p><p></p><p>首先，失效消息必须在对 UFS 的修改完成后才能发布，其次，UFS 必须在线性一致性或外部一致性（S3 中的一致性）层面上确保强一致性。如果这两个条件中的任何一个没有得到满足，那么当订阅者收到失效信息并执行同步时，集群可能无法观测到文件的最新版本。第三，如果一个集群与 CrossClusterMaster 的连接断开，后来又重新建立了连接，那么该集群也必须经历故障恢复过程，这是因为在连接中断期间可能有某个外部集群挂载并修改了路径。</p><p></p><h4>发布完整的元数据</h4><p></p><p></p><p>如前所述，发布的失效消息只包含被修改的路径。但是，这些消息也可以包括路径的更新元数据，从而避免在订阅集群上进行同步。之所以不这样做是因为无法通过常规方法知道哪个版本的元数据是最新的版本。</p><p></p><p>例如，两个 Alluxio 集群 C1 和 C2 在 UFS 上更新同一个文件。在 UFS 上，集群 C1 的更新发生在集群 C2 的更新之前。然后，两个集群都将他们更新的元数据发布到第三个集群 C3。由于网络条件的原因，C2 的消息比 C1 先到达。此时，C3 需要知道，它应该放弃来自 C1 的更新，因为已经有了最新的元数据版本。当然，如果元数据包含版本信息，就可以做到这一点，但可惜对于 Alluxio 支持的所有 UFS，常规方法都做不到。因此，C3 仍然需要与 UFS 进行元数据同步，以便直接从唯一的数据源获得最新的版本。</p><p></p><h4>订阅通知服务</h4><p></p><p></p><p>某些底层存储系统（UFS）（例如 Amazon SNS 和 HDFS iNotify）提供通知服务，让用户知道文件何时被修改了。对于这类 UFS，相较于订阅 Alluxio 集群，订阅这些服务可能是更好的选择。这样做的好处是支持不通过 Alluxio 对 UFS 进行写入。同样，系统设计将保持不变，只是不订阅其他 Alluxio 集群，而是订阅此类通知服务。</p><p></p><p>请注意，Alluxio 还为 HDFS 提供了 ActiveSync 功能，允许元数据与底层 UFS 保持同步。这与跨集群的同步机制有所不同，因为 ActiveSync 在文件更新时执行同步，而跨集群同步只在文件被访问时执行同步。</p><p></p><h2>四、结论</h2><p></p><p></p><p>本文主要介绍了运行多个 Alluxio 集群能带来优势的场景，以及 Alluxio 使用基于时间同步和跨集群同步功能，用来保持集群与所挂载 UFS 同步的过程。关于如何部署跨集群同步功能的更多内容，点击<a href=\"https://docs.alluxio.io/ee/user/stable/en/core-services/Cross-Cluster-Sync.html\">此链接</a>\"查看。</p><p></p>",
    "publish_time": "2023-03-23 10:24:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]