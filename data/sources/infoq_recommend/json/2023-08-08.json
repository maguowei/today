[
  {
    "title": "eBay改造“2.5亿次访问”页面：工作效率翻倍、变更成功率飙升",
    "url": "https://www.infoq.cn/article/M1jtje5B5I0SD7Bxigpv",
    "summary": "<p>eBay<a href=\"https://tech.ebayinc.com/engineering/how-ebay-modernized-the-most-important-page-on-our-platform/\">整合了负责提供“查看商品”页面的服务</a>\"——该页面每天加载超过2.5亿次——去除了重复代码，提高了开发人员的工作效率。结果，他们的团队速度翻了一番，现在甚至可以每天将变更部署到该页面，并且变更失败率降低了许多。</p><p>&nbsp;</p><p>在经历了十年的自然增长之后，eBay用于支撑“查看商品”页面的代码库已经变得相当难以维护，因为需要将更改复制到4个支撑平台（桌面、移动Web、iOS和Android）上。这导致一次页面更改需要花费数周的时间，而部署最多一个月才能进行一次。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/07/078f92fb6632dcbcbc593b7ba5e961f1.jpeg\" /></p><p></p><p>图片来源：<a href=\"https://tech.ebayinc.com/engineering/how-ebay-modernized-the-most-important-page-on-our-platform/\">https://tech.ebayinc.com/engineering/how-ebay-modernized-the-most-important-page-on-our-platform/</a>\"</p><p>&nbsp;</p><p>团队决定解决这个问题，并一致同意改进关键的<a href=\"https://www.atlassian.com/devops/frameworks/devops-metrics\">DevOps指标</a>\"（参见Nicole Forsgren、Jez Humble和Gene Kim在<a href=\"https://www.oreilly.com/library/view/accelerate/9781457191435/\">Accelerate</a>\"&nbsp;一书中的定义）。新架构需要将现有的3个服务整合到一个View Item Experience Service中，以支持不同的平台，增强所有平台的用户体验，消除重复代码，提高开发体验和生产力。</p><p>&nbsp;</p><p>为了实现增量迁移，在替换现有架构时需要引入一个新的服务。该服务开始时只负责代理数据，然后逐渐迁移并合并所有平台的业务逻辑。最后，升级客户端使其使用新服务，并停用遗留服务。</p><p>&nbsp;</p><p>为了做好变更准备，团队一开始时曾试图分析遗留代码并编写文档。事实证明，这个过程非常缓慢而有挑战性。因此，他们改变了策略，集中精力快速了解了遗留模块，获得了一个高级视图，然后基于此对现有的功能进行了逆向，并编写了描述新实现的文档。为了进一步简化流程，他们将后端更改与面向用户的更改解耦，使得后端团队可以加速后续的迁移。</p><p>&nbsp;</p><p>eBay（买家体验工程）副总裁<a href=\"https://www.linkedin.com/in/lakshimid/\">Lakshimi Duraivenkatesh</a>\"及其协同开发者描述了这项现代化工作的成果：</p><p></p><blockquote>这些改进最终将速度提高了200%。更好的是，我们立马在项目的模块迁移阶段看到了这种提升。从第一个模块到最后一个模块，每个模块的迁移都会带来相应的速度提升。随着项目接近完成，我们在新产品改进方面的的工作量已经减少了50%（以天为单位）。</blockquote><p></p><p>&nbsp;</p><p>团队超额完成了所有初始目标，变更失败率变得非常低（即使部署更频繁）。与此同时，变更的交付时间和<a href=\"https://en.wikipedia.org/wiki/Mean_time_to_recovery\">平均恢复时间（MTTR）</a>\"也大大减少了。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/55/558ea622329ca74d8268de149cd396d3.jpeg\" /></p><p></p><p>图片来源：<a href=\"https://tech.ebayinc.com/engineering/how-ebay-modernized-the-most-important-page-on-our-platform/\">https://tech.ebayinc.com/engineering/how-ebay-modernized-the-most-important-page-on-our-platform/</a>\"</p><p>&nbsp;</p><p>新的业务逻辑实现使用了新的现代化技术栈和更快的自动化管道。更好的文档、更干净的代码则改善了开发体验，降低了团队新成员的上手难度。</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/06/ebay-view-item-page-rework/\">https://www.infoq.com/news/2023/06/ebay-view-item-page-rework/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/oSZ2iBOpLuxapQeZtmH0\">eBay平台自动升级解决方案</a>\"</p><p><a href=\"https://www.infoq.cn/article/U8walzaYhwOZQzsVypVj\">eBay和Lastminute采用契约测试来驱动架构演进</a>\"</p>",
    "publish_time": "2023-08-08 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "【实战篇】通过 SoFlu 构建一个低代码平台实现过程之“表单”",
    "url": "https://www.infoq.cn/article/08o8PUsZWETRu3puvAOu",
    "summary": "<p>在现代企业开发中，初级开发者难以掌握开发企业级 Java 应用，中高级开发者则被繁琐任务所占据。为了让大家能快速上手可以解决这个难题的“SoFlu 软件机器人”，前蚂蚁金服技术专家杨彪设计了《2 小时学会 10 个组件“取代”传统 Java 开发》课程，本节为该系列课程的第九讲。</p>\n<p>低代码平台案例中包括页面设计、表单设计和流程引擎设计三大核心模块，而表单设计模块相对复杂，所以在本讲中将深入剖析如何通过SoFlu来实现表单创建功能。本讲主要聚焦剖析“新建表单”的接口、复杂流程、逻辑图等。</p>\n<p>大家在课后可以登录 Gitee 下载 SoFlu 软件机器人客户端进行实践：<a href=\"http://suo.im/8wROo\">点击下载</a></p>\n<p>大家可以扫码添加小助手，进学习群与专家一对一交流：<br />\n<img alt=\"\" src=\"https://static001.infoq.cn/resource/image/e8/c9/e8833a01ba0bc705acab14a572b57cc9.png\" /></p>",
    "publish_time": "2023-08-08 09:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "文生图模型又“卷”起来了！比Stable Diffusion中文理解能力更强、更懂国人的文生图模型是如何构建的？",
    "url": "https://www.infoq.cn/article/4LKYBOU859NxLSk2klif",
    "summary": "<p></p><blockquote>本期节选自<a href=\"https://www.infoq.cn/minibook/b8qPXJ8SuGLwTDVO7sSJ\">《中国卓越技术团队访谈录》（2023年第二季）</a>\"。此次我们深入采访了网易伏羲预训练及生成式人工智能平台负责人赵增博士，进一步了解文生图模型丹青的构建思路，以及网易伏羲对文生图模型未来发展的思考。</blockquote><p></p><p></p><p>宋徽宗赵佶曾创作过一幅名为《蜡梅山禽图轴》的画作，并为该画题了一首诗：“山禽矜逸态，梅粉弄轻柔，已有丹青约，千秋指白头。”讲述的是一对白头翁立于这丹青笔墨的虚空中，没有风，没有阴影，没有俗世喧嚣、红尘侵染，一千年恩爱如初，一千年只不过黯淡些羽毛上的墨色，艺术比生命更长久。</p><p>&nbsp;</p><p>以此诗为灵感，网易集团高级副总裁胡志鹏给网易伏羲自研文生图模型取名为“丹青”，依托于该模型之上构建的 AIGC 平台名为“丹青约”。</p><p>&nbsp;</p><p>丹青模型基于原生中文语料数据及网易自有高质量图片数据训练，与其他文生图模型相比，丹青模型的差异化优势在于对中文的理解能力更强，对中华传统美食、成语、俗语、诗句的理解和生成更为准确。比如，丹青模型生成的图片中，鱼香肉丝没有鱼，红烧狮子头没有狮子。基于对中文场景的理解，丹青模型生成的图片更具东方美学，能生成“飞流直下三千尺”的水墨画，也能生成符合东方审美的古典美人。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/91/9178cc1ced84f3234f8cda3f1537e14d.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4a/4a4c05111706bc44ecde1da65f0621f1.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/13/131356898cdb3c612bfde30327a1e97d.png\" /></p><p></p><p>近日，InfoQ 采访到了网易伏羲预训练及生成式人工智能平台负责人赵增博士，进一步了解丹青模型的构建思路。网易伏羲成立于 2017 年，主要研究方向为强化学习、自然语言、用户画像，视觉计算，虚拟人等，技术应用智能捏脸、反外挂、智能 NPC、对战匹配、竞技机器人、人机协作、数字孪生等多个方向，团队已在世界顶级学术会议发表论之 200 余篇，申请发明专利 550 余项。</p><p></p><h2>文生图模型“卷”起来了</h2><p></p><p>&nbsp;</p><p>2022 年被称为 <a href=\"https://www.infoq.cn/article/rggHjzaBfCVPV5hxTF7H\">AIGC</a>\"（生成式人工智能）的元年。</p><p>&nbsp;</p><p>这一年，Stable Diffusion 正式开源，并掀起了文生图模型的热潮；这一年，ChatGPT 火遍全球，成为现象级应用。在年末 Science 杂志发布的 2022 年度科学十大突破中，AIGC 作为人工智能领域的重要突破赫然在列。</p><p>&nbsp;</p><p>进入 2023 年，AIGC 技术助推出新的人工智能浪潮，AI 大模型的创新应用按下加速键。而其中，文生图仍是大模型最火热的应用领域之一，国内外发布的文生图模型数量不断攀升。越来越“卷”的文生图模型们，正促进模型生成效果和效率迈上新台阶。</p><p>&nbsp;</p><p>“在过去的半年里，我深刻地感受到了 AIGC 技术的飞速发展。整体来看，去年整个行业和技术相对来说不如今年活跃。今年以来，行业和社会都开始更加关注 AIGC 的发展，AIGC 技术发展速度惊人。”</p><p>&nbsp;</p><p>赵增在接受 InfoQ 采访时表示，AIGC 技术的飞速发展使得文生图模型不断实现更加良好的生成效果，与此同时，以 Stable Diffusion 为代表的开源项目空前活跃，很多没有强大 AI 背景的开发者也能够基于开源生态做出优秀的 AI 模型。“这对我们产生了很大的冲击，我们需要重新审视自身的工作路径，并考虑如何与有志于参与模型建设的行业伙伴建立关系。同时，我们也要考虑如何支持内部同事，尤其是那些掌握了一定 AI 生产能力的美术同事们，帮助他们更好地利用 AIGC 技术，以提升他们的工作效率和质量。”</p><p></p><h2>如何构建更懂中文的文生图模型？</h2><p></p><p>&nbsp;</p><p>据了解，<a href=\"https://www.infoq.cn/article/dgCKRuC1owW8A1WPXUFs\">网易伏羲</a>\"从 2018 年开始关注&nbsp;AIGC 技术在产品中的应用可能性，不断尝试将其应用于实际场景。</p><p>&nbsp;</p><p>2018 年，GPT 横空出世，其强大的生成效果令人印象深刻。在胡志鹏的推动下，网易伏羲开始尝试在游戏中使用AIGC 技术，推出一些互动玩法。比如，在《遇见逆水寒》游戏中，网易伏羲引入了一个文字生成类的玩法——傀儡戏。</p><p>&nbsp;</p><p>在这个玩法中，玩家可以扮演剧情角色，通过聊天的方式，与 AI 共同创作剧本，共同协作达成一些目标。这也是国内首个将 AI 接入游戏中，与玩家共同创作剧本的玩法。2019 年，网易伏羲尝试将这一设计正式大规模上线，并在训练应用、工程加速等多个方面进行直接探索。</p><p>&nbsp;</p><p>与其他 AI 研究机构相比，网易伏羲的优势在于能够快速在产品中验证 AI 技术，根据实际应用效果不断迭代优化。赵增表示，网易有多款产品，可以通过类似“实验田”的方式验证 AI 产品在游戏或其他产品中的可行性，“这也是网易的一个良好机制，可以快速验证和实现 AI 的应用。”</p><p>&nbsp;</p><p>2021 年，网易伏羲正式启动大规模预训练研发项目，并得到了浙江省政府的支持。根据项目规划，网易伏羲计划开发文本、图像、音乐等一系列 AI 大模型。在与网易集团多个业务的专家交流后，网易伏羲判断多模态将是未来发展趋势，决定优先专注多模态相关的工作，如文本到图像、文本到音乐、图像到音乐的理解和生成。</p><p>&nbsp;</p><p>文生图模型丹青正是其中的主要工作之一。2022 年上半年，网易伏羲开始启动丹青模型的各项工作，该模型基于原生中文语料数据及网易自有高质量图片数据训练，100% 自研。</p><p></p><h3>“生产好的内容之前，需要先理解好的内容”</h3><p></p><p>&nbsp;</p><p>在丹青模型出现以前，国内外已有多个文生图模型，随着去年&nbsp;<a href=\"https://www.infoq.cn/article/hzqWDTkJbUCLghFPXmel\">Stable Diffusion</a>\" 的开源，文生图模型数量激增，很多创业公司直接基于&nbsp;Stable Diffusion&nbsp;模型进行适配训练和推理生成，并利用 API 的翻译接口将中文的输入转化成英文，实现对中文用户的支持。</p><p>&nbsp;</p><p>不过，Stable Diffusion 使用的核心数据集是开放图像-文本对数据集 LAION-5B，存在一些偏西方化的特点。比如，海外数据的内容组成大多由当地的人文地理、生活历史构成，对中文语言、美食、文化、习俗缺乏理解，直接地英译中可能引起语义的缺失，由此生成的图片也容易引发争议。像淮扬名菜“红烧狮子头”，一些模型会生成狮子头的图片；河北小吃驴肉火烧，也有模型直接生成一头驴和一团火。</p><p>&nbsp;</p><p>此外，海外数据集在合规性和安全性方面存在一定风险，比如，存在种族不平等、大量裸露、暴力等内容，直接将这些数据模型用于国内的生产，存在巨大的隐患。</p><p>&nbsp;</p><p>“网易伏羲的观点是，生产好的内容之前，需要先理解好的内容。”赵增认为，Stable Diffusion 的确给文生图模型领域带来了一些参考和启示，但 Stable Diffusion 在很大程度上仍是“黑盒”，如果在其基础上进行修改，对模型的优化和控制力是相对有限的。做文生图模型，如果只是简单的重复并无意义，需要走出自己的一条路子。</p><p>&nbsp;</p><p>具体来说，网易伏羲的关注点主要有三大方面：</p><p>&nbsp;</p><p>第一，网易伏羲需要构建的是一个对中文领域以及中文的艺术知识有更深理解的生成模型，满足国内用户的使用需求。第二，从技术的可控性、安全性和规则性出发，需要打造一个完全开放的基础模型，知道它是如何构建和运作的，以及如何对其进行优化，而不是始终等待别人开源新版本。第三，AIGC 并不代表只是大模型，大模型只是其中的重要环节，要真正将生成的内容用于生产，还需要做很多大模型以外的工作。比如建立生产管线，将专家及 AI 能力整合起来，提供专业化解决方案。</p><p>&nbsp;</p><p>基于这一认识，网易伏羲选择兼容开源数据的同时，又分为四步推进丹青模型的研发工作：建设高质量的大规模中文数据集；构建中文领域的优质理解模型；基于数据集和理解模型重构图文生成算法，做到语义的有效提升；引入专家和人类的反馈，引导模型生成用户更加需要的高质量内容。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ad/ad773c1ff600518a6db39f03db194bd4.png\" /></p><p></p><p>数据集方面，网易伏羲联合网易多个部门，包括网易雷火、传媒、云音乐等核心业务，从用户和业务维度提供对数据的理解和需求，完成对于优质数据的定义，建设包括文本质量、图像美观度、版权合规性以及伦理评估等评价标准。以此框架作为约束共同推进数据构建，同时设计了一套基于分布式任务的数据可信系统，各专家团队各自提供数据质量评审模型，完成共同打分后再交由数据治理引擎统一管理。</p><p>&nbsp;</p><p>大模型方面，网易伏羲自主研发了中文文本预训练大模型系列“玉言”，“玉言”先后登顶知名中文榜单 FewCLUE和 CLUE 分类榜单，在多项任务上超过人类水平。在文本理解的基础上，网易伏羲自 2021 年起着力打造“玉知”多模态图文理解大模型，采用图片-文本双塔结构和模块化的训练思想，基于亿级别的中文图文数据对，先后迭代了三种规格的模型版本。</p><p>&nbsp;</p><p>基于数据集和理解模型，网易伏羲对图文生成算法进行重构，依托于扩散模型的原理，在广泛的（8 亿）图文数据上训练以达到较好的生成结果。具体来说，丹青模型侧重文本与图片的交互，强化了在文图引导部分的参数作用，能够让文本更好地引导图片的生成，因此生成的结果也更加贴近用户意图。同时，丹青模型进行了图片多尺度的训练，充分考虑图片的不同尺寸和清晰度问题，将不同尺寸和分辨率的图片进行分桶。在充分保证训练图片训练的不失真的前提下，保留尽可能多的信息，适应不同分辨率的生成。</p><p>&nbsp;</p><p>在数据策略方面，丹青模型在初始阶段使用亿级别的广泛分布的数据，不仅在语义理解上具有广泛性，可以很好地理解一些成语、古文诗句，在生成的画风上也具有多样性，可以生成多种风格。在之后的阶段，丹青模型分别从图文关联度、图片清晰度、图片美观度等多个层面进行数据筛选，以优化生成能力，生成高质量图片。</p><p>&nbsp;</p><p>此外，丹青模型在训练和生成阶段还引入了人工反馈。在训练阶段，人工从多个维度的评估，筛选出来大批高质量图文匹配、高美观度数据，以补足自动流程缺失能力，帮助基础模型获得更好的效果；在生成阶段，人工对模型的语义生成能力和图片美观度进行评分，筛选出大批量优质生成的结果，引入模型当做正反馈，实现数据闭环。</p><p></p><h3>丹青约背后的东方美学</h3><p></p><p>&nbsp;</p><p>丹青模型是底层基础，在实际场景中进行应用需要依赖于上层平台的建设。依托于丹青模型，网易伏羲和雷火艺术中心联合研发了 AI 绘画平台“丹青约”。</p><p>&nbsp;</p><p>在赵增看来，丹青约的优势在于对中文和美的理解，依赖于较强的中文理解能力，以及对美学的专业理解，丹青约创作出的作品更能满足中式审美。“我们会请一些美术专家对模型进行把控。目前来看，国内具备美术专家群体的 AI 机构寥寥无几，网易在这一领域具有显著优势，我们知道什么样的模型生成内容更符合大家的审美需求。”</p><p>&nbsp;</p><p>比如，雷火艺术中心会派遣艺术家前来指导，从艺术的角度对生成图片效果、插件、版本给予专业意见。丹青约也会为艺术家提供定制化的生成工具，及时获取艺术家们的反馈意见，进一步迭代优化。</p><p>&nbsp;</p><p>此外，丹青约还充分结合了网易游戏美术设计的工作流，无论是生成图片的美观度，还是满足高质量要求的图片生产（如原画、美术资产等），都做了深入的探索和研发，并且支持用户跨文字、图片等多模态给予多轮修改建议，直到生成满意的图片效果。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/27/27063c9fba4faa5cd910cdd6549c91e8.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ac/accf120e14d6331c3a3de2ab81d5809f.jpeg\" /></p><p></p><p>目前，网易伏羲正在推进丹青约的建设，并携手网易集团内部生态共同参与艺术风格和算法模型的设计和训练。此外，网易伏羲还积极推动将 AI 技术应用于企业美术资产的生产创作流程中。即将上线的网易伏羲有灵美术平台集成了丹青约等多种美术工具，涵盖了美术资产制作、工具管理、审核验收等生产全链路功能，大幅提升了美术创作的生产效率，为艺术家们提供了更加灵活的生产力工具。</p><p>&nbsp;</p><p>“大模型业务不仅包括模型算法本身，还需要一个非常完善的数据计算和人工智能系统支撑。我们系统地从多个方面来建设大模型能力，以满足实际应用需求，并不断持续关注和发展大模型技术。”赵增说道。</p><p></p><h2>文生图模型如何应对版权争议？</h2><p></p><p>&nbsp;</p><p>文生图作为大模型最火热的应用领域之一，近几年取得了突破性的进展，并成功在多个领域落地应用。与热度随之而来的也有争议，其中，最大争议点在于版权。</p><p>&nbsp;</p><p>今年 1 月份，三位艺术家曾对 Stable Diffusion 背后的公司 Stability AI，AI 绘画工具Midjourney，以及艺术家作品集平台 DeviantArt 提起诉讼，称这些组织通过在“未经原作者同意的情况下”从网络上获取的 50 亿张图像来训练其人工智能，侵犯了“数百万艺术家”的权利。</p><p>&nbsp;</p><p>该案的代理律师 Matthew Butterick&nbsp;指出，从法律的角度来看，几乎没有艺术家明确同意他们的作品用于训练 AI 系统。即使系统生成的图像作为原始图像传递，生成系统仍将基于未经授权的数据。“因为系统中的所有视觉信息都来自受版权保护的培训图像，所以产生的图像无论外观如何，必然是从这些训练图像中衍生出来的。”</p><p>&nbsp;</p><p>版权争议是文生图模型继续向前发展必须解决的问题。赵增认为，能够真正训练好 AI 模型并使其发挥作用的并不是技术人员，而是具有行业需求和美术能力的专家。“我们需要聚集这些专家，让专家们围绕这个生态进行创作。必须考虑到专家的版权和原始利益，否则整个生态无法运转。”</p><p>&nbsp;</p><p>在版权问题上，目前网易伏羲团队正与网易区块链团队搭建相关平台，通过区块链和 Web3.0 的模式，将大家在整个生产链路过程中的贡献记录下来。例如，有人提供了原始训练图片，有人提供模型，有人提供创意，将这些生产日志记录下来，并通过回报分配的方式尽可能给予大家相对公平的激励。“这是我们现在非常明确要做的非常重要的事情。但是这个事情比较新，我们目前还在与网易的区块链团队搭建平台，并在内部进行验证。”</p><p></p><h2>写在最后</h2><p></p><p>&nbsp;</p><p>目前，丹青模型还在持续的迭代优化中，团队的短期目标是将丹青模型打造成一个更完善的产品。“我们正在努力提升大模型的效果，包括丰富其知识和提高生成的稳定性。其中，丰富知识是指对一些特定领域的理解，例如对于中国传统文化或海外知识的掌握。当我们需要生成一个中国古代建筑或榫卯结构的建筑时，我相信许多模型缺乏相关的知识。此外，我们的模型对于海外支持相对较弱，这也是需要进一步提升的地方。”赵增表示，除了将基础生成模型发展为一个更完善的产品，网易伏羲还希望构建一条更高效的生成图片的路径，以帮助美术专家进行创作。这涉及到多个模型能力的整合和闭环学习系统的建设，“这些都是我们接下来的重点努力方向”。</p><p>&nbsp;</p><p>在技术之外，开源生态同样值得关注。“今年以来出现了很多基于开源生态的大模型，包括图文、文本等。未来基于这些开源生态，工具和模型的版本迭代一定会发生非常有趣的变化，这个可能是我们现在都想象不到的。因此，我们需要保持关注并适应这些变化。”赵增说道。</p><p></p><h4>采访嘉宾</h4><p></p><p>&nbsp;</p><p>赵增，计算机博士，网易人工智能专家，预训练及生成式人工智能平台负责人、计算效能部门负责人。网易集团技术委员会机器学习分委会、音视频分委会委员。研究领域包括大规模人工智能系统、生成式预训练及基础算法优化。浙江省重点研发项目-超大规模预训练云平台主要研发人员，组织多项超大规模预训练模型研制及平台示范工作，参与申请发明专利近30项、高质量论文5篇。主导研发人工智能平台“丹炉”，日调用量超百亿次。曾参与国产芯片基础数学库优化、国产万亿高性能集群、“十四五”数字人等多个国家、省部级重点研发计划。</p><p></p><p><a href=\"https://www.infoq.cn/minibook/b8qPXJ8SuGLwTDVO7sSJ\">中国卓越技术团队访谈录（2023 年第二季）</a>\"深入采访了腾讯、网易伏羲、阿里云、QQ 等技术团队，呈现了这些团队在向量数据库、大模型、前端和研效等方面的技术落地、产品演进和团队建设等方面的多年实践经验和相关心得体会。<a href=\"https://www.infoq.cn/minibook/b8qPXJ8SuGLwTDVO7sSJ\">点击下载电子书</a>\"，查看更多精彩内容。</p>",
    "publish_time": "2023-08-08 10:10:56",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "金蝶重磅发布苍穹GPT，包含中国首款财务领域大模型",
    "url": "https://www.infoq.cn/article/LUHdjDy1v1FPfmlkPx0k",
    "summary": "<p></p><p>过去几个月，金蝶人频繁被客户问，<a href=\"https://www.infoq.cn/article/CTbOrxaOBwlDXwCYw6ae\">AIGC</a>\"是什么？GPT是什么？当时的金蝶还难以给出一个确切的答复。8月8日，金蝶在30周岁之际，于2023全球创见者大会上正式给出了自己的答案——金蝶正在将大模型技术融入到金蝶云里，并重磅发布金蝶云·苍穹GPT大模型，其中涵盖中国首个财务领域大模型。</p><p></p><p>据金蝶中国执行副总裁赵燕锡介绍，金蝶云是一个产品系列，它有平台和应用，平台就是<a href=\"https://www.infoq.cn/article/lE6jeHaWYIlcHexd5YTg\">金蝶云苍穹PaaS</a>\"，应用就是面向大中小企业的星瀚、星空、星辰。如今，金蝶在苍穹里增加了一个模型层，这个模型层被命名为苍穹GPT。</p><p></p><p>“苍穹GPT是大模型的能力平台，是金蝶云的智能技术底座，它和云原生架构构建了新的云智一体的新技术底座；同时还提供了新的组装能力，它可以实现智能任务调度，可以通过嵌入式AI助手，能够使得SaaS应用调用大模型能力；还可以提供一个新的企业大脑，因为生成式AI是聪明的，有知识引擎可以分析洞察、可以创意生成。”赵燕锡表示，苍穹GPT的定位是最懂管理的企业级大模型平台。</p><p></p><p>据了解，本次发布的苍穹GPT于2023年初与生成式AI能力相结合进行研发和优化，基于技术层、模型层、服务层、能力层及安全治理打造了“四横一纵”的架构体系，在企业级复杂的业务场景下实现了多模型能力、多任务编排、智能知识引擎、个性化扩展、安全可信任等特点。</p><p></p><p>多模型能力：苍穹GPT支持多种通用和垂域大模型的调用，并基于金蝶三十年企业服务积累具备百亿级的参数规模。这种多模型调用能力赋予了平台在各种应用场景下灵活且高效的性能表现，使得企业能够更好地满足不同场景的需求。多任务编排：基于智能中控可以让用户轻松实现复杂场景下的任务智能调度。无论用户需要处理什么样的任务，苍穹GPT都可以为企业用户提供最优的解决方案，自动分析、规划、执行和展示任务结果。用户可以通过自然语言（CUI）或者图形界面（GUI）与苍穹GPT进行交互，享受多模态的体验。智能知识引擎：智能知识引擎更像是一个企业私域知识的智慧大脑，无论是文字、文档、图片还是语音等都能识别和理解，并以精准的方式生成答案，让用户在提出问题时快速获得准确的答案，从而帮助企业提高效率和准确性，使得苍穹GPT成为了企业管理中不可或缺的智能助手。个性化扩展：整合了金蝶独创的KDDM（金蝶动态领域模型），支持灵活的插件机制，并鼓励用户与生态参与模型的共创，使得企业能够根据自身需求进行定制化，进而更好地适应不同的应用场景。安全可信任：苍穹GPT采用了多重防护机制，保障了用户的体验和算法回答的安全性。它不仅确保合法合规，还具备伦理判断的能力。此外，苍穹GPT提供安全可信的用户交互体验，让用户能够更加放心地使用这一智能平台。</p><p></p><p>会上，金蝶还发布了业内首个财务大模型，可以理解为苍穹GPT在垂域大模型的应用之一。</p><p></p><p>财务大模型是在通用模型的基础上，通过精标语料进行“继续预训练+模型微调”，让它更懂财务。金蝶预制了大量的提示语工程，使得大模型能够更加容易理解输入的财务指令，用户可以开箱即用。另外，金蝶预制了财务知识库，将沉淀的财务知识和税务政策沉淀到模型里。</p><p></p><p>“为什么可以做财务大模型？是因为我们有三十年的财务专业知识积累，有数百万客户的实践经验。”赵燕锡举例道，苍穹GPT+财务，可以提供 AI 助手应用，包括全员助手、专员助手、决策助手。其中，全员助手面向全体员工，提升交互体验；面向专业岗位员工，提升效率及专业度；面向管理者时，实现从经验主导到AI驱动的决策，给管理者提供更多专业建议，加速财务智能化发展。</p><p></p><p>除了财务领域，现场金蝶还介绍了苍穹GPT助手在HR、供应链与制造领域以及开发领域的应用。赵燕锡指出，苍穹GPT在研发、采购、生产、库存、办公这些领域都有很多场景，接下来的关键是如何识别这些场景，并将生成式的能力应用进去。在金蝶看来，商用大模型的未来在垂直领域，每个行业都将会有自己的专业大模型。金蝶也不参与“百模大战”，只专注做好能解决企业管理难题的AI。</p>",
    "publish_time": "2023-08-08 12:15:04",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "倚天CPU架构以及产品特性介绍",
    "url": "https://www.infoq.cn/article/TQcIxua83Fi6ikk1DoFj",
    "summary": "<p><img alt=\"\" src=\"https://static001.infoq.cn/resource/image/94/fc/94b9e1f6b404a66cyy23279f8580e5fc.jpg\" /></p>",
    "publish_time": "2023-08-08 13:50:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "曝光：Android恶意应用巧妙伪装，谷歌紧急出手修复漏洞",
    "url": "https://www.infoq.cn/article/J8M4ZzYCFyW7d2b4Oz3a",
    "summary": "<p>研究人员表示，移动恶意软件传播者一直在利用谷歌Android平台上的一个漏洞。该漏洞允许攻击者将恶意代码隐藏在移动应用之内，并可逃避安全扫描工具的检测。谷歌称为响应这项研究发现，已经对其应用程序恶意软件检测机制做出更新。</p><p>&nbsp;</p><p>来自阿姆斯特丹的安全厂商ThreatFabric的研究人员发现一种在移动应用中混淆恶意软件的方法。该公司高级恶意软件分析师Aleksandr Eremin在采访中解释道，他们近期发现一些移动银行木马，利用的正是全体Android系统版本中均存在的bug。该bug会损坏应用程序组件，导致将恶意代码被目前流行的移动安全扫描工具视为无效并忽略，因此整个应用仍可通过Android操作系统验证并成功安装。</p><p>&nbsp;</p><p>Eremin进一步指出，“有恶意软件将自身添加至.apk文件当中（Android应用安装文件），使其得以通过平台验证并成功执行所有恶意操作。目前许多用于解压和反编译移动应用的工具都无法正常处理这部分恶意代码。”</p><p>&nbsp;</p><p>Eremin表示，ThreatFabric过去曾多次发现过这种恶意软件混淆方法。但从2023年4月起，该公司发现其他已知恶意软件家族出现了更多此类变体，采取同样的方式悄然作恶。此后，该公司将这种趋势归因于地下网络犯罪中的半自动化恶意软件即服务产品，即通过混淆或“加密”恶意移动应用的方式赚取利益。</p><p>&nbsp;</p><p>Eremin还提到，谷歌已经在2023年5月9日将这份早期报告标记为“高”严重等级。近期，谷歌向他们支付了5000美元的bug上报奖金。不过从技术层面来讲，谷歌并没有将此次发现归类为安全漏洞。</p><p>&nbsp;</p><p>谷歌在书面声明中表示，“这是一种特殊情况，上报的问题并未被归类为安全漏洞，也不会影响到Android开源项目（AOSP）。但问题确实存在，我们也针对潜在的bug滥用情况对Android应用的恶意软件检测机制进行了更新。”</p><p>&nbsp;</p><p>谷歌也承认，他们向开发人员提供的一些工具（包括APK分析器）目前无法正确解析此类恶意应用并将其视为无效，它们仍被允许安装在用户设备上。</p><p>&nbsp;</p><p>谷歌在声明中补充称，“我们正在研究开发者工具的可行修复方案，并计划就此对文档内容做相应更新。”</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3e/3e035d08032f137169a26dee547ef87f.png\" /></p><p></p><p>&nbsp;</p><p>根据ThreatFabric的介绍，常见的应用分析器能够发现一些明显的恶意迹象，表明恶意应用正滥用该bug以伪装成良性应用软件。在研究中，他们发现被这种方式篡改过的应用中的Android Manifest文件，将包含比软件包中其他文件都要早的更新时间戳。</p><p>&nbsp;</p><p>更重要的是，Manifest文件本身也会被篡改，以便应用所指定的“字符串”数量（即代码中的纯文本，例如注释）与软件内的实际字符串数量相符。</p><p>&nbsp;</p><p>目前已知利用这种混淆方法的移动恶意软件家族之一为Anatsa，这是一种基于Android系统的复杂银行木马，经常伪装成用于管理文件的无害应用。上个月，ThreatFabric详尽介绍了Anatsa背后黑客团伙如何购买陈旧废弃的文件管理应用，或者开发自己的原创应用，在先积累起一定规模的用户群体之后再向其中注入恶意软件更新。</p><p>&nbsp;</p><p>ThreatFabric表示，Anatsa会冒充成PDF阅读器及其他文件管理应用，因为这类应用往往拥有删除或修改设备上其他文件的高级权限。该公司估计，Anatsa背后的黑客团伙已经在Google Play应用商店上持续开展恶意软件活动，并借此安装了超30000个银行木马。</p><p>&nbsp;</p><p>最近几个月来，谷歌因未能主动监管其Play应用商店中的恶意软件应用、或者曾经合法但后来沦为流氓软件的问题而受到批评。技术外媒Ars Technica曾于2023年5月发表一篇报道，称一款原本良性的屏幕录制应用在积累了5万名用户之后转为恶意软件。文件指出，谷歌在其平台上发现恶意软件时不会对外公布，仅在收到上报时对发现问题的外部研究人员表示感谢并删除相关恶意软件。</p><p>&nbsp;</p><p>Ars Technica的文章写道，“谷歌公司从未解释过自己的研究人员和自动扫描流程为什么会漏掉外部人员发现的这些恶意应用。即使谷歌明智Play用户被其第一方服务推广和提供的应用感染，也不愿主动发出安全通报。”</p><p>&nbsp;</p><p>报道还提到谷歌最近正做出一项积极的潜在转变：Android 11及更高版本将迎来一项预防措施。该措施可实现“应用休眠”，即让挂起的应用进入休眠状态，从而消除之前正常运行时被授予的运行时权限。</p><p>&nbsp;</p><p>原文链接：</p><p></p><p><a href=\"https://krebsonsecurity.com/2023/08/how-malicious-android-apps-slip-into-disguise/\">https://krebsonsecurity.com/2023/08/how-malicious-android-apps-slip-into-disguise/</a>\"</p><p>&nbsp;</p><p></p><h5>相关阅读：</h5><p></p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MzAxMTI4MTkwNQ==&amp;mid=2650847264&amp;idx=1&amp;sn=3c88c091cd736f0fc92f852d6884268c&amp;chksm=80b76cbeb7c0e5a87195101d8f6dc8cce101c134a2197917ce655945adc716113a5afb45eadb&amp;scene=27#wechat_redirect\">Android 资源大汇总</a>\"</p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MzA5MzI3NjE2MA==&amp;mid=2650268366&amp;idx=1&amp;sn=30899e011ebeb9c6ad367015f2d6b803&amp;chksm=886313a1bf149ab7021d908f784b932fc2127005a6fae447b1bb12a60a0794e3d997a5d465c3&amp;scene=27#wechat_redirect\">在 Android 12 中构建更现代的应用 Widget</a>\"</p><p><a href=\"https://xie.infoq.cn/article/c3e67a87128a6446872b9e782\">Android 面试必备！爆火超全的《Android 性能优化全方面解析》</a>\"</p><p><a href=\"https://xie.infoq.cn/article/cdee9c8b441f091efdeaee717\">Android Manifest 功能与权限描述大全，阿里大牛整理</a>\"</p>",
    "publish_time": "2023-08-08 14:32:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "洞悉微服务：从 PaaS 到 Serverless 的演进",
    "url": "https://www.infoq.cn/article/Az7tqVww0SabTTuOUPJ5",
    "summary": "<p>本文整理自 QCon 全球软件开发大会北京站 2023，字节跳动基础架构函数计算负责人杨华辉的主题演讲微服务从 PaaS 到 Serverless 的演进。以下为演讲全文实录。</p><p></p><p>本文将带你洞悉微服务 Serverless 的挑战和实战经验，了解函数计算如何打破固有模式，扩展应用边界和提高领域天花板的思路。本次演讲共分为 4 个部分：</p><p></p><p>背景介绍：PaaS/Serverless/ 字节微服务 / 函数计算；探索之路：FaaS 尝试 / 改造 / 变数 / 优势；生产实战：框架 /RPC/Mesh/ 镜像 / 异步长任务；总结展望：应用场景 / 通用 Serverless/ 云边一体。</p><p></p><p></p><h2>背景介绍：PaaS/Serverless/ 字节微服务 / 函数计算</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/dd/ddf8221d76f9a86a38512f6267013c65.png\" /></p><p></p><p>对于 PaaS，可以很直观的以汽车行业作为比喻，FaaS 的演进思路类比于汽车行业，就像是打车的形态，是资源效率极度高度的利用，去增加弹性的能力，比起租车更加灵活。对于整体的集团业务来说，资源的利用率进一步提升，可能比较重要的一种计算承载形式就是函数计算。当然这是在传统概念中，今天的 topic 不是纯粹的函数计算，我希望用函数计算去承载一些微服务的 workload。</p><p></p><p></p><h3>字节的微服务与函数计算规模</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/cf/cfe1df25dc9f64c778ed4c637cac9709.png\" /></p><p></p><p>字节跳动的微服务应该是业内比较庞大的体系了。对于字节的私有云租户来说，有 9 万 + 的微服务，日变更有 2 万 +，容器数有 1,000 万 +。字节跳动的在 Mesh 方面已经大规模落地，支持 Golang（Kitex/Hertz）、C++、Python、Java 等高级语言。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/04/047496bde6ed86f568b7508e9d5635ab.png\" /></p><p></p><p>字节跳动函数计算跟微服务框架是属于一个大的部门，体量在业界已经做到最大的规模。目前在私有云场景，有 17 万 + 的函数，高峰的 QPS 每秒钟有 1.2 亿的请求数，低峰的时候大概是 3,000 万的这样子。支持的语言生态体系除了前面这些所谓的高级语言，也为了微服务形态支持 native 形态。</p><p></p><p></p><h3>PaaS -&gt; Serverless 演进的原因</h3><p></p><p></p><p>为什么要做微服务 PaaS -&gt; Serverless 演进。目标很明确，就是要降本。我们从两个思路去看，一是弹性调度，如果能做到整体的弹性调度，对于整个集团规模的机器调度是一种容量托管，平台方就可以做到满足用户 SLA 的弹性，对于高低峰错峰比起混部来说会做到更加的极致。二是因为要上 serverless，服务必须要有个假设，就是扩缩会成为常态，所以服务的整体部署跟研发体系其实是要往弹性方面去做变更的，至少你得有这样的一个心态，为整体架构体系带来一种比较鲁棒的设计，因为你可以随时应对弹性，弹性不会让你的业务受损。</p><p></p><p></p><h2>探索之路：FaaS 尝试 / 改造 / 变数 / 优势</h2><p></p><p></p><p>既然要做的话我们怎么做？先说一下我们一些错误的示范，大家之后避免走弯路。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/77/77c7175fbb0e3d73641157c2c3a8536b.png\" /></p><p></p><p>首先我们希望去复用 FaaS 这种弹性的能力的，因为既然 FaaS 做到了弹性，为什么不用？因为都在一个组织架构下，所以思路也很简单。早期我们希望 FaaS 改的尽量少，只在现有架构上改，对于 FaaS 体系来看，这张图应该是比较具备代表性的， FaaS 一般都会走 Gateway，后面会打到 function Pod，它只是一个运行时的载体，然后无论在中心的 Gateway 的网关还是 Pod，都会有个我们内部叫 runtime 的组件，不同的地方叫的不一样。我们要支持 KiteX，rpc 的话如果是 HTTP 相对简单，因为大部分 FaaS 本身就是 HTTP 这种 transport 协议的。</p><p></p><p>如果对于 Thrift 这种框架的支撑，针对客户端的流量，你需要去能认识它的 Thrift，我们前期是让 Thrift 去用 HTTP transport 去做，这样可以用现有的 FaaS gateway 去承载流量。在每个 pod 内部，我们改变了用户的编程习惯，让他既知道了 rpc server，又知道了 FaaS 的 handler，这样确实能去 enable 一些业务上 FaaS，而且获得 rpc 用 FaaS 的体验。但是问题不久就显露出来了，一个是学习成本高，用户不仅需要学习 rpc 框架，也要学习 FaaS 这种框架。第二个是排查错误困难，因为涉及到两个团队的跨团队协同，在上线具体业务的时候，在 trouble shooting 的时候需要去明确错误的边界在哪里。第三个是用户接受度相对来说比较低，因为 RPC 相对在 FaaS 上面有点像二等公民，所以这块的支撑未来都是具备不确定性的。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/43/432bebd9e8261681b0b34ead7b2c0613.png\" /></p><p></p><p>我们反观看一下 Lambda 怎么做的。Lambda 在支持这种现有的框架的时候，右边 Web APP 为每一个框架去启用 adapter，但是 Lambda 这种模型基本上是用橙色部分去向它的内部的事件中心组件去拿这种消息转化成 HTTP 格式发给现有的框架。这套架构写出来的 container image 放在 paas 平台就是 AWS Fargate 或者放在 AWS Lambda 上面，只要通过一个开关去 enable 这个 adapter，就可以去实现一套的代码或者一套 container image 在不同的平台中做切换。所以给我们带来启发，不能让用户动太多的代码，用户基本上就是写蓝色部分就行了。</p><p></p><p>我们从以上的这种错误示范中得到了一些经验教训。</p><p></p><p>开发体验对齐：支持运行原生的框架代码，HTTP/RPC⽤户不⽤额外学习 FaaS 开发规范</p><p></p><p>RPC 协议⽀持：FaaS 要原生支持 RPC 协议，不用引入代码层⾯的协议转化</p><p></p><p>性能深度优化：贴近原生的性能，减少流量调度引入的额外性能损耗</p><p></p><p>但是我们也看到如果 FaaS 要做这个事情的话，有一定的变数：</p><p></p><p>1、自动扩缩容是一种非稳态的情况</p><p></p><p>2、服务发现机制和传统微服务的不⼀致，因为 FaaS 是一种毫秒级别的冷启动要求，对于服务发现的这种中心化的架构来说，其实在设计中不太满足这样的需求，基本 FaaS 都会自己去做一套比较快速的毫秒级别的服务发现体系，势必带来两种服务发现体系之间的差异</p><p></p><p>3、数据链路的管控带来的开销</p><p></p><p>有劣势当然肯定也会有优势，我们要去规避劣势，发挥 FaaS 的以下优势：</p><p></p><p>无流量缩零，快速冷启动，自动扩缩，敏捷开发上线，降本增效结合 FaaS 事件驱动的能力，便捷的触发器接⼊一套代码，处理在线请求、MQ 请求等</p><p></p><p></p><h2>生产实战：框架 /RPC/Mesh/ 镜像 / 异步长任务</h2><p></p><p></p><p></p><h3>FaaS 整体架构</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/58/58378ad27a09264656b3ebc2e8a37f9e.png\" /></p><p></p><p>我们先简单看一下 FaaS 的整体架构，各家的 FaaS 的架构基本上都是差不多的，大家基本上可以只关注于机房内部，因为外部的多个机房是为了多机房容灾。我们需要关注 FaaS 做弹性的能力以及做流量管控需要引入的一些组件，在此现出来的是 gateway 组件和 dispatcher，它是一种流量管控的组件，这种组件可以对流量进行强管控，这样才会在平常没有流量而突然有流量进来之后，能兜住流量，让它能启动完之后把流量再打过去。冷启动需要有一些比如说池化技术、预先启动等技术，一般是通过 Worker Manager 来做的。我们内部通过一些快速的消息通道去做服务发现，抽象出来一个 Discovery 服务。我们是在 k8s 这种生态上面去打造的，我们可以把 k8s 当成一个运维平台，让它去承载 FaaS 这样的 workload。但是 k8s 原生的对 pod 的拉起、服务发现其实是不满足 FaaS 需求的，所以我们内部需要在每台机器上去构建一种 Daemonset，就是 HostAengt 去做一些强管控。</p><p></p><p>当然这只是极致情况下 FaaS 的一个路径，当你做一些大规模部署的时候，一些组件可能会被无意识或有意识的 bypass 掉，去满足大规模情况下的部署需求。</p><p></p><p></p><h3>目标：开发原生应用</h3><p></p><p></p><p>开发原生态应用，这是我们的一个目标，围绕这个目标，我们希望做到以下几件事：</p><p></p><p>支持不同类型，不同语言的原生应用迁移到 FaaS 平台，低成本 Serverless 化帮助业务便捷的接⼊FaaS 已有事件源（消息队列、定时器、⽹关）提供完整的冷启动、自动扩缩容能力</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/26/262f2f1becf9426508c388c0f5706974.png\" /></p><p></p><p>用户说：我不想改代码，但是我想 Serverless。</p><p></p><p>我们提出了 FaaS Native 这样的一个方案。如图左边大概是 FaaS 原业务的单 pod 内部的一种主要组件，它需要用户去写用户 handler，用户 initialize 它（比如用 Golang），我们会提供一个 SDK。这是传统像 FaaS 事件触发类型的模式，其实需要进一步去支撑 HTTP 这种框架的话相对比较简单，因为内部都是 HTTP 协议的，我们只要去约定监听在哪个端口，然后你去监听我的 health checker 请求，我的 HTTP 的请求比较透明的去 proxy，中间可能有些 debug server。</p><p></p><p></p><h3>多协议支持</h3><p></p><p></p><p>用户说：服务侧的微服务⼀般都是 RPC 框架，HTTP 不够！</p><p></p><p>我们去支持多协议的时候，看到了几个需求，在讲这个需求之前，我们可能需要对架构进行一定的调整跟梳理。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d8/d87cd582035d81ec243f2984d92358eb.png\" /></p><p></p><p>在 FaaS 这种体系当中，其实是有虚线跟实线两种主要的路径实现部分，就是数据流的转发和数据包的转发。虚线部分其实是什么时候拉起 pod，有点像管控的需求，这部分你在支持多协议方面其实是不需要改动的，这也是为什么用同一套架构可以比较快速地去支撑多协议的这种应用。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/2d/2d56620882060bfa4e26c009d244de22.png\" /></p><p></p><p>具体其实一开始左边这部分我们有一个统一流量端口，因为我们都是 HTTP 协议的，所以大家通过 HTTP 的 header 直接去区分就可以了，没必要去启两个端口，但是在多协议支撑方面，我们意识到这对于工程代码质量方面是一个负担。我们需要去开两个端口，实现单独开数据请求窗口，流量到户。在多协议支持方面，这种数据路径上基本趋向于一致。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7c/7c68c0932b15eab7034a3f57eecdfb9e.png\" /></p><p></p><p>一开始我们是 HTTP1.1 的，而 gRPC 是基于 HTTP2 的，然后所以 HTTP2 反正都得做。另外 HTTP1.1 其实对于微服务是不太友好的，原因是 HTTP1.1 不是二进制协议，它本身的传输代价比较高，另外它不能在一条连接中去多路复用，一个连接进行一个多个 connection 的传输。所以 HTTP2 二进制跟多路复用的特性也是让我们有升级的动力。整体上的变化如图，右边部分是代表它是可以做到多路复用，多个 stream 的 request 和 response 可以在同一个连接中去完成，这样对于 pod 多并发模式是更加友好的。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/70/70cc21d40b6442effea76cc8fdaa6734.png\" /></p><p></p><p>做完 HTTP2 的支持，gRPC 相对来说就比较简单了，因为它本身就有 HTTP2 的。不一样的地方是 gRPC 不看 HTTP 整体的返回码 400、500 或者 200 这种 status code，更多看的是 head 中返回的 response 中的 gRPC status。所以为什么我们要去看 response，但是不会去看它的 body，原因是在 FaaS 中你需要去监听他的错误或者正确，所以我们要针对这种请求的结果做一些支撑。当然 gRPC 做流式传输的时候，在 FaaS 平台上也是支持的，比如说我们一次请求调用支持最长 15 分钟，那 15 分钟之内做一些流式传输是不会被掐断的，如果有更长时间的流式传输，我们会有其他方案。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c2/c27a147bd419dac8e16e61697de15c3a.png\" /></p><p></p><p>讲完这种 gRPC 的支持，我们看一下 Thrift 的这种支持，因为 Thrift 在字节跳动内部还是主要的一种协议场景。</p><p></p><p>我们内部有一个私有协议，叫 TTheader，它开源叫 Theader，关键就是中间用中文写的，可变长度的 Header 内容，可以让你去携带一些原数据信息，为什么要携带原数据信息？是因为在 FaaS 中我们是通过 FaaS 的 function ID 或者其他 ID 做一些传输，但是整体微服务肯定会根据整个公司治理的一种唯一标识，在我们自己内部叫做 psm，这个在函数底层架构要有一些转化，我们不希望去感知这种上层的智力带来的复杂的无意义的东西，所以我们希望把它做一个转换，转换成 FaaS 内部自己可以感知的一种唯一标识。所以说你要在 head 中去感知这个东西，刚好有个地方可以存，当然你在协议设计方面本来就应该有这种灵活度，否则你的协议就是不健康的。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/24/24d09104c9aea3f4f8b5f4821ba90556.png\" /></p><p></p><p>刚才一直在讲的是单机层面的多协议的支持，但是对于一整个系统来说，遇到一些中心的流量，可能会经过一些网关。刚才我们一开始讲 FaaS Gateway 只是一个 HTTP 的 Gateway， HTTP 不可能去接受这种 sleep 的协议，他直接就拒绝掉了。所以我们需要在 gRPC 跟 http 共享一个 http Gateway，但是在 SaaS 的这种场景中，我们要独立部署一个新的 Gateway 去支撑所有的协议，因为我们要对一些长尾的流量做强管控。当然要强调一点，我们不是所有的流量都是过网关的，否则每秒就会有 1.2 亿的流量过网关，资源开销也是巨大的。</p><p></p><p></p><h3>融入字节微服务治理体系 ByteMesh</h3><p></p><p></p><p>用户说：前端流量通过网关进来没问题，微服务流量如果都经过网关引入额外消耗，治理也不够自由！</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3c/3cd5fdca446ac4687ccb84275d30b514.png\" /></p><p></p><p>其实我们的回答也很明确，我们做微服务上 FaaS 是不希望丢弃掉原先在传统的微服务平台上面建设的各种治理能力的，如果你能很好地继承下来，这件事情的推进会相对的更加顺畅。</p><p></p><p>简单来看，我们去迎合自己内部微服务的一个治理体系，内部的产品名称叫做 ByteMesh。首先要解决几个问题：</p><p></p><p>上游服务，通过 ByteMesh 出流量代理，访问下游 FaaSFaaS 服务，通过 ByteMesh 出流量代理，访问下游服务FaaS 服务，通过 ByteMesh⼊流量代理，承接上游服务发来的请求</p><p></p><p>上游的服务要通过 Mesh 去访问到 FaaS 类的服务，要通过 Mesh 达到下游。FaaS 本身的服务可能要开启 Mesh 入流量去做单机 pod 的治理，无论是安全的治理还是限流的治理。这些都可能是一种开关，当然是一种排列组合的关系，不一定所有的服务要把所有都开启，是按需开启的，我们在一定场景中开启的大部分可能都是 FaaS 针对下游的出流量 Mesh。目前跳动内部的 Mesh 体系推广的更多是一种 sidecar 的体系。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/78/7846f7bfa5a02463aac315ffa4e88743.png\" /></p><p></p><p>然后这边讲一下上游服务要访问 FaaS 的话，我们要解决两个问题，一方面是我们跟 Mesh 之间要有一种服务发现的协商，我们不希望把这种路由信息发布到原始的 Faas 体系中的服务中心里头，因为它太慢了，所以它不能支撑 FaaS 这种需求，所以我们要去打通 Mesh 跟 FaaS 之间的服务发现体系，做到毫秒级别的服务发现。对于小流量跟大流量我们是分开去考虑的，对于小流量场景，完全通过 gateway 的话更加简单一点，因为可能流量就是从 0 个实例变成个位数的实例，网关去承载这些流量完全没有负担，如果是超大流量的话，我们会跟 Mesh 进行协商，其实 Mesh 不太敢做这一点，原因是我们返回给 Mesh 的，有可能是 gateway 的 IP，有可能是后面直接的 IP。所以对于 Mesh 团队来说，他没有这种心智负担，主要问我们有哪些 IP 就可以了。我们可能有时候告诉他是 gateway 的，有可能告诉他不是 gateway 的，取决于我们觉得流量规模有多大，能不能过中心网关。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/65/65ce21dada61ed67c1ecfa727e01224d.png\" /></p><p></p><p>处理代理做完之后，用户通过 Mesh 就可以访问到 FaaS 了，上游的 FaaS 如果访问下游的话，如果要去享受一些治理的特征，也得去 follow Mesh 这条链路。不同点在于，常规的 Mesh 做这种流量的服务的拉起的时候，更多考虑的是环境变量或者环境是后注入的，原因是在 FaaS 上有一些冷启动的 pod 会给这种合作提供一些更高的要求，我们需要 Mesh 提供 hot reload 的机制，让我们动态可以加载一些服务信息。另一方面对于 Mesh 本身的 sidecar 的拉起速度我们也提了更高的要求。所以其实是 FaaS 团队跟 Mesh 团队一起去达成这样的目标。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d4/d470190232c9b82da106c52d50b28226.png\" /></p><p></p><p>对入流量接入代理，其实跟出流量差不多。入流量也是流量先先过 Runtime Agent，当然在实际情况下可能经过 Mesh，可能经过 sidecar，当然这是内部架构的调整，我们预期的这种模式应该是先过 FaaS Runtime Agent，然后再过流量代理，然后再到用户的代码，然后 Mesh 可以去做一些流量治理，可能还会有一些 sidecar 策略。其实这些大部分都是一些传统微服务的内容，我们只是把它在 FaaS 的场景中做适配，然后让整体的 FaaS 体系跟原先的微服务体系尽量趋近，做到这种流量治理的继承。</p><p></p><p></p><h3>自定义镜像支持</h3><p></p><p></p><p>用户说：我有好多依赖，默认的镜像环境没有我要的依赖， 我的依赖打成 static library 很麻烦！</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/52/52f1296fa7242d888ed994bc9584aa93.png\" /></p><p></p><p>FaaS 逻辑是基础镜像从整体的产品角度管控，如果有太多的基础镜像的话，做基础镜像的分发对于冷启动来说是一个很大的压力，所以我们要去管控基础镜像是有限个的。但是基础镜像中可能没有某些客户要的东西，我们要支撑这部分用户的话，就得去做自定义镜像的支持。在 k8s 上面有一种 Init 这样的模式。Init 跟应用的 business content，share 一个 volume，volume 里头可以扔一些二进制，应用容器可以看到里头的二进制，我们控制启动命令，用户提供的就是应用容器的镜像，我们不需要对镜像进行二次的打包修改，但是可以直接享受 FaaS 能力，因为我们会注入一个 sidecar 运行它。Init 容器在跑完之后就会消失不见，所以它本质不占用运行时的资源开销，所以整体上对于资源开销也是没有问题的。</p><p></p><p></p><h3>异步长任务支持</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/84/8476f09b7c2262d10e4acd07862e7e5f.png\" /></p><p></p><p>用户说：15min 调用时长不够，我的业务需要是⼀个长任务</p><p></p><p>不支持太长时间的原因是传统的 FaaS 平台更多是一种同步调用的逻辑，这种逻辑去支撑更长时间的调用对于平台来说是一个很大的负担。但是有时候用户说没办法，你就得支持异步任务。在异步任务方面，我们抽象出来几个组件做为边界，在单机 Pod 层面可以看右边的两条线，运行时它落在同样的一个 Pod 内部，同样一个 Pod 内部的网络空间，基本上是可以支撑超长时间连接的建立跟维护。你要做的是要在你的中心调度系统跟 Runtime Agent 的之间做异步调用的解耦。这种解耦通过异步的轮巡的机制，用户调用你的时候，一次返回一个 request ID 然后可以慢慢拿到结果。通过这样的方式，其实只是用户调用的方式有一定的改变，剩下的仍然是在一套系统中做的支撑，只是可能在调度系统这边会引入一个 Gateway。</p><p></p><p></p><h3>微服务方面的 building block</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/27/27a54bf5a7b99347bda647231b23a22c.png\" /></p><p></p><p>以上说的那些部分，基本上解决完之后，原生的服务框架基本上可以不改代码的情况下运行在 FaaS 平台上，但要落到实际生产中仍然会遇到一些问题。</p><p></p><p>一是在 FaaS 平台中我们基本上会强调一种并发的强控制，无论是单 Pod 的单次并发，还是你单 Pod 同一时间支持 100 个并发。在支持这种并发的时候，其实更多考虑的 workload 是比较单一的，但在微服务场景中不一样，不同的 endpoint 都可能是不同的 workload，无法用归一化的 workload 去简单描述一个 Pod 在同一时间能接受多少并发，所以就只能改变，就是我们要弱化并发这种模式。我们希望通过过载反馈的机制把扩容的需求做出来，因为之前你要去控制并发，无非就是防止 Pod 过载。我们弱化并发，不再在微服务场景中去算并发，仅把它作为一个兜底扩容的策略，本质上我们会用一些服务的表现，去做过载因子的判断，判断反馈服务 Pod 是否过载，可以在 Pod 内部快速感知到这种情况，反馈到 FaaS 一些组件中，在毫秒级别内去拉起一个实例，做到快速扩容。快速扩容完之后，这个服务需要被上游发现才能用得起来。所以又涉及到需要做一些 p2p 的转发，才能让这个新的 Pod 可以尽快加入到生产系统中。</p><p></p><p>二是对于弹性实例 / 预留实例的思考。传统云厂商是不一样的策略，如左边这张图，绿色部分是整个业务需要的计算资源的情况，蓝色部分是 FaaS 的 autoscaling，在一些突发场景，比如标红的 cold start 场景，是不够满足的，这就会造成一种尖峰尖刺，在业务场景里面就会出现一种抖动。传统情况下，如果在 FaaS 上面遇到这样问题，传统的 FaaS 平台告诉你说如果非得让尖峰不存在，要么就是提前知道波峰，提前扩容，要么就是直接预留最大实例，退化成 PaaS 平台。我们不希望那么大浪费，不希望用户为低峰的时候去买单，但是我又不希望自动扩充引入这种毛刺的效应。</p><p></p><p>我们做法是区分了弹性实例跟预留实例，然后在预留实例场景中关键时预留实例，比如说你要预留三个，日常尽量的不把请求打到预留实例上，只有当迫不得已的情况下才打过去，跟传统的其他的 FaaS 的做法都不一样。</p><p></p><p></p><h2>总结展望：应用场景 / 通用Serverless/ 云边一体</h2><p></p><p></p><p>总结展望一下我们应用场景。</p><p></p><p></p><h3>微服务 serverless</h3><p></p><p></p><p>微服务 serverless 支持和应用情况如下：</p><p></p><p>FaaS支持原生HTTP 框架，Hertz、Koa、Flask、DjangoFaaS支持 RPC 框架，gRPC、Thrift based Kitex(Golang)、Python、C++、 Node.js、Rust自定义镜像、异步任务Mesh &lt;-&gt; FaaS QPS: 15 million qps（5 million online service）</p><p></p><p></p><h3>通用Serverless</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d2/d2dcb4efa1d490da13ade9c008efa284.png\" /></p><p></p><p>非微服务场景怎么办呢？有人提出一种通用 Serverless 的想法，如图右边有点像目前 FaaS 的形态，包含了 FaaS 加上 BaaS，然后把各种非 FaaS 的计算形态或者存储形态提供出来的服务归类成 BaaS。其实这种归类有一个问题，就是不同的 BaaS，假设哪一天说要做 Serverless 的话，可能需要把 Serverless 的各种东西重新做一遍。有没有可能把大家的层次提一级，变成左边这个部分，把最核心的弹性需要的能力、FaaS 的计算能力、存储的能力去下沉。你把单机想象成一个分布式环境的简化版本，在一个分布式环境中，你无非是需要计算跟存储资源，还有网络资源，然后主要考虑计算跟存储能不能抽象成一些 building block，让 FaaS 专注于做弹性计算，让 Object storage 去做存储方面的 Serverless 支撑，统一去构建基础架构的统一的 Serverless 平台，让上面的各种各样的服务可以在这种平台上面去建设，然后获得这种弹性的能力。</p><p></p><p></p><h3>Multi-runtime Architecture</h3><p></p><p></p><p>我们刚才说的更多是一种渐进式的演进，为什么说是渐进式？因为我们一种理念是希望用户不怎么改变，我们去渐进的去迎合用户去做 Serverless，有没有一些其他的思路？</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/54/542e31c450bad98d69beffa702028a5d.png\" /></p><p></p><p>这 4 张图从单体到微服务到 FaaS，这是我们现在都知道的模式，有没有最右边这种模式，它比起第三种模式，中间又切了一层，把用户的 Business domain 跟基础的一些能力去做分割，为什么要做这个分割？</p><p></p><p>这么分割的话，灰色部分会专注于所有底层引擎跟远端的交互，有点像 Dapr 那样的一个思路，就是把所有跟架构其他层面上的一些交互全部收敛到下层，因为这是大家都需要建设的，不如让一个技术架构团队去做建设，让它的封装程度进一步的增加。好处是 business domain 会更加收敛，它的产物也会比较小。因为在上面的这种微服务的体系中，其实冷启动是很难解决的问题。能不能让你的业务的代码足够的小，小到基本上可以去做一些比较全量的预加载？</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a3/a323778ecba77d3aa4a8ed6bedc4d9f0.png\" /></p><p></p><p>对于基础架构来说，提供的是一种 Runtime 更加聚合收敛的系统接口，这种系统接口可能不像暴露 Linux 上面的各种 syscall，你不能随意的去读写文件，去跟外头进行交互，你可能更多的是通过 Runtime 提供出来的语义，给你提供系统界面，你在这个基础上做一些编程，这种系统界面就可以高度的去做抽象跟收敛。Business code 上面就会变得比较小，它的二进制产物也比较小。我们把整体的 Runtime 进行聚合，WebAssembly Runtime 会去收敛 Hostcalls 对外部的 HTTP、KV、日志的所有东西。</p><p></p><p></p><h3>精简架构</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b8/b8da731382b35c53ddafec815cf10c33.png\" /></p><p></p><p>其实很多 gateway、dispatcher、Worker manager 等等这些 FaaS 上面为了弹性做出来的组件都可以一概不要，这就变成一个很精简化的架构。你要流量的话它瞬间去拉起，然后瞬间做冷启动，待会可以 share 下数据，这个数据是我们在 Wasm 让他们做的冷启动，是带业务逻辑的，这个冷启动可以做到 0.5 毫秒。无论是微服务内部之间的，还是前场的应用这种冷启动开销都是无感知的。这基本上可以做到充分的弹性，这种充分的弹性其实可以应用到一些云边场景。</p><p></p><p>以上基本就是我们针对字节微服务 Serverless 场景的技术分享和一些展望，希望可以和大家充分交流，共同推动 Serverless 领域的基础能力建设和业务应用。</p><p></p><h5>相关阅读：</h5><p></p><p></p><p><a href=\"https://xie.infoq.cn/article/8f68c7fabb67aa4ba8163c561\">如何用 7 分钟击破 Serverless 落地难点？</a>\"</p><p><a href=\"https://xie.infoq.cn/article/d6b5fb50ecfc4a41d8e1a6bc5\">Serverless Devs 重大更新，基于 Serverless 架构的 CI/CD 框架：Serverless-cd</a>\"</p><p><a href=\"https://xie.infoq.cn/article/5724f1c2c5f448b15339eade2\">应用 Serverless 化，让业务开发心无旁骛</a>\"</p><p><a href=\"https://xie.infoq.cn/article/5c76ea183f1b079f5077ba46d\">Serverless 的前世今生</a>\"</p>",
    "publish_time": "2023-08-08 14:32:44",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "会议内容被拿去训练大模型！Zoom：我的AI功能可不“白给”",
    "url": "https://www.infoq.cn/article/yfd3Ib1N7mFmzOX5kFYF",
    "summary": "<p>最近，流行的视频会议平台 Zoom 对其<a href=\"https://explore.zoom.us/en/terms/\">服务条款</a>\"进行了重大更改，这在其庞大的用户群中引发了强烈担忧。</p><p>&nbsp;</p><p>通过此次更改，Zoom 获得了使用用户数据来训练人工智能 (AI) 的许可。更新后的条款授予<a href=\"https://www.cyberkendra.com/2022/01/zoom-fix-high-severity-bug-disclose-by.html\">Zoom</a>\"针对客户内容的“永久性、全球性、非排他性、免版税、可再许可和可转让的许可”，并延伸到“机器学习”和“人工智能”等目的。也就是说，Zoom可以使用特定的用户数据来增强机器学习或人工智能，包括算法训练和调整。</p><p>&nbsp;</p><p>这些变化最初是由以开发者为中心的网站 Stack Diary 发现的，不久之后，该消息就在网上引发了激烈的争论。许多用户对 Zoom 将客户数据用于人工智能的决定表示愤怒，而Zoom 将数据用于人工智能和机器学习细节的不透明进一步加剧了人们的恐慌。</p><p>&nbsp;</p><p></p><h2>“Zoom 还能相信吗？”</h2><p></p><p>&nbsp;</p><p>该公司的法律文件将用户的视频、音频和聊天记录统称为“客户内容”。该公司对“服务生成数据”也保留类似的权利，其中包括遥测数据、产品使用数据、诊断数据以及通过分析用户内容/行为获取的其他信息。</p><p>&nbsp;</p><p>“许多与医院/治疗师/等进行的远程医疗操作都使用Zoom——我怀疑是因为他们的客户可以通过浏览器在没有应用程序或账户的情况下进行连接。当您通过浏览器加入到 Zoom 会话时，您无需签署 TOS（Terms of Service，服务条款）。我认为，获得许可的医疗机构都有自己的 TOS 条款，这些条款与 HIPPA 要求兼容。语音到文本转录等方面的培训……将是相当严重的隐私侵犯，特别是在医疗等服务范围内。一方面，存在对人工智能的明显攻击，以从中获取训练数据；另一方面，这些数据可能提供给正在验证其是否适合训练的员工/承包商访问。”网友“danShumway&nbsp;”提出了自己的担忧。</p><p>&nbsp;</p><p>注： TOS（Terms of Service，服务条款）；HIPAA（Health Insurance Portability and Accountability Act《健康保险可携性和责任法案》）由美国第104届国会制定，并由比尔·克林顿总统于1996年8月21日签署通过。</p><p>&nbsp;</p><p>虽然有网友指出，Zoom 有针对 HIPPA 法规的特定版本。但仍有网友指出，医疗保健专业人员仍然使用传真。“模拟线路传真符合 HIPAA 标准，因为它不会‘存储’。”</p><p>&nbsp;</p><p>“我认为问题不在于 Zoom 的安全措施是否经过审计，”网友haldujai说道，“而在于他们是否可以在法律不明确的情况下使用存储的 PHI 进行产品开发。”</p><p>&nbsp;</p><p>Zoom 的服务条款更改也引发了大家对其他会议软件的担忧。“Google Meet 的 TOS没有具体提到人工智能，但确实提到了使用客户数据来更广泛地“开发新技术和服务”。”有网友指出。</p><p>&nbsp;</p><p>当有网友表示“值得庆幸的是，<a href=\"https://jitsi.org/meet-jit-si-terms-of-service/\">Jitsi Meet</a>\" 的 TOS 中没有类似的内容”时，有人在帖子下指出，Jitsi Meet ToS 第 4 节授予了他们类似的权利，只是用了更模糊的语言。</p><p>&nbsp;</p><p>“您授予8×8 Inc（以及我们的合作伙伴）全球范围内的许可，允许其使用、托管、存储、复制、修改、创建衍生作品……传播、发布、公开表演、公开展示和分发此类内容，但仅限于以下目的：运营和使服务能够按您的预期运行的有限目的，不用于其他目的。”</p><p>&nbsp;</p><p>该网友指出，每个运营视频会议服务的人都会在其服务条款中包含类似这样的条款。Zoom 变得更加明确，这通常是一件好事。如果 Jitsi 想要同样明确，他们可以添加一些内容来澄清这不包括训练人工智能模型。</p><p>&nbsp;</p><p>引发大家强烈担忧的另外一个原因是，Zoom在遵守消费者隐私承诺方面一直表现不佳。2020年，Zoom表示将只向付费用户提供端到端加密，但这种将隐私保护作为付费功能的行为受到强烈抗议而被迫作罢。一项诉讼称，该公司口头上表示向所有人提供端到端加密，但实际使用的却是另一种安全性更弱的加密形式（Zoom随后解决了此问题）。</p><p>&nbsp;</p><p>该公司还在客户不知情的情况下，向谷歌和Facebook共享用户数据。2021年，Zoom同意以8500万美元就这些问题及其他争议达成和解。上周，Zoom又撕毁了居家办公政策，要求住在公司附近的员工每周至少要有两天到单位工作，作为一个生产在线办公产品的企业，此举让广大网友直呼“在线办公的时代已经结束”。</p><p>&nbsp;</p><p></p><h2>Zoom 回应了个寂寞</h2><p></p><p>&nbsp;</p><p>Zoom的AI政策之前并不受关注，直到上周末相关帖子在高影响力的黑客新闻论坛上爆火，用户群体才普遍惊觉并表示愤怒。周一上午，Zoom公司首席产品官Smita Hashim发表博文，称原则上该公司并没做过服务条款中描述的行为。</p><p>&nbsp;</p><p>Hasim澄清道，虽然该公司确实将数据用于某些机器学习目的，但“在AI方面，若未经客户同意，我们不会使用音频、视频或聊天内容来训练我们的模型。”然而值得注意的是，Zoom也表示，如果用户选择使用 Zoom 的人工智能功能（例如会议摘要工具），他们将被要求允许共享该内容以进行人工智能培训。</p><p>&nbsp;</p><p>也就是说，作为通话对象，我们如果想要使用Zoom 的人工智能功能，那么就别无选择，只能同意Zoom的政策，允许 Zoom 利用我们的数据构建和训练模型。</p><p>&nbsp;</p><p>当前，各行各业都在寻找AI的合适落地，Zoom也不例外。Zoom今年3月推出了“Zoom IQ”，一组能总结聊天线索并帮助用户根据书面聊天内容自动生成回复的功能。</p><p>&nbsp;</p><p>Zoom IQ包含多项功能，重点的是会议主持人能使用其生成会议纪要，并通过Zoom内置聊天功能Zoom Team Chat或电邮发送给与会者，不用对会议进行录影以便回顾。此外，用户还能使用AI协助其在聊天室里撰写讯息。该功能由Open AI驱动，会根据聊天内容创建讯息，并允许用户修改讯息语气或长度。</p><p>&nbsp;</p><p>Zoom IQ属于可选功能，在启用之后，Zoom会默认开启一个小的复选框。而如果懒得点击取消，用户就相当于允许该公司收集数据并利用自己的数据构建/改进其AI模型。在启用Zoom IQ开始通话后，通话对话也会收到标题为“会议纪要已启用”的通知。弹出窗口显示“帐户所有者可能允许Zoom访问和使用您的输入与AI生成内容，以支持功能交付和Zoom IQ产品改进，包括用于模型训练。”</p><p>&nbsp;</p><p>据悉，Zoom 利用了自己专有的大型语言 AI 模型，以及来自领先 AI 公司（如 OpenAI 和 Anthropic）和特定客户自己的模型。此前 <a href=\"https://support.zoom.us/hc/en-us/articles/16269138857229\">Zoom 称</a>\"，该公司“从用户与 Zoom IQ 功能的交互中收集数据，包括输入、消息和人工智能生成的内容”，并可以使用这些信息来训练 Zoom IQ 人工智能模型（但不能是第三方模型），除非用户选择不与 Zoom 共享数据。</p><p>&nbsp;</p><p>近期，Zoom 针对大中型董事会、高层面试等场景，发布了新的<a href=\"https://explore.zoom.us/en/products/zoom-rooms/features/intelligent-director/\">智能导演</a>\"功能。Zoom 的软件将聚焦于每个参与者的面部，并将他们的面部显示在屏幕上的一个框中，然后跟踪他们的移动。对此，Zoom 首席产品官 Smita Hashim 声称，其系统不会收集任何类型的生物识别数据，而只是检测镜头前的人是否具有必要比例。</p><p>&nbsp;</p><p>未来，Zoom 还计划通过与 OpenAI 和 Anthropic 的合作推出其他几项人工智能驱动的功能，包括将以过往的会议、电话和电邮内容生成电邮草稿，以及一键整合聊天室的对话。据悉，Zoom 正在开发会议查询功能，用户可以在聊天室内向AI发问，AI便会在不打断会议的情况下生成其错过的会议内容。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>结束语</h2><p></p><p>&nbsp;</p><p>不可忽视的是，对于普通用户来说，Zoom 的进入门槛比同类中的任何其他应用程序都要低。许多人会认为，相对隐私，可用性可能更为重要。但这并不意味着我们要在数据隐私上做出妥协。</p><p>&nbsp;</p><p>最近，国家网信办联合国家发展改革委、教育部、科技部、工业和信息化部、公安部、广电总局公布《生成式人工智能服务管理暂行办法》，并规定生成式人工智能服务提供者在进行预训练、优化训练等训练数据处理活动时，要使用具有合法来源的数据和基础模型；涉及个人信息的，应当取得个人同意或者符合法律、行政法规规定的其他情形；涉及知识产权的，不得侵害他人依法享有的知识产权等。</p><p>&nbsp;</p><p>欧洲议会在6月份通过了《人工智能法案》（AI Act），成为全球首个监管AI的法律草案。该法案规定，AI 基础模型供应商如谷歌、微软等有义务公开披露所用材料是否受版权保护，从而提高版权及核心数字资产的价值。</p><p>&nbsp;</p><p>随着人工智能在我们生活中应用地不断增多，怎么安全、放心地使用这些功能不仅是对厂商们的考验，更是我们对自己负责的表现。</p><p></p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://gizmodo.com/zoom-ai-privacy-policy-train-on-your-data-1850712655\">https://gizmodo.com/zoom-ai-privacy-policy-train-on-your-data-1850712655</a>\"</p><p><a href=\"https://www.theverge.com/2023/6/5/23749338/zoom-ai-summaries-missed-meetings\">https://www.theverge.com/2023/6/5/23749338/zoom-ai-summaries-missed-meetings</a>\"</p><p><a href=\"https://news.ycombinator.com/item?id=37021160\">https://news.ycombinator.com/item?id=37021160</a>\"</p><p><a href=\"https://shimo.im/outlink/gray?url=https%3A%2F%2Fblog.zoom.us%2Fzooms-term-service-ai%2F\">https://shimo.im/outlink/gray?url=https%3A%2F%2Fblog.zoom.us%2Fzooms-term-service-ai%2F</a>\"</p>",
    "publish_time": "2023-08-08 14:52:19",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "阿里云资深技术专家周洋（中亭），确认担任QCon北京架构稳定性专题出品人",
    "url": "https://www.infoq.cn/article/A9GNzOMj894iVB3WVYgb",
    "summary": "<p>9 月 3 日 - 5 日，在 <a href=\"https://qcon.infoq.cn/202309/beijing?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=0808&amp;utm_content=zhouyang\">QCon 全球软件开发大会（北京站）</a>\"，阿里云资深技术专家周洋（中亭）将担任「架构稳定性」的专题出品人。在此次专题中，你将了解到架构稳定性和可观测性在当今软件开发中的重要性。</p><p></p><p><a href=\"https://qcon.infoq.cn/202309/beijing/track/1585?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=0808&amp;utm_content=zhouyang\">周洋（中亭）</a>\"，阿里云应用可观测 &amp; 高可用架构团队负责人，QCon 大会出品人、QCon 北京 2019 明星讲师、混沌工程布道师。2011 年加入阿里巴巴，主导高可用架构的多项技术的规划、演进和规模化实践落地，双十一大促保障负责人，积累了丰富的架构和稳定性经验。</p><p></p><p>相信周洋（中亭）的到来，可以帮助提升此专题的质量，让你认识到在当今的软件开发中，架构稳定性和可观测性都是非常重要的考虑因素。通过保持架构稳定性和提高可观测性，开发人员可以更好地管理和维护系统，确保其可靠性和高性能，以满足不断变化的业务需求。</p><p></p><p>除上述专题外，QCon 北京还将围绕<a href=\"https://qcon.infoq.cn/202309/beijing/track/1553?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">异构计算</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1554?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">向量数据库</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1556?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">FinOps&nbsp;落地</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1558?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">业务安全技术</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1557?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">从&nbsp;BI&nbsp;到&nbsp;BI+AI，新计算范式下的大数据平台</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1559?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">从&nbsp;MLOps&nbsp;到&nbsp;LLMOps</a>\" 等进行分享。</p><p></p><p>近 100 名讲师、近 30 个精彩专题、8 种交流活动，QCon 北京 2023，相约 9 月！现在购票，享 9 折特惠，立省 ¥880！咨询购票请联系 18514549229（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/33/33cbbbf20baa8b2a18db4f0681f159aa.jpeg\" /></p><p></p>",
    "publish_time": "2023-08-08 15:21:17",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "数据量爆炸式增长，“万众瞩目”的MongoDB 有何解决方案？",
    "url": "https://www.infoq.cn/article/0ZM77Ph6N4ioloJjtbv4",
    "summary": "<p></p><p>随着人工智能和机器学习技术发展进入深水区，数据量呈现出爆炸性增长的趋势，企业需要确保应用程序能够高效地存储、处理和分析海量数据，同时还需要确保数据的高可用性和可扩展性。另外在业务要求下，企业开发者还需要确保应用程序能够支持包括实时分析和离线分析等在内的各种数据分析需求。</p><p>MongoDB 作为一种流行的<a href=\"https://xie.infoq.cn/article/5aa617805063b1c0f4ec53dee\"> NoSQL</a>\" 数据库，因其可扩展性、灵活的<a href=\"https://xie.infoq.cn/article/36c678cbc9b3f8c515827b4dc\">数据</a>\"模型和易用性而受到广泛欢迎。它能够处理各种规模的数据，并且可以轻松扩展以支持不断增长的用户和数据量，同时还提供了高可用性和冗余选项，以确保数据在硬件故障或系统维护时仍然可用，近几年一直是开发者和架构师们关注的热门数据库。</p><p></p><p>MongoDB .local （MongoDB 用户大会），是面向各行各业的<a href=\"https://xie.infoq.cn/article/372320c6bb93ddc5b7ecd0b6b\">数据库</a>\"专家、技术爱好者、客户和用户的年度盛会。MongoDB 用户大会将在 8 月 29 日北京和 8 月 31 日深圳举办。在每一场大会中，大家都将学习到 MongoDB 最新发布的技术、高效的工具和典型行业的最佳实践，帮助您轻松构建数据驱动的应用程序，帮助企业降低成本，提升开发效率。</p><p></p><p>2023 MongoDB 中国用户大会北京站</p><p>8 月 29 日，北京 JW 万豪酒店</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/62/625ed1d70890920c49d491ef449a9d80.jpeg\" /></p><p></p><p>2023 MongoDB 中国用户大会深圳站</p><p>8 月 31 日，深圳益田威斯汀酒店</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/de/ded6d0b2956f2b2aca260877c76821ab.jpeg\" /></p><p></p><p>在现场的互动展区，你可以与 MongoDB 的技术专家进行面对面交流、探讨业务需求以及所面临技术问题，技术专家们将在现场带你手把手体验 MongoDB 最新产品功能，现场指导 demo 使用。参与互动的伙伴，还可以获得多种多样的 MongoDB 周边礼物！</p><p></p><p>立即识别下方二维码进行报名</p><p>我们在现场不见不散！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f4/f45aceaded5ef21e02e503e57e1fb7dd.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c6/c608ced3968364dd3dee1ddfd987635a.jpeg\" /></p><p></p><p>特别福利</p><p>大会现场前 50 名到场签到的嘉宾</p><p>还将享受早鸟福利——&nbsp;MongoDB 定制保温杯！</p><p>一定要早早到现场哦！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b6/b6daf95e226a60521c72a50ee194a715.jpeg\" /></p><p></p>",
    "publish_time": "2023-08-08 17:45:56",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]