[
  {
    "title": "组装式专家洞察|中国移动初瑞：基于智慧中台的“组装式”探索实践",
    "url": "https://www.infoq.cn/article/c52f4adacf2e19cb093c15869",
    "summary": "<p></p><h4>引言</h4><p></p><p></p><blockquote>近期，企业数字化发展共建共享平台、云计算标准和开源推进委员会（CCSA TC608）成功举办了首次“技术前沿|“组装式”发展趋势观察沙龙”，与会专家分享了对“组装式”的探索与实践，中国移动信息技术中心智慧中台运营中心副总经理初瑞带来了《基于智慧中台的“组装式”探索实践》的主题分享。初瑞表示，中国移动作为建设网络强国、数字中国、智慧社会的主力军，紧跟组装式前沿技术发展趋势，依托智慧中台进行探索实践，在赋能企业高质量发展和数智化转型方面取得积极成效。</blockquote><p></p><p></p><h4>一、“组装式”带来技术架构和业务模式的变革</h4><p></p><p>“组装式”是近两年新出现的热门技术词汇，作为“塑造变化”的关键技术之一，将成为数字业务和创新力量的加速器。“组装式”带来的不仅仅是思维方式的变化，更是技术架构和业务模式的变革。通过封装成具有可复用、可扩展、可组装、可自治等特征的组件，充分实现资源利用率提升、业务弹性扩充。</p><p></p><h4>二、运营商在传统应用开发运维中的3个痛点</h4><p></p><p>当前数智化转型已成为各企业的必答题，数字经济和实体经济融合发展加速，不断推动制造业、服务业、农业等产业数字化，利用互联网新技术对传统产业进行全方位、全链条的改造，提高全要素生产率，发挥数字技术对经济发展的放大、叠加、倍增作用。</p><p><img src=\"https://static001.geekbang.org/infoq/04/049dea6ddc691b3ce33bf0e88fadb228.jpeg\" /></p><p>传统运营商在开发运维中存在三大痛点：第一，开发复杂度高，业务上线慢；第二，系统稳定性差，运维难度高；第三，能力复用度低，成本投入大。受“组装式”所带来的一系列新方式的启发：如组装式企业、组装式应用、组装式平台、组装式构架等，中国移动积极开展组装式的研究和推进工作。</p><p></p><h4>三、中国移动从智慧中台实践到组装式发展探索</h4><p></p><p>面对数字经济新蓝海和数智化转型新要求，中国移动将全力打造业界标杆级智慧中台，聚焦“积淀能力、支撑发展、注智赋能”总体目标，边建设、边运营、边完善，目前智慧中台已迈入“规模化发展、精细化运营”快车道。</p><p></p><p>在智慧中台的建设运营过程中，中国移动积极开展“组装式”探索实践，一是遵循“业务闭环”、“可扩展”、“互联互通”、“能力标准化”等原则，构建组装式框架和体系，从中台能力打造到中台能力应用，实现对业务创新和数智化转型过程的充分赋能；二是打造“中央厨房式”一体化开发交付环境，实现组件的集中汇聚、分级管控和灵活编排，关键业务需求的支撑响应速度提升了20%以上。</p><p></p><p>初瑞强调，在组装式研究中，无论是对组装式组件的探索，还是对组装式平台的标准化，这些组装式模块，不仅要能够被灵活组装，同时其运行时框架以及框架所依赖的技术底座也需要进行规范化。如果“组装式”能够在更大面积、更大程度上成为一种统一标准的话，可能对整个社会的发展和运行所带来的成本节省以及业务创新是我们今天所不能想象的，组装式应用的前景是不可估量的。</p><p></p><h4>四、产业生态合作未来展望</h4><p></p><p><img src=\"https://static001.geekbang.org/infoq/87/870a07e0b9bdb029731ec88b6de2cbbb.jpeg\" /></p><p>初瑞强调，为应对不断变化的业务环境和发展挑战，倡导构建“组装式”技术实践联盟，通过战略合作和技术联合，实现产业级能力整合、组件共享和价值共创。</p><p></p><p>组装式能力更有意义的地方在于，面向全部行业，甚至是整个国家，它能够实现汇集，将各领域擅长的方面进行组合，形成联合的解决方案，快速的支撑各方需求；同时，组装式还能降低门槛，一定程度上可以降低承接大项目所要的资源、人力、资本投入等方面的门槛。</p><p></p><p>组装式应用联盟未来的发展应该极大降低ToB甚至ToC这些企业进入到不同行业的门槛，所以在这个过程里面，中国移动认为外严内疏，对于整个行业来说，组装式非常值得去推进，非常有前景的发展方向。</p><p><img src=\"https://static001.geekbang.org/infoq/e9/e912fe630a336a18761cfb394003e04c.png\" /></p><p></p><p></p><p>说明：</p><p>为进一步探讨交流数字化转型相关话题，我们建立了微信群，您可添加董老师微信号，注明身份后，申请加入。</p><p>联系人：董老师&nbsp; 13810413143（微信同号）</p><p></p>",
    "publish_time": "2023-02-17 10:51:49",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "谷歌宣布支持使用Rust开发Chromium",
    "url": "https://www.infoq.cn/article/UpEHUe43yhWZaictYG0u",
    "summary": "<p></p><p>谷歌计划在其开源浏览器项目 Chromium 中支持使用第三方 Rust 库，这是对 Rust 编程语言及其安全特性的一次重大认可。</p><p></p><p>在 1 月份发布的一篇博文中，来自 Chrome 安全团队的 Dana Jansens 表示，谷歌的软件工程师已经开始致力于将 Rust 工具链应用于其构建系统。希望在年底之前将<a href=\"https://www.infoq.cn/article/z4MCCu8W62Je7d2fED7p\"> Rust 代码</a>\"包含到 Chrome 二进制文件中。</p><p></p><p>“我们将 Rust 引入 Chromium 的目标是提供一种更简单（无 IPC）且更安全（总体上包含更少的复杂 C++ 代码，同时在沙盒中也没有内存安全漏洞）的方法来满足二个原则，从而加快开发速度（需要写的代码更少、设计文档更少、安全审查更少）并且提升 Chrome 的安全性（增加了没有内存安全漏洞的代码的行数，降低了代码的错误密度）”，Jansens 解释道。</p><p></p><p>Rust 在不写成不安全的情况下，可以避免内存安全缺陷，而内存安全缺陷占 Chromium 中发现的严重安全漏洞的 70%。Rust 语言不能保证代码没有漏洞，但它可以保证潜在的缺陷要少得多。</p><p></p><p>值得一提的是，谷歌也一直致力于一种语言来提升 C++ 中的内存安全，创建者 Bjarne Stroustrup 坚称当符合 ISO C++ 标准并遵守静态分析器所强制执行的特定标准时，这种语言是内存安全的。</p><p></p><p>Jansens 感谢 Mozilla 一直支持 Rust 的开发直到它成熟并吸引了足够的外部支持来建立其自己的基础。Mozilla 长期以来一直得到谷歌的资金支持，作为回报，谷歌成为 Mozilla 的火狐浏览器的默认搜索引擎。但由于谷歌浏览器侵蚀了火狐浏览器的使用率，因此 Mozilla 正寻求其它资金来源。</p><p></p><p>Jansens 解释道，Rust 和 C++ 是 Chromium 的基础，可以通过 cxx、autocxx bindgen、cbindgen、diplomat 和 crubit 等工具进行交互。这些工具提供了一种安全的方法来从 C++ 代码调用 Rust 代码，反过来也一样。但是由于这两种语言各自的设计不同，它们之间的互操作性也存在限制。</p><p></p><p>Jansens 解释道，“例如，Rust 通过静态分析来保证临时内存安全。这个静态分析依赖两个输入：生存周期（推断或显式写入）和互斥可变性。后者与 Chromium 的大部分 C++ 的编写方式不兼容。”</p><p></p><p>Jansens 观察到，由于 Rust 和 C++ 遵循不同的规则，因此两者之间的互操作很容易出错。这就是为什么谷歌采取了一种谨慎方案的原因。</p><p></p><p>最初，谷歌想支持 C++ 到 Rust 的单项互操作性来控制依赖图的形状。Jansens 解释道，“Rust 不能依赖于 C++，因此它无法理解 C++ 类型和函数，除非通过依赖注入。这样的话，Rust 就不能在任意 C++ 代码中调用，只能在从 C++ 通过 API 传递的函数中调用。”</p><p></p><p>目前，Chromium 只能通过第三方库来暴露给 Rust。</p><p></p><p>尽管如此，随着谷歌对 crubit 等工具的开发和维护来提高 C++ 和 Rust 之间的双向互操作性，其对 Rust 的不断深化投入有望大大丰富 Rust 包生态系统。</p><p></p><p>谷歌已经将 Rust 引入安卓生态系统。微软 Azure CTO Mark Russinovich 呼吁在新项目中使用 Rust 而不是 C++。Linux 内核已经增加了 Rust 支持。甚至是不愿意使用其不能控制的技术的苹果公司都已经一直在用 Rust。®</p><p></p><p>作者介绍：</p><p></p><p>Thomas Claburn 位于旧金山湾区，为 The Register 提供软件开发、DevOps、计算机安全等服务。</p><p></p><p>原文链接：</p><p></p><p>Google polishes Chromium code with a layer of Rust（<a href=\"https://www.theregister.com/2023/01/12/google_chromium_rust%EF%BC%89\">https://www.theregister.com/2023/01/12/google_chromium_rust）</a>\"</p><p></p><p>声明：本文为 InfoQ 翻译，未经许可禁止转载。</p><p></p><p>今日好文推荐</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651156431&amp;idx=1&amp;sn=07b8156d7794c0e3d4895fb4c0991c7b&amp;chksm=bdb8979c8acf1e8aad370f504e2d64a6efcf766651c7702c786e13a8a86fc42ffb8ed2f1c75e&amp;scene=21#wechat_redirect\">18.3 万美元offer到手！ChatGPT 通过谷歌 L3 面试：留给谷歌的时间不多了</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651156320&amp;idx=1&amp;sn=8de49e53191865d9d4ed7801cfb6642f&amp;chksm=bdb897338acf1e25a4874f147dae16c1ad31851865ccf8be190998cfe925c77359b63cbb1b92&amp;scene=21#wechat_redirect\">我被微服务坑掉了CTO职位</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651156319&amp;idx=1&amp;sn=c3d54a533ea4bd913145f08097492181&amp;chksm=bdb8970c8acf1e1a9dfd72d843a59d2eae113547f48cedbcaad4c76e8faf4561311fe1f8df65&amp;scene=21#wechat_redirect\">微信全面支持“小号”；员工购买公司福利房，被裁员后遭巨额索赔；16岁少年孤身前往深圳腾讯总部解封QQ账号｜Q资讯</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651156129&amp;idx=1&amp;sn=c41a83236635ded0db3a9d45048da15f&amp;chksm=bdb896f28acf1fe4b2f98c5d0ef4b18293debf7d7907dbc5fa13869f457b21f9cf9f010ca284&amp;scene=21#wechat_redirect\">现代软件越来越大、越来越慢、越来越烂！还有救吗？</a>\"</p><p></p><p></p><p></p>",
    "publish_time": "2023-02-17 11:02:43",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "掀起云基础设施管理革命的IfC",
    "url": "https://www.infoq.cn/article/pxj6qAcsVXkGZ9zHIV4j",
    "summary": "<p><a href=\"https://klo.dev/state-of-infrastructure-from-code-2023/\">基于代码基础设施（Infrastructure-from-Code，IfC）</a>\"是一种创建、配置和管理云资源的方法，它理解软件应用程序的源代码，而无需明确的描述。Infra-from-Code有四种主要的方法：基于SDK的、基于代码注解的、基于两者组合的，以及一种明确定义基础设施的新编程语言。</p><p>&nbsp;</p><p>基于SDK的方法允许开发人员使用他们的代码，并且在部署时，这些工具会分析服务代码如何使用SDK并生成基础设施。基于SDK的方法使得根据代码推断使用情况更加可预测，但在利用新的云特性方面，SDK总是落后一步。基于SDK工具的示例有<a href=\"https://getampt.com/\">Ampt</a>\"和<a href=\"https://nitric.io/\">Nitric</a>\"。</p><p>&nbsp;</p><p><code lang=\"null\">import { api } from '@nitric/sdk';\n\n\nconst helloApi = api('main');\n\n\nhelloApi.get('hello/:name', async(ctx) =&gt; {\n    const {name} = ctx.req.params;\n    ctx.res.body = 'Hello ${name}';\n})</code></p><p>向互联网公开端点的Nitric示例</p><p>&nbsp;</p><p>纯注解方法是仅基于代码内注解的。这种方法侧重于理解开发人员对框架和工具的使用。这种方法的主要工具是<a href=\"https://klo.dev/\">Klotho</a>\"，它更像是一种基于代码架构（Architecture-from-code）的工具。Klotho引入了诸如 expose 、 persistent 和 static_unit 等功能（关键注解），这些功能可以使现有编程语言成为云原生语言。</p><p>&nbsp;</p><p><code lang=\"null\">const redis = require(\"redis\");\n/**\n* @klotho:persist{\n*   id = \"UserDB\" \n*}\n*/\n\n\nconst client = redis.createClient();</code></p><p>Redis客户端持久化数据的Klotho示例</p><p>&nbsp;</p><p>使用注解和SDK方法，开发人员可以对代码进行注解，工具可以将这些注解和SDK结合到框架中。该类别的主要工具是<a href=\"https://encore.dev/\">Encore</a>\"和<a href=\"https://www.shuttle.rs/\">Shuttle</a>\"。这些工具可以托管在IfC供应商的平台上，也可以与GCP、AWS或Azure等第三方云提供商集成。另一个有趣的工具是AWS <a href=\"https://github.com/aws/chalice\">Chalice</a>\"，它允许创建和部署在Python中使用AWS Lambda的应用程序。</p><p>&nbsp;</p><p><code lang=\"null\">// encore:api public method=POST path=/url\nfunc Shorten(ctx context.Context, p *ShortenParams)(*URL, error){\n    id, err := generateID()\n    if err != nil {\n       return nil, err\n    }\n    return &amp;URL(ID: id, URL: p.URL), nil\n}</code></p><p>API请求/响应的Encore示例。注释指定了URL路径</p><p>&nbsp;</p><p>基于语言的方法引入了旨在以云为中心的新编程语言。<a href=\"https://www.winglang.io/\">Wing</a>\"和<a href=\"https://darklang.com/\">DarkLang</a>\"是最常用的两种编程语言。这种方法允许在现有编程语言中引入难以实现的概念。每种新的编程语言都有一些权衡：软件开发人员需要首先学习它，然后将其集成到现有的工具和服务中。此外，寻找和雇用具有新编程语言专业知识的开发人员可能也需要时间和精力。</p><p>&nbsp;</p><p><code lang=\"null\">bring cloud;\n\n\nlet bucket = new cloud.Bucket();\n\n\nnew cloud.Function(inflight (_: str): str =&gt; {\n    bucket.put(\"hello.txt\",\"world\");\n}</code></p><p>云函数定义的Wing示例</p><p>&nbsp;</p><p><a href=\"https://www.chef.io/products/chef-infra\">Chef</a>\"、<a href=\"https://www.ansible.com/\">Ansible</a>\"、<a href=\"https://www.puppet.com/\">Puppet</a>\"和<a href=\"https://www.terraform.io/\">Terraform</a>\"是<a href=\"https://en.wikipedia.org/wiki/Infrastructure_as_code\">基础设施即代码</a>\"（&nbsp;Infrastructure-as-Code，IaC）的首批工具，并开始支持云基础设施的创建和管理。第二批IaC使用现有的编程语言（Python、Go、TypeScript）来表达与第一批工具相同的想法。<a href=\"https://www.pulumi.com/\">Pulumi</a>\"和<a href=\"https://github.com/aws/aws-cdk\">CDK</a>\"是第二代工具。</p><p>&nbsp;</p><p>有关基于代码基础设施现状的更多详细信息，请阅读Klotho的2023<a href=\"https://klo.dev/state-of-infrastructure-from-code-2023/\">基于代码基础设施状况</a>\"报告。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/01/google-gitops-observability/\">https://www.infoq.com/news/2023/01/google-gitops-observability/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://xie.infoq.cn/article/b3068ba053dfd72cc36743d3b\">面向分布式云原生 构筑无处不在的云原生基础设施</a>\"</p><p><a href=\"https://www.infoq.cn/article/oi5qfvo5NUCHeZScpaib\">揭秘 Meta 的云游戏基础设施</a>\"</p><p><a href=\"https://www.infoq.cn/article/HXgMpZwrxmhGU2DyWE9M\">SaaS 初创公司如何选择合适的云基础设施</a>\"</p>",
    "publish_time": "2023-02-17 11:19:18",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "经历亿级话单处理优化打磨检验，江苏移动云流一体化到底如何玩转",
    "url": "https://www.infoq.cn/article/dNr1QRTdsDeawLLHIIeA",
    "summary": "<p></p><p>作者 ｜王娟</p><p></p><p>中国移动通信集团江苏有限公司（后文统一简称为江苏移动）是省内规模最大的通信运营商，公司计费用户数近 2 亿，日均话单量超 200 亿。其业务支撑系统包含话单计费、账务处理、服务开通等多个业务场景。</p><p></p><p>近期，江苏移动引入 Apache Pulsar 等流原生新技术，结合云原生技术体系，完成了基于流云一体化架构的新一代业务支撑系统全面升级，实现了支撑系统在云原生时代新的演进。面对 5G+ 时代的新挑战，新一代业务支撑系统打造了全新支撑架构，通过跨系统间的资源融合、能力融智、数据融通，实现规模化、敏捷化、智能化、弹性化、自主可控的支撑目标，有效助力公司业务支撑效能提升。本文将介绍江苏移动核心支撑系统面临的挑战与应对挑战的系统演进措施，以及如何结合 Apache Pulsar、Ignite 和 SkyWalking 等分布式云原生系统提高开发效率并实现智能运维与运营。</p><p></p><p></p><h2>面临三大挑战</h2><p></p><p></p><p>随着市场竞争加剧，业务需求越来越个性化，江苏移动的核心支撑系统面临诸多挑战。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f2/f28b7aa9c2a93aa3f33863cbc1729bcf.png\" /></p><p></p><p>系统性能面临瓶颈</p><p></p><p>近几年流量业务呈爆发性增长。江苏省用户日均流量从数百 TB 增长到数万 TB，话单量、消息量增长，计费系统压力大幅增加。每天近百亿的话单、数十亿的消息对共享文件存储的依赖极高，NAS 逐渐出现 I/O 瓶颈，计费系统无法线性扩展。同时终端用户对提醒的及时性要求越来越高，提醒不及时极易引起用户投诉。</p><p></p><p>需求开发面对挑战</p><p></p><p>随着市场竞争的加剧，业务部门对需求交付的时间要求越来越短。现有 BOSS 系统架构越来越复杂，很多功能模块变得十分庞大，业务研发难以做到同时跟进，交付速度跟不上业务要求。</p><p></p><p>系统运维愈加复杂</p><p></p><p>随着 BOSS 系统的演进，多地多中心、多云混合的环境已经变成标配，增加了系统的复杂性，大大提高了运维的难度。</p><p></p><p></p><h2>演进措施</h2><p></p><p></p><p>面对上述挑战，江苏移动采取多项措施，进行针对性解决。通过引入微服务架构、Pulsar 消息平台、分布式内存库 Ignite、云原生架构，提升系统性能、提高开发效率、减轻运维压力。同时通过 PaaS 平台对资源进行的统一管理、调度，BOSS 系统的应用全部运行在 PaaS 平台上，部署、更新使用平台提供的运维工具，有效提升了整体的资源利用率。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3f/3f724f11132bccc394eb131961147fcb.png\" /></p><p></p><p></p><h3>设计目标</h3><p></p><p></p><p>应对业务需求，计费系统技术架构需要具备四大特性：强一致、高性能、高可用、高可靠。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a5/a59052caf9440c6de1cfb8aeba5ce6b0.png\" /></p><p></p><p>强一致</p><p></p><p>计费系统承载用户数近 2 亿，语音、短信、流量等业务日均话单量超 200 亿条，在海量的话单批价规模下，如何确保费用计算零差错，实现强一致性，是计费的最核心问题。</p><p></p><p>高性能</p><p></p><p>计费流程在忙时话单数量以数十倍突发，瞬间峰值超百万 TPS，因此计费系统需要具备很高的处理性能。</p><p></p><p>高可用</p><p></p><p>计费系统必须具备很强的业务容灾和数据容灾能力，有充分的弹性和容错设计，来保证 7*24 高可用。高可靠在数据存储层，只要话单处理成功就表示数据一定完成落盘，发生如操作系统崩溃、网络异常、磁盘异常等意外宕机时必须能够确保数据不丢；同时，针对分布式任何节点的故障，引发的主机数据损坏等问题，要求系统数据严格不错不丢。</p><p></p><p></p><h3>架构概述</h3><p></p><p></p><p></p><h4>提高开发效率</h4><p></p><p></p><p>为了支持以上技术要求，江苏移动在系统演进中做了针对性的架构设计与开发。</p><p></p><p>Serverless 构架</p><p></p><p>在新一代计费系统中引入 Serverless 架构，函数计算与 PaaS 平台为计费系统 Serverless 化提供应用引擎。在 BaaS 服务层，存储服务、应用监控、日志、数据库、内存库、消息等产品不断向 Serverless 化演进。基于 Serverless 架构计费系统可以根据语音、短信、GPRS 业务的话单流量波动，自动进行资源的分配和销毁，并最大程度化地平衡稳定性、高性能、提升资源利用率。计费系统开发追求完全自动的自适应分配的核心目标：更快地实现业务逻辑，减少在环境搭建和系统连接上的开发时间，将更多的时间聚焦在业务开发上。</p><p></p><p>微服务化</p><p></p><p>为实现系统高可用与业务功能快速扩展，新一代计费系统对应用进行了全面的微服务化改造，即微服务化设计。按照不同业务域的功能需求，通过合理的功能拆分，精细化的服务治理，如：服务的注册、发现、熔断、自愈、负载均衡、链路跟踪等实现功能的快速扩展和流量的高效调度，以此达成整体系统的高可伸缩。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/9a/9a14a1b3ffeeffee4e40819381570fa5.png\" /></p><p></p><p>流程编排</p><p></p><p>计费批价模块采用 Dubbo 作为微服务框架，在自主研发的 SNF 消息处理框架中集成 Pulsar 消费者中读取话单消息，通过 Dubbo 消费者调用 Dubbo 服务提供者的业务处理能力，完成话单批价的业务流程。在批价模块中支持流程编排能力，可按照业务需求动态调整流程的处理逻辑。批价完成后，批价成功的话单消息通过 Pulsar 生产者发送至下游模块并提交偏移量，批价失败的话单消息写入重试和死信队列，等待后续处理。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e4/e4debbf4153e2527ff45bf71cf4eb8ab.png\" /></p><p></p><p>流程编排通过可视化界面提供节点拖拽的效果，批价模块根据定义的流程模型执行不同的业务处理逻辑</p><p></p><p>分布式配置中心</p><p></p><p>通过引入 Disconf 配置中心，实现业务应用配置发布、更新统一化，配置更新自动化，并提供操作简易的控制台，方便管理配置版本及配置文件。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f9/f9aeb7469959f8c0fef6ac9ac1993723.png\" /></p><p></p><p>幂等性</p><p></p><p>Pulsar 作为一个可靠的消息中间件，只要消息成功投递到了 Pulsar 中就不会丢失，至少保证消息能被消费者成功消费一次，即“At Least Once”至少一次语义。然而这种可靠的特性在异常的场景下会导致消息可能被多次投递，造成消息重复处理。如：</p><p></p><p>在消息消费的场景下，消息已投递到消费者并完成业务处理，当消费者给 Pulsar Broker 端反馈应答的时候网络闪断。为了保证消息至少被消费一次，Pulsar 将在网络恢复后再次尝试投递之前已被处理过的消息或将消息投递给同一消费组内的其他消费者来处理，同一条消息在同一个消费组内会被处理两次。Pulsar Broker 负载均衡时消息重复，包括但不限于网络抖动、Broker 重启以及消费者应用重启，当 Pulsar Broker 或客户端重启、扩容或缩容时，会触发 Rebalance，此时消费者可能会收到重复消息。</p><p></p><p>但是，计费系统要求话单处理达到 100% 的正确性。因此，计费系统在消费逻辑上需要自我实现幂等性，探索出一个通用的消息幂等的方法，从而抽象出一个通用的框架用以适用各个业务的场景，达到“Exactly Once”有且仅有一次语义的目标。</p><p></p><p>计费消息幂等性引入了 Ignite 内存库作为存储介质，基于 Ingite EP 天然的事务原子性操作实现幂等。核心就是在 Pulsar 消费者接收到消息之后，根据话单构建的唯一标识在 Ignite 中查重，如果已经消费过，则直接提交偏移量；如果没有，则进行业务操作，并在业务处理成功之后将话单唯一标识写入 Ignite，防止重复消费。同时，存储在 Ingite 中的缓存数据，可以直接利用 Ignite 的 TTL 特性实现数据的自动清理，释放内存库资源。</p><p></p><p>顺序消息</p><p></p><p>服务开通系统要求消息按照严格的顺序消费，如服务开通接收到 CRM 的先停机后复机的工单指令，在业务处理时必须严格按照先停机后复机的顺序执行。如果先复机后停机，必然会造成用户的投诉。目前大部分 MQ 支持两种顺序模式，一种是全局有序，要求 Topic 只能有一个 Partition，对生产和消费的并行度有较大的限制；另一种是局部有序，保证 Message 中 Key 的有序生产和消费，例如用户 ID，这也是业务场景使用最多的一种方式。Kafka 和 RocketMQ 采用的是第二种种形式，通过将相同的消息 Key 路由到相同的 Partition 中，单个 Partition 的消息只能被同一个消费者消费。但是在消息量非常大的情况下，系统会出现性能瓶颈，因为相同消费组的消费者个数受限于 Partition 的个数。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/81/819e253b6c0b0121ce085d359bd61e62.png\" /></p><p></p><p>Pulsar 的 Key_Shared 模式可以很好地解决这个问题，消费者的消息按照 Key 分配，因此 Key 的分散度越高，消费者的并发度越高，系统的吞吐量也就越高。新一代服务开通系统基于 Pulsar Key_Shared 特性实现消息顺序消费，使相同 Key 的消息被路由到同一消费者上处理，同 Key 的消息经过业务处理后批量更新至目标存储上，在保证消息的顺序性消费的同时提升系统的性能。</p><p></p><p></p><h4>追踪与监控：Pulsar+Log4j2+Skywalking 等</h4><p></p><p></p><p>随着业务规模的增长，计费系统应用的实例数规模不断增长，核心业务的依赖也变得愈加复杂，开发效率提升的同时故障定位成本也居高不下，特别是当业务出现问题的时候，如何快速完成故障定位成为新的挑战。</p><p></p><p>计费系统的可观测性按照指标、日志、链路追踪进行分类，围绕 Prometheus 服务、Grafana 服务和链路追踪服务，形成指标存储分析、链路存储分析、异构数据源集成的可观测数据层，通过标准的 PromQL 和 SQL 提供数据大盘展示、告警和数据探索能力，达成全面覆盖业务观测 / 应用层观测 / 中间件观测 / 系统层观测的目标。</p><p></p><p>指标</p><p></p><p>Pulsar 原生的指标包含集群总览、消息、Topic、组件 JVM、Bookie 等多项指标。基于 Pulsar 原生的监控能力，江苏移动自主研发 Pulsar Exporter 组件，基于 Spring-boot 框架调用 Pulsar Rest API 和 JMX 指标服务接口，提供扩展 Pulsar 自定义指标的能力，如集群健康状态、磁盘使用率、追单性能、延迟消费等指标，满足计费系统复杂的业务场景和个性化的监控需求。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f1/f115b94c079bab6fb229028033000bde.jpeg\" /></p><p></p><p>集群总览</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/80/80b676d8de57ed7ab5120128cdcab472.jpeg\" /></p><p></p><p>批价追单性能</p><p></p><p>日志</p><p></p><p>Pulsar 集群的多个组件 ZooKeeper、Bookie、Broker、Functions Worker 和 Proxy 以分布式的方式部署在多台主机上，因此每个组件的日志文件也分散在多台主机上。当组件出现问题时，由于日志比较分散，我们希望通过对日志进行聚合、监控，能够快速地找到 Pulsar 各个服务的报错信息并排查，使得运维更加具有目的性、针对性和直接性。为了解决日志检索的问题，计费系统采用集中式日志收集系统，对 Pulsar 所有节点上的日志统一收集、管理和访问。</p><p></p><p>传统的日志采集必须以文件的方式落一次磁盘，缺点是占用了主机磁盘的 IO。为此，在计费系统中 Pulsar 集群基于 Log4j2+Kafka+ELK 实现日志的快速检索。Log4j2 默认支持将日志发送到 Kafka，使用 Kafka 自带的 Log4j2Appender 在 Log4j2 配置文件中进行相应的配置，即可完成将 Log4j2 产生的日志实时发送至 Kafka 中。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/06/06ff8536075400b1f81befbdd32116d2.png\" /></p><p></p><p>Elasticsearch 根据检索字段进行分词，并创建索引。Pulsar 的日志建立了 8 个检索字段，分别是：集群名、主机名、主机 IP、组件名、日志内容、系统时间、日志级别、集群实例。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/63/63be1bc6b8519db132c1ce38a4a89322.png\" /></p><p></p><p>在 Kibana 页面，根据分词的字段指定查询条件进行检索。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/37/375981d2d74e31c36fc4b0390e16aa47.jpeg\" /></p><p></p><p>借助 Pulsar SQL，计费系统使用 Pulsar 作为消息总线的同时，支持追踪回溯话单消息，能够动态查询存储在 Pulsar 内部的实时消息，并支持从外部系统提取数据，与 Pulsar 中的话单消息多维聚合分析，以图表的方式输出统计结果。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/49/4904276702d73a05587a639164728b3a.jpeg\" /></p><p></p><p>Pulsar SQL 支持以 JDBC 的方式访问持久化在 Topic 中的话单消息，运维智能分析系统基于 Java SQL 语言结合查询条件、时间范围等进行查询，并实时输出分析结果。</p><p></p><p>消息链路追踪</p><p></p><p>计费系统使用 Skywalking 分布式系统性能监视工具对话单消息进行链路追踪和性能监控。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/43/43ac28599603eee0e5557ce94b3dfb5f.png\" /></p><p></p><p>在计费系统的所有环节中集成 Pulsar 的生产者和消费者，在启动模块的应用程序时，使用 Skywalking 的 JavaAgent 探针埋入 Java 程序中，用于收集应用程序和 Topic 中话单消息的指标数据。</p><p></p><p>通过 Trace 机制，追踪话单消息在 Pulsar 集群中一次全链路调用的完整记录，实现话单消息处理的可观测性。Trace 由所有环节的 Span 组成，每个 Span 使用 APM 插件在 Pulsar 生产者的拦截器上设置 Pulsar 的 Brokers URL 列表、Topic 名称、消息 ID 等 Tag，在 Pulsar 消费者的拦截器上设置 Pulsar 的 Brokers URL 列表、Topic 名称、消息 ID、订阅者名称等 Tag，用于记录应用节点中的关键信息。</p><p></p><p>话单消息在同一个消费者模块中，业务处理异常重新消费时需要使用 Pulsar 消息系统的重试和死信队列的特性，并使用 Skywalking 监控每条话单在同一个 Topic 和同一个订阅中的重试消费的次数和详情，用于观测话单处理的原因和执行链路的流转。</p><p></p><p>Skywalking 在追踪话单消息在 Pulsar 集群中的链路执行情况的同时，会采集话单消息在计费系统的每个模块中的性能指标，通过 Skywalking Analysis Core 分析聚合之后，在 Skywalking UI 上查看话单链路和指标数据。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3e/3e005977c322a2df3d827b2d54a95df7.jpeg\" /></p><p></p><p>以上一套完整的可观测解决方案可以为计费系统提供高效运维、业务连续性保障的能力。</p><p></p><p></p><h4>精细化管控与应用云化</h4><p></p><p></p><p>计费系统按照多层次业务隔离来完善系统精细化管理控制。通过 Pulsar 多租户、Namespace、Topic 分层特性来实现物理架构部署的分系统、分业务、分地市多级别隔离，实现硬件资源复用、逻辑数据隔离、业务互不影响，使得系统控制力度从地市级升级到业务级，组件、应用集群全高可用部署：</p><p></p><p>通过多租户区分系统：计费、账务、服务、信控等；通过 Namespace 区分业务：高清语音、物联网、行业网关、流量等；通过 Topic 区分地市：苏州、南京、泰州等。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/1b/1bec2e478769045401327f0b1462964d.png\" /></p><p></p><p>计费系统的所有应用全面云化，计算资源通过 PaaS 动态调度、弹性伸缩，按需控制系统处理能力，实现整体开发成本和硬件投入的节约。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ba/ba593d7b8e9af52383b403ab72170f2e.jpeg\" /></p><p></p><p></p><h2>未来展望</h2><p></p><p></p><p>未来江苏移动将在现有架构的基础上，进一步结合算力网络构建云边一体化的计费系统。通过计费策略的智能决策、系统资源的精细控制、业务服务的高效执行以及运营状态的全景洞察，满足未来差异化用户服务需求，有效提升系统的处理能力、开放能力和运营能力。</p><p></p><p></p><blockquote>注：文档中的全部内容属中国移动通信集团江苏有限公司所有。未经允许，不可全部或部分发表、复制、使用于任何目的。</blockquote><p></p><p></p><p>作者简介：</p><p></p><p>王娟，江苏移动计费专家，负责 BOSS 计费系统的架构演进和维护。面对 5G+ 时代的新挑战，她将 Apache Pulsar 引入公司 IT 业务支撑系统，致力于打造新一代高效智能的计费架构，助力公司 IT 支撑效能提升。</p><p></p><p>今日好文推荐</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651156830&amp;idx=1&amp;sn=1388ad34d6acaa55714d6476ff055de4&amp;chksm=bdb8890d8acf001bc24a5c7b80893e6dc8a85250e0ac289ca12cfc5f67dc8dc32f515b026533&amp;scene=21#wechat_redirect\"></a>\"<a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651156919&amp;idx=1&amp;sn=3ed2dd72d55e4c978f189f770cf1022a&amp;chksm=bdb889e48acf00f23c2c148912b1b60a45b534e181abb376afc72c055572b177c4492cefdd6d&amp;scene=21#wechat_redirect\">GitHub裁员10%，办公室全关，全体远程办公；微软必应集成ChatGPT下载量猛增10倍；谷歌出师不利市值蒸发超万亿｜Q资讯</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651156830&amp;idx=1&amp;sn=1388ad34d6acaa55714d6476ff055de4&amp;chksm=bdb8890d8acf001bc24a5c7b80893e6dc8a85250e0ac289ca12cfc5f67dc8dc32f515b026533&amp;scene=21#wechat_redirect\">马斯克开会当场解雇Twitter首席工程师：我有1亿多粉丝，他却说公众对我失去兴趣</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651156705&amp;idx=1&amp;sn=f7e6e01de4763afc61a83a35dd3901ae&amp;chksm=bdb888b28acf01a4b4443c5e09eac7a54f591ac6b96937ec6c45008203598a721b8c1f73d4f3&amp;scene=21#wechat_redirect\">15年做不好的代码搜索，用Rust重写搞定：GitHub声称能从此“改变游戏规则”</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651156618&amp;idx=1&amp;sn=a8e0585cbb0f4d580957ab598129625b&amp;chksm=bdb888d98acf01cf69cd221c048833497157edfc13ed2de5e55cd0f28acf1234e732b38a8fcf&amp;scene=21#wechat_redirect\">搜索引擎技术大战，始于今日</a>\"</p><p></p><p></p><p></p>",
    "publish_time": "2023-02-17 11:33:20",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Shopify为系统编程提供Rust",
    "url": "https://www.infoq.cn/article/hLu8pCjMkwFz4HYyLAWT",
    "summary": "<p></p><p>Shopify 为商业构建互联网基础设施，以满足数百万商家的需求。为了做到这一点，需要构建灵活的业务逻辑和健壮的高性能系统。除了我们对 Ruby 的灵活性和表现力的承诺之外，我们最近还<a href=\"https://www.infoq.cn/article/hioW21XT8opvbip3hs5F\">采用了 Rust </a>\"作为我们官方的系统编程语言。作为这项工作的一部分，我们加入了 Rust 基金会，并且我们很高兴能加入 Rust 社区。</p><p></p><p>系统编程是软件工程中的一个要求很高的领域，为其选择的语言将会对系统软件的成功和有效性产生巨大的影响。用于解决这些问题的语言需要快速、高效且安全。此外，如果可能，Shopify 更喜欢社区驱动的开源项目。</p><p></p><p>Rust 不断增长的行业势头和 Shopify 不断扩大的系统编程项目基础，使我们在 Rust 上进行标准化并加入 Rust 基金会正当其时。</p><p></p><p></p><h2>Shopify 的系统编程</h2><p></p><p></p><p>自成立以来，Shopify 的主要服务端应用程序编程语言一直是 Ruby。Ruby 的灵活性和表现力使 Shopify 能够开发出强大的商务系统，满足数百万商家以及数亿买家的需求。Ruby 过去是，现在是，将来依然是我们构建现代商务服务端组件时的首选工具。</p><p></p><p>对于系统编程，例如高性能网络服务器或使用“原生”代码扩展 Ruby，而不是定义业务逻辑，Shopify 开发人员过去一直使用 C 和 Go 等语言。最近，我们决定将 Rust 标准化为我们的系统编程语言。因此，我们正致力于在开发和部署流程中更好地支持 Rust，并帮助 Shopify 工程师开发 Rust 编程方面的专业知识。</p><p></p><p></p><h2>为什么选择 Rust？</h2><p></p><p></p><p>Rust 的许多方面使它成为我们系统编程语言的一个有吸引力的选择。这些因素结合起来使我们相信 Rust 将会成为我们软件堆栈中一个强大且受欢迎的组件。其他公司可能会对语言的不同属性进行不同的权衡，做出不同的选择；我们的评估最终使我们选择了 Rust。</p><p></p><p></p><h3>一致性</h3><p></p><p></p><p>Shopify 的系统编程需要涵盖多个领域，而且随着时间的推移，这个数字可能会增加。它们包括高性能服务器、用于提高性能或桥接到其他库的 Ruby 扩展，以及编译为 WebAssembly。我们非常希望将对单一语言的投资运用到众多领域，这意味着要确定一种可以非常灵活使用的语言。相关类型的系统编程将对组织的语言选择产生重大影响；我们需要对此有更宽泛的视角。</p><p></p><p></p><h3>性能</h3><p></p><p></p><p>Shopify 需要能够高效且可持续地扩缩，以支持全球商业。Rust 为我们提供了可预测的原生代码性能，包括对内存使用的精细控制，这使其适用于我们堆栈的最低级别。当然，Rust 并不是唯一能够提供或接近这种性能的语言。在此基础上，还可以考虑使用现代 C++，或者如果可以接受垃圾收集器的分配行为和性能的话，则可以考虑 Go。</p><p></p><p>当然，虽然 Rust 具有很高的性能上限，但它本质上并没有提高性能下限。一个应用程序或组件并不会因为它是用 Rust 编写的就神奇地快；程序员仍然需要设计和衡量性能，我们需要确保 Shopify 的 Rust 开发人员拥有必要的工具来轻松完成这项工作。随着我们与 Rust 及其社区的合作，这种支持将成为 Shopify 感兴趣的一个重要领域。</p><p></p><p></p><h3>社区</h3><p></p><p></p><p>Rust 语言和生态系统是由一个健康的社区驱动的，我们打算像参与 Ruby、 Rails、 React Native 和其他开源项目一样参与这个社区。Rust 的 RFC 流程和治理架构为包容且深思熟虑的讨论提供了坚实的基础，从而推动了语言和工具的未来发展。希望我们的贡献不仅能使 Rust 在 Shopify 的使用中变得更加高效，而且还能为所有 Rust 开发人员带来改进。</p><p></p><p>这就是 Shopify 加入 Rust 基金会的原因。我们希望支持 Rust 优秀的治理模式和“Rust 公地”的维护，并将我们的知识和观点带入到更大的 Rust 对话中。Rust 基金会为确保 Rust 社区和生态系统的健康所做的工作至关重要，我们非常自豪能够参与他们的使命。</p><p></p><p></p><h3>生产力</h3><p></p><p></p><p>在某些圈子里，Rust 以难以学习和使用而闻名，但 Shopify 内部和外部的开发人员发现，在通过了最初的学习阶段之后，他们可以非常高效且轻松地使用 Rust 进行构建。Rust 还有一个强大的库生态系统（“板条箱”）和良好的 IDE 集成工具，当然还有非常好的编译器错误消息。类型和宏系统的强大功能允许非常有表现力的 API 和语法，将开发人员的精力集中在表达他们的思想上，而不是在头脑中摆弄大量的状态和不变量。Go 在这方面也享有盛誉，C 和 C++ 就没那么好了。</p><p></p><p></p><h3>安全性</h3><p></p><p></p><p>Rust 提供了许多让编译器来帮助确保程序正确的工具，包括它们可以安全地管理内存，并且可以“无所畏惧地并行”。随着我们越来越熟练地使用 Rust，我们将会找到更多的方法来使用 Rust 的类型系统和安全规则来保持系统中的不变量。从我们最初的项目中，我们发现与我们评估的其他语言相比，Rust 会在编译时而不是运行时暴露出更多的错误。这促成了 Rust 开发人员经常表达的“有信心部署”情绪。</p><p></p><p>在我们所考虑的所有语言中，Rust 在安全因素方面遥遥领先：不仅是在生命周期管理方面的内存安全上，它还消除了并行程序中的大多数数据竞争。当然，即使是 Rust，它也有改进的空间，例如静态死锁预防，但所有生产语言都是如此。我们相信 Rust 对静态安全性的承诺会使其最有可能在未来几年中实现这一目标。在这个领域已经有了一些有趣的工作，例如 Ferrocene。</p><p></p><p></p><h3>互操作性</h3><p></p><p></p><p>系统编程通常涉及到与现有的“原生”库（比如用 C 编写的库）的接口。与 Go 不同的是，Rust 没有垃圾收集器，这使得它可以更容易地插入到可以使用 C 的任何地方。更具体地说，Rust 很好地支持了使用 bindgen 等工具与现有的 C 代码的集成，而像 rb-sys 和 magnus 这样的板条箱允许 Rust 安全地与 Ruby 互操作。C++ 的集成仍然有些笨拙，但像 cxx 这样的板条箱可以帮助弥合语言障碍。除了 RubyVM 本身之外，我们没有大型的 C 或 C++ 代码库，但这种互操作对我们来说仍然是一个重要的考虑因素。</p><p></p><p></p><h2>接下来做什么?</h2><p></p><p></p><p>在 Shopify，我们的 Rust 之旅才刚刚开始。我们需要开发教育资源和内部工具，并学习如何最好地参与 Rust 社区和生态系统。我们很高兴能成为 Rust 使命的一部分，让每个人都能构建可持续的、内存安全的、高效的软件，并感谢 Rust 基金会的欢迎加入。</p><p></p><p></p><blockquote>Mike Shaver 是 Shopify 核心工程的杰出工程师。</blockquote><p></p><p></p><p>如果你对从头开始构建系统来解决现实世界中的问题感兴趣，我们的工程博客中有关于我们遇到的其他挑战故事。访问我们的工程职业位页面，了解我们的空缺职位。加入我们的远程团队，可以（几乎）在任何地方工作。了解我们是如何通过招聘来共同设计未来的——一个通过设计实现数字化的未来。</p><p></p><p>原文链接：</p><p></p><p><a href=\"https://shopify.engineering/shopify-rust-systems-programming\">https://shopify.engineering/shopify-rust-systems-programming</a>\"</p><p></p><p>声明：本文为 InfoQ 翻译，未经许可禁止转载。</p><p></p><p>今日好文推荐</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651156431&amp;idx=1&amp;sn=07b8156d7794c0e3d4895fb4c0991c7b&amp;chksm=bdb8979c8acf1e8aad370f504e2d64a6efcf766651c7702c786e13a8a86fc42ffb8ed2f1c75e&amp;scene=21#wechat_redirect\">18.3 万美元offer到手！ChatGPT 通过谷歌 L3 面试：留给谷歌的时间不多了</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651156320&amp;idx=1&amp;sn=8de49e53191865d9d4ed7801cfb6642f&amp;chksm=bdb897338acf1e25a4874f147dae16c1ad31851865ccf8be190998cfe925c77359b63cbb1b92&amp;scene=21#wechat_redirect\">我被微服务坑掉了CTO职位</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651156319&amp;idx=1&amp;sn=c3d54a533ea4bd913145f08097492181&amp;chksm=bdb8970c8acf1e1a9dfd72d843a59d2eae113547f48cedbcaad4c76e8faf4561311fe1f8df65&amp;scene=21#wechat_redirect\">微信全面支持“小号”；员工购买公司福利房，被裁员后遭巨额索赔；16岁少年孤身前往深圳腾讯总部解封QQ账号｜Q资讯</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651156129&amp;idx=1&amp;sn=c41a83236635ded0db3a9d45048da15f&amp;chksm=bdb896f28acf1fe4b2f98c5d0ef4b18293debf7d7907dbc5fa13869f457b21f9cf9f010ca284&amp;scene=21#wechat_redirect\">现代软件越来越大、越来越慢、越来越烂！还有救吗？</a>\"</p><p></p><p></p><p></p>",
    "publish_time": "2023-02-17 11:51:33",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Serverless Streaming：毫秒级流式大文件处理探秘",
    "url": "https://www.infoq.cn/article/25z7Wv4OPKI6dJv0ALZB",
    "summary": "<p>点击查看Serverless系列文章：</p><p><a href=\"https://www.infoq.cn/article/e4ly6UcN93KApvKGzUCK\">Serverless 时代的微服务开发指南：华为云提出七大实践新标准</a>\"</p><p><a href=\"https://www.infoq.cn/article/bdczHWk9LxuOC9GrVToL\">华为云发布冷启动加速解决方案：助力 Serverless 计算速度提升 90%+</a>\"</p><p></p><p>旧浪 | 华为云 Serverless 研发专家</p><p>平山 | 华为云中间件 Serverless 负责人</p><p></p><h2>背景</h2><p></p><p></p><p>企业应用从微服务架构向 Serverless（无服务器）架构演进，开启了无服务器时代，面向无服务器计算领域的 Serverless 工作流也应运而生。许多 Serverless 应用程序不是由单个事件触发的简单函数，而是由一系列函数多个步骤组成的，而函数在不同步骤中由不同事件触发。Serverless 工作流用于将函数编排为协调的微服务应用程序。</p><p></p><p>Serverless 工作流由于自身可编排、有状态、持久化、可视化监控、异常处理、云服务集成等特性，适用于很多应用场景，比如：</p><p></p><p>复杂度高需要抽象的业务（订单管理，CRM 等）业务需要自动中断 / 恢复能力，如多个任务之间需要人工干预的场景（人工审批，部署流水线等）业务需要手动中断 / 恢复（数据备份 / 恢复等）需要详细监控任务执行状态的场景流式处理（日志分析，图片 / 视频处理等）</p><p></p><p>当前大部分 Serverless Workflow 平台更多关注控制流程的编排，忽视了工作流中数据流的编排和高效传输，上述场景 1-4 中，由于数据流相对简单，所以各大平台支持都比较好，但是对于文件转码等存在超大数据流的场景，当前各大平台没有给出很好的解决方案。华为云 FunctionGraph 函数工作流针对该场景，提出了 Serverless Streaming 的流式处理方案，支持毫秒级响应文件处理。本文将以图片处理的场景作为例子详细描述当前的问题以及华为云 FunctionGraph 函数工作流在面对该问题时采取的一系列实践。</p><p></p><p></p><h2>问题描述</h2><p></p><p></p><p>先以一个图片处理的场景举例，用户想要执行一个图片压缩并且加水印的任务，这个场景在典型的工作流系统中，可以用如图一所示的方式进行处理。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e5/e5e75e4ca42eee961b896dcba24040c6.png\" /></p><p></p><p>图 1：一个典型的图片处理工作流</p><p></p><p>如上图所示，图片压缩和图片加水印的结果都是二进制文件格式，但是当前主流的 Serverless Workflow 平台在多个步骤之间传输上下文都只能支持文本格式传输，所以图片压缩和加水印的结果都需要经过 BASE64 或者其他转码方式转成文本进行数据流传输。</p><p></p><p>但是这种方案的限制和使用成本都比较高：</p><p></p><p>函数的 Response Body 通常有大小限制，所以这种方式无法处理超大文件。执行结果转换为文本，需要消耗大量内存，内存成本比较高。</p><p></p><p>如何简单高效的进行文件处理，业界也给出了其他解决方案，如通过云存储进行中间结果转储、AWS 的 Lambda Object 文件转换方案。下面给出了这两个方案的优缺点分析。</p><p></p><p></p><h3>方案一：中间结果通过云存储进行转储</h3><p></p><p></p><p>该方案如图 2 所示：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5f/5fb4056eaf790ca73ae6b36af364dfe3.png\" /></p><p></p><p>图 2：云存储转储运行方式示意图</p><p></p><p>两个步骤之间的文件流通过云存储去传递，这种方案支持大文件流的传输，但是由于中间多了一次到云存储的网络传输，如果业务对时延要求不高，该方案问题不大，但是对于时延敏感类业务，这种多出的时延是无法接受的。另外云存储转储需要额外的成本，如果调用量比较大，使用成本较高。</p><p></p><p></p><h3>方案二：AWS Lambda Object</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/2a/2a17adef96f9b7f62f6e4b43c1bf7694.png\" /></p><p></p><p>图 3：AWS 解决方案示意图 [1]</p><p></p><p>AWS 对于这种文件处理场景，提出了基于 S3 和 Lambda 的 Lambda Object 的方案，参考 [1]，简单来说，是支持为 S3 文件桶的 getObject API 提供 Access Point，AccessPoint 可以指向某一个 Lambda 函数，在函数中可以对原来的桶数据文件进行修改，比如可以将原始视频转码，得到转码后的结果返回到客户端。虽然解决了时延和大文件处理的问题，但是这个方案强依赖 S3 的 API，用户无法进行流程编排，也无法通过事件触发，不是一个真正通用的方案。</p><p></p><p></p><h3>业界方案总结</h3><p></p><p></p><p>简单总结如表 1 所示，当前业界提供的各个方案或多或少存在一些局限性，没有办法在同时满足低时延的情况下支持可编排的文件处理。然而低时延和可编排都是大量客户所追求的关键能力，如何解决这些关键痛点，提升客户体验，成为了当前我们重点想要攻克的难题。</p><p></p><p>表 1：业界文件处理方案对比</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/46/46513f19000023bc8aa85ced448b4a57.png\" /></p><p></p><p></p><h2>华为云 FunctionGraph 的 Serverless Streaming 流式处理方案</h2><p></p><p></p><p>针对当前业界缺少高效，可编排的文件处理方案的痛点，华为云 FunctionGraph 函数工作流提出 Serverless Streaming 的流式可编排的文件处理解决方案，步骤与步骤之间通过数据流驱动，更易于用户理解。本章通过图片处理的例子解释该方案的实现机制。</p><p></p><p>如果需要驱动一个工作流执行，工作流系统需要处理两个部分：</p><p></p><p>控制流：控制工作流的步骤间流转，以及步骤对应的 Serverless 函数的执行。确保步骤与步骤之间有序执行。数据流：控制整个工作流的数据流转，通常来说上一个步骤的输出是下一个步骤的输入，比如上述图片处理工作流中，图片压缩的结果是打水印步骤的输入数据。</p><p></p><p>在普通的服务编排中，由于需要精准控制各个服务的执行顺序，所以控制流是工作流的核心部分。然而在文件处理等流式处理场景中，对控制流的要求并不高，以上述图片处理场景举例，可以对大图片进行分块处理，图片压缩和加水印的任务不需要严格的先后顺序，图片压缩处理完一个分块可以直接流转到下一个步骤，而不需要等待图片压缩把所有分块处理完再开始加水印的任务。</p><p></p><p>基于上述理解，华为云 FunctionGraph 工作流的 Serverless Streaming 方案架构设计如图四所示：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f6/f60f146191dd4c11186626b7419924d6.png\" /></p><p></p><p>图 4：Serverless Streaming 流式处理架构图</p><p></p><p>在 Serverless Streaming 的流程中，弱化控制流中步骤之间的先后执行顺序，允许异步同时执行，步骤与步骤之间的交互通过数据流驱动。其中数据流的控制通过 Stream Bridge 组件来实现。</p><p></p><p>同时函数 SDK 增加流式数据返回接口，用户不需要将整个文件内容返回，而是通过 gRPC Stream 的方式将数据写入到 Stream Bridge，Stream Bridge 用来分发数据流到下一个步骤的函数 Pod 中。</p><p></p><p>这种方式存在如下优点：</p><p></p><p>由于控制流的弱化，完全通过数据流来驱动流程执行，不需要再强限制步骤之间完成的先后顺序，如图片处理场景中，压缩和加水印的步骤可以做到完全并行执行，这样可以加速整个流程的执行速度。每次请求都开辟独立缓冲区，缓冲区限制大小，数据流仅在内网传输，保证整体数据传输的可靠性和安全性。不依赖其他外部服务，使用成本低。对于开发人员来讲，只需要关注数据流的处理，而不需要关心数据流如何转发，如何存储，降低开发难度。底层流式传输通过 gRPC 进行，整体数据传输效率高</p><p></p><p></p><h3>在 FunctionGraph 中开发文件处理工作流</h3><p></p><p></p><p>当前 FunctionGraph 已经基于上述方案支持了在函数工作流中进行数据流处理，并且将结果通过流数据的方式返回到客户端，以构建一个图片处理工作流举例：</p><p></p><p>1. 首先创建一个图片压缩的函数，其中代码在处理返回数据通过 ctx.Write() 函数将结果以流式数据的形式返回：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/18/181b246c23cd758a6c193a8bce83ad5a.png\" /></p><p></p><p>FunctionGraph 通过 ctx.Write() 函数提供了流式返回的能力，对开发者来说，只需要将最终结果通过流的方式返回，而不需要关注网络传输的细节。</p><p></p><p>2. 在函数控制台中启用该函数的流式返回能力</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e9/e9753a53cb9f2bfa400801122a47b947.png\" /></p><p></p><p>3. 用上面的方式完成其他函数的编写，最后在 FunctionGraph 的函数流控制台完成工作流编排，举例如下：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/0a/0abbd1c0611083e4a0dcda841a62a859.png\" /></p><p></p><p>4. 调用工作流的同步执行接口，获取最终结果的文件流，数据将以 chunked 流式返回的方式返回到客户端</p><p></p><p></p><h3>使用效果</h3><p></p><p></p><p>针对图片处理的具体场景，我们测试对比了不同大小图片（333k、1m、4m、7m、10m、12m）进行图片切割和图片压缩的场景，由于 BASE64 转码方案无法支持大文件，AWS Lambda Object 方案无法支持编排，所以这里只对比使用 OBS 转储方案和基于流式返回的 Servlerss Streaming 方案的时延数据。具体对比数据图表如下：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/66/6633c9733adb935d9e5694cd6b273bae.png\" /></p><p></p><p>图 5：测试数据对比</p><p></p><p>响应时延：指客户端发出请求到收到第一个字节消耗的时延（单位：秒）</p><p></p><p>端到端时延：指客户端发出请求到收到最后一个字节消耗的时延（单位：秒）</p><p></p><p>从测试数据可以看出，响应时延和端到端时延使用流式返回方案后都得到了不同程度的降低。其中响应时延降低幅度较大，OBS 转储方案响应时延随着图片大小增大，响应时延呈线性上升，超过 4M 的图片响应时延就达到秒级，使用流式返回方案后，响应时延持续稳定在毫秒级的水平。从中可以发现，基于 Serverless Streaming 的流式返回方案不仅具备流式处理和可编排的能力，并且在文件处理场景中可以显著降低时延，从多个方面提升了用户使用体验。</p><p></p><p></p><h2>总结与展望</h2><p></p><p></p><p>本文主要讨论了 Serverless Workflow 在大文件处理时碰到的问题，FunctionGraph 通过简化数据传输链路，提升文件流处理效率, 给出了一种稳定高效、极低时延的大文件处理方法 Serverless Streaming，支持毫秒级的文件流式处理, 显著改善函数编排在文件处理等场景中的用户体验。</p><p></p><p>FunctionGraph 作为华为元戎加持的下一代 Serverless 函数计算与编排服务，将围绕通用全场景 Serverless 的前沿理论及案例实践，持续分享，回馈社区。</p><p></p><p>参考资料：</p><p></p><p>[1]Introducing Amazon S3 Object Lambda (<a href=\"https://aws.amazon.com/cn/blogs/aws/introducing-amazon-s3-object-lambda-use-your-code-to-process-data-as-it-is-being-retrieved-from-s3/\">https://aws.amazon.com/cn/blogs/aws/introducing-amazon-s3-object-lambda-use-your-code-to-process-data-as-it-is-being-retrieved-from-s3/</a>\")</p><p></p><p>今日好文推荐</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651157194&amp;idx=1&amp;sn=8c547e61981f9d0c52358d5a4ff7b6b4&amp;chksm=bdb88a998acf038f25b03331ee5f17221ee6661408c4bcf0f48c60800b35aaac0e3a98d0a7fe&amp;scene=21#wechat_redirect\">告别SVN，Git成“独苗”：GitHub 在 13 年后宣布淘汰Subversion支持</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651156926&amp;idx=1&amp;sn=2839c68c1455a13e0567826460a69e88&amp;chksm=bdb889ed8acf00fb0e0dba04e9e25d8b77fca3cf1168b2c3f512bccdf25a0c31c4cd3840d70f&amp;scene=21#wechat_redirect\">被逼出来的自主可控，从华为自研看国产IDE的未来和商业模式</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651156919&amp;idx=1&amp;sn=3ed2dd72d55e4c978f189f770cf1022a&amp;chksm=bdb889e48acf00f23c2c148912b1b60a45b534e181abb376afc72c055572b177c4492cefdd6d&amp;scene=21#wechat_redirect\">GitHub裁员10%，办公室全关，全体远程办公；微软必应集成ChatGPT下载量猛增10倍；谷歌出师不利市值蒸发超万亿｜Q资讯</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651156830&amp;idx=1&amp;sn=1388ad34d6acaa55714d6476ff055de4&amp;chksm=bdb8890d8acf001bc24a5c7b80893e6dc8a85250e0ac289ca12cfc5f67dc8dc32f515b026533&amp;scene=21#wechat_redirect\">马斯克开会当场解雇Twitter首席工程师：我有1亿多粉丝，他却说公众对我失去兴趣</a>\"</p><p></p><p></p><p></p>",
    "publish_time": "2023-02-17 12:20:07",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "打破数据孤岛，Apache Doris 助力纵腾集团快速构建流批一体数仓架构",
    "url": "https://www.infoq.cn/article/0MiKpHhupXlSOFjbxQrV",
    "summary": "<p>作者｜纵腾集团数据技术架构师 张彬华</p><p></p><p></p><blockquote>福建纵腾网络有限公司（简称“纵腾集团”）成立于 2009 年， 以“全球跨境电商基础设施服务商”为企业定位，聚焦跨境仓储与物流， 为全球跨境电商商户、出口贸易企业、出海品牌商提供海外仓储、商业专线物流、定制化物流等一体化物流解决方案， 旗下拥有谷仓海外仓 、云途物流 、WORLDTECH 等知名品牌 。</blockquote><p></p><p></p><p>随着纵腾集团业务的快速发展，各产品线提出的数据需求越发严格，而早期基于多套 CDH 大数据架构的技术栈和组件繁杂，开发和运维难度高、效率低，数据质量和时效难以保障，已无法满足当下数据分析需求，严重影响相关工作的开展。因此，纵腾集团在 2022 年正式引入<a href=\"https://github.com/apache/doris\"> Apache Doris</a>\"，基于 Apache Doris 构建了新的流批一体数据架构，同时建立了以<a href=\"https://www.infoq.cn/article/26ICMg30p0LS8UY8rbrw\"> Apache Doris 为核心</a>\"的数据中台。 构建过程中对读写时效性、服务的稳定性及高并发读写等多方面进行了优化，在这一过程中我们也积累了诸多实践经验，在此总结分享给大家。</p><p></p><h1>早期架构</h1><p></p><p>早期数仓架构主要分为两套基于 CDH 的大数据集群，这两套架构用于不同产品线的数仓需求、数据大屏和 BI 报表等应用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/17/179e9c4864d20d8f5762ebcb81548be4.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a1/a19576d9a944f925f24d18e0a20584cb.png\" /></p><p></p><p>这两套架构为独立的数据管道，具有耦合度低，集群间相互独立等特点，便于精细化管理。但随着业务需求的不断变化，这样的特点也引发出许多新的问题。</p><p></p><p>遇到的问题</p><p></p><p>元数据和数据质量缺乏管控，数据质量无法得到保证不同业务数据独立存储维护导致数据孤岛，不利于数据整合每个集群的机房分布不一，维护成本非常高集群间的技术栈和组件较多且存在差异性，对统一开发运维和数据整合都极具挑战性</p><p></p><h1>架构选型</h1><p></p><p>为了解决早期架构的痛点、更好满足日益严苛的数据需求，我们希望能有一款产品帮助我们快速构建流批一体的数仓架构、构建数据中台服务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/87/870a622470f3b6beb2203df2bb673eb8.png\" /></p><p></p><p>我们对传统数仓、 实时数仓和数据湖进行了对比。从上图可知，传统数仓可以支撑超 PB 级的海量数据，但是交互查询性能相对差一些，偏离线场景，不满足我们对数据实时性的要求；数据湖可以支撑超海量的数据，支持数据更新，查询性能适中，但是数据湖近两年才开始应用，成熟度较低，使用风险较大；实时数仓适用 PB 级数据存储，支持数据更新且查询性能非常好。结合我们的要求，实时数仓与我们的使用和需求场景都比较贴合，因此我们最终决定选择实时数仓作为数据底座。</p><p></p><p>接着我们对市面上较为流行的三款实时数仓：ClickHouse、Apache Druid、Apache Doris 进行了选型对比，对比图如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/79/79530885d3105c22d568a35cb8ac8015.png\" /></p><p></p><p>对比可知，<a href=\"https://www.infoq.cn/article/iT7purpsKqaPwr8Touco\">Apache Doris 优势明显</a>\"、性价比更高，具有独立主从架构简单、运维更灵活便捷、丰富的数据模型、优秀的查询性能和周全的生态规划等诸多优势，对比这三个产品，Apache Doris 最符合我们的选型要求。</p><p></p><h1>新数据架构</h1><p></p><p><img src=\"https://static001.geekbang.org/infoq/07/07601f623e6bfdc396f21b52edf82398.png\" /></p><p></p><p>新数据架构基于 Apache Doris 简化了数据采集、存储和计算的流程：</p><p></p><p>结合 DataHub 实现自研元数据采集和周期管理通过 Seatunnel 集成 Flink Doris Connector 稍加改造实现全量加增量数据的一体化采集简化存储媒介，对 ClickHouse、Kudu、HBase 等技术栈进行收敛，由 Apache Doris 进行流批数据的统一存储以 Apache Doris 为核心数据底座，结合 Apache Kyuubi 的 JDBC 引擎直连查询（自研）和 Spark 引擎中的 Spark Doris Connector 进行 ETL 开发（原生），统一计算引擎管理、权限管控和对外服务。</p><p></p><p>基于上述几点进行了数据应用开发及对外提供数据服务，构建了数据中台。</p><p></p><h2>数据中台</h2><p></p><p>我们以 Apache Doris 为核心底座创建了数据平台，核心功能包括：指标中心、元数据中心、基础配置中心、即席分析和数据接口服务中心，其中指标中心和即席分析的数据主要来源于 Aapche Doris ，当前已上线几百个指标。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3c/3ce0b3f2bab108d57810950a4f941309.png\" /></p><p></p><h2>数仓建模</h2><p></p><p>我们结合 Apache Doris 的特性重新对数仓进行了建模，数仓分层与传统数仓类似，其中 ODS 数据为存量加增量一体的导入模式，同时为防止出现[随机查询结果问题]，ODS 层最终选用 Unique 数据模型，相比于 Aggregate 模型可以实现写时合并（Merge-on-Write），有效提高数据实时性，且 Aggregate 模型查询性能更接近于 Duplicate 模型，对于 ODS 层是非常好的选择。</p><p></p><p>DIM/DED/DWS/ADS 层主要选用 Aggregate 数据模型；Aggregate 数据模型提供的四种聚合方式可以在大部分场景下达到事半功倍的效果，帮助我们快速应对不同的需求场景。</p><p></p><p>SUM： 能够高效实现 PV 类指标计算，但对于 UV 类的指标需要考虑预去重。MAX/MIN： 常用于最大最小运单时间节点类指标或包裹体积/重量最大最小值的指标计算。REPLACE_IF_NOT_NULL： 可以自动地过滤空值，非常便捷地实现仅记录最后一条数据，适用于大部分 DW 场景。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/96bb3f2b423c489d00728d36c34563a0.png\" /></p><p></p><h2>数据导入</h2><p></p><p>ODS 层的数据导入目前主要以 Stream Load 为主，在 HDFS 上的历史存量数据也会通过 Broker Load 或Spark Load 导入。DW 层数据主要以 insert into 方式导入，同时为减轻 Doris 内存压力，我们将部分 ETL 任务放到 Kyuubi On Spark 引擎上去计算，目前在 DolphinScheduler 每天平稳调度 Doris DW 任务有上万个，其中大部分为 T+1 任务，小部分为小时级任务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f6/f652d7fa0d5bf8fec89515d7094f49bc.png\" /></p><p></p><h1>实践经验</h1><p></p><p><img src=\"https://static001.geekbang.org/infoq/6a/6af8b354ba384d6c374a8dd1c0cea63d.png\" /></p><p></p><p>对于以 Apache Doris 为核心的新数据架构，我们规划了6个阶段进行运行测试，直至可以上线运行。（重点关注压测阶段和运行阶段，有一些调试优化经验分享给大家）</p><p></p><h2>1、准备阶段</h2><p></p><p>引入 Apache Doris 时是 2022 年 2月，因此选择当时最新版本 Apache Doris 0.15 Release 版本进行应用，主要考虑维度如下：</p><p></p><p>支持事务性插入语句功能支持 Unique Key 模型下的 Upsert支持 SQL 阻塞 List 功能，可以通过正则、哈希值匹配等方式防止某些 SQL 的执行官方不支持跨两位版本号进行升级，而 0.15 为当时最新的 Release 版本，选用该版本利于后期版本升级可通过资源标签的方式将一个Apache Doris 集群中的 BE 节点划分为多个资源组，实现多租户和资源隔离该版本提供了官方认可的 Flink-Doris-Connector/Spark-Doris-Connector/DataX Doriswriter 等插件，利于ETL流程建设</p><p></p><h2>2、验证阶段</h2><p></p><p>该阶段主要是为了二次验证官方文档中介绍的功能是否满足我们的实际运用场景，比如生态扩展中的 Connector、外表联邦查询、各种 Load 方式、多租户隔离及物化视图等。</p><p></p><h2>3、压测阶段</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/7e/7e467074fe6a5890250657610d68b186.png\" /></p><p></p><p>压测阶段首先进行数据生成，数据集选用的是 TPC-DS 数据，接着根据 Doris 的特性对 DDL 和 SQL 等规则进行对应调整，最后通过脚本将数据导入到 Apache Doris 存储中，再通过自动化脚本进行查询及导入压测，最终将压测结果输出到 MySQL 表中，量化为图表进行展示。下方为本阶段的基本配置及压测过程介绍：</p><p></p><p>- 硬件环境</p><p></p><p>内存：256GCPU：96C硬盘：SSD 1.92T * 8</p><p></p><p>- 软件环境</p><p></p><p>Apache Doris 版本：0.15-release/1.0-release（该阶段进行时，1.0-release 版本刚好发布）Apache Doris 集群：3 FE + 9 BE系统：CentOS Linux release 7.9.2009</p><p></p><p>- 数据集信息</p><p></p><p>我们生成了 1T、5T、10T 的 TPC-DS 数据集，1T 的数据集约有 30 亿数据量。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0a/0a138cfa9610543c34e1da1f5861188f.png\" /></p><p></p><h3>查询压测</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/84/8409544a87a38c71896d236c0bb13e3a.png\" /></p><p></p><p>压测过程中，最初使用 0.15-release 版本进行测试，正巧 1.0-release 版本发布，后决定更换为 1.0-release 版本进行后续的压测。下图是基于 1T 的 TPC-DS 数据在同等硬件配置环境下和某商业 MPP 数据库的对比结果：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/05/050899ac5d4764e39bcb0659455ab5ae.png\" /></p><p></p><p>如图所示，Apache Doris 的查询压测性能优异，有着明显的性能优势，作为开源产品能够达到这样的效果是非常优秀也是十分不易的。</p><p></p><h3>导入压测</h3><p></p><p>导入方式：通过 DataX Doriswriter 以 StreamLoad 方式进行写入压测数据来源：为避免因 Source 端原因影响写入时效，选择 100 张相同大表，即 100 个并发从内网 Hive 中导入（例如 tpcds-ds 的 store_sales_1t 表）数据模型：选用 Unique 模型（模拟ODS层），同时为充分考虑 Compaction 性能及小文件场景，每张表设置 70 个 Tablet</p><p></p><p>经调整优化后，最大写入时效为 269 MB/S&amp;680K ops/s，平均写入时效 70 MB/S&amp;180K ops/s，写入时效大幅提升。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d9/d97290555532395ce0baf93439bea7ed.png\" /></p><p></p><h2>4、上线阶段</h2><p></p><p>该阶段主要是确认 Apache Doris 上线需要的检查清单、预调参数、BE 资源组规划及用户权限的划分。</p><p></p><p>检查清单：包括但不限于 FE &amp; BE 端口、网络检查及 Apache Doris 的一些功能性验证，例如读写是否正常等。预调参数：确认优化后的 FE&amp;BE 参数是否配置，是否开启global enable_profile、动态分区以及数据盘保存位置是否有误等。BE 资源组：由于我们需要通过 Apache Doris 的多租户特性对不同的用户进行资源隔离，所以需要提前规划好每个 BE 节点对应的资源组。用户权限：对于不同的用户群体提前规划好权限范围，比如分析师开发只需要SELECT_PRIV权限，而 ETL 工程师需要SELECT_PRIV、LOAD_PRIV和CREATE_PRIV权限。</p><p></p><h2>5、宣导阶段</h2><p></p><p>该阶段主要是输出前面各阶段的 TimeLine、总结以及上线后使用 Apache Doris 的注意事项说明，比如我们用到多租户隔离，那么 DDL 建表时则需要在 Properties 中显示指定各副本对应的资源组：</p><p></p><p><code lang=\"text\">create table zt_table\n......\nproperties(\n    \"replication_allocation\"=\"tag.location.group_a:1, tag.location.group_b:1, tag.location.group_c:1\"\n)\n</code></p><p></p><h2>6、运行阶段</h2><p></p><p></p><h3>Tablet 规范问题</h3><p></p><p>问题描述： 上线运行一段时间后，随着越来越多的数据增长，集群每次重启后一周左右，读写就会开始变得越来越慢，直到无法正常进行读写。</p><p></p><p>问题处理：</p><p></p><p>经过对生产和 UAT 环境的对比测试以及对数仓表的 Schema 的分析，我们发现有些表数据并不大，但是 Bucket 却设置的非常大。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1e/1e958e9b6b783ddf7198f67afa238e50.png\" /></p><p></p><p>结合show data from database命令，我们将整个集群所有表的 Bucket 信息罗列出来，明确了大部分表的 Bucket 设置的不合理；而当前集群共 20T 左右数据，平均 1T 数据近 10W 个 Tablet，这就会导致小文件过多，造成 FE 元数据负载过高，从而影响导入和查询性能。定位原因后与社区小伙伴二次确认，并根据官方建议将 Bucket 设置不合理的表全部调整，调整后集群逐步恢复读写正常。（即将发布的 Apache Dorie 1.2.2 版本将推出 Auto Bucket 动态分桶推算功能，可以根据历史数据和机器数目自动推算新建 Partition 的分桶个数，保证分桶数始终保持在合理范围内，可有效解决上述问题）</p><p></p><p>问题小结：</p><p></p><p>Tablet数 = 分区数 * 桶数 * 副本数1TB 数据的 Tablet 数量控制在 8000 个左右（三副本控制到 2.4W 左右）建议大表的单个 Tablet 存储数据大小在 1G-10G 区间，可防止过多的小文件产生建议百兆左右的维表 Tablet 数量控制在 3-5 个，保证一定的并发数也不会产生过多的小文件</p><p></p><h3>集群读写优化</h3><p></p><p>问题描述： 1.1.3 release 版本中，高并发的同时进行 Stream Load、Broker Load、insert into 和查询时，读写会变得非常慢，如下图 11/01 19:00 并发上来后的 Txn Load 所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/56/56ce7d64b02734ea9bd69fac8bbc7594.png\" /></p><p></p><p>问题处理：</p><p></p><p>我们进行了十几轮对比测验，结论如下：</p><p></p><p>写入速度与并发的增长成反比（但不会骤变，而是缓慢变化）单表 Bucket（Tablet）设置过大会导致集群写入速度骤减；例如 A 库的 TA 表，设置 80 个 Bucket 时，启动相关 Flink Sink Job 就会导致集群整体写入速度迅速变慢，降低 Bucket（9~10个）时写入恢复正常。insert into select 的 ETL 任务与 Stream Load 写入任务会进行资源抢占，同时并发运行会使整个集群读写变慢。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/aa/aa007b19e2637176901bb3e507f4e081.png\" /></p><p></p><p>通过be.INFO发现，80 个 Bucket 表写入某个 Tablet 的memsize/rows/flushsize/duration数值比 10 个 Bucket 写入时的数值呈数倍之差，即 80 个 Bucket 表的数据写入时效无论 Memsize 还是 Flushsize 都非常小、但花费时间却很长。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/65/65165c4cb5a9407950a6a1726bf3535f.png\" /></p><p></p><p>同时收集 Pstack 日志，经过分析可以确定，Tcmalloc 在频繁地寻找 pageheap_lock，导致高频竞争锁从而降低了读写性能。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2a/2abd505af3f58af9f3ecadd96ffa305c.png\" /></p><p></p><p>于是，进行如下参数调整：</p><p></p><p><code lang=\"text\">减少doris_be进程内存返回给linux系统的频率，从而减少tcmalloc频繁竞争锁的情况\ntc_use_memory_min = 207374182400\ntc_enable_aggressive_memory_decommit = false\ntc_max_total_thread_cache_bytes=20737418240\n</code></p><p></p><p>调参并滚动重启 BE 后，集群状况如下图所示：</p><p></p><p>18:50 前将 Broker Load、insert into 和查询任务同时开启，18:50 后将 Stream Load 任务也开启（包括 80 bucket的表），集群整体的读写性能不仅没有下降，反而 Stream Load 时效突破了压测阶段的最大值 269 MB/S&amp;680K /ops/s，并且持续稳定。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ae/aebed62eb74e18eb32f430e3ed9696bf.png\" /></p><p></p><p>问题小结：</p><p></p><p>使用 Apache 1.1.3 及以上版本，非常推荐调整 Tcmalloc 相关参数，减少doris_be进程与系统之间的内存申请回收过程，可明显减少锁竞争的现象，大大提升读写性能和集群稳定性。（从 Apache Doris 1.1.5 版本开始，增加了Tcmalloc 简化配置，可将众多 Tcmalloc 参数归约到参数memory_mode中，compact 为节约内存模式，performance 为性能模式，用户可根据实际需求进行调整）</p><p></p><h1>总结收益</h1><p></p><p>当前 Apache Doris 的生产集群为 3 FE + 9 BE 组合， 已导入集团存量和增量数据的 60%以及部分 DW 数据生成，3 副本共占 44.4TB 的存储。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/38/38e07357927119172b7e191f06e55f20.png\" /></p><p></p><p>依赖 Apache Doris 自身优异特性及其生态圈帮助我们快速构建了一套新的流批一体数据架构，平均每天实时入库的数据量达到上亿规模，同时支持上万个* *调度任务平稳运行，相比早期架构单表查询效率提升近 5 倍 ，数据导入效率提升近 2 倍**，内存资源使用率显著减少。除此之外，Apache Doris 以下优势也是我们快速构建数据架构的重要推动力：</p><p></p><p>扩展表：联邦查询的设计，便于集成其它存储数据表设计：丰富的数据模型，可快速应对不同的数据需求。数据查询：不同的 Join 算子结合自身完善的优化器，让查询快而稳。架构设计：架构清晰明了且运维简单，大大地降低了我们的运维成本。数据导入：各种 Load 方式及 Connector 的扩展，基本涵盖大部分的数据同步场景应用。活跃度：社区高度活跃，SelectDB 为 Apache Doris 社区组建了一支专职技术支持团队，疑难杂症基本能在 12H 内快速响应并有社区小伙伴跟进和协助解决。</p><p></p><h1>未来规划</h1><p></p><p>结合当下业务场景的考虑，未来我们将引入数据湖进行非结构化和结构化数据一体存储，进一步完善流批一体架构。同时也会将 Apache Doris 回归它最本质的定位，专注于 OLAP 分析场景，并通过 Apache Doris 统一湖仓查询引擎层，发挥其最大的功效。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7c/7cf344c618c3f97d85fa7507b9dac4ee.png\" /></p><p></p><p>最后，非常感谢 Apache Doris 社区和 SelectDB 团队的张家锋、曲率和杨勇强等小伙伴对我们无私的技术支持，未来我们也将持续参与 Apache Doris 社区建设中，贡献绵薄之力。祝 Apache Doris 社区和 SelectDB 越来越好，日臻完善！</p>",
    "publish_time": "2023-02-17 12:56:25",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从资源弹性到数据弹性，乾象如何将云上量化研究效率提升40%？",
    "url": "https://www.infoq.cn/article/AwaZ5xmgwguT7PJkYU2Q",
    "summary": "<p></p><p>作者 | 李治昳、李健弘</p><p>&nbsp;</p><p></p><blockquote>机器学习、云计算、云原生等技术的进步给金融行业创新注入了新的动力，以乾象投资 Metabit Trading为代表的以人工智能为核心的科技型量化投资公司的工作就非常有代表性。我们通过深度融合和改进机器学习算法，并将其应用于信噪比极低的金融数据中，为投资人创造长期可持续的回报。&nbsp;与传统的量化分析不同，机器学习不仅关注股价、交易量和历史回报率等结构化数据，还注入来自研报、财报、新闻和社交媒体等非结构化数据来深入了解证券价格走势和波动性。然而，将机器学习应用于量化研究是具有挑战性的，因为原始数据可能包含噪声。此外，他们还需要应对许多挑战，如突发任务、高并发数据访问和计算资源限制等。&nbsp;为此，乾象投资在研发投入、创新支持和基础平台建设方面持续发力。他们的研究基础设施团队构建了一个高效、安全、规模化的工具链研发流程，通过合理利用云计算和开源技术突破了单机研发的限制。&nbsp;本文将分享乾象量化研究基础平台的具体实践，介绍基于Fluid+JuiceFSRuntime的公共云弹性量化投研工作支撑。</blockquote><p></p><p>&nbsp;</p><p></p><h2>量化研究的工作详解</h2><p></p><p>&nbsp;</p><p>作为AI-powered hedge fund，通过AI模型训练进行策略研究是我们最主要的研究方式。首先，在模型训练之前需要对原始数据做特征提取。金融数据的信噪比特别低，如果直接使用原始的数据进行训练，得到的模型噪音会非常大。原始数据除了行情数据，即大家经常会看到的市场上的股价、交易量之类的数据，也包括一些非量价的数据，比如研报、财报、新闻、社交媒体等之类的非结构化数据，研究人员会通过一系列的变换提取出特征，再进行 AI 模型训练。可以参考下面我们研究场景中和机器学习关联最紧密的策略研究模式的简化示意图。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/34/342b13f0e623682ebcad288b1d286335.png\" /></p><p>&nbsp;</p><p>模型训练会产出模型以及信号。信号是对未来价格趋势的判断，信号的强度意味着策略导向性的强度。量化研究员会根据这些信息去优化投资组合，从而形成交易的实时仓位。这个过程中会考虑横向维度（股票）的信息来进行风险控制，例如某一行业的股票不要过度持仓。当仓位策略形成之后，量化研究员会去模拟下单，而后得到实时仓位对应的盈亏信息，从而了解到这个策略的收益表现，这就是一个量化研究的完整流程。</p><p>&nbsp;</p><p></p><h2>量化研究基础平台的需求</h2><p></p><p>&nbsp;</p><p>第一，突发任务多，弹性要求高。在策略研究的过程中，量化研究员会产生策略想法，并会通过实验去验证自己的想法。伴随着研究人员新想法的出现，计算平台就会产生大量的突发任务，因此我们对计算的弹性伸缩能力要求很高。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/ae/aec25bce4587659a316545ea1714831f.png\" /></p><p>&nbsp;</p><p>上图是我们某个集群一段时间的运行实例数据。以上图为例，可以看到在多个时间段里，整个集群实例数高峰时刻可以达到上千个，但是同时整个计算集群的规模也会有缩容到0时候。量化机构的计算任务和研究员的研发进度是有很大关联的，波峰波谷的差距会非常大，这也是离线研究任务的特点。</p><p>&nbsp;</p><p>第二，热数据高并发访问，除了计算需要弹性，数据缓存也需要弹性。对于热数据，比如行情数据，通常会有上百个任务同时访问数据，它的吞吐要求非常高，峰值时数百 Gbps 甚至 Tbps 级别的聚合带宽才能满足需求。但是当计算集群中没有任何节点的时候，此时的吞吐需求为0，如果是刚性吞吐这就需要弹性吞吐扩缩容的能力。</p><p>&nbsp;</p><p>第三，容量和吞吐的独立线性扩展能力，对金融模型训练非常重要。传统分布式存储带宽与吞吐仅和数据使用容量成正比，而量化研究过程中会创建大量的容器并发访问存储系统的数据，会触发存储系统访问限流。这就造成计算资源极致弹性与存储系统有限带宽之间的矛盾。 而量化研究的数据量其实不是特别大，很多市场的量价数据总量也不会超过 TB 级，但是数据访问需要的峰值吞吐却非常高。</p><p>&nbsp;</p><p>第四，数据亲和性调度，同一数据源多次运行访问本地缓存可以被复用。充分发挥热点数据集的缓存节点优势，在对用户无感知的前提下，智能的将任务调度到数据缓存节点上。让常用的模型训练程序越来越快。</p><p>&nbsp;</p><p>第五，IP保护：数据共享与数据隔离。出于IP 保护的需求，不仅在计算任务上需要做隔离，在数据上也是需要具备权限控制的隔离能力；同时对行情数据这类相对公开的数据，还需要支持研究员的获取方式是便捷的。</p><p>&nbsp;</p><p>第六，缓存中间结果。计算任务模块化的场景会对中间结果的存储跟传输也有需求。举个简单的例子，在特征计算过程中会生成比较大量的特征数据，这些数据会立刻用于接下来大规模高并发的训练节点上。显而易见在这种场景下我们需要一个高吞吐和高稳定的中间缓存做数据传递。</p><p>&nbsp;</p><p>第七，多文件系统的支持。计算任务中各类型的任务会对应的各种特性的数据类型和使用方式，因而我们不同团队会采用不同的文件系统包括OSS，CPFS，NAS，JuiceFS，以获取在各自情况下的性能最优化。Fluid的不同runtime能够灵活的支持文件系统与任务的组合，使得任务计算能够在k8s上更高效合理的利用对应资源避免不必要的浪费。</p><p></p><h2>Fluid+JuiceFSRuntime：为云上量化研究基础平台提供高效支撑</h2><p></p><p>&nbsp;</p><p>出于POSIX兼容，成本，高吞吐的考虑，我们选择了JuiceFS云服务作为分布式底层存储。选择了JuiceFS，发现现有Kubernetes的CSI体系并不能很好地支持我们对数据访问性能、弹性吞吐能力以及数据共享隔离的需求，具体来看：</p><p>&nbsp;</p><p>传统的Persistent Volume Claim是面向通用存储的抽象，缺乏对同一个存储复杂数据访问模式协同良好的支持：在不同的应用场景下，应用对同一存储中不同文件的使用方式不同，比如我们多数并发计算任务要求只读；但是也有Pipeline 数据中转，数据特征生成之后，需要中转到模型训练中，此时就要求读写；这导致了很难在同一个PVC中统一设置元数据更新和缓存策略。实际上，这些策略应该完全取决于应用使用数据的模式。数据隔离与共享：不同数据科学家团队访问不同的数据集需要天然隔离，并且要求比较容易管理；同时支持公共数据集访问共享，特别是缓存数据共享，由于行情数据这类相对公开的数据，不同的研究员团队会反复使用，希望获得“一次预热、全公司收益”的效果。数据缓存感知的Kubernetes调度：相同模型、相同输入、不同的超参的作业以及微调模型、相同输入的作业都会不断重复访问同一数据，产生可以复用的数据缓存。但是原生的 Kubernetes 调度器无法感知缓存，导致应用调度的结果不佳、缓存无法重用，性能得不到提升。数据访问吞吐可以弹性扩容到数百Gbps：传统的高性能分布式文件存储，一般的规格是200 MB/s/TiB基线的存储规格，其最大IO带宽是20Gbps，而我们任务的峰值 IO 带宽需求至少需要数百 Gbps，显然无法满足我们的要求。数据缓存的成本最优：由于公共云提供了计算资源极致弹性，可以短时间内弹出几百甚至上千计算实例，而当这些计算资源同时访问存储时，在高峰时吞吐需要数百Gbps甚至更高，此时需要通过计算中的缓存集群去服务热数据。但是很多时间段内，计算集群会缩容为0，此时维护一个很大的缓存集群就得不偿失了。我们更倾向于在使用之前进行数据预热，同时根据业务的运行规律执行定时扩缩容；而当计算集群没有作业在运行，再缩容到默认缓存节点，从而达到对数据缓存吞吐的动态弹性伸缩控制。</p><p>&nbsp;</p><p>为了达到上述目标，我们迫切希望找到 Kubernetes 上具有弹性分布式缓存加速能力同时很好支持JuiceFS存储的软件。我们发现 CNCF Sandbox 项目<a href=\"https://github.com/fluid-cloudnative/fluid\">Fluid</a>\"&nbsp;和JuiceFS存储有很好的协同，JuiceFS团队正好也是Fluid项目中JuiceFSRuntime的主要贡献者和维护者。于是，我们设计了基于 Fluid 的架构方案并选择了原生的JuiceFSRuntime。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/77/77e1be2ed9b2fe131b0a60c4f1ee9acd.png\" /></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h3>架构组件介绍</h3><p></p><p></p><h4>Fluid</h4><p></p><p>Fluid 不同于传统的面向存储的 PVC 抽象方式，而是在 Kubernetes 上针对“计算任务使用数据”的过程进行抽象。它提出了弹性数据集 Dataset 的概念，以应用对数据访问的需求为中心，给数据赋予特征，如小文件、只读、可读写等；同时将数据从存储中提取出来，并且给有特征的数据赋予范围，如用户只关心某几天的数据。围绕 Dataset 构建调度系统，关注数据本身和使用数据的应用的编排，强调弹性和生命周期管理。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/81/81ea05abafd21df3721d3779d35b6b00.png\" /></p><p>&nbsp;</p><p></p><h4>JuiceFSRuntime</h4><p></p><p>JuiceFSRuntime 基于JuiceFS的分布式缓存加速引擎, 通过将数据分布式缓存技术与Fluid自动弹性伸缩(Autoscaling)、可迁移(Portability)、可观测(Observability)、亲和性调度（Scheduling）能力相结合，支持场景化的数据缓存和加速能力。在Fluid上使用和部署JuiceFSRuntime流程简单、兼容原生 Kubernetes 环境、可以开箱即用，并深度结合JuiceFS存储特性，针对特定场景优化数据访问性能。</p><p>&nbsp;</p><p></p><h3>使用基于 JuiceFSRuntime 的 Fluid 的原因</h3><p></p><p>&nbsp;</p><p>Dataset抽象满足云原生机器学习场景的性能优化和隔离共享等多样需求：</p><p>&nbsp;</p><p>场景化性能调优：通过Dataset可以针对不同访问特点的数据集作相应的优化，比如模型训练场景通常是只读，而特征计算需要读写。数据隔离： Dataset天然的通过Kubernetes 的命名空间这种资源隔离机制用来限制不同团队对集群中数据集的访问权限，并且不同的数据集对应JuiceFS中不同的子目录（JuiceFS企业版还支持目录配额），这可以满足数据隔离的需求。数据缓存共享：对于一些不同团队都会频繁使用的公开数据集，Fluid支持跨Kubernetes Namespace的数据访问，可以做到一次缓存，多个团队共享，这也满足了数据缓存共享的需求。</p><p>&nbsp;</p><p>Runtime场景化的计算资源优化：Dataset是数据的通用抽象，而对于数据真正的操作，实际上由JuiceFSRuntime实现，所以Runtime的CPU，Memory，网络和缓存Worker数量等资源配置势必会影响性能，这就需要针对Dataset的使用场景，对Runtime的计算资源进行优化配置。</p><p>&nbsp;</p><p>弹性分布式缓存：支持丰富的扩缩容策略，包括手动伸缩、自动弹性伸缩和定时弹性伸缩，可以根据需要找到最优的弹性方案。</p><p>&nbsp;</p><p>手动伸缩：通过Dataset的可观测性，可以了解数据集的数据量和缓存Runtime需要的缓存资源，也可以根据应用访问的并发度设置Runtime的Replicas数量（缓存Worker的数量），不用的时候可以随时缩容。自动弹性伸缩：根据数据指标进行自动弹性伸缩。比如根据数据缓存量和吞吐量等指标进行缓存弹性伸缩，可以制定当缓存百分比超过80%，或者当客户端数量超过一定阈值的时候进行自动扩容。&nbsp;定时弹性伸缩：根据业务特性设置定时弹性伸缩，可以实现无人参与的数据弹性扩缩容机制。</p><p>&nbsp;</p><p>自动的数据预热：避免在训练时刻并发拉取数据造成数据访问竞争，还可以和弹性伸缩配合，避免过早的创建缓存资源。</p><p>&nbsp;</p><p>数据感知调度能力：在应用被调度时，Fluid会通过JuiceFSRuntime把数据缓存位置作为一个调度信息提供给K8s调度器，帮助应用调度到缓存节点或者离缓存更近的节点。整个过程对用户透明，实现数据访问性能的优势最大化。</p><p></p><h3>落地实践</h3><p></p><p>&nbsp;</p><p>根据实践，我们总结了以下经验供大家参考。</p><p></p><h4>在Fluid的JuiceFSRuntime选择高网络IO和大内存的ECS作为缓存节点</h4><p></p><p>&nbsp;</p><p>随着ECS网络能力的不断提升，当前网络带宽已经远超SSD云盘IO能力。以阿里云上的ecs.g7.8xlarge规格的ECS为例，其带宽峰值为25Gbps，内存为128GiB。理论上，完成40G数据读取仅需要13s。我们的数据是存储在JuiceFS上的，因此为了实现大规模的数据读取，我们需要首先将数据加载到计算所在VPC网络中的计算节点中。以下为我们使用的一个具体例子，为了提高数据读取速度，我们配置cache节点使其选择使用内存来缓存数据。这里需要注意：</p><p>&nbsp;</p><p>Worker 主要负责分布式数据缓存，为了提高数据读取速度，我们可以为 Worker 配置内存性能相对较高的机型。而 Worker 的调度策略在 Dataset 中配置，因而需要在 Dataset 中为 Worker 配置亲和性策略。当任务没有特定机型需求时，为保证Cluster的AutoScaler能成功扩容，实践中也建议在进行亲和性配置时选择多种实例类型以保证扩容/任务执行的成功。Replicas是初始的缓存Worker数量，后期可以通过手动触发或自动弹性伸缩进行扩缩容。当指定tieredstore后，即无需在Kubernetes的Pod中设置request的内存，Fluid可以自动处理。如在缓存节点上的JuiceFS mount有不同的配置，例如cache size大小， 挂载路径等，可以通过worker里的options进行覆盖。</p><p>&nbsp;</p><p><code lang=\"null\">apiVersion: data.fluid.io/v1alpha1\nkind: Dataset\nmetadata:\n  name: metabit-juice-research\nspec:\n  mounts:\n    - name: metabit-juice-research\n      mountPoint: juicefs:///\n      options:\n          metacache: \"\"\n          cache-group: \"research-groups\"\n      encryptOptions:\n        - name: token\n          valueFrom:\n            secretKeyRef:\n              name: juicefs-secret\n              key: token\n        - name: access-key\n          valueFrom:\n            secretKeyRef:\n              name: juicefs-secret\n              key: access-key\n        - name: secret-key\n          valueFrom:\n            secretKeyRef:\n              name: juicefs-secret\n              key: secret-key\n  nodeAffinity:\n    required:\n      nodeSelectorTerms:\n        - matchExpressions:\n            - key: node.kubernetes.io/instance-type\n              operator: In\n              values:\n                - ecs.g7.8xlarge\n                - ecs.g7.16xlarge\n  tolerations:\n  -key: jfs_transmittion\n  operator: Exists\n  effect: NoSchedule\n \n---\napiVersion: data.fluid.io/v1alpha1\nkind: JuiceFSRuntime\nmetadata:\n  name: metabit-juice-research\nspec:\n  replicas: 5\n  tieredstore:\n    levels:\n      - mediumtype: MEM\n        path: /dev/shm\n        quota: 40960\n        low: \"0.1\"\n   worker:\n     nodeSelector:\n       nodeType: cacheNode\n     options:\n       cache-size: 409600\n       free-space-ratio: \"0.15\"</code></p><p></p><p></p><h4>配置自动弹性伸缩策略</h4><p></p><p>&nbsp;</p><p>受业务形态的影响，Metabit在固定时段会有跟高的用量需求，因此简单的配置定时缓存节点的弹性伸缩策略能到达到不错的收益，例如对成本的控制，对性能提升。apiVersion:</p><p>&nbsp;</p><p><code lang=\"null\">autoscaling.alibabacloud.com/v1beta1\nkind: CronHorizontalPodAutoscaler\nmetadata:\n  name: research-weekly\n  namespace: default\nspec:\n   scaleTargetRef:\n      apiVersion: data.fluid.io/v1alpha1\n      kind: JuiceFSRuntime\n      name: metabit-juice-research\n   jobs:\n   - name: \"scale-down\"\n     schedule: \"0 0 7 ? * 1\"\n     targetSize: 10\n   - name: \"scale-up\"\n     schedule: \"0 0 18 ? * 5-6\"\n     targetSize: 20</code></p><p>&nbsp;</p><p>更进一步，如果通过业务中具体的metrics如缓存比例阈值， IO throughput等触发带有复杂自定义规则的弹性伸缩策略可以实现更为灵活的缓存节点扩缩容配置以带来更高和更稳定的性能表现。具体来讲，在灵活度和性能层面会有以下一些优点：</p><p>&nbsp;</p><p>无需精准感知底层数据或拥有固定的扩缩容规则， 依据集群状态自适应的配置缓存副本上下限。阶梯式扩容避免一开始就创建过多的ECS，造成花费上的浪费。避免爆发式的ECS访问JuiceFS数据造成带宽抢占。</p><p></p><h4>触发数据预热</h4><p></p><p>&nbsp;</p><p>通过数据预热提升缓存比例，进而触发自动弹性伸缩；同时监控缓存比例，当缓存比例达到一定阈值同时开始触发任务下发，避免过早下发高并发任务导致IO延迟。</p><p></p><h4>镜像预埋</h4><p></p><p>&nbsp;</p><p>由于Metabit Trading使用计算和数据弹性的规模很大，瞬间会弹出非常多的Pod，这就会导致镜像下载限流。网络带宽资源在pod拉起过程中是稀缺的，为避免pod 创建时因拉取容器镜像延时带来的各种问题，我们建议对ECS的镜像进行客制化改造，对需要的系统性镜像做到“应埋尽埋”从而降低pod拉起的时间成本。具体例子可参考<a href=\"https://#L191\">ACK</a>\"的基础镜像。</p><p>&nbsp;</p><p></p><h2>弹性吞吐提升带来的性能和成本收益</h2><p></p><p>&nbsp;</p><p>在实际部署评估中，我们使用20个ecs.g7.8xlarge规格的ECS作为woker结点构建JuiceFSRuntime集群，单个ECS结点的带宽上限为25Gbps；为了提高数据读取速度，我们选择使用内存来缓存数据。</p><p>&nbsp;</p><p>为便于对比，我们统计了访问耗时数据，并与使用Fluid方式访问数据耗时进行了对比，数据如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f3/f3303c7c2967c4938fb5bfe285fda6e4.png\" /></p><p></p><p>&nbsp;</p><p>可以看出，当同时启动的Pod数量较少时，Fluid与分布式存储相比并没有明显优势；而当同时启动的Pod越多时，Fluid的加速优势也越来越大；当同时并发扩大到100个Pod时，Fluid相比传统分布式存乎可以降低超过40%的平均耗时。这一方面提升了任务速度，另外一方面也确实的节省了ECS因为IO延时带来的成本。</p><p>&nbsp;</p><p>更重要的是，因整个Fluid系统的数据读取带宽是与JuiceFSRuntime集群规模正相关的，如果我们需要同时扩容更多的Pod，则可以通过修改JuiceFSRuntime的Replicas来增加数据带宽，这种动态扩容的能力是分布式存储目前无法满足的。</p><p></p><p></p><h2>展望</h2><p></p><p>&nbsp;</p><p>Metabit在Fluid的实践上走出了踏实的第一步，面对这个不断创新和持续输出的技术框架我们也在思考如何发挥在更多合适的场景发挥其完备的功能。这里简单聊聊我们的一些小观察，抛砖引玉，供大家发挥。</p><p>&nbsp;</p><p>Serverless化能够提供更好的弹性：目前我们通过自定义镜像的方式提升应用容器和Fluid组件的弹性效率，我们也关注到在ECI上使用Fluid能更高效和简单的应用扩展弹性，同时降低运维复杂度。这是一个在实践中值得去探索的方向。任务弹性和数据缓存弹性的协同：业务系统了解一段时间内使用相同数据集的任务并发量，并且任务排队的过程中执行数据预热和弹性扩缩容；相应的当数据缓存或者数据访问吞吐满足一定条件，触发排队任务从等待变成可用。</p><p>&nbsp;</p><p></p><h2>总结和致谢</h2><p></p><p>&nbsp;</p><p>Metabit Trading在生产环境使用Fluid已经接近一年半了，包括JindoRuntime、JuiceFSRuntime等，目前通过JuiceFSRuntime实现了高效的大规模量化研究。Fluid很好的满足了简单易用、稳定可靠、多Runtime、易维护以及让量化研究员的使用感透明等好处。</p><p>&nbsp;</p><p>Metabit Trading的大规模实践帮助我们团队在使用公共云上积累了很好的认知，在机器学习和大数据场景下，不但计算资源需要弹性，与之配合的数据访问吞吐也需要与之相匹配的弹性，传统的存储侧缓存由于成本、灵活、按需弹性的差异，已经很难满足当前场景的需求，而Fluid的计算侧弹性数据缓存的理念和实现则非常合适。</p><p>&nbsp;</p><p>这里要特别感谢JuiceData的朱唯唯，Fluid社区的车漾，徐之浩和顾荣老师的持续支持。因为有他们的维护，社区内有活跃的讨论和快速的响应，这对我们的顺利adoption起到了关键的作用。</p><p>&nbsp;</p><p>作者介绍：</p><p>&nbsp;</p><p>本文作者来自乾象投资 Metabit Trading，分司成立于2018年，是一家以人工智能为核心的科技型量化投资公司。核心成员毕业于 Stanford、CMU、清北等知名高校。目前，管理规模已突破 50 亿元人民币, 并且在2022年市场中性策略收益排名中名列前茅，表现亮眼。</p><p></p><p>李治昳，Metabit Trading - AI Platform Engineer，builder 、云原生技术learner，曾任Citadel高级工程师。</p><p>&nbsp;</p><p>李健弘， Metabit Trading - Engineering manager of AI Platform，专注于在量化研究领域搭建机器学习平台和高性能计算平台，曾任 Facebook 高级工程师。</p><p>&nbsp;</p><p></p>",
    "publish_time": "2023-02-17 14:03:11",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "专访吉利汽车：供应链数字化不能有“断点”，业技融合是必经之路",
    "url": "https://www.infoq.cn/article/dXYjsLxYiFhOzSyfNwxu",
    "summary": "<p></p><p>核心要点</p><p>目前吉利汽车集团下多个板块的业务能力成熟度处于 B 级到 C 级之间，包括供应链体系的团队。实施物流一体化项目之后，也就实现了任意销售订单向物流订单的转化及物流全链路可视。信息化项目的验收汇报工作从原来由 IT 人员负责、逐渐变为由业务人员负责。如果 IT 人员不主动拥抱数字化转型，不主动了解业务以及提升业务架构设计能力，那IT团队就容易被边缘化，沦为名副其实的“外包团队”。</p><p></p><p>100 多年前，“汽车大王”亨利·福特 (Henry Ford) 关于 T 型车有这样一句名言：“任何客户都可以将汽车涂成他想要的任何颜色，只要它是黑色的。”福特的言外之意是只能选黑色，但结合当时的生产条件来看，这其实是为了量产而做的妥协，T 型车之所以只有黑色，是因为只有这样才能提高效率和提高质量。</p><p></p><p>但发展到今天，在数字化浪潮下，“<a href=\"https://xie.infoq.cn/article/b944fcb9fbea9a28996a054b4\">新四化</a>\"”（电动化、联网化、智能化和共享化）已经成为汽车产业发展的趋势。汽车企业的核心战略逐步向“用户定义汽车”转变，而要满足用户的个性化需求，必须有数字化的支撑，也只有敏捷的数字化供应链，才能对需求做出快速响应和交付。</p><p></p><p>吉利汽车集团数字化中心供应链产品总监张炜向 InfoQ 表示，除了应对用户的个性化需求，在新的产业竞争格局下，吉利也面临着新技术的重新定义和商业模式的转型等多重挑战，尤其在过去 3 年多，受疫情影响，零部件供应中断多次给供应链带来较大风险和挑战，这要求汽车企业对供应链模式建立新的认识。</p><p></p><p>因此，对吉利汽车来说，供应链数字化的重要性不言而喻。</p><p></p><h2>打通全链路，快速定位和响应供应链风险</h2><p></p><p></p><p>据张炜介绍，在吉利的供应链体系里，物流与备件中心原来是职能协调部门。这意味着，作为“后台”，物流部门对前端业务的响应会存在一定程度的滞后。</p><p></p><p>如果说在过去，当汽车还是“卖方市场”，定制化需求还不凸显，原材料还不紧缺，生产节奏还可控的情况下，这种“一定程度”的滞后和延迟还在可接受的范围内；那么，现如今，随着汽车产业竞争的加剧，消费者的个性化需求开始影响汽车研发和生产，以及在恶劣的全球供应链环境下，则要求汽车的物流和备件环节也必须做到灵活且快速的响应。</p><p></p><p>为了解决这一问题，就需要在执行过程中将采购订单、生产订单都转化为物流订单。具体如何实现？吉利汽车给出的答案是打造供应链 OTWB 一体化物流信息平台。</p><p></p><p>所谓供应链 OTWB 一体化物流信息平台，具体包括了 OMS 订单管理系统、TMS 调度管理系统、WMS 仓储管理系统、BMS 计费管理系统，是目前被物流行业广泛应用的数字化供应链系统框架。过去两年，吉利自主研发了一个 OTWB 平台。</p><p></p><p>具体来说，吉利 OTWB 平台实现了其内外部零部件和售后备件在需求、仓储、运输、包装和配送环节的一体化管理，可以大大降低供应链整体运营成本，提升客户服务时效；同时以 OTWB 为中心，通过与 SAP（企业资源管理软件系统）、LES（物流执行系统）、SRM（供应商关系管理）、GWS（吉利云仓系统）、KDMS 等吉利内部业务系统集成，还打破信息孤岛，打通了物流全链路信息。</p><p></p><p>这意味着，实施物流一体化项目之后，也就实现了任意销售订单向物流订单的转化及物流全链路可视。</p><p></p><p>不过，与其它制造行业相比，汽车的供应链体系还要更为复杂。通常来说，一辆汽车需要配备上万个来自不同国家和地区的零件，不同车型的原材料采购需求又千差万别，供应链风险的控制难度要大得多。</p><p></p><p>因此，在信息化层面，除了建设一体化物流信息平台，吉利数字化中心还构建了供应链控制塔，可以快速定位供应链风险，比如哪个环节出问题，风险源头是哪家供应商，哪些零部件能够快速响应等等，对于风险可以进行实时监控，提高端到端的可视化。这使得吉利汽车在面对供应断点问题时，拥有了更加快速高效的响应体系，可以更灵活地应对外部环境的不确定变化。</p><p></p><p>同时，通过 LES 的全面推广实施，在各汽车制造基地导入视觉收货、RFID 自动出入库、自动化立体库、货到人拣选、AGV 转运等智能化手段，实现集团物流作业智能化、自动化。</p><p></p><p>除此之外，在采购层面，张炜还提及，通过与京东<a href=\"https://www.sohu.com/a/479888646_161795\">合作</a>\"搭建的采购商城，吉利还面向工业品实现了高效采购，可以从产品、仓储、物流、数字化服务等方面助力集团降低采购成本，提高运营效率。</p><p></p><p></p><h2>快速响应业务需求，数字化中心各司其职</h2><p></p><p></p><p>不过，与多数企业相似，吉利内部的数字化转型的过程，也不可避免地遭遇了来自组织、人和战略等多方面的考验。</p><p></p><p>业界充斥着各种各样的数字化转型思路和案例，吉利要找出适合自身场景的数字化理念，需要耗费不少功夫。而在起初阶段，由于内部对数字化的认知参差不齐，尽管管理层已经意识到来自行业的数字化转型压力，但执行层总不免有些抵触，多数人对此持怀疑态度：比如忧虑推进数字化工作之后，会不会给自己的岗位带来变化，甚至把自己淘汰了。</p><p></p><p>经过多年的持续探索，吉利汽车供应链数字化路径和方向逐渐明晰。</p><p></p><p>此前，吉利汽车的数字化建设主要是以落地信息化项目的模式推进，主要由吉利汽车信息工程部下的 IT 咨询部和研发部等部门负责，后来为了快速响应业务需求，数字化中心应运而生，组织架构也随之调整。</p><p></p><p>吉利汽车集团供应链数字化中心于 2021 年 9 月建立，团队规模约 180 人。由于集团的供应链体系是由采购公司、物流与备件中心、SQE 中心（Supplier Quality Engineer，供应商质量工程师）组成，因此对应的数字化中心亦分为 4 个团队，其中 3 个分别服务于采购、物流、SQE 等业务部门，各自负责对应业务团队的信息化项目落地和数字化场景应用。剩余的 1 个是供应链公共能力部门，主要负责大数据应用、供应链互联互通，供应链控制塔（供应链运营平台）等公共能力的建设。</p><p></p><p>据介绍，中心在不久的未来还会增设 1 个“供应链数字化使能团队”，主要负责架构规划和数字化成熟评估模型的迭代，原本这部分工作是从集团层面牵头规划，接下来将由供应链数字化中心负责推进。</p><p></p><h2>“六大方向”推进数转</h2><p></p><p></p><p>对于企业而言，从信息化到数字化，很关键的一点是统一转型的思路和方针，这有助于企业统一目标，更有效地分配资源和提高整体效率。</p><p></p><p>2021 年，吉利汽车集团数字化中心开始对数字化转型思路做系统性的梳理，并由此得出“六大方向”转型思路。目前，包括供应链在内的各业务板块均围绕“六大方向”思路展开数字化建设和运营。</p><p></p><p>促液态。首先，组织层面，构建“液态型组织”。内部认为，组织形式可以简单分为“稳态”和“液态”，大多数情况下组织是处于相对固定的“稳态”，但为了响应层出不穷的业务场景需求，需要灵活地从各团队抽调人员，继而组成新的支持团队，即“液态”组织；其次，这里说的“液态”也可以从文化构建层面理解，将数字化作为战略融入到集团文化中，甚至落到各职能部门和工厂的指标中；最后，“液态”也意味着 IT 和业务融合共创。绘蓝图。围绕集团战略，做好“四个坚持”。第一，坚持“一把手工程”，从 2005 年开始，集团内许多信息化项目开始贯彻“一把手”理念；第二、将数字化转型作为核心战略推动；第三、坚持顶层设计，从原来站在项目交付的思考维度，切换到从顶层设计的角度去研究架构规划；第四、坚持协同治理，信息化项目落地后，IT 与业务协同治理和迭代。搭平台。吉利数智平台朝着构建“高可用、高复用、生态化、国际化”等能力的目标演进，其中的核心内容包括构建敏捷的转型体系、共享中台、生态平台以及实现数智赋能（通过技术和平台工具挖掘数字价值，赋能业务），从而支撑业务的快速创新和发展。打基础。致力于数字化基础设施的稳定可靠、安全可信、资源弹性、成本精益。强运营。提供安全、可靠、高效的 IT 运营服务，借助自动化和智能化手段，让运维体系得以持续高效、可靠安全地运转起来。育人才。管理上融入数字化意识，落地上共创数字化能力，数字化人才不局限于技术专业人才，所有人都可以提升数字化能力。</p><p></p><h2>迫切的“一把手”，主动的业务人</h2><p></p><p></p><p>围绕集团的转型思路，供应链板块的数字化工作得以顺利落地。</p><p></p><p>在“促液态”层面来看，从 2022 年下半年起，吉利汽车供应链的业务侧和 IT 侧已逐渐“融合”，这主要得益于同年 3 月成立的“供应链数字化委员会”，尽管这是一个虚拟组织，但它也有相应的职能，在实际工作中能起到推动业务和 IT 加强沟通的作用。</p><p></p><p>虽然目前从组织结构上看，业务和 IT 是分开的，但供应链数字化委员会每两周进行一次共创会议。会上，委员会成员一同就业务架构梳理、业务能力梳理、数字化转型内容评估、顶层架构设计等话题进行讨论，并推导出所需的业务能力和项目内容。</p><p></p><p>比如在委员会最初成立之时，为了尽快规划顶层架构设计，为数字化转型提供制度供给的保障，数字化中心需要率先跟业务侧直接对接，让业务侧的“一把手”或核心管理层输入一些顶层战略，并形成业务架构和应用架构。随后再把这些业务构想结合行业趋势、国家政策导向以及自身能力期望，转变为数字化场景，逐渐找到更清晰的定位和发展脉络。</p><p></p><p>“除了每双周一个例会，还有月度会，而且供应链的‘一把手’每次都会参加。”张炜提到，对于数字化，“一把手”甚至比 IT 部门还要着急，会督促 IT 侧去推进数字化，有些时候 IT 部门都感到应接不暇。</p><p></p><p>这一切也导向了一个令人欣慰的变化。过往信息化项目的验收通常是由 IT 人员负责，现在很多时候变成了业务人员去介绍项目成果，比如由供应链的采购人员或者物流人员，对 IT 系统的实施思路和实施效果进行汇报。</p><p></p><p>张炜强调，“六大方向”数字化转型思路的践行离不开业务人员的参与。“我们发现，很多做得比较优秀的供应商，在数字化过程中往往会重视业务人员的数字化能力培养，甚至有些企业的核心数字化团队，其大部分成员是源自业务部门。”</p><p></p><p>除了业务人员，数字化也对 IT 人员提出了更高的要求。原先 IT 人员都是埋头做信息化项目的交付，按传统的产品交付制度，只要交付了某个功能或应用就基本完成任务，因此鲜少会去思考项目对业务带来的实际价值、能否提升竞争力等比较深层的问题。</p><p></p><p>如今，如果 IT 人员不主动拥抱数字化转型，不主动了解业务以及提升业务架构设计能力，那 IT 团队就容易被边缘化，沦为名副其实的“外包团队”。</p><p></p><p></p><h2>数字化成熟度模型：认清现状</h2><p></p><p></p><p>对于数字化中心而言，也许一年下来做的项目多达数十个，但多数是站在所在业务部门的角度考虑，只做到了“在线化”，还没有做到更全面的“数字化”。</p><p></p><p>因此，尽管吉利汽车供应链的数字化工作初见成效，但张炜表示现阶段依然任重而道远。尽管有了大的战略方针，但具体到落地，如何把控各业务数字化的进展，及时找出推进数字化不利的可能原因，以及要采取的相应措施，并非易事。</p><p></p><p>为此，2022 年 6 月，吉利汽车构建了数字化成熟度评估模型，分别从 5 个等级去评估“数字化转型准备度”和“业务能力数字化成熟度”。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/99/58/99fb6f05d916276bd7b3f652c7d38958.jpeg\" /></p><p></p><p><a href=\"https://xie.infoq.cn/article/d485ccf9cd64cbb1410b0991c\">数字化成熟度评估模型</a>\"是一种用于评估组织在数字化转型过程中所处成熟度水平的模型。它可以帮助组织更好地理解自身的数字化状态，识别其存在的瓶颈和发展机会，从而更好地指导数字化转型的过程和路径。有了这个模型，各业务单元的晋级目标也就更清晰。</p><p></p><p>张炜表示，依据该数字化成熟度模型进行评估，目前吉利汽车集团下多个板块的业务能力成熟度都处于 B 级到 C 级之间，包括供应链体系的团队。以满分 5 分来看，目前采购、物流和 SQE 3 个实体单位的平均分大约为 1.8 分，大部分还处于审批在线级的阶段，部分已处于流程在线级。</p><p></p><p>“2023 年，供应链团队会朝着‘全面数字化级’目标努力，同时形成局部‘智能运营级’，希望与业务一道通过吉利数字化转型的实践，2023 年实现尽可能多的业务能力达到全面数字化的水平。”张炜说道。</p>",
    "publish_time": "2023-02-17 15:25:16",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "全球都为ChatGPT疯狂，它到底是风口还是虚火？深度解读风暴眼中的ChatGPT | 直播预约",
    "url": "https://www.infoq.cn/article/5lzBBTLf5ddX8974MNVo",
    "summary": "<p></p><p></p><blockquote>火爆全球，ChatGPT 何以狂飙？</blockquote><p></p><p></p><p></p><h2>主题介绍</h2><p></p><p></p><h4>直播主题：</h4><p></p><p></p><p>《极客圆桌派：狂飙的 ChatGPT》</p><p></p><h4>直播时间：</h4><p></p><p></p><p>2023 年 2 月 20 日 19:30-21:30</p><p></p><h2>直播背景：</h2><p></p><p></p><p>自去年 11 月底正式发布以来，OpenAI 最新的 AI 聊天机器人 ChatGPT 火出天际，成为现象级应用，在全网话题度狂飙。</p><p></p><p>就连马斯克都在感叹，“很多人疯狂地陷入了 ChatGPT 循环中”，“ChatGPT 好得吓人，我们离强大到危险的人工智能不远了”。</p><p></p><p>ChatGPT 就像是一个无所不知的虚拟体，它能回答各种问题，而且总能给到让人满意，甚至超过预期的答案。ChatGPT 的应用也频频出圈，它还能写代码、改 Bug、创建编程语言、构建虚拟机，甚至写毁灭人类计划书...ChatGPT 展示出的强大的能力和无限可能，让人们看到，通过 ChatGPT 这样的技术方案解决很多任务的潜力。</p><p></p><p>以 ChatGPT 为代表的新一代聊天机器人开始广泛应用人工智能，这波浪潮有望重塑甚至取代传统互联网搜索引擎。ChatGPT 在解决各种问题上的能力超出很多人意料，因此很多用户都表示 ChatGPT 可以取代 Google 等搜索引擎和编程问答社区 Stack Overflow 等。</p><p></p><p>不久前，达摩院基础视觉负责人赵德丽在接受 InfoQ 采访时表示，以前谷歌等搜索引擎做搜索和检索，只是找已经存在的信息，ChatGPT 的应用，实现了从信息的搜索到信息的创造这样一个范式的转变，从算法能力上看，它取得了一个质的飞跃。短期来看，ChatGPT 有望成为或者辅助像谷歌这种传统信息检索的强有力的工具；长期来看，它有望发展成为 AI 系统级的服务。</p><p></p><p>自 ChatGPT 走红后，全球互联网大厂、创业公司纷纷加码布局，一场关于 ChatGPT 的军备竞赛已然拉开。</p><p></p><p>搜索引擎大战迅速爆发。在国外，谷歌加急推出了 ChatGPT 的竞争对手—人工智能聊天机器人 Bard Bard；微软已经宣布推出了由 OpenAI 提供技术支持的最新版必 Bing 索引擎。在国内，百度将在 3 月推出类似 ChatGPT 的产品— 文心一言的消息早已传遍全网。除了百度，几家中国初创公司也在探索生成人工智能。</p><p></p><p>ChatGPT 蹿红的速度，堪称前所未有。ChatGPT 上线仅仅几天，其用户就已经突破 100 万大关。2 月 1 日，瑞银发布研究报告称，ChatGPT 在 2022 年 11 月推出后，今年 1 月的月活跃用户估计已达 1 亿，成为历史上用户增长最快的消费应用。</p><p></p><p>“在互联网领域发展 20 年来，我们想不出有哪个消费者互联网应用比它上升速度更快，”瑞银分析师在报告中写道。</p><p></p><p>ChatGPT 出现对 AI 界来说，有着十分重要的意义。清华大学计算机科学与技术系长聘副教授黄民烈认为，“ChatGPT 宣示着无缝人机交互时代的来临。过去我们讲 conversation as a service （caas）还停留在纸面，但实际上今天，无论是开放域聊天，还是通用任务助理（ChatGPT）都在强烈地表明这一点”。</p><p></p><p>ChatGPT 的出现，其实不亚于阿尔法狗曾经在人工智能界带来的影响力。可以看到，ChatGPT 正在引领新一波 AI 浪潮。</p><p></p><p>让全网沸腾的 ChatGPT 到底有什么魔力？ChatGPT 具有哪些颠覆性的创新？其落地和商业化应用的前景几何？对于科技界来说，ChatGPT 的出现到底会带来哪些改变？ChatGPT 为什么是 OpenAI 最先做出来？爆红之下，有多少泡沫？...</p><p></p><p>我们试图找到这些问题的答案。于是，InfoQ 发起了一场《极客有约》特别栏目《极客圆桌派：狂飙的 ChatGPT》，我们邀请了多位 AI 领域的资深技术专家一起共同探讨 ChatGPT 的现在和未来。</p><p></p><p></p><h2>直播核心议题：</h2><p></p><p></p><p>人们会什么会觉得 ChatGPT 非常神奇？ChatGPT 特点讨论：哪些是创新？哪些是颠覆式创新？ChatGPT 的落地与商业化局限性Generative AI 和 ChatGPT 的关系。ChatGPT 的军备竞赛还有入局机会吗？这场游戏该怎么玩？为什么不是先出现在中国？中国版 ChatGPT 还会远吗？ChatGPT 能颠覆搜索引擎吗？除此以外，还有哪些可能探讨机会：对行业 / 大公司 / 创业公司 / 对互联网科技从业者</p><p></p><p>预约</p><p>本期极客有约特别策划之《极客圆桌派：狂飙的 ChatGPT》。</p><p>视频号</p><p>&nbsp;嘉宾介绍</p><p>圆桌主持&amp;嘉宾：</p><p>Mingke，MRS.ai 联合创始人兼CEO，组建面向未来的智能网络，《人工智障》系列作者。</p><p>圆桌嘉宾：</p><p>鲍捷，文因互联董事长，创始人。爱荷华州立大学（Iowa State University）博士，伦斯勒理工学院（RPI）博士后，麻省理工学院（MIT）分布式信息组（DIG）访问研究员。曾任三星美国研发中心研究员，曾任 W3C OWL(Web 本体语言) 工作组成员，参与撰写了 OWL2 知识图谱语言国际标准。现任 W3C（万维网联盟）顾问委员会委员、中国中文信息学会语言与知识计算专业委员会委员、中国人工智能学会心智计算专委会委员、金融知识图谱工作组主席、中文开放知识图谱联盟 (OpenKG) 发起人之一，国际 Data Intelligence 杂志编委。</p><p>张晴晴，Magic Data 创始人 &amp; CEO。曾任中国科学院声学研究所副研究员，是对话式 AI 先行者和 Data-Centric MLOps 引领者。</p><p>祝海林，Kyligence 技术合伙人 / 资深数据架构师、新一代开源编程语言 Byzer 的作者，拥有 13+ 年技术开发经验。一直专注于 Data + AI 融合方向，致力于帮助工程师们从根本上提高数据平台落地和 AI 工程化的效率。</p><p>&nbsp;如何看直播？</p><p>扫描下图海报【二维码】，预约 InfoQ 视频号，直播开始有提醒。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/76/76c8d0af3d5657feed7c1e71d5dc9e99.png\" /></p><p></p><p></p><h2>如何向讲师提问？</h2><p></p><p></p><p>点击此处：<a href=\"https://www.infoq.cn/form/?id=907\">https://www.infoq.cn/form/?id=907</a>\"填写提问表单，讲师会在直播中为你解答：</p><p></p><h2>更多福利</h2><p></p><p></p><p>除了分享干货，直播进行中，我们会在参与直播的同学安排幸运观众抽奖福袋，赠送 InfoQ 周边产品！敬请期待哦～</p>",
    "publish_time": "2023-02-17 16:03:44",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "铸基会议 | 2023年中国信通院铸基计划“集成平台即服务（iPaaS）系列标准”研讨会成功召开",
    "url": "https://www.infoq.cn/article/Ui3JSdRN2cSbqkPDjoJH",
    "summary": "<p>2023年<a href=\"http://www.caict.ac.cn/\">中国信通院</a>\"铸基计划“集成平台即服务系列标准”研讨会于2023年2月13日在中国信息通信研究院成功召开，来自浪潮通软、<a href=\"https://www.360.cn/\">360</a>\"、<a href=\"https://www.asiainfo.com/zh_cn/index.html\">亚信科技</a>\"、<a href=\"http://www.yonyou.com/\">用友网络</a>\"、<a href=\"https://www.dingtalk.com/\">钉钉</a>\"、<a href=\"http://www.primeton.com/about/\">普元科技</a>\"、<a href=\"https://authing.co/\">AUTHING</a>\"、<a href=\"https://www.clickpaas.com/\">ClickPaas</a>\"、<a href=\"https://www.infoq.cn/\">InfoQ</a>\"、北京银行、工商银行、<a href=\"https://www.uyun.cn/\">广通优云</a>\"、<a href=\"https://www.hengshi.com/\">衡石科技</a>\"、<a href=\"https://www.teamsun.com.cn/\">华胜天成</a>\"、明源云、<a href=\"https://www.bingosoft.net/home/index.html\">品高软件</a>\"、炎黄盈动、致远互联、<a href=\"https://www.gientech.com/\">中电金信</a>\"、民生银行、<a href=\"http://www.harmonsw.com/h-col-107.html\">鸿雪科技</a>\"等企业的代表线下线上同时参与了本次会议。中国信通院泰尔终端实验室数字生态发展部工程师曹海啸主持本次会议。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fa/faa1f8ae687847689c3948fd92288c8a.png\" /></p><p></p><p>中国信通院泰尔终端实验室王景尧博士到会致辞。王景尧表示，建立标准和评测认证是提高数字化产品与应用质量的关键环节，也是铸基计划高质量数字化推进专项行动的重要步骤，iPaaS 可以帮助企业连接应用程序、自动化业务流程，并从分布在不同系统中的数据生成报告和分析，对于企业数字化转型过程中实现应用程序现代化非常重要。同时，在集成、安全、服务、可扩展性等方面需要凝聚多方共识，形成行业标准助力行业高质量发展。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d2/d2584959f68c9cbc753a5062997bcb98.jpeg\" /></p><p></p><p>中国信通院泰尔终端实验室吴荻博士对中国信通院“铸基计划-高质量数字化转型推进行动”进行了介绍。“铸基计划”发起成立以来，专注于链接数字化转型的供给方和需求方，在企业直播、即时办公、协作文档、5G消息、组装式应用等多个企业服务热点领域开展标准制定、测试评估工作，持续推动数字化转型供给侧高质量发展。同时，铸基计划聚焦需求侧在转型中遇到的选型问题，通过揭榜行动、全景图等方式，帮助企业更好的遴选数字化产品及服务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d5/d5f0d6ddea6f0f417ba28c6c6342ecd3.jpeg\" /></p><p></p><p>&nbsp;</p><p>中国信通院泰尔终端实验室专家曾晨曦对集成平台即服务系列标准的框架和内容进行了介绍和解读，该系列标准将从供给侧和需求侧出发，建立集成平台即服务评测体系和评估标准，基于iPaaS在总体框架、API全生命周期管理、API网关、安全能力、自研能力等方面明确要求、目标、适用主体等，保障行业健康持续发展。参会专家结合自身企业特点、行业热点、产品安全痛点，就此次讨论标准的完整性、适用性、全面性进行了热烈讨论，为标准内容提出了许多宝贵建议。后续中国信通院将整理此次会议上专家提出的意见，牵头对标准内容进行调整和完善。</p>",
    "publish_time": "2023-02-17 16:19:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]