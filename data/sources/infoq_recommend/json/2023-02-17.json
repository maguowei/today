[
  {
    "title": "组装式专家洞察|中国移动初瑞：基于智慧中台的“组装式”探索实践",
    "url": "https://www.infoq.cn/article/c52f4adacf2e19cb093c15869",
    "summary": "<p></p><h4>引言</h4><p></p><p></p><blockquote>近期，企业数字化发展共建共享平台、云计算标准和开源推进委员会（CCSA TC608）成功举办了首次“技术前沿|“组装式”发展趋势观察沙龙”，与会专家分享了对“组装式”的探索与实践，中国移动信息技术中心智慧中台运营中心副总经理初瑞带来了《基于智慧中台的“组装式”探索实践》的主题分享。初瑞表示，中国移动作为建设网络强国、数字中国、智慧社会的主力军，紧跟组装式前沿技术发展趋势，依托智慧中台进行探索实践，在赋能企业高质量发展和数智化转型方面取得积极成效。</blockquote><p></p><p></p><h4>一、“组装式”带来技术架构和业务模式的变革</h4><p></p><p>“组装式”是近两年新出现的热门技术词汇，作为“塑造变化”的关键技术之一，将成为数字业务和创新力量的加速器。“组装式”带来的不仅仅是思维方式的变化，更是技术架构和业务模式的变革。通过封装成具有可复用、可扩展、可组装、可自治等特征的组件，充分实现资源利用率提升、业务弹性扩充。</p><p></p><h4>二、运营商在传统应用开发运维中的3个痛点</h4><p></p><p>当前数智化转型已成为各企业的必答题，数字经济和实体经济融合发展加速，不断推动制造业、服务业、农业等产业数字化，利用互联网新技术对传统产业进行全方位、全链条的改造，提高全要素生产率，发挥数字技术对经济发展的放大、叠加、倍增作用。</p><p><img src=\"https://static001.geekbang.org/infoq/04/049dea6ddc691b3ce33bf0e88fadb228.jpeg\" /></p><p>传统运营商在开发运维中存在三大痛点：第一，开发复杂度高，业务上线慢；第二，系统稳定性差，运维难度高；第三，能力复用度低，成本投入大。受“组装式”所带来的一系列新方式的启发：如组装式企业、组装式应用、组装式平台、组装式构架等，中国移动积极开展组装式的研究和推进工作。</p><p></p><h4>三、中国移动从智慧中台实践到组装式发展探索</h4><p></p><p>面对数字经济新蓝海和数智化转型新要求，中国移动将全力打造业界标杆级智慧中台，聚焦“积淀能力、支撑发展、注智赋能”总体目标，边建设、边运营、边完善，目前智慧中台已迈入“规模化发展、精细化运营”快车道。</p><p></p><p>在智慧中台的建设运营过程中，中国移动积极开展“组装式”探索实践，一是遵循“业务闭环”、“可扩展”、“互联互通”、“能力标准化”等原则，构建组装式框架和体系，从中台能力打造到中台能力应用，实现对业务创新和数智化转型过程的充分赋能；二是打造“中央厨房式”一体化开发交付环境，实现组件的集中汇聚、分级管控和灵活编排，关键业务需求的支撑响应速度提升了20%以上。</p><p></p><p>初瑞强调，在组装式研究中，无论是对组装式组件的探索，还是对组装式平台的标准化，这些组装式模块，不仅要能够被灵活组装，同时其运行时框架以及框架所依赖的技术底座也需要进行规范化。如果“组装式”能够在更大面积、更大程度上成为一种统一标准的话，可能对整个社会的发展和运行所带来的成本节省以及业务创新是我们今天所不能想象的，组装式应用的前景是不可估量的。</p><p></p><h4>四、产业生态合作未来展望</h4><p></p><p><img src=\"https://static001.geekbang.org/infoq/87/870a07e0b9bdb029731ec88b6de2cbbb.jpeg\" /></p><p>初瑞强调，为应对不断变化的业务环境和发展挑战，倡导构建“组装式”技术实践联盟，通过战略合作和技术联合，实现产业级能力整合、组件共享和价值共创。</p><p></p><p>组装式能力更有意义的地方在于，面向全部行业，甚至是整个国家，它能够实现汇集，将各领域擅长的方面进行组合，形成联合的解决方案，快速的支撑各方需求；同时，组装式还能降低门槛，一定程度上可以降低承接大项目所要的资源、人力、资本投入等方面的门槛。</p><p></p><p>组装式应用联盟未来的发展应该极大降低ToB甚至ToC这些企业进入到不同行业的门槛，所以在这个过程里面，中国移动认为外严内疏，对于整个行业来说，组装式非常值得去推进，非常有前景的发展方向。</p><p><img src=\"https://static001.geekbang.org/infoq/e9/e912fe630a336a18761cfb394003e04c.png\" /></p><p></p><p></p><p>说明：</p><p>为进一步探讨交流数字化转型相关话题，我们建立了微信群，您可添加董老师微信号，注明身份后，申请加入。</p><p>联系人：董老师&nbsp; 13810413143（微信同号）</p><p></p>",
    "publish_time": "2023-02-17 10:51:49",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "谷歌宣布支持使用Rust开发Chromium",
    "url": "https://www.infoq.cn/article/UpEHUe43yhWZaictYG0u",
    "summary": "<p></p><p>谷歌计划在其开源浏览器项目 Chromium 中支持使用第三方 Rust 库，这是对 Rust 编程语言及其安全特性的一次重大认可。</p><p></p><p>在 1 月份发布的一篇博文中，来自 Chrome 安全团队的 Dana Jansens 表示，谷歌的软件工程师已经开始致力于将 Rust 工具链应用于其构建系统。希望在年底之前将<a href=\"https://www.infoq.cn/article/z4MCCu8W62Je7d2fED7p\"> Rust 代码</a>\"包含到 Chrome 二进制文件中。</p><p></p><p>“我们将 Rust 引入 Chromium 的目标是提供一种更简单（无 IPC）且更安全（总体上包含更少的复杂 C++ 代码，同时在沙盒中也没有内存安全漏洞）的方法来满足二个原则，从而加快开发速度（需要写的代码更少、设计文档更少、安全审查更少）并且提升 Chrome 的安全性（增加了没有内存安全漏洞的代码的行数，降低了代码的错误密度）”，Jansens 解释道。</p><p></p><p>Rust 在不写成不安全的情况下，可以避免内存安全缺陷，而内存安全缺陷占 Chromium 中发现的严重安全漏洞的 70%。Rust 语言不能保证代码没有漏洞，但它可以保证潜在的缺陷要少得多。</p><p></p><p>值得一提的是，谷歌也一直致力于一种语言来提升 C++ 中的内存安全，创建者 Bjarne Stroustrup 坚称当符合 ISO C++ 标准并遵守静态分析器所强制执行的特定标准时，这种语言是内存安全的。</p><p></p><p>Jansens 感谢 Mozilla 一直支持 Rust 的开发直到它成熟并吸引了足够的外部支持来建立其自己的基础。Mozilla 长期以来一直得到谷歌的资金支持，作为回报，谷歌成为 Mozilla 的火狐浏览器的默认搜索引擎。但由于谷歌浏览器侵蚀了火狐浏览器的使用率，因此 Mozilla 正寻求其它资金来源。</p><p></p><p>Jansens 解释道，Rust 和 C++ 是 Chromium 的基础，可以通过 cxx、autocxx bindgen、cbindgen、diplomat 和 crubit 等工具进行交互。这些工具提供了一种安全的方法来从 C++ 代码调用 Rust 代码，反过来也一样。但是由于这两种语言各自的设计不同，它们之间的互操作性也存在限制。</p><p></p><p>Jansens 解释道，“例如，Rust 通过静态分析来保证临时内存安全。这个静态分析依赖两个输入：生存周期（推断或显式写入）和互斥可变性。后者与 Chromium 的大部分 C++ 的编写方式不兼容。”</p><p></p><p>Jansens 观察到，由于 Rust 和 C++ 遵循不同的规则，因此两者之间的互操作很容易出错。这就是为什么谷歌采取了一种谨慎方案的原因。</p><p></p><p>最初，谷歌想支持 C++ 到 Rust 的单项互操作性来控制依赖图的形状。Jansens 解释道，“Rust 不能依赖于 C++，因此它无法理解 C++ 类型和函数，除非通过依赖注入。这样的话，Rust 就不能在任意 C++ 代码中调用，只能在从 C++ 通过 API 传递的函数中调用。”</p><p></p><p>目前，Chromium 只能通过第三方库来暴露给 Rust。</p><p></p><p>尽管如此，随着谷歌对 crubit 等工具的开发和维护来提高 C++ 和 Rust 之间的双向互操作性，其对 Rust 的不断深化投入有望大大丰富 Rust 包生态系统。</p><p></p><p>谷歌已经将 Rust 引入安卓生态系统。微软 Azure CTO Mark Russinovich 呼吁在新项目中使用 Rust 而不是 C++。Linux 内核已经增加了 Rust 支持。甚至是不愿意使用其不能控制的技术的苹果公司都已经一直在用 Rust。®</p><p></p><p>作者介绍：</p><p></p><p>Thomas Claburn 位于旧金山湾区，为 The Register 提供软件开发、DevOps、计算机安全等服务。</p><p></p><p>原文链接：</p><p></p><p>Google polishes Chromium code with a layer of Rust（<a href=\"https://www.theregister.com/2023/01/12/google_chromium_rust%EF%BC%89\">https://www.theregister.com/2023/01/12/google_chromium_rust）</a>\"</p><p></p><p>声明：本文为 InfoQ 翻译，未经许可禁止转载。</p><p></p><p>今日好文推荐</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651156431&amp;idx=1&amp;sn=07b8156d7794c0e3d4895fb4c0991c7b&amp;chksm=bdb8979c8acf1e8aad370f504e2d64a6efcf766651c7702c786e13a8a86fc42ffb8ed2f1c75e&amp;scene=21#wechat_redirect\">18.3 万美元offer到手！ChatGPT 通过谷歌 L3 面试：留给谷歌的时间不多了</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651156320&amp;idx=1&amp;sn=8de49e53191865d9d4ed7801cfb6642f&amp;chksm=bdb897338acf1e25a4874f147dae16c1ad31851865ccf8be190998cfe925c77359b63cbb1b92&amp;scene=21#wechat_redirect\">我被微服务坑掉了CTO职位</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651156319&amp;idx=1&amp;sn=c3d54a533ea4bd913145f08097492181&amp;chksm=bdb8970c8acf1e1a9dfd72d843a59d2eae113547f48cedbcaad4c76e8faf4561311fe1f8df65&amp;scene=21#wechat_redirect\">微信全面支持“小号”；员工购买公司福利房，被裁员后遭巨额索赔；16岁少年孤身前往深圳腾讯总部解封QQ账号｜Q资讯</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651156129&amp;idx=1&amp;sn=c41a83236635ded0db3a9d45048da15f&amp;chksm=bdb896f28acf1fe4b2f98c5d0ef4b18293debf7d7907dbc5fa13869f457b21f9cf9f010ca284&amp;scene=21#wechat_redirect\">现代软件越来越大、越来越慢、越来越烂！还有救吗？</a>\"</p><p></p><p></p><p></p>",
    "publish_time": "2023-02-17 11:02:43",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "掀起云基础设施管理革命的IfC",
    "url": "https://www.infoq.cn/article/pxj6qAcsVXkGZ9zHIV4j",
    "summary": "<p><a href=\"https://klo.dev/state-of-infrastructure-from-code-2023/\">基于代码基础设施（Infrastructure-from-Code，IfC）</a>\"是一种创建、配置和管理云资源的方法，它理解软件应用程序的源代码，而无需明确的描述。Infra-from-Code有四种主要的方法：基于SDK的、基于代码注解的、基于两者组合的，以及一种明确定义基础设施的新编程语言。</p><p>&nbsp;</p><p>基于SDK的方法允许开发人员使用他们的代码，并且在部署时，这些工具会分析服务代码如何使用SDK并生成基础设施。基于SDK的方法使得根据代码推断使用情况更加可预测，但在利用新的云特性方面，SDK总是落后一步。基于SDK工具的示例有<a href=\"https://getampt.com/\">Ampt</a>\"和<a href=\"https://nitric.io/\">Nitric</a>\"。</p><p>&nbsp;</p><p><code lang=\"null\">import { api } from '@nitric/sdk';\n\n\nconst helloApi = api('main');\n\n\nhelloApi.get('hello/:name', async(ctx) =&gt; {\n    const {name} = ctx.req.params;\n    ctx.res.body = 'Hello ${name}';\n})</code></p><p>向互联网公开端点的Nitric示例</p><p>&nbsp;</p><p>纯注解方法是仅基于代码内注解的。这种方法侧重于理解开发人员对框架和工具的使用。这种方法的主要工具是<a href=\"https://klo.dev/\">Klotho</a>\"，它更像是一种基于代码架构（Architecture-from-code）的工具。Klotho引入了诸如 expose 、 persistent 和 static_unit 等功能（关键注解），这些功能可以使现有编程语言成为云原生语言。</p><p>&nbsp;</p><p><code lang=\"null\">const redis = require(\"redis\");\n/**\n* @klotho:persist{\n*   id = \"UserDB\" \n*}\n*/\n\n\nconst client = redis.createClient();</code></p><p>Redis客户端持久化数据的Klotho示例</p><p>&nbsp;</p><p>使用注解和SDK方法，开发人员可以对代码进行注解，工具可以将这些注解和SDK结合到框架中。该类别的主要工具是<a href=\"https://encore.dev/\">Encore</a>\"和<a href=\"https://www.shuttle.rs/\">Shuttle</a>\"。这些工具可以托管在IfC供应商的平台上，也可以与GCP、AWS或Azure等第三方云提供商集成。另一个有趣的工具是AWS <a href=\"https://github.com/aws/chalice\">Chalice</a>\"，它允许创建和部署在Python中使用AWS Lambda的应用程序。</p><p>&nbsp;</p><p><code lang=\"null\">// encore:api public method=POST path=/url\nfunc Shorten(ctx context.Context, p *ShortenParams)(*URL, error){\n    id, err := generateID()\n    if err != nil {\n       return nil, err\n    }\n    return &amp;URL(ID: id, URL: p.URL), nil\n}</code></p><p>API请求/响应的Encore示例。注释指定了URL路径</p><p>&nbsp;</p><p>基于语言的方法引入了旨在以云为中心的新编程语言。<a href=\"https://www.winglang.io/\">Wing</a>\"和<a href=\"https://darklang.com/\">DarkLang</a>\"是最常用的两种编程语言。这种方法允许在现有编程语言中引入难以实现的概念。每种新的编程语言都有一些权衡：软件开发人员需要首先学习它，然后将其集成到现有的工具和服务中。此外，寻找和雇用具有新编程语言专业知识的开发人员可能也需要时间和精力。</p><p>&nbsp;</p><p><code lang=\"null\">bring cloud;\n\n\nlet bucket = new cloud.Bucket();\n\n\nnew cloud.Function(inflight (_: str): str =&gt; {\n    bucket.put(\"hello.txt\",\"world\");\n}</code></p><p>云函数定义的Wing示例</p><p>&nbsp;</p><p><a href=\"https://www.chef.io/products/chef-infra\">Chef</a>\"、<a href=\"https://www.ansible.com/\">Ansible</a>\"、<a href=\"https://www.puppet.com/\">Puppet</a>\"和<a href=\"https://www.terraform.io/\">Terraform</a>\"是<a href=\"https://en.wikipedia.org/wiki/Infrastructure_as_code\">基础设施即代码</a>\"（&nbsp;Infrastructure-as-Code，IaC）的首批工具，并开始支持云基础设施的创建和管理。第二批IaC使用现有的编程语言（Python、Go、TypeScript）来表达与第一批工具相同的想法。<a href=\"https://www.pulumi.com/\">Pulumi</a>\"和<a href=\"https://github.com/aws/aws-cdk\">CDK</a>\"是第二代工具。</p><p>&nbsp;</p><p>有关基于代码基础设施现状的更多详细信息，请阅读Klotho的2023<a href=\"https://klo.dev/state-of-infrastructure-from-code-2023/\">基于代码基础设施状况</a>\"报告。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/01/google-gitops-observability/\">https://www.infoq.com/news/2023/01/google-gitops-observability/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://xie.infoq.cn/article/b3068ba053dfd72cc36743d3b\">面向分布式云原生 构筑无处不在的云原生基础设施</a>\"</p><p><a href=\"https://www.infoq.cn/article/oi5qfvo5NUCHeZScpaib\">揭秘 Meta 的云游戏基础设施</a>\"</p><p><a href=\"https://www.infoq.cn/article/HXgMpZwrxmhGU2DyWE9M\">SaaS 初创公司如何选择合适的云基础设施</a>\"</p>",
    "publish_time": "2023-02-17 11:19:18",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "经历亿级话单处理优化打磨检验，江苏移动云流一体化到底如何玩转",
    "url": "https://www.infoq.cn/article/dNr1QRTdsDeawLLHIIeA",
    "summary": "<p></p><p>作者 ｜王娟</p><p></p><p>中国移动通信集团江苏有限公司（后文统一简称为江苏移动）是省内规模最大的通信运营商，公司计费用户数近 2 亿，日均话单量超 200 亿。其业务支撑系统包含话单计费、账务处理、服务开通等多个业务场景。</p><p></p><p>近期，江苏移动引入 Apache Pulsar 等流原生新技术，结合云原生技术体系，完成了基于流云一体化架构的新一代业务支撑系统全面升级，实现了支撑系统在云原生时代新的演进。面对 5G+ 时代的新挑战，新一代业务支撑系统打造了全新支撑架构，通过跨系统间的资源融合、能力融智、数据融通，实现规模化、敏捷化、智能化、弹性化、自主可控的支撑目标，有效助力公司业务支撑效能提升。本文将介绍江苏移动核心支撑系统面临的挑战与应对挑战的系统演进措施，以及如何结合 Apache Pulsar、Ignite 和 SkyWalking 等分布式云原生系统提高开发效率并实现智能运维与运营。</p><p></p><p></p><h2>面临三大挑战</h2><p></p><p></p><p>随着市场竞争加剧，业务需求越来越个性化，江苏移动的核心支撑系统面临诸多挑战。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f2/f28b7aa9c2a93aa3f33863cbc1729bcf.png\" /></p><p></p><p>系统性能面临瓶颈</p><p></p><p>近几年流量业务呈爆发性增长。江苏省用户日均流量从数百 TB 增长到数万 TB，话单量、消息量增长，计费系统压力大幅增加。每天近百亿的话单、数十亿的消息对共享文件存储的依赖极高，NAS 逐渐出现 I/O 瓶颈，计费系统无法线性扩展。同时终端用户对提醒的及时性要求越来越高，提醒不及时极易引起用户投诉。</p><p></p><p>需求开发面对挑战</p><p></p><p>随着市场竞争的加剧，业务部门对需求交付的时间要求越来越短。现有 BOSS 系统架构越来越复杂，很多功能模块变得十分庞大，业务研发难以做到同时跟进，交付速度跟不上业务要求。</p><p></p><p>系统运维愈加复杂</p><p></p><p>随着 BOSS 系统的演进，多地多中心、多云混合的环境已经变成标配，增加了系统的复杂性，大大提高了运维的难度。</p><p></p><p></p><h2>演进措施</h2><p></p><p></p><p>面对上述挑战，江苏移动采取多项措施，进行针对性解决。通过引入微服务架构、Pulsar 消息平台、分布式内存库 Ignite、云原生架构，提升系统性能、提高开发效率、减轻运维压力。同时通过 PaaS 平台对资源进行的统一管理、调度，BOSS 系统的应用全部运行在 PaaS 平台上，部署、更新使用平台提供的运维工具，有效提升了整体的资源利用率。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3f/3f724f11132bccc394eb131961147fcb.png\" /></p><p></p><p></p><h3>设计目标</h3><p></p><p></p><p>应对业务需求，计费系统技术架构需要具备四大特性：强一致、高性能、高可用、高可靠。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a5/a59052caf9440c6de1cfb8aeba5ce6b0.png\" /></p><p></p><p>强一致</p><p></p><p>计费系统承载用户数近 2 亿，语音、短信、流量等业务日均话单量超 200 亿条，在海量的话单批价规模下，如何确保费用计算零差错，实现强一致性，是计费的最核心问题。</p><p></p><p>高性能</p><p></p><p>计费流程在忙时话单数量以数十倍突发，瞬间峰值超百万 TPS，因此计费系统需要具备很高的处理性能。</p><p></p><p>高可用</p><p></p><p>计费系统必须具备很强的业务容灾和数据容灾能力，有充分的弹性和容错设计，来保证 7*24 高可用。高可靠在数据存储层，只要话单处理成功就表示数据一定完成落盘，发生如操作系统崩溃、网络异常、磁盘异常等意外宕机时必须能够确保数据不丢；同时，针对分布式任何节点的故障，引发的主机数据损坏等问题，要求系统数据严格不错不丢。</p><p></p><p></p><h3>架构概述</h3><p></p><p></p><p></p><h4>提高开发效率</h4><p></p><p></p><p>为了支持以上技术要求，江苏移动在系统演进中做了针对性的架构设计与开发。</p><p></p><p>Serverless 构架</p><p></p><p>在新一代计费系统中引入 Serverless 架构，函数计算与 PaaS 平台为计费系统 Serverless 化提供应用引擎。在 BaaS 服务层，存储服务、应用监控、日志、数据库、内存库、消息等产品不断向 Serverless 化演进。基于 Serverless 架构计费系统可以根据语音、短信、GPRS 业务的话单流量波动，自动进行资源的分配和销毁，并最大程度化地平衡稳定性、高性能、提升资源利用率。计费系统开发追求完全自动的自适应分配的核心目标：更快地实现业务逻辑，减少在环境搭建和系统连接上的开发时间，将更多的时间聚焦在业务开发上。</p><p></p><p>微服务化</p><p></p><p>为实现系统高可用与业务功能快速扩展，新一代计费系统对应用进行了全面的微服务化改造，即微服务化设计。按照不同业务域的功能需求，通过合理的功能拆分，精细化的服务治理，如：服务的注册、发现、熔断、自愈、负载均衡、链路跟踪等实现功能的快速扩展和流量的高效调度，以此达成整体系统的高可伸缩。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/9a/9a14a1b3ffeeffee4e40819381570fa5.png\" /></p><p></p><p>流程编排</p><p></p><p>计费批价模块采用 Dubbo 作为微服务框架，在自主研发的 SNF 消息处理框架中集成 Pulsar 消费者中读取话单消息，通过 Dubbo 消费者调用 Dubbo 服务提供者的业务处理能力，完成话单批价的业务流程。在批价模块中支持流程编排能力，可按照业务需求动态调整流程的处理逻辑。批价完成后，批价成功的话单消息通过 Pulsar 生产者发送至下游模块并提交偏移量，批价失败的话单消息写入重试和死信队列，等待后续处理。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e4/e4debbf4153e2527ff45bf71cf4eb8ab.png\" /></p><p></p><p>流程编排通过可视化界面提供节点拖拽的效果，批价模块根据定义的流程模型执行不同的业务处理逻辑</p><p></p><p>分布式配置中心</p><p></p><p>通过引入 Disconf 配置中心，实现业务应用配置发布、更新统一化，配置更新自动化，并提供操作简易的控制台，方便管理配置版本及配置文件。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f9/f9aeb7469959f8c0fef6ac9ac1993723.png\" /></p><p></p><p>幂等性</p><p></p><p>Pulsar 作为一个可靠的消息中间件，只要消息成功投递到了 Pulsar 中就不会丢失，至少保证消息能被消费者成功消费一次，即“At Least Once”至少一次语义。然而这种可靠的特性在异常的场景下会导致消息可能被多次投递，造成消息重复处理。如：</p><p></p><p>在消息消费的场景下，消息已投递到消费者并完成业务处理，当消费者给 Pulsar Broker 端反馈应答的时候网络闪断。为了保证消息至少被消费一次，Pulsar 将在网络恢复后再次尝试投递之前已被处理过的消息或将消息投递给同一消费组内的其他消费者来处理，同一条消息在同一个消费组内会被处理两次。Pulsar Broker 负载均衡时消息重复，包括但不限于网络抖动、Broker 重启以及消费者应用重启，当 Pulsar Broker 或客户端重启、扩容或缩容时，会触发 Rebalance，此时消费者可能会收到重复消息。</p><p></p><p>但是，计费系统要求话单处理达到 100% 的正确性。因此，计费系统在消费逻辑上需要自我实现幂等性，探索出一个通用的消息幂等的方法，从而抽象出一个通用的框架用以适用各个业务的场景，达到“Exactly Once”有且仅有一次语义的目标。</p><p></p><p>计费消息幂等性引入了 Ignite 内存库作为存储介质，基于 Ingite EP 天然的事务原子性操作实现幂等。核心就是在 Pulsar 消费者接收到消息之后，根据话单构建的唯一标识在 Ignite 中查重，如果已经消费过，则直接提交偏移量；如果没有，则进行业务操作，并在业务处理成功之后将话单唯一标识写入 Ignite，防止重复消费。同时，存储在 Ingite 中的缓存数据，可以直接利用 Ignite 的 TTL 特性实现数据的自动清理，释放内存库资源。</p><p></p><p>顺序消息</p><p></p><p>服务开通系统要求消息按照严格的顺序消费，如服务开通接收到 CRM 的先停机后复机的工单指令，在业务处理时必须严格按照先停机后复机的顺序执行。如果先复机后停机，必然会造成用户的投诉。目前大部分 MQ 支持两种顺序模式，一种是全局有序，要求 Topic 只能有一个 Partition，对生产和消费的并行度有较大的限制；另一种是局部有序，保证 Message 中 Key 的有序生产和消费，例如用户 ID，这也是业务场景使用最多的一种方式。Kafka 和 RocketMQ 采用的是第二种种形式，通过将相同的消息 Key 路由到相同的 Partition 中，单个 Partition 的消息只能被同一个消费者消费。但是在消息量非常大的情况下，系统会出现性能瓶颈，因为相同消费组的消费者个数受限于 Partition 的个数。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/81/819e253b6c0b0121ce085d359bd61e62.png\" /></p><p></p><p>Pulsar 的 Key_Shared 模式可以很好地解决这个问题，消费者的消息按照 Key 分配，因此 Key 的分散度越高，消费者的并发度越高，系统的吞吐量也就越高。新一代服务开通系统基于 Pulsar Key_Shared 特性实现消息顺序消费，使相同 Key 的消息被路由到同一消费者上处理，同 Key 的消息经过业务处理后批量更新至目标存储上，在保证消息的顺序性消费的同时提升系统的性能。</p><p></p><p></p><h4>追踪与监控：Pulsar+Log4j2+Skywalking 等</h4><p></p><p></p><p>随着业务规模的增长，计费系统应用的实例数规模不断增长，核心业务的依赖也变得愈加复杂，开发效率提升的同时故障定位成本也居高不下，特别是当业务出现问题的时候，如何快速完成故障定位成为新的挑战。</p><p></p><p>计费系统的可观测性按照指标、日志、链路追踪进行分类，围绕 Prometheus 服务、Grafana 服务和链路追踪服务，形成指标存储分析、链路存储分析、异构数据源集成的可观测数据层，通过标准的 PromQL 和 SQL 提供数据大盘展示、告警和数据探索能力，达成全面覆盖业务观测 / 应用层观测 / 中间件观测 / 系统层观测的目标。</p><p></p><p>指标</p><p></p><p>Pulsar 原生的指标包含集群总览、消息、Topic、组件 JVM、Bookie 等多项指标。基于 Pulsar 原生的监控能力，江苏移动自主研发 Pulsar Exporter 组件，基于 Spring-boot 框架调用 Pulsar Rest API 和 JMX 指标服务接口，提供扩展 Pulsar 自定义指标的能力，如集群健康状态、磁盘使用率、追单性能、延迟消费等指标，满足计费系统复杂的业务场景和个性化的监控需求。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f1/f115b94c079bab6fb229028033000bde.jpeg\" /></p><p></p><p>集群总览</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/80/80b676d8de57ed7ab5120128cdcab472.jpeg\" /></p><p></p><p>批价追单性能</p><p></p><p>日志</p><p></p><p>Pulsar 集群的多个组件 ZooKeeper、Bookie、Broker、Functions Worker 和 Proxy 以分布式的方式部署在多台主机上，因此每个组件的日志文件也分散在多台主机上。当组件出现问题时，由于日志比较分散，我们希望通过对日志进行聚合、监控，能够快速地找到 Pulsar 各个服务的报错信息并排查，使得运维更加具有目的性、针对性和直接性。为了解决日志检索的问题，计费系统采用集中式日志收集系统，对 Pulsar 所有节点上的日志统一收集、管理和访问。</p><p></p><p>传统的日志采集必须以文件的方式落一次磁盘，缺点是占用了主机磁盘的 IO。为此，在计费系统中 Pulsar 集群基于 Log4j2+Kafka+ELK 实现日志的快速检索。Log4j2 默认支持将日志发送到 Kafka，使用 Kafka 自带的 Log4j2Appender 在 Log4j2 配置文件中进行相应的配置，即可完成将 Log4j2 产生的日志实时发送至 Kafka 中。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/06/06ff8536075400b1f81befbdd32116d2.png\" /></p><p></p><p>Elasticsearch 根据检索字段进行分词，并创建索引。Pulsar 的日志建立了 8 个检索字段，分别是：集群名、主机名、主机 IP、组件名、日志内容、系统时间、日志级别、集群实例。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/63/63be1bc6b8519db132c1ce38a4a89322.png\" /></p><p></p><p>在 Kibana 页面，根据分词的字段指定查询条件进行检索。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/37/375981d2d74e31c36fc4b0390e16aa47.jpeg\" /></p><p></p><p>借助 Pulsar SQL，计费系统使用 Pulsar 作为消息总线的同时，支持追踪回溯话单消息，能够动态查询存储在 Pulsar 内部的实时消息，并支持从外部系统提取数据，与 Pulsar 中的话单消息多维聚合分析，以图表的方式输出统计结果。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/49/4904276702d73a05587a639164728b3a.jpeg\" /></p><p></p><p>Pulsar SQL 支持以 JDBC 的方式访问持久化在 Topic 中的话单消息，运维智能分析系统基于 Java SQL 语言结合查询条件、时间范围等进行查询，并实时输出分析结果。</p><p></p><p>消息链路追踪</p><p></p><p>计费系统使用 Skywalking 分布式系统性能监视工具对话单消息进行链路追踪和性能监控。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/43/43ac28599603eee0e5557ce94b3dfb5f.png\" /></p><p></p><p>在计费系统的所有环节中集成 Pulsar 的生产者和消费者，在启动模块的应用程序时，使用 Skywalking 的 JavaAgent 探针埋入 Java 程序中，用于收集应用程序和 Topic 中话单消息的指标数据。</p><p></p><p>通过 Trace 机制，追踪话单消息在 Pulsar 集群中一次全链路调用的完整记录，实现话单消息处理的可观测性。Trace 由所有环节的 Span 组成，每个 Span 使用 APM 插件在 Pulsar 生产者的拦截器上设置 Pulsar 的 Brokers URL 列表、Topic 名称、消息 ID 等 Tag，在 Pulsar 消费者的拦截器上设置 Pulsar 的 Brokers URL 列表、Topic 名称、消息 ID、订阅者名称等 Tag，用于记录应用节点中的关键信息。</p><p></p><p>话单消息在同一个消费者模块中，业务处理异常重新消费时需要使用 Pulsar 消息系统的重试和死信队列的特性，并使用 Skywalking 监控每条话单在同一个 Topic 和同一个订阅中的重试消费的次数和详情，用于观测话单处理的原因和执行链路的流转。</p><p></p><p>Skywalking 在追踪话单消息在 Pulsar 集群中的链路执行情况的同时，会采集话单消息在计费系统的每个模块中的性能指标，通过 Skywalking Analysis Core 分析聚合之后，在 Skywalking UI 上查看话单链路和指标数据。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3e/3e005977c322a2df3d827b2d54a95df7.jpeg\" /></p><p></p><p>以上一套完整的可观测解决方案可以为计费系统提供高效运维、业务连续性保障的能力。</p><p></p><p></p><h4>精细化管控与应用云化</h4><p></p><p></p><p>计费系统按照多层次业务隔离来完善系统精细化管理控制。通过 Pulsar 多租户、Namespace、Topic 分层特性来实现物理架构部署的分系统、分业务、分地市多级别隔离，实现硬件资源复用、逻辑数据隔离、业务互不影响，使得系统控制力度从地市级升级到业务级，组件、应用集群全高可用部署：</p><p></p><p>通过多租户区分系统：计费、账务、服务、信控等；通过 Namespace 区分业务：高清语音、物联网、行业网关、流量等；通过 Topic 区分地市：苏州、南京、泰州等。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/1b/1bec2e478769045401327f0b1462964d.png\" /></p><p></p><p>计费系统的所有应用全面云化，计算资源通过 PaaS 动态调度、弹性伸缩，按需控制系统处理能力，实现整体开发成本和硬件投入的节约。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ba/ba593d7b8e9af52383b403ab72170f2e.jpeg\" /></p><p></p><p></p><h2>未来展望</h2><p></p><p></p><p>未来江苏移动将在现有架构的基础上，进一步结合算力网络构建云边一体化的计费系统。通过计费策略的智能决策、系统资源的精细控制、业务服务的高效执行以及运营状态的全景洞察，满足未来差异化用户服务需求，有效提升系统的处理能力、开放能力和运营能力。</p><p></p><p></p><blockquote>注：文档中的全部内容属中国移动通信集团江苏有限公司所有。未经允许，不可全部或部分发表、复制、使用于任何目的。</blockquote><p></p><p></p><p>作者简介：</p><p></p><p>王娟，江苏移动计费专家，负责 BOSS 计费系统的架构演进和维护。面对 5G+ 时代的新挑战，她将 Apache Pulsar 引入公司 IT 业务支撑系统，致力于打造新一代高效智能的计费架构，助力公司 IT 支撑效能提升。</p><p></p><p>今日好文推荐</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651156830&amp;idx=1&amp;sn=1388ad34d6acaa55714d6476ff055de4&amp;chksm=bdb8890d8acf001bc24a5c7b80893e6dc8a85250e0ac289ca12cfc5f67dc8dc32f515b026533&amp;scene=21#wechat_redirect\"></a>\"<a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651156919&amp;idx=1&amp;sn=3ed2dd72d55e4c978f189f770cf1022a&amp;chksm=bdb889e48acf00f23c2c148912b1b60a45b534e181abb376afc72c055572b177c4492cefdd6d&amp;scene=21#wechat_redirect\">GitHub裁员10%，办公室全关，全体远程办公；微软必应集成ChatGPT下载量猛增10倍；谷歌出师不利市值蒸发超万亿｜Q资讯</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651156830&amp;idx=1&amp;sn=1388ad34d6acaa55714d6476ff055de4&amp;chksm=bdb8890d8acf001bc24a5c7b80893e6dc8a85250e0ac289ca12cfc5f67dc8dc32f515b026533&amp;scene=21#wechat_redirect\">马斯克开会当场解雇Twitter首席工程师：我有1亿多粉丝，他却说公众对我失去兴趣</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651156705&amp;idx=1&amp;sn=f7e6e01de4763afc61a83a35dd3901ae&amp;chksm=bdb888b28acf01a4b4443c5e09eac7a54f591ac6b96937ec6c45008203598a721b8c1f73d4f3&amp;scene=21#wechat_redirect\">15年做不好的代码搜索，用Rust重写搞定：GitHub声称能从此“改变游戏规则”</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651156618&amp;idx=1&amp;sn=a8e0585cbb0f4d580957ab598129625b&amp;chksm=bdb888d98acf01cf69cd221c048833497157edfc13ed2de5e55cd0f28acf1234e732b38a8fcf&amp;scene=21#wechat_redirect\">搜索引擎技术大战，始于今日</a>\"</p><p></p><p></p><p></p>",
    "publish_time": "2023-02-17 11:33:20",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Shopify为系统编程提供Rust",
    "url": "https://www.infoq.cn/article/hLu8pCjMkwFz4HYyLAWT",
    "summary": "<p></p><p>Shopify 为商业构建互联网基础设施，以满足数百万商家的需求。为了做到这一点，需要构建灵活的业务逻辑和健壮的高性能系统。除了我们对 Ruby 的灵活性和表现力的承诺之外，我们最近还<a href=\"https://www.infoq.cn/article/hioW21XT8opvbip3hs5F\">采用了 Rust </a>\"作为我们官方的系统编程语言。作为这项工作的一部分，我们加入了 Rust 基金会，并且我们很高兴能加入 Rust 社区。</p><p></p><p>系统编程是软件工程中的一个要求很高的领域，为其选择的语言将会对系统软件的成功和有效性产生巨大的影响。用于解决这些问题的语言需要快速、高效且安全。此外，如果可能，Shopify 更喜欢社区驱动的开源项目。</p><p></p><p>Rust 不断增长的行业势头和 Shopify 不断扩大的系统编程项目基础，使我们在 Rust 上进行标准化并加入 Rust 基金会正当其时。</p><p></p><p></p><h2>Shopify 的系统编程</h2><p></p><p></p><p>自成立以来，Shopify 的主要服务端应用程序编程语言一直是 Ruby。Ruby 的灵活性和表现力使 Shopify 能够开发出强大的商务系统，满足数百万商家以及数亿买家的需求。Ruby 过去是，现在是，将来依然是我们构建现代商务服务端组件时的首选工具。</p><p></p><p>对于系统编程，例如高性能网络服务器或使用“原生”代码扩展 Ruby，而不是定义业务逻辑，Shopify 开发人员过去一直使用 C 和 Go 等语言。最近，我们决定将 Rust 标准化为我们的系统编程语言。因此，我们正致力于在开发和部署流程中更好地支持 Rust，并帮助 Shopify 工程师开发 Rust 编程方面的专业知识。</p><p></p><p></p><h2>为什么选择 Rust？</h2><p></p><p></p><p>Rust 的许多方面使它成为我们系统编程语言的一个有吸引力的选择。这些因素结合起来使我们相信 Rust 将会成为我们软件堆栈中一个强大且受欢迎的组件。其他公司可能会对语言的不同属性进行不同的权衡，做出不同的选择；我们的评估最终使我们选择了 Rust。</p><p></p><p></p><h3>一致性</h3><p></p><p></p><p>Shopify 的系统编程需要涵盖多个领域，而且随着时间的推移，这个数字可能会增加。它们包括高性能服务器、用于提高性能或桥接到其他库的 Ruby 扩展，以及编译为 WebAssembly。我们非常希望将对单一语言的投资运用到众多领域，这意味着要确定一种可以非常灵活使用的语言。相关类型的系统编程将对组织的语言选择产生重大影响；我们需要对此有更宽泛的视角。</p><p></p><p></p><h3>性能</h3><p></p><p></p><p>Shopify 需要能够高效且可持续地扩缩，以支持全球商业。Rust 为我们提供了可预测的原生代码性能，包括对内存使用的精细控制，这使其适用于我们堆栈的最低级别。当然，Rust 并不是唯一能够提供或接近这种性能的语言。在此基础上，还可以考虑使用现代 C++，或者如果可以接受垃圾收集器的分配行为和性能的话，则可以考虑 Go。</p><p></p><p>当然，虽然 Rust 具有很高的性能上限，但它本质上并没有提高性能下限。一个应用程序或组件并不会因为它是用 Rust 编写的就神奇地快；程序员仍然需要设计和衡量性能，我们需要确保 Shopify 的 Rust 开发人员拥有必要的工具来轻松完成这项工作。随着我们与 Rust 及其社区的合作，这种支持将成为 Shopify 感兴趣的一个重要领域。</p><p></p><p></p><h3>社区</h3><p></p><p></p><p>Rust 语言和生态系统是由一个健康的社区驱动的，我们打算像参与 Ruby、 Rails、 React Native 和其他开源项目一样参与这个社区。Rust 的 RFC 流程和治理架构为包容且深思熟虑的讨论提供了坚实的基础，从而推动了语言和工具的未来发展。希望我们的贡献不仅能使 Rust 在 Shopify 的使用中变得更加高效，而且还能为所有 Rust 开发人员带来改进。</p><p></p><p>这就是 Shopify 加入 Rust 基金会的原因。我们希望支持 Rust 优秀的治理模式和“Rust 公地”的维护，并将我们的知识和观点带入到更大的 Rust 对话中。Rust 基金会为确保 Rust 社区和生态系统的健康所做的工作至关重要，我们非常自豪能够参与他们的使命。</p><p></p><p></p><h3>生产力</h3><p></p><p></p><p>在某些圈子里，Rust 以难以学习和使用而闻名，但 Shopify 内部和外部的开发人员发现，在通过了最初的学习阶段之后，他们可以非常高效且轻松地使用 Rust 进行构建。Rust 还有一个强大的库生态系统（“板条箱”）和良好的 IDE 集成工具，当然还有非常好的编译器错误消息。类型和宏系统的强大功能允许非常有表现力的 API 和语法，将开发人员的精力集中在表达他们的思想上，而不是在头脑中摆弄大量的状态和不变量。Go 在这方面也享有盛誉，C 和 C++ 就没那么好了。</p><p></p><p></p><h3>安全性</h3><p></p><p></p><p>Rust 提供了许多让编译器来帮助确保程序正确的工具，包括它们可以安全地管理内存，并且可以“无所畏惧地并行”。随着我们越来越熟练地使用 Rust，我们将会找到更多的方法来使用 Rust 的类型系统和安全规则来保持系统中的不变量。从我们最初的项目中，我们发现与我们评估的其他语言相比，Rust 会在编译时而不是运行时暴露出更多的错误。这促成了 Rust 开发人员经常表达的“有信心部署”情绪。</p><p></p><p>在我们所考虑的所有语言中，Rust 在安全因素方面遥遥领先：不仅是在生命周期管理方面的内存安全上，它还消除了并行程序中的大多数数据竞争。当然，即使是 Rust，它也有改进的空间，例如静态死锁预防，但所有生产语言都是如此。我们相信 Rust 对静态安全性的承诺会使其最有可能在未来几年中实现这一目标。在这个领域已经有了一些有趣的工作，例如 Ferrocene。</p><p></p><p></p><h3>互操作性</h3><p></p><p></p><p>系统编程通常涉及到与现有的“原生”库（比如用 C 编写的库）的接口。与 Go 不同的是，Rust 没有垃圾收集器，这使得它可以更容易地插入到可以使用 C 的任何地方。更具体地说，Rust 很好地支持了使用 bindgen 等工具与现有的 C 代码的集成，而像 rb-sys 和 magnus 这样的板条箱允许 Rust 安全地与 Ruby 互操作。C++ 的集成仍然有些笨拙，但像 cxx 这样的板条箱可以帮助弥合语言障碍。除了 RubyVM 本身之外，我们没有大型的 C 或 C++ 代码库，但这种互操作对我们来说仍然是一个重要的考虑因素。</p><p></p><p></p><h2>接下来做什么?</h2><p></p><p></p><p>在 Shopify，我们的 Rust 之旅才刚刚开始。我们需要开发教育资源和内部工具，并学习如何最好地参与 Rust 社区和生态系统。我们很高兴能成为 Rust 使命的一部分，让每个人都能构建可持续的、内存安全的、高效的软件，并感谢 Rust 基金会的欢迎加入。</p><p></p><p></p><blockquote>Mike Shaver 是 Shopify 核心工程的杰出工程师。</blockquote><p></p><p></p><p>如果你对从头开始构建系统来解决现实世界中的问题感兴趣，我们的工程博客中有关于我们遇到的其他挑战故事。访问我们的工程职业位页面，了解我们的空缺职位。加入我们的远程团队，可以（几乎）在任何地方工作。了解我们是如何通过招聘来共同设计未来的——一个通过设计实现数字化的未来。</p><p></p><p>原文链接：</p><p></p><p><a href=\"https://shopify.engineering/shopify-rust-systems-programming\">https://shopify.engineering/shopify-rust-systems-programming</a>\"</p><p></p><p>声明：本文为 InfoQ 翻译，未经许可禁止转载。</p><p></p><p>今日好文推荐</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651156431&amp;idx=1&amp;sn=07b8156d7794c0e3d4895fb4c0991c7b&amp;chksm=bdb8979c8acf1e8aad370f504e2d64a6efcf766651c7702c786e13a8a86fc42ffb8ed2f1c75e&amp;scene=21#wechat_redirect\">18.3 万美元offer到手！ChatGPT 通过谷歌 L3 面试：留给谷歌的时间不多了</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651156320&amp;idx=1&amp;sn=8de49e53191865d9d4ed7801cfb6642f&amp;chksm=bdb897338acf1e25a4874f147dae16c1ad31851865ccf8be190998cfe925c77359b63cbb1b92&amp;scene=21#wechat_redirect\">我被微服务坑掉了CTO职位</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651156319&amp;idx=1&amp;sn=c3d54a533ea4bd913145f08097492181&amp;chksm=bdb8970c8acf1e1a9dfd72d843a59d2eae113547f48cedbcaad4c76e8faf4561311fe1f8df65&amp;scene=21#wechat_redirect\">微信全面支持“小号”；员工购买公司福利房，被裁员后遭巨额索赔；16岁少年孤身前往深圳腾讯总部解封QQ账号｜Q资讯</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651156129&amp;idx=1&amp;sn=c41a83236635ded0db3a9d45048da15f&amp;chksm=bdb896f28acf1fe4b2f98c5d0ef4b18293debf7d7907dbc5fa13869f457b21f9cf9f010ca284&amp;scene=21#wechat_redirect\">现代软件越来越大、越来越慢、越来越烂！还有救吗？</a>\"</p><p></p><p></p><p></p>",
    "publish_time": "2023-02-17 11:51:33",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Serverless Streaming：毫秒级流式大文件处理探秘",
    "url": "https://www.infoq.cn/article/25z7Wv4OPKI6dJv0ALZB",
    "summary": "<p>点击查看Serverless系列文章：</p><p><a href=\"https://www.infoq.cn/article/e4ly6UcN93KApvKGzUCK\">Serverless 时代的微服务开发指南：华为云提出七大实践新标准</a>\"</p><p><a href=\"https://www.infoq.cn/article/bdczHWk9LxuOC9GrVToL\">华为云发布冷启动加速解决方案：助力 Serverless 计算速度提升 90%+</a>\"</p><p></p><p>旧浪 | 华为云 Serverless 研发专家</p><p>平山 | 华为云中间件 Serverless 负责人</p><p></p><h2>背景</h2><p></p><p></p><p>企业应用从微服务架构向 Serverless（无服务器）架构演进，开启了无服务器时代，面向无服务器计算领域的 Serverless 工作流也应运而生。许多 Serverless 应用程序不是由单个事件触发的简单函数，而是由一系列函数多个步骤组成的，而函数在不同步骤中由不同事件触发。Serverless 工作流用于将函数编排为协调的微服务应用程序。</p><p></p><p>Serverless 工作流由于自身可编排、有状态、持久化、可视化监控、异常处理、云服务集成等特性，适用于很多应用场景，比如：</p><p></p><p>复杂度高需要抽象的业务（订单管理，CRM 等）业务需要自动中断 / 恢复能力，如多个任务之间需要人工干预的场景（人工审批，部署流水线等）业务需要手动中断 / 恢复（数据备份 / 恢复等）需要详细监控任务执行状态的场景流式处理（日志分析，图片 / 视频处理等）</p><p></p><p>当前大部分 Serverless Workflow 平台更多关注控制流程的编排，忽视了工作流中数据流的编排和高效传输，上述场景 1-4 中，由于数据流相对简单，所以各大平台支持都比较好，但是对于文件转码等存在超大数据流的场景，当前各大平台没有给出很好的解决方案。华为云 FunctionGraph 函数工作流针对该场景，提出了 Serverless Streaming 的流式处理方案，支持毫秒级响应文件处理。本文将以图片处理的场景作为例子详细描述当前的问题以及华为云 FunctionGraph 函数工作流在面对该问题时采取的一系列实践。</p><p></p><p></p><h2>问题描述</h2><p></p><p></p><p>先以一个图片处理的场景举例，用户想要执行一个图片压缩并且加水印的任务，这个场景在典型的工作流系统中，可以用如图一所示的方式进行处理。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e5/e5e75e4ca42eee961b896dcba24040c6.png\" /></p><p></p><p>图 1：一个典型的图片处理工作流</p><p></p><p>如上图所示，图片压缩和图片加水印的结果都是二进制文件格式，但是当前主流的 Serverless Workflow 平台在多个步骤之间传输上下文都只能支持文本格式传输，所以图片压缩和加水印的结果都需要经过 BASE64 或者其他转码方式转成文本进行数据流传输。</p><p></p><p>但是这种方案的限制和使用成本都比较高：</p><p></p><p>函数的 Response Body 通常有大小限制，所以这种方式无法处理超大文件。执行结果转换为文本，需要消耗大量内存，内存成本比较高。</p><p></p><p>如何简单高效的进行文件处理，业界也给出了其他解决方案，如通过云存储进行中间结果转储、AWS 的 Lambda Object 文件转换方案。下面给出了这两个方案的优缺点分析。</p><p></p><p></p><h3>方案一：中间结果通过云存储进行转储</h3><p></p><p></p><p>该方案如图 2 所示：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5f/5fb4056eaf790ca73ae6b36af364dfe3.png\" /></p><p></p><p>图 2：云存储转储运行方式示意图</p><p></p><p>两个步骤之间的文件流通过云存储去传递，这种方案支持大文件流的传输，但是由于中间多了一次到云存储的网络传输，如果业务对时延要求不高，该方案问题不大，但是对于时延敏感类业务，这种多出的时延是无法接受的。另外云存储转储需要额外的成本，如果调用量比较大，使用成本较高。</p><p></p><p></p><h3>方案二：AWS Lambda Object</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/2a/2a17adef96f9b7f62f6e4b43c1bf7694.png\" /></p><p></p><p>图 3：AWS 解决方案示意图 [1]</p><p></p><p>AWS 对于这种文件处理场景，提出了基于 S3 和 Lambda 的 Lambda Object 的方案，参考 [1]，简单来说，是支持为 S3 文件桶的 getObject API 提供 Access Point，AccessPoint 可以指向某一个 Lambda 函数，在函数中可以对原来的桶数据文件进行修改，比如可以将原始视频转码，得到转码后的结果返回到客户端。虽然解决了时延和大文件处理的问题，但是这个方案强依赖 S3 的 API，用户无法进行流程编排，也无法通过事件触发，不是一个真正通用的方案。</p><p></p><p></p><h3>业界方案总结</h3><p></p><p></p><p>简单总结如表 1 所示，当前业界提供的各个方案或多或少存在一些局限性，没有办法在同时满足低时延的情况下支持可编排的文件处理。然而低时延和可编排都是大量客户所追求的关键能力，如何解决这些关键痛点，提升客户体验，成为了当前我们重点想要攻克的难题。</p><p></p><p>表 1：业界文件处理方案对比</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/46/46513f19000023bc8aa85ced448b4a57.png\" /></p><p></p><p></p><h2>华为云 FunctionGraph 的 Serverless Streaming 流式处理方案</h2><p></p><p></p><p>针对当前业界缺少高效，可编排的文件处理方案的痛点，华为云 FunctionGraph 函数工作流提出 Serverless Streaming 的流式可编排的文件处理解决方案，步骤与步骤之间通过数据流驱动，更易于用户理解。本章通过图片处理的例子解释该方案的实现机制。</p><p></p><p>如果需要驱动一个工作流执行，工作流系统需要处理两个部分：</p><p></p><p>控制流：控制工作流的步骤间流转，以及步骤对应的 Serverless 函数的执行。确保步骤与步骤之间有序执行。数据流：控制整个工作流的数据流转，通常来说上一个步骤的输出是下一个步骤的输入，比如上述图片处理工作流中，图片压缩的结果是打水印步骤的输入数据。</p><p></p><p>在普通的服务编排中，由于需要精准控制各个服务的执行顺序，所以控制流是工作流的核心部分。然而在文件处理等流式处理场景中，对控制流的要求并不高，以上述图片处理场景举例，可以对大图片进行分块处理，图片压缩和加水印的任务不需要严格的先后顺序，图片压缩处理完一个分块可以直接流转到下一个步骤，而不需要等待图片压缩把所有分块处理完再开始加水印的任务。</p><p></p><p>基于上述理解，华为云 FunctionGraph 工作流的 Serverless Streaming 方案架构设计如图四所示：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f6/f60f146191dd4c11186626b7419924d6.png\" /></p><p></p><p>图 4：Serverless Streaming 流式处理架构图</p><p></p><p>在 Serverless Streaming 的流程中，弱化控制流中步骤之间的先后执行顺序，允许异步同时执行，步骤与步骤之间的交互通过数据流驱动。其中数据流的控制通过 Stream Bridge 组件来实现。</p><p></p><p>同时函数 SDK 增加流式数据返回接口，用户不需要将整个文件内容返回，而是通过 gRPC Stream 的方式将数据写入到 Stream Bridge，Stream Bridge 用来分发数据流到下一个步骤的函数 Pod 中。</p><p></p><p>这种方式存在如下优点：</p><p></p><p>由于控制流的弱化，完全通过数据流来驱动流程执行，不需要再强限制步骤之间完成的先后顺序，如图片处理场景中，压缩和加水印的步骤可以做到完全并行执行，这样可以加速整个流程的执行速度。每次请求都开辟独立缓冲区，缓冲区限制大小，数据流仅在内网传输，保证整体数据传输的可靠性和安全性。不依赖其他外部服务，使用成本低。对于开发人员来讲，只需要关注数据流的处理，而不需要关心数据流如何转发，如何存储，降低开发难度。底层流式传输通过 gRPC 进行，整体数据传输效率高</p><p></p><p></p><h3>在 FunctionGraph 中开发文件处理工作流</h3><p></p><p></p><p>当前 FunctionGraph 已经基于上述方案支持了在函数工作流中进行数据流处理，并且将结果通过流数据的方式返回到客户端，以构建一个图片处理工作流举例：</p><p></p><p>1. 首先创建一个图片压缩的函数，其中代码在处理返回数据通过 ctx.Write() 函数将结果以流式数据的形式返回：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/18/181b246c23cd758a6c193a8bce83ad5a.png\" /></p><p></p><p>FunctionGraph 通过 ctx.Write() 函数提供了流式返回的能力，对开发者来说，只需要将最终结果通过流的方式返回，而不需要关注网络传输的细节。</p><p></p><p>2. 在函数控制台中启用该函数的流式返回能力</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e9/e9753a53cb9f2bfa400801122a47b947.png\" /></p><p></p><p>3. 用上面的方式完成其他函数的编写，最后在 FunctionGraph 的函数流控制台完成工作流编排，举例如下：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/0a/0abbd1c0611083e4a0dcda841a62a859.png\" /></p><p></p><p>4. 调用工作流的同步执行接口，获取最终结果的文件流，数据将以 chunked 流式返回的方式返回到客户端</p><p></p><p></p><h3>使用效果</h3><p></p><p></p><p>针对图片处理的具体场景，我们测试对比了不同大小图片（333k、1m、4m、7m、10m、12m）进行图片切割和图片压缩的场景，由于 BASE64 转码方案无法支持大文件，AWS Lambda Object 方案无法支持编排，所以这里只对比使用 OBS 转储方案和基于流式返回的 Servlerss Streaming 方案的时延数据。具体对比数据图表如下：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/66/6633c9733adb935d9e5694cd6b273bae.png\" /></p><p></p><p>图 5：测试数据对比</p><p></p><p>响应时延：指客户端发出请求到收到第一个字节消耗的时延（单位：秒）</p><p></p><p>端到端时延：指客户端发出请求到收到最后一个字节消耗的时延（单位：秒）</p><p></p><p>从测试数据可以看出，响应时延和端到端时延使用流式返回方案后都得到了不同程度的降低。其中响应时延降低幅度较大，OBS 转储方案响应时延随着图片大小增大，响应时延呈线性上升，超过 4M 的图片响应时延就达到秒级，使用流式返回方案后，响应时延持续稳定在毫秒级的水平。从中可以发现，基于 Serverless Streaming 的流式返回方案不仅具备流式处理和可编排的能力，并且在文件处理场景中可以显著降低时延，从多个方面提升了用户使用体验。</p><p></p><p></p><h2>总结与展望</h2><p></p><p></p><p>本文主要讨论了 Serverless Workflow 在大文件处理时碰到的问题，FunctionGraph 通过简化数据传输链路，提升文件流处理效率, 给出了一种稳定高效、极低时延的大文件处理方法 Serverless Streaming，支持毫秒级的文件流式处理, 显著改善函数编排在文件处理等场景中的用户体验。</p><p></p><p>FunctionGraph 作为华为元戎加持的下一代 Serverless 函数计算与编排服务，将围绕通用全场景 Serverless 的前沿理论及案例实践，持续分享，回馈社区。</p><p></p><p>参考资料：</p><p></p><p>[1]Introducing Amazon S3 Object Lambda (<a href=\"https://aws.amazon.com/cn/blogs/aws/introducing-amazon-s3-object-lambda-use-your-code-to-process-data-as-it-is-being-retrieved-from-s3/\">https://aws.amazon.com/cn/blogs/aws/introducing-amazon-s3-object-lambda-use-your-code-to-process-data-as-it-is-being-retrieved-from-s3/</a>\")</p><p></p><p>今日好文推荐</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651157194&amp;idx=1&amp;sn=8c547e61981f9d0c52358d5a4ff7b6b4&amp;chksm=bdb88a998acf038f25b03331ee5f17221ee6661408c4bcf0f48c60800b35aaac0e3a98d0a7fe&amp;scene=21#wechat_redirect\">告别SVN，Git成“独苗”：GitHub 在 13 年后宣布淘汰Subversion支持</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651156926&amp;idx=1&amp;sn=2839c68c1455a13e0567826460a69e88&amp;chksm=bdb889ed8acf00fb0e0dba04e9e25d8b77fca3cf1168b2c3f512bccdf25a0c31c4cd3840d70f&amp;scene=21#wechat_redirect\">被逼出来的自主可控，从华为自研看国产IDE的未来和商业模式</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651156919&amp;idx=1&amp;sn=3ed2dd72d55e4c978f189f770cf1022a&amp;chksm=bdb889e48acf00f23c2c148912b1b60a45b534e181abb376afc72c055572b177c4492cefdd6d&amp;scene=21#wechat_redirect\">GitHub裁员10%，办公室全关，全体远程办公；微软必应集成ChatGPT下载量猛增10倍；谷歌出师不利市值蒸发超万亿｜Q资讯</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651156830&amp;idx=1&amp;sn=1388ad34d6acaa55714d6476ff055de4&amp;chksm=bdb8890d8acf001bc24a5c7b80893e6dc8a85250e0ac289ca12cfc5f67dc8dc32f515b026533&amp;scene=21#wechat_redirect\">马斯克开会当场解雇Twitter首席工程师：我有1亿多粉丝，他却说公众对我失去兴趣</a>\"</p><p></p><p></p><p></p>",
    "publish_time": "2023-02-17 12:20:07",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "打破数据孤岛，Apache Doris 助力纵腾集团快速构建流批一体数仓架构",
    "url": "https://www.infoq.cn/article/0MiKpHhupXlSOFjbxQrV",
    "summary": "<p>作者｜纵腾集团数据技术架构师 张彬华</p><p></p><p></p><blockquote>福建纵腾网络有限公司（简称“纵腾集团”）成立于 2009 年， 以“全球跨境电商基础设施服务商”为企业定位，聚焦跨境仓储与物流， 为全球跨境电商商户、出口贸易企业、出海品牌商提供海外仓储、商业专线物流、定制化物流等一体化物流解决方案， 旗下拥有谷仓海外仓 、云途物流 、WORLDTECH 等知名品牌 。</blockquote><p></p><p></p><p>随着纵腾集团业务的快速发展，各产品线提出的数据需求越发严格，而早期基于多套 CDH 大数据架构的技术栈和组件繁杂，开发和运维难度高、效率低，数据质量和时效难以保障，已无法满足当下数据分析需求，严重影响相关工作的开展。因此，纵腾集团在 2022 年正式引入<a href=\"https://github.com/apache/doris\"> Apache Doris</a>\"，基于 Apache Doris 构建了新的流批一体数据架构，同时建立了以<a href=\"https://www.infoq.cn/article/26ICMg30p0LS8UY8rbrw\"> Apache Doris 为核心</a>\"的数据中台。 构建过程中对读写时效性、服务的稳定性及高并发读写等多方面进行了优化，在这一过程中我们也积累了诸多实践经验，在此总结分享给大家。</p><p></p><h1>早期架构</h1><p></p><p>早期数仓架构主要分为两套基于 CDH 的大数据集群，这两套架构用于不同产品线的数仓需求、数据大屏和 BI 报表等应用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/17/179e9c4864d20d8f5762ebcb81548be4.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a1/a19576d9a944f925f24d18e0a20584cb.png\" /></p><p></p><p>这两套架构为独立的数据管道，具有耦合度低，集群间相互独立等特点，便于精细化管理。但随着业务需求的不断变化，这样的特点也引发出许多新的问题。</p><p></p><p>遇到的问题</p><p></p><p>元数据和数据质量缺乏管控，数据质量无法得到保证不同业务数据独立存储维护导致数据孤岛，不利于数据整合每个集群的机房分布不一，维护成本非常高集群间的技术栈和组件较多且存在差异性，对统一开发运维和数据整合都极具挑战性</p><p></p><h1>架构选型</h1><p></p><p>为了解决早期架构的痛点、更好满足日益严苛的数据需求，我们希望能有一款产品帮助我们快速构建流批一体的数仓架构、构建数据中台服务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/87/870a622470f3b6beb2203df2bb673eb8.png\" /></p><p></p><p>我们对传统数仓、 实时数仓和数据湖进行了对比。从上图可知，传统数仓可以支撑超 PB 级的海量数据，但是交互查询性能相对差一些，偏离线场景，不满足我们对数据实时性的要求；数据湖可以支撑超海量的数据，支持数据更新，查询性能适中，但是数据湖近两年才开始应用，成熟度较低，使用风险较大；实时数仓适用 PB 级数据存储，支持数据更新且查询性能非常好。结合我们的要求，实时数仓与我们的使用和需求场景都比较贴合，因此我们最终决定选择实时数仓作为数据底座。</p><p></p><p>接着我们对市面上较为流行的三款实时数仓：ClickHouse、Apache Druid、Apache Doris 进行了选型对比，对比图如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/79/79530885d3105c22d568a35cb8ac8015.png\" /></p><p></p><p>对比可知，<a href=\"https://www.infoq.cn/article/iT7purpsKqaPwr8Touco\">Apache Doris 优势明显</a>\"、性价比更高，具有独立主从架构简单、运维更灵活便捷、丰富的数据模型、优秀的查询性能和周全的生态规划等诸多优势，对比这三个产品，Apache Doris 最符合我们的选型要求。</p><p></p><h1>新数据架构</h1><p></p><p><img src=\"https://static001.geekbang.org/infoq/07/07601f623e6bfdc396f21b52edf82398.png\" /></p><p></p><p>新数据架构基于 Apache Doris 简化了数据采集、存储和计算的流程：</p><p></p><p>结合 DataHub 实现自研元数据采集和周期管理通过 Seatunnel 集成 Flink Doris Connector 稍加改造实现全量加增量数据的一体化采集简化存储媒介，对 ClickHouse、Kudu、HBase 等技术栈进行收敛，由 Apache Doris 进行流批数据的统一存储以 Apache Doris 为核心数据底座，结合 Apache Kyuubi 的 JDBC 引擎直连查询（自研）和 Spark 引擎中的 Spark Doris Connector 进行 ETL 开发（原生），统一计算引擎管理、权限管控和对外服务。</p><p></p><p>基于上述几点进行了数据应用开发及对外提供数据服务，构建了数据中台。</p><p></p><h2>数据中台</h2><p></p><p>我们以 Apache Doris 为核心底座创建了数据平台，核心功能包括：指标中心、元数据中心、基础配置中心、即席分析和数据接口服务中心，其中指标中心和即席分析的数据主要来源于 Aapche Doris ，当前已上线几百个指标。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3c/3ce0b3f2bab108d57810950a4f941309.png\" /></p><p></p><h2>数仓建模</h2><p></p><p>我们结合 Apache Doris 的特性重新对数仓进行了建模，数仓分层与传统数仓类似，其中 ODS 数据为存量加增量一体的导入模式，同时为防止出现[随机查询结果问题]，ODS 层最终选用 Unique 数据模型，相比于 Aggregate 模型可以实现写时合并（Merge-on-Write），有效提高数据实时性，且 Aggregate 模型查询性能更接近于 Duplicate 模型，对于 ODS 层是非常好的选择。</p><p></p><p>DIM/DED/DWS/ADS 层主要选用 Aggregate 数据模型；Aggregate 数据模型提供的四种聚合方式可以在大部分场景下达到事半功倍的效果，帮助我们快速应对不同的需求场景。</p><p></p><p>SUM： 能够高效实现 PV 类指标计算，但对于 UV 类的指标需要考虑预去重。MAX/MIN： 常用于最大最小运单时间节点类指标或包裹体积/重量最大最小值的指标计算。REPLACE_IF_NOT_NULL： 可以自动地过滤空值，非常便捷地实现仅记录最后一条数据，适用于大部分 DW 场景。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/96bb3f2b423c489d00728d36c34563a0.png\" /></p><p></p><h2>数据导入</h2><p></p><p>ODS 层的数据导入目前主要以 Stream Load 为主，在 HDFS 上的历史存量数据也会通过 Broker Load 或Spark Load 导入。DW 层数据主要以 insert into 方式导入，同时为减轻 Doris 内存压力，我们将部分 ETL 任务放到 Kyuubi On Spark 引擎上去计算，目前在 DolphinScheduler 每天平稳调度 Doris DW 任务有上万个，其中大部分为 T+1 任务，小部分为小时级任务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f6/f652d7fa0d5bf8fec89515d7094f49bc.png\" /></p><p></p><h1>实践经验</h1><p></p><p><img src=\"https://static001.geekbang.org/infoq/6a/6af8b354ba384d6c374a8dd1c0cea63d.png\" /></p><p></p><p>对于以 Apache Doris 为核心的新数据架构，我们规划了6个阶段进行运行测试，直至可以上线运行。（重点关注压测阶段和运行阶段，有一些调试优化经验分享给大家）</p><p></p><h2>1、准备阶段</h2><p></p><p>引入 Apache Doris 时是 2022 年 2月，因此选择当时最新版本 Apache Doris 0.15 Release 版本进行应用，主要考虑维度如下：</p><p></p><p>支持事务性插入语句功能支持 Unique Key 模型下的 Upsert支持 SQL 阻塞 List 功能，可以通过正则、哈希值匹配等方式防止某些 SQL 的执行官方不支持跨两位版本号进行升级，而 0.15 为当时最新的 Release 版本，选用该版本利于后期版本升级可通过资源标签的方式将一个Apache Doris 集群中的 BE 节点划分为多个资源组，实现多租户和资源隔离该版本提供了官方认可的 Flink-Doris-Connector/Spark-Doris-Connector/DataX Doriswriter 等插件，利于ETL流程建设</p><p></p><h2>2、验证阶段</h2><p></p><p>该阶段主要是为了二次验证官方文档中介绍的功能是否满足我们的实际运用场景，比如生态扩展中的 Connector、外表联邦查询、各种 Load 方式、多租户隔离及物化视图等。</p><p></p><h2>3、压测阶段</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/7e/7e467074fe6a5890250657610d68b186.png\" /></p><p></p><p>压测阶段首先进行数据生成，数据集选用的是 TPC-DS 数据，接着根据 Doris 的特性对 DDL 和 SQL 等规则进行对应调整，最后通过脚本将数据导入到 Apache Doris 存储中，再通过自动化脚本进行查询及导入压测，最终将压测结果输出到 MySQL 表中，量化为图表进行展示。下方为本阶段的基本配置及压测过程介绍：</p><p></p><p>- 硬件环境</p><p></p><p>内存：256GCPU：96C硬盘：SSD 1.92T * 8</p><p></p><p>- 软件环境</p><p></p><p>Apache Doris 版本：0.15-release/1.0-release（该阶段进行时，1.0-release 版本刚好发布）Apache Doris 集群：3 FE + 9 BE系统：CentOS Linux release 7.9.2009</p><p></p><p>- 数据集信息</p><p></p><p>我们生成了 1T、5T、10T 的 TPC-DS 数据集，1T 的数据集约有 30 亿数据量。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0a/0a138cfa9610543c34e1da1f5861188f.png\" /></p><p></p><h3>查询压测</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/84/8409544a87a38c71896d236c0bb13e3a.png\" /></p><p></p><p>压测过程中，最初使用 0.15-release 版本进行测试，正巧 1.0-release 版本发布，后决定更换为 1.0-release 版本进行后续的压测。下图是基于 1T 的 TPC-DS 数据在同等硬件配置环境下和某商业 MPP 数据库的对比结果：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/05/050899ac5d4764e39bcb0659455ab5ae.png\" /></p><p></p><p>如图所示，Apache Doris 的查询压测性能优异，有着明显的性能优势，作为开源产品能够达到这样的效果是非常优秀也是十分不易的。</p><p></p><h3>导入压测</h3><p></p><p>导入方式：通过 DataX Doriswriter 以 StreamLoad 方式进行写入压测数据来源：为避免因 Source 端原因影响写入时效，选择 100 张相同大表，即 100 个并发从内网 Hive 中导入（例如 tpcds-ds 的 store_sales_1t 表）数据模型：选用 Unique 模型（模拟ODS层），同时为充分考虑 Compaction 性能及小文件场景，每张表设置 70 个 Tablet</p><p></p><p>经调整优化后，最大写入时效为 269 MB/S&amp;680K ops/s，平均写入时效 70 MB/S&amp;180K ops/s，写入时效大幅提升。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d9/d97290555532395ce0baf93439bea7ed.png\" /></p><p></p><h2>4、上线阶段</h2><p></p><p>该阶段主要是确认 Apache Doris 上线需要的检查清单、预调参数、BE 资源组规划及用户权限的划分。</p><p></p><p>检查清单：包括但不限于 FE &amp; BE 端口、网络检查及 Apache Doris 的一些功能性验证，例如读写是否正常等。预调参数：确认优化后的 FE&amp;BE 参数是否配置，是否开启global enable_profile、动态分区以及数据盘保存位置是否有误等。BE 资源组：由于我们需要通过 Apache Doris 的多租户特性对不同的用户进行资源隔离，所以需要提前规划好每个 BE 节点对应的资源组。用户权限：对于不同的用户群体提前规划好权限范围，比如分析师开发只需要SELECT_PRIV权限，而 ETL 工程师需要SELECT_PRIV、LOAD_PRIV和CREATE_PRIV权限。</p><p></p><h2>5、宣导阶段</h2><p></p><p>该阶段主要是输出前面各阶段的 TimeLine、总结以及上线后使用 Apache Doris 的注意事项说明，比如我们用到多租户隔离，那么 DDL 建表时则需要在 Properties 中显示指定各副本对应的资源组：</p><p></p><p><code lang=\"text\">create table zt_table\n......\nproperties(\n    \"replication_allocation\"=\"tag.location.group_a:1, tag.location.group_b:1, tag.location.group_c:1\"\n)\n</code></p><p></p><h2>6、运行阶段</h2><p></p><p></p><h3>Tablet 规范问题</h3><p></p><p>问题描述： 上线运行一段时间后，随着越来越多的数据增长，集群每次重启后一周左右，读写就会开始变得越来越慢，直到无法正常进行读写。</p><p></p><p>问题处理：</p><p></p><p>经过对生产和 UAT 环境的对比测试以及对数仓表的 Schema 的分析，我们发现有些表数据并不大，但是 Bucket 却设置的非常大。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1e/1e958e9b6b783ddf7198f67afa238e50.png\" /></p><p></p><p>结合show data from database命令，我们将整个集群所有表的 Bucket 信息罗列出来，明确了大部分表的 Bucket 设置的不合理；而当前集群共 20T 左右数据，平均 1T 数据近 10W 个 Tablet，这就会导致小文件过多，造成 FE 元数据负载过高，从而影响导入和查询性能。定位原因后与社区小伙伴二次确认，并根据官方建议将 Bucket 设置不合理的表全部调整，调整后集群逐步恢复读写正常。（即将发布的 Apache Dorie 1.2.2 版本将推出 Auto Bucket 动态分桶推算功能，可以根据历史数据和机器数目自动推算新建 Partition 的分桶个数，保证分桶数始终保持在合理范围内，可有效解决上述问题）</p><p></p><p>问题小结：</p><p></p><p>Tablet数 = 分区数 * 桶数 * 副本数1TB 数据的 Tablet 数量控制在 8000 个左右（三副本控制到 2.4W 左右）建议大表的单个 Tablet 存储数据大小在 1G-10G 区间，可防止过多的小文件产生建议百兆左右的维表 Tablet 数量控制在 3-5 个，保证一定的并发数也不会产生过多的小文件</p><p></p><h3>集群读写优化</h3><p></p><p>问题描述： 1.1.3 release 版本中，高并发的同时进行 Stream Load、Broker Load、insert into 和查询时，读写会变得非常慢，如下图 11/01 19:00 并发上来后的 Txn Load 所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/56/56ce7d64b02734ea9bd69fac8bbc7594.png\" /></p><p></p><p>问题处理：</p><p></p><p>我们进行了十几轮对比测验，结论如下：</p><p></p><p>写入速度与并发的增长成反比（但不会骤变，而是缓慢变化）单表 Bucket（Tablet）设置过大会导致集群写入速度骤减；例如 A 库的 TA 表，设置 80 个 Bucket 时，启动相关 Flink Sink Job 就会导致集群整体写入速度迅速变慢，降低 Bucket（9~10个）时写入恢复正常。insert into select 的 ETL 任务与 Stream Load 写入任务会进行资源抢占，同时并发运行会使整个集群读写变慢。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/aa/aa007b19e2637176901bb3e507f4e081.png\" /></p><p></p><p>通过be.INFO发现，80 个 Bucket 表写入某个 Tablet 的memsize/rows/flushsize/duration数值比 10 个 Bucket 写入时的数值呈数倍之差，即 80 个 Bucket 表的数据写入时效无论 Memsize 还是 Flushsize 都非常小、但花费时间却很长。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/65/65165c4cb5a9407950a6a1726bf3535f.png\" /></p><p></p><p>同时收集 Pstack 日志，经过分析可以确定，Tcmalloc 在频繁地寻找 pageheap_lock，导致高频竞争锁从而降低了读写性能。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2a/2abd505af3f58af9f3ecadd96ffa305c.png\" /></p><p></p><p>于是，进行如下参数调整：</p><p></p><p><code lang=\"text\">减少doris_be进程内存返回给linux系统的频率，从而减少tcmalloc频繁竞争锁的情况\ntc_use_memory_min = 207374182400\ntc_enable_aggressive_memory_decommit = false\ntc_max_total_thread_cache_bytes=20737418240\n</code></p><p></p><p>调参并滚动重启 BE 后，集群状况如下图所示：</p><p></p><p>18:50 前将 Broker Load、insert into 和查询任务同时开启，18:50 后将 Stream Load 任务也开启（包括 80 bucket的表），集群整体的读写性能不仅没有下降，反而 Stream Load 时效突破了压测阶段的最大值 269 MB/S&amp;680K /ops/s，并且持续稳定。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ae/aebed62eb74e18eb32f430e3ed9696bf.png\" /></p><p></p><p>问题小结：</p><p></p><p>使用 Apache 1.1.3 及以上版本，非常推荐调整 Tcmalloc 相关参数，减少doris_be进程与系统之间的内存申请回收过程，可明显减少锁竞争的现象，大大提升读写性能和集群稳定性。（从 Apache Doris 1.1.5 版本开始，增加了Tcmalloc 简化配置，可将众多 Tcmalloc 参数归约到参数memory_mode中，compact 为节约内存模式，performance 为性能模式，用户可根据实际需求进行调整）</p><p></p><h1>总结收益</h1><p></p><p>当前 Apache Doris 的生产集群为 3 FE + 9 BE 组合， 已导入集团存量和增量数据的 60%以及部分 DW 数据生成，3 副本共占 44.4TB 的存储。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/38/38e07357927119172b7e191f06e55f20.png\" /></p><p></p><p>依赖 Apache Doris 自身优异特性及其生态圈帮助我们快速构建了一套新的流批一体数据架构，平均每天实时入库的数据量达到上亿规模，同时支持上万个* *调度任务平稳运行，相比早期架构单表查询效率提升近 5 倍 ，数据导入效率提升近 2 倍**，内存资源使用率显著减少。除此之外，Apache Doris 以下优势也是我们快速构建数据架构的重要推动力：</p><p></p><p>扩展表：联邦查询的设计，便于集成其它存储数据表设计：丰富的数据模型，可快速应对不同的数据需求。数据查询：不同的 Join 算子结合自身完善的优化器，让查询快而稳。架构设计：架构清晰明了且运维简单，大大地降低了我们的运维成本。数据导入：各种 Load 方式及 Connector 的扩展，基本涵盖大部分的数据同步场景应用。活跃度：社区高度活跃，SelectDB 为 Apache Doris 社区组建了一支专职技术支持团队，疑难杂症基本能在 12H 内快速响应并有社区小伙伴跟进和协助解决。</p><p></p><h1>未来规划</h1><p></p><p>结合当下业务场景的考虑，未来我们将引入数据湖进行非结构化和结构化数据一体存储，进一步完善流批一体架构。同时也会将 Apache Doris 回归它最本质的定位，专注于 OLAP 分析场景，并通过 Apache Doris 统一湖仓查询引擎层，发挥其最大的功效。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7c/7cf344c618c3f97d85fa7507b9dac4ee.png\" /></p><p></p><p>最后，非常感谢 Apache Doris 社区和 SelectDB 团队的张家锋、曲率和杨勇强等小伙伴对我们无私的技术支持，未来我们也将持续参与 Apache Doris 社区建设中，贡献绵薄之力。祝 Apache Doris 社区和 SelectDB 越来越好，日臻完善！</p>",
    "publish_time": "2023-02-17 12:56:25",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从资源弹性到数据弹性，乾象如何将云上量化研究效率提升40%？",
    "url": "https://www.infoq.cn/article/AwaZ5xmgwguT7PJkYU2Q",
    "summary": "<p></p><p>作者 | 李治昳、李健弘</p><p>&nbsp;</p><p></p><blockquote>机器学习、云计算、云原生等技术的进步给金融行业创新注入了新的动力，以乾象投资 Metabit Trading为代表的以人工智能为核心的科技型量化投资公司的工作就非常有代表性。我们通过深度融合和改进机器学习算法，并将其应用于信噪比极低的金融数据中，为投资人创造长期可持续的回报。&nbsp;与传统的量化分析不同，机器学习不仅关注股价、交易量和历史回报率等结构化数据，还注入来自研报、财报、新闻和社交媒体等非结构化数据来深入了解证券价格走势和波动性。然而，将机器学习应用于量化研究是具有挑战性的，因为原始数据可能包含噪声。此外，他们还需要应对许多挑战，如突发任务、高并发数据访问和计算资源限制等。&nbsp;为此，乾象投资在研发投入、创新支持和基础平台建设方面持续发力。他们的研究基础设施团队构建了一个高效、安全、规模化的工具链研发流程，通过合理利用云计算和开源技术突破了单机研发的限制。&nbsp;本文将分享乾象量化研究基础平台的具体实践，介绍基于Fluid+JuiceFSRuntime的公共云弹性量化投研工作支撑。</blockquote><p></p><p>&nbsp;</p><p></p><h2>量化研究的工作详解</h2><p></p><p>&nbsp;</p><p>作为AI-powered hedge fund，通过AI模型训练进行策略研究是我们最主要的研究方式。首先，在模型训练之前需要对原始数据做特征提取。金融数据的信噪比特别低，如果直接使用原始的数据进行训练，得到的模型噪音会非常大。原始数据除了行情数据，即大家经常会看到的市场上的股价、交易量之类的数据，也包括一些非量价的数据，比如研报、财报、新闻、社交媒体等之类的非结构化数据，研究人员会通过一系列的变换提取出特征，再进行 AI 模型训练。可以参考下面我们研究场景中和机器学习关联最紧密的策略研究模式的简化示意图。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/34/342b13f0e623682ebcad288b1d286335.png\" /></p><p>&nbsp;</p><p>模型训练会产出模型以及信号。信号是对未来价格趋势的判断，信号的强度意味着策略导向性的强度。量化研究员会根据这些信息去优化投资组合，从而形成交易的实时仓位。这个过程中会考虑横向维度（股票）的信息来进行风险控制，例如某一行业的股票不要过度持仓。当仓位策略形成之后，量化研究员会去模拟下单，而后得到实时仓位对应的盈亏信息，从而了解到这个策略的收益表现，这就是一个量化研究的完整流程。</p><p>&nbsp;</p><p></p><h2>量化研究基础平台的需求</h2><p></p><p>&nbsp;</p><p>第一，突发任务多，弹性要求高。在策略研究的过程中，量化研究员会产生策略想法，并会通过实验去验证自己的想法。伴随着研究人员新想法的出现，计算平台就会产生大量的突发任务，因此我们对计算的弹性伸缩能力要求很高。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/ae/aec25bce4587659a316545ea1714831f.png\" /></p><p>&nbsp;</p><p>上图是我们某个集群一段时间的运行实例数据。以上图为例，可以看到在多个时间段里，整个集群实例数高峰时刻可以达到上千个，但是同时整个计算集群的规模也会有缩容到0时候。量化机构的计算任务和研究员的研发进度是有很大关联的，波峰波谷的差距会非常大，这也是离线研究任务的特点。</p><p>&nbsp;</p><p>第二，热数据高并发访问，除了计算需要弹性，数据缓存也需要弹性。对于热数据，比如行情数据，通常会有上百个任务同时访问数据，它的吞吐要求非常高，峰值时数百 Gbps 甚至 Tbps 级别的聚合带宽才能满足需求。但是当计算集群中没有任何节点的时候，此时的吞吐需求为0，如果是刚性吞吐这就需要弹性吞吐扩缩容的能力。</p><p>&nbsp;</p><p>第三，容量和吞吐的独立线性扩展能力，对金融模型训练非常重要。传统分布式存储带宽与吞吐仅和数据使用容量成正比，而量化研究过程中会创建大量的容器并发访问存储系统的数据，会触发存储系统访问限流。这就造成计算资源极致弹性与存储系统有限带宽之间的矛盾。 而量化研究的数据量其实不是特别大，很多市场的量价数据总量也不会超过 TB 级，但是数据访问需要的峰值吞吐却非常高。</p><p>&nbsp;</p><p>第四，数据亲和性调度，同一数据源多次运行访问本地缓存可以被复用。充分发挥热点数据集的缓存节点优势，在对用户无感知的前提下，智能的将任务调度到数据缓存节点上。让常用的模型训练程序越来越快。</p><p>&nbsp;</p><p>第五，IP保护：数据共享与数据隔离。出于IP 保护的需求，不仅在计算任务上需要做隔离，在数据上也是需要具备权限控制的隔离能力；同时对行情数据这类相对公开的数据，还需要支持研究员的获取方式是便捷的。</p><p>&nbsp;</p><p>第六，缓存中间结果。计算任务模块化的场景会对中间结果的存储跟传输也有需求。举个简单的例子，在特征计算过程中会生成比较大量的特征数据，这些数据会立刻用于接下来大规模高并发的训练节点上。显而易见在这种场景下我们需要一个高吞吐和高稳定的中间缓存做数据传递。</p><p>&nbsp;</p><p>第七，多文件系统的支持。计算任务中各类型的任务会对应的各种特性的数据类型和使用方式，因而我们不同团队会采用不同的文件系统包括OSS，CPFS，NAS，JuiceFS，以获取在各自情况下的性能最优化。Fluid的不同runtime能够灵活的支持文件系统与任务的组合，使得任务计算能够在k8s上更高效合理的利用对应资源避免不必要的浪费。</p><p></p><h2>Fluid+JuiceFSRuntime：为云上量化研究基础平台提供高效支撑</h2><p></p><p>&nbsp;</p><p>出于POSIX兼容，成本，高吞吐的考虑，我们选择了JuiceFS云服务作为分布式底层存储。选择了JuiceFS，发现现有Kubernetes的CSI体系并不能很好地支持我们对数据访问性能、弹性吞吐能力以及数据共享隔离的需求，具体来看：</p><p>&nbsp;</p><p>传统的Persistent Volume Claim是面向通用存储的抽象，缺乏对同一个存储复杂数据访问模式协同良好的支持：在不同的应用场景下，应用对同一存储中不同文件的使用方式不同，比如我们多数并发计算任务要求只读；但是也有Pipeline 数据中转，数据特征生成之后，需要中转到模型训练中，此时就要求读写；这导致了很难在同一个PVC中统一设置元数据更新和缓存策略。实际上，这些策略应该完全取决于应用使用数据的模式。数据隔离与共享：不同数据科学家团队访问不同的数据集需要天然隔离，并且要求比较容易管理；同时支持公共数据集访问共享，特别是缓存数据共享，由于行情数据这类相对公开的数据，不同的研究员团队会反复使用，希望获得“一次预热、全公司收益”的效果。数据缓存感知的Kubernetes调度：相同模型、相同输入、不同的超参的作业以及微调模型、相同输入的作业都会不断重复访问同一数据，产生可以复用的数据缓存。但是原生的 Kubernetes 调度器无法感知缓存，导致应用调度的结果不佳、缓存无法重用，性能得不到提升。数据访问吞吐可以弹性扩容到数百Gbps：传统的高性能分布式文件存储，一般的规格是200 MB/s/TiB基线的存储规格，其最大IO带宽是20Gbps，而我们任务的峰值 IO 带宽需求至少需要数百 Gbps，显然无法满足我们的要求。数据缓存的成本最优：由于公共云提供了计算资源极致弹性，可以短时间内弹出几百甚至上千计算实例，而当这些计算资源同时访问存储时，在高峰时吞吐需要数百Gbps甚至更高，此时需要通过计算中的缓存集群去服务热数据。但是很多时间段内，计算集群会缩容为0，此时维护一个很大的缓存集群就得不偿失了。我们更倾向于在使用之前进行数据预热，同时根据业务的运行规律执行定时扩缩容；而当计算集群没有作业在运行，再缩容到默认缓存节点，从而达到对数据缓存吞吐的动态弹性伸缩控制。</p><p>&nbsp;</p><p>为了达到上述目标，我们迫切希望找到 Kubernetes 上具有弹性分布式缓存加速能力同时很好支持JuiceFS存储的软件。我们发现 CNCF Sandbox 项目<a href=\"https://github.com/fluid-cloudnative/fluid\">Fluid</a>\"&nbsp;和JuiceFS存储有很好的协同，JuiceFS团队正好也是Fluid项目中JuiceFSRuntime的主要贡献者和维护者。于是，我们设计了基于 Fluid 的架构方案并选择了原生的JuiceFSRuntime。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/77/77e1be2ed9b2fe131b0a60c4f1ee9acd.png\" /></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h3>架构组件介绍</h3><p></p><p></p><h4>Fluid</h4><p></p><p>Fluid 不同于传统的面向存储的 PVC 抽象方式，而是在 Kubernetes 上针对“计算任务使用数据”的过程进行抽象。它提出了弹性数据集 Dataset 的概念，以应用对数据访问的需求为中心，给数据赋予特征，如小文件、只读、可读写等；同时将数据从存储中提取出来，并且给有特征的数据赋予范围，如用户只关心某几天的数据。围绕 Dataset 构建调度系统，关注数据本身和使用数据的应用的编排，强调弹性和生命周期管理。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/81/81ea05abafd21df3721d3779d35b6b00.png\" /></p><p>&nbsp;</p><p></p><h4>JuiceFSRuntime</h4><p></p><p>JuiceFSRuntime 基于JuiceFS的分布式缓存加速引擎, 通过将数据分布式缓存技术与Fluid自动弹性伸缩(Autoscaling)、可迁移(Portability)、可观测(Observability)、亲和性调度（Scheduling）能力相结合，支持场景化的数据缓存和加速能力。在Fluid上使用和部署JuiceFSRuntime流程简单、兼容原生 Kubernetes 环境、可以开箱即用，并深度结合JuiceFS存储特性，针对特定场景优化数据访问性能。</p><p>&nbsp;</p><p></p><h3>使用基于 JuiceFSRuntime 的 Fluid 的原因</h3><p></p><p>&nbsp;</p><p>Dataset抽象满足云原生机器学习场景的性能优化和隔离共享等多样需求：</p><p>&nbsp;</p><p>场景化性能调优：通过Dataset可以针对不同访问特点的数据集作相应的优化，比如模型训练场景通常是只读，而特征计算需要读写。数据隔离： Dataset天然的通过Kubernetes 的命名空间这种资源隔离机制用来限制不同团队对集群中数据集的访问权限，并且不同的数据集对应JuiceFS中不同的子目录（JuiceFS企业版还支持目录配额），这可以满足数据隔离的需求。数据缓存共享：对于一些不同团队都会频繁使用的公开数据集，Fluid支持跨Kubernetes Namespace的数据访问，可以做到一次缓存，多个团队共享，这也满足了数据缓存共享的需求。</p><p>&nbsp;</p><p>Runtime场景化的计算资源优化：Dataset是数据的通用抽象，而对于数据真正的操作，实际上由JuiceFSRuntime实现，所以Runtime的CPU，Memory，网络和缓存Worker数量等资源配置势必会影响性能，这就需要针对Dataset的使用场景，对Runtime的计算资源进行优化配置。</p><p>&nbsp;</p><p>弹性分布式缓存：支持丰富的扩缩容策略，包括手动伸缩、自动弹性伸缩和定时弹性伸缩，可以根据需要找到最优的弹性方案。</p><p>&nbsp;</p><p>手动伸缩：通过Dataset的可观测性，可以了解数据集的数据量和缓存Runtime需要的缓存资源，也可以根据应用访问的并发度设置Runtime的Replicas数量（缓存Worker的数量），不用的时候可以随时缩容。自动弹性伸缩：根据数据指标进行自动弹性伸缩。比如根据数据缓存量和吞吐量等指标进行缓存弹性伸缩，可以制定当缓存百分比超过80%，或者当客户端数量超过一定阈值的时候进行自动扩容。&nbsp;定时弹性伸缩：根据业务特性设置定时弹性伸缩，可以实现无人参与的数据弹性扩缩容机制。</p><p>&nbsp;</p><p>自动的数据预热：避免在训练时刻并发拉取数据造成数据访问竞争，还可以和弹性伸缩配合，避免过早的创建缓存资源。</p><p>&nbsp;</p><p>数据感知调度能力：在应用被调度时，Fluid会通过JuiceFSRuntime把数据缓存位置作为一个调度信息提供给K8s调度器，帮助应用调度到缓存节点或者离缓存更近的节点。整个过程对用户透明，实现数据访问性能的优势最大化。</p><p></p><h3>落地实践</h3><p></p><p>&nbsp;</p><p>根据实践，我们总结了以下经验供大家参考。</p><p></p><h4>在Fluid的JuiceFSRuntime选择高网络IO和大内存的ECS作为缓存节点</h4><p></p><p>&nbsp;</p><p>随着ECS网络能力的不断提升，当前网络带宽已经远超SSD云盘IO能力。以阿里云上的ecs.g7.8xlarge规格的ECS为例，其带宽峰值为25Gbps，内存为128GiB。理论上，完成40G数据读取仅需要13s。我们的数据是存储在JuiceFS上的，因此为了实现大规模的数据读取，我们需要首先将数据加载到计算所在VPC网络中的计算节点中。以下为我们使用的一个具体例子，为了提高数据读取速度，我们配置cache节点使其选择使用内存来缓存数据。这里需要注意：</p><p>&nbsp;</p><p>Worker 主要负责分布式数据缓存，为了提高数据读取速度，我们可以为 Worker 配置内存性能相对较高的机型。而 Worker 的调度策略在 Dataset 中配置，因而需要在 Dataset 中为 Worker 配置亲和性策略。当任务没有特定机型需求时，为保证Cluster的AutoScaler能成功扩容，实践中也建议在进行亲和性配置时选择多种实例类型以保证扩容/任务执行的成功。Replicas是初始的缓存Worker数量，后期可以通过手动触发或自动弹性伸缩进行扩缩容。当指定tieredstore后，即无需在Kubernetes的Pod中设置request的内存，Fluid可以自动处理。如在缓存节点上的JuiceFS mount有不同的配置，例如cache size大小， 挂载路径等，可以通过worker里的options进行覆盖。</p><p>&nbsp;</p><p><code lang=\"null\">apiVersion: data.fluid.io/v1alpha1\nkind: Dataset\nmetadata:\n  name: metabit-juice-research\nspec:\n  mounts:\n    - name: metabit-juice-research\n      mountPoint: juicefs:///\n      options:\n          metacache: \"\"\n          cache-group: \"research-groups\"\n      encryptOptions:\n        - name: token\n          valueFrom:\n            secretKeyRef:\n              name: juicefs-secret\n              key: token\n        - name: access-key\n          valueFrom:\n            secretKeyRef:\n              name: juicefs-secret\n              key: access-key\n        - name: secret-key\n          valueFrom:\n            secretKeyRef:\n              name: juicefs-secret\n              key: secret-key\n  nodeAffinity:\n    required:\n      nodeSelectorTerms:\n        - matchExpressions:\n            - key: node.kubernetes.io/instance-type\n              operator: In\n              values:\n                - ecs.g7.8xlarge\n                - ecs.g7.16xlarge\n  tolerations:\n  -key: jfs_transmittion\n  operator: Exists\n  effect: NoSchedule\n \n---\napiVersion: data.fluid.io/v1alpha1\nkind: JuiceFSRuntime\nmetadata:\n  name: metabit-juice-research\nspec:\n  replicas: 5\n  tieredstore:\n    levels:\n      - mediumtype: MEM\n        path: /dev/shm\n        quota: 40960\n        low: \"0.1\"\n   worker:\n     nodeSelector:\n       nodeType: cacheNode\n     options:\n       cache-size: 409600\n       free-space-ratio: \"0.15\"</code></p><p></p><p></p><h4>配置自动弹性伸缩策略</h4><p></p><p>&nbsp;</p><p>受业务形态的影响，Metabit在固定时段会有跟高的用量需求，因此简单的配置定时缓存节点的弹性伸缩策略能到达到不错的收益，例如对成本的控制，对性能提升。apiVersion:</p><p>&nbsp;</p><p><code lang=\"null\">autoscaling.alibabacloud.com/v1beta1\nkind: CronHorizontalPodAutoscaler\nmetadata:\n  name: research-weekly\n  namespace: default\nspec:\n   scaleTargetRef:\n      apiVersion: data.fluid.io/v1alpha1\n      kind: JuiceFSRuntime\n      name: metabit-juice-research\n   jobs:\n   - name: \"scale-down\"\n     schedule: \"0 0 7 ? * 1\"\n     targetSize: 10\n   - name: \"scale-up\"\n     schedule: \"0 0 18 ? * 5-6\"\n     targetSize: 20</code></p><p>&nbsp;</p><p>更进一步，如果通过业务中具体的metrics如缓存比例阈值， IO throughput等触发带有复杂自定义规则的弹性伸缩策略可以实现更为灵活的缓存节点扩缩容配置以带来更高和更稳定的性能表现。具体来讲，在灵活度和性能层面会有以下一些优点：</p><p>&nbsp;</p><p>无需精准感知底层数据或拥有固定的扩缩容规则， 依据集群状态自适应的配置缓存副本上下限。阶梯式扩容避免一开始就创建过多的ECS，造成花费上的浪费。避免爆发式的ECS访问JuiceFS数据造成带宽抢占。</p><p></p><h4>触发数据预热</h4><p></p><p>&nbsp;</p><p>通过数据预热提升缓存比例，进而触发自动弹性伸缩；同时监控缓存比例，当缓存比例达到一定阈值同时开始触发任务下发，避免过早下发高并发任务导致IO延迟。</p><p></p><h4>镜像预埋</h4><p></p><p>&nbsp;</p><p>由于Metabit Trading使用计算和数据弹性的规模很大，瞬间会弹出非常多的Pod，这就会导致镜像下载限流。网络带宽资源在pod拉起过程中是稀缺的，为避免pod 创建时因拉取容器镜像延时带来的各种问题，我们建议对ECS的镜像进行客制化改造，对需要的系统性镜像做到“应埋尽埋”从而降低pod拉起的时间成本。具体例子可参考<a href=\"https://#L191\">ACK</a>\"的基础镜像。</p><p>&nbsp;</p><p></p><h2>弹性吞吐提升带来的性能和成本收益</h2><p></p><p>&nbsp;</p><p>在实际部署评估中，我们使用20个ecs.g7.8xlarge规格的ECS作为woker结点构建JuiceFSRuntime集群，单个ECS结点的带宽上限为25Gbps；为了提高数据读取速度，我们选择使用内存来缓存数据。</p><p>&nbsp;</p><p>为便于对比，我们统计了访问耗时数据，并与使用Fluid方式访问数据耗时进行了对比，数据如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f3/f3303c7c2967c4938fb5bfe285fda6e4.png\" /></p><p></p><p>&nbsp;</p><p>可以看出，当同时启动的Pod数量较少时，Fluid与分布式存储相比并没有明显优势；而当同时启动的Pod越多时，Fluid的加速优势也越来越大；当同时并发扩大到100个Pod时，Fluid相比传统分布式存乎可以降低超过40%的平均耗时。这一方面提升了任务速度，另外一方面也确实的节省了ECS因为IO延时带来的成本。</p><p>&nbsp;</p><p>更重要的是，因整个Fluid系统的数据读取带宽是与JuiceFSRuntime集群规模正相关的，如果我们需要同时扩容更多的Pod，则可以通过修改JuiceFSRuntime的Replicas来增加数据带宽，这种动态扩容的能力是分布式存储目前无法满足的。</p><p></p><p></p><h2>展望</h2><p></p><p>&nbsp;</p><p>Metabit在Fluid的实践上走出了踏实的第一步，面对这个不断创新和持续输出的技术框架我们也在思考如何发挥在更多合适的场景发挥其完备的功能。这里简单聊聊我们的一些小观察，抛砖引玉，供大家发挥。</p><p>&nbsp;</p><p>Serverless化能够提供更好的弹性：目前我们通过自定义镜像的方式提升应用容器和Fluid组件的弹性效率，我们也关注到在ECI上使用Fluid能更高效和简单的应用扩展弹性，同时降低运维复杂度。这是一个在实践中值得去探索的方向。任务弹性和数据缓存弹性的协同：业务系统了解一段时间内使用相同数据集的任务并发量，并且任务排队的过程中执行数据预热和弹性扩缩容；相应的当数据缓存或者数据访问吞吐满足一定条件，触发排队任务从等待变成可用。</p><p>&nbsp;</p><p></p><h2>总结和致谢</h2><p></p><p>&nbsp;</p><p>Metabit Trading在生产环境使用Fluid已经接近一年半了，包括JindoRuntime、JuiceFSRuntime等，目前通过JuiceFSRuntime实现了高效的大规模量化研究。Fluid很好的满足了简单易用、稳定可靠、多Runtime、易维护以及让量化研究员的使用感透明等好处。</p><p>&nbsp;</p><p>Metabit Trading的大规模实践帮助我们团队在使用公共云上积累了很好的认知，在机器学习和大数据场景下，不但计算资源需要弹性，与之配合的数据访问吞吐也需要与之相匹配的弹性，传统的存储侧缓存由于成本、灵活、按需弹性的差异，已经很难满足当前场景的需求，而Fluid的计算侧弹性数据缓存的理念和实现则非常合适。</p><p>&nbsp;</p><p>这里要特别感谢JuiceData的朱唯唯，Fluid社区的车漾，徐之浩和顾荣老师的持续支持。因为有他们的维护，社区内有活跃的讨论和快速的响应，这对我们的顺利adoption起到了关键的作用。</p><p>&nbsp;</p><p>作者介绍：</p><p>&nbsp;</p><p>本文作者来自乾象投资 Metabit Trading，分司成立于2018年，是一家以人工智能为核心的科技型量化投资公司。核心成员毕业于 Stanford、CMU、清北等知名高校。目前，管理规模已突破 50 亿元人民币, 并且在2022年市场中性策略收益排名中名列前茅，表现亮眼。</p><p></p><p>李治昳，Metabit Trading - AI Platform Engineer，builder 、云原生技术learner，曾任Citadel高级工程师。</p><p>&nbsp;</p><p>李健弘， Metabit Trading - Engineering manager of AI Platform，专注于在量化研究领域搭建机器学习平台和高性能计算平台，曾任 Facebook 高级工程师。</p><p>&nbsp;</p><p></p>",
    "publish_time": "2023-02-17 14:03:11",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "专访吉利汽车：供应链数字化不能有“断点”，业技融合是必经之路",
    "url": "https://www.infoq.cn/article/dXYjsLxYiFhOzSyfNwxu",
    "summary": "<p></p><p>核心要点</p><p>目前吉利汽车集团下多个板块的业务能力成熟度处于 B 级到 C 级之间，包括供应链体系的团队。实施物流一体化项目之后，也就实现了任意销售订单向物流订单的转化及物流全链路可视。信息化项目的验收汇报工作从原来由 IT 人员负责、逐渐变为由业务人员负责。如果 IT 人员不主动拥抱数字化转型，不主动了解业务以及提升业务架构设计能力，那IT团队就容易被边缘化，沦为名副其实的“外包团队”。</p><p></p><p>100 多年前，“汽车大王”亨利·福特 (Henry Ford) 关于 T 型车有这样一句名言：“任何客户都可以将汽车涂成他想要的任何颜色，只要它是黑色的。”福特的言外之意是只能选黑色，但结合当时的生产条件来看，这其实是为了量产而做的妥协，T 型车之所以只有黑色，是因为只有这样才能提高效率和提高质量。</p><p></p><p>但发展到今天，在数字化浪潮下，“<a href=\"https://xie.infoq.cn/article/b944fcb9fbea9a28996a054b4\">新四化</a>\"”（电动化、联网化、智能化和共享化）已经成为汽车产业发展的趋势。汽车企业的核心战略逐步向“用户定义汽车”转变，而要满足用户的个性化需求，必须有数字化的支撑，也只有敏捷的数字化供应链，才能对需求做出快速响应和交付。</p><p></p><p>吉利汽车集团数字化中心供应链产品总监张炜向 InfoQ 表示，除了应对用户的个性化需求，在新的产业竞争格局下，吉利也面临着新技术的重新定义和商业模式的转型等多重挑战，尤其在过去 3 年多，受疫情影响，零部件供应中断多次给供应链带来较大风险和挑战，这要求汽车企业对供应链模式建立新的认识。</p><p></p><p>因此，对吉利汽车来说，供应链数字化的重要性不言而喻。</p><p></p><h2>打通全链路，快速定位和响应供应链风险</h2><p></p><p></p><p>据张炜介绍，在吉利的供应链体系里，物流与备件中心原来是职能协调部门。这意味着，作为“后台”，物流部门对前端业务的响应会存在一定程度的滞后。</p><p></p><p>如果说在过去，当汽车还是“卖方市场”，定制化需求还不凸显，原材料还不紧缺，生产节奏还可控的情况下，这种“一定程度”的滞后和延迟还在可接受的范围内；那么，现如今，随着汽车产业竞争的加剧，消费者的个性化需求开始影响汽车研发和生产，以及在恶劣的全球供应链环境下，则要求汽车的物流和备件环节也必须做到灵活且快速的响应。</p><p></p><p>为了解决这一问题，就需要在执行过程中将采购订单、生产订单都转化为物流订单。具体如何实现？吉利汽车给出的答案是打造供应链 OTWB 一体化物流信息平台。</p><p></p><p>所谓供应链 OTWB 一体化物流信息平台，具体包括了 OMS 订单管理系统、TMS 调度管理系统、WMS 仓储管理系统、BMS 计费管理系统，是目前被物流行业广泛应用的数字化供应链系统框架。过去两年，吉利自主研发了一个 OTWB 平台。</p><p></p><p>具体来说，吉利 OTWB 平台实现了其内外部零部件和售后备件在需求、仓储、运输、包装和配送环节的一体化管理，可以大大降低供应链整体运营成本，提升客户服务时效；同时以 OTWB 为中心，通过与 SAP（企业资源管理软件系统）、LES（物流执行系统）、SRM（供应商关系管理）、GWS（吉利云仓系统）、KDMS 等吉利内部业务系统集成，还打破信息孤岛，打通了物流全链路信息。</p><p></p><p>这意味着，实施物流一体化项目之后，也就实现了任意销售订单向物流订单的转化及物流全链路可视。</p><p></p><p>不过，与其它制造行业相比，汽车的供应链体系还要更为复杂。通常来说，一辆汽车需要配备上万个来自不同国家和地区的零件，不同车型的原材料采购需求又千差万别，供应链风险的控制难度要大得多。</p><p></p><p>因此，在信息化层面，除了建设一体化物流信息平台，吉利数字化中心还构建了供应链控制塔，可以快速定位供应链风险，比如哪个环节出问题，风险源头是哪家供应商，哪些零部件能够快速响应等等，对于风险可以进行实时监控，提高端到端的可视化。这使得吉利汽车在面对供应断点问题时，拥有了更加快速高效的响应体系，可以更灵活地应对外部环境的不确定变化。</p><p></p><p>同时，通过 LES 的全面推广实施，在各汽车制造基地导入视觉收货、RFID 自动出入库、自动化立体库、货到人拣选、AGV 转运等智能化手段，实现集团物流作业智能化、自动化。</p><p></p><p>除此之外，在采购层面，张炜还提及，通过与京东<a href=\"https://www.sohu.com/a/479888646_161795\">合作</a>\"搭建的采购商城，吉利还面向工业品实现了高效采购，可以从产品、仓储、物流、数字化服务等方面助力集团降低采购成本，提高运营效率。</p><p></p><p></p><h2>快速响应业务需求，数字化中心各司其职</h2><p></p><p></p><p>不过，与多数企业相似，吉利内部的数字化转型的过程，也不可避免地遭遇了来自组织、人和战略等多方面的考验。</p><p></p><p>业界充斥着各种各样的数字化转型思路和案例，吉利要找出适合自身场景的数字化理念，需要耗费不少功夫。而在起初阶段，由于内部对数字化的认知参差不齐，尽管管理层已经意识到来自行业的数字化转型压力，但执行层总不免有些抵触，多数人对此持怀疑态度：比如忧虑推进数字化工作之后，会不会给自己的岗位带来变化，甚至把自己淘汰了。</p><p></p><p>经过多年的持续探索，吉利汽车供应链数字化路径和方向逐渐明晰。</p><p></p><p>此前，吉利汽车的数字化建设主要是以落地信息化项目的模式推进，主要由吉利汽车信息工程部下的 IT 咨询部和研发部等部门负责，后来为了快速响应业务需求，数字化中心应运而生，组织架构也随之调整。</p><p></p><p>吉利汽车集团供应链数字化中心于 2021 年 9 月建立，团队规模约 180 人。由于集团的供应链体系是由采购公司、物流与备件中心、SQE 中心（Supplier Quality Engineer，供应商质量工程师）组成，因此对应的数字化中心亦分为 4 个团队，其中 3 个分别服务于采购、物流、SQE 等业务部门，各自负责对应业务团队的信息化项目落地和数字化场景应用。剩余的 1 个是供应链公共能力部门，主要负责大数据应用、供应链互联互通，供应链控制塔（供应链运营平台）等公共能力的建设。</p><p></p><p>据介绍，中心在不久的未来还会增设 1 个“供应链数字化使能团队”，主要负责架构规划和数字化成熟评估模型的迭代，原本这部分工作是从集团层面牵头规划，接下来将由供应链数字化中心负责推进。</p><p></p><h2>“六大方向”推进数转</h2><p></p><p></p><p>对于企业而言，从信息化到数字化，很关键的一点是统一转型的思路和方针，这有助于企业统一目标，更有效地分配资源和提高整体效率。</p><p></p><p>2021 年，吉利汽车集团数字化中心开始对数字化转型思路做系统性的梳理，并由此得出“六大方向”转型思路。目前，包括供应链在内的各业务板块均围绕“六大方向”思路展开数字化建设和运营。</p><p></p><p>促液态。首先，组织层面，构建“液态型组织”。内部认为，组织形式可以简单分为“稳态”和“液态”，大多数情况下组织是处于相对固定的“稳态”，但为了响应层出不穷的业务场景需求，需要灵活地从各团队抽调人员，继而组成新的支持团队，即“液态”组织；其次，这里说的“液态”也可以从文化构建层面理解，将数字化作为战略融入到集团文化中，甚至落到各职能部门和工厂的指标中；最后，“液态”也意味着 IT 和业务融合共创。绘蓝图。围绕集团战略，做好“四个坚持”。第一，坚持“一把手工程”，从 2005 年开始，集团内许多信息化项目开始贯彻“一把手”理念；第二、将数字化转型作为核心战略推动；第三、坚持顶层设计，从原来站在项目交付的思考维度，切换到从顶层设计的角度去研究架构规划；第四、坚持协同治理，信息化项目落地后，IT 与业务协同治理和迭代。搭平台。吉利数智平台朝着构建“高可用、高复用、生态化、国际化”等能力的目标演进，其中的核心内容包括构建敏捷的转型体系、共享中台、生态平台以及实现数智赋能（通过技术和平台工具挖掘数字价值，赋能业务），从而支撑业务的快速创新和发展。打基础。致力于数字化基础设施的稳定可靠、安全可信、资源弹性、成本精益。强运营。提供安全、可靠、高效的 IT 运营服务，借助自动化和智能化手段，让运维体系得以持续高效、可靠安全地运转起来。育人才。管理上融入数字化意识，落地上共创数字化能力，数字化人才不局限于技术专业人才，所有人都可以提升数字化能力。</p><p></p><h2>迫切的“一把手”，主动的业务人</h2><p></p><p></p><p>围绕集团的转型思路，供应链板块的数字化工作得以顺利落地。</p><p></p><p>在“促液态”层面来看，从 2022 年下半年起，吉利汽车供应链的业务侧和 IT 侧已逐渐“融合”，这主要得益于同年 3 月成立的“供应链数字化委员会”，尽管这是一个虚拟组织，但它也有相应的职能，在实际工作中能起到推动业务和 IT 加强沟通的作用。</p><p></p><p>虽然目前从组织结构上看，业务和 IT 是分开的，但供应链数字化委员会每两周进行一次共创会议。会上，委员会成员一同就业务架构梳理、业务能力梳理、数字化转型内容评估、顶层架构设计等话题进行讨论，并推导出所需的业务能力和项目内容。</p><p></p><p>比如在委员会最初成立之时，为了尽快规划顶层架构设计，为数字化转型提供制度供给的保障，数字化中心需要率先跟业务侧直接对接，让业务侧的“一把手”或核心管理层输入一些顶层战略，并形成业务架构和应用架构。随后再把这些业务构想结合行业趋势、国家政策导向以及自身能力期望，转变为数字化场景，逐渐找到更清晰的定位和发展脉络。</p><p></p><p>“除了每双周一个例会，还有月度会，而且供应链的‘一把手’每次都会参加。”张炜提到，对于数字化，“一把手”甚至比 IT 部门还要着急，会督促 IT 侧去推进数字化，有些时候 IT 部门都感到应接不暇。</p><p></p><p>这一切也导向了一个令人欣慰的变化。过往信息化项目的验收通常是由 IT 人员负责，现在很多时候变成了业务人员去介绍项目成果，比如由供应链的采购人员或者物流人员，对 IT 系统的实施思路和实施效果进行汇报。</p><p></p><p>张炜强调，“六大方向”数字化转型思路的践行离不开业务人员的参与。“我们发现，很多做得比较优秀的供应商，在数字化过程中往往会重视业务人员的数字化能力培养，甚至有些企业的核心数字化团队，其大部分成员是源自业务部门。”</p><p></p><p>除了业务人员，数字化也对 IT 人员提出了更高的要求。原先 IT 人员都是埋头做信息化项目的交付，按传统的产品交付制度，只要交付了某个功能或应用就基本完成任务，因此鲜少会去思考项目对业务带来的实际价值、能否提升竞争力等比较深层的问题。</p><p></p><p>如今，如果 IT 人员不主动拥抱数字化转型，不主动了解业务以及提升业务架构设计能力，那 IT 团队就容易被边缘化，沦为名副其实的“外包团队”。</p><p></p><p></p><h2>数字化成熟度模型：认清现状</h2><p></p><p></p><p>对于数字化中心而言，也许一年下来做的项目多达数十个，但多数是站在所在业务部门的角度考虑，只做到了“在线化”，还没有做到更全面的“数字化”。</p><p></p><p>因此，尽管吉利汽车供应链的数字化工作初见成效，但张炜表示现阶段依然任重而道远。尽管有了大的战略方针，但具体到落地，如何把控各业务数字化的进展，及时找出推进数字化不利的可能原因，以及要采取的相应措施，并非易事。</p><p></p><p>为此，2022 年 6 月，吉利汽车构建了数字化成熟度评估模型，分别从 5 个等级去评估“数字化转型准备度”和“业务能力数字化成熟度”。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/99/58/99fb6f05d916276bd7b3f652c7d38958.jpeg\" /></p><p></p><p><a href=\"https://xie.infoq.cn/article/d485ccf9cd64cbb1410b0991c\">数字化成熟度评估模型</a>\"是一种用于评估组织在数字化转型过程中所处成熟度水平的模型。它可以帮助组织更好地理解自身的数字化状态，识别其存在的瓶颈和发展机会，从而更好地指导数字化转型的过程和路径。有了这个模型，各业务单元的晋级目标也就更清晰。</p><p></p><p>张炜表示，依据该数字化成熟度模型进行评估，目前吉利汽车集团下多个板块的业务能力成熟度都处于 B 级到 C 级之间，包括供应链体系的团队。以满分 5 分来看，目前采购、物流和 SQE 3 个实体单位的平均分大约为 1.8 分，大部分还处于审批在线级的阶段，部分已处于流程在线级。</p><p></p><p>“2023 年，供应链团队会朝着‘全面数字化级’目标努力，同时形成局部‘智能运营级’，希望与业务一道通过吉利数字化转型的实践，2023 年实现尽可能多的业务能力达到全面数字化的水平。”张炜说道。</p>",
    "publish_time": "2023-02-17 15:25:16",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "全球都为ChatGPT疯狂，它到底是风口还是虚火？深度解读风暴眼中的ChatGPT | 直播预约",
    "url": "https://www.infoq.cn/article/5lzBBTLf5ddX8974MNVo",
    "summary": "<p></p><p></p><blockquote>火爆全球，ChatGPT 何以狂飙？</blockquote><p></p><p></p><p></p><h2>主题介绍</h2><p></p><p></p><h4>直播主题：</h4><p></p><p></p><p>《极客圆桌派：狂飙的 ChatGPT》</p><p></p><h4>直播时间：</h4><p></p><p></p><p>2023 年 2 月 20 日 19:30-21:30</p><p></p><h2>直播背景：</h2><p></p><p></p><p>自去年 11 月底正式发布以来，OpenAI 最新的 AI 聊天机器人 ChatGPT 火出天际，成为现象级应用，在全网话题度狂飙。</p><p></p><p>就连马斯克都在感叹，“很多人疯狂地陷入了 ChatGPT 循环中”，“ChatGPT 好得吓人，我们离强大到危险的人工智能不远了”。</p><p></p><p>ChatGPT 就像是一个无所不知的虚拟体，它能回答各种问题，而且总能给到让人满意，甚至超过预期的答案。ChatGPT 的应用也频频出圈，它还能写代码、改 Bug、创建编程语言、构建虚拟机，甚至写毁灭人类计划书...ChatGPT 展示出的强大的能力和无限可能，让人们看到，通过 ChatGPT 这样的技术方案解决很多任务的潜力。</p><p></p><p>以 ChatGPT 为代表的新一代聊天机器人开始广泛应用人工智能，这波浪潮有望重塑甚至取代传统互联网搜索引擎。ChatGPT 在解决各种问题上的能力超出很多人意料，因此很多用户都表示 ChatGPT 可以取代 Google 等搜索引擎和编程问答社区 Stack Overflow 等。</p><p></p><p>不久前，达摩院基础视觉负责人赵德丽在接受 InfoQ 采访时表示，以前谷歌等搜索引擎做搜索和检索，只是找已经存在的信息，ChatGPT 的应用，实现了从信息的搜索到信息的创造这样一个范式的转变，从算法能力上看，它取得了一个质的飞跃。短期来看，ChatGPT 有望成为或者辅助像谷歌这种传统信息检索的强有力的工具；长期来看，它有望发展成为 AI 系统级的服务。</p><p></p><p>自 ChatGPT 走红后，全球互联网大厂、创业公司纷纷加码布局，一场关于 ChatGPT 的军备竞赛已然拉开。</p><p></p><p>搜索引擎大战迅速爆发。在国外，谷歌加急推出了 ChatGPT 的竞争对手—人工智能聊天机器人 Bard Bard；微软已经宣布推出了由 OpenAI 提供技术支持的最新版必 Bing 索引擎。在国内，百度将在 3 月推出类似 ChatGPT 的产品— 文心一言的消息早已传遍全网。除了百度，几家中国初创公司也在探索生成人工智能。</p><p></p><p>ChatGPT 蹿红的速度，堪称前所未有。ChatGPT 上线仅仅几天，其用户就已经突破 100 万大关。2 月 1 日，瑞银发布研究报告称，ChatGPT 在 2022 年 11 月推出后，今年 1 月的月活跃用户估计已达 1 亿，成为历史上用户增长最快的消费应用。</p><p></p><p>“在互联网领域发展 20 年来，我们想不出有哪个消费者互联网应用比它上升速度更快，”瑞银分析师在报告中写道。</p><p></p><p>ChatGPT 出现对 AI 界来说，有着十分重要的意义。清华大学计算机科学与技术系长聘副教授黄民烈认为，“ChatGPT 宣示着无缝人机交互时代的来临。过去我们讲 conversation as a service （caas）还停留在纸面，但实际上今天，无论是开放域聊天，还是通用任务助理（ChatGPT）都在强烈地表明这一点”。</p><p></p><p>ChatGPT 的出现，其实不亚于阿尔法狗曾经在人工智能界带来的影响力。可以看到，ChatGPT 正在引领新一波 AI 浪潮。</p><p></p><p>让全网沸腾的 ChatGPT 到底有什么魔力？ChatGPT 具有哪些颠覆性的创新？其落地和商业化应用的前景几何？对于科技界来说，ChatGPT 的出现到底会带来哪些改变？ChatGPT 为什么是 OpenAI 最先做出来？爆红之下，有多少泡沫？...</p><p></p><p>我们试图找到这些问题的答案。于是，InfoQ 发起了一场《极客有约》特别栏目《极客圆桌派：狂飙的 ChatGPT》，我们邀请了多位 AI 领域的资深技术专家一起共同探讨 ChatGPT 的现在和未来。</p><p></p><p></p><h2>直播核心议题：</h2><p></p><p></p><p>人们会什么会觉得 ChatGPT 非常神奇？ChatGPT 特点讨论：哪些是创新？哪些是颠覆式创新？ChatGPT 的落地与商业化局限性Generative AI 和 ChatGPT 的关系。ChatGPT 的军备竞赛还有入局机会吗？这场游戏该怎么玩？为什么不是先出现在中国？中国版 ChatGPT 还会远吗？ChatGPT 能颠覆搜索引擎吗？除此以外，还有哪些可能探讨机会：对行业 / 大公司 / 创业公司 / 对互联网科技从业者</p><p></p><p>预约</p><p>本期极客有约特别策划之《极客圆桌派：狂飙的 ChatGPT》。</p><p>视频号</p><p>&nbsp;嘉宾介绍</p><p>圆桌主持&amp;嘉宾：</p><p>Mingke，MRS.ai 联合创始人兼CEO，组建面向未来的智能网络，《人工智障》系列作者。</p><p>圆桌嘉宾：</p><p>鲍捷，文因互联董事长，创始人。爱荷华州立大学（Iowa State University）博士，伦斯勒理工学院（RPI）博士后，麻省理工学院（MIT）分布式信息组（DIG）访问研究员。曾任三星美国研发中心研究员，曾任 W3C OWL(Web 本体语言) 工作组成员，参与撰写了 OWL2 知识图谱语言国际标准。现任 W3C（万维网联盟）顾问委员会委员、中国中文信息学会语言与知识计算专业委员会委员、中国人工智能学会心智计算专委会委员、金融知识图谱工作组主席、中文开放知识图谱联盟 (OpenKG) 发起人之一，国际 Data Intelligence 杂志编委。</p><p>张晴晴，Magic Data 创始人 &amp; CEO。曾任中国科学院声学研究所副研究员，是对话式 AI 先行者和 Data-Centric MLOps 引领者。</p><p>祝海林，Kyligence 技术合伙人 / 资深数据架构师、新一代开源编程语言 Byzer 的作者，拥有 13+ 年技术开发经验。一直专注于 Data + AI 融合方向，致力于帮助工程师们从根本上提高数据平台落地和 AI 工程化的效率。</p><p>&nbsp;如何看直播？</p><p>扫描下图海报【二维码】，预约 InfoQ 视频号，直播开始有提醒。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/76/76c8d0af3d5657feed7c1e71d5dc9e99.png\" /></p><p></p><p></p><h2>如何向讲师提问？</h2><p></p><p></p><p>点击此处：<a href=\"https://www.infoq.cn/form/?id=907\">https://www.infoq.cn/form/?id=907</a>\"填写提问表单，讲师会在直播中为你解答：</p><p></p><h2>更多福利</h2><p></p><p></p><p>除了分享干货，直播进行中，我们会在参与直播的同学安排幸运观众抽奖福袋，赠送 InfoQ 周边产品！敬请期待哦～</p>",
    "publish_time": "2023-02-17 16:03:44",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "铸基会议 | 2023年中国信通院铸基计划“集成平台即服务（iPaaS）系列标准”研讨会成功召开",
    "url": "https://www.infoq.cn/article/Ui3JSdRN2cSbqkPDjoJH",
    "summary": "<p>2023年<a href=\"http://www.caict.ac.cn/\">中国信通院</a>\"铸基计划“集成平台即服务系列标准”研讨会于2023年2月13日在中国信息通信研究院成功召开，来自浪潮通软、<a href=\"https://www.360.cn/\">360</a>\"、<a href=\"https://www.asiainfo.com/zh_cn/index.html\">亚信科技</a>\"、<a href=\"http://www.yonyou.com/\">用友网络</a>\"、<a href=\"https://www.dingtalk.com/\">钉钉</a>\"、<a href=\"http://www.primeton.com/about/\">普元科技</a>\"、<a href=\"https://authing.co/\">AUTHING</a>\"、<a href=\"https://www.clickpaas.com/\">ClickPaas</a>\"、<a href=\"https://www.infoq.cn/\">InfoQ</a>\"、北京银行、工商银行、<a href=\"https://www.uyun.cn/\">广通优云</a>\"、<a href=\"https://www.hengshi.com/\">衡石科技</a>\"、<a href=\"https://www.teamsun.com.cn/\">华胜天成</a>\"、明源云、<a href=\"https://www.bingosoft.net/home/index.html\">品高软件</a>\"、炎黄盈动、致远互联、<a href=\"https://www.gientech.com/\">中电金信</a>\"、民生银行、<a href=\"http://www.harmonsw.com/h-col-107.html\">鸿雪科技</a>\"等企业的代表线下线上同时参与了本次会议。中国信通院泰尔终端实验室数字生态发展部工程师曹海啸主持本次会议。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fa/faa1f8ae687847689c3948fd92288c8a.png\" /></p><p></p><p>中国信通院泰尔终端实验室王景尧博士到会致辞。王景尧表示，建立标准和评测认证是提高数字化产品与应用质量的关键环节，也是铸基计划高质量数字化推进专项行动的重要步骤，iPaaS 可以帮助企业连接应用程序、自动化业务流程，并从分布在不同系统中的数据生成报告和分析，对于企业数字化转型过程中实现应用程序现代化非常重要。同时，在集成、安全、服务、可扩展性等方面需要凝聚多方共识，形成行业标准助力行业高质量发展。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d2/d2584959f68c9cbc753a5062997bcb98.jpeg\" /></p><p></p><p>中国信通院泰尔终端实验室吴荻博士对中国信通院“铸基计划-高质量数字化转型推进行动”进行了介绍。“铸基计划”发起成立以来，专注于链接数字化转型的供给方和需求方，在企业直播、即时办公、协作文档、5G消息、组装式应用等多个企业服务热点领域开展标准制定、测试评估工作，持续推动数字化转型供给侧高质量发展。同时，铸基计划聚焦需求侧在转型中遇到的选型问题，通过揭榜行动、全景图等方式，帮助企业更好的遴选数字化产品及服务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d5/d5f0d6ddea6f0f417ba28c6c6342ecd3.jpeg\" /></p><p></p><p>&nbsp;</p><p>中国信通院泰尔终端实验室专家曾晨曦对集成平台即服务系列标准的框架和内容进行了介绍和解读，该系列标准将从供给侧和需求侧出发，建立集成平台即服务评测体系和评估标准，基于iPaaS在总体框架、API全生命周期管理、API网关、安全能力、自研能力等方面明确要求、目标、适用主体等，保障行业健康持续发展。参会专家结合自身企业特点、行业热点、产品安全痛点，就此次讨论标准的完整性、适用性、全面性进行了热烈讨论，为标准内容提出了许多宝贵建议。后续中国信通院将整理此次会议上专家提出的意见，牵头对标准内容进行调整和完善。</p>",
    "publish_time": "2023-02-17 16:19:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "终于承认了，因存在事故风险，特斯拉在美召回36万辆配备“完全自动驾驶系统”的车辆",
    "url": "https://www.infoq.cn/article/QtGA7QPzlFc1l2wORpgP",
    "summary": "<p>2月17日，据外媒报道，特斯拉正着手召回超362000辆配备其“完全自动驾驶”驾驶辅助系统的车辆。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4a/4a1d41dbe89302f9c3b21b2b3fab22d6.png\" /></p><p></p><p>特斯拉同意组织召回，并计划通过空中更新解决这些软件缺陷。</p><p>&nbsp;</p><p>此前，政府监管机构发现这套系统增加了发生交通事故的风险。美国国家公路交通安全管理局表示，这项技术可能导致撞车事故，并提到特斯拉公司并未发现因该缺陷造成的任何死亡或伤害。</p><p>&nbsp;</p><p>国家公路交通安全管理局在周四官网发布的文件中强调，特斯拉公司的“完全自动驾驶”技术能够自行导引、加速、制动和更换车道，使车辆以“违规或无法预测的方式”在十字路口处超速通过。</p><p>&nbsp;</p><p>经过交管机构的测试和分析，在城市街道上引导汽车的系统中存在一个组件，可能导致“对交通安全法规的依从性不足，进而引发不合理的汽车安全风险。”该机构表示，特斯拉并未发现因这项缺陷造成的任何死亡或伤害。</p><p>&nbsp;</p><p>交通安全管理局认为，召回所解决的只是涉及“完全自动驾驶”的相关问题，目前其正在进一步调查特斯拉的Autopilot系统及其他非前沿技术。</p><p>&nbsp;</p><p>千万别被这些产品的名字给唬住，其实“完全自动驾驶”跟Autopilot都做不到让汽车真正自动行驶。特斯拉要求车主随时准备接管车辆操作，包括手必须一直放在方向盘上、眼睛也得时刻盯紧路况。</p><p>&nbsp;</p><p>安全专家经常给特斯拉及其他汽车制造商提供的技术系统挑毛病，这也引起了不少用户的担忧。他们最害怕的就是汽车有自己的想法，而坐在车上的人却束手无策，这样一旦发生技术故障或特殊交通状况就会引发灾难性后果。</p><p>&nbsp;</p><p>交通安全管理局去年夏季曾发布数据，显示自2021年7月1日至2022年5月15日，共发生近400起涉及使用高级驾驶辅助技术的事故，造成6人死亡、5人受伤。由于市场份额可观，特斯拉造成了其中273起撞车事故并导致5人死亡。</p><p>&nbsp;</p><p>交通安全管理局周四指出，特斯拉已经同意组织召回，并计划通过对受影响车辆开展空中更新来解决这些缺陷。此次召回的共有4种车型，涵盖2016年至2022年间生产的车辆。特斯拉将在最晚4月15日之前通过邮件向车主发送召回通知。</p><p>&nbsp;</p><p>但特斯拉并不同意监管部门的分析，称此次召回属于“出于谨慎态度”的自愿行为。</p><p>&nbsp;</p><p>目前，特斯拉并未回应。</p><p>&nbsp;</p><p>自2016年以来，交通安全管理局曾调查过41起涉及特斯拉高级驾驶辅助系统的撞车故事。其中有14起引发重大后果，共致19人死亡。</p><p>&nbsp;</p><p>参考链接：</p><p>&nbsp;</p><p><a href=\"https://www.nytimes.com/2023/02/16/business/tesla-recall-full-self-driving.html\">https://www.nytimes.com/2023/02/16/business/tesla-recall-full-self-driving.html</a>\"</p><p>&nbsp;</p><p><a href=\"https://www.theguardian.com/technology/2023/feb/16/tesla-recall-full-self-driving-cars\">https://www.theguardian.com/technology/2023/feb/16/tesla-recall-full-self-driving-cars</a>\"</p>",
    "publish_time": "2023-02-17 17:21:50",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "谷歌面临企业文化危机？出走创业者痛批谷歌效率低下、管理不善，员工陷入官僚程序的“迷宫”中",
    "url": "https://www.infoq.cn/article/tdGOpkSMOYhpr0OYwRmJ",
    "summary": "<p></p><blockquote>在谷歌工作 3 年后，低代码平台创始人 Praveen Seshadri 意识到这家曾经伟大的科技公司正在止步不前。</blockquote><p></p><p></p><p>2014 年 3 月，Praveen Seshadri 和朋友共同创立了低代码平台 <a href=\"https://www.infoq.cn/article/Qc1IXkyhKTzxmk3YESxl\">AppSheet</a>\"。AppSheet 允许用户使用谷歌 Drive、DropBox、Office 365 和其他基于云的电子表格和数据库平台等数据源创建手机、平板电脑和 Web 应用程序，此外，该平台还可用于广泛的业务用例，包括项目管理、客户关系管理、现场检查和个性化报告。</p><p></p><p>2020 年 1 月，谷歌正式收购 AppSheet。根据 PitchBook 数据，AppSheet 曾以 6000 万美元估值筹集超过 1700 万美元，但谷歌并未披露此次交易的具体金额。AppSheet 加入谷歌云团队，其服务将扩展到谷歌的 Sheets、表单、Android 地图和谷歌分析集成，并继续为其现有和新客户提供服务。谷歌将此次收购视为通过无代码及其 API 管理来扩展其开发理念。</p><p></p><p>与 AppSheet 团队一道，创始人 Seshadri 也加入了谷歌。按照 Seshadri 的说法，谷歌的收购团队和高管都很善待 AppSheet 团队成员，AppSheet 团队也以极大的热情加入谷歌，致力于将 AppSheet 集成到谷歌中，并使其取得成功。</p><p></p><p>但在首个三年合同到期后，Seshadri 还是选择离开谷歌，因为他发现，这家曾经伟大的科技公司正止步不前，他亲眼见证了这家伟大的公司是如何慢慢衰弱下去的。Seshadri 坦言，“我们觉得谷歌还有希望，只是必须尽早实施干预。”</p><p></p><p>Seshadri 在 Medium 上发表了一篇措辞严厉的帖子，详细描述了他在公司工作期间遇到的问题。他指出，谷歌的问题不是源于它的技术，而是它的文化。比如，谷歌陷入了“批准、启动流程、法律审查、绩效审查、执行审查”和其他官僚程序的迷宫中，虽然员工有能力，但他们“季度环比、年环比完成的工作很少”。</p><p></p><p>关于这一点，<a href=\"https://www.infoq.cn/article/web-development-ten-years\">Waze</a>\" 创始人 Noam Bardin 等其他一些前同事也对此早有论述。</p><p></p><p>Waze 前首席执行官 Noam Bardin 于 2021 年离开谷歌，他曾在一篇博文中表示，员工没有动力去构建谷歌产品。“推动员工职业发展的是产品，而不是激情、使命或经济游戏规则的改变者。与产品增长相比，个人更注重晋升。选择哪种产品的判断主要依据于是否能在将来得到晋升，因此我们开始以错误的心态进行工作——将 Waze 视为垫脚石，而不是被使命感所驱使。”</p><p></p><p>近日，Waze 创始人 Noam Bardin 也在 LinkedIn 上分享了 Seshadri 的帖子，并补充说：“这在几年前就很明显了——问题是，只要股票在上涨，就没有人在乎”。</p><p></p><h2>“问题只是暴露在技术端而已”</h2><p></p><p></p><p>据 Seshadri 介绍，谷歌拥有超过 17.5 万名能力出众、薪酬可观的员工，但这些人却一天一天基本不干正事——就像“老鼠”一样，被困在了谷歌这座迷宫当中。</p><p></p><p>审批、启动流程、分类、OKR、H1 计划连着 H2 计划、全体会议和无休止的重复……“老鼠”们会定期得到自己的“奖励”（福利、奖金、精美的食物、丰厚的津贴等）。虽然也有少数不安分的“老鼠”想要创造、满足个人的充实感并扩大影响力，但谷歌的制度会抚平他们这种不必要的欲望，告诉他们不要瞎折腾。</p><p></p><p>一日谷歌人，一生谷歌人，混就完了。</p><p></p><p>但这样的整体氛围，也开始回头重塑谷歌的精神与气质。正如 Deepak Malhotra 提出的警告，长此以往，就不再是迷宫困住“老鼠”，而成了“老鼠”困住迷宫。</p><p></p><p>Seshadri 在文中表示，目前正是谷歌硬抗 <a href=\"https://www.infoq.cn/article/7oYfCjaI0rbbpGsBSYWk\">OpenAI</a>\"+ 微软组合拳的艰难时刻。大多数人都觉得这只是技术层面的挑战，但问题只是暴露在了技术端而已，这背后肯定有更深层的因素。谷歌近期的裁员也引发了公司内部的焦虑情绪，很多员工觉得这是管理层的失败、或者说在向激进派投资方投降。这类观点的存在，从某种程度上也证明管理层和员工普遍缺乏自我认知。</p><p></p><p>Seshadri 认为，谷歌的一切基本问题都由文化引起，并在各个层面有所体现。</p><p></p><h2>谷歌的问题源于企业文化</h2><p></p><p></p><p>在 Seshadri 看来，谷歌面临着四大核心文化问题，而这些都是谷歌在长期依赖“广告”这台无成本印钞机后的必然结果。这台机器不断吐出钞票，让每个谷歌人都活得滋润、笑得开心，遮蔽掉其他一切问题。</p><p></p><p>具体来说，这四个核心文化问题是：没有使命、缺乏紧迫性、活在妄想中、管理不善。</p><p></p><h4>没有使命：过于敬畏风险</h4><p></p><p></p><p>在现在的谷歌里，还有人在工作时考虑这其实是一家“组织全球信息”的企业吗？ Seshadri 认为，谷歌失去了自己想要服务谁，以及为什么要服务他们的基本信念。</p><p></p><p>Seshadri 曾在一家初创公司工作过 8 年，他的答案很明确——始终为用户服务。但很少有谷歌员工认为自己是在为客户或者用户服务，因为他们产出的大多是过程（例如负责审查隐私设计）或者技术（负责保持 CI/CD 系统正常运转）。他们顶多可以说是为经理或副总裁服务，为其他内部员工服务。有些人甚至专为某些谷歌技术或文档资料服务。</p><p></p><p>**这是个封闭的世界，几乎每个人都只为其他谷歌员工负责，所以反馈循环就只基于同事和上司对工作产出的看法。**在这样的环境下，努力工作或者多想多试并不会创造出任何新价值，甚至反而对升迁之路有害。</p><p></p><p>Seshadri 认为，虽然谷歌一直把“敬畏用户”和“敬畏机会”两大核心价值观挂在嘴边，但实际上从故意设计出来的系统和流程来看，个中真相其实是“敬畏风险”。控制风险胜于一切，毕竟只要企业不发生过多动荡，那谷歌就能继续捧稳“广告业务”这只金饭碗，一路在全球经济上升的大趋势中分得肥美的一块。但曾经知晓正确答案的谷歌这是在麻痹自己——在如今这个时代，潜在风险无处不在，根本就避无可避。</p><p></p><p>变更的每行代码都有风险，为了确保每行代码都完全规避风险（忽略能不能让用户满意），就得极大增加相应流程；发布的一切都有风险，所以要用大量审查和批准（任何新功能的启动都经经过 15 道以上批准，堪比 NASA 发射火箭）来保证对最小产品做出最小变更；任何不够明确的决策都是风险，因此打压任何不符合集体共识和传统经验的行为；不同于以往行事方式的任何变化都是风险，所以必须固守在原地；任何抱有不满的员工都是“刺头”、是职场风险，因此管理者的目标就是把员工满意度维持在 100%。即使业绩表现不佳，也要装出一副大度的样子（至于个人客户，他们的任何抱怨都不属于风险，只有大客户的意见才是意见，所以客户满意度就成了仪表板上的一条空头指标）；但在行政管理链条上，任何有违上级意愿的分歧都是职场风险，所以我们要对副总裁永远说“是”，副总裁对高级副总裁永远说“是”。Seshadri 表示，如果能把关注点放在价值创造上，那整个套路都会随之改变。如果谷歌能每天追问“我们在为谁创造价值”，那公司上下的运作逻辑都会不同。如果每份半年度计划都能确定“为全世界产生了多少价值”，那每位员工的思维方式也将随之调整。总之，如果谷歌能以价值为导向以不断扩大自己的影响力，那员工会更愿意为这家公司付出一切。</p><p></p><h4>缺乏紧迫性：慢是原罪</h4><p></p><p></p><p>谷歌提出的一大核心价值是“互相尊重”。这话可以做两种解释，Seshadri 更倾向于“尊重每个人的独特优势，并思考如何让每个人能最大程度发挥自己的潜力和影响。”但很遗憾，因为各个部门都完全缺乏改变现状的意愿，所以“互相尊重”被理解成了“找到一种能囊括所有异见的办法”。</p><p></p><p>于是乎，本应发挥积极作用的包容性文化（好处是一切信息和机会都有展示的空间）跟高度分布化的所有权结构（坏处是各方很难统一意见）交织起来，导致任何一项决策都要经历漫长且复杂的审批过程。如果把这套制度整理成一种算法，那可以称之为“最谨慎的胜利”，因为几乎总有人想在毫发无伤的前提下赢得战争。另外，因为参与者的知识、能力和立场差异很大，所以合作起来特别不舒服，也导致很多人干脆直接摆烂、什么都不干。于是乎，只有跟传统经验和既有路径完全相符的预案才能顺利通过，其他任何尝试都会被批为冒进。</p><p></p><p>在现在的谷歌预案当中（例如申请 A 团队着手开发 B 产品），最高优先级永远是寻求风险最低的可行性。每位经理都想用“按部就班、不要过度交付”为借口掩盖自己原地踏步、毫无建树的本质。Seshadri 表示自己还没在谷歌遇到任何一个愿意“过度交付”的工程团队。</p><p></p><p>这种愚蠢源自一种通过调低期望来实现管理的企业文化。甚至会有内部文件公开嘲讽“英雄主义”，并断言这样的“英雄”不仅不该鼓励，其他员工最好能主动劝阻。如果某人愿意加倍努力地工作，其实会面临很大的阻力。如果有人说能在一个月内完成手头的项目，经理会提醒把计划定得现实一点——于是给员工留了四个月，并向副总裁报告说需要六个月。很多人说事情做得越慢，就代表越稳健、越优质。但是慢代表不了正确，慢就是慢。</p><p></p><p>总的来看，这就是一种岁月静好式的慢性自我毁灭，毕竟没有什么值得为之奋斗。而且这种负面氛围有着极强的感染性，会很快侵蚀那些原本想为客户考虑、或者还有点新念头和创造力的员工。这是一种超越性的抑制倾向，任何个人层面的冲动和探索都会被“粘稠”的周遭环境所消解。至于职业规划，就是公司定下的明确阶梯，任何员工都必须沿路前行。L5 软件工程师能做什么、不能做什么，都有相应的明确要求，所以一切唯职级论。</p><p></p><p>至于“客户”，根本不需要操心，操心了也得不到任何赞赏。半年前官方计划中没有的东西，之后也不会被接纳。一旦有人非要调整和增补一点部署，项目经理、产品经理、用户体验、市场营销乃至IT等各个部门都会一拥而上，怒斥你这乱臣贼子。不要折腾，只要混上两年，你就会自然晋升。正如 Waze 创始人 Noam Bardin所言，尽管每个人的出发点都是好的，但这套体制拥有自己的动态，其特征就是“没有什么值得为之奋斗”。</p><p></p><h4>活在妄想中：长期原地踏步</h4><p></p><p></p><p>Seshadri 表示，在谷歌内部，存在着“我们永远争第一”的集体幻想，或者说妄想。之所以说是虚妄，因为大家只是站在巨人的肩膀上享受到了胜利的果实，体验到了凶猛搏杀后夺取来的一片安乐净土。最终，当初积累的优势开始消失，但这种幻想或者妄想却挥之不去。大家不会每天考虑怎么做得更好，如何提升客户体验和增加工作效率。相反，大家觉得自己目前已臻完美，保持现状是唯一的选择。于是宣传成了头等大事，老员工需要靠这个保持状态，新员工需要靠这个找到感觉。在“这就是我们谷歌的行事风格”的灌输之下，大多数人其实已经意识到曾经的搜索巨头已经效率低下、愚蠢无能。</p><p></p><p>比如，谷歌曾有一套独特的内部技术堆栈，名为“Google3”。公司一切大规模消费级产品都建立在这套堆栈之上。而公司里的一大妄想就是谷歌拥有世界上最好的技术栈。十年前这话可能是真的，但现在绝对不是。其他很多企业都在不依靠特定堆栈的前提下，也建立起了大规模消费服务。这说明什么？说明 React、Twilio，包括Intercom 和 Mixpanel 等 SaaS 服务也找到了同等水平，而且根本不依赖于谷歌的技术实现路径，而且跟外部的整体环境高度一致。这种一致性，让他们能更好地雇用人才、更快推动创新。</p><p></p><p>此外，谷歌的内部流程无疑已经过时。就像 20 年前的瀑布式开发流程一样，如今的谷歌还是被困在这个“时间陷阱”里。团队中的所有高层管理者每半年都要拿出整整一个月来做规划，一个月休假，还有一个月做绩效评估。在这种情况下，谷歌一年能完成一次策略调整就算是谢天谢地了。所以人们找到了最适合自己的办法——什么都不做，什么都不错，福利照发奖金照领。</p><p></p><p>谷歌倒是在口号里强调“敬畏用户”，但对客户成功率根本就不重视。除非是那种一掷千金的大主顾，否则大多数人被分配到的只是技能平庸的支持工程师，他们对产品的了解甚至还不如客户自己。更要命的是，谷歌允许他们保持这种无知无用的状态，只要在 30 分钟以内做出回复，仪表板都会亮起成功回应客户的小绿灯。各个职级的员工愿意花几百个小时准备一场述职演讲，但绝不愿意浪费十分钟认真听听客户在抱怨什么。</p><p></p><h4>管理不善：糟糕的招聘与绩效评估</h4><p></p><p></p><p>Seshadri 曾在 2005、2009 年两次通过谷歌面试，虽然最终都没有入职，但在当时，谷歌还是给他留下了独特的印象。那时候的谷歌还有冲劲，面试官们想听 Seshadri 对于改变世界抱有怎样的雄心——这就是那时的谷歌，这就是那时他们认同的人才。而现在，这些似乎不复存在。</p><p></p><p>尽管人员持续流失，但短短几年内谷歌的规模还是增加了一倍以上。 Seshadri 在2020 年初加入谷歌，到 2022 年，Seshadri 已经比半数谷歌员工的资格都要老了。Seshadri 认为，这样的流失率其实大有问题，催生出的消极员工会带出更多消极员工。当然，“消极”这个判断是主观的，每个人在做自己的工作时都不消极，但他们也没能最大化自身优势并尽可能消除自己的劣势。</p><p></p><p>谷歌的面试一直难度很大，只有非常优秀的人才可以顺利通过。但这些好材料其实大部分被浪费了，也就是所谓“面试造火箭，入职打螺丝”。这个问题的根源在于招聘中层主管甚至是高管人员时体现出的考核思路。到了这个级别，面试过程就是完全主观的了，面试官的素养基本决定了一切。而且，谷歌云其实就是靠直接从其他企业那挖中高级人才而迅速发展起来的。但大多数情况下，在小公司里让你出类拔萃的技能，跑到谷歌这边往往就没什么用处。人们之所以愿意接受邀约，要么是觉得原先的公司烂，要么是觉得谷歌更好。但无论如何，四面八方涌来的新成员冲垮了谷歌原本稳定的企业文化，最终杂烩出一锅难以描述、功效未知的混沌药方。</p><p></p><p>招聘工作还有内化的一面，也就是人才的管理和留存。但谷歌云的实际作法是等员工已经不开心了、想走了，才提交一条招聘请求。这种招人时全力以赴，用人时如弃敝履的行为无疑是种巨大的浪费。</p><p></p><p>正是由于管理能力各不相同，所以对绩效评估的解释在各团队间也有很大差别。但谷歌员工还是相信着那个十年前的“神话”——一切绩效评估都是标准化的，谷歌任何团队中的任何同职级成员，都和你拥有相同的业务水平。既然制度相信这是真的，那团队在自我崩塌前也不会搞内部评议，大家遇到问题时踢踢皮球也就行了。</p><p></p><p>**战略和战术性决策也反映出谷歌的领导力缺失。**谷歌内部的决定往往来自高职级者，而非高知识者。几乎没有哪条重要决策来自副总裁以下的群体，只有高管才有权力自由发表意见。更糟糕的是，这帮纯管理层特别喜欢从其他公司那照搬创意，做出关键决策时既不了解产品、也不熟悉对应的客户。而且，他们很少把策略表述得清楚明确（这样会构成职业风险）。如果没能立即转化落地，那审查往往会随着管理层的人事变动而左右摇摆。</p><p></p><p>一般来说，上一任副总裁提出的内部项目往往会被下任副总裁直接干掉。至于全体中层管理者，没有目标、没有前瞻，谁是领导他们就听谁的。反正两年固定晋升，求的就是个稳字。</p><p></p><h2>谷歌能否成功实现“软着陆”？</h2><p></p><p></p><p>Seshadri 认为，**谷歌不能再靠回避风险来追求成功了。前进的道路必然始于文化的转变，这是一场必须自上而下的变革。**谷歌高层管理者应该认真研究微软 CEO Satya Nadella 的管理心得，并执行类似的策略：</p><p></p><p>将管理工作与践行使命联系起来。这种关联要超越技术（例如 AI）或者绩效（比如谷歌云的收益），面向真实世界中的用户/客户做出积极的变化。谷歌人都是理想主义者，他们要求自己的工作有意义、有价值。他们需要相信自己的领导者正在追求切实的成果，而非假大空的口号。如果他们真的“敬畏用户”，那副总裁和董事应该取消每周一小时的会议，亲自参与到客户支持当中。总之，高层必须身体力行才能让普通员工感受到文化导向的力量。</p><p></p><p>和平时期的将军，名不副实的精英。谷歌需要定义值得为之共同努力的目标，并奖励那些愿意牺牲个人利益为此奋斗的员工。只有这样的斗争，才能孕育出值得珍视和奖励的英雄。最出色的人永远胸怀冲动，这股冲动将支持他们在合适的时机下做出巨大而独特的贡献。</p><p></p><p>很多员工确实靠熬年头坐上了比较高的位置，这种现状暂时无法改变。他们往往已经跟产品和团队失去了联系，而由此衍生出的董事、规划经理、产品经理、幕僚长等职位进一步加剧了矛盾。答案很简单，谷歌可以加大对经理层级的裁员力度并削弱组织结构的深度。接下来的裁撤可以主要针对经理、董事乃至副总裁。要想继续待在谷歌，每个人都要投入轰轰烈烈的生产劳动、再次成为有价值的贡献者，为了真正有价值的事物而奋斗。</p><p></p><p>Seshadri 希望那些中高层管理者可以用怀疑的眼光审视过去 25 年间谷歌积累下的一切“金科玉律”。那些与世隔绝的技术栈唯一的意义，就是让谷歌保持低下的运行效率。拥抱敏捷、拥抱精益开发，瀑布式开发早已腐朽。别再用“服务内部客户”之类的废话掩饰自己混吃等死的现实。去看看哪些产品值得做审查，然后快速把它们推向下一阶段。</p><p></p><p>谷歌需要的是具备独特才能、可以迸发耀眼光彩的员工，而不是那些高薪豢养起来的通用“零配件”。前者培养的是人才的上限，后者维持的是人才的下限，这个道理并不难理解。鼓励团队勇于向客户承诺，更勇于兑现承诺。客户想要什么很重要，副总裁想要什么不重要。</p><p></p><p>最后， Seshadri 呼吁各位谷歌员工别再把时间浪费在 memegen 内部论坛上了。这里贫乏空泛，任何声音都激不起一丝涟漪。照照镜子，看你自己能不能在团队、产品和客户的层面上做点积极的改变。这只是个人的小小发声，却必将成为唤醒谷歌巨人的震耳雷鸣。</p><p></p><p>谷歌还能不能成功实现“软着陆”——即通过逐步转变重获活力，且继续保持稳定增长？</p><p></p><p>其实大多数企业都没能做到，他们要么不可逆转地衰弱下去，永远活在自己曾经的辉煌阴影之下（例如 IBM）；要么快速崩塌，短时间内退出巨头行列（例如 AT&amp;T）。但微软是位成功者，这里既要有出色的领导决策、又需要不少运气。</p><p></p><p>Seshadri 认为，谷歌同样有机会。如果谷歌真能重燃自己的勃勃雄心，成为那位以“不作恶”和让世界更美好为宗旨的巨头，整个人类社会都将因此而受益。到那时，“老鼠”也将与迷宫和解，创造出一个没有相互围困的新时代。</p><p></p><p>参考链接：</p><p></p><p><a href=\"https://medium.com/@pravse/the-maze-is-in-the-mouse-980c57cfd61a\">https://medium.com/@pravse/the-maze-is-in-the-mouse-980c57cfd61a</a>\"</p><p></p><p><a href=\"https://arstechnica.com/gadgets/2023/02/app-founder-quits-google-says-company-doesnt-serve-users-anymore/\">https://arstechnica.com/gadgets/2023/02/app-founder-quits-google-says-company-doesnt-serve-users-anymore/</a>\"</p><p></p><p><a href=\"https://www.nytimes.com/2021/06/21/technology/sundar-pichai-google.html\">https://www.nytimes.com/2021/06/21/technology/sundar-pichai-google.html</a>\"</p>",
    "publish_time": "2023-02-17 17:23:42",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "YouTube CEO即将卸任，曾在Alphabet工作近25年",
    "url": "https://www.infoq.cn/article/m0OeQW5SINVA5Jsyeb6v",
    "summary": "<p>2月17日，据外媒报道，YouTube首席执行官苏珊·沃西基（Susan Wojcicki）宣布她将辞去流媒体视频服务的掌舵人一职。Wojcicki在<a href=\"https://www.infoq.cn/article/r8CLWdrPO9uFWNWz7kiq\">Alphabet</a>\"工作了近25年，她表示，正在开启“一个新篇章，专注于我的家庭、健康和我热衷的个人项目。”</p><p>&nbsp;</p><p>实际上，Wojcicki 从一开始就参与了 <a href=\"https://www.infoq.cn/article/PX7hUhtJmshxACEaYYgE\">Google </a>\"的工作。Google公司的创始人拉里·佩奇和<a href=\"https://www.infoq.cn/article/40yrDxcTp83fuwlFuaFK\">谢尔盖·布林</a>\"在 1998 年成立谷歌后不久就在Wojcicki父母的车库里设立了办公室。次年，Wojcicki成为谷歌的第一位营销经理。</p><p>&nbsp;</p><p>此外，Wojcicki还参与了最早的 Google Doodles项目，共同创建了 Google Image Search，并且是 AdSense（Google 的主要广告计划之一）的第一任产品经理。2006 年，她鼓励谷歌收购一年前推出的YouTube。八年后，Wojcicki 接管了 YouTube，成为为数不多的几位经营一家大型科技公司的女性之一。</p><p>&nbsp;</p><p>在 Wojcicki 任职期间，YouTube 成为<a href=\"https://www.infoq.cn/article/FB6BxlokIrMQgNLl3Vzt\">谷歌</a>\"和 Alphabet 越来越重要的一部分。仅该平台的广告收入就占公司上个季度总收入的 10% 以上。</p><p>&nbsp;</p><p>Wojcicki 在告别信中说，她副手尼尔·莫汉 (Neal Mohan) 将接任 YouTube 的新任首席执行官。Mohan 在 2007 年谷歌收购广告公司 Double Click时加入了这家公司。他在 2015 年成为 YouTube 的首席产品官，并帮助推出了 YouTube TV、YouTube Music、Premium 和 Shorts。Mohan 还领导了该服务的信任和安全团队。&nbsp;</p><p>&nbsp;</p><p>Wojcicki 表示，她不会立即离开 YouTube。“在短期内，我计划支持 Mohan并帮助过渡，这将包括继续与一些 YouTube 团队合作、指导团队成员以及与创作者会面，”她写道。Wojcicki仍将继续以顾问的身份参与谷歌和 <a href=\"https://mp.weixin.qq.com/s?__biz=MzIzNjUxMzk2NQ==&amp;mid=2247517674&amp;idx=1&amp;sn=98edafdf5dd6ec04a0db9e0437478768&amp;chksm=e8d47a28dfa3f33ec6dfd7a63169b04a2198e988577b09e9907055840ad834eb3209bbda2525&amp;scene=27#wechat_redirect\">Alphabet</a>\" 的发展。“这将使我能够利用我多年来积累的各方面的经验，为谷歌和 Alphabet 公司的投资组合提供建议和指导，”她指出。</p>",
    "publish_time": "2023-02-17 17:26:49",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AIGC应用持续升温！aiXcoder代码生成大模型正式开放API接口，开发者可共建智能编程工具",
    "url": "https://www.infoq.cn/article/KJwyZy7rFdZwbumRMHty",
    "summary": "<p>AIGC 是继PGC、UGC后新的内容生产形态。当下，AIGC 应用持续升温，AI在内容生成的渗透率也快速提升，输入自然语言就可自动生成图像、视频、代码以及 3D 模型等。AIGC作为生产力工具，正不断推动智能聊天机器人（ChatGPT）、智能编程机器人（aiXcoder）、数字人等领域发展，以高效率、高度智能化的方式满足用户的不同内容需求。</p><p></p><p>在AIGC的代码生成领域，日前，智能编程机器人提供商 aiXcoder首次开放了代码生成模型的API接口，与广大开发者共享服务、能力和数据。据了解，aiXcoder 专注于通过人工智能技术来提升软件研发的效率和代码质量，长期以来面向金融、军工、科技等领域企业提供国内领先的AIGC代码生成技术以及一站式智能化软件开发解决方案，包括代码编写、代码搜索、代码检测、代码修复等。</p><p></p><p>2022年6月，aiXcoder 宣布推出国内首个基于深度学习的支持方法级代码生成的智能编程模型——<a href=\"https://www.infoq.cn/article/v60479a7wA8Xryafdhho\">aiXcoder XL</a>\"，该模型能同时理解人类语言和编程语言，可根据自然语言功能描述一键生成完整程序代码(NL to Code）。</p><p>&nbsp;</p><p>现在，通过简单易用的API服务接口和工具，开发者即能体验并使用到aiXcoder XL代码生成模型的真正能力。</p><p></p><p>据了解，aiXcoder XL大模型API接口目前提供了三项核心编码能力：</p><p></p><p>1.「方法级」代码生成。aiXcoder XL模型“学过”海量代码，拥有强大的理解与生成能力，可以根据用户的中英文自然语言描述⼀键生成完整函数代码。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/b5/ec/b549b97821dff897c4ecfa38628df2ec.gif\" /></p><p></p><p>2.多行代码补全。根据用户已编写的代码，自动补全多行代码，直到整个方法完成。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/bf/41/bfd20de2e401979ffb289b2ab68c8d41.gif\" /></p><p></p><p>3.整行代码补全。根据已有代码自动推荐和补全整行及字、词组级别的代码。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/18/6c/189095440ecb2e73e5de871e8efccc6c.gif\" /></p><p></p><p>目前，aiXcoder XL代码生成模型的API接口已正式开放，开发者可前往<a href=\"https://aixcoder.com/nl2code/?completion=true\">aiXcoder官网</a>\"使用Web界面进行交互体验，也可<a href=\"https://github.com/aixcoder-plugin/doc/blob/master/aiXcoder_XL_API.md\">点击此处</a>\"，获取详细调用说明。</p><p><img src=\"https://static001.geekbang.org/infoq/35/3561a242b2663979e79c8dea229ffae0.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2c/2c16161bd04f7657df4d543c12e4ba10.png\" /></p><p></p><p>数据显示，目前aiXcoder智能编程产品已在多个国际应用市场发布，大模型累计调用次数突破200亿次，国际开发者用户数量超50万人。未来，aiXcoder将持续探索AI与开发场景的高效深度结合，以实现更大的用户价值。</p>",
    "publish_time": "2023-02-17 17:27:13",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AIGC创投火热，聆心智能宣布完成Pre-A轮融资，打造“超拟人大模型”| InfoQ快讯",
    "url": "https://www.infoq.cn/article/msiWSjQiHPFOLoNU9vVr",
    "summary": "<p>2月17日，InfoQ获悉，北京聆心智能科技有限公司（以下简称“聆心智能”）近日宣布完成Pre-A轮融资，本轮融资由SEE Fund领投，老股东超额跟投。</p><p>&nbsp;</p><p>据悉，聆心智能一直以来都致力于打造“超拟人大模型”，核心技术是具有可控、可配置、拟人特点的大模型，通过简单设置即可构造一个有知识、有个性、有风格的类人智能体。聆心智能的愿景是创造AGI（通用人工智能）时代的类人智能体，使得AI Companion进入人类生活的所有角落，科技向善为人类谋福祉始终是聆心智能的目标。</p><p>&nbsp;</p><p>聆心智能创始人黄民烈教授认为，未来的人工智能将达到AGI的水平，具备功能属性和人格属性。前者对应智商，后者对应情商，两者结合成为一个完整的类人生命体。通过聆心智能的技术 ，不但可以赋予AI智商——获得问答、知识、工具的功能，还可以赋予AI情商——拥有情感、人格与灵魂，在将来成为人类的专属AI campanion，AI与人共同成长，相辅相成。</p><p>&nbsp;</p><p>聆心智能孵化自清华大学计算机系，该团队核心成员均来自于清华大学、卡内基梅隆大学、谷歌等国内外顶尖高校及公司，具有丰富的商业化经验，一直以来，在大模型和对话系统的开发与应用领域中处于行业领先位置。</p><p>&nbsp;</p><p>聆心智能的核心人员是国内最早开展大模型底层技术的团队，在语言生成、对话生成方面具有独特的技术优势。基于生成式大模型，他们打造了Emohaa情绪疗愈机器人，并与知名精神心理平台好心情达成合作，成功落地了国内首款人工智能心理陪伴数字人；与高端豪华电车品牌Beyonca合作，打造了新一代智能驾舱的贴心助手。同时，聆心智能自研全球技术指标领先的中文对话大模型OPD，在自动评测和人工评测中显著优于同类模型；去年11月，推出了首个超拟人AI产品---“AI乌托邦”，该系统允许用户快速定制AI角色，只需要输入简单的角色描述，就可以生成相应人设的AI，与之进行深度对话和聊天。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/8b/94/8b4e491269b4029dd36bee894d173b94.png\" /></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/63/2f/6300a949a07d2e35634c8426e88a072f.png\" /></p><p></p><p></p><p>在AI乌托邦中，不局限于“捏”一个自己喜欢的二次元角色，“复活”去世多年的亲人，“链接”自己心心念念的偶像，和“情感顾问”倾诉内心，和自己的宠物吐吐槽，和品牌AI畅聊营销构思。</p><p>&nbsp;</p><p>除此之外，这项技术可以被应用在更多领域，具有非常广阔的商业前景：品牌营销、知识传播、情感陪伴、学习助手、游戏NPC的“灵魂”、AIGC创作工具......</p><p>&nbsp;</p><p>目前，聆心智能正致力于打造一个全新的超拟人大模型，作为和最近火热出圈的ChatGPT同类的大模型，除了写诗问答写论文之外，聆心智能的超拟人AI大模型增加了可配置、场景化、拟人化的风格设定，让AI不再局限于冷冰冰的机械属性，而是具备个性、情感和成长能力的AGI时代的智能体。</p><p>基于该模型，所有AI的创建过程无门槛难度，可以建立不同的对话风格，在符合角色设定的语言风格中完成所需任务和指定诉求，同时，聆心已经完整建立数据与模型之间的飞轮，让AI具备自我学习和进化能力，不断提高机器人智能化水平。</p><p>&nbsp;</p><p>相信本轮融资之后，聆心智能可以丰富更多的产品应用领域及场景。</p><p>&nbsp;</p><p>未来，聆心智能将在大模型的浪潮下，打造更多具有里程碑式的AI产品，探索AI的认知智能边界，引领前沿AI技术的创新突破。</p><p>&nbsp;</p><p>AI乌托邦地址：https://www.ai-topia.com/</p><p>&nbsp;</p><p>无限基金SEE Fund投资人认为：ChatGPT引发了市场对于人工智能技术发展的再一次关注，特别是其背后的底层技术创新，以及在应用中可能带来的颠覆性效果。聆心团队长期专注人工智能领域的科研与应用，在业内有很高的知名度。针对技术的落地，他们打造了基于人格化、个性化的超拟人大模型底座，在功能性的基础上为AI与人的互动增加了温暖和情感链接，有望成为未来数字社会最重要的基础设施之一。我们期待聆心将其技术应用于更多的场景和领域，成为AGI时代对话智能体的基础性平台之一。</p><p>&nbsp;</p>",
    "publish_time": "2023-02-17 17:33:25",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "数据库隔离级别及MVCC",
    "url": "https://www.infoq.cn/article/wquY0xgoKe5zRoylibxl",
    "summary": "<p></p><h2>数据库隔离级别介绍</h2><p></p><p>数据库在同时处理多个事务时需要决定事务之间能否看到对方的修改，能看到多少等等。根据隔离的严格程度，从严到松可以分为Serializable, Repeatable reads, Read committed, Read uncommitted。我们用下面这个 KV 存储的例子来解释这四个隔离级别。</p><p></p><p>KV存储的初始状态如下：</p><p>Table 1:</p><p></p><p></p><p></p><h4>Read uncommitted</h4><p></p><p></p><p>有两个事务同时被执行，自上而下是执行顺序。</p><p>Table 2:</p><p></p><p></p><p>在Read uncommitted 的隔离级别中，多个同时执行的事务是能够互相看到互相没有 commit 的写操作，因此可以认为这种隔离级别几乎没有作用。在上述例子中，Operation 2 读到的内容是 “AA”，Operation 4 读到的内容则是“DD”，即使第二个事务最终 Rollback了。</p><p></p><h4>Read committed</h4><p></p><p></p><p>有两个事务同时被执行，自上而下是执行顺序。</p><p>Table 3:</p><p></p><p></p><p>在Read committed 的隔离级别中，只有被 Commit 后的结果可以被看到，因此在 Table 2 的执行顺序中，Operation 2 和 4 都能够读取到 “AA” 的值，即 Key 1 的值没有改变。如果按照 Table 3 中的情况执行两个事务，Operation 2 读到的值为 “AA”，Operation 5 读到的值为 “DD”，因为此时事务 2 已经执行成功。</p><p>Repeatable read</p><p>如果在Table 3 中的事务1 两次连续读操作，用户想要保证读到相同的值，那就需要使用 repeatable read 隔离级别。在这个隔离级别中，在同一个事务中对同一条数据的多次读取保证会得到相同的值，即使这个过程中该数据被其他已经提交的事务修改掉。当然该隔离级别也有一些情况无法保证隔离性，比如下列情况：</p><p>Table 4:</p><p></p><p></p><p>在repeatable read 的隔离级别下，Operation 2 的返回结果是 [\"CC\"] —— 只有 Key 3 的值被返回了，但是Operation 5 的返回值是 [\"CC\", \"DD\"]。总结一下，repeatable read 的隔离级别仍然无法很好处理涉及多条数据的情况，特别是当有新的数据插入或者删除的情况。</p><p></p><h4>Serializable</h4><p></p><p></p><p>最严格的隔离级别叫做Serializable，这个级别的定义也是最清晰明了的，在这种隔离级别下的执行结果，就“仿佛”是将所有事务串行起来一条一条执行的结果。上面这句话中值得强调的是 “仿佛” 二字，为了提高性能，几乎没有数据库是采用真正物理意义上的串行执行来保证 Serializable 的，仅仅达到类似效果即可，实现的方法是可以多种多样的。</p><p></p><p>在Serializable 级别下还有一个细致的分类，叫做 Snapshot，该分类与 Serializable 类似但约束能力上稍弱。正是因为 Snapshot 在约束上的放松，使得其实现起来具有更好的性能，也是绝大多数数据库默认支持的隔离级别。下面我们就来说说 Snapshot，以及引申出来的 MVCC 实现方法。</p><p></p><h4>Snapshot 隔离级别及 MVCC</h4><p></p><p></p><p>想要区分最严格的Serializable 和 Snapshot，我们还是从例子来看，看下列两个事务的操作：</p><p>Table 5:</p><p></p><p></p><p>如果按照严格的Serializable 的隔离级别，无论 Transaction 1 和 2 哪个先执行，最终 Key 1 和 2 的值都是相同的，有可能是 “AA”， 也有可能是 “BB”。但是在 Snapshot 的级别下执行，执行结果则是 Key 1 和 2 的值进行互换。很明显在这种情况下 Snapshot 的隔离能力明显更弱。Isolation 对于存在读写交集的事务的先后顺序无能为力，只能保证存在写冲突的事务间的先后顺序。</p><p>&nbsp;</p><p>上述例子中，我们虽然具体地看了Snapshot 隔离级别和 Serializable 之间的差异，但是我们还没有完整介绍过 Snapshot 的特性：</p><p></p><p>在Snapshot 中的事务具有两个重要的时间戳，一个是读时间戳 R，另外一个是写时间戳 W，R之后的所有读取操作都只能读取到 R 之前 commit 的数据。Snapshot 允许两个不存在写交集的事务同时执行，并行不悖。</p><p></p><p>为了同时满足上面两个特性，很自然地就会想到为每一个数据保存多个版本，当写操作被commit的时候，新的数据被保存在新的版本中，旧的数据不会被覆盖，这也就是我们所说的 MVCC（Multiversion concurrency control）。</p><p>&nbsp;</p><p>我们知道读操作之间是不存在冲突的，写操作之间在Snapshot 的级别下也无法同时执行（或者发现冲突进行回滚），所以 MVCC 主要在读写操作发生冲突时起作用，可以让两个看似冲突的事务并发执行。</p><p>&nbsp;</p><p>MVCC 还需要进行垃圾回收，否则过多的旧版本数据会占据不必要的存储空间。下一个问题则是，如何判断某个版本的数据是否可以删除？答案是：当涉及该版本数据所有读取操作都结束了就可以被删除，当然前提是前面还有更新版本的数据存在。</p><p></p><p></p><h2>一点联想</h2><p></p><p></p><p>在介绍MVCC 的过程中我们很容易抓到以下几个关键点：</p><p>1.&nbsp;多版本。</p><p>2.&nbsp;垃圾处理。</p><p>3.&nbsp;提高并发操作效率。</p><p></p><p>在之前达坦科技（DatenLord）的题为“Rust语言无锁数据结构的内存管理”的文章当中，介绍了另外一项技术和这几个关键词是相关的，那就是无锁数据结构中的 “基于世代的内存管理方法”，英文是 epoch-based memory management，以下简称 epoch。epoch 维护了两个世代的内存状态，当最老世代的内存已经没有人继续访问的时候，那么对应的内存就会被回收释放，然后开启一个新的世代。这样做的目的其实也是为了让对新世代数据修改的操作和对老世代数据的读取操作能够并行，目的也是为了读写并发的优化。当然除了这些相似的地方，也有不同的地方，MVCC 可以同时存在许多个版本，epoch 同时存在的版本永远都是两个。这其实可以理解成为epoch 的内存管理颗粒度更粗，所以当contention 重的时候 epoch 有时会造成内存压力增大。</p><p>&nbsp;</p><p>总体而言，MVCC 和 epoch 在中心思想上是类似的，为了解决并发读写冲突的问题，采用了多版本的内存控制技术。</p><p></p><p></p><h2>总结</h2><p></p><p></p><p>本文为大家介绍了数据库的四种隔离级别，分别用例子介绍了不同隔离级别之间的区别。然后详细介绍了Snapshot 这个使用最广泛的隔离级别，并且说明了其最长用的实现方式 MVCC。最后结合了 MVCC 和 无锁数据结构的内存管理机制进行了对比和探讨。</p>",
    "publish_time": "2023-02-17 17:34:20",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "GitHub 更新 Copilot 以阻止不安全代码，并称其支持了超 60% 的 Java 开发者",
    "url": "https://www.infoq.cn/article/s5tL9MAGc53wXWqrgc9R",
    "summary": "<p>近日，GitHub 宣布对 Copilot 编码助手<a href=\"https://github.blog/2023-02-14-github-copilot-now-has-a-better-ai-model-and-new-capabilities/\">进行了更新</a>\"。</p><p>&nbsp;</p><p>为了提高 <a href=\"https://www.infoq.cn/article/weSmeUflc2RhAVvoR5Xt\">GitHub Copilot</a>\" 代码建议质量并减少向用户提供建议的时间，GitHub 更新了底层的 Codex 模型。根据 GitHub 分享的数据，2022 年 6 月首次为个人开发者推出 GitHub Copilot 时，平均有超过 27% 的开发人员代码文件由 GitHub Copilot 生成。如今，在所有<a href=\"https://www.infoq.cn/topic/programing-languages\">编程语言</a>\"中，GitHub Copilot 平均支持 46% 的开发人员代码——而在 Java 中，这一数字跃升至 61%。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/37/37cc05756a2763b288ba862c875b2cba.png\" /></p><p>、</p><p>&nbsp;GitHub Copilot 代码建议的总体接受率，来源：GitHub</p><p>&nbsp;</p><p>另外，GitHub Copilot 还推出了一个基于 AI 的漏洞过滤系统，声称可以实时阻止不安全的编码模式，使 GitHub Copilot 建议更加安全。据悉，该模型主要针对最常见的易受攻击编码模式，包括硬编码凭证、SQL 注入和路径注入。</p><p>&nbsp;</p><p>GitHub Copilot 表示，新系统利用 LLM 来近似静态分析工具的行为。由于GitHub Copilot 在强大的计算资源上运行高级 AI 模型，因此它的速度非常快，甚至可以检测不完整代码片段中的漏洞模式，这意味着不安全的编码模式会很快被阻止并被提出的建议所取代。</p><p>&nbsp;</p><p>更多详情：</p><p><a href=\"https://github.blog/2023-02-14-github-copilot-now-has-a-better-ai-model-and-new-capabilities/\">https://github.blog/2023-02-14-github-copilot-now-has-a-better-ai-model-and-new-capabilities/</a>\"</p><p></p><p>推荐阅读：</p><p><a href=\"https://www.infoq.cn/article/UCaTitOegreb3NGiX24m\">一个架构师在 2023 年需要掌握哪些“必杀技”？</a>\"</p>",
    "publish_time": "2023-02-17 18:08:53",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "数据治理之需求层次",
    "url": "https://www.infoq.cn/article/fQtaq77TxZ1KkMPG0IJw",
    "summary": "<p></p><h2>01什么是数据治理</h2><p></p><p></p><p>国际数据管理协会（DAMA）给出的定义：数据治理是对数据资产管理行使权力和控制的活动集合。</p><p></p><p>国际数据治理研究所（DGI）给出的定义：数据治理是一个通过一系列信息相关的过程来实现决策权和职责分工的系统，这些过程按照达成共识的模型来执行，该模型描述了谁（Who）能根据什么信息，在什么时间（When）和情况（Where）下，用什么方法（How），采取什么行动（What）。</p><p></p><p>IBM给出的定义：数据治理通过不同的策略和标准提高组织数据的可用性、质量和安全性。这些流程确定数据所有者、数据安全措施和数据的预期用途。总体而言，数据治理的目标是维护安全且易于访问的高质量数据，以获取更深入的业务洞察。</p><p></p><p>不同的企业和机构对数据治理有不同的理解和目标。通过我的理解和查阅，数据治理比较通用的目标是：</p><p>通过一系列技术等手段提升企业数据质量、稳定性和安全性通过数据标准和数据资产的建立，提高数据资产使用效率，降低数据使用成本通过数据挖掘，提升数据的价值，提高企业核心竞争力和影响力，实现商业价值</p><p></p><p>针对上面的目标，参考马斯洛需求的分层，我也将数据治理分成了5层。</p><p></p><p></p><h2>02数据治理的需求分层</h2><p></p><p></p><p>马斯洛需求的五个层次分别是：生理需求、安全需求、社交需求、尊重需求、自我实现需求。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/32/32683d16231437ed7d93ae2376a850ac.png\" /></p><p></p><p>按照马斯洛需求分层的模式我们可以将数据治理分成以下五个层次，分别是：稳定需求、安全需求、易用需求、质量需求、成本价值需求。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/98/9825984d61b27b4233d245afbe95e745.png\" /></p><p></p><p></p><p>模型越往上带来的价值越高，越往下越是基础的要求。但是没有基础需求层的支持就谈不上上层的需求。</p><p></p><h2>03稳定需求</h2><p></p><p></p><p>数据的稳定性需求是指数据能够稳定产出，并且产出及时。就相当于马斯洛的第一层生理需求，解决吃饱饭（稳定产生数据）的问题。</p><p></p><p>这里对于数据稳定，我们将获取数据的及时性也归纳为稳定，那么主要分为3个维度，2个指标：</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/34/348293eded88f09fd55a1af3f96251fd.png\" /></p><p></p><p>可靠性:</p><p></p><p>在高可靠性（也称为可用性，英文描述为HA，High Available）里有个衡量其可靠性的标准——X个9，这个X是代表数字，X个9表示在系统1年时间的使用过程中，系统可以正常使用时间与总时间（1年）之比。</p><p></p><p>3个9：(1-99.9%)*365*24=8.76小时4个9：(1-99.99%)*365*24=0.876小时=52.6分钟5个9：(1-99.999%)*365*24*60=5.26分钟</p><p></p><p>由于数据数据计算往往不是供用户直接使用的在线系统，有的业务中经常用数据计算任务出现问题的次数来衡量数据的可靠性。</p><p></p><p>时延性</p><p></p><p>在大数据中我们经常将（交易日期 Transaction Date 简称 T，数据产生的日期）作为基准，然后通过它来描述数据行为产生到数据结果呈现的延迟。它们是：</p><p>T + 0：当天就能看到当天发生的数据，如果是及时的就是实时数据T + 1：当天产生的数据，在第二天才可以查询T+ 2，T+3 ... ：当天产生的数据，在第2，3...天才可以查询</p><p></p><p>此外 T 可以指代当周、当月、当年，如当 T+1 的月数据，是指当月产生的数据，在次月才能看到数据，一般适用于月度统计。</p><p></p><p>在准实时数据处理中也可以用H+0，H+1的方式来反馈数据处理的时延。</p><p></p><p></p><h2>04 安全需求</h2><p></p><p>       </p><p>数据安全需求，是指数据权限管理、敏感数据保护、合规要求。就相当于马斯洛的第二层安全需求，解决环境安全（数据安全合规）的问题。</p><p></p><p>数据安全包括两个方面第一就是数据不被泄露窃取，第二个就是数据合法合规。随着欧洲联盟《通用数据保护条例》（General Data Protection Regulation，简称GDPR）的颁布和《国内数据安全法》，《个人信息保护法》的实施，数据安全越来越重要。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2d/2d1efbc677007c51c21d6fe418ea51cf.jpeg\" /></p><p></p><h1>数据权限</h1><p></p><p></p><p>近年来，随着互联网的快速发展，数据泄漏屡见不鲜，基本上每年都会有数据或者账号的泄露的事件。如果数据安全都不能保证，那就谈不上数据治理。通常我们可以从下面三方面去做好数据的权限控制和隔离：</p><p>计算存储资源的多租户数据隔离系统的多账号角色权限数据隔离内外网以及系统之间的数据隔离</p><p></p><p>数据合规</p><p>数据合规是指数据存储和使用符合相关法规和规范的要求。按照法规、公司制度、监管或行业标准对数据一般有以下要求：</p><p>存档保留的时间数据脱敏处理</p><p>&nbsp; &nbsp; &nbsp;对于像身份证、手机号、住址、籍贯等个人隐私敏感数据以及财务等企业敏感数据，必须要做好相应的脱敏处理，保证数据不被泄露。方法通常有遮盖处理、静态加密算法加密、动态加密算法加密。</p><p>&nbsp;合规的获取和使用用户数据</p><p></p><p></p><h2>05 易用需求</h2><p></p><p></p><p>数据易用需求，是指数据在共享使用中，易于查询，理解，规范。就相当于马斯洛的第三层社交需求，解决交流分享（数据易查询使用）的问题。这个层主要解决的范畴为：</p><p></p><p>数据查询</p><p>对于这块，往往是通过搭建一套BI，OLAP自主系统等手段来提升用户的使用查询数据的体验。技术手段比如采用开源的OLAP引擎：Kylin、Druid、ClickHouse、Doris、StarRocks，开源的数据可视化组件：Superset、Grafana、Davinci常用指标有：TP90, TP95, TP99查询返回时间，即 9X% 的数据都满足某一条件；QPS:（Queries Per Second），每秒查询率。</p><p></p><p>数据标准</p><p>业务标准规范。数据统计标准，例如CTR，ROI如何计算；数据中分类的统一规范。</p><p>技术标准规范。数据的类型、长度、格式、编码、命名规则等。</p><p>管理标准规范。数据访问的标准流程，数据的删除，接入规范</p><p></p><p>数据模型</p><p>数据模型的复用性。复用性低，说明模型设计的不太好，新需求不能基于模型开展，提高了开发维护成本。</p><p>数据模型的耦合性。耦合度过高会给数据的运维、治理带来很多影响，在数据下线、变更、治理过程中不得不考虑到依赖。</p><p>数据模型的稳定性。稳定性差，经常变动说明设计脱离业务，缺乏标准或者业务覆盖度不够。</p><p></p><p>解决好上面三方面的需求，数据易用性基本上就可以达到用户需求，数据治理成效也可以用前端页面给用户体现出来。</p><p></p><h2>06 质量需求</h2><p></p><p></p><p>数据易用需求，是指数据在准确性、完整性、一致性、有效性。就相当于马斯洛的第四层尊重需求，解决受人尊重（解决数据质量就会被使用者尊重）的问题。</p><p></p><p>数据质量需求主要依靠数据监控和数据调度配合完成才能提高数据质量，当然人工的参与和流程也需要规范。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e3/e3029c9e0c98c7c9918421ad9b835545.png\" /></p><p></p><p>数据准确性监控。主要监控数据接入是否符合标准，数据产生到计算结果过程中数据是否出错，不一致。数据完整性监控。数据一致性监控。监测两种数据渠道数据结果是否一致。数据有效性监控</p><p></p><p>通过监测我们可以产生数据质量质量的数据，我们可以通过一些算法形成数据质量报告，来定期评估数据质量的提升。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/82/82076e6b6f08426bcc4a13b1bbb9cae2.png\" /></p><p></p><p></p><p></p><h2>07 成本价值需求</h2><p></p><p></p><p>数据成本价值需求，是指数据生产的经济性，数据应用创造的价值。就相当于马斯洛的第五层自我实现需求，解决花钱赚钱（解决数据产生效益，完成自我实现）的问题。</p><p></p><p>这一层次的需求主要其实就是通过降低成本增加收益。我认为做到以下几点是数据质量在这块关注的重点：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b8/b8990ab02604b2bca5d01f09886495a7.png\" /></p><p></p><p></p><p>成本量化</p><p>数据血缘，元数据管理等手段，理清每个表数据的成本。通过日志分析来可视化每个大数据处理任务Job的费用。</p><p></p><p>价值量化</p><p>数据治理到底重不重要，能带来什么价值，一直是困扰企业数据治理问题，也会经常被企业领导和业务部门质疑。如果能有够将数据治理带来的成功量化那势必会打消大家的疑虑。例如通过数据治理业务部门节约了多少成本；通过数据质量的提高业务部门的ROI是否得到提高；通过数据稳定性安全性的提升，业务系统是否更加稳定和避免了数据泄露损失。</p><p></p><p>成本优化</p><p>通过表热度分析，处理僵尸报表和任务。对数据表进行LTV分析，对于低价值高消耗的数据计算任务，进行降级处理，例如降低计算频次，排到计算资源空闲的时间处理，存储在成本较低的介质上。对于高价值高消耗的任务，评估成本改造方案。</p><p></p><h2>08 总结</h2><p></p><p></p><p>数据治理几个需求分层之间是相互依赖不断迭代的，越往上层越接近业务，也越容易体现数据治理带来的成功。要想数据治理取得成功，除了技术工具，我们还应该关注流程规范和组织保障。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/82/8281d513569fd61c859a87f84207cb93.png\" /></p><p>组织保障</p><p>组织统一规划数据治理目标，固定的专业组织、充分赋权，有利于数据治理实施的整体推进；一套行之有效的制度，更容易让数据治理，数据规范落地执行。</p><p>流程规范</p><p>这个其实就是指在数据治理中制定的数据接入输出等相关流程，建立的数据标准。有了流程规范才能知道数据治理的方向和细则，避免数据使用和提供方盲目抓虾。</p><p>技术工具</p><p>技术工具平台是保障数据成果转化的关键，没有工具平台数据治理可能最后只是设想和空谈。一组优秀的平台工具可以保障数据治理规划和流程的完整落地，从而产生价值收益。</p><p></p><p>在数据治理过程中我们应该结合需求层次制定具体方案，通过评估收益来决策数据治理的投入。</p><p></p><p>原文链接：</p><p>https://mp.weixin.qq.com/s/tMoP8bCG3udLyPlCt9eUgA</p><p></p><p>作者简介：</p><p>刘周龙，易点天下大数据专家，大数据平台负责人。加入易点天下前曾就职于搜狐视频、腾讯，擅长大数据平台和相关系统建设，个人公众号“早起的码农”。</p><p></p>",
    "publish_time": "2023-02-17 18:35:10",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从用云焦虑到“深度云化”，新云原生时代带给我们哪些思考？",
    "url": "https://www.infoq.cn/article/hY7tm3r2NQlhCaRO6a7T",
    "summary": "<p>企业技术基础设施“云原生化”的改造速度，远超大部分人的心理预期。</p><p></p><p>据 Gartner 预测，到 2025 年，云原生平台将在超过 95% 的新数字计划中作为基础，而此前 2021 年的数据只有不到 40%。这说明，今天的云原生关键词，正从“构建”、“落地”，逐步转变为“协同”、“优化”。“如何深度云化”是大家关注的重点。中国信息通信研究院云计算与大数据研究所副所长栗蔚预测，2023 年我国云计算行业应用将从“资源上云”正式迈入“深度用云”。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/72/72d68a916cbb9d2b66b4beba32cf1206.jpeg\" /></p><p></p><p>2 月 17 日，由 CNCF、中国信通院、华为云联合主办的创原会·云原生技术创新峰会在四川成都举行，超过 150 名云原生领域的专家学者、创新企业和机构代表齐聚一堂，就深度云化的前沿技术趋势、产业机遇和创新实践展开交流。</p><p></p><p>会上，华为云 CTO 张宇昕发表了主题演讲，并正式提出华为云在云原生领域的核心技术主张——上好云、用好云、管好云，成就新云原生企业。其中“管好云”的概念，首次得到如此重要地阐释。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ec/ec40700bfd8ae18fd67e161bb7534923.jpeg\" /></p><p></p><p>张宇昕表示，随着越来越多的企业从“搬迁上云”走向“深度云化”阶段，云上的数字化价值将得到真正释放。在这一过程中，“用好云”和“管好云”成为了企业数字化进程中的一体两面，企业不仅要投入于应用现代化、数智融合的“创新”实践，也要关注 IT 治理、云上安全、成本优化、确定性运维等“精益”方面的挑战。</p><p></p><p>例如，企业在上云前会担心用云的效率、成本、安全等；上云后会担心云上资源怎么管？如何提高利用率？云上和线下的业务资源如何协调？管理体系该怎么建设？应用和数据改造后怎么运维？如何应对无处不在的安全和稳定威胁？一言以蔽之，云原生其实就是企业全方位的数字化变革，在这场“新云原生企业”的蜕变中，企业内所有的部门都将迎来转型。</p><p></p><p>在这一语境下，“管好云”已不仅仅是字面意义上的管理问题，更是企业对崭新技术体系、数字思维的二次理解问题。云，作为底座支撑起门类繁多的根技术、现代化应用，几乎重构了现代企业的技术基础，让“用好云”与“管好云”成为所有企业跨越数字鸿沟的一次必经考验。</p><p></p><h2>技术红利浪潮下，企业在焦虑什么？</h2><p></p><p></p><h3>降本增效压力加剧“云成本焦虑”</h3><p></p><p></p><p>谈到上云，不少企业的首要关切就在于成本。</p><p></p><p>对云成本的最早担忧，大概来自国外部分企业在发展中的“下云”冲动，他们表示，对于一家增长稳定的中型企业来说，租赁基础设施资源有时候会让管理者承担不少额外的云支出。</p><p></p><p>对于业内人士而言，这一问题并不难解答，“下云”的冲动，大部分归结于对云原生以及企业隐形成本的理解、估算不足——首先，云原生不是简单的“租赁基础设施资源”；其次， 由于云上的资源是共享的，通常单个集群可以托管多个工作负载和应用，但云厂商的账单并不会体现每个工作负载或应用消耗的资源。这意味着，多个团队如何利用或共享基础设施，往往难以被精准测算出来，因而产生了资源配置策略设置不合理、计量方式不够灵活等问题，从而导致成本浪费。Flexera 的 State of the Cloud Report 显示，部分企业的云上开支浪费明显，超过 30% 的云花费用属于“无效”开支。</p><p></p><p>此外，云本身也存在“超支挑战”。根据 InfoQ 此前的报道，从 2020 到 2021 ，近 40% 的公司在云计算服务上预算超支，在预算为 200 万～1000 万美元的企业中，近半数（46%）出现了超支。三分之二的已超支受访者预计，新一年内云预算将继续超支。关于超支理由，该报告 29% 受访者给出的理由是内部事项优先级的转换， 21% 的受访者将超支与新冠疫情临时上云联系起来。也就是说，50% 的原因与技术无关。</p><p></p><p>于是问题开始变得微妙起来——根因越来越复杂模糊，账单上的数字却醒目刺眼。要真正的用好云、管好云，首先就要解决此类云成本问题。</p><p></p><h3>代码漏洞及人为事故带来的“云安全焦虑”</h3><p></p><p></p><p>除了云成本挑战，云安全挑战同样是这两年行业关注的焦点。无论是 2021 年底的 Log4j 核弹级漏洞带来的行业震动，还是 Kubernetes 由于自身复杂性导致的人为事故频发，都给全行业敲响了“数字安全”的警钟。</p><p></p><p>据统计，2022 年全球勒索软件事件达数千万次、平均每事件的损失达百万美元以上、全球新增安全漏洞超过 23900 例。以华为云为例，每年云上防御超过 1000 亿次的网络攻击，10 亿次 DDOS 攻击、最高攻击流量高达 3T，1 亿次的账号暴力破解。</p><p></p><p>数字背后反映的是，数字化时代，每家企业可能面临同样的攻击。随着千行百业开始步入数字化转型的“深水区”，如何以云为基础，构建更加安全可靠的数字体系？</p><p></p><h3>云原生复杂场景背后的“云运维焦虑”</h3><p></p><p></p><p>云时代也对 IT 运维提出了新的挑战。过去，传统运维工程师只需要面对单个机房或者 IDC，去处理服务器、网络等硬件设备。但是在当前这样一个涵盖了私有云、公有云、虚拟化平台、容器平台的多维度、多云协同环境下，技术迭代、人员技能、产品更新的不确定性，成为了行业面临的共同挑战。</p><p></p><p>一方面，云上的物理设备不可见，这对运维人员的认知转变提出了较高的要求；另一方面，云原生下的业务系统由单体变成了多个虚拟的微服务，用传统的 IT 思维已难以全面掌握业务整体运行状态。而多云环境则加剧了这一问题，也对运维人员的技术提出了更大的挑战。除此之外，部分企业手工运维导致的效率、安全等问题也层出不穷。</p><p></p><p>另外，随着企业业务的调整发展，对数字化系统的可靠性、稳定性等方面的需求剧增，传统模式下基础设施运维与应用运维团队割裂，无法有效协同守护 SLA 目标。</p><p></p><p>资料显示，仅 2022 年一年，IT 领域重大恶性事件超过 40 起，平均恢复时长超过 4 小时，传统的 ITIL 体系已经无法适用于云原生时代，亟需构建一套全新的运维体系。</p><p></p><h3>新 IT 环境带来的“云治理焦虑”</h3><p></p><p></p><p>传统的 IT 管理体系，在云时代的新技术需求下同样面临挑战。相比传统模式，云上的 IT 治理更重视数字转换相关的要素，重点关注整合和治理应用程序、数据和基础架构之间的互动、数字业务流程的协调与打通，以及运营可扩展性、安全性和可操作性等概念。尤其是随着多云、混合云等概念的出现，企业的 IT 治理难度进一步加大。</p><p></p><p>从企业管理视角来看，当业务发展加快，众多业务单元（如子公司、事业部、部门等）遍布在不同的领域和地域时，一方面要对业务单元进行管理隔离，另一方面又需要进行集中管控，没有建立行之有效的 IT 治理体系，导致云上资源、数据和人员等要素的管理失控，进而很容易导致成本和安全失控。</p><p></p><p>除此之外，近几年不少企业正逐步从单一应用上云转为全面深度云化，虚拟机数量、存储容量、业务单元数量、应用数量、访问云资源的用户数量等上升了多个数量级。大规模上云的背后，企业如何做好业务多维度管理、数据安全合规和数字治理体系建设，对于 IT 管理团队而言是一次业务“蜕变”挑战。</p><p></p><h2>走进“云深处”的行业探索与实践</h2><p></p><p></p><p>如今，针对上述伴随“深度云化”涌现出的新挑战，行业内已进行了大量探索。</p><p></p><p>在精益用云方面，紧随着云成本“不可知”所带来的成本焦虑，FinOps 开始崭露头角。FinOps 本质上是把财务和整个架构技术结合在一起，弄清楚各业务对云服务使用的具体账目，然后提升资源利用率，减少成本消耗。根据信通院发布的《中国 FinOps 产业发展现状研究报告（2022 年）》，IT 资源精细化运营管理已被广泛提及，六成企业已经了解或听说过 FinOps 相关理念，其中两成企业已经实际展开 FinOps 相关实践。</p><p></p><p>而云厂商们也在不断扩展和增强他们的成本管理服务，帮助他们的客户更好地管理 IT 资源及成本。比如亚马逊云科技推出了 Amazon Billing Conductor，这是其云财务管理解决方案的一部分；谷歌云也推出了计算引擎暂停 / 恢复功能和无人值守项目推荐器；华为云则更进一步，基于 FinOps 理念构建了端到端的、涵盖计划、控制、分析、优化的成本运营能力，帮助企业实现一站式成本管理、多维度成本分析、精准实时成本预测、多样化成本优化。</p><p></p><p>“企业的CEO、CFO可能会关注，数字化转型能实现这么多创新，有这么多数据化需要变革，那它的成本是不是可控的？未来成本的投入是不是无底洞？”张宇昕指出，针对这一痛点，华为云 FinOps 的出现，就是为了帮助企业提升云化的成本效益，构建完整的云成本运营能力，企业据此可以建立一套云成本运营的机制和流程，持续进行成本优化，不断提升成本效益。</p><p></p><p>除了 FinOps 外，“多云”架构也正在成为越来越多企业实现 IT 资源精细化运营、节省成本的选择。2022 年，国内外行业领导者们不断围绕“多云”这个话题发起具有前瞻性的讨论。借助多云架构，企业的成熟“现金牛”业务可以部署于自有云原生基础设施之上，从而降低在数据安全性和低延时流水线上的成本；另一方面，企业希望通过借助多个公有云的服务，新产品和业务能够“弹性”地拥抱新技术和生态，并且借助多个公有云也能使企业在满足合规性的同时，低成本快速将业务拓展至别的国家和地区，从而在市场上取得先机。</p><p></p><p>张宇昕表示，未来，随着云成本管理的精益化加深，FinOps 有可能会与多云管理结合，作为多云管理的一个模块。</p><p></p><p>在云安全方面，业内也有不少新的探索。比如，在开发阶段，华为云采用 DevSecOps 软件安全开发流程，通过安全左移，结合代码级安全深度测试，提前发现漏洞、修复漏洞，防范于未然；在运营阶段，基于“三分建设、七分运营”理念，华为云通过一个中心 + 七层防线的云原生统一安全架构，构建立体化、智能化、自动化的安全防御机制。华为云以安全云脑为中心，帮助实现一键安全合规、一屏全面感知、一云全局分析、一体全程处置，让企业安全运营效率实现 10 倍提升。</p><p></p><p>在 IT 运维方面，可观测性和 AIOps 智能运维正发挥越来越大的价值。近两年“可观测性”讨论热度颇高，它为开发人员和运维人员构建了合作的桥梁，Gartner 在 2022 年度的基础设施和运维自动化技术成熟度周期图里，把“可观测性”放在膨胀期波峰最顶端位置，可以说是风头正盛；无独有偶，AIOps 成为了 IT 运维领域另一颗明珠，当企业云化不断加速，应对重复冗杂的运维活动，引入智能算法的 AIOps 则有机会帮助企业进一步解放生产力，提高运维效率，赋能业务创新。</p><p></p><p>在华为云看来，可观测性、AIOps 都只是工具或手段，对业务而言，最终希望看到的是运维的确定性，由此提出了“确定性运维”的实践方向，希望通过全站可观测性、故障快速恢复、管控变更风险、韧性评估优化、一体化运维管理等方式，帮助企业将不确定性的运维风险变为确定性运维管控。</p><p></p><p>此外，随着 DevOps 的大热，业内开始出现一些新的观点：DevOps 要求开发运维交付一条龙，当开发者将精力分摊到运维中去后，必然会影响开发周期，同时如今的云原生生态已经覆盖了海量不同类别的工具，这些都大大增加了开发者的认知负担。</p><p></p><p>基于此，新兴技术“平台工程”（Platform Engineering）越来越受关注和热议。平台工程旨在通过减少现代软件交付的复杂性和不确定性来提高开发人员的生产力。有观点认为，平台工程是云原生软件交付的一个重要转向。Gartner 在其 2022 年 8 月发布的软件工程炒作周期中添加了“平台工程”，并将其列为企业机构 2023 年需要探索的十大战略技术趋势之一。据 Gartner 预测，到 2026 年，80% 的软件工程组织将建立平台团队，其中 75% 将包含开发者自助服务门户。不过当前国内真正在实践平台工程的企业尚属少数。</p><p></p><h2>“新云原生企业”的未来展望</h2><p></p><p></p><p>过去几年，在全球经济换挡和互联网经济转型的大背景下，云原生技术的蓬勃发展对全行业而言都称得上是一个“小确幸”。当然，经济下行等因素也给到了企业更多理性思考的空间，据 InfoQ 的观察和与行业专家的探讨结果来看，接下来无论是云原生技术的演进，还是产业实践，都会往更务实的方向发展，更聚焦于解决具体的问题，从数字化中要到真正的业务价值。</p><p></p><p>如前文提到的云成本、云安全、确定性运维、IT 治理体系等相关技术实践，都是对于企业场景的需求而思考诞生。这本身就是深度云化的标志性特征，是一件好事。如果行业仍然是上了云就万事大吉，没有针对相关问题推进解决，反而才是一个值得忧虑的问题。</p><p></p><p>从云原生技术的发展趋势来看，未来可能会更进一步渗透云虚拟化层，成为下一代操作系统层级的基础设施；向上则可能更深层次地融合并赋能开发、运维、数据库等云产品。“服务”的概念会进一步加深，关注云产品本身对业务的友好度、对开发者的友好度，降低软性的研发成本，兼容更多接口和基础设施。这又是“深度云化”的另一条必经之路。</p><p></p><p>虽然据 Gartner 新兴技术成熟度曲线预估，完成上述技术基础建设和行业普及，至少还需要 2-5 年，但随着数字化转型的进一步深化，会有更多的企业接入云端，这极大可能会加速云服务的进化。</p><p></p><p>在数字化浪潮技术百花齐放的趋势下，也许极少有行业能如云计算一样，在技术与商业的双轮驱动下，始终将“客户服务”放在第一位，由技术方牵头布道新理念、并在与行业痛点结合下，持续迭代新的解决方案。</p><p></p><p>从 2020 年首次面向业界提出云原生 2.0 概念，到持续探讨“深度云化”实践，再到 2023 年全面阐释“上好云、用好云、管好云，成就新云原生企业”，华为云正在将云上创新的路径与理念不断清晰化。正如张宇昕所言，上云只是第一步，只有深度云化，上好云，用好云，管好云，以云原生思维践行云原生，才能真正释放出云的价值。相信这样的模式将成为表率，在未来牵引更多企业加快数字化转型，加速产业变革。</p>",
    "publish_time": "2023-02-17 19:25:44",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]