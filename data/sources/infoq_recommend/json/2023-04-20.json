[
  {
    "title": "亚马逊云科技开源Mountpoint for Amazon S3，通过挂载点技术简化 Amazon S3 对象存储的使用",
    "url": "https://www.infoq.cn/article/OzPQdde0UPv9O5Cs9xAu",
    "summary": "<p>在<a href=\"https://aws.amazon.com/blogs/aws/celebrate-amazon-s3s-17th-birthday-at-aws-pi-day-2023/\">Pi Day</a>\"活动期间，AWS发布了<a href=\"https://aws.amazon.com/about-aws/whats-new/2023/03/mountpoint-amazon-s3/\">Mountpoint for Amazon S3</a>\"，这是一个开源文件客户端，可以提供Amazon S3的高吞吐量访问。该工具目前处于Alpha阶段，其本地挂载点提供了很高的单实例传输速率，主要用于数据湖应用程序。</p><p>&nbsp;</p><p>Mountpoint for Amazon S3将本地文件系统API调用转换为S3对象API调用，如GET和LIST。它支持对文件进行随机和顺序读操作，支持列出文件和目录。但该Alpha版本不支持写入操作（PUT），预计将来只支持新对象的顺序写入。</p><p>&nbsp;</p><p>AWS学者、德克萨斯大学助理教授<a href=\"https://www.amazon.science/author/james-bornholt\">James Bornholt</a>\"、AWS高级产品经理<a href=\"https://www.linkedin.com/in/devabrat-kumar/\">Devabrat Kumar</a>\"和AWS杰出工程师<a href=\"https://www.linkedin.com/in/andywarfield/\">Andy Warfield</a>\"承认，该客户端不是一个通用的网络文件系统，并且在文件操作上有一些限制，他们<a href=\"https://aws.amazon.com/blogs/storage/the-inside-story-on-mountpoint-for-amazon-s3-a-high-performance-open-source-file-client/\">写道</a>\"：</p><p>&nbsp;</p><p></p><blockquote>Mountpoint是为大规模分析型应用程序而设计的，它们可以并行读取和生成大量的S3数据，但不需要向现有对象中间写入数据。Mountpoint允许你将S3存储桶或前缀映射到实例的文件系统命名空间，遍历存储桶的内容，就像它们是本地文件一样，并实现对对象的高吞吐量访问。</blockquote><p></p><p>&nbsp;</p><p>这个开源客户端没有模拟目录重命名等操作，因为那会产生S3 API调用，或者说需要S3 API不支持的POSIX文件系统特性。</p><p>&nbsp;</p><p>Mountpoint for S3并不是第一个将S3作为文件系统呈现的客户端，我们也可以使用<a href=\"https://github.com/kahing/goofys\">Goofys</a>\"和<a href=\"https://github.com/s3fs-fuse/s3fs-fuse\">s3fs</a>\"这些流行的开源选项通过FUSE挂载桶。在Reddit上，有一些开发人员质疑<a href=\"https://www.reddit.com/r/aws/comments/11rdbhp/introducing_mountpoint_for_amazon_s3_a_file/\">新客户端的必要性</a>\"，并担心它会被用在<a href=\"https://www.reddit.com/r/aws/comments/11rdbhp/comment/jc80y8e/?utm_source=share&amp;utm_medium=web2x&amp;context=3\">数据湖之外的领域</a>\"，Bornholt、Kumar和Warfield写道：</p><p>&nbsp;</p><p></p><blockquote>Mountpoint并不是第一个用于访问S3的文件客户端——有几个开源的文件客户端，我们有客户使用过。然而，我们从这些客户那里都听到过的一个话题是，他们希望这些客户端能够提供与S3 REST API和AWS SDK相同的稳定性、性能和技术支持。</blockquote><p></p><p>&nbsp;</p><p>新客户端使用Rust在大多数AWS SDK都使用的<a href=\"https://docs.aws.amazon.com/sdkref/latest/guide/common-runtime.html\">公共运行时（CRT）</a>\"上构建，它依赖于<a href=\"https://aws.amazon.com/blogs/storage/how-automated-reasoning-helps-us-innovate-at-s3-scale/\">自动推理</a>\"来验证文件系统语义。The Duckbill Group首席云经济学家<a href=\"https://twitter.com/QuinnyPig/status/1635703963269107714\">Corey Quinn在推特上写道</a>\"：</p><p>&nbsp;</p><p></p><blockquote>哦不，AWS做了什么？15年来，我之所以没有呼吁人们不要将S3用作文件系统，就是希望S3团队自己来做这件事！</blockquote><p></p><p>&nbsp;</p><p>云专家和AWS无服务器英雄<a href=\"https://twitter.com/ben11kehoe/status/1635704924884303888\">Ben Kehoe提醒说</a>\"：</p><p>&nbsp;</p><p></p><blockquote>使用文件概念来考虑S3会使你对API的语义产生误解，最终做出错误的假设，当系统总是因为这些假设不成立而出现轻微的故障时，你就要难过了。</blockquote><p></p><p>&nbsp;</p><p>Mountpoint遵循Apache License 2.0许可，尚不能应用于生产工作负载。GitHub上提供了<a href=\"https://github.com/awslabs/mountpoint-s3\">初始Alpha版本</a>\"和<a href=\"https://github.com/orgs/awslabs/projects/84/views/1\">公共路线图</a>\"。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/03/mountpoint-amazon-s3/\">https://www.infoq.com/news/2023/03/mountpoint-amazon-s3/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://xie.infoq.cn/article/929a761df9243e16ee2317b5c\">通过 Amazon Managed Microsoft Active Directory 运行混合 Active Directory 服务</a>\"</p><p><a href=\"https://www.infoq.cn/article/LW5JeoLR0Jcl1ktRNV0o\">亚马逊云科技为蓝绿及金丝雀策略引入 CloudFront 持续部署</a>\"</p>",
    "publish_time": "2023-04-20 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "火山引擎发力大模型训练云服务：与字节国内业务“并池”，为大模型企业提供底层支持",
    "url": "https://www.infoq.cn/article/WKwdgBY1f4wdpjgoSDPf",
    "summary": "<p>4月18日，<a href=\"https://www.infoq.cn/video/xUq5Q66QSwsTU4G3sLQx\">火山引擎</a>\"在其举办的“原动力大会”上发布了自研DPU、分布式云原生平台、多云安全、多云<a href=\"https://xie.infoq.cn/article/fda69a1075f814cb8bd36d8b0\">CDN</a>\"、veStack混合云平台等等系列云产品，并推出新版机器学习平台：支持万卡级大模型训练、微秒级延迟网络，让大模型训练更稳更快。</p><p>&nbsp;</p><p>“国内有数十家做大模型的企业，大多已经在<a href=\"https://www.infoq.cn/article/yaV5V1R0iuUvpbrBIJYq\">火山引擎云</a>\"上”，火山引擎总裁谭待认为，大模型不会一家独大。与其他云厂商力推自家大模型不同的是，火山引擎将接入多家大模型深度合作，为企业和消费者提供更丰富的AI应用。</p><p>&nbsp;</p><p>另外在会上，火山引擎宣布与字节跳动国内业务并池。基于内外统一的云原生基础架构，抖音等业务的空闲计算资源可极速调度给火山引擎客户使用，离线业务资源分钟级调度10万核CPU，在线业务资源也可潮汐复用，弹性计算抢占式实例的价格最高可优惠80%以上。</p><p>&nbsp;</p><p></p><h2>上云，缓解成本焦虑</h2><p></p><p>&nbsp;</p><p>云的弹性，不仅能够帮助企业降低成本，也能大幅降低创新所需要的等待时间。尤其是大模型时代，训练和托管大模型都会带来大量的成本开销，继而带来巨大的价值不确定性。谭待认为，选择上云，是这个问题的最优解。火山引擎在这个方面的优势在于：</p><p>&nbsp;</p><p>资源复用，目前字节国内业务拥有过亿核CPU资源池、数十EB的企业存储。以此为基础，火山通过充分和抖音进行并池和混部，分钟级可调度十万级核CPU，实现更极致的弹性和性价比。全面云原生化，字节内部计算体系已经实现超过95%的容器化，并且基于云原生实现了超大规模存储池化。这些技术能帮助客户通过云原生进一步用好云的弹性，并且通过业务混布提升资源利用率。坚持全栈自研，包括自研服务器、自研OS、自研虚拟网络、自研mGPU技术等，将部署密度提升超过500%，为上层应用带来更高资源利用率。</p><p>&nbsp;</p><p>本次大会上，火山引擎还公布了全栈自研的新核心组件：火山引擎DPU。谭待表示，云计算的本质是资源池化和软件定义，但随着云基础设施规模越来越大，计算、存储、网络的虚拟化损耗始终占据10-20%的额外开销。要想提供更便宜的云服务，必须解决好这部分额外开销，把CPU和GPU释放到更关键的业务负载里。这就是火山要做DPU的原因。</p><p>&nbsp;</p><p>据悉，火山引擎DPU 整体网络性能升级到5000万pps转发能力，20us延迟。目前，字节内部已经实现上万台DPU的部署，并且将持续提升渗透率。基于自研DPU的各类计算实例性能也有显著提升，例如适用于大模型分布式并行训练场景的GPU实例，相较上一代实例集群性能最高提升3倍以上。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b2/b2b55385f7663f003eab4e3651f1a05e.png\" /></p><p></p><p>谭待认为，未来3年内，大规模的算力中心都将形成“CPU+GPU+DPU”的混合算力结构：CPU负责通用计算，GPU负责AI计算，DPU负责资源卸载、加速和隔离，提升资源效率。</p><p></p><h4>应对多云挑战</h4><p></p><p>&nbsp;</p><p>会上，谭待分享了一组数据：2022年，火山引擎对超过4500个云消耗大于100万的企业进行调研，使用多云架构的企业占比达到88%，达到历史新高；根据麦肯锡的报告，到2025年依然会有42%的企业保留有私有云；根据IDC报告，25年超过30%的数据需要边缘实时处理。</p><p>&nbsp;</p><p>谭待表示，造成这些现象背后的原因是复杂的，既有业务形态和成本管控的原因，也有数据安全和监管要求的原因。对于企业来说，必须要有能力来解决好这一分布式多云体系带来的挑战。</p><p>&nbsp;</p><p>那么，企业如何建设好分布式云？火山引擎认为需要解决好三个问题：一是从单一公共云架构向多公共云架构升级，实现降本增效；二是从传统私有云架构向混合云架构升级，既能保障数据安全也能享受云的弹性；三是基于“算力靠近数据”的理念，形成覆盖1-40ms不同延时的架构方案，包括现场边缘、近场边缘和云边缘的体系化架构。</p><p>&nbsp;</p><p>谭待表示，火山引擎是中国最懂多云和分布式云的云计算公司。因为字节跳动成立11年以来，内部使用过全球几乎每一朵公有云服务和边缘云服务，形成了一整套完整的分布式云管理体系和架构实践。</p><p>&nbsp;</p><p>会上，火山引擎正式发布分布式云原生平台，能够支持超过20万节点，千万级核的使用场景，可以实现火山引擎云、第三方云、IDC 私有云和边缘云上集群资源与权限的统一管理，实施应用跨集群分发和故障迁移。面向边缘场景，火山引擎正式发布多云CDN管理平台。该平台基于字节数百TB带宽，十多家CDN厂商实操经验构建而成。安全方面，火山引擎发布了全栈多云安全平台。</p><p>&nbsp;</p><p>最后，面向公有云和私有云长期并存的场景，火山引擎正式推出混合云平台：veStack。据悉，veStack采取和火山公有云完全同源的架构设计，搭配火山DPU后可以让裸金属资源利用率达到100%。此外，veStack也支持多种异构存储协议，支持海光、鲲鹏等国产芯片服务器等。</p><p>&nbsp;</p><p></p><h2>云上如何创新</h2><p></p><p>&nbsp;</p><p>谭待分享了两个现象：一是多模态基础大模型的风起云涌。随着ChatGPT 、GPT-4的推出，国内的大模型创新公司也在奋力追赶；二是大模型在垂直行业的加速应用。</p><p>&nbsp;</p><p>在ChatGPT带动下，大模型成为新的技术热点。有人认为，大模型将成为云厂商弯道超车的机会。对此，谭待表示，大模型还在发展初期，数据安全、内容安全、隐私保护、版权保护等许多问题还需要解决。但可以预见，大模型将带动云上AI算力急剧增长，AI算力的工作负载与通用算力的差距会越来越小，这会为各家云厂商带来新的机会，同时也会对数据中心、软硬件栈、PaaS平台带来新的挑战。</p><p>&nbsp;</p><p>在大模型及下游应用发展推动下，无论传统企业还是初创企业，对AI算力都有迫切需求，企业使用多家云服务将成为常态。同时，各行业有自己高质量的私有语料，大模型不会一家独大，而是会在千行百业生长，形成多模型共生甚至协作的生态。谭待表示，未来将是“多云多模型”的时代。</p><p>&nbsp;</p><p>为此，火山引擎发布了面向推荐场景的高速训练引擎，支持100GB-10TB+超大模型的高效训练。该引擎实现高可用PS-Worker架构，支持 PS、Chief、Worker 全方位容错。另外还支持多种模型瘦身技术、多种GPU模式，训练加速比10倍以上，综合成本可降低25%~67%。</p><p>&nbsp;</p><p>同时，火山引擎对去年发布的机器学习平台进行了升级：一是全新的实验管理-模型效果对比功能：二是支持弹性实例，资源灵活调度；三是针对大模型训练场景进行了全面优化，目前可以支持万卡级别大模型训练场景，微秒级超低延时网络。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/99/99b2ef4cf764e3e20ac7b391288b66ec.png\" /></p><p></p><p>需要明确的是，火山引擎自己并不做大模型，主要是服务做大模型的公司，比如MiniMax、智谱AI等。</p><p>&nbsp;</p><p>谭待表示，国内很多科技公司投入到大模型建设中，他们有优秀的技术团队，也有丰富的行业知识和创新想法，但往往缺乏经过大规模场景实践的系统工程能力。火山引擎要做的就是为大模型客户提供高稳定性和高性价比的AI基础设施。</p><p>&nbsp;</p><p>谭待介绍，大模型需要大算力才能做出来，此外还需要很好的工程能力，去解决千卡甚至万卡并行的训练问题、网络问题，以及训练过程中如何更早地进行人为干预、观测。这些非常依赖机器学习平台。</p><p>&nbsp;</p><p>“MiniMax的训练场景都跑在火山引擎上，我们吸引它的点，除了算力供给外，最重要的就是通过机器学习帮它解决了很多工程上的问题，让它的资源更好地集中在业务上，即模型训练、分析和提效上等。”谭待表示，“所以对于火山引擎来说，除了算力供给，另外一方面就是云原生机器学习平台。”</p><p>&nbsp;</p><p>MiniMax是目前国内少数已经推出自研大模型产品的AI技术公司，拥有文本、视觉、声音三种通用大模型引擎能力。据MiniMax联合创始人杨斌介绍，MiniMax与火山引擎合作建立了超大规模实验平台，实现千卡级常态化训练；超大规模推理平台有万卡级算力池，支撑单日过亿次调用。在火山引擎的云上，MiniMax大模型业务实现快速突破。</p><p>&nbsp;</p><p>谭待透露，国内大模型领域，七成以上已是火山引擎客户。</p><p>&nbsp;</p><p></p><h4>机器学习做智能化</h4><p></p><p>&nbsp;</p><p>在杨震原看来，机器学习很重要的一点，是把问题数字化。数字化可以让这个问题可以定量评估。当问题可以定量评估的时候，接下来就可以智能化，进一步用机器学习的方法来优化。</p><p>&nbsp;</p><p>但用机器学习做智能化会主要面临两个问题：复杂和贵。复杂是因为机器学习软件栈很深，有PyTorch、TensorFlow等很多平台，也涉及到框架、操作系统，还有底层的硬件等，每个环节都要做对、做好。贵则体现在人力、数据、硬件等的昂贵上。</p><p>&nbsp;</p><p>字节跳动副总裁杨震原认为，机器学习做得好不好可以用下面的三角形来表示，其中最重要的是算法。算法在效果上做到领先就能对业务产生很大的价值。而支撑算法效果需求的有两件事：一是硬件ROI，另一个是人力ROI。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/13/13dc3503bff79a07b8dfe2d5fdd03059.png\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>硬件ROI指的是单位模型的成本，人力ROI 是指招一个厉害的算法工程师进来，他能否发挥最大潜能，主要看系统能否支持他足够容易、足够敏捷地去尝试新的想法。“业务创新需要试错，试错要大胆、敏捷，但试错也一定要控制成本。”杨震原表示，火山引擎通过潮汐、混部等方式，来实现资源的高利用率和极低成本。</p><p>&nbsp;</p><p>以抖音推荐系统为例，工程师用15个月的样本训练某个模型，5小时就能完成训练，成本只有5000元。据悉，火爆全网的抖音“AI绘画”特效，从启动到上线只用一周多时间，模型由一名算法工程师完成训练。</p><p>&nbsp;</p><p>杨震原表示，火山引擎的机器学习平台是内外统一的，火山引擎客户和抖音会用使用同样的平台。</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-04-20 11:41:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "都是做 AIGC，亚马逊云科技怎么就那么“不一样”？",
    "url": "https://www.infoq.cn/article/j3qbSPiG9Hmapal2exir",
    "summary": "<p>去年起，生成式 AI 技术的发展引起了广泛关注，其中就包括 OpenAI 的 <a href=\"https://www.infoq.cn/article/5lzBBTLf5ddX8974MNVo\">ChatGPT</a>\" 模型，ChatGPT 模型甚至可以算为自然语言处理领域的重要里程碑之一，不仅在各种应用场景中得到了广泛的应用，同时也激发了各大科技公司的竞争热情。</p><p></p><p>4 月 13 日，在 AIGC 圈内一直处于“隐身”状态的<a href=\"https://www.infoq.cn/article/VWcXyicY1Iylo4Ikh2tJ\">亚马逊云科技</a>\"突然加入生成式 AI 竞赛。不鸣则已一鸣惊人，与大多服务 C 端用户的科技公司和那些选择在热点期发布 AIGC 产品不同的是，拥有丰富企业服务经验的云厂商亚马逊云科技打出了一套组合拳，结合多年对企业需求的观察，依托自己在云资源、云计算、机器学习技术研发等多方面的优势，从大模型到生成式 AI 工具，为大家交上了一份漂亮的答卷：</p><p></p><p>推出 Amazon Bedrock 服务和 Amazon Titan 大语言模型，以帮助云企业提高效率和创新能力；</p><p></p><p>提供两款基于自研 AI 训练 (Trainium) 与推理芯片 (Inferentia) 的专门针对生成式 AI 优化的高性价比的虚机实例 EC2 Trn1n 和 EC2 Inf2，帮助企业大幅节省生成式 AI 训练和推理的成本；</p><p></p><p>发布 AI 编码助手 Amazon CodeWhisperer，面向所有个人用户免费开放，不设任何资质或使用时长的限制！</p><p></p><p></p><h2>一、意料之中：亚马逊云科技基于 2B 经验及 ML 优势交出“漂亮答卷”</h2><p></p><p></p><p>在过去几个月，全球的科技公司几乎都发布了自家的 <a href=\"https://www.infoq.cn/video/p3dLdf62ug9k3x6DzDpH\">AIGC </a>\"类产品，生成式预训练语言模型更是成为了各家技术的博弈点。在这个过程中，亚马逊云科技的动作显得慢了一些，但其实一直在背后憋大招。上周五亚马逊云科技终于发布了生成式 AI 系列重磅产品，性能都颇为强悍，但也都在意料之中。</p><p>为什么会这样说？</p><p></p><p>以 ChatGPT 为代表的 AIGC 日益火热，让大家对 AI 技术产生了新关注。AIGC（生成式 AI）其背后的核心技术之一就是机器学习（ML），机器学习算法可以根据用户的输入和提示生成内容，这些内容包括但不限于文本和图片；机器学习模型则是基于大量数据进行预先训练的大模型，被称为基础模型（Foundation Models）。而机器学习创新一直是亚马逊云科技的 DNA。</p><p></p><p>我们能看到，亚马逊云科技多年来一直在不断降低机器学习技术的使用门槛，为机器学习提供高性能、可伸缩的基础设施和具有超高性价比的机器学习训练和推理，在人工智能和机器学习堆栈的三个层级都投入了众多技术研发成本，产出了不少重磅的产品组合。亚马逊云科技拥有超过 20 年人工智能和机器学习的实践经验，在赋能自有业务与千行百业创新方面做出了很多成绩。亚马逊云科技给企业提供的许多功能都是由机器学习驱动的，比如电商推荐引擎、运营中心捡货机器人的路径选择以及供应链、预测和产能规划等；又比如亚马逊云科技自己的 Prime Air（无人机）和 Amazon Go（线下无人零售实体店）中的计算机视觉场景中也都使用了深度学习技术。</p><p></p><p>这些技术上的积累，让亚马逊云科技站在了机器学习领域前沿，他们观察到目前机器学习技术正处于“拐点期”，计算能力提升、数据增长、模型复杂度提高三大因素正在驱动着机器学习技术的下一步演进。机器学习技术的演进直接带来了基础模型的爆发式增长，据亚马逊科技公开演讲中的数据，该类模型通常包含数十亿个参数或变量，像 2019 年最大的预训练模型是 3.3 亿个参数，但现在最大的模型的参数已超过 5000 亿，这相当于在这几年间，变量增加了 1600 倍。</p><p></p><p>同时，亚马逊云科技在与 Intuit、汤森路透、阿斯利康、法拉利、德甲联赛、3M 和宝马等数以万计的企业打交道的过程中，发现了许多企业对于生成式 AI 的诉求。根据当前大多业务的发展，企业需要能够直接找到并访问高性能基础模型，这些模型需要能够给出最匹配业务场景的优秀反馈结果。紧接着企业希望无缝与应用程序集成且无需管理大量基础设施集群的同时，还不会增加太多成本。在落地过程中，企业还需要自己的技术团队能够快速上手，能够基于基础模型利用自己具有“弹性”的数据构建差异化的应用程序。此外，企业需要在保证数据安全和隐私保护的同时，还能够控制数据共享和使用。</p><p></p><p>当下的企业需求确实比较复杂，但“复杂性”也不是一朝而成的，而亚马逊云科技作为行业发展的观察者，也早早就在机器学习方面做不同程度的技术探索，将这些企业痛点逐一击破。可以说，我们今天看到的亚马逊云科技发布的生成式 AI 和大模型产品，其实早就有迹可循。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/00/001e491232fc1558c41e0d6a7c499ed0.png\" /></p><p>图：在亚马逊云科技平台上构建生成式 AI</p><p></p><p></p><h2>二、与众不同：亚马逊云科技的生成式 AI 主要面向企业</h2><p></p><p></p><p>亚马逊云科技的天然基因就是有足够丰富的企业服务经验，所以与其他家推出的面向大众的 AIGC 类的产品不同，亚马逊云科技此次推出的产品，主要是瞄准了企业，深入对云基础设施和应用程序的变革，以推动生成式 AI 的创新。</p><p></p><p>为了解决企业需求，亚马逊云科技的生成式 AI 技术在过去几年里主要做了以下 5 方面的技术探索：</p><p></p><p>灵活性：从 AI21 Labs、Anthropic、Stability AI 以及 Amazon 构建的基础模型中选择，以找到适合企业使用的模型。</p><p></p><p>安全自定义：仅需数个已标记样本，就可为企业企业定制基础模型。由于所有数据均已加密，不会从亚马逊云科技虚拟私有云（VPC）泄露企业数据，所以数据将始终保持私密且机密。</p><p></p><p>成本效益不错的基础设施：利用由亚马逊云科技设计的机器学习芯片和 NVIDIA GPU 驱动的基础设施，可为生成式人工智能带来最佳性价比。经济有效地扩展基础设施，以训练和运行包含数千亿个参数的基础模型。</p><p></p><p>轻松上手基础模型构建：使用熟悉的控件与亚马逊云科技能力和服务，如 Amazon SageMaker 和 Amazon S3 的深度和广度的集成，快速将基础模型集成并部署到企业在亚马逊云科技上运行的应用程序和工作负载中。</p><p></p><p>生成式 AI 技术支持的解决方案：由于内置生成式人工智能，如 Amazon CodeWhisperer（一种人工智能编码伴侣）等服务可帮助企业提高效率。此外，可使用亚马逊云科技样例解决在方案部署中常见的生成式人工智能案例，如调用归纳总结与问答。此类解决方案将亚马逊云科技人工智能服务与领先的基础模型相结合。</p><p></p><p>在企业的期待中，亚马逊云科技在本次发布会中推出了 Amazon Bedrock 和 Amazon Titan 模型，借助基础模型构建和扩展生成式 AI 应用程序的最简单途径。Amazon Bedrock 既提供自研的大语言基础模型—— Amazon Titan Text 、Amazon Titan Embeddings，也与 AI21 Labs、Anthropic、Stability AI 等基础模型提供商广泛合作，助力企业轻松灵活构建生成式 AI 应用，降低所有开发者的使用门槛。</p><p></p><p>展开来讲就是，在 Bedrock 上，用户可以通过可扩展、可靠且安全的亚马逊云科技托管服务，访问从文本到图像的一系列强大的基础模型以及 Amazon Titan 基础模型。凭借 Bedrock 所带来的无服务器体验，企业可以快速找到适合自身业务的模型，在确保数据安全和隐私保护的前提下，使用自有数据基于基础模型进行个性化定制，将定制化模型集成并部署到他们已有的应用程序中，不需要管理其他任何基础设施。</p><p></p><p>Bedrock 最突出的能力就是极易定制模型，企业只需要向 Bedrock 提供 Amazon S3 中的 20 个标注好的数据示例，Bedrock 就可以针对特定任务完成模型微调，整个过程中，用户数据不会离开 VPC，有效地保证了用户的数据安全与隐私。</p><p></p><p>另外值得一提的是，Bedrock 还允许用户通过 API 访问来自 AI21 Labs、Anthropic、Stability AI 和亚马逊云科技的基础模型，Bedrock 的 serverless 方案，让用户只需调用 API，不需要关心底层基础设施，就可以轻松获得多语言 LLM 用于生成西班牙语 / 法语 / 德语 / 葡萄牙语 / 意大利语 / 荷兰语文本、LLM 用于会话和文本处理任务、文生图等大模型能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/86/8614374d3925e2db7350370223aeaf89.png\" /></p><p>左：来自亚马逊云科技的基础模型；右：来自 AI21 Labs、Anthropic 和 Stability AI 的基础模型</p><p></p><p>为了持续推动生成式 AI 在企业落地更多优秀实践，亚马逊云科技发布的 Titan 基础模型可以识别和删除客户提交给定制模型的数据中的有害内容，拒绝用户输入不当内容，过滤模型中不当内容的输出结果。本次亚马逊云科技的发布会上主要发布了两个 Titan 模型——针对总结、文本生成、分类、开放式问答和信息提取等任务的“生成式大语言模型”及能够将文本输入翻译成包含语义的数字表达的“文本嵌入（embeddings）大语言模型”。虽然这种大语言模型不生成文本，但在个性化推荐和搜索等应用程序上面的表现却十分亮眼，因为相对于文字匹配，编码对比可以帮助模型反馈更相关的结果。</p><p></p><p></p><h2>三、技术革命：生成式 AI 也需要生态</h2><p></p><p></p><p>事实上，无论运行、构建还是定制基础模型，除了这些业务需求，企业技术的底层需要还是离不开高性能、低成本且为机器学习专门构建的基础设施。于是，亚马逊云科技不只是在模型上下功夫，在生态方面也做了一些努力。</p><p></p><p>亚马逊云科技扩大了对定制芯片的创新，在本次发布会上，亚马逊云科技全新推出了两款专门针对生成式 AI 优化的计算实例 EC2 Trn1n 实例和 EC2 Inf2。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c4/c42f10f89eac61aa0204e33beb5f2ebe.png\" /></p><p>图：亚马逊云科技专为生成式 AI 设计的加速器</p><p></p><p>其中需要说明的是，训练实例 EC2 Trn1 由其自研芯片 Trainium 支持，与其他任何 EC2 实例相比，可节省高达 50% 的训练成本，历经优化后，已经可以在与高达 800Gbps 的第二代 EFA（弹性结构适配器）网络相连的多个服务器上分发训练任务，但 Trn1n 实例更为强悍它可以提供 1600 Gbps 的网络带宽，专为大型网络密集型模型设计，其性能比 Trn1 高出 20%。</p><p></p><p>企业在超大规模集群中部署 Trn1 实例时，数量就已经可以扩展到在同一可用区中 3 万个 Trainium 芯片，相当于超过 6 exaflops 的计算能力。Helixon、Money Forward 和亚马逊云科技的搜索团队曾在使用 Trn1 实例后，将训练大规模深度学习模型的时间从几个月缩短到了几天。所以，如果不出意外，此次亚马逊云科技发布的性能全面提升的全新网络优化型 Trn1n 实例将会带给我们更多惊喜。</p><p></p><p>无独有偶，2018 年亚马逊云科技发布了首款推理专用芯片 Inferentia，亚马逊云科技使用 Inferentia 运行了数万亿次推理，节省了数亿美元的成本，此次推理实例 Inf2 则是基于其自研芯片 Inferentia2，针对运行数千亿个参数模型的大规模生成式 AI 应用程序进行了优化，吞吐量提高了 4 倍，延迟降低了 10 倍，从这个数据来看，亚马逊云科技再次帮助企业大幅节省了生成式 AI 训练和推理的成本。</p><p></p><p>此外，Inferentia2 还可实现加速器之间的超高速连接以支持大规模分布式推理，与同类 Amazon EC2 实例相比，这些能力将推理性价比提高了 40%，并把云中的推理成本降到最低，企业利用 Inferentia2 可将部分模型的吞吐量提升至原来的两倍。</p><p></p><p>除了在芯片方面的创新，亚马逊云科技还发布了 AI 编码助手 Amazon CodeWhisperer，这是一款面向个人开发者免费使用的辅助代码编写工具，是一种人工智能代码生成扩展，目标是提高软件开发者的工作效率。开发者可以在没有亚马逊云科技账户的情况下，用邮箱完成 CodeWhisperer 的注册后开始使用，同时该工具对开发者不设任何资质或使用时长的限制。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a9/a9beea6bf2892c3be1a86359954263a6.png\" /></p><p>图：CodeWhisperer 三大能力</p><p></p><p>CodeWhisperer 可以更快地完成更多工作，避免软件开发人员花费大量时间编写非常简单且无差别的代码，CodeWhisperer 作为 AI 编码伴侣，它使用引擎盖下的 FM 通过根据开发人员的自然语言评论和集成开发环境 ( IDE ) 中的先前代码实时生成代码建议，从根本上提高开发人员的工作效率。</p><p></p><p>在软件供应链安全问题频发的今天，CodeWhisperer 有一个非常突出的亮点，其可以增强代码的安全性，该工具利用了亚马逊云科技在安全方面的积累来扫描各种安全问题，能自动扫描代码中的安全漏洞并帮用户修复。目前该工具提供 Python、Java、JavaScript、TypeScript、C#、Go、Kotlin、Rust、PHP 和 SQL 等十余种开发语言供开发者选择，同时开发者还可以通过在 VS Code、IntelliJ IDEA、Amazon Cloud9 等集成开发环境中的 Amazon Toolkit 插件访问 CodeWhisperer。</p><p></p><p>构建像 CodeWhisperer 这样强大的应用程序对开发人员来说是变革性的，但是从整个生成式 AI 生态的发展来看，利用正确的基础模型进行构建相关工具是非常有必要的。生成式 AI 的发展永远不仅仅是大模型，它需要在基础设施、一站式应用开发工具等层面“全面开花”，而亚马逊云科技已经为行业做出了一个很好的表率。</p><p></p><p>纵观整个行业的发展，对于云厂商来说，只有打造生态协同效应，切实帮助企业实现降本增效，才能走得更远。而形成“大小生态”的良好闭环是打造生态协同的必由之路，亚马逊云科技似乎就是在探索这样的一条路。人工智能作为云计算的一部分，人工智能产品构建自己的“AI 小生态”，通过“小生态”的构建去推动“云平台大生态”的发展，云厂商再利用“大生态”的势能反哺“AI 小生态”，转而促进单一 AI 能力的发展。</p><p></p><p>从目前亚马逊云科技搭建的“AI 小生态”来看，这些生成式 AI 能力和工具，不再是那些冰冷的性能提升数字，而是卓越性价比，为企业解决问题提供了切实可行的企业技术解决方案。回溯本身，亚马逊云科技之所以能够实现这些突破，源于将每一个客户的难题都视为一个新的探索方向，将“探索精神”和“创新精神”贯彻始终，输出接地气的技术能力和解决方案。不积跬步无以至千里，亚马逊云科技凭借其多年来积累的企业服务经验，深刻理解企业需求，并在实际业务中持续获取洞察，这必定能帮助亚马逊云科技在市场竞争中脱颖而出。</p><p></p><p>据悉，近期亚马逊云科技在生成式 AI 能力方面的发声不仅只有这一次发布会，有内部消息称，5 月 25 日将举办亚马逊云科技大模型及生成式 AI 发布深度解读大会，感兴趣的同学可以立即<a href=\"https://www.awsevents.cn/innovate/ai2023/registerSignUp.aspx?s=8440&amp;smid=17578\">点击此处</a>\"进行报名。</p>",
    "publish_time": "2023-04-20 14:10:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "云原生时代，如何建设稳定性可观测体系？",
    "url": "https://www.infoq.cn/article/cLOZHdYidBgziEl4ZaN6",
    "summary": "<p>从单体架构到集群架构再到微服务架构，业务越来越庞大，也越来越复杂。每一次架构的升级，在提升了业务吞吐量的同时，必然会带来更大的复杂度。云原生时代背景下，微服务、Service Mesh、 Serverless等新技术的出现，业务的复杂度很快就远远超越了个人的人力极限，大规模应用更是需要成千上万专业的人协作才能完成。应用稳定性链路中的因素也越来越多，一个应用相关的稳定性指标从基础设施到中间件，再到应用自身的模块、组件、中间件、基础设施等，每个环节都会有致命的因素导致应用无法正常提供服务。</p><p>&nbsp;</p><p>依赖传统的稳定性体系，通过日志服务查看业务日志，通过各个中间件去感知中间件的运行状态， 再通过网络、存储、操作系统层面的监控来查看基础监控信息， 这些信息每一个都只能片面的代表业务链路中的某一个节点的状态，且每个状态与其他节点之间都是割裂且毫无联系的。最终只能依赖人力投入，汇总分析最终判断，再验证。</p><p>&nbsp;</p><p>在互联网时代， 时间就是金钱这个真理从来都没有像今天这样被深刻的践行着，每一秒的不可用时间里都有可能产生大量的损失。于是，稳定性应急就越来越像是高悬头上的达摩克里斯之剑，成为让运维、研发的睡眠质量急速下降的罪魁祸首。</p><p></p><h2>可观测体系诞生的背景</h2><p></p><p></p><h4>数据孤岛问题</h4><p></p><p>&nbsp;</p><p>传统的方式下，基于稳定性体系的需求，业务稳定性需要完成： APM链路监控、 日志服务、指标监控等不同的解决方案才能完成异常因素的覆盖，而正是因为这样技术方案的影响下，稳定性体系变成了一个个割裂的数据孤岛，难以打通，难以联系，这直接导致故障的定位事件及稳定性体系的维护成本十分高昂。</p><p></p><h4>能力匹配问题</h4><p></p><p>&nbsp;</p><p>为了快速迭代，很多时候业务都需要很大程度上降低对开发质量的要求选择快速交付，这造成了大量的技术债务堆积。稳定性异常事件和风险高频出现，但稳定性能力建设对快速扩张的业务规模以及业务演进带来的技术复杂性应对不足，无法对复杂业务的稳定性应急提供高效的技术支撑。且在微服务，云原生编排， 弹性伸缩等技术的影响下，业务运行时的数量和位置会随着时间的变化而变化，这种变化虽然使业务更灵活和健壮，但同时也为稳定性带来了混乱，而这种混乱必须被解决。</p><p>&nbsp;</p><p>越复杂的系统可观测越难以实现，越复杂的系统对观测能力的要求越高。</p><p></p><h4>快速演进带来的核心诉求</h4><p></p><p>&nbsp;</p><p>系统可观测性越强，就能越迅速地了解为什么出现问题并修复，在这个分秒必争的时代，快速的解决业务异常问题，是对稳定性最核心的诉求，也是稳定性体系的价值所在，毕竟每秒钟的不可用时间都可能会带来难以承受的损失。</p><p>&nbsp;</p><p>在越来越复杂的业务拓扑下，传统的解决方案：即通过告警被动的发现业务异常已经不能满足应急诉求，通过观测手段主动发现，通过业务链路全貌定位到已存在或者潜在的问题才能更大程度上降低业务出现异常的风险，从而降低损失。</p><p></p><h4>数字化</h4><p></p><p>&nbsp;</p><p>用户对于业务运行质量的要求越来越高，业务需要对运行指标数据做分析，为可持续的技术优化、深度运维等提供有力的支撑，此外还需要通过数据来发现业务瓶颈，协助决策技术的演进方向，管理侧则需要对业务质量有更清晰明确的认知，促使业务优化的可持续性以及方向的正确性。</p><p></p><h2>如何理解可观测性？</h2><p></p><p>&nbsp;</p><p>告警是一个点，告诉我们发生了异常；监控可视化是一个个代表各种因素的平面，例如日志控制台、中间件控制台、基础监控dashboard、业务监控情况、请求链路情况等等；而可观测性就是一个将各个面联系起来，作为一个能够体现所有因素的整体。基于这个整体，可观测让我们拥有了一个全局的，包含上下游全链路信息的全局视角。在这个视角下，问题的定位将非常快速且清晰。</p><p>&nbsp;</p><p>总的来说：稳定性可观测 &gt;（日志服务 + 业务APM + 监控告警系统 + 各种稳定性相关的技术栈的组合）。</p><p></p><h3>可观测性的三大支柱</h3><p></p><p></p><h4>1、Log 日志 - 问题是什么？</h4><p></p><p>&nbsp;</p><p>⽇志是在特定时间发⽣的事件的⽂本记录，常见的⽇志有三种格式：纯⽂本、结构化和⼆进制。</p><p>&nbsp;</p><p>纯⽂本是最常⻅的，也是最容易采集的，但结构化⽇志：通过将日志数据进行结构化处理使得日志更容易检索和定位，同时配合大数据的手段可以基于日志产出更丰富且更灵活的指标，所以结构化日志是目前最为流行的解决方案。通过日志可以体现问题细节，告诉我们具体发生了什么事情。</p><p></p><h4>2、Trace 跟踪 - 问题出在哪里？</h4><p></p><p>&nbsp;</p><p>Trace表示分布式系统中一个请求从客户端到服务端完整的“旅程”详情，能够体现一个请求事务过程中所发生的每一件事情以及所发生的事情的状态及质量。</p><p></p><h4>3、Metric 指标 - 是否出现了问题？</h4><p></p><p>&nbsp;</p><p>指标是在一段时间内测量取样的数值，例如业务及性能的各项指标，可以通过对Metric的度量来反应业务运行的质量指标。</p><p></p><h3>传统稳定性体系VS可观测体系</h3><p></p><p>&nbsp;</p><p>传统的模式下，Log、Trace、Metric这三大支柱是各自独立，互不联系的独立个体，但是我们很容易就能发现： 这并不是一种正确的结构化观察的方法。调查问题的步骤通常是： 我们通过metric的度量（告警）发现了问题， 再去分别查看日志、trace等去定位原因，孤立的使用每个工具给操作者带来了很大的认知负担。</p><p>&nbsp;</p><p>例如： 找到跟一个异常告警相关的异常日志是个成本很高的事情， 或者调查一个请求异常需要先找到网关日志、业务日志、各种中间件日志再到各种基础设施日志， 相关的异常指标情况以及相关的跟踪信息，成本非常高。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c6/c6a099fa02107ef68c15d79fe4c66e89.png\" /></p><p></p><p>当系统足够庞大时，找到确切的问题日志甚至已经变的不太可能：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/48/48afb835431a7f1ba7ccf6ec71179650.png\" /></p><p></p><p>而可观测性则是把Log、 Trace、 Metric拧成了一股绳，让三大支柱互相之间建立亲密的“血缘关系”，通过这种关系我们可以结构化的从整体到局部再到具体细节的观测业务：</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/26/26f95cd625d1f09b0372b91367c69590.png\" /></p><p></p><p>如果把业务系统比作一座海上的冰山，监控仅能看到的是冰山之上，可观测性则能全面展现出冰山的全貌：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b0/b0fe3627d49a5296f08f7ebd7675e7b1.png\" /></p><p></p><p></p><h3>OpenTelemetry的架构设计与优势</h3><p></p><p>&nbsp;</p><p>Log、 Trace、 Metric是传统的稳定性解决方案，每一种解决方案都有多种不同的开源或商业软件可以支撑，问题是每个产品都有自己一套数据采集标准和SDK，异构的数据结构导致我们很难以用统一的方案建立数据关联。于是在这个背景下，诞生了Opentracing（分布式追踪数据规范）和OpenCensus（Traces + Metrics规范）等标准，然后，为了更好的将 Traces、Metrics 和 Logs 融合在一起，通过合并OpenTracing和OpenCensus这两个标准，诞生了OpenTelemetry。</p><p>&nbsp;</p><p>OpenTelemetry旨在管理观测类数据，如 trace、metrics、logs 等 (非固定未来很可能有新的观测类数据类型出现)。 OpenTelemetry 自身不提供与可观测性相关的后端服务，这类服务通常需要提供的是存储、查询、可视化等能力，需要基于自身需求来研发迭代。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/06/06273acce809bf92316d39d77ce5e323.png\" /></p><p></p><h4>架构设计</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3d/3d669552fc3280eceeb5407eb096d95e.png\" /></p><p></p><p>OpenTelemetry提供了一组API和库来标准化遥测数据的采集和传输。多语言支持： OpenTelemetry支持多种开发语言的后端。OpenTelemetry通过标准化以及工具体系降低了可观测体系建设的成本，让稳定性体系的建设者可以更专注于业务观测需求本身。</p><p></p><h4>优势</h4><p></p><p>&nbsp;</p><p>作为事实上的标准，OpenTelemetry具备厂商无关的特性，免于被某个厂商绑定的风险。多语言支持的SDK，OpenTelemetry 几乎为每个常见语言都实现了对应 SDK，可以方便的完成各种技术栈的适配对接，其中java agent利用字节码注入结束，可以实现低侵入的数据采集。OpenTelemetry的工具生态除了多语言的SDK支持之外还提供了开源的Collector来支持多种数据源的数据的上报采集，处理和输出。就像是kubernetes拿下了容器编排的标准一样，OpenTelemetry带来了可观测所需的标准且已经被广泛应用。标准化的优势在于面对各种技术栈都可以使用同样的解决方案。</p><p></p><h2>可观测性能力建设思考</h2><p></p><p>&nbsp;</p><p>对可观测性能力的建设来说，最关键最核心的问题是解决数据统一和关联让数据产生“血缘”关系。事实上这也是稳定性体系中最为繁重的地方。</p><p>&nbsp;</p><p>要解决这个问题，对于采集到的数据，可观测需要做大量的计算和关联操作。所以可观测并不是一个低成本的解决方案（网络数据：美国企业的可观测性相关投入为例，会占用企业整体 IT 支出的 5%-10%）。无论是研发成本还是资源成本，能力的建设都需要比较大的投入。可观测需要通过长时间的应用，为业务提供大量的数据支撑进行技术性优化，从而产生价值。</p><p></p><h3>可观测性建设面临的挑战</h3><p></p><p>&nbsp;</p><p>数据规模大：可观测数据为无界数据，会持续不断的产生并累加，这就需要大量的存储及计算成本。同时随着数据量大， 计算和检索数据的成本也越来越大，数据的存储成本也持续累加。数据关联计算成本高：各种中间件的稳定性数据， 埋点数据，基础设施监控数据，业务日志，网关日志等等建立联系需要做大量的计算。所需要投入的研发及资源成本较高。需求多样化：观测的角度，维度不一样， 可观测建设会产生大量的交互图表和拼装式能力要求。且为了应对多样化的诉求，很多时候都需要基于可观测性数据做二次应用， 例如输出稳定性指标，赋能一些业务场景中的需求等等。这些多样化的需求对可观测的能力灵活性要求很高。</p><p></p><h3>可观测性核心技术</h3><p></p><p></p><h4>1、数据采集</h4><p></p><p></p><p>技术生态</p><p>&nbsp;</p><p>客户端数据采集：OpenTelemetry提供了多语言的agent， 其中java独有的字节码注入技术可以在不侵入应用逻辑的前提下，仅需要添加一个启动项即可完成数据采集， 而目前其他语言则需要再业务逻辑的上下文中引用逻辑。这给业务带来了比较大的侵入性。</p><p>&nbsp;</p><p>一个更优的解决方案是ebpf，ebpf通过内核级的代码注入，以“上帝”视角观测操作系统之上的应用程序运行情况。但是ebpf本身的技术栈限定了内核态只能通过C++（rust也有希望）来开发， 且通过ebpf来采集数据需要对Linux内核API有比较深入的了解，同时还要针对各种协议做解析，因此开发成本较高。</p><p>&nbsp;</p><p>好消息是随着ebpf的生态不断的完善， 社区涌现了不少优秀的开源项目，例如deepflow，可以通过这些开源项目进行可观测能力的建设， 同时也可以将比较好的思路或者实现提交到社区，与社区一起共建。此外，为了更好的反映出业务的运行情况，同时也需要支持通过其他的agent采集所需要的数据，例如政采云的稳定性可观测平台就利用jvm-profile不断的采集火焰图数据， 为业务提供某一时刻的“现场”情况，协助业务研发更好的排查问题。</p><p>&nbsp;</p><p>数据处理： OpenTelemetry 提供了Collector来进行客户端数据的上报采集，处理和输出，其目的是打造一个万能的数据采集器，在支持各种数据源的数据采集的同时，还可以通过Collector对采集到的数据做初步的处理。但是目前Collector所提供的的能力未必能够满足实际的业务需求，因此，在政采云的场景中，我们基于Collector进行了二次开发，扩充了能力的同时基于自身需求进行了部分逻辑的定制化研发。</p><p>&nbsp;</p><p>数据计算</p><p>&nbsp;</p><p>采集到的数据本身是独立的离散数据，而数据的处理能力是可观测性的核心需求， 例如日志需要做格式化才能支撑更细粒度的关联需求，日志本身的规则，Trace链路的上下游关系，Metric度量，以及这三者的关系都需要对数据做大量的计算。</p><p>&nbsp;</p><p>可观测并不只是体现服务自身的情况，从客户端请求开始， 到流量网关，再到业务网关，再到应用， 应用会调用其他应用， 同时每个应用都涉及各种中间件的调用，中间件的运行情况也会对业务造成很大的影响，所以也十分重要，然后再到Kubernetes基础设施，再到IaaS层的基础设施，这整个链路任何一个环节出现问题最终都会表现为业务问题。</p><p>&nbsp;</p><p>可观测要体现全局的业务情况， 快速的观测到链路中的那个节点出现了问题，就必须将外部数据纳入可观测的体系中。链路中所能体现的稳定性因素占比是衡量可观测能力水平的重要依据。</p><p></p><h4>2、数据存储</h4><p></p><p>&nbsp;</p><p>可观测体系对于数据存储的要求是：满足可进行高速、大数据量查询，能应对数据规模的线性增长的同时保障数据访问效率。因为可观测的数据会不断的持续累加，这导致存储规模的不断增大，不仅仅产生了过高的存储成本，同时很大程度上影响查询效率。因此对于数据就需要做好取舍，规划好日志的存储资源，例如一些业务日志具备存储价值，一些安全审计的日志更是需要长期留存， 同时大部分的业务日志本身具备时效性。</p><p>&nbsp;</p><p>因此，可观测的日志体系就需要对日志定义灵活的存储周期，根据日志的时效性要求灵活的定制存储时长并自动清理。对于Trace数据，业务流量巨大的情况下，100%的存储会造成很大的性能及资源压力，因此可以根据实际情况进行采样存储。</p><p></p><h4>3、数据分析</h4><p></p><p>&nbsp;</p><p>基于数据的计算，各种指标、中间件、应用依赖、告警等等数据产生了联系， 这种联系不仅仅可以为稳定性应急赋能，实际上可观测的定义中， 定位问题只是能力之一，更广义一点的定义：可观测要帮助业务更细粒度的了解自己的业务， 发现潜在风险，发现性能缺陷等等，同时，可观测性数据可以支撑对研发质量的管控：输出考核性指标。</p><p>&nbsp;</p><p>例如： 可观测可以告诉你应用存在那些性能低下的SQL， 告诉你存在那些不合理的调用以及不合理的技术运用。基于有关联的数据，输出这些指标会变的非常容易。</p><p></p><h4>4、数据可视化</h4><p></p><p>&nbsp;</p><p>数据的呈现最终要通过可视化来解决，问题是：单一基于需求定制的可视化实际上只能片面的展示一部分维度的数据。很多时候不同的角色，希望看到的指标是不一样的，例如运维希望从全局到局部的去掌握当前存在异常或者风险的点，更关注基础设施的稳定性情况。而研发关心的是：以应用为中心所负责的业务更明细的稳定性指标情况，而部门的主管则关心：平台整体的稳定性质量考核指标是什么样子的。</p><p>&nbsp;</p><p>每一种需求都存在合理性，只是体现的维度不同而已，因此首先可观测的数据体系应该具备多个视角的，例如：运维视角，开发视角，乃至于在稳定性体系之外， 还需要建立指标运营体系来满足指标考核的需要。另外，在不同的业务场景下，所需要关心的业务稳定性的指标很可能是不同的，因此可观测的可视化还需要支持用户可定制的组装式解决方案， 通过可视化界面或者类SQL语句来自由定制。例如支持业务研发自定义稳定性大盘。</p><p></p><h2>总结</h2><p></p><p>&nbsp;</p><p>随着业务系统拓扑的复杂度越来越高，业务对于稳定性的要求也不断升高，稳定性可观测为业务提供了白盒的全局观测能力，支撑业务快速定位异常，很大程度上可以解决稳定性应急效率底下和应急复杂度过高的问题。稳定性可观测可以各种维度的体现业务运行指标情况，可以赋能业务，感知潜在问题及风险，输出稳定性考核指标，同时通过可观测的数据运营支撑稳定性体系数字化。可观测性通过为业务提供数据支撑帮助业务持续的进行技术优化而体现价值。可观测体系并不是低成本的解决方案，在实现的过程中需要较多的资源投入。但在当下的进程中数字化已经凸显了对可观测性的强烈需求，在不远的将来，不考虑可观测性体系建设的业务很可能将无法满足用户越来越高的服务水平要求。</p><p></p><h4>作者介绍</h4><p></p><p>&nbsp;</p><p>汪勋，政采云有限公司运维开发团队负责人，关注 DevOps、平台工程，以及稳定性可观测、持续集成持续交付、云原生技术等各种运维能力。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://lib.jimmysong.io/opentelemetry-obervability\">https://lib.jimmysong.io/opentelemetry-obervability</a>\"<a href=\"https://newrelic.com/blog/best-practices/opentelemetry-opentracing-opencensus\">https://newrelic.com/blog/best-practices/opentelemetry-opentracing-opencensus</a>\"</p>",
    "publish_time": "2023-04-20 14:16:40",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]