[
  {
    "title": "警方通报网传中电科加班事件调查结果；逼死程序员诈骗千万的“翟欣欣案”一审宣判；比特币白皮书隐藏在 macOS中｜ Q资讯",
    "url": "https://www.infoq.cn/article/D5pflLk3qGfehXllW492",
    "summary": "<p></p><blockquote>抖音与腾讯视频达成合作，网友：怎么有种见证历史的感觉；拼多多解散了在应用中加入恶意功能的团队；警方通报网传中电科加班事件调查结果；逼死Wephone创始人、诈骗千万的“翟欣欣案”一审宣判；三星引入ChatGPT不到20天就出事，半导体机密恐已外泄；爆ChatGPT大规模封号亚洲节点，尤其是使用中文对话的用户；搭载 RISC-V 芯片的 ROMA 开放笔记本电脑发布；首批因AI失业的人出现，某游戏公司裁掉半数原画师；比特币白皮书隐藏在 macOS Mojave 之后的所有版本中......</blockquote><p></p><p>&nbsp;</p><p></p><h2>科技企业</h2><p></p><p>&nbsp;</p><p></p><h4>抖音与腾讯视频达成合作，网友：怎么有种见证历史的感觉</h4><p></p><p>&nbsp;</p><p>4月7日消息，抖音旗下官方账号“抖音和 ta 的朋友们”发布消息称，近期抖音和腾讯视频达成合作，双方将围绕长短视频联动推广、短视频二次创作等方面展开探索。根据合作，腾讯视频将向抖音授权其享有信息网络传播权及转授权权利的长视频，并明确了二创方式、发布规则。未来，抖音集团旗下抖音、西瓜视频、今日头条等平台用户都可以对这些作品进行二次创作。</p><p>&nbsp;</p><p>在版权问题上，抖音和腾讯视频多有纠葛。去年，抖音因侵权《云南虫谷》被西安市中级人民法院判赔腾讯3200余万元，创下“影视版权侵权案最大索赔”。如今，抖音和腾讯视频达成和解，引得不少网友感慨：“怎么有种见证历史的感觉？”</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c1/c10127ef297c9cbdc5f77132355136e0.jpeg\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>拼多多解散了在应用中加入恶意功能的团队</h4><p></p><p>&nbsp;</p><p><a href=\"https://edition.cnn.com/2023/04/02/tech/china-pinduoduo-malware-cybersecurity-analysis-intl-hnk/index.html\">据CNN消息</a>\"，谷歌发现拼多多存在恶意行为，包括未经用户同意收集个人信息、使用非法的广告技术以及通过其他非法活动来获取收入，于是谷歌将拼多多下架，并建议已下载的用户删除App。</p><p>&nbsp;</p><p>CNN 在收到举报后与来自亚洲、欧洲和美国的六个网络安全团队以及多名拼多多前雇员和现雇员进行了交谈，网络安全专家称，“从未见过（拼多多）这样的事情”。而据匿名员工的消息，公司在 2020 年组建了一支由大约 100 名工程师和产品经理组成的团队，致力于挖掘 Android 手机漏洞，开发漏洞利用方法，将其转化为利润。</p><p>&nbsp;</p><p>3 月 5 日，拼多多发布了其应用程序的更新版本 6.50.0，删除了这些漏洞。消息人士称，在更新两天后，该团队被解散：“团队成员发现他们被内部使用的工作通讯应用 Kn­o­ck 锁定，失去了访问内网文件的权限。工程师访问大数据、数据表和日志系统的权限也被撤销。大部分团队成员被转移到了 Te­mu，被分配到不同部门，从事营销或开发推送通知的工作。20 名核心的网络安全工程师仍然留在公司。”</p><p>&nbsp;</p><p></p><h4>警方通报网传中电科加班事件调查结果</h4><p></p><p>&nbsp;</p><p>4月5日，一段员工怒怼领导的聊天记录登上微博热搜。中国电科（CETC）成都区陈姓员工因被上级强行安排加班，直接在群聊中用激烈的言语痛斥部门领导长期无理要求员工加班，用压榨下属的方式讨好上司。</p><p>&nbsp;</p><p>当事人声称自己全部门同事整月从8点上班，到晚上11点下班，严重违反劳动法，而公司领导却在家悠闲“躺平”，激起群愤。这最终导致软件开发部门23人集体请求辞职，硬件和其他部门的员工也有几十人纷纷请辞。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e2/e2216cec36bc195a0f205d7e30aabbb0.jpeg\" /></p><p></p><p></p><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/05/055cd7de3aef370b0de5775c7ce4bc95.jpeg\" /></p><p></p><p>&nbsp;</p><p>4月5日，中国电科回应称，中国电科高度重视，认真排查，上述微信群聊天记录所涉单位和人员，非集团公司所属成员单位和员工。尽管中国电科否认上述内容，但舆论仍在发酵。</p><p>&nbsp;</p><p>4月7日，@平安德阳经开区 微博通报，经初查，陈某龙目前居住在德阳经开区，系网上发布不实信息者，因此前向中国电科求职未被录用，心生不满，利用图像处理软件虚设“CETC一软件开发课”“CETC成都事业部”2个微信群，虚拟CETC员工姓名、头像，捏造制作了多张“怒怼领导、发泄情绪”的微信聊天记录截图，并发布在网络社交平台，引发公众热议，造成恶劣影响。警方已依法对其作出行拘处罚。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/77/77e627f8fb95d88ce4337f93b2d15c0c.jpeg\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>逼死Wephone创始人、诈骗千万的“翟欣欣案”一审宣判</h4><p></p><p>&nbsp;</p><p>六年前，曾有一条新闻轰动全网——闪婚41天之后，因妻子翟欣欣索要千万财产，Wephone创始人、程序员苏享茂被逼无奈，在互联网上留下公开遗书，跳楼自杀。2018年苏享茂家属将翟欣欣告上法庭，要求法院撤销苏享茂价值近千万的赠予，并要求对方返还近百万现金。</p><p>&nbsp;</p><p>本周，据红星新闻报道，本案于3月31日在北京市朝阳区人民法院宣判，一审判决翟欣欣退还苏享茂家属现金、汽车共近千万以及撤销翟欣欣海南、北京两套房产的个人所有权。</p><p>&nbsp;</p><p>赠予合同纠纷一案判决书显示，根据审理查明的情况，翟欣欣与苏享茂相识至协议离婚仅110余天，期间收受苏享茂赠与的车辆、物品、款价值超过300万元，婚恋过程具有明显的经济特征。翟欣欣在离婚中为取得高额补偿，对苏享茂实施了胁迫，未顾及到苏享茂赠与其财产、希望与其共同生活、维系感情的初衷以及苏享茂受胁迫下的主观感受和客观经济情况，是造成苏享茂自杀的重要因素。翟欣欣与苏享茂婚恋，以增加自身财产为目的受赠取得的大额婚前婚后财产，均属可撤销范围。</p><p>&nbsp;</p><p>根据此份判决，翟欣欣需退还苏享茂家属价值约108万元的特斯拉汽车一辆；退还价值30余万的卡蒂尔钻戒和项链；退还转账共计186万余元。根据离婚后财产纠纷一案判决书显示，翟欣欣在离婚过程中采取胁迫手段，使苏享茂陷于恐惧而作出非自愿意思表示，符合可撤销行为法律特征。</p><p>&nbsp;</p><p></p><h4>三星引入ChatGPT不到20天就出事，半导体机密恐已外泄</h4><p></p><p>&nbsp;</p><p>据韩国媒体报道，三星电子引入ChatGPT不到20天，近日便曝出机密资料外泄的给意外事故，涉及半导体设备测量资料、产品良率等内容，传已经被存入ChatGPT的数据库中。总共有3起事故涉及ChatGPT，2个跟半导体设备有关，1个跟会议内容有关。据悉，三星DS设备解决方案部门的员工在操作半导体测试设备下载软件的过程中，发现复制有问题，他就把有问题的代码复制到ChatGPT中寻找答案，这很可能让ChatGPT把三星的机密信息当作训练资料使用。另一个事故也是DS设备部门的，也是寻求ChatGPT来优化代码，只不过这个代码是涉及芯片良率的，第三起则是让ChatGPT记录会议内容，虽然不是技术机密，但也可能导致会议内容外泄。</p><p>&nbsp;</p><p>更多阅读：</p><p><a href=\"https://mp.weixin.qq.com/s/YewUFX6nT3xAxadTtmFgYA\">三星被曝芯片机密代码遭ChatGPT泄露，引入不到20天就出3起事故，内部考虑重新禁用</a>\"</p><p>&nbsp;</p><p></p><h2>IT业界</h2><p></p><p>&nbsp;</p><p></p><h4>爆ChatGPT大规模封号亚洲节点，尤其是使用中文对话的用户</h4><p></p><p>&nbsp;</p><p>4月3日消息，据上观新闻报道，ChatGPT大面积封号，即使开通了付费的会员也无法幸免于难。数据显示，OpenAI的本次封号处理主要集中在亚洲地区，尤其是使用中文对话的用户和批量注册的账号。据统计，已有数百万用户的账号受到了影响。ChatGPT 突然的封控行动，业内人士认为风控最最可能相关的有三个：本身账号使用的邮箱权重；登录的 IP 或代理服务器的所在地(比如在中国，批量封)；页面所有 ChatGPT 使用中文（这个可能不会让你直接封号，但是会上调风控级别）。不仅是个人用户容易中招，国内不少公司都把业务接入到ChatGPT API了。不过随后国内也有多家A股上市公司否认自己被封号。因为ChatGPT概念股价涨了2倍的汤姆猫公司澄清，表示被封号的相关消息不实，公司目前API接入正常。</p><p>&nbsp;</p><p></p><h4>搭载 RISC-V 芯片的 ROMA 开放笔记本电脑发布</h4><p></p><p>&nbsp;</p><p>近日，第十届开源操作系统年度技术会议（OS2ATC）在京举办，会上发布了全球首款 RISC-V 笔记本电脑“ROMA”。该设备搭载 openKylin（开放麒麟）国产操作系统，是由 RISC-V 基金会牵头，深度数智开发、鉴释科技调试的原生 RISC-V 开发笔记本电脑，可体验原生 RISC-V 开发及 RISC-V 软件生态系统。</p><p>&nbsp;</p><p>RISC-V 是由加州大学伯克利分校开发并开源的，基于精简指令集思想设计的 CPU 指令集架构（ISA）。与主流的 x86、ARM 指令集不同，RISC-V 完全开源，任何企业都可以免费使用该指令集设计自己的 CPU 微架构（microarchitecture），甚至对指令集进行自主扩展。由于 RISC-V 采用了大量现代设计思想，厂商可以基于该指令集设计出针对各类应用场景（嵌入式/物联网设备、低功耗便携设备、PC、服务器）的处理器。</p><p>&nbsp;</p><p>本次发布的 ROMA PC 采用了国产 RISC-V SoC 芯片，但没有公布开发厂商和具体的参数。该芯片采用 12nm (专业版)/28nm (标准版) SoM 封装，配备 GPU、NPU 和功能加速器，有四个 CPU 核心，支持 16GB LPDDR4/LPDDR4X 内存。鉴释科技研发的 RISC-V 高性能编译器已经适配该芯片。</p><p>&nbsp;</p><p></p><h4>首批因AI失业的人出现，某游戏公司裁掉半数原画师</h4><p></p><p>&nbsp;</p><p>4月5日，据时代财经消息，已经有一众游戏公司将AI绘画引进工作流程，用以摆脱游戏行业巨大的人才压力和资金焦虑，根据早前心动网络创始人黄一孟透露的消息，已有游戏团队把原画外包团队给砍了。另有某游戏美术外包公司的技术总监也透露，在近一个月，其所在公司已经裁掉了一半的原画师。</p><p>&nbsp;</p><p>据介绍，原画师利用Al完成方案，工作效率至少能提升50%以上。此次AI对游戏原画师造成的冲击，来自今年2月发布的一款名为ControlNet的通用型插件。在这一插件的基础上，AI绘图软件Stable Diffusion可以更精准地呈现人体姿态、画面层次感，以及复杂的三维结构，并支持用户对图片细节进行调整，这将有效解决此前AI绘图难以解决的肢体细节问题。</p><p>&nbsp;</p><p></p><h4>比特币白皮书隐藏在 macOS Mojave 之后的所有版本中</h4><p></p><p>&nbsp;</p><p>据奇客Solidot消息，一位苹果 macOS 用户在修复打印机时无意中发现中本聪著名的比特币白皮书作为示例文档隐藏在 2018 年之后发布的所有 macOS 版本中。从 Mojave (10.14.0) 到当前版本 Ventura (13.3)都包含该文档，如果你是 Mac 用户，可以在终端输入命令“open /System/Library/Image\\Capture/Devices/VirtualScanner.app/Contents/Resources/simpledoc.pdf” 。High Sierra (10.13) 以及之前的版本不包含该白皮书。有消息来源称，白皮书是一位苹果工程师放置的，一年前苹果内部有人认为包含该白皮书不妥，但问题分配给了这位工程师去处理，而此人没有采取任何行动。</p>",
    "publish_time": "2023-04-09 12:11:20",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "通用视觉的GPT时刻来临？智源推出通用分割模型SegGPT，可「分割一切 」",
    "url": "https://www.infoq.cn/article/3vwqK0O6lj1ZOTE4wmmI",
    "summary": "<p>ChatGPT引发了语言大模型狂潮，AI另一个重大领域 — 视觉的GPT时刻何时到来？</p><p></p><p>4月8日，智源研究院视觉团队推出通用分割模型SegGPT（Segment Everything In Context）——首个利用视觉提示（prompt）完成任意分割任务的通用视觉模型。</p><p>&nbsp;</p><p>SegGPT与Meta AI图像分割基础模型SAM同时发布，两者的差异在于：</p><p></p><p>•&nbsp;SegGPT“一通百通”：给出一个或几个示例图像和意图掩码，模型就能get用户意图，“有样学样”地完成类似分割任务。用户在画面上标注识别一类物体，即可批量化识别分割同类物体，无论是在当前画面还是其他画面或视频环境中。</p><p></p><p>•&nbsp;SAM“一触即通”：通过一个点或边界框，在待预测图片上给出交互提示，识别分割画面上的指定物体。</p><p>无论是“一触即通”还是“一通百通”，都意味着视觉模型已经“理解”了图像结构。SAM精细标注能力与SegGPT的通用分割标注能力相结合，能把任意图像从像素阵列解析为视觉结构单元，像生物视觉那样理解任意场景，通用视觉GPT曙光乍现。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/39/396fdfbcfb76d86e37d53e998b0f80d9.png\" /></p><p></p><p></p><p>论文地址：https://arxiv.org/abs/2304.03284</p><p>代码地址：<a href=\"https://github.com/baaivision/Painter\">https://github.com/baaivision/Painter</a>\"</p><p>Demo：https://huggingface.co/spaces/BAAI/SegGPT</p><p>&nbsp;</p><p>SegGPT是智源通用视觉模型Painter的衍生模型，针对分割一切物体的目标做出优化。SegGPT训练完成后无需微调，只需提供示例即可自动推理并完成对应分割任务，包括图像和视频中的实例、类别、零部件、轮廓、文本、人脸等等。</p><p>&nbsp;</p><p>该模型具有以下优势能力：</p><p></p><p>1.&nbsp;通用能力：SegGPT具有上下文推理能力，模型能够根据提供的分割示例（prompt），对预测进行自适应的调整，实现对“everything”的分割，包括实例、类别、零部件、轮廓、文本、人脸、医学图像等。</p><p>2.&nbsp;灵活推理能力：支持任意数量的prompt；支持针对特定场景的tuned prompt；可以用不同颜色的mask表示不同目标，实现并行分割推理。</p><p>3.&nbsp;自动视频分割和追踪能力：以第一帧图像和对应的物体掩码作为上下文示例，SegGPT能够自动对后续视频帧进行分割，并且可以用掩码的颜色作为物体的ID，实现自动追踪。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>案例展示</h2><p></p><p>&nbsp;</p><p>1.&nbsp;标注出一个画面中的彩虹（上图），可批量化分割其他画面中的彩虹（下图）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a9/a9696564fc7ede8557837c038f396cb8.png\" /></p><p></p><p></p><p>&nbsp;</p><p>2.&nbsp;作者在广泛的任务上对SegGPT进行了评估，包括少样本语义分割、视频对象分割、语义分割和全景分割。下图中具体展示了SegGPT在实例、类别、零部件、轮廓、文本和任意形状物体上的分割结果。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b5/b5ae99f498e7dcf98eee1af0383a3ff6.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ba/ba3220954bc4d67ef7aa1ce9bdf848d9.png\" /></p><p></p><p>3.&nbsp;用画笔大致圈出行星环带（上图），在预测图中准确输出目标图像中的行星环带（下图）。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/96/96e283c7028c2f05c362e8c5ddccb4fd.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/9621a289d0833b586017514b80c127b1.png\" /></p><p></p><p>&nbsp;</p><p>4.&nbsp;SegGPT能够根据用户提供的宇航员头盔掩码这一上下文（上图），在新的图片中预测出对应的宇航员头盔区域（下图）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/aa/aa9bd96bd528c847f65d8a4158db9baa.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/83/83ba81c2fa8af33e5c53763a287120c5.png\" /></p><p></p><p></p><h2>训练方法</h2><p></p><p>&nbsp;</p><p>SegGPT将不同的分割任务统一到一个通用的上下文学习框架中，通过将各类分割数据转换为相同格式的图像来统一各式各样的数据形式。</p><p></p><p>具体来说，SegGPT的训练被定义为一个上下文着色问题，对于每个数据样本都有随机的颜色映射。目标是根据上下文完成各种任务，而不是依赖于特定的颜色。训练后，SegGPT可以通过上下文推理在图像或视频中执行任意分割任务，例如实例、类别、零部件、轮廓、文本等。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/68/68058bc1c8a21d0c18f20b4a987f9749.png\" /></p><p></p><p></p><h2>Test-time techniques</h2><p></p><p>&nbsp;</p><p>如何通过test-time techniques解锁各种能力是通用模型的一大亮点。SegGPT论文中提出了多个技术来解锁和增强各类分割能力，比如下图所示的不同的context ensemble方法。所提出的Feature Ensemble方法可以支持任意数量的prompt示例，实现丰俭由人的推理效果。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/25/2591da62eb0e3f27274325d5728e7524.png\" /></p><p></p><p>此外，SegGPT还支持对特定场景优化专用prompt提示。对于针对性的使用场景，SegGPT可以通过prompt tuning得到对应prompt，无需更新模型参数来适用于特定场景。比如，针对某一数据集自动构建一个对应的prompt，或者针对一个房间来构建专用prompt。如下图所示：</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/28/28ac98447fa53dd47b01ff09d2babbeb.png\" /></p><p></p><p>&nbsp;</p><p></p><h2>结果展示</h2><p></p><p>&nbsp;</p><p>模型只需少数prompt示例，在COCO和PASCAL数据集上取得最优性能。SegGPT显示出强大的零样本场景迁移能力，比如在少样本语义分割测试集FSS-1000上，在无需训练的情况下取得state-of-the-art性能。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/31/31fbdc40ebab75a9ad449f50c3be2c0d.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/74/74562c2c6b51235298d852a37124198e.png\" /></p><p></p><p></p><p>无需视频训练数据，SegGPT可直接进行视频物体分割，并取得和针对视频物体分割专门优化的模型相当的性能。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3a/3ab18e83910e8b2a062a626feee0d9a5.png\" /></p><p></p><p></p><p>以下是基于tuned prompt在语义分割和实例分割任务上的效果展示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/38/38caa20aed1f718f5ae0da6948ebefa2.png\" /></p><p></p><p>&nbsp;</p>",
    "publish_time": "2023-04-09 12:56:38",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "华为去年拿出 720 亿分红；谷歌亚马逊开高价鼓励欧洲员工自愿离职；国美 CTO 回应员工贷款上班 | AI 一周资讯",
    "url": "https://www.infoq.cn/article/8HsbpKpXKB8svyXOYdiV",
    "summary": "<p></p><p></p><blockquote>阿里大模型来了，“通义千问”开启企业邀测；科大讯飞将在5月发布“1+N认知智能大模型”；意大利“封杀”ChatGPT后续，OpenAI拿出了补救方案；ChatGPT停售Plus服务；比尔·盖茨：呼吁暂停人工智能开发不能化解未来的挑战...</blockquote><p></p><p></p><p></p><h2>资讯</h2><p></p><p></p><h4>阿里大模型来了，“通义千问”开启企业邀测</h4><p></p><p>4月7日，阿里自研大模型“通义千问”开始邀请用户测试体验。现阶段该模型主要定向邀请企业用户进行体验测试，用户可通过官网申请（tongyi.aliyun.com），符合条件的用户可参与体验。</p><p></p><p>据悉，阿里达摩院在NLP自然语言处理等前沿科研领域早已布局多年，并于2019年启动大模型研发。2021年，阿里先后发布国内首个超百亿参数的多模态大模型M6及被称为“中文版GPT-3”的语言大模型PLUG，此后还训练实现了全球首个10万亿参数AI模型。</p><p></p><h4>让员工贷款上班，公司报销利息？国美CTO回应：虚假消息</h4><p></p><p>近日，一名认证为国美零售员工的网友在职场应用平台上爆料，国美开启了新型上班模式：贷款上班，公司报销部分利息。</p><p></p><p>该员工发布的截图显示，一名身份未明的人士发言道，为缓解大家欠薪下的生活压力，李一冰(国美CTO)引入民生银行信用贷，年利率3.48%。在公司发薪前，每月为员工报销3万元以内的贷款利息，超出部分员工自行负责。该人士强调，相对于利息，更重要的是优惠的年利率，有意向者可登记。</p><p></p><p>针对此事，国美公关部回应上证报称，“国美CTO李一冰本人表示：此为虚假信息。”</p><p></p><h4>科大讯飞将在5月发布“1+N认知智能大模型”</h4><p></p><p>近日在人工智能大模型发展论坛上，科大讯飞副总裁、研究院执行院长刘聪透露：科大讯飞“1+N认知智能大模型”将在5月6日正式发布。</p><p></p><p>其中，“1”是通用认知智能大模型算法研发及高效训练底座平台，“N”则是应用于多个行业领域的专用大模型版本。同时，“N”个场景的示范性应用产品也将随之呈现。</p><p></p><p>3月14日，科大讯飞发布公告称公司接受招商基金及中金公司等机构调研。在调研中，公司表示计划采用“1+N”架构进一步提高大模型在细分行业的实用性。讯飞拥有一流的数据中心，在工程技术方面实现了百亿参数大模型推理效率的近千倍加速。</p><p></p><h4>意大利“封杀”ChatGPT后续，OpenAI拿出了补救方案</h4><p></p><p>4月6日，据路透社4月6日消息，意大利数据保护局(Garante per la Protezione dei Dati Personali)表示，OpenAI计划当地时间周四向意大利当局提交补救措施，寻求缓解意方担忧。意大利数据保护局称，在当地时间周三晚的视频会议上，OpenAI承诺在处理用户数据和核实用户年龄的方式上更加透明。该机构表示将评估OpenAI提出的措施。</p><p></p><p>意大利数据保护局 Garante 在 3 月 31 日宣布暂时禁用 ChatGPT，并对其涉嫌违反隐私规则展开了调查。目前OpenAI 已在意大利下线 ChatGPT，意大利也成为了全球首个封禁 ChatGPT 的国家（部分国家和地区在一开始就无法使用 ChatGPT）。</p><p></p><h4>在欧洲裁员很难办，谷歌亚马逊开出丰厚补偿鼓励员工自愿离职</h4><p></p><p>美国大型科技公司面临的一个新的难题是，如何在欧洲裁减员工。因为欧洲的劳动保护法更严格，在某些国家如果不事先与员工利益团体协商，解雇员工几乎是不可能的。</p><p></p><p>据知情人透露，在法国，谷歌的母公司Alphabet正在与员工就自愿离职进行谈判，公司愿提供丰厚的补偿以实现减员目标。为了让高级管理人员辞职，亚马逊则提供高达一年薪水的悬赏，并兑现离职员工股票作为奖金。</p><p></p><p>法国和德国的劳动法在欧盟中最为严格。据悉谷歌正在与劳工委员会进行谈判，该团体由公司内部选举产生的员工代表组成，他们与管理层就劳动力问题谈判。</p><p></p><p>在巴黎，谷歌有大约1600名员工，工会正在就多少员工以及哪些类型的员工将被纳入自愿集体离职计划与公司进行谈判。知情人士表示，解决方案出炉可能需要数周时间，而在此期间，一切都会照常进行。一位匿名员工透露，管理层明确表示不会强迫任何员工离开。</p><p></p><p>据悉，亚马逊法国在巴黎有大约1,500名办公室员工，一些工作了5至8年的高级经理被提供了一年的薪水，可以选择离职。离职员工被允许在“园艺休假”期间继续留在公司，直到5月份亚马逊股票解除限制并支付奖金时才正式离职。</p><p></p><p>据悉，亚马逊过去几年的员工离职补偿标准非常低，每工作一年只得到不到一个月的补偿。</p><p></p><p>一位知情人士透露，亚马逊德国分公司已经开始开除仍处于试用期的员工，并提供自愿离职方案。而另一位知情人士透露，在亚马逊卢森堡分公司，离职员工每年服务期得到一个月的薪水，并额外获得根据国家法律规定的补贴。裁员提议始于上月中旬，离职员工将于4月1日或6月1日离开，具体时间取决于他们是否参加了为期两个月的内部求职窗口。</p><p></p><p></p><h4>华为余承东将“跳槽”到小米汽车？小米回应了</h4><p></p><p></p><p>4月5日，有传言称，华为终端公司总裁余承东将赴小米汽车任职。对此，小米集团公关负责人对第一财经回应称，此消息不实。</p><p></p><p>3月31日，华为创始人任正非发公告，再次强调“华为不造车，有效期5年”。任正非还指出不能使用华为/HUAWEI出现在整车宣传和外观上，不能使用“华为问界”。3月31日夜间，余承东亲自下达：问界门店将于4月1日开始拆除所有相关华为字样的宣传物料。</p><p></p><p>据悉，今年3月6日，小米小米集团创始人、董事长兼CEO雷军作为全国人大代表，在北京团全体会上表示，小米造车进展超预期，已经顺利完成了冬季测试，预计将会在明年上半年实现量产。雷军还表示，自己有二分之一的时间花在汽车业务上，汽车研发团队超2300人。</p><p></p><h4>比尔·盖茨：呼吁暂停人工智能开发不能化解未来的挑战</h4><p></p><p>4月4日，微软联合创始人比尔·盖茨表示，暂停开发人工智能（AI）的做法并不能“化解未来的挑战”。</p><p></p><p>在接受路透社采访时，盖茨表示，更好的做法是专注于如何最好地利用AI技术的发展，因为他很难理解这种所谓“暂停开发”将如何在全球范围内奏效。</p><p></p><p>“我不认为要求某个特定群体暂停行动就能化解这些挑战。显然，这些东西有很大的好处……而我们需要做的是明确棘手的领域。”在采访中他还说，任何这种暂停在强制执行时都将变得很复杂，“我真的不明白他们说的是谁应该暂停，是让世界上每个国家都同意暂停和为何暂停吗，但是在这个领域有很多不同的观点。”</p><p></p><p>在埃隆·马斯克带头呼吁暂停开发更强大AI系统并引发相关讨论后，这是盖茨首次公开对此话题发表评论。</p><p></p><h4>MacBook卖不动了，因需求低迷，苹果M2芯片曾暂停生产两个月</h4><p></p><p>4 月 3 日，据 TheElec 报道，由于 MacBook 需求明显下滑，苹果已经在今年 1 月停产了 M2 系列芯片的生产工作。</p><p></p><p>报道称，M2 芯片采用倒装芯片封装完成，由台积电加工晶圆，然后交由核心封测厂商（韩国 Amkor 和 STATSChipPAC Korea），这两家外包半导体封装和测试 (OSAT) 公司最终将其封装成完整的芯片。但是，这两大厂在今年前两个月均未收到苹果 M2 芯片的 5nm 晶圆进行封装测试，所以基本上都处于停工状态。报道称，M2 系列处理器的生产已在 3 月份恢复，但产量只有去年同期的一半。</p><p></p><p>苹果今年 2 月公布的 2023 财年第一财季（2022 年 10 月到 12 月）财报中披露，其 Mac 业务收入同比下降 30%、且下一季度还会下滑。</p><p></p><h2>IT 业界热评新闻</h2><p></p><p></p><h4>ChatGPT停售Plus服务</h4><p></p><p>4月5日，ChatGPT官网的“升级为Plus”按钮，进行点击后无法进行付费升级。按钮下方会弹出提示“由于需求量太大（due to high demand），暂时关闭升级通道”。</p><p></p><p>ChatGPT Plus订阅计划是OpenAI在今年2月1日发布的，ChatGPT Plus每月收费20美元（约合135元人民币），服务特权包括高峰时期正常访问、更快的响应速度以及优先获取新功能。</p><p></p><p>无法升级为付费版Plus并不会影响用户与ChatGPT正常对话，但免费版用户无法使用新款模型GPT-4以及测试版插件。</p><p></p><p>有Reddit网友表示，因为需求过高而关闭付费服务“一点也不奇怪，和ChatGPT对话时，10%-15%的回复会出现网络错误情况，且回应速度比以前至少慢了2倍”。</p><p></p><h4>2022年，华为拿出719.55亿元分红，惠及14万持股员工</h4><p></p><p>4月4日，华为2022年分红总额出炉。4月4日，经华为公司内部有权机构决议，拟向股东分配股利人民币719.55亿元。相比2021年分红总额614.04亿元，同比增加105.51亿元。华为员工薪酬主要包括工资、奖金和股票分红，股票分红是华为员工收入的重要组成部分。</p><p></p><p>华为2022年年报显示，华为投资控股有限公司是100%由员工持有的民营企业，股东为华为投资控股有限公司工会委员会和任正非。公司通过工会实行员工持股计划，员工持股计划参与人数为142315人（截至2022年12月31日），参与人均为公司在职员工或退休保留人员。</p>",
    "publish_time": "2023-04-09 13:08:34",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Slint 1.0正式发布，基于 Rust 的 原生GUI工具包已成熟",
    "url": "https://www.infoq.cn/article/sJ8oyZAf7uiFL5zxGsWT",
    "summary": "<p>本周一，Slint 1.0 版正式发布，标志着该项目已顺利从开发阶段 “毕业”，可正式用于生产环境。</p><p>&nbsp;</p><p>1.0 文档：<a href=\"https://slint-ui.com/releases/1.0.0/docs/slint/\">https://slint-ui.com/releases/1.0.0/docs/slint/</a>\"</p><p>&nbsp;</p><p>Slint 可用于为各种操作系统和处理器架构开发 UI，包括 Linux、macOS、Windows、WebAssembly、Blackberry QNX 和裸机。它允许 JavaScript 开发人员为嵌入式和桌面应用程序创建原生用户界面。</p><p>&nbsp;</p><p>Slint 曾经被称为 SixtyFPS，特点是既快又小，“使用 Slint 构建的图形应用程序可以在 RAM 小于 300 kB 的系统上运行，例如 Raspberry Pi Pico，”SixtyFPS GmbH 的联合创始人 Olivier Goffart 曾表示，该工具是用Rust编写的，但附加了 C++ 和 JavaScript 的绑定，允许开发人员与 JavaScript、Rust 或 C++ 库交互以构建 UI 界面。</p><p>&nbsp;</p><p>Slint的另一位联合创始人是Simon Hausmann，他们两位在当时的挪威公司 Trolltech 工作时相识，该公司在被诺基亚收购之前创建了 Qt C++ 工具包。后来Goffart 搬到柏林创建了自己的公司，但两人依然在 Qt 生态系统中。“我们非常清楚人们在为嵌入式设备或桌面构建复杂的用户界面时会遇到什么样的问题，”Hausmann 说。“我们还知道 Qt 积累了很多遗留问题，这些遗留问题使产品变得笨重，并且在某些方面不灵活。我们觉得是时候重新开始了。”</p><p>&nbsp;</p><p>该团队表示，Slint 是从头开始构建的，考虑了可扩展性、包容性、工具性和跨平台兼容性。其中的工具是能够加快 UI 开发过程。Slint 支持代码完成、导航、重构和语法高亮显示。</p><p>&nbsp;</p><p>Qt 有其他语言的绑定，但根据 Goffart 的说法，“所有的文档，一切都在 C++ 上……。开发人员可以使用多种语言工作，像 C++ 这样的系统语言并不是 UI 的最佳语言。它们是实现库本身的好语言，因为它需要非常快，但应用程序的逻辑可以使用更高级的语言。我们希望支持多种编程语言。”而且“在 15 到 20 年内，将很难找到 C++ 开发人员，”Hausmann 说。“我们想看看是否有可能为未来构建一些不受 C++ 束缚的东西。”所以Slint有意识地弃用了 C++。</p><p>&nbsp;</p><p>最终，总共50 位贡献者花费了三年，Slint 1.0 版正式推出，“这是一个重要的里程碑。与之前的版本相比，1.0 版仅引入了较小的 API 清理和错误修复，”宣布<a href=\"https://slint-ui.com/blog/announcing-slint-1.0.html\">新版本的团队博客文章</a>\"称。“1.x 系列标志着 Slint 现在已经从‘开发阶段’毕业，可以用于生产项目了。”</p><p>&nbsp;</p><p>另外，Slint 有自己的声明性语言来描述用户界面，在概念上类似于 QML（Qt 建模语言）或 Microsoft 的 XAML。<a href=\"https://slint-ui.com/releases/1.0.0/editor/\">这使得像SlintPad</a>\"这样的演示成为可能，开发人员可以在其中编写 Slint 设计标记语言并通过 Wasm 立即查看它。同样，Visual Studio Code 有一个扩展，可提供 Slint 标记的即时预览。</p><p>&nbsp;</p><p>更多阅读：</p><p><a href=\"https://slint-ui.com/blog/announcing-slint-1.0.html\">https://slint-ui.com/blog/announcing-slint-1.0.html</a>\"</p><p><a href=\"https://thenewstack.io/dev-news-rust-based-slint-matures-and-shopify-cleans-up/\">https://thenewstack.io/dev-news-rust-based-slint-matures-and-shopify-cleans-up/</a>\"</p><p><a href=\"https://devclass.com/2023/04/06/interview-the-story-behind-slint-1-0-a-new-cross-platform-gui-toolkit-coded-in-rust/\">https://devclass.com/2023/04/06/interview-the-story-behind-slint-1-0-a-new-cross-platform-gui-toolkit-coded-in-rust/</a>\"</p>",
    "publish_time": "2023-04-09 14:14:09",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "途游邹轶：中小公司的运维怎么做？",
    "url": "https://www.infoq.cn/article/PU83fmpOqzZccjav4dA3",
    "summary": "<p></p><blockquote><a href=\"https://flashcat.cloud/blog/sretalk-002/\">作者的话</a>\"：我们观察到：国内运维行业，不同的公司做法差异巨大，从业人员水平参差不齐，缺少普遍性行业认知，难以形成合力（这也会让 To B 的产品异常难做，不利于行业整体发展），甚至在部分公司，运维人员处在技术鄙视链最底层，我们希望为行业带来一些新的思路和发展推动力。这需要很多行业老炮一起，输出观点，共同碰撞，才有可能形成一些先进的共识，形成行业前进的思想旗帜。所以，我们准备策划《运维百家讲坛》这么一档栏目，诚邀 100 个运维总监（或更高）级别的老炮，通过采访或约稿的方式输出他们的观点，给行业一些借鉴。这一期我们邀请到的是邹轶，途游游戏运维总监，邹总经常戏称自己是世界500万强企业的运维代表，可见内心中是觉得中小公司的运维建设思路和大型企业是有差别的，今天我们带着几个问题，来请邹总分享一下他的中小公司研运一体化之路。这里是接地气、有高度的《<a href=\"https://mp.weixin.qq.com/s/Y4rIfV4_7MuYigLNNrtifg\">运维百家讲坛</a>\"》第 6 期，开讲！</blockquote><p></p><p></p><p></p><h2>问题预览</h2><p></p><p>途游是游戏公司，您觉得游戏运维有哪些独特性？面临的最大运维挑战是什么？您又是如何解决这些挑战的？游戏运维的人才技能是什么样子的，如果想在游戏运维方向发展，您对职业路径规划上有没有什么建议？中型公司的运维团队通常不会很大，您是如何对这有限的人力排兵布阵的，有没有什么心得可以分享给大家？您是否会遇到因为团队人才水平不行，导致自己的想法落地慢，落地难的问题，您是如何解决的？您说您特别认同《运维的未来是平台工程》文章中的观点，您的团队也是一个产研式的全功能组织，想请您介绍一下：对于业务研发，相比直接使用云厂商提供的平台产品，您这个团队带来的Delta增益是什么？您经常说成本节省要硬桥硬马，节省了大量成本，公司给发个奖状，说明这个FinOps的项目大概率是在自嗨，在云上、云下Infra建设上，您的团队为公司带来了巨额成本节省，而且得到了公司的物质奖励，能否分享一下相关的心得？运维团队一直是站在公司业务的后面，离业务的距离相对远，对如何更好的支持业务，或如何说明运维对业务的价值这个点，您有什么建议？</p><p></p><p></p><h2>采访实录</h2><p></p><p>问：途游是游戏公司，您觉得游戏运维有哪些独特性？面临的最大运维挑战是什么？您又是如何解决这些挑战的？</p><p></p><p>整体游戏运维架构相对传统互联网业务来比较，相对简单，但是单机可靠性要求比较高，运维日常工作，相对事务性的工作较多，比如开服合服等等。 面临最大的运维挑战，其实不是技术层面的，更多的是价值认可度层面的，怎么让我们业务部门认可我们的价值，这个挑战我相信也是整个运维赛道同仁们一致的挑战。要去赢得业务部门的认可，提升运维团队的价值，从我以及我团队的实践来总结，其实就是一句话：扎扎实实的做好服务，以业务部门/用户为中心。</p><p></p><p>问：游戏运维的人才技能是什么样子的，如果想在游戏运维方向发展，您对职业路径规划上有没有什么建议？</p><p></p><p>游戏运维的人才技能和传统互联网行业没有太大的区别，对于运维这个赛道来说，认知比较低和缺乏体系的成长环境，是我们中小厂运维面临的比较现实的问题，我们常年和机器底层打交道，很少去认真思考过，未来10年，15年后的发展，更多的是追逐热点，追逐变化，很少去思考沉淀那些不变的内容，以及怎么去利用这些内容来做时间的朋友形成自己的竞争力。我个人建议中小厂的运维同学，还是要在理论方法论学习和技能提升两手抓，用理论指导实践，通过实践完善自己对理论的理解。学习理论和方法这块，我也提几点建议：</p><p>持有开放的心态去学习，ITIL，SRE，lean, scrum，平台工程，可观测等等，不要纠结于门派之见，只要对自己有价值的内容，都可以去学习去吸收融合，比如ITIL抓住变更管理、故障管理、问题管理、持续服务改进，这几个流程去学习并应用于实践，其实就能解决好大部分运维问题。又比如对SRE的理念的学习，抓住SLO的理念，开展可靠性建设，引导业务部门与运维团队建立一个可靠性目标共担的协作模式。而在实践的SLO落地的过程中，又可以引入可观测性理念和方法，来加强自己对可观测性能力的建设。面向国外科技公司学习为主，面向国内大厂学习为辅，国外科技公司的理论和工程方法相对严谨和体系，不太受场景限制，可以学以致用，国内的大厂更多偏向于特殊场景的实践，理论和工程方法抽象不够，基本上都是万亿并发，千亿流量的场景，其实和中小厂的运维没啥关系，中小厂去深度对标学习，价值杠杆率不高。</p><p></p><p>问：中型公司的运维团队通常不会很大，您是如何对这有限的人力排兵布阵的，有没有什么心得可以分享给大家？</p><p></p><p>有限的资源，往往容易激发创新，团队规模可以不大，但是要保持精干、敏捷，换句话说就是你团队要足够能打，而且应对不确定性能力要强，要想达到这个效果，我个人总结了我们这5年的组织能力建设实践：</p><p>人才结构要做深度优化，要引入专业产研人才，用产研驱动团队价值输出。目前途游的运维安全团队，产研和传统运维比例接近1:1。研运一体化的组织模式去构建，要形成一支全职能，端到端的混合型团队。目前的途游的运维安全团队，有产品经理、研发负责人，前，后端工程师，服务运营工程师，运维工程师，IT工程师。围绕互信、目标一致、信息共享、去中心化去构建敏捷的文化氛围。通过敏捷的文化氛围，来形成一支能应对不确定性的敏捷组织。</p><p>关于敏捷组织的实践，可以看我的分享：<a href=\"https://tuyoo.feishu.cn/docs/doccnFlAD2m7WnSpcLYxFJRImZb\">https://tuyoo.feishu.cn/docs/doccnFlAD2m7WnSpcLYxFJRImZb</a>\"</p><p></p><p>问：您是否会遇到因为团队人才水平不行，导致自己的想法落地慢，落地难的问题，您是如何解决的？</p><p></p><p>这个肯定会遇到，我们解决思路：</p><p>保持耐心，对团队持续迭代，这个就和打牌一样，你不能期望上手一手好牌，这个都得不断的进出的换牌，最后把牌理顺去赢得比赛。对新人的标准是潜力要高于团队现有70%的人员，不符合标准宁可不招聘，招人谨慎，对人的培养才会用心。团队负责人自己一定是团队首席HR，要主动出击去找人才，我最近4年在BOSS直聘上大概聊过接近两万人吧，看过的简历应该超过2万多份，这个可能很难有中小公司的运维负责人会做到这点。利用敏捷组织作为基础支持，发挥集体智慧。</p><p>关于我团队转型实践分享：<a href=\"https://tuyoo.feishu.cn/docx/doxcnGMuijglK6NdENYC2vD7KKh\">https://tuyoo.feishu.cn/docx/doxcnGMuijglK6NdENYC2vD7KKh</a>\"</p><p></p><p>问：您说您特别认同《运维的未来是平台工程》文章中的观点，您的团队也是一个产研式的全功能组织，想请您介绍一下：对于业务研发，相比直接使用云厂商提供的平台产品，您这个团队带来的Delta增益是什么？</p><p>在回答这个问题之前，我还是想阐述下我们对造轮子和外采服务的认知：</p><p>我们其实对外采还是自研，蛮开放的心态，也是蛮简单的判断，就是看ROI的投入产出比，标准化的，投入巨大的，自己搞不定的肯定是尽量用外部三方的服务或者产品来帮助我们解决问题，我们更关注的是如何服务好我们的业务部门，关注我们提供的服务结果和质量，不太关注这个能力是我们自己具备的还是三方的服务能力，只要能帮助我们提升服务质量和效率的，我们都非常开放的心态去吸收和融合。</p><p>再来回答这个产研团队对我们的增益问题，每个公司都有它本身一些特性或者定制化场景需求，这些东西外来产品肯定不能完全覆盖到位，所以这样的一支端到端的团队，其实是让整个团队有了解决一些非标问题的能力。这种能力其实非常关键，很大程度决定了团队的价值实现。</p><p>另外再来说说我们对运维的未来是平台工程的理解，我对平台工程的理解有两点关键要素：</p><p>平台工程面向的对象是以业务部门为主，而不是运维为主。平台工程提供的是自服务，平台工程输出的产品和工具一定是业务部门自服务为主。</p><p></p><p>我们团队转型探索，就是主要按照这两个要素来做的实践，但是理论水平不够，没有清晰的去提出平台工程的理念。我们游戏运维有一个蛮大的痛点就是琐事很多，比如CDN的上传发布，游戏的配置更新，例行起停服，都是游戏运维日常的事务，不可或缺，但是都是事务性的，价值很低，可能在我们游戏运维的常识里面，我们会想到做一些自动化的工具，去提升运维的人效，把运维从人肉或者写脚本的状态，变成WEBOPS状态，这个感觉杠杆率还是太低，并没有把运维释放出来，所以在解决这些问题过程中，诞生了我对平台工程理念的原始理解，目前我们游戏运维的日常事务性工作有50%都是项目组自服务，通过我们提供的工具，这在我们接触平台工程的理念后，发现是高度认知一致的。所以对运维的未来是平台工程，我相信只要尝过自服务的甜头，吃过人肉运维的苦的同学，应该都会有很深的认同感。</p><p></p><p>问：您经常说成本节省要硬桥硬马，节省了大量成本，公司给发个奖状，说明这个FinOps的项目大概率是在自嗨，在云上、云下Infra建设上，您的团队为公司带来了巨额成本节省，而且得到了公司的物质奖励，能否分享一下相关的心得？</p><p></p><p>对于FINOPS这件事，平时也和行业一些专家老师做过一些交流碰撞，结合我们团队自己的实践，我个人感觉FINOPS实践落地难，难在改变老板的认知，目前行业还是偏技术实现或者理念碰撞阶段，还停留在比谁更专业，更规范的阶段，个人感觉不能影响到老板认知的FINOPS，基本都是无价值，或者价值极低，做和不做没啥区别。对于FINOPS这个领域不过多评价，我们缩小到成本优化这件事来讲，在我们团队我没有设定过成本优化的OKR，我们一直用精益的理念在指导开展工作，精益有一个核心的理念，一切不产生价值的都是浪费，持续消除浪费， 这样在工作开展过程中，其实就不用搞运动式的成本优化。很多省了几个亿的成本优化，可能在老板眼里就是应该的，以前浪费太大了，现在只是消除浪费，这自然就不会得到价值认可。</p><p></p><p>成本优化实践过程中我个人总结了几点：</p><p>要用精益的理念去持续指导成本优化，而不是简单的运动式降本增效。要拉齐价值共识，要和相关部门比如总办，财务等监管部门达成共识。成本优化的计算模型不能太复杂，模型计算太复杂，很难去达成共识。数据要统一按照财务口径进行核对，不能我们从技术角度想当然。</p><p></p><blockquote>作者的话：邹总做成本优化，具体节省多少钱是经过财务最终测算的，个人觉得很值得借鉴，很多公司的成本优化，都是自己测算的，缺乏公信力，老板较难有体感。</blockquote><p></p><p></p><p>问：这是老问题了，运维团队一直是站在公司业务的后面，离业务的距离相对远，对如何更好的支持业务，或如何说明运维对业务的价值这个点，您有什么建议？</p><p></p><p>具体怎么去体现价值，我建议运维团队要想体现价值，首先是要有服务意识，然后是要对服务体系进行建设，再就是保持耐心和持续改善，通过这个去形成一个正循环，从而把时间做朋友。</p><p></p><p>在这块我简单分享下我们团队的服务体系建设指导纲要。我们以客户为中心，构建安全、可靠、高效、低成本、可持续的服务。通过服务运营输出价值，通过产品和工具落地服务运营，并持续改善。在这个指导纲要中，我们将团队里的运维、产研和运营三个职能角色进行了深度融合。通过服务运营的输出来把价值进行体现。很多时候，做技术的人往往不太容易意识到服务运营的重要性，我们常常听到人们谈论技术运营和产品运营，但很少有人谈论服务运营。这与我们做技术出身的惯性认知有很大关系，更多的是站在自己专业领域去表达，很少去站在我们服务对象的角度去看我们的价值。很多人提到服务可能就会简单联想到端茶倒水、跑腿这种角色，比较排斥提服务。但实际上，每个团队都是服务型团队。比如我们服务项目组，项目组服务我们最终的用户，我们的最终用户可能是在他的工作领域服务其他客户。因此，提供服务是一件非常重要的事情。只有服务好了客户，帮助他们获得结果，才能真正体现自己的价值。</p>",
    "publish_time": "2023-04-09 18:04:48",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "资深运维王明松： 自我革命的“王四条”是怎样练成的",
    "url": "https://www.infoq.cn/article/533bi9EkhPPgMd9tiZP6",
    "summary": "<p></p><blockquote><a href=\"https://flashcat.cloud/blog/sretalk-002/\">作者的话</a>\"：我们观察到：国内运维行业，不同的公司做法差异巨大，从业人员水平参差不齐，缺少普遍性行业认知，难以形成合力（这也会让 To B 的产品异常难做，不利于行业整体发展），甚至在部分公司，运维人员处在技术鄙视链最底层，我们希望为行业带来一些新的思路和发展推动力。这需要很多行业老炮一起，输出观点，共同碰撞，才有可能形成一些先进的共识，形成行业前进的思想旗帜。所以，我们准备策划《运维百家讲坛》这么一档栏目，诚邀 100 个运维总监（或更高）级别的老炮，通过采访或约稿的方式输出他们的观点，给行业一些借鉴。这一期我们邀请到的是王明松，王老板针对云原生应用实践，提出“王四条”，在业内广受认可。从19年开始，王老板所在公司的所有IDC业务就全部搬到了云上，体量还不小，SRE团队却很小，有点Netflix的味道。这一讲，我们一起了解一下资深云上运维到底是怎么玩的。这里是接地气、有高度的《<a href=\"https://mp.weixin.qq.com/s/Y4rIfV4_7MuYigLNNrtifg\">运维百家讲坛</a>\"》第 7 期，开讲！</blockquote><p></p><p></p><p></p><h2>问题预览</h2><p></p><p>初识王老板，是因为微信群里的一次讨论，王老板提出了四条云原生应用实践，认为只要做到了这四条，应用基本就是云原生的了，群友们深表认同，并且命名为“王四条”，可否请王老板给 SRETalk 的读者再分享一下“王四条”中的精粹？“王四条”中罗列了一些最佳实践，需要研发一起配合，在公司内部落地的时候，不知道是否会遇到阻碍？您又是如何摆平的呢？最近有些文章讲述他们综合衡量 ROI 觉得下云更划算，比如 RoR 之父的文章，比如运维百家讲坛上一期途游游戏邹总，看起来您更倾向于深度用云，能否给大家分享一下您的思考？最近有个文章《运维的未来是平台工程》，您认可这个观点么？在平台工程方面您的团队承担了一个什么角色和边界？您是怎么规划所谓的平台工程的呢（尤其是在多云环境下）？王老板这样的工作模式下，感觉只需要非常资深的人，新鲜血液太嫩，没法承担研发教练的角色，但是没有新鲜血液，也没法长期维计，能否分享一下您是如何建设您的梯队的？我们知道，明松你一直是“运维自我革命”的鼓吹手，这是“反人性”的，能谈谈这背后的思考吗？</p><p></p><h2>嘉宾介绍</h2><p></p><p>问：开始之前，先请王老板做个自我介绍吧。聊聊工作履历，尤其是用云的经历，给大家输入一些背景信息。</p><p></p><p>大概2005年前后，在学校里搞过BBS的运维，算是入门。毕业后入职现在已经略微没落的某互联网大厂（编者注：是指百度），跨行从P1级的运维开始做。2010年跑路去了一家移动互联网创业公司，当时基本上系统网络布线机房IT啥都做，服务器的采购周期就算小公司也会略长，所以当时就开始考虑用云了。</p><p>2011年开始，曾经用过一段时间曙光云，基于Vmware的，体验就很差，从我个人的角度来看可用性和经济性都没有，唯一就是可能上机器比IDC快吧。然后网络也是怪怪的，造成了很多困扰。同时期也用了一段时间盛大云，这个体验比中科曙光强一些，但是其实也是vps的水准吧。感觉vpc那层都没有做。没敢放上去太重要的资源，后来屡次拉跨就没再用了（可能是我用的方式不对加上也不好监控）。</p><p></p><p>2013年开始用Ucloud，这个也主要是用虚拟机，别的用的不多。但是vpc产品当时应该有了，会把一些重要业务往上放了。2014年因为开始做出海，所以开始用AWS。2019年把所有IDC业务全部迁移到了云上。</p><p></p><h2>采访问题</h2><p></p><p>问：初识王老板，是因为微信群里的一次讨论，王老板提出了四条云原生应用实践，认为只要做到了这四条，应用基本就是云原生的了，群友们深表认同，并且命名为“王四条”，可否请王老板给 SRETalk 的读者再分享一下“王四条”中的精粹？</p><p></p><p>云原生王四条详细版的内容我放到瑞典马工的repo（&nbsp;<a href=\"https://github.com/lipingtababa/cloud-native-best-practices\">https://github.com/lipingtababa/cloud-native-best-practices</a>\"&nbsp;）里了 ，欢迎大家提issue，我也会不定期的更新<a href=\"https://github.com/lipingtababa/cloud-native-best-practices/blob/main/%E4%BA%91%E5%8E%9F%E7%94%9F%E7%8E%8B%E5%9B%9B%E6%9D%A1.md\">云原生王四条</a>\"</p><p>简要版的内容是：</p><p>用对象存储静态文件；用role不能用ak sk；尽量用托管服务；数据不要存在服务器上。</p><p></p><p>这四条的出发点其实基本上是围绕着应用的无状态和数据的安全来做，同时会兼顾成本，性能和可靠性，适应范围其实也不局限于云计算，传统IDC也可以参考来实施。</p><p></p><blockquote>编者注：这个简版内容看起来不多，实际内有乾坤，建议大家读一下，云原生王四条这个链接如果点击不了，就移步到上面的 repo，从中找 云原生王四条.md 即可。</blockquote><p></p><p></p><p>问：“王四条”中罗列了一些最佳实践，需要研发一起配合，在公司内部落地的时候，不知道是否会遇到阻碍？您又是如何摆平的呢？</p><p></p><p>我几乎没有遇到任何阻碍，但是这是因为我们有自己的情况。</p><p></p><p>一方面是我们当时除了上云别无选择，而且成本管控是硬指标，没有其他可以绥靖的路线可以选。</p><p></p><p>我们是团队分拆出来的一个新公司，所以只给了一年的时间做过渡，管理层给的目标就是把现有几千台机器上跑着的还挺赚钱的业务无缝的迁移出来。因为我们当时只做海外，所以压根没考虑非云的方案，但是管理层依然要求云上成本相较于之前用IDC要更省。</p><p></p><p>如果直接把原来的架构直接搬到云上去，那么管理层给的成本目标是肯定无法达成的（这个pigsty的冯老板已经写了很多类似的文章来佐证传统IDC对云的成本优势了），所以当时的选择只有一条：就是对现有的架构进行改造，使之适应云，从而使之迁移后即可达到成本，性能，稳定性的目标。</p><p></p><p>另外一方面，让研发在选型和成本优化上充分参与进来，大家形成共识。</p><p></p><p>我大概提前花一年时间开始对公有云做选型，并且专门参加培训来学习如何更好的使用云，也逐步形成了自己的方法论。迁移前也带领研发的主干成员去参加相关的培训，通过培训后他们也能理解我的很多做法是对的，而且实际迁移中，AWS也提供了比较专业的方案设计。所以“王四条”的内容落地是比较容易的，比如：</p><p>数据存EBS非常贵，那么存S3就是非常经济的选择，通过培训和各种方案对比，研发非常明确这个情况，所以会有比较大的意愿去做程序的修改。Role这个是安全要求，因为AWS的sdk支持的非常好，刚上手的时候使用Role还是ak sk没有任何难度区别，从一开始就把控好，对于研发而言没问题。托管服务这个，其实研发并不关心是运维去做还是用现有的服务。这个只要我们运维放得下执念就可以。数据不要存在服务器上。其实我们是经历了一次比较大的磨合。</p><p></p><p>我们这次迁移是从一个有完备的平台支持的IDC环境迁移到AWS，在AWS的partner的帮助下，新架构按照AWS的最佳实践设计，并且满足了之前的使用习惯和要求。但是因为做了重构，使用上还是有差异的。因为使用了ASG，所以在缩容或者故障迁移时，服务器是直接干掉的，上面如果要存持久化数据的话就没了，所以这次之后，研发基本能接受在线业务数据不存在服务器上了。而且因为这个设计，我们对于服务器存储的要求就可以能多小就多小，超过100G的都需要我审批。节省了大量的EBS成本。后续，研发在做K8S的部署的时候，对于这个的理解就更加深刻了，毕竟容器里的数据都是会丢的。</p><p></p><p>问：最近有些文章讲述他们综合衡量 ROI 觉得下云更划算，比如 RoR 之父的文章，比如运维百家讲坛上一期途游游戏邹总，看起来您更倾向于深度用云，能否给大家分享一下您的思考？</p><p></p><p>我其实一直在鼓吹“最佳实践”，但是我也跟大家交流过“最佳实践是投资人或者管理层的帝王之术”，使用最佳实践很可能就是要砸自己和很多人的饭碗才能达到最优，如果以不砸饭碗的前提下实现最优，选择就会更多样。</p><p></p><p>下云还是上云，得看利益出发点，也得看管理层支持的力度，还得看历史包袱。如果我在邹总或者DHH的位子上，也未必会坚持我现在的观点。我能坚持在云上：</p><p></p><p>一方面是管理层的认可，管理层都吃过资产闲置的亏，我做了很久的闲置IDC资源的优化的工作，所以加上出海自建机房也不是特别容易，上云基本上就是管理层支持的唯一方案。</p><p></p><p>另外一方面也是如上面所说机缘巧合，我们架构改造的很彻底，而且改造成本是管理层支持的，可以充分利用云的优势。</p><p></p><p>最后一点，我们的业务形态到现在还没有一个长期稳定的高负载而且无状态的业务。这种业务比较适合传统IDC。</p><p></p><p>我相信邹总或者DHH现在去改造他们现有系统的架构，付出的成本太高了，即使说可以因此削减运维部门的人力成本，可能很难得到支持，因为这还涉及到其他部门的利益。但是如果是新公司新项目，我相信没有比云更合适的场景了，选一家合适的云厂商，采用云原生的架构来实现业务，使整个业务从性能和成本上都是弹性的。</p><p></p><p>很多朋友吐槽云杀猪，锁定之类的。但是从投资人或者管理层的角度看，一切要素都是为了达成业务的盈利，人/云/IDC等 都是实现业务的要素，投资人想实现业务，不仅要为这些要素支付成本，还要能及时获取到符合需求的要素（这个更重要）。云这个要素的获取再简单不过了，相对而言非常标准的产品质量和价格，点几下就可以付款使用了，可以按需可以包周期，但是随时都可以停止使用。 但是人呢？人的获取很难，质量也很难明确，也不是标准化的，会有价格的波动（加薪），不能随便裁，离岗也不会帮你顶替一个绝对一摸一样的。人可以是很有创造力的，但是在标准化和机械枯燥的事情方面，人永远不是机器的对手，更不是SaaS服务的。</p><p></p><p><a href=\"https://www.infoq.cn/article/PU83fmpOqzZccjav4dA3\">对于邹总的情况</a>\"，如果他们业务团队不愿意改造程序架构的话，他现在的选择就是最佳实践了：稳定高负载的业务选用成本有优势的IDC，并且租赁机器而不是购买；弹性业务的上云。</p><p></p><p>对于37signals 的Basecamp，从产品的定价模型设定上就决定了他们上云有点麻烦。现在大多数SaaS服务都是按用量或者使用人数付费的，但是Basecamp主要卖无限制套餐，一个月只有199刀。这个定价模型就导致他们无法充分利用云的弹性来盈利，而只能走低价资源的超售。不改变这个定价模式，无论怎么优化架构恐怕也不太适合云。</p><p></p><p>问：最近有个文章《运维的未来是平台工程》，您认可这个观点么？在平台工程方面您的团队承担了一个什么角色和边界？您是怎么规划所谓的平台工程的呢（尤其是在多云环境下）？</p><p></p><p>是阮一峰写的还是Charity Majors 写的？不过这两篇我之前没看过，刚简要的看了一下。我不完全认可这个，而且我个人也不会去尝试做内部的平台工程。</p><p></p><p>首先说一下不认可的地方吧：就是那篇文章对于概念有一些误解。</p><p></p><p>首先，DevOps不是一个岗位，我曾经试图理解了很久，最终的感觉就是这是一种开发模式。但是这个开发模式的核心是研发，所有的要素都要围绕高效的研发迭代服务。 那篇文章前面认为DevOps是一个岗位，后面又认为这个岗位是开发业务的，我觉得都是不妥当的理解。</p><p></p><p>其次，运维对未来的探索是很丰富的。转型不是一个新话题，大家很早就明白运维这个行业是夕阳行业了，过去这十多年，有很多运维都在尝试转型，找下一步的出路，有试图搞CI/CD的，有尝试做监控研发的，有尝试做自动化运维平台研发的，有尝试搞新领域（比如K8s，大数据，AI，云计算之类的），也有尝试转向其他子项的（比如DBA，网络安全）。</p><p></p><p>可以看出来这些转型很多都是服务于DevOps这个开发模式的。</p><p></p><p>平台工程或许是一种实现模式，但是以运维群体的产品力和研发水平，自己搞平台工程恐怕只能自娱自乐，甚至连稳定性都无法保证，徒增背锅可能。但是如果引入更加专业的产研团队去做，一方面是不务正业跟主营业务收入无关很难得到支持，另外一方面只是自用的平台，拉这么多人做一个没有收入的产品并不经济，更何况这种做法对于现有的运维而言没有参与感，算不上转型。</p><p></p><p>所以，我认为正确的做法是自己用成熟的平台和工具（开源/付费自建，使用SaaS均可），可以基于这些平台做一些定制和二开，但是不要造轮子。</p><p></p><p>最后，我对那篇文章中平台的理解也不一样。</p><p></p><p>一方面，平台本身就可以是SaaS的形式去提供，不需要二开整合，现在主要是国内SaaS环境不佳，以及软件服务也不重视相互集成兼容，而更喜欢做大而全。我们把目光放到海外就会发现海外有很多细分领域的SaaS或者软件，做的很好而且可以跟其他软件集成，生态很好所以集成很容易配置，没有太多二开的工作量。</p><p></p><p>另外一方面，平台的用户应该是研发，研发应该可以直接使用，而不需要运维去转达，审批。</p><p></p><p>所以未来的确需要用平台，是专业的产研团队做的平台，而不是自己做的玩具；是产研团队来直接使用的平台，而不是运维拦在中间做传话筒。</p><p></p><p>所以对于平台工程，我选择积极的使用成熟的软件或者SaaS服务，并且尽可能提供给产研团队直接使用。</p><p></p><p>运维只基于成本和安全做一些必要的卡口，通过策略、权限、审计来控制，保证产研团队可以正确的使用。</p><p></p><p>问：王老板这样的工作模式下，感觉只需要非常资深的人，新鲜血液太嫩，没法承担研发教练的角色，但是没有新鲜血液，也没法长期维计，能否分享一下您是如何建设您的梯队的？</p><p></p><p>这个问题很好，因为我的确也没解决。这不是这种工作模式的问题。</p><p></p><p>对于资深人才的需求，很多公司，很多工种都是有的，一样面临我现在的问题。什么工种才不需要资深人才呢？我认为是工作内容已经非常标准化，公司要求不高，随便一个人都能根据需求就能明确指示做好。甚至机器就能做好。</p><p></p><p>邹总有个说法是传统运维类似保洁，工作内容重要但是价值不高。我比较认可这个说法，这就是我们现在运维面临的困境。那么保洁团队他们自研清洁工具还是去采购？</p><p></p><p>因为采用了大量成熟的产品和外部服务，我如同保洁使用各种自动半自动的清扫工具一样，可以比较稳定的输出清扫任务。但是不需要担心某个保洁能力欠缺导致拖地不干净，不够敬业导致简单扫一遍就交差。固然要操作好这些工具，保洁需要学习的比传统工具要多一点难一点，但是总体的SOP要比原来要少，因为成熟的工具屏蔽了细节。</p><p></p><p>所以，我们不要在低价值的工作内容上浪费时间，这类工作用专业的软件或者SaaS来完成，它们有规模效应，功能好还有SLA。我们应该把工作重心放在业务，管理层，投资人更关心的领域。</p><p></p><p>问：我们知道，王老板一直是“运维自我革命”的鼓吹手，这是“反人性”的，能谈谈这背后的思考吗？</p><p></p><p>我们现在看到的事实就是运维并不是一个蓬勃发展的行业，绝大多数企业并不会有一个庞大的运维部来支撑企业的系统运转，甚至可能只需要一个人，这个人还会兼任IT、网管、安全之类的工作。我们没有上升空间了，运维总监极少，运维经理基本上就是极限了，以我现在管理的人数，叫我运维主管都可以。</p><p></p><p>现在业界也是这样的状态，大量培训班速成的运维，够用而且价廉。中高端运维很少，运维不像是网工或者DBA，我们技术栈非常杂，没有权威的认证标注我们的能力，这一方面不利于我们规划职业路线，也不利于形成一个良性的人才市场。所以市场对于我们运维的定位其实就是打杂了，“不写业务代码的那个技术”可能是我们最准确的定位。</p><p></p><p>根据DevOps的理念，我们应该是加速业务的交付，做好服务，而不是添乱给产研使绊子。 但是运维的意义和工作不仅仅在于DevOps，这也是我跟很多人观点不一样的地方。</p><p></p><p>一方面，运维是公司数字资产的“看门狗”，从这个角度上看，运维代表管理层和投资人的利益，对公司的数字资产进行妥善的保管，保证其能正确的使用，满足各种监管要求，参与各种内部审计。是管理层对于产研团队的制衡。这其实就是最初运维的意义。</p><p></p><p>另外一方面，国家赏饭吃。监管要求日益严格，无论是网络安全，数据安全还是个人信息保护，都需要有专人负责相关工作。对于小规模的企业而言，这些工作必然是运维来兼任，特别是数据安全，直接掌管数字资产的运维肯定要参与的。这是新时代对运维的要求。</p><p></p><p>所以如果想明白这些，你就会发现什么DevOps，什么平台，都是运维工作的一小部分，我们应该把自己从这些纠结里解放出来，给自己解绑，也给产研团队解绑，做好我们管理和监管视角的工作。</p>",
    "publish_time": "2023-04-09 18:36:44",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "存算分离实践：JuiceFS 在中国电信日均 PB 级数据场景的应用",
    "url": "https://www.infoq.cn/article/rvEBNhVGCwPaFv457tEm",
    "summary": "<p></p><h2>01 大数据运营的挑战 &amp; 升级思考</h2><p></p><p></p><h3>大数据运营面临的挑战</h3><p></p><p>中国电信大数据集群每日数据量庞大，单个业务单日量级可达到 PB 级别，且存在大量过期数据（冷数据）、冗余数据，存储压力大；每个省公司都有自己的集群，以及多个收集全国各省级业务信息的集团大数据集群，导致数据分散冗余，省集群与集团集群数据无法共享，跨地域任务延迟高。</p><p>电信早在 2012 年就开始创建各种集群，内部集群由各个厂商或其他内部团队部署，承载的业务由各个厂商运营，运维团队也是由各个厂商提供，因此集群涉及的版本非常多，包括 Apache、CDH、HDP 等多个版本。随着集群规模的不断膨胀，运维压力越来越大，定位和修复问题都需要依靠厂商，这并不是一种可持续发展的道路。</p><p>为解决现网痛点，强化集群安全，聚焦降本增效，满足内外部支撑需求，2021 年，中国电信组建了 PaaS 自研团队。在两年中，PaaS 团队针对现有的集群进行了优化，保证上万台机器的现有集群平稳运行。</p><p>在 2022 年初，PaaS 团队开始自主研发 TDP（TelecomDataPlatform）大数据平台，逐步替换现有集群，推进产品化。2022 年上半年，通过 Hadoop 2 版本的 TDP 底座部署了两大新集群，开始用于生产业务。2022 年下半年研发了 Hadoop 3 版本的 TDP 底座，开始面对如何使用自研底座升级现网大量的 Hadoop 2 集群的问题。</p><p></p><h3>集群升级思考</h3><p></p><p>在升级集群的过程中，希望新的集群设计可以解决现有痛点，具备业界先进的特性，并且为后续的技术迭代做好前置准备。</p><p>以下是我们在集群升级的过程中希望可以解决的问题：</p><p></p><h4>拆分为小集群</h4><p></p><p>我们计划将大集群拆分为小集群，原因如下：</p><p>从机器资源层面来说，无法同时使用几千台机器进行原有业务的迁移。此外，针对部分非常重要、对 SLA 的保证要求很高的业务，无法在生产环境直接从 Hadoop 2 原地升级到 Hadoop 3。</p><p>每个集群中都有许多不同的业务，将大集群拆分为小集群后可以按照业务进行划分，尽量减少它们之间的影响，降低业务迁移的压力和风险。拆分成小集群后也可以改善一些任务可能引起的整个集群不稳定的问题，更好地控制稳定性。</p><p>举个例子：有些机器学习的任务，并没有使用 Sark、Machine Learning 这样的方式去编写，而是直接在自己的程序中调用 Python 库。这个操作没有限制线程的使用。这样即使任务只申请了 2 核 10G 的内存，实际上也可能把这台机器的负载打到 100 以上。因此，拆分成小集群后，可以减少任务之间的互相影响，尤其是当平台上需要执行非常重要的任务时，在小节点的情况下，运维工作会相对容易。</p><p>此外，拆分集群还可以避免 Namenode 和 Hive 元数据的膨胀，降低整体的运维压力。因此，在业务允许的情况下，计划采用大集群拆分成小集群的方式进行升级。</p><p></p><h4>升级过程尽量平滑</h4><p></p><p>拆分小集群的过程中涉及到数据和计算两个维度，数据的迁移需要大量时间，如果业务复杂，计算也可能需要花费很长时间。因此，需要想办法将数据和计算的迁移分开，尽量扩大这两个集群之间的并行时间。</p><p></p><h4>多集群之间的数据互访问题</h4><p></p><p>当大集群拆分成小集群之后，需要考虑多个集群之间如何做数据互访。同时，在内部系统中有上万台机器和海量的数据，一直面临着不同类型的数据搬迁、冗余以及冷热数据的问题。</p><p></p><h4>大数据、AI 结合需求</h4><p></p><p>我们的 PaaS 平台正在逐步承接各种 AI 需求，其中最大的需求之一是非结构化数据的存储。将这部分需求与现有的结构化和半结构化数据存储集成在一起，这也是业界的一个前沿方向。</p><p></p><h4>降本增效</h4><p></p><p>将大集群拆分成小集群后，资源实际上会更紧张，由于不同集群的使用情况不同，某些集群可能只在假期、周末或进行日批量计算时才会被使用，因此需要确保闲置资源得到充分利用。</p><p>我们现有的所有机器都是高性能机器，拥有非常高的存储、内存和 CPU 性能。在未来的采购中，是否所有业务都需要采购这种高性能的机器呢？例如，对于小集群，是否可以快速搭建集群并省去部分存储和计算资源的成本？此外，在整个 Hadoop 2 升级到 Hadoop 3 的过程中，EC 技术可以省去 50% 的存储资源，希望能够将整体存储费用降到更低。</p><p>基于上述思考，总结出以下四个策略：</p><p>•&nbsp;存算分离：将存储和计算分离。•&nbsp;对象存储：使用对象存储来解决结构化、非结构化和半结构化数据的存储问题。•&nbsp;弹性计算：采用弹性计算技术来解决拆分小集群后集群资源不充分利用的问题。•&nbsp;容器化：采用容器化技术来解决深度学习计算任务和资源管理的问题，从而实现更高效地降本增效。</p><p></p><h2>02 存算分离架构设计及建设历程</h2><p></p><p></p><h3>存算分离－组件选型</h3><p></p><p>早期大数据架构是基于 Hadoop 2.0 的存储计算一体化集群，计算和存储均使用高性能机器。而现在的架构则是存储计算分离，将更多的磁盘用于对象存储，建立了一个对象存储池，以及相应的元数据加速层，所有的HDFS访问都会通过元数据加速层访问底层的对象存储层。</p><p><img src=\"https://static001.geekbang.org/infoq/6c/6c4d518c62c267f26b903a1018450b2b.png\" /></p><p></p><h3>存算分离技术选型</h3><p></p><p></p><h4>对象存储</h4><p></p><p>在考虑不同的对象存储方案时，主要对比了 Minio、Ceph 和 Curve，而云上的对象存储并不在的考虑范围之内。在这三种选择中，最终选择了业界使用最广泛、支持各种 K8S 容器、S3 以及底层块存储的 Ceph。</p><p></p><h4>对接 HDFS</h4><p></p><p>存算分离的主要目标是将对象存储与 HDFS 打通。在自研的 Hadoop 2 和 Hadoop 3 中都涉及了这项工作，最初是采用亚马逊提交的 S3 代码，国内的阿里云、腾讯云和华为云也分别推出了自己的实现并提交到 Hadoop 社区中，但这些方案缺乏对元数据的加速支持。</p><p>近年来，元数据加速和数据缓存技术逐渐成熟。这些技术旨在解决存算分离后，Yarn 底层数据无法与本地数据进行亲和的问题。在这次打通中，不仅希望将对象存储与 HDFS 直接打通，还希望达到业界领先的性能水平。</p><p>对象存储可以通过多种方式与 HDFS 对接，例如使用 Hadoop 原生接口、Ceph 的 CephFileSystem 或 JuiceFS 等开源产品。云厂商也提供了类似的解决方案，例如阿里云的 Jindo 和腾讯云的 GooseFS。这些产品都提供了元数据加速和缓存功能。</p><p>虽然云厂商的产品具有成熟性和规模优势，但无法获取它们的源代码，并且它们需要与云厂商提供的云上资源绑定。因此，我们选择了开源的 JuiceFS。JuiceFS 目前是最成熟的开源解决方案，社区活跃度很高。能够适配 Hadoop 商业版本如 CDH 和 HDP。最终，决定了 Hadoop 3+JuiceFS+TiKV+Ceph 的组合作为我们的存算分离方案。</p><p></p><h3>存算分离架构带来的价值</h3><p></p><p>1. 单个集群存储的数据变少，元数据压力变小经过计算存储解耦，存储和计算可以独立进行弹性扩缩容，并实现数据的统一存储和跨计算集群共享。这种方式可以显著降低单个集群内的存储数据量，减轻整体元数据的压力。</p><p>2. 解决元数据瓶颈以及单点性能问题&nbsp;元数据可水平扩展，无单点性能瓶颈：元数据的压力反而会在元数据加速层这一层来承担，并且可以做到水平的扩展，解决了原来的元数据的瓶颈和单点的性能的问题。</p><p>3. 解决 Ceph 层联邦不均衡问题</p><p>Ceph 层之前集群里出现了很多的联邦不均衡的问题，比如某一个业务在使用了 namespace3（ns3），会使它的数据都存在 ns3 上面，导致 ns3 和其他的联邦整体数据、压力不均衡。</p><p>4.解决整体扩容时的瓶颈问题&nbsp;</p><p>在新的集群里通过纠删码去降低存储成本，然后通过对象存储的水平扩展，让集群的扩展的能力变得更好。</p><p></p><h3>存算分离项目实践：流量轨迹项目迁移</h3><p></p><p>流量轨迹的数据主要是 DPI 数据，它是用户上网的各种各样的流量数据，包括 3G、4G 和 5G 数据。电信客服可以通过一个展示页面查到用户在历史的一段时间里流量消耗是否跟费用扣款一致。</p><p>随着 5G 用户的增多，现有的集群需要不断填充 5G 流量数据，导致存储压力不断增加。所有的数据都是通过采集系统从 31 个省采集而来，现在的数据量已经达到 PB 级别，并且整体规模还在不断增长，每天处理的数据量约为 800-900TB。这是一个比较简单的业务场景，但是挑战在于面临的数据量级太大了。</p><p>之所以选择这个业务场景进行迁移，是因为这个的场景的 SLA 要并不是那么高，它本身是小时级的，如果宕机一个小时，影响相对较小。</p><p><img src=\"https://static001.geekbang.org/infoq/63/637d05837ec4e8f75d56f088ba16e7d8.png\" /></p><p>由于面临的数据量太大，选择了执行小时级别的批处理任务。通过耗费大量的资源来处理整体的计算量，以便统计用户每小时的流量消耗及其分布情况，并将这些数据存储到 HBase 和 Hive 中。</p><p>基于现有采集系统的数据，将所有数据上传到 Hadoop2 集群中。迁移需要打通 Hadoop2 集群和对象存储之间的连接，JuiceFS 在这个过程中发挥了关键作用。有了 JuiceFS，无需重启 Yarn 和 HDFS 等核心组件服务，就可以将对象存储挂载上去。当新的数据进来时，当天的采集系统就可以将其写入对象存储中。计算任务则可以直接从对象存储中读取数据，对于原有任务来说，只需修改路径，其他事项均不需要变化。</p><p></p><h4>项目迁移实践</h4><p></p><p>在存算分离的上线过程中，迭代速度非常快，仅用了两个月时间就完成了整个项目的落地。JuiceFS 的易用性，是能够让我们在巨大压力下按时保量解决问题的重要前提。同时，在实践中，JuiceFS 在解决一些关键问题方面也发挥了非常重要的作用。</p><p>第一：PB 级的支撑能力</p><p>1. 解决元数据存储和连接压力</p><p>在之前的 JuiceFS 测试中，选择使用 Redis 作为元数据引擎，数据存储在 Redis 中，整体性能非常好。但是，随着搭建了几百台机器，每个节点启动 Yarn 任务时，每个容器都会访问元数据，导致 Redis 崩溃。因此，将其替换为 TiKV。</p><p>2. 时间戳写竞争压力</p><p>在众多集群中，即使时间窗口是保持一致的，由于机器规模非常庞大，仍然可能出现时间冲突和竞争的问题。为了解决这个问题，添加了一些补丁来优化时间和竞争，放宽了相应的一些参数配置。</p><p>3. 垃圾清理速度瓶颈</p><p>我们发现 Ceph 存储的数据量越来越高，并没有完全释放下去，主要是因为 DPI 的业务数据量非常大，只会去存几天的数据，所以每天都会去写入 PB 级数据，然后消费 PB 级数据，以及删除PB级数据。</p><p>4. 回收站清理线程泄露问题</p><p>在部署监控后发现，有些特定时间点会出现 TiKV 和 Ceph的稳定性问题。经过排查，发现问题出现在客户端回收站线程泄露上。</p><p>第二：在高负载下提升性能</p><p>流量轨迹项目试点时，为了满足 32TB 计算和 10PB 存储的需求 ，选择了一部分性能较好的机器。然而，在评估 Ceph 的时候，没有考虑到 Ceph 所使用的内存和 CPU 资源，导致每台机器的吞吐量、网络带宽和磁盘带宽基本上都已经打满了，处于类似于压力测试一样的环境。在这种高负载的环境下，不得不对 Ceph 进行调整以解决内存溢出导致的宕机问题，并优化适配 JuiceFS 以加速 Ceph 的数据删除和写入性能。</p><p></p><h4>项目规划</h4><p></p><p>计划在 2023 年的 Hadoop 3 升级中实现以下规划：</p><p><img src=\"https://static001.geekbang.org/infoq/2e/2e6147918431922eaf4dafd2139dd95c.png\" /></p><p>在底层，将完全依赖 JuiceFS 来储存和加速元数据，并根据不同业务将对象存储拆分成不同池或集群。</p><p>在计算资源层，每个集群都会有自己的计算资源池，但我们将添加一个弹性资源池，用于多个资源池之间的调度。</p><p>在统一访问层，将提供一套统一的管理工具，任务的提交都将通过任务网关，并通过元数据打通多个集群。还将把集群划分为不同的 Pod 或集群，例如 DPI 集群、位置集群和纹理集群等，某些集群也可以将热数据存储到自己的 HDFS 中，并通过数据库和 MPP 来提高性能。</p><p>另外，还将提供一套统一的集群管理工具，包括存储画像、任务画像、集群日志采集和日志大盘等，以便更好地监控和管理集群。</p><p>总之，希望通过按小集群划分、存算分离等方式来提高性能，通过 JuiceFS 加速元数据并弹性调度计算资源，最终通过统一的管理工具来简化运维流程。</p><p></p><h2>03 运维经验分享</h2><p></p><p></p><h4>如何使用高性能机器进行混合部署</h4><p></p><p>原则上在集群规划时不要有异构机型，尽可能选择同种类型的机器。这样可以保证 vcore 和 mem 保持恒定的配比。但由于公司内部对于机器的申请非常谨慎，因此流量轨迹项目实际上只拿到了 180 台左右的旧的高性能机器进行替换，这些机器虽然性能高，但并不适合作为大量计算或存储的机器。为了充分利用这些资源，使用存量机器混合部署，解决了规划方面的问题。</p><p><img src=\"https://static001.geekbang.org/infoq/4e/4e93118e8bd59d825a16546e378bb601.png\" /></p><p>共提供 10PB 存储，8100（45C180）Vcore、 32TB（180G180）计算资源，其中，Ceph 使用了48G（4G*12）的计算资源，其他的都属于 Yarn。</p><p></p><h4>机器 CPU 内存规划不合理</h4><p></p><p>在规划时期 Ceph 占用的 CPU、内存没有考虑，导致机器内存耗尽、机器负载持续偏高造成服务器宕机，引发任务失败。Ceph 节点与 Hadoop 集群共用一块网卡，节点宕机触发 OSD 数据迁移，计算任务 Shuffle 与数据迁移打满网卡，经过实践优化配置：</p><p>•&nbsp;所有节点：需两块 SSD Raid1 方式做根盘，以此来提高稳定性。•&nbsp;计算节点：建议 CPU 线程数：内存 为 1:4 | 1:5 左右，混合部署预留出 Ceph 占用资源•&nbsp;存储节点：单个 OSD（单块盘）建议分配 6GB 内存，高性能服务器建议使用双网络平面；如果条件允许，建议将内外网分开，将 Ceph 内部的数据同步和外部的访问分开，这是一种更加理想的状态•&nbsp;元数据节点：建议高性能 NVME 磁盘 这是与 PingCAP 做了多次沟通后得出的结论，磁盘的负载包括 TiKV 在当前 180 台计算高频的使用下，压力很大，到 70%~80% 的情况。• Ceph节点操作系统：CentOS-Stream-8•&nbsp;其他节点操作系统：CentOS-7.6+、CentOS-Stream-8</p><p></p><h4>NodeManager 本地目录不合理</h4><p></p><p>在高负载、PB 级别的情况下，任务需要大量的磁盘空间，因此将几乎所有的磁盘空间都分配给了 Ceph，而 HDFS 只有一块机械硬盘。然而，在任务高峰期，由于中间数据需要写入到这块机械硬盘中，导致磁盘 IO 延迟过高，最终成为了任务执行的瓶颈。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9d/9decce216c39f9ba0c15454a56e573ae.png\" /></p><p></p><p>经过优化，在机器的受限的条件下，把 Yarn 本地目录配置到根盘（SSD)，数据盘全部分配给 OSD，解决磁盘带来的性能问题。</p><p></p><h4>JuiceFS 上报指标关闭</h4><p></p><p>为了减轻 JuiceFS 的负载，关闭了 Pushgateway 所有的监控指标。因为监控指标需要通过容器持续上报，如果 Pushgateway 响应时间过长，就会导致 HDFS 的回调一直卡住，从而无法结束任务。虽然这样做无法查看一些基础的统计指标，但希望后续能够通过其他方式来展示 JuiceFS 的监控指标。</p><p></p><h4>Redis 连接数限制问题</h4><p></p><p>使用 Redis 作为元数据引擎时，连接数与 Yarn 容器的数量成正相关。当数据量过大，任务过多时，Redis的最大连接数上限（4K）瞬间就被打满。因此，在处理冷数据时使用 Redis 或关系型数据库，在高性能计算方面则建议使用 TiKV（数据盘使用 NVMe）。目前正使用 TiKV，它能够支持大约 10 万个并行连接数。</p><p><img src=\"https://static001.geekbang.org/infoq/93/93eeaa7fc686c461b828486457a27711.png\" /></p><p></p><h4>Tikv 6 小时周期性繁忙</h4><p></p><p><img src=\"https://static001.geekbang.org/infoq/88/88f8da5546ceb0ed3516b70a552e1814.png\" /></p><p>之前曾遇到一个困扰很久的问题，使用 TiKV 时会出现 6 小时的周期性 Busy。通过日志分析，发现 JuiceFS 开启了大量的日志清除线程。首先试图关闭 TiKV 的上报机制来解决，但是发现这个问题仍然存在。</p><p>通过研究发现，JuiceFS 存在一个线程溢出 bug，导致每个 nodemanager 开启了上万个日志清除线程。每个线程在调用文件系统时都会触发一个清除操作。每到 8 点整点，这些线程同时执行清除操作，压垮了 TiKV，导致高峰期出现非常高的尖峰。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5e/5edd222b48443153ef82d91cbe4eecc4.png\" /></p><p></p><p>因此，在选择存储垃圾回收机制时，需要取舍 HDFS 和 JuiceFS 两种机制。尽管两种机制都可选，但更倾向于关闭 HDFS 的垃圾回收机制，让 JuiceFS 独自负责整体的垃圾回收。</p><p></p><h4>JuiceFS 删除慢</h4><p></p><p>JuiceFS 的垃圾回收功能需要进行文件删除操作。在最初使用 JuiceFS 时，发现即使调整了 Ceph 的相应参数，将删除和写入权重调整到了最高，每天也无法删完 PB 级的数据。</p><p>删除性能很低，需要使用多线程的方式来进行删除，但 JuiceFS 的每次删除操作都需要客户端上报指标，然后客户端检测回收站中哪些文件需要删除。如果删除的数量很大，无法使用客户端进行处理。最终，JuiceFS 社区提供了一个解决方案和相应的补丁，可以修复多线程问题并满足 PB 级别的删除需求。将其挂载到了固定的几台服务器上进行删除，并将线程数调整到了最高。目前，这个补丁还没有被合并到正式版中，但预计它将在未来被合并。</p><p></p><h4>JuiceFS 写冲突</h4><p></p><p>JuiceFS 存在写冲突的问题，已通过调大父文件夹更新修改时间的时间间隔，降低频繁的文件属性改写来进进行缓解，但是还没有根本的解决。目前团队在积极地和 JuiceFS 团队一起探讨这个问题，计划在JuiceFS 的 1.0.4 版本修复这个问题。</p><p></p><h2>04-后续计划</h2><p></p><p>部署更大规模存算分离集群探索不同集群与对象存储池之间的打通探索单集群访问多对象存储集群探索存算分离和数据湖的结合构建结构化非结构化统一存储池</p><p>长期来看，希望存算分离产品能够在内部的上万台机器的升级过程中发挥更好的作用，并在各种场景下得到验证；解决 Ceph 扩容带来的集群稳定性问题、支持 Kerberos、Range 提升安全性，提升超大规模性能，继续提高产品的稳定性、安全性和易用性；也会进一步探索云原生的发展。</p><p>最后，中国电信期望与 JuiceFS 社区和各位专家持续交流和解决问题，非常希望社区的各位专家可以加入电信，一起来构建 TDP 产品。也欢迎大家试用 TDP 产品。</p><p>中国电信简历投递：https://app.mokahr.com/apply/chinatelecomai/72380#/jobs</p><p>直播回顾：https://www.bilibili.com/video/BV1wX4y1X7em/</p><p></p><h3>关于作者</h3><p></p><p>杨磊，电信大数据AI中心大数据平台组组长</p><p></p><h3>部分现场 Q&amp;A</h3><p></p><p>Q1：开源版本不支持 Kerberos，集群安全问题如何保证呢？</p><p>目前，采用多种方式来确保安全。此外，任务提交都要经过 Kerberos 认证，这为数据访问提供了一层保护。当然，仍希望社区版能够增加对 Kerberos 和 Ranger 的支持。</p><p></p><p>Q2：流量轨迹业务是如何从 HDFS 集群迁移到 JuiceFS 集群的？迁移过程中有没有遇到什么问题？</p><p>请参考上文了解具体细节。在迁移过程中，致力于尽可能地建立原始数据和对象存储之间的连接，并优先进行数据迁移，再进行计算系统的适配。</p><p>在迁移过程中遇到了一些问题：</p><p>1、由于不同组件版本的多样性，在适配过程中花费了不少时间。如果软件版本能够兼容，迁移过程将更加顺利。</p><p>2、在机器资源不足的情况下，需要同时满足大规模计算和存储需求，并在高压力集群中进行性能调优。</p><p></p><p>Q3：迁移到存算分离的架构以后对业务的性能是否有影响，目前有什么优化的方法？</p><p>在存储和计算机器分离之后，性能可能会受到一定的损失，例如无法实现 YARN 的数据亲和性以及无法通过本地方法直接访问。为了优化性能，目前采用 JuiceFS 的缓存功能。对 Ceph 也有一些参数优化。</p>",
    "publish_time": "2023-04-09 18:49:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "浅析三款大规模分布式文件系统架构设计",
    "url": "https://www.infoq.cn/article/J3ulcioRIXNfR0HDtZjr",
    "summary": "<p>当提到文件系统时，大部分人都很陌生。但实际上我们几乎每天都会使用它。比如，大家打开 Windows、macOS 或者 Linux，不管是用资源管理器还是 Finder，都是在和文件系统打交道。如果大家曾经手动安装过操作系统，一定会记得在第一次安装时需要格式化磁盘，格式化时就需要为磁盘选择使用哪个文件系统。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3b/3ba10ee4e0ed31e83c2ec3bcd511ffdb.png\" /></p><p></p><p>维基百科上的关于文件系统[1]的定义是：</p><p></p><blockquote>In computing, file system is a&nbsp;method and data structure&nbsp;that the operating system uses to control how data is stored and retrieved.</blockquote><p></p><p></p><p>简而言之，文件系统的任务是管理存储介质（例如磁盘、SSD、CD、磁带等）上的数据。在文件系统中最基础的概念就是文件和目录，所有的数据都会对应一个文件，通过目录以树形结构来管理和组织这些数据。基于文件和目录的组织结构，可以进行一些更高级的配置，比如给文件配置权限、统计文件的大小、修改时间、限制文件系统的容量上限等。</p><p></p><p>以下罗列了一些在不同操作系统中比较常见的文件系统：</p><p>• Linux：ext4、XFS、Btrfs• Windows：NTFS、FAT32• macOS：APFS、HFS+</p><p><img src=\"https://static001.geekbang.org/infoq/5a/5aa666b0f5f45126ed312e5973e57323.png\" /></p><p>（图片来源：《Modern Operating Systems》10.2.5 小节）</p><p></p><p>上图是 Linux 内核的架构，左边 Virtual file system 区域，也就是虚拟文件系统简称 VFS。它的作用是为了帮助 Linux 去适配不同的文件系统而设计的，VFS 提供了通用的文件系统接口，不同的文件系统实现需要去适配这些接口。</p><p></p><p>日常使用 Linux 的时候，所有的系统调用请求都会先到达 VFS，然后才会由 VFS 向下请求实际使用的文件系统。文件系统的设计者需要遵守 VFS 的接口协议来设计文件系统，接口是共享的，但是文件系统具体实现是不同的，每个文件系统都可以有自己的实现方式。文件系统再往下是存储介质，会根据不同的存储介质再去组织存储的数据形式。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/98/98fa6c23a752eca9a45a51d0454e07c2.png\" /></p><p>一次写操作的请求流程</p><p>（图片来源：《Linux Kernel Development》第 13 章 Filesystem Abstraction Layer）</p><p></p><p>上图是一次写操作的请求流程，在 Linux 里写文件，其实就是一次&nbsp;write()&nbsp;系统调用。当你调用&nbsp;write()&nbsp;操作请求的时候，它会先到达 VFS，再由 VFS 去调用文件系统，最后再由文件系统去把实际的数据写到本地的存储介质。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4f/4f4250a148abb6e9ed08462d712c3d9c.png\" /></p><p></p><p>目录树（图片来源：《Modern Operating Systems》4.2.2 小节）</p><p></p><p>上图是一个目录树的结构，在文件系统里面，所有数据的组织形式都是这样一棵树的结构，从最上面的根节点往下，有不同的目录和不同的文件。这颗树的深度是不确定的，相当于目录的深度是不确定的，是由每个用户来决定的，树的叶子节点就是每一个文件。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9e/9e028397f833a0e27953916e45291038.png\" /></p><p></p><p>文件描述符与 inode</p><p>（图片来源：《Modern Operating Systems》10.6.3 小节）</p><p></p><p>最右边的 inode 就是每个文件系统内部的数据结构。这个 inode 有可能是一个目录，也有可能是一个普通的文件。Inode 里面会包含关于文件的一些元信息，比如创建时间、创建者、属于哪个组以及权限信息、文件大小等。此外每个 inode 里面还会有一些指针或者索引指向实际物理存储介质上的数据块。</p><p></p><p>以上就是实际去访问一个单机文件系统时，可能会涉及到的一些数据结构和流程。作为一个引子，让大家对于文件系统有一个比较直观的认识。</p><p></p><h2>分布式文件系统架构设计</h2><p></p><p>单机的文件系统已经能够满足我们大部分使用场景的需求，管理很多日常需要存储的数据。但是随着时代的发展以及数据的爆发增长，对于数据存储的需求也是在不断的增长，分布式文件系统应运而生。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3b/3b16b9bc24d63698db9d37b6d50699cb.png\" /></p><p></p><p>上面列了一些大家相对比较熟悉或者使用比较多的分布式文件系统，这里面有开源的文件系统，也有公司内部使用的闭源产品。从这张图可以看到一个非常集中的时间点，2000 年左右有一大批的分布式系统诞生，这些分布式文件系统至今在我们日常工作中或多或少还是会接触到。在 2000 年之前也有各种各样的共享存储、并行文件系统、分布式文件系统，但基本上都是基于一些专用的且比较昂贵的硬件来构建的。</p><p></p><p>自 2003 年 Google 的 GFS（Google File System）论文公开发表以来，很大程度上影响了后面一大批分布式系统的设计理念和思想。GFS 证明了我们可以用相对廉价的通用计算机，来组建一个足够强大、可扩展、可靠的分布式存储，完全基于软件来定义一个文件系统，而不需要依赖很多专有或者高昂的硬件资源，才能去搭建一套分布式存储系统。</p><p></p><p>因此 GFS 很大程度上降低了分布文件系统的使用门槛，所以在后续的各个分布式文件系统上都可以或多或少看到 GFS 的影子。比如雅虎开源的 HDFS 它基本上就是按照 GFS 这篇论文来实现的，HDFS 也是目前大数据领域使用最广泛的存储系统。</p><p></p><p>上图第四列的「POSIX 兼容」表示这个分布式文件系统对 POSIX 标准的兼容性。POSIX（Portable Operating System Interface）是用于规范操作系统实现的一组标准，其中就包含与文件系统有关的标准。所谓 POSIX 兼容，就是满足这个标准里面定义的一个文件系统应该具备的所有特征，而不是只具备个别，比如 GFS，它虽然是一个开创性的分布式文件系统，但其实它并不是 POSIX 兼容的文件系统。</p><p></p><p>Google 当时在设计 GFS 时做了很多取舍，它舍弃掉了很多传统单机文件系统的特性，保留了对于当时 Google 搜索引擎场景需要的一些分布式存储的需求。所以严格上来说，GFS 并不是一个 POSIX 兼容的文件系统，但是它给了大家一个启发，还可以这样设计分布式文件系统。</p><p></p><p>接下来我会着重以几个相对有代表性的分布式文件系统架构为例，给大家介绍一下，如果要设计一个分布式文件系统，大概会需要哪些组件以及可能会遇到的一些问题。</p><p></p><h3>GFS</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4b/4be65d9648021294cee184e4f85921aa.png\" /></p><p></p><p>（图片来源：The Google File System 论文）</p><p></p><p>首先还是以提到最多的 GFS 为例，虽然它在 2003 年就公布了，但它的设计我认为至今也是不过时的，有很多值得借鉴的地方。GFS 的主要组件可以分为三块，最左边的 GFS client 也就是它的客户端，然后就是中间的 GFS master 也就是它的元数据节点，最下面两块是 GFS chunkserver 就是数据实际存储的节点，master 和 chunkserver 之间是通过网络来通信，所以说它是一个分布式的文件系统。Chunkserver 可以随着数据量的增长不断地横向扩展。</p><p></p><p>其中 GFS 最核心的两块就是 master 和 chunkserver。我们要实现一个文件系统，不管是单机还是分布式，都需要去维护文件目录、属性、权限、链接等信息，这些信息是一个文件系统的元数据，这些元数据信息需要在中心节点 master 里面去保存。Master 也包含一个树状结构的元数据设计。</p><p></p><p>当要存储实际的应用数据时，最终会落到每一个 chunkserver 节点上，然后 chunkserver 会依赖本地操作系统的文件系统再去存储这些文件。</p><p></p><p>Chunkserver 和 master、client 之间互相会有连接，比如说 client 端发起一个请求的时候，需要先从 master 获取到当前文件的元数据信息，再去和 chunkserver 通信，然后再去获取实际的数据。在 GFS 里面所有的文件都是分块（chunk）存储，比如一个 1GB 的大文件，GFS 会按照一个固定的大小（64MB）对这个文件进行分块，分块了之后会分布到不同的 chunkserver 上，所以当你读同一个文件时其实有可能会涉及到和不同的 chunkserver 通信。</p><p></p><p>同时每个文件的 chunk 会有多个副本来保证数据的可靠性，比如某一个 chunkserver 挂了或者它的磁盘坏了，整个数据的安全性还是有保障的，可以通过副本的机制来帮助你保证数据的可靠性。这是一个很经典的分布式文件系统设计，现在再去看很多开源的分布式系统实现都或多或少有 GFS 的影子。</p><p></p><p>这里不得不提一下，GFS 的下一代产品: Colossus。由于 GFS 的架构设计存在明显的扩展性问题，所以 Google 内部基于 GFS 继续研发了 Colossus。Colossus 不仅为谷歌内部各种产品提供存储能力，还作为谷歌云服务的存储底座开放给公众使用。Colossus 在设计上增强了存储的可扩展性，提高了可用性，以处理大规模增长的数据需求。下面即将介绍的 Tectonic 也是对标 Colossus 的存储系统。篇幅关系，这篇博客不再展开介绍 Colossus，有兴趣的朋友可以阅读官方博客[2]。</p><p></p><h3>Tectonic</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dd/dddf0d3dcf730c550998f988a727d9bb.png\" /></p><p></p><p>（图片来源：Facebook’s Tectonic Filesystem: Efficiency from Exascale 论文）</p><p></p><p>Tectonic 是 Meta（Facebook）内部目前最大的一个分布式文件系统。Tectonic 项目大概在 2014 年就开始做了（之前被叫做 Warm Storage），但直到 2021 年才公开发表论文来介绍整个分布式文件系统的架构设计。</p><p></p><p>在研发 Tectonic 之前，Meta 公司内部主要使用 HDFS、Haystack 和 f4 来存储数据，HDFS 用在数仓场景（受限于单集群的存储容量，部署了数十个集群），Haystack 和 f4 用在非结构化数据存储场景。Tectonic 的定位即是在一个集群里满足这 3 种存储支撑的业务场景需求。和 GFS 一样，Tectonic 也主要由三部分构成，分别是&nbsp;Client Library、Metadata Store 和 Chunk Store。</p><p></p><p>Tectonic 比较创新的点在于它在 Metadata 这一层做了分层处理，以及存算分离的架构设计。从架构图可以看到 Metadata 分了三层：Name layer、File layer 和 Block layer。</p><p></p><p>传统分布式文件系统会把所有的元数据都看作同一类数据，不会把它们显式区分。在 Tectonic 的设计中，Name layer 是与文件的名字或者目录结构有关的元数据，File layer 是跟当前文件本身的一些属性相关的数据，Block layer 是每一个数据块在 Chunk Store 位置的元数据。</p><p></p><p>Tectonic 之所以要做这样一个分层的设计是因为它是一个非常大规模的分布式文件系统，特别是在 Meta 这样的量级下（EB 级数据）。在这种规模下，对于 Metadata Store 的负载能力以及扩展性有着非常高的要求。</p><p></p><p>第二点创新在于元数据的存算分离设计，前面提到这三个 layer 其实是无状态的，可以根据业务负载去横向扩展。但是上图中的 Key-value Store 是一个有状态的存储，layer 和 Key-value Store 之间通过网络通信。</p><p></p><p>Key-value Store 并不完全是 Tectonic 自己研发的，而是用了 Meta 内部一个叫做 ZippyDB 的分布式 KV 存储来支持元数据的存储。ZippyDB 是基于 RocksDB 以及 Paxos 共识算法来实现的一个分布式 KV 存储。Tectonic 依赖 ZippyDB 的 KV 存储以及它提供的事务来保证整个文件系统元信息的一致性和原子性。</p><p></p><p>这里的事务功能是非常重要的一点，如果要实现一个大规模的分布式文件系统，势必要把 Metadata Store 做横向扩展。横向扩展之后就涉及数据分片，但是在文件系统里面有一个非常重要的语义是强一致性，比如重命名一个目录，目录里面会涉及到很多的子目录，这个时候要怎么去高效地重命名目录以及保证重命名过程中的一致性，是分布式文件系统设计中是一个非常重要的点，也是业界普遍认为的难点。</p><p>Tectonic 的实现方案就是依赖底层的 ZippyDB 的事务特性来保证当仅涉及单个分片的元数据时，文件系统操作一定是事务性以及强一致性的。但由于 ZippyDB 不支持跨分片的事务，因此在处理跨目录的元数据请求（比如将文件从一个目录移动到另一个目录）时 Tectonic 无法保证原子性。</p><p></p><p>在 Chunk Store 层 Tectonic 也有创新，上文提到 GFS 是通过多副本的方式来保证数据的可靠性和安全性。多副本最大的弊端在于它的存储成本，比如说你可能只存了1TB 的数据，但是传统来说会保留三个副本，那么至少需要 3TB 的空间来存储，这样使得存储成本成倍增长。对于小数量级的文件系统可能还好，但是对于像 Meta 这种 EB 级的文件系统，三副本的设计机制会带来非常高昂的成本，所以他们在 Chunk Store 层使用 EC（Erasure Code）也就是纠删码的方式去实现。通过这种方式可以只用大概 1.2~1.5 倍的冗余空间，就能够保证整个集群数据的可靠性和安全性，相比三副本的冗余机制节省了很大的存储成本。Tectonic 的 EC 设计细到可以针对每一个 chunk 进行配置，是非常灵活的。</p><p></p><p>同时 Tectonic 也支持多副本的方式，取决于上层业务需要什么样的存储形式。EC 不需要特别大的的空间就可以保证整体数据的可靠性，但是 EC 的缺点在于当数据损坏或丢失时重建数据的成本很高，需要额外消耗更多计算和 IO 资源。</p><p></p><p>通过论文我们得知目前 Meta 最大的 Tectonic 集群大概有四千台存储节点，总的容量大概有 1590PB，有 100 亿的文件量，这个文件量对于分布式文件系统来说，也是一个比较大的规模。在实践中，百亿级基本上可以满足目前绝大部分的使用场景。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b8/b8550d0b86f3108a8822606a5c67b02a.png\" /></p><p>（图片来源：Facebook’s Tectonic Filesystem: Efficiency from Exascale 论文）</p><p></p><p>再来看一下 Tectonic 中 layer 的设计，Name、File、Block 这三个 layer 实际对应到底层的 KV 存储里的数据结构如上图所示。比如说 Name layer 这一层是以目录 ID 作为 key 进行分片，File layer 是通过文件 ID 进行分片，Block layer 是通过块 ID 进行分片。</p><p></p><p>Tectonic 把分布式文件系统的元数据抽象成了一个简单的 KV 模型，这样可以非常好的去做横向扩展以及负载均衡，可以有效防止数据访问的热点问题。</p><p></p><h3>JuiceFS</h3><p></p><p>JuiceFS 诞生于 2017 年，比 GFS 和 Tectonic 都要晚，相比前两个系统的诞生年代，外部环境已经发生了翻天覆地的变化。</p><p></p><p>首先硬件资源已经有了突飞猛进的发展，作为对比，当年 Google 机房的网络带宽只有 100Mbps（数据来源：The Google File System 论文），而现在 AWS 上机器的网络带宽已经能达到 100Gbps，是当年的 1000 倍！</p><p></p><p>其次云计算已经进入了主流市场，不管是公有云、私有云还是混合云，企业都已经迈入了「云时代」。而云时代为企业的基础设施架构带来了全新挑战，传统基于 IDC 环境设计的基础设施一旦想要上云，可能都会面临种种问题。如何最大程度上发挥云计算的优势是基础设施更好融入云环境的必要条件，固守陈规只会事倍功半。</p><p></p><p>同时，GFS 和 Tectonic 都是仅服务公司内部业务的系统，虽然规模很大，但需求相对单一。而 JuiceFS 定位于服务广大外部用户、满足多样化场景的需求，因而在架构设计上与这两个文件系统也大有不同。</p><p><img src=\"https://static001.geekbang.org/infoq/dc/dc5363f5a4a01abcab5c4903b6caa9ff.png\" /></p><p>基于这些变化和差异，我们再来看看 JuiceFS 的架构。同样的，JuiceFS 也是由 3 部分组成：元数据引擎、数据存储和客户端。虽然大体框架上类似，但其实每一部分的设计 JuiceFS 都有着一些不太一样的地方。</p><p></p><p>首先是数据存储这部分，相比 GFS 和 Tectonic 使用自研的数据存储服务，JuiceFS 在架构设计上顺应了云原生时代的特点，直接使用对象存储作为数据存储。前面看到 Tectonic 为了存储 EB 级的数据用了 4000 多台服务器，可想而知，如此大规模存储集群的运维成本也必然不小。对于普通用户来说，对象存储的好处是开箱即用、容量弹性，运维复杂度陡然下降。对象存储也支持 Tectonic 中使用的 EC 特性，因此存储成本相比一些多副本的分布式文件系统也能降低不少。</p><p></p><p>但是对象存储的缺点也很明显，例如不支持修改对象、元数据性能差、无法保证强一致性、随机读性能差等。这些问题都被 JuiceFS 设计的独立元数据引擎，Chunk、Slice、Block 三层数据架构设计，以及多级缓存解决了。</p><p></p><p>其次是元数据引擎，JuiceFS 可使用一些开源数据库作为元数据的底层存储。这一点和 Tectonic 很像，但 JuiceFS 更进了一步，不仅支持分布式 KV，还支持 Redis、关系型数据库等存储引擎，让用户可以灵活地根据自己的使用场景选择最适合的方案，这是基于 JuiceFS 定位为一款通用型文件系统所做出的架构设计。使用开源数据库的另一个好处是这些数据库在公有云上通常都有全托管服务，因此对于用户来说运维成本几乎为零。</p><p></p><p>前面提到 Tectonic 为了保证元数据的强一致性选择了 ZippyDB 这个支持事务的 KV 存储，但 Tectonic 也只能保证单分片元数据操作的事务性，而 JuiceFS 对于事务性有着更严格的要求，需要保证全局强一致性（即要求跨分片的事务性）。因此目前支持的所有数据库都必须具有单机或者分布式事务特性，否则是没有办法作为元数据引擎接入进来的（一个例子就是 Redis Cluster 不支持跨 slot 的事务）。基于可以横向扩展的元数据引擎（比如 TiKV），JuiceFS 目前已经能做到在单个文件系统中存储 200 多亿个文件，满足企业海量数据的存储需求。</p><p><img src=\"https://static001.geekbang.org/infoq/e5/e5d13211530b8d140979d260fb39920a.png\" /></p><p>上图是使用 KV 存储（比如 TiKV）作为 JuiceFS 元数据引擎时的数据结构设计，如果对比 Tectonic 的设计，既有相似之处也有一些大的差异。比如第一个 key，在 JuiceFS 的设计里没有对文件和目录进行区分，同时文件或目录的属性信息也没有放在 value 里，而是有一个单独的 key 用于存储属性信息（即第三个 key）。</p><p></p><p>第二个 key 用于存储数据对应的块 ID，由于 JuiceFS 基于对象存储，因此不需要像 Tectonic 那样存储具体的磁盘信息，只需要通过某种方式得到对象的 key 即可。在 JuiceFS 的存储格式[3]中元数据分了 3 层：Chunk、Slice、Block，其中 Chunk 是固定的 64MiB 大小，所以第二个 key 中的&nbsp;chunk_index&nbsp;是可以通过文件大小、offset 以及 64MiB 直接计算得出。通过这个 key 获取到的 value 是一组 Slice 信息，其中包含 Slice 的 ID、长度等，结合这些信息就可以算出对象存储上的 key，最终实现读取或者写入数据。</p><p></p><p>最后有一点需要特别注意，为了减少执行分布式事务带来的开销，第三个 key 在设计上需要靠近前面两个 key，确保事务尽量在单个元数据引擎节点上完成。不过如果分布式事务无法避免，JuiceFS 底层的元数据引擎也支持（性能略有下降），确保元数据操作的原子性。</p><p></p><p>最后来看看客户端的设计。JuiceFS 和另外两个系统最大的区别就是这是一个同时支持多种标准访问方式的客户端，包括 POSIX、HDFS、S3、Kubernetes CSI 等。GFS 的客户端基本可以认为是一个非标准协议的客户端，不支持 POSIX 标准，只支持追加写，因此只能用在单一场景。Tectonic 的客户端和 GFS 差不多，也不支持 POSIX 标准，只支持追加写，但 Tectonic 采用了一种富客户端的设计，把很多功能都放在客户端这一边来实现，这样也使得客户端有着最大的灵活性。此外 JuiceFS 的客户端还提供了缓存加速特性，这对于云原生架构下的存储分离场景是非常有价值的。</p><p></p><h2>结语</h2><p></p><p>文件系统诞生于上个世纪 60 年代，随着时代的发展，文件系统也在不断演进。一方面由于互联网的普及，数据规模爆发式增长，文件系统经历了从单机到分布式的架构升级，Google 和 Meta 这样的公司便是其中的引领者。</p><p></p><p>另一方面，云计算的诞生和流行推动着云上存储的发展，企业用云进行备份和存档已逐渐成为主流，一些在本地机房进行的高性能计算、大数据场景，也已经开始向云端迁移，这些对性能要求更高的场景给文件存储提出了新的挑战。JuiceFS 诞生于这样的时代背景，作为一款基于对象存储的分布式文件系统，JuiceFS 希望能够为更多不同规模的公司和更多样化的场景提供可扩展的文件存储方案。</p><p></p><h3>关于作者</h3><p></p><p>高昌健，Juicedata 技术专家，参与建设 JuiceFS 开源社区的主力队员。</p><p></p><h4>引用链接</h4><p></p><p>[1]&nbsp;文件系统:&nbsp;https://en.wikipedia.org/wiki/File_system[2]&nbsp;官方博客:&nbsp;https://cloud.google.com/blog/products/storage-data-transfer/a-peek-behind-colossus-googles-file-system[3]&nbsp;存储格式:&nbsp;https://juicefs.com/docs/zh/community/architecture#how-juicefs-store-files</p>",
    "publish_time": "2023-04-09 19:01:06",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]