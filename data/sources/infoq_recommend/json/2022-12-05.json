[
  {
    "title": "“理想解决方案”：Daltix的自动化数据湖归档节省了10万美元",
    "url": "https://www.infoq.cn/article/CMBPBjdfuQufcOc56P9U",
    "summary": "<p>本文最初发布于 Backblaze 官方博客。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fd/fd4cc0d8b066a369ded892a56c98fed6.png\" /></p><p></p><p>在快消领域，Daltix 是提供完整、透明、高质量零售数据的先行者。GFK 和联合利华等全球行业领导者依靠他们的定价、产品、促销和位置数据来制定入市策略并做出关键决策，对 Daltix 来说，维护一个可靠的数据生态系统势在必行。</p><p></p><p>自 2016 年成立以来，随着公司的发展，Daltix 处理的数据量呈指数级增长。他们目前管理着大约 250TB 的数据，分散在数十亿个文件中，很快就造成了巨大的时间和资源消耗。Daltix 的基础设施几乎完全是围绕 AWS 构建，因为需要管理数十亿个极小的文件，所以在可扩展性和成本效益方面，AWS 的存储选项已经开始无法满足他们的需求。</p><p></p><p>我们与 Daltix 首席软件工程师 Charlie Orford 进行了交流，了解他们如何迁移到 Backblaze B2 云存储以及他们从那个过程中得出了什么结论。以下是其中的一些要点：</p><p></p><p>他们使用一个自定义引擎将数十亿个文件从 AWS S3 迁移到 Backblaze B2；月度成本减少了 2500 美元，数据的可移植性和可靠性都得到了提升；Daltix 创建的基础设施每天可以自动备份 840 万个数据对象。</p><p></p><p>请继续阅读，看看他们是如何做到的。</p><p></p><p></p><h2>一个基于 AWS 构建的复杂数据管道</h2><p></p><p></p><p>Daltix 在公司创立初期创建的基于 S3 的基础设施，大部分还完好无损。过去，数据管道将从网络上抓取的资源直接写入 Amazon S3，经由基于 Lambda 的提取器进行标准化后，再发送回 S3。然后，由 AWS Batch 选取要使用其他数据源进行补充和丰富的资源。</p><p></p><p>所有这些步骤都是在 Daltix 的分析师团队准备好数据之前进行的。为了优化流程并提高效率，Orford 开始将该流程的部分环节纳入到 Kubernetes 中，但数据存储仍然存在问题；Daltix 每天生成大约 300GB 的压缩数据，而且这个数值还在迅速增长。“随着数据收集规模的扩大，我们必须更加关注成本控制、数据可移植性和可靠性，”Orford 说，“这些都是显而易见的，但规模大了，就更加重要了。”</p><p></p><p></p><h2>成本方面的考量促使我们寻找更友好的归档存储</h2><p></p><p></p><p>到 2020 年，Daltix 开始意识到，在 AWS 中构建这么多基础设施存在局限性。例如，围绕 S3 元数据进行的大量定制使得移动对象的能力完全受制于目标系统与 S3 的兼容性。Orford 还担心，在 S3 中永久存储如此巨大的数据湖的成本。如他所言，“很明显，没有必要把所有东西都永远存在 S3 中。如果不采取任何措施，那么我们的 S3 成本将继续上升，并最终远远超出我们使用其他 AWS 服务的成本。”</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/84/84bc4ae9d4c2ff7d0b676abbf05afd8f.png\" /></p><p></p><p></p><p>服务器成本对比</p><p></p><p>因为 Daltix 要处理数十亿个小文件，所以不可能使用 Glacier，因为它的定价模式是基于检索费用的。即使是使用 Glacier 即时检索，Daltix 所处理的文件数量也会使他们每年额外支付 20 万美元的费用。因此，Daltix 的数据收集团队（公司 85% 以上的数据都来自这个团队）推动实施了一种可替代的解决方案，解决了一些相互矛盾的问题：</p><p></p><p>数据湖的庞大规模；需要将原始资源存储为离散文件（这意味着无法进行批处理）；团队能够投入的时间和精力有限；简化解决方案，以保证其可靠性。</p><p></p><p>Daltix 决定使用 Amazon S3 进行热存储，并将暖存储转移到新的归档解决方案中，这可以降低成本，同时保持重要数据可访问——即使目的是将文件存储在别处。Orford 说：“重要的是要找到某个非常容易集成而且开发风险低的东西，并且有助于降低我们的成本。对我们来说，Backblaze 确实可以满足所有要求。”</p><p></p><p></p><h2>只是初步迁移每月就立省 2000 美元</h2><p></p><p></p><p>在开始全面迁移之前，Orford 和他的团队做了概念验证（POC），以确保解决方案解决了他们重点关注的问题：</p><p></p><p>确保海量数据成功迁移；避免数据损坏并使用审计日志检查错误；保留每个对象的自定义元数据。</p><p></p><p>“早期，我们与 Backblaze 合作，定制了一个可以满足我们所有需求的迁移工具，”Orford 说，“这给了我们继续前进的信心。”Backblaze 为我们定制了一个迁移引擎，可以保证迁移过程能够可靠地传输整个数据湖，并且保证对象级元数据完好无损。在成功迁移了一开始的 POC 存储桶之后，Daltix 就拥有了开始建模和预测未来成本所需的一切。Orford 说道：“在开始接触 Backblaze 之后，我们便不再寻找其他选项“。</p><p>2021 年 8 月，Daltix 将一个包含 22 亿个对象的 120TB 的存储桶从 S3 的标准存储转移到 Backblaze B2 云存储。仅最初的迁移就立即节省了 2000 美元 / 月或 24000 美元 / 年的成本。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d8/d8742d1006e419ddd999e63692f10fe7.png\" /></p><p>宁静的数据湖</p><p></p><h3>三倍的数据，直接兼容 S3，累计节省 10 万美元</h3><p></p><p></p><p>现在，Daltix 每天从 Amazon S3 向 Backblaze B2 迁移 320 万个数据对象（大约 160GB 的数据）。他们在 S3 中保存了 18 个月的热数据，一旦一个对象存在达 18 个月零一天，就会被归档到 B2 中。在少数情况下，Daltix 也会接收到请求 18 个月窗口期之外的数据的请求，由于 Backblaze 的 API 兼容 S3 且数据永远可用，所以他们可以直接将数据从 Backblaze B2 拉到 Amazon S3。</p><p></p><p>每日审计日志会汇总已传输的数据量，整个迁移过程每天自动执行。Orford 说：“它在后台运行，我们不需要管理任何东西，什么都可以看到，而且很划算。对我们来说，Backblaze B2 是一个理想的解决方案。”</p><p></p><p>随着每日数据收集量的增加，会有越来越多的数据从热存储窗口中迁出，Orford 预计成本会进一步降低。据 Orford 估计，日迁移量将在大约一年半后接近目前水平的三倍：这意味着 Daltix 每天将向 Backblaze B2 备份 900 万个对象（约 450GB 数据）。长远来看，从 Amazon S3 切换到 Backblaze B2 为 Daltix 节省的成本都令人难以置信。Orford 说：“因为使用了 Backblaze B2，预计到 2023 年，我们在存储支出上将累计节省 7.5 万至 10 万美元，每年至少节省 3 万美元。”</p><p></p><p></p><h2>自己算算看</h2><p></p><p></p><p>想知道每年多出 3 万美元能做什么吗？可以利用我们的云存储定价计算器，了解下迁移到 Backblaze B2 可以节省多少钱。</p><p></p><p>声明：本文为 InfoQ 翻译，未经许可禁止转载。</p><p></p><p>原文链接：https://www.backblaze.com/blog/an-ideal-solution-daltixs-automated-data-lake-archive-saves-100k/</p>",
    "publish_time": "2022-12-05 10:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "程序员上手 Rust 2年后感悟：它的确强大，但想要取代C还远着呢",
    "url": "https://www.infoq.cn/article/mEux81fTgUD0NlbJK9Lj",
    "summary": "<p></p><p>本文最初发布于Nabil Elqatib的个人博客。</p><p></p><p>接触Rust开发快两年了。我觉得，回顾下自己在这个过程中的一些感想和汲取的经验教训，应该会很有趣。</p><p></p><p>下图是我第一次向一个Rust存储库提交代码。虽然时间是2021年1月，但彼时我接触Rust已经有几个周了。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6f/6fe39ebbb6d88f658304419ab86cd436.png\" /></p><p></p><h2>初识Rust</h2><p></p><p>在2020年12月找到一份新工作之前，我早就听说过Rust。以我嵌入式开发的视角看，我认为Rust是一种现代而强大的语言，最终可能成为C/C++的合法继承者。我隐隐有一种担优，我可能会错过一个新时代的开始。</p><p></p><p>剧透：事实证明，Rust并没有取代C/C++，不过它正在稳步增长。<a href=\"https://survey.stackoverflow.co/2022/#section-most-loved-dreaded-and-wanted-programming-scripting-and-markup-languages\">它越来越受开发人员欢迎</a>\"，甚至谷歌也对它怀有浓厚的<a href=\"https://www.reddit.com/r/rust/comments/mgz7y5/androids_new_bluetooth_stack_rewrite_gabeldorsh/\">兴</a>\"<a href=\"https://opensource.googleblog.com/2022/10/announcing-kataos-and-sparrow.html\">趣</a>\"。</p><p></p><h2>我的感受</h2><p></p><p>首先需要声明一下：我没有正式学习过Rust。相反，我只是通过开发、阅读代码和来回翻阅文档来学习。回想起来，我认为这并不是一个好的做法。我坚信，在实际使用这门语言进行开发之前，必须花一些时间，利用<a href=\"https://www.rust-lang.org/learn\">官方提供的学习资料</a>\"来快速地理解这门语言、它的哲学和生态系统。</p><p></p><h3>Rust的学习曲线比较陡峭</h3><p></p><p>我记得，Rust是作为一种强类型语言向人“推销”的，它承诺提供强大的工具，通过在编译期间跟踪对象生命周期和所有引用变量的作用域，来防止内存安全Bug（见下一小节）。Borrow-checker出场！</p><p></p><p>在使用静态类型和Rc以及其他微妙的语言构件处理多个crate时，这个看起来非常简单的想法（Rust文档中关于这部分的内容非常全面）变成了一场噩梦。当时，我很难理解这个新概念，最容易钻的空子是不断地克隆变量，这样做不好（特别是在处理大型数据结构时），而且还有一个副作用，就是使我花了更多的时间才最终掌握它。</p><p></p><p>幸运的是，编译器提供了非常有用的提示和文档链接，我必须说，它们非常有用。</p><p></p><h3>Cargo不是一个严谨的验证工具</h3><p></p><p>这是一个非常普遍的误解，是我最近与一位非Rust工程师同事聊天时了解到的。在他看来，Rust程序因为运行时内存越界故障而恐慌（panic）是不可想象的。遗憾的是，Cargo编译器并不是一种包治百病的灵丹妙药，显然，欺骗它成功编译只会在运行时失败的程序很容易。下面这个例子使用了一种非常常见的Rust数据结构：</p><p></p><p><code lang=\"plain\">let mut v = vec![];\nv.push(0);\nv.clear();\nlet _ = v[0]; // panics \n</code></p><p></p><p>或者更棘手：</p><p></p><p><code lang=\"plain\">let mut v = Vec::new();\n\n#[cfg(target_os = \"windows\")]\nv.push(\"a\");\n\nlet _ = v[0]; // panics\n</code></p><p></p><p>在编译时检测越界访问需要对代码进行更深入的分析，这可以显著降低编译速度（在我看来，编译时间已经太长了）。</p><p></p><h3>Rust可能会让人捉摸不透</h3><p></p><p>这一节和我最近观察到的一个行为有关。我们的团队发现，在特定条件下，生产环境中的其中一个crate（依赖项的）依赖项开始出现恐慌。简单来说就是，当与rustls-tls-native-roots特性一起使用时，如果系统证书损坏，那么特定版本的<a href=\"https://docs.rs/reqwest/latest/reqwest/\">reqwest</a>\"会引发错误和恐慌。</p><p></p><p>这让我很惊讶，因为它使得处理依赖关系多了几分风险。</p><p></p><p>尽管现在大多数crate都是开源的，但人们也不能为了评估使用“风险”而把所有源代码都检查一遍。而且，大多数crate的文档比较糟糕，也没法提供很好的支持。有一个类似于cargo tree的工具，可以分析项目的依赖关系，让开发人员可以概览容易出现恐慌的crate，会非常有帮助。</p><p></p><p>习惯上，快速处理这个问题的一个替代方法是重写Rust的panic_handler，但很遗憾，这只有在#![no_std] 项目中才有可能。</p><p></p><h3>程序的二进制文件可能会很大</h3><p></p><p>说到来自嵌入式世界的no_std，这是我特别感兴趣的一个点。我还没有机会为内存有限的低端设备和外设编写Rust代码。尽管这现在不是我关心的问题，但Rust二进制文件的开销确实非常大。</p><p></p><p>我读过一些关于这个话题的博客和论文，特别是Jon Gjengset的视频，非常有趣，因为他们概要介绍了一个真实的实践过程。但我想说的是，对于内存有限的目标设备，Rust要成为C语言的有力竞争者还有很长的路要走。我觉得，在#![no_std] 领域，Rust还需要找到一种方法来提供可行的恐慌处理程序库，不再依赖开箱即用的格式化函数，因为它们非常消耗内存。<a href=\"https://jamesmunns.com/blog/fmt-unreasonably-expensive/\">James Munns的这篇文章</a>\"让我大开眼界。</p><p></p><h3>Rust工具有很棒的互操作性</h3><p></p><p>这点也给我留下了深刻的印象。</p><p></p><p>我参与过一个项目，包含900K+行与Rust互操作的C代码。这并没有多难，因为Rust让这个过程变得非常简单，而且，因为有许多crate和示例，这个用例似乎也已经比较完善。借助FFI机制，为外部代码编写Rust绑定也相对简单，我不能说所有语言，但C语言家族（C/ C++ /Objective-C）都得到了很好的支持。</p><p></p><p>这不是说没有多少工作要做了，因为你还需要编写一些“管道”代码来把所有东西串联起来，这有代价，但我认为相当低。此外，Rust坚持自己的哲学，要求将可疑的底层代码声明为不安全的，这一点很好（实际上，基本上所有FFI函数都是不安全的，因为Rust无法控制用另一种语言编写的代码）。</p><p></p><h3>Rust很强大</h3><p></p><p>最后说一个积极的方面。Rust是一种非常丰富的语言，有可能让系统编程取得巨大的进步。严格的所有权和借阅有助于确保数据访问安全高效。它的现代语法和设计使得开发人员更容易理解和使用这门编程语言的软件模式和最新范式。此外，虽然说的不多，但Rust在线程并发运行方面做得非常好，可以保证不出现竞态条件及类似问题。</p><p></p><h3>小结</h3><p></p><p>我真的很喜欢Rust开发。如果在2020年甚至2022年要选择一种新的软件开发语言，那么我一定会毫不犹豫地选择Rust。我看到了它的巨大潜力，希望接下来的几个月里，它可以获得嵌入式系统世界的更多关注。最近发布的Rust Linux内核模块显示出了其广阔的前景和光明的未来。</p><p></p><p>就我个人而言，我希望更多地参与塑造 Rust 的未来，为它的软件做出贡献，同时不断学习它的概念及那些纷繁芜杂之处。</p><p></p><p>声明：本文为InfoQ翻译，未经许可禁止转载。</p><p></p><p>原文链接：<a href=\"https://n-eq.github.io/blog/2022/11/01/rust-fiddling-2-years\">https://n-eq.github.io/blog/2022/11/01/rust-fiddling-2-years</a>\"</p>",
    "publish_time": "2022-12-05 10:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "携程商旅CEO张勇：TMC不止一站式解决方案 携程商旅推出“产品云图”",
    "url": "https://www.infoq.cn/article/2db527a86c857301ab0972658",
    "summary": "<p>12月2日，携程商旅在2022年“与时·聚进”携程集团全球合作伙伴峰会上，发布全新“产品云图”。通过这一举措，携程商旅突破了“一站式商旅解决方案服务商”的固有角色，将在未来全面打造“全景服务能力体系”。</p><p><img src=\"https://static001.geekbang.org/infoq/65/65015f430772464ba7dc080e6ceea21e.png\" /></p><p></p><p>“产品云图”展示了携程商旅整个体系化的产品、服务、管理工具以及运行机制，有助于用户及上下游供应链一目了然锁定需求。基于云图战略，与商旅相关的每一个环节方都将从中获得“可选择、可搭配、可延展、可迭代、可融合”的全景解决提案。“产品云图的发布，意味着商旅行业将从一站式差旅解决方案时代，迈入全景服务能力体系时代”。携程商旅CEO张勇表示。</p><p>&nbsp;</p><p>TMC不止一站式解决方案 云图战略探照商旅冰山下隐藏价值</p><p>&nbsp;</p><p>“当中国的商旅行业已经发展到国际领先水平之后，下一个阶段到底是什么？TMC只提供一体化的解决方案就够了吗？”张勇现场提出一个商旅时代性问题。</p><p>&nbsp;</p><p>调研显示，超过67%的管理者认为，商旅管理可以作为一家企业在探索数字化转型中的试验田。然而还有许多企业，仅把商旅作为员工出差预订机票酒店的工具。“产品云图”为用户、合作伙伴列举了商旅的更多可能性：例如费控报销体系、支付解决方案、交通酒店专家、合规管理方案、咨询服务等等。</p><p><img src=\"https://static001.geekbang.org/infoq/11/1170ac3c25f8ee2af3c0830e2c595761.png\" /></p><p></p><p>“显然，不通过云图放大差旅预订以外的“人智数”价值，用户的隐性成本就像海平面下的冰山，不被发现但持续损耗用户权益。”张勇表示。记者了解到，日常企业差旅管理中，重复提报、超预算、违规操作、无法使用三方协议价等问题依旧是企业商旅的顽疾。</p><p>&nbsp;</p><p>为了发挥“产品云图”的效能，真正打造出携程商旅的全景服务能力体系，携程商旅重新构建了技术中心、资源中心、服务中心、合规中心以及营销中心五大能力中心。五大能力中心由内向外发挥各自职能，达到给养内部支援外部的协同作用。例如重构前携程商旅营销部仅是企业内部支持机构，重新定义后的营销中心可通过产品手册、行业趋势、数据报告等内容智库为客户多元化赋能。</p><p>&nbsp;</p><p>共建共拓携程商旅为客户提供2700+定制化生态系统集成方案</p><p>&nbsp;</p><p>事实上，云图战略只是携程商旅的自我迭代中的一部分：更多的行业共建、生态共拓，也正在基于对客户的洞察而推进。</p><p>&nbsp;</p><p>“我们发现随着客户差旅体系的完善与成熟化，新的碎片化问题逐渐衍生出现。例如面对越来越多的三方订单需求，我们通过积极推进行业内的系统覆盖，与酒店伙伴的系统对接率提升了467%，帮助酒店的三方协议订单确认效率再提升80%，做到优化商旅客户体验的同时，降低酒店的满房率与变价率，有效赋能酒店的服务和管理能力。”张勇介绍道。</p><p>&nbsp;</p><p>针对企业对可持续发展和绿色出行的关注，携程商旅采用Travalyst的旅行影响模型，上线航班碳排放量数据标签，记录商旅客户的每一次差旅的碳足迹，鼓励商旅客户选择低碳航班出行。</p><p>&nbsp;</p><p>此外，携程商旅已经与6大生态系统，超过140家的国内外主流厂商合作，为企业客户提供了超过2700份生态合作定制化系统集成方案和55000份标准化系统集成方案。经过统计，采用集成方案后的每位企业员工平均一年可以节省200分钟的时间成本。</p><p>&nbsp;</p><p>携程商旅国内国际纵横发展三季度总业绩反超2019年</p><p>&nbsp;</p><p>从用户出发奠定了携程商旅业绩增长的基石，虽然经历了疫情的跌宕冲击，但从整体业绩恢复情况来看，携程商旅在第三季度反超2019年同期水平。同时受海外商旅复苏影响，今年前10个月出入境商旅机票订单量同比增长245%，国际商旅酒店订单量同比增长531%。</p><p>&nbsp;</p><p>在国内市场下沉布局方面，携程商旅在新一线城市的供应链部署量级同比增长90%，企业客户数增长了20%，用户数增长53%。国际方面，当前携程商旅已经在包括东亚、东南亚、欧洲地区的5个市场做好了基础布局。随着今年国际商旅的开放，商旅海外用户数同比增长超过8倍。</p>",
    "publish_time": "2022-12-05 11:20:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "实时数据赋能制造业产能升级：详解半导体和汽车制造行业最佳实践（活动报名）",
    "url": "https://www.infoq.cn/article/7c240ec922a870266ee34f2ba",
    "summary": "<p>如今，数据的时效性会真正影响到一个企业的生存。特别是对于制造行业而言，一面是信息化建设过程中数百套业务系统积累的历史包袱；一面是多种数据源下数字化建设的更多新需求，数据孤岛成为企业内长期存在的问题，数据实时同步难度升级，直接对产能、研发效率等产生影响。以半导体制造和车企在生产环境的真实需求为例：</p><p></p><p>某大型半导体制造企业：无人实验室作业</p><p></p><p>不同于常规生产流水线，半导体制造的无人实验室生产模式，通过自动化排程完成机器人工作，高度依赖机器人作业来完成兼具复杂性与精密性的任务。每次数据需要计算 10-15 分钟，才能将结果给到排程系统，这就导致机器人大量时间没有工作，直接影响企业产能。如果能有效提升数据实时性，做到将数据在 1 分钟内推送到排程系统，生产速度跃升，占据产能优势的目标便不再是问题。</p><p></p><p>某头部车企：60+业务系统运转中</p><p></p><p>行业深耕数十载，在稳扎资深根基的同时，也在历史数字化变革求新的过程中遗留了一些数据负担——大量独立构建的系统，彼此数据难以共享打通；涉及数据库种类及版本多样；数据量不容小觑。在日益凸显的孤岛问题影响下，面对来自不同业务组提交的数据请求，研发很难做到快速响应。如果能快速打通数据孤岛，实现数据实时入湖，研发团队才能真正有机会将被数据层工作“绑架”的精力释放出来，助力业务团队实现更多创新。</p><p></p><p>想要了解当下制造行业的企业数据现状和根本痛点？想要接触更多制造业实时数据实践方案，吸收数字化成功经验？想要快速对比不同实时数据集成解决方案的特性与缺陷，为技术选型提供更多参考？……</p><p></p><p>欢迎参加 Tapdata 线上交流活动！</p><p></p><p>12月7日（周三）19:00，Tapdata 直播间与您相约。Tapdata 首席架构师杨庆麟（Arthur）在线讲解当下制造行业有关实时数据集成的真实诉求，结合成功案例解析各类解决方案的特点与架构。</p><p></p><p>更多活动信息及报名方式，详见海报：</p><p><img src=\"https://static001.geekbang.org/infoq/eb/ebf2aa7c2aa2839da0b2ecca4a01a8a0.png\" /></p><p>立刻扫码，关注报名</p>",
    "publish_time": "2022-12-05 11:48:04",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "OpenAI最新聊天机器人ChatGPT火爆全网！能写代码、编剧本，马斯克盛赞：好得吓人",
    "url": "https://www.infoq.cn/article/AWWsrfb54zTvglZ0I5qS",
    "summary": "<p></p><blockquote>写代码、编故事、构建虚拟机……聊天机器人 ChatGPT 还有多少惊喜是我们不知道的？</blockquote><p></p><p></p><h2>OpenAI 发布测试版聊天机器人 ChatGPT</h2><p></p><p></p><p>近日，OpenAI 发布了一个全新的聊天机器人模型 <a href=\"https://chat.openai.com/auth/login\">ChatGPT</a>\"，这也是 GPT-3.5 系列的主力模型之一。目前，ChatGPT 还处于测试阶段，只需登录就能免费使用，OpenAI 希望可以通过用户反馈开发出更好的 AI 系统。</p><p></p><p>虽然类似的聊天机器人并不少见，但 ChatGPT 一经发布迅速火爆全网，并收获了无数好评。有开发者认为，有些技术问题就算问谷歌和 <a href=\"https://www.infoq.cn/article/egLtw4WYSjlaO3ShdYix\">Stack Overflow</a>\"，都没有 ChatGPT 回答得靠谱。</p><p></p><p>连马斯克也在感叹“很多人疯狂地陷入了 ChatGPT 循环中”，“ChatGPT 好得吓人，我们离强大到危险的人工智能不远了”。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6c/6c7a6a9a0c2fa0c535cbbed7c406df6b.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/36/36f04b961e949adf68503b8252d5be13.png\" /></p><p></p><p>让马斯克盛赞、全网沸腾的 ChatGPT 到底有什么魔力？</p><p></p><p>根据 OpenAI 的介绍，ChatGPT 使用了与另一款 GPT-3.5 系列的模型 InstructGPT 相同的方法，但另外收集了 AI 与人类对话的数据，既包括人类自己的，也包括 AI 的，这些 AI 训练师可以参照建模建议写出自己的答案。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/92/922921afd39e519de8720f28f227e2d6.png\" /></p><p></p><p>对于强化学习奖励模型，OpenAI 记录了 AI 训练师和聊天机器人之间的对话。然后，该团队随机选择了一个人工智能利用不同自动补全功能生成的回复，并让训练师对其进行评分。在进行微调时，OpenAI 使用了近端策略优化（proximal policy optimization），这个过程会反复进行多次。</p><p></p><p>目前，不少网友展示了与 ChatGPT 对话的有趣内容，并解锁了多个 ChatGPT 的用途。</p><p></p><p>有网友询问 ChatGPT 如何设计客厅，ChatGPT 给出了三种装饰方案，还贴心地给出了三幅设计图。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6c/6ccd06c1dea69050ebc111229c32ff53.png\" /></p><p></p><p>有网友用《老友记》等喜剧演员为角色，让 ChatGPT 写一些肥皂剧对白，ChatGPT 把好几个场景描绘得惟妙惟肖：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4a/4a5ac7bda550265f07715ecd1fe12ce4.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/77/770dfaed20c947e695ff18e8cdaffe76.png\" /></p><p></p><p>也能解释各种科学概念：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fa/facdfa77255926e0624e2d71410c6048.png\" /></p><p></p><p>就连写论文这种比较有挑战的事情，ChatGPT 也冲上来试了试。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ee/ee8de2e71da48e0ca5a6c8ff2d6af1d6.jpeg\" /></p><p></p><p>其中，最令人兴奋的当属 ChatGPT 在技术领域的用途。</p><p></p><p>区别于普通的聊天机器人，ChatGPT 显然更懂技术，它能写代码、改 Bug、创建编程语言、构建虚拟机……</p><p></p><p>与 GitHub 的 <a href=\"https://www.infoq.cn/article/93kD4l5m0pye7k5CrKRT\">AI 编程神器 Copilot </a>\"相比，ChatGPT 似乎更能抢走程序员饭碗。技术公司 Replit CEO Amjad Masad 称赞 ChatGPT 是一个优秀的“调试伙伴”，“它不仅解释了错误，而且修复了它，并解释了修复方法”。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1f/1fe5a82ae93a6cc958efb9b9022296cd.png\" /></p><p></p><p>而对于一些更简单的问题，ChatGPT 更是“对答如流”，有网友在对比了谷歌的搜索结果和与 ChatGPT 的聊天结果之后，自信地宣称谷歌已经“完蛋”了。</p><p></p><h2>ChatGPT 还存在许多局限性</h2><p></p><p></p><p>虽然给大家带来了很多惊喜，但不得不承认，当前的 ChatGPT 还存在大型语言模型中常见的局限性。其中，部分网友对 ChatGPT 提供的回答准确性存在质疑。有网友指出，ChatGPT 提供的代码包含完全不相关的解释：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/95/95736aa73e1799328499c58914df0673.png\" /></p><p></p><p>另外，ChatGPT 有时还会生成听起来合理，但既不正确又无意义的回复。按照 OpenAI 的说法，因为缺少单一事实来源，过度谨慎训练的模型会拒绝问题，而在有监督训练中，理想的答案取决于模型的知识，而不是人类演示者。</p><p></p><p>ChatGPT 对输入的微小变化也会有很大的反应。根据输入内容的不同，它可能不回答，回答错误内容，或者回答正确内容——根据 OpenAI 的说法，简单的重新措辞就可以了。此外，ChatGPT 的回答太过于冗长，大多使用短句，并爱说些车轱辘话。出现这种情况的原因是过度优化和人类导师的偏见，他们更喜欢人类反馈中那些比较详细的答案。</p><p></p><p>ChatGPT 不会用提问来回应不清楚的表述，而是尝试猜测用户的意图。有时，对于不恰当的请求，该模型会回应而不是拒绝它们。OpenAI 试图使用其适度性 API，来拒绝不符合其内容策略的请求。</p><p></p><p>如果你问 ChatGPT 它自己的意见，它会拒绝回答，给出的理由是没有接入互联网。</p><p></p><p>OpenAI 表示：“ChatGPT 模型还有许多局限性，所以我们计划定期更新模型，在这些方面做些改进。但我们也希望，通过提供 ChatGPT 的访问接口，获取宝贵的用户反馈，以发现我们尚未意识到的问题。”</p><p></p><p>虽然当前的 ChatGPT 还不算完美，但它像人们描述除了一个更光明的 AI 未来。谷歌母公司 Alphabet 的工程师评论道：</p><p></p><p>“像 GPT 这样的大型语言模型是谷歌活跃的 ML 研究的最大领域之一，并且有大量非常明显的应用程序可以用来回答查询、索引信息等。谷歌有大量预算与人员来处理这些类型的模型，并进行实际训练，这是非常昂贵的，因为训练这些超大型语言模型需要大量的计算能力。然而，我从谈话中收集到的是，在最大的谷歌产品（例如搜索、gmail）中实际使用这些语言模型的经济性还不完全存在。放一个大家感兴趣的演示是一回事，但考虑到服务成本，尝试将它深入集成到一个每天服务数十亿个请求的系统中是另一回事。我想我记得主持人说过他们希望将成本降低至少 10 倍，然后才能将这样的模型集成到搜索等产品中。</p><p></p><p>10 倍甚至 100 倍的改进显然是未来几年可以实现的目标，所以我认为这样的技术将在未来几年内出现。”</p>",
    "publish_time": "2022-12-05 13:41:06",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "踩坑之旅：配置 ROS 环境",
    "url": "https://www.infoq.cn/article/b34c9dcad688d4890815e0e2c",
    "summary": "<p>以下内容为本人的著作，如需要转载，请声明原文链接<a href=\"https://mp.weixin.qq.com/s/IS2lkMud7x_u0aZKar9z3w\"> 微信公众号「englyf」</a>\"https://mp.weixin.qq.com/s/IS2lkMud7x_u0aZKar9z3w</p><p></p><p></p><p></p><p>最近在学习机器人相关的导航算法，为了方便于验证算法的效果，需要搭一个 ROS(Robot Operate System) 环境。特地写点笔记，这是这个机器人系列的首篇笔记。</p><p></p><p>虽然在网络上有很详细的教程，不过在对着教程一步步安装的过程中还是踩了不少坑。因为在墙内(你懂的)，会导致联网下载文件的时候老是失败。可能你会说不可以指定墙内的安装源吗？可以是可以，不过在安装完 ROS 包后还需要初始化一些环境，比如 rosdep 的初始化，这时候还是需要从 github 联网下载文件的，这时就算指定了墙内的安装源也不管事，因为这个 github 的域名被污染了。下面就记录一下解决的过程吧，回首往事真的一把心酸。。。</p><p></p><p></p><blockquote>基础环境:<br />Ubuntu 18.04<br />ROS Melodic<br />VMware® Workstation 14 Pro<br /></blockquote><p></p><p></p><h2>1.配置软件仓库</h2><p></p><p>确保软件仓库里允许下载的资源类型包括 main, universe, restricted, multiverse。如下面图所示，</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/64/64f1fd79b9a086dbe5ed3a76e5d51a2a.png\" /></p><p></p><h2>2.指定墙内的安装源</h2><p></p><p>国内的安装源有好几个，还是觉得阿里的安装源比较快一些，直接拷贝下面的内容到 /etc/apt/sources.list 文件中替换原来的内容并且保存</p><p></p><p><code lang=\"text\">deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse\n\ndeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse\n\ndeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse\n\n# deb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse\n# deb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse\n\ndeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse\n</code></p><p></p><p>单独指定 ROS 包的安装源</p><p></p><p><code lang=\"text\">sudo sh -c '. /etc/lsb-release &amp;&amp; echo \"deb http://mirrors.aliyun.com/ros/ubuntu/ `lsb_release -cs` main\" &gt; /etc/apt/sources.list.d/ros-latest.list'\n</code></p><p></p><h2>3.指定密钥</h2><p></p><p><code lang=\"text\">sudo apt-key adv --keyserver 'hkp://keyserver.ubuntu.com:80' --recv-key C1CF6E31E6BADE8868B172B4F42ED6FBAB17C654\n</code></p><p></p><p>到目前为止，以上的设置都很顺利。如果这一步你刚好出错了，可以到<a href=\"http://wiki.ros.org/cn/melodic/Installation/Ubuntu\">这里</a>\"去看看处理方法。</p><p></p><h2>4.安装 ROS 包</h2><p></p><p>更新一下安装索引</p><p></p><p><code lang=\"text\">sudo apt update\n</code></p><p></p><p>安装完整的桌面版</p><p></p><p><code lang=\"text\">sudo apt install ros-melodic-desktop-full\n</code></p><p></p><p>中间会出现提示</p><p></p><p><code lang=\"text\">Do you want to continue? [Y/n]\n</code></p><p></p><p>输入 Y 然后回车继续安装过程，花点时间休息一下再回来。。。</p><p></p><p>回来一看</p><p></p><p><code lang=\"text\">E: Failed to fetch http://mirrors.aliyun.com/ros/ubuntu/pool/main/r/ros-melodic-rqt-moveit/ros-melodic-rqt-moveit_0.5.10-1bionic.20210505.031448_amd64.deb  Undetermined Error [IP: 120.241.234.99 80]\nE: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n</code></p><p></p><p>出现了这一坨失败提示，后边还建议加个参数 --fix-missing 下载补漏，好的再来一次</p><p></p><p><code lang=\"text\">sudo apt install ros-melodic-desktop-full --fix-missing\n</code></p><p></p><p>好了，安装完成</p><p></p><h2>5.配置 ROS 环境变量</h2><p></p><p>为了在每次启动 bash 时都自动载入 ROS 的环境变量，输入</p><p></p><p><code lang=\"text\">echo \"source /opt/ros/melodic/setup.bash\" &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></p><p></p><p>配置完，重启一下 Terminal 窗口</p><p></p><h2>6.安装一些关键的依赖包</h2><p></p><p><code lang=\"text\">sudo apt install python-rosdep python-rosinstall python-rosinstall-generator python-wstool build-essential\n</code></p><p></p><p>中间又会出现提示</p><p></p><p><code lang=\"text\">Do you want to continue? [Y/n]\n</code></p><p></p><p>输入 Y 然后回车继续安装过程</p><p></p><h2>7.初始化 ROS 的依赖安装管理包 rosdep</h2><p></p><p>rosdep 是 ROS 安装管理包。使用 ROS 过程中如果需要安装被 ROS 要编译的源代码，或被某些 ROS 核心组件依赖的包，那么就可以用 rosdep 来安装。使用前，这个包需要被初始化一次</p><p></p><p><code lang=\"text\">sudo rosdep init\n</code></p><p></p><p>但是，很多情况下你会碰到下面这些错误提示</p><p></p><p><code lang=\"text\">ERROR: cannot download default sources list from:\nhttps://raw.githubusercontent.com/ros/rosdistro/master/rosdep/sources.list.d/20-default.list\nWebsite may be down.\n</code></p><p></p><p>报错内容的意思说白了就是说域名 raw.githubusercontent.com/ros/rosdistro/master/rosdep/sources.list.d/20-default.list 的页面找不到了。真实情况其实是这个地址的域名因为众所周知的原因被污染了，并不是页面已经下架。</p><p></p><p>我是这么处理的，在网上搜一下关键词 域名查IP 找到可以查域名对应 IP 的网站，然后根据查到的 IP 来修改 主机名静态查询表 文件。如果网站告诉你 禁止查询该域名，那就再换一个网站再查，多大点事！</p><p></p><p>我这里<a href=\"http://mip.chinaz.com/?query=raw.githubusercontent.com\">页面</a>\"返回的结果是</p><p></p><p></p><p></p><p><code lang=\"text\">sudo gedit /etc/hosts\n</code></p><p></p><p>对应上边查到的 IP 地址，把下面的内容拷贝追加到 /etc/hosts 的尾部并保存</p><p></p><p><code lang=\"text\">185.199.108.133 raw.githubusercontent.com\n185.199.111.133 raw.githubusercontent.com\n185.199.110.133 raw.githubusercontent.com\n185.199.109.133 raw.githubusercontent.com\n</code></p><p></p><p>然后，再试一次</p><p></p><p><code lang=\"text\">~$ sudo rosdep init\nWrote /etc/ros/rosdep/sources.list.d/20-default.list\nRecommended: please run\n\n  rosdep update\n</code></p><p></p><p>成功通过这一关，接着执行更新一下</p><p></p><p><code lang=\"text\">~$ rosdep update\nreading in sources list data from /etc/ros/rosdep/sources.list.d\nHit https://raw.githubusercontent.com/ros/rosdistro/master/rosdep/osx-homebrew.yaml\nERROR: error loading sources list:\n  ('The read operation timed out',)\n</code></p><p></p><p>可惜又访问失败了，这会儿报的是读操作超时。重试了好几回，没办法了，看来要动用大招~</p><p></p><p>上面说白了就是读 github 网站的资源不稳定，那么我们就找一个 github 的代理资源吧。刚好我这认识一个 https://ghproxy.com/ 支持对 github 资源代理加速，速度非常好，目前是的。</p><p></p><p></p><blockquote>下面是应用加速代理</blockquote><p></p><p></p><p>打开文件，这里注意一下 ROS Melodic 用的是 python2</p><p></p><p><code lang=\"text\">sudo gedit /usr/lib/python2.7/dist-packages/rosdep2/sources_list.py\n</code></p><p></p><p>找到函数 download_rosdep_data，把变量 url 赋值成</p><p></p><p><code lang=\"text\">url = \"https://ghproxy.com/\" + url\n</code></p><p></p><p>修改后效果</p><p></p><p><code lang=\"text\">def download_rosdep_data(url):\n    \"\"\"\n    :raises: :exc:`DownloadFailure` If data cannot be\n        retrieved (e.g. 404, bad YAML format, server down).\n    \"\"\"\n    try:\n        # http/https URLs need custom requests to specify the user-agent, since some repositories reject\n        # requests from the default user-agent.\n      url = \"https://ghproxy.com/\" + url\n        if url.startswith(\"http://\") or url.startswith(\"https://\"):\n            url_request = request.Request(url, headers={'User-Agent': 'rosdep/{version}'.format(version=__version__)})\n        else:\n            url_request = url\n        f = urlopen(url_request, timeout=DOWNLOAD_TIMEOUT)\n        text = f.read()\n        f.close()\n        data = yaml.safe_load(text)\n        if type(data) != dict:\n            raise DownloadFailure('rosdep data from [%s] is not a YAML dictionary' % (url))\n        return data\n    except (URLError, httplib.HTTPException) as e:\n        raise DownloadFailure(str(e) + ' (%s)' % url)\n    except yaml.YAMLError as e:\n        raise DownloadFailure(str(e))\n</code></p><p></p><p>打开下面的几个文件，在所有找到的 https://raw.githubusercontent.com 字符串前添加上 https://ghproxy.com/ 保存即可。</p><p></p><p><code lang=\"text\">/usr/lib/python2.7/dist-packages/rosdistro/__init__.py\n/usr/lib/python2.7/dist-packages/rosdep2/gbpdistro_support.py\n/usr/lib/python2.7/dist-packages/rosdep2/sources_list.py\n/usr/lib/python2.7/dist-packages/rosdep2/rep3.py\n/usr/lib/python2.7/dist-packages/rosdistro/manifest_provider/github.py\n</code></p><p></p><p>不过，对于文件 /usr/lib/python2.7/dist-packages/rosdep2/gbpdistro_support.py 里函数 download_gbpdistro_as_rosdep_data 的输入参数 gbpdistro_url 在应用前也需要补上加速地址</p><p></p><p><code lang=\"text\">def download_gbpdistro_as_rosdep_data(gbpdistro_url, targets_url=None):\n    \"\"\"\n    Download gbpdistro file from web and convert format to rosdep distro data.\n\n    DEPRECATED: see REP137. This function will output\n                (at least) one deprecation warning\n\n    :param gbpdistro_url: url of gbpdistro file, ``str``\n    :param target_url: override URL of platform targets file\n    :raises: :exc:`DownloadFailure`\n    :raises: :exc:`InvalidData` If targets file does not pass cursory\n     validation checks.\n    \"\"\"\n    # we can convert a gbpdistro file into rosdep data by following a\n    # couple rules\n    # will output a warning\n    targets_data = download_targets_data(targets_url=targets_url)\n    gbpdistro_url = \"https://ghproxy.com/\" + gbpdistro_url\n    try:\n        f = urlopen(gbpdistro_url, timeout=DOWNLOAD_TIMEOUT)\n        text = f.read()\n        f.close()\n        gbpdistro_data = yaml.safe_load(text)\n        # will output a warning\n        return gbprepo_to_rosdep_data(gbpdistro_data,\n                                      targets_data,\n                                      gbpdistro_url)\n    except Exception as e:\n        raise DownloadFailure('Failed to download target platform data '\n                              'for gbpdistro:\\n\\t' + str(e))\n</code></p><p></p><p>好了，大招都使完了，看看效果</p><p></p><p><code lang=\"text\">~$ rosdep update\nreading in sources list data from /etc/ros/rosdep/sources.list.d\nHit https://raw.githubusercontent.com/ros/rosdistro/master/rosdep/osx-homebrew.yaml\nHit https://raw.githubusercontent.com/ros/rosdistro/master/rosdep/base.yaml\nHit https://raw.githubusercontent.com/ros/rosdistro/master/rosdep/python.yaml\nHit https://raw.githubusercontent.com/ros/rosdistro/master/rosdep/ruby.yaml\nHit https://raw.githubusercontent.com/ros/rosdistro/master/releases/fuerte.yaml\nQuery rosdistro index https://ghproxy.com/https://raw.githubusercontent.com/ros/rosdistro/master/index-v4.yaml\nSkip end-of-life distro \"ardent\"\nSkip end-of-life distro \"bouncy\"\nSkip end-of-life distro \"crystal\"\nSkip end-of-life distro \"dashing\"\nSkip end-of-life distro \"eloquent\"\nAdd distro \"foxy\"\nAdd distro \"galactic\"\nSkip end-of-life distro \"groovy\"\nAdd distro \"humble\"\nSkip end-of-life distro \"hydro\"\nSkip end-of-life distro \"indigo\"\nSkip end-of-life distro \"jade\"\nSkip end-of-life distro \"kinetic\"\nSkip end-of-life distro \"lunar\"\nAdd distro \"melodic\"\nAdd distro \"noetic\"\nAdd distro \"rolling\"\nupdated cache in /home/if/.ros/rosdep/sources.cache\n</code></p><p></p><h2>8.测试一下环境</h2><p></p><p>分别按顺序独立在各自的终端里执行下边的这几个指令</p><p></p><p><code lang=\"text\">// 启动 ROS 核心\nroscore\n\n// 启动 ROS 仿真平台\nrosrun turtlesim turtlesim_node\n\n// 接收方向键按键信息\nrosrun turtlesim turtle_teleop_key\n</code></p><p></p><p>在最后的终端里按着键盘方向键就可以控制仿真窗口里的小乌龟动起来了</p><p></p><h2><img src=\"https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7c80fc33daf24654b7cc1e3dda0670e9~tplv-k3u1fbpfcp-watermark.image?\" /></h2><p></p><p>如果你能顺利走到这里，说明 ROS 环境可以正常跑了。</p><p></p><p>后记：其实写这篇笔记的过程中，除了首次配置环境，还穿插了很多任务，导致配置的过程一直停滞不前，笔记也落下那么久才发出来。如果你在对照这篇笔记来配置 ROS 环境的时候也碰到了其它的问题，欢迎留言提出来，或者添加我的微信公众号englyf给我留言？毕竟博客不一定一直在线。</p>",
    "publish_time": "2022-12-05 01:50:42",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "CDH+Kylin三部曲之一：准备工作",
    "url": "https://www.infoq.cn/article/4bebc83c4e3ce9908cebf041d",
    "summary": "<p></p><h3>欢迎访问我的GitHub</h3><p></p><p></p><blockquote>这里分类和汇总了欣宸的全部原创(含配套源码)：<a href=\"https://github.com/zq2599/blog_demos\">https://github.com/zq2599/blog_demos</a>\"</blockquote><p></p><p></p><p>本文是《CDH+Kylin三部曲》的第一篇，整个系列由以下三篇组成：</p><p></p><p>准备工作：搭建CDH+Kylin环境前，将所有硬件、软件资源准备好部署和设置：部署CDH和Kylin，再做相关设置Kylin实战：在搭好的环境上运行Kylin官方demo</p><p></p><p>整个三部曲的实战内容如下图所示：<img src=\"https://img-blog.csdnimg.cn/20200411114013690.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2JvbGluZ19jYXZhbHJ5,size_16,color_FFFFFF,t_70\" />接下来，就从最基本的准备工作开始吧。</p><p></p><h3>关于CDH与Kylin</h3><p></p><p>Kylin的运行需要Hadoop、Hive、HBase等服务，因此用CDH来集中部署这些应用更为方便，下图来自Kylin官方，可见是支持CDH的：<img src=\"https://img-blog.csdnimg.cn/20200411114120834.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2JvbGluZ19jYXZhbHJ5,size_16,color_FFFFFF,t_70\" />官方说支持CDH6.0版本，但实际部署中发现Kylin2.6在CDH6.0.1环境启动会有问题，经尝试发现Kylin2.6+CDH5.16可以正常运行，本次实战就用这样的版本搭配；</p><p></p><h3>部署方式</h3><p></p><p>ansible是常用的运维工具，可大幅度简化整个部署过程，接下来会使用ansible来完成部署工作，如果您对ansible还不够了解，请参考<a href=\"https://blog.csdn.net/boling_cavalry/article/details/105342744\">《ansible2.4安装和体验》</a>\"，部署操作如下图所示，在一台安装了ansible的电脑上运行脚本，由ansible远程连接到一台CentOS7.7的服务器上，完成部署工作：<img src=\"https://img-blog.csdnimg.cn/20200411114224459.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2JvbGluZ19jYXZhbHJ5,size_16,color_FFFFFF,t_70\" /></p><p></p><h3>硬件准备</h3><p></p><p>一部能运行ansible的电脑，我用的是MacBook Pro，也用CentOS验证过，都能顺利完成部署；一台CentOS7.7电脑，用于运行HDFS、Hive、HBase、Spark、Kylin等所有服务(后续文中的 CDH服务器 就是指该电脑)， 用一台机器部署所有服务仅适用于学习和开发阶段 ，实测发现，此电脑 CPU至少要双核 ，内存不低于 16G ，如果您想用多台电脑部署CDH，建议自行修改ansible脚本来分别部署，脚本地址后面会给出；</p><p></p><h3>CDH服务器设置</h3><p></p><p>需要登录CDH服务器做以下设置：检查/etc/hostname文件是否正确，如下图：<img src=\"https://img-blog.csdnimg.cn/20200411114439528.png\" />修改 /etc/hosts 文件，将自己的IP地址和hostname配置上去，如下图红框所示（ 事实证明这一步很重要 ，如果不做可能导致在部署时一直卡在\"分配\"阶段，看agent日志显示agent下载parcel的进度一直是百分之零）：<img src=\"https://img-blog.csdnimg.cn/20200411114542166.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2JvbGluZ19jYXZhbHJ5,size_16,color_FFFFFF,t_70\" /></p><p></p><h3>下载文件(ansible电脑)</h3><p></p><p>本次实战一共要准备13个文件，这里用表格列举如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d3/d3a92237ade579f24816bff60a8ba625.png\" /></p><p></p><p>下面是每个文件的下载地址：</p><p>jdk-8u191-linux-x64.tar.gz：Oracle官网可下，另外我将jdk-8u191-linux-x64.tar.gz和mysql-connector-java-5.1.34.jar一起打包上传到csdn，您可以一次性下载，地址：<a href=\"https://download.csdn.net/download/boling_cavalry/12098987\">https://download.csdn.net/download/boling_cavalry/12098987</a>\"mysql-connector-java-5.1.34.jar：maven中央仓库可下，另外我将jdk-8u191-linux-x64.tar.gz和mysql-connector-java-5.1.34.jar一起打包上传到csdn，您可以一次性下载，地址：<a href=\"https://download.csdn.net/download/boling_cavalry/12098987\">https://download.csdn.net/download/boling_cavalry/12098987</a>\"cloudera-manager-server-6.3.1-1466458.el7.x86_64.rpm：<a href=\"https://archive.cloudera.com/cm6/6.3.1/redhat7/yum/RPMS/x86_64/cloudera-manager-server-6.3.1-1466458.el7.x86_64.rpm\">https://archive.cloudera.com/cm6/6.3.1/redhat7/yum/RPMS/x86_64/cloudera-manager-server-6.3.1-1466458.el7.x86_64.rpm</a>\"cloudera-manager-daemons-6.3.1-1466458.el7.x86_64.rpm：<a href=\"https://archive.cloudera.com/cm6/6.3.1/redhat7/yum/RPMS/x86_64/cloudera-manager-daemons-6.3.1-1466458.el7.x86_64.rpm\">https://archive.cloudera.com/cm6/6.3.1/redhat7/yum/RPMS/x86_64/cloudera-manager-daemons-6.3.1-1466458.el7.x86_64.rpm</a>\"cloudera-manager-agent-6.3.1-1466458.el7.x86_64.rpm：<a href=\"https://archive.cloudera.com/cm6/6.3.1/redhat7/yum/RPMS/x86_64/cloudera-manager-agent-6.3.1-1466458.el7.x86_64.rpm\">https://archive.cloudera.com/cm6/6.3.1/redhat7/yum/RPMS/x86_64/cloudera-manager-agent-6.3.1-1466458.el7.x86_64.rpm</a>\"CDH-5.16.2-1.cdh5.16.2.p0.8-el7.parcel：<a href=\"https://archive.cloudera.com/cdh5/parcels/5.16.2/CDH-5.16.2-1.cdh5.16.2.p0.8-el7.parcel\">https://archive.cloudera.com/cdh5/parcels/5.16.2/CDH-5.16.2-1.cdh5.16.2.p0.8-el7.parcel</a>\"CDH-5.16.2-1.cdh5.16.2.p0.8-el7.parcel.sha：<a href=\"https://archive.cloudera.com/cdh5/parcels/5.16.2/CDH-5.16.2-1.cdh5.16.2.p0.8-el7.parcel.sha1\">https://archive.cloudera.com/cdh5/parcels/5.16.2/CDH-5.16.2-1.cdh5.16.2.p0.8-el7.parcel.sha1</a>\" （下载完毕后，将扩展名从.sha1为.sha）apache-kylin-2.6.4-bin-cdh57.tar.gz：<a href=\"https://archive.apache.org/dist/kylin/apache-kylin-2.6.4/apache-kylin-2.6.4-bin-cdh57.tar.gz\">https://archive.apache.org/dist/kylin/apache-kylin-2.6.4/apache-kylin-2.6.4-bin-cdh57.tar.gz</a>\"hosts、ansible.cfg、cm6-cdh5-kylin264-single-install.yml、cdh-single-start.yml、vars.yml ：这五个文件都保存在我的GitHub仓库，地址是：<a href=\"https://github.com/zq2599/blog_demos\">https://github.com/zq2599/blog_demos</a>\" ，这里面有多个文件夹，上述文件在名为 ansible-cm6-cdh5-kylin264-single 的文件夹中，如下图红框所示：</p><p></p><h3>文件摆放(ansible电脑)</h3><p></p><p>如果您已经下载好了上述13个文件，请按照如下位置摆放，这样才能顺利完成部署：</p><p></p><p>在家目录下新建名为playbooks的文件夹：mkdir ~/playbooks把这五个文件放入playbooks文件夹：hosts、ansible.cfg、cm6-cdh5-kylin264-single-install.yml、cdh-single-start.yml、vars.yml在playbooks文件夹里新建名为cdh6的子文件夹；把这八个文件放入cdh6文件夹(即剩余的八个)：jdk-8u191-linux-x64.tar.gz、mysql-connector-java-5.1.34.jar、cloudera-manager-server-6.3.1-1466458.el7.x86_64.rpm、cloudera-manager-daemons-6.3.1-1466458.el7.x86_64.rpm、cloudera-manager-agent-6.3.1-1466458.el7.x86_64.rpm、CDH-5.16.2-1.cdh5.16.2.p0.8-el7.parcel、CDH-5.16.2-1.cdh5.16.2.p0.8-el7.parcel.sha、apache-kylin-2.6.4-bin-cdh57.tar.gz摆放完毕后目录和文件情况如下图，再次提醒： 文件夹playbooks一定要放在家目录下 （即： ~/ ）：<img src=\"https://img-blog.csdnimg.cn/20200411115047864.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2JvbGluZ19jYXZhbHJ5,size_16,color_FFFFFF,t_70\" /></p><p></p><h3>ansible参数设置(ansible电脑)</h3><p></p><p>ansible参数设置的操作设置很简单：配置好CDH服务器的访问参数即可，包括IP地址、登录账号、密码等，修改 ~/playbooks/hosts 文件，内容如下所示，您需要根据自身情况修改deskmini、ansible_host、ansible_port、ansible_user、ansible_password：</p><p></p><p><code lang=\"shell\">[cdh_group]deskmini ansible_host=192.168.50.134 ansible_port=22 ansible_user=root ansible_password=888888\n</code></p><p></p><p>至此，所有准备工作已完成，下一篇文章我们将完成这些操作：</p><p></p><p>部署CDH和Kylin启动CDH设置CDH、在线安装Yarn、HDFS等调整HDFS、Yarn参数修改Spark设置(否则Kylin启动会失败)启动Kylin</p><p></p><h3>欢迎关注InfoQ：程序员欣宸</h3><p></p><p></p><blockquote><a href=\"https://www.infoq.cn/profile/42B106DFEF790F/publish\">学习路上，你不孤单，欣宸原创一路相伴...</a>\"</blockquote><p></p><p></p>",
    "publish_time": "2022-12-05 07:36:53",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "mysql优化之 performance Schema常用查询sql",
    "url": "https://www.infoq.cn/article/db032ef4cf33edab02f34aabe",
    "summary": "<p></p><p><code lang=\"sql\">use `performance_schema`\n</code></p><p></p><p>--1、哪类的 SQL 执行最多?</p><p></p><p><code lang=\"sql\">SELECT\n  DIGEST_TEXT,\n  COUNT_STAR,\n  FIRST_SEEN,\n  LAST_SEEN\nFROM\n  events_statements_summary_by_digest\nORDER BY\n  COUNT_STAR DESC\n</code></p><p></p><p>--2、哪类 SQL 的平均响应时间最多?</p><p></p><p><code lang=\"sql\">SELECT\n  DIGEST_TEXT,\n  AVG_TIMER_WAIT\nFROM\n  events_statements_summary_by_digest\nORDER BY\n  COUNT_STAR DESC\n</code></p><p></p><p>-3、哪类SQL 排序记录数最多?</p><p></p><p><code lang=\"sql\">SELECT\n  DIGEST_TEXT,\n  SUM_SORT_ROWS\nFROM\n  events_statements_summary_by_digest\nORDER BY\n  COUNT_STAR DESC\n</code></p><p></p><p>-4、哪类 SQL 扫描记录数最多?</p><p></p><p><code lang=\"sql\">SELECT\n  DIGEST_TEXT,\n  SUM_ROWS_EXAMINED\nFROM\n  events_statements_summary_by_digest\nORDER BY\n  COUNT_STAR DESC\n</code></p><p></p><p>--5、哪类 SQL 使用临时表最多?</p><p></p><p><code lang=\"sql\">SELECT\n  DIGEST_TEXT,\n  SUM_CREATED_TMP_TABLES,\n  SUM_CREATED_TMP_DISK_TABLES\nFROM\n  events_statements_summary_by_digest\nORDER BY\n  COUNT_STAR DESC\n</code></p><p></p><p>--6、哪类 SQL 返回结果集最多?</p><p></p><p><code lang=\"sql\">SELECT\n  DIGEST_TEXT,\n  SUM_ROWS_SENT\nFROM\n  events_statements_summary_by_digest\nORDER BY\n  COUNT_STAR DESC\n</code></p><p></p><p>--7、哪个表物理IO最多?</p><p></p><p><code lang=\"sql\">SELECT\n  file_name,\n  event_name,\n  SUM_NUMBER_OF_BYTES_READ,\n  SUM_NUMBER_OF_BYTES_WRITE\nFROM\n  file_summary_by_instance\nORDER BY\n  SUM_NUMBER_OF_BYTES_READ + SUM_NUMBER_OF_BYTES_WRITE DESC\n</code></p><p></p><p>--8、哪个表逻辑 IO 最多?</p><p></p><p><code lang=\"sql\">SELECT\n  object_name,\n  COUNT_READ,\n  COUNT_WRITE,\n  COUNT_FETCH,\n  SUM_TIMER_WAIT\nFROM\n  table_io_waits_summary_by_table\nORDER BY\n  sum_timer_wait DESC\n</code></p><p></p><p>--9、哪个索引访问最多?</p><p></p><p><code lang=\"sql\">SELECT\n  OBJECT_NAME,\n  INDEX_NAME,\n  COUNT_FETCH,\n  COUNT_INSERT,\n  COUNT_UPDATE,\n  COUNT_DELETE\nFROM\n  table_io_waits_summary_by_index_usage\nORDER BY\n  SUM_TIMER_WAIT DESC\n</code></p><p></p><p>--10、哪个索引从来没有用过 ?</p><p></p><p><code lang=\"sql\">SELECT\n  OBJECT_SCHEMA,\n  OBJECT_NAME,\n  INDEX_NAME\nFROM\n  table_io_waits_summary_by_index_usage\nWHERE\n  INDEX_NAME IS NOT NULL\nAND COUNT_STAR = 0\nAND OBJECT_SCHEMA &lt;&gt; 'mysql'\nORDER BY\n  OBJECT_SCHEMA,OBJECT_NAME;\n</code></p><p></p><p>--11、哪个等待事件消耗时间最多?</p><p></p><p><code lang=\"sql\">\nSELECT\n  EVENT_NAME,\n  COUNT_STAR,\n  SUM_TIMER_WAIT,\n  AVG_TIMER_WAIT\nFROM\n  events_waits_summary_global_by_event_name\nWHERE\n  event_name != 'idle'\nORDER BY\n  SUM_TIMER_WAIT DESC\n</code></p><p></p><p>--12-1、剖析某条 SQL 的执行情况，包括 statement 信息，stege 信息，wait 信息</p><p></p><p><code lang=\"sql\">SELECT\n  EVENT_ID,\n  sql_text\nFROM\n  events_statements_history\nWHERE\n  sqL_text LIKE '%count(*)%';\n</code></p><p></p><p>--12 - 2、查看每个阶段的时间消耗</p><p></p><p><code lang=\"sql\">\nSELECT\n  event_id,\n  EVENT_NAME,\n  SOURCE,\n  TIMER_END - TIMER_START\nFROM\n  events_stages_history_long\nWHERE\n  NESTING_EVENT_ID = 1553\n</code></p><p></p><p>--12 - 3、查看每个阶段的锁等待情况</p><p></p><p><code lang=\"sql\">SELECT\n  event_id,\n  event_name,\n  source,\n  timer_wait,\n  object_name,\n  index_name,\n  operation,\n  nesting_event_id\nFROM\n  events_waits_history_long\nWHERE\n  nesting_event_id = 1553\n</code></p><p></p>",
    "publish_time": "2022-12-05 00:29:04",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "2022 深圳国际金融科技大赛——西丽湖金融科技大学生挑战赛圆满收官",
    "url": "https://www.infoq.cn/article/5DkdKQyjRuC9YNTgbhm6",
    "summary": "<p>为推动深圳市金融科技产业繁荣发展，抢占金融科技发展先机，丰富金融科技人才储备以打造深圳市金融科技发展高地，深圳大学微众银行金融科技学院、微众银行、深圳香蜜湖国际金融科技研究院近期联合主办了 <a href=\"https://www.infoq.cn/article/7ejrDIB7r5KRIuLwaRPd\">2022 深圳国际金融科技大赛（FinTechathon）—— 西丽湖金融科技大学生挑战赛</a>\"（下文称“大赛”）。该大赛由深圳市地方金融监督管理局、深圳市南山区人民政府、深圳市福田区人民政府作为战略指导单位，经过初赛、决赛选拔圆满收官。</p><p>&nbsp;</p><p>自 9 月 19 日启动以来，本届大赛共有来自 364 所国内外院校的逾 1400 名学生组成 500 多支队伍报名参加，共收到超过 230 份作品。该大赛的初赛评审委员会由来自微众银行的多位技术专家组成，从区块链、人工智能、金融产品经理赛道分别选拔出了 <a href=\"https://www.infoq.cn/news/bz1qHKo6YolDdq3Wza3v\">10 组作品</a>\"进入决赛。</p><p>&nbsp;</p><p>晋级决赛的队伍历时 73 天，经历了初赛作品打磨、云上决赛 36 小时黑客马拉松、小组创意/技术讨论及云上答辩等多轮比拼。最终，在经过来自中科院、深圳大学、清华大学、北京大学、武汉大学、中山大学、西安电子科技大学、厦门大学、微众银行等单位的数十位专家组成的评审委员会多轮考核及讨论后，决出前三甲名单。以下为获奖名单及作品公示：</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/02/cf/020002c8884b51b9da3ebbf1fab9f8cf.jpg\" /></p><p>*注：获奖作品详情之后可在大赛官网<a href=\"https://www.infoq.cn/zones/fintechathon/campus2022/\">https://www.infoq.cn/zones/fintechathon/campus2022/</a>\"查看</p><p>&nbsp;</p><p>本届大赛创新人才荟萃，优秀项目云集，展现了金融科技企业卓越人才建设、金融科技技术演进的趋势方向。获奖作品分别聚焦供应链金融、工业回收、生物云、碳排放、数据权限、隐私计算等垂直领域，并提出独具价值的解决方案。</p><p>&nbsp;</p><p>据悉，获奖团队除了奖杯、实体证书，还可获得最高 10 万元的奖金（一等奖 10 万元；二等奖 8 万元；三等奖 5 万元）。此外，每位获奖选手均可获得一张面向微众银行、平安银行信用卡中心、江南银行、金证股份、安信证券、第一创业证券、德科信息、国家金融科技测评中心、华策数科、微言科技等10 余家企业的近百个实习岗位、可双向选择的面试直通卡，以及一张具有唯一标识的数字化获奖凭证“区块链数字证书”。</p><p>&nbsp;</p><p>据悉，该数字证书基于微众区块链技术，采用国产安全可控开源平台 FISCO BCOS 为底层链，上链获奖信息防篡改、可追溯、数据来源可信任。获奖选手可随时查看和下载数字证书，校方、招聘企业等也可以扫码快速验证证书真伪，达到可信验证、高效互通的效果。未来，区块链数字证书可进一步拓展到奖学金认证、技能培训认证等场景，为金融科技人才专业资格与资质提供便捷的查验与认证通道，助力构建金融科技人才培养可信体系。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/34/93/34c16cyye473f667b0d32c8166ca6393.jpg\" /></p><p>*图：区块链证书示例，微众区块链、深圳大学微众金融科技实验室、深圳市金融区块链发展促进会（金链盟）提供技术支持。</p><p>&nbsp;</p><p>作为<a href=\"https://www.infoq.cn/article/2HNNAjCIPfprkaqd43vw\">深圳国际金融科技节</a>\"的一环，本届大赛为高校学子和企业搭建了交流的桥梁，营造了守正创新、合作共赢、共同推动金融科技产业高质量发展的良好氛围，为深圳市金融科技发展注入活力源泉。&nbsp;</p>",
    "publish_time": "2022-12-05 17:43:05",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "对话Spring大神：Spring 生态系统的新时代来了！",
    "url": "https://www.infoq.cn/article/ATGFHsJa5HqNroEuNBLd",
    "summary": "<p>VMware发布了Spring Framework 6和Spring Boot 3。在Spring Framework 5发布5年之后，这些新版本开启了Spring生态系统的新时代。Spring Framework 6需要Java 17和Jakarta EE 9，并与<a href=\"https://www.infoq.com/news/2022/09/jakarta-ee-10-updates/\">最近发布</a>\"的Jakarta EE 10兼容。它还通过带有跟踪和指标功能的Micrometer内嵌了可观察性。Spring Boot 3需要Spring Framework 6，内置支持使用GraalVM原生镜像的静态预先编译（AOT）构建原生可执行文件。关于这两个新版本框架的更多细节可以在InfoQ的这个<a href=\"https://www.infoq.com/news/2022/11/spring-6-spring-boot-3-launch/\">报道</a>\"中找到。</p><p>&nbsp;</p><p>InfoQ就这两个新版本的框架采访了Java Champion、VMware的Spring开发者布道师<a href=\"https://www.infoq.com/profile/Josh-Long/\">Josh Long</a>\"。VMware的Spring Framework项目负责人<a href=\"https://www.linkedin.com/in/juergenhoeller\">Juergen Hoeller</a>\"也回答了其中一个问题。</p><p>&nbsp;</p><p>InfoQ：作为一名Spring开发者布道师，你会发表演讲、编写代码、发表文章和书籍，并运营着一个播客。那么你的一天是怎么过的？</p><p>&nbsp;</p><p></p><blockquote>Josh Long：这很难说！我的工作需要我和各种各样的人交流，面对面或通过网络，所以我永远不知道我会在哪里，也不知道我会专注在什么事情上。不过通常来说，我的目标是推动生态系统的发展。也就是说，我要了解他们的应用场景，并推动他们找到问题的解决方案。如果说这需要我和Spring团队交流或贡献代码，我很乐意这么做。如果说需要我发表演讲、录制播客、写一些文章或一本书或制作视频，我也会去做。</blockquote><p></p><p>&nbsp;</p><p>InfoQ：VMware从许多来源获得关于Spring的反馈：会议、用户组、问题跟踪器、Stack Overflow、Slack、Reddit、Twitter等等。但满意度高的用户通常不会说什么，而抱怨声最大的人可能反应不了本质的问题。那么，VMware是如何收集用户反馈和给它们安排优先级的呢？</p><p>&nbsp;</p><p></p><blockquote>Long：这是一个非常好的问题：所有的东西最终都会落到GitHub上。我们特别关注StackOverflow标签，并尽最大努力对它们做出响应。但如果在那里发现了bug，最终会落到GitHub上。GitHub是参与这个项目的一个很好的方式。我们试着让它变得简单，比如为那些想要参与贡献的新人创建标签，让他们从可以接受我们指导的地方开始。当然，GitHub不是一个进行问答的好地方——所以我们使用Stackoverflow。我们非常依赖GitHub，以至于即使在团队内部，我们也会向自己的项目发送拉取请求并使用这个工作流。</blockquote><p></p><p>&nbsp;</p><p>InfoQ：Spring下有很多项目。VMware必须让Spring用户了解所有相关的东西。VMware如何知道Spring用户不了解哪些东西，从而可以教会他们？</p><p>&nbsp;</p><p></p><blockquote>Long：简单地说，我们不知道，不过我们可以猜测。我们花了很多精力开发新的、新颖的、最新的和最好的项目，也在不断更新基础的东西。你不会相信我为一些项目重做了多少次“开始的第一步”之类的东西。我们也非常清楚，登陆我们门户网站的人可能是长期用户，但通过其他方式找到Spring的人对Spring可能了解甚微。所以我们要不断推出“开始的第一步”的介绍性内容。有时候“开始的第一步”变化得足够多，以至于最基础的东西也变得很新颖。</blockquote><p></p><p>&nbsp;</p><p>InfoQ：Java遗留应用程序通常使用较老版本的Java和框架。微服务架构让开发人员可以以较低的风险引入新的技术栈。你是否认为这是Java展示新特性和新版本的好机会？或者这更像是一种对Java的威胁，因为开发人员可以尝试Java的竞争对手，如.NET、Go、JavaScript或Python？</p><p>&nbsp;</p><p></p><blockquote>Long：威胁？恰恰相反——如果在其他编程语言看来，Java表现得很差，那么最好将其暴露出来，这样可以推动Java向前发展。而且，老实说，Java不可能在所有方面都是最好的。微服务意味着我们可以在有意义的场景中使用Spring和Java，不会有Java和Spring不能提供最好的解决方案时就会陷入困境的感觉。不要问我是什么样的场景，因为我真的不知道……</blockquote><p></p><p>&nbsp;</p><p>InfoQ：Spring 5增加了对Kotlin的显式支持。你估计现在有多少百分比的Spring开发使用的是Kotlin？</p><p>&nbsp;</p><p></p><blockquote>Long：我不知道，但Kotlin是Spring Initializer上被使用第二多的语言。</blockquote><p></p><p>&nbsp;</p><p>InfoQ：Scala从来没有获得Spring这种显式的支持。你认为这是为什么？</p><p>&nbsp;</p><p></p><blockquote>Long：有的！<a href=\"https://spring.io/blog/2012/12/10/introducing-spring-scala\">早在2012年</a>\"，我们就有一个叫作Spring Scala的项目。我们真的希望它能成功。在我们发布Spring Scala之前，我们甚至有一个Scala的Spring Integration DSL。我们尝试过了，但似乎没有一个社区希望它能成功。这是一个遗憾。如今，随着反应式和函数式编程的日益崛起，我觉得Java和Scala社区之间的共性变得比以往任何时候都要大。</blockquote><p></p><p>&nbsp;</p><p>InfoQ：Spring 5也加入了反应式应用程序。现在你是反应式应用程序的支持者，甚至还为此写了一本书。是什么让反应式应用程序对你如此有这么大的吸引力？</p><p>&nbsp;</p><p></p><blockquote>Long：我喜欢反应式编程。它为我们带来了三个显著的好处：&nbsp;1. 一种用来表达系统状态转移的DSL——通过回压、超时、重试等机制来健壮地解决系统的脆弱性问题。这种简洁的DSL简化了构建系统的过程，你最终得到的是一个为所有场景提供的抽象。2. 一种用来编写多线程并发代码的DSL——没有那么多困扰并发代码的线程和状态管理逻辑。3. 能够优雅地编写让运行时更好地伸缩线程（即每秒处理更多请求）的代码。</blockquote><p></p><p>&nbsp;</p><p>InfoQ：反应式开发最适合解决哪些问题或最适合用于构建哪种应用程序？</p><p>&nbsp;</p><p></p><blockquote>Long：如果反应式抽象适合你的领域，并且你想学习一些新东西，那么反应式编程就可以用于所有的工作负载。编写更可伸缩、更安全（更健壮）和更一致的代码有什么不好的呢？</blockquote><p></p><p>&nbsp;</p><p>InfoQ：哪些场景不适合使用反应式开发？</p><p>&nbsp;</p><p></p><blockquote>Long：反应式开发要求代码的编写范式做出一些改变。它不像Loom项目，一个开关就可以让你获得可伸缩性方面的一些好处。如果你对学习这种新范式不感兴趣，也不需要反应式编程所能带来的好处，那么它对你来说就没有任何意义。</blockquote><p></p><p>&nbsp;</p><p>InfoQ：人们对反应式开发常见的抱怨是认知负荷的增加和调试难度的增加。他们抱怨的这些问题在Spring Framework 6和Spring Boot 3中也会有吗？</p><p>&nbsp;</p><p></p><blockquote>Long：我不知道我们是否在Spring Boot 3中直接解决了这些问题。不过，通常的机制仍然有效！用户可以在反应式管道的各个部分设置断点。他们可以使用Reactor Tools从管道中的所有线程捕获堆栈跟踪信息。他们可以使用.log()和.tap()操作符来获取流经管道的数据的信息，等等。Spring Boot 3有一个显著的改进——Spring现在支持通过Micrometer Metrics和Micrometer Tracing捕获指标和跟踪信息。Reactor甚至提供了对反应式管道中Micrometer Observation抽象的支持。</blockquote><p></p><p>&nbsp;</p><p>InfoQ：工具支持（例如IDE和构建工具）对于框架的成功来说有多重要？至少，有经验的用户通常会绕过向导和实用工具，直接修改配置文件和代码。</p><p>&nbsp;</p><p></p><blockquote>Long：这个问题很有意思。我已经非常努力地证明，工具对于Spring Boot开发人员的体验来说并不是非常重要的。事实上，自从Spring Boot发布以来，已经可以支持使用任意的Java IDE开发新的应用程序。你不需要IntelliJ IDEA终极版、对Spring XML名称空间的支持，甚至不需要Eclipse中的Java EE和WTP支持来Spring Boot。如果你的工具支持public static void main、Apache Maven或Gradle，以及所需的Java版本，就万事大吉了！&nbsp;Spring Boot可能在某些地方会从工具中获得好处，比如application.properties和application.yaml。但即使在这里，你也不一定需要工具——Spring Boot的Spring Boot Actuator模块可以为你提供这些文件中定义的所有属性。&nbsp;也就是说，即使你需要亲自编辑所有的东西，你也不会感到麻烦。好的工具会给人一种整个按键都摆在你前面的感觉。谁不喜欢这样呢？为了达到这个目的，我们做了很多工作，尽可能提升Eclipse和VS Code（以及扩展到大多数支持Eclipse Java Language Server的工具）的开发者体验。&nbsp;我认为，好的工具对于迁移已有代码来说会更加重要。新的Jakarta EE API就是一个很好的例子。Jakarta EE取代了Java EE——javax.*下所有的类型都迁移到jakarta.*下。Eclipse基金会的工作人员已经付出了巨大的努力，让熟悉这些新类型的过程变得尽可能简单，但仍有很多工作需要完成。我想，你所选择的IDE也将使这些变得更容易些。</blockquote><p></p><p>&nbsp;</p><p>InfoQ：自2010年以来，这是第一次Spring Framework的更新不是在上一次重大发布一年之后，而是两年之后（5.3版本在2020年发布）。因此，Spring Framework 6似乎有两年的开发时间而不是一年。是什么导致花了这么长时间？</p><p>&nbsp;</p><p></p><blockquote>Long：我甚至没有注意到这个！老实说，我感觉SpringFramework 6已经开发了两年多了。这个版本令人感到难以置信的忙乱！迁移到Java17很容易，但迁移到JakartaEE对我们来说是一个挑战。首先，我们必须清理所有受支持的Spring Boot库中的依赖项。然后，我们一个接一个地处理所有的库，直到一切都变为绿色。这是一项艰苦而缓慢的工作，我很高兴已经完成了。但是，这些工作对于使用Spring Boot的开发人员来说可能是微不足道的。&nbsp;我们也做了大量有关可观测性的工作，要点是Micrometer现在支持跟踪，并且跟踪和指标都有一个统一的抽象，即Observation。现在我们来了解一些背景故事。在Spring Boot 2.x中，我们引入了Micrometer来捕获指标并将其保存到各种时间序列数据库中，如Netflix Atlas、Prometheus等。Spring Framework依赖Micrometer，Spring Boot依赖Spring Framework，Spring Cloud依赖Spring Boot，支持分布式跟踪的Spring Cloud Sleuth依赖Spring Cloud。因此，指标位于抽象栈的最底层，分布式跟踪位于最顶层。&nbsp;这样的抽象栈在很大程度上是没有问题的，但这意味着我们有两种不同的指标和跟踪抽象。这也意味着，如果不引入循环依赖关系，Spring Framework和Spring Boot就不能支持分布式跟踪。Spring Boot 3中的变化——Spring Framework依赖Micrometer，Micrometer通过一个简单、统一的抽象支持跟踪和指标。&nbsp;最后，使用GraalVM Native Image进行提前（AOT）编译的工作在Spring Framework 6（2022年11月15日发布）中正式落地。从2019年起，这项工作就已经在以某种形式进行中。最先是一个叫作Spring Native的实验性研究项目，我们在这个项目中验证了Spring Boot 2.x和Spring Framework 5.x的各项功能。这些工作成果已包含在Spring Framework 6和Spring Boot 3中。</blockquote><p></p><p>&nbsp;</p><p>InfoQ：正如去年宣布的那样，Spring Framework 6.0和6.1的免费支持时间将<a href=\"https://spring.io/projects/spring-framework#support\">更短</a>\"。与Spring 5.2的27个月相比，两者都下降了20%（降至21.5个月）。相比之下，Spring Boot 3.0的免费支持期限仍然为一年。这是为什么？</p><p>&nbsp;</p><p></p><blockquote>Long：我们在2021年底对计算方式进行了标准化。我们一直为开源版本提供12个月的免费支持。每个项目都可以根据发布周期和社区需求进行扩展，但所有项目至少需要12个月的开源支持和额外的12个月商业支持。对于我们来说，在主要版本中进一步扩展对最后一个次要版本的支持是正常的（就像我们在SpringFramework5.3.x中所做的那样）。&nbsp;需要注意的是，支持时间的标准化发生在2021年底。自那时以来，我们没有发布过任何主要或次要的Spring Framework版本。Spring Framework 6将是新标准下的第一个。&nbsp;Juergen Hoeller：Spring Framework 6.0和6.1的商业支持时间也更短。我们没有为了商业支持而缩短了开源版本的支持时间。更确切地说，所有的时间都变短了——人们希望更快地升级到最新的6.x版本，就像他们近来更快地升级JDK一样。从这方面来说，Spring Framework 5.x仍然紧密配合JDK8的使用风格——“你可以停留在你的JDK级别和JavaEE级别上”。Spring Framework 6.x旨在尽可能紧跟JDK 17+和Jakarta EE 9+（两者都比以前更频繁地发布），并相应地调整发布理念。</blockquote><p></p><p>&nbsp;</p><p>InfoQ：Spring Boot 3支持GraalVM Native Image的AOT编译器。这样可以获得启动速度更快、使用更少内存、容器镜像更小且更安全的原生Java应用程序。这在云计算的哪些领域会让Java与Go等竞争对手处于更平等的地位？</p><p>&nbsp;</p><p></p><blockquote>Long：我不知道我是否应该将Java与Go放在一起讨论。无论Go表现得怎么样，Java都不是最节省内存的编程语言。这导致Java错过了一些机会，如物联网和无服务器。使用GraalVM Native Image进行AOT编译可以保持Java引以为傲的可伸缩性和生产力。</blockquote><p></p><p>&nbsp;</p><p>InfoQ：原生Java在云计算的哪些领域不会起到很大作用？</p><p>&nbsp;</p><p></p><blockquote>Long：我不知道。我感觉GraalVM Native Image可能是JRE的替代品。事实上，GraalVM也打开了新的大门。开发人员现在可以使用Spring Boot编写自定义Kubernetes控制器。你也可以编写特定于操作系统的客户端二进制文件，如CLI（hello，Spring Shell！）。</blockquote><p></p><p>&nbsp;</p><p>InfoQ：原生Java的缺点是构建管道更慢、更复杂、工具支持更少、可观察性降低。构建管道的缺点似乎不可避免——AOT编译需要更长的时间，不同的操作系统需要不同的可执行文件。但是，你认为从中期来看，与动态Java相比，原生Java的工具支持和可观察性会是怎样的？</p><p>&nbsp;</p><p></p><blockquote>Long：IntelliJ已经为调试GraalVM原生镜像提供了极好的支持。我不认为大多数人会为失去Java引以为傲的可移植性而感到悲哀。毕竟，大多数应用程序都在Linux主机上的Linux操作系统上的Linux容器中运行。有一个很棒的GitHub Action，你可以用它来进行交叉编译，构建过程可以在多个操作系统上运行，并生成特定于这些操作系统的可执行文件。你可以使用Buildpacks（Spring Boot可与之集成，例如：mvn -Pnative spring-boot:build-image）等工具在macOS或Windows主机上构建和运行容器镜像。GraalVM的可观测性支持受到了一些影响，因为Java代理不能很好地在原生可执行文件中运行。但是，前面提到的Micrometer支持可以避开许多限制，并产生更详尽的结果。</blockquote><p></p><p>&nbsp;</p><p>InfoQ：说到可观测性，这是Spring 6的另一个主要功能。它包含了日志记录、指标和跟踪，并是基于Micrometer的。Java已经有许多可观测性选项，为什么要在Spring中再加入一个？而且为什么是现在呢？</p><p>&nbsp;</p><p></p><blockquote>Long：Java并没有像Micrometer那样做了那么多的事情。我们并不是加入了另一个——我们是在增强一个现有的。Micrometer已成为事实上的标准。许多其他的库已经将其集成到表面指标中：RabbitMQ Java客户端Vert.x?HibernateHikariCPApache CamelReactorRSocketR2DBCDS-ProxyOpenFeignDubboSkywalkingResilience4J（进行中）Neo4J</blockquote><p></p><p>&nbsp;</p><p>InfoQ：除了直接读取数据文件之外，该如何查看和分析Spring 6和Spring Boot 3的可观测性数据？</p><p>&nbsp;</p><p></p><blockquote>Long：Micrometer提供了一系列与Graphite、Prometheus、Netflix Atlas、InfluxDB、Datadog等指标工具集成的能力。它可以与OpenZipkin等分布式跟踪工具一起使用。它还与OpenTelemetry（“OTel”）集成，因此你可以与OTel服务通信。</blockquote><p></p><p>&nbsp;</p><p>InfoQ：Spring Boot 3在发布时并<a href=\"https://www.infoq.com/news/2022/10/spring-boot-3-jax-london\">不会为所有的项目和库提供全面的原生Java和可观测性支持</a>\"。那么我如何知道我的Spring Boot 3应用程序是否可以支持原生Java并提供完整的可观察性数据？</p><p>&nbsp;</p><p></p><blockquote>Long：这只是一个更长、更大的旅程的开始。与GraalVM Native Image配合的东西几乎每天都在增加。虽然没有明确的清单，但你应该知道，所有主要的Spring项目都在提供支持。这是我们的首要任务。可以看一下我们的<a href=\"https://github.com/spring-projects/spring-aot-smoke-tests\">Spring AOT冒烟测试</a>\"，看看哪些核心项目已经经过了验证。</blockquote><p></p><p>&nbsp;</p><p>InfoQ：Java即将推出的哪项功能最令你感到兴奋？</p><p>&nbsp;</p><p></p><blockquote>Long：我对即将到来的三个项目感到非常兴奋：Loom项目、Leyden项目和Panama项目。Loom项目为JVM带来了<a href=\"https://www.infoq.com/articles/java-virtual-threads\">轻量级绿色线程</a>\"，并承诺提升可伸缩性。<a href=\"https://www.infoq.com/news/2022/06/project-leyden-delays-aot\">Leyden项目</a>\"似乎将为应用程序开发人员提供更多的参数来约束和优化他们的JVM应用程序。其中一个更引人注目的限制似乎是GraalVM原生镜像。Panama项目希望最终能让对外函数的访问像Python、Ruby、PHP、.NET等语言一样轻松。这三个方面的努力将推动Java进入新的领域。</blockquote><p></p><p>&nbsp;</p><p>InfoQ：如果你能对Java做出一个改变，你希望是什么？</p><p>&nbsp;</p><p></p><blockquote>Long：结构化的lambda！我想要真正的lambda。目前，lambda差不多就是一种单一抽象方法接口的语法糖，所有的lambda都必须遵循单一抽象方法（SAM）接口，如java.util.function.Function<i>。这在Java加入我喜欢的var关键字之前都还好，但现在从美学上看它有点令人感到不快，因为需要告诉编译器给定的lambda遵循的是哪个接口。&nbsp;下面是Kotlin的一些代码：</blockquote><p></p><p></p><p><code lang=\"kotlin\">val name = \"Karen\" // 一个常规的String类型变量\n\nval myLambda: (String) -&gt; Int = { name -&gt; name.length } // 一个以字符串为参数并返回整数的lambda</code></p><p>&nbsp;</p><p></p><blockquote>下面是Java的等效代码：</blockquote><p></p><p></p><p><code lang=\"java\">var name = \"Karen\";\n\nvar myLambda = new Function() {\n\n&nbsp; @Override\n\n&nbsp; public Integer apply(String s) {\n\n&nbsp; &nbsp; return s.length();\n\n&nbsp; }\n\n};</code></p><p></p><p></p><blockquote>有几种方法可以解决这个问题：&nbsp;</blockquote><p></p><p><code lang=\"java\">var name = \"Karen\";\n\nFunction myLambda = s -&gt; s.length();&nbsp;</code></p><p>&nbsp;</p><p></p><blockquote>这就是我所说的美学上令人感到不快：要么不能两行都以var开头，要么放弃lambda的简洁性。&nbsp;这个问题可能会得到解决吗？可能不会。这是一个严重的问题吗？当然不是。总的来说，Java是一种奇妙的语言。大多数语言都应该很幸运，因为它们也已经到了Java的年纪，但没有像它那样奇怪的语法！</blockquote><p></p><p>&nbsp;</p><p>InfoQ：你希望Spring或Spring Boot做出一个什么样的改变？</p><p>&nbsp;</p><p></p><blockquote>Long：这很难说！我希望我们能够恢复并更新Spring Rich（一个早已失效的框架），用于构建桌面Swing驱动的客户端应用程序。目前Griffon是唯一能解决这个问题的框架。很遗憾，因为Spring本可以在这面做得很棒，特别是现在它已经深度集成了GraalVM Native Image支持。当然，这可能也只是一个利基的应用场景。</blockquote><p></p><p>&nbsp;</p><p>嘉宾简介：</p><p>&nbsp;</p><p>Josh Long（推特账号@starbuxman）是2010年以来的第一位Spring开发者布道师。Josh是Java Champion，著有6本书（包括O’Reilly的《云原生Java：使用Spring Boot、Spring Cloud和Cloud Foundry设计弹性系统》和《Reactive Spring》），录制过众多很受欢迎的培训视频（包括与Spring Boot联合创始人Phil Webb合作的《使用Spring Boot构建微服务》），他还是一名开源贡献者（Spring Boot、Spring Integration、Spring Cloud、Activiti和Vaadin等）、一位播客和YouTube博主。</p><p>&nbsp;</p><p>Karsten Silz 在欧洲和美国做了23年的全栈Java开发者（Spring Boot、Angular、Flutter）。2004年，他在美国联合创办了一家软件产品初创公司。Karsten领导了13年的产品开发，并在公司成功销售后离开。自2003年以来，他一直担任承包商。2020年，他作为首席技术官在英国联合创办了SaaS初创企业“Your Home in Good Hands”。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/josh-long-spring-6/\">https://www.infoq.com/articles/josh-long-spring-6/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/8XzPjAwr5e6bMs3HjX9K\">Java近期新闻：Spring Framework 6、JCP选举、Valhalla项目、OpenJDK更新</a>\"</p><p><a href=\"https://www.infoq.cn/article/5VMP2p3hLyEKpYIILxLr\">Spring Boot 3将于2022年11月发布，延迟了对Java模块系统的支持</a>\"</p><p><a href=\"https://www.infoq.cn/article/M8Tcely7QZhZYx4od2t1\">Spring Boot Migrator简介</a>\"</p>",
    "publish_time": "2022-12-05 18:38:26",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "我们从Vue到Alpine.js的旅程",
    "url": "https://www.infoq.cn/article/UW1D6tvPXeqw1eke9S7a",
    "summary": "<p></p><h2>问题</h2><p></p><p></p><p>在 2019 年底，我们为一位客户重发布了电子商务网站。这次重新发布的变动很大，不仅影响了整体设计和模板，还涉及了前端的架构。唯一没什么改动的就是后端。</p><p></p><p>客户的主要需求是：</p><p></p><p>优化 PageSpeed 指标提高可用性，从而提高转化率</p><p></p><p>在数月的实施之后，客户和我们都对最终成果感到满意。我们在 Lighthouse 的全部四个类别中都达到了绿色评级，转化率也有了显著的提升。直到谷歌在 Lighthouse 6.0 更新中更改了性能评分的计算模式，让我们的评分从绿色降级为红色。</p><p></p><p>顺带一提，Lighthouse 在新标准中将重点转移到了前端内容上，在首字节时间（TTFB）以及如文件大小、CSS 优化、网页字体等会对总体网页性能有影响的内容之外，还囊括了“可交互时间（TTI）”以及“最大内容绘制（LCP）”指标。随着网页可交互性越来越强，其对性能的感知也越发重要。理论上来说，我们是支持谷歌将这些新指标纳入评分标准的，尽管谷歌在展示“优秀范例”时用的是几乎没有任何交互性的博客站点，这完全是在拿苹果和橘子在作比较。</p><p></p><p>在与客户的一次会议后，我们延后了针对 Lighthouse 新指标的优化工作。在分析了网站访客的常用设备后，我们很难再说服自己将大量时间花费在我们和所有竞争对手都要面临的问题上。</p><p></p><p>然而，随着在 2020 年底、2021 年初谷歌公布部分新指标将对搜索结果排名有影响后（是时候将页面体验引入谷歌搜索了），显然我们并不能再继续将这个问题推延了。在与客户的又一次商讨后，我们确定了我们所能提供显著竞争优势，并让最终用户感受到速度的提升。</p><p></p><p></p><h2>分析过程</h2><p></p><p></p><p>我们需要更多的数据。坦白来说，在这之前我们从来没怎么重视过更深层次的性能指标，而现在我们要开始赶进度了。我们通过谷歌 Chrome 浏览器和其内置的 Lighthouse 应用，外加开发者工具中的性能标签，三管齐下分析网站性能。</p><p></p><p></p><h2>我们当前的设置</h2><p></p><p></p><p>在重发布后，我们将前端架构完全推翻重写，用 Vue 2 作为 JavaScript 框架，TailwindCSS 为 CSS 框架。所有内容都由 Symfony Encore（Webpack）进行打包。</p><p></p><p>我们的站点没有用 SPA，而是将根实例捆绑到一个 div 元素 #app 上。借助无渲染组件（Vue.js 中的无渲染组件）让我们可以使用服务器端变量或是用 Twig 轻松编写大部分模板，而不需要编写任何 API。</p><p></p><p><code lang=\"html\">\n  </code></p><div><code lang=\"html\">\n    <button>Toggle</button>\n  </code></div><code lang=\"html\">\n\n</code><p></p><p></p><p></p><blockquote>product_id是服务器端变量，is_stared(product_id)是Twig函数，二者都是作为props传入Vue组件的。</blockquote><p></p><p></p><p></p><h2>问题分析</h2><p></p><p></p><p>目前我们的流程大致是这样子的：</p><p></p><p>在 chrome 里生成性能报告研究报告结果改点东西重新生成新报告以确定或者推翻我们假设</p><p></p><p>性能报告中最有用的部分是“评估脚本”，似乎浏览器在评估我们 JavaScript 包的时候要做不少事。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/12/1230d894e10f2961c88d4ee90094649d.png\" /></p><p></p><p></p><h5>生产环境</h5><p></p><p></p><p>我们的第一步是注释掉脚本标签，看看对指标会有什么影响。结果发现，效果相当显著。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5d/5da5199fc91114a321dc22f15057200e.png\" /></p><p></p><p>注：这份报告是我们在开发环境中生成的，与实际生产环境大约有 10%-15% 的差异。</p><p></p><p></p><h2>需要做什么</h2><p></p><p></p><p>我们确定了以下几点亟需关注：</p><p></p><p>优化关键资源的预加载最大限度地缩减阻断时间优化交互时间最大限度地减少主线程工作</p><p></p><p></p><h4>Part 1：优化预加载</h4><p></p><p></p><p>为追求简单快速简单的部署，我们没有对谷歌标签管理和我们的 CCM 进行完善的性能测试，这也导致了一些渲染阻塞。我们测试了预加载和预连接的各种不同组合，并最终得出了以下结果：</p><p></p><p>预加载关键资源，如 CCM 脚本预连接 GTM预加载我们自己的关键资源，如网页字体或我们自己的主要 css、js 文件</p><p></p><p>这些是我们用到的工具：</p><p></p><p>Lighthouse：直观展示哪些资源应该被预加载Firefox：通过开发者工具可以找到被预加载，但在最初几秒内未被使用的字体</p><p></p><p></p><h4>Part 2-4：优化其余部分</h4><p></p><p></p><p>在优化预加载后，剩下可能对我们关键指标有影响的就只有我们 JavaScript 包中自己的资源了，其余指标也都或多或少跟这些资源挂钩。</p><p></p><p></p><h3>找到问题</h3><p></p><p></p><p>在开始优化之前，我们需要先从更深层次分析问题。如前文所述，我们对所有的 Vue 组件都应用了无渲染组件，并用 Vue 实例打包了整个网站。这种方式让我们可以很方便地进行全局状态管理，我们还可以通过添加额外的混合器来为网站增加交互性，比如：</p><p></p><p><code lang=\"kotlin\">export const searchOverlay = {\n  data() {\n    return {\n      showSearchOverlay: false,\n    }\n  },\n}\n</code></p><p></p><p>全局状态示例 / 混合器提供功能性</p><p></p><p></p><h3>Vue 的不同版本</h3><p></p><p></p><p>Vue 有两个不同的版本：运行时构建，以及包含模板编译器的版本。运行时构建的文件大小相比来说要小很多，但只能用于单一文件的组件，因为这类组件会被包含在捆绑包中，因此不需要模板编译器。另一方面，模板编译器让我们可以从模板引擎（Twig）中生成模板，并插入到无渲染组件的默认槽中。</p><p></p><p>另外，由于我们需要将网站整体打包，Vue 需要对所有可见的 DOM 节点进行评估，而光是在主页上就有大约 4500 个节点。这也是为什么我们的脚本评估时间会是如此的长。</p><p></p><p>既然对根因有了更好的理解，我们可以开始着手评估问题缓解的方法了。</p><p></p><p>很可惜我们最终并没有找到能显著提升当前架构性能的方法，我们的模板架构和后端结构并不允许我们优雅地切换到运行时构建。</p><p></p><p></p><h3>评估需求</h3><p></p><p></p><p>下一步，我们开始整理当前网页上所提供的组件和交互功能，以从我们全新的解决方案中获得新的视角。</p><p></p><p>这些是我们目前已有组件的例子：</p><p></p><p>实时搜索动态侧边栏导航弹出框菜单模态框</p><p></p><p>我们还有一些之前由混合器提供的小型函数。这些函数因为没有状态且可以简单直接地在任何地方触发，主要用于不需要单独组件即可实现的功能，如：</p><p></p><p>动态更新产品类别打开发货模式展示或隐藏全局信息轮播图</p><p></p><p>这些功能都有一个共同点：需要组件间的交流。这些组件都不算复杂，主要用于提供互动性或防止网页重新加载。</p><p></p><p>我们希望且需要从新框架中获得的有：</p><p></p><p>反应性，在数据发生变化后模板会重新渲染事件系统以方便组件间交流占用空间小</p><p></p><p></p><h3>引入 Alpine.js</h3><p></p><p></p><p>我们曾在其他项目中用 Alpine.js 来提供交互性，最终效果也很好。既然我们已经在项目中使用 TailwindCSS 了，Alpine.js 所声称的“类似 JavaScript 中的 TailwindCSS”说法很得我们心。我们并不确定 Alpine.js 是否能胜任如此大型的电子商务站点，因此我们需要建立一个概念验证，以测试它是否最难处理的部分。我们重新构建了如滑动导航、动态购物车以及主菜单等包含前文所提到需求的重要组件，如果我们能重新整合这些组件，那我们可以肯定地认为其他组件都没问题。在经过了大约一天左右的工作，我们收获了满意的成果。虽然重构过程并不是一帆风顺，但既然我们的大部分逻辑都是用 JavaScript 写的，从 Vue 到 Alpine.js 的转换都是很直接的。我们最终确定了以下的架构形式：</p><p></p><p><code lang=\"typescript\">js/\n├── components/\n│   ├── cart.js\n│   ├── mobileMenu.js\n│   └── ...\n├── enums/\n│   ├── events.js\n│   └── ...\n├── helper/\n│   └── customEvent.js\n├── providers/\n│   ├── cart.js\n│   ├── googleTagManager.js\n│   └── ...\n└── stores/\n    ├── cart.js\n    ├── global.js\n    └── ...\n</code></p><p></p><p></p><h5>组件</h5><p></p><p></p><p>组件是以窗口范围的函数所定义的，可以返回用于在 Alpines 的 x-data 属性中用于初始化组件的对象。</p><p></p><p>下面是一个简化的模态组件示例，请注意我们是怎么使用 customEvent 函数和“枚举（enums ）”的。</p><p></p><p><code lang=\"kotlin\">import customEvent from '@/helper/customEvent'\nimport { MODAL_OPEN, MODAL_OPENED, MODAL_CLOSE } from '@/enums/events'\n\nwindow.modal = () =&gt; ({\n  open: false,\n  init() {\n    if (this.instantDisplay !== undefined) {\n      this.open = true\n    }\n  },\n  close() {\n    this.open = false\n    customEvent(MODAL_CLOSE, this.name)\n  },\n  wrapper: {\n    async [`@${MODAL_OPEN}.window`](e) {\n      if (modalToOpen !== e.payload.name) {\n        return\n      }\n\n      customEvent(MODAL_OPENED, this.name)\n      this.open = true\n    },\n  },\n})\n</code></p><p></p><p></p><h5>enum</h5><p></p><p></p><p>并不是指实际意义上的枚举，只是个用来保存常量的辅助文件，方便我们在整体代码库中使用这些常量，而不用担心事件在重命名时会连锁搞崩掉别的东西。</p><p></p><p><code lang=\"javascript\">const MODAL_OPEN = 'modal-open'\nconst MODAL_OPENED = 'modal-opened'\nconst MODAL_CLOSE = 'modal-close'\n</code></p><p></p><p></p><h5>helper</h5><p></p><p></p><p>我们可以在任何地方导入 helper 函数且不会保留任何状态。这个是我们的 customEvent helper 函数：</p><p></p><p><code lang=\"typescript\">export default function (name, payload = null, originalEvent = null) {\n  // 入参对象应包含以下：\n  // name: 'string',\n  // payload: 'object'\n  // originalEvent: 'this'，或者其他你需要点击的目标\n\n  const customEvent = new CustomEvent(name, {\n    detail: {\n      payload: payload,\n      originalEvent: originalEvent,\n    },\n  })\n\n  window.dispatchEvent(customEvent)\n}\n</code></p><p></p><p>这个简单的 helper 给我们带来极大的灵活性，让我们摆脱了定义无数个 Alpine 组件的烦恼，在包括 HTML 中等任何地方直接调用。其本质也不过是标准 CustomEvent API 的一部分，改造成可在窗口范围内使用的函数且能接收 onclick 属性入参。</p><p></p><p><code lang=\"html\"><button type=\"button\"></button>\n</code></p><p></p><p></p><h5>内容提供器</h5><p></p><p></p><p>内容提供器通过可复用功能提供数据，可以把它看作是客户端的 API 层。和 helper 函数一样，这些函数不应包含任何状态，且可被组件消耗的。</p><p></p><p>下面是实时搜索的内容提供器大致代码：</p><p></p><p><code lang=\"javascript\">import customEvent from '@/helper/customEvent'\nimport { SEARCH_GET } from '@/enums/events'\n\nasync function getResultFor(searchTerm) {\n  let result = undefined\n\n  await fetch(`/search?q=${searchTerm}`)\n    .then((response) =&gt; response.json())\n    .then((data) =&gt; {\n      result = data\n    })\n\n  customEvent(SEARCH_GET, result)\n\n  return result\n}\n\nexport { getResultFor }\n</code></p><p></p><p></p><h5>store</h5><p></p><p></p><p>既然我们 JavaScript 框架选择依赖 Alpine.js 2.8，那么选择 Spruce 做全局状态管理也很合理。网站的每个部分都有一个 store，以下几行代码是我们用于管理大型菜单状态的：</p><p></p><p><code lang=\"kotlin\">Spruce.store('megamenu', {\n  activeId: null,\n  toggle(id) {\n    if (id === this.activeId) {\n      this.activeId = null\n      return\n    }\n    this.activeId = id\n  },\n})\n</code></p><p></p><p></p><h3>新旧指标的对比</h3><p></p><p></p><p>在确定架构并顺利实施最复杂的组件后，我们很自信我们前进的道路一定是正确的。性能标准测试结果也很好，大部分的性能分类都有了 15-20 百分点的提升。</p><p></p><p>我们迫不及待地想实现所有组件以获得完整的指标结果，每次点击 Lighthouse 标签中“生成报告”按钮，都会让我们的心跳加速。如果不包含脚本的话，预计我们的网站是不可能达到 56 的评分，但这是我们现在的结果：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/4f/4f985cb1ce61c1acf3ddd3819549dfbe.png\" /></p><p></p><p>再次声明，这只是我们的开发环境，因此很多图中的“机会”并不适用于实际生产环境。</p><p></p><p>这次的结果让我们颇为满意，在最后的几项测试，并对代码进行清理后，我们开始准备下周一的版本发布。</p><p></p><p>上午 8 点 24 分，我们点下了“合并”按钮。在这之前我们进行了发布前的最后一次 Lighthouse 测试，性能评分当时下降到了 28，具体是什么原因造成的这次 10 分左右的下降我们并不清楚。部署工作顺利进行，网站运行正常，于是我们又进行了一次 Lighthouse 测试。这是测试结果：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/87/87ac604ed6c6f5ef38fee8f44ea8a60d.png\" /></p><p></p><p>在上线之后我们发现了一些小问题，在及时修复后我们成功将评分打上 62 分，真是太刺激了！当然，这并不会是我们旅途的终点，我们仅仅是为后续进一步改善用户界面体验打下了良好的基础。</p><p></p><p></p><h2>荣誉提名：Debugbear</h2><p></p><p></p><p>在这次重新部署中，我们需要一个能对指标进行监控的工具。在研究通过 CI/CD 管道、手动测试或是通过 Lighthouse 节点 CLI 运行脚本时，我们偶然发现了 Debugbear。</p><p></p><p>Debugbear 的服务可以检测网站的核心状态、运行 Lighthouse 测试并将测试结果与竞争对手或历史结果进行对比，从而提供对两次测试结果的深层次解读。它不仅帮我们更好地了解问题根因，还提升了我们对优化工作的信心。</p><p></p><p>可以说，Debugbear 的性价比非常高，再加上 Matt 人真的很好，当时我们的信用卡除了问题，他非常慷慨地延长了我们的试用期，让我们安心测试而不用担心最后期限。</p><p></p><p></p><h2>写在最后</h2><p></p><p></p><p>以上基本就是我们旅程的第一阶段了。</p><p></p><p>最终的成果让我们对自己的决策充满了信心。Vue 并不适合我们的项目，老实说，当初选择 Vue 或许是因为它看起来不错，但它从来不是我们最好的选择。错处不在 Vue，Vue 是个很强的框架，我们也还在继续使用它，但现在我们有了另一个比 Vue 更合适的工具。</p><p></p><p>希望这篇文章能帮上你！如果有任何问题，欢迎在<a href=\"https://twitter.com/timkley%EF%BC%89%E4%B8%8A%E8%81%94%E7%B3%BB%E6%88%91%F0%9F%98%8A%E3%80%82\">推特</a>\"上联系我😊。</p><p></p><p>原文链接：</p><p><a href=\"https://www.tim-kleyersburg.de/articles/from-vue-to-alpinejs\">https://www.tim-kleyersburg.de/articles/from-vue-to-alpinejs</a>\" </p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/YbaZecBM65FPWmPsmlXL\">Vue涉及国家安全漏洞？尤雨溪回应：前端框架没有渗透功能</a>\"</p><p><a href=\"https://www.infoq.cn/article/RLV1zm3GAKE3i4GxTA66\">尤雨溪：Vue 3 将成为新的默认版本</a>\"</p>",
    "publish_time": "2022-12-05 19:19:06",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]