[
  {
    "title": "“理想解决方案”：Daltix的自动化数据湖归档节省了10万美元",
    "url": "https://www.infoq.cn/article/CMBPBjdfuQufcOc56P9U",
    "summary": "<p>本文最初发布于 Backblaze 官方博客。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fd/fd4cc0d8b066a369ded892a56c98fed6.png\" /></p><p></p><p>在快消领域，Daltix 是提供完整、透明、高质量零售数据的先行者。GFK 和联合利华等全球行业领导者依靠他们的定价、产品、促销和位置数据来制定入市策略并做出关键决策，对 Daltix 来说，维护一个可靠的数据生态系统势在必行。</p><p></p><p>自 2016 年成立以来，随着公司的发展，Daltix 处理的数据量呈指数级增长。他们目前管理着大约 250TB 的数据，分散在数十亿个文件中，很快就造成了巨大的时间和资源消耗。Daltix 的基础设施几乎完全是围绕 AWS 构建，因为需要管理数十亿个极小的文件，所以在可扩展性和成本效益方面，AWS 的存储选项已经开始无法满足他们的需求。</p><p></p><p>我们与 Daltix 首席软件工程师 Charlie Orford 进行了交流，了解他们如何迁移到 Backblaze B2 云存储以及他们从那个过程中得出了什么结论。以下是其中的一些要点：</p><p></p><p>他们使用一个自定义引擎将数十亿个文件从 AWS S3 迁移到 Backblaze B2；月度成本减少了 2500 美元，数据的可移植性和可靠性都得到了提升；Daltix 创建的基础设施每天可以自动备份 840 万个数据对象。</p><p></p><p>请继续阅读，看看他们是如何做到的。</p><p></p><p></p><h2>一个基于 AWS 构建的复杂数据管道</h2><p></p><p></p><p>Daltix 在公司创立初期创建的基于 S3 的基础设施，大部分还完好无损。过去，数据管道将从网络上抓取的资源直接写入 Amazon S3，经由基于 Lambda 的提取器进行标准化后，再发送回 S3。然后，由 AWS Batch 选取要使用其他数据源进行补充和丰富的资源。</p><p></p><p>所有这些步骤都是在 Daltix 的分析师团队准备好数据之前进行的。为了优化流程并提高效率，Orford 开始将该流程的部分环节纳入到 Kubernetes 中，但数据存储仍然存在问题；Daltix 每天生成大约 300GB 的压缩数据，而且这个数值还在迅速增长。“随着数据收集规模的扩大，我们必须更加关注成本控制、数据可移植性和可靠性，”Orford 说，“这些都是显而易见的，但规模大了，就更加重要了。”</p><p></p><p></p><h2>成本方面的考量促使我们寻找更友好的归档存储</h2><p></p><p></p><p>到 2020 年，Daltix 开始意识到，在 AWS 中构建这么多基础设施存在局限性。例如，围绕 S3 元数据进行的大量定制使得移动对象的能力完全受制于目标系统与 S3 的兼容性。Orford 还担心，在 S3 中永久存储如此巨大的数据湖的成本。如他所言，“很明显，没有必要把所有东西都永远存在 S3 中。如果不采取任何措施，那么我们的 S3 成本将继续上升，并最终远远超出我们使用其他 AWS 服务的成本。”</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/84/84bc4ae9d4c2ff7d0b676abbf05afd8f.png\" /></p><p></p><p></p><p>服务器成本对比</p><p></p><p>因为 Daltix 要处理数十亿个小文件，所以不可能使用 Glacier，因为它的定价模式是基于检索费用的。即使是使用 Glacier 即时检索，Daltix 所处理的文件数量也会使他们每年额外支付 20 万美元的费用。因此，Daltix 的数据收集团队（公司 85% 以上的数据都来自这个团队）推动实施了一种可替代的解决方案，解决了一些相互矛盾的问题：</p><p></p><p>数据湖的庞大规模；需要将原始资源存储为离散文件（这意味着无法进行批处理）；团队能够投入的时间和精力有限；简化解决方案，以保证其可靠性。</p><p></p><p>Daltix 决定使用 Amazon S3 进行热存储，并将暖存储转移到新的归档解决方案中，这可以降低成本，同时保持重要数据可访问——即使目的是将文件存储在别处。Orford 说：“重要的是要找到某个非常容易集成而且开发风险低的东西，并且有助于降低我们的成本。对我们来说，Backblaze 确实可以满足所有要求。”</p><p></p><p></p><h2>只是初步迁移每月就立省 2000 美元</h2><p></p><p></p><p>在开始全面迁移之前，Orford 和他的团队做了概念验证（POC），以确保解决方案解决了他们重点关注的问题：</p><p></p><p>确保海量数据成功迁移；避免数据损坏并使用审计日志检查错误；保留每个对象的自定义元数据。</p><p></p><p>“早期，我们与 Backblaze 合作，定制了一个可以满足我们所有需求的迁移工具，”Orford 说，“这给了我们继续前进的信心。”Backblaze 为我们定制了一个迁移引擎，可以保证迁移过程能够可靠地传输整个数据湖，并且保证对象级元数据完好无损。在成功迁移了一开始的 POC 存储桶之后，Daltix 就拥有了开始建模和预测未来成本所需的一切。Orford 说道：“在开始接触 Backblaze 之后，我们便不再寻找其他选项“。</p><p>2021 年 8 月，Daltix 将一个包含 22 亿个对象的 120TB 的存储桶从 S3 的标准存储转移到 Backblaze B2 云存储。仅最初的迁移就立即节省了 2000 美元 / 月或 24000 美元 / 年的成本。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d8/d8742d1006e419ddd999e63692f10fe7.png\" /></p><p>宁静的数据湖</p><p></p><h3>三倍的数据，直接兼容 S3，累计节省 10 万美元</h3><p></p><p></p><p>现在，Daltix 每天从 Amazon S3 向 Backblaze B2 迁移 320 万个数据对象（大约 160GB 的数据）。他们在 S3 中保存了 18 个月的热数据，一旦一个对象存在达 18 个月零一天，就会被归档到 B2 中。在少数情况下，Daltix 也会接收到请求 18 个月窗口期之外的数据的请求，由于 Backblaze 的 API 兼容 S3 且数据永远可用，所以他们可以直接将数据从 Backblaze B2 拉到 Amazon S3。</p><p></p><p>每日审计日志会汇总已传输的数据量，整个迁移过程每天自动执行。Orford 说：“它在后台运行，我们不需要管理任何东西，什么都可以看到，而且很划算。对我们来说，Backblaze B2 是一个理想的解决方案。”</p><p></p><p>随着每日数据收集量的增加，会有越来越多的数据从热存储窗口中迁出，Orford 预计成本会进一步降低。据 Orford 估计，日迁移量将在大约一年半后接近目前水平的三倍：这意味着 Daltix 每天将向 Backblaze B2 备份 900 万个对象（约 450GB 数据）。长远来看，从 Amazon S3 切换到 Backblaze B2 为 Daltix 节省的成本都令人难以置信。Orford 说：“因为使用了 Backblaze B2，预计到 2023 年，我们在存储支出上将累计节省 7.5 万至 10 万美元，每年至少节省 3 万美元。”</p><p></p><p></p><h2>自己算算看</h2><p></p><p></p><p>想知道每年多出 3 万美元能做什么吗？可以利用我们的云存储定价计算器，了解下迁移到 Backblaze B2 可以节省多少钱。</p><p></p><p>声明：本文为 InfoQ 翻译，未经许可禁止转载。</p><p></p><p>原文链接：https://www.backblaze.com/blog/an-ideal-solution-daltixs-automated-data-lake-archive-saves-100k/</p>",
    "publish_time": "2022-12-05 10:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "程序员上手 Rust 2年后感悟：它的确强大，但想要取代C还远着呢",
    "url": "https://www.infoq.cn/article/mEux81fTgUD0NlbJK9Lj",
    "summary": "<p></p><p>本文最初发布于Nabil Elqatib的个人博客。</p><p></p><p>接触Rust开发快两年了。我觉得，回顾下自己在这个过程中的一些感想和汲取的经验教训，应该会很有趣。</p><p></p><p>下图是我第一次向一个Rust存储库提交代码。虽然时间是2021年1月，但彼时我接触Rust已经有几个周了。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6f/6fe39ebbb6d88f658304419ab86cd436.png\" /></p><p></p><h2>初识Rust</h2><p></p><p>在2020年12月找到一份新工作之前，我早就听说过Rust。以我嵌入式开发的视角看，我认为Rust是一种现代而强大的语言，最终可能成为C/C++的合法继承者。我隐隐有一种担优，我可能会错过一个新时代的开始。</p><p></p><p>剧透：事实证明，Rust并没有取代C/C++，不过它正在稳步增长。<a href=\"https://survey.stackoverflow.co/2022/#section-most-loved-dreaded-and-wanted-programming-scripting-and-markup-languages\">它越来越受开发人员欢迎</a>\"，甚至谷歌也对它怀有浓厚的<a href=\"https://www.reddit.com/r/rust/comments/mgz7y5/androids_new_bluetooth_stack_rewrite_gabeldorsh/\">兴</a>\"<a href=\"https://opensource.googleblog.com/2022/10/announcing-kataos-and-sparrow.html\">趣</a>\"。</p><p></p><h2>我的感受</h2><p></p><p>首先需要声明一下：我没有正式学习过Rust。相反，我只是通过开发、阅读代码和来回翻阅文档来学习。回想起来，我认为这并不是一个好的做法。我坚信，在实际使用这门语言进行开发之前，必须花一些时间，利用<a href=\"https://www.rust-lang.org/learn\">官方提供的学习资料</a>\"来快速地理解这门语言、它的哲学和生态系统。</p><p></p><h3>Rust的学习曲线比较陡峭</h3><p></p><p>我记得，Rust是作为一种强类型语言向人“推销”的，它承诺提供强大的工具，通过在编译期间跟踪对象生命周期和所有引用变量的作用域，来防止内存安全Bug（见下一小节）。Borrow-checker出场！</p><p></p><p>在使用静态类型和Rc以及其他微妙的语言构件处理多个crate时，这个看起来非常简单的想法（Rust文档中关于这部分的内容非常全面）变成了一场噩梦。当时，我很难理解这个新概念，最容易钻的空子是不断地克隆变量，这样做不好（特别是在处理大型数据结构时），而且还有一个副作用，就是使我花了更多的时间才最终掌握它。</p><p></p><p>幸运的是，编译器提供了非常有用的提示和文档链接，我必须说，它们非常有用。</p><p></p><h3>Cargo不是一个严谨的验证工具</h3><p></p><p>这是一个非常普遍的误解，是我最近与一位非Rust工程师同事聊天时了解到的。在他看来，Rust程序因为运行时内存越界故障而恐慌（panic）是不可想象的。遗憾的是，Cargo编译器并不是一种包治百病的灵丹妙药，显然，欺骗它成功编译只会在运行时失败的程序很容易。下面这个例子使用了一种非常常见的Rust数据结构：</p><p></p><p><code lang=\"plain\">let mut v = vec![];\nv.push(0);\nv.clear();\nlet _ = v[0]; // panics \n</code></p><p></p><p>或者更棘手：</p><p></p><p><code lang=\"plain\">let mut v = Vec::new();\n\n#[cfg(target_os = \"windows\")]\nv.push(\"a\");\n\nlet _ = v[0]; // panics\n</code></p><p></p><p>在编译时检测越界访问需要对代码进行更深入的分析，这可以显著降低编译速度（在我看来，编译时间已经太长了）。</p><p></p><h3>Rust可能会让人捉摸不透</h3><p></p><p>这一节和我最近观察到的一个行为有关。我们的团队发现，在特定条件下，生产环境中的其中一个crate（依赖项的）依赖项开始出现恐慌。简单来说就是，当与rustls-tls-native-roots特性一起使用时，如果系统证书损坏，那么特定版本的<a href=\"https://docs.rs/reqwest/latest/reqwest/\">reqwest</a>\"会引发错误和恐慌。</p><p></p><p>这让我很惊讶，因为它使得处理依赖关系多了几分风险。</p><p></p><p>尽管现在大多数crate都是开源的，但人们也不能为了评估使用“风险”而把所有源代码都检查一遍。而且，大多数crate的文档比较糟糕，也没法提供很好的支持。有一个类似于cargo tree的工具，可以分析项目的依赖关系，让开发人员可以概览容易出现恐慌的crate，会非常有帮助。</p><p></p><p>习惯上，快速处理这个问题的一个替代方法是重写Rust的panic_handler，但很遗憾，这只有在#![no_std] 项目中才有可能。</p><p></p><h3>程序的二进制文件可能会很大</h3><p></p><p>说到来自嵌入式世界的no_std，这是我特别感兴趣的一个点。我还没有机会为内存有限的低端设备和外设编写Rust代码。尽管这现在不是我关心的问题，但Rust二进制文件的开销确实非常大。</p><p></p><p>我读过一些关于这个话题的博客和论文，特别是Jon Gjengset的视频，非常有趣，因为他们概要介绍了一个真实的实践过程。但我想说的是，对于内存有限的目标设备，Rust要成为C语言的有力竞争者还有很长的路要走。我觉得，在#![no_std] 领域，Rust还需要找到一种方法来提供可行的恐慌处理程序库，不再依赖开箱即用的格式化函数，因为它们非常消耗内存。<a href=\"https://jamesmunns.com/blog/fmt-unreasonably-expensive/\">James Munns的这篇文章</a>\"让我大开眼界。</p><p></p><h3>Rust工具有很棒的互操作性</h3><p></p><p>这点也给我留下了深刻的印象。</p><p></p><p>我参与过一个项目，包含900K+行与Rust互操作的C代码。这并没有多难，因为Rust让这个过程变得非常简单，而且，因为有许多crate和示例，这个用例似乎也已经比较完善。借助FFI机制，为外部代码编写Rust绑定也相对简单，我不能说所有语言，但C语言家族（C/ C++ /Objective-C）都得到了很好的支持。</p><p></p><p>这不是说没有多少工作要做了，因为你还需要编写一些“管道”代码来把所有东西串联起来，这有代价，但我认为相当低。此外，Rust坚持自己的哲学，要求将可疑的底层代码声明为不安全的，这一点很好（实际上，基本上所有FFI函数都是不安全的，因为Rust无法控制用另一种语言编写的代码）。</p><p></p><h3>Rust很强大</h3><p></p><p>最后说一个积极的方面。Rust是一种非常丰富的语言，有可能让系统编程取得巨大的进步。严格的所有权和借阅有助于确保数据访问安全高效。它的现代语法和设计使得开发人员更容易理解和使用这门编程语言的软件模式和最新范式。此外，虽然说的不多，但Rust在线程并发运行方面做得非常好，可以保证不出现竞态条件及类似问题。</p><p></p><h3>小结</h3><p></p><p>我真的很喜欢Rust开发。如果在2020年甚至2022年要选择一种新的软件开发语言，那么我一定会毫不犹豫地选择Rust。我看到了它的巨大潜力，希望接下来的几个月里，它可以获得嵌入式系统世界的更多关注。最近发布的Rust Linux内核模块显示出了其广阔的前景和光明的未来。</p><p></p><p>就我个人而言，我希望更多地参与塑造 Rust 的未来，为它的软件做出贡献，同时不断学习它的概念及那些纷繁芜杂之处。</p><p></p><p>声明：本文为InfoQ翻译，未经许可禁止转载。</p><p></p><p>原文链接：<a href=\"https://n-eq.github.io/blog/2022/11/01/rust-fiddling-2-years\">https://n-eq.github.io/blog/2022/11/01/rust-fiddling-2-years</a>\"</p>",
    "publish_time": "2022-12-05 10:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "携程商旅CEO张勇：TMC不止一站式解决方案 携程商旅推出“产品云图”",
    "url": "https://www.infoq.cn/article/2db527a86c857301ab0972658",
    "summary": "<p>12月2日，携程商旅在2022年“与时·聚进”携程集团全球合作伙伴峰会上，发布全新“产品云图”。通过这一举措，携程商旅突破了“一站式商旅解决方案服务商”的固有角色，将在未来全面打造“全景服务能力体系”。</p><p><img src=\"https://static001.geekbang.org/infoq/65/65015f430772464ba7dc080e6ceea21e.png\" /></p><p></p><p>“产品云图”展示了携程商旅整个体系化的产品、服务、管理工具以及运行机制，有助于用户及上下游供应链一目了然锁定需求。基于云图战略，与商旅相关的每一个环节方都将从中获得“可选择、可搭配、可延展、可迭代、可融合”的全景解决提案。“产品云图的发布，意味着商旅行业将从一站式差旅解决方案时代，迈入全景服务能力体系时代”。携程商旅CEO张勇表示。</p><p>&nbsp;</p><p>TMC不止一站式解决方案 云图战略探照商旅冰山下隐藏价值</p><p>&nbsp;</p><p>“当中国的商旅行业已经发展到国际领先水平之后，下一个阶段到底是什么？TMC只提供一体化的解决方案就够了吗？”张勇现场提出一个商旅时代性问题。</p><p>&nbsp;</p><p>调研显示，超过67%的管理者认为，商旅管理可以作为一家企业在探索数字化转型中的试验田。然而还有许多企业，仅把商旅作为员工出差预订机票酒店的工具。“产品云图”为用户、合作伙伴列举了商旅的更多可能性：例如费控报销体系、支付解决方案、交通酒店专家、合规管理方案、咨询服务等等。</p><p><img src=\"https://static001.geekbang.org/infoq/11/1170ac3c25f8ee2af3c0830e2c595761.png\" /></p><p></p><p>“显然，不通过云图放大差旅预订以外的“人智数”价值，用户的隐性成本就像海平面下的冰山，不被发现但持续损耗用户权益。”张勇表示。记者了解到，日常企业差旅管理中，重复提报、超预算、违规操作、无法使用三方协议价等问题依旧是企业商旅的顽疾。</p><p>&nbsp;</p><p>为了发挥“产品云图”的效能，真正打造出携程商旅的全景服务能力体系，携程商旅重新构建了技术中心、资源中心、服务中心、合规中心以及营销中心五大能力中心。五大能力中心由内向外发挥各自职能，达到给养内部支援外部的协同作用。例如重构前携程商旅营销部仅是企业内部支持机构，重新定义后的营销中心可通过产品手册、行业趋势、数据报告等内容智库为客户多元化赋能。</p><p>&nbsp;</p><p>共建共拓携程商旅为客户提供2700+定制化生态系统集成方案</p><p>&nbsp;</p><p>事实上，云图战略只是携程商旅的自我迭代中的一部分：更多的行业共建、生态共拓，也正在基于对客户的洞察而推进。</p><p>&nbsp;</p><p>“我们发现随着客户差旅体系的完善与成熟化，新的碎片化问题逐渐衍生出现。例如面对越来越多的三方订单需求，我们通过积极推进行业内的系统覆盖，与酒店伙伴的系统对接率提升了467%，帮助酒店的三方协议订单确认效率再提升80%，做到优化商旅客户体验的同时，降低酒店的满房率与变价率，有效赋能酒店的服务和管理能力。”张勇介绍道。</p><p>&nbsp;</p><p>针对企业对可持续发展和绿色出行的关注，携程商旅采用Travalyst的旅行影响模型，上线航班碳排放量数据标签，记录商旅客户的每一次差旅的碳足迹，鼓励商旅客户选择低碳航班出行。</p><p>&nbsp;</p><p>此外，携程商旅已经与6大生态系统，超过140家的国内外主流厂商合作，为企业客户提供了超过2700份生态合作定制化系统集成方案和55000份标准化系统集成方案。经过统计，采用集成方案后的每位企业员工平均一年可以节省200分钟的时间成本。</p><p>&nbsp;</p><p>携程商旅国内国际纵横发展三季度总业绩反超2019年</p><p>&nbsp;</p><p>从用户出发奠定了携程商旅业绩增长的基石，虽然经历了疫情的跌宕冲击，但从整体业绩恢复情况来看，携程商旅在第三季度反超2019年同期水平。同时受海外商旅复苏影响，今年前10个月出入境商旅机票订单量同比增长245%，国际商旅酒店订单量同比增长531%。</p><p>&nbsp;</p><p>在国内市场下沉布局方面，携程商旅在新一线城市的供应链部署量级同比增长90%，企业客户数增长了20%，用户数增长53%。国际方面，当前携程商旅已经在包括东亚、东南亚、欧洲地区的5个市场做好了基础布局。随着今年国际商旅的开放，商旅海外用户数同比增长超过8倍。</p>",
    "publish_time": "2022-12-05 11:20:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "实时数据赋能制造业产能升级：详解半导体和汽车制造行业最佳实践（活动报名）",
    "url": "https://www.infoq.cn/article/7c240ec922a870266ee34f2ba",
    "summary": "<p>如今，数据的时效性会真正影响到一个企业的生存。特别是对于制造行业而言，一面是信息化建设过程中数百套业务系统积累的历史包袱；一面是多种数据源下数字化建设的更多新需求，数据孤岛成为企业内长期存在的问题，数据实时同步难度升级，直接对产能、研发效率等产生影响。以半导体制造和车企在生产环境的真实需求为例：</p><p></p><p>某大型半导体制造企业：无人实验室作业</p><p></p><p>不同于常规生产流水线，半导体制造的无人实验室生产模式，通过自动化排程完成机器人工作，高度依赖机器人作业来完成兼具复杂性与精密性的任务。每次数据需要计算 10-15 分钟，才能将结果给到排程系统，这就导致机器人大量时间没有工作，直接影响企业产能。如果能有效提升数据实时性，做到将数据在 1 分钟内推送到排程系统，生产速度跃升，占据产能优势的目标便不再是问题。</p><p></p><p>某头部车企：60+业务系统运转中</p><p></p><p>行业深耕数十载，在稳扎资深根基的同时，也在历史数字化变革求新的过程中遗留了一些数据负担——大量独立构建的系统，彼此数据难以共享打通；涉及数据库种类及版本多样；数据量不容小觑。在日益凸显的孤岛问题影响下，面对来自不同业务组提交的数据请求，研发很难做到快速响应。如果能快速打通数据孤岛，实现数据实时入湖，研发团队才能真正有机会将被数据层工作“绑架”的精力释放出来，助力业务团队实现更多创新。</p><p></p><p>想要了解当下制造行业的企业数据现状和根本痛点？想要接触更多制造业实时数据实践方案，吸收数字化成功经验？想要快速对比不同实时数据集成解决方案的特性与缺陷，为技术选型提供更多参考？……</p><p></p><p>欢迎参加 Tapdata 线上交流活动！</p><p></p><p>12月7日（周三）19:00，Tapdata 直播间与您相约。Tapdata 首席架构师杨庆麟（Arthur）在线讲解当下制造行业有关实时数据集成的真实诉求，结合成功案例解析各类解决方案的特点与架构。</p><p></p><p>更多活动信息及报名方式，详见海报：</p><p><img src=\"https://static001.geekbang.org/infoq/eb/ebf2aa7c2aa2839da0b2ecca4a01a8a0.png\" /></p><p>立刻扫码，关注报名</p>",
    "publish_time": "2022-12-05 11:48:04",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "OpenAI最新聊天机器人ChatGPT火爆全网！能写代码、编剧本，马斯克盛赞：好得吓人",
    "url": "https://www.infoq.cn/article/AWWsrfb54zTvglZ0I5qS",
    "summary": "<p></p><blockquote>写代码、编故事、构建虚拟机……聊天机器人 ChatGPT 还有多少惊喜是我们不知道的？</blockquote><p></p><p></p><h2>OpenAI 发布测试版聊天机器人 ChatGPT</h2><p></p><p></p><p>近日，OpenAI 发布了一个全新的聊天机器人模型 <a href=\"https://chat.openai.com/auth/login\">ChatGPT</a>\"，这也是 GPT-3.5 系列的主力模型之一。目前，ChatGPT 还处于测试阶段，只需登录就能免费使用，OpenAI 希望可以通过用户反馈开发出更好的 AI 系统。</p><p></p><p>虽然类似的聊天机器人并不少见，但 ChatGPT 一经发布迅速火爆全网，并收获了无数好评。有开发者认为，有些技术问题就算问谷歌和 <a href=\"https://www.infoq.cn/article/egLtw4WYSjlaO3ShdYix\">Stack Overflow</a>\"，都没有 ChatGPT 回答得靠谱。</p><p></p><p>连马斯克也在感叹“很多人疯狂地陷入了 ChatGPT 循环中”，“ChatGPT 好得吓人，我们离强大到危险的人工智能不远了”。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6c/6c7a6a9a0c2fa0c535cbbed7c406df6b.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/36/36f04b961e949adf68503b8252d5be13.png\" /></p><p></p><p>让马斯克盛赞、全网沸腾的 ChatGPT 到底有什么魔力？</p><p></p><p>根据 OpenAI 的介绍，ChatGPT 使用了与另一款 GPT-3.5 系列的模型 InstructGPT 相同的方法，但另外收集了 AI 与人类对话的数据，既包括人类自己的，也包括 AI 的，这些 AI 训练师可以参照建模建议写出自己的答案。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/92/922921afd39e519de8720f28f227e2d6.png\" /></p><p></p><p>对于强化学习奖励模型，OpenAI 记录了 AI 训练师和聊天机器人之间的对话。然后，该团队随机选择了一个人工智能利用不同自动补全功能生成的回复，并让训练师对其进行评分。在进行微调时，OpenAI 使用了近端策略优化（proximal policy optimization），这个过程会反复进行多次。</p><p></p><p>目前，不少网友展示了与 ChatGPT 对话的有趣内容，并解锁了多个 ChatGPT 的用途。</p><p></p><p>有网友询问 ChatGPT 如何设计客厅，ChatGPT 给出了三种装饰方案，还贴心地给出了三幅设计图。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6c/6ccd06c1dea69050ebc111229c32ff53.png\" /></p><p></p><p>有网友用《老友记》等喜剧演员为角色，让 ChatGPT 写一些肥皂剧对白，ChatGPT 把好几个场景描绘得惟妙惟肖：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4a/4a5ac7bda550265f07715ecd1fe12ce4.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/77/770dfaed20c947e695ff18e8cdaffe76.png\" /></p><p></p><p>也能解释各种科学概念：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fa/facdfa77255926e0624e2d71410c6048.png\" /></p><p></p><p>就连写论文这种比较有挑战的事情，ChatGPT 也冲上来试了试。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ee/ee8de2e71da48e0ca5a6c8ff2d6af1d6.jpeg\" /></p><p></p><p>其中，最令人兴奋的当属 ChatGPT 在技术领域的用途。</p><p></p><p>区别于普通的聊天机器人，ChatGPT 显然更懂技术，它能写代码、改 Bug、创建编程语言、构建虚拟机……</p><p></p><p>与 GitHub 的 <a href=\"https://www.infoq.cn/article/93kD4l5m0pye7k5CrKRT\">AI 编程神器 Copilot </a>\"相比，ChatGPT 似乎更能抢走程序员饭碗。技术公司 Replit CEO Amjad Masad 称赞 ChatGPT 是一个优秀的“调试伙伴”，“它不仅解释了错误，而且修复了它，并解释了修复方法”。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1f/1fe5a82ae93a6cc958efb9b9022296cd.png\" /></p><p></p><p>而对于一些更简单的问题，ChatGPT 更是“对答如流”，有网友在对比了谷歌的搜索结果和与 ChatGPT 的聊天结果之后，自信地宣称谷歌已经“完蛋”了。</p><p></p><h2>ChatGPT 还存在许多局限性</h2><p></p><p></p><p>虽然给大家带来了很多惊喜，但不得不承认，当前的 ChatGPT 还存在大型语言模型中常见的局限性。其中，部分网友对 ChatGPT 提供的回答准确性存在质疑。有网友指出，ChatGPT 提供的代码包含完全不相关的解释：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/95/95736aa73e1799328499c58914df0673.png\" /></p><p></p><p>另外，ChatGPT 有时还会生成听起来合理，但既不正确又无意义的回复。按照 OpenAI 的说法，因为缺少单一事实来源，过度谨慎训练的模型会拒绝问题，而在有监督训练中，理想的答案取决于模型的知识，而不是人类演示者。</p><p></p><p>ChatGPT 对输入的微小变化也会有很大的反应。根据输入内容的不同，它可能不回答，回答错误内容，或者回答正确内容——根据 OpenAI 的说法，简单的重新措辞就可以了。此外，ChatGPT 的回答太过于冗长，大多使用短句，并爱说些车轱辘话。出现这种情况的原因是过度优化和人类导师的偏见，他们更喜欢人类反馈中那些比较详细的答案。</p><p></p><p>ChatGPT 不会用提问来回应不清楚的表述，而是尝试猜测用户的意图。有时，对于不恰当的请求，该模型会回应而不是拒绝它们。OpenAI 试图使用其适度性 API，来拒绝不符合其内容策略的请求。</p><p></p><p>如果你问 ChatGPT 它自己的意见，它会拒绝回答，给出的理由是没有接入互联网。</p><p></p><p>OpenAI 表示：“ChatGPT 模型还有许多局限性，所以我们计划定期更新模型，在这些方面做些改进。但我们也希望，通过提供 ChatGPT 的访问接口，获取宝贵的用户反馈，以发现我们尚未意识到的问题。”</p><p></p><p>虽然当前的 ChatGPT 还不算完美，但它像人们描述除了一个更光明的 AI 未来。谷歌母公司 Alphabet 的工程师评论道：</p><p></p><p>“像 GPT 这样的大型语言模型是谷歌活跃的 ML 研究的最大领域之一，并且有大量非常明显的应用程序可以用来回答查询、索引信息等。谷歌有大量预算与人员来处理这些类型的模型，并进行实际训练，这是非常昂贵的，因为训练这些超大型语言模型需要大量的计算能力。然而，我从谈话中收集到的是，在最大的谷歌产品（例如搜索、gmail）中实际使用这些语言模型的经济性还不完全存在。放一个大家感兴趣的演示是一回事，但考虑到服务成本，尝试将它深入集成到一个每天服务数十亿个请求的系统中是另一回事。我想我记得主持人说过他们希望将成本降低至少 10 倍，然后才能将这样的模型集成到搜索等产品中。</p><p></p><p>10 倍甚至 100 倍的改进显然是未来几年可以实现的目标，所以我认为这样的技术将在未来几年内出现。”</p>",
    "publish_time": "2022-12-05 13:41:06",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]