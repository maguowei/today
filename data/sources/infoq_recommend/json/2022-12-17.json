[
  {
    "title": "2022 Gartner全球云数据库管理系统魔力象限发布，腾讯云数据库入选",
    "url": "https://www.infoq.cn/article/wpsOPplWbagOX1albwBT",
    "summary": "<p>12月16日，在刚刚发布的Gartner® 2022年度《云数据库管理系统魔力象限》研究报告中，腾讯云数据库进入特定领域者（Niche Players）象限。同时据Gartner云数据库管理系统运行用例关键功能报告，腾讯云数据库在OLTP事务和轻量级事务用例上，得分均为本土厂商第一。</p><p>&nbsp;</p><p>腾讯云旗下涵盖丰富的云数据库管理系统（DBMS）产品矩阵，包括OLTP型数据库TDSQL、键值数据库KeeWiDB、时序数据库CTSDB、图数据库KonisGraph等，在OLAP方面则提供以大数据处理套件TBDS为代表的多款分析型数据库产品。</p><p>&nbsp;</p><p>基于持续的产品与生态建设，腾讯云数据库TDSQL已应用于超过50万客户，包括主流金融、政务、运营商、工业制造企业，并在亚太、日本和欧洲等海外市场拥有广泛业务布局。</p><p>&nbsp;</p><p>在产品能力上，腾讯云数据库TDSQL旗下已涵盖金融级分布式、云原生、分析型等多引擎融合的完整数据库产品体系，提供了业界领先的金融级高可用、存算分离、数据仓库、企业级安全等能力，同时具备智能运维平台、Serverless版本等完善的产品服务。</p><p>&nbsp;</p><p>截止目前，腾讯云数据库TDSQL核心代码自研率已达到100%，管理超过50万个节点，金融级容灾要求下，单实例存储规模达到PB级别，单实例日请求次数超百亿次，服务客户资源完成百万核和百PB的“双百”里程碑。</p><p>&nbsp;</p><p>在OLTP方面，根据Gartner云数据库管理系统运行用例关键功能报告，腾讯云数据库TDSQL在OLTP事务、轻量级事务和增强事务三个用例中得分均高于3.0（总分5分，3分以上代表满足要求），其中OLTP事务用例得分最高（3.7）。</p><p>&nbsp;</p><p>市场对腾讯优异的OLTP产品能力进行了印证：TDSQL正在被国内各行业广泛采用，以取代Oracle和IBM在其核心业务中的应用。</p><p>&nbsp;</p><p>通过对OLTP数据库能力的持续投入，腾讯云数据库TDSQL迅速抓住了中国金融行业数字化转型的需求，并在其核心系统国产化替换场景中表现抢眼。目前，腾讯云数据库TDSQL已经服务了TOP 10银行中的七家，在TOP 20银行中也服务过半，在不同金融机构核心系统中的渗透率均有显著提升。</p><p>&nbsp;</p><p>在轻量级事务方面，腾讯云自研的分布式数据库KeeWiDB实现国内首个三级存储架构设计，搭载全自研存储引擎，自研代码量超过25万行，单节点读写能力超过18万QPS，最高可线性堆叠至千万级并发吞吐量，同时兼容Redis协议，访问延迟达到毫秒级，解决了Redis在性能、成本、持久化和规模存在的四大挑战。</p><p>&nbsp;</p><p>在OLAP方面，腾讯云数据库TDSQL集高并发、高SQL兼容度、高扩展性、以及企业安全审计等多项能力于一身。产品采用无共享架构，支持海量数据高并发实时在线交易和完整的事务分布式ACID能力，支持海量数据多维统计分析。今年6月，新升级后的TDSQL带来了通用场景下查询性能10倍以上的提升。</p><p>&nbsp;</p><p>腾讯大数据处理套件TBDS支持超过8万个节点集群规模，日接入数据超80万亿条，日实时计算次数150万亿以上，做到万亿数量全量秒级查询。</p><p>&nbsp;</p><p>TBDS融入腾讯内部海量数据处理先进实践，面向数据全生命周期提供了一站式、安全可信的大数据存储、查询、分析能力，通过核心自研的管理引擎TBDS&nbsp;Manager和联邦分析引擎SuperSQL，可实现跨源跨引擎亿级数据毫秒级联合查询，可满足日增万亿级数据、数千万级DAU、千万级QPS的海量数据分析业务场景，已在政府、金融、教育、工业、交通等众多行业广泛应用。</p><p>&nbsp;</p><p>目前，腾讯云大数据已涵盖底层以弹性MapReduce、云数据仓库CDW、数据湖计算DLC等为代表的云原生大数据引擎，中层的一站式数据开发治理平台WeData与大数据处理套件TBDS，以及上层的智能推荐、隐私计算、BI等应用，致力于成为企业数智化升级中的助推器。</p><p>&nbsp;</p><p>同时，腾讯云大数据一直秉持技术开源开放的理念，开源了数据集成Inlong、机器学习Angel等八大项目，并成为众多开源社区的主要贡献者，提高了在全球开发者社区中的认可度，并以此立于数据和分析领域的创新前沿。</p><p>&nbsp;</p><p>随着数据应用场景的不断拓展，企业的数字化转型进程也已进入深水区。面向未来，腾讯云DBMS产品矩阵也将不断加强基础能力建设、持续创新技术，不断满足企业对数据库性能、成本、稳定性和安全性的新需求，助力千行百业数字化升级，实现更广泛的数据库安全可控。</p><p>&nbsp;</p><p>Gartner, Magic Quadrant for Cloud Database Management Systems, December 2022.</p><p>Gartner, Critical Capabilities for Cloud Database Management Systems for Operational Use Cases, December 2022.</p><p>&nbsp;</p><p>Gartner不对其研究出版物中所述的任何厂商、产品或服务做背书，也不建议技术使用者只选择那些评价最高或其他指定的厂商。Gartner研究出版物包含Gartner研究组织的观点，不应被解释为事实陈述。Gartner对这项研究不提供明示或默示的所有担保，包括适售性之任何担保或符合特定目的之任何担保。Gartner Peer Insights内容包含个人用户根据自己的经验发表的意见，不代表Gartner或其附属公司的观点。GARTNER和Magic&nbsp;Quadrant是Gartner, Inc和/或其在美国与全球关係企业的注册商标和服务标章，经许可使用。著作权所有，并保留一切权利。</p><p>&nbsp;</p>",
    "publish_time": "2022-12-17 13:10:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "ChatGPT爆火，揭秘AI大模型背后的高性能计算网络",
    "url": "https://www.infoq.cn/article/IevuMz2RfOLEPfPh7Mx2",
    "summary": "<p></p><p></p><blockquote>导言——AI 大模型以其优异的自然语言理解能力、跨媒体处理能力以及逐步走向通用 AI 的潜力成为近年 AI 领域的热门方向。业内头部厂商近期推出的大模型的参数量规模都达到了万亿、10 万亿级别。</blockquote><p></p><p></p><p>前几天横空出世的 AI 爆款产品 ChatGPT，可以聊天、写代码、解答难题、写小说，其技术底座正是基于微调后的 GPT3.5 大模型，参数量多达 1750 亿个。据报道，GPT3.5 的训练使用了微软专门建设的 AI 计算系统，由 1 万个 V100 GPU 组成的高性能网络集群，总算力消耗约 3640 PF-days (即假如每秒计算一千万亿次，需要计算 3640 天)。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/0a/0a7f4d1585883057367e909317f5b129.png\" /></p><p></p><p>图 1. ChatGPT 的 AI 内容生成</p><p></p><p>如此大规模、长时间的 GPU 集群训练任务，对网络互联底座的性能、可靠性、成本等各方面都提出极致要求。对此，追求极致高性能与高可用的星脉高性能计算网络面世了。</p><p></p><p>在最新的自然语言理解任务榜单 CLUE 上，腾讯首个低成本、可落地的 NLP 万亿大模型训练斩获总榜、分类榜和阅读理解榜三个榜首，其在训练速度以及训练精度上全面超越传统算力集群，甚至超过人类水平。而在金榜题名的背后，星脉高性能计算网络为腾讯万亿大模型构筑了高性能网络底座。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d1/d1ed09dc5d906636edce83c51516f635.png\" /></p><p></p><p>图 2. 自然语言理解任务榜 CLUE</p><p></p><p>星脉网络在极致高性能上，采用 1.6T 超带宽接入、多轨道聚合流量网络架构、异构网络自适应通信优化技术、定制加速通信库，构建了 1.6T ETH RDMA 网络，实现了 AI 大模型通信性能的 10 倍提升，GPU 利用率 40% 提升，通信时延降低 40%，单集群规模达到 2K（最大规模 32K），基于全自研网络硬件平台网络建设成本降低 30%，模型训练成本节省 30%~60%。在高可用保障上，通过全自动化部署配置核查，覆盖服务器 NUMA、PCIE、NVSwitch、NCCL、网卡、交换机数百个配置项，并通过实时 Service Telemetry 技术监控业务系统运行效率，保障大规模集群部署，实现性能实时监控与故障告警。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d9/d9af90144ce2ef1fba61c3668555690b.png\" /></p><p></p><p>图3. 星脉高性能计算网络</p><p></p><p></p><h2>AI 时代下的网络诉求：极致网络</h2><p></p><p></p><p></p><h3>网络性能决定 GPU 集群算力</h3><p></p><p></p><p>根据阿姆达尔定律，串行通信决定了并行系统整体运行效率，并行系统节点数越多，其通信占比越高，通信对整体系统运行效率的影响越大。</p><p></p><p>在大模型训练任务场景，动辄需要几百甚至几千张 GPU 卡的算力，服务器节点多、跨服务器通信需求巨大，使得网络带宽性能成为 GPU 集群系统的瓶颈。</p><p></p><p>特别是 MoE（混合专家系统）在大模型架构中的广泛应用，由于其稀疏门控特性构建在 All-to-All 通信模式之上，会随集群规模的增长对网络性能提出极高要求。业界近期针对 All-to-All 的优化策略，都是极致利用网络提供的大带宽来缩短通信耗时，从而提升 MoE 模型的训练速度。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/41/412a882ef34bfce59cbab70cfa8adc91.png\" /></p><p></p><p>图 4. MoE 模型引入 All-to-All 集合通信操作</p><p></p><p>Lepikhin, Dmitry, et al. “Gshard: Scaling giant models with conditional computation and automatic sharding.” arXiv preprint arXiv:2006.16668 (2020).</p><p></p><p></p><h3>网络可用性决定 GPU 集群算力稳定性</h3><p></p><p></p><p>GPU 集群规模达到一定量级后，如何保障集群系统的稳定性，是除了性能外必须面对的另一个挑战。网络的可用性，决定了整个集群的计算稳定性，这是由于：</p><p></p><p>1）网络故障域大：相比单点 GPU 故障只影响集群算力的千分之几，网络故障会影响数十个甚至更多 GPU 的连通性，只有网络稳定才能维持系统算力的完整性。</p><p></p><p>2）网络性能波动影响大：相比单个低性能 GPU 或服务器容易被隔离，网络作为集群共享资源，性能波动会导致所有计算资源的利用率都受影响。</p><p></p><p>因此在大模型任务训练的整个周期中（数天、数周），维持网络的稳定高效，是 GPU 训练集群在工程化实践中极其重要的目标，对网络运维带来新的挑战。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e4/e429393a8cda7eb2dbb2eeb6c571565d.png\" /></p><p></p><p>图 5. 网络故障 / 性能对集群算力影响大</p><p></p><p></p><h2>创造高性能——AI 训练集群下的极致性能网络</h2><p></p><p></p><p>面对千亿、万亿参数规模的大模型训练，仅仅是单次计算迭代内梯度同步需要的通信量就达到了百 GB 量级，此外还有各种并行模式、加速框架引入的通信需求，使得传统低速网络的带宽远远无法支撑 GPU 集群的高效计算。因此要充分发挥 GPU 计算资源的强大算力，必须构建一个全新的高性能网络底座，用高速网络的大带宽来助推整个集群计算的高效率。面向 AI 大模型训练需求，腾讯推出了业界领先的高性能计算网络架构——星脉：采用 1.6T 超带宽接入、多轨道聚合流量网络架构、异构网络自适应通信、定制加速通信库，构建了 1.6T ETH RDMA 高性能网络。</p><p></p><p></p><h3>超带宽计算节点</h3><p></p><p></p><p>AI 大模型训练是一种带宽敏感的计算业务，腾讯星脉网络为每个计算节点提供 1.6T 的超高通信带宽，带来 10 倍以上的通信性能提升。</p><p></p><p>星脉网络主要特点有：采用无阻塞 Fat-Tree 拓扑，单集群规模支持 2K GPU，超 EFLOPS（FP16）的集群算力；可灵活扩展网络规模，最大支持 32K GPU 计算集群；计算网络平面配备 8 张 RoCE 网卡，提供 1.6Tbps 的超高带宽接入。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a4/a41872619365d02238e91c2e5f4ce459.png\" /></p><p></p><p>图 6. 星脉组网架构</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c5/c5affa2c1d2bed610d2434c6551b4230.png\" /></p><p></p><p>图 7. 集合通信性能理论建模</p><p></p><p>上图从理论上展示了 1.6Tbps 带宽与 100Gbps 带宽的集合通信性能对比。可以看到，对于 AllReduce 和 All-to-All 这两种典型通信模式，在不同集群规模下，1.6Tbps 超带宽都会带来 10 倍以上的通信性能提升。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7e/7e765a8fab901a7bc0f0164297ead7d9.png\" /></p><p></p><p>图 8. GPT3 模型训练性能</p><p></p><p>上图是对 GPT3 模型的实测性能数据，主要通信模式是 AllReduce。以 64 GPU 规模为例，由于 1.6Tbps 超带宽网络将 AllReduce 的耗时大幅缩短 14 倍，将通信占比从 35% 减少到 3.7%，最终使得单次迭代的训练耗时减少 32%。从集群算力的角度，相当于用同样的计算资源，超带宽网络能将系统算力提升 48%。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/02/027c33072326a0ced91998400e6e644b.png\" /></p><p></p><p>图 9. T5-MoE 模型训练性能</p><p></p><p>上图是对 T5-MoE 模型的实测性能数据，主要通信模式是 All-to-All。同样可以看到，在 64 GPU 模型下，1.6Tbps 带宽下的单次迭代训练耗时降低 64%。从集群算力的角度，相当于用同样的计算资源，超带宽网络能将系统算力提升 2.8 倍。</p><p></p><p></p><h3>多轨道流量聚合架构</h3><p></p><p></p><p>除了超带宽计算节点，星脉网络对通信流量做了基于多轨道的流量亲和性规划，使得集群通信效率达 80% 以上。</p><p></p><p>多轨道流量聚合架构将不同服务器上位于相同位置的网卡，都归属于同一 ToR switch；不同位置的网卡，归属于不同的 ToR switch。由于每个服务器有 8 张计算平面网卡，这样整个计算网络平面从物理上划分为 8 个独立并行的轨道平面，如下图所示（不同颜色代表不同的轨道）。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a6/a6ba9d9df267044cfef69f6709e74a7e.png\" /></p><p></p><p>图 10. 多轨道流量聚合架构</p><p></p><p>在多轨道网络架构中，AI 训练产生的通信需求（AllReduce、All-to-All 等）可以用多个轨道并行传输加速，并且大部分流量都聚合在轨道内传输（只经过一级 ToR switch），小部分流量才会跨轨道传输（需要经过二级 switch），大幅减轻了大规模下的网络通信压力。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/16/16947fe3b96cf7d1a53a949a66a37d98.png\" /></p><p></p><p>图 11. 集合通信效率</p><p></p><p>从上图实测的集合通信性能可以看出，在不同网络规模下，AllReduce 与 All-to-All 始终能维持较高的集合通信效率。</p><p></p><p></p><h3>异构网络自适应通信</h3><p></p><p></p><p>大规模 AI 训练集群架构中，GPU 之间的通信实际上由多种形式的网络来承载的：机间网络（网卡 + 交换机）与机内网络（NVLink/NVSwitch 网络、PCIe 总线网络）。星脉网络将机间、机内两种网络同时利用起来，达成异构网络之间的联合通信优化，使大规模 All-to-All 通信在业务典型 message size 下的传输性能提升达 30%。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3c/3cfd02a007b1742b08733ed8cd6934bf.png\" /></p><p></p><p>图 12. 异构网络自适应通信</p><p></p><p>上图展示了 All-to-All 集合通信如何利用异构网络来优化。当机间、机内网络同时使能时（右图）：不同 host 上相同位置的 GPU 仍然走机间网络通信；但是要去往不同位置的 GPU（比如 host1 上的 GPU1 需要向其他 host 上的 GPU8 发送数据），则先通过机内网络转发到对应位置的 GPU 代理上，然后通过该 GPU 代理走机间网络来完成通信。</p><p></p><p>异构网络通信带来的优势有两点：1）异构网络通信使得机间网络的流量数目大幅减少；2）异构网络通信使机间网络的流量大部分都聚合在轨道内传输（只经过一级 ToR switch）。异构网络通过将小流聚合为大流的方式来减少流量的数目，减少对机间网络的冲击（RDMA QP 数量、拥塞控制、微突发等），从而提升整网的传输性能。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/51/518d6ad05cf5a6a1d24f9a96f06c4020.png\" /></p><p></p><p>图 13. 异构网络自适应通信提升 All-to-All 性能</p><p></p><p>从上图的实测数据可以看出，异构网络通信在大规模 All-to-All 场景下对中小 message size 的传输性能提升在 30% 左右。</p><p></p><p></p><h3>定制加速通信库</h3><p></p><p></p><p>腾讯高性能集合通信库 TCCL（Tencent Collective Communication Library）定制适配星脉网络硬件平台，在 AllReduce/AllGather/ReduceScatter 等常用通信模式下带来 40% 的性能加速。</p><p></p><p>星脉网络基于 1.6Tbps ETH RDMA 网络定制，从网络性能、建设成本、设备供应、网络可靠性等多方面综合考虑，大量部署了 2*100Gbps 的单网卡硬件。从服务器角度上看，需要管理、配置 8 张 2*100G 的网卡；从网络架构角度上看，每张网卡需要上联两个 LA/ToR switch 来保证带宽与可靠性。组网架构图如下所示。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b0/b0e2dc1e3b129fdf76e7872a151ebb83.png\" /></p><p></p><p>图 14. 2*100G 网卡双端口动态聚合组网架构</p><p></p><p>面对定制设计的高性能组网架构，业界开源的 GPU 集合通信库（比如 NCCL）并不能将网络的通信性能发挥到极致，从而影响大模型训练的集群效率。为解决星脉网络的适配问题，我们基于 NCCL 开发了高性能集合通信库 TCCL，在网卡设备管理、全局网络路由、拓扑感知亲和性调度、网络故障自动告警等方面融入了定制设计的解决方案。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7e/7e34421e488a4adf3ee961524bc2b9e5.png\" /></p><p></p><p>图 15. TCCL 集合通信性能</p><p></p><p>从上图实测的集合通信性能可以看出，在 AllReduce/AllGather/ReduceScatter 等常用通信模式下，针对星脉网络定制的 TCCL 都会带来 40% 左右的通信性能提升。</p><p></p><p></p><h2>驾驭高性能——最大以太 RDMA 网络的工程实践</h2><p></p><p></p><p>一匹马再快，若桀骜不驯，也难以称之为“良驹”。</p><p></p><p>为了驾驭高性能，我们先是实现了端网部署一体化以及一键故障定位，提升高性能网络的易用性，进而通过精细化监控与自愈手段，提升可用性，为极致性能的星脉网络提供全方位运营保障。</p><p></p><p></p><h3>端网部署一体化</h3><p></p><p></p><p>众所周知，RDMA 为业务带来了大带宽低时延，但同时其复杂多样化的配置也往往被网络运营人员诟病，因为一套错误的配置往往影响业务性能，还有可能会带来很多的不符合预期的问题。在星脉网络之前，据统计 90% 的高性能网络故障 case 均是配置错误导致的问题。出现这一问题的主要原因就是网卡配置套餐多，取决于架构版本，业务类型和网卡类型。在高性能网络运营平台提供的端网一体部署能力下，大模型训练系统的整体部署时间从 19 天缩减到 4.5 天，并保证了基础配置 100% 准确。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/13/13078cce08a9b032464775813a360635.png\" /></p><p></p><p>图 16. 高性能网络自动化部署</p><p></p><p>对此，我们先是实现了基础网络自动部署流程，整个自动部署的框架主要具备三方面的特点，第一是通过 API 提供单台 / 多台并行部署的能力。第二是在部署前，我们提供预校验的功能，一个是检查需要部署的机器上联交换机是否也配置了合理的拥塞控制相关配置，否则会影响到 RDMA 使用的性能。并将结果反馈给到用户。</p><p></p><p>最后是自动选择配置模板，我们会识别影响网卡配置模板的因素，包括架构版本，业务类型以及网卡类型，例如不同的网卡类型，配置的命令不同，选择的模板也不同。但这个流程对于用户侧是完全透明的。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f8/f827061139ab3c52bda31402ec0be4cd.png\" /></p><p></p><p>图 17. 高性能网络自动化验收</p><p></p><p>在网络与端侧的基础配置完成后，为了保证交付质量，运营平台会做进一步的自动化验收，其中包含：</p><p></p><p>1）端网基础环境校验：通过端网状态数据以及周边建设系统的信息采集，在硬件上判断 PCIe，光模块，连线等是否正确。在软件上通过配置审计校验端网配置是否正确。</p><p></p><p>2）RDMA 基础测试：通过运行 Perftest，并进行数据采集分析，判断网卡性能是否达到预期。</p><p></p><p>3）通信库性能测试：通过运行 NCCL/TCCL test，并进行数据采集分析，判断集合通信性能是否达到预期。</p><p></p><p>4）模型 &amp; 可靠性测试：运行典型模型训练，判断业务模型性能是否达到预期；通过设计端侧故障模拟、网络内故障模拟以及交换机配置错误等三类故障来判断业务可用性是否达到预期。</p><p></p><p>以上四个步骤全部通过后正式转为交付状态，否则会联动自动故障定位手段进行相关排查。</p><p></p><p></p><h3>全栈巡检，一键故障定位</h3><p></p><p></p><p>回顾过往，网络运营在服务器与交换机之间形成了分界线。然后在端网协同的高性能网络下，不仅仅需要考虑传统交换机上的问题定位，更要结合端侧“网卡，中间件等”的状态数据综合判断。在端侧能力具备的条件下，困扰了网络运营人员多年的问题“是否出现在网络交换机上”迎刃而解。同时也随着端侧运营能力的加强，针对不同的运营用户，自动排障的工具集也将多样化。</p><p></p><p>例如“一机八卡”的复杂拓扑下，连线与网段配置的正确率直接影响到应用是否能够成功建立，对此，我们通过封装交换机与服务器状态数据，联动网管拓扑信息，做到快速诊断与自动化检查。一方面在网络交付时屏蔽问题，另一方面快速定位运营中的网络挪线等操作带来的通信问题。</p><p></p><p>除了软件相关问题外，硬件故障也一样逃不出高网运营平台的法眼，例如在验收中发现部分网卡 8QP 带宽最多只能跑到 50Gbps 左右。通过故障池的沉淀，一键自动检测出 PCIE 带宽协商出错，定界为硬件故障，并自动推送到服务器运营相关人员进行网卡硬件更换。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e9/e999a365a61e856430376aaaa5e51055.png\" /></p><p></p><p>图 18. 高性能网络自动排障</p><p></p><p>高性能网络一键故障定位提供了两方面的功能，一方面可以快速定界问题所向，精准推送到对应团队的运营人员（网络 or 业务），减少团队之间的沟通成本，划分责任界限。另一方面可以一键快速定位问题根因，并给出解决手段。</p><p></p><p>整体系统具备层次化多维度的特征，通过端侧服务器以及交换机上的各种计数，向上逻辑封装抽象为子功能，例如带宽校验 &amp; 丢包校验等。之后继续向上逻辑封装，形成定位与定界的场景，底层复杂的技术与逻辑彻底透明化，自下而上，最终呈现到用户的只有简单易用的场景按钮。目前高性能网络运营平台已支持“性能不足”、“业务丢包”、“配置异常”、“连接建立不成功”四个维度的一键故障定位，优雅地为高性能网络业务提供一键自检，健康可视等功能。</p><p></p><p></p><h3>业务无感秒级网络自愈</h3><p></p><p></p><p>一些网络故障（例如静默丢包）的发生是不可被预期的，在网络故障演练时发现，一些网络故障（例如静默丢包）发生后通信库就会出现超时，导致训练业务进程长时间卡死，虽然可以依靠拉起定期的保存的 checkpoint，但是也需要回退版本，损失精度，且整个过程需要几十分钟来加载和推送参数等。此前我们通过网络上的各种探测手段，或是基于探针，或是基于设备状态，加上控制器路由隔离手段，将故障自愈时间控制在 20s 以内。然而在面对高性能业务的秒级自愈要求下，我们转变了避障思路，需求起源于业务，那么为何不把避障的主动权交于业务呢？为了让极致性能恒久，我们推出了秒级故障自愈产品——“HASH DODGING”。</p><p></p><p>我们创造性地提出基于 Hash 偏移算法的网络相对路径控制方法。即，终端仅需修改数据包头特定字段（如 IP 头 TOS 字段）的值，即可使得修改后的包传输路径与修改前路径无公共节点。该方案可在网络数据平面发生故障（如静默丢包、路由黑洞）时帮助 TCP 快速绕过故障点，不会产生对标准拓扑及特定源端口号的依赖。也可用于保证多路径协议（如 MPTCP）中各子流均匀负载到不同网络节点，避免性能退化。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c2/c2732014de8807a141db2eda2010cac7.png\" /></p><p></p><p>图 19. 单路径传输协议使用本方案实现确定性换路</p><p></p><p>通过端网协同，我们先是在端侧实现了协议栈层面的 TCP&amp;RDMA 状态检测，通过内核获取协议栈状态信息。从而细粒度的获得业务流吞吐、丢包等信息，将故障发现降低到 600ms 以内。其次在故障换路上，相对于更换五元组改变 hash 结果的不确定性，我们在自研交换机上实现了基于 HASH 偏移的确定性换路特性，业务可以通过更换魔术字来确保 100% 更换到其余路径上。当发生静默丢包时，端侧无需依赖于网络，自身快速秒级内避障。</p><p></p><p></p><h2>结语</h2><p></p><p></p><p>未来随着 GPU 算力的持续提升，GPU 集群网络架构也需要不断迭代升级，才能保证系统算力的高利用率与高可用性。星脉高性能计算网络作为腾讯大规模训练集群的重要基石，会持续在超带宽、异构网络通信、通信库定制加速、智能监控等技术上不断创新，为 AI 大模型训练构筑可靠的高性能网络底座。</p><p></p><p>今日好文推荐</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651151229&amp;idx=1&amp;sn=8e2eb0e76be7f160f94e830eaa99ba3b&amp;chksm=bdb8a32e8acf2a3879bbfca1c073c640efa7d110052d51ff55259e199a76d5f5c9ca41ab4057&amp;scene=21#wechat_redirect\">远程协作、降本增效正成为过去，新的三年正在到来</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651151025&amp;idx=1&amp;sn=0eb5092609992ae51ba538b1f4a58c51&amp;chksm=bdb8a2e28acf2bf4144f14d0dc67e71d2d0d59f6b6d412a4888ec06f9db7129d5b2948827937&amp;scene=21#wechat_redirect\">想彻底改变云行业！Spark发源地UC伯克利分校再推开源项目应对云成本飙升：平均降至三分之一</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651150877&amp;idx=1&amp;sn=46d44e9ba141a65793284c8801ade6ed&amp;chksm=bdb8a24e8acf2b58d74549cdb0406106505f7fb6ff2a88981ddfc15f24affd09c9e164f0c309&amp;scene=21#wechat_redirect\">你的Flutter应用该考虑迁移代码了：Dart 3将在2023年成为100%健全的空安全语言</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651150838&amp;idx=1&amp;sn=4915ac418c5c39ccf153fb9c0273db83&amp;chksm=bdb8a1a58acf28b379c0a19edb84433459b53ee89c11a7570eb21b7c410d1cfd63242ca79e6b&amp;scene=21#wechat_redirect\">重磅！阿里开源自研高性能核心搜索引擎Havenask</a>\"</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/93/93a6e30a75e8e663d639c54513765ef5.gif\" /></p><p></p>",
    "publish_time": "2022-12-17 13:25:49",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "re:Invent 2022 全回顾：看见云计算的力量，透视未来的云计算",
    "url": "https://www.infoq.cn/article/0O8eBz5ZJAbO3EiTbYwR",
    "summary": "<p>不知不觉， re:Invent 已经走过了 11 个年头。11 月 28 日，一年一度的 re:Invent 2022 全球大会开幕。</p><p></p><p>这是自 2019 年疫情以来的首次现场活动，因此也格外有意义。据悉，re:Invent 2022 吸引了约 50000 人现场参加，与疫情前的水平相当。而线上参加的人数超过 300000 人。</p><p></p><p>这场为期五天的云计算盛会又给大家带来了很多新的惊喜。</p><p></p><p></p><h2>重要发布综述</h2><p></p><p></p><p>在 re:Invent 2022 上，亚马逊云科技推出了广泛的新应用程序和产品增强功能，旨在优化数据分析和治理，并加强计算基础设施，发布了涵盖存储、计算、分析、机器学习、数据库和安全服务的新服务和功能，并首次涉足供应链管理。</p><p></p><p>亚马逊云科技首席执行官 Adam Selipsky 在“如何借助云的力量，在未知领域抓住机遇并茁壮成长”的主题演讲中表示:“到目前为止，亚马逊云科技大多数创新都是通过倾听和回应客户来推动的”。</p><p></p><h3>Serverless 迎来里程碑式创新</h3><p></p><p></p><p>近两年，Serverless 概念迅速蹿红。去年，CNCF 发布的《2020 年度中国云原生调查报告》显示，Serverless 架构正在持续增长，31% 的企业在生产中使用Serverless，41% 的企业正在评估，12% 的企业计划在未来 12 个月使用。</p><p></p><p>作为Serverless 技术的先驱，Amazon Lambda 在采用率方面一直保持领先地位。公开数据显示，已有上百万家客户在用 Amazon Lambda 来构建服务。</p><p></p><p>如今，亚马逊云科技已领跑完成 Serverless 在云服务上的全面布局，从计算、存储、应用集成、数据库、数据分析、人工智能等多个服务领域全面推进 Serverless 进程。</p><p></p><p>在今年的 re:Invent 2022 上，亚马逊云科技进一步发布了 Amazon Lambda SnapStart ，将冷启动时间缩短了 90%，让用户几乎可以无感知地实现应用扩展。</p><p></p><p>据介绍，Lambda SnapStart for Java 可以将延迟敏感型应用程序的启动性能提高多达 10 倍，无需额外费用，而且通常无需更改函数代码。</p><p></p><p>冷启动延迟主要由函数初始化过程造成，包括下载函数的代码、启动运行时等。借助 SnapStart，Lambda 会在用户发布函数版本时初始化函数。Lambda 采用 Firecracker microVM 初始化执行环境的内存和磁盘状态的快照，加密快照，并缓存它以实现低延迟访问。当第一次调用函数版本时，随着调用的增加，Lambda 会从缓存的快照中恢复新的执行环境，而不是从头开始初始化它们，从而改善启动延迟。</p><p></p><p>亚马逊云科技公用计算高级副总裁 Peter DeSantis 在主题演讲中指出，Lambda（以及所有其他 Serverless 平台）的构建目标之一是应对业务峰值的挑战。凭借其 Firecracker microVM，亚马逊云科技已经将冷启动时间从几秒缩短到不到一秒。现在，亚马逊云科技承诺通过使用 Firecracker 的快照功能可将冷启动时间缩短 90% 。</p><p></p><p>亚马逊云科技还宣布推出了适用于 Amazon OpenSearch Service 的Serverless 选项预览版，使客户无需管理集群即可轻松运行大规模搜索和分析工作负载。它能自动配置和扩展底层资源，即使是最苛刻和不可预测的工作负载也能提供快速数据摄取和查询响应，无需配置和优化集群。</p><p></p><p>借助 Amazon OpenSearch Serverless，用户无需考虑难以提前了解的因素，例如查询的频率和复杂性或预期分析的数据量，可以专注于使用 OpenSearch 来探索数据并从中获取洞察，而不是管理基础架构。用户还可以开始使用熟悉的 API 来加载和查询数据，并使用 OpenSearch Dashboards 进行交互式数据分析和可视化。</p><p></p><p>Amazon OpenSearch Serverless 也填补了亚马逊云服务 Serverless 分析产品组合最后的空白，这意味着现在亚马逊云科技提供的所有的数据分析服务已全部实现了 Serverless 化。</p><p></p><p>亚马逊云科技Serverless计算副总裁 Holly Mesrobian 在其演讲中介绍了 Serverless 多项重要创新。其中有一项是 Amazon Inspector 开始提供对 Amazon Lambda 的支持，为 Serverless 计算工作负载添加了持续的自动化漏洞评估。借助此扩展功能，Amazon Inspector 现在可以自动发现所有符合条件的 Lambda 函数，并识别 Lambda 函数代码中使用的应用程序包依赖项中的软件漏洞。</p><p></p><h3>大数据驱动云技术演进</h3><p></p><p></p><p>re:Invent 2022 的一个主题是简化企业的数据管理和分析。为此，亚马逊云科技宣布了十几项数据服务更新。</p><p></p><p>其中包括两项重要的新功能 —— Amazon Aurora 支持与 Amazon Redshift 实现 Zero ETL 集成，以及 Amazon Redshift 支持与 Apache Spark 集成，不再需要数据的提取、转换、加载（ETL）过程。</p><p></p><p>亚马逊云科技还发布了一项名为 Amazon Data Zone 的新数据管理服务预览版，旨在帮助企业对存储在亚马逊云科技、本地和第三方来源的数据进行分类、发现、共享和管理。</p><p></p><p>此外，为了帮助企业与合作伙伴进行数据协作，亚马逊云科技推出了一项名 Amazon Clean Rooms 的新服务。同时还推出了 Amazon Glue Data Quality (Preview) ，可以进一步提升数据质量，萃取数据价值，保证数据治理。</p><p></p><p>数据治理需要有非常高的数据质量规范，然而越高的规范代表了越高的管理成本，非常费时费力，有时要花几天，甚至几周的时间。Amazon Glue Data Quality 能识别丢失、陈旧或不良数据，将这些手动的数据质量工作从几天缩短到几小时。</p><p></p><p>亚马逊云科技也为其统一商业智能服务 Amazon QuickSight 添加了新功能，包括可以通过名为 “QuickSight Q”的新功能进行自然语言查询的能力。添加到 QuickSight 的其他功能还包括生成分页、大型数据集的报告和快速分析。</p><p></p><p>如今，网络攻击不断激增，而数据又已成为企业的命脉，因此亚马逊云科技针对当前形势发布了其数据安全服务的更新。</p><p></p><p>其中一项重大发布是推出了新的网络安全服务 Amazon Security Lake ，该服务能够自动将来自云和本地来源的安全数据集中到客户在亚马逊云账户中专门构建的数据湖中。</p><p></p><p>其他安全功能更新还包括对自动化漏洞管理服务 Amazon Inspector 及其机器学习安全和隐私服务 Amazon Macie 的更新。</p><p></p><h3>AI 能力加成</h3><p></p><p></p><p>亚马逊云科技继续完善其 AI 应用程序，宣布对其 SageMaker 机器学习服务进行了更新，以改进该服务的治理属性。</p><p></p><p>作为这些更新的一部分，亚马逊云科技推出了 Amazon SageMaker Role Manager，旨在让管理员更轻松地控制访问并为用户定义权限。</p><p></p><p>此外，它还向 SageMaker 添加了一个名为 Amazon SageMaker Model Cards 的新工具，以帮助数据科学团队简化模型信息收集。</p><p></p><p>该服务还添加了 Amazon SageMaker Model Dashboard，为 SageMaker 提供一个中央界面来跟踪机器学习模型。</p><p></p><p>亚马逊云科技也为 Amazon SageMaker Studio Notebook 添加了数据准备功能，并在 SageMaker 中增加了一个新的工作区，旨在让数据科学团队实时阅读、编辑和运行 Notebook。</p><p></p><p>为了帮助企业获得更多的数据回报， 亚马逊云科技也在一系列其他服务中添加了新的人工智能功能，包括 Textract、Transcribe、Kendra、CodeWhisperer 和 HealthLake。</p><p></p><p>比如，为了帮助企业提供更好的客户服务和体验，亚马逊云科技更新了其自动语音识别 (ASR) 服务 Amazon Transcribe，以提供实时呼叫分析。</p><p></p><p>与此同时，亚马逊云科技 通过添加支持 HTML 表格搜索的新功能，增强了其基于人工智能的企业搜索服务 Amazon Kendra。</p><p></p><h3>计算服务更新</h3><p></p><p></p><p>随着企业收集、存储和处理更多数据，他们的计算需求也必然会增长。在认识到这一趋势后，亚马逊云科技发布了其计算服务的多项更新以及一些旨在运行极其繁重的工作负载的行业特定功能。</p><p></p><p>为了提升其高性能计算服务，亚马逊云科技宣布推出 Amazon EC2 Hpc6id 实例，它可以支持密集型工作负载，具有更高的每 vCPU 计算性能以及更大的内存和本地磁盘存储，以减少数据密集型作业的完成时间和工作量。</p><p></p><p>此外还推出了用于高性能计算（HPC）的新芯片— Graviton3E 和下一代 Nitro 智能网络芯片，以及可以充分发挥新硬件性能的新实例。</p><p></p><h3>真实世界模拟</h3><p></p><p></p><p>动态 3D 实验可以帮助跨行业（交通、机器人、公共安全等）的组织，了解可能的现实世界结果并为他们进行培训。例如，确定工厂车间的新工作流程，运行不同的自然灾害响应场景，或考虑不同的道路封闭组合。</p><p></p><p>但复杂的空间模拟需要大量的计算资源，而且跨计算实例集成和扩展、模拟数百万个交互对象可能是一个困难且昂贵的过程。</p><p></p><p>为了帮助客户构建、操作和运行大规模空间模拟，亚马逊云科技推出了 Amazon SimSpace Weaver。这是一种全新的、完全托管的计算服务，可帮助用户在云上运行大规模空间模拟，而无需管理复杂的基础设施。它允许用户将空间模拟部署到具有许多数据点的模型系统，例如城市的交通模式、场地中的人群流动或工厂车间的布局中。</p><p></p><p>亚马逊云科技表示，SimSpace Weaver 面向希望对超过一百万个实体（人、汽车、交通信号灯、道路…）运行复杂 3D 模拟的企业。“就像一个真实的城市，模拟本身就是一个广阔的‘世界’”。亚马逊云科技正在为每个行业赋予空间模拟的能力，使客户能够更轻松地模拟从交通模式到公共交通网络再到供应链基础设施的一切。</p><p></p><h2>重要变化解读</h2><p></p><p></p><h3>数据战略的新变化</h3><p></p><p></p><p>大数据可以说是这次 re:Invent 发布的一个重要核心主题。</p><p></p><p>亚马逊云科技大中华区解决方案架构部总监代闻在接受 InfoQ 采访时表示，此前，亚马逊云科技一直在提的战略是云原生的数据战略。这一战略包括云原生的数据基础设施、数据一体化的融合、数据驱动智能化的创新、保证数据安全和数据治理等。</p><p></p><p>代闻感受到，在今年的 re:Invent 上，数据战略在原先的基础上，又做了进一步提升，尤其是在数据底盘上。此前亚马逊云科技一直强调数据的跨域流动、数据的无缝流转等，这次 re:Invent 发布的内容则进一步侧重数据可见性，例如某一区域的部分数据不止区域可见，还能做到全球可见，并在安全的情况下可用。此外更进一步强调了数据的无缝流转，这次大会发布的内容非常强调专门构建的产品，以及这些产品如何给客户最好的体验。</p><p></p><h3>首次涉足供应链</h3><p></p><p></p><p>另一个值得关注的变化是，亚马逊云科技首次围绕供应链发布了新产品。</p><p></p><p>看到了供应链应用场景需求增长的机会，亚马逊首次涉足供应链管理，发布了集成机器学习的云应用程序，名为 Amazon Supply Chain，以帮助经常使用多个 ERP 系统的大型企业获得供应商、库存、物流和其他供应链相关组件的统一视图。</p><p></p><p>近年来，因为广泛的资源短缺、地缘政治、自然事件等因素，供应链经历了前所未有的供需波动。供应链中断给企业带来不小的压力，要求企业针对潜在的供应链不确定性进行规划，并在降低成本的同时快速响应客户需求的变化。当企业对供应链风险（例如，组件短缺、航运港口拥堵、意外需求激增或天气中断）的预测不充分时，他们可能难以应对库存成本过高或缺货的情况。</p><p></p><p>新的 Amazon Supply Chain 服务通过跨多个供应链系统组合和分析数据来帮助简化这一过程。亚马逊云科技称，借助这一新服务，企业可以实时观察运营，快速识别趋势，并生成更准确的需求预测。</p><p></p><p>这项新服务基于 Amazon.com 近 30 年的物流网络经验。它使用预训练的机器学习模型来理解、提取和聚合来自 ERP 和供应链管理系统的数据。然后将信息实时上下文化，突出显示每个位置的当前库存选择和数量。机器学习模型显示潜在的库存短缺或延迟，并在出现风险时提醒用户。一旦发现问题，Amazon Supply Chain&nbsp;就会根据解决风险的百分比、设施之间的距离以及可持续性影响提供建议的操作，例如在不同地点之间移动库存。</p><p></p><h3>基础设施：专注高性能的同时，更专注低功耗、构建生态</h3><p></p><p></p><p>代闻观察到，今年亚马逊云科技在芯片等基础设施方面的发布，可以说更往前走了一步。这主要表现在两个方面：一是真正继续践行“低功耗、高性能”的准则，很多新发布的硬件在关注高性能的同时，也非常关注低功耗，如单瓦特能提供什么样的算力，这也与我们国家在提的碳融合、碳达峰的理念相契合；第二是更关注生态，业务和数据是跑在基础设施上的，新发布的基础设施能否提供最终的业务价值很重要。对企业客户来说，业务可以直接无缝迁移到亚马逊云科技的基础设施上，这样既节约成本，又获得了良好的性能。</p><p></p><h2>透视云计算的未来</h2><p></p><p></p><p>re:Invent 可谓是云计算领域的“春晚”，也是云计算行业的风向标。岁末年尾之际，透过这场大会，我们在看到云计算在过去一年里的发展现状的同时，也能够感知到接下来云计算的发展趋势。</p><p></p><h3>数据量剧增，对云计算的灵活性要求提高</h3><p></p><p></p><p>亚马逊云科技首席执行官 Adam Selipsky 在主题演讲中强调了数据的重要性。</p><p></p><p>Adam 认为，数据增长的速度预计只会进一步加快，因此，对那些需要随着数据增长而扩大规模的组织来说，云计算所能提供的灵活性是非常有吸引力的。“分析人士预测，在未来五年内，我们创造的数据量将是数字时代开始以来的两倍多，”他说，“管理数据的规模和增长对每个组织来说都是巨大的挑战和机遇。”</p><p></p><p>企业需要对数据做到很好的管理，来保证数据是安全的，同时还要去理解这些数据，探索这些数据可以给企业带来的各种潜力。</p><p></p><p>Adam 认为，在数据管理领域需要有合适的工具、有效的数据集成、规范的数据治理和深入的业务洞察力。</p><p></p><p>为此，亚马逊云科技针对性地构建了多款工具。在数据分析服务方面，亚马逊云科技宣布正式推出 Amazon OpenSearch Serverless 版本；在数据集成方面，Adam 重点提到了Zero ETL， ETL（数据提取、转换和加载）是重复性无差别的繁重工作，因此亚马逊云科技认为 Zero ETL 必将是最终目标；在数据管理方面，亚马逊云科技宣布推出一项用于分类、发现、共享和管理数据的数据管理服务 Amazon DataZone；为实现业务洞察，Adam 宣布使用 Amzon Quicksight Q 应用探索新的基于机器学习的预测服务发布，以探索更广阔的数据领域。</p><p></p><p>Adam 表示，亚马逊云科技在整个数据之旅中做了大量投入，目标是帮助客户更好地释放数据的价值。</p><p></p><h3>异步计算架构的世界</h3><p></p><p></p><p>亚马逊副总裁兼 CTO Werner Vogels 在主题演讲中强调了异步的概念。“这个世界上绝对没有什么是同步的，”他说，“如果是这样，我们真的不会喜欢它。” Vogels 表示，异步的概念可以用于构建计算机系统，以及开发整个数字世界。异步计算机体系结构提供的选项和变化可能意味着即使出现数字灾难，也有可能向前推进。“当我想到异步时，”他说，“就是我们应该在任何情况下都取得进展，无论发生什么。”</p><p></p><p>Vogels 说，随着 S3 产品的开发，异步的概念就已经在亚马逊发挥作用。“我们希望确保该系统在任何情况下都能完美应对”，“无论涉及什么；不管有什么故障。” 然而，他还表示，乍一看，就延迟和吞吐量而言，计算同步似乎更容易。“同步是一种简化。它只是让我们更容易编写程序的东西，”Vogels 说，但有一个警告。“同步是一种幻觉。这是我们在一个异步的世界上构建的东西。”</p><p></p><p>人们通常认为异步编程很困难，所以操作系统往往具有受限的接口。Vogels 说：“如果你想写入磁盘，在写入块之前你会被阻塞。” 变化在 1990 年代开始出现，操作系统从头开始设计，以向世界展示异步性。Windows NT 可能是第一个将异步通信或与设备交互作为内核第一原则的系统。Linux 直到 2000 年代初才采用异步技术。</p><p></p><p>异步的好处是，与同步的错觉相比，它是自然的。Vogels 说，当计算系统紧密耦合在一起时，如果出现问题，可能会导致广泛的故障。对于异步系统，一切都是解耦的。“最重要的是，这是一种无需更改任何其他组件即可非常轻松地发展的架构，”他说。“这是隔离故障的一种自然方式。即使任何组件出现故障，整个系统将继续工作。”</p><p></p><p>Vogels 还表示，异步架构是不断演进的，而不是一蹴而就的。“分解成小的、易于理解的构建块是构建这些异步、松耦合、事件驱动系统的基本部分。”</p><p></p><h3>机器学习的六大趋势</h3><p></p><p></p><p>亚马逊人工智能和机器学习副总裁兼总经理 Bratin Saha 概述了这家云巨头看到的六大关键趋势，这些趋势有助于推动 2022 年及以后的机器学习技术创新。</p><p></p><p>亚马逊云科技称其 AI/ML 服务拥有超过 100,000 名客户。这些服务分布在三个层级：机器学习基础设施服务，使组织能够构建自己的模型；SageMaker，提供构建应用程序的工具；以及针对特定用例的专用服务，例如转录。</p><p></p><h4>趋势 1：模型复杂度不断提高</h4><p></p><p></p><p>近年来机器学习模型的复杂度呈指数级增长。衡量机器学习模型复杂程度的一种方法是计算其中的参数数量。Saha 解释说，参数可以被认为是嵌入在机器学习模型中的值变量。2019 年，当时最先进的机器学习模型大约有 3 亿个参数。快进到 2022 年，最好的模型的参数量现在已经超过 5000 亿。“换句话说，在短短三年内，机器学习模型的复杂程度增加了 1600 倍。”</p><p></p><p>这些庞大的模型就是现在通常所说的基础模型。使用基础模型方法，可以使用海量数据集对机器学习模型进行一次训练，然后针对各种不同的任务进行重复使用和调整。因此，企业可以通过更易于采用的方法从日益复杂的过程中受益。“Foundation models 将机器学习的成本和工作量降低了一个数量级。”</p><p></p><h4>趋势 2：数据增长</h4><p></p><p></p><p>越来越多的数据和不同类型的数据被用于训练机器学习模型。组织现在正在构建经过结构化数据源（如文本）以及非结构化数据类型（包括音频和视频）训练的模型。为了将不同的数据类型放入机器学习模型中，亚马逊云科技开发了多种服务来帮助训练模型。Saha 重点强调了其中一项工具是 SageMaker Data Wrangler，它可以帮助用户使用一种适用于机器学习训练的方法来处理非结构化数据。</p><p></p><h4>趋势 3：机器学习产业化</h4><p></p><p></p><p>亚马逊云科技 也看到了机器学习产业化的趋势。这意味着机器学习工具和基础架构更加标准化，使组织能够更轻松地构建应用程序。Saha 表示，机器学习工业化很重要，因为它可以帮助组织实现开发自动化并使其更加可靠。随着组织构建和部署更多模型，工业通用方法对于扩展至关重要。“即使在亚马逊内部，我们也在使用 SageMaker 进行工业化和机器学习开发。”</p><p></p><h4>趋势 4：针对特定用例的机器学习支持的应用程序</h4><p></p><p></p><p>针对特定用例的专用应用程序，机器学习的支持也在增加。Saha 表示，亚马逊云科技的客户已要求供应商自动化常见的机器学习用例。例如，亚马逊云科技（和其他供应商）现在提供语音转录、翻译、文本转语音和异常检测等服务。这些为组织提供了一种更简单的方法来使用机器学习支持的服务。</p><p></p><h4>趋势 5：负责任的人工智能</h4><p></p><p></p><p>负责任的人工智能也有增长的趋势和需求。随着人工智能和机器学习的发展，人们意识到必须负责任地使用它。从亚马逊云科技的角度来看，负责任的人工智能需要具备几个关键属性。系统需要公平，无论种族、宗教、性别和其他用户属性如何，系统应该对所有用户平等运作。机器学习系统还需要可解释，以便组织了解模型的运作方式。另外也需要治理机制，以确保负责任的人工智能得到实践。</p><p></p><h4>趋势 6：机器学习民主化</h4><p></p><p></p><p>推动机器学习向前发展的最后一个关键趋势是使技术民主化，使更多人可以获得工具和技能。“客户告诉我们，他们通常很难招聘到需要的所有数据科学人才。”在 Saha 看来，民主化挑战的答案在于继续开发低代码和用例驱动的工具，以及展开相应的教育工作。“亚马逊云科技正在投资培训下一批机器学习开发人员，”Saha 表示：“亚马逊承诺，到 2025 年，我们将通过免费的云计算技能培训帮助超过 2900 万人提高他们的技术技能。”</p><p></p><p>在亚马逊云科技开发者社区官网，我们发布了关于本次 re:Invent 更全面的信息资讯，<a href=\"https://dev.amazoncloud.cn/reinvent2022?sc_channel=infoq\">点击链接</a>\"即可访问。</p><p></p>",
    "publish_time": "2022-12-17 18:37:53",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]