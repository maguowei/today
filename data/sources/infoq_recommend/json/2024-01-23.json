[
  {
    "title": "规则大作战：企业如何走出合规迷宫",
    "url": "https://www.infoq.cn/article/k7DvizO0LcLW4TwycKeM",
    "summary": "<p></p><blockquote>本文要点：合规性是风险管理的基础。如果企业能够驾驭棘手的规则，并且以符合道德的方式行事，那么就能在竞争中脱颖而出。从“合规性优先”的方式转变到“风险优先”的思维模式，要认识到合规性不应被孤立地看待，而应该将其作为更广泛的风险管理战略的一个组成部分。“风险优先”是一种理念，重点是识别、处理和管理最高的合规性风险，并通过控制、政策和标准的操作过程对其进行优先排序。风险优先的方法能够增强组织的风险意识，巩固组织风险管理的基础，使其成为所有企业决策的一部分。如果组织能够为员工在管理合规性方面的职责上提供明确的指导，就能培养员工在组织内部进行探索和革新。</blockquote><p></p><p>&nbsp;</p><p></p><h2>引言</h2><p></p><p>合规性是现代商业运作的基础，也是其成功的组成部分。它涉及到<a href=\"https://www.techtarget.com/searchdatamanagement/definition/compliance\">遵守</a>\"法律法规要求、行业标准和合乎道德的商业实践。合规性对于组织管理风险、防止法律惩罚和声誉受损以及提供竞争优势都至关重要。在当今的商业环境中，社会责任和道德行为比以往任何时候都更加重要，合规性已经成为组织成功的关键。组织可以通过优先考虑合规性来维护其声誉并确保长期的可持续性。</p><p>&nbsp;</p><p>合规性的意义不仅仅是明确列出的义务清单，它还是有效管理风险的基础，是抵御潜在的法律风险和声誉受损的屏障。在当今的商业世界中，企业必须遵守社会责任和道德规范，遵守规则变得至关重要。如果企业能够驾驭棘手的规则，并且以符合道德的方式行事，那么就能在竞争中脱颖而出。</p><p>&nbsp;</p><p>随着业务的不断发展，企业从传统的“合规性优先”转换成了更具动态性和前瞻性的“风险优先”的思维方式，模式正在发生着变化。这种文化转移意识到，合规性虽然重要，但是不应被孤立地看待，而应该将其作为更广泛的风险管理战略的一个组成部分。这种变革不仅是理念上的调整，还是一种实践上的变更，因为组织要积极主动地识别、了解和降低风险，从而在不断变化的商业环境中增强自身的风险意识和适应能力。</p><p>&nbsp;</p><p>本文深入探讨了企业进行文化转型的重要性。这种转变包括从狭隘地重视合规性转变为更广泛、更具战略性眼光的对风险的认识。</p><p>&nbsp;</p><p>这种转变不仅仅是一种业务，而且还能培育一种文化，这种文化不仅能够满足监管的需要，同时又能使组织在充满不确定性的环境中发展壮大，从而在这种变化、不确定性和风险中确保组织的长期可持续发展。</p><p>&nbsp;</p><p>本文阐述了企业如何满足预期并进一步优化，从而开创具备韧性、创新性和持续成功的新时代。</p><p></p><h2>合规性至上</h2><p></p><p><a href=\"https://www.linkedin.com/pulse/compliance-mindset-vs-relationship-21-ways-help-calibrate-peter-rufus\">合规性优先的思维模式</a>\"将遵守法律、法规和行业标准置于决策和运营的其他考虑因素之上。<a href=\"https://www.perillon.com/blog/10-most-regulated-industries-in-the-us\">监管严格的组织</a>\"，如金融服务、交通运输和医疗保健，通常会采用这种方式，以确保履行法律和道德义务，并最大程度降低面临处罚或法律诉讼的风险。这需要积极识别并解决潜在的合规性问题，同时建立并实施流程管理和控制措施，以保持合规性。<a href=\"https://medium.com/the-seek-blog/proactive-vs-reactive-approach-to-compliance-54af31241f4d\">这种方式</a>\"的重点是遵守法规和要求，达到最低标准，以避免法律和声誉上的严重后果。在合规性优先的思维模式中，组织将风险管理视为成本中心，而不是战略机遇。鉴于如下的一个或多个原因，组织往往非常重视以合规性为导向的态势：</p><p>&nbsp;</p><p>企业和组织承担了强有力的法律和监管义务，这样能够在<a href=\"https://reciprocity.com/blog/heres-why-regulatory-compliance-is-important/\">很大程度上</a>\"避免法律和财务处罚、声誉受损和运营中断。关注合规性<a href=\"https://uprighthc.com/blog/5-key-reasons-why-your-business-needs-compliance\">有助于组织保持良好的声誉，并通过展示对道德和业务实践的责任心，与客户和股东建立信任</a>\"。<a href=\"https://www.leapxpert.com/why-is-compliance-risk-management-important/\">注重合规性的姿态</a>\"有助于组织更有效地管理、减轻和转移风险。注重合规性有助于最大限度地减少风险对组织运营和声誉的潜在负面影响。<a href=\"https://ca.indeed.com/career-advice/career-development/why-compliance-is-important\">注重合规性</a>\"的组织会努力遵守适用的规则和法规，这有助于使他们避免巨额罚款和破坏性的法律后果。此外，合规性还有助于降低风险，减少风险管理相关的成本。<a href=\"https://www.financierworldwide.com/how-to-retain-customers-trust-the-importance-of-compliance#.ZBGuIbTMLdo\">在客户和股东眼中</a>\"，注重合规性的组织更负责任、更值得信赖，这使得他们比那些不太遵守法规的组织更具优势。</p><p>&nbsp;</p><p>尽管这种以合规性为重点的方式有很多的收益，但是也带来了一些组织必须要注意的挑战。其中，包括如下的挑战：</p><p>&nbsp;</p><p>缺乏灵活性：合规性优先的思维模式会降低组织的适应性，以及适应不断变化的业务和经济环境的能力。他们必须专注于满足法律和监管的要求，这最终会使得它们<a href=\"https://www.bizagi.com/en/blog/governance-compliance/why-agility-is-the-key-to-regulatory-compliance\">丧失应对不断变化的业务环境的灵活性</a>\"。官僚主义：采用<a href=\"https://www2.deloitte.com/us/en/insights/focus/behavioral-economics/compliance-challenges-public-sector-programs.html\">合规性优先的思维模式</a>\"会导致决策过程的层层累加，从而延缓决策和运营的速度，增加成本。阻碍创新：合规性优先的思维方式可能会<a href=\"https://www.forbes.com/sites/tendayiviki/2021/10/24/the-one-thing-legal-and-compliance-hate-about-innovation-teams/?sh=4cc4c0e76bf6\">扼杀创新和创造力</a>\"，因为如果组织认为某件事可能会违反法律法规，那么他们会不太愿意承担风险或尝试新事物。视野受限：合规性优先的组织可能专注于满足法律法规的要求，而忽视了其他重要风险或机会。对客户的关注度有限：合规性优先的思维模式可能会导致对客户需求缺乏关注，因为公司可能更注重满足法律法规的要求，而不是满足客户的需求。</p><p>&nbsp;</p><p>过分强调满足合规性要求的代价是很高的，而且不利于其他重要业务目标的实现。这种专注性会导致对合规性的狭隘和僵化关注，从而导致缺乏创新和冒险精神。它还可能导致畏惧和裹足不前的文化，使员工将合规性置于道德行为或客户满意度之上。虽然基于法律和道德的原因，合规性是必不可少的，但是一味追求合规性会阻碍组织的成长和发展。</p><p>&nbsp;</p><p></p><h2>案例研究：合规性优先思维方式的代价</h2><p></p><p>在许多引起广泛关注的案例中，合规优先的思维方式导致组织付出了高昂的代价，并造成了巨大的损失。</p><p>&nbsp;</p><p><a href=\"https://www.wsj.com/articles/volkswagen-tries-to-change-workplace-culture-that-fueled-emissions-scandal-11601425486\">大众汽车</a>\"：2015年，调查人员发现大众汽车在其柴油发送机中安装了软件，以欺骗排放测试。根据他们的陈述，该公司合规性优先的文化迫使员工以牺牲道德的行为为代价来达到排放的目标。<a href=\"https://www.delta-net.com/blog/equifax-a-tale-of-caution-about-bad-information-security-and-compliance-practices/\">Equifax</a>\"：2017年，Equifax遭遇了大规模的数据泄露事件，数百万客户的个人信息外泄。该公司只注重实现其合规性目标，而不是改善其系统和网络安全，这是数据泄露背后的众多驱动因素之一。</p><p></p><h2>构建韧性</h2><p></p><p>“风险优先”是一种<a href=\"https://ganintegrity.com/blog/what-a-risk-based-approach-means/\">理念</a>\"，重点是识别、处理和管理最高的合规性风险，并通过控制、政策和标准的操作过程对其进行优先排序。这种方式有助于将资源优先分配给合规性风险更高的领域。组织可以评估每种风险的可能性和影响，制定有针对性和高效的合规性策略。组织可以通过风险优先的合规性方式保持领先的位置，确保达到最高的合规性标准，并通过处理影响最大的合规性风险来避免代价高昂的后果。风险优先的组织化思维方式的优势包括：</p><p>&nbsp;</p><p>风险优先的理念可用于识别、优先处理和解决财务收益、合规性/法律、运营和声誉方面的问题。提升韧性，更好地应对突发情况所造成的干扰，并在不造成严重后果的情况下进行恢复。通过审慎的风险管理并帮助员工跳出固有思维方式，寻找创新性的解决方案，从而能够培养创新、实验和改进的文化。与风险意识较弱的竞争者相比，通过武装自己来应对突发事件和适应不断变化的市场条件，从而能够获得竞争优势。</p><p>&nbsp;</p><p>建立风险优先的合规性文化，包括在日常工作中为员工灌输一种优先考虑风险管理和合规性的思维方式。这种主动的方式能够加强组织的风险意识，并为将风险意识作为所有组织决策的一部分奠定基础。在下面的内容中，我们将讨论帮助组织建立风险优先的合规性文化所需的步骤：</p><p>&nbsp;</p><p>企业必须确保员工理解风险管理和合规性在其工作角色中的重要性。治理、风险与合规（Governance, Risk, and Compliance，GRC）是该领域的专家。GRC必须能够准确描述和说明什么是风险，以及他们如何理解组织的合规性。企业应该为管理合规性风险和满足监管要求创建和维护明确的标准和指南。这些文档应该可以方便地供全体员工查阅，并在法规或风险发生变化时定期进行修订。这些文档再加上定期的培训，就能确保员工了解自己的责任，并能采取必要的措施降低合规性风险和遵守法规。员工应定期接受风险管理和合规性方面的指导。这种指导应该针对每位员工的特定角色和职责来开展，以便于他们能够识别、评估和降低在工作中所遇到的合规性风险。这种方式有助于确保员工具备处理风险和遵守法规的能力，从而降低产生不合规和相关风险的几率。创建一个开诚布公的沟通平台，帮助员工表达对合规性风险和违规行为的担忧。鼓励员工提出问题，并确保组织能够认真应对他们的担忧，这有助于识别和降低合规性风险，防止可能发生的商业损失。组织的领导者应该以身作则，遵循风险优先的合规性态度。他们应该激励和赞赏在工作中优先考虑风险管理和合规性而不影响交付质量的员工。领导者应该为员工树立积极的榜样，主动承担风险管理和合规性方面的责任和义务。企业必须定期审查和评估其风险管理和合规性流程，并识别需要改进的地方。鼓励员工提出改进建议，并在必要时实施变革。这种方法有助于确保风险管理和合规性流程保持有效性和时效性，降低不合规行为产生的可能性和相关的风险。表彰和庆祝风险管理和合规性方面的成功，这可以激励员工优先考虑风险管理和合规性。分享成功的案例，并将其作为范例，这可以鼓励员工效仿并保持风险管理和合规性方面的高标准。</p><p>&nbsp;</p><p>如果组织能够为员工提供关于合规性职责的明确和全面的指导，那么这可以为合规性管理打下良好的基础，从而促进员工在组织内部进行创新和改革。这种积极主动的交流方式能够为企业提供一个安全的空间，促成一种负责任的企业决策和遵守标准的文化，在面临市场竞争的条件下，这对于保持竞争力和适应性是至关重要的。此外，这还能培育一种免于互相指责的文化，从而提升员工专注度和竞争力。</p><p>&nbsp;</p><p>如果每个人都重视并勇于承担风险，在组织中就会产生主人翁精神和目标感，这有助于改善决策和提升领导效率。在充满活力的环境中，不断迎接挑战会为企业提供前进的动力，通过促进创新、鼓励尝试和犯错，并培育持续增长的文化，就能为企业的发展奠定基础。</p><p>&nbsp;</p><p>构建一种将风险管理和合规性放在首位的文化需要决心、团队合作和持续改进。在合规性方面，采取风险优先的态度可以降低风险，确保遵守法规，并保护组织的声誉。在当前瞬息万变、难以预测的环境下，组织必须首先考虑风险。通过遵循风险管理和合规性的基本原则，企业可以更好地识别和应对潜在的风险，保持合规性，并在面临质疑时取得成功。建立风险优先的文化对企业大有裨益，也是保证企业未来稳健发展的关键。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/risk-first-compliance/\">From Compliance-First to Risk-First: Why Companies Need a Culture Shift</a>\"</p>",
    "publish_time": "2024-01-23 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "OpenAI 背书的计算引擎迎里程碑：蚂蚁集团成功部署百万核心计算平台",
    "url": "https://www.infoq.cn/article/vT4lewlRgUMuFIbRULHz",
    "summary": "<p>Ray 是一个通用的分布式计算引擎，最初由 UC Berkeley RISELab 在 2016 年开源。创建该项目的团队是 RISELab 的 Ion Stoica 教授领导的技术团队，该团队曾经在早些年创建过另外一个颠覆性的计算引擎——Spark。相比 Spark，Ray 的接口设计源于更加底层的抽象，这使得 Ray 的应用场景更加通用。Ray 从诞生开始即全面拥抱 Python 生态，并在多年的发展中深耕 AI 分布式计算领域，形成了丰富的 AI 生态。在大模型引领的 AI 浪潮爆发之际，Ray 也在近一年迎来了高速的发展，吸引了业内大量的关注。很多业内人士了解 Ray 是从 OpenAI 对 Ray 的应用开始，但从 9 月底举办的 Ray Summit 可以看出，Ray 已经广泛应用于国内外的互联网巨头、传统软件行业、硬件厂商以及大模型创业公司。</p><p></p><p>蚂蚁集团从 2017 年开始深度参与 Ray 社区的建设，并在内部探索 Ray 的新计算场景，是最早将 Ray 应用于生产环境的企业。多年来，蚂蚁集团在 Ray 项目上持续投入，并坚定不移地走“开源路线”，与 RISELab 和 Anyscale（Ray 创始团队创办的公司）维持了多年的开源合作。去年，随着业务的高速发展，Ray 在蚂蚁迎来了新的里程碑：生产规模达到 100 万 CPU 核。本文将以此为背景，介绍 Ray 在蚂蚁的发展概况、Ray 规模化背后的技术挑战与实践、以及 Ray 在业界发展的现状和趋势。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e9/e9b04bf56721cbcc7686db4a1b408561.png\" /></p><p></p><p>蚂蚁集团 Ray 生产规模增长趋势</p><p></p><p></p><h3>背景介绍</h3><p></p><p></p><p>9 月下旬，Ray 社区一年一度的盛会「Ray Summit」在美国旧金山顺利举办。本次 Ray Summit 全面拥抱 AI 时代重大变革，将会议主题定为「THE LLM AND GENERATIVE AI CONFERENCE FOR DEVELOPERS」，足以说明 &nbsp;Ray 社区在大模型方向的重视与投入。作为 Ray 中文社区的运营团队，蚂蚁 Ray 团队也受邀参与本次会议。</p><p></p><p>在本次峰会上，我们披露了蚂蚁集团 Ray 生产规模的现状。首先在 Keynotes 上，UC Berkeley 的 Ion Stoica 教授在分享 Ray 相关增长数据时，披露了蚂蚁集团目前具有 50 万 CPU，4K GPU 的在线服务规模。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c8/c86e98152e922edb38d6b6dd12dd51c3.png\" /></p><p></p><p>IonStoica Keynotes</p><p> </p><p>其次在关于《How Ray Empowered Ant Group to Deliver a Large-Scale Online Serverless Platform》的主题分享中，蚂蚁 Ray 团队开源负责人宋顾杨和李冲揭露了蚂蚁集团整体的 Ray 生产规模已经达到了 100 万 CPU 核。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a8/a899aa4ed7038b04b1f086dff6f82055.png\" /></p><p></p><p>蚂蚁 Ray 团队在 Ray Summit 的分享</p><p></p><p>100 万核的 Ray 生产环境，是蚂蚁 Ray 团队在多年的研发投入、业务探索和开源共建后，达到的新的里程碑。这一里程碑标志着 通用分布式计算引擎 Ray 已经在蚂蚁内部实现了大规模落地，成为公司内部重要的分布式基础设施，为数字支付、数字金融和数字科技等多个方向的业务持续赋能。</p><p></p><p></p><h3>Ray 在蚂蚁的发展概况</h3><p></p><p></p><p></p><h4>Ray 在蚂蚁的发展历程</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/2e/2e72f61ec7888c1c1d539f301e8dac37.png\" /></p><p></p><p>蚂蚁集团 Ray 发展历史</p><p></p><p>蚂蚁 Ray 团队成立于 2017 年中旬，也就是在 Ray 开源后的一年。当时 Ray 的版本跟现在差距还比较大，架构设计上也有很多需要优化的。经常有社区的同学会问：“为什么蚂蚁在这么早期就决定投入到 Ray 这个开源项目中？是什么原因可以让团队下定决心？” 从笔者的角度来看，我们最初是被 Ray 清爽的 API 设计所吸引了。Ray 是一个基础设施层的引擎和编程框架，面向的主要是程序员群体。Ray 清爽、简洁的 API 设计可以说是分布式系统或者应用开发者的福音。Ray 核心的 API 从设计之初到现在，基本上没有改变过，也从侧面证明 Ray 创始团队对这套 API 优秀的设计。</p><p></p><p>Ray 在设计之初主要面向强化学习场景，因此只有 Python API 的支持。但考虑到蚂蚁内部的应用场景大部分是 Java 体系，蚂蚁 Ray 团队在早期做的一项比较重大的工程就是让 Ray 支持 Java API。其实说 Java API 并不准确，因为它并不像封装一套 API 那么简单，实际上是 Java 分布式编程框架。有了这套框架支持，我们支持了公司内部第一个更上层框架：流图计算 Geaflow。Geaflow 利用 Ray 灵活的 Java API 实现了一套流计算和图计算一体的融合计算框架，2018 年在蚂蚁的安全风控场景落地，取得了不错的效果。这也打响了 Ray 在蚂蚁集团发展的第一枪。</p><p></p><p>2019 年，我们落地了另外一个重要的融合计算场景，即在线学习。在线学习引擎融合了流计算、模型训练和模型部署三个场景，主要面向实时推荐场景，在支付宝首页推荐中落地后取得了不错的效果。在线学习引擎是一个多语言的框架，流计算通过 Ray 的 Java API 实现，模型训练通过 Ray 的 Python API 实现。为了实现多语言的融合引擎，我们在 Ray 中还支持了另外一个重要的功能：跨语言调用。简单的说，就是你可以在 Ray 的应用程序中，通过 Python 创建或者调用 Java 的 Task 或者 Actor，反之亦可。</p><p></p><p>2020 年，经过几年的发展，Ray 在蚂蚁内部已经初具规模。但当时我们的运维模式是单租户架构，随着业务越来越多，系统的问题慢慢显现出来：集群越来越多，Ray 版本越来越难收敛，作业启动成为越来越多的业务瓶颈，资源共享困难等。经过 Ray 团队深度的讨论之后，我们决定对整个架构进行升级，走多租户路线。多租户会给 Ray 集群带来诸多挑战，其中一个比较重要的问题就是资源隔离。因此在当时，我们做的一个比较重要的工作就是在一个大的 Ray 集群中支持划分虚拟集群。同年，运筹优化、科学计算、在线推理等场景也在蚂蚁落地。</p><p></p><p>随着业务的发展，多年来我们持续不断地对 Ray 进行完善和增强，也沉淀出了一批批新的 feature 和优化点，不断地贡献到了 Ray 社区主分支。到了 2021 年，蚂蚁对开源 Ray 内核的代码贡献已经超过了 26%。总结起来，贡献主要是以下方向：Java 分布式编程框架，C++ 分布式编程框架，跨语言调用，Actor task 流控，多租户，新版本 Ray Dashboard，Core Worker 架构，GCS Service 架构，GCS 调度，Actor Direct Call 等。</p><p></p><p>2022 年，我们将 Ray 的应用领域拓展到隐私计算领域，与蚂蚁隐私计算团队合作推出了开源框架“隐语”。后期随着 Ray 在隐私计算场景的探索，我们还孵化出了一个新的项目 RayFed。同年，Ray 也在公司内部函数计算场景落地，同时也在南网、浦发、中信等企业实现商业化输出。</p><p></p><p>时间来到 2023 年，我们正在做的事情是统一 AI 服务框架，希望通过基于 Ray 的一套引擎，同时支持传统推理、大模型推理和搜索引擎等重要场景的 AI 服务。</p><p></p><p></p><h4>Ray 在蚂蚁的架构体系</h4><p></p><p></p><p>历经多年的社区共建打磨，Ray 已经发展成为蚂蚁集团的计算基础设施底盘（作为高性能计算的分布式研发框架）。Ray 提供了灵活易用的分布式编程 API 及任务调度、编排、服务发现、多语言、跨语言、故障恢复、自动扩缩容、无感迁移、云原生等能力，使得上层计算引擎或分布式应用开发者只需关注计算 pattern 内的事情，专注于核心价值，极大地缩短了分布式应用从原型设计到生产上线的研发周期，提高了研发效率。</p><p></p><p>Ray 在蚂蚁的架构体系如下图：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/cb/cb9199556cd6669539b8afeba34ed7b4.png\" /></p><p></p><p>从整体上看，在最底层我们依托于 Kubernetes 提供服务。基于 Kubernetes 的 Pod 交付能力，我们将 Ray 打造成了一套通用计算底座，为上层提供通用分布式编程 API、运维组件和可观测组件。基于通用计算底座，我们提供了一系列基础库，除了社区原生库如 Ray Serve、Ray Data 等以外，还有许多自研的基础库，如 RayFed、Realtime 和视频算子库等。基于基础库，Ray 在蚂蚁内部衍生出了多种计算引擎并服务了多种业务场景，如：</p><p></p><p>在线服务（Ray Serving）：在线推理引擎，EventBus，金融核心。图计算（GeaFlow）：安全、数金 、图谱、社交、IOT。在线学习（Realtime）：智能营销、首页 Feed 流、Tab3。金融计算（Mars）：罗马、灯火。运筹优化（RayOR）：支付宝资金调度、欧拉。函数计算（FC）：推荐平台、数字科技、生态质量、算法中台、智能对话。隐私计算（SecretFlow/Fair/Morse）：微贷、阿里云医疗、国际。强化学习（RLlib）：Tab3、运筹。</p><p></p><h3>Ray 规模化背后的技术挑战与实践</h3><p></p><p></p><p></p><h4>Ray 规模化落地的挑战</h4><p></p><p></p><p>最近在支付宝 Tab3 生活频道刷到了罗翔老师的一个短视频，他说非常欣赏一位法官说的这样一段话：“贪腐就像蝙蝠一样，只在黑暗中翩翩起舞；而正义就像鲜花一样，只有在阳光下，才能看到它的美”，说的很有哲理，但这位法官最后因贪腐被双规了。所以他感慨道：“世界上最遥远的距离不是马里亚纳海沟到珠穆朗玛峰，而是「知道」和「做到」”。</p><p></p><p>作为挨踢工程师，我相信很多同学在工作中都遇到或参与过从 0 到 1 的分布式应用或系统研发，当你面对一个这样一个从 0 到 1 的分布式应用 / 系统构建时，你首先要做的事情就是技术选型，你知道组件通信可以用 GRPC 或 BRPC，你知道通信协议可以用 ProtoBuffer 或 FlatBuffer，你知道数据存储形式可以用 DB、Redis 或者自己裸写内存池，你也知道代码写完后要用 k8s 云原生来部署，但当你将要准备着手时，你会发现系统模块之间的衔接、集成、调试与部署有多么复杂，你会发现将所了解的知识进行系统性的转化是多么无力。</p><p></p><p>Ray 的出现拉近了「知道」与「做到」之间的距离，甚至将「不知道」到「做到」变为可能。</p><p></p><p>Ray 是一个通用的计算引擎，它提供了一套灵活易用的分布式编程 API，能快速构建各种分布式系统且不绑定计算范式，同时屏蔽分布式系统的底层细节，它提供的基础能力有：</p><p></p><p>组件通信：通过一个简单的 ray.remote 屏蔽所有底层 RPC 框架及协议的细节。资源调度：通过在类上进行简单的 @ray.remote 注解或者 .option(…) 调用就能指定任务执行所需要的资源或者调度策略。数据存储：通过简单的 put、get 及 wait 等接口就能管理任务的依赖及输出。多语言：支持 python、java 及 c++ 三种主流语言，同时每种语言之间可以相互调用，能很容易的将多种语言所组成的系统有机的衔接融合在一起。故障恢复：通过在类上简单的表注 @ray.remote 或者执行 .option(…) 调用就能指定实例 Failover 或者任务的重试次数。部署：通过 kuberay 与 k8s 深度集成，提供高效的云原生部署的效率。</p><p></p><p>利用 Ray 提供的基础能力可以很容易地构建出你的系统原型。在之前的文章中我们分享过一个 Case：我们尝试利用 Ray 所提供的 Actor、Task、资源管理、调度与运行时环境等能力构建了一个 AutoML Service Case ，与云原生开发方式相比，发现 Ray 对整体研发效率上提升非常明显。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/2e/2ec14450cfcba3199ba425e8367f1d30.png\" /></p><p></p><p>AutoML Service Case</p><p></p><p>上面 Case 仅是单个作业，对应社区的用法是一个 Ray 集群。蚂蚁目前总体 100 万核规模、实时长跑作业 8k+，那么面对这样规模的业务体量，面临的挑战有哪些呢？主要的挑战在以下几方面：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/37/373e1e056a7d8270174d9bd2a3e769f1.png\" /></p><p></p><p>Ray 规模化落地中的挑战</p><p></p><p>集群管理：面向上万个离在线作业，如何做好集群管理和服务是 Ray 团队面临的最严峻的挑战。多租户下会暴露 Ray 引擎诸多问题，如集群资源抢占、节点内物理资源隔离、定制化运行环境等。如何权衡隔离性、效率与利用率之间的关系往往是超大集群管理中的难题。并且随时 Ray 本身的迭代，如何做好版本管理和版本升级也是集群管理中重要的工作。一旦版本无法收敛，就需要研发团队同时维护多套代码，增加研发成本。</p><p></p><p>调度：从调度模式上看，Ray 原生的分布式调度在大规模 Actor 并发调度场景下存在效率问题（分布式决策冲突引起）；另外在 Java 业务中，JVM 的启动会成为 Actor 调度的瓶颈；在大规模 scale up 和集群重启场景，Pod 申请开销会占用大部分作业的启动时间，对时延敏感的在线业务不友好；原生的调度从策略上也很难满足所有用户的需求，需要更加丰富的亲和性和反亲和性调度策略；Ray 原生的逻辑资源调度会忽略真实的资源占用情况，引起节点间真实资源利用率的失衡。</p><p></p><p>运维：计算引擎集群的运维工作往往是件耗时的事情，一旦整个体系不完善，会导致运维工作占用研发团队大部分的精力，产生投入失衡。Ray 上的运维操作主要有：集群创建、人工扩缩容、版本升级、批量作业运维、故障节点处理等。随着业务的增长，运维操作逐渐变得更加频繁，Ray 团队值班工作繁重。如何降低运维成本和提高运维效率是需要重点关注的问题。</p><p></p><p>稳定性：随着业务的发展，蚂蚁 Ray 生产环境承接了越来越多的核心业务，这部分业务对稳定性要求更高，往往需要 Ray 提供 99.99% 的服务稳定性和调度稳定性。引擎本身的稳定性是基础，除此之外还需要完善的集群和应用自愈体系，以及完善的告警与应急体系。</p><p></p><p>为了解决以上问题，蚂蚁 Ray 团队在 Ray 的“基础能力”之外，从“多租户”、“多元调度”、“智能运维”和“稳定性”几个方向打造了 Ray 在蚂蚁的“规模化能力”。通过“基础能力”+“规模化能力”共同支撑超 100W 核的业务。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ba/ba7cfc00830faa5b2fee3c629d5cb919.png\" /></p><p></p><p></p><h4>多租户</h4><p></p><p></p><p>多租户是指在一个分布式系统中，多个用户或组织可以共享同一套系统实例，并且彼此之间具备一定的相互隔离的能力。通过使用多租户架构能够有效提高资源利用率和复用率、灵活扩展系统、简化系统管理。蚂蚁内部 Ray 集群的多租户主要靠 Virtual Cluster 和 Runtime Env 两套框架来保障，其中 Virtual Cluster 用来从节点维度切分 Ray 集群，而 Runtime Env 用来解决节点内的环境隔离和物理资源隔离。</p><p></p><p></p><h5>Virtual Cluster</h5><p></p><p></p><p>Ray 在社区的定位主要局限于单个 Ray 集群仅服务于单个应用，大部分的场景是集群随着作业而拉起，随着作业下线而销毁。即作业模式：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/1c/1c2c0c8617223957d99ff3327b3c200c.png\" /></p><p></p><p>蚂蚁内部早期采用的也是作业模式，但随着业务量的增加，各种弊端逐渐显露出来。比如每个作业无论大小都需要冗余一份 Head 及 Redis 元数据缓存资源；多个作业之间有数据依赖时无法直接使用 Ray 的 API 来交互，必须要引入一个公共服务或中间件来间接完成数据交互；成百上千的作业版本冗杂，维护比较困难。</p><p></p><p>面对这些问题，我们推出了集群模式，用户的多个作业可以提交至同一 Ray 集群，集群支持异构节点部署，异构节点通过 work group 来划分（如下图：有红、绿、蓝三种 work group，每一种异构节点仅隶属于一个 work group），集群内的作业共享同一套系统组件（GCS、Dashboard、Raylet、TBase 等），作业之间可以直接通过 Ray API 完成数据交互。</p><p></p><p>切换到集群模式后，我们面临的第一个问题是集群内的资源抢占问题。由于 Ray 的调度是动态化并且在运行时随机发生的，集群内会发生不可预知的资源抢占，更棘手的情况会在多个作业之间发生资源死锁。特别是对于在线服务类业务而言，作业重启中资源被其他业务抢占后会导致业务恢复时间不可控，进而会引起严重的服务质量降级。如何才能保证“不同类型业务”之间的资源隔离性及稳定性？为此，我们引入了 Virtual Cluster 概念， 每一个 Virtual Cluster 可以承载多种 work group 的节点（如下图 VirtualCluster1 划分了绿、蓝两类 work group 的若干节点）。针对同类型业务内“不同作业”的隔离性诉求，我们提供了「混部」和「独占」两类 Virtual Cluster（分别如下图 VirtualCluster1、VirtualCluster2），前者单个节点可以同时执行多个作业的 Task，后者单个节点同时只能执行 1 个作业的 Task。在集群模式下，通过这两种模式的有机结合能覆盖大部分业务场景，用户可以根据自己的需求来权衡适合的模式，以达到理想的性能和稳定性。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5b/5b49e34e351d3bb8c0a6d0cc7a263641.png\" /></p><p></p><p></p><h5>Runtime Env</h5><p></p><p></p><p>Virtual Cluster 从集群的维度提供了节点资源切分与隔离的能力，但在单节点内部，Ray 的运行时也较为复杂。不同于 K8S 的交付对象 Pod，Ray 的交付对象仅仅是一个进程。因此在 Ray 的单节点内部，无法避免地会发生多个进程共享节点去执行 Task 或者 Actor 的情况。如下图所示，无论对于「混部」还是「独占」的 Virtual Cluster，节点内都会发现多个 Task 同时运行。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/cd/cd5d17d239c14e5e1334c90929da2fe9.jpg\" /></p><p></p><p>节点内同时运行多个 Task，该场景主要存在两方面的隔离问题：代码运行环境和物理资源。</p><p></p><p>首先，代码运行环境隔离。随着 Ray 上的业务越来越复杂，不可避免地会出现两种复杂的场景：同一 Ray 集群，不同作业之间，存在差异化的代码运行环境要求；同一作业内，不同 Actor 或 Task 之间，存在差异化的代码运行环境要求。而 Ray 节点的基础环境独立于任何作业而存在，所以不可能将所有的环境依赖预装到 Ray 节点的基础镜像里。无论以上哪一种情况，都需要一套细粒度的（Actor 和 Task 维度）运行时环境框架来支持。</p><p></p><p>其次，物理资源隔离。Ray 中的调度为逻辑资源调度，即分配给 Actor 或 Task 的 CPU、Memory 等资源仅仅在调度器中记账，但实际上不限制进程的物理资源使用。当 Worker 进程的物理资源使用超出实际申请的资源时，会在很大程度上影响同节点的其他 Task。因此对于稳定性要求较高的 Task，需要考虑引入物理资源隔离机制。</p><p></p><p>Runtime Env 框架即解决了以上两方面的问题。Runtime Env 框架是蚂蚁 Ray 团队在开源社区共建开发的一套面向一站式解决多租户场景下运行时环境构建问题的框架，经过多次架构重构后，目前已经成为 Ray Core 中关键的组件。Runtime Env 框架有如下特点：</p><p></p><p>细粒度的环境定制：同时支持粗粒度的 Job 级环境定制和细粒度的 Actor/Task 级环境定制；在触发条件上支持 eager 模式和 lazy 模式，满足不同的场景需求。插件化设计：内置丰富的插件实现（如 pip、conda、py_modules 等），外置插件可独立于 Ray 版本维护。跨语言设计：覆盖应用环境构建的全场景。无论是多语言还是跨语言，都可以实现“只开发一个 Python 插件”即可使用。</p><p></p><p>蚂蚁内部的 Runtime Env 框架在社区版本基础上进行了增强。以 Python Task 运行环境为例，我们为 Python 用户提供了不同维度的隔离化运行环境：最简单的是 VirtualEnv，即通过继承 Ray 节点中的 Python 基础环境再加上独立安装的用户依赖来运行 Task，这种方式隔离了 Task 之间的 Python 包依赖。然后是 Conda。相比 VirtualEnv，Conda 环境除了可以隔离 Python 包依赖，还可以隔离整个 Python 环境，做 Python Executable 和一些 Native Libraries 的定制。最后是 Container，这也是云原生场景下标准的隔离手段。通过定制 image，将 Task 运行在特点的 Container 里，可以实现 rootfs 级别的代码运行环境定制与隔离；同时由于 Container 集成了 cgroup 的能力，这种方式可以同时实现物理资源隔离。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/1d/1ddead449a69556986b662f0ca1a5c58.png\" /></p><p></p><p>如下图，从右到左看，三种方式的隔离性是从弱到强，但使用体验是由轻到重。我们认为，Ray 上的应用对隔离性有着不同的要求，不同的业务可以根据自身情况去权衡隔离性和使用体验，选择最适合的方式。这相比 K8S 给了用户更多的选择。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ed/edcee48e5827c32268825d3da645125b.jpg\" /></p><p></p><p>Runtime Env</p><p></p><p></p><h4>多元调度</h4><p></p><p></p><p>调度是分布式计算引擎非常核心的能力，对于 Ray 来说也不例外。随着业务越来越多样，随之而来的会是越来越多的差异化调度需求。蚂蚁 Ray 团队根据内部的业务特点，分别从调度模式、调度策略、调度效率和调度质量四个维度构建了一套多元调度体系，这套体系可以稳定地支撑蚂蚁的 Ray 生产环境。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a4/a484dd012c610bfcfa4820a2fc3c44ed.png\" /></p><p></p><p></p><h5>调度模式</h5><p></p><p></p><p>Ray 原生的调度方式为分布式调度，即每个节点的 Raylet 具有全局资源视图，在调度 Task 和 Actor 的时候是 Raylet 之间的点对点调度。这种调度方式在低并发的场景中可以实现高效的调度，可以满足大部分社区用户的需求。但在蚂蚁内部，我们遇到了很多大规模并发调度 Actor 的场景，比较典型的场景是集群重启后的 Job 并发提交。在此场景下，由于分布式调度中各 Raylet 节点间的资源视图无法快速同步，会导致调度冲突，调度请求 reject 的概率增高，反而影响调度效率。</p><p></p><p>因此，我们增加了新的调度模式，基于 GCS 的集中式调度。经过多年的实践经验，我们形成了“Raylet 调度 Task，GCS 调度 Actor”的最佳实践。</p><p></p><p></p><h5>调度策略</h5><p></p><p></p><p>策略方面，首先我们有基于水位线的平铺 + 堆叠混合调度策略。平铺的优势是更加负载均衡，堆叠的优势是资源碎片更少。不同业务可以根据自己的业务特点来定制水位线，权衡这两种策略。</p><p></p><p>面向复杂的自定义编排场景，我们支持了 Ray 的 Placement Group（PG）。用户可以通过 PG 预留单节点或跨多节点的资源组，一方面可以实现 Actor 和 Task 的 gang-scheduling，另一方面可以通过不同的策略（PACK 和 SPREAD）实现亲和性和反亲和性调度。</p><p></p><p>有了 PG 之后，用户可以实现各种复杂的调度需求，但增加了应用程序开发的成本，毕竟用户需要自己管理资源组。有些业务的调度需求并没有那么复杂，因此我们参考 K8S 的设计，引入了基于 Label 的调度。基于 Label 的调度接口简单，同时可以满足大部分亲和性和反亲和性的调度需求。</p><p></p><p>在实际生产中，往往存在一些少量珍贵的资源，我们通常称为稀缺资源。比较典型的稀缺资源有两种：GPU 和超大内存。对于稀缺资源，我们往往不希望它们被无关的 Task 占用，需要把资源留给真正需要它的 Task。因此，我们新增了稀缺资源调度功能。调度器会优先将 Task 调度到非稀缺资源的节点上，最大程度去保障稀缺资源的利用率。</p><p></p><p></p><h5>调度效率</h5><p></p><p></p><p>效率方面，我们除了通过上文提到的 GCS 集中式调度来提高调度效率外，还做了一些特殊的优化。</p><p></p><p>蚂蚁内部存在着大量的 Ray Java 应用。对于 Java 应用来说，一个明显的瓶颈就是 JVM 启动速度，它占用了大量的 Java Actor 的交付时间。针对这个问题，我们支持了“线程化”Actor，即多个 Java Actor 可以共享一个 Java 进程。JVM 复用后大大提升了 Java Actor 的交付效率，该功能在蚂蚁内部得到了广泛的应用。</p><p></p><p>Ray 是一个高弹性的计算引擎，集群在运行中会频繁地发生扩缩容，即 Pod 被反复创建和销毁。Pod 的创建和销毁还会发生在集群重启的场景，如配置修改和版本更新。Pod 的创建是一个相对较重的过程，而且在实践过程中，还会经常遇到不稳定因素导致 Pod 创建被长时间 Pending。Pod 的交付会直接影响 Ray 上 Actor 和 Task 的调度。针对这个问题，我们在 Ray 底层支持了 Pod 缓存（预留）机制，减少 Pod 的反复销毁和创建，提升 Ray 的交付效率和稳定性。</p><p></p><p></p><h5>调度质量</h5><p></p><p></p><p>Ray 原生的调度是一种逻辑资源调度，即节点资源的计算仅仅根据用户填写（申请）的资源进行扣除。这样的方式往往需要用户对每一个 Actor 和 Task 的资源进行精准的控制。但在实践过程中，往往会出现资源申请量和实际使用量的偏差，这样会带来两个弊端：</p><p></p><p>申请量大于实际使用量时，节点上被分配的 Actor/Task 太少，资源利用率会偏低。这也是我们在生产环境中经常发现的问题。申请量小于实际使用量时，节点上容易被分配过多的 Actor/Task, 导致 OOM 等问题。</p><p></p><p>因此，我们实现了基于真实资源的调度。在节点端，我们会周期性地采集所有 worker 进程的真实资源使用情况，经统计后更新到 GCS。在此基础上，上文提到的调度策略就可以基于集群的真实资源情况来执行。</p><p></p><p>在蚂蚁的在线学习等业务集群上，我们已经大规模启用了真实资源调度，并收获了显著的资源利用率提升和稳定性保障。</p><p></p><p></p><h4>智能运维</h4><p></p><p></p><p>如上文提到，大规模的业务会带来大量的运维工作，我们需要不断提升 Ray 运维的智能化水平，提升运维质量，解放运维带来的人力投入。因此在智能运维方向，我们做了以下三方面的工作：自动弹性、无感迁移和滚动升级。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/35/35203f54ba7518c228c299e729029730.jpg\" /></p><p></p><p></p><h5>自动弹性</h5><p></p><p></p><p>上文提到，为了支持多租户架构，蚂蚁内部引入了虚拟集群（Virtual Cluster）。因此相比社区版本的 Ray，蚂蚁内部 Ray 的弹性架构更加复杂，主要分三层：作业弹性、虚拟集群弹性和物理集群弹性。对于作业来说，需要根据负载调整自己的实例数量和规格，这个实例落到 Ray 上就是 Task、Actor、PG 或者 Serve 的 Deployment。作业的弹性会首先反映到虚拟集群的弹性上，虚拟集群需要根据用户实例和集群空闲资源情况决定是否要扩容或者缩容，而虚拟集群弹性的资源池是真正的 Ray 集群。最后，Ray 集群的弹性会反映到基于 K8S 的 autoscaling 上。</p><p></p><p>为了支持多级的自动弹性，我们接入了公司内部的端到端弹性优化系统：Cougar。Cougar 是蚂蚁内部 AI 和大数据领域统一的弹性服务，可以根据应用和引擎的离线数据和实时数据构建资源画像，然后提供运行时的横向和纵向两个维度的弹性决策。具体到 Ray 中，我们会通过 Ray 的 Dashboard 透出作业、虚拟集群、物理集群三个维度的数据给 Cougar 系统，然后通过 Cougar 系统反馈的决策做最终的弹性（扩容或者缩容）。</p><p></p><p></p><h5>无感迁移</h5><p></p><p></p><p>在大规模集群长跑过程中，我们往往会遇到机器故障或大促腾挪等场景，因此 Ray worker 节点 (Pod) 被下线是不可避免的。但在此过程中，经常会导致业务在一定程度上被中断，从而引入非常繁杂的人工运维。为了缓解此类问题，我们实现了无感迁移功能，可以使 Pod 下线操作对上层业务透明，保证业务可用性不受影响。</p><p></p><p>无感迁移的挑战有：</p><p></p><p>长、短周期作业并存，无法简单的设置 timeout 来强杀；DAG 类型作业要求 FO 频次尽可能少；迁移时机不一。</p><p></p><p>因此，我们将无感迁移的管控功能实现在 Ray 集群对应的 K8S Operator 上。当 Operator 探测到 Pod 下线需求时，会根据作业的特性进行 batching，再选择适当的时机通知 GCS (并补充新节点用于后续的 Actor 迁移)。GCS 根据待下线 Pod (Worker 节点) 上的 Actors，会向相应的作业通知哪些 Actors 需要迁移。基于我们提供的 SDK, 用户可以预先自定义收到 Actor 迁移通知时的处理逻辑。由于该处理逻辑独立于业务代码，因此，Actor 迁移操作可以做到对业务无感，从而极大地缓解人工介入的成本。</p><p></p><p></p><h5>滚动升级</h5><p></p><p></p><p>伴随软件版本的迭代，Ray 引擎中的 Bug 会得到修复，我们也会引入性能提升和一些新特性，这些都促使用户对集群进行引擎版本升级。然而，在一个长期运行的集群中，一方面用户期待在线服务的业务不会受到升级影响而中断，另一个方面用户的资源（尤其是当下热门的 GPU 资源）大概率是有限的，这两点制约因素都要求引擎提供滚动升级的能力，即分批次地升级集群中已有的节点。</p><p></p><p>滚动升级带来了两点新的挑战：第一是滚动升级的过程中，集群处于一种多个软件版本的共存的状态，这就需要一套协议来确保版本之间的兼容性；第二是当某个节点被升级时，节点上的所有业务进程都会被杀死，引擎要和用户达成业务进程迁移的协议，在升级前通知业务代码做好准备并提供必要的资源。</p><p></p><p>为了实现滚动升级，Ray 团队充分利用 Ray 的核心能力，开发了滚动升级作业来协调整个集群的有序升级。在升级过程中，我们首先升级系统组件，包含 Head 节点和 SystemJob 节点，这一过程是对节点内的容器进行原地升级重启，而 Ray 的核心组件 GCS 会进行一次自动故障恢复，从 Tbase 中恢复集群状态。Worker 节点的升级由一个滚动升级作业来完成，这个作业根据用户指定的规则，选择需要升级的节点，并通知业务作业迁移节点上的任务，在任务迁移完成后，作业发起对节点内容器的原地升级。这一过程主要利用了 Ray 引擎的弹性扩缩容来为业务作业迁移提供足够的资源，并借助无感迁移协议确认任务全部安全迁移后再进行节点的升级。</p><p></p><p></p><h4>稳定性</h4><p></p><p></p><p></p><h5>自愈能力建设</h5><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/45/45664f4d7ea3d8f5b6b05160a64dbd79.png\" /></p><p></p><p>分布式系统是由多个节点组成的复杂网络，每个节点都可能由于硬件故障、软件错误或网络问题而导致故障。良好的自愈能力是分布式系统高可用性、稳定性、可靠性、容错性的必要前提。</p><p></p><p>作为快速构建分布式应用的编程框架，Ray 为上层应用提供了丰富的自愈能力。同时 Ray 集群本身也是一个分布式系统，所以 Ray 对节点、自身系统组件异常等情况也做了多方面的考虑。下面将从“集群自愈”和 “应用自愈”两方面进行介绍。</p><p></p><p>Ray 集群自愈</p><p></p><p>Ray 自身就是一个分布式系统，为了保证给上层应用提供稳定的服务，我们首先对 Ray 自身的自愈能力进行了建设。先回顾下 Ray 的集群架构：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/2a/2ad27e5b380cbfb5df26905b79e3a1b6.png\" /></p><p></p><p>Ray 集群分为 Head 和 Worker 两种角色的节点。</p><p></p><p>Head 节点一般一个 Ray 集群只有一个。里面有 GCS(Gloabl Control Store)、Dashboard 等进程。Head 节点负责整个 Ray 集群的元数据管理和中心化服务。Worker 节点上有 Raylet 进程主要负责节点内的 Actor 和 Task 管理以及分布式调度；Dashboard agent 进程负责运行时环境构建、Metrics 和实时信息采集等。</p><p></p><p>从以上架构可以看出，Ray 集群能够正常服务的前提是 Head 节点及其元数据的可靠性。在蚂蚁内部，我们在以下两方面来保证 Head 节点的高可用。首先是 Head 元数据高可用。蚂蚁生产环境中的每个 Ray 集群都会配置一套独立的 Tbase 集群来做元数据的存储。Tbase 集群接口兼容 Redis，同时可以在故障时自动进行存储节点的主备切换。GCS 重启的场景也可以自动从 Tbase 中恢复故障前的元数据。其次是 Head 节点高可用。Ray 本身的所有节点都依赖 Ray Operator 和 K8S 进行故障恢复，即具备 Pod 重新调度的能力。但对于 Head 节点而言，Pod 恢复期间整个调度和作业接入服务不可用，对业务影响较大。因此，为了实现 Head 节点的秒级恢复，我们以 standby 的方式为所有高保的 Ray 集群同时启动了 2 个 Head 节点，他们通过 Tbase 进行选主，确定主备关系。在主 Head 节点出现故障后，备用 Head 节点会经过选主协议升主，继续为整个集群提供服务，实现快速恢复。</p><p></p><p>除此之外，Head、Worker 节点上的 GCS/Dashboard/Raylet 等关键进程，都具备本地自愈能力。进程偶发性异常退出会触发本地自愈功能，这种方式相比 Pod 重建效率更高。连续高频的进程异常退出会回退到 Pod 维度的自愈做兜底。</p><p></p><p>Ray 应用自愈</p><p></p><p>Ray 本身无法感知到应用内部的状态和复杂的业务逻辑，因此无法提供无感知的应用自愈。但 Ray 提供了多维度的自愈的原子能力，方便用户在集成过程中快速构建一套具备自愈能力的应用。主要有以下几个方面：</p><p></p><p>Actor 自愈：Ray 的 Actor 相当于用户的一个应用进程，如果 Actor 因为用户自己业务代码 bug crash 了，Ray 会认为这个 Actor 是异常 crash 了，会重启调度拉起这个 Actor。Ray 还提供了 max_restarts 参数给予用户灵活设置最大的重启次数。如果设置为 0 或是重启次数超过 max_restarts，Ray 就不会再次拉起这个 Actor 了， 而且将其标记为 Dead。所以用户可以灵活设置自己的 Failover 策略。同时 Ray 还 max_task_retries 参数让用户灵活设置 actor task 是 at-most-once 语义还是 at-least-once 语义。Task 自愈：Ray 的普通 Task 具备血缘回溯的能力，即当一个 Task 依赖的 Object 丢失时，可以通过血缘找到 Object 对应的 Task 并重新执行，以此恢复 Object。- 作业局部自愈：Ray 的用户基本是提交一个 Ray 作业就是一个完整的应用。一个 Ray 作业里可能同时创建了几百上千的 Actor。Ray 同时还提供了 Attached/Dettached Actor 的能力来帮忙用户管理具有层级关系的 Actor 的 Failover。此特性在大数据计算中很实用，在计算 workflow 中某个算子故障 failover 后，可以自动触发下游节点的 failover。作业全局自愈（L1FO）：L1FO 是专门为某些特殊场景开发的特性。此特性可以做到一个 Ray 作业中某个 Actor 发生 crash 后。同时触发整个作业 所有 Actor 的 Failover。让整个作业重启自愈。</p><p></p><p></p><h5>告警体系建设</h5><p></p><p></p><p>最后是监控告警体系建设，很多系统里也叫 Observability。对于计算引擎来说，这部分工作一般需要结合各公司的基础设施来进行集成。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/74/74d42edab26720f0646fc45955f550eb.png\" /></p><p></p><p>在 Ray 的监控告警体系中，主要有三种数据源：Log、Event 和 Metric。</p><p></p><p>Log：Ray 的 logs 相对较为复杂，logs 文件多，数量不固定，并且文件名里会有多个变量。我们将 Ray 的 logs 对接到蚂蚁内部的 SLS 服务中，实现了 logs 的集中化收集和 logs 无盘化。同时在 Ray Dashboard 中提供 standalone 的 logs 查询能力，方便服务简单的查询场景。复杂的 logs 查询与分析场景会引导用户直接去 SLS 平台。</p><p></p><p>Event：早些年，我们在 Ray 的内核中开发了 Event 框架。events 可以看作特殊的 logs，具有结构化的数据。在分布式系统中，经常会发现一些难定位的分布式故障，这种故障往往涉及到多个角色和组件。我们通过将集群内关键的日志转化为结构化的 events，大大提高了分布式系统故障定位的效率，也为告警提供了可靠的数据源。</p><p></p><p>Metric：Metric 几乎是任何一个服务系统必不可少的数据。同样的，Ray 在蚂蚁内部接入了公司内部的 Metric 基础设施，并通过集群级和作业级两个维度来建设 Metric 埋点。通过已有的 Metric 埋点，我们构建了多维度的监控大盘，这些大盘同时服务集群的运维人员和应用的运维人员。</p><p></p><p>有了 Log、Event 和 Metric 三种数据源后，我们就可以建设 Ray 的告警体系和应急体系。另外特色的，我们还构建了一套根因分析系统，通过一套规则引擎自动分析分布式系统中各种异常日志和事件之间的关系，自动分析故障的根因，提高故障定位的效率，降低故障处理的人力成本。</p><p></p><p></p><h4>展望</h4><p></p><p></p><p>尽管蚂蚁 Ray 团队在努力打造通用分布式基座以及支持上层分布式应用 / 框架方面取得了诸多进展，但在应对如此庞大的业务体量和复杂的业务场景时，仍然存在很大的改进空间。主要体现在以下几点：</p><p></p><p>资源利用率。目前 Ray 的总业务资源占用超过 100 万 CPU 核，总 CPU 平均利用率 10%～20%，总内存平均利用率在 30%～40%。导致利用率低下的因素有很多，如：</p><p></p><p>自定义镜像：Ray 所提供的基础镜像能覆盖大部分场景，但仍然存在一部分业务作业依赖较为复杂，期望通过定制基础镜像创建独立集群的方式来加速作业运行时依赖下载的开销，不同基础镜像的集群可能存在各种依赖冲突无法合并进行作业混布，导致利用率低下。集群灾备：蚂蚁内部存在多个机房，一些在线类业务往往配备了多个 Ray 集群以降低集群或机房内基础设施故障带来的可用性风险，每个机房之间的资源碎片不能相互整合也会影响整体利用率的提升。业务类型差异：基于 Ray 通用分布式计算底座构建的上层引擎 / 框架较多，每类引擎 / 框架都会配置不同的 Ray 集群参数以定制适合于自己的集群。“RayServing- 在线服务”集群定制了 Runtime Env 及自定义资源能力；“GeaFlow- 图计算”集群定制了独占型虚拟集群、全局 Failover，Actor 线程化等能力；“Mars- 科学计算”集群定制了亲和性调度、自定义编排、Object Store 大对象依赖传输等能力；“Realtime- 在线学习”集群定制了真实资源调度能力；“FaaS- 函数计算”集群定制了三方 sidecar 部署及 cgroup 资源限制能力。不同类型业务所定制的集群所提供的能力可能存在冲突，导致集群不宜合并。如：“Mars”需要的 Object Store 大对象依赖传输能力需要预留足够的共享内存，挤压了业务运行时可调度的内存资源，而这是其它类型业务不期望的；“FaaS”需要的 sidecar 部署能力来启动 Service Mesh 系统的中间件，挤压用户资源的同时也会拉低 Pod 的交付时间，而这也是其它类型业务所不期望的。历史版本迁移困难：早期版本的 Ray 集群采用的是作业模式，这种模式的好处是针对“离线短周期任务”执行完后能及时释放资源，弊端是作业环境及依赖相对独立，很难及时跟随大版本升级，随着时间的推移管控及运维越来越难。现阶段，内部仍然存在相当一部分历史版本需要升级整合。</p><p></p><p>节点迁移实效性。现有的无感迁移基于“优先增补节点”为前提，即优先保障新节点补进后再触发迁移逻辑，以保障迁移过程资源可靠性，但在 K8S 资源池紧张情况下，很有可能没有新的节点能够补进，进而影响整体的迁移实效性。除此之外，Ray 所触发的迁移事件亦依赖于上层引擎 / 框架的迁移行为，上层引擎 / 框架在收到迁移事件可能会因为各种因素（如：Bug、迁移规则等）影响，导致迁移进程受阻，影响整体的迁移实效性。近期我们设计了无感迁移 2.0 方案，结合弹性伸缩从“优先增补节点”到“仿真资源缺口”转变，从被动依赖上层引擎 / 框架迁移行为到主动提供多种迁移策略转变，以多方位提升迁移实效性。</p><p></p><p>滚动升级兼容性。由于 Ray 的各个组件依赖众多，系统的 API 也极为丰富，在版本迭代过程中，难免会产生版本间的不兼容性。不兼容的版本会在滚动升级中引起不可预期的问题，最终仍然要回退到原始的集群升级方式（即全局重启）。</p><p></p><p>开闭源系统差异性。鉴于内外业务及发展定位差异性等因素的影响，蚂蚁内部基于不同业务场景研发的 Features 推入社区周期较长，社区一些新的迭代回合也有一定滞后，开闭源研发节奏和侧重点的差异导致了代码的差异也逐步扩大。随着大模型浪潮在全球范围内的兴起，社区在 AI 领域的研发节奏也逐步加快，蚂蚁内部用户对 Ray 在 AI 方面的产品生态（如：RayData、Stream Generator 等功能）也越来越关注。因此，我们将逐步与社区最新版本同步，以支撑内部业务在 AI 方面的新发展。</p><p></p><p></p><h3>Ray 在业界发展的现状和趋势</h3><p></p><p></p><p>介绍完蚂蚁的情况，让我们从项目本身的角度出发，看看 Ray 在业界的发展现状和趋势。</p><p></p><p></p><h4>谁在用 Ray</h4><p></p><p></p><p>首先是大家最关心的第一个问题：哪些企业在用 Ray。我们汇总了部分企业：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/9a/9a71c943d10688d5b2e253328d903f3d.png\" /></p><p></p><p>从上图可以看出，Ray 在企业应用领域的普及程度越来越高。除了众所周知的 OpenAI，国外的科技巨头（如 Google、AWS、Microsoft、Meta）也都在积极拥抱 Ray。传统企业（Adobe、Vmware、IBM）和硬件厂商（NVIDIA、Intel）也在积极融入 Ray 的生态圈，国内企业蚂蚁集团、网易、字节跳动、华为等也都在 Ray 上持续发力。此外，许多知名创业公司也选择了 Ray，其中原阿里云计算平台负责人贾扬清在去年投入创业后，也选择将 Ray 集成到他们最新的开源项目 Lepton AI 中实现分布式计算。</p><p></p><p></p><h4>一些数据</h4><p></p><p></p><p>接下来再看一些有关 Ray 开源社区发展的数据。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ef/ef8df540145acb7cb83045f8b63d5d47.png\" /></p><p></p><p>Github Stars 数方面。 从 2016 年开源至今，Ray 已经积累了 28k+ stars。比较有意思的是，Ray 的增长速度在近期达到了跟 Spark 同期的水平。另外一个里程碑是在去年年中，Ray 的 stars 总量超过了 Kafka。</p><p></p><p>Contributors 数方面。Ray 在社区有不错的数据和活跃度，近一年内（2022.09～2023.09），Ray 的 Contributors 数量从 700 增长至 870（最新的数据是 890），增长幅度 25%。</p><p></p><p>Ray Clusters 数方面。 据 Anyscale 统计，从去年 1 月到 9 月，全球范围 Ray 集群数量在去年已经增长了 6 倍。</p><p></p><p>这几个维度的数据从一定程度上反映了 Ray 在开源社区良好的增长趋势。</p><p></p><p></p><h4>为什么用 Ray</h4><p></p><p></p><p>另一个大家比较关心的问题就是：为什么使用 Ray。</p><p></p><p>我们收集了一些会话：</p><p></p><p>首先是 OpenAI 的 Co-founder John Schulman，他在访谈中分享了一些使用 Ray 的经历。事实上，他是 Ray 最早一批用户，在读 PhD 期间就在尝试使用 Ray。他提到，在 OpenAI 内部有一个专门做分布式训练的 library，Ray 作为这个 library 重要的一部分负责通信工作。他强调 Ray 是一个非常 solid 的组件。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/9b/9b87f8777cecde77702f289d53083a77.png\" /></p><p></p><p>John Schulman, Co-founder, OpenAI</p><p></p><p>LinkedIn 的 VP，Ya 分享了他们使用 Ray 构建 ML 应用的感受。为了支持拥有多模型的复杂应用，他们非常依赖 Ray 做在线应用的编排。具体来说，他们通过 Ray Serving 将整个推理图切分成多个原子层，同时优化 CPU 和 GPU 的混合计算场景。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/02/020b39ef159d242ae990f3eba21d2fc4.png\" /></p><p></p><p>Ya Xu, VP of Engineering, Head of Data and AI, LinkedIn</p><p></p><p>Adobe 和 Niantic 也分别分享了他们使用 Ray 的感受。Adobe 的 Ersin Yumer 总结了他们喜欢 Ray 的三个原因：Flexibility，Extensibility 和 Scalability。Niantic 的 Brian McClendon 分享了 Ray 在开发上带给他们的便利性：Ray 可以减少 85% 用于编排任务的代码，加速生产化应用。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e8/e863f3eff83f59fae682bcce39b5d905.png\" /></p><p></p><p></p><h4>应用案例</h4><p></p><p></p><p>接下来的问题：用户是如何使用 Ray 的。我们在这里分享三个案例：</p><p></p><p>第一个案例是 Spotify。Spotify 作为流媒体平台，拥有超过 5 亿的用户。如下图所示，他们充分利用 Ray 构建自己的 AI 平台 Hendrix。在该平台中，最底层利用 Ray 提供了计算基础设施的通用能力：GPU 管理，网络，资源调度，监控，运行时环境等。上层通过 Ray + Pytorch 封装 MLOps SDK，提供标准的 ML 能力：Features，Training，Serving 等。对于特殊的需求，通过 Ray 进行 OSS Ecosystem 的扩展，实现相应的功能（如 Embedding Evaluation，Graph Learning 等）。这是一个非常典型的利用 Ray 来构建一体化 AI 平台的案例。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/07/073df83b2f7a87a1864d0d725c7c067a.png\" /></p><p></p><p>Spotify</p><p></p><p>第二个案例是 Pinterest。Pinterest 是全球知名的社交媒体平台，拥有超过 4 亿月活用户。他们分享了内部训练场景中最后一公里的数据处理架构演进。在先前的架构中，他们通过集成多进程的 Pytorch data loader 到 GPU 节点进行训练前的数据处理，如下图。这种架构的主要问题有：（1）仅利用单机多进程处理数据，scale 能力有限。（2）CPU 运算和 GPU 运算在同节点，GPU 利用率低，无法实现高效的异构计算。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7d/7dba11232fb07f3781f22518f7c6c731.png\" /></p><p></p><p>Last-Mile data processing by Pytorch data loader</p><p></p><p>为了解决以上问题，他们进行了重构，利用 Ray Cluster 管理和调度异构集群，如下图。他们通过 Ray Dataset 对训练前的数据进行统一的预处理，可以利用多 CPU 节点实现并行化；处理后的数据灌入 GPU 节点进行训练。他们还优化了数据转换和拷贝的链路，使整个流程更加高效。重构后的系统，相比之前 Pytorch data loader 的方案，在复杂场景下可以降低 40% 的训练耗时。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/fd/fded70786b404a8c9e30ffd4a1c4c585.png\" /></p><p></p><p>Last-Mile data processing by Ray Dataset</p><p></p><p>第三个案例是 Uber。下图是 Uber 内部支持 LLMOps 的架构。他们选择了流行的开源技术栈：NCCL 和 Torch 作为基础库，Deepspeed + Huggingface Transformers 训练 SOTA LLMs，通过 Ray 的 TorchTrainer 调度和编排训练中的进程组。这也是一个比较典型的 Ray 在 LLM 基础架构中应用的案例，可以直观地看出 Ray 与其他 LLM 生态框架的集成关系。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/2a/2aba8f1916bf1cc6e2dbf30a619ab4d0.png\" /></p><p></p><p>LLM Training Architecture</p><p></p><p></p><h4>发展趋势</h4><p></p><p></p><p>最后，分享一些我们从 Ray Summit 上看到的发展趋势。</p><p></p><p>首先，开源模型越来越好。 随着 Llama2 等开源模型的发布，我们可以看到，整个大模型领域已经形成了开源模型与闭源模型共同发展的局面。据 Anyscale 研究显示，被 fine-tuned 的 Llama-2-7B 可以在效果上超过 GPT-4。两个模型的量级相差甚远，但 fine-tune 的效果显著。所以目前一个比较明显的方向就是通过 fine-tune 开源模型来实现自主可控的 LLM 应用技术栈。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/91/9106b6662b580d6ee6dc5d4639f59a0a.png\" /></p><p></p><p>Fine-tuned Llama-2-7B vs GPT-4</p><p></p><p>其次，LLM API 价格越来越低。 在 Ray Summit 上，Anyscale 重磅发布了新产品 Anyscale Endpoints。这是一款 LLM API 产品，经过一系列成本优化之后，Llama-2-70B 的 API 价格可以做到 $1/million tokens，是目前市面上最低的价格之一。自从 LLM 火爆全球以后，推理架构和性能的优化一直是除预训练以外最火热的方向之一。相信后续的 API 成本可以做得越来越低，普惠中小企业和大众用户。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5b/5bb682b9dab11f6a5c7a1748c7423aec.png\" /></p><p></p><p>The price of Anyscale Endpoint</p><p></p><p>除此之外，从 Infra 的角度来看，LLM 开源技术栈已经呈现出比较典型的架构。 如下图所示（From @Meta)，整个架构从底层到上层分别是：云原生服务（如 Kubernetes，云厂商等），以 Ray 为代表的 ML 编排层，以 Pytorch、OpenXLA 为代表的神经网络前后端框架，最上层是主流的开源模型（如 Llama2）。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b9/b96beb55bdb7e81d727bbd73b6cf7119.png\" /></p><p></p><p>另一块比较明显的发展趋势是 AI 算力在 Ray 上的原生支持。 在 Ray Summit 中，Ray 宣布了与四家持有专属加速硬件的厂商进行合作，它们分别是：Nvidia，AWS，Intel 和 Google。这意味着在更高版本的 Ray 中，无需特殊的适配，即可在训练和推理任务中开箱即用主流的 AI 加速硬件。在大模型时代，AI 算力显然至关重要。未来，Ray 将不断优化新硬件的插件化接口，实现最低成本接入包括国产硬件在内的新型加速硬件。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/bf/bf9508722eed9fdaa24de5771282a47a.png\" /></p><p></p><p>Nvidia + Ray</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/2e/2e9ee4a51adf8c7394387f325acbbd79.png\" /></p><p></p><p>AWS + Ray</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/fa/fa098af13802ac48c3a2a48ebbc36acb.png\" /></p><p></p><p>Intel + Ray</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f3/f3d27aa1333dc64d3c6f8466da8d2c5f.png\" /></p><p></p><p>Google + Ray</p><p></p><p>值得一提的是，最近华为公司也与 Ray 社区进行了深度的合作，晟腾 NPU 已经在 Ray 的最新版本实现了原生支持，欢迎大家试用。</p><p></p><p>总结起来，随着 LLM 和生成式 AI 的飞速发展，已经在分布式计算领域深耕多年的 Ray 也迎来了高速发展的一年，越来越多的企业正在使用或者正在尝试使用 Ray，Ray 的潜力也在被不断地挖掘中。对于 Ray 本身，基于核心的调度与编排能力之上，在处理复杂的 Data + AI 场景中 Ray 更能够发挥易用性和性能的优势。随着大模型行业的不断发展和变迁，Ray 将深度融合 AI 算力，赋能更高效和开箱即用的 AI 计算。</p><p></p><p></p><p></p>",
    "publish_time": "2024-01-23 10:14:37",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "数字经济“国家队”，央国企的数字化现状、挑战和成功经验",
    "url": "https://www.infoq.cn/article/iuQB6ZaAfUhUlPqo0ywF",
    "summary": "<p></p><blockquote>采访嘉宾 |&nbsp;孙司雷 昆仑数智数字化咨询中心主任</blockquote><p></p><p></p><p>近年来，以习近平同志为核心的党中央高度重视数字化发展，作出一系列重大部署，擘画了数字中国建设的宏伟蓝图。党的十九大报告明确提出建设数字中国战略目标，“数字中国”首次写入党和国家纲领性文件。党的二十大报告指出，要“加快建设世界一流企业”，形成一批产品卓越、品牌卓著、创新领先、治理现代的企业，为我国实现高质量发展、构建新发展格局提供重要支撑。</p><p></p><p>2020 年，国务院国资委发布《<a href=\"http://www.sasac.gov.cn/n2588020/n2588072/n2591148/n2591150/c15517908/content.html\">关于加快推进国有企业数字化转型工作的通知</a>\"》，其中明确提出，要“发挥国有企业在新一轮科技革命和产业变革浪潮中的引领作用，进一步强化数据驱动、集成创新、合作共赢等数字化转型理念，系统组织数字化转型理论、方法和实践的集中学习……”</p><p></p><p>2023 年，国务院国资委在国资央企信息化工作推进会上强调，在建设世界一流企业过程中，要同步建成一流信息化能力，以“智慧国资、数字央企”建设，加快推进国资央企高质量发展，为推进国家治理体系和治理能力现代化贡献更大力量。</p><p></p><p>2024 年，是实施国家“十四五”规划的关键年。作为推动数字经济和实体经济融合发展的“排头兵”，央国企也迎来上交数字化转型“答卷”的关键一年。<a href=\"https://xie.infoq.cn/article/34ba71bd6e07f67e83e9aa7d9?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">央国企数字化</a>\"部署和实践成果显著，突出表现之一是专业化数科公司的密集成立。数据显示，约 80% 的央企已成立数科公司，数量累计达到 500 多家——中国石油旗下昆仑数智，就是其中之一。</p><p></p><p>日前，InfoQ 采访了昆仑数智数字化咨询中心主任孙司雷，他参与主持了中国石油信息技术总体规划、政策研究和咨询服务等多项工作。十多年来，一直致力于国有企业数字化转型研究，并带领咨询团队为油气领域数字化转型提供咨询服务。</p><p></p><p>在孙司雷看来，由于央国企在国民经济中扮演重要角色，其数字化转型推进速度过快可能会增加运行波动，反之过于保守则难以充分发挥领头羊作用。因此，央国企数字化转型面临着一系列的独特挑战，如何在“十四五”收官之前交出一份漂亮的“成绩单”，还有一系列攻坚问题需要解决。</p><p></p><h3>数字化是主角，整体发展水平呈现积极态势</h3><p></p><p></p><p>“对于央国企来说，近五年数字化一直扮演着主角，从未离开过聚光灯。”孙司雷直言。而这背后，是外驱力和内驱力共同作用的结果。</p><p></p><p>从外部来看，数字中国建设上升至国家战略层面，数字经济发展逐步深化。其中，央国企作为国民经济最重要的组成部分，不仅承载着牵头响应政府号召的特殊使命，并且在面对全球环境新变局时，还承担着引领创新产业发展、攻克核心技术自主可控等关键问题的责任。</p><p></p><p>从内部来看，随着经济趋于平缓，传统运营模式遭遇瓶颈，数字技术的注入成为新发展动能。为了实现高质量发展，央国企和其它企业一样，同样亟需通过数字化基础的夯实，提高集团管控和运营能力。并且，在练好“内功”的基础上，加速产业链整合、拓展新的业务领域，从而塑造新的竞争力。</p><p></p><p>“近几年，央国企对数字化转型的重视和投入力度空前。例如，我们看到很多央国企都在调整内部的组织架构和人员配置，原技术负责人在企业内的地位大幅提升。”孙司雷表示。</p><p></p><p>第一，数字化管理体系日益健全，企业稳步推进数字化管理体系建设，体制机制各方面稳步提升，呈现出“战略推动力日益增强、组织健全不断提高、资金投入大幅提升、数字人才数量激增”等趋势特点。尤其是在战略规划方面，各企业纷纷开展数字化转型专项规划，形成了渐趋完备的数字化转型顶层设计。</p><p></p><p>第二，生产经营数字化逐步覆盖，企业生产经营数字化成效显著，在研发设计、产品交付、现场作业、用户服务、经营决策等方面均体现出“全面数字化”的趋势。“面上”数字化覆盖程度不断扩大，“点上”各类生产经营数字化大幅提升。</p><p></p><p>第三，数字技术创新能力全面提升，企业在数字技术创新方面充分体现出“技术创新、基础保障、平台自主可控和数字产业发展”等能力全面提升的特点。</p><p></p><p>第四，数据要素潜能不断释放，企业积极建立健全数据治理组织，推进<a href=\"https://www.infoq.cn/article/WKPj5NSiSpE28pz5WZ5w\">数据资源汇聚</a>\"，加强内外部数据共享，推动数据资源开放，数据价值逐步释放，打造标准、统一、复用、共享的高价值数据资产，支撑内外部“用数赋智”。</p><p></p><p>“跳出央企范畴，进一步提升视角，央国企整体数字化发展水平仍旧参差不齐，相比央企，地方国有企业大多数还处于数字化转型的深水期，数字化的价值实现和规模化拓展仍然充满挑战。”孙司雷指出，“尤其是对于很多中下游的国企而言，还在信息化建设的补课阶段。”这其中，央国企侧重领域的差异化特点值得关注。</p><p></p><p>从行业视角来看，各重点领域数字化转型各有亮点。</p><p></p><p>油气化工企业“重管控重运营”，充分利用数字技术完善能源产供储销体系，实现降本增效、协同共享、持续创新、风险预控和智慧决策，提高全员劳动生产率和资产创效能力。</p><p></p><p>电力电网企业“重运营”，全力推动传统电力向更加智慧、更加安全、更加友好的能源互联网转型跨越，助推企业清洁低碳转型、质量效益提升、新旧动能转换。制造企业“重数字制造”，以智能制造为主攻方向，以数字技术与制造业融合为主要路径，推动制造业高端化、智能化、绿色化发展。</p><p></p><p>建筑企业“重数字孪生”，推进智能建造与建筑工业化协同发展，推进数字技术在科研、设计、生产加工、施工装配、运营等建筑全领域的创新应用和数据融通。</p><p></p><p>电信企业“重营销”，加快推进高速、移动、安全、泛在的新一代信息基础设施建设，提升 5G 和云网业务数字化运营和服务能力，推动企业发展模式创新，打造现代化运营型企业。</p><p></p><p>交通企业“重服务”，加快全流程的数字化覆盖，以数据汇聚、流动、共享和创新应用，构建“数据化、网络化、智能化”的综合立体运输服务体系。</p><p></p><p>矿业企业“重安全”，以数字技术促进增产增效、提升行业竞争力，落实能源资源安全战略，实现安全、高效、智能、透明、绿色发展。</p><p></p><p>商贸服务企业“重交易”，以用户需求为导向，积极创新服务模式和商业模式，加快线上线下融合发展，全面提升客户体验，持续引领服务创新、共创美好生活。</p><p></p><p>具体到行业差异化对比，由于业务的数字原生优势，以中国移动、中国联通、中国电信为代表的网络通信行业以及能源行业的数字化水平更高；而在非数字原生行业中，直接面向消费者的行业（如商贸流通等）数字化水平更高。“这意味着，谁能在此过程中更快趟过深水区，谁就能突出重围。数字化就像是给我们的企业装上了一个高效的引擎，让我们在竞争中跑得更快。”孙司雷表示。</p><p></p><h3>企业数字化转型，学华为，要学过程，而不是结果</h3><p></p><p></p><p>然而，“深水区”注定阻力重重且暗流涌动、变幻莫测。</p><p></p><p>用孙司雷的话说，数字化转型本质上不是技术问题，也不是管理问题，而是企业经营的综合性问题。“机遇和收益越大，风险就越大。数字化与变革管理相辅相成，数字化转型意味着企业要自上而下更新自己的思维，拥抱数字化的变化，打造全新的数字文化、敏捷思维、管理工具和流程机制。”</p><p></p><p>这和过去可直接复制国外先进管理经验的信息化时代不同，通过看一个样本、引入一个软件就能提升管理水平的模式不复存在。换言之，企业在数字化转型过程中，首先要输入足够的成功样本，并且以企业自身为主体进行思考和实践，数字化已经没有现成的“作业”可以照抄。</p><p></p><p>与此同时，投入和见效的周期也被拉长。“企业学<a href=\"https://www.infoq.cn/news/NTJYRtUm0xOma4gOYPC6\">华为</a>\"，要学的是过程，而不是结果。”孙司雷告诉 InfoQ，“很多企业只看到数字化标杆企业的成功表象，即‘水面上的冰山一角’，而忽略了他们在过程中的弯路曲折和失败教训。这导致大家在数字化投入过程中，很容易因为期望过高而缺乏耐心。”</p><p></p><p>以宝信软件为例，公司由宝钢股份自动化部门转化而来，成立于 2000 年并于 2001 年上市。“根据公开信息，在 2015 年之前，宝信软件长期处于收入平缓状态，直到 2015 年左右才出现大规模跃升。”孙司雷举例，“究其原因，宝信把自己 10 多年积累的全场景、全层级、全链路的转型经验通过平台化全面对外输出，借此实现了产业级的巨大跃升。”</p><p></p><p>在他看来，宝信软件的成功，是数字产业化和产业数字化模式相结合的典型。但是，目前大多数国企仍然还处在产业数字化建设阶段，通过数字产业化沉淀自己的产品和解决方案的案例还为数不多。“数字产业化发展是新的经营战略，需要沉淀核心产品和商业战略。这需要一定时间周期才能产生聚合效应，在整个产业基础打好之后，才可能在某个时间点出现业务的规模化增长。”</p><p></p><p>当然，以上是几乎所有企业普遍面临的共性挑战，但如前文所说，央国企是经济的“压舱石”，其业务发展的第一目标是稳定经济，因此，数字化转型容错试错的空间较小。同时，央国企通常覆盖多元产业，组织层级繁多、人员规模庞大且管理结构复杂。</p><p></p><p>这就要求央国企在推进数字化转型过程中更要找到策略的平衡点，在内部机制调整方面要投入更大的精力和努力。</p><p></p><p>这就对企业数字化的牵头人提出了极高的要求，“他要能足够吸取成功和失败的经验，并且说服上级管理、内外部伙伴以及下属机构等，要有调动各种资源并进行优化组合的能力，能够把业务和技术板块融合在一起，既能完成近期、中期和远期的任务，又能激发大家的动力。”</p><p></p><p>孙司雷认为这像是一个“艺术家”的工作，但目前市场这类人才凤毛麟角。“如果企业能找到这样的<a href=\"https://b.geekbang.org/?utm_source=geektimeweb&amp;utm_medium=menu&amp;utm_campaign=entranceplatform&amp;gk_source=2021090101_geektimeweb_menu\">人才</a>\"，数字化就等于已经成功了一半。”他表示。</p><p></p><h3>数字化领先企业的四点共性经验</h3><p></p><p></p><p>在为众多央国企和其它油气行业企业提供数字化咨询服务的过程中，孙司雷及其团队积累了大量成功“样本”，总结在数字化转型中走在前列的企业的共性经验，孙司雷认为主要有以下四点：</p><p></p><p>第一，在认知方面，对数字化抱有全面认识，能够做好长期投入的准备，并且逐步探索、保持耐心，并据此进行体系化、机制化的路径设计，而不是仅为解决临时的具体问题。</p><p></p><p>随着今年<a href=\"https://www.infoq.cn/article/LBC3Rujd6xFoYfS2duGf?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">《数字中国建设整体布局规划》</a>\"的发布，央国企数字化战略基本可以遵照“数字中国”建设的“2522”整体框架进行制定和布局，由于顶层设计和思路趋同，具体的实施策略和路径就成为关键。</p><p></p><p>“因为落地机制因企业而异，对于央国企而言，内部基本上都有固定的运转机制，如何处理好任务优先级、把数字化工作融入到整个蓝图中就变得非常重要。在这个过程中，要利用好政策资源和产业力量，因势利导完成关键项目。同时定期拿出标志性成果，培育好数字化品牌。”孙司雷表示，除此之外，还要通过把稳态和敏态相结合实现产业稳定运营的首要目标，在创新探索过程中设定好容错和迭代机制。</p><p></p><p>第二，在文化方面，能够将战略渗透到企业全员中，关注价值导向和解决实际问题，注重数字文化和数字素养的建设，并且保持开放和创新，构建完善的探索机制。</p><p></p><p>孙司雷认为，企业文化具有导向性，数字化转型并不是为了强迫所有人使用新的系统和工具，而是让所有人在其工作范围内主动使用数字化工具、模型和数据。这意味着，数字化不再是某个条线、某个部门的事情，而是<a href=\"https://www.infoq.cn/article/zvjR1E1wzUVeLbseYJ4r\">全员的事情</a>\"。</p><p></p><p>“很多企业把数字素养培育作为单独任务来布置和推进，这会在一定程度上提升数字化平台的使用率，但是，如果员工无法在意识上发生转变，规模化创新和良性循环的建立就难以实现。”孙司雷进一步介绍，“为此，企业需要构建与数字化相匹配的文化体系，并且让这种文化体系能映射到员工的具体行为中，包括招聘和考核等环节。”</p><p></p><p>今年，大模型技术成了热门话题，这项技术将助力企业完成数字化文化的渗透。“为了配合数字化转型，企业往往需要建立全新的管理体系，这对员工产生了新的约束。但如果我们能够把员工日常的繁琐工作交给人工智能，让他们只需进行简单的人机交互，我相信大多数人都会接受这种创新的工作模式。”</p><p></p><p>第三，在组织架构方面，我们看到拥有完善数字化组织体系的企业非常重视企业架构建设。基于这样的基础，企业可以充分利用核心资源，形成完整的协同机制，为战略的实施提供保障。</p><p></p><p>孙司雷介绍说，目前很多央国企都在进行企业架构的研究，其中南方电网成立的企业架构部就是一个典型的例子。通过企业架构，锚定战略落地，构建横向协同、纵向贯通的业务架构，构建敏捷统一、数智赋能的 IT 架构。这一模式为央国企落实国家战略、实现数字化转型以及推动企业管理体系和管理能力现代化提供了经验参考。</p><p></p><p>第四，在心态方面，企业始终要保持开放，注重各个方面的输出和交流，同时实事求是，保持“空杯”心态。但同时，也要转变“拿来主义”的固有思维，充分结合自身发展情况，以自我为中心进行学习、交流和合作。</p><p></p><p>“成功的企业之所以成功，是因为他们并不是把数字化作为最终目标，而是不断追求更适合、更敏捷，以及更大的价值。”孙司雷提到，“简而言之，数字化转型永远在路上，永远不会实现 100% 覆盖，而是持续向 100% 无限逼近。企业通过持续的数字化努力，将引领行业，创造出更多的可能性。”</p><p></p><h4>关于昆仑数智</h4><p></p><p></p><p><a href=\"http://www.klszkj.com/\">昆仑数智</a>\"作为中国石油集团下属科技公司，始终以“数字化转型赋能者”为定位、以助力“数字化转型、智能化发展”为使命。我们深入研究产业技术与数字技术融合发展趋势，全力打造数字化转型、智能化发展的新引擎。我们致力于成为国内领先、国际一流的能源行业和流程工业数字化智能化科技公司，为企业的数字化转型、智能化发展贡献力量。</p><p></p><p>数字化咨询中心以其昆仑数智高端智库的定位，致力于打造高端化、体系化、专业化咨询能力，成为数字化转型政策研究参与者、咨询服务引领者和生态体系推动者。面向国家部委、中国石油集团总部及专业公司、其他央国企等三类客户，提供战略决策、研究咨询、智库研究、生态与合作等四类服务，并沉淀形成国有企业数字化转型、油气数字化转型、国资监管数智化等能力。凝练出一系列理论研究成果、一批典型实践案例、一套关键数据，形成一套智库能力建设与咨询服务的方法论，构建出一套央国企智库合作生态体系，提高智库服务创新性、价值性和实践性，发挥引领油气行业和国资央国企数字化咨询、研究、培训和生态服务标杆作用，为行业提供具有前瞻性的解决方案和咨询服务，为客户提供多元化的数字化转型服务和赋能应用而贡献力量！</p><p></p><p></p><blockquote>📣&nbsp;&nbsp;欢迎向「InfoQ 数字化经纬」投稿，与我们共享您的思考、洞见和实践经验！投稿可邮箱至 editors@geekbang.com（邮件标题前注明【数字化投稿】）</blockquote><p></p>",
    "publish_time": "2024-01-23 13:48:28",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Big Data：From Theory to Systems",
    "url": "https://www.infoq.cn/article/xmMKxsoHi1raqCmCgFj1",
    "summary": "<p>Qcon上海站，中国科学院外籍院士、国际数据库专家，樊文飞教授坐镇大会，主讲大数据如何从理论到系统，从五个角度：Volume, Variety, Velocity, Veracity, Value 大数据的量，数据多样性，数据质量，数据价值，动态数据等，通过大量应用实践案例阐述大数据理论与系统的关系。</p>",
    "publish_time": "2024-01-23 14:05:30",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "纯干货｜聊一聊大促活动背后的技术：火山引擎边缘云 CDN/DCDN/GA",
    "url": "https://www.infoq.cn/article/RE9lGXuy2Q63rplWALN8",
    "summary": "<p>去年 12 月 12 日，“抖音商城双 12 好物节”正式结束。据了解，双 12 期间，抖音电商推出了超值购、秒杀等多个优价频道和多个类目的主题榜单，让有消费需求的用户更高效地发现高性价比好物。除了货架场景，“抖音商城双 12 好物节”还发力重点达人直播间、好物直播间等内容场域，通过电商优质内容为商家和达人创造生意增量。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/06/06d4e29a20e5d76dd972449f8b86da53.jpeg\" /></p><p></p><p>“抖音商城双 12 好物节”的背后是大流量、高并发对基础技术提出的挑战，保障大促期间平台的平稳运行、用户流畅的购物体验尤为重要。在经受了双十一海量流量考验的基础上，火山引擎 CDN/DCDN 和 GA 作为抖音静态/动态/长连接业务流量入口，保障了大促期间抖音电商平台的平稳运行。</p><p></p><p>下图为抖音客户端视频业务/动态接口/长连接业务主要流量架构图，客户请求通过火山引擎内容分发网络（CDN）、全站加速（DCDN）、全球加速（GA）回源到中心网关，转发到对应的业务服务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/68/6828e38562e38b7513c195127bfb4312.png\" /></p><p></p><p></p><h1>技术架构</h1><p></p><p></p><p>火山引擎 CDN/DCDN 和 GA 利用丰富的网络资源，依托边缘云全球网络（含到主要地区的合规专线）降低网络抖动、时延和丢包，显著提升传输效率，结合自研的传输优化、智能缓存、动态路由、安全防护等能力，为用户提供安全、稳定的一站式加速服务，提升用户访问体验。</p><p></p><p>火山引擎内容分发网络产品 CDN&nbsp;(Content Delivery Network）提供稳定、弹性、高性能的全球内容分发服务。 火山引擎全站加速产品 DCDN&nbsp;(Dynamic Content Delivery Network) 是一款在 CDN 静态内容加速服务的基础上，提供纯动态及动静态混合内容加速的服务。火山引擎全球加速产品 GA（Global Accelerator）是一款实现全球范围网络就近接入和跨地域部署的四层网络加速服务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f2/f27136c663a5c4a0b70386f2a0636bae.png\" /></p><p>                                                火山引擎CDN/DCDN/GA资源分布</p><p></p><p>火山引擎 CDN/DCDN/GA 通过抖音集团业务和规模化 ToB 业务的打磨，已经形成了一套完备且具备规模商业化能力的系统。</p><p></p><p>资源分布：全球 2500+加速节点，国内实现三大运营商本省覆盖，海外覆盖了主要国家和地区；丰富协议：支持 HTTP(S)、QUIC、WebSocket、TCP、UDP 协议接入；智能调度：保证客户就近接入，实现大规模 QPS 的全网调度；智能路由：自研智能路由系统，保证请求最优路径回源，提升用户体验；传输优化：通过协议优化、回源预建连、公网路由择优等策略，提升动态 API、上传、下载等各个场景的传输速度；安全防护：支持大容量的 DDoS 防护、CC 防护、Web 漏洞防护，全链路 HTTPS（支持国密协议），确保数据传输安全；稳定性：通过大规模 QPS 的验证，稳定性经过充分验证，经历了抖音春晚红包、抖音世界杯直播、抖音电商双十一等大型活动考验。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c6/c624f7a00b08746bd1a816bbfb58377b.png\" /></p><p>                                           火山引擎CDN/DCDN/GA网络拓扑</p><p></p><p></p><h1>解决方案</h1><p></p><p></p><p>火山引擎 CDN/DCDN/GA 作为抖音业务动静态流量入口，在双 12 期间，不仅要承载常态流量，还需要应对大促带来的洪峰流量冲击，这对火山引擎 CDN/DCDN/GA 的容量、调度能力、容灾能力都提出了更高的要求。对此，本文从 5 个方面介绍应对双 12 突发流量时火山引擎 CDN/DCDN/GA 提供的解决方案。</p><p></p><p></p><h2>动态扩容</h2><p></p><p></p><p>为了解决大促高峰时间段的资源不足问题，火山引擎 CDN/DCDN/GA 采用动态扩容技术。双 12 带来的流量是脉冲式流量，持续时间短，峰值高。虽然火山引擎 CDN/DCDN/GA 常态下会保留一定的流量冗余，但依然无法应对大促带来的突发流量。如果想要通过短时间内完成大量边缘节点扩容来解决这一问题，不仅操作难度极大，而且仅为活动进行大规模扩容，也会造成资源浪费。因此，如何动态扩容以应对短时间洪峰流量，是火山引擎 CDN/DCDN/GA 产品在双 12 遇到的主要挑战之一。</p><p></p><p>火山引擎 CDN/DCDN/GA 使用火山引擎边缘云统一技术底座，主要流量运行在边缘云容器/虚拟机上。因此可以在活动正式开始前，充分利用边缘容器平台的弹性能力，快速创建出一批新资源，完成资源动态扩容，满足活动期间的容量需求。在活动结束后，将扩容资源释放，实现整体容量的快速扩缩。</p><p></p><p></p><h2>流量调度</h2><p></p><p></p><p>为了应对突发流量，火山引擎 CDN/DCDN/GA 引入“活动”流量模型。常态下，火山引擎 CDN/DCDN/GA 会根据业务实时以及最近几天的 QPS/带宽/连接数进行调度，但面对双 12 带来的突发流量，这种调度模式显然无法适应。</p><p></p><p>为解决这个问题，火山引擎引入了“活动”流量模型。假设活动期间各个地区的流量分布与常态流量一致，根据业务预估的总 QPS/带宽/连接数，按比例分配到不同地区。在进行调度时，将预估的活动流量一并纳入考虑，因此调度后的节点能够承载活动突发流量。同时会根据前一天的流量值修正下一次活动流量模型。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d6/d6851040f9121b88596a86160017ee4a.png\" /></p><p>                                                     引入“活动”的流量模型</p><p></p><p></p><h2>自保能力</h2><p></p><p></p><p>为了应对容量风险，火山引擎 CDN/DCDN/GA 具备熔断能力实现自保。资源和调度已具备应对预估峰值的能力，但业务预估流量跟真实流量很可能存在偏差。如果业务预估比真实流量低，突发流量很有可能超出 CDN/DCDN/GA 服务上限，当出现短时间的可用性降低、请求耗时增加后，会触发客户端不断重试，进一步加剧服务压力，极有可能造成线上整体的雪崩，影响产品请求。</p><p></p><p>因此，为了应对极端场景的风险，CDN/DCDN/GA 需具备熔断能力，当请求量达到一定阈值后，通过熔断降低系统压力，保证线上主要业务流量的稳定性。</p><p></p><p>活动期间，主要有以下容量风险：</p><p></p><p>CPU 资源风险：大量客户端冷启，新建连接（CPS）突增，抖音支持全链路 HTTPs，因此冷启客户端会进行大量的 SSL 握手，消耗 DCDN 节点大量 CPU 资源；QPS 突增风险：电商 API 接口请求量（QPS）突增，超过 CDN/DCDN/GA 处理能力上限，造成服务崩溃；请求堆积风险：随着 QPS 突增，活动业务后端服务压力增加，响应耗时变大，造成大量请求堆积，拖垮 CDN/DCDN/GA 和业务服务。</p><p></p><p>为了应对上述风险，火山引擎 CDN/DCDN/GA 产品引入多维度熔断能力：</p><p></p><p>CPS 熔断能力：针对最耗费 CPU 的 SSL 握手，支持针对单域名和全局 SSL 握手限流能力，当单个域名的 SSL 流量超出阈值后，将拒绝新 SSL 请求，避免打爆 CPU；QPS 熔断能力：当活动域名的 QPS 超过设定阈值后，拒掉新请求，避免过多请求回源，保护自身和源站服务；回源熔断能力：当单个域名同时回源的请求达到一定阈值后，新的回源请求会在 CDN/DCDN/GA 直接熔断，响应异常码，避免业务服务响应变慢后，请求堆积拖垮业务后端服务。</p><p></p><p>上述熔断能力，均支持单域名和全局粒度。</p><p></p><p>单域名熔断：主要针对活动域名配置，避免活动域名突增影响全局流量。全局熔断能力：主要是保护DCDN服务，当超过DCDN服务能力上限后，熔断一部分流量，保证大部分流量可正常服务。</p><p></p><p></p><h2>流量压测</h2><p></p><p></p><p>具备资源、调度、熔断能力后，还需要在活动之前对上述功能进行验证。对此，火山引擎 CDN/DCDN/GA 与抖音客户端合作，进行全链路压测，利用真实的客户端请求，模拟活动期间洪峰，验证全链路的处理能力。</p><p> </p><p><img src=\"https://static001.geekbang.org/infoq/af/af9cbde0e08d6e096b4f24df1d035dd4.png\" /></p><p>                                                          流量压测曲线</p><p></p><p></p><h2>加速性能</h2><p></p><p></p><p>性能接入是加速产品最重要的衡量指标之一。如何更好的提升性能，也是火山引擎 CDN/DCDN/GA 产品持续探索的方向，经过多年的打磨，沉淀了经验，以下是火山引擎 CDN/DCDN/GA 产品在性能优化方面的主要策略。</p><p></p><p></p><h3>智能调度</h3><p></p><p></p><p>移动端用户通过 4G/5G/WIFI 无线网络访问源站应用，信号不稳定，如果直连源站，RTT 较长，按照主流的基于 ACK 反馈或超时来判断丢包的拥塞控制算法，需要很长时间才能感知到丢包，再进行重传，导致时延非常大，如果通过更近的接入点上车，移动端和节点之间RTT更短，就可以更快感知到丢包，更快进行重传，降低时延。</p><p> </p><p>火山引擎 CDN/DCDN/GA 自研的智能调度算法会基于用户分布情况，动态实时计算出接入质量更优的节点，例如在某城市，会根据用户分布的集中度，选择离大多数用户更近的接入点上传，相比传统的 DNS 调度能更好的实现就近接入，提升用户体验。</p><p></p><p></p><h3>智能路由</h3><p></p><p></p><p>广域网网路存在复杂的运营商和地域限制策略，经常出现绕路、限速等情况。针对此问题，火山引擎自研的智能选路系统可在复杂的广域网中实时选择最优路径回源，保障业务的最佳体验。智能路由解决的是多目标路径规划问题，需要兼顾性能、容量等，重点是归一化目标函数设计。火山引擎</p><p>CDN/DCDN/GA 综合考虑了链路质量、节点水位、亲缘性等目标，同时根据不同的业务场景（API、上传、下载等）采用不同权重值，保证各种业务场景按照最佳链路回源。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fc/fc8da6e3db4ae87b5670ad3aa2474e96.png\" /></p><p></p><p></p><h3>传输优化</h3><p></p><p></p><p>协议栈优化：回源链路采用火山引擎自研的 TTCP 协议栈，TTCP 具备内核插件化能力，已在火山引擎 CDN/DCDN/GA 全网部署，支持域名粒度控制，可根据业务场景（API、上传、下载）实现精准化的参数控制和自适应拥塞控制算法，保证最佳的访问体验。同时 TTCP 实现了平台化的管理，利用采集现网数据通过大数据实时分析决策动态的调整系统参数和拥塞控制算法，提升访问体验。</p><p></p><p>连接优化：火山引擎 CDN/DCDN/GA 产品为提升访问性能、降低中心服务的压力，采取了“预建连”优化手段。节点在没有真实请求时，主动与源站建立一批连接，维护在连接池内，当突发业务请求到达，回源时可直接复用连接，提高访问性能。通过抖音集团内部业务测试显示，采用预连接策略后，首包时间耗时从 115ms 降低到 54ms，降低了 53%以上，效果明显。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d3/d345fb8e1fc1d0e6ca9e8435858e6f47.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7e/7e4cad5ed9bbceb87493ef0524655705.png\" /></p><p></p><p></p><h1>应用案例</h1><p></p><p></p><p>火山引擎 DCDN 承载了双十一期间抖音业务主要 API 流量，在双十一的洪峰挑战中保证了用户最佳购物体验，性能、稳定性得到了充分验证。通过客户端监测数据，火山引擎 DCDN 活动期间服务稳定，且加速性能达到行业领先水平。</p><p></p><p>1. 抖音短视频：抖音短视频核心 Feed 流 API 请求通过开启 QUIC 协议，采用智能路由、预建连等优化策略，网络耗时均值降低 7%以上，长尾耗时降低 17%以上，人均播放时长等核心业务收益显著正向。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/07/077daeb52d38f2968c14fdb77a24daf9.png\" /></p><p></p><p>2. 抖音电商：结合边缘高防调度以及边缘 WAF 能力，解决 API 防护、 DDoS 和 CC 攻击、保护内容不被恶意爬取、劫持、篡改等，通过自研的传输优化、智能缓存、动态路由等技术提供了纯动态及动静态混合内容的加速服务，为用户提供更优质的访问体验。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/88/8877aef82d5b7f936dc9ccd4e7f8f4c2.png\" /></p><p></p><p></p><h1>展望未来</h1><p></p><p></p><p>火山引擎 CDN/DCDN/GA 自上线以来，通过字节内部大规模 QPS、亿级并发连接数的验证，经历了双十一、春节活动、世界杯等大型活动考验，经过多年的打磨，性能、稳定性达到业内领先水平，沉淀了典型应用场景的加速解决方案。火山引擎 DCDN 和 GA 先后于 2021 年和 2022 年正式 ToB，把服务抖音业务的技术积累提供给更多的外部客户。</p><p></p><p>下一步，火山引擎 CDN/DCDN/GA 会继续进行深度优化，持续降低访问时延，比如在加速网络内部使用基于 UDP 的私有协议，针对动态 API、上传、下载场景使用更加自助可控的丢包检测和拥塞控制算法，另外结合端上的能力，针对时延敏感性业务，比如游戏场景联动火山引擎游戏加速解决方案 GNA 支持全链路的加速能力，开启 FEC、双通道、网络检测能力等，为用户提供极致性价比的加速服务。</p><p></p>",
    "publish_time": "2024-01-23 14:23:16",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "连接云-边-端，构建火山引擎边缘云网技术体系",
    "url": "https://www.infoq.cn/article/JOGNSaNEdUlZK9QSzOxN",
    "summary": "<p>近日，火山引擎边缘云网络产品研发负责人韩伟在 LiveVideoStack Con 2023 上海站围绕边缘云海量分布式节点和上百 T 的网络规模，结合边缘云快速发展期间遇到的各种问题和挑战，分享了火山引擎边缘云网的全球基础设施，融合开放的云网技术体系以及未来火山引擎边缘云网的发展展望。</p><p></p><p>迄今为止，云计算已经发展了近二十年，成为了事实上的社会基础设施。5G 时代到来后，消费互联网开始不断向产业互联网延伸，涌现了物联网、车联网等大流量、低延迟、高并发的场景。原有云端的架构难以满足新场景下产生的各种需求，这促进了算力持续下沉，数据落至边缘。随着边缘云在不同场景的渗透，云中心和边缘结合的基础架构将成为新一代的基础设施，边缘云会加速进入成熟期。</p><p></p><p>韩伟表示：边缘云快速发展，需要网络的完美支撑。只要网络出去，算力就能出去，这也是火山引擎边缘云所持续突破的目标，即让连接和计算无处不在。如何构建一张融合开放的网络来连接算力、数据、场景甚至多云？以下将分享火山引擎边缘云网络技术体系建设路径。</p><p></p><p></p><h1>火山引擎边缘云网基础设施建设</h1><p></p><p></p><p>首先是建设全球云网的基础设施，火山引擎在 2020 年开始大力建设边缘云的资源底座，目标是提供全球统一的资源及技术底座支撑业务的快速发展。截至去年，已经覆盖了 50+国家，1300+节点，全网的带宽储备达到 110Tbps+。</p><p></p><p>此外，火山引擎选取了一些优质的区域节点，在不同的节点之间通过专线进行互联，同时还覆盖了不同国家和地域的跨域专线，通过节点互联，结合海量的分布式节点，构建了一张全球的骨干网络，很好地满足了业务的快速发展。基于这张全球骨干网络，向上支撑了内容分发网络、联网与加速相关的产品体系、以及安全防护一体的整个边缘云网的产品矩阵。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d8/d8da897dd391bd2792a03486421f15d1.png\" /></p><p></p><p>这张网络具备以下几点特征：</p><p></p><p>首先，超大的规模与弹性。上文提到骨干网络有海量的分布式节点，整体储备带宽达到 110Tbps+，此外，火山引擎边缘云在不同节点选取了高性能硬件，并基于此构建了整个边缘云的云原生操作系统。经历抖音的春晚、双十一、世界杯以及内部业务突发情况的锤炼。目前，边缘云基础设施在具备一定规模的同时还具备了较好的弹性。</p><p></p><p>第二，骨干网络的打通。包括跨域专线、区域节点互联，真正做到了基础设施层面的全球一张网，为上层业务的互联互通打下了基础。</p><p></p><p>第三，安全可靠。火山引擎边缘云基于业务诉求，选取部分节点建设了高防的清洗中心。不同的节点具备云原生的 DDoS 和 WAF 防护能力，从而为上层业务保驾护航。</p><p></p><p>最后，节约成本。抖音规模已经非常大，火山引擎边缘云将抖音的业务规模对基础设施的资源需求和 ToB 做了并池，使其在更大范围内复用，极大优化了成本。</p><p></p><p>此外，火山引擎边缘云在边缘云网体系以及边缘计算节点体系中搭建了运维和管理的相关平台，降低运维成本的同时提升了运维效率。</p><p></p><p></p><h1>构建火山引擎边缘云网的技术体系</h1><p></p><p></p><p></p><h2>火山引擎边缘云网解决方案</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/de/de0902873bb357e75e7c2491a20eb18c.png\" /></p><p></p><p>边缘云网的解决方案已经连接了云、边、端，从下向上首先是整个网络的基础设施。</p><p></p><p>火山引擎边缘云拥有海量分布式节点，并在线路较好的资源节点做了专线的资源覆盖。整体在基础网络层搭建了一张全球骨干网络，合规跨境上则覆盖了东南亚/中日/中韩/中欧等主要区域。为了更好地使用这张基础物理网络，火山引擎边缘云在此之上抽象出了边缘互联服务，能够结合边缘节点的公网带宽、专线容量进行整体的调度容灾，从而为上层业务提供更好的复用能力。</p><p></p><p>除了结合网络基础设施的底座之外，火山引擎边缘云还推出了边缘联网的产品体系，覆盖了 SD-WAN+产品，边缘接入产品、跨境加速以及边缘计算节点网络相关能力；通过 SD-WAN+，能够在端侧支持 VPN、移动 APP 及 CPE 设备的接入。在边缘接入侧，通过专线的接入能力，能够解决企业上云相关场景；通过边缘节点间联网能力，可以连接不同的计算节点，最终形成一张由分布式节点构成的具备业务自治能力的云上网络。</p><p></p><p>基于这个边缘联网的产品体系，火山引擎边缘云构建了覆盖 3-4-7 层、连接了云/边/端的网络加速体系，分为三个产品：第一个是全球加速，面向 4 层加速相关场景；第二个是 DCDN，支持一站式动静态混合网络加速服务，第三个是面向游戏相关场景的 GNA。GNA 在 APP 上会有加速和诊断的能力，再结合云上的路径择优、网络调度，能够为游戏加速行业的客户提供更好的服务体验。左侧是边缘计算节点，边缘计算节点的商业化会对网络提出云化的需求。火山引擎边缘云研发了满足边缘计算节点发展相关需求所必需的产品能力，包括 VPC、负载均衡、NAT、EIP。不同的边缘计算节点之间能够通过边缘联网的整个体系互联互通，连接到一起。</p><p></p><p></p><h2>火山引擎边缘云网技术体系</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7b/7b4f92598349e21d2d7931fea5ff66c8.png\" /></p><p>                                                      图为边缘云网技术体系</p><p></p><p>最下层的基础设施有以下特征：覆盖全球的边缘节点，目前火山引擎的规模比较庞大，带宽储备比较充足；覆盖全球的骨干网络，包括国内和海外，具备一定的专线资源覆盖；优质线路，在选取节点的同时对线路的选取也有比较高的要求，火山引擎边缘云提供了优质的单线及三线带宽资源；丰富的硬件形态，针对不同节点的容量诉求及节点的规划，我们提供丰富的硬件形态，能够满足不同场景需求。</p><p></p><p>基础设施之上是技术层。首先，网络转发平台提供 EVS、EGW、TTGW 三个转发平面。其中 EVS 是主机网络，支撑虚拟机和容器的算力资源，提供网络隔离、网络限速及安全组等能力。EGW 是融合网关，边缘节点是异构的，有海量的分布式节点，我们把很多网络能力融合到一个融合网关中，它是整个边缘云 To B 的网络和安全的流量入口以及安全支点。TTGW 是核心网关，整个集团的所有流量的公网入口都基于此构建，它同时承载了高防的流量入口。基于以上三个不同场景功能组件的诉求，我们在底层抽象出了一个网络转发框架，以解决设备异构问题，提供软硬一体的转发能力。此外，网络转发框架中沉淀了通用的性能优化相关能力，能够为上层不同数据面的组件提供更好的复用。其次是基础云安全，我们协同安全团队提供原生防护能力、主机安全以及高级网络威胁检测能力。</p><p></p><p>在边缘云上，有 CDN、DCDN、GA 和 GNA 等不同的网络加速场景，其中很多能力具备一定的通用性，于是火山引擎边缘云抽象出了网络加速平台。未来，网络加速平台还会对外开放，它将具备以下能力：第一，多维调度能力，能够基于成本、质量、容灾，提供不同维度的调度能力，供各个业务选择；第二，通过自研的私有协议更好地优化传输体验，同时在传输优化方面开展了较多探索工作，提升了整个传输的性能。此外，在数据压缩上包括头部压缩及报文压缩，能够有效降低数据传输的负载。在路径探测方面，包括端探测及转发探测进行了有机的融合，能够更快速地发现并定位整个数据转发路径中的各种问题，从而快速恢复。</p><p></p><p>整个边缘云网体系中的产品非常多，为了简化配置平面的复杂度，我们将其抽象为北向的业务编排，南向的设备管理以及通用的技术服务。</p><p></p><p>在北向，可以继续抽象为面向业务的核心控制层，如 VPC、SD-WAN、EIC 边缘互联。这里北向主要面向用户配置，包括控制台及 OpenAPI 层，有许多业务自身的语义，需要元数据存储，进行元数据编排，形成底层能够理解的基础配置平面。</p><p></p><p>第二层面向设备，所有的配置下发需要连接设备、管理设备、探测设备。其中，面向设备有许多通用能力，我们构建了高性能的配置下发通道，并提供设备的水位管理，配置管理能力，通用的配置序列化通道；在资源调度层面，提供跨集群资源调度能力。举个例子，在多 Group 场景下，比如一个配置应该落在哪个 Group，需要根据配置水位及实际水位的情况，做全局调度优化；我们会在通用管控层抽象出通用的框架能力，从而满足各个业务方的需求。基础服务层也是一层抽象，其中有很多抽象出的原子的能力，能够被各个业务复用，包括任务调度、动态配置下发，如增量全量的配置下发、配置对账、一致性巡检，这些都能够在动态配置层被屏蔽。此外是针对南向的配置，编排之后的数据存储。</p><p></p><p>右边是结合网络运维及产品研发需求搭建的智能网络平台，主要面向运维、产品、售后、运营及研发等不同角色对网络平台的需求。基于此平台，做了变更的白屏化、自动化、告警、巡检、大盘展示、水位管理。面向产品售后提供部分问题根因分析能力，如一键诊断能力。</p><p></p><p>网络的前台面向用户，而上述能力的采集、聚合、清洗则在中台完成。对于这个智能网络平台，未来我们希望能够将一部分能力赋能客户，比如用户使用了云上的许多资源，它的管理如网络拓扑管理比较复杂，那么通过网络拓扑的可视化、网络路径的分析能够帮助用户更好地管理网络。其次，当用户配置比较多时，经常会出现错误配置的情况，或者配上后健康检查不通，但用户发现不了，那么便可以通过一键诊断能力，在用户配置完成后，结合其配置做预检查，发现问题后给用户提示。</p><p></p><p>综合以上的能力，边缘云网技术体系便能够很好地支撑计算服务及网络服务。</p><p></p><p></p><h2>火山引擎边缘云网的技术特征</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b7/b79ecb3f3dad3f866f2b109f767555c4.png\" /></p><p></p><p>结合上文提到的产品体系及技术体系，这张网络的特点如下：</p><p></p><p>云网一体，多点协同：GNA 产品在游戏端的 APP 上有 SDK 部署，而 SD-WAN+在端侧有 CPE，APP 及 VPN 等不同端的接入能力，基于端的连接及管理能力，我们能够更好地和云上协同。同时，边缘智能一体机会在近场、现场的边缘部署。围绕边缘的分布式节点，我们会有许多互联及加速相关需求。目前这张网络的基座已经具备了通用加速和通用互联能力，此外，我们围绕边缘和中心的协同，在回源加速、带宽降本方面做了很多优化。静态带宽能够为更多业务所复用，云边互通能够支持公网及内网的互通。</p><p></p><p>融合网络，更高性价比：边缘的网络相比中心会更加复杂，线路资源也更多样化，包括小运营商，单线、多线公网带宽，及回源专线、跨境专线。对于如此复杂的网络，我们需要在更多维度进行调度及融合，给业务提供更极致的性价比，其中必需的是基于成本、质量、延迟的全局调度。</p><p></p><p>小型云化，灵活部署：边缘云的节点比较多，异构比较复杂，不同节点的容量也各不相同，对成本灵活度的要求也随之提高。为了满足不同节点对网络的差异化需求，对外体现相同的服务界面和产品界面，我们把很多网络能力融合到同一个网关中，这是 All in one 的策略。比如公网入口、安全防护、跨域互联、专线接入都通过融合网关构建。其次，网络组件非常多，上文提到许多产品是由较多的技术组件组成，为了解决灵活性的需求，我们支持裸金属、虚拟机、容器的灵活部署，同时在不同的节点上，虚拟机、容器、网络、存储也具备按需混合部署能力。通过这一系列的灵活部署能够更好地满足分布式云的小型云化需求。</p><p></p><p>超大规模，全球覆盖：目前，火山引擎的全球节点达到 1300+，网络带宽达到 100Tbps，无论是线路选择、节点互联、跨域覆盖，都形成了一张全球优质的加速网络。</p><p></p><p>软硬一体，高性能转发：边缘云分布式节点比较多，而且大小容量差异性非常大。在边缘会有部分大容量节点及大流量场景，包括核心机房业务，我们支持 P4 导流网关，单机能跑 3.2T 流量，可以级联到不同的软件转发能力上，通过 Overlay 的灵活调度和封装解决网络转发在全网的灵活弹性伸缩能力。其次，集团场景如今日头条、TikTok、抖音对核心的负载均衡提出了更高的要求，基于软硬一体的技术 目前我们单机已经能跑到 800G 带宽。最后，EVS 主机网络在边缘也会面临着更大的挑战，主要是边缘机型的差异化，网卡的差异化，我们按照产品需求及规划，在部分机型及场景下进行了网卡 Offload 的优化。</p><p></p><p>全面上云，稳定可靠：边缘云的资源池是高度统一的，设备、带宽、专线都统一到了相同的资源池。面向不同的计算、网络、存储相关场景，我们在同一个资源池做复用和调度，从而更好地提升资源的利用率和复用比。第二点是内外统一，大家看到的边缘云上所有的产品，无论是界面还是服务都与内部高度统一，我们将许多内部的业务跑到了标准的 To B 产品上，可以更好地打磨产品体系。目前，CDN、DCDN、GA 等产品已经全面上到边缘计算节点上，因此，火山引擎边缘云是经过大规模验证的，安全可靠的一朵云。</p><p></p><p></p><h1>展望未来：网络先行，驱动业务发展</h1><p></p><p></p><p>在边缘云快速发展的过程中，韩伟对火山引擎边缘云网络有了更多的思考——网络先行，驱动业务发展。</p><p></p><p></p><h2>传输可视，数据驱动的网络智能平台</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/07/07800b00af21397fddeddea4fa1fb0d8.png\" /></p><p></p><p>从定位来看，网络连接了算力、数据及不同的场景，所以各个产品和业务对它都有非常多的诉求。但网络经常遇到各种各样的问题，如网络不通、丢包、速度慢，出现问题时候很难精确定位。在边缘云上，这个问题会放大。边缘云不同节点之间的规模差异较大，分布式节点较多，很多的场景，需要互相联动，节点之间还要互联，所以业务依赖比较重，转发路径比较长。作为云计算的厂商来讲，上面一定会有各种各样的租户，承载的租户又非常多。所以整个网络的服务，其实面向了业务，面向了售后，面向了客户，挑战非常大。</p><p></p><p>站在我们的角度来看，私网是相对容易可控的，所以目标是能直接定位问题。对于公网，有一段是不可控的，所以在可控的范围内定位问题，在不可控的范围内做到能很快地定界，即判断是私网的问题，还是公网的问题。</p><p></p><p>基于这样的背景，我们想去把网络的分层，做一个传输的刻画。</p><p></p><p>首先是网络层，面向 3 层，有很多的业务基于 3 层做网络的互联互通，我们会在整个网络体系里增加很多的埋点，会对报文做染色，记录走了云上的哪些组件、产品、软件等，我们通过软件定义网络的思想，会给这个报文去打标，当它丢掉后，能够知道它的源端、目标在哪里，路径是什么样子的，判断出它在哪个路径的哪个点上丢了包。通过路径覆盖的能力，再结合场景的覆盖，可以把很多的场景枚举出来，当场景出现问题时，埋点能够及时启动，就可以快速地定位问题。</p><p></p><p>此外，我们还建设了比较完善的异常发现体系，在告警、监控、巡检、丢包方面，增加了比较细粒度的数据采集，希望能先于客户先发现问题，有更多时间来快速修复它。</p><p></p><p>最后是可用性探测，云上的实例数量非常多，出了故障之后，我们需要快速判断清楚它的影响面，所以会对云上的所有资源做一些低频的可用性验证。比如 DC 故障之后，很容易看到哪些可用率发生了大规模下降，从而更好地看到影响面。</p><p></p><p>在传输层，上文提到的产品中很多是基于 7 层应用代理转发的。在客户端到代理这一侧，其实是一个连接，代理到后端的终端节点之间，是另一个连接，中间是一个请求。站在请求的角度来看，我们没有办法把客户端包括服务端的连接，连接在一起，因为中间被代理截断了，所以看不到整体。出现问题后，只能去查日志分段定位，看一下到底是请求等待的时间太长，还是建连或响应的时间太长。我们希望不管是基于 kernel 还是用户态的协议栈，都能够刻画出整个传输过程，比如首包时延，响应的时间，整个建连包括请求等待的时间，然后在用户态抽象出客户端的连接和服务端的连接，这样在连接层面能看到从客户端到真实服务端之间的链路。在请求的维度，也可以把它关联到一起，这样当一个请求慢了之后，能辨别是连接层面还是应用软件本身发生了问题。</p><p></p><p>在应用层，结合日志分析系统，可以研发异常发现的能力，比如状态码、请求的响应时间，包括请求的地域来源、目标资源，能够做很多的聚合，比如哪些资源有问题，哪些地域有问题，通过异常发现，获取业务分布，帮助用户量化体验。</p><p></p><p>在结合网络层、传输层、应用层后，能够高效直接地定位许多网络上的问题。基于这样的思考，我们会推出一个网络智能的平台，前面提到的是站在运维运营角度，而这里是指在网络传输，包括网络的一些疑难杂症维度开展更多工作；针对离线和实时数据的一些分析，以及机器学习相关的处理后，火山引擎边缘云在网络大盘上，在更多场景下，把可视化异常诊断的能力做到更好。</p><p></p><p></p><h2>网络开放，助力云上生态</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/00/00eba36f318006f2aaa8f13bcbdd5195.png\" /></p><p></p><p>网络从场景上会连接算力、连接数据、连接场景，云上的各种产品和场景对网络是强依赖的。而边缘云的发展，目前更多的发力点还是在 IAAS 和 PAAS 这一层。所以如果让云上的产品包括能力更加多元化，网络也需要更开放。</p><p></p><p>当下的网络更多是做了一些基础相关的能力，比如计算节点对网络云化的需求，资源商品化的需求；以及在网络基础能力之上，我们在 PAAS 层做了一部分网络加速，游戏加速，SD-WAN 组网相关的需求，这些能力聚焦的点还是在 IAAS 和 PAAS 上。</p><p></p><p>再看用户需求场景，云发展到后面一定是生态，我们需要协同更多的产业伙伴去共建这个生态，才能有更好的发展。很多的产品厂商，比如安全的厂商，在传统领域可能做了十几二十多年，安全设备很复杂，能力很强，技术也很深，但是以前主要市场在线下 IDC，到云上后，可能会做一些云化的相关场景部署，在云上卖镜像卖给用户，目前还是让用户自己解决部署问题。所以如果传统厂商能更好地上云并给客户提供服务，对云是非常好的补充。</p><p></p><p>第二就是传统行业的搬站，第一阶段解决的是企业上云，包括云上原生相关的一些场景，里面更多的是互联网相关的厂商，所以可能第一阶段更容易上云。第二个阶段更多的是金融政企相关的传统行业，因为他们对 IDC 的依赖比较重，所以一般是在后一阶段上云。我们在此阶段发现非常多问题，比如以前在线下的设备厂商，他的组网方案里有很多定制化，而在云上，更多是面向公有云的租户，做一些通用化的诉求，这就存在很多产品的能力匹配度问题。</p><p></p><p>此外，即使他们上了这朵云，未来可能也会有很多个性化场景的需求，因为在以往的经验里面，他们其实已经享受到这个红利，很多设备厂商愿意帮他们做定制化的场景。再者，很多的金融政企或者其他类似行业客户，他们希望平滑上云，不希望做太多的改造。所以从用户需求场景来看，包括从厂商的定位来看，都需要将这朵云开放出来。而云的开放模式一定是网络先行。</p><p></p><p>网络开放分为以下维度：</p><p></p><p>第一，能力构建方面，需要具备网络编排能力，在网络转发路径中可以接入更多应用的提供商和服务商。第二，接入后要为云上租户提供安全隔离的能力；而且不能让用户感到太多差异化，需要具备透明接入能力。此外，还需基础配套的运维、监控、日志体系，帮助用户更好地使用及管理好云。</p><p></p><p>火山引擎边缘云希望未来能够和更多的网络厂商、安全厂商、应用服务商成为合作伙伴。在产品生态、应用生态、服务生态协同促进，共建边缘云市场的明天。</p>",
    "publish_time": "2024-01-23 14:23:18",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "拥抱云原生——下一代边缘计算云基础设施",
    "url": "https://www.infoq.cn/article/FtSARGXvqdrijxNbFKrR",
    "summary": "<p>去年，火山引擎边缘云边缘计算架构师郭少巍在 LiveVideoStack Con 2023 上海站围绕火山引擎边缘云海量分布式节点和上百T带宽，结合边缘计算在云基础设施架构方面带来的挑战，分享了面对海量数据新的应用形态对低时延和分布式架构的需求，边缘计算将成为新一代边缘计算云基础设施以及未来边缘计算发展的未来展望。</p><p></p><p>近十几年众多云厂商纷纷涌现，出现了基础设施即服务、平台即服务、软件即服务，云计算的形态上演变出了公有云、私有云和混合云等多种模式，当前“云”已经触达了企业应用的方方面面。传统的中心式部署架构已无法满足新型资源下的部署模式，业务架构采取云边端配合的模式进行部署，才能够充分的发挥云边端的优势，未来会有越来越多的业务向着云边端混合部署的新架构方向发展。</p><p></p><p>随着云计算和边缘结合，出现了边缘计算概念，在数据源和云中心路径之间提供轻量、弹性、智能、异构、低时延的边缘计算服务能力。</p><p></p><p>郭少巍表示：首先，边缘计算是对云计算最有力的补充，两者互相补充而非简单的替代概念。其次，云边协同放大了云计算和边缘计算的价值，只有更好地协同云和边，才能发挥两者最大的价值。</p><p></p><p></p><h1>业务发展为边缘计算云基础设施带来新的挑战</h1><p></p><p></p><p>边缘计算的发展带来好处的同时，也在云基础设施架构方面带来许多挑战。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6d/6dffb0aa5147b82c69606f564091e408.png\" /></p><p></p><p>边缘计算的优势如下：</p><p></p><p>低延迟：边缘计算节点分布在全国各地，并且覆盖全链路运营商，为用户提供低延迟体验。高带宽：边缘计算就近处理和传输，能够承载更大的带宽。节约成本：边缘计算可以减少客户端与中心节点通信的数据量，从而帮助客户节约了较多的带宽成本。数据安全：数据在边缘节点进行预处理和预聚合，无需在整个网络传输，从而降低数据在公网传输被窃取的风险。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/32/32ee5dc6b8ada7d0595fec727e898917.png\" /></p><p></p><p>边缘计算主要带来以下四点挑战：</p><p></p><p>资源限制：边缘计算节点规模通常较小，机器数量通常为几台到几十台的规模，甚至有些边缘节点只有一台服务器，因此必须考虑如何在小规模节点下管理资源，在有限的资源下尽可能提高资源售卖率。分布式管理：边缘计算节点的数百个集群分布在全国各地，存在弱网管理及边缘自治问题。需求多样：由于客户的业务是多种多样的，客户在边缘节点的需求也比较多，客户需要在边缘提供云主机/容器/裸金属等各种资源类型。此外，在网络层面客户希望我们提供 VPC、PIP、EIP 等能力，在存储层面客户希望我们提供云盘、本地盘、文件存储、对象存储等能力。安全管理：需要在很小的节点之内实现租户隔离，并保证公网和边缘节点协同的公网传输的安全性。</p><p></p><p></p><h1>应对挑战：边缘计算云基础设施逐步完善</h1><p></p><p></p><p>为了应对以上挑战，边缘计算云基础设施正在逐步完善。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a6/a60b2ddc2918fe9edde352f181847c4d.png\" /></p><p></p><p>正如上文提到，边缘计算面临着小型化、分布式和安全隔离等挑战。</p><p></p><p>对此，云原生技术首先被想到，它具有以下特点：</p><p></p><p>资源管理方面，云原生技术支持弹性伸缩和资源按需分配，为在边缘小型节点构建一个弹性伸缩的边缘节点提供可能性。技术架构方面，云原生技术具有松耦合、可插拔和良好的扩展性。为边缘节点异构及按需部署提供可能性。应用部署方面，云原生技术提供了标准部署、自动化运维和可观测性。为在边缘构建简单化运维及可自动恢复的能力提供可能性。</p><p></p><p>云原生是面向云应用设计的一种思想理念，有助于构建弹性可靠、松耦合、易管理、可观测的系统。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f5/f5b06ddf4a6c2ba4487c7f9f1687b099.png\" /></p><p></p><p>边缘计算的架构演进与业务架构演进相契合，经历了三个阶段：</p><p></p><p>面向资源阶段：业务初期基本都是直接运行在虚拟机或物理机上的，这时的业务直接面向资源，并没有解决应用如何编排、如何快速部署、如何运维，如何观测等面向应用云上使用的能力。</p><p></p><p>面向应用：随着容器技术的兴起，2014年出现 kubernetes，2018年出现 Cloud Native 的概念，与此同时，边缘也演进到了以云原生为主流架构的时期。然而，云原生并没有解决所有边缘的问题，边缘场景其自身特点：在资源层面，边缘有着广泛的节点覆盖，单个节点资源十分有限，这对海量节点管控和单节点资源优化提出了非常高的要求。在网络层面，存在云边弱网环境的问题，这对边缘自治提出了要求。</p><p></p><p>由此，迎来了边缘云技术架构的第三个阶段，将云原生与边缘特性结合，形成边缘独有的技术方案，即边缘原生。</p><p></p><p>边缘计算架构演进分为以下三个阶段：</p><p></p><p>第一个阶段是传统虚拟化阶段，此阶段将虚拟化技术和边缘结合，提供将大粒度资源拆分成小粒度资源，以及资源间的隔离能力，其主要着力点是面向资源。客户需要自行解决部署，运维，监控等一系列问题，这种管控模式对客户基础运维能力要求极高，要求客户有非常专业的运维和管控系统。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/20/2022d6a9fe145a7ffb947f63207df267.png\" /></p><p></p><p>随着容器技术和云原生技术的成熟，云原生应用越来越多，此时出现了在虚拟机中部署容器，容器和虚拟机相互嵌套。这一方案中，虚拟化仍然是主要技术，容器是辅助，是传统超融合应对云原生趋势的“过渡”方案。此阶段虽然解决了部分编排能力，但容器的弹性能力受限于虚拟机的弹性能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2b/2b8418ce94e97d6928c8260401c5021b.png\" /></p><p></p><p>基于边缘计算的特色，最终演变出了云原生超融合的架构。在同一套资源池上既实现了虚拟机也实现了容器和裸金属的管控和部署，具有以下两点优势：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ef/efdcd50c00bb9db388ca766dcb9bdaad.png\" /></p><p></p><p>第一，资源共池，三种资源形态共享一个资源池，可以灵活调配不同的资源池，提升整体的资源售卖率。</p><p></p><p>第二，满足更多业务形态，通过不同容器为云原生应用提供服务。用虚拟机为有基础运维能力的客户提供服务，用虚拟机解决 Windows 生态问题，在边缘的大流量场景下，用裸金属为用户提供更高性能的资源。</p><p></p><p>边缘原生结合了边缘和云原生技术的特点和优势，因此它具有云原生的应用和服务的可移植性，可观测性，易管理、统一编排的能力，同时也具有云边协同、边边协同、中心管控和边缘自治能力。在全局调度方面，具有全局资源调度和局部资源优化能力，在边缘节点具有异构能力。结合云原生和边缘的特性，使得应用和服务能够充分发挥边缘的能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c5/c5b55015de5943593c8fc8e0f9d1ac14.png\" /></p><p></p><p></p><h1>内外统一的边缘原生云基础设施架构</h1><p></p><p></p><p>火山引擎是如何构建边缘原生的云基础设施的呢？</p><p></p><p></p><h2>火山引擎边缘原生技术方案</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4b/4b587b6e0b3b2d34547f3a4dfda13c23.png\" /></p><p></p><p>图示为整体的技术方案，从底层开始介绍：</p><p></p><p>火山引擎边缘计算节点分布在全国各省市、各个运营商、具有优质的网络线路。同时，结合丰富的边缘硬件设备，如定制 x86 服务器、ARM 服务器、GPU 异构服务器资源、高性能 nvme 存储、100G 带宽的智能网卡设备。</p><p></p><p>基于这些高质量的基础设施，火山引擎边缘云设计出了边缘云原生操作系统的能力，包含边缘自治管理、系统组件管理、以及面向边缘的镜像服务能力。自治管理包含集群管理、应用生命周期管理。系统组件包含网络组件、服务发现、消息队列。镜像组件包含公共镜像、自定义镜像、镜像预热及镜像加速。</p><p></p><p>云边管理提供云边通道、集群管理、智能调度等子系统，优化了云边协同。</p><p></p><p>数据管理提供数据采集、监控告警、数据大屏及数据仓库。将边缘数据进行预处理后发送到中心进行分析告警。</p><p></p><p>最终在产品形态层面为客户提供边缘计算服务，包含边缘虚拟机、裸金属、容器等多种形态，同时提供云上一致的边缘网络、边缘存储等多种云服务能力。此外，火山引擎边缘云还构建了 FaaS 和 SaaS 等边缘服务。</p><p></p><p>场景应用层面能够支撑 CDN、视频直播、实时音视频、云游戏、动态加速、边缘智能等各个业务场景的需求。</p><p></p><p>架构设计的整体理念为云边协同，边缘自治，分层治理。</p><p></p><p></p><h2>边缘原生操作系统</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/98/982cd907a6e21a60c66e3971e6ab2428.png\" /></p><p></p><p>边缘原生操作系统融合了云原生和边缘特点，提供以下四点关键能力：</p><p></p><p>统一编排：通过云原生操作系统，可以实现对算力资源、存储资源、网络资源、以及自身云服务资源的统一编排。协同管控：支持中心和边缘协同管控，实现中心与边缘的高效融合。按需部署：通过算力混合部署和服务混合部署及组件可插拔，能够在不同资源场景下的提供异构算力和异构产品能力。云边协同：实现了云边通道、边边协同等能力。</p><p></p><p></p><h3>统一资源编排</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b9/b973c55164d0e5f8a9a800722c6b893c.png\" /></p><p></p><p>边缘节点对资源编排的需求可以归纳为小型化和多样化：</p><p></p><p>小型化：通常节点规模较小，只有数台机器，甚至有的节点只有 1 台机器。计算需求：由于业务的诉求多样，需要在边缘节点同时支持虚拟机、容器和裸金属等多种产品形态。存储层面：需要块存储，文件存储和对象存储等能力。网络方面：需要自定义 VPC 网络、负载均衡、弹性公网IP等能力。</p><p></p><p>对此采用的方案是统一资源编排。</p><p></p><p>最底层是 Kubernetes，在此之上通过 CRD 统一抽象，比如需要虚拟机，定一个 Virtual Machine  的CRD，通过 CRD 实现控制器逻辑，从而实现对资源的管控。生态方面，可以直接复用在 Kubernetes 之上现有的网络、存储、GPU 等资源类型，实现容器和虚拟机存储和网络资源的统一。</p><p></p><p></p><h3>统一服务编排</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/24/2411ce7d28a5d0f7fc2535a91e4d785e.png\" /></p><p></p><p>统一服务编排的需求是组件统一管理。包括两点诉求，第一点是轻量化，边缘集群通常较小，因此管控服务需要实现轻量化。第二点是服务运行依赖，由于服务种类繁多，因此底层依赖的组件库也多种多样，部分服务对 OS 也有特定场景诉求。</p><p></p><p>对此的方案是统一服务编排，将所有的组件进行微服务化设计，将组件统一容器化打包和发布，使得组件运行时不依赖特定宿主机的 OS 和组件库版本。</p><p></p><p>图片最底层是引擎层，通过复用 Kubernetes 的基础管理能力，直接接入 Kubernetes 提供的网络、存储等基本能力。在引擎层之上自研了日志、监控、报警等能力，使用并强化了云原生的扩缩容、健康探测、故障迁移及自动恢复能力。在此之上，对外统一提供虚拟机、容器实例、裸金属等外部能力。</p><p></p><p></p><h3>协同管控</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/60/602e1db244fee618996ce98ee0a197b8.png\" /></p><p></p><p>协同管控的需求是统一管控和调度，包括云边联动管控和统一资源调度。方案是自研的云边协同管控系统，包括三个关键点：</p><p></p><p>全局感知：在中心基于 Watch 机制，实现了对边缘资源的实时感知，更快感知到资源和库存变化。边缘自治：利用多 Master 机制保障边缘的可用性，即使与中心失联，边缘仍可以独立工作。统一调度：实现了虚拟机、容器统一库存管理。</p><p></p><p>图示为创建虚机调度的过程，首先用户发起创建虚机实例请求，虚机管控收到后再向库存服务发起请求，调度系统经过全局最优的调度策略，返回结果，管控系统将资源下发至对应的边缘节点，通过边缘管控及边缘调度器执行轻量化调度，最终将实例运行到具体节点之上。</p><p></p><p></p><h3>按需部署</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9b/9b36283cabdeec5f14f8376b3b3ab241.png\" /></p><p></p><p>按需部署的需求是能力多样性，主要包括以下几点：</p><p>规模异构：有的节点会比较小，有的节点规模会比较大资源异构：不同节点提供的服务器类型包括 X86、ARM、GPU存储资源：不同节点提供的存储能力包括云盘、本地盘、文件存储等产品能力：不同节点会提供 X86 虚拟机或 ARM 虚拟机</p><p></p><p>对此的方案是组件标准化和按需部署。</p><p></p><p>首先是标准化节点规格，我们对节点类型及组件进行标准化，前者分为小规格节点、通用型节点、大规格节点等，后者分为虚拟机、容器、网络等。</p><p></p><p>同时在部署方案针对不同节点类型和产品需求做了固定编排，在节点建设时，根据节点类型和产品需求，选择不同的部署方案。图片上可以看到，在小规格节点为用户提供标准的虚拟机、容器和 LB 能力，在通用节点还额外提供裸金属能力，只需在通用节点基础上部署裸金属插件即可。在大规格节点之上为用户提供更多能力如 GPU 和文件存储产品能力，同样只需在大规格节点基础上部署对应插件即可。</p><p></p><p></p><h3>云边协同</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9b/9b7f125bf4ad85eecc62f4bd69ef1dfc.png\" /></p><p></p><p>云边协同解决了云边弱网问题，包括网络和安全层面。前者包括网络丢包、链路不稳定、网络链路中断等问题。后者主要是公网链路传输安全问题。</p><p></p><p>相应方案是自研的云边通道。</p><p></p><p>首先，通过边缘与中心建立长链接的方式，复用边缘与中心的链路，在中心实现了各个边缘节点的数据缓存，保障中心更快地感知到边缘变化，中心组件在操作边缘时能够对读请求加速。</p><p></p><p>其次，在安全性保障方面，通过身份认证、双向证书等机制保证客户端和服务端双向认证的安全性。在传输安全方面，通过全链路 SSL 加解密，保障传输数据的安全性。在 SSL、ACL 访问控制方面，保证只有白名单的边缘节点才可以注册到中心，增强了云边通信的安全性。</p><p></p><p>最后在网络容灾方面，采用多机房、多副本、负载均衡和故障自动迁移等技术，确保云边通道的高可用性。</p><p></p><p></p><h2>边缘节点的最佳技术实践</h2><p></p><p></p><p></p><h3>实例创建加速</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/71/719891991e59c59c19782fbaf049ee64.png\" /></p><p></p><p>第一个是实例创建加速，其问题是边缘节点创建实例慢，包括两方面原因：一是镜像下载慢，由于边缘节点从中心下载镜像较慢，由于镜像下载需要走公网进行传输，因此镜像下载的时间是不可控的。二是实例创建需要从基础镜像完整拷贝一份，如果镜像较大，拷贝也会较耗时。</p><p></p><p>对此采用的方案是预热及快照。</p><p></p><p>首先，将虚拟机镜像和用户自定义镜像提前预热到边缘节点。再对边缘的镜像预创建快照，当需要创建虚拟机时直接基于快照进行创建，虚拟机底层共享同一快照层，快照采用 Copy On Write 机制，虚拟机创建时并不会完全拷贝镜像数据，而是当真正要写入数据时才对需要变动的数据进行拷贝，通过快照机制，可以做到虚拟机的秒级创建。</p><p></p><p></p><h3>性能优化-虚拟化</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4b/4b685f80acd3eaa36946e1d22834aa67.png\" /></p><p></p><p>我们在性能优化层面进行了虚拟化性能优化。顾名思义，虚拟机是由软件虚拟而来，因此虚拟机在一定程度上存在性能损耗，体现在以下三点：</p><p></p><p>第一，vCPU 在操作系统上是被当做普通用户态进程进行调度的，因此 vCPU 之间可能会存在性能争抢。第二，由于虚拟机是大颗粒内存拆分为小颗粒内存，存在内存转化性能开销。第三，VMM Exit 可能影响 CPU 性能。</p><p></p><p>为了更加深入地了解以上问题，现为大家介绍一下虚拟机的基本原理：</p><p></p><p>CPU 的运行级别分为 Ring0~3 这 4 个运行状态等级，Linux 只使用了其中的 Ring0 和 Ring3，分别表示内核态和用户态。</p><p></p><p>虚拟机主要由 VMM(Hypervisor)和 Guest 组成，X86 服务器为了支持虚拟化提供了两种运行模式，root 模式和 non-root 模式。CPU 的虚拟机运行过程实际上就是 CPU 受控制地在 root 和 non-root 两个操作模式之间进行切换。</p><p></p><p>VMM 与 Guest 的操作模式切换主要分为两个部分。假设当前运行的代码在 VMM 层，如果想要运行客户的代码，就需要进入到 Guest 层，可以手动调用 VMLAUNCH 或 VMRESUME 指令将当前运行的代码切换到客户侧，这个过程我们叫做 VM Entry。假设在客户侧运行过程中需要响应外部中断或缺页异常（page fault），此时 CPU 运行会切换到 VMM，我们将这个过程叫做 VM Exit。</p><p></p><p>为了减少虚拟机的性能损耗，我们做了以下几件事：</p><p></p><p>vCPU 绑定：通过将 vCPU 和物理机 CPU 一对一绑定，减少了 CPU 的频繁切换，从而减低了 CPU 的上下文切换损耗；Hugepage：通过利用内存大页，减少内存页表，减低了 TLB 的 miss，提升虚机的访存性能；Exit 优化：通过将 Timer/IPI 等 Exit 透传，消除了大部分的 VM Exit，使虚拟化损耗降至 5%以下。</p><p></p><p></p><h3>性能优化-I/O 优化</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e8/e89560dd15cf004554b701c7dd3b86ff.png\" /></p><p></p><p>I/O 层面的优化主要包括两点：</p><p></p><p>网络 I/O：超大带宽，例如 vCDN 场景存储层面：本地化缓存场景需要较强的存储带宽和 IOPS 能力</p><p></p><p>对应方案是采用硬件 Offloading、硬件直通、Polled I/O 等方式：</p><p></p><p>硬件 Offloading：将网络流量卸载到专用网卡设备中，使用专用网络设备做网络包的转发，不仅提升了转发的吞吐能力，还可以释放部分 CPU 资源设备直通：将磁盘或网卡设备直通到虚拟机中，减少软件转发路径提升了整体 IO 性能Polled I/O：通过用户态 Polling，减少对于通知机制的依赖，更快感知数据变化</p><p></p><p></p><h1>未来展望</h1><p></p><p></p><p>未来，边缘计算会继续呈现增长的趋势，边缘计算的崛起也会带来更多便利。未来边缘计算主要会向着轻量化、算网融合和开放生态的方向努力发展。</p><p></p><p></p><h2>轻量化</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0b/0b46d0c1cdb9b0d799b35274ef439d12.png\" /></p><p></p><p>当前火山引擎边缘云在边缘提供了标准的虚拟化能力及非常完善的功能，但当前存在虚拟化较重的问题。</p><p></p><p>未来，火山引擎边缘云会通过优化 Hypervisor 实现更轻量的 Overhead，进一步降低虚拟化损耗。此外，在管控层面通过云边协同将部分管控能力统一在中心，边缘做轻量的自治能力，做到边缘的管控面和 Hypervisor 轻量级。</p><p></p><p></p><h3>算网融合</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/24/240cc5c576a07e5424a496012cf38ce3.png\" /></p><p></p><p>其次是算网的深度融合，当前火山引擎边缘云更依赖于单个节点的弹性能力以及单个节点的算力资源调度。应用需要自己做多机房的容灾能力，未来我们会做算力网络深度融合，统一调度网络资源和 CPU 算力资源，实现跨节点的弹性伸缩能力，使得部分业务在不同节点间自由迁移，更好地利用不同节点的资源。</p><p></p><p></p><h3>开放生态</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/43/43e90a02d91e81f148574b4d8df6f611.png\" /></p><p></p><p>最后是更加开放的生态。当前，火山引擎边缘云基于云原生技术构建了边缘原生的操作系统，对外统一提供虚拟机、容器及裸金属等公有云服务。</p><p></p><p>未来，火山引擎边缘云会为用户开放更多云原生能力，吸纳更多云原生生态的合作伙伴，通过更加开放的模式，使得云原生技术不仅可以服务于自身，也可以让更多的客户享受云原生带来的生态便利。</p>",
    "publish_time": "2024-01-23 14:23:21",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "大规模流量下的云边端一体化流量调度体系",
    "url": "https://www.infoq.cn/article/Z7AyKHpVuEBDKs6xjxmf",
    "summary": "<p>去年，火山引擎边缘云流量治理团队的负责人刘学在 LiveVideoStackCon 2023 上海站结合大规模流量场景的挑战，介绍了火山引擎边缘云的云边端一体化流量调度体系，分享了场景落地实例和未来展望。</p><p></p><p>刘学及他所在的流量治理团队在大规模流量和场景的挑战下，从调度视角对各个接入产品的调度能力和策略进行整合，形成了一个云边端一体化的调度体系。</p><p></p><p></p><h1>大规模流量场景的挑战</h1><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bc/bc8e0ec7ad80d0ee77a70ae9528f213d.jpeg\" /></p><p></p><p>火山引擎边缘云提供了一系列标准化的接入产品，在端边云的接入路径上，长期服务于抖音集团内各种大规模音视频流量 APP，包括抖音、今日头条、火山小视频、西瓜视频等。这些应用产生的基础流量主要分为点播、直播、投稿和 API，各类型流量的特点分别为：</p><p></p><p>点播流量：包括 CDN 边缘层面的超大规模流量，以及多层缓存系统的回源流量。当边缘流量足够庞大、资源足够丰富时，回源流量在源站层面也是非常重要的流量之一；直播流量：随着大型赛事活动、电商等业务的发展，直播也是流量成分中的重要组成部分。直播的流量架构会包括推拉流及审核流等，在源站和边缘层也都会占用比较可观的网络资源；投稿流量：作为 ugc 形态的 APP，投稿这部分流量是不可忽视的，近一段时间随着点播业务社交属性的增强，投稿流量的压力主要在冷流业务。比如每年投稿系统最大的峰值挑战，其实是在元旦春节的零点，这个时间观众都喜欢集中感慨一下，这给系统提出了比较严峻的挑战；API 类流量：这类流量的特点是请求必须在源站，基于复杂的计算或海量用户数据来完成服务，且单个请求的体量较小。场景包括推荐、搜索、账号、直播间刷礼物、消息等等，这些也是音视频 APP 必不可少的流量构成。</p><p></p><p>对于多种类型的业务流量，这些流量在外网接入的范畴，会经过火山引擎边缘云的哪些产品集进行支持呢？</p><p></p><p>在端内，火山引擎边缘云提供了字节统一的移动端网络库 MNet，经过 MNet 代理的网络请求，在性能、协议、安全性等方面均能得到深度的定制优化支持；在边的层面，边缘云提供了多种形态的缓存和加速服务。其中包括用于支持点播流量的 CDN 产品，贴近用户提供点播推拉流、转码等计算和网络服务的边缘计算、边缘网络产品，以及为 API 类流量提供就近接入、全路径加速的 DCDN 产品；在云的层面，在请求到达最终的业务 server 之前，边缘云接入团队也提供了相应的 4/7 层负载均衡产品。</p><p></p><p>那么，对于异构的流量，在比较复杂的全局接入架构下，会有哪些具有挑战性的场景呢？流量治理团队在过去几年中帮助业务解决的一个主要问题是：对于抖音集团全部的接入流量，在日常用户规模、流量规模都非常庞大的的背景下，在公司层面进行诸如春晚红包、世界杯直播等大型活动时，外网流量接入的总体解决方案是什么？</p><p></p><p>流量治理团队面临的流量压力包括：</p><p></p><p>首先，各种流量都有常态的流量作为基础，并且随着活动的拉活、在线人数增加，像 API、点播这类日常流量会有一定的放大；在此基础上，还需要继续承担特定的活动行为所带来的额外流量需求。比如春晚的红包组队任务、世界杯主直播间消息刷屏等；最后，就是一些特殊时刻的关键挑战。比如春晚的口播、元旦零点的投稿，这可能是整场活动的焦点时刻。是在前面所有流量上涨的基础之上，再叠加一个比较夸张的需求数字。</p><p></p><p>在上述流量场景的背景下，面临的挑战包括：</p><p></p><p>首先是在整个活动的时间轴上，流量治理团队需要考虑上述各种流量增长的高水位叠加。这些增长的流量，在时间和空间层面，有些是可预期的。比如红包的时间点，口播广告的时间点等等；有些是难以预期的，比如世界杯的小组赛阶段阿根廷对沙特、德国对日本的这两场直播，在比分爆冷后整个直播间流量上涨的的情况是远超前期预估的。这就需要团队在难以准确预估的前提下，在方案上去根据资源的供给情况做倒推，根据流量上涨的程度设计分级的降级处理方案；</p><p></p><p>第二层挑战来自于资源层面。首先是周期问题，相对于活动决策、资源建设的周期，带宽扩容、机器的采购等都是需要比较长的周期的。其中有部分资源如果短期购买的话，成本非常高，这种高价资源的必要性需求怎样进行评估；以及即使短期内买到了一些异构的资源，架构上如何把这些资源比较稳妥的使用起来，在规划层面要给出经过计算排布、确保可行性、变量和风险可控制的接入方案，这些都是资源层面所面临的一些挑战；</p><p></p><p>最后是容灾场景，在前面提及的海量需求和复杂架构的背景下，需要进一步考虑容灾场景。在活动期间如果发生了各种场景的故障，团队需要具备提前设计好、计算好、演练过的预案。基于常规的接入架构设计方案，进一步的去做n种场景的容灾预案，这会将整体的工作量放大 n 倍。并且会进一步的拷问：系统极限在哪里、在最恶劣的情况下，团队要舍弃什么，保留什么，如何确保计划的动作能精准的实施下去。这些是流量治理团队在容灾极限场景下所面临的挑战。容灾的能力十分重要。在各种大规模流量的输入情况下，资源十分受限，可能会导致出现一些故障，这时就需要按照提前计算规划以及演练过的成熟预案进行场景展开。场景上的展开，无论是在技术层面还是工作量层面都翻了很多倍，如何保证容灾的可行可控也具有挑战性。</p><p></p><p></p><h1>云边端一体化调度体系</h1><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bd/bd1cd4e4ed5f7ee5e4330976060a59c2.jpeg\" /></p><p></p><p>基于前文提及的流量和场景的挑战下，从调度视角对各个接入产品的调度能力和策略进行整合，形成了一个云边端一体化的调度体系。图示架构图是对前文提到的接入架构图进行了一个简单的细化，里面包含了各组件的流量调度能力的部分：</p><p></p><p>首先在端内的层面，抖音集团的流量调度体系中，一个比较突出的特色点就是：调度系统的边界，从传统的基于域名解析方式，上升到了端内。基于端内网络库的能力及云控方案，可以构造出生效速度更快、能力更加强大多样、调度粒度更加精准的新一代解决方案；</p><p></p><p>其次，在边缘层面，抖音集团大规模的使用了融合架构。其中包括静态 CDN 在多厂商间的融合、直播 CDN 在自建的边缘计算资源和三方厂商之间的融合，以及动态 CDN 的融合。这里面提到的融合，即包括同构资源的横向融合，也包括一些异构资源在纵向的跨层融合，比如当核心机房的资源不足时，可以将一部分业务上移至距离核心机房较近的边缘资源上；</p><p></p><p>在源站层面，对于源站各机房、线路的入口带宽，各种接入组件提供了不同的回源调度能力，比如 CDN 系统基于 302、回源配置的源站调度，以及 API 类流量基于域名解析的源站调度。在源站的入口和下游业务之间，LB 产品也提供了最后一层的内网调度能力，将源站业务的调度需求，与复杂的外网接入接入链路进行最大程度的解耦和屏蔽。</p><p></p><p>由此，调度体系的一个关键特点被凸显，即各系统间的分层和协作。</p><p></p><p>为了构建一个高内聚、低耦合的调度协作体系，计算机领域的一个通用思想需要被引用，即能力和策略分层。在特定问题上，需要十分明确的定义：哪些系统是提供配置能力的、哪些系统或角色是负责对配置进行取值决策的。比如对于融合CDN调度系统，在边缘层面首先要负责指定域名在指定线路到指定厂商的决策，这是一个策略系统，其依赖的能力可以是 dns、httpdns 或者 302 配置；另一方面，对于回源流量，CDN 提供多种回源配置的能力，但源站带宽的规划就是另一个独立的策略系统。</p><p></p><p>好的设计能够使每个模块的目标是单一、内聚的，避免在决策时引入太多不合理的顾虑。比如字节在过去的一段时间，各 API 类流量的机房间流量调度，是依赖外网调度的，这会导致后端业务模块间的调度配置在域名维度被绑死，不够灵活；同时外网在局部线路带宽不足需要调整时，还要参考各后端业务的部署容量情况，为了解决这类问题，流量治理团队在7层转发层强化了源站的内网调度能力，通过对内外网调度的解耦，使得各层级所要处理的问题更加合理。</p><p></p><p>这种跨多层问题的处理也可以从另一个角度去理解：当问题规模足够大时，是采用 sacle up 的方式尝试在一个单元中去解决所有问题呢；还是用 scale out 的方式，将问题进行合理的拆解，将不同的子问题分发到不同的单元中进行处理，最后再进行整合呢？在这里显然，火山引擎边缘云走的是 scale out 的路线。</p><p></p><p>最后，在每个调度子系统各司其职的前提下，仍然需要一个对全局情况进行汇总的综合调度系统，即全局流量调度系统 BTM。一些综合性的问题，需要在全局层面进行统一决策协调，因此仍然需要一个顶层的仲裁者角色。比如前面提到过的活动期间的容灾场景，假设一个源站机房故障，各流量负责的系统都在向其他机房切流，那么谁来计算和保障其他机房的容量是安全的呢？谁来协调各流量间的降级优先级和降级深度呢？这都需要一个综合决策性质的系统，参考各业务流量的特点、流量实时大小，以及资源的水位和状态，从全局角度进行决策，在调度系统通用的这几个目标下，即容量、容灾、成本、质量、以及考虑特定的业务约束，寻求相对的最优解或者可行解。</p><p></p><p></p><h1>场景落地 Story</h1><p></p><p></p><p>接下来通过一些具体的场景和案例，介绍火山引擎边缘云调度体系能够提供的解决方案，以及对应的特点。</p><p></p><p></p><h2>Story1</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3c/3c6d0cb5294d9a5eda422ec75635bf62.jpeg\" /></p><p></p><p>首先将镜头拉回到春晚的场景，介绍一个最极端的时刻——口播时刻。这个场景在业务层面的情况是，主持人会在特定的广告时刻，引导全国的观众打开抖音系的 app，进入红包活动。在技术层面，预期会发生的流量包括，以活动期间高于常规晚高峰的大盘流量为基础，短时间内叠加海量的冷启流量和活动流量。冷启流量包括启动后的一系列 api 请求，以及首刷点播，活动流量主要指红包玩法。众所周知，红包玩法可以做一系列的缓存、打散、削峰的定制化设计，反而是冷启流量更加难以控制，因为口播行为是固定的，口播带来的冷启请求也是无法做打散的。</p><p></p><p>为了应对这些挑战，传统的解决方案包括：对于首刷点播流量，可以通过限制码率、推荐高热视频等手段尽量减少 CDN 流量的消耗；对于 API 类流量，可以通过版本更新，将活动版本的冷启流量限制到最低。但这受限于活动版本的开发时间和发布周期，往往到活动时刻的版本覆盖率并不理想。在此基础上，常见的一些处理方案可能包括在 dns 层做黑洞，但整域名的封禁往往会伴随很多误杀，且 dns 层面的封禁和解封时效性也并不可控；或者将接入层作限流作为主要手段，但这需要对接入层堆很多的资源，毕竟流量洪峰到来时，握手和协议的开销不可避免。</p><p></p><p>那么，是否存在着更加有效的解决方案呢？</p><p></p><p>在抖音集团内部，端上的请求主要是通过定制化的网络库进行代理发送的。请求处理的过程中，会由网络库进行内部域名的定制、协议优化、甚至请求 drop 等操作，这一系列操作都是云端实时可控的。经过网络库的请求，在调度层面可以获得更快、能力更强、维度更加精准的优势：</p><p></p><p>首先对于调度的生效速度。端内的请求根据是否链接复用，会分为两种不同的执行情况。使用 dns 或 httpdns 解析，在变更解析结果进行调度时，除去解析结果缓存更新速度的影响，链接复用也是影响切流速的重要因素。在链接复用维持的较好的业务上，可能数十分钟都难以完成切流操作。而端内调度使用的是域名替换的机制，在请求发起前决策具体要使用的域名，这样就避免了链接复用的影响。当前端调度流量治理团队能做到 5min 内切流 93%的生效速度，结合动态加速回源机制，最快能做到 2min97%的外网切流生效速度，这种方式对比常规域名解析的切流形成了巨大的优势；</p><p></p><p>其次，在能力方面，由于网络库代理了端上网络请求的全流程，因此在请求的各个阶段都可以施加定制逻辑。比如决定这个请求使用什么协议，解析结果的使用策略如何，自动化的测速选路，甚至决定这个请求是否要发出。这对比传统的决策一个非连接复用的请求的目标 ip，在能力上也是得到了极大的提升；</p><p></p><p>最后，在调度的粒度上，由于端上网络库的获取机制是基于用户参数的，因此火山引擎边缘云的调度除了区分传统的地域运营商外，还可以增加各种丰富的维度。比如根据用户的机型和操作系统版本、 app 版本、用户 id 分组、实验分组，甚至能够在域名之内对不同的 path 定制不同的调度策略。</p><p></p><p>综上所述，火山引擎边缘云在端内的调度层面提供了很多强大的特性，可以一定程度上理解为将 7 层能力下沉到端上，并且，这一切是不需要额外的资源消耗的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/32/32401dfa64027ee9a3b54c52d64af02e.jpeg\" /></p><p></p><p>这张图是在 21 年春晚的现场，基于流量治理团队的接口级降级能力，现场全站实际流量的控制情况。在整场晚会期间，通过实时控制及预埋配置等手段，确保降级配置的在各版本的覆盖度。在口播前后，能做到 2min 内执行深度降级，口播结束 2min 后全量回复。可以看到，中间这个峰值就是口播降级后冷启流量的冲锋，如果没有高效灵活的降级策略，这个峰值会对系统造成比较大的冲击。最终正常活动在用户体验无损的情况下，基于有限的资源消耗顺利结束。</p><p></p><p></p><h2>Story2</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/21/21372b203642f250e7c2853dfe1ae568.jpeg\" /></p><p></p><p>接下来介绍的是端边调度结合的案例：</p><p></p><p>同样是春晚场景，即使流量治理团队在端上做了一系列的深度降级尝试，流出到网络上的需求，依然对资源产生了巨大的压力。比如在动态加速层面，需求已经到达了 97%的规划水位。这对团队提出了一个新的问题：如何做精细化的调度控制，确保流量在高水位情况下的运行是高度可控的。</p><p></p><p>对于静态流量，常见的精细化调度，可以通过 302 调度，或者在 feed 推荐服务返回资源链接时，顺便在服务端进行精细化的厂商间调度。这些操作对于 CDN 这种资源类的请求是合理的，因为调度的成本相对与请求的成本还是比较小的。但是对于 API 类流量，不太可能在请求的同时，为了做调度而大范围的增加一跳 302，或者对每个请求附加一次调度计算，这样会导致成本很高。实际的解决方案，还是基于端能力的维度控制能力，将端按照设备 id 进行 hash 分组，控制不同分组的用户，指定请求发往不同的厂商，从而低成本的实现了高度精准可控的调度效果。</p><p></p><p></p><h2>Story3</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e6/e6bce9bedf4a4a554c6a34b9b26b250b.jpeg\" /></p><p></p><p>接下来介绍一个云边调度结合的案例：</p><p></p><p>仍然是春晚场景，当流量需求过大时，即使已经在端上做了足够的降级，在边缘层面做了精细化的调度。但是在源站层面，当时已有的资源，仍然不能满足需求。这就需要对系统架构进行一些调整。</p><p>经过业务方的努力，可以将一部分便于拆解的活动业务，上移到源站机房之外，距离源站机房较近且有专线互联的边缘资源上，那么接下来对调度系统的挑战就会被细化成：</p><p></p><p>首先，业务在新的架构下部署，如何引导流量进行快速验证、在云边之间做灵活的流量切换；其次，是流量进入边缘侧后，在边缘层面的多个节点间，符合确保负载均衡、就近接入的效果，以及容灾效果。</p><p></p><p>应对这些挑战，火山引擎边缘云提供了功能丰富的标准化解析类调度产品 TrafficRoute。TrafficRoute 能够将多个边缘节点上的业务，进行地址池的定义和编排，结合每个接入点的容量、以及临近省份线路的质量和举例，进行综合的负载均衡调度决策，并且其自带的拨测模块，也能够快速的发现故障并自动执行故障转移。</p><p></p><p>TrafficRoute 在真实的海量活动流量场景下，提供了有效可靠的支持，也是火山引擎边缘云内部最早完成内外部统一的标准化调度组件。</p><p></p><p></p><h2>Story4</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9f/9f2d3d97fe5d96e694dbec2aa3191a8a.jpeg\" /></p><p></p><p>接下来介绍云边端一体的综合调度系统。</p><p></p><p>当缺乏一个全局综合操作系统时，可能会遇到如下的情况：各标准化的产品，基于自身提供的能力，各自面向不同的业务需求提供服务。其中有一些是经过接入方 SRE 把控的，有一些是业务直接和产品对接的。在这种情况下，各需求和方案没有一个统一的控制方，可能会导致方案的规范性问题，比如有些自动容灾特性被遗漏，或者有些特性被应用到错误的场景上。此外，各方案独立维护，对于全局公用的资源缺乏协调决策，当出现冲突时，方案之间的同步成本较高，决策链条较长，这在大型流量场景下都导致了全局可控性变差。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/18/18c1911e324ad0d5d33365ee19b4497d.jpeg\" /></p><p></p><p>为了规范性的管理和解决上述问题，流量治理团队对调度体系中的策略管理体系进行了梳理。从策略影响的资源角度进行划分，对于完全独立控制资源的策略系统，不需要综合调度系统进行干涉的，可以直接对接全部需求方。比如融合 CDN 在厂商间的容量分配，或者自建 CDN 在节点间的容量分配，这些问题都是系统内闭环的；另一方面，对于需要进行综合决策的资源，比如源站的带宽、各业务公用的接入集群，可以将需求统一收敛到全局流量综合调度系统 BTM 中，由 BTM 负责感知全局的流量和资源情况，在具备全量背景信息的状态下进行综合决策，并负责将决策结果下发至各实际调度系统中去执行。</p><p></p><p>那么，BTM 作为一个全局感知、综合决策的系统，其内部应当如何设计呢？</p><p></p><p>这是一个在业界没有参考的问题，需要流量治理团队独立去抽象和拆解它。首先，从系统的核心元数据模型进行介绍。根据经验，大多数调度决策系统的共性问题，可以抽象为流量、策略、资源三元素。这个模型可以描述为，首先存在这一定接入资源，这些资源有容量、拓扑、状态信息；其次，系统中存在着各种流量，每种流量可能由不同的调度系统负责，根据不同的策略，最终都在这个具有拓扑和容量的资源系统中。只要能对这个三元素的元数据完成建模，就有可能在一个抽象的空间中进行模拟和规划，快速获得全局调度的可行解。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c8/c871816bc6e590b48c4ba3336bbfd378.jpeg\" /></p><p></p><p>简单的介绍一下 BTM 系统的架构：</p><p></p><p>首先整个系统的运行被划分成物理层和抽象层：如同为了让一次编译后的程序运行在不同的硬件机器上一样，需要有一个操作系统，有各种硬件设备的驱动适配，有虚拟的运行时地址空间，通过物理和抽象之间的映射，为上层策略层提供统一稳定的控制环境。物理层和抽象层的边界，称为 adapter，对标操作系统的驱动。adapter 需要适配各个实际调度系统的 api、逻辑和特性，尽可能的将各系统的能力按照流量、策略、资源三元素进行抽象，完成状态上传和指令下达的功能。同时，还需要一套强大的数据 adapter，根据多种数据源，根据 BTM 对各种流量和资源的定义将真实的流量运行数据反馈上来。</p><p></p><p>在抽象层内，BTM 调度系统的工作会分为静态管理和运行时管理；</p><p></p><p>在静态管理范畴，BTM 的主要工作是，基于对资源的容量及拓扑、流量的调度策略模型的抽象，对流量需求进行管理。在规划层面对流量进行快速的预分配，其中也包含了大量容灾场景的自动规划工作。这些前置性的工作能够以较低的成本，快速发现局部的资源风险，为流量架构设计及资源建设提供有效的输入；</p><p></p><p>运行时的管理是 BTM 的核心模块。其中包含了对流量的实时数据、调度配置的实时元数据取值的统一管理。在运行时根据资源和流量调度的实时结果，快速完成规划，并通过 adapter 下发执行，观察执行后的流量变化情况，在下一轮中进一步调整，最终形成闭环。当前 BTM 的规划能力，对于上千条 flow，在上百各资源对象的规划取值，已经能够做到分钟级求解。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/32/3282dd34208dbe8b2c8e4012eb1e454d.jpeg\" /></p><p></p><p>最后从另一个角度来介绍 BTM 系统的愿景，即数字孪生。</p><p></p><p>数字孪生的概念提出，对于物理运行的系统，应当存在着一套 infrastructure as code 的数字系统，对其进行实时映射。那么基于这个数字的映射，就可以监控观察系统的状态，当系统存在问题时，能够进行快速的诊断。当团队预期要做一些操作时，可以在数字孪生系统中对系统行为进行预测，从而提前规避风险。最终，数字系统对物理系统应当是具有可控性，能够将规划验证好的操作，快速批量的执行下去。基于这样的数字孪生系统，火山引擎边缘云的调度体系对于大规模复杂流量场景的控制，能够获得更加成熟、高效、可控的效果。</p><p></p><p></p><h1>未来展望</h1><p></p><p></p><p>结合实际处理线上大规模流量的经验，刘学提出了对未来的一些展望。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b4/b4847db38dc7ae7b89932844c7163e47.jpeg\" /></p><p></p><p>首先在资源层面，当前源站接入正在向更加复杂的 pop 点方式演进。如果调度系统能够适配加入资源的复杂度，就能获得新资源在容量和成本上的收益。当然这对火山引擎边缘云的资源体系构建、容灾场景的复杂化，都提出了进一步的挑战。</p><p></p><p>其次，字节整体的服务架构正在向着多 Region 化、多云的方向演进，这对调度系统的适配也提出了进一步的挑战，流量治理团队需要在抽象层面全面适配业务的单元化改造。</p><p></p><p>最后，综合调度系统作为一个协调者，它对下游调度系统的影响，有些是指令式的，比如直接控制一个域名的解析，这种方式对底层的能力系统是没有决策空间的；而另一种和下游调度系统的联动是策略式的，是间接的影响。比如，如果希望直播系统在源站某条线路的使用，最多不能超过一个 quota 值，而在 quota 内的调度，由直播调度系统来自行决策。这样对综合调度系统提出的挑战是，为了给出实际可执行的决策，需要对这些策略型的调度系统进行建模，根据一个有效的模型推导出有效的 quota 决策，进而持续提升策略联动的可控性。</p>",
    "publish_time": "2024-01-23 14:23:30",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "拓展智能边界，开启云计算崭新时代",
    "url": "https://www.infoq.cn/article/wVV1pauDlSQve8BGF27l",
    "summary": "<p>Qcon上海站，阿里云CTO周靖人为我们带来大模型系列产品，从基础大模型到模型垂直领域产品创新，详细介绍大模型的演进与应用。视频中介绍了基础大模型通义千问以及大模型服务平台阿里云百炼等，更多大模型产品邀你共同体验与应用。</p>",
    "publish_time": "2024-01-23 15:41:13",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "2023 京东零售技术年度盘点",
    "url": "https://www.infoq.cn/article/Idl1P18pvSSWDqtZ2mHc",
    "summary": "<p>过去一年，围绕开放生态建设、低价心智等主要方向，京东零售技术团队持续攻坚。从百亿补贴、调整流量分配机制为用户提供低价品质好货，到简化商家进驻流程、优化商家体验，带动商家数量增长和平台生态活跃，再到将大模型结合到内部大量业务场景，探索效率提升……快速响应、助力业务的同时，京东零售技术团队继续夯实增强自身能力、探索创新。</p><p></p><p>我们选取了 11 项有代表性的技术成果，与大家分享。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1a/1a61a525ac086eb250f6334d23002e36.png\" /></p><p></p><p></p><h1>供应链创新技术入围行业最高奖项</h1><p></p><p></p><p>京东长期致力于通过前沿的数智化技术和算法，提高供应链效率。2023 年，智能供应链团队提出并应用了端到端库存管理技术和可解释 AI 技术，显著提升了补货决策的精准度，实现更快的库存周转和更高效的供应链决策、协同。前者入围 2023 年管理科学界最高奖项弗兰兹厄德曼奖决赛，后者入围 2024 年 Gartner Power of the Profession 供应链流程与技术创新奖决赛，也是该奖项唯一亚洲入围者。</p><p></p><p>传统的库存补货方法多采用先预测再优化的两步式方案，导致预测和优化阶段割裂。智能供应链团队提出端到端库存管理技术，基于深度神经网络模型，直接根据原始的历史数据输出最优补货建议，将预测和优化问题一步式解决，通过缩短决策链降低了累积误差，提升决策的准确度。</p><p></p><p>另一项痛点问题是需求预测和补货策略的解释性不足，导致一线采销人员和供应商对补货建议的实际采纳率很低。为此智能供应链团队首提可解释 AI 技术，实现预测流程白盒化，利用残差网络等前沿深度网络技术，对模型输出的建议加以清晰明确的归因和阐释，构建可解释性、自适应、高扩展性的预测模型框架，从而使下游业务人员可以清晰理解预测流程和结果。</p><p></p><p>以这两项技术为基础的自动补货系统，已实现超过 85%的自动化率。目前京东在自营商品 SKU 数量超过 1000 万的基础上，实现采购自动化率超过 85%，平均现货率超过 95%，库存周转天数降至近 30 天，在全球范围达到领先水平。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f4/f4746fb259d1e7ce01f1b1438e5e27a0.png\" /></p><p>                                      图1 京东入围2023年弗兰兹厄德曼奖决赛</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a4/a49020d525a73b722b6234daf12a3b49.png\" /></p><p>                                      图2 京东入围Gartner 2024年流程与技术创新奖</p><p></p><p></p><h1>后行为序列时代的人货匹配技术：更智能地理解用户和商品</h1><p></p><p></p><p>当前，商家经营和营销进入存量博弈、精耕细作阶段，对广告营销技术也提出了通过技术创新提高人货匹配的效率的核心要求。京东零售广告研发部坚持创新，取得了多项突破性技术进展，共发表顶会论文17 篇，累计提交专利申请一百多篇。</p><p></p><p>（1）将隐私合规保护下的预训练技术应用于用户和商品理解算法创新，在合规前提下，借助多方安全计算、群体建模技术来解决数据匮乏问题，提出序列摘要技术，成功将精排模型的序列交互建模部分前置到排序模型之前，将行为序列的长度提升到万级别，提升了对用户兴趣的刻画能力。以行业知识+预训练的方式引入非 ID 类电商特征，在避免数据组合爆炸的同时解决稀疏表征问题提升泛化能力，是目前电商领域最大的预训练模型，并提出生成式对比学习序列预训练方案，提升新品刻画力。建设排序大模型（参数量达数百亿）提升模型容量，成为京东零售最大在线排序实时模型，并提出了基于数据先验的增量学习框架，实现了分钟级更新感知，有效提升在线学习模型对用户行为变迁的建模能力。</p><p></p><p>（2）巨幅增长的数据和愈发复杂的算法对算力提出了更高要求，广告技术团队将业务、算法、工程进行了 co-design 推进建设新一代算力体系。主要体现在：异构算力的应用探索与实践、弹性动态算力分配能力、新一代模型算力系统。CPU+GPU 异构硬件技术上，突破业界 GPU 调度难题，实现了多流多组范式，根据算力负载实现多流多组的动态分配，GPU 硬件利用率达到理论上限，比 TensorFlow 调度提升 2 倍+吞吐能力。</p><p></p><p></p><h1>自研融合ReAct/SFT/RAG的大模型基础应用框架 高效完成微调、部署和应用</h1><p></p><p></p><p>2023 年，大语言模型绝对是整个技术圈最被热议的话题之一，关键方向之一是如何将大型语言模型的强大能力融入实际业务、产生业务价值。京东零售九数算法中台推出了一整套大语言模型应用解决方案，一种融合 ReAct 框架、SFT（指令微调）与 RAG（检索增强生成）技术的应用框架，支持大语言模型学习领域知识，并提升自主决策能力及信息处理的精确度，帮助业务人员高效完成大语言模型的微调、部署和应用，快速落地业务场景。</p><p></p><p>通过自研大语言模型高效微调（SFT）框架，京东内部可以支持大语言模型高效学习领域知识，并通过编译优化、算子优化、网络和 IO 优化，提升训练性能 40%+，并且支持 70B+超大规模模型微调。在信息检索方面，建设了 Embedding 无损高性能信息压缩能力，打通大模型应用开发框架和向量数据库 Vearch，实现信息检索效率大幅提升。在复杂业务模型自主规划层面，基于 ReAct 范式构建 Agent LLM，帮助大语言模型理解上下文，精确把握用户意图，并在复杂情况下做出决策、执行任务和使用工具。</p><p></p><p>目前，已在包括知识问答、用户增长、舆情风险挖掘、数据分析等多个业务场景应用，加速了业务智能化升级。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9d/9d6243fc4b95645ed6af62881bb7b40a.png\" /></p><p></p><p></p><h1>搜推导购体系全面升级探索用户高效便捷购物体验</h1><p></p><p></p><p>打造前沿的搜索推荐领域技术，实现用户与商家之间的精准高效连接，一直是京东零售搜推团队的关注重点。2023 年，通过导购体系的一体化升级，集成了导购路径引导和算法匹配技术，解决了一系列技术难题，技术成果沉淀数十篇专利和行业顶会论文。</p><p></p><p>面对导购场景模型和样本数据的分散以及用户反馈数据稀疏问题，区别于行业里常见的数据增强等解决方案，创新地提出了预训练-微调范式，对 session 链路中的用户行为进行精准预测，随后在各个导购场景的用户反馈数据上进行微调，显著提升了流量分发的准确性。</p><p></p><p>在主图个性化分发从 0 到 1 的建设中，一方面优化分发能力。一方面通过“模型+策略”的协同，既构建了高效的优选模型，又根据自身数据特性设计了独特的负向属性值过滤策略，极大化提升用户体验。</p><p></p><p>面对图像搜索的高精准度挑战，我们将图搜召回任务建模为一个涉及千万级图片百万级ID数据的 Re-ID 任务，并通过利用多损失联合监督，显著提升了模型特征学习的判别力。为了应对数据巨量化和模型复杂化趋势，在算力优化方面，通过分布式模型并行技术和稀疏分类采样策略，大幅提升了 GPU 显存效率和模型训练速度。</p><p></p><p>去年，我们自主设计并实现了新一代交互式引擎系统，上线了 AIGC 应用京言。通过反馈式 prompt 优化、session 切分、人类偏好指令对齐增强以及弹性多路检索等创新技术，持续探索为用户提供高效便捷购物体验。</p><p></p><p></p><h1>商家系统深度改造提升效率优化体验</h1><p></p><p></p><p>2023 年初，京东发布“春晓计划”，扩展百万量级的商家进入平台。京东以往的商家系统以服务企业用户为主，业务模式众多、复杂性很高，但新加入的有大量个人商家。如何兼顾原有复杂业务逻辑，又能快速打造适应大量个人商家移动化、简约化办公需求的运营系统？如何能简化运营和快速交付、保障商家规模的快速扩展及商家体验提升，成为京麦商家系统面临的主要挑战。</p><p></p><p>为此，移动端系统整合原生、Flutter 和 Taro 技术，实现功能间的无缝调用，提高业务功能的快速交付和互通能力，同时以内置的一体化 UI 组件确保交互设计与实现的统一；商家入驻环节应用 OCR、RPA 及大模型语义理解能力进行智能化、自动化的审核，提高入驻效率；商品管理环节结合多模态大模型、海量相似商品主体检索和结构化数据 OCR 识别等技术，智能生成商品基础信息；商品营销上首推【主图浮层】功能，即通过动态加载营销利益点实时合成主图技术；履约、售后、结算正逆向交易环节，采用 PaaS 化插件业务流程扩展、规则计算引擎动态配置等技术方式快速支持个人小店运营模式。</p><p></p><p>这些深度改造，大大提高商家入驻效率，个人店入驻时间缩短至约 4 分钟，普通店 15 分钟，企业店 3 个工作日内；商品管理环节，商家只需维护库存和价格即可轻松完成商品上架；营销信息便捷推送，共同助力商家打造“更快运营、更好服务、更省成本”的开店体验。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/04/24/0400386bbed82e7efa1c5fcb08e93824.png\" /></p><p></p><p></p><h1>AIGC技术应用 实现电商创意素材的自动化生成</h1><p></p><p></p><p>电商创意素材中包含了大量的商品直观信息，优秀素材不仅能快速吸引消费者，还可以建立起情感联系。然而现有创意大多依赖人工制作，存在效率和成本的限制。京东零售技术团队基于 AIGC 技术，在图片、文案、图文创意等方面进行了技术突破，实现了高质量广告创意的自动生成。</p><p></p><p>图片创意上，技术团队提出通过类别生成器实现大规模背景生成，并使用个性化生成器从参考图像学习个性化风格，在保持个性化风格的同时能够生成高质量的不同类别背景；文案创意上，基于大语言模型通识，结合商详 OCR 卖点挖掘、标题、属性亮点词等电商数据，通过模型 fine-tune、外挂知识库等方式，实现了满足用户偏好的营销文案创意生成；图文创意上，提出了一种 P&amp;R 框架并分为规划和渲染两个阶段，规划阶段考虑产品外观和文本语义特征，使用 PlanNet 生成多样化、合理的布局，渲染阶段虑生成的布局和融合不同组件的空间关系，使用 RenderNet 生成背景。</p><p></p><p>以上技术突破成功解决了现有图片创意生成方法存在扩大生产规模时设计提示词的低效问题，克服了为特定品牌定制个性化背景时描述细节风格的困难，实现了创意化的图文生成，超越已有的图像生成方法，显著提升了设计效率并降低了制作成本。相关创新性成果已在 ACM MM、CIKM、ICME 等顶会上发表多篇论文。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/c7/6a/c70fe217ba12f2fcyy676c1ab66b9e6a.png\" /></p><p></p><p></p><h1>端智能面向手机计算环境的端云协同 AI 技术创新</h1><p></p><p></p><p>近年来，随着移动端设备软硬件能力的进步，移动端的算力有了很大提升，同时面向移动端的机器学习框架和模型轻量化技术越来越成熟，端上的 AI 能力逐渐进入大众视野，端智能在电商领域也开始逐步走向规模化应用。通过持续探索，京东零售技数中心团队创新突破了端侧高性能推理引擎、端侧模型分发、异构环境及复杂任务兼容等技术卡点，完成了多个业务应用和落地，并获得信通院边缘计算产业全景图行业认证。目前均已集成端智能 SDK，首页推荐、搜索重排、结算风控业务运行情况良好，日推理次数已经突破亿级，为用户带来了更好的互交体验。核心的技术亮点包括：（1）高度量化压缩的端推理引擎：手机端对加载推理引擎体积有严格限制，既要引擎小，也要支持多类型业务。目前端侧推理引擎控制在 1.9M。 （2）高并发场景下的稳定性保障：受限与手机端复杂异构的计算条件，端侧推理稳定性是衡量端智能能力的核心因素。目前端推理几十亿次/日，推理成功率超过 99%。 （3）异构环境及复杂任务兼容性能力：同一套引擎兼容 Android/IOS/鸿蒙 3 套系统，4 种计算芯片，支持多种类型模型，支持内部不同业务多线程调用。 （4）云端协同的工程平台建设：通过建设端侧 PythonVM 能力，实现同一套代码逻辑云端共用。建设了模型预加载和模型后加载等多种端模型分发和部署能力，支持云端模型训练共用一套训练引擎能力。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/ay/7a/ayy4214976c46c8becfa8fd81b65047a.png\" /></p><p></p><p></p><h1>数据安全屋：“可用不可见”技术驱动的数据合规应用新基建</h1><p></p><p></p><p>如何让数据既能被无障碍使用，同时又确保数据安全、个人隐私不被泄露？近年来成为数据开放流通领域的重要难题。</p><p></p><p>2023 年集团安全、集团大数据平台、零售隐私计算团队从 0 到 1 共同打造了集团首个“安全屋”系统，落地数据沙箱、联邦学习、多方安全计算等数据安全计算能力，基于可信平行切面技术实现高效、安全、及可扩展的系统能力，并无缝衔接集团内大数据基座、算法基座和安全基座，为集团内部数据共享应用、外部数据合作等场景提供合规支撑，成为集团数智化基础设施的重要板块。 </p><p></p><p>安全屋落地京东自研版本 Hive、Spark 等安全计算引擎，确保业务层 SQL 逻辑、UDF 算子、复杂数据 ETL 过程低感知切换，兼具衍生数据脱敏、衍生数据透明加密、入出管控等技术手段，保证数据“可用而不可见”；构建了一套免入侵的安全切面控制技术将大数据平台与算法开发平台无缝打通，对关键环节植入控制点实现同一个安全策略全局适用；融合硬件安全TEE，提供内存级数据加密运算，可有效保证运行时安全，更深度消除恶意注入和通信窃取等安全隐患；对原有 ACL、RBAC 权限管控模型进行升维扩展，从技术架构上兼顾系统灵活性和安全管控的统一性。</p><p></p><p>安全屋已经在集团内外项目中进行广泛应用，包括精准营销、金融风控、成本分析等多个场景。随着数据要素、数据市场的进一步发展，安全屋将在数据融合共享、数据安全计算等领域发挥更重要的作用。</p><p> </p><p></p><h1>数据资产全面升级实现存算集约化和生产智能化</h1><p></p><p> </p><p>京东自营和商家自运营模式，以及伴随的多种运营视角、多种组合计算、多种销售属性等观测方法，相较于行业同等量级，数据处理的难度与复杂度都显著增加。如何从海量的数据模型与数据指标中提升检索数据的效率，降低数据存算的成本，快速支撑业务的数据决策与分析，是数据团队去年聚焦解决的核心课题。过程中沉淀了多级加速引擎、基于代价的智能物化策略、基于 One Metric 的异构融合服务、基于 One Logic 的离近在线转换，显著提升业务数字化决策效率，也沉淀了多篇软著与多项技术专利。</p><p></p><p>对于智能物化与数据加速，行业普遍采用 cube 预计算+缓存模式，京东创新性落地了基于主动元数据的口径定义以及基于数据消费场景与消费频次的正负反馈动态决策，确保整个数据链路的存算分配“当下最优”，同时相较于粗粒度的物化策略，模型生命周期参考存储代价配置，数据查询链路根据 RT 表现动态寻址，使得数据生产与数据消费形成交互反馈链路，决策依据更丰富，决策粒度更精准。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/85/77/85001905ef49b8eb713e3677465a4a77.png\" /></p><p></p><p>基于图形语法和多端一体的可视化能力打造层面，京东 JMT 数据可视化能力可以依托底层指标中台快速进行智能诊断与归因，相较于 tableau 等头部解决方案，融入了更多图形语法同时可灵活适配多端多场景。</p><p></p><p>结合 AIGC 技术的智能数据问答系统 chatBI，基于业务知识与数据资产的 Prompt 工程，使用本地大模型 SFT 对实体进行 embedding，通过指标服务平台统一 DSL 取代了行业普遍 NL2SQL 的解决方案，解决了人为意识到数据语言的转换难题，所消耗芯片规模也优于行业水平，在数据智能分析诊断系统里准确率大幅领先。</p><p></p><p>以上核心技术通过 23 年的打磨与应用，数据指标开发与共享效率大幅提升，分析看板搭建时间从天级别缩短到小时级别，且业务用户逐渐可以进行自交付，解决了集中式研发的人力瓶颈，日均指标消费频次从 23 年初的百万级别增长到年末的几千万。未来还将在数据加速、智能物化、智能诊断、大模型应用等方面持续深耕，不断优化数据存算成本，提升数据应用的效率、体验。&nbsp;</p><p></p><p></p><h1>宏图系统首创即时零售行业一站式 LBS 网格化运营</h1><p></p><p></p><p>即时零售行业进入全品类小时达时代，用户丰富且真实的\"使用场景\"切换构成了消费增长新趋势，品牌需要进行全渠道优化、重新配置资源，寻找成本、效率和体验的最优解。在此背景下，2023 年，京东到家正式发布 LBS 网格化运营工具“宏图系统”，通过 B2C+O2O 全域数据分析，实现人、货、场基于 LBS 网格化的供需精准高效匹配，帮助品牌提升全渠道运营效率，创造价值增量。</p><p></p><p>基于京东+京东到家行业独特的 B2C+O2O 零售数字化能力、数据沉淀，宏图系统能够实现基于 LBS 的网格化洞察、识别、分析、判断各个网格内的供需匹配情况，并输出用户、供给、营销策略。将京东数坊用户运营平台、京准通 LBS 流量运营平台、京东到家完美门店系统等进行打通，保障执行落地。作为标准化产品，宏图系统实现了服务模块的标准化、数据处理全周期流程的标准化和前端页面的标准化，同时解决了海量数据产出时效性与查询性能、数据指标交叉计算与验证导致数据准确性问题、数据安全保障和海量数据操作与渲染性能保障的技术难题。</p><p></p><p>宏图系统作为京东到家数字化系统持续为品牌商技术赋能全渠道数字化升级，提升 C 端获客能力、降低 B 端获客成本，实现全渠道营销提升。同时基于网格视角对品牌供给情况进行追踪，帮助链接品牌和商家，从供给覆盖、商品运营方面发现运营问题及机会，为从品牌角度的商品铺货，流通运营提供数字化的系统协同能力。</p><p></p><p></p><h1>自研实现低成本、高质量 3D 建模</h1><p></p><p></p><p>3D 建模的本质是理解物理世界并进行数字重构的过程，符合信息传递从图片、视频到 3D 的发展趋势。它在数字孪生、场景重建等场景有广泛应用，在电商场景中最直接的是商品的 3D 展示，为用户提供全面的商品信息、弥补图片形式单一角度的不足，帮助商家实现业务数据的增长。</p><p></p><p>3D 建模的常见技术路径包括基于传统图形学的方案、基于 NeRF 的深度学习方案，但从商品展示的效果看，想达到主流商详图片和视频质量的要求(PSNR&gt;40dB)都还有距离。为此，我们设计了一套全新技术方案，针对 3D 商品展示场景重点突破，可实现商详图片级展示质量，并对不同材质、形状的商品有更好的鲁棒性。目前该方案已开展商家试点，上线几百个 SKU，在引单转化率上表现正向。</p><p></p><p>3D 建模的技术管线分为采集端、服务端、展示端，除了核心建模算法，我们对采集端、展示端的用户体验有更多的投入。为了保证采集端的便利性和高质量，设计了一款采集 APP，在该 APP 中实现了详实的用户指导、准确的位姿估计、运动模糊控制等功能。在服务端，自研了一套空间编码算法和全新的3D内容格式(.jdv)，实现了高压缩、高质量、可交互，将原始采集的 400MB 素材压缩到 10MB 以内；设计了一套图像分割系统来提取干净的商品前景，通过准确的位姿估计和容积变换方法来稳定输出效果，涉及 NeRF 建模、背景分割等算法，实现了用户在复杂采集背景下的商品展示效果。在展示端，自研的空间解码器能够支持用户在商详主图上可交互式地自由查看商品 3D 展示。目前仍在继续降低采集难度、降低环境光照对展示效果影响等问题。</p><p></p><p>凡是过往，皆为序章。未来，坚持成本、效率、体验、可信、普惠、突破的技术追求，京东零售技术继续和大家一起交流成长、向新而行。</p>",
    "publish_time": "2024-01-23 16:08:51",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "OpenAI也搞“年龄歧视”？奥特曼对话盖茨爆料：员工整体年龄偏大，是个坏兆头",
    "url": "https://www.infoq.cn/article/Ly4avjCIkBp2gF3eqrEK",
    "summary": "<p>编译 | 核子可乐、Tina</p><p>&nbsp;</p><p>去年，比尔·盖茨发表了一篇十分引人关注的博客文章，在文中他表示OpenAI的GPT AI模型是技术上最具革命性的进步，这是他人生中第二次被科技真正震撼到。</p><p>&nbsp;</p><p>盖茨写道，第一次是在1980年，当时他第一次看到图形用户界面（GUI）。他表示，GUI成为他创建微软Windows操作系统的基石。第二次是在2022年年中，当时他见识到了OpenAI及其生成式人工智能ChatGPT的学习能力。盖茨写道：“人工智能的发展与微处理器、个人电脑、互联网和移动电话的诞生一样重要。它将改变人们工作、学习、旅行、获得医疗保健以及彼此交流的方式。整个行业都将围绕它重新定位。企业将通过如何使用它而脱颖而出。”</p><p>&nbsp;</p><p>今年，比尔·盖茨又发布了一个与OpenAI 首席执行官山姆·奥特曼对话的播客，两人深入探讨了 ChatGPT 的发展。在交谈中，比尔·盖茨称赞道：“没想到 ChatGPT 会变得这么厉害！”显然他对这个模型及其快速发展印象深刻。</p><p>&nbsp;</p><p>ChatGPT 最初只是一个语言模型，如今却成长为一个拥有听觉、视觉和语言能力的人工智能媒介。而OpenAI 推出的最新语言模型 GPT-4 更具创造力和协作性，它能与用户一起生成、编辑和迭代各类创意和技术写作任务。目前，ChatGPT团队正在努力拓展GPT-4，使其摆脱目前的推理限制，并专注于提升可靠性。</p><p>&nbsp;</p><p>在与比尔·盖茨的对话中，山姆·奥特曼展望了 ChatGPT 的未来，同时强调他们的 AI 系统仍在不断学习和进化。“现在我们所见到的成果令人兴奋，但更重要的是要认识到这项技术至少在未来五到十年仍将飞速发展。 我们可以说，现在这些模型还处于早期阶段，还有很大的进步空间，”</p><p>&nbsp;</p><p>另一方面，山姆·奥特曼在上周的达沃斯采访中说道，他目前的首要任务是推出新的模型，很可能被称为 GPT-5。同时，他认为实现这一切的前提条件是能源生产能取得突破。他坚信能源生产的突破是推动日益强大、耗能巨大的 AI 模型发展的重要一步，“如果没有取得突破，我们就无法实现目标。”</p><p>&nbsp;</p><p>但ChatGPT未来到底能达到什么样的能力？这恐怕主要在于比尔·盖茨和山姆·奥特曼想将生成式AI带向何方。这也是比尔·盖茨这期播客所讨论的内容，我们将他们的聊天内容翻译出来以飨大家。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5d/5d81fe3c18a3c66cffa4f4fe5b80704a.png\" /></p><p></p><p>&nbsp;</p><p></p><h2>为我解惑：比尔·盖茨与山姆·奥特曼的对话</h2><p></p><p>&nbsp;</p><p>比尔·盖茨: 今天我们主要讨论AI话题，这是个令人兴奋的方向，也有不少人表达了担忧。欢迎你，山姆。</p><p>山姆·奥特曼: 非常荣幸能来到这里。</p><p>&nbsp;</p><p>比尔·盖茨: 我很高兴能看到你的工作不断推进，但我个人也抱有一点怀疑。我真没想到ChatGPT会那么强大，着实令人大吃一惊，特别是它在编码架构之外的出色表现。我们熟悉数字，知道怎么做数学运算，但模仿莎士比亚的文字风格是怎么实现的？你能给大家解释一下吗？</p><p>山姆·奥特曼: 当然可以。其实这种模仿能力对人类来说非常困难，而在计算机这边也差不多，都需要依靠彼此相连的神经元。这种连接是动态的，虽然我们没法直接切开大脑去做观察，但可以用X射线检查并建立起科学理论。我们在可解释性方面已经取得了不错的进展，相信随时间推进还会有更多成果。我希望最终能够理解神经网络的完整运作方式，但目前的认知确实比较有限。如你所说，我们愿意一点点改进对原理的了解，这也将成为后续发展的基石。哪怕抛开科学探索上的好奇心，我们也有意愿解开这个谜题。只是神经网络的规模太过巨大，我们连人类如何理解莎士比亚、表达莎士比亚都不清楚，更别说去分析计算机了。</p><p>&nbsp;</p><p>比尔·盖茨: 确实不清楚。</p><p>山姆·奥特曼: 不光是运作机理不明确，我们甚至不知道怎样完美进行X光检查、观察并设计机能测试，所以要做的工作还很多。</p><p>&nbsp;</p><p>比尔·盖茨: 但我相信在未来五年内，人类会逐渐理解这一切。而这样的理解，也能让未来的AI模型获得远超当下的训练效率和准确性。</p><p>山姆·奥特曼: 确实是这样。技术的发展过程就是艰难探索的过程，总有人率先做出实证发现，但却无法解释其底层原理，只知道确切有效。之后随着科学理解的加深，人类终于可以理解一切、运用一切。</p><p>&nbsp;</p><p>比尔·盖茨: 是的，物理学、生物学都是这样。总有让人摸不着头脑的时候，比如“这些机能是怎么组合在一起的”？</p><p>山姆·奥特曼: 以我们的研究为例，GPT-1自己学会了如何解决问题，着实令人印象深刻，而当时研究人员根本就不清楚其工作原理或者实现原因。之后我们发现了规模越大、性能越好的规律，初步掌握了后续开发的方向。因此我们才能信心满满地保证，自己的演示模型肯定能够发挥作用。虽然当时我们的模型还没训练完成，但对这个规律已经很有信心。我们就对此进行了一系列尝试，开始对当前发生的一切做科学解释。不过这些都是后话，最初的判断首先来自实证结果。</p><p>&nbsp;</p><p></p><h4>谈 ChatGPT、人工智能和法规</h4><p></p><p>&nbsp;</p><p>比尔·盖茨: 展望未来两年，你觉得会出现哪些关键里程碑？</p><p>山姆·奥特曼: 多模态肯定是重中之重。</p><p>&nbsp;</p><p>比尔·盖茨: 就是直接支持语音输入-语音输出？</p><p>山姆·奥特曼: 对，语音输入-语音输出。之后是支持图像，最后是视频。很明显，人们对AI的期待也是如此。我们发布了图像和音频支持功能，市场反响甚至远超我们的预期。后续我们将更进一步，而最重要的进步方向应该会体现在推理能力上。目前，GPT-4还只能以极其有限的方式进行推理。再就是可靠性。如果把大部分问题反复问GPT-4上万次，那么其中部分答案当然会很好，但模型本身不知道哪个才是最佳答案，所以整个重复加筛选的过程只能由用户进行。如果能让可靠性更上一层楼，那么GPT的实用意义将大大增加。</p><p>&nbsp;</p><p>可定制性和个性化也非常重要。人们希望从GPT-4中得出差异化的结果：不同风格、不同的假设前提等等。我们将让这一切成为可能，允许大家提交自己的数据。比如吸纳你的个人信息、电子邮件、日历安排、约会规划并接入其他外部数据源等等。这些都是接下来最重要的改进方向。</p><p>&nbsp;</p><p>比尔·盖茨: 现在的基础算法还主要是前馈和乘法，所以输出每个新单词在本质上就是在做重复迭代。如果想要实现进一步发展目标，比如求解复杂的数学方程，那可能会涉及随机次数变换，意味着推理的控制逻辑也将更加复杂。不知道在这方面，你们做了哪些探索。</p><p>山姆·奥特曼: 确实，我们似乎需要某种自适应计算。现在我们在每个token上耗费的计算量是相同的，无论是最简单的token、还是最复杂的数学计算，这肯定不行。</p><p>&nbsp;</p><p>比尔·盖茨: 是的，比如要求大模型“证明黎曼猜想”。</p><p>山姆·奥特曼: 那肯定需要大量算力。</p><p>&nbsp;</p><p>比尔·盖茨: 但对现在的模型来说，它为这个问题分配的自力跟输出“the”完全一样。</p><p>山姆·奥特曼: 没错，所以目前的方案只能算是能用。在此之后，我们还需要为更复杂的问题找到答案。</p><p>&nbsp;</p><p>比尔·盖茨: 你和我都出席了参议院教育会议，很高兴有约30名参议员能够到场，大家交换意见并共同推进这项巨大的变革。很难讲政界为什么会重视这个问题，但他们提出的问题的确非常现实——“我们没能管好社交媒体，我们本应做得更好”。这确实是个严峻挑战，在舆论层面引发严重的两极分化迹象。而且哪怕是现在，我也没想好该如何处理这个问题。</p><p>山姆·奥特曼: 我不太理解政府为什么没能把社交媒体管理得更好，但似乎不妨以此为契机，帮助政府为接下来的AI研究探索指导方针。</p><p>&nbsp;</p><p>比尔·盖茨: 这确实是个不错的研究案例。说起监管，你对于未来的监管思路有没有大体上的理解？</p><p>山姆·奥特曼: 我们已经在着手解决这个问题了。而且包括AI在内，对技术领域的监管很容易过度，以往就多次发生过这类状况。虽然不敢保证，但假设我们的这条发展路线是对的，而且AI技术的发展也确实能够达到我们预期的水平，那么其必将对全社会、地缘政治平衡等重要因素产生深远影响。这些当然还只是假设，可如果真的出现了算力达到10万甚至100万倍于GPT-4的超级AI系统，那么必须在人类社会建立起覆盖全球的监管机构，由他们管控和指导技术演进。毕竟这已经不再是单一技术，而是一股能够左右世界局势的力量。我们讨论的一种潜在模式，可能是类似国际原子能机构的组织方式。在核能方面，我们曾经做出过成功的尝试。强大的潜在全球影响力，必须对应强有力的全球性机构。我深切认同这一点。该机构应该负责解决各种短期问题，包括AI模型可以输出什么、不该输出什么，如何处理版权争议等等。不同的国家对这些问题有着不同的看法，需要充分进行讨论。</p><p>&nbsp;</p><p>比尔·盖茨: 有些人认为，如果真出现了如此强大的模型，人类必须对其保持警惕——毕竟核监管之所以能够在全球范围内广泛发挥作用，原因就是至少在民用层面，每个人都希望遵循安全实践、受到妥善保护。但在武器化问题上，对核能的约束就非常有限了。其中的关键是如何阻止全世界都不用它做危险的事，但从目前各国在气候、恐怖主义等问题的合作态势上看，恐怕难度会很大。人们甚至援引美中竞争的现实，认为任何着眼长期的发展放缓方案都不会成功。你觉得呢，是不是要求各方放缓开发、提高警惕的想法只会成为空谈？</p><p>山姆·奥特曼: 是的，我觉得要求大家放慢开发的脚步确实不切实际。但如果换个角度讲，“你可以做自己想做的事，但不能让计算集群的功率超出某个极高的阈值”，可能更容易被各方所接收。考虑到高昂的实施成本，全世界可能也只有五个左右的国家能够构建这样的集群，此类系统需要经过国际武器核查机构的管控。其中运行的模型必须接受安全审查，在训练期间和部署前通过相关测试。我觉得这应该是可行的。之前我还不太确定，但今年我们组织过一场全球访问，与许多准参与国的元首交换了意见，且几乎得到了普遍支持。这套方案当然不足以彻底解决问题，在某些情况下，即使规模较小的AI系统也有可能引发风险或者导致严重错误。但在我看来，这至少能帮助全人类规避最高级别的风险因素。</p><p>&nbsp;</p><p></p><h4>山姆·奥特曼眼中的 ChatGPT 未来</h4><p></p><p>&nbsp;</p><p>比尔·盖茨: 但从乐观的角度看，AI也能帮助人类解决一些极端复杂的难题。</p><p>山姆·奥特曼: 那是当然。</p><p>&nbsp;</p><p>比尔·盖茨: 这也是个典型的两极分化问题。AI可能会破坏民主，这当然不是好事。但另一方面，我们也看到AI技术在某些领域极大提高了生产力水平。现在你比较关注哪些领域？</p><p>山姆·奥特曼: 首先，我觉得必须意识到AI发展是一条漫长且连续的曲线。现在我们已经拥有能够执行某些任务的AI系统。它们还无法独立完成整项工作，但却可以处理其中的特定环节，由此带来生产力提升。最终，它们应该可以承接以往只能由人类解决的任务。当然，人类也会在AI的基础上找到新的岗位、获得更好的工作体验。我一直认为只要能为人们提供更强大的工具，那他们不仅可以加快工作速度，更可以将质量提升到全新的高度。</p><p>&nbsp;</p><p>比如说，也许我们可以程序员的开发效率提高3倍。这个目标已经在实现当中，也是我们最关注的应用领域之一。更重要的是，让程序员的效率提高3倍可不止是能编写出3倍的代码量，更能让他们把脑力集中在抽象度更高的问题上、思考完全不同的内容。这就像是从当初的打孔卡到高级编程语言，这不仅加快了我们的开发速度，也让我们拿出了以往无法想象的软件成果。我们坚信这一点，也观察到了喜人的变化态势。</p><p>&nbsp;</p><p>而在AI技术进一步发展之后，其也许能够朝着执行完整任务再做迈进。比如说未来会出现小小的AI Agent，用户可以要求它“帮我编写个程度，期间我会通过提问给你引导”。那时候的AI不再简单编写几条函数，而是会带来全新的开发成果，这也是承担复杂工作的前提。终有一天，我们甚至可以要求AI“帮我经营这家公司”，或者直接要求它“去发现新的物理学规律”。所以大家千万不要被眼前的现实局限住，虽然现有成果已经相当美妙且令人兴奋，但结合这项技术的发展背景来看，未来五到十年之间AI将会出现非常陡峭的改进曲线。到时候回头来看，人们可能会感叹当初的AI模型怎么那么蠢。</p><p>&nbsp;</p><p>总之，编码应该是我们目前最关注的生产力提升领域。目前相关产品已经得到大规模部署和应用。此外，医疗保健和教育领域也同样值得关注。</p><p>&nbsp;</p><p>比尔·盖茨: 但让人心生疑虑的是，与之前的技术改进不同，这次AI的发展可以说是极为迅速且几乎没有上限。AI已经在很多领域都达到了人类从业者的水平，哪怕还没法用于科学研究，它们也已经在客服和销售电话上广泛普及。我猜你也跟我一样有点担心，就是在积极因素之外，AI的快速发展也会加大我们适应时代变化的压力。</p><p>山姆·奥特曼: 这确实是令人担忧的一面。但我觉得这人类既不一定要被迫适应，也不是说缺乏适应变化的能力。我们都经历过巨大的技术变革，任何人做的任何工作都有可能在几代人时间内发生变化。这种变革速度越来越快，但人们也适应得越来越好。过去任何一次伟大的技术革命都是这样，只不过AI变革是速度最快的一次。这的确会令人心生忧虑，担心社会跟不上变化的速度，劳动力市场适应不了层出不穷的挑战。</p><p>&nbsp;</p><p>比尔·盖茨: AI还有另外一个侧重点，就是机器人技术。它要替代的是蓝领工作。只要它的操作能力发展到人类手脚的水平，这个临界点就会到来。ChatGPT那令人印象深刻的功能突破让“消灭白领”成了核心议题，但我担心人们同时忘记去关心那些蓝领岗位。那你是怎么看待机器人技术的？</p><p>山姆·奥特曼: 我倒是非常期待。之前的机器人技术研究都太早了，所以往往进展缓慢、长期停滞。受时代局限，开发工作举步维艰，也没能帮助我们在机器学习研究中取得显著进展。长期以来，大家拿出的只有性能差劲的模拟机械和肢体复健器材之类的东西。但随着时间推移，我们意识到应该首先实现智能与认知，之后才搞清楚意识如何作用于肢体。所以我们从更易于上手的语言模型构建起步，也从未放弃过跟实体机械相结合的目标。</p><p>&nbsp;</p><p>我们已经开始对机器人公司做投资。在物理硬件方面，我终于第一次看到了真正令人兴奋的新平台。也许未来的某一天，我们能把自己的大模型跟机器人结合起来，就像你所说，发挥它们的语言理解和视频理解能力，真正让机器人独立完成某些复杂的工作。</p><p>&nbsp;</p><p>比尔·盖茨: 如果那些特定机械肢体上的研发成果被整合起来，比如腿部、手臂和手指部件，而且价格也不是高得离谱，那它们会不会很快就消灭大量蓝领岗位，彻底改变整个劳动力就业市场？</p><p>&nbsp;</p><p>山姆·奥特曼: 肯定会的。但大家应该还记得，就在七、八年之前，人们对机器人技术的理解都是先替代蓝领岗位，之后才是白领岗位。归根结底，人类最不可替代的永远是创造力，所以未来的从业者也只能依靠自己的创造力。</p><p>&nbsp;</p><p>但实际情况跟当初的预测相反，是白领先受冲击，蓝领反而相对安全。关于这个问题出现了很多有趣的讨论，而且说起创造力，我一直认为GPT模型的“幻觉”并不是bug、而是一项功能。幻觉是创造的来源。但如果想让机器人去搬弄重型机械，那最好能做到精确无误。这就是先验理论需要随实际技术做出调整的例子。我们都有事前判断，但科学的发展往往并不给面子。</p><p>&nbsp;</p><p>比尔·盖茨: 现在的AI已经非常强大了，再加上AGI通用人工智能和未来的AGI+，这三样东西会不会太危险了。我很担心这些系统落入坏人的手里。强大的系统只有在好人手中，才能最大限度受到控制。而且除了这个，我还好奇人类会用AI做什么。你知道我最近一直在投身于治疗疟疾、消灭疟疾的工作，努力招募人才并投入资源。那如果有一天，机器告诉我“比尔，你可以休息了，以你的脑力解决不了这个问题。疟疾已经被AI消灭了。”那我可能会有点难以接受。但必须承认，人类的认知是有极限的，我想消灭疟疾，但不知道如何组织起社会力量。我想改善教育，但搞不清教育到底要如何设计。想要打造出极致的架构，必须解决其中极大的不确定性。而AI的崛起，终于让20年内解决这些终极问题有了一丝可能。</p><p>山姆·奥特曼: 技术工作确实会造成沉重的心理负担，我也感觉这才是其中最困难的部分，但我也因此获得了巨大的满足感。</p><p>&nbsp;</p><p>比尔·盖茨: 你毕竟创造出了巨大的价值。</p><p>山姆·奥特曼: 说句实话，这可能是我最后一次接受这么困难的挑战了。</p><p>&nbsp;</p><p>比尔·盖茨: 我们的解决思路是围绕稀缺性组织起来的：因为好的教师、医生和方案都很稀缺，所以才有了现行制度。所以我的确很好奇，在这一切都不再稀缺中成长起来的下一代人，会以怎样的哲学理念设计社会结构、定义人生目标。也许他们会有自己的答案，而我担心自己的思维已经被稀缺性所绑架，甚至无法想象新的时代会是怎样的形态。</p><p>山姆·奥特曼: 我也一直在提醒自己，就是说虽然人类会失去一些东西，但最终得到的却是才智超越自身的新成果。我们只有适应这样一个后稀缺时代，才能找到属于自己的奋斗方向。这种感觉肯定跟以前大不一样，毕竟我们要解决的不再是疟疾这类现实问题，而是选择自己喜爱的星系，想在那里做些什么。但我相信人类足够灵活，总能用各种各样的方式找到满足感和充实感。相互扶持，用自己的方式服务他人，是人类社会永远的母题。虽然具体形式可能有所不同，但我认为唯一的出路就在这里。我们必须勇敢面对未来，因为未来必将到来。这是一个不可阻挡的技术进程，其中蕴藏着难以想象的巨大价值。我对此很有信心，我们会让这个美好时代来临，但也必将迎来不同于以往的问题。</p><p>&nbsp;</p><p>比尔·盖茨: AI的应用有很多种，其中一些比较明确，比如如何指引和激励孩子学习、如何发现能治疗阿尔茨海默症的药物，这些都有清晰的方向。但也有些问题比较模糊，比如AI能否帮助我们减少战争。在你们这些研究者看来，在智能发展中控制两极分化是常识，阻止战争也是常识，但很多人却对此抱怀疑态度。我希望人类能解决好那些最棘手的问题，比如相互间怎样和睦相处。如果AI能在这些问题上做出贡献，那就再好不过了。</p><p>山姆·奥特曼: 我坚信AI肯定会带给我们惊喜。这项技术的效用将远远超出我们的预期。虽然仍有待时间来证明，但我对此非常乐观。我也认同你的观点，希望AI能够立此奇功。</p><p>&nbsp;</p><p>比尔·盖茨: 说起来，技术的实现成本往往非常高昂，就像当初的个人电脑或者互联网连接一样，而且成本需要时间来逐渐下降。那现在AI系统的运行成本怎么样，是不是每过段时间就会有显著下降？</p><p>山姆·奥特曼: 已经下降了很多。GPT-3是我们优化时间和训练周期最长的模型，在它推出的这三年多时间里，我们已经把成本降低到40%。短短三年能实现这样的成本削减已经是个不错的开端。</p><p>&nbsp;</p><p>我敢打赌，GPT-3.5的成本则降低到接近10%。GPT-4还很新，所以我们没有多少时间做成本控制，但相关探索仍在继续。</p><p>&nbsp;</p><p>我认为在我所知晓的所有技术中，AI正处于成本降低曲线上最陡峭的部分，速度远超当初的摩尔定律。我们不仅破解了模型效率的难题，而且随着研究理解的加深，我们还能从中获取更多知识、在更小的模型中获得基本相当的性能。终有一天，我们的智能成本将趋近于零，那时候就将是全社会的彻底转型之时。</p><p>&nbsp;</p><p>但至少目前，真实世界的两大核心仍然是智力成本与能源成本。这是改善生活质量的两项基本投入，特别是对贫困群体来说。如果能够同时降低这两项指标，就能在同样收入的前提下扩大占有物的数量、极大改善生活体验。我们正处于智力改进的曲线之上，我们也将踏踏实实践行这一承诺。而且即使是按照目前的成本（远远超出预期的最高成本），每月花20美元即可获得巨量GPT-4访问资源，其创造的价值将远超20美元。可以说，我们已经在探索的道路上走得很远了。</p><p>&nbsp;</p><p></p><h4>经营OpenAI的那些事儿</h4><p></p><p>&nbsp;</p><p>比尔·盖茨: 那竞争关系如何？跟那么多同行同台竞技有趣吗？</p><p>山姆·奥特曼: 感觉很复杂，烦人、有趣也让人充满斗志。相信你当年也有过类似的感觉。竞争关系确实敦促我们做得更好、做得更快。我们对自己的研究方法抱有信心，而且OpenAI最大的优势在于：其他厂商朝着球所在的位置冲刺，而我们是朝着球飞往的位置冲刺。这种感觉还不错。</p><p>&nbsp;</p><p>比尔·盖茨: 很多人可能没想到，OpenAI居然是一家体量这么小的公司。你们有多少员工？</p><p>山姆·奥特曼: 大约500人，这还是扩张之后的规模。</p><p>&nbsp;</p><p>比尔·盖茨: 但那很小。至少跟谷歌、微软和苹果比起来不大。</p><p>山姆·奥特曼: 那是当然。而且我们不仅要运营研究实验室，还管理着整个业务体系和两款产品。</p><p>&nbsp;</p><p>比尔·盖茨: 不断扩大业务规模，与全球各地的人们交谈，倾听支持者们的意见，你应该很享受这个过程吧？</p><p>山姆·奥特曼: 是的，非常享受。</p><p>&nbsp;</p><p>比尔·盖茨: OpenAI员工的平均年龄很小吧？</p><p>山姆·奥特曼: 哈哈，其实比一般公司的平均年龄要大些。</p><p>&nbsp;</p><p>比尔·盖茨: 好吧。&nbsp;</p><p>山姆·奥特曼: 反正不像大家想象的，是一堆20来岁的程序员。</p><p>&nbsp;</p><p>比尔·盖茨: 看来是我先入为主了，毕竟我自己都60多岁了，所以看到你就会觉得是个年轻人。但你也40多岁了，没那么年轻了。OpenAI的员工也是。</p><p>山姆·奥特曼: 是的，30多、40多、50多岁的员工都有。</p><p>&nbsp;</p><p>比尔·盖茨: 这跟早期的苹果和微软真不一样，那时候我们就是帮愣头青。</p><p>山姆·奥特曼: 确实不一样，我也反思过这一点。我觉得OpenAI的整体年龄有点偏大了，不知道该怎么说，但这种现象放在社会上应该是个坏兆头。我当初在Y Combinator的时候就关注过这个问题，发现随时间推移，优秀的年轻创业者越来越少。</p><p>&nbsp;</p><p>比尔·盖茨: 这是个有趣的现象。</p><p>山姆·奥特曼: 所以哪怕是OpenAI，员工的平均年龄其实也挺大了。</p><p>&nbsp;</p><p>比尔·盖茨: 通过在Y Combinator帮助公司创业，你肯定学到了很多，这些经验正好用在现在OpenAI的管理和经营上。</p><p>山姆·奥特曼: 的确很有帮助。</p><p>&nbsp;</p><p>比尔·盖茨: 但也有很多反面案例。</p><p>山姆·奥特曼: 是的。OpenAI也做了很多违背Y Combinator常规建议的事情。我们花了四年半才推出首款产品，当初创办公司时根本说不清未来要开发怎样的产品，也压根没跟用户交流过。时至今日，我还是不建议大多数公司学习OpenAI。但在Y Combinator学习了这些规则之后，我才切身体会到这些规则何时、如何以及为何可以打破。总而言之，OpenAI的成长路线跟我见过的任何企业都截然不同。</p><p>&nbsp;</p><p>比尔·盖茨: 关键在于你聚集起了人才，让他们专注于解决那些意义重大的问题，而不是纠结于短期收入之类的小事。</p><p>山姆·奥特曼: 我觉得硅谷投资者不可能为这样一个看起来不靠谱的项目投钱，所以在产品实际上线之前，我们必须自掏腰包支持研究。但我们坚信“这个模型最终会非常出色，也一定会为人们创造价值”。这里很感激微软愿意与我们合作，这种超前收益投资明显有违风险投资行业的操作惯例。</p><p>&nbsp;</p><p>比尔·盖茨: 确实，而且投资额太高了，几乎达到了风险投资所能承受的极限。</p><p>山姆·奥特曼: 没准都超过了。&nbsp;</p><p>&nbsp;</p><p>比尔·盖茨: 没准都超过了。我对萨蒂亚持高度赞赏，就是因为他一直在思考“如何将这家出色的AI组织整合到微软的软件体系中来？”这是一项极具前瞻性的战略判断。</p><p>山姆·奥特曼: 一切都超乎预期。你说得对，我在Y Combinator学到了很多，并据此管理OpenAI。我们一方面聘请全世界最优秀的人才，另外也要保证大家在发展方向和AGI使命上保持一致。但在此之外，员工们可以随意发挥。我们都知道这种复杂问题需要时间的沉淀，回报也绝不会很快到来。</p><p>好在我们的理论被证明大致正确，但一路走来很多策略也被证明属于严重错误。科学的探索就是这样，永远喜忧参半。</p><p>&nbsp;</p><p>比尔·盖茨: 我记得当初刚看到技术演示时，自己一直在想这样的产品要怎样创收？服务会是什么样子？哪怕是在这个疯狂的时代，你们团队都有点太过超前了。</p><p>山姆·奥特曼: 是的。优秀的人们希望能跟优秀的同事一起工作。</p><p>&nbsp;</p><p>比尔·盖茨: 这是一种强大的吸引力。&nbsp;</p><p>山姆·奥特曼: 很多公司都喜欢说英雄惜英雄、好汉重好汉，但大家在OpenAI是真正感受到了自己的历史使命。每个人都希望参与到AGI的实现中来。</p><p>&nbsp;</p><p>比尔·盖茨: 这样的使命感确实令人心潮澎湃。当初你拿出技术演示时，我就为其中承载的热情所震撼；我看到了新的朋友，新的想法。而你们一刻不停，仍在以令人难以置信的速度前进。</p><p>山姆·奥特曼: 大家一定经常让你提点建议，那你一般会怎么说？</p><p>&nbsp;</p><p>比尔·盖茨: 我觉得这世界上有很多不同形式的人才。在我的职业生涯之初，我只重视纯粹的智商，类似于工程技术的灵性。当然，这个逻辑在财务和销售领域也有体现。但事实证明这是不对的。能建立起强大团队的技能组合才是重中之重。能引导人们思考、找到想要解决的问题、建立一支融合不同人才的队伍，才是最重要的能力所在。所以我想告诉年轻人，数学和科学能力当然很重要，但如果你真想成就一番事业，那么前面说的这种才能组合必不可少。</p><p>你呢，你会给出什么样的建议？</p><p>山姆·奥特曼: 我比较关注大多数人对于风险的错误理解。大家往往害怕放弃自己当前这份轻松愉快的工作，不敢奔赴自己真正想做的事情。但实际上，如果始终止步不前，那他们最终回顾一生，只会感叹自己从没有投入过、没有创办自己想象中的企业、也没试着成为一名AI研究者。我觉得这才是最大的风险，是让整个人生沦于平庸的风险。</p><p>正因为如此，我们应该明确自己的目标，同时积极询问其他人需要什么，这就是良好的开端。很多人都在以自己不想的方式虚耗时间，而我给出的建议就是试着以积极的方式解决这个问题。</p><p>&nbsp;</p><p>比尔·盖茨: 确实，让人们从事一份自己有成就感、满足感的工作，往往能够迸发出他们自己都难以想象的力量。</p><p>山姆·奥特曼: 绝对是这样。</p><p>&nbsp;</p><p>比尔·盖茨: 感谢你的到来，很高兴跟你聊了这么多。相信我们在不断尝试以更好的方式塑造AI的过程中，还会有更多值得交流的话题。</p><p>山姆·奥特曼: 也感谢你邀请我过来，聊得很开心。</p><p>&nbsp;</p><p>&nbsp;播客链接：</p><p><a href=\"https://www.gatesnotes.com/Unconfuse-Me-podcast-with-guest-Sam-Altman\">https://www.gatesnotes.com/Unconfuse-Me-podcast-with-guest-Sam-Altman</a>\"</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2024-01-23 19:33:07",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]