[
  {
    "title": "三步实现Lambda向Kubernetes大迁移",
    "url": "https://www.infoq.cn/article/AhfmZfWjvUAmap5lcTAI",
    "summary": "<p><a href=\"https://en.wikipedia.org/wiki/Infrastructure_as_code\">基础设施即代码（IaC）</a>\"的世界已经掀起了云原生的风暴，如今配置云服务和应用程序时，它已成为一种通用的最佳实践。当云操作呈指数级增长时（这在当今基于SaaS和云托管的按需应用程序中发生得相当快），对于仍在利用ClickOps的公司来说，很快就会崩溃，ClickOps通过手动配置，但这在云应用程序中会造成漂移。</p><p></p><p>值得注意的是，虽然IaC是一种最佳实践，并提供了许多好处（包括避免漂移），当我们需要进行重大的基础设施迁移时，我们看到了它的真正价值。我们发现，由于我们很早就利用了IaC的强大功能，并在配置方面与最佳实践保持一致，因此以前复杂的迁移过程变得简单多了。（还记得像VeloStrata和CloudEndure这样的公司吗？它们就是为此目的而建立的吗？）当我们谈论云和供应商锁定时，我们已经了解到如何打包、配置和部署应用程序会直接影响它们的可移植性和可扩展性。</p><p></p><p>在本文中，我想分享我们在Firefly的工作，将作业从Serverless迁移到Kubernetes Job的伟大旅程、经验教训、以及帮助我们以最小的痛苦实现这一目标的技术。</p><p></p><h1>第一站：Lambda事件</h1><p></p><p></p><p>Serverless（无服务器）正在成为许多新兴甚至成熟公司的热门选择架构，因为它提供了云的所有好处——规模、可扩展性、弹性——以及最小管理和维护开销的附加值。它不仅速度快、可扩展，而且构建起来还非常有趣。</p><p></p><p><a href=\"https://aws.amazon.com/lambda/\">Lambda</a>\"、函数、连接它们的服务以及基于事件的架构是开发人员试验和快速迭代之前复杂架构的游乐场。对于专为此类工作而构建的<a href=\"https://developer.hashicorp.com/terraform/intro\">Terraform</a>\"和<a href=\"https://developer.hashicorp.com/terraform/language/modules\">Terraform Modules</a>\"来说尤为如此。突然之间即可通过lambda运行程序在数小时内构建支持大规模、并发操作的基础设施，这过去至少需要几天甚至几周。</p><p></p><p>然而，随着时间的推移，我们开始遇到事件驱动架构和设计方面的问题。 由于我们的数据和流正常工作所需的服务种类繁多——API网关、SQS、SNS、S3、事件桥等，事件的数量及其输入/输出开始增加。这就是我们开始触及已知的<a href=\"https://stackoverflow.com/questions/74193863/lambda-timeout-after-10s-both-in-serverless-offline-and-online\">Serverless超时墙</a>\"的地方。由于Serverless本质上是短暂的运行时，它基本上只有一个15分钟的任务完成窗口。如果任务没有及时完成，就会失败。</p><p></p><p>我们开始意识到，蜜月期可能已经结束了，我们需要根据用例和操作的具体性质来重新思考我们的基础设施选择。当你走上微服务的道路时——在我们的案例中，我们选择了利用<a href=\"https://go.dev/tour/concurrency/1\">Go例程</a>\"来实现多线程服务（所以我们谈论的是很多服务），你通常会开始失去对正在运行的作业和服务数量的控制。</p><p></p><p>我们“微服务统治一切！”的心态，在以前我们认为它是令人难以置信的可扩展性的标志，但现在是我们崩溃的根源。我们试图通过添加限制来解决超时问题，但这大大减慢了我们的流程（对SaaS公司来说这不是一件好事），这当然不是我们所希望的结果。当我们增加集群时，这带来了巨大的成本影响，这对于一家初创公司来说也不是理想的选择。</p><p></p><p>技术债的累积使我们开始考虑我们的选择——重写还是迁移？如果不进行重大改革，我们还可以考虑或利用哪些其他技术呢？</p><p></p><h1>第二站：停靠在ECS</h1><p></p><p></p><p>我们旅程的下一站是<a href=\"https://aws.amazon.com/ecs/\">ECS（Elastic Container Service，弹性容器服务</a>\"）。选择ECS实际上是我们最初选择将应用程序打包并部署到Serverless的副产品。我们选择将所有的应用程序进行docker化，并通过Terraform进行配置。这种早期的选择最终使我们能够选择我们的架构和基础设施。</p><p></p><p>我们决定尝试一下ECS，主要是因为它的分析能力，以及处理任务、事件和作业时没有时间限制，就像Serverless一样。</p><p></p><p>ECS的优势在于它的控制机制——这是它的核心功能，AWS在其中管理任务调度、优先级、在何处以及何时运行。然而，对我们来说，这也是一把双刃剑。</p><p></p><p>特定事件的性质要求我们在任务调度方面有更大的控制权，比如更细粒度的优先级排序、任务排序、基于预定义的指标和阈值推动动态配置，而不仅仅是编程限制，还需更具动态性并利用遥测数据的限制。例如，如果我们有一个特定的帐户或租户正在使系统超载或向系统发送垃圾邮件，我们可以更动态地限制该事件，并更好地控制每个租户的自定义配置。</p><p></p><p>当我们分析这种情况时，我们意识到缺少的是一台“计算机”，或者说是Kubernetes世界中的操作（operator）。（这是一篇关于如何编写第一个Kubernetes操作的好文章，在这里你可以了解更多详细信息）。</p><p></p><h1>第三站：回到Kubernetes作业的旅程中</h1><p></p><p></p><p>回到使用容器化lambda的选择上，我们意识到，由于这个选择，我们并没有局限于基于AWS的基础设施，突然间，一个开放的社区标准选项出现了，这对我们和我们的需求来说是正确的选择。</p><p></p><p>如果我们想看看迁移到Kubernetes的好处，有很多需要考虑的因素：</p><p>有了Kubernetes作业（job），就有了一个可以实现更动态配置的操作（operator）作为一家以IaC为先的公司，<a href=\"https://helm.sh/\">Helm</a>\"是配置应用程序的绝佳方式在无限规模上进行更大、更细粒度的分析、限制和配置</p><p></p><p>对我们来说，能够手动配置和管理CPU和内存分配，以及通过深度分析对其进行定制和自动化，这一好处是非常重要的。特别是当我们谈论由具有高度不同使用行为的各种客户端组成的规模时，其中一个租户可以运行两个小时，而其他租户只能运行三秒。因此，这种可定制性对我们来说是一个关键特性，也是最终让我们确信这一举措的关键。</p><p></p><p>接下来是检查应用程序的不同层，以了解这种迁移的复杂性。</p><p></p><h2>如何将Lambda转换为Kubernetes作业？</h2><p></p><p></p><p>现在是我们进行哲学思考的时候了。最终，什么是lambda？这是一种需要使用特定配置并一次性完成的作业，该配置运行一组worker来完成作业。这让我们顿悟，这听起来很像……K8s的作业。</p><p></p><p>我们的容器化lambda和完全编码的配置使我们能够重用运行时和配置，在不同环境之间移动只需进行很少的调整。让我们来看看其中的一些关键元素。</p><p></p><h3>网络</h3><p></p><p></p><p>绝大多数网络要素都是通过容器化来覆盖的，包括安全组等等。另一方面，如果网络未配置为代码或定义不明确，那么可能会发现服务之间的通信崩溃。确保所有安全组及其资源，从VPC到其他任何东西，都得到了正确的配置，可以确保更加无缝的过渡，这本质上是民主化基础设施选择的基础。</p><p></p><h3>权限和外部配置</h3><p></p><p></p><p>另一个可以促成或破坏这种迁移的关键方面是权限和访问控制。Serverless（AWS）、ECS和Kubernetes与<a href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/id.html\">IAM角色</a>\"一起工作时，问题只在于如何设计角色，使流不会中断，然后就可以轻松地跨环境移植它们。通过这种方式，我们可以确保流程不会在过渡中中断。会存在一些小的更改和优化，例如配置信任关系； 但是，这比从头开始配置所有权限要好的多。</p><p></p><p>更改IAM角色的信任关系：</p><p><code lang=\"null\">{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"Service\": \"lambda.amazonaws.com\"\n            },\n            \"Action\": \"sts:AssumeRole\"\n        }\n    ]\n}\n</code></p><p></p><p>这使其可移植且可重复使用：</p><p><code lang=\"null\">{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"\",\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"Federated\": \"arn:aws:iam::123456789:oidc-provider/oidc.eks.us-east-1.amazonaws.com/id/XXXXXXXXXXXXXXXXX\"\n            },\n            \"Action\": \"sts:AssumeRoleWithWebIdentity\"\n        }\n    ]\n}\n</code></p><p></p><p>我们需要确保所涉及的其他更改也在Kubernetes部署中将环境变量转换成了configmap格式。这样，就可以连接到首选的运行时和环境上了。</p><p></p><h3>令人不快的运行时流</h3><p></p><p></p><p>这并不意味着不会存在另人不快的流。Docker并不是万能的，在某些情况下会出现兼容性问题，例如基础镜像可能会随着服务的不同而变化，或者在不同的操作系统发行版本之间发生变化，此外还有Linux问题，比如文件目录中的依赖关系。</p><p></p><p>然而，我们可以通过使用尽可能多的抽象来构建自己的Docker镜像和依赖关系，从而克服这些挑战。例如，在单独的构建器镜像中编译我们的Golang应用程序，并在目标镜像中使用它，或者在具有显式引用的结构中管理我们的环境变量，以避免依赖任何运行时为我们注入，这些都是避免运行时问题的良好实践。</p><p></p><h2>蓝/绿部署</h2><p></p><p></p><p>那么最终的发布是什么样的呢？虽然有一些停机时间，但这并不重要。我们团队选择了蓝/绿的方法来进行部署，并对此进行了密切监控，以确保所有数据都能正常接收，迁移也能顺利进行。</p><p></p><p>在我们进一步深入探讨之前，先简单介绍一下监控和日志记录。这是在部署任何内容之前需要确保正确迁移的另一个方面。当涉及到监控时，我们需要确保正确地转换了一些元素。如果我们之前监控过lambda，那么现在就需要将它们转换为监控集群和pod。我们需要验证日志是否能正常发送和到达——CloudWatch与fluentd。</p><p></p><p>一旦我们把所有这些都准备好了，就可以按照蓝/绿部署来重新路由我们的流量了。我们通过SQS将一些事件流路由到新的基础设施，并进行持续的完整性检查，以确保业务逻辑没有中断，一切都在传输，并且监控和日志记录都在正常工作。一旦我们检查了这个流程，并在没有任何中断的情况下将流量从以前的基础设施缓慢增加到新的基础设施上，我们的迁移就已经完成了。</p><p></p><p>这可能需要几个小时或几天的时间，具体时间取决于部署规模以及操作、SLA、数据等的敏感程度。唯一明确的建议是要确保我们有适当的可见性来了解它是否在有效地工作。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/lambda-migration-k8s-jobs/\">https://www.infoq.com/articles/lambda-migration-k8s-jobs/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/INZSfZJfHU5BR6buJXcT\">更便捷地迁移+开发：3年时间，鲲鹏 DevKit真的做到了</a>\"</p><p><a href=\"https://www.infoq.cn/article/hSHcmyE9R5HPhuNj7mSP\">迁移至云端：真的像看上去那样让人望而生畏吗？</a>\"</p><p><a href=\"https://www.infoq.cn/article/hH21bwuEudJFL93PNSh3\">使用 Rspack 构建真实开源项目，实测迁移成本和性能收益</a>\"</p>",
    "publish_time": "2023-05-30 10:04:18",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Bun发布全新Bundler：比Webpack快220倍",
    "url": "https://www.infoq.cn/article/Uj6bY5VyC6IDheuilHOC",
    "summary": "<p>Bun 的高速原生 bundler 目前正处于 beta 阶段。大家已经可以通过 bun build CLI 命令或者新的 Bun.build() JavaScript API 抢先体验。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/92/926a8f7f50516c8881ddcf2d6749326f.png\" /></p><p></p><p>在带 sourcemaps 和 minification 的情况下，从零开始捆绑 10 个 three.js 副本</p><p></p><p>通过内置的 Bun.build() 函数或者 bun build CLI 命令用这款 bundler 构建前端应用。</p><p></p><p><code lang=\"css\">Bun.build({\n  entrypoints: ['./src/index.tsx'],\n  outdir: './build',\n  minify: true,\n  // additional config\n});\n</code></p><p></p><p></p><h2>降低 JavaScript 复杂性</h2><p></p><p></p><p>JavaScript 最初只负责自动填充表单字段，如今却在多年发展之后成了众多关键场景内的开发手段，甚至负责驱动火箭发射项目的地面控制台。</p><p></p><p>相应的，JavaScript 生态系统的复杂性也呈现出爆发式增长。我们该如何运行 TypeScript 文件？如何构建 / 捆绑生产代码？软件包是否适用于 ESM？如何加载仅限本地的配置？需不需要安装相应的依赖项？如何让 sourcemaps 顺利起效？需要烦恼的问题实在太多。</p><p></p><p>复杂性是效率的大敌，导致我们得花很长时间把工具组合起来，或者坐等处理完成。npm 包的安装速度很慢，测试消耗的时间也远比预想的长。既然 2003 年的时候只需要几毫秒就能把文件上传到 FTP 服务器，2023 年部署软件反倒还需要好几分钟？</p><p></p><p>多年以来，我一直对 JavaScript 缓慢的运行速度感到沮丧。如果测试变更甚至是保存文件所消耗的时间都足够我们看几眼 Hacker News，那肯定是哪里出了大问题。</p><p></p><p>倒不是说复杂性就不该存在。Bundlers 和 minifiers 让网站的加载速度圩快，TypeScript 的编辑器内交互文档则提升了开发人员的工作效率。类型安全有助于在实际报错前就提出警告，而作为版本化包形式的依赖项也要比以往的复制文件更易于维护。</p><p></p><p>但 Unix 的基本理念就是“集中精力做好一件事”，但这“一件事”被多种孤立工具所割裂时，理念也将随之崩溃。</p><p></p><p>正因为如此，我们决定打造 Bun，并在今天高兴地向大家介绍刚刚推出的 Bun bundler。</p><p></p><p></p><h2>没错，一款全新 bundler</h2><p></p><p></p><p>使用这款新的 bundler，Bun 生态系统将捆绑雕琢成了一流元素，具体涵盖 bun build CLI 命令、新的顶级 Bun.build 函数，还有稳定的插件系统。</p><p></p><p>之所以决定打造 Bun 的专有 bundler，主要是考虑到以下几个原因。</p><p></p><p></p><h3>集成度更好</h3><p></p><p></p><p>Bundlers 是一种元工具，能够协调并启用所有其他工具，包括 JSX、TypeScript、CSS 模块和服务器组件等——所有这一切都需要 bundler 的集成才能工作。</p><p></p><p>现如今，bundlers 已经成为 JavaScript 生态系统中巨大复杂性的来源。通过向 JavaScript 运行时内引入新捆绑机制，我们相信能够让前端和全栈代码的交付变得更简单、更快捷。</p><p></p><p>快速插件。插件将在快速启动的轻量化 Bun 进程内执行。无冗余转译。使用 target:”bun”，新 bundler 就能生成面向 Bun 运行时进行优化的预转译文件，从而提高运行性能并避免不必要的重新转译。统一插件 API。Bun 提供统一的插件 API，能够与 bundler 和运行时配合使用。任何扩展 Bun 捆绑功能的插件亦可用于扩展 Bun 的运行时功能。运行时集成。构建会返回一个 BuildArtifact 对象数组，这些对象将实现 Blob 接口，并可被直接传递至 HTTP API，例如 new Resonpse( )。运行时还为 BiuildArtifact 实现了非常精美的输出效果。独立的可执行文件。此 bundler 可以通过—compile 标志在 TypeScript 和 JavaScript 脚本中生成独立的可执行文件。这些可执行文件是完全独立的，包括 Bun 运行时副本。</p><p></p><p>bundler 还将很快与 Bun 的 HTTP 服务器 API（Bun.serve）相集成，从而利用简单的声明性 API 表达当前复杂的构建管线。这一点将在后文中具体介绍。</p><p></p><p></p><h3>性能表现</h3><p></p><p></p><p>性能当然有所提高。作为运行时，Bun 的代码库已经包含了快速解析和转换源代码的基础成果（在 Zig 中实现）。但问题是其很难与现有原生 bundler 相集成，而且进程间通信所引发的额外开销还会损耗性能。</p><p></p><p>而新 bundler 没有让我们失望。在基准测试中（esbuild 的 three.js 基准测试），Bun 比 esbuild 快 1.75 倍，比 Parcel 2 快 150 倍，比 Rollup + Terser 快 180 倍，比 Webpack 快 220 倍。</p><p></p><p></p><h3>开发者体验</h3><p></p><p></p><p>回顾原有 bundlers 的 API，我们发现其中仍有巨大的改进空间。没人喜欢被 bundler 的配置工作消耗宝贵精力，因此 Bun bundler 的 API 设计中着重强调了清晰易用。</p><p></p><p></p><h2>API</h2><p></p><p></p><p>API 目前遵循设计最小化的理念。我们的初始版本希望能在不牺牲性能的情况下，提供一个速度快、稳定性佳、可适应大多数现代用例的最小功能集。</p><p></p><p>下面来看目前的 API：</p><p></p><p><code lang=\"typescript\">interface Bun {\n  build(options: BuildOptions): Promise;\n}\ninterface BuildOptions {\n  entrypoints: string[]; // required\n  outdir?: string; // default: no write (in-memory only)\n  target?: \"browser\" | \"bun\" | \"node\"; // \"browser\"\n  format?: \"esm\"; // later: \"cjs\" | \"iife\"\n  splitting?: boolean; // default false\n  plugins?: BunPlugin[]; // [] // see https://bun.sh/docs/bundler/plugins\n  loader?: { [k in string]: string }; // see https://bun.sh/docs/bundler/loaders\n  external?: string[]; // default []\n  sourcemap?: \"none\" | \"inline\" | \"external\"; // default \"none\"\n  root?: string; // default: computed from entrypoints\n  publicPath?: string; // e.g. http://mydomain.com/\n  naming?:\n    | string // equivalent to naming.entry\n    | { entry?: string; chunk?: string; asset?: string };\n  minify?:\n    | boolean // default false\n    | { identifiers?: boolean; whitespace?: boolean; syntax?: boolean };\n}\n</code></p><p></p><p>其他很多 bundler 为了追求功能完备性，而做出了很多糟糕的架构决策，最终导致整体性能下降。而我们正努力避免重蹈覆辙。</p><p></p><p></p><h3>模块系统</h3><p></p><p></p><p>目前仅支持 format: \"esm\"格式。我们打算后续逐步添加对其他模块系统和目标（如 iife）的支持。如果大家确有需求，我们也会考虑添加 cjs otuput 支持（支持 CommonJS 输入，但不支持输出）。</p><p></p><p></p><h3>目标</h3><p></p><p></p><p>我们目前支持三个“targets”目标，分别为“browser”（默认）、“bun”和“node”。</p><p></p><p></p><h4>browser</h4><p></p><p></p><p>TypeScript 和 JSX 将被自动转译为原始 JavaScript。在有可用模块时，通过 “browser” package.json \"exports\"执行模块解析。Bun 在浏览器中导入时会自动填充某些 Node.js API，例如 node:crypto，这种行为与 Webpack 4 类似。Bun 自己的 API 目前禁止导入，但我们未来可能会重新考虑这个问题。</p><p></p><p></p><h4>bun</h4><p></p><p></p><p>Bun 和 Node.js APIs 仍受支持且将保持不变。通过 Bun 运行时所使用的默认解析算法进行模块解析。生成的捆绑包使用特殊的 // @bun 标注，表明它们是由 Bun 所生成。通过这种方式，Bun 运行时就能意识到该文件在执行前无需重新编译。</p><p></p><p></p><h4>node</h4><p></p><p></p><p>目前，node 的处理方式等同于 target: “bun”。未来，我们计划自动填充 Bun API，例如 Bun global 和 bun:* 内置模块。</p><p></p><p></p><h3>文件类型</h3><p></p><p></p><p>新 bundler 支持以下文件类型：</p><p></p><p>.js .jsx .ts .tsx – 各种 JavaScript 和 TypeScript 文件；.txt — 纯文本文件，将被内联为字符串；.json .toml — 这些格式将在编译时被解析并内联为 JSON。</p><p></p><p>其他一切都将被视为资产，资产会按原本被复制到 outdir，并使用该文件的相对路径或 URL（/images/logo.png）替换导出。</p><p></p><p><code lang=\"javascript\">import logo from \"./images/logo.png\";\nconsole.log(logo);\n</code></p><p></p><p></p><h3>插件</h3><p></p><p></p><p>与运行时本身一样，新 bundler 在设计上可通过插件实现扩展。实际上，运行时插件和 bundler 插件间没有任何区别。</p><p></p><p><code lang=\"javascript\">import YamlPlugin from \"bun-plugin-yaml\";\nconst plugin = YamlPlugin();\n// register a runtime plugin\nBun.plugin(plugin);\n// register a bundler plugin\nBun.build({\n  entrypoints: [\"./src/index.ts\"],\n  plugins: [plugin],\n});\n</code></p><p></p><p></p><h3>构建输出</h3><p></p><p></p><p>Bun.build 函数会返回一个 Promise，具体定义为：</p><p></p><p><code lang=\"typescript\">interface BuildOutput {\n  outputs: BuildArtifact[];\n  success: boolean;\n  logs: Array; // see docs for details\n}\ninterface BuildArtifact extends Blob {\n  kind: \"entry-point\" | \"chunk\" | \"asset\" | \"sourcemap\";\n  path: string;\n  loader: Loader;\n  hash: string | null;\n  sourcemap: BuildArtifact | null;\n}<p></p><p></p><p>其中 outputs 数组中包含构建所生成的所有文件。每个 artifact 均实现 Blob 接口。</p><p></p><p><code lang=\"javascript\">const build = await Bun.build({\n  /* */\n});\nfor (const output of build.outputs) {\n  output.size; // file size in bytes\n  output.type; // MIME type of file\n  await output.arrayBuffer(); // =&gt; ArrayBuffer\n  await output.text(); // string\n}</code></p><p></p><p>Artifacts 还包含以下附加属性：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/71/713e333a1befdd6f8009251891c6b118.png\" /></p><p></p><p>与 BunFile 类似，BuildArtifact 对象也可以被直接传递至 new Response( ) 当中。</p><p></p><p><code lang=\"javascript\">const build = Bun.build({\n  /* */\n});\nconst artifact = build.outputs[0];\n// Content-Type is set automatically\nreturn new Response(artifact);</code></p><p></p><p>Bun 运行时在记录 BuildArtifact 对象时会提供更精美的输出效果，让调试过程更加轻松。</p><p></p><p><code lang=\"javascript\">// build.ts\nconst build = Bun.build({/* */});\nconst artifact = build.outputs[0];\nconsole.log(artifact);</code></p><p></p><p></p><h3>服务器组件</h3><p></p><p></p><p>Bun 的 bundler 目前通过—server-components 标志对 React 服务器组件提供实验性支持。我们将在本周之内发布额外的说明文档和示例项目。</p><p></p><p></p><h2>摇树机制</h2><p></p><p></p><p>Bun bundler 支持对未使用代码进行摇树，且在捆绑过程中始终执行摇树精简。</p><p></p><p></p><h4>package.json “sideEffects” 字段</h4><p></p><p></p><p>Bun 在 package.json 当中支持\"sideEffects\": false，相当于提示 bundler 当前包没有副作用，可以积极消除其中的无用代码。</p><p></p><p></p><h4>PURE 注释</h4><p></p><p></p><p>Bun 支持 PURE 注释：</p><p></p><p><code lang=\"javascript\">function foo() {\n  return 123;\n}\n/** #__PURE__ */ foo();</code></p><p></p><p>由于 foo 没有副作用，因此这会产生一个空文件：output.js。</p><p></p><p>请参阅 Webpack 说明文档，了解更多细节信息。</p><p></p><p><a href=\"https://webpack.js.org/guides/tree-shaking/#mark-a-function-call-as-side-effect-free\">https://webpack.js.org/guides/tree-shaking/#mark-a-function-call-as-side-effect-free</a>\"</p><p></p><p></p><h4>process.env.NODE_ENV 与 --define</h4><p></p><p></p><p>Bun 支持 NODE_ENV 环境变量和—define CLI 标志。这些一般用于按特定条件在生产构建中包含代码。</p><p></p><p>如果 process.env.NODE_ENV 被设置为\"production\"，则 Bun 会自动删除包含在 if (process.env.NODE_ENV !== “production”) { … }中的代码。</p><p></p><p><code lang=\"javascript\">if (process.env.NODE_ENV !== \"production\") {\n  module.exports = require(\"./cjs/react.development.js\");\n} else {\n  module.exports = require(\"./cjs/react.production.min.js\");\n}</code></p><p></p><p></p><h3>ES 模块摇树</h3><p></p><p></p><p>ESM 和 CommonJS 输入文件均支持 ESM 摇树。Bun bundler 将在安全的情况下，自动删除 ESM 文件中未使用的导出。</p><p></p><p><code lang=\"javascript\">import { foo } from \"./foo.js\";\nconsole.log(foo);</code></p><p></p><p>未使用的 bar 导出被删除，因此：</p><p></p><p><code lang=\"php\">// foo.js\nvar $foo = 456;\nconsole.log($foo);</code></p><p></p><p></p><h3>CommonJS 摇树</h3><p></p><p></p><p>在某些受限情况下，Bun bundler 会自动以零运行时开销自动将 CommonJS 转换为 ESM。考虑以下简单示例：</p><p></p><p><code lang=\"javascript\">import { foo } from \"./foo.js\";\nconsole.log(foo);</code></p><p></p><p>Bun 会自动将 foo.js 转换为 ESM，并摇树精简未使用的 exports 对象。</p><p></p><p><code lang=\"php\">// foo.js\nvar $foo = 123;\n// entry.js\nconsole.log($foo);</code></p><p></p><p>注意，在大多数情况下，CommonJS 的动态特性会令摇树难以实现。例如考虑以下三个文件：entry.js、foo.js、bar.js。</p><p></p><p><code lang=\"javascript\">// entry.js\nexport default require(\"./foo\");</code></p><p></p><p>Bun 无法在不执行 foo.js 的情况下静态确定其导出（Object.assign 可能被覆盖掉，基本导致无法进行静态分析）。在这种情况下，Bun 不会对 exports 对象执行摇树；相反，它会注入 CommonJS 运行时代码以确保其按预期工作。</p><p></p><p><code lang=\"null\">CommonJS打包器</code></p><p></p><p></p><h2>Sourcemaps</h2><p></p><p></p><p>新 bundler 同时支持内联与外部 sourcemaps。</p><p></p><p><code lang=\"javascript\">const build = await Bun.build({\n  entrypoints: [\"./src/index.ts\"],\n  // generates a *.js.map file alongside each output\n  sourcemap: \"external\",\n  // adds a base64-encoded `sourceMappingURL` to the end of each output file\n  sourcemap: \"inline\",\n});\nconsole.log(await build.outputs[0].sourcemap.json()); // =&gt; { version: 3, ... }\n</code></p><p></p><p></p><h2>Minifier</h2><p></p><p></p><p>没有 minifier 的 JavaScript bundler 显然是不完整的。新版本引入了 Bun 中内置的全新 JavaScript minifier。使用 minify: true 即可启用 minification 功能，通过以下选项具体配置 minification 行为：</p><p></p><p><code lang=\"typescript\">{\n  minify?: boolean | {\n    identifiers?: boolean; // default: false\n    whitespace?: boolean; // default: false\n    syntax?: boolean; // default: false\n  }\n}\n</code></p><p></p><p>Minifier 能够删除无用代码、重命名标识符、删除空格并智能压缩和内联常量值。</p><p></p><p><code lang=\"javascript\">// This comment will be removed!\nconsole.log(\"this\" + \" \" + \"text\" + \" will\" + \" be \" + \"merged\");\n</code></p><p></p><p></p><h2>在 React 中使用新 bundler</h2><p></p><p></p><p>我们已经更新了以下 React bun create 模板，可在后台使用 Bun.build。运行下列命令，即可构建一个由 Bun bundler 支持的简单 React 项目。</p><p></p><p><code lang=\"properties\"># a React single-page app\nbun create react ./myapp\n# a Next.js-like app with a /pages directory\n# with SSR and client-side hydration\nbun create react-ssr ./myapp\n</code></p><p></p><p></p><h2>先睹为快：Bun.App</h2><p></p><p></p><p>Bundler 只是我们更多开发计划的前提和基础。在未来几个月中，我们还将发布 Bun.App——一个“超级 API”同，能够将 Bun 的原生高速 bundler、HTTP 服务器和文件系统路由程序融合为统一的整体。</p><p></p><p>其目标是通过几行代码，轻松使用 Bun 表达任何类型的应用程序：</p><p></p><p><code lang=\"properties\">new Bun.App({\n bundlers: [\n   {\n     name: \"static-server\",\n     outdir: \"./out\",\n   },\n ],\n routers: [\n   {\n     mode: \"static\",\n     dir: \"./public\",\n     build: \"static-server\",\n   },\n ],\n});\napp.serve();\napp.build();\n</code></p><p></p><p>此 API 仍在积极讨论当中，后续可能随时有所更改。</p><p></p><p></p><h5>参考链接：</h5><p></p><p><a href=\"https://bun.sh/blog/bun-bundler\">https://bun.sh/blog/bun-bundler</a>\"</p><p></p><p></p><h5>相关阅读：</h5><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MzUxMzcxMzE5Ng==&amp;mid=2247516386&amp;idx=1&amp;sn=94bed4b16790a46359e19cf8c759949c&amp;chksm=f95235a1ce25bcb7531410a4fa25f0ab3e6de659d6189fb765a4de40eb2faa009a438824edbb&amp;scene=27#wechat_redirect\">Bun&nbsp;会是&nbsp;Webpack&nbsp;之后的下一件大事吗？</a>\"</p><p><a href=\"https://www.infoq.cn/article/m48tvaz8w2BbblIQKZZF\">比 Node.js 快三倍，新 JavaScript 运行时&nbsp;Bun&nbsp;火了</a>\"</p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MzUxMzcxMzE5Ng==&amp;mid=2247516765&amp;idx=1&amp;sn=b899b050ea9125222ed283bbe76acc85&amp;chksm=f952371ece25be08bcf259c6cd8a1a9fbd6fe5b5f75e9c9512f1f75799adacbc046aebdeb741&amp;scene=27#wechat_redirect\">亲身试用新&nbsp;JS&nbsp;运行时&nbsp;Bun&nbsp;后，我觉得未来可期</a>\"</p><p><a href=\"https://xie.infoq.cn/article/c03cd143a6604ee58b0d8cce4\">疑为针对最近大火的“Bun”</a>\"</p></code></p>",
    "publish_time": "2023-05-30 10:42:12",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "直面挑战，如何应对开源社区中的恶意行为",
    "url": "https://www.infoq.cn/article/SRHsToJALgxKhCMlhm5h",
    "summary": "<p>开源维护者经常遇到的三种恶意行为分别为得寸进尺、人们随意发泄的挫败感和直接的攻击。面对这种行为，厚颜以对和熟视无睹都会导致愤怒和伤感情绪的负面循环。相反，我们应该指出这种行为，并提醒人们，开源意味着协作和配合。</p><p></p><p>Gina Häußge在<a href=\"https://www.oop-konferenz.de/\">OOP 2023 Digital上</a>\"谈到了作为开源维护者如何处理发起恶意行为的人。</p><p></p><p>Gina Häußge提到，维护者经常会面临三种恶意行为。最常见的一种就是得寸进尺。有不少用户认为，由于你已经给了他们一些东西，所以你亏欠他们得更多，当你没有满足他们的要求时，他们就会变得极具攻击性。</p><p></p><p>Gina Häußge说，还有一些人因为某些事情没有按照他们期望的方式进行而发泄挫败感，在这个过程中会变得非常粗暴。</p><p></p><p>第三种恶意行为是直接进行攻击，主要来自那些觉得自己的权利没有得到满足的人，或者无法处理其挫败感的人，有时候会非常恶毒，Gina Häußge解释到：</p><p></p><p></p><blockquote>这已经从辱骂升级到了建议直接结束我的生命。</blockquote><p></p><p></p><p>Häußge提到，面对这些恶意行为，她曾经尝试厚颜以对和熟视无睹。她认为，对这些行为大动干戈是她自己的问题。事实证明，她试图忽视人性和压力反应周期，Häußge这样解释到：</p><p></p><p></p><blockquote>试图无视这些事情只会让它们在我的脑海里无休无止的盘旋，经常持续好几天，甚至几周的时间，这使得我变得越来越愤怒，或越来越伤感。而这反过来又影响了我的沟通方式，往往只会使事情进一步升级，或造成其他方面的问题。</blockquote><p></p><p></p><p>Häußge提到，当面对得寸进尺或发泄行为时，她经常提醒人们注意工作中的实际情况。她说，“开源意味着协作和配合，而不是要求”。如果人们希望看到某些东西变成现实，那么就应该帮助完成它，通过代码，或者像文档和缺陷分析这样的东西：</p><p></p><p></p><blockquote>任何不需要我自己做的事情都意味着我会有更多的时间用于编码工作，以解决其他人的问题。</blockquote><p></p><p></p><p>Häußge说，这不应该只落在维护者身上。我们都可以在看到恶意行为时将其识别出来，并公之于众。她说，我们不应该让维护者不断捍卫自己的底线，或默默忍受虐待。</p><p></p><p>Häußge提到，我们也要经常照照镜子，反思自己，确保不要成为攻击者：</p><p></p><p></p><blockquote>在任何时候，都要记住站在别人的角度思考一下。</blockquote><p></p><p></p><p>InfoQ就针对开源维护者的恶意行为采访了<a href=\"https://www.linkedin.com/in/ginahaeussge/\">Gina Häußge</a>\"。</p><p></p><p>InfoQ：据你观察，恶意行为对维护者和OSS社区有什么影响？</p><p></p><p>Gina Häußge：多年来，我和很多OSS的维护者都有过交流，大家的普遍共识也反映了我自己的经历：这些经历会毁掉你一整天，毁掉你整整一周，有时会让你怀疑自己为何要继续维护这样一个项目。这肯定会导致维护者的倦怠，从而给整个项目带来风险。这是一种极其痛苦的体验。如果不加以制止，它们会危害整个社区。</p><p></p><p>InfoQ：你是如何学会应对这种恶意行为的？</p><p></p><p>Gina Häußge：解决压力反应循环的方法是体育运动。我的办公室里有一个沙袋，即便只运动30秒钟，也能让我重新活过来！这向我的大脑发出信号，表明我已经认识到了威胁，并且正在做一些事情来对付它，从而完成压力反应循环。一旦做到这一点，我就再次掌控了局面，可以采取下一步措施了。</p><p>如果遇到粗鲁的攻击，我就会明确表示，他们刚刚表现出来的行为是无法容忍的。多年来，这让我得到了很多的道歉，但有时也会导致事态进一步升级。在这种情况下，我会请他们离开，如果迫不得已，我会封掉他们。</p><p></p><p>InfoQ：在开源项目中，我们可以采取何种措施来应对恶意行为？</p><p></p><p>Gina Häußge：在开源项目中，有一个普遍的说法，作为维护者，你要脸皮够厚，无视那些讨厌的人。如果你做不到这一点，就根本无法胜任这项工作。</p><p></p><p>我不同意这种观点。这种恶意行为的不断冲击要么让你崩溃，要么让你变成一个更糟糕的人，而这两者都不应该是维护OSS所必须要承受的。请坚守你的底线和项目的行为准则（CoC，code of conduct），并要求得到人道的待遇。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/05/open-source-toxic-behavior/\">How Open-Source Maintainers Can Deal with Toxic Behavior</a>\"</p>",
    "publish_time": "2023-05-30 10:54:30",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何避免写重复代码：善用抽象和组合",
    "url": "https://www.infoq.cn/article/a15e5fef95aa12830004f42ac",
    "summary": "<p>作者：何品</p><p></p><p></p><blockquote>通过抽象和组合，我们可以编写出更加简洁、易于理解和稳定的代码。类似于金字塔的建筑过程，我们总是可以在一层抽象之上再叠加一层，从而达到自己的目的。但是在日常的开发工作中，我们如何进行实践呢？本文将以笔者在Akka项目中的一段社区贡献作为引子分享笔者的一点心得。</blockquote><p></p><p></p><p></p><h1>一、场景</h1><p></p><p></p><p>通常，为了简化我们对数据流的处理，我们可能会使用Java8中首次引入的Stream、或者是Kotlin、Scala等编程语言中提供的更加丰富的集合库，亦或者使用反应式流的相关三方库来简化工作。虽然这些类库已经提供了丰富的操作符，但是我们依然会在工作中遇到一些未提供合适操作符的场景。比如：</p><p></p><p>在直播场景下，需要对某些类型的消息进行缓冲和聚合，一段时间内的多个点赞合并为1个点赞，并且在处理了N个消息的时候进行整体发送，保障整体的扩散量级维持在一个平稳的水平。在IOT场景中，接收来自终端设备上报的数据，并返回当前的数据和前值，或者最近3个值，从而计算其中的变化趋势。此时我们可能会使用反应式流库中提供的：zipWithNext、zipWithPrevious、zipWithPreviousAndNext，或者是sliding。在建立一个聊天室的时候，如果用户输入bye，则让用户断开连接，离开聊天室，那么这个时候我们可能会使用takeWhile。假设我们有一组SQL，我们需要按照顺序执行，并合并他们的结果，并在处理完成后关闭对应的数据库连接，这时我们可能会用mapWithResource，using（资源安全）。当处理文件、写入数据库等使用资源的时候，我们需要打开一个文件或获取一个数据库连接，将数据写入，然后在处理完成后关闭对应的资源，这时我们可能会使用foldResource（资源安全）。假设需要对数据进行分批，每3个元素一批，进行打包，这个时候我们可能会使用&nbsp;batch(3)。假设我们需要将元素和每个元素的下标结合在一起，这个时候我们可能需要使用&nbsp;zipWithIndex。假设我们需要缓存元素，并在指定条件满足前一直缓存，我们可能需要&nbsp;bufferUntil(predicate)、bufferWhile(predicate)。假设我们需要缓存元素，直到数据变更，把相同项合并在一起，我们可能需要&nbsp;bufferUtilChanged。假设我们需要对所有的元素进行去重，或者去掉连续的重复元素，我们可能会需要用到distinct、distinctUntilChanged。假设我们只需要返回前N个元素，我们可能需要使用limit(N)、take(N)，或者按照条件takeWhile、takeUntil。假设我们需要跳过前N个元素，我们可能需要使用skip(N)、drop(N)，或者按照条件dropWhile、dropUntil。……</p><p></p><p>我们可以看到，上面这些操作符，每个都拥有具体的语义，虽然看起来只是一个简单的方法，但是如果需要我们完全自主实现，也有不小的难度，比如zipWithNext、zipWithPrevious、zipWithPreviousAndNext在Reactor-core目前的发行版本中就没有直接提供，而和资源相关的，Reactor-core中则只有一个using。</p><p></p><p>下面我们思考一下如何实现这些操作符。</p><p></p><p></p><h1>二、分析</h1><p></p><p></p><p>作为程序员，第一件事情，肯定就是Ctrl+C ，第二件事就是Ctrl+V，第三件事就是Commit&amp;Push。然而，事情并没有这么简单。</p><p></p><p>难点有：</p><p></p><p>反应式流操作符需要完整实现反应式流的规范、并通过默认的测试套件的验证。操作符需要尽可能的抽象和可组合。无论是单线程还是并发场景下都拥有正确的行为和语义、并有完整单元测试覆盖。操作符的实现需要尽可能的具备最高效的性能。</p><p>﻿</p><p>比如，以zipWithIndex举例，在Reactor-core中有FluxIndexFuseable（370行代码）和&nbsp;FluxIndex（296行代码）两个实现。而且清晰的处理了各种情况。而其他操作符也有类似：release 3.4.23</p><p></p><p>FluxBuffer —— 575行代码FluxBufferPredicate —— 464 行代码FluxDistinct —— 609行代码FluxDistinctFuseable —— 70行代码FluxDistinctUntilChanged —— 337 行代码FluxUsing —— 583 行代码</p><p></p><p>如果要实现一个zipWithNext自定义操作符 ，应该也有接近的工作量。这样的工作强度，个人认为无论是在代码审查还是后期的维护都是一个大问题。</p><p></p><p>为此，我认为需要一个新的抽象，来对上面的这些操作进行进一步的抽象。然后再这个之上，通过使用和组合其他的操作，从而更简单的实现自定义操作符。</p><p></p><p></p><h1>三、解法</h1><p></p><p></p><p>所有上面的这些都可以抽象为：</p><p></p><p>带有状态，且线程安全；状态可变，且根据状态的不同，对输入应用不同的操作，产生不同的值；可以提前结束、或者对不满足条件的值进行选择性丢弃；有完整的生命周期；在结束时可以根据内部状态而产生可选的值，而不会丢失内部状态。</p><p>﻿</p><p>经过分析，这里可以表达为 :&nbsp;状态 + 输入 -(应用行为)-&gt; 新的状态 + 输出，这样再加上onCraete、onComplete生命周期函数，就可以完整表达。而提前结束等行为，则可以通过组合takeWhile实现。我们将方法命名为：statefulMap，声明如下：</p><p></p><p><code lang=\"null\">public&nbsp;<s>&nbsp;statefulMap(\n    java.util.function.Supplier<s> create,\n    java.util.function.BiFunction<s><s>&gt; f,\n    java.util.function.Function<s>&gt; onComplete){...}\n</s></code></p><p></p><p><s>让我们看一下如何通过这个方法来实现zipWithIndex。</s></p><p></p><p></p><h2><s>3.1 实现zipWithIndex (indexed)</s></h2><p></p><p></p><p><s><img src=\"https://static001.geekbang.org/infoq/6e/6eb77e47448a413f1f2ac53246fdcf69.png\" /></s></p><p></p><p><s><code lang=\"null\">Source.from(Arrays.asList(\"A\",&nbsp;\"B\",&nbsp;\"C\",&nbsp;\"D\"))\n​\n    .statefulMap(\n        () -&gt; 0L,\n        (index, element) -&gt; Pair.create(index + 1, Pair.create(element, index)),\n        indexOnComplete -&gt; Optional.empty())\n​\n​\n    .runForeach(System.out::println, system);\n// prints\n// Pair(A,0)\n// Pair(B,1)\n// Pair(C,2)\n// Pair(D,3)\n</code></s></p><p></p><p><s>也可以实现zipWithNext、zipWithPreviousAndNext。然后下面我们再看看如何实现较为复杂的bufferUntilChanged。</s></p><p></p><p></p><h2><s>3.2 实现bufferUntilChanged</s></h2><p></p><p></p><p><s><img src=\"https://static001.geekbang.org/infoq/96/96f8eafaee6a73970a4be6760563d4c5.png\" /></s></p><p></p><p><s><code lang=\"null\">Source.from(Arrays.asList(\"A\", \"B\", \"B\", \"C\", \"C\", \"C\", \"D\"))\n​\n​\n    .statefulMap(\n        () -&gt; (List) new LinkedList(),\n        (buffer, element) -&gt; {\n          if (buffer.size() &gt; 0 &amp;&amp; (!buffer.get(0).equals(element))) {\n            return Pair.create(\n                new LinkedList&lt;&gt;(Collections.singletonList(element)),\n                Collections.unmodifiableList(buffer));\n          } else {\n            buffer.add(element);\n            return Pair.create(buffer, Collections.emptyList());\n          }\n        },\n        Optional::ofNullable)\n    .filterNot(List::isEmpty)\n​\n    .runForeach(System.out::println, system);\n// prints\n// [A]\n// [B, B]\n// [C, C, C]\n// [D]\n</code></s></p><p></p><p></p><h2><s>3.3 实现distinctUntilChanged</s></h2><p></p><p></p><p><s><img src=\"https://static001.geekbang.org/infoq/08/08fe8f872c9da2e5de32ca06fb78104f.png\" /></s></p><p></p><p><s><code lang=\"null\">Source.from(Arrays.asList(\"A\", \"B\", \"B\", \"C\", \"C\", \"C\", \"D\"))\n​\n​\n    .statefulMap(\n        Optional::empty,\n        (lastElement, element) -&gt; {\n          if (lastElement.isPresent() &amp;&amp; lastElement.get().equals(element)) {\n            return Pair.create(lastElement, Optional.empty());\n          } else {\n            return Pair.create(Optional.of(element), Optional.of(element));\n          }\n        },\n        listOnComplete -&gt; Optional.empty())\n    .via(Flow.flattenOptional())\n​\n​\n    .runForeach(System.out::println, system);\n// prints\n// A\n// B\n// C\n// D\n</code></s></p><p></p><p></p><h2><s>3.4 实现buffer</s></h2><p></p><p></p><p><s><img src=\"https://static001.geekbang.org/infoq/12/122958d8d380a4e1361c9f781a651c29.png\" /></s></p><p></p><p><s><code lang=\"null\">Source.fromJavaStream(() -&gt; IntStream.rangeClosed(1, 10))\n​\n​\n    .statefulMap(\n        () -&gt; new ArrayList(3),\n        (list, element) -&gt; {\n          list.add(element);\n          if (list.size() == 3) {\n            return Pair.create(new ArrayList(3), Collections.unmodifiableList(list));\n          } else {\n            return Pair.create(list, Collections.emptyList());\n          }\n        },\n        listOnComplete -&gt; Optional.ofNullable(listOnComplete))\n    .filterNot(List::isEmpty)\n​\n​\n    .runForeach(System.out::println, system);\n// prints\nList(1, 2, 3)\nList(4, 5, 6)\nList(7, 8, 9)\nList(10)\n</code></s></p><p></p><p></p><h1><s>四、更复杂的例子：处理资源</s></h1><p></p><p></p><p><s>在前面看了如何实现zipWithIndex&nbsp;、bufferUntilChanged之后，让我们进一步看看如何优雅和安全地处理资源。在任何的编程语言和框架中，资源的处理都是非常基础但是又很棘手的事项。在Java 7中首次引入了try-with-resources语法，对资源处理进行了一定程度的简化，而在反应式流中，我们又应该如何的操作呢？这里我们可以分为两种情况：</s></p><p></p><p><s>1）针对流中的每个元素都创建一个新的资源，使用这个资源，关闭这个资源。</s></p><p></p><p><s>2）针对整个流创建一个资源，并在处理流中的每个元素时使用这个资源，并在流的生命周期结束后，关闭这个资源。</s></p><p><s>﻿</s></p><p><s>因为资源通常开销较大且需要妥善管理，所以在开发过程中，我们更容易遇到的是第二种情况，即资源的创建和销毁和流的生命周期进行了绑定。反应式流中的资源管理，还有更多的细节需要考虑：</s></p><p></p><p><s>资源的初始化和关闭需要支持并发安全；反应式流可以被多次物化，被多个下游订阅者订阅和处理，并且以任意的顺序进行取消订阅，需要在各种情况下（上游完成、下游取消、处理异常等）等情况下妥善的创建和销毁资源。在流生命周期的各个阶段安全地创建和销毁资源，比如：即使在创建资源或者销毁资源的时触发了异常，也不会对同一个资源关闭多次。支持异步从而提高资源使用的效率。感知流的生命周期，支持在关闭资源时提供可选的值给到下游以标识流的结束，比如处理文件时，使用一个特殊的标识符标识文件的结尾。</s></p><p><s>﻿</s></p><p><s>综合上面的这些诉求，对应的代码就会变得很复杂，大家可以用一点时间思考：如果是自己独立实现类似的操作需要做出那些努力呢？在现实的开发过程中，我们遇到的诉求很多时候并非一起提出，而时随着迭代接踵而至，那么如果当初的代码编写的不是很易于扩展，拥有良好的测试，则可能按下葫芦浮起瓢。</s></p><p><s>﻿</s></p><p><s>比如在reactor-core中就有如下的using操作符：</s></p><p></p><p><s><code lang=\"null\">&nbsp;&nbsp;public&nbsp;static&nbsp;&nbsp;Mono&nbsp;using(\n    Callable<!--? extends D--> resourceSupplier,\n    Function<!--? super D, ? extends Mono<? extends T-->&gt; sourceSupplier,\n    Consumer<!--? super D--> resourceCleanup) {...}\n</code></s></p><p></p><p><s>resourceSupplier针对每个订阅者，创建一个资源。sourceSupplier结合创建的资源，产生对应的元素。resourceCleanup取消订阅或者流完成时，清理对应的资源。</s></p><p></p><p><s>﻿在reactor-core中，对应的底层实现为MonoUsing共360行代码，而要实现我们想要的逻辑，我们还需要和另一个流进行合并，即这里的using类似于unfoldResource。那么有没有可能使用更加简单的方案来进行实现呢？答案是肯定的，和前面的几个操作符一样，我们可以使用statefulMap来实现mapWithResource，思维过程如下：</s></p><p></p><p><s>using/mapWithResource的生命周期管理和statefulMap的create和&nbsp;onComplete方法对应，针对资源，onComplete方法可以被命名为更加贴切的release/close/cleanUp。在流中使用的资源，我们可以认为是一个状态，只不过这个状态在流的整个生命周期中不再变化，一直是create方法中返回的Resource。在关闭资源时，我们可以通过返回一个Optional来返回一个可选的值。对并发资源的异步处理，则可以通过返回一个CompletionStage而非Out来实现，在using方法中，我们返回的是一个Mono。</s></p><p></p><p><s>经过上面的思维过程，我们不难得出这个流上的方法的声明可以为：</s></p><p></p><p><s><code lang=\"null\">public&nbsp;&nbsp;mapWithResource(\n  Supplier<!--? extends R--> create,\n  BiFunction<!--? super R, ? super In, ? extends Out--> function,\n  Function<!--? super R, ? extends Optional<? extends Out--> close) {...}\n</code></s></p><p></p><p><s>resourceSupplier针对每个订阅者/每次物化，创建一个资源。function使用create中创建的资源处理流中的每个元素。close在流关闭的同时关闭资源，并再向下游提供一个可选的值。</s></p><p></p><p><s>﻿具体的的实现这里留空，感兴趣的小伙伴可以结合前面的例子进行实现。下面我们看一下如何使用这个mapWithResource方法，从而加深大家的理解。</s></p><p></p><p></p><h2><s>4.1 使用mapWithResource</s></h2><p></p><p></p><p><s>假设我们有一组SQL需要进行处理，我们需要从数据库中的多个表中查询对应的结果，并将最终结果进行合并和输出到控制台。在mapWithResource的帮助下，我们可以极大的简化我们的代码：</s></p><p></p><p><s><code lang=\"null\">Source.from(\n            Arrays.asList(\n                \"SELECT * FROM shop ORDER BY article-0000 order by gmtModified desc limit 100;\",\n                \"SELECT * FROM shop ORDER BY article-0001 order by gmtModified desc limit 100;\"))\n        .mapWithResource(\n            () -&gt; dbDriver.create(url, userName, password),\n            (connection, query) -&gt; db.doQuery(connection, query).toList(),\n            connection -&gt; {\n              connection.close();\n              return Optional.empty();\n            })\n        .mapConcat(elems -&gt; elems)\n        .runForeach(System.out::println, system);\n</code></s></p><p></p><p><s>在上面的例子中：我们有一组预先定义好的SQL，分别从多个表中读取最新的100条数据，通过使用mapWithResource，我们优雅地为每个流创建了db相关的连接，并进行对应的查询操作，并合并查询结果，在流处理完成后，关闭对应的资源。上面的代码通过复用我们前面编写的mapWithResource将复杂资源和生命周期管理进行了简化，作为对比，大家可以思考一下如果我们不使用已有抽象所需要付出的努力。</s></p><p></p><p></p><h1><s>五、总结</s></h1><p></p><p></p><p><s>在上面的例子中，我们通过statefulMap以及和其他的操作符相互组合，实现了很多和状态、生命周期相关的操作符，而代码量则大大减少。基于一个经过考验的操作符来编写自定义操作符，也能进一步降低出错的概率，以及代码审查的难度，而相关的操作符都是通过一个底层的statefulMap来实现。</s></p><p></p><p><s>映射到我们的工作中则是尽可能地抽象、提炼，对系统的核心模型、核心功能进行打磨，从而每个应用都有一个精巧的内核，并和其他的应用构成丰富的生态，而非上来就复制粘贴重复造轮子。</s></p><p></p><p><s>虽然有时我们可能没有足够的时间来进一步抽象，而是业务先行。但是我依然建议，在后续的实践中，进行不断回顾和提炼，在保障系统稳定可靠、在有测试手段保障的情况下，进行逐步的重构，使得系统更加容易理解、维护和稳固。</s></p><p></p><p><s>笔者相信：磨刀不误砍柴工，在设计、方案review、测试和不断重构、精炼的过程中所花费的时间，一定会在将来多倍的回报。</s></p>",
    "publish_time": "2023-05-30 10:59:47",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "国产替代正当时：我们是如何迁移到国产操作系统的？",
    "url": "https://www.infoq.cn/article/9eOei85d9GIO8lW0JPwQ",
    "summary": "<p>过去一年，国产操作系统在技术、社区和商业化方面均取得了快速发展：技术方面，更多企业及研究机构投入到自研系统项目中，原创组件和技术如雨后春笋般涌现；社区方面，头部社区蓬勃发展，新的社区不断出现；商业化方面，OSV 都有较为明显的业绩增长。国产操作系统的发展正加速驶入快车道，与此同时，不少企业也开始向国产操作系统迁移。</p><p>&nbsp;</p><p>那么，如何才能更好地迁移到国产操作系统？操作系统迁移会对软件栈带来哪些影响？企业开发、运维人员如何拥抱变化？近日，InfoQ《极客有约》邀请到了政采云公司运维支撑负责人朱海峰老师，为大家分享政采云公司的国产操作系统迁移实战经验。</p><p>&nbsp;</p><p>以下为访谈实录，完整视频参看：<a href=\"https://www.infoq.cn/video/KZ6bJkiHlfmfcCsMBibS\">https://www.infoq.cn/video/KZ6bJkiHlfmfcCsMBibS</a>\"</p><p></p><p>姜雨生：欢迎朱海峰老师做客InfoQ《极客有约》，首先，请您简单介绍一下政采云这家公司。</p><p>&nbsp;</p><p>朱海峰：<a href=\"https://www.infoq.cn/article/qfcz1fj9wvFvGidjpcho\">政采云</a>\"有限公司是一家提供购政企采购云服务生态的公司。旗下有两个核心产品，分别是政采云平台和乐采云平台。</p><p>&nbsp;</p><p>政采云平台是专门面向政府采购的平台，是顺应政府采购数字化改革要求和电商化采购趋势，在监管部门指导下搭建的集网上交易、网上监管和网上服务于一体，覆盖政府采购各领域、全流程、多用户的一站式云服务平台。</p><p>&nbsp;</p><p>乐采云平台是一个政企采购开放平台，两者面向不同的用户群体。乐采云平台是为适应数字化采购的新形势，由政采云有限公司为主建设、独立运营，并将在政府采购领域多年积累的技术能力、运营经验和资源优势等引入到企业采购等非政府采购领域，是为广大企业、村社组织等单位用户搭建的一体化、数智化采购云服务平台。</p><p>&nbsp;</p><p>目前，政采云平台已成为政府采购领域中服务范围最广、用户量最多、交易最活跃的全国性区域一体化云平台。</p><p>&nbsp;</p><p>姜雨生：在提到云时，我们更多地关注云PaaS方面的能力，尤其是在机器上的搭建。咱们的产品是SaaS软件产品，还是同时包含了管理机器和集群能力的VM等云平台方面的产品呢？</p><p>&nbsp;</p><p>朱海峰：政采云平台是一个以SaaS产品为主的平台，主要是提供SaaS服务。此外，平台还在构建生态应用的功能，支持采购服务相关的第三方ISV进行入驻等方面提供应用管理的功能。</p><p>&nbsp;</p><p>姜雨生：在过去几年中，我们将企业的操作系统迁移到国产操作系统上，并做了一系列与操作系统迁移相关的工作。请您简单介绍一下所做的工作以及整个迁移过程。</p><p>&nbsp;</p><p>朱海峰：在2020年12月，CentOS社区宣布在2021年和2024年6月底停止为CentOS服务器操作系统8和7提供服务，这一事件被视为一个显著的触发事件。国家的“十四五”数字经济发展规划强调数字基础设施建设，其中特别强调了云计算、5G和物联网等基础领域的发展。这些规划推动了计算产业的变革。</p><p>&nbsp;</p><p>在这种背景下，政采云技术团队意识到CentOS停服可能对我们产生影响，并且国家也在强调数字基础设施建设。因此，我们发起了对国产操作系统的调研工作，该调研工作大约从2021年开始进行。</p><p>&nbsp;</p><p>在CentOS宣布停服后，一些国产系统如龙蜥和欧拉也提供了替代方案。我们主要使用阿里云作为云资源，并注意到了龙蜥开源社区的活跃度，因此选择了龙蜥操作系统。</p><p>&nbsp;</p><p>政采云平台是一个提供SaaS服务的云平台。我们支持不同用户以租户的形式入驻云服务，同时也支持政府行业、金融行业和企业等不同领域的本地化部署需求。云上我们主要采用<a href=\"https://www.infoq.cn/article/15ZhicNUoFx2bXzgy3AZ\">龙蜥操作系统</a>\"，因为我们观察到龙蜥社区非常活跃，并且它兼容我们之前使用的CentOS生态系统。本地化部署上，我们适配了麒麟、统信和红旗等操作系统，根据客户采购的操作系统发行版进行适配。我们的业务包括各地政府采购网搭建，以及电子卖场、项目采购等交易平台的建设，这些业务系统都进行了国产化适配的工作。</p><p>&nbsp;</p><p>姜雨生：我们迁移到龙蜥操作系统，整个迁移过程大概是什么样的？大概多久完成了迁移工作？</p><p>&nbsp;</p><p>朱海峰：在迁移龙蜥操作系统之前，我们主要使用的是CentOS 7.4版本。当时龙蜥社区是一个非常活跃的开源社区，它完全兼容CentOS生态,&nbsp;并在性能、安全方面也有所改进，因此我们选择了龙蜥操作系统。</p><p>&nbsp;</p><p>在选择操作系统之后，我们主要有两个步骤。首先是迁移评估，需要评估新系统是否兼容现有软件。接下来是迁移实施。</p><p>&nbsp;</p><p>在评估阶段，我们对操作系统层面和业务应用层面进行了整体评估。在操作系统层面，主要关注内核软件包、系统配置、软件服务等方面的兼容性；而在业务层面，我们主要是Java应用，需要检查是否存在依赖系统层面不兼容的配置和软件，比如字体，或者基础软件服务等。龙蜥在操作系统层面提供了一些很好的工具，可以在升级之前比较系统软件包的差异。在评估阶段，我们做了一些基准测试，如磁盘、网络和中间件方面的测试，我们发现龙蜥操作系统与当前的CentOS性能数据保持一致。对于应用层面，我们还进行了关键业务的性能测试和功能测试，以确保功能一切正常。</p><p>&nbsp;</p><p>综上所述，迁移评估的结果是，龙蜥操作系统在软件版本上与CentOS生态完全兼容，性能数据基本一致，并且对业务层面的影响较小。</p><p>&nbsp;</p><p>在实施阶段，有两种方式可选：一种是原地升级，在原有机器上进行版本更新；另一种是新节点的滚动替换。对于原地升级，龙蜥提供了相应的工具，可以直接从CentOS切换到龙蜥操作系统。由于政采云平台是基于Kubernetes部署的，我们大部分业务采用了替换节点的方式进行迁移，因Kubernetes对于节点的增减是很方便的，只有一小部分业务进行了原地升级。</p><p>&nbsp;</p><p>整个版本升级评估大约两周的时间完成，后续的实施过程中滚动升级，随着旧节点下线和新节点增加，整个实施过程会相对拉长，这块对业务的影响较小。</p><p>&nbsp;</p><p>姜雨生：政采云平台原应用系统所需软件包和龙蜥操作系统中软件包的兼容性和依赖包存在差异，最后我们是如何解决这一问题的？在迁移的过程中还遇到了哪些技术挑战？</p><p>&nbsp;</p><p>朱海峰：在实际操作中存在一些差异，因为我们当时使用的是CentOS 7，而龙蜥操作系统只支持CentOS 8，所以这两个大版本之间有一些功能变更，比如安装包的工具不同。我们通过比较软件包找到了这些差异，并判断不同的系统依赖是否满足我们的需求。实际上，大部分系统层的依赖都是向前兼容的，所以升级对我们的影响并不大，需要做的改动也较小。</p><p>&nbsp;</p><p>另外，在软件安装方面，我们制定了标准规范，使用自建的安装包源，并采用自定义安装包的形式进行安装，尽量避免对系统安装的依赖。对于大部分服务，如NGINX、Elasticsearch、RocketMQ和Zookeeper等，我们通过容器化实现了基础容器镜像，镜像中包含了服务运行环境，这样可以实现在一次构建中多操作系统的部署。</p><p>&nbsp;</p><p>姜雨生：有观众提问，想了解下政采云技术团队在迁移过程中的监控系统以及与稳定性、性能和安全性相关的实施过程。</p><p>&nbsp;</p><p>朱海峰：在迁移过程中，我们对基础设施、中间件和应用层进行了性能测试，非常关注性能数据。同时我们也重视系统调优方面和安全层面的工作。我们根据之前的版本使用了一些固定的参数进行系统调优，而在迁移到新的操作系统时，我们会关注这些参数的适配性，并进行相应的调整。在监控和系统安全方面，我们在云上使用了一些安全产品，例如主机防护会进行巡检并提醒可能存在的差异以及潜在风险。我们还有专门的安全部门负责这些事情。此外，我们配置了稳定性相关的监控指标，通过监控面板和告警以保证变更不会对业务稳定性产生影响。</p><p>&nbsp;</p><p>姜雨生：政采云公司也有针对金融支撑服务和政务行业的项目，是否也进行了操作系统迁移？不同行业的国产化有哪些异同？您能分别介绍下当时的迁移情况吗？</p><p>&nbsp;</p><p>朱海峰：金融支撑服务和政府行业的项目对国产化操作系统有特定要求。在金融和政务领域，麒麟和统信等国产操作系统被广泛使用，而龙蜥操作系统或欧拉操作系统的使用较少。由于金融支撑服务的采购量相对较小，选择性也较为有限。他们可能只需考虑一款操作系统的迁移，比如银河麒麟或红旗操作系统，金融支撑服务对网络安全的要求更高一些,&nbsp;在进行操作系统迁移解决方案时，我们需要规划离线迁移方案，金融支撑服务对硬件和中间件的国产化要求不那么强烈，政务行业的情况有些不同，它们在操作系统选择方面可能有更多的选项，比如统信、银河麒麟等操作系统。但对硬件和中间件的国产化要求更为强烈，一般政务行业的国产化迁移会包括操作系统，CPU架构，甚至中间件的迁移。</p><p>&nbsp;</p><p>姜雨生：为了帮助企业更平滑地完成操作系统迁移，不少操作系统厂商都会提供对应的迁移工具，我们在迁移的过程中采用了哪些不错的迁移工具？有哪些迁移经验可以分享下吗？</p><p>&nbsp;</p><p>朱海峰：在龙蜥操作系统迁移过程中，我们进行了调研，并使用了一个叫作centos2anolis的工具。该工具直接支持原地升级，实际上它是通过操作系统本身的软件升级方式实现的。它预先进行了一些软件包的检查，非常方便且易于使用，可以直接支持操作系统原地升级。</p><p>&nbsp;</p><p>在本地化方面，我们使用了一个名为sealor的阿里开源kubernetes集群管理工具，它将Kubernetes以镜像的方式进行部署。我们也可以利用该工具进行节点的动态下线/上线，很方便的实现节点滚动升级。</p><p>&nbsp;</p><p>在此方面，我有几点经验分享：首先，在进行大型升级时，建议进行镜像备份或数据备份，因为升级过程中可能会遇到一些问题，需要有手段将系统恢复到升级之前的状态。其次，对于依赖的系统包问题，建议采用解耦的方式来解决，比如，可以通过容器化或自定义安装包的方式对服务运行时环境进行封装，对操作系统的依赖解耦掉。最后，在迁移过程中建议通过一些脚本比如ansible进行自动化，可以重复执行并自动化执行整个升级或迁移过程，从而最大限度地降低人力成本。</p><p>&nbsp;</p><p>姜雨生：在操作系统迁移过程中，包括日常开发工作，主要涉及到时间成本和人力成本。当我们为客户进行这种迁移工作时，通常的时间和人力成本是怎样的？对于私有化部署的客户来说，我们在迁移过程中除了提供相关的人力支持，客户可能还需要提供一些相关的业务人员支持。那么这方面的时间和人力成本大概是多少呢？</p><p>&nbsp;</p><p>朱海峰：在前期进行评估阶段时，需要业务人员的参与。然而，一旦方案成熟并开始实施阶段，就不需要业务人员参与了。我们可以通过自动化脚本来完成运维人员的工作，他们只需进行实施观察，并在需要时进行紧急操作。根据粗略估计的时间占比，业务人员的投入可能在前期较多，而后续则不需要投入。运维人员则需要全程投入，后期的投入可能会更多一些。因此，评估和实施的时间比例是1:1的关系。</p><p>&nbsp;</p><p>姜雨生：从运维的视角来看，操作系统的迁移会带来哪些变化？开发者如何才能更好地拥抱变化？</p><p>&nbsp;</p><p>朱海峰：操作系统的迁移对系统运维方面可能会涉及一些变化。例如，安装软件包、网络排查和性能排查工具等日常工作可能会有一些变化，尤其是包的安装方面可能会有较大的变更。此外，使用不同的操作系统发行版时，解决方案的制定需要考虑不同操作系统的兼容性，对运维工作本身会有一定影响。</p><p>&nbsp;</p><p>对于开发人员而言，他们应尽量减少对系统变化的感知度。一种方式是通过容器化，将应用程序的运行环境与宿主机操作系统解耦。另外，通过工程化理念将运维能力抽象为产品功能，使开发人员无需关心底层技术的变化。这样一来，开发人员对操作系统的变更的感知度就可以最小化。</p><p>&nbsp;</p><p>姜雨生：对于那些有操作系统迁移诉求，但还没进行迁移的企业，您会给他们提供哪些建议？</p><p>&nbsp;</p><p>朱海峰：对于一些客户而言，他们并未迁移到国产操作系统。原因之一是国产操作系统的成熟度尚不够，另外在进行本地化部署时依赖于客户的基础设施，比如客户并未购买国产操作系统，因此没有进行迁移，这取决于客户自身的技术规划。我们不主动建议客户进行国产化迁移，但我们具备国产化迁移的能力，会向客户提供这方面的解决方案的支持。</p><p>&nbsp;</p><p>姜雨生：对于那些未迁移的客户来说，如果面临版本停止服务的情况，那么未来会不会对他们造成严重影响呢？</p><p>&nbsp;</p><p>朱海峰：除了国产操作系统，他们可能也在使用一些其他的操作系统，例如Oracle&nbsp;Linux或其他开源的操作系统。对于使用CentOS操作系统，并且该停服对客户可能造成影响的，我们会提醒他们关注到这方面的问题，提早规划相关的迁移方案。然而，客户可能会坚持使用某类操作系统，并不愿意改变使用习惯，这会是一个挑战。但是随着国产操作系统的成熟和观念的变化，我相信会有一些转变发生。</p><p>&nbsp;</p><p>姜雨生：您之前提到了多款操作系统，在使用它们的过程中，针对它们的操作系统本身和生态建设，您有哪些建议吗？</p><p>&nbsp;</p><p>朱海峰：某些操作系统无法自行升级内核，并且它们的软件生态系统不够丰富。由于某些操作系统的兼容性问题，必须根据官方的介绍来进行版本升级或内核升级，如果它们没有提供支持，我们将无法进行相应的升级。</p><p>&nbsp;</p><p>目前很多社区都采用商业版和社区版相结合的发展模式。然而，一些操作系统的社区版并不活跃，这导致企业使用该操作系统的成本较高，需要购买商业版才能获得支持。如果使用社区版，可能会在面临一些问题的时候缺乏有效的支持。此外，目前的操作系统如欧拉和龙蜥等，与云服务提供商有一定的关联。比如，欧拉是华为云天然支持的操作系统，而龙蜥操作系统则是阿里云直接提供的。一个优秀的国产操作系统应该与主流云服务提供商都有合作，无论是在哪个云上，都可以方便的使用他们的操作系统。</p><p>&nbsp;</p><p>姜雨生：国产化适配是一个系统性工程，实现国产化操作系统替换只是第一步，未来我们还会有哪些规划？会探索哪些新技术方向来解决我们和客户面临的主要产品问题？</p><p>&nbsp;</p><p>朱海峰：我们在规划国产化适配时，并不仅仅考虑操作系统，还包括硬件方面，如CPU架构的变更，目前国内一些公司，如华为，正在推广ARM架构的鲲鹏服务器；还包括了国产化的数据库、中间件替代方案。在整个平台中，国产化替代方案也有相应的规划，比如，我们要支持ARM架构的CPU，数据库的国产化支持，如达梦数据库等。</p><p>&nbsp;</p><p>在操作系统层面，运维会尽量减少对业务的影响，但在CPU架构，数据库层面的变化，业务的感知度会特别大，尤其是数据库方面，对业务的侵入性比较大，需要业务方面提供相应的支持，改造适配成本会比较高。</p><p>&nbsp;</p><p>作为运维支撑部门，我目前的主要关注点是政府采购平台的多云部署、运维和维护，技术侧主要关注多集群管理，集群弹性能力和云原生网关等。</p><p>&nbsp;</p><p>姜雨生：从您的部门角度来看，运维部会探索哪些方面的新技术呢？</p><p>&nbsp;</p><p>朱海峰：首先，我们需要基于现有技术来思考我们的技术发展方向。其次，我们需要明确这些技术实际上解决了哪些业务问题。在运维和技术保障方面，我们已经着手处理一些重要项目，例如可观测性平台。关于这些项目，您可以在InfoQ平台上找到相关文章，这些内容非常值得一读（延伸阅读：<a href=\"https://www.infoq.cn/article/cLOZHdYidBgziEl4ZaN6\">《云原生时代，如何建设稳定性可观测体系？》</a>\"）。</p><p>&nbsp;</p><p>姜雨生：有观众提问，可以简单介绍下如何建立可观测体系吗？</p><p>&nbsp;</p><p>朱海峰：我们以前主要是基于日志、指标、链路等指标来构建整个监控体系，这三类数据是分别处理的。我们的运维开发部门基于Open Telemetry开发了的整体可观测性系统。该系统能够收集上述数据并建立关联。当收到指标警告时，该指标可以关联链路和日志数据，从而是告警接受者全面的了解问题。</p><p>&nbsp;</p><p>此外，我们的工程师还在使用eBPF技术进行更精细的数据收集，尽量减少对业务层的依赖。在这方面，社区里比较热门的项目是DeepFlow，我们团队也在与DeepFlow协同合作，收集不同类型的数据，通过数据计算关联，最终形成稳定性大盘。此外，我们希望能够把监控数据基于算法与模型进行计算，提供智能化的监控解决方案。</p><p>&nbsp;</p><p></p><h4>嘉宾介绍</h4><p></p><p>&nbsp;</p><p>特邀主持：</p><p>&nbsp;</p><p>姜雨生，微软软件工程师，负责微软资讯业务与 GPT 集成，曾负责微软广告团队基础设施搭建与维护工作。</p><p>&nbsp;</p><p>嘉宾：</p><p>&nbsp;</p><p>朱海峰，政采云有限公司运维支撑负责人，关注混合云架构下的云原生技术场景，比如多集群管理、弹性能力、云原生网关等。</p>",
    "publish_time": "2023-05-30 11:30:28",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "测试工程师为什么要关注研发效能？",
    "url": "https://www.infoq.cn/article/uYHCyCHU27weYcA94azl",
    "summary": "<p></p><blockquote>研发效能中的“研发”，指的是广义的研发团队，包含开发、测试、和研发团队内部的产品经理。测试工程师身处其中，作为研发团队的一员，对于整体的效能如何提升也应该了然于胸。这篇文章，我们详细聊聊为什么测试工程师需要关注研发效能。本文经公众号<a href=\"\">思码逸研发效能</a>\"授权转载。</blockquote><p></p><p></p><p></p><h2>测试团队的价值困境</h2><p></p><p></p><p>在效能改进方面，测试团队的困境往往是不能很好地自证价值。单纯从本位主义出发、只考虑测试团队自身的效能目标，不一定能给研发团队带来整体效益。</p><p></p><p>比如，有些测试团队会制定缺陷数量的目标，如果仅仅从测试团队自身角度来考量，这个目标是能够产生一定效用的。可是站在整个团队角度思考，却会产生副作用，这种情况想必很多同行遇到过。</p><p></p><p>还有一些团队致力于提升测试效率，着手点就是通过大规模开展自动化测试来提升自动化测试比例（自动化测试用例数量/自动化测试用例数量+手工测试用例数量）。通过自动化测试，让机器自动执行过往需要手动执行的重复工作用，理想状态下是提升效率的最佳手段。然而，实际效果有时却没那么理想，当研发总监提出这样的质疑：“自动化测试比例这么高，为什么测试周期没有缩短，测试人员没有减少呢？”，测试团队只能无言以对。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7e/7e07fc2fe0a94b94738c108f4163910b.jpeg\" /></p><p>图 1-自动化测试的效能</p><p></p><p>而研发效能领域，正是测试开发团队突破瓶颈的最优选项。</p><p></p><p>和朋友聊天，发现关注和从事研发效能领域工作的有几波人，包括敏捷教练、项目经理、质量和测试开发团队、研发 Leader 和架构师，大家的视角略有差异，同时也存在相似性。</p><p></p><p>引用京东技术专家新栋老师分享过的 PPT 的图片来说明：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1b/1b01515d1f40cc6b71ec5ac253efe960.jpeg\" /></p><p>图2-研发效能提升“金三角”（引自：研发效能提升三部曲-王新栋）</p><p></p><p>这些关注研发效能的角色当中，架构师和测试开发团队侧重工程领域，也就是图中的流程机制和基础设施两部分。随着这几年测试团队转型的潮流，很多测试开发团队负责的领域越来越广，从质量内建、效能工具、SRE&nbsp;和流程改进等方面都有涉猎，正好切合了研发效能的横跨全生命周期的特点。而测试开发团队在基础设施和架构层面的弱势，可以通过和架构师团队合作，从而达成结果。</p><p></p><h2>提升测试效能就是为研发效能做贡献</h2><p></p><p></p><p>现在无论是互联网企业，还是传统 IT 企业，“唯快不破”的理念已经深入人心。而在整个产品交付过程中，测试阶段的时间占比和人力投入都是不容小视的，这种情况下，如何提升测试效能就成了一个关键的问题，提升测试效能不仅仅给测试团队带来收益，还能影响整个研发团队的价值交付效率。</p><p>DevOps 的基础实践之一就是通过部署流水线打通整个研发过程，并且通过各个阶段的自动化，实现交付效率的提升。其中自动化技术实践包含自动代码扫描、自动化测试和自动化环境部署等，都是测试开发团队持续关注且擅长的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f2/f23c8032ca10c7b387faab1c5beaf43c.jpeg\" /></p><p>图 3-自动化技术实践</p><p></p><p>提升测试效能可以从回归测试做起。在敏捷和 DevOps 的软件开发方法模式下，提倡把大需求进行拆分，把按季度/月交付的周期切分为两周一个迭代进行交付，从而提升研发团队的需求吞吐率。这给测试工作带来了新的挑战——如果不能精准定位测试范围，而选择每次迭代都进行全量的用例回归的话，其工作量是非常大的。</p><p></p><p>流量录制回放技术和测试精准化是业界常用的实践。通过流量录制回放来生成回归测试用例集，可以极大减少自动化用例编写和维护的时间成本。而测试精准化实践能够精准化匹配代码变更范围，从而推荐最小有效回归用例集，使回归测试执行效率达到最优。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9d/9d3d84afe5003c4b843dd85ecceb84ab.jpeg\" /></p><p>图 4-提升回归测试效率的技术手段</p><p></p><h2>质量内建是效能提升的关键实践</h2><p></p><p></p><p>有时候我们会把测试效率提升作为重点，其实质量内建同样是效能提升中不容忽视的关键实践之一。</p><p>质量是效能的一部分，我们应该从开始就认识到，效能包含但不等同于效率，质量同样非常重要。“质量是设计和构建出来的，不是测试出来的”的理念已经逐渐被大家所认识到。因此，在设计和开发阶段就需要引入一些实践，来实现质量的内建。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ab/ab70b4cbe310c6c60c1a0108bb2b86a7.png\" /></p><p></p><p>图 5-质量内建的实践</p><p></p><p>测试开发团队擅长质量工具和平台的建设，可以通过测试能力平台化和服务化的方法把测试能力赋能给架构师和开发人员。具体包含：</p><p>通过搭建代码质量平台来实现对静态代码扫描和人工代码评审的支持；通过自动生成单元测试技术来减少单元测试用例编写的工作量，通过单元测试覆盖率工具来衡量单元测试的有效性；通过建设低代码/无代码的接口测试平台，使开发人员能够低成本实现接口级别的测试；把界面测试、接口测试和单元测试等不同类型的测试抽离成为独立的测试服务，组装形成不同类型测试任务的混合编排，并且实现与流水线的集成，从而全面支持质量内建实践。</p><p></p><p>可靠的内建质量不仅提升了软件品质，也为效率提升打下了基础——一方面减少了缺陷和事故概率，使得研发团队不再四处奔忙于救火；另一方面通过测试能力平台化和服务化，降低架构师和开发人员的精力成本，而能够更专注于他们擅长的工作。</p><p></p><h2>测试开发团队向左和向右的效能边界拓展</h2><p></p><p></p><p>由于测试处于研发生命周期偏下游的位置，为了化被动为主动，避免由于前期的进度延期或者质量较差等问题影响测试阶段的正常进行，往往会更加关注流程。</p><p></p><p>其中，比较典型的实践是实现“提测/送测”流程的线上化，使提测流程标准化和自动化。</p><p><img src=\"https://static001.geekbang.org/infoq/79/79bfe7978769d162ec22be2ef97d2041.jpeg\" /></p><p>图 6-提测流程的线上化</p><p></p><p>相比起来产研团队中的其他角色，测试开发更关注流程，且具备流程线上化和平台化的实际经验。因此测试开发团队常常会把这种能力扩展到需求和发布运维阶段，从而实现需求全生命周期端到端的流程线上化执行。有不少案例表明，端到端的持续交付平台或者 DevOps 平台都是在此基础上不断完善、演进而来的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3c/3c531eac8f249df8591fbee8340edc73.jpeg\" /></p><p>图 7-研发流程线上化</p><p></p><p></p><h2>从质量度量走向效能度量</h2><p></p><p></p><p>做测试时间比较长的朋友们应该都对缺陷燃尽图比较熟悉了。通过观察缺陷燃尽图是否收敛，可以判断一个软件和系统版本的质量情况——如果临近发版的时候，缺陷数量还在不断发散（新增），那此次发版能够按计划施行的几率就比较小了。</p><p></p><p>在团队还未实现整个研发流程的线上化和平台化时，往往会最先实现缺陷管理的规范化。因此，基于缺陷数据来进行质量分析是我们常用的手段。缺陷数量、缺陷严重等级、缺陷逃逸率、缺陷燃尽图、缺陷密度和人均缺陷数量等等指标从不同视角刻画了研发的质量表现。</p><p></p><p>而研发团队中关注度量的其他角色，如项目经理和传统 QA 人员，在工具平台建设方面缺少投入和具体的实践；而测试开发团队从一开始就担负着缺陷管理工具、自动化测试报表和测试报告统计等工具的建设工作。因此我们看到，很多由产研团队内部孵化出来的效能度量工具平台，都是由测试开发团队来推动和建设的。</p><p></p><p>由产研团队内部演进出来的效能度量工具和平台，一般更聚焦于工程性指标和过程改进，更符合产研团队的具体需求。相比之下，由专门的平台部门建设的效能度量平台，则更擅长于大量数据分析、关联数据分析、数据报表下钻等方面。</p><p></p><p>正是由于两者互有特长，两个团队可以通过合作实现一举两得，既保证海量数据的分析和处理能力，又在一线团队很好地实现落地改进。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/12/124ef4c8119d5f7f13b9f90fd25c4396.jpeg\" /></p><p>图 8-合作共建效能度量</p><p></p><h2>小结</h2><p></p><p></p><p>研发效能提升离不开团队中多个角色的协同。其中，测试工程师逐步转型为测试开发工程师，越来越多的测试同仁具备了全栈的技术能力。也许一个测试开发人员，对需求和业务的理解不如产品经理深刻，对代码和架构的掌握不如开发人员精通，对运维和监控的体系不如 SRE 熟练。但是，由于质量和效率是贯穿全流程的，因此对测试开发人员应具备的知识技能的要求也是全栈的。在研发效能的提升之战中，每一个测试开发工程师都必然是先行者。</p><p></p><p>作者简介：</p><p>熊志男，DevOps 及研发效能专家。曾负责京东行云 DevOps 平台的产品规划和架构设计，平台覆盖万人规模的产研团队；曾作为京东数科一站式自动化测试平台的架构师和负责人，推动集团内部多个质量测试平台的共建；曾推动京东商城代码质量平台建设，并实现业务研发团队规模化持续集成落地。</p><p>云上软件工程社区 2022 年度研发效能方向创新技术专家，曾担任 QECon2021 的自动化测试专场出品人，测试窝社区联合创始人。</p><p></p><p>原文链接：</p><p><a href=\"https://mp.weixin.qq.com/s/z-2tqBLrmawhI9PQPmStBA\">https://mp.weixin.qq.com/s/z-2tqBLrmawhI9PQPmStBA</a>\"</p>",
    "publish_time": "2023-05-30 12:29:54",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "十年征程，做金融圈的技术弄潮儿｜InfoQ 《一探到底》",
    "url": "https://www.infoq.cn/article/Ypahd84ki4pyNWK4mA5i",
    "summary": "<p>科技驱动着各行各业发生着翻天覆地的变化，同样也改变着保险行业。在十余年的发展历程中，传统保险到业务数字化的变革过程中到底经历了什么？在引入创新技术的同时，金融行业该如何与自身业务发展进行平衡？530全国科技工作者日，InfoQ《一探到底》带大家走进国内首家互联网保险公司众安保险，一探究竟！</p>",
    "publish_time": "2023-05-30 13:19:58",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "坐拥多个TOP级开源项目，不搞“竞争性开源”，蚂蚁在玩一种很新的开源",
    "url": "https://www.infoq.cn/article/ralvB4xqACr4oMyUzOmv",
    "summary": "<p></p><blockquote>搞出国内绝对 TOP 级的开源项目 ant-design、开源办公室实体化、尽力避免“竞争性开源”… 蚂蚁集团的开源路径是如何形成的？</blockquote><p></p><p></p><p>近几年，国内大厂纷纷成立了开源委员会、开源办公室等组织，以期规范开源流程，并对内进行开源治理相关工作。在对开源商业化诉求强烈的大厂中，这类组织很容易在商业模式中找到自己的定位：开源社区往往承担着生产力、需求池、推广渠道等角色，这也因此更容易持续运营下去。</p><p></p><p>那么，对商业化诉求不那么明显的大厂会基于哪些原因设立这类组织？如何保证这类组织可以持续运营下去？如何让商业公司开源的项目保持良性的发展状态？AI 底层技术的逐渐成熟对整个开源社区的协作方式、格局等带来了哪些影响？</p><p></p><p>InfoQ 有幸采访到了<a href=\"https://www.infoq.cn/article/9LtMbS3xyfvteo6yuU6X\">蚂蚁集团</a>\"开源技术委员会主席何征宇，以期寻求上述问题的答案。蚂蚁集团是非常典型的并不以开源项目商业化为主要营收的企业，但是其依旧在过去十几年发展出了近百个社区头部开源项目及近 1600 个开源仓库，蚂蚁集团应该是上述问题的最佳答题者之一。</p><p></p><h2>当前国内开源虽火爆，但存在泡沫和不良竞争</h2><p></p><p></p><p>过去两年，社区里经常出现类似 “这是开源最好的时代” 的感叹。2021 年，开源第一次被写入国家《“十四五”软件和信息技术服务业发展规划》；从资本角度看，2021 年开源领域的融资事件较前一年增加了 4 倍以上，2022 年上半年融资事件数量占到三年融资数量的 36%，确实也称得上一个“好”字。</p><p></p><p>而基础软件领域大量开源项目的出现，确实加快了企业的转型进度，尤其是数据库、中间件、操作系统这些领域，国内企业和开发者有了更高的话语权和选择权，这是开源带来的好处，开源让基础软件生态更加繁荣，让开发者从“没得选”到“还可以挑挑”，让基础软件的最高评价权回归社区。</p><p></p><p>“任何行业没有泡沫是很难发展的，但是泡沫戳破之后，行业肯定会受到一些冲击，开源领域也是如此，如今国内的火爆不过是一个插曲，不会持久，希望大家可以看到行业发展的周期性。”-- 何征宇</p><p></p><p>泡沫之下，我们发现“竞争性开源”的现象越来越严重，个别领域的开源项目虽然数量多，但同质化现象也很严重，很多基础软件项目跟随、分叉为主，比如数据库领域很多项目源于 MySQL 和 PostgreSQL，在新兴技术领域则缺少引领能力。</p><p></p><p>纵观蚂蚁集团的开源版图，我们不难发现，其一直在尽力避免“竞争性开源”这件事情。</p><p></p><h2>尽力避免“竞争性开源”，蚂蚁的开源路径是什么？</h2><p></p><p></p><p>“首先，蚂蚁集团开源不是为了竞争，而且我也非常反对‘竞争性开源’，蚂蚁内部并没有相关 KPI；其次，开源的精神应该是开放共享，项目贡献值较高者，话语权也更高，不用在意项目所属，只要不违背相关许可即可。蚂蚁集团希望通过自身的努力对当前国内鱼龙混杂的开源生态做出一些改变”。采访中，何征宇如是说道。</p><p></p><p>那么，蚂蚁集团具体在开源层面做了哪些事情来避免“竞争性开源”呢？</p><p></p><p>1. 完善组织架构。蚂蚁集团内设开源委员会，下设开源办公室。在部分企业内部，这类组织多为虚拟的且由内部员工兼任，蚂蚁集团的开源办公室则是实体化的且由全职员工运营，最大程度保证所有开源项目均可及时按照流程进行项目审查，然后再面向社区开放。</p><p></p><p>2. 严格的项目审查和分级机制。蚂蚁集团对待每一个开源项目都非常谨慎，开源技术评估小组有专门的打分表，从技术先进性、安全性、潜在风险、开源价值（社会价值和商业价值）、成本、是否遵守开源许可等诸多维度进行评估。同时，蚂蚁集团自研了静态扫描、代码分析等一系列工具帮助提高审查效率。项目开源之后，团队还会每月召开一次会议，针对项目过去一个月的情况进行复盘，保证其发展符合预期。</p><p></p><p>由于一些历史原因，国内开发者对于大厂的开源项目最为担心的问题之一便是：项目本身是内部 KPI 开源出来的，一旦组织架构或者战略有变，导致该项目在内部被砍掉，整个项目就会突然停止运营。</p><p></p><p>为了避免此类情况发生，蚂蚁集团内部 针对开源项目做了 S、A、B、C 四类分级，S 级项目背后是公司级的资源支持，只要蚂蚁集团还在，S 级项目就会获得支持。以此类推，C 级项目基本由个人开发者支持，整体采用分级的方式治理。</p><p></p><p>3. 用战略眼光做开源，不用战术性的结果来评判好坏。 很多企业在开源层面经常顾虑的问题是“开源之后是不是降低了自身的竞争力？”。以谷歌为例，当前云原生领域的事实性操作系统 K8s 起初由谷歌开源，虽然 K8s 在日后发展的如日中天，但是谷歌的云业务并没有成为全球第一。因此，经常有业内人士称谷歌“为他人做了嫁衣”，尤其是在谷歌犹豫 <a href=\"https://www.infoq.cn/article/Se6QqLkbVyZk1v8KOcB5\">Knative</a>\"、<a href=\"https://www.infoq.cn/article/1bm54C5umd9jjhhLIA5k\">Istio </a>\"的开源方式期间，类似的言论更为常见。</p><p></p><p>2018 年之前，何征宇就职于谷歌，见证了诸如 K8s、TensorFlow 那一批优秀项目的诞生。采访中，何征宇表示，谷歌内部讨论一个项目是否开源会花费至少半年的时间，这些讨论并不是局限在一个项目开源之后到底能给现有业务带来多大价值，而是类似要不要做云业务、该项目三至五年之后会给业内带来哪些改变。简言之，这件事情的意义是战略层面的，而战略不应该用战术性的结果来评价。</p><p></p><h2>将开源作为核心技术战略，而不是业务的指标</h2><p></p><p></p><p>在蚂蚁集团内部，开源是最重要的战略之一。采访中，何征宇表示：“我们判断，未来的基础软件领域将全部开源，这一层不会有太多秘密；各大领域的企业一定会思考如何降低软件成本，通过开源的方式让其中多方共担成本是最佳路径”。</p><p></p><p>基于这样的战略判断，何征宇要求每一个开源项目都有未来三到五年的清晰规划，开源办公室会对此进行严格审查，并在项目开源之后定期校对进度。</p><p></p><p>也是因为这样的战略规划，蚂蚁集团不搞“竞争性开源”，最明显的是 纵观整个开源版图，我们会发现在图计算、隐私计算这样的冷门领域，蚂蚁集团均有贡献，而这些领域短期内很难在营收上带来很大贡献。在数字化转型步伐加快的当下，大量数据暴露在网络世界，金融企业需要新的技术来满足其自身对安全、可信的要求，而这正是蚂蚁集团最擅长的领域。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d1/d1cfb0c69884dc92faed0ae56510de0e.png\" /></p><p></p><p>“蚂蚁集团并不只是希望自身足够强大，而希望能把自身的经验、技术和优秀人才输出给全行业，包括在很多前沿领域，通过自身的探索带动行业整体水平提高，促进技术成熟。这是蚂蚁集团应该承担的社会责任，而且整个行业稳步向前，蚂蚁作为行业一份子也会得到提高。 当前时代也给了我们很好的机遇，以金融企业为代表，很多行业正处在技术架构转型的关键时期，用户对其安全性、稳定性、7x24 小时不间断服务等能力都提出了更高要求，这是蚂蚁集团可有所为的地方”，何征宇在采访中表示。</p><p></p><p>此外，蚂蚁集团开源办公室用数字化的方式管理每一个开源项目的进度，而这套系统是依靠蚂蚁集团开源的前端和图计算项目等搭建起来的。过去，很多大厂开源项目最被人诟病的一点就是“自己不用，然后开源”，而蚂蚁集团不仅自身也在用，同时内部的工程师文化也是鼓励开源，很多项目都是内部先开源使用后才对外开源。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/75/758724c7152b70d9cfd22149fed99546.jpeg\" /></p><p></p><p>基于上述路径，蚂蚁集团正在推进数据库、云原生、中间件等基础软件领域的自研核心技术全部开源。目前，蚂蚁集团积累了近 100 个社区头部开源项目、近 1600 个开源仓库、9 大核心开源项目，包括隐私计算技术栈<a href=\"https://www.infoq.cn/article/q5jpzKT7FQPXGihouEQR\">“隐语”</a>\"、分布式数据库 OceanBase、密码学技术“铜锁”等自研技术。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b0/b04186d0f3ab8f5fb725bd35c7c011cc.jpeg\" /></p><p>注：蚂蚁集团的 ant-design 项目在<a href=\"https://www.infoq.cn/minibook/DTAg4l8piWHrBGfU3der\"> InfoQ《中国开源发展研究分析 2022》</a>\"中综合排名第一</p><p></p><h2>AIGC 会对未来的开源世界带来哪些影响？</h2><p></p><p></p><p>面向未来，蚂蚁集团开源技术委员会同样有自己的判断。去年底至今，所有人都在密切关注 AIGC 相关技术对自身所处领域带来的影响。如果以 2023 年为启点，未来三到五年的开源世界又会是什么样子的呢？</p><p></p><p>当前部分大模型具备一定的编程能力，而训练这些能力大多依靠对社区内开源项目的代码学习。基于此，何征宇表示未来三到五年，开源的主体还是会以人为主，项目的格局不会发生根本性转变。但是，我们有理由相信未来大模型将会因为开源项目的增多而获得更强的代码编写能力，进而帮助程序员完成部分代码撰写的工作，而 这类 AI 工具所优先推荐的或者掌握的方法一定也是开源的项目，毕竟其以开源代码作为训练基础；开源作为一种软件生产方式也将从中获利，我们将有机会看到社区内出现自动写注释、自动补全等等相关的工具。总之，开源生态将会因此更加繁荣。</p><p></p><p>此外，国内确有研发团队在考虑通过自动编码工具代替部分人工产出。从何征宇的角度来看，国内首先没有大量的开源代码供训练，所以国内短期可能还不太会出现开源的、通用的自动编码工具。其次，企业如果希望内部沉淀一个专属的大模型，从经营角度来看，研发一个大模型投入的成本远高于经营所需的研发人力成本，这肯定是划不来的。未来，这类大模型最可能的结局是出现私有化部署版本供企业内部使用，解决数据安全问题。</p><p></p><p>嘉宾介绍：</p><p></p><p>何征宇，蚂蚁集团开源技术委员会主席、蚂蚁基础设施技术委员会主席</p><p></p>",
    "publish_time": "2023-05-30 13:43:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Microsoft Build完美落幕，下一站：中国！",
    "url": "https://www.infoq.cn/article/Lfp9vXBl0K0yh0vxNRZC",
    "summary": "<p></p><p><img src=\"https://static001.geekbang.org/infoq/81/814656c4114255d39fe0157543c63ce2.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b2/b2becc689fe1fe9d391bc8b20d700a06.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/db/db6f075f128ea98b3f6c216d0b98dd24.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/11/11937127218aa2848c88a394f4f36d4f.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d4/d44121cab3eb8d105841730b52a296c7.jpeg\" /></p><p></p><p></p><p></p>",
    "publish_time": "2023-05-30 14:19:06",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "混沌工程实验室稳保行动·深圳站活动成功举办",
    "url": "https://www.infoq.cn/article/dvX1KQqMLTvc3kcDVLfz",
    "summary": "<p>2023年5月27日，中国信息通信研究院（以下简称“中国信通院”）混沌工程实验室主办，华为云计算有限公司、腾讯云计算(北京)有限责任公司协办、InfoQ极客传媒支持的混沌工程实验室深圳站沙龙成功举办。沙龙以“保障系统稳定，构建韧性业务”为主题，旨在共同交流实践经验，深入探索业务系统的稳定性保障，提升行业内对系统稳定性的认知。本次沙龙吸引了多位业内专家、企业负责人和社区的系统稳定性专家到场参加，并吸引线上超万人观看。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d2/d2e519b1dba3e126f6a241f05e2a95a1.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d5/d521121deac30fef11de15d8aa0d1efc.png\" /></p><p></p><p></p><h2>致辞</h2><p></p><p></p><p>沙龙邀请中国信通院云大所云计算部主任马飞发表致辞。马主任表示，要实现高质量发展，重视业务系统的韧性和稳定安全运行至关重要，并提出三个展望：在战略上稳定运行将成为企业发展的重要目标、在工程上服务韧性工程将成为稳定运行目标实现的关键要素、在生态上“稳保”标准将成为促进技术发展的重要动力。马主任还提到，信通院自2020年开始研究稳定性保障工作，包括标准制定、政府支持和行业服务，他希望通过此次沙龙，传播先进技术思想和理念，分享最佳实践，推动稳保工作健康快速发展。</p><p></p><h2>SRE白皮书及系列标准启动仪式</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ec/ec3597b5b9ecb18db6b57b4b282c3d74.png\" /></p><p></p><p>中国信通院依托混沌工程实验室，基于SRE理论，自2021年起相继完成多项行业标准的制定，涵盖了可观测性、混沌工程等关键技术领域。在深圳站沙龙上，中国信通院与华为云、腾讯云、天翼云、中国移动、中国联通、阿里云共同启动SRE白皮书及系列标准的撰写工作。这一合作将充分发挥各方优势，借助混沌工程实验室的支持，进一步推动SRE领域的发展与创新。</p><p></p><h2>稳定可信云|《云服务稳定运行能力标准体系》解读及首评招募</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/17/174f1dd91dc319c2a7950ef2701f536b.png\" /></p><p></p><p>中国信通院云大所高级业务主管王海清对“云服务稳定运行能力标准体系”进行了详细解读并启动了首批评估工作。工信部信管局于2022年6月组织 “云服务稳定安全运行应急演练专项活动”，中国信通院全程支持了此专项活动，对全国31个省市的65家企业进行了针对云主机（含宿主机）、云存储、云网络、容器集群、消息队列以及云数据库等主要云服务的稳定性保障能力考察。</p><p></p><p>该标准体系是基于上述专项活动构建的，旨在保障企业云上系统的稳定性，提升服务连续性，促进业务的高质量发展。为推动标准的实施，中国信通院依据标准内容正式启动首批测评工作。该测评工作面向云服务提供商及自建云服务用户，综合运用混沌工程、可观测性和全链路压测技术，从稳定性架构设计水平的考察和“稳保”测试分级确认两个方面，综合评估被测云服务的“稳保”水平，及时发现和总结云服务中的潜在问题和实战经验，助力企业打造“稳定可信的云”。</p><p></p><p>首批评估共发布8类云服务评估方案，包括云主机、云存储、云网络服务、消息中间件、容器服务、分布式缓存、内容分发CDN以及融合云DNS服务。欢迎相关企业咨询参与！</p><p></p><h2>各方嘉宾发表精彩演讲</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cf/cfe151517def91691f88f7d37c06da19.jpeg\" /></p><p></p><p>金蝶云</p><p>金蝶软件研发工程与运维部副总经理邹俊发表了题为《金蝶云稳定性运维及平台建设实践分享》的演讲，并从自助运维、多产品、安全高可用和数字化运营四个维度对金蝶云的稳定性运维进行了详细阐述。</p><p></p><p>腾讯云</p><p>腾讯云计算(北京)有限责任公司云技术运营服务部研发总监周峰在分享中带来了《腾讯云混沌工程实践》，他详细介绍了腾讯云在应对动力不足、影响不可控和门槛过高等混沌工程落地挑战方面的经验。</p><p></p><p>货拉拉</p><p>深圳依时货拉拉科技有限公司的大数据SRE负责人张伟伟，在演讲中分享了《货拉拉大数据SRE体系建设实践》，并重点介绍了货拉拉在考虑稳定性保障要求时，如何从离线计算场景和实时计算场景两个核心场景的能力保障角度开展建设。</p><p></p><p>华为云</p><p>华为云计算技术有限公司的测试技术专家钟锦锋分享了题为《基于字节码增强的非侵入微服务健壮性评估》的演讲。在演讲中，钟锦锋提出了华为云在微服务流水线的α阶段中引入可靠性测试环节的实践。</p><p></p><p>安信证券</p><p>安信证券股份有限公司的互联网应用运维专家梁恩浩，为大家带来了题为《混沌工程在证券行业的实践与探索》的技术分享，梁老师详细介绍了在安信证券如何应对证券行业在稳定性保障方面的两个核心问题：数据不丢失和业务不中断，以及强实时性和强监管所带来的挑战。</p><p></p><p>中国移动</p><p>中国移动信息技术有限公司的研发专家严俊，带来了题为《中国移动磐基PaaS平台》的主题演讲。在演讲中，严老师提出了“用弹性化解意外”的理念，并介绍了磐基平台稳定性实践中的四个关键意识：生产意识、安全意识、忧患意识和运营意识。</p><p></p><p>平安银行</p><p>平安银行总行云计算平台团队的技术测试专家王华，他分享了题为《平安银行的混沌工程实践》的演讲，详细介绍了平安银行在混沌工程建设方面如何使用多样的真实世界事件进行验证，如何在生产环境中运行实验以及最小化爆炸半径等。</p><p></p><p>观测未来</p><p>上海观测未来信息技术有限公司的技术生态VP吴亚昆带来主题演讲《浅谈软件工程全生命周期视角下的可观测性》，阐述了如何通过开发可观测、测试可观测、运维可观测和业务可观测四个方面建设全生命周期的数字化平台。</p><p></p><p>SRE社区</p><p>中国SRE社区发起人刘峰分享了《SRE的新发展和可观测性》，刘老师详细介绍了SRE如何通过满足客户期望的可靠服务来交付业务价值。</p><p></p><h2>圆桌会议</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a1/a110e4b49617d62d594ceb8057b1d70e.png\" /></p><p></p><p>圆桌会议由华为云混沌工程专家崔成主持，腾讯云售后技术顾问周永飞、天翼云高级运维专家尹磊、深信服可靠性专家汤洪亮和广东移动云资源池运维专家黎传琛共同参与。圆桌探讨了云时代云服务和云商应用的稳定性挑战，混沌工程对系统稳定性的贡献，可观测性与混沌工程的联合应用价值，以及业界对服务韧性工程（SRE）的看法。专家们的讨论非常热烈，提出了许多关于稳定性保障建设和行业应用的建议和意见，对与会者和观众们产生了深刻的启发。</p><p></p><p>参会的各位专家深度探讨了系统稳定性保障的理论内涵和重要价值，挖掘了行业内系统稳定性保障痛点，本次沙龙在热烈的技术讨论中圆满结束。中国信通院目前正在推进一系列系统稳定性保障领域标准研讨及产品评估，引导行业构建稳定安全的运行生态。我们欢迎更多的业界同仁和专家加入，共同汇聚行业智慧、知识和技术，探索更完善的“稳保”标准和更先进的技术实践。</p>",
    "publish_time": "2023-05-30 14:31:45",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "市值暴涨至万亿美元后，英伟达再放大招！推出超级AI计算平台：集成256个GH200芯片、共享内存144TB",
    "url": "https://www.infoq.cn/article/e95bPU2tu1o9eGQqmQvP",
    "summary": "<p></p><blockquote>美国企业对H100处理器的旺盛需求，推动英伟达市值飙升至1万亿美元。</blockquote><p></p><p>&nbsp;</p><p>上周，英伟达股价一周内上涨了25%，市值直逼万亿美元，其创始人黄仁勋的身价也突破了330亿美元。</p><p>&nbsp;</p><p>春风得意的黄老板于5月29日现身在中国台北举办的COMPUTEX大会，并在大会上发布了面向所有行业的<a href=\"https://www.infoq.cn/article/wAM6PJiYjiyyj3l2jt4x\">生成式AI平台</a>\"。“我们正在重新发明计算机，加速计算和人工智能标志着计算正在被重新定义。”黄仁勋表示。</p><p>&nbsp;</p><p>黄仁勋正在带领英伟达从一家芯片公司转向提供<a href=\"https://qcon.infoq.cn/2023/guangzhou/track/1512\">AI计算</a>\"系统的公司，他此前称，人工智能的iPhone时刻已经来临。</p><p></p><h2>英伟达发布超级芯片GH200和AI计算平台</h2><p></p><p></p><p>受AI热潮的推动，英伟达也在硬件领域紧跟技术潮流，发布了一系列产品和解决方案：推出大内存<a href=\"https://qcon.infoq.cn/2023/guangzhou/track/1512\">生成式AI</a>\"超级计算机DGX GH200，可加速生成式AI设计的Grace Hopper超级芯片GH200已全面投产；推出全新加速以太网平台Spectrum-X，为游戏提供定制化AI模型代工服务；与全球最大的营销服务机构WPP合作打造生成式AI内容引擎，多家世界顶级电子制造商采用英伟达生成式AI工具与Omniverse平台构建先进的数字工厂。</p><p>&nbsp;</p><p>据悉，NVIDIA® GH200 Grace Hopper超级芯片将为全球各地即将上线的系统提供运行复杂AI和HPC工作负载所需的动力。在COMPUTEX上，黄仁勋公布了关于GH200 Grace Hopper超级芯片的更多细节。</p><p>&nbsp;</p><p>NVIDIA® GH200 Grace Hopper超级芯片使用NVIDIA NVLink®-C2C互连技术，将基于Arm的NVIDIA Grace CPU和Hopper GPU架构互联，实现了高达900GB/s的总带宽，比传统加速系统中的标准PCIe Gen5通道高出7倍，算力有了很大程度的提高，并且能够满足要求最苛刻的生成式AI和HPC应用。</p><p>&nbsp;</p><p>具体来说，&nbsp;GH200超级芯片是将 72 核的Grace CPU、H100 GPU、96GB 的 HBM3 和 512 GB 的 LPDDR5X 集成在同一个封装中，拥有高达 2000 亿个晶体管。这种组合提供了 CPU 和 GPU 之间惊人的数据带宽，高达&nbsp;900&nbsp;GB/s，为某些内存受限的工作负载提供了巨大的优势。</p><p>&nbsp;</p><p>值得一提的，<a href=\"https://qcon.infoq.cn/2023/guangzhou/track/1512\">英伟达</a>\"正式发布了一款新型大内存AI超级计算机——由NVIDIA GH200 Grace Hopper超级芯片和NVIDIA NVLink Switch System 驱动的NVIDIA DGX超级计算机，旨在助力开发面向生成式AI语言应用、推荐系统和数据分析工作负载的巨型、下一代模型。</p><p></p><p>DGX GH200 的细节还不太清楚，但已确认英伟达使用了一种新的 NVLink Switch 系统，包含 36 个 NVLink 开关，将 256 个 GH200 Grace Hopper 芯片和 144TB 的共享内存连接成一个单元，英伟达 CEO 黄仁勋表示，GH200 芯片为“巨型 GPU”。英伟达表示，256 颗 Grace Hopper 超级芯片将 DGX GH200 的“AI 性能”提升到了 exaflop（一百万万亿次）。</p><p>&nbsp;</p><p>NVIDIA加速计算副总裁Ian Buck表示：“<a href=\"https://www.infoq.cn/article/M4oBLcDHp7reGbveMud8\">生成式AI</a>\"正在迅速带来业务变革，解锁医疗、金融、商业服务等行业的新机遇并加速这些行业的研发工作。随着Grace Hopper超级芯片的全面投产，全球的制造商很快将会提供企业使用专有数据构建和部署生成式AI应用所需的加速基础设施。”</p><p></p><h2>ChatGPT问世后，芯片行业变天了</h2><p></p><p>&nbsp;</p><p>2022年，英伟达发布了H100——这是其有史以来最强大、也最昂贵的处理器之一，单位价格约为4万美元。当时看来，这款产品的发布时机并不理想，企业客户纷纷在巨大的通胀压力下削减开支。</p><p>&nbsp;</p><p>但就在11月，<a href=\"https://www.infoq.cn/article/k1EU1cHr1FflCxRuATtv\">ChatGPT</a>\"横空出世后，情况发生了变化。</p><p>&nbsp;</p><p>英伟达首席执行官黄仁勋表示，“刚刚经历艰难的一年，情况似乎一夜之间就出现了转机。”OpenAI打造的这款热门聊天机器人堪称“尤里卡时刻”（或顿悟时刻），“立即创造出巨大需求”。</p><p>&nbsp;</p><p>ChatGPT的迅速蹿红在全球领先的科技巨头和初创公司之间掀起一波军备竞赛，各方开始竞相争夺宝贵的H100资源。黄仁勋称这款产品是“全球首个为生成式AI专门设计的计算机芯片”，能够帮助AI系统更快输出顺畅自然的文本、图像和内容。</p><p>&nbsp;</p><p>就在过去一周，在正确的时间推出正确的产品再次成为决胜的关键。英伟达上周三宣布，其截至7月的本季度销售额预计将达110亿美元，较华尔街之前的估计高出50%以上。这波强劲浪潮背后，无疑是众多大型科技公司恢复数据中心支出和疯狂采购AI芯片的现实需求。</p><p>&nbsp;</p><p>投资人对此番预测也给出了积极回应，仅上周四一天之内就让英伟达公司的市值增加了1840亿美元。于是这家已经是全球最有价值的芯片公司在估值方面开始逼近万亿大关。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/02/0229377268ab5da29c0efa370e4ca6e6.png\" /></p><p>这项技术有望重塑各行各业，带来巨大的生产力提升并取代数百万个工作岗位。</p><p>&nbsp;</p><p>而H100芯片将加快这一技术飞跃。H100基于名为“Hopper”的英伟达全新芯片架构，以美国编程先驱Grace Hopper的名字命名，如今已经是整个硅谷最炙手可热的稀缺资源。</p><p>&nbsp;</p><p>黄仁勋表示，“就在我们着手将Hopper投入量产之际，AI突破到来了。”也就是说，Hopper刚好是在ChatGPT正式亮相的几周之前开始大规模生产。</p><p>&nbsp;</p><p>黄仁勋对于持续收益的信心，很大程度来自与芯片制造巨头台积电的密切合作。双方计划扩大H100的生产规模，以满足微软、亚马逊和<a href=\"https://www.infoq.cn/article/V24vD7kvHyuT3byVVObJ\">谷歌</a>\"等云服务商，Meta等互联网大厂以及其他企业客户的爆发式需求。</p><p>&nbsp;</p><p>CoreWeave是一家专注AI的云基础设施初创公司。作为首批收到H100的客户之一，公司首席战略官Brannin&nbsp;McBee表示“这已经成为地球上最稀缺的工程资源之一”。</p><p>&nbsp;</p><p>也有部分客户要等待半年之久，才能拿到自己用来训练大规模数据模型的H100芯片供应。更多AI初创公司则纷纷表示担心，称在需求起飞那一刻，H100就将面临供不应求。</p><p></p><h2>英伟达成为了AI浪潮中的首批赢家</h2><p></p><p>&nbsp;</p><p>马斯克也已经为自己的AI初创公司X.ai买下大量英伟达芯片，他本人也在本周《华尔街日报》的活动中表示，目前GPU“比药品更难获得”，还开玩笑说“而且这种情况在旧金山随处可见”。</p><p>&nbsp;</p><p>“计算成本已经飙升至天文数字，最低的准入门槛也是投入2.5亿美元为生成式AI系统构建服务器硬件。”</p><p>&nbsp;</p><p>事实证明，H100特别受到微软和亚马逊等大型科技企业的欢迎。他们正纷纷建立以AI工作负载为中心的更多数据中心。此外，OpenAI、Anthropic、Stability AI和Inflection AI等AI初创公司也在密切关注H100的性能承诺，希望借助它的力量加快产品发布、降低训练成本。</p><p>&nbsp;</p><p>英伟达超大规模与高性能计算业务负责人Ian Buck表示，“从购买难度来讲，没错，新架构GPU就是不容易买到。”肩负增加H100以满足需求这项艰巨任务的Buck承认，“目前供不应求已经成为规模性事件”，部分大客户正疯狂采购数以万计的GPU。</p><p>&nbsp;</p><p>这种性能极强的芯片负责充当数据中心的“加速器”，其搭载的800亿个晶体管达到最新款iPhone处理器晶体管数的5倍。尽管H100的售价高达2020年发售的上代A100芯片的2倍，但早期买家纷纷表示其性能至少提高了3倍，所以仍然极具性价比。</p><p>&nbsp;</p><p>作为Stable Diffusion图像生成服务背后的厂商，Stability AI联合创始人兼CEO Emad Mostaque表示“H100解决了长期困扰AI模型创建者的可扩展性问题”。“这非常重要，它能让我们更快训练出更大的模型，真正将研究问题转化为工程问题。”</p><p>&nbsp;</p><p>虽然H100的发布可谓正当其时，但英伟达在AI领域的突破实际源自近20年前的软件创新。</p><p>&nbsp;</p><p>英伟达的Cuda软件诞生于2006年，作用就是让GPU在图形之外作为其他工作负载类型的加速器。待时间来到2012年左右，“AI终于找上了我们。”</p><p>&nbsp;</p><p>加拿大的研究人员们很快意识到GPU非常适合用于创建神经网络，这是一种由人脑内神经元间相互作用启发而来的AI形式，后来成为AI开发的新焦点。Buck感慨道，“我们花了近20年才最终走到了今天。”</p><p>&nbsp;</p><p>英伟达如今拥有的软件工程师比硬件工程师还多，这也使其得以支持后续几年出现的多种不同类型的AI框架，也使其芯片在训练AI模型所需要的统计计算方面愈发高效。</p><p>&nbsp;</p><p>Hopper是首个针对transformers进行优化的架构，而transformers则是支持OpenAI聊天机器人明星的底层AI方法。通过与AI研究人员的密切合作，英伟达在2017年就注意到了transformers的出现，并开始相应调整自己的软件。</p><p>&nbsp;</p><p>AI初创企业投资方Air Street Capital的普通合伙人Nathan Benaich指出，“英伟达可以说比其他人更早看到了未来，并将重点放在了GPU可编程方面。在发现机遇并押下赌注之后，英伟达获得了持续领先于竞争对手的优势。”</p><p>&nbsp;</p><p>Benaich估计，英伟达比其他竞争对手要领先约两年。但他也补充称，“英伟达硬件和软件方面的市场地位恐怕还达不到坚不可摧的水平。”</p><p>&nbsp;</p><p>Stability AI的Mostaque对此表示赞同。“谷歌、英特尔和其他公司打造的下一代芯片正在迎头赶上。而且随着软件标准化的普及，就连Cuda也不足以构成可靠的技术护城河。”</p><p>&nbsp;</p><p>但对AI领先的另一些从业者来说，华尔街本周的热情似乎有点过度乐观。不过芯片咨询公司D2D Advisory创始人Jay Goldberg仍然承认，“从目前的情况看，AI半导体市场仍然保持着英伟达赢家通吃的局面。”</p><p>&nbsp;</p><p>参考参考：</p><p><a href=\"https://www.ft.com/content/315d804a-6ce1-4fb7-a86a-1fa222b77266\">https://www.ft.com/content/315d804a-6ce1-4fb7-a86a-1fa222b77266</a>\"</p>",
    "publish_time": "2023-05-30 14:39:09",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Rust 正式分叉出新的 Crab 语言",
    "url": "https://www.infoq.cn/article/Vi8CwvOv0jfe9PhCCycC",
    "summary": "<p>在<a href=\"https://www.infoq.cn/article/rJzSoNk3t5aNHccTa9Hh\">Rust 基金会商标新规</a>\"“闹剧“下，Rust 社区里愤愤不平的成员以 Crab 的名义<a href=\"https://github.com/crablang/crab\">分叉了</a>\"该语言，以抗议该组织近期准备为 Rust 和 Cargo 商标使用制定的新规范。</p><p>&nbsp;</p><p>4 月 7 日，Rust 基金会发布了新政策草案，并通过谷歌文档征求意见，截止日期为 4 月 16 日。这可能会对广泛的 Rust 社区产生严重影响，因为该基金会限制包括禁止在 Rust 相关工具或用 Rust 编写的软件的名字中使用 Rust，甚至在域名或子域名的部分也禁止使用 Rust。</p><p>&nbsp;</p><p>虽然后来Rust 基金会<a href=\"https://blog.rust-lang.org/inside-rust/2023/04/12/trademark-policy-draft-feedback.html\">发表声明</a>\"试图平息这一最新事件，但愤怒的社区还是对Rust做了分叉。</p><p>&nbsp;</p><p>GitHub地址：</p><p><a href=\"https://github.com/crablang/crab\">https://github.com/crablang/crab</a>\"</p><p>&nbsp;</p><p>“Crab&nbsp;（也称 CrabLang）社区分叉的创建是为了对社区内日益增长的、对公司影响和基金会提出的限制性商标政策的担忧，而作出的轻松而慎重的回应。这不是‘下意识’反应，也不是试图散布恐惧或引起恐慌。虽然基金会起草的文件确实导致了分叉，但我们认为这是对已经存在问题的逾期解决方案，并解决了许多社区成员一段时间以来遇到的一些问题。”CrabLang<a href=\"https://crablang.org/\">官网介绍道</a>\"。</p><p>&nbsp;</p><p>Crab方面还表示，首先也是最重要的：CrabLang 并不是要取代大家钟爱的语言。“如果您对现状感到满意，我们鼓励您继续使用您选择的语言。我们的目标不是分裂社区，而是为那些与我们有共同担忧并希望在使用、创造和推广语言方面有更多自由，而不必担心与商标侵权相关诉讼的人提供另一种选择。”</p><p>&nbsp;</p><p>Crab方面强调，Crab与项目或原始语言并不矛盾。Crab的主要分支将继续与上游代码库保持同步。</p><p>&nbsp;</p><p>“这里有您喜欢的所有内存安全功能，但现在完全没有那套官僚主义作风了！”Crab官网上写道。</p>",
    "publish_time": "2023-05-30 17:39:43",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]