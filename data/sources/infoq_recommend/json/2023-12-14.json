[
  {
    "title": "工商银行大数据平台助力全行数字化转型之路",
    "url": "https://www.infoq.cn/article/FuBdGKz3IUQef0gchvNO",
    "summary": "<p>在当前的金融行业中，面临着前所未有的数据增长和技术变革。随着大数据和人工智能的兴起，银行业面临着巨大的转型挑战和机遇。一方面，数据量的激增带来了存储和处理的问题；另一方面，客户对个性化和即时服务的需求日益增加。在这样的背景下，中国工商银行通过建立先进的大数据平台，致力于应对这些挑战并抓住这些机遇。</p>\n<p>在FCon 全球科技大会上，中国工商银行 /大数据和人工智能实验室/部门经理袁一详细介绍了数据平台的发展历程、实时数据处理的重要性、架构的演变、数据集成工具EasyDI的应用、适应不同场景的多样化数据库，以及未来的发展方向。以下为要点内容：</p>\n<ol>\n<li><strong>发展历程与总体架构</strong>：介绍了工行数据平台多年来的演变，突出技术进步和数据处理方法的转变。</li>\n<li><strong>实时数据仓库</strong>：强调实时数据处理在银行运营中的重要性，以及从传统批量处理方法的转变。</li>\n<li><strong>架构演化</strong>：涵盖了系统架构随时间的逐步变化，解决了挑战并引入了创新。</li>\n<li><strong>EasyDI（数据集成）</strong>：重点介绍了工行的数据分析平台EasyDI，在数据集成和分析中的关键作用。</li>\n<li><strong>多样化数据库适应不同场景</strong>：讨论了针对特定运营需求和场景选择不同数据库技术的用途。</li>\n<li><strong>未来展望</strong>：提供了银行数据管理策略和技术未来发展方向的见解。</li>\n</ol>\n<p><strong>活动推荐：</strong></p>\n<p>QCon 全球软件开发大会（上海站）即将在 12 月 28-29 日开始，届时将围绕 GenAI和通用大模型应用探索、AI Agent 与行业融合应用的前景、LLM 时代的性能优化、智能化信创软件 IDE、面向人工智能时代的架构、性能工程：提升效率和创新的新方法等专题进行交流。现在购票，享 9 折优惠，立减￥680！咨询购票请联系：18514549229（微信同手机号）。</p>",
    "publish_time": "2023-12-14 10:19:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "用友发布数据资产入表解决方案 加速激发数据要素价值",
    "url": "https://www.infoq.cn/article/Rz9Fg3sErszImZKG3Aze",
    "summary": "<p>12月13日，用友BIP数据资产入表解决方案正式发布，助力盘活企业数据资产、激发数据要素价值。用友通过提供咨询、设计、产品、交付、运营等全流程的解决方案与服务，帮助企业完成数据资产基础入表、统一数据治理和释放数据价值，并拉通数据服务到数据交易的通路，增强企业数据的开放、流通和变现能力，加速数据要素的社会级流转。</p><p></p><h2>数据要素市场化提速 企业加速数智化转型</h2><p></p><p></p><p>数据要素是数字经济的主要驱动力。数据要素价值的充分释放，将促进产业链全要素的生产力提升，助推经济高质量发展。数据对企业的生产经营和运营管理能够产生巨大价值，已经成为企业越来越重要的一个战略资源和极具价值的资产。企业只有真正挖掘和释放出数据的价值，才有望成为数智化时代的领先者。</p><p></p><p>数据价值的释放要求企业加速推进数智化转型。企业数智化转型的核心之一就是要释放数据的价值，通过新的数据要素驱动企业的创新发展，实现经营和管理的变革。作为全球领先的企业数智化软件与服务提供商，用友在服务众多行业领先企业数智化建设的过程当中，总结提炼出企业数智化进阶模型，即“企业数智化1-2-3”。处在不同发展阶段、不同行业的企业，可以参考此模型，在数智化1、2、3层级，分别重点推进云化连接（用云）、数据驱动（用数）、智能运营（赋智），从而构建数智化能力、发挥数据价值、创新应用，加速数智化进程。目前，多数企业处在数智化2层级，通过升级数智底座、全面推进数据治理，释放数据要素价值、管好用好数据资产，实现数据驱动的业务流程与决策、管理行动等。</p><p></p><p>用友网络科技股份有限公司高级副总裁杜宇在致辞中指出：“企业首先要树立‘数据是资产’的理念，分三个阶段即数据资源化、数据资产化、数据资本化，对数据进行运用、释放数据价值。在新的数据要素市场中，用友将从全产业视角，发挥35年的积累，即懂企业、知场景、强平台、聚生态的众多优势，助力企业全面融入数据要素市场实现创新发展。”</p><p></p><p>数据资产化是数据要素市场化的重要起点，当前，企业数据资产入表进入倒计时。财政部会计司于2023年8月发布《企业数据资源相关会计处理暂行规定》为企业数据资产入表提供了操作指引，将于2024年1月1日起施行。企业数据资产入表对企业的经营和组织发展都会带来影响，包括增资产、提利润，提高盈利水平，改善资产负债率；真实反映数据价值，重塑企业估值体系；重塑部门权责，成本中心变利润中心等。</p><p></p><h2>用友BIP数据资产入表解决方案正式发布</h2><p></p><p></p><p>当前企业数据资产入表和全面激发数据价值，还面临着诸多挑战。如在完成数据资产入表基础工作之前，企业需梳理清楚哪些数据属于数据资产、哪些数据属于资源、哪些工作项可以作为数据资产成本，这些成本哪些归入无形资产、哪些归入存货，完成初始计量后、如何处理后续计量，以及如何快速应对审计、进行数据资产的披露。</p><p></p><p>同时，要全面激发数据价值，企业还需关注数据在企业内部的应用场景、做好统一数据治理与数据中台的建设、关注数据资产的变现与数据安全等问题，以及需要遵循完善、科学的数据管理体系建设评定标准。</p><p>为助力企业充分发挥数据生产要素价值，实现数据驱动业务，用友网络大型企业客户事业群首席数据官张旭现场正式发布用友BIP数据资产入表解决方案，通过三个层级帮助企业完成数据资产入表和数据要素价值产出。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9b/9b1253dc55cb1a871406563539f9f81e.png\" /></p><p>用友BIP数据资产入表解决方案正式发布</p><p></p><p>用友BIP数据资产入表解决方案一共涵盖了3个层级12个关键工作，即通过数据盘点、数据登记/确权、数据资产判定、数据成本归集以及列表与披露等5个关键工作完成基础入表工作；通过统一的数据治理、构建全生命周期的数据管理体系和实现全面数据服务，激发企业内部数据价值；通过确定数据要素交易场景、制定数据战略与组织变革、搭建数据交易平台和实现企业数据资本化，最终完成数据要素的社会级流转。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6f/6f71609354170f318a7ccca6800f6f19.png\" /></p><p>图为用友BIP数据资产入表解决方案整体服务框架</p><p></p><p>完成基础入表工作</p><p></p><p>其中，在完成基础入表工作阶段，用友BIP通过入表系统帮企业实现敏捷高效的数据资源盘点、内外结合的数据产权确认与登记体系，依托权威生态及基于广泛实践进行数据资产判定，同时预制成本项、快速归集数据资产相关成本，最后基于平台自动形成披露报告初版内容。</p><p></p><p>激发企业内部数据价值</p><p></p><p>完成基础入表工作之后，企业需要进一步进行统一数据治理、激活企业内数据价值。用友“六横三纵”数据治理体系，即数据架构管理、数据标准管理、数据质量管理、数据安全管理、数据生命周期管理和数据应用管理等“六横”，以及管理组织、制度/流程和技术/平等“三纵”为企业进行以业务价值为导向的全局数据治理提供保障。同时，基于用友iuap数据中台，为企业构建一站式数据采集、加工、治理和应用的数据底座。在这个阶段，企业充分激活数据价值，可实现涵盖展现级、分析级、控制级、决策级和创新级的全面的数据服务。</p><p></p><p>数据要素的社会级流转</p><p></p><p>最后，在数据要素场景规划上，用友基于广泛应用经验为企业提供完整的社会级数据服务场景的五维模型，以促进企业数据在社会级的广泛流通。同时，在企业数据交易环节，提供核心关键节点的全面技术支撑能力体系，可以覆盖数据交易全生命周期。</p><p></p><p>数据资产入表对于企业而言，不只是一项财务工作，其最终的目的是充分激发数据要素，为企业创造全新价值，是企业数智化转型的关键环节。用友BIP数据资产入表解决方案帮助企业实现从数据资源化，走向数据资产化、数据资本化。</p><p></p><h2>《全球数据要素企业应用研究中心》揭牌成立</h2><p></p><p></p><p>当前，我国的数据要素生态框架已成雏形。与其他生产要素相比，数据具有可复制、非消耗、边际成本接近于零等新特性，对其他生产要素具有放大、叠加、倍增作用。同时，相比其他要素，数据要素还具有越用越有价值的优势。</p><p></p><p>用友自1988年创立以来，始终专注于企业软件与服务领域，通过35年持续深耕，已经构建了完备的数据应用服务能力，包括数据咨询、数据服务、数据应用服务和大模型等数智化产品与服务，并沉淀了一套完整的数据服务能力体系以及一批行业的数智化领先实践。</p><p></p><p>国际数据管理协会是一个全球性的专业组织，由数据管理和相关的专业人士组成，自成立以来，一直致力于数据管理和数字化的研究、实践及相关知识体系的建设，先后发行了《DAMA数据管理字典》和《DAMA数据管理知识体系》等。该知识体系目前已被广泛使用，并已成为业界的标杆和权威。</p><p></p><p>国际数据管理协会-中国分会(DAMA China)与国际数据管理高级研究院主席胡本立在会上表示，数据的产生和使用是不断循环的过程，数据方面的问题需要人（群）与人（群）间达成共识来解决。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/81/81f2c4e574a8a9d6214c0999f44f2e35.png\" /></p><p>用友网络副总裁罗小江（图左）与国际数据管理协会-中国分会、国际数据管理高级研究院负责人吴大有（图右）为《全球数据要素企业应用研究中心》进行揭牌</p><p></p><p>为推进企业高效释放数据产能，并利用数据要素为社会创造出更大价值、助力数字中国建设，用友联合国际数据管理协会-中国分会、国际数据管理高级研究院揭牌成立《全球数据要素企业应用研究中心》，以探索企业数据资产的产品化场景、推动企业数据交易。同时，通过产学研用开放合作、共享共创，发掘数据要素价值、共建繁荣数据生态。</p><p></p><p>在这一波的数据建设浪潮中，加速数智化转型是释放数据价值的关键步骤。用友希望通过全球领先的数智商业创新平台用友BIP的创新产品和服务持续服务企业的数智化建设与运营，实现数据驱动和智能运营，让数智化在中国和全球更多的企业与公共组织成功。</p>",
    "publish_time": "2023-12-14 10:26:59",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "上海华瑞银行风险特征计算平台演进路线",
    "url": "https://www.infoq.cn/article/pg5aKfMKTtUKabm0xJzd",
    "summary": "<p>在数字化和大数据时代，银行业面临着前所未有的机遇与挑战。随着技术的发展，客户对金融服务的期望日益提高，而银行必须不断创新以满足这些需求。特别是在风险管理领域，高效、精确的风险特征计算成为银行竞争力的关键。上海华瑞银行在这样的背景下，推动了其风险特征计算平台的演进，旨在通过先进的数据处理技术，提高风控效率和决策质量。在<a href=\"https://fcon.infoq.cn/2023/shanghai/\">FCon全球金融科技大会</a>上，上海华瑞银行风控数据团队负责人<strong>丁清华</strong>分享了《上海华瑞银行风险特征计算平台演进路线》，以下为演讲要点：</p>\n<ol>\n<li>\n<p><strong>演进阶段</strong>：从无独立系统、与决策引擎耦合，到发展成统一的特征计算平台。</p>\n</li>\n<li>\n<p><strong>业务痛点</strong>：最初特征少、计算功能弱、无特征管理能力。缺乏统一特征管理平台导致开发重复、资源浪费。频繁变更增加系统运营风险。</p>\n</li>\n<li>\n<p><strong>解决方案实施</strong>：构建高性能、易开发、可重用的数字风控决策实时数据处理平台。包括风险分析平台、特征工厂、决策分析，具备实时和离线数据处理能力。</p>\n</li>\n<li>\n<p><strong>关键运营指标</strong>：平台实现了显著的性能指标，如千余特征计算不到一秒，每日处理数百万接口计算。</p>\n</li>\n<li>\n<p><strong>未来展望</strong>：讨论了未来计算场景，强调支持风控、客户画像等多种应用的实时计算中心的需求。</p>\n</li>\n</ol>\n<p><strong>活动推荐：</strong><br />\nQCon 全球软件开发大会（上海站）即将在 12 月 28-29 日开始，届时将围绕 GenAI和通用大模型应用探索、AI Agent 与行业融合应用的前景、LLM 时代的性能优化、智能化信创软件 IDE、面向人工智能时代的架构、性能工程：提升效率和创新的新方法等专题进行交流。现在购票，享 9 折优惠，立减￥680！咨询购票请联系：18514549229（微信同手机号）。</p>",
    "publish_time": "2023-12-14 11:08:59",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "华为公共开发部 /Web 前端技术专家涂旭辉确认出席 QCon 上海，分享 LLM 赋能声明式前端框架调试的实践与思考",
    "url": "https://www.infoq.cn/article/hDvLlU98PB2bRXcQd1Xa",
    "summary": "<p><a href=\"https://qcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=1214&amp;utm_content=tuxuhui\">QCon 全球软件开发大会</a>\"，将于 12 月在上海召开。华为公共开发部 /Web 前端技术专家涂旭辉将发表题为《<a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5633?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=1214&amp;utm_content=tuxuhui\">LLM 赋能声明式前端框架调试的实践与思考</a>\"》主题分享，探讨如何将大语言模型赋能前端调试领域，结合 record &amp; replay 对声名式框架进行交互式调试。</p><p></p><p><a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5633?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=1214&amp;utm_content=tuxuhui\">涂旭辉</a>\"，毕业于西安交通大学自动化系，就职于华为西安研究所，参与开源前端框架研发与探索相关工作，是开源前端框架 openInula 核心贡献者，负责框架技术演进规划及生态拓展等工作，目前担任 openInula AI 赋能技术项目负责人，主导 AI 辅助前端开发工具实践与探索。他在本次会议的演讲内容如下：</p><p></p><p>演讲：LLM 赋能声明式前端框架调试的实践与思考</p><p></p><p>随着 AI 技术的快速发展，ChatGPT 的亮相进一步提高了人们对生成式 AI 的期待，大语言模型赋能千行百业的时代已经到来。本次演讲将介绍如何将大语言模型赋能前端调试领域，结合 record &amp; replay 对声名式框架进行交互式调试。开发者通过调试聊天框与模型互动，大模型对缺陷库进行学习增强程序分析推理能力并基于时间戳给出调试建议，开发者结合经验执行调试给出反馈，可以帮助开发者高效准确定位问题根因，为开发者带来全新开发调试范式。</p><p></p><p>演讲提纲：</p><p></p><p>背景与趋势</p><p>○ 前端框架发展 next </p><p>○ LLM 赋能千行百业</p><p>AI 赋能前端领域洞察</p><p>○ why AI for debug </p><p>○ 技术选型</p><p>程序分析技术在前端调试的应用</p><p>○ 程序切片技术 </p><p>○ 程序分析 × LLM</p><p>人机交互调试解决方案</p><p>○ 传统声名式前端框架调试流程 </p><p>○ record &amp; replay 交互式调试流程 </p><p>○ 整体技术架构 </p><p>○ 实践问题经验分享</p><p>未来与展望</p><p>○ AI 赋能前端开发全场景</p><p></p><p>听众收益点：</p><p></p><p>○ 传统前端调试 vs AI 赋能调试</p><p>○ 程序切片在前端调试的应用</p><p>○ LLM 对前端开发提效的思考</p><p></p><p>除上述演讲外，QCon 上海还将围绕&nbsp;<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart\">GenAI和通用大模型应用探索</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1596?utm_source=infoqweb&amp;utm_medium=teacherart\">AI&nbsp;Agent&nbsp;与行业融合应用的前景</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart\">LLM&nbsp;时代的性能优化</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart\">智能化信创软件&nbsp;IDE</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart\">面向人工智能时代的架构</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart\">性能工程：提升效率和创新的新方法</a>\"等专题进行交流。</p><p></p><p>QCon 上海 2023，相约 12 月！ 9 折优惠仅剩最后 2 天，现在购票立减￥680！咨询购票请联系：18514549229（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/0113b3dfb187d5f9988b7eb16d2e0594.png\" /></p><p></p>",
    "publish_time": "2023-12-14 11:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Anthropic 发布 Claude 2.1 大模型，提供更宽的上下文窗口并支持 AI 工具",
    "url": "https://www.infoq.cn/article/t9Olysl803omSfN5JfVe",
    "summary": "<p>据 Anthropic 称，最新版本的 Claude 大模型为企业提供了许多“关键特性方面的进步，包括行业领先的 200K token 上下文窗口、模型幻觉率显著降低、系统提示词以及我们新开发的测试功能：支持外部工具”。Anthropic 还宣布了降价措施，以提升各款模型用户的成本效益。</p><p>&nbsp;</p><p>增强的上下文窗口是 Claude 2.1 的一项亮点特性，其拥有 200,000 个 token 的容量，超过了 OpenAI 的 GPT-4，后者提供了 128,000 个 token 的窗口。Anthropic 表示，与之前的模型相比，新模型输出虚假陈述的可能性更小。Claude 2.1 会试图避免不正确的答案并承认一些问题存在不确定性，它输出相关答案时一般会选择提出质疑，而不是提供不正确的信息。Anthropic 表示，该模型输出的错误答案减少了 30%，并且模型错误地作出缺乏信源的判断的比率大大降低。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a84459e202646167175df02ee536748e.jpeg\" /></p><p></p><p>另一个值得注意的新增特性是 Claude 2.1 使用工具并与 API 交互的能力。该功能让模型能够利用计算器、数据库等外部资源，甚至执行网络搜索来更有效地响应查询。它还可以集成到用户的技术栈中，从而在各个领域中实现更多样化的应用。</p><p>&nbsp;</p><p>此外，Claude 2.1 引入了系统提示词，使用户能够为其请求设置特定的上下文。此功能可确保模型的响应更加结构化且前后一致。现在模型的价格定为输入的提示词每百万 token 8 美元，模型输出则是每百万 token 24 美元，这样包括开发人员和企业在内的很多用户群体都能负担得起了。</p><p>&nbsp;</p><p>一些用户对新模型的评价褒贬不一。从积极的一面来看，一些用户发现 Claude 2.1 非常适合聊天和摘要等任务，并赞扬了它的进步和功能改进，特别是在摘要任务方面。然而，其他用户也对该模型的拒绝响应情况和严格的审查表示失望，一些用户认为这让这款工具的实用性和自主性打了折扣。此外，由于严格的安全协议和内容指南，人们担心 Claude 在处理某些内容（例如学术或研究材料）方面存在局限性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2d/2d04c3c66956f6211f1baf9746682c76.jpeg\" /></p><p></p><p></p><blockquote>发现：在 200K 个 token（近 470 页）的情况下，Claude 2.1 能够回忆起某些文档级深度的事实文档最顶部和最底部的事实被回忆的准确率接近 100%位于文档顶部的事实的回忆性能低于底部（类似于 GPT-4）从 ~90K token 开始，文档底部的回忆性能开始变得越来越差无法保证短上下文长度下的性能 - Greg Kamradt</blockquote><p></p><p></p><p>Anthropic 及时推出 Claude 2.1 的时机恰逢 OpenAI 的内部冲突时期，后者导致 ChatGPT Plus 订阅暂停购买，首席执行官 Sam Altman 也陷入了风波。尽管如此，Devin Coldewey 写道，“不管怎样，GPT-4 仍然是代码生成领域的黄金标准，Claude 处理输入请求的方式与竞争对手是不一样的，有些更好，有些更差。”</p><p>&nbsp;</p><p>想要了解更多关于 Claude 2.1 细节的用户可以参考 Anthropic 网站上的模型介绍<a href=\"https://www-files.anthropic.com/production/images/ModelCardClaude2_with_appendix.pdf?dm=1700589594\">页面</a>\"。 Anthropic 还制作了一个示例<a href=\"https://github.com/anthropics/anthropic-tools\">存储库</a>\"，演示如何使用工具功能。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/11/anthropic-announces-claude-2-1/\">https://www.infoq.com/news/2023/11/anthropic-announces-claude-2-1/</a>\"</p>",
    "publish_time": "2023-12-14 12:57:17",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Gemini演示视频“翻车”后，谷歌接连放大招：向云客户免费提供Gemini Pro，还推出AI代码辅助工具，集成25家公司数据集",
    "url": "https://www.infoq.cn/article/h6397o17RRiXV73zbH2P",
    "summary": "<p>上周，谷歌公布了该公司有史以来体量最大、功能最强的 AI 模型 Gemini，这也是谷歌在推动 AI 实际落地过程中的重要一步。Gemini 模型共分为三个版本：Ultra 版、Pro 版与 Nano 版。谷歌已经开始在自家产品组合中引入 Gemini：从 Pixel 8 Pro 开始，Gemni Nano 将正式登陆 Android 系统；而经过专门微调的 Gemini Pro 则即将现身 Google Bard。</p><p>&nbsp;</p><p>12 月 13 日，谷歌在其云平台上推出了一系列 AI 模型以供用户体验并实际应用：包括向开发者和企业开放 Gemini Pro、面向开发者和安全运营的 Duet AI、图像生成 Imagen 2 以及用于医疗保健场景的 MedLM。</p><p></p><h2>谷歌正式开放 Gemini Pro</h2><p></p><p>&nbsp;</p><p>Gemini 属于完整的内容生成模型家族，据称采用了谷歌迄今为止最强大的大语言模型架构。在此之前，微软和包括谷歌在内的各家云服务及商业 IT 巨头纷纷在自家产品中引入所谓机器学习增强功能。而从目前的态势来看，这股潮流很可能会延续 2023 年全年，并在 2024 和 2025 年继续成为核心趋势。</p><p>&nbsp;</p><p>Gemini 提供多种参数规模，其中 Nano 版最小、面向设备端工作负载；Pro 版居中；而体量最大的 Ultra 版则负责处理后端服务器上的高强度工作负载。</p><p>&nbsp;</p><p>12 月 13 日，谷歌开始向开发者和企业开放 Gemini Pro，供其根据自有用例进行构建。据悉，谷歌将在未来几周到几个月内持续收集用户反馈，并据此对模型做进一步微调。明年初，在经过进一步微调、安全测试并收集来自合作伙伴的宝贵反馈之后，谷歌将正式推出 Gemini Ultra——这也是谷歌旗下体量最大、功能最强、可执行高度复杂任务的顶尖模型。谷歌还计划将 Gemini 引入更多开发者平台，包括 Chrome 和 Firebase。</p><p>&nbsp;</p><p>关于 Gemini Pro 更多详细信息：</p><p>&nbsp;</p><p>Gemini Pro 在各类研究性基准测试中的性能表现，优于其他同等体量的大语言模型。当前版本提供 32K 文本上下文窗口，后续版本的上下文窗口还将进一步扩大。Gemini Pro 将在一定时段内提供免费使用，最终定价也将具有竞争力。它提供一系列功能：函数调用、嵌入、语义检索、自定义知识背景以及聊天功能等。它支持全球 180多个国家和地区的 38 种语言。在当前版本中，Gemini Pro 接受文本作为输入，并可生成文本输出。谷歌此次还发布了专用的 Gemini Pro Vision 多模态端点，可接受文本和图像作为输入，并据此输出文本响应。Gemini Pro 提供的 SDK 将帮助用户构建出可在任何地方运行的应用程序。Python、Android（Kotlin）、Node.js、Swift 和 JavaScript 均在支持之列。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/bf/bf660fa989d23870b0007992f5561a1c.png\" /></p><p>&nbsp;</p><p>目前，Gemini Pro 的首个版本现可通过 Gemini API 进行访问：开发者可以使用此远程接口在 Gemini Pro 上构建自己的聊天机器人应用，还可以认真设计提示词并提交自有数据以对模型做出微调，再将其接入其他 API，借此在特定任务之上获得更好的处理能力与功能选项。如果希望在自己的应用程序中引入自然语言界面，Gemini Pro 应该会是个好选择，且使用体验与 OpenAI 的 ChatGPT 等同类产品基本一致。</p><p></p><h4>Google AI Studio：速度最快的 Gemini 构建选项</h4><p></p><p>&nbsp;</p><p>谷歌还发布了一款基于 Web 的免费开发者工具——Google AI Studio，可帮助用户快速设计提示词，而后获取 API 密钥以用于应用程序开发。开发者可以使用谷歌账户登录 Google AI Studio 并享受免费配额，免费部分每分钟可接收 60 条请求，数量达到其他同类免费产品的 20 倍。准备就绪之后，只需单击“获取代码”即可将生成结果转移至指定的 IDE，也可以使用 Android Studio、Colab 或者 Project IDX 中提供的各种快速入门模板。为了帮助谷歌提高产品质量，在用户使用免费配额时，经过培训的审核人员可能会访问 API 及 Google AI Studio 上的输入和输出。谷歌表示，谷歌账户及 API 密钥中的身份信息均经过脱敏处理。</p><p></p><h4>在 Google Cloud 使用 Vertex AI 进行构建</h4><p></p><p>&nbsp;</p><p>如果需要全托管AI平台，开发者也可以轻松从 Google AI Studio 转向 Vertex AI。后者允许通过全面的数据控制来自定义 Gemini，且充分享受 Google Cloud 提供的企业安全、隐私、数据治理与合规性保障。</p><p>&nbsp;</p><p>借助 Vertex AI，同样可以访问 Gemini 模型，并能够：</p><p>&nbsp;</p><p>使用自有企业数据微调及蒸馏 Gemini，立足底层对模型进行增强，使其包含最新信息和扩展以获取实际功能。在低代码/无代码环境中构建 Gemini 支持的搜索和对话 agent，包括支持检索增强生成（RAG）、混合搜索、嵌入、对话 playbook 等。安心进行应用部署。谷歌不会利用 Google Cloud 上的客户输入或输出数据训练 Gemini 模型，相关数据与 IP 将始终归客户所有。</p><p>&nbsp;</p><p>目前，开发者可以通过 Google AI Studio 免费访问 Gemini Pro 与 Gemini Pro Vision，每分钟最多支持 60 条请求，可以满足大部分应用开发需要。Vertex AI 计划于明年发布正式版本，在此之前开发者同样能以每分钟 60 条请求的方式访问 Gemini 基础模型。未来，Google AI Studio 与 Vertex AI 将以每 1000字符/1 张图片为单位收取费用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/be/be734eca7b6ee57d2beb3a6fe1f0a8bd.png\" /></p><p></p><h2>面向开发者和安全运营的 Duet AI</h2><p></p><p>&nbsp;</p><p>谷歌此次还正式公布了 Duet AI for Developers。这是一项聊天机器人服务，旨在提高程序员群体的工作效率。很明显，这就是目前常见的编程助手产品。根据谷歌的介绍，它能与各种 IDE 配合使用，并尝试在开发者输入过程中自动补全源代码、回答编码查询问题、帮助排除故障，并就如何使用 MongoDB、Crowdstrike 等第三方软件提供操作指导。</p><p>&nbsp;</p><p>谷歌副总裁 Gabe Monroy 解释道，“例如，使用 MongoDB 编写代码的开发人员可以询问 Duet AI for Developers，“请按地理位置筛选过去 30 天内消费额超过 50 美元的客户订单，再计算各地区的总收入”。之后，Duet AI for Developers 就会使用 MongoDB 中的产品信息提供代码建议并完成任务。如此一来，开发人员的构建速度将得到显著提升。”</p><p>&nbsp;</p><p>据悉，目前已经有超过 25 家供应商与谷歌合作，确保自家产品能够顺畅对接 Duet AI for Developers。</p><p>&nbsp;</p><p>在未来几周内，负责为 Duet AI 服务提供支持的大语言模型也将全面升级为 Gemini。这项开发者服务计划免费开放至 2024 年 1 月 12 日。此外，Duet AI in Security Operations 这次也正式开放，这款聊天机器人将帮助处理基础设施保护、网络日志分析等查询任务。</p><p></p><h2>图像生成 Imagen 2 模型与用于医疗保健场景的 MedLM 模型</h2><p></p><p>&nbsp;</p><p>本次，谷歌还更新了 Vertex AI 以引入 Imagen 2 模型。据介绍，这款文本到图像工具由 Google DeepMind 工程师开发而成，其最新版本已经能够生成极为逼真的图片并准确响应文本要求，大大降低了品牌宣传门槛。此外，Imagen 2 还能生成注释并回答与图像内容有关的问题。</p><p>&nbsp;</p><p>社交应用 Snapchat、图形设计平台 Canva 以及图片库网站 Shutterstock 都在使用 Imagen。而且 Imagen 2 模型生成的所有图像都将包含人眼不可见的 SynthID 数字水印，可通过计算检测来判断该图像是否为 AI 合成。</p><p>&nbsp;</p><p>此外，谷歌还推出了 MedLM，这是一个面向医疗保健用例的大语言模型家族。其中的两套模型均基于谷歌自家的 Med-PaLM 2 系列。其中较大、更强的模型专为较复杂的任务而设计，例如筛选学术论文及技术文档以提供潜在的新药研发线索；另一套模型则负责处理比较简单的杂务，例如总结医患对话和回应常见的医疗咨询问题。</p><p>&nbsp;</p><p>MedLM 模型的早期采用者包括 HCA Healthcare 诊所、药物设计企业 BenchSci，以及埃森哲与德勤等。</p><p>&nbsp;</p><p>谷歌表示，未来几周，MedLM 模型将正式入驻谷歌的开放 Model Garden，后续还将有更多基于 Gemini 的模型被纳入 MedLM 家族以提供更多功能。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://blog.google/technology/ai/google-gemini-pro-imagen-duet-ai-update/\">https://blog.google/technology/ai/google-gemini-pro-imagen-duet-ai-update/</a>\"</p><p><a href=\"https://blog.google/technology/ai/gemini-api-developers-cloud/\">https://blog.google/technology/ai/gemini-api-developers-cloud/</a>\"</p><p><a href=\"https://www.theregister.com/2023/12/13/google_gemini_duet_ai/\">https://www.theregister.com/2023/12/13/google_gemini_duet_ai/</a>\"</p>",
    "publish_time": "2023-12-14 14:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "流计算迎来代际变革：流式湖仓Flink+Paimon加速落地、Flink CDC重磅升级",
    "url": "https://www.infoq.cn/article/Njkx2lBJj0M6iVbFoH83",
    "summary": "<p>2023 年 12 月 9 日，Flink Forward Asia 2023 （以下简称 FFA ）在北京圆满结束。70+ 演讲议题、30+ 一线大厂技术与实践分享，以及座无虚席的现场，无一不昭示着重回线下的 FFA 的行业号召力。</p><p>借用 Apache Flink 中文社区发起人、Apache Paimon PPMC Member、阿里云智能开源大数据平台负责人王峰的话来说：“经过近十年的发展，Flink 已然成为了流式计算的事实标准。”</p><p></p><p>当然，对于社区开发者而言，这次大会上带来的流计算的新趋势、新实践与新进展或许才是关注的重点。</p><p></p><p></p><h3>Flink 两大版本更新，深入场景、精益求精</h3><p></p><p></p><p>过去十年，随着大数据、物联网和实时分析等需求的日益增长，传统的批量处理和静态分析方法无法满足新型数据处理场景下的高效、实时的要求，流计算的概念由此出现。流计算具有实时性强、处理实时数据流等能力，使得系统能够更加及时地响应和分析从大规模设备、传感器以及其他数据源产生的数据。Apache Flink 开始崭露头角，并且凭借其出色的性能和灵活性在全球范围内赢得了众多企业和开发者的青睐。</p><p></p><p>发布会上，王峰表示：“Flink 作为开源大数据领域的一棵常青树，一直保持着快速的发展，根本原因是我们在核心技术领域的不断演进。2023 年我们同样取得了一些新的进展，依然保持一年两个大版本的发布，包括 Flink1.17 和 1.18，也产生了很多新的贡献者。”</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0e/0ed64ad2bf4ddcbafd863be1281a25a1.png\" /></p><p></p><p>“在核心的流处理领域内，整体总结就是精益求精。”王峰提到。事实上，从技术层面来看，当前 Flink 已经成为了全球流计算领域的标杆，所以 2023 年 Flink 把版本更新的重点放到了深入场景、持续打磨上。比如持续完善 Flink 在批处理模式下的性能问题、功能完善性问题等，让 Flink 成为一款对有限数据集和无限数据集都能统一处理的计算引擎。</p><p></p><p>具体来说，在用户最关注且使用最多的开发语言—— Flink SQL 方面，Flink 团队进行了数百项调整或优化。比如，今年社区推出了一项新的功能特性—— Plan Advice，它可以帮助用户智能检查流式 SQL。Plan Advice 会在用户编写完流式 SQL 后，自动检查 SQL 可能存在的问题或风险，并第一时间给出提示和可行的建议。目前这项功能受到了用户的热烈欢迎。</p><p></p><p>在 Streaming Runtime 也就是真正的 Streaming 核心架构上，今年同样做出了较大的升级。“Flink 最大的特点是面向状态计算，自带状态存储和状态访问能力，因此状态管理、State 管理、Checkpoint、快照管理等都是 Flink 非常核心的部分，也是用户有很强诉求的部分。虽然 Flink 定期会做全局一致性快照，但用户希望快照频率越快越好，且代价越小越好，可行的思路是让系统在出现容错的时候，尽量少的数据回放，比如做到秒级的 Checkpoint。”王峰表示。经过一年的努力，通用的增量 Checkpoint 能力在 Flink1.17 和 1.18 成功落地，并且达到了一个完全生产可用的状态。</p><p></p><p>此外，在 Batch（批处理）引擎层面，Flink 也做了很多性能优化。王峰介绍称：“Flink 作为一款流批一体的引擎，除了强大的流计算能力，我们希望它在批处理方面同样优秀，给用户带来一站式的数据计算、数据开发体验。”</p><p></p><p>今年，Flink 不仅基于核心的流引擎优势来优化批处理场景下的执行效率，同时也将传统批处理上的优化手段引入到了 Flink 中去。经测试，Flink 1.18 版本的 Batch 执行模式在 TPC-DS 10T 数据集上的性能比 Flink 1.16 提高了 54%，基本达到了业界领先水平。</p><p></p><p>“这些优化会持续下去，保障 Flink 不仅在流计算领域达到业界的最强水平，在批处理领域依然可以达到一流的引擎执行能力。实际上今年我们已经看到非常多的公司在分享基于 Flink 的流批一体实践了。”王峰介绍道。</p><p></p><p>在部署架构方面，Flink 社区开发者也做了大量工作，以推动 Flink 在云上更好地运行。毋庸置疑的是，云原生不仅是大数据的新趋势，也为包括 AI 的普惠提供了基础。为了满足越来越多的项目和软件能够更好地在云上运行并提升用户体验，社区开发者做了大量工作。比如支持用户通过 API 在线、实时地进行扩缩容且不必重启整个 Flink 实例。同时为了实现云上全程无人值守的弹性扩缩容， Flink 社区还推出了基于 Kubernetes 的 Autoscaling 技术，通过 Autoscaling 去动态地、实时地监控整个任务的负载和延迟性，来保障用户的弹性扩缩容体验。</p><p></p><p>在场景方面，王峰表示，为了让更多的数据流动起来，Flink 社区也做了非常多的尝试，比如让 Flink 跟 Lakehouse 的架构协同，希望利用 Flink 强大的实时计算能力，加速 Lakehouse 的数据流动与分析。值得一提的是，今年 Flink 的两个版本加入了许多新的 API 来实现对 Lakehouse 的支持；同时也增加了对 JDBC driver 的支持，用户利用传统的 BI 工具就能实现与 Flink 的无缝对接。</p><p></p><p>“其实 Flink 的演进一直遵循着一个规律，即大数据行业的发展趋势。当前，大数据的场景正在从离线向实时加速升级转换。在这个大的浪潮下，Flink 的每一项工作都在不停地被验证。”王峰总结道。</p><p></p><p>发布会现场，曹操出行基础研发部负责人史何富分享了他们基于 Flink 的实时数仓实践。根据介绍，目前曹操出行公司运营中有三类主要的实时数据需求。首先，管理层需要实时的数据来随时了解公司的运营状况；其次，运营团队也需要一个聚焦的工具来可视化掌握运营细节；最后，算法对实时数据的要求越来越高，越实时的数据对于算法的效果越好。</p><p></p><p>“在过去的一年多里，通过基于 Flink 的流式数仓 ，曹操出行能够生成多样化的指标和实时特征，并输送给算法引擎，最终使得乘客补贴效率提高了 60%，司机效率提高了 20%。更令人振奋的是我们的毛利增长了 10 倍。” 曹操出行基础研发部负责人史何富表示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e9/e942542106f479ea1511eeb239ed07d7.png\" /></p><p></p><p>对于 Flink 的后续规划，阿里云智能 Flink 分布式执行负责人、Apache Flink PMC 成员、Flink 2.0 Release Manager 宋辛童表示：“我们刚刚在 10 月份推出的 1.18 版本，在明年的 2 月份和 6 月份，我们会分别推出 1.19 跟 1.20 版本，以满足 API 迁移周期的需求。另外，我们将在明年的 10 月份推出全新的 Flink2.0 版本，将围绕流处理的极致优化与技术演进、流批一体架构演进、用户体验提升三个核心方向，大力推动存算分离状态管理、Batch 动态执行优化、流批统一 SQL 语法、流批融合计算模式、API 与配置系统升级等工作，期待更多的社区小伙伴们能够加入共建！”</p><p></p><p></p><h3>Apache Paimon：引领流式湖仓新变革</h3><p></p><p></p><p>除了持续加速 Flink 的演进外，Flink 社区过去一年还孵化出了一个全新的项目，并且成功捐赠给了 Apache 社区，它便是 Apache Paimon。</p><p></p><p>Apache Paimon &nbsp;前身为 Flink Table Store，是一项流式数据湖存储技术，可以为用户提供高吞吐、低延迟的数据摄入、流式订阅以及实时查询能力。</p><p></p><p>事实上，随着 Lakehouse 成为了数据分析领域新的架构趋势，越来越多的用户将传统的基于 Hive、Hadoop 的数仓体系，转移到 Lakehouse 架构上。Lakehouse 架构主要有五大优势：计算存储分离、存储冷热分层、操作更灵活、查询可更换以及分钟级时效性。</p><p></p><p>“时效性是业务迁移的核心动力，而 Flink 是把时效性降低下来的核心计算引擎，有没有可能把 Flink 融入到 Lakehouse 中去，解锁一个全新的 Streaming House 的架构呢？这就是 Paimon 的设计初衷。”阿里云智能开源表存储负责人、Founder of Paimon、Flink PMC 成员李劲松表示。</p><p></p><p>当然，为了实现这一构想，Flink 团队同样经历了不小的挑战。其中最大的挑战源于“湖格式”，流技术以及流当中产生的大量更新，对湖存储格式带来了非常巨大的挑战。</p><p></p><p>“首先 Iceberg 是一个架构简单、生态开放的优秀湖存储格式，早在 2020 年，我们就在试图把 Flink 融入 Iceberg 当中，让 &nbsp;Iceberg &nbsp;具备了流读、流写的能力。但是逐渐我们发现， Iceberg 整体还是面向离线设计的，它必须保持简洁的架构设计来面向各类计算引擎，而这给我们对它做内核改进带来了极大的阻碍。”李劲松解释道。</p><p></p><p>在 Flink+ Iceberg 的探索碰壁之后，Flink 团队开始思考 Flink+Hudi 的集成。Flink 接入之后，把 Hudi 的时延从 Spark 更新的小时级降低到了十分钟级。但是再往下，又遇到了新的阻碍，因为 Hudi 本身是面向 Spark，面向批计算设计的，它的架构不符合流计算以及更新的需求。</p><p></p><p>“在总结了 Flink+Iceberg 与 Flink+Hudi 这两套架构的经验之后，我们重新设计了一套全新的流式数据湖架构，也就是 Flink+Paimon。”李劲松表示。</p><p></p><p>Flink+Paimon 具有湖存储 +LSM 原生的设计，专为流更新而构建。Paimon 与 Flink、 Spark 都有良好的兼容性，并支持强大的流读流写功能，从而能够真正将延迟降低至 1-5 分钟。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2c/2cdda0a4cf7905382a9ac7dca463f9ea.png\" /></p><p></p><p>“Apache Paimon 是一个流批一体的湖存储格式，它只是一个格式，把数据存储在的 OSS 或者 HDFS 上。然后基于这样的湖格式，通过我们推出的 Flink CDC 就能实现一键入湖，也能通过 Flink、Spark 来流写、批写到 Paimon 中去，后面 Paimon 也将支持各种主流开源引擎的读以及 Flink、Spark 的流读。”李劲松补充道。</p><p></p><p>“随着 Paimon 的版本迭代，你可以看到非常巨大的进步，目前 Paimon 社区已经有了 120 个来自各行各业的 Contributors，Star 数也达到了 1500+，越来越多的企业开始应用 Paimon 并且分享 Paimon 相关的实践。”</p><p></p><p>发布会上，同程旅行分享了他们基于 Paimon 的数据湖实践。据介绍，目前同程旅行已将 80% 的 Hudi 湖仓切换至 Paimon，涵盖了 500 多个任务和十多个基于 Paimon 的实时链路场景，处理大约 100TB 的数据量，整体数据条数达到约 1000 亿。</p><p></p><p>同程旅行大数据专家、Apache Hudi &amp; Paimon Contributor 吴祥平表示，同程旅行基于 Paimon 做了架构升级之后，ODS 层同步效率提高了约 30%，写入速度提升约 3 倍，部分查询速度甚至提升了 7 倍；利用 Tag 的能力，在导出场景节省了约 40% 的存储空间；通过中间数据的可复用性，指标开发人员的工作效率提高了 约 50%。</p><p></p><p>此外，在汽车服务领域，汽车之家同样成功将 Paimon 应用于运营分析和报表等场景，不仅带来了极大的便利，同时也帮助业务取得了显著的收益。</p><p></p><p>汽车之家大数据计算平台负责人邸星星表示，通过与 Flink CDC 深度合作，汽车之家实现了流式读取，将数据写入 Paimon，并使用 Flink 再次消费 Paimon 的增量数据，从而将整个 Pipeline 打造成一个实时智能化的系统。</p><p></p><p>同样，得益于对 Flink+Paimon 的结合使用，在保证数据一致性的基础上，实现了架构简化，主机资源相较于之前减少了约 50%，同时在数据订正、实时批量分析以及中间结果实时查询等方面都获得了很好的支持。</p><p></p><p>从以上案例中，不难看出 Paimon 在实现流批一体方面发挥了重要作用。它成功地将流计算和批计算这两种不同的计算模式融合到了一起，与 Flink 的流批一体计算和存储能力相结合，打造出一个真正融合流和批的架构。Paimon 最常见的应用场景是数据实时入湖，而在这个过程中，Flink CDC 与 Paimon 的结合能够实现极简的入湖链路，使入湖操作达到全量与增量一体化的状态。这种组合为构建实时数据仓库、实时分析系统等提供了强有力的支持。</p><p></p><p></p><h3>Flink CDC 3.0 实时数据集成框架发布，并宣布捐赠 Apache 基金会</h3><p></p><p></p><p>Flink CDC 是一款基于 Flink 打造的一系列数据库的连接器，主要用于帮助 Flink 去读取隐藏在业务数据库里的增量变更日志。目前 Flink CDC 支持十多种主流的数据源，同时又能跟 Flink SQL 无缝链接，让用户通过 SQL 就能构建丰富的应用形态。</p><p></p><p>据悉，通过捕获数据变更，Flink CDC 能够实时地将数据变更传输到目标系统，从而实现近实时的数据处理。这种处理方式大大缩短了数据处理的时延，能够将数据处理的时效性从天级别降低到分钟级别，从而显著提升业务价值。</p><p></p><p>在发布会上，阿里云智能 Flink SQL、Flink CDC 负责人伍翀表示，Flink CDC 在 2023 年发展非常迅速。在生态方面，新增了对 IBM DB2 和 Vitess 这两个新 Connector 的支持，并且将增量快照读取的能力扩充到了更多的数据源；在引擎能力方面，提供了非常多的高级特性，比如动态加表、自动缩容、异步分片、指定位点等，还支持了 At-Least-Once 读取模式，并且还具备了横跨 Flink 1.14 到 1.18 五大版本的兼容能力。</p><p></p><p>Flink CDC 从诞生至今，已经有三年多的时间。一开始它的定位是做一系列数据库、数据源的连接器，但是随着 Flink CDC 在业界的广泛应用，Flink 团队逐渐发现最初的产品定位无法去 cover 更多的业务场景。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ca/caed384b287c8e9c54c2c5463f86264e.png\" /></p><p></p><p>“如果它只是一个数据库的连接器，用户如果要搭建一个数据集成的解决方案，还是需要去做很多的拼装工作，或者遇到一些条件限制。所以我们希望 Flink CDC 它不仅仅是去做数据库的连接器，还能够去连接更多的数据源，包括消息队列数据库、数据湖、文件格式、SaaS 服务等等。更进一步，我们希望把它打造成一个能够打通数据源、数据管道、结果目标的端到端的实时数据集成解决方案和工具。而这也就是我们今天要正式发布的 Flink CDC 3.0 实时数据集成框架。”伍翀表示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ea/eaf37fa690db9de46db80efb25acbf24.png\" /></p><p></p><p>据悉，Flink CDC 3.0 实时数据集成框架是基于 Apache Flink 的内核之上去构建的。在引擎层，Flink CDC 3.0 开放了很多高级特性，包括实时同步、整库同步、分库分表合并等等；在连接层，Flink CDC 3.0 已经支持了 MySQL、StarRocks、Doris 的同步链路，Paimon、kafaka、MongoDB 等同步链路也已经在计划中；在接入层 Flink CDC 3.0 提供了一套 YAML + CLI 的 API 方式，以此来简化用户开发实时数据集成的成本。</p><p></p><p>“Flink CDC 3.0 实时数据集成框架的发布，是 Flink CDC 在技术上的一次里程碑突破，而在这背后，离不开社区的力量、开源的力量，所以我们希望能够利用技术去回馈开源。”伍翀表示。</p><p></p><p>随后，在发布会现场，阿里巴巴正式宣布将捐赠 Flink CDC 到 Apache Flink 和 Apache 软件基金会。</p><p></p><p></p><h3>从引进来到走出去，全球化视野下的开源生态</h3><p></p><p></p><p>不止于技术层面的持续创新与硕果累累，近年来 Apache Flink 在国际化生态社区构建方面同样令人瞩目。</p><p></p><p>在中国，Flink 中文社区成为了最活跃的技术社区之一。在 Flink 中文社区五周年之际，社区开发者们共同见证了 750 篇技术文章的累计发布，吸引了 111 个公司和 351 位开发者的积极参与，这些文章累计获得了高达 235 万的阅读量，凸显了 Flink 全球化社区技术布道的中国力量。</p><p></p><p>放眼世界，目前 Flink 已经成为 Apache 基金会最活跃的顶级项目之一，Flink 的社区成员覆盖到欧洲、北美、东南亚各地，涵盖了学术界、工业界、开源社区等各个领域。作为其中的主导者，阿里巴巴国际化社区的管理也得到日益增强。根据统计，阿里巴巴培养了 70% 以上的 Flink 项目管理委员会（PMC）成员和提交者（Committor）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4e/4ee77cfb4eeb431dd91b2d9ef2049236.png\" /></p><p></p><p>值得一提的是，今年 6 月，Flink 凭借其在实时大数据领域的技术创新和全球影响力，被数据库国际顶级会议 SIGMOD 授予 SIGMOD System Award 2023 大奖。过往获得该奖项的均为全球数据库领域的明星项目，如 Apache Spark、Postgres 和 BerkeleyDB 等。</p><p></p><p>从国外引入到中国，再到华人贡献推动 Flink 开源技术全球化，华人开发者在这个过程中正在扮演着越来越重要的角色。他们不仅在开源项目的开发中发挥了重要作用，还积极参与到各种开源社区的活动中，共同推动技术的发展和创新。而这些华人开发者的贡献则对 Apache Flink 生态系统的成长和发展起到了关键作用。</p><p></p><p>Apache Flink 全球化视野的开源生态已经成为其持续繁荣的重要力量。在这个生态中，各种技术、文化和思想得到了充分的交流和融合，为其创新带来了巨大的推动力。我们也有理由相信，未来在这片具备全球视野的开源沃土之上，将会有越来越多的开发者加入，共同为实时计算的未来贡献自己的力量。</p>",
    "publish_time": "2023-12-14 14:48:33",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]