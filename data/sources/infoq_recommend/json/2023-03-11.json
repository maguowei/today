[
  {
    "title": "Netflix是如何利用联合平台控制台统一工程体验的",
    "url": "https://www.infoq.cn/article/3sYe2eD6ilfFyBWRt1fL",
    "summary": "<p></p><h3>摘要</h3><p></p><p>为了解决开发人员在日常工作中，面对工具和服务碎片化所带来的效率下降，Netflix的Brian Leathem团队开发了一个联合平台控制台，统一了开发人员的工程体验。</p><p></p><p>本文最初发表于<a href=\"https://platformengineering.org/talks-library/netflix-platform-console-to-unify-engineering-experience\">Platform Engineering网站</a>\"，由InfoQ中文站翻译分享。</p><p></p><p>大多数开发人员的日常工作都是低效的，主要是因为他们在构建、运行和扩展应用的时候，会使用数十种碎片化的服务和工具。这种低效在无意间会导致生产力的损失。对于小公司来说，碎片化的开发体验或许是可容忍的，但是随着业务的增长，统一它们的需求也会不断增长。</p><p></p><p>在Brian Leathem的带领下，Netflix的开发人员很早就采用了微服务架构，但是随着平台工具的增加，他们发现这种方式过于琐碎，于是，他们需要在公司的软件开发生命周期Software Development Life Cycle（SDLC）中统一开发人员的体验。在PlatformCon 2022上，Brian Leathem分享了如下的经验。</p><p></p><p>为了在Netflix的SDLC中统一开发人员体验，Netflix的平台体验和设计（Platform Experiences and Design，PXD）团队决定建立一个联合平台控制台（federated platform console）。Netflix的联合平台控制台是一个一站式的商店，提供了工程师开发和部署软件需要的所有工具。它将开发人员使用的几十种服务和工具整合到一个单一的、易于使用的界面中。</p><p></p><p>通过这个控制台，Netflix希望能够解决在与开发人员访谈时所发现的主要的碎片化挑战，其中包括：</p><p></p><h3>1.管理多个服务和软件</h3><p></p><p>开发人员每天都要使用太多的工具了，这给开发、交付以及运维服务和软件带来了挑战。例如，在整个SDLC过程中，开发人员需要分别使用Bitbucket来审查pull request，Spinnaker来检查部署流水线，Jenkins来检查构建失败，并且使用内部告警度量工具来检查运维状态等。除此之外，他们可能需要多次重复这些工作流程。</p><p></p><h3>2.平台发现</h3><p></p><p>Netflix的产品服务所有者已经为开发人员创建了工具和文档，但是很多开发人员不知道这些工具的存在。所有开发人员都无法立即知道他们的团队正在使用的众多工具和文档，他们可能会发现自己依赖于团队内传递给新成员的部落知识（tribal knowledge，这里指的是只有部落内部成员知道的信息，部落外面的人所不知道的知识，也就是所谓的小圈子——译者注）。另一方面，工作时间比较久的开发人员可能不知道为改善他们的日常工作流程而增加的新工具。</p><p></p><h3>3.在不同工具之间切换上下文</h3><p></p><p>当开发人员需要使用多个服务和工具时，他们需要在它们之间进行上下文切换。这可能会导致效率低下和错误，因为开发人员切换到另外一个工具时可能会忘记他们在当前工具中的工作。</p><p>Netflix的PXD团队很清楚，开发人员能够从一个平台控制台中获益，该控制台可以作为一个共同的入口，让他们能够从一个统一的地方来查看和评估其服务的状态，并且可以作为一个启动点，从中能够发现和访问用来管理服务的必要工具。</p><p></p><h2>控制台平台的初始理念</h2><p></p><p>PXD团队希望利用他们在Netflix Studio部门中GraphQL Federation的成功经验来建立控制台的后端架构。GraphQL Federation允许用户建立一个领域图服务（domain graph service，DGS），将其服务作为单个联合图的一部分对外进行暴露，这个联合图可以被一个联合图网关来访问。当网关处理请求时，它会委托对应的DGS来完成该请求中引用的所有字段。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ea/ea7f5edaee209e6ff24981f77cd5f23c.jpeg\" /></p><p></p><p>该团队对基于GraphQL平台API的投资不仅可以为新的平台控制台提供动力，还可以为其他体验提供支持，包括更专用的UI、CLI和Slack bot。</p><p></p><p>对于前端，平台体验和设计团队希望跨多个平台团队和服务提供联合方案，这些服务会在平台控制台中汇聚在一起。他们知道，这项工作的范围不是一个团队可以实现的，需要利用领域的专业知识，以及平台、供应商和合作伙伴的代码贡献。</p><p></p><h2>利用Netflix内部的设计系统Hawkins</h2><p></p><p>PXD的第一站是Netflix的内部设计系统Hawkins，它有80多个应用。这些应用为Netflix的内容生产提供了支撑，其范围涵盖从初始评估，到财务预测以及资产交付。在所有的平台产品中使用Hawkins可以实现更多的跨工具工作流，并为用户提供一致的体验。</p><p></p><p>按照设计，Hawkins是可重用、可配置和可组合的，它为套件中的所有应用提供了一致的用户体验，降低了用户的学习曲线。它允许工程师重用组件、工具集和设计模式，这提升了效率，同时降低了成本。</p><p></p><h2>调查现有的开源和专有方案</h2><p></p><p>Leathem的团队并不想直接开发另一个开发人员门户和服务目录，并将其置于他们的平台之上。相反，他们首先评估了可以解决这个问题的开源和专有工具，他们基于终端用户和平台合作伙伴供应商的需求和期望来考虑这些工具。团队最终确定Backstage是最适合其使用场景的工具。</p><p></p><p>Backstage是Spotify的开源开发人员门户，基于如下原因，它非常适合该团队：</p><p>Backstage在前端和后端之间实现了松耦合，允许团队轻松整合现有的后台解决方案，包括联合GraphQL。Backstage UI技术与PXD的专业技能非常契合。Backstage的插件是轻量级的。</p><p></p><h2>对比使用Backstage与重新构建一个开发人员门户</h2><p></p><p>使用Backstage（现有的开源工具）与构建一个定制的内部解决方案相比，好处在什么地方呢？为了回答这个问题，PXD根据其功能和各自的要素进行了评估。借助Wardley Map，它们评估了将开发人员资源投入到从头创建一个内部工具，或基于Backstage进行构建，以确定哪个方案更好。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cd/cd02fc920a1f028867482af7e72b49db.jpeg\" /></p><p>“我们确定了系统的各个组件，根据它们对最终用户体验的影响程度对其进行纵向定位，并根据它们在行业中的商业化程度进行横向定位。组件被分解成组件，抽取出已经被商业化的组成部分”——Brian Leathem</p><p></p><p>Wardley Map是一种可视化技术，它将组织的开发速度与价值链进行对比，并形成自定义UI组件对商业成功关键程度的见解。该团队发现，最关键的增值部分是自定义UI组件，这些组件是通过明确每个平台的特性、功能和特征而形成的。他们意识到，与其重建Backstage上的插件和核心API，不如将开发资源投入到创建自定义UI组件上。</p><p></p><h2>通过联合平台控制台MVP的提供连接体验</h2><p></p><p>开发平台控制台MVP（最小化可行产品，Minimum Viable Product）的最初目标是建立一个具有共同入口的连接体验，让开发人员在整个SDLC中查看和访问项目的状态，然后链接控制台中现有的工具。计划随着的时间推移有了新的变化，将控制台从连接体验升级为集成体验，并最终升级为一个平台，让组织所有的周边工具得到全面管理。</p><p></p><p>在设计和开发这些插件时，团队很谨慎，没有简单地将现有的经验提升并转移到控制台中，而是利用这个机会重新思考用户从数据中所获取的经验和价值。为了解决管理多个服务软件的问题，他们引入了集合的概念。有了集合，用户可以将服务进行分组，一起查看和评估它们的状态。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f0/f01ebd4636b7acca3f466a6c40f0c4ee.jpeg\" /></p><p>Paved Roads通过一个中心化的产品仓库和组织框架，协助工程师为特定的问题找到合适的工具，在产品知识和工程过程之间搭起了桥梁。</p><p></p><p>控制台还包括为集合中的服务启动批量突变（bulk mutation）的能力，这个概念在Netflix的任何其他平台工具上还不存在。为了解决平台和工具的发现问题，Leathem和团队想出了Paved Roads这个概念，旨在将产品文档集中到一个地方，并且它们的组织方式能够帮助工程师找到解决其挑战的最佳工具。</p><p></p><h2>用户采用和反馈</h2><p></p><p>PXD团队一直在不断地推出MVP，让它出现在Netflix的工程师面前。MVP已经达到了提供最小价值特性集的目标，用户可以用它来查看和评估软件的状态。然而，团队通过用户反馈和新的研究发现，仅靠这种综合功能还不足以吸引开发人员，并打破他们围绕现有工具的既定常规思路和习惯。</p><p></p><p>因此，该团队正在研究将控制台插入现有的工作流程或完全创建新的工作流程，以推动用户使用该平台。他们还希望用新的功能来丰富控制台，希望用户能够围绕平台控制台形成新的常规思路和习惯，并有机地将其添加到他们的工具链中。</p><p></p><h2>总结</h2><p></p><p>以下是Brian Leathem在虚拟PlatformCon 2022会议上分享的主要内容总结：</p><p>联合平台控制台有助于统一Netflix的工程体验，为开发者提供一个共同的入口来查看和访问他们在整个SDLC中的项目状态。Brian和他的团队创建的平台控制台MVP已经达到了提供这种最小价值特性集的目标，用户可以用它来查看和评估其软件的状态。该团队正在考虑将控制台插入现有的工作流程或完全创建新的工作流程，以推动用户使用该平台。他们还希望用新的功能来丰富控制台，希望用户能围绕平台控制台形成新的常规思路和习惯，并有机地将其添加到他们的工具链中。该团队承认，仅仅整合功能是不够的。为了成功，平台控制台必须被整合到现有的工作流程中，或者创造出对开发人员来说有足够价值的新工作流程，以打破他们既定的常规流程。</p>",
    "publish_time": "2023-03-11 10:50:32",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Palo Alto Networks的平台工程",
    "url": "https://www.infoq.cn/article/efE1d6fhN3C10ZGoNgZ6",
    "summary": "<p>本文最初发布于Palo Alto Networks工程博客。</p><p>&nbsp;</p><p>我一直在思考，我在Palo Alto Networks公司的第一篇博客应该写什么，什么时候发表合适。我觉得，要回顾我领导云基础设施和平台工程的旅程和经验，现在就是一个完美的时间。</p><p>&nbsp;</p><p>我于2021年4月加入Palo Alto Networks，负责网络安全组织下云交付安全服务组织的生产工程团队，最近又承担了一个延伸角色，负责整个NetSec组织的基础设施平台。在这篇博文中，我将探讨下我们如何将生产工程服务转化为平台。首先，我将概要地介绍下我们的内部开发平台（IDP）。</p><p>&nbsp;</p><p>让我们先快速了解一下PAN IDP的启动背景。以下是促使我们踏上这段旅程的两个主要因素：</p><p>Palo Alto Networks的平台方法：众所周知，Palo Alto Networks是网络安全的领导者，其成功的主要原因之一是其网络安全解决方案的平台方法。我们已经将这一理念应用于构建一个包含基础设施配置、成本管理、可观察性和事件管理等生产工程服务的平台，而不是将这些服务作为孤立的自动化解决方案提供给工程团队。自助开发工具：遗留生产工程/DevOps/SRE实践的一个主要问题源于提供相关文档的独立自动化脚本；人们必须阅读许多页的文档或者咨询主题专家才能理解和运行这些工具。</p><p>&nbsp;</p><p>一旦我们决定采用平台方法，接下来的挑战就是决策：是内部开发还是购买。经过仔细分析，我们决定针对Palo Alto Networks特有的用例专门构建一个。我们的理念不是重新发明轮子，而是设法利用开源项目来实现飞跃。我们的团队发现，我们可以从一个很棒的开源项目<a href=\"https://backstage.io/\">backstage.io</a>\"开启我们的旅程。我们将后台OSS代码分叉，添加了必要的抽象，并将其命名为“Palo Alto Networks DevClues”。</p><p>&nbsp;</p><p>我们实现的第一个用例是“服务目录”，用于帮助开发人员或SRE轻松快速地找到特定生产服务的详细信息。现在，经过一年半的发展，我们的IDP已经提供了相当多的处于不同采用阶段的服务，如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/82/82fb8a8e96cc4f487f52523e3f7f797e.png\" /></p><p></p><p>该平台包括4类服务：资源管理、基础设施管理、生产管理和开发者门户。开发者门户（DevClues）是平台提供的所有服务的入口点（一站式商店）。例如，如果任何工程团队想要将他们的服务安装到可观察性类别下，他们就可以简单地登录到开发者门户网站，并使用安装插件（由可观察性团队贡献的自定义插件）来完成可观察性集成。</p><p>&nbsp;</p><p>如今，开发者门户（DevClues）提供了12个插件和数十个服务模板，提高了整体的工程效率。我们将继续根据我们的工程需求构建更多的模板和插件。我还想指出的是，其中一些是由开发团队（即我们的客户）贡献的。因此，我们从第一天起就采用了内部开源模式（即内部外包）。</p><p>&nbsp;</p><p>接下来，我将简要介绍下Palo Alto Networks IDP的4个服务类别，以及根据<a href=\"https://www.gartner.com/en/documents/4010078\">2022年高德纳发布的报告</a>\"，这些能力与以下开发生命周期阶段的关系：</p><p>发现与创建集成与部署运营与改进</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/89/89c2be65a81ba8c383bc321537b2c157.png\" /></p><p></p><p>图1：Palo Alto Networks IDP概述（在Gartner报告的语境下）</p><p>&nbsp;</p><p>现在，让我们分阶段看下相关的IDP功能。</p><p>&nbsp;</p><p></p><h1>发现与创建（第0天）</h1><p></p><p>发现与创建阶段涵盖了开发生命周期的初始部分，包括安装、培训、启动、本地开发等，如图1所示，所有这些功能都是Palo Alto Networks“开发者门户”的一部分。</p><p>&nbsp;</p><p></p><h2>开发者门户（Palo Alto Networks DevClues）</h2><p></p><p>如前所述，DevClues基于开源项目<a href=\"https://backstage.io/\">backstage.io</a>\"。这是一个一站式商店，包含基础设施平台提供的所有内部服务。现在，我们将详细看下DevClues的每个功能。</p><p>&nbsp;</p><p>内部开发者门户应该使开发人员在软件交付生命周期（SDLC）的所有阶段都能够轻松地执行第0天、第1天和第2天的活动。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/40/4020a7f142f95e79b8b1787a6344227f.png\" /></p><p></p><p>图2：Palo Alto Networks DevClues首页</p><p>&nbsp;</p><p>Palo Alto Networks DevClues为开发人员提供了可以直接使用的服务模板，其中嵌入了新建软件应用程序、服务和基础设施组件的最佳实践。</p><p>&nbsp;</p><p></p><h2>服务目录</h2><p></p><p>该功能使开发人员能够轻松快速地搜索和查找生产服务（如On Boarded into DevClues），包括：</p><p>可用的服务及其元数据（即所有者和电话值班工程师）它们的API规范其他详细信息，如文档、CICD统计、代码覆盖率和如下所示的DORA指标</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/eb/eb2a1114c0a97d4b67cfa68194313054.png\" /></p><p></p><p>图3：服务目录中的服务概述</p><p>&nbsp;</p><p></p><h2>服务生成模板</h2><p></p><p>该功能使开发人员可以基于预定义的模板创建新的服务、基础设施组件或应用程序。目前，DevClues为Go、Python和React应用程序开发提供了一套服务模板，为“GKE集群启动”和“GitOps安装”（借助GitLab和argoCD）提供了基础设施组件配置模板。</p><p>&nbsp;</p><p></p><h2>文档和培训资料</h2><p></p><p>这有助于开发人员了解如何以自助服务的方式最大限度地利用平台，并促进平台社区的发展，让来自不同服务团队的个人成为平台专家，帮助他们的团队实现自己的目标，而不必等待平台团队提供信息或帮助。其中包括：</p><p>平台使用指南培训文档和视频社区培训（brown-bags）和辅导（office hours）</p><p>&nbsp;</p><p></p><h2>自动支持&amp;搜索</h2><p></p><p>为开发人员提供自助查找平台及其特性信息的方法，响应开发人员的提问，并自动帮助解决问题，其中包括：</p><p>全局搜索所有可用的文档、指南和示例联系平台团队的Slack或电子邮件链接聊天机器人协助安装</p><p>&nbsp;</p><p></p><h2>最佳实践指南和工具</h2><p></p><p>为开发人员提供架构最佳实践：</p><p>模板和自助解决方案生产就绪指南SRE最佳实践和标准</p><p>&nbsp;</p><p></p><h2>自定义插件</h2><p></p><p>DevClues是使Palo Alto Networks开发人员能够构建内部工具和流程的门户。在Palo Alto Networks，我们有以下插件：</p><p>云计算成本可观察性安装事件分析基础设施管理证书管理新增云区域编辑自动修正生产审计日志适合“内部采购”的内部项目市场</p><p>&nbsp;</p><p></p><h1>集成与部署（第1天）</h1><p></p><p>集成与部署阶段包括将应用程序部署到非生产/生产环境、分布式系统集成、资源配置等。提供一个统一的仪表板，管理跨云和本地环境管理分布式基础设施。以下是当前提供的功能，它们分属于基础设施管理和生产管理两个类别。</p><p>&nbsp;</p><p></p><h2>基础设施准备&amp;编排</h2><p></p><p>在Palo Alto Networks，我们构建了一个DevClues插件Uno（如图4），它可以帮助开发人员为使用GitOps的服务/应用准备和配置云资源和其他基础设施组件。这包括：</p><p>在私有云和公有云中按需提供资源将所有必需资源定义为符合最佳实践的代码</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c9/c903fa19191fe1b1f295a041f9e55eba.png\" /></p><p></p><p>图4：Uno —— 用于多云基础设施管理的DevClues插件</p><p>&nbsp;</p><p></p><h2>策略管理</h2><p></p><p>在资源和应用/服务运行上执行业务、运营和最佳实践策略。我们已经实现了一个基于OPA（开放策略代理）的“控制平面”来帮助实现：</p><p>所有内部门户和底层API的授权（RBAC）将资源配置限制为允许值（即CICD）执行特定的注解/标签</p><p>&nbsp;</p><p></p><h2>环境管理</h2><p></p><p>我们构建的用于管理基础设施资源的DevClues插件经过扩展后，可以轻松创建、配置和管理服务/应用环境，例如：</p><p>轻松添加新环境/区域，或删除旧环境/区域创建和删除用于开发和测试的临时环境</p><p>&nbsp;</p><p></p><h2>秘密管理</h2><p></p><p>在Palo Alto Networks，这项功能提供了一项服务，可以管理生产环境中的证书、秘密和配置同步，以便可以安全地：</p><p>将秘密管理系统与部署/交付系统自动集成在一个集中的存储库中存储/调换它们的配置、秘密和证书（即vault或GSM或ASM）当相应的秘密/证书/配置发生变化时，无缝地重新配置/加载应用，它们运行在K8s、Docker和本地Linux进程上</p><p>&nbsp;</p><p></p><h1>运营与改进（第2天）</h1><p></p><p>这个阶段通过DevClues插件访问工具箱，获得自动化、监控、可观察性和事件管理等功能，实现连续操作。</p><p>&nbsp;</p><p>在Palo Alto Networks，运营与改进阶段的能力分布在三个类别中——生产管理、基础设施管理和资源管理。</p><p>&nbsp;</p><p></p><h2>监控和可观察性</h2><p></p><p>监视和可观察性是Palo Alto Networks的关键生产工程服务之一。我们已经建立了一个名为“Garuda”的内部可观察性平台，使用了一些成熟的开源技术，如Grafana、Grafana Mimir、Grafana Loki、Grafana Tempo和<a href=\"https://vector.dev/\">vector.dev</a>\"。我们很快将单独发表一篇博文，深入介绍Garuda及其能力。</p><p>&nbsp;</p><p>Garuda现在提供的功能包括：</p><p>日志和事件跟踪指标报警仪表板</p><p>&nbsp;</p><p>我们为Garuda构建了一个DevClues插件（见下图5），以便工程团队可以轻松地将他们的基础设施和服务/应用安装到“可观察性平台”。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b9/b967eb507b2543f2cb2ac0c7879c53c0.png\" /></p><p></p><p>图5：DevClues中的Garuda安装插件</p><p>&nbsp;</p><p>监控和可观察性的主要挑战之一是不同资源类型（云、本地、K8s、VM、无服务器和裸金属）的复杂安装过程。通过这个插件，我们使安装过程尽可能地顺畅无停顿。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c9/c9712c74915b7bf35054aa15c24e405f.png\" /></p><p></p><p>图6：Garuda代理安装</p><p>&nbsp;</p><p></p><h2>事件管理</h2><p></p><p>有效的事件管理是SRE最佳实践的一个关键方面，当影响业务的事件/中断发生时，我们可以及时提醒和通知工程师，并提供管理这些事件的工具，其中包括：</p><p>事件管理仪表板事件分析用于提醒和创建Slack Channel的工具</p><p>&nbsp;</p><p>我们的DevClues事件分析插件提供了以下洞察：</p><p>按日统计的事件按小时统计的事件按组件统计的事件按团队统计的事件事故修复与发生对比按组件/服务统计的重复事件</p><p>&nbsp;</p><p></p><h2>自动修复</h2><p></p><p>根据最近的一项行业研究，30-50%的生产事故是重复的，并导致了大多数SRE工作。我们希望通过自动化来解决这个问题，因此建立了一个名为“Nutrix”的系统，即我们基于开源项目<a href=\"https://stackstorm.com/\">stackstorm</a>\"构建的内部自动修复平台。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9e/9e01f37463963a1d97c6b46ab0c29a76.png\" /></p><p></p><p>图7：DevClues中的Nutrix插件</p><p>&nbsp;</p><p>同样，提升自动化应用的主要瓶颈之一是没有一个健壮的编辑框架，因此，我们在DevClues Nutrix插件中构建了编辑框架，如下所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/74/746f5e77404762091877a56cbf80926c.png\" /></p><p></p><p>图8：DevClues中的Nutrix自动修复编辑</p><p>&nbsp;</p><p></p><h2>洞察仪表板</h2><p></p><p>仪表板利用可观察性和监控数据来诊断问题和调试运行中的系统，以减少MTTR（平均解决时间），其中包括：</p><p>主机360仪表板证书360仪表板Kubernetes 360仪表板成本洞察</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e6/e6cd5d67495f0f4ca418021d829b236f.png\" /></p><p></p><p>图9：Garuda主机360仪表板</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f1/f1ca2aea379a1ec9841d3845fa3ba4f7.png\" /></p><p></p><p>图10：Garuda证书360仪表板</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/19/19784f88052509c79ae68f28f831ec71.png\" /></p><p></p><p>图11：Garuda Kubernetes 360仪表板</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e5/e576847f3ebf1cc9431fcc34d160424b.png\" /></p><p></p><p>图12：Garuda Kubernetes 成本洞察仪表板</p><p>&nbsp;</p><p></p><h2>IAM</h2><p></p><p>管理身份信息，以及用户和工具对云资源和系统的访问。</p><p>&nbsp;</p><p>下面是几个例子：</p><p>根据角色管理K8s集群的访问等级，如服务操作员和集群操作员进行不同的访问定义RBAC权限来执行部署，更新服务/应用及资源的配置将堡垒机作为访问生产基础设施的服务即时访问管理</p><p>&nbsp;</p><p></p><h2>安全和合规管理</h2><p></p><p>Palo Alto Networks的信息安全团队负责定义和执行安全策略以及自动化验证和检查，但修复是工程团队的责任，其中包括：</p><p>安全审查和审批（信息安全）漏洞扫描和检查（信息安全）漏洞修复（工程）实现符合业务策略的措施的框架（平台工程）遵循治理规则和法规的框架（平台工程）</p><p>&nbsp;</p><p></p><h2>成本管理</h2><p></p><p>在多云和混合云世界中，基础设施成本成了一个热门话题。毫无疑问，成本需要持续地监测、报告和优化。</p><p>&nbsp;</p><p>在Palo Alto Networks，我们开始从两个维度来解决这个问题，即自上而下和自下而上：</p><p>自上而下——由FinOps和CloudOps驱动执行团队在组织和业务单元层面推动成本优化；自下而上——由基础设施平台和工程团队驱动，为了优化成本，我们提供了各个云资源或用户级的详细成本洞察，包括异常检测和自动化。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ed/ed18ab70414d7821dbbdc05b3f2371bb.png\" /></p><p></p><p>图13:DevClues SKU级的成本洞察</p><p>&nbsp;</p><p></p><h2>配置管理</h2><p></p><p>在云世界中，基础设施管理有两个重要的方面，即基础设施准备和配置。在Palo Alto Networks，我们用Terrform标准化了基础设施准备，用Ansible标准化了配置管理。</p><p>&nbsp;</p><p>开发人员应该用一种可伸缩且可靠的方式来管理应用程序的配置，就像我们对源代码或基础设施即代码（IaC）进行管理和版本控制那样。</p><p>&nbsp;</p><p>为了更好地管理Ansible代码，我们采用了<a href=\"https://www.ansible.com/products/controller\">Ansible Tower</a>\"的开源版本<a href=\"https://github.com/ansible/awx\">awx</a>\"，帮助开发人员/SRE标准化配置的部署、初始化、下发和审计。</p><p>&nbsp;</p><p></p><h2>资源管理</h2><p></p><p>在Palo Alto Networks，资源和基础设施管理是密不可分的。DevClues的Uno插件旨在提供简单流畅的基础设施准备和端到端管理，其中包括：</p><p>以代码形式管理Kubernetes集群和组件，并利用最佳实践和持续部署；以代码的形式管理跨云提供商的虚拟机，并利用最佳实践；云供应商资源管理；例如：谷歌BigQuery、CloudSQL、Cloud Run、Cloud Functions等。</p><p>&nbsp;</p><p></p><h1>小结</h1><p></p><p>根据Gartner的报告，到2025年，75%拥有平台团队的组织将提供自助服务开发者门户，以改善开发体验并加速产品创新。</p><p>&nbsp;</p><p>IDP的采用与组织DevOps、SRE和平台工程实践的成熟度成正比。所以，成熟度指数越高，他们使用开发者门户的可能性就越高。</p><p>&nbsp;</p><p>Palo Alto Networks的平台工程团队致力于通过管理IDP采用、路线图、收集来自工程团队的反馈以及推广其功能来不断创新。</p><p></p><p>声明：本文为InfoQ翻译，未经许可禁止转载。</p><p>&nbsp;</p><p>原文链接：<a href=\"https://medium.com/engineering-at-palo-alto-networks/platform-engineering-at-palo-alto-networks-part-1-e48afdcfb1f8\">https://medium.com/engineering-at-palo-alto-networks/platform-engineering-at-palo-alto-networks-part-1-e48afdcfb1f8</a>\"</p>",
    "publish_time": "2023-03-11 11:08:47",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Log4j一周年观察：我们如何应对日益严峻的软件供应链安全风险？",
    "url": "https://www.infoq.cn/article/WMs7uoxvNLc1J5qBMtoR",
    "summary": "<p>2021年12月10日，全球知名开源日志组件Apache Log4j被曝存在严重高危险级别远程代码执行漏洞，这个“核弹级”的漏洞时至今日影响仍然存在，InfoQ在《<a href=\"https://www.infoq.cn/article/ftjYfScOfpLFLTIUvwGe\">开源意味着不问责，我们准备好应对比 Log4Shell 更大的安全危机了吗？</a>\"》中表示2022 年本应是“供应链安全元年”，不幸的是，一年后的现在这个漏洞仍然普遍存在，修复版本采用率没有想象中的高，而且数据显示，软件供应链攻击频次反而呈现出急剧上升趋势。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/10/10ae19906ae5cef44e558ac438987322.png\" /></p><p></p><p>自 2019年以来软件供应链攻击的发展趋势，年平均增长率达到742%</p><p></p><p>软件供应链安全如今已经成了一个世界性难题。它的成因、为什么难以解决，以及企业如何应对，我们咨询了腾讯安全开发安全专家刘天勇。</p><p></p><p>问：当我们在说“软件供应链安全”的时候，我们实际上是在说什么？</p><p>答：基于中国信通院的定义，软件供应链安全是指“ 软件供应链上软件设计与开发的各个阶段中来自本身的编码过程、工具、设备或供应链上游的代码、模块和服务的安全，以及软件交付渠道及使用过程安全的总和。”</p><p></p><p>这里是把软件供应链安全分为了两部分。一是软件自身的供应链安全，二是软件供应链交界面的安全管理。</p><p></p><p>软件自身的供应链，可以简单理解为应用的代码来源，应用的代码来源主要有两个部分：一个是产品研发自己写的代码，另一个就是引入的第三方的开源组件代码。针对这两者的安全检测也是我们常说的开发安全。</p><p></p><p>软件供应链交接界面，针对的是开源软件或者商业采购第三方软件。这部分的供应链安全管理主要是在交付和使用过程中进行相关的准入检测并形成标准化可溯源的软件物料清单。</p><p></p><p>问：开源已经有十几年历史了，但是直到最近两三年，软件供应链安全才成为了一个世界性难题，这期间发生了什么变化？</p><p>答：软件供应链的安全的重要性提升和开源的大趋势是息息相关的，软件开源化的趋势是一个累积的过程，十几年的时间经历了一个量变到质变的阶段，现在全球的开发者都在依赖开源组件来做应用的研发，绝大多数现代代码库都包含开源组件。</p><p></p><p>但是开源的繁荣本身就建立在一系列自由许可协议和免责条款上——其中也包括风险免责，“使用者风险自负”是开源社区的共识。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/45/4528ec938dadec3a604e0df52ffbde8f.png\" /></p><p></p><p></p><p>21年底Apache Log4j风险的爆发是一个里程碑事件，软件供应链安全直接关系着关键基础设施和重要信息系统安全，保障软件供应链安全也成为业界关注焦点。</p><p></p><p>最近中证协向各大券商下发了一份征求意见稿（按：指《网络和信息安全三年提升计划(2023—2025)》），里面写到“在软件自主可控方面，要求券商提升自主掌控能力，不管自研还是外购代码全部代码100%审计，重要信息系统的自动化测试比例不低于整体测试比例 30%，从研发规范制定、研发工具建设方面建设统一的源代码管理工具、标准化的研发运维一体化工具”，这就是行业对于开源代码使用规范的一个表现。</p><p></p><p>问：从技术角度看，软件供应链安全治理的主要难点在哪里？</p><p>答：软件供应链安全的治理的难点可以分成以下三个部分：</p><p></p><p>第一个难点是检测门槛高，开源组件的来源复杂，依靠单一的技术手段难以做到全面覆盖。市面上常见的开源组件检测技术是基于源代码的SCA分析，但基于源码的SCA难以覆盖软件供应链交接界面的第三方软件成品；</p><p></p><p>第二个难点是修复成本高，在企业开始做开源组件的风险治理的时候，存量业务往往会发现大量的漏洞，但这些业务大多数处于上线运营的阶段，修复的过程对研发资源是一个较大的消耗，同时对安全团队来说也是较大的推动阻力。</p><p></p><p>第三个难点是攻击影响范围广，第三方开源组件的使用，间接扩大了软件的受攻击面，针对上游供应链环节的漏洞挖掘和恶意利用，能够快速覆盖大量的下游软件，同时相关的攻击具有较高的隐蔽性，常用的安全检测手段难以进行全面的防御，目前软件供应链攻击已经成为攻防演练中非常常用的攻击手段。</p><p></p><p>问：当前业界常见的开源组件检测技术有哪些？</p><p>答：SCA是目前业界主要的解决开源组件风险检测的手段。市面上的SCA产品主要有两条技术路线，一个是基于开源组件源代码进行分析，另一个是基于二进制制品进行分析。目前国内的安全厂商的产品主要是通过源代码层面去做的，而腾讯安全的SCA产品，在源代码分析的基础上，同时还支持二进制SCA分析，能够同时覆盖软件自身以及交接界面的软件供应链安全问题。</p><p></p><p>从技术原理上看，源码SCA分析主要是根据源码文件相似度或代码相似度检测，主要为依赖扫描；二进制SCA分析是从二进制文件中提取常量、函数特征来进行分析。</p><p></p><p>从使用场景来看，源码SCA能够全面的分析源码仓库，但在不能获得源码的情况下，不能检测商业采购的第三方软件安全包。二进制SCA分析可以直接分析安装包，同时不会因为源码而引入一些额外的，不会被带入构建产物的数据，影响分析结果。</p><p></p><p>和源代码SCA相比，二进制SCA的技术门槛更高，需要有效涵盖移动端，嵌入式，后台开发，云原生各种开发场景下的跨架构格式解析，同时要支持固件、镜像、文件系统、压缩文件等多种文件格式。得益于腾讯安全科恩实验室在物联网安全以及AI安全上过去多年的技术积累，腾讯的二进制SCA技术有着独家的技术领先优势。</p><p></p><p>问：腾讯本身是一个SCA的使用者，也提供SCA的工具，我们自身的实践情况是什么样的？</p><p>答：腾讯的SCA是作为腾讯整个DevSecOps解决方案中的一环进行落地的，我先介绍下腾讯DevSecOps的整体实践。</p><p></p><p>目前腾讯的开发业务已经全量上线自研的DevOps平台，我们包括SAST、IAST、DAST、SCA在内的各类开发安全检测工具都和DevOps平台做了深度的集成和联动，相关检测工具会作为开发流水线中的自动化质量门禁红线，进行相关的卡点检测。</p><p></p><p>除了在流水线中进行使用外，我们的SCA产品还与自身的制品仓库进行对接， 实现了对制品的全面扫描和分析，生成了自身的SBOM软件物料清单，能够有效应对突发的软件供应链安全事件。此外，我们也将SCA分析用到的开源组件知识库进行开放，开发同事可以在开发阶段自查CVE风险以及License风险</p><p></p><p>问：供应链安全肆虐，给企业的建议？</p><p>答：1、&nbsp; 面向研发团队，强化开发安全意识培训以及安全编码规范的落地，提升自身研发的安全水平</p><p>2、&nbsp; 针对自研应用，完成包括SCA、SAST、IAST在内的开发安全工具建设并全面接入DevOps流程，实现安全左移</p><p>3、&nbsp; 针对第三方软件，建立标准的准入检测机制，借助二进制SCA工具实现对第三方软件的安全评估</p><p>4、&nbsp; 借助SCA工具，完成企业自身的SBOM软件物料清单建设，同时拉通安全和研发团队，制定软件供应链安全事件的应急响应流程制度</p>",
    "publish_time": "2023-03-11 11:35:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "查询性能较 Trino/Presto 3-10 倍提升！Apache Doris 极速数据湖分析深度解读",
    "url": "https://www.infoq.cn/article/8SU754VFuKpw8gwjF24v",
    "summary": "<p>从上世纪 90 年代初 Bill Inmon 在《building the Data Warehouse》一书中正式提出数据仓库这一概念，至今已有超过三十年的时间。在最初的概念里，数据仓库被定义为「一个面向主题的、集成的、相对稳定的、反映历史变化的数据集合，用于支持管理决策」，而数据湖最初是为了解决数仓无法存储海量且异构的数据而构建的集中式存储系统。</p><p></p><p>时代的发展与用户数据应用诉求的演进，催生了数据架构的不断革新，也衍生了更复杂的技术形态。可以清晰看到现代数据架构从计算到存储都在向着融合统一的方向发展，新的数据湖范式被提出，这也是 Lakehouse 诞生的背景。作为一种全新的、开放式的数据管理架构，Lakehouse 提供了更强的数据分析能力与更好的数据治理能力，也保留了数据湖的灵活性与开放式存储，为用户带来更多价值：</p><p></p><p>从存储的角度：统一数据集成，避免冗余存储以及跨系统间 ETL 带来的繁重工程和失败风险；从治理的角度：支持 ACID、Schema Evolution 与 Snapshot，数据与元数据皆可治理；从应用的角度：多引擎访问支持、可插拔，通过统一接口进行数据访问，同时适用于多种工作负载 Workload；……</p><p></p><p>如果我们把 Lakehouse 从系统层面进行解构，会发现除了需要 Apache Iceberg、Apache Hudi 以及 Delta Lake 等数据湖表格式（Table Format）以外，高性能分析引擎更是充分发挥湖上数据价值的关键。</p><p></p><p>作为一款极速易用的开源实时 OLAP 数据库，Apache Doris 自 0.15 版本即开始尝试在 Apache Iceberg 之上探索与数据湖的能力结合。而经过多个版本的优化迭代，Apache Doris 在数据湖分析已经取得了长足的进展，一方面在数据读取、查询执行以及优化器方面做了诸多优化，另一方面则是重构了整体的元数据连接框架并支持了更多外部存储系统。因此 Apache Doris 已经完全具备了构建极速易用的 Lakehouse 架构的能力，并且也已在多个用户的真实业务场景中得到验证和推广，我们希望通过 Apache Doris 能为用户在更多场景中带来价值：</p><p></p><p>湖仓查询加速利用 Apache Doris 优秀的分布式执行引擎以及本地文件缓存，结合数据湖开放格式提供的多种索引能力，对湖上数据及文件提供优秀的查询加速能力，相比 Hive、Presto、Spark 等查询引擎实现数倍的性能提升。统一数据分析网关利用 Apache Doris 构建完善可扩展的数据源连接框架，便于快速接入多类数据源，包括各种主流关系型数据库、数据仓库以及数据湖引擎（例如 Hive、Iceberg、Hudi、Delta Lake、Flink Table Store 等），提供基于各种异构数据源的快速查询和写入能力，将 Apache Doris 打造成统一的数据分析网关。统一数据集成基于可扩展的连接框架，增强 Doris 在数据集成方面的能力，让数据更便捷的被消费和处理。用户可以通过 Doris 对上游的多种数据源进行统一的增量、全量同步，并利用 Doris 的数据处理能力对数据进行加工和展示，也可以将加工后的数据写回到数据源，或提供给下游系统进行消费。该能力使得 Apache Doris 能够成为业务的统一数据枢纽，降低数据流转成本。更加开放的数据生态通过对 Parquet/ORC 等数据格式以及开放的元数据管理机制的支持，用户不用再担心数据被特定数据库引擎锁定，无法被其他引擎访问，也不用再为数据的迁移和格式转换付出高昂的时间和算力成本，降低用户的数据迁移成本和对数据流通性的顾虑，更便捷、放心地享受 Apache Doris 带来的极速数据分析体验。</p><p></p><p>基于以上的场景定位，我们需要进一步去思考在构建 Lakehouse 过程中需要如何去设计和改造系统，具体包括：</p><p></p><p>如何支持更丰富的数据源访问以及更便捷的元数据获取方式；如何提升湖上数据的查询执行性能；如何实现更灵活的资源调度与负载管理；</p><p></p><p>因此本文将重点介绍 Apache Doris 在 Lakehouse 上的设计思路和技术细节，同时会为大家介绍后续的发展规划。</p><p></p><h1>元数据连接与数据访问</h1><p></p><p>截至最新的 1.2.2 版本，Apache Doris 已经提供了十余种的数据湖格式和外部数据源的访问支持。同时也支持通过 Table Value Function 直接对文件进行分析。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1b/1b181997febeadb60abe5c1d75b219c7.png\" /></p><p></p><p>为了支持这些数据源，Apache Doris 分别在元数据连接和数据访问两方面做了大量的架构调整和性能优化 。</p><p></p><h2>元数据连接</h2><p></p><p>元数据包括数据源的库、表信息、分区信息、索引信息、文件信息等。不同数据源的元信息格式、组织方式各有不同，对于元数据的连接需要解决以下问题：</p><p></p><p>统一的元数据结构：屏蔽不同数据源的元数据差异。可扩展的元数据连接框架：低成本、快速地接入数据源。高效的元数据访问能力：提供可靠、高效的元数据访问性能，并支持实时同步元数据变更。自定义鉴权服务：能够灵活对接外部的权限管理系统，降低业务迁移成本。</p><p></p><h3>统一的元数据结构</h3><p></p><p>在过去 Apache Doris 的元数据只有 Database（数据库） 和 Table（表）两个层级，当外部数据目录 Schema 发生变化或者外部数据目录的 Database 或 Table 非常多时，需要用户手工进行一一映射，维护量非常大。因此在 Apache Doris 1.2.0 版本中新增了 Catalog（数据目录）层级，提供了快速接入外部数据源的能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/51/513630b002c9573fec02262947be702d.png\" /></p><p></p><p>Catalog 层级的引入解决以下问题：</p><p></p><p>数据源层级的映射：用户不再需要在 Database、Table 层级进行一一映射，可以通过 Catalog 直接映射整个数据源，自动同步其中的所有元信息，简化元数据映射逻辑数据源统一信息管理：在 Catalog 层级统一维护指定数据源的属性，如连接信息、权限信息、同步方式等，更方便的管理多个数据源。</p><p></p><p>引入 Catalog 层级后，我们也对 Doris 的元数据进行调整和划分：</p><p></p><p>Internal Catalog：原有的自管理的 Table 和 Database 都归属于 Internal Catalog。External Catalog：用于对接其他非自管理的外部数据源。比如 HMS External Catalog 可以连接到一个 Hive Metastore 管理的集群、Iceberg External Cataog 可以连接到 Iceberg 集群等。</p><p></p><p>用户可以使用 SWITCH语句切换不同的 Catalog，也可以通过全限定名方便的进行跨数据源的联邦查询，如：</p><p></p><p><code lang=\"text\">SELECT * FROM hive.db1.tbl1 a JOIN iceberg.db2.tbl2 b\nON a.k1 = b.k1;\n</code></p><p></p><p>相关文档：https://doris.apache.org/zh-CN/docs/dev/lakehouse/multi-catalog</p><p></p><h3>可扩展的元数据连接框架</h3><p></p><p>基于新的元数据层级，用户可以通过 CREATE CATALOG语句方便的添加新的数据源：</p><p></p><p><code lang=\"text\">CREATE CATALOG hive PROPERTIES (\n    'type'='hms',\n    'hive.metastore.uris' = 'thrift://172.21.0.1:7004',\n);\n</code></p><p></p><p>在数据湖场景下，目前 Doris 支持的元数据服务包括：</p><p></p><p>Hive Metastore 兼容的元数据服务Aliyun Data Lake FormationAWS Glue</p><p></p><p>同时，开发者也可以自行扩展 External Catalog，只需要实现对应的访问接口，即可在 Doris 中快速接入新的元数据服务。</p><p></p><h3>高效的元数据访问</h3><p></p><p>元数据存储在外部数据源中，而对外部数据源的访问受到网络、数据源资源等限制，性能和可靠性是不可控的。所以 Doris 需要提供高效、可靠的元数据服务以保证线上服务的稳定运行，同时 Doris 也需要实时感知元数据的变更，提升数据访问的实时性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/70/708eaf383c299d6f9e2649e6d1303bb7.png\" /></p><p></p><p>Doris 通过内存中的元数据缓存提供高效的元数据服务。元数据缓存包括列信息缓存，分区缓存，文件缓存。 通过元信息缓存，可以显著提升元数据访问性能并降低对外部元数据服务的请求压力，使得Doris 可以应对数千张表，数十万分区场景下，毫秒级别的元数据查询响应。</p><p></p><p>Doris 支持在 Catalog/Database/Table 级别，对元数据缓存进行手动刷新。同时，针对 Hive Metastore，Doris还支持通过监听 Hive Metastore Event 自动同步元数据，提供元数据秒级实时更新能力。</p><p></p><h3>自定义鉴权服务</h3><p></p><p>外部数据源通常拥有自己的权限管理服务，而很多企业也会使用统一的权限管理系统（例如 Apache Ranger）来管理多套数据系统。Doris支持通过自定义鉴权插件对接企业内部已有的权限管理系统，从而可以低成本的接入现有业务，完成授权、审计、数据加密等操作。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ef/ef001433107b277cfa6938dcd65ef2ea.png\" /></p><p></p><p>具体实现上，用户可以基于 Doris 的 AccessController 接口实现插件对接相应的权限管理系统，并在创建 Catalog 时，指定对应的鉴权插件。通过这种机制，所有通过 Doris 对外部数据源的访问，都将统一使用自定义的插件完成鉴权、审计等操作。</p><p></p><h2>数据访问</h2><p></p><p>外部数据源的数据访问，主要集中在对存储系统的访问支持上。在数据湖场景下，主要是对 HDFS 以及各种 S3 兼容的对象存储的支持。目前 Apache Doris 支持的存储系统如下，并且仍在不断增加中：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8a/8aef34ea47b4e37490eaf442d0947773.png\" /></p><p></p><h1>性能优化</h1><p></p><p>在实现数据源的连接和访问后，下一个问题是我们如何结合 Apache Doris 自身优异的查询性能以及各类存储系统的特性，进行针对性的查询性能优化，这也是在 构建 Lakehouse 过程中最需要解决的问题和权衡的因素。在具体实现过程中，Apache Doris 分别在数据读取、执行引擎、优化器方面进行了诸多优化。</p><p></p><h2>数据读取</h2><p></p><p>湖上数据通常存储在远端存储系统上，相较于本地存储，在数据的访问延迟、并发能力、IO 带宽上天然存在一定劣势。因此，在数据读取上，Apache Doris 从减少远端读取频率，降低读取量等方面出发进行了细致的优化。</p><p></p><h3>Native File Format Reader</h3><p></p><p>Parquet 和 ORC 是最常见的开放数据格式，这些数据格式本身提供了包括索引、编码、统计信息在内的多种特性，如何针对格式特性来提升文件读取效率是性能优化的关键一步。在早期的实现中，Apache Doris 是通过 Apache Arrow 来读取 Parquet/ORC 数据文件的，但这种方式存在以下问题：</p><p></p><p>数据格式转换的开销：Arrow Reader 需要先将文件读取成 Arrow 的内存格式，再转换到 Doris 自己的内存格式，两次数据转换带来额外的开销。无法支持高级文件格式特性。如不支持 Parquet 的 Page Index，不支持 Bloom Fitler，无法实现谓词下推、延迟物化等功能。</p><p></p><p>基于以上问题，我们对 Flile reader 进行了重构，实现了全新的 Native File Format Reader。这里我们以 Parquet Reader 为例，介绍 Doris 的文件格式读取方面所做的优化：</p><p></p><p>减少格式转换。新的 File Reader 直接将文件格式转换成 Doris 的内存格式，并可以直接利用字典编码等功能转换到对应的更高性能的内存格式，以提升数据转换和处理的效率。细粒度的智能索引。支持了 Parquet 的 Page Index，可以利用 Page 级别的智能索引对 Page 进行过滤。相比之前只能在 Row Group 级别过滤，Page Index 过滤粒度更细、过滤效果更好。谓词下推和延迟物化。延迟物化的基本逻辑是先读取有过滤条件的列，再使用过滤后的行号读取其他列。这种方式能显著降低文件的读取量。这一点在远程文件读取场景下尤为重要，可以最大限度减少不必要的数据读取。数据预读。 将多次文件读取合并成一次，充分利用远端存储高吞吐、低并发的特性，提高数据的总体吞吐效率。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fb/fbf4168dd1db96029948d88a0df8633a.png\" /></p><p></p><h3>File Cache</h3><p></p><p>利用本地高性能磁盘对远端存储系统中的文件进行本地缓存，能最大限度的减少远程数据读取的开销，同时可以提供接近 Doris 内部表数据的访问性能。在本地文件缓存方面 Doris 进行了如下优化：</p><p></p><p>文件块缓存（Block Cache） 。支持对远端文件进行 Block 级别的缓存。Block 的大小会根据读取请求自动调整，从 4KB 到 4MB 不等。Block 级别的缓存能有效减少缓存导致的读写放大问题，优化缓存冷启动场景下的数据读取延迟。缓存一致性哈希。通过一致性哈希算法对缓存位置和数据扫描任务进行管理和调度，充分利用已缓存的数据提供服务，并避免节点上下线导致缓存大面积失效的问题，提升缓存命中率和查询服务的稳定性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/960d6dc8a961774b760151ef18d08f15.png\" /></p><p></p><p>通过 Flie Cache，在命中缓存的情况下，Apache Doris 可以提供和本地表一致的查询性能。</p><p></p><h2>执行引擎</h2><p></p><p>在执行引擎层面，我们希望能够完全复用 Apache Doris 的向量化执行引擎以及各类执行层面的算子优化，为数据湖提供极速的查询体验。因此，Apache Doris 对数据扫描（Scan）节点进行了重构，使得每一种新的数据源的接入，开发者只需要关注数据源本身的访问逻辑，无需重复地开发通用功能。</p><p></p><p>通用查询能力的分层</p><p></p><p>包括内表在内的所有数据查询，都会使用相同的 Join、Sort、Agg 等算子。唯一不同在于数据源的访问方式上，例如对本地内部格式数据的读取，或存储在 S3 上的 Parquet 格式数据的读取。因此 Doris 将不同数据源的查询逻辑差异下推到最底层的 Scan 节点上。Scan 节点之上，所有查询逻辑统一，Scan 节点之下，由具体的实现类负责不同数据源的访问逻辑。</p><p></p><p>Scan 算子的通用框架</p><p></p><p>对于 Scan 节点，不同数据源也有很多共性的方面，如子任务的拆分逻辑、子任务的调度、IO 的调度、谓词下推以及 Runtime Filter 的处理等。因此我们也对这一部分架构进行了重构。首先，将共性部分都以接口的形式对外暴露，如子任务的拆分、下推谓词的处理等；其次，对子任务实现了统一的调度管理逻辑，可以由统一的调度器管理整个节点 Scan 任务的执行。调度器拥有节点全局的信息，可以方便的实现更细粒度的Scan 任务调度策略。在这样的统一的数据查询框架下，大约 1 人周就可以完成一种新数据源接入。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bc/bcb5c1fd08aab34a371bbe38c70f45ea.png\" /></p><p></p><h2>查询优化器</h2><p></p><p>查询优化器层面的优化集中在统计信息收集和代价模型的推导方面。</p><p></p><p>Apache Doris 支持对不同数据源的统计信息收集，如 Hive Metastore、Iceberg Metafile、Hudi MetaTable 中存储的统计信息等。同时在代价模型推导方面，我们也针对外部数据源的特性做了细致的调整。基于这些优化，Doris 可以为复杂的外表查询提供更优的查询规划。</p><p></p><h2>性能对比</h2><p></p><p>以上优先项，我们分别在宽表场景（Clickbench）和多表关联场景（TPC-H）下与 Presto/Trino 进行了 Hive 数据集的查询性能对比。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d3/d3bc4fde9398fca8225c418c9b5ba93a.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/40/40cde829687e8f5f8854da6f5f03a0c3.png\" /></p><p></p><p>可以看到，在相同计算资源和数据集下，无论是宽表场景或多表关联场景，绝大多数 SQL Apache Doris 的查询耗时都是大幅低于 Presto/Trino ，整体性能 相比 Presto/ Trino 有 3-10 倍的提升。</p><p></p><h1>负载管理与弹性计算</h1><p></p><p>对外部数据源的查询并不依赖 Doris 的数据存储能力，这也为 Doris 实现弹性的无状态计算节点成为可能。在即将发布的 2.0 版本中，Apache Doris 还实现了弹性计算节点功能（Elastic Compute Node），可以专门用于支持外部数据源的查询负载。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bf/bfea84a78c712f1aff996922b271a559.png\" /></p><p></p><p>由于计算节点是无状态的，因此我们可以对这类节点进行快速扩缩容，以灵活地应对峰谷期的查询负载，在查询性能与成本消耗之间取得更好的平衡。</p><p></p><p>同时，Doris 也针对 k8s 场景下的集群管理和节点调度进行了优化，Master 节点可以自动管理弹性计算节点的上下线，方便业务在云原生场景、混合云场景下都能便捷的管理集群负载。</p><p></p><h1>案例实践</h1><p></p><p>随着以上功能的完善与性能的提升，Apache Doris 已经被多家社区用户应用于数据湖分析，在真实业务中发挥着重要的作用，在此以某金融企业的风控场景为例。</p><p></p><p>金融风控场景往往对数据的实时性有着更高的要求，早期基于 Greenplum 和 CDH 搭建的风控数据集市已经无法满足其高时效性的需求，T+1 的数据生产模式成为业务迅速发展的掣肘，因此该企业于 2022 年引入 Apache Doris 并改造了整个数据生产和应用流程，实现对 Elasticsearch、Greenplum 以及 Hive 的联邦分析，整体效果包括：</p><p></p><p>只需创建一个 Hive Catalog 即可对现存的数万张 Hive 表进行查询分析，查询性能得到极大幅度提升；利用 Elasticsearch Catalog 实现对 ES 实时数据的联邦分析，数据时效性从过去的分钟级提升至秒级甚至毫秒级，满足了风控策略的实时性要求；将日常跑批与统计分析进行解耦，降低资源消耗的同时使系统稳定性得到进一步增强。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6b/6b78110aa36b17525cdeb863e95552f5.png\" /></p><p></p><h1>未来规划</h1><p></p><p>后续 Apache Doris 将持续在 Lakehouse 方向进行迭代和升级，下一步的工作将围绕在更丰富的数据源支持、数据集成和资源隔离与调度等方面：</p><p></p><h2>更丰富的数据源支持</h2><p></p><p>随着数据湖在各种业务场景中的不断落地，数据湖本身的功能也在不断迭代以满足越来越多样的业务需求。Doris也将和各个开源社区紧密合作，提供更完善的数据湖分析支持。</p><p></p><p>Hudi Merge-On-Read 表的 Incremental Query 支持利用 Iceberg/Hudi 丰富的索引功能，结合查询优化器提供更低延迟的分析性能。支持包括 Delta Lake、Flink Table Store 等更多数据湖格式。</p><p></p><h2>数据集成</h2><p></p><p>具体到功能层面，数据集成可以分为数据的读取和写回两部分。</p><p></p><p>数据读取方面，Doris 将进一步整合数据湖的数据访问特性，包括：</p><p></p><p>数据湖 CDC 的接入以及增量物化视图的支持，为用户提供近实时的数据视图。支持 Git-Like 的数据访问模式，通过多版本、Branch 等机制，在数据安全、数据质量等方面为用户提供更便捷的数据管理模式。</p><p></p><p>数据写回功能的支持，帮助 Doris 进一步完善统一数据分析网关的生态闭环。用户可以使用 Doris 作为统一数据管理入口，管理各个数据源中的数据，包括加工后数据的写回、数据导出等，对业务提供统一的数据视图。</p><p></p><h2>资源隔离与调度</h2><p></p><p>随着越来越多数据源的接入，Doris 也在逐步承接不同的工作负载，比如在提供低延迟的在线服务的同时，对 Hive 中 T-1 的数据进行批量处理。所以同集群内的资源隔离会愈发重要。</p><p></p><p>Doris 会持续优化弹性计算节点在不同场景下的调度管理逻辑，同时会支持更细粒度的节点内资源隔离，如 CPU、IO、内存等，帮助 Doris 支持多样且稳定的工作负载。</p><p></p><h1>加入我们</h1><p></p><p>目前社区已成立 Lakehouse SIG（湖仓兴趣小组），汇集了来自多家企业的开发者，旨在共同打造 Apache Doris 的 Lakehouse 场景支持，欢迎感兴趣的同学加入我们。</p><p></p><p># 相关链接：</p><p></p><p>SelectDB 官网：</p><p></p><p>https://selectdb.com</p><p></p><p>Apache Doris 官网：</p><p></p><p>http://doris.apache.org</p><p></p><p>Apache Doris Github：</p><p></p><p>https://github.com/apache/doris</p>",
    "publish_time": "2023-03-11 12:00:44",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]