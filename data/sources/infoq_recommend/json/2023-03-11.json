[
  {
    "title": "Netflix是如何利用联合平台控制台统一工程体验的",
    "url": "https://www.infoq.cn/article/3sYe2eD6ilfFyBWRt1fL",
    "summary": "<p></p><h3>摘要</h3><p></p><p>为了解决开发人员在日常工作中，面对工具和服务碎片化所带来的效率下降，Netflix的Brian Leathem团队开发了一个联合平台控制台，统一了开发人员的工程体验。</p><p></p><p>本文最初发表于<a href=\"https://platformengineering.org/talks-library/netflix-platform-console-to-unify-engineering-experience\">Platform Engineering网站</a>\"，由InfoQ中文站翻译分享。</p><p></p><p>大多数开发人员的日常工作都是低效的，主要是因为他们在构建、运行和扩展应用的时候，会使用数十种碎片化的服务和工具。这种低效在无意间会导致生产力的损失。对于小公司来说，碎片化的开发体验或许是可容忍的，但是随着业务的增长，统一它们的需求也会不断增长。</p><p></p><p>在Brian Leathem的带领下，Netflix的开发人员很早就采用了微服务架构，但是随着平台工具的增加，他们发现这种方式过于琐碎，于是，他们需要在公司的软件开发生命周期Software Development Life Cycle（SDLC）中统一开发人员的体验。在PlatformCon 2022上，Brian Leathem分享了如下的经验。</p><p></p><p>为了在Netflix的SDLC中统一开发人员体验，Netflix的平台体验和设计（Platform Experiences and Design，PXD）团队决定建立一个联合平台控制台（federated platform console）。Netflix的联合平台控制台是一个一站式的商店，提供了工程师开发和部署软件需要的所有工具。它将开发人员使用的几十种服务和工具整合到一个单一的、易于使用的界面中。</p><p></p><p>通过这个控制台，Netflix希望能够解决在与开发人员访谈时所发现的主要的碎片化挑战，其中包括：</p><p></p><h3>1.管理多个服务和软件</h3><p></p><p>开发人员每天都要使用太多的工具了，这给开发、交付以及运维服务和软件带来了挑战。例如，在整个SDLC过程中，开发人员需要分别使用Bitbucket来审查pull request，Spinnaker来检查部署流水线，Jenkins来检查构建失败，并且使用内部告警度量工具来检查运维状态等。除此之外，他们可能需要多次重复这些工作流程。</p><p></p><h3>2.平台发现</h3><p></p><p>Netflix的产品服务所有者已经为开发人员创建了工具和文档，但是很多开发人员不知道这些工具的存在。所有开发人员都无法立即知道他们的团队正在使用的众多工具和文档，他们可能会发现自己依赖于团队内传递给新成员的部落知识（tribal knowledge，这里指的是只有部落内部成员知道的信息，部落外面的人所不知道的知识，也就是所谓的小圈子——译者注）。另一方面，工作时间比较久的开发人员可能不知道为改善他们的日常工作流程而增加的新工具。</p><p></p><h3>3.在不同工具之间切换上下文</h3><p></p><p>当开发人员需要使用多个服务和工具时，他们需要在它们之间进行上下文切换。这可能会导致效率低下和错误，因为开发人员切换到另外一个工具时可能会忘记他们在当前工具中的工作。</p><p>Netflix的PXD团队很清楚，开发人员能够从一个平台控制台中获益，该控制台可以作为一个共同的入口，让他们能够从一个统一的地方来查看和评估其服务的状态，并且可以作为一个启动点，从中能够发现和访问用来管理服务的必要工具。</p><p></p><h2>控制台平台的初始理念</h2><p></p><p>PXD团队希望利用他们在Netflix Studio部门中GraphQL Federation的成功经验来建立控制台的后端架构。GraphQL Federation允许用户建立一个领域图服务（domain graph service，DGS），将其服务作为单个联合图的一部分对外进行暴露，这个联合图可以被一个联合图网关来访问。当网关处理请求时，它会委托对应的DGS来完成该请求中引用的所有字段。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ea/ea7f5edaee209e6ff24981f77cd5f23c.jpeg\" /></p><p></p><p>该团队对基于GraphQL平台API的投资不仅可以为新的平台控制台提供动力，还可以为其他体验提供支持，包括更专用的UI、CLI和Slack bot。</p><p></p><p>对于前端，平台体验和设计团队希望跨多个平台团队和服务提供联合方案，这些服务会在平台控制台中汇聚在一起。他们知道，这项工作的范围不是一个团队可以实现的，需要利用领域的专业知识，以及平台、供应商和合作伙伴的代码贡献。</p><p></p><h2>利用Netflix内部的设计系统Hawkins</h2><p></p><p>PXD的第一站是Netflix的内部设计系统Hawkins，它有80多个应用。这些应用为Netflix的内容生产提供了支撑，其范围涵盖从初始评估，到财务预测以及资产交付。在所有的平台产品中使用Hawkins可以实现更多的跨工具工作流，并为用户提供一致的体验。</p><p></p><p>按照设计，Hawkins是可重用、可配置和可组合的，它为套件中的所有应用提供了一致的用户体验，降低了用户的学习曲线。它允许工程师重用组件、工具集和设计模式，这提升了效率，同时降低了成本。</p><p></p><h2>调查现有的开源和专有方案</h2><p></p><p>Leathem的团队并不想直接开发另一个开发人员门户和服务目录，并将其置于他们的平台之上。相反，他们首先评估了可以解决这个问题的开源和专有工具，他们基于终端用户和平台合作伙伴供应商的需求和期望来考虑这些工具。团队最终确定Backstage是最适合其使用场景的工具。</p><p></p><p>Backstage是Spotify的开源开发人员门户，基于如下原因，它非常适合该团队：</p><p>Backstage在前端和后端之间实现了松耦合，允许团队轻松整合现有的后台解决方案，包括联合GraphQL。Backstage UI技术与PXD的专业技能非常契合。Backstage的插件是轻量级的。</p><p></p><h2>对比使用Backstage与重新构建一个开发人员门户</h2><p></p><p>使用Backstage（现有的开源工具）与构建一个定制的内部解决方案相比，好处在什么地方呢？为了回答这个问题，PXD根据其功能和各自的要素进行了评估。借助Wardley Map，它们评估了将开发人员资源投入到从头创建一个内部工具，或基于Backstage进行构建，以确定哪个方案更好。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cd/cd02fc920a1f028867482af7e72b49db.jpeg\" /></p><p>“我们确定了系统的各个组件，根据它们对最终用户体验的影响程度对其进行纵向定位，并根据它们在行业中的商业化程度进行横向定位。组件被分解成组件，抽取出已经被商业化的组成部分”——Brian Leathem</p><p></p><p>Wardley Map是一种可视化技术，它将组织的开发速度与价值链进行对比，并形成自定义UI组件对商业成功关键程度的见解。该团队发现，最关键的增值部分是自定义UI组件，这些组件是通过明确每个平台的特性、功能和特征而形成的。他们意识到，与其重建Backstage上的插件和核心API，不如将开发资源投入到创建自定义UI组件上。</p><p></p><h2>通过联合平台控制台MVP的提供连接体验</h2><p></p><p>开发平台控制台MVP（最小化可行产品，Minimum Viable Product）的最初目标是建立一个具有共同入口的连接体验，让开发人员在整个SDLC中查看和访问项目的状态，然后链接控制台中现有的工具。计划随着的时间推移有了新的变化，将控制台从连接体验升级为集成体验，并最终升级为一个平台，让组织所有的周边工具得到全面管理。</p><p></p><p>在设计和开发这些插件时，团队很谨慎，没有简单地将现有的经验提升并转移到控制台中，而是利用这个机会重新思考用户从数据中所获取的经验和价值。为了解决管理多个服务软件的问题，他们引入了集合的概念。有了集合，用户可以将服务进行分组，一起查看和评估它们的状态。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f0/f01ebd4636b7acca3f466a6c40f0c4ee.jpeg\" /></p><p>Paved Roads通过一个中心化的产品仓库和组织框架，协助工程师为特定的问题找到合适的工具，在产品知识和工程过程之间搭起了桥梁。</p><p></p><p>控制台还包括为集合中的服务启动批量突变（bulk mutation）的能力，这个概念在Netflix的任何其他平台工具上还不存在。为了解决平台和工具的发现问题，Leathem和团队想出了Paved Roads这个概念，旨在将产品文档集中到一个地方，并且它们的组织方式能够帮助工程师找到解决其挑战的最佳工具。</p><p></p><h2>用户采用和反馈</h2><p></p><p>PXD团队一直在不断地推出MVP，让它出现在Netflix的工程师面前。MVP已经达到了提供最小价值特性集的目标，用户可以用它来查看和评估软件的状态。然而，团队通过用户反馈和新的研究发现，仅靠这种综合功能还不足以吸引开发人员，并打破他们围绕现有工具的既定常规思路和习惯。</p><p></p><p>因此，该团队正在研究将控制台插入现有的工作流程或完全创建新的工作流程，以推动用户使用该平台。他们还希望用新的功能来丰富控制台，希望用户能够围绕平台控制台形成新的常规思路和习惯，并有机地将其添加到他们的工具链中。</p><p></p><h2>总结</h2><p></p><p>以下是Brian Leathem在虚拟PlatformCon 2022会议上分享的主要内容总结：</p><p>联合平台控制台有助于统一Netflix的工程体验，为开发者提供一个共同的入口来查看和访问他们在整个SDLC中的项目状态。Brian和他的团队创建的平台控制台MVP已经达到了提供这种最小价值特性集的目标，用户可以用它来查看和评估其软件的状态。该团队正在考虑将控制台插入现有的工作流程或完全创建新的工作流程，以推动用户使用该平台。他们还希望用新的功能来丰富控制台，希望用户能围绕平台控制台形成新的常规思路和习惯，并有机地将其添加到他们的工具链中。该团队承认，仅仅整合功能是不够的。为了成功，平台控制台必须被整合到现有的工作流程中，或者创造出对开发人员来说有足够价值的新工作流程，以打破他们既定的常规流程。</p>",
    "publish_time": "2023-03-11 10:50:32",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Palo Alto Networks的平台工程",
    "url": "https://www.infoq.cn/article/efE1d6fhN3C10ZGoNgZ6",
    "summary": "<p>本文最初发布于Palo Alto Networks工程博客。</p><p>&nbsp;</p><p>我一直在思考，我在Palo Alto Networks公司的第一篇博客应该写什么，什么时候发表合适。我觉得，要回顾我领导云基础设施和平台工程的旅程和经验，现在就是一个完美的时间。</p><p>&nbsp;</p><p>我于2021年4月加入Palo Alto Networks，负责网络安全组织下云交付安全服务组织的生产工程团队，最近又承担了一个延伸角色，负责整个NetSec组织的基础设施平台。在这篇博文中，我将探讨下我们如何将生产工程服务转化为平台。首先，我将概要地介绍下我们的内部开发平台（IDP）。</p><p>&nbsp;</p><p>让我们先快速了解一下PAN IDP的启动背景。以下是促使我们踏上这段旅程的两个主要因素：</p><p>Palo Alto Networks的平台方法：众所周知，Palo Alto Networks是网络安全的领导者，其成功的主要原因之一是其网络安全解决方案的平台方法。我们已经将这一理念应用于构建一个包含基础设施配置、成本管理、可观察性和事件管理等生产工程服务的平台，而不是将这些服务作为孤立的自动化解决方案提供给工程团队。自助开发工具：遗留生产工程/DevOps/SRE实践的一个主要问题源于提供相关文档的独立自动化脚本；人们必须阅读许多页的文档或者咨询主题专家才能理解和运行这些工具。</p><p>&nbsp;</p><p>一旦我们决定采用平台方法，接下来的挑战就是决策：是内部开发还是购买。经过仔细分析，我们决定针对Palo Alto Networks特有的用例专门构建一个。我们的理念不是重新发明轮子，而是设法利用开源项目来实现飞跃。我们的团队发现，我们可以从一个很棒的开源项目<a href=\"https://backstage.io/\">backstage.io</a>\"开启我们的旅程。我们将后台OSS代码分叉，添加了必要的抽象，并将其命名为“Palo Alto Networks DevClues”。</p><p>&nbsp;</p><p>我们实现的第一个用例是“服务目录”，用于帮助开发人员或SRE轻松快速地找到特定生产服务的详细信息。现在，经过一年半的发展，我们的IDP已经提供了相当多的处于不同采用阶段的服务，如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/82/82fb8a8e96cc4f487f52523e3f7f797e.png\" /></p><p></p><p>该平台包括4类服务：资源管理、基础设施管理、生产管理和开发者门户。开发者门户（DevClues）是平台提供的所有服务的入口点（一站式商店）。例如，如果任何工程团队想要将他们的服务安装到可观察性类别下，他们就可以简单地登录到开发者门户网站，并使用安装插件（由可观察性团队贡献的自定义插件）来完成可观察性集成。</p><p>&nbsp;</p><p>如今，开发者门户（DevClues）提供了12个插件和数十个服务模板，提高了整体的工程效率。我们将继续根据我们的工程需求构建更多的模板和插件。我还想指出的是，其中一些是由开发团队（即我们的客户）贡献的。因此，我们从第一天起就采用了内部开源模式（即内部外包）。</p><p>&nbsp;</p><p>接下来，我将简要介绍下Palo Alto Networks IDP的4个服务类别，以及根据<a href=\"https://www.gartner.com/en/documents/4010078\">2022年高德纳发布的报告</a>\"，这些能力与以下开发生命周期阶段的关系：</p><p>发现与创建集成与部署运营与改进</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/89/89c2be65a81ba8c383bc321537b2c157.png\" /></p><p></p><p>图1：Palo Alto Networks IDP概述（在Gartner报告的语境下）</p><p>&nbsp;</p><p>现在，让我们分阶段看下相关的IDP功能。</p><p>&nbsp;</p><p></p><h1>发现与创建（第0天）</h1><p></p><p>发现与创建阶段涵盖了开发生命周期的初始部分，包括安装、培训、启动、本地开发等，如图1所示，所有这些功能都是Palo Alto Networks“开发者门户”的一部分。</p><p>&nbsp;</p><p></p><h2>开发者门户（Palo Alto Networks DevClues）</h2><p></p><p>如前所述，DevClues基于开源项目<a href=\"https://backstage.io/\">backstage.io</a>\"。这是一个一站式商店，包含基础设施平台提供的所有内部服务。现在，我们将详细看下DevClues的每个功能。</p><p>&nbsp;</p><p>内部开发者门户应该使开发人员在软件交付生命周期（SDLC）的所有阶段都能够轻松地执行第0天、第1天和第2天的活动。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/40/4020a7f142f95e79b8b1787a6344227f.png\" /></p><p></p><p>图2：Palo Alto Networks DevClues首页</p><p>&nbsp;</p><p>Palo Alto Networks DevClues为开发人员提供了可以直接使用的服务模板，其中嵌入了新建软件应用程序、服务和基础设施组件的最佳实践。</p><p>&nbsp;</p><p></p><h2>服务目录</h2><p></p><p>该功能使开发人员能够轻松快速地搜索和查找生产服务（如On Boarded into DevClues），包括：</p><p>可用的服务及其元数据（即所有者和电话值班工程师）它们的API规范其他详细信息，如文档、CICD统计、代码覆盖率和如下所示的DORA指标</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/eb/eb2a1114c0a97d4b67cfa68194313054.png\" /></p><p></p><p>图3：服务目录中的服务概述</p><p>&nbsp;</p><p></p><h2>服务生成模板</h2><p></p><p>该功能使开发人员可以基于预定义的模板创建新的服务、基础设施组件或应用程序。目前，DevClues为Go、Python和React应用程序开发提供了一套服务模板，为“GKE集群启动”和“GitOps安装”（借助GitLab和argoCD）提供了基础设施组件配置模板。</p><p>&nbsp;</p><p></p><h2>文档和培训资料</h2><p></p><p>这有助于开发人员了解如何以自助服务的方式最大限度地利用平台，并促进平台社区的发展，让来自不同服务团队的个人成为平台专家，帮助他们的团队实现自己的目标，而不必等待平台团队提供信息或帮助。其中包括：</p><p>平台使用指南培训文档和视频社区培训（brown-bags）和辅导（office hours）</p><p>&nbsp;</p><p></p><h2>自动支持&amp;搜索</h2><p></p><p>为开发人员提供自助查找平台及其特性信息的方法，响应开发人员的提问，并自动帮助解决问题，其中包括：</p><p>全局搜索所有可用的文档、指南和示例联系平台团队的Slack或电子邮件链接聊天机器人协助安装</p><p>&nbsp;</p><p></p><h2>最佳实践指南和工具</h2><p></p><p>为开发人员提供架构最佳实践：</p><p>模板和自助解决方案生产就绪指南SRE最佳实践和标准</p><p>&nbsp;</p><p></p><h2>自定义插件</h2><p></p><p>DevClues是使Palo Alto Networks开发人员能够构建内部工具和流程的门户。在Palo Alto Networks，我们有以下插件：</p><p>云计算成本可观察性安装事件分析基础设施管理证书管理新增云区域编辑自动修正生产审计日志适合“内部采购”的内部项目市场</p><p>&nbsp;</p><p></p><h1>集成与部署（第1天）</h1><p></p><p>集成与部署阶段包括将应用程序部署到非生产/生产环境、分布式系统集成、资源配置等。提供一个统一的仪表板，管理跨云和本地环境管理分布式基础设施。以下是当前提供的功能，它们分属于基础设施管理和生产管理两个类别。</p><p>&nbsp;</p><p></p><h2>基础设施准备&amp;编排</h2><p></p><p>在Palo Alto Networks，我们构建了一个DevClues插件Uno（如图4），它可以帮助开发人员为使用GitOps的服务/应用准备和配置云资源和其他基础设施组件。这包括：</p><p>在私有云和公有云中按需提供资源将所有必需资源定义为符合最佳实践的代码</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c9/c903fa19191fe1b1f295a041f9e55eba.png\" /></p><p></p><p>图4：Uno —— 用于多云基础设施管理的DevClues插件</p><p>&nbsp;</p><p></p><h2>策略管理</h2><p></p><p>在资源和应用/服务运行上执行业务、运营和最佳实践策略。我们已经实现了一个基于OPA（开放策略代理）的“控制平面”来帮助实现：</p><p>所有内部门户和底层API的授权（RBAC）将资源配置限制为允许值（即CICD）执行特定的注解/标签</p><p>&nbsp;</p><p></p><h2>环境管理</h2><p></p><p>我们构建的用于管理基础设施资源的DevClues插件经过扩展后，可以轻松创建、配置和管理服务/应用环境，例如：</p><p>轻松添加新环境/区域，或删除旧环境/区域创建和删除用于开发和测试的临时环境</p><p>&nbsp;</p><p></p><h2>秘密管理</h2><p></p><p>在Palo Alto Networks，这项功能提供了一项服务，可以管理生产环境中的证书、秘密和配置同步，以便可以安全地：</p><p>将秘密管理系统与部署/交付系统自动集成在一个集中的存储库中存储/调换它们的配置、秘密和证书（即vault或GSM或ASM）当相应的秘密/证书/配置发生变化时，无缝地重新配置/加载应用，它们运行在K8s、Docker和本地Linux进程上</p><p>&nbsp;</p><p></p><h1>运营与改进（第2天）</h1><p></p><p>这个阶段通过DevClues插件访问工具箱，获得自动化、监控、可观察性和事件管理等功能，实现连续操作。</p><p>&nbsp;</p><p>在Palo Alto Networks，运营与改进阶段的能力分布在三个类别中——生产管理、基础设施管理和资源管理。</p><p>&nbsp;</p><p></p><h2>监控和可观察性</h2><p></p><p>监视和可观察性是Palo Alto Networks的关键生产工程服务之一。我们已经建立了一个名为“Garuda”的内部可观察性平台，使用了一些成熟的开源技术，如Grafana、Grafana Mimir、Grafana Loki、Grafana Tempo和<a href=\"https://vector.dev/\">vector.dev</a>\"。我们很快将单独发表一篇博文，深入介绍Garuda及其能力。</p><p>&nbsp;</p><p>Garuda现在提供的功能包括：</p><p>日志和事件跟踪指标报警仪表板</p><p>&nbsp;</p><p>我们为Garuda构建了一个DevClues插件（见下图5），以便工程团队可以轻松地将他们的基础设施和服务/应用安装到“可观察性平台”。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b9/b967eb507b2543f2cb2ac0c7879c53c0.png\" /></p><p></p><p>图5：DevClues中的Garuda安装插件</p><p>&nbsp;</p><p>监控和可观察性的主要挑战之一是不同资源类型（云、本地、K8s、VM、无服务器和裸金属）的复杂安装过程。通过这个插件，我们使安装过程尽可能地顺畅无停顿。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c9/c9712c74915b7bf35054aa15c24e405f.png\" /></p><p></p><p>图6：Garuda代理安装</p><p>&nbsp;</p><p></p><h2>事件管理</h2><p></p><p>有效的事件管理是SRE最佳实践的一个关键方面，当影响业务的事件/中断发生时，我们可以及时提醒和通知工程师，并提供管理这些事件的工具，其中包括：</p><p>事件管理仪表板事件分析用于提醒和创建Slack Channel的工具</p><p>&nbsp;</p><p>我们的DevClues事件分析插件提供了以下洞察：</p><p>按日统计的事件按小时统计的事件按组件统计的事件按团队统计的事件事故修复与发生对比按组件/服务统计的重复事件</p><p>&nbsp;</p><p></p><h2>自动修复</h2><p></p><p>根据最近的一项行业研究，30-50%的生产事故是重复的，并导致了大多数SRE工作。我们希望通过自动化来解决这个问题，因此建立了一个名为“Nutrix”的系统，即我们基于开源项目<a href=\"https://stackstorm.com/\">stackstorm</a>\"构建的内部自动修复平台。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9e/9e01f37463963a1d97c6b46ab0c29a76.png\" /></p><p></p><p>图7：DevClues中的Nutrix插件</p><p>&nbsp;</p><p>同样，提升自动化应用的主要瓶颈之一是没有一个健壮的编辑框架，因此，我们在DevClues Nutrix插件中构建了编辑框架，如下所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/74/746f5e77404762091877a56cbf80926c.png\" /></p><p></p><p>图8：DevClues中的Nutrix自动修复编辑</p><p>&nbsp;</p><p></p><h2>洞察仪表板</h2><p></p><p>仪表板利用可观察性和监控数据来诊断问题和调试运行中的系统，以减少MTTR（平均解决时间），其中包括：</p><p>主机360仪表板证书360仪表板Kubernetes 360仪表板成本洞察</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e6/e6cd5d67495f0f4ca418021d829b236f.png\" /></p><p></p><p>图9：Garuda主机360仪表板</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f1/f1ca2aea379a1ec9841d3845fa3ba4f7.png\" /></p><p></p><p>图10：Garuda证书360仪表板</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/19/19784f88052509c79ae68f28f831ec71.png\" /></p><p></p><p>图11：Garuda Kubernetes 360仪表板</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e5/e576847f3ebf1cc9431fcc34d160424b.png\" /></p><p></p><p>图12：Garuda Kubernetes 成本洞察仪表板</p><p>&nbsp;</p><p></p><h2>IAM</h2><p></p><p>管理身份信息，以及用户和工具对云资源和系统的访问。</p><p>&nbsp;</p><p>下面是几个例子：</p><p>根据角色管理K8s集群的访问等级，如服务操作员和集群操作员进行不同的访问定义RBAC权限来执行部署，更新服务/应用及资源的配置将堡垒机作为访问生产基础设施的服务即时访问管理</p><p>&nbsp;</p><p></p><h2>安全和合规管理</h2><p></p><p>Palo Alto Networks的信息安全团队负责定义和执行安全策略以及自动化验证和检查，但修复是工程团队的责任，其中包括：</p><p>安全审查和审批（信息安全）漏洞扫描和检查（信息安全）漏洞修复（工程）实现符合业务策略的措施的框架（平台工程）遵循治理规则和法规的框架（平台工程）</p><p>&nbsp;</p><p></p><h2>成本管理</h2><p></p><p>在多云和混合云世界中，基础设施成本成了一个热门话题。毫无疑问，成本需要持续地监测、报告和优化。</p><p>&nbsp;</p><p>在Palo Alto Networks，我们开始从两个维度来解决这个问题，即自上而下和自下而上：</p><p>自上而下——由FinOps和CloudOps驱动执行团队在组织和业务单元层面推动成本优化；自下而上——由基础设施平台和工程团队驱动，为了优化成本，我们提供了各个云资源或用户级的详细成本洞察，包括异常检测和自动化。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ed/ed18ab70414d7821dbbdc05b3f2371bb.png\" /></p><p></p><p>图13:DevClues SKU级的成本洞察</p><p>&nbsp;</p><p></p><h2>配置管理</h2><p></p><p>在云世界中，基础设施管理有两个重要的方面，即基础设施准备和配置。在Palo Alto Networks，我们用Terrform标准化了基础设施准备，用Ansible标准化了配置管理。</p><p>&nbsp;</p><p>开发人员应该用一种可伸缩且可靠的方式来管理应用程序的配置，就像我们对源代码或基础设施即代码（IaC）进行管理和版本控制那样。</p><p>&nbsp;</p><p>为了更好地管理Ansible代码，我们采用了<a href=\"https://www.ansible.com/products/controller\">Ansible Tower</a>\"的开源版本<a href=\"https://github.com/ansible/awx\">awx</a>\"，帮助开发人员/SRE标准化配置的部署、初始化、下发和审计。</p><p>&nbsp;</p><p></p><h2>资源管理</h2><p></p><p>在Palo Alto Networks，资源和基础设施管理是密不可分的。DevClues的Uno插件旨在提供简单流畅的基础设施准备和端到端管理，其中包括：</p><p>以代码形式管理Kubernetes集群和组件，并利用最佳实践和持续部署；以代码的形式管理跨云提供商的虚拟机，并利用最佳实践；云供应商资源管理；例如：谷歌BigQuery、CloudSQL、Cloud Run、Cloud Functions等。</p><p>&nbsp;</p><p></p><h1>小结</h1><p></p><p>根据Gartner的报告，到2025年，75%拥有平台团队的组织将提供自助服务开发者门户，以改善开发体验并加速产品创新。</p><p>&nbsp;</p><p>IDP的采用与组织DevOps、SRE和平台工程实践的成熟度成正比。所以，成熟度指数越高，他们使用开发者门户的可能性就越高。</p><p>&nbsp;</p><p>Palo Alto Networks的平台工程团队致力于通过管理IDP采用、路线图、收集来自工程团队的反馈以及推广其功能来不断创新。</p><p></p><p>声明：本文为InfoQ翻译，未经许可禁止转载。</p><p>&nbsp;</p><p>原文链接：<a href=\"https://medium.com/engineering-at-palo-alto-networks/platform-engineering-at-palo-alto-networks-part-1-e48afdcfb1f8\">https://medium.com/engineering-at-palo-alto-networks/platform-engineering-at-palo-alto-networks-part-1-e48afdcfb1f8</a>\"</p>",
    "publish_time": "2023-03-11 11:08:47",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Log4j一周年观察：我们如何应对日益严峻的软件供应链安全风险？",
    "url": "https://www.infoq.cn/article/WMs7uoxvNLc1J5qBMtoR",
    "summary": "<p>2021年12月10日，全球知名开源日志组件Apache Log4j被曝存在严重高危险级别远程代码执行漏洞，这个“核弹级”的漏洞时至今日影响仍然存在，InfoQ在《<a href=\"https://www.infoq.cn/article/ftjYfScOfpLFLTIUvwGe\">开源意味着不问责，我们准备好应对比 Log4Shell 更大的安全危机了吗？</a>\"》中表示2022 年本应是“供应链安全元年”，不幸的是，一年后的现在这个漏洞仍然普遍存在，修复版本采用率没有想象中的高，而且数据显示，软件供应链攻击频次反而呈现出急剧上升趋势。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/10/10ae19906ae5cef44e558ac438987322.png\" /></p><p></p><p>自 2019年以来软件供应链攻击的发展趋势，年平均增长率达到742%</p><p></p><p>软件供应链安全如今已经成了一个世界性难题。它的成因、为什么难以解决，以及企业如何应对，我们咨询了腾讯安全开发安全专家刘天勇。</p><p></p><p>问：当我们在说“软件供应链安全”的时候，我们实际上是在说什么？</p><p>答：基于中国信通院的定义，软件供应链安全是指“ 软件供应链上软件设计与开发的各个阶段中来自本身的编码过程、工具、设备或供应链上游的代码、模块和服务的安全，以及软件交付渠道及使用过程安全的总和。”</p><p></p><p>这里是把软件供应链安全分为了两部分。一是软件自身的供应链安全，二是软件供应链交界面的安全管理。</p><p></p><p>软件自身的供应链，可以简单理解为应用的代码来源，应用的代码来源主要有两个部分：一个是产品研发自己写的代码，另一个就是引入的第三方的开源组件代码。针对这两者的安全检测也是我们常说的开发安全。</p><p></p><p>软件供应链交接界面，针对的是开源软件或者商业采购第三方软件。这部分的供应链安全管理主要是在交付和使用过程中进行相关的准入检测并形成标准化可溯源的软件物料清单。</p><p></p><p>问：开源已经有十几年历史了，但是直到最近两三年，软件供应链安全才成为了一个世界性难题，这期间发生了什么变化？</p><p>答：软件供应链的安全的重要性提升和开源的大趋势是息息相关的，软件开源化的趋势是一个累积的过程，十几年的时间经历了一个量变到质变的阶段，现在全球的开发者都在依赖开源组件来做应用的研发，绝大多数现代代码库都包含开源组件。</p><p></p><p>但是开源的繁荣本身就建立在一系列自由许可协议和免责条款上——其中也包括风险免责，“使用者风险自负”是开源社区的共识。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/45/4528ec938dadec3a604e0df52ffbde8f.png\" /></p><p></p><p></p><p>21年底Apache Log4j风险的爆发是一个里程碑事件，软件供应链安全直接关系着关键基础设施和重要信息系统安全，保障软件供应链安全也成为业界关注焦点。</p><p></p><p>最近中证协向各大券商下发了一份征求意见稿（按：指《网络和信息安全三年提升计划(2023—2025)》），里面写到“在软件自主可控方面，要求券商提升自主掌控能力，不管自研还是外购代码全部代码100%审计，重要信息系统的自动化测试比例不低于整体测试比例 30%，从研发规范制定、研发工具建设方面建设统一的源代码管理工具、标准化的研发运维一体化工具”，这就是行业对于开源代码使用规范的一个表现。</p><p></p><p>问：从技术角度看，软件供应链安全治理的主要难点在哪里？</p><p>答：软件供应链安全的治理的难点可以分成以下三个部分：</p><p></p><p>第一个难点是检测门槛高，开源组件的来源复杂，依靠单一的技术手段难以做到全面覆盖。市面上常见的开源组件检测技术是基于源代码的SCA分析，但基于源码的SCA难以覆盖软件供应链交接界面的第三方软件成品；</p><p></p><p>第二个难点是修复成本高，在企业开始做开源组件的风险治理的时候，存量业务往往会发现大量的漏洞，但这些业务大多数处于上线运营的阶段，修复的过程对研发资源是一个较大的消耗，同时对安全团队来说也是较大的推动阻力。</p><p></p><p>第三个难点是攻击影响范围广，第三方开源组件的使用，间接扩大了软件的受攻击面，针对上游供应链环节的漏洞挖掘和恶意利用，能够快速覆盖大量的下游软件，同时相关的攻击具有较高的隐蔽性，常用的安全检测手段难以进行全面的防御，目前软件供应链攻击已经成为攻防演练中非常常用的攻击手段。</p><p></p><p>问：当前业界常见的开源组件检测技术有哪些？</p><p>答：SCA是目前业界主要的解决开源组件风险检测的手段。市面上的SCA产品主要有两条技术路线，一个是基于开源组件源代码进行分析，另一个是基于二进制制品进行分析。目前国内的安全厂商的产品主要是通过源代码层面去做的，而腾讯安全的SCA产品，在源代码分析的基础上，同时还支持二进制SCA分析，能够同时覆盖软件自身以及交接界面的软件供应链安全问题。</p><p></p><p>从技术原理上看，源码SCA分析主要是根据源码文件相似度或代码相似度检测，主要为依赖扫描；二进制SCA分析是从二进制文件中提取常量、函数特征来进行分析。</p><p></p><p>从使用场景来看，源码SCA能够全面的分析源码仓库，但在不能获得源码的情况下，不能检测商业采购的第三方软件安全包。二进制SCA分析可以直接分析安装包，同时不会因为源码而引入一些额外的，不会被带入构建产物的数据，影响分析结果。</p><p></p><p>和源代码SCA相比，二进制SCA的技术门槛更高，需要有效涵盖移动端，嵌入式，后台开发，云原生各种开发场景下的跨架构格式解析，同时要支持固件、镜像、文件系统、压缩文件等多种文件格式。得益于腾讯安全科恩实验室在物联网安全以及AI安全上过去多年的技术积累，腾讯的二进制SCA技术有着独家的技术领先优势。</p><p></p><p>问：腾讯本身是一个SCA的使用者，也提供SCA的工具，我们自身的实践情况是什么样的？</p><p>答：腾讯的SCA是作为腾讯整个DevSecOps解决方案中的一环进行落地的，我先介绍下腾讯DevSecOps的整体实践。</p><p></p><p>目前腾讯的开发业务已经全量上线自研的DevOps平台，我们包括SAST、IAST、DAST、SCA在内的各类开发安全检测工具都和DevOps平台做了深度的集成和联动，相关检测工具会作为开发流水线中的自动化质量门禁红线，进行相关的卡点检测。</p><p></p><p>除了在流水线中进行使用外，我们的SCA产品还与自身的制品仓库进行对接， 实现了对制品的全面扫描和分析，生成了自身的SBOM软件物料清单，能够有效应对突发的软件供应链安全事件。此外，我们也将SCA分析用到的开源组件知识库进行开放，开发同事可以在开发阶段自查CVE风险以及License风险</p><p></p><p>问：供应链安全肆虐，给企业的建议？</p><p>答：1、&nbsp; 面向研发团队，强化开发安全意识培训以及安全编码规范的落地，提升自身研发的安全水平</p><p>2、&nbsp; 针对自研应用，完成包括SCA、SAST、IAST在内的开发安全工具建设并全面接入DevOps流程，实现安全左移</p><p>3、&nbsp; 针对第三方软件，建立标准的准入检测机制，借助二进制SCA工具实现对第三方软件的安全评估</p><p>4、&nbsp; 借助SCA工具，完成企业自身的SBOM软件物料清单建设，同时拉通安全和研发团队，制定软件供应链安全事件的应急响应流程制度</p>",
    "publish_time": "2023-03-11 11:35:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "查询性能较 Trino/Presto 3-10 倍提升！Apache Doris 极速数据湖分析深度解读",
    "url": "https://www.infoq.cn/article/8SU754VFuKpw8gwjF24v",
    "summary": "<p>从上世纪 90 年代初 Bill Inmon 在《building the Data Warehouse》一书中正式提出数据仓库这一概念，至今已有超过三十年的时间。在最初的概念里，数据仓库被定义为「一个面向主题的、集成的、相对稳定的、反映历史变化的数据集合，用于支持管理决策」，而数据湖最初是为了解决数仓无法存储海量且异构的数据而构建的集中式存储系统。</p><p></p><p>时代的发展与用户数据应用诉求的演进，催生了数据架构的不断革新，也衍生了更复杂的技术形态。可以清晰看到现代数据架构从计算到存储都在向着融合统一的方向发展，新的数据湖范式被提出，这也是 Lakehouse 诞生的背景。作为一种全新的、开放式的数据管理架构，Lakehouse 提供了更强的数据分析能力与更好的数据治理能力，也保留了数据湖的灵活性与开放式存储，为用户带来更多价值：</p><p></p><p>从存储的角度：统一数据集成，避免冗余存储以及跨系统间 ETL 带来的繁重工程和失败风险；从治理的角度：支持 ACID、Schema Evolution 与 Snapshot，数据与元数据皆可治理；从应用的角度：多引擎访问支持、可插拔，通过统一接口进行数据访问，同时适用于多种工作负载 Workload；……</p><p></p><p>如果我们把 Lakehouse 从系统层面进行解构，会发现除了需要 Apache Iceberg、Apache Hudi 以及 Delta Lake 等数据湖表格式（Table Format）以外，高性能分析引擎更是充分发挥湖上数据价值的关键。</p><p></p><p>作为一款极速易用的开源实时 OLAP 数据库，Apache Doris 自 0.15 版本即开始尝试在 Apache Iceberg 之上探索与数据湖的能力结合。而经过多个版本的优化迭代，Apache Doris 在数据湖分析已经取得了长足的进展，一方面在数据读取、查询执行以及优化器方面做了诸多优化，另一方面则是重构了整体的元数据连接框架并支持了更多外部存储系统。因此 Apache Doris 已经完全具备了构建极速易用的 Lakehouse 架构的能力，并且也已在多个用户的真实业务场景中得到验证和推广，我们希望通过 Apache Doris 能为用户在更多场景中带来价值：</p><p></p><p>湖仓查询加速利用 Apache Doris 优秀的分布式执行引擎以及本地文件缓存，结合数据湖开放格式提供的多种索引能力，对湖上数据及文件提供优秀的查询加速能力，相比 Hive、Presto、Spark 等查询引擎实现数倍的性能提升。统一数据分析网关利用 Apache Doris 构建完善可扩展的数据源连接框架，便于快速接入多类数据源，包括各种主流关系型数据库、数据仓库以及数据湖引擎（例如 Hive、Iceberg、Hudi、Delta Lake、Flink Table Store 等），提供基于各种异构数据源的快速查询和写入能力，将 Apache Doris 打造成统一的数据分析网关。统一数据集成基于可扩展的连接框架，增强 Doris 在数据集成方面的能力，让数据更便捷的被消费和处理。用户可以通过 Doris 对上游的多种数据源进行统一的增量、全量同步，并利用 Doris 的数据处理能力对数据进行加工和展示，也可以将加工后的数据写回到数据源，或提供给下游系统进行消费。该能力使得 Apache Doris 能够成为业务的统一数据枢纽，降低数据流转成本。更加开放的数据生态通过对 Parquet/ORC 等数据格式以及开放的元数据管理机制的支持，用户不用再担心数据被特定数据库引擎锁定，无法被其他引擎访问，也不用再为数据的迁移和格式转换付出高昂的时间和算力成本，降低用户的数据迁移成本和对数据流通性的顾虑，更便捷、放心地享受 Apache Doris 带来的极速数据分析体验。</p><p></p><p>基于以上的场景定位，我们需要进一步去思考在构建 Lakehouse 过程中需要如何去设计和改造系统，具体包括：</p><p></p><p>如何支持更丰富的数据源访问以及更便捷的元数据获取方式；如何提升湖上数据的查询执行性能；如何实现更灵活的资源调度与负载管理；</p><p></p><p>因此本文将重点介绍 Apache Doris 在 Lakehouse 上的设计思路和技术细节，同时会为大家介绍后续的发展规划。</p><p></p><h1>元数据连接与数据访问</h1><p></p><p>截至最新的 1.2.2 版本，Apache Doris 已经提供了十余种的数据湖格式和外部数据源的访问支持。同时也支持通过 Table Value Function 直接对文件进行分析。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1b/1b181997febeadb60abe5c1d75b219c7.png\" /></p><p></p><p>为了支持这些数据源，Apache Doris 分别在元数据连接和数据访问两方面做了大量的架构调整和性能优化 。</p><p></p><h2>元数据连接</h2><p></p><p>元数据包括数据源的库、表信息、分区信息、索引信息、文件信息等。不同数据源的元信息格式、组织方式各有不同，对于元数据的连接需要解决以下问题：</p><p></p><p>统一的元数据结构：屏蔽不同数据源的元数据差异。可扩展的元数据连接框架：低成本、快速地接入数据源。高效的元数据访问能力：提供可靠、高效的元数据访问性能，并支持实时同步元数据变更。自定义鉴权服务：能够灵活对接外部的权限管理系统，降低业务迁移成本。</p><p></p><h3>统一的元数据结构</h3><p></p><p>在过去 Apache Doris 的元数据只有 Database（数据库） 和 Table（表）两个层级，当外部数据目录 Schema 发生变化或者外部数据目录的 Database 或 Table 非常多时，需要用户手工进行一一映射，维护量非常大。因此在 Apache Doris 1.2.0 版本中新增了 Catalog（数据目录）层级，提供了快速接入外部数据源的能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/51/513630b002c9573fec02262947be702d.png\" /></p><p></p><p>Catalog 层级的引入解决以下问题：</p><p></p><p>数据源层级的映射：用户不再需要在 Database、Table 层级进行一一映射，可以通过 Catalog 直接映射整个数据源，自动同步其中的所有元信息，简化元数据映射逻辑数据源统一信息管理：在 Catalog 层级统一维护指定数据源的属性，如连接信息、权限信息、同步方式等，更方便的管理多个数据源。</p><p></p><p>引入 Catalog 层级后，我们也对 Doris 的元数据进行调整和划分：</p><p></p><p>Internal Catalog：原有的自管理的 Table 和 Database 都归属于 Internal Catalog。External Catalog：用于对接其他非自管理的外部数据源。比如 HMS External Catalog 可以连接到一个 Hive Metastore 管理的集群、Iceberg External Cataog 可以连接到 Iceberg 集群等。</p><p></p><p>用户可以使用 SWITCH语句切换不同的 Catalog，也可以通过全限定名方便的进行跨数据源的联邦查询，如：</p><p></p><p><code lang=\"text\">SELECT * FROM hive.db1.tbl1 a JOIN iceberg.db2.tbl2 b\nON a.k1 = b.k1;\n</code></p><p></p><p>相关文档：https://doris.apache.org/zh-CN/docs/dev/lakehouse/multi-catalog</p><p></p><h3>可扩展的元数据连接框架</h3><p></p><p>基于新的元数据层级，用户可以通过 CREATE CATALOG语句方便的添加新的数据源：</p><p></p><p><code lang=\"text\">CREATE CATALOG hive PROPERTIES (\n    'type'='hms',\n    'hive.metastore.uris' = 'thrift://172.21.0.1:7004',\n);\n</code></p><p></p><p>在数据湖场景下，目前 Doris 支持的元数据服务包括：</p><p></p><p>Hive Metastore 兼容的元数据服务Aliyun Data Lake FormationAWS Glue</p><p></p><p>同时，开发者也可以自行扩展 External Catalog，只需要实现对应的访问接口，即可在 Doris 中快速接入新的元数据服务。</p><p></p><h3>高效的元数据访问</h3><p></p><p>元数据存储在外部数据源中，而对外部数据源的访问受到网络、数据源资源等限制，性能和可靠性是不可控的。所以 Doris 需要提供高效、可靠的元数据服务以保证线上服务的稳定运行，同时 Doris 也需要实时感知元数据的变更，提升数据访问的实时性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/70/708eaf383c299d6f9e2649e6d1303bb7.png\" /></p><p></p><p>Doris 通过内存中的元数据缓存提供高效的元数据服务。元数据缓存包括列信息缓存，分区缓存，文件缓存。 通过元信息缓存，可以显著提升元数据访问性能并降低对外部元数据服务的请求压力，使得Doris 可以应对数千张表，数十万分区场景下，毫秒级别的元数据查询响应。</p><p></p><p>Doris 支持在 Catalog/Database/Table 级别，对元数据缓存进行手动刷新。同时，针对 Hive Metastore，Doris还支持通过监听 Hive Metastore Event 自动同步元数据，提供元数据秒级实时更新能力。</p><p></p><h3>自定义鉴权服务</h3><p></p><p>外部数据源通常拥有自己的权限管理服务，而很多企业也会使用统一的权限管理系统（例如 Apache Ranger）来管理多套数据系统。Doris支持通过自定义鉴权插件对接企业内部已有的权限管理系统，从而可以低成本的接入现有业务，完成授权、审计、数据加密等操作。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ef/ef001433107b277cfa6938dcd65ef2ea.png\" /></p><p></p><p>具体实现上，用户可以基于 Doris 的 AccessController 接口实现插件对接相应的权限管理系统，并在创建 Catalog 时，指定对应的鉴权插件。通过这种机制，所有通过 Doris 对外部数据源的访问，都将统一使用自定义的插件完成鉴权、审计等操作。</p><p></p><h2>数据访问</h2><p></p><p>外部数据源的数据访问，主要集中在对存储系统的访问支持上。在数据湖场景下，主要是对 HDFS 以及各种 S3 兼容的对象存储的支持。目前 Apache Doris 支持的存储系统如下，并且仍在不断增加中：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8a/8aef34ea47b4e37490eaf442d0947773.png\" /></p><p></p><h1>性能优化</h1><p></p><p>在实现数据源的连接和访问后，下一个问题是我们如何结合 Apache Doris 自身优异的查询性能以及各类存储系统的特性，进行针对性的查询性能优化，这也是在 构建 Lakehouse 过程中最需要解决的问题和权衡的因素。在具体实现过程中，Apache Doris 分别在数据读取、执行引擎、优化器方面进行了诸多优化。</p><p></p><h2>数据读取</h2><p></p><p>湖上数据通常存储在远端存储系统上，相较于本地存储，在数据的访问延迟、并发能力、IO 带宽上天然存在一定劣势。因此，在数据读取上，Apache Doris 从减少远端读取频率，降低读取量等方面出发进行了细致的优化。</p><p></p><h3>Native File Format Reader</h3><p></p><p>Parquet 和 ORC 是最常见的开放数据格式，这些数据格式本身提供了包括索引、编码、统计信息在内的多种特性，如何针对格式特性来提升文件读取效率是性能优化的关键一步。在早期的实现中，Apache Doris 是通过 Apache Arrow 来读取 Parquet/ORC 数据文件的，但这种方式存在以下问题：</p><p></p><p>数据格式转换的开销：Arrow Reader 需要先将文件读取成 Arrow 的内存格式，再转换到 Doris 自己的内存格式，两次数据转换带来额外的开销。无法支持高级文件格式特性。如不支持 Parquet 的 Page Index，不支持 Bloom Fitler，无法实现谓词下推、延迟物化等功能。</p><p></p><p>基于以上问题，我们对 Flile reader 进行了重构，实现了全新的 Native File Format Reader。这里我们以 Parquet Reader 为例，介绍 Doris 的文件格式读取方面所做的优化：</p><p></p><p>减少格式转换。新的 File Reader 直接将文件格式转换成 Doris 的内存格式，并可以直接利用字典编码等功能转换到对应的更高性能的内存格式，以提升数据转换和处理的效率。细粒度的智能索引。支持了 Parquet 的 Page Index，可以利用 Page 级别的智能索引对 Page 进行过滤。相比之前只能在 Row Group 级别过滤，Page Index 过滤粒度更细、过滤效果更好。谓词下推和延迟物化。延迟物化的基本逻辑是先读取有过滤条件的列，再使用过滤后的行号读取其他列。这种方式能显著降低文件的读取量。这一点在远程文件读取场景下尤为重要，可以最大限度减少不必要的数据读取。数据预读。 将多次文件读取合并成一次，充分利用远端存储高吞吐、低并发的特性，提高数据的总体吞吐效率。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fb/fbf4168dd1db96029948d88a0df8633a.png\" /></p><p></p><h3>File Cache</h3><p></p><p>利用本地高性能磁盘对远端存储系统中的文件进行本地缓存，能最大限度的减少远程数据读取的开销，同时可以提供接近 Doris 内部表数据的访问性能。在本地文件缓存方面 Doris 进行了如下优化：</p><p></p><p>文件块缓存（Block Cache） 。支持对远端文件进行 Block 级别的缓存。Block 的大小会根据读取请求自动调整，从 4KB 到 4MB 不等。Block 级别的缓存能有效减少缓存导致的读写放大问题，优化缓存冷启动场景下的数据读取延迟。缓存一致性哈希。通过一致性哈希算法对缓存位置和数据扫描任务进行管理和调度，充分利用已缓存的数据提供服务，并避免节点上下线导致缓存大面积失效的问题，提升缓存命中率和查询服务的稳定性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/960d6dc8a961774b760151ef18d08f15.png\" /></p><p></p><p>通过 Flie Cache，在命中缓存的情况下，Apache Doris 可以提供和本地表一致的查询性能。</p><p></p><h2>执行引擎</h2><p></p><p>在执行引擎层面，我们希望能够完全复用 Apache Doris 的向量化执行引擎以及各类执行层面的算子优化，为数据湖提供极速的查询体验。因此，Apache Doris 对数据扫描（Scan）节点进行了重构，使得每一种新的数据源的接入，开发者只需要关注数据源本身的访问逻辑，无需重复地开发通用功能。</p><p></p><p>通用查询能力的分层</p><p></p><p>包括内表在内的所有数据查询，都会使用相同的 Join、Sort、Agg 等算子。唯一不同在于数据源的访问方式上，例如对本地内部格式数据的读取，或存储在 S3 上的 Parquet 格式数据的读取。因此 Doris 将不同数据源的查询逻辑差异下推到最底层的 Scan 节点上。Scan 节点之上，所有查询逻辑统一，Scan 节点之下，由具体的实现类负责不同数据源的访问逻辑。</p><p></p><p>Scan 算子的通用框架</p><p></p><p>对于 Scan 节点，不同数据源也有很多共性的方面，如子任务的拆分逻辑、子任务的调度、IO 的调度、谓词下推以及 Runtime Filter 的处理等。因此我们也对这一部分架构进行了重构。首先，将共性部分都以接口的形式对外暴露，如子任务的拆分、下推谓词的处理等；其次，对子任务实现了统一的调度管理逻辑，可以由统一的调度器管理整个节点 Scan 任务的执行。调度器拥有节点全局的信息，可以方便的实现更细粒度的Scan 任务调度策略。在这样的统一的数据查询框架下，大约 1 人周就可以完成一种新数据源接入。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bc/bcb5c1fd08aab34a371bbe38c70f45ea.png\" /></p><p></p><h2>查询优化器</h2><p></p><p>查询优化器层面的优化集中在统计信息收集和代价模型的推导方面。</p><p></p><p>Apache Doris 支持对不同数据源的统计信息收集，如 Hive Metastore、Iceberg Metafile、Hudi MetaTable 中存储的统计信息等。同时在代价模型推导方面，我们也针对外部数据源的特性做了细致的调整。基于这些优化，Doris 可以为复杂的外表查询提供更优的查询规划。</p><p></p><h2>性能对比</h2><p></p><p>以上优先项，我们分别在宽表场景（Clickbench）和多表关联场景（TPC-H）下与 Presto/Trino 进行了 Hive 数据集的查询性能对比。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d3/d3bc4fde9398fca8225c418c9b5ba93a.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/40/40cde829687e8f5f8854da6f5f03a0c3.png\" /></p><p></p><p>可以看到，在相同计算资源和数据集下，无论是宽表场景或多表关联场景，绝大多数 SQL Apache Doris 的查询耗时都是大幅低于 Presto/Trino ，整体性能 相比 Presto/ Trino 有 3-10 倍的提升。</p><p></p><h1>负载管理与弹性计算</h1><p></p><p>对外部数据源的查询并不依赖 Doris 的数据存储能力，这也为 Doris 实现弹性的无状态计算节点成为可能。在即将发布的 2.0 版本中，Apache Doris 还实现了弹性计算节点功能（Elastic Compute Node），可以专门用于支持外部数据源的查询负载。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bf/bfea84a78c712f1aff996922b271a559.png\" /></p><p></p><p>由于计算节点是无状态的，因此我们可以对这类节点进行快速扩缩容，以灵活地应对峰谷期的查询负载，在查询性能与成本消耗之间取得更好的平衡。</p><p></p><p>同时，Doris 也针对 k8s 场景下的集群管理和节点调度进行了优化，Master 节点可以自动管理弹性计算节点的上下线，方便业务在云原生场景、混合云场景下都能便捷的管理集群负载。</p><p></p><h1>案例实践</h1><p></p><p>随着以上功能的完善与性能的提升，Apache Doris 已经被多家社区用户应用于数据湖分析，在真实业务中发挥着重要的作用，在此以某金融企业的风控场景为例。</p><p></p><p>金融风控场景往往对数据的实时性有着更高的要求，早期基于 Greenplum 和 CDH 搭建的风控数据集市已经无法满足其高时效性的需求，T+1 的数据生产模式成为业务迅速发展的掣肘，因此该企业于 2022 年引入 Apache Doris 并改造了整个数据生产和应用流程，实现对 Elasticsearch、Greenplum 以及 Hive 的联邦分析，整体效果包括：</p><p></p><p>只需创建一个 Hive Catalog 即可对现存的数万张 Hive 表进行查询分析，查询性能得到极大幅度提升；利用 Elasticsearch Catalog 实现对 ES 实时数据的联邦分析，数据时效性从过去的分钟级提升至秒级甚至毫秒级，满足了风控策略的实时性要求；将日常跑批与统计分析进行解耦，降低资源消耗的同时使系统稳定性得到进一步增强。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6b/6b78110aa36b17525cdeb863e95552f5.png\" /></p><p></p><h1>未来规划</h1><p></p><p>后续 Apache Doris 将持续在 Lakehouse 方向进行迭代和升级，下一步的工作将围绕在更丰富的数据源支持、数据集成和资源隔离与调度等方面：</p><p></p><h2>更丰富的数据源支持</h2><p></p><p>随着数据湖在各种业务场景中的不断落地，数据湖本身的功能也在不断迭代以满足越来越多样的业务需求。Doris也将和各个开源社区紧密合作，提供更完善的数据湖分析支持。</p><p></p><p>Hudi Merge-On-Read 表的 Incremental Query 支持利用 Iceberg/Hudi 丰富的索引功能，结合查询优化器提供更低延迟的分析性能。支持包括 Delta Lake、Flink Table Store 等更多数据湖格式。</p><p></p><h2>数据集成</h2><p></p><p>具体到功能层面，数据集成可以分为数据的读取和写回两部分。</p><p></p><p>数据读取方面，Doris 将进一步整合数据湖的数据访问特性，包括：</p><p></p><p>数据湖 CDC 的接入以及增量物化视图的支持，为用户提供近实时的数据视图。支持 Git-Like 的数据访问模式，通过多版本、Branch 等机制，在数据安全、数据质量等方面为用户提供更便捷的数据管理模式。</p><p></p><p>数据写回功能的支持，帮助 Doris 进一步完善统一数据分析网关的生态闭环。用户可以使用 Doris 作为统一数据管理入口，管理各个数据源中的数据，包括加工后数据的写回、数据导出等，对业务提供统一的数据视图。</p><p></p><h2>资源隔离与调度</h2><p></p><p>随着越来越多数据源的接入，Doris 也在逐步承接不同的工作负载，比如在提供低延迟的在线服务的同时，对 Hive 中 T-1 的数据进行批量处理。所以同集群内的资源隔离会愈发重要。</p><p></p><p>Doris 会持续优化弹性计算节点在不同场景下的调度管理逻辑，同时会支持更细粒度的节点内资源隔离，如 CPU、IO、内存等，帮助 Doris 支持多样且稳定的工作负载。</p><p></p><h1>加入我们</h1><p></p><p>目前社区已成立 Lakehouse SIG（湖仓兴趣小组），汇集了来自多家企业的开发者，旨在共同打造 Apache Doris 的 Lakehouse 场景支持，欢迎感兴趣的同学加入我们。</p><p></p><p># 相关链接：</p><p></p><p>SelectDB 官网：</p><p></p><p>https://selectdb.com</p><p></p><p>Apache Doris 官网：</p><p></p><p>http://doris.apache.org</p><p></p><p>Apache Doris Github：</p><p></p><p>https://github.com/apache/doris</p>",
    "publish_time": "2023-03-11 12:00:44",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "运维百家讲坛第1期：井源的运维几何",
    "url": "https://www.infoq.cn/article/kTtlLZxNUPmlvYpzA0eF",
    "summary": "<p></p><blockquote><a href=\"https://flashcat.cloud/blog/sretalk-001/\">作者著</a>\"：我们观察到：国内运维行业，不同的公司做法差异巨大，从业人员水平参差不齐，缺少普遍性行业认知，难以形成合力（这也会让To B的产品异常难做，不利于行业整体发展），甚至在部分公司，运维人员处在技术鄙视链最底层，我们希望为行业带来一些新的思路和发展推动力。这需要很多行业老炮一起，输出观点，共同碰撞，才有可能形成一些先进的共识，形成行业前进的思想旗帜。所以，我们准备策划《运维百家讲坛》这么一档栏目，诚邀100个运维总监（或更高）级别的老炮，通过采访或约稿的方式输出他们的观点，给行业一些借鉴。井老板是我11年入行加入百度时的团队大老板，骨灰级老炮，逮着这个机会不容易，把业内常见问题都问了个遍，以飨读者。井老板生性洒脱，嬉笑怒骂皆成文章，道理自在其中。这里是接地气、有高度的《<a href=\"https://mp.weixin.qq.com/s/Y4rIfV4_7MuYigLNNrtifg\">运维百家讲坛</a>\"》第 1 期，开讲！</blockquote><p></p><p></p><h2>嘉宾介绍</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/72/72943b646775ed1fa21f9a66ed73e4d2.jpeg\" /></p><p></p><p>井源，左一，前百度运维架构师，前小米运维负责人，前美菜CIO。</p><p></p><h2>采访内容</h2><p></p><p></p><h3>有些运维人员反映公司对运维的价值所知甚少，您当年是怎么给公司讲清楚运维的价值的呢？</h3><p></p><p>首先需要和公司讲清楚运维的岗位职责（运维是干什么、产出什么）和关键指标（度量产出成果），比如工作围绕稳定、安全、高效等方向展开，开展了哪些运维项目，如何主动推进关键指标的达成。</p><p></p><p>关键指标，不仅仅包含服务可用性，还有比如服务器资源达标率、服务故障数据（故障分类、故障响应时间、平均故障恢复时间、故障告警覆盖率）、服务安全指标、服务资源到位时长等等。</p><p></p><p>比如搭建一套完善的监控系统：</p><p>监控服务器资源使用率，找出使用率不达标的服务器进行回收或资源重新分配，通过虚拟化、容器化等手段提升资源使用率；梳理告警阈值，规范P0、P1、P2、P3告警级别；监控系统提供告警合并、智能定位建议，提供活跃告警聚合，提供时间纬度的告警分析。方便更快的告警响应和故障定位，提升故障响应时间、故障恢复时间等；服务的告警和预案梳理，缩短平均故障恢复时间，提升故障告警覆盖率。</p><p></p><h3>业内有观点认为云和Kubernetes这样的基础设施的崛起会让运维岗位逐渐消亡，您是怎么看待这样的观点呢？</h3><p></p><p>很多年前我们运维团队的口号是NO Ops，博客是noops.me。</p><p></p><p>很早就说过，运维岗位会逐渐消亡，或者部分工作职责会消亡。拿系统运维来举例，以前管理的团队需要服务器工程师、内核工程师、网络工程师、CDN工程师、机房运维工程师等小20人的团队。后来通过引入公有云，团队只有4个人，云资源管理员1人、CDN调度工程师1人、网络工程师1人、内核工程师1人，他们只需要管理和调度好第三方公司提供的资源和服务即可。</p><p></p><p>随着K8s和云的普及，以及研发代码工程化的不断成熟，运维在这个过程中的参与度会越来越少。在部署框架成熟的情况下，为了节省运维人力，提升部署效率，二、三级服务的部署已经交给研发自助完成。</p><p>随着科技的发展，时代的变化，一个岗位的消亡是很正常的事情，及时做好调整和规划才是思考的重心。</p><p></p><h3>在企业大范围上云的当下大环境里，您觉得运维人员应该做出哪些调整才能更适合当下的人才需求？</h3><p></p><p>在上云的大环境下，运维工程师更应该面向业务、面向架构，拓展自己的业务范围，成为保障业务稳定的关键人才。如果还是和以前一样，仅仅只关注监控报警，只负责服务部署变更，那么势必会被淘汰。</p><p></p><p>另一方面，可以往专精的方向走，成为某个领域的专家（监控、大数据、K8s、数据库等等），走运维研发专家的方向。</p><p></p><p>人生的建议，多寻找一些副业，运维工作只是生活的一小部分。</p><p></p><h3>AIOps热炒了几年，但是最近明显声量变小了，您觉得企业现阶段应该落地AIOps么？应该注意哪些问题？</h3><p></p><p>就拿智能监控为例，看到了很多文案说要通过AI预测故障、智能定位。到现在没有看到任何靠谱的案例。在一个服务变更快、依赖关系复杂、故障影响因素多的互联网业务系统中，如果真能通过历史数据，实现故障预测。那还不如去做地震预测，有几千年的地震数据积累，能够产生很大的社会价值。</p><p></p><p>做AIOps的前提，是真的懂AI，清楚机器学习和神经网络的原理。有多少人工才有多少智能，AIOps才能不是一个口号。</p><p></p><h3>chatGPT这样的AI能力您觉得未来是否有可能解决运维行业的问题？</h3><p></p><p>比如在故障管理中，根据故障的设备、数据、描述，通过知识库、历史故障库等等，给出故障可能的辅助建议(suggestbot)</p><p></p><p>BTW，如果你已经可以玩转chatGPT了，把这个技术投入到其他更能产生价值的领域吧，别老在运维这个领域耗着……</p><p></p><h3>业务程序的部署，到底应该交给研发来做还是应该交给运维来做，在很多公司争论不休，您是怎么看待这个问题呢？</h3><p></p><p>之前提到过，我们二、三级的服务是完全由研发去做，一级服务是运维和研发轮流去做，主要目的主要是让运维清楚当前服务的变化情况而已。运维人员在公司一开始做部署，更多是规范线上环境，规范服务部署方式，从而更好的研发部署系统，掌控所负责的服务架构。</p><p></p><p>安全问题、流程问题，完全可以通过部署系统去解决。运维就不要守着这个没任何价值，没任何沉淀的工作不放了。</p><p></p><h3>您最想对（运维）行业说的一句话是？为什么？</h3><p></p><p>“物理学没有不存在，只是我们认为的物理学，可能不存在。” 运维行业可能也不存在了，多少运维人的梦想是AIOps、NOOps，要么自己去干掉这个行业，要么在这个行业被干掉。</p><p></p><h3>工具选型这块，到底是自研，还是使用开源，还是使用商业产品，是如何抉择的？</h3><p></p><p>有能力有时间就使用开源，能力一般时间有限就使用商业产品。有钱有闲还很自负的话，可以尝试下自研。</p><p></p><h3>您所在的公司是否也是多云架构？您觉得多云场景下哪些能力应该依托云厂商哪些能力应该自建？</h3><p></p><p>我们是多云架构。专线或者数据传输的能力，这个需要自建。基于多云之上的公共能力也可以自建，比如监控系统、数据备份系统、部署系统、微服务核心组件等，其他的交给云厂商就好了。</p><p></p><h3>您印象最深的一次故障是什么？对您有何启示？</h3><p></p><p>运维这么多年，遇到的诡异故障太多了，root cause让你根本想象不到。只能说，故障很难避免，只能设法减少故障的频率、影响面和影响时间。</p><p></p><p>所以你的绩效不是故障次数和故障级别，而是故障影响面、故障响应、恢复时间等。</p><p></p><h3>面对当下快速发展的基础技术，您对给刚入行和入行已久的运维人员，分别有什么职业规划的建议吗？</h3><p></p><p>比较偏激哈~刚入行的，建议尽快转行！入行已久的，转行技术相对困难，已经打上了深深的运维烙印。我见过太多运维人员转行其他技术，多数都是运维研发、运维产品经理的岗位，还是找一下副业吧。</p><p></p><h3>您觉得传统运维和SRE的区别是什么？您的团队做出这样的转型，其背后的思考是？</h3><p></p><p>这都2023年了，聊这个话题就跟互联网运维弄个NOC监控值班一样，开倒车。</p><p></p><p>如果现在还在考虑要不要转型SRE、怎么转型SRE、SRE的变化这些问题，就跟5g时代，还在考虑用2g，还是3g……都会被时代所淘汰。</p>",
    "publish_time": "2023-03-11 13:11:59",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "CTO药方：如何搭建运维/SRE能力",
    "url": "https://www.infoq.cn/article/vSjY7L6ykpLBlHD7RuxQ",
    "summary": "<p></p><blockquote><a href=\"https://flashcat.cloud/blog/how-to-build-sre/\">作者按</a>\"：近期有很多文章在探讨运维岗位去留的问题，我主持的SRETalk公众号里也发了多个运维总监的观点，个人也和行业内挺多人做了交流，有些许小小的想法，记录下来，供各位CTO/CIO参考，作为运维/SRE的你如果觉得迷茫，也推荐你仔细读一下本文。本文欢迎有理有据的讨论，不欢迎杠精，另外，很多事情其实也没有非黑即白，文章内容对你有些启发，对CXO们的决策带来新的思考，那就是极好的。</blockquote><p></p><p></p><h2>关于标题</h2><p></p><p>首先说一下标题，《如何搭建运维/SRE能力》，这里我没有写搭建团队，而是搭建能力，因为有些目标的达成未必一定需要自建团队，从成本、结果可预见性、长期投入维护的角度来看，需要慎重决策，决策错了，未来将是一地鸡毛，这个后文再展开。</p><p></p><h2>关于运维/SRE团队</h2><p></p><p>另外一点也要提前澄清，文中提到的运维/SRE团队都是为业务服务的，业务的成功是第一要务。有些运维团队做了一些产品在对外商业化输出，本身成了一条业务，这个另当别论，而且，以我在老东家的经验来看，运维/SRE团队这样的做法（对外商业化输出）不可取，尤其是在一个没有ToB基因、没有相应的ToB组织建设的公司。</p><p></p><h2>从哪里获取运维/SRE能力</h2><p></p><p>既然一切都是为了业务成功（不考虑业务，只考虑自己能否晋升能否忽悠老板的另当别论），我们就重点来看业务需要哪些运维能力（后文详细讲解），需要从哪里获取这些运维能力，典型的获取方式有三种。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/87/8786e505e62e677595ebb0e60a02af62.png\" /></p><p></p><p></p><h3>自建团队</h3><p></p><p>首先是通过自建团队提供相关能力，这个方式大家最为熟悉，自建的团队对业务的交付物通常包括两部分：产品+服务。先说产品：</p><p>如果产品需求是通用需求，产品大概率是直接使用的开源项目。需要考虑开源项目的持久性（开源项目研发人员是否有商业公司做收入上的支持，个人开源项目大都会死在没有收入上）、活跃性（项目是否已经多年未更新？提的issue、pr是否及时处理？通常一周内处理就可以看做是活跃的）、生态繁荣性（是否有很多人参与做贡献？很多公司投入使用？）开源项目是否要二次开发？如果二次开发的代码可以merge回主干，通常意味着二次开发的代码具有通用性，得到了开源项目团队的认可。如果无法merge回主干，后面的维护就是麻烦事了，尤其是人才变动之后，一地鸡毛。基于开源项目的API做一些胶水代码，和内部系统做整合，通常是可以的，毕竟没有改造开源代码，后面开源项目升级还是可以跟得上的当然也有不用开源完全自研的（只是使用一些开源的lib库，核心产品逻辑自研），这种要慎重，如果开源社区没有相关的产品，那只能自研，但是自研之后就要考虑长期维护的问题，研发人员通常喜欢做从0到1的事情，后面收益小了，无法晋升涨薪，就容易变动。而运维这个赛道，开源社区的产品琳琅满目，需要自研的产品可能屈指可数，三思。</p><p></p><p>其次就是服务，这里所谓的服务，说的是向业务侧输出的专家经验。比如自建团队做了一款监控产品，这个团队需要给公司内部的“客户”输出监控的最佳实践、监控产品出问题的时候需要这个团队快速解决。其实，公司内部的中后台团队需要有很强的服务意识，同时还得了解行业最佳实践，否则，就容易被业务牵着鼻子走，走出了和行业最佳实践背道而驰的路子，后面，就都是问题了。</p><p></p><p>服务的核心，是靠人（当然，能把最佳实践固化到产品里，那自然是极好的），作为管理者，要想让这个团队输出好的服务，就需要考虑很多人的问题，比如：能否招到相关的人才、能否留住相关的人才（发展空间、薪资等）、自建团队每个方向至少两个人互备，成本是否可以接得住。</p><p></p><h3>第三方供应商</h3><p></p><p>通过第三方供应商来获取运维能力，是另一个路子，供应商的交付物显然也包括两部分：产品+服务。产品分为开源、闭源两种类型，有哪些考量点呢？</p><p>开源的产品通常会有更多的用户、更多的场景来打磨，但是一些长尾需求，通常不开源，至于原因么，要么是开源团队把这些长尾需求作为收费项，要么就是开源团队觉得这些长尾需求不够通用，不值得放到产品里。闭源的产品，通常受众小，没有太多的开源用户帮助打磨产品，就需要经过较长时间的商业化客户打磨，或者，闭源产品的供应商有很强大的质量管理体系，对产品有完备的测试，这就需要找那些家大业大的供应商了，而且，测试人员和终端用户毕竟是两类人群，商业客户的打磨是不可或缺的，只是，如果供应商有强大的质量保障团队，会让这个打磨过程变得短一些。不管是开源还是闭源，供应商都是带着产品来的，作为甲方可以直接测试，来看产品匹配度，很快就可以得到反馈，而自建团队来做的话，可能需要几个月甚至一两年的时间来开发，业务可能等不起，开发完了之后产品是否真的符合预期，又有很多因素决定，结果具有不可预见性。</p><p></p><p>其次是服务，供应商相比自建的团队，通常会有优势。原因如下：</p><p>因为供应商见识了更多的客户场景，而ToB公司，长期的行业Know-How的积累，是这个公司的核心竞争力，供应商会不断的从优秀客户那里汲取经验，反哺给那些不那么先进的客户，良性循环，多方共赢。也是因为供应商见识了更多的场景，可以对产品做更好的抽象，可以让产品更通用，更像一个产品，而自建团队做的产品，通常更偏工具，无意冒犯，我说的是通常。供应商之所以在运维这个赛道创业，大概率是在这个赛道有些建树的，相比自建团队，供应商的顶层认知通常会好一些，你真的去招人的时候就会发现了，最牛逼的那群人，要么创业了，要么太贵了，要么不愿意来。</p><p></p><p>另外说一下成本问题，供应商的收费大概率是比自己招人（前提是招到合适的人）来的划算，否则的话，商业逻辑不成立。这个道理显而易见不再赘述。</p><p></p><p>从第三方供应商这里获取运维能力，看起来是碾压自建团队的，所以，后面的文章还用读么？其实也不尽然，对于某个运维能力，到底更看重的是产品能力，还是服务能力，你最需要的是产品能力还是服务能力，需要 case by case 的看，后文，我会从业务侧需要的各个方面的运维能力分别拆解。</p><p></p><h2>业务需要哪些技术支撑能力</h2><p></p><p>运维本质是一类技术支撑能力，跟基础架构团队很像，有些活放到运维团队是可以的，放到基础架构团队问题也不大，甚至有些公司直接把这类人放到业务研发团队，我们暂且不管分工的问题，先来梳理一下业务需要什么样的技术支撑能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5e/5e8c60c9b2329cef18b88d3319160625.png\" /></p><p></p><p>这个图其实已经很能说明问题了，我再稍微啰嗦一下：</p><p>可靠的基础环境和组件：业务程序要运行，需要基础网络、硬件、操作系统、数据库、中间件等，需要这些环境和组件稳定可靠快速安全变更的能力：快速变更的能力，大家很容易理解，作为研发人员，写了一个feature或者做了个bugfix，肯定很想快速交付，但是变更很容易导致故障，变更需要受控，需要尽量确保安全可靠性保障能力：软件部署到生产环境之后，可能会遇到各类问题，如何能够提前做好风险量化，如何能快速发现问题、定位问题、快速止损，这可能是业务侧对运维侧最重要的诉求了最佳实践：业务依赖很多基础支撑能力，这些能力用的如何？是不是业界最佳实践？是不是公司内其他大部分业务的最佳实践？需要基础支撑团队反哺给业务</p><p></p><h2>各个能力如何获取</h2><p></p><p>上面谈及的四个能力，应该如何获取？下面我们就掰开了揉碎了讲一讲。</p><p></p><h3>可靠的基础环境和组件</h3><p></p><p>首先说基础硬件环境，显然有两种选择，上云 or 自建，如果是政策有要求必须自己折腾，那没有办法，以政策为准。如果可以自行选择，现在这个时代，大概率是上云更合适，除非公司体量很大，机器量很大，自建才可能有优势。注意，我这里说的是才可能，算成本的时候切记要把人力成本算上，别只算了硬件的成本。</p><p></p><p>关于择业：对于系统运维工程师、网络运维工程师，看起来并不是个好消息，云的出现确实抢占了一部分这类岗位的空间，没办法，时代的车轮滚滚向前，大家都是历史的尘埃。</p><p></p><p>再说组件，比如MySQL、Redis、MongoDB、Kafka、ElasticSearch、Nginx、Kubernetes等等，显然有3种选择，使用云上PaaS产品 or 自己折腾 or 自己出硬件+供应商出方案和服务。针对每种选择，我们分别做一下点评：</p><p>云上PaaS产品：如果规模不大，没有相关人才储备，使用云上PaaS产品，是比较合适的，可以快速把能力建设起来，选择使用云上PaaS产品的甲方，通常已经使用了云上的虚拟机、Kubernetes类的Runtime环境，顺带采买PaaS类的产品，也比较丝滑，不需要再跟新的供应商做对接。自己折腾：如果某个组件规模很大，或许是有自建的必要性的，比如Kafka，自己折腾，招2个人一主一备，水平还可以，出了问题能兜底，在北京的话每年大概100万的成本，得多大的规模才能从硬件和组件上省出这些钱呢？当然，也可以招聘一些低成本的运维工程师（划重点，这里可能需要运维工程师，但是职级不高），能解决日常问题，高阶问题解不了，高阶问题可以求助外部供应商的专家服务。自己出硬件+供应商出方案和服务：第三方供应商相比云厂商的PaaS产品，通常性价比更高，响应更快，但是组件如此之多，每个供应商大概率只能搞定有限的几款，作为甲方，可能要同时跟多个供应商打交道，略微麻烦。对于需要跨云协同的产品，比如统一监控、故障定位、FinOps相关的产品，如果公司用了多家云或是混合云架构，大概率是第三方供应商更为合适。</p><p></p><p>关于择业：各组件的资深老炮，第一选择是去云厂商工作或创业输出经验，第二选择去自建组件的大厂，普通中小厂，很难有高薪资，毕竟第三方的专家服务性价比不低。</p><p></p><h3>快速安全变更的能力</h3><p></p><p>业务研发最常做的变更是二进制、配置的变更，当然，还有对基础环境以及组件的变更需求。</p><p></p><p>我们先说二进制、配置的变更，怎么做才能又快又安全的迭代呢？可以分阶段，公司还比较小的时候，不用太关注工具的建设，只需要定好规范和流程即可。规范方面比如：部署在哪个账号下，哪个目录下，日志怎么放，进程怎么托管，任何变更必须能够可回滚等等，流程方面比如：变更通报机制、多模块协同上线机制、无法回滚的需要有审批机制等等。</p><p></p><p>然后，需要有历史变更的量化数据，比如某个团队最近一个季度有多少次变更，回滚率如何，故障率如何，各个团队有个对比，做的不好的团队就会在下个季度好好改善的。</p><p></p><p>当公司继续变大，就可以投入人力做变更类的平台，把规范制度落实到平台上，产出量化数据，因为不同的公司情况各异，在传统的物理机虚拟机时代，很少看到有商业化的变更系统。当然，Kubernetes起来之后，屏蔽掉了底层的很多差异，基于Kubernetes做变更平台通用性强了很多，开始有相关的产品出来。</p><p>生产环境的变更，和测试环境、联调环境的变更还不太一样，生产环境对稳定性要求比较苛刻，测试环境、联调环境则相对没有太高的要求。所谓的CI/CD的系统，大都是针对测试环境、联调环境的，能够对生产环境做到CD的公司，屈指可数。</p><p></p><p>划重点：测试、联调环境的CI/CD系统，更多的是为研发效率提速；生产环境的变更系统，更多的是确保稳定性、落地规范制度的。公司前期体量小，靠规章制度就够了，后面就需要规章制度+变更平台协同发力了。</p><p></p><h4>这个规范制度谁来定？变更平台谁来开发？</h4><p></p><p>规范的制定其实偏前期，可能运维团队都还没有的时候规范就已经有了，所以，大概率是CTO以及下辖的Core团队来制定就好了。如果之前没有制定过，运维总监（运维总监上场了）可以牵头制定，CTO下辖的Core团队来评审（大家有参与度），最终CTO拍板（自顶向下）发布，大家执行。</p><p></p><p>变更平台的开发，由运维团队来开发相对比较合适，后文还会介绍一些其他的平台，成立一个专门的运维团队（这里我说的运维和SRE没有区别，你也可以管这个团队叫SRE团队）是合适的。变更平台因为要落地公司的规范，外采的情况比较少，公司大到一定规模之后，基于开源的东西自研、攒，是个大概率的选择。</p><p></p><p>关于择业：变更管理是企业中的重要一环，同时服务于稳定性体系。这是一个典型的DevOps岗位，天花板大概在P7+的水平（纯属个人看法，仅供参考）。</p><p></p><p>另外就是基础组件和环境的变更，典型的比如MySQL表结构、Nginx配置、DNS、VIP等等，这类变更可以内化到组件管控平台里，让组件能力提供方提供变更入口和管控能力。</p><p></p><h3>可靠性保障能力</h3><p></p><p>这个能力非常重要，SRE就是Site Reliability Engineering的缩写，即站点可靠性工程。从CTO的角度，软件部署到生产环境，后续可能会有各种问题发生，希望能有一套工程体系来保障可靠性。这是一个巨大的话题，本文不会事无巨细，只是理清楚哪些事哪些人来负责即可。</p><p></p><p>所谓的可靠性，就是与故障做斗争的过程，所以，我们还是来看故障的生命周期，从生命周期的各个环节着手，把故障打趴下，甚至直接把它扼杀在摇篮之中。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0e/0e2dd11d2e2a66049feaf01a98e4b318.png\" /></p><p></p><p></p><h4>故障开始之前降发生</h4><p></p><p>事前的预防和风控，有很多的工作。比如：制定告警完备性标准并对各个业务线做量化评估；制定定位原则和流程以及故障定级定责的标准；提前梳理各个业务的核心功能和服务模块的对应关系，建立全局稳定性视图或者作战室，便于快速揪出故障模块或接口；对架构做优化；梳理故障预案并定期演练保鲜，也就是混沌工程那摊事；等等等等。</p><p></p><p>这里有些事情是需要业务研发来搞定的，比如架构优化，剩下的事情，我的建议是：让运维团队来牵头，研发配合。比如CTO下辖的Core团队大概率既有运维一号位也有各个业务的技术一号位，名义上要CTO拍板，授权运维一号位来牵头，各个业务的研发一号位来配合，当然了，实际操刀的时候，运维一号位可能是找了一个得力干将来实操，各个业务线可能也是有技术一号位依仗的人来做接口人配合。</p><p></p><p>除了架构优化之外，其他这些事情都是横向的事情，是可以有一些方法论和最佳实践的，把大家拉通，有利于共享这些方法论和最佳实践。当然，有些人会有疑问：我们能否直接在研发团队找个人来组成这么一个稳定性的虚拟组织，共同推进这个事情呢？其实也可以尝试。不过会有这么几点问题：</p><p>每个业务线通常只有这么一两个接口人，人少活多，这个人大概率很难兼顾业务代码开发和稳定性工作，如果这个人全职做稳定性了，其实就相当于SRE了如果是SRE，和业务研发人员的考核体系其实是不同的，KPI怎么定？而且这个人可能也没有很好的归属感如果这个人同时兼顾两个事情：稳定性、业务研发，可能会引发人的惰性，稳定性工作遇到问题的时候，天然的就会想去干点业务研发的活，业务研发遇到问题的时候，又想偷懒去干稳定性的活</p><p></p><p>划重点：事前的预防和风控，请各位CXO找运维总监要结果，但是必须给予极大的配合，从上往下推。对于搞定这摊事的SRE工程师角色，看起来是需要非常专业的高级别人士，工作5年以内大概率认知跟不上，或许，从资深研发团队招SRE是一个不错的选择，各位CXO可以尝试下。</p><p></p><h4>故障开始之后降影响</h4><p></p><p>一旦故障发生，我们的首要目标就变成降影响了。相关团队立马协作起来，快速定位直接原因、快速止损，事后再慢慢排查根因即可。这里会涉及如下一些工作内容：</p><p>定义故障：通常，业务的指标出现问题就代表故障开始了，比如订单量下跌、叫车呼叫量下跌、支付量下跌，老板会尤为关注这类指标；而某个机器的CPU飙高或者磁盘用满，可能只是团队内部消化的问题，甚至K8s类的系统自动漂移解决，通常对客户主流程没有影响，老板是不关注的。为了不至于草木皆兵，我们就需要区分故障和问题的定义，不同的业务线指标不同，但是总体方法论是一样的。响应故障：故障告警接收人是给业务研发？还是SRE？还是OnCall中心？不同的公司做法差异巨大，我个人的想法是：直接发给有能力处理的人！没有非黑即白，不同的告警不同的处理机制，比如基础网络有问题，显然是要发给网工，某个业务有问题，发给对应的运维和研发，尽量不要在中间再转一次，发给张三，张三处理不了去联系李四，就浪费时间了，故障处理应该争分夺秒。快速定位：一套行之有效的故障定位系统，是大杀器。故障定位系统通常是基于可观测性数据构建的，可以看做是驾驶舱级别的产品。可观测性数据是海量的，如果不经过梳理利用，这些海量的数据无法变成有价值的信息。从定位的角度来看，通常需要的是：可观测性体系+故障定位+持续运营，这里要展开的话内容就太多了，如想详细探讨可以联系我，什么？不知道怎么联系？SRETalk公众号，了解一下。快速止损：止损要快，就要有完备的预案，每次故障复盘的时候，建议CTO、运维总监关注预案有效率，就是说，这个故障是否是利用一个既有的预案来止损的，还是现攒的解决方案。如果是现攒的，说明你们的预案不够完备啊。</p><p></p><p>OK，上面洋洋洒洒一片，回归问题，针对这块工作内容，CTO找谁要结果？我的建议是：SRE团队（文中多次出现运维、SRE字眼，在本文中基本都代表一个意思，这里的运维不止是Operations）。显然SRE无法搞定所有的故障，应该说大部分故障都得借助其他团队的人，但是CTO总不能一会找A团队一会找B团队吧。所以，SRE要携CTO的尚方宝剑，牵头整体的稳定性建设，各个业务需要出接口人极力配合，所谓的稳定性建设，包括事前的预防风控、事中的统筹协同、事后的复盘推进，这也是SRE对公司的最大价值。</p><p></p><h3>最佳实践</h3><p></p><p>这个内容很多，比如用什么机型套餐比较合适，用什么组网方式比较合适，用哪些组件公司具有更好的掌控力、可以得到更好的支持（不管是内部团队还是借助第三方供应商），公司推荐甚至要求的编程语言、框架是什么，业界推荐的接入层方案是什么？变更方案是什么？可观测性怎么做？等等等等。</p><p></p><p>不可否认，牛逼的业务研发团队，这些实践方式是门清的，但是同样不可否认，业务线多了之后，水平是良莠不齐的，水平差的团队势必需要教练角色的人，总不能啥事都去找CTO吧，SRE团队作为一个横向的技术团队，特别适合负责这摊事。但是显然，这是一个高端职位，新瓜蛋子干不来，招聘高阶人士做业务BP是推进技术栈趋于统一的有效手段，如果CTO用不好这个抓手，技术体系会百花齐放，后面则是各种治理困局。</p><p></p><p>上面的四个支撑能力，业务侧应该如何获取，CTO应该如何统筹，各团队应该如何配合，大致就说这么多。下面我们再做两个小结。</p><p></p><h2>小结1：CTO如何帮助业务线获取这些支撑能力？</h2><p></p><p>显然，CTO不需要亲力亲为，但CTO要做好把关，CTO要颁发政策，是全军统帅。横向的工作落给SRE团队，各团队出接口人极力配合，大概率是个最佳实践。如果把横向的工作目标完全打散到业务团队自闭环，就无法享受到横向团队带来的经验传播能力。而且，屁股决定脑袋，不在其位不谋其政，各个业务自己容易有小九九，中心的横向组织也是一个削藩机制，抱歉这个词用的重了，本意是好的，你要自己体会啦。</p><p></p><p>另外补充一点FinOps的话题，FinOps也是一个横向能力，是否也要交由SRE来做呢？这个倒是未必。就让业务自闭环我觉得也挺好的，业务自己要负责盈亏，IT支出是支出大头，业务的GM理应是很上心的，CEO把营收净利相关的KPI压给业务GM，业务GM可以自闭环做好折中的。</p><p></p><h2>小结2：运维/SRE择业建议</h2><p></p><p>如果没有太高的职级和薪资期望，做一些相对基础的Operations工作也是可以的，10年内这个岗位大概率不会消亡。如果对职级和薪资有更高期望，先深扎某个细分领域，做到行业专家，是一条行之有效的路径。再之后，则讲究多个技术方向的融会贯通了，又要往广度发展。再之后，创业或者高管。</p><p></p><p>作者简介：</p><p>秦晓辉，Open-Falcon、Nightingale 创始研发，极客时间《运维监控系统实战笔记》作者，公众号 SRETalk 主理人，快猫星云创业合伙人，创业方向是稳定性保障方向。</p>",
    "publish_time": "2023-03-11 13:20:47",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "作业帮聂安：运维如何转型，听听作业帮的OPaS思路",
    "url": "https://www.infoq.cn/article/OTr4OQ7jVdI9Z9JHpwNF",
    "summary": "<p></p><blockquote><a href=\"https://flashcat.cloud/blog/sretalk-002/\">作者著</a>\"：我们观察到：国内运维行业，不同的公司做法差异巨大，从业人员水平参差不齐，缺少普遍性行业认知，难以形成合力（这也会让 To B 的产品异常难做，不利于行业整体发展），甚至在部分公司，运维人员处在技术鄙视链最底层，我们希望为行业带来一些新的思路和发展推动力。这需要很多行业老炮一起，输出观点，共同碰撞，才有可能形成一些先进的共识，形成行业前进的思想旗帜。所以，我们准备策划《运维百家讲坛》这么一档栏目，诚邀 100 个运维总监（或更高）级别的老炮，通过采访或约稿的方式输出他们的观点，给行业一些借鉴。<a href=\"https://www.infoq.cn/article/kTtlLZxNUPmlvYpzA0eF\">第1期</a>\"央请井老板发表了很多有趣的观点，有人留言说是运维劝退指南，哈哈，这一期的嘉宾，观点会有不同，请大家抱着开放的心态，听百家之言，自己做职业、人生规划。所谓兼听则明，偏信则暗，如果只听自己顺耳的，大概率不会有深度思考碰撞，憾事也。这里是接地气、有高度的《<a href=\"https://mp.weixin.qq.com/s/Y4rIfV4_7MuYigLNNrtifg\">运维百家讲坛</a>\"》第 2 期，开讲！</blockquote><p></p><p></p><h2>嘉宾介绍</h2><p></p><p>本期我们邀请的是作业帮的运维负责人聂安，聂安是资深行业老炮，先后履职于阿里、小米、滴滴、作业帮，有10多年的运维/研发/管理经验。</p><p></p><h2>要点简述</h2><p></p><p>传统运维，职责是将工业制成品组装成服务、交付给用户，并维持服务运转；特点是强依附于业务领域危机，云原生时代公有云大量使用、微服务架构和DevOps真实达成、工具体系持续繁荣，传统运维的职责不断被外包、转移、替代，出现了领域危机组织结构，协作方式从人人协同、逐渐升级为平台自助，运维的主旋律从横向协同、转变为服务产品和技术中台运维转型，技术上通过自助化的平台、对外提供运维服务能力OPaS(OP as Service)，分成对象、场景两层；底层对象做到同构维持，就构成了一套可持续的运维架构业务运维，服务化转型的核心是角色认知，运维人要把自己从依附于业务的运营角色、调整为独立的运维服务提供方；在超服务视角上，业务运维大有可为组件运维，掌控组件本身、比纯运维管理更进一步，遵循洋葱模型，即立足于资源交付、建设管理平台、再深入到组件自身的专业领域运维开发，剥离掉重复的平台迭代工作，聚焦到公共的运维中台，做专技术、做高杠杆</p><p></p><h2>运维阶段</h2><p></p><p>互联网运维，先后经历了纯手工、标准化、平台化、数智化等几个阶段，如下图。其中，DevOps是技术驱动的组织变革、非专业变革。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/43/4358d1fcec907bb2eafc528a43bcf438.jpeg\" /></p><p></p><p>从运维的发展历史，我们可以看到几个特点：</p><p>继承性。新阶段往往继承、发扬老阶段的优秀经验，又会在理念、技术、组织上有所创新比如，平台化继承、强化了标准化阶段的成果，数智化继承了平台化的成果、同时引入大数据技术职责转移。DevOps是运维管理模式的分水岭，DevOps之后的运维一方面，沿着运维专业化的方向继续推进，对更高量级的运维对象、保持同构管理的能力另一方面，则强调运维研发融合，运维职责逐步转移到业务研发</p><p></p><p>学习某个领域的发展历史，能够让我们以史为鉴、顺势而为。</p><p></p><h2>传统运维</h2><p></p><p>在传统的运维模式中，服务对象基本可以划分为三层。最底层是硬件基础设施IaaS，主要是计算、网络、存储构成；中间层是软件基础设施，包括了操作系统、虚拟化技术、代码框架、中间件等；最上层是业务层，主要是应用服务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c9/c9042295a1d6dff57d8c8cbcc5a56a56.png\" /></p><p></p><p>传统运维的职责是，通过一系列的流程、技术、方法，将工业制成品组装成服务、交付给用户，并维持服务运转；通常要求达成稳定、成本、安全、效率等多个维度的目标(运营性)。从某种程度上来讲，传统运维需要依附于业务才能产生价值；很多公司，会把是否理解业务、作为运维工作者的主要考核之一(依附性)。</p><p></p><p>随着云计算、云原生技术的普及，传统的运维模式遇到了很多挑战。比如:</p><p>企业使用公有云后，IaaS/PaaS甚至SaaS基本都服务化了，通过API即可获取；大量的运维建设工作、由云厂商帮忙完成了，比如硬件、系统、网络、数据库、大数据等，原厂只需要保留少量的专业选型和集成能力(外包)云原生技术普及后，微服务架构和DevOps大范围达成，之前由专业运维人员完成的操作、逐步交给业务研发自助完成，比如交付、变更、监控、容量等，运维职责被大量转移到业务研发(转移)公有云的专业聚集效应、以及云原生的开源体系，提供了持续向好的工具化前景。工具化提升效率后，同一岗位需要的人工变少；工具化沉淀了专业能力，对操作人员的技术门槛越来越低；工具进化到自动化、智能化后，机器就可以替代人工。平台对人工的替代，还在逐步深化(替代)</p><p></p><p>上面讲到的，基础设施外包给公有云、云原生之后运维职责转移给业务研发、平台替代人工的专业性。面对这样的趋势、事实，运维从业者需要做出一些转型。</p><p></p><h2>组织结构</h2><p></p><p>首先聊聊组织结构。长期看，云原生时代的公司组织形态，由如下几部分构成：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b7/b70ddd2935b9b63978b9730845d828ed.png\" /></p><p></p><p>最上面的终端用户，是企业的甲方客户、也是潜在的营利人群。业务团队，为终端用户负责，角色包括了产品、商务、市场、营销等。业务研发，直接为业务团队服务，主要是提供SaaS化的应用/服务。平台研发，则是为业务研发服务，提供各种各样的PaaS化能力，对下封装了云厂商。还会有一些跨功能组织，如成本运营FinOps、效率运营EP、行政团队IT等等。</p><p></p><p>在新的组织结构中，大家最终的目标是各司其事、服务好终端用户。业务团队更关注业务价值，研发体系聚焦在服务质量。随着信息化技术的进步，当前由跨功能组织履行的职能、将逐步分解到平台研发团队，组织协作的主要方式从人人协同、升级为平台自助。运维有了新的岗位目标，即：运维的主旋律是管理平台、是资源&amp;技术中台，不是横向协同，运维要做高技术杠杆、赋能业务、助力企业提升经营效率。</p><p></p><h2>技术架构</h2><p></p><p>运维转型，目标是：通过自助化的平台，向上层团队、提供运维管理服务；本质是运维服务化OPaS(OP as Service)。按照内容差异，运维工作可以分为对象管理、场景管理两大类，如下图所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1a/1ac9bd117c4f123254b6a38b5cb4d623.png\" /></p><p></p><p>对象管理是纵向模式，围绕运维对象、建设生命周期的管理平台。运维对象的分类，可以按照IaaS资源(机器、网络、存储、云服务)、PaaS组件(数据库、缓存、MQ、网关)、SaaS应用(业务中台、业务应用)、服务框架(运行时、代码框架、名字服务)等维度，不同公司的分类粒度不尽相同。每类对象都有独立的管理平台(烟囱)，管理平台功能要覆盖运维对象的完整生命周期，关键阶段包括 建模(元数据)、交付/变更、监控/度量、下线等，跟公有云的管理功能类似。对象管理的目标是，产出纵向完备的云产品、建成内部云平台ICSP。</p><p></p><p>场景管理是横向模式，根据运维场景、纳管多种运维对象的生命周期阶段。运维场景的分类，包括交付/变更、监控/度量、多云、成本等等，非常贴近业务研发的工作习惯、覆盖少数高频场景，不同公司大同小异。每类运维场景，有独立的场景管理平台，如工单中心、数据中心、FinOps平台等。场景管理建立在对象管理之上，场景管理平台对运维对象的纳管方式包括 统一模型、汇聚数据、编排管控API等。场景管理的目标是，提供自助化的业务管理能力、建成内部开发者平台IDP。</p><p></p><p>运维对象的产生方式，常见的有 自研、开源搭建、外采(公有云)等。每种运维对象，又能再细分出不同的品类、集群、实例等，规模和复杂度空前巨大。只有维持运维对象管理特征的同构，才能大规模建设、低成本维持运维服务化，进而实现规模运维(技术杠杆效应)，因此运维对象的同构维持是整个运维架构的基本前提。</p><p></p><h2>同构维持</h2><p></p><p>同构维持，针对的是运维对象的管理特征、不是所有特征。同构维持，方式是：控增量、修存量、防裂变。如下图，通过平台做需求交付、来控增量，通过度量驱动治理、来修存量，通过规范服务框架、来防止技术体系的大范围裂变；平台、度量严格遵循规范，规范也需要度量或平台的问题输入来完善，三者相辅相成。规范，分为服务规范(对应服务治理)、管理规范(对应运维管控)等类型。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/93/934861ab8bbc5e56abe59fb750921e9a.png\" /></p><p></p><p>同构维持，依赖主责明确的组织分工。比如，运维专注于管理，剥离业务Toils、将之返还给业务研发，如现状治理、报警响应、CD；业务研发专注于业务实现，剥离服务框架这部分非业务逻辑、将之交给基础架构实现，如服务发现、流量控制；基础架构专注于服务框架等中台能力，剥离管理职能、将之交给运维，如需求交付、变更管控等。文化影响也不能忽视，运维和架构会通过沟通引导的方式，输出理念、培养用户习惯，如对个性化需求不提供SLA承诺、对标准应用提供开箱即用的观测能力等。</p><p></p><p>以运维对象同构维持为基础，向上支撑运维服务化技术体系，这就形成了一套可持续的运维架构，如下图。在当前的技术水平下，以自助平台为主的运维服务能解决70%的需求、剩余30%仍需要人工，比如需求沟通、问题排查、结果验收、政策合规等。随着技术和理念的进步，相信运维服务化的占比将进一步上升。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b5/b5c8166a5979c13f7bbc79e5ff923331.png\" /></p><p></p><p>备注：本文中的服务框架，既包括N年前的代码框架、代码库，也包括当前流行的微服务治理，过渡阶段、起名捉急。</p><p></p><h2>转型实践</h2><p></p><p></p><h3>运维服务化OPaS</h3><p></p><p>业务运维，也有人叫应用运维，离云原生最近、被冲击的最大。除却传统的规范制定、流程建设、全局管理等跨团队职责外，业务运维要朝着服务化的方向转型，路径如下图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e7/e7aaff9a23b9cae852d13186ccad7924.png\" /></p><p></p><p>第一，角色认知要转变。把自己从依附于业务才能产生价值的运营角色，调整为具有独立价值的运维服务提供方。角色转变是关键组织上，重新划分主责。业务研发是应用主责方，运维不是应用主责方、也不是外挂式保姆，而是应用的管理能力提供方，业务研发使用运维服务、自助完成运营工作机制上，重构评价体系。业务运维岗位的绩效，不再强绑定业务团队和业务研发、而是更突出运维服务化，做轻主观评价、做重技术评价第二，运维转型四步走。明确对象 –&gt; 抽象共性 –&gt; 建设平台 –&gt; 实现规模运维业务运维的对象，首先是应用(也称为服务)，然后是应用的扩展场景(如业务视角、公司全局视角)抽象共性是难点，也是关键点。应用的数量大、技术栈复杂、个性化特征非常多，要抽象出应用的管理共性、避免陷入个性化case。严格来说，应用的共性特征才是运维管理的对象建设平台指的是应用管理平台，规模运维是一个可持续的终态第三，应用对象维持同构。除去服务化能力建设外，运维人员的主要精力应该投在同构维持上</p><p></p><p>运维服务化OPaS(OP as Service)，是我们转型中期、从业务运维角度提出的目标，指出了大方向、但缺少路径比较抽象；之后，OPaS逐渐被细化为 ICSP+IDP 的运维架构，适用范围扩展到整个运维团队，才算有了清晰的路径和抓手。</p><p></p><h3>超服务视角(业务运维)</h3><p></p><p>除了服务化，业务运维还可以主导超服务视角(现已更名为场景)建设。云原生下的DevOps技术拼图并不完整，只搞好了应用+计算这一块、其它方向存在能力空白，特别是向上的业务视角、部门视角、公司视角等，姑且称为超服务视角。对于超服务视角，业务研发人员通常没有能力、没有动力主R(主责)；部门主管或架构师可以照顾到本部门，但受限于岗位职责、很难扩展到全局。反观，超服务视角是传统业务运维的老战场，具备无与伦比的体验、理解和认知优势。业务运维主导超服务视角建设，既能添补云原生领域的空白、又能发挥业务运维的专业优势、借势转型，会是一个双赢的选择，如下图。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f8/f84038b5805c4bebdc4bd2f44c49e263.png\" /></p><p></p><p>超服务视角，包括但不限于：</p><p>需求交付：工单中心，编排引擎、执行引擎变更管控：五条军规、集中管控，编排审批、执行审批、服务检查、变更度量观察度量：聚合展示业务视角的观测、度量数据，支持下钻到应用粒度多云架构：贯穿整个技术体系的度量、治理、预案、演练成本管控：公司全部IT资源的计费、分摊、管控、优化，独立为FinOps方向规范制定：公司全局角度的运维规范制定、流程落地监督，避免小团队烟囱式重复建设</p><p>等等。</p><p></p><p>云原生下的DevOps技术拼图，向下看也有能力空白，如针对CDN、对象存储、MQ、EMR等基础服务支持的并不完善，2022年还处在探索期；站在运维管理角度，只要被服务框架(鉴权、发现、通信、感知、流控)辐射到了，就算被云原生纳管了。</p><p></p><h3>洋葱模型(云服务、中间件、大数据运维)</h3><p></p><p>云服务、中间件、大数据等运维对象，技术栈收敛、专业聚焦。运维人员转型实施时，可以按照洋葱模型来。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2b/2b5702b9fc1ab3d460f3b4715cfde0f4.png\" /></p><p></p><p>第一阶段，立足于资源交付，把原来的运维对象、转变为资源实体，向上游交付有保障的服务功能、建立岗位价值的底线第二阶段，投入大精力、建设管理平台，把资源实体的生命周期管理好、解放自己，平台要能ToC自助化、实现解耦第三阶段，深入到组件自身的专业领域，从架构、代码、性能、运维等方方面面提升专业性。做到这一步时，运维已经成为该领域的服务专家、而不仅仅是管理员</p><p></p><p>洋葱模型，最早在数据库、大数据、中间件等岗位上被验证，后来被拿过来用到云服务上、同样成功了。比如，我司的云服务运维CloudOps团队，就是按照洋葱模型、来实施转型的，具体如下，</p><p>这个团队的对象就是各种云服务，分布在腾讯、阿里、百度等几家云厂商两年前，通过各种手工的方式，对外提供机器、存储等资源，支撑了业务的快速发展(资源交付)之后，我们开始建设多云管理平台，管理机器、带宽、对象存储、CDN等云服务的生命周期。在这个过程中，CloudOps的管理平台成功转型为公司内部的二级云服务提供商ICSP(平台能力)接下来，我们还会不断加强对公有云产品的学习、认知、选型、演化推动等等，争取在这个领域建立更多的专业性(组件自身)</p><p></p><h3>运维中台(运维开发)</h3><p></p><p>随着业务运维、组件运维、系统运维(资源网络云服务)等角色开始参与开发工作，留给运维开发DevOps团队的空间逐渐变少，转型过程中出现了分工不清晰的情况。参照组织结构、技术架构的升级预判，我们重新调整了OpDev的岗位定位：OpDev不应该是运维人员的开发外包或附庸、而应该有自己独立提供的服务。于是乎，原有的运维平台被拆分成了两部分，一部分偏重功能迭代无法复用、交给原使用方自己维护，比如IDP资源控制台、ICSP场景管理工具等；另一部分是公共功能、抽象为运维中台由OpDev负责，如统一账号IAM、工单编排引擎、监控指标采集器等，如下图。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/aa/aa819fe15d62c2690502269f6b3c25a4.png\" /></p><p></p><p>运维中台是原运维平台的子集，不需要重新构建领域知识，需要重新做一下领域抽象建模、对代码质量要求也比较高(同基础组件)，这正是OpDev童鞋的长处所在。随着职责的聚化缩减，OpDev要同步瘦身、做到更高的杠杆。</p><p></p><h2>一些教训</h2><p></p><p>简单分享下我司的一些转型教训，包括：</p><p>转型和保守要折中。传统运维转型到服务提供方，既不会一蹴而就、也不会全员迁徙，总要有人留下来殿后(当前技术水平大概73开)。资源集中后，殿后人员会获得更多的价值回报研发能力区分梯度。从运维转型到开发的童鞋能力参差不齐，要从业务需求迭代做起，要严控设计和验收来保质量、要有意识的补齐工程理论，要配备精良的运维中台能力、保证底层干净平台不是唯一选择。平台是服务能力最有力的承接方式，但绝对不是唯一方式。组织、文化、规范、流程、平台，一样都不能少(但转移成本可能略高)明确运维管理对象。运维、特别是应用运维，管理对象不是应用本身、而是应用的共性特征；应用的共性特征越多，应用运维的价值才能越大(杠杆)组织保障不容忽视。组织结构是第一生产力，CTO要有所作为、目标明确、清晰分工，如明确主责、设置独立验收机构、度量和治理循环等，这是运维转型的组织保障警惕纯粹项目思维。运维还是要参与一些项目，短期内爆发价值、揽获成就感，但也很容易人走茶凉、价值归零；需要有意识的设计目标，在项目过程中的沉淀服务能力预防比应急更有效。稳定性问题要在架构领域求解，预防比应急更有效。优先延长MTBF、其次才是缩短MTTR</p><p></p><p>以下是附加内容，不是本文核心。</p><p></p><h3>需求交付的演进</h3><p></p><p>无论是公有云，还是内部的K8S平台，都存在着大量的需求交付操作。这类ToM(ToManager)的交付平台，往往缺少必要约束、只能对资深人士开放。</p><p></p><p>为了优化分工、提升效率，可以通过「工单编排+审批」的方式、将运维管理面ToC(ToRD)；工作流/工单本身会大量融入运维管理的最佳实践，可以安全的开放给研发。这是运维能力服务化的一个重要方向。交付自助化的演化路径如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/99/9956aca9dd4c2c79db5be343a9234249.png\" /></p><p></p><p>目前看，从需求到技术方案的沟通环节，是比较难自助化或者自动化的，需要将来更多的尝试。</p><p></p><h2>规模运维的边际点</h2><p></p><p>规模运维的经济学本质是边际成本，是「运维管理边际成本递减vs同构维持边际成本递增」的相互作用。如下图，运维对象数量较少时，运维管理的成本占大头儿，比如建设平台、人工运营；运维对象数量变大后，同构维持构成主要成本；边际转折点，会受到技术、理念等环境因素的影响。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/19/196c95491d46b0b273f982b2ffa67a75.png\" /></p><p></p><p>云原生技术，降低了同构维持难度(促进同构维持曲线右移)、提升了运维服务化能力(促进运维管理曲线下移)，使得运维人员能够以更低的成本、管理更多运维对象，因此显著提升了生产效率。</p>",
    "publish_time": "2023-03-11 13:34:46",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "快猫来炜：如何端好运维的饭碗",
    "url": "https://www.infoq.cn/article/TLGRcZ8Zz7JmyNvd6rCQ",
    "summary": "<p></p><blockquote><a href=\"https://flashcat.cloud/blog/sretalk-003/\">作者著</a>\"：我们观察到：国内运维行业，不同的公司做法差异巨大，从业人员水平参差不齐，缺少普遍性行业认知，难以形成合力（这也会让 To B 的产品异常难做，不利于行业整体发展），甚至在部分公司，运维人员处在技术鄙视链最底层，我们希望为行业带来一些新的思路和发展推动力。这需要很多行业老炮一起，输出观点，共同碰撞，才有可能形成一些先进的共识，形成行业前进的思想旗帜。所以，我们准备策划《运维百家讲坛》这么一档栏目，诚邀 100 个运维总监（或更高）级别的老炮，通过采访或约稿的方式输出他们的观点，给行业一些借鉴。讲坛第1期《<a href=\"https://www.infoq.cn/article/kTtlLZxNUPmlvYpzA0eF\">井源的运维几何</a>\"》和前段时间马驰的《<a href=\"https://mp.weixin.qq.com/s/z6FV0-lghXqC6rOPXe34kw\">是时候让运维集体下岗了</a>\"》在业界引起广泛讨论，运维岗位真的没有前途了吗？如何把饭碗端稳？这一期，我们采访了快猫星云的来炜，来炜是运维破圈创业人士，既然能创业，一定是在行业内有很深的积累的，他会怎么看待这个问题？让我们一起来听一种新的声音！这里是接地气、有高度的《<a href=\"https://mp.weixin.qq.com/s/Y4rIfV4_7MuYigLNNrtifg\">运维百家讲坛</a>\"》第 3 期，开讲！</blockquote><p></p><p></p><h3>介绍一下您自己以及现在的公司？</h3><p></p><p></p><p>大家好，我是快猫星云的来炜。快猫星云是一家云原生智能运维科技公司，由开源监控工具“夜莺监控”的核心开发团队组成。快猫星云打造的云原生监控分析平台——“Flashcat平台”，旨在解决云原生架构、混合云架构下统一监控难、故障定位慢的问题。 如果想更多了解快猫星云创立背后的故事，大家可以进一步阅读 ITPub 对我的一个专访《<a href=\"https://mp.weixin.qq.com/s/LL0T3pBrhTa8i8SkOhY14g\">十年死磕，从一线工程师到CEO</a>\"》，欢迎大家指正。</p><p></p><h3>有些运维老炮反映公司对运维的价值所知甚少，您是怎么给公司讲清楚运维的价值的？</h3><p></p><p></p><p>把工作的价值，如何通俗易懂的给公司管理层讲清楚，并取得理解和支持，是所有中后台技术团队普遍面临的难题，否则失业分分钟的事情，运维工作的价值讲清楚更是难上加难。</p><p></p><p>从我的朋友圈来看，时不时就会看到劝运维下岗/转行的帖子：</p><p>比如瑞典马工的《是时候让运维集体下岗了》，振聋发聩，开篇就提到：明人不说暗话：在云原生和DevOps成熟的今天，运维作为一个岗位和团队已经完成了历史任务，应该退出舞台了。再比如带我入行的井老板，在 SRETalk 第一期中，用心良苦的劝导：随着科技的发展，时代的变化，一个岗位的消亡是很正常的事情，及时做好调整和规划才是思考的重心。</p><p></p><p>但是，运维这个岗位以及背后的运维人，从来都是一次次站在要被淘汰的边缘徘徊，又一次次倔强的起死回生，柳暗花明。他们往往乐于自嘲、主动拥抱危机、敢于求变。回想下，近十年来，云计算也好、云原生也罢、DevOps 也算，SRE 也行，所有这些 IT 的大变革，都是尝试在不断优化和改进“大运维”这个领域。运维这个行业没有消亡，反而是不断进化，生发出了新的内涵。</p><p></p><p>这说明了什么？说明运维很重要，说明运维也很难！但是如何把这个价值说清楚，我们从站位、目标设定、投入产出比上来分别着手分析。</p><p></p><h3>您觉得运维工作最重要的几个目标是什么？您是怎么落地这些目标的？运维的价值如何更好的得到体现？</h3><p></p><p></p><h4>聚焦经典的运维领域，最主要的几个工作职责：</h4><p></p><p>代码发布和交付（delivery），做好最后一公里的价值交付；提升架构的可伸缩性（scalability）并付诸实施；保障系统的稳定性（reliability）并不断改善；在满足前三项目标的同时，不断优化并降低系统的运行成本（finops）；</p><p></p><p>如果你发现自己的工作，并不是围绕着以上范畴展开，那么有两种可能，你不是运维或者你的工作超纲了！</p><p></p><p>明确了工作范畴，说大点就是明确了运维的使命之后，设定目标就相对容易些了，比如：</p><p>针对代码发布和交付，可以简单的用发布次数来度量；针对系统的伸缩性，可以用扩容的时效性来度量；针对稳定性，我们可以通过观察核心功能的不可用时长来度量；针对系统运行成本，我们可以计算到每完成一笔核心交易所花费的资源成本和人力成本来表示和追踪；</p><p></p><h4>关于如何体现运维的价值：</h4><p></p><p>首先我们运维人要转变的是态度和立场：坚定和业务站在一起，争取共背业务目标。</p><p></p><p>我举个例子，HR部门，也是属于公司内部后台的不能再后台的部门了，但是我所接触过的优秀的hr中，不管是recruiter、还是hrbp，从来都是把自己当作业务部门的一份子，把业务部门的目标当作自己的目标。当立场一致，大家都是自己人的时候，价值就好说了。</p><p></p><p>其次，价值这个事情，永远都是和“成本投入”相对应的。你如果组建了一个很大的运维团队，人力成本在公司很显眼，那么你就很容易成为老板眼中的“重点关注对象”，也会受到业务方更苛刻的挑战，正所谓，楚人无罪怀璧其罪:) 客观上来讲，运维团队的资源投入，一定是要和业务收入相匹配的，过高过低都是不健康的，不利于团队发展的。所以，“运维的价值创造”最后会落到运维效率的竞争上来。</p><p></p><p>最后，关于价值，定量和定性的描述都得有。譬如和行业水平的定量对比，来自公司内业务部门满意度调查的定量数据。也要有比如对公司战略项目支撑中的“存在感”这些定性数据。</p><p></p><h3>ChatGPT这样的AI能力您觉得未来是否有可能解决运维行业的问题？</h3><p></p><p>首先我们看看，ChatGPT的核心优势是什么？ChatGPT，在知识的丰富度、自然语言理解能力（以及上下文理解）、内容生成能力方面，有着代际的革新。</p><p></p><p>然后，我们再分析下运维行业的核心问题是什么？</p><p>是缺少领域知识吗？是交互效率低吗？是内容输出难吗？</p><p></p><p>以上都不是，运维行业所处理的问题，本质上还是一个系统性的工程问题，是为了解决IT系统价值快速交付的问题、解决伸缩性的问题、解决稳定性的问题、是不断提高系统运行维护性价比的问题。</p><p></p><p>目前来看，云计算、微服务对于运维行业的改变来的要更实质性一些。ChatGPT能有效改善运维行业知识沉淀的问题，或许会很快代替一些初级的运维架构师岗位。</p><p></p><h3>工具选型这块，到底是自研，还是使用开源，还是使用商业产品，是如何抉择的？</h3><p></p><p>这个问题没有绝对的答案，从我个人的从业经验来看，大概有以下几种情况：</p><p></p><h4>自研的好处：</h4><p></p><p>心理上的自主可控感会更强一些；短中期维度来看，对于团队的发展空间会更有利；能根据自己的实际情况进行有针对性的、灵活的设计；</p><p></p><h4>自研的弊端：</h4><p></p><p>时间成本很高，会造成较长一段时间拖后腿的情况，给业务的发展带来一定的影响；人力成本高，以北京为例，要招聘一位相对资深的工程师，每年的薪资大概在50万，如果要自研相关运维工具到成熟，投入两位工程师还是需要的；受限于研发人员的认知，自研容易和行业最佳实践脱钩，长期会造成内部工具落后于时代。</p><p></p><h4>开源和开源二次开发：</h4><p></p><p>好处是能很快见效，投入生产。坏处有三：</p><p>开源工具一般注重灵活性，功能上也比较聚焦，在产品化和用户体验上通常比较欠缺，拿来快速使用存在体验方面的问题；写代码的朋友大家都有个体会，完全读懂和理解别人的代码和自己开发一套，难度其实是相当的，所以开源项目投入到生产环境，也是要投入足够的人力和时间去掌握的；大多数针对开源项目的二次开发，会导致和社区主干脱钩，导致无法顺利升级到后续的最新版本，享受不到开源项目真正的红利。</p><p></p><h4>使用商业产品和解决方案：</h4><p></p><p>优势：</p><p>时间成本优势明显，借助商业产品能够快速敏捷的支持业务的发展需要，首先做到不拖后腿！原则上来讲，商业化产品的成本相比自研会有数倍的降低。这个成本差距是由商业模式决定的。商业产品能盈利的根本原因就是产品研发成本（加上销售成本）随着客户数量的增加而摊薄，否则这个公司没有存在的意义和可能；商业产品的核心竞争力包括领域know-how、极致的产品体验、良好的技术支持和服务共同构成的，这通常意味着采用商业产品的技术团队会在公司业务方取得更好的口碑。</p><p></p><p>不足：</p><p>国内tob领域起步较晚，目前阻碍客户采用商业化产品最大的问题是缺少极致好用的产品，以及价格优势还不明显；很多甲方客户技术历史包袱较重，个性化方案多，商业化产品往往很难做到完全匹配，导致客户不得不硬着头皮选择自研；</p><p></p><h3>业内有观点认为云计算和Kubernetes这样的基础设施的崛起会让运维岗位逐渐消亡，您是怎么看待这样的观点呢？</h3><p></p><p>诚然，云计算、K8s的出现，核心是为了改进“运维”这个行业，对运维行业的工作方式发生了重大影响。比如：</p><p>以前的 clickops 逐步过渡到 IaC传统监控升级为更全面的可观测性体系release 也从大版本定期发布变成了更敏捷的持续集成老中医式的开源软件维护模式，变成了对应的云服务的正确选型和使用扛机器上架的体力活变成了简单的控制台分分钟开通手敲命令配置网络路由的专家工作转变成云服务的各个网络产品的组合搭配从物理机混部提升利用率转变为采用微服务、云原生架构成本天然下降…</p><p></p><p>我们看到，运维工作的内涵并没有变，工作的价值也并没有变弱，只是运维要掌握的技能树在升级。运维人继续保持危机感、保持主动求变精神、立足服务好业务，就能永立潮头，处处柳暗花明。</p><p></p><h3>可选的监控工具有很多，用户选择贵司的 Flashcat 平台，理由是什么？</h3><p></p><p>的确，开源的、商业化的监控平台有很多，我之前也写过一篇博客：《<a href=\"https://mp.weixin.qq.com/s/ByQ3skUrcf1c_DPD4dCbRg\">二十年里12个开源监控工具大对比</a>\"》，大家可以参考。</p><p></p><p>回到为什么选择Flashcat平台，需要从监控系统的发展趋势以及Flashcat平台的特点说起。监控系统的发展趋势，可以参考我之前的博客文章 《<a href=\"https://mp.weixin.qq.com/s/cdNq2qYFoqWT1B-MkFhYOw\">云原生监控的十大特点和趋势</a>\"》。而Flashcat平台，正是面向这些趋势而生的针对性的解决方案：</p><p>Flashcat面向更广泛多元的用户群：从面向运维工程师群体到面向全体研发、运营、CTO/CIO，Flashcat 让监控分析、信息拉齐如此简单；Flashcat与业务指标密切联动：当业务受损时，Flashcat 总能第一时间发现，并和 IT 系统深入联动，辅助技术团队快速展开调查；云原生、混合云统一监控：无论采用什么样的 IT 架构，您只需要一套 Flashcat 平台；</p>",
    "publish_time": "2023-03-11 13:48:56",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "又拍云邵海杨：25年Linux老兵聊DevOps八荣八耻",
    "url": "https://www.infoq.cn/article/1aX7LLK2oxjhjJF3WDuS",
    "summary": "<p></p><blockquote><a href=\"https://flashcat.cloud/blog/sretalk-004/\">作者的话</a>\"：我们观察到：国内运维行业，不同的公司做法差异巨大，从业人员水平参差不齐，缺少普遍性行业认知，难以形成合力（这也会让 To B 的产品异常难做，不利于行业整体发展），甚至在部分公司，运维人员处在技术鄙视链最底层，我们希望为行业带来一些新的思路和发展推动力。这需要很多行业老炮一起，输出观点，共同碰撞，才有可能形成一些先进的共识，形成行业前进的思想旗帜。所以，我们准备策划《运维百家讲坛》这么一档栏目，诚邀 100 个运维总监（或更高）级别的老炮，通过采访或约稿的方式输出他们的观点，给行业一些借鉴。这一期我们邀请到的是又拍云科技的邵海杨，一个25年的Linux老炮，邵总醉心技术，一步一步往上走，是普通运维人员的典型成长路径，希望今天的采访可以对你有那么一些启发。这里是接地气、有高度的《<a href=\"https://mp.weixin.qq.com/s/Y4rIfV4_7MuYigLNNrtifg\">运维百家讲坛</a>\"》第 4 期，开讲！</blockquote><p></p><p></p><h2>您好邵总，请您先做个自我介绍吧，聊聊您的履历和现状，让大家更好的认识您，了解您的背景也有助于读者理解后面的采访内容</h2><p></p><p>我是来自又拍云科技的邵海杨，从1998年开始使用Linux至今快25年了，资深(老鸟)Linux系统运维/架构师，DevOps八荣八耻倡导者，业余撰稿人；精通(心虚)系统优化及网络服务管理，Linux系统定制，CDN加速和安全防御; 擅长互联网高性能网络及架构设计、虚拟化KVM及OpenStack云平台, K8S容器云和Ceph分布式存储等新技术；喜欢交流分享，活跃于社区，一直积极投身于开源活动的组织和传播。</p><p></p><h2>运维领域，每个公司都会制定自己的运维准则或者操作规范，能否分享一下贵司的经验，给我们一些参考？</h2><p></p><p>又拍云是一家提供云存储，云分发，云处理服务的公司，也是国内首创可编程CDN 服务的专业云服务提供商，特点就是7x24全年不间断服务，所以云运维也有一些律条或原则，比如：</p><p></p><h3>先保障稳定，然后再优化</h3><p></p><p>过度设计或过早优化很可能会带来更多的故障停机时间，要先集中精力提高系统的可扩展性和高可用性。坚持 “先完成，再完善，后完美”，项目也是“先能用，再好用，后用好”的实施策略。</p><p></p><h3>提供可靠的测试依据和时间验证</h3><p></p><p>引入新技术到架构之前，要确保新技术的稳定性和足够时间久的考验，更要有运维工程化中开发出来的工具链的完整。一旦线上返工或变更造成的措手不及可能已经是故障的导火索。</p><p></p><h3>使用可控的自动化手段提升效率</h3><p></p><p>自动部署、自动编排、自动巡检、自动升级等自动化手段越来越多应用于云运维。这是适应云计算时代的趋势，但能力越强，责任越大，要谨慎自动化的雪崩和惊群效应，做好灰度/蓝绿部署和各种测试。</p><p></p><h3>保持简单，监控一切</h3><p></p><p>保持简单，别把事搞的太复杂。除了常见的异常问题报警外，面向业务指标，市场指标和销售数据，成本等都可以用来做趋势分析信息。定期的轮询查看各个趋势数据的峰值峰谷有助于见微知著。</p><p></p><h3>面向预算的运维</h3><p></p><p>运维团队通常是最大的花费者，因为预算不足，没有钱的运维是很难兼顾到日益增长的公司业务规模，除非公司业务已经停滞或不再有爆炸式的增长，面对这样的挑战，运维要学会降本增益，开源节流，利用新技术实现能效比的提升。</p><p></p><h3>面向场景的智能运维</h3><p></p><p>各种各样的负载场景，从高并发处理到视频转码，从高性能并行计算到海量的网络请求。这些不同的负载场景，对网络带宽，各种处理和IO的要求也各不相同。智能运维就是需要深入理解业务，合理配置资源和架构来满足不同业务场景的需求。</p><p></p><h3>持续集成和发布系统</h3><p></p><p>持续发布包括灰度发布、测试发布、滚动发布、回滚发布等多种场景，并且确保每种场景都应该是可以可控的。</p><p></p><h3>确保任何人都可以被替换</h3><p></p><p>铁打的营盘流水的兵，人挪活是常态，做好员工的共享文档管理和知识传递和分享，理论上所有人都可以被替换，任何人也不应该成为公司的天花板。</p><p></p><h2>虽说成长是自己的事情，但如果有合适的场域、合适的项目机会、合适的团队、合适的机制，会让工程师的成长更快，团队更有战斗力，您能否系统的谈一下是如何促成运维同学的成长的？</h2><p></p><p>公司一直是积极鼓励员工的技能自我提高和促进成长：</p><p>每月开放日：公司内技术委员会会定期举办讲座，分享前沿研究中的一些收获，要求有主题，有重点，有应用场景，最好有实例。每周分享会：鼓励所有开发者定期分享新的技术，谈论他们面对的问题，或者任何别的他们正思考的东西，分享的内容会形成文档和视频存档，并根据评分给予奖金和积分激励。公司悬赏项目：无论是公司还是员工自身都可以发起项目，技术委员会评审通过后，自行组队完成，根据产出文档，数据对比，技术分享后获取相应的项目奖金。申请专利还有相应的专利奖金。培养个人影响力：鼓励员工通过发表文章或演讲的形式，走出去做工程经验分享、工作心得的梳理，提高个人的影响力，并根据受众的反馈给予稿费和讲师费激励。订阅报刊，杂志等纸质书籍，了解最新动态。以部门为单位，配置一定的购书津贴。</p><p>又拍云运维团队内的培养包括：</p><p>化“天花板为托板”：把自己放在一个培养新人的管理角色，不让自己成公司瓶颈和员工的天花板，鼓励新人们去尝新和处理故障，增加自身的技能和实战经验；信任，互助，激励，他们会持续不断创造惊喜。制作“自动化工具”：利用自己的经验抽象业务成程序模型，制作或培训自动化脚本的编写，提高团队的工作效率，让员工节省精力和时间去学习其它新知识；承担“高精专”项目：提前准备最新知识的研究和可行性分析，整理成文档作公开培训，再交给团队去深入研究和实施，转化成生产力，积累一线经验再反馈完善文档，良性循环；积极提倡“知识分享”：各种案例和“坑”都会整理成wiki文档，通过文档共享，定期分享讲座，鼓励员工撰写高质量的，可读性很强的文档，开口培训，增加感染力和自信心；鼓励“参与开源交流”：公司鼓励员工走出去参与技术交流大会，闭门造车耗时耗力，不如专业的人点拨。也会有购书经费，团建活动经费，茶歇文化；</p><p></p><h2>运维工程师其中一个典型的职业路径是做管理者，但管理者和资深运维要解决的问题截然不同，对于那些刚刚步入管理岗的资深运维，是否可以分享一些您的经验？</h2><p></p><p>对于刚步入管理岗的运维来说，我的建议是及时梳理遗留的技术债和人才技能的盘点和培养，先打好基础，后面才能有更大的空间进步，具体可以参考我的《DevOps的八荣八耻》的分享。</p><p>一、 以可配置为荣，以硬编码为耻二、 以互备为荣，以单点为耻三、 以随时重启为荣，以不能迁移为耻四、 以整体交付为荣，以部分交付为耻五、 以无状态为荣，以有状态为耻六、以标准化为荣，以特殊化为耻七、以自动化工具为荣，以手动和人肉为耻八、以无人值守为荣，以人工介入为耻</p><p>人才上技能树的盘点，主要是配合人事做好人才九宫格的划分（如果是开发或运维，把左侧的绩效换成潜力，绩效针对销售而言），考查的是管理者对员工的全方面的辨析能力，知人善用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6f/6f298b35c35d5094089b4c9a52d54146.jpeg\" /></p><p></p><p>再结合公司的OKR目标管理来激励员工，它的优点在于聚集目标的同时，还能：</p><p>激励个人自驱力，鼓励员工创新和反思；考查的是相对结果，鼓励有难度的挑战和突破；考核的协同配合能力，鼓励员工去全方位的协调推进；</p><p></p><h2>Kubernetes火了好一段时间了，很多公司也在大规模应用了，但显然，每个技术都不是银弹，无法解决所有场景的问题，这几年观察下来，您觉得哪些公司不适合上Kubernetes？能否给一个这类公司的画像，并说明理由？</h2><p></p><p>虽然Kubernetes代表着目前为止的devops的最佳工程应用实践(真香)，但也不是所有场合都能应用，如又拍云的CDN边缘服务器，数据中心的日志分析平台，Ceph分布式存储就以物理机为主。所以，我建议找一些合适的场景先试用起来，如：</p><p>机器资源错峰空闲浪费严重的；CPU，磁盘和网络IO都不密集的；不需要持久化存储的或抢占资源的；软件架构已经做了微服务改造的；业务处理程序有周期性、可弹性扩容的；</p><p></p><h2>运维和研发是最亲密的伙伴，贵司是如何做工作边界划分的？另外关于如何让这两个角色保持亲密合作，是否可以分享一些经验？</h2><p></p><p></p><blockquote>运维工程师 = 冲锋陷阵的将军软件工程师 = 坐阵帐中的军师</blockquote><p></p><p></p><p>理论上，优秀的软件工程师是可以把部分(甚至全部)运维工程师的工作做掉，比如说业务软件性能的监控，如果程序员在程序中插入很多的钩子或探针，就可以统计出数据来，不需要运维劳心劳力的监控；比如说程序员在设计程序的时候，考虑到了分库分表，考虑到了大并发和分布式的设计，那运维就可以水平扩展机器就行；如果软件没有那么多bug，还有很多如果……但是，现实是残酷的，这种高水平的程序员太少了，尤其在中国，大家都忙于实现业务功能，连个文档甚至注释都不愿意写，更别提能够考虑这么周全了；同理，运维接触的很多是开源很优秀很成熟的软件，从中是可以借鉴知晓优秀软件是怎么设计的，比如优秀的程序，日志信息会非常详尽，我们可以通过标准的syslog或者日志去监控它，所以，资深的运维会:</p><p>积极参与事前的规划，配合开发做演练，自动化部署，协助架构改进合理提需求，要资源，最好是有预算，做到防患于未燃线上监控，故障复盘，反馈给整个团队，倒逼上下协调做改进</p><p></p><p>当然，要达到上述能力的运维管理，肯定需要潜心研究，承上启下，协调团队，任劳任怨的修行多年，到那个时候，运维就不再是对事情的结果负责，而是转变角色，主导和协调整个过程。当然，这里指的能力不仅仅是技能，还包括对业务的理解能力，站在公司管理层面对整个项目和资源的分配和把握。 因此，运维工程师其实是现实中的软件工程师的互补，因为大家的能力侧重点不同，所以大家更要团结一体，要能够打胜仗，离开谁都是不行的，这是一个共同修炼进步的过程。</p><p></p><p>最后，我的个人观点：架构师它可能不是一个人的角色，而是一个团队的统称，它可以:</p><p>不必冲锋陷阵，就可以纵观全局，运筹帷幄，调度所有的资源（运维架构师的功能）可以带领和团结团队，高屋筑瓴，因时制宜的实现解决方案（软件架构师的功能）可以把握公司业务方向和深度，洽谈合作，控制成本（业务架构师的功能）</p><p></p><h2>运维需要和其他多个部门沟通协作，鉴于各个团队目标关注点未必一致，合作起来可能未必有那么顺畅，针对这个问题您是用什么招来让这个过程更加顺畅的？</h2><p></p><p>其实沟通不顺畅的原因大部分在于对后果的不可预见性，你说冗余他说预算，你说架构他说工期，各有立场又各有苦衷，但就是没人对结果负责。我在工作中发现，当故障发生时，各部门的配合是空前团结，战斗力也是最强的，所以，沟通协作的关键在于：既要团队协作，也要责任分明</p><p>事前部门沟通时，确定好项目预期，成本，影响要素，故障后果及责任方；事后故障复盘时，根据故障原因，有理有据的“甩锅”，同时要引以为戒，亡羊补牢；</p><p></p><p>比如说提供在线10W并发的能力，需要冗余带宽冗余服务器数量x2，因为预算不足减半所导致的后果及责任人；再比如软件设计不好，通过性能监控，发现指标异常的后果及责任人；当然，报警处理不及时，人为操作故障也会算到运维亦无可厚非；故障文化就是要关注问题和关注事情本身，对事不对人。大家都在故障中成长，在复盘中变强。</p><p></p><h2>您觉得运维工作最重要的几个目标是什么？您是怎么落地这些目标的？</h2><p></p><p>运维自动化；监控常态化；日志可视化！</p><p>这个篇幅太多了，不展开讲，可以参考《<a href=\"https://mp.weixin.qq.com/s/bgJk2WisB8uFPWgIrY2zYQ\">云运维的启示和架构设计</a>\"》</p><p></p><h2>工具选型这块，到底是自研，还是使用开源，还是使用商业产品，是如何抉择的？</h2><p></p><p>又拍云通常不会重复造轮子，但一定会先用好轮子，或者把轮子改造得更加称手，选择自研往往具备了一定的开发能力，再加上某些必要原因，如：</p><p>找不到符合要求的开源软件，如我们自研的云处理软件…开源软件有bug或者issue，社区短期内无法推进，但业务又急需，只能通过自研解决，如ats的内存泄露问题…开源软件的功能特点跟公司的业务不相符合，不得不改造软件，如nginx的防盗链模块，需要与客户对接定制…开源软件的设计目标过于高大上，通用性好但很臃肿，如果我们只要某个小功能点，就不需要牛刀了，如性能探针的埋点…有数据保护要求，或者有隐私的场合…</p><p></p><h2>越来越多的公司在迁往公有云，云原生架构下，SRE团队的核心职能是否有些变化？应该如何凸显团队的价值呢？</h2><p></p><p>公有云做为IaaS基座，容器云作为CaaS中间层，云原生做为SaaS应用层，整个云生态日新月异，SRE团队的核心职能会更加注重顶层系统性的容量规划，指标监控，高可用性和分布式的弹性设计，所以跨平台跨部门的职能互补、团队协作、持续精进、勇于承担包括：</p><p>积极参与事前的规划，配合开发做演练，协助架构改进；合理提可用性需求，冗余资源，最好是有预算，做到防患于未燃；线上监控，故障分析，反馈给整个团队，倒逼上下协调做改进；</p><p></p><p>团队的价值就在于是否总是能够接受新事物，新的挑战，各施所长，不做井底之蛙，也不是温水煮青蛙，在创新或者颠覆来临的时候，也能保持不被时代脱钩。</p><p></p><h2>对于运维工程师个体，SRE的转型路径是？应该注意些什么？</h2><p></p><p>技术领域：</p><p>学会抽象业务模型，标准化组件，定制化脚本，自动化部署，提升整体效率；学会收集日志和日志分析并可视化，提升运维监控和预警报警的效率；掌握和熟悉一门或若干语言，能够帮助你成长，提升你的战斗力；勤做笔记，温故而知新，学思结合，要学会沉淀，举一反三；勇于面对新兴技术的挑战，打不过就学它；</p><p></p><p>非技术领域：</p><p>学习能力，要知识面广；沟通方面，了解客户的精确需求；技术风险、人工、进度等成本，权衡取舍；社区活动，积极分享，锻炼口才和交流能力；提升自己的影响力，学会与人同行，可以交到更多的朋友；</p><p></p><h2>面对当下快速发展的基础技术，您对给刚入行和入行已久的运维人员，分别有什么职业规划的建议吗？</h2><p></p><p>首先不是工作选择人，而是人选择工作，一个人若对某方面有了兴趣，真正用心学习了近10000个小时，其实做什么都是可以的。比如说我毕业那个时候，都是强调复合型人才，根本没有运维这个职业，我们不光自己攒(DIY)机器，自学Linux操作系统，还学习编程，折腾网络，自己动手写论坛聊天室等程序；Linux给我们带来的是每天都有创新的，好玩的，优秀的开源软件让我们保持激情去尽情的折腾和学习，当互联网兴起的机会来临时，做个运维总监其实也是顺理成章的事； 其实，除此之外，我还转型做过售前，技术支持，跑过市场，经常做演讲培训，所以真正的高手是什么不会学什么，技多不压身，做个懂业务、会开发的运维工程师。</p><p></p><h2>您觉得运维人员最重要的素养是什么？对新入行的运维人员有哪些寄语？</h2><p></p><p>我认为最重要的能力是表达沟通能力，但不排除运维本身所需的技术储备、实践动手能力、编程能力和学习能力。考虑到运维大部分还是一个成本支出的岗位，如何把深奥隐晦的性能及瓶颈指标，用直观的图表展示来获取上层持续的投入是需要技巧的；然后面对你的同事，你的兄弟部门，也需要你的影响力去协调推进工作，如果能够做到这些，说明你已经具备了领导的才能，这样以后做什么事都会站在更高的水平，用全局观的格局去统筹规划整个项目的目标，人员，工期和资源的合理分配和把握。</p>",
    "publish_time": "2023-03-11 14:04:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]