[
  {
    "title": "Meta宣布推出新一代AI硬件平台Grand Teton，将英伟达 Hopper 架构引入数据中心",
    "url": "https://www.infoq.cn/article/E3GhWKgg0YHy1OzmXg3U",
    "summary": "<p>最近，<a href=\"https://engineering.fb.com/\">Meta</a>\"宣布推出下一代用于人工智能训练的硬件平台<a href=\"https://engineering.fb.com/2022/10/18/open-source/ocp-summit-2022-grand-teton/\">Grand Teton</a>\"，与前代相比有多项优化，包括两倍的网络带宽及四倍的主机到CPU带宽升级。</p><p></p><p>Meta公司工程副总裁<a href=\"https://www.linkedin.com/in/alexisblack\">Alex Bjorlin</a>\"于近期的<a href=\"https://www.opencompute.org/summit/global-summit\">开放计算项目（OCP）全球峰会</a>\"的主题演讲中宣布了这一消息。Grand Teton的开放硬件设计是Meta对数据中心人工智能工作负载的最新迭代贡献，与前一代由三个“盒子”组成的Zion-EX不同，Grand Teton的集成机箱让它可以更快、更容易地部署。Meta还为Grand Teton设计了一个新的数据中心机架和冷却系统，用于支撑大型人工智能模型训练所需要的服务集群电力需求。Bjorlin称：</p><p></p><p></p><blockquote>Meta是全心全意支持人工智能的，但人工智能的未来不可能完全由我们创造，而是通过合作，通过如OCP一样的组织分享想法和技术来创造。我们渴望继续合作，建立新的工具和技术以推进人工智能的未来。希望人们能加入我们的各种努力，无论是现在开发新的人工智能方法，还是从根本上重新思考未来的软硬件设计，我们对这个行业的未来发展非常乐观。</blockquote><p></p><p></p><p>Meta训练并部署了许多大型人工智能模型，其中不乏包含数万亿参数，需要等量规模数据集训练的模型，这也意味着他们会需要大量与GPU互联的服务器。Meta自2016年起便开源了他们的人工智能硬件设计，且推出了<a href=\"https://engineering.fb.com/2015/12/10/ml-applications/facebook-to-open-source-ai-hardware-design/\">Big Sur平台</a>\"。去年，InfoQ同步报道了Meta的最新迭代<a href=\"https://www.infoq.com/news/2021/05/facebook-zionex-training/\">Zion-EX</a>\"平台，该迭代是由数千计算节点组成集群，其中每个节点都含有四个CPU插座和八个GPU。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/news/2022/11/meta-ai-hardware/en/resources/1meta-hardware-timeline-1666536464626.jpg\" /></p><p>图源：<a href=\"http://engineering.fb.com/2022/10/18/open-source/ocp-summit-2022-grand-teton/\">https://engineering.fb.com/2022/10/18/open-source/ocp-summit-2022-grand-teton/</a>\"</p><p></p><p>然而，Zion平台的每个节点都需要外部布线才能整合三个不同的组件：CPU“头部”、GPU系统，以及一个交换系统。全新的Grand Teton则将这些组件全部整合到一个机箱之中，且该机箱也包括了电源、计算和网络接口，“以实现更好的整体性能、信号完整性和散热性能”。英伟达称，Grand Teton还拥有英伟达基于<a href=\"https://www.infoq.com/news/2022/05/nvidia-grace-hopper/\">Hopper架构</a>\"的<a href=\"https://blogs.nvidia.com/blog/2022/10/18/meta-grand-teton/\">H100 Tensor核心GPU</a>\"。Meta还更新了他们的底层存储平台：新版本的<a href=\"https://www.opencompute.org/documents/grand-canyon-storage-system-specification-v1-0-pdf\">Grand Canyon</a>\"在前代Bryce Canyon架构的基础上进行了改进，让Meta公司“达到驱动器的极限水平”。</p><p></p><p>在Grand Teton的设计之外，Meta公司还发布了一款数据中心机架设计：<a href=\"https://www.opencompute.org/projects/rack-and-power\">开放式机架v3</a>\"（ORV3）。与其他将电源架直连母线的机甲不同，ORV3的电源架可以安装在任何位置，设计更加灵活。改进后的备用电源与前代仅支持90秒的供电相比，可提供长达四分钟的供电。ORV3还支持多个电源架和48 VDC的输出，可部署处理高达30 kW的机架。Meta还为这代更高的功率容量设计了新的冷却策略：ORV3支持空气辅助液冷，设施水冷，以及“可选盲配液体冷却接口设计”。</p><p></p><p>Meta公司设计的可互动3D模型可在这个<a href=\"https://metainfrahardware.com/\">官网</a>\"找到。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/11/meta-ai-hardware/\">Meta Announces Next Generation AI Hardware Platform Grand Teton</a>\"</p>",
    "publish_time": "2022-11-17 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]