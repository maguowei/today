[
  {
    "title": "JetBrains为IntelliJ IDEA推出Kotlin Notebook Plugin",
    "url": "https://www.infoq.cn/article/rA9ISmFDMSat7ZluPryJ",
    "summary": "<p>开发人员可以使用<a href=\"https://blog.jetbrains.com/kotlin/2023/07/introducing-kotlin-notebook/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA3OTUwMzksImZpbGVHVUlEIjoiTDAzTlJ1TU15eDg4ejNRTiIsImlhdCI6MTY5MDc5NDczOSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.6AyM69s20viEvfIrPiYVy8jtF1AP2XM1sRt2m0HZTFA\">IntelliJ IDEA提供的Kotlin Notebook实验性插件</a>\"在一个文档中写代码、可视化、写文本，以及运行代码片段并查看结果。</p><p></p><p>根据JetBrains的说法，Kotlin Notebook插件使实验、原型创建和代码文档好变得更加容易。</p><p></p><p></p><blockquote>Kotlin Notebook插件将交互式开发能力带到了IntelliJ IDEA中，补足了IDE对Kotlin语言的全面支持，并结合了浏览器的多功能可视化能力。</blockquote><p></p><p></p><p>一个Notebook由一些单元格组成，每个单元格可以包含代码或文本。当你运行单元格内的代码时，其结果会显示在单元格下方。单元格可以按任意顺序执行，并且可以在任何时候修改和重新运行，包括声明和重新声明变量。</p><p></p><p>IntelliJ IDEA的Kotlin Notebook插件支持多种不同的输出格式，如简单文本、HTML、图像、Markdown富文本和LaTeX公式和方程。</p><p></p><p>在Notebook中，你可以使用标准库的任意函数或类型。你还可以包含Notebook所属项目的依赖项，也可以在Maven配置文件中或使用DependsOn注解指定它们。对于后者，你需要知道依赖项的Maven坐标，这可能很麻烦。为了避免这种情况，你可以在单元格内键入%use命令来显示流行的开发库清单，然后根据你的需求下载并导入它们。</p><p></p><p>JetBrains公司表示，Kotlin Notebook还允许开发者通过<a href=\"https://github.com/Kotlin/kotlin-jupyter/blob/master/docs/libraries.md?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA3OTUwMzksImZpbGVHVUlEIjoiTDAzTlJ1TU15eDg4ejNRTiIsImlhdCI6MTY5MDc5NDczOSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.6AyM69s20viEvfIrPiYVy8jtF1AP2XM1sRt2m0HZTFA\">外部库</a>\"扩展其功能。例如，扩展库可以定义在每个单元格执行前后运行的代码，或预处理单元格内容、自定义结果显示等。这为创建交互式用户体验提供了许多可能性。</p><p></p><p>最后要注意的是，Notebook可以与他人共享。这得益于其采用了Jupyter格式，这种格式可以在任何一种Notebook Web查看器中渲染，包括GitHub。</p><p></p><p>你可以在IntelliJ IDEA Ultimate的2023.1.2或更高版本中从JetBrains <a href=\"https://plugins.jetbrains.com/plugin/16340-kotlin-notebook?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA3OTUwMzksImZpbGVHVUlEIjoiTDAzTlJ1TU15eDg4ejNRTiIsImlhdCI6MTY5MDc5NDczOSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.6AyM69s20viEvfIrPiYVy8jtF1AP2XM1sRt2m0HZTFA\">Marketplace</a>\"上下载并安装Kotlin Notebook插件。</p><p></p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/07/kotlin-notebook-plugin/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTA3OTUwMzksImZpbGVHVUlEIjoiTDAzTlJ1TU15eDg4ejNRTiIsImlhdCI6MTY5MDc5NDczOSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.6AyM69s20viEvfIrPiYVy8jtF1AP2XM1sRt2m0HZTFA\">https://www.infoq.com/news/2023/07/kotlin-notebook-plugin/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/adcCDFjOWA1stLKY7pJZ\">无距离编程，使用JetBrains Rider进行远程开发</a>\"</p><p><a href=\"https://www.infoq.cn/article/4zm3T5aeOKzej15X9YKR\">另一种“推翻”&nbsp;VS Code 的尝试：JetBrains Fleet 现开放公测</a>\"</p>",
    "publish_time": "2023-08-01 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "复杂业务开发基石之“顺序、分支、循环”：赋值、计数器、子流程和互斥组件",
    "url": "https://www.infoq.cn/article/U1jWGuFczrQsAbA03kMp",
    "summary": "<p>在现代企业开发中，初级开发者难以掌握开发企业级 Java 应用，中高级开发者则被繁琐任务所占据。为了让大家能快速上手可以解决这个难题的“SoFlu 软件机器人”，前蚂蚁金服技术专家杨彪设计了《2 小时学会 10 个组件“取代”传统 Java 开发》课程，本节为该系列课程的第二讲。</p>\n<p>本节主要基于对伯姆-贾可皮尼理论的介绍，演示“ SoFlu 软件机器人”是如何通过可视化的配置方式来实现顺序、分支和循环程序流程的，同时会详细为大家解析  SoFlu 软件机器人——赋值、计数器、子流程和互斥组件的使用，帮助大家解决“SoFlu是如何像Java开发语言一样实现复杂业务逻辑的？”这个问题。</p>\n<p>大家在课后可以登录 Gitee 下载 SoFlu 软件机器人客户端进行实践：<a href=\"http://suo.im/8wROo\">点击下载</a></p>\n<p>大家可以扫码添加小助手，进学习群与专家一对一交流：<br />\n<img alt=\"\" src=\"https://static001.infoq.cn/resource/image/e8/c9/e8833a01ba0bc705acab14a572b57cc9.png\" /></p>",
    "publish_time": "2023-08-01 09:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "解锁 Serverless 新进展：与 AIGC 结合会有哪些搞头？",
    "url": "https://www.infoq.cn/article/NK736p4BdrqQT5zLmVD8",
    "summary": "<p></p><p>Serverless&nbsp;在中国发展这些年，经历了高潮、低谷、现在重新回到大众视野。这期间，很多企业都非常感兴趣并进行浅尝，但是只有部分企业开始大规模应用；之所以有很多企业止步于对技术的好奇，是因为不知道如何在生产环境真正的落地。那么在当下的&nbsp;AIGC&nbsp;技术浪潮中，Serverless&nbsp;如何与&nbsp;AIGC&nbsp;更好结合发挥更大的作用呢？</p><p></p><p>带着这个问题，InfoQ《极客有约》近日邀请到了阿里云智能&nbsp;Serverless研发负责人杨皓然（不瞋）、高德服务端负责人孙蔚，一起探讨&nbsp;Serverless&nbsp;和&nbsp;AIGC&nbsp;结合可以去激发哪些想象力。以下内容根据直播整理，我们在不改变原意的基础上做了删减，<a href=\"https://www.infoq.cn/video/ihlWu9yppWciFjm7b0NH\">点击可以查看完整视频。</a>\"</p><p></p><p></p><h2>Serverless&nbsp;实践如何？</h2><p></p><p></p><p>InfoQ：从去年强调Serverless化至今，在这半年的时间里，阿里云在Serverless&nbsp;技术方面取得了哪些进展？</p><p></p><p>杨皓然（不瞋）：2022年，阿里云在Serverless方面提出了非常明确的观点，认为Serverless是云计算的下一个阶段，阿里云致力于让整个产品体系Serverless化。主要在以下几个方向上持续发展：</p><p></p><p>第一个方向是产品体系的Serverless化。2022年，数据库已经全面采用了Serverless的形式，而今年更多的中间件服务也逐步Serverless化，包括传统的微服务注册中心和网关等，同时消息中间件也会提供Serverless的产品形态。</p><p></p><p>第二个方向是通过Serverless让云服务能够更细腻地集成，最终目标是让这些服务成为开发者构建应用的原子化、可组合组件，使开发者能够使用即开即用的组件来快速构建应用。</p><p></p><p>第三个方向是继续深耕Serverless计算平台本身的技术能力。这包括进一步提升函数计算、Serverless应用引擎&nbsp;SAE的弹性速度，以及GPU的Serverless化进展等。在容器的Serverless形态方面，阿里云推出了全新升级的容器服务&nbsp;Serverless&nbsp;版，为开发者提供更丰富的选择，从容器到应用将得到全栈支持。</p><p></p><p>孙蔚（圣翁）：从具体应用Serverless的角度，我来补充下关注到的三个进展。</p><p></p><p>第一方面，Serverless的产品越来越稳定，而且支持以单元化的方式部署。同时其可观测性和性能等方面做的也非常好，观测指标丰富可以直观看出问题本质，性能方面延时很低对服务本身没有影响，冷启动时间也在不断优化。根据我们的实测，业务切换到Serverless确实会增加TP99&nbsp;RT（Response&nbsp;Time）时间，大约延迟2毫秒&nbsp;左右，稳定性方面表现非常好。从交易切换到Serverless上的实践结论得出，交易架构Serverless化是可行的。</p><p></p><p>第二方面，Serverless生态工具产品现在非常丰富，如：支持工具流，集成工具等。开发者真正要做的是组装式研发：代码和配置分离，选择适用的工具流，采用BFF（Backend&nbsp;For&nbsp;Frontend）模式，结合自己的FaaS（Function&nbsp;as&nbsp;a&nbsp;Service）框架去开发，这能够极大地提升工作效率降低开发成本。</p><p></p><p>第三方面，目前有很多产品支持Serverless。其中对我们吸引较大的是数据库类Serverless产品。如果数据库的全部功能都已经实现了Serverless，那么我们就可以实现从前端到后端再到数据库的全面Serverless化，从而极大地降低成本，真正做到零运维、按需付费。</p><p></p><p>InfoQ：实践中，还有哪些技术难点仍在攻坚中？</p><p></p><p>孙蔚（圣翁）：Serverless的开发存在许多技术难点，而每家公司在这方面的探索都各不相同。每个公司都有自己的框架，需要将其与现有架构相结合并进行调用。这个过程中，确保自己的架构能够真正与Serverless产品紧密结合、提升效率的同时还要保证稳定性，可能需要在运行时Runtime上或原有架构上做一些改动。</p><p></p><p>杨皓然（不瞋）：我从平台角度再补充下孙蔚老师提到的问题。刚才提到的冷启动或者延时方面，确实对Serverless来说是一个比较大的挑战。Serverless的资源使用是动态的，这给性能和延时稳定性带来了挑战。</p><p></p><p>解决这个问题也是今年阿里云Serverless要攻克的技术难点之一，即提供非常稳定的TP99延时。这需要对整个端对端链路的优化，甚至软硬结合的优化，以尽可能地缩减整个链路的延时。</p><p></p><p>另外，还需要深度优化和整合整个系统，包括操作系统和安全容器，以尽可能地让实例应用、实例函数的执行以及算力保持稳定。另外在GPU上面，新的GPU虚拟化技术和弹性技术也有很多技术需要攻关。</p><p></p><p>InfoQ：在应用方面，企业通常会遇到什么样的问题？</p><p></p><p>孙蔚（圣翁）：每个企业在Serverless上的决策不同，面临的问题也不同。我分享下高德开始接入的难题，就是解决“一套代码解决多地运行的问题”。核心来讲就是2个词：“提效、降本”。所以，高德在最开始就做了脚手架，后续也会对其开源。该脚手架的核心目标是解决直接使用Serverless成本高的问题，让业务只关心业务本身，无需管理底层运行机制。借助这个脚手架，应用可以更高效地开发，同时在在函数里面也可以调用多个中间件或聚合服务。脚手架实现MQ、事件、编排等功能，目前也在支持“多云底座”。</p><p></p><p>杨皓然（不瞋）：高德能够一开始就在&nbsp;Serverless&nbsp;领域里投入并取得比较好的效果，我观察有以下几个原因：首先它本身在整个服务端的架构设计，包括语言选择等有长时间的积累。比如他们整个技术栈是用&nbsp;Go，这跟&nbsp;Serverless&nbsp;的理念非常合拍；其次他们做了大量针对业务场景的定制化脚手架，促进&nbsp;Serverless&nbsp;研发提效。我们今天看到的一些Serverless落地，更多地是在&nbsp;Golang、&nbsp;Node.js、Python&nbsp;等非常适配云原生理念的语言上，能够获得更多的好处。</p><p></p><p>阿里集团内部研发配套的框架能力相对完整，我们主要工作方向就是为公有云的客户把配套的研发提效能力释放出来，让公有云客户充分利用好云的能力。并且是以开源的方式，包括跟高德一起开放&nbsp;runtime&nbsp;Golang&nbsp;相关的工具。我们会以更开放的方式去打造针对Serverless的研发效能服务。大家会在今年看到我们的一些结果，并且以开源开放的模式来运营。</p><p></p><p>InfoQ：有观众问道，这些功能是不是&nbsp;Knative也可以实现？这样其实背后也是想了解下厂商的产品和开源产品有什么区别？</p><p></p><p>杨皓然（不瞋）：可以实现的。但本质上说，当讨论Serverless平台时，开发者主要关注投入产出比。举个例子，用户有多种选择，一种是基于Knative+Java体系，使用Spring&nbsp;Boot、Spring&nbsp;Cloud框架，并在ECS上运行。在微服务场景下，这种生态环境非常完整，但资源使用缺乏弹性，与云相比降低成本难度较大。为了解决这个问题，可以采用容器化加上HPA模式的弹性伸缩。</p><p></p><p>整个Serverless平台可以大致分为两个层次。第一个层次是计算层，旨在实现实例的快速弹性伸缩，甚至支持0～N的弹性伸缩。在弹性伸缩的情况下，要保持P99延时的稳定性，但这会带来系统性挑战。目前在开源体系中尚未有对应的产品能够解决这些挑战，但云平台或云服务可以更好地解决，因为它们可以进行软硬体系整合并投入更多资源进行优化。这样的投入成本需要由较大的平台来分摊，才能使整体投资回报率较为合算。</p><p></p><p>第二个层次是应用层，即与应用的管理和研发效能服务配套的研发效能服务。这包括整合云服务和开源软件，为开发者提供问题诊断测试、开发测试、问题诊断以及自动化部署等全流程服务。这方面的优化也需要投入大量精力进行打磨。</p><p></p><p>在我看来，大家都有能力做好这些，关键在于解决问题是业务导向还是技术导向或平台导向。如果以业务导向为目标，就需要考虑行动的成本效益。我个人非常看好Serverless，如果能够将研发提效和降本的价值更好的传达给企业和开发者，它必定会变得非常流行，因为这符合业务导向公司的本质需求。</p><p></p><p>InfoQ：在国内&nbsp;Serverless&nbsp;落地处在哪一个阶段？</p><p></p><p>杨皓然（不瞋）：根据我的观察，很多头部公司面临着高速变化和高速增长的业务需求。为了能够快速支撑这些业务诉求，这些公司开始考虑采用Serverless架构。然而，要让Serverless架构得以实际应用，就需要相应的配套研发效能服务以及平台本身的性能和稳定性能力。这是Serverless落地的主要挑战点。</p><p></p><p>另一个问题是关于Serverless如何落地，我认为需要根据具体情况来考虑。对于类似SAE（Serverless&nbsp;应用引擎，一款极简易用的应用托管产品）的产品，这类产品最主要的优势在于其弹性和差异化能力，如果能够做好对存量应用的兼容，那么用户在选型时就不会遇到特别大的阻力。例如，它在降本提效方面给用户带来更多优势？如果能够明确表现出这一点，那么许多公司都会对这类产品产生兴趣和需求。</p><p></p><p>目前，国内的头部公司实际上已经在非常核心的链路上使用了Serverless。然而，现在最主要的问题是如何将这些能力以开源开放的方式在公有云上释放出来，使其成为一个普惠的能力，进而让更多公司受益于Serverless所带来的成果。</p><p></p><p>孙蔚（圣翁）：我补充两个建议。对于前端业务，理论上一般是用Node.js来进行多端适配，解决前端研发提效的问题，即客户的研发和产品开发，再加上测试，就可以搞定端到端服务。</p><p></p><p>对于后端业务，相对来说使用Go语言会比较好。相同环境和功能下，Java的包会比较大，镜像也比较大，启动时间比较长，而Go语言可以做到快速拉起，天生适合后端业务。当然也可以考虑使用Rust语言，但Rust的门槛比较高，且对于前端来说，通常会使用Node.js作为FaaS的函数语言，后端则可以选择Go语言。如果涉及到较多算法，可以考虑使用Python等。C++也可以是一个选择，但主要问题仍然是成本较高，模板的成本也较高。不管如何，核心还是要让开发变得更简单。</p><p></p><p>以高德为例，前端主要使用Node.js，后端在导航层面使用C++，在功能层面使用Go，而算法层面则部分使用Python。这样多种语言结合起来使用，能够更好地满足业务需求。</p><p></p><p></p><h2>AIGC&nbsp;带来了哪些变化</h2><p></p><p></p><p>InfoQ：AIGC&nbsp;给我们两位老师的日常工作带来了哪些变化？高德和阿里云有做过哪些初步的尝试吗？</p><p></p><p>杨皓然（不瞋）：我认为AIGC对我们的工作有着巨大的影响，或者说在未来会有巨大的影响。作为一个主要从事服务方面工作的人，我们要解决云原生应用的弹性、容错性和开发便捷性等问题。在AIGC的框架下，我相信未来AI能力将以API的形式释放，并与业务紧密结合。这需要我们将多变的业务与AI的能力有效结合起来，这也是我们一直关注的Serverless领域的一个重点。</p><p></p><p>另一方面，AI&nbsp;不断加强的一个体现就是代码生成能力，我们要思考未来的应用架构如何更适配AIGC的能力和特点。比如，如果你有一个全功能的单体架构应用，那你是否能够在这个单体架构上借助AIGC的能力来增量开发功能？是否存在其他更好的架构能够充分利用AIGC的代码生成能力，从而加速整个代码开发和测试效率？</p><p></p><p>在未来，我认为开发者或架构师需要具备一个非常重要的能力，就是思考如何设计一个应用架构，使其与AI的能力适配，并能够更好地使用AI的能力。无论是从快速功能迭代、架构弹性、稳定性，还是从成本等角度考虑，这都是一个非常有意思且值得我们长期思考的问题。</p><p></p><p>孙蔚（圣翁）：我关注的主要有两个方面。</p><p></p><p>从业务和商业产品的角度来看，每家公司都有自己的专业领域知识。比如在营销领域，你可能拥有很强的专业能力，并且所在公司也是一家营销公司，你可能会思考如何将AIGC应用到营销领域中。当然你可能会面临一些挑战，例如如何利用开源工具构建大型模型应用、如何使用深度学习方法和多个图像来训练模型、如何构建向量数据库，以及如何在业务场景下进行调度和聚合等。这些涉及将序列化架构的理念与AIGC基于API的服务架构相结合，从而构建整体应用并向他人提供服务或API。用户可以根据业务领域的知识和积累，充分利用AIGC来优化业务领域的产品设计。</p><p></p><p>综上所述，我认为有三个关键要素：首先是自身拥有非常专业的业务领域知识，如：向量数据库、Serverless架构等方面；其次是具备大模型的技术能力，可能需要算法方面的知识；最后是Serverless架构的销售理念。将这三者结合起来，就可以打包输出做商业变现。</p><p></p><p></p><h2>Serverless&nbsp;+&nbsp;AIGC&nbsp;=&nbsp;？</h2><p></p><p></p><p>InfoQ：业界有一种说法，Serverless&nbsp;是AIGC&nbsp;的下一块拼图，为什么会这样说？在两位看来，与AIGC结合将会带来哪些全新的想象？</p><p></p><p>孙蔚（圣翁）：AIGC确实给各行业带来了很多想象的空间，涵盖了图像处理、视频剪辑、文字生成、广告素材、Logo设计、智能客服以及语音合成等方面。然而，目前存在的一个主要问题是，大多数厂商提供的大模型对外都是量化调用的，需要通过API接口调用，因厂商算力问题调用一次时间很长，还会受到调用次数限制。因此，我们目前仍处于探索阶段。</p><p></p><p>但是，假设所有的大模型（无论是GPT系列还是其他开源模型）作为产品来进行销售和计费，可以按需付费，同时最大化解决算力问题。此外，还涉及到运行隔离和大数据安全等问题。从这个角度来看，Serverless可以被视为解决AIGC商业化问题的下一个拼图。</p><p></p><p>我个人的判断是，AIGC存在这些问题最终都会得到被解决，许多与AIGC相关的产品就会去解决算力和调度等问题，推动AIGC相关产品的发展。如果这些产品能够结合起来，对整个系统从工程到终端服务、数据库、底层中间件以及AI和算力等层面进行一体化的调用，那么整个系列将全部完整。</p><p></p><p>杨皓然（不瞋）：AI与应用架构和服务集成的适配是一个重要问题。针对AIGC应用，可以从几个方面进行考虑。</p><p></p><p>首先，软件架构应该适应AI的能力。以前的\"All&nbsp;in&nbsp;One\"单体架构可以充分利用AIGC的潜力，然而基于AI的应用通常需要更松散耦合的微服务架构，以便实现每个功能或微服务的单一目标和明确的输入输出。这种架构可以提高代码生成的精确度和效率，但也带来了管理和调试挑战，这些其实正好就是Serverless架构要解决的问题，我觉得这是他们很好的结合点。</p><p></p><p>其次，AIGC在应用的全流程中都发挥重要作用。在开发阶段，我们可以利用AIGC的代码生成能力和辅助工具（如GitHub&nbsp;Copilot）加快迭代速度。在部署阶段，可以使用基础设施即代码（IaC）等自动化工具快速部署不同的云服务或资源，满足应用的依赖关。此外，通过类似声明式语言或YAML的定义，底层的IaC服务也可以自动化地执行这些能力，而不是手动在控制台上进行操作。</p><p></p><p>那么，Serverless怎么帮助AIGC更好地落地？我们可以从以下几个方面展开。</p><p></p><p>首先，在业务逻辑与AI能力的结合方面，AI应用可以分为两方面。一方面，只有将AI的能力与业务逻辑结合，才能实现真正的业务价值。另一方面，AI模型的能力通常是通过API暴露出来的，类似在线应用将业务逻辑与AI的API能力组合起来后可以快速构建应用。这种情况下，建议采用类似微服务架构的松耦合架构和组装式开发理念。</p><p></p><p>此外，AI模型的托管和服务化也是重要的考虑因素。将AI模型的能力转化为API服务、提供灰度发布和回滚等功能，可以更高效地利用资源并降低复杂性。这种模式能够让更多的模型能力通过API方式提供。我相信Serverless能让这个复杂度变得更低。有助于让更多的模型能力通过API方式发挥出来。</p><p></p><p>最后，AIGC中的模型迭代和版本化也很重要。特别是对于大型公司来说，可能需要围绕大型模型构建数据库和知识库等周边资源，并进行数据清洗、提炼和模型微调，最终将它们转化为新的模型。这种以版本化方式进行迭代并部署发布方式的实现，需要大量的软件工程能力。在这方面，开源软件和云服务提供商都在努力增加自身能力，以便更好地整合AIGC的复杂流程和软件栈、降低复杂度。这种集成对于AIGC来说是非常有价值的，也是Serverless能够为AIGC提供价值的一个重要方面。</p><p></p><p></p><p>InfoQ：有一个观众提问道，他理解的“Serverless是用于部署&nbsp;AIGC相关模型的”是否正确？</p><p></p><p>孙蔚（圣翁）：有两个角度可以考虑。首先，根据不瞋老师的说法，你可以将AIGC与Serverless结合。Serverless可以解决前期服务的按需定制、计算资源保护等问题。在消耗大量计算资源、同时运行多个计算任务导致内存溢出等情况下，你可以在Serverless上进行部署，并采取适当的调度。</p><p></p><p>另一方面，如果要解决相关模型的问题，需要考虑模型的数量以及在何处部署模型。在部署模型时可以使用Serverless，这意味着当你搭建自己的算法平台时，可以自行设计算法平台。当要部署多个模型或者拆分模型等时，可以结合Serverless来提高性能并改善效能。无论是进行训练还是自动化都可用Serverless。</p><p></p><p>总结来说，Serverless&nbsp;可以用于外部，也可以应用于内部。在外部使用时，它更像是一个黑盒，你可以通过公开的信息进行解释。而在内部使用时，它主要用于提高算法模型的部署、自动迭代训练，包括数据清洗等方面。内部还是外部使用取决于个人选择，因为Serverless本身是一种架构理念，并没有限定的使用范围。</p><p></p><p>杨皓然（不瞋）：从架构理念的角度来看，我们可以更具体地讨论Serverless平台和计算服务是否适合托管模型。我认为这取决于具体情况。通常情况下，Serverless计算服务适合托管一部分模型，即那些能够充分发挥服务弹性的模型。</p><p></p><p>然而，对于通义千问、ChatGPT或开源版本等较大的模型来说，它们对计算资源的需求非常高。在这种情况下，我认为这类模型可能不太适合在Serverless平台上托管。是否托管最终还是取决于平台本身的计算能力取向与限制。</p><p></p><p>InfoQ：AIGC应用有哪些特点？Serverless&nbsp;如何帮助帮助开发者进行AIGC应用开发和部署？此外，Serverless+AIGC还有哪些成熟的案例或者应用场景？</p><p></p><p>杨皓然（不瞋）：我觉得，AIGC应用与常见的在线应用有许多相似之处。在许多情况下，它们仍然会组合底层模型的API能力，以实现业务逻辑。然而，对于一类特殊的AIGC应用，更适合采用异步自驱动的架构，例如聊天机器人或者像LangChain这样专门的开发框架。在LangChain框架中定义了许多类似代理(agent)的概念，这些代理与底层模型的API进行交互，像一个大脑，但需要执行许多实际操作。</p><p></p><p>这些实际操作是真正与实际业务需求和场景结合、解决实际问题的。而这些操作实际上是具体的功能，是无状态的，能完成简单的操作，但非常灵活。在这种模式下，将它们部署在类似函数服务上是非常契合的。因此，根据我们之前的观察，AIGC应用的特点与Serverless架构理念非常适配。Serverless提供了一些开发工具，让客户将模型转化为服务的能力更加简单。通过Serverless平台，用户可能不需要太多的开发背景，只需了解其中的一些细节就可以快速设置并使用。</p><p></p><p>我之前与一位客户进行过交流。他是一位设计师，有一定的代码开发背景，但并不深入。他在Serverless平台上能够快速设置Stable&nbsp;Diffusion等开源模型，并最终实现业务效果。这是Serverless与AIGC应用结合的实际案例。我相信在未来，随着以LangChain为代表的AI应用框架的成熟，我们将看到许多类似的应用将在Serverless平台上运行，这是最短的路径。</p><p></p><p>孙蔚（圣翁）：AIGC应用的本质是提高效率。无论是制作广告素材、内容、视频或Logo等，AIGC应用都是利用现有工具提高效率来替代传统的人力成本。此外，AIGC应用还可以用于数据处理，包括数据标注和数据清洗等领域。使用AIGC可以实现提效的核心目标，一方面是智能提效，另一方面是功能提效。</p><p></p><p>然而，在部署AIGC时，是否真正使用Serverless平台主要取决于预测的场景，以及是基于开源还是自行开发的模型。对于基于开源的情况，需要考虑应用中的挑战点；而对于自行开发的模型，需要根据消耗情况来使用Serverless进行优化和保护。</p><p></p><p>具体使用Serverless平台部署AIGC应用时，还需综合考虑使用场景和相关挑战，并根据预测场景进行优化。对于基于开源或自行开发的模型，可以通过Serverless平台来优化算力消耗，尤其是在模型加载和AI计算环节中消耗较大的情况，可以考虑使用Serverless架构进行重写。同时，引入其他向量并在训练值上构建领域性的向量数据库，也有助于进一步优化AIGC应用。</p><p></p><p>通过将架构拆分并使用Serverless平台进行开发和部署的优化，用户可以根据业务需求在内核层面进行适当的改进。建议在使用Serverless打包时，不仅将其视为黑盒进行发布和部署，而是根据业务层面或内核层面的需求进行调整。</p><p></p><p>需要指出的是，目前尚没有大规模应用于线上的AIGC案例。这些都还在探索阶段。提出的这些想法是我们正在探索的一个方向，供大家参考。</p><p></p><p></p><p>InfoQ：在AI浪潮下，基础云服务或者说Serverless&nbsp;服务怎么体现为其带来的价值？</p><p></p><p>杨皓然（不瞋）：AIGC应用需要将AI能力与实际业务逻辑结合起来，基础的云服务如数据库、对象存储和消息队列等仍然是必需的，并且与底层的AI能力进行交互通常需要使用API。如果这些组合天然形成了一个业务逻辑与AI能力的整体，那么与云服务整体架构紧密集成后，开发者能够快速组合这些功能来构建应用，这是非常匹配的。</p><p></p><p>随着云服务基础架构的Serverless化以及云产品整体架构的紧密集成，这对AI应用的发展具有巨大的加速作用。AI应用可能并不仅限于传统的在线应用形式，还可以采用事件驱动的架构或像LangChain这样的快速开发框架，实现交互式的AI能力应用。</p><p></p><p>从逻辑上看，AIGC应用可以分为两个部分：决策逻辑和执行动作。决策逻辑涉及根据输入进行决策的AI能力，而执行动作涉及与第三方API的交互等碎片化的代码、强调轻量和可靠地执行。这种执行功能非常适合在Serverless计算服务上运行。</p><p></p><p>此外，刚刚还提到了如何根据业务场景对AI模型进行Fine-tuning，甚至构建专属于企业的大型模型。这是一个复杂的流程，需要深入的技术栈和软件栈。在这方面，需要集成许多开源软件和云产品，使客户能够更快地设置整个流水线。问题诊断等能力也非常重要。因此，Serverless服务的目标是使云的整体产品体系相互集成和可组合。</p><p></p><p>通过工作流等工具，可以快速编排流水线，将大数据服务或AI服务等已有的服务通过事件驱动的方式与用户自己的业务逻辑和数据处理流程相结合。这样，客户可以根据自身企业的情况建立适配的学习流水线，这些能力将极大地帮助客户。</p><p></p><p>InfoQ：阿里云的Serverless产品线有因为&nbsp;AIGC&nbsp;做一些相应的调整吗？</p><p></p><p>杨皓然（不瞋）：在过去几年的规划和发展中，我们平台注重适配各种功能，包括与流行的开源AI框架匹配。在整个平台的发展方向上，我们注重与AI的发展相契合。&nbsp;从整个布局来看，我们在几年前就开始布局GPU和Serverless等能力，并发布了相应的产品，并持续进行迭代和改进。</p><p></p><p>孙蔚（圣翁）：在我看来，Serverless本质上是一种架构理念。在当前的技术浪潮中，我认为它有两个重要的价值。</p><p></p><p>首先，AI的痛点有很多，比如算力等问题，通过结合服务化的架构理念，可以将AI产品进行服务化，这确实能够解决目前中心化的问题，并实现更多的AI产品商业化。</p><p></p><p>其次，如果AI支持商业化、整个业务也支持商业化，那么通过业务逻辑与AIGC&nbsp;API的结合上，再加上对整个算法的商业化支持，就能够实现从前到后的全方位支持，例如可以实现按需弹性扩展、事件驱动、流程编排等各种功能，这才是真正的实现。</p><p></p><p>举例来说，对于一个创业公司来说，如果他们只懂前端、Python、PHP或Node.js，他们也可以使用AIGC，还可以进行工程开发、提供服务、设计界面等各种工作，几乎可以做任何事情。实际上，Serverless屏蔽了所有底层实现的细节，从工程到算法到数据到服务，极大地释放了效率。这样，有人专注于底层开发，其他人专注于工程开发，我认为这才是未来的终局。</p><p></p><p>InfoQ：底层技术演进对大模型等最新AI&nbsp;趋势会带来哪些影响？</p><p></p><p>孙蔚（圣翁）：根据我的观察，主要有两个方面的发展。</p><p></p><p>首先，我想先谈谈算力的普惠化。在未来两到三年，算力将变得越来越普及。目前算力确实是一个问题。随着技术的发展，算力将能够真正解决大规模商业AI的问题，并广泛应用于各行各业，迎来一个普惠的时代。</p><p></p><p>其次，我想谈谈技术工程的发展，这包括云原生应用、服务化以及前面提到的云原生数据库等。这些底层技术的发展将促进AI技术领域的进步。从前到后，无论是算法的内核、模型加载还是训练部分，它们都将采用公正的理念，即算法的融合，来推动整个AIGC或AI的功能化，使其更多地商用化。换言之，通过算力、AI、工程、业务、前端等的普及化，使研发变得更加简单。</p><p></p><p>杨皓然（不瞋）：我认为底层技术的演进对于大模型等最新AI趋势会产生以下影响。</p><p></p><p>首先，涉及到大模型的生成和训练，与服务化、虚拟化关系不大。这些大模型的训练通常需要高性能计算集群，类似于高性能计算（HPC）的模式，对于网络带宽和计算效能的要求非常高。然而，一旦这些模型训练完成，如何通过API等方式发挥其能力，或者让客户能够快速开发基于这些大型模型的AI应用并实现业务价值，则与Serverless或云原生等相关技术密切相关。这与我们之前反复提到的内容相关，我就不再赘述了。</p><p></p><p>这里的重点在于，底层技术的演进不仅涉及到大型模型的生成和训练，还包括如何将其能力通过服务化和云原生等技术应用于实际业务中，以实现快速开发和兑现价值的目标。</p><p></p><p>InfoQ：未来3~5年，高德对于Serverless&nbsp;还会有哪些技术改革和深入探索的地方？&nbsp;阿里云面对AIGC的快速发展将如何布局？</p><p></p><p>杨皓然（不瞋）：我理解阿里云的AIGC布局非常重要，因为AI和大型模型的能力对阿里云来说是核心战略。这涵盖了从大型模型训练到以大型模型为核心构建应用的能力，都是阿里云非常重要的任务。我并不是该领域的专家，因此不会展开讨论大型模型的训练，但我认为阿里云将通过将Serverless与AIGC能力结合，实现围绕大型模型能力快速构建应用的目标，这与我的工作相关。</p><p></p><p>在这种结合方式方面，我提到了几个方向。首先，我们将推动应用开发架构与AI能力的适配。我们倡导打造一系列产品和研发效能工具，支持松耦合、精简的代码和应用架构，使这些应用能够与AIGC能力完美适配。</p><p></p><p>其次，我们的研发效能工具将与AIGC能力结合，使客户更容易生成精准的代码，包括工作流程定义和云资源的基础设施及代码（IaC）定义，从而让客户能够更快速地在整个应用生命周期中享受AIGC带来的效率提升。</p><p></p><p>第三，我们会在Serverless&nbsp;GPU方面持续投入研发。然而，我们的目标并不是托管大模型，而是让更精简的模型能够适配Serverless平台的特点，并在该平台上运行。本质目标仍然是帮助用户解决高成本的问题。</p><p></p><p>孙蔚（圣翁）：&nbsp;高德目前主要在下面三个方面进行探索。</p><p></p><p>第一，是高德的Serverless主要在事件驱动、工作流方面进行改进和深入探索，实现Serverless的极致弹性和无限扩展，目的是降低成本和提高效率。工作流方面，高德的目标是实现代码和配置的分离，并结合自己开发的业务流程引擎，使提升效率加倍。</p><p></p><p>这不仅仅是简单的低代码，还涉及流程编排和与业务的结合，与高德的特点密切相关。高德的特点在于拥有大量的流量，同时可以提供打车和加油等不同的交易服务，这是一个跨多个应用的领域。</p><p></p><p>第二，高德将继续与行业结合，在数据库相关的Serverless产品以及向量数据库等方面继续探索。这些产品都具有一个特点，即存算分离。通过存算分离可以充分利用Serverless来降低研发成本、极大地提升效率。不过，可能需要根据开源工具进行定制和Serverless攻关的处理。Serverless&nbsp;不仅指使用各种云端工具，还与系列产品进行探索结合，定制各种应用和功能。关键目标是极致地提升研发效率，降低成本，实现业务收益，实现商业目标。</p><p></p><p>第三，我们将尽量屏蔽多种语言的差异，使知识具备多语言特性。此外还有底层解耦，包括未来的云漂移，核心在于解除厂商锁定。高德将努力参与开源，共建更好的运行环境、回馈生态系统，使大家能更好地接入这些技术。</p>",
    "publish_time": "2023-08-01 09:41:22",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "字节跳动智能创作 CV 技术负责人吴兴龙，确认担任QCon北京视频与智能创作专题出品人",
    "url": "https://www.infoq.cn/article/fcybweJByURrafE2pGXd",
    "summary": "<p>9 月 3 日 - 5 日，在 <a href=\"https://qcon.infoq.cn/202309/beijing?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=0801&amp;utm_content=wuxinglong\">QCon 全球软件开发大会（北京站）</a>\"，字节跳动智能创作 CV 技术负责人吴兴龙将担任「视频与智能创作」的专题出品人。在此次专题中，你将了解到音视频体验优化的各项手段、智能创作工具的建设，以及它如何为视频生态的繁荣而赋能。</p><p></p><p>吴兴龙，2013 年硕士毕业，一直从事计算机视觉领域研究，当前主要负责多模态 AIGC、智能编辑等技术方向。</p><p></p><p>相信吴兴龙的到来，可以帮助提升此专题的质量。目前视频已成为新时代的主流表达语言之一，通过本专题，你能了解到如何优化音视频体验，如何建设智能创作工具，以及它是怎样赋能视频生态的繁荣的，为视频与智能创作领域拓展了新的发展方向。</p><p></p><p>除上述专题外，QCon 北京还将围绕<a href=\"https://qcon.infoq.cn/202309/beijing/track/1553?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">异构计算</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1554?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">向量数据库</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1556?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">FinOps&nbsp;落地</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1558?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">业务安全技术</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1557?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">从&nbsp;BI&nbsp;到&nbsp;BI+AI，新计算范式下的大数据平台</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1559?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">从&nbsp;MLOps&nbsp;到&nbsp;LLMOps</a>\" 等进行分享。</p><p></p><p>近 100 名讲师、近 30 个精彩专题、8 种交流活动，QCon 北京 2023，相约 9 月！现在购票，享 9 折特惠，立省 ¥880！咨询购票请联系 18514549229（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/33/33cbbbf20baa8b2a18db4f0681f159aa.jpeg\" /></p><p></p>",
    "publish_time": "2023-08-01 14:22:38",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "OceanBase 数据库",
    "url": "https://www.infoq.cn/article/z3dflU6W0wilkaSAgh53",
    "summary": "<p>OceanBase 数据库是蚂蚁集团完全自主研发的原生分布式关系数据库软件。它在普通服务器集群上实现金融级稳定性和高可用，首创“三地五中心”城市级故障自动无损容灾新标准，具备基于原生分布式的卓越的水平扩展能力。</p><p></p><p>OceanBase 是全球首家通过 TPC-C 标准测试的分布式数据库，单集群规模超过 1500 节点。OceanBase 目前承担蚂蚁集团支付宝 100% 核心链路，在国内几十家银行、保险公司等金融客户的核心系统中稳定运行。</p><p></p><p>本电子书将从多租户架构、数据库对象、数据链路、用户接口和查询语言等多维度，教你全面掌握 OceanBase 数据库的相关知识！</p><p><img src=\"https://static001.geekbang.org/infoq/f1/f11bc4495c0ac7886dbe9858752b9579.png\" /></p><p>扫/码/下/载</p>",
    "publish_time": "2023-08-01 15:10:37",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "年薪超600万，比技术总监还高：电影行业AI产品经理的崛起",
    "url": "https://www.infoq.cn/article/0C4UMi4cVGDygpJjhblL",
    "summary": "<p></p><blockquote>90万美元高薪招募AI产品经理，65万美元招聘生成式AI技术总监。</blockquote><p></p><p>&nbsp;</p><p>近几天，由人工智能制作的《创世纪》电影预告片在推特上引起了轰动。</p><p>&nbsp;</p><p>这部富有想象力的预告片，具有专业级的视觉效果，已经吸引了上百万的观看。它由德国大众ELLI产品经理<a href=\"https://www.iamneubert.com/\">Nicolas Neubert</a>\"使用Midjourney 和Runway 工具制作完成。而且更为重要的是从概念、故事、剪辑、音乐，都只有他一个人。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d4/d447160b8516f39a9c411d74b7476703.png\" /></p><p></p><p>&nbsp;</p><p>Neubert 在推特上阐述了制作的全过程，他表示整个片子总共花了他 7 个小时，“在 Midjourney 中生成了 316 个提示，在 Midjourney 中放大了 128 个图像，在 Runway 中生成了 310 个视频，以及一个使用 texta 生成的视频。预告片中总共使用了 44 个视频。” 总费用：Runway费用 95 美元，Midjourney费用 30 美元，一共125 美元。</p><p>&nbsp;</p><p>“预告片非常棒，”Magic Leap 创始人 Rony Abovitz 说道，目前他已转投电影行业。“毫无疑问，我认为电影的未来将永远改变，许多新的、令人惊叹的电影将被创造出来。以前这些电影通常需要数亿美元和数千人才能创造出来，然后调整和完善又需要花费数年时间，但我认为到 2030 年，这一切将永远改变。”</p><p>&nbsp;</p><p></p><h2>AI让演员们害怕，但这阻止不了技术前进的脚步</h2><p></p><p>&nbsp;</p><p>7月以来，好莱坞16万演员还在罢工，制片厂显然没有让步的意思。好莱坞高管们一边坚称演员们的涨薪诉求“不切实际”（目前87%的演员收入不足2.6万美元），一边在AI项目上投入大量资金。</p><p>&nbsp;</p><p>尽管迪士尼等娱乐公司拒绝透露其AI投资的具体细节，但外媒The Intercept从招聘信息和财务报告中追寻到了他们采用AI技术的大量蛛丝马迹。</p><p>&nbsp;</p><p>其中，Netflix为一个AI岗位开出了高达90万美元（约645万人民币）的惊人年薪。</p><p>&nbsp;</p><p>该职位的官方描述是机器学习部门的产品经理，薪资范围为 30 万至 90 万美元，可以远程工作。他们将负责增强 Netflix 的机器学习平台（MLP），并将人工智能用于“创造精彩的内容”。</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/61/618523c0edf8bcbe57230dbcec143db1.jpeg\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>7月13日，电影与电视制片人联盟（代表电视和电影企业同演员与剧作家工会谈判的行业协会）公布了一项突破性的AI智能提案，要求演员同意创建和使用基于他们本人的数字复制品或对他们的表演进行数字更改。</p><p>&nbsp;</p><p>美国演员工会（SAG-AFTRA）指出，制片厂是想用人工智能取代背景演员。美国演员工会的首席谈判代表Duncan Crabtree-Ireland表示，这意味着制片厂可以对演员进行扫描，这样一来，只要付给他们一天的工资，就可以直接用人工智能把他们插入到电影的其他部分。</p><p>&nbsp;</p><p>在《黑镜》剧集中出演角色的演员Rob Delaney坦言，“在他们建立的这支无神论AI军队当中，每名士兵的年薪高达90万美元，而这笔收入足够让35名演员及其家人获得美国演员工会联合会（SAG-AFTRA）的健康保险。这简直太可怕了。经历了这个行业中的种种贫富极端对立，我可以向大家保证，企业掌握着足够的金钱；他们只是对资金划拨有自己的优先级考量。”</p><p>&nbsp;</p><p>而演员们的核心诉求之一，就是保护自己的数字肖像不会在未得到足够补偿的情况下，受到AI的随意操弄。</p><p>&nbsp;</p><p>根据SAG-AFTRA的制式合同，群众演员的日薪约为200美元。Realeyes公司发布的招聘条件比这略高：在两个小时内“表达不同情感”并“即兴创作简短场景”以“训练AI数据库更好地表达人类情感”的工作，报酬为300美元。</p><p></p><p>Realeyes开发出了能衡量用户对视频内容关注度和观看反应的技术。虽然这份招聘信息没有提到与流媒体公司合作，但Realeyes网站上的一段视频还是显示出Netflix和Hulu的徽标。</p><p></p><p>在这条招聘信息中，专门强调表演是出于“研究”目的，因此“并不受罢工活动影响”：“请注意，本项目并非意在取代演员，而是需要借助演员的专业知识。”Realeyes多次指出，会在训练中限制AI创造出“富有表现力的化身”。</p><p></p><p> “这里所说的「研究」很大程度上是在混淆视听，大家都知道行业研究成果总会进入商业产品。”</p><p>专家们则质疑研究和商用之间是不是真的这么泾渭分明。芝加哥大学计算机科学教授Ben Zhao表示，“几乎可以肯定，这项「研究」在商业化后会被用于打造取代人类的数字演员。这里所说的「研究」很大程度上是在混淆视听，大家都知道行业研究成果总会进入商业产品。”</p><p></p><h2>90万美金年薪的产品经理需要做些什么？</h2><p></p><p>Netflix发布的AI产品经理职位年薪为90万美元，这也清楚地表明AI不只是确定向用户推荐影音内容的算法。该帖子还暗示了这家流媒体巨头正努力将人工智能整合到所有业务领域：“AI正推动所有业务领域的创新”。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/30/3062da3ffed0d20db2bc75b9bfea97ff.jpeg\" /></p><p></p><p>&nbsp;</p><p>与工程部门合作，制定MLP的战略愿景、目标、关键结果和成功指标，并与更广泛的业务目标协调一致；从Netflix内部的ML/AI参与者和应用工程师那里收集反馈并了解用户需求，得出产品需求并确定其重要性和优先级；确保战略性重要产品举措在整个生命周期内取得成功，包括从构思到全面推出和持续支持；向利益相关者和高管沟通反馈战略计划、发展路径和最新进展，例如通过产品审查论坛、季度OKR检查等；针对ML平台用户创建用户教育和支持计划；跟进和评估外部行业趋势和创新；</p><p>&nbsp;</p><p>Netflix的AI产品经理在招聘帖中还提到该公司正为拥抱AI做出巨大努力，包括“机器学习平台”和“涉及整个Netflix”的AI专家。Netflix网站还列出了<a href=\"https://research.netflix.com/research-area/machine-learning\">研究专栏</a>\"，描述了该公司的内部机器学习平台。这里提到虽然该平台以往曾被用于推荐等功能，但现在已经开始转向内容创建。</p><p>&nbsp;</p><p>“从历史上看，个性化一直是最著名的应用场景，机器学习成为我们推荐算法的底层驱力。我们还利用机器学习整理成功内容中的特征，借此塑造我们的电影和电视节目目录。我们也在用它优化Netflix快速发展的工作室原创电影和电视节目制作。”</p><p>&nbsp;</p><p>Netflix已经开始将AI技术投入实际应用。7月6日，这家流媒体巨头首播了新的西语真人约会节目《Deep Fake Love》，其中使用参赛者的面部与体态扫描创建出了由AI生成的deepfake模拟形态。</p><p>&nbsp;</p><p>在另一则招聘启事中，Netflix正为其游戏工作室和研发技术实验室物色生成式AI技术总监&nbsp;。这可能是要替代电子游戏领域的配音演员和故事编剧。</p><p>&nbsp;</p><p>生成式AI是一种能够根据输入数据生成文本、图像和视频的AI类型——这是内容原创制作中的关键一环，同时也可用于广告宣传等其他目的。生成式AI与以往那些为人所熟知的AI模型不同，能够在算法推荐和流派标签之外提供更丰富的功能实现。</p><p>&nbsp;</p><p>Zhao解释道，“所有这些模型通常都被视为判别模型或者分类器。它们无法像ChatGPT或图像生成器模型那样创造出新的内容。”</p><p>&nbsp;</p><p>“但生成模型存在自己的道德问题”。</p><p>&nbsp;</p><p>Netflix为其生成式AI技术总监职位开出的年薪，为65万美元（约465万人民币）。另外，会员满意度 ML（可能是推荐引擎类）的工程经理薪资高达 849,000 美元，但“市场范围”的基准为 449,000 美元。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/35/35239e751069967b35d13734a2d448ad.png\" /></p><p></p><p>&nbsp;</p><p>电子游戏编剧们也担心自己的饭碗被生成式AI抢走。主要游戏开发商育碧表示，他们已经在使用生成式AI为非玩家角色编写对话。</p><p>&nbsp;</p><p>Netflix正宣传其一款名为《Scriptic:&nbsp;Crime Stories》的游戏，这款犯罪背景的作品“使用生成式AI帮助讲述故事”。</p><p>&nbsp;</p><p></p><h2>迪士尼的AI运营之道</h2><p></p><p>迪士尼也列出了AI相关职位的招聘信息。这家娱乐巨头正寻求一名高级AI工程师，以“推动我们的电影流程和创新戏剧体验。”帖子里提到，AI已经在迪士尼旗下多家知名工作室中得到应用，包括漫威、沃特迪士尼动画和皮克斯。</p><p>&nbsp;</p><p>在最近的一次财报电话会议上，迪士尼CEO Bob Iger分享了该公司在将AI整合进现有商业模式中面临的实际挑战。</p><p>&nbsp;</p><p>根据报道，Iger指出“实际上，我们已经开始用AI技术来提高效率，并最终更好地服务消费者。但我们也明显发现，AI将具有极高的颠覆性，甚至可能极其难以管理，特别是在知识产权管理的角度带来麻烦。”</p><p>&nbsp;</p><p>Iger补充道，“可以告诉大家，我们的法务团队正在加班加点，努力应对其中可能引发的一系列挑战。”尽管Iger拒绝透露具体细节，但迪士尼向美国证券交易委员会提交的文件中仍显现了一些端倪。</p><p>&nbsp;</p><p>文件指出，“用于管理新技术，例如生成式AI，发展的规则仍悬而未决。这些进展可能会给我们现有商业模式带来全方位的影响，包括我们的知识产权收入源和创造娱乐产品的具体方式。”</p><p>虽然知名演员们纷纷开始保护自己的知识产权免受AI侵害，但Iger认为工会的要求“不切实际”。但迪士尼自己又何尝不是如此？</p><p>&nbsp;</p><p>Zhao表示，“很明显，娱乐业愿意在生成式AI方面进行大量投资。这说的可不是潜在的几亿美元，还包括对其知识产权的宝贵访问权，以便训练AI模型来取代演员、作家、记者等岗位所对应的人类创造力。”</p><p>&nbsp;</p><p>对于一些演员来说，这代表的已经不只是一场对抗AI本身的反乌托邦式斗争，而更多是为了自己能在行业中争取到公平的工作条件，夺回对肖像、身体、动作和言语模式的控制权。</p><p>&nbsp;</p><p>Delaney总结道，“AI并不邪恶，只是我们雇员需要掌握和控制生产资料！我优美的嗓音、宽阔的臂膀和随音乐起舞的电臀，都要由我自己说了算！这可不是那帮风险投资人和董事会成员一边喝着小酒、一边晒着太阳就能决定的。”</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://twitter.com/iamneubert\">https://twitter.com/iamneubert</a>\"</p><p><a href=\"https://www.maginative.com/article/the-making-of-genesis-movie-trailer-midjourney-runway/\">https://www.maginative.com/article/the-making-of-genesis-movie-trailer-midjourney-runway/</a>\"</p><p><a href=\"https://www.forbes.com/sites/charliefink/2023/07/28/gen-ai-movie-trailer-for-sci-fi-epic-genesis/?sh=46b285b9799d\">https://www.forbes.com/sites/charliefink/2023/07/28/gen-ai-movie-trailer-for-sci-fi-epic-genesis/?sh=46b285b9799d</a>\"</p><p><a href=\"https://jobs.netflix.com/jobs/278437235\">https://jobs.netflix.com/jobs/278437235</a>\"</p><p><a href=\"https://research.netflix.com/research-area/machine-learning\">https://research.netflix.com/research-area/machine-learning</a>\"</p><p><a href=\"https://research.netflix.com/research-area/machine-learning\">https://research.netflix.com/research-area/machine-learning</a>\"</p><p><a href=\"https://theintercept.com/2023/07/25/strike-hollywood-ai-disney-netflix/\">https://theintercept.com/2023/07/25/strike-hollywood-ai-disney-netflix/</a>\"</p>",
    "publish_time": "2023-08-01 15:18:22",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "高性能网络通信架构RDMA的设计与实现",
    "url": "https://www.infoq.cn/article/d9w4NK2l1Pi8FIMi24K4",
    "summary": "<p></p><blockquote>传统以太网方案存在系统调用消耗大量时间、数据复制增加传输延时、数据包的封装和解析对 CPU 造成很重的负担三个缺点，而 RDMA 技术可以解决以上三个缺点。那 RDMA 究竟是什么？RDMA 方案的设计思路是什么？</blockquote><p></p><p></p><h2>RDMA技术的软件架构与设计思路</h2><p></p><p></p><h4>RDMA 和传统网络方案的比较</h4><p></p><p>&nbsp;</p><p>传统以太网方案存在三个缺点：send/sendto 等系统调用导致 CPU 在用户态和内核态之间切换，消耗大量时间；发送过程中需要 CPU 把数据从用户空间复制到内核空间（接收时反向复制），增加了数据传输延时；需要 CPU 全程参与数据包的封装和解析，在数据量大时将对 CPU 将造成很重的负担。</p><p>&nbsp;</p><p>RDMA 技术可以解决上述三个问题：首先，其在数据传输过程中没有系统调用；然后，在系统内存内部做到零拷贝，省掉了数据在用户空间和内核空间之间拷贝的步骤。最后，把数据包的封装和解析交由网卡硬件来做，降低了 CPU 负载。</p><p></p><h4>RDMA 协议类型</h4><p></p><p>&nbsp;</p><p>RDMA 指的是一种远程直接内存访问技术。具体到协议层面，它主要包含了Infiniband（IB），RDMA over Converged Ethernet（RoCE）和Internet Wide Area RDMA Protocol（iWARP）三种协议。三种协议都符合RDMA标准，共享相同的上层用户接口（Verbs），只是在不同层次上有一些差别。</p><p></p><h4>RDMA 软件架构</h4><p></p><p>&nbsp;</p><p>RDMA 的软件架构按层次可分成两部分，即 rdma-core 和内核 RDMA 子系统，分别运行在 Linux 系统中的用户态和内核态。整个软件架构适用于所有类型的 RDMA 网卡，不管网卡硬件执行了哪种 RDMA 协议（Infiniband/RoCE/iWARP）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0a/0adde59572b59f515b925cd31852a5ef.png\" /></p><p></p><p></p><h4>RDMA 基本元素和操作类型</h4><p></p><p>&nbsp;</p><p>WQE（Work Queue Element，工作队列元素）的作用类似于以太网方案中收发队列里的描述符（Desc）&nbsp;。其中包含了软件希望硬件去做的任务类型（远程读、远程写、发送还是接收等）以及任务的详细信息（数据所在的内存地址、数据长度和访问密钥等）。</p><p>&nbsp;</p><p>WQ（Work Queue，工作队列）类似于以太网方案中的发送/接收队列，WQ 里面可以容纳很多 WQE，这些 WQE 在 WQ 中以先进先出（FIFO）队列的形式存在。</p><p>&nbsp;</p><p>QP&nbsp;是一个发送工作队列和一个接受工作队列的组合，这两个队列分别称为 SQ（Send Queue）和 RQ（Receive Queue）。SQ 和 RQ 都是一种 WQ。SQ 专门用来存放发送任务，RQ 专门用来存放接收任务。在一次 SEND-RECV 流程中，发送端需要把表示一次发送任务的 WQE 放到 SQ 里面（这种操作称为 Post Send）。同样的，接收端需要把表示一次接收任务的 WQE 放到 RQ 里面（称为Post Receive），这样硬件才知道收到数据之后放到内存中的哪个位置。在RDMA技术中，通信的基本主体或对象是 QP，而不是节点。对于每个节点来说，每个进程都可以申请和使用若干个 QP，而每个本地 QP 可以“连接到”一个远端的 QP。每个节点的每个 QP 都有一个唯一的编号，称为 QPN（Query Pair Number），通过 QPN 可以唯一确定一个节点上的 QP。</p><p>&nbsp;</p><p>CQ&nbsp;意为完成队列（Completion Queue）。跟 WQ 中含有很多 WQE 类似，CQ 这个队列中也有很多元素，叫做 CQE（Completion Queue Element）。可以认为 CQE 跟 WQE 是相反的概念。如果 WQE 是软件下发给硬件的任务，CQE 就是硬件完成任务之后返回给软件的“完成报告”。每个 CQE 都包含某个 WQE 的完成信息。</p><p>&nbsp;</p><p>RDMA WRITE 操作是一端应用主动写入远端内存的行为，除了准备阶段，远端 CPU 不需要参与，也不感知何时有数据写入、数据在何时接收完毕。所以这是一种单端操作。需要注意的是，操作发起端的应用程序是通过虚拟地址来读写远端内存的，上层应用可以非常方便的对其进行操作。实际的虚拟地址—物理地址的转换是由 RDMA 网卡完成的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/be/bebf58722df89f9b03971e0d15d8c942.png\" /></p><p></p><p></p><h4>RDMA 方案的设计思路</h4><p></p><p>&nbsp;</p><p>下图中横向箭头表示的是某应用程序执行的步骤。每个步骤中下行的箭头和方框表示当前这个步骤的简要实现流程。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0b/0bbf8a22c0be7eb219e1368dd946cd0d.png\" /></p><p></p><p>RDMA 实现方案的设计思路中比较重要的三点：初始化和配置等低频操作可以进入内核态执行；数据传输等高频操作旁路内核；独立的 QP、CQ 资源保证多线程并发。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/48/48a270d0ce17ab0bc410452fdbc2f1d3.png\" /></p><p></p><p></p><h2>浪潮 iRDMA 方案的设计思路</h2><p></p><p>&nbsp;</p><p>iRDMA&nbsp;是浪潮信息体系结构研究部利用自研 F10A FPGA 加速卡，基于 Linux 内核 IB 驱动架构和 rdma-core 开源协议栈，开发的一套 RDMA 网络加速平台，用户可在其基础上进行二次开发。</p><p>&nbsp;</p><p>下面是它的软件模块框图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/39/39a8eef4a883234f9146a4f414d1d1f9.png\" /></p><p></p><p>我们使用 perftest 工具测试 iRDMA，并和 Mellanox ConnectX-4 Lx 10G 网卡做比较，带宽测试结果见下图。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/94/948247be610190ae3aa2d5f35c9fbcf3.png\" /></p><p></p><p>总体来说 Mellanox 网卡比 iRDMA 带宽大一点，按比例看小 size 时比较明显。</p><p></p><h4>作者介绍</h4><p></p><p></p><p>刘伟，浪潮信息驱动工程师，著有《Linux高性能网络详解:从DPDK、RDMA到XDP》一书。</p>",
    "publish_time": "2023-08-01 17:39:54",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]