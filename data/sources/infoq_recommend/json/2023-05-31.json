[
  {
    "title": "云绑定应用：实现业务逻辑，减轻开发者负担",
    "url": "https://www.infoq.cn/article/bc2s3cFS2UOgCmHCgVAJ",
    "summary": "<p>随着对<a href=\"https://www.diagrid.io/blog/evolution-of-cloud-computing\">应用为先</a>\"的云服务采用愈发广泛，应用与云服务的融合程度也到了前所未有的深度。应用程序和云运行时的边界从虚拟机转移到了容器和函数中。集成边界从仅使用数据库和消息代理访问，转换成应用程序的机械部分在云中的混合运行。在这些因素影响下的架构中，应用程序与“云绑定”，应用逻辑与管理责任转移至云服务中，允许开发者专注于业务逻辑。</p><p>&nbsp;</p><p>本文中将分析，通过使用具备灵活性和可移植性的公开 API 和标准将应用程序与云服务绑定，所带来的软件全栈平价化。</p><p></p><h2>内部架构的演变</h2><p></p><p></p><p>应用程序的内部架构通常归属于单一团队掌控。内部的边界则由所选编程语言、运行时、工具，以及包、模块、接口、类、函数等抽象协助开发者进行控制。<a href=\"https://martinfowler.com/bliki/DomainDrivenDesign.html\">领域驱动设计</a>\"（DDD）协助开发者构建领域模型，用抽象概念封装服务业务逻辑，缓解业务实际与代码之间的鸿沟。</p><p>&nbsp;</p><p><a href=\"https://alistair.cockburn.us/hexagonal-architecture/\">Hexagonal</a>\"、<a href=\"https://jeffreypalermo.com/2013/08/onion-architecture-part-4-after-four-years/\">Onion</a>\"，以及 <a href=\"https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html\">Clean</a>\" 架构可以与 DDD 相<a href=\"https://herbertograca.com/2017/11/16/explicit-architecture-01-ddd-hexagonal-onion-clean-cqrs-how-i-put-it-all-together/\">互补</a>\"，以不同边界与外部基础设施依赖划分应用程序代码。虽然这些方式最初都是颇具创新意识且时至今日仍然适用，但这些架构的设计初衷只考虑了包含 JSP、Servlet、部署于共享应用运行时的 EJB 这三层的 Java 应用程序，当年设计的重点还是应用逻辑与 UI、数据库解耦，实现独立测试方面。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7b/7b2660b0979f4d1dffdcbf12c57eec85.png\" /></p><p></p><p>图一：内部应用架构</p><p>&nbsp;</p><p>后来，微服务、<a href=\"https://12factor.net/\">十二因素</a>\"应用程序等新挑战、新概念层出不穷，应用程序的设计方式也受此影响。微服务的核心是将应用逻辑切分为归属单一团队的独立可部署单元，十二因素应用程序方法意在构建可在动态云环境中运行、扩展的分布式无状态应用。这些架构所引入的原则和最佳实践改写了我们构建应用程序内部架构并管理的方式。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/18/186eb84291ac96f0c7c328cfc8d033f3.png\" /></p><p></p><p>图二：应用程序架构演变时间线</p><p>&nbsp;</p><p>在应用程序架构演变时间线的后半段，容器的采用和 Kubernetes 的引入成为主流，彻底改变了应用打包、协调的方式。AWS Lambda 引入了高度可扩展的功能即服务（FaaS）的概念，将应用程序细粒度概念再度拔高，将完整的基础设施管理责任卸至云供应商。其他如服务网格、<a href=\"https://www.infoq.com/articles/multi-runtime-microservice-architecture/\">Mecha 架构</a>\"等技术潮流的出现，网络和分布式开发者基元等非功能性应用栈平价化并剥离至 sidecar 中。受微服务启发，数据网格架构设计意图将应用程序的数据分析架构拆分至更小的独立数据域中，让每个域都有自己的项目和团队。再加上近期的应用为先云服务等等，这一系列技术潮流开始重塑应用程序的外部架构，本文中我将这些统一称为“云绑定应用”。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>外部架构演变</h2><p></p><p></p><p>外部架构是应用与其他团队和组织以专门的内部中间件、存储系统，或云服务等形式拥有的其他应用和基础设施交互的部分。应用与外部系统相连并卸除部分责任的方式构建了外部架构。为充分利用基础设施，应用需要与该基础设施绑定，确立明确分界线以保留其敏捷性。应用的内部架构和实现应独立进行修改，并在不变动内部的情况下与云服务等外界依赖关系互换。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7c/7c37818055195a38e324b7ab10b34892.png\" /></p><p></p><p>图三：外部引用架构</p><p>&nbsp;</p><p>大体上来说，我们可以将应用程序与其周围环境相绑定的方式分为两类。</p><p>&nbsp;</p><p>计算绑定，包含所有必需的绑定、配置、API，以及程序在 Kubernetes、容器服务，乃至无服务功能（如 AWS Lambda）等计算平台中运行所用的协议。多数情况下，这些绑定对内部架构是透明的，配置更多是为运维团队而非开发所用。容器抽象目前是最广为人知的应用计算绑定“API”。集成绑定，覆盖范围非常广，从除计算绑定外的其他绑定，到应用的外部依赖关系。云服务同样利用这类绑定与应用交互，常见形式是通过定义完善的 HTTP “API”或专门的消息和存储访问协议，如 AWS S3、阿帕奇卡夫卡、Redis API 等等。集成绑定没有运行时绑定的透明度，开发者也需要实现额外的相关逻辑，如重试、TTL、延时、死信队列（DLQ）等等，并将其与应用的业务逻辑相绑定。</p><p>&nbsp;</p><p>云上运行的应用会通过这些绑定消费其他服务，下面让我们这些绑定背后究竟都是些什么。</p><p></p><h2>计算绑定</h2><p></p><p></p><p>从理论上来说，所有应用程序对运维团队而言都是需要在计算平台上操作的黑盒单元。计算绑定是用于管理应用在 Kubernetes、AWS Lambda 及其他服务平台上的生命周期。这类绑定均是规范化，以配置集合加上应用与其所运行的平台间交互的 API 的形式进行定义。多数交互都是对应用透明的，只有少数 API 需要开发者自行实施，如健康端点和指标 API。这是目前 CNCF 对此的<a href=\"https://github.com/cncf/toc/blob/main/DEFINITION.md\">定义</a>\"，也是“云原生”概念所囊括的范围，开发者只需实现云原生应用，就能将其绑定在云计算平台上运行。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/36/3629b982b603e17c83dff1132a83ea4a.png\" /></p><p></p><p>图四：应用与平台的计算绑定</p><p>&nbsp;</p><p>为让云平台上的运行更为可靠，应用必须在规范到最佳实践等多个层面与平台绑定。这一过程是通过一系列业界标准规范的实现的，如容器 API 和指标 API、基于普罗米修斯（Prometheus）的健康端点、AWS Lambda 或 AWS ECS 等云供应商规范。此外，还有云原生的最强技术和共享知识，如健康检查、部署策略和安置政策。让我们再看看目前最常见的计算绑定方式。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h3>资源需求</h3><p></p><p></p><p>无论是微服务还是功能，应用总会对 CPU、内存和存储等资源有所需求。根据所用的平台不同，资源的定义也会不同。举例来说，Kubernetes 上 CPU 和内存是通过<a href=\"https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\">请求和限制</a>\"定义的，而 AWS Lambda 则是由用户<a href=\"https://docs.aws.amazon.com/lambda/latest/dg/configuration-function-common.html\">指定</a>\"运行时需要分配的内存大小和对应 CPU。不同平台对存储的处理方式也是各异，Kubernetes 使用短期存储和卷，而 Lambda 则提供短期资源抓取和基于亚马逊 EFS 挂载的持久存储。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h3>生命周期钩子</h3><p></p><p></p><p>由平台管理的应用程序通常需要对重要的生命周期事件有感知。举例来说，Kubernetes 中的概念（如容器初始化）和钩子（如容器启动后钩子 PostStart 和容器结束前钩子 PreStop）就可以让应用对这些事件做出反应。同理，Lambda 的<a href=\"https://docs.aws.amazon.com/lambda/latest/dg/runtimes-extensions-api.html\">扩展</a>\" API 也能让应用处理初始、调用、关闭阶段。其他处理生命周期事件的方式包括脚本封装或针对特定语言的运行时修改选项（比如 JVM 的关闭钩子）。这些机制为平台与应用程序之间形成协议，使其能够响应并管理自身的生命周期。</p><p>&nbsp;</p><p></p><h3>健康检查</h3><p></p><p></p><p>健康探针是平台用于监测应用程序健康状况并按需采取对应行动（如重启应用程序）的方式。虽然出于请求短暂的生命周期，Lambda 函数没有<a href=\"https://cloud.google.com/run/docs/configuring/healthchecks\">健康探针</a>\"，但容器化应用程序和Kubernetes、AWS EKS，GCP 云运行等协调器却可以在其定义中涵盖健康探针，让平台上的应用运行更为顺利，出现问题时也能及时采取行动。</p><p>&nbsp;</p><p></p><h3>部署和置放策略</h3><p></p><p></p><p>在获得所需资源后，计算平台可以开始管理应用程序的生命周期了。若想在不破坏业务逻辑完整性的前提下管理生命周期，平台必须要能意识到扩展的限制所在。部分程序只会是单体程序，比如，平台需要维护事件处理的顺序，且不能将其扩展超过一个实例。其他有状态应用可能受法定人数（Quorum）驱动且需要维持指定数量的最小实例，函数才能正常运行。再有，无状态函数可能会倾向于快速扩展以解决负载中不断增长的额峰值。一旦确定了应用程序的扩展方式，平台便能控制应用程序实例的启动和终止。</p><p>&nbsp;</p><p>计算平台同样提供包括滚动、蓝绿、金丝雀、一次性等多种部署策略，用于控制服务的更新顺序。除了部署顺序外，平台可能还支持用户指定置放策略。比如 Kubernetes 提供标签、污点（Taint）、容忍度、亲和性、反亲和性等选项，而 Lambda 则允许用户在区域置放和<a href=\"https://aws.amazon.com/lambda/edge/\">边缘置放</a>\"类型中进行选择。这些平台的偏好选择确保了应用程序的部署，且与预期合规性和性能要求相符。</p><p></p><h3>网络流量</h3><p></p><p></p><p>将低层级网络流量导向服务实例同样是计算平台的责任之一。平台所负责处理的部署顺序、置放，以及自动扩缩容都会影响流量向服务实例的引导。健康检查在流量管理中也发挥着作用，如 GCP 云运行和 Kubernetes 中的<a href=\"https://cloud.google.com/run/docs/configuring/healthchecks\">就绪检查</a>\"。通过处理这些任务，计算平台能够协助确保流量是高效且有效地路由到适当的服务实例。</p><p></p><h3>监测与报告</h3><p></p><p></p><p>任何用于分布式应用程序的计算平台都必然以日志、指标、跟踪的形式提供深入的应用洞察。如今，在当前领域中也有了约定俗成的标准：日志最好为结构化格式，如 JSON 或其他业界特定标准。计算平台通常会收集日志或提供特殊日志清理和分析服务的访问扩展点。比如 Kubernetes 上的 DaemonSet、Lambda 的监控合作伙伴扩展、Vercel 的边缘函数日志 Drainer。计算平台必须要能支持指标、跟踪数据的收集和分析，才能针对分布式应用程序的性能和行为提供全面的洞察力。业界标准中有许多处理这类数据的格式和工具，如普罗米修斯的指标、<a href=\"https://opentelemetry.io/\">OpenTelemetry</a>\"（OTEL）的跟踪。计算平台或提供内置数据收集和分析工具，或提供扩展点允许专门服务访问这类数据。计算平台应支持任何细粒度（微服务或功能）或位置（边缘与否）的代码，对日志、指标、跟踪数据进行捕捉，并导出至其他优秀的云服务中，如 <a href=\"http://honeycomb.io/\">Honeycomb</a>\"、<a href=\"https://www.datadoghq.com/\">DataDog</a>\"、<a href=\"https://sysdig.com/\">Grafana</a>\" 等等。&nbsp;</p><p></p><h3>计算绑定的趋势</h3><p></p><p></p><p>计算绑定是对编程语言和应用运行时不可知的，主要为运维团队管理运行时的应用，而非为开发人员实施所用。</p><p>&nbsp;</p><p>虽然应用的大小和复杂度随单体应用或函数而不同，但基本都会封装在容器内，具有健康检查端点，实现了生命周期钩子，并有指标暴露。理解计算绑定有助于高效使用任何基于容器的计算平台，无论是企业内部的 Kubernetes 集群，还是 AWS ECS、谷歌云运行、Azure 容器应用等管理型容器服务，基于函数的运行时 AWS Lambda、GCP 函数等等，以及基于边缘运行时的 Vercel <a href=\"https://vercel.com/docs/concepts/functions/edge-functions\">边缘函数</a>\"、CloudFlare <a href=\"https://workers.cloudflare.com/\">工作者</a>\"、Netlify 边缘<a href=\"https://docs.netlify.com/edge-functions/overview\">函数</a>\"等等。这些开放和事实标准的 API 不仅能协助创建可移植应用程序，还能通过跨云供应商和服务提供方的操作方法和工具，避免被供应商锁定。</p><p></p><h2>集成绑定</h2><p></p><p></p><p>另一方面，集成绑定则是供开发人员而非运维团队使用。集成绑定以常见分布式系统的实现区域为中心，如服务调用、事件驱动交互、任务调度，以及有状态工作流协调。协助应用程序通过基于云的中间件形式服务，与专用存储系统及外部系统相连，在本文中我将这些服务统一称作“集成云”。与容器所提供的计算抽象类似，集成云提供了编程语言不可知集成抽象即服务。其基元与用例、应用实现、运行时和计算环境相独立。<a href=\"https://learn.microsoft.com/en-us/azure/architecture/patterns/retry\">重试模式</a>\"、<a href=\"https://www.enterpriseintegrationpatterns.com/DeadLetterChannel.html\">DLQ 模式</a>\"、<a href=\"https://microservices.io/patterns/data/saga.html\">Saga 模式</a>\"、服务发现、<a href=\"https://martinfowler.com/bliki/CircuitBreaker.html\">断路器</a>\"模式等等，都可以通过服务形式在集成云中被消费。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d1/d103b9a4bd4466a12ea065667d17bdc2.png\" /></p><p></p><p>图五：应用程序和平台的集成绑定</p><p>&nbsp;</p><p>目前尚不存在将所有主要模式都以独立功能形式暴露的纯集成云。早期的云服务可提供部分集成基元作为卡夫卡、Redis 等存储系统的功能，但却很少能有独立使用或与其他功能相结合的。少有的例外情况是 AWS 事件总线（EventBridge）和 Azure 事件网格等服务，允许与同一厂商的多个云服务同时使用，但不能直接使用其他供应商。这个领域的发展如此快速，虽然还有一些例子或空缺，但我相信在未来，这些空白一定能得到填补。应用程序必须与集成云服务相绑定才能运作，并将部分开发者肩头的责任卸载。以下我将介绍集成云服务的主要类型和绑定方面。</p><p></p><h3>集成需求</h3><p></p><p></p><p>与应用对资源的要求和对计算平台的部署和置放需求同理，应用也会对特定集成绑定有需求。这些绑定可通过声明性配置传入平台，也可在运行时通过代码交互激活。举例而言，应用程序可使用声明式和程序式<a href=\"https://docs.dapr.io/developing-applications/building-blocks/pubsub/subscription-methods/\">订阅</a>\" pub/sub 主题。AWS Lambda 函数可以通过配置声明式地订阅数据源，也可以通过客户端库或 SDK，以程序形式向集成平台发送注册或取消注册特定绑定请求。应用程序可订阅 cron 定时任务触发器，激活连接外部系统的连接器，修改配置等等行为，都是在集成云上进行的。</p><p></p><h3>工作流协调</h3><p></p><p></p><p>逻辑协调对持久性服务而言不仅是一种极为普遍的需求，还是将其外部化并作为服务消费的主要候选。因此，工作流协调是如今最为知名的集成绑定类型之一。这种服务的常见用途包括：用于服务和业务流程协调的 Saga 模式实现、AWS 编排函数（Step Function）、谷歌有状态函数、Azure 持久函数、谷歌工作流的任务分配等等。在使用这类绑定时，应用程序中的部分编排状态和逻辑被卸载至其他服务中。应用服务内部虽然还有状态和逻辑对状态进行管理，但其他的都放在了外部，比如其他云服务上。这代表了现今应用程序以独立单元的形式设计并操作方式的转变。未来的应用程序可能不仅仅只有<a href=\"https://queue.acm.org/detail.cfm?id=3415014\">数据在外</a>\"，集成也会被放在外部。随着对集成云采用的不断出现，更多的集成数据和逻辑将会存在于外部。</p><p></p><h3>临时触发器</h3><p></p><p></p><p>临时绑定是协调绑定中的一类基于时间的分类，具有单一目标，即根据给定策略在特定时间触发不同服务。类似的例子有：事件总线调度器、谷歌云调度器、Upstash Qstack 服务等等。</p><p></p><h3>事件驱动和消息服务</h3><p></p><p></p><p>这类绑定以事件存储形式卸载请求并解耦应用，但其应用如今也越发地不再局限于存储，而是向提供消息处理模式的方向扩展。除了事件存储，这类绑定也为开发者提供了死信队列、重试、延迟交付等各类基元，还有过滤、聚合、重新排序、基于内容的路由、窃听等等消息处理模式。其示例有：Confluent Cloud kSQL、AWS 事件总线、Decodable 数据管线等等。</p><p></p><h3>外部连接器</h3><p></p><p></p><p>这类绑定可协助应用连接至外部系统的同时，也可执行数据规范化、错误处理、协议转换、数据转换。示例有：Knative 源导入器、AWS 事件总线连接器、Confluent 云<a href=\"https://www.confluent.io/product/confluent-connectors\">连接器</a>\"、Decodable 卡夫卡连接器、AWS Lambda 源和目的地。</p><p></p><h3>健康检查</h3><p></p><p></p><p>健康检查是计算绑定中不可或缺的一环，健康检查失败通常会致使应用重启。集成绑定同样需要健康检查，但集成绑定中健康检查不会影响应用的运行时，只会告知集成云当前应用是否有能力处理与集成驱动的交互。失败的集成健康检查会中止集成绑定的过程，直至应用恢复健康才会恢复绑定。经常会出现计算和集成绑定使用同一应用端点进行检查，比如 Dapr 的应用<a href=\"https://docs.dapr.io/developing-applications/building-blocks/observability/app-health/\">健康检查</a>\"可以临时阻止消费者和连接器将数据推入不健康的应用。</p><p></p><h3>其他绑定</h3><p></p><p></p><p>许多其他的绑定类型也可被归为集成绑定。比如自省数据传入应用程序，指类似 Kubernetes 的<a href=\"https://kubernetes.io/docs/concepts/workloads/pods/downward-api/\">向下</a>\" API 或 Lambda 的<a href=\"https://docs.aws.amazon.com/lambda/latest/dg/configuration-envvars.html\">环境</a>\"变量等，通过简单机制将自省数据和元数据注入应用；配置和秘密绑定，指不仅在应用启动时将秘密注入，还可在任何配置更新时都推送至应用之中，如 Hashicorp Vault Sidecar <a href=\"https://developer.hashicorp.com/vault/docs/platform/k8s/injector\">注入器</a>\"、Dapr 的<a href=\"https://docs.dapr.io/developing-applications/building-blocks/configuration/configuration-api-overview/\">配置</a>\" API、Kubernetes 的<a href=\"https://servicebinding.io/\">服务绑定</a>\"规范。此外，不太常见的集成绑定模式还有分布式<a href=\"https://docs.dapr.io/developing-applications/building-blocks/distributed-lock/distributed-lock-api-overview/\">锁</a>\"，提供对共享资源的互斥访问。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h3>集成绑定趋势</h3><p></p><p></p><p>无论是长期运行的微服务还是短期的功能，容器都在逐渐成为应用程序打包和运行使用中最多最广的可移植格式。不过，集成绑定也可以被划分为不同的问题领域：事件驱动交互、有状态协调和状态访问，在底层存储和使用模式方面各有不同。举例来说，阿帕奇卡夫卡是事件日志的<a href=\"https://www.kai-waehner.de/blog/2021/05/09/kafka-api-de-facto-standard-event-streaming-like-amazon-s3-object-storage/\">事实标准</a>\"，AWS S3 API 用于文档访问、Redis 用于键值缓存、PostgreSQL 用于关系型数据访问等等。这些成为标准化的原因在于不断成长的生态系统，其中包含库、工具，以及围绕其所构建的种种服务，保证了相当程度的成熟度、稳定性、未来的向后兼容性。但是，这些 API 本身只局限于存储访问方面，常常需要开发者自行应对应用程序内的分布式系统挑战。随着软件的平价化，集成绑定也逐渐以服务形式可用。越来越多的无服务云服务提供了额外的集成能力，让应用程序可以绑定数据访问之外的东西。</p><p>&nbsp;</p><p>在这种模式下，云绑定应用通常在无服务计算基础设施中运行，和云原生基元一样。它与其他无服务的云服务相绑定，用于服务协调、事件处理或同步互动，如下所示：</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/67/678d173c03082faca797c5c34ff4ac7a.png\" /></p><p></p><p>图六：云绑定应用程序的生态系统</p><p>&nbsp;</p><p>一项将多数集成绑定和开发者关注的问题统一至开源 API 的项目是 CNCF 的 <a href=\"https://dapr.io/\">Dapr</a>\"。该项目提供了同步的服务调用、有状态的服务协调、异步的事件驱动的交互，以及以 API 为特定技术的连接器。与容器和 Kubernetes 作为计算抽象类似，Dapr 也是外部服务的抽象。此外，Dapr 也提供与底层云服务独立的集成功能，并经常需要在应用层实现，其中就有弹性策略、死信队列、<a href=\"https://github.com/dapr/dapr/issues/2675\">延迟交付</a>\"、跟踪、细粒度授权等等其他。Dapr 的设计是多边形且可在应用之外运行，在不改变应用内部架构的情况下，让外部依赖关系交换可以更轻松，正如其在六边形架构中描述的一样。虽然 Dapr 主要为开发者实施应用程序而用，不过在引入后 Dapr 也提高了分布式应用程序的可靠性和可观测性，为运维和架构团队提供了<a href=\"https://www.diagrid.io/blog/dapr-as-a-10x-platform\">整体效益</a>\"。关于这点更多信息，我将于今年后半年的 QConLondon 大会上<a href=\"https://qconlondon.com/presentation/mar2023/commoditization-software-stack-how-application-first-cloud-services-are\">讲述</a>\"“应用为先的云服务如何改变游戏”，欢迎通过线上或线下形式参与。</p><p></p><h2>后云原生应用</h2><p></p><p></p><p>云绑定的的出现代表了云原生从单纯解决计算问题到管理应用层需求的进步。随着云服务对应用栈的不断扩展，从基础设施向应用为先的转换，让这一趋势也在加速发展。这点从以开发者为中心的有状态协调、事件驱动应用基础设施、同步交互、基于云的开发和部署环境、无服务运行时等爆炸性云服务发展中也能一窥一二。这种向应用为先的云服务正在催生一种新的应用程序架构，其中越来越多的应用逻辑在云服务中执行。这种应用程序于第三方云服务的融合也让开发者们能将更多的责任卸载，但随之而来的还可能有对灵活性和敏捷性的限制，这些都会是不断变化的需求所必备的能力。为保持应用程序内部和外部架构的独立性，应用与云服务应在开发时以整齐的边界进行解耦，并在运行时使用定义明确的开放 API 和格式深度绑定。与容器和 Kubernetes 为计算提供了开放的 API 一样，我们需要为应用集成抽象提供开放的 API。这会使操作实践和工具以及开发模式、能力和实践具有可移植性和可复用性。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/cloud-bound-applications/\">What Are Cloud-Bound Applications?</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/9z8EK3keFuAmJ0NWm9hv\">微软推出Azure Developer CLI公开预览版，帮助开发者加速云应用开发</a>\"</p><p><a href=\"https://www.infoq.cn/article/3xRjcVaKD8zP1D43owc5\">全新 AWS Auto Scaling – 适用于云应用程序的统一扩展</a>\"</p><p></p>",
    "publish_time": "2023-05-31 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AIGC浪潮下，如何推动企业应用及落地？| InfoQ《极客有约》",
    "url": "https://www.infoq.cn/article/w6IoL0J8OBlcCC28SoPB",
    "summary": "<p>AIGC 是当前 AI 领域最热的技术话题，并在全球范围内掀起了一股热潮。可以看到，越来越多的企业开始重视 AIGC 相关技术创新和技术实践，并积极探索应用落地。有预测数据显示，到 2030 年，AIGC 的市场规模或将超过万亿人民币。</p>\n<p>那么，AIGC 技术典型的应用场景有哪些？不同行业如何落地 AIGC 应用？最适合大模型的商业模式是什么？未来会走向完全的 AIGC 吗？本期《极客有约》，我们邀请到了星汉未来联合创始人&amp;CPO 胡忠想老师，为大家分享 AIGC 浪潮下，企业应用及落地经验。</p>\n<p><strong>内容大纲：</strong></p>\n<ul>\n<li>为什么 AIGC 突然爆火？</li>\n<li>AIGC 技术典型的应用场景有哪些？</li>\n<li>不同行业如何落地 AIGC 应用？</li>\n<li>AIGC 最主要的应用价值是降本增效吗？</li>\n<li>这类大模型具体会如何改变我们的工作状态？</li>\n<li>企业在应用 AIGC 技术时如何应对治理挑战？</li>\n<li>目前 AIGC 已经达到大规模商业化的条件了吗？</li>\n<li>最适合大模型的商业模式是什么？</li>\n<li>AIGC 时代需要什么样的人才？</li>\n</ul>\n<p><strong>特邀主持：</strong></p>\n<p>姜雨生，微软软件工程师，负责微软资讯业务与 GPT 集成，曾负责微软广告团队基础设施搭建与维护工作。</p>\n<p><strong>嘉宾：</strong></p>\n<p>胡忠想，星汉未来联合创始人&amp;CPO。北航本硕，2012年加入微博，2015年作为技术负责人负责S级项目Feed核心业务的研发。2017年作为技术负责人带领团队完成公司级Weibo Mesh平台的研发并推广到多个核心业务，使得微博成为业界领先的Service Mesh实践者。2018年作为微博峰值热点应对项目的负责人，带领团队完成公司级热点应对联动机制的建设，保障了微博在后续多次热点事件中的稳定性。2021年作为联合创始人，成立星汉未来并任CPO。</p>\n<p>体验多款 AIGC 应用：<a href=\"https://apps.galaxy-future.com/#/platform/explore&amp;utm_source=c\">https://apps.galaxy-future.com/#/platform/explore&amp;utm_source=c</a></p>",
    "publish_time": "2023-05-31 10:09:33",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "DTDS 全球数字人才发展线上峰会圆满结束：数智升级是每个企业也是每个人的“必修课”",
    "url": "https://www.infoq.cn/article/uNkPRr16JO2m6qqVEGZ3",
    "summary": "<p>人才是驱动社会和经济发展的核心要素，是企业创新的基石。而不同的时代背景，往往会衍生出差异化的人才技能和劳动力结构需求。</p><p></p><p>世界经济论坛曾做过这样一个预判，&nbsp;“到2030年，我们需要对超过10亿员工进行再培训。”站在2030年的时间点，这10亿员工将代表着届时1/3的人才市场；站在眼下的时间点，数字化思维和能力提升，是企业人才储备和人才升级的确定方向，也是未来竞争力的关键所在。</p><p></p><p>2023年5月30日，以“人才为本，数智蝶变”为主题的<a href=\"https://www.infoq.cn/article/zBvRpHrTQY5pIgDNhm3J\">&nbsp;DTDS&nbsp;</a>\"全球数字人才发展线上峰会圆满结束。本次峰会由极客时间企业版、培训杂志联合主办，并得到了GHR&nbsp;环球人力资源智库、InfoQ&nbsp;极客传媒、TGO&nbsp;鲲鹏会、保利威、online-edu在线教育资讯网、酷学院等行业媒体伙伴的大力支持。</p><p></p><p>在会上，来自德勤、东亚银行、南京钢铁、宁德核电等处于行业领先地位的数字化企业，从不同视角分享了对人才趋势的洞察，以及自身在数字化转型背景下，如何进行人才战略制定和人才体系建设。此外，极客时间企业版也在会上发布了&nbsp;AI&nbsp;未来教育学习产品，并深度解读了与培训杂志联合推出的《<a href=\"https://app.jingsocial.com/microFrontend/leadGeneration/jsf-leads/list/contentMarketing/WEHsWZ8h4h3mf5sCez4feD/2ykbEVvnAyg6cH24W64rug\">中国企业数字人才发展白皮书</a>\"》。</p><p></p><h2>洞察与实践</h2><p></p><p></p><h4>“岗位”边界消失，技能将替代岗位</h4><p></p><p></p><p>根据<a href=\"https://www2.deloitte.com/cn/zh.html\">德勤</a>\"2023年全球人力资本趋势研究发现，企业正在失去传统的边界，这意味着他们熟悉的管理秩序将会逐渐消失，企业需要经过探索、试点和创新去定义管理的新法则。德勤中国管理咨询合伙人秦芹女士表示，面对众多挑战，人才建设将成为企业数字化转型最为核心的要素；而面对数字化转型带来的人才需求，企业不得不重新思考“人才从何而来、人才能力重塑”的问题。</p><p></p><p>秦芹重点围绕“组织”和“人”两个维度介绍了企业如何在“无边界世界”实现良性发展：一方面，企业必须构建能力型组织。随着“岗位”的边界消失，技能将替代岗位，成为员工和工作的连接点。对于企业而言，需要健全人才能力标签体系，从而更好的选人、识人、用人，最大化发挥员工价值。另一方面，企业也需要不断提升数字化人才能力，通过搭建数字化人才画像，实现能力和技术的共同提升。</p><p></p><h4>东亚银行（中国）有限公司数字化人才实践</h4><p></p><p></p><p>作为一家拥有百年历史的港资银行，<a href=\"https://www.hkbea.com.cn/PersonalBusiness/\">东亚银行</a>\"（中国）有限公司（以下简称“东亚中国”）于2021年全面启动数字化转型，并始终秉承数字发展，人才先行的理念，走出一条适合自己的数字化人才“认证+自培养”模式和路径，为银行持续输送具备数字化背景的业务骨干和管理人才。</p><p></p><p>据东亚中国行长助理李燕青女士在会上介绍，2021年，东亚中国构建了映射行内职级和岗位职责的数字化产品经理、数据分析、数据治理、数据工程四大序列，明确了集12大维度为一体的数字化专业人才的能力画像。2022年，又进一步推动数字化人才专业认证体系——“数赢”专业资格认证，面向全行符合数字化岗位背景的员工，推出“1+3”认证培养体系——即一套数字化人才晋升培养机制&nbsp;+&nbsp;三阶段资格认证。</p><p></p><p>同期，东亚中国还率先在外资银行推出“数赢”培训生DT计划，旨在通过建立“严筛选、精培养、持续陪伴、重实践”为一体的数字化复合型人才培养机制，优选数字化专业背景的应届生。</p><p></p><p>而围绕“认证+自培养”体系，过去一年多，东亚中国还构建并开展了包括“科技赋能月”系列、“融课堂数字化”系列、引入母行“Fintech&nbsp;101”课程、数赢杯赛一系列数字化文化普及活动，形成了从行管理层到行员对转型工作的高认可度和强共识性，极大程度地提升了数字化转型的效率。</p><p></p><h4>南京钢铁数字化人才实践</h4><p></p><p></p><p>当然，数字技术红利并没有止步于金融、互联网等这些数字原生基因更好的行业。如今，技术同样也在快速深入工业领域，推动制造业向高质量发展。</p><p></p><p><a href=\"http://www.njsteel.com.cn/\">南京钢铁</a>\"人才发展中心主任/高级经济师仲崇波表示，数字化人才是传统制造提质升级的关键因素，但是人才需求总量和缺口巨大，这也是摆在面前的实际挑战。为此，南京钢铁明确了“1+2+7”人力资源战略，致力于实现钢铁联合企业全球效能领先的目标，并据此思考数字化人岗匹配路径。</p><p></p><p>在这一战略目标指导下，南京钢铁构建了分类别、分阶段、分层级、全覆盖、精准培养的数字化人才培养体系，并绘制了名为“育龙计划”的人才发展地图。此外，南京钢铁还首创行业人力资源体系数字化序列，建立了数字化人才活水机制，通过构建职级对照体系，支撑数字化组织迭代进化。</p><p></p><h4>宁德核电数字化人才实践</h4><p></p><p></p><p>无独有偶，<a href=\"http://www.ndnp.com.cn/\">宁德核电</a>\"也是工业领域的数字化典型企业。自2021年至今，宁德核电的数字化从快速启动期迈进了关键转型期。中国广核集团福建宁德核电有限公司培训部经理、数字化转型组培训负责人徐锋涛强调，数字化转型一定要“转”，并且一定要按照自己的节奏“转”。而在这个过程中，数字化转型成功与否，与人才队伍建设密不可分。</p><p></p><p>徐锋涛在会上详细介绍了宁德核电的系统化培训方法（SAT），这套路径和方法覆盖从需求分析、大纲设计、材料开发到培训实施、效果评价五阶段，是宁德核电内部数字化人才梯队建设和人才培养规划非常重要的抓手。如今，宁德核电面向数字化，已经从战略、思维、执行三个层面梳理了11项人才能力维度，并且每个能力维度根据表现不同分为4个级别，从而构成了数字化人才胜任力模型。</p><p></p><h2>平台赋能与白皮书解读</h2><p></p><p></p><h4>用智能化手段重塑企业培训</h4><p></p><p></p><p>除了依赖内部的人才培养，越来越多的企业也在借助外部平台，加强和完善人才体系建设。</p><p></p><p>在极客邦科技联合创始人、<a href=\"https://b.geekbang.org/?utm_source=geektimeWeb&amp;utm_medium=menu&amp;utm_campaign=entranceplatform&amp;gk_source=2021090101_geektimeweb_menu\">极客时间企业学习服务</a>\"总经理司巧蕾女士看来，“以人为本”是数字人才培养的基本出发点。随着AI的持续发展，人工智能在教育领域的渗透程度越来越深入，这同样带来了学习场景的重塑。为此，极客时间也紧跟技术趋势，结合行业洞察，对好产品、好内容和好服务做了全面升级，利用智能化力量提高企业学习培训效率，加强企业综合竞争力。</p><p></p><p>以产品为例，极客时间聚焦平台功能，对定制岗位能力模型、AI测评、智能学习路径、AI学习助手、智能学习报告、AI制课六个方面进行了持续升级，打造面向全新的学习培训体验，致力于以AI赋能企业培训，助力数字人才发展提质增效。</p><p></p><p>以内容为例，极客时间还推出了一系列AIGC相关的课程和行动营，通过理论+实践的内容实现学习培训的闭环。上新的课程采取极客时间一贯坚持的PGC内容生产模式，邀请一线技术专家与极客时间的专业教研团队一起通过稳定、可复制的内容设计生产流程，打磨体系化精品课程。</p><p></p><h4>《中国企业数字人才发展白皮书》深度解读</h4><p></p><p></p><p>在风云变幻的数字时代浪潮下，极客邦科技始终保持着对市场的敏锐洞察。面向人才发展，极客时间企业版还于日前与培训杂志联合推出了《中国企业数字人才发展白皮书》。</p><p></p><p>极客邦科技内容总监、极客邦双数研究院首席研究员李佳女士表示，本白皮书研究了国内关于数字化和数字化人才发展的众多报告，并对近二十家企业进行了深入的访谈调研，收录了一批典型企业的数字化人才发展案例。从生态、成长和赋能的角度讨论中国企业的数字化人才发展，是这份白皮书最重要的特点。</p><p></p><p>首先，白皮书指出，产业集群数字化转型呈现出数字经济平台化生态化特征，而数字人才在生态中分层分布并保持流动的状态，数字化人才服务的平台化生态，将极大促进产业与人才融合发展；</p><p></p><p>其次，聚焦人才问题，白皮书指出，技术发展使得应用性人才培养更为便利，数字化领导人才是数字化转型的关键因素，复合型创新人才的市场需求也日趋明显；</p><p></p><p>此外，白皮书还强调，企业内平台化赋能已经成为数字化人才发展重要趋势，平台型企业建设使得数字人才赋能生态动力更强，数字化人才发展的自主性也更强。</p><p></p><p>基于这些趋势和观察，白皮书的最后还分类讨论了不同企业人才发展的重点和路径，并提出了数字化人才发展的七条建议。</p><p></p><h2>数智升级是每个人的课题</h2><p></p><p></p><p>总而言之，数字化转型的关键在于人，而不只是技术本身。如司巧蕾在演讲中所说，人才是数字化转型和应用的基石，数字人才培养的目标，是培养具有数字思维和数字技能的高素质人才，以满足企业数字化转型和发展的需求。</p><p></p><p>在这个过程中，数智升级不仅是企业的迫切需求，也是每一个人在这个时代必须要面对的问题。每个人都需要通过不断学习和自我提升，跟上时代的步伐，拥抱新技术，适应新的工作模式，以实现自身和组织的持续蝶变。</p><p></p><h4>&gt;&gt;&gt;&nbsp;福利通道</h4><p></p><p>扫描下图二维码即可领取《中国企业数字化人才发展白皮书》完整版</p><p><img src=\"https://static001.geekbang.org/infoq/50/500a368d20bda76142442a8a2da197e6.png\" /></p><p></p><p>关注「InfoQ数字化经纬」公众号，&nbsp;“追更”DTDS&nbsp;全球数字人才发展线上峰会完整演讲内容</p><p><img src=\"https://static001.infoq.cn/resource/image/d3/da/d31d4e0e474feb853493fb404102b3da.png\" /></p><p></p>",
    "publish_time": "2023-05-31 10:32:28",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "天翼云重磅发布AccessOne，为企业打造安全加速一体化服务",
    "url": "https://www.infoq.cn/article/zvVv1rgg6vLz8qeItxGB",
    "summary": "<p>5月30全国科技工作者日，以“连接世界从边缘开始”为主题的天翼云边缘安全加速平台发布会在线上顺利举办。会上，天翼云重磅发布边缘安全加速平台AccessOne（后称AccessOne），并深入介绍了产品四大能力，以及在教育行业的实践成果，为企业提供性能、安全、算力等满足不同场景需求的智能边缘网络。</p><p></p><h2>应对多重网络应用挑战，一体化服务成优先选择</h2><p></p><p></p><p>数字化转型进程中，新型产业在改善人们生活质量的同时，也对网络应用服务提出挑战。天翼云智能边缘事业部副总经理鄢智勇指出，首先，越来越多的数据和应用需在离数据源更近的位置进行实时处理和分析，满足对低延迟和高带宽的需求。其次，诸多企业应用程序可能分布在多云环境，安全防护也随之变得更加复杂。另外，全球化时代，企业更关注业务在全球范围内的可用性，并采取各种措施确保业务数据高速传输和处理。最后，攻击手段日益成熟、攻击范围不断扩大等变化，让传统网络和安全模型逐渐式微，产业亟需新的网络和安全模型来应对业务变化。</p><p></p><p>一体化解决方案以一体化平台实现工作组件间的紧密协作，构建更流畅、更高效的工作流程，简化了企业选择和部署过程，减少集成和交互操作挑战，成为企业应对多重网络应用挑战的优先之选。</p><p></p><p>AccessOne依托中国电信分布式边缘资源，基于CDN底座，将云原生安全能力注入分布式边缘节点，实现网络底层对性能、安全、算力原子能力编排，并以“安全与加速、零信任、边缘接入、开发者平台”四大产品能力，一站式响应客户加速与防护需求，助力政企轻松管理自身业务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a5/a55726c5b26776294ea8cd8d702e4766.png\" /></p><p></p><p></p><h2>AccessOne四大产品能力，助力企业轻松制胜边缘</h2><p></p><p></p><p>安全与加速能力方面，AccessOne将已有产品能力聚合在一起，并做了两方面升级。一是全球边缘节点全面升级，全球节点达到1800+。AccessOne通过多项技术实现静态内容就近交付及动态内容快速回源，显著提升源站性能。二是推动DDoS防护、Web防护、Bot防护等安全原子能力下沉边缘，在最靠近攻击发起的位置进行检测，将正常、安全的流量回源到服务器，避免网站服务器被恶意入侵，保障业务核心数据安全。</p><p></p><p>为了在不可信网络中构建信任的安全系统，AccessOne推出零信任服务，基于零信任安全理念和架构，依托天翼云边缘节点，以身份认证与动态评估为基础，打造全新的企业安全远程访问能力，提供更安全、便捷、统一的接入服务。通过零信任控制面服务，天翼云助力客户有效进行统一管控、策略下发，实现身份可信、设备可信和行为可信；通过零信任数据面服务，天翼云可为客户提供包括智能选路、解除安全威胁的全方位保障。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0a/0a9a41bf56d4875561109d6ade59af40.png\" /></p><p></p><p>全球化趋势下，越来越多的企业开始在海外市场拓展业务，如何使全球用户获得一致性网络访问体验及安全保障成为巨大挑战。AccessOne边缘接入服务通过多样、灵活的接入方式，可将任意用户请求安全接入至边缘网络的三网节点，实现全球范围内高速、稳定、安全的数据传输。</p><p></p><p>为助力客户加快业务上线时间，减轻研发人员负担，AccessOne推出开发者平台，提供易上手的开发者工具，丰富的编程语言生态，符合W3C标准的Service Worker API、Streams API、WebCrypto，可读可写、全球同步的边缘存储，帮助企业网站在边缘节点上完成自定义鉴权、访问控制、内容改写、内容生成以及AB测试。企业研发人员在使用开发者平台部署业务时，可彻底免去底层机器的运维和管理，极大地释放了人力成本。</p><p></p><h2>加速实践落地，天翼云赋能千行百业快速安全发展</h2><p></p><p></p><p>目前，AccessOne已成功应用在政务、金融、教育、游戏、电商等多个行业，在帮助用户高效应对网络攻击、保障业务零中断的同时，为办公应用提速增效。尤其在教育行业，AccessOne基于四大能力，一站式满足教育行业对于网站高可用、远程办公学习、跨境加速等不同场景的需求。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/08/08da2de8f68fb140dbfcb31551d45ca3.png\" /></p><p></p><p>以AccessOne在教育行业考试季应用为例，为帮助考试院、高校网络缓解访问压力，AccessOne通过动、静态加速能力减少回源访问量，大大提升了网站访问体验。天翼云要客行业中心总经理王晓东介绍，AccessOne可根据需求动态扩容，当某个应用节点故障时，快速将流量转移到其他节点上，保证服务的可靠性和稳定性。同时，考务查询、成绩查询涉及大量客户个人数据，在AccessOne平台上开启DDoS、WAF防护功能，可有效应对大流量攻击，保障客户数据安全。此外，AccessOne还适用于攻防演练、IPv6改造等场景，以完善的服务为教育行业的数字化转型注智赋能。</p><p></p><p>数字经济发展浪潮下，边缘业务规模激增，提升边缘侧应用与服务的稳定性、安全性成为企业实现繁荣发展的重中之重。面向未来，天翼云将不断优化自身技术实力，以更加安全、完善、经济的解决方案，持续助力客户应对多元业务需求和安全压力，携手共同制胜边缘，推动万物互联的时代早日来临。</p><p>&nbsp;</p>",
    "publish_time": "2023-05-31 11:06:34",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "字少事大！OpenAI 创始人等超350名大牛再签联名信，一句话声明简短有力：AI或引发灭绝风险",
    "url": "https://www.infoq.cn/article/ARJEOOh2M5oAmwRCpzfk",
    "summary": "<p></p><blockquote>应该像对待包括流行病和核战争等其他全球性迫切社会问题一样，缓解AI引发的灭绝性风险。</blockquote><p></p><p></p><h2>全球AI大牛又签署一封公开信</h2><p></p><p>本周二，人工智能安全中心（CAIS）发布了一份由OpenAI及DeepMind高管、图灵奖获得者及其他AI研究人员签署的简短声明，警告称他们的毕生成果可能会毁灭全人类。</p><p></p><p>CAIS表示，这份声明希望讨论“AI所带来的广泛且紧迫的风险”。</p><p></p><p>正所谓字越少、事情越大，声明内容只有一句：“应该像对待包括流行病和核战争等其他全球性迫切社会问题一样，缓解AI引发的灭绝性风险。”</p><p></p><p>在声明上签字的名人包括图灵奖获得者Geoffery Hinton和Yoshua Bengio、OpenAI CEO Sam Altman、OpenAI首席科学家Ilya Sutskever、OpenAI首席技术官Mira Murati、DeepMind CEO Demis Hassabis、Anthropic CEO Dario Amodei，以及来自加州大学伯克利分校、斯坦福大学和麻省理工学院的多位教授， 据悉，目前约超过 350 名从事人工智能工作的高管、研究人员和工程师签署了这份公开信。</p><p></p><p>作为风口浪尖上的人物，声明发表之际OpenAI掌门人Altman正访问全球，与各国元首就AI及其潜在风险展开讨论。5月初，Altman还参与了美国参议院关于AI行业的监管听证。</p><p></p><p>这份关于AI风险的模糊声明，很快激起了反对者的批评。</p><p></p><p>从内容上看，这份声明没有对AI做出确切定义、也没有提及要如何缓解灭绝风险，只是将这项工作放在了与其他全球性社会问题相同的高度。</p><p></p><p>但在另一份新闻稿中，CAIS进一步强调希望“设置护栏并建立相关机构，确保AI风险不会让人类措手不及。”</p><p></p><h2>2个月前，马斯克等人呼吁叫停AI研发</h2><p></p><p>2个月前，AI 领域数十人共同署名、科技富豪马斯克高调参与的一封公开信震惊世界。</p><p></p><p>今年3 月 22 日，生命未来研究所（Future of Life）向全社会发布了一封《暂停大型人工智能研究》的公开信，呼吁所有人工智能实验室立即暂停比GPT-4更强大的人工智能系统的训练，暂停时间至少为 6 个月。</p><p></p><p>马斯克、图灵奖得主 Yoshua Bengio、苹果联合创始人 Steve Wozniak、Stability AI 创始人兼CEO Emad Mostaque、DeepMind 高级研究科学家 Zachary Kenton、AI 重量级人物 Yoshua Bengio（通常被称为“AI 教父”之一）和该领域研究的先驱 Stuart Russell等上千名科技大佬和 AI 专家已经签署公开信。</p><p></p><p>公开信中提到，通过广泛研究和顶级 AI 实验室的调查认可，具备类人智能的 AI 系统很可能对社会和人类构成深远风险。正如广受推崇的阿西洛马 AI 原则中所述，高级 AI 可能代表着地球生命史上一场影响深远的变化，应给予相应的关注和资源进行规划和管理。但遗憾的是，我们并没有看到这种级别的规划和管理。最近几个月来，AI 实验室陷入了一场失控般的技术竞赛，全力开发和部署一颗颗愈发强大的“数字大脑”，但就连创造者自己都无法理解、预测或可靠地加以控制。</p><p></p><p>公开信认为，这种暂停应当对外公开且可加验证，涵盖所有关键参与者。如果未能迅速实施暂停，政府应介入并强制要求其暂停。各 AI 实验室和独立专家则应把握这次暂停，共同开发和实施一套用于高级 AI 设计和开发的共享安全协议，并由外部独立专家进行严格审计与监督。这些协议应确保依其构建的系统具备无可置疑的安全性。AI 研究和开发工作应当集中注意力，努力让目前最强大、最先进的系统变得更准确、更安全、更可解释、更透明、更稳健、更一致，也更加忠诚且值得信赖。与此同时，AI 开发商必须与立法机构合作，加快开发出强大的 AI 治理体制。</p><p></p><p>通过这封公开信可以看出，人们想要叫停更先进的AI系统的研发，无非是担心在缺乏有效监管的情况下，AI发展太快会为人类社会带来一系列潜在隐患和危险。更重要的是，AI太过强大了，发展到一定成程度时甚至人类都无法掌控它。</p><p></p><h2>AI伦理专家：并不Care这类警告AI风险的公开信</h2><p></p><p>但，长期关注AI伦理问题的专家，对这类公开信根本不感兴趣。</p><p></p><p>Hugging Face公司机器学习研究科学家Sasha Luccioni博士觉得CAIS的这封信如同儿戏：“首先，声明把AI的假想风险跟流行病和气候变化等现实威胁混为一谈，这只会扰乱公众的基本判断。这同时也是一种误导，只要把公众的注意力吸引到未来风险上，他们就会忽略当前的更多有形风险，比如AI偏见、法律纠纷和同意权等。”</p><p></p><p>作家兼未来学家Daniel Jeffries也发推称，“AI的风险和危害如今成了一种表明立场的游戏，每个人都想在这波风潮下扮演好人……问题是这么吵来吵去有用吗？看着挺好，但没人真正付出，完全是在浪费时间。”</p><p></p><p>CAIS是总部位于旧金山的非营利组织，目标是通过技术研究和宣传“减少AI引发的规模化社会风险”。其联合创始人之一Dan Hendrycks拥有加州大学伯克利分校的计算机科学博士学位，之前还曾在DeepMind实习。另一位联合创始人Oliver Zhang也时常在LessWrong论坛上发表关于AI安全的帖子。</p><p></p><p>在机器学习领域，一部分AI安全研究者总是担心比人类更聪明的超级AI将很快出现、脱离约束，要么控制人类文明、要么彻底消灭人类文明。**作为目前这波AI浪潮的发起者，OpenAI的基础安全工作也是围绕着这种“AGI”（通用人工智能）焦虑而展开。**换言之，AI末日论在科技行业中已经颇有市场。</p><p></p><p>但也有不少人觉得，签署这样一封内容含糊的公开信没有任何意义，无非就是让从业者们减轻一点内心深处的道德压力。Luccioni强调，“这群创造出AI技术的人参与声明，无非是给自己博取了个好名声。”</p><p></p><p>这里澄清一点，Luccioni和她的同事们并非认定AI毫无危害，而是觉得重点考虑未来的假想风险会让人们忽略目前客观存在的AI负面影响。这些影响正在带来棘手的道德难题，而科技巨头们却无视威胁、大肆出售相关产品。</p><p></p><p>Hugging Face首席伦理科学家Margaret Mitchell认为，“某些弱势群体已经因此受到伤害：基于AI的监控系统正强迫伊朗女性保持传统穿着，甚至对某些群体施以监视和软禁。”</p><p></p><p>尽管有朝一日，某种形式的先进AI也许确实会威胁到全人类，但批评者们认为2023年讨论这个问题还为时过早、不可能带来建设性的帮助。对于尚不存在的问题，如何开展研究？</p><p></p><p>Jeffries也发推重申了这一观点，“AI远期风险是种不切实际的幻想，我们无法解决并不存在的问题。这完全是在浪费时间，我们应当集中精力解决当下的问题，未来的事就交给未来去办。”</p><p></p><h2>AI“教父”Yoshua Bengio放话：面对毕生工作成果，我也很“迷茫”</h2><p></p><p>近日，在这封最新的公开信上签名的AI大牛科学家，Yoshua Bengio在接受采访中坦言，他开始对自己这一辈子的工作成果感到“迷茫”。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/88/88dabc234eada3d1459d3653bebd5f0b.png\" /></p><p></p><p>作为AI三大“教父”之一，他在该领域做出了不少开创性的贡献。而AI的发展方向和惊人速度正引发他的忧虑。Bengio教授表示自己曾经出于认同感而投身其中，但如今的状况却让他困惑不已。</p><p></p><p>“从情感上讲，身处AI领域内部的人们肯定都受到了冲击。“迷茫是真的，但我们还是得继续前进，必须参与其中、加入讨论、鼓励他人和自己一同思考。”</p><p></p><p>这位加拿大学者最近签署了两份声明，敦促对AI的未来风险保持谨慎态度。部分学者和行业专家已经发出警告，称AI发展过快可能导致这项技术被恶意人士滥用。即使抛开这一层，AI自身也有可能引发恶劣影响。</p><p></p><p>Bengio教授也加入了AI监管的行列，并表示他个人认为不该把AI的能力给予军方。Bengio教授认为，一切构建强AI产品的企业都应当注册报备。</p><p></p><p>“政府需要跟踪这些企业的活动，对工作内容展开审计，对AI产业起码也要像飞机、汽车或制药等领域一样施加监管。”</p><p></p><p>“我们还需要推动AI相关人员的资质认证……包括道德培训。大家可能不知道，计算机科学家很少能接触到这方面知识。”</p><p></p><h2>Geoffrey Hinton：曾表示痛悔毕生工作</h2><p></p><p>另一位AI“教父”Geoffrey Hinton博士也签署了Bengio教授参与的声明。</p><p></p><p>本月月初，有外媒报道称， Geoffrey Hinton 辞去了在谷歌的工作，并警告这一技术领域的持续发展或将带来巨大风险。</p><p></p><p>Geoffrey Hinton 作为“三位 AI 教父”之一，与另外两位合作伙伴共同获得了 2018 年图灵奖，旨在表彰他们为当前 AI 繁荣做出的基础性贡献。但如今的他却对自己投入一生的研究感到遗憾。</p><p></p><p>根据《纽约时报》对他的采访，Hinton在辞去在谷歌的工作，也终于可以畅谈 AI 技术背后的风险了。已经在谷歌工作十多年的 Hinton 表示，“我总在用这样的借口安慰自己：哪怕我自己不做，其他人也会这样做。但目前真的不知道要怎么防止坏蛋利用 AI 来作恶。”</p><p></p><p>虚假信息的传播只是 Hinton 眼下想要强调的风险之一。从长远来看，他担心 AI 会彻底消除一切需要大量记忆的工作，而随着其逐步编写并运行构成自身的代码，AI 也许会最终取代人类。</p><p></p><p>Hinton 在采访中指出，“其实不少人都相信，AI 实际上能够变得比人类更聪明，但大多数人认为这还很遥远。没错，我也曾经觉得还很遥远，没准要再过 30 年、50 年甚至更久。但现在，我显然没法再这么想了。”</p><p></p><p>在接受 BBC 采访时，他甚至提到 AI 聊天机器人已经构成“相当可怕”的威胁。&nbsp;“据我所知，目前的 IT 还不比我们聪明，但我相信它们很快就会超越人类。”</p><p></p><h2>不一样的声音：Yann LeCun对AI发展比较乐观</h2><p></p><p>不过AI领域也有不一样的声音存在。</p><p></p><p>第三位“教父”Yann LeCun与Bengio和Hinton共同凭借开创性贡献获得了图灵奖，但他的态度比较乐观，认为AI毁灭人类的警告有点言过其实。</p><p></p><p>还有人觉得在务虚讨论之前，应当先解决迫在眉睫的真问题。</p><p></p><p>AI公司Huggingface研究科学家Sasha Luccioni博士认为，社会应该关注AI偏见、预测性执法和聊天机器人传播错误信息等问题，她觉得这些都是“非常具体的现实危害”。</p><p></p><p>“我们应当关注这些问题，而不是深陷AI可能毁灭人类的假想泥潭。”</p><p></p><p>除了风险，AI也确实给人类社会带来不少福祉。上周，AI工具就发现了一种新型抗生素。而借助AI技术开发的微芯片，也让一名瘫痪男子能在意念控制下正常行走。</p><p></p><p>但好消息再多，也无法抵消人们对AI冲击各国经济的深远担忧。众多企业已经开始用AI工具取代人类员工，好莱坞编剧正就这个问题组织集体罢工。</p><p></p><p>Bengio教授在谈到AI现状时认为，“亡羊补牢，为时未晚。这就像应对气候变化问题一样。我们向大气排放了大量的碳，虽然不可能一夜之间就停止排放，但我们至少该认真想想当下能够做点什么。”</p><p></p><p>参考链接：</p><p></p><p><a href=\"https://www.bbc.com/news/technology-65760449?at_medium=RSS&amp;at_campaign=KARANGA\">https://www.bbc.com/news/technology-65760449?at_medium=RSS&amp;at_campaign=KARANGA</a>\"</p><p></p><p><a href=\"https://arstechnica.com/information-technology/2023/05/openai-execs-warn-of-risk-of-extinction-from-artificial-intelligence-in-new-open-letter/\">https://arstechnica.com/information-technology/2023/05/openai-execs-warn-of-risk-of-extinction-from-artificial-intelligence-in-new-open-letter/</a>\"</p><p></p><p><a href=\"https://www.infoq.cn/article/Y9rIogQk8Sjt33bLDMHk\">https://www.infoq.cn/article/Y9rIogQk8Sjt33bLDMHk</a>\"</p>",
    "publish_time": "2023-05-31 14:17:48",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "后CentOS时代，国产操作系统能否扛起大旗？",
    "url": "https://www.infoq.cn/article/zI9eP1qgSd6a1ALmXMrU",
    "summary": "<p>2020 年 12 月，CentOS 社区宣布 CentOS 服务器操作系统 8 和 7 系列分别于 2021 年底和 2024 年 6 月底停止服务。CentOS 停服对于国产操作系统而言，既有挑战，也有机遇。一方面，如何为国内用户提供 CentOS 停服之后的解决方案，平稳完成服务器操作系统和数据的迁徙是国内操作系统厂商必须要解决的难题；另一方面，CentOS 停服也有望加速国产服务器操作系统替代进程。</p><p>&nbsp;</p><p>那么，CentOS 的停服到底会带来哪些影响？国产操作系统能否扛起时代大旗？如何迁移到国产操作系统？近日，InfoQ《极客有约》邀请到了龙蜥社区产品生态总监张鹏程，为大家分享国产操作系统迁移实践经验。</p><p>&nbsp;</p><p>以下为访谈实录，完整视频参看：<a href=\"https://www.infoq.cn/video/li7m8YayKpF8iVACRoB6\">https://www.infoq.cn/video/li7m8YayKpF8iVACRoB6</a>\"</p><p></p><h2>云计算给操作系统带来了哪些改变？</h2><p></p><p>&nbsp;</p><p>姜雨生：近几年，国内外操作系统整体发展如何？有哪些值得关注的行业大事件？</p><p>&nbsp;</p><p>张鹏程：经过几十年的发展，<a href=\"https://www.infoq.cn/article/4lDxHRoqXbSw6zl29AEo\">操作系统</a>\"已成为一个相对成熟的产业领域。大家对桌面端常用的操作系统如Windows、macOS非常熟悉。在服务器端，Linux具有开源和免费的特性，广泛应用于服务器操作系统。</p><p>&nbsp;</p><p>由于我们今天的话题主要涉及服务器操作系统，因此我们将聚焦在近年来国际和国内两方面，讨论其中的标志性事件和发展趋势。首先看国际方面，最典型的标志性事件是Red Hat公司在2021年和2024年停止维护CentOS 8和CentOS 7的版本，并转向CentOS Stream作为上游版本。这意味着之前基于CentOS的企业级生态系统将受到重大影响，这是一个非常典型的国际标志事件。</p><p>&nbsp;</p><p>接下来，我想谈一下发展趋势。从十多年前云计算的兴起开始，经过了持续的发展，云计算已逐渐成熟。这种发展浪潮给操作系统领域带来了一种“降维打击”的趋势。一个典型例子是亚马逊在其云计算平台上提供的Amazon Linux，对红帽等操作系统市场地位造成了巨大冲击，形成了颠覆性效果。微软也将其Windows部门转移到了Azure云平台，这有助于操作系统技术在云上的演进和推广。这是过去几年持续发酵的产业发展趋势，国际上值得关注。</p><p>&nbsp;</p><p>国内方面，一个标志性事件是从2019年开始，国家产业主管部门组织了针对操作系统领域的原生开源社区的重大专项活动。随后，欧拉社区和龙蜥社区相继诞生。这一系列事件标志着国内在自主操作系统演进方面迈出了重要步伐，对国产操作系统的发展和应用推广非常有帮助。此外，在国内除了前面提到的云计算蓬勃发展外，围绕国产化的生态系统也是我们必须关注的发展趋势，这促使更广泛的自主创新，相信这对操作系统发展将产生深远影响。</p><p></p><h2>CentOS停服给国产操作系统带来的挑战与机遇</h2><p></p><p>&nbsp;</p><p>姜雨生：CentOS 是比较流行的 Linux 发行版之一，2020 年 12 月，CentOS 社区宣布 CentOS 服务器操作系统 8 和 7 系列分别于 2021 年底和 2024 年 6 月底停止服务。随着 CentOS 系列版本停服时间临近，现有 CentOS 以及衍生版用户会面临哪些风险？</p><p>&nbsp;</p><p>张鹏程：这个问题可能已经成为一个正在发生的状态。尽管CentOS 8用户群规模可能相对小于CentOS 7，但 CentOS 8 在2021年12月底已停止维护。对于CentOS 8 或者截止到2024年的CentOS 7，它们都将直接受到影响。随着社区停止服务，所有正在运行的版本在截止日期后将不再获得任何问题修复或升级维护。</p><p>&nbsp;</p><p>对于广泛使用存量运行 CentOS 系统的用户而言，这样的事实可能带来连带影响。如果系统因为一些 bug 导致不稳定、宕机甚至不可用的情况，很难获得及时修复。同时，由于潜在的安全漏洞没有及时修复，这些漏洞可能对使用 CentOS 的用户，特别是企业用户的系统安全和数据安全构成重大威胁。此外，许多用户由于商业需求而使用商业发行版本，但这些商业发行版本在过去的发展过程中也是基于 CentOS 演进而来。因此，CentOS 的停止维护因素可能间接导致一些依赖于 CentOS 的商业发行版本很难进行后续演进，这对使用者也会产生连带影响。</p><p>&nbsp;</p><p>姜雨生：CentOS 有广泛的行业用户基础，停服将导致操作系统迁移浪潮。有声音认为，CentOS 停服对于国产操作系统而言，既有挑战，也有机遇，请您分别谈谈其中的挑战与机遇？</p><p>&nbsp;</p><p>张鹏程：这个机遇和挑战，我认为可以看作是两面的。就像我们之前讨论的，它既包含挑战，也蕴藏着机遇。对于操作系统而言，一个非常核心的问题是操作系统的生态系统。因此，在我看来，最大的挑战和机遇都可能在于这个生态系统中。</p><p>&nbsp;</p><p>生态系统带来的挑战是我们现在使用的操作系统和相关的成熟硬件体系，以及上游的数据库、中间件和各种企业应用软件，大部分都是在欧美市场环境下经过数十年成熟发展和不断迭代形成的。在这个发展过程中，软硬件体系相互适配、优化和促进是相互融合的。在这个层面上，现在出现了一些风险和停服的迹象。如果要解决操作系统的替代方案，这个替代操作系统必须解决如何与国外成熟发展的软硬件软件生态系统良好兼容的问题。对于国内操作系统的发展来说，这是一个巨大的挑战，因为我们是在追赶的位置上。在这个过程中，还有许多非技术因素会直接产生影响。我相信这是我们国内从业者共同面临的问题，大家都在努力不断完善和解决。</p><p>&nbsp;</p><p>同时，我认为这个过程中也有很多机会，因为我们正处在一个发展浪潮中，这个浪潮带来了许多新的机会，影响着发展的变化。正如之前提到的，不论是云计算的发展还是国内自主创新的软硬件生态发展，都意味着在国内的许多行业领域，企业在解决自身发展问题的同时，考虑如何进行IT架构或技术升级来给业务产生更大的收益。我们现在有更多选择，可以使用创新的云生态系统以及国内产生的芯片、数据库和应用软件等，这些都构成了国内独特的生态系统。这些发展也是我们共同面临的机遇，因为在这个过程中，我们不再仅仅进行“苹果与苹果”的简单比较，而是在进行系统与系统的比较。国内伴随着我们快速发展和强大需求的机遇，可以帮助我们将上下游合作伙伴联合起来。通过在更广泛的应用领域中锤炼，我们能更快地使国内建立起的生态系统更加成熟。</p><p>&nbsp;</p><p>姜雨生：民生证券研究报告称，国内整体 CentOS 存量替代空间有望达到 148 亿元，这个数字符合您的预估吗？目前国内主要是哪些行业有操作系统迁移替换需求？迁移的主要原因是什么？</p><p>&nbsp;</p><p>张鹏程：这个问题可以从两个方面来看。您刚才提到的第一个方面可能是关于市场空间的判断。我认为不同机构或不同视角可能对统计口径有所差异。所以这个数字本身很难直接判断对错，它只是一个相对的指标，但确实能提供一些见解。判断服务器操作系统的市场规模，我们还可以参考服务器规模，每年国内的物理服务器出货量是一个相对确定且得到共识的数字。过去几年的情况，每年大约有300～400万台的服务器出货量。</p><p>&nbsp;</p><p>这么多年来，在操作系统领域中，CentOS一直处于主导地位。因此，国内物理服务器的使用规模至少应该达到百万级别，每年的存量不断累积。此外，考虑到过去5～10年，国内云计算从虚拟化发展到云计算，以及众多的虚拟机和类似容器的使用环境，综合考虑这些物理机、虚拟机甚至容器的部署规模，至少达到千万级别。如果将部署规模转化为市场空间，一部分将直接对应各种操作系统选项，包括免费社区发行版的发展，同时也会有商业选项。</p><p>&nbsp;</p><p>对于某些企业客户来说，根据他们的发展角度，仍然需要商业服务来支持他们。这些需求将产生对操作系统的消费，对应到之前提到的千万级别的规模。因此，就整个市场规模而言，我相信超过百亿是一个发展趋势，也是整个行业共识。所以对于整个产业的从业者来说，这可能是一个相对确定性的发展机遇，他们都面临着这个机遇。</p><p>&nbsp;</p><p>刚才您也提到国内的需求。我们看到在各行各业中都广泛应用国内的服务器。根据使用规模，我们可以从中看到一些端倪。当我分析我们操作系统的用户需求时，包括不同行业的发展时，我习惯使用象限来进行分解。纵轴可以定义为业务对服务器或操作系统使用的影响程度，而横轴则可能对应不同行业领域的部署规模，根据相应行业的整体经济规模或企业数量来确定，这些因素可能决定了消耗的规模。</p><p>&nbsp;</p><p>根据这个象限的观察，最典型的需求来源可能体现在政务、金融、电信、能源以及教育和医疗等行业。这些行业在服务器和IT资源的消耗方面都属于前几类，而且它们的业务连续性直接关系到日常的国计民生。在这些领域，我相信替代CentOS的需求非常高，因为它们影响到业务的连续运行，也影响到它们所提供的广泛经济活动的服务。因此，这些行业迫切希望能有良好的迁移替代选项。另外，还有一大部分服务器消费量来自互联网行业。由于互联网行业在架构演进过程中更多地采用分布式架构，同时在操作系统层面上有更多的替代选项，因此它们对替代的需求可能不会那么强烈。</p><p>&nbsp;</p><p>综上所述，国内市场的机会可以从不同方面来看。从市场规模的角度，超过百亿是一个发展趋势。而从需求的角度来看，政务、金融、电信、能源以及教育和医疗等行业对替代操作系统的需求非常高。同时，互联网行业也是一个重要的消费者群体，尽管对替代需求的迫切性可能相对较低。</p><p>&nbsp;</p><p>姜雨生：有观众提问说，在教育行业的操作系统，我们目前替换的需求量如何？</p><p>&nbsp;</p><p>张鹏程：在教育行业中，我们面临着一个庞大的存量规模。与电信、金融和能源等行业相比，教育行业的存量规模仅次于它们，属于高度使用的行业。在过去的两年多里，我们通过社区工作发现了许多教育机构的需求，包括大众院校和教职机构。这些机构都关注如何解决CentOS停服替换的问题。</p><p>&nbsp;</p><p>第一类需求比较直接，原本使用的服务器数量并不是特别多，可能总共只有一两百台。它们通常使用的是免费的社区版本，例如CentOS。针对这些需求，龙蜥提供了对应版本的操作系统升级，以确保其与学校原先使用的许多软件的兼容性。同时，龙蜥还提供了一些迁移工具，帮助用户进行原地升级迁移，或者在有冗余资源的情况下进行升级替换，以便更好地完成CentOS替换。</p><p>&nbsp;</p><p>另一类需求是顺应当前发展趋势产生的新需求。我们注意到一些大学近年来正在构建智能计算平台，以解决其内部现有IT资源池的问题，并在科研方向上实现更多的智能化能力。这种方式更适用于规模较大、具有规模效应的大学。在这种情况下，在解决CentOS替换的同时，考虑搭建智能计算平台，通过云化方式提供内部使用，并满足科研需求。通过搭建新平台的方式，他们可以一举两得，随着新项目的发展，解决了CentOS停服可能带来的威胁。</p><p>&nbsp;</p><p>这两种案例是教育行业用户前进发展的典型代表。一方面，我们满足了那些使用规模较小的学校的需求，通过升级替代的方式帮助他们迁移问题。另一方面，对于规模较大、有新业务方向或科研规划的大学，我们支持他们搭建新平台来替代原有的老资源，从而解决CentOS替换的问题，并顺应其业务发展方向。</p><p></p><h2>如何进行操作系统迁移？</h2><p></p><p>&nbsp;</p><p>姜雨生：在迁移过程中，我们提到了从旧系统到新系统的替代过程。我个人在之前的工作中也做过很多与监控相关的系统，但是对于更底层的操作系统内容，特别是在物理机或云Kubernetes环境中，我确实没有完全接触过。服务器操作系统的迁移并不是简单的重新安装系统，还需要对操作系统及其搭载的应用软件和业务系统进行替代、适配、迁移和重构等，一套完整的迁移方案应该包括哪些步骤？</p><p>&nbsp;</p><p>张鹏程：我想首先回应一下您刚才提出的问题。您提到了在使用Kubernetes等技术时，对操作系统的感知和维护方面可能比较低。这确实是一个事实，而且代表了我们共同面临的发展趋势。随着云原生技术的普及，操作系统在与上层应用的耦合性方面正在降低。这种分层解耦有利于降低维护成本并提高大规模应用的易用性。</p><p>&nbsp;</p><p>在现实世界中，很多用户目前仍然主要使用物理机的操作环境。如果已经使用虚拟机，那对于后续的维护可能已经有所帮助。对于这些物理机或虚拟机形态的主机，迁移过程需要考虑更多因素，特别是硬件和软件对操作系统兼容性的影响。</p><p>&nbsp;</p><p>通常，在进行迁移之前，我们先需要进行评估，包括对操作系统和相关软硬件环境的评估，以及可能需要进行的兼容性适配。第二步，如果涉及硬件环境的变化，或者软件版本的升级，可能需要进行跨架构迁移的兼容性适配。例如，从x86架构转向ARM架构，或者操作系统版本升级，这些都可能需要考虑应用的兼容性适配。第三步是对原有环境进行备份，这对于任何迁移操作都是必要的保障。第四步是正式进行迁移实施。在具体的迁移实施过程中，通常有以下两种典型的操作步骤。</p><p>第一种是原地升级，即在原有环境下重启和升级操作系统，使其能够继续正常运行。这种方式对兼容性要求较高，而且需要进行充分的前期测试。第二种方式是轮转升级，这可以借助集群化管理或主备集群的形式实现。我们可以先将新版本安装部署在备用节点或新增节点上，并确保应用在该环境下能够正常运行。然后，在集群调度和管控层面逐渐将旧节点下线，并将其作为新节点逐步升级和重新安装。</p><p>&nbsp;</p><p>迁移实施完成后，最后一步是进行必要的验证，并结合操作系统或软硬件环境的变化进行必要的优化。</p><p>&nbsp;</p><p>通过上述五步骤流程，我们能够尽可能应对每个操作系统所在环境中可能出现的风险，并制定相应的方案。</p><p>&nbsp;</p><p>姜雨生：您提到了在迁移过程中涉及到主备切换的问题。在实际操作中，我们可能会先升级备份集群，然后需要确保备份环境可以接收流量或承担服务的运行，同时进行指标监控。我们是在这个过程中进行直接做切换操作吗？</p><p>&nbsp;</p><p>张鹏程：这个问题涉及环境架构的健壮性和主备切换的设计能力。例如，如果现有的集群环境已经具备了强大的负载均衡和数据同步能力，那么在这个环境下进行主备切换可能会比较顺利，实现一次平稳的切换。</p><p>&nbsp;</p><p>在某些极端情况下，我们可能会对主备切换持谨慎态度。在这种情况下，通常会先进行验证，然后在停机窗口内进行升级和维护。具体的处理方式需要根据具体情况进行分析和决策。实际情况中，我们会发现新系统更容易处理迁移需求。通常建议先进行增量环境的升级，甚至做一些妥协，旧系统可能需要长期运行，直到系统生命周期结束或者出现新的机会才进行升级替换。毕竟，一些系统由于年久原因，可能无法找到维护方，这些风险是现实中需要考虑的。</p><p>&nbsp;</p><p>姜雨生：在实际迁移过程中，我们通常会关注哪些验证指标？</p><p>&nbsp;</p><p>张鹏程：在验证阶段，针对操作系统通用环境，我们通常需要确保原有系统的功能正常运行。对于常规系统而言，如果之前经历了完整的项目周期，通常会有回归测试场景来验证功能的可用性。在兼容性满足的情况下，这些测试通常不会出现大的意外。</p><p>&nbsp;</p><p>第二步可能更关键，即在关键性能场景下进行验证。例如，系统可能具有特定的QPS指标或响应时间要求，针对这些指标，对新部署环境也需要进行测试。实际企业环境中，还需要考虑端到端的整体效果。验证的具体步骤因系统而异。</p><p>&nbsp;</p><p>姜雨生：操作系统的迁移工作主要包含哪些成本？比如迁移时间通常需要多久？需要多少人力？运行和使用成本如何？如何才能降低企业的操作系统迁移成本？</p><p>&nbsp;</p><p>张鹏程：在企业进行迁移过程中，成本方面需要考虑资源和人力投入。资源成本包括验证和测试所需的资源，以及生产环境的轮转和替换成本。人力成本涉及企业自有的IT运维人员负责操作系统管理和基础环境维护，以及与应用系统维护方或项目参与方相关的人员投入。</p><p>&nbsp;</p><p>在迁移过程中，由于兼容性适配和性能调优的需要，很可能需要应用层面的软件维护人员或开发人员提供帮助。这与所处环境的技术架构和应用程度有关。举例来说，传统架构体系相对复杂的情况下，可能涉及多个业务管理系统、企业IT系统和云服务系统，组件数量可能超过100个，涉及的服务器节点可能达到上千个。在这个过程中，硬件投入资源相对可控。由于环境已经云化，可以利用冗余资源进行轮转，因此迁移过程不会导致大量额外资源采购。借助云的优势，可以快速创建、使用、验证，并在完成后销毁回收，从而节省额外资源投入。</p><p>&nbsp;</p><p>然而，人力成本是不可避免的。在项目中，参与人员包括项目组成员、IT人员、应用系统相关人员和软件供应商人员，项目组成员通常达到上百人的配置。经过近三个月的时间，项目组成功地完成了从最初的评估测试到生产级别轮转的新试点项目。考虑到迁移过程中的不确定性和影响，这可以被视为一个高效的项目运作方式。在这方面，对于高要求和推进方面有很多挑战，但团队成功应对了这些挑战。</p><p>&nbsp;</p><p>姜雨生：有观众提问说，龙蜥对于社区用户会提供哪些生产级的技术支持，以何种方式支持？</p><p>&nbsp;</p><p>张鹏程：龙蜥社区是阿里云,统信软件,浪潮信息,龙芯,Intel,Arm等国内外知名厂商共同创建和维护的社区。龙蜥社区由24家理事单位共同管理，超过300家操作系统产业生态伙伴共同维护,为国内用户提供更加安全稳定使用的操作系统。在社区操作系统中，我们提到的产品形态可以分为两层结构。</p><p>&nbsp;</p><p>第一层是社区自身的上游产品，称为龙蜥社区版Anolis OS(龙蜥操作系统)，它是一个开源、免费的版本供大家使用。</p><p>&nbsp;</p><p>第二层是在社区中，理事单位和广泛伙伴可以基于社区版进行衍生开发和商业扩展的版本。其他理事单位可以构建衍生版本，通常与厂商合作，在社区版本的基础上增加自主研发的能力，并提供附加的商业服务和增值功能。这样的衍生版本以商业产品的形式提供给市场上的用户。</p><p>&nbsp;</p><p>在国内广泛的社区使用中，存在两种情况：一种是使用社区免费版本的用户，另一种是使用基于社区发行的商业衍生版本的用户。对于广泛的用户群体而言，如果使用的是社区免费版本，通常会采用社区的服务或开源方式进行维护和推进。在这个过程中，用户可能会在官网或通过钉钉群、微信群等渠道报告问题。社区内包括阿里的成员、不同理事单位的成员以及广泛的开发者用户，大家可以在这个开放平台上共同协作，解决问题并提供解决方案。这是第一层次。</p><p>&nbsp;</p><p>如果用户选择了商业衍生发行版本，通常会获得服务提供方提供的商业服务。在生产环境下，这些服务可能包括on-call支持或专家服务。这些商业服务是商业产品的配套服务，用于支持实际使用的应用场景。</p><p>&nbsp;</p><p>姜雨生：当前国内外已经出现了不少 CentOS 停服解决方案，在选择操作系统迁移替换时，不同行业的关注重点分别是什么？与其他迁移方案相比，龙蜥社区的差异化和优势体现在哪里？主要有哪些迁移工具？</p><p>&nbsp;</p><p>张鹏程：龙蜥社区的诞生源自阿里云将其内部使用的操作系统进行开源，并与更广泛的社区伙伴合作，以开源社区的方式更好地推进这项工作。</p><p>&nbsp;</p><p>龙蜥操作系统是基于阿里云在过去十多年发展历程中的沉淀而来，经过大规模验证的生产级别产品。阿里云最初在内部开发龙蜥操作系统是为了替换CentOS，以满足内部的需求，例如“双十一”等大规模稳定运行的要求。龙蜥操作系统在满足自用的阶段已经在内部发展出了雏形。</p><p>&nbsp;</p><p>随后，我们考虑到云上存在许多企业用户，他们对操作系统需要具备差异化的能力，例如快速启动和弹性部署等。为此，我们将其产品化为阿里巴巴云操作系统（Alibaba&nbsp;Cloud Linux），以更好地服务于云上的广泛用户。</p><p>&nbsp;</p><p>随着龙蜥社区的发展，从2020年开始，我们围绕开源社区产业协同共建机制，共同完善龙蜥操作系统。总的来说，我们的发展差异化最核心的基础一直是立足于云计算趋势的发展，并不断演进，以满足国内的自主需求以及整个技术体系的发展需求。</p><p>&nbsp;</p><p>我们的操作系统具备操作系统必备的核心要素，如稳定性和安全性。阿里云上的龙蜥操作系统经过上百万台服务器的运行打磨，其稳定性显而易见，相比我们所熟悉的开源版本具有更高的稳定性。同时，在安全性方面也进行了针对云场景的优化。</p><p>&nbsp;</p><p>龙蜥社区还积累了一个生态协同的优势。例如，在国外发展成熟的操作系统中，存在停服和不同生态发展之间的差异和隔阂问题。而在我们的社区中，国际合作伙伴（如Intel/ARM）和国内芯片厂商（如海光、飞腾、申威、龙芯、兆芯）积极参与合作，形成了良好的产业协作样板。大家围绕操作系统基础进行软、硬件协同共同研究，使我们共同研发的操作系统无论在通用服务器还是国产芯片服务器上运行，都能保证相应的硬件支持和优化。随着国内生态的进一步发展，这方面的优势和积累将得到更好的体现。</p><p>&nbsp;</p><p>姜雨生：面对国内的芯片厂商，我们在提供支持的过程中进行了合作。这种合作是在我们的社区内部自发进行的，厂商也会提供一些兼容性方面的支持，毕竟他们可能需要进行一些开发工作。在这个过程中，我们社区的开源工作者们不断构建相关内容以满足需求，还是由厂商主导来支持代码仓库构建？</p><p>&nbsp;</p><p>张鹏程：这是一个综合发展的过程。首先，社区内部有一个完整的治理结构。我们提到了理事单位，国产芯片厂商大部分都参与其中，并负责相应的职责。在理事单位下面，还有一个技术委员会，由理事单位的代表组成，大家从技术角度参与进来。</p><p>&nbsp;</p><p>这意味着芯片厂商确实在这个过程中拥有话语权，并参与讨论。同时，通过一些特殊兴趣小组（SIG）的方式，我们实际上创建了许多小型开源项目，大家在操作系统的范围内进行合作。因此，我们将不同的芯片路线对应到不同的SIG合作上，以推动代码的合作。当然，更广泛的个人开发者也非常欢迎参与其中。</p><p>&nbsp;</p><p>目前国产芯片的发展主要由芯片厂商主导，因为他们需要考虑如何使硬件与操作系统相匹配，将其整合到软件生态系统中。这是他们需要完成的一项重要任务。一旦这个飞轮开始转动并且得到越来越多的应用和开发者的支持，这部分可能会有更好的基础，然后可能吸引更广泛的开发者群体参与SIG组。这样的结构有助于在这样的基础设施环境下，推动社区的产业协同共研，不断地将其发展壮大，就像滚雪球一样。</p><p>&nbsp;</p><p>姜雨生：龙蜥在金融、交通、教育等多个领域帮助企业实现了操作系统迁移，在这些过往的迁移案例中，有哪些让您印象深刻、特定场景下的迁移诉求？我们对应的解决方案是什么？</p><p>&nbsp;</p><p>张鹏程：确实每个客户都是独特的，无论是在我们的咨询、交流，还是在共同开展项目方面，包括我在阿里云接触的客户，都有特定的情况。从我们的角度来看，我们都有自己的能力和边界，以及生态发展方式。因此，我们需要关注需求的共性和差异，以更好地开展工作。在用户群体中，我们主要关注的是保证操作系统的兼容性。如果兼容性存在不确定性，我们需要识别兼容性风险并进行相应的适配调整，以确保操作系统的顺利运行。另外，对于迁移后的优化和运维管理方式，我们也需要思考如何处理。从容器设计的角度来看，这类需求具有共性。</p><p>&nbsp;</p><p>为了满足这类共性需求，我们从社区的角度推动了一个名为\"迁移SIG\"的专项兴趣小组。我们完成了一个名为“社区运维工具”的项目，并与“迁移SIG”和“运维SIG”合作，将其打造成一个综合平台或工具集。它不仅包括满足迁移评估、适配和验证的自动化流程能力，还是一个组件化的平台，提供系统运维管理和诊断能力，以及对问题的调优建议。因此，我们基于社区合作的成果，创建了一个升级版的SysOM&nbsp;2.0平台，满足了迁移需求和迁移后的使用调优需求，而上层应用的适配则更多是个性化的需求。</p><p>&nbsp;</p><p>通常情况下，我们希望通过社区合作的方式解决这些个性化问题。有时我们会与一些应用厂商进行合作，他们是应用的提供商，并且由于迁移的机会，与我们社区建立了联系。在应用层面，我们希望借助这些应用厂商的专业知识来解决问题。解决客户问题的同时，我们希望这些厂商与龙蜥社区建立更长期的合作关系。实际上，许多厂商在经历了迁移案例后，已经成为龙蜥社区的生态伙伴，并加入了我们的龙蜥社区生态发展计划-龙腾计划。</p><p>&nbsp;</p><p>姜雨生：在迁移过程中，我想了解您是否遇到了一些技术上的难点，哪些难点可能让您头疼很长时间，也可能困扰了整个团队，需要花费大量时间来解决？</p><p>&nbsp;</p><p>张鹏程：在迁移过程中，可以按照前面提到的三个阶段，分享一些典型问题的经验。首先是迁移评估阶段，因为国内用户的评估环境多种多样，非常复杂。硬件设备、部件的兼容性对操作系统的兼容性有很大影响，例如RAID卡、网卡等。在开始阶段，很多用户都会提出这些问题。为了应对这些问题，我们借助社区采用了一些兼容性验证小工具，并通过推广和积累逐渐建立了丰富的兼容性列表。我们希望通过这种方式尽早发现问题，应对碎片化的硬件生态。</p><p>&nbsp;</p><p>在迁移过程中，更多的问题可能出现在每个系统环境上。老旧系统在升级过程中的成功率较低，或者在真正进行迁移的系统改动之后，由于环境的变化或重启，系统的运行状态可能不如之前正常。这些问题在运行过程中普遍存在。解决这些问题并没有灵丹妙药，最好的方式是提前进行系统测试验证，确保在生产环境中没有充分验证之前，不要贸然进行调整。在整个项目管理流程中，需要加强验证工作。当然，如果是新系统或者有系统升级的机会，结合项目会有事半功倍的效果。</p><p>&nbsp;</p><p>第三种情况是迁移后的问题排查，通常涉及性能提升。有时候我们会发现，在升级后，性能可能下降了50%甚至更多，这时我们需要依赖一些调优工具。在社区中，我们积累了一些调优工具，例如我们自研的Keentune工具，它结合社区环境提供调优诊断和性能优化建议。这些都是常见的头疼问题，需要结合工具和经验来解决。</p><p></p><h2>开发者如何拥抱变化？</h2><p></p><p>&nbsp;</p><p>姜雨生：对于企业开发者而言，企业在完成操作系统迁移后，开发者在后续的工作中会发生哪些变化？</p><p>&nbsp;</p><p>张鹏程：这确实是一个现实情况。我认为迁移本身可以分解为两大类型。一种是仅进行操作系统的变更，为了解决原有担忧CentOS所带来的停服风险，而解决系统更换的问题。对于这种情况，从用户的角度来看，我们的开发者和系统管理员决策方面无需过多担心，因为原有软件生态的兼容性相对较高，具有一致性。所以对于用户来说，他们原有的运维管理工具、开发工具，包括脚本等，基本上都可以正常运行，不会产生太大的意外。</p><p>&nbsp;</p><p>另一种迁移往往伴随着架构升级，这种架构升级可能体现在前面提到的国内情况中，通常伴随着本土化生态的替代。这可能导致跨架构的情况，例如从原来使用的x86体系，经过迁移和升级，开始使用ARM甚至一些用户接触到了龙芯或申威等架构。在这种情况下，原有的工具和软件需要与新架构相结合进行相应的生态调整。</p><p>&nbsp;</p><p>还有一种情况是朝着云原生化方向发展。例如从物理机维护或虚拟机逐渐转向容器和PaaS层的使用。对于开发者来说，不仅操作系统发生了变化，开发范式和运维管理方式也可能发生变化，整体的工作流都会产生影响。</p><p>&nbsp;</p><p>姜雨生：国产操作系统替换浪潮下，对于身处其中的开发者而言，您认为最关键的、最需要掌握的技能是什么？</p><p>&nbsp;</p><p>张鹏程：我认为今天的技术浪潮不仅限于操作系统领域，我们所看到的是云计算不断发展的浪潮，以及国产化趋势下的新兴趋势。最近，AI 大模型也引发了人们对人工智能的期待，这些都是开发者面临的时代机遇。</p><p>&nbsp;</p><p>因此，在这个过程中，我们可以不仅仅局限于参与操作系统社区的工作。诚实地说，能够参与操作系统级别开发的开发者是非常有限的，但更广泛的开发者群体在进行应用和系统开发方面发挥着重要作用。因此，我们欢迎大家参与龙蜥社区的使用。龙蜥社区不仅仅是一个操作系统，它提供了编程语言的编译环境，以及系统管理和优化工具，这些工具对开发者来说非常实用，可以帮助他们完善自己的工作。</p><p>&nbsp;</p><p>所以我想借这个机会进行一点宣传，我们欢迎读者多关注和了解龙蜥社区，参与其中的活动，如前面提到的SIG小组或Meetup活动。这些活动能够帮助大家了解龙蜥社区的成员，了解他们最近在忙什么，以及一些新兴创新产品。这些内容可能与我们日常工作相关，如果能对大家有所帮助，那么大家可以逐渐参与到龙蜥社区的活动中来。</p><p></p><h2>开源会成为国产操作系统的主流模式吗？</h2><p></p><p>&nbsp;</p><p>姜雨生：正如我们之前讨论过的，对于龙蜥的产品生态，有一个开源版本，还有一个企业级版本。在这样的生态下，目前龙蜥的主要方向是怎样的？从整体来看，国内操作系统未来的趋势可能会以开源为主，还是以商业化模式为主呢？开源生态建设是否会成为未来的主流趋势？</p><p>&nbsp;</p><p>张鹏程：在开源和闭源、开源和商业之间的话题上，随着开源的发展，它们之间确实像DNA的双螺旋一样共同发展。简单来说，我认为开源肯定是发展的主流力量。</p><p>&nbsp;</p><p>具体到您提到的开源和商业之间的比重，我觉得开源依赖于一个强大而健康的商业模式，以确保开源不会变得无根之木。参与开源的人除了出于热爱之外，在企业角度上，他们也从中获得商业利益的满足，才会更愿意投入开源的发展。因此，我认为总体而言，追求商业发展的企业会成为开源的主导力量。就使用方面和未来发展的预测而言，我认为供给侧和需求侧都会影响其发展的趋势和比重。</p><p>&nbsp;</p><p>从供给侧来看，开源方式是必不可缺的。就像我之前提到的，如果几个硬件厂商或芯片厂商各自发展各自的操作系统，构建起生态将变得更加困难。然而，基于像龙蜥社区这样的操作系统层面的中转，硬件厂商可以在下一代芯片演进时基于这个中转来嫁接更广泛的软件生态，这样是符合利益的。因此，从供给侧来看，开源为大家提供了一个促进参与开源并从中获益的过程。</p><p>&nbsp;</p><p>而从需求侧来看，它与我们面对的广泛用户群体的需求有关。一些用户可能IT预算较低，或者对业务连续性的要求不高，对他们来说，选择开源已经足够。或者在开源的基础上，叠加其他技术层面的解决方案，也能摆脱对单一节点的需求。另外，一些企业在业务连续性、稳定性和安全性方面有较高要求，这就催生了商业版本的价值。商业版本可以由商业厂商提供更充分的服务、更好的升级以及专家资源，这些都有助于企业解决自身问题。</p><p>&nbsp;</p><p>总体来说，开源和商业版本是相辅相成的。开源作为背后的动力基础，使得参与其中的群体在商业循环中有更强的动力继续贡献开源，并进一步获得回报。这是我们的期望。</p><p>&nbsp;</p><p>龙蜥目前主要的定位是什么，以及国内操作系统未来的趋势，是以开源为主还是商业化模式为主，我认为这是一个相互影响的过程。龙蜥作为一个开源操作系统，在开源社区中发挥着重要的作用，并通过健康的商业模式支持其发展。我们希望在未来能够将两者并驾齐驱，相辅相成，共同发展。</p><p></p><h4>嘉宾介绍</h4><p></p><p>&nbsp;</p><p>特邀主持：</p><p>&nbsp;</p><p>姜雨生，微软软件工程师，负责微软资讯业务与 GPT 集成，曾负责微软广告团队基础设施搭建与维护工作。</p><p>&nbsp;</p><p>嘉宾：</p><p>&nbsp;</p><p>张鹏程，龙蜥操作系统产品生态总监，阿里云基础软件部产品负责人，在基础软件和云计算领域拥有 15 年从业经验，负责龙蜥操作系统产品生态和社区运营工作，围绕开源联合产业链上下游生态伙伴协同创新发展，立足云计算场景打造数智时代领先的操作系统产品和解决方案。</p>",
    "publish_time": "2023-05-31 14:22:32",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "李彦宏宣布启动“文心杯”创业大赛，参赛者最高可获千万大奖，同时设立10亿创投基金促进大模型生态",
    "url": "https://www.infoq.cn/article/ecGvttdahFzqtS9DtBJJ",
    "summary": "<p>5月31日，百度创始人、董事长兼首席执行官李彦宏在摩根大通全球中国峰会期间宣布，百度将设立10亿元人民币的百度文心投资基金，旨在推动大模型生态繁荣，同时启动\"文心杯\"创业大赛，最高奖项为价值1000万元早期投资。</p><p></p><p>李彦宏表示：“为打造更有活力的生态系统，并帮助开发者开发各种AI原生应用，百度计划设立一个10亿元人民币的投资基金。我们还将推出“文心杯”创业大赛。参赛者可以提交想法和原型，我们将寻找最有潜力的想法，并为其提供资金。美国开发者正基于ChatGPT或其他语言模型开发新应用。在中国，更多开发者将会基于文心大模型来开发AI应用。\"</p><p></p><p>“未来，我认为中国会有自己的生态系统，拥有自己的大语言模型和基础模型。中国会出现至少一个、也可能是两个或三个基础大模型，可以支持人们开发各种AI原生应用。比如，百度的文心大模型就致力于成为AI开发者的默认基础模型之一。\"他在发言中表示。</p><p></p><p>李彦宏还指出，“我非常看好中国AI应用的发展前景，如果回顾过去几十年历史，在中国大家都非常愿意拥抱新兴技术。虽然我们没有发明Android、iOS或Windows系统，但我们开发了许多非常创新的应用，比如微信、抖音和滴滴等，还有很多应用都很受欢迎、很实用。在人工智能时代，也是同样的情况。科技带来了很多可能，我们非常善于开发应用，并充分利用了这些可能。\"</p><p></p><p>据介绍，本次创业大赛于5月31日正式启动，报名持续到6月25日24:00关闭。按要求，参赛团队需专注于AIGC、大模型创新应用方向，有意愿且有能力基于文心大模型搭建应用，或将文心大模型与自有产品进行结合。无论是有创业计划的初创团队，还是有成型产品或demo的初创公司，均可参赛。大赛将为参赛团队开放文心大模型相关能力及百度智能云算力资源，并邀请来自IDG资本、百度风投、百度资本等知名机构投资人与多位百度AI专家担任评审。获奖团队有机会获得总值1000万元、500万元、200万元的资金与资源投资，以及AI大模型技术辅导与交流赋能。</p><p></p><p>同时，百度还将设立规模为10亿元的文心投资基金，面向AIGC领域潜力股创企，提供涵盖资金、技术、业务资源在内的全面扶持，持续关注AI领域优质创业团队，推动中国AI大模型生态繁荣。（完）</p><p></p><p>【报名方式】参赛人员可百度搜索“百度文心杯创业大赛”进入官网报名或直接点击下方链接。</p><p>报名网址：<a href=\"https://cloud.baidu.com/summit/ernie_cup\">https://cloud.baidu.com/summit/ernie_cup</a>\"</p><p></p><p>请参赛者仔细阅读报名须知，并关注官网通知。如有任何问题，可向aigcsupport@baidu.com邮件咨询。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/e2/59/e22c779659973883a148c3f599cfe759.jpg\" /></p><p></p><p></p><p>&nbsp;</p>",
    "publish_time": "2023-05-31 15:47:12",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "连代码都没写就敢要融资：被ChatGPT带火的向量数据库，带来了一大波造富神话",
    "url": "https://www.infoq.cn/article/saW52Ys9ymut3c2zb9WP",
    "summary": "<p></p><p>&nbsp;</p><p>“我见过10多个数据库突然变成了向量数据库！”</p><p>&nbsp;</p><p>“我预测每个数据库都会突然原生支持向量嵌入和向量搜索。”</p><p>&nbsp;</p><p>“是的，兄弟，我的向量数据库初创公司刚刚结束了 A 轮融资。”</p><p>&nbsp;</p><p>......</p><p>&nbsp;</p><p>OpenAI掀起的这波AI变革，让向量数据库越来越受关注。</p><p>&nbsp;</p><p>AI技术不断向前发展，一个核心驱动因素，就是背后的存储、处理和分析大量数据所需要的强大基础设施也在不断发生进步。这波“新基建”浪潮也催生出又一颗冉冉升起的新星——向量数据库，一种用于管理非结构化数据，包括数字形式的文本、音频、图像和视频的强大解决方案。</p><p>&nbsp;</p><p>随着市场对AI基础设施需求的不断增加，<a href=\"https://www.infoq.cn/article/ulloKY4sMiy1pizsuLaa\">向量数据库</a>\"预计也将保持强劲的发展势头，并一步步成为未来AI技术愿景的重要基石。</p><p>&nbsp;</p><p></p><h2>新型数据库成就一批新富豪</h2><p></p><p>&nbsp;</p><p>数据库领域经历过一系列发展阶段。最早的是SQL类关系数据库，其中所有数据都被纳入结构化的矩形表中。Web 2.0企业的需求增长引发了NoSQL革命，数据库变得更加灵活，能够处理体量更大的数据。如今，随着市场为AI技术积极筹划，向量数据库的时代也终于来临。</p><p>&nbsp;</p><p>与传统数据库不同，向量数据库特别擅长从非结构化数据中提取见解。这些数据库使用向量嵌入来表示数值型数据，并将其排列在彼此相似的一个个聚类当中，能够帮助用户使用相似对象查询数据库，从而轻松比较并找出最适合的匹配项。向量搜索的另一个优势就是这类查询延迟更低，特别适合生成式AI应用。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0c/0c6f2f0b41a29833d88c4fa10bb7b380.png\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>受到近期AI炒作的影响，更多企业开始大力<a href=\"https://www.infoq.cn/article/6sJmDyNkcY0hmQt6Csd1\">投资向量数据库</a>\"以提升算法准确性和效率。据相关统计，2023年4月的AI投资领域呈增长趋势，尤其是向量数据库领域的投资活动颇为活跃，Pinecone、Chroma和Weviate等向量数据库初创公司都在这个月获得了融资。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/82/82a8f9c842afee4c97861a6bc7814f2f.jpeg\" /></p><p></p><p>&nbsp;</p><p>让我们具体来看看向量数据库领域非同一般的融资情况。</p><p>&nbsp;</p><p>这个月，Pinecone宣布以7.5亿美元的投后估值完成1亿美元的B轮融资。本轮融资由Andreessen Horowitz领投，加上去年的2800万美元的A轮融资和2021年的1000万美元的种子轮融资，该公司已累计筹集1.38亿美元。</p><p>&nbsp;</p><p><a href=\"https://www.pinecone.io/learn/vector-database/\">Pinecone是一款云原生向量数据库</a>\"，专为高性能、低延迟和可扩展的向量相似性搜索而设计。它能够处理密集和稀疏向量，因此成为各种用例的理想通用选项。Pinecone提供易于使用的API，用户只需编写几行代码就能实现向量的添加、搜索和检索。</p><p>&nbsp;</p><p>而开源搜索引擎Weviate的开发商SeMI Technologies于去年2月宣布拿下由New Enterprise Associates 和 Cortical Ventures 领投的 1600 万美元 A 轮融资。</p><p>&nbsp;</p><p>今年4月，Weaviate 再次获得 5000 万美元B轮融资。</p><p>&nbsp;</p><p>Weaviate是一款功能丰富的向量数据库，专为复杂的数据建模和搜索用例而生。它提供GraphQL API，支持向量相似性搜索和一系列其他高级搜索与过滤功能。Weaviate能够存储和搜索各种数据类型，包括结构化数据、非结构化数据和图像。</p><p>&nbsp;</p><p>同月，向量数据库初创公司 Chroma 也获得了 1800 万美元的种子资金，估值达到 7500 万美元。</p><p>&nbsp;</p><p>Chroma是一款简单的轻量级向量搜索数据库，可用于构建内存内的文档-向量存储。它以Apache Cassandra为基础，提供易于使用的API。Chroma的核心优势就是简单性。它能快速完成设定和配置，无需任何特殊硬件或软件。</p><p>&nbsp;</p><p>但值得注意的是，Chroma 上个月在 GitHub 上只获得1.2k star。</p><p>&nbsp;</p><p>最近，另一家开发开源向量搜索引擎和非结构化数据库的德国初创公司Qdrant也刚刚获得750万美元种子资金，领投方为Unusual Ventures、42cap和IBB Ventures，另有包括Cloudera联合创始人Amr Awadallah在内的一众天使投资人跟投。</p><p>&nbsp;</p><p>就目前的情况看，跟以往的其他新技术一样，我们恐怕很难区分向量数据库领域的虚假炒作与真实优势。谷歌开发专家Jeff Delaney就在他的节目上（搞笑地？）谈到他在尚无任何收入、商业计划甚至是实际代码可以展示的情况下，凭借Rektor向量数据库初创项目让公司估值飙升至4.2亿美元，并呼吁大家为其投资。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6a/6a2ab4304584c194d797f52addb0ae3c.jpeg\" /></p><p></p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/84/84022ae054c2f8612eb89ea5fc8a5eef.jpeg\" /></p><p></p><p>&nbsp;</p><p>社交媒体上，关于向量数据库的段子也明显多了起来。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/75/75afebde4dd44dd2832436aa3e31f4cd.jpeg\" /></p><p></p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a1/a15e16b29492165239a9d2d260948890.jpeg\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f1/f1433876455f33b27ee3ac04c11b3635.jpeg\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>被ChatGPT带火的向量数据库</h2><p></p><p>&nbsp;</p><p>向量数据库的兴起，与生成式AI应用对“嵌入”概念的日益推崇密切相关。嵌入是一种高维向量，可表示连续数字空间中的非结构化数据，例如文本、图像和音频等。在NLP场景下，嵌入以向量格式表示单词或句子的语义和句法，并可作为输入被馈送至深度学习模型当中。</p><p>&nbsp;</p><p>例如，“我爱披萨”这句话就可以表示为一个300维的向量，其中每个维度代表句子的特定特征或属性，例如字数、是否存在某些关键字或情绪倾向等。为自然语言生成嵌入的过程，往往是由预训练语言模型（例如OpenAI GPT或BERT）来完成。</p><p>&nbsp;</p><p>嵌入向量的长度不受限制，可以根据具体用例和用于生成嵌入的模型而有所变化。嵌入的质量越高，语言建模、情感分析、机器翻译和问答系统等NLP任务的性能表现也就越好。</p><p>&nbsp;</p><p>大语言模型（LLM）就是高度依赖嵌入的先进AI用例之一。这些模型往往包含数十亿个参数，嵌入则广泛作用于这些模型的训练和微调过程，使其获得执行各种NLP任务的能力。</p><p>&nbsp;</p><p></p><h4>SQL数据库在处理高维嵌入方面的局限性</h4><p></p><p>&nbsp;</p><p>SQL数据库擅长处理具有固定模式的结构化数据，各条目通常存储在行和列构成的表内。与之相反，嵌入属于高维向量，表示连续数字空间中的非结构化数据，例如文本、图像和音频。嵌入可以包含数百甚至几千个维度，因此不适合被存储在专门针对小型、固定维度数据集进行优化的传统SQL数据库内。</p><p>&nbsp;</p><p>向量数据库在设计上特别适合处理高维向量，例如嵌入，因此可以为大量非结构化数据的存储、查询和分析提供更具可扩展性的效率优势的解决方案。凭借高效处理数千列相似性搜索的能力，向量数据库已经成为AI基础设施中的重要组成部分，为各类大语言模型和其他高级AI应用提供支持。</p><p>&nbsp;</p><p>向量数据库的嵌入处理优势源自以下几个特性：</p><p>高效存储：向量数据库强调对高维向量的高效存储，能够在最小存储空间下处理大量数据。这一点对于包含数百或几千个维度的嵌入而言非常重要。高性能相似性搜索：向量数据库使用专门的算法和数据结构对嵌入进行高性能的相似性搜索。用户可以借此快速找到与给定查询最接近的嵌入，因此非常适合对图像或文本的相似性搜索任务。可扩展性：向量数据库具备良好的可扩展性，能够轻松处理大规模数据集。这一点对嵌入非常重要，自然也能良好支持广泛依赖嵌入的大语言模型和其他AI应用。灵活性：向量数据库能够处理各种数据类型，包括文本、图像、音频和视频，因此广泛适合各类AI应用。</p><p>&nbsp;</p><p>总体而言，向量数据库在设计上非常适合处理高维向量（例如嵌入），这也使其成为现代AI基础设施中的重要组成部分。</p><p>&nbsp;</p><p></p><h4>通过语义搜索实现ChatGPT定制</h4><p></p><p>OpenAI的嵌入方法是一种无监督学习方法，也被称为“表示学习”。该模型能够学会特定的数据表示方式，在无需明确了解须提取哪些特征或如何表示数据的情况下，即可完成自然语言处理等下游任务。这种方法在大语言模型训练当中效果拔群，能够准确地生成顺畅自然的文本内容。</p><p>&nbsp;</p><p>但OpenAI模型也有自己的局限，那就是只能处理有限数量的输入数据。例如，ChatGPT 3.5的token上限为4096，意味着如果没有额外技术的加持，它就无法搜索更大的数据库。而嵌入的意义也正在于此。</p><p>&nbsp;</p><p>向量数据库凭借在非结构化数据中提取见解的能力而愈发流行，其重要特征体现在语义搜索等高级AI应用当中。语义搜索的效果与ChatGPT类似，但可以在自定义知识库上运行。这里的知识可以是客户关系管理（CRM）数据，技术手册甚至是研发信息。但要实现语义搜索，数据首先需要被存储在支持低延迟查询的位置，而向量数据库就凭借种种优势而特别适合这项工作。因此，向量数据库的日益流行，也反映出越来越多的企业有意基于内部知识打造属于自己的定制化ChatGPT。</p><p>&nbsp;</p><p></p><h2>竞争激烈程度持续提升</h2><p></p><p>当然，Postgres和NoSQL数据库Redis这类传统方案在AI时代也占据着一席之地。Postgres同样具备Pgvector向量/相似性搜索功能。</p><p>&nbsp;</p><p>为了不被时代抛弃，老牌数据库厂商正通过AI相关服务巩固自身业务。例如，甲骨文就推出一系列AI算法，并以“数据库内高速学习”为宣传重点。IBM的传统db2如今也被更名为“AI数据库”，利用机器学习技术改善查询性能并提供“基于置信度的查询”功能。</p><p>&nbsp;</p><p>此外，领域中的老牌劲旅（如微软）也开始提供在自定义知识库上构建AI应用的解决方案。例如，Azure Cognitive Search就能帮助企业构建并部署基于向量数据库功能的AI应用。Matchlt则是谷歌开发的向量搜索解决方案。可以看到，新老势力正纷纷登场，希望能为想要在AI流程中引入向量数据库的客户提供有价值的技术服务。</p><p>&nbsp;</p><p>如果说AI已经成为众多企业的研究前沿和中心，那么面向AI的基础设施自然会随之升温。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4a/4a989519c77da430f1d8bafaaf37e1c3.png\" /></p><p></p><p>资料来源：GradientFlow.com</p><p>&nbsp;</p><p>SeMI Technologies公司CEO Bob van Lujit<a href=\"https://venturebeat.com/data-infrastructure/database-technology-evolves-to-combine-machine-learning-and-data-storage/\">解释了Weviate这样的厂商跟传统关系数据库供应商之间的区别</a>\"。“这是我们第一次打造AI优先的基础设施，希望在数据科学成果跟市场业务需求之间架起桥梁。”</p><p>&nbsp;</p><p>软件服务初创公司Heltar的创始人Avyukt Aggarwal也解释了向量数据库与生成式AI工具间的紧密联系。“每一场淘金热都不缺卖铲子的人。对于生成式AI，这里的铲子是什么？就是向量数据库。几乎一切由大语言模型支持的应用程序都在用向量数据库，或者即将用上。大语言模型被集成到几乎所有主流应用当中，而提供一揽子托管向量数据库的厂商就是在挣淘金热当中卖铲子的钱。”</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f0/f0e97fa4526d3668a8e5029b95a37721.png\" /></p><p></p><p>&nbsp;</p><p>资料来源：Dhruv Anand是谷歌前工程师，也是科技创新初创企业AI Northstar tech的创始人。</p><p>&nbsp;</p><p>把向量数据库称为生成式AI的“铲子”并不为过。随着AI应用在企业生产部署中的快速普及，对高质量向量数据库的需求也重现了SQL在当年云黄金期的辉煌。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://techcrunch.com/2023/04/27/pinecone-drops-100m-investment-on-750m-valuation-as-vector-database-demand-grows/\">https://techcrunch.com/2023/04/27/pinecone-drops-100m-investment-on-750m-valuation-as-vector-database-demand-grows/</a>\"</p><p><a href=\"https://thenewstack.io/vector-databases-long-term-memory-for-artificial-intelligence/\">https://thenewstack.io/vector-databases-long-term-memory-for-artificial-intelligence/</a>\"</p><p><a href=\"https://twitter.com/GPTDAOCN/status/1658238286605975552\">https://twitter.com/GPTDAOCN/status/1658238286605975552</a>\"</p><p><a href=\"https://twitter.com/mattturck/status/1648825069177634820\">https://twitter.com/mattturck/status/1648825069177634820</a>\"</p><p><a href=\"https://github.com/codediodeio/rektor-db\">https://github.com/codediodeio/rektor-db</a>\"</p><p><a href=\"https://www.youtube.com/watch?v=klTvEwg3oJ4\">https://www.youtube.com/watch?v=klTvEwg3oJ4</a>\"</p><p><a href=\"https://analyticsindiamag.com/why-are-investors-flocking-to-vector-databases/\">https://analyticsindiamag.com/why-are-investors-flocking-to-vector-databases/</a>\"</p><p><a href=\"https://www.relataly.com/vector-databases-the-rising-star-in-generative-ai-infrastructure/13599/\">https://www.relataly.com/vector-databases-the-rising-star-in-generative-ai-infrastructure/13599/</a>\"</p>",
    "publish_time": "2023-05-31 17:37:41",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "自主研发先知·智能风险评估系统，灰度安全完成数千万元Pre-A轮融资",
    "url": "https://www.infoq.cn/article/XkGRefBR638pV3lWZbB2",
    "summary": "<p>近日，北京灰度科技有限公司（下称“灰度安全”）宣布完成数千万元Pre-A轮融资，投资方为安恒信息，航行资本担任独家财务顾问。本轮融资将主要用于产品研发迭代、专家知识研究和市场拓展。</p><p></p><p>近几年，企业安全运营理念逐步成熟，伴随企业资产和业务的复杂化、多样化，安全风险评估重要性开始凸显。</p><p></p><p>据CCIA（中国网络安全产业联盟）数据统计，2021年网络安全行业“大动作不断”，吸引了不少创业者的目光，仅上半年，中国就有4525家公司开展网络安全业务，相比上一年增长27%，网络安全市场总体支出达102.2亿美元，并有望在2025年增长至187.9亿美元，增速持续领跑全球。</p><p></p><p>在如此市场驱动下，催生了一批新兴的安全细分赛道，吸引创业者们加入，“灰度安全”正是在该背景下成立的一家帮助用户解决风险度量问题、提升主动防御能力的公司。</p><p></p><p>灰度安全研发的先知·智能风险评估系统，采用云原生架构，以专家知识库为核心，快速、弹性的构建专项风险度量场景，支持本地化部署、云部署和SaaS化交付。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0a/0aefa218bb72649297cab1092fa64af0.png\" /></p><p></p><p></p><p>针对传统防御措施在评估验证方面存在的缺失问题，灰度安全通过纵深防御风险评估、安全设备风险评估、漏洞利用风险评估、数据泄露风险评估和人员安全意识风险评估等场景帮助用户了解风险及对业务的影响，提升日常安全运营效率，积淀企业安全知识，帮助用户快速了解风险考核指标的落实情况。</p><p></p><p>该平台聚焦风险度量，通过实战化攻击场景构造和攻击向量编排技术，帮助企业持续验证防御措施有效性，实战度量安全风险，有效提升主动防御能力，自动化编排评估对象、评估域、攻击向量和攻击过程等要素，灵活适配企业场景化评估需求，针对企业特有评估场景，如攻防沙盘，构建沙盘剧本，实现自动化编排验证。</p><p></p><p></p><h4>聚焦实战化安全运营，支持四大场景应用</h4><p></p><p></p><p>网络安全领域的发展趋势已经从满足等保合规要求逐步迈向实战化的安全运营，越来越多的企业不仅参加攻防演练，还会在区域、行业和企业内将实战常态化开展。显然，实战化是检验安全运营效果的极佳手段，实战化的安全运营工具将是未来越来越多企业的刚需。</p><p></p><p>灰度安全的产品服务聚焦实战化安全运营，可弹性扩展的技术架构支持四大应用场景，包括安全决策支撑、日常运营支持、红蓝运营支撑、安全监管支撑。“不同的场景服务不同的客户对象，对于安全建设相对比较完善的客户，需求会集中在安全设备风险评估和网络纵深防御风险评估上，比如金融、央企、运营商客户，而对于一些SMB客户，需求则会集中在互联网边界风险评估。</p><p></p><p>灰度安全的核心竞争力体现在其安全防护与安全监测类验证技战术上，覆盖ATT&amp;CK框架70%+；全面覆盖网络层面、应用层面、主机层面、数据层面的等攻击100+类，10000+攻击向量；覆盖基于国内外主流的漏洞库及HW、重保、实战漏洞的POC知识数量3000+；基于阿里、微软、ATT&amp;CK、SYSDIG生成自有云原生攻击框架，覆盖率70%+。</p><p>&nbsp;</p><p>关于未来的发展，灰度安全CEO曹静表示，“公司从2021年成立至今，主要精力放在产品研发，在产品演进过程中，根据行业客户的关键痛点和业务需求，我们将产品进行针对性优化设计，不断地优化和打磨，得到金融、政府、运营商等不同行业的客户认可。目前，已完成10个产品的版本迭代及数十家客户的测试和交付，未来，灰度安全将继续深耕安全运营领域，聚焦实战化安全运营，将持续技术创新，为企业提供多维度安全运营产品、服务及整体解决方案，让灰度安全技术迈上新的台阶，成为具有行业影响力的安全公司。”</p>",
    "publish_time": "2023-05-31 18:08:13",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "谷歌正推出Passkey，密码将成历史",
    "url": "https://www.infoq.cn/article/BCiz4sPRaDGCl6NfP1VE",
    "summary": "<p>谷歌已经开始在所有主要平台的谷歌账户上<a href=\"https://blog.google/technology/safety-security/the-beginning-of-the-end-of-the-password/\">提供Passkey支持</a>\"。Passkey将作为现有机制（包括密码、两步认证等）的附加身份验证选项提供。</p><p>&nbsp;</p><p>按照谷歌的说法，Passkey为用户提供了一种更简单、更安全的认证方式。</p><p>&nbsp;</p><p></p><blockquote>Passkey允许用户像解锁设备一样登录应用和网站：通过指纹、面部扫描或屏幕锁定PIN码。而且，与密码不同，Passkey可以抵御网络钓鱼等在线攻击，这使得它们比一次性短信验证码更安全。</blockquote><p></p><p>&nbsp;</p><p>对于用户来说，密码是出了名的难以管理，他们需要创建并记住大量的强密码，而且要为他们使用的每个服务都设定不同的密码。事实上，尽管密码可能很强大，但它们并不能保护用户免受网络钓鱼攻击的侵害，并且越来越频繁地与另一种机制——双因素身份验证（2FA）——搭配使用，而这种机制也有自身的缺点。</p><p>&nbsp;</p><p>在底层，Passkey是存储在用户设备上的加密私钥，而对应的公钥则上传到谷歌。当用户试图使用Passkey登录谷歌时，谷歌将要求他们的设备使用私钥签署挑战书（sign a challenge）。</p><p>&nbsp;</p><p></p><blockquote>这个签名向我们证明了设备是你的，因为它有私钥，是你在设备上解锁它，而你确实是在尝试登录谷歌，而不是一些中间网络钓鱼站点。</blockquote><p></p><p>&nbsp;</p><p>用户只有在解锁了设备的情况下才能签署挑战书，这一步可以利用许多设备都提供的先进的生物识别硬件，包括指纹和面部识别。或者，用户可以使用更传统的PIN码。根据谷歌的说法，任何生物特征数据都不会在签名设备之外共享，签名设备只会发送公钥和签名。</p><p>&nbsp;</p><p>谷歌还提供了一种机制，让你可以借助自己的手机在另一台设备上登录。当你需要从共享设备上访问自己的账户时，这一点至关重要。在这种情况下，设备将首先使用蓝牙检查手机是否在附近，然后它会显示一个QR码，如果用户要授权，就可以用手机进行扫描并用它生成一次性密码签名。这个新设备既不会收到Passkey，也不会接收到任何生物特征信息。</p><p>&nbsp;</p><p>密钥驻留在个人设备上，每个设备都需要获得自己的Passkey，这可能会很麻烦。为了规避这个问题，你可以在所有设备上共享Passkey。谷歌并没有为此提供一种通用的机制，但用户可以依靠苹果设备上的iCloud Keychain，以及Android和Chrome设备上的谷歌密码管理器来获得完美的体验。遗憾的是，除非使用第三方SSH密钥管理器，否则不能在iPhone和Android设备之间共享Passkey。值得注意的是，微软官方尚未提供一个可以跨Windows设备共享秘密的解决方案。</p><p>&nbsp;</p><p>要为自己的谷歌帐户创建一个Passkey，目前你需要使用一个<a href=\"http://g.co/passkeys\">专用域</a>\"。</p><p>&nbsp;</p><p>去年，谷歌一直在与苹果和微软合作，制定标准的方法，其中包括可以在全行业采用的无密码认证方法<a href=\"https://fidoalliance.org/\">FIDO</a>\"和<a href=\"https://www.w3.org/TR/webauthn-2/\">W3C WebAuthn</a>\"。</p><p>&nbsp;</p><p>声明：本文为InfoQ翻译，未经许可禁止转载。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/05/google-passkeys-rollout/\">https://www.infoq.com/news/2023/05/google-passkeys-rollout/</a>\"</p><p></p><p>延伸阅读：</p><p><a href=\"https://www.infoq.cn/article/HKsPfKWmCpbHHA7diwNA\">AI 开始抢黑客饭碗？攻击快又准，不到一分钟破解超过半数的密码</a>\"</p><p><a href=\"https://www.infoq.cn/article/QMgmfb48A8AD1YHBdyPC\">让部署更快更安全，GitHub 无密码部署现已上线</a>\"</p>",
    "publish_time": "2023-05-31 18:24:15",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Record模式提升了Java，能实现更具表现力的编码",
    "url": "https://www.infoq.cn/article/0ZTAForQs79EseZhPRXU",
    "summary": "<p>摘要：</p><p>由于在JEP 432和JEP 405中进行了反馈驱动的增强，JEP 440，最终确定的记录模式（Record Patterns）已从JDK 21从Proposed to Target状态提升为Target状态。在与类型模式一起使用时，记录模式现在允许进行强大的数据导航和处理。JEP 432的主要更改是删除了增强for语句头中的记录模式。</p><p></p><p>JDK 21的JEP 440，<a href=\"https://openjdk.org/jeps/440\">记录模式</a>\"已从Proposed to Target状态<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-May/007729.html\">提升</a>\"为Targeted状态。该JEP最终确定了这个特性，并结合了增强功能以响应前两轮<a href=\"https://openjdk.java.net/jeps/12\">预览</a>\"的反馈：JEP 432，<a href=\"https://openjdk.org/jeps/432\">记录模式（第二次预览）</a>\"，在JDK 20中交付；以及JEP 405，<a href=\"https://openjdk.org/jeps/405\">记录模式（预览）</a>\"，在JDK 19中提供。该特性通过记录模式增强了语言以解构记录值。记录模式可以与类型模式结合使用，以“实现一种强大的、声明式的和可组合的数据导航和处理形式”。类型模式最近进行了扩展以用于 switch case 标签：JEP 420，<a href=\"https://openjdk.java.net/jeps/420\">switch模式匹配（第二次预览</a>\"），在JDK 18中提供，以及JEP 406，<a href=\"https://openjdk.java.net/jeps/406\">switch模式匹配（预览）</a>\"，在JDK 17中提供。与JEP 432相比，其最重要的更改是删除了对出现在增强for语句头中记录模式的支持。</p><p></p><p>通过所有这些更改，Java现在通过引入可嵌套的记录模式，正朝着更具声明式、以数据为中心的编程风格发展。这一演变是在模式匹配与Java 16引入的<a href=\"https://openjdk.org/jeps/394\">JEP 394</a>\"，instanceof操作符集成之后发生的。</p><p>考虑这样一种情况，即你有一个记录Point和一个枚举Color：</p><p><code lang=\"null\">record Point(int x, int y) {}\nenum Color { RED, GREEN, BLUE }\n</code></p><p>无论对象是否是record的实例，新的记录模式都允许对其进行测试，并直接解构其组件。例如：</p><p><code lang=\"null\">if (r instanceof Rectangle(ColoredPoint ul, ColoredPoint lr)) {\n    System.out.println(ul.c());\n}\n</code></p><p>更强大的是它提供了嵌套模式，允许进一步解构record值。考虑如下的声明：</p><p><code lang=\"null\">record ColoredPoint(Point p, Color c) {}\nrecord Rectangle(ColoredPoint upperLeft, ColoredPoint lowerRight) {}\n</code></p><p>如果我们想从左上角提取颜色，可以这样写：</p><p><code lang=\"null\">if (r instanceof Rectangle(ColoredPoint(Point p, Color c), ColoredPoint lr)) {\n    System.out.println(c);\n}\n</code></p><p>记录模式的这种演变扩展了模式匹配，以解构记录类的实例，从而支持了更复杂的数据查询。无论对象是否是record的实例，它都允许对其进行测试，并直接提取对象的组件。这种方法使代码更加简洁，而且不易出错。考虑如下的示例：</p><p><code lang=\"null\">static void printXCoordOfUpperLeftPointWithPatterns(Rectangle r) {\n    if (r instanceof Rectangle(ColoredPoint(Point(var x, var y), var c),\n                               var lr)) {\n        System.out.println(\"Upper-left corner: \" + x);\n    }\n}\n</code></p><p>此外，嵌套模式的引入通过提供解构嵌套数据结构的能力，进一步实现了这一点。它们使开发人员能够集中处理错误，因为整个模式只有匹配和不匹配两类。这样就不需要检查和处理每个单独的子模式匹配故障了。</p><p>这些嵌套模式也可以很好地与<a href=\"https://openjdk.org/jeps/441\">JEP 441</a>\"引入的switch表达式配合使用。switch表达式的模式匹配增强了switch语句，允许在case标签中使用模式。这使得代码更具表现力，并减少了由于switch语句中的遗漏case而导致缺陷的可能性。</p><p>例如，考虑以下的声明：</p><p><code lang=\"null\">class A {}\nclass B extends A {}\nsealed interface I permits C, D {}\nfinal class C implements I {}\nfinal class D implements I {}\nrecord Pair(T x, T y) {}\n\nPair<i> p;\n</i></code></p><p><i>使用记录模式和枚举switch，我们可以执行以下操作：</i></p><p><i><code lang=\"null\">switch (p) {\n    case Pair<i>(C c, I i) -&gt; ...\n    case Pair<i>(D d, C c) -&gt; ...\n    case Pair<i>(D d1, D d2) -&gt; ...\n}\n</i></i></i></code></i></p><p><i><i><i>然而，这些更新带来了一些风险和假设。与任何语言的更改一样，其存在影响现有代码库的风险。此外，这些更改假设开发人员熟悉记录类和模式匹配，而这两个特性对Java来说相对还较新。</i></i></i></p><p></p><p><i><i><i>展望未来，有许多方向可以扩展记录模式。其中包括可变变量记录的varargs模式、匹配任何值但不声明模式变量的未命名模式，以及可以应用于任意类而不仅仅是记录类的值模式。</i></i></i></p><p></p><p><i><i><i>总而言之，在Java中引入记录和嵌套模式是该语言的一次重大飞跃。它允许更具声明式的编码风格，从而产生更干净、更易于理解的代码。虽然存在一些风险，但潜在的好处能使它成为Java未来版本中一个很有前途的特性。</i></i></i></p><p></p><p><i><i><i>原文链接：</i></i></i></p><p><i><i><i><a href=\"https://www.infoq.com/news/2023/05/java-gets-boost-with-record/\">https://www.infoq.com/news/2023/05/java-gets-boost-with-record/</a>\"</i></i></i></p><p></p><p><i><i><i>延伸阅读：</i></i></i></p><p><i><i><i><a href=\"https://www.infoq.cn/article/wxcjbFtvT7Twva0eeXTj\">JEP 444：JDK 21 中出现虚拟线程，开创并发新纪元</a>\"</i></i></i></p><p><i><i><i><a href=\"https://www.infoq.cn/article/PyfmlboNJMKzlhZTwDL3\">加入有序集合，Java 集合框架变得更加完善</a>\"</i></i></i></p>",
    "publish_time": "2023-05-31 18:37:03",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Rust综述：生态系统的当前趋势和缺陷",
    "url": "https://www.infoq.cn/article/2Jvvh3pE289XkgwNAbyW",
    "summary": "<p>Rust生态系统会定期通过众多的开发者调查进行探索。仔细阅读这些调查报告可以深入了解社区和技术的潜力。例如，大多数Rust开发人员是最近才开始使用该语言的，这可能是一个信号，表明雇主应该审查他们的工作描述，不要再指望应聘者能有10年的Rust经验。</p><p></p><p>该社区正在迅速发展。虽然行业的采用率略有落后，<a href=\"https://www.thurrott.com/windows/282471/microsoft-is-rewriting-parts-of-the-windows-kernel-in-rust\">但科技巨头已经铺平道路了。</a>\"我们还识别了工具中的薄弱环节，主要在测评分析和调试支持方面，与这些领域中普遍存在的稚嫩技术有关。</p><p>在本文中，我们将分享关于Rust社区和生态系统的发现和见解，并将详细阐述使用Rust启动新项目或从其他语言迁移到Rust的独特性和陷阱。</p><p></p><h2>Rustaceans</h2><p></p><p>有多少Rust开发者（或Rustaceans，他们自称为Rustaceans）？尽管统计开发人员并不是一门精确的科学，但我们有一些估算。在<a href=\"https://www.slashdata.co/blog/state-of-the-developer-nation-23rd-edition-the-fall-of-web-frameworks-coding-languages-blockchain-and-more\">《SlashData 23届开发者国家状态报告》</a>\"（2022年第三季度）中，SlashData估算的Rust开发者数量为280万，是JavaScript社区规模的1/7，不到C/C++社区规模的1/4。</p><p>该调查报告还显示，这一数字在过去两年中增加了两倍，使其成为增长最快的开发者社区之一。那它还有增长的潜力吗？</p><p></p><p>根据<a href=\"https://survey.stackoverflow.co/2022/\">《Stack Overflow 2022开发者调查》</a>\"，在没有使用过Rust的开发人员当中，有17.6%的人想要使用它，这使得Rust成为开发者社区最受期待的语言。考虑到当前的趋势以及该技术的年龄尚轻，它的未来看起来还是很光明的。</p><p></p><p>Rust社区还很年轻。根据JetBrains发布的<a href=\"https://www.jetbrains.com/lp/devecosystem-2022/\">《2022年开发者生态系统状态报告》</a>\"，在将Rust作为主要语言的开发者中，有60%的人年龄在30岁以下。</p><p></p><p>Rust团队的《2021年Rust状态调查报告》称，有一半的开发人员在任何一门编程语言中的编程经验都不超过10年。</p><p></p><p>我们也来看看Rust开发人员的背景编程经验。关于其所使用的其他编程语言，《Rust状态调查》确定了以下几大类（可能交叉）Rust开发人员群体：</p><p>41%的Rust开发人员认为自己是动态类型语言（JavaScript、Python、PHP等）的专家。27%的人认为自己是具有垃圾收集功能的面向对象的静态类型语言（Java、C#、Go等）的专家。20%的人认为自己是手动内存管理语言（C、C++等）的专家。</p><p></p><p>《Stack Overflow调查》还<a href=\"https://survey.stackoverflow.co/2022/#section-worked-with-vs-want-to-work-with-programming-scripting-and-markup-languages\">报告了大量对使用Rust感兴趣</a>\"的JavaScript、TypeScript、Python、Java和C++开发人员。有趣的是，C开发人员并不那么倾向于Rust，但考虑到<a href=\"https://www.infoq.com/news/2022/12/linux-6-1-rust/\">最近Linux关于内核开发的政策发生了变化</a>\"，以及在其他主要基于C的项目（例如<a href=\"https://daniel.haxx.se/blog/2022/02/01/curl-with-rust/\">curl</a>\"）中支持Rust的趋势，这种情况可能会改变。</p><p>根据《2022年开发者生态系统状态》的Rust部分，只有5%的Rust开发人员使用该语言的时间超过了3年。大约一半的Rust项目是纯粹的Rust项目，而其他项目则是与JavaScript/TypeScript（22%）、Python（15%）、C++（12%）、Go（12%）和C（11%）以及其他语言共享代码库。在GitHub上搜索以Rust作为主要语言的流行代码库会发现，其中20%的代码库还包含Python代码，另有20%包含JavaScript。</p><p></p><p>根据这些数据和我对Rust社区的观察，我猜想它正在增长，这要归功于大量具有Python和JavaScript背景的年轻人正在转向他们的第一门系统编程语言。这类语言很难学习，但会为他们带来全新的软件开发体验。像C和C++这样的老语言对他们来说没有那么吸引人，但Rust有。</p><p></p><h2>技术领域和行业采用</h2><p></p><p>Rust团队的调查显示，服务器端（后端）项目是Rust的主要技术领域。云计算基础设施和应用程序是应用Rust的另一个巨大领域，而分布式应用程序也是Rust社区的热门选择。</p><p></p><p>Linux是最具针对性的平台（占77%，而Windows和macOS分别占41%和36%）。WebAssembly占22%，而嵌入式系统仅占11%。Rust在移动应用程序中的使用基本上可以忽略不计。</p><p></p><p>对于Rust项目，CLI工具比GUI应用程序更受欢迎。这可以归因于生态系统中CLI库的主要供应，而GUI库则不太常见。根据《2022年开发者生态系统状态调查》，46%的Rust开发者将其用于CLI工具的开发。</p><p>有一个技术领域，虽然在展示Rust应用程序时非常重要，但仅仅从数字上看可能并不那么容易看出：那就是为其他编程语言提供的工具。我们可以看到，在JavaScript和Python社区中都使用Rust来作为开发高性能的替代方案，以替代当前可用于这些语言的工具。像<a href=\"https://deno.land/\">deno</a>\"（一个JavaScript和TypeScript运行时）和<a href=\"https://github.com/charliermarsh/ruff\">Ruff</a>\"（一个Python linter）这样的项目就是这种趋势的很好的例子。这些开源项目表明，Rust在提供高性能和高开发速度的同时也吸引了大量的贡献者。使用编程语言来开发工具有着悠久的传统。Rust非常有效地打破了这一传统。</p><p></p><p>微软、谷歌、亚马逊和Meta等科技巨头都<a href=\"https://engineering.fb.com/2022/07/27/developer-tools/programming-languages-endorsed-for-server-side-use-at-meta/\">推崇</a>\"并<a href=\"https://foundation.rust-lang.org/members/\">支持</a>\"Rust。尽管如此，《2022年开发者生态系统状态调查》报告称，大多数Rust开发人员在工作之外使用Rust。只有18%的受访者在他们正式工作中使用Rust来开发软件。在Rust团队的调查中，只有不到一半的受访者认为自己使用Rust是高效的。在同一调查中，只有不到一半的受访者每天都在使用Rust。这些数字表明，其他人仍在学习Rust，或者偶尔将其作为爱好用于个人项目。</p><p></p><p>各种网站上的招聘信息并不能让我们得出这样的结论：有成千上万的中小型公司有兴趣雇佣Rust开发人员。在Rust团队的调查受访者中，只有15%的人表示他们的公司在大量项目中使用Rust，而另有18.5%的人认为它只在少数项目中使用。似乎在公司中引入Rust的主要方式是通过从其他语言中重写非关键组件，或者在Rust中启动一个新的非必要项目来衡量其有效性。Rust社区正在积极讨论关于过渡到Rust或启动新项目过程中的<a href=\"https://www.infoq.com/presentations/rust-adoption-journey/\">成功案例</a>\"和<a href=\"https://mdwdotla.medium.com/using-rust-at-a-startup-a-cautionary-tale-42ab823d9454\">失败案例</a>\"。</p><p></p><p>开始Rust之旅需要公司拥有一些具有长期Rust经验的高级工程师来监督过渡。正如我们已经强调的那样，社区中缺乏这种类型的开发人员。幸运的是，随着时间的推移，这个问题会自动得到解决。</p><p>《2021年Rust状态调查》将Rust在行业中的使用不足确定为首要问题。然而，这种情况有望改变。</p><p></p><h2>语言和工具</h2><p></p><p>Rust的一大优点是它兑现了自己的承诺。内存安全允许消除某些类型的错误。谷歌将安卓系统中关键漏洞数量的下降部分<a href=\"https://security.googleblog.com/2022/12/memory-safe-languages-in-android-13.html\">归因于</a>\"采用Rust作为C++的内存安全替代品。Rust的性能使亚马逊在能源效率方面<a href=\"https://aws.amazon.com/blogs/opensource/sustainability-with-rust/\">具有可持续性</a>\"。降低CPU使用率和有效的内存管理都是Rust语言特性的成果。</p><p></p><p>70%的在工作中使用Rust的开发人员强烈赞同Rust的性能特征（如速度、内存占用等）会影响其采用。其中64%的人看重Rust的安全性和安全特性。大约80%的人同意Rust可以帮助他们实现自己的目标，并能弥补采用成本。65%的开发人员认为Rust语言和标准库文档写的很棒。这些数字解释了为什么Rust<a href=\"https://survey.stackoverflow.co/2022/#section-most-loved-dreaded-and-wanted-programming-scripting-and-markup-languages\">连续七年成为最受欢迎的语言</a>\"，根据Stack Overflow的调查，87%的开发人员表示他们想继续使用Rust。Rustaceans忠于Rust，与开发人员本身相比，Rust更能说明语言及其质量。</p><p></p><p>38%的Rust团队调查受访者一致认为，与其他编程语言相比，Rust的编程要复杂得多。62%的人认为它的学习需要付出更多的努力。他们还担心情况会变得更加复杂。这是调查受访者对Rust未来的第二大担忧。</p><p></p><p>所有的调查都一致认为，由<a href=\"https://rust-analyzer.github.io/\">rust-analyzer</a>\"提供支持的Visual Studio Code是最流行的Rust编写IDE。大约一半的Rust开发人员都在使用它。亚军是由我们的<a href=\"https://intellij-rust.github.io/\">IntelliJ Rust插件</a>\"提供支持的JetBrains IDE（CLion、IntelliJ IDEA和其他），根据调查的不同，份额从25%到40%不等。Vim/Neovim是第三大最受欢迎的选择。三分之二的Rust开发人员认为他们的IDE体验很棒或足够好。</p><p></p><p>当深入到开发体验的细节时，调查显示，问题最多的部分是调试和测评分析。32%的《2022年开发者生态系统状态》调查受访者提到他们怀念本机调试体验。29%的Rust团队调查受访者认为调试体验可以更好。超过一半的Rust开发人员使用println风格的调试作为调试代码问题的主要方式，其中三分之一的开发人员只使用这种方法。</p><p></p><p>代码评测分析体验更差；超过80%的Rust开发人员根本不使用性能分析工具。其中一个原因可能是目前可用的工具都很难用，而且它们的发现也很难解释。侧重于分析的教材也多有缺失。开发人员似乎很乐意盲目地相信Rust的性能而不进行实际地检查。随着Rust在行业中的普及，这种态度可能会成为一个关键问题。评测分析工具本身和学习资料都需要认真努力地加以改进。</p><p></p><p>不幸的是，现有的调查还没有进入Rust库。关于库生态系统缺失的部分，我们还没有很好的数据。作为一项年轻的技术，会存在技术完整性的问题，但考虑到Rust良好的互操作性，这从未被认为是一个关键问题。</p><p></p><h2>结论</h2><p></p><p>和调查中经常出现的情况一样，这些结果既支持了一些有趣的结论，也破坏了一些著名的理论。以后一种情况为例，这些结果表明，最初认为Rust是C/C++杀手的观点在今天看来似乎并不相关。我们没有证据表明在现有的代码库中C/C++代码被大量替换，我们也不希望这种情况在未来发生。为什么呢？因为C和C++都可以继续工作。C++正在发展，长期存在的问题正在得以解决。根本没有必要用Rust重写所有内容。此外，也没有足够的劳动力来做这件事。尽管如此，现在用C或C++启动一个新项目仍需要仔细考虑。Rust也可能是该项目的一个不错选择，尤其是当目标平台是Linux并且你关心性能和安全性时。</p><p></p><p>社区成员的年轻化预示着Rust有着光明的未来。它不会消失，而且在该行业的采用率将继续上升。随着经验丰富的Rust开发人员数量的增长，我们将看到更多的纯Rust项目的出现。科技巨头已经上了Rust的船，我们预计中小企业很快就会效仿。</p><p></p><p>Rust工具正在不断发展，世界各地的许多爱好者和公司都在为工具生态系统做出贡献。</p><p></p><p>要想用Rust高效工作，需要对其概念有深刻的理解，尤其是在所有权、内存管理和并发方法方面。用Rust高效编程需要专门的学习和培训。这就是为什么让精通其他编程语言的开发人员切换到Rust的常见做法可能比切换到其他语言更成问题。从任何语言转换都需要改变很多习惯。不要指望开发人员自己掌握这些概念并迅速养成新习惯；相反，应该事先对他们进行教育和培训。</p><p></p><p>原文链接：<a href=\"https://www.infoq.com/articles/rust-ecosystem-review-2023/\">https://www.infoq.com/articles/rust-ecosystem-review-2023/</a>\"</p><p></p><p>延伸阅读：</p><p><a href=\"https://www.infoq.cn/article/HdhHwuPQk4FCdPBpmdlP\">Azure CTO： Rust 已登陆 Windows 11 内核</a>\"</p><p><a href=\"https://www.infoq.cn/article/z4MCCu8W62Je7d2fED7p\">Rust 语言 2022 年度回顾：全球企业如何采用 Rust？</a>\"</p><p><a href=\"https://www.infoq.cn/article/hioW21XT8opvbip3hs5F\">Rust 语言 2022 年度回顾：开源生态发展</a>\"</p>",
    "publish_time": "2023-05-31 19:08:01",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Mobvista 技术 VP 兼首席架构师蔡超，确认担任 ArchSummit 深圳专题出品人",
    "url": "https://www.infoq.cn/article/4epMtIAXgEE98y4X4p4Z",
    "summary": "<p>7&nbsp;月&nbsp;21&nbsp;日&nbsp;-&nbsp;22&nbsp;日，&nbsp;在&nbsp;<a href=\"https://archsummit.infoq.cn/2023/shenzhen?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">ArchSummit&nbsp;全球架构师峰会（深圳站）</a>\"，Mobvista&nbsp;技术&nbsp;VP&nbsp;兼首席架构师蔡超，将担任「大模型时代的实践与思考：重塑传统研发方式及技能」的专题出品人，在此次专题中，你将了解到在新的大模型时代下，我们如何应对传统研发方式的变革，以及如何充分发掘和培养新技能。</p><p></p><p>蔡超拥有超过&nbsp;15&nbsp;年的软件开发经验，其中&nbsp;9&nbsp;年任世界级&nbsp;IT&nbsp;公司软件架构师/首席软件架构师。2017&nbsp;年加入&nbsp;Mobvista，任公司技术副总裁及首席架构师，领导公司的数字移动营销平台的开发，该平台是国内最大，全球前十的全栈式移动广告平台，其完全建立于云计算技术之上，每天处理来自全球不同区域的超过&nbsp;2000&nbsp;亿次的请求。&nbsp;</p><p></p><p>蔡超也将在大会上发表题为《提高可测试性：大模型时代的软件设计与自动化测试实践》的主题分享，探讨如何使程序更具可测试性，并重点介绍软件设计和实现的关键要素。</p><p></p><p>相信蔡超的分享，可以帮你掌握编写具有可测试性及支持大模型的软件的关键方法和原则，为项目实践提供可靠的指导思路。</p><p></p><p>除上述专题外&nbsp;，ArchSummit&nbsp;深圳还将围绕<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1537?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">基础架构技术</a>\"、<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1536?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">智能化数据治理</a>\"、<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1532?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">DataOps、Data&nbsp;Fabric&nbsp;等高效数据开发与服务模式</a>\"、<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1534?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">Mesh&nbsp;技术实践案例</a>\"、<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1535?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">QUIC&nbsp;传输和架构优化</a>\"等进行分享。</p><p></p><p>数十位业界专家，上百个国内外一线大厂前沿技术案例，一定会给你带来很多全新的开发灵感。期待与你线下交流！&nbsp;现在购票，享&nbsp;8&nbsp;折特惠，立省&nbsp;¥1760！咨询购票请联系&nbsp;18514549229（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9d/9d6a27547062ee2e089f91bdc4ba1eaa.png\" /></p><p></p>",
    "publish_time": "2023-05-31 19:19:25",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "多层网关已成过去，网关多合一成潮流，网关改造正当时｜Higress 1.0 正式发布",
    "url": "https://www.infoq.cn/article/Ez2pf3Zcv0fmeSwzeF3s",
    "summary": "<p></p><p></p><p></p><h2>前言</h2><p></p><p></p><p>K8s 通过 Ingress / Gateway API 将网关标准化，逐步将安全网关、流量网关、微服务网关内聚，解决从单体到微服务到云原生多层网关的复杂度，合久必分，分久必合，多层网关已成过去，网关多合一成潮流，成为 K8s 开发者和微服务开发者共同关心的话题。</p><p></p><p></p><h2>Higress 1.0 正式发布，即官方推荐生产可用</h2><p></p><p></p><p>Higress 是阿里云开源的下一代网关，从 2022 年 11 月在云栖大会上宣布开源，走过大半年时间，发布了 GA 版本 1.0.0，即官方推荐生产可用。回顾 Higress 的发展历程，经历了三个阶段：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/19/1948e8a9c426dc841c4ab0a3485bbb60.png\" /></p><p></p><p></p><h4>Higress 的技术选型和首次业务落地（2020.05~2020.11）</h4><p></p><p></p><p>Higress 的创建源于阿里内部的“本地生活战役”，核心技术目标是实现阿里巴巴业务域与蚂蚁业务域之间 RPC 直接调用，但因阿里巴巴与蚂蚁业务域网络是隔离的，即网络是不通的，很自然想到利用网关来解决此问题。利用网关来解决阿里巴巴与蚂蚁跨业务域 RPC 互通问题，首先要对网关做技术选型。选型期，除了关注技术方案是否完美支持 HTTP/gRPC 协议、支持丰富路由策略以及是否业内主流技术，还关注是否支持热更新。</p><p></p><p>热更新是我们的核心关注点。</p><p></p><p>Tengine/Nginx 的配置更新需要 reload，reload 需要重启 worker 进程，重启时会引起流量抖动，对长连接影响尤为明显。在网关的集群规模非常大时，更是不能随意的做 reload，这时就会引发一个矛盾点：业务向网关提交配置后，希望能快速验证，但受限于 reload 机制和稳定性要求，无法满足业务快速验证与快速试错的诉求。</p><p></p><p>如何解决这点呢？</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/46/46e79580b603bb6e0d76b4af3e5982bb.png\" /></p><p></p><p>一是采用两层网关，即流量网关 + 业务网关；二是实现网关原生支持配置热更新。除了对比不同方案的优劣势，我们也调研了 Envoy 作为网关在业界的趋势，结论是目前 Envoy 作为 K8s 中的 Ingress Provider 增长最快的事实（Ingress Provider 指 K8s Ingress 规范具体实现，因 K8s Ingress 自身只是规范定义，是 K8s 下外部流量进入集群内部的网关规范定义），我们最终选择了 Envoy 来实现两层网关，并完美支撑双 11 大促每秒数十万的请求流量。</p><p></p><p></p><h4>Higress 的重要演进和服务更多业务场景（2020.12~2021.10）</h4><p></p><p></p><p>随着在阿里巴巴和蚂蚁的成功落地，越来越多的业务场景找到了我们。</p><p></p><p>这个过程中，Higress 实现了东西向、南北向全域流量的调度分发，东西向上不仅支持跨业务域的蚂蚁 RPC 互通，也扩展到了混合云的云上云下 RPC 互通场景，覆盖钉钉文档、阿里视频云、达摩院的店小蜜、智慧数字人等。</p><p></p><p>2021 年，阿里巴巴开启了中间件三位一体战役，目标是用云产品支撑集团业务。我们开始将孵化成熟的 Higress 技术沉淀为云产品，即目前阿里云上提供的 MSE 云原生网关，一方面面向广大的公有云用户提供托管的网关服务，另一方面也对内服务集团。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/32/321406215913334b172c2f0aeb33a271.png\" /></p><p></p><p></p><h4>Higress 对外开源，通过社区力量加速发展（2021.11~ 至今）</h4><p></p><p></p><p>随着 Higress 成为云产品服务于更多外部用户，我们逐步发现用户对 Higress 提出了更高的要求，其中反馈较多的大的需求点是插件扩展、Waf 防护、多注册中心、Nginx Ingress 注解兼容以及 HTTP 转 Dubbo 协议，当然也有很多小的需求点在此就不一一列出，因此该阶段我们重点发力在上述用户反馈的高频需求。</p><p></p><p>开源已经成为软件发展的必然趋势与快速路径，因为社区的力量是非常强大的。</p><p></p><p>因此我们将这套经过内部实践沉淀下来的网关方案 Higress 正式对外开源，以 Kubernetes Ingress 网关为契机带来了流量网关与微服务网关融合的可能性，结合阿里内部实践沉淀 Higress 实现了流量网关 + 微服务网关 + 安全网关三合一的高集成能力，同时深度集成了 Dubbo、Nacos、Sentinel 等，能够帮助用户极大的降低网关的部署及运维成本，而且能力不打折。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/44/44aa1d9370342df0eb407df4c58b4f41.png\" /></p><p></p><p></p><h2>为什么 Higress 能替代多层网关，成为下一代网关</h2><p></p><p></p><p>Higress 是 标准化、高集成、易扩展、热更新的云原生网关。无缝集成容器和微服务生态，是云原生时代的默认选项。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/06/06a1c50d1c883356610d50533027c955.png\" /></p><p></p><p></p><h4>高集成，连接微服务生态</h4><p></p><p></p><p>Envoy 提供了 EDS/DNS/STATIC 等多种类型的 Cluster，Higress 基于此具备了对接多种服务发现的能力，可以实现：</p><p></p><p>通过 Nacos 发现服务 （EDS）通过 Zookeeper 发现服务 （EDS）通过 K8s Service 发现服务 （EDS）通过 DNS 域名发现服务 （DNS）通过配置静态 IP 发现服务 （STATIC）</p><p></p><p>通过 Higress 控制台可以很方便地进行相应的服务发现配置：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/1e/1e8fc06436c365b5137f8821b094f5b0.png\" /></p><p></p><p>随着云原生技术的发展，不少企业开始从传统架构向云原生架构演进，但这过程中传统架构部署的服务无法被 K8s 的 Ingress 发现并路由成为一个阻塞点，导致业务架构无法平滑地向云原生平滑演进。Higress 依托于 Nacos 等注册中心的能力，无论服务是否部署在 K8s 集群内，都可以发现服务并进行请求路由。如上图所示，业务在迁移过程中，可以通过 Higress 将 5% 的灰度流量导入部署在 K8s 上新架构的服务中，进行灰度测试验证，逐步切流，从而实现业务架构平稳升级。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e2/e238455f608d6b7e327931aca20e8368.png\" /></p><p></p><p>对于灰度能力，Higress 实现了和 OpenKruise Rollout 进行联动，可以实现服务灰度发布。整个 Rollout 过程，可以实现自动整合 Deployment、Service、Ingress 一起工作，并向用户屏蔽底层资源变化。用户无需手动编辑多个 K8s 资源，即可轻松使用金丝雀发布，A/B Test 等灰度机制。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/26/2629c9513939feb4a839ac324f786ff8.png\" /></p><p></p><p></p><h4>易扩展，提升网关的业务使命</h4><p></p><p></p><p>将插件的生命周期划分为三个阶段：</p><p></p><p>插件开发阶段分发集成阶段运行生效阶段</p><p></p><p>Envoy 提供的 Wasm 插件机制，解决了插件运行生效阶段的问题，基于 ECDS 配置更新机制，插件代码和配置发生变更均不会导致连接断开，并且插件运行在安全沙箱中，即使代码逻辑出现空指针等异常，也不会导致网关发生 Crash。</p><p></p><p>在插件开发阶段，Higress 基于 Proxy Wasm 生态提供了更容易上手的 C++ 和 Go 语言的 Wasm 插件 sdk，在 sdk 中封装了插件路由和域名级生效的机制，开发者只需关心插件配置解析和运行逻辑即可，在分发集成阶段，Higress 定义了 Wasm 插件的 OCI 镜像规范（<a href=\"https://higress.io/zh-cn/docs/user/wasm-image-spec%EF%BC%89%EF%BC%8C%E5%B0%86%E6%8F%92%E4%BB%B6%E7%9A%84\">https://higress.io/zh-cn/docs/user/wasm-image-spec），将插件的</a>\" README 文档，配置字段约束信息，以及 Wasm 文件等一起打包在一个 OCI 镜像中，可以通过支持 OCI 格式的镜像仓库进行存储和拉取。并且可以通过 Higress 控制台快速启用插件：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/48/483c15037d8d3e233ac969e9448d1198.png\" /></p><p></p><p>Higress 的插件机制和传统的基于 OpenResty Lua 扩展的插件机制最本质的区别，也是往往最容易被开发者忽略的是插件分发集成的环节。传统的 Lua 插件扩展机制，插件自身的版本生命周期是跟着网关的版本走，插件版本更新，以及自己开发插件都需要重新部署网关。而 Higress 依托于 OCI 镜像进行网关插件的版本管理和分发，实现了插件版本生命周期和网关版本的解耦，用户只需调整一行插件 OCI 镜像地址，即可完成插件的热更新，整个过程网关连接不会发生断开，流量完全无损。</p><p></p><p>基于此，在网关上的业务插件逻辑可以很方便地实现热更新。Higress 也基于此能力提供了很多业务认证和安全相关的官方插件，开箱即用。</p><p></p><p></p><h4>标准化，降低改造综合成本</h4><p></p><p></p><p>因为 Envoy 是面向配置管理服务器设计的配置系统，对程序友好，对手写配置并不友好。因此像 Istio 设计了 VirtualService/DestinationRule/AuthorizationPolicy 等等 CRD 抽象，来解决 Envoy 配置复杂的问题，Istio 的 CRD 本身是解决 ServiceMesh 下复杂的服务治理场景而设计，而对于网关路由场景，更多用户需要的是 Ingress 这样更简单的 API 标准。</p><p></p><p>Higress 结合阿里内部实践以及阿里云产品沉淀，积累了基于 Ingress API 的丰富的路由策略扩展能力，同时还兼容大部分 Nginx Ingress 能力，并且可以通过 Higress 提供的控制台来创建路由，开箱即用：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/95/95c93a5e5ca52ad1cfa2396751f66605.png\" /></p><p></p><p>Higress 控制台目前对接的底层模型是 Ingress API，如果你对 Gateway API 有了解，会发现 Higress 控制台上的路由模型，也完全可以用 Gateway API 进行描述：</p><p></p><p><code lang=\"properties\">apiVersion: gateway.networking.k8s.io/v1beta1\nkind: HTTPRoute\nmetadata:\n  name: foo\nspec:\n  parentRefs:\n  - name: foo-example\n  hostnames:\n  - \"foo.example.com\"\n  rules:\n  - matches:\n    - path:\n        type: PathPrefix\n        value: /foo\n      headers:\n      - type: Prefix\n        name: x-higress-header\n        value: hi\n      queryParams:\n      - type: Exact\n        name: higressQuery\n        value: hi\n      method: POST\n    backendRefs:\n    - name: foo-service\n      port: 5678\n\n</code></p><p></p><p>Gateway API 标准目前还处在 beta 阶段，尚未完全定稿，生产使用我们更多还是建议用户使用 Ingress API，避免后续 Gateway API 标准改动带来 Breaking Change。Higress 对 Gateway API 的支持正在开发中，可以看到基于上面的模型，借助 Higress 控制台可以帮助用户屏蔽底层 API 路由标准的代际差异，实现路由从 Ingress API 平滑迁移到 Gateway API，根治对技术标准追赶的焦虑。</p><p></p><p>K8s 带来了云原生的路由标准 Ingress/Gateway API，如同 POSIX 定义 Unix 可移植操作系统标准，历时 35 年经久不衰，云原生的路由标准的生命周期一定会远超过 K8s 本身。</p><p></p><p></p><h4>热更新，提升接入层稳定性</h4><p></p><p></p><p>Higress 基于 Envoy 引擎，为适应现代应用和微服务架构的需求，对传统流量网关（本文以 Nginx 为例）的不足之处进行改进，实现了真正的配置热更新，并让流量网关和微服务网关的融合成为可能。</p><p></p><p>Nginx 的配置变更 reload ，会导致 downstream 和 upstream 连接都断开触发重连，在高并发场景下，downstream 并发重连将导致 Nginx 的 CPU 飙升，最严重的还是 upstream 的并发重连，很可能打垮后端业务程序的线程池，造成雪崩。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/14/14c29cb88c793484d17114adc41c3d61.png\" /></p><p></p><p>而 Envoy 依托于精确的配置变更管理，做到了真正的热更新。在 Envoy 中 downstream 对应 listener 配置，交由 LDS 实现配置发现；upstream 对应 cluster 配置，交由 CDS 实现配置发现。listener 配置更新重建，只会导致 downstream 连接断开，不会影响 upstream 的连接；downstream 和 upstream 的配置可以独立变更，互不影响。再进一步，listener 下的证书 (cert)，过滤器插件 (filter)，路由 (router) 均可以实现配置独立变更，这样不论是证书 / 插件 / 路由配置变更都不再会引起 downstream 连接断开。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/71/713402b7409bd1d177ed21a9c23e4eb6.png\" /></p><p></p><p></p><h2>Higress 生产实践最佳参考</h2><p></p><p></p><p></p><h4>可观测</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/16/16541edb97400bb063efe254dd027d28.png\" /></p><p></p><p>Higress 提供了自带的 prometheus 和 grafana 可以开箱即用，同时也支持对接用户自建的监控系统，详细请参考：《基于 Prometheus 实现 Higress 流量观测》：<a href=\"https://higress.io/zh-cn/docs/user/prometheus\">https://higress.io/zh-cn/docs/user/prometheus</a>\"</p><p></p><p></p><h4>安装部署</h4><p></p><p></p><p>可以使用 Helm 一键完成 Higress 的生产安装部署</p><p></p><p><code lang=\"typescript\">helm repo add higress.io https://higress.io/helm-charts\nhelm install higress -n higress-system higress.io/higress --create-namespace --render-subchart-notes --set higress-console.domain=console.higress.io\n\n</code></p><p></p><p>通过增加 helm 参数 --set global.local=true 可以在本地 PC 环境基于 k3s/kind 等工具，进行全功能测试和试用：</p><p></p><p>详情可以参考：</p><p></p><p>《Higress Quickstart》：<a href=\"https://higress.io/zh-cn/docs/user/quickstart\">https://higress.io/zh-cn/docs/user/quickstart</a>\"</p><p></p><p>《Higress 安装部署》：<a href=\"https://higress.io/zh-cn/docs/ops/deploy-by-helm\">https://higress.io/zh-cn/docs/ops/deploy-by-helm</a>\"</p><p></p><p></p><h4>微服务生态集成</h4><p></p><p></p><p>不论 Dubbo/SpringCloud 服务是否部署在 K8s 集群内， Higress 都可以实现对接。因此在 K8s 场景下，用户可以将 Nginx Ingress 这类流量网关和 Spring Cloud Gateway 这类微服务网关合并，统一替换为 Higress。</p><p></p><p>《Higress 对接 Dubbo 服务》：<a href=\"https://cn.dubbo.apache.org/zh-cn/overview/what/ecosystem/gateway/higress/\">https://cn.dubbo.apache.org/zh-cn/overview/what/ecosystem/gateway/higress/</a>\"</p><p></p><p>《Higress 对接 SpringCloud 服务》：<a href=\"https://higress.io/zh-cn/docs/user/spring-cloud\">https://higress.io/zh-cn/docs/user/spring-cloud</a>\"</p><p></p><p></p><h4>性能压测数据</h4><p></p><p></p><p>Higress 和 Nginx 对比，在 HTTP1 上会略逊一筹，但在现代化协议如 gRPC/HTTP2 上则比 Nginx 好很多。</p><p></p><p>《gRPC 吞吐是 Nginx 的 4 倍》：<a href=\"https://gist.github.com/johnlanni/aac7480c17b0fde05fa64a20fc93b165\">https://gist.github.com/johnlanni/aac7480c17b0fde05fa64a20fc93b165</a>\"</p><p></p><p>而如果你使用的是 K8s Nginx Ingress，因为其 Lua 代码性能较差，即使在 HTTP1 场景下，Higress 性能也更好，具体数据可以参考：</p><p></p><p>《K8s 网关选型初判》：<a href=\"https://xie.infoq.cn/article/0a2c9ac4ed139bc28f881d7c3\">https://xie.infoq.cn/article/0a2c9ac4ed139bc28f881d7c3</a>\"</p><p></p><p></p><h4>企业用户落地</h4><p></p><p></p><p>Higress 自从 4 月份发布 1.0.0 RC 版本以来，在社区有大量用户进行安装和测试，帮助 Higress 变得更成熟，并且适应了更多系统和安装环境。同时有多家企业完成了 Higress 技术的落地。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/55/55328326593dc1f44dca0f93d3514018.png\" /></p><p></p><p>开源软件的发展离不开社区用户的实践，用户的参与和贡献是推动开源项目成功的关键因素。在这里，我们欢迎更多的社区用户加入 Higress 实践落地的行列！欢迎到 Higress GitHub issue（<a href=\"https://github.com/alibaba/higress/issues/1%EF%BC%89%E7%99%BB%E8%AE%B0%E4%BF%A1%E6%81%AF%EF%BC%8C%E7%A4%BE%E5%8C%BA%E5%B0%86%E9%82%80%E8%AF%B7%E6%82%A8%E5%8A%A0%E5%85%A5\">https://github.com/alibaba/higress/issues/1）登记信息，社区将邀请您加入</a>\" Higress 落地支持群，我们会为落地用户提供指导和帮助。</p><p></p><p></p><h2>社区：回顾和展望</h2><p></p><p></p><p>Higress 一路走来，保持一个月发布一个版本的频率，一共完成了 183 个 PR 的合并，发布了 13 个 Release，完成了 5 个里程碑：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/8b/8b78b0458883698c7d27c5ce81265883.png\" /></p><p></p><p>Higress 在 1.0 版本 GA 后，将继续保持高投入，并快速迭代。社区未来三个大版本的核心功能规划如下：</p><p></p><p>1.1 版本（6 月）实现 HTTP2RPC API支持非 K8s 场景下使用1.2 版本（7 月）支持和 Skywalking 等更多可观测生态集成完整实现 Gateway API1.3 版本（8 月）实现 API 管理产品形态建设推出独立的 Wasm 插件集市项目</p><p></p><p>其中 Wasm 插件生态会作为 Higress 社区长期重点投入方向，目前在中科院开源之夏 /CCF 编程之夏 / 云原生编程挑战赛等活动中均有 Higress Wasm 插件相关的项目推出，完成项目既能收获项目奖金，还能收获开源荣誉，欢迎有兴趣的同学参与。</p><p></p><p>今日好文推荐</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651170234&amp;idx=1&amp;sn=efe169627d1a41fc773c86dc288bfdee&amp;chksm=bdb85de98acfd4ff4bf22db05d13cd3ed1cde112f3bd1c4fa1fd40b5fa70160c06e75c61a662&amp;scene=21#wechat_redirect\">百度回应 Bing 成中国桌面搜索第一；阿里回应大裁员传闻；文心一言市场负责人怒怼科大讯飞｜Q资讯</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651170127&amp;idx=1&amp;sn=51d90d5f6743b2026b273cb3ffab2a99&amp;chksm=bdb85d1c8acfd40ae97e45286c4746aed63de72edd9a577b6e1e6efdf393d9337118de9fab3c&amp;scene=21#wechat_redirect\">中国的“贝尔实验室”：我们的数据库从内核的第一行代码写起</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651169756&amp;idx=1&amp;sn=2352752c53d20368a6f332f4ff6514b7&amp;chksm=bdb85b8f8acfd299ee630c5abef8369476f0b75097d7c18d405d42399f8d358893c8ebbfcf8b&amp;scene=21#wechat_redirect\">微软Copilot“杀疯了”：Windows引入AI助手、Bing接入ChatGPT，弯道超车的机会来了？</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651169428&amp;idx=1&amp;sn=f851adfbd87ac750ff463e5bcd27033a&amp;chksm=bdb85ac78acfd3d1d6feb3898297dbb27393f5cd062398e78fb37f424a3885152de4f5fff620&amp;scene=21#wechat_redirect\">一个价值70亿美元的教训！如何避免平台工程变成“大灾难”？</a>\"</p><p></p><p></p><p></p>",
    "publish_time": "2023-05-31 20:45:18",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]