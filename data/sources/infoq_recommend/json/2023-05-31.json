[
  {
    "title": "云绑定应用：实现业务逻辑，减轻开发者负担",
    "url": "https://www.infoq.cn/article/bc2s3cFS2UOgCmHCgVAJ",
    "summary": "<p>随着对<a href=\"https://www.diagrid.io/blog/evolution-of-cloud-computing\">应用为先</a>\"的云服务采用愈发广泛，应用与云服务的融合程度也到了前所未有的深度。应用程序和云运行时的边界从虚拟机转移到了容器和函数中。集成边界从仅使用数据库和消息代理访问，转换成应用程序的机械部分在云中的混合运行。在这些因素影响下的架构中，应用程序与“云绑定”，应用逻辑与管理责任转移至云服务中，允许开发者专注于业务逻辑。</p><p>&nbsp;</p><p>本文中将分析，通过使用具备灵活性和可移植性的公开 API 和标准将应用程序与云服务绑定，所带来的软件全栈平价化。</p><p></p><h2>内部架构的演变</h2><p></p><p></p><p>应用程序的内部架构通常归属于单一团队掌控。内部的边界则由所选编程语言、运行时、工具，以及包、模块、接口、类、函数等抽象协助开发者进行控制。<a href=\"https://martinfowler.com/bliki/DomainDrivenDesign.html\">领域驱动设计</a>\"（DDD）协助开发者构建领域模型，用抽象概念封装服务业务逻辑，缓解业务实际与代码之间的鸿沟。</p><p>&nbsp;</p><p><a href=\"https://alistair.cockburn.us/hexagonal-architecture/\">Hexagonal</a>\"、<a href=\"https://jeffreypalermo.com/2013/08/onion-architecture-part-4-after-four-years/\">Onion</a>\"，以及 <a href=\"https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html\">Clean</a>\" 架构可以与 DDD 相<a href=\"https://herbertograca.com/2017/11/16/explicit-architecture-01-ddd-hexagonal-onion-clean-cqrs-how-i-put-it-all-together/\">互补</a>\"，以不同边界与外部基础设施依赖划分应用程序代码。虽然这些方式最初都是颇具创新意识且时至今日仍然适用，但这些架构的设计初衷只考虑了包含 JSP、Servlet、部署于共享应用运行时的 EJB 这三层的 Java 应用程序，当年设计的重点还是应用逻辑与 UI、数据库解耦，实现独立测试方面。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7b/7b2660b0979f4d1dffdcbf12c57eec85.png\" /></p><p></p><p>图一：内部应用架构</p><p>&nbsp;</p><p>后来，微服务、<a href=\"https://12factor.net/\">十二因素</a>\"应用程序等新挑战、新概念层出不穷，应用程序的设计方式也受此影响。微服务的核心是将应用逻辑切分为归属单一团队的独立可部署单元，十二因素应用程序方法意在构建可在动态云环境中运行、扩展的分布式无状态应用。这些架构所引入的原则和最佳实践改写了我们构建应用程序内部架构并管理的方式。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/18/186eb84291ac96f0c7c328cfc8d033f3.png\" /></p><p></p><p>图二：应用程序架构演变时间线</p><p>&nbsp;</p><p>在应用程序架构演变时间线的后半段，容器的采用和 Kubernetes 的引入成为主流，彻底改变了应用打包、协调的方式。AWS Lambda 引入了高度可扩展的功能即服务（FaaS）的概念，将应用程序细粒度概念再度拔高，将完整的基础设施管理责任卸至云供应商。其他如服务网格、<a href=\"https://www.infoq.com/articles/multi-runtime-microservice-architecture/\">Mecha 架构</a>\"等技术潮流的出现，网络和分布式开发者基元等非功能性应用栈平价化并剥离至 sidecar 中。受微服务启发，数据网格架构设计意图将应用程序的数据分析架构拆分至更小的独立数据域中，让每个域都有自己的项目和团队。再加上近期的应用为先云服务等等，这一系列技术潮流开始重塑应用程序的外部架构，本文中我将这些统一称为“云绑定应用”。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>外部架构演变</h2><p></p><p></p><p>外部架构是应用与其他团队和组织以专门的内部中间件、存储系统，或云服务等形式拥有的其他应用和基础设施交互的部分。应用与外部系统相连并卸除部分责任的方式构建了外部架构。为充分利用基础设施，应用需要与该基础设施绑定，确立明确分界线以保留其敏捷性。应用的内部架构和实现应独立进行修改，并在不变动内部的情况下与云服务等外界依赖关系互换。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7c/7c37818055195a38e324b7ab10b34892.png\" /></p><p></p><p>图三：外部引用架构</p><p>&nbsp;</p><p>大体上来说，我们可以将应用程序与其周围环境相绑定的方式分为两类。</p><p>&nbsp;</p><p>计算绑定，包含所有必需的绑定、配置、API，以及程序在 Kubernetes、容器服务，乃至无服务功能（如 AWS Lambda）等计算平台中运行所用的协议。多数情况下，这些绑定对内部架构是透明的，配置更多是为运维团队而非开发所用。容器抽象目前是最广为人知的应用计算绑定“API”。集成绑定，覆盖范围非常广，从除计算绑定外的其他绑定，到应用的外部依赖关系。云服务同样利用这类绑定与应用交互，常见形式是通过定义完善的 HTTP “API”或专门的消息和存储访问协议，如 AWS S3、阿帕奇卡夫卡、Redis API 等等。集成绑定没有运行时绑定的透明度，开发者也需要实现额外的相关逻辑，如重试、TTL、延时、死信队列（DLQ）等等，并将其与应用的业务逻辑相绑定。</p><p>&nbsp;</p><p>云上运行的应用会通过这些绑定消费其他服务，下面让我们这些绑定背后究竟都是些什么。</p><p></p><h2>计算绑定</h2><p></p><p></p><p>从理论上来说，所有应用程序对运维团队而言都是需要在计算平台上操作的黑盒单元。计算绑定是用于管理应用在 Kubernetes、AWS Lambda 及其他服务平台上的生命周期。这类绑定均是规范化，以配置集合加上应用与其所运行的平台间交互的 API 的形式进行定义。多数交互都是对应用透明的，只有少数 API 需要开发者自行实施，如健康端点和指标 API。这是目前 CNCF 对此的<a href=\"https://github.com/cncf/toc/blob/main/DEFINITION.md\">定义</a>\"，也是“云原生”概念所囊括的范围，开发者只需实现云原生应用，就能将其绑定在云计算平台上运行。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/36/3629b982b603e17c83dff1132a83ea4a.png\" /></p><p></p><p>图四：应用与平台的计算绑定</p><p>&nbsp;</p><p>为让云平台上的运行更为可靠，应用必须在规范到最佳实践等多个层面与平台绑定。这一过程是通过一系列业界标准规范的实现的，如容器 API 和指标 API、基于普罗米修斯（Prometheus）的健康端点、AWS Lambda 或 AWS ECS 等云供应商规范。此外，还有云原生的最强技术和共享知识，如健康检查、部署策略和安置政策。让我们再看看目前最常见的计算绑定方式。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h3>资源需求</h3><p></p><p></p><p>无论是微服务还是功能，应用总会对 CPU、内存和存储等资源有所需求。根据所用的平台不同，资源的定义也会不同。举例来说，Kubernetes 上 CPU 和内存是通过<a href=\"https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\">请求和限制</a>\"定义的，而 AWS Lambda 则是由用户<a href=\"https://docs.aws.amazon.com/lambda/latest/dg/configuration-function-common.html\">指定</a>\"运行时需要分配的内存大小和对应 CPU。不同平台对存储的处理方式也是各异，Kubernetes 使用短期存储和卷，而 Lambda 则提供短期资源抓取和基于亚马逊 EFS 挂载的持久存储。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h3>生命周期钩子</h3><p></p><p></p><p>由平台管理的应用程序通常需要对重要的生命周期事件有感知。举例来说，Kubernetes 中的概念（如容器初始化）和钩子（如容器启动后钩子 PostStart 和容器结束前钩子 PreStop）就可以让应用对这些事件做出反应。同理，Lambda 的<a href=\"https://docs.aws.amazon.com/lambda/latest/dg/runtimes-extensions-api.html\">扩展</a>\" API 也能让应用处理初始、调用、关闭阶段。其他处理生命周期事件的方式包括脚本封装或针对特定语言的运行时修改选项（比如 JVM 的关闭钩子）。这些机制为平台与应用程序之间形成协议，使其能够响应并管理自身的生命周期。</p><p>&nbsp;</p><p></p><h3>健康检查</h3><p></p><p></p><p>健康探针是平台用于监测应用程序健康状况并按需采取对应行动（如重启应用程序）的方式。虽然出于请求短暂的生命周期，Lambda 函数没有<a href=\"https://cloud.google.com/run/docs/configuring/healthchecks\">健康探针</a>\"，但容器化应用程序和Kubernetes、AWS EKS，GCP 云运行等协调器却可以在其定义中涵盖健康探针，让平台上的应用运行更为顺利，出现问题时也能及时采取行动。</p><p>&nbsp;</p><p></p><h3>部署和置放策略</h3><p></p><p></p><p>在获得所需资源后，计算平台可以开始管理应用程序的生命周期了。若想在不破坏业务逻辑完整性的前提下管理生命周期，平台必须要能意识到扩展的限制所在。部分程序只会是单体程序，比如，平台需要维护事件处理的顺序，且不能将其扩展超过一个实例。其他有状态应用可能受法定人数（Quorum）驱动且需要维持指定数量的最小实例，函数才能正常运行。再有，无状态函数可能会倾向于快速扩展以解决负载中不断增长的额峰值。一旦确定了应用程序的扩展方式，平台便能控制应用程序实例的启动和终止。</p><p>&nbsp;</p><p>计算平台同样提供包括滚动、蓝绿、金丝雀、一次性等多种部署策略，用于控制服务的更新顺序。除了部署顺序外，平台可能还支持用户指定置放策略。比如 Kubernetes 提供标签、污点（Taint）、容忍度、亲和性、反亲和性等选项，而 Lambda 则允许用户在区域置放和<a href=\"https://aws.amazon.com/lambda/edge/\">边缘置放</a>\"类型中进行选择。这些平台的偏好选择确保了应用程序的部署，且与预期合规性和性能要求相符。</p><p></p><h3>网络流量</h3><p></p><p></p><p>将低层级网络流量导向服务实例同样是计算平台的责任之一。平台所负责处理的部署顺序、置放，以及自动扩缩容都会影响流量向服务实例的引导。健康检查在流量管理中也发挥着作用，如 GCP 云运行和 Kubernetes 中的<a href=\"https://cloud.google.com/run/docs/configuring/healthchecks\">就绪检查</a>\"。通过处理这些任务，计算平台能够协助确保流量是高效且有效地路由到适当的服务实例。</p><p></p><h3>监测与报告</h3><p></p><p></p><p>任何用于分布式应用程序的计算平台都必然以日志、指标、跟踪的形式提供深入的应用洞察。如今，在当前领域中也有了约定俗成的标准：日志最好为结构化格式，如 JSON 或其他业界特定标准。计算平台通常会收集日志或提供特殊日志清理和分析服务的访问扩展点。比如 Kubernetes 上的 DaemonSet、Lambda 的监控合作伙伴扩展、Vercel 的边缘函数日志 Drainer。计算平台必须要能支持指标、跟踪数据的收集和分析，才能针对分布式应用程序的性能和行为提供全面的洞察力。业界标准中有许多处理这类数据的格式和工具，如普罗米修斯的指标、<a href=\"https://opentelemetry.io/\">OpenTelemetry</a>\"（OTEL）的跟踪。计算平台或提供内置数据收集和分析工具，或提供扩展点允许专门服务访问这类数据。计算平台应支持任何细粒度（微服务或功能）或位置（边缘与否）的代码，对日志、指标、跟踪数据进行捕捉，并导出至其他优秀的云服务中，如 <a href=\"http://honeycomb.io/\">Honeycomb</a>\"、<a href=\"https://www.datadoghq.com/\">DataDog</a>\"、<a href=\"https://sysdig.com/\">Grafana</a>\" 等等。&nbsp;</p><p></p><h3>计算绑定的趋势</h3><p></p><p></p><p>计算绑定是对编程语言和应用运行时不可知的，主要为运维团队管理运行时的应用，而非为开发人员实施所用。</p><p>&nbsp;</p><p>虽然应用的大小和复杂度随单体应用或函数而不同，但基本都会封装在容器内，具有健康检查端点，实现了生命周期钩子，并有指标暴露。理解计算绑定有助于高效使用任何基于容器的计算平台，无论是企业内部的 Kubernetes 集群，还是 AWS ECS、谷歌云运行、Azure 容器应用等管理型容器服务，基于函数的运行时 AWS Lambda、GCP 函数等等，以及基于边缘运行时的 Vercel <a href=\"https://vercel.com/docs/concepts/functions/edge-functions\">边缘函数</a>\"、CloudFlare <a href=\"https://workers.cloudflare.com/\">工作者</a>\"、Netlify 边缘<a href=\"https://docs.netlify.com/edge-functions/overview\">函数</a>\"等等。这些开放和事实标准的 API 不仅能协助创建可移植应用程序，还能通过跨云供应商和服务提供方的操作方法和工具，避免被供应商锁定。</p><p></p><h2>集成绑定</h2><p></p><p></p><p>另一方面，集成绑定则是供开发人员而非运维团队使用。集成绑定以常见分布式系统的实现区域为中心，如服务调用、事件驱动交互、任务调度，以及有状态工作流协调。协助应用程序通过基于云的中间件形式服务，与专用存储系统及外部系统相连，在本文中我将这些服务统一称作“集成云”。与容器所提供的计算抽象类似，集成云提供了编程语言不可知集成抽象即服务。其基元与用例、应用实现、运行时和计算环境相独立。<a href=\"https://learn.microsoft.com/en-us/azure/architecture/patterns/retry\">重试模式</a>\"、<a href=\"https://www.enterpriseintegrationpatterns.com/DeadLetterChannel.html\">DLQ 模式</a>\"、<a href=\"https://microservices.io/patterns/data/saga.html\">Saga 模式</a>\"、服务发现、<a href=\"https://martinfowler.com/bliki/CircuitBreaker.html\">断路器</a>\"模式等等，都可以通过服务形式在集成云中被消费。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d1/d103b9a4bd4466a12ea065667d17bdc2.png\" /></p><p></p><p>图五：应用程序和平台的集成绑定</p><p>&nbsp;</p><p>目前尚不存在将所有主要模式都以独立功能形式暴露的纯集成云。早期的云服务可提供部分集成基元作为卡夫卡、Redis 等存储系统的功能，但却很少能有独立使用或与其他功能相结合的。少有的例外情况是 AWS 事件总线（EventBridge）和 Azure 事件网格等服务，允许与同一厂商的多个云服务同时使用，但不能直接使用其他供应商。这个领域的发展如此快速，虽然还有一些例子或空缺，但我相信在未来，这些空白一定能得到填补。应用程序必须与集成云服务相绑定才能运作，并将部分开发者肩头的责任卸载。以下我将介绍集成云服务的主要类型和绑定方面。</p><p></p><h3>集成需求</h3><p></p><p></p><p>与应用对资源的要求和对计算平台的部署和置放需求同理，应用也会对特定集成绑定有需求。这些绑定可通过声明性配置传入平台，也可在运行时通过代码交互激活。举例而言，应用程序可使用声明式和程序式<a href=\"https://docs.dapr.io/developing-applications/building-blocks/pubsub/subscription-methods/\">订阅</a>\" pub/sub 主题。AWS Lambda 函数可以通过配置声明式地订阅数据源，也可以通过客户端库或 SDK，以程序形式向集成平台发送注册或取消注册特定绑定请求。应用程序可订阅 cron 定时任务触发器，激活连接外部系统的连接器，修改配置等等行为，都是在集成云上进行的。</p><p></p><h3>工作流协调</h3><p></p><p></p><p>逻辑协调对持久性服务而言不仅是一种极为普遍的需求，还是将其外部化并作为服务消费的主要候选。因此，工作流协调是如今最为知名的集成绑定类型之一。这种服务的常见用途包括：用于服务和业务流程协调的 Saga 模式实现、AWS 编排函数（Step Function）、谷歌有状态函数、Azure 持久函数、谷歌工作流的任务分配等等。在使用这类绑定时，应用程序中的部分编排状态和逻辑被卸载至其他服务中。应用服务内部虽然还有状态和逻辑对状态进行管理，但其他的都放在了外部，比如其他云服务上。这代表了现今应用程序以独立单元的形式设计并操作方式的转变。未来的应用程序可能不仅仅只有<a href=\"https://queue.acm.org/detail.cfm?id=3415014\">数据在外</a>\"，集成也会被放在外部。随着对集成云采用的不断出现，更多的集成数据和逻辑将会存在于外部。</p><p></p><h3>临时触发器</h3><p></p><p></p><p>临时绑定是协调绑定中的一类基于时间的分类，具有单一目标，即根据给定策略在特定时间触发不同服务。类似的例子有：事件总线调度器、谷歌云调度器、Upstash Qstack 服务等等。</p><p></p><h3>事件驱动和消息服务</h3><p></p><p></p><p>这类绑定以事件存储形式卸载请求并解耦应用，但其应用如今也越发地不再局限于存储，而是向提供消息处理模式的方向扩展。除了事件存储，这类绑定也为开发者提供了死信队列、重试、延迟交付等各类基元，还有过滤、聚合、重新排序、基于内容的路由、窃听等等消息处理模式。其示例有：Confluent Cloud kSQL、AWS 事件总线、Decodable 数据管线等等。</p><p></p><h3>外部连接器</h3><p></p><p></p><p>这类绑定可协助应用连接至外部系统的同时，也可执行数据规范化、错误处理、协议转换、数据转换。示例有：Knative 源导入器、AWS 事件总线连接器、Confluent 云<a href=\"https://www.confluent.io/product/confluent-connectors\">连接器</a>\"、Decodable 卡夫卡连接器、AWS Lambda 源和目的地。</p><p></p><h3>健康检查</h3><p></p><p></p><p>健康检查是计算绑定中不可或缺的一环，健康检查失败通常会致使应用重启。集成绑定同样需要健康检查，但集成绑定中健康检查不会影响应用的运行时，只会告知集成云当前应用是否有能力处理与集成驱动的交互。失败的集成健康检查会中止集成绑定的过程，直至应用恢复健康才会恢复绑定。经常会出现计算和集成绑定使用同一应用端点进行检查，比如 Dapr 的应用<a href=\"https://docs.dapr.io/developing-applications/building-blocks/observability/app-health/\">健康检查</a>\"可以临时阻止消费者和连接器将数据推入不健康的应用。</p><p></p><h3>其他绑定</h3><p></p><p></p><p>许多其他的绑定类型也可被归为集成绑定。比如自省数据传入应用程序，指类似 Kubernetes 的<a href=\"https://kubernetes.io/docs/concepts/workloads/pods/downward-api/\">向下</a>\" API 或 Lambda 的<a href=\"https://docs.aws.amazon.com/lambda/latest/dg/configuration-envvars.html\">环境</a>\"变量等，通过简单机制将自省数据和元数据注入应用；配置和秘密绑定，指不仅在应用启动时将秘密注入，还可在任何配置更新时都推送至应用之中，如 Hashicorp Vault Sidecar <a href=\"https://developer.hashicorp.com/vault/docs/platform/k8s/injector\">注入器</a>\"、Dapr 的<a href=\"https://docs.dapr.io/developing-applications/building-blocks/configuration/configuration-api-overview/\">配置</a>\" API、Kubernetes 的<a href=\"https://servicebinding.io/\">服务绑定</a>\"规范。此外，不太常见的集成绑定模式还有分布式<a href=\"https://docs.dapr.io/developing-applications/building-blocks/distributed-lock/distributed-lock-api-overview/\">锁</a>\"，提供对共享资源的互斥访问。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h3>集成绑定趋势</h3><p></p><p></p><p>无论是长期运行的微服务还是短期的功能，容器都在逐渐成为应用程序打包和运行使用中最多最广的可移植格式。不过，集成绑定也可以被划分为不同的问题领域：事件驱动交互、有状态协调和状态访问，在底层存储和使用模式方面各有不同。举例来说，阿帕奇卡夫卡是事件日志的<a href=\"https://www.kai-waehner.de/blog/2021/05/09/kafka-api-de-facto-standard-event-streaming-like-amazon-s3-object-storage/\">事实标准</a>\"，AWS S3 API 用于文档访问、Redis 用于键值缓存、PostgreSQL 用于关系型数据访问等等。这些成为标准化的原因在于不断成长的生态系统，其中包含库、工具，以及围绕其所构建的种种服务，保证了相当程度的成熟度、稳定性、未来的向后兼容性。但是，这些 API 本身只局限于存储访问方面，常常需要开发者自行应对应用程序内的分布式系统挑战。随着软件的平价化，集成绑定也逐渐以服务形式可用。越来越多的无服务云服务提供了额外的集成能力，让应用程序可以绑定数据访问之外的东西。</p><p>&nbsp;</p><p>在这种模式下，云绑定应用通常在无服务计算基础设施中运行，和云原生基元一样。它与其他无服务的云服务相绑定，用于服务协调、事件处理或同步互动，如下所示：</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/67/678d173c03082faca797c5c34ff4ac7a.png\" /></p><p></p><p>图六：云绑定应用程序的生态系统</p><p>&nbsp;</p><p>一项将多数集成绑定和开发者关注的问题统一至开源 API 的项目是 CNCF 的 <a href=\"https://dapr.io/\">Dapr</a>\"。该项目提供了同步的服务调用、有状态的服务协调、异步的事件驱动的交互，以及以 API 为特定技术的连接器。与容器和 Kubernetes 作为计算抽象类似，Dapr 也是外部服务的抽象。此外，Dapr 也提供与底层云服务独立的集成功能，并经常需要在应用层实现，其中就有弹性策略、死信队列、<a href=\"https://github.com/dapr/dapr/issues/2675\">延迟交付</a>\"、跟踪、细粒度授权等等其他。Dapr 的设计是多边形且可在应用之外运行，在不改变应用内部架构的情况下，让外部依赖关系交换可以更轻松，正如其在六边形架构中描述的一样。虽然 Dapr 主要为开发者实施应用程序而用，不过在引入后 Dapr 也提高了分布式应用程序的可靠性和可观测性，为运维和架构团队提供了<a href=\"https://www.diagrid.io/blog/dapr-as-a-10x-platform\">整体效益</a>\"。关于这点更多信息，我将于今年后半年的 QConLondon 大会上<a href=\"https://qconlondon.com/presentation/mar2023/commoditization-software-stack-how-application-first-cloud-services-are\">讲述</a>\"“应用为先的云服务如何改变游戏”，欢迎通过线上或线下形式参与。</p><p></p><h2>后云原生应用</h2><p></p><p></p><p>云绑定的的出现代表了云原生从单纯解决计算问题到管理应用层需求的进步。随着云服务对应用栈的不断扩展，从基础设施向应用为先的转换，让这一趋势也在加速发展。这点从以开发者为中心的有状态协调、事件驱动应用基础设施、同步交互、基于云的开发和部署环境、无服务运行时等爆炸性云服务发展中也能一窥一二。这种向应用为先的云服务正在催生一种新的应用程序架构，其中越来越多的应用逻辑在云服务中执行。这种应用程序于第三方云服务的融合也让开发者们能将更多的责任卸载，但随之而来的还可能有对灵活性和敏捷性的限制，这些都会是不断变化的需求所必备的能力。为保持应用程序内部和外部架构的独立性，应用与云服务应在开发时以整齐的边界进行解耦，并在运行时使用定义明确的开放 API 和格式深度绑定。与容器和 Kubernetes 为计算提供了开放的 API 一样，我们需要为应用集成抽象提供开放的 API。这会使操作实践和工具以及开发模式、能力和实践具有可移植性和可复用性。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/cloud-bound-applications/\">What Are Cloud-Bound Applications?</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/9z8EK3keFuAmJ0NWm9hv\">微软推出Azure Developer CLI公开预览版，帮助开发者加速云应用开发</a>\"</p><p><a href=\"https://www.infoq.cn/article/3xRjcVaKD8zP1D43owc5\">全新 AWS Auto Scaling – 适用于云应用程序的统一扩展</a>\"</p><p></p>",
    "publish_time": "2023-05-31 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AIGC浪潮下，如何推动企业应用及落地？| InfoQ《极客有约》",
    "url": "https://www.infoq.cn/article/w6IoL0J8OBlcCC28SoPB",
    "summary": "<p>AIGC 是当前 AI 领域最热的技术话题，并在全球范围内掀起了一股热潮。可以看到，越来越多的企业开始重视 AIGC 相关技术创新和技术实践，并积极探索应用落地。有预测数据显示，到 2030 年，AIGC 的市场规模或将超过万亿人民币。</p>\n<p>那么，AIGC 技术典型的应用场景有哪些？不同行业如何落地 AIGC 应用？最适合大模型的商业模式是什么？未来会走向完全的 AIGC 吗？本期《极客有约》，我们邀请到了星汉未来联合创始人&amp;CPO 胡忠想老师，为大家分享 AIGC 浪潮下，企业应用及落地经验。</p>\n<p><strong>内容大纲：</strong></p>\n<ul>\n<li>为什么 AIGC 突然爆火？</li>\n<li>AIGC 技术典型的应用场景有哪些？</li>\n<li>不同行业如何落地 AIGC 应用？</li>\n<li>AIGC 最主要的应用价值是降本增效吗？</li>\n<li>这类大模型具体会如何改变我们的工作状态？</li>\n<li>企业在应用 AIGC 技术时如何应对治理挑战？</li>\n<li>目前 AIGC 已经达到大规模商业化的条件了吗？</li>\n<li>最适合大模型的商业模式是什么？</li>\n<li>AIGC 时代需要什么样的人才？</li>\n</ul>\n<p><strong>特邀主持：</strong></p>\n<p>姜雨生，微软软件工程师，负责微软资讯业务与 GPT 集成，曾负责微软广告团队基础设施搭建与维护工作。</p>\n<p><strong>嘉宾：</strong></p>\n<p>胡忠想，星汉未来联合创始人&amp;CPO。北航本硕，2012年加入微博，2015年作为技术负责人负责S级项目Feed核心业务的研发。2017年作为技术负责人带领团队完成公司级Weibo Mesh平台的研发并推广到多个核心业务，使得微博成为业界领先的Service Mesh实践者。2018年作为微博峰值热点应对项目的负责人，带领团队完成公司级热点应对联动机制的建设，保障了微博在后续多次热点事件中的稳定性。2021年作为联合创始人，成立星汉未来并任CPO。</p>\n<p>体验多款 AIGC 应用：<a href=\"https://apps.galaxy-future.com/#/platform/explore&amp;utm_source=c\">https://apps.galaxy-future.com/#/platform/explore&amp;utm_source=c</a></p>",
    "publish_time": "2023-05-31 10:09:33",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "DTDS 全球数字人才发展线上峰会圆满结束：数智升级是每个企业也是每个人的“必修课”",
    "url": "https://www.infoq.cn/article/uNkPRr16JO2m6qqVEGZ3",
    "summary": "<p>人才是驱动社会和经济发展的核心要素，是企业创新的基石。而不同的时代背景，往往会衍生出差异化的人才技能和劳动力结构需求。</p><p></p><p>世界经济论坛曾做过这样一个预判，&nbsp;“到2030年，我们需要对超过10亿员工进行再培训。”站在2030年的时间点，这10亿员工将代表着届时1/3的人才市场；站在眼下的时间点，数字化思维和能力提升，是企业人才储备和人才升级的确定方向，也是未来竞争力的关键所在。</p><p></p><p>2023年5月30日，以“人才为本，数智蝶变”为主题的<a href=\"https://www.infoq.cn/article/zBvRpHrTQY5pIgDNhm3J\">&nbsp;DTDS&nbsp;</a>\"全球数字人才发展线上峰会圆满结束。本次峰会由极客时间企业版、培训杂志联合主办，并得到了GHR&nbsp;环球人力资源智库、InfoQ&nbsp;极客传媒、TGO&nbsp;鲲鹏会、保利威、online-edu在线教育资讯网、酷学院等行业媒体伙伴的大力支持。</p><p></p><p>在会上，来自德勤、东亚银行、南京钢铁、宁德核电等处于行业领先地位的数字化企业，从不同视角分享了对人才趋势的洞察，以及自身在数字化转型背景下，如何进行人才战略制定和人才体系建设。此外，极客时间企业版也在会上发布了&nbsp;AI&nbsp;未来教育学习产品，并深度解读了与培训杂志联合推出的《<a href=\"https://app.jingsocial.com/microFrontend/leadGeneration/jsf-leads/list/contentMarketing/WEHsWZ8h4h3mf5sCez4feD/2ykbEVvnAyg6cH24W64rug\">中国企业数字人才发展白皮书</a>\"》。</p><p></p><h2>洞察与实践</h2><p></p><p></p><h4>“岗位”边界消失，技能将替代岗位</h4><p></p><p></p><p>根据<a href=\"https://www2.deloitte.com/cn/zh.html\">德勤</a>\"2023年全球人力资本趋势研究发现，企业正在失去传统的边界，这意味着他们熟悉的管理秩序将会逐渐消失，企业需要经过探索、试点和创新去定义管理的新法则。德勤中国管理咨询合伙人秦芹女士表示，面对众多挑战，人才建设将成为企业数字化转型最为核心的要素；而面对数字化转型带来的人才需求，企业不得不重新思考“人才从何而来、人才能力重塑”的问题。</p><p></p><p>秦芹重点围绕“组织”和“人”两个维度介绍了企业如何在“无边界世界”实现良性发展：一方面，企业必须构建能力型组织。随着“岗位”的边界消失，技能将替代岗位，成为员工和工作的连接点。对于企业而言，需要健全人才能力标签体系，从而更好的选人、识人、用人，最大化发挥员工价值。另一方面，企业也需要不断提升数字化人才能力，通过搭建数字化人才画像，实现能力和技术的共同提升。</p><p></p><h4>东亚银行（中国）有限公司数字化人才实践</h4><p></p><p></p><p>作为一家拥有百年历史的港资银行，<a href=\"https://www.hkbea.com.cn/PersonalBusiness/\">东亚银行</a>\"（中国）有限公司（以下简称“东亚中国”）于2021年全面启动数字化转型，并始终秉承数字发展，人才先行的理念，走出一条适合自己的数字化人才“认证+自培养”模式和路径，为银行持续输送具备数字化背景的业务骨干和管理人才。</p><p></p><p>据东亚中国行长助理李燕青女士在会上介绍，2021年，东亚中国构建了映射行内职级和岗位职责的数字化产品经理、数据分析、数据治理、数据工程四大序列，明确了集12大维度为一体的数字化专业人才的能力画像。2022年，又进一步推动数字化人才专业认证体系——“数赢”专业资格认证，面向全行符合数字化岗位背景的员工，推出“1+3”认证培养体系——即一套数字化人才晋升培养机制&nbsp;+&nbsp;三阶段资格认证。</p><p></p><p>同期，东亚中国还率先在外资银行推出“数赢”培训生DT计划，旨在通过建立“严筛选、精培养、持续陪伴、重实践”为一体的数字化复合型人才培养机制，优选数字化专业背景的应届生。</p><p></p><p>而围绕“认证+自培养”体系，过去一年多，东亚中国还构建并开展了包括“科技赋能月”系列、“融课堂数字化”系列、引入母行“Fintech&nbsp;101”课程、数赢杯赛一系列数字化文化普及活动，形成了从行管理层到行员对转型工作的高认可度和强共识性，极大程度地提升了数字化转型的效率。</p><p></p><h4>南京钢铁数字化人才实践</h4><p></p><p></p><p>当然，数字技术红利并没有止步于金融、互联网等这些数字原生基因更好的行业。如今，技术同样也在快速深入工业领域，推动制造业向高质量发展。</p><p></p><p><a href=\"http://www.njsteel.com.cn/\">南京钢铁</a>\"人才发展中心主任/高级经济师仲崇波表示，数字化人才是传统制造提质升级的关键因素，但是人才需求总量和缺口巨大，这也是摆在面前的实际挑战。为此，南京钢铁明确了“1+2+7”人力资源战略，致力于实现钢铁联合企业全球效能领先的目标，并据此思考数字化人岗匹配路径。</p><p></p><p>在这一战略目标指导下，南京钢铁构建了分类别、分阶段、分层级、全覆盖、精准培养的数字化人才培养体系，并绘制了名为“育龙计划”的人才发展地图。此外，南京钢铁还首创行业人力资源体系数字化序列，建立了数字化人才活水机制，通过构建职级对照体系，支撑数字化组织迭代进化。</p><p></p><h4>宁德核电数字化人才实践</h4><p></p><p></p><p>无独有偶，<a href=\"http://www.ndnp.com.cn/\">宁德核电</a>\"也是工业领域的数字化典型企业。自2021年至今，宁德核电的数字化从快速启动期迈进了关键转型期。中国广核集团福建宁德核电有限公司培训部经理、数字化转型组培训负责人徐锋涛强调，数字化转型一定要“转”，并且一定要按照自己的节奏“转”。而在这个过程中，数字化转型成功与否，与人才队伍建设密不可分。</p><p></p><p>徐锋涛在会上详细介绍了宁德核电的系统化培训方法（SAT），这套路径和方法覆盖从需求分析、大纲设计、材料开发到培训实施、效果评价五阶段，是宁德核电内部数字化人才梯队建设和人才培养规划非常重要的抓手。如今，宁德核电面向数字化，已经从战略、思维、执行三个层面梳理了11项人才能力维度，并且每个能力维度根据表现不同分为4个级别，从而构成了数字化人才胜任力模型。</p><p></p><h2>平台赋能与白皮书解读</h2><p></p><p></p><h4>用智能化手段重塑企业培训</h4><p></p><p></p><p>除了依赖内部的人才培养，越来越多的企业也在借助外部平台，加强和完善人才体系建设。</p><p></p><p>在极客邦科技联合创始人、<a href=\"https://b.geekbang.org/?utm_source=geektimeWeb&amp;utm_medium=menu&amp;utm_campaign=entranceplatform&amp;gk_source=2021090101_geektimeweb_menu\">极客时间企业学习服务</a>\"总经理司巧蕾女士看来，“以人为本”是数字人才培养的基本出发点。随着AI的持续发展，人工智能在教育领域的渗透程度越来越深入，这同样带来了学习场景的重塑。为此，极客时间也紧跟技术趋势，结合行业洞察，对好产品、好内容和好服务做了全面升级，利用智能化力量提高企业学习培训效率，加强企业综合竞争力。</p><p></p><p>以产品为例，极客时间聚焦平台功能，对定制岗位能力模型、AI测评、智能学习路径、AI学习助手、智能学习报告、AI制课六个方面进行了持续升级，打造面向全新的学习培训体验，致力于以AI赋能企业培训，助力数字人才发展提质增效。</p><p></p><p>以内容为例，极客时间还推出了一系列AIGC相关的课程和行动营，通过理论+实践的内容实现学习培训的闭环。上新的课程采取极客时间一贯坚持的PGC内容生产模式，邀请一线技术专家与极客时间的专业教研团队一起通过稳定、可复制的内容设计生产流程，打磨体系化精品课程。</p><p></p><h4>《中国企业数字人才发展白皮书》深度解读</h4><p></p><p></p><p>在风云变幻的数字时代浪潮下，极客邦科技始终保持着对市场的敏锐洞察。面向人才发展，极客时间企业版还于日前与培训杂志联合推出了《中国企业数字人才发展白皮书》。</p><p></p><p>极客邦科技内容总监、极客邦双数研究院首席研究员李佳女士表示，本白皮书研究了国内关于数字化和数字化人才发展的众多报告，并对近二十家企业进行了深入的访谈调研，收录了一批典型企业的数字化人才发展案例。从生态、成长和赋能的角度讨论中国企业的数字化人才发展，是这份白皮书最重要的特点。</p><p></p><p>首先，白皮书指出，产业集群数字化转型呈现出数字经济平台化生态化特征，而数字人才在生态中分层分布并保持流动的状态，数字化人才服务的平台化生态，将极大促进产业与人才融合发展；</p><p></p><p>其次，聚焦人才问题，白皮书指出，技术发展使得应用性人才培养更为便利，数字化领导人才是数字化转型的关键因素，复合型创新人才的市场需求也日趋明显；</p><p></p><p>此外，白皮书还强调，企业内平台化赋能已经成为数字化人才发展重要趋势，平台型企业建设使得数字人才赋能生态动力更强，数字化人才发展的自主性也更强。</p><p></p><p>基于这些趋势和观察，白皮书的最后还分类讨论了不同企业人才发展的重点和路径，并提出了数字化人才发展的七条建议。</p><p></p><h2>数智升级是每个人的课题</h2><p></p><p></p><p>总而言之，数字化转型的关键在于人，而不只是技术本身。如司巧蕾在演讲中所说，人才是数字化转型和应用的基石，数字人才培养的目标，是培养具有数字思维和数字技能的高素质人才，以满足企业数字化转型和发展的需求。</p><p></p><p>在这个过程中，数智升级不仅是企业的迫切需求，也是每一个人在这个时代必须要面对的问题。每个人都需要通过不断学习和自我提升，跟上时代的步伐，拥抱新技术，适应新的工作模式，以实现自身和组织的持续蝶变。</p><p></p><h4>&gt;&gt;&gt;&nbsp;福利通道</h4><p></p><p>扫描下图二维码即可领取《中国企业数字化人才发展白皮书》完整版</p><p><img src=\"https://static001.geekbang.org/infoq/50/500a368d20bda76142442a8a2da197e6.png\" /></p><p></p><p>关注「InfoQ数字化经纬」公众号，&nbsp;“追更”DTDS&nbsp;全球数字人才发展线上峰会完整演讲内容</p><p><img src=\"https://static001.infoq.cn/resource/image/d3/da/d31d4e0e474feb853493fb404102b3da.png\" /></p><p></p>",
    "publish_time": "2023-05-31 10:32:28",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "天翼云重磅发布AccessOne，为企业打造安全加速一体化服务",
    "url": "https://www.infoq.cn/article/zvVv1rgg6vLz8qeItxGB",
    "summary": "<p>5月30全国科技工作者日，以“连接世界从边缘开始”为主题的天翼云边缘安全加速平台发布会在线上顺利举办。会上，天翼云重磅发布边缘安全加速平台AccessOne（后称AccessOne），并深入介绍了产品四大能力，以及在教育行业的实践成果，为企业提供性能、安全、算力等满足不同场景需求的智能边缘网络。</p><p></p><h2>应对多重网络应用挑战，一体化服务成优先选择</h2><p></p><p></p><p>数字化转型进程中，新型产业在改善人们生活质量的同时，也对网络应用服务提出挑战。天翼云智能边缘事业部副总经理鄢智勇指出，首先，越来越多的数据和应用需在离数据源更近的位置进行实时处理和分析，满足对低延迟和高带宽的需求。其次，诸多企业应用程序可能分布在多云环境，安全防护也随之变得更加复杂。另外，全球化时代，企业更关注业务在全球范围内的可用性，并采取各种措施确保业务数据高速传输和处理。最后，攻击手段日益成熟、攻击范围不断扩大等变化，让传统网络和安全模型逐渐式微，产业亟需新的网络和安全模型来应对业务变化。</p><p></p><p>一体化解决方案以一体化平台实现工作组件间的紧密协作，构建更流畅、更高效的工作流程，简化了企业选择和部署过程，减少集成和交互操作挑战，成为企业应对多重网络应用挑战的优先之选。</p><p></p><p>AccessOne依托中国电信分布式边缘资源，基于CDN底座，将云原生安全能力注入分布式边缘节点，实现网络底层对性能、安全、算力原子能力编排，并以“安全与加速、零信任、边缘接入、开发者平台”四大产品能力，一站式响应客户加速与防护需求，助力政企轻松管理自身业务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a5/a55726c5b26776294ea8cd8d702e4766.png\" /></p><p></p><p></p><h2>AccessOne四大产品能力，助力企业轻松制胜边缘</h2><p></p><p></p><p>安全与加速能力方面，AccessOne将已有产品能力聚合在一起，并做了两方面升级。一是全球边缘节点全面升级，全球节点达到1800+。AccessOne通过多项技术实现静态内容就近交付及动态内容快速回源，显著提升源站性能。二是推动DDoS防护、Web防护、Bot防护等安全原子能力下沉边缘，在最靠近攻击发起的位置进行检测，将正常、安全的流量回源到服务器，避免网站服务器被恶意入侵，保障业务核心数据安全。</p><p></p><p>为了在不可信网络中构建信任的安全系统，AccessOne推出零信任服务，基于零信任安全理念和架构，依托天翼云边缘节点，以身份认证与动态评估为基础，打造全新的企业安全远程访问能力，提供更安全、便捷、统一的接入服务。通过零信任控制面服务，天翼云助力客户有效进行统一管控、策略下发，实现身份可信、设备可信和行为可信；通过零信任数据面服务，天翼云可为客户提供包括智能选路、解除安全威胁的全方位保障。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0a/0a9a41bf56d4875561109d6ade59af40.png\" /></p><p></p><p>全球化趋势下，越来越多的企业开始在海外市场拓展业务，如何使全球用户获得一致性网络访问体验及安全保障成为巨大挑战。AccessOne边缘接入服务通过多样、灵活的接入方式，可将任意用户请求安全接入至边缘网络的三网节点，实现全球范围内高速、稳定、安全的数据传输。</p><p></p><p>为助力客户加快业务上线时间，减轻研发人员负担，AccessOne推出开发者平台，提供易上手的开发者工具，丰富的编程语言生态，符合W3C标准的Service Worker API、Streams API、WebCrypto，可读可写、全球同步的边缘存储，帮助企业网站在边缘节点上完成自定义鉴权、访问控制、内容改写、内容生成以及AB测试。企业研发人员在使用开发者平台部署业务时，可彻底免去底层机器的运维和管理，极大地释放了人力成本。</p><p></p><h2>加速实践落地，天翼云赋能千行百业快速安全发展</h2><p></p><p></p><p>目前，AccessOne已成功应用在政务、金融、教育、游戏、电商等多个行业，在帮助用户高效应对网络攻击、保障业务零中断的同时，为办公应用提速增效。尤其在教育行业，AccessOne基于四大能力，一站式满足教育行业对于网站高可用、远程办公学习、跨境加速等不同场景的需求。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/08/08da2de8f68fb140dbfcb31551d45ca3.png\" /></p><p></p><p>以AccessOne在教育行业考试季应用为例，为帮助考试院、高校网络缓解访问压力，AccessOne通过动、静态加速能力减少回源访问量，大大提升了网站访问体验。天翼云要客行业中心总经理王晓东介绍，AccessOne可根据需求动态扩容，当某个应用节点故障时，快速将流量转移到其他节点上，保证服务的可靠性和稳定性。同时，考务查询、成绩查询涉及大量客户个人数据，在AccessOne平台上开启DDoS、WAF防护功能，可有效应对大流量攻击，保障客户数据安全。此外，AccessOne还适用于攻防演练、IPv6改造等场景，以完善的服务为教育行业的数字化转型注智赋能。</p><p></p><p>数字经济发展浪潮下，边缘业务规模激增，提升边缘侧应用与服务的稳定性、安全性成为企业实现繁荣发展的重中之重。面向未来，天翼云将不断优化自身技术实力，以更加安全、完善、经济的解决方案，持续助力客户应对多元业务需求和安全压力，携手共同制胜边缘，推动万物互联的时代早日来临。</p><p>&nbsp;</p>",
    "publish_time": "2023-05-31 11:06:34",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "字少事大！OpenAI 创始人等超350名大牛再签联名信，一句话声明简短有力：AI或引发灭绝风险",
    "url": "https://www.infoq.cn/article/ARJEOOh2M5oAmwRCpzfk",
    "summary": "<p></p><blockquote>应该像对待包括流行病和核战争等其他全球性迫切社会问题一样，缓解AI引发的灭绝性风险。</blockquote><p></p><p></p><h2>全球AI大牛又签署一封公开信</h2><p></p><p>本周二，人工智能安全中心（CAIS）发布了一份由OpenAI及DeepMind高管、图灵奖获得者及其他AI研究人员签署的简短声明，警告称他们的毕生成果可能会毁灭全人类。</p><p></p><p>CAIS表示，这份声明希望讨论“AI所带来的广泛且紧迫的风险”。</p><p></p><p>正所谓字越少、事情越大，声明内容只有一句：“应该像对待包括流行病和核战争等其他全球性迫切社会问题一样，缓解AI引发的灭绝性风险。”</p><p></p><p>在声明上签字的名人包括图灵奖获得者Geoffery Hinton和Yoshua Bengio、OpenAI CEO Sam Altman、OpenAI首席科学家Ilya Sutskever、OpenAI首席技术官Mira Murati、DeepMind CEO Demis Hassabis、Anthropic CEO Dario Amodei，以及来自加州大学伯克利分校、斯坦福大学和麻省理工学院的多位教授， 据悉，目前约超过 350 名从事人工智能工作的高管、研究人员和工程师签署了这份公开信。</p><p></p><p>作为风口浪尖上的人物，声明发表之际OpenAI掌门人Altman正访问全球，与各国元首就AI及其潜在风险展开讨论。5月初，Altman还参与了美国参议院关于AI行业的监管听证。</p><p></p><p>这份关于AI风险的模糊声明，很快激起了反对者的批评。</p><p></p><p>从内容上看，这份声明没有对AI做出确切定义、也没有提及要如何缓解灭绝风险，只是将这项工作放在了与其他全球性社会问题相同的高度。</p><p></p><p>但在另一份新闻稿中，CAIS进一步强调希望“设置护栏并建立相关机构，确保AI风险不会让人类措手不及。”</p><p></p><h2>2个月前，马斯克等人呼吁叫停AI研发</h2><p></p><p>2个月前，AI 领域数十人共同署名、科技富豪马斯克高调参与的一封公开信震惊世界。</p><p></p><p>今年3 月 22 日，生命未来研究所（Future of Life）向全社会发布了一封《暂停大型人工智能研究》的公开信，呼吁所有人工智能实验室立即暂停比GPT-4更强大的人工智能系统的训练，暂停时间至少为 6 个月。</p><p></p><p>马斯克、图灵奖得主 Yoshua Bengio、苹果联合创始人 Steve Wozniak、Stability AI 创始人兼CEO Emad Mostaque、DeepMind 高级研究科学家 Zachary Kenton、AI 重量级人物 Yoshua Bengio（通常被称为“AI 教父”之一）和该领域研究的先驱 Stuart Russell等上千名科技大佬和 AI 专家已经签署公开信。</p><p></p><p>公开信中提到，通过广泛研究和顶级 AI 实验室的调查认可，具备类人智能的 AI 系统很可能对社会和人类构成深远风险。正如广受推崇的阿西洛马 AI 原则中所述，高级 AI 可能代表着地球生命史上一场影响深远的变化，应给予相应的关注和资源进行规划和管理。但遗憾的是，我们并没有看到这种级别的规划和管理。最近几个月来，AI 实验室陷入了一场失控般的技术竞赛，全力开发和部署一颗颗愈发强大的“数字大脑”，但就连创造者自己都无法理解、预测或可靠地加以控制。</p><p></p><p>公开信认为，这种暂停应当对外公开且可加验证，涵盖所有关键参与者。如果未能迅速实施暂停，政府应介入并强制要求其暂停。各 AI 实验室和独立专家则应把握这次暂停，共同开发和实施一套用于高级 AI 设计和开发的共享安全协议，并由外部独立专家进行严格审计与监督。这些协议应确保依其构建的系统具备无可置疑的安全性。AI 研究和开发工作应当集中注意力，努力让目前最强大、最先进的系统变得更准确、更安全、更可解释、更透明、更稳健、更一致，也更加忠诚且值得信赖。与此同时，AI 开发商必须与立法机构合作，加快开发出强大的 AI 治理体制。</p><p></p><p>通过这封公开信可以看出，人们想要叫停更先进的AI系统的研发，无非是担心在缺乏有效监管的情况下，AI发展太快会为人类社会带来一系列潜在隐患和危险。更重要的是，AI太过强大了，发展到一定成程度时甚至人类都无法掌控它。</p><p></p><h2>AI伦理专家：并不Care这类警告AI风险的公开信</h2><p></p><p>但，长期关注AI伦理问题的专家，对这类公开信根本不感兴趣。</p><p></p><p>Hugging Face公司机器学习研究科学家Sasha Luccioni博士觉得CAIS的这封信如同儿戏：“首先，声明把AI的假想风险跟流行病和气候变化等现实威胁混为一谈，这只会扰乱公众的基本判断。这同时也是一种误导，只要把公众的注意力吸引到未来风险上，他们就会忽略当前的更多有形风险，比如AI偏见、法律纠纷和同意权等。”</p><p></p><p>作家兼未来学家Daniel Jeffries也发推称，“AI的风险和危害如今成了一种表明立场的游戏，每个人都想在这波风潮下扮演好人……问题是这么吵来吵去有用吗？看着挺好，但没人真正付出，完全是在浪费时间。”</p><p></p><p>CAIS是总部位于旧金山的非营利组织，目标是通过技术研究和宣传“减少AI引发的规模化社会风险”。其联合创始人之一Dan Hendrycks拥有加州大学伯克利分校的计算机科学博士学位，之前还曾在DeepMind实习。另一位联合创始人Oliver Zhang也时常在LessWrong论坛上发表关于AI安全的帖子。</p><p></p><p>在机器学习领域，一部分AI安全研究者总是担心比人类更聪明的超级AI将很快出现、脱离约束，要么控制人类文明、要么彻底消灭人类文明。**作为目前这波AI浪潮的发起者，OpenAI的基础安全工作也是围绕着这种“AGI”（通用人工智能）焦虑而展开。**换言之，AI末日论在科技行业中已经颇有市场。</p><p></p><p>但也有不少人觉得，签署这样一封内容含糊的公开信没有任何意义，无非就是让从业者们减轻一点内心深处的道德压力。Luccioni强调，“这群创造出AI技术的人参与声明，无非是给自己博取了个好名声。”</p><p></p><p>这里澄清一点，Luccioni和她的同事们并非认定AI毫无危害，而是觉得重点考虑未来的假想风险会让人们忽略目前客观存在的AI负面影响。这些影响正在带来棘手的道德难题，而科技巨头们却无视威胁、大肆出售相关产品。</p><p></p><p>Hugging Face首席伦理科学家Margaret Mitchell认为，“某些弱势群体已经因此受到伤害：基于AI的监控系统正强迫伊朗女性保持传统穿着，甚至对某些群体施以监视和软禁。”</p><p></p><p>尽管有朝一日，某种形式的先进AI也许确实会威胁到全人类，但批评者们认为2023年讨论这个问题还为时过早、不可能带来建设性的帮助。对于尚不存在的问题，如何开展研究？</p><p></p><p>Jeffries也发推重申了这一观点，“AI远期风险是种不切实际的幻想，我们无法解决并不存在的问题。这完全是在浪费时间，我们应当集中精力解决当下的问题，未来的事就交给未来去办。”</p><p></p><h2>AI“教父”Yoshua Bengio放话：面对毕生工作成果，我也很“迷茫”</h2><p></p><p>近日，在这封最新的公开信上签名的AI大牛科学家，Yoshua Bengio在接受采访中坦言，他开始对自己这一辈子的工作成果感到“迷茫”。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/88/88dabc234eada3d1459d3653bebd5f0b.png\" /></p><p></p><p>作为AI三大“教父”之一，他在该领域做出了不少开创性的贡献。而AI的发展方向和惊人速度正引发他的忧虑。Bengio教授表示自己曾经出于认同感而投身其中，但如今的状况却让他困惑不已。</p><p></p><p>“从情感上讲，身处AI领域内部的人们肯定都受到了冲击。“迷茫是真的，但我们还是得继续前进，必须参与其中、加入讨论、鼓励他人和自己一同思考。”</p><p></p><p>这位加拿大学者最近签署了两份声明，敦促对AI的未来风险保持谨慎态度。部分学者和行业专家已经发出警告，称AI发展过快可能导致这项技术被恶意人士滥用。即使抛开这一层，AI自身也有可能引发恶劣影响。</p><p></p><p>Bengio教授也加入了AI监管的行列，并表示他个人认为不该把AI的能力给予军方。Bengio教授认为，一切构建强AI产品的企业都应当注册报备。</p><p></p><p>“政府需要跟踪这些企业的活动，对工作内容展开审计，对AI产业起码也要像飞机、汽车或制药等领域一样施加监管。”</p><p></p><p>“我们还需要推动AI相关人员的资质认证……包括道德培训。大家可能不知道，计算机科学家很少能接触到这方面知识。”</p><p></p><h2>Geoffrey Hinton：曾表示痛悔毕生工作</h2><p></p><p>另一位AI“教父”Geoffrey Hinton博士也签署了Bengio教授参与的声明。</p><p></p><p>本月月初，有外媒报道称， Geoffrey Hinton 辞去了在谷歌的工作，并警告这一技术领域的持续发展或将带来巨大风险。</p><p></p><p>Geoffrey Hinton 作为“三位 AI 教父”之一，与另外两位合作伙伴共同获得了 2018 年图灵奖，旨在表彰他们为当前 AI 繁荣做出的基础性贡献。但如今的他却对自己投入一生的研究感到遗憾。</p><p></p><p>根据《纽约时报》对他的采访，Hinton在辞去在谷歌的工作，也终于可以畅谈 AI 技术背后的风险了。已经在谷歌工作十多年的 Hinton 表示，“我总在用这样的借口安慰自己：哪怕我自己不做，其他人也会这样做。但目前真的不知道要怎么防止坏蛋利用 AI 来作恶。”</p><p></p><p>虚假信息的传播只是 Hinton 眼下想要强调的风险之一。从长远来看，他担心 AI 会彻底消除一切需要大量记忆的工作，而随着其逐步编写并运行构成自身的代码，AI 也许会最终取代人类。</p><p></p><p>Hinton 在采访中指出，“其实不少人都相信，AI 实际上能够变得比人类更聪明，但大多数人认为这还很遥远。没错，我也曾经觉得还很遥远，没准要再过 30 年、50 年甚至更久。但现在，我显然没法再这么想了。”</p><p></p><p>在接受 BBC 采访时，他甚至提到 AI 聊天机器人已经构成“相当可怕”的威胁。&nbsp;“据我所知，目前的 IT 还不比我们聪明，但我相信它们很快就会超越人类。”</p><p></p><h2>不一样的声音：Yann LeCun对AI发展比较乐观</h2><p></p><p>不过AI领域也有不一样的声音存在。</p><p></p><p>第三位“教父”Yann LeCun与Bengio和Hinton共同凭借开创性贡献获得了图灵奖，但他的态度比较乐观，认为AI毁灭人类的警告有点言过其实。</p><p></p><p>还有人觉得在务虚讨论之前，应当先解决迫在眉睫的真问题。</p><p></p><p>AI公司Huggingface研究科学家Sasha Luccioni博士认为，社会应该关注AI偏见、预测性执法和聊天机器人传播错误信息等问题，她觉得这些都是“非常具体的现实危害”。</p><p></p><p>“我们应当关注这些问题，而不是深陷AI可能毁灭人类的假想泥潭。”</p><p></p><p>除了风险，AI也确实给人类社会带来不少福祉。上周，AI工具就发现了一种新型抗生素。而借助AI技术开发的微芯片，也让一名瘫痪男子能在意念控制下正常行走。</p><p></p><p>但好消息再多，也无法抵消人们对AI冲击各国经济的深远担忧。众多企业已经开始用AI工具取代人类员工，好莱坞编剧正就这个问题组织集体罢工。</p><p></p><p>Bengio教授在谈到AI现状时认为，“亡羊补牢，为时未晚。这就像应对气候变化问题一样。我们向大气排放了大量的碳，虽然不可能一夜之间就停止排放，但我们至少该认真想想当下能够做点什么。”</p><p></p><p>参考链接：</p><p></p><p><a href=\"https://www.bbc.com/news/technology-65760449?at_medium=RSS&amp;at_campaign=KARANGA\">https://www.bbc.com/news/technology-65760449?at_medium=RSS&amp;at_campaign=KARANGA</a>\"</p><p></p><p><a href=\"https://arstechnica.com/information-technology/2023/05/openai-execs-warn-of-risk-of-extinction-from-artificial-intelligence-in-new-open-letter/\">https://arstechnica.com/information-technology/2023/05/openai-execs-warn-of-risk-of-extinction-from-artificial-intelligence-in-new-open-letter/</a>\"</p><p></p><p><a href=\"https://www.infoq.cn/article/Y9rIogQk8Sjt33bLDMHk\">https://www.infoq.cn/article/Y9rIogQk8Sjt33bLDMHk</a>\"</p>",
    "publish_time": "2023-05-31 14:17:48",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "后CentOS时代，国产操作系统能否扛起大旗？",
    "url": "https://www.infoq.cn/article/zI9eP1qgSd6a1ALmXMrU",
    "summary": "<p>2020 年 12 月，CentOS 社区宣布 CentOS 服务器操作系统 8 和 7 系列分别于 2021 年底和 2024 年 6 月底停止服务。CentOS 停服对于国产操作系统而言，既有挑战，也有机遇。一方面，如何为国内用户提供 CentOS 停服之后的解决方案，平稳完成服务器操作系统和数据的迁徙是国内操作系统厂商必须要解决的难题；另一方面，CentOS 停服也有望加速国产服务器操作系统替代进程。</p><p>&nbsp;</p><p>那么，CentOS 的停服到底会带来哪些影响？国产操作系统能否扛起时代大旗？如何迁移到国产操作系统？近日，InfoQ《极客有约》邀请到了龙蜥社区产品生态总监张鹏程，为大家分享国产操作系统迁移实践经验。</p><p>&nbsp;</p><p>以下为访谈实录，完整视频参看：<a href=\"https://www.infoq.cn/video/li7m8YayKpF8iVACRoB6\">https://www.infoq.cn/video/li7m8YayKpF8iVACRoB6</a>\"</p><p></p><h2>云计算给操作系统带来了哪些改变？</h2><p></p><p>&nbsp;</p><p>姜雨生：近几年，国内外操作系统整体发展如何？有哪些值得关注的行业大事件？</p><p>&nbsp;</p><p>张鹏程：经过几十年的发展，<a href=\"https://www.infoq.cn/article/4lDxHRoqXbSw6zl29AEo\">操作系统</a>\"已成为一个相对成熟的产业领域。大家对桌面端常用的操作系统如Windows、macOS非常熟悉。在服务器端，Linux具有开源和免费的特性，广泛应用于服务器操作系统。</p><p>&nbsp;</p><p>由于我们今天的话题主要涉及服务器操作系统，因此我们将聚焦在近年来国际和国内两方面，讨论其中的标志性事件和发展趋势。首先看国际方面，最典型的标志性事件是Red Hat公司在2021年和2024年停止维护CentOS 8和CentOS 7的版本，并转向CentOS Stream作为上游版本。这意味着之前基于CentOS的企业级生态系统将受到重大影响，这是一个非常典型的国际标志事件。</p><p>&nbsp;</p><p>接下来，我想谈一下发展趋势。从十多年前云计算的兴起开始，经过了持续的发展，云计算已逐渐成熟。这种发展浪潮给操作系统领域带来了一种“降维打击”的趋势。一个典型例子是亚马逊在其云计算平台上提供的Amazon Linux，对红帽等操作系统市场地位造成了巨大冲击，形成了颠覆性效果。微软也将其Windows部门转移到了Azure云平台，这有助于操作系统技术在云上的演进和推广。这是过去几年持续发酵的产业发展趋势，国际上值得关注。</p><p>&nbsp;</p><p>国内方面，一个标志性事件是从2019年开始，国家产业主管部门组织了针对操作系统领域的原生开源社区的重大专项活动。随后，欧拉社区和龙蜥社区相继诞生。这一系列事件标志着国内在自主操作系统演进方面迈出了重要步伐，对国产操作系统的发展和应用推广非常有帮助。此外，在国内除了前面提到的云计算蓬勃发展外，围绕国产化的生态系统也是我们必须关注的发展趋势，这促使更广泛的自主创新，相信这对操作系统发展将产生深远影响。</p><p></p><h2>CentOS停服给国产操作系统带来的挑战与机遇</h2><p></p><p>&nbsp;</p><p>姜雨生：CentOS 是比较流行的 Linux 发行版之一，2020 年 12 月，CentOS 社区宣布 CentOS 服务器操作系统 8 和 7 系列分别于 2021 年底和 2024 年 6 月底停止服务。随着 CentOS 系列版本停服时间临近，现有 CentOS 以及衍生版用户会面临哪些风险？</p><p>&nbsp;</p><p>张鹏程：这个问题可能已经成为一个正在发生的状态。尽管CentOS 8用户群规模可能相对小于CentOS 7，但 CentOS 8 在2021年12月底已停止维护。对于CentOS 8 或者截止到2024年的CentOS 7，它们都将直接受到影响。随着社区停止服务，所有正在运行的版本在截止日期后将不再获得任何问题修复或升级维护。</p><p>&nbsp;</p><p>对于广泛使用存量运行 CentOS 系统的用户而言，这样的事实可能带来连带影响。如果系统因为一些 bug 导致不稳定、宕机甚至不可用的情况，很难获得及时修复。同时，由于潜在的安全漏洞没有及时修复，这些漏洞可能对使用 CentOS 的用户，特别是企业用户的系统安全和数据安全构成重大威胁。此外，许多用户由于商业需求而使用商业发行版本，但这些商业发行版本在过去的发展过程中也是基于 CentOS 演进而来。因此，CentOS 的停止维护因素可能间接导致一些依赖于 CentOS 的商业发行版本很难进行后续演进，这对使用者也会产生连带影响。</p><p>&nbsp;</p><p>姜雨生：CentOS 有广泛的行业用户基础，停服将导致操作系统迁移浪潮。有声音认为，CentOS 停服对于国产操作系统而言，既有挑战，也有机遇，请您分别谈谈其中的挑战与机遇？</p><p>&nbsp;</p><p>张鹏程：这个机遇和挑战，我认为可以看作是两面的。就像我们之前讨论的，它既包含挑战，也蕴藏着机遇。对于操作系统而言，一个非常核心的问题是操作系统的生态系统。因此，在我看来，最大的挑战和机遇都可能在于这个生态系统中。</p><p>&nbsp;</p><p>生态系统带来的挑战是我们现在使用的操作系统和相关的成熟硬件体系，以及上游的数据库、中间件和各种企业应用软件，大部分都是在欧美市场环境下经过数十年成熟发展和不断迭代形成的。在这个发展过程中，软硬件体系相互适配、优化和促进是相互融合的。在这个层面上，现在出现了一些风险和停服的迹象。如果要解决操作系统的替代方案，这个替代操作系统必须解决如何与国外成熟发展的软硬件软件生态系统良好兼容的问题。对于国内操作系统的发展来说，这是一个巨大的挑战，因为我们是在追赶的位置上。在这个过程中，还有许多非技术因素会直接产生影响。我相信这是我们国内从业者共同面临的问题，大家都在努力不断完善和解决。</p><p>&nbsp;</p><p>同时，我认为这个过程中也有很多机会，因为我们正处在一个发展浪潮中，这个浪潮带来了许多新的机会，影响着发展的变化。正如之前提到的，不论是云计算的发展还是国内自主创新的软硬件生态发展，都意味着在国内的许多行业领域，企业在解决自身发展问题的同时，考虑如何进行IT架构或技术升级来给业务产生更大的收益。我们现在有更多选择，可以使用创新的云生态系统以及国内产生的芯片、数据库和应用软件等，这些都构成了国内独特的生态系统。这些发展也是我们共同面临的机遇，因为在这个过程中，我们不再仅仅进行“苹果与苹果”的简单比较，而是在进行系统与系统的比较。国内伴随着我们快速发展和强大需求的机遇，可以帮助我们将上下游合作伙伴联合起来。通过在更广泛的应用领域中锤炼，我们能更快地使国内建立起的生态系统更加成熟。</p><p>&nbsp;</p><p>姜雨生：民生证券研究报告称，国内整体 CentOS 存量替代空间有望达到 148 亿元，这个数字符合您的预估吗？目前国内主要是哪些行业有操作系统迁移替换需求？迁移的主要原因是什么？</p><p>&nbsp;</p><p>张鹏程：这个问题可以从两个方面来看。您刚才提到的第一个方面可能是关于市场空间的判断。我认为不同机构或不同视角可能对统计口径有所差异。所以这个数字本身很难直接判断对错，它只是一个相对的指标，但确实能提供一些见解。判断服务器操作系统的市场规模，我们还可以参考服务器规模，每年国内的物理服务器出货量是一个相对确定且得到共识的数字。过去几年的情况，每年大约有300～400万台的服务器出货量。</p><p>&nbsp;</p><p>这么多年来，在操作系统领域中，CentOS一直处于主导地位。因此，国内物理服务器的使用规模至少应该达到百万级别，每年的存量不断累积。此外，考虑到过去5～10年，国内云计算从虚拟化发展到云计算，以及众多的虚拟机和类似容器的使用环境，综合考虑这些物理机、虚拟机甚至容器的部署规模，至少达到千万级别。如果将部署规模转化为市场空间，一部分将直接对应各种操作系统选项，包括免费社区发行版的发展，同时也会有商业选项。</p><p>&nbsp;</p><p>对于某些企业客户来说，根据他们的发展角度，仍然需要商业服务来支持他们。这些需求将产生对操作系统的消费，对应到之前提到的千万级别的规模。因此，就整个市场规模而言，我相信超过百亿是一个发展趋势，也是整个行业共识。所以对于整个产业的从业者来说，这可能是一个相对确定性的发展机遇，他们都面临着这个机遇。</p><p>&nbsp;</p><p>刚才您也提到国内的需求。我们看到在各行各业中都广泛应用国内的服务器。根据使用规模，我们可以从中看到一些端倪。当我分析我们操作系统的用户需求时，包括不同行业的发展时，我习惯使用象限来进行分解。纵轴可以定义为业务对服务器或操作系统使用的影响程度，而横轴则可能对应不同行业领域的部署规模，根据相应行业的整体经济规模或企业数量来确定，这些因素可能决定了消耗的规模。</p><p>&nbsp;</p><p>根据这个象限的观察，最典型的需求来源可能体现在政务、金融、电信、能源以及教育和医疗等行业。这些行业在服务器和IT资源的消耗方面都属于前几类，而且它们的业务连续性直接关系到日常的国计民生。在这些领域，我相信替代CentOS的需求非常高，因为它们影响到业务的连续运行，也影响到它们所提供的广泛经济活动的服务。因此，这些行业迫切希望能有良好的迁移替代选项。另外，还有一大部分服务器消费量来自互联网行业。由于互联网行业在架构演进过程中更多地采用分布式架构，同时在操作系统层面上有更多的替代选项，因此它们对替代的需求可能不会那么强烈。</p><p>&nbsp;</p><p>综上所述，国内市场的机会可以从不同方面来看。从市场规模的角度，超过百亿是一个发展趋势。而从需求的角度来看，政务、金融、电信、能源以及教育和医疗等行业对替代操作系统的需求非常高。同时，互联网行业也是一个重要的消费者群体，尽管对替代需求的迫切性可能相对较低。</p><p>&nbsp;</p><p>姜雨生：有观众提问说，在教育行业的操作系统，我们目前替换的需求量如何？</p><p>&nbsp;</p><p>张鹏程：在教育行业中，我们面临着一个庞大的存量规模。与电信、金融和能源等行业相比，教育行业的存量规模仅次于它们，属于高度使用的行业。在过去的两年多里，我们通过社区工作发现了许多教育机构的需求，包括大众院校和教职机构。这些机构都关注如何解决CentOS停服替换的问题。</p><p>&nbsp;</p><p>第一类需求比较直接，原本使用的服务器数量并不是特别多，可能总共只有一两百台。它们通常使用的是免费的社区版本，例如CentOS。针对这些需求，龙蜥提供了对应版本的操作系统升级，以确保其与学校原先使用的许多软件的兼容性。同时，龙蜥还提供了一些迁移工具，帮助用户进行原地升级迁移，或者在有冗余资源的情况下进行升级替换，以便更好地完成CentOS替换。</p><p>&nbsp;</p><p>另一类需求是顺应当前发展趋势产生的新需求。我们注意到一些大学近年来正在构建智能计算平台，以解决其内部现有IT资源池的问题，并在科研方向上实现更多的智能化能力。这种方式更适用于规模较大、具有规模效应的大学。在这种情况下，在解决CentOS替换的同时，考虑搭建智能计算平台，通过云化方式提供内部使用，并满足科研需求。通过搭建新平台的方式，他们可以一举两得，随着新项目的发展，解决了CentOS停服可能带来的威胁。</p><p>&nbsp;</p><p>这两种案例是教育行业用户前进发展的典型代表。一方面，我们满足了那些使用规模较小的学校的需求，通过升级替代的方式帮助他们迁移问题。另一方面，对于规模较大、有新业务方向或科研规划的大学，我们支持他们搭建新平台来替代原有的老资源，从而解决CentOS替换的问题，并顺应其业务发展方向。</p><p></p><h2>如何进行操作系统迁移？</h2><p></p><p>&nbsp;</p><p>姜雨生：在迁移过程中，我们提到了从旧系统到新系统的替代过程。我个人在之前的工作中也做过很多与监控相关的系统，但是对于更底层的操作系统内容，特别是在物理机或云Kubernetes环境中，我确实没有完全接触过。服务器操作系统的迁移并不是简单的重新安装系统，还需要对操作系统及其搭载的应用软件和业务系统进行替代、适配、迁移和重构等，一套完整的迁移方案应该包括哪些步骤？</p><p>&nbsp;</p><p>张鹏程：我想首先回应一下您刚才提出的问题。您提到了在使用Kubernetes等技术时，对操作系统的感知和维护方面可能比较低。这确实是一个事实，而且代表了我们共同面临的发展趋势。随着云原生技术的普及，操作系统在与上层应用的耦合性方面正在降低。这种分层解耦有利于降低维护成本并提高大规模应用的易用性。</p><p>&nbsp;</p><p>在现实世界中，很多用户目前仍然主要使用物理机的操作环境。如果已经使用虚拟机，那对于后续的维护可能已经有所帮助。对于这些物理机或虚拟机形态的主机，迁移过程需要考虑更多因素，特别是硬件和软件对操作系统兼容性的影响。</p><p>&nbsp;</p><p>通常，在进行迁移之前，我们先需要进行评估，包括对操作系统和相关软硬件环境的评估，以及可能需要进行的兼容性适配。第二步，如果涉及硬件环境的变化，或者软件版本的升级，可能需要进行跨架构迁移的兼容性适配。例如，从x86架构转向ARM架构，或者操作系统版本升级，这些都可能需要考虑应用的兼容性适配。第三步是对原有环境进行备份，这对于任何迁移操作都是必要的保障。第四步是正式进行迁移实施。在具体的迁移实施过程中，通常有以下两种典型的操作步骤。</p><p>第一种是原地升级，即在原有环境下重启和升级操作系统，使其能够继续正常运行。这种方式对兼容性要求较高，而且需要进行充分的前期测试。第二种方式是轮转升级，这可以借助集群化管理或主备集群的形式实现。我们可以先将新版本安装部署在备用节点或新增节点上，并确保应用在该环境下能够正常运行。然后，在集群调度和管控层面逐渐将旧节点下线，并将其作为新节点逐步升级和重新安装。</p><p>&nbsp;</p><p>迁移实施完成后，最后一步是进行必要的验证，并结合操作系统或软硬件环境的变化进行必要的优化。</p><p>&nbsp;</p><p>通过上述五步骤流程，我们能够尽可能应对每个操作系统所在环境中可能出现的风险，并制定相应的方案。</p><p>&nbsp;</p><p>姜雨生：您提到了在迁移过程中涉及到主备切换的问题。在实际操作中，我们可能会先升级备份集群，然后需要确保备份环境可以接收流量或承担服务的运行，同时进行指标监控。我们是在这个过程中进行直接做切换操作吗？</p><p>&nbsp;</p><p>张鹏程：这个问题涉及环境架构的健壮性和主备切换的设计能力。例如，如果现有的集群环境已经具备了强大的负载均衡和数据同步能力，那么在这个环境下进行主备切换可能会比较顺利，实现一次平稳的切换。</p><p>&nbsp;</p><p>在某些极端情况下，我们可能会对主备切换持谨慎态度。在这种情况下，通常会先进行验证，然后在停机窗口内进行升级和维护。具体的处理方式需要根据具体情况进行分析和决策。实际情况中，我们会发现新系统更容易处理迁移需求。通常建议先进行增量环境的升级，甚至做一些妥协，旧系统可能需要长期运行，直到系统生命周期结束或者出现新的机会才进行升级替换。毕竟，一些系统由于年久原因，可能无法找到维护方，这些风险是现实中需要考虑的。</p><p>&nbsp;</p><p>姜雨生：在实际迁移过程中，我们通常会关注哪些验证指标？</p><p>&nbsp;</p><p>张鹏程：在验证阶段，针对操作系统通用环境，我们通常需要确保原有系统的功能正常运行。对于常规系统而言，如果之前经历了完整的项目周期，通常会有回归测试场景来验证功能的可用性。在兼容性满足的情况下，这些测试通常不会出现大的意外。</p><p>&nbsp;</p><p>第二步可能更关键，即在关键性能场景下进行验证。例如，系统可能具有特定的QPS指标或响应时间要求，针对这些指标，对新部署环境也需要进行测试。实际企业环境中，还需要考虑端到端的整体效果。验证的具体步骤因系统而异。</p><p>&nbsp;</p><p>姜雨生：操作系统的迁移工作主要包含哪些成本？比如迁移时间通常需要多久？需要多少人力？运行和使用成本如何？如何才能降低企业的操作系统迁移成本？</p><p>&nbsp;</p><p>张鹏程：在企业进行迁移过程中，成本方面需要考虑资源和人力投入。资源成本包括验证和测试所需的资源，以及生产环境的轮转和替换成本。人力成本涉及企业自有的IT运维人员负责操作系统管理和基础环境维护，以及与应用系统维护方或项目参与方相关的人员投入。</p><p>&nbsp;</p><p>在迁移过程中，由于兼容性适配和性能调优的需要，很可能需要应用层面的软件维护人员或开发人员提供帮助。这与所处环境的技术架构和应用程度有关。举例来说，传统架构体系相对复杂的情况下，可能涉及多个业务管理系统、企业IT系统和云服务系统，组件数量可能超过100个，涉及的服务器节点可能达到上千个。在这个过程中，硬件投入资源相对可控。由于环境已经云化，可以利用冗余资源进行轮转，因此迁移过程不会导致大量额外资源采购。借助云的优势，可以快速创建、使用、验证，并在完成后销毁回收，从而节省额外资源投入。</p><p>&nbsp;</p><p>然而，人力成本是不可避免的。在项目中，参与人员包括项目组成员、IT人员、应用系统相关人员和软件供应商人员，项目组成员通常达到上百人的配置。经过近三个月的时间，项目组成功地完成了从最初的评估测试到生产级别轮转的新试点项目。考虑到迁移过程中的不确定性和影响，这可以被视为一个高效的项目运作方式。在这方面，对于高要求和推进方面有很多挑战，但团队成功应对了这些挑战。</p><p>&nbsp;</p><p>姜雨生：有观众提问说，龙蜥对于社区用户会提供哪些生产级的技术支持，以何种方式支持？</p><p>&nbsp;</p><p>张鹏程：龙蜥社区是阿里云,统信软件,浪潮信息,龙芯,Intel,Arm等国内外知名厂商共同创建和维护的社区。龙蜥社区由24家理事单位共同管理，超过300家操作系统产业生态伙伴共同维护,为国内用户提供更加安全稳定使用的操作系统。在社区操作系统中，我们提到的产品形态可以分为两层结构。</p><p>&nbsp;</p><p>第一层是社区自身的上游产品，称为龙蜥社区版Anolis OS(龙蜥操作系统)，它是一个开源、免费的版本供大家使用。</p><p>&nbsp;</p><p>第二层是在社区中，理事单位和广泛伙伴可以基于社区版进行衍生开发和商业扩展的版本。其他理事单位可以构建衍生版本，通常与厂商合作，在社区版本的基础上增加自主研发的能力，并提供附加的商业服务和增值功能。这样的衍生版本以商业产品的形式提供给市场上的用户。</p><p>&nbsp;</p><p>在国内广泛的社区使用中，存在两种情况：一种是使用社区免费版本的用户，另一种是使用基于社区发行的商业衍生版本的用户。对于广泛的用户群体而言，如果使用的是社区免费版本，通常会采用社区的服务或开源方式进行维护和推进。在这个过程中，用户可能会在官网或通过钉钉群、微信群等渠道报告问题。社区内包括阿里的成员、不同理事单位的成员以及广泛的开发者用户，大家可以在这个开放平台上共同协作，解决问题并提供解决方案。这是第一层次。</p><p>&nbsp;</p><p>如果用户选择了商业衍生发行版本，通常会获得服务提供方提供的商业服务。在生产环境下，这些服务可能包括on-call支持或专家服务。这些商业服务是商业产品的配套服务，用于支持实际使用的应用场景。</p><p>&nbsp;</p><p>姜雨生：当前国内外已经出现了不少 CentOS 停服解决方案，在选择操作系统迁移替换时，不同行业的关注重点分别是什么？与其他迁移方案相比，龙蜥社区的差异化和优势体现在哪里？主要有哪些迁移工具？</p><p>&nbsp;</p><p>张鹏程：龙蜥社区的诞生源自阿里云将其内部使用的操作系统进行开源，并与更广泛的社区伙伴合作，以开源社区的方式更好地推进这项工作。</p><p>&nbsp;</p><p>龙蜥操作系统是基于阿里云在过去十多年发展历程中的沉淀而来，经过大规模验证的生产级别产品。阿里云最初在内部开发龙蜥操作系统是为了替换CentOS，以满足内部的需求，例如“双十一”等大规模稳定运行的要求。龙蜥操作系统在满足自用的阶段已经在内部发展出了雏形。</p><p>&nbsp;</p><p>随后，我们考虑到云上存在许多企业用户，他们对操作系统需要具备差异化的能力，例如快速启动和弹性部署等。为此，我们将其产品化为阿里巴巴云操作系统（Alibaba&nbsp;Cloud Linux），以更好地服务于云上的广泛用户。</p><p>&nbsp;</p><p>随着龙蜥社区的发展，从2020年开始，我们围绕开源社区产业协同共建机制，共同完善龙蜥操作系统。总的来说，我们的发展差异化最核心的基础一直是立足于云计算趋势的发展，并不断演进，以满足国内的自主需求以及整个技术体系的发展需求。</p><p>&nbsp;</p><p>我们的操作系统具备操作系统必备的核心要素，如稳定性和安全性。阿里云上的龙蜥操作系统经过上百万台服务器的运行打磨，其稳定性显而易见，相比我们所熟悉的开源版本具有更高的稳定性。同时，在安全性方面也进行了针对云场景的优化。</p><p>&nbsp;</p><p>龙蜥社区还积累了一个生态协同的优势。例如，在国外发展成熟的操作系统中，存在停服和不同生态发展之间的差异和隔阂问题。而在我们的社区中，国际合作伙伴（如Intel/ARM）和国内芯片厂商（如海光、飞腾、申威、龙芯、兆芯）积极参与合作，形成了良好的产业协作样板。大家围绕操作系统基础进行软、硬件协同共同研究，使我们共同研发的操作系统无论在通用服务器还是国产芯片服务器上运行，都能保证相应的硬件支持和优化。随着国内生态的进一步发展，这方面的优势和积累将得到更好的体现。</p><p>&nbsp;</p><p>姜雨生：面对国内的芯片厂商，我们在提供支持的过程中进行了合作。这种合作是在我们的社区内部自发进行的，厂商也会提供一些兼容性方面的支持，毕竟他们可能需要进行一些开发工作。在这个过程中，我们社区的开源工作者们不断构建相关内容以满足需求，还是由厂商主导来支持代码仓库构建？</p><p>&nbsp;</p><p>张鹏程：这是一个综合发展的过程。首先，社区内部有一个完整的治理结构。我们提到了理事单位，国产芯片厂商大部分都参与其中，并负责相应的职责。在理事单位下面，还有一个技术委员会，由理事单位的代表组成，大家从技术角度参与进来。</p><p>&nbsp;</p><p>这意味着芯片厂商确实在这个过程中拥有话语权，并参与讨论。同时，通过一些特殊兴趣小组（SIG）的方式，我们实际上创建了许多小型开源项目，大家在操作系统的范围内进行合作。因此，我们将不同的芯片路线对应到不同的SIG合作上，以推动代码的合作。当然，更广泛的个人开发者也非常欢迎参与其中。</p><p>&nbsp;</p><p>目前国产芯片的发展主要由芯片厂商主导，因为他们需要考虑如何使硬件与操作系统相匹配，将其整合到软件生态系统中。这是他们需要完成的一项重要任务。一旦这个飞轮开始转动并且得到越来越多的应用和开发者的支持，这部分可能会有更好的基础，然后可能吸引更广泛的开发者群体参与SIG组。这样的结构有助于在这样的基础设施环境下，推动社区的产业协同共研，不断地将其发展壮大，就像滚雪球一样。</p><p>&nbsp;</p><p>姜雨生：龙蜥在金融、交通、教育等多个领域帮助企业实现了操作系统迁移，在这些过往的迁移案例中，有哪些让您印象深刻、特定场景下的迁移诉求？我们对应的解决方案是什么？</p><p>&nbsp;</p><p>张鹏程：确实每个客户都是独特的，无论是在我们的咨询、交流，还是在共同开展项目方面，包括我在阿里云接触的客户，都有特定的情况。从我们的角度来看，我们都有自己的能力和边界，以及生态发展方式。因此，我们需要关注需求的共性和差异，以更好地开展工作。在用户群体中，我们主要关注的是保证操作系统的兼容性。如果兼容性存在不确定性，我们需要识别兼容性风险并进行相应的适配调整，以确保操作系统的顺利运行。另外，对于迁移后的优化和运维管理方式，我们也需要思考如何处理。从容器设计的角度来看，这类需求具有共性。</p><p>&nbsp;</p><p>为了满足这类共性需求，我们从社区的角度推动了一个名为\"迁移SIG\"的专项兴趣小组。我们完成了一个名为“社区运维工具”的项目，并与“迁移SIG”和“运维SIG”合作，将其打造成一个综合平台或工具集。它不仅包括满足迁移评估、适配和验证的自动化流程能力，还是一个组件化的平台，提供系统运维管理和诊断能力，以及对问题的调优建议。因此，我们基于社区合作的成果，创建了一个升级版的SysOM&nbsp;2.0平台，满足了迁移需求和迁移后的使用调优需求，而上层应用的适配则更多是个性化的需求。</p><p>&nbsp;</p><p>通常情况下，我们希望通过社区合作的方式解决这些个性化问题。有时我们会与一些应用厂商进行合作，他们是应用的提供商，并且由于迁移的机会，与我们社区建立了联系。在应用层面，我们希望借助这些应用厂商的专业知识来解决问题。解决客户问题的同时，我们希望这些厂商与龙蜥社区建立更长期的合作关系。实际上，许多厂商在经历了迁移案例后，已经成为龙蜥社区的生态伙伴，并加入了我们的龙蜥社区生态发展计划-龙腾计划。</p><p>&nbsp;</p><p>姜雨生：在迁移过程中，我想了解您是否遇到了一些技术上的难点，哪些难点可能让您头疼很长时间，也可能困扰了整个团队，需要花费大量时间来解决？</p><p>&nbsp;</p><p>张鹏程：在迁移过程中，可以按照前面提到的三个阶段，分享一些典型问题的经验。首先是迁移评估阶段，因为国内用户的评估环境多种多样，非常复杂。硬件设备、部件的兼容性对操作系统的兼容性有很大影响，例如RAID卡、网卡等。在开始阶段，很多用户都会提出这些问题。为了应对这些问题，我们借助社区采用了一些兼容性验证小工具，并通过推广和积累逐渐建立了丰富的兼容性列表。我们希望通过这种方式尽早发现问题，应对碎片化的硬件生态。</p><p>&nbsp;</p><p>在迁移过程中，更多的问题可能出现在每个系统环境上。老旧系统在升级过程中的成功率较低，或者在真正进行迁移的系统改动之后，由于环境的变化或重启，系统的运行状态可能不如之前正常。这些问题在运行过程中普遍存在。解决这些问题并没有灵丹妙药，最好的方式是提前进行系统测试验证，确保在生产环境中没有充分验证之前，不要贸然进行调整。在整个项目管理流程中，需要加强验证工作。当然，如果是新系统或者有系统升级的机会，结合项目会有事半功倍的效果。</p><p>&nbsp;</p><p>第三种情况是迁移后的问题排查，通常涉及性能提升。有时候我们会发现，在升级后，性能可能下降了50%甚至更多，这时我们需要依赖一些调优工具。在社区中，我们积累了一些调优工具，例如我们自研的Keentune工具，它结合社区环境提供调优诊断和性能优化建议。这些都是常见的头疼问题，需要结合工具和经验来解决。</p><p></p><h2>开发者如何拥抱变化？</h2><p></p><p>&nbsp;</p><p>姜雨生：对于企业开发者而言，企业在完成操作系统迁移后，开发者在后续的工作中会发生哪些变化？</p><p>&nbsp;</p><p>张鹏程：这确实是一个现实情况。我认为迁移本身可以分解为两大类型。一种是仅进行操作系统的变更，为了解决原有担忧CentOS所带来的停服风险，而解决系统更换的问题。对于这种情况，从用户的角度来看，我们的开发者和系统管理员决策方面无需过多担心，因为原有软件生态的兼容性相对较高，具有一致性。所以对于用户来说，他们原有的运维管理工具、开发工具，包括脚本等，基本上都可以正常运行，不会产生太大的意外。</p><p>&nbsp;</p><p>另一种迁移往往伴随着架构升级，这种架构升级可能体现在前面提到的国内情况中，通常伴随着本土化生态的替代。这可能导致跨架构的情况，例如从原来使用的x86体系，经过迁移和升级，开始使用ARM甚至一些用户接触到了龙芯或申威等架构。在这种情况下，原有的工具和软件需要与新架构相结合进行相应的生态调整。</p><p>&nbsp;</p><p>还有一种情况是朝着云原生化方向发展。例如从物理机维护或虚拟机逐渐转向容器和PaaS层的使用。对于开发者来说，不仅操作系统发生了变化，开发范式和运维管理方式也可能发生变化，整体的工作流都会产生影响。</p><p>&nbsp;</p><p>姜雨生：国产操作系统替换浪潮下，对于身处其中的开发者而言，您认为最关键的、最需要掌握的技能是什么？</p><p>&nbsp;</p><p>张鹏程：我认为今天的技术浪潮不仅限于操作系统领域，我们所看到的是云计算不断发展的浪潮，以及国产化趋势下的新兴趋势。最近，AI 大模型也引发了人们对人工智能的期待，这些都是开发者面临的时代机遇。</p><p>&nbsp;</p><p>因此，在这个过程中，我们可以不仅仅局限于参与操作系统社区的工作。诚实地说，能够参与操作系统级别开发的开发者是非常有限的，但更广泛的开发者群体在进行应用和系统开发方面发挥着重要作用。因此，我们欢迎大家参与龙蜥社区的使用。龙蜥社区不仅仅是一个操作系统，它提供了编程语言的编译环境，以及系统管理和优化工具，这些工具对开发者来说非常实用，可以帮助他们完善自己的工作。</p><p>&nbsp;</p><p>所以我想借这个机会进行一点宣传，我们欢迎读者多关注和了解龙蜥社区，参与其中的活动，如前面提到的SIG小组或Meetup活动。这些活动能够帮助大家了解龙蜥社区的成员，了解他们最近在忙什么，以及一些新兴创新产品。这些内容可能与我们日常工作相关，如果能对大家有所帮助，那么大家可以逐渐参与到龙蜥社区的活动中来。</p><p></p><h2>开源会成为国产操作系统的主流模式吗？</h2><p></p><p>&nbsp;</p><p>姜雨生：正如我们之前讨论过的，对于龙蜥的产品生态，有一个开源版本，还有一个企业级版本。在这样的生态下，目前龙蜥的主要方向是怎样的？从整体来看，国内操作系统未来的趋势可能会以开源为主，还是以商业化模式为主呢？开源生态建设是否会成为未来的主流趋势？</p><p>&nbsp;</p><p>张鹏程：在开源和闭源、开源和商业之间的话题上，随着开源的发展，它们之间确实像DNA的双螺旋一样共同发展。简单来说，我认为开源肯定是发展的主流力量。</p><p>&nbsp;</p><p>具体到您提到的开源和商业之间的比重，我觉得开源依赖于一个强大而健康的商业模式，以确保开源不会变得无根之木。参与开源的人除了出于热爱之外，在企业角度上，他们也从中获得商业利益的满足，才会更愿意投入开源的发展。因此，我认为总体而言，追求商业发展的企业会成为开源的主导力量。就使用方面和未来发展的预测而言，我认为供给侧和需求侧都会影响其发展的趋势和比重。</p><p>&nbsp;</p><p>从供给侧来看，开源方式是必不可缺的。就像我之前提到的，如果几个硬件厂商或芯片厂商各自发展各自的操作系统，构建起生态将变得更加困难。然而，基于像龙蜥社区这样的操作系统层面的中转，硬件厂商可以在下一代芯片演进时基于这个中转来嫁接更广泛的软件生态，这样是符合利益的。因此，从供给侧来看，开源为大家提供了一个促进参与开源并从中获益的过程。</p><p>&nbsp;</p><p>而从需求侧来看，它与我们面对的广泛用户群体的需求有关。一些用户可能IT预算较低，或者对业务连续性的要求不高，对他们来说，选择开源已经足够。或者在开源的基础上，叠加其他技术层面的解决方案，也能摆脱对单一节点的需求。另外，一些企业在业务连续性、稳定性和安全性方面有较高要求，这就催生了商业版本的价值。商业版本可以由商业厂商提供更充分的服务、更好的升级以及专家资源，这些都有助于企业解决自身问题。</p><p>&nbsp;</p><p>总体来说，开源和商业版本是相辅相成的。开源作为背后的动力基础，使得参与其中的群体在商业循环中有更强的动力继续贡献开源，并进一步获得回报。这是我们的期望。</p><p>&nbsp;</p><p>龙蜥目前主要的定位是什么，以及国内操作系统未来的趋势，是以开源为主还是商业化模式为主，我认为这是一个相互影响的过程。龙蜥作为一个开源操作系统，在开源社区中发挥着重要的作用，并通过健康的商业模式支持其发展。我们希望在未来能够将两者并驾齐驱，相辅相成，共同发展。</p><p></p><h4>嘉宾介绍</h4><p></p><p>&nbsp;</p><p>特邀主持：</p><p>&nbsp;</p><p>姜雨生，微软软件工程师，负责微软资讯业务与 GPT 集成，曾负责微软广告团队基础设施搭建与维护工作。</p><p>&nbsp;</p><p>嘉宾：</p><p>&nbsp;</p><p>张鹏程，龙蜥操作系统产品生态总监，阿里云基础软件部产品负责人，在基础软件和云计算领域拥有 15 年从业经验，负责龙蜥操作系统产品生态和社区运营工作，围绕开源联合产业链上下游生态伙伴协同创新发展，立足云计算场景打造数智时代领先的操作系统产品和解决方案。</p>",
    "publish_time": "2023-05-31 14:22:32",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]