[
  {
    "title": "南京大外企将研发撤离中国，最高赔偿N+8；OpenAI回应GPT-4变懒；周星驰Web3团队下月上线独立App | AI一周资讯",
    "url": "https://www.infoq.cn/article/roW4NR1hJzIyl1oikzE3",
    "summary": "<p></p><blockquote>“自动驾驶卡车第一股”图森未来缩减美国业务，拟裁减75%在美员工；商汤科技 AI 编程助手“代码小浣熊 Raccoon”开放公测；快手开启年内最大规模组织架构调整，涉主站、电商等多个业务线……</blockquote><p></p><p></p><h2>资讯</h2><p></p><p></p><h4>OpenAI回应GPT-4变懒</h4><p></p><p></p><p>OpenAI 的 GPT-4 大语言模型日前遭到部分用户投诉，部分用户表示，这段时间使用 ChatGPT 或 GPT-4 API 时，会遇到高峰期速度非常慢、敷衍回答、拒绝回答、中断会话等一系列问题。</p><p></p><p>北京时间周五中午，ChatGPT 官方通过 X 平台通知用户，“我们听到了你们关于 GPT-4 变得越来越懒的反馈！我们自 11 月 11 日起就没有更新过模型了，当然这不是故意的。”</p><p></p><h4>微软与OpenAI合作面临英国审查</h4><p></p><p></p><p>12月9日消息，当地时间周五英国监管机构英国竞争与市场管理局（CMA）表示，正在就微软与ChatGPT开发商OpenAI之间的合作关系进行评估，看是否有必要进一步展开反垄断调查。</p><p></p><h4>马斯克：Grok AI测试版现已向美国所有X Premium+订阅者开放</h4><p></p><p></p><p>12月8日，埃隆·马斯克在社交媒体上发文称，Grok AI测试版现已向美国所有X Premium+订阅者开放。据悉，现有 X 平台用户可以每月花费 16 美元或每年 168 美元来进行订阅。</p><p></p><p>马斯克此前表示，Grok 使用来自公开数据的数十亿个数据点进行训练，但是目前尚不清楚使用了哪些数据。此外他还提到 Grok 将能够实时访问 X 平台，因此与其他生成式人工智能相比这是一个巨大的优势。</p><p></p><h4>谷歌承认Gemini演示视频经特殊剪辑处理</h4><p></p><p></p><p>美东时间12月6日，谷歌CEO桑达尔・皮查伊宣布迄今为止规模最大，能力最强的谷歌大模型Gemini 1.0 版正式上线。Gemini是原生多模态大模型，是谷歌大模型新时代的第一步，它包括三种量级：能力最强的 Gemini Ultra，适用于多任务的 Gemini Pro，以及适用于特定任务和端侧的 Gemini Nano。</p><p></p><p>不过，外界已开始有声音指控谷歌对Gemini的性能“造假”。彭博社一篇专栏文章就表示，谷歌在一段演示视频中歪曲了Gemini的AI性能。专栏作家帕米·奥尔森（Parmy Olson）认为，在谷歌发布的这段视频中，Gemini似乎非常强大，但有点过于强大了。对此质疑，谷歌回应时承认，这段关于Gemini性能演示的视频并不是实时的，而是使用了原始镜头中的静止图像帧，然后编写了文本提示，以便让Gemini做出回应。</p><p></p><h4>阿里夸克大模型已通过备案</h4><p></p><p></p><p>日前，阿里智能信息事业群自研的夸克大模型已通过备案，将陆续在通识、健康、创作等领域升级内容产品与智能工具，并落地一系列AIGC创新应用。夸克相关负责人表示，夸克大模型是面向搜索、生产力工具和资产管理助手的应用型大模型。在搜索应用中，将通过图文多模理解、专业知识生成、交互方式创新进一步拓宽应用场景，提升用户体验。</p><p></p><h4>周星驰Web3团队下月上线独立App</h4><p></p><p></p><p>据新浪科技报道，12月7日下午消息，据接近周星驰团队人员对新浪科技透露，周星驰旗下Web3初创公司Moonbox 最早将于明年1月份完成上线Moonbox App，届时App将免费向用户开放。目前，App研发工作已经基本完成，Moonbox团队在 NFT 玩法上下了很多功夫，已设计出基于AI和NFT聊天的互动玩法。</p><p></p><p>据上述知情人士透露，伴随着Moonbox App的独立上线，“周星驰将以Moonbox First Creator身份与大家见面”。与此同时，周星驰参与创作的Nobody NFT新品，也将随之发售，用户可以通过App和每个Nobody NFT角色聊天互动以了解人物性格、爱好、背景故事。</p><p></p><h4>“自动驾驶卡车第一股”图森未来缩减美国业务，拟裁减75%在美员工</h4><p></p><p></p><p>近日，图森未来向美国证券交易会提交的一份报告显示，公司将裁撤150名在美员工，约为美国员工总数的75%，全球员工总数的19%。这是图森未来继去年12月和今年5月的裁员后，再一次进行人员削减。</p><p></p><p>图森未来预计，此次重组计划将产生约700万至800万美元费用，大部分用于支付遣散费、员工福利和相关费用，重组费用将在2023年第四季度入账。</p><p></p><p>据华尔街日报报道，本次裁员后，图森未来在美人数仅为30人，将负责图森未来美国业务的收尾工作，逐步出售公司在美资产，并且协助公司向亚太地区转移。因此，此次裁员意味着图森未来或将彻底退出美国市场。</p><p></p><h4>通义千问登顶HuggingFace开源大模型排行榜榜首</h4><p></p><p></p><p>12月8日消息，全球最大的开源大模型社区HuggingFace日前公布了最新的开源大模型排行榜，阿里云通义千问力压Llama2等国内外开源大模型登顶榜首。</p><p></p><p>HuggingFace的开源大模型排行榜（Open LLM Leaderboard）是目前大模型领域最具权威性的榜单，收录了全球上百个开源大模型，测试维度涵盖阅读理解、逻辑推理、数学计算、事实问答等六大评测。通义千问（Qwen-72B）表现抢眼，以73.6的综合得分在所有预训练模型中排名第一。</p><p></p><h4>商汤科技 AI 编程助手“代码小浣熊 Raccoon”开放公测</h4><p></p><p></p><p>12月7日，商汤科技官微宣布，基于商汤自研大语言模型的智能编程助手——代码小浣熊Raccoon，即日起开放公测。据介绍，在实际应用中，代码小浣熊可帮助开发者提升编程效率超50%；未来，应用代码小浣熊，开发者可以将80%的编写工作交由AI完成。</p><p></p><h4>特斯拉Dojo超算项目被曝更换负责人</h4><p></p><p></p><p>外媒援引知情人士消息称，特斯拉Dojo超级计算机的项目负责人Ganesh Venkataramanan已经于11月份离职。在过去五年中，Venkataramanan一直在领导Dojo项目的推进工作，加入特斯拉前他在AMD担任了近15年的长期工程总监。现在Dojo项目由Peter Bannon负责，Bannon已经在特斯拉担任高管近8年，之前还在苹果公司中任职超过7年。</p><p></p><h4>快手开启年内最大规模组织架构调整，涉主站、电商等多个业务线</h4><p></p><p></p><p>12月7日消息，快手发布内部邮件宣布新一轮组织调整。此次组织调整涉及主站、电商、商业化、杜区科学等多个业务线，属于今年以来最大范围的一次组织架构调整。其中，商业化事业部下本地消费业务部调整至主站线下，更名为招聘房产业务部，负责快聘、房产相关业务，取消主站产品部，主站线下成立孵化产品部，负责快影、一甜相机、回森等独立APP产品。</p><p></p><h4>南京大外企将研发撤离中国，裁员赔偿最高N+8</h4><p></p><p></p><p>近日，南京知名外企趋势科技计划搬离国内。知情人士透露，趋势科技打算将核心技术从国内转移到加拿大，因此裁员只涉及研发部门，其他部门几乎没有调整，共计约 70 人左右，赔偿 N+4 起步，一些老员工则超过 N+8。</p><p></p><p>据悉，该公司从上个月就开始裁员了，目前已接近尾声。值得一提的是，趋势科技本次撤离还会带走一部分员工，同意去加拿大的话也可以协调不裁。</p><p></p><h4>苹果因故意降低性能被判赔偿韩国7名用户每人7万韩元</h4><p></p><p></p><p>据韩联社消息，6日，韩国7名消费者集体起诉苹果通过升级系统降低旧款iPhone性能案二审宣判，法院判处原告部分胜诉。</p><p></p><p>据报道，韩国首尔高等法院民事当天开庭审理，判处苹果向原告每人支付7万韩元(约合人民币382元)赔偿金。</p><p></p><p>据悉，法院对原告所谓“苹果升级iOS系统属于发布恶意程序或损坏iPhone手机性能”的主张不予采纳，但法院认为，即使更新操作系统旨在防止手机自动关机，但也限制了中央处理器(CPU)等性能。苹果有义务向消费者说明是否安装更新，但苹果违反这一规定。同时，消费者因选择权被侵害而产生精神损失，认定苹果有赔偿责任。</p><p></p><h4>王慧文入股OneFlow团队新创业项目</h4><p></p><p></p><p>近日，北京硅动科技有限公司发生工商变更，新增王慧文为股东，同时注册资本由100万人民币增至约105.26万人民币。该公司成立于今年8月，法定代表人、执行董事、经理为OneFlow创始人袁进辉，公司经营范围含软件开发、技术进出口、电子产品销售、人工智能应用软件开发、人工智能通用应用系统、人工智能行业应用系统集成服务等。</p><p></p><p>公开信息显示，王慧文病休后，光年之外收购的核心团队OneFlow宣布重新创业。袁进辉称，新创业项目拟解决大模型推理成本问题。天眼查显示，目前，王慧文仍为OneFlow关联公司北京一流科技有限公司董事。</p><p></p><h4>量子计算技术重磅升级：IBM展示最新的模块化量子处理器</h4><p></p><p></p><p>当地时间周一（12月4日），IBM在官方博客发文，展示了“量子效用”所需的硬件和软件，其中包括新的量子处理器芯片和量子计算系统。</p><p></p><p>新闻稿称，IBM展示了一种新方法：将芯片连接到机器内部，再将机器连接到一起，以形成模块化系统，使规模的扩展不受物理条件限制。IBM称，将这种方法叠加新的纠错码，有望在2033年之前制造出引人注目的量子机器。</p><p></p><h2>IT 业界热评新闻</h2><p></p><p></p><h4>投票开除奥特曼的董事发声：OpenAI之乱跟AI安全没关系</h4><p></p><p></p><p>在上个月令全球科技圈震惊的OpenAI“内乱100小时”中，AI圈的顶流明星山姆·奥特曼在遭到董事会扫地出门后又迅速凯旋而归。即便如此，由于事发后核心人物鲜少谈及幕后的考量，整件事情至今还留有诸多疑问。</p><p></p><p>当地时间周四，已经离开OpenAI董事会的Helen Toner公开发声，对于外界的诸多疑问和“知情人士消息”做出一些回应。</p><p></p><p>Toner表示，董事会开除奥特曼的原因与AI安全没有关系，而是“缺乏信任”。她进一步解释称：“我们解雇山姆的目的，是为了加强OpenAI并使其更有能力实现其使命。”</p><p></p><p>在面对OpenAI的律师试图施压董事会辞职时，她也坚持了这一立场。Toner介绍称：“律师试图声称，如果我们不立即辞职，将会违法。因为若公司因此崩溃，我们将违反受托责任。但OpenAI是一个非常特殊的组织，非营利使命——确保人工通用智能（AGI）惠及全人类——是最重要的。”</p><p></p><p>事实上，在面对律师强调“公司会因此崩溃”时，Toner回应称“这样也符合我们的使命”，令房间里的一众公司高管感到吃惊。对于这一点，Toner也补充道，这句话是对律师“恐吓策略”的回应。她试图表达的是：对于创建造福全人类的AGI这一使命而言，OpenAI的持续存在并不是必要条件。</p>",
    "publish_time": "2023-12-10 14:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从滴滴的故障中我们能学到什么",
    "url": "https://www.infoq.cn/article/lGzz3DULicICzvOIbPXh",
    "summary": "<p></p><blockquote>本文作者为曹伟（鸣嵩），云猿生数据创始人 &amp; CEO，KubeBlocks 项目发起人。前阿里云数据库总经理 / 研究员，云原生数据库 PolarDB 创始人。中国计算机学会数据库专委会执行专委，中国计算机学会开源专委会执行专委，获得 2020 年中国电子学会科技进步一等奖，在 SIGMOD、VLDB、ICDE、FAST 等数据库与存储国际顶级学术会议发表论文 20 余篇。&nbsp;&nbsp;</blockquote><p></p><p></p><p>11 月 27 日晚滴滴发生了大范围、长时间的故障。官方消息说是“底层系统软件发生故障”，而据网上的小道消息，一个规模非常大的 K8s 集群进行在线热升级，因为某些原因，所有 Pod（容器）被 kill，而 K8s 的元数据已经被新版本 K8s 修改，无法回滚，因此恢复时间拉的很长。</p><p></p><p>从滴滴近期分享的技术文章来看，这个说法并不是空穴来风。滴滴团队近两个月正在把公司内部的 K8s 从 1.12 升级到 1.20，1.12 是 2018 年 9 月发布的，而 1.20 是 2020 年 12 月，对高速发展的 K8s 项目来说，两个版本存在相当大的差距。K8s 官方推荐的方法是沿着一个个版本升上去。但滴滴团队认为多次升级风险更高，采取了一把梭哈的策略，跨越 8 个版本一把升。而且为了避免中断业务，在不重启容器的情况下原地升级，滴滴团队还修改了 kubelet 的代码。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ef/ef3b7f09f47be225afa89dd28d7e84ac.png\" /></p><p>这个升级流程如果一切正常理论上是 work 的。我推测还是遇上了未考虑到的意外因素，比如运维误操作，造成了这次大规模的故障。从我的经验来说，遵循以下设计原则，可以极大的降低风险概率、减小故障范围。</p><p></p><h2>控制规模，用多个小规模 K8s 集群的联邦代替一个大 K8s</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/a6/a68debaf9916b8ba87a693b329b8ce66.jpeg\" /></p><p>先说我的⼀个经历。早年阿⾥云发起过⼀个 5K 项⽬，⽤ 5000 台物理机组成⼀个 ODPS（即后来的 MaxCompute）大集群来⽀持阿⾥内部的⼤数据业务，5K &nbsp;项⽬在 13 年上半年进⼊攻坚阶段，我作为技术⻣⼲被抽调到这个项⽬⾥。ODPS &nbsp;有⼀个组件叫⼥娲，类似 Hadoop 的 Name Node，提供名字解析、分布式锁等服务。当 5K 集群进⾏机房级掉电测试时，⼏千台服务器（其中有⼏万个服务）在重启后会向 3 台⼥娲服务器发起远程调⽤去解析彼此的地址，就像 DDoS 攻击⼀样，瞬时流量会持续打满千兆⽹卡，造成整个 5K 集群⼀波⼜⼀波的雪崩。</p><p></p><p>这段经历告诉我，当一个集群规模很大时，很容易在意想不到的地方发生类似的问题。因此，在设计系统时，我倾向于把集群的规模控制在⼀个合理的范围。例如把⼀个资源池的⼤⼩控制在⼏百台机器的规模，当需要更多资源时，不是去扩展单个资源池的⼤⼩，⽽是去新建资源池，扩展资源池的数量。换句话说，为了解决业务增长问题，不要 scale up 单个集群，⽽是 scale out 出更多的集群！</p><p></p><p>另一个要考虑的问题是爆炸半径。再举个例子，PolarDB 的底层存储组件叫 PolarStore，从外部来看，PolarStore 是⼀个可⽆限扩容的存储服务，但内部实现上，我将其设计成由一个个隔离开的⼩集群组成，每个集群⼏⼗到上百台服务器。这个设计 2017 年投入商用，虽然之后 PolarDB 的规模逐年激增，但 PolarStore 服务从来没出现过大范围的故障。K8s 集群也是⼀样。特别⼤规模的 K8s 集群，例如上万台的，其实都存在爆炸半径过⼤的的稳定性⻛险。与其不断优化与提⾼ K8s 的规模极限，不如梳理业务，把这些巨型 K8s 集群拆为多个⼤⼩适中的集群。</p><p></p><p>实际系统设计和开发中，我们可能会因为多种原因倾向于选择大集群。我听过的⼀个理由是为了避免跨 K8s 集群⽹络不连通问题，就⼲脆把所有 Pod 都塞到了⼀个 K8s 集群⾥。但⽹络连通性的问题还是应该由⽹络⽅案来解，比如这个问题可以通过负载均衡器（LB）暴露 Pod 地址，或给 Pod 额外分配⼀个 Underlay ⽹络地址（例如物理网络或者 VPC 网络的地址）来解决，而不应该将其和架构设计相耦合。KubeBlocks 的⽤户经常来咨询我们，⼀套 KubeBlocks 能不能管理⼏千或者上万个数据库实例。我们给出的答案是能，但我们推荐的最佳实践是采⽤多个 K8s 集群⽔平扩展的⽅法，每个 K8s 集群都是⼀个资源池，各⾃部署⼀套⾃治的 KubeBlocks，然后再把这些资源池注册到我们的中⼼管理集群⾥来，通过这种架构扩展到⼏⼗万个数据库实例数都不存在问题。这本质上是⼀种将多个 K8s 集群组成联邦的⽅案。</p><p></p><h2>避免单点，一个 K8s 集群也应该被视作一个单点</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/cc/cc75fe9f06550bbf0d57ece2937887b1.png\" /></p><p>架构师们一直都很小心谨慎的避免单点故障。服务要进行冗余部署，数据库要有主备。在机房内，网络要有双上联交换机，服务器除了市电供电，还要准备柴油发电机应急。在支付宝机房被挖断光纤后，大家又开始重视机房级别的高可用容灾，业务要做跨机房甚至是跨地域的部署。如果一个机房断网、断电，那流量要能快速的从故障机房切走，业务处理以及底层的存储都要切换到其他机房。比如，八年前我在设计 RDS 专有云双机房部署方案的时候，要考虑单机房灾难发生时，数据库的主备复制关系、负载均衡还有 IP 网段如何从主机房漂移到备机房，以及故障恢复时流量如何再切回主机房。</p><p></p><p>但 K8s 经常被架构师们视作是一个业已具有多机房容灾、高可用能力的分布式系统。从而忽视了把高可用业务部署在单 K8s 集群上的固有风险。K8s 是一个管理容器编排的系统软件，如同所有的软件系统，遇到非预期的事件，例如本次滴滴故障中跨多个版本的原地升级，也是有几率彻底挂掉的。这个时候，业务和存储系统在单 K8s 里纵使有再多的副本，也要歇菜。</p><p></p><p>因此我们建议架构师们在设计部署方案时，要把 K8s 视作存在单点风险的单元，一个 K8s 是一个部署单元，把过去多单元多活的技术方案移植到多 K8s 多活的场景下来。不仅是无状态的服务，服务所依赖的数据库的副本也要跨 K8s 部署。除了数据面，在控制面管理业务负载与数据库的 K8s operator 管理软件也需要做到多 K8s 多活。这类似于，在 RDS 系统里，除了数据库要做高可用，RDS 的管控系统必须要实现双活，否则故障发生时，自动化系统都失效了，所有操作都得人工执行，自然会增加故障的处理时长。这个能力我们会在 KubeBlocks 里支持上。</p><p></p><p>额外的好处是，如果你的业务部署在多个 K8s 集群中，那么&nbsp;K8s 的升级策略可以更加灵活，可以通过逐个升级 K8s 集群，这样能够进一步降低升级过程中可能出现的风险。</p><p></p><h2>拥抱重启，把重启和迁移视作常态</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/9a/9ab60b6c0e589d76e4b9e76fe5a4bb9f.jpeg\" /></p><p>回到 K8s 的升级，K8s 官方推荐的方式是这样的，逐一地将每个节点上的 Pod 驱逐到其他节点上去，从集群中移除节点，升级，然后再将它重新加入到集群，这是一种滚动升级机制（Rolling）。而 AWS EKS 还支持一种蓝绿部署机制（Blue-Green），创建一个新的节点组，使用新的 K8s 版本，然后，将 Pod 从旧的节点组迁移到新的节点组，实现蓝绿部署，一旦所有的 Pod 都已经成功迁移到新的节点组，再可以删除旧的节点组。两种方法都需要迁移和重启 Pod。这次故障里，滴滴采用了非常规的 K8s 升级手段，其中一个重要的动机是避免 Pod 重启影响业务。这其实代表了一类 old-school 的服务器管理理念。</p><p></p><p>在 DevOps 中，\"Pets vs Cattle\" 是一个常用的比喻，用来描述两种不同的服务器管理策略。Pets（宠物，例如猫）代表的是那些我们精心照料和维护的服务器。当它们出现问题时，我们会尽一切可能去修复，而不是直接替换它们。每一个 Pet 都是独一无二的，有自己的名字，我们知道它们的性能，甚至它们的\"性格\"（例如，某个服务器可能会经常出现某种特定的问题）。过去工程师和运维们非常的厌恶服务器重启，以至于云厂商 ECS 团队的一个奋斗目标就是把虚拟机做到如小型机般的可靠，为此不断的改进虚拟机热迁移等技术。</p><p></p><p>Cattle（牲口，例如牛）代表的是那些我们可以随意新增或删除的服务器。我们不会对它们进行个别管理，而是将它们视为一个整体来管理。如果其中的任何一个出现问题或者变化，我们通常会选择直接替换，而不是修复。Cattle 的例子包括在云环境中运行的虚机，或者是在 Kubernetes 集群中运行的 Pod。甚至可以把 K8s 集群本身也视作 Cattle，如果 K8s 出现问题，或者是 K8s 集群要做版本升级，直接把这个 K8s 换掉，把老的 K8s 里的 Pod 直接迁移到新的 K8s 里。</p><p></p><p>把 Pod 看做 Pets，就会想尽一切办法来避免 Pod 重启。而把 Pod 看做 Cattle，就会换一个思维，把 Pod 的重启和迁移作为一个需求来设计系统。我建议工程师们采用后一种思维。不要害怕 Pod 重启和迁移，而是把处理 Pod 重启、迁移以及遇到问题回滚的代码视为系统的正常运行例程的一部分。在复杂系统设计中，期待并规划故障的发生，而不是试图阻止它们发生，通过定期升级系统，验证处理重启、迁移、回滚的代码，确保系统在面对重启和迁移这种常态时能够正常运作。把重启和迁移视为常态，而不是异常，这种思维方式能够帮助我们设计出更可靠、更健壮的系统。</p><p></p><p>因此，在 KubeBlocks 执行数据库大版本升级时，我们并不推荐原地升级，因为原地升级总有一天会踩到坑的。我们会新建一个高版本的数据库实例，通过全量和增量数据迁移将数据导入到新实例中，通过数据库代理层保持来自应用端的网络连接，降低在实例间切换对业务的影响。在升级完成后，我们还会保持老版本和新版本的数据库同时运行一段时间并且维持双向同步，在业务确认升级不造成非预期影响后再清理老版本的实例。</p><p></p><h2>数据面的可用性和控制面要解耦</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/54/546c1683e29138a416364dccdc9bc4eb.jpeg\" /></p><p>最后想说的一个经验是数据面的可用性要和控制面解耦。我先举两个例子，这两个都是存储系统，但是基于不同理念设计的：</p><p></p><p>第一个系统是 PolarDB 的存储系统 PolarStore。PolarStore 采取了控制面与数据面分离的理念（详情参考我在 VLDB 2018 年发表的\"PolarFS\"论文）。数据面的读写操作都仅依赖查询缓存在本地的全量元数据。控制面仅仅在执行管理操作，例如创建卷、卷的扩缩容、节点宕机发起数据迁移、集群扩缩容的时候需要修改元数据才会被强依赖。控制面对元数据的修改会通过元数据通知机制异步更新到数据面的缓存里。这个设计的优点是高度的可靠性，即使整个控制面不可用，在数据面读写文件都可以正常完成，这对数据库业务而言很重要。</p><p></p><p>而在另一个系统中，控制面与数据面是耦合的。这个系统有三个很重要的 Master 节点，Master 节点除了承担控制面的任务外，还承担了一部分数据面的职责。举个例子，在这个系统中，数据是以 Append only 的形式不断追加到一个日志流中，而日志流会按 64MB 分割为 chunk，每写满一批 chunk，数据面的节点就要找 Master 节点分配下一批新 chunk 的调度策略。这个设计有一个缺限，就是 Master 节点一旦宕机，整个存储集群很快就无法写入新数据。为了克服这个缺陷，Master 从三副本改为了五副本，同时 Master 还采用了 Sharding 的方案来提高吞吐能力。</p><p></p><p>我还想到第三个例子，前阵子阿里云的史诗级故障，对象存储的关键路径里依赖了 RAM 的鉴权逻辑，因此 RAM 出现故障时，也造成了对象存储的不可用。这几个存储例子告诉我们，数据面的可用性如果和控制面解耦，那么控制面挂掉对数据面的影响很轻微。否则，要么要不断去提高控制面的可用性，要么就要接受故障的级联发生。</p><p></p><p>KubeBlocks 也采取了控制面与数据面分离的设计，控制面包括 KubeBlocks operator、K8s API Server、Scheduler、Controller Manager 和 etcd 存储，它负责整个集群的管理，包括调度、资源分配、对象生命周期管理等功能。而数据面则是在 Pods 中运行的容器，包含各种数据库的 SQL 处理与数据存储组件。KubeBlocks 可以保证即使控制面的节点全部宕机，数据面仍然可用。而结合数据库内核、代理与负载均衡的协同，还可以进一步做到控制面失败，数据面仍然可以执行高可用切换。</p><p></p><h2>结语</h2><p></p><p></p><p>控制规模、避免单点、拥抱重启、数据面的可用性和控制面解耦。这些点是我过去十多年在设计 RDS 和 PolarDB 这样的大规模云服务时所重视的一些设计原则，这些原则可以帮助防御系统出现大规模故障。在开发 KubeBlocks 的过程中，我发现这些原则在 K8s 的场景下仍然是有效的，希望可以帮助架构师和工程师们设计更稳定的系统。</p><p></p><p>本文转载自公众号“云猿生聊技术”，原文链接：https://mp.weixin.qq.com/s/KFZCQFP1oB5YOrT3tHBRCQ</p>",
    "publish_time": "2023-12-10 20:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]