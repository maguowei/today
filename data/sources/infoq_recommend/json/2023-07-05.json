[
  {
    "title": "OpenAI API 功能升级：ChatGPT 支持描述函数调用",
    "url": "https://www.infoq.cn/article/P9BKLy4VOaKEpyJAALBM",
    "summary": "<p>OpenAI对API进行了更新，其中包括一种名为<a href=\"https://openai.com/blog/function-calling-and-other-api-updates\">函数调用（function calling）</a>\"的功能，它允许开发人员向<a href=\"https://openai.com/research/gpt-4\">GPT-4</a>\"和<a href=\"https://platform.openai.com/docs/models\">GPT-3.5</a>\"描述函数，并让模型创建代码来执行这些函数。</p><p></p><p><a href=\"https://openai.com/blog/function-calling-and-other-api-updates\">根据OpenAI的说法</a>\"，函数调用有助于聊天机器人的开发，这些聊天机器人能够利用外部工具，将自然语言转换为数据库查询，并从文本中提取结构化数据。这些模型经过了微调，不仅可以识别应该调用函数的实例，还可以提供与函数签名一致的JSON响应。</p><p></p><p>由于函数调用发挥了至关重要的作用，人工智能模型可以智能地与外部工具和API连接。开发人员可以通过为这些模型指定函数来访问大量的功能和服务。通过使用外部工具来响应查询、搜索数据库或从非结构化文本中提取结构化数据，这种连接使人工智能模型能够完成超出其自然能力之外的任务。由于函数调用，人工智能模型变得更加通用和有效，能够应对现实世界中的复杂挑战。</p><p></p><p>随着<a href=\"https://platform.openai.com/docs/models\">gpt-4-0613</a>\"和<a href=\"https://community.openai.com/t/gpt-3-5-turbo-0613-function-calling-16k-context-window-and-lower-prices/263263\">gpt-3.5-turbo-0613</a>\"的发布，开发人员现在可以向这些模型描述函数。因此，模型可以智能地生成<a href=\"https://en.wikipedia.org/wiki/JSON\">JSON</a>\"对象，这些对象包含调用这些函数所需的参数。这一激动人心的开发提供了一种更可靠的方式，将GPT的功能与外部工具和API连接起来，为无缝集成开辟了新的可能性。</p><p></p><p>这些模型已经开发出了一种能力，可以根据用户输入通过仔细的微调来识别应该激活哪个函数。此外，他们还学会了提供与特定函数签名相匹配的JSON答案。开发人员现在可以通过使用函数调用更可靠、更一致地从模型中获取结构化数据。</p><p></p><p>除了函数调用，OpenAI<a href=\"https://openai.com/blog/function-calling-and-other-api-updates\">还推出</a>\"了<a href=\"https://platform.openai.com/docs/models\">GPT-3.5-turbo</a>\"的增强版本，该版本提供了一个显著扩展的上下文窗口。该上下文窗口以标记或原始文本为单位测量，表示模型在生成进一步文本之前考虑的文本量。这一扩展允许模型访问和整合更大的信息体，使其能够做出更明智和与上下文相关的响应。</p><p></p><p>人工智能开发中的函数调用允许模型使用开发人员设计的工具，使它们能够扩展自己的能力并集成定制的功能。这种协作方法弥合了人工智能模型和开发人员设计的工具之间的差距，促进了人工智能系统的多功能性、适应性和创新性。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/06/openai-api-function-chatgpt/\">https://www.infoq.com/news/2023/06/openai-api-function-chatgpt/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/UNmAT4eReyYCOISHbrTc\">AI 进入普及应用阶段，用友已启动企业应用大模型训练</a>\"</p><p><a href=\"https://www.infoq.cn/article/85UCQYO6sJUC23W1JWBu\">用 AIGC 重构后的智能客服，能否淘到大模型时代的第一桶金？</a>\"</p><p><a href=\"https://www.infoq.cn/news/AsiUxMs8ARkZEkuEZYgL\">OpenAI 又赢麻了！谷歌 DeepMind 创始人刚称 Gemini 能碾压 GPT-4，OpenAI 的挖人大计就出炉了</a>\"</p>",
    "publish_time": "2023-07-05 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "解锁 Serverless 新进展：与 AIGC 结合会有哪些搞头？ ｜InfoQ《极客有约》",
    "url": "https://www.infoq.cn/article/ihlWu9yppWciFjm7b0NH",
    "summary": "<p>Serverless有哪些最新进展？AIGC 给研发领域带来了哪些影响？Serverless+AIGC会有什么价值？本期《极客有约》，阿里云智能 Serverless研发负责人杨皓然(不嗔)、高德服务端负责人孙蔚和阿里云智能高级技术专家聂大鹏（拓山），与大家一起聊聊Serverless与AIGC如何碰撞出新的火花。</p>",
    "publish_time": "2023-07-05 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "银行智能化转型：AI 中台的关键要素与实施策略",
    "url": "https://www.infoq.cn/article/xPds1taN1Xcgx1jWBXH4",
    "summary": "<p>数字化时代，<a href=\"https://www.infoq.cn/topic/AI\">人工智能（AI）</a>\"正日益成为各行各业的核心驱动力。近几年在竞争激烈的银行业内， AI  中台逐渐崭露头角，成为银行不可或缺的战略工具。</p><p></p><p><a href=\"https://www.infoq.cn/article/5_2QekZHvBj88q859P2U\">AI 中台</a>\"通常被定义为一种集中管理、整合和开放人工智能能力的平台。它提供了一种基础设施，使得银行能够有效地整合和管理各种 AI 技术、算法和模型，以支持业务创新和优化。通过 AI 中台，银行可以更好地利用数据、进行智能决策、提供个性化的服务，并优化内部业务流程。</p><p></p><p>针对这一趋势，近年来关于银行 AI 中台建设的讨论日益频繁。与此相关，InfoQ 最近与东亚银行（中国）有限公司（以下简称“东亚中国”）研发中心副总经理、<a href=\"https://tgo.infoq.cn/\">TGO鲲鹏会</a>\"（上海）会员周文彬进行了交流，探讨了 AI 中台的技术能力构建、应用场景、新旧技术的冲突和选择等话题，希望能为读者提供有价值的参考。</p><p></p><h2>银行纷纷打造 AI 中台</h2><p></p><p>银行建设 AI 中台并非什么新鲜事，国内无论是四大行还是规模较大的商业银行，这几年都有在加大投入布局 AI 中台/平台的建设。综合来看，这些银行搭建 AI 中台的原因主要包括“降本增效”、“推动业务创新和发展”以及“提高客户体验”等等。</p><p></p><p>首先，通过集中管理和调度 AI 资源，银行能够更好地利用算力和数据资源，提高业务处理的效率和准确性，同时降低相关的运营成本。</p><p></p><p>其次，AI 中台相当于为银行内部各个部门和团队提供了一个统一的平台，这有利于促进协作和共享，加速新的AI应用的开发和部署。</p><p></p><p>第三，通过 AI 中台，银行能够更好地分析和理解客户数据，提供个性化的产品和服务，提升客户体验和满意度。</p><p></p><p>周文彬进一步表示，由于 AI 任务对算力有很大的需求，为了合理地分配和调度 GPU 资源，并提供便捷的调用方式，这时候就需要建立一个中台来统一管理AI资产，包括数据、算法、算例、模型、服务，并提供统一的AI能力接口供其他业务系统调用。</p><p></p><p>据悉，目前东亚中国战略及数字化办公室和资讯科技处的 IT 团队也正共同打造 AI 中台的技术能力中心，以便可以在整个银行系统中充分利用 AI 技术。“构建 AI 中台，是为了形成行内数智化升级的 AI 能力底座，为业务场景建设提供丰富的 AI 原子能力及算法模型支撑。”</p><p></p><h2>AI 中台三大核心技术能力</h2><p></p><p>AI 中台的核心目标之一是建立统一的 AI 核心能力底座。据周文彬介绍，东亚中国 AI 中台的技术能力主要分为以下三大模块： OCR（光学字符识别）、ASR 和 TTS（语音识别和文字转换成语音播放）以及 NLP（自然语言处理）。</p><p></p><p>OCR ：利用光学字符识别技术，实现对纸质文档的自动化识别和转换，提高数据录入的效率和准确性；NLP ：利用自然语言处理技术，实现对文本信息的分析和理解、关键信息提取、提供智能问答、情感分析、文本摘要等功能；ASR &amp; TTS ： TTS技术（TextToSpeech） ，即文本到语音的转换，又称计算机语音合成。 ASR 技术（ Automatic Speech Recognition ），是将声音转化为文字，可类比于人类的耳朵。</p><p></p><h3>OCR 在银行的应用：提高工作效率和准确性</h3><p></p><p>OCR技术在银行中的应用，传统典型的应用场景主要是识别身份证、护照和银行卡等要素，为客户提供便捷的身份验证和账户开立流程。总的来说，通过使用OCR技术，银行可以实现自动化的识别和数据提取，提高业务处理的效率和准确性，降低成本，并改善客户体验。</p><p></p><p>周文彬举例道，票据录入是银行在办理业务时经常面临的场景之一。尽管在简单环境下，基于专用的OCR技术可以实现高准确率的识别，但其处理过程却极为繁琐复杂。该过程涉及多个步骤，比如灰度化、二值化、去黑边等，导致识别速度缓慢，并且对于识别图像的质量有比较高的要求——例如票据只允许单张上传，多张票据混合在同一页面会造成识别失效。</p><p></p><p>随着银行业务的数字化进程的加速，用户对OCR的智能化能力提出了更高的要求。比方说在报销场景中，需要识别多种不同类型的票据，如船票、车票、全电发票等。同时，这些票据往往会混合在同一张图片上，或者手机拍摄的照片或复印件，导致图像模糊不清。传统的OCR方法在这种“混合场景”中显得力不从心。因此，东亚中国研发团队正在引入深度学习的OCR技术解决方案，以来应对各种复杂的业务场景。</p><p></p><p>除了上述混合识别场景，OCR在银行合同签署管理上也发挥巨大作用。传统的合同管理过程通常繁琐且容易出错，而通过将合同扫描到系统中，并利用OCR技术自动识别合同内容和变化，银行可以实现快速合同比对和审核，大大提高了合同管理的效率和准确性。</p><p></p><p>周文彬介绍了合同审核中的一个常见难题：尽管公司拥有标准的合同模板，但每次与供应商合作都存在特殊性：合作内容和条款通常需要根据公司要求对标准模板进行补充和调整。然而，项目经理并非专业的法律顾问，因此在调整过程中可能会出现词汇不够准确的情况。此外，在整个合同审核流程中，还需要多个部门（如采购、科技风险和法务等）进行审核。一旦业务条线提出异议，就需要将合同退回给发起人进行修改，整个过程涉及多个版本的合并。</p><p></p><p>所以为了有效应对法律风险、合规风险和操作风险，审核工作需要人工逐页核对、与模版合同做对比，判断条款是否有增、删、改。但当合同有数十页甚至上百页时，即使投入了大量的人力进行检验审核，也无法完全保证核对效果，效率也很低，同时也对后续的审计工作产生较大的困难。因此，东亚中国利用OCR技术和NLP技术对关键信息进行提取，可以将所有合同扫描进系统，AI 会自动识别并比对签署版本内容和合同模版之间的差异，包含一对一比对与批量一对多比对，在确保审核准确度的前提下，大幅提升效率。</p><p></p><p>总的来说，东亚中国目前主要利用 OCR 来解决复杂场景识别和合同审核场景所对应的“准确度”和“效率”两大痛点。而 AI 中台里的OCR能力，则是往精准度和灵活度更高的方向去发展。</p><p></p><h3>ASR &amp; TTS，从语音质检到“智库”</h3><p></p><p>语音方面的技术，周文彬表示目前主要是在呼叫中心智能化建设方面发挥着重要作用。</p><p></p><p>他主要提到两个方面，首先是语音质检，即通过语音转写和语义理解，对客服接听电话的语气、语音和内容是否符合要求进行评估，取代了以往的人工抽检方式。</p><p></p><p>其次是<a href=\"https://www.infoq.cn/article/32r9H4xdWYmRQLk7vGFC\">辅助功能</a>\"，比如在客服工作中，以前需要查阅手册、搜索电脑系统来获取问题答案和客户信息。未来则希望能通过智能化升级给出话术推荐和营销建议，以最优解方式呈现在客服桌面上，提供更高效的支持。同时，“辅助”能力还包括对客服语速过快、音量调整、检测违规词等情况的实时提醒，以帮助客服及时调整。</p><p></p><p>此外，周文彬表示，东亚中国正在研发自己的智能话术库。不过他指出，其他银行已经有在应用智能话术库，但在运营过程中，其实也是一把双刃剑，用得恰当是一个得力助手，过度依赖的话也会影响客户体验。他举例说，最优秀的保险销售员通常是通过线下社群方式面对面运营的，即使话术再好，也不一定能与客户建立有效链接。因此，技术的作用主要是帮助新手迅速成长、用标准回复提升工作质量，但要成为资深专家，还需要其他经验和技能的积累。</p><p></p><h3>NLP 的多重应用场景</h3><p></p><p>银行业可以将自然语言处理应用到大量的文本和语音数据，其常见应用场景也比较多。比如在银行的呼叫中心智能化建设中，银行可以利用NLP技术构建聊天机器人，以回答客户的常见问题、提供账户信息、处理简单的交易请求等。</p><p></p><p>电话中的智能语音助手也可以通过NLP技术来完成，使得客户能够通过语音与银行进行交互，包括查询账户余额、进行转账、报告卡片丢失等操作。NLP技术可以让语音指令能够被准确地解释和执行。</p><p></p><p>此外，NLP还可以用于分析客户的文本反馈、社交媒体帖子和评论等，以获得有关客户满意度、产品偏好和市场趋势的洞察。</p><p></p><h2>旧方案与新技术的“冲突”，如何平衡？</h2><p></p><p>然而，周文彬指出 AI 中台的建设过程往往会面临一些挑战和难点。</p><p></p><p>比如，很多中小银行为了满足各业务条线的人工智能场景需求，选择引入成熟的 AI 厂商能力。然而，这导致了AI应用场景分散在各业务系统中，虽拥有多种 AI 的原子能力，但是无法实现能力的复用与合理编排。</p><p></p><p>在东亚银行 AI 中台的建设过程中，也遇到了类似的挑战。其中一个难点是如何将现有的 OCR 系统与中台内新的 OCR 解决方案整合成一体，以确保统一的业务逻辑和结果输出。这类似于超市的“翻新”工程，超市要如何既进行翻新工程但又不耽误经营呢？</p><p></p><p>针对这一难题，东亚目前采取了以下方案：集中管理OCR的能力，并利用已有的 OCR 解决方案来处理现有简单场景，而对于复杂的新场景则采用新的OCR解决方案。在架构规划上，将新旧两个 OCR 解决方案都定义为工具类服务，提供OCR的标准接口，以增强统一性和复用性。每新增一个业务场景，如涉及OCR能力的使用，都会调用银行内部统一的OCR服务。通过这种整合方式，可以确保不同场景对于OCR的需求，同时能够统一管理AI能力，以避免重复造“轮子”。</p><p></p><p>此外，这也引出了一个重要问题，即在引入 AI 技术时，大概率会面临现有架构的冲突。这时候是新场景用新 AI 技术，还是说全部推倒重来？</p><p></p><p>这个问题的复杂性在于不同场景可能需要不同的解决方案，尤其对于银行这种业务复杂、多条线业务并存的情况。周文彬强调，新的业务场景下，有时需要使用新的 AI 技术，而在某些场景中，保持现有复杂的解决方案可能更为适合。每个银行和机构都有其特定的需求和实际情况，因此需要针对不同场景进行定制。</p><p></p><p>他认为，虽然已有一些国内银行在 AI 中台建设方面取得了成果，但整个领域仍处于探索的初级阶段，还需要不断尝试和落地。</p><p></p><h2>数字化思维和业务理解并行</h2><p></p><p>在银行内实施 AI 项目，除了需要具备数字化思维，深入了解业务同样很重要。</p><p></p><p>比如在设计数字化场景或产品时，需要充分了解业务数据安全和产品定位。尤其是在银行等领域的应用中，个人信息保护、商业机密及数据安全是需要格外关注的方面。我们要避免让 AI 技术带来便利性的同时，忽略了安全和合规问题。</p><p></p><p>其中，周文彬举了合同比对功能的例子。其指出，在进行合同比对功能时，会涉及到多种不同类型的合同，如个人贷款合同和企业合同。但 AI 中台或 OCR 等技术只是工具，它可以帮助处理合同数据、提取关键信息等，业务合规方面的考虑应由调用方业务系统来完成。</p><p></p><p>最初，技术供应商设计的合同比对功能如下：如果发现不一致之处，文字会被存储在数据库中，以便查看历史记录。从工具类系统设计的角度来看，将文字对比后的差异片段保存下来并没有太大问题。然而，结合业务场景来评估的时候，我们发现发现该功能可能会涉及个人合同比对或企业商务合同中个人信息部分的核对，各类业务场景的调用可能会无意间导致系统存储大量客户敏感信息。而该功能仅作为一个工具服务存在，是不应涉及存储与管理客户敏感信息。</p><p></p><p>因此，在每个系统设计之初，关注数据信息的使用和保护是至关重要的。这里就凸显了架构平台部对整体架构统一规划和管理的重要性，在该系统的前期架构评审中，就明确为工具类应用，不存储和管理客户敏感信息。经东亚银行项目团队与供应商产品团队的沟通后，供应商同意对原产品进行改造，在每一次的查询结果显示完毕后，比对数据立即从后台数据库中被删除。当需要查看历史记录时，则通过业务系统调用的方式重新提交查询，这样的改进保证了数据的安全性和隐私保护。</p><p></p><p>“技术本身并无好坏，其使用效果的好坏取决于人们如何运用。在评估供应商提供的技术产品时，我们需要提前了解新场景的需求和后续的发展方向，保持专业的敏感度和前瞻性，对产品的差异性进行评估。这包括产品设计、详细构成、设计要求、功能、使用范围和用途等方面。”周文彬进一步说，“我们不能简单地认为市面上成熟产品一定是最好的，每家金融机构都有自己的定位，经过差异性分析后往往需要进行大量的客制化改造，以打造出适应各家机构自己的系统。因此，最适合自身需求的产品才是最好的选择。”</p><p></p><h2>小结</h2><p></p><p>综上，在数字化历程中，对于银行搭建 AI 中台或应用其他 AI 技术时需要重点考虑的因素，周文彬总结了以下方面的建议：</p><p></p><p>首先，明确目标和战略。每个银行对于数字化转型的定义都不同，因此明确机构的目标和战略非常重要。比如是追求业务增长、改善客户体验，还是确保数据的准确性和合规性，这些都需要明确定义。东亚银行的战略及数字化办公室在推动和实现数字化转型方面取得了重要的成效，因此得到了高层领导的关注与支持。</p><p></p><p>其次，制定综合的计划。在企业数字化转型的过程中，AI的应用是一个复杂的过程，涉及多个业务场景和技术。制定综合计划时，需要考虑组织的资源和人员能力是否足够，并制定明确的路线图，逐步实施和集成。</p><p></p><p>第三，重视数据管理和数据质量。数据在 AI 应用中起着核心作用，无论是训练模型还是其他应用，有效的数据管理策略是必要的，包括收集、存储、清理和标准化等环节，以保证数据质量和满足后续的要求。</p><p></p><p>第四，培养内部的数字化技能和文化。人员的技能需要与业务的数字化要求相匹配，例如供应链业务的线上签约场景，需要对各个环节数据的保密性、完整性、和抗抵赖性以及证据链的防篡改等方面具备相应技能的数字化人才参与。此外，鼓励创新和探索的文化也是重要的，以提高效率和推动进步。</p><p></p><p>第五，风险管理和合规性是不可忽视的方面。应用 AI 技术时，必须重视风险管理和合规性，确保结果可靠和符合监管要求。需要建立有效的风险管理措施，进行新产品评估和相关审查，并参考监管要求以保持一致性。</p><p></p><p>（本文受访嘉宾所提供的信息和发表观点为其个人意见，不代表所在企业立场。）</p>",
    "publish_time": "2023-07-05 12:14:21",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "2023 可信数据库发展大会在京成功召开！",
    "url": "https://www.infoq.cn/article/tQtvumNcUUEZuf4Tglex",
    "summary": "<p>当前，全球数字经济加速发展，数据正在成为重组全球要素资源、重塑全球经济结构、改变全球竞争格局的关键力量。数据库作为存储与处理数据的关键技术，在数字经济大浪潮下，全球<a href=\"https://xie.infoq.cn/article/9620099f9dba05a788713a3e6\">数据库产业</a>\"中新技术、新业态、新模式不断涌现。</p><p></p><p>2023 年 7 月 4 日，由中国通信标准化协会和中国信息通信研究院主办，大数据技术标准推进委员会承办，InfoQ 联合主办的<a href=\"https://www.infoq.cn/article/GQXOXrhBD3PisE1YsEjA\">“ 2023 可信数据库发展大会”</a>\"主论坛在北京国际会议中心隆重召开。中国通信标准化协会副理事长兼秘书长代晓慧以视频方式致辞，中国信息通信研究院副院长王志勤出席会议并致辞，清华大学、复旦大学、中移信息、上海国际汽车城、华为云、腾讯云、科蓝软件、阿里云、浪潮KaiwuDB、蚂蚁集团、云和恩墨、深算院等行业内专家代表出席会议并发表主题演讲。大会重磅发布多项中国信通院及中国通信标准化协会大数据技术标准推进委员会（CCSA TC601）在数据库领域的最新研究和实践成果。大会由中国信通院云计算与大数据研究所副所长魏凯主持。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e1/e11d1ac334bf6ed5ca5c46b27ad1d108.jpeg\" /></p><p></p><p>代晓慧在致辞中表示，中国通信标准化协会是信息通信领域全国性标准化组织，紧密围绕国家信息技术战略需求，大力推动数据库等信息技术领域标准体系建设，取得了诸多进展。“十四五”是我国数字经济发展和数据要素市场培育的关键时期，数据库作为支撑数据存储和计算的核心组件，正发挥重要支撑作用。下一步，协会将加快推进数据库领域关键技术标准体系研制，充分发挥标准引领作用，助力我国数据库产业高质量发展，共筑数字经济可信底座，为我国数字经济发展做出更大贡献。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d1/d142f3ea7b2e4c19951880b7ca588dfe.jpeg\" /></p><p></p><p>王志勤在致辞中表示，中国信通院在工业和信息化部指导下，积极推进落实国家政策，持续围绕数据库技术、产业及应用进行深入研究，逐步构建“可信数据库”评估评测体系，发布多本技术与产业报告，不断为业界输出智库洞察，努力搭建行业交流平台。未来，中国信通院将持续深耕数据库领域研究与应用，助力我国数据库产业自立自强高水平发展。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a4/a40a5ea4cd36b8ca7aa45adbf231ea66.jpeg\" /></p><p></p><p>中国通信标准化协会互联网与应用技术工作委员会主席何宝宏在会上正式发布《数据库发展研究报告（2023年）》。《数据库发展研究报告（2023年）》（以下简称“报告”）围绕数据库相关产业、技术及行业应用情况进行了深入研究及探讨。报告指出，当前我国数据库行业市场前景广阔，产业欣欣向荣，正在经历由“数量型”向“质量型”关键转变期。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3b/3b41dc0bd44f0963353bcd2a3aa2a4c6.jpeg\" /></p><p></p><p>清华大学计算机系长聘教授、副主任，博导，IEEE Fellow 李国良发表题为“数据库与大模型”主题报告，围绕目前各界关注度较高的数据库与大模型技术融合进行了分享。针对大模型在数据库领域落地应用情况及未来面临的挑战和数据库为大模型带来的价值进行了深入阐释。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/48/4890df660864596c8b6f33d224b56669.jpeg\" /></p><p></p><p>中移动信息技术有限公司副总经理陶涛发表题为“构建大数据湖仓一体生态，促进数据要素价值发挥”主题演讲。围绕湖仓一体产生的背景架构方案和实践案例进行阐述，并希望产业合作伙伴能够携手共同构建湖仓一体新生态。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/25/25d9dfc018ae88eb41e41e193fcd92f1.jpeg\" /></p><p></p><p>上海国际汽车城（集团）有限公司党委副书记、总经理潘晓红发表题为“打造世界级智能新能源汽车公共数据中心，赋能汽车产业数字经济新生态”主题演讲。围绕汽车城在汽车产业创新转型、数字赋能方面进行经验和实践分享。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9b/9b18d0d0abc079bd571ef7469038cd8b.jpeg\" /></p><p></p><p>华为云数据库服务产品部总经理苏光牛在会上进行了分享。他表示，华为在数据库领域的技术积累已经有 20 多年，未来也将坚定不移投入数据库研发。华为云 GaussDB 的发展战略，一是深入金融行业，一次性解决金融客户数字化转型和可持续发展的双重诉求，二是要从金融走向政务、能源、交通等更多关键信息基础设施行业。并分享了华为如何通过技术创新，打造端到端可信的数据库产品。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a3/a38bb21fbda96ab5bafd960f2aed3594.jpeg\" /></p><p></p><p>腾讯云数据库总经理王义成发表题为“腾讯云 TDSQL 助力金融业核心系统国产化转型”主题演讲。详细阐述了 <a href=\"https://xie.infoq.cn/article/dcc9581dc2f67b7c70da1bc05\">TDSQL</a>\" 数据库如何助力企业实现数字化转型。王义成表示，随着信息技术的快速发展，企业已意识到数字化转型对于提高效率和竞争力的重要性。在这个过程中，数据库技术发挥着关键作用，而 TDSQL 数据库凭借其高性能、高可用、高安全、易扩展等特点，成为越来越多企业数字化转型的首选方案。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3a/3a654b3dd0f1a5051bc31afc97054354.jpeg\" /></p><p></p><p>北京科蓝软件系统股份有限公司董事长王安京发表题为“由知识产权强国与数据库应用探讨信息安全”主题演讲。强调只有把核心技术掌握在自己手中，才能真正掌握竞争和发展的主动权，只有保护知识产权才能为创新提供保障。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f5/f580e86d7ac8c19f8de5b842d437513f.jpeg\" /></p><p></p><p>阿里云数据库技术架构部负责人、PolarDB 开源数据库总经理、PolarDB 开源社区技术委员会主席王远发表了题为“阿里云瑶池数据库自主研发之路”的主题演讲，围绕云原生数据库技术趋势、瑶池数据库产品体系、以 PolarDB 为代表的云原生数据库核心技术、瑶池数据库安全可信等内容进行分享。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d7/d767decee4e2e3c2001ae636577d0554.jpeg\" /></p><p></p><p>下午举行的“共话数据库产业自立自强高水平发展”圆桌论坛由极客邦科技创始人以及 CEO 霍太稳主持，复旦大学计算机科学技术学院教授汪卫、中移动信息技术有限公司政企业务支撑中心副总经理梁恩磊、云和恩墨创始人兼总经理盖国强、浪潮 KaiwuDB CTO 魏可伟、蚂蚁集团图平台负责人洪春涛、深圳计算科学研究院 YashanDB 产品总监、崖山科技副总裁王南共同探讨数据库产业发展的掣肘因素、数据库技术动向和产业趋势等。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8a/8a6052627f2369392c3695314c593b24.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2b/2b851e3487bc3cec8fed654cf7152f6d.jpeg\" /></p><p></p><p>中国信通院 2023 年上半年“可信数据库”系列评测结果也在大会正式发布。经过严苛的测试和评审，2023 年上半年，共有 28 家企业的 33 款产品通过了本批次 36 项测试。中国信通院云计算与大数据所大数据与区块链部主任姜春宇为通过评测的企业颁发证书，并针对本批“可信数据库”的评测观察进行解读。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/97/97f60437dedb435df6a825ee67e5718c.jpeg\" /></p><p></p><p>浪潮 KaiwuDB CTO 魏可伟发表题为“打造多模引擎，AIoT 数据库探索之道”的主题演讲，重点围绕物联网时代多模态数据融合带来的数据存储与治理的新趋势及新特性展开分析，分享通过“多模数据架构”、“就地计算”、“原生 AI“等关键技术实现物联网时代的数据价值挖掘与行业数字化转型升级实践。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/97/970eed371e46ef8723b223aa4261d671.jpeg\" /></p><p></p><p>蚂蚁集团图平台负责人洪春涛博士发表题为“蚂蚁集团大规模图计算系统应用实践”主题演讲。介绍蚂蚁集团如何基于自研的 TuGraph 企业级图数据管理平台，支撑安全风控、商家服务、会员关系等内部 300 多图应用场景。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d2/d2b3e67dcfd6f63c86385b31582b84af.jpeg\" /></p><p></p><p>云和恩墨创始人兼总经理盖国强做了题为“耕获菑畬，反本归原 - MogDB 的价值主张和技术创新”的分享。当下，我国数据库产品的发展呈现出百花齐放的新局面，云原生、分布式、HTAP 等新技术方向层出不穷，但是如何选择适合自己的数据库产品，如何甄别技术方向与未来，是用户面临的关键挑战。盖国强表示：云和恩墨 MogDB 通过资源池化、三层解耦，自然满足分布式需求，在单机极致性能方向上不断突破；通过单机大容量实时计算、以百 TB 存储起步，毫秒级相应，带来 HTAP 普惠价值。在“十倍性能，百 T 存储”的愿景主张下，云和恩墨 MogDB 产品持续创新，正在为中国数据库产业界贡献独特价值。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fc/fc3e9a5efe6828508763aaf3dcd4e174.jpeg\" /></p><p></p><p>深圳计算科学研究院 YashanDB 产品总监王南发表了题为“从淄博模式，看面向未来的数据库创新和发展方向”的演讲，针对市场和用户对数据库创新发展的关键诉求、痛点，借鉴“淄博模式”，从产品、技术、生态、市场等方面探讨数据库可能的发展路线，以及如何重塑“供需信任”。数据库作为未来全球数字化的底座和基础设施，不但要解决有无问题，更关键的是如何解决社会效率、资源效率、人才效率问题。崖山数据库系统 YashanDB，为数据库行业带来一种新的可能。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/20/20265ea3350ad9dc81aa6537839fc1a4.jpeg\" /></p><p></p><p>主论坛最后，中国信通院云计算与大数据研究所大数据与区块链部副主任马鹏玮对中国信通院 2023 上半年“可信数据库”新增标准进行详细解读，围绕搜索型数据库、数据库一体机、时空数据库、数据库稳定性等方向展现了中国信通院在数据库技术领域最新标准研制进展。</p><p></p><p>除主论坛外，此次大会围绕数据库热点话题设置了金融、电信、互联网以及汽车四大行业应用分论坛，以及云原生与开源数据库、搜索与分析型数据库、数据库运维及生态工具和时空时序及图数据库四大技术研讨分论坛，从供给侧及应用侧等多角度深度呈现中国数据库产业发展格局，为数据库产业高质量发展指明方向。</p>",
    "publish_time": "2023-07-05 13:38:44",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "GPU 容器虚拟化新能力发布和全场景实践",
    "url": "https://www.infoq.cn/article/kqPbdlvF3Jp55PodQLAo",
    "summary": "<p>本文为《大模型时代的 AI 基础设施——百度 AI 大底座》系列云智公开课“AI 算力构建”模块中第二讲《GPU 容器虚拟化新能力发布和全场景实践》的内容精华，以百度智能云资深工程师王利明的演讲视角进行了整理:</p><p></p><p>今天给大家分享的主题是百度智能云在「GPU 容器虚拟化」方面的最新进展和全场景实践，希望通过这次分享和大家一起探讨如何在实际业务场景更好的应用 <a href=\"https://xie.infoq.cn/article/64df7b9a6606c139753658758\">GPU 容器虚拟化</a>\"技术。</p><p></p><p>本次分享将首先介绍百度智能云 GPU 容器虚拟化 2.0 的升级变化，然后介绍新版本中的技术实现方法并演示具体功能，最后介绍在各类业务场景的实践和探索。</p><p></p><p></p><h2>一、双引擎 GPU 容器虚拟化 2.0</h2><p></p><p></p><p>我们去年发布了业内首个双引擎 GPU 容器虚拟化架构，采用了「用户态」和「内核态」两种引擎，以满足用户对隔离性、性能、效率等多方面不同侧重的需求。</p><p></p><p>在隔离引擎之上是资源池化层，该层次主要基于远程调用实现资源的解耦和池化。</p><p></p><p>在资源池化层之上是 K8s 统一资源调度层。在调度机制之上，我们会根据不同业务场景，抽象出来多种混布方式，包括共享混布、抢占混布、分时混布、潮汐混布等。</p><p></p><p>通过以上技术能力支持了各类 AI 业务的落地，包括模型开发、模型训练、在线推理等，大幅提升了 GPU 资源的使用率，减少了 GPU 的使用数量。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f1/f10cdbef4ea67961653626fe20870254.png\" /></p><p></p><p>1.0 版本很好地满足了 AI 场景的业务需求，不管是厂内还是厂外的业务中，得到了比较广泛的应用。</p><p>我们的技术目标就是希望：吃干榨尽所有资源，覆盖所有业务场景，提升业务总体表现。所以 1.0 版本还不够完美，并没有释放 GPU 的全部能力：GPU 上的所有资源在容器虚拟化环境中并没有完全使能，更多的场景是无法使用 GPU 容器虚拟化能力的，所以今年我们继续推出了 2.0 版本。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c6/c6ec1153237ee5de4432d3e6c10551e2.png\" /></p><p></p><p>这是我们双引擎 GPU 容器虚拟化 2.0 架构图。</p><p></p><p>在 2.0 版本中， 除了对 GPU 的显存和 AI 算力进行隔离之外，还实现了对 GPU 的渲染算力和编解码器的隔离。</p><p></p><p>基于这些新的能力，在资源调度层面可以提供渲染混布和编解码混布，实现了 AI 算力、渲染算力、编解码器等 GPU 全部资源的统一调度。</p><p></p><p>同时，2.0 版本可以通过多调度器的方式，支持客户的现有业务平滑融合到我们的架构中，这对客户业务能够快速使用最新的 GPU 容器虚拟化能力，是非常重要的。</p><p></p><p>在这些新能力的支持下，更多的业务场景，比如自动驾驶仿真、ARM 平台的云游戏等都可以通过这套平台提升资源利用率，将所需 GPU 的使用量明显降低。</p><p></p><p>除此之外，两个容器虚拟化引擎我们都会随着底层库的更新进行不断迭代，确保用户能够使用业界最新的技术。其中用户态支持最新版本 nvidia driver 和 cuda 12.1，内核态支持 nvidia driver 525/530/535 等最新版本。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4a/4aa28fa4c8d76a700335cd916f9660ea.png\" /></p><p></p><p></p><h2>二、新能力技术解析</h2><p></p><p></p><p>接下来我会详细介绍渲染算力和编解码器隔离的技术方案。</p><p></p><p>首先我们先分析一下 AI 算力和渲染算力的区别。</p><p></p><p>在 NVIDIA GPU 上不仅能进行 AI 计算，还可以做图形的渲染计算。AI 负载通过 Cuda 访问 GPU，渲染负载通过 OpenGL/Vulkan 访问 GPU。这两类计算均使用相同的算力资源。</p><p></p><p>那么在 AI 计算隔离已经实现的基础上，渲染负载能否在 AI 计算的隔离环境中成功运行？</p><p></p><p>如果渲染负载能够隔离成功，使用哪种类型的 GPU 容器虚拟化引擎是合适的方案？</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/60/6093fc9375973bd5d4ce04ed7d31456d.png\" /></p><p></p><p>接下来我们详细分析一下 AI 算力架构。</p><p></p><p>从上往下看，最上层的是 AI APP，它们依赖于底层的 Cuda 系列库，包括 cuda-x，cuda runtime 等，它们给上层 AI APP 提供易于使用的高级 API。再往下就是应用层 driver 库，包括 cuda driver，NVML 等，它们会通过设备文件和内核态的 driver 进行通信，最终达到使用 GPU 的目的。</p><p></p><p>架构图中灰色的箭头是 AI 程序使用 GPU 的控制流，红色的箭头是 AI 程序使用 GPU 的的数据流。</p><p></p><p>那么 AI 算力架构和渲染架构有什么不一样呢？我们继续往下看。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/77/779597c8f992218d105d262848905fd2.png\" /></p><p></p><p>渲染算力架构，从上往下看，最上层的是 UI/3D APP，比如游戏引擎，它的底层库相比 AI 算力架构要复杂一些，调用底层库主要包括两种方式：通过转发层 GLX 调用 X11 server，或者直接调用 EGL。</p><p></p><p>最终他们都会调用底层的图形库 OpenGL 或者 Vulkan，这些图形库就相当于 AI 计算中的 Cuda 库。</p><p></p><p>再往下就是应用层 driver 库，包括 libnvidia-glcore/libnvidia-eglcore/libdrm 等，它们也是通过设备文件和内核态的 driver 进行通信，最终达到使用 GPU 的目的。</p><p></p><p>架构图中灰色的箭头是渲染程序使用 GPU 的控制流，红色的箭头是渲染程序使用 GPU 的数据流。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f2/f2426c5bd6750b0f94ffd0bf9d33fc3a.png\" /></p><p></p><p>经过以上分析和对比，我们可以发现 AI 算力架构和渲染算力架构，虽然上层软件不同，但是他们的控制流都是一致的，使用相同的设备文件和内核模块进行通信。</p><p></p><p>回到我们之前的问题，渲染负载能否在 AI 计算的隔离环境中成功运行？依据这个分析结果预测，渲染应用是可以在 AI 算力的隔离环境中运行。</p><p></p><p>但是在实际验证中，结论是否定的。</p><p></p><p>经过逆向分析发现两个方案的控制命令字存在一些差异，需要将这部分差异在隔离实现中区分开来。通过大量的实验后，最终在内核层面实现了渲染算力的隔离。</p><p></p><p>为什么我们没有选择在用户态实现这个方案呢？</p><p></p><p>因为用户态实现需要拦截的上层库函数多，实现难度高。同时，对用户的软件不透明。所以通过<a href=\"https://xie.infoq.cn/article/25df22c38dc0e925879ce4e9b\">用户态</a>\"实现渲染算力隔离并不是一个好的工程方案。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a5/a5c4935c4145f6bce23021d157437bdc.png\" /></p><p></p><p>接下来我向大家演示 AI 算力和渲染算力的隔离效果。演示的硬件环境为一张 NVIDIA V100 16G。</p><p></p><p>在这个 GPU 上运行单个 AI 负载，pytorch resnet50 训练，batch-size 为 32 时，分配 100% 算力，吞吐在 340 左右。运行单个渲染负载，使用的 GPUtest 的 Furmask 测试，分配 100% 算力，FPS 在 550。在混合负载测试中，一个 AI 负载，一个渲染负载，各分配 50% 算力，AI 负载的吞吐为 170，渲染的 FPS 为 260~270。</p><p></p><p>可以看到在单个 GPU 上，AI 负载和渲染负载都实现了隔离，获得了约一半的算力，得到了预期的性能表现。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/37/376074f4ed00ec4dc0684dce37c62bd5.png\" /></p><p></p><p>在 2.0 版本中，另外一个新增的功能就是编解码器的隔离。</p><p></p><p>我们分别在用户态和内核态都实现了编解码实例。</p><p></p><p>用户态的编解码器实例中，编解码器是裸混使用，不支持对编解码器的算力做隔离，每个实例都可以全部编解码算力。</p><p></p><p>内核态的编解码器实例中，我们实现了对编解码器的隔离，在实例中编码器的权重和 AI 算力、渲染算力的权重共享，做到统一算力分配。</p><p></p><p>那么内核态和用户态的实现有什么不同呢？用户态在实例中使用的是编解码器的全部算力，而内核态实现了编解码器的算力分配。比如在内核态分配 20% 的算力，那么你就可以在内核态的编解码实例中使用 20% 的编解码能力。</p><p></p><p>这样我们就完成了 GPU 资源的统一算力分配和使能，做到了资源的吃干榨净。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/39/398f3101d9e67c03dfba07e638e3c226.png\" /></p><p></p><h2>三、全场景实践</h2><p></p><p></p><p>接下来我们将会结合前面的技术，做各个场景的实践分享。</p><p></p><p>我们先看看用户态和内核态两个引擎在技术和场景上的差异。</p><p></p><p>在技术特性对比上，业务层一般会在隔离性能的强弱、延时高低、资源分配颗粒度、多用户支持能力等维度做技术考量，为应用匹配合适的 GPU 容器虚拟化引擎。</p><p></p><p>依据这些特性的分析，我们列出了不同应用场景适用的技术方案。</p><p></p><p>比如在线推理，对延时的要求很高，一般就会推荐用户态的方案。离线推理，则两种方案都可以选择。在渲染仿真场景，由于用户态不支持渲染隔离，故只能使用内核态的方案。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/71/71bc3f92bf0280cda48a0994667a5ce2.png\" /></p><p></p><p>这是一个经典的互联网的推荐业务，包含了数据处理、模型开发和在线服务等业务。其中数据处理和模型开发是离线业务，用来支持在线服务，所有业务都使用了大量的 GPU。</p><p></p><p>在没有使用 GPU 容器虚拟化方案之前，每个业务实例使用一个 GPU，通过大量的监控数据发现，在线推理服务的整体 GPU 使用率并不高，整体在 20%，这是一个业界普遍存在的问题。</p><p></p><p>因为在线服务对时延要求比较高，我们在这种场景选择部署用户态的方案。在保证业务 SLA 相同的情况下，大幅提升整体 GPU 资源使用率，将整体资源利用率到 35%。</p><p></p><p>在结合用户态本身支持的抢占混布和分时混布，使得数据处理和模型开发等离线任务，可以和在线推理业务进行在离线混布，当在线业务处于波谷时，离线业务抢占较多 GPU 空闲资源进行业务处理，节省了整体的 GPU 使用数量。</p><p></p><p>这种场景在厂内和厂外都得到了大量的应用，节省了很多的成本。在 GPU 资源比较紧张的时代是一个很好的技术选择。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bf/bf86ed9a297429696383ea79ebabf05e.png\" /></p><p></p><p>很多客户的平台中已经存在自己定制的任务调度器，包括自定义的排队算法等功能。客户如果要引入第三方供应商的 GPU 容器虚拟化平台，则需要使用相应的任务调度器。</p><p></p><p>如何使得定制的任务调度器和百度智能云的任务调度器在客户业务中共存，一种方式是使用多套 K8s 集群，这会导致管理复杂。另外一种方式就是使用百度智能云开发的多调度器支持方案，在同一 K8s 调度集群内使用多个调度器。</p><p></p><p>在这个方案里面我们将 GPU 资源分为两个池子，通过标签识别两个 GPU 池的资源。任务描述使用不同的标签，K8s 会把任务分配对应的任务调度器，从而使不同任务调度器的共存。</p><p></p><p>如果客户使用的是开源版的任务调度器，未做深度改动，则可以通过这套方案实现业务的平滑过渡，最后将所有业务都迁移到百度智能云的任务调度器上。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/23/23df99ab60754e95d71e67d4e5e5c078.png\" /></p><p></p><p>开发人员会用小规模的模型进行调试、验证、算子开发等工作，这些模型参数规模一般在 1.5B 以内。一般使用一块 A100 或者 A800 GPU 进行，支持 2~4 个用户。</p><p></p><p>但是在开发过程中，GPU 有较多时间处于空闲状态，导致整体 GPU 使用率较低。</p><p></p><p>同时，每个开发人员需要大量的存储资源，保存自己的训练数据和模型数据，需要通过大容量的远程文件系统来存储。</p><p></p><p>远程文件系统要挂载到客户容器内，需要采用不同参数进行挂载，以挂载不同的卷。这是通过不同用户的 user id 来识别用户的身份来实现的。</p><p></p><p>但是用户态虚拟化不支持不同 user id 的用户使用，即不支持多用户隔离，无法在此场景使用。内核态虚拟化可以实现多用户隔离，可以保证不同用户同时挂载不同的资源来使用。</p><p></p><p>内核态虚拟化支持 burst 调度策略，可以只针对活跃的容器负载，按照权重进行算力分配。比如一个 GPU，虚拟化给两个用户使用，平分 50% 的算力，当只有一个用户实际使用 GPU 时，调度策略会把所有算力分配给此用户。当两个用户都在使用时，各使用 50% 的算力。</p><p></p><p>这样既提供了共享算力的能力，又总体提高了 GPU 的使用率和业务表现。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/82/82800fa8e0a4bee4108322ae209e6c1e.png\" /></p><p></p><p>自动驾驶仿真场景涉及到了 3 个模块，其中渲染仿真编码模块和感知推理模块使用了 GPU，覆盖了 AI 计算、图形渲染和编解码器等全部资源类型。</p><p></p><p>在没有使用 GPU 容器虚拟化方案之前，渲染仿真编码仿真使用一块 GPU 运行类似游戏引擎的环境，实时渲染出车辆和路面状况，每隔 1 到 2 秒，截取一张图片编码后输出给感知推理模块。感知推理模块使用另外一块 GPU，运行类似图像识别和分类推理的 AI 模型，识别出车道线、行人、障碍物等，把数据给规控模块。规控模块会根据感知数据，规划和控制车辆的下一步状态，发送控制命令给仿真模块，进行下一步操作。</p><p></p><p>这时候业务对 GPU 的使用率都较低，不超过 50%。</p><p></p><p>我们采用内核态虚拟化技术，在同一个 GPU 上同时运行仿真和推理任务，每个任务分配 50% 的算力，达到同时在一个 GPU 运行两种不同的负载。同时数据在一个 GPU 中的显存传递，提高了数据传输效率，提升了业务性能。</p><p></p><p>相比过去，这样在仿真环境提高了 100% 的 GPU 使用率。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e8/e823cd7ee9591e8d2fbbee97ec06b259.png\" /></p><p></p><p><a href=\"https://www.infoq.cn/article/25BE8j4cPhYs2euyvrwH\">云游戏</a>\"通常是同一个 GPU 上运行多个容器，每个容器运行着一个完整的 android 实例。在这个实例里包含了 android 的运行时环境，在最上面会运行一个 android 游戏，例如王者荣耀、和平精英、原神等。</p><p></p><p>因为云游戏是没有真实屏幕的，只有模拟出来的虚拟屏幕，每个实例会使用 GPU 渲染资源，把游戏的图像界面渲染到虚拟屏幕的上。这些图像画面会通过对虚拟屏幕的截屏和编码，输出成类似 H.264 视频流，通过流媒体协议播放到用户的手机客户端上。</p><p></p><p>在没有使用 GPU 容器虚拟化方案之前，多个云游戏实例是通过裸混争抢的方式，共享 GPU 的渲染资源，可以说是没有任何服务保证和资源隔离能力的，导致游戏体验无法进行 SLA 管理。</p><p></p><p>由于手机云游戏运行在 ARM 平台中，我们做了大量新的技术开发，使得整个云原生 AI 平台能够运行在 ARM 上。</p><p></p><p>我们使用内核态方案来对每个 android 实例进行管理，进行渲染显存的隔离，保证显存分配的 QoS。</p><p></p><p>那么在这个场景中，我们为什么没有用内核态虚拟化对渲染算力和编解码器做隔离？因为云游戏对实时性要求比较高，内核态虚拟化无法满足时延的要求，渲染隔离更多满足对实时性不高的场景。所以在这个场景，只使用了内核态虚拟化的显存隔离能力，保证显存分配的 QoS。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/39/394d603a9c1d2feee003f7d188dafac9.png\" /></p><p></p><p>请大家持续关注后续章节精彩内容，下一节由百度智能云资深工程师陈志鹏分享的《面向大模型的存储加速方案设计和实践》即将在 7 月 5 日 19:30 上线，点击<a href=\"https://www.infoq.cn/form/?id=1631&amp;utm_source=1&amp;sign=iq_647ee213d1be4\">链接</a>\"即可报名。</p>",
    "publish_time": "2023-07-05 14:45:54",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "全球数字经济大会召开 蚂蚁旗下两项目入选“人工智能行业赋能典型案例”",
    "url": "https://www.infoq.cn/article/iBHmuLWBH14YgWjhD1Xq",
    "summary": "<p>近日，“2023 全球数字经济大会”人工智能高峰论坛在京召开。会议发布了一批<a href=\"https://xie.infoq.cn/article/2858ee89f581665400779ac2e\">人工智能行业赋能</a>\"典型案例，为行业提供重要的示范效应，以推动大模型应用加速赋能千行百业。其中，蚂蚁集团旗下数字藏品平台“鲸探”及内容安全平台“天鉴”两项目成功入选。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/62/629c31ae68695e175d4e847f4ac54e8f.png\" /></p><p></p><p>据了解，作为国内数字藏品头部平台，鲸探较早将 <a href=\"https://www.infoq.cn/article/uui4NVydvW9GO32OA3tB\">AIGC</a>\" 视为战略探索方向，今年 4 月份，鲸探在业内率先引入 AIGC 技术功能，为用户提供 AI 作画工具，并支持输入文字生成图片、输入图片生成图片两种模式。</p><p>&nbsp;</p><p>目前已经有百万级用户在鲸探平台体验使用。未来，内容创作或可借助 AIGC、<a href=\"https://xie.infoq.cn/article/c370f16c02bee18aba609b8d7\">区块链</a>\"技术实现作品版权保护和确权，进一步激活文化行业数字生命力。</p><p>&nbsp;</p><p>在 AI 内容安全方面，蚂蚁集团数字内容安全平台天鉴集大数据底座、AI 计算平台、智能运营、应用场景为一体，可高效抵御内容伪造、音视频多模风险、AIGC 内容真实性等新型内容风险。自落地以来，已在零售、金融、直播、游戏等数字化行业完成内容安全能力部署。</p><p>&nbsp;</p><p>公开资料显示，蚂蚁集团于 2015 年投入研究可信 AI，构建了可解释性、公平性、鲁棒性、隐私保护在内的技术架构，并逐步将自研技术对外开放。2023 年 1 月，全球专利权威机构 IPR&nbsp;Daily 发布的报告显示，蚂蚁集团“AI 安全可信关键技术”专利数连续两年全球第一。</p>",
    "publish_time": "2023-07-05 14:58:16",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]