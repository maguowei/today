[
  {
    "title": "Terraform引入新的CI/CD工具，增加对Azure Linux的支持",
    "url": "https://www.infoq.cn/article/H7CJpGyk0BRjUTAqIXbM",
    "summary": "<p>HashiCorp发布了一系列针对Terraform和Terraform Cloud的改进。Terraform Cloud提供了一个新的<a href=\"https://www.hashicorp.com/blog/hashicorp-releases-new-ci-cd-pipeline-integration-tool-templates-for-terraform\">CI/CD管道集成工具</a>\"。Terraform为Azure Kubernetes Service增加了对<a href=\"https://www.hashicorp.com/blog/terraform-adds-support-azure-linux-container-host-azure-kubernetes-service\">Azure Linux容器主机</a>\"的支持。HashiCorp Terraform <a href=\"https://www.hashicorp.com/blog/terraform-aws-provider-5-0-adds-updates-to-default-tags\">AWS Provider 5.0</a>\"发布，改进了对默认标记的支持。</p><p>&nbsp;</p><p>新的CI/CD管道工具有一个相关的命令行工具，叫作tfci。这个工具通过API调用自动运行Terraform Cloud，并支持可以嵌入到CI工具中的Terraform Cloud操作。tfci提供的<a href=\"https://github.com/hashicorp/tfc-workflows-tooling/blob/main/docs/USAGE.md\">命令</a>\"包括：通过Terraform Cloud Run ID显示运行详情、执行新的计划运行、在计划确认后继续执行暂停的任务，以及返回计划详情。</p><p>&nbsp;</p><p>除了tfci，还有为<a href=\"https://github.com/hashicorp/tfc-workflows-github/blob/main/actions/plan-output/action.yml\">GitHub Actions</a>\"和<a href=\"https://github.com/hashicorp/tfc-workflows-gitlab\">GitLab CI</a>\"提供的<a href=\"https://github.com/hashicorp/tfc-workflows-tooling\">模板</a>\"。这些模板包含用户在使用tfci时可能需要配置的常见操作。例如，下面的代码片段是在GitHub Actions中使用tfci执行计划的部分内容：</p><p><code lang=\"null\">runs:\n  using: docker\n  image: 'docker://hashicorp/tfci:v1.0.1'\n  args:\n  - tfci\n  ## global flags\n  - -hostname=${{ inputs.hostname }}\n  - -token=${{ inputs.token }}\n  - -organization=${{ inputs.organization }}\n  ## command\n  - run\n  - create\n  - -workspace=${{ inputs.workspace }}\n  - -configuration_version=${{ inputs.configuration_version }}\n  - -message=${{ inputs.message }}\n  - -plan-only=${{ inputs.plan_only }}</code></p><p>&nbsp;</p><p>HashiCorp还增加了在Azure Kubernetes Service上部署Azure Linux容器主机的支持。微软最近提供了<a href=\"https://learn.microsoft.com/en-us/azure/aks/use-mariner\">Azure Linux容器主机</a>\"（之前的Mariner OS）的<a href=\"https://www.infoq.com/news/2023/06/azure-linux-cbl-mariner/\">一般可用性</a>\"。Azure Linux被设计成一个最小化的、云优先的Linux发行版。</p><p>&nbsp;</p><p>这些更新包含在<a href=\"https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/kubernetes_cluster\">azurerm Terraform Provider</a>\"中。要在AKS上配置Azure Linux容器主机，可以将os_sku设置为Mariner：</p><p><code lang=\"null\">resource \"azurerm_kubernetes_cluster\" \"default\" {\n  name                = \"aks-${random_string.suffix.result}\"\n  location            = azurerm_resource_group.default.location\n  resource_group_name = azurerm_resource_group.default.name\n  \n  kubernetes_version  = var.kubernetes_version\n  dns_prefix          = \"k8s-${random_string.suffix.result}\"\n \ndefault_node_pool {\n    name            = \"default\"\n    node_count      = var.aks_node_count\n    vm_size         = var.aks_confidential_computing_enabled ? \"Standard_DC2s_v2\" : \"Standard_D2_v2\"\n    os_sku          = \"Mariner\"\n    os_disk_size_gb = 50\n  }\n \n  confidential_computing {\n    sgx_quote_helper_enabled = true\n  }\n \n  identity {\n    type = \"SystemAssigned\"\n  }\n \n  tags = {\n    name = \"demo-aks-${random_string.suffix.result}\"\n    environment = \"demo\"\n  }\n}</code></p><p>&nbsp;</p><p><a href=\"https://github.com/hashicorp/terraform-provider-aws/releases/tag/v5.0.0\">HashiCorp Terraform AWS Provider 5.0</a>\"改进了对默认标签的支持，允许在Provider级别设置标签。这个更新解决了之前默认标签实现的许多痛点，包括处理不一致的最终计划、默认标签和资源标签之间的相同标签，以及标签配置中的永久差异。</p><p>&nbsp;</p><p>可以使用default_tags在Provider级别指定默认标签：</p><p><code lang=\"null\">provider \"aws\" {\n  default_tags {\n    tags = {\n      environment = \"Dev\"\n      department  = \"WebEng\"\n      application = \"HashiCafe website\"\n      cost_center = \"8675309\"\n    }\n  }\n}\n \nresource \"aws_s3_bucket\" \"example\" {\n  bucket = \"example-bucket-aj-11122\"\n  tags = {\n    environment = \"Production\"\n    created_at  = timestamp()\n  }\n}</code></p><p>&nbsp;</p><p>该版本还调整了已弃用或已删除的属性的报告方式，之前用户会收到警告通知，现在会向用户显示“不受支持错误”。EC2的典型功能也被完全移除，因为这些功能早在2022年8月就被AWS弃用了。</p><p>&nbsp;</p><p>CI/CD管道集成工具和模板对Terraform Cloud和Terraform Enterprise用户可用。更多细节可以在<a href=\"https://www.hashicorp.com/blog/hashicorp-releases-new-ci-cd-pipeline-integration-tool-templates-for-terraform\">发布博客</a>\"和<a href=\"https://github.com/hashicorp/tfc-workflows-tooling\">GitHub代码库</a>\"中找到。Terraform AWS Provider 5.0提供了一个<a href=\"https://www.hashicorp.com/blog/terraform-aws-provider-5-0-adds-updates-to-default-tags\">升级指南</a>\"，其中包含了有关该版本变更的更多详细信息。</p><p></p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/06/hashicorp-azure-linux/\">https://www.infoq.com/news/2023/06/hashicorp-azure-linux/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/LFa4ESMJOMY66HtTjYsG\">中国企业研发高效能白皮书-CI/CD篇</a>\"</p><p><a href=\"https://www.infoq.cn/article/lPSPNxwMD2US2WEHamr4\">可观测的崭新进化：加速CI/CD管道的秘密武器</a>\"</p><p><a href=\"https://www.infoq.cn/article/V5NBFgrCIVMpXVazuGQE\">干货 | 携程 Web CI/CD 实践</a>\"</p>",
    "publish_time": "2023-07-04 09:59:44",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "厂商征集 | 中国人工智能成熟度模型报告 2023",
    "url": "https://www.infoq.cn/article/Rxyrty9TAXacP99lCtWF",
    "summary": "<p></p><h1>研究背景</h1><p></p><p>去年，AI绘画等生成式AI的内容激发了AI领域的广泛关注，年底发布的ChatGPT更是迅速破圈，话题度和讨论度不断提升。这些变化的趋势也延续到了2023年上半年，人们讨论话题也向着大模型的实际应用逐渐深入，同时AI安全也展现了大家对技术突破的不同态度。</p><p>今年年初，InfoQ研究中心发布了《中国软件技术发展洞察和趋势预测报告&nbsp;2023》，在报告中将各个领域的关键技术按照不同成熟度阶段进行了划分，总结成为中国技术成熟度评估曲线。报告发布之后也获得了众多企业和开发者的关注和讨论。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a4/a4d85ee1cd05f4b611bde1b873183ecc.png\" /></p><p></p><p>因此，InfoQ研究中心将基于人工智能领域的种种变化，更新人工智能领域的技术成熟度模型，为技术的应用决策和未来投资参考提供研究分析工具。</p><p></p><h1>研究内容</h1><p></p><p>基于技术发展时间、技术专利规模、技术应用市场规模、技术舆论热度等基础评价指标，构建中国人工智能技术成熟度模型。</p><p>报告包含“行业发展洞察”、“人工智能技术成熟度模型解读”、“人工智能技术企业生态图谱”等多个行业研究内容，以及在模型解读中还会有案例分析等厂商研究内容。</p><p></p><h1>征集范围</h1><p></p><p>企业主要业务类型包括：</p><p>提供人工智能产品与服务的各类厂商（RPA、计算机视觉、自然语言学习、数据挖掘、脑机接口、生成式AI等）；其他综合科技厂商。</p><p></p><h1>参与价值</h1><p></p><p>参与本次征集的厂商，将有机会获得：</p><p>InfoQ研究中心《中国人工智能成熟度模型报告&nbsp;2023》人工智能技术企业生态图谱、典型案例两大内容露出，提升厂商品牌知名度和行业影响力。报告通过InfoQ官网、公众号InfoQ等多个官方平台进行发布，同时会在多家生态链接的渠道传播。将有机会受邀参加InfoQ的线上线下活动，与行业内的甲方，行业专家，投资机构等进行深入的交流。</p><p></p><p>本次厂商征集自即日起，截至07月25日，欢迎识别下方二维码，添加小助手后，填写表单参与报告征集。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8a/8a0f5451e7cea9ef0c7f9c70c0da9421.png\" /></p><p></p>",
    "publish_time": "2023-07-04 10:06:58",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "厂商征集 | 中国云原生成熟度模型报告 2023",
    "url": "https://www.infoq.cn/article/Hlwwy6hW43iG9PUs1RO8",
    "summary": "<p></p><h1>研究背景</h1><p></p><p>随着云计算技术的不断发展和普及，越来越多的企业和组织开始采用云原生架构来构建和运行应用程序。云原生是近些年重要战略技术趋势，也是企业数字化转型的重要途径。</p><p>今年年初，InfoQ研究中心发布了《中国软件技术发展洞察和趋势预测报告&nbsp;2023》，在报告中将各个领域的关键技术按照不同成熟度阶段进行了划分，总结成为中国技术成熟度评估曲线。报告发布之后也获得了众多企业和开发者的关注和讨论。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a4/a4d85ee1cd05f4b611bde1b873183ecc.png\" /></p><p></p><p>因此，InfoQ研究中心将基于收集到的云原生领域的各种数据，更新云原生领域的技术成熟度模型，为技术的应用决策和未来投资参考提供研究分析工具。</p><p></p><h1>研究内容</h1><p></p><p>基于技术发展时间、技术专利规模、技术应用市场规模、技术舆论热度等基础评价指标，构建中国云原生技术成熟度模型。</p><p>报告包含“行业发展洞察”、“云原生技术成熟度模型解读”、“云原生技术企业生态图谱”等多个行业研究内容，并且在模型解读中还会有案例分析等厂商研究内容。</p><p></p><h1>征集范围</h1><p></p><p>企业主要业务类型包括：</p><p>提供云原生产品与服务的各类厂商（云原生数据库、容器服务、数据流与消息传递、Kubernetes&nbsp;集群托管、监控、安全与合规等）；其他综合科技厂商。</p><p></p><h1>参与价值</h1><p></p><p>参与本次征集的厂商，将有机会获得：</p><p>1、InfoQ研究中心《中国云原生成熟度模型报告&nbsp;2023》云原生技术企业生态图谱、典型案例两大内容露出，提升厂商品牌知名度和行业影响力。</p><p>2、报告将通过InfoQ官网、公众号InfoQ等多个官方平台进行发布，同时会在多家生态渠道传播。</p><p>3、将有机会受邀参加InfoQ的线上线下活动，与行业内的专家、投资机构等进行深入的交流。</p><p></p><p>本次厂商征集自即日起，截至07月20日，欢迎识别下方二维码，添加小助手后，填写表单参与报告征集。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8a/8a0f5451e7cea9ef0c7f9c70c0da9421.png\" /></p><p></p>",
    "publish_time": "2023-07-04 10:26:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "面向故障处理的可观测性体系建设",
    "url": "https://www.infoq.cn/article/g4LyEj3Ue2JCD2vLAfXc",
    "summary": "<p><a href=\"https://www.infoq.cn/article/kTtlLZxNUPmlvYpzA0eF\">笔者</a>\"从 12 年开始入行，从事 DevOps 研发工作，做过部署系统、监控系统、可观测性相关产品，也做过 SRE 一线和管理工作，对于可观测性的理解和实践，有一些小小的见解，利用本文和大家做一个探讨分享。本文主要内容包括：</p><p>可观测性在整个商业体系中的位置和价值如何快速发现故障，使用哪类指标告警SRE 在谈论故障定位的时候，谈的是什么如何找到故障直接原因，找到止损依据如何让可观测性系统呈现观点，辅助洞察，定位故障</p><p></p><h2>可观测性在整个商业体系中的位置和价值</h2><p></p><p>做一个事，首先得有价值，如果价值太小不值得投入。可观测性也不例外，我们首先分析一下可观测性在整个商业体系中的位置和价值。思考第一个问题：作为在线类产品，我们希望客户/用户有一个好的产品体验，那怎么算一个好的产品体验？</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/79/797ea306fce73a3782598262c260cf3c.png\" /></p><p></p><p>很明显，产品体验包括功能体验和可靠性体验。功能体验依赖产品设计和迭代速度，跟今天的话题关系不大暂且按下不表。可靠性体验呢？可靠性体验核心就是追求高可用、低延迟，通俗讲就是每次打开站点或app，都不报错，速度嗖嗖的。那如何才能具有好的可靠性体验呢？</p><p></p><p>其实如果一切正常，就应该是可用且速度快的，除非哪里出了问题，也就是发生了故障，才会报错或者延迟大增。那技术团队要做的，除了持续优化架构和性能，就是不断和故障做斗争了。降低故障发生的频率，降低故障的影响范围，降低故障的恢复时间。归纳为 6 个字：降发生、降影响！</p><p></p><p>怎么做？有没有方法论来指导？我们可以从故障的生命周期着手，来优化生命周期的各个环节，每个环节都做好了，理论上结果就是好的。故障生命周期的梗概图如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/73/73c9e6f892d22efd34b3b90df3f6fadc.png\" /></p><p></p><p>从大面上，可以分成事前、事中、事后三个大的阶段：</p><p>事前：及时发现风险，做好架构、预案、演练事中：及时发现故障，及时定位，及时止损事后：排查根因，落实复盘改进项</p><p></p><p>看起来寥寥数语，没有特殊的东西，但实际上每个环节要做好，都不容易。那可观测性，在这整个过程的职能是什么？在哪个环节发挥价值？</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/72/72ab3a951c58cb598c5d098ae537850f.png\" /></p><p></p><p>显然，可观测性，是在故障发现、定位环节发挥作用的，核心价值就是帮我们快速发现故障、快速定位故障，进而降低故障的影响。如此，可观测性的位置和价值就很明确了，用一张图概括：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f6/f61bada46081700d99d9dab70e438889.png\" /></p><p></p><p>客户/用户需要好的产品体验，好的产品体验包括可靠性体验，要想有好的可靠性体验，就得减少故障，所谓的降发生、降影响，而这，又依赖了可观测性的能力。所以：可观测性最终是服务于产品体验、服务于商业成功的（想不想取得商业成功？根据刚才的分析可观测性可是重点因素哦），核心目标是快速发现、定位故障。</p><p></p><p>那么，如何快速发现故障？</p><p></p><h2>如何快速发现故障，使用哪类指标告警</h2><p></p><p>要想能够快速发现故障，得先定义什么是故障！简单来看，产品体验受损，就是故障！比如：</p><p>电商产品：用户无法下单、无法支付、无法查看商品、无法查看历史订单存储系统：用户无法读、无法写、或者读写延迟过高流媒体产品：无法开启播放、无法拉流、无法浏览视频信息</p><p></p><p>既然能够定义如何算是产品体验受损，那就可以梳理出相关的监控指标，比如：</p><p>电商产品：订单量、支付量、商品/订单访问成功率/延迟存储系统：读/写成功率、读/写延迟流媒体产品：播放量和成功率、拉流延迟、视频浏览成功率/延迟等</p><p></p><p>大家有没有发现这类指标的特点？显然，都是可以量化客户体验的指标，这类指标我们称为结果类指标（后面会介绍原因类指标），大面上可以分为两类，一类是业务指标，另一类是 SLO 指标。</p><p></p><p>一般公司做监控的时候，可能会意识到要做 SLO 指标的监控，容易忽略业务类指标的监控。其实，业务类指标才是老板更为关注的指标，而且，SLO 指标正常的时候，业务指标未必正常。比如客户到服务端的网络出问题了，服务端的成功率、延迟指标都是正常的，但是客户无法下单，订单量会下跌。所以，一定要重视业务指标体系的构建和监控。</p><p></p><p>听起来，业务指标和 BI 数据很像有没有？确实，最大的相同点是：都是老板关注的，哈哈。不同点呢？BI 数据对准确性要求很高，对实时性要求没有那么高，而业务指标监控，对准确性要求没有那么高（只要能发现数据趋势出问题了就可以了），对实时性要求很高，毕竟是用来发现故障的，如果实时性太差，黄花菜都凉了。</p><p></p><p>指标体系的构建，除了结果类指标，与之对应的还有原因类指标。都需要，但是我们配置告警的时候，一般是针对结果类指标来配置。因为产品的核心业务功能是可枚举的，每个功能对应的结果类指标就是可枚举的，做好结果类指标的告警，就可以保证告警是全的，做到有故障必有告警！举个例子：实时交易类系统，交易量突然下跌。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8c/8c15623e52d18db86e9487b0ad3b39de.png\" /></p><p></p><p>如果，面向原因类指标配置告警，则永远无法配全，无法做到有故障必有告警！实际上，原因类指标不必一定要配置告警，出故障的时候可观测，其实也基本够了。</p><p></p><p>如上，要构建可观测性体系，首先要建立完备的指标体系，其中非常关键的是结果类指标，即业务指标和 SLO 指标，结果类指标配合告警系统可以快速发现故障！从这里也可以看出，监控（monitoring）和可观测性（observability）是相辅相成的，非替代关系。</p><p></p><p>OK，既然可以发现故障了，下一步就是定位故障了。</p><p></p><h2>SRE 在谈论故障定位的时候，谈的是什么</h2><p></p><p>在讨论这个问题之前。先分享一个信息层级的概念。说：信息分4个层级，最底下是数据，杂乱无章，比如海量的指标、日志、链路追踪的数据；数据上面是特征，比如最大值、最小值、同环比等，比如5个服务实例，延迟的最大的是哪个，这叫数据特征；特征上面是观点，从故障定位场景来举例，比如根据特征数据分析之后发现，数据库没有问题，依赖的第三方服务也没问题，这就是观点；观点之上就是洞察，或称洞见，综合所有观点，得出故障定位结论，得知具体是哪个模块的什么原因导致了本次故障，就是最终洞察。画个图示例一下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ab/ab4212cba5a30046ad10f5412eeca63b.png\" /></p><p></p><p>要想得到最终的洞察（定位到故障），首先要依赖底层的数据完备性，否则就是巧妇难为无米之炊！但是故障原因五花八门，数据能全么？做过 SRE 或者运维的朋友肯定感触颇深，故障可能是电源模块坏了、机房空调坏了、机柜压住网线了、供电不稳、某个盘故障了、中间件配置错了、被黑客攻击了、分布式中间件脑裂了、写日志hang住了、程序配置错了、程序连接第三方的地址错配成线下地址了、DNS配错了、证书过期了、代码Bug了、疏漏了某个罕见用户流程…等等等等。</p><p></p><p>这么多可能的故障原因，要通过可观测性数据分析出来，这数据能全么？比如代码 Bug，要想能根据可观测性数据分析出是哪一行代码的问题，岂不是要像在 IDE 里调试那样，每一行代码的输入输出都得拿到啊，这成本谁扛得住啊，性能损耗谁扛得住啊…</p><p></p><p>如果我们的目标只是定位直接原因，找到止损依据尽快止损，这个底层数据需求就少多了。比如我们不需要知道是哪行代码出了问题，我们只要知道是某个模块做了变更导致了故障，就可以去止损（这个场景的止损动作就是回滚）了。再比如，多活的服务，有时仅仅知道是 A 机房的问题就可以了，把流量切到 B 机房就可以解决。</p><p></p><p>综上，个人观点：使用可观测性数据定位根因，几无可能100%覆盖全部场景！因为数据就不可能全！但如果只是用可观测性数据定位直接原因，找到止损依据，则100%是可以做到的，而这，才是我们应该努力的方向。</p><p></p><p>当 SRE 在谈论故障定位的时候，其实谈论的时是如何找到直接原因，尽快止损。而根因，可以留在复盘阶段慢慢找的。</p><p></p><h2>如何找到故障的直接原因</h2><p></p><p>回答这个问题之前，我们先来看看一个服务要想正常运行，依赖了哪些内容，或者说一个服务如果出故障，可能会是哪里的问题。如果我们能够枚举故障类别，那么我们就可以针对每个类别去分析，找到故障的直接原因。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/65/65f9508d26469553daa68aeec70808f8.png\" /></p><p></p><p>首先，依赖的基础设施（基础网络、硬件、Runtime环境）不能出问题，依赖的第三方其他服务不能出问题，这两个方面大家比较容易理解，不多说了。还有就是服务本身的变更，比如二进制变更、配置的变更、部署方式的变更、流量接入方式的变更，等等，也可能引发问题。最后就是上游访问的方式，比如流量突增，显然也可能会带来故障。</p><p></p><p>那针对这些故障场景，我们应该去看哪些数据呢？这其实就是可观测性数据底座的建设方向。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e8/e8eaf8e2083e1b39adc7cb8eea62cb34.png\" /></p><p></p><p>咦？说来说去，还是要建立 metrics、logs、traces、events？是的，但不仅是，只有数据还远远不够，我们需要通过平台工具，通过数据运营整理，帮助用户找到数据特征，建立初步观点，最终形成洞察定位故障直接原因。还记得那张信息层级的图吧：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/04/04b672f449297f8e87f0314e7722547f.png\" /></p><p></p><p>网上有人批评可观测性三支柱的说法，核心要点是：不能只关注 raw data，就像一道菜，只有原料还不能称之为一道菜，没有炊具、菜谱、厨师，无法最终产出那道菜（客人要的是那道菜，那道菜才是结果，应该没有哪个餐厅说，你看我原料都有，完活了，让客人吃吧，应该没有这样的餐厅…）。</p><p></p><p>Martin Mao 曾经也写过一篇文章《Beyond the 3 Pillars of Observability》来论述这个事情。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1e/1e49091cfa86e586ab6323f998457137.png\" /></p><p></p><p>他的核心观点是：只关注三支柱raw data，认为有了三支柱数据就建立了可观测性，是不对的，我们更应该面向结果来思考如何构建整个体系，Martin Mao 认为，所谓的结果，就是 Remediate，就是止损！英雄所见略同。</p><p></p><h2>可观测性体系具体要如何做才能辅助技术团队止损</h2><p></p><p>还是参考刚才信息层级的图，有了 raw data 数据底座之后，可观测性体系还需要利用平台能力、通过数据运营整理，呈现数据特征、帮用户建立初步观点，最终形成洞察，定位故障直接原因。</p><p></p><h3>可观测性体系要告诉我故障模块</h3><p></p><p>这应该是可观测性体系提供给客户/用户的第一个观点，故障发生了，现在都是微服务的，你得一目了然的告诉我具体是哪个模块故障了不是。总不能让我写一条有一条的 promql，看一个又一个监控大盘，才能找到故障模块吧。故障处理可是要争分夺秒的，一个一个查看太浪费时间了。</p><p></p><p>既然要一目了然，初始页面上的内容不能太多，从技术角度来看，一般模块都是有层级关系的，首先是系统，然后是子系统，然后是模块。所以，初始页面应该展示系统的健康状况，如果某个系统有问题，应该可以点击进去查看详情（这个过程称为下钻），下钻到子系统，再下钻到模块，最终找到故障模块。</p><p></p><p>那如何衡量一个模块是否健康呢？这其实就可以使用 SLO/SLI 这套体系，每个模块都有几个 SLI，每个 SLI 异常，这个模块就可以定义为异常，进而定义子系统异常、系统异常，这个过程也有种故障冒泡上浮的感觉。</p><p></p><p>我以我们的产品来举例这种效果图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/73/734f0c69aa555d015852229751dbcd86.png\" /></p><p></p><p>这样的系统我们称为灭火图，最上层是一个个的系统卡片，如果有问题就会有个飘红的小火苗，点击详情进入，可以看到相关子系统，点击故障子系统，可以看到模块以及核心接口的列表，进而可以定位到故障模块或核心接口。产品通过颜色做引导，而且具备层级关系，即可做到一目了然。</p><p></p><h3>可观测性体系要告诉我故障模块的各项依赖是否健康</h3><p></p><p>模块依赖的数据库、中间件、基础网络、机器硬件、第三方服务等等，都会影响模块的健康状况。所以，当模块异常的时候，我们需要知道各项依赖是否健康，如果依赖也异常，那么模块异常的直接原因基本可以断定是异常的依赖项导致的。</p><p></p><p>要用可观测性产品建立这样的视图，核心有两点，一个是依赖的关联关系，一个是依赖项的 SLO 视图（通常体现为 metrics 仪表盘）。下图是一个逻辑示意图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/44/4421982147704e140791a3118590e58a.png\" /></p><p></p><p></p><h3>可观测性体系要告诉我是否是变更导致的</h3><p></p><p>线上故障，大概 70% 都是变更导致的，所以运维行业中流传一句话叫：“变更是万恶之源”。所以，当故障发生的时候，我们需要知道是否是变更导致的，如果是变更导致的，就要尽快止损。</p><p></p><p>如果迭代比较快，每周的变更数量会很多，那么如何快速定位到是哪个变更导致的故障呢？这需要可观测性产品提供一些数据特征给用户，用户才能方便分析。典型的是在时间维度上做文章。把故障和变更放到一张图上，在时间维度上做对比，比如从故障时刻往前看 1 小时，看看有没有变更，如果有，那个变更很可能就是罪魁祸首。示意图如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/02/0286cb42253bcdbfa54b5d9755ffc3e6.png\" /></p><p></p><p>注意，这里的变更不仅仅是代码变更，还包括配置变更、机器变更、网络变更等等，变更事件收集得越全，越有价值。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/21/21c586c7231033ac28f4e0507e5a6211.png\" /></p><p></p><p>上面，我举例了三个可观测性产品需要为用户输出的观点：</p><p>可观测性体系要告诉我故障模块可观测性体系要告诉我故障模块的各项依赖是否健康可观测性体系要告诉我是否是变更导致的</p><p></p><p>当然，还有其他观点可以输出，比如是否是容量不足导致的故障，大家可以自行思考看看还可以让可观测体系输出哪些观点。但是，罗马不是一天建成的，在某个阶段，可观测性体系输出的观点有限，不足以帮我们定位故障，此时，可观测性体系还可以做什么呢？</p><p></p><p>至少，还需要提供工具帮我们分析数据特征，别让用户陷入海量散乱的可观测性 raw data 中。这需要多维分析引导能力、数据串联打通能力。举一个数据串联的例子：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/45/453c988a566d2f0a1283a435ec48fbec.png\" /></p><p></p><p></p><h2>总结</h2><p></p><p>可观测性体系不能仅仅只有散乱的数据，而应让数据呈现特征，让特征呈现观点，让特征和观点辅助洞察：洞悉故障直接原因，完成止损！这才是建设可观测性体系的核心目标。</p><p></p><p>作者简介：</p><p>秦晓辉，Open-Falcon、Nightingale 创始研发，极客时间《运维监控系统实战笔记》作者，公众号 SRETalk 主理人，快猫星云创业合伙人，创业方向是稳定性保障方向。如果你有兴趣来《<a href=\"https://mp.weixin.qq.com/s/Y4rIfV4_7MuYigLNNrtifg\">运维百家讲坛</a>\"》输出一些自己的宝贵经验和见解，欢迎联系我，联系方式如下：18612185520（微信同号）。</p>",
    "publish_time": "2023-07-04 11:40:39",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "之江实验室： 如何基于 JuiceFS 为超异构算力集群构建存储层 ？",
    "url": "https://www.infoq.cn/article/83tfpS8cgjfuZTU27QgK",
    "summary": "<p></p><blockquote>今天，高性能计算结合人工智能技术正在推动科研创新。例如通过破解水稻基因密码推动作物育种从“试验选优”向“计算选优”发展，在医药领域快速分析分子与蛋白之间的相互作用，发现潜在的能够有效干预疾病发生的药物分子。&nbsp;</blockquote><p></p><p></p><p>之江实验室就是上述科研创新的推动者，实验室由浙江省政府主导、浙江大学等院校支持、企业参与的事业单位性质的新型研发机构，为材料、基因、制药、天文、育种等科学领域的研究提供新的方法、工具和手段。&nbsp;</p><p></p><p>由于算力资源的天然异构性，以及不同技术实现的计算能力往往出自不同的系统架构或指令集，会导致软件不兼容性，从而提高了算力使用的门槛，也使得算力利用率难以有效提高。为解决这个问题，之江实验室将各种异构算力资源汇聚在一起，形成一个庞大的“算力池”。本文将分享之江实验室如何基于 JuiceFS 为超异构算力集群构建存储层的实践。</p><p></p><h2>01-之江实验室的输出反应堆</h2><p></p><p>数字反应堆是之江实验室一个大型科研装置。整个科研装置由软硬件部分组成。在软件方面，负责研发之江瑶光智能操作系统。</p><p><img src=\"https://static001.geekbang.org/infoq/d0/d053313d04e6e76453f1f40ccb6de9b3.png\" /></p><p>该智能操作系统主要包含两个关键组成部分。首先，它提供了通用的计算平台解决方案，为上层应用层提供支持。通过这个平台，用户可以针对不同的应用领域，如计算材料、计算制药、计算天文等，进行开发和应用。</p><p></p><p>其次，我们实现了一个异构资源聚合方案。在之江实验室，我们拥有多个异构集群，包括CPU集群、GPU集群以及一些超算资源。这些不同类型的计算资源具有不同的使用方式。通过异构资源聚合方案，我们将这些不同的计算资源统一聚合，实现统一的管理和使用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/57/57e367290b5c79bdbb57c8cd27da20c3.png\" /></p><p>整体架构如上，在之江实验室的计算与数据中心，我们部署了多套异构集群，包括 H3C 的傲飞集群、之江的计算集群、国产的曙光集群等，以及边缘计算场景，这些都纳入了我们的管控系统中。通过集群设备插件的方式，我们对这些不同的集群进行了统一抽象，并实现了算力的聚合。在整个异构算力联邦的体系中，我们将这些不同的算力集群都抽象为 Kubernetes（k8s）集群进行管理。</p><p></p><p>上层下发的业务指令及不同类型的作业，通过元调度器来决定将这些作业发送到哪个集群。根据不同的调度策略，如计算优先级、能耗优先级和性能优先级，来确定计算作业的具体执行方式。目前，我们已接入约 200P（PFLOPS, 1P 相当于每秒执行一千万亿次浮点运算） 的 AI 算力和 7000 核的 HPC 算力。</p><p></p><h3>算力侧对存储的需求</h3><p></p><p>首先：存储层的抽象和统一。因为在许多计算场景中，包括超算和AI训练，都使用 POSIX 接口。因此，我们希望在这一层面上统一使用 JuiceFS 的接口来提供服务。</p><p></p><p>第二个方面：存储方案的通用性。目前接入的算力集群是异构的，那么尽量需要考虑方案在不同的异构集群中都能适用。</p><p></p><p>第三个方面：数据的编排条件。我们的数据是有典型的冷热特性，在一个任务在计算过程中，它用到的数据是热数据，任务计算之后或者过了几天之后，这个数据就变成了冷数据，我们对冷数据的读和操作是比较少的。</p><p></p><p>第四个方面：存储性能的要求。数据读写性能要好。特别是热数据的读取性能。在算力集群中，计算资源非常宝贵，如果因为数据读取慢导致CPU，GPU空转等待，是极大的浪费。</p><p></p><h3>存储方案选型</h3><p></p><p>方案1：裸露的对象存储（OSS）与S3FS + NAS 相结合</p><p></p><p>这个方案存在一个较大的问题，即直接使用裸露的对象存储性能非常差。另外，裸露使用对象存储的 S3FS 挂载点经常会出现莫名其妙的丢失。一旦挂载点丢失，容器将无法访问，如果要恢复挂载点，必须对整个容器进行重启，这对用户业务造成了很大的干扰。</p><p></p><p>由于开始时集群规模较小，而且这套方案部署简单，实验室一开始采用了这种方案进行部署。但随着集群规模的逐渐扩大，尤其是从去年开始建设的数字反应堆，从单一集群到多集群的演进过程中，当节点数量从最初的 10 多台逐渐扩展到 100 多个节点时，这个方案基本上已经行不通了。</p><p></p><p>方案2：Alluxio + Fluid + OSS</p><p></p><p>经过调研，我们发现该方案的结构相对复杂，涉及到许多组件的组成。之江实验室是一个超异构的多集群环境，由于 Alluxio 并不是一个强一致性的文件系统，它实际上只是一个缓存的粘合层。在这种多集群环境下，会面临元数据不一致的问题，而解决这个问题特别困难。由于上层用户的业务产品非常繁多，我们不能干涉用户的使用方式。在这种情况下，如果不同集群之间的数据不一致，将会导致严重的问题。其次底层仍然使用OSS，当数据规模扩大到一定程度时，由于 OSS 的元数据性能问题，当存储规模达到一定级别后， 元数据同步、新集群的缓存层初始化等操作也会遇到较大的性能瓶颈。</p><p></p><p>方案3 ：JuiceFS（最终采用）</p><p></p><p>JuiceFS 有非常详细的社区文档，可以直接上手使用，并且在我们的搭建测试集群以及最终的上线部署中表现出色。另外，JuiceFS 支持 CSI可以容器化部署，另外对国产硬件的适配性较好。因此我们最终选择将 JuiceFS 作为我们算力侧的存储底座。</p><p></p><h3>使用 JuiceFS 的优势</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/2f/2f56f28f2d866ea9921f0c440327c20b.png\" /></p><p>首先，JuiceFS 提供了丰富的元数据引擎选择，比如 Redis 和 TiKV，使得 JuiceFS 具有较好的元数据性能。目前我们实验室使用的是由三个节点搭建的 TiKV 作为元数据引擎。由于该配置是去年建立的，现在的性能已经有些不够用，后续我们将逐步提升性能。</p><p></p><p>最初我们考虑使用 Redis 作为元数据引擎，但后来发现如果使用 Redis，就无法实现水平扩容。从而使用了 TiKV，则可以随着文件系统数量的增长逐步扩展，这确实更好。</p><p></p><p>第二，在跨集群环境下，使用 JuiceFS 可以实现文件的原子性和一致性。在集群 A 中写入的文件在集群 B 中立即可见。然而，如果使用 Alluxio，就无法做到这一点。Alluxio 需要进行一些数据同步事件等操作才能实现，而这些事件实际上会带来一定的开销。</p><p></p><p>第三， JuiceFS 具备缓存能力。客户端可以配置一个缓存目录，使用缓存后可以大大降低算力集群对底层存储的压力。</p><p></p><p>第四，JuiceFS 对于 POSIX 的兼容性非常好。我们发现 Alluxio 的实际兼容性并不那么好，而且其客户端性能相对较一般。Alluxio 可能更适用于不同异构数据源的统一接入层，用于读取数据较好。但是，如果需要频繁写入或修改数据，则可能使用起来并不理想。</p><p></p><p>第五 JuiceFS 的社区是常活跃。</p><p><img src=\"https://static001.geekbang.org/infoq/52/52e68a70d44d1821247c428d73930845.png\" /></p><p>这个是我们自己在实验室环境下测出来的，测试工具：FIO 16 线程、4M Block 、1GB 数据 上图 NAS 的性能就没法看，因为当时测评的时候还在生产环境正在提供服务，当时有大概七十几个节点正在运行，带宽很小，基本就运行不了。</p><p></p><h2>02-存算分离架构演进</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/ce/ceb60d24d04c55aada05f0746fe6894e.png\" /></p><p>初期，整个高性能计算的过程实际上是分为很多个环节，但是数据分散在不同的存储系统中会带来使用效率和便利性上的挑战。为了简化数据的管理和流转，我们使用了一个统一的存储底座作为存储基础设施。存储底座的核心能力包括高可靠性、低成本和高吞吐量，因此我们选择了对象存储作为存储底座。将数据存储到对象存储中可以轻松实现数据的冷热分层，从而节省存储空间。</p><p></p><p>然而，直接让计算集群直接使用裸对象存储仍然存在一些问题。首先是元数据性能差的问题，例如对同一目录下文件的列表操作，在文件数量较多的情况下，耗时会非常长。第二个问题是带宽消耗大，数据湖提供的是普通的IP网络，而不是 RDMA 高速网络，因此总带宽有限。</p><p><img src=\"https://static001.geekbang.org/infoq/af/afc7be237781c15bc7555e3fd2e43d07.png\" /></p><p>因此，在对象存储之外，我们还建立了一个元数据集群，并使用了 TiKV 数据库。基于对象存储和 TiKV，我们构建了JuiceFS 分布式文件系统。算力集群通过在节点上安装 JuiceFS 客户端来读取文件系统的数据。这样，我们可以克服对象存储的一些限制，提高元数据性能，并减少带宽消耗。</p><p></p><p>为了实现高效的数据流转，我们通过文件管理系统允许用户进行文件的上传和下载操作。文件管理系统底层采用JuiceFS S3 网关，将数据写入底层存储。</p><p></p><p>除了数据湖和元数据集群，我们还建立了一个高速缓存集群，它紧密部署在计算集群中，主要目的是为了实现最佳的 I/O 性能。这样解决了计算集群与对象存储数据湖底座之间高效数据流转的问题。用户并不需要关心数据是存储在对象存储中还是在高速缓存集群中。</p><p></p><p>算力系统对数据流转进行管控。计算集群和高速缓存集群之间通过200G的RDMA高速网络连接。高速缓存集群上部署了BeeGFS高速并行文件系统，将该文件系统作为一个目录挂载到计算集群。这样，计算集群可以像使用本地目录一样使用该缓存系统。</p><p></p><h2>03- 存储能力产品化建设</h2><p></p><p>在不同的业务场景中，对存储的需求和性能指标是不一样的。为了能够更高效地服务用户，我们提出了打造存储能力产品化这样的想法，目前JuieFS 被应用到了以下几类存储产品中。</p><p></p><h3>通用文件存储</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/4f/4fbcd5b12b0f9eee4a2115954ea76c7a.png\" /></p><p>JuiceFS 会将其数据保存在一个特定的目录下，并根据用户所属的组织架构生成一个唯一的访问路径。通过直接将该路径挂载到容器内，实现数据的隔离。用户可以通过页面端进行文件的上传和下载，也可以使用我们提供的命令和工具对文件进行操作。</p><p></p><h3>存储卷</h3><p></p><p>在初始建设阶段，通用文件存储存在一个问题，容量的扩展性较差。底层的对象存储集群（oss）的容量有限，随着数据量的增加，用户无法申请更多的存储空间。为解决这个问题，我们引入了存储卷的概念。</p><p><img src=\"https://static001.geekbang.org/infoq/a0/a0f22e78e2e1bfa0f577a6919c1c8950.png\" /></p><p>存储卷可以类比为云盘，不同的存储卷相当于不同类型的云盘。对于不同的存储类型，我们可以将它们包装成不同的存储卷，以满足用户在不同场景下的需求。</p><p></p><p>对于需要频繁地读写海量小文件的场景，它需要使用延迟较低且吞吐量较高的存储产品。为满足这种需求，我们将之前搭建的高速缓存集群转化为高速存储卷的功能，直接将其文件系统目录开放给用户使用。这样，用户可以直接使用高速存储，而无需通过 JuiceFS 来访问，可以更直接地感受到高速存储的性能优势。</p><p></p><p>而对于需要保存大数据但实际上不频繁读取的用户，可以结合JuiceFS和对象存储来创建标准存储卷。这样可以提供较大的存储容量和可接受的吞吐性能，同时相对于高速存储卷，支持跨集群的网络互通能力。</p><p>此外，一些用户可能对性能有更高的要求，例如他们需要本地盘的产品，但同时也需要数据持久化的能力。在 Kubernetes 场景下，如果用户直接将数据写入本地盘，存在数据丢失的风险，例如遇到意外重启或物理节点问题。在这种情况下，用户需要一种持久化的解决方案。我们可以通过将用户在受影响节点的本地盘开放一部分存储空间作为本地存储卷，并在作业调度时根据用户指定的存储卷将任务调度到指定的节点上。</p><p></p><p>另外，不同存储产品在容量、吞吐量和跨集群互通能力方面存在差异。例如，高速存储可以在集群内部进行互通，但无法跨集群；存储产品的容量和成本也各不相同。高速存储采用全闪存的集群，建设成本较高，而对象存储的建设成本相对较低，且具备较大的存储容量。因此，将不同的存储硬件（设施）能力包装成不同的存储产品来适配用户不同的业务场景。</p><p></p><h3>数据编排</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/ed/ed750852102e298c674c4b474a42a323.png\" /></p><p>在使用 JuiceFS 时，我们还实现了一个数据编排功能。管理员可以将常用的数据集上传到文件系统某个目录，这个目录可以在上层抽象成一个公开的数据集。不同用户在创建作业时都可以挂载这些数据集。普通用户也可以上传自己的私有数据集，并通过 JuiceFS 的预热功能对这些数据集进行预热。</p><p></p><p>我们在算力集群内部建立了一个高速缓存集群。使用 warmup 指令，用户的数据集可以直接从两端预热到计算节点的高速缓存集群。这样，用户在进行大量模型训练时，可以直接与自己搭建的高性能集群交互，无需与远程 OSS 集群进行交互，从而获得更好的性能。</p><p></p><p>另外，这种设置可以降低对象存储底座的网络带宽压力。整个缓存的淘汰过程由 JuiceFS 客户端自动管理，因为可以对访问目录进行上限容量的配置。对用户来说，这部分功能相对透明且易于使用。</p><p></p><h2>04-JuiceFS使用过程当中也遇到了一些问题</h2><p></p><p></p><h3>文件读取性能</h3><p></p><p>在我们选择使用JuiceFS之后，我们在内部进行了一些文件读取性能的测试，并与算法团队合作进行了测试。当时，从测试结果看，JuiceFS 的读取性能总是比 NAS 慢得多。我们开始查找原因为什么 JuiceFS 比 NAS 还要慢。</p><p><img src=\"https://static001.geekbang.org/infoq/7b/7b47102b88536be0cbf622fe988e46ce.png\" /></p><p>后来我们发现，在使用 JuiceFS 和 TiKV 作为元数据的场景中，像列举目录这样的 API 操作实际上是随机的，它并不像 NAS 或其他文件系统那样保证一致的顺序。在这种情况下，如果算法是基于随机选择文件或者代码是固定的，那么可能会认为选择的那些文件应该是固定的。</p><p></p><p>在处理海量小文件的场景中，元数据的开销是相当可观的。如果元数据没有被缓存到内存中，每次都需要从元数据引擎那里获取，与没有缓存相比这会带来较大的开销。因此，通过这个问题，我们发现在特定的场景下需要对文件的索引目录进行编排。例如，某个算法可能需要处理数十万甚至数百万个文件，如果要确保算法训练的一致性，首先需要将这些文件作为索引文件，作为自己的一个索引目录树。每次进行算法训练时，直接读取索引文件，而不再调用 list dir 的操作，以确保这个文件夹下的文件目录树在算法训练中保持一致性。</p><p></p><p>编著注：造成读性能慢主要与用户的使用场景相关，评估后对“目录的随机读”这个功能未作调整，如果其他用户在这个问题上也有类似问题，欢迎提出。</p><p></p><h3>TiKV 无法垃圾回收</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/af/af9f5f17d471180741b51cdf60eb0e07.png\" /></p><p>在使用过程中，我们遇到了 TiKV 无法进行垃圾回收的问题。由于我们只使用了这个文件系统，并且显示容量为 106T、1.4 亿个文件，而 TiKV 占用了 2.4T 的容量，这显然是不正常的。</p><p></p><p>根据官方文档的显示，例如 Redis，大约 1 亿个文件应该只占用大约 30GB 的容量。我们进行了排查后发现可能是 TiKV 的元数据引擎没有进行垃圾回收。我们还查看了报表，发现整个垃圾回收指标为空。可能的原因是我们只部署了 TiKV，而没有部署 TiDB。然而，TiKV 的垃圾回收实际上需要依赖 TiDB，这是一个容易被忽视的问题点。</p><p>编著注：JuiceFS 在 #3262 和 #3432 的 PR 中加上了 TiKV 的后台 GC 任务，修复了这个问题。这些修复已经在 v1.0.4 中合入。</p><p></p><h3>JuiceFS client 内存占用较高</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/af/af4c48bdeb39da32ffea72f8c40d73de.png\" /></p><p>当我们挂载 JuiceFS 客户端时，我们将高速缓存集群设置为保存目录，并将其容量设置得相对较高，理论上限为 50T。</p><p></p><p>在这种情况下，JuiceFS 客户端会定期扫描缓存目录，并建立内存索引，以便 JuiceFS 知道哪些数据位于缓存目录中。因此，这会占用相当多的内存。如果目录非常庞大，我们建议用户关闭这个扫描功能。</p><p>在测试小文件随机 I/O 时，我们觉得表现还可以，但在测试顺序 I/O 时，出现了一个较大的问题。例如，使用 dd 命令创建一个 500MB 的文件，结果发现对象存储生成了大量快照。可以看出，这里的存储和对对象存储的操作远远超过了创建一个 500MB 文件应有的操作。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e5/e5ebf2b6c93d18741d6c3c18c77427d4.png\" /></p><p>在进一步排查时，我们发现在启用&nbsp;-o writeback_cache&nbsp;参数后，顺序写会变成随机写，从而降低整体的顺序写性能。该参数只适用于非常高级的随机性场景。如果在不是这种场景下使用该参数，将导致严重的问题。这也是在使用 JuiceFS 时需要注意的一个点。</p><p></p><p>编著注：这个问题主要是针对使用 NAS 做缓存的场景，已经在1.1beta中优化，扫描时大幅减少内存占用，并提升速度。JuiceFS 在 #2692 中添加了 --cache-scan-interval 来自定义扫描时间，并且可以选择只在启动时扫描一次或完全关闭扫描，用户可以配置该选项。对于使用本地盘做缓存的用户则不需要调整。</p><p></p><p></p><h2>05-后续规划：更丰富多样的存储产品</h2><p></p><p>多层次</p><p>我们将提供更多层次的软硬件产品，并将这些能力以不同的存储卷形式进行产品化，以适应用户在不同场景下的存储需求。</p><p></p><p>隔离性</p><p>目前存在数据安全风险，所有用户的数据都存储在同一个大型文件系统中并通过hostpath挂载在裸机。如某些用户拥有节点登录权限，实际上可以访问整个文件系统内部的数据。为了解决这个问题，我们计划在后续采用 CSI 模式结合路径定制来避免隔离性问题。我们还将上线配额管理功能。在用户使用存储产品时，需要有一种强制手段来限制用户可以使用的存储容量，并且能够准确查看用户实际使用了多少容量。直接使用 du 命令查看容量的过程开销很大，并且不太方便。配额管理功能将解决这个问题。在计量计费场景下，我们需要了解用户产生的流量和消耗的能量，并根据实际使用的容量进行计费。因此，良好的容量管理能力是必需的。</p><p>监控&amp;运维</p><p>在使用 JuiceFS 时，我们是直接在物理机上挂载，通过暴露一个监控端口，我们的生产集群可以与这些端口进行通信，并建立了一套监控系统，可以监控和收集所有的监控数据。数据的容灾和迁移能力目前还比较欠缺。我们遇到了一个典型场景，即现有集群的容量不足，需要上线新的集群。在新旧集群之间，如何处理数据迁移以及不同数据的迁移方式，如何在不影响生产用户的情况下尽量保证业务不中断，实现数据迁移仍然是一个较为困难的问题。因此，我们计划在后续寻找解决方案，以提升这方面的能力另外，我们还在开发基于 JuiceFS 和 CSI 插件的通用能力，以实现在不同的存储客户端上动态挂载的能力。在生产环境中，用户对挂载参数的调整有一定需求，因为不同的挂载参数适配不同的业务产品。然而，如果直接调整挂载参数，可能会导致整个物理节点的中断。因此，如果能够实现动态挂载的能力，用户只需要对业务进行适当的切换，而无需进行重启等操作。</p><p></p><p>对 JuiceFS 一些功能期望：</p><p>卷管理能力&nbsp;（配额、用户、权限）卷能力在之前已经部分实现了配额的功能，但实际上我们更需要的是基于用户和管理人员权限的管理能力。目前，JuiceFS是挂载在一个大型文件系统上，如果为每个用户创建文件系统，将会带来很高的开销。因此，我们目前采用的是基于一个大型文件系统，通过不同的目录来管理不同用户的权限配合，缺少一个统一的、中心化的用户权限管理系统，仍然需要依赖Linux的权限管理。然而，Linux的权限管理是分布在不同节点上的，对用户权限的管理相对较为困难。我在思考是否可以依赖元数据，并将其作为一个中心化数据库的能力，实现用户和权限的管理。这样，卷的管理能力就可以更加产品化。支持分布式缓存能力。它可以充分利用计算机的物理资源和本地磁盘，通过集群内的计算节点和网络进行利用。目前我们了解到，商业版有提供这个功能，但社区版也还没有。挂载点热更新能力。在不同的场景下，用户需要不同的挂载参数，但是卸载和重新挂载的操作太重，会影响用户的业务。用户可以接受短暂的不可读取或者读取中断，但是不能重启业务容器或中断算法或策划程序。我们正在内部调研和开发这个能力。</p><p></p><p>编著注：目录配额需求在1.1Beta中已经实现了，详情请大家关注下周的发版信息。分布式缓存和挂载点更新能力，目前商业版可以提供，这两个功能也在社区版的规划当中。</p><p></p><p>直播回顾：https://www.bilibili.com/video/BV1Fo4y1V7Ka/</p><p></p><p>作者简介：</p><p>洪晨</p><p>之江实验室高级工程专员，负责计算侧存储的架构和演进</p>",
    "publish_time": "2023-07-04 12:15:32",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "承接百亿保单的新基建，无界山到底是什么山｜InfoQ 《一探到底》",
    "url": "https://www.infoq.cn/article/ZhIJE05sJgdxkPdYci37",
    "summary": "<p>新基建的推动使得数字化转型成为各行各业的必然趋势，众安保险也从其中看到机遇，把握机遇并通过加强创新，探索出共建共赢的新模式。《一探到底》众安之行的第三期，带大家探访保险行业的一座“神山”——无界山的前世今生，并畅谈如何在新基建时代通过技术创新实现合作共赢。</p>",
    "publish_time": "2023-07-04 12:29:59",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]