[
  {
    "title": "Oracle正式发布MySQL Heatwave on AWS",
    "url": "https://www.infoq.cn/article/2a4wyAUCqEjD2ilr0s41",
    "summary": "<p>近日，Oracle正式发布了<a href=\"https://www.oracle.com/mysql/\">MySQL Heatwave</a>\"。该服务将OLTP、分析、机器学习和基于机器学习的自动化融合到了单个AWS实例中。</p><p>&nbsp;</p><p>2020年，Oracle在<a href=\"https://www.oracle.com/cloud/\">Oracle云基础设施（OCI）</a>\"上推出了云数据库服务，为客户提供融合了在线分析和事务处理能力的托管服务。2022年5月底，他们又<a href=\"https://www.oracle.com/en/news/announcement/mysql-heatwave-supports-in-database-machine-learning-2022-03-29/\">将autoML添加到了该服务中</a>\"。现在，他们首次在Oracle云基础设施之外提供了这样的服务——让用户可以在AWS上的单个服务中运行事务处理、分析和机器学习工作负载，而且不需要在独立的OLTP数据库和OLAP数据库之间进行ETL复制。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/15/1599874a8f8760f790aec1d25ab0638d.png\" /></p><p></p><p>图片来源：<a href=\"https://www.oracle.com/mysql/heatwave/\">https://www.oracle.com/mysql/heatwave/</a>\"</p><p>&nbsp;</p><p>Percona创始人兼首席执行官<a href=\"https://twitter.com/PeterZaitsev\">Peter Zaitsev</a>\"发了这样一条<a href=\"https://twitter.com/PeterZaitsev/status/1569754788295999490\">推文</a>\"：&nbsp;</p><p></p><p></p><blockquote>Oracle最终承认了没人对Oracle云感兴趣，并将Heatwave带到了AWS上，那之前曾是OCI罕有的比较“完备”的功能之一。</blockquote><p></p><p></p><p>在<a href=\"https://www.oracle.com/news/announcement/mysql-heatwave-on-aws-2022-09-12/\">新闻公告</a>\"中，Oracle宣布了MySQL HeatWave on AWS的多项新功能。该服务提供了AWS原生体验和监控预分配资源性能和使用率的能力，并集成了<a href=\"https://blogs.oracle.com/mysql/post/mysql-autopilot-machine-learning-automation-for-mysql-heatwave\">MySQL Autopilot</a>\"。后者提供了工作负载感知，基于机器学习的应用程序生命周期自动化，包括数据管理和查询执行。此外，它还提供了全面的安全特性，如服务器端数据屏蔽和去身份标识、非对称数据加密和数据库防火墙。</p><p>&nbsp;</p><p>Sanjmo负责人<a href=\"https://twitter.com/SanjMo\">Sanjeev Mohan</a>\"在LinkedIn的一篇<a href=\"https://www.linkedin.com/feed/update/urn:li:share:6975245363116986369/\">博文</a>\"中写道：&nbsp;</p><p></p><p></p><blockquote>数据平面、控制平面和控制台都是在AWS本地运行。用于AWS的代码库和用于OCI的代码库完全相同。不过，Oracle做了多项增强，集成了AWS服务，如监控资源和操作日志及指标的CloudWatch。</blockquote><p></p><p></p><p>还是在同一份新闻公告中，Oracle宣称，MySQL HeatWave的性价比优于AWS上的其他系统。比如，在运行<a href=\"https://github.com/oracle/heatwave-tpch\">来自4TB TPC-H基准测试的查询</a>\"时，<a href=\"https://www.oracle.com/mysql/heatwave/performance/\">MySQL HeatWave on AWS的性价比</a>\"是Amazon Redshift的7倍，Snowflake的10倍，Google BigQuery的12倍，Azure Synapse的4倍。</p><p>&nbsp;</p><p>Constellation Research副总裁兼首席分析师<a href=\"https://twitter.com/holgermu\">Holger Mueller</a>\"在其中一份关于MySQL on AWS的<a href=\"https://www.oracle.com/mysql/heatwave/analysts/#heatwave-on-aws\">行业分析报告</a>\"中指出：</p><p></p><p></p><blockquote>事实是，MySQL工程团队不仅在AWS上提供了MySQL Heatwave服务，为了提高性能，他们还进行了架构调整，TCO（总拥有成本）是底层软件架构卓越性的另一个证据。</blockquote><p></p><p></p><p>此外，Mueller告诉InfoQ：</p><p></p><p></p><blockquote>Oracle正在将其软件移到AWS上，这有助于AWS客户的采用，因为他们的数据就托管在这个颇具竞争力的平台上，那样可以简化迁移工作。</blockquote><p></p><p></p><p>现在MySQL HeatWave已在多家云上可用，包括OCI 和AWS，很快Microsoft Azure也会提供。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/09/oracle-mysql-heatwave-aws/\">https://www.infoq.com/news/2022/09/oracle-mysql-heatwave-aws/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/MwBXrRq4fprblHP43hpR\">AWS 数据库迁移服务：将 Oracle 数据库迁移到 MySQL</a>\"</p><p></p>",
    "publish_time": "2022-09-27 08:52:48",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从趋势到挑战，一站式解读操作系统运维和可观测性",
    "url": "https://www.infoq.cn/article/ZVP2EPUiQmOQbqAiYtjD",
    "summary": "<p></p><blockquote>编者按：随着企业数字化转型步入深水区，设备数量增加，业务系统更加复杂，除了要保证物理硬件的稳定性和可靠性，运维目的和手段也发生了深刻变革。对此，龙蜥社区系统运维 SIG 组 Maintainer、统信软件资深操作系统研发工程师高冲从系统运维的趋势与挑战、系统运维 SIG 组项目及未来展望和规划三个方面，带我们了解操作系统运维和可观测性。本文整理自&nbsp;<a href=\"https://openanolis.cn/video/#643729391503840851\">2022&nbsp;年阿里巴巴开源开放周技术演讲</a>\"，视频回放已上线至龙蜥官网（首页-动态-视频），欢迎大家观看。</blockquote><p></p><p></p><h2>一、系统运维的趋势与挑战</h2><p></p><p></p><p>随着企业数字化转型步入深水区，设备数量增加，业务系统更加复杂，除了要保证物理硬件的稳定性和可靠性，运维目的和手段也发生了深刻变革，通过平台化和智能化保证运维环境的实时性、数据安全性和业务连续性。</p><p></p><p>运维的整个发展历程主要有下面四个阶段：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/72/72c65c32cd917bcdc69ab879fb133e2c.png\" /></p><p></p><p>从最初的手动运维，依赖于运维人员的经验，发展为流程化的一个运维，依赖流程的规范化管理来实现运维，前两种的运维方式为企业带来很大的运维成本，现阶段的主流运维方式有两种：</p><p></p><p>平台化的运维。通过平台化的自动化和可视化的运维，来大大减少企业运维的成本。智能化运维。随着数据分析、人工智能的技术引入，慢慢地我们也会介入智能化运维。</p><p></p><p>下面为大家介绍下运维业务的架构。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/82/82df16e1b35713cebbdb57a94ddf7fa4.png\" /></p><p></p><p>最底层的是对于硬件的一个运维，通常就包含硬件的一些信息，比如温度、读写寿命、风扇转速等等。再往上层就是对操作系统的运维，还有是通过外挂的一些运维，比如 IPMI 协议，通常比较常见就是 BMC 。</p><p></p><p>在整个系统的运维方面，其实有两大部分，一个是管控，另外一部分是诊断。</p><p></p><p>1、管控主要分为三个方向：</p><p></p><p>第一是资源管理。首先就是对资源的一个纳管，比如说主机的一些纳管。另外就是监控，如对资源的一些监控，包含 CPU 的算力、磁盘的使用情况、带宽、内存，最后是对资源的分配。</p><p></p><p>第二是配置管理。它包含有三部分：安全、包管理、自动化。在整个运维方向来看，其实都视为是配置。配置中的安全一个是 CVE，还有一些是配置项的安全，比如说端口扫描都属于安全。另外是包的管理，现在比较主流的有两种：一个是 RPM 包，另一个是 deb 包。包管理其实就包含这个包的升级回退、版本控制。最后就是自动化，也是相对比较重要的一部分，比如说我们配置的批量下发、定时任务，还有一些模板下发。</p><p></p><p>第三就是权限管理。权限管理分两部分，一部分是用户权限控制，相对比较常见的 RBCA。另外是审计，包含行为审计和日志审计。除了审计，还有一部分是危险拦截，比如拦截危险命令的操作、提权操作等。</p><p></p><p>2、另外比较核心的一块是 SLI：</p><p></p><p>SRE(站点可靠性工程)的概念是由 gongle 创建出的, SLI 是指度量系统可靠性的测试指标。OS SLI 通常有可靠性、可用性、性能等方向，OS 通常为延迟、吞吐量、相应时间、准确性、完整性。一部分 SLI 是传统式主动触发，比如说网络延迟抖动发生的时候，运维人员去调用相关的 SLI 一些工具，做下钻式的分析或者是我们去利用凌晨或者定时巡检来发现问题，类似于轮询这样的方式。</p><p></p><p>传统的 SLI 的采集是通过系统调用获取系统信息，比较耗费资源的。目前比较火的 eBPF 技术就解决了底噪占用高和安全的问题，可以结合一些基本处理手段来获取更有价值的数据。</p><p></p><p>以上介绍的管控和诊断，我们都会通过这两块业务收集到数据，也就涉及到数据处理。</p><p></p><p>数据处理，目前有四个方向的处理方式：</p><p></p><p>一个是时续化的数据处理。我们将整个诊断，还有管控的数据做一个时续化的处理来帮助运维人员做一些更好的、更深层次的分析。第二就是一些性能的分析，需要对整个性能做负载画像。第三系统的各个的方向实际是相对比较复杂的，我们需要利用一些算法做聚合分析。最后就是异常检测。比如 IO 的一个延迟，需要对 IO 企业的时间或者读时间比较长，做一个离群检测分析。</p><p></p><p>有了这些数据之后，我们会对数据利用运维的一些经验或者 AI 技术，做一些智能化的一些介入，当然也包含告警。</p><p></p><p>结合传统运维工具和 eBPF 技术，我们可以对整个系统的进行全栈观测。从最底层，比如 CPU 的诊断来说，我们可以利用 CPU frequency 去看到每个进程在对 CPU 的一个调动频率的观测。再到上层的一个设备驱动、网络，还有文件系统，系统调用等，都是可以利用&nbsp;eBPF&nbsp;技术来做到很深层次的观测。</p><p></p><p>那同样的对用户态的一些进程，比如说数据库、中间件或者是 runtime 的一个状态都可以就是利用 uproble 技术去做观测。</p><p></p><h2>二、龙蜥社区系统运维 SIG 核心项目技术实践</h2><p></p><p></p><p><a href=\"https://openanolis.cn/sig/sysom\">系统运维 SIG 组</a>\"（Special Interest Group）是致力于打造一个集主机管理配置部署，还有监控报警、异常诊断、安全审计等一系列功能的一个自动化运维平台。目前 SIG 组有三个核心的项目：一个是&nbsp;<a href=\"https://www.infoq.cn/article/cso0DaFXwurDh4Kp9qwQ\">SysOM</a>\"，提供一站式的运维的管理平台。<a href=\"https://xie.infoq.cn/article/bcae3669c2f3c6f158c6fdaeb\">SysAK</a>\"&nbsp;是系统的一个分析诊断套件，也是核心驱动 SysOM&nbsp;一些诊断功能的技术底座。最后是比较前瞻性的&nbsp;<a href=\"https://www.infoq.cn/article/IielSpCwjf6Owd6jMBef\">coolbpf</a>\"，是对 BPF 编译套件的增强，包括一个远程编译的技术。还有是对低内核版本的在 eBPF 上特性的回合。目前整个&nbsp;SIG&nbsp;组比较活跃的，PR&nbsp;提交了有一千多。</p><p></p><p>下面为大家介绍一下 <a href=\"https://gitee.com/anolis/sysom?_from=gitee_search\">SysOM </a>\"的整个的架构。SysOM 的架构核心是分为两部分，一个是 server 端，另一个是 client 端。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/24/24273829998c9b71f523d4f344e86a51.png\" /></p><p></p><p>前端主要是 dashboard 的展示。有主机管理、监控中心、宕机中心、诊断中心、日志中心和安全中心，主要是负责和用户的一个 UI 交互。后端是负责一些核心的技术实现。比如说监控，有资源监控（目前是通过 prometheuse 的exporter-node 去实现资源的监控）、任务监控、异常监控。还有宕机分析、诊断，依托的是 SysAK 的一些功能去做到网络诊断、存储诊断、内存诊断和调度诊断。最后在安全这一块，主要包括漏洞检查、漏洞修复，加固以及日志审计。</p><p></p><p>整个的后端存储有两部分，一部分是关系型数据库，就是 RDB，还有一个就是时序性数据库。</p><p></p><p>client 包含 SysAK 负责提供系统的性能和故障诊断。vmcored client 主要是负责提供诊断信息的收集。node exporters 负责整个资源的一个诊断，还包含时序化的处理、回传 prometheus。</p><p></p><p>那下面我将是通过前端的展示，为大家直观的了解 SysOM 整个的功能：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fc/fcd58ea4f09f9e1e2558e626ce925f9e.png\" /></p><p></p><p>SysOM 主机管理，支持批量导入导出、集群化管理，当然也支持远程的终端。监控中心集成了一些常用的资源的配置项。比如说磁盘、CPU 算力，还有网络带宽的使用情况，也包含一些关键进程的监控，还有网络的延时情况。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fb/fbcfce379e54014421433d6ae1f00b27.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bc/bcd5bcf7d5d60c121fb7db67d7f08a91.png\" /></p><p></p><p>SysOM 诊断中心，也是相对比较核心的功能。我们目前对系统做了 SRE 诊断，另外也包含整个的软硬件诊断的情况，还有 IO 诊断，也去做了系统的低状态的检查。性能包括系统的调度的使用情况做了火焰图的分析，这样我们也就能够通过很直观的去看到系统的一些瓶颈、性能的问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fb/fb154ef502f9d3ab8df53062818e5687.png\" /></p><p></p><p>也包括可用性的检查，我们做了静态的一些配置项检查。比如说调度、内存和 IO 网络去通过和我们专家经验去做对比，分析出性能或者是一些故障隐患。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fb/fb154ef502f9d3ab8df53062818e5687.png\" /></p><p></p><p>SysOM 比较有亮点的两个功能：网络诊断和 IO 诊断。我们现在从单时报能看到的是网络诊断，通过从 server 端发包给 agent 端，然后把整个调用链，在每个阶段平均的耗时计算出来，通过一个直观的图展示出来，也可以通过鼠标的悬停去看具体的某个阶段的耗时情况做一个下转式的分析。比如下图对用户态的整个内核的实验做了分析：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d5/d5239e2c332073494cd57478fbc03a9c.png\" /></p><p></p><p>从上图中我们能看到它整个的一个平衡平均耗时是三十七毫秒。但是在具体的某个时间段是有一定的波动的。</p><p></p><p>整个 SysOM 的功能是相对比较多的，也欢迎感兴趣的小伙伴可以做一些有趣的探索。</p><p></p><p>最后是 SysOM 安全中心。安全中心通过是 errata 的机制，结合 Anolis 的公勘去做了漏洞的一个实施，定期扫描。当然也是支持漏洞的第三方配置。我们通过比如说配置漏洞数据库，接入第三方的一些数据库来增强整个系统或者是运维环境的安全性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/76/766cd8beb55678afed138f3ead1466f8.png\" /></p><p></p><p>那对一些高危的或者是需要我们重启的一些 CUE，我们在修复之后也是会给出相应的提示。如重启服务或者说内核需要重启系统来生效。</p><p></p><p>以上是整个 SysOM 相关内容的介绍，关于 SysAK 和 coolbpf 相关介绍可以通过 SIG 组了解，也希望大家参与到系统运维 SIG 组，大家一起来多多贡献。</p><p></p><h2>三、展望和规划</h2><p></p><p></p><p>目前 eBPF 提供了一种全新的动态插桩技术，为运维的性能和故障诊断带来新活力。统信软件也将持续贡献在 OS 方向的专家运营经验，携手龙蜥社区一起把系统运维 SIG 组做好，也把龙蜥生态做好，未来也将会在故障诊断、安全和权限管理持续发力。</p>",
    "publish_time": "2022-09-27 10:00:29",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "那些 Go 语言发展历史上的重大决策",
    "url": "https://www.infoq.cn/article/Et5Tz8NElyYf3WyUKXC9",
    "summary": "<p><a href=\"https://xie.infoq.cn/article/09cf4903f886feff5f9d77a21\">Go</a>\" 是 2007 年末由谷歌创立的一种程序设计语言，2009 年 11 月以开源形式发行。自那以后，Go 就作为一个公共项目运作，有成千上万的个人和几十家公司作出贡献。Go 已经成为一种很受欢迎的语言，用于构建云计算基础设施：Linux <a href=\"https://xie.infoq.cn/article/ec593fed3e7f334be8a44233f\">容器管理器 Docker </a>\"和<a href=\"https://mp.weixin.qq.com/s?__biz=MzIzNjUxMzk2NQ==&amp;mid=2247488904&amp;idx=1&amp;sn=613073cac30cb95dc04c4ad0033a449c&amp;chksm=e8d7ea4adfa0635ce0bbb941e6df23aa92b6b15c179b15e1d8934b03280d91e69b177f544949&amp;scene=27#wechat_redirect\">容器部署系统 Kubernetes </a>\"是由 Go 开发的一种核心云计算技术。现如今，Go 已经成为了各大云计算提供商的重要基础设施的基础，也是云原生计算基金会托管的大多数项目的实现语言。</p><p></p><p>有许多理由让早期使用者对 Go 感兴趣。一种用于构建系统的垃圾收集、静态编译的语言是不寻常的。Go 提供的并行性和并发性的原生支持，使其能够充分发挥当时正在成为主流的多核机器的优势。自带的二进制文件和简单的交叉编译使部署变得更加容易。当然，谷歌这个名称也是一大亮点。</p><p></p><p>但是为什么用户会留下来？为什么 Go 在很多其他语言项目还没有开发出来的时候，它就变得如此流行了呢？我们认为，语言本身只是答案的一小部分。完整的故事应该包括整个 Go 环境：库、工具、约定和软件工程的整体方法，这些都支持用该语言编程。所以，在语言设计方面，最关键的决策是让 Go 能够更好地适应大型软件工程，并且能够吸引有相同想法的开发人员。</p><p></p><p>在本文中，我们将会回顾那些我们认为对 Go 的成功负有最大责任的设计决策，并探讨这些设计决策如何不仅适用于语言，而且适用于更广泛的环境。很难将具体决策中的贡献分开，因此本文不应被视为一种科学的分析，而是一种对 Go 十多年来的经验和对用户反馈作出的最好的诠释。</p><p></p><p></p><h2>起源</h2><p></p><p></p><p>Go 的诞生源于谷歌构建了大规模分布式系统，在一个由成千上万的软件工程师共享的大型代码库中工作。我们希望为这种环境设计的语言和工具能够应对公司和整个行业所面临的挑战。随着开发工作的开展和生产系统的大量部署，这些都带来了一些挑战。</p><p></p><p>开发规模。在开发方面，谷歌在 2007 年有大约 4000 名活跃的用户在一个单一的、共享的、多语言（C++、Java、Python）的代码库中工作。单一的代码库使它很容易修复，例如，内存分配器中的问题会让主 Web 服务器变慢。但是在使用库的时候，由于很难找到一个包的所有依赖关系，所以很容易在不知不觉中破坏了一个以前未知的客户端。</p><p></p><p>另外，在我们使用的现有语言中，导入一个库可能会导致编译器递归加载所有导入的库。在 2007 年的一次 C++ 编译中，我们观察到，（在 #include 处理后）传递一组总共 4.2MB 的文件时，编译器读取了超过 8GB 的数据，在一个已经很大的程序上，扩展系数几乎达到 2000。如果为编译一个给定的源文件而读取的头文件的数量随着源树线性增长，那么整个源树的编译成本就会呈平方增长。</p><p></p><p>为了弥补速度的减慢，我们开始研究一个新的、大规模并行和可缓存的编译系统，它最终成为开源的 Bazel 编译系统。我们认为，光靠语言本身是远远不够的。</p><p></p><p>生产规模。在生产方面，谷歌运行的是规模非常庞大的系统。例如，在 2005 年 3 月，Sawzall 日志分析系统的一个拥有 1500 块 CPU 的集群处理了 2.8PB 的数据。2006 年 8 月，谷歌的 388 个 Big-table 服务集群由 24500 个独立的 Tablet 服务器组成，其中一组 8069 个服务器每秒处理 120 万个请求。</p><p></p><p>不过，像业界其他公司一样，谷歌也在致力于编写高效率的程序，以便充分发挥多核系统的优势。我们的很多系统都必须在一台机器上运行同一个二进制文件的多个副本，这是由于现有的多线程支持繁琐且性能低下。庞大的、固定大小的线程栈，重量级的栈开关，以及用于创建新线程和管理它们之间的交互的笨拙语法，都使得使用多核系统变得更加困难。但是显然，在服务器中，内核的数量只会越来越多。</p><p></p><p>我们还认为，语言自身能够提供易于使用的轻量级的并发性原语。我们也在这些额外的内核中看到了一个机会：垃圾收集器可以在一个专用的内核上与主程序并行地运行，这样可以减少它的延迟。</p><p></p><p>我们想知道，为应对这些挑战而设计的语言可能会是什么样子的，答案就是 Go。Go 的流行，一定程度上是因为所有的科技行业都要面对这样的挑战。云计算提供商使得最小型企业也可以将目标锁定在大规模的生产部署上。尽管大部分公司没有数千名雇员编写代码，但是如今几乎每个公司都依靠着数以千计的程序员完成的大量开源基础设施。</p><p></p><p>本文的其余部分将探讨具体的设计决定如何解决这些开发和生产的扩展目标。我们从核心语言本身开始，向外扩展到周围的环境。我们不打算全面地介绍这门语言。关于这一点，可以参阅 Go 语言规范或者<a href=\"https://www.infoq.cn/article/the-go-programming-language-book-review\">《Go 编程语言》</a>\"（The Go Programming Language）之类的书籍。</p><p></p><p></p><h2>包</h2><p></p><p></p><p>一个 Go 程序是由一个或多个可导入的包组成的，每个包都包含一个或多个文件。图 1 中的 Web 服务器展示很多有关 Go 的包系统设计的重要细节：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/42/421632ce001abd2d1349b78514c23d7b.jpeg\" /></p><p></p><p>图 1：Go Web 服务器</p><p></p><p>该程序启动了一个本地的 Web 服务器（第 9 行），它通过调用 hello 函数来处理每个请求，hello 函数用消息“hello, world”（第 14 行）进行响应。</p><p></p><p>与许多语言相同，一个包使用明确的 import 语句导入另一个包（第 3-6 行），但与 C++ 的文本 #include 机制不同。不过，与大多数语言不同的是，Go 安排每个 import 只读取一个文件。例如，fmt 包的公共 API 引用了 io 包的类型：fmt.Fprintf 的第一个参数是 io.Writer 类型的接口值。在大多数语言中，处理 fmt 的 import 的编译器也会加载所有的 io 来理解 fmt 的定义，这可能又需要加载额外的包来理解所有 io 的定义。一条 import 语句可能最终要处理几十甚至几百个包。</p><p></p><p>Go 采用与 Modula-2 相似的方式，将编译后的 fmt 包的元数据包含了了解其自身依赖关系所需的一切，例如 io.Writer 的定义，从而避免了这种工作。因此，import \"fmt\" 的编译只读取一个完全描述 fmt 及其依赖关系的文件。此外，在编译 fmt 时，可以一次性实现这种扁平化，这样就可以避免每次导入时的多次加载。这种方式减少了编译器的工作量，加快了构建速度，为大规模的开发提供了便利。此外，包的导入循环是不允许的：由于 fmt 导入 io，io 就不能导入 fmt，也不能导入任何其他导入 fmt 的东西，即使是间接的。这也降低了编译器的工作量，确保了在单个单独编译的包的级别上对某个特定的构建进行拆分。这也使我们可以进行增量式的程序分析，即使在执行测试之前，我们也会执行这种分析来捕捉错误，如下所述。</p><p></p><p>导入 fmt 并不能使 io.Writer 这个名字对客户端可用。如果主包想使用 io.Writer 这个类型，那么它就必须为自己导入“io”。因此，一旦所有对 fmt 限定名称的引用被从源文件中删除——例如，如果 import \"fmt\" 调用被删除，import \"fmt\" 语句就可以安全地从源文件中删除，而无需进一步分析。这个属性使得自动管理源代码中的导入成为可能。事实上，Go 不允许未使用的导入，以避免将未使用的代码链接到程序中而造成的臃肿。</p><p></p><p>导入路径是带引号的字符串字面，这使其解释具有灵活性。斜线分隔的路径在导入时标识了 import 的包，但随后源代码会使用在包声明中声明的短标识符来引用该包。例如，import \"net/http\" 声明了顶层名称 http，提供对其内容的访问。在标准库之外，包由以域名开头的类似 URL 的路径来识别，如 import \"github.com/google/uuid\"。我们将在后面对这种包有更多的介绍。</p><p></p><p>作为最后一个细节，注意 fmt.Fprintf 和 io.Writer 这两个名字中的大写字母。Go 对 C++ 和 Java 的 public、private 和 protected 概念和关键字的模拟是一种命名惯例。带有大写字母的名字，如 Printf 和 Writer，是“导出的”（公共的）。其他的则不是。基于大小写的、编译器强制执行的导出规则适用于常量、函数和类型的包级标识符；方法名称；以及结构域名称。我们采用这一规则是为了避免在公共 API 中涉及的每一个标识符旁边都写上一个像 export 这样的关键字的语法负担。随着时间的推移，我们已经开始重视查看标识符是否在包之外可用或在其每一次使用时纯粹是内部的能力。</p><p></p><p></p><h2>类型</h2><p></p><p></p><p>Go 提供了一套常见的基本类型。布尔，大小整数，如 uint8 和 int32，非大小 int 和 uint（32 或 64 位，取决于机器大小），以及大小浮点数和复数。它提供了指针、固定大小的数组和结构，其方式类似于 C 语言。它还提供了一个内置的字符串类型，一个称为<a href=\"https://www.infoq.cn/article/OcC9isEfI4PwcxXmiFRx\"> map 的哈希表</a>\"，以及称为 slices 的动态大小的数组。大多数 Go 程序都依赖于这些，而没有其他特殊的容器类型。</p><p></p><p>Go 不定义类，但允许将方法绑定到任何类型，包括结构体、数组、切片、映射，甚至是基本类型，如整数。它没有类型层次结构；我们认为继承性往往会使程序在成长过程中更难适应。相反，Go 鼓励类型的组合。</p><p></p><p>Go 通过其接口类型提供面向对象的多态性。就像 Java 接口或 C++ 的抽象虚拟类一样，Go 接口包含一个方法名称和签名的列表。例如，前面提到的 io.Writer 接口被定义在 io 包中，如图 2 所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0e/0e75d09b3ba0f85b9e9a8bac8efc778d.jpeg\" /></p><p></p><p>图 2：io 包的 Writer 接口</p><p></p><p>Write 接收一段字节，然后返回一个整数和可能的错误。与 Java 和 C++ 不同的是，任何 Go 类型如果拥有与某个接口相同的名称和签名的方法，都可以被视为实现了该接口，而无需显式声明它是这样做的。例如，os.File 类型有一个签名相同的 Write 方法，因此它实现了 io.Writer，所以不需要像 Java 的“implements”注释那样的显式信号。</p><p></p><p>不要把这些接口当作一个复杂类型层次结构的基础块，而是要避免在接口和实现之间的显式关联，这样，Go 程序员就可以定义小型、灵活、通常是临时性的接口。它鼓励捕捉开发过程中出现的关系和操作，而不是需要提前计划和定义它们。这对大型程序尤其有帮助，因为在刚开始开发时，最终的结构是很难看清楚的。去除声明实现的簿记，鼓励使用精确的、只有一种或两种方法的接口，如 Writer、Reader、Stringer（类似于 Java 的 toString 方法）等，这些接口普遍存在于标准库中。</p><p></p><p>初次学习 Go 的开发人员常常担心一个类型会意外地实现一个接口。虽然构建假设很容易，但在实践中，不太可能为两个不兼容的操作选择相同的名称和签名，而且我们从未在实际的 Go 程序中看到过这种情况发生。</p><p></p><p></p><h2>并发性</h2><p></p><p></p><p>当我们开始设计 Go 的时候，多核计算机已经开始广泛使用，但线程在所有流行的语言和操作系统中仍然是一个重量级的概念。创建、使用和管理线程的难度使其不受欢迎，限制了对多核 CPU 全部功能的使用。解决这一矛盾是创建 Go 的主要动机之一。</p><p></p><p>Go 语言本身包含了多个并发控制线程的概念，称为 goroutines，在一个共享地址空间中运行，并有效地复用到操作系统线程上。对阻塞操作的调用，如从文件或网络中读取，只阻塞进行该操作的 goroutine；该线程上的其他 goroutine 可能会被移到另一个线程，以便在调用者被阻塞时继续执行。goroutine 开始时只有几千字节的堆栈，它可以根据需要调整大小，无需程序员参与。开发人员将 Goroutines 作为一种丰富的、廉价的结构化程序的原语。对于一个服务器程序来说，拥有数千甚至数百万个 goroutines 是很平常的，因为它们的成本要远低于线程。</p><p></p><p>例如，net.Listener 是一个带有 Accept 方法的接口，可以监听并返回新进入的网络连接。图 3 显示了一个接受连接的函数 listen，并为每个连接启动一个新的 goroutine 来运行服务函数。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/24/2432a583b8f3bcecf99fb4c1730dc75e.jpeg\" /></p><p></p><p>图 3：一个 Go 的网络服务器。</p><p></p><p>listen 函数主体中的无限 for 循环（第 22-28 行）调用 listener.Accept，它返回两个值：连接和一个可能的错误。假设没有错误，go 语句（第 27 行）在一个新的 goroutine 中启动其参数——函数调用 serve(conn)，类似于 Unix shell 命令的后缀 &amp;，但在同一个操作系统进程中。要调用的函数及其参数在原 goroutine 中被评估；这些值被复制以创建新 goroutine 的初始堆栈框架。因此，程序为每个进入的网络连接运行一个独立的 serve 函数实例。对 serve 的调用一次处理一个给定连接上的请求（第 37 行对 handle(req) 的调用没有以 go 为前缀）；每次调用都可以阻塞而不影响对其他网络连接的处理。</p><p></p><p>在幕后，Go 的实现使用了高效的复用操作，比如 <a href=\"https://xie.infoq.cn/article/5e7ae820ac641b9ff86df4789\">Linux 的 epoll</a>\"，它可以处理并发的 I/O 操作，但用户是看不到的。Go 的运行库呈现的是阻塞式 I/O 的抽象，其中每个 goroutine 都是按顺序执行的，无需回调，这很容易推理。</p><p></p><p>在创建了多个 goroutine 之后，一个程序必须经常在它们之间进行协调。Go 提供了通道，允许 goroutine 之间进行通信和同步：通道是一个单向的、尺寸有限的管道，在 goroutine 之间传输类型化的信息。Go 还提供了一个多向 select 原语，可以根据通信的进行来控制执行。这些想法改编自 Hoare 的 \"通信顺序过程 \"19 和早期的语言实验，特别是 Newsqueak、Alef 和 Limbo。</p><p></p><p>图 4 展示了另一个版本的 listen，它是为了限制任何时候的连接数量而写的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/90/900478890a302ec09f84bee6f3812de0.jpeg\" /></p><p></p><p>图 4：一个 Go 网络服务器，限制为 10 个连接。</p><p></p><p>这个版本的 listen 首先创建了一个名为 ch 的通道（第 42 行），然后启动了一个由 10 个服务器 goroutines 组成的池（第 44-46 行），它们接收来自这个单一通道的连接。当新的连接被接收时，listen 使用 send 语句 ch &lt; - conn（第 53 行）在 ch 上发送每个连接。一个服务器执行接收表达式 &lt; - ch（第 59 行），完成通信。通道的创建没有空间来缓冲正在发送的值（Go 中的默认值），所以在 10 个服务器忙完前 10 个连接后，第 11 个 ch &lt; - conn 将被阻塞，直到一个服务器完成对服务的调用并执行新的接收。被阻塞的通信操作对监听器产生了隐性的背压，阻止它接受一个新的连接，直到它放弃前一个连接。</p><p></p><p>请注意，在这些程序中缺乏互斥或其他传统的同步机制。在通道上进行的数据值通信可以作为同步的一部分；按照惯例，在通道上发送数据会将所有权从发送方传给接收方。Go 有提供互斥、条件变量、信号灯和原子值的库，供低级别的使用，但通道往往是更好的选择。根据我们的经验，人们对消息传递——利用通信在<a href=\"https://xie.infoq.cn/article/e01a8978e8c9accdac92b73fa\"> goroutine</a>\" 之间转移所有权——的推理比对互斥和条件变量的推理更容易、更正确。早期的口号是：“不要通过共享内存来交流，而是通过交流来共享内存”。</p><p></p><p>Go 的垃圾收集器大大简化了并发 API 的设计，消除了关于哪个 goroutine 负责释放共享数据的问题。与大多数语言一样（但与 Rust 不同），可变数据的所有权不由类型系统静态跟踪。相反，Go 集成了 TSAN，为测试和有限的生产使用提供了一个动态竞争检测器。</p><p></p><p></p><h2>安全性</h2><p></p><p></p><p>任何新语言的部分原因都是为了解决以前语言的缺陷，比如 Go，它涉及影响网络软件安全的安全问题。Go 删除了在 C 和 C++ 程序中造成许多安全问题的未定义行为。整数类型不会自动相互牵制。空指针取消引用和越界的数组和片索引会导致运行时异常。不存在指向栈框架的迷途指针。任何可能超出其栈框架的变量，例如在闭包中捕获的变量，将被移到堆中。在堆中也没有迷途指针；使用垃圾收集器而不是手动内存管理可以消除使用后的错误。当然，Go 并没有解决所有问题，有些东西被遗漏了，也许应该得到解决。例如，整数溢出可以被定义为运行时错误，而不是定义为绕过。</p><p></p><p>由于 Go 是一种用于编写系统的语言，它可能需要破坏类型安全的机器级操作，因此它能够将指针从一种类型胁迫到另一种类型，并执行地址运算，但只能通过使用 unsafe 包及其受限制的特殊类型 unsafe.Pointer。必须注意保持对类型系统的违反与垃圾收集器兼容——例如，垃圾收集器必须始终能够识别一个特定的字是一个整数还是一个指针。在实践中，unsafe 包很少出现：安全 Go 是相当有效的。因此，看到 import \"unsafe\" 是一个信号，可以让我们更仔细地检查源文件是否存在安全问题。</p><p></p><p>与 C、C++ 之类的语言相比，Go 的安全性更好，更适合用于加密和其他重要的安全代码。在 C 和 C++ 中，一个微小的错误，比如一个越界的数据索引，就会造成敏感数据的泄漏或者被远程执行，但是在 Go 中，它会造成运行时的异常，从而使程序停止，极大地限制了潜在的影响。Go 提供了一个完整的加密库套件，其中包含了 SSL/TLS 的支持；标准库包含 HTTPS 客户端和服务器，可用于生产环境。实际上，Go 的安全性、性能和高品质库的结合使它成为了一个现代安全工作的热门试验场。比如，Let's Encrypt 是一家免费提供证书的机构，它依靠 Go 来提供生产服务，并在最近跨越了一个里程碑：签发了 10 亿份证书。</p><p></p><p></p><h2>完整性</h2><p></p><p></p><p>Go 在语言、库和工具层面提供了现代开发所需的核心部分。这就需要小心翼翼地平衡，既要增加足够多的“开箱即用”功能，又不能增加太多，以至于我们自己的开发过程因为要支持太多的功能而陷入困境。</p><p></p><p>该语言提供了字符串、哈希图和动态大小的数组作为内置的、易于使用的数据类型。如前所述，这些对于大多数 Go 程序来说已经足够了。其结果是 Go 程序之间有了更大的互操作性——例如，没有竞争性的字符串或哈希图的实现来分割包的生态系统。Go 包含的 goroutines 和 channel 是另一种形式的完整性。这些功能提供了现代网络程序中所需要的核心并发功能。直接在语言中提供这些功能，而不是在库中提供，这样可以更容易地调整语法、语义和实现，使其尽可能地轻量和易于使用，同时为所有用户提供统一的方法。</p><p></p><p>该标准库包括一个生产就绪的 HTTPS 客户端和服务器。对于在互联网上与其他机器互动的程序来说，这一点至关重要。直接满足这一需求可以避免额外的碎片化。我们已经看到了 io.Writer 接口；任何输出数据流都按惯例实现了这个接口，并与所有其他 I/O 适配器进行互操作。图 1 的 ListenAndServe 调用，作为另一个示例，期望有一个 http.Handler 类型的第二个参数，其定义如图 5 所示。参数 http.HandlerFunc(hello) 通过调用 hello 实现其 ServeHTTP 方法。该库创建了一个新的 goroutine 来处理每个连接，就像本文“并发性”部分中的监听器示例一样，所以处理程序可以用简单的阻塞风格来编写，服务器可以自动扩展以处理许多同步连接。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e9/e91d1c158d32cde07c3262a2b72284d1.jpeg\" /></p><p></p><p>图 5：net/http 包的处理程序接口</p><p></p><p>http 包还提供了一个基本的调度器，它本身就是 Handler 的另一种实现，它允许为不同的 URL 路径注册不同的处理程序。将 Handler 确立为约定俗成的接口，使得许多不同类型的 HTTP 服务器中间件能够被创建并相互操作。我们不需要将所有这些实现添加到标准库中，但我们确实需要建立一个允许它们一起工作的接口。</p><p></p><p>标准 Go 发行版还提供了对交叉编译、测试、剖析、代码覆盖率、模糊处理等的集成支持。测试是另一个领域，在这个领域中，建立关于核心概念的协议——例如什么是测试用例以及如何运行——使得创建的自定义测试库和测试执行环境都能很好地互操作。</p><p></p><p></p><h2>一致性</h2><p></p><p></p><p>我们对 Go 的一个目标是让它在不同的实现、执行环境中，甚至在不同的时间内表现出相同的行为。这种“无聊”的一致性行为使开发人员能够专注于他们的日常工作，并使 Go 隐退到后台。</p><p></p><p>首先，语言尽可能地规定了一致的结果，即使是错误的行为，如空指针解除引用和越界数组索引，正如本文的“安全性”部分所讨论的。Go 需要不一致行为的一个例外是对哈希图的迭代。我们发现，程序员经常不经意地写下依赖于哈希函数的代码，导致在不同的架构或 Go 实现上出现不同的结果。</p><p></p><p>为了使程序在任何地方都有相同的表现，一种选择是强制规定一个特定的哈希函数。相反，Go 定义了映射迭代是非确定的。该实现为每个映射使用不同的随机种子，并从哈希表中的一个随机偏移量开始对映射进行每次迭代。其结果是，映射在不同的实现中都是不可预知的。代码不能意外地依赖于实现细节。与此类似，竞争检测器为调度决策增加了额外的随机性，创造了更多的机会来观察竞争。</p><p></p><p>一致性的另一个方面是在程序的生命周期内的性能。使用传统的编译器而不是 Java 和 Node.js 等语言使用的 JIT 来实现 Go 的决策，在启动时和短期程序中提供了一致的性能。不存在“慢速启动”来惩罚每个进程生命周期的前几秒。对于命令行工具和规模较大的网络服务器（如 Google App Engine）来说，这种快速的启动使 Go 成为一个有吸引力的目标。</p><p></p><p>一致性的性能包括垃圾收集的开销。最初的 Go 原型使用了一个基本的、即停即用的垃圾收集器，当然，它在网络服务器中引入了明显的尾部延时。今天，Go 使用了一个完全并发的垃圾收集器，暂停时间不到一毫秒，通常仅为几微秒，与堆的大小无关。最主要的延迟是操作系统向必须中断的线程传递信号所需的时间。</p><p></p><p>最后一种一致性是语言和库随着时间的推移而产生的一致性。在 Go 诞生的前几年，我们在每周的发布中都会对它进行修补和调整。用户在更新到新的 Go 版本时，往往不得不改变他们的程序。自动化的工具减轻了负担，但手动调整也是必要的。从 2012 年发布的 Go 版本开始，我们公开承诺只对语言和标准库进行向后兼容的修改，这样程序在编译到较新的 Go 版本时，可以在不改变的情况下继续运行。这一承诺吸引了业界，不仅鼓励了长期的工程项目，也鼓励了其他努力，如书籍、培训课程和第三方软件包的繁荣生态系统。</p><p></p><p></p><h2>工具辅助开发</h2><p></p><p></p><p>大规模的软件开发需要大量的自动化和工具化。从一开始，Go 的设计就是为了鼓励这种工具化，使其易于创建。</p><p></p><p>开发人员对 Go 的日常体验是通过 go 命令进行的。与只编译或运行代码的语言命令不同，go 命令为开发周期的所有关键部分提供了子命令：go build 和 go install 构建和安装可执行文件，go test 运行测试用例，go get 添加新的依赖。go 命令还提供了对构建细节的编程访问，例如软件包图，从而实现了新工具的创建。</p><p></p><p>其中一个工具是 go vet，它可以执行增量的、每次打包的程序分析，可以像缓存编译的对象文件那样缓存，实现增量构建。go vet 工具的目的是高精度地识别常见的正确性问题，这样开发人员就有条件按照它的报告进行处理。简单的例子包括在调用 fmt.Printf 和相关函数时检查格式和参数是否匹配，或者诊断对变量或结构域的未使用的写入。这些不是编译器错误，因为我们不希望仅仅因为发现了一个新的可能的错误就停止编译旧代码。它们也不是编译器警告；用户要学会忽略这些。将这些检查放在一个单独的工具中，可以让它们在开发人员方便的时候运行，而不干扰普通的构建过程。这也使得所有的开发人员都可以使用同样的检查，即使是在使用 Go 编译器的另一种实现，如 Gccgo15 或 Gollvm17。增量方法使得这些静态检查足够有效，我们在 go test 期间自动运行它们，然后再运行测试本身。无论如何，测试是用户寻找错误的时候，而报告往往有助于解释实际的测试失败。这个增量框架也可以被其他工具重用。</p><p></p><p>分析程序的工具非常有用，但编辑程序的工具就更好了，特别是对于程序的维护方面，很多都是枯燥乏味的，并且已经是成熟的自动化。</p><p></p><p>Go 程序的标准布局是通过算法定义的。一个名为 gofmt 的工具将源文件解析为抽象的语法树，然后使用一致的布局规则将其格式化为源代码。在 Go 中，在将代码存储到源控制中之前将其格式化被认为是一种最佳做法。这种方法使数以千计的开发人员能够在一个共享的代码库中工作，而不需要经常为大括号样式和其他细节进行争论，这些都是伴随着这种大型工作的。更重要的是，工具可以通过对抽象语法形式的操作来修改 Go 程序，然后用 gofmt 的打印机写出结果。只有实际改变的部分才会被触及，产生的“差异”与人们的手写结果是一致的。人们和程序可以在同一个代码库中无缝协作。</p><p></p><p>为了实现这种方法，Go 的语法被设计为能够在没有类型信息或任何其他外部输入的情况下就可以对源文件进行解析，并且不需要预处理器或其他宏系统。Go 标准库提供了一些包，允许工具重新创建 gofmt 的输入和输出端，同时还有一个完整的类型检查器。</p><p></p><p>在发布 Go 第 1 版（第一个稳定的 Go 版本）之前，我们编写了一个叫做 gofix 的重构工具，它使用这些包来解析源代码，重写树，并写出格式良好的代码。例如，当从映射中删除一个条目的语法被改变时，我们就使用了 gofix。每次用户更新到一个新版本时，他们可以在他们的源文件上运行 gofix，自动应用更新到新版本所需的大部分变化。</p><p></p><p>这些技术也适用于 IDE 插件和其他支持 Go 程序员的工具——过滤器、调试器、分析器、构建自动程序、测试框架等等的构建。Go 的常规语法、既定的算法代码布局惯例以及对标准库的直接支持，使得这些工具的构建比其他方式要容易得多。因此，Go 世界拥有一个丰富的、不断扩展的、可互操作的工具包。</p><p></p><p></p><h2>库</h2><p></p><p></p><p>在语言和工具之后，用户如何体验 Go 的下一个关键方面是可用的库。作为一种分布式计算的语言，Go 中没有必须发布 Go 软件包的中央服务器。相反，每个以域名开始的导入路径都被解释为一个 URL（有一个隐含的前导 https://），提供远程源代码的位置。例如，import \"github.com/google/uuid\" 可以获取托管在相应的 GitHub 仓库的代码。</p><p></p><p>托管源代码最常见的方式是指向公共的 Git 或 Mercurial 服务器，但私人服务器也同样得到了很好的支持，作者可以选择发布一个静态的文件包，而不是开放对源控制系统的访问。这种灵活的设计和发布库的便利性创造了一个繁荣的可导入 Go 包的社区。依靠域名，避免了在扁平的包名称空间中急于声明有价值的条目。</p><p></p><p>仅仅下载软件包是不够的，我们还必须知道要使用哪些版本。Go 将包分组为称为模块的版本单位。一个模块可以为它的一个依赖关系指定一个最低要求的版本，但没有其他限制。当构建一个特定的程序时，Go 通过选择最大版本来解决竞争的依赖模块的所需版本。如果程序的一部分需要某个依赖模块的 1.2.0 版本，而另一部分需要 1.3.0 版本，Go 会选择 1.3.0 版本——也就是说，Go 要求使用语义版本划分，其中 1.3.0 版本必须是 1.2.0 的直接替换。另一方面，在这种情况下，即使 1.4.0 版本可用，Go 也不会选择它，因为程序中没有任何部分明确要求使用该较新的版本。这个规则保持了构建的可重复性，并最大限度地减少了因意外破坏新版本所引入的变化而造成的潜在风险。</p><p></p><p>在语义版本管理中，一个模块只能在一个新的主要版本中引入有意的破坏性变化，比如 2.0.0。在 Go 中，从 2.0.0 开始的每个主要版本在其导入路径中都有一个主要版本后缀，比如 /v2。不同的主版本和其他不同名字的模块一样被分开。这种方法不允许出现钻石依赖性问题，而且在实践中，它可以适应不兼容的情况，也可以适应具有更精细约束的系统。</p><p></p><p>为了提高从互联网上下载软件包的构建的可靠性和可重现性，我们在 Go 工具链中运行了两个默认使用的服务：一个是可用 Go 软件包的公共镜像，一个是加密签名的预期内容的透明日志。即使如此，广泛使用从互联网上下载的软件包仍然存在安全和其他风险。我们正在努力使 Go 工具链能够主动识别并向用户报告脆弱的软件包。</p><p></p><p></p><h2>总结</h2><p></p><p></p><p>虽然大多数语言的设计都集中在语法、语义或类型的创新上，但 Go 的重点是软件开发过程本身。Go 语言高效、易学、免费，但我们相信，它的成功之处在于它所采取的编写程序的方式，特别是多个程序员在一个共享代码库上工作时。该语言本身的一个重要属性，即并发性，解决了 2010 年代随着多核 CPU 的大量使用而出现的问题。但更重要的是，早期的工作为打包、依赖关系、构建、测试、部署和软件开发领域的其他工作任务奠定了基础，这些方面通常在语言设计中并不重要。</p><p></p><p>这些想法吸引了志同道合的开发人员，他们重视的结果是：容易并发、明确的依赖关系、可扩展的开发和生产、安全的程序、简单的部署、自动代码格式化、工具辅助开发等等。这些早期的开发人员帮助普及了 Go，并播种了最初的 Go 包生态系统。他们还推动了该语言的早期发展，例如，将编译器和库移植到 Windows 和其他操作系统上（最初的版本只支持 Linux 和 MacOS X）。</p><p></p><p>并非所有的人都会喜欢——比如，有些人反对该语言省略了继承和泛型等常见功能。但是 Go 的开发导向的理念足够吸引人，也足够有效，以至于社区在保持最初推动 Go 存在的核心原则的同时，也得到了蓬勃发展。在很大程度上，多亏了这个社区和它所建立的技术，Go 如今已成为现代云计算环境的一个重要组成部分。</p><p></p><p>自 Go 第一版发布以来，该语言几乎被冻结。然而，工具已经大大扩展，有了更好的编译器，更强大的构建和测试工具，以及改进的依赖性管理，更不用说支持 Go 的大量开源工具了。然而，变化正在到来。2022 年 3 月发布的 Go 1.18，它包含了对语言的真正改变的第一个版本，一个被广泛要求的改变：首次实现了参数化多态。我们将任何形式的泛型排除在原始语言之外，因为我们敏锐地意识到，它很难设计好，而且在其他语言中，往往是复杂性而不是生产力的来源。在 Go 的第一个十年中，我们考虑了很多设计，但直到最近才找到一个我们认为很适合 Go 的设计。在坚持一致性、完整性和社区原则的前提下进行如此大的语言变革，对于这种方式来说，将是一个巨大的挑战。</p><p></p><p>作者介绍：</p><p></p><p>本文作者为：Russ Cox、Robert Griesemer、Rob Pike、Ian Lance Taylor、Ken Thompson，均为谷歌公司软件工程师，参与了 Go 项目。Rob Pike、Ken Thompson 已退休。</p><p></p><p>原文链接：</p><p></p><p><a href=\"https://m-cacm.acm.org/magazines/2022/5/260357-the-go-programming-language-and-environment/fulltext?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjQyNDc4MzAsImZpbGVHVUlEIjoiMndBbFgwVjA0bWlabzVBUCIsImlhdCI6MTY2NDI0NzUzMCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo4MjQxNjgxMn0.nL4jlifNyunPrhLL4S9fFPzqzA9N44B-FOXLVx4vZBE\">https://m-cacm.acm.org/magazines/2022/5/260357-the-go-programming-language-and-environment/fulltext</a>\"</p>",
    "publish_time": "2022-09-27 11:33:13",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "《架构师成长计划》之算力网络圆桌对话：筑算力，话东西",
    "url": "https://www.infoq.cn/article/Yxq6QiXCKgp4Q4l8vL7O",
    "summary": "<p>“算力”——如水利之于农业时代，电力之于工业时代，已成为数字经济时代的核心生产力。“东数西算”通过构建数据中心、云计算、大数据一体化的新型算力网络体系，将东部算力需求有序引导到西部，优化数据中心建设布局，促进东西部协同联动，已成为中国继南水北调、西电东送后的重点发展战略。</p>\n<p>但现实是，中国东西部地区跨度大、云边距离远，这些问题对计算、存储、通讯网络的跨域调度提出了新的挑战。如何提升算网融合后的效率？如何构建节能先进的新型绿色数据中心，更好地赋能“数字经济”、“双碳”目标发展？</p>\n<p>英特尔携手Science推出《筑算力、话东西》圆桌对话！中国工程院院士邬贺铨，中国移动研究院副院长段晓东，英特尔市场营销集团副总裁、中国区数据中心销售总经理兼中国区运营商销售总经理庄秉翰三位重量级嘉宾联袂，聚焦算力网络，直击当下痛点和难点，详解前沿技术趋势与发展方向，全览“东数西算”的宏观意义和价值。更多精彩内容 ，请戳 <a href=\"https://bizwebcast.intel.cn/eventstart.aspx?eid=327&amp;tc=ouox4dyr5e&amp;frm=InfoQ\">https://bizwebcast.intel.cn/eventstart.aspx?eid=327&amp;tc=ouox4dyr5e&amp;frm=InfoQ</a></p>\n<p><strong>精彩亮点</strong></p>\n<p>院士解析东数西算宏观意义，东西部之间如何实现算力优化</p>\n<p>算力网络如何布局构建创新型信息基础设施</p>\n<p>算力、网络、绿色节能的三位一体如何助力东数西算</p>\n<p><strong>议程</strong></p>\n<p>圆桌讨论：筑算力，话东西</p>\n<p>邬贺铨 中国工程院院士</p>\n<p>段晓东 中国移动研究院副院长</p>\n<p>庄秉翰 英特尔市场营销集团副总裁、中国区数据中心销售总经理兼中国区运营商销售总经理</p>\n<p>刘启诚 通信世界全媒体总编辑</p>",
    "publish_time": "2022-09-27 11:55:15",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "GTLC全球技术领导力峰会-上海站 闭门会精彩回顾",
    "url": "https://www.infoq.cn/article/zG1NWbZhgoiTWBjOcYCG",
    "summary": "<p></p><p>2022 年 9 月 25 日，<a href=\"https://www.webeye.com/\">WebEye </a>\"在<a href=\"https://gtlc.infoq.cn/2022/shanghai?utm_source=infoq&amp;utm_medium=conference\">GTLC 全球技术领导力峰会·上海站</a>\"举办《云原生时代，企业数据体系建设探讨》技术专场闭门会，全面覆盖方法论及业务实操，通过主题分享、话题讨论和专家观点分享环节，与科技领导者深度探讨如何借助云上大数据技术，加速数据体系建设与数据价值挖掘的过程。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a6/a6153be6de000c8e2d5b180e01bac6f5.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ca/cae2ed962875d12246528709d6149988.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b0/b09ccc9d12fcc4b984cbea1e7ad0bd91.jpeg\" /></p><p></p><p></p><h2>主题分享 -《云上数据体系建设思考》</h2><p></p><p></p><p>对出海企业来说，数字化思考贯穿出海业务全生命周期，WebEye 联合创始人 &amp; CTO 任翔基于 WebEye 5 年数据体系迭代历程，对“云上数据体系建设思考”进行深入剖析。</p><p></p><p>启动数据体系建设前，科技领导者可站在“业务、管理、平台”视角，纵览出海和国内产品业务，打通用户增长和变现链条，衡量经营活动产出效率，统一数据资产管理与建设，把握“时机、目的、投入”的三大要素。</p><p></p><p>选择数据方案时，根据企业所处的不同阶段，明确业务目标，有效整合数据源，赋能整个运营决策，坚持“ALL IN CLOUD”，以<a href=\"https://baike.baidu.com/item/PaaS/219931?fr=aladdin\">PaaS</a>\"云平台托管，结合部分开源方案持续迭代，统一数据治理，多种BI可视化方案兼容，以适应全球化模式数据体系，企业上云成为驱动各行业数字化转型的新引擎。</p><p></p><p>企业数据体系建设是数据应用场景、数据管理与运营、数据技术平台、各组织单元等多方面协作推进的长期过程，此番分享获得参会科技领导者的高度认可，使得互动环节反应热烈，气氛一度达到高潮。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7a/7a6293b558e239dada45f2d72002342b.png\" /></p><p></p><p></p><h2>主题分享 -《GCP数据分析类产品的应用与落地》</h2><p></p><p></p><p>然而数据上云之路并非坦途一片，面临诸多痛点和挑战。细分到技术层面，也同样面临收集、处理、存储、分析、洞察等困局。这些出海企业关心的问题，通过统一的云平台技术能够得到最优解。</p><p></p><p>为此，WebEye云服务技术总监 田晨凭借丰富的实战经验，与参会科技领导者进行了热烈的讨论，并分享了“GCP数据分析类产品的应用与落地”，在具体的技术范畴，为大家介绍了GCP Smart Analytics平台”开放、灵活、智能、可靠“的特性，并通过Dataflow、Dataproc、Datastream、BigQuery等多元产品矩阵在助力现代数据分析、强化商业智能领域的能效，加速企业数据资产化，进一步推进数字经济转型。</p><p></p><p>田总在本次演讲中，还展示了GCP产品解决游戏客户难题的真实数据案例，WebEye 通过事件采集和抓取服务，运行于GKE集群，根据计算规模动态扩缩，使用Cloud Build，Container Registry等云原生的代码仓库和镜像仓库，提高发布效率，使服务可用性达99.99%......并以“不同业务场景，企业如何选择合适的数据分析产品，在云上构建数据分析平台？”触发业务新灵感，引起热议。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0a/0aa201bda64400f7c756f5b3d75819a8.png\" /></p><p></p><p></p><h2>Lean Coffee 讨论</h2><p></p><p></p><p>面对市场变化的新常态，企业纷纷加码数字化转型，充分发挥数据效能，是当下以及未来长时间内的重要任务。而此时，企业所需的敏捷反应意识和高效迭代能力，使得云原生成为最短路径。</p><p></p><p>WebEye 邀请到2位 Google Cloud 专家一同加入话题组，从产品技术到实际应用，与参会科技领导者同桌讨论，共探出海业务技术层面的痛点和创新实践，找到企业最佳数据体系建设的应对策略。</p><p></p><p>企业应如何选择数据体系建设路径，赋能业务增长？</p><p></p><p>不同业务场景，企业如何选择合适的数据分析产品，在云上构建数据分析平台？</p><p></p><p>在此期间，大家畅所欲言，各抒己见，博采众长。在群策群力的思想碰撞中，进一步梳理了对企业数据体系建设发展方向，并从中收获良多。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/26/2609f11e606721c79b88d1ecdb61f388.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ad/ad66c43771279c1be49cf15892f6b9a6.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3f/3f2e3ae7edf34e2f74e052fbaceec4ae.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e3/e3326ffdb8a1ee8a0df4266f4aa332d7.jpeg\" /></p><p></p><p>感谢各位科技领导者对此次专题闭门会的支持，WebEye 将继续致力于用创新的技术向中国企业提供数字化效率创新服务，实现数字化赋能。用更开放的态度拥抱科技，助力中国企业致胜海外！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/29/2909ae36a61161ac15476a41f184798c.jpeg\" /></p><p></p>",
    "publish_time": "2022-09-27 14:18:32",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "腾讯 scBERT 算法模型登上《Nature》子刊，能辅助医生精准治癌",
    "url": "https://www.infoq.cn/article/HPiFNeaslD5cY3BfyywH",
    "summary": "<p>InfoQ 获悉，9月27日，腾讯在人工智能、生命科学跨学科应用领域的最新研究成果<a href=\"https://www.nature.com/articles/s42256-022-00534-z\">《scBERT as a Large-scale Pretrained Deep Language Model for Cell Type Annotation of Single-cell RNA-seq Data》</a>\"（《基于大规模预训练语言模型的单细胞转录组细胞类型注释算法》），登上国际顶级学术期刊《Nature》子刊《Nature Machine Intelligence》。</p><p></p><p>据悉，单细胞测序技术是生命科学领域的一项革命性技术。可以细粒度地观察和刻画各个物种中组织、器官和有机体中单细胞分子图谱（细胞表达），便于更好地了解肿瘤微环境，以达到精细分析病因、精准匹配治疗方案的效果，对于“精准医疗”具有极高的应用价值。</p><p></p><p>值得注意的是，受数据样本量小、人工干预多、过度依赖marker gene（已报道的特异性基因）等因素的影响，单细胞测序细胞类型注释技术一直面临着泛化性、可解释性、稳定性均比较低的问题，现存的算法难以有更广泛的应用。其中，人工注释费时、主观、误差大、无法发现新的细胞类型；机器注释经常出现在一个检测组织里有效，在另外一个检测组织里就没效的情况，还是需要人工参与。</p><p></p><p>1.0 人工注释。marker gene（标记基因）注释法：首先对单细胞测序数据进行聚类，然后可视化聚类结果中的marker gene，然后根据人工判读注释。marker gene一般会发表在各大文献里，相当于某个细胞类群的标志基因，知道了它就知道了这个细胞类群的身份。人工判读，就是查找资料进行注释。就好比：将基因比作一行文字，要识别出来，便要去逐个字查字典，看这行文字是什么意思。</p><p></p><p>2.0 机器注释。目前使用的<a href=\"https://www.infoq.cn/article/j2HBHBDR1YFQtbiEjEMu\">深度学习</a>\"技术较为原始，通常只采用几层全连接网络作为深度学习模型，这就限制了模型对高维度数据提取整体有效表征的能力。没有充分发挥深度学习基于数据驱动发现的能力，泛化能力差。就好比：一个初代翻译机，只能识别出一些文字的内容，比如含“人”偏旁。遇到不认识的字，也没办法。对这一行文字的理解并不清晰。</p><p></p><p>3.0 基于大规模预训练语言模型的单细胞转录组细胞类型注释算法。即“scBERT”模型，首次将“<a href=\"https://www.infoq.cn/article/QBloqM0Rf*SV6v0JMUlF\">Transformer</a>\"”（自然语言处理算法经典计算单元）运用到单细胞转录组测序数据分析领域。该模型基于BERT范式，将细胞中基因的表达信息转化成可被计算机理解、学习的“语言”，并对细胞进行精准标注。</p><p></p><p>开源地址：https://github.com/TencentAILabHealthcare/scBERT</p><p></p><p>为了保证全基因组内基因级别的<a href=\"https://www.infoq.cn/article/5kbN0qw43VmNQK2GBFPh\">可解释性</a>\"，“scBERT”在预训练数据上没有做任何的降维或筛选处理，最大程度上保留数据本身的特性和信息。此外，该模型复用了大规模的公开数据集，包含不同实验来源、批次和组织类型的单细胞数据，以保证模型能学习到更为“通用”的知识，精准捕获单个基因的表达信息及两两基因之间的作用关系。</p><p></p><p>从结果上来看，“scBERT”模型实现了高解释性、高泛化性、高稳定性的单细胞类型注释技术。截至目前，通过了9个独立数据集、超过50万个细胞、覆盖17种主要人体器官和主流测序技术组成的大规模benchmarking测试数据集上，该算法模型的优越性均得以验证。其中，在极具挑战的外周血细胞亚型细分任务上，相较现有最优方法的70%准确度提升了7%。</p><p></p><p>在应用价值层面，该项技术能给细胞中的每个基因都印上专属“身份证”，可用于临床单细胞测序数据，并辅助医生描述准确的肿瘤微环境、检测出微量癌细胞，从而实现个性化治疗方案或者癌症早筛。同时，对疾病致病机制分析、耐药性、药物靶点发现、预后分析、免疫疗法设计等领域都具有极其重要的作用。目前，单细胞测序技术正处于向临床应用转化的阶段。</p>",
    "publish_time": "2022-09-27 14:18:58",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Apache Doris 在橙联的应用实践：数仓架构全面革新，数据计算时间从2小时变成3分钟",
    "url": "https://www.infoq.cn/article/JpZR7aT1waRlUhbsSrjr",
    "summary": "<p></p><h2>业务背景</h2><p></p><p></p><p>橙联股份是一家服务全球跨境电商的科技公司，致力于通过市场分析、系统研发及资源整合，为客户提供物流、金融、大数据等多方面的服务产品，为全球跨境电商提供高品质、全方位的服务解决方案。</p><p></p><p>随着公司业务的发展和数据的不断增长，早期基于 MySQL 的传统数仓架构已经无法应对公司数据的快速增长。业务的需求和运营的决策对于数据时效性的要求越来越高，对数仓准实时能力的需求越发强烈。</p><p></p><p>为了适应快速的增长需求，橙联于 2022 年正式引入 <a href=\"http://doris.apache.org/\">Apache Doris</a>\"，以 Apache Doris 为核心构建了新的数仓架构，构建过程中对服务稳定性、查询稳定性、数据同步等多方面进行了优化，同时建立了以 <a href=\"https://xie.infoq.cn/article/0f316cdd71a454f81da963a4d\">Apache Doris </a>\"为核心的数据中台，在这一过程中积累了诸多使用及优化经验，在此分享给大家。</p><p></p><h2>数仓架构演进</h2><p></p><p></p><h4>早期数仓架构</h4><p></p><p></p><p>公司在成⽴初期业务量不⼤，数据团队规模⽐较⼩，对数据的需求仅局限于少量 T + 1 定制化报表需求。因此，早期数仓架构十分简单，如下图所示，直接使用 MySQL 构建数仓集市层，使用数仓集市层的数据进行报表开发，基于商业化的报表平台向需求方提供 T + 1 的数据报表服务。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/b0/91/b0efccf592a9fba3aedcf88dd55c0791.png\" /></p><p></p><p>存在的问题</p><p></p><p>随着公司业务规模扩大、数据量激增以及对数据时效性要求不断提高，使⽤ MySQL 进⾏数据分析越来越不能满⾜业务⽅的要求。没有对数仓进⾏分层划域，烟囱式的开发模式数据复⽤性很差，开发成本⾼，业务⽅提出的需求不能快速得到响应。对数据的质量和元数据的管理缺乏管控。</p><p></p><h4>新数仓架构</h4><p></p><p></p><p>为了解决旧架构日益凸显的问题，适应快速增长的数据和业务需求，今年正式引入 Apache Doris 构建新的数仓架构。</p><p></p><p>选择 Apache Doris 的原因：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/da/fa/da2a89a839f880988869bd4dbcdc2afa.png\" /></p><p></p><p>易⽤性 - 在当前应用场景下，引入新技术，将面临大量报表迁移问题，因此必须要考虑的产品易用性问题，而 Apache Doris 在学习成本、报表迁移成本、服务运维成本上有着非常优秀的表现，具体包括：</p><p></p><p>采⽤ MySQL 协议和语法，⽀持标准 SQL，可以通过各类客户端⼯具来访问 Doris，能够与 BI ⼯具⽆缝对接。⽀持多表 Join，针对不同场景的 Join 提供了多种优化⽅案。⽣态扩展完善，离线数据的⾼效批量导⼊、流式数据的低延迟实时导⼊都有很好的⽀持。相较于业界其他热⻔ OLAP 数据库，Doris 的分布式架构⾮常简洁，只有 FE、BE 两个进程，运⾏不依赖任何第三⽅系统。⽀持弹性伸缩，对于部署、运维⾮常友好。</p><p></p><p>性能 - 当前报表存在大量降耦聚合操作，对多表关联的查询性能和实时查询的时效性有着十分高的要求，而 Apache Doris 基于 MPP 架构实现，并自带了⾼效的列式存储引擎，可以支持：</p><p></p><p>数据的预聚合以及预聚合结果的⾃动更新。数据的实时更新。⾼并发查询。</p><p></p><p>基于以上的原因，最终选择了以 Apache Doris 为核心构建新的数仓。</p><p></p><p>架构介绍</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/35/43/3555fb5bdaaeac1353b487ab39ac3143.png\" /></p><p></p><p>Apache Doris 的数仓架构十分简洁，不依赖 <a href=\"https://www.infoq.cn/article/8kwSM0CaUVYW1EzeO7GT\">Hadoop</a>\" 生态组件，构建及运维成本较低。</p><p></p><p>如以上架构图所示，我们的数据源共有4种，业务数据 MySQL、文件系统CSV、埋点数据和第三方系统 API；针对不同的需求，使用了不同的数据导入方式，文件数据导入使用 Doris Stream Load，离线数据使用 DataX doriswriter 进行数据初始化，实时增量数据使用 Flink CDC + Flink Doris Connector 的方式进行数据同步；数据存储和计算层使用了 Doris ，在分层设计上采用 ODS(Operation Data Store 数据准备区，也称为贴源层)、 明细层 DWD、中间层 DWM、服务层 DWS、应用层 ADS 的分层思想，ODS 之后的分层数据通过 DolphinScheduler 调度 Doris SQL 进行增量和全量的数据更新。最终上层数据应用使用自研的一站式数据服务平台，可以和 Apache Doris 无缝对接，提供自助报表、自助取数、数据大屏、用户行为分析的数据应用服务。</p><p></p><p>基于 Apache Doris 的数仓架构方案可同时支持离线和准实时应用场景，准实时的 Apache  Doris 数仓可以覆盖 80% 以上的业务场景。这套架构大大降低了研发成本，提高了开发效率。</p><p></p><p>当然在架构构建过程中也遇到一些问题和挑战，我们针对问题进行了相应的优化。</p><p></p><h2>Apache Doris 构建数仓优化方案</h2><p></p><p></p><p>在数仓的使用过程中，主要遇到三方面问题。首先是服务稳定性问题，其次是查询速度逐渐变慢的问题，最后是 Doris 数据同步和 Doris SQL 调度问题。具体体现在以下：</p><p></p><h4>服务稳定性</h4><p></p><p></p><p>优化前</p><p></p><p>在 Apache Doris 使用初期，FE 和 BE 的部署方式如下：</p><p></p><p>FE 负责元数据的管理、用户请求接入、查询的解析规划，资源占用较低，因此将 FE 和其他大数据组件混合部署 FE*3。BE 负责数据存储、计算、查询计划的执行，资源占用较大，因此 BE 进行独立部署且分配了较多的资源 BE（16C 128G 4T*1）*7。</p><p></p><p>基于以上方式部署，使用初期运行的稳定性还不错。然而在使用了一段时间之后，这种部署方式暴露的问题就越来越明显。</p><p></p><p>存在的问题</p><p></p><p>首先，FE 混合部署存在资源竞争。其他组件与 FE 服务竞争资源，导致 FE 资源不足，服务运行稳定性不好。具体问题表现在：每当机器资源使用率打满，就会导致 FE 节点无法连接，长时间获取不到心跳而被 FE 集群判定为离线。其次，BE 单磁盘存在 Compaction 效率低的问题。初期，我们在部署 BE 时，每个节点只分配了 1 块 4T 的磁盘，虽然磁盘的空间并不小，但是磁盘的数量比较少，Compaction 线程数只有 2，Compaction 效率很低，这是导致 BE Compaction Score 不健康的原因之⼀。Compaction 配置参数</p><p></p><p>compaction_task_num_per_disk 每个磁盘上的任务数，默认为 2</p><p>max_compaction_threads Compaction 线程的总数，默认为 10</p><p>total_permits_for_compaction_score Compaction 任务配额，默认 10000</p><p></p><p></p><blockquote>Compaction 工作机制：Apache Doris 的数据写⼊模型使⽤了与 LSM-Tree 类似的数据结构。数据以追加（Append）的⽅式写⼊磁盘，在读逻辑中，需要通过 Merge-on-Read 合并处理写入的数据。Merge-on-Read 会影响读取的效率，为了降低数据读取时需要合并的数据量，使⽤ LSM-Tree 的系统会引⼊后台数据合并逻辑，以⼀定策略定期的对数据进⾏合并。</blockquote><p></p><p></p><p>优化后</p><p></p><p>为了解决以上的问题，对部署方式进行了优化以提升服务的稳定性：</p><p></p><p>FE 进行独⽴部署，避免了 FE 混合部署资源竞争问题BE 进行磁盘拆分，多磁盘部署，从原来一块 4T 磁盘变更为 5块 1T 磁盘，使 BE Compaction 线程数提升 5 倍，Compaction 效率、磁盘 I/O 带宽也得到了提升增加客户端连接代理层 ProxySQL，对 FE 连接进⾏负载均衡，解决 FE 连接单点问题增加 Supervisor 对 FE、BE 服务进程状态监控，FE、BE 进程意外宕机可以快速恢复</p><p></p><p>经过以上对部署的优化，Apache Doris 服务的稳定性有了很大的提升，基本可以满足目前对稳定性的需求。</p><p></p><h4>查询稳定性</h4><p></p><p></p><p>初期刚部署时，无论进行数据导入还是数据查询，执行起来都比较顺畅。但随着承载的表和数据导入作业数量不断增多，查询稳定性问题逐渐暴露出来。</p><p></p><p>优化前</p><p></p><p>存在的问题</p><p></p><p>随着使用时间和数据量的增加，集群开始频繁出现不可用的问题，主要体现在以下几个方面：</p><p></p><p>DDL 操作很难执行，查询速度变得比较缓慢FE 服务频繁出现 OOM 宕机，有时候甚至出现无法连接的情况</p><p></p><p>下图是生产环境某张表的体积的大小和 Tablet 数量的情况。这张表的体积只有 275M，但是 Tablet 的数量却达到了 7410，这非常不合理。进一步排查确认整个集群 Tablet 数量非常庞大，集群只有 5T 的数据量，然而 Tablet 数量达到 150 万。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/94/e0/940cf2e7de56b4323f06bd72983d57e0.png\" /></p><p></p><p>最初我们对 Apache Doris 表数据量大小、分区粒度、Bucket 数量、Tablet 数量的关系及 Tablet 数量对集群的影响没有清晰的概念。开发人员在 Apache Doris 使用中更多的是追求查询速度，将大部分的动态分区表的分区粒度设置的比较小，分区 Bucket 数量设置却比较大。</p><p></p><p>经过与 Apache Doris 社区小伙伴的沟通交流，了解到 Tablet 数量过大可能会导致元数据管理和运维压力增大，出现查询速度缓慢、FE 不稳定的问题。</p><p></p><p>优化方案</p><p></p><p>首先明确 Tablet 数量的计算方式，Tablet 数量 = 分区数量 * Bucket 数量 * 副本数。结合当前实际使用情况，确认可以在分区粒度和 Bucket 数量上进⾏优化。我们将分区的粒度从按天、按周分区更改为按月分区，Bucket 数量按照数据体积大小进行合理的配置。如下图所示，是建议数据体积大小对应的 Bucket 数量设定。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/20/c2/20e194304f72462db0e224b31yy243c2.png\" /></p><p></p><p>本次的优化目标是将 Tablet 数量从 150 万降低到 15 万，同时我们也对未来的增长速度进行了规划，在三副本情况下，期望 Tablet 数量增长速度是 30000/TB。</p><p></p><p>优化后</p><p></p><p>实际上，在仅对 ODS 表进⾏了分区粒度和 Bucket 数量调整后，集群 Tablet 数量从 150万下降到了 50万，效果显著。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/2c/94/2caba2f5bc68225e374bb55435f13e94.png\" /></p><p></p><p>优化前的 FE</p><p></p><p>下图是 FE JVM Heap Stat 的监控情况，每当 FE 执行 Checkpoint 时，元数据就会在内存中复制一份。体现在 FE JVM Heap Stat 上就是形成一个个的波峰。优化之前 FE 对内存占用几乎持续在 90% 以上，而且每一个波峰都非常的尖锐。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/1d/f0/1d0bfaa5fec7c4ac53f5a0efd169f5f0.png\" /></p><p></p><p>优化后的 FE</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/10/55/10a3c6f098f1aa86aba122a0313c7855.png\" /></p><p></p><p>优化后，FE 堆内存占用明显下降，波峰也变得很平缓。FE 的稳定性得到了比较明显的提升。</p><p></p><p>优化前、后的 BE</p><p></p><p>BE Compaction Score 监控反映版本的堆积情况，版本堆积的数值在 100 内属于正常范围，超过 100 说明集群可能存在潜在风险。上文也讲到，查询时需要先进行文件合并，再进行数据查询，如果 Tablet 版本过多，版本合并会影响到查询的速度和稳定性。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/69/10/69b7ae29138c6cf8aa5d67c0d974b710.png\" /></p><p></p><p>经过磁盘的部署优化和 Tablet 优化后，BE Compaction Score 可以稳定在 50 以内，查询的稳定性和性能都得到了非常大的提升。</p><p></p><h4>数据同步优化</h4><p></p><p></p><p>优化前：</p><p></p><p>MySQL 数据同步使用 Flink CDC -&gt; Kafka -&gt; Flink Doris Connector -&gt; Doris 的方式全量 + 增量进入  Apache Doris。</p><p></p><p>在这个方案中，虽然 Flink CDC 支持全量历史数据的初始化，但由于历史遗留问题，部分表数据量较大，单表有几亿数据，而且这种表大多是没有设置任何分区和索引，在执行简单的 COUNT 查询时都需要花费十几分钟的时间。</p><p></p><p>其次，Flink CDC 虽然可以进行增量数据同步，但对于这类表的全量数据初始化几乎是不能实现的，因为 Flink CDC 做全量同步要先读取全量数据，然后对数据分块，再做数据同步，这种情况下，读取是非常非常缓慢的。</p><p></p><p>优化后</p><p></p><p>针对这种情况，在数据同步上，我们做了以下优化：</p><p></p><p>全量同步使用 MySQL Dump -&gt; CSV -&gt; Doris Stream Load -&gt; Doris</p><p></p><p>增量同步使用 Flink CDC -&gt; Kafka -&gt; Flink Doris Connector -&gt; Doris</p><p></p><h4>数据调度优化</h4><p></p><p></p><p>我们在使用 DolphinScheduler 进行 Doris SQL 的任务调度时，同一 node 下配置多条 SQL 时会出现 node 执行状态异常的情况，导致工作流 DAG 的 node 依赖失效，前一个节点未执行完，后一个节点就开始执行，结果会有缺数据甚至没有数据的情况。这个问题是因为 DolphinScheduler 2.x 在同一个 node 下不支持按顺序执行 MySQL 的多段 SQL，而 Doris 在 DolphinScheduler 中使用 MySQL 数据源创建连接。</p><p></p><p>此问题在 DolphinScheduler 3.0.0 版本被修复，配置中可以设置多段 SQL 的分隔符，解决了 DAG 依赖关系失效的问题。</p><p></p><h2>Apache Doris 元数据管理和数据血缘实现方案</h2><p></p><p></p><p>在没有元数据管理和数据血缘之前，我们经常会遇到一些问题，比如想找一个指标，却不知道指标在哪张表，只能找相关开发人员来确认，当然也存在开发人员忘记指标的位置和逻辑的情况。因此只能通过层层筛选确认，此过程十分耗费时间。</p><p></p><p>之前我们将表的分层划域、指标口径、负责人等信息放在 Excel 表中，这种维护方式很难保证其完整性，维护起来也比较困难。当需要对数仓进行优化时，无法确认哪些表是可以复用的、哪些表是可以合并的。当需要对表结构进行变更时，或者需要对指标的逻辑进行修改时，也无法确定变更是否会对下游的报表产生影响。</p><p></p><p>在以上问题背景下，我们经常遭到用户的投诉，接下来介绍如何通过元数据管理和数据血缘分析方案来解决这些问题。</p><p></p><h4>实现方案</h4><p></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/fb/3d/fbyy5a082cca3feec875c7f12d1f6d3d.png\" /></p><p></p><p>元数据管理和数据血缘是围绕 Apache Doris 展开，同时对 DolphinScheduler 的元数据进行了整合。</p><p></p><p>我们将元数据分为物理元数据和业务元数据两大类：</p><p></p><p>物理元数据维护表的属性信息和调度信息业务元数据维护数据在应用过程中约定的口径和规范信息</p><p></p><p>数据血缘实现了表级血缘和字段级血缘：</p><p></p><p>表级血缘支持粗粒度表关系和跨层引用分析字段级血缘支持细粒度的影响分析</p><p></p><p>上图中，右侧表格是物理元数据业务，元数据指标和血缘分析能够提供的数据服务。</p><p></p><p>接下来，一起看下元数据管理和数据血缘的架构和工作原理。</p><p></p><p>架构介绍</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/d4/4c/d45982730843ecfc0eed53a45c72634c.png\" /></p><p></p><p>元数据管理和数据血缘实现方案技术栈</p><p></p><p>数据采集：使用 Apache Doris 提供的审计日志插件 Doris Audit Plugin 进行数据采集</p><p></p><p>数据存储：对审计日志插件做了定制化开发，使用 Kafka 存储 Doris 审计日志数据</p><p></p><p>血缘解析：使用 Druid 进行 Doris SQL 解析</p><p></p><p>血缘关系存储：使用 Nebula Graph 存储血缘关系数据</p><p></p><p>业务元数据：因为业务元数据经常发生 CRUD，因此使用 MySQL存储业务元数据信息</p><p></p><p>搜索数据：使用 ElasticSearch 存储血缘关系查询索引以及表和字段的搜索索引数据</p><p></p><p>接下来介绍一下个架构四个组成部分：审计日志的采集和清洗服务、血缘解析服务、元数据信息整合服务、应用接口服务。</p><p></p><p>Apache Doris 审计日志的采集/清洗服务</p><p></p><p>考虑到如果将数据清洗逻辑放在审计日志插件中，当数据清洗逻辑发生变更，可能会出现数据遗漏，这样会对血缘分析和元数据管理产生影响，所以我们将审计日志插件数据采集和数据清洗进行了解耦，对 Apache Doris 的审计日志插件进行了改造，改造后审计日志插件可以实现审计日志数据的格式化以及将数据发送到 Kafka 的功能。</p><p></p><p>数据清洗服务，首先在清洗逻辑中增加数据重排逻辑，针对多个审计日志插件发送的数据进行重新排序，解决数据乱序的问题。其次把非标准 SQL 转化成标准 SQL，虽然  Apache Doris 支持 MySQL 协议以及标准 SQL 语法，但有一些建表语句、SQL 查询语法与标准 SQL 存在一定差异，因此将非标准 SQL 转化为 MySQL 的标准语句，最后将数据发送到 ES 和 Kafka 中。</p><p></p><p>血缘解析服务</p><p></p><p>血缘解析服务使用 Druid 进行 Doris SQL 的解析，通过 Druid 抽象语法树逐层递归获取表和字段的血缘关系，最后将血缘关系数据封装发送到图数据库、血缘查询索引发送到 ES 。进行血缘解析的同时会将物理元数据和业务元数据发送到对应存储位置。</p><p></p><p>元数据信息整合服务</p><p></p><p>元数据信息整合服务借鉴了 Metacat 的架构实现方案。</p><p></p><p>Connector Manager 负责创建 Apache Doris 和 DolphinScheduler 的元数据链接，同时也支持后续其他类型数据源接入的扩展。</p><p></p><p>Meta Service 负责元数据信息获取的具体实现。Apache Doris 元数据信息主要从 information Schema 库、Restful API、以及 SHOW SQL 的查询结果三种途径来获取。DolphinScheduler 的工作流元数据信息和调度记录信息从 DolphinScheduler 元数据库获取。</p><p></p><p>应用接口服务</p><p></p><p>我们提供了3种类型的应用接口服务，分别是血缘应用接口服务、元数据应用接口服务和数据行为分析应用接口服务。</p><p></p><p>血缘应用接口服务提供表、字段、血缘关系、影响分析的查询服务。元数据应用接口服务提供元数据的查询和字段搜索的服务。数据行为分析应用接口服务提供表结构变更记录、数据读写记录、产出信息的查询服务。</p><p></p><p>以上就是元数据管理和数据血缘分析架构的整体方案的全部内容介绍。</p><p></p><h2>总结及收益</h2><p></p><p></p><p>今年我们完成了以 Apache Doris 为核心的准实时数仓建设，Apache Doris 经过半年的使用和优化，现在已经趋于稳定，能够满足我们生产的要求。</p><p></p><p>新的准实时数仓，对数据计算效率、数据时效的提升是巨大的。</p><p></p><p>以 On Time Delivery 业务场景报表计算为例，计算 1000w 单轨迹节点时效变化，使用 Apache Doris 之前需要计算 2 个多小时，并且计算消耗的资源非常大，只能在空闲时段进行错峰计算；使用 Apache Doris 之后，只需要 3min 就可以完成计算，之前每周更新一次的全链路物流时效报表，现在可以做到每 10 分钟更新最新的数据，达到了准实时的数据时效。</p><p></p><p>得益于 Apache Doris 的标准化 SQL，上手难度小，学习成本低，报表的迁移工作全员都可以参与。</p><p></p><p>原来报表使用 PowerBI 进行开发，需要对 PowerBI 有非常深入的了解，学习成本很高，开发周期也很长，而且 PowerBI 不使用标准 SQL，代码可读性差；现在基于 Doris SQL 加上自研的拖拉拽形式的报表平台，报表的开发成本直线下降，大部分需求的开发周期从周下降到了天。</p><p></p><h2>未来规划</h2><p></p><p></p><p>后续我们也将继续推进基于 Apache Doris 的数据中台建设，对元数据管理的完善、数据血缘的解析率持续进行优化，考虑到数据血缘是大家都渴望的应用，在未来血缘解析成熟后，我们会考虑将其贡献给社区。</p><p></p><p>与此同时，我们正在着手进行用户行为分析平台的构建，也在考虑使用 Apache Doris 作为核心的存储和计算引擎。目前 Apache Doris 在部分分析场景支持的函数还不够丰富，例如在有序窗口漏斗分析场景，虽然 Apache Doris 已经支持了 window_funnel 函数，但是每层漏斗转化的计算需要用到的 Array 相关计算函数还没有得到很好的支持。不过好在即将发布的 Apache Doris 1.2 版本将包含了 Array 类型以及相关函数，相信未来在越来越多的分析场景中 Apache Doris 都将得到落地。</p><p></p><h4>作者介绍</h4><p></p><p></p><p>付帅，橙联（中国）有限公司数字化团队，大数据研发经理，负责数字化团队数据中台的研发以及 OLAP 引擎的应用落地及性能优化。</p>",
    "publish_time": "2022-09-27 14:59:19",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "十问分布式数据库：技术趋势、选型及标准思考",
    "url": "https://www.infoq.cn/article/lqSvRZ7AB3NtjYpH79Rk",
    "summary": "<p>嘉宾 ｜李卫、王南、杨建荣、刘博</p><p></p><p>编辑 ｜赵钰莹</p><p></p><p>随着信息技术的迅猛发展，各行各业产生的数据量呈爆炸式增长，传统集中式数据库的局限性在面对大规模数据处理中逐渐显露，从而分布式数据库应运而生。分布式数据库是在集中式数据库的基础上发展起来的，是分布式系统与传统数据库技术结合的产物，具有透明性、数据冗余性、易于扩展性等特点，还具 备高可靠、高可用、低成本等方面的优势，能够突破传统数据库的瓶颈。</p><p></p><p><a href=\"https://qcon.infoq.cn/2022/beijing/track/1306\">分布式数据库</a>\"目前已应用到金融、电信等大数据行业，未来将走向更广阔的领域。本期<a href=\"https://www.infoq.cn/video/aFGc1l02v39SsT1XSEAU\">“数据库 Talk Show”圆桌直播</a>\"邀请到了国家工业安全发展研究中心软件所副所长李卫，OceanBase 产品和解决方案部高级总监王南，dbaplus 社群联合发起人、OracleACE、竞技世界资深 DBA 杨建荣，携程数据库总监刘博。几位专家围绕分布式数据库技术路线和产业现状，分析分布式数据库的技术特点以及面临的问题与挑战，对企业如何进行数据库选型互动讨论。</p><p></p><h4>InfoQ 第一问：我国分布式数据库的产业现状如何？</h4><p></p><p></p><p>李卫：最近几年，分布式数据库在国内发展较快。一方面，丰富的数据库应用场景，新一代信息技术与实体经济的深度融合，各行各业的数字化转型，社会全面进入数字经济时代，这些变化都给数据处理和存储的主要核心技术带来了非常好的发展机遇，尤其是随着数据规模的增加，数据使用复杂程度的提升，原有的集中式数据库已经渐渐不能满足现在很多场景的需要，分布式数据库成为很多企业必然的选择。另一方面，分布式数据库因为发展时间不是很长，落地实践层面还存在不足。</p><p></p><p>目前来说，国内主要有三种技术路线可供选择：一是分布式中间件 + 单机数据库，通过在单机数据库系统上进行改造，主要解决了扩展性的问题；二是构建分布式共享存储实现扩展，采用非对称计算节点，大部分公有云数据库是这条路线；三是原生分布式数据库，从底层设计就采用分布式架构，是未来很重要的趋势。</p><p></p><p>当下，国内从事分布式数据库的厂商非常多，这三种技术路线各自存在应用场景，未来随着应用更广泛的深入和推广，路线还会进一步收敛，肯定会向着第三种路线推进。整体来说，国内的环境和技术需求还是给分布式数据库带来了非常好的机会，甚至未来在分布式数据库领域，国内在世界上处于引领地位。</p><p></p><p>杨建荣：早期，分布式数据库对业务的侵入性比较高，可能需要将一个业务拆分成多个业务模式，而后逐步演进到相对一体化的模式，出现了分布式中间件这种架构模式，如今又出现了越来越多的原生分布式数据库，技术体系上发生了很大变化，也面临着更多技术挑战，包括技术生态构建以及技术体系迭代层面。</p><p></p><p>王南：如果从数据库厂商和用户，也就是供给端和消费端的角度来讲，分布式数据库的发展两端并不同步。从数据库厂商的角度来说，分布式数据库已经走了很长时间，但用户对分布式数据库的认知、接受、使用及运维是有滞后的，当然这是一项技术或者产品发展的正常过程。随着数字经济的飞速发展，用户对分布式的诉求将越来越强烈，数据库厂商还需要在产品成熟化、产品能力、技术体系的完整易用以及生态建设层面花费更多时间。</p><p></p><p>刘博：技术的发展最终还是业务驱动的。以携程为例，如今的数据量与 2003 年刚上市时相比增长了上百倍甚至上千倍。携程 2018 年就开始尝试分布式数据库，发展路线也从最初的非核心业务逐渐过渡到核心业务。在过渡到核心业务时，我们也做了一些备份手段，比如数据双写等。根据 2019 年的数据统计，国内创业的数据库厂商有 160 多家，数据库产品可能有两百多个，其中分布式产品大概占 40%，处于野蛮生长的阶段。但根据 IDC 的调查，目前真正在核心系统中部署分布式数据库的比例不是太高。</p><p></p><h4>InfoQ 第二问：分布式数据库最核心解决的问题到底是什么？</h4><p></p><p></p><p>李卫：第一，分布式数据库解决了传统集中式单机数据库时期的问题，单机数据库面对海量数据在处理能力、存储能力、性能等方面都存在瓶颈；第二，分布式数据库需要解决数据一致性的问题，数据跨的节点越多，风险就越高；第三，分布式数据库的高可用能力保证不会因为单点故障而影响整体的可用性，这保障了金融、电信等对高可用需求较高业务的连续性；第四，应用存在波峰波谷，分布式数据库通过灵活扩展的设计做到了成本优化。</p><p></p><p>杨建荣：随着互联网场景快速增长的数据量，我们需要数据库系统支持水平扩展，这种支持可能是两个方面：数据存储和数据计算。在这个层面上来说，更多的是让数据存储实现水平扩展。实现此的前提则是保证整个分布式数据库的性能、可靠性等有更好的表现。从我实际接触的场景来看，更侧重于解决水平扩展的问题，让扩展方式更优雅。</p><p></p><p>王南：首先，分布式数据库的本质还是数据库，所以也会具备传统数据库的关键特征；其次，分布式数据库需要解决的核心问题之一是扩展，解决研发团队按需扩容、不需要按照业务波峰额外准备硬件资源的问题；然后是高可用问题，集中式数据库的系统可用性很大程度构建在可靠硬件的基础上，分布式架构将高可用问题转变为软件解决；最后在上述问题基础上，如何低成本地将现有应用平滑迁移至分布式数据库，整个过程需要一些方法论。</p><p></p><p>相较于其他原生分布式数据库，OceanBase 立足于 TP 领域，不断强化 AP 能力，去走向更全面的场景，这是一个关键的立足点，也是我们坚持的设计理念，尽量把复杂性从用户侧向数据库侧转移，对外呈现的是 OceanBase 对用户的应用兼容，包括语法、语义以及存储过程等高级能力的兼容，让用户快速、透明迁移到 OceanBase 。</p><p></p><p>刘博：从定义来看，分布式数据库首要解决区域间数据的一致性，映射到互联网行业主要是如下两点：一是分布式数据库内置 HA 功能，以携程为例，过去主要采用商业数据库结合存储的模式，靠高端硬件解决 HA 问题，后来这套架构逐渐在主流互联网公司中消失，取而代之的是一些 MySQL 的高可用方案，但这与分布式原生数据库提供的能力差别很大，切换时的中断是业务可以感知到的，分布式数据库本身就可以提供多机房或者异地机房等部署方式，提升了高可用性及数据安全性，切换过程可以做到业务无感知，携程已经将 OceanBase 部署在了生产环境，采用了同城三机房的部署方式，可以抵御同城单机房的故障，且三个机房对等，业务可就近访问，故障时的切换不再需要人工参与，免去了复杂的切换逻辑和人工操作流程。</p><p></p><p>二是横向扩展问题，虽然携程的业务峰值可能不如几大主流电商平台大促期间那么高，但也是存在明显的波峰波谷，例如暑假和春运火车票抢票。类似 K8s 这样的技术已经很好地弥补了应用的弹性诉求，但数据库层面的弹性一直是欠缺的，分布式数据库提供的动态伸缩功能，解决了数据库层的弹性问题。</p><p></p><h4>InfoQ 第三问：用户如何判断哪种技术路线更适合自己？</h4><p></p><p></p><p>李卫：当前这个阶段，我觉得三种路线都存在现实需求，现实需求导致每个应用方要根据自己的业务特点和现实的资源环境决定采用哪种路线，每一种路线都有优势和劣势。分布式中间件路线最大的劣势是代码层级的改造量很大，因为中间加了一层分布式中间件；分布式存储依赖于存储的扩展，在扩展能力上存在局限，尤其是跨地域等较长距离的扩展难度比较大，优势是代码几乎不需要改造；原生分布式的未来趋势非常明显，但因为发展时间相对较短，相较于前两者在稳定性、生态等层面还存在短板，企业需要结合自己的业务进行抉择。</p><p></p><p>杨建荣：我提炼了六个维度对技术栈进行对比：</p><p></p><p>事务管理，相对传统模式，原生数据库的事务管理有天然的优越性，因为业务都在一起。中间件的模式可能会放大事务风险或者隐患，原生模式因为是全新的体系，在事务管理层面有较大差异。发展周期，原生分布式数据库的周期相对来说更短一些，也是这些年非常流行的。中间件的模式，尤其银行等企业，早期在方向上的沉淀，包括这样的落地场景也会更多一点。迁移升级，原生模式的迁移相对平滑，其他模式还需要配合做一些架构设计和拓扑扩展。高可用。原生模式依赖云平台的能力在高可用层面具备天然优势，但其他模式依赖底层的标准化模式会有一些短板。扩缩容，中间件的模式是一个域定义的模式，在做 N+1 的扩展上存在诸多限制，云原生分布式数据库相对来说更加弹性和灵活。性能。云原生分布式数据库推出早期也经历了大量验证，与其他模式相比，可能会有更多的成本消耗，但性能也有比较大的提升。</p><p></p><p>王南：我从场景的角度来聊，首先是中间件方案，当集中式数据库无法满足诉求，大家很自然地选择用分库分表的方式解决问题，将流量负载均衡到每个节点，该方案适用一些特定场景，比如对跨节点的分布式事务和一致性没有强诉求，但也有很多问题无法解决，比如支付类场景或者其他需要跨节点事务的场景。</p><p></p><p>其次是分布式共享存储，不同场景的存储和计算负载要求不同，很可能存在扩展出来的计算和存储资源有一个被浪费掉，该方案的存在很好地解决了这一问题，并且可以充分协同和发挥云存储的优势，这也是公有云厂商积极推动该方案的原因，厂商在公有云存储基础上做了一层封装，可以提供不同类型、不同成本和价格的云存储方案，这种方案需要用户考虑的因素较多，比如数据库架构设计层面如何与这种模式更好地融合。</p><p></p><p>最后是云原生分布式数据库方案，这对用户来讲是最简单的，因为对用户而言，其与集中式数据库的使用体验没有差异，数据分布、负载均衡以及故障自动恢复等数据库都可以搞定，还免去了集中式场景下理解、学习及对应用改造的成本，但是产品成熟度以及当前积累的场景实践案例是否可以很好地解决问题是企业比较担心的，用户可以场景的不同来选择更合适的方案。</p><p></p><p>刘博：三种路线与时代发展有很强的关系。第一种中间件的方式对代码侵入性比较强，需要在单机版数据库的基础上增加分片规则，以携程为例，可以从用户的维度进行分片，但有些数据无法找到合适的分片规则，例如：酒店信息很难找到合适的维度，如果以城市为维度划分，一线城市的酒店资源和三四线城市的酒店资源无法对等分片，这是该种方式的局限性。该方式的好处是运维相对简单，没有引入新技术给基础运维带来负担，但压力就给到了业务侧，代码需要做较大的改造。</p><p></p><p>第二种是公有云厂商提供的方式，好处是存储资源基本做到无限扩充，用户按量付费即可，缺点是计算资源有限，如果业务没有明显的读写分离场景，写的计算节点资源受限于公有云的计算规格，这种路径更适合读的场景偏多的业务。</p><p></p><p>第三种，从技术、架构层面来说是目前最好的选择，且对业务没有侵入性，扩缩容都比较弹性，但目前观察到的落地案例还不是特别多，我们比较期待这种方式更加成熟，因为对业务比较友好。</p><p></p><h4>InfoQ 第四问：为什么在近些年分布式数据库逐渐成为主流的商业数据库选择？</h4><p></p><p></p><p>李卫：一是上文提到的用户需求的改变催生了分布式数据库的发展；二是数字经济时代，数据成为了最核心的生产要素，要想发挥数据价值，底层的核心技术运用也非常关键。如今的很多企业都在做数字化转型，技术架构从集中式向分布式转化，分布式数据库的支持效果显然更好。</p><p></p><p>杨建荣：我主要从四个方面回答该问题：</p><p></p><p>分布式数据库相较商业数据库发展更快主要得益于其他解决方案更耗成本，通过更高配的硬件或者高端存储解决问题长期来看，成本是不容忽视的一个因素。从使用体验来看，分布式数据库可以让整个过程更加平滑。从研发模式来看，历史债务较多的企业迁移到分布式是一个很大瓶颈。传统的研发模式与当前越来越轻量化的方式是不相符的，分布式数据库在这个方向上是可以做到相辅相成的。性能，并不是说这种模式的性能一定比单机要好，但具有更强的扩展性，可以通过分布式平滑实现倍数的性能提升。技术生态，国内的分布式数据库厂商提供了完善的工具、文档包括配套的迁移工具，可以帮助企业实现无感迁移。</p><p></p><p>王南：这个话题的争议度在几年前还是比较大的，包括分布式是否是正确的方向都有比较大的争议，当然这几年好很多了。大家对分布式的接受度和诉求越来越强，但不代表已经成为主流，国内外也是有差异的，因此我不会轻易对这件事情下结论，但任何技术的发展都是需求驱动的，没有普遍需求，这个观点肯定是不成立的。</p><p></p><p>不论是市场占有率还是用户接受度来说，分布式数据库目前距离主流肯定还有差距，但越来越多的场景对分布式是有强烈诉求的。在云化的大趋势下，我们相信这会是未来的主流方向之一。</p><p></p><p>刘博：目前业内很多创业公司和新型的数据库产品都是以分布式的形态出现，这可以理解为时代的产物。从市场需求来看，业务的增长速度更快，对计算和存储资源的要求更高。携程的发展过程经历了单机数据库、单机数据库加高端硬件、分库分表（前文提到的第一种中间件的方式）时代，虽然分库分表模式表面看起来没有增加新的技术，但运维复杂度升高很多，因为分库分表后，DB 规模和表规模越来越大。</p><p></p><p>分布式的引入对业务更加友好，以维护窗口为例，原来凌晨三四点的时候，业务量很低，可以在这个窗口进行维护升级，如今的携程业务逐步国际化，很难找到维护窗口，需要在不需要宕机的情况下进行维护升级，这也是携程自 2018 年开始使用分布式数据库解决的问题之一。原来需要熬到凌晨三四点才可以做的维护，现在可以选择白天任何一个业务低峰时段进行，这也算是分布式的红利之一。</p><p></p><h4>InfoQ 第五问：分布式数据库有哪些安全方案可以聊一聊？</h4><p></p><p></p><p>王南：从安全角度来看，我想到了几个方面：一是分布式数据库与集中式数据库场景下的安全体系基本能力，如用户决策权限是一样的，这些依然存在很强的诉求；二是分布式可能会带来更多挑战，毕竟涉及多节点及更复杂的底层基础设施，OceanBase 目前可以同时物理机、虚拟化、私有云和公有云四种部署方式，未来也会支持多云。除传统的安全手段之外，分布式数据库可能会需要解决数据全链路的安全、数据存储加密等问题，目前也会通过云平台提供一些加解密的方式，安全不是一蹴而就的，未来会逐渐将这些产品能力补齐。</p><p></p><p>刘博：作为一款商业产品来说，OceanBase 也会遵循国际通用的安全标准，用户可以从三个维度来看待安全问题：存储、审计和传输。比如 OceanBase 可以开启 SSL 功能，实现客户端和服务器之间数据的安全传输。也可以开启透明加密，实现存储的加密。OceanBase 提供的审计表，记录了所有的 SQL 访问。这里提一下，携程根据审计表做了一些功能开发，我们将审计表中的数据全部抽取出来，做了 SQL 的实时分析，用于访问异常检测和性能分析。</p><p></p><h4>InfoQ 第六问：在国内，HTAP 被很多人提及，海外更多是 OLTP 或 OLAP，那么真正的 HTAP 到底是怎样的？</h4><p></p><p></p><p>李卫：HTAP 这两年的讨论热度较高，当企业内部对 TP 和 AP 同时有需求的时候，结合肯定是性价比最高的方式，否则面临着人力、资源等各方面的浪费，至少目前来看这种方式是存在实际需求的，但需要与场景相结合。</p><p></p><p>杨建荣：从存储角度来看，AP 本身的存储会占用一部分成本，这需要从成本层面做出取舍，无论是底层压缩还是针对性的热点数据，尽量在不影响原有 TP 业务的情况下让业务更加平滑。</p><p></p><p>从计算层面来说，可以做扩展或者说插件模式，整个的 AP 计算不是放在一个大池子里，还是需要做出一些取舍。长远来看，HTAP 的方式可以解决大部分诉求，但肯定有一些更专业的方向或者更长历史周期的数据需要专门的 OLAP 实现。</p><p></p><p>王南：HTAP 严格来说并没有特别明确的定义，这是 Gartner 首次提出的概念，大家的理解或许有所差异。目前有一类实现方式是同一个产品部署 AP 和 TP 系统，虽然是两个系统，但是同一个产品解决了两类场景问题。这就进一步分化为两套引擎（一套处理 TP，一套处理 AP）和一套引擎（既可以处理 AP，又可以处理 TP）两种方式。</p><p></p><p>如果回到用户的原始诉求上来，HTAP 对用户来讲就是既要解决业务交易负载，也要解决复杂查询、报批、报表这样分析类负载问题，无非是用一个系统还是建两个系统来跑的问题。数据量较小的情况下，Oracle 或许就可以；数据量较大的情况下，目前普遍选择通过两套系统来解决问题。随着分布式的发展，这个问题又出现了新的解决方案，OceanBase 目前的路线是一个系统、一套引擎可以同时解决 TP 和 AP 两类问题，包括数据存储层面的优化，我们正在尝试运行几十 TB 量级 TPC-DS 的负载，希望通过技术手段解决这个问题。</p><p></p><p>刘博：在实际的场景中，TP 和 AP 的边界可能没有那么清晰，很多业务的响应可能是 TP 级的，资源消耗又是 AP 级的，这个边界越来越模糊，我们很难定义。而且国内的生态基本还是基于 Hadoop 的生态来构建的 AP 系统，这就有可能出现数据延迟、数据重复存储、运维成本上升（需要两个团队各自运维两个系统）等问题，HTAP 可以很好地解决这些问题。</p><p></p><h4>InfoQ 第七问：Hadoop 等于 HDFS 和 MapReduce，分布式数据库里边的 MapReduce 可能是什么样子？</h4><p></p><p></p><p>王南：这可能还不太一样。OceanBase 将问题拆分为不同的维度：分布式的问题、计算模型的问题和存储的问题。OceanBase 之所以选择用一个存储引擎来解决问题，主要是充分利用了闪存等硬件 + 新架构来解决海量数据的并发更新问题。虽然从概念上来看，分布式和存储是两层，但实际是放在一起解决的，通过分布式的协议解决节点间的数据复制和存储问题，同时保证数据强一致性和多核高可用。只要做好优化器和语法层，计算引擎和模型是可以比较快速地满足业务诉求的。在不同的层次解决不同的问题，存储层解决效率问题，分布式解决高可用和扩展问题，计算层解决并行、兼容性和生态问题。</p><p></p><h4>InfoQ 第八问：分布式数据库的学习门槛如何？</h4><p></p><p></p><p>刘博：学习成本可能分两个层面：语法层面常用的 SQL 语句都是兼容的，在 OceanBase 的测试中，携程仅发现了极个别无法支持的语句，也是使用频度较低的；运维层面复杂度确实高出几个数量级，因为数据访问涉及的路径变多了。当然，学习途径也变多了，社区有文档、视频等很多资料都可以翻阅。数据库学习最重要的是需要实操，先把 OceanBase 的开源版本运行起来看看，自行编译看看。</p><p></p><h4>InfoQ 第九问：分布式数据库选型可以从哪几个方面进行考虑？</h4><p></p><p></p><p>李卫：分布式数据库选型需要与业务场景相结合。在国内，金融、电信等领域已经在分布式数据库层面有了大量实践。我们从上述两大行业抽离出了一些与数据库高度相关的系统，比如计费系统、客户系统等，经过试验证明分布式数据库确实已经能够很好地支撑起相关业务的运行，但与老牌商用数据库的能力相比还存在差距，此外还需要关注未来的持续稳定运行能力。</p><p></p><p>杨建荣：数据库选型的这个问题可以通过 BATD 模型来看。其中，B 指的是业务驱动；A 指的是架构演进的视角看待技术选型，比如中间件就是这样一种技术；T 指的是技术生态，是否在某些场景中有足够的沉淀；D 指的是多元化，数据库选型不要做大一统，而是更多考虑多元化，从技术栈演进的层面做出取舍。</p><p></p><p>王南：用户对数据库选型是最有发言权，从我们这些年来和众多已经上线核心业务的客户在选型关心维度的反馈上，用户期望在满足以下基本要求再去谈产品的各种特性：</p><p></p><p>首先，数据是企业的核心命脉，不管选择什么样的数据库，保障数据不丢、不错、不乱是最基本的要求。</p><p></p><p>其次，如果选择分布式架构的数据库，如何确保永远可信任的数据一致性，包括集群和集群之间、副本和副本之间，分区和分区之间，索引和索引之间甚至是宏块和宏块之间的数据一致性链式校验，从而防止因磁盘静默错误或者因为硬件故障导致的数据不一致。</p><p></p><p>再次，是否能够对于异构芯片、操作系统等可以实现混合部署、灰度部署，形成逃生机制，确保在数据库改造升级时实现业务逃生。</p><p></p><p>然后，是否支持 DB-Mesh 的数据中心的部署和建设以满足业务的弹性，可以实现单元化、云原生、全密态的部署。</p><p></p><p>最后，有专业的团队和支撑可以兜底。</p><p></p><p>基于上述的基本要求，从功能上可以归纳为四大方向：</p><p></p><p>第一个也是最主要的，刚性能力和指标满足度，这可能涉及到很多问题，包括性能、功能、安全、可靠，兼容、资质等，这是最基础的。</p><p></p><p>第二个是产品成熟度，是否已经在足够多的不同行业进行了落地实践，在不同的用户量、不同的业务负载下进行了验证，产品是否只有一个内核，还是上下游产品生态兼具。</p><p></p><p>第三个是数据库的厂商，也就是背后团队的技术能力，以及这家公司对数据库战略的定力和稳定性，也是影响巨大的，特别是对于中大型企业而言，这关系到系统后续是否可以稳定持续运行。</p><p></p><p>第四个是成本和性价比，这不仅仅是表面的价格，还包括稳定性的成本、迁移成本、服务成本、运维成本等各方面，甚至有些用户考虑一旦出现问题，兜底方案的成本有多大。</p><p></p><p>从市场来看，如今的数据库市场确实是百花齐放，好处是提供了更多样化的能力，避免被单一供应商绑定；坏处是选择的成本很高，也可能出现重复造轮子的现象。这就需要行业监管和标准化组织的引导，让行业健康发展。</p><p></p><p>刘博：我也同意三位老师关于选型肯定需要与场景结合的看法。携程在选择分布式数据库时主要考虑了功能完备度、与现有数据库的兼容性以及性能和支持等方面。OceanBase 目前也有社区版本，我们可能也会考虑社区的 star 数量、PR 数量、issue 数量等。</p><p></p><h4>InfoQ 第十问：分布式数据库的迁移过程中应该注意哪些问题？</h4><p></p><p></p><p>刘博：迁移可能需要考虑是否平滑、兼容性和性能等。我们之前针对 OceanBase 做过一些测试，比如同样的语句在 MySQL 和 OceanBase 上等比例放上，看两边的响应程度等，也包括一些兼容性测试。</p><p></p><p>此外，企业还需要考虑迁移过程的稳定性，对新的数据库是否具备足够的掌控力，一旦发生问题，是否有回退方案。以 OceanBase 为例，我们通过 OceanBase 自身提供的 OMS 功能，搭了一条反向链路到 MySQL，一旦遇到紧急情况，可以平滑再切到 MySQL。</p><p></p><p>王南：从横向来看，可以分为迁移前、迁移中和迁移后三个阶段。事前，我们提供了 OMA 这样的工具，可以对业务负载进行分析，包括可视化的报表告知用户兼容程度、建议使用的迁移方案和可能存在的风险。</p><p></p><p>事中，提供一个工具完成整个自动化迁移过程，这个后面详细展开。</p><p></p><p>事后，需要检验迁移是否真的完成以及数据是否一致，这也不意味着万事大吉了，还需要准备一些预案以应对运行后可能的突发情况。</p><p></p><p>从纵向的角度来看也就是上述提到的事中阶段，这里面有几个核心问题需要考虑：一是原数据如何迁移，假设兼容度极高，各种高级能力都可以直接运用，这是比较省心的。假设兼容度不高，这可能需要大量的手工 SQL 转换，甚至需要进行应用层的改写，成本极高，OceanBase 本身的 OMS 中提供了大量工具可供选择，比如静态的全量数据迁移、增量的数据迁移，自定义过滤条件，甚至一些算子转换等。</p><p></p><p>此外，对于丰富的数据源和目标端的支持，因为数据迁移不仅仅是从原来的集中式数据库迁移到分布式数据库，不同的用户可能会有不同的诉求，比如对一些流、缓存进行迁移等，这需要云端支持的目标类型足够丰富。</p><p></p><p>杨建荣：我在上述两位的回答上补充一些细节，迁移过程中常用的一种方式是双写，通过这种模式验证，相对来说整个迁移过程更平滑可控。另外，我们可能会在一些场景做数据同步，比如 A 到 B 的切换过程持续做数据同步，需要不断地考虑数据的一些基础训练，包括 SQL 回放、性能验证等。当然，从整个切换模式来说，业务方几乎是无感知或者闪断。</p><p></p><h4>活动推荐</h4><p></p><p></p><p>QCon北京站的<a href=\"https://qcon.infoq.cn/2022/beijing/track/1306\">【分布式数据库】</a>\"专场集结了众多专家围绕未来云数据库的架构设计、开发方式以及部署维护等各个阶段和方面进行探讨，从数据库的角度为你带来最新的行业趋势以及技术趋势。</p>",
    "publish_time": "2022-09-27 15:12:11",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AI帮了大忙！原先10万个方程式才能解决的量子物理问题，现在只需要4个就搞定",
    "url": "https://www.infoq.cn/article/1fSW66E3YPawWiqQN1ay",
    "summary": "<p>近日，物理学家们借助<a href=\"https://archsummit.infoq.cn/2022/hangzhou/track/1280\"> AI </a>\"将一个需要 10 万个方程才能解决的量子问题压缩到了一个只有四个方程的小任务中，且结果依然是准确的。</p><p></p><p>这项工作发表在 9 月 23 日的《物理评论快报》上，可能会颠覆科学家研究包含许多相互作用电子的系统的方式。此外，如果可扩展到其他问题上，该方法可能有助于设计出具有超导性或清洁能源发电效用等受欢迎特性的材料。</p><p></p><p>“我们从所有这些耦合在一起的微分方程的巨大对象开始研究；然后我们使用<a href=\"https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247575316&amp;idx=2&amp;sn=47fc879ba3add5db7064447b01172599&amp;chksm=fbeb1edbcc9c97cd13d2c81a98e95ab7e0dfa85b27d71bfa26dd517725db0ce8580b1a892026&amp;scene=27#wechat_redirect\">机器学习</a>\"将它变成小到可以用手指数得过来的东西，”研究的主要作者 Domenico Di Sante 说道。Domenico Di Sante 是一名访问研究纽约 Flatiron 研究所计算量子物理中心（CCQ）研究员，也是意大利博洛尼亚大学助理教授。</p><p></p><p>电子在网格状晶格上移动时的行为方式是令人头疼的物理问题之一。当两个电子占据相同的晶格位置时，它们会相互作用。这种被称为 <a href=\"https://en.wikipedia.org/wiki/Hubbard_model\">Hubbard model</a>\"（哈伯德模型）的设置是几种理想化的重要材料类别，有了这些材料类别，科学家们就能够了解电子行为如何产生珍贵的物质相，例如超导性，也就是电子能够在没有阻力的情况下流过材料的一种特性。在将新方法应用于更复杂的<a href=\"https://www.infoq.cn/article/HmppHMJseJVj7sZkR7Te\">量子系统</a>\"之前，该模型还可以作为新方法的“试验场”。</p><p></p><p>然而，哈伯德模型并不像看上去那么简单。即使是少量的电子和尖端的计算方法，这个问题也需要强大的计算能力。那是因为当电子相互作用时，它们就会变成量子力学纠缠：即使它们在不同的晶格位置相距很远，这两个电子也不能单独处理，因此物理学家必须同时处理所有电子，而不是一次处理一个电子。随着电子数的增多，就会出现更多的纠缠，使计算挑战成倍增加。</p><p></p><p>研究量子系统的一种方法是使用所谓的重正化群。这是物理学家用来观察系统行为（例如哈伯德模型）的一种数学仪器技术。具有挑战的是，一个能跟踪电子之间所有可能的耦合并且不牺牲任何东西的重正化组可能包含数万、数十万甚至数百万个需要求解的单个方程。更重要的是，每个方程式都很棘手：每个方程式代表一对相互作用的电子。</p><p></p><p>Di Sante 和他的同事想知道他们是否可以使用一种称为神经网络的机器学习工具来使重正化组更易于管理。神经网络就像一个疯狂的总机操作员和适者生存进化的交叉。首先，机器学习程序在全尺寸重整化组内创建连接。然后，神经网络调整这些连接的强度，直到找到一小组方程，这些方程生成的解与原始的超大尺寸重正化组相同。即使只有四个方程，该程序的输出也能捕捉到哈伯德模型的物理特性。</p><p></p><p>“它本质上是一台能够发现隐藏模式的机器，”Di Sante 说。“当我们看到结果时，我们说，‘哇，这超出了我们的预期。’ 我们真的能够捕捉到相关的物理现象。”</p><p></p><p>训练机器学习程序需要大量的计算能力，程序运行了整整几周。Di Sante 说，好消息是，现在他们的程序已经得到指导，他们可以调整它以解决其他问题，而无需从头开始。他和他的合作者也在研究机器学习实际上是在“学习”系统的什么，这可能会为物理学家们提供一些灵感，否则物理学家可能很难破译这些难题。</p><p></p><p>最终，最大的悬而未决的问题是，新方法在更复杂的量子系统上的效果如何还未可知。但 Di Sante 表示，在处理重正化群的其他领域中使用该技术也有令人兴奋的可能性，例如宇宙学和神经科学。</p><p></p><p>参考链接：</p><p>https://phys.org/news/2022-09-artificial-intelligence-equation-quantum-physics.html</p>",
    "publish_time": "2022-09-27 15:12:40",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Rust 正在「吞噬」我们的系统，C/C++ 是时候下课了",
    "url": "https://www.infoq.cn/article/eG4ify4PeuCtJ1yoP7tD",
    "summary": "<p></p><h2>C/C++是时候下课了，Rust 才是未来</h2><p></p><p>&nbsp;</p><p>Rust正快速渗透我们的系统。</p><p>&nbsp;</p><p>首个<a href=\"https://www.infoq.cn/article/a7HAfAis5U70O1vbxFg3\">Rust编写的驱动程序正入驻Linux</a>\"，微软Azure首席技术官Mark Russionvich也直言C/C++这对主流系统语言是时候下课了，Rust 才是未来的发展方向。</p><p>&nbsp;</p><p>但不少从业者仍然抱有反对意见。技术生态系统向来充斥着冲突与对抗，长久以来的编程语言战火已经不止一起。只不过这一回，战争的赌注比以往任何时候都更高。</p><p>&nbsp;</p><p>C++最初于1985年进入商业应用，也就是任天堂游戏机NES登陆美国的那一年。当时那些时髦前卫的年轻程序员，如今已成长为各家企业的高管和顶梁柱，而他们对于IT基础设施的认知往往也永远留在了过去那个年代。于是其中很多人成了<a href=\"https://qcon.infoq.cn/2022/beijing/track/1288\">Rust</a>\"的反对者，认为Rust能做的，<a href=\"https://www.infoq.cn/article/ScK8IZsfqecKY0axzRcJ\">C++</a>\"本来就能做，而且好的程序员根本就不需要在编程语言层面寻求额外帮助。</p><p>&nbsp;</p><p>没错，旧工具仍然有效，甚至能够满足大部分人的开发需求。再加上长期积累下来的技术惯性，导致如今市面上仍充斥着堪称“活化石”般的古老系统。法律和医疗行业仍在使用拉丁术语，宗教中的很多思维方式可以一路追溯到铁器时代，道理都是相同的。</p><p>&nbsp;</p><p>但很多事实已经向我们证明，诞生于过去的语言终将不足以描述这个新世界。所以接下来就看谁能更好地紧跟时代的脚步，于是旧的事物决定以新的形式进行重新“编译”，以更好地同当今世界相兼容。</p><p>&nbsp;</p><p></p><h2>C/C++把安全开关交给开发者，Rust：“放着我来”</h2><p></p><p>&nbsp;</p><p>而导致<a href=\"https://www.infoq.cn/article/Y9KJX5zaEXov90wK68JP\">C/C++</a>\"与现实世界无法兼容的巨变，就是无处不在的异构分布式计算。</p><p>&nbsp;</p><p>让我们放下手头的计算任务，看看上一代人和下一代人的计算应用场景。有多少任务在多少种操作系统实例上运行？这些代码部署在哪里？没错，大家马上会意识到大部分代码都驻留在共享环境当中，依靠某些底层技术实现沙箱/分区/隔离。</p><p>&nbsp;</p><p>遥想当年，对bug的修复只能依靠发布新版本，这种方式在如今这个时代可能立即影响到数百万人的隐私安全，或者在国家层级的卫生系统中给勒索软件留下可乘之机。在这个IDE键入内容会被快速转化为全局输出的高效时代，C/C++仍然把安全的开关交给每位开发者，而Rust则表示“放着我来”。</p><p>&nbsp;</p><p>没错，一些内核开发高手用不着<a href=\"https://qcon.infoq.cn/2022/beijing/track/1287\">编程语言</a>\"的协助，毕竟他们已经用这种方式工作了30年都没出什么大问题。但请记住，这个世界上的开发者不全是高手，还有很多有待成长、对安全细节懵懵懂懂的新人。Rust能在不影响性能的前提下降低风险，让更多人快速编写出<a href=\"https://www.infoq.cn/article/0bErNQNbOsdo7Xq3JgQS\">高质量代码</a>\"，这有什么不好的？</p><p>&nbsp;</p><p>当然，Rust并不是万金油，它只是更理解数据在现代环境中可能受到哪些意外疏忽的影响，而且知道如何在编译时以不牺牲性能的方式强制执行安全保护。这只是把起点设置得更完善，绝不是要限制开发者们的奇思妙想。</p><p>&nbsp;</p><p></p><h2>成功的语言需要与时俱进</h2><p></p><p>&nbsp;</p><p>成功的语言应该对需求做出反应，给孕育出这些需求的时代指明前进的道路。</p><p>&nbsp;</p><p>C的出现伴随着小型计算机的成长，而后延伸至8位微型计算机，在这里效率和可移植性才是重中之重。随着个人计算机强大到足以对复杂数据执行复杂任务，C++快速跟进解决了软件范围扩大的问题，并在1990年代趋于稳定。</p><p>&nbsp;</p><p>与二者类似，Rust诞生自2010年代的计算成熟度，主要强调安全性、可靠性和并发性，也就是分布式时代需要解决的核心问题。</p><p>&nbsp;</p><p>转型绝非易事。</p><p>&nbsp;</p><p>开源项目需要由大量熟练的开发者参与贡献，并由经验丰富的专家进行代码检查和修复。从这个方面讲，C/C++的系统技能积淀更厚重，远非Rust可比。但是，真正优秀的系统<a href=\"https://qcon.infoq.cn/2022/beijing/track/1299\">工程师</a>\"应该关于进行形式与抽象思考，毕竟这才是不同编程语言之间的最大共性。</p><p>&nbsp;</p><p>所以到底能不能完成语言交接，很大程度上取决于文化和自我意识，而绝非技术熟练度。任何人都很难彻底放下自己磨练多年的技艺，马上转投新语言的怀抱，但只要这代表着新时代下的实际生产力要求，我们就必须抛开成见、做正确的选择。</p><p>&nbsp;</p><p>其实我们这些经历过变革的群体是幸福的一代人。1970年代，信息技术一步步从只有银行业、科学家们关心的小众概念，发展成了影响每个人日常生活的普适成果，而这样的颠覆式转变只经历了两代系统语言。这是专属于开发者的moment，是只有IT行内人才能产生共鸣的美妙体验。</p><p>&nbsp;</p><p>从现实来看，Rust有着成为第三代语言标杆的所有特质。它站在巨人的肩膀上，专注于解决现实问题，有望释放出更多人的开发才能以创造更美好的未来。这既是种技术变革，也是一波文化变革。人类这个物种向来不惮于直面时代的更迭与挑战，而新的进击钟声已经敲响。所以请大家放平心态，毕竟Rust终有一天也将被取代，正是这样的传承与发展构成了人类社会辉煌灿烂的历史。</p><p>&nbsp;</p><p>原文链接：</p><p>&nbsp;</p><p><a href=\"https://www.theregister.com/2022/09/26/rust_column/\">https://www.theregister.com/2022/09/26/rust_column/</a>\"</p>",
    "publish_time": "2022-09-27 15:33:39",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "云原生下缓存架构如何演变 | DBTalk 技术公开课第3期",
    "url": "https://www.infoq.cn/article/yNzW2fibuhV76z9URH2I",
    "summary": "<p>当下，随着云原生在企业应用的场景越来越多，业务程序在容器等技术的加持下，也越来越灵活，高弹性，易伸缩，多活需求的业务程序，给传统的缓存也带来了挑战，怎么演变才能更好的服务业务？</p>",
    "publish_time": "2022-09-27 16:23:41",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "在敏态业务场景中，微盟数据库的应用实践之路 | DBTalk 技术公开课第3期",
    "url": "https://www.infoq.cn/article/ZFvSY1PNYlS9tuJGY9Sd",
    "summary": "<p>企业级SaaS平台重要考量指标之一：持续创新的能力；这种以业务创新、管理创新为导向的技术创新，传导至后台支撑应用的数据库更需要具备持续变更的能力。本次分享，将从资源部署、数据赋能、灵活集成、动态扩展四个维度阐述微盟在全链路压测项目中数据库侧的应用实践之路</p>",
    "publish_time": "2022-09-27 16:25:37",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "TDSQL破局敏态业务背后的技术演进 | DBTalk 技术公开课第3期",
    "url": "https://www.infoq.cn/article/tKJy8kCY9cqdXK8YCDkl",
    "summary": "<p>TDSQL 是腾讯云发布的一款全自研的，面向企业级应用的分布式数据库产品。在敏态业务下，数据库需要具备频繁扩缩容的能力。本次分享主要介绍 TDSQL 是如何在频繁扩缩容时，不影响事务执行，做到对上层业务无感知的。</p>",
    "publish_time": "2022-09-27 16:26:45",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]