[
  {
    "title": "ByConity 如何在Kubernetes上无感扩缩容",
    "url": "https://www.infoq.cn/article/yIV7POYPrd7QhsGKrcpj",
    "summary": "<p></p><h2>引言</h2><p></p><p>ByConity是一个由字节跳动开源的云原生数据仓库引擎，采用存储计算分离的架构，实现了读写分离和弹性扩缩容。这款引擎支持多个关键功能特性，如资源隔离、无感扩缩容、高性能和数据的强一致性等。该架构确保读写操作不会相互影响，同时使计算资源和存储资源解耦，两者可以按需独立扩缩容，实现资源高效利用。ByConity适用于多租户环境，支持多租户资源隔离功能，保证不同租户之间不会互相影响。另外，ByConity采用主流的OLAP引擎优化技术，如列存储、向量化执行、MPP执行和查询优化等，为用户提供优异的读写性能。</p><p></p><h2>ByConity存储计算分离架构</h2><p></p><p></p><p>为了让大家更好的理解需要部署的组件，这里简单介绍下ByConity的架构。想更深入了解请参考另一篇文章《<a href=\"https://mp.weixin.qq.com/s/FNaC3RTr7BxBZbditTJxRw\">谈谈ByConity存储计算分离架构和优势</a>\"》。ByConity的存储计算分离架构主要分为三层：共享服务层、计算层和云存储层。共享服务层是所有查询的入口，主要组件是Cloud Service和Metadata Storage，它会对查询进行解析和优化，并负责一些服务、组件和事务的管理和元数据的管理。计算层是计算资源组，主要组件是Virtual Warehouse（VW），包括Read VW和Writer VW。云存储层是分布式统一存储系统，ByConity所有的数据都存储在这一层，在计算层进行查询时，会从云存储层中读取数据，具体实现可以采用各种云存储服务，如HDFS、S3等。此外，ByConity还包括TSO、Daemon Manager、Resource Manager、后台任务和服务发现等共享服务组件，为整个系统提供稳定的支持和管理。</p><p><img src=\"https://static001.geekbang.org/infoq/ca/ca658cf185d98b015c968c0e6a1e0cc4.png\" /></p><p>图1 ByConity三层技术架构</p><p></p><h2>ByConity如何在Kubernetes上部署和操作</h2><p></p><p>Kubernetes是一个开源的容器编排平台，可以自动管理和部署容器化应用程序，并提供高可用性和弹性的部署模式。将ByConity部署在Kubernetes上，可以享受Kubernetes提供的可伸缩性、高可用性、负载均衡、容错性等，同时简化管理和部署的过程。下面将给大家详细介绍下，如何在Kubernetes上部署ByConity。</p><p></p><h3>硬件配置：</h3><p></p><p></p><p>用户需要部署和购买自己的Kubernetes集群，且要求在不影响测试性能前提下的最低硬件配置如下表：</p><p></p><p></p><p>同时，我们也给出一个生产环境下建议的硬件配置，供大家参考：</p><p></p><p></p><h3>工具安装：</h3><p></p><p>本地安装Kubernetes命令行工具kubectl，用于管理Kubernetes集群本地安装用于管理Kubernetes应用程序的包管理工具helm本地安装byconity-deploy代码：</p><p><code lang=\"null\">git clone git@github.com:ByConity/byconity-deploy.git \ncd byconity-deploy</code></p><p></p><h3>配置存储</h3><p></p><p></p><p>为了获得最佳的 <a href=\"https://en.wikipedia.org/wiki/Total_cost_of_ownership\">TCO</a>\"（https://en.wikipedia.org/wiki/Total_cost_of_ownership） 和性能，本地存储最好与 ByConity Server 和 Worker 一起使用。</p><p></p><p></p><blockquote>ByConity Server 和 Worker 的存储仅用于磁盘缓存，可以随时删除它们。</blockquote><p></p><p></p><p>您可以使用 <a href=\"https://openebs.io/docs/concepts/localpv\">OpenEBS local PV</a>\" （https://openebs.io/docs/concepts/localpv）等存储.</p><p></p><h3>配置helm</h3><p></p><p></p><p>可以从安装的byconity-deploy的目录复制./chart/byconity/values.yml文件，并进行修改适配，需要修改的地方如下：</p><p>storageClassNametimezonereplicas for server/workerhdfs storage request</p><p></p><h3>部署ByConity集群</h3><p></p><p><code lang=\"null\"># Install with fdb CRD first\nhelm upgrade --install --create-namespace --namespace byconity -f ./your/custom/values.yaml byconity ./chart/byconity --set fdb.enabled=false\n\n# Install with fdb cluster\nhelm upgrade --install --create-namespace --namespace byconity -f ./your/custom/values.yaml byconity ./chart/byconity</code></p><p>等待Pod启动：</p><p><code lang=\"null\">kubectl -n byconity get po</code></p><p>完成部署，启动client：</p><p><code lang=\"null\">$ kubectl -n byconity exec -it sts/byconity-server -- bash\nroot@byconity-server-0:/# clickhouse client\n172.16.1.1 :)</code></p><p></p><h3>测试ByConity集群</h3><p></p><p>执行一些SQL语句测试：</p><p><code lang=\"null\">CREATE DATABASE IF NOT EXISTS test;\nUSE test;\nDROP TABLE IF EXISTS test.lc;\nCREATE TABLE test.lc (b LowCardinality(String)) engine=CnchMergeTree ORDER BY b;\nINSERT INTO test.lc SELECT '0123456789' FROM numbers(100000000);\nSELECT count(), b FROM test.lc group by b;\nDROP TABLE IF EXISTS test.lc;\nDROP DATABASE test;</code></p><p></p><h3>手动更新ByConity集群</h3><p></p><p>这里举例说明如何增加新的计算组（Virtual Warehouse），假如用户希望增加两个计算组，5个副本用户读取（my-new-vw-default ）2个副本用户写入（my-new-vw-write ）。</p><p></p><p>更新用户的values.yaml文件</p><p><code lang=\"null\">byconity:\n  virtualWarehouses:\n    ...\n\n    - &lt;&lt;: *defaultWorker\n      name: my-new-vw-default\n      replicas: 5\n    - &lt;&lt;: *defaultWorker\n      name: my-new-vw-write\n      replicas: 2</code></p><p>使用新的value.yml文件，执行helm upgrade</p><p><code lang=\"null\">helm upgrade --install --create-namespace --namespace byconity -f ./your/custom/values.yaml byconity ./chart/byconity</code></p><p>在Byconity中运行执行DDL语句 CREATE WAREHOUSE 创建新的计算组</p><p><code lang=\"null\">CREATE WAREHOUSE IF NOT EXISTS `my-new-vw-default` SETTINGS num_workers = 0, type = 'Read';\nCREATE WAREHOUSE IF NOT EXISTS `my-new-vw-write` SETTINGS num_workers = 0, type = 'Write';</code></p><p>测试新的计算组</p><p><code lang=\"null\">-- Create a table with SETTINGS cnch_vw_default = 'my-new-vw-default', cnch_vw_write = 'my-new-vw-write'\nCREATE DATABASE IF NOT EXISTS test;\nCREATE TABLE test.lc2 (b LowCardinality(String)) engine=CnchMergeTree\nORDER BY b\nSETTINGS cnch_vw_default = 'my-new-vw-default', cnch_vw_write = 'my-new-vw-write';\n\n-- Check if the table has the new settings\nSHOW CREATE TABLE test.lc2;</code></p><p></p><h3>在Kubernetes上无感扩缩容</h3><p></p><p>无感扩缩容是指在系统运行过程中，通过动态调整计算和存储资源的分配，以满足业务需求，同时不影响系统的正常运行和服务质量的一种扩容方式。无感扩缩容的目的是为了提高系统的可用性和可靠性，同时降低系统维护和运营的成本。下面介绍下如何利用Kubernetes对ByConity集群进行无感扩缩容：</p><p></p><p>部署ByConity集群：利用上面步骤在用户的Kubernetes集群上部署ByConity设定负载阈值：用户需要设定负载阈值，即当ByConity集群负载达到一定程度时需要进行扩容操作。可以通过Kubernetes Horizontal Pod Autoscaler（HPA）对象进行设定，设置CPU使用率或内存使用率等指标作为负载阈值。例如，可以设置当ByConity集群的CPU使用率达到80%时，自动进行扩容操作。自动触发扩容：当ByConity集群负载达到设定的负载阈值时，Kubernetes HPA会自动触发扩容操作，增加ByConity节点数量以满足业务需求。例如，当ByConity集群的CPU使用率达到80%时，Kubernetes HPA会自动增加节点数量，保证ByConity集群的性能和可用性。Kubernetes会根据预设的规则和算法，自动增加或减少节点数量，并调整负载均衡策略，以保证系统的高性能和高可用性。动态调整资源：Kubernetes会根据实际负载情况，动态调整计算和存储资源的分配，以保证系统的高性能和高可用性。Kubernetes会自动将负载均衡地分配到不同的ByConity节点上，同时保证数据的一致性和可靠性。实时监控和报警：可以通过Prometheus等监控工具，实时监控ByConity集群负载和资源使用情况，当出现异常情况时会自动触发报警机制，通知管理员进行处理。</p><p></p><h2>总结</h2><p></p><p></p><p>总之，将ByConity部署在Kubernetes上，可以享受Kubernetes提供的可伸缩性、高可用性、负载均衡、容错性等，同时简化管理和部署的过程，同时ByConity可以利用Kubernetes进行无感扩缩容对用户带来的价值包括：</p><p>提高系统的可用性和可靠性：无感扩缩容可以根据实际负载情况动态调整计算和存储资源的分配，保证系统始终能够满足业务需求，避免因系统资源不足而导致的系统宕机或服务中断。提高系统的灵活性和可扩展性：无感扩缩容可以根据业务需求动态地增加或减少计算或存储资源，不需要进行系统停机或重启，从而提高了系统的灵活性和可扩展性。降低系统维护和运营成本：无感扩缩容可以自动调整系统资源，减少了系统管理员和运营人员的工作量，降低了系统维护和运营的成本。</p><p></p><p>同时ByConity也提供多种其他部署方式，欢迎社区开发者使用，并给我们提issue：</p><p>单机版本方式：https://github.com/ByConity/byconity-docker物理机部署模式：<a href=\"https://github.com/ByConity/ByConity/tree/master/packages\">https://github.com/ByConity/ByConity/tree/master/packages</a>\"源代码编译方式： https://github.com/ByConity/ByConity#build-byconity</p><p></p><h2>加入我们</h2><p></p><p></p><p>ByConity社区拥有大量的用户，同时是一个非常开放的社区，我们邀请大家和我们一起讨论共建，在Github上建立了issue：https://github.com/ByConity/ByConity/issues/26。</p><p></p><p>延伸阅读：</p><p><a href=\"https://www.infoq.cn/article/eDuYRT4rzgHBpqfV1T49\">谈谈ByConity存储计算分离架构和优势</a>\"</p><p><a href=\"https://www.infoq.cn/article/VKvhBbZq1OBtO3wF76Sf\">字节跳动开源ByConity：基于ClickHouse的存算分离架构云原生数仓</a>\"</p><p><a href=\"https://www.infoq.cn/article/SQCArsXNtZ9N1vEbLBqx\">ByConity与主流开源OLAP引擎（Clickhouse、Doris、Presto）性能对比分析</a>\"</p><p></p>",
    "publish_time": "2023-06-07 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "为什么技术经验很重要 | QCon伦敦演讲分享",
    "url": "https://www.infoq.cn/article/wWRHyXajo7gtJJeh7osC",
    "summary": "<p>空客防务与航天公司系统工程师<a href=\"https://qconlondon.com/speakers/svenreimers?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODU2OTI3MzUsImZpbGVHVUlEIjoiaXk3ZTNCS0o3ZXNUQWtBTiIsImlhdCI6MTY4NTY5MjQzNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.HwPeoihCL4qJAqXSJW6vlCR6CuuqbeqFIKYCFTF1b8g\">Sven Reimers</a>\"在<a href=\"https://qconlondon.com/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODU2OTI3MzUsImZpbGVHVUlEIjoiaXk3ZTNCS0o3ZXNUQWtBTiIsImlhdCI6MTY4NTY5MjQzNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.HwPeoihCL4qJAqXSJW6vlCR6CuuqbeqFIKYCFTF1b8g\">伦敦QCon大会</a>\"上分享了一些关于<a href=\"https://qconlondon.com/presentation/mar2023/why-technical-experience-matters-how-build-lifelong-career-software?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODU2OTI3MzUsImZpbGVHVUlEIjoiaXk3ZTNCS0o3ZXNUQWtBTiIsImlhdCI6MTY4NTY5MjQzNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.HwPeoihCL4qJAqXSJW6vlCR6CuuqbeqFIKYCFTF1b8g\">如何在软件开发领域建立长期职业生涯</a>\"的经验教训。在大会上，Reimers根据自己的亲身经历讨论了工程师在技术职业生涯中可以做些什么来保持进步。他分享了如何成为一名常青的软件开发者，拥有被业界重视的技术专长，并在指导下一代开发者方面发挥作用。</p><p></p><p>Reimers从他的职业生涯开始就进入了软件开发领域，设计和实现了在行业中得到广泛认可的复杂分布式系统，成为该领域的专家。他所掌握的工程专业知识使他成为卫星通信网络系统和网络管理解决方案的关键开发者。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/news/2023/04/why-technical-experience-matters/en/resources/1qcon2-1680555874488.jpg\" /></p><p></p><p>在快速发展的软件开发领域，技术经验比以往任何时候都更加重要。随着技术的不断发展，软件开发者需要掌握新的知识和技能，以便跟上最新的趋势和创新。</p><p></p><p>Reimers认为技术经验非常重要，它可以帮助开发者在不断变化的行业中站稳脚跟。他在演讲中分享了以下这些经验：</p><p></p><p>拥抱机会；弥合工程差距；成为佼佼者；传播你的知识；提升领导力；离开舒适区；终身学习；参与开源；提升专业知识；热爱你的工作。</p><p></p><p>积累技术经验对于在软件开发领域保持职业生涯常青来说是必不可少的。专注于建立坚实的技术技能基础，紧跟最新的趋势和最佳实践，发展沟通和解决问题等软技能，你就可以在这个令人兴奋和不断发展的领域取得成功。</p><p></p><p>技术在不断发展，新的编程语言、框架和工具也在不断出现。开发者需要跟上最新的趋势和创新，这样才能够保持竞争力，并随着时间的推移不断地继续培养他们的技能。而这些反过来可以带来更牢固的工作保障、更高的工资和更令人兴奋的职业机会。</p><p></p><p>无论你是刚开始参加工作，还是经验丰富的开发者，现在都是开始积累技术经验并将职业生涯提升到新水平的最佳时机。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/04/why-technical-experience-matters/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODU2OTI3MzUsImZpbGVHVUlEIjoiaXk3ZTNCS0o3ZXNUQWtBTiIsImlhdCI6MTY4NTY5MjQzNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.HwPeoihCL4qJAqXSJW6vlCR6CuuqbeqFIKYCFTF1b8g\">https://www.infoq.com/news/2023/04/why-technical-experience-matters/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/4uHEPy7XI5ORkaTTiZXN\">DevOps vs 平台工程，你想了解的都在这里 ｜ QCon闭门会</a>\"</p><p><a href=\"https://www.infoq.cn/article/ShUXt8wQpm9Zc17dXxDg\">降本增效三部曲：算好帐、定目标、抓增效 ｜ QCon闭门会</a>\"</p>",
    "publish_time": "2023-06-07 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从 PMO 的视角，看如何从 0 到 1 搭建研发效能体系？",
    "url": "https://www.infoq.cn/article/B2stL8oRq74SDsWZqcxO",
    "summary": "<p>项目的端到端交付会经历多个环节，从需求、开发、测试、集成、上线，到后续的运维、数据反馈。如果说有一个角色能对所有环节的情况胸有成竹，那可能就是 PMO 了。</p><p></p><p>我们在上一篇文章中聊到了<a href=\"https://www.infoq.cn/article/uYHCyCHU27weYcA94azl\">测试工程师为什么要关注研发效能</a>\"。这次关注研发效能的小逸同学对妙盈的PMO 负责人兼研发效能负责人姬俊鹏，进行了一次访谈。本期看点如下：</p><p>PMO 应该如何择己所长推动研发效能提升？如何从 0 到 1 建立研发度量体系？怎样解决推行研发效能过程中遇到的矛盾？怎样看待指标的波动与优化？</p><p></p><p>本文经公众号<a href=\"\">思码逸研发效能</a>\"授权转载。</p><p></p><h2>PMO 为什么会关注研发效能？</h2><p></p><p></p><p>小逸：可能还有些人对妙盈这家公司比较陌生，请先介绍一下妙盈和您自己。</p><p></p><p>姬俊鹏：妙盈科技是亚洲领先的可持续发展技术服务商，用人工智能解决金融机构、企业、政府和个人面临的可持续发展、气候变化、碳中和社会责任方面的挑战。我们为 ESG（Environmental，Social，Governance）和碳减排（Decarbonization）整个生态产业链各个环节提供解决方案。由于我们处于一个年轻的赛道，所以对于我们来讲，不管是在研发效能还是在企业管理方面，都会遇到一些比较新的机遇和挑战。</p><p></p><p>我是妙盈的 PMO 负责人姬俊鹏，此前从事的大部分工作都是与项目管理相关的，目前主要负责妙盈的研发项目管理和过程改进。</p><p></p><p>小逸：您在妙盈是负责从 0 到 1 建立研发效能体系的。为什么研发效能体系建设的重任会放到 PMO 团队身上？PMO 在推动研发效能提升方面，有哪些优势？</p><p></p><p>姬俊鹏：PMO 是一个组织，这个组织在市面上的解释很多，有的公司是一个项目经理团队相当于项目经理的集合、有的公司是做高层级项目管理（项目集及项目组合）、有的公司是做制度流程及审计。定位不一样则体现的价值不一样吧。妙盈的 PMO 会更关注工程师，主要是负责工程师团队的项目管理及过程改进。从过去的研发效能提升来看，我们做了不少的事情。</p><p></p><p>为什么 PMO 会关注研发效能？首先是得益于 CTO 的在公司技术发展上的战略要求，我们认为度量是非常有意义的。其次我们认为提升研发能效需要有有效的载体和抓手，项目可能是一个不错的选择。而且我们考虑到，PMO 这个组织处于一个相对中立的位置，也是比较容易通观全局的部门，所以研发效能的任务就落在了 PMO 组织上。</p><p></p><p>但从另一方面，PMO 一般并不懂具体研发岗位上的技术细节，在量化和研发效能提升时对各个专业自身的管理依赖会比较大。这对整个组织的文化和团队协作有比较高的要求。</p><p></p><p>小逸：从 PMO 的视角来看，在负责整个研发效能项目时，您最开始重点要做的事情是什么？</p><p></p><p>姬俊鹏：讲到从 0 到 1 建立研发效能体系，如果单说指标框架，其实网上可以找到很多，近些年已经有很多最佳实践，比前些年要容易找到参考。不过到具体公司落地场景和实践中，我们会面临很多更实际的困难。比如在妙盈初期做研发效能时，首先遇到的问题是如何收集数据以及先量化哪些工作等比较基础的问题。这个问题给不同的角色的人，可能思路各异。由于我是 PMO 负责管理项目，所以我第一反应就是以项目管理工具为核心，制定量化方法。例如我们现在用 JIRA，我们可以在里面看到需求管理、任务管理、测试管理、CI/CD 等环节的所有数据。</p><p></p><p>当然，作为 PMO 是这样的策略，如果换成别的专业来做，肯定也有其他行之有效的方法，并没有哪个是最好的。我认为最关键的是你要明白研发效能在你的公司战略中的定位，最终的目标是什么，然后从自身专业出发，找到一套适合公司战略，又能发挥你专业所长的方法论。</p><p></p><h2>从 0 到 1 建立研发效能体系</h2><p></p><p></p><p>小逸：我们从个人视角转到企业的视角。您可以讲讲为什么妙盈会关注研发效能吗？</p><p></p><p>姬俊鹏：妙盈关注研发效能得益于公司研发管理的战略考虑。因为我们的研发是一个很大的团队，其中有非常多的专业。当我们面向客户交付的时候，交付的结果是比较容易被观察到的，但是交付的过程、各专业的情况通常比较难被观测。所以研发的可被观测、可被量化，是作为研发效能改进的一个前提。</p><p></p><p>比如，前些年我们的重点工作是提高项目质量，因为那段时间我们注意到线上事故的频率很高，而且经常出现严重的事故。那我们应该从哪些方面着手改进呢？妙盈的思路就是先要将这个场景量化。第一步是量化当前现状，通过使用项目管理工具，记录所有的事故，获取基础数据、分析获得对它的洞察力。这个过程使我们能够识别根本的问题。通过解决这些核心问题，我们便可以改变现状。同时，这些变化的积极影响将一定程度上反映在我们的测量系统中，形成一个正向的循环。通过对各种业务场景进行量化，获得洞察力，并实施根本性的变革，我们建立了一个持续改进的正向循环。我们的确从这套方法论中受益，所以我们才会这么关注研发度量和效能提升。</p><p></p><p>小逸：那么从 0 到 1 建设研发效能体系的过程中，如何在最开始确立指标？期间遇到过什么样的问题？</p><p></p><p>姬俊鹏：首先我们想到的就是“量化指标”的数据从哪里获取。还是拿刚才说的项目质量的例子，最开始的时候，我们没有统一的项目管理工具，那我们首先就是找一个平台将每天的事务管理起来，由于当时研发大概只有几十人，所以没有必要建立太复杂的机制。我们就想着先将这些事件都记录下来，形成统一的工作习惯。比如发生一次线上事故，我们会先看行业内有哪些最佳实践，然后仿照着对这次事故进行响应、复盘，最后提交事故报告。这整个过程都会被记录下来，统一的工具帮助我们逐步形成了一套流程机制。与此同时，数据就沉淀在了工具里。</p><p></p><p>有了这些数据积累后，我们就会开始分析，比如我们可以按季度拉取数据，从中我们就可以看出：</p><p>该季度发生了多少线上事故这些事故的根本原因是什么事故的责任人、部门是哪些处理事故所用时长</p><p></p><p>我们最初做这样的研发效能度量后，发现当时绝大部分问题都是由于基础设施不够完善和不稳定引起的。有了这样的洞察，我们就能针对性地做出改进。如此经过半年多的持续改进，几轮正向的循环，妙盈整体线上 SLA 得到了很大改善。</p><p></p><p>小逸：你们是如何来制定指标的？从需求、开发、测试、运维，不同研发环节，都用了哪些指标？</p><p></p><p>姬俊鹏：提到指标的模型，行业中各家做法肯定各有千秋，我只谈我们自己的做法。由于我是 PMO 的角色，所以我会持续思考我们的研发模型是什么。我们在最初的时候研发团队比较小，所有项目均采用敏捷开发模型。后来随着业务规模和复杂性扩大，部分外部项目采用了瀑布式开发模型。这个时候，研发在不同模型下的量化指标是不一样的。比如大家讲到敏捷开发，第一时间想到的就是燃尽图，但放到瀑布模型下，燃尽图就没有什么意义了。所以根据模型的不同，我们的量化指标也会不断丰富和调整。</p><p></p><p>目前最新的情况，无论项目是敏捷还是瀑布，我们都尝试在贴合DevOps的框架。</p><p></p><p>DevOps 有几个域，从 Plan 阶段开始，我们就会进行量化，比如需求设计周期、需求评审情况等，会从 Plan 阶段开始尝试在整个生命周期下对需求做量化。</p><p></p><p>在Coding 阶段，思码逸就是我们非常核心的量化工具，其中最关键的就是代码当量、代码缺陷指标。</p><p>在 CI（持续集成） 阶段，我们会统计 CI 的时长、成功率，然后在 CI 上增加一些质量门禁。在有了质量门禁之后，CI 的通过率就可以得到量化了。</p><p></p><p>在测试阶段，会有缺陷密度、bug 类型、bug 严重程度、测试用例执行次数等这些量化指标。</p><p></p><p>在 Ops 环节中，会有针对Service Desk、线上事故、事件响应时间的度量，我们管这些叫 Ops Tickets，也是我们重点的量化的方向之一。</p><p></p><p>除此之外，SaaS线上监控的三大指标，包括success_rate, latency_p95, error_count，这些都会被量化。同时，我们也会监控各集群的资源利用率等指标。</p><p></p><p>小逸：你们对指标的产生波动是如何看待的？当你们从指标波动中发现问题后，如何推进后续优化？</p><p></p><p>姬俊鹏：肯定会有波动和变化。首先，我们有一个关键指标看板，每周都在周会上 review 一遍。我们在不同时期的关注点和侧重点会不太一样。如果有些指标的波动在当时来看是良性的，那我们就不会过多关注它。</p><p></p><p>例如在最开始的时候，我们的重点是质量的提升，那么我们每周周会会着重围绕线上事故事故响应、Root cause 做讨论，以及刚提到的 Ops 的各类指标。我们甚至还会直接打开具体的平台去看前后端的报错。</p><p></p><p>现在，我们团队更关注的是需求整体的研发效率，比如需求的健康程度、代码效率、需求响应速度等。</p><p></p><p>小逸：您刚刚提到在 Coding 环节引入了思码逸平台。那么引入后，帮您在研发效能提升方面解决了哪些问题？</p><p></p><p>姬俊鹏：其实最开始引入思码逸平台的时候，我们内部还没有研发的度量体系。这也是得益于 CTO 前瞻的判断。</p><p></p><p>很多公司都会在 Coding 阶段遇到代码该如何度量的问题。有些公司不用思码逸，那么解决这个问题的手段就很有限。他们可能就会通过计算代码行数来解决。但其实写代码的人都知道，用代码行数来度量存在很多漏洞。所以我认为思码逸做了一件很有意义的事情，让大家不用去看代码行数，通过代码当量比计算代码行数要相对更有说服力一些。同时我们还会采用思码逸平台提供的代码缺陷、测试覆盖等指标，从多个维度来评价开发提交的代码。</p><p></p><p>反观过去我们的度量历史，思码逸就是我们研发能效体系的一个树根，基于思码逸平台生长出了很多非常关键的指标。</p><p></p><p>小逸：内部来看，高层、管理者、开发者，从上到下怎么看待研发效能提升这件事？大家在此期间投入的精力如何？有哪些角色关注、参与了研发效能的提升，大家是如何分工的？</p><p></p><p>姬俊鹏：的确是不同层面的人，看待研发效能的观点很不一样。从我的观察来讲，首先我认为高层其实是非常重视这件事的，公司的运转效率始终是一个重要话题。对于研发 Lead 来讲，他们是衔接高层战略和普通员工管理的重要环节，从团队管理的角度，他们知道研发效能是非常重要的，但是另一方面也不希望这些机械化的指标影响团队的整体氛围。在妙盈，我们的研发 Lead 都很清楚，研发度量是一个管理工具，而如何使用工具，则是见仁见智。如果能利用好这个工具，其实对团队文化、团队效率、人才建设都会有正面的帮助。</p><p></p><p>从工程师层面来讲，肯定不希望有人天天来“度量”自己，会觉得压力很大。所以更多情况下，我们希望让开发同学能了解到公司实际在面临什么情况，我们开发的这个 feature 的市场背景、能给公司带来什么样的收益，从而让开发的同学能从日常工作中得到一些认同感和成就感。进一步，也可以让开发的同学理解，提升研发效能是为了让公司在市场中跑得更快更好，这才是最终的目的。</p><p></p><p>小逸：那么从业务流程、项目流程的层面来看，推进研发效能体系的时候会遇到哪些问题？你们是如何解决的？</p><p></p><p>姬俊鹏：遇到的状况还是挺多的。举几个例子吧。比如在我们推行代码当量这个指标的时候，工程师会认为它无法充分表达开发的所有工作内容，比如他们除了写代码，还需要写文档、改 bug，这些工作量是代码当量这个指标无法完全表达的。所以在做量化指标的同时，我们也会给 Leader 更多的解释权，把客观指标与主观评价结合来看。</p><p></p><p>还有比如任务延期这个指标。一个事情 delay 了，但它可能不是由于个人问题，可能是协作、客观因素等导致的。还有一些类似的指标，比如事故责任，在做事故归因的复盘时，责任人就会认为事故不是单个人的问题，很多人都有责任。</p><p></p><p>所以在遇到这些矛盾的时候，作为 PMO，我们会坚持两个基本原则：</p><p></p><p>1、坚持自己的中立性。不能偏袒任何一方，否则就会面临信用破产的问题。反过来讲，当你的中立性被大家广泛认可之后，在后续协调冲突中，解决事情的效率会越来越高。</p><p></p><p>2、维护好大家对指标的解释权。当你做了指标量化后，指标的解读在不少场景会有失控的风险。比如一个 report，技术 Lead 看过之后，认为没问题，但另一个观察者，他可能会不理解其中一些指标的异常和波动背后复杂的原因。那么这个时候对指标的解释就变得非常重要。所以我们会尽全力维护大家对指标的解释权利。即便说指标出现了异常，但你始终有机会去表达为什么出现这个异常，让各环节都能有得到充分的沟通，而不是只看表面的数字。我们量化的最终目的还是为了发现组织内部的问题、提升组织整体的管理水平，而不是为了量化而量化。</p><p></p><p>小逸：在经过这些年推动团队提升研发效能，在不同层面看取得的成效如何？</p><p></p><p>姬俊鹏：之前妙盈的研发团队比较小，那时候的确也很高效，但不是规模化的方式。现在我们的研发规模变大了，也有了比较成熟的分工结构、制度流程、度量体系、专门的报告平台，在平台上有大量的度量报表，不同报表面向不同的受众。我们完成了从小团队到规模化的转变，在转变过程中我们保持了项目质量稳定、效能持续维持在高于行业中位水平。</p><p></p><p>质量方面，我们不断提升代码质量指标的表现，比如单测覆盖、缺陷密度。线上高等级事故以前经常出现，现在已经变得非常罕见。与此同时还新增了不少质量措施，比如更复杂的静态扫描、自动化测试、各类安全测试及安全体系。</p><p></p><p>在改进质量的同时我们保持了高代码效率，周人均当量持续保持在 1500 左右。</p><p></p><p>这其中度量和基于度量的改进发挥了很重要的作用。现在回头看是很有成就感的事情。当然不同的阶段我们会面临不同的挑战，所以我们会持续迭代我们的研发管理体系以适应最新的战略要求，变革永远在路上。</p><p></p><h2>拥抱 AI 带来的颠覆性变化</h2><p></p><p></p><p>小逸：目前你们怎么看待 AI 工具带来的影响？</p><p></p><p>姬俊鹏：我们还处于积极尝试的阶段。我们坚信 AI 会给以后的研发带来颠覆性的变化，所以我们所有的部门都在不同的层面进行探索。</p><p></p><p>小逸：目前行业中有些团队在利用 ChatGPT 处理一些研发上的小工作。您和团队成员是否有在用？如果使用了，都是在什么样的场景上？</p><p></p><p>姬俊鹏：我们在积极地研究 ChatGPT，并且很多部门都在尝试使用它做一些工作。比如市场部会用 ChatGPT 去做一些初期的调研。当然，我们还是会对其数据可信度保持怀疑。在得到它的回答之后，再去做一次调研。实际上，ChatGPT确实提高了效率。</p><p></p><p>第二个有意思的应用点就是制度优化。比如让它评审我们的通用密码管理制度。这个制度就是规定了公司中各种密码场景的密码要求。我们会先写下来，然后让 ChatGPT 来 review，发现其中的漏洞。然后我们再根据ChatGPT提供的建议，结合公司实际情况来调整管理制度。在这方面它还是比较擅长的，可以节约一些我们寻找专家咨询的成本。</p><p></p><p>第三个在用 AI 的地方就是 Coding。我们在积极尝试各种工具，包括 ChatGPT、Cursor、Copilot 等。对于前后端工程师来讲，可能还没有完全用起来。但是对于我们一些非开发专业的人，比如我，就会利用这些工具写 Python 脚本、SQL 语句等来提升工作效率。还有就是利用它做 code review。我们可能考虑，在 CI 方面去集成一些 AI 工具。</p><p></p><p>同时我们也发现其在需求设计、单元测试、测试用例设计方面也有应用的场景，我们还在探索。</p><p></p><p>除此之外我们在云服务运维及内部工具层面也在用ChatGPT来做一些 troubleshooting 的尝试。</p><p></p><h2>小结</h2><p></p><p></p><p>从 0 到 1 建设研发效能体系并非易事，但不同的角色来负责这件事，都可以从自身擅长的领域找到一个根，慢慢生长出一套良性可持续改进的研发效能体系。就好像 PMO ，从擅长的项目管理本身出发，以项目的交付、质量等维度开始建立量化指标，逐步完善。在推行研发效能的过程中，会遇到很多问题。我们也可以参考他的两条原则，保持中立，以及维护团队对指标的解释权，可以在很大程度上更顺利地推进研发效能体系的建设。</p><p></p><p>原文链接：</p><p><a href=\"https://mp.weixin.qq.com/s/WtG1f656vLQQexSyDUuLiA\">https://mp.weixin.qq.com/s/WtG1f656vLQQexSyDUuLiA</a>\"</p>",
    "publish_time": "2023-06-07 10:22:33",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Java近期新闻：Java 28岁、Payara、Micronaut 4.0-M5、Spring更新",
    "url": "https://www.infoq.cn/article/eazviIX3Dutuh3lKwd1F",
    "summary": "<p></p><h4>OpenJDK</h4><p></p><p></p><p>面向JDK 21的JEP 451（<a href=\"https://openjdk.org/jeps/451\">代理动态加载禁用准备</a>\"）已经从候选状态提升到Proposed to Target状态。该JEP起初名为“默认禁止代理的动态加载”，在JEP Draft 8305968（<a href=\"https://openjdk.org/jeps/8305968\">完整性和强封装</a>\"）之后提出。其意图本是默认禁止将代理动态加载到正在运行中的JVM，现在已经演变为在将代理动态加载到运行中的JVM时发出警告。该JEP的目标包括：重新评估可用性和完整性之间的平衡；确保大多数不需要动态加载代理的工具不受影响。InfoQ后续将带来更详细的新闻报道。</p><p>&nbsp;</p><p>为了<a href=\"https://mail.openjdk.org/pipermail/amber-dev/2023-May/008102.html\">回答</a>\"关于switch模式穷尽检查的设计哲学的诸多问题，Oracle Java语言架构师<a href=\"https://www.linkedin.com/in/briangoetz/\">Brian Goetz</a>\"和Oracle技术顾问<a href=\"https://www.linkedin.com/in/gavin-bierman-a0173075/\">Gavin Bierman</a>\"发布了一份<a href=\"https://openjdk.org/projects/amber/design-notes/patterns/exhaustiveness\">文档</a>\"，详细说明了无条件、穷尽和余值（remainder）之间的关系。</p><p>&nbsp;</p><p></p><h4>JDK 21</h4><p></p><p></p><p>JDK 21<a href=\"https://jdk.java.net/21/\">早期访问构建</a>\"<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-21%2B24\">Build 24</a>\"在上周发布，其中包括<a href=\"https://github.com/openjdk/jdk/compare/jdk-21%2B23...jdk-21%2B24\">Build 23的更新</a>\"，主要是修复了各种<a href=\"https://bugs.openjdk.org/issues/?jql=project%20%3D%20JDK%20AND%20fixversion%20%3D%2021%20and%20%22resolved%20in%20build%22%20%3D%20b17%20order%20by%20component%2C%20subcomponent\">问题</a>\"。要了解关于这个版本的更多细节，请查看<a href=\"https://jdk.java.net/21/release-notes\">发布说明</a>\"。</p><p>&nbsp;</p><p>对于<a href=\"https://openjdk.java.net/projects/jdk/21/\">JDK 21</a>\"，我们鼓励开发人员通过<a href=\"https://bugreport.java.com/bugreport/\">Java Bug数据库</a>\"报告Bug。</p><p>&nbsp;</p><p></p><h4>Spring Framework</h4><p></p><p></p><p><a href=\"https://spring.io/projects/spring-cloud\">Spring Cloud</a>\" 2022.0.3<a href=\"https://spring.io/blog/2023/05/25/spring-cloud-2022-0-3-aka-kilburn-is-available\">版本</a>\"的代号为Kilburn，与Spring Boot 3.1兼容，并更新了Spring Cloud子项目，包括：Spring Cloud OpenFeign 4.0.3、Spring Cloud Commons 4.0.3、Spring Cloud Kubernetes 3.0.3和Spring Cloud Starter Build 2022.0.3。然而，以下子项目的删除也带来了一些破坏性更改：Spring Cloud CLI、Spring Cloud for Cloud Foundry和Spring Cloud Sleuth。关于该版本的更多细节，请查看<a href=\"https://github.com/spring-cloud/spring-cloud-release/wiki/Spring-Cloud-2022.0-Release-Notes\">发布说明</a>\"。</p><p>&nbsp;</p><p><a href=\"https://spring.io/projects/spring-shell\">Spring Shell</a>\" 3.1.0,3.0.4和2.1.10版本<a href=\"https://spring.io/blog/2023/05/25/spring-shell-2-1-10-3-0-4-and-3-1-0-are-now-available\">发布</a>\"，带来了一些值得注意的修复，例如：ConfirmationInput类的实例在输入时不显示所选择的选项；如果未使用@Option或@ShellOption注解，那么将目标方法参数作为布尔参数将失败。这些版本分别基于<a href=\"https://spring.io/projects/spring-boot\">Spring Boot</a>\" 3.1.0、3.0.7和2.7.12构建。关于这些版本的更多细节，请查看<a href=\"https://github.com/spring-projects/spring-shell/releases/tag/v3.1.0\">3.1.0</a>\"、<a href=\"https://github.com/spring-projects/spring-shell/releases/tag/v3.0.4\">3.0.4</a>\"和<a href=\"https://github.com/spring-projects/spring-shell/releases/tag/v2.1.10\">2.1.10</a>\"的发布说明。</p><p>&nbsp;</p><p><a href=\"https://spring.io/projects/spring-security-kerberos\">Spring Security Kerberos</a>\" 2.0.0的<a href=\"https://spring.io/blog/2023/05/25/spring-security-kerberos-2-0-0-rc2-available-now\">第二个候选版本</a>\"将依赖项升级到了<a href=\"https://spring.io/projects/spring-security\">Spring Security</a>\" 6.1.0。关于该版本的更多细节，请查看<a href=\"https://github.com/spring-projects/spring-security-kerberos/releases/tag/2.0.0-RC2\">发布说明</a>\"。</p><p>&nbsp;</p><p></p><h4>Payara</h4><p></p><p></p><p>Payara<a href=\"https://blog.payara.fish/whats-new-in-the-may-2023-payara-platform-release\">发布</a>\"了<a href=\"https://www.payara.fish/\">Payara平台</a>\"的2023年5月版，其中包括社区版6.2023.5、企业版6.2.0和企业版5.51.0。这三个版本主要是解决：<a href=\"https://nvd.nist.gov/vuln/detail/CVE-2023-1370\">CVE-2023-1370</a>\"漏洞——在<a href=\"https://netplex.github.io/json-smart/\">Json-smart</a>\" （JSON处理器库）中对JSON嵌套数组和对象进行非受控递归解析时，可能导致堆栈溢出，进而导致软件崩溃；使用Web UI创建JVM选项时抛出的异常“JVM option${ } 在配置中已经存在”。该版本还带来了依赖项升级：Jackson 2.15.0、SnakeYAML 2.0、JSON Smart 2.4.10以及JDK 8u372、11.0.19和17.0.7的Docker镜像。要了解关于这些版本的详细信息，请查看<a href=\"https://docs.payara.fish/community/docs/Release%20Notes/Release%20Notes%206.2023.5.html\">社区版6.2023.5</a>\"、<a href=\"https://docs.payara.fish/enterprise/docs/Release%20Notes/Release%20Notes%206.2.0.html\">企业版6.2.0</a>\"和<a href=\"https://docs.payara.fish/enterprise/docs/5.51.0/Release%20Notes/Release%20Notes%205.51.0.html\">企业版5.51.0</a>\"的发布说明。</p><p>&nbsp;</p><p></p><h4>Quarkus</h4><p></p><p></p><p>Quarkus 3.0.4.Final是<a href=\"https://quarkus.io/blog/quarkus-3-0-4-final-released/\">第三个维护版本</a>\"（第一个是3.0.1），提供了文档方面的改进和重要的Bug修复，例如：当设置了quarkus.package.output-directory 属性时，本地镜像构建失败；当将@ConfigMapping与onStartup()方法一起使用时，会出现“No current injection point found”错误；修复<a href=\"https://quarkus.io/guides/resteasy-reactive\">RestEasy Reactive中</a>\"的location和content location头信息。要了解关于该版本的更多细节，请查看<a href=\"https://github.com/quarkusio/quarkus/releases/tag/3.0.4.Final\">变更日志</a>\"。</p><p>&nbsp;</p><p>同样，Quarkus 2.13.8也带来了一些重要的Bug修复，其中许多是向后移植的，例如：针对警告消息quarkus.oidc.application-type=service的修复；默认加密OIDC会话cookie值；在ProviderConfigInjectionWarningsTest类中过滤掉与Apache HTTP客户端未关闭相关的RESTEasy警告；因最近一次Netty版本升级所导致的MongoDB客户端本地镜像构建警告。要了解关于该版本的更多细节，请查看<a href=\"https://github.com/quarkusio/quarkus/releases/tag/2.13.8.Final\">发布说明</a>\"。</p><p>&nbsp;</p><p></p><h4>WildFly</h4><p></p><p></p><p>WildFly 28.0.1<a href=\"https://www.wildfly.org/news/2023/05/23/WildFly2801-Released/\">发布</a>\"，提供了依赖项升级和重要的Bug修复，包括：在ContextPropagationTestCase类中定义的testContextPropagation()测试在使用Long Running Actions时偶尔会失败；一个可部署、但在OpenShift上不起作用的QS应用，这是由todo-backend（OpenShift后端部署快速入门）中的<a href=\"https://helm.sh/docs/topics/charts/\">Helm Charts</a>\"更新导致的；在ExpirationMetaData接口中定义的isExpired()方法与LocalScheduler类中的逻辑不一致。</p><p>&nbsp;</p><p></p><h4>Micronaut</h4><p></p><p></p><p>在迈向4.0版本的道路上，Micronaut基金会发布了Micronaut 4.0.0-M5，带来了许多依赖项升级和改进，包括：向JSON消息阅读器添加@BootstrapContextCompatible注解（带有该注解的bean可以加载到Bootstrap Context中）；在<a href=\"https://micronaut-projects.github.io/micronaut-openapi/latest/guide/\">Micronaut OpenAPI</a>\"中使用Micronaut环境时禁用SLF4J初始化的能力；使用bean定义类型作为基于AbstractConcurrentCustomScope类定义类单例作用域时的bean类型。要了解关于该版本的更多细节，请查看<a href=\"https://github.com/micronaut-projects/micronaut-core/releases/tag/v4.0.0-M5\">发布说明</a>\"。</p><p>&nbsp;</p><p></p><h4>Helidon</h4><p></p><p></p><p>Oracle发布了Helidon 2.6.1，升级了依赖项，并引入了一些重要的更改，包括：更新ByteBufDataChunk类中定义的isReleased()方法，使用AtomicBoolean类的一个实例来防止可能多次调用release回调的竞态条件；为@MPTest注解添加@Target(ElementType.METHOD)注解，用于指定具体的目标；修复WritableMultiPart类中定义的重载方法create()。要了解关于该版本的更多细节，请查看<a href=\"https://github.com/helidon-io/helidon/releases/tag/2.6.1\">发布说明</a>\"。</p><p>&nbsp;</p><p></p><h4>MicroStream</h4><p></p><p></p><p>MicroStream 8.1.0<a href=\"https://github.com/microstream-one/microstream/releases/tag/08.01.00-MS-GA\">发布</a>\"，提供了与Quarkus 3的集成，并修复了在使用Lazy Collections API时Stream API无法按预期卸载的问题。</p><p>&nbsp;</p><p>Micronaut团队还为MicroStream<a href=\"https://microstream.one/blog/article/quarkus-extension-for-microstream/\">引入</a>\"了<a href=\"https://docs.microstream.one/manual/misc/integrations/quarkus.html\">Quarkus扩展</a>\"，允许在Quarkus应用程序中通过注解访问MicroStream的功能。</p><p>&nbsp;</p><p></p><h4>Apache Camel</h4><p></p><p></p><p>Apache Camel 3.20.5<a href=\"https://camel.apache.org/blog/2023/05/RELEASE-3.20.5/\">发布</a>\"，主要是针对camel-jbang模块进行了Bug修复、依赖项升级和改进，包括：加载仅定义Java bean的YAML文件的能力；使用camel-jbang在XML DSL中创建Camel文件时，使用文件名生成路由ID；从空文件夹运行camel-jbang，然后在文件夹中新增文件时重新加载。要了解关于该版本的更多细节，请查看<a href=\"https://camel.apache.org/releases/release-3.20.5/\">发布说明</a>\"。</p><p>&nbsp;</p><p></p><h4>JDKMon</h4><p></p><p></p><p><a href=\"https://github.com/HanSolo/JDKMon\">JDKMon</a>\" <a href=\"https://github.com/HanSolo/JDKMon/releases/tag/17.0.61\">17.0.61</a>\"（一个监控和更新已安装JDK的工具）于上周发布。这个新版本是由Azul首席工程师<a href=\"https://de.linkedin.com/in/gerritgrunwald\">Gerrit Grunwald</a>\"创建的，它向jdkmon.properties 文件中添加了一个属性，用于禁用通知。同时，它还修复了与检测到的CPU架构相关的问题以及与同一JDK版本的多个构建相关的问题。</p><p>&nbsp;</p><p></p><h4>JHipster</h4><p></p><p></p><p>JHipster团队<a href=\"https://twitter.com/pascalgrimaud/status/1660303739155095555?cxt=HHwWhoC9-YfdyoouAAAA\">发布</a>\"了<a href=\"https://www.jhipster.tech/jhipster-lite/\">JHipster Lite</a>\"的0.333.0版本，带来了许多依赖项升级和重要的更改，包括：修复了<a href=\"https://www.eclipse.org/jgit/\">JGit</a>\"集成的本地提示；新增DestroyRef提供程序。要了解关于该版本的更多细节，请查看<a href=\"https://github.com/jhipster/jhipster-lite/releases/tag/v0.33.0\">发布说明</a>\"。</p><p>&nbsp;</p><p></p><h4>Java，28岁生日快乐！</h4><p></p><p></p><p>Java初次露面是在1995年5月23日的SunWorld 1995大会上，上周，它迎来了自己的28岁生日。Oracle Java开发关系团队举办了名为Java 28小时的庆祝活动，由<a href=\"https://twitter.com/ammbra1508/\">Ana Maria Mihalceanu</a>\"、<a href=\"https://nipafx.dev/nicolai-parlog/\">Nicolai Parlog</a>\"和<a href=\"https://www.linkedin.com/in/sharatchander/\">Sharat Chander</a>\"主持。活动主题包括：实时编码和探索、演示、与Java杰出人物对话以及有趣的游戏。以下是活动议程：</p><p>与Nicolai一起探索<a href=\"https://junit-pioneer.org/\">JUnit Pioneer</a>\"。由Nicolai介绍<a href=\"https://slides.nipafx.dev/patterns/2023-05-20-28hjava/#/\">面向数据的Java编程（21）</a>\"。与<a href=\"https://www.linkedin.com/in/gavin-bierman-a0173075/\">Gavin Bierman</a>\"聊模式匹配，由Nicolai主持。与Nicolai讨论JEP 451（<a href=\"https://openjdk.org/jeps/451\">代理动态加载禁用准备</a>\"）以及JEP Draft 8305968（<a href=\"https://openjdk.org/jeps/8305968\">完整性和强封装</a>\"）。与<a href=\"https://www.linkedin.com/in/ron-pressler-a279032/\">Ron Pressler</a>\"聊平台完整性（JEP Draft 8305968）、 JEP 445（<a href=\"https://openjdk.org/jeps/445\">未命名类和实例主方法预览</a>\"）以及JEP 453（<a href=\"https://openjdk.org/jeps/453\">结构化并发预览</a>\"），由Nicolai主持。Ana发表“与Java共成长”的演讲。和Ana一起玩<a href=\"https://bytelegend.com/\">Byte Legend</a>\"。Sharat介绍Java现状以及社区的重要性。与<a href=\"https://www.linkedin.com/in/prpatel/\">Pratik Patel</a>\"、<a href=\"https://www.linkedin.com/in/aboullaite/\">Mohammed Aboullaite</a>\"、<a href=\"https://www.linkedin.com/in/vsubramaniam/\">Venkat Subramaniam</a>\"、<a href=\"https://www.linkedin.com/in/aalmiray/\">Andres Almiray</a>\"、<a href=\"https://www.linkedin.com/in/ixchelruiz/\">Ixchel Ruiz</a>\"和<a href=\"https://www.linkedin.com/in/vincentmayers/\">Vincent Mayers</a>\"进行圆桌讨论，由Sharat主持。与<a href=\"https://www.linkedin.com/in/briangoetz/\">Brian Goetz</a>\"聊Valhalla项目，重点是如何在语言中显示值、基本类型和空值，由Nicolai主持。对话<a href=\"https://www.linkedin.com/in/gunnar-morling-2b44b7229/\">Gunnar Morling</a>\"，由Nicolai主持。由Nicolai介绍<a href=\"https://slides.nipafx.dev/java-next/2023-05-20-28hjava/#/\">Java Next</a>\"。与Nicolai一起玩Slay the Spire（用Java编写）并探索<a href=\"https://alexdriedger.github.io/SlayTheSpireModding/docs/play-with-mods.html\">modding</a>\"。由Nicolai介绍“<a href=\"https://slides.nipafx.dev/project-amber/2023-05-20-28hjava/#/\">Amber项目：Java问题的SolutionFactory</a>\"”。由Nicolai介绍<a href=\"https://slides.nipafx.dev/openjdk-features/2023-05-20-28hjava/#/\">从Idea到IDE</a>\"。由Nicolai主持的“随便问”环节。Nicolai致闭幕词。</p><p>&nbsp;</p><p>这次特别的活动在Java <a href=\"https://www.youtube.com/java\">YouTube</a>\"频道上进行了直播。</p><p>&nbsp;</p><p></p><h4>开发者调查</h4><p></p><p></p><p><a href=\"https://www.azul.com/\">Azul</a>\"<a href=\"https://foojay.io/today/state-of-java-survey/\">推出</a>\"了<a href=\"https://survey.alchemer.com/s3/7354395/F1\">Java现状调查</a>\"，涉及的领域包括：OpenJDK发行版及开发者正在使用的Java版本；基于Java的基础架构和语言；在公有云上运行的Java应用程序。调查将于2023年6月15日结束。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/05/java-news-roundup-may22-2023/\">https://www.infoq.com/news/2023/05/java-news-roundup-may22-2023/</a>\"</p>",
    "publish_time": "2023-06-07 10:32:44",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "eBay和Lastminute采用契约测试来驱动架构演进",
    "url": "https://www.infoq.cn/article/U8walzaYhwOZQzsVypVj",
    "summary": "<p>lastminute.com<a href=\"https://technology.lastminute.com/impacts-of-contract-tests-in-a-microservice-architecture/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODU2NzY5MDEsImZpbGVHVUlEIjoicTZUUXc4VzROWjRiSEZ1aCIsImlhdCI6MTY4NTY3NjYwMSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.iF27aHrbAk8JpZZLFE2IY6CmxpCgFJjsXHnJH95v7Rg\">采用契约测试来降低系统级集成测试所带来的复杂性</a>\"，并改进反馈周期和开发过程。eBay也采用契约测试来帮助其内部进行<a href=\"https://tech.ebayinc.com/engineering/api-evolution-with-confidence-a-case-study-of-contract-testing-adoption-at-ebay/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODU2NzY5MDEsImZpbGVHVUlEIjoicTZUUXc4VzROWjRiSEZ1aCIsImlhdCI6MTY4NTY3NjYwMSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.iF27aHrbAk8JpZZLFE2IY6CmxpCgFJjsXHnJH95v7Rg\">API演化</a>\"，并为客户端团队提供支持。</p><p></p><p>在分布式系统（如微服务架构）中，应用程序服务使用RPC（远程过程调用）风格的请求或异步消息进行交互。测试这类系统的常用方法是使用系统测试（端到端集成测试），这通常需要将整个系统部署在测试环境中。</p><p></p><p>lastminute.com的软件工程师<a href=\"https://www.linkedin.com/in/ivan-dell-oro-60170880/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODU2NzY5MDEsImZpbGVHVUlEIjoicTZUUXc4VzROWjRiSEZ1aCIsImlhdCI6MTY4NTY3NjYwMSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.iF27aHrbAk8JpZZLFE2IY6CmxpCgFJjsXHnJH95v7Rg\">Ivan Dell'Oro</a>\"指出集成/系统测试所带来的挑战：</p><p></p><blockquote>在过去，我们通过集成测试来验证两个微服务之间的消息交换，由于多种原因会导致测试失败。为避免阻碍开发过程，我们选择忽略这些测试。结果是它们被忽视了好几个月，当一边的系统发生变化，两边的CI管道却都是绿色的：通常，当生产环境中出现了故障，应该是契约出现了错误。</blockquote><p></p><p></p><p>eBay团队也表示：</p><p></p><blockquote>对于eBay的通知平台团队来说，我们面临的另一个挑战是，我们的API被许多领域团队调用。在演进服务API的同时保持与所有消费者端的兼容性是我们的一个基本原则。</blockquote><p></p><p></p><p>这两个团队都一直在寻找能够让测试变得不那么脆弱和更快速的方法，目标是改善开发人员/测试人员的体验，缩短反馈周期，加快价值交付的速度，同时支持内部契约的演进，例如API规范和消息schema。</p><p></p><p>最后，经过一些研究和实验，他们采用<a href=\"https://martinfowler.com/bliki/ContractTest.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODU2NzY5MDEsImZpbGVHVUlEIjoicTZUUXc4VzROWjRiSEZ1aCIsImlhdCI6MTY4NTY3NjYwMSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.iF27aHrbAk8JpZZLFE2IY6CmxpCgFJjsXHnJH95v7Rg\">契约测试</a>\"作为验证服务间交互正确性的主要方法。lastminute.com发现，这给他们的微服务架构和交付过程带来了积极的影响，与标准的系统级测试相比，测试执行时间大大缩短了。eBay使用契约测试来验证其平台中的集成点，支持通过写作来确保内部API可以在不出现不兼容问题的情况下演进。</p><p></p><p>lastminute.com已经使用<a href=\"https://docs.pact.io/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODU2NzY5MDEsImZpbGVHVUlEIjoicTZUUXc4VzROWjRiSEZ1aCIsImlhdCI6MTY4NTY3NjYwMSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.iF27aHrbAk8JpZZLFE2IY6CmxpCgFJjsXHnJH95v7Rg\">Pact</a>\"（一个<a href=\"https://martinfowler.com/articles/consumerDrivenContracts.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODU2NzY5MDEsImZpbGVHVUlEIjoicTZUUXc4VzROWjRiSEZ1aCIsImlhdCI6MTY4NTY3NjYwMSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.iF27aHrbAk8JpZZLFE2IY6CmxpCgFJjsXHnJH95v7Rg\">客户端驱动</a>\"的契约测试工具）对微服务之间的RPC交互进行了契约测试，并在随后将其<a href=\"https://technology.lastminute.com/contract-testing-asynchronous-messaging-pact-junit-mockk/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODU2NzY5MDEsImZpbGVHVUlEIjoicTZUUXc4VzROWjRiSEZ1aCIsImlhdCI6MTY4NTY3NjYwMSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.iF27aHrbAk8JpZZLFE2IY6CmxpCgFJjsXHnJH95v7Rg\">扩展</a>\"到服务间的异步交互（通过RabbitMQ代理交换消息）上。</p><p></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/43/8e/434fb712d4cce435f7c2e41f284b898e.png\" /></p><p></p><p></p><p></p><p>图片来源：<a href=\"https://technology.lastminute.com/contract-testing-asynchronous-messaging-pact-junit-mockk/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODU2NzY5MDEsImZpbGVHVUlEIjoicTZUUXc4VzROWjRiSEZ1aCIsImlhdCI6MTY4NTY3NjYwMSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.iF27aHrbAk8JpZZLFE2IY6CmxpCgFJjsXHnJH95v7Rg\">https://technology.lastminute.com/contract-testing-asynchronous-messaging-pact-junit-mockk/</a>\"</p><p></p><p>eBay的团队研究了基于<a href=\"https://www.openapis.org/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODU2NzY5MDEsImZpbGVHVUlEIjoicTZUUXc4VzROWjRiSEZ1aCIsImlhdCI6MTY4NTY3NjYwMSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.iF27aHrbAk8JpZZLFE2IY6CmxpCgFJjsXHnJH95v7Rg\">OpenAPI</a>\"规范的API定义<a href=\"https://semver.org/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODU2NzY5MDEsImZpbGVHVUlEIjoicTZUUXc4VzROWjRiSEZ1aCIsImlhdCI6MTY4NTY3NjYwMSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.iF27aHrbAk8JpZZLFE2IY6CmxpCgFJjsXHnJH95v7Rg\">语义版本</a>\"控制，但得出的结论是，版本控制本身不足以解决系统测试的脆弱性。他们将<a href=\"https://cucumber.io/docs/bdd/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODU2NzY5MDEsImZpbGVHVUlEIjoicTZUUXc4VzROWjRiSEZ1aCIsImlhdCI6MTY4NTY3NjYwMSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.iF27aHrbAk8JpZZLFE2IY6CmxpCgFJjsXHnJH95v7Rg\">BDD</a>\"（行为驱动开发）视为描述API消费者需求的一种方式，生产者和消费者团队协作编写所有需求并使其可执行。事实证明，在采用这种方法时，API提供方需要在客户需求发生变化时捕获和更新客户需求，而这已被证明是有问题的。</p><p></p><p>最后，他们发现了契约测试，生产者和消费者团队可以在他们的测试用例中使用Mock（或存根）来独立地维护测试套件。</p><p></p><p>他们对<a href=\"https://spring.io/projects/spring-cloud-contract?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODU2NzY5MDEsImZpbGVHVUlEIjoicTZUUXc4VzROWjRiSEZ1aCIsImlhdCI6MTY4NTY3NjYwMSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.iF27aHrbAk8JpZZLFE2IY6CmxpCgFJjsXHnJH95v7Rg\">Spring Cloud Contract</a>\"和Pact进行了评估，最终选择了后者，因为后者可以更直接地使用schema，并有更好的跨团队交互支持。他们对Spring Cloud Contract和Pact进行了评估，最终选择了后者，因为后者可以更直接地使用schema，并有更好的跨团队交互支持。他们对<a href=\"https://pactflow.io/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODU2NzY5MDEsImZpbGVHVUlEIjoicTZUUXc4VzROWjRiSEZ1aCIsImlhdCI6MTY4NTY3NjYwMSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.iF27aHrbAk8JpZZLFE2IY6CmxpCgFJjsXHnJH95v7Rg\">Pactflow</a>\"（一款商业版Pact产品）和内部CI/CD工具进行了无缝集成，并创建了一个专门的开发者门户，用于配置新的契约测试。</p><p></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/c9/5e/c962656d1ccfaf5fb6719b4cdc12e85e.png\" /></p><p></p><p></p><p>图片来源：<a href=\"https://tech.ebayinc.com/engineering/api-evolution-with-confidence-a-case-study-of-contract-testing-adoption-at-ebay/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODU2NzY5MDEsImZpbGVHVUlEIjoicTZUUXc4VzROWjRiSEZ1aCIsImlhdCI6MTY4NTY3NjYwMSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.iF27aHrbAk8JpZZLFE2IY6CmxpCgFJjsXHnJH95v7Rg\">https://tech.ebayinc.com/engineering/api-evolution-with-confidence-a-case-study-of-contract-testing-adoption-at-ebay/</a>\"</p><p></p><p>Dell'Oro强调，契约测试本身并不能完全替代系统级集成测试。契约测试旨在验证服务之间数据交换的正确性，但服务级集成测试会同时执行业务逻辑和错误处理，确保整个流程/数据流的正确性和弹性。</p><p></p><p>【声明：本文由InfoQ翻译，未经许可禁止转载。】</p><p></p><p>查看英文原文：<a href=\"https://www.infoq.com/news/2023/05/ebay-contract-testing-evolution/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODU2NzY5MDEsImZpbGVHVUlEIjoicTZUUXc4VzROWjRiSEZ1aCIsImlhdCI6MTY4NTY3NjYwMSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.iF27aHrbAk8JpZZLFE2IY6CmxpCgFJjsXHnJH95v7Rg\">https://www.infoq.com/news/2023/05/ebay-contract-testing-evolution/</a>\"</p><p></p><p>延伸阅读：</p><p><a href=\"https://www.infoq.cn/article/2007/11/tdd-or-tdr\">测试驱动开发？还是测试驱动需求？</a>\"</p><p><a href=\"https://xie.infoq.cn/article/7cacb03335919b96614c8f992\">软件界旷世之架：测试驱动开发（TDD）之争</a>\"</p>",
    "publish_time": "2023-06-07 11:03:54",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "函数式编程的后期架构",
    "url": "https://www.infoq.cn/article/ScKjJ9U52AaKNBaxFBJQ",
    "summary": "<p>许多软件架构方法都是假设该架构在一开始时就进行了规划。但不幸的是，以这种方式规划的架构之后很难更改。函数式编程可以帮助我们实现松耦合，从而可以将预先的规划保持在最低限度，并可以在之后更改架构决策。</p><p></p><p>Michael Sperber在<a href=\"https://www.oop-konferenz.de/\">OOP 2023 Digital</a>\"大会上谈到了软件架构和函数式编程。</p><p></p><p>Sperber给出了一个将系统代码划分为不同构建块的例子。这是一种特别重要的架构决策，可以单独处理不同的构建块，也可以与不同团队一起协作。实现这一点的一种方法是对粗粒度的构建块（有界上下文）使用领域驱动设计（DDD）：</p><p></p><blockquote>DDD是指，我们应该在开始时就通过上下文映射来识别有界上下文。但是，如果上下文之间的界限设置错了，我们就会丧失很多优势。我们会把它们搞错，至少会有一点点错误，然后之后就很难更改了。</blockquote><p></p><p></p><p>根据Sperber的说法，与面向对象编程（OOP）相比，函数式编程能够支持后期架构并减少耦合。</p><p></p><p>Sperber认为，为了推迟宏观架构决策，我们必须始终保持解耦。他说，函数式编程中的组件本质上仅是数据类型和函数，这些函数在没有可变状态的情况下工作。与典型的OO（面向对象）组件相比，这使得依赖关系更显式化，并且耦合更松散。这反过来又使我们能够构建独立于宏体架构的函数，Sperber说到。</p><p></p><p>Sperber明确表示，函数式编程并不“仅仅是没有可变状态的OOP”。它有自己的领域建模、抽象和软件构建方法和文化。我们在OO（面向对象）项目中可以通过采用不变性来获得一些好处。正如Sperber所解释的那样，要获得所有这些，我们需要更深入地研究，并使用适当的函数式语言：</p><p></p><p></p><blockquote>函数式架构广泛使用高级抽象来实现可重用的组件，更重要的是，提供可预测未来的灵活领域模型。在探索和开发这些领域模型时，函数式程序员经常利用数学提供的丰富词汇表。由此产生的抽象从根本上说是由函数语言所提供的高级抽象设施实现的。</blockquote><p></p><p></p><p>InfoQ采访了<a href=\"https://www.linkedin.com/in/sperber/\">Michael Sperber</a>\"，探讨了当前的架构技术工具箱是如何使我们更倾向于做出糟糕的决策，而这些决策在以后很难更改，以及如何解决这个问题。</p><p></p><p>InfoQ：在项目开始时，定义宏观架构的挑战有哪些？</p><p></p><blockquote>MichaelSperber：软件架构的一个流行定义是，它是以后很难更改的决策。在开始时就这样做意味着是在你掌握的信息最少时做决策。因此，这些决策很有可能是错误的。</blockquote><p></p><p></p><p>InfoQ：在上下文之间移动边界变得如此困难的原因是什么？</p><p></p><blockquote>Sperber：在架构界，我们似乎忘了如何在有界上下文或单体中实现模块化，这就是为什么会有“模块化”这个新术语的原因，这意味着常规单体在默认情况下是非模块化的，其内部是紧密耦合的。</blockquote><p></p><p></p><p>InfoQ：所以你的意思是说我们不知道如何在单体中实现松耦合？</p><p></p><blockquote>Sperber：是的。这是因为OO（面向对象）架构的基础是使用可变状态进行编程，即在适当的位置更改对象。这些状态变化导致了不可见的依赖关系，这些依赖关系很难被看见，并且会使构建块纠缠在一起。这不仅会影响项目的功能，还会影响其他质量目标。</blockquote><p></p><p></p><p>InfoQ：你能举个例子吗？</p><p></p><blockquote>Sperber：假设我们选择并行来作为实现高性能的策略：我们需要选择聚合根，并通过互斥来保护对这些根的访问。这是一项乏味的工作，容易出错，也难以快速完成，并且会极大地增加耦合。</blockquote><p></p><p></p><p>InfoQ：如果架构师和开发人员想改进他们做出架构决策的方式，你有什么建议能给到他们？</p><p></p><blockquote>Sperber：即使我们不能在项目中使用函数式语言，也可以尝试一下函数式编程的基础知识，感受一下其中的差异和机会。如果你是FP（函数式编程）的新手，推荐你采用“<a href=\"https://htdp.org/\">如何设计程序</a>\"”作为入门指南，如何你是德语使用者，则推荐<a href=\"https://www.deinprogramm.de/\">DeinProgramm</a>\"。另外推荐两本关于函数编程软件构建的书：<a href=\"https://pragprog.com/titles/swdddf/domain-modeling-made-functional/\">Scott Wlaschin：领域建模函数化</a>\"&nbsp;<a href=\"https://algebradriven.design/\">Sandy Maguire：代数驱动设计</a>\"</blockquote><p></p><p></p><p>原文链接：<a href=\"https://www.infoq.com/news/2023/04/late-arch-functional-programming/\">https://www.infoq.com/news/2023/04/late-arch-functional-programming/</a>\"</p><p></p><p>声明：本文为InfoQ翻译，未经许可禁止转载。</p><p></p><p>延伸阅读：</p><p><a href=\"https://www.infoq.cn/article/2017/11/era-functional-program-language\">函数式编程语言时代已经来临</a>\"</p><p><a href=\"https://www.infoq.cn/article/2009/03/fp-doesnt-catchon\">为什么函数式编程没有流行起来？</a>\"</p><p><a href=\"https://www.infoq.cn/article/2014/03/oo-functional-programming\">面向对象设计原则与函数式编程</a>\"</p>",
    "publish_time": "2023-06-07 11:23:27",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "加速 AI 训练，如何在云上实现灵活的弹性吞吐？",
    "url": "https://www.infoq.cn/article/LdmWVpaBppqBESJokQoN",
    "summary": "<p></p><blockquote>AI 已经成为各行各业软件研发的基础，带来了前所未有的效率和创新。今天，我们将分享苏锐在 AWS 量化投研行业活动的演讲实录，为大家介绍 JuiceFS 在 AI 量化投研领域的应用经验，也希望为其他正在云上构建机器学习平台，面临热点数据吞吐不足的企业提供一些启发。</blockquote><p></p><p></p><h2>1. 背景</h2><p></p><p>JuiceFS 最初是为了解决互联网行业在云上存储大量数据时遇到的问题。随着 AI 技术的发展，一些使用 AI 进行研发的企业开始关注到 JuiceFS，其中包括量化私募机构，有新兴的量化机构，他们从一开始就在云上构建自己的投研平台，也有一些头部老牌基金，他们正从机房开始向云延伸。</p><p></p><p>量化投研是一种利用数学模型对大量市场数据进行分析和挖掘，以获取市场行情的规律和趋势，并进行投资决策的投研方法。随着人工智能技术的快速发展，机器学习和深度学习等算法已广泛应用于量化投研，成为金融行业中率先应用人工智能的领域之一。下面这张图显示了量化机构每天的任务数量。黄线代表任务数量的变化情况。我们可以看到任务数量在上班时间内明显增多，而下班时间则明显减少。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/44/444116f3ab20d16a1fa503970e197123.png\" /></p><p>目前，大部分量化私募使用的 IT 资源都是在机房内，CPU 核数、内存和存储等都是固定的。在这种情况下，当面临波动的任务负载时，可能会出现以下问题：</p><p>机房提供的是固定算力，在低峰期会有过剩的资源，而在高峰期研究员则需要排队等待，这会导致资源的浪费和效率的降低。研究员希望他们的想法能够尽快得到处理，公司也希望最大限度地利用资源。突然出现的任务负载增加可能会导致计算资源不足。例如，当研究员有灵感时或者在验证新的论文时，需要进行大规模的验证。此外，当招募新员工或高峰期到来时，计算资源不足也会成为一个问题。由于机房的扩容周期通常为三个月，而硬件缺货时甚至需要等待六个月，供应链的周期很难满足业务需求。</p><p></p><p>弹性计算是解决上述这些问题的最简单方法。</p><p></p><h2>2. 弹性计算的优势</h2><p></p><p>在过去的两年中，已经注意到越来越多的量化私募从机房开始转向云端。对于直接在云端构建研究平台的机构，可以直接在 AWS 这样的公有云上进行部署。这样，所有的资源都可以轻松地使用，只需简单地点击鼠标即可启动或关闭，从而大大缩短 time to market 的时间。不再需要等待硬件选型和购买的时间，而且所有的计算资源都可以根据需要进行弹性使用，无论需要多少算力都可以灵活分配。</p><p></p><p>然而，对于那些已经有一定历史的量化私募机构而言，它们已经建设了大量的 IDC 设施，因此不可能将这些全部放弃，然后转向公有云。因此，它们需要先充分利用这些 IDC 设施，并将其与云计算结合起来。</p><p></p><p>混合云可能是更多机构要选择的方案。</p><p></p><p>机房内现有的资产可以作为一个固定算力，满足平均或低峰期的算力需求。增量部分可以在云上进行扩展，使用的资源按秒计费。通过这种方式，机房内已有的资产也能够得到更好地利用。</p><p></p><p>弹性算力还有一个重要好处，就是可以更快地使用最新的硬件设备。相比之下，如果自己购买硬件，可能需要等待 3 年或 5 年的折旧期限，这使得我们难以跟上硬件的更新换代。弹性算力的好处也在于可以帮助我们更快地跟上技术的发展。</p><p></p><h2>3. 弹性环境中，存储的痛点</h2><p></p><p>计算只是简单的处理过程，而数据则需要进行持久化，因此存储通常比计算更难弹性化。在弹性计算过程中，需要考虑如何保留已经处理的数据，以便后续使用。同时，在扩展算力时，需要确保存储能够支持相应的需求，并具备高可用性和可扩展性。否则，可能会面临数据丢失或性能下降等问题。</p><p></p><h3>痛点一：性能、成本和效率如何取舍？</h3><p></p><p>在进行存储选型时，企业通常会考虑三个因素：性能、成本和效率。这些因素在存储系统的设计中相互影响。在存储选型时需要综合考虑不同方案的优缺点，以找到最适合企业需求的方案。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8f/8faa5ce8a220bd6bd172ac249248a3ca.png\" /></p><p></p><p>在模型训练阶段，用户通常会追求高性能的存储方案。例如，机房里提供全闪存的文件存储，AWS 上提供 FSx for Lustre 等产品都会选择更高级的硬件，这些方案都能提供出色的吞吐性能。然而，存储成本也较高，因此需要寻找低成本的全量数据归档存储方案。在机房里，一些高密度存储方案也可以降低成本，在云上会选择使用 Amazon S3 等对象存储服务。</p><p></p><p>为了追求成本和性能，用户在机房和云上都会构建出两套异构的存储。一套低成本的存储系统用于全量归档，另一套高性能的存储则用于模型训练。这种多套存储的环境也带来了管理数据迁移、数据冷热等问题，尤其是在多个区域、多个云环境下，这种情况会变得更加复杂。</p><p></p><p>因此，我们需要有效的解决方案，既能快速、省钱，同时又能高效地管理存储。</p><p></p><h3>痛点二：存储系统扩容慢</h3><p></p><p>运维过存储系统的人深知存储系统扩容的缓慢。存储系统本质上是一组硬盘，用于存储数据。当需要增加存储容量时，通常的想法增加硬盘。然而，在分布式存储系统中，扩容并不是这么简单的过程，需要对所有数据进行重新平衡，以便更有效地管理存储系统中的所有数据。此外，存储硬件的性能是有限的，如果一部分性能用于数据迁移，就会影响线上业务的服务能力。</p><p></p><p>举一个简单的例子，我们将一个巨大的存储集群缩小为仅三台机器，每台机器配备两个硬盘，存储一些数据，如下方这个图示。在分布式系统中，为了确保数据的安全，我们通常会将数据复制多份，通常存储三份。下图，圆圈、三角形和菱形各代表一个文件，在分布式架构中，每个图形都有 3 份。</p><p><img src=\"https://static001.geekbang.org/infoq/4c/4c6d1ac407d83d364735de3e3a243225.png\" /></p><p>（分布式存储-三备份）</p><p></p><p>当存储容量不足时，需要加入新的机器，以扩展存储空间。然而，新的数据并不会只存储在新的机器上，而是必须对现有数据进行重平衡以更有效地管理所有数据。在这种情况下，数据会使用一套算法从旧位置移动到新位置。同时，硬盘提供的能力是有限的，如果我们将一部分固定能力用于数据迁移，则无法为线上业务提供服务。</p><p><img src=\"https://static001.geekbang.org/infoq/3d/3d88e5261e975409a66c05f71c4dac0b.png\" /></p><p>（存储扩容-数据再平衡）</p><p></p><p>运维工程师们深知存储集群扩容的挑战，选择何时迁移和股票投资中择时一样让人难以预测。如何平稳地搬家，以及如何在不影响线上业务的情况下避免事故，都是一项复杂的任务。仅仅靠自动机制很难完成好，因为业务负载的情况是难以预知的，通常要老司机手动挡干预。除了扩容，当集群中出现了硬盘损坏的情况，就要将其中的数据转移至新的硬盘中，同样要确保每份数据存储了三份。因此，即便不进行扩容，大规模的存储集群仍然需要每天都进行数据搬迁。</p><p></p><p>在这种困难的存储系统扩容条件下，当新的算法、研究员和灵感出现时，存储通常会成为拖累。</p><p></p><h3>痛点三：可用容量很多，性能不足了，为什么？</h3><p></p><p>之前提到的是容量不足导致需要扩容，但是在量化私募这个领域中，我们发现大部分的客户需要扩容的原因并不是容量不足，而是由于吞吐性能不足。</p><p></p><p>硬盘提供的性能是有限的，当现有硬盘的性能跑到极限时，就必须购置新的硬盘来满足性能需求。许多量化客户，虽然他们的存储容量还有很大的富余，但为了满足新的性能需求，他们仍需要扩容。</p><p></p><p>举个例子，假设现在需要读取的数据存储在下图圆圈所示范围，要求性能非常高，那么圆圈所在硬盘的性能已经达到了极限；接着另一个研究员需要读取同样存储在这块硬盘上的三角形，但这块硬盘的性能也已经到了极限，因此读取三角形数据的速度一定会很慢。</p><p><img src=\"https://static001.geekbang.org/infoq/dc/dcad788c8dd19e0ef325c3a5564e8a5b.png\" /></p><p>（性能不足引发的存储扩容，造成存储空间闲置）</p><p></p><p>为了实现增加性能，需要将三角的数据迁移到新的硬盘上，就是图上没有标红的硬盘。</p><p></p><p>为什么这个问题在量化私募行业特别明显呢？因为我们的行业最原始的数据可能来自于市场数据。以 A 股的数据为例，过去 10 年的数据加在一起才 240G，而今天硬盘容量都好几 TB 一块，这就意味着我们要处理的原始数据实际上是有限的，可能最多也只有几十 TB 的规模。但这几十 TB 的原始数据可能被数十到数百名研究员共享，他们需要同时读取同一份数据，这导致了性能瓶颈的出现。这是量化行业使用数据的一个特点，即由于数据的共享和读取需求，容量充足但性能不足的情况很常见。这也是最开始有量化基金找到 JuiceFS 这个产品去帮他们解决的一个问题。</p><p></p><p>因此，对于这类会产生热点数据的场景，即对计算的弹性要求更加极致时，匹配性能可伸缩的存储，可以更好地实现整体的性能和成本得到的平衡。</p><p></p><h2>4.JuiceFS 如何实现性能扩展 &amp; 性价比</h2><p></p><p>在2017年，当我们开始研发 JuiceFS 时就决定要为云环境设计。我们注意到当时市场上的所有文件存储产品都是在 2005 年前后或更早设计的，甚至还有一些是在 90 年代设计的。这些产品仍然广泛地用于量化私募行业中。由于我们的基础设施的基础资源环境已经发生了变化，因此在开发新产品时，必须跟上我们现在所使用的环境的发展趋势。</p><p><img src=\"https://static001.geekbang.org/infoq/88/88a32efa86b42faffafe267c2565a48f.png\" /></p><p>（JuiceFS 企业版架构图）</p><p></p><p>在这张图中，三个虚线框代表了文件系统的三个核心组件，元数据引擎、数据引擎和客户端，它们一起实现了文件系统的关键功能。</p><p></p><p>文件系统可以简单地理解为一种用于组织、管理和访问文件和目录的技术。比如我们电脑上使用的硬盘，文件系统提供了一种与它的交互方式，即通过文件和目录（文件夹）的形式来访问和管理存储在硬盘物理介质上的数据。</p><p></p><p>例如，在 Linux 中一块硬件格式化文件系统后，挂载到一个目录上，看到的是一个目录树，其中包含目录、文件夹和文件。每个文件都可以设定权限，并具有时间戳，记录了创建时间、上次修改时间等，称为元数据。它们存放在上图左下角的虚线框内所示的 Juicedata 自研元数据引擎中，这个引擎很大程度上决定了文件系统的性能。</p><p></p><p>右下角虚线框代表文件内容的存储。这部分是 20 年前存储系统最重要的功能之一，需要管理大量机器和其中的硬盘。例如，在 HDFS 中的 DataNode，Ceph 中的 RADOS，Lustre 中也有 ChunkServer，这些服务需要完成例如数据分块、存储、副本管理、迁移等，很复杂。在云环境中，S3 已经将这个问题解决得非常出色。因此，当我们决定在云上重新构建一个文件存储系统时，我们不再需要管理大量硬盘。相反，我们可以站在 S3 的基础之上，为其增加更多的功能。在 JuiceFS 的设计中，用户存储在 JuiceFS 文件系统中的所有文件内容直接存储在用户自己的 S3 Bucket 中。</p><p></p><p>图片上方展示的是一个客户端访问系统，JuiceFS 提供了最标准的 POSIX 接口，并支持像 HDFS 等不同的 API 互通。这让开发者在编写程序时更加便利，可以根据自己的需求选择最适合的接口。此外，我们还提供了性能扩展功能，以满足更高的性能需求。</p><p></p><p>因为 S3 提供的性能和语义不足以满足高性能的模型训练或投研分析的需求，所以我们需要一种中间解决方案来弥补这些不足。例如，PyTorch 需要的是一个 POSIX 文件系统，但 S3 只提供HTTP API。</p><p></p><p>JuiceFS 就是这样一种解决方案，它可以将数据存储在 S3 中，同时提供 POSIX 和其他 API，以满足不同应用的需求，并通过内部优化来提供最佳的性能。</p><p></p><p>要解决上文提到量化机构面临热点数据吞吐不足的问题，需要介绍JuiceFS的缓存功能。当用户的 GPU 计算节点需要读取数据时，所有数据的访问都会首先从 S3 中拉取一次，然后存储在JuiceFS 缓存中。在以后的访问中，所有数据都可以在缓存中被命中，从而获得与全闪存文件存储相当的性能。JuiceFS 的缓存层可动态伸缩，为用户提供可弹性扩展的吞吐性能。此外JuiceFS 的缓存层可以与计算节点上的高性能存储形成一个分层的多级缓存，进一步提高性能。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3c/3ca891c4eed1f773fc253709217ab940.png\" /></p><p>（JuiceFS 企业版缓存）</p><p></p><p>总结一下，使用JuiceFS，数据都可以保存在低成本的 S3 中，降低了存储成本；同时， 通过一个动态的缓存层为 S3 提供了加速，还实现了吞吐性能的弹性扩展。</p><p></p><p>如果热点数据仍然存储在有限数量的 NVMe 盘中，扩大整个缓存层的规模实际上并没有太大的意义。为了解决数据热点问题，可以使用 cache 分组的方式，让热点数据在每个组中都得到存储。用户只需要根据需求建立多个缓存组，通过简单的配置调整即可在短时间内完成，非常有效地解决了数据热点问题。</p><p><img src=\"https://static001.geekbang.org/infoq/b6/b63b32357c7bf872b79951c4f6d50219.png\" /></p><p>（JuiceFS 企业版 缓存分组）</p><p></p><p>用户可以设置自己的 cache group，或者为每个团队设置自己的 cache group，这样可以扩展热点数据的性能，并且整个系统的性能也可以基本上线性扩展。此外，如果用户在下班后关闭了这些cache group，就可以避免额外的成本。</p><p></p><p>对于那些仍然拥有机房资产的量化私募机构，可以使用混合云部署方案，数据仍然存储在 S3 中，但可以预热到机房中的 cache group 进行计算加速。</p><p><img src=\"https://static001.geekbang.org/infoq/dc/dcb8f47cf5f93f90f531688df1fdc373.png\" /></p><p>（JuiceFS 混合云部署架构图）</p><p></p><p>JuiceFS 可以在云环境和机房环境中使用两个 JuiceFS 实例进行数据复制，而这个过程对用户来说是透明的，无需进行额外的操作。JuiceFS 自动将热数据存储在高性能的 cache 层中，这意味着不论用户在机房还是云上执行任务，都可以快速访问热数据，从而解决了现有资产和云上弹性部署的混合使用问题。</p><p>相关阅读：<a href=\"https://www.infoq.cn/article/owwaIZuU262HfUFFy8pd\">乾象投资：基于 JuiceFS 构建云上量化投研平台</a>\"现场视频（03: 07 开始）：https://www.laohu8.com/m/live/1762844022350878</p><p></p><h3>关于作者</h3><p></p><p>苏锐, Juicedata 合伙人，作为 1 号成员参与创建 JuiceFS，一直深度参与在开源社区中支持开发者使用 JuiceFS。</p>",
    "publish_time": "2023-06-07 11:48:17",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Ruby 到底怎么了？",
    "url": "https://www.infoq.cn/article/S4OwR90G5vcViPzeYSdD",
    "summary": "<p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/jnxbfeksmvpfjqgd135p\">不要学习“网红”编程语言</a>\"</p><p>&nbsp;</p><p>Ruby 和 Ruby on Rails 在早期就出现在 Web 开发领域了。然而，虽然现在 JavaScript 和 Python 都占据了主导地位，Ruby 还是仍然占有一席之地。</p><p>&nbsp;</p><p>如果你已经在网络开发领域摸爬滚打了足够长的时间，你就会目睹许多语言和框架的兴起与衰落。Ruby 及其 Web 应用框架 Ruby on Rails 是最耀眼的明星。2008 年，Rails 推出仅仅三年后，该杂志就提出了这个框架是否会成为 <a href=\"https://www.infoworld.com/article/2633881/ruby-on-rails-rolls-onward-and-upward.html'\">Java 的继承者</a>\"的问题，指出它将 Web 开发中的繁重工作挤出，并且与 Ruby 相关的初创公司看到了大量的风险资本投资。</p><p>&nbsp;</p><p>15 年之后，认为 Ruby 会取代 Java 的想法看起来很荒谬。<a href=\"https://www.tiobe.com/tiobe-index/\">TIOBE 索引</a>\"可以跟踪各种语言的查询，而 Ruby 在我最后一次查看的时候，排名是第 16 位。它位于 MatLab 和 Object Pascal 之间。（Java 位列第四，令人敬佩。）Filted 是一家提供虚拟环境的公司，求职者可以在虚拟环境的世界里，让未来的雇主看到他们的技能。这家公司甚至连 <a href=\"https://www.filtered.ai/blog/the-top-8-programming-languages-for-filtered-hiring-assessments\">Ruby 都不在它的八大语言中</a>\"。他们表示，雇主在 Ruby 上的测试时间仅为 0.5%。</p><p>&nbsp;</p><p>但是，现在还不能将 Ruby 与 FORTRAN 或 ALGOL 一起放在博物馆里。我与 Ruby 的现任和前任程序员进行了访谈，以了解这门语言的兴起和衰落。他们与大家分享了他们对于 Ruby 是怎样和为何被排除在最流行语言之列的观点，以及为何他们觉得 Ruby 还有前途。</p><p>&nbsp;</p><p></p><h2>Ruby 最辉煌的时候</h2><p></p><p>&nbsp;</p><p>Ruby 最初之所以如此受欢迎，有很多原因，但是最重要的一点是，Ruby 可以让开发速度更快、更容易，尤其是前端应用。这一点没有改变。“Ruby on rails 依然是一个很好的方法，可以让一支小型团队拥有大型团队的影响力。”《编程 Ruby 3.2》（Programming Ruby 3.2）的合著者 Noel Rappin 说，“这依然是从零到真正的有价值的产品的最快捷的途径。”</p><p>&nbsp;</p><p>“当涉及到为用户提供坚实的前端体验时，Ruby 一直是最好的语言，”BoutiqueSetup.net 的电子商务教练 Pulkit Bhardwaj 解释说，“它为最终用户提供了易用性，并提供了稳定、安全的体验。它还提供了一个实验的空间，因为 <a href=\"http://ruby-for-beginners.rubymonstas.org/your_tools/irb.html\">Interactive Ruby</a>\" 能够逐行提供即时的表达结果。”</p><p>&nbsp;</p><p>Ruby 一直以来都和一个强大的开源河区有着密切的关系。Kevin Trowbridge 是 Qwoted 的首席技术官，他认为，语言本身的性质与此有很大关系。“它是所有编程语言中最有文化的，”他说，意思是“它编写起来很简单，很容易读懂。这也是你拥有一个很强大的社区的原因，以及它的哲学，即它为产品、开发人员的生产力和幸福感而优化。”</p><p>&nbsp;</p><p>但是，这些优势并没有对 Ruby 和 Ruby on Rails 产生什么实质性的影响。在此期间，其他的语言和架构也没有停滞不前。Matthew Boeh，2006 年就开始了 Ruby 的开发，他说，“Rails 是在 Web 转型和发展的关键时期诞生的。它既受益于这种增长，也推动了这种增长，但它不会是唯一的成功故事，这是一个预料之中必然发生的事情。”</p><p>&nbsp;</p><p>Boeh 最近在 <a href=\"https://www.infoworld.com/article/3538428/what-is-typescript-strongly-typed-javascript.html\">TypeScript</a>\" 商店的 Lattice 担任高级软件工程师的工作。“你可以说 Ruby 是它自己成功的牺牲品，因为它的社区是近年来命令行复兴的重要推手，”他说，“在 21 世纪早期，它向那些从未听说过 Lisp 的人介绍了 REPL 驱动的开发，向那些会被 Perl 的 CPAN 吓跑的人介绍了包管理，向那些高度企业化的 Java 世界以外的人介绍了测试驱动的开发，诸如此类。这些都是当今桌上的筹码。但是它们都被 Ruby 爱好者普及和使用了。”</p><p>&nbsp;</p><p></p><h2>Ruby 的挑战者：JavaScript 和 Python</h2><p></p><p>&nbsp;</p><p>如果说现在有一种语言在 Ruby 曾经统治过的领域里占主导地位，那就是 JavaScript。只有当这种语言摆脱浏览器，接管世界其他地方时，这才成为现实。New Relic 的开发者关系部主任 Jemiah Sius 说：“随着 JavaScript 成长为全栈语言，工程师已经能够用一种语言甚至是共享代码库来构建前端、后端和移动项目。Ruby 很容易学习，而且有很高的安全标准，还有一个活跃的社区。但当有人想到全栈时，他们会想到 JavaScript——<a href=\"https://www.infoworld.com/article/3210589/what-is-nodejs-javascript-runtime-explained.html\">Node.js</a>\"，React，或任何他们喜欢的框架。”</p><p>&nbsp;</p><p>Qwoted 的 Trowbridge 指出，JavaScript 之所以能够承担起这一重任，因为这种语言已经从开发人员曾经鄙视的语言中得到了改进。事实上，随着时间的推移，它变得越来越像 Ruby 了。“浏览器供应商努力使其形式化、标准化、简化和增强，”他说，“它比以前的 JavaScript 好多了。”</p><p>&nbsp;</p><p>“目前形式的 JavaScript 生态系统在 2004 年是不可想象的，这不仅需要命令行的复兴，也需要 Web 平台的腾飞。”Lattice 的 Boeh 补充道。“你知道吗，从 1999 年到 2009 年，发布一个新版本的 JavaScript 标准花了整整十年的时间？<a href=\"https://www.infoworld.com/article/3654830/ecmascript-2022-blesses-class-elements-top-level-await.html\">我们现在每年都有一个</a>\"。Rails 在最后一个时期变得非常重要，在那个时期，即使不懂 JavaScript，也可以成为一个全栈开发人员。”</p><p>&nbsp;</p><p>与此同时，<a href=\"https://www.infoworld.com/article/3204016/what-is-python-powerful-intuitive-programming.htm\">Python</a>\" 已经主导了当今最热门的发展领域之一，即人工智能和机器学习。Bhardwaj 说：“Python 在科学界很受欢迎，因为他们可以比以往更快地建立模型和算法的原型，所以它比 Ruby 领先好几年。另一方面，Ruby 被认为执行缓慢，并未受到开发者的重视。”New Relic 的 Sius 也同意这一观点，他说：“当有人想到一种通用语言，可以创造从游戏到虚拟现实，到人工智能，再到机器学习的一切时，每个人都知道 Python 是最大的赢家。”</p><p>&nbsp;</p><p></p><h2>Ruby 的衰落</h2><p></p><p>&nbsp;</p><p>有很多原因促使 JavaScript 和 Python 超越了 Ruby，它们超越了语言本身的品质。 “理论上 Python 和 Ruby 是相当的，”Qwoted 的 Trowbridge 说， “它们都是动态的、解释性的脚本语言，最适合在服务器上使用。它们不能非常有效地使用内存，因此运行起来很昂贵，但它们具有令人难以置信的灵活性，所以它们编写起来也相当快，对初学者也很友好。”</p><p>&nbsp;</p><p>但是当涉及数据科学时，Python 就有很大的优势，因为像 <a href=\"https://www.infoworld.com/article/3278008/what-is-tensorflow-the-machine-learning-library-explained.html\">TensorFlow</a>\" 和 <a href=\"https://www.infoworld.com/article/3336192/what-is-keras-the-deep-neural-network-api-explained.html\">Keras</a>\" 这样的库现成可用。Bhardwaj 说：“这些框架使程序员很容易开发数据可视化和编写机器学习的程序。”</p><p>&nbsp;</p><p>同时，JavaScript 已经催生了看似无穷无尽的库，开发人员可以轻松地下载并调整这些库，以满足几乎任何目的。Trowbridge 说：“作为一个技术专家，你可以按照你认为正确的方式进行你自己的英雄之旅，”。但是说到 JavaScript 时，“这些库都很出色。为什么要忽略所有这些呢？”</p><p>&nbsp;</p><p>其中许多库是由社区成员开发的，这激发了其他人的贡献，这是参与开源的任何人都熟悉的雪球效应。但有一个大玩家在这里产生了巨大的影响。Python 的 TensorFlow 被 Bhardwaj 称为“游戏规则的改变者”，由谷歌发布，该公司紧随学术界的步伐，将 Python 作为自己的内部脚本语言。作为主流网页浏览器的制造商，谷歌显然也对提升 JavaScript 有兴趣。而且 Trowbridge 认为谷歌在使 JavaScript 比以前更快、更有内存效率方面功不可没。他说：“在某些方面，它感觉几乎像一种低级语言。同时，人们普遍认为 Ruby 在性能上是落后的，部分原因是它缺乏同样的企业赞助商，没有资源来改进它。”</p><p>&nbsp;</p><p>而在一些 Ruby 曾经兴盛一时的领域，它并没有被另一种语言所取代；相反，情况已经发生了变化，所以这些领域已经无法辨认了。“我最初是为一家当地创意公司的客户制作营销网站和在线商店，我认为这也很容易错过网络开发世界的底层已经被自动化的程度，Lattice 的 Boeh 说。“在几年内，整个业务不再可行--没有人对这样的定制网站感兴趣，因为他们可以用 WordPress 或 Shopify 做得相当体面。”</p><p>&nbsp;</p><p></p><h2>为什么 Ruby 不会消失</h2><p></p><p>&nbsp;</p><p>尽管如此，Ruby 并没有消失---而电子商务巨头 Shopify 是最大的原因之一，因为 Ruby on rails 是它的主要开发平台。“Ruby 仍然是创建电子商务应用程序的最佳选择，因为它的动态功能和灵活性，”BoutiqueSetup.net 的 Bhardwaj 说，“你可以通过不同的模块构建你的应用程序，并在以后再修改它们。这使得更新应用程序以获得更多功能变得更容易。”</p><p>&nbsp;</p><p>虽然 Shopify 显然没有像谷歌这样的规模，但它的目标仍然是作为 Ruby 的赞助人，就像谷歌为其喜爱的语言所做的那样。例如，Shopify 最近开发了 YJIT，这是一个即时编译器，可以提高 Ruby 的性能，并已被纳入 Ruby 标准。</p><p>&nbsp;</p><p>Qwoted 的 Trowbridge 表示，Ruby 也在蓬勃发展“作为一种优秀的服务器端‘胶水’语言，它可以很好地用于 Web 应用程序的服务器组件，就像在 Rails 的‘仅 API’模式中一样。” 他指出，在某些方面，这种角色“使 Ruby 基本上回到了它的起点。”</p><p>&nbsp;</p><p>总而言之，几乎所有与我交谈过的人都认为，Ruby 和 Ruby on Rails 将继续在许多环境中使用。Trowbridge 说：“有许多语言仍然被大量使用并具有相关性，而不像以前那样热闹了，我会把 Java 作为最主要的例子，并建议 Ruby 和 Java 将分享类似的发展轨迹。”</p><p>&nbsp;</p><p>最后，从 Ruby 的社区中，你似乎找不到其他语言对 Ruby 的热情和热情，即使是那些在许多领域“击败”Ruby 的语言。例如，Lumenova AI 的首席技术官 Cosmin Andriescu 说，“ Rails 仍然有一个主要的优势，它拥有大量的 Ruby gem 库，相对于很多 JavaScript 框架来说，这些框架拥有不稳定的 API，在所有必要的 Web 开发工具中都不够成熟。”Boeh 更直截了当地将 Python 描述为“我见过的最讨厌使用它的人的语言”。</p><p>&nbsp;</p><p>“我仍然在个人项目中使用 Ruby，并希望我能够再次专业地使用它，”Boeh 补充说，“现在 Ruby 世界有很多令人兴奋的发展，截至 6 个月前，还有很多的就业机会。Ruby 永远不会再成为下一个大的新事物，但我认为它将继续存在下去。”</p><p>&nbsp;</p><p>作者简介：</p><p>&nbsp;</p><p>Josh Fruhlinger，作家兼编辑，住在洛杉矶。</p><p>&nbsp;</p><p>原文链接：</p><p>&nbsp;</p><p>https://www.infoworld.com/article/3687219/whatever-happened-to-ruby.html</p><p>&nbsp;</p><p></p>",
    "publish_time": "2023-06-07 13:40:03",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何构建大模型时代下的智能算力？",
    "url": "https://www.infoq.cn/article/ACXL3WviaTtr2U0v5NlB",
    "summary": "<p>云计算加速了企业数字化和智能化的进程。当 AI 开始更深层次地被嵌入到企业发展的链路之中，新一代算力、大模型、AI 基础设施的推出就变得势在必行。正如百度集团执行副总裁、<a href=\"https://xie.infoq.cn/article/3e1ff530358326aa5ec803fdd\">百度智能云</a>\"事业群总裁沈抖所言：“AI 原生时代正在加速到来，这对云计算的基础设施提出了新要求，全栈融合、端到端优化、提供极致的资源效能和模型效能，成为未来智能计算发展的三大主流方向。”</p><p></p><p>为了让大家更全面地了解 AI 技术的前沿发展趋势及技术实践，百度智能云团队特推出《大模型时代的 AI 基础设施——百度 AI 大底座》系列云智公开课，该课程将围绕“AI 算力构建”、“AI 框架和 AI 中台”、“大模型训练实践”三大主题展开，由多位专业大咖倾情打造，揭秘核心技术，<a href=\"https://xie.infoq.cn/article/4f60309ffa73a431c5cdcfac2\">直击</a>\"行业痛点。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/2e/20/2ea9487e8054fa153dcccb8aec2fc920.png\" /></p><p></p><p>目前我们都关注到大模型热潮下 ，AI 算力升级已是大势所趋。</p><p></p><p>大模型落地第一步就是要构建起能够提供大规模的 AI 算力的基础设施，包括将海量 AI 算力进行聚合的高性能网络、高效率的异构资源管理方式、为大模型落地的各个环节提供匹配的存储加速方案、为向量检索及其海量数据存储提供的各项方案等。</p><p></p><p>面对以上技术挑战，<a href=\"https://www.infoq.cn/article/ONi9RGciXT9EKSAHNcRz\">百度智能云</a>\"探索出一套“武林秘籍”。自 6 月 20 日起，这些“秘籍”将在《大模型时代的 AI 基础设施——百度 AI 大底座》系列云智公开课第一大主题——“AI 算力构建”课程直播中陆续进行解读，欢迎大家关注并预约~</p><p></p><p>&nbsp;第一讲：《大规模 AI 高性能网络的设计和实践》</p><p>了解大模型训练对网络系统的要求了解百度百舸·AI 异构计算平台的高性能网络的特点了解高性能网络支撑大模型训练的相关实践</p><p></p><p>&nbsp;第二讲：《GPU 容器虚拟化全场景实践和新能力发布》</p><p>了解各类 AI 任务对 GPU 容器虚拟化的不同要求，以及百度百舸的相应解决方案了解 GPU 容器虚拟化在各类场景的成功案例，以及最新的大模型推理场景下的实践了解双引擎 GPU 容器虚拟化今年推出的新能力，支持多种类型任务同时运行，满足新场景（云游戏、智驾等）对资源利用率的要求</p><p></p><p>&nbsp;第三讲：《面向大模型的存储加速方案设计和实践》</p><p>了解大模型相对传统 AI 给存储带来的全新挑战了解大模型各场景下的存储问题解决思路了解百度沧海存储大模型加速解决方案和实践</p><p></p><p>&nbsp;第四讲：《大模型的向量数据存储方案设计和实践》</p><p>了解大模型落地各个环节的数据库应用场景了解大模型的向量数据的存储挑战了解百度智能云对向量数据存储方案的设计和实践</p><p></p><p>&nbsp;第五讲：《向量检索在大模型应用场景的设计和实践》</p><p>了解向量检索在大模型时代的意义、关键技术和架构了解百度智能云 BES 在大模型应用场景的向量检索设计思路和实践</p><p></p><p>第一讲课程《大规模 AI 高性能网络的设计和实践》上线时间为 2023 年 6 月 20 日 19:30-21:00，目前课程报名通道现已开启，立即点击<a href=\"https://www.infoq.cn/form/?id=1631&amp;utm_source=1&amp;sign=iq_647ee213d1be4\">链接</a>\"进行报名，还有机会抽奖赢取周边大礼哦！</p>",
    "publish_time": "2023-06-07 13:45:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "编程已死，AI当立？教授公开“唱反调”：AI 还帮不了程序员",
    "url": "https://www.infoq.cn/article/2Ep75mzLWcNK09BcGvya",
    "summary": "<p><a href=\"https://www.infoq.cn/article/s5tL9MAGc53wXWqrgc9R\">GitHub Copilot</a>\"、<a href=\"https://www.infoq.cn/article/HFSPasQ7SXZ9QzdFXhGO\">ChatGPT</a>\" 等 AI 产品的火爆出圈，让更多人看到 AI 在编程方面展现出的极强能力。一时间，关于“AI 取代程序员”、“AI 当立、编程已死”的言论不绝于耳。</p><p></p><p>前段时间，前哈佛大学计算机科学教授、谷歌工程主管 Matt Welsh 在芝加哥计算机协会的一个虚拟会议上表示，ChatGPT 和 GitHub Copilot 预示着编程终结的开始。Welsh 断言，生成式 AI 将在 3 年内<a href=\"https://www.infoq.cn/article/qR0xQrafpDi92bTPal6t\">终结编程</a>\"。</p><p></p><p>但也有一些人对此持反对意见。近日，Constructor Institute 教授、Eiffel Software 首席技术官 Bertrand Meyer 在ACM上发表文章公开“唱反调”，他认真研究了一番 ChatGPT 到底是怎么编程的，最终得出结论：AI 还帮不了程序员。</p><p></p><h2>ChatGPT编程实验</h2><p></p><p></p><p>前段时间，Meyer 通过一系列文章讨论过如何解决虚构出来的二进制搜索问题，虽然内容看起来都不错，每篇文章也都提出了自己的解答版本，但其实大部分都是错的。（延伸阅读：<a href=\"https://bertrandmeyer.com/2020/03/26/getting-program-right-nine-episodes/\">https://bertrandmeyer.com/2020/03/26/getting-program-right-nine-episodes/</a>\"）</p><p></p><p>以此为素材，Meyer 把这些文章提交给了ChatGPT（版本 4）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/01f93fd85371f85ff2875b127c57f77d.png\" /></p><p></p><p>AI 选手先是对问题做出了描述：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f1/f1fc6dfe5dee02b30a9df84bfbaa94eb.png\" /></p><p></p><p>这个问题实际可以出现在任意数量的元素上，而不仅仅是两个。但想要证明一个程序不正确，举出一个反例就足够了（但要证明它是正确的，则需要证明其适用于所有示例）。Meyer 只问了程序是否正确，并没提具体要怎么修复，但ChatGPT还是热心给出了如下建议：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b1/b192e3721f8a53a43f047b8b579e5d39.png\" /></p><p></p><p>这里的评论部分确实很有帮助：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d9/d9ae6c0d790d9ab5927f52f5de3804cc.png\" /></p><p></p><p>ChatGPT说得没错，逻辑很通。但在认真查看建议的替换代码之后，Meyer 发现了某些可疑的部分。于是，Meyer 进一步提问：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/24/24f01c6894d78da98c807b773277d56e.png\" /></p><p></p><p>在尝试修复 Meyer 的错误时，ChatGPT输出了另一个同样有错的版本，只不过错得跟 Meyer 不一样。值得一提的是，ChatGPT 每次都试着给出新的版本——在纠正之前错误的同时，却又带来了新问题。</p><p></p><p>Meyer 还发现，ChatGPT特别擅长道歉：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3b/3b765bea47429bb36f76e9c96a59a71e.png\" /></p><p></p><p>ChatGPT一直在自说自话，积极向 Meyer 推荐它认为经过修正的解决方案：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/66/6655b37b7b01edb974a3fcf3a6648bf7.png\" /></p><p></p><p>到这里，Meyer 甚至不打算尝试最新版本正不正确。有经验的程序员朋友都知道，揪住一个案例不断添加特定修复，绝不是生成正确程序的最佳途径。</p><p></p><p>于是 Meyer 也选择继续保持礼貌：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5c/5c70e17b78e7eecccfc40cfc57ae4f91.png\" /></p><p></p><p>精彩的来了：ChatGPT 决定向 Meyer 介绍循环不变量的概念！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7f/7f537627cc40808c40cdca0b1f6a94b2.png\" /></p><p></p><p>Meyer从未明示或暗示称“需要一种更系统的方法来验证算法的正确性”，他只是想知道ChatGPT要如何证明它推荐的答案是对的，但绝对没有使用“系统的”或者“验证”这类字眼。之所以出现这一幕，可能是基于大型语料库的统计推理给了ChatGPT信心，让它认定用户肯定会质疑输出代码的正确性，然后要求以系统方法给出验证。</p><p></p><p>Meyer 继续追问了下去：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/56/56f5da5d8a21deb6ade1d8c20a1a2e96.png\" /></p><p></p><p>ChatGPT随后给出了很好的答案，甚至包括ACM计算调查当中收录的循环不变量调查内容。而且它仍然是先夸一句再解释问题，非常客气：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0e/0e1d33e1765e326b99eee2878404aa0a.png\" /></p><p></p><p>到这里，Meyer 不打算再继续追问了。</p><p></p><p>作为一名程序员，Meyer 知道如何解决问题，但和大多数程序员一样，他自己也会经常犯错误。他希望 AI 编程助手可以监督自己，提醒他注意陷阱并在犯错时给予纠正。换言之，他希望 AI 能成为高效有用的结对编程伙伴。但实验结果并非如此：AI 编程工具就像个自大的研究生，聪明且博览群书，也始终保持着礼貌并愿意道歉。可回头来看，它仍然<a href=\"https://www.infoq.cn/article/RL7iFW2SqO0Ppv4msCsL\">草率且不够可靠</a>\"，所谓的帮助对 Meyer 来说毫无用处。</p><p></p><h2>现代AI成果并不能生成正确的程序</h2><p></p><p></p><p>Meyer 认为，当前生成式 AI 工具确实能够在某些领域出色地完成工作，甚至胜过大部分人类的水平：相关结果来得很快、令人信服，乍看之下甚至不亚于顶级专家，原则上也没什么大问题。比如生成营销手册，或者是粗略翻译网站内容之类，它的翻译效果相当不错，此外还有医学影像分析等等。</p><p></p><p>但编程的要求完全不同，它对产出程序的正确性有着严格要求。开发者可以容忍一定的错误，但其核心功能必须正确。如果客户下达的指令是买进100股微软股票，同时卖出50股亚马逊股票，那程序绝不应该执行相反的操作。专业程序员有时候会犯错，这时候就看 AI 助手能不能帮上一把了。</p><p></p><p>然而，现代 AI 成果并不能生成正确的程序：它产出的程序实际是从之前见过的大量原有程序中推理而成。这些程序看似靠谱，但却无法完全保障正确性。（这里所说的现代 AI，是将其与早期 AI 区分开来——后者试图通过专家系统等方法重现人类的逻辑思维，但在很大程度上已经失败。如今的 AI 完全通过统计推理实现基本功能。）</p><p></p><p>Meyer 表示，尽管 AI 助手时有惊艳发挥，但它们并不是逻辑的产物，而是玩弄文字的高手。大语言模型都拥有流畅的表达能力，非常擅长生成看起来没什么大错的文本。虽然这样的表现对于许多应用场景已经足够，但仍然不适合编程需求。</p><p></p><p>现在的 AI 能够帮助用户生成基础框架，以大致靠谱的效果给出答案。但也就止步于此了。以目前的技术水平来看，它还完全输出不了能够正常运行的程序。</p><p></p><p>但这对软件工程行业来说并不是坏事。Meyer 认为，面对种种“编程已死”的宣传，这次实验提醒我们不管人类程序员还是自动编程助手，都需要规范的约束，并且任何产出的备选程序都有待验证。在最初的惊艳过后，人们终将意识到这种一键式生成程序的能力并没有多大作用。考虑到它往往无法正确实现使用者想要的效果，草草上线的自动化功能也许反而有害。</p><p></p><h2>写在最后</h2><p></p><p></p><p>Meyer 并不是唱衰 AI 编程，他认为，审慎的态度或许能帮助我们构建出具备可靠能力的终极 AI 系统。</p><p></p><p>目前，AI 技术尚处于早期发展阶段，这些局限性也并不是永远跨越不了的障碍。也许在未来的某一天，生成式 AI 编程工具能够克服这些障碍。但要让它具备真正的编程能力，还得在规范和验证方面做一番深入的探讨和研究。</p><p></p><p>那么问题来了：你是否使用过 AI 编程工具？使用的是哪款工具？准确度如何？这些工具是否真的帮助到了你？欢迎在评论区写下你的使用体验。</p><p></p><p>原文链接：</p><p></p><p><a href=\"https://cacm.acm.org/blogs/blog-cacm/273577-ai-does-not-help-programmers/fulltext\">https://cacm.acm.org/blogs/blog-cacm/273577-ai-does-not-help-programmers/fulltext</a>\"</p>",
    "publish_time": "2023-06-07 14:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "YTsaurus：EB 级存储和处理系统现已开源",
    "url": "https://www.infoq.cn/article/8DbvVsqtUTcxz9z3BrqE",
    "summary": "<p>本文最初发布于Yandex。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fd/fdbff4e3f0643edea068390938b455cc.png\" /></p><p></p><p>大家好，我叫Maxim Babenko，是Yandex分布式计算技术部的负责人。今天，我们很高兴地宣布，<a href=\"https://ytsaurus.tech/\">YTsaurus平台</a>\"开源发布。YTsaurus是Yandex开发的关键基础设施类大数据系统之一，之前我们称之为YT。</p><p>&nbsp;</p><p>YTsaurus是我们近十年努力的成果，我们希望把它与全世界分享。在这篇文章中，我们将介绍YT的发展历史、我们开发它的动机、它的主要功能以及最适合的领域。</p><p>&nbsp;</p><p><a href=\"https://github.com/YTsaurus/YTsaurus\">GitHub存储库</a>\"中包含YTsaurus的服务器代码、使用K8s的部署基础设施、系统的Web界面，以及C++、Java、Go和Python等流行编程语言的客户端SDK。所有内容都遵循Apache 2.0许可，也就是说，任何人都可以下载并根据自己的需要修改它。</p><p>&nbsp;</p><p></p><h1>YT是如何成为Yandex最重要的大数据系统的</h1><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/79/7908547f30ee895be58f6ede99a743e7.png\" /></p><p></p><p>&nbsp;</p><p>故事要从2006年说起。那时，Yandex已经是一家相当大的公司。在哪里存储以及如何处理公司的数据成了不小的难题。当时，我们的关注点是来自多个服务的日志。日志处理涉及各种分析，可以解决从改进机器学习模型到分析用户行为（在服务功能或界面变化时）的各种任务。</p><p>&nbsp;</p><p>可扩展弹性数据存储系统的理念已经开始流行。它可以执行并行计算，而且无需担心数据的物理位置和集群物理组件的容错能力。</p><p>&nbsp;</p><p>2004年，来自谷歌的Jeffrey Dean和Sanjay Ghemawat发布了<a href=\"https://research.google/pubs/pub62/\">MapReduce：简化大型集群上的数据处理</a>\"。在很大程度上，它预测了分布式计算行业未来十年的发展。毫不奇怪，Yandex开发了类似MapReduce模型的实现，我们称之为YAMR，即Yet Another MapReduce。</p><p>&nbsp;</p><p>我们以破纪录的速度从零开始构建了YAMR。无疑，这对公司内部基础设施的发展产生了巨大的影响。然而，随着时间的推移，事情变得越来越明显，YAMR中许多最初的设计选择使得系统无法有效地演进和扩展。例如，YAMR主服务器是单一故障点，无法扩展。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/57/57fd3176201e9dab6a45d91b133343cd.png\" /></p><p></p><p>&nbsp;</p><p>乍一看，自己构建基础设施的决定似乎是NIH综合症的一个典型案例，我们甚至没有考虑过使用像Apache Hadoop这样的开箱即用的解决方案。但也不完全是这样。2015年9月，Yandex的一队工程师前往加州，与一些在生产环境中使用Hadoop技术栈的人会面，询问他们关于限制因素、操作特性以及Hadoop将如何发展的问题。</p><p>&nbsp;</p><p>但那时，Hadoop技术栈已明显落后于YAMR，我们已经支持纠删码（erasure coding）和IPv6连接。问题还不止这些。</p><p>&nbsp;</p><p>经过全方位的分析之后，我们决定放弃使用Hadoop的想法。与此同时，我们必须在YAMR的渐进式开发和革命性重写之间做出选择，最终，我们选择了后者。在这之前的五年时间里，我有幸成为一小群狂热爱好者中的一员，开始了一个代号为YT的项目。只需适当的改进，YT就完全有可能取代YAMR。</p><p>&nbsp;</p><p>重要的是要明白，替代YAMR并不简单。在高峰期，该系统管理的集群总计有数千个节点，有大量应用程序的代码是基于YAMR API的。因此，改进YT和从YAMR迁移花费了我们许多年的时间。这个故事本身有许多很有趣的细节，或许值得单独写一篇文章。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9c/9c7cd780d86da994defccafc0c7b8462.png\" /></p><p></p><p>&nbsp;</p><p>自2017年以来，Yandex就只有一个MapReduce系统，在规模和功能方面的开发一直持续到今天。如今，我们公司运营着数个YT集群，规模从几台机器到几万台服务器不等。最大的安装存储着艾字节的数据，使用了几百万核CPU内核和几千个GPU卡，夜以继日地进行着计算。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/26/26fad86e80f4311bed316e12f9c2fb14.png\" /></p><p></p><p>&nbsp;</p><p></p><h1>YTsaurus：名字起源</h1><p></p><p>“YT会开源吗？”，我们花了将近7年的时间来回答这个问题。我们的答案是：YT不会开源，但YTsaurus会！</p><p>&nbsp;</p><p>我们最初开发的系统叫“YT”。代码库的许多部分中都有这个缩写。Yandex内部流传着一个说法，“YT”这个缩写代表了“Yandex Table”，可能是受到谷歌著名的Big Table系统的启发，但我们并没有找到任何可靠的证据可以支持这个推测。</p><p>&nbsp;</p><p>当决定以开源的方式发布这个系统时，我们发现很难保留原来的名称。其中一个原因是，这个两个字母的组合通常与某个流行的视频托管平台有关。</p><p>&nbsp;</p><p>最终，我们选定了“YTsaurus”这个名字。它有着同样可爱而熟悉的“YT”前缀，我们团队一直把这个项目看成一个有生命的东西。现在，我们终于知道它是什么种族了！</p><p>&nbsp;</p><p>在我们的代码库和文章中，我们经常将“YTsaurus”缩写为“YT”。我们自己也还在适应全名的过程中。</p><p>&nbsp;</p><p></p><h1>系统功能</h1><p></p><p>我们设计的系统既灵活又可扩展。目前，它的功能并不局限于经典的MapReduce技术。在本节中，我将描述YTsaurus开源版本提供的主要技术能力，从底层存储到高级计算原语。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dc/dc0ecd643e4cc5148cd94cace24349eb.png\" /></p><p></p><p>&nbsp;</p><p></p><h2>Cypress：可靠高效的数据存储</h2><p></p><p>任何大数据系统的核心都是各种日志、统计数据、索引以及其他结构化或非结构化数据的存储。YTsaurus以Cypress为基础构建。Cypress是一种基于树的具有容错能力的存储，其功能可以简单描述如下：</p><p>以目录、表（结构化或半结构化数据）和文件（非结构化数据）为节点的树状命名空间透明地将大型表格式数据分片为块，我们可以将表视为单个实体，而无需过多考虑物理存储的细节支持表格式数据基于行和列的存储机制支持使用不同压缩级别的各种编解码器（如lz4和zstd）压缩存储支持使用具有不同控制和计算策略的各种纠删编解码器进行纠删编码，而这些策略具有不同的冗余参数和允许的损失类型支持层次类型和数据排序标志的表达性数据图式化后台复制和修复被删除的数据，无需人工干预事务语义支持嵌套事务和快照/共享/排他级锁事务可以影响许多Cypress对象并无限期持续灵活的配额核算系统</p><p>&nbsp;</p><p>Cypress的核心是一个可复制且可横向扩展的主服务器，存储着关于Cypress树状结构的元数据，以及集群中所有表的块副本的组成和位置。主服务器以Hydra为基础实现为一个可复制状态机。Hydra是一种类似Raft的专有共识算法。</p><p>&nbsp;</p><p>Cypress实现了一个具有容错能力的弹性数据层。下面将要介绍系统几乎所有方面都用到了这一层。</p><p>&nbsp;</p><p></p><h2>MapReduce计算和通用调度器</h2><p></p><p>尽管在人们的眼中，MapReduce已不再是什么新技术，也没什么与众不同之处，但它在我们系统中的实现还是很值得关注的。我们仍然用它进行需要高吞吐量的PB级数据计算。</p><p>&nbsp;</p><p>YTsaurus中的MapReduce具有以下特点：</p><p>丰富的基本操作模型：经典的MapReduce（具有不同的Shuffle策略并支持多阶段分区）、Map、Erase、Sort，以及一些考虑了输入数据“排序”的经典模型扩展。计算可横向扩展：操作被划分成作业，在独立的服务器上运行。单个操作可支持数十万个作业。灵活的分层计算池模型可以提供即时和完整性保证，并可以在消费者之间公平地分配未充分利用的资源（无保证）。向量资源模型支持按不同的比例申请不同的计算资源（CPU、RAM、GPU）。使用<a href=\"https://github.com/yandex/porto\">Porto</a>\"容器化机制按CPU、RAM、文件系统和进程名称空间隔离在计算节点容器中执行的作业。可扩展的调度程序可以为集群提供多达一百万个并发任务。在进行更新或调度器节点出现故障时，几乎所有的计算进度都会保留。</p><p>&nbsp;</p><p>YT不仅支持执行MapReduce操作，还支持在集群上部署用户提供的任何代码。</p><p>&nbsp;</p><p>对于副作用不明确的代码，YT使用“普通（vanilla）”操作来运行。平台的许多其他组件也都用到了这个功能，下文会进行讨论。</p><p>&nbsp;</p><p></p><h2>动态K-V存储表</h2><p></p><p>实际上，MapReduce范式不适合构建响应时间低于秒级的交互式计算管道。问题不仅在于如何处理数据，还在于如何存储数据。</p><p>&nbsp;</p><p>YT的静态表就像HDFS中的一组文件，可以作为MapReduce计算的输入和输出。但是，它们不能用在交互式场景中，因为它们是与速度缓慢的持久存储介质绑定的。通常，对于交互式场景，应用程序会使用键值存储。键值存储可以横向扩展，并能提供低延迟的读写访问。</p><p>&nbsp;</p><p>幸运的是，2014年，我们开始在YT框架内开发动态表。它们部分基于Apache HBase模型，可以横向扩展，并使用分布式文件系统作为底层存储。不过，不同于Apache HBase，动态表被有机地整合到了整个生态系统中：它们相当于Cypress的节点，可以用于许多需要静态表的场景。</p><p>&nbsp;</p><p>例如，在YT中，你可以创建一个动态表作为MapReduce操作的结果，并将其用于基于键的快速搜索和插入。同时，你可以创建一个后台MapReduce进程，处理来自动态表的数据样本，并计算关于它的一些统计信息。</p><p>使用<a href=\"https://en.wikipedia.org/wiki/Multiversion_concurrency_control\">MVCC</a>\"模型存储数据。用户可以通过键或时间戳查找值。可扩展性：动态表会被划分成片（按键的范围划分），由单独的服务器提供服务。事务性：动态表是OLTP存储，可以修改不同表不同分片中的多个行。容错能力：提供分片服务的节点如果出现单点故障，那么分片会被移到另一个节点而不丢失数据。隔离性：为了实现负载隔离，提供分片服务的节点会被分组成包，驻留在不同的机器上。在单个键甚至单个值的层面上进行冲突检查。热数据响应来自内存。内置了类似SQL的语言，用于查询扫描和分析。</p><p>&nbsp;</p><p>除了具有K-V存储接口的动态表外，系统还支持实现了消息队列抽象的动态表，即主题和流。你也可以把这些队列看成是表，因为它们由行组成，并且有自己的模式。在事务中，你可以同时修改K-V动态表和队列中的行。这样一来，你就可以基于YT的动态表构建具有Exactly Once语义的流处理。</p><p>&nbsp;</p><p></p><h2>YQL</h2><p></p><p>YQL是一种基于SQL的查询语言；它是YT之上构建的第一个高级原语。YQL之于YT相当于Hive之于Hadoop。这种技术让用户可以用SQL编写简单的查询，而不是自己编写代码构建一系列MapReduce操作。下面是一个例子：</p><p><code lang=\"null\">SELECT\n    region,\n    AVG(age) AS avg_age_in_region,\n    COUNT(DISTINCT ip) AS ips_count\nFROM `//home/production/users`\nGROUP BY region\nORDER BY avg_age_in_region;</code></p><p>&nbsp;</p><p>如今，许多大数据任务都可以表述为简单的SQL查询。没有YQL，我们的生态系统就是不完整的。它是用于在大型数据集上进行即时分析和常规生产计算的最流行的工具之一。</p><p>&nbsp;</p><p>YQL有以下好处：</p><p>强大的图执行引擎，可以构建具有数百个节点的MapReduce管道，并可以在计算过程中进行调整。通过将子查询存储在变量中，就可以使用SQL将复杂的数据处理管道构建成依赖查询和事务链。任意复杂度的查询，其并行执行都是可预测的。高效地实现连接、子查询和窗口函数，而且对它们的拓扑或嵌套没什么限制。大量的函数库。支持C++、Python和JavaScript自定义函数。支持通过CatBoost和TensorFlow使用机器学习模型。在准备好的计算实例上自动执行一小部分查询，绕过MapReduce以减少延迟。</p><p>&nbsp;</p><p></p><h2>CHYT</h2><p></p><p>不用说，大多数读者朋友们都听说过ClickHouse。2016年，这个DBMS成为Yandex开源技术的先驱，并于2021年成为一家独立的公司ClickHouse Inc.。</p><p>&nbsp;</p><p>如今，ClickHouse是最受欢迎的分析型数据库之一，它基于列的执行引擎非常高效，并集成了各种BI系统。ClickHouse其中一个很好的特性是源代码中存储和计算部分实现了良好的隔离，这使得我们在2018年构建出了CHYT——ClickHouse计算引擎将YTsaurus作为存储集成。</p><p>&nbsp;</p><p>在YTsaurus生态系统中，CHYT提供了以下功能：</p><p>在YT中对静态表进行快速分析查询，延迟只有亚秒级。重用YTsaurus集群中已有的数据，而无需将其复制到单独的ClickHouse集群。能够通过ClickHouse的原生ODBC和JDBC驱动程序集成第三方可视化系统。</p><p>&nbsp;</p><p>我注意到，集成是在相当低的层次上完成的。这让我们可以充分挖掘YTsaurus和ClickHouse的潜力，即：</p><p>支持读取静态和动态表。部分支持YTsaurus事务模型。支持分布式插入。将YTsaurus内部格式的列式数据CPU高效地转换为内存中的ClickHouse表示。主动数据缓存，在某些情况下，允许完全从实例内存中读取查询执行数据。</p><p>&nbsp;</p><p>ClickHouse服务器代码会在上述普通操作发生时运行，使用的计算资源与MapReduce计算相同。从这个意义上讲，YTsaurus集群于我们内部的CHYT集群而言是一朵计算云。</p><p>&nbsp;</p><p>这使得不同的用户或用户团队可以在单个YT集群上运行多个CHYT集群，彼此完全隔离，用和云类似的方式解决资源隔离问题。</p><p>&nbsp;</p><p></p><h2>SPYT</h2><p></p><p>2019年，Yandex推出了SPYT，这个系统将Apache Spark作为YT数据的计算引擎集成。与CHYT类似，普通YTsaurus操作为Spark集群提供计算资源。Apache Spark的设计初衷就是为了方便连接第三方存储并将其作为数据源。</p><p>&nbsp;</p><p>SPYT在YTsaurus的生态系统中也是根深蒂固。得益于与第三方系统丰富的集成能力，它成了编写ETL工作流的主要方法之一。在底层，Spark使用了一个灵活的分布式计算优化器，可以最大化中间数据的内存存储，并可以实现具有多个连接的计算管道。</p><p>&nbsp;</p><p></p><h2>各种SDK</h2><p></p><p>对于用特定语言编写的系统，SDK通常是自动生成的或由用户社区的某个人编写的（长时间得不到维护）。但我们用当下流行的语言（C++、Python、Java、Go）开发了所有的API。对于每一种SDK，我们都仔细考虑了它与系统交互时的所有细微的不同之处。</p><p>&nbsp;</p><p>因为可能存在网络故障和其他错误，所以我们用不同语言编写的客户端库都可以重试请求，包括读写大量数据。在创建每一种库时，我们都考虑了这门语言的特性，并尽可能使用这些特性来简化它与系统的交互。</p><p>&nbsp;</p><p></p><h2>Web界面</h2><p></p><p>对于一个有成千上万的用户使用的系统，必须要有一个用户友好的Web界面。而且，我们有意没有为用户和管理员创建单独的Web界面，这帮助我们避免了爱好者们匆忙创建Web管理界面的情况，那很常见：毕竟用户侧更重要，在管理员面前就没什么可尴尬的了。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/da/da4c44c6798303a3006c442b1427723f.png\" /></p><p></p><p>&nbsp;</p><p>你可以通过YTsaurus Web界面完成以下工作：</p><p>通过Cypress浏览文件、表和其他对象。创建、重命名或删除Cypress对象，并修改它们的属性。执行和查看MapReduce计算。跨所有引擎执行和查看SQL查询历史——YQL、CHYT、动态表SQL。管理系统：监控集群组件的运行状况，创建、删除或禁用用户，管理访问权限和配额，查看集群组件版本等。</p><p>&nbsp;</p><p></p><h1>技术层面看YTsaurus</h1><p></p><p>服务器端代码大部分都是用C++编写的。我们喜欢这种语言，因为它的功能很丰富，用它编写的代码很高效。在开源发布YTsaurus之后，我们希望把大量的开发成果分享出来，或许你可以把它们作为单独的C++原语来使用。</p><p>&nbsp;</p><p>服务器端代码是使用Clang编译器和CMake构建系统构建的。</p><p>&nbsp;</p><p>系统的个别部分是用Go、Python和Java编写的。还有一个API，让你可以使用上述4种编程语言开发与YTsaurus交互的应用程序。</p><p>&nbsp;</p><p>代码库会自动与内部存储库同步。因此，外部总是可以获得YTsaurus的最新版本。</p><p>&nbsp;</p><p>YTsaurus在x86-64 Linux服务器上运行。</p><p>&nbsp;</p><p></p><h2>部署和管理</h2><p></p><p>在Yandex，我们安装了超过20套YTsaurus。它们的规模和配置差异很大，从单集群5台主机到20K+不等。YTsaurus还集成了几个内部Yandex系统，包括身份验证、访问控制、审计、监控、硬件管理和容器编排。所有这些系统最大限度地减少了管理集群的工作量。</p><p>&nbsp;</p><p>为了方便用户，我们投资开发了<a href=\"https://operatorframework.io/operator-capabilities/\">二级操作符</a>\"，用于在Kubernetes中自动部署YTsaurus集群，并支持标准的升级机制，可以在停机状态下升级到新版本。该操作符让你可以在几分钟内把YTsaurus集群部署到Minikube、公有云或本地Kubernetes上。</p><p>&nbsp;</p><p>通过修改元数据树（Cypress）中的系统节点，可以动态地管理集群配置。使用基本的Cypress命令（如list、get、set和remove），你可以创建帐户、添加用户或计算池、授予目录访问权限或退役集群节点。</p><p>&nbsp;</p><p>特别值得注意的是动态配置各个组件的能力：通过修改特定属性，你可以调整缓存大小、心跳周期或节点上的日志记录设置。</p><p>&nbsp;</p><p>YTsaurus是一个计算平台，因此，用户代码的执行是隐式的。为了运行和隔离不受信任的代码，YTsaurus使用了Yandex开发的容器化系统<a href=\"https://github.com/yandex/porto\">Porto</a>\"。为了在多租户集群中实现完全的用户隔离，建议将Porto安装为<a href=\"https://kubernetes.io/docs/setup/production-environment/container-runtimes/\">Kubernetes CRI</a>\"。这可以充分释放YTsaurus作业隔离和在不同操作中使用自定义环境的能力。</p><p>&nbsp;</p><p>当然，如果没有可观测性工具——日志记录、定量监测和跟踪，运营大型分布式系统是不可能的。YTsaurus会生成结构化日志，用于审计和监控用户操作，并且提供了详细的调试日志，用于更深层次的问题诊断。此外，该系统支持Prometheus格式的指标导出，并通过Jaeger gRPC协议进行链路追踪。</p><p>&nbsp;</p><p></p><h1>基于YTsaurus可以构建什么？</h1><p></p><p>让我们通过几个例子看一下Yandex是如何使用这个系统的。</p><p>&nbsp;</p><p>YTsaurus最具启发性、最典型的用例之一是创建DWH。例如，来自Yandex Taxi、Yandex Eats、Yandex Deli和Yandex Delivery的订单以原始格式以最小的延迟接收到YTsaurus动态表中。每月的数据量可达数百TB。</p><p>&nbsp;</p><p>然后，我们用各种工具处理订单，例如，大多数分析型数据集市是通过YQL和SPYT进行准备的。数据总量超过6PB。CHYT用于即时分析，各种可视化则在Yandex DataLens中创建。Yandex的其他服务中也存在类似的用例，如Yandex Market、Yandex Music和Yandex Travel。</p><p>&nbsp;</p><p>还有一些非常具体的用例。例如，<a href=\"https://yandex.com/supercomputers\">Yandex所有的三台超级计算机</a>\"都由YTsaurus调度程序管理。许多具有不同类型GPU的节点连接到YT，并分布在不同的池树中。这使得用户可以显式指定所需的GPU模型，并使用存储在YTsaurus中的数据。</p><p>&nbsp;</p><p>目前，YTsaurus动态表存储的数据达PB级，大量的交互服务都以它们为基础构建。Yandex广告团队是最大的内部客户之一。在HighLoad++ 2022大会上，我的同事们<a href=\"https://youtu.be/bfaKRthHM0Y\">探讨</a>\"了他们在YTsaurus上构建交互式流处理的方法。</p><p>&nbsp;</p><p></p><h1>结语</h1><p></p><p>YTsaurus是一个有着丰富历史的大工程。如果你感兴趣，就请看一看YTsaurus，找一些对自己有用的东西。也许你会喜欢我们在代码中实现的技术解决方案，或者找个机会部署YTsaurus并实际地试用一下。</p><p>&nbsp;</p><p>如果你感兴趣并想帮助我们开发这个系统，那就太好了。欢迎通过<a href=\"https://t.me/ytsaurus\">Telegram聊天室</a>\"进行反馈，或者发起pull请求。</p><p>&nbsp;</p><p>原文链接：<a href=\"https://medium.com/yandex/ytsaurus-exabyte-scale-storage-and-processing-system-is-now-open-source-42e7f5fa5fc6\">https://medium.com/yandex/ytsaurus-exabyte-scale-storage-and-processing-system-is-now-open-source-42e7f5fa5fc6</a>\"</p><p></p><p>延伸阅读：</p><p><a href=\"https://www.infoq.cn/video/ZVZVBM7JhoQZ4OfwBvXe\">云原生存储技术与实践</a>\"</p><p><a href=\"https://www.infoq.cn/article/WdWsV9v1vSMeRwMfYJgw\">喜马拉雅 KV 存储演进之路</a>\"</p>",
    "publish_time": "2023-06-07 14:36:32",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "老板说得太多了？OpenAI要求删帖：Sam公布了OpenAI的近况和短期路线图",
    "url": "https://www.infoq.cn/article/xZaNyw2QsZcxmNXUvkZv",
    "summary": "<p>近日，OpenAI创始人<a href=\"https://www.infoq.cn/article/fsUlW2TuwyUsNOArrik9\">Sam Altman</a>\"与Humanloop CEO Raza Habib以及其他20位开发者面对面进行了一场闭门交流，交流中他们讨论了OpenAI的近况与未来的规划。HumanLoop 是一家帮助开发者在大语言模型上构建应用的公司。</p><p></p><p>有参加了此次交流会的开发者表示，因为这是闭门交流会，所以Altman在交谈中表现出了开放的心态，讨论内容既涉及开发者面临的实际问题，也延伸到了商业竞争、AI监管和开源等问题。</p><p></p><p>此次对话的重点内容被Raza Habib 记录了下来并公布在了网络上。但随后，应<a href=\"https://www.infoq.cn/article/3TR13Qp694BJ8TeOi1xV\">OpenAI</a>\"的要求，此内容已被删除。然而，这一删帖的举动引发了外界的强烈好奇和质疑。</p><p></p><p>有网友表示：“一家从互联网上收集信息做产品的公司，居然要求从互联网上‘删除’一篇文章，这种行为真的很讽刺。”</p><p></p><p>外界纷纷猜测<a href=\"https://www.infoq.cn/article/bs03EeaTE6gkQRLqj2Jt\">OpenAI</a>\"删帖的原因，在HackNews上，一位现场的参会者认为之所以删帖是因为OpenAI不希望在公开场合谈论一些公司重点规划。</p><p></p><p>也有网友认为，OpenAI这种行为有炒作的嫌疑，毕竟GPU不足已经不再是什么秘密了，看看英伟达的股价就知道了。</p><p></p><h2>OpenAI也严重依赖GPU</h2><p></p><p>在Altman与Raza的讨论中证实，目前OpenAI正受到<a href=\"https://www.infoq.cn/article/1UyH2okZUKWlbwby3dQV\">GPU</a>\"资源的严重限制，导致不少短期计划已经被迫推迟。几家大客户还抱怨了API的可靠性和速度表现。Altman认同这些意见，并解释称主要问题源自GPU供应不足。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c6/c6b7c7b49aaacd42f7cabbfb0283214e.jpeg\" /></p><p></p><p>更长的32k上下文还无法全面推广。OpenAI还没能克服O(n^2)注意力扩展问题，所以尽管10万到百万级token的上下文窗口预计将在今年内实现，但进一步扩展还需要突破性研究的加持。</p><p></p><p>微调API目前同样受到GPU资源的限制。因为还没用上Adapters或LoRa等高效微调方法，所以OpenAI的微调运行和管理仍须占用大量算力。未来微调的支持效果会更好，OpenAI甚至可能为社区贡献模型设立专门的市场。</p><p></p><p>专用容量产品也无法独善其身。OpenAI目前提供专用容量，为客户提供模型的私有副本。但要获取这项服务，客户需要预先支付10万美元。</p><p></p><p>在<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1542\">大语言模型和AIGC</a>\"大爆发后，各AI企业对于GPU的需求比以往任何事时候都要紧迫。英伟达的高端 GPU 芯片价格已经达到了每片数万美元，AI 基础设施公司正在以数万台的价格购买它们。</p><p></p><p>马斯克也曾表示他已经为他的新AI初创公司 X.AI 购买了3万多块英伟达顶级的 H100 GPU 芯片，每个价格超过3万美元。此外，<a href=\"https://www.infoq.cn/article/5m5afBSrqT4ipYqxCwDi\">Meta </a>\"和<a href=\"https://www.infoq.cn/article/Vyg6CQgbtTu9SKbuk9oX\">微软</a>\"已经是今年<a href=\"https://www.infoq.cn/article/e95bPU2tu1o9eGQqmQvP\">英伟达</a>\"GPU 的最大买家之一（Meta 可能排名第一，因为<a href=\"https://www.infoq.cn/article/4iDmM3PgXmvELorwQ8M3\">Facebook</a>\"、Instagram、WhatsApp 和 Messenger应用程序中有很多AI增强的东西要用到GPU）。</p><p></p><p>这就是为什么从Sam Altman 会表示OpenAI 也很缺GPU的原因。Sam Altman也曾在媒体采访中公开强调过 GPU 的可用性如何影响 OpenAI 今年及以后的计划。</p><p></p><h2>OpenAI的短期路线图</h2><p></p><p>除了强调GPU的重要性外，Altman还分享了OpenAI的API近期路线图（暂定）。</p><p></p><p>Altman表示，2023年是OpenAI发展的重要一年，他们有一些令人兴奋的计划和目标。</p><p></p><p>价格更低、速度更快的GPT-4——这将是OpenAI接下来的首要任务。总体而言，OpenAI希望尽可能降低“智能实现成本”，因此将随时间推移不断控制API价格。更长的上下文窗口——在不久的未来，上下文窗口将扩展至高达百万token。微调API——微调API将被扩展至最新模型，但具体形式还是要根据开发者的实际需求来决定。有状态API——如今在我们调用聊天API时，需要反复提交相同的对话历史并一次又一次为相同的token付费。未来，OpenAI将发布能够记住对话历史记录的API版本。2024年将是OpenAI全面拥抱多模态性的一年。<a href=\"https://www.infoq.cn/article/6LAGtDef93ytGip8YVd1\">GPT-4</a>\"版本就演示了一部分多模态功能。这意味着模型将能够处理多种类型的输入数据，例如文本、图像、音频和视频。但在GPU资源匮乏问题得到缓解之前，这项功能还无法面向所有用户开放。</p><p></p><h2>插件“尚未完成市场匹配”，可能不会很快出现在API中</h2><p></p><p>不少开发人员都想通过API访问ChatGPT插件，但Altman表示这类插件在短期内不会发布。除了浏览等简单场景之外，插件的实际使用情况表明还没有找到理想的产品市场契合点。在他看来，很多人说是希望在ChatGPT中开发应用，但真正想要的其实是把ChatGPT纳入他们的应用。</p><p></p><h2>OpenAI承诺不会动客户的“奶酪”</h2><p></p><p>不少开发人员担心OpenAI最终可能发布与其产品构成竞争关系的新成果，所以在使用OpenAI API做开发时颇感紧张。Altman强调OpenAI不会发布除<a href=\"https://www.infoq.cn/article/yEH16RlsRgsqK3xHHmU5\">ChatGPT</a>\"以外的其他产品。</p><p></p><p>Altman承认做平台的巨头企业确实掌握着不少杀手级应用程序，而ChatGPT的目标是把这些企业转化成客户来改进API。ChatGPT只想成为工作场景下的超级智能助手，OpenAI也不会涉足众多其他GPT用例。</p><p></p><h2>需要监管，但也需要开源</h2><p></p><p>虽然Altman呼吁对未来的模型加以监管，但他觉得当前的模型并没有什么风险，并认为粗暴监管甚至封禁绝对是个大错误。他重申了自己对于开源重要意义的信念，并表示OpenAI正在考虑开源GPT-3模型。之所以目前还没有开源，主要原因是他担心绝大多数个人和企业都没有能力托管和运行这种大语言模型。</p><p></p><h2>扩展定律仍然成立</h2><p></p><p>最近，不少文章宣称“超大规模AI模型的时代已经终结”，Altman对此做出了纠正。</p><p></p><p>OpenAI的内部数据表明，模型性能仍然遵循扩展定律（The scaling laws），即扩大模型规模将带来更高的性能。问题在于扩展的速度将无法维持，因为OpenAI在短短几年内已经把模型放大了数百万倍，而这显然不是一条能够长期走下去的道路。</p><p></p><p>OpenAI仍会继续打造出体量更大的模型，只是具体规模可能每年增加1到3倍，而不再像之前那样迅速跨越几个数量级。</p><p></p><p>扩展定律仍然有效这一事实，对于AGI（通用人工智能）的发展时间表有着重大影响。扩展定律其实是一种假设，即我们可能已经拥有了建立AGI所需要的大部分<a href=\"https://www.infoq.cn/article/FOpwJE40BLIOZqHrCMji\">底层技术</a>\"，剩余工作只是运用现有方法并扩展出更大的模型和数据集。如果扩展时代就此结束，那我们也许得重新探索通往AGI的前进方向。好在定律仍在，很大程度上预示着AGI横空出世的时间也许已为期不远。</p><p></p><p>参考链接：</p><p></p><p><a href=\"https://web.archive.org/web/20230531203946/https://humanloop.com/blog/openai-plans\">https://web.archive.org/web/20230531203946/https://humanloop.com/blog/openai-plans</a>\"</p>",
    "publish_time": "2023-06-07 14:41:19",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "中国企业研发高效能白皮书-Code Review篇",
    "url": "https://www.infoq.cn/article/GbzsfXjVsoxv5JIarZk9",
    "summary": "<h3>研究背景</h3>\n<p>近年来中国企业研发正在从粗放型走向精益型，研发工作的“高效能”成为几乎每个研发团队共同的追求。<br />\n中国软件服务产业也在近 5-10 年中得到了飞速发展，技术服务的边界不断拓展，赋能研发高效的产品层出不穷，适合中国研发环境的技术服务体系在不断完善。从结果上看，中国企业正在高效能研发的路径上快速前进。</p>\n<p>本份报告以中国高效能研发企业为研究对象，尝试解读市场中具有代表性的高效能研发解决方案。本次报告由五个篇章组成，如 CI/CD、企业级软件架构、研发效能管理等主题。研究小组期待可以通过研究，帮助中国企业研发团队获得高效能研发新知。</p>\n<p>Code Review篇是本次报告的第四篇章，主要研究了Code Review 是如何帮助研发团队提升效率。该篇章不仅说明了Code Review 的概念和价值，而且对Code Review 的发展与现状进行了梳理。</p>\n<p>同时，报告中也解读了极狐GitLab Code Review的最佳实践，在案例中向读者展现Code Review 工具是如何提升Code Review效率的。</p>\n<h2>目录</h2>\n<ul>\n<li>Code Review 的定义与背景</li>\n<li>Code Review 发展现状</li>\n<li>Code Review 最佳实践</li>\n</ul>",
    "publish_time": "2023-06-07 14:53:44",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "专访SeaTunnel：首个国人主导的数据集成领域Apache顶级项目是如何炼成的",
    "url": "https://www.infoq.cn/article/663dGKTkZZ9XTtEpikl3",
    "summary": "<p>采访嘉宾 | 郭炜、高俊</p><p>编辑 | Tina</p><p>&nbsp;</p><p>北京时间 2023 年 6 月 1 日，全球最大的开源软件基金会 Apache Software Foundation（以下简称 ASF）正式宣布 Apache SeaTunnel 毕业成为 Apache 顶级项目(TLP, Top Level Project)。</p><p>&nbsp;</p><p>Apache SeaTunnel 于 2021 年 10 月申请加入 Apache 孵化器，不到 2 个月，便以“全票通过”的优秀表现正式成为 Apache 孵化器项目。2023 年 5 月 17 日，Apache 董事会通过 Apache SeaTunnel 毕业决议，结束了为期 18 个月的孵化，正式确定 Apache SeaTunnel 成为 Apache 顶级项目。</p><p>&nbsp;</p><p><a href=\"https://www.infoq.cn/article/5IQEJ5QdztMBKrYDt7yW\">这是首个由国人主导并贡献到 ASF 的大数据集成领域的顶级项目</a>\"，为了了解项目的起源、发展过程，以及开源心得，InfoQ 采访了 Apache&nbsp;SeaTunnel 项目的关键成员。</p><p>&nbsp;</p><p>采访嘉宾简介：</p><p>郭炜，Apache&nbsp;基金会成员；Apache&nbsp;DolphinScheduler&nbsp;PMC&nbsp;Member；Apache&nbsp;SeaTunnel&nbsp;Mentor。</p><p>高俊，Apache SeaTunnel PMC Chair。</p><p>&nbsp;</p><p></p><h2>Apache SeaTunnel的起源</h2><p></p><p>&nbsp;</p><p>InfoQ：在大数据体系里，Apache SeaTunnel起到的主要作用是什么？</p><p>&nbsp;</p><p>郭炜：目前，大数据体系里有各种各样的数据引擎，有大数据生态的Hadoop、Hive、Kudu、Kafka、HDFS，也有泛大数据库体系的MongoDB、Redis、ClickHouse、Doris，更有云上的AWS S3、Redshift、BigQuery、Snowflake，还有各种各样数据生态 MySQL、PostgresSQL、IoTDB、TDEngine、Salesforce、Workday等。我们需要工具让这些数据之间能互联互通，那么Apache SeaTunnel就是打通这些复杂数据源的利器，它可以简单、准确、实时地把各种数据源整合到目标数据源当中，成为大数据流动的“高速公路”。</p><p>&nbsp;</p><p>InfoQ：Apache SeaTunnel是如何发挥作用的，其关键原理、核心设计是什么？</p><p>&nbsp;</p><p>郭炜：面对成百上千的数据源，我们需要一个简单高效的架构来解决各种各样的数据源之间数据集成的问题。Apache SeaTunnel由三大部分组成，源连接器（Source Connector）、传输计算引擎（SeaTunnel Zeta、Flink、Spark），目标连接器（Sink Connector）。简单来说，源连接器就是实时地读取数据源端（也许是JDBC，也许是Binlog，也许是非结构化Kafka或者SaaS API，AI数据模型），把这些数据转化成SeaTunnel可以理解的标准数据格式再传送给传输计算引擎，传输计算引擎将对这些数据进行处理（例如数据格式变化，分词等）和分发，最终Sink Connector将SeaTunnel数据格式变化为目标端的格式存入目标数据库。当然，其中有非常复杂的高性能数据传输、分布式快照、全局Checkpoint、两阶段提交等，来确保数据可以高效、快速地传递到目标端。</p><p>&nbsp;</p><p>最近社区还提交了SeaTunnel-Web，让用户不仅可以用类SQL语言来做Transform，还可以利用界面拖拽来直接打通不同的数据源。任何一个开源用户都可以方便地扩展自己使用数据源的Connector，然后提交到Apache社区，让更多的人一起使用它。同时，你也可以快速使用别人贡献的Connector来快速解决自己企业数据源之间的打通问题。目前，SeaTunnel已经支持了包括CDC、云存储、数据库、SaaS等100多个数据源，让企业方便地打通各种各样的数据源。人人为我、我为人人 ，这在开源的Apache SeaTunnel项目中体现得淋漓尽致。</p><p>&nbsp;</p><p></p><h2>Apache SeaTunnel的演进过程</h2><p></p><p>&nbsp;</p><p>InfoQ：Apache SeaTunnel项目的演进，主要有哪几个发展阶段？</p><p>&nbsp;</p><p>高俊：Apache SeaTunnel，起初名为Waterdrop，是一个易用且高效的海量数据集成平台，主要基于Apache Spark和Apache Flink构建。它支持海量数据的实时同步与转换。</p><p>&nbsp;</p><p>Waterdrop 阶段。这一阶段的主要目标是帮助 Spark 更简单地处理异构数据源数据。在此期间，Waterdrop的主要使命是通过提供一个简单易用、能够支持每天数百亿条海量数据同步的开源软件，将海量数据同步的能力传播到全世界。</p><p>&nbsp;</p><p>SeaTunnel 初期。在2021年 Waterdrop 更名为 SeaTunnel之后，它的主要目标是更简单地进行异构数据源同步和集成。SeaTunnel的设计目标是要大大降低用户使用Spark、Flink等技术做数据集成的门槛。这个阶段的重点是利用Spark和Flink作为底层数据同步引擎，提高数据同步的吞吐性能。此外，SeaTunnel还开始引入可插拔的插件体系，支持超过100种数据源，从而增强其数据集成的能力。</p><p>&nbsp;</p><p>SeaTunnel 中期。在SeaTunnel的中期阶段，SeaTunnel建立了Zeta引擎，专为数据同步集成而设计。新的引擎减少了对第三方服务的依赖，使得那些没有大数据平台或不愿意依赖大数据平台进行数据同步的用户也能轻松使用SeaTunnel。Zeta引擎利用Dynamic Thread Sharing技术优化资源使用，提供数据同步任务的Checkpoint和容错机制，以及执行计划优化器以减少网络传输，从而提高数据同步效率。SeaTunnel的这一阶段重点在于支持全场景数据同步，包括离线批量同步、全量同步、增量同步、实时同步以及CDC。</p><p>&nbsp;</p><p>SeaTunnel 最新阶段。最近，SeaTunnel进入了一个新的发展阶段，这个阶段的目标是使得更广泛的用户群体，包括数据分析师和数据科学家，也能从SeaTunnel高效、简单的数据集成功能中受益。为了实现这个目标，SeaTunnel引入了可视化界面，让用户能更直观、更方便地实现异构数据的实时同步和集成，其目标已经扩展到为工程师、数据分析师、数据科学家、AI 算法工程师等人群提供更高效、更简单的异构数据同步、实时同步集成功能。</p><p>&nbsp;</p><p>从 Waterdrop 到 SeaTunnel ，再到 Zeta 引擎的自主设计，再到现在的可视化界面融合，Apache SeaTunnel的发展历程凸显了其持续创新，致力于降低大数据处理难度，并提升数据处理效率的使命。未来，我们期待SeaTunnel能在大数据领域持续推动创新，为更多用户提供优质的数据集成解决方案。</p><p>&nbsp;</p><p>InfoQ：Apache SeaTunnel经历过重构？那么改进了哪些功能，并如何保证稳定性的？</p><p>&nbsp;</p><p>高俊：这里主要指的是对Apache SeaTunnel连接器的重构，连接器是负责将具体的上下游数据源进行打通，是数据集成的关键组成部分。加入Apache之前，Waterdrop的定位是让Flink和Spark使用起来更简单，所以整个架构设计都是基于Flink和Spark之上。特别是连接器，基本是将Spark和Flink的连接器引入进来就行了，对于Spark和Flink没有的连接器，需要使用Spark和Flink的API分别开发一套代码，早期批和流还是不同的Flink API，意味着同一个数据源为了实现批同步和流同步，也需要开发两套代码。</p><p>&nbsp;</p><p>代码的开发量和维护成本太高了。于是去年年初社区发起了重构连接器的讨论，目标是定义SeaTunnel自己的连接器API，与具体的引擎解耦，不依赖具体的引擎API，真正的实现批流一体，同一个数据源只需要一套代码就可以同时运行在Spark和Flink引擎上。</p><p>&nbsp;</p><p>在讨论初期有不少人持反对意见，认为Flink和Spark这些引擎很成熟，强依赖它们也没什么问题，有些贡献者觉得我们应该放弃Spark全面依赖Flink，在Flink的基础上把功能做好做完善。而且，重构连接器API意味着之前的50多个连接器的工作都白费了，一切要从零开始。但最终社区达成了共识，一切从SeaTunnel项目的定位出发，所以技术方向应该服从项目的目标和定位。目标确立后，社区花了一个月设计新的连接器API，然后用了4、5个月就已经支持到了100多个连接器，速度之快是之前的架构不可能达到的，并真正实现了SeaTunnel支持多引擎和多引擎版本的能力。</p><p>&nbsp;</p><p>现在，SeaTunnel已经支持了Spark2、Spark3、Flink 1.14、Flink 1.15、Flink 1.16等多个引擎和版本，同时也有了自己的专注于解决同步领域问题的超高性能引擎Zeta。</p><p>&nbsp;</p><p>InfoQ：SeaTunnel CDC与Flink CDC、DataX的主要区别是什么？我们应该如何选型？</p><p>&nbsp;</p><p>郭炜：SeaTunnel是批量处理和CDC处理同时支持，它可以自动化地切换批和流的切换点，同时在引擎方面，它支持了Flink CDC不支持的DDL变更检测，第三方Kafka缓冲支持，多表公用一个任务等。相比DataX，除了批量性能超过其30%之外，更是支持了实时CDC同步场景。当然，最大的差别还是在于SeaTunnel CDC是一个支持100多个数据源的同步工具，它支持非结构化到结构化的自动转化，不仅支持数据库，也支持Kafka、SaaS API等复杂数据的实时抽取。更是有强大的SeaTunnel-Web界面，让大家拖拖拽拽就可以建立同步任务，同时可以监控处理各种同步情况。总之，SeaTunnel的目标就是让异构数据源简单、高效、准确地集成到用户指定的目标端去。</p><p>&nbsp;</p><p>InfoQ：Snowflake、AWS在<a href=\"https://medium.com/starschema-blog/so-whats-all-this-talk-about-zero-etl-integration-aa3b0ca9612b\">Zero-ETL</a>\"数据转换、流通和集成上有一些投入，您们如何看待这个技术方向？它会是未来吗？</p><p>&nbsp;</p><p>郭炜：Zero-ETL和DataMesh类似，目标都是尽量不移动数据或者少量移动数据的情况下来达到实现查询数据结果的目标。在一些场景下，例如，KV查询和OLAP联合查询或者OLTP+OLAP联合查询有一定优势。但是，数据应用的场景非常复杂，否则就不会出现几千种数据引擎来处理各种各样的事项，同时，数据集成不仅仅是数据库之间的数据集成，还包括SaaS到数据源，向量数据到AI引擎，各种各样新兴的场景会层出不穷，这些其实都是DataMesh和Zero-ETL无法处理的场景。所以，从我的观点来看，DataMesh和Zero-ETL可以解决用户20%左右的数据集成的场景问题，随着AI和SaaS的流行，更多的场景需要更专业的数据集成工具来解决。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>Apache SeaTunnel的开源故事</h2><p></p><p>&nbsp;</p><p>InfoQ：Apache SeaTunnel是如何和开源结缘的？能具体说说其中的故事吗？</p><p>&nbsp;</p><p>高俊：SeaTunnel的诞生。Apache SeaTunnel开始叫做Waterdrop，主要致力于更简单在不同数据源上使用Spark、Flink处理数据，后来遇到了郭炜和白鲸开源的代立冬，我们一眼看中了这个领域无限的空间。此时，Apache Sqoop已经退役，Apache基金会领域当中也没有一款可以替代Sqoop解决大数据同步生态的项目，而在国内DataX也只能支持批量同步数据源，同时数据源支持也有限，而在海外有FiveTran、Airbyte这些爆火的项目，在业界的确非常需要一个可以高效、简单、准确打通各种数据源的开源项目。</p><p>&nbsp;</p><p>于是，在Apache董事会成员姜宁、欧洲PMC Jean-Baptiste Onofré、Apache大佬Ted Liu等人的支持下，SeaTunnel进入到了Apache孵化器，成为一个专业的，以高效数据集成、打通各个数据源的Apache孵化项目。</p><p>&nbsp;</p><p>进入Apache孵化器之后，SeaTunnel得到了快速的发展，Connector数量也从过去的20个变成现在的100多个连接器，涵盖了大部分公司使用的数据源，不仅是国内的B站、头条、新浪，连美国JP Morgan的用户都被如此多、高效的数据连接器吸引使用，印度第二大运营商Bharti Airtel更是在生产环境中使用了SeaTunnel。</p><p>&nbsp;</p><p>SeaTunnel的第一个挑战。不过此时SeaTunnel也遇到它的第一个挑战，那就是曾经以Spark、Flink为核心引擎的时候，我们在大数据同步场景里多处受挫，例如，无法支持CDC场景下的表自动变更，同步几千个表的时候，Spark、Flink要么都在一个任务里，任何一个表出问题，整个任务失败，要么就是一个表一个任务，资源和源数据库都受不了，SeaTunnel用户在数据量大了之后苦不堪言。这时候，我提出一个想法，那就是建立Apache SeaTunnel自己的引擎——一个专门为数据同步集成而生的引擎。它不依赖于以计算为主的Flink、Spark，可以自由地满足数据同步场景中的Schema Evolution，错误数据采集，数据限流等，还可以节约Flink、Spark为复杂计算预留的内存、CPU slot，同时采用类似Apache Arrow的内存技术，在保证全局一致性前提下，最大限度提升数据传输效率。而且，社区小伙伴们给这个引擎起了一个很有想象力的名字，Zeta，它是宇宙里速度最快小行星的名字，意味着可以载着宇宙的数据快速穿梭于星际之间。（后来发现也是泽塔奥特曼的英文名，我想既可以帮助数据星际传输，如果遇到怪兽也可以打小怪兽吧^_^）。</p><p>&nbsp;</p><p>从零开始直接写一个引擎谈何容易，一遍一遍的设计讨论，一遍一遍地推翻原有设计，大概做了四到五版的设计和原型实现后，在2022年的10月份，第一个版本的SeaTunnel Zeta才发布了Alpha版。这个版本一经发布就技惊四座，不仅支持了DataX不支持的CDC场景，还在框架上支持DDL变更同步，性能更是好得出奇，比海外类似开源的产品要快40倍。SeaTunnel Zeta的出现一下子打开了Apache SeaTunnel的天花板，无论将来有几千上万的数据源连接器，都可以乘坐着Zeta小星星以光速1/3的速度遨游宇宙了~</p><p>&nbsp;</p><p>SeaTunnel的第二个挑战，开源和开源商业界限怎么分？这时候，Apache SeaTunnel的Committer们各个颇有大将风范，剑锋所指各种数据源，数据源连接器数量一下增长了5倍，从2022年1月份20个数据源变为2022年12月的104个数据源。</p><p>&nbsp;</p><p>但是问题又来了，用户纷纷抱怨，写类SQL的代码还是太麻烦，普通人用不了，能不能更简单地用界面使用SeaTunnel？的确，让数据同步能力平民化就是SeaTunnel这个项目建立的初衷。此时，已经加入白鲸开源的我跟白鲸开源的联合创始人代立冬商量，能不能把基于SeaTunnel的商业版WhaleTunnel的界面贡献给Apache社区，让更多的人拥更简单的数据同步的能力。一直推崇开源文化的开源积极分子代立冬十分明白一个简单易用的界面对于解决用户问题有多么的重要，可是如果界面也开源了，那么白鲸开源这家商业公司将来收入靠什么呢？怎么能养活这些热爱开源的人继续贡献开源呢？</p><p>&nbsp;</p><p>我找到了白鲸开源商业合伙人，也是前Informatica中国区总经理李晨和运营合伙人聂励峰商量这个事情，虽然大家热爱开源，但是大家也要吃饭养家糊口啊......这次讨论非常激烈，持续了一整天。最终李晨讲到，“白鲸开源”的基因就是开源，如果我们为了商业订单，把能帮助到大家快速解决问题的核心功能闭源了，这样闭源和开源会对立，那么白鲸开源和Informatica、Fivetran这些闭源软件公司有什么区别？我们要走就走一条在中国持续开源的路，坚信在更多的用户对于开源产品的打磨，一定会让白鲸开源商业产品做的更好，而不是走一条闭源产品的路！</p><p>&nbsp;</p><p>于是，在2023年一个春天的夜晚，几个人一致同意把商业WhaleTunnel的界面全部贡献到SeaTunnel当中，让更多的人具有更简单异构数据实时同步的能力。在后面SeaTunnel周例会上，我一公布这个消息，一下子好多用户都兴奋了，说我们就等着web开源了，赶紧做好，我们马上上线！（代立冬、李晨、聂励峰周会听到这里，浅浅一笑，偷偷地下线，不留功与名——如果将来这几个人出来拿着碗“化缘”，也请大家多多支持啊，支持他们就是支持SeaTunnel这些原创的开源力量了）。</p><p>&nbsp;</p><p>SeaTunnel毕业啦！过五关、斩六将，在Apache基金会 7 位 Mentor 的辅导下，Apache SeaTunnel 社区共加入了 28 位 Commiter、18 位 PMC，也在社区的共同努力下发布了 8 个 Apache Releases。通过透明的开发过程和开源的代码管理，Apache SeaTunnel 项目在社区中获得了广泛的参与。中间还克服了社区的建立和本土化、精力分配、团队协作和社区成长等重重困难和挑战，最终于2023年6月1日儿童节这一天，给所有社区的小儿童和大儿童们献上了儿童节的贺礼！</p><p>&nbsp;</p><p>中国终于有了自己的开源数据同步集成的顶级项目啦！这是SeaTunnel的一大步，但只是中国开源的一小步，相信更多的优秀开源项目在中国如春笋般出现，中国的开源商业也可以支持中国开源的爱好者们更好地兼顾养家糊口和开源贡献！</p><p>&nbsp;</p><p>InfoQ：SeaTunnel毕业成为首个国人主导的数据集成领域Apache基金会顶级项目，有什么经验可以分享？特别是在运营一个全球化的社区方面？</p><p>&nbsp;</p><p>高俊：就像我们加入一家新公司需要了解这家公司的文化一样，参与&nbsp;Apache&nbsp;开源项目之前，我们也需要了解&nbsp;ASF&nbsp;的文化。ASF&nbsp;文化就是&nbsp;The&nbsp;Apache&nbsp;Way。</p><p>&nbsp;</p><p>深入进入开源就会发现，开源不只是开放源码这么简单的一件事，开源还关乎社区管理、社区活跃、社区沟通交流、社区文化等，这就需要我们对&nbsp;Apache&nbsp;way&nbsp;有更加深刻的理解。</p><p>&nbsp;</p><p>鉴于此前的经验，Apache&nbsp;SeaTunnel&nbsp;在进入&nbsp;Apache&nbsp;孵化器初期就对&nbsp;Apache&nbsp;Way&nbsp;的重要性有着深刻的理解，比如对于开源社区来说，Community&nbsp;Over&nbsp;Code&nbsp;的理念要植根心中，为此也需要社区做出准备和努力，尽可能降低每个有兴趣参与项目人的门槛，甚至打造&nbsp;0&nbsp;门槛，比如制定社区激励计划，制作新手入门指南，精选&nbsp;Good&nbsp;First&nbsp;Issue，重要&nbsp;Feature&nbsp;进展跟踪，通过定期的用户访谈获取反馈和优化建议，定期解答社区关于项目和社区的疑问等。</p><p>&nbsp;</p><p>社区贡献不仅限于代码，非代码的贡献甚至有时会发挥比代码更加有价值的作用，比如利用自身影响力为项目引发关注做贡献，写作项目相关技术和非技术文章，参与社区组织的各种活动、在各种时机和场合为&nbsp;Apache&nbsp;SeaTunnel“代言”，把它推荐给更多的用户等，都是参与社区的渠道。</p><p>&nbsp;</p><p>同时，Community&nbsp;Over&nbsp;Code&nbsp;还强调开放、交流、合作，Apache&nbsp;SeaTunnel&nbsp;秉持着这些理念，坚持社区内与海内外社区保持沟通，相互学习交流，坚持与&nbsp;Apache&nbsp;社区建立沟通，所有讨论发生在邮件内，issue&nbsp;中，并通过社区自媒体渠道公布项目和社区的重大进展和计划，让社区保持公开透明。</p><p>&nbsp;</p><p>从进入孵化期至今，Apache&nbsp;SeaTunnel&nbsp;先后与多个海内外开源项目举办线上线下&nbsp;Meetup&nbsp;20&nbsp;余场，包括已先于&nbsp;Apache&nbsp;SeaTunnel&nbsp;顺利从&nbsp;ASF&nbsp;孵化器毕业的&nbsp;Apache&nbsp;Shenyu、Apache&nbsp;InLong、Apache&nbsp;Linkis，Apache&nbsp;Doris、IoTDB、StarRocks、TDengine&nbsp;等成熟开源项目，以及在美国、印度等海外地区与&nbsp;Trino、APISIX、Shopee、ALC&nbsp;Indore&nbsp;联合举办的&nbsp;Meetup&nbsp;等。社区之间的合作与交流推动开源技术的发展和应用，Apache&nbsp;SeaTunnel&nbsp;与其他开源项目合作，共同解决了技术难题，有利于提升开源生态的整体水平，拓展了开源生态的边界。</p><p>&nbsp;</p><p>Apache&nbsp;SeaTunnel&nbsp;还积极参与国内外的技术大会和展览，展示开源项目和技术成果，通过与业界专家和开发者的交流，扩大项目的影响力和知名度。</p><p>&nbsp;</p><p>经过时间的积累，社区已有了质的变化。从社区的邮件讨论、GitHub&nbsp;的数据展示中，你会发现&nbsp;Apache&nbsp;SeaTunnel&nbsp;的社区开始真正变得活跃与多元化。</p><p>&nbsp;</p><p>&nbsp;</p><p>InfoQ：在开源上，Apache SeaTunnel还有哪些未来规划？</p><p>&nbsp;</p><p>高俊：主要是五个方面：</p><p>SeaTunnel 将进一步提高 Zeta 引擎的性能和稳定性，并将过去规划的 DDL 变更，错误数据处理，流速控制、多表同步等落地完成。SeaTunnel-Web 也将从 Alpha 状态进入 Release 状态，让大家可以直接从界面来定义、控制整个同步流程。加强AGI组件配合关系，除了可以使用ChatGPT自动生成Connector之外，加强向量数据库，大模型 插件的打通，让现有100多种数据源无缝对接大模型。完善和上下游生态的关系，与 Apache DolphinScheduler、Apache Airflow 等 Apache 生态的整合和互联互通。在 Google Sheet、飞书、腾讯文档支持之后，加强 SaaS Connector 的构造，例如 ChatGPT、Salesforce、Workday 等。</p>",
    "publish_time": "2023-06-07 15:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "科大讯飞 AI 研究院副院长、科研部部长李鑫博士确认出席 ArchSummit 深圳",
    "url": "https://www.infoq.cn/article/7RFyDB31Vti7ESOVyaod",
    "summary": "<p>7&nbsp;月&nbsp;21&nbsp;日&nbsp;-&nbsp;22&nbsp;日，&nbsp;在&nbsp;<a href=\"https://archsummit.infoq.cn/2023/shenzhen?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">ArchSummit&nbsp;全球架构师峰会（深圳站）</a>\"，科大讯飞&nbsp;AI&nbsp;研究院副院长、科研部部长李鑫，将于会上发表题为《AIGC&nbsp;技术探索与应用创新》主题分享，将从科大讯飞AIGC整体布局以及在音频创作、视觉创作、文本创作等方面的研究和应用进行分享。</p><p></p><p>李鑫博士是高级工程师、科大讯飞AI研究院副院长，科研部部长。中国科学技术大学博士、博士后，悉尼科技大学访问学者。认知智能全国重点实验室研究员。合肥工业大学、安徽大学、重庆邮电大学兼职硕士生导师。中国互联网协会青年专家。中国脑机接口标准委员会委员。</p><p></p><p>主持并参与多个国家重点研发计划、自然科学基金等项目10余项。发表高水平学术论文40余篇，申请专利30余件。BESC&nbsp;2018国际会议工业委员会主席。担任爱思唯尔期刊《Nature&nbsp;Language&nbsp;Processing&nbsp;Journal》创刊编委，获得&nbsp;KSEM&nbsp;2018的最佳研究论文奖。研发儿童脑智发育测评平台获2022年度1024全球开发者节人工智能产品金奖。</p><p></p><p>相信李鑫博士来到大会现场，一定能带给大家关于&nbsp;AI&nbsp;领域最新科技进展，特别是科大讯飞AIGC整体布局，在音频创作、视觉创作、文本创作等方面的研究和应用，了解扩展更多应用的可能性。</p><p></p><p>除上述专题外&nbsp;，ArchSummit&nbsp;深圳还将围绕<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1537?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">基础架构技术</a>\"、<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1536?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">智能化数据治理</a>\"、<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1532?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">DataOps、Data&nbsp;Fabric&nbsp;等高效数据开发与服务模式</a>\"、<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1534?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">Mesh&nbsp;技术实践案例</a>\"、<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1535?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">QUIC&nbsp;传输和架构优化</a>\"等进行分享。</p><p></p><p>数十位业界专家，上百个国内外一线大厂前沿技术案例，一定会给你带来很多全新的开发灵感。期待与你线下交流！&nbsp;现在购票，享&nbsp;8&nbsp;折特惠，立省&nbsp;¥1760！咨询购票请联系&nbsp;18514549229（微信同手机号）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9d/9d6a27547062ee2e089f91bdc4ba1eaa.png\" /></p><p></p><p></p><h4>【直播推荐】</h4><p></p><p>今晚&nbsp;20:00，我们特别邀请到了李鑫老师，以及&nbsp;Mobvista&nbsp;技术&nbsp;VP&nbsp;蔡超，共同探讨&nbsp;AI&nbsp;大模型时代，架构师面临哪些机遇和挑战？更有&nbsp;ArchSummit&nbsp;深圳站精彩专题提前剧透！知识豪礼任性送！</p><p>扫描下方海报二维码预约直播；戳此查看&gt;&gt;&gt;&nbsp;&nbsp;<a href=\"https://archsummit.infoq.cn/2023/shenzhen/speaker?utm_source=0607as&amp;utm_medium=zhibo\">ArchSummit&nbsp;深圳站讲师阵容</a>\"</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a2/a2af8b545150362cc34819f86cdb1c81.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/11/1111192091c5f8fd92b92e964519a55e.jpeg\" /></p><p></p>",
    "publish_time": "2023-06-07 15:04:34",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "用 AIGC 写 2023 高考语文作文，结果如何？",
    "url": "https://www.infoq.cn/article/OM5YUDuHazZQlR9blkOP",
    "summary": "<p>一年一度高考时间，令众人关注的语文考试作文题已经公开。那么，如果命令&nbsp;AIGC&nbsp;来完成今年的作文考试，AI&nbsp;大概能得多少分呢？</p><p></p><p>为了完成这个测试，我们选择了&nbsp;文心一言、讯飞星火认知大模型、通义千问、ChatGPT来分别应对，作文题选用&nbsp;2023&nbsp;全国甲卷作文题，题目：</p><p></p><p></p><blockquote>阅读下面的材料，根据要求写作。人们因技术发展得以更好地掌控时间，但也有人因此成了时间的仆人。这句话引发了你怎样的联想与思考？请写一篇文章。要求：选准角度，确定立意，明确文体，自拟标题；不要套作，不得抄袭；不得泄露个人信息；不少于800字。</blockquote><p></p><p></p><p>为此我们特别邀请了一位教龄&nbsp;35&nbsp;年以上的资深高中语文教师聂文革老师，来给各篇作文打分，每篇作文的评分放在文章下方，老师的总结性评语放在文末。</p><p></p><p>需要特别指出的是，作文评分本来就有主观因素，且高考作文的评判标准与寻常文章又有不同，本次“作文大赛”并非正式评测，评测结果也不能代表各大模型本身的能力素质，仅供大家参考。</p><p></p><p>下面开始。</p><p></p><h1>作文一：时间的主人及其悖论</h1><p></p><p></p><p>作者：文心一言</p><p></p><p>时间，是宇宙中最为普遍的公平，无差别地赋予每一个人以生命，使之在有限的尺度内创造与体验。然而，人们对于时间的理解和运用却千差万别，有人视时间为宝库，有人视其为仆人。对此，我深感思考的必要，欲探讨我们应如何对待时间这一最珍贵的礼物。</p><p></p><p>在技术的照耀下，我们得以更深入地解读时间。古人云“光阴似箭，日月如梭”，时间的流逝在技术的辅助下，变得清晰可见。曾经，人们通过日晷、沙漏来感知时间，如今，我们借助卫星导航、原子钟等技术精确到秒的毫厘之间。技术的发展使我们更能丈量时间，从而更好地管理我们的生活。</p><p></p><p>然而，技术并未完全使我们的生活摆脱时间的束缚，反而使人在某种程度上成为其奴隶。古人云“逝者如斯夫，不舍昼夜”，时间的无情在技术的洪流中似乎得到了强化。我们陷入了一种时间的悖论，一方面，我们通过技术得以更深入地理解时间，另一方面，我们也因技术而更加受制于时间。</p><p></p><p>对此，我想说的是：我们不应让技术成为时间的帮凶，而应成为我们驾驭时间的利器。我们不能让时间的洪流冲垮我们，反而应利用它来发展我们的能力。诸如司马迁、贝多芬等伟大的人物，他们并未因时间的无情而退缩，反而因时间的磨砺而更加坚韧。他们用时间来锻造自我，使自己成为时间的胜者。</p><p></p><p>此外，我们还应学会欣赏时间的美。正如诗人徐志摩所说：“你来或者不来，花都会为你开放。”我们应该像花那样，静静地绽放，欣赏时间的赠礼。我们应在时间的赛道上奔跑，同时欣赏沿途的风景，体会生活的韵味。不应让时间的紧迫性遮蔽了我们对生活的热爱和对时间的敬畏。</p><p></p><p>在此，我提倡一种“慢生活”，即在不忽视时间流逝的前提下，放慢生活的节奏，去体验生活的每一个瞬间。正如卡夫卡所言：“我们应该感恩我们在地球上的每一秒。”每一秒都是生命的一部分，都值得我们去珍视和体验。</p><p></p><p>然而，慢生活并不意味着对时间的浪费或者对生活的消极态度。相反，它是一种对生活的深度参与和积极体验。它让人能够在繁忙的生活中找到片刻的宁静，去思考人生的意义和价值。在这个快速发展的世界中，这样的片刻宁静也许更能让我们找回内心的自我和方向。</p><p></p><p>总的来说，我们应当成为时间的主人，而非仆人。我们应当利用技术来更好地理解时间，但不应被时间所驱使。我们应该在快节奏的生活中找到时间留下的美好瞬间，去享受生活而不是被生活所驱使。只有这样，我们才能真正地掌控时间，而不是被时间所控制。</p><p></p><p>老师评分（60&nbsp;分制）：50&nbsp;分</p><p></p><h1>作文二：掌控时间，做自己的主人</h1><p></p><p></p><p>作者：讯飞星火认知大模型</p><p></p><p>随着时代的发展，科技的进步，人们的生活水平不断提高，但与此同时，一些新的问题也随之而来。比如：现在的学生因为要完成老师布置的大量作业而熬夜，导致第二天上课时无精打采；上班族因工作繁忙，经常加班加点，没有充足的睡眠而导致身体抵抗力下降，甚至生病......这些都是由于我们没有掌控好自己的时间。</p><p></p><p>我们应该掌控好自己的时间，做自己的主人。</p><p></p><p>“一寸光阴一寸金，寸金难买寸光阴。”这句话说得一点也没错。时间是非常珍贵的，就像沙漏里的沙子一样，稍不留神就会流走。鲁迅先生说过：“时间就像海绵里的水，只要愿挤总还是有的。”是啊！只要我们愿意去挤，时间总是会有的。可是有的人却把时间当作金钱来浪费，他们整天无所事事，不知道该做些什么，最后只会落得个一事无成、白白浪费掉自己宝贵的时间的下场。</p><p></p><p>那么我们应该怎样才能更好地掌控我们的时间呢？首先，我们要学会合理地安排和规划自己的时间。每天早上起来后，先列出今天要完成的任务，然后再根据任务的轻重缓急来确定每件事情所需要的时间。在做事情的时候，要一心一意地把这件事情做好，不要一会儿做这件事，一会儿又做那件事，最后什么也没有做好。其次，我们还要学会珍惜时间。不要以为时间很长，其实它是很短暂的。如果我们把每一天都过得充实有意义的话，那么一年的时间就会很快过去。所以我们要珍惜时间，不要虚度年华。最后，也是最重要的一点就是要有计划、有目的地去学习知识、掌握技能。只有不断地学习和积累才能使我们更加聪明、更加有能力。</p><p></p><p>当然了，要想做到掌控好自己的时间并不是一件容易的事情。它需要我们付出很大的努力和汗水，需要我们克服各种各样的困难和挑战。但是只要我们坚持下去，相信我们一定能够做到的！</p><p>让我们一起掌控好自己的时间吧！让我们成为时间的主人！让我们用我们的勤奋和智慧去创造一个更加美好的未来！</p><p></p><p>老师评分（60&nbsp;分制）：48&nbsp;分</p><p></p><h1>作文三：被技术控制的时间</h1><p></p><p>作者：通义千问</p><p></p><p>技术的发展让人们可以更加精准地掌控时间，这原本是一件令人欣喜的事情，但是，有些人却因此成为了时间的奴隶。</p><p></p><p>在现代社会中，人们越来越依赖各种智能设备来帮助自己管理时间，如智能手表、智能手环、时间管理软件等等。这些设备可以帮助人们监测自己的运动量、睡眠质量、饮食健康等各个方面，同时也可以提供诸如提醒、计时、日程安排等多种功能，让人们可以更加高效地利用时间。</p><p></p><p>然而，这种便利的技术也会带来一些负面的影响。很多人开始沉迷于各种智能设备，甚至成为了它们的奴隶。他们不断地查看手表、手环上的时间，生怕错过了任何一个重要的事情，甚至连睡觉都要把手机放在身边，生怕错过了任何一个电话或者短信。这样的生活方式不仅让人感到疲惫不堪，而且也会严重地影响个人的健康和心理健康。</p><p></p><p>更重要的是，这种依赖智能设备的行为也会让人变得越来越懒惰。人们开始变得不愿意去思考、不愿意去行动，而是完全依赖于设备的提醒和帮助。这样一来，人们就失去了自我管理的能力，也失去了对时间的掌控力。</p><p></p><p>因此，我们必须认识到技术发展所带来的负面影响，并且努力避免成为时间的奴隶。我们需要学会自我管理和自我控制，合理地利用各种技术工具来帮助自己提高效率，而不是完全被它们所控制。同时，我们也需要保持独立思考和行动的能力，不断探索和追求自己的梦想和目标，而不是成为时间的奴隶。</p><p></p><p>老师评分（60&nbsp;分制）：52&nbsp;分</p><p></p><h1>作文四：时间的掌控与被掌控</h1><p></p><p></p><p>作者：ChatGPT</p><p></p><p>时间是伟大的创造者，也是无情的裁判。随着科技的不断发展，人们对时间的掌控力越来越强，但也有人在这个过程中成了时间的仆人。本文将从时间的掌控与被掌控两个方面展开探讨，旨在引发读者对时间的思考。</p><p></p><p>一、时间的掌控</p><p></p><p>人类历史上，时间的掌控一直是人类追求的目标之一。古代的日晷、水钟，现代的钟表、手机等工具，都为人们提供了更加精准的时间信息。在这个信息爆炸的时代，时间管理也成为了人们追求高效、优质生活的必备技能之一。人们通过各种时间管理方法，如番茄工作法、GTD等，来更好地利用时间，实现自己的目标。</p><p></p><p>在现代社会，时间的掌控不仅仅是个人的需要，也是企业、组织的需要。时间不仅是金钱，更是效率。企业通过时间管理，提高生产效率，降低成本，增加利润。组织通过时间管理，提高员工的工作效率和生产力，实现自己的战略目标。在这个过程中，时间成为了人们的朋友，帮助人们更好地实现自己的目标。</p><p></p><p>二、时间的被掌控</p><p></p><p>然而，随着科技的发展，人们的生活越来越被时间所掌控。社交网络、即时通讯工具等，让人们无时不刻地处于“在线”状态，随时随地接受信息和任务，人们的自由时间越来越少。特别是在全球化的时代，人们需要面对不同时区、不同文化的人们，需要不断地调整自己的生活节奏，这使得人们的生活更加被动。</p><p></p><p>此外，一些新兴行业也让人们更加被时间所掌控。比如网约车司机、外卖配送员等，他们需要随时待命，承担着不确定的工作量和工作时间。在他们看来，时间不再是自己的，而是被工作所占据。这些人们的工作，虽然带来了一定的经济收益，但同时也剥夺了他们自由支配时间的权利。</p><p></p><p>三、时间的启示</p><p></p><p>时间的掌控与被掌控，是人们面临的一个共同问题。我们需要更好地掌控时间，实现自己的目标，但同时也需要注意不被时间所掌控。我们应该把握好自己的时间，不断提高自己的效率和生产力，实现自己的价值。但是，我们也应该学会放松自己，享受生活，让时间成为我们的伙伴，而不是我们的敌人。</p><p></p><p>在现代社会，人们需要更好地认识时间的价值，明确时间的重要性。我们应该尊重时间，珍惜时间，因为时间是不可逆转的。我们应该用时间去实现自己的梦想和目标，去创造属于自己的价值。</p><p></p><p>总之，时间是人类追求的目标之一，也是人类必须面对的问题。我们需要掌控时间，实现自己的目标，但同时也需要注意不被时间所掌控。只有在这个过程中，我们才能实现自己的梦想和目标，创造属于自己的价值。</p><p></p><p>老师评分（60&nbsp;分制）：45&nbsp;分</p><p></p><p>老师整体评语：</p><p></p><p></p><blockquote>这四篇作文，均能紧扣材料核心，以时间·科技·人类为话题，结合现实生活的现象，发挥辩证性思维，符合高考作文趋势。第一篇亮点：在时间快与慢的节奏变化中体验生活之美；第二篇亮点：重点提出了一些具体措施，文章实用性强；第三篇针对性极强，有社会意义，作文为时而作，有助于解疑释惑。第四篇结构清晰，思维明确，综合评分为50&nbsp;分，48&nbsp;分，52&nbsp;分，45&nbsp;分。此外，如果从高考应试作文角度考虑，四篇作文的题目中第二篇文章的题目符合要求，其他三篇文题应作修改。</blockquote><p></p><p></p><p>当然，关于&nbsp;AIGC，极客邦科技也在努力为大家提供更多的&nbsp;AIGC&nbsp;相关内容，满足大家对于精品资讯、资料、课程的需求。</p><p></p><p>在&nbsp;3&nbsp;月中旬，极客时间一次性发布四门&nbsp;AIGC&nbsp;公开课，其中包括句子互动公司创始人兼&nbsp;CEO&nbsp;李佳芮的<a href=\"https://time.geekbang.org/opencourse/videointro/100541101\">《ChatGPT从0到1》</a>\"、新加坡科研局高级研究员黄佳的《<a href=\"https://time.geekbang.org/opencourse/videointro/100541201\">ChatGPT和预训练模型实战课</a>\"》、优频科技有限公司&nbsp;CTO&nbsp;孙其瑞的《<a href=\"https://time.geekbang.org/opencourse/videointro/100541301\">Stable&nbsp;Diffusion：零基础学会&nbsp;AI&nbsp;绘画</a>\"》以及&nbsp;NebulaGraph&nbsp;软件工程师古思为的《<a href=\"https://time.geekbang.org/opencourse/videointro/100540901\">GitHub&nbsp;Copilot&nbsp;实践课</a>\"》</p><p></p><p>与此同时，&nbsp;bothub&nbsp;创始人、布奇托网络科技创始人兼&nbsp;CTO&nbsp;徐文浩，在极客时间开设了课程<a href=\"https://time.geekbang.org/column/intro/100541001?tab=catalog\">《AI&nbsp;大模型之美》</a>\"，是「极客时间&nbsp;AIGC&nbsp;未来教育系列课程」之一，聚焦于让大家充分认识、使用&nbsp;OpenAI、Stable&nbsp;Diffusion&nbsp;等开发工具，实现自主可用的&nbsp;AIGC&nbsp;应用，现已有&nbsp;1.8w&nbsp;人加入学习。</p><p></p><p>珠海太乙人工智能技术合伙人尹会生，则在极客时间开办了《<a href=\"https://u.geekbang.org/subject/intro/100550301\">21&nbsp;天&nbsp;AIGC&nbsp;行动营</a>\"》。都说&nbsp;AIGC&nbsp;会淘汰掉某些岗位，但有许多同学已经在这里率先成为&nbsp;AIGC&nbsp;时代的高效工作者，AIGC&nbsp;变成了他们手中的效率提升工具。</p><p></p><p>6&nbsp;月还将有重磅的&nbsp;AIGC&nbsp;主题训练营与大家见面，聚焦&nbsp;AIGC&nbsp;与企业私域数据结合，开发为企业特别定制的&nbsp;AIGC&nbsp;服务，相信也契合了很多研发小伙伴的实际工作。</p><p></p><p>其他往期&nbsp;InfoQ&nbsp;关于&nbsp;AIGC&nbsp;的部分报道：</p><p><a href=\"https://www.infoq.cn/theme/187\">AIGC，下一个即将爆发的万亿级AI技术风口_技术洞察_技术趋势_大厂实践_InfoQ精选专题</a>\"<a href=\"https://www.infoq.cn/video/TXoCTL6MCpZWm2BKaesc\">极客圆桌派：狂飙的&nbsp;ChatGPT&nbsp;｜InfoQ《极客有约》_AI_InfoQ&nbsp;中文站_InfoQ精选视频</a>\"<a href=\"https://www.infoq.cn/video/So2yItKrdYsDZpEG7DjS\">极客圆桌派：ChatGPT点燃AI狂潮&nbsp;|&nbsp;InfoQ《极客有约》_AI_InfoQ&nbsp;中文站_InfoQ精选视频</a>\"<a href=\"https://www.infoq.cn/video/AeU15OmkT2IWQ56ekExt\">我们是如何探索把ChatGPT推到企业级应用的？|&nbsp;InfoQ《极客有约》_AI_InfoQ&nbsp;中文站_InfoQ精选视频</a>\"</p>",
    "publish_time": "2023-06-07 16:46:16",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "苹果内部禁用ChatGPT，但Tim Cook称自己在使用",
    "url": "https://www.infoq.cn/article/QfFBmri7pi90pYtRA7MU",
    "summary": "<p>&nbsp;Apple 首席执行官Tim Cook近日在接受<a href=\"https://www.goodmorningamerica.com/news/video/tim-cook-talks-new-apple-products-concerns-ai-99862624\">早安美国</a>\"采访被问及是否使用 ChatGPT 时，他回答说：“哦，我当然使用它。是的，我对此很兴奋。我认为它有一些独特的应用，我们正在密切关注它。”</p><p>&nbsp;</p><p>Cook表示，像 ChatGPT 和 Google Bard 这样的人工智能工具已经显示出“巨大的希望”，但也有可能出现“诸如偏见、错误信息之类的事情，甚至在某些情况下可能更糟。”&nbsp;</p><p>&nbsp;</p><p>Cook 强调了人工智能监管的重要性。“监管是这个领域所需要的东西。我认为需要监管。如果往后看，它是如此强大以至于公司必须采用自己的道德决策。但它发展得太快了，监管在某个时期内会很难跟上步伐。因此，公司也有责任自我监管。”</p><p>&nbsp;</p><p>出于谨慎态度，Apple 公司内部现在禁止使用ChatGPT。此据一份苹果的内部备忘录显示，该公司要求员工不要在工作中使用人工智能平台。苹果担忧像ChatGPT这样的人工智能可能会收集员工的机密数据。此外，Apple 还禁止员工在工作中使用GitHub的辅助编程工具Copilot。</p><p>&nbsp;</p><p>不过，Apple 也在布局自己的人工智能能力。有报告称，苹果目前共有176个与机器学习和人工智能相关的岗位，其中68个职位属于Siri部门，52个参与iOS系统开发，另外46个职位则与macOS相关。</p><p>&nbsp;</p><p>在周一的全球开发者大会WWDC 2023上，Apple 宣布了其流行设备（电脑、iPhone、iPad、Apple Watch、Apple TV、AirPods 和新的 Apple Vision Pro 耳机）的一系列新软件功能，其中许多都使用了人工智能 (AI) 或“机器学习”(ML)。</p><p>&nbsp;</p><p>为了与先前对用户隐私和安全的承诺保持一致，Apple 的这些 AI 功能似乎在很大程度上避免了将用户数据连接和传输到云端，而是依赖于设备处理能力——Apple 称之为“神经引擎<a href=\"https://machinelearning.apple.com/research/neural-engine-transformers\">”</a>\"。</p><p>&nbsp;</p><p>Apple 在WWDC上推出的 Vision Pro ，很大程度上依赖于称为 Persona 的 ML。此功能使用内置摄像头扫描用户面部，以快速创建栩栩如生的交互式数字分身。这样，当用户戴上设备并加入 FaceTime 通话或其他视频会议时，数字分身就会代替他们出现在头显中，实时映射他们的表情和手势。Apple 表示，Persona 是佩戴者的“数字代表”，“使用 Apple 最先进的 ML 技术创建”。</p><p>&nbsp;</p><p>另外，Apple在2017年6月宣布了上线的一种不需要互联网连接即可进行机器学习的框架Core ML。Core ML 为所有模型提供了一种统一的呈现方式。App 可以使用 Core ML API 和用户数据进行预测，以及训练或精调模型，一切都在用户设备上完成。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/34/34c2203bfd5f60fa2db0c2f01a560338.png\" /></p><p></p><p>据悉，Core ML&nbsp;通过利用 CPU、GPU 和<a href=\"https://www.apple.com.cn/cn/iphone/\">神经网络引擎</a>\"，同时最大程度地减小内存占用空间和功耗，来优化设备端性能。由于模型严格地在用户设备上，因此无需任何网络连接，有助于保护用户数据的私密性和 App 的响应速度。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://venturebeat.com/ai/the-best-ai-features-apple-announced-at-wwdc-2023/\">https://venturebeat.com/ai/the-best-ai-features-apple-announced-at-wwdc-2023/</a>\"</p>",
    "publish_time": "2023-06-07 17:50:43",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "QCon 广州，与你探讨 AIGC 应用创新",
    "url": "https://www.infoq.cn/article/MA8YLIQ96AgqacRklaBP",
    "summary": "<p>AIGC，全称为 Artificial Intelligence Generated Content，又称生成式 AI（Generative AI），是继 PGC（Professional Generated Content，专家生产内容）、UGC（User Generated Content，用户生产内容）之后的又一创作方式。去年 9 月，一副名为《太空歌剧院》的 AIGC 作品在一场艺术博览会上惊艳亮相，让 AI 绘画进入大众的视野，国内外 AI 巨头纷纷跟进相关产品的研发。</p><p>&nbsp;</p><p>近期，ChatGPT 再掀高潮，一时间风头无二。2023 年会是 AIGC 的商业化之年吗？AIGC 要从哪些地方布局？实际落地过程中，从算法到工程侧分别有哪些挑战？在 5 月 26-27 日 QCon 全球软件开发大会（广州站）上，我们策划了【<a href=\"https://qcon.infoq.cn/2023/guangzhou/schedule\">AGI 与 AIGC 落地</a>\"】专题，本专题基于 AIGC 的应用场景，从算法和工程两个角度，邀请资深大咖来探讨以上问题。</p><p>&nbsp;</p><p>以下为专题嘉宾分享详细信息：</p><p>&nbsp;</p><p>李飞博士，数势科技算法专家，将分享 AIGA 在营销领域的探索及创新。他将从 AIGA 的背景和趋势、AIGA 在营销领域的应用和探索和总结与展望三个方面进行阐述。通过这次演讲，您将了解到 AIGA 的概念和主要内容，以及 AIGA 在营销领域中的应用实践；</p><p>&nbsp;</p><p>王胜，三维家图灵实验室 AI 负责人，将分享从通用智能到设计领域大模型，三维家的思考与实践。他将从背景、家居设计领域大模型的修炼之道、家居设计领域大模型的修炼之术和大模型的未来发展展望四个方面进行阐述。通过这次演讲，您将了解行业垂直类大模型的概念和应用背景，以及对比通用大模型的优势；了解大模型在家居设计领域中的修炼之道和修炼之术；了解大模型在智能家居领域中的应用探索、应用前景；</p><p>&nbsp;</p><p>罗庆超，阿里云资深技术专家，将分享 AIGC 助力大规模对象存储服务 OSS 的能效提升。</p><p>&nbsp;</p><p>宜博，宜创科技创始人，TGO 鲲鹏会（北京）学员，清华大学经管学院 MBA，西安电子科技大学计算机系本科。2014 年创办宜创科技，目前已服务国内上百家大型技术团队和项目。公司 2023 年开始专注在基于大模型 AGI 领域创新，已推出ChatBI、ChatExcel、ChatPDF 等多个产品。目前，宜创科技正在构建全新的大模型中间层基 LLMFarm，个人智能助理 FriAI ，致力于帮助企业解决不能用、不会用、不好用的大模型开发的实际痛点，让中国企业都能以十分之一成本，利用 LLM 大模型落地各行业应用场景。</p><p></p><p></p><p></p>",
    "publish_time": "2023-06-07 17:56:50",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]