[
  {
    "title": "于晓波：数字经济下 HR 的转型 ｜DTDS 8 月",
    "url": "https://www.infoq.cn/article/AyQYLHHsgEqT09lP5HOX",
    "summary": "<p>在工业和信息化部人才交流中心和中国移动通信联合会教育与考试中心的大力支持与指导下，由极客时间企业版、培训杂志共同举办，甫瀚咨询联合举办的 DTDS 全球数字人才发展线上峰会于 8 月 9 日拉开帷幕。</p>\n<p>经过多年在企业数字人才发展领域的耕耘，极客时间于 2022 年发布了数字人才粮仓模型，深入定义了五层数字人才，收获了来自各行各业的企业客户的认可。我们也看到许多企业都在加大对数字人才的培养，并且希望向行业标杆学习，完善自己的数字人才培养体系，融入数字人才标准和生态。</p>\n<p>为此，DTDS 峰会汇聚了来自政府和产业的权威，以及金融、汽车、制造、ICT、零售、互联网、风控审计企业的数字化先锋人物，旨在建立数字人才培养“朋友圈”，让大家从多维视角了解企业数字化转型，人才发展，和组织变革的先进经验。</p>",
    "publish_time": "2022-10-11 00:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "云端机器人的“智慧大脑”是如何获取知识，提升认知，完成“进化”的？| InfoQ《极客有约》",
    "url": "https://www.infoq.cn/article/vPaILEuvZaaeMxe2O4pl",
    "summary": "<p>云端智能机器人和普通机器人有何差别？未来智能机器人技术有哪些值得关注的？本期《极客有约》直播，带你了解云端智能机器人如何获取知识，完成进化的。</p>",
    "publish_time": "2022-10-11 11:07:26",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Spring Boot Migrator简介",
    "url": "https://www.infoq.cn/article/M8Tcely7QZhZYx4od2t1",
    "summary": "<p><a href=\"https://github.com/spring-projects-experimental/spring-boot-migrator\">Spring Boot Migrator</a>\"（SBM）是一个实验性的Spring项目，最初发布于2022年3月。SBM允许开发人员将现有的、非<a href=\"https://spring.io/projects/spring-boot\">Spring Boot应用（基于JAX-RS、EJB和JMS等技术）转换成Spring Boot</a>\"应用，也可以将较旧的Spring Boot应用升级为最新版本。</p><p></p><p>SBM是基于<a href=\"https://docs.openrewrite.org/\">OpenRewrite</a>\"实现的，这是一个用于源码和配置重构的通用工具。OpenRewrite使用<a href=\"https://docs.openrewrite.org/reference/recipes\">Recipes</a>\"修改现有的Kubernetes、Gradle、Maven、Java等文件。例如，借助recipes能够将现有的应用升级为较新的Java版本。SBM使用OpenRewrite实现Spring Boot的迁移。</p><p></p><p><a href=\"https://github.com/spring-projects-experimental/spring-boot-migrator/releases\">下载</a>\"最新版本的SBM之后，可以使用命令行界面（CLI）启动：</p><p><code lang=\"java\">java -jar spring-boot-migrator.jar</code></p><p>几秒钟之后，用户可以看到一个专门的SBM提示：migrator:&gt;。</p><p></p><p>list命令能够展示当前可用的30个recipes。比如，其中的recipes能够升级Spring Boot到新版本、将XML bean配置变更为Java配置以及迁移各种Java EE/Jakarta到Spring Boot。</p><p></p><p>scan [directory]命令能够分析一个应用并展示适用的recipes。如下展示了一个样例，SBM分析了一个比较旧的<a href=\"https://en.wikipedia.org/wiki/Jakarta_RESTful_Web_Services\">JAX-RS</a>\"应用，该应用没有提供对Spring Boot的支持，结果如下所示：</p><p><code lang=\"java\">scanning 'JAXRS'\nChecked preconditions for '.../JAXRS'\n[ok] Found pom.xml.\n[ok] 'sbm.gitSupportEnabled' is 'true', changes will be committed to branch [master] after each recipe.\n[ok] Required Java version (17) was found.\n[ok] Found required source dir 'src/main/java'.\nMaven       100% ││ 2/2 (0:00:09 / 0:00:00)\nApplicable recipes:\n    = 'automated recipe'\n  = 'partially automated recipe'\n    = 'manual recipe'\n  - initialize-spring-boot-migration []\n    -&gt; Initialize an application as Spring Boot application.\n  - migrate-jax-rs []\n    -&gt; Any class has import starting with javax.ws.rs\n  - cn-spring-cloud-config-server []\n    -&gt; Externalize properties to Spring Cloud Config Server</code></p><p>基于应用的源码，SBM将会展示与条件相匹配的recipes。如果没有匹配的recipes话，可用recipes的列表将保持为空。此时，我们可以使用其中列出的某个recipes，比如，将现有的代码转换成Spring Boot应用：</p><p><code lang=\"java\">migrator:&gt; apply initialize-spring-boot-migration</code></p><p>上述命令将会产生一个新的Git提交，描述为SBM: applied recipe 'initialize-spring-boot-migration'。</p><p>我们分析一下该提交会发现在pom.xml中有如下变化：打包方式从WAR改变成了JAR、增加了spring-boot-starter、spring-boot-starter-test依赖和spring-boot-maven-plugin、dependencyManagement区域包含了pom类型的spring-boot-dependencies。pom.xml文件的缩进方式可能会与最初有所差异。</p><p></p><p>源码也会有所变更，现在包含了SpringBootApp.java和SpringBootAppTest.java类：</p><p><code lang=\"java\">@SpringBootApplication\npublic class SpringBootApp {\n    public static void main(String[] args) {\n        SpringApplication.run(SpringBootApp.class, args);\n    }\n}</code></p><p></p><p><code lang=\"java\">@SpringBootTest\nclass SpringBootAppTest {\n    @Test\n    void contextLoads() {\n    }\n}</code></p><p>现在，应用已经转换成了Spring Boot应用。下一步就是通过如下的命令将JAX-RS源码转换成Spring Boot：</p><p><code lang=\"java\">migrator:&gt; apply migrate-jax-rs</code></p><p>该命令会产生一个新的Git提交，其描述为:SBM: applied recipe 'migrate-jax-rs'. 分析该提交可以看出，JAX-RS的导入被删除，取而代之的是导入了Spring、类文件上的JAX-RS&nbsp;@Path注解被Spring Boot的@RestController和@RequestMapping取代。各个方法现在都有Spring Boot的@RequestMapping、@RequestParam、@PathVariable注解，以替换JAX-RS的注解，如@Get、@Post、@Path、@Produces、@QueryParam和@PathParam。最后，这些方法的返回值不再是Response类型，而是ResponseEntity类型。</p><p></p><p>遗憾的是，迁移后运行该Spring Boot应用失败了，这是因为pom.xml文件中定义的<a href=\"https://maven.apache.org/plugins/maven-compiler-plugin/\">maven-compiler-plugin</a>\"使用了旧版本的Java。手动修改pom.xml文件以使用当前安装的Java版本可以解决这个问题，也可以通过OpenRewrite的<a href=\"https://docs.openrewrite.org/reference/recipes/maven/changepluginconfiguration\">Change Maven插件配置</a>\"来自动完成这个步骤。</p><p></p><p>分析产生的代码和配置，我们可能会发现一些Spring Boot不再需要的依赖。可以手动删除这些过时的依赖，也可以通过SBM或OpenRewrite自动完成这一步骤。</p><p></p><p>SBM目前支持仅Maven，因为OpenRewrite对Gradle的支持还没有<a href=\"https://github.com/spring-projects-experimental/spring-boot-migrator/issues/216\">完成</a>\"。关于SBM的更多信息可以参阅其<a href=\"https://spring-projects-experimental.github.io/spring-boot-migrator/user-documentation.html\">用户文档</a>\"和<a href=\"https://spring-projects-experimental.github.io/spring-boot-migrator/developer-documentation.html\">开发者文档</a>\"。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/09/spring-boot-migrator/\">Introducing Spring Boot Migrator</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/TJrVEvEhmrxAIVzMj10R\">Spring Boot 2.7.0 发布，支持 GraphQL、Podman 和 Cache2k</a>\"</p>",
    "publish_time": "2022-10-11 11:36:49",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "马斯克吐槽无用的“阑尾”终于被割掉，特斯拉移除超声波传感器，All In 纯视觉自动驾驶",
    "url": "https://www.infoq.cn/article/ieqsEOaplV4GQOMdl03j",
    "summary": "<p></p><p></p><p></p><blockquote>马斯克“干掉”最后的雷达。</blockquote><p></p><p></p><p></p><h2>Tesla Vision 替代超声波传感器</h2><p></p><p></p><p>10 月 4 日，特斯拉宣布，将从 Model 3 和 Model Y 车型中移除超声波传感器（USS）。</p><p></p><p>自 2022 年 10 月上旬开始，为北美、欧洲、中东和中国台湾制造的所有 Model 3 与 Model Y 车型均不再配备超声波传感器，而将完全依靠 Tesla Vision 以实现 Autopilot、增强 Autopilot、FSD 以及主动安全等功能。</p><p></p><p>未来几个月，特斯拉将在全球范围内推广这一波去超声波传感器运动，随后 Model S 和 Model X 也将于 2023 年加入行列。</p><p></p><p>特斯拉表示，此举也标志着 Tesla Vision 在发展道路上迈出了新的一步。</p><p></p><p>自 2021 年，特斯拉开始转向 Tesla Vision，先期在 Model 3 与 Model Y 车型上移除雷达，随后又在今年推广至 Model S 与 Model X。如今，在全球大部分地区，这些车型都将采用 Tesla Vision 纯摄像头自动驾驶系统。</p><p></p><p>自推出以来，特斯拉不断在功能对等性与安全性等方面开展渐进式改进。与配备雷达的车型相比，配备 Tesla Vision 的 Model 3 与 Model Y 在美国和欧洲的主动安全等级保持不变或有所提升，而且在行人自动紧急制动（AEB）干预方面表现更好。</p><p></p><p>自取消雷达以来，特斯拉对其软件进行了重大改进，以启用其高级驾驶辅助功能 (ADAS)。这包括其基于视觉的占用网络（occupancy network，目前已在 FSD Beta 中应用），Full Self-Driving Beta 依赖于该网络。根据特斯拉的公告，占用网络将取代 USS 生成的输入。借助当前软件，这种方法能够为 Autopilot 提供高清空间定位、更远距离的可见性以及识别 / 区分对象的能力。与其他特斯拉功能一样，占用网络模型也将随时间推移而不断快速改善。</p><p></p><p>在这段过渡期内，未配备 USS 的 Tesla Vision 车型可能出现部分功能暂时受限 / 不可用的情形，包括：</p><p></p><p>泊车辅助：当车辆以低于 5 英里 / 小时行驶时，提示车身周边的物体。自动泊车：自动驶入纵向或侧向车位。召唤：通过 Tesla 应用手动向前 / 向后移动车辆。智能召唤：通过 Tesla 应用将车辆导航至车主所在 / 所指定的位置。</p><p></p><p>特斯拉表示，在过渡期间，未安装超声波传感器的 Tesla Vision 并不会影响到 2022 年 10 月及之后交付的 Model 3/Model Y 车型的安全等级。过渡期间的影响不涉及碰撞安全等级，配备 Tesla Vision 的车辆与配备 Vision+ 雷达 +USS 的车辆拥有相同的碰撞安全等级。</p><p></p><p>在不久的将来，当这些功能达到与当前车型相当的功能，上述选项将通过一系列 OTA 软件更新得以恢复。所有其他可用的 Autopilot、增强 Autopilot 及 FSD 功能将在车辆交付时正常起效，具体取决于用户的订单配置。</p><p></p><p>而针对已售出的车型，特斯拉并不打算移除其配备的超声波传感器功能。</p><p></p><p></p><h2>“&nbsp;雷达杀手”马斯克</h2><p></p><p></p><p>作为高级传感器，激光雷达对于自动驾驶来说非常重要，激光雷达是安全自动驾驶是必不可少的设备之一。现在很多自动驾驶车企以及造车新势力等都在自家车型上应用了激光雷达，例如，小鹏 P5、蔚来 ET7、理想 L9、威马 M7、智己 L7 等搭载激光雷达的车型已在国内上市。</p><p></p><p>但作为全球最具影响力的自动驾驶探索者之一，马斯克和他的特斯拉对激光雷达却一向没有好感。马斯克一直是坚定的纯视觉自动驾驶倡导者。</p><p></p><p>为了节省成本，特斯拉坚决拒绝使用激光雷达进行精准测距。2014 年，被称为“激光雷达”的激光传感器成本为 75,000 美元。虽然之后随着激光雷达和摄像头混合技术的进步，成本有所降低，但使用激光雷达还是会让特斯拉挣不到钱。所以特斯拉选择依靠计算机视觉方案实现自动驾驶。</p><p></p><p>马斯克经常嘲讽激光雷达和多传感器融合路线。2019 年，马斯克“False and foolish = HD maps and LiDAR”（傻子才采用高清地图加激光雷达）的言论一出，当即引起了很大的争论。</p><p></p><p>马斯克认为，“（激光雷达）就像是人身上长了一堆阑尾，阑尾本身的存在基本是无意义的，如果长了一堆的话，那就太可笑了。任何依赖激光雷达的公司都可能无疾而终。”&nbsp; “当雷达和视觉系统发生判断冲突时，你会相信哪一个？视觉系统的精度更高，所以倒不如配合必要的传感器进一步发掘视觉系统的潜力”；“激光雷达毫无意义，对于自动驾驶汽车来说没有必要”；“激光雷达昂贵、丑陋、没有必要”...</p><p></p><p>去年 7 月，特斯拉公司 AI 高级总监 Andrej Karpathy &nbsp;曾在 CVPR2021 年自动驾驶研讨会上表示，激光雷达加高清地图这套基础设施的持续更新会带来极高的成本，所以特斯拉采取的方案则主要基于视觉元素。车辆可以依靠环绕车身的 8 个摄像头即时捕捉并理解周边发生的一切。这样当第一次来到某个十字路口，就需要弄清楚车道在哪里、每条车道间如何连接、交通灯在哪里、什么灯控制什么车道等，一切都由车辆亲自观察和处理，不需要高清地图作为支持。</p><p></p><p>特斯拉认为，其深度学习系统比雷达要强上一百倍，激光雷达技术并不是自动驾驶技术的最终选择。</p><p>Karpathy 表示，特斯拉过去几年构建的视觉系统已经非常出色，因此不再需要其他各类传感器。摄像头已经能够满足视觉感知方面的大部分需求，因此特斯拉能够更有信心地逐渐去掉那些已无必要的旧有传感器装置。</p><p></p><p>Karpathy 认为，视觉加传感器的组合在自动驾驶效果上已经远远超越了雷达方案。自动驾驶中的元素并不是越多越好，需要保留真正有贡献的元素、去掉经常产生噪声的元素，这样才能构建起稳定可靠的解决方案。”</p><p></p><p>此前特斯拉的传感器方案为 8 摄像头，1 毫米波雷达，12 超声波雷达。在特斯拉汽车的前后保险杠上安装有 12 个超声波传感器，短程声波传感器主要用于停车和检测近距离物体。</p><p></p><p>2021 年 5 月，特斯拉宣布去掉了毫米波雷达。一年多后，特斯拉再度减配，移除超声波雷达，以后将是8个摄像头走天下了。Guidehouse Insights 分析师 Sam Abuelsamid 认为，“去掉超声波传感器，会为他们节省几美元。因为超声波传感器都很便宜。”</p><p></p><p>业内关于激光雷达与视觉算法的技术之争由来已久，激光雷达数据精度更高，但其成本高昂，视觉方案成本优势高，但感知精度不够。此前有自动驾驶专家曾向 InfoQ 谈到自己的观点，“自动驾驶离不开激光雷达，图像技术足够成熟至少还要十年。”</p><p></p><p>参考链接：</p><p></p><p>https://www.tesla.com/support/transitioning-tesla-vision</p><p></p><p>https://www.notateslaapp.com/news/1003/tesla-is-removing-ultrasonic-sensors-from-all-of-its-vehicles</p>",
    "publish_time": "2022-10-11 14:56:25",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "进入工业大生产阶段，能让AI真正产业落地的关窍是什么？",
    "url": "https://www.infoq.cn/article/csAtICUTZ3ejLpRM7S2G",
    "summary": "<p></p><p></p><blockquote>AI深入产业落地，关键在于人才。</blockquote><p></p><p></p><p></p><h3>大模型等基础共性AI技术降低应用门槛&nbsp;, AI人才推动产业智能化升级</h3><p></p><p></p><p>9月25日，在由深度学习技术及应用国家工程研究中心与百度联合发起的AICA首席AI架构师培养计划第五期、第六期双期毕业典礼上，来自五期班的57位学员与六期班的75位学员通过答辩获得毕业证书。</p><p></p><p>现场，百度集团副总裁、深度学习及应用国家工程研究中心副主任吴甜在致辞中表示，人工智能与产业的融合越来越深入，通过深度学习平台持续建设和发展，大模型等基础共性 AI 技术让应用门槛不断降低，可以预见 AI 应用更有前景的未来。</p><p></p><p>吴甜讲到，预训练大模型技术是人工智能发展的重要方向，通过自监督学习、弱监督学习，大模型从海量数据中学习知识和规律。依托于大模型，在场景应用中通过少量数据的精调就得到很好的效果，成本降低且效果提升，从而 AI 技术可以更大规模的应用，推动实现工业大生产。人工智能和产业共同发展的底层规律在 AICA 项目中得到印证，飞桨将与来自各行各业的学员们一起持续推动 AI 深入产业，推动智能化升级。</p><p></p><p>数据显示，截止2022年5月，飞桨已凝聚477万开发者，创建56万模型，服务18万企事业单位，同时产学研用紧密协同培养超过200万AI人才。</p><p></p><p></p><h3>培养深入产业的AI架构师</h3><p></p><p></p><p>随着AI进入工业大生产阶段，全新AI应用正在加速与纵深垂直行业场景深度融合。AICA首席AI架构师培养计划目标培养集业务理解、技术理解和工程实践为一体的复合型AI人才，通过培养产业人才的方式来打通产业智能化升级的关窍。</p><p></p><p>据悉，百度AICA六期班首次采取了百人班制，课程内容设置以对深度学习落地技术的全景解读和框架梳理为起点。对于具体实际的AI产业落地问题，百度架构师们一对一帮助学员梳理项目困难与难点，帮助学员构建AI项目架构与思考路径。AICA希望助力学员将AI与各自企业实际业务相结合，为业务问题带去可实践的方案，最终为企业创造智能化价值。</p><p></p><p>参与培训计划的学员中来自500强企业、专精特新龙头企业的比例较往期提高一倍，并首次出现了来自海外企业的AI方向学员；在AI业务方向上，五、六期班学员所关注的AI与业务融合场景更加广泛和深入，涉及能源油气、智能制造、智慧医疗、智慧城市、智能交通等多个领域，场景也更贴近民生。</p><p>&nbsp;</p><p>例如在交通领域，铁路客运从人脸识别进一步升级到步态识别，开创新的研究方向和应用可能；医疗领域，学员利用AI技术实现基于音频分类的呼吸暂停事件检测及分析系统；能源领域，场景已广泛拓展覆盖煤矿视频分析、风电场无人巡检和风机叶片缺陷检测、电力业务模型压缩和异构转换、智慧加油站解决方案、光伏组件故障识别诊断等；AI+科学计算的前沿领域探索上，学员利用AI技术进行台风风场重构和风暴潮预测研究。</p><p>&nbsp;</p><p>目前，六期班来自国家能源、中石油、中海油、中国一汽、中国铁道科学研究院、光大科技、山东瑞邦等行业龙头、专精特新在内的企业学员已经成功将AI技术应用到公司的项目中，并为以后AI场景融合的大规模落地打下基础。</p><p></p><p></p><h3>代表案例解析</h3><p></p><p>据悉，自2019年推出至今，AICA已累计向业界输送了322名AI架构师，培养了懂AI、懂业务，并将AI付诸于业务实践的高端复合型AI人才。</p><p></p><p>以下为第六期优秀学员中，AI方向的代表案例解析。</p><p></p><h4> 基于铁路客运进出站的步态身份识别研究</h4><p></p><p></p><p>来自中铁程科技有限责任公司的李贝贝，此前是一名架构师，在工作了几年后，他看到了AI火热的趋势和蕴藏的能量，并且产生了浓厚的兴趣，于是，他决定转型成为一名AI架构师。</p><p></p><p>转型之后，李贝贝发现，与普通架构师相比，AI架构师需要掌握的技能知识点更多，例如对基础数学的能力和经验要求更高，此外还需要掌握AI知识。为了锻炼和提升自己，李贝贝报名了百度AICA计划。</p><p></p><p>今年5月加入AICA六期班时，李贝贝选择的项目方向是基于铁路客运进出站的步态身份识别研究。与人脸识别相比，步态识别不仅具有人脸识别的“无接触”特点，还具有可远距离观察、易于捕捉等特点，结合疫情的安全防护需要，辅助实现旅客无需摘口罩即可出站，简化旅客出站的同时，降低新冠传播或感染风险。</p><p></p><p>在研究过程中，李贝贝通过AICA的学习，参考并不断吸收百度飞桨的相关经验。例如飞桨企业版EasyDL零门槛AI开发平台和BML全功能AI开发平台，能够让开发者更便捷、高效地完成AI应用开发；PaddleLite端侧推理引擎能实现多种算法之间的串联部署等。“我们面向的主要是铁路场景，但其中也有很多细分场景，百度飞桨给予我很多思考和支持。”</p><p></p><p>李贝贝表示，AICA的学习经历让他对AI整体体系和理念有了非常直观的认识，未来也将持续在铁路领域进行AI应用的探索。</p><p></p><h4>软通动力数字人探索：未来你的面试官可能是虚拟人！</h4><p></p><p></p><p>易呈是软通动力正在进行中的虚拟数字人项目的一员，他所在的AI专项组主导两个项目，虚拟数字人和简历解析与智能匹配。易呈主要负责AI算法模型研究，包括AI产品和架构设计。</p><p></p><p>软通动力一直深耕数字化转型，并持续追踪和探索行业前沿技术与产品，元宇宙就是其中之一。目前，软通已推出自己的数字孪生和元宇宙产品平台，而近年来大火的数字人便是重要的一个研究方向。</p><p></p><p>软通动力计划从数字人这条线切入，初期实现在软通内部使用，而后对外推出企业级应用。项目主要面向两个细分方向，一是虚拟主播，在公司内部的展厅、电梯等做新闻播报；二是结合组内简历解析的优势打造虚拟数字人面试官。一般面试官进行一轮面试通常需要花费几十分钟时间，而软通每年有大量的面试，数字人面试官可以作为初面环节的面试官，通过在线的方式与候选人做初步的沟通，了解候选人的意向，并通过AI算法进行自动化的评价，以待用人方做出进一步判断，提升候选人面试体验。</p><p></p><p>今年，软通动力数字人项目的Demo出炉，在对其进行更高层次的研发过程中，易呈团队遇到了一系列挑战。在这时，易呈想到了此前在铁路领域工作时接触到的飞桨，恰巧软通动力也已经与百度飞桨建立了生态伙伴合作关系，于是易呈便撰写了课题，申请前往AICA进行交流学习，希望借助飞桨进一步提升软通动力虚拟数字人的表现。</p><p></p><p>通过在AICA的交流学习，易呈团队面临的诸多技术难题有了重大突破。例如，虚拟面试官对实时性要求较高，易呈团队与飞桨PaddleGAN团队一起探索人脸表情和唇形实时渲染方案，即用离线方式、工程化的思路打造近似实时的体验，通过生成很多短视频，根据用户的输入指令把离线视频通过流的形式推给用户，实现与用户的实时问答。</p><p></p><p>回顾该经历，易呈表示，AICA对有经验的技术人员带来的提升不仅仅局限在技术上，更多地是开拓眼界和思维方式，还有在AICA结识了众多老师、助教老师，以及一帮同学好友。</p><p></p><p>另一个重要的价值在于，AICA能够带领一些“门外”的人进来，从认识到实操。“我发现，很多学员之前不是AI领域的，AICA能够是把这些人从‘门外’拉进来，真正去摸一摸AI到底是什么东西，让产业的企业引起对AI的重视。对普通人来说，人工智能就像是雾里看花一般，但对实际应用开发者来说，它与做软件或硬件开发类似，都会经历一个‘1+1=2’的过程，，只是很多人根本就不知道怎样找到1+1的路径，AICA就是把这些人引到这条路上来”。</p>",
    "publish_time": "2022-10-11 15:56:27",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "新一波 JavaScript Web 框架",
    "url": "https://www.infoq.cn/article/2SyNfw6RkyTV4gkRavIQ",
    "summary": "<p></p><blockquote>这篇文章让读者们了解为什么新的 JavaScript Web 框架扩散如此迅速，并且对大规模的问题和创新的最新发展进行了深入的探讨。</blockquote><p></p><p>&nbsp;</p><p>太过保守很难在 Javascript 生态系统中保持与时俱进。对于那些刚进入这个行业的人来说，要在新的库、框架、概念和有力的意见中关注正在发生的事情，很有挑战性。这是个很好的提醒，默认情况下，使用“无聊”的技术，你所熟悉的技术，并且成为晚期采用者，通常是个不错的选择。</p><p>&nbsp;</p><p>闲话少叙，本文将带读者了解 Javascript 中生态系统中的最新进展，通过研究过去在构建大规模 Web 应用时的痛点来了解当前的情况。</p><p>&nbsp;</p><p>不要把注意力集中在快速增长的解决方案上，而是从潜在问题入手。每一种架构都会有不同的答案，并且会有不同的权衡。到本文结束时，我们会列出流行框架的高级模型，如 React、Svelte、Vue、Solid、Astro、Marko、Fresh、Next、Remix、Qwik，以及适合当今环境的“元框架” 。</p><p>&nbsp;</p><p>鉴往知来。让我们回首来时路，再看看未来的趋势。这次，我们将专注于大型项目中的问题，这些问题激发了其他方法和思维方式。</p><p>&nbsp;</p><p></p><h2>网页简史</h2><p></p><p>&nbsp;</p><p>Web 最初由静态文档链接在一起组成。那时候，人们可以提前准备一份文件，并把它放在电脑上。而现在最酷的就是，人人都可以访问它，无需亲临其境。</p><p>&nbsp;</p><p>不知从何时起，我们觉得，让这些文件变成动态，会非常酷。于是我们有了像 <a href=\"https://en.wikipedia.org/wiki/Common_Gateway_Interface\">CGI</a>\" 这样的技术，使我们能够根据请求提供不同的内容。然后，我们有了像 <a href=\"https://www.perl.org/\">Perl</a>\" 这样的表达式语言来编写这些脚本。它对最初针对 Web 开发的 <a href=\"https://en.wikipedia.org/wiki/PHP\">PHP</a>\" 产生了影响。PHP 的创新之处在于将 HTML 直接连接到后端代码。这使得以编程方式创建嵌入动态值的文件变得容易了。</p><p>&nbsp;</p><p>Web 最重要的突破之一来自于此：</p><p>&nbsp;</p><p><code lang=\"null\">\n\nThis document has been prepared ahead of time.\nRegards.\n\n</code></p><p>&nbsp;</p><p>具有易于嵌入的动态值：</p><p>&nbsp;</p><p><code lang=\"null\">\n\nY2K? <!--?php echo time(); ?-->\n\n</code></p><p>&nbsp;</p><p></p><h3>框架时代拉开大幕</h3><p></p><p>&nbsp;</p><p>这些动态页面很受欢迎。我们可以很轻松地对发送给用户的内容进行定制，包括启用会话的 cookies。在与数据库交互的语言生态系统中，已经有了基于服务器的模板框架。通过这些框架，我们可以轻松地从静态页面开始，然后扩展到动态页面。</p><p>&nbsp;</p><p>Web 的发展一日千里，我们想要更多的互动体验。为了这个目的，我们使用了 <a href=\"https://en.wikipedia.org/wiki/Adobe_Flash\">Flash</a>\" 这样的浏览器插件。在其他方面，我们会在后端提供的 HTML 上“撒上” Javascript 片段。</p><p>&nbsp;</p><p>像 jQuery 和 Prototype 这样的工具出现了，它们隐藏了 Web API 的复杂度，消除了浏览器之间的差异。</p><p>&nbsp;</p><p>光阴荏苒，科技公司的规模在不断扩大，并且由于项目和开发团队的增长，在模板中加入更多的业务逻辑是非常普遍的。</p><p>&nbsp;</p><p>编写的服务器代码，将处理后的数据传输到服务器模板语言中。模板常常会演变成业务逻辑的“混合体”来访问全局变量。由于像 SQL 注入这样的攻击已经司空见惯，因此安全问题也越来越突出。</p><p>&nbsp;</p><p>最终，论文《<a href=\"https://designftw.mit.edu/lectures/apis/ajax_adaptive_path.pdf\">Ajax：Web 应用的新方法</a>\"》（Ajax: A New Approach to Web Applications）为我们带来了 Ajax 技术。现在你用 Ajax 技术可以做的新事情就是用异步方式更新页面，而不再是以同步的方式来更新页面。这种模式被第一批大型客户端应用程序所推广，如谷歌地图和谷歌文档。后来，我们开始看到 Web 分发对桌面风格的软件的影响力。与在商店里购买光盘的软件相比，这是一个重大的进步。</p><p>&nbsp;</p><p></p><h3>JavaScript 壮大</h3><p></p><p>&nbsp;</p><p>当 node 出现的时候，它所带来的新特性，就是用与前端相同的语言来编写你的后端。所有这些都是开发人员所熟悉的异步优先模式。这曾经令人无法抗拒，当然现在也是。随着越来越多的企业上线，竞争优势在于能否快速交付和迭代。</p><p>&nbsp;</p><p>Node 的生态系统强调重复使用小型的单用途包，你可以利用现成的去完成任务。</p><p>&nbsp;</p><p></p><h3>前端与后端分离</h3><p></p><p>&nbsp;</p><p>我们更渴求能够与桌面、移动设备相媲美的 Web。现在，我们已经有了一系列可重用的“小部件”库和工具，如 jQuery UI、Dojo、Mootools、ExtJs 和 YUI 等。</p><p>&nbsp;</p><p>我们对这些小玩意儿的关注程度与日俱增，并且在前端的工作也越来越多。这往往导致了前端和后端的模板重复。像 Backbone 和 Knockout 以及许多其他的框架出现了。它们通过 MVC、MVVM 等架构为前端增加了关注点的分离，并且，架构可以兼容我们收集到的所有小部件和 JQuery 插件。添加结构有助于扩展所有这些前端代码。并且可以加速从后端传送模板。</p><p>&nbsp;</p><p>我们仍然编写微调的 DOM 操作来更新页面并保持组件的同步。这个问题非同小可，而且与数据同步相关的错误也很常见。</p><p>&nbsp;</p><p>在谷歌的支持下，Angular 登场了。它通过增强 HTML 的动态性，促进了生产力的提高。它配备了双向数据绑定，以及一个受电子表格启发的反应性系统。这些声明式的双向绑定消除了许多必须更新的模板。这是好事，可以让我们的工作效率更高。</p><p>&nbsp;</p><p>随着规模的扩大，跟踪变化越来越困难，常常会造成性能下降。更新的周期会发生，并占据主线程（今天像 Svelte 这样的库可以在降低其缺陷的情况下保<a href=\"https://imfeld.dev/writing/how_svelte_makes_two_way_binding_safe\">持双向绑定</a>\"）。除了移动设备的兴起之外，这些提高生产力的框架也加速了前端和后端的分离。这为探索强调这种解耦的不同架构铺平了道路。</p><p>&nbsp;</p><p>这是 JAMstack 理念的一个主要部分，强调提前预生成 HTML，并从 CDN 提供服务。在当时，这是对提供静态文档服务的一种倒退。但现在，我们有了基于 git 的工作流，有了强大的 CDN 基础设施，有了可以与独立 API 互动的解耦前端，就无需依靠远在天边的中央服务器。与运营服务器相比，将静态资产放置到 CDN 上要便宜很多。</p><p>&nbsp;</p><p>今天，像 Gatsby、Next 和很多的其他工具都利用了这些想法。</p><p>&nbsp;</p><p></p><h2>React 崛起</h2><p></p><p>&nbsp;</p><p>快步流星地进入大科技时代。我们正试图追风逐电，一改故辙。对于那些进入这个行业的人来说，Javascript 很大，而构建一个由独立后端支持的解耦 SPA 已经成为现实。</p><p>&nbsp;</p><p>在 Facebook，React 的诞生面临着几个挑战。</p><p>&nbsp;</p><p>数据频繁变化时的一致性：保持许多小部件之间的同步，仍然是一项重大的挑战。由于数据流缺乏可预测性，这在规模上是个问题。组织上的扩展：优先考虑进入市场的时间和速度。对于新开发人员来说，能否快速上手，并且富有成效，这一点至关重要。</p><p>&nbsp;</p><p><a href=\"https://www.infoq.cn/article/YZMFbo42uyHdps9WiQif\">React </a>\"诞生了，你能做得很酷的新事情就是声明性地编写前端代码。</p><p>&nbsp;</p><p>前端关注点的分离是著名的反思，以前的 <a href=\"https://www.youtube.com/watch?v=nYkdrAPrdcw&amp;feature=share&amp;si=ELPmzJkDCLju2KnD5oyZMQ&amp;t=438\">MVC 框架无法扩展</a>\"。人们并不喜欢从模板向 Javascript 驱动的 JSX 过渡。但是我们大多数人都接受了。</p><p>&nbsp;</p><p>组件模型允许解耦独立的前端团队，他们可以更容易地在独立组件上并行工作。作为一个架构，它允许组件的分层。从共享的原语到构成页面根目录的“有机体”。单向的数据流使数据流更易于理解、跟踪和调试。这就提高了之前难以企及的可预见性。虚拟 DOM 就是我们可以编写函数，返回用户界面的说明，让 React 去解决这些难点。这样可以避免在数据频繁变化时出现的一致性问题，并且使得模板的组成更加人性化。</p><p>&nbsp;</p><p></p><h2>规模化的 React 已达到 CPU 和网络的极限</h2><p></p><p>&nbsp;</p><p>React 非常流行，已经成为了业界的标准，即使是那些不想要其特性的网站来说也是如此。在规模的远端，我们开始看到一些限制。</p><p>&nbsp;</p><p></p><h3>CPU 遭遇很大阻力</h3><p></p><p>&nbsp;</p><p>DOM 是 <a href=\"https://www.infoq.cn/article/3zjScEsgksmFNdgIR7sM\">React 模型</a>\"的一个问题。浏览器并不是为了在连续的渲染周期中不断创建和销毁 DOM 节点而构建的。就像任何可以通过引入一个新的间接级别来解决的问题一样，React 把它抽象到了虚拟 DOM 后面。</p><p>&nbsp;</p><p>人们只有在 100 毫秒以内感知到反馈，才会感到流畅。而在做像滚动页面这样的事情时则要低得多。在与单线程环境相结合的情况下，这种优化已经成为高度交互式应用的新瓶颈。当虚拟 DOM 和真实 DOM 之间发生协调时，大型交互式应用程序会对用户的输入失去响应。像“长任务”这样的术语开始出现了。</p><p>&nbsp;</p><p>这导致了 React 在 2017 年被重新编写，为并发模式奠定了基础。</p><p>&nbsp;</p><p></p><h3>运行时成本增加</h3><p></p><p>&nbsp;</p><p>与此同时，更快的移动意味着传输更多的代码。浏览器在运行大量 Javascript 时，启动速度慢就成为一个问题。我们开始注意到所有隐含的运行时成本，不仅是 HTML 和虚拟 DOM，还有我们编写 CSS 的方式。</p><p>&nbsp;</p><p>组件模型简化了我们在 CSS 方面的经验。我们可以将样式与组件放在一起，这提高了可删除性。对于那些以前不敢删除 CSS 代码的人来说，这是一个非常好的属性。我们一直在处理的级联和所有的特殊性问题都被 JavaScript 库中的 CSS 抽象化了。</p><p>&nbsp;</p><p>这些第一波的库往往伴有隐含的运行时成本。我们需要等到组件被渲染后，再将这些样式注入到页面中，这就造成了 JavaScript 包中的样式问题。从规模上来说，糟糕的性能往往是千夫所指，而我们也注意到了这些成本。这导致 JavaScript 库中出现了新的 CSS，它通过使用智能预编译器来提取样式表，这些库专注于没有运行时的开销。</p><p>&nbsp;</p><p></p><h3>效率低下的网络和渲染受阻的组件</h3><p></p><p>&nbsp;</p><p>当浏览器渲染 HTML 时，像 CSS 或脚本这样的渲染障碍资源会阻止 HTML 的其他部分显示出来。在一个组件的层次结构中，父组件往往会成为子组件的渲染障碍。</p><p>&nbsp;</p><p>在实践中，许多组件依赖于数据库的数据和 CDN 的代码（通过代码分割）。这经常会造成瀑布式的网络请求阻塞。在渲染之后，组件会获取数据，解锁异步子组件。接着，它们将会获取它们所需的数据，并重复这一过程。经常可以看到“下拉列表的地狱”或累积布局偏移，这些变化是在加载 UI 时出现在屏幕上的。</p><p>&nbsp;</p><p>React 后来发布了 Suspense，以使页面的加载阶段更加顺畅。但是，默认情况下，这并不能防止持续的网络瀑布问题。Suspense 支持“在获取数据时渲染”的模式。</p><p>&nbsp;</p><p></p><h2>Facebook 如何解决这些问题</h2><p></p><p>&nbsp;</p><p>我们将继续绕行，了解 React 的一些权衡如何在规模上得到缓解。这将有助于构建新框架中的模式。</p><p>&nbsp;</p><p>优化运行时成本</p><p>&nbsp;</p><p>在 React 中，<a href=\"https://svelte.dev/blog/virtual-dom-is-pure-overhead\">虚拟 DOM 的运行时成本是无法避免的</a>\"。并发模式是一个解决问题的方法，它可以让你在高度互动的体验中保持对事情做出响应。</p><p>&nbsp;</p><p>在 JavaScript 中的 CSS 领域，使用了一个名为 Stylex 的内部库。当成千上万的组件被渲染时，这可以维持人性化的开发人员体验，而无需运行时的成本。</p><p>&nbsp;</p><p>优化网络</p><p>&nbsp;</p><p>Facebook 用 Relay 来避免顺序性的网络瀑布问题。对于一个给定的入口点，静态分析可以精确地确定要加载的代码和数据。这就意味着代码和数据都可以在一个优化的 graphQL 查询中并行加载。</p><p>&nbsp;</p><p>这比初始加载和 SPA 转换的顺序网络瀑布要快得多。</p><p>&nbsp;</p><p>优化 Javascript 包</p><p>&nbsp;</p><p>其中一个基本问题就是传递 JavaScript，这些 JavaScript 与具体的用户无关。</p><p>&nbsp;</p><p>如果有 A/B 测试，特性标记的经历，以及针对特定类型和群组的用户的代码时，那就很困难了。还有语言和地区设置。当代码有许多分支时，静态依赖关系图不能看到在实践中为特定用户群一起使用的模块。</p><p>&nbsp;</p><p>Facebook 使用了一个由人工智能驱动的动态包系统。这利用其紧密的客户-服务器集成，在运行时根据请求计算出最佳的依赖图。这与一个根据优先级分阶段加载包的框架相结合。</p><p>&nbsp;</p><p></p><h3>生态系统的其他部分呢？</h3><p></p><p>&nbsp;</p><p>Facebook 拥有复杂的基础设施和多年来构建的内部库。如果你是一家大型科技公司，你可以投入大量的资金和资源来优化这些大规模的权衡。</p><p>&nbsp;</p><p>这为前端产品开发人员创造了一个成功的深渊，可以让他们在完成任务的同时保持性能。</p><p>&nbsp;</p><p>我们中的大多数人都不会像 Facebook 那样的规模上构建一套应用。然而，对于许多大型企业来说，性能是个话题。我们可以从这些模式中学习，例如：尽可能多地获取数据，并行化网络，以及使用内联需求等等。</p><p>&nbsp;</p><p>大型科技公司经常在内部推出自己的应用框架。在不同的用户资源库中，遗留了大量的解决方案。这导致了许多 Javascript 生态系统疲劳和框架倦怠。</p><p>&nbsp;</p><p></p><h2>JavaScript 的世界：群龙无首</h2><p></p><p>&nbsp;</p><p>还跟我们在一起？我们正处于 SPA 的时代。这就是目前从事这一行的人所面临的现状。</p><p>&nbsp;</p><p>React 是无可争议的冠军，然而，我们看到了大规模的取舍。</p><p>&nbsp;</p><p>React 提供了一个层。它将其他必要的层留给了生态系统，在路由、状态管理、数据获取等各个重要方面造成了混乱，每个层都有自己的概念和 API。</p><p>&nbsp;</p><p>不可变与可变，带有类的 OOP 与函数式的 OOP，争论和库都如火如荼。</p><p>&nbsp;</p><p>如今，很多开发人员都被不确定的事情所困扰，他们不知道应该怎么去做，也不知道该怎么去构建。</p><p>&nbsp;</p><p></p><h2>起来，起来，React 替代品！</h2><p></p><p>&nbsp;</p><p>组件是有黏性的。但运行时成本、Javascript 驱动的 JSX 以及复杂性都有待讨论。很多不是来自大型科技公司的草根替代方案，已经获得了广泛的认同。让我们对这些方案做一个总论：</p><p>&nbsp;</p><p></p><h3>Vue</h3><p></p><p>&nbsp;</p><p>当人们在评估迁移到 Angular 2 或 React 时，Vue 填补了入门门槛低的空白。你不必为复杂的 webpack 配置而担心。你可以从 CDN 上下载并开始使用对许多开发人员来说很直观的模板来构建组件。</p><p>&nbsp;</p><p>核心团队可以使用路由和样式等核心组件，减少决策疲劳。它还通过对模板进行静态分析，缓解了 React 调和算法的某些方面，以实现优化，加快运行时。这被称为编译器通知的虚拟 DOM。</p><p>&nbsp;</p><p></p><h3>Svelte</h3><p></p><p>&nbsp;</p><p>Svelte 开创了预编译方法的先河，消除了我们在运行时看到的复杂性和开销。</p><p>&nbsp;</p><p>我们的想法是要有一个可以自行编译的框架，并简化输出最小的普通 JavaScript。所有这些都是基于声明式组件和熟悉的可变 Javascript 风格来保持现代的创作体验。Svelte 完全避免了使用虚拟 DOM，因此不会受到编写 Javascript 的不可变风格的约束，这种风格可以用来做更新状态之类的事情。对于许多人来说，这是一个更简单、更理智地在 Web 上构建东西的模型。</p><p>&nbsp;</p><p></p><h3>Solid</h3><p></p><p>&nbsp;</p><p>Solid 有一个直接的和可预测的反应性模型，其灵感来自 Knockout。像 React 一样，它也避免了使用模板来简化函数的可组合性。</p><p>&nbsp;</p><p>而 React 采取的是不断重新渲染世界的方法。Solid 只渲染一次，并在不增加虚拟 DOM 开支的情况下，使用精简的反应性系统进行细粒度的更新。Solid 看起来就像我们许多 React 开发人员想要使用钩子的新代码那样。它的 API 也许更人性化，并且在许多方面非常顺利，例如钩子的依赖数组，其重点是细粒度的反应性和可组合的原语。</p><p>&nbsp;</p><p></p><h3>交流互鉴</h3><p></p><p>&nbsp;</p><p>对于每个框架，还有许多可说的。每个人都会在自己的基本模式和喜好上作出不同的权衡。</p><p>&nbsp;</p><p>在现实中，进化往往是由人类的意志决定的。尝试不同的解决方案来解决当前的痛点，每个框架都从彼此中学习。其中一个重要的主题就是精简和简化。把事情从运行时移到编译时是这些主题之一，它激发了 “React forget”，这是一个有望能够消除记忆化需求的特性。它们的共同点是解决了文件的交互部分。正如我们所看到的，这是一个具有挑战性的方面，要以一种容易扩展的方式来解决。</p><p>&nbsp;</p><p>同时，我们看到了纯客户端渲染的权衡。当加载一个页面时，那个空白的白屏需要更长的时间。在移动设备和网络上，这真是一场灾难。对于很多网站来说，网页打开速度更快，且性能不降低，成为一个主要的竞争优势。</p><p>&nbsp;</p><p>我们迈出了这一步，正在探索通过首先在服务器上渲染内容来加快渲染速度的方法（后来才发现这是一种权衡）。这个最初的倒退引发了许多“元”框架和 HTML 优先前端框架的新浪潮。</p><p>&nbsp;</p><p></p><h2>新一波的 JavaScript Web 框架</h2><p></p><p>&nbsp;</p><p></p><blockquote>我们不会停止探索。我们所有探索的终点就是我们开始的地方。也是第一次知道这个地方。</blockquote><p></p><p>&nbsp;</p><p>受 PHP 的启发，Next 开始简化创建静态页面推送到 CDN 的过程。它还解决了在 React 应用程序中使用 SSR 的棘手问题。</p><p>&nbsp;</p><p>它还提供了一些关于使用基于文件的路由来构建应用程序的意见，这很受欢迎。还有其他一些不错的特点。从那时起，又有一波“元”框架被创建。对于 Vue，我们在 Nuxt 中有一个类似的框架。Svelte 的 Sveltekit，以及即将推出的 SolidStart。</p><p>&nbsp;</p><p>这些都是服务器优先，旨在整合 Web 框架的所有部分和人体工程学。这并不仅仅是人们长久以来所关心的互动元素。</p><p>&nbsp;</p><p>对话的出发点是改进用户的经验和开发人员的经验，而非一种交换。</p><p>&nbsp;</p><p></p><h3>MPA 的反击</h3><p></p><p>&nbsp;</p><p>多页面架构从服务器上提供 HTML，其中导航是全页面刷新。快速启动对于很多站点来说都是至关重要的，尤其是那些没有登录的站点。它直接关系到诸如搜索排名和跳出率之类的事情。对于许多互动性低的网站和应用程序来说，使用像 React 这样的客户端渲染库，就过于夸张了。</p><p>&nbsp;</p><p>对许多人来说，这意味着翻转脚本。做到 HTML 优先而不是 Javascript 优先，MPA 优于 SPA，并默认为零 Javascript。</p><p>&nbsp;</p><p>像 Marko、Astro、Fresh、Rocket 和 Enhance 等框架都采用了这种方法。与一些元框架相比，路由器停留在服务器上，而不是让客户端的路由器在第一次加载后接管。在 Javascript 生态系统中，这是对 Node 之后不久的基于服务器的模板制作的一种倒退。</p><p>&nbsp;</p><p>这一轮的 MPA 与前几代不同。“Sprinkles”是在一个基于组件的模型中编写的，通常使用 island 模式。在前端和后端代码中使用相同的语言。往往在同一个文件中共存。这就消除了在添加一些交互性时前端和后端构造不同的重复模板代码的问题。</p><p>&nbsp;</p><p></p><h3>渐进增强的回归</h3><p></p><p>&nbsp;</p><p>Remix 在 React 生态系统中带来了渐进增强的回归。</p><p>&nbsp;</p><p>从技术角度来看，Remix 是 React Router 的编译器，和其他新兴的元框架一样，是一个边缘兼容运行时。它通过嵌套布局和数据获取 API，解决了 Facebook 通过 Relay 大规模解决的相同挑战。</p><p>&nbsp;</p><p>这允许早期的代码和数据的并行获取。这是用 Suspense 实现“边渲染边获取”模式的一个良好前提条件。对渐进增强的强调意味着它的 API 基于 Web 标准，数据变异的故事基于 HTML 表单。</p><p>&nbsp;</p><p>而不是通过连接事件处理程序来进行必要的获取请求。你渲染表单，将数据提交给在服务器上处理它们的动作函数（通常在同一个文件中）。受到 PHP 的启发。</p><p>&nbsp;</p><p>与 Next 类似，应用程序可以缩小规模，像传统的服务器渲染的 MPA 那样在没有 Javascript 的情况下工作，或者按每页的规模扩展到交互式 React 应用程序。</p><p>&nbsp;</p><p>Remix 还提供了许多 API 和模式，用于处理诸如乐观的 UI 更新、静态条件的处理以及优雅的退化之类的事情，这些都是你希望一个专注于终端用户体验的深思熟虑的框架所提供的。</p><p>&nbsp;</p><p></p><h3>混合的未来</h3><p></p><p>&nbsp;</p><p>不要与 Quic 协议相混淆。Qwik 这个框架是关于尽量减少不必要的 Javascript。虽然它的 API 看起来像 React，但它的方法与其他元框架不同，因为它专注于水化过程。</p><p>&nbsp;</p><p>就像你可以暂停一台虚拟机并将其移动到不同的物理机上。Qwik 把这个想法带到了服务器和浏览器之间发生的工作。它的“可恢复”水化的想法意味着你可以在服务器上启动一些东西，然后在客户端上恢复，而不需要任何重新工作。这与部分水化形成对比，后者在水化工作发生时进行移动，而 Qwik 则试图在一开始就避免这样做。</p><p>&nbsp;</p><p>这是一套有趣的想法，它利用了服务器和客户端紧密结合的力量，允许这种动态捆绑和服务。</p><p>&nbsp;</p><p>这些概念开始模糊了 MPA 和 SPA 之间的界限，一个应用程序可以从 MPA 开始，动态地过渡到 SPA。有时（用更流行的话来说）被称为 “过渡性应用程序”。</p><p>&nbsp;</p><p></p><h2>边缘的生活</h2><p></p><p>&nbsp;</p><p>同时，后端基础设施和托管也在不断改进。CDN 的边缘使我们的 SPA 的静态资产服务变得简单而快速。现在将运行时和数据转移到边缘也变得可行了。这是在浏览器之外创建一个新的运行时层，但仍然尽可能地接近用户。这使得将目前在浏览器中完成的许多事情移回服务器变得更加容易。同时在一定程度上减轻了这样做所带来的网络延迟的取舍。</p><p>&nbsp;</p><p>像 React 服务器组件这样的想法正在探索将服务器组件的输出从这一层流向浏览器的概念。像 Deno 和 Bun 这样的新的 Javascript 运行时正在出现，以简化和精简 Javascript 生态系统，并为这个边缘运行时的新世界而构建，为速度和快速启动时间而优化。</p><p>&nbsp;</p><p>这也导致了应用框架采用标准的网络 API 来在这一层运行。随着无服务器功能和流媒体架构被探索出来。</p><p>&nbsp;</p><p>流（Streaming）是这里的一个大主题。它允许提前刷新 HTML，因此浏览器可以在接收到它时逐步进行渲染。在后端同时获取任何数据时，开始处理任何阻碍渲染的资源，如 CSS 和 JS。这有助于并行化许多其他顺序往返行程。</p><p>&nbsp;</p><p></p><h2>概括</h2><p></p><p>&nbsp;</p><p>本文讲了那么多，但实际上只是触及皮毛而已。对于本文中提到的最佳框架、架构或模式，以及我们没有提到的无数其它框架、架构和模式，并没有一个通用的答案。它始终是对特定指标的权衡。而要知道如何权衡，取决于你正在构建的东西、你的用户是谁、他们的使用模式，以及围绕关键用户体验的任何其他要求（如性能预算）的设定。</p><p>&nbsp;</p><p>对于我们中的大多数人来说，真相在某个中间的地方。新一波框架和创新的伟大之处在于，它们提供了根据需要扩大和缩小规模的杠杆。对于那些进入这个行业的人和那些经验丰富的人来说，投资于基本面总是一个不错的选择。</p><p>&nbsp;</p><p>框架的演变慢慢地将原生 Web 推向了更远的地方，消除了以前对框架的需求，并减轻了之前的取舍，使我们能够越来越多地采用其原生特性。</p><p>&nbsp;</p><p>原文链接：</p><p>&nbsp;</p><p><a href=\"https://frontendmastery.com/posts/the-new-wave-of-javascript-web-frameworks/\">https://frontendmastery.com/posts/the-new-wave-of-javascript-web-frameworks/</a>\"</p>",
    "publish_time": "2022-10-11 16:31:27",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Go运行时：4年之后",
    "url": "https://www.infoq.cn/article/UcGg4BHuORGwQ1df5VGg",
    "summary": "<p>自2018年以来，<a href=\"https://www.infoq.cn/article/MwasczNiyzIY7VCNlwo1\">Go</a>\" GC，以及更广泛的Go运行时，一直在稳步改进。近日，<a href=\"https://www.infoq.cn/article/BrxvMywuC2YV79wvgWCN\">Go</a>\"社区总结了4年来Go运行时的一些重要变化。</p><p></p><p>这些重要变化主要是：</p><p>sync.Pool是一种GC感知的重用内存的工具，具有较低的延迟影响，并且能够比之前更有效地回收内存。（Go 1.13）Go运行时能够更主动地将不需要的内存返回给操作系统，减少了内存消耗和出现内存不足的可能性。这将减少最高20%的空闲内存消耗。（Go 1.13和1.14）在许多情况下，Go运行时能够更容易地抢占goroutine，最高可减少90%的stop-the-world延迟。（Go 1.14）Go运行时能够比以前更有效地管理计时器，特别是在拥有多核CPU的机器上。（Go 1.14）在大多数情况下，现在使用defer语句的函数调用的开销与常规函数调用一样少。点击这里观看Gophercon 2020的相关演讲。（Go 1.14）内存分配器的慢路径对CPU核心的伸缩性更好，将吞吐量提升了最多10%，并将尾部延迟降低了最多30%，特别是在高度并行的程序中。（Go 1.14和1.15）Go内存统计数据现在可以通过更细粒度、更灵活、更高效的API（runtime/metrics包）来访问。这将获取运行时统计信息的延迟减少了两个数量级（从毫秒到微秒）。（Go 1.16）Go调度器在寻找新任务时花费的CPU时间减少了30%。（Go 1.17）Go代码现在在amd64、arm64和ppc64上遵循基于寄存器的调用约定，将CPU效率提升了最多15%。（Go 1.17和1.18）Go GC的内部审计和调度已经进行了重新设计，解决了长期存在的各种与效率和健壮性相关的问题。对于goroutine占内存使用很大一部分的应用程序来说，这显著降低了应用程序的尾部延迟（最高达66%）。（Go 1.18）Go GC现在在应用程序空闲时会限制自己的CPU使用。这将空闲应用程序的GC周期的CPU使用降低了75%，从而减少可能导致作业调度器混淆的CPU峰值。（Go 1.19）</p><p></p><p>这些变化对用户来说大多是看不见的——他们只需要升级Go，就可以看到他们所熟悉和喜爱的Go代码运行得更好了。</p><p></p><p></p><h2>一个新的“旋钮”</h2><p></p><p></p><p>Go 1.19带来了一个期待已久的特性，使用这个特性需要做一些额外的工作，但它具备很大的潜力：Go运行时的软内存限制。</p><p></p><p>多年来，Go GC只有一个调优参数——GOGC。GOGC允许用户在CPU开销和内存开销之间做出权衡。多年来，这个“旋钮”为Go社区提供了很好的服务，被用在各种各样的场景中。</p><p></p><p>Go运行时团队一直不愿意在Go运行时中添加新的旋钮，他们的理由很充分——每个新的旋钮代表了配置空间中的一个新的维度，我们需要对其进行测试和维护，而且可能要永远持续下去。旋钮的激增也给Go开发人员增加了理解和使用它们的负担，随着旋钮的增多，情况会变得愈加困难。因此，Go运行时总是倾向于用最小配置实现合理的行为。</p><p></p><p>那么为什么要添加内存限制旋钮呢？</p><p></p><p>内存不像CPU时间那么具有可互换性。对于CPU时间，如果稍等片刻，将来总会得到更多的CPU时间。但对于内存，你所拥有的总是有限的。</p><p></p><p>内存限制解决了两个问题。</p><p></p><p>首先，当应用程序的内存使用峰值不可预测时，仅靠GOGC几乎无法防止内存被耗尽。如果只使用GOGC，Go运行时根本不知道它有多少可用的内存。通过设置内存限制，运行时能够意识到什么时候需要更努力地工作以减少内存开销，从而使运行时能够健壮地应对瞬时的、可恢复的负载峰值。</p><p></p><p>第二是为了避免不使用内存限制时出现的内存不足。我们必须根据内存峰值调优GOGC，而为了保持较低的内存开销会导致更高的GC CPU开销，即使应用程序没有处于内存使用峰值且有足够的可用内存。这在容器化的环境中尤其重要。在容器化的环境中，程序被部署在具有独立预留内存的容器中。设置内存限制可以为峰值负载提供保护，并可以针对CPU开销更主动地调优GOGC。</p><p></p><p>内存限制的设计旨在易用性和健壮性。例如，它是对应用程序中Go部分的整个内存占用的限制，而不仅仅是Go的堆，因此用户不需要额外计算Go运行时的开销。运行时还会根据内存限制调整其内存清除策略，以便在内存出现压力时更主动地将内存返回给操作系统。</p><p></p><p>虽然内存限制是一个强大的工具，但在使用时仍然要谨慎。其中一个需要注意的地方是，它会让你的程序陷入GC抖动状态——在这种状态下，程序运行GC的时间过多，导致没有足够的时间来处理其他任务。例如，如果内存限制设置得比程序实际需要的内存少，Go程序可能会崩溃。以前不太可能出现GC抖动，除非显式对GOGC进行了大量调优。我们选择让内存耗尽而不是陷入抖动状态，因此作为一种缓解措施，运行时将GC限制为总CPU时间的50%，即使这样会超过内存限制。</p><p></p><p>所有这些都需要慎重考虑，因此，作为这项工作的一部分，我们发布了一个新的GC指南，其中包含了交互式可视化的图表，以帮助你们理解GC成本以及如何操作它们。</p><p></p><p>更多可以查看GC指南：<a href=\"https://go.dev/doc/gc-guide?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjU0Nzc4NDEsImZpbGVHVUlEIjoiNVRnYk1qZFdIRjByYWx3USIsImlhdCI6MTY2NTQ3NzU0MSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.XJNqs-kezT_9bttILHS29vTPPwcOi4sf6kHvboBVETo\">https://go.dev/doc/gc-guide</a>\"</p><p></p><p>原文链接：<a href=\"https://go.dev/blog/go119runtime?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjU0Nzc4NDEsImZpbGVHVUlEIjoiNVRnYk1qZFdIRjByYWx3USIsImlhdCI6MTY2NTQ3NzU0MSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.XJNqs-kezT_9bttILHS29vTPPwcOi4sf6kHvboBVETo\">https://go.dev/blog/go119runtime</a>\"</p>",
    "publish_time": "2022-10-11 17:35:01",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "关于RabbitMQ，多么希望当初有人告诉我们这些",
    "url": "https://www.infoq.cn/article/XVbtYzyD7PWsV26S2luc",
    "summary": "<p>我的手表嗡嗡作响，在黎明前的昏沉中，我不知道这是闹钟响了还是来电话了。现在是凌晨4点45分。我回过神来，才意识到这是一个陌生号码来电——这可不是什么好兆头。我接通电话，是我的一个同事——他负责我们的支持团队，为我们的客户处理所有的生产问题。“Ryan，抱歉吵醒你，现在还很早。我们最大的客户报告说，他们发出的请求需要两个多小时才能返回结果。我们认为是我们的信息系统出问题了，但我们不确定接下来该怎么做。我们需要你的帮助。请加入我们的电话会议。”过了一会儿，我的手表又响了，这次是闹钟。今天早上的早起可不是为了锻炼。</p><p></p><p>我们已经在生产环境中运行<a href=\"https://www.infoq.cn/article/2010/09/RabbitMQ2.0-release\">RabbitMQ</a>\"将近三年了，99.5%的时间都没有问题。在此期间，我们扩展到了200多个运行在数十个虚拟机上的并发消费者客户端，并处理来自我们.NET应用程序的数亿条消息。我们的主要业务场景是通过HTTP调用Web服务，获取JSON数据或下载PDF文档。我会推荐使用RabbitMQ，因为我们就用了。在大多数情况下，它都很棒，在我们的系统中表现良好。但这里有一个很大的问题，我们在做架构决策时并不知道。</p><p></p><p>我们使用<a href=\"https://www.infoq.cn/article/W7ayyUv5Wx1K5csq36CX\">RabbitMQ</a>\"来轮询调度作业的执行结果。一般的操作顺序是这样的：用户通过Web应用程序提交请求，后端在处理请求时向RabbitMQ中添加消息，消费者客户端获取消息并通过HTTP调用另一个Web服务，将请求提交给实际处理业务逻辑的服务。然后，轮询逻辑开始接管，队列中的后续消息用于轮询处理结果。如果作业还没有执行结果，消费者将消息放回队列，等待下一次轮询尝试（等待时间可由客户配置）。等待的延迟逻辑使用了存活时间（Time-To-Live，TTL）和死信队列。</p><p></p><p>我们的非生产集群使用两个或三个节点，生产集群使用三个节点。每个集群都有一个负载均衡器，应用程序的流量严格流经负载均衡器。在运行时，发布者和消费者使用相同的负载均衡器。</p><p></p><p></p><h1>你应该知道的</h1><p></p><p></p><p>在使用RabbitMQ三年后，如果再要写与RabbitMQ交互相关的代码，我一定会这样告诉我自己。</p><p></p><p></p><h1>一开始就请专家帮忙</h1><p></p><p></p><p>你可以大概花2000到3000美元从RabbitMQ咨询公司找来专家，利用这个机会审查和验证你的假设和计划、提出问题、获取建议并进行尽职调查，这样就可以减少可能在未来出现的问题。从长远来看，现在做出正确的决策，最有可能在未来帮你节约成本。或者你也可以像我们一样，在遇到麻烦时找专家帮忙。</p><p></p><p></p><h1>我们使用了EasyNetQ或NServiceBus</h1><p></p><p></p><p>我们的应用程序使用了RabbitMQ.Client库，一些抽象库（如EasyNetQ和NServiceBus）也使用了它。这些抽象库比我更了解RabbitMQ的底层交互。RabbitMQ的驱动程序相对底层，所以你需要了解RabbitMQ的底层细节。如果这是你第一次使用RabbitMQ，我保证你不会对它有任何溢美之词。</p><p></p><p>如果你想知道“为什么不使用包装器库”，我可以告诉你，最初的开发人员在实现接近尾声时离开了公司，他已经使用了RabbitMQ.Client ，而这个项目最后落到了我的手上。我没有足够的时间重构（我也没想到要把它换成包装器库）。</p><p></p><p></p><h1>网络分区是个大问题</h1><p></p><p></p><p>RabbitMQ一般被部署成集群，集群由一个或多个节点组成，节点是运行RabbitMQ实例的服务器或容器。集群中所有的节点都必须运行完全相同版本的RabbitMQ。</p><p></p><p>RabbitMQ提供了一种叫作聚簇（Clustering）的机制，这样你就可以将多个RabbitMQ实例链接起来，成为一个逻辑Broker。你可以将请求发送给集群中的任意一个节点，节点会合作发布消息或将消息发送给消费者。</p><p></p><p>节点之间通过交换关于消息、队列等的信息不断相互通信。如果通信中断，即使只是几毫秒，RabbitMQ也会进入分区状态，然后它们会根据配置文件中配置的内容决定如何处理通信中断。默认的处理策略是ignore，也就是直接进入分区状态，并在这种“脑裂”模式下继续运行，从而使集群陷入完全的混乱。这对我们来说简直就是地狱（对我来说更是如此）。退出分区状态的唯一方法是重启分区一侧的节点，然后重新连接另一侧，并丢弃从集群发生分区时积累的数据。</p><p></p><p>我经历过两种方式的网络分区：通过Windows更新和防火墙规则同时更新集群中所有的节点。</p><p></p><p>对于这个话题，我可以无休止地咆哮，所以我不得不让自己消停一下。正确的配置应该是将partition_handling策略设置为pause_minority。当集群发生分区时，分区的一侧应该将自己关闭，避免发生脑裂。被关闭的一方继续监控集群，等待恢复通信，并在恢复时重新加入。现在你所要做的就是确保你的代码能够正确地处理断开的连接，这样你就有了一个相当健壮的队列解决方案。</p><p></p><p>根据CAP定理，ignore策略意味着牺牲一致性换取可用性，而pause_minority意味着牺牲可用性换取一致性。如果你问我的话，我认为后者是值得的。</p><p></p><p></p><h1>你打算如何升级RabbitMQ</h1><p></p><p></p><p>你的RabbitMQ版本总归会有过时的那一天。到时候你会怎么做？继续使用不受支持的版本？创建一个新的集群？你计划怎样将流量从遗留集群迁移到新集群？之前已经提到，集群中的所有节点都应该是相同的版本。如果你的计划是进行就地升级，你就会知道这将是多么棘手。</p><p></p><p>我留给你的只有问题，没有答案。因为每一个决策都高度依赖具体的组织和运营策略。换句话说，每个人可能都有不同的方法来解决这些问题。</p><p></p><p></p><h1>如果RabbitMQ的消息全部丢失，你该怎么办</h1><p></p><p></p><p>如果RabbitMQ中所有（或者三分之一）的消息丢失了，你会有多惨？RabbitMQ是你用来保存记录的系统吗？你有让应用程序回到正常状态的恢复策略吗？如果你把本地服务器迁移到云端，如何让你的RabbitMQ消息再次流动起来？</p><p></p><p></p><h1>让发布者和消费者使用不同的连接地址</h1><p></p><p></p><p>在未来的某个时刻（可能是在升级期间），你希望能够灵活地向不同的集群或负载均衡器发布消息或读取消息。这是一种零风险高回报的模式，你可以尽早在应用程序中使用这种模式，未来的你会因此感谢现在的你。</p><p></p><p></p><h1>不断增长的日志文件将占用几十GB的磁盘空间</h1><p></p><p></p><p>随着时间的推移，RabbitMQ的日志文件会增长到占用几十GB的磁盘空间。我们可以使用rabbitmqctl rotate_logs来滚动这些文件，不过也要努力使这个过程自动化，避免因“磁盘空间不足”导致停机。</p><p></p><p></p><h1>结论</h1><p></p><p></p><p>RabbitMQ是我们基础设施的一个稳固的组件，选择它可能是一个正确的决定。但你也应该认真对待我在本文中提出的那些问题，至少应该与你的同事和利益相关者沟通，看看应该试着解决哪些痛点。</p><p></p><p>原文链接：<a href=\"https://ryanrodemoyer.github.io/what-i-wish-someone-would-have-told-me-about-using-rabbitmq-before-it-was-too-late/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjU0ODE4NzMsImZpbGVHVUlEIjoiSnU4QXdaRW5VNjg2MFBJNCIsImlhdCI6MTY2NTQ4MTU3MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.MNhDc4atbhxT1QWSApgk1qeGF2Zwpb6-E1ZKDZpp5jU\">https://ryanrodemoyer.github.io/what-i-wish-someone-would-have-told-me-about-using-rabbitmq-before-it-was-too-late/</a>\"</p><p></p>",
    "publish_time": "2022-10-11 17:55:24",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "JuiceFS 在 Elasticsearch/ClickHouse 温冷数据存储中的实践",
    "url": "https://www.infoq.cn/article/IcYKHdkPgKmBe7MBdKlJ",
    "summary": "<p>企业数据越存越多，存储容量与查询性能、以及存储成本之间的矛盾对于技术团队来说是个普遍难题。这个难题在 Elasticsearch 与 ClickHouse 这两个场景中尤为突出，为了应对不同热度数据对查询性能的要求，这两个组件在架构设计上就有一些将数据进行分层的策略。</p><p></p><p>同时，在存储介质方面，随着云计算的发展，对象存储以低廉的价格和弹性伸缩的空间获得了企业的青睐。越来越多的企业将温、冷数据迁移至对象存储。但如果将索引、分析组件直接对接至对象存储时会发生查询性能、兼容性等问题。</p><p></p><p>这篇文章将为大家介绍这两个场景中冷热数据分层的基本原理，以及如何通过使用 JuiceFS 来应对在对象存储上存在的问题。</p><p></p><h2>Elasticsearch 数据分层结构详解</h2><p></p><p></p><p>在介绍 ES 如何实现冷热数据分层策略之前先来了解三个相关的概念：Data Stream，Index Lifecycle Management 和 Node Role。</p><p></p><h3>Data Stream</h3><p></p><p>Data Stream（数据流）是 ES 中一个重要概念，它有如下特征：</p><p>流式写入：它是一个流式写入的数据集，而不是一个固定大小的集合；仅追加写：它是用追加写的方式将数据更新进去，且不需要修改历史数据；时间戳：每一条新增的数据都会有一个时间戳记录是什么时候产生的；多个索引：在 ES 里有一个索引的概念，每一条数据最终会落到它对应的一个索引中，但是数据流是一个更上层、更大的概念，一个数据流背后可能会有很多索引，这些索引是根据不同的规则来生成的。一个数据流虽然由很多的索引来构成，但是只有最新的索引才是可写的，历史索引是只读的，一旦固化好之后就不能再修改。</p><p></p><p>日志数据就是符合数据流特征的一类数据，它是只追加写，同时也得有时间戳，用户会根据不同的维度，比如按天或者按其他的维度来生成新的索引。</p><p></p><p>下图是一个数据流建立索引的简单示例，在用数据流的过程中，ES 会直接写到最新的索引，而不是历史索引，历史索引不会被修改。随着后续更多新的数据生成，这个索引也会沉淀成为一个老的索引。</p><p><img src=\"https://static001.geekbang.org/infoq/2d/2d5a0e9d4d0673ec19ef815c933eb01a.png\" /></p><p>下图，当用户往 ES 里面去写数据时，大致分为两个阶段：</p><p>阶段 1：数据会先写到内存的 In-memory buffer 缓冲区；阶段 2：缓冲区根据一定的规则和时间，再落到本地磁盘上，就是下图绿色的持久化的数据，在 ES 中叫做 Segment。</p><p></p><p>这个过程中可能会有一些时间差，在持久化的过程中，如果去触发查询， 新创建的Segment 不能被搜索到。一旦这个 Segment 持久化完成之后，就可以立即被上层的查询引擎搜索。</p><p><img src=\"https://static001.geekbang.org/infoq/e6/e61f03c8326e0a701043fa80d8dc8b83.png\" /></p><p></p><h3>Index Lifecycle Management</h3><p></p><p>Index Lifecycle Management，简称 ILM，就是索引的生命周期管理。ILM 将索引的生命周期定义为 5 个阶段：</p><p>热数据（Hot）：需要频繁更新或者查询的数据；温数据（Warm）：不再更新，但仍会被频繁查询的数据；冷数据（Cold）：不再更新，且查询频率较低的数据；极冷数据（Frozen）：不再更新，且几乎不会被查询的数据。可以比较放心地把这类数据放在一个相对最低速最便宜的存储介质中；删除数据（Delete) : 不再需要用到，可以放心删除的数据。</p><p></p><p>一个索引里的数据，不管是 index 还是 segment，都会经历这些阶段，这个分类的规则很好地帮助用户去管理 ES 里的数据，用户可以自己定义不同阶段的规则。</p><p></p><h3>Node Role</h3><p></p><p>在 ES 中，每一个部署节点都会有一个 Node Role，也就是节点角色。每一个 ES 节点会分配不同的角色，比如 master、data、ingest 等。用户可以结合节点角色，以及上文提到的不同生命周期的阶段来组合进行数据管理。</p><p></p><p>数据节点会有不同的阶段，可能是一个存储热数据的节点，也可能是一个存储温数据、冷数据，甚至极冷数据的节点。需要根据节点的功能去给他分配不同的角色，同时会给不同的角色的节点配置不同的硬件。</p><p>比如，对于热数据节点需要配置高性能的 CPU 或者磁盘，对于温冷数据的节点，基本上认为这些数据被查询的频率较低，这个时候其实对于某些计算资源的硬件要求就没有那么高了。</p><p></p><p>节点角色是根据生命周期的不同阶段来定义的，需要注意的一点是，每一个 ES 节点，可以有多种角色，这些角色并不是一一对应的关系。下面有个示例，在 ES 的 YAML 文件里面配置的时候，node.roles 就是节点角色的配置，可以针对这个节点应该有的角色给它配置多种角色。</p><p><code lang=\"null\">node.roles:&nbsp;[\"data_hot\",&nbsp;\"data_content\"]</code></p><p></p><h3>生命周期策略</h3><p></p><p>在了解完 Data Stream 、Index Lifecycle Management、Node Role 这些概念以后，就可以为数据创建一些不同的生命周期策略（Lifecycle Policy）。</p><p></p><p>根据生命周期策略中定义的不同维度的索引特征，如索引的大小、索引里的文档的数量、索引创建的时间，ES 可以自动地帮用户把某个生命周期阶段的数据滚动到另一个阶段，在 ES 中的术语是 rollover。</p><p>比如，用户可以制定基于索引大小维度的特征，把热数据滚动到温数据，或者根据一些其它规则，再把温数据滚动到冷数据。这样，索引在不同生命周期的阶段之间去滚动的时候，相应的它索引的数据也会去做迁移和滚动。ES 可以自动完成这些工作，但是生命周期策略则需要用户自己来定义。</p><p></p><p>下面的截图，是 Kibana 的管理界面，用户可以通过图形化的方式去配置生命周期策略。可以看到有三个阶段，从上到下分别是热数据、温数据以及冷数据。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a0/a04860d29a4b9f508caa0cf549d20dbe.png\" /></p><p></p><p>展开其中热数据阶段的高级设置，可以看到更详细，上文提到的基于不同维度特征的策略配置，如在下图右边看到的这三个选项。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8b/8b662c7dc6ef8ecbe826fe05352ea4df.png\" /></p><p></p><p>索引的大小，示意图上的例子是 50GB，当索引的大小超过 50GB 的时候，就会把它从热数据阶段滚动到温数据阶段。最大的文档数，ES 里索引的单元是文档，用户数据是以文档的形式写入 ES 中的，所以文档数也是一个可以衡量的指标。最大索引创建时间，这里的示例是 30 天，假设某个索引已经创建了 30 天了，这个时候就会触发刚刚提到的从热数据阶段到温数据的滚动。</p><p></p><h2>ClickHouse 数据分层架构详解</h2><p></p><p>下图是一组从大到小的俄罗斯套娃，它非常形象地展现了 ClickHouse 的数据管理模式， MergeTree 引擎。</p><p>Table: 在图片的最右边是一个最大的概念，用户最开始要创建或者能够直接接触到的就是 Table；Partition：是一个更小的维度或者更小的粒度。在 ClickHouse 里，数据分成 Partition 来存储，每个 Partition 会有一个标识；Part：在每个 Partition 中，又会再进一步地细分为多个 Part。如果查看 ClickHouse 磁盘上存储的数据格式，可以认为每一个子目录就是一个 Part；Column：在 Part 里会看到一些更小粒度的数据，即 Column。ClickHouse 的引擎使用的是列式存储，所有的数据都是按照列存的方式来组织。在 Part 目录里会看到很多列，比如 Table 可能有100 列，就会有 100 个 Column 文件；Block：每个 Column 文件里是按照 Block 的粒度来组织。</p><p><img src=\"https://static001.geekbang.org/infoq/d1/d13bda05d8525ee573c0fb234b737057.png\" /></p><p>下面这个示例中，在 table 目录下可以看到有 4 个子目录，每个子目录就是上文提到的 Part。</p><p><code lang=\"null\">$&nbsp;ls&nbsp;-l&nbsp;/var/lib/clickhouse/data//\ndrwxr-xr-x&nbsp;&nbsp;2&nbsp;test&nbsp;&nbsp;test&nbsp;64B&nbsp;Aug&nbsp;&nbsp;8&nbsp;13:46&nbsp;202208_1_3_0\ndrwxr-xr-x&nbsp;&nbsp;2&nbsp;test&nbsp;&nbsp;test&nbsp;64B&nbsp;Aug&nbsp;&nbsp;8&nbsp;13:46&nbsp;202208_4_6_1\ndrwxr-xr-x&nbsp;&nbsp;2&nbsp;test&nbsp;&nbsp;test&nbsp;64B&nbsp;Sep&nbsp;&nbsp;8&nbsp;13:46&nbsp;202209_1_1_0\ndrwxr-xr-x&nbsp;&nbsp;2&nbsp;test&nbsp;&nbsp;test&nbsp;64B&nbsp;Sep&nbsp;&nbsp;8&nbsp;13:46&nbsp;202209_4_4_<p></p><p>图示的最右边这一列，每个子目录的名字前面可能是一个时间，比如 202208 类似这样的前缀，202208 其实就是 Partition 名。Partition 名字是用户自己来定义的，但是按照约定俗成或者一些实践习惯，通常会使用时间来命名。</p><p></p><p>比如， 202208 这个 Partition，它会有两个子目录，子目录就是 Part，一个 Partition 通常会由多个 Part 来构成。用户在往 ClickHoue 写入数据时，会先写到内存里，再根据内存里的数据结构，持久化到磁盘上。同一个Partition 里面的数据如果比较大的话，在磁盘上就会变成很多 part。ClickHouse 官方建议不要在一个 Table 下创建太多 Part，它会定期或者不定期地对 Part 进行合并，减少总的 Part 数量。Merge 的概念就是合并 Part，这也是 MergeTree 这个引擎的名字来源之一。</p><p></p><p>再通过一个例子来了解 Part。Part 里会有很多小文件，有一些是元信息，比如索引信息，帮助用户快速查找数据。</p><p><code lang=\"null\">$&nbsp;ls&nbsp;-l&nbsp;/var/lib/clickhouse/data//</code></p><table></table><code lang=\"null\">/202208_1_3_0\n-rw-r--r--&nbsp;&nbsp;1&nbsp;test&nbsp;&nbsp;test&nbsp;&nbsp;??&nbsp;Aug&nbsp;&nbsp;8&nbsp;14:06&nbsp;ColumnA.bin\n-rw-r--r--&nbsp;&nbsp;1&nbsp;test&nbsp;&nbsp;test&nbsp;&nbsp;??&nbsp;Aug&nbsp;&nbsp;8&nbsp;14:06&nbsp;ColumnA.mrk\n-rw-r--r--&nbsp;&nbsp;1&nbsp;test&nbsp;&nbsp;test&nbsp;&nbsp;??&nbsp;Aug&nbsp;&nbsp;8&nbsp;14:06&nbsp;ColumnB.bin\n-rw-r--r--&nbsp;&nbsp;1&nbsp;test&nbsp;&nbsp;test&nbsp;&nbsp;??&nbsp;Aug&nbsp;&nbsp;8&nbsp;14:06&nbsp;ColumnB.mrk\n-rw-r--r--&nbsp;&nbsp;1&nbsp;test&nbsp;&nbsp;test&nbsp;&nbsp;??&nbsp;Aug&nbsp;&nbsp;8&nbsp;14:06&nbsp;checksums.txt\n-rw-r--r--&nbsp;&nbsp;1&nbsp;test&nbsp;&nbsp;test&nbsp;&nbsp;??&nbsp;Aug&nbsp;&nbsp;8&nbsp;14:06&nbsp;columns.txt\n-rw-r--r--&nbsp;&nbsp;1&nbsp;test&nbsp;&nbsp;test&nbsp;&nbsp;??&nbsp;Aug&nbsp;&nbsp;8&nbsp;14:06&nbsp;count.txt\n-rw-r--r--&nbsp;&nbsp;1&nbsp;test&nbsp;&nbsp;test&nbsp;&nbsp;??&nbsp;Aug&nbsp;&nbsp;8&nbsp;14:06&nbsp;minmax_ColumnC.idx\n-rw-r--r--&nbsp;&nbsp;1&nbsp;test&nbsp;&nbsp;test&nbsp;&nbsp;??&nbsp;Aug&nbsp;&nbsp;8&nbsp;14:06&nbsp;partition.dat\n-rw-r--r--&nbsp;&nbsp;1&nbsp;test&nbsp;&nbsp;test&nbsp;&nbsp;??&nbsp;Aug&nbsp;&nbsp;8&nbsp;14:06&nbsp;primary.id\n</code><p></p><p>在示例的右侧，以 Column 作为前缀的这些文件是实际的数据文件，相比元信息通常会比较大。这个示例中只有 A、B 两列，实际的表里可能有很多列。所有这些文件，包括元信息、索引信息，都会共同帮助用户快速地在不同文件之间去做跳转或者查找。</p><p></p><h3>ClickHouse 存储策略</h3><p></p><p></p><p>如果要在 ClickHouse 里做冷热数据分层，会用到类似于 ES 中提到的生命周期策略，在 ClickHouse 里称为存储策略（Storage Policy）。</p><p></p><p>与 ES 稍有不同，ClickHouse 官方并没有将数据划分不同的阶段，比如热数据、温数据、冷数据这些不同的阶段，ClickHouse 提供了一些规则和配置方法，需要用户自己来制定分层策略。</p><p></p><p>每个 ClickHouse 节点支持同时配置多块磁盘，存储介质可以是多种多样的。比如，一般用户为了性能会给 ClickHouse 节点配置 SSD 盘；对于一些温冷数据，用户可以把数据存储在成本更低的介质，如机械盘。ClickHouse 的用户对底层存储介质是无感知的。</p><p></p><p>与 ES 相似，ClickHouse 用户需要根据数据不同的维度特征去制定存储策略，比如每个 part 子目录的大小、整个磁盘的剩余空间比例等，当满足某个维度特征设定的条件时就会触发存储策略的执行。这个策略会将某一个 part 从一块盘迁移到另外一块盘。在 ClickHouse 中，一个节点配置的多块盘是有优先级的，默认情况下数据会优先落在最高优先级的盘上。这样实现了 Part 从一个存储介质转移到另外一个存储介质上。</p><p></p><p>通过 ClickHouse 的一些 SQL 命令，如 MOVE PARTITION/PART 命令可以手动触发数据迁移，用户也可以通过这些命令做一些功能性的验证。其次有某些情况下，可能也希望能够通过手动的方式，而不是自动转移的方式来显式把 part 从当前的存储介质上转移到另外一个存储介质上。</p><p></p><p>ClickHouse 还支持基于时间的迁移策略，这是一个独立于存储策略的概念。数据写入后，ClickHouse 会按照每个表的 TTL 属性设置的时间来触发磁盘上数据的迁移。比如设置 TTL 为 7 天，ClickHouse 就会把表中超过 7 天的数据从当前的磁盘（如默认的 SSD）再写到另外一个更低优先级的磁盘上（如 JuiceFS）。</p><p></p><h2>温冷数据存储：为什么使用对象存储+ JuiceFS ？</h2><p></p><p></p><p>企业把温、冷数据存放到云上后，存储成本相较于传统的 SSD 架构大为下降。企业还享受到了云上的弹性伸缩空间；不用为数据存储去做任何运维操作，比如扩缩容，或者一些数据清理类的工作。温冷数据所需的存储容量比热数据大很多，尤其是随着时间推移，会产生大量需要长期保存的数据，如果这些数据都存储在本地，相应的运维工作将不堪重负。</p><p></p><p>但如果在对象存储上使用 Elasticsearch、ClickHouse 这类数据应用组件，会存在写入性能差、兼容性等问题。希望兼顾查询性能的企业，开始在云上寻找解决方案。在这样的背景之下，JuiceFS 被越来越多地应用于数据分层的架构之中。</p><p></p><p>通过下面 ClickHouse 写入性能测试可以直观了解到写入SSD、JuiceFS 以及对象存储的性能差异。</p><p><img src=\"https://static001.geekbang.org/infoq/9a/9a3c2ddd72ce698a4edfc8516753b29c.png\" /></p><p></p><p>JuiceFS 的写入吞吐量远大于直接对接对象存储，接近 SSD。当用户把热数据转移到温暖数据这一层时，对于写入性能也有一定要求。在迁移的过程中，如果底层存储介质的写入性能差，整个迁移的流程也会拖得很长，对于整个 pipeline 或数据管理也会带来一些挑战。</p><p></p><p>下图的 ClickHouse 查询性能测试使用真实业务中的数据，并选取几个典型的查询场景进行测试。其中 q1-q4 是扫描全表的查询，q5-q7 是命中主键索引的查询。测试结果如下图：</p><p><img src=\"https://static001.geekbang.org/infoq/d5/d50a135cac468d1bc3482cd722a6fcd9.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1b/1b1de69a900b1d21fa26f0a887aad3d6.png\" /></p><p></p><p>JuiceFS 与 SSD 盘的查询性能基本相当，平均差异在 6% 左右，但是对象存储相比 SSD 盘有 1.4 至 30 倍的性能下降。得益于 JuiceFS 高性能的元数据操作以及本地缓存特性，可以自动将查询请求需要的热数据缓存在 ClickHouse 节点本地，大幅提升了 ClickHouse 的查询性能。需要注意的是以上测试中对象存储是通过 ClickHouse 的 S3 磁盘类型进行访问，这种方式只有数据是存储在对象存储上，元数据还是在本地磁盘。如果通过类似 S3FS 的方式把对象存储挂载到本地，性能会有进一步的下降。</p><p></p><p>另外值得一提的是 JuiceFS 是一个完全兼容 POSIX 的文件系统，它能够与上层应用（如 Elasticsearch、ClickHouse）有很好的兼容。用户对底层存储是分布式文件系统或者是本地磁盘是没有感知的。如果直接使用对象存储，不能很好地实现与上层应用的兼容。</p><p></p><h2>实操：ES + JuiceFS</h2><p></p><p></p><p>Step 1：准备多种类型节点，分配不同角色。每一个 ES 节点可以分配不同的角色，比如存热数据、温数据、冷数据等，用户需要准备不同机型的节点来匹配不同角色的需求。</p><p>Step 2：挂载 JuiceFS 文件系统。一般用户将 JuiceFS 用于温、冷数据的存储，用户需要在 ES 温数据节点或冷数据的节点上把 JuiceFS 文件系统挂载到本地。用户可以通过符号链接或其它方式把挂载点配置到 ES 中去，让 ES 认为它的数据存储在本地目录里，但这个目录背后其实是一个 JuiceFS 文件系统。</p><p>Step 3：创建生命周期策略。这个需要每个用户自己去定制，用户既可以通过 ES API 去创建，也可以通过 Kibana 去创建，Kibana 提供了一些相对便捷的方式去创建和管理生命周期策略。</p><p>Step 4：为索引设置生命周期策略。创建完生命周期策略之后，用户需要把这个策略应用到索引上，也就是要为索引去设置刚刚创建好的策略。用户可以通过索引模板的方式，可以在 Kibana 里创建索引模板，也可以通过 index.lifycycle.name，显式通过 API 配置。</p><p></p><p>这里有几个小提示：</p><p>Tip 1：Warm 或 Cold 节点的副本数（replica）可以设置为 1。所有数据本质上都是放在 JuiceFS 上，它的底层是对象存储，因而数据的可靠性已经足够高了，所以在 ES 这边可以适当降低副本数，节省存储空间。</p><p><img src=\"https://static001.geekbang.org/infoq/0e/0ec94c63e23c25fc58476a49ad208cfe.png\" /></p><p>Tip 2：开启 Force merge 可能会导致节点 CPU 持续占用，酌情关闭。从热数据转移到温数据这个阶段时，ES 会将所有热数据索引对应的底层 segment 做合并。如果开启 Force merge 这个功能，ES 会先合并完这些 segment 以后，再把它存储到温数据的底层系统。然而合并 segment 是一个非常消耗 CPU 的过程，如果温数据的数据节点同时也需要承载一些查询请求，可以酌情关闭这个功能能，也就是原封不动地把数据保留下来，直接写到底层存储中。</p><p></p><p>Tip 3：Warm 或 Cold 阶段的索引可以设置为只读。在给温数据和冷数据阶段建立索引时，我们基本上可以认为这些数据是只读的，这些阶段的索引不会被修改。设置为只读可以适当降低温冷数据节点上的资源，比如内存可以释放一些，从而节省一些在温节点或者冷节点上的硬件资源。</p><p></p><h2>实操：ClickHouse + JuiceFS</h2><p></p><p>Step 1：在所有 ClickHouse 节点上挂载 JuiceFS 文件系统。这个路径可以是任意路径，因为 ClickHouse 会有一个配置文件去指向挂载点。</p><p>Step 2：修改 ClickHouse 配置，新增 JuiceFS 盘。在 ClickHouse 中把刚刚挂载好的 JuiceFS 文件系统挂载点添加进来，让 ClickHouse 可以识别这个新磁盘。</p><p>Step 3：新增存储策略，设定下沉数据规则。这个存储策略会根据用户的规则去不定期的、自动地将数据从默认磁盘上下沉到指定的，比如 JuiceFS 中。</p><p>Step 4：为特定表设置存储策略及 TTL。存储策略制定好之后，需要把这个策略应用到某一个表上。前期测试阶段和验证阶段，可以把用相对大一点的表去做测试和验证，如果用户希望基于时间维度来实现数据下沉，就同时也需要在表上设置 TTL。整个下沉过程是一个自动的机制，可以通过 ClickHouse 的 system 表查看当前正在进行数据迁移的 part 以及迁移进度。</p><p>Step 5：手动移动 part 进行验证。可以通过手动执行&nbsp;MOVE PARTITION&nbsp;命令的方式去验证当前的配置或存储策略是否生效。</p><p></p><p>下图是一个具体示例，在 ClickHouse 中有一个叫做&nbsp;storage_configuration&nbsp;的配置项，其中包含 disks 配置，这里会把 JuiceFS 作为一个盘加进来，我们将它命名为“jfs”，但其实可以用任意名字，挂载点是&nbsp;/jfs目录。</p><p><code lang=\"null\">\n&nbsp;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/jfs\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n&nbsp;\n&nbsp;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;default\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1073741824\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;jfs\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.1\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n&nbsp;\n\n</code></p><p>再往下是 policies 配置项，这里定义了一个叫做&nbsp;hot_and_cold&nbsp;的存储策略，用户需要定义一些具体的规则，如 volumes 中按照先热后冷的优先级排列，数据首先会落到 volumes 里的第一个 hot 盘上，及默认的 ClickHouse 磁盘，一般是本地的 SSD。</p><p></p><p>volumes 中的&nbsp;max_data_part_size_bytes&nbsp;配置表示当某一个 part 的大小超过设定的大小之后，就会触发存储策略的执行，对应的 part 会下沉到下一个 volume，也就是 cold volume。在上面的示例中，cold volume 就是 JuiceFS。</p><p></p><p>最下面的&nbsp;move_factor&nbsp;&nbsp;配置代表 ClickHouse 会根据当前磁盘的剩余空间比例来触发存储策略的执行。</p><p><code lang=\"null\">CREATE&nbsp;TABLE&nbsp;test&nbsp;(\n&nbsp;&nbsp;d&nbsp;DateTime,\n&nbsp;&nbsp;...\n)&nbsp;ENGINE&nbsp;=&nbsp;MergeTree\n...\nTTL&nbsp;d&nbsp;+&nbsp;INTERVAL&nbsp;1&nbsp;DAY&nbsp;TO&nbsp;DISK&nbsp;'jfs'\nSETTINGS&nbsp;storage_policy&nbsp;=&nbsp;'hot_and_cold'；\n</code></p><p>如上面的代码所示，有了存储策略之后，在创建表或者修改这个表的 schema 时，可以在 SETTINGS 中设置&nbsp;storage_policy&nbsp;&nbsp;为前面定义的&nbsp;hot_and_cold&nbsp;存储策略。上述代码中倒数第二行的 TTL 即为上文提过的基于时间的分层规则。在这个示例中，我们指定的表中某一个叫做 d 的列，它的类型是&nbsp;DateTime，结合&nbsp;INTERVAL 1 DAY&nbsp;就表示当新的数据写进来超过一天之后，这些数据就会转移到 JuiceFS 上。</p><p></p><h2>展望</h2><p></p><p>第一，副本共享。无论是 ES 还是 ClickHouse，他们都是由多副本来保证数据的可用性和可靠性。JuiceFS 本质上是一个共享文件系统，任何一份数据写入到 JuiceFS 之后，不再需要维护多个副本。比如，用户有两个 ClickHouse 节点，都有某一个表的或者某一个 part 的副本，这两个节点都下沉到了 JuiceFS，它可能会写两次一样的数据。未来，我们是否可以做到让上层引擎能够感知到下层使用的是一个共享存储，当数据下沉的时候去降低副本数，这样在不同节点之间是可以做副本共享的。从应用层来说，用户查看这个表， part 数还是多副本，但实际在底层的存储上只保了一个副本，因为本质上数据是可以共享的。</p><p></p><p>第二点，故障恢复。当数据已经下沉到一个远端的共享存储之后，如果 ES 或 ClickHousle 节点宕机故障之后，怎么快速地做故障恢复？除了热数据以外的大部分数据其实都已经转移到了一个远端的共享存储上，这个时候如果要去恢复或创建一个新的节点时，成本会比传统的基于本地盘的故障恢复方式轻量很多，这在 ES 或者 ClickHouse 场景上是值得探索的。</p><p></p><p>第三点，存算分离。不管 ES 也好，还是 ClickHouse，整个社区也都在尝试或者探索在云原生的大环境下，怎么去让传统的这些基于本地盘的存储系统变成一个真正的存算分离系统。但存算分离不是仅仅简单地把数据和计算分离就好了，同时要满足上层各种复杂的需求，比如对于查询性能的需求、对于写入性能的需求、对各种维度调优的需求，在存量分离整个大的方向上还是有许多值得探索的技术难点。</p><p></p><p>第四点，其他上层应用组件数据分层探索。除了ES 和 ClickHouse 这两个场景，我们最近也有在做一些尝试，把 Apache Pulsar 中的温冷数据下沉到 JuiceFS 中，用到的一些策略和方案与本文中提到的是类似的，只不过在 Apache Pulsar 中，它需要下沉的数据类型或者数据格式不太一样。有了进一步成功实践后，会分享出来。</p><p></p><p>作者简介：</p><p>高昌健，Juicedata 技术专家，参与建设 JuiceFS 开源社区的主力队员。十年互联网行业从业经历，曾在知乎、即刻、小红书多个团队担任架构师职位，专注于分布式系统、大数据、AI 领域的技术研究。</p><table></table></code></p>",
    "publish_time": "2022-10-11 18:16:34",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "字节跳动基础架构团队参会报告：一文看懂VLDB 22技术趋势及精选论文",
    "url": "https://www.infoq.cn/article/cBGu3PG7figVhcLZQOev",
    "summary": "<p>作者 ｜ 字节跳动基础架构团队</p><p></p><h2>前言</h2><p></p><p></p><p>VLDB 会议，全称 International Conference on Very Large Data Bases，是全球数据库系统领域最负盛名的三大顶会之一。从 1975 年开始举办，每年一次，全球各地顶尖高校的大量研究者、各大高科技公司都会将自己的学术研究进展或工业界成果以论文形式投递到 VLDB 组委会，而组委会会审阅并接收其中最前沿、最具影响力的一批，并召开线下会议，供论文作者们分享、交流。</p><p></p><p>今年的 VLDB 在 9 月 5 号到 9 号，在澳大利亚悉尼举办。字节跳动有三篇论文被 VLDB 接收：其中两篇来自 Graph 团队 ，一篇 ByteHTAP 系统。应 VLDB 组委会邀请，字节相关团队来到悉尼，与世界各地的数据领域专家学者分享交流。</p><p></p><p>为了让大家能对 VLDB 2022 有个快速的了解，我们总结了 VLDB 的论文分类、研究趋势以及工业界重点论文的摘要，当然啦，也包括字节跳动三篇论文简介。本文抛砖引玉，如果想深入了解学习，还是非常建议找到论文原文仔细研究。</p><p></p><p></p><h2>论文分类概览</h2><p></p><p></p><p>今年的 VLDB 会议日程中，将所有参会讨论的论文共划分成了以下几类：</p><p></p><p>Database Engines(45 篇)Database Performance(10 篇)Distributed Database Systems(11 篇)Novel DB Architectures(10 篇)Specialized and Domain-Specific Data Management(20 篇)Machine Learning, AI and Databases(50 篇)Data Mining and Analytics(35 篇)Information Integration and Data Quality(20 篇)Data Privacy and Security(15 篇)Graphs(45 篇)</p><p></p><p>作为老牌系统会议，VLDB 既有传统的数据库管理系统的最新进展 80 篇左右，也有一些这些年来前沿的机器学习和系统结合领域的最新内容。此外，Graph 领域的论文依然收录了 45 篇之多，VLDB 延续这几年对 Graph 的重点关注。可以看出，VLDB 所收录的论文内容，从传统的数据库底层技术、性能分析，到机器学习、图、区块链这些新兴的数据库使用场景，再到最上层的数据隐私安全、数据分析，基本覆盖了数据的完整处理链路。</p><p></p><p>我们将不同领域的论文数量绘制成了饼状图，方便读者对不同领域的热度有大致了解：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/96/966a3fac8fbfd3b12bf74b4cc245c11d.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/1f/1fd7b0a11598aa09373d3ad478e75253.jpeg\" /></p><p></p><p>VLDB 历来重视学术界与工业界的融合和交流。因此，VLDB 专门将工业界论文和学术界论文进行了分类，分别是 research track paper 和 industrial track paper。工业界论文 industrial track 共有 22 篇，其中校企合作的论文 12 篇，企业独立发表的论文有 10 篇；这些论文中，包含了 Google、Meta、微软、字节跳动、阿里、腾讯等多家国内外知名互联网企业的成果。相比于 research track，industrial track 更偏向于已经落地实用的技术或者系统，这些成果中有相当一部分与大家在日常生活中所用到的应用息息相关，也是各大技术公司相关领域人员关注的重点。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/1b/1b000adc9fb7dd2e00215ff790dcb39e.jpeg\" /></p><p></p><p></p><h2>2022 的趋势和启迪</h2><p></p><p></p><p>从论文的分布领域，以及工业界论文的重点，我们能够分析和洞察出数据库业界的一些趋势，一家之言，欢迎大家交流讨论。</p><p></p><p></p><h3>机器学习与数据库的结合在不断加深</h3><p></p><p></p><p>机器学习是目前计算机学界最为热门的话题，这种热度自然也传导到了数据库领域。今年 VLDB 最为火爆的话题就是 Machine Learning, AI and Databases，收录了足足 50 篇论文，且 Best Regular Research Paper、Best Scalable Data Science Paper 均花落这个领域，在悉尼的现场中，听众人数最多的也是这个方向，挤满了整个屋子。</p><p></p><p>具体来说，机器学习与数据库的结合点又主要包含三个部分：机器学习框架和平台与数据库的深度融合、使用机器学习技术优化数据库性能以及自动化运维。其中，使用机器学习来优化数据库系统进而整个 infrastructure 系统是一个在工业界已经徐徐展开的方向，有显著的线上需求和收益，字节在这一方面也有团队在持续研究探索。</p><p></p><p></p><h3>新硬件，软硬一体</h3><p></p><p></p><p>在传统的 CPU、内存硬件的处理性能无法保持高速提升的大背景下，各大公司和学术界不约而同地将目光投向新硬件领域，包括 FPGA、GPU、PMem 等。如果充分利用 FPGA、GPU 进行计算加速，以及如何充分发挥 PMem 相比于内存的优势，是未知领域探索的低垂果实，自然成了近年研究的热点。本届 VLDB，有多篇工业界论文专题研究 FPGA 和 PMem，并且 SAP HANA 的 FPGA 加速论文荣获了此次工业界 best paper 的桂冠；学术界也有至少五篇论文讨论 GPU、PMem 的相关话题，热度可见一斑。</p><p></p><p></p><h3>NoSQL 领域持续发展</h3><p></p><p></p><p>过去十几年，随着互联网业务快速增长，丰富的业务场景和数据规模的爆炸增长，催生了 NoSQL 领域的蓬勃发展。对于涌现的各种 NoSQL 产品种类，都持续有新的技术思路体现在每年的 VLDB 中。在 2022 年的 VLDB，NoSQL 领域有工业界贡献的时空数据库、向量数据库和图数据库，也有关于 LSM 引擎的架构优化论文，继续保持了 NoSQL 欣欣向荣百花齐放的态势。</p><p></p><p></p><h3>Graph 保持高热度</h3><p></p><p></p><p>在数据爆炸时代，数据关联性的价值逐渐突显，学术界 Graph 早已火热多年。今年 VLDB 一共有 9 个 Graph Sessions，占到了整体比例的 20%，在论文数量上 Graphs 有 45 篇， 仅次于 Machine Learning, AI and Databases，与传统的 Database Engines 打平。在这 9 个 Graph Sessions 中，被接收的论文方向覆盖了：时序图（系统与算法），动态图（系统与算法），概率图（算法），图查询优化，Graph AI(系统与应用），子图匹配（算法优化与应用），图数据库系统，图计算系统等方向。不难看出，对图算法的研究远多于图系统，且图算法相关论文几乎都是各大学的独立研究成果。作为学术论文，创新性是最重要的，从算法角度探索新方法新问题，会比系统角度取得创新性周期更短依赖条件更少，因此高校偏爱算法也就不难理解了。其实，从小编来看，场景、算法、系统是三个密切联动的环节，需要互相促进来实现螺旋上升。因此，图领域需要加强工业界和学术界的进一步交流合作。</p><p></p><p></p><h2>字节跳动论文介绍</h2><p></p><p></p><p>字节今年共有三篇论文被收录，其中两篇关于图数据库 ByteGraph 以及 ByteGNN，一篇介绍了 ByteHTAP 系统，相信读者从名字就能看出论文介绍的系统类型。这些系统都广泛应用于字节业务丰富的业务场景，在实践中沉淀打磨推陈出新，相比有更强的实际参考意义，在悉尼现场，也吸引了大量研究人员关注和交流。</p><p></p><p>我们在此，对这三篇论文做简要介绍，也非常欢迎大家找来原文阅读。</p><p></p><p></p><h3>ByteGraph: A High Performance Distributed Graph Database in ByteDance</h3><p></p><p></p><p>论文链接：<a href=\"https://www.vldb.org/pvldb/vol15/p3306-li.pdf\">https://www.vldb.org/pvldb/vol15/p3306-li.pdf</a>\"</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ce/ceb68a65ff5cf90c766d74a9f1c02688.jpeg\" /></p><p></p><p>本文介绍了在字节跳动内部广泛使用的图数据库系统 ByteGraph。在字节跳动内部，用户、视频、评论 / 点赞、商品等等多种类型元素及其之间联系可以用 Graph 模型来完美表达；这些图状数据上，有出度几亿的超级节点的存储查询挑战，也有 TP、AP 甚至大量 Serving 流量的混合挑战，ByteGraph 在多年支持这些场景中不断演进和迭代，本篇论文就详细介绍了 ByteGraph 的整体架构和设计，以及多年沉淀的一些场景问题及其方法探索。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a2/a28044bb568575e9025917faee0e4a71.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/36/36d48ae9add669f5d67df67a0861a989.png\" /></p><p></p><p>表 - 字节内部 Graph OLTP/OLAP/OLSP workloads 特点总结</p><p></p><p>ByteGraph 采用了计算存储分离的架构，支持 gremlin 分布式查询，可分层水平扩展到几百个节点规模。面向字节内部广泛存在的超级顶点问题、查询 workload 多样且经常变化的问题，采用了 EdgeTree 存储结构、自适应 Graph 索引等针对性设计，并对工程实践做了大量优化以提高并发性能。目前 ByteGraph 在内部已有数百个集群、上万台机器的部署规模，是全球最大部署规模的图数据库之一。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3f/3fa49c9de25924d5eb7b7218f61e4823.png\" /></p><p></p><p>图 -ByteGraph 系统架构图</p><p></p><p>在查询层，ByteGraph 自研了 Gremlin 的查询引擎，支持了常见的 Gremlin step 并针对字节业务做了不少扩展。在海量的数据与并发的打磨下，做了基于 RBO/CBO 策略的查询优化以及列式数据格式等执行优化。但坦率讲，相比关系型数据库经过几十年里无数工程师和研究人员的努力建设，图数据库理论和实践都还有很多的路要走，也希望在未来能有机会 ByteGraph 能够继续通过顶会论文的方式作出自己的贡献，和大家交流学习。</p><p></p><p>图数据库的内存组织结构非常关键，不仅需要表达 Graph 的数据模型还需要支持高吞吐低延迟的访问性能。如图 4 所示，ByteGraph 分别使用 Vertex Storage 和 Edge Storage 在内存中缓存顶点和边。每个顶点及其属性都存储为 KV 对，其中键由唯一的 ID 和顶点类型编码，值是顶点的属性列表。为了有效地执行图遍历查询，边被组织为邻接表。为了减少在图遍历中访问超顶点后产生大量中间结果的可能性，邻接表根据边类型和方向进一步划分。为了处理超顶点和频繁更新，减少边的插入带来的写入放大以及在整个列表扫描期间产生更少的磁盘 I/O。每个邻接表都存储为一个树结构，称为 edge-tree。edge-tree 由三种类型的节点组成，即 Root node、meta node 和 edge node，每一种节点都存储为 KV 对。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/04/0411fc8fe9a505d14693065cbb769567.png\" /></p><p></p><p>关于 ByteGraph 更多细节，欢迎大家查阅论文或者联系 ByteGraph 团队同学交流讨论。</p><p></p><p></p><h3>ByteGNN &nbsp;: Efficient Graph Neural Network Training at Large Scale</h3><p></p><p></p><p>论文链接：<a href=\"https://www.vldb.org/pvldb/vol15/p1228-zheng.pdf\">https://www.vldb.org/pvldb/vol15/p1228-zheng.pdf</a>\"</p><p></p><p>Graph AI 方向是近几年大热的一个系统方向，比如上届 OSDI 会议连续有 4 篇 GNN 相关的论文被发表，SOSP/EuroSys/ATC/MLSys 每年也有很多有关于如何高效设计 GNN 训练 / 推理系统的文章被接收。今年 VLDB 上有关于 GNN 系统设计，优化以及应用的文章也不少。</p><p></p><p>图神经网络（GNN）作为新兴的机器学习方法，广泛应用于字节的推荐、搜索、广告、风控等业务场景中。面对字节海量的数据，采用分布式 GNN 系统提升训练的可扩展性和训练效率变得至关重要。然而，现有的分布式 GNN 训练系统存在各种性能问题，包括网络通信成本高、CPU 利用率低和端到端性能差。ByteGNN 通过三个关键设计解决了现有分布式 GNN 系统的局限性：</p><p></p><p>（1）将 mini-batch based 图采样的逻辑抽象成计算图以支持并发处理</p><p></p><p>（2）粗粒度和细粒度的调度策略以提高资源利用率并减少端到端 GNN 训练时间</p><p></p><p>（3）为 GNN workloads 量身定制的图分区算法。实验表明，ByteGNN 的性能优于最先进的分布式 GNN 系统（i.e., DistDGL, Euler, GraphLearn）, 端到端执行速度提高了 3.5-23.8 倍，CPU 利用率提高了 2-6 倍，网络通信成本降低了大约一半。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/86/86e6a3320b456f41f7405a1db7808d1d.jpeg\" /></p><p></p><p>ByteGNN 为了显著降低网络开销，首先从系统架构层面将采样与训练这两个阶段作了解耦，让不同执行器分别负责一次 mini-batch 中的采样与训练：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b9/b96fd5a63068d3a3ba3a075081b02371.png\" /></p><p></p><p>同时，ByteGNN 提供了一套自定义的采样编程接口，不同 GNN 模型将统一用该接口来实现不同的采样逻辑。系统后端基于该接口自动地将采样逻辑解析成为一个计算图 DAG。采样计算图化的好处是可以充分利用 CPU 利用率，动态地将分布式采样过程抽象成更细粒度的小 task 并将其流水线化。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/56/5662422d0ef1effbe680833f5e92b297.png\" /></p><p></p><p>ByteGNN 也做了一层中间调度层，将采样计算图和训练计算图“软连接”到了一起，通过一个调度器动态地平衡采样与训练这两个阶段的资源消耗和消费速率，目标使得系统的 CPU 利用率和内存开销达到最优：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c0/c00f7cc13397025764e72a50ffc14ed0.png\" /></p><p></p><p></p><h3>ByteHTAP: ByteDance’s HTAP System with High Data Freshness and Strong Data Consistency</h3><p></p><p></p><p>论文链接：<a href=\"https://www.vldb.org/pvldb/vol15/p3411-chen.pdf\">https://www.vldb.org/pvldb/vol15/p3411-chen.pdf</a>\"</p><p></p><p>近年来，在公司业务中，我们看到越来越多的场景需要对新导入的数据进行复杂的分析，并同时强调事务支持和数据强一致性。因此在论文中，我们重点描述了字节跳动的自研 HTAP 系统 ByteHTAP 的构建过程。ByteHTAP 是具有高数据新鲜度和强数据一致性的 HTAP 系统，采用分离引擎和共享存储架构。</p><p></p><p>其模块化系统设计充分利用了字节跳动现有的 OLTP 系统和开源 OLAP 系统。通过这种方式，我们节省了大量资源和开发时间，并允许将来轻松地扩展，例如用其他替代方案替换计算引擎。ByteHTAP 可以提供高数据新鲜度（数据从 OLTP 写入到 OLAP 查询可见，相隔不到 1 秒），这为我们的客户带来了许多新的能力。客户还可以根据业务需求配置不同的数据新鲜度阈值。ByteHTAP 还通过其 OLTP 和 OLAP 系统的全局时间戳提供强大的数据一致性，减轻业务开发人员自行处理复杂的数据一致性问题的负担。此外，文中还描述了我们对 ByteHTAP 引入的一些重要的性能优化，例如将计算推送到存储层，以及使用删除位图（Delete Bitmap）来高效处理删除。最后，依惯例我们在文中分享了生产环境中开发和运行 ByteHTAP 的经验教训和最佳实践。</p><p></p><p>ByteHTAP 的高层架构如下图所示，在共享存储系统上搭建了两个彼此分离的计算引擎。ByteHTAP 使用了字节的自研 OLTP 数据库 ByteNDB 作为 OLTP 负载的计算和存储引擎，并使用 Apache Flink 作为 OLAP 负载的计算引擎。ByteHTAP 支持一个统一的，兼容 ANSI SQL 标准的用户入口并拥有一个智能代理层，DML，DDL 和 OLTP 负载的典型查询（如点查）会被发送给 OLTP 计算引擎，而复杂查询（如多重联接，大量聚合）会被发送给 OLAP 的计算引擎。这样的组织架构将 OLTP 和 OLAP 负载发给更合适的处理引擎，并能够有效防止这两类负载之间的串扰。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/bd/bd340b4bea531ab65c8cbcc5eeb26547.png\" /></p><p></p><p>图 -ByteHTAP 系统架构图</p><p></p><p>作为 ByteHTAP OLTP 侧的计算和存储引擎，ByteNDB 遵循“log is database”的理念。用户数据的插入，更新和删除的日志在其 LogStore 存储组件持久化之后即完成提交，并通过一个分布式数据复制框架可靠地按数据分区分发至各存储节点（PageStore）回放为行存数据页面。ByteHTAP 扩展了 ByteNDB 的复制框架，已提交 的 DML 事务的逻辑日志（即 MySQL 二进制日志）根据用户表中定义的分区方案被连续分发到列存储节点，以构建列存格式的数据存储，该存储可能存储在与其对应的行存不同的存储节点上。ByteHTAP 的列存存储由内存中的 Delta Store 和持久化的 Base Store 组成。OLAP 查询使用指定的 LSN 作为其快照版本来扫描基量存储和增量存储。集中式元数据服务 Metadata Service 负责为 OLAP 的查询优化器和存储节点提供元数据信息，会消费 DDL 信息并构建多版本元数据，持久化并将元数据缓存在内存中供查询。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e1/e16e9d5d42f33b676a4ef621634b3472.png\" /></p><p></p><p>图 -ByteHTAP 列存前后台数据操作及其一致性协调示意图</p><p></p><p>上述的共享存储设计保证了从 OLTP 存储侧分发的逻辑日志可以马上进入 OLAP 的内存存储 Delta Store，从而马上对 OLAP 的用户查询可见，从而保证了 ByteHTAP 的高数据新鲜度。而 ByteHTAP 通过为其查询提供一致的数据快照来保证强数据一致性。每个 DML 和 DDL 语句都会在系统中生成一个全局唯一的 LSN（日志序号）。同一事务中的语句会被包装在一起并以原子方式分发到目标节点。元数据服务 Metadata Service 负责将最新的“全局提交 LSN” 发送给 OLAP 计算引擎，我们的设计保证了 LSN 小于此“全局提交 LSN” &nbsp;的所有日志都已经被 OLAP 列存接收并持久化。OLAP 查询引擎中的 Metadata Service 客户端会定期从 Metadata Service 获取最新的全局提交 LSN 并缓存。OLAP 查询引擎将根据缓存了的全局提交的 LSN 为每个用户查询分配一个 read LSN，此 read LSN 会被下发到各 OLAP 列存存储节点，并用以确定数据可见性。在 OLAP 存储内部存在着大量的并发前后台数据操作，他们之间的数据一致性也由这一套 LSN 系统来进行保证。在大多数情况下，ByteHTAP 数据更改之后不到一秒即可提供给 OLAP 侧的用户查询。</p><p></p><p>实验和线上数据均表明，ByteHTAP AP 侧的性能达到业界优秀水平，并在 TP 侧数据吞吐量显著增加（客户连接数 0-64，数据吞吐量 2k-60k tpmC）时保持查询性能稳定（劣化小于 5%）。同样的，ByteHTAP 在数据吞吐量较大的情况下（182MB/s) 依然保持着远小于 1s （606ms）的数据新鲜度。</p><p></p><p></p><h2>部分工业界论文介绍</h2><p></p><p></p><p>工业论文主要来自头部企业，这些企业拥有超大规模的数据和系统，也聚集了高水平的系统开发人员，在多年的场景积累下，能够持续探索新的方法解决有挑战的问题，也自然是 VLDB 青睐的对象。</p><p></p><p></p><h3>Hardware Acceleration of Compression and Encryption in SAP HANA（Best Industrial paper）</h3><p></p><p></p><p>使用 FPGA 等专有硬件进行加速是一个热门的研究课题，多家公司都尝试过类似的 approach 来加速各系统中的瓶颈环节。FPGA 的专项性能要强于 CPU，且减少了 CPU 与 I/O 链路中的损耗，能够为系统提供不错的性能优势。来自 ETH Zurich 和 SAP 的这篇论文，就来自这个领域。主要介绍了使用 FPGA 加速 SAP HANA 的压缩与加密流程，有效提高了系统吞吐，并在实验中，具体展示了分析型数据库引擎的应用场景和各个重要性能参数中的 trade-off。本文介绍了 FPGA 在 HANA 这样一个工业级内存数据库的落地情况，并对相关性能场景进行了进行了较为详细的测试，数据翔实，best paper 当之无愧。</p><p></p><p>文中主要 offload 的部分是压缩与解压缩，加密与解密，整体的 pipeline 结构如下</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/9e/9e96ca474b16cf95745f0efece99f9a0.png\" /></p><p></p><p>具体的实现方法是，将 OpenCL 作为一个库整合到系统内核中以函数调用的方法提供支持，压缩部分已经已经整合到了 OpenCL 中，而加密部分则使用 VHDL 实现，即图中的 AES-256 算法。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/22/22c1dbb86bf69e284e31a066fe7cb5fa.png\" /></p><p></p><p>通过测试，我们发现 FPGA 的加入带来了几大优势：压缩与加密流程被显著加速；CPU 计算资源部分释放；数据传输更加安全；加密过程由数据库引擎控制，而不是云服务提供商；存储空间和网络流量有所减少。详细测试数据可以参见论文。</p><p></p><p></p><h3>Tair-PMem: a Fully Durable Non-Volatile Memory Database</h3><p></p><p></p><p>本文出自阿里巴巴，主要介绍了基于傲腾的 Tair-PMem 内存数据库设计。Tair-PMem 解决了传统内存数据库不能胜任完全持久化的问题，并通过巧妙的设计缓解了 NVM 的性能开销，减少了 NVM 编程的复杂性，获得了极低的尾部延迟以及更低成本的优势。同时也满足了内存数据库对大数据存储等需求的负载。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/cc/cc4ebdd1704d326ac56f80ba7467bc70.png\" /></p><p></p><p>傲腾的核心特性主要体现在与传统 DDR 内存相比，容量更大，且数据断电后不丢失，但整体的时延表现与内存相比是其数倍。又由于这些不同于传统内存的特性，其编程难度也有所提升。</p><p></p><p>对于此文，我们可以着重看一下他的架构设计：为了让傲腾提供与 DRAM 近似的性能，Tair-Pmem 设计了一个高可控的数据放置逻辑，其会根据数据的持久性，访问频次和大小来决定数据和其对应的元数据的存放位置。在设计上使用了统一的 API 来解决 Pmem 的编程困难问题。整体的模块化改造保持了代码的低侵入性，提高了系统整体的稳定性。使用 Pmem 的 byte addressable 特性增强了数据库的基本能力。例如通过 Pmem 的持久化特性，Tair-Pmem 系统的 recovery 速度远超传统实现。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/98/983e2d32faf1c56ad73496ceeeefbaf9.png\" /></p><p></p><p>在整个 Toolkit 中，最重要的两个核心组件是 Allocator 和 Log &amp; data pool：Allocator 的整体设计与传统的 jemalloc 类似，都使用了 slab 来管理内存，这里比较特别的是尽量将元数据存放在 DRAM 中。在真实分配内存的过程中，Allocator 会根据申请的内存类别和预定义的 DRAM-NVM 使用比例来分配。而对于 Log &amp; data pool，其选择了链表的变种 ES-linked list 来管理，并在其上构建了一些基础数据结构的支持。</p><p></p><p>从实验的结果来看 Tair-Pmem 系统的整体吞吐和长尾时延表现都很优秀，且从成本角度考虑其提供的性能也十分惊艳。</p><p></p><p></p><h3>CloudJump: Optimizing Cloud Database For Cloud Storage</h3><p></p><p></p><p>近十年来，数据库领域的一个重要的架构发展趋势就是存储计算分离。在存算分离的系统中，数据通常会放置在某种云存储中，而非传统的本地存储。阿里云的存算分离数据库 PolarDB 已经进行了多年的发展与探索，实践中积累了大量思考与经验，本文就介绍了在设计一个适用于存算分离数据库的云存储时，需要考虑的设计原则，值得一读。</p><p></p><p>首先，文中梳理了云存储相比本地 SSD 的性能指标差异，以及这些差异对不同种类的存储引擎（B-Tree，LSM Tree）所产生的技术挑战和影响。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d7/d7c44ff927460d78faca371b77878505.png\" /></p><p></p><p>基于这些问题，文中提出了一些解决的思路和设计原则。例如，云存储场景应当尽量利用多机优势，将数据、大 IO 请求和 recover 带宽打散到不同节点上；通过预读、数据聚合、压缩、过滤等方式，尽量减少单次请求路径上的 IO 次数；需要考虑请求之间的资源隔离性，等等。</p><p></p><p>最后，论文结合 PolarDB 和 rocksdb 在云上的实现，举例说明了上述设计原则如何付诸具体实践，由于篇幅限制，这里只简单介绍 polardb 的相关内容。针对 redo log，polardb 将 redo log 按修改的 page 进行了分片，使得 redo log 被打散，能够获得写入性能优势；对于单个 redo log 分片，还会进一步拆分为多个物理 chunk，使得单个大的 log IO 任务可以被拆分开来，并发执行。得益于 redo log 的打散，recovery 过程也可以并发执行，另外 polardb 还会将元信息维护在统一的 superblock 中，减少读取次数。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a2/a253a2b6035f8ba12d27771ad5c09f10.png\" /></p><p></p><p>除了 log 拆分之外，polardb 还引入了新的预取策略，降低请求延迟；针对 innodb 的锁使用进行优化，避免加锁 IO，降低锁冲突；针对不同写入路径上的 IO 任务，区分优先级和多队列，确保高优先级任务（比如写 WAL）能够优先执行；IO 请求进行对齐，等等。</p><p></p><p></p><h3>Ganos: A Multidimensional, Dynamic, and Scene-Oriented Cloud-Native Spatial Database Engine</h3><p></p><p></p><p>本文出自阿里巴巴，主要介绍了阿里巴巴出品的最新一代地理信息数据库引擎。在智慧城市、电子地图、卫星遥感、物联网、车联网 / 智能交通、互联网出行、智慧物流、传感网与实时 GIS 等众多领域都有较为广泛的应用场景。</p><p></p><p>Ganos 设计、实现上高度兼容 PostGIS 语法和接口，可以无缝对接支持 PostGIS 的各类软件生态，架构上基于 PolarDB 实现主流的存储计算分离架构，实现计算 / 内存 / 存储组件解耦，形成可独立伸缩的资源池。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/50/508f46f37d06ba8d8f7204f9baa92048.png\" /></p><p></p><p>引入拓展存储 (Extended storage) 设计 ：时空数据是很复杂的数据模型，相比于传统的关系型数据，数据结构更丰富、需要占用更多的存储资源，并且在使用过程中具有明显的冷热数据分离问题，为此 Ganos 采用了分布式共享存储 + 拓展存储（OSS Alibaba Cloud Object Storage Service）的方案，很好的平衡了存储成本、数据访问性能需求。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/03/0352caa6a6f575aa85e6a9226d58226a.png\" /></p><p></p><p>支持多级并行计算加速：跨节点并行 (IQP intra-query parallelism)+ 节点内并行 (IFP intra-function parallelism) 加速计算。其中 IQP 将一个 query 要处理的数据切分成数据片，分发给多个 RO 节点进行独立的计算；而 IFP 将超大的单个时空数据片切分成一个个的小时空单元，然后通过多线程并行计算达到计算加速效果。在 benchmark 测试中对比 PostgreSQL，Ganos 通过多级并行计算获得显著的加速。</p><p></p><p></p><h3>Magma: A high data density storage engine used in Couchbase</h3><p></p><p></p><p>本文是 Couchbase 公司贡献，总结了 couchbase 作为文档数据库对于 KV 引擎的使用方式和痛点，并介绍了其下一代存储引擎 magma。magma 在设计上仍是基于 LSM Tree 结构的 KV 存储引擎，采用 KV 分离的设计，但做了很多有趣的创新设计，其中 key 存储在 key SST 中，value 维护在按照 sequence id 有序排列、切分为多个文件的 value log 中。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/0a/0a05748cd11e6320ce4c179fcce7c7f5.png\" /></p><p></p><p>相比于经典的 WiscKey，这篇论文最大的贡献在于 GC 的设计，其不需要像 WiscKey 在 GC 时扫描整个 value log 并进行 point get 查询，而是首先对 key sst 进行 compact 产生 deleted key set，再根据 deleted key set 中记录的 value sequence id 计算得出每段 value log 对应的垃圾数据的比例，只需要对垃圾比例较高的 value log 段与邻接段进行 merge 即可。这样既可以避免 WiscKey GC 时的大量 point get，也可以根据垃圾比例对 value log 进行分段 compact，降低写入放大。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/65/6563afa6ad6d11a9fbce37ba577bae2e.png\" /></p><p></p><p></p><h3>Manu: A Cloud Native Vector Database Management System</h3><p></p><p></p><p>Manus（Milvus 2.0 版本产品代号）是 Zilliz 公司发布的一款 “面向向量数据管理而设计的云原生数据库系统”。向量数据管理系统是用于存储、检索向量数据的数据库系统。向量数据库广泛应用于现在 AI 各种系统中，例如人脸识别、推荐系统、图片搜索、视频指纹、语音处理、自然语言处理等场景，使用深度学习的方法将这些非结构化数据映射成向量表示，然后在使用时就需要到巨大的向量集合中检索和某个向量距离（各种内积、欧氏距离等相似度计算方法）最近的 top-k 个向量。这类系统的开山鼻祖是 Facebook 开发的 Faiss，之后各大公司都研发自己的向量检索系统，而 Milvus 则是业界专业广受认可的开源向量检索系统。该系统的设计主要针对以下几方面痛点 :灵活的一致性策略，系统提供可见性 / 时效性配置功能，用户可以根据业务的需求，来指定插入数据在可被查询到前所能容忍的最大时延，从而平衡系统执行开销和业务时效性；支持组件级的弹性扩展能力，对于不同类型的任务，根据对不同组件运行开销的不同，针对性给系统瓶颈部分添加资源；简单高效的事务处理模型，因为系统处理的是向量数据，不需要像关系数据库那样提供多表的复杂事务支持，可以对单表行上的事务做特定的性能优化。系统的整体架构如下图所示，Manu 采用了一个四层的架构来实现对读 / 写、计算 / 存储以及有状态 / 无状态组件的分离：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/dd/ddcbffc117106dca23fdc946465560a2.png\" /></p><p></p><p>Access layer 是访问层， 由若干个无状态的 proxy 组成，这些 proxy 负责接收用户请求，将处理过的请求转发给系统内的相关组件进行处理，并将处理结果收集整理好之后返回给用户。Coordinator layer 任务协调管理器，负责维护元数据以及协调各个功能组件完成各类系统任务。其中 Root Coordinator 负责处理数据集创建 / 删除等数据管理类型的请求；Data Coordinator 负责管理系统中数据的持久化工作，协调各个 data node 处理数据更新请求；Index Coordinator 负责管理系统中数据索引的相关工作，协调各个 index node 完成索引任务；Query Coordinator 负责管理各个 query node 的状态，并根据负载的变化调整数据和索引在各 query node 上的分配情况。上面各种 Coordinator 通常都有多个实例，从而提高组件的可靠性。worker layer 负责执行系统中的各类任务。所有的 worker node 都被设计成无状态执行的的，它们读取数据的只读副本并进行相关的操作，并且 worker node 之间不需要通信协作，从而实现 worker node 的数量可以根据不同场景的负载差异进行调整，弹性增加必要的技术资源。值得重点关注的是存储层 (Storage Layer) 设计，Manu 采用了“日志即数据（log as data）”的设计理念，将日志作为系统主干用来连接各个组件。基于对延迟、容量和成本等方面的考虑，Manu 实现了 WAL（write ahead log） 和 binlog 两类日志流，存量数据被被组织在 Binlog 当中，而增量部分则被组织在 WAL 中。Data node 消费 WAL 中的内容并对数据进行处理后产出到 Binlog 中，query node、index node 则仅需消费处理 Binlog 日志流中的数据。从而各个 worker node 实现互相独立的关系。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/bb/bbd4ee946e70c223f168699b2070f42f.png\" /></p><p></p><p></p><h3>SQLite: Past, Present, and Future</h3><p></p><p></p><p>SQLite 的大名在数据库领域可谓是如雷贯耳，本篇论文由 SQLite 的开发者和威斯康辛大麦迪逊分校联合出品，介绍了 SQLite 的 workload、近二十年中所处环境的变化以及未来的展望。在硬件方面，近年来硬件领域有了长足的进步，很难想象目前的低端移动设备（树莓派 4）在性能上也远超 SQLite 最早运行的设备（Palm Pilot）；在 workload 上 SQLite 的用户存在大量不同比例的读写混合的场景，以及类 KV 的 blob point get 使用场景，近年来随着数据分析领域的发展，还存在一些 OLAP 的查询，这些都与 SQLite 最早设计时的假设有偏差。文中花较大篇幅，对 SQLite 在 OLAP 方面的性能和优化进行了讨论，并与 DuckDB 进行了对比。在 OLAP benchmark 之后，作者对 SQLite 的执行情况进行了分析，提出了针对 equijoin 使用预购建 bloomfilter 对原有的 nested loop join 进行优化的方案，并进行了实现；除此之外，还提出了对提取记录中特定列的流程的优化，但是由于复杂度较高、涉及到兼容性问题，没有进行实践。小编认为，文章的美中不足之处在于，所有 benchmark 都是针对 duckdb 进行对比，包括写入相关的测试和 blob 使用场景的测试，但是 duckdb 针对这两种场景并没有什么独特的设计，因此文中也没有针对这两种场景对 SQLite 进行优化。</p><p></p><p></p><h3>Velox: Meta’s Unified Execution Engine</h3><p></p><p></p><p>为了处理特定的，非常个性化的数据负载，业务经常需要临时开发新的专用计算引擎，但这实际上创建了一个又一个孤立的数据环境。通常，这些引擎之间几乎没有共享，难以维护、发展和优化，最终导致数据用户提供了体验不一致。为了解决这些问题，Meta 创建了 Velox，一个新颖的开源 C++ 数据库加速库。Velox 提供可重用、可扩展、高性能且与程序方言无关的数据处理组件，用于构建执行引擎和增强数据管理系统。该库依赖于矢量化执行和自适应性，并由 Meta 的工程师从头开始设计，以支持对复杂数据类型的高效计算，并适应无处不在的现代计算负载。Velox 目前已与 Meta 的十几个数据系统集成或正在集成，包括 Presto 和 Spark 等分析查询引擎、流处理平台、消息总线和数据仓库的数据摄取架构、用于特征工程和数据预处理的机器学习系统（PyTorch）等。它在以下方面提供了好处：(a) 通过泛用化以前仅适用于单个引擎中的优化来提高效率，(b) 为用户提高数据一致性，以及 © 通过提高可重用性来加强工程效率。</p><p></p><p></p><h3>OceanBase: A 707 Million tpmC Distributed Relational Database System</h3><p></p><p></p><p>OceanBase 是由蚂蚁金服自主研发的分布式关系数据库系统，已经设计开发了超过十年。OceanBase 是一个横向扩展的多租户系统，提供基于 shared-nothing 架构的跨地域高可用性。除了与其他分布式 DBMS 共享许多相似的目标，例如水平可扩展性、高可用性等，我们的设计还受到其他需求的驱动，例如对典型 RDBMS 的兼容性，以及同时适应客户内部和外部部署。OceanBase 实现了其设计目标。它实现了某些主流经典 RDBMS 的显著特性，这些 RDBMS 承载的大部分应用程序都可以在 OceanBase 上运行，只需稍加修改甚至不加改动。在支付宝等众多商业业务中已经部署了数万台 OceanBase 服务器。它还成功通过了 TPC-C 基准测试，并以超过 7.07 亿的 tpmC 夺得第一。本文介绍了 OceanBase 的目标、设计标准、基础设施和关键组件，包括其用于存储和事务处理的引擎。此外，它详细介绍了 OceanBase 是如何在一个分布式集群中达到上述领先的 TPC-C 基准测试的结果的，该集群拥有 1,500 多台服务器，分布在 3 个区域上。文章还描述了蚂蚁团队十多年来在构建 OceanBase 中所学到的经验教训，这对构建工业级的分布式数据库来说，有非常宝贵的学习和借鉴价值。</p><p></p><p></p><h2>总结</h2><p></p><p></p><p>在当前数据智能时代，数据存储计算技术已经成为社会信息化的核心引擎，VLDB 等顶会无疑是数据技术创新殿堂的明珠，持续汇集全世界的新方法新思路，指引和启迪学术界和工业界不断攀登突破。</p><p></p><p>服务全球用户的字节，既有数据创新技术的土壤也依赖技术赋能产品，从而更好的服务亿万用户。相信 VLDB 2022 收录的 Graph 和 HTAP 领域论文只是一个开始，未来字节会有更多技术创新突破通过各种形式为技术创新社会进步做出自己的贡献。同时，也非常欢迎大家加入我们（ https://job.toutiao.com/s/6snYofd），一起在 NoSQL、数据库等相关领域解决世界级挑战，拓展未知技术边界。</p><p></p>",
    "publish_time": "2022-10-11 18:34:21",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]