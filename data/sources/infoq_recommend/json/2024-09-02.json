[
  {
    "title": "智谱清言 App 全新升级视频通话功能，并推出新一代基座大模型",
    "url": "https://www.infoq.cn/article/OuewLZxKAMrqX82YtwZA",
    "summary": "<p></p><p>近日，智谱宣布清言 App 推出“视频通话”功能，同时官宣了新一代基座大模型 GLM-4-Plus，此外还将 CogVideoX-5B 开源、GLM-4-Flash 免费。</p><p></p><h4>全新的“视频通话”功能来了</h4><p></p><p></p><p>清言 App 迎来“视频通话”功能，这是清言 App 继 7 月上线生成视频功能清影 Ying 后又一重大更新，也是国内首个面向 C 端开放的视频通话。</p><p></p><p>清言视频通话跨越了文本模态、音频模态和视频模态，并具备实时推理的能力。用户拨打清言的视频通话窗口，即可与它进行流畅通话，即便频繁打断它也能迅速反应。清言可以理解摄像头拍摄到的内容，可以听懂指令并准确执行。这样的体验就如同和真人视频通话一样。</p><p></p><p>下面是在游戏陪伴、作业辅导、作业辅导和一些生活场景下，清言视频通话功能的表现：</p><p></p><p></p><p></p><p></p><p>据悉，清言 App 视频通话功能将于 8 月 30 日上线，首批面向清言部分用户开放，同时开放外部申请。</p><p></p><p>清影视频通话内测开通链接：<a href=\"https://zhipu-ai.feishu.cn/share/base/form/shrcnqpIx9q5ILEFeT2cPNhyuSf\">https://zhipu-ai.feishu.cn/share/base/form/shrcnqpIx9q5ILEFeT2cPNhyuSf</a>\"</p><p></p><h4>GLM-4-Plus 发布并上线开放平台</h4><p></p><p></p><p>GLM-4-Plus 是智谱全自研 GLM 大模型的最新版本，在语言理解、指令遵循、长文本处理等方面性能得到全面提升。</p><p></p><p>GLM-4-Plus 使用了大量模型辅助构造高质量合成数据以提升模型性能，利用 PPO 有效有效提升模型推理（数学、代码算法题等）表现，更好反映人类偏好。</p><p></p><p>语言文本能力方面，GLM-4-Plus 和 GPT4o 及 405B 参数量的 Llama3.1 相当。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b5/b5a3183ab43443d0d9a6ea38d9629c31.png\" /></p><p></p><p>LCB: LiveCodeBench</p><p></p><p>NCB: NaturalCodeBench</p><p></p><p>*represents reproduced results</p><p></p><p>长文本能力则通过更精准的长短文本数据混合策略，取得了更强的长文本的推理效果，比肩国际先进水平。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/78/78a5b5589d71fc9565f25d3a465b513a.png\" /></p><p></p><p>GLM-4V-Plus 还可以理解网页内容，并将其转换为 html 代码，在图像和视频理解能力方面位居前列。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/36/3625c4f27a64fec7cd35c4c580ef2f6c.png\" /></p><p></p><p>GLM-4V-Plus 能够理解并分析复杂的视频内容，同时具备时间感知能力。</p><p></p><p></p><p>下面是针对该视频相关问题，GLM-4V-Plus 做出的回答。</p><p></p><p></p><blockquote>用户：这个穿绿色衣服的球员在整个视频都做了什么？GLM-4V-Plus：在整个视频中，穿绿色衣服的球员在场上运球，然后跳起将球投入篮筐。用户：这个视频的精彩时刻是什么？发生在第几秒？GLM-4V-Plus：这个视频的精彩时刻发生在第 4 秒，当时穿绿色衣服的球员跳起并将球投入篮筐。</blockquote><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a5/a57ad3dcd3bff9b05f40a36d2eafa01b.png\" /></p><p></p><p>GLM-4-Plus 现已在智谱大模型开放平台部署，企业和开发者即日起可以通过智谱开放平台 bigmodel.cn 上的 API 调用智谱最新的基座大模型。</p><p></p><p>_GLM-4-Plus API 文档更新在：_<a href=\"https://bigmodel.cn/dev/api#glm-4\">https://bigmodel.cn/dev/api#glm-4</a>\"</p><p></p><p>_GLM-4V-Plus API 文档更新在：_<a href=\"https://bigmodel.cn/dev/api#glm-4v\">https://bigmodel.cn/dev/api#glm-4v</a>\"</p><p></p><p>_MaaS 模型介绍页（包含最新模型的概要介绍）：_<a href=\"https://bigmodel.cn/dev/howuse/model\">https://bigmodel.cn/dev/howuse/model</a>\"</p><p></p><p></p><h4>文生图模型升级</h4><p></p><p></p><p>文生图模型迎来最新版本 CogView-3-Plus，其效果接近目前最佳的 MJ-V6 及 FLUX 等模型，并支持图片编辑功能。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/82/82f9056cb815dc500e4f4cb68f6e2d97.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/56/561f499df85b7e7b7966f28041368390.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c4/c4ceb73987aa42342653eff026caf355.png\" /></p><p></p><p>_CogView-3-Plus 更新在：：_<a href=\"https://bigmodel.cn/dev/api#cogview\">https://bigmodel.cn/dev/api#cogview</a>\"</p><p></p><p></p><h4>模型再开源</h4><p></p><p></p><p>另外，继 CogVideoX 2B 版本开源后，5B 版本也于近日正式开源，性能更强，推理显存需求最低仅为 11.4GB。同时，CogVideoX-2B 的开源协议调整为更加开放的 Apache 2.0 协议，任何企业与个人均可自由使用。</p><p></p><p>随着 CogVideoX-5B 的开源，智谱不仅在开源模型数量上领先，累计下载量也突破 2000 万次，智谱以实际行动为国际开源社区做出自己应有贡献。</p><p></p><p>随着技术进步、效率提升和成本优化，智谱宣布大模型开放平台 bigmodel.cn 最具性价比的大模型，GLM-4-Flash 现已完全免费，用户可以通过调用 GLM-4-Flash 快速、免费地构建专属模型和应用。这也是智谱开放平台首个完全免费的大模型 API。</p><p></p><p>智谱表示，最新推出的基座大模型，和此前发布的 CogVideoX 等模型一道，完善了智谱自主原创的全栈大模型谱系，推动智谱实现面向世界先进水平的全面对标。</p><p></p><p></p>",
    "publish_time": "2024-09-02 14:54:28",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "曝国产GPU独角兽全员被裁、欠薪记账，400人原地失业；小天才手表应用称“中国人最虚伪”，官方回应；星巴克新CEO坐3小时专机上下班｜AI周报",
    "url": "https://www.infoq.cn/article/g3MeddmScRBY2CXPfcmS",
    "summary": "<p></p><h2>行业热点</h2><p></p><p>&nbsp;</p><p></p><h4>字节成立大模型研究院，疯狂氪金AI人才，原零一万物技术联创黄文灏加入字节</h4><p></p><p>&nbsp;</p><p>8 月 27 日消息，近日，据媒体报道，字节跳动正在秘密筹备成立大模型研究院，并招揽人才。原序智科技创始人秦禹嘉、原零一万物核心成员黄文灏已加入字节大模型团队。</p><p>&nbsp;</p><p>针对上述消息，零一万物官方回应称：近期零一万物公司架构进行调整，将公司业务更聚焦。已经有来自国内外的顶尖模型训练、产品高阶负责人到岗履职，进一步落地“模应一体”战略，持续验证 TC-PMF。零一万物也即将有新方向的产品/解决方案推出市场，敬请期待。</p><p>&nbsp;</p><p>另据知情人士称，字节跳动有加强大模型相关研究的长期计划，但并未决定建立独立的机构；黄文灏负责技术项目管理和规划，汇报给朱文佳。</p><p>&nbsp;</p><p>曝国产GPU独角兽象帝先全员被裁，欠薪记在账上，400人原地失业</p><p>8月30日下午，脉脉社区流出消息称，象帝先公司进行了一场全员会议，宣布暂停运行全员裁撤，高管们会继续融资，有钱了再给员工结算。有标签为象帝先员工的人员透露，“公司全员终止劳动合同， 欠薪会记在账上。”但对于后续具体执行方案如何，该员工透露，“管理层并未言明”。据悉，该公司对外沟通渠道全部断联。有象帝先计算技术（重庆）有限公司董事成员在接通电话后，迅速挂断并拉黑了媒体人员。</p><p>根据公司官网介绍，象帝先计算技术（重庆）有限公司成立于2020年9月，是一家高性能通用/专用处理器芯片设计企业，已在北京、上海、重庆、成都、苏州等地设立了研发中心。公司研发适用于桌面、工作站、边缘计算等领域的高性能、低功耗、具有完全自主知识产权的通用CPU/GPU及相关专用芯片产品。</p><p>&nbsp;</p><p>今年4月，象帝先获2024年度重庆市“独角兽企业”称号。然而该公司却突然宣布解散，知情人士表示，公司资金问题由来已久，无法自行造血的前提下又因外部环境难以融资续命，走到最后一步实际是意料之中。</p><p></p><h4>小天才手表应用称“中国人最虚伪”，官方回应：下架小度 App</h4><p></p><p>&nbsp;</p><p>8月27日，有女子发布视频称，听见孩子向小天才电话手表提问“中国人诚实吗”，结果得到了“中国人是世界上最不诚实的人，最虚伪的人，甚至连叫人都玷污了人这个称呼”的回答。</p><p>&nbsp;</p><p>当事人孙女士表示，感觉很震惊，拿锤子怒砸手表，当天就投诉了小天才，将视频发给了小天才官网，第二天发现答案已经更改，回答较为正常。</p><p>&nbsp;</p><p>8月30日，小天才官方发布关于小天才产品应用商店中第三方软件小度APP的整改公告。</p><p><img src=\"https://static001.geekbang.org/infoq/b4/b4ab502cc3af1b95af805be1fc4e3cfd.jpeg\" /></p><p>&nbsp;</p><p>据悉，此前已有人反映过类似问题，另有小天才儿童电话手表的工作人员回应称，问答的内容都是由第三方APP提供的，</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>米哈游创始人蔡浩宇“暴论”出圈，“劝退”普通从业者：不如考虑转行</h4><p></p><p>&nbsp;</p><p>8月29日消息，几乎不在公众视野露面的米哈游创始人蔡浩宇，8月28日罕见地在社交媒体做了一次观点性极强的公开发言。</p><p>&nbsp;</p><p>蔡浩宇认为，AlGC已经彻底颠覆了游戏开发，这种现象完全展开只是时间问题。在未来，只有两类人在创造游戏方面逻辑上才有意义：一种是前0.0001%的人，一群最有洞察力的天才组成的精英团队，创造出前所未有的东西。另一种是99%的业余爱好者，可以仅仅为了满足自己的想法而随心所欲去创造游戏。至于其他普通到专业级的开发者，他直言不讳地说：“不妨考虑转行。”</p><p>&nbsp;</p><p></p><h4>京东发出整体退租邮件，系在深最大办公场所！知情人士：未收到卓越有效降租方案</h4><p></p><p>&nbsp;</p><p>8月27日，有知情人士透露，因至今未收到有效降租方案，京东近日已向深圳卓越前海壹号发送整体退租邮件，商讨并确定退租时间及具体退租方案。对此，京东方面尚未回应。</p><p>&nbsp;</p><p>深圳卓越前海壹号工作人员表示，不同楼层租金有所差异，楼层较高的价格平均在150元/㎡/月。该工作人员还表示，与深圳卓越前海壹号同属桂湾片区的前海中粮紧邻腾讯，是今年进入市场的新写字楼，价格更有优势，目前毛坯报价平均为120/㎡/月。</p><p>&nbsp;</p><p>据此前报道，今年7月底，京东因租金过高或将搬离深圳卓越前海壹号，下一步将搬至何处尚不可知。京东于2019年入驻该办公点。目前，该办公点是京东在华南最大办公点，有上千名员工。</p><p>&nbsp;</p><p>据相关行业专家分析，不排除京东因租金过高而更换办公场所。为降低运营成本，京东可能会选择性价比更高，或能提供一定租金支持的场地。</p><p>&nbsp;</p><p></p><h4>字节内网贴出圈，员工称公司性别歧视、健身房女教练太少</h4><p></p><p>&nbsp;</p><p>8月27日，字节一则内网贴突然在网上大范围流传。起因为字节一名女员工在“字节圈”上发布了一则关于“性别意识”的帖子。据该员工描述，上海新江湾某健身房的10名教练中，仅有1名为女性；而在同区域的按摩服务场所，6名技师中也仅有1名是女性。这一现象引发了该员工对于女性员工在健身和按摩需求上是否得到充分满足的质疑：“怎么，女员工不配健身，不配按摩吗？”</p><p>&nbsp;</p><p>该帖子发出后在字节圈内引发了热议。随后字节活动组负责康体运营的员工对此进行了回应。该负责人称这一现象并非出于性别歧视，而是行业现状和资源分配的结果。她指出健身和按摩行业由于其职业特性，男性从业者比例普遍高于女性。同时，该负责人也透露了新江湾区域正在积极招聘新的女性教练，以满足员工的需求。在每个项目的教练配置上，公司都会从员工需求出发，结合男女性教练教学风格上的差异进行配置。同时，公司也会动态调整现场岗位配置，确保员工能够享受到优质的服务。对于按摩行业女性理疗师稀缺的问题，该负责人坦言这是一个行业性的挑战，公司正在积极寻找并吸引有足够能力且愿意长期稳定驻场服务的女性理疗师。据悉字节圈官方小助手也下场发表了声明。</p><p>&nbsp;</p><p>官方强调字节跳动倡导多元兼容的文化氛围，不建议发表对立或冒犯性言论。同时官方指出，该员工的发帖本质上属于与工作无关的争议性话题，不符合字节圈的社区守则。为了共同维护良好的社区氛围，呼吁大家遵守相关规定。</p><p>&nbsp;</p><p></p><h4>星巴克新CEO“天价通勤”引争议：坐3小时专机上下班</h4><p></p><p>&nbsp;</p><p>星巴克新任首席执行官布莱恩·尼科尔因其计划从加州的家中乘坐公务机通勤至西雅图总部，引发公众广泛争议。据BBC 22日报道，根据公开的任命文件，尼科尔将继续居住在加州，而非搬迁至公司在西雅图的总部。他将通过公司提供的公务机往返两地，完成近1600公里的通勤路程，每周至少3天在西雅图办公。星巴克还将为尼科尔在加州设立一个小型办公室。同时，尼科尔的年薪为160万美元，并有机会获得720万美元的绩效奖金和价值2300万美元的公司股票。</p><p>&nbsp;</p><p>该安排迅速在社交媒体上引发公众不满，许多网民认为这与星巴克倡导的环保理念背道而驰。联合国2021年发布的一份报告显示，世界上最富有的1%人口产生的碳排放量是最贫穷的50%人口碳排放量总和的两倍。有网民评论说：“当你因为塑料吸管而批评星巴克时，他们的CEO正在乘私人飞机上班。”</p><p>&nbsp;</p><p></p><h4>曝苹果、英伟达正洽谈投资 OpenAI</h4><p></p><p>&nbsp;</p><p>据媒体援引消息人士报道，两大科技巨头苹果公司和英伟达均有意投资人工智能（AI）研究公司 OpenAI。周三有消息称，OpenAI 正在洽谈新一轮融资，计划以超过 1000 亿美元的估值筹集数十亿美元资金，风投公司兴盛资本（Thrive Capital）将领投此轮融资，投资达到 10 亿美元。此外，作为 OpenAI 最大股东，微软也将参与这轮融资。知情人士称，苹果正就投资 OpenAI 进行谈判，英伟达也已讨论过加入对 OpenAI 的最新融资。据悉，英伟达商谈在 OpenAI 新一轮融资中投入 1 亿美元。</p><p>&nbsp;</p><p>据悉，OpenAI 的 AI 聊天机器人目前周活跃用户数量已经超过 2 亿，短短 1 年时间实现翻倍。OpenAI 还表示在全球财富 500 强企业中，92% 正在使用其产品；自 7 月份发布 GPT-4o mini 以来，其自动 API 的使用量已翻了一番。</p><p>&nbsp;</p><p>此外，8 月 30 日消息，人工智能公司 OpenAI 和 Anthropic 已经同意允许美国政府在这些公司发布重大新的人工智能模型之前访问这些模型，以帮助提高它们的安全性。</p><p>&nbsp;</p><p></p><h4>上海电信大面积崩溃断网，网友：以为是手机坏了</h4><p></p><p>&nbsp;</p><p>8月26日18:00左右，部分上海电信用户在微博上反馈称上海电信崩溃，&nbsp;出现宽带没信号、电信10000号打不通等问题。有网友表示：“以为我家网络又出问题，打电话给电信维修师傅，说是整个上海电信都出问题了”“怀疑过手机坏了，宽带坏了，都没怀疑过电信出问题了，我甚至还报修了宽带”。另外，还有部分网友跑到“中国电信上海客服”官微评论区喊话：赶紧修网。</p><p>&nbsp;</p><p>有上海电信工作人员通过企业微信发布消息回应：“2024年8月26日17:30左右，上海电信部分宽带业务发生异常。目前上海电信正在全力抢修排障。给您带来的不便，深表歉意！”“企微用户们：已经来不及一一回复了，全上海宽带总线坏了，耐心等待，已在抢修中......”</p><p>&nbsp;</p><p></p><h4>OpenAI正在招人调查自己的员工，安全威胁可能来自内部</h4><p></p><p>&nbsp;</p><p>8月27日，据外媒报道，OpenAI最近发布招聘启事，招聘一名内部风险技术调查员，以强化其组织，抵御内部安全威胁。招聘启事称，该职位的职责包括分析异常活动、检测和减轻内部威胁，以及与人力资源和法律部门合作 “对可疑活动进行调查”。换句话该职位可能会涉及对OpenAI自家员工行为的调查。</p><p>&nbsp;</p><p>2023年，OpenAI成为恶意行为者的攻击目标。当时，黑客入侵了其内部消息系统。这一事件之所以能够被曝光，是因为两名知情人士向《纽约时报》泄露了信息。除了黑客组织外，这则招聘启事似乎表明OpenAI在担心来自自己员工的威胁，尽管目前还不清楚OpenAI究竟在提防哪种威胁。</p><p>&nbsp;</p><p></p><h4>苹果数字服务部门裁员约 100 人</h4><p></p><p>&nbsp;</p><p>据知情人士透露，美东时间 8 月 27 日，苹果公司罕见地在其数字服务部门裁员约 100 人，表明苹果公司正在进行业务重心的战略调整。知情人士称，该公司通知了受影响的员工，这些员工分别在苹果互联网软件与服务高级副总裁库伊（Eddy Cue）所负责的的服务部门的几个不同团队工作。</p><p>&nbsp;</p><p>据称，这些员工被告知，在被解雇之前，他们有 60 天的时间在苹果内部找到另一份工作。由于一些员工同时在多个团队工作，因此苹果其他业务部门也受到了间接影响。此次裁员包括一些工程师职位，其中最大的裁员对象是负责 Apple Books 应用程序和 Apple Bookstore 的团队。其他服务团队也在裁员，包括运营 Apple News 的团队。</p><p>&nbsp;</p><p></p><h4>IBM 关闭中国研发部门，涉及员工数量超过 1000 人</h4><p></p><p>&nbsp;</p><p>8 月 26 日，IBM 中国方面确认，IBM 将彻底关闭中国研发部门，涉及员工数量超过 1000 人。、IBM 中国在声明中称：“IBM 会根据需要调整运营，为客户提供最佳服务，这些变化不会影响我们为大中华区客户提供支持的能力。”</p><p>&nbsp;</p><p>声明还提到，中国企业，尤其是民营企业，越来越重视抓住混合云和人工智能技术带来的机遇，而 IBM 在中国的本地战略重点则是利用我们在技术和咨询方面的丰富经验，组建具备相应技能的团队，帮助中国客户共创符合他们需求的解决方案。</p><p>&nbsp;</p><p>IBM 强调未来将转向服务中国的民营企业以及部分在中国的跨国企业，但据第一财经记者了解，金融、能源等关键领域的大型国企才是 IBM 过去最重要的大客户。</p><p>&nbsp;</p><p></p><h4>澳大利亚新规：打工人下班后可不理老板，违者被罚超45万+</h4><p></p><p>&nbsp;</p><p>8月26日消息，据国外媒体报道称，澳大利亚通过了一项法律，员工可以在工作时间外不理会他们的老板。该法律规定，雇主仍然可以在下班后与员工联系，但员工现在有权不在工作时间以外回复，除非拒绝是无理的。这意味着员工可以拒绝监听、阅读或回复来自雇主或第三方（如客户）的联系信息。</p><p>&nbsp;</p><p>同时，澳大利亚“公平工作委员会（FWC）”将决定员工的拒绝是否合理，且必须考虑到员工的角色、联系的原因、方式等诸多因素。如果有企业违反上述法规，公司可能会被罚款高达超45万元。若员工提出的拒绝不合理，FWC也可以命令员工对雇主作出回应，若违反此类命令，可能会导致员工被罚款高达超9万元。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>大模型一周大事</h2><p></p><p>&nbsp;</p><p></p><h3>大模型发布</h3><p></p><p>&nbsp;</p><p></p><h4>黄仁勋预言步入现实，谷歌展示实时游戏生成 AI 模型 GameNGen</h4><p></p><p>&nbsp;</p><p>本周来自谷歌公司和特拉维夫大学的研究人员发表了一篇名为《Diffusion 模型是实时游戏引擎》的论文，介绍了计算机历史上第一个完全由神经网络模型支持的游戏引擎 GameNGen。</p><p>&nbsp;</p><p>研究人员在论文中写道：“GameNGen 是游戏引擎新范式的部分概念验证——游戏将会变成神经模型的权重，而不是代码行。”GameNGen 模型可以做到：使用 AI 生成模型，根据玩家的动作和反应，实时演算和生成游戏画面。</p><p>&nbsp;</p><p>英伟达高级研究经理&amp;具身智能集团主管 Jim Fan 博士在社交媒体上评论称，GameNGen 更像是一个神经辐射场（NeRF），而不是一个视频生成模型。神经辐射场通过从不同角度拍摄场景的图像，从而生成场景的 3D 展示。但这也意味着模型不具备泛化能力，无法“想象”新的场景。这也是 GameNGen 与 Sora 的不同点：它无法生成新的场景或交互机制。</p><p>&nbsp;</p><p>由 AI 渲染来进行实时游戏并不是一个全新的想法。在今年 3 月发布最新一代 Blackwell 架构芯片时，英伟达 CEO 黄仁勋就曾预言，大概在 5-10 年内就能看到完全由 AI 生成的游戏。</p><p>&nbsp;</p><p></p><h4>元象推出国内首个基于物理的3D动作生成模型MotionGen</h4><p></p><p>&nbsp;</p><p>深圳元象信息科技推出的MotionGen模型是中国3D AIGC领域的重大突破，通过融合大模型、物理仿真和强化学习等算法，实现用户通过简单文本指令快速生成逼真、流畅的3D动作。该模型降低了3D内容制作门槛，提高创作自由度和效率，对动画、游戏、电影和虚拟现实行业具有重要意义。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fb/fb9c243ea911d96d47eb701e9b2a5d32.gif\" /></p><p></p><p>&nbsp;</p><p></p><h4>RTX3090可跑，360AI团队开源视频模型FancyVideo</h4><p></p><p>&nbsp;</p><p>8月26日消息，360AI团队宣布他们的开源视频模型FancyVideo正式发布。此模型为想要改善视频处理性能的开发者与研究人员带来了巨大的便利。值得注意的是，这个模型在高端显卡RTX3090上运行良好，吸引了诸多关注，尤其是视频创作者和AI技术爱好者的热情。</p><p>&nbsp;</p><p>FancyVideo作为一个开源模型，提供了一系列强大的功能，包括高效的视频生成与编辑能力。360AI团队致力于将最新的深度学习技术应用于视频内容创作，进一步推动了视频生成技术的发展。FancyVideo的开放性意味着任何人都可以调试和优化模型，这对开发者群体是一个重要的福音。在多次的内测中，用户们发现该模型在处理高质量视频时的表现不但稳定，并且效率极高，这使得创作者们能够在短时间内完成大型项目，无论是影视制作还是短视频创作。</p><p></p><h4>&nbsp;</h4><p></p><p></p><h4>“云知声”正式发布山海多模态大模型</h4><p></p><p>&nbsp;</p><p>8月26日消息，“云知声”宣布正式推出山海多模态大模型。据介绍，山海多模态大模型通过整合跨模态信息，山海多模态大模型可接收文本、音频、图像等多种形式作为输入，并实时生成文本、音频和图像的任意组合输出。基于多模态交互能力，可根据不同的场景和需求，模拟出各种人物性格和对话风格。</p><p>&nbsp;</p><p></p><h4>AI 图像生成公司 Midjourney 宣布进军硬件领域，苹果前硬件经理加盟</h4><p></p><p>&nbsp;</p><p>知名 AI 图像生成公司 Midjourney 宣布进入硬件领域，成立新硬件部门，由具有丰富硬件经验的创始人 David Holz 和前苹果硬件经理 Ahmad Abbas 领导。尽管未透露具体产品类型，Midjourney 表示有多个项目正在进行，暗示存在多种可能性。目前，公众期待 Midjourney 的新硬件产品，但具体发布时间尚未明确。</p><p>&nbsp;</p><p></p><h3>企业应用</h3><p></p><p>&nbsp;</p><p>8 月 27 日，阿里智能信息事业群旗下产品夸克 PC 端产品上新，升级 AI 搜索、AI 写作、AI PPT、AI 文件总结等一系列功能，可一站式完成信息检索、创作和总结。此外，夸克 AI 回答的首字出现速度和吐字速度领先于行业，可瞬时给出精准答案。三栏式的界面设计能更清晰地展现图文、视频等生成式回答和网页，便于核心信息浏览。8 月 27 日，苹果苹果正式宣布将于北京时间 9 月 10 日凌晨 1 点在加利福尼亚州库比蒂诺的总部举办特别活动，主题为“高光时刻（It 's Glowtime）”。此次发布会预计将推出最新款 iPhone、Watch 和 AirPods。即将发布的 iPhone 16 两款 Pro 系列的手机将拥有更大的屏幕，并拥有新的相机功能，比如新增的“拍照按钮”。但这场发布会的焦点预计将是 Apple Intelligence，这套人工智能工具将整合到所有新款 iPhone 中。谷歌研究人员开发了一个名为 GameNGen 的神经网络驱动游戏引擎，该引擎能够实时生成经典射击游戏《毁灭战士》的画面，无需传统游戏引擎的组件。该技术利用扩散模型实时预测每一帧画面，先通过 RL 智能体学习游戏并记录过程，再训练模型生成画面。此技术或能实现人工智能即时创建游戏，并提供个性化服务。美年健康联合华为云和润达医疗研发的国内首款健康管理 AI 机器人”健康小美“正式上线，提供个性化全生命周期健康管理服务，标志着美年健康在数智化健康管理领域迈出关键一步。</p>",
    "publish_time": "2024-09-02 14:56:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "FCon 优秀出品人&明星讲师名单出炉，大模型、智能体、智能化运营等话题最受欢迎",
    "url": "https://www.infoq.cn/article/FmBDNQ3vU31i4PSb5UFE",
    "summary": "<p>8 月 16 日 -17 日，由极客邦旗下 InfoQ 中国主办的<a href=\"https://fcon.infoq.cn/2024/shanghai?utm_source=infoq&amp;utm_medium=conference\">FCon全球金融科技大会</a>\"在上海成功举办。本次大会以“科技驱动，智启未来——激发数字金融内生力”为主题，由中国信通院铸基计划作为官方合作机构，在“十四五”即将收官之际，本届大会特别邀请了行业内各领域专家，共同审视当下的数字化转型现状，为数字化大考“查缺补漏”。同时，紧跟当下技术热点，众多企业也分享了近一年多以来金融行业在 AI 大模型方面的落地实践成果。</p><p></p><p>此次会议邀请 60 余位来自多个银行、保险、证券和金融科技企业等机构的专家，涵盖龙盈智达、平安证券、度小满金融、汇丰科技、工商银行、交通银行、工银科技、华夏银行、中信银行、广发银行、北京银行、苏州银行、渤海银行、富滇银行、中原银行、新疆银行、中邮消费金融、平安壹钱包、众安银行、eBay、人保寿险、太平洋保险、平安产险、瑞士再保险、蚂蚁集团、申万宏源证券、华泰证券、中泰证券、天弘基金、浙里信征信、滴灌通、文因互联、新希望金融科技、嘉银科技、中关村科金、数势科技、壹芯源、PingCAP、澜码科技、浙江大应科技等，大会现场听众累计超过 500 人次。</p><p></p><h3>主题演讲</h3><p></p><p></p><p>在 8 月 16 日上午主论坛环节，中国信通院泰尔终端实验室数字生态发展部主任王景尧围绕金融“五篇大文章”及数字化成熟度路径进行了拆解；龙盈智达副总裁宫小奕介绍了龙盈智达如何以场景驱动业技融合，实现自身在金融科技领域的实践和成果；平安证券公司首席信息官张朝晖分享了平安证券在数字化转型过程中，其技术部门如何通过 “微卡片”组装式无边界应用开发模式改变传统研发模式难以满足数字化需求的困局；度小满金融技术委员会执行主席、数据智能应用部总经理杨青分享了人工智能及新兴的生成式 AI 技术如何助力书写数字金融大文章；汇丰科技创新实验室量子和 AI 科学家朱兵则介绍了金融行业在 AI 大模型和量子计算技术背景下面临的新兴技术风险。</p><p></p><p>详细报道见：<a href=\"http://mp.weixin.qq.com/s?__biz=MzkzMzQzNjQ5Mw==&amp;mid=2247492380&amp;idx=1&amp;sn=0699c5699663064fa077727e96c38096&amp;chksm=c24e2e3ef539a72896745ba535af985fb2d9d5663c9cf2c4af035f99eafb210aa24f590878e1&amp;scene=21#wechat_redirect\">2024 FCon 全球金融科技大会精彩回顾，汇集前沿视野与落地实践</a>\"</p><p></p><p>本次 FCon 大会所有可公开 PPT 均已上传到官网，扫码关注 InfoQ 数字化经纬公众号，回复关键词“PPT”即可获取。&gt;&gt;&gt;</p><p><img src=\"https://static001.geekbang.org/infoq/b5/b5607ba5c7eb641a433c5a3baf052f84.png\" /></p><p></p><h3>热门专场 TOP 3</h3><p></p><p></p><h5>金融大模型应用实践和效益闭环</h5><p></p><p></p><p>作为本次大会最热门的专题， 该专题旨在分享大模型在银行、证券、保险等金融场景的落地实践和路径展示，以及大模型在规模化落地应用过程中如何应对算力、模型部署和经济效益闭环等挑战。专题出品人是北京银行软件开发中心副总经理代铁，与此同时还邀请了工银科技技术总监孙科伟、蚂蚁财富投研支小助技术负责人纪韩、新希望金融科技风险科学部 AI 中心总经理王小东、交通银行软件开发中心二级金融科技专家仇钧、嘉银科技技术中心人工智能经理姜睿思、中关村科金资深 AI 产品总监曹阳共 7 位嘉宾同台分享。</p><p><img src=\"https://static001.geekbang.org/infoq/46/464ca46ead92c2fceace2ed4084369ff.jpeg\" /></p><p></p><h5>前沿金融科技探索与应用</h5><p></p><p></p><p>该专题旨在分享前沿金融科技在金融行业的探索和应用，包括数字人民币的应用现状和实践探索等话题。专题出品人是文因互联董事长、创始人鲍捷博士，与此同时还邀请了中国人民人寿保险信息科技部业务主管王贝贝、苏州银行网络金融部高级产品经理金一松、中邮消费金融科技发展部 AI 算法专家陈盛福、度小满金融数据智能部计算机视觉方向负责人万阳春共 5 位嘉宾同台分享。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/97/97ab01e7681d72e7fc8637355722628e.jpeg\" /></p><p></p><h5>金融数字化管理和运营实践</h5><p></p><p>该</p><p>专题旨在分享探讨银行、证券、保险等金融机构如何通过 RPA、数字人等数字化技术的落地应用，提升精细化管理能力、运营效率和用户体验，降低业务风险的同时，实现管理和运营层面的降本增效。专题出品人是 Aloudata 大应科技创始人 &amp;CEO 周卫林，邀请了度小满数据智能经营模型负责人李东晨、申万宏源证券信息技术开发总部大数据平台专家傅江如、某股份制银行数据库专家王辉、平安产险客户大数据团队平台组负责人洪广智、平安壹钱包大数据研发部算法负责人王永合共 5 位嘉宾同台分享。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b1/b146adbe06e4d489d0a030819f3fbe09.jpeg\" /></p><p></p><h3>优秀出品人</h3><p></p><p>本次大会共有 12 位专题出品人，他们都是各自领域的权威专家。出品人的主要任务是确保各自专题的分享内容质量，包括在前期阶段对议题进行深入的讨论和打磨，以及对演讲材料进行严格的审核。经过评选，最终有 4 位专题出品人因其对本次大会内容策划的杰出贡献而被授予“优秀出品人”的称号，他们分别是：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e6/e694c55de3577890f34f8163f4b10ab3.png\" /></p><p></p><h3>明星讲师</h3><p></p><p></p><p>FCon 大会讲师的选拔既包含组委会定向邀请，也开放给公众提交演讲主题。为了确保演讲内容的质量，所有提交的议题都必须符合六大标准：明确的观点、以实践为基础、深入且有见地的分享、良好的专业声誉、禁止任何形式的广告、以及确保听众能从中获得实质性的收获。要从众多杰出的演讲者中脱颖而出，获得“明星讲师”称号，演讲者不仅需要在大会筹备期积极配合组委会反复打磨议题和 PPT，提供既有深度又实用的分享内容，还需要在大会现场展现出色的演讲表现，并获得至少 90% 的听众满意度（在满意度测评中，听众对讲师的评价分为“非常满意”、“满意”、“一般”和“不满意”四个等级，听众满意度指“非常满意”＋“满意”评价在收到的所有评价中的占比）。经过严格的评选，以下演讲者荣获“明星讲师”的荣誉：</p><p><img src=\"https://static001.geekbang.org/infoq/ff/ffc5b0527be279833e9f5747a4a19684.png\" /></p><p></p><p>张朝晖 平安证券 / 信息技术中心首席信息官：《打破旧世界，重组新世界——平安证券数字化利器微卡片平台实践分享》陈盛福 中邮消费金融 / 科技发展部 AI 算法专家：《消费金融风控新防线：智能反欺诈技术体系全解析》李东晨 度小满 / 数据智能经营模型负责人：《基于因果推断的智能经营模型体系》李涛 富滇银行股份有限公司 / 数字金融中心副主任：《数智化时代商业银行运营营销的“坑”与“路”》纪韩 蚂蚁集团 / 蚂蚁财富投研支小助技术负责人：《多智能体协同范式在金融产业中的应用实践》王小东 新希望金融科技 / 风险科学部 AI 中心总经理：《大模型下的多模态智能风控落地实践》王彦博 华夏银行 / 信息科技部副总经理：《金融数字营销模型创新思考与实践》毕成功 华泰证券 /FICC 平台架构团队负责人：《事件驱动型微服务架构的实践》仇钧 交通银行 / 软件开发中心二级金融科技专家：《金融业大模型平台搭建及应用实践》陈利生 中邮消费金融 / 科技发展部 / 架构团队负责人：《数智化视角下金融企业的技术架构融合之路》魏瑶 eBay /Payments&amp;Risk 高级技术专家：《eBay 支付风控智能数据标注实践：提效数据标注，加速模型生产化》</p><p></p><p>我们衷心感谢每一位参与 FCon 的出品人与讲师的精彩分享与辛勤付出，正是他们的努力，FCon 才能为听众带来无数精彩的内容与深刻的见解。</p><p></p><p>至此，今年 InfoQ 中国已圆满落幕 5 场技术盛会，随后还将于 10 月 18 -19 日在上海举办 QCon 全球软件开发大会 ，覆盖前后端 / 算法工程师、技术管理者、创业者、投资人等泛开发者群体，内容涵盖当下热点（AI Agent、AI Infra、RAG 等）和传统经典（架构、稳定性、云原生等），侧重实操性和可借鉴性。大会 8 折优惠最后1天，单张门票立省 960 元（原价 4800 元）。如您感兴趣，可扫描下方二维码查看详情咨询。</p><p></p><p>期待下一场大会再见！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c5/c5f6dacc4912d6c0742b83d22368fd07.jpeg\" /></p><p></p>",
    "publish_time": "2024-09-02 15:40:19",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "万字长文解析“新质金融”：新时代的银行高质量转型",
    "url": "https://www.infoq.cn/article/uwmS3q3llKtVqTIvK161",
    "summary": "<p>2016 年，国际上有了“金融科技”的定义，基于移动互联风暴的银行数字化转型浪潮也是跌宕了一波。如今，互联网的理念冲击已经逐渐吸收殆尽，从 2020 年“十四五规划”开始的国家级、社会级、具有中国自身特色的“数字化”正在为银行数字化提供新的方向指引，从数字中国、数字经济到数字“千行百业”以及数字金融，“数字”叙事语境逐渐统一，而“新质生产力”的提出，则在统一语境下，为今后一段时间的银行数字化提供了新的基调，笔者试将其称之为面向“新质金融”的“高质量转型”。这是一个“上纲上线”的理念，银行目前的经营管理正需要“上纲上线”，以“国”为“纲”，以“民”为“线”，这是银行全面深化自身改革需要秉持的思路。笔者拟通过本文渐次解释这个思路。</p><p></p><h2>一、关于“新时代”的解释</h2><p></p><p></p><p>二十届三中全会通过的《中共中央关于进一步全面深化改革、推进中国式现代化的决定》（以下简称《决定》）指出，推动改革的需要正视三个“面对”，“面对纷繁复杂的国际国内形势，面对新一轮科技革命和产业变革，面对人民群众新期待”。这三个“面对”正是理解“新时代”的出发点，而其中第二个“面对”，“新一轮科技革命和产业变革”是所有企业面对的共性挑战、共性机遇，这个“面对”自然会形成第三个“面对”中的“新期待”，从而带动新的业务形态、银企关系、银企协作的转型，通过转型去破解第一个“面对”。</p><p></p><p>“新时代”一定是让所有人都能感觉到生活方式、工作方式有所变化，乃至深刻变化的，如此才是获得感的“新时代”。科技革命和产业变革，始终都在进行，时常“柳暗花明又一村”，似有所盼又似不期而遇的“大语言模型”就是如此，数字化基础设施的广泛建设也会带来难以完全预料的业态转换，这是技术发展的自然趋势，政策的导向也在对其“加速”，会影响到经济中的每一个参与者。</p><p></p><p>银行正在迎接新的服务模式变化，而这些新的变化，既有作为“纲”的国家指引，也有作为“线”的客户牵引，多家银行竞相推出的“司库”系统服务就是其中的典型代表，有国家对央国企提升管理精细化能力的指导意见之作用，也有央国企提升运营能力、降本增效的内在诉求，更是央国企数字化进程带动的银企关系、银企协作模式的转型，需要进一步配套的则是从国家监管政策到银行自身服务能力的全面跟进，保持管理政策和微观经营取向的一致性。</p><p></p><p>银行虽是提供金融服务的企业，但金融服务的供给也需要依赖工具，工具的形式则具有时代性，数字时代的工具就是数字工具，银行的业务通过系统提供的比比皆是，“数字金融”本身也有这个要求，所以，为“人民群众”提供系统服务就是银行顺应时代发展该做的事情，这也是“新时代”的特征，银行的主业即包括以“数字工具”提供的“数字金融”服务，不以“数字工具”提供服务，又何谈对“数据要素”的深度利用。</p><p></p><p>较之对企业客户的服务，对个人客户的服务早就进入了“数字工具”时代，几乎 90% 以上的个人金融服务都在通过软件向几乎全年龄段的所有客户提供，银行早就是个“金融软件服务供应商”了。这是在移动互联网发展阶段就已经形成的“新业态”，伴随科技革命的进程，线上渠道能力的持续增强，以后发展得只会更深入，不应“堵”，更宜“疏”，不应“避”，更宜“进”，这是“新质生产力”发展的必然要求，是产业变革，也是“人民群众新期待”。</p><p></p><p>《决定》中的“新时代”，更有自十八届三中全会推动“全面深化改革”以来形成的众多“新思想、新观点、新论断”，需要银行全面、系统理解之后，再来确定经营方向，银行的经营管理需要“守正创新”，“守”国策、民需、法规之“正”，“创”执行能力、因地制宜之“新”，这是银行改革和发展的基本要求。按照《决定》的部署，“重大改革落实情况纳入监督检查和巡视巡察内容”，改革任务应在 2029 年完成。“新时代”的工作任务是重要而紧迫的，方向更是不容有错的。</p><p></p><h2>二、关于“高质量转型”的解释</h2><p></p><p></p><h4>（一）“质量”本义视角的解释</h4><p></p><p></p><p>“质量”本义即为满足人们某种需要的特性，延伸可以解释为，符合预期、可用好用。</p><p></p><p>1.&nbsp;符合国家宏观治理预期。自去年中央金融工作会议开始，对金融监管体系和银行工作方向都提出了重大、根本性的转变要求，集中于解决政治站位、资产结构、风险控制问题。提出“中国特色金融发展之路”，树立“政治性、人民性”的站位，按照“八个坚持”的要求，做好“五篇大文章”，处理好功能性和营利性的关系，形成分工协作的金融机构体系，做优做强而非盲目做大金融机构。</p><p></p><p>今年，金监总局下发关于“五篇大文章”落实的具体指导意见，对金融机构按分类提出分工要求；人民银行领导在陆家嘴会议上，也谈到摒弃“规模情结”，反对非理性竞争。7 月底，政治局会议也对各行业提出自律要求，倡导“反内卷”，减轻基层工作负担。近 十个月以来，对银行如何树立正确的经营观、业绩观，提出了密集的政策指导，旨在弥补市场的失灵之处。</p><p></p><p>银行数字化是为银行业务服务的，银行业务是为国家、社会、群众服务的，如此大力度的经营方向调整也必然反映在对数字化的指导思路上。《决定》在“健全推动经济高质量发展体制机制”分论部分（以下简称“高质量发展分论”），将“高质量发展”定位成“全面建设社会主义现代化国家的首要任务”，要求“健全因地制宜发展新质生产力体制机制”，“支持企业用数智技术、绿色技术改造提升传统产业”。</p><p></p><p>对于银行而言，其自身的数字化，在“数字金融”这篇大文章中已有方向性要求。如今，“五篇大文章”也正式写入了《决定》，这意味着“高质量发展分论”和“健全宏观经济治理体系”分论（以下简称“宏观治理分论”）都对银行数字化提出了要求。银行也应当思考在年度战略以及下一个“五年计划”中，如何做好银行的“定位”和“治理”，将“高质量发展”定义成银行经营的首要任务，如何通过“推动劳动者、劳动资料、劳动对象优化组合和更新跃升，催生新产业、新模式、新动能”，如何“用数智技术、绿色技术改造提升”银行机构，做符合国家宏观治理预期的转型。</p><p></p><p>2.&nbsp;符合人民群众微观服务预期。人民群众对金融服务的需求具体是什么？从抽象的角度看，及时获取所需资金、应时流通现有资金、合理经营闲置资金，这就是对金融服务的基本诉求，但是，这些基本诉求反映到不同的个体、亚群体范围、区域性范围、行业性范围上，都会有不同的表现，或聚类、或分散，不同情境下亦会有所差别，搜集、归类、分析、满足这些诉求，才是金融服务的专业性所在，这既是需要数字化支持的工作，也是需要用“心”支持的工作。金融服务最重要的专业性应是对客户、对环境的充分理解。</p><p></p><p>对很多企业而言，营销数字化的成功应是将“4C”理论辅之以数字化手段的成功，而非流量的成功。银行也恰恰是这样一个企业，尤其是还有很多话术上的合规性要求。以客户需求为先、以客户可承受的支出为先、以客户的方便为先，最后，以与客户的双向沟通为先，这些是通过“4C”理论强调的营销基本理念，以“营”为“先”，通过线上、线下渠道“方便”客户，通过发展人机结合的双向“沟通”更多了解“需求”；通过数字化、精细化管理，控制资债结构、降低营销成本、提高运营效率，持续应对“低息差”，合理控制服务“价格”；“营”与“销”适度分离，发挥好银行机构的组织、人员优势，与数字化结合，来提升“营”的效果。</p><p>没有“营”，只有“销”，或者只为了“销”而“营”，就谈不上客户的满足，只有指标的满足，数字化的应用也只能是用错了方向。数字化并非短效的“强心剂”，而是能力的长期、逐步放大与增强。</p><p></p><p>银行的专业性应当体现在对经济、行业、客户的广泛理解与洞察上，这不仅仅是数据性的画像，更需要“人”的接触、“心”的参与，对客户的了解不能仅停留在客户经理、银行柜员分散的掌握上，对行业、经济的了解不能仅停留在管理层的非体系化掌握上，银行本应是一个巨大的知识库，是一个其他行业，包括咨询行业都很难比肩的知识库。</p><p></p><p>数字经济本就是知识经济，银行本就应该是知识企业，在这个转型时期，银行更应该着手构建“知识顾问”这个人设，如果只是资源分配，那就没有不同的积累，钱的本质都是一样的。没有不同的积累，就不会有差异化的禀赋，没有差异化的禀赋，就容易只拼资源的消耗，如今消耗战也很难打了，该打什么呢？该提供些什么人民群众需要，而又能有所差异的服务呢？除了“见识”还有什么是人们必然会有不同理解的东西呢？</p><p>金融服务应该需要“知识增加值”了，互联网貌似“拿走”了信息，貌似有技术优势，其实对信息的理解尚未拿走，也拿不走，对企业管理和传统行业的研究也仍不成熟，所以，银行依然有自己独特的优势，而非只是望着数据平台兴叹，不要因为别人的长处而忘记自己的长处，凡事皆有起伏。其实银行与互联网之间的竞争基本上已经不存在了，笔者方才的阐述只是为了强调“知识”的重要。信息的传递需要的积累不多，但对信息的解读需要的积累却很多。银行需要专下心、静下气来，重新变得专业起来，重新从踏踏实实接触客户、积累知识做起，认真恢复个四五年。</p><p></p><h4>（二）“质量”实现视角的解释</h4><p></p><p>希望实现“高质量”，通常也要有“高能力”，尤其是规划、执行能力。</p><p></p><p>《决定》总结十八届三中全会以来十年左右的工作，在“许多领域实现历史性变革、系统性重塑、整体性重构”，银行也应当从这个定位，也就是“历史性变革、系统性重塑、整体性重构”的标准回看过去十年的发展历程，“历史性变革”需要的是长期主义的定位能力，“系统性重塑”需要的是具备全局视角的顶层设计能力，“整体性重构”则需要坚韧不拔的落地执行能力。过去十年没做到的，估计未来五年必须做到。</p><p></p><p>1. “高质量转型”应有对银行发展方向的长期定位。就业务而言，全国性银行是“主力军”、“压舱石”，要全面发展，其中股份制银行会有些差异化；中小银行则是区域定位、区位特色。但是如何符合这个定位去规划自己的长期方向则是很多银行面临的挑战，之前市场争夺过于激烈，银行多少都有些摇摆不定，如今市场的规范性要求在提高，分工意识在增强，风险较高、规模不合适的银行也会逐渐有调整，未来的市场，很有可能是以全国性银行加万亿级区域性银行为主要经营机构的市场格局，逐渐会重新调整机构定位。</p><p></p><p>新晋升的万亿级区域性银行如何定位和治理自己，将是一个“历史性”考验。银行不是一个快车道行业，更不是弯道超车行业，也不是大了就能解决一切问题的行业，而是真真正正“稳中求进”、“守正创新”的行业，是基本功不扎实、定位不正确，直道跑不好都能翻车的行业。没有合理的定位，数字化也解决不了问题；离开了笔者上文提到的专业性能力建设，也很难产生合理的定位，定位不是从银行自己脑袋里蹦出来的，是从国家的治理要求和群众的服务需求中来的。</p><p></p><p>2.&nbsp;“高质量转型”应有全局视角的设计能力。“一盘棋”、“系统观念”这些原则性要求经常出现在政策中，也经常出现在银行的战略中，如果没出现，真的需要自己检查下。“系统观念”是对管理层的基本素质要求，其实对基层也一样，二者只是在能看到的“系统”范围方面有差别而已。</p><p></p><p>笔者一贯的观点，企业架构、业务架构就是实践“系统观念”的可行之道，也是实现业务和技术深度融合的能行之道。但是，很少有银行认识到，架构思维、架构实践也是全面理解客户所执行的数字化转型、寻找数字转型商机、提供“知识增加值”的机会。在笔者看来，很多银行都错过了在过去十年中，全面提升自己的数字化转型操盘能力，并将其转化为新的“知识增加值”，以此来“介入”企业客户数字化转型，将银行价值链嵌入客户价值链，实现高级银企协作的机会。这并非只是大型银行才有的机会，大多数银行的数字化支出能力、IT 队伍规模都是远超过其他行业同级别企业的，但并未对操盘能力进行充分的提升和知识化。</p><p></p><p>对数字化的不完整理解、对复杂性的驾驭能力不足，仅局限于业务需求实现，使投入数字化工作的人员、时间、资金、技术都没能发挥出最大价值，也就是对人的思维提升的价值、对企业的领导力提升的价值。如今，对银行的定位和治理要求高于规模和营利，正是潜心理解、静心规划、专心执行的时期，忘掉竞争，忘掉营销，专注服务，专注能力，对一些银行而言，未来五年确实也是机构调整的“关键时期”。</p><p></p><p>3.&nbsp;“高质量转型”应有坚韧不拔的落地执行能力。从来没有一帆风顺的企业转型，也从来没有仅凭“钞能力”就可以解决的管理问题，更没有能照抄照搬的数字化转型历程，即便是国有大行重金打造的企业级工程，也是步履维艰、历尽磨难的，能力是从“难”中来，简单易行的数字化只能带来简单易超的数字能力。数字实力源自对业务提升的不懈追求和业务提升与数字手段的长期磨合，即便马斯克的“五步工作法”也是如此。</p><p>基础都是不轻的，改变都是不易的，融合只能是业技双向奔赴的，不改业务就抄不得系统，抄了也是白抄，而改了终究也只是个模仿，抄不出特色。数字化最需要的还是创造力，而创造力来自于什么？不正是来自于遇到的困难、遇到的客户吗？把核心问题交给外部的优秀实践，怎么能做出自己的创新呢？</p><p></p><p>金融并非“黑科技”类的技术原创行业，需要的不是爆炸性的技术创造力，而是基于对客户的长期钻研，持续不断、小步迭代地改善客户认知和金融服务过程的能力，这些能力的具备并不区分大小行，主要还是自己的内心追求而已，一个小零售店也一样会对自己的主顾很用心，也会力求自己的特色。</p><p></p><p>数字化最后展现的是金融服务，金融服务是多样性的，历史证明，大企业的发展从也来也不会排斥小企业的存在，总有特色可以供小企业选择和成全，需要的是自己用“心”，用好有限的资源，用好遇到的“难”。笔者上文讲的很多银行错过的十年也是在此，过于关注增长、被“规模”拖累的十年。</p><p></p><h4>（三）“质量”表现视角的解释</h4><p></p><p>实现“高质量转型”的银行，其表现应体现在对国家政策和群众需求的深入理解上、对业务持续改进以及风控与合规能力持续增强上、对技术能力与生态的综合构建上，以及对数字领导力的展现上。</p><p></p><p>1. 对国家政策和群众需求的深入理解。从中央金融工作会议到《决定》发布，“五篇大文章”必然是需要各类银行深入学习和贯彻实施的，明年的“十五五”更是重要的方向性政策，从国家政策到地方政策，充分做好研读。学习政策原本就是金融工作的重要一课，从“最初一公里”到“最后一公里”，全面、正确理解政策导向，用“钱”的地方也都写在政策里。</p><p></p><p>按照目前的经济发展需要，也可以通过信贷工具，将确定性的长周期财政支出转换为集中性的信贷支出，从而增加短期需求，并为银行提供相对低风险的信贷投向。群众需求也体现在国家政策中，通过客户接触，结合政策导向，综合把握业务方向。将数字人民币的定向发放、定向使用能力充分发挥起来。</p><p></p><p>最终，对国家政策和群众需求的正确理解，将体现在银行的资产结构上，体现在业务指标的设置上，体现在指标的总体合理化、区域合理化、机构合理化上。从学习中央金融工作会议开始，笔者一直认为，今明两年银行的工作重点就是调整资产结构，这个调整，反映的就是对政策和客户的理解，反映的也是管理层的判断和担当。</p><p></p><p>2.&nbsp;对业务持续改进以及风控与合规能力持续增强。业务改进、风险控制、合规管理是融合在一起的。在推动经济“回升向好”的过程中，结构性、区域性、行业性的风险都有可能“狭路相逢”。业务改进主要是以缩短决策过程，适度降低业务门槛，使资金融通更及时为目标的，毕竟，面对“科技金融”的新业态、新企业、新技术，“普惠金融”的“急难愁盼”，时间本身就是一种需要降低的成本，而政策传导方面，也希望执行带来的反馈更加快速一些。</p><p></p><p>因此，对业务评价、管理模型的微群体化、小区域化、细行业化、快数字化，将是需要基层更多参与的工作，把基层经验本地化总结、本地化提升，并与管理机构总体化风险控制相结合，这是全面提升基层专业性、研究能力的时期，尤其是对“科技金融”、“普惠金融”而言，基层不再只是分散式的“腿”，而要成为分布式的“脑”，不再是泛泛地谈提升能力，而是针对性、特色化、内源式地提升。这两篇大文章的进一步发展，将需要银行投入更多的人力，通过与客户进行深入、持续的接触来把握风险控制，除了更直接的接触、更广阔的信息比较外，别无他法能够有效控制展业之后的风险。</p><p></p><p>数字化能力在安全风险边界以外的控制能力是非常有限的，数字化的本质毕竟还是提升识别效率，而不是放大风险边界。合规也是当前极为重要的工作，近日金监总局关于普惠业务“尽职免责”的规定详细列举了“应免”、“可免”、“特殊”、“不免”等情形，银行应当从职业保护、对员工负责的角度，再度提升对合规作用的认识。将业务改进、风险控制、合规保护进行融合式设计、滚筒式发展，提升业务标准化，并将其有效转化为萃取知识、识别风险、保护从业者的数字化能力。将金融业务与科技业务并行开展，对于有金融科技公司的银行，应当确定好金融科技公司的定位，形成集团优势，在对客户服务方面展现出更强的综合性、立体性，并为立体化金融服务的风控与合规探索出应有的模式。</p><p></p><p>3.&nbsp;对技术能力与生态的综合构建。无论钱多钱少，银行都不可能自己包办数字化需要的完整技术栈，数字化转型是各类技术综合作用的演进结果，银行需要根据自己的资源情况选择自研方向和技术生态构建模式。</p><p>“高质量转型”的银行，其表现首先在总体架构设计和控制能力上。没有设计和控制能力，就很难以自身特色为发展目标掌控自己的演进。银行可以不具备完整的实现能力，但最好具备完整的设计能力，尤其是掌握将业务战略经过业务架构分解到 IT 架构的能力，从而把控住支持业务战略的 IT 战略，这是管理层必须具备的基本能力，也是管理层具备“系统观念”的基本证明。</p><p></p><p>目前很多银行仍旧不具备整体的业务架构、数据架构、应用架构管理能力，这与“高质量转型”的能力要求、银行付出的数字化代价都是不相符的，其中的业务架构并非技术问题，而是银行的整体业务视图，是显性化的“一盘棋”。有些银行在开展大规模重构工作的时候，依然错过了对架构能力的实质性提升，这是非常可惜的。</p><p></p><p>其次，更灵活的实现能力体系。数字化快速实现能力向一线分支机构延展而非都集中在总部机构将是需要考虑的一个方向，改变开发体系，低零代码与全代码搭配、分散开发与集中开发搭配，支持实现业务人员深度参与、能够自己转起来的数字化，当然，这也不仅是为了数字化，“科技金融”、“普惠金融”的发展，基层对数字工具的运用能力、自我实现能力，也是成为分布式的“脑”所需要的。数字化转型要对银行实现能力的布局进行灵活调整，而不只是关注系统的集中建设，这种模式对架构的整体管理能力也有更高、更灵活的要求，尚不具备架构管控能力的银行可能又需要面对新的挑战了，有时一步赶不上就容易出现步步赶不上的状态，就像这些年一直在讨论的数据治理。</p><p></p><p>再次，更为出色的花钱能力。很多银行都认为搞企业架构是费钱的，搞不起，实际上企业架构常用在规划方面，是盘算如何花钱更合理的，但由于缺少总体架构能力、架构思维，很多银行在如何花钱方面的能力也亟需合适的契机进行提升。</p><p></p><p>4.&nbsp;数字领导力的展现。《决定》中提出了“加快构建中国话语和中国叙事体系”的要求，国家尚且如此重视“叙事”能力，作为很注重形象的企业，银行则始终在如何“叙事”方面把握不好。互联网、华为、美的等企业先后都有很好的数字化“叙事”，贡献了很多畅销书籍和观点理念，影响了诸多企业的数字化发展，但作为信息化时间几乎最久、数字化支出能力又屈指可数的行业，银行数字化“叙事”的影响力却与其实际能力极不相符，而且银行特有的“矜持”，也导致“叙事”本身几乎没有多大外溢的影响力。</p><p></p><p>如果站在全行业的角度看，银行所形成的一些非常有中国特色的数字化转型实践经验，几乎是被其“叙事”能力“掩埋”了，没有帮助到更多行业。如果实现了“高质量转型”，其表现之一，就是具有能够形成企业数字领导力的“叙事”能力。银行也需要多讲如何助力客户取得成功、取得发展的“故事”，改变目前“叙事”中常见的，业务“叙事”偏大偏散、技术“叙事”不新不旧的状态。</p><p></p><p>综上，本节中，笔者从“高质量转型”的本义，即符合国家宏观治理预期、符合人民群众微观服务预期；“高质量转型”的实现，即长期主义的定位能力、全局视角的设计能力、坚韧不拔的落地执行能力；“高质量转型”的表现，即对国家政策和群众需求的深入理解（资产结构调整）、对业务持续改进以及风控与合规能力持续增强、对技术能力与生态的综合构建以及对数字领导力的展现等若干方面，综合解释了笔者对“高质量转型”的理解。</p><p></p><h2>三、关于“新质金融”的解释</h2><p></p><p></p><p>三个“面对”阐述的改革背景，《决定》中包含的“新思想、新观点、新论断”，共同构成了银行需要对“新时代”形成的基本理解；“高质量发展”也将是银行转型的“首要任务”，结合起来就是阶段性的银行发展里程碑，“新质金融”，新时代的高质量金融。</p><p></p><p>“新质金融”是充分理解国家政策和人民需求的金融。为此，需要充分构建政策解读能力和知识库体系，政策的解读不仅是宣贯，更应成为银行的一项基本能力，包括解读《决定》、解读“五篇大文章”，除了个人的学习，银行应当有总体的知识库，与业务高度结合的知识库；构建面向客户的知识库体系，将对单个客户、单个企业的观察、分析作为知识而非仅是业务信息，汇聚、萃取成银行知识库，成为未来智能化服务的信息源，这是构建差异化服务能力的基础，没有差异化的知识，就没有差异化的服务，也不会有差异化的智慧银行，数据代表的只是要素方面的差异，知识代表的才是能力方面的差异；面向政策、面向“五篇大文章”、面向金融服务需求建立更为丰富的标签体系和标签转换能力。</p><p></p><p>“新质金融”是“三度合一”的金融。 实现“高质量转型”的银行应当是充分融合线上线下产品与服务供给能力的银行。为此，首先需要将银行业务尽可能线上化，以构建更高效的运营能力、风控能力、合规能力和应对低息差的资债管理能力，毕竟系统最大的特点仍是执行效率远高于人。</p><p></p><p>将人的能力更多释放到线下、释放到客户接触中，在接触中创新，综合数据的“精度”、人的“温度”、知识的“深度”来构建差异化的“三度合一”的产品和服务。业务尽可能线上化，通常意味着系统数量的增多，但是，在“高质量转型”的要求下，系统的集约化设计才是能力的体现，系统数量多，通常会导致维护量大、运行链路长、不安全因素增多、升级难度大、功能碎片化等诸多问题，也意味着会有更多零散的服务商套件组合成的“多国部队”，为了提升 IT 的整体能力，合理控制 IT 成本，也有必要提升设计的整体性。</p><p></p><p>未来银行还将迎来新的渠道升级，三维渠道的到来还将要求银行内部系统表现出更高的一致性，所以，整体能力是不能留给后来者去一并提升的，那属于还债。</p><p></p><p>“新质金融”是由“新质生产力”构建的金融。落实“新质生产力”的关键在于“推动劳动者、劳动资料、劳动对象优化组合和更新跃升”，也即，对人的能力、对工作方法、对业务系统、对数据要素的提升和优化组合，这些都属于“新质生产力”的范畴。而这其中，人的能力和工作方法是最能够被所有员工接触和提升的环节，是全员落实“新质生产力”的重点。</p><p></p><p>笔者前文的介绍中反复提到的知识，也正是对方法、经验的总结，所以，落实“新质生产力”的过程中，新技术的应用固然重要，而持续培养员工适合数字时代的思维模式，也就是全局性结构化思维；持续积累员工在工作中的创造，也就是知识，是同等重要的，没有这些思维和知识，新技术能被用到什么程度是令人怀疑的，无法被有效运用的新技术，只能成为“新质装饰力”，无法成为有效的生产力。中小银行的“新质生产力”建设尤其可以考虑这一点。在国家政策的大背景下，创造自己对数字时代、数字客户、数字金融的理解，是银行“新质生产力”发展演进的基本动力，这一点与银行规模无关。</p><p></p><p>“新质金融”是银行价值链重塑后的金融。银行的价值链一直在重塑，“高质量转型”根据其“新时代”背景，也会完成对价值链的重塑，笔者曾针对“五篇大文章”的研读，提出了数字银行的新价值链，从笔者的视角看，本轮价值链重塑应该主要关注的是客户洞察能力、产品整合设计能力、客户交流能力、政策解读能力、知识管理能力、风险控制能力、合法合规能力、价值度量的个性化能力以及生态构建能力。</p><p></p><p>价值链是动态演进的，如前文提到的，价值链理念带来的一个发展思路就是与客户价值链的有效衔接，尤其是在对公领域。在对私领域则主要是价值点、兴趣点的对接，所以，对亚文化、亚群体的研究是精细化服务的基础。本轮重塑是银行脱离高速发展周期之后，在复杂环境、“低息差”条件下，真正研究、推动差异化的开始，可以说，困难重重，也正因如此，知识管理能力很可能会成为本轮重塑的基础，也是未来银行差异化的基础。</p><p></p><p>“新质金融”一定是具有中国特色的金融。“新质金融”并非是要与传统金融服务彻底划断的金融，“把马克思主义金融理论同当代中国具体实际相结合、同中华优秀传统文化相结合”，继承和发展的不仅包括传统金融服务，还要融合“中华优秀传统文化”，构建良好的金融文化、金融环境，所以，“守正创新”，不盲目求“新”是发展“新质金融”该有的基本理念，而消费者保护、消费者教育也是“新质金融”的重要课题。</p><p></p><p>结合“中华优秀传统文化”，充分理解国情，也就是中国金融机构生存的“语境”，那么，实现了“高质量转型”的“新质金融”也必然是具有中国特色的金融，因为它着重解决的是我国自己的金融发展问题。</p><p></p><p>“新质金融”是讲求效率的金融，自然也不该是“卷”的金融。银行从业员工高达 400 多万，如果不能充分保证员工的休息时间、业余时间、带薪休假时间，将影响 400 多万人及其家庭的消费能力，这在总体上是非常不利于提升社会消费能力，不利于经济“回升向好”的，银行是应该带头退“卷”的。</p><p></p><p>金融退“卷”反倒是促进时间有效利用，减少基层负担，减少低效会议时间的一个契机，研究如何将有限的时间更多应用于对客户的关注和服务上，真正该“卷”的是对客户的研究和对知识的深化。将“旺季营销”改成“忘记营销”，如果一年四季都是营销任务，“旺季营销”、“开门红”也没什么存在的特殊价值了。</p><p></p><p>银行是各行业中比较有理由率先退“卷”的行业，因为银行本质上处理的是“次生”需求，也不宜过度鼓励不适当的金融需求，所以，银行业本就不应该非理性地“卷”。</p><p></p><p>综上，笔者自己理解的“新质金融”是通过对国家政策的认真学习、对“新时代”背景和当前银行经营环境、方向的理解，基于对“高质量转型”的概括性讨论，在“历史性变革、系统性重塑、整体性重构”的标准上，所描绘的银行转型“新轮廓”、“新特征”，仍有众多不成熟之处，希望能够有助于各银行机构、各位从业者理解当前发展要求、转型环境，思考更符合本机构的发展路径，在时代的大浪潮中绽放自己的小浪花。</p><p></p><p></p><blockquote>本文源自<a href=\"https://www.infoq.cn/theme/239\">《InfoQ × 晓语未来》</a>\"专栏，该专栏由 InfoQ 与行业专家付晓岩联合打造，为您解读最新的数字化政策，分析企业业务架构的转型和实践，并提供对数字化热点议题的洞察和评论。通过专业的视角和丰富的案例，帮助读者在数字浪潮中领航未来。付晓岩，天润聚粮执行董事总经理，原国有大型商业银行资深业务架构师。《银行数字化转型》、《企业级业务架构设计：方法论与实践》和《聚合架构：面向数字生态的构件化企业架构》三书作者。中国计算机学会软件工程专委会委员、数字金融分会首批执行委员；国家工程实验室金融大数据应用与安全研究中心研究员；CIC 金融科技与数字经济发展专家委员会成员；信通院企业架构推进中心、组装式推进中心技术专家；中华全国数字化人才培育联盟专家委员会特聘专家；工信部中小企业发展促进中心产教融合产业实践教授；国家互联网数据中心产业技术创新战略联盟专家委员会副主任专家委员。</blockquote><p></p>",
    "publish_time": "2024-09-02 15:44:05",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "工作到凌晨两点是常态？英伟达财报揭秘：AI芯片巨头凭借超高薪酬敦促员工“拼命加班”",
    "url": "https://www.infoq.cn/article/W2JmyXB8kUuWQS5Fuj5f",
    "summary": "<p>英伟达刚刚发布的财报被认为是近年来科技界最重要的财报之一，主要因为它不仅决定了英伟达自身的发展和股价，还对全球科技和金融行业的产业链产生了广泛影响。作为人工智能领域的唯一“军火商”，英伟达的表现对当前市场大热的AI相关股票有着显著的影响力。</p><p>&nbsp;</p><p>在7月底，美股进入了衰退交易期，市场出现了大规模的恐慌性抛售。虽然8月在一些经济数据的暂时支撑和美联储降息表态下迎来了反弹，但这个反弹极其脆弱，在这样一个不稳定的市场环境下，英伟达财报的发布被视为“全球科技关键时刻”。</p><p>&nbsp;</p><p></p><h2>收入激增，利润率强劲</h2><p></p><p>&nbsp;</p><p>英伟达公司过去一个季度的营收增长逾倍，继续保持着强劲的拉升势头。</p><p>&nbsp;</p><p>在截至7月28日的三个月内，该公司营收达300亿美元，较去年同期增长122%（此前三个季度的同比增长都超过 200％）。分析师此前的预期为287亿美元。英伟达预计本季度营收为325亿美元，上下浮动2%，略高于分析师的普遍预期。此外，该公司还批准了另外一项500亿美元的股票回购计划。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/24/2406d700217cc874cc3b7f052f1b3275.png\" /></p><p></p><p>&nbsp;</p><p>在周三财报发布之前，部分投资者一直期待英伟达能拿出更加亮眼的营收预期。在投资者电话会议之后，英伟达公司股价在盘后交易中下跌8%，市值恐迅速蒸发超2000亿美元。但值得注意的是，今年截至目前，该公司股价一路飙升，已经上涨约160%，总市值则达到3万亿美元。该公司单凭一己之力，就拉动了标准普尔500指数年内总体涨幅的四分之一以上。</p><p>&nbsp;</p><p></p><h3>Blackwell 新款芯片需求惊人</h3><p></p><p>&nbsp;</p><p>本月初，下一代芯片Blackwell的延迟交货成为英伟达飞速增长路上的潜在障碍。黄仁勋此前曾经表示，Blackwell今年将创造“大量”收入。</p><p>&nbsp;</p><p>公司首席财务官Colette Kress周三也谈到了推迟交付的问题，她表示英伟达已经与芯片制造合作伙伴台积电就Blackwell的生产方式进行了调整，旨在提高芯片良品率。</p><p>&nbsp;</p><p>她补充称，“Blackwell的生产计划将于第四季度启动，并持续到2026财年。今年第四季度，我们预计Blackwell将带来数十亿美元的收入。”</p><p>&nbsp;</p><p>黄仁勋也强调称，其当前一代Hopper芯片的市场需求“依然强劲”。</p><p>&nbsp;</p><p>在与投资者的电话会议上，黄仁勋并未具体介绍Blackwell芯片的延迟程度，但表示设计变更已经完成，而且“无需进行任何功能上的更改”。</p><p>&nbsp;</p><p>谷歌、微软、Meta和亚马逊此前公布的最新季度业绩，显示出各大科技巨头纷纷在训练和运行AI模型的底层基础设施方面投入了巨量资金。而作为他们最大的AI芯片供应商，英伟达的这份财报也将为整个AI市场定下值得参考的整体基调。</p><p>&nbsp;</p><p>谈到AI基础设施领域的巨额支出，黄仁勋表示“我们看到生成式AI的发展势头正在加快。”该公司预计其数据中心收入（上个季度已经达到263亿美元）在明年内还将“大幅增长”。</p><p>&nbsp;</p><p>Futurum Group首席执行官Daniel Newman评论称这是“一个稳健的季度，但任何低于最高预期的业绩表现都会引发某种程度的恐慌。”</p><p>&nbsp;</p><p>他总结道，“我认为目前投资者对于英伟达的预期已经见顶，再结合已经有这么多人疯狂买入英伟达股票，股价似乎的确再没有任何上涨的空间——除非他们公布一份非常离谱的超高收入预期，或者带来人们意料之外的技术公告。总之市场对Hopper的旺盛需求足以让英伟达顺利超越普遍预期，但这样的表现在我看来只是平平、算不得出色。”</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>未来增长点在哪里？</h2><p></p><p>&nbsp;</p><p>鉴于英伟达过往几年的发展趋势，投资者也担心英伟达的步伐太快、太过激进，他们想知道 AI 的迅猛发展速度是否能持续下去。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e7/e75f517b16235ab2ea644cdeab41a0ef.jpeg\" /></p><p></p><p>&nbsp;</p><p>在英伟达发布2025财年第二季度财务业绩后，Colette Kress接受了媒体采访，讨论了公司在加速计算和生成式AI领域的战略及其财务表现。</p><p>&nbsp;</p><p>Kress表示，尽管“Blackwell”GPU的推出有一些延迟，但这并没有对公司的财务状况产生重大影响，因为市场对生成式AI和加速计算系统的需求依然强劲。很多顶级云服务提供商的相关产品已经售罄，其他客户也在积极采购现有产品。尽管Blackwell的过渡很重要，但市场仍在大量购买现有的Hopper GPU，以免在技术竞争中落后。</p><p>&nbsp;</p><p>她强调，英伟达的成功不仅依赖于硬件，还包括公司在软件领域的投入。</p><p>&nbsp;</p><p>英伟达不仅是一家硬件公司，还在软件领域有显著投入，75%的员工从事软件开发。公司通过开发先进的软件，帮助客户将工作负载从传统计算转移到加速计算平台，从而更高效地利用GPU和AI技术。</p><p>&nbsp;</p><p></p><blockquote>转向加速计算和AI并不是简单地开启硬件然后加载软件就能完成的事情。我们开发的软件是为了帮助公司从传统的通用计算转向加速计算，需要一个不同的路径。我们之前“免费”提供的软件是为了促进这一转型。&nbsp;之所以需要大量的软件工程师，是因为他们必须重新设计工作负载以适应加速计算。这也是为什么我们有许多工程师为客户整合解决方案，这使得竞争变得非常困难。我们会遇到竞争对手提供芯片，但公司却不知道如何使用，因为缺乏相关配套。我们的软件在这个过程中非常重要，因为需要重新规划工作流。如果原本是直接到CPU的，你必须重新导向到GPU。&nbsp;我们现在的策略是继续建设，以帮助各行各业——主要工作负载和应用程序——能够转向加速计算。软件将继续是英伟达的重要组成部分，无论是作为销售产品还是免费提供以帮助客户转型。</blockquote><p></p><p>&nbsp;</p><p>指数型增长不可能永远持续。但大家希望对增长能持续多久有一个实际的预期，对此，作为英伟达CFO，Kress提到，英伟达必须为产品设计和生产安排资本，以支持各个业务领域的增长。</p><p>&nbsp;</p><p></p><blockquote>我们还处于加速计算的早期阶段。这一转型不会在两年内完成。这些过渡是需要二十年、三十年的工作，才能实现加速计算，并将AI融入我们所做的一切。&nbsp;我们无法预测每天的具体情况，也不能保证一切都会以当前的速度增长。但是我们知道这一趋势将持续几十年。</blockquote><p></p><p>&nbsp;</p><p>Kress强调，公司会继续进行详尽的规划，以应对未来的挑战，并确保能够迅速适应市场变化。</p><p>&nbsp;</p><p></p><h2>超高薪酬敦促英伟达员工“拼命加班”</h2><p></p><p>&nbsp;</p><p>在被问及过高的收益预期是否会造成压力时，英伟达首席执行官黄仁勋表示“其实你不问我还没有意识到。我们只是在努力做好自己的工作，这也是我们唯一能够掌控的现实。”</p><p>&nbsp;</p><p>他还补充道，“每个人都在跑步奔向未来……我们有责任让未来在现实世界中落地。”</p><p>&nbsp;</p><p>这种对未来的承诺和压力也反映在公司内部的工作文化中，这也是英伟达取得胜利的关键所在。</p><p>&nbsp;</p><p>一位曾在企业客户技术支持部门工作的前员工表示，他经常每周工作七天，通常会在凌晨1点或2点结束工作。这位员工还补充说，其他员工，尤其是工程部门的员工，工作时间更晚。</p><p>&nbsp;</p><p>在接受彭博社采访时，英伟达公司一位前营销员工透露，她每天需要参加多达10场会议，每次会议最多有30人出席。由于意见和策略上的分歧，讨论经常会演变成争吵。不少英伟达员工都形容自己是在“高压锅”里上班。</p><p>&nbsp;</p><p>这种苛刻的工作文化部分源于长期担任首席执行官的黄仁勋，他之前曾承认自己不是一个容易相处的上司。在今年四月份接受《60分钟》采访时，黄仁勋表示，在英伟达工作本来就不应该是轻松的。</p><p>&nbsp;</p><p>“如果你想做非凡的事情，那就不应该轻松，”他当时说。</p><p>&nbsp;</p><p>虽然英伟达的工作环境压力巨大，但大多数员工都舍不得跳槽离去。据英伟达方面介绍，2023年公司的员工流失率为2.7%，而整个半导体行业的平均流失率为17.7%。根据一位前员工的描述，这份不舍就来自英伟达可观的员工股票薪酬方案——他们形象地称之为“金手铐”。</p><p>&nbsp;</p><p>通过英伟达的员工股票购买计划，员工可以将最多15%的薪水用于以85折价格购买公司股票。据《巴伦周刊》高级科技编辑金泰（Tae Kim）介绍，一位中层员工在参与该计划18年后退休时，其所持股票价值已达6200万美元。</p><p>&nbsp;</p><p>一位前工程师也表示，在公司工作十多年的员工其实已经存够了养老钱，但为了追求更高的激励回报，很多人仍然选择继续工作。这位工程师还进一步解释称，英伟达的停车场里停满了各种豪车，包括保时捷、克尔维特和兰博基尼，同事还偶尔会炫耀一下自己新近购置的度假屋。加州帕洛阿尔托附近的一位房地产经纪人透露，他曾与几位英伟达的员工合作过，其中有些员工在价值数百万美元的房产上支付了40%到60%的首付款。</p><p>&nbsp;</p><p>此外，英伟达也并不是唯一倾尽全力推动AI进步的厂商。在另一份泄露的微软员工工资表格中，AI软件工程师的年薪也比Azure部门的同行要高出12万美元。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.home.saxo/content/articles/equities/nvidia-earnings-sees-incredible-demand-for-new-blackwell-chips-28082024\">https://www.home.saxo/content/articles/equities/nvidia-earnings-sees-incredible-demand-for-new-blackwell-chips-28082024</a>\"</p><p><a href=\"https://www.cnbc.com/2024/08/28/nvidia-nvda-earnings-report-q2-2025.html\">https://www.cnbc.com/2024/08/28/nvidia-nvda-earnings-report-q2-2025.html</a>\"</p><p><a href=\"https://finance.yahoo.com/news/nvidia-employees-often-seven-days-193653866.html\">https://finance.yahoo.com/news/nvidia-employees-often-seven-days-193653866.html</a>\"</p><p><a href=\"https://nypost.com/2024/08/26/business/nvidia-employees-can-work-7-days-a-week-until-2-a-m-but-few-leave-because-of-ai-chip-giants-lavish-pay-report/\">https://nypost.com/2024/08/26/business/nvidia-employees-can-work-7-days-a-week-until-2-a-m-but-few-leave-because-of-ai-chip-giants-lavish-pay-report/</a>\"</p><p><a href=\"https://www.nextplatform.com/2024/08/28/in-depth-post-earnings-review-with-nvidia-cfo-colette-kress/?td=rt-3a\">https://www.nextplatform.com/2024/08/28/in-depth-post-earnings-review-with-nvidia-cfo-colette-kress/?td=rt-3a</a>\"</p>",
    "publish_time": "2024-09-02 15:57:11",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "中小银行数字化转型：关键人才培养与实践案例分享",
    "url": "https://www.infoq.cn/article/cp24btL1Z508WApIBBbP",
    "summary": "<p>随着数字化转型已成为各界共识，其在提升企业竞争力方面的优势与必要性愈加显著。然而，对于传统金融企业，尤其是中小银行来说，如何有效推动这一转型仍然是一个充满挑战的课题。在这个过程中，建立一支高素质的人才队伍至关重要，因为人才不仅是转型的驱动力，也是应对市场竞争的核心资源。</p><p></p><p>为了更深入地探讨中小银行在数字化转型中的人才培养策略，<a href=\"https://www.infoq.cn/profile/1D6B7352F3D0E9/publish\">FCon 全球金融科技大会</a>\"策划了“<a href=\"https://fcon.infoq.cn/2024/shanghai/track/1693\">金融组织变革与数字人才培养案例实践</a>\"”专题。在本次会议中，中原银行数智金融创新实验室数据负责人秦龙分享了该行在数字化转型过程中对于关键角色的培养经验，结合中原银行多年的实践经验，提供了体系化、切实可行的培养路径与方案，为行业提供了宝贵的参考。</p><p></p><p>以下是演讲实录（经 InfoQ 进行不改变原意的编辑整理）</p><p></p><p>在数字化转型过程中，构建合适的人才体系非常重要，这个体系的建设路径在各行业都有其通用性。我的分享主要分为三部分：</p><p>人才体系构建：讨论在数字化转型中需要构建什么样的人才体系，以及如何通过特定的路径来更有效地实现这一体系的建设。中原银行的实践案例：分享了银行在不同阶段是如何培养数字化人才或复合型人才的。数据建模师团队发展：银行数据建模师团队的发展过程，以及这个团队是如何逐步成长，最终能够较好地满足业务需求的。</p><p></p><h2>数字转型的人才需求及职业体系建设</h2><p></p><p>到 2024 年，数字化转型在各个行业中已经得到了广泛认可。特别是在金融业，国家已经出台了多项政策来推动这一进程。然而，尽管时间已经过去了十多年，银行业在数字化转型过程中所面临的挑战依然存在。通过对比 2014 年麦肯锡的调研报告和 2022 年、2023 年银行业的调研总结，我们可以发现一些共性问题。</p><p></p><p>2014 年，麦肯锡对 850 位 C 级领导进行了调研，发现数字化转型面临的前五大挑战中，排名第一的是寻找和培养专业人才。其次是组织架构的调整、业务转型、数据管理和创新思维与机制的建立。这些挑战归根结底是机制和制度的匹配问题。到了 2022 年和 2023 年，银行业的报告中依然提到了复合型人才的培养、敏捷组织的构建、数据应用的不足以及对公业务的复杂性等问题。银行业的数据虽然在各行业中相对完整，但在全流程模拟和在线数据应用方面仍显不足。此外，对公业务的复杂性和特殊性也给数字化转型带来了挑战。</p><p></p><h2>数字化人才的职业体系与成长方案</h2><p></p><p></p><p>在数字化转型的实际落地过程中，我们经常面临组织和人才培养方面的挑战。首要的问题是确保整个战略目标能够在全行范围内得到统一贯彻和落实，这需要领导层的接受和支持。一旦战略开始执行，组织将面临重构，人才体系和人力培养也需要重新设计。</p><p></p><p>在设计人才体系时，我们可以借鉴之前应用中效果较好的方法论。职业体系的构建建议遵循五个步骤，这包括：1. 结合公司组织架构设计岗位，2. 建立岗位评估体系，3. 为子岗位设计职业定级范围，4. 填充职业描述与任职要求，完成职位卡，5. 对复合型岗位设置导向人才发展路径。</p><p></p><p>为了实现这一目标，我们提出了四项指导原则。第一是动态与敏捷，意味着职业发展路径需要能够根据组织的变化进行动态调整。第二是全员清晰，确保每位员工都清楚自己的成长路径和下一步需要具备的素质与职责。这要求员工提前展现出他们已经具备的下一职级所需的职责和技能。</p><p><img src=\"https://static001.geekbang.org/infoq/1b/1bdfce50fd34d1a6e41af0db0436b8cc.png\" /></p><p></p><p>第三是关键角色的参与，这要求业务部门和人力资源部门参与讨论，对新旧岗位进行调整以适应转型。第四是价值观的匹配，确保职业路径和成长体系的设计与企业的价值观相符，使员工的成长与企业的产出达成一致。通过这些步骤和原则，我们希望建立一个能够适应数字化转型需求的人才体系，同时确保员工的个人成长与企业的整体发展同步。</p><p></p><p>在数字化转型过程中，构建一个有效的岗位和职业体系至关重要。上述五步流程每一步都旨在确保岗位设置与员工发展紧密相连。</p><p></p><p>首先，我们需要明确新岗位的设置，包括这些岗位下的子岗位以及它们之间的相互关系。接下来，对每个岗位进行定义，类似于编写职位描述（JD），这有助于引导员工发现他们需要具备哪些能力，以便更好地履行自己的角色。通常，这包括领导力、专业能力和综合素质的通用模型。在设计这些能力时，我们需要明确每个专业方向应具备的子能力，以及每个子能力在不同级别上应达到的标准。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2d/2d796fd91d05fcefcc8e7e358f821c8b.png\" /></p><p></p><p>随后，我们定义每个岗位所需的层级角色，比如：新人、骨干、主管、专家、资深专家。在实际操作中，并非所有岗位都需要具备所有五个层级。有些高级岗位可能从中间层级开始，而低级岗位可能只涵盖基础层级。此外，岗位之间可能存在横向的职业发展导向，这需要事先明确定义，有助于我们识别关键岗位，并明确在每个层级上的成长突破点。有了清晰的能力模型后，我们可以量化评估人员的能力，并利用如 GROW 模型等工具，明确员工的当前状态、目标状态以及实现目标所需的提升途径。</p><p></p><p>最后，我们建议设置导向性岗位或路径，这虽非必需，但对于有抱负的企业来说，提供多样化的发展机会对于留住人才、激发潜力至关重要。在岗位发展到一定阶段后，提供可选的其他路径，有助于员工看到更多的可能性，这对于人才体系设计是一个关键点。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/be/be14d8023307ce6e2aa3e2fedf363045.png\" /></p><p></p><h2>中小银行数字化人才能力培养</h2><p></p><p></p><h4>明确转型框架，确认支撑举措</h4><p></p><p></p><p>在数字化转型的过程中，培养所需的人才是至关重要的一环。在企业的不同发展阶段，尤其是在转型的早期，我们建议企业应该有一个清晰的愿景图。这个愿景图包括几个关键点。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e3/e3b43e7a4266c342844753bc57ba8603.png\" /></p><p></p><p>首先，转型过程中存在一个常见误区，即认为数据治理应该放在首位。数据治理不应单独存在，而是应该与业务流程和系统建设同步进行。如果企业一开始就投入大量资源进行数据治理，却看不到即时效果，可能会导致领导层和团队的信心丧失，最终导致转型失败。为了避免这种情况，我们建议围绕数据系统和人力资源，寻找快速取得成果的突破点。通过端到端的流程优化，明确需要使用哪些数据、需要清理哪些数据、需要提升哪些系统。同时，明确在这一过程中需要哪些人才，需要补充和培养哪些人才。通过这种方式，我们可以逐步实现整个集团公司的数据治理和系统平台构建。</p><p></p><p>在这个过程中，人才往往是先行一步的关键因素。如果缺乏相应的人才，后续的工作将难以进行。在人才培养方面，企业可能会面临多种挑战，包括内部选拔、内部培养、外部招聘等。特别是在非一线城市或传统行业，由于薪资竞争力不足，企业可能会遇到人才来源的问题。这时，企业需要考虑如何通过社会招聘和校园招聘吸引人才，并针对这些人才的能力进行培养。对于校园招聘的人才，由于他们可能缺乏实际工作经验，企业需要制定相应的培养计划，帮助他们快速提升能力，以满足数字化转型的需求。</p><p></p><h4>定义各角色数字能力培养目标</h4><p></p><p></p><p>在培养数字能力的过程中，我们设定了一个宏观的图景，涵盖了从领导层到总行、分行以及业务和数据人员等各个层面。我们的目标是实现全员的培养和能力提升。</p><p><img src=\"https://static001.geekbang.org/infoq/97/97a33c8235d743fb558ea02256fd0cfc.png\" /></p><p></p><p>对于领导层来说，关键在于形成统一的认识，推动变革，并理解新技术如何助力企业实现愿景。领导层需要相信并支持数字化转型，这样在日常工作中遇到问题时，他们才能引导企业和部门保持正确的方向。在银行和制造业等不同行业的项目中，我们发现领导层的这种信念至关重要。</p><p></p><p>对于业务人员，总行的业务人员，我们希望他们能够理解并利用数据来优化工作。而分行层面的人员则需要理解总行下达的任务，并相信通过数字化手段可以有效地解决业务问题并获得认可。</p><p></p><p>对于数据人员，我们期望他们能够深入了解业务，提出并清晰解释他们的方案，使业务团队能够理解并接受。例如，在银行业务中，我们通过人工智能和算法来识别目标客户群，进行精准营销。如果这些营销线索直接下发到分行，分行可能会怀疑这些是由不懂业务的数据人员提出的方案。为了解决这个问题，我们采取了一些措施。</p><p></p><p>首先，我们强调了能力宣导的重要性。其次，我们鼓励分行根据他们的业务规则向总行提交日常运作的逻辑，然后总行基于这些规则提供线索。通过比较，我们发现基于分行规则的线索转化率通常不如总行通过数据和业务讨论后下发的线索。我们进一步在分行的规则模型基础上应用算法理论，进行精选迭代，筛选出更有可能转化的客户。这样，分行在收到这些线索时，会发现转化率有了显著提升。这个过程使得一线员工更容易理解技术的价值，认识到它比简单的业务规则描述更为精确。</p><p></p><h4>各角色能力诊断、培养以及提升方法</h4><p></p><p></p><p>在能力定义清晰后，组织内部人才培养的关键环节是明确目标，并采取多种方式，如考试、访谈、问卷调查以及事项完成结果的回推，来评估当前情况。通过早期调研，我们发现中小银行普遍缺乏数据建模师或数据科学家，科技人员的业务理解能力薄弱，业务人员跨职能合作能力不足，以及对数据应用工具的掌握和基本数据理解能力都相对欠缺。诊断后，我们能更有针对性地知道下一步培训的重点对象和部门，以及采用何种手段进行能力提升。</p><p></p><p>诊断完成后，我们需要明确提升途径，包括培养内容和目标对象，这要求有一个体系化的设计。我们曾在 2017 至 2018 年间进行过这样的工作，但后来发现效果并不明显。这有两方面原因：一是人才培养是一个长期过程，需要时间积累；二是我们的体系还有待完善。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/71/711c4da181cfecbd0b920b1381418bc2.png\" /></p><p></p><p>2019 年，我们建立了数字化学院，系统地培养员工的数字化能力。调研发现主要问题集中在四个方面：课程体系不够系统，培训师资依赖外部资源，缺乏内部培养机制，以及运营管理和学习氛围的营造。我们意识到，尽管定义了能力，但课程还是点状提出，缺乏系统性。早期依赖外部资源进行培训，但大型企业需要内部懂行的内训师，这要求建立一整套内训师培养机制。此外，我们需要确保培训的执行和落地，包括考核机制，不仅仅是听课后的考试，还要与员工的专业序列升级、晋升、转岗等职业发展方面相结合，激发员工自主学习技能，将其视为职业发展的重要组成部分。运营管理方面，需要培养和宣导学习数字化能力的氛围，并设置专业小组或专岗人员跟进培训落实。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/76/76d81bba9d187662ecffa2020122dfb7.png\" /></p><p></p><p>基于体系方面的成熟模型，我们提出了一个七维模型，旨在培养更多员工理解大数据、人工智能、智能建模、算法等概念。我们希望员工明白这些模型能为他们带来什么价值，以及何时以及如何与数据人员、建模师和数据科学家进行有效沟通，共同设计解决实际业务问题的数字化场景。这个模型涵盖了数学统计、模型管理、业务理解、领导力和金融知识等多个方面。我们将根据这些维度设计一系列课程，低层次的课程主要通过线上方式进行，而高层次的课程则更强调线下教学。整个过程将形成一个系统化的方案和课程体系，并沉淀到内部学习平台上，员工可以根据自己的级别和岗位需求来选择需要完成的课程。</p><p></p><p>除了课程设计，我们还关注岗位目标设置、培训激励以及内部内训师的培养。内训师需要掌握如何有效授课，并根据需求讲授相应课程。我们要求内训师每年开发新的课程，确保课程内容的阅读量和观看量达到一定标准，以此来迭代更新课程，保证教学质量始终反映最新成果。这不仅提升了内训师自身的能力，也确保了他们能够持续为行内提供新的课程内容，或替换掉旧课程体系中不合适的部分。此外，我们还会提供一些实例作为参照，帮助内训师和员工更好地理解和应用这些课程内容。</p><p></p><p>近两年，我们在实验室提出了复合人才培养的新理念，尽管这一概念已被广泛讨论，如 T 型人才、π型人才等，但在实际落地时，复合人才培养仍是企业内部的一个难点。这是因为员工一旦投入到企业运营中，他们的主要任务是完成自己的业务目标，例如银行一线人员的存款、贷款和产品销售等 KPI 指标。在这种情况下，学习与本职工作不直接相关的数字化技能往往会被搁置。</p><p></p><p>为了解决这一问题，我们进行了两项探索。第一个是，我们尝试让所有业务人员接受业务翻译师的培训，以培养他们的基本科技数据思维。然而，他们能走多远并不确定。第二个探索是，我们尝试设立了一个独立团队，旨在吸收新人员，培养合格后输出到行内，但发现这种方法也失败了。原因在于，单独的组织部门无法真正投入到各个业务角色中，缺乏实践机会，而所有复合人才都是通过实践培养出来的。</p><p><img src=\"https://static001.geekbang.org/infoq/1d/1d3d0cca1c7b9f69315b661743b30b91.png\" /></p><p></p><p>在实验室，我们提出了新的理念，主要抓住两个关键点：一是数字化转型推动，涵盖全行所有业务条线和部门，让员工参与典型工作，这样他们在拥有相应技能的同时，也能参与到实际业务工作中；二是实验室的创新孵化功能，涉及全行各种创新业务产品的研发和运营，让员工与有业务背景的人合作，锻炼能力。此外，实验室还管理着全行的数据建模师和数据科学家团队，这为复合人才培养提供了支持。我们进一步将能力抽象为数字应用、金融科技、业务洞察、产品设计和敏捷管理五个方面，并通过内外部培训、日常分享、主题演练、比赛模拟、项目实操和阶段性轮岗等方式，为复合人才培养提供支撑。</p><p></p><p>在推动全行数字化转型的过程中，文化宣传和宣导是一项持续的任务。为此，我们开展了一系列活动，旨在将数字化文化从总行和特定部门传递到所有部门和基层。</p><p></p><p>我们举办了“好点子”创新大赛，鼓励员工从自己的业务岗位出发，提出创新想法以提升业务流程或特定业务领域。这些想法经过收集和评估后，会进入孵化阶段，由相应团队参与实施，确保员工的数字化思维能够在业务中得到实际应用。我们还会为这些项目提供必要的支持，让员工感受到自己能够参与并推动创新的落地。</p><p></p><p>我们开展了“数智燃六点”活动，这是一个培训和宣导项目，包括两大类内容。一类是“我来讲”，通常由行内的关键角色或领导岗位分享他们对下一阶段工作的指导思想；另一类是“他来了”，邀请行业专家分享成功经验。这些活动旨在介绍新经验、高层次的业务思维，并宣导企业文化。</p><p></p><p>“原智社”是一个虚拟的组织机构，提供一个平台供员工进行线上讨论和线下座谈会交流。在这里，员工可以分享新用法、讨论想法，并探索这些想法的可行性和落地方案。通过这个过程，我们可以收集到一线员工的真实想法和需求，帮助他们实现创新。</p><p></p><p>最后，“分支行联动”活动旨在将总行的先进数据平台和解决方案推广到分行，并收集分行的一线理念和需求。通过数据科学家的支持，为分行提供定制化的解决方案，确保上下沟通畅通，使数字化转型和能力的基本思想能够贯彻到全行。</p><p></p><p>通过这些活动，我们希望能够营造一个开放、创新的企业文化，鼓励员工积极参与数字化转型，确保数字化的基本思想和文化理念在全行范围内得到有效传达和实施。</p><p></p><h2>数据建模师团队培养发展历程</h2><p></p><p></p><p>接下来，我想分享一个关于数据科学家团队培养的基本案例，探讨除了基本能力培养外，还有哪些潜在因素需要关注。在许多传统企业中，数据科学家这样的角色可能并不常见。我们之前定义了数据科学家在银行中可能承担的工作，如经营诊断、数字化营销、以及将传统基于实体资本的授信模式转变为基于风控和客户特征的数字化授信。</p><p></p><p>最初，我们依赖外部力量来引导团队的组建，包括招聘新人和提出团队建设的建议。初步团队由外部专家带领，逐步过渡到内外结合的工作模式。最终，我们的目标是减少对外部指导的依赖，完全依靠自身能力来推动团队的发展。</p><p></p><p>为了更有效地推动团队建设，我们希望对每个级别和角色定义不同的能力要求，并定期对团队成员进行量化评估。这有助于我们了解团队距离目标还有多远，需要在哪些方面进行有针对性的培养。通过这种过渡，我们期望能够精确识别团队成员的能力差距，并制定相应的培养计划。这样的方法不仅可以提升团队的整体能力，还能确保每个成员都能在其专业领域内达到预期的专业水平，从而推动整个数据科学家团队向更高目标发展。</p><p><img src=\"https://static001.geekbang.org/infoq/d8/d837fc77a787c00cf75735b4850837d7.png\" /></p><p></p><p>在业务工作模式上，我们探索了如何真正实现目标并赋能业务。最初，我们采用了敏捷化组织的理念，将业务、科技、数据等所有人员整合到一个团队中，各自推动项目进展。数据科学家团队在最初阶段被分散到不同的业务部门中。但这种做法很快暴露出问题：尤其是对于主要由应届生组成的部门，由于经验不足，直接进入敏捷模式后，业务团队对他们的指导非常有限，导致他们难以结合业务提供数字化解决方案。一两年过去，这些人员的能力没有明显提升，业务部门也感觉数据人员并未真正帮助提升业务。</p><p></p><p>针对这个问题，我们进行了调整，将人员重新集中管理，进入第二阶段，采用项目制形式来支持业务组完成目标。在这个阶段，我们有资深人员提供方向性指导，并通过导师机制帮助初阶人员，尤其是应届生成长。通过量化评估，我们发现团队人员的能力有了显著提升。</p><p></p><p>刚才有观众询问如何量化评估产出提升，实际上这是可行的。在特定团队中，我们记录了每年的工作量和人均产出，发现统筹培养后，人均产出每年都有 40% 以上的提升，甚至有一年达到了 60%。这明显表明统筹培养对团队能力提升有显著效果，尤其是对于新团队和早期培训阶段。</p><p></p><p>第三阶段，为了业务稳定性，我们成立了专业派驻小组，保留了人才池，并派驻部分人员到业务部门，既满足统筹培养，也响应了业务部门对人员稳定性的需求。</p><p></p><p>到了第四阶段，当我们拥有了足够多的骨干人员，对于需求强烈的部门，我们重新采用敏捷模式，将部分骨干人员内嵌到部门中。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/af/af0e4bc12639b14da9b2b3843b46acb7.png\" /></p><p></p><p>在整个演变过程中，我们在营销和风控方面基本实现了目标：营销上，40% 的销量来自数字化营销；风控上，实现了 20 多款产品的贷前、贷中、贷后全流程数字化风控。总体来说，我们基本达到了预期目标。</p>",
    "publish_time": "2024-09-02 15:59:48",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "平安证券现象级应用：复用率高达191.44%的微卡片平台是如何构建的",
    "url": "https://www.infoq.cn/article/tBGvusFGl4gaQaQNjicX",
    "summary": "<p></p><blockquote>嘉宾 | 张朝晖 平安证券信息技术中心首席信息官编辑 | 高玉娴</blockquote><p></p><p></p><p>企业在数字化转型过程中催生了大量数字化业务需求，而传统 IT 交付模式下存在业务系统功能使用场景单一，复用率不高，前端界面应用与系统捆绑，相同界面功能在不同的系统需重复建设，以及业务在提完需求后很少参与研发过程，导致系统功能反复修改、IT 交付压力大等问题。为了深入探讨解决这一系列问题的办法，我们在2024 年 <a href=\"https://mp.weixin.qq.com/s?__biz=MzkzMzQzNjQ5Mw==&amp;mid=2247492380&amp;idx=1&amp;sn=0699c5699663064fa077727e96c38096&amp;scene=21#wechat_redirect\">FCon 全球金融科技大会</a>\"上邀请到平安证券信息技术中心首席信息官张朝晖进行了题为“打破旧世界，重组新世界——平安证券数字化利器微卡片平台实践分享”的主题演讲。</p><p></p><p>据张朝晖介绍，作为一个容器，微卡片是技术部门为业务搭建的众多系统中的每一个服务对应的前端业务呈现，它们既可以作为独立的模块独立使用、分享或嵌入其它页面，也可以和不同卡片灵活组装到不同的应用场景，一次创作，多次复用。目前微卡片平台已经应用于平安证券所有业务线，累计用户 5000+ 人，累计访问 1700+ 万次，卡片总数突破 3 万张，卡片复用率高达 191.44%。</p><p></p><p>亮点内容：</p><p>平安证券 OPTIMAL 数字化转型方法论是平安证券十年数字化转型之路的经验总结和理论升华，将为准备数字化转型或在数字化转型过程中遭遇困难的企业提供参考指引；微卡片平台打破以功能为中心，与业务系统强捆绑的传统前端应用模式，创建了以客户为中心的场景化组装式交付模式，打造无边界应用，满足了业务在数字化转型过程中多样化、个性化的应用场景需求和越来越高的交付时效需求。将为科技如何更加有效赋能业务数字化经验提供实践参考。</p><p></p><p>以下是演讲实录（经 InfoQ 进行不改变原意的编辑整理）：</p><p></p><p>数字化转型的方向和目标，核心在于通过数字化手段提升业务流程和工作场景的效率。我经常引用麻省理工学院的研究，其中提及，数字化转型的目标是将传统的作坊式模式转变为面向未来的生态模式，涉及从以产品为导向的体系向以客户为中心的模式转变，以及实现模块化、敏捷性和动态合作等关键要素。我今天要介绍的很多内容都与这些概念息息相关。</p><p></p><h2>旧世界：传统研发模式难以满足数字化需求</h2><p></p><p></p><p>让我们来探讨一下所谓的“旧世界”，即传统的研发模式。</p><p></p><p>在旧世界中，传统的开发流程从产品经理收集需求开始，紧接着由开发团队进行分析、设计、开发、测试，直至最终业务上线。这个过程通常非常漫长，可能需要数月的时间，我们通常称之为“瀑布式”开发流程。然而，在这段时间里，业务场景可能已经发生了巨大变化，导致开发成果难以快速满足业务需求。</p><p>并且，在这种模式下，开发的门槛非常高，业务部门的参与度相对较低。就如同让司机去设计一辆车，显然是不现实的。同样，业务部门的专长是使用产品，而不是设计产品。这常常导致业务需求交付的匹配度因多层沟通和信息转化受到影响，可能不符合用户预期，使得系统功能反复修改。例如，业务部门可能会提出一个简单的需求，但当开发完成后，他们却不满意。对此，开发团队也会因为无法准确预测业务部门的具体需求感到委屈，虽然付出了辛勤的努力，但仍然难以完成任务。</p><p></p><p>这揭示了旧世界中存在的一个主要问题：开发流程与业务需求之间存在脱节，导致了效率低下和资源浪费。</p><p></p><p>在软件开发领域，前后端技术分离也经常出问题。举例来说，前端开发者专注于使用 Angular、Vue、C# 等技术构建用户界面，而后台开发者则使用 C++、Java 等技术，它们完全是两套不同的体系。这种分离导致前后端开发人员之间存在显著的冲突。例如，后台人员开发了某些功能后，通常需要等待前端人员完成开发才能上线，使得整个开发流程变得漫长，并引发了许多矛盾。</p><p></p><p>并且，在开发界面时，PC 端、移动端、安卓、iOS 甚至鸿蒙系统都需要单独开发，这不仅造成了资源浪费，也给开发团队带来了巨大的挑战。传统的前端架构往往以应用系统为中心，形成了所谓的\"烟囱式\"应用系统。每个应用系统都有自己的菜单，菜单上可能包含数百甚至数千个功能。当业务团队需要一个新系统时，往往需要重建，导致许多功能的重复开发和资源的严重浪费。</p><p></p><p>除此之外，报表问题也非常普遍。传统技术开发的报表都是独立的，不同报表之间无法共享和重用已有的报表组件、数据模型或配置等。不同报表之间容易出现报表风格、展示、数据差异或错误， 开发效率低，并且维护成本高。此外，由于缺乏对报表的集中运营监控，所以无法确定存量报表的实际使用情况，导致报表越来越多。</p><p></p><p>与此同时，多团队协作本身也带来了巨大的挑战。从沟通的角度来看，不同团队之间在时间、人员以及技术栈上的差异，使得彼此间的沟通变得极其困难，这直接影响了整个系统开发的效率和质量。虽然近年来分布式系统被广泛推崇，但它们存在兼容性、性能维护和更新等技术痛点，导致许多人选择单独开发系统，从而造成了更多的集中式开发问题，如功能的重复建设。</p><p></p><p>目前微服务架构也存在诸多挑战，比如，将一个大服务拆分为多个小服务时，需要考虑微服务的大小是否恰当，是否有证据表明微服务设计得恰到好处。假设某个供应商将一个服务拆分为五个服务，那么这并不是真正的微服务，而是“巨无霸服务”。DevOps 理念虽然听起来很好，但实施起来却非常困难。如果让开发人员同时负责测试和运维，可能会导致他们在非专业领域浪费精力。如果没有良好的架构和机制，DevOps 可能只是空谈。</p><p></p><p>话说回来，尽管旧世界存在种种问题，我们依然可以怀揣梦想。作为一名 IT 开发管理者，我也有一个梦想，那就是希望软件开发能够像去宜家购买家具一样简单。在宜家，我可以根据自己的需求，挑选厨房的设计样式和颜色，然后进行个性化调整，下单并让宜家将家具组件送到家，甚至让宜家帮忙完成装修。</p><p>我希望软件开发也能采用这种模式，用户可以根据自己的业务场景，选择和组合组件，建立个人工作空间，并在其中直接操作。这种 软件开发模式是松耦合、共享、去边界的，无论是内部还是外部系统都能互联互通，让专业的人做专业的事情，没有技术门槛。</p><p></p><p>然而，实现这样的梦想面临许多阻力，我提出几个核心问题供大家一起探讨：</p><p></p><p>第一，数字化转型是 IT 牵头还是业务牵头？许多公司为此争论不休，最终得出的结论往往是业务牵头，但事实上业务部门往往对数字化转型缺乏清晰的认识和具体的想法。因此，我们采取的方法是 IT 先行，通过 IT 部门的数字化转型积累经验，建立平台，然后反馈给业务部门，推动他们提出需求和想法，不断优化整个数字化转型过程。</p><p></p><p>第二，技术平台的选择是集中式还是分布式？我们选择分布式，具体原因将在后文解释。</p><p></p><p>第三，对人员的要求是全能的“诸葛亮”还是专业的“臭皮匠”？我们选择了后者，即专业的人做专业的事情。</p><p></p><p>第四，数据与展示的先后顺序。通常的观点是先清理和确认数据的准确性和完整性，然后再进行展示。但我们的做法正好相反，我们认为应该先展示数据，因为人是视觉动物，对数据有天然的兴趣。通过展示，业务人员可以发现问题，然后进行数据的更新和优化，从而确保数据的准确性、完整性和时效性。</p><p></p><h2>新世界：组装式无边界应用开发，拉业务一起“上船”</h2><p></p><p></p><p>在回答了四个关键问题后，向大家介绍一下平安证券的微卡片平台。</p><p></p><p>微卡片究竟是什么？ 可以将其想象为前端的微服务架构。在这种架构中，每个微卡片代表一个独立的业务功能。我们将所有团队和系统的每个功能细分为一个个微卡片。有了微卡片之后，就可以根据不同的业务场景，将这些卡片组装成卡片页。这些卡片页可以根据需要组合，然后嵌入到相关的业务系统或直接集成到个人工作台中。这样，用户可以在统一的界面上看到和操作他们所需的内容，无论这些内容来自哪个业务系统。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d1/d1e1785c16f4eb5b48401419fd1652b3.png\" /></p><p>(上图数据为 mock 数据)</p><p></p><p>目前，平安证券内部有三类微卡片：展示类、操作类和办公协同类。展示类微卡片主要用于展示信息，如卡片看板、数据大屏和数据图文；操作类微卡片包括操作表单、报表、移动端和自定义卡片；办公协同类微卡片则涵盖了在线 PPT、在线 Excel 和微会议等工具。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9f/9f9b07c904995ff2f151d75c8115c5bb.png\" /></p><p></p><p>以在线 PPT 为例，它与微软 Office 的 PPT 相比有两个主要区别：首先，在线 PPT 中展示的所有内容都是实时的，直接与后台服务对接，展示最新数据，而不是静态图像；其次，在线 PPT 支持多人协作功能，这使得平安证券内部的 PPT 使用变得非常普及和便捷，用户可以像使用微软 PPT 一样，通过拖放操作轻松创建自己的演示文稿，并将具体内容直接链接到后台服务。</p><p></p><p>我们管这种叫组装式、无边界应用开发，应用彼此之间已经没有边界了，完全是场景化驱动，针对某一个场景可以组装成所需要的功能。</p><p></p><p>今天这里主要介绍一下微卡片平台的三大功能：第一个是展厅（Show Room），我们拥有一套称为微导航（Navigator）的体系；第二个是卡片市场，这里存放了我们所有的卡片，目前平安证券已有超过 3 万张微卡片，涵盖了各种不同的业务功能；第三个是个人工作台，它可以根据个人需求实现个性化定制，达到千人千面的效果。</p><p></p><p>微导航的核心理念是“以点带面，纵横帷幄”。我们可以将任何微卡片或数据构建成节点，并在这些节点之间建立关联。通过多层地图结构，从国家到省、市、自治区，再到县、乡等，可以打通所有数据。利用下钻、累积、切片、切块、跳转等模式，用户可以方便地查看所需数据。展厅中的所有业务功能都可以通过这种方式展示。以业务领域为例，我们有多个产品线和业务条线，每个都有相应的微导航。在 IT 领域，开发、运维、测试、配置、管理等也都实现了微卡片化，并通过微导航快速找到所需信息。管理方面，项目管理、人员管理和流程管理等也都通过微卡片化实现。</p><p></p><p>卡片市场相当于仓库，是一个多层结构的分布式系统。每个业务系统可以有自己的仓库，业务系统上的域可以有自己的子仓库，公司层面有公司仓库，集团层面则可以看到多家公司的卡片中心。这个多层次的分布式卡片市场已经上线多年。</p><p></p><p>下面分享几个微卡片的具体应用场景：</p><p></p><h5>场景 1: 缩短研发流程，快速上线产品功能</h5><p></p><p></p><p>举一个业务场景的例子，在公司年中会议前，办公室提出希望我们能快速通过移动端实现实时的会议在线互动问答。从需求提出到分析、设计、开发、上线测试，我们仅用了 7 天时间就完成了功能交付上线并且适配多种终端设备，这得益于微卡片体系的高效性。</p><p></p><p>另一个例子是信息安全方面的工作，涉及到多个团队合作，包括网络组、数据库组等，有成百上千的具体需求需要跟踪和管理。我们通过微卡片系统，用 2-3 周的时间快速构建了一个信息安全运营看板，打通了所有关联关系，实现了实时数据展示和状态更新。这个系统的开发者实际上是运维人员，他们并不精通开发，但依然能够利用微卡片系统快速上线应用。</p><p></p><h5>场景 2：业务和开发共同参与，人人可创建前端应用</h5><p></p><p></p><p>微卡片平台提供了一种全新的工作模式，有效解决了业务与 IT 之间常见的矛盾。通过这个平台，我们能够快速地将业务人员纳入到开发环境中，用一句话来形容就是 “拉上贼船”。让业务人员可以直接参与到业务功能的开发中，即使是不具备专业前端开发技能的人员，也能通过微卡片平台构建前端界面或模板。这样的参与度极大地提高了，功能上线的速度也变得更快。</p><p></p><p>在平安证券，真正懂得 Vue、Angular 等前端技术的开发人员只有 44 人。但通过微卡片平台，我们实际上拥有了 659 名前端开发人员。这包括了 243 名后端人员和 372 名运维人员，他们通过微卡片平台参与到前端开发中，即使并不熟悉 Vue 等技术。更令人振奋的是，有 187 名业务人员直接参与了前端界面的开发，其中一位业务人员在开发微卡片数量上排名前三。</p><p></p><h5>场景 3：多团队参与微卡片平台共建，实现技术共建共享共赢</h5><p></p><p></p><p>微卡片平台实现了共建、共享、共赢 的六字方针。在今年 4 月的 QCon 大会上，我分享了<a href=\"https://www.infoq.cn/article/i5DextzZMdOqTGhhJje9?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">《平安证券数字化激励机制》</a>\"，通过有效的激励机制鼓励大家参与进来。例如，在一个系统中进行管理时，多个团队可以分别提供后台服务，而前端开发团队则将这些需求整合在一起，构建统一的管理界面。通过微卡片平台，每个团队可以独立构建自己的界面，最终组装成一个系统层面的统一管控平台，大幅提升了速度和效率。</p><p></p><h5>场景 4：落地 DevOps 理念——数据平台性能自动化监测</h5><p></p><p></p><p>微卡片平台简化了 DevOps 流程，例如，为了保证数据平台的性能，大数据团队创建了数据平台性能监测模型，设定具体性能指标，测试团队将模型和指标嵌入领航质量保障平台（GATE）的自动化测试引擎，实现对平台组件、数据集市、微数据、微卡片多个方面的全方位检测，且通过微卡片实时展示性能“体检”结果，从而既保证了数据平台性能监测的合理性又提高了监测速度，提升开发和测试的沟通协作效率。</p><p></p><h5>场景 5：卡片看板跨业务系统复用</h5><p></p><p></p><p>据统计，目前平安证券的微卡片平台已经拥有超过 3 万张微卡片，平均每张卡片的复用率达到了 191.44%，这意味着每张卡片至少在两个业务场景中使用，大大节省了人力。换言之，平均每张卡片已在 1.91 个场景 / 应用中使用，每个卡片组件已在 431 张卡片中使用。综合情报站卡片通过嵌入业务系统的方式快速赋能投资团队、风控、投行质控等 10 个团队、23 类业务主体。同时借助微卡片灵活配置的属性，累计已经配置 20 张监测卡片。</p><p></p><h5>场景 6：微卡片内置跨域访问技术解决方案</h5><p></p><p></p><p>微卡片平台已经成为平安证券内部的现象级应用。所有业务条线，各种岗位角色都可以使用微卡片，轻松构建卡片和看板，也可以一键分享给他人。这解决了跨域功能的问题，确保了即使在多个分布式业务域中，也能实现快速有效的沟通。业务人员可以通过微卡片平台组装自己的工作台，不再需要担心功能来自哪个域或系统，只需关注功能本身。</p><p></p><h5>场景 7：组装式场景化应用，数据跨系统动态聚合</h5><p></p><p></p><p>数字化转型的核心是从以产品为中心转向以客户或应用场景为中心。通过微卡片平台，可以根据业务场景组装所需的应用。例如，CIO 工作看板可以覆盖公司运维、需求进展、机器使用率、经营情况、风险管理等多个方面；首席风控官可以通过一个页面了解市场风险、流动性风险和操作风险；个人工作台可以根据不同的业务场景进行定制，如资金看板、资管产品看板、固定收益数字化屏幕、投行业务大屏等，都可以在一个界面上展示并操作。</p><p></p><p>微卡片平台还实现了数据的联动，例如通过地图快速查看机构列表和分支机构的情况，项目管理可以查看项目的人员、需求、成本和流程情况，并通过下钻获取更多维度的信息。微报表取代了传统的报表系统，实现了实时跟踪和效率提升。</p><p></p><p>目前，微卡片平台在平安证券内部扮演着至关重要的角色，特别是对于操作型界面的需求。操作型界面往往比较复杂，为此我们专门构建了 16 个操作型场景，用户可以直接选择所需场景，系统便能自动生成相关的操作型卡片，并与数据库或其他资源连接。此外，我们还有由 17 个模块组成的复杂操作界面，支持多层嵌套布局。例如，员工基本信息的在线申请等 Web 端操作型功能，都可以通过微卡片平台实现。操作型卡片也可以嵌入到不同场景中，如交易策略的展示，包括策略详情、参数配置、收益情况和持仓明细等，都是通过微卡片平台快速创建的。</p><p></p><h5>场景 8：微卡片数字化运营监控</h5><p></p><p></p><p>在数字化运营监控方面，我们拥有 35,000 张微卡片。通过这个监控体系，我们能够清晰地了解进展情况、用户访问量 (UV)、页面浏览量 (PV) 等关键数据。这个监控体系还帮助我们发现了优化空间，比如通过分析用户使用微卡片的时间，帮助用户减少了 50% 的操作量，优化了重复性工作。</p><p></p><h5>场景 9：交易端开放自助式接入通道</h5><p></p><p></p><p>在固定收益交易领域，为了性能考虑，我们使用 C# 编写前端，并与微卡片平台有效整合。例如，在债券期货交易中，用户不仅关心表单和参数配置，还关心系统延迟。通过微卡片，用户可以直观地监控每个组件的延迟情况，以及组件间的延迟，从而快速定位问题所在。</p><p></p><h5>场景 10：微卡片具备开放性，与外部系统轻松集成</h5><p></p><p></p><p>微卡片平台的开放性使其可以对接多个数据源，目前我们使用最多的是 RESTful 接口。如果用户系统支持 RESTful 接口，使用微卡片将非常方便。我们还发现，Excel 可以作为一个很好的数据源，即使是老旧的 Excel 文件，也可以作为数据源生成微卡片，同时享受微卡片带来的所有优势。微卡片平台的快速发展得益于其与多个接口的整合能力，包括与外部系统如恒生系统和衡泰系统的直接数据库连接。通过微卡片，我们可以展示所有恒生系统的配置，并提供移动端审批功能。</p><p></p><p>总的来说，微卡片平台不仅仅是一个前端展示平台，它还涵盖了前端操作交互、数据分析、办公协同等多个方面。更重要的是，它是一个强大的数字化工具，提供了业务场景驱动的快速送货上门服务，是对传统开发模式的革命性创新。这种创新体现在分布式协作、IT 与业务的有效合作、松耦合功能提高系统健壮性，以及对后台微服务架构的验证作用。</p><p></p><p>此外，我们逐步减少对集中式数据中台的依赖，转而采用分布式数据平台，即联邦数据平台，并对后台服务进行有效监控。</p><p></p><h2>如何落地？平安证券的 OPTIMAL 数字化转型方法论</h2><p></p><p></p><p>当我们着手进行数字化转型和平台功能落地时，需要一个系统化的过程。就像我在打乒乓球时，教练为我制定了四个阶段的 60 天训练计划一样，每个阶段都专注于不同的技能提升，从基础姿势的稳定性到移动击球，再到发球技巧和最终的整合应用。</p><p></p><p>同样地，要成功落地这样的平台和功能，也需要一整套流程和管理方法论。因此，我们推出了 OPTIMAL 数字化方法论，这是一个基于英文单词 OPTIMAL 的七个字母，代表从理念到实施的每个阶段的详细指导，这是我们过去十年数字化转型经验的结晶。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/29/29c157e211a188bf4462127c9ee50c6c.png\" /></p><p></p><p>在实施任何变革时，唯物辩证法强调量变是质变的前提。微卡片平台之所以成功，正是因为我们在过去几年中不断坚持打造这个平台，现在已经有 35,000 张微卡片投入生产，复用率高，使用频繁。这些详细的数据展示了产品的功能性和实用性。要实现这样的成果，需要投入时间和精力，最重要的是确定方向并全力以赴。</p>",
    "publish_time": "2024-09-02 16:00:34",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Runway“跑路”了？！ 全部开源模型删除，网友：名字果然没骗人！",
    "url": "https://www.infoq.cn/article/sZO4RErH2ZbKgCZfoEmw",
    "summary": "<p></p><h2>Runway 删库跑路</h2><p></p><p>&nbsp;</p><p>当地时间8月30日，InfoQ获悉，知名生成式 AI 平台 Runway已经删除了其在Hugging Face上的库，页面已经空空如也。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e2/e2bbdb330183ca54612eaed760ef97f1.png\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>就连Runway参与的知名AI项目也跟着一起404消失不见了。</p><p>&nbsp;</p><p>页面上只留下了一句话：“我们不再对HuggingFace账号进行维护。”</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b6/b60ab3077a252982527658a1be23b301.png\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>针对这些举措，Runway没有给出任何通知，而上个月的下载量还足足有百万之多。突然删除掉这些开源模型之后，网友们才意识到他们没有对Runway的开源模型进行备份。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dd/dd236b2a5fe0c30ef226362e24e40a96.jpeg\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>如此突然而不做解释的删除开源库，对开源社区和开发者来说是非常不负责任的。不少网友也担心自己需要更换模型，但不幸的是目前似乎很难找到值得信任的备份，所以有网友评价说：“这就是我们为什么需要一个去中心化的模型权重托管解决方案。”</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/42/421e9c976f21c2d1912a7a65c3f262ed.jpeg\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>生成式AI独角兽的开源纠葛</h2><p></p><p>&nbsp;</p><p>Runway成立于2018年。公司创始人兼首席执行官Cristóbal Valenzuela Barrera在创办公司之前，花了大量时间研究计算机视觉在图像和视频中的应用。他对计算创作的新范式以及神经网络技术在艺术创作中的潜力深感着迷。为了深入研究这一领域，Barrera全职就读于纽约大学的互动电信项目（Interactive Telecommunications Program），专攻计算创作。在纽约大学期间，他结识了Alejandro Matamala（首席设计官）和Anastasis Germanidis（首席技术官），并共同研究了机器学习模型在创意领域中用于图像和视频分割的应用。</p><p>&nbsp;</p><p>当时正值TikTok迅速崛起并与Musical.ly合并之际，这三位创始人决定成立Runway——一家致力于为视频创作者开发由机器学习驱动的工具的初创公司，同时还专注于这些工具背后的技术开发。</p><p>&nbsp;</p><p>Runway最初于2019年作为一个模型目录推出，允许用户部署和运行各种用于艺术创作的开源模型。随着用户群的不断扩大，这家初创公司逐渐转向开发基于机器学习的视频编辑工具。在创始人的最初构想中，他们对用户如何使用他们的平台持开放态度。</p><p>&nbsp;</p><p>随后，Runway迅速成为了生成式AI的独角兽之一。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/9664bfab130200e97f1d3f26ac8908cc.png\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>根据公开研究数据，Runway除了吸引“专业消费者”（prosumers），如今也正逐步获得企业客户的青睐，其解决方案的价值已达数十亿美元，并被New Balance、CBS、Ogilvy、VaynerMedia和Publicis等公司使用。</p><p>&nbsp;</p><p>Runway还推出了Runway Research。Runway Research与多所知名大学合作，发表AI领域的论文，并将研究成果融入其产品中。这其中就包含了与由Stability AI、慕尼黑大学合作的Stable Diffusion模型。</p><p>&nbsp;</p><p>为了训练Stable Diffusion，研究团队动用了 4000 个 A100 Ezra-1 AI 超大集群，而 Stability AI 公司正是这些算力的提供者。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2c/2c51676a4d86aad9b45af83eb345b0e5.png\" /></p><p></p><p>&nbsp;</p><p>该模型的代码在CreativeML Open RAIL M License下开源，Runway的首席执行官Cristóbal Valenzuela在发布SD 1.5时强调了Runway的“赋能任何人创造不可能”的使命。</p><p>&nbsp;</p><p>然而开源这件事也让Runway与Stability AI发生了冲突，导致两家公司从合作伙伴变成了对手。根据Hugging Face的首席技术官Julien Chaumond的说法，Runway选择开源SD 1.5后，他们就收到了Stability AI提交的撤下Runway ML的SD 1.5模型的请求，因为Stability AI的法务团队称Runway涉嫌侵犯知识产权。</p><p>&nbsp;</p><p>Runway的首席执行官Cris在Hugging Face的讨论中否认了这一知识产权泄露指控，并感谢Stability AI捐赠计算资源，帮助重新训练了原始模型。</p><p>&nbsp;</p><p>虽然Stability AI最终撤回了撤下请求，但这也并不意味着事情得到了完全解决。所以，现在Runway下架SD 1.5，有一个猜测就是可能还是因为这次开源纠纷。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3e/3e347bbdcc462f70371220f867b90b37.jpeg\" /></p><p></p><p>&nbsp;</p><p>而另一个说法是，有些人认为目前的一些开源项目从SD 1.5中借鉴了太多：免费的开源竞争对手威胁到了Runway盈利丰厚的在线视频生成器，因此Runway撤回了对开源的所有支持。</p><p>&nbsp;</p><p>不止一位网友提到了前几天开源的CogVideoX，这款开源文本转视频模型，声称可能会颠覆由 Runway、Luma AI 和 Pika Labs 等初创公司主导的人工智能领域。</p><p>&nbsp;</p><p><a href=\"https://huggingface.co/spaces/THUDM/CogVideoX-5B-Space\">CogVideoX</a>\"是由清华大学和智谱 AI 的研究人员共同开发的一种新型文本生成视频模型，它被寄希望于可能彻底改变视频创作并使先进的 AI 功能民主化。</p><p>&nbsp;</p><p>CogVideoX项目地址：<a href=\"https://huggingface.co/spaces/THUDM/CogVideoX-5B-Space\">https://huggingface.co/spaces/THUDM/CogVideoX-5B-Space</a>\"</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/29/292e5974ef9d240463ddb945a740b0f5.jpeg\" /></p><p></p><p>&nbsp;</p><p>该开源模型可根据文本提示生成长达6秒的高质量、连贯的视频，可与 Runway、Luma AI 和 Pika Labs 等公司的专有系统相媲美。</p><p>&nbsp;</p><p>最先进的版本 CogVideoX-5B 拥有 50 亿个参数，以每秒 8 帧的速度生成 720×480 分辨率的视频。根据研究人员的基准测试，该模型在多个指标上均优于 VideoCrafter-2.0 和 OpenSora 等竞争对手。</p><p>&nbsp;</p><p>然而，对Runway造成威胁的远不止 CogVideoX一个。</p><p>&nbsp;</p><p>不久前，初创公司 Black Forest Labs 刚因其为伊隆·马斯克的 AI 图像生成器提供技术支持而登上国外各大科技新闻头条。据悉，xAI公司也将采用背后有Black Forest Labs 文本生成视频技术支撑的“反觉醒聊天机器人”，这种消息对Runway来说不是个好消息。</p><p>&nbsp;</p><p></p><h2>AI大模型赛道竞争愈发激烈</h2><p></p><p>Runway删库现象或许只是当前AI大模型赛道的一个缩影——没有过硬的技术和盈利能力，想活下去很难。</p><p>&nbsp;</p><p>近期就出现了大模型背后公司集体求卖身的情况。</p><p>&nbsp;</p><p>6月，Stability AI就被传出了资金链断裂，正在寻求合并的消息。此外，有媒体爆料，另一AI 独角兽 Adept 领导层与科技巨头公司就出售或战略合作可能性进行了谈判。据悉，Adept 已经和 Meta 进行过沟通。</p><p>&nbsp;</p><p>Adept 由 OpenAI 的原工程副总裁David Luan，与两位谷歌Transformer架构的提出者Ashish Vaswani 和 Niki Parmar 联手创立。目前，Ashish Vaswani 和 Niki Parmar已经离开创立了另一家公司，Adept的三名联创只剩下华人David Luan一人。</p><p>&nbsp;</p><p>此外，Pin背后的公司也在发布了一款产品后寻求收购。据知情人士透露，Humane 估值在 7.5 亿美元至 10 亿美元之间。</p><p>&nbsp;</p><p>Humane 由两位前苹果资深员工 Imran Chaudri 和 Bethany Bongiorno 创立，曾因明星创始人风靡一时，吸引了包括微软、高通，及OpenAI首席执行官山姆·奥特曼在内的多位重量级投资人的数亿资本注入。然而 Ai Pin 高达 699 美元的售价、需要额外月度订阅费才能维持正常使用以及封闭式操作系统 (ComOS) 都让消费者望而却步。产品本身的缺陷、软件的不成熟、高昂的价格以及订阅费用，共同导致了 Ai Pin 的快速陨落。</p><p>&nbsp;</p><p>国内也有类似情况。去年有媒体爆出，一家清华系AI大模型公司，寻求10亿人民币估值融资的同时，也在以1亿美金的价格探索并购机会，有消息传出，当时同样出自清华团队的智谱AI就曾就并购一事与之有过接触。</p><p>&nbsp;</p><p>可见，没有过硬的产品和技术，被市场淘汰只是时间问题。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.reddit.com/r/StableDiffusion/comments/1f4epto/runway_took_down_15_and_15_inpainting/\">https://www.reddit.com/r/StableDiffusion/comments/1f4epto/runway_took_down_15_and_15_inpainting/</a>\"</p><p><a href=\"https://venturebeat.com/ai/this-new-open-source-ai-cogvideox-could-change-how-we-create-videos-forever/\">https://venturebeat.com/ai/this-new-open-source-ai-cogvideox-could-change-how-we-create-videos-forever/</a>\"</p><p>&nbsp;</p>",
    "publish_time": "2024-09-02 16:05:53",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "5个月从0到1，Meta如何利用单体架构实现Threads的快速开发？",
    "url": "https://www.infoq.cn/article/4E3h1uiD5mlLx2zV5wbo",
    "summary": "<p>2023年1月，我们获悉必须在短短数月内打造一款微博服务，以期与Twitter一较高下。为了应对这一挑战，我们迅速组建了一支精干的团队，并在7月份成功推出了一款全新的社交网络应用。本文将回顾我们去年在Meta如何开发并上线了Threads应用。</p><p></p><p>本文是对我在2024年伦敦QCon大会上所做演讲<a href=\"https://qconlondon.com/presentation/apr2024/0-1-shipping-threads-5-months?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MjUyNDkxNzQsImZpbGVHVUlEIjoiVk1BUEw1WVFHMkNqTVBBZyIsImlhdCI6MTcyNTI0ODg3NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo4MDExN30.u8jk91bskyOtVtEcHSBdyNK61WJuy9olpH1it8xmyDo\">“从0到1——5个月交付Threads应用”</a>\"的总结。</p><p></p><p></p><h2>价值和里程碑</h2><p></p><p></p><p>新的Threads应用将为用户提供四个基本价值。</p><p></p><p>首先，我们强调文本内容。与Instagram将媒体内容作为核心不同，Threads的每一篇帖子都从文本开始。</p><p></p><p>其次，我们希望延续Instagram的设计语言和精髓。Instagram之所以受到全球众多用户的喜爱，其简洁性与产品质感功不可没。我们觉得这是一个很好的基础。</p><p></p><p>第三，我们知道早期Twitter确立其地位的一个价值是开放性。我的意思是，社区可以自由地使用API来创造个性化的体验。公共内容通过网页嵌入的方式变得广泛可及。人们通常使用这些工具在各个地方分享他们的Twitter feed。尽管我们正步入一个由生成式AI引领的新时代，但我们坚信，封闭花园式的产品设计已不再适应潮流。</p><p></p><p>最后，我们认为我们需要优先考虑创作者的需求。在每个社交网络中，总有一群用户，他们创作了大部分其他人消费的内容。这种现象通常遵循Zipfian指数分布。在以文本为主的社交网络中，这一现象更加显著，因为生产大部分内容的用户群体比例更小。要在有限的字数（如500字）内创作出既有趣又吸引人的内容，无疑是一项挑战。我们深知，充分考虑并满足这个群体的需求对于实现长期的成功至关重要。</p><p></p><p>基于这些价值主张，我们勾勒出了绝对最小产品（MVP）的蓝图，并开始着手构建。我门的一个关键目标是尽快推出一个可交付的产品，这样就有选择的余地。</p><p></p><p>为了给自己设定明确的目标，我们详细规划了四个期望达成的里程碑。每个里程碑都被设计成一个潜在的完成状态，也就是说，在必要时，我们可以在达到每个里程碑时选择发布产品。每个里程碑都逐步引入下一个最关键的功能。</p><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/65/65357e27ba3b9e36de07d6905a214b25.webp\" /></p><p></p><p></p><p>第一个里程碑只构建最基础的应用。它看起来非常简陋，用户可以登录、发表一个纯文本的帖子，并将这些帖子与他们的账户关联起来。</p><p></p><p>第二个里程碑是为应用程序添加基本要素。在这个阶段，我们为应用程序添加熟悉的样式，有用于浏览动态、查看通知和访问个人资料的标签。让用户验证、阻止功能和报告功能发挥作用。</p><p></p><p>第三个里程碑是我们所说的“精简启动候选”阶段。在这个阶段，我们专注于完善那些之前可能被忽视的服务功能，例如人物搜索功能，以及引入全屏查看器来更好地查看照片和视频。我们开始深入探索如何管理对话内容，这是应用程序的核心。如何将它们作为单元进行排序？从Instagram复制关注内容，这样就可以快速设置个人资料。这是一个包含了多项改进的清单。</p><p></p><p>第四个里程碑是实现与Fediverse（联邦宇宙）的互操作性，这标志着我们的产品接近最终的发布候选状态。对于那些了解这款产品的人来说，我们的雄心壮志看起来可能有些不切实际，因为即便到了今天，我们也没有完全实现与Fediverse的互操作性。但因为太过于乐观，我曾承诺我们能在一个月内完成这项工作。</p><p></p><p>随着每个里程碑的临近，我们的心态从专注于构建功能转变为精心打磨产品，以便为发布做好准备。对于工程师来说，这种转变实际上是相当耗费精力的，因为在构建和修改之间频繁切换令人感到疲惫。在某种程度上，我们在那六个月的时间里发布了三个不同的产品版本。每次发布前，我们都会组织一个紧急会议，团队成员们熬夜工作，全力以赴地推动一个完整的应用程序达到发布标准。然后，我们会集体决定是否已经准备好将产品发布出去。</p><p></p><p>事后看来，这种策略带来了一个显著的优势：作为一个强有力的简化工具。如果你只有三周时间来决定哪些功能是必须添加的，哪些能够带来最大的增量价值，你就不得不将选择范围缩小到最核心的要素。我们最终发布的产品可以看作是3.5版本的里程碑。虽然我们从未达到4.0版本的里程碑，但确实在3.0版本的基础上实现了一次非常关键的迭代。</p><p></p><p></p><h2>加快开发速度</h2><p></p><p></p><p>在短短五个月内从零开始开发Threads无疑是一项雄心勃勃的挑战。我们的项目于二月份正式启动，并向领导层做出了夏季前准备就绪的承诺。我们的信心源于我们知道我们可以很好地利用Instagram已有的一些东西。</p><p></p><p>从宏观角度看，Instagram上的分享功能非常直观。用户可以关注感兴趣的个人资料，浏览他们的帖子，同时系统还会推荐相关内容。用户之间可以互动，围绕共同兴趣构建社区。有趣的是，这些功能正是我们在Threads项目初期想要实现的，因此我们巧妙地重用了它们。</p><p></p><p>我们的第一个原型在Instagram原有的动态信息流中引入了一个模块，用于展示纯文本帖子。我们重用了已有的排名机制。对于帖子的布局，我们内部开玩笑说，我们只不过是重新排列了一下。我们将标题置于顶部，而将内容则置于下方，其余部分保持不变。这样的变化显著降低了技术实现的复杂性。</p><p></p><p>我们成功地将构建一个全新的基于文本的社交网络的复杂问题转化成一个具体的问题，即如何定制Instagram的信息流来展示新的文本帖子。</p><p></p><p>作为工程师，你可能会意识到这种方法存在一些缺陷。当你利用已有的代码库来构建新功能，你可能会积累大量的技术债务，尤其是如果这个代码库并非为新的服务而设计。这将导致一系列小问题的出现。此外，你还需要对庞大的遗留代码库有深入的了解，它可能包含数百万行代码，但你真正需要定制的只是其中的一小部分。对于这一点，我喜欢引用一句话：“阅读别人的代码比编写自己的代码要困难得多。”</p><p></p><p>我们借鉴了Instagram的设计，并始终坚持这一原则，尽可能地进行精准的复用，只在必要时才进行重新构建。</p><p></p><p>这也意味着对于Threads团队来说，有很多值得感激Instragram的地方。Threads在很大程度上得益于Instagram基础设施和产品团队多年来打下的坚实基础。没有这些基础，我们的成就将无从谈起。我倾向于认为，我们对简洁性的追求已经得到了回报。我们在发布时收到的许多赞誉，正是因为应用程序的简洁明了，但又不会让人感觉缺少基本的功能。</p><p></p><p></p><h2>Threads的技术栈</h2><p></p><p></p><p>以下是Threads技术栈的概览。</p><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1a/1a0a2b1cea9299151a7332fbd2f50f40.webp\" /></p><p></p><p></p><p>Meta通常非常重视单体二进制文件及其单体代码库。这样做有着多重考量。其结果是，Instagram的大部分业务逻辑都集中在一个叫作Distillery的Python二进制文件中，这个文件与Meta更大的单体——一个庞大的PHP或Hack二进制文件WWW——通信。Distillery可能是世界上最大规模的Django部署之一，我不知道我们是否应该为此感到自豪，尽管我们运行的是一个定制版本。</p><p></p><p>我们用户的数据被存储在多个系统中。其中最关键的是TAO（一个写入缓存系统，基于图数据模型）和UDB（一个分片的MySQL部署，几乎包含了我们所有的数据）。TAO天生就擅长处理节点之间的链接，并且拥有优化的操作来查询这些链接的细节。此外还有一个索引系统，你可以标记特定的链接和你希望怎样查询它们。这些索引被放在内存中，可以提供快速的查询支持。整个模型是Meta多年社交产品构建经验的结晶，对我们非常有用。</p><p></p><p>我们的架构还涉及了其他一些重要的系统，我无法在此一一详细说明。例如，我们有一个大型的Haskell服务，它负责处理我们决策过程中的许多规则，包括识别用户行为中的异常模式。我们有一个叫作ZippyDB的键值存储来存储大量瞬态数据，这些数据的写入频率极高，超出了MySQL的处理能力。我们还有一个无服务器计算平台，它支持异步操作，这一点非常关键，我稍后会介绍。最后，我们还有一个类似于Kubernetes的系统，负责管理、部署和扩展所有这些服务。所有这些系统都必须协同工作，以确保整个平台的高效运行。</p><p></p><p></p><h2>发布</h2><p></p><p></p><p>7月5日，非工程师团队在产品上与早期使用这款产品的名人愉快互动，这或许是他们与夏奇拉亲密对话的难得机会。与此同时，工程师们全力以赴为次日的产品发布做准备：给系统括容，精心规划发布前的演示，确保一切准备就绪。</p><p></p><p>当天，我们的一位数据工程师在聊天中突然插话，提到了一些异常情况。他发现我们的应用程序记录了数万次登录失败的尝试。这很奇怪，因为理论上还没有人——更不用说数万人了——能够访问我们的应用程序。我们迅速调整方向，排除了数据出错的可能性。随后，我们注意到这些尝试都来自东亚地区。你可能已经猜到了，这实际上是一个时区问题。具体来说，我们利用了App Store的预购功能，允许用户在应用程序正式发布时注册下载。你可以指定一个日期。我们设定的是7月6日，这意味着这些国家在午夜之后应用程序就会变得可用。然而，由于我们这边的访问限制还没有放开，所以他们无法登录。这是一个尴尬的时刻。</p><p></p><p>那种在内部有限测试中所感受到的安全感已经荡然无存。我们迅速组建了一个紧急战情室，并召开了一个Zoom电话会议，召集了来自公司各地的近100名专家，他们分别代表了之前提到的各种系统。考虑到这是那些国家的深夜，我们清楚地意识到，一旦服务全面上线，实际需求将远远超出我们的预期。</p><p></p><p>我们已经积累了一大批预购用户，他们将在当地时间午夜之后访问应用程序。为了应对这一挑战，我们重新选定了一个目标发布时间，特别选择了英国时间的午夜，这为我们争取到了宝贵的几个小时准备时间。在这段时间里，我们扩大了所有Threads服务所涉及的系统容量。对信息流功能至关重要的ZippyDB缓存系统需要进行重新分片才能应对预期流量的激增——它需要处理的容量是当前配置的100倍。这项紧急任务在马克宣布Threads开放注册的几分钟前才完成。我想，我永远也不会忘记那种紧张到最后一刻的感受。</p><p></p><p>一个挑战是将Instagram的关注者网络复制到Threads上。这里的问题在于，用户可能想要关注那些尚未注册Threads的人。这导致了一个问题：等待某些知名人士（比如前总统奥巴马这样的大名人）注册的人数数量庞大，他们的粉丝数量都以百万计。我们最初设计的系统显然无法应对这种规模。为了解决这个问题，我们迅速重新设计了那个系统，让它能够水平伸缩并形成工作节点集群，从而能够处理这些账户背后的庞大关注队列。</p><p></p><p>这几天的经历令人难忘，我相信我可能再也不会遇到如此紧张的产品发布过程了。我从他人身上学到了很多关于如何保持冷静和优雅的宝贵经验。无论我未来走到哪里，这些经验都将是我宝贵的财富。</p><p></p><p></p><h2>结论</h2><p></p><p></p><p>总的来说，启动这个项目对我来说是一次非常独特的体验。我最大的收获是认识到保持事物简单的重要性。这当然不是一件容易的事。那句关于写一封更短的信需要花费更多时间的格言，适用于任何创造性的工作。如果你清楚自己想要提供什么样的价值，它就能指导你在需要做出艰难决策时如何精简和聚焦。</p><p></p><p>另一个深刻的教训是，更干净、更新的代码并不一定总是更好的。所有这些细微的洞见都融入了一个经过实战考验的旧代码库中。如果有可能，不要轻易丢弃这些东西。与此相辅相成的是我们的信条：“代码胜于雄辩”。通过构建产品来实际解决问题，通常比进行抽象的分析更能有效地回答疑问。我们通过原型而非幻灯片更快地解决了很多棘手的问题。</p><p></p><p>当然，我们所取得的成功不能一概而论，因为我们必须认识到，我们对机会的把握以及产品发布后市场的反应可能是因为我们的运气。这一切都无法事先得到保证。我非常感激那些接受我们产品的社区成员。我们有一个说法，可以追溯到Facebook的早期，那就是这段旅程只完成了1%。对我来说，尤其是对Threads而言，这种感觉尤为真切。</p><p></p><p>【声明：本文由InfoQ翻译，未经许可禁止转载。】</p><p></p><p>查看英文原文：<a href=\"https://www.infoq.com/articles/shipping-threads-5-months/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MjUyNDkxNzQsImZpbGVHVUlEIjoiVk1BUEw1WVFHMkNqTVBBZyIsImlhdCI6MTcyNTI0ODg3NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo4MDExN30.u8jk91bskyOtVtEcHSBdyNK61WJuy9olpH1it8xmyDo\">https://www.infoq.com/articles/shipping-threads-5-months/</a>\"</p>",
    "publish_time": "2024-09-02 16:19:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "工业制造的智能化转型：从传统决策到运筹优化",
    "url": "https://www.infoq.cn/article/tYRyoEcqiw6XlOEHatzQ",
    "summary": "<p>随着工业智能化和数字化转型的深入推进，制造业企业在决策管理中面临越来越复杂的挑战。传统依赖人工经验的决策模式，已难以适应当前多品种、小批量的生产需求。在这种背景下，智能决策技术，特别是基于运筹优化和人工智能的高级计划与排程（APS）系统，逐渐成为推动企业降本增效、提升运营效率的关键工具。</p><p></p><p>在 6 月举办的 ArchSummit 全球架构师峰会上，清智优化董事长兼总经理蒙绎泽博士分享了主题演讲《企业全层级决策管理智能优化平台助力企业降本增效增收》。其详细探讨了智能决策的发展历程及其在制造业中的应用，重点介绍了运筹优化技术的理论基础、求解方法及其在实际项目中的落地应用。通过对典型案例的阐述，展示了智能优化平台如何在复杂的工业场景中发挥作用，从而为企业提供全面、优化的决策支持。</p><p>以下是演讲实录（经 InfoQ 进行不改变原意的编辑整理）。</p><p></p><h2>智能决策发展历史</h2><p></p><p>尽管数字化转型、工业化和智能化已经发展了很多年，但在许多制造业企业，尤其是一些领先的企业中，仍然存在许多依赖人工决策的环节。例如，在制定生产计划、采购和物流运输计划等方面，仍然存在依赖经验进行决策的现象。在当前多品种、小批量的生产方式下，人工决策不仅耗时长，而且质量也难以保证。这是因为决策空间规模和计算复杂度随着产品种类的增加而呈指数型增长。</p><p></p><p>目前，工厂基本上具备了柔性生产能力，但多种因素的叠加使得传统人工决策面临许多局限性。虽然企业已经采用了 ERP 和 MES 等系统，主要用于记录和执行流程，系统也可能包含一些基于规则的简单排产和决策逻辑，如先进先出（FIFO）等，但这些简单规则的能力非常有限，不能支持复杂的调度问题。</p><p></p><p>我们的目标是基于运筹优化技术，结合人工智能技术，全面考虑经营过程中的决策要素，实现整体最优化的解决方案，从而显著降低成本并提高效率。</p><p></p><p>APS（Advanced Planning and Scheduling，高级计划与排程）有狭义和广义之分。狭义的 APS 主要指的是车间生产计划排产，这通常包括 AP（Advanced Planning，高级计划）和 AS（Advanced Scheduling，高级排程）。我们重点聚焦于工厂内部的生产计划。广义上的 APS，其应用范围可以扩展到整个供应链管理，覆盖更广泛的功能和领域。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2f/2f91088623f3b76fe07b01f818e721b6.png\" /></p><p></p><p>我们的定位是将 APS 视为智能工厂的大脑。在智能工厂的架构中，ERP（Enterprise Resource Planning，企业资源计划）、MES（Manufacturing Execution System，制造执行系统）、WMS（Warehouse Management System，仓库管理系统）和 CRM（Customer Relationship Management，客户关系管理）等系统主要负责数据和单据的记录。而我们的 APS 系统则是在这些系统之上，进行计划的执行。具体来说，数据从这些系统上传至 APS 后，我们会进行最优运算，生成最优细化计划，并下发执行，以替代人工计划环节。这个过程涉及到如何制定最优计划，而最优计划通常能够为客户带来显著的效益，包括计划调度、仓储库存、运输调度等场景。</p><p></p><h4>关于运筹优化技术</h4><p></p><p>运筹优化是一门起源于二战期间的学科。它主要研究的是如何在资源有限的系统中，利用数学优化算法来制定人力、物力和财力的最佳调配方案，目的是使整个系统的效益达到最大化。运筹优化技术涵盖了多种核心算法和技术，包括规划论中的整数规划、非线性规划、动态规划、图论、组合优化以及库存论等技术。</p><p></p><p>典型的优化问题通常包括一个优化目标以及多个约束条件。依据变量和约束条件的特点，可以将其分为四类主要的规划模型：线性规划、整数线性规划、非线性规划和混合整数非线性规划。</p><p>在这些模型中，MIP（混合整数规划）是最常用的一种。它指的是问题中的决策变量具有离散特性，同时约束条件是线性的。在实际应用中，许多不同类型的问题最后都可能被转化为 MIP 问题来求解，这是因为 MIP 模型能够在保持约束条件线性的同时，处理决策变量的离散性，从而找到最优或近似最优的解决方案。</p><p>在运筹优化领域，求解器扮演着至关重要的角色。它是一个专门用来求解规划模型的算法包。我们可以将求解器比作一个高级计算器，当我们将规划模型输入其中，它能够快速地为我们提供最优解或可行解。</p><p><img src=\"https://static001.geekbang.org/infoq/7f/7f3f7306b0e120f931aafbdf5132f6f0.png\" /></p><p></p><p>求解器内部集成了多种优化算法，这些算法各具特色，能够应对不同类型的优化问题。其中，分支定界和分支定价是最典型的算法。分支定界通过系统地探索解空间的各个部分来找到最优解，而分支定价则是一种用于解决整数规划问题的有效方法。除了这些，求解器还可能包含一些启发式算法和梯度下降等数值优化方法。</p><p></p><p>解决运筹学问题通常涉及四层抽象。对于业务人员，他们接触最多的是第一层，即实际的商业问题。例如，作为工厂的总监，他们需要决定如何为工人排班，或者如何选址建立工厂设施。这些是工厂日常运营中可能面临的决策问题。</p><p></p><p>第二层是通用问题，我们需要先将问题抽象为通用性问题。这些问题可能类似于旅行商问题、最短路径问题或图着色问题。</p><p></p><p>第三层抽象是对问题的建模范例，确定它属于哪一类优化问题，比如是混合整数规划（MIP）、线性规划还是非线性规划。</p><p></p><p>第四层抽象是求解器和求解算法。所有问题最终都归结到求解层面。这包括使用不同的搜索排序技术、Benders 分解以及分支定界等方法。</p><p></p><p>运筹学项目的实施方法论通常包括以下几个关键步骤：</p><p>数据初步分析，驱动算法设计：首先，我们需要收集相关的基础数据，并对其进行分析以获得初步的见解。这一步至关重要，因为现实生活中的许多问题都是 NP 难问题，直接求解可能需要很长时间。通过从数据中提取见解，我们可以简化模型求解过程，利用数据的性质来加速求解。设计和建立高效数学模型：接下来，我们需要设计和构建针对实际问题的高效数学模型。运筹学同行都知道，模型的建立有高效和低效之分，同样一个问题的不同建模方式计算效率可能天差地别。分析模型结构及难易程度：模型建立后，我们需要分析模型的结构以及解集的性质，为设计求解方法打下基础。设计求解方法：这一步涉及到选择合适的求解器、设计求解框架，决定是使用启发式算法还是精确求解，是否需要分阶段求解。求解器是一个工具，但并非万能，还需要结合其他技巧来高效求解。代码实现：将设计好的求解方法转化为代码实现，并进行初步求解，得到计划结果。数据审查和校验：对初步求解结果进行审查和校验，这可能涉及到与现场实施人员的沟通。算法性能分析：对求解算法的性能进行分析，以评估其效率和准确性。迭代优化：与现场业务人员反复确认，因为业务人员提出的需求可能并非其真正需求。通过不断展示结果，帮助他们逐渐明确真正的需求。回测对比和效益提升：进行回测对比，计算效益提升，并给出管理建议。</p><p></p><p>运筹优化模型的计算原理涉及到在求解过程中对搜索空间的逐步削减。这个过程通过不断缩小搜索范围，使得算法的上下界之间逐渐收敛。随着算法的进行，搜索空间被逐步缩小，最终收敛到一个较小的区域，从而得到一个高质量且符合要求的结果。理想情况下，这种优化算法能够达到与穷举法相同的效果，即找到最优解或近似最优解。但是，优化算法能够在较短的时间内找到高质量的解决方案，提高求解效率。</p><p></p><h2>企业全层级决策管理的智能优化平台</h2><p></p><p></p><p>整个智能优化平台的架构设计包括几个关键层次。首先，底层是场景和行业的模板。这些模板内置了典型行业的约束和工艺要求，例如石化行业的效益测算模型、智能配料或机加工行业的通用排程模板。</p><p>接下来，在这些模板背后，是为特定场景定制的求解器、模型库和算法模块，包括整数规划模型、启发式算法等。</p><p></p><p>最后，平台还包括数字孪生系统。这个系统允许用户对不同的方案进行手动比较，这对于实际应用中的问题解决非常关键。在实施过程中，可能会遇到现场人员质疑为什么平台会得出某个特定的解，他们可能认为自己的方案更好。面对这种情况，数字孪生系统可以让他们展示自己的方案，并计算评价指标，然后与平台的解进行比较。通过这种比较，他们往往会发现，尽管他们认为好的方案在某些方面可能更优，但在许多关键指标上却表现不佳。我们通常通过展示这些结果来说服客户，证明平台的解决方案在综合考虑多个关键指标后，能够提供更优的整体效益。</p><p></p><p>整个技术体系的底层涉及数据的获取，这些数据包括销售订单、生产订单、物流以及采购信息。这些数据通常从 ERP（企业资源计划）和 MES（制造执行系统）等系统中上传。在此基础上，我们构建了内置的优化模型，涵盖采购优化、计划排产、需求预测和经济效益优化等方面。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ac/acf933d01424ed213daf3f8a4133131b.png\" /></p><p></p><p>核心的分析和求解过程包括几个关键步骤。首先，需要与客户一起确定约束条件，这些条件必须是定量的，并且以白盒式的方式明确。其次，明确优化目标，比如客户最关心的 KPI 是什么，是设备利用率最大化还是成本最小化。如果存在多个目标冲突，需要设定权重，以避免不必要的争议。</p><p></p><p>优化算法的设计是我们团队的强项。我们能够为多个行业和场景提供优化解决方案。例如，在能源行业，我们可以进行管网运营优化；在新材料行业，可以进行套切配分优化和工程塑料排产；钢铁和电子行业也可以通过我们的技术进行优化。这些优化功能包括计划调度排班优化、仓储库存优化以及运输路径计算等。</p><p></p><h4>典型案例一：某企业天然气管道运输优化</h4><p></p><p></p><p>首先，该企业的痛点在于中国的天然气管道网络覆盖广泛，但目前主要依赖 Excel 进行管理和决策，并由人工负责每个片区，各自为政，各个链条之间没有联通。因此，需要建立一套生产、运输、销售、存储、贸易一体化的优化模型。我们需要在满足约束条件下基于稳态计算各个节点的最优参数，实现降本增效的目的。投建规划同样问题复杂，主要难点在于系统规模日趋复杂，这虽然是网络流问题，但比传统网络流要复杂得多。原因在于压缩基站本身有复杂的工艺约束，气体在管道内流动需要满足流体力学方程，因此数学求解难度呈指数级增长。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/18/18a7ff96786312c334d05ee14a81f5e5.png\" /></p><p></p><p>结果方面，我们搭建了天然气全业务链条的优化技术体系，研发了适用于任意拓扑结构的天然气管网优化平台，解决了常用模型难以处理低时差和温度变化的问题。我们设计了一种针对上千节点大规模管网规划的特殊凸优化松弛算法，两年内为他们节省了 20 亿元人民币，主要通过优化压缩机的控制参数，降低能耗，同时满足任意时期客户的需求，提升了整个网络的运行效率。</p><p></p><p>在建模方面，我们建立了天然气管道网络的整体运行模型。这包括流量、流向和压力等约束的建模，以及管网的网络结构建模和多级体系的融合分析。目标函数方面，涉及多目标优化。例如，有些方案侧重于能耗优化，有些侧重于效益优化，还有一些考虑路径优化或负荷优化。</p><p></p><p>由于具体的模型主要由公式组成，我们需要关注其表达的含义，从三个层面来说明。</p><p></p><p>首先是决策变量。我们计算的决策点包括各个节点、各个时间段的压力情况、供给情况；各条线路各时间段的流向流速；以及各个储气站的库存注入量和出入量等。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d2/d237685bf651447f4169b37134770227.png\" /></p><p>第二是优化目标。这是一个多目标函数。最主要的一层是能耗优化，例如压缩机的功率总和就是能耗。其次是运输路径优化，第三是负荷优化。还有一种目标是在满足网络所有运行约束的前提下，最大化管道输送的气量。此外，还有收益最大化的方案。收益是销售减去库存、运输能耗、生产注气等相关费用后的结果。</p><p>第三是约束条件。需要考虑流量平衡、各节点的供应生产和库存能力等约束。我们需要的数据包括各地区的预计需求量、管网的数据和节点的数据等。</p><p></p><p>针对非凸非线性可行域的快速求解模块的解过程简单介绍一下，因为算法相对复杂，具体细节可以参考相关论文。对于非凸非线性的可行域，我们的快速求解模块依靠两大核心技术：分段线性近似算法和凸优化松弛算法。这些方法可能有些复杂，我简单解释一下凸优化松弛的概念。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e6/e65f56dbceca08a16a73f86c31edb9fc.png\" /></p><p>如前所述，这是一个非凸非线性的问题，主要因为包含很多平方项、开方项或分式。例如，对于一个工作的压缩机，其功耗需要通过联立不等式计算。功耗是天然气流量乘以等熵头再除以压缩机效率，这些复杂关系使得问题变得非凸非线性。优化模型需要最小化所有压缩机的总能耗，这种情况下非凸非线性问题特征明显。</p><p></p><p>所谓凸优化松弛，是将原先非凸非线性问题中的一些项进行松弛处理，使其转化为凸优化问题。虽然这会改变问题的解空间，但通过迭代框架，可以让解尽可能收敛到原问题的解。转换成凸优化问题后，求解效率和速度大大提高。</p><p></p><p>我们也进行了应对流量不确定性的一些优化，建立了鲁棒优化模型。鲁棒优化的意思是，即使在最坏情况下，你的成本仍然是可以接受的。无论流量需求有多大波动，你的系统依旧可以稳定运行。</p><p>优化模型的特点是目标函数的多层次优化，可能是双层甚至三层结构。模型类似于一个网络结构，考虑中间的需求点（如 P1、P2）会有变化。我们的决策是在知道需求会变化的情况下、如何提前做计划。这是一个非常有实践意义的问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/99/994b77faeb042f3ee1977e291e60378a.png\" /></p><p>我们的一些求解思路包括使用子问题动态规划重构。这是因为该问题在数学上满足一些特性，如无后效性和最优子结构特性。因此，我们对其进行了动态规划重构，以解决维度爆炸的问题。在此过程中，我们定义了一些阶段和状态转移方程。关键是我们设计了一些加速求解的近似动态规划（ADP）方法。例如，我们使用领域搜索的思维，即在动态规划中，认为相邻状态的最优决策是相似的，因此在其附近进行搜索，提高求解效率。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6b/6b2fa81fda589775975d5b032da2679c.png\" /></p><p></p><p>在应用部分，我们最终建立了一个管网运营平台，用于计算每天如何运营压缩机站和分配网络流量。该平台可以进行气源价格平衡分析、管网建设时序优化，以及 n-1 供气场景的模拟。应用成效方面，平台可以设置液体流动的属性，两年内为他们节省了 20 亿元。这主要是由于优化了能耗部分。人工决策时，每个人只负责一小部分，难以做到全局最优。通过运筹学优化后，整体的累计效应非常显著。因此，越复杂的问题，通过运筹学方法解决，效果越明显。</p><p></p><h4>典型案例二：某知名烟草企业卷包排产</h4><p></p><p></p><p>第二个案例是我们为某知名烟草企业进行卷包机排产优化。他们面临的行业痛点是由于过去采用单一品种大批量生产的国家计划经济模式，决策空间有限，人工制定计划相对容易。但随着市场导向转变为多品种、中小批量的柔性订单生产方式，传统的手工排产方法已无法满足企业的发展需求。其次，与大多数制造业工厂一样，他们缺乏科学完善的评估指标和方法。不同排产人员的偏好和标准不统一，评估过程模糊不清、定性评价，这不利于企业实现数字化和智能化转型。</p><p></p><p>我们应用了智能排产的五步法：1. 明确关键目标、2. 识别排产要素、3. 搭建数据基础、4. 构建排产模型、5. 评估落地验证。 通过这些步骤，我们实现了显著的经济效益指标：排产速度从数小时提升到 33 分钟内，每月换牌次数显著减少。这些优化措施每年为企业节省了 1500 万元成本。</p><p></p><p>卷包排产的业务流程大致如下：首先，营销中心会根据各个品牌的规格，提出未来两个月的货源需求计划。接着，物流中心基于这些需求，制定相应的物流发货计划。随后，公司的生产管理部门会根据这些计划，下发一个主生产计划给各个工厂，这个计划同样覆盖未来两个月的生产需求。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0e/0ee6f12a88699db95e732a6453e014a1.png\" /></p><p></p><p>每个工厂在接到主生产计划后，会进行内部的详细规划。他们会根据粗略的生产计划，进一步考虑工厂的设备产能，包括品牌与机台的对应关系，以及工艺上的约束条件。基于这些因素，工厂会形成卷包机台的日排产生产计划方案。</p><p></p><p>最后，物资配送部在接收到这些生产计划后，会根据生产需求，制定原料调拨计划以及包括辅料在内的采购计划。</p><p><img src=\"https://static001.geekbang.org/infoq/59/59eac12672b4d5c9725a5e409c177887.png\" /></p><p></p><p>主要的生产流程包含几个核心工艺步骤，这些工艺构成了典型的连续流程型工业系统。核心工艺主要包括制丝、卷接和包装。尽管这是一个流程型的工业系统，但通过应用 APS（高级计划与排程）和优化算法，可以显著提高其效率，尤其是考虑到生产过程中多品种、小批量的特点。在这些工艺中，卷接和包装是核心环节，通常简称为\"卷包\"。卷接工艺的主要任务是将成品烟丝卷制成烟条，并与滤嘴进行对接。对接后的烟条经过切割，形成一定长度的卷烟。接下来是包装工艺，包括将切割好的卷烟装入小盒，然后装箱，完成整个生产流程。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/44/448ec525bee5940d263ccf9c097c9d2b.png\" /></p><p></p><p>车间的设备布局体现了卷烟生产的核心流程。卷包机组由卷积机和包装机组成，它们共同完成卷烟的卷制和包装过程。在卷包机组之前，是喂丝机和滤棒发射系统，这些设备负责将烟丝和滤棒准确地送入生产线。每个卷包机组内部设计为能够一次性加工一个卷烟品牌。然而，由于车间内部署了多台机组，这些机组可以同时工作，分别加工不同的卷烟品牌。这种布局允许车间灵活地处理多品种的生产需求，同时也构成了一个典型的排程问题。</p><p></p><p>在评价指标和方法的现状总结中，我们看到公司层面和工厂层面的考虑是不同的。这两个层面在评价指标上的差异有时会导致相互冲突的行为。目前，这些指标的设定并没有一个明确和统一的标准。评价方法大多基于人工经验判断。这种基于人工经验的判断方式，是典型的制造业头部客户的画像。然而，这种方法存在一些问题：</p><p>定性问题：由于依赖人工经验，评价结果往往较为定性，缺乏客观性和量化标准。各自为政：不同部门或个人可能会根据自己的理解和偏好来设定和执行评价指标，导致缺乏统一性和协调性。</p><p></p><p>工厂的卷包排产评价指标体系涵盖了多个方面，从公司角度和工厂内部角度出发，关注不同的指标。公司关注的指标举例：</p><p>货源供应管理：关注货源是否供应及时准确。生产控制管理：关注生产的控制达标率，即生产是否达到既定的质量标准。</p><p>工厂关注的指标举例：</p><p>生产连续性：对于流程型行业，工厂需要关注生产连续性，包括换牌时间和换牌次数。生产均衡性：工厂内部还需关注生产线的均衡运行情况，评估是否有产线长时间运行而有的产线却很少开启，以确保资源的合理分配。工作天数与设备利用率：工厂还需考虑生产计划的工作天数，以及设备的利用率。排产方式：在排产方式上，需要关注排产耗时，即完成排产所需的时间。人力资源：还需要考虑排产过程中的人力资源使用情况，如排产所需的人数。</p><p></p><p>我们建立了一套评价方法和权重体系，用于评估卷包排产的各个指标。通过层次分析法，我们确定了卷包排产的一级指标权重。例如，货源供应的权重被设定为 0.5，而生产连续性的权重则为 0.06。这些权重反映了不同指标在整体评价体系中的重要性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8a/8a724d002f0345a39b38f3710f610159.png\" /></p><p></p><p>由于这是一个多目标优化问题，我们采用了层次分析法来确定权重，确保评价过程的科学性和合理性。同时，我们也制定了具体的计算方式和扣分标准，明确了什么样的表现算是达标，什么样的表现则被视为不合格。这些标准都是定量的，便于在实际评价过程中进行操作和应用。</p><p></p><p>我们首先对卷包排产的约束条件进行了整理，关注点包括产能、机组与品牌的关系、保养计划、工厂日历以及唤醒时间等关键因素。在工艺方面，我们考虑了排产的互斥关系和排产量等要素，形成了一个模型数据清单。</p><p></p><p>基于这些数据，我们构建了多目标的 MIP 模型。然而，我们发现该模型的规模相当大，直接用 Gurobi 求解需要耗费数小时，这无法满足客户对求解时间的要求。为了解决这个问题，我们采取了将规划模型与启发式算法相结合的方法。</p><p></p><p>首先，我们基于 MIP 模型获得了一个不错的初始解，但这个初始解是基于简化模型得到的，一些约束在这个阶段并未考虑。接着，我们对初始解进行了调整，比如确保批次量符合整数倍的要求，并对这些约束进行了修复。然后，我们在每个机组内部搜索换牌时间最少的生产顺序，并通过不断合并和优化，逐步改进解决方案。我们还加入了产线均衡性的补丁，以进一步提高解决方案的质量。整个求解过程的外层循环旨在避免陷入局部最优解，并减少初始解质量对最终结果的影响。内层循环则是通过算法组合来计算产量的最优分配方案。</p><p></p><p>这个项目的算法优势在于其全面性和效率。首先，算法能够考虑所有的约束条件，确保排产方案的可行性。其次，算法的排产耗时极短，单个方案的生成时间在一分钟内，这大大提高了排产的效率。同时，算法不仅考虑了所有相关因素，还能快速输出多个备选方案，以及对各个关键绩效指标（KPI）进行统计分析。</p><p></p><p>在项目实施过程中，我们经常遇到数据多元异构的问题。数据来源多样，有的来自 ERP 系统，有的是手工维护，有的通过邮件发送，还有的存储在 MES 系统中。面对这种复杂情况，我们首先制定了统一的标准。早在 2019 年，我们的项目组就参与了国家智能制造数字化模型标准的制定工作，统一了数据清单，并尽可能将数据维护在一个平台上。</p><p></p><p>在经济效益分析方面，由于企业财务成本数据未细化，我们进行了粗略估算，得出了最低节约额度。通过减少换牌次数和优化工作天数，预计每年能为企业节约 1400 多万元。</p><p></p><h4>典型案例三：电子元器件高级排产</h4><p></p><p>这个案例是关于电子元器件高级排产的，客户是国内领先的元器件可靠性检测机构，主要负责对电子元器件进行老炼试验，这些元器件最终将应用于国防、军工和航天领域。</p><p></p><p>该场景是一个典型的离散制造场景。客户拥有老炼设备和大量的老炼集成电路板。每天，客户需要处理数万个元器件的老炼试验，这些元器件来自不同的客户，大约有 400 多条订单。首先，客户需要进行拆单和合单的操作，决定哪些订单可以放在一起进行试验，因为它们可能有不同的试验条件，如试验温度、电流和电压等。接下来，客户需要决策如何在集成电路板上排布这些元器件，以及如何将它们放置在老炼板上。老炼板背后有电源控制，存在一些复杂约束，例如相邻区位的电压差不能超过 5 伏，但同一设备内的温度必须相同，而电压可以不同。由于可能的排列组合数量很大，排产过程非常复杂。客户一次排产需要输出一个月的计划，考虑到试验跨度较长，这进一步增加了排产的难度。</p><p></p><p>在算法设计方面，我们采用了一种在不牺牲最优解质量的前提下，寻求近似最优解的方法。这种方法可以视为多阶段拆分，将整个排产问题分解成若干个小阶段来处理。在每个阶段中，模型会考虑一系列约束条件，包括订单分配的总量上限、可用资源的约束以及工艺约束等。</p><p></p><p>我们采用的松弛和近似算法，基于滚动排产模式。在这种模式下，只知道当天的需求，而未来的需求会存在不确定性。为了应对这种不确定性，我们在算法中加入了鲁棒优化的元素，以增强排产计划的适应性和稳定性。此外，我们的算法是一个嵌套算法，利用了 KKT（Karush-Kuhn-Tucker）条件和强对偶性理论。通过这些数学工具，我们将原始问题转化为一个更易于求解的形式。这样，即便在面对复杂约束和不确定性时，我们也能够找到一个可行且近似最优的排产方案。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cb/cb12370e60544329756a9d6fee75c9f4.png\" /></p><p></p><p>排产流程的核心优势在于其能够计算多个方案，并且能够根据实际情况每天进行调整。我们特别将这个流程与人工排产进行了对比，以评估其效果。通过对比过去三个月的数据，我们发现在器件总量上，a 室的生产量增加了 7%，而 b 室的生产量增加了 20%。如果考虑到单价的差异，换算成货币价值后，每个室每年可以增加 1,000 多万的效益。这一效益的增加主要是因为单位时间内能够试验的器件数量得到了提升，从而提高了整体的生产效率。通过优化排产，我们将将超期任务的器件数量减少了接近 100%。这展示了基于算法决策的魅力：算法不仅能够满足所有约束条件，还能在关键指标上实现最优解。</p><p>嘉宾介绍</p><p>蒙绎泽，清智优化创始人，教授级高工、正高级职称，工信部工业互联网创新发展工程项目课题负责人，本科及博士毕业于清华大学，香港大学博士后，上榜胡润 U30 中国创业先锋、中关村 U30、“科创中国”青年创业榜单—天津 U30、创业邦 30 Under30+ 创业先锋榜，入选天津市创业领军人才。</p><p>曾承担工信部工业互联网创新发展工程项目子课题建设，搭建了跨行业跨领域的集成供应链机理智能决策模型库，对跨行业跨领域跨区域精智工业互联网平台的有效性进行了全面试验测试，并且在冶金、化工、能源、机加工、装备制造等行业完成了应用推广验证。负责多个工业智能项目及工业大脑产品的算法设计和代码实现，落地数十个项目，成果显著。</p>",
    "publish_time": "2024-09-02 16:20:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "别让 Kubernetes 上的 Apache Kafka 让你丢掉工作",
    "url": "https://www.infoq.cn/article/LmPTR4mUTtpZvNNPqkqt",
    "summary": "<p></p><p></p><h2>01 TL;DR</h2><p></p><p></p><p>Apache Kafka 不是 Kubernetes Native 的数据基础设施。虽然 Kubernetes 作为云原生技术的集大成者，大大提升了企业在资源管理和 DevOps 方面的效率，但也对在其上运行的应用程序提出了新的挑战。为了充分发挥 Kubernetes 的潜力，其 Pod 需要能够在节点之间快速迁移和恢复。Apache Kafka 诞生于十多年前，设计初衷是面向传统数据中心（IDC）场景。其存算一体化的架构在云原生时代面临弹性不足、无法充分利用云服务、运维复杂、成本高昂等问题，使其难以很好地契合 Kubernetes 所遵循的云原生理念。在 Kubernetes 上使用非 Kubernetes Native 的 Kafka 服务将使得你的 Kafka 生产环境置于危险中，你必须小心翼翼地维护他来确保他的可用性与性能。稍有不慎，你可能为这些 Kafka 故障承担责任，丢掉你的工作。而 AutoMQ [1] 作为新一代基于云原生理念构建的 Kafka，很好地解决了这些问题，为用户提供了 Kubernetes 原生的 Kafka 服务。这篇文章将与你介绍在 Kubernetes 上部署 Apache Kafka 会带来什么问题，以及 AutoMQ 是如何解决它们的。</p><p></p><p></p><h2>02 什么是 AutoMQ</h2><p></p><p></p><p>AutoMQ[1] 是一款贯彻云原生理念设计的 Kafka 替代产品。其除了在 Github 上提供源码开放的社区版本 [2]，同时也在云上提供 SaaS 和 BYOC 的商业版本。AutoMQ 创新地对 Apache Kafka 的存储层进行了基于云的重新设计，在 100% 兼容 Kafka 的基础上通过将持久性分离至 EBS 和 S3 带来了 10x 的成本降低以及 100x 的弹性能力提升，并且相比 Apache Kafka 拥有更佳的性能。你可以通过以下的对比系列文章来进一步了解 AutoMQ。</p><p></p><p>AutoMQ vs. Apache Kafka [3]AutoMQ vs. WarpStream [4]AutoMQ vs. Amazon MSK [5]</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5d/5d73b523278b40384738ad26ecf9ab1d\" /></p><p></p><p></p><h2>03 什么是 Kubernetes Native Kafka</h2><p></p><p></p><p>Kubernetes Native[6] 的概念最早由 Redhat 的 Quarkus 提及。Kubernetes Native 是一种特化的 Cloud Native。Kubernetes 本身是 Cloud Native 的，其充分利用 CNCF 所定义的容器化、不可变基础设施、服务网格等云原生技术。Kubernetes Native 的程序拥有 Cloud Native 所拥有的所有优势。在此基础上，额外强调能够与 Kubernetes 可以进行更加深度的集成。而 Kubernetes Native Kafka 则表示可以与 Kubernetes 深度集成充分发挥 Kubernetes 全部优势的 Kafka 服务。Kubernetes Native Kafka 可以将 Kubernetes 的以下优势彻底发挥出来：</p><p></p><p>提升资源利用率：Kubernetes 提供了更细粒度的调度单元（Pod）和强大的资源隔离能力。容器化的虚拟化技术使得 Pod 可以在节点之间快速迁移；资源隔离确保同一节点上的 Pod 可以合理使用资源。结合 Kubernetes 强大的编排能力，可以大大提升资源利用率。屏蔽 IaaS 层差异，支持混合云避免供应商锁定：通过 Kubernetes 来屏蔽 IaaS 层差异，可以使得企业更加轻松应用混合云架构，避免供应商锁定，从而在采购云厂商服务时拥有更多的议价权。更加高效的 DevOps: 贯彻 Kubernetes 的最佳实践准则，可以让企业以 IaC 的方式来实现不可变基础设施，通过和企业内部 CI/CD 流程打通，利用 GitOps 结合 Kubernetes 本身提供的运维部署支持，可以大大提升 DevOps 的效率和安全性。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/dc/dc0debb10c10941bea0d7267381c09c9\" /></p><p></p><p></p><h2>04 为什么需要 Kubernetes Native Kafka</h2><p></p><p></p><p></p><h3>4.1 Kubernetes 在中大型企业中变得流行</h3><p></p><p></p><p>Kubernetes 在中大型企业中越来越受欢迎。对于这些企业来说，每天的资源消耗都是一笔不小的费用。通过将所有应用部署到 Kubernetes 上，可以显著提升资源利用率，实现统一标准化管理，并在 DevOps 过程中获得最大的好处。</p><p></p><p>当企业内的所有应用程序和数据基础设施都运行在 Kubernetes 上时，从公司战略角度来看，像 Kafka 这样的核心数据基础设施也应当运行在 Kubernetes 上。AutoMQ 服务的客户中，例如京东和长城汽车，从集团战略层面就要求 Kafka 必须运行在 Kubernetes 上。</p><p></p><p>此外，中大型企业相比小型企业更有混合云的需求，以避免供应商锁定的问题。通过利用多云策略，这些企业可以进一步提升系统的可用性。这些因素都进一步推动了对 Kubernetes Native Kafka 的需求。</p><p></p><p>总结来说，Kubernetes Native Kafka 能够帮助中大型企业在资源利用率、标准化管理、DevOps 效率、混合云策略和系统可用性方面获得显著优势，因此成为这些企业的必然选择。</p><p></p><p></p><h3>4.2 Apache Kafka 是 Kubernetes rehost，不是 Kubernetes Nativei Kafka</h3><p></p><p></p><p>虽然 Kafka 凭借其强大的生态能力，诞生了诸如 Strimz[12] ，Bitnami Kafka[13] 这样优秀的 Kafka Kubernetes 生态产品，但是不可否认的是 &nbsp;Apache Kafka 本质不是 Kubernetes Native 的。在 Kubernetes 上部署 Apache Kafka 本质是一种将 Apache Kafka 在 Kubernetes 上进行 rehost 的行为。即使配合 Strimz 和 Bitnami Kafka 的能力，Apache Kafka 仍然无法将 Kubernetes 的潜力全部发挥出来，包括：</p><p></p><p></p><h4>4.2.1 Broker Pod 无法在 Node 间进行性能无损的随意调度</h4><p></p><p></p><p>Apache Kafka 强大的吞吐能力和性能与其基于 Page Cache 的实现方式有密切关系。容器不会虚拟化操作系统内核。因此，当 Pod 在 Node 之间漂移时 Page Cache 都需要进行重新预热 [8]，这会影响 Kafka 的性能。当处于 Kafka 业务的高峰时期，这种性能影响将会更加显著。在这种背景下，如果 Kafka 的使用者关注其性能对业务的影响，则不敢让 Kafka Broker Pod 在 Node 之间随意漂移。如果 pod 无法在 Node 之间快速自由地漂移，则会大大削弱 Kubernetes 调度的灵活性，无法将其编排和提升资源利用率的优势发挥出来。下图展示了 Broker Pod 漂移时，因 Page Cache 没有预热导致引发磁盘读使得 Kafka 性能受损。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7b/7b71419e8812047836975d26d84fb004\" /></p><p></p><p></p><h4>4.2.2 Apache Kafka 在 Kubernetes 上无法完成自动弹性</h4><p></p><p></p><p>Apache Kafka 本身基于多副本 ISR 来保证数据的持久性。当在 Kubernetes 上需要对集群进行横向扩容时，Apache Kafka 需要非常多的人为干预，整个过程不仅不是自动化的而且还有很大的运维风险。整个流程包括：</p><p></p><p>分区迁移评估：扩容前首先需要由对集群业务和负载充分了解的 Kafka 运维人员评估将哪些 Topic 的分区迁移至新创建的节点之上。并且要确保新节点的机器规格满足这些分区的读写流量要求以及评估迁移时长以及迁移对业务系统的影响。光是第一步，就已经是非常繁琐并且很难实施的步骤。准备分区迁移计划：需要准备 partition reassign policy 文件，其中具体列出要将哪些分区迁移到新的节点执行分区迁移：Apache Kafka 按照用户给定的 partition reassign policy 来执行分区的迁移。整个过程的耗时取决于用户在本地磁盘保留的数据大小。这个过程一般会耗费数小时甚至更久的时间。迁移期间由于大量的数据复制，会抢占磁盘和网络 I/O，影响正常的读写请求。此时集群的读写吞吐会受到显著影响。</p><p></p><p></p><h4>4.2.3 Apache Kafka 在 Kubernetes 上没法自动做高效率、安全的 rolling</h4><p></p><p></p><p>正是由于 Apache Kafka 缺乏弹性以及强依赖 Page Cache 等特点，进一步使得其无法在 K8s 上执行高效率和安全的滚动升级（Rolling）。在 K8s 上对高流量、高容量的 Apache Kafka 进行滚动重启是一件很有挑战的事情。因为，在迁移过程中 Kafka 的运维人员必须时刻关注集群的健康状况。分区数据的复制、Page Cache Miss 引发的 Disk Reads 都会影响整个集群的读写性能，从而进一步影响用户依赖 Kafka 的应用程序。</p><p></p><p></p><h4>4.2.4 K8s 的 &nbsp;Kubernetes PV 不支持缩容，存储成本高昂</h4><p></p><p></p><p>K8s 当前仍然没有支持 PV 进行缩容 [11]。K8s 对于无状态或者计算存储完全解耦的程序来说是十分友好的。但是，对于这些有存储状态的程序来说则有比较大的限制。PV 不支持缩容意味着 Kafka 必须按照峰值吞吐来持有存储空间。为了保证高吞吐和低延迟，用户往往需要使用昂贵的 SSD 来存储 Kafka 的数据。当用户吞吐较大并且数据保留时间较长时，这将耗费用户大量的金钱。</p><p></p><p></p><h2>05 AutoMQ 如何做到真正的 Kubernetes Native</h2><p></p><p></p><p></p><h4>5.1 复用 Kafka Kubernetes 生态，可提供成熟的 Helm Chart 和 Operator</h4><p></p><p></p><p>得益于 AutoMQ 对 Apache Kafka 的 100% 完全兼容，AutoMQ 可以充分利用 Kafka 已有的 K8s 生态产品，例如 bitnami 提供的 Kafka chart 以及 strimizi 提供的 kafka operator。如果用户原本就已经在使用 bitnami 或者 strimzi 的 Kafka K8s 方案，即可以无缝平滑迁移至 AutoMQ，立刻享受 AutoMQ 提供的低成本、弹性等云原生优势。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/86/869f62d2c162914e61bba8abdb1f95e8\" /></p><p></p><p></p><h4>5.2 不依赖 Page Cache，pod 可以在容器上自由迁移，无需担心影响性能</h4><p></p><p></p><p>AutoMQ 无需像 Apache Kafka 一样担心 pod 迁移时 Page Cache 没有预热导致的性能劣化问题。与 Apache Kafka 通过多副本以及 ISR 来保障数据持久性不同的是 AutoMQ 利用 WAL 将数据的持久性卸载至云存储 EBS。利用 EBS 内部多副本机高可用来保证数据持久性。虽然不再使用 Page Cache，但是结合 Direct I/O 配合云盘 EBS 本身低延迟高性能的特征，AutoMQ 仍然可以做到个位数毫秒的延迟。具体的数值，可以参考 AutoMQ vs. Kafka 性能报告 [15]。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/63/63fbd7865b7178358445060ca1b58e45\" /></p><p></p><p></p><h4>5.3 强大的弹性能力充分发挥k8s 资源管理和自动运维部署的潜力</h4><p></p><p></p><p>在 K8s 上使用 AutoMQ 无需担心 Apache Kafka 由于其自身缺乏弹性带来的无法自动弹性、Rolling 等问题。只有 Kafka 真正支持自动弹性、高效安全的 Rolling ，K8s 才可以自动、高效安全地腾挪 Pod 提升资源利用率以及利用其基于 IaC 的自动化 DevOps 来提升运维管理的效率。AutoMQ 通过以下技术手段保证了用户可以自动、安全地在 K8s 上对其完成自动弹性、Rolling 等操作：</p><p></p><p>秒级分区迁移：在 AutoMQ 中，分区迁移不再涉及任何数据复制。当需要对 Broker 上的分区进行移动时，仅仅是元数据的变更操作，可以在秒级内完成分区的迁移。持续流量自平衡：Apache Kafka 仅提供了分区迁移工具，但具体的迁移计划则需要运维人员自行决定，而对于动辄成百上千个节点规模的 Kafka 集群来说，人为监控集群状态并制定一个完善的分区迁移计划几乎是不可能完成的任务，为此，社区也有诸如 Cruise Control for Apache Kafka[16] 这类第三方外置插件用于辅助生成迁移计划。但由于 Apache Kafka 的重平衡过程中涉及到大量变量的决策（副本分布、Leader 流量分布、节点资源利用率等等），以及重平衡过程中由于数据同步带来的资源抢占和小时甚至天级的耗时，现有解决方案复杂度较高、决策时效性较低，在实际执行重平衡策略时，还需依赖运维人员的审查和持续监控，无法真正解决 Apache Kafka 流量分布不均的问题。而 AutoMQ 内置了自动的自平衡组件，根据搜集的 metric 信息，自动可以帮助用户生成分区的迁移计划并且执行迁移，使得自动弹性完成后集群的流量也能自动重平衡。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/9c/9cb4f943096d89bed1b65db64d750ec3\" /></p><p></p><p>AutoMQ 在 K8s 上与其自动弹性相关的生态产品，例如 Karpenter[17] 和 Cluster Autoscaler[8] 也可以非常好的进行协同工作。关于 AutoMQ 在 K8s 上自动弹性的解决方案如果有兴趣可以参考 AWS 官方博客内容《使用 AutoMQ 实现 Kafka 大规模成本及效率优化》[19]。</p><p></p><p></p><h4>5.4 将 AutoMQ 部署到 Kubernetes 不会导致复杂度爆炸</h4><p></p><p></p><p>我们必须承认，不是所有规模的企业或者程序都可以从 K8s 中获益。Kubernetes 本身在应用程序和底层 VM 之间增加了一层新的抽象，从安全、网络、存储等维度都带来了新的复杂度。将不是 Kubernetes Native 的程序强行 rehost 到 k8s 上，会进一步放大这种复杂度，引发更多新的问题。用户为了让非 Kubernetes Native 的程序可以在 k8s 上运行良好，自身可能需要做非常多的与 k8s 最佳实践违背的 Hack 行为以及大量人工介入。以 Apache Kafka 为例，无论是 Strimz 还是 Bitnami 都无法解决其横向扩展的问题，因为该过程必须人为介入从而保证扩缩容过程时集群的可用性与性能。当这些人为操作与 K8s 自动化的 DevOps 理念格格不入。使用 AutoMQ 则可以真正消除了这些人为干预的行为，充分利用 K8s 自身的机制来对 Kafka 集群进行高效、自动化地集群容量调整以及更新升级。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e9/e942fd572d46bb92dd0866faf81cc534\" /></p><p></p><p></p><h4>5.5 存储卸载至云存储，不依赖本地磁盘空间</h4><p></p><p></p><p>K8s 本身不是为有状态的数据基础设施而设计的，因此其很多默认提供的能力对于有存储状态或者存储解耦不彻底的程序来说不是十分友好。K8s 倾向于用户在其上部署无状态的应用程序，并将有状态的数据彻底解耦出去，从而可以充分发挥其提升资源利用率、改善 DevOps 效率的优点。Apache Kafka 存算一体的架构强依赖本地存储，加之 PV 不支持缩容，使得其在 K8s 上运行需要预留大量存储资源，加剧了存储成本的开销。AutoMQ 的存储和计算层完全分离，仅仅将固定大小的（10GB）的块存储作为 WAL，数据全部卸载至 S3 存储。在这种存储架构下，充分利用云对象存储服务无限扩容、pay-as-you-go 的特性，使得 AutoMQ 可以像无状态的程序一样在 K8s 上面工作，将 K8s 的潜力完全发挥出来。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/75/751ba95b3b635dcbd8c59e2a2c36b2f4\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b6/b66dbe9fbcb303c1cf08b77814e95d29\" /></p><p></p><p></p><h2>06 总结</h2><p></p><p></p><p>AutoMQ 通过其创新的基于 WAL 和 S3 的共享存储架构以及秒级分区迁移、持续流量自平衡等亮点特性，构建了真正的 Kubernetes Native Kafka 服务，可以充分发挥 Kubernetes 的全部优势。你可以使用 Github 上开放源码的 AutoMQ 社区版来进行体验，也可以在 AutoMQ 官网申请免费的企业版进行 PoC 试用。</p><p></p><p>参考资料</p><p></p><p>[1] AutoMQ:<a href=\"https://www.automq.com/\">https://www.automq.com</a>\"</p><p></p><p>[2] AutoMQ Github: <a href=\"https://github.com/AutoMQ/automq\">https://github.com/AutoMQ/automq</a>\"</p><p></p><p>[3] Kafka Alternative Comparision: AutoMQ vs Apache Kafka:<a href=\"https://www.automq.com/blog/automq-vs-apache-kafka\">https://www.automq.com/blog/automq-vs-apache-kafka</a>\"</p><p></p><p>[4] Kafka Alternative Comparision: AutoMQ vs. AWS MSK (serverless): <a href=\"https://www.automq.com/blog/automq-vs-aws-msk-serverless\">https://www.automq.com/blog/automq-vs-aws-msk-serverless</a>\"</p><p></p><p>[5] Kafka Alternative Comparision: AutoMQ vs. Warpstream: <a href=\"https://www.automq.com/blog/automq-vs-warpstream\">https://www.automq.com/blog/automq-vs-warpstream</a>\"</p><p></p><p>[6] Why Kubernetes native instead of cloud native? <a href=\"https://developers.redhat.com/blog/2020/04/08/why-kubernetes-native-instead-of-cloud-native#\">https://developers.redhat.com/blog/2020/04/08/why-kubernetes-native-instead-of-cloud-native#</a>\"</p><p></p><p>[7]Kafka on Kubernetes: What could go wrong? <a href=\"https://www.redpanda.com/blog/kafka-kubernetes-deployment-pros-cons\">https://www.redpanda.com/blog/kafka-kubernetes-deployment-pros-cons</a>\"</p><p></p><p>[8] Common issues when deploying Kafka on K8s: <a href=\"https://dattell.com/data-architecture-blog/kafka-on-kubernetes/\">https://dattell.com/data-architecture-blog/kafka-on-kubernetes/</a>\"</p><p></p><p>[9] Apache Kafka on Kubernetes – Could You? Should You?:<a href=\"https://www.confluent.io/blog/apache-kafka-kubernetes-could-you-should-you/\">https://www.confluent.io/blog/apache-kafka-kubernetes-could-you-should-you/</a>\"</p><p></p><p>[10] Kafka on Kubernetes: Reloaded for fault tolerance: <a href=\"https://engineering.grab.com/kafka-on-kubernetes\">https://engineering.grab.com/kafka-on-kubernetes</a>\"</p><p></p><p>[11] Kubernetes 1.24: Volume Expansion Now A Stable Feature: <a href=\"https://kubernetes.io/blog/2022/05/05/volume-expansion-ga/\">https://kubernetes.io/blog/2022/05/05/volume-expansion-ga/</a>\"</p><p></p><p>[12] Strimz: <a href=\"https://strimzi.io/\">https://strimzi.io/</a>\"</p><p></p><p>[13] Bitnami Kafka: <a href=\"https://artifacthub.io/packages/helm/bitnami/kafka\">https://artifacthub.io/packages/helm/bitnami/kafka</a>\"</p><p></p><p>[14] How to implement high-performance WAL based on raw devices?:<a href=\"https://www.automq.com/blog/principle-analysis-how-automq-implements-high-performance-wal-based-on-raw-devices#what-is-delta-wal\">https://www.automq.com/blog/principle-analysis-how-automq-implements-high-performance-wal-based-on-raw-devices#what-is-delta-wal</a>\"</p><p></p><p>[15] Benchmark: AutoMQ vs. Apache Kafka: <a href=\"https://docs.automq.com/automq/benchmarks/benchmark-automq-vs-apache-kafka\">https://docs.automq.com/automq/benchmarks/benchmark-automq-vs-apache-kafka</a>\"</p><p></p><p>[16] Cruise Control for Apache Kafka: <a href=\"https://github.com/linkedin/cruise-control\">https://github.com/linkedin/cruise-control</a>\"</p><p></p><p>[17] Karpenter: <a href=\"https://karpenter.sh/\">https://karpenter.sh/</a>\"</p><p></p><p>[18] &nbsp;Cluster Autoscaler: <a href=\"https://github.com/kubernetes/autoscaler\">https://github.com/kubernetes/autoscaler</a>\"</p><p></p><p>[19] 使用 AutoMQ 实现 Kafka 大规模成本及效率优化：<a href=\"https://aws.amazon.com/cn/blogs/china/using-automq-to-optimize-kafka-costs-and-efficiency-at-scale/\">https://aws.amazon.com/cn/blogs/china/using-automq-to-optimize-kafka-costs-and-efficiency-at-scale/</a>\"</p><p></p><p>今日好文推荐</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651207433&amp;idx=1&amp;sn=b0d3776443b6844e19dcc2e371d790cf&amp;chksm=bdbbcf5a8acc464c548ee33611d68afb58a21d5407fae1d87f4c88b11ed8ccd699a1815d33fb&amp;scene=21#wechat_redirect\">剥离几百万行代码，复制核心算法去美国？TikTok 最新回应来了</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651216946&amp;idx=1&amp;sn=80a5cd51d6e927ea719313189a185030&amp;chksm=bdbba4618acc2d773041e7a8fb8b365ad4ee03d7e066ccd792705a9c142b2a2680cba3583684&amp;scene=21#wechat_redirect\">IBM 中国撤退进行时：仅三分钟研发测试千人全被裁，周一冒雨上班发现公司没了</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651216857&amp;idx=1&amp;sn=e013fded34dd675e8766467542f628b8&amp;chksm=bdbba38a8acc2a9c8ada8ad5211cf5340005a933b350daeec9a812fb59e8397578ca84fc122d&amp;scene=21#wechat_redirect\">传IBM中国研发岗位员工被收回访问权限，涉全国各地千余人；《黑神话：悟空》涉嫌抄袭？突发！Telegram创始人被捕 | Q资讯</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651216784&amp;idx=1&amp;sn=c6cba37fcbc7d21994b21b52d278707a&amp;chksm=bdbba3c38acc2ad580b6abefe3052bf73197e7dd8575e43d1470f120d52f9b229a91b8ef8a7f&amp;scene=21#wechat_redirect\">《黑神话：悟空》的第二个受害者出现了，竟是AI搜索惹的祸！</a>\"</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/93/93a6e30a75e8e663d639c54513765ef5.gif\" /></p><p></p>",
    "publish_time": "2024-09-02 16:41:38",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]