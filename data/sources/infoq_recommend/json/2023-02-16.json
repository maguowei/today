[
  {
    "title": "谷歌改进gVisor提高沙箱容器文件系统性能",
    "url": "https://www.infoq.cn/article/NIqyIMorP3VMhsoFLMFT",
    "summary": "<p>谷歌<a href=\"https://cloud.google.com/blog/products/containers-kubernetes/gvisor-file-system-improvements-for-gke-and-serverless/\">改进</a>\"了<a href=\"https://github.com/google/gvisor\">gVisor</a>\"中的文件系统实现，gVisor是一个开源隔离层，用于面向商业容器的产品，如App Engine、Cloud Run和Cloud Functions。根据谷歌工程师Ayush Ranjan和Fabricio Voznika的说法，新的gVisor文件系统被称为VFS2，可以将文件密集型工作负载的性能提高大约50%-75%。</p><p>&nbsp;</p><p>gVisor的主要目标是在容器和底层内核之间提供一个隔离层，该隔离层由运行在同一节点上的所有容器共享。为了防止恶意或易受攻击的容器危及整个节点的安全，gVisor实现了Linux系统表层的很大一部分，包括一个名为 runsc 的符合开放容器倡议（OCI）的兼容运行时，该运行时在应用程序和主机内核之间提供隔离边界。</p><p>&nbsp;</p><p></p><blockquote>由于gVisor内核不可信任，因此它不能直接访问文件系统。文件系统操作由代理（称为Gofer）来代理操作，该代理与可能的恶意工作负载相隔离。像open、create和stat这样的操作被转发到代理，经过审核，然后再由代理执行。</blockquote><p></p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ae/ae5544961b4795e7d056166753d8038a.png\" /></p><p></p><p>&nbsp;</p><p>谷歌工程师发现，gVisor Gofer文件系统通过将路径解析委派给底层文件系统（每个路径组件使用一个RPC调用）来处理路径解析的方式对性能有害。对于频繁执行文件操作的工作负载，例如构建任务或运行带有大量导入的Python和NodeJS程序时，情况尤其如此。</p><p>&nbsp;</p><p></p><blockquote>要解决这个问题，需要启用gVisor的Sentry，使其能够将路径解析直接委托给文件系统。......例如，在VFS1 stat（/foo/bar/baz）中，至少生成三个到gofer（foo，bar，baz）的RPC，而VFS2仅生成一个。</blockquote><p></p><p>&nbsp;</p><p>此外，谷歌还借此机会创建了一个用于在gVisor沙箱和Gofer之间进行通信的新协议。该新协议名为<a href=\"https://github.com/google/gvisor/tree/master/pkg/lisafs\">LISAFS</a>\"（(Linux Sandbox File system protoco，Linux沙箱文件系统协议），它既减少了RPC调用的数量，也减少了它的内存使用量，改善了多路径组件的遍历，并加快了文件I/O。</p><p>&nbsp;</p><p>Ranjan和Voznika表示，由于这些变化， 根据许多不同的度量指标，runsc引入的开销减少了50%-75%。</p><p>&nbsp;</p><p>与在根文件系统或内存文件系统中托管源代码相比，使用绑定装载时的改进最大。这些结果是通过运行官方bazel基准测试构建gRPC和Abeil而获得的。</p><p>&nbsp;</p><p>基准测试的结果基本上得到了实验数据的证实，实验数据表明，整个平台上的Google App Engine冷启动时间提高了25%以上，这一数据包括了所有类型的工作负载，而不仅仅是文件系统密集型的工作负载。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/01/gvisor-file-system-improvements/\">https://www.infoq.com/news/2023/01/gvisor-file-system-improvements/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/2011/09/app-engine-price-hike\">Google App Engine 涨价，开发者深受打击</a>\"</p><p><a href=\"https://www.infoq.cn/articles/2015/07/JavaScript-GitHub\">Google 发布 App Engine 的 Go 语言通用版</a>\"</p>",
    "publish_time": "2023-02-16 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "第四届高端制造业CIO上海论坛将于2月22日举办，报名倒计时3天",
    "url": "https://www.infoq.cn/article/hQ0IRh0iBN7ygCzdpcAT",
    "summary": "<p>当前，我国<a href=\"https://www.infoq.cn/article/FYSwjaR1k8vyzyVwWQjm\">工业互联网</a>\"创新发展战略深入实施，工业互联网赋能高端制造将进一步催生融合创新应用，赋予各产业转型升级发展新动力。然而，数字化转型是一个长期系统工程，产业升级之路依旧任重道远。</p><p></p><p>由中国能源研究会信息通信专委会、上海市航空学会、上海市汽车工程学会、上海交通运输研究中心大力支持的 “第四届高端制造业CIO上海论坛” 将于2023年2月22日在上海举办。本次峰会以《数智转型 融合发展》为主题。现场汇集350+高端制造行业知名企业高管、CIO、IT负责人以及行业知名信息化服务商，共同总结制造业信息化建设成果，研讨 “十四五”信息化发展方向。加快5G、工业互联网、<a href=\"https://www.infoq.cn/article/u_ck0krm3Hp06fcyvBq2\">工业大数据</a>\"、人工智能、区块链、边缘计算、<a href=\"https://xie.infoq.cn/article/95847fb1bd1680c8d22ca2320\">增强现实</a>\"等在制造行业的应用，促进工业化与信息化全面融合，推动中国制造产业智慧建设、高质量发展。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/f2/50/f22fe27f73b1ef20488f105657f93650.jpg\" /></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/79/c3/791fb5697b053bb11c51dd9f8e0283c3.jpg\" /></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/a9/8f/a98504effe17c0c7983757a18c3fe48f.jpg\" /></p><p></p><p>大会期间，InfoQ将作为独家媒体合作伙伴全程报道大会盛况。组委会诚挚邀请大家的拨冗支持，共同推动高端制造行业的数字化转型落地！ </p><p></p><h4>会议核心议题</h4><p></p><p>人工智能与工业大数据</p><p>数字孪生与智能制造</p><p>智能制造与数字化运营</p><p>信息安全与数据管理</p><p>云管理与智能运维</p><p>数字化工厂与自动化技术</p><p>第四届高端制造业CIO “创智奖” 颁奖典礼</p><p></p><h4>会议议程</h4><p></p><p>上午主论坛：数智转型 融合发展</p><p>下午论坛A- 工业互联网-制造业数字化转型关键赋能者</p><p>下午论坛B- AI赋能制造行业转型升级</p><p></p><p>报名倒计时3天，请提前扫码预留席位。详情请咨询组委会余秘书 13917378771</p><p></p>",
    "publish_time": "2023-02-16 10:11:59",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "ChatGPT带火OpenAI！华盛顿大学博士放弃高校offer，加入OpenAI",
    "url": "https://www.infoq.cn/article/xzRzqmUAAhCo69ZSuDJz",
    "summary": "<p></p><blockquote><a href=\"https://www.infoq.cn/article/YYqCPSdRmtkdSl2hhb9Y\">ChatGPT</a>\" 的爆火让 OpenAI 名气大涨，事实上，在发布 ChatGPT 之前，OpenAI 就已因<a href=\"https://www.infoq.cn/article/w1lxxO4qtaVPxZUdqzwi\"> GPT-3</a>\" 等大模型在业界颇具名气。Rowan Zellers 是华盛顿大学博士，研究方向为多模态人工智能系统。在求职时，他做出了一个自己意想不到的决定：他放弃了所有的学术工作机会，转而接受了 OpenAI 的 Offer。本文为他的自述，讲述自己为什么会做出这一决策。</blockquote><p></p><p></p><p>本文最初发表于作者个人博客，经原作者授权，InfoQ 翻译并分享。</p><p></p><p>在我做这一决定的过程中，我感到很紧张，也很有压力，当时感觉就好像在坐过山车一样，但最终我对事情的结果还是非常满意的。对我来说，有两个关键因素起了作用。</p><p></p><p>我感到自己能够胜任 <a href=\"https://www.infoq.cn/article/ZWixRo76hFsOw38tRHNF\">OpenAI</a>\" 的工作。OpenAI 的所在地——旧金山，是一个非常适合我和伴侣生活和工作的城市。在本文中，我将对我的决策过程进行更深入的讨论。</p><p></p><h2>我为什么要写这篇文章？</h2><p></p><p></p><p>在我求职的过程中，我从我的教授那儿学到了许多有用信息，比如，怎样应聘，怎样去面试，怎样创建一个强有力的职位申请。但是，到了做出决定的时候，我反而觉得有点孤独。的确，我很庆幸自己有如此强大的人脉，身边有这么多优秀的教授和行业研究人员。但在职业道路上做出决策，更多的是一种个性化的个人决策，从某种意义上说，“没有正确的答案”。</p><p></p><p>对我决策产生影响的另一个因素是：我所认识的大部分人看起来都在学术界和工业界中做出了抉择。比如，我所认识的大多数教授都是坚定地站在学术体系中（尽管也有涉足工业界），但是我所认识的大多数工业界人士，从未认真地将学术当成一种职业。</p><p></p><p>（这对我来说感觉特别奇怪，因为我在读博士读到一半的时候，就下决心要走“学术路线”，因为那样可以让我推迟在学术界或工业界之间做出最终的决定：人们普遍认为，从学术界转到工业界比从工业界转到学术界要容易得多。不过，几年过去了，我觉得走学术路线是我职业身份的一部分，我许多同龄人也在做同样的事情，所以我感到势头正把我推向了学术路线。）</p><p></p><p>总之，我写这篇文章是为了给出一种独到的看法，说明我如何在一些截然不同的选择中做出自己的决定。（如果有人向我发送电子邮件要求提供建议，或许也能帮上忙！）</p><p></p><p>一些免责声明：本文仅代表本人的观点。我无意提供一般性的建议。我并不认为我有资格给出任何建议（毕竟我从来没有想过要成为一名教授）。此外，我做出这一决定的一个很重要的因素是，我觉得我的领域正处于一种非常独特的情况（稍后再说！），因此这并不一定适用于所有领域。</p><p></p><p>我会尽量把自己的经历告诉大家。我还会以我 2022 年春末的视角来写这篇文章，那时我正在做出一个决定。这么做可能对其他人的决定更相关：因为没有人可以预见将来会怎样，因此做出决定很困难。不过，我非常享受在 OpenAI 的工作，而且我对自己的选择毫不后悔。我对研究和这一领域的想法都改变了（并且会持续下去），向这儿的伟人们学习。</p><p></p><h2>学术求职期间，我的想法发生了转变</h2><p></p><p></p><p>从个人背景来看，我是 2016 ~ 2022 年的华盛顿大学的博士生，很享受读博的经历。我的研究方向是多模态人工智能：我创建的是能够理解语言、视觉以及其他领域的机器学习系统。</p><p></p><p>我的研究兴趣决定了我未来的职业道路，我最兴奋的是从事基础研究和指导初级研究人员。至少在传统的计算机领域，这是学术界的重点。而工业界则专注于应用研究，致力将科学进步转化为成果。</p><p></p><p>在学术界求职，使我对如何在计算机科学的许多不同机构和子领域担任教授有了更深刻的认识。我在所有的面试中，与 160 多名教授进行过交谈。不过，我最后还是很担心，学术界到底能不能适合我。</p><p></p><h3>某些领域在学术界开展大规模基础研究，正变得越来越困难</h3><p></p><p></p><p>我感到脚下大地的晃动。</p><p></p><p>在过去的六年里，学术界（更准确地说是华盛顿大学的顾问研究小组）对我来说是一个绝佳的环境。我被推动着去开辟一个令我兴奋的研究方向。我感到在指导和资源方面得到了慷慨的支持：通过它，我能够领导关于建立多模态人工智能系统的研究，这些系统随着规模的扩大而改进，反过来，（对我来说）产生的问题比答案更多。</p><p></p><p>相比之下，在那段时间里，大多数大型行业研究实验室对我来说并不是很有吸引力。在读博的时候，我曾经试图去应聘实习生，但是从来没有发现任何与我的研究议程相一致的地方。我所知道的大多数行业团队都专注于语言，或者注重视觉，而我不能从中挑选。我在艾伦人工智能研究所（Allen Institute for AI）花了很多时间，这是一家非营利性的研究实验室，与此相比，我觉得它更具学术性。</p><p></p><p>但是，我觉得情况正在改变。在我关注的领域，我担心在学术界开展具有开拓性意义的体系构建研究是非常困难的，并且是一种日益困难的过程。</p><p></p><p>事实上，建立这个体系是非常困难的。这是一项耗资巨大、技术含量高的工程技术。我认为，目前学术界的激励机制并不能适应这种高成本、高风险的体系构建研究。构建一个工件并展示它良好的可扩展性，可能需要研究生花费几年的时间，以及超过 10 万美元的无补贴计算成本；随着该领域的发展，这些数字似乎呈指数级增长。所以写很多论文并不是一个可行的策略。无论如何，这都不应该是目标。</p><p></p><p>但不幸的是，我知道许多学者倾向于将论文发表数量作为一种客观的衡量标准；此外，论文是学术界的硬币——你需要论文来写助学金，在会议上有话可谈，以及让你的学生实习，等等。归根结底，学术生涯的成功有助于学生“建立帝国”，开拓自己的研究议程（因此他们可能会成为其他地方的教授，这样的循环可以继续下去），这与做伟大研究所需的合作形成了内在张力。</p><p></p><p>我认为，更广泛的趋势是学术界转向应用研究。</p><p></p><p>随着核心模型越来越强大，构建成本越来越高，这促使更多的学者在其基础上进行构建——这是我在自然语言处理和计算机视觉中看到的趋势，这两个领域是我一直活跃的领域。这反过来又影响了学术研究、花时间思考和在会议上讨论的问题。这一趋势意味着在会议上发表的关于如何构建这些系统的论文越来越少（当然，还有其他因素在起作用。）。</p><p></p><p>至少对我最初的研究愿景来说，这表明机会之窗在学术界正在迅速关闭。假设我在筹集资金方面非常成功，建立了一个令人惊叹的研究人员实验室，并推动他们做出了令人惊叹的事情——那么，所有这些极其艰难的工作都要花费数年的时间才能完成。在经历了这么多时间之后，我所感兴趣的研究还会有支持者吗？如果该领域目前的进展速度继续下去，无论是从能力和准入门槛来看，似乎都是指数级的进展，那么，七年之后，也许再也没有学者在这一领域工作了，那时候就是我需要终身职位的时候。这是一个疯狂的想法。但话说回来，在过去的七年里，它的进步也是相当疯狂的。</p><p></p><p>从更实际的角度来看，我得改变我的研究方向。但是，这并不是我希望做的事情。也许这就是我最终走上工业道路的根本原因。</p><p></p><h3>学术界和工业界的其他区别</h3><p></p><p></p><p>我对研究的想法（当然是针对我工作的领域）是我做出决定的最重要因素。不过，我也在考虑一系列不同的事情：</p><p></p><p>对重大问题全神贯注。我对教授们的其他职责感到担忧：准备教学材料，为院系和现场服务，建立和管理计算机基础设施，申请拨款和管理经费。虽然我觉得这些事情很多都很有趣，很令人兴奋，特别是在教学中，但我不认为我会喜欢不断变换工作内容的环境。</p><p></p><p>相比之下，在我读博期间，我更愿意把重点放在一个重大课题上。我想，在工业中，这样做要简单得多。作为一名教授，从事实验和编写程序确实非常辛苦，但是在工业界中，在个人贡献者和管理者之间，选项更多。</p><p></p><p>名声和财富。我想，许多人都会潜意识里被学术界所吸引，因为这会让人产生一种名声和排外的心理。我对此没有任何兴趣。我认为，如果追逐错误的东西，把精力集中在排名和名声上，那么就会造成一种陈腐而有毒的氛围。另一方面，很多人都被工业界所吸引，原因是更高的工资（这一点可以理解）。我非常庆幸，我能够投入大把的精力去寻找一个能够让我内心更加充实的环境，这是最重要的。</p><p></p><p>工作保障与职业保障。我想许多人对终身职位有错误的理解，不管是学者还是非学者。终身职位是一份工作的保障，教授更难被辞退。但学术性就业市场的错综复杂性，意味着他们几乎没有职业保障，能够轻松地更换工作。所以，与行业研究人员相比，即便是在如此严峻的宏观经济形势下，他们也能轻松地转换工作（当然，这是由于人工智能在工业界的表现比其他产业要好），而学者们更倾向于反对那些可能给他们分配更多责任、可能减薪或可能让每个人在疫情高峰期亲自授课的管理人员。</p><p></p><p>（顺便说一句，我认为学者们唯一的办法就是成立工会；但有些令人沮丧的是，在华盛顿大学，许多计算机科学教授之前签署了一份反工会声明，扼杀了早些时候的工会运动。）</p><p></p><p>“自由”很复杂。在学术界，我可以在理论上自由地解决任何我想解决的问题，但由于没有足够的资源、正确的激励结构或者一个足够支持的环境，我的工作就可能会受阻。我加入 OpenAI 的原因是，在那里，我能感觉到自己得到了令人难以置信的良好支持，能够精确地解决我最感兴趣的问题。我认为，对于任何行业实验室来说，解决我所关心的问题的能力都需要与产品保持一致，我对这样的安排感到自在。</p><p></p><p>这些只是我加入 OpenAI 后不得不接受的几个维度，但我真的很高兴我做到了。也许我以后会写更多关于这方面的内容，但这里超级有趣。我正在指导初级研究人员，并在一个团队中工作，我可以获得充足的资源，并且我被激励着去解决那些对我来说很重要的挑战性问题。</p><p></p><h2>生活：旧金山是一座神奇的城市</h2><p></p><p></p><p>关于工作，我写了很长的篇章。但是，这个世界不只有眼前的苟且，还有诗与远方。就我而言，我也在寻找一个能让我和我的伴侣都开心的城市。</p><p></p><p>为了说明情况：我的伴侣和我已经相处了九年。她从事技术工作，在大流行期间，她完全是远程办公，这在理论上给了我们很多选择。但是我们希望要一个这样的地方，这样的地方我们不仅能忍受，而且能热爱，最好是和我们过去六年居住的西雅图一样（或更多）。按照美国的标准，西雅图很适合步行，我们发现西雅图是一个与其他同龄年轻人交朋友的好地方，也是一个追求共同兴趣的好地方，如旅游、徒步旅行、滑雪、攀岩和双人瑜伽。</p><p></p><p>一方面，作为一个进入学术界就业市场的人来写这些话，我感到很荣幸。学术界的就业市场是如此严酷和艰苦，以至于许多人不得不做出极大的牺牲，仅仅为了追求他们所热爱的事业，尤其是在计算机以外的领域。我听说过一些恐怖的故事，例如，教授上下班的路上要花好几个小时，或者双学位夫妇在不同的城市接受工作，然后长途跋涉，只是希望将来有一天能够一起找到工作。</p><p></p><p>另一方面，我不需要加入这场游戏。我对进入学术界还是进入工业界的犹豫不决和疑虑，也给了我足够的选择和自由。</p><p></p><p>我喜欢旧金山的城市规划，比我过去几年有机会参观的任何美国城市都要喜欢。这座城市适宜步行，商店、餐馆和杂货店都很有人情味，并且有一个连接的自行车基础设施和公共交通网络。</p><p></p><p>这并不是说这座城市十全十美。旧金山的物价昂贵，而且中产阶级化也存在严重的问题，我意识到搬到这里会加剧这个问题。不过，我也很欣赏像租金管制这样的政策，至少为现有居民提供了一些保护。与之形成鲜明对比的是，西雅图没有租金控制，因此企业房东可以轻易地提高租金价格。</p><p></p><p>在基础设施和城市规划方面，我认为旧金山还没有达到阿姆斯特丹的水平。许多自行车道感觉没有得到很好地保护，送货司机经常把车停在这些自行车道上。我很高兴能够支持像旧金山自行车联盟这样的地方组织，这些组织正在解决这些问题方面取得进展。</p><p></p><p>还有一个重要的因素：我和我的伴侣都是在旧金山湾区长大的，父母都住在这一带。这一点，再加上其他因素，让我们意识到旧金山将是一个非常适合居住的地方。</p><p></p><h2>收场白：加盟 OpenAI</h2><p></p><p></p><p>所以，这是一个漫长的讨论，关于我权衡的因素。</p><p></p><p>我有几个选择。在我所在的地区，担任教授职位，推迟一年，然后在工业界度过这一年，这种感觉很普遍。这有点像“预科”，对于研究人员来说没有什么坏处，但有很多好处：可以继续研究一年，还可以在春季招生期间招收学生。</p><p></p><p>然而，我决定不这样做。我担心我最终会不想来，而且这样做（通过签署学术聘书），我可能会让学校失去一个宝贵的招聘名额。我把这个想法告诉了我在各个学校的教员联系人，他们都非常理解，也很包容。可是，我越是思考，就越是明白自己要做的事情。 我谢绝了一切学术上的 Offer，并与 OpenAI 签订了全职 Offer。</p><p></p><p>半年过去了，我真的很高兴我这么做了，有很多原因。我真的很喜欢在 OpenAI 工作，我和我的伴侣都很享受生活在旧金山。</p><p></p><p>作者简介：</p><p></p><p>罗文·泽勒斯（Rowan Zellers），华盛顿大学博士，研究方向为多模态人工智能系统，最近刚入职 OpenAI。</p><p></p><p>原文链接：</p><p></p><p>https://rowanzellers.com/blog/rowan-job-search2/</p>",
    "publish_time": "2023-02-16 10:40:41",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "ChatGPT“大战”谷歌搜索：新王加冕还是旧王延续？",
    "url": "https://www.infoq.cn/article/A1EsBgNZp6ejaTRW08KP",
    "summary": "<p></p><blockquote>自从OpenAI发布ChatGPT以来，关于它的杀手级应用会是什么，人们有很多猜测。排名第一的可能要属在线搜索。据《纽约时报》报道，谷歌的管理层已经宣布进入“红色警戒”，努力保护其在线搜索的垄断地位，以抵御ChatGPT将带来的冲击。这场ChatGPT与谷歌搜索之间的大战，究竟谁能称王？可能不同的人心中都有不同的答案。日前，TeckTalks 博客发表评论文章认为，ChatGPT确实是一项很棒的技术，但从现阶段来看，取代谷歌搜索还存在一定的难度。</blockquote><p></p><p></p><p>本文最初发布于TeckTalks博客。</p><p></p><p>ChatGPT是一项很棒的技术，它很有可能会重新定义我们创建以及与数字信息交互的方式。它可以有许多有趣的应用，包括在线搜索。</p><p>&nbsp;</p><p>但说它将取代谷歌可能有点牵强——至少从目前来看是这样。目前，<a href=\"https://www.infoq.cn/article/UrFKiffb44jcffwP5FbH\">大型语言模型（LLM）</a>\"在挑战搜索引擎之前还有许多问题需要解决。即使技术成熟，谷歌搜索也可能是从LLM中获益最多的。</p><p></p><h2>LLM与真实性</h2><p></p><p></p><p>ChatGPT非常擅长回答问题。它让你觉得自己就像是在和一个花了几百年时间汲取知识的人说话。它的输出很流畅，语法也正确，甚至可以模仿不同的演讲风格。</p><p></p><p>然而，有个问题是ChatGPT的答案有时候不对。事实上，它经常产生幻觉，陈述的事实完全错误。在读写能力的表象之下，ChatGPT是一个非常先进的自动补全引擎。它会根据你的提示（和聊天记录）尝试预测接下来会发生什么。而且，即使它的答案大部分看起来是合理的，它也没有把事情做好。</p><p>&nbsp;</p><p>解决ChatGPT输出的<a href=\"https://www.infoq.cn/article/U5xfFfPULVbkDSLR3PAQ\">真实性问题</a>\"将是一项重大的挑战。遗憾的是，目前还没有办法在ChatGPT的输出中区分幻觉和真相，除非你用其他事实来源验证它的答案（或许可以使用谷歌？）。但如果重点是使用大型语言模型作为搜索引擎的替代品，那可能会弄巧成拙。</p><p>&nbsp;</p><p>现在，谷歌或其他搜索引擎所提供的所有内容都不一定是真实的。但至少，它们为你提供了可以进行验证的资源链接。而ChatGPT提供纯文本，不会引用实际的网站（注：在融合ChatGPT的<a href=\"https://www.infoq.cn/article/N2DHuiaEtcIEeXvjbVLC\">最新版Bing</a>\"中，会引用相关网址）。</p><p>&nbsp;</p><p>一个可能的解决方案是添加一种机制，将LLM输出的不同部分链接到实际的网页（一些公司正在试验这种方法）。但这是一项复杂的任务，可能无法用纯基于深度学习的方法来解决。这就需要访问另一个信息源，比如搜索引擎索引数据库（这是经典搜索引擎不太可能很快失去其重要地位的原因之一）。</p><p></p><h2>更新模型</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ed/ede1d2325d7b5f0aa609de4f8a7030a6.jpeg\" /></p><p></p><p>ChatGPT及其他LLM面临的另外一项挑战是更新知识库。搜索引擎可以借助工具和软件不断索引新页面以及修改过的页面。更新搜索引擎数据库也是一项非常高效的操作。</p><p>&nbsp;</p><p>但对于大型语言模型，添加新知识需要重新训练模型。也许不是每次更新都需要重新训练，但与在搜索引擎数据库中添加和修改记录相比，其成本要高得多。如果你想了解最新的新闻，就得每天做很多次。</p><p>&nbsp;</p><p>ChatGPT基于GPT 3.5构建，它可能至少有1750亿个参数。由于任何一个单独的硬件都无法运行这个模型，所以必须将其分解并分布在几个处理器上，比如A100 GPU。配置这些处理器并行训练和运行模型不管在技术上还是财务上都是不小的挑战。</p><p>&nbsp;</p><p>LLM搜索引擎的运营商还需要有机制和工具，来确定哪些网络资源是可靠的知识源并应优先考虑。再一次，我们看到了搜索引擎组件的踪迹。</p><p></p><h2>速度挑战</h2><p></p><p></p><p>LLM还存在推理速度的问题。像谷歌这样的公司已经创建了高度优化的数据库基础设施，可以在不到一秒钟的时间内找到数百万个答案。像ChatGPT这样的LLM则需要几秒钟来撰写回复。</p><p></p><p>搜索引擎不需要为每个查询浏览整个数据集。它们有索引、排序和搜索算法，可以非常快的定位到正确的记录。因此，尽管在线信息的数量在增长，但搜索引擎的速度并没有下降。</p><p>&nbsp;</p><p>另一方面，LLM每次收到提示时都会浏览整个神经网络的信息。诚然，神经网络的规模无法与搜索引擎数据库相比。但是，计算量仍然比查询索引大很多。鉴于深度神经网络的非线性性质，并行化推理操作的程度是有限的。随着LLM训练语料库的增长，模型也必须变得更大，才能在其知识库中很好地泛化。</p><p></p><h2>ChatGPT的商业模式</h2><p></p><p></p><p>不过，基于LLM的搜索引擎最大的挑战可能是商业模式。谷歌在其搜索引擎上建立了一个广告帝国。</p><p>&nbsp;</p><p>谷歌搜索并不是一个完美的商业模式。人们很少会点击那些越来越多地出现在搜索引擎结果页面上方的广告。但谷歌在在线搜索市场的份额如此之大，所以即使点击率很低，它每年也能赚上数十亿美元。</p><p>&nbsp;</p><p>谷歌还可以根据从用户那里收集的数据来个性化搜索结果和广告。这使得它的业务更加高效和有利可图。别忘了谷歌还有许多其他产品，包括YouTube、Gmail、Chrome和Android，可以强化它为用户创建的数字档案。它的广告网络也扩展到了网站和其他媒体。</p><p>&nbsp;</p><p>基本上，谷歌控制着市场的两端：内容搜寻者和广告商。通过控制整个市场，它成功地创造了一个自我强化的循环。在这个循环中，它收集了更多的数据，改善了搜索结果，并提供了更多相关的广告。</p><p>&nbsp;</p><p>作为一个潜在的搜索引擎，ChatGPT还没有一个商业模式，而且成本很高。粗略估计，在100万用户的情况下，ChatGPT每天的成本为10万美元，每月约为300万美元。</p><p></p><p></p><blockquote>据我估计，运行ChatGPT的成本是每天10万美元或每月300万美元。这是一个粗略的计算。我是假设节点都总是在使用，批处理大小为1。而实际上，它们可能在访问量大时进行批处理，而在访问量小时会有GPU处于空闲状态。—— Tom Goldstein （@tomgoldsteincs）2022年12月6日</blockquote><p></p><p>&nbsp;</p><p>现在想象一下，当人们每天运行80亿个搜索查询时会发生什么。现在，再加上定期训练模型的成本，以及通过强化学习和人类反馈来优化模型所需的人工劳动。</p><p>&nbsp;</p><p>训练和运行像ChatGPT这样的大型语言模型的成本是如此之高，以至于让它发挥作用将成为大型科技公司的专利，这些公司可以在没有明确商业模式的无利可图的产品上投入大量资金。</p><p>&nbsp;</p><p>盈利的一个可能途径是将LLM作为像Codex和GPT-3那样的付费API交付。但这并不是搜索引擎的传统商业模式，我不确定它们将如何做到这一点。另一种方法是将其作为一些问答功能集成到微软Bing中，但这将使其与谷歌搜索相提并论，而不是提供一个可以颠覆搜索市场的不同系统。</p><p></p><h2>ChatGPT是一个搜索引擎吗？</h2><p></p><p></p><p>很多人都在谈论ChatGPT将成为万能助手，可以回答任何问题，这在逻辑上引出了它将取代谷歌搜索的想法。</p><p>&nbsp;</p><p>但是，尽管拥有一个可以回答问题的人工智能系统非常有用（假设OpenAI解决了它的问题），但这并不是在线搜索的全部。谷歌搜索有缺陷，它会显示很多没用的广告，也会返回很多没用的结果。但这是一个价值不可估量的工具。</p><p>&nbsp;</p><p>大多数时候，当我使用谷歌搜索时，我甚至不知道正确的问题是什么。我只是把一堆关键字混在一起，看看结果，做一些研究，然后缩小或修改搜索。在我看来，这种应用还不是一个非常有效的问答模型所能取代的。</p><p>&nbsp;</p><p>表面看来，ChatGPT或其他类似的LLM将成为在线搜索引擎的补充。最终，它们很可能会强化现有搜索巨头的地位，因为这些巨头拥有训练和运营它们的资金、基础设施和数据。</p><p>&nbsp;</p><p>原文链接：<a href=\"https://bdtechtalks.com/2023/01/02/chatgpt-google-search/\">https://bdtechtalks.com/2023/01/02/chatgpt-google-search/</a>\"</p>",
    "publish_time": "2023-02-16 11:13:21",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "RTC 端到端视频体验优化技术实践与探索",
    "url": "https://www.infoq.cn/article/zeyou9a4e4YYieNEi0Ot",
    "summary": "<p></p><blockquote>本文来自火山引擎视频云的技术实践分享</blockquote><p></p><p></p><p>RTC 是一个“发布-订阅”系统，我们在发布端和订阅端做的很多关于画质、性能、卡顿、延时的优化，在经过网络传输之后，不一定能够达到端到端的最优效果。本文介绍 RTC 如何通过发布端和接收端的联动优化，为用户提供更佳的视频通话体验。</p><p></p><h2>传统 RTC 上下行联动优化技术——带宽探测</h2><p></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/33/90/3358f70540d1818264ae392c259de190.png\" /></p><p></p><p>&nbsp;这是一个多人 RTC 系统的示意图，左边是发布端 Pub（Publisher），右边是接收端 Sub（Subscriber），把视频流从发布端通过一连串的媒体级联服务器送到接收端，就是“发布——接收”的整体链路。在这条链路上，我们可以有效利用一些信息来帮助 RTC 系统做端到端优化，比如把接收端的信息送回发布端做优化。</p><p></p><p>上图是一个比较常见的端到端优化的例子——上下行带宽联动探测。发布端上行带宽有 1 Mbps，接收端下行带宽只有 0.5 Mbps，如果发布端和接收端不做“沟通”，发布端就会按照它的带宽探测 1 Mbps发流，造成的结果就是下行带宽不够了，接收端收不了，延时不断增加，当增加到一定程度的时候，Buffer清空重新发I帧造成大卡顿，用户的感受就是突然一个画面闪过去，中间一段内容都看不到了。</p><p></p><p>当前市面上 99% 的 RTC 厂商都是基于 WebRTC 来开发自己的 RTC 系统，WebRTC 系统支持 RTCP（RTP 的传输控制协议，专门用来传输控制信号），通过 RTCP 协议，我们可以把接收端探测到的网络状况，包括接收端网络的抖动信息、延时信息等回传给发送端，让发送端知道现在接收端的网络状况怎么样。由于 WebRTC 是一个点对点的系统，既然可以通过媒体级联服务器传递音视频数据，也能够使用同样的链路传递其他信息。通过 RTCP 传回的接收端带宽信息，发布端就会“知道”虽然自己有<a href=\"https://xie.infoq.cn/article/2b41c1bd956506770ac2529f7\"> 1 Mbps</a>\" 的带宽，但考虑到接收端的情况，用 0.5 Mbps 来发流更合理。</p><p></p><p>以上是最常见的一个「上下行带宽联动应用」的例子。</p><p></p><p></p><h2>真·端到端上下行联动优化实践</h2><p></p><p></p><p>RTC 系统中的这些“通道”以及通过这些通道传递的“信息”可以被应用来做一些上下行的联动优化，解决一些 RTC 深水区的问题。由于不同应用会使用不同的“信息”和不同的“通道”，我们先归纳一下发布端和接收端的特点，看看哪些是发布端有、接收端没有的，或者哪些是接收端有、发布端没有的“独有信息”。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/60/bc/605afd568e4ebcc776430605a19823bc.png\" /></p><p></p><p>先看发布端。发布端的特点之一是它有“视频源”，即采集或美颜后未受压缩损坏的视频源。RTC 系统中间是网络传输，网络传输的时候不可避免会碰到一些带宽波动，比如弱网、丢包、抖动等情况，为了确保把内容传输出去，发布端势必要做压缩，有压缩就会有损伤，所以接收端永远拿不到损伤前的“源”，只有在发布端才有“源”。如果我们要做质量评估，想知道 RTC 里画质好不好，只有在发布端做才更准确——因为只有在有“源”的情况下，我们才能客观评价接收到的内容跟“源”有多少差距。</p><p></p><p>发布端还有一个特点，就是 1 条流只有 <a href=\"https://xie.infoq.cn/article/458d5f3b741af2134b4e6f03a\">1 个</a>\"发布端，但可能有多个接收端。如果我们需要在 RTC 系统里做 1 个任务，特别是在多人通话场景下，一定会选择在发布端做，因为只要做 1 次就够了。比如在下文「智能场景识别/内容识别」的例子中，我们需要做一些视频内容的分析识别任务，假设 1 条流有 10 个接收端，如果在接收端做识别就需要做 10 遍重复的事，不如在发布端做1次识别，然后把这个信息传递给接收端来得高效。</p><p></p><p>接收端的特点是它能拿到所有网络相关的信息，常见的有丢包、抖动、延时等状态信息，它还“知道”收到了哪些帧，丢了哪些帧，而发布端只“知道”它发出了哪些帧。</p><p></p><p>说完了发布端和接收端的特点，我们再来看看有哪些“通道”可以传输这些信息。</p><p></p><p>上文中已提到，WebRTC 已经可以实现利用标准的“沟通”通道 RTCP 把接收端的网络状态信息回传给发布端。视频的压缩码流标准定义了一个叫 SEI 的 协议，SEI 里面可以带一些 meta data，可以通过它来携带一些个性化的内容信息。SEI 的好处是它可以做到“帧”级别的对齐，RTCP 无法保证什么时候到达，无法精准地控制在某一视频帧做什么事情，但是SEI可以，SEI的劣势是它只能“单向沟通”，只能从“发布端”传到“接收端”。</p><p></p><p>同样方向的流还有 RTP，RTP 是 WebRTC 的标准传输协议，它提供扩展头（Header Extension）功能，我们可以自定义地去扩展一些头部，在 RTP 数据包头中附加一些需要的信息传输。以上 RTCP、SEI、RTP 走的都是 UDP 协议，所以它们有可能会丢。</p><p></p><p>RTC 系统里也有一些“不会丢”的沟通通道，比如 data channel（它在 UDP 协议里做了一些可靠传输机制），还有基于 TCP 传输的信令，这两个都不会丢。不过，“不会丢”并不表示它就是好的，一般来说，“不会丢”表示丢了以后会重传，所以相对来说比较慢。</p><p>&nbsp;</p><p>有了这些总结归纳后，下面通过三个故事来介绍我们如何使用这些信息和通道来做上下行联动优化，解决弱网、丢包、4K屏幕分享卡顿等问题。这三个小故事的基本叙事逻辑是一致的——走的是什么通道？传的是什么信息？解决的是什么问题？</p><p></p><p></p><h2>超分辨率的性能迭代优化框架</h2><p></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/69/be/69150b301ac56e9fc1d63d17299710be.png\" /></p><p></p><p>&nbsp;第一个故事是关于「超分辨率」。超分辨率是一个比较古老的图像处理问题，它的本质是把低分辨率的图像放大到高分辨率，并想办法恢复或重建图像中的一些细节。由于网络带宽等限制，视频在压缩时无可避免地会受到一些损坏，超分可以做一个“修复者”的工作，它最合适的位置是在接收端。</p><p></p><p>超分在 RTC 中的作用很大，它解决的问题是在系统资源有“限制”的情况下，视频质量被损坏，它能够部分恢复视频的质量（不是完全恢复）。“限制”包含了带宽限制和系统性能限制，比如在网络带宽非常低的时候，假设只有 200Kbps，我们需要要传一个 720P 分辨率的视频，这时传输的视频质量就会非常差，在这种情况下，我们不如先把它先缩小（比如先下采样到 360P），用好一点的质量把小分辨率先传出去，再在接收端用超分把画质还原回来。还有比如一些低端机发不出 720P 的视频，一发就卡顿，我们就可以先降低分辨率发出去，再通过超分把它修复回来。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/c0/6f/c0be74d023fa4ca381ec008898a5106f.png\" /></p><p></p><p>超分在 RTC 中应用会遇到一些挑战。首先是计算复杂度的问题，超分不是简单的上采样，目前学术界的方式都是用深度学习卷积神经网络去训练超分模型，不可避免地，这是一个计算量非常大的操作，计算量大会限制超分的分辨率和运行设备，比如限制在比较低的<a href=\"https://xie.infoq.cn/article/1161506f1e55b2e399f5130f2\">分辨率</a>\"，或者一些超分模型只能限制在一些高端机上使用，低端机上跑不动。</p><p></p><p>其次是所有类似的后处理技术都会面临的一个问题：如何衡量超分做得好不好？线上打开超分后，我们非常需要知道，超分到底让画质增加了多少？新的模型在线上是不是比旧的模型要好？这些数据不仅对线上运营有帮助，对之后的算法模型迭代也有帮助。另外，由于深度学习并不是我们设计的一个我们能够理解的算法，它也有可能会造成“损坏”，比如损坏一些暗场景增强、一些美颜特效的效果。“衡量效果”是一个比较大的难题，因为我们只知道它在线下训练模型的测试组里面跑得好不好，无法知道这个模型在线上跑的效果好不好。</p><p></p><p>这两个挑战是我们在 RTC 中应用超分时遇到的比较实际的问题。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/e9/18/e9c18d6e4c899775ff6f7aff155fa818.png\" /></p><p></p><p>在讨论如何解决这两个问题之前，我们先了解一下RTC系统中实现视频超分的卷积神经网络——使用 Resnet 的残差神经网络。Resnet 网络可以有很多层，甚至可能高达一百五十几层，但因为要跑在客户端上，所以我们使用了一个非常小的神经网络，我们使用的这个网络有 6 层，但即使是这样，它的复杂度也远比做一些线性的上采样要高。</p><p></p><p>和 Bicubic（OpenCV 常用的一种上采样方法）相比，当我们把视频从 270P 超分到 360P，基本可以达到 0.5dB 左右的视频修复能力。0.5dB 是什么概念？1.5dB 大概是 H.264 和 H.265 两代视频压缩标准之间相差的压缩收益，0.5dB 是它的 1/3。也就是说，在什么事情都不做、所有网络传输条件都一样的情况下，通过超分就可以平白让视频质量增加 0.5dB，这是很高的收益。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/89/89/891b7aceb67dc9fb58eb76f7c6a64689.png\" /></p><p></p><p>我们怎么用“收发联动端到端优化”这个思路解决超分“复杂度高”和“结果难衡量”的问题？</p><p></p><p>刚才我们说过，因为只有发送端有“视频源”，如果要做质量评估，只有在发送端做才是最直接、最准确的，所以我们的解法很简单，就是把超分搬到发布端去做质量评估，计算出超分能够在接收端恢复多少质量。通过这个方式，我们可以对每一个超分迭代模型在线上的表现进行评价。大家可能会认为这么做的复杂度很高，不建议这么做，但实际上，我们在线上只会放比如 2% 的量来做评价，再利用大数据来了解这个模型在线上的表现，了解这个模型在线上到底跑得好不好，第二代模型有没有比第一代模型好。</p><p></p><p>然后，我们用 SEI 把“超分收益好不好、值不值得做”的评估结果传递给接收端。这样做有什么好处？因为超分是在恢复带宽造成的质量“损伤”，但 RTC 系统弱网情况大概只占 20%，也就是说，80% 的情况都是好网，并不会造成视频的损伤，如果我们打开了超分，它不管网络好坏照样跑，把绝大部分计算量资源跑去恢复一个并没有什么损伤的视频是资源的浪费。</p><p></p><p>所以，当发布端已经知道超分在这一系列帧到底有多少恢复量的时候，如果恢复不多（比如网络很好没有什么压缩破坏，或者这帧视频非常简单，低带宽就可以压缩得很好），它就可以直接告诉接收端“现在不值得做超分，把超分关了”，这样我们就可以把复杂度投入在它产出最高画质、修复最高的那一段视频帧里，降低计算的复杂度。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/6y/6c/6yyaf208558789065856584b324a906c.png\" /></p><p></p><p>经过端到端优化后的超分技术在抖音直播连麦场景帮我们节省了很多计算量。抖音直播连麦在实际应用时，如果处于弱网条件下，我们的做法是先下采样到 270P，再通过超分把它还原到 360P。由于 52% 的网络情况是带宽大于 500Kbps，网络传输并不会给视频带来额外的质量损伤，这时候用超分做修复的收益是很低的，可以忽略的。</p><p></p><p>所以，针对带宽大于 500Kbps 的场景，我们告诉接收端“不用开启超分”；针对带宽小于 500Kbps 的场景，我们则告诉接收端“开启超分”。发布端通过 SEI 把决策传递给接收端，接收端开启“Adaptive Switch”，动态地开关超分这个功能。通过这个动态的开关，CPU 计算量增量从 4.8% 降到 2.5%，内存的增量也可以几乎减少一半，从 35MB 到 18MB，但整体的质量修复并没有明显的减少，证明了我们其实是把计算量放在了真正有修复能力的这段视频帧上。</p><p></p><p></p><h2>智能内容模式的下行延时优化</h2><p></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/90/68/90367f85670c16dbcf031661f2e58168.png\" /></p><p></p><p>第二个故事是关于「屏幕分享」的。屏幕分享是视频会议的一个常用功能，它在视频会议里的使用率比开视频还要高。大家在使用屏幕分享时可能会遇到这种情况：在讲 PPT 时突然播一段视频，视频会变得很卡，帧率很低。有一些视频会议厂商针对这种情况支持提供一个模式，叫“流畅模式”，如果播放视频卡，勾一下“流畅模式”，视频就流畅了；下一页 PPT 又变成了文字，我们又发现文字变模糊了，然后厂商会说，这时候应该选择“清晰模式”，它就会变清晰了。这种做法给用户的体验非常差，用户很容易忘记，切来切去也很麻烦。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/ec/5c/ecd7650bfa4a760fa1fa98fbfd2f725c.png\" /></p><p></p><p>这个问题的本质在于，屏幕分享的 PPT 和视频是两种截然不同特性的内容，它们具备完全不同的视频参数和弱网对抗策略参数：在共享 PPT（或文档）的时候，我们的要求是越清晰越好，也就是说，它对分辨率的要求很高，但帧率可以很低，一般我们在分享文档的时候，如果是 4K，其实只要每秒 1 帧就够了，大家会看着就会觉得非常舒适，很清楚；在共享视频的时候（比如电影），它对帧率的要求很高，但分辨率可以很低，比如一般的视频可能 720P 就够了，但帧率需要 30FPS。</p><p></p><p>这是在视频参数上的不同，在弱网情况下，这两种内容也有非常不一样的弱网对抗策略：PPT（或文档）需要非常低的延时，特别是投屏场景，大家一定希望电脑换页的时候投屏也马上换页，但它可以忍受非常高的卡顿，两帧之间可以忍受 500ms 的间隔，甚至很多时候每 2 秒 1 帧用户也不会感受到它有没有卡；视频则是完全相反的，视频需要非常高的流畅性和非常低的卡顿，但是它可以容忍比较高的延时，大家其实并不太在意他看到的视频和演讲人分享的视频差了 2 秒钟，只要视频本身是流畅的就可以，但一旦两帧之间有有卡顿的情况，大家就会觉得很不舒服。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/30/6a/30cdd70485b9fa19df2f61638926516a.png\" /></p><p></p><p>在实际情况中，分享的内容是视频还是 PPT 是会动态变化的，用这种“屏幕分享前勾选“清晰模式”或“流畅模式”，勾选后就不动”的做法不太行得通，我们需要一个实时的、能够动态去分辨分享内容类型的机制——我们叫内容检测，去分辨当前分享的视频帧到底是PPT还是视频，然后通过这个信息在发布端做一些策略联动，比如分享 PPT 需要 4K 的分辨率，发布端就可以通知采集来提升分辨率。同时，编码器也可以针对不同的视频内容做不同的参数调整。</p><p></p><p>举几个比较常见的例子，在 H.264 年代有一个非常有名的开源编码器叫 X264 直播，虽然那时还没有“屏幕分享”，但已经有“动画模式 Animation”，如果你告诉它现在在编码的是一个动画，它就可以通过参数调整把压缩率提高 30%。在 H.265 年代，视频标准里面直接写入了 SCC（Screen Content Coding），这是一种针对文字的编码模式，它里面用的 Hash ME 可以针对屏幕内容去做压缩，将压缩率提升 40%，也就是说，如果你告诉编码器它编码的内容是什么，它就可以降低 40% 的带宽。同样地，如果你告诉 Pacer（Pacer是发布端的一个网络控制模块，它可以决定冗余控制，FEC、重传控制的响应）现在共享的是什么类型的内容，它也可以去控制屏幕内容和视频内容的延时。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/87/c6/8780ea53c2ebf10aaf4e09ff67913ec6.png\" /></p><p></p><p>当然，这里最关键的是发布端要怎么把内容检测的结果传给接收端。接收端里的 Jitter Buffer 是整个 RTC 系统里控制延时和卡顿 Trade Off 的关键模块，它可以决定系统的延时是多少，而延时则会直接决定卡顿程度。一个简单的概念，如果愿意使用延时很大的策略，换来的就是系统卡顿减少，类似地，像分享视频这种场景对卡顿的要求很高，就可以选择一定程度的“牺牲延时”。目前，我们使用RTP扩展头的方式把内容检测的结果传递给接收端，传递给 Jitter Buffer，由 Jitter Buffer 来决定“延时”和“卡顿”的偏好。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/ec/f4/ecb4b31e24e874c84475697c1b4f4bf4.png\" /></p><p></p><p>我们看一下这个策略为“飞书屏幕分享”带来的收益。在体验方面，如果用户分享的是 PPT，屏幕可以直接从 1080P 提升到 4K，帧率从 15FPS 降到 5FPS，如果用户分享的是视频，帧率可以从 15FPS 提升到 30FPS。另外，通过收发联动优化，Jitter Buffer 收到了内容检测信息以后，可以针对 PPT 限制它的 Max Jitter Delay，同时关闭 AV 同步，这样做以后，整体分享文档的延时可以从 400ms 降低到  240ms。</p><p></p><h2>智能参考帧的极致弱网延时体验优化</h2><p></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/62/ce/628a0f26bab39970bc03886a78b3c5ce.png\" /></p><p></p><p>第三个故事是关于「智能参考帧」的一些实践。智能参考帧技术解决了 RTC 的一个深水区问题——大卡顿（我们一般定义两帧间隔超过 2s 以上的叫做大卡）。一个丢包造成的弱网很容易导致卡死的情况（Frozen Frames），它是怎么造成的？</p><p></p><p>举个简单的例子，一般情况下，如果丢包了，短时间之内接收端会请求重传，让发送端再传一次（视频参考帧是有依赖关系的，这一帧其实依赖前一帧，下一帧就依赖这一帧），如果发送端能够重传过来，接收端能够补上这一帧，后面就都可以顺利地解码和输出。但如果重传失败，时间到一定的长度，接收端就会直接请求一个 PLI（Package Loss Indication），它会触发发布端开始发送 I 帧，I 帧就是关键帧，它不依赖任何其他帧，所以它特别大，在丢包网络中，越大的帧越容易丢包，越丢包它越传不到，越传不到越请求它，它就越编一个更大的帧给接收端，然后越接收不到，如此便会造成大卡顿的恶性循环。</p><p></p><p>大家可能会想到，把I帧编小一点是不是就解决问题了。这里给大家一个数字，I 帧跟 P 帧大概是 3-5 倍的大小差，也就是说，I 帧约是 P 帧的 5 倍大。如果把它限制在2倍大，让它好传一点，它的质量就会特别差。大家在开视频会议的时候，如果发现每 2 秒画面就会闪一下，这种间隔的闪动叫呼吸效应，它表示你看到 I 帧了。 为了把I帧缩小，I 帧就会很模糊，它的质量和前后帧会很不一样。</p><p></p><p>这并不是我们想要的结果。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/5e/c4/5efd38f93d966b5abyy5fe50bbdc7ac4.png\" /></p><p></p><p>智能参考帧提供的方案很简单，它在接收端跟发布端维持了一套一模一样的参考帧关系。这样做的好处是，当系统进入大卡时，发布端其实知道接收端手上有什么已经成功解码的关键帧，所以它可以发布一个接收端已经有的参考帧，而不是重新发I帧，这个技术叫做 LTR (Long Term Reference)，它的原理是，不管什么时候向发布端请求，因为发布端“知道”接收端已经完整收到了某些帧（这些帧可以当参考），它就发一个接收端手上已有的参考帧。它改变了原来固定的参考帧关系，变成“我知道你有什么，让你去参考你自己有的东西，这样你永远可以解码”。其次，它可以解决带宽浪费的问题，原来接收端请求一个关键帧，需要清空 Buffer；现在发布端发送的任何东西，除非被网络丢包了，只要接收端可以收，它就可以解码。这一点很重要，尤其是在丢包网络的情况下，这么做可以避免带宽浪费。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/3b/ca/3b8ab62e8eyy8bc2997fa2d1217d1aca.png\" /></p><p></p><p>智能参考帧的关键是在发布端和接收端维护一样的参考帧关系，即，接收端需要把它的参考帧关系通过编一个很精炼的信息来传递给发布端。通过在 RTCP 加入 ACK（Acknowledgement），接收端告诉发布端它已经收到并完整解码了哪些帧，这些帧可以进入参考帧关系结构，一旦发生弱网，接收端就告诉发布端取消 PLI，不再请求I帧，而是请求 LTR，避免弱网情况下发I帧导致弱网情况更恶化、甚至导致卡死的状况。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/9y/a7/9yye1fee5yy54740121e14f45c9347a7.png\" /></p><p></p><p>智能参考帧技术在一些对卡顿、延时比较敏感的场景中对提升用户体验有很大帮助，比如在抖音好友通话场景中，通过智能参考帧，“大卡”比例下降了 14%（两秒钟不出帧的“大卡”比“小卡”对用户体验的影响要大很多），而在一般的卡顿指标上，200ms 卡顿和 500ms 卡顿分别下降了 2.6% 和 0.7%。另外，智能参考帧在很大程度上也解决了延时的问题。刚才有提到，智能参考帧只要收到就能解码，而不需要通过重传，因此在智能参考帧中大部分重传是可以被关掉的，关掉后延时可以降低 11%，也就是说， 200ms 的传输可以减少 20ms，端到端延时 200ms 的达标率可以提升 16%。</p><p></p><p></p><h2>视频端到端优化技术的未来展望</h2><p></p><p></p><p>以上三个故事就是利用收发联动优化的技术解决视频参数上升、带宽限制下的视频修复、弱网丢包、延时、“大卡”体验的问题，未来我们还可以做哪些优化呢？</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/5d/a8/5d7ebc80c142948b40bb91d8e93e83a8.png\" /></p><p></p><p>在「超分辨率」上，除了告诉接收端它可以开关超分，针对线上不同的机型，我们还可以推荐它使用不同的模型，比如高端一点的机型可以使用复杂一点、强一点的模型，我们可以告诉接收端哪个模型最适合它，哪个模型的“性价比”更高。另外，发布端其实是可以知道接收端有没有超分的能力，如果知道接收端有超分的能力，那么在碰到弱网的时候，发布端可以更进一步地去主动降低分辨率。</p><p></p><p>现在的做法虽然也可以主动降低分辨率，但做得不够激进，因为发布端并不“确定”接收端能不能开启超分。如果发布端“确定”接收端可以开启超分，那么，也许本来是在 200K 的带宽才降低分辨率，现在甚至可以在 300K 的带宽下就降低分辨率——因为降低分辨率后之后再进行画质修复的效果，会比不降分辨率直接传输的效果更好。这就是所谓的 SR-aware 参数选择。</p><p></p><p>在「内容检测」上，我们也可以扩展一下，目前内容检测的结果是非黑即白的，即，内容的分类不是 PPT 就是视频，未来它会向更精细的视频分析方向演进，比如检测视频内容是运动的还是偏静止的，是复杂的运动还是简单的运动（比如是有人在跳舞健身，还是只是一个主播在播新闻）。视频和PPT是两个非常极端的场景，中间频谱上还可以细分很多档位，每一个档位都可以有不同的视频参数以及弱网对抗的策略（比如运动的内容可能需要 60FPS，但是一个静态的主播可能只需要 15FPS）。未来，内容检测可以告诉我们这个视频的复杂程度、或运动的程度是怎么样，而不只是简单告诉我们它是文字还是视频。</p><p></p><p>在「智能参考帧」上，智能参考帧技术和编解码器有强绑定的关系，目前支持智能参考帧的硬件编码器非常少，基本只支持 Nvidia 和 Intel 这类比较常见的硬件，iOS 跟 Android 大部分没有硬件编码器支持，这会把智能参考帧的性能限制在软件编码器中，而用软编实现的方案会限制智能参考帧只能应用在一些分辨率较低的场景。未来，智能参考帧技术还将往移动端硬件方向进一步发展，研究让更多的硬件编码器来支持这个技术，拓展更多高分辨率的应用场景。</p><p>&nbsp;</p><p>未来，RTC的问题会越来越破碎化，特别是当我们进入深水区以后。「上下行联动优化」是一种方式，希望以上这些分享可以帮助大家在一堆混乱的麻绪之中理出一些思路，来思考或解决一些问题。</p>",
    "publish_time": "2023-02-16 13:10:07",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "穷人的 API",
    "url": "https://www.infoq.cn/article/Xd171zBPrIY4zTeujQ1m",
    "summary": "<p>创建成熟的API需要资源，包括时间和金钱。你需要考虑模型、设计、REST原则等方面的东西。大多数情况下，你不知道这样做是否值得：你只是想要做出一个最小可行性产品，然后基于这个产品开始迭代。现在，我想向你展示如何在不编写一行代码的情况下实现它。</p><p></p><h2>解决方案</h2><p></p><p>&nbsp;</p><p>解决方案的主要要求是使用PostgreSQL数据库，这是一个功能完善的开源SQL数据库。</p><p>&nbsp;</p><p>我们不编写REST API，而是使用PostgREST组件。</p><p>&nbsp;</p><p></p><blockquote>PostgREST是一个独立的Web服务器，可以将PostgreSQL数据库直接转换成REST API。数据库的结构约束和权限决定了API有哪些端点和操作。&nbsp;—— PostgREST官网</blockquote><p></p><p>&nbsp;</p><p>我们将在一个简单的场景中使用它。下面是一张我想通过CRUD API暴露出来的product数据表。</p><p><img src=\"https://static001.geekbang.org/infoq/1d/1df0304c66045f1307ddf28d37f11b03.png\" /></p><p></p><p>&nbsp;</p><p>PostgREST的入门指南（<a href=\"https://postgrest.org/en/stable/tutorials/tut0.html\">https://postgrest.org/en/stable/tutorials/tut0.html</a>\"）提供了完整的内容，不过我没有找到现成的Docker镜像，所以自己创建了一个。</p><p>&nbsp;</p><p>Dockerfile：</p><p><img src=\"https://static001.geekbang.org/infoq/86/863eb61c711328de75680f717add4b10.png\" /></p><p></p><p>基于最新的Debian。参数化构建。获取二进制包。安装依赖项并解压二进制包。</p><p>&nbsp;</p><p>Docker镜像的/postgrest文件夹中有一个postgrest可执行文件。我们可以通过Docker Compose来“部署”。</p><p>&nbsp;</p><p>docker-compose.yml：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/83/83ea6a75d7ccf32adc2bbc9c317ffe93.png\" /></p><p></p><p>构建上面的Dockerfile。共享配置文件。运行postgrest可执行文件。使用配置文件。初始化Schema、权限和数据。</p><p>&nbsp;</p><p>这个时候，我们可以查询product表：</p><p><code lang=\"null\">curl localhost:3000/product</code></p><p>&nbsp;</p><p>我们会立即得到结果：</p><p><code lang=\"null\">[{\"id\":1,\"name\":\"Stickers pack\",\"description\":\"A pack of rad stickers to display on your laptop or wherever you feel like. Show your love for Apache APISIX\",\"price\":0.49,\"hero\":false},\n {\"id\":2,\"name\":\"Lapel pin\",\"description\":\"With this \\\"Powered by Apache APISIX\\\" lapel pin, support your favorite API Gateway and let everybody know about it.\",\"price\":1.49,\"hero\":false},\n {\"id\":3,\"name\":\"Tee-Shirt\",\"description\":\"The classic geek product! At a conference, at home, at work, this tee-shirt will be your best friend.\",\"price\":9.99,\"hero\":true}]</code></p><p>&nbsp;</p><p>真是立竿见影！</p><p></p><h2>改进解决方案</h2><p></p><p>&nbsp;</p><p>虽然这个解决方案是有效的，但还有很大的改进空间。例如，虽然用户不能修改数据，但每个人都可以访问到它。对于产品相关的数据，这可能不是一个大问题，但对于医疗数据呢？</p><p>&nbsp;</p><p>PostgREST文档提到了这个问题，并明确建议使用反向代理：</p><p>&nbsp;</p><p></p><blockquote>PostgREST是快速构造REST API的一种方法，默认情况下非常适合用于构建开发脚手架。它也可以进入到生产环境，只要你需要采取一些预防措施。PostgREST只是一个用于实现API到数据库映射的小工具，我们需要依靠像Nginx这样的反向代理来提供额外的安全性保障。&nbsp;—— PostgREST官网</blockquote><p></p><p>&nbsp;</p><p>不过我们没有使用Nginx，而是一个成熟的API网关——Apache APISIX。我们把它添加到Docker Compose中。</p><p>&nbsp;</p><p>docker-compose.yml</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d3/d3fdf5f094f16a428aaaf455607b36ac.png\" /></p><p></p><p>&nbsp;</p><p>使用Apache APISIX。APISIX将配置存储在etcd中。</p><p>&nbsp;</p><p>我们先配置Apache APISIX，用它来代理对postgrest的调用：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/14/1460d15e976f4f0759c2b6f22033b326.png\" /></p><p></p><p>&nbsp;</p><p>应该运行在其中一个Docker节点上，因此使用Docker镜像名称。或者也可以使用localhost，但一定要公开端口。创建可重用的上游。指向PostgREST节点。创建到上游的路由。</p><p>&nbsp;</p><p>现在，我们可以通过APISIX来查询端点：</p><p><code lang=\"null\">curl localhost:9080/product</code></p><p>&nbsp;</p><p>它返回与之前相同的结果。</p><p></p><h2>DDoS攻击保护</h2><p></p><p>&nbsp;</p><p>我们还没有加入任何东西，不过我们已经做好准备了。我们首先需要保护API免受DDoS攻击。Apache APISIX是基于插件架构而设计的，为了防止DDoS攻击，我们将使用一个插件。我们可以在创建路由时设置插件，也可以在每个路由上设置插件。如果是第二种情况，就变成了全局规则。我们希望默认保护每一个路由，因此我们将使用第二种方式。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0e/0e793097a7335378fa062d219181273a.png\" /></p><p></p><p>limit-count限制一个时间窗口内的调用次数。限制为每5秒调用1次，这只是为了演示。返回“429 Too Many Requests”，默认值为503。</p><p>&nbsp;</p><p>现在，如果我们发送了太多请求，Apache APISIX会保护上游：</p><p>&nbsp;</p><p><code lang=\"null\">curl localhost:9080/product\n\n\n\n429 Too Many Requests\n\n</code></p><center><h1><code lang=\"null\">429 Too Many Requests</code></h1></center><code lang=\"null\">\n<hr /><center>openresty</center>\n\n</code><p></p><p>&nbsp;</p><p></p><h2>路由授权</h2><p></p><p>&nbsp;</p><p>PostgREST还提供了一个root的Open API端点，因此我们有两个路由：/用于遵循Open API规范，/product是产品的相关端点。假设我们想禁止未经授权的人访问我们的数据，即普通用户可以访问产品信息，admin用户可以访问Open API规范和产品信息。</p><p>&nbsp;</p><p>APISIX提供了几种身份验证方法。我们将使用最简单的key-auth。它依赖了消费者抽象，key-auth需要一个特定的标头：插件对标头中的值进行反向查找，并找到对应的消费者。</p><p>&nbsp;</p><p>下面演示如何创建一个消费者：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/85/85357d3d7c8e472ed139b4630479f478.png\" /></p><p></p><p>创建新的消费者。消费者的名字。消费者的键值。</p><p>&nbsp;</p><p>我们也为消费者user和键user做同样的事情。现在，我们可以创建一个路由并配置它，只让来自admin的请求通过：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ba/bada96e42d8096c93eb1347522b0346e.png\" /></p><p></p><p>创建一个新的路由。使用key-auth和消费者限制插件。只有管理员认证的请求才能调用路由。</p><p>&nbsp;</p><p>我们来尝试一下：</p><p><code lang=\"null\">curl localhost:9080</code></p><p>&nbsp;</p><p>无法调用，因为我们没有通过API标头进行身份验证：</p><p><code lang=\"null\">{\"message\":\"Missing API key found in request\"}</code></p><p>&nbsp;</p><p><code lang=\"null\">curl -H \"apikey: user\" localhost:9080</code></p><p>&nbsp;</p><p>也无法调用，因为我们使用了user的身份，但路由只授权给了admin身份。</p><p>&nbsp;</p><p><code lang=\"null\">{\"message\":\"The consumer_name is forbidden.\"}</code></p><p>&nbsp;</p><p><code lang=\"null\">curl -H \"apikey: admin\" localhost:9080</code></p><p>&nbsp;</p><p>这一次，它像预期的那样返回Open API规范。</p><p></p><h2>监控</h2><p></p><p>&nbsp;</p><p>任何一个软件系统都有一个被低估的特性，那就是监控。在将组件部署到生产环境中后，我们就必须监控其运行状况。现在，我们有许多服务可用于监控。我们将使用Prometheus，因为它是开源的，经过了实战的考验，并已被广泛使用。为了显示监控数据，我们将使用Grafana。我们把组件添加到Docker Compose文件中。</p><p>&nbsp;</p><p>docker-compose.yml</p><p><img src=\"https://static001.geekbang.org/infoq/02/02bea5ec8fd61b033bd405b663cf59e6.png\" /></p><p></p><p>&nbsp;</p><p>Prometheus镜像。Prometheus的配置。可以在这里（<a href=\"https://github.com/ajavageek/poor-man-api/blob/master/prometheus/prometheus.yml\">https://github.com/ajavageek/poor-man-api/blob/master/prometheus/prometheus.yml</a>\"）查看完整的文件。Grafana镜像。Grafana的配置。其中大部分来自APISIX提供的配置（<a href=\"https://github.com/apache/apisix/blob/master/docs/assets/other/json/apisix-grafana-dashboard.json\">https://github.com/apache/apisix/blob/master/docs/assets/other/json/apisix-grafana-dashboard.json</a>\"）。将默认端口3000改为3001，避免与PostgREST服务冲突。</p><p>&nbsp;</p><p>有了监控基础设施之后，我们只需要APISIX按照Prometheus期望的格式提供数据即可。我们可以通过配置和一个新的全局规则来实现。</p><p>&nbsp;</p><p>config.yaml</p><p><img src=\"https://static001.geekbang.org/infoq/5e/5e50b891ffc5dfa5b29cc8769ee2c96a.png\" /></p><p></p><p>&nbsp;</p><p>绑定到任意地址。绑定到9091端口。Prometheus的指标信息可参考<a href=\"http://apisix:9091/apisix/prometheus/metrics\">http://apisix:9091/apisix/prometheus/metrics</a>\"。</p><p>&nbsp;</p><p>我们可以创建全局规则：</p><p><code lang=\"null\">curl http://apisix:9080/apisix/admin/global_rules/2 -H 'X-API-KEY: 123xyz' -X PUT -d '\n{\n  \"plugins\": {\n    \"prometheus\": {}\n  }\n}'</code></p><p>&nbsp;</p><p>发送几个查询并打开Grafana仪表板，看起来应该像这样：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/74/74ec99b5d860bfd065c3fb640c9ff290.png\" /></p><p></p><p></p><h2>结论</h2><p></p><p>&nbsp;</p><p>创建一个完整的REST API是一项巨大的投资。我们可以通过PostgREST将数据库暴露成CRUD API，进行快速简单的测试。当然，这样的架构并不适用于生产环境。</p><p>&nbsp;</p><p>要解决这个问题，我们需要在PostgREST前面设置一个门面，可以是反向代理或API网关。Apache APISIX提供了很多特性，包括授权和监控等。有了它，我们就可以用较低的成本快速验证API需求。</p><p>&nbsp;</p><p>在验证了需求后，我们可以保留现有的门面，并用定制开发的API替换PostgREST。</p><p>&nbsp;</p><p>这篇文章相关的完整源代码可以在Github（<a href=\"https://github.com/ajavageek/poor-man-api\">https://github.com/ajavageek/poor-man-api</a>\"）上找到。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://blog.frankel.ch/poor-man-api/\">https://blog.frankel.ch/poor-man-api/</a>\"</p><p></p><p>推荐阅读：</p><p><a href=\"https://www.infoq.cn/article/UCaTitOegreb3NGiX24m\">一个架构师在 2023 年需要掌握哪些“必杀技”？</a>\"</p>",
    "publish_time": "2023-02-16 14:24:48",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "ASML指控前中国员工窃取芯片相关数据，不涉及核心技术但被迫开始调查",
    "url": "https://www.infoq.cn/article/Lh48QkNvj0BIhP4Tihll",
    "summary": "<p>荷兰的 ASML是世界上最重要的半导体公司之一。在近日<a href=\"https://www.asml.com/en/investors/annual-report/2022/highlights#ceo-message\">公布的年度报告</a>\"中，ASML 表示：“我们在中国经历了一名(现)前员工未经授权盗用与专有技术有关的数据。我们迅速启动了全面的内部审查。”</p><p>&nbsp;</p><p>根据初步调查结果，ASML 认为这次事件对其业务不存在重大影响，然而这可能已违反了某些出口管制条例。因此，ASML已向有关部门报告了该事件。针对这一事件，ASML 正在实施额外的补救措施。</p><p>&nbsp;</p><p>对于被盗用的数据涉及文件，ASML 没有详细说明。不过根据<a href=\"https://www.bnnbloomberg.ca/asml-stolen-data-came-from-detailed-repository-for-chip-machines-1.1884443\">彭博社的报道</a>\"，该漏洞发生在一个存储库中，该存储库包含了对生产一些世界上最先进的芯片至关重要的光刻系统的详细信息。</p><p>&nbsp;</p><p>据报道，这些数据来自一个名为Teamcenter的产品生命周期管理程序，Teamcenter工具用于内部共享信息。</p><p>&nbsp;</p><p>根据提供该软件的西门子网站介绍，Teamcenter 充当技术信息的共享仓库，允许不同的员工团队协作和管理他们的产品开发。据该网站称，它允许“共同访问所有与产品相关的知识、数据和流程的单一存储库”。据悉，ASML使用该程序存储有关其机器的详细信息。</p><p>&nbsp;</p><p>据另一位知情人士透露，ASML 最近的数据泄露涉及技术信息而非硬件，并且是在过去几个月由一名男性员工实施的。这位不愿透露姓名的人士表示，美国当局已收到通知，因为调查仍在进行中。</p><p>&nbsp;</p><p>荷兰对外贸易和发展合作部长 Liesje Schreinemacher 表示，ASML 已将此事告知政府，目前正在进行调查。</p><p></p><h2>ASML的关键角色</h2><p></p><p>&nbsp;</p><p>ASML在芯片供应链中占有独特的地位。ASML 不生产芯片，相反它制造并向台积电等半导体制造商销售价值 2 亿美元的极紫外 (EUV) 光刻机。这些制造商需要使用这些机器来制造世界上最先进的芯片，而 ASML 实际上在这个领域处于垄断地位，因为ASML 是世界上唯一一家生产这种套件的公司。</p><p>&nbsp;</p><p>根据 ASML 首席执行官 Peter Wennink&nbsp; 的说法，ASML 在过去十年中总共售出了大约 140 套 EUV 系统，每套成本高达 2 亿美元，而其下一台名为High NA 的机器价格将超过 3 亿美元。</p><p>&nbsp;</p><p>根据最新财报，ASML第四季度净销售额达到64亿欧元，毛利率51.5%，净利润达18亿欧元。第四季度订单金额为63亿欧元，其中包括34亿欧元的EUV系统。2022全年净销售额达到212亿欧元，毛利率为50.5%，净利润为56亿欧元。</p><p>&nbsp;</p><p>ASML 的主导地位是近些年才形成的。十年前，该公司的EUV研究能力取决于英特尔、三星和台积电的重大投资。&nbsp;</p><p>&nbsp;</p><p>“我们没有钱，”1999 年加入 ASML 的 Wennink 表示，“所以我们出去寻找合作伙伴，这实际上是我们建立公司方式的基础。所以我们被迫成为系统架构师和系统集成商。”</p><p>&nbsp;</p><p>ASML 于 1984 年开始作为荷兰电子巨头飞利浦的子公司运行，它推出了第一台用于半导体光刻的机器。“第一台光刻工具真的看起来像一台投影仪，”ASML EUV 执行副总裁 Christophe Fouquet 表示，“基本上有一个掩模版，保存着你想要投射的图像。然后是一个光学系统，它将拍摄这个图像并将其投射到晶圆上。”</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8b/8b8eef3840773b5432238fc02f92bfc3.png\" /></p><p></p><p>ASML 于 1984 年在荷兰Eindhoven飞利浦办公大楼外的一个漏水棚子里开发了第一台光刻系统</p><p>&nbsp;</p><p>即将出版的《芯片战争：争夺世界上最关键技术的战争》一书的作者Miller&nbsp;表示，“当业界准备进入极紫外辐射研究的早期阶段时，没有一家美国公司准备冒险进行这项昂贵且有风险的提议，但ASML准备好了。”“ASML是一家荷兰公司，但它也是一家非常依赖美国零部件的荷兰公司，尤其是在其机器方面。”</p><p></p><h2>出口管制“不是我们的选择”</h2><p></p><p>&nbsp;</p><p>这起安全事件发生在荷兰政府与美国外交的敏感时期，荷兰政府处于中美科技霸权的漩涡之中，半导体是这场竞争的重要组成部分。</p><p>&nbsp;</p><p>EUV 由数个模块组成，包含了数十万个组件，它们来自全球近 800 家供应商。每个模块都在 ASML全球<a href=\"https://www.asml.com/en/company/about-asml/locations\">60 个地点之一建造，然后运往 Veldhoven 进行组装。</a>\"每台组装好的机器经过测试后，会被拆开运往芯片制造商。运输需要 20 辆卡车和三架满载的<a href=\"https://www.cnbc.com/quotes/BA/\">波音</a>\"747s。&nbsp;但 ASML 不会将其 EUV 技术运送到的国家是中国。</p><p>&nbsp;</p><p>自 2018 年以来，美国向荷兰政府施压，要求其停止 ASML 向中国运送 EUV 机器。ASML 便从此未将工具运送到中国。上个月，<a href=\"https://www.bloomberg.com/news/articles/2023-01-27/biden-wins-deal-with-dutch-japan-on-china-chip-export-controls\">彭博社</a>\"报道称，美国与日本和荷兰达成协议，限制向中国出口先进芯片制造设备。</p><p>&nbsp;</p><p>对此，ASML回应称：“我们了解到，已经采取的措施将涵盖先进的光刻工具以及其他类型的设备。该协议的条款尚未公开披露，目前仍处于保密状态。我们预计政府将需要数月时间才能编写和制定新规则。”</p><p>&nbsp;</p><p>如今，ASML 仅将机器出售给五家芯片制造商。其中，台积电、三星和英特尔在 2021 年为其贡献了将近 84%的收入。</p><p>&nbsp;</p><p>“全球有 42 个国家同意对其实施出口管制措施，”Wennink 表示，“所以这不是我们的选择，而是政府的选择。”</p><p>&nbsp;</p><p>据外媒CNBC称，ASML 在以另一种身份与中国打交道。该公司翻新了称为深紫外线或 DUV 的旧光刻系统，并将其中许多系统出口给了中国。Wennink 表示， ASML 售出的所有机器中有 96% 仍在工作。根据报告，2022 年中国占ASML 销售额的 15% 左右，今年将达到“相似”的水平。</p><p>&nbsp;</p><p></p><h2>结束语</h2><p></p><p>&nbsp;</p><p>有美国媒体指出，这次与中国相关的数据盗用事件并不是第一次。</p><p>&nbsp;</p><p><a href=\"https://www.asml.com/en/investors/annual-report/2021\">ASML 在2021年的年度报告中指出，一家名为东方晶源电子的公司</a>\"“在中国积极销售可能侵犯 ASML 知识产权的产品。”ASML提到，东方晶源与一家已经破产的美国公司XTAL存在关联，2019年美国法院曾判定XTAL侵犯ASML知识产权。</p><p>&nbsp;</p><p>根据报道，东方晶源申请了146件国内外发明专利，其中70%的员工都是研究人员，其中博士占8%，硕士研究生占53%。去年11月份，东方晶源宣布完成新一轮近10亿元股权融资。东方晶源后来发表声明否认了这些报道，之后该事件暂无新的进展。</p><p>&nbsp;</p><p>但对于ASML 来说，技术垄断也意味着树大招风。ASML 在另一份声明中表示，看到越来越多的攻击者试图窃取其技术。</p><p>&nbsp;</p><p>ASML发言人称，“由于 ASML 的独特地位和半导体行业日益加剧的地缘政治紧张局势，我们看到安全风险不断上升：从勒索软件和网络钓鱼攻击，到试图获取知识产权或破坏业务连续性。”</p><p>&nbsp;</p><p>参考资料：</p><p><a href=\"https://www.cnbc.com/2023/02/15/critical-chip-firm-asml-says-former-china-employee-misappropriated-data.html\">https://www.cnbc.com/2023/02/15/critical-chip-firm-asml-says-former-china-employee-misappropriated-data.html</a>\"</p><p><a href=\"https://www.bnnbloomberg.ca/asml-stolen-data-came-from-detailed-repository-for-chip-machines-1.1884443\">https://www.bnnbloomberg.ca/asml-stolen-data-came-from-detailed-repository-for-chip-machines-1.1884443</a>\"</p><p><a href=\"https://www.cnbc.com/2022/03/23/inside-asml-the-company-advanced-chipmakers-use-for-euv-lithography.html\">https://www.cnbc.com/2022/03/23/inside-asml-the-company-advanced-chipmakers-use-for-euv-lithography.html</a>\"</p><p></p><p>今日推荐：</p><p><a href=\"https://www.infoq.cn/article/UCaTitOegreb3NGiX24m\">一个架构师在 2023 年需要掌握哪些“必杀技”？</a>\"</p>",
    "publish_time": "2023-02-16 14:33:05",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "蚂蚁自研图数据库TuGraph国际权威测评再创纪录，已全面支持国产软硬件",
    "url": "https://www.infoq.cn/article/KwyY33CqqageY9LyjLch",
    "summary": "<p>在最近一次国际权威图数据库基准测评“LDBC SNB”测评中，蚂蚁集团自研图数据库 TuGraph 采用国产CPU，打破了官方审计纪录蝉联世界第一。基于自身性能优势以及对国产 CPU 的良好适配，测评结果较上一次提升了31%。这意味着 TuGraph 已经全面支持了国产软硬件，且领先性得到了权威验证。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/e1/e12c541fe36dc5a49ad477027c13eecd.png\" /></p><p>（图注：LDBC公布蚂蚁集团TuGraph打破LDBC SNB测评纪录）</p><p>&nbsp;</p><p>本次测评 TuGraph 采用的是国产倚天 710&nbsp;ARM 架构CPU，这是中国首个云上大规模应用的自研CPU。TuGraph对新硬件进行了适配调优，在大规模100GB的数据集上，TuGraph的吞吐率较上一次官方纪录提升了31%，云端机器开销降低了40%，大大提升了资源能效。</p><p></p><p>ARM架构的 CPU 拥有轻量化、功耗小的优势，近年来基于 ARM 架构的 CPU 越来越普遍。据统计，个人PC行业苹果 M1/M2 芯片均采用 ARM 架构，手机行业 ARM 芯片已占90%以上份额，在服务器领域华为鲲鹏、飞腾等 ARM 架构 CPU 也逐步被接纳。</p><p></p><p>作为开源的图数据库产品，TuGraph需要兼容国内外软硬件，更需要充分发挥出国产新型软硬件的优势。本次测评不仅验证了 TuGraph 对于 ARM 架构的兼容性，成为对 X86 和 ARM 架构均完整适配的图数据库，也使得 TuGraph 继麒麟、鲲鹏、海光等国产操作系统和处理器之后，实现了对国产软硬件的全面支持，为用户的机器选型提供更多选择。</p><p></p><p>近年来 TuGraph 在技术迭代、产品化等方面持续突破，并通过开源开放的形式与社会共享。去年9月，TuGraph单机版在世界人工智能大会上开源，可提供完备的图数据库基础功能。去年12月，TuGraph上线阿里云计算巢，用户可一键部署，快速打造图数据库应用。据悉，本次测评的代码和流程已在 GitHub 开源，开发者可在云上复现测评流程。下一步，TuGraph计划接入亚马逊云，为全球用户提供领先的图计算服务。</p><p></p><p>&nbsp;“国际关联数据基准委员会（LDBC）”是由高校、研究所、企业联合组成的非盈利组织，其中企业成员包括Intel、Oracle、Neo4j、蚂蚁集团等国内外知名图数据库厂商，致力于推进行业的规范标准化。SNB是LDBC主导的基于社交网络的基准测评，是国际图数据库领域公认的权威测评，为评估图数据库的性能和使用选型提供了专业、客观的参考标准。</p>",
    "publish_time": "2023-02-16 14:48:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "企业容器云管理平台选型指南",
    "url": "https://www.infoq.cn/article/KizStJ21rQmmXNB9Nirv",
    "summary": "<p></p><p></p><h2>数字时代下的容器云管理平台</h2><p></p><p></p><p>数字时代，市场竞争加剧，业务需求日新月异，敏态IT建设被越来越多的企业纳入重点发展规划，以容器、Kubernetes为核心的云原生是目前敏态IT中最热门的技术架构。</p><p>&nbsp;</p><p>CNCF把云原生划分为多个领域，包括基础设施、应用开发与部署、服务发布与治理、运行时、网络、存储、观测与分析、安全与合规等，每个领域中都有非常丰富的开源项目。从技术视角来看，云原生建设就是在各领域中找到能够满足自身需求的技术，并组合起来，为我们所用。在这个过程中，我们直面的问题包括：如何选择合适的技术？如何对这一技术组合进行统一管理？如何调整和优化这些技术以实现高效、稳定的运行？</p><p>&nbsp;</p><p>对此，容器云管理平台的概念应运而生，简单地说就是提供一系列开箱即用的功能，并围绕Kubernetes提供更多的扩展和创新。容器云管理平台是一个中间态的产品，对下能够实现集群的生命周期管理，对上能够实现对Kubernetes上运行的应用的生命周期管理，同时还需具备企业所需的功能，如租户管理、安全管理、用户认证以及权限管理等。</p><p>&nbsp;</p><p>目前，国内有不少厂商专注于这个领域，提供了很多优秀的解决方案，面对琳琅满目的产品，我们该如何选择？</p><p>&nbsp;</p><p></p><h2>平台选型</h2><p></p><p>在日常和企业客户的交流中我不难们发现，大家在建设云原生平台过程中，讨论最多的就是规划和选型问题。如果把选型过程比作通关游戏，那么我们会遇到性质思考、模式思考和能力思考三个关卡。</p><p>&nbsp;</p><p></p><h3>性质思考&nbsp;</h3><p></p><p>&nbsp;</p><p>从企业实际应用场景来看，容器云管理平台是一个跨部门平台，至少会涉及基础设施部门、研发部门、安全部门；当然，不同企业对部门的划分可能会更细致。而且，容器云管理平台和业务应用又有着紧密的关联性，他会影响业务应用的构建发布流程和运行运维方式，所以从整体看来容器云管理平台具备了2个特点：技术上的确定性和能力上的特异性。</p><p></p><p>技术上的确定性：在建设容器云管理平台时，相关的技术栈基本是确定的，例如容器编排调度引擎使用Kubernetes，监控使用Prometheus，日志使用ELK或者Loki，模板商店使用Helm等，还有像容器运行时、网络、存储等也都有很清晰的选择范围。能力上的特异性：每个企业IT部门都有自己的工作方式、流程、组织架构和内部环境，对容器云管理平台建设都有自己的看法。有些企业的容器云管理平台相对独立；有些可能需要与内部的其他系统做集成和联动，如与内部监控集成形成统一环境监控，与内部日志平台集成形成统一认证，与内部用户认证平台集成实现sso单点登录，需要与组织架构相对应的多租户能力等，这就需要不同的能力支持。从这个角度来讲，完全按照自身需求，自研一套容器云管理平台是企业的最优选择。</p><p>&nbsp;</p><p>但是自研的门槛比较高，需要一定的团队和技术实力，大多数企业都不具备这样的能力。商用是更务实的选择，有很多厂商提供了相应的平台产品，但也有不少挑战。虽然平台都基于Kubernetes搭建，但是不同的产品理念，可能造就了不同的功能侧重点，以及未来不同的发展和延伸路线；还有一些产品存在不同程度的捆绑，一旦选错可能将深陷泥淖。</p><p>&nbsp;</p><p>综合来看，选择开源的、兼容性好的商用产品能够在一定程度上实现自研和商用的平衡。一方面，企业可以通过标准化的产品能力和厂商的专业技术支持及赋能，快速培养和提升自身团队对云原生的认知和技术水平；另一方面，在团队能力达标，且标准化的能力已经无法满足内部需求时，企业可以基于开源产品更便捷地进行二次开发。实际上，在团队实力达标的情况下，我们也不太建议一开始就完全自研平台，因为从0-1的建设可能会踩很多坑遇到很多问题，一些功能直接复用开源产品造好的轮子会事半功倍。同时，使用开源产品确保了技术的延续性了，在购买商业支持后，可以大幅的减少人力成本支出和提升人员工作效率，让更多的时间专注在自身的主营业务。</p><p>&nbsp;</p><p></p><h3>模式思考</h3><p></p><p>在明确了性质选择后，我们转角就遇到了第二个选型问题：应该选择全功能模式还是组合功能模式？</p><p>&nbsp;</p><p>当前，各种容器云管理平台产品丰富，大致可以分为两类：功能全面型和开放兼容型。</p><p>功能全面型：平台中功能基本覆盖了云原生所有元素，如包括了Kubernetes集群管理、应用管理、DevOps、微服务治理、中间件等各大板块能力，并且高度封装。开放兼容型：平台中功能以保有核心能力为主，如Kubernetes集群管理、应用管理，其他能力以开箱即用的插件方式提供，具备高度的可替换性。</p><p>&nbsp;</p><p>功能全面的容器云管理平台能够屏蔽掉很多技术细节，企业可以拿来即用；开放兼容型产品可以提供更灵活的组合方式。在早期，容器和Kubernetes技术还不是那么普及，功能全面型的产品是比较好的选择，企业可以借助其全面的能力快速构建，屏蔽掉一些技术门槛，预研云原生技术和带来的价值；当今，容器和Kubernetes技术已经比较普及，整个CNCF生态也进入了繁荣时期，云原生的建设更多是积木式、集成式的组合。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/9e/19/9ec0yyc3d8325b498b04bfd81468be19.png\" /></p><p></p><p>“专业的事情交给专业的人去做”，大而全平台的问题在于整体功能都是内聚的、互相依赖的、标准化的。用户往往在使用时发现，很多地方并不能很好地契合自身需求，还需要替换功能模块。然而在高内聚的布局下，模块的剥离和替换往往难以实现，或者成本很高；所以，越来越多的用户会选择开放兼容性好的产品，在需要替换平台中的某些功能模块时，只需要关闭相应模块，直接进行替换或者集成即可。</p><p>&nbsp;</p><p>同时我们也看到，越来越多功能全面的平台也开始化整为零，固化必备的基础能力，周边能力则以模块插件方式提供，方便用户进行替换。</p><p>&nbsp;</p><p></p><h3>能力思考&nbsp;</h3><p></p><p>走到这一步，选型的思路就比较清晰了。我们遇到的最后一个问题是：除了性质和模式，还需要考虑哪些因素呢？</p><p>&nbsp;</p><p>基于与众多客户的接触，我们提炼出两点：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/9b/bc/9bea884c207600bf0c5a0f00767c05bc.png\" /></p><p></p><p>&nbsp;</p><p>沉淀包含很多方面，比如产品的迭代历史、使用人数，行业落地案例等。这些沉淀可以很好地反映产品的成熟度和稳定性，毕竟大家都不想在生产环境中做第一个吃螃蟹的人，更希望的是有一个成功的参照物可以借鉴。创新是一个企业的灵魂，云原生就像是一列飞驰的高铁，好的产品提供者应该能紧跟技术发展，并不断推陈出新。企业在使用容器云管理平台的同时，在不同的阶段总会出现不同的需求场景和问题，能不能走在用户前面引领用户，并陪伴用户成长，也是选型考虑的一个重要因素。</p><p>&nbsp;</p><p>通过以上三个关卡，想必大家已经有了选型的初步想法。下面让我们从应用场景出发，再对产品选型能力指标做一些考量。</p><p>&nbsp;</p><p></p><h2>场景</h2><p></p><p></p><h3>多集群及环境统一管理&nbsp;</h3><p></p><p>企业中不同类型的Kubernetes集群越来越多，混合管理的需求与日俱增。我们在与客户聊集群规划的时候经常听到：</p><p>我们需要在不同的环境建设Kubernetes集群，包括开发、测试、UAT、生产这些应用比较重要，需要单独的集群支撑，方便重点运维我们X应用是外采的，它的底座也是Kubernetes集群，要把平台管理起来我们之前X部门走的比较靠前，当时用开源工具部署了一个Kubernetes，现在需要暂时管理起来，后续再考虑新建集群并迁移我们除了私有云以外，某公有云上也使用了Kubernetes集群（也想在公有云上使用Kubernetes集群），能否方便地实现混合云管理我们现在容器和VM是共存的状态，整体应用包含了容器运行部分和VM运行部分，有没有能统一管理容器和VM的方式……</p><p>&nbsp;</p><p>在云原生时代，随着企业的不断发展，多云混合云的场景变得越来越普遍。以某零售企业为例，其APP商城平常运行在私有数据中心，在早期业务量不大的时候，即使在大促时也完全可以承载和支撑。但随着企业的不断发展，大促带来的访问压力已经到了本地无法支撑的程度，但是为了应对大促而去扩大私有数据中心规模的做法又不够经济，这会造成平时大量的资源闲置。</p><p>&nbsp;</p><p>最终，该企业采用了混合云方案，在公有云上使用Kubernetes集群，通过统一入口管理私有云集群和公有云集群。当大促来临时，通过公有云临时扩充集群节点，应对压力。</p><p>&nbsp;</p><p>由此可以看出，多集群以及环境的统一管理是考量容器云管理平台的重要能力指标。Kubernetes作为通用基础架构，可以很好地应对多云带来的差异性，满足企业的多云策略需求。从ROI的角度看，容器云管理平台覆盖的公有云类型越多，就越能增强FinOps和多云议价能力。</p><p>&nbsp;</p><p></p><h3>增强式安全防护&nbsp;</h3><p></p><p>从前，大家更关注应用如何容器化、怎样上Kubernetes；而当下，大家越来越关注安全问题。容器安全处于早期发展阶段，还存在一些问题。从技术角度看，Kubernetes自身的安全能力较低，之前版本内置了PSP功能，但也局限在一些与权限相关的防护上；而且，高版本已经废弃了这一功能。CIS虽然提供了Kubernetes基线扫描，但主要用于检测Kubernetes的配置是否有安全隐患，防护面很有限。从知识储备角度看，在多数企业内，懂云原生的工程师不太懂安全，懂安全的又不太了解云原生，这导致容器安全防护建设工作无从下手。</p><p>&nbsp;</p><p>近几年，云原生相关安全事件层出不穷，当事企业遭受了不少损失，安全建设已成为当下亟需解决的问题。一个合格的云原生安全防护平台至少应具备以下能力：</p><p>CICD嵌入能力：可以在流水线中启用防护，比如镜像打包完成后的扫描，实现一定程度的安全左移准入控制能力：可以在应用部署时进行相应防护，尽量降低不安全因素进入集群，如可信仓库和镜像白名单、有安全隐患的部署配置阻断等运行时防护能力：可以在容器运行态上进行相应防护，如网络防护、进程防护、文件防护以零信任为核心的安全防护理念：可以实现零日攻击防护以及一些未知的攻击行为</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/48/26/48bb16c7a8d7791c75e656df19f16b26.png\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>目前有不少厂商专注这一领域，提供的产品也各有特色，可以有效帮助我们补强Kubernetes安全能力不足的问题。综合考虑使用体验、易用性以及统一管理等方面，如果容器云管理平台能提供足够的安全防护能力，那将是最佳的选择。</p><p>&nbsp;</p><p></p><h3>数据中心到边缘&nbsp;</h3><p></p><p>边缘计算是近两年的热门领域，很多企业都在积极布局，利用容器和Kubernetes技术充分发挥云边协同的效能。业界对边缘的定义至今没有统一，不同的企业由于不同的业态对边缘的定义也不尽相同，对于银行来说边缘可以是网点也可以是各种金融终端设备，对于制造业来说边缘可以是工厂侧也可以是产线侧。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/77/775fae828fcd3688c1cab32b129539c4.png\" /></p><p></p><p>&nbsp;</p><p>对于有边缘应用场景的企业来说，选型时首先要考虑平台是否具备实现云边协同的能力，还要考虑云边协同的方案是否有延展性，大能适应各类服务器，小能覆盖各类小型计算资源设备，另外还要考虑能否实现高度的自动化交付从而提升效率。</p><p>&nbsp;</p><p>比如现在边端有海量的设备，一般的部署流程大致是：</p><p>安装操作系统--&gt;安装相应的Kubernetes发行版--&gt;部署边端集群并注册到云端管理平台--&gt;部署各类应用</p><p>&nbsp;</p><p>目前热门的边缘计算交付方式分为两个步骤：</p><p>Day1: 设备通过定制镜像自动部署操作系统及集群，并实现自动注册</p><p>&nbsp;</p><p>Day2: 按照编排需求，GitOps自动同步各类应用到不同边缘集群</p><p>&nbsp;</p><p>可以看出，后者通过自动化极大简化了交付过程，从而提升了整体效率。如果平台能够提供足够弹性的云边协同方案以及高度自动化交付，将为企业带来强劲的边缘计算建设助力。</p><p>&nbsp;</p><p>现在，在实施大多数边缘计算方案的时候，还需要在边缘端投入不少的人力进行前期工作，如操作系统安装，半自动化的Kubernetes发行版安装以及云端注册等，自动化程度越高就越能降低人力成本。</p><p>&nbsp;</p><p></p><h2>写在最后</h2><p></p><p>本文站在行业大视角，为大家提供了一些普遍适用的容器云管理平台考量要素。云原生领域可选择的平台很多，有开源也有闭源，虽然表面上看产品功能有同质化趋势，但其底蕴和理念是不同的。</p><p>&nbsp;</p><p>以&nbsp;Rancher为例，作为最早的一款全开源的容器管理平台，其1.x版本陪伴用户走过了docker swarm、mesos和Kubernetes的三国鼎立时期；2.x版本则紧跟社区和技术发展，专注于Kubernetes管理。在此过程中，Rancher不断总结用户的需求和痛点，围绕Kubernetes推出了很多开源产品，如存储产品Longhorn，边缘计算产品K3s，超融合产品Harvester，安全产品NeuvVector 等，旨在帮助用户解决更多问题，通过Rancher更轻松地设计和构建自己的云原生平台。</p><p></p><p>作者简介：</p><p>涂家英，SUSE&nbsp;资深架构师，专注&nbsp;Cloud-Native&nbsp;相关产品和解决方案设计，在企业级云原生平台建设领域拥有丰富的经验。</p>",
    "publish_time": "2023-02-16 16:15:08",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从中国到全球，阿里交易链路演进历程",
    "url": "https://www.infoq.cn/article/TKx5bJJ8RqU7fehR7ulE",
    "summary": "<p>随着全球化业务的发展，如何将国内成熟的电商能力出海，并满足海外多个市场的差异化诉求，成为了电商平台寻求业务增量的长期目标。随着覆盖市场的增多，作为基础的交易链路，在出海过程中面临着跟国内天差地别的核心挑战，如何应对这些全新的挑战并设计满足全球化特性的交易链路架构成为了我们的主要命题。</p><p></p><p>整个演讲会从 Voyager 进行首次电商能力出海为起点，介绍当需要在海外从 0 到 1 搭建一整套交易链路时，我们是如何进行技术方案和技术架构设计的。之后随着海外业务的不断发展，在面临来自全球多中心、多竞对激烈竞争、新市场扩张等挑战时，我们是如何通过去中心化能力交付架构升级以满足全球多中心独立发展诉求、如何通过交易链路最小集来满足海外新市场低成本快速扩展和合规拆分，以及如何通过允许平台多基线的开放研发体系，支持海外多区域、多时区研发自闭环快速迭代。</p><p></p><p>本文整理自阿里巴巴资深技术专家赵麟翔（勿乞）在 QCon 2022 广州站 演讲分享，主题为“从国内到国际看交易链路架构演进”。</p><p></p><p>本次分享主要涉及阿里巴巴海外业务板块，分享从国内到国际、整条基础交易链路的架构演进，聚焦在整个全球化板块。在面临全球多组织、多区域，多时区，以及全球各种合规挑战时，阿里巴巴海外业务架构如何一步步演进，以适应整个的海外市场。</p><p></p><p>以下是分享实录。</p><p></p><h2>交易链路的业务特点和架构演进出发点</h2><p></p><p>我们先分析交易链路的特点，这里分为国内和国际两个视角。其实里面细节很多，这里只抓几个关键点来说。</p><p></p><p>首先是国内视角下整个交易链路的特点。从 2012 年到 2017 年、再到 2020 年左右，国内采取的策略都是“手淘超级大航母”的策略。这种策略下的交易链路需要为手淘这个中心化的流量场提供统一的购物车、统一的下单，以完成所有商品的购买。同时随着市场和业务的发展，整个淘宝的商品种类也变得越来越多，而不同的商品种类对于交易链路的个性化定制诉求也非常强烈。在这个阶段，整个架构的策略用一句话总结就是，解决手淘单中心流量场下的国内单市场多行业隔离的问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/52/521d2f9a56f3fe41907976e3561427dc.png\" /></p><p></p><p>讲完了国内，让我们转到国际视角。国际的整个演进阶段跟国内相比不太一样。我们大概划分成了四个阶段，从 Voyager 到 Yatra 到 Sirius 再到 Polaris，它们分别代表了每个阶段交易链路的特性。我们整个的架构也是基于这四个阶段不断演进。在阿里内部每次起动公司级的大型战役时，我们都会起一个对应的代号，这些名字就是战役的代号。</p><p></p><p>在 Voyager 阶段，阿里巴巴在 2017 年完成了 Lazada 电商平台的收购，收购了这个电商平台后，集团要求我们完成阿里整个技术栈的出海。Lazada 是一家服务于东南亚市场的本对本电商平台，它的核心是用一个电商品牌支持东南亚、新加坡、马来西亚、印度尼西亚 6 个国家的市场，在 6 个国家的市场间还要支持国家特性隔离，包含币种、时区、语言等对应的国家逻辑。在这个阶段，核心的架构策略就是解决 Lazada 这个单一站点下的多个不同国家之间的市场隔离问题。</p><p></p><p>下一个阶段是 Yatra 阶段，这个阶段我们又收购了一家电商 Daraz。Daraz 是一家服务于南亚的电商平台，包括巴基斯坦，缅甸，尼泊尔等 5 个国家。但是 Daraz 和 Lazada 毕竟是两个单独的公司主体，他们在运营策略、大促策略上面是完全不一样的。在这个阶段，我们整个的架构策略是要解决多站点互相隔离的问题。</p><p></p><p>接下来是 Sirius 阶段。到了这个阶段，我们整个业务策略跟过去的两个阶段比有个本质的区别：不再局限于本对本的单一模式进行发力，而是在新的跨境模式下持续发力并投入更多的资源。比如，我们投了非常多的资源进行 AliExpress（速卖通）跨境能力的建设。除了加大在速卖通这种老牌跨境站点的投入外，我们也在建设 F1 站点，对标 SHEIN 做快时尚。我们不仅聚焦内部的 AE 全品类跨境平台，也对精细化的跨境品类进行发力。这个阶段对整个交易链路的要求是，不仅要具备本对本的能力，同时也要具备跨境的能力。而在具备这种多模式的能力要求下，我们也看到不同的站点所需要的模式是不一样的，所以在这个阶段，我们整个架构演进的策略是解决多模式灵活扩张的问题。</p><p></p><p>最后到了 Polaris 阶段。在经过前三个阶段后，我们不管是收购也好，自己内部新建品牌也好，还是通过建立二方合资公司也好，都使我们的电商占比非常高，覆盖了全球的各个区域。但覆盖的每一个区域、每一个电商品牌背后都是由独立的业务运作组织，这必然面临更多的市场竟对。在这个阶段，对于整个交易链路的架构要求是为每个独立的业务运作组织匹配研发节奏，即无论 Lazada、AE 还是 Daraz，保障各组织之间互相的研发节奏相互并行，并能根据不同的站点业务策略做快速的响应。这个阶段要解决的核心问题是多站点自主闭环，让整个研发结构解耦。</p><p></p><h2>架构演进主线</h2><p></p><p></p><h3>单市场交易链路典型架构实现</h3><p></p><p>这里先分享一些国内市场的架构实现。我们内部有很多框架实现细节，这里就不展开了。我想给大家介绍的一点是，到现在为止，我们国内每年支持双十一整体大流量的国内交易平台的挑战。在这个阶段要解决的核心问题是，国内单市场下的多行业隔离。</p><p></p><p>我们面临两个挑战。第一个是要为手淘中心化的流量入口提供统一的购物车和统一的下单，并且要保证这个中心化流量入口的全局稳定性。第二个挑战是支持行业的差异，因为话费充值、游戏充值、生鲜业务下单以及购物车是不一样的。</p><p></p><p>面对上述两个挑战，我们面临的是要在全局稳定性和可扩展性之间做取舍。所谓“没有完美的架构，只有适合的架构”，我们需要尽量控制逻辑改动，以保证手淘这个超级 App 的基础链路的下单稳定性，从而做到手淘整条链路的高可用。在这个背景下，整套架构采取的策略是稳定为主、扩展为辅。我们将整个架构实现分为了业务层、应用层和平台层三层。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/71/71f2e9784b18dedccd5c46297e1d2d42.png\" /></p><p></p><p>从下往上讲，首先在平台层，为了保障稳定性，我们把核心流程、核心逻辑进行了收敛。在平台层的核心逻辑之上，提供一些局部的、面向行业维度的扩展点，允许行业自行定制。在最上面的业务层，我们为不同的行业分配不同的行业插件。这个行业插件主要有两部分组成：第一部分是业务身份，就是每个行业配一个全局独立的 Stream 字符串标识的业务身份；第二部分是把行业特殊的定制逻辑放到对应的行业插件内。</p><p></p><p>完成了平台跟业务分层之后，在应用层我们采取的方案是中心化应用方案。在中心化应用方案发布过程中，我们采用平台集成业务的方式，提供统一的发布通道，在这个过程中加载业务层的各种平台插件，统一形成一个平台中心化应用。当真正的用户请求到来的时候，通过应用层的一套统一调度框架完成调度。</p><p></p><p>请求调度框架的细节相对比较复杂，我从模块的角度讲讲它做的几件事情。第一件事情是身份识别，当请求到来之后，需要通过请求识别对应的业务身份是什么，这是第一步必须要做的事情。完成了业务身份识别之后，第二步要通过这个业务身份找到对应的平台流程，之后才能进入整个平台的逻辑处理过程。在平台逻辑的处理过程中，会找到对应的域服务，每个域服务会提供对应的 Ext 扩展点。第一步身份识别产生的业务身份走到扩展点后，通过回调定制找到那个行业对应的定制逻辑。我们把这套架构叫做中心化平台集成业务的架构。这套架构很好地保障了整个交易链路稳定性的同时，还提供了局部扩展的能力。</p><p></p><p>海外 V1.0：多市场交易链路多租户架构实现</p><p></p><p>海外 V1.0 的架构策略是解决单站点的多市场隔离问题。我们面临两个挑战。第一个挑战是要设计一套架构，满足 Lazada 一个站点支持 6 个国家的特性。第二个挑战是，因为 Lazada 是收购的来，我们需要在最短时间内用最低成本完成它的遗留系统的逻辑切换。Lazada 有 6 个国家，我们源于这套遗留系统为每个国家搭建了一套独立的系统。</p><p></p><p>为了应对上述两个挑战，在做整个架构决策的时候，我们面临的是在维护成本和隔离性之间的取舍问题。如果要隔离性最高，那就跟过去的架构一样，每个国家一套下单、一套购物车，这个隔离性是最强的，但这套架构方案带来的问题就是任意改动都需要改 6 次、发 6 次，维护成本非常高。我们最终目的是让 Lazada 未来的迭代效率更高、降低它的维护成本，以应对东南亚日益激烈的竞争。此时整个的架构策略是强维护、弱隔离，追求更低的维护成本。低维护成本意味着要牺牲一些隔离性。如图下侧所示，我们没有再去采用每个国家一套系统的物理隔离方案，而是为每个国家单独搭建一个租户插件，通过这个插件实现内部逻辑隔离的架构。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/df/dff5d6633b5f589c7ffa2ef1a204d08c.png\" /></p><p></p><p>这里我详细展开一下。首先在平台层，我们这里叫做 V1.0 阶段。在平台层需要做的工作是把国内的交易链路能力搬到海外。为了减少维护成本，我们做了些减法。我们并没有把国内成本、预售的多阶段交易等复杂功能都搬到海外，而是只选取了最基础的担保交易能力，把它从国内的能力里面抽取出来，将它作为基础搭建了一整套海外的交易平台。</p><p></p><p>我们在应用层的部署方式上也做了一个反潮流的架构。国内整条基础交易链路涉及应用大概有两千多个，为了维护成本更低，我们不可能把这两千个应用都输出到海外。举个例子，大概有 200 人承担这个项目，如果两千个应用出海，意味着每个人平均维护 10 个应用，未来改动成本、维护成本是非常高的。我们在这里做了合并部署，把原来两千多个应用通过合并部署的方式控制在了 15 个以内。这意味着，整个电商站点基础交易链路用 15 个应用完成从 0 到 1 的搭建，这是为了降低整个维护成本而做的取舍架构设计。在隔离性上，我们在业务层为不同国家分配了对应的租户身份，租户身份背后是单独的租户插件，不同国家可以使用租户插件定制语言、币种、时区等与国家相关的信息。</p><p></p><p>在业务层完成了整个租户逻辑隔离之后，数据层上我们并没有采取这个逻辑隔离的方案。因为未来数据合规会越来越严，所以我们为每个国家单独分配了数据库。这样，如果未来某个国家面临合规诉求或者合规挑战的时候，不会影响 Lazada 整个电商站点。当请求来了之后，会识别用户的请求底是哪个租户，根据租户路由到对应的租户插件做逻辑处理，再路由到对应的数据层的数据库，进行对应的数据写入。以上的这整套架构是在 1.0 阶段完成 Lazada 电商站点搭建过程我们所做的事情，即单站点多市场隔离。</p><p></p><h3>海外 V2.0：交易链路从平台中心化到去中心化</h3><p></p><p>我们接下来进入到海外的 V2.0 阶段。在这个阶段，我们工作的核心是把交易链路架构从平台中心化进行去中心化的转变。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/57/5766b1e46838ae50d3651a8c3499b364.png\" /></p><p></p><p>接下来详细为什么要做去中心化。在这个阶段，我们不再只是服务 Lazada 这一家电商站点，我们又收购了 Daraz，同时我们也知道未来要服务的站点会变得越来越多，所以我们需要解决多站点互相隔离问题，需要找到满足海外强隔离诉求的整套架构。为了设计这套架构，我觉得还是需要回到业务特性来分析。在这个阶段，业务坐标系跟国内相比已经发生了非常大的转变。我们不再是国内单市场、多行业组成的二维坐标系，而是已经演进到由多市场、多行业、多站点组成的三维坐标系。这个三维坐标系的每一个平面代表需要支持的一个单独站点，背后是一个单独的电商品牌、单独的业务组织，还有更关键一点：单独的流量，这是业务上的差异。</p><p></p><p>这个阶段在系统架构上的差异是，这里不再是像国内一样一个手淘超级方案共享中心化流量的方式，而是变成了每个单独的站点都有其独特的流量中心。如果仍然采用平台中心化的方式就意味着，在面临全球多站点、多时区的时候，我们每天都需要安排很多同学值班，去帮助每个站点完成对应站点的发布。我们知道电商每年最烦人的、流量最大就是大促。随着站点、时区增多，这个中心化的方式就会导致 4 个站点一年有 4 个月左右的时间都要封网。所谓封网就是，这个时候不能修改代码，不能发布。如果站点多到 8 个，那一年 12 个月都要封网，陷入无休止的互相排队。同时背后还有一个问题就是，如果仍然采用国内这种中心化应用的架构方案，如果 Lazada 站点出了重大故障，一定会影响 Daraz 其他所有的站点，所以我们必须去做平台去中心化的架构升级。这里的核心目标是要完成从平台集成业务到业务集成平台的一个转变。我们要从过去单中心、单通道串行交付的方式，变成业务集成平台、多应用并行迭代的方式。要完成这个核心目标，关键的手段是为不同站点分配独特的全局唯一站点身份，然后再通过这个站点身份完成研发态、编译态、运行态、请求态这四态的去中心化改造，从而实现整条链路的去中心化。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/83/8319f5a1b8a75ed773f55df8b0df5c17.png\" /></p><p></p><p>如上图右侧的架构设计图所示。在研发态，我们为每一个三维坐标系的平面分配了独立的研发空间，我们把它叫做站点包。在编译态，由于在研发态已经有独立的站点包了，那我们就能在编译态为每个独立站点包分配独立的交付通道。通过这个独立的交付通道，我们可以根据站点身份动态匹配，站点身份决定对应的交付通道应该去拉取哪个站点包、平台，然后拉取整个站点包的逻辑和平台逻辑，组装成每个站点都不同的站点镜像。这里整体的实现是基于云原生的技术，利用 Kubernetes 相关编排能力去做的。当站点镜像生成之后，我们会把它放到独立的站点应用，这个独立站点应用的实现基于自身的产品化能力。我们会对研发态生成的每个不同站点包自动构建出站点应用、做了一些产品化升级，我们把多租户逻辑隔离的能力、基础运维监控相关的能力都内置在了这个站点应用中。在请求态，我们在统一接入层也做了一轮大升级。我们会根据请求识别关联站点的身份是什么。在统一接入层，通过识别站点身份完成一次请求的路由，最终通过站点身份再找到对应的站点应用。综上所述，我们完成了整个架构的去中心化升级，也做到了不同站点有各自独立的研发空间、独立的交付通道和独立的运行容器。</p><p></p><h3>海外 V3.0：交易链路从能力最大集到最小集</h3><p></p><p>在海外 V2.0 阶段，我们完成了去中心化，接下来给大家介绍一下海外 V3.0。3.0 阶段的核心是从一个平台的最大集到最小集的转变。在这个阶段，我们要解决的是多模式灵活扩张的问题。站点越来越多，但每个站点背后的模式都不一样。站点越多，模式差异越大，我们需要找到一套满足海外低成本扩张的架构。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/99/99d88e90768b1c2d994e43c71340d99a.png\" /></p><p></p><p>上图用了一套坐标系表示海外数字商业板块的业务迭代的策略，即一套纵横迭代的策略。在纵轴上，我们既需要支持 Lazada 代表的本对本电商相关存量站点的能力迭代，也需要支持 AliExpress 代表的跨境电商站点对应的能力迭代。在横轴，我们要去开更多的站点、用不同的模式覆盖不同的站点。在这个纵横迭代的策略下，如果还是采用平台最大集的架构方式就会面临以下问题。</p><p></p><p>第一个问题在纵轴上，即本对本和跨境能力互相干扰。举个实际例子，Lazada 是做本地化电商的，做本地化电商有一些特殊类目。比如在 Lazada 我们有一个比较有名的生鲜电商 Red Mart，类似于国内的天猫超市，需要进场电商相关能力。但问题是，跨境是不能做生鲜的，因为冷链、供应链等都不能保证时效。我们通过业务调研发现，跨境平台的消费者对生鲜没有一点兴趣，而跨境交易链路的特点是需要非常复杂的多币种处理能力。这个币种不是传统意义上的从 A 到 B 汇率转换。多币种是一个卖家可以在 AliExpress 上把商品卖给全球消费者。比如，卖家发布了一个 10 美元的商品，无论全球哪个地区的消费者购买后，我们都要保证，卖的是 10 美元，结算的也是 10 美元。如果消费者是俄罗斯用户，用卢布购买，通过实时汇率结算无法保障卖家收到 10 美元。为了达到这个目的，我们和巴克莱银行签订一些保护协议。</p><p></p><p>在本对本方面，我们显然不需要上述相关能力，因为买家和卖家都是用本币进行支付和结算的。如果把多币种能力也集成到这个平台就会出大问题，因为多币种肯定有一些汇率保价相关的逻辑，稍有不慎把汇率改错了，比如改成 0.1，那本对本错误的依赖了这段逻辑之后，就意味着会有大量的平台亏损。所以说在纵向迭代上，不同能力的互相干扰已经严重阻碍了存量站点的发展了。</p><p></p><p>第二个问题在横向扩张上，如果用平台最大集这种方式也会有很多问题。首先随着能力越来越多、系统越来越复杂，如果用它直接覆盖新的市场，那么人事成本和资源成本非常大。我们当时评估，人事成本接近上万、资源成本上亿。一个新的电商品牌可能一年都达不到一亿的规模，如果光做建站就花一亿，那肯定是不能接受的。其次，我们在做全球多站点部署时，遇到越来越多的合规和当地市场的不确定性。举个例子，我们在做俄罗斯市场时，俄罗斯市场要求必须本地公司提供支付服务，那就意味着交易链路需要具备局部可被替换能力。再比如，在做海外扩张的过程中，我们会通过合资手段生成很多 GV 公司，在签定协议的过程中，他会要求物流由他们这边公司统一提供，这个时候交易链路的物流或者履约相关的能力必须要具备局部替换的能力。如果我们用最大集去做横向扩张就无法做到灵活可被替换。</p><p></p><p>综上所述，纵横策略交易链路的架构演进要求降低扩张的整体成本，我们需要设计一个“最小集架构”，核心目标是希望能完成整个架构从最大集能力必选到最小集能力可选的转变。本地也好，跨境也好，不是一个拆不开的、紧密耦合的架构，而是把本地和跨境相关能力做更好的分类，该给本地的给本地、该给跨境的给跨境，通过这种方式来降低整个系统复杂度，降低迭代、扩张成本。</p><p></p><p>要达到这个目标，核心手段是之一需要做到领域可选。在横向扩张过程中，交易链路的领域可以被当地公司或者当地的一些技术栈替换。第二个手段是能力可选。我们把电商按照 0 到 1、1 到 N 的生命周期进行了划分，把本地和跨境都需要的基础能力放到 0 到 1 的电商生命周期阶段，我们会单独搭建一个空间，而将本地和跨境的那些特有能力放到电商 1 到 N 空间，为 1 到 N 的空间构建单独的研发空间。通过 0 到的 1 空间和 1 到 N 到空间的组合，实现本地只关注本地的能力、跨境只关注跨境的能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/61/61d1289064a839893a74aba20ddc7e55.png\" /></p><p></p><p>如上图右侧所示，在领域协议层，我们需要做到领域可选。这里的核心做法非常简单，我们把 0 到 1 阶段所必要的 API 梳理出来，把定义和实现分离，把单独的定义抽取出来，封闭成一份完整的领域协议，通过这种方式，在支付、履约、营销等被其他技术站点替换之后，确保整个交易链路的信息流互通互联的稳定性不受影响。</p><p></p><p>在领域层，我们核心工作是“瘦身”。平台层只保留了 0 到 1 所必须的业务模式的实现，以及业务模式实现背后所需要的领域能力，也就是领域的最小集。为了保证领域最小集不会随着时间而逐渐腐化，我们建立了一套保鲜机制，采用了自动化流量回归的方式。我们会去所有的站点采集消费者消费的流量，采集完成之后会生成流量库，在流量库的中完成一轮清洗之后，形成 0 到 1 所必须的用户消费者的请求流量，再把这个请求流量通过自动化回放的方式，回放到领域最小集。用通过率和行业覆盖率来保证最小集的整个能力保鲜。</p><p></p><p>在 1 到 N 的衍生级，我们把本对本和跨境这两大能力进行了分类。举个例子，我们把生鲜预约购相关的能力划分到了本对本、把多币种保价能力划分到了跨境，从而做到本对本和跨境之间的相互隔离，以及本对本和跨境的模块化交付。通过 0 到 1 的最小集加 1 到 N 的衍生级的模块化交付，和在中间提供的的框架嫁接，最终实现了最小集可以和衍生级的按需集成、按需输出，也就是说本对本站点只需输出本对本相关的能力、跨境站点只需输出跨境相关的能力，从而把成本降到最低。</p><p></p><h3>海外 V4.0：交易链路从平台单基线到多基线</h3><p></p><p>最后是海外 V4.0 阶段的介绍。这个阶段要解决的核心问题是解决多站点自主闭环。随着站点变得越来越多，海外市场的竞争越来越激烈，我们的架构需要满足整个海外高效率迭代。任何架构设计都离不开对应的业务设计。对比海外，国内的业务运作机制是采取行业小分队的运作模式。因为国内经过这么多年发展之后，电商平台已经相对比较成熟，已经适应了整个国内市场，所以规则相对比较稳定。国内要的是基于成熟电商平台下的行业局部调整，所以需要有垂直维度的行业小分队。比如现在大淘系的业务运作机制，是由各种行业组织来运作。通过这种垂直行业小分队的方式，采用集中的拓展能力为每个不同的行业提供行业纬度的定制能力，以支持行业调整。</p><p></p><p>接下来转向海外，经过这几年迭代后我们发现，不能拿着成熟的运作机制出海，原因是跟国内相比，海外还处在相对比较初始阶段。我们服务的国家很多，背后的服务市场也很多，需要通过调整平台规则去适应。海外市场整个电商平台相对不成熟，需要采用集团军运作机制。它不再是垂直维度的行业运作，而是一个个站点水平维度的。Lazada 有个 Regional 系统（Regional 组织），需要调整平台规则以适应东南亚市场。Daraz 也有对应的 Regional 组织要做规则调整以适应南亚市场。在站点集团军运作的方式下，如果我们仍然采用过去行业小分队运作的行业扩展点方式，一定会遇到跑不快的问题，会有大量的平台规则调整带来的平台中心化排期问题。平台排期巨大的协同成本一定会影响业务发展。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d1/d1019a020ba42099a3dfd31d8530d115.png\" /></p><p></p><p>为了解决上述问题，也为了跟海外业务运作机制相匹配，我们设计了一套多基线的架构设施，核心目标是完成从垂直维度的单一扩展方式到既支持垂直维度的单一行业扩展，也支持水平站点维度的分层扩展方式。为了达到这个目标，我们的核心手段就是开源。开源允许我们通过一个主站，拉对应分支。但跟传统的开源不同，我们开源的是一个基础链路或者偏商业基础链路的软件，这个软件需要提供完善的开闭准则，保证平台不会因为不同站点的业务分支影响整个平台的互通互联，以及频繁出现重大故障。</p><p></p><p>这套架构设计把平台分成了“教堂 + 集市”两层。教堂就是主干，我们把 V3.0 阶段的最小阶段能力放到教堂内部，把它当做可被拉取分支的主干，让教堂的迭代成本和复杂度最低。同时我们制定了一份 ClosedTemplate 的黑名单，把影响互通互联的跨域通信的资源库、领域模型、数据模型，以及影响可用性、止损能力和逻辑进行封闭，放到这个黑名单内。在教堂之上是整个开放框架。这个开放框架核心作用有两点，第一是通过 License 的授权保证集市层不会泛滥，第二是提供一个能力替换引擎。能力替换引擎可以根据教堂的黑名单在运行过程中识别出哪些是不可变部分、哪些是可变部分，如果发现集市层将不可变部分进行了修改就会启动拦截，如果发现集市层将可变部分进行了修改就会做优先级替换。</p><p></p><p>在集市层，我们提供了一个集市样板工程，允许不同的站点基于这个样板工程拉取对应的平台分支。在这个平台分支内基于黑名单形成一份开放协议，完成站点级别的定制。举个例子，Lazada 电商平台有自己的包裹分组，因为 Lazada 本身是本对本物流电商平台，它是按包裹维度进行购物车和下单分组。Lazada 也偏自营，需要整个平台在指定单的维度按照件数进行拆单，Lazada 整个平台所有行业都应该适配这套规则。同时 AE 也实现了按照不同商家报价币种进行购物车分组和价格美化的能力。通过这种方式在逻辑上实现了每个站点可以有自己的平台分支。最后在物理态，每个集市分支会基于 V2.0 阶段提供的去中心化交付机制，完成每个站点的集市分支和每个站点身份绑定，从而实现 Lazada 的集市分支可以单独交付其站点应用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1b/1b64131ffc9a3b13d7b64455e7709146.png\" /></p><p></p><p></p><h2>得失总结 &amp; 未来思考</h2><p></p><p>最后做一个完整的得失总结。通过几次系统演进，我们现在整个架构基本分成了三层：第一层是达成强隔离诉求的站点应用层，第二层是达到高效率诉求的开放生态层，第三层是达到低成本目标的基础能力层。这三层架构让我们得到的收获有如下三点：</p><p></p><p>通过站点应用层完成了“平台集成业务”到“业务集成平台”的转变，让多站点 100% 全并行，24 小时想发就发；通过开放生态层完成了从单一扩展能力到分层扩展能力的转变，让研发时长缩短了 50%，自助率做到了 90%；通过基础能力层完成了平台最大集能力必选到最小集能力可选的转变，让平台简化了 60%，让建站成本降低 95%，且具备局部灵活替换能力。</p><p></p><p>有得必有失，这套架构的问题有如下两点：</p><p></p><p>线性增加的维护成本：拥有了更大自由度的同时，也要求业务维护平台分支，多站点的维护成本会线性增加。业务难以一体化合力：整套架构侧重在保障各站点之间互相独立发展，在业务互通上的思考和建设不够，业务站点之间难以形成合力与竞对竞争。</p><p><img src=\"https://static001.geekbang.org/infoq/36/36259a53d4bf205f52330d2136d7a8e8.png\" /></p><p></p><p>回到业务战略，拆解到整个交易链路的技术战略，我把它总结为两点。第一，为了实现业务战略，我们需要做到闭环更轻量，让这些不同站点的维护成本越来越低，不要再呈线性增长趋势。存量维护成本降低之后，我们就有更多的资源能释放出来，去服务更多的增量市场。第二，让业务合力更简单，让业务之间顺畅流通，让存量市场的各种资源更好整合，最终用一体化合力的方式输出到新的市场。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d2/d284f64c5cf921d63d49e0e53dd9f347.png\" /></p><p></p><p>围绕这两个技术战略，我们将规划分为两点。第一个是希望通过标准化方式让闭环更轻量。在这里我们更多面向架构治理相关的集市这一层，我们希望不同的站点不再需要去维护一个完整的集市分支，只需要去关注局部需求。要达成这个效果，就需要把集市这层做更强的标准化治理，使其具备更细力度的模块交付能力，让业务开发不再面向完整集市在大平台上做研发，而是面向局部的场景做研发。同时也不需要每次改动都把整个站点应用全量交付，而是基于标准场景做模块交付。我们希望降低门槛、让迭代效率更高，从而达到闭环更轻量。</p><p></p><p>第二个是通过数据基础建设让合力更简单。我们希望建立整条交易链路的一个“统一”的数据中心，通过这个数据中心让不同站点之间信息流通。针对交易链路，主要是定单、履约单对帐、单据信息，避免流通的一致性、跨站点之间信息流通的零合规风险。接下来我们会尝试通过这个统一的中心化数据建设，让整个全球化板块之间的不同站点、不同商品、以及背后订单等的信息流更加顺畅。</p><p>以上我的分享就到这里，谢谢大家。</p><p></p><h2>演讲嘉宾</h2><p></p><p>阿里巴巴资深技术专家赵麟翔（勿乞）。2012 年校招加入阿里后，至 2017 年，一直在参与国内交易平台建设，期间设计的淘宝大型秒杀系统解决了热点商品抢购问题，业务跟平台分离框架奠定了平台插件化架构基础，前后端分离框架统一了多端逻辑。</p><p></p><p>2017 年作为交易架构师加入到 Voyager 项目，正式开始全球化电商之旅，在项目中负责交易整体架构设计和落地，并在项目结束后正式负责国际化中台交易团队。此后，针对全球化板块遇到的多站点多时区迭代、新市场扩张、合规等挑战，进行更大范围的交易链路架构升级，逐步建立了一套支持 Lazada、AliExpress、Daraz、天猫淘宝海外等全球化电商业务持续高质量发展的交易链路平台。</p><p></p><h5>相关阅读：</h5><p></p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MzI5ODQ2MzI3NQ==&amp;mid=2247509454&amp;idx=1&amp;sn=678a84f810aa21f5373b983fc471421a&amp;chksm=eca79c8adbd0159c2f507cfc6d4355667e7504291febd052e07eb49f28c71e405d46a11eefdc&amp;scene=27#wechat_redirect\">京东vs阿里，如何打造支撑万亿电商交易的K8s集群？</a>\"</p><p><a href=\"https://xie.infoq.cn/article/3d35d03cf6011aaed0004e642\">阿里巴巴重磅开源云原生网关: Higress</a>\"</p><p><a href=\"https://xie.infoq.cn/article/80d45663f426f27275318ea96\">阿里 CTO 程立：Severless 化正加速重塑阿里应用架构和研发模式</a>\"</p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651148161&amp;idx=2&amp;sn=57d1d0dc5e001d94f9ff62336669fd82&amp;chksm=bdb8b7d28acf3ec45a4545ffce74785711296bc1238ca6eccc0526d1a8fa0b8a54dd0801d806&amp;scene=27#wechat_redirect\">从底层资源到核心竞争力，揭秘阿里集团深度用云实践｜专访阿里技术风险与效能部负责人张瓅玶</a>\"</p>",
    "publish_time": "2023-02-16 16:35:46",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "基于云原生的架构设计与实践——荔枝魔方智能计算平台",
    "url": "https://www.infoq.cn/article/3H1BWePqTQXjOyv6d79y",
    "summary": "<p></p><h2>背景</h2><p></p><p></p><p>近年来，荔枝集团在国内和海外的业务迅速发展，业务数据规模也是成几何式地增长，海量数据的计算分析场景、业务智能算法应用需求随之而生，为了快速地满足业务发展的需要，我们面临着诸多的技术挑战：</p><p>&nbsp;</p><p></p><h3>工程问题</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7b/7b184ed6f718ae858b5581c7aebadd84.png\" /></p><p></p><p></p><h3>资源问题</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f8/f898414dc0ea51df682499f2d0f21cf8.png\" /></p><p></p><p>计算资源存在滥用</p><p></p><p>如生产环境、预发环境上的在线服务独占GPU，但是在很多业务细分场景下GPU资源使用率低，特别是在一些预发环境下经常出现偶尔才有请求的情况。</p><p></p><p>资源在时间维度利用率较低</p><p></p><p>有很多团队下的训练是单机多卡的模式训练，任务之间的训练无法跨越单机的限制，任务之间的训练靠人工去控制资源，多台机器在同一时刻无法达到最大化利用率，比如A机器上的任务把机器资源已经跑满负荷了，B机器上当前可能资源剩余很多。</p><p></p><p>GPU机器当作CPU机器使用</p><p></p><p>超大型CPU任务在GPU机器上跑或者是GPU任务流中的大型CPU计算过程在GPU机器上执行（占用磁盘、机器网络资源、GPU任务计算过程中所需要的CPU及内存资源等等）。</p><p></p><p>资源环境运维困难，机器迁移扩容效率低下</p><p></p><p>很多时候开发人员的任务开发及运行环境与固定机器绑定，如果机器出现损坏、扩容机器等这些复杂的环境都需要重做一遍，有时出现几天甚至更久才能交付一台机器，同时单机资源有限在大型算法模型情况下经常会出现如磁盘、内存等资源不足。</p><p></p><p>业务开发人员对代码及架构的优化经验、意愿不高，导致资源无法有效利用，机器成本上升快于业务发展大</p><p></p><p>部分情况下相关算法人员对资源利用优化经验或者意愿并不高，基本上是通过加机器来满足计算资源的不足，但有时候能过技术架构和代码的小小优化能节省大量的资源成本。</p><p></p><h3>技术问题</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b4/b409d00bd8d193e3497aa3a03fc22ff3.png\" /></p><p></p><p>数据量大，模型大单机无法支撑，同时模型训练周期过长，线上模型线新缓存，影响业务。单模型训练周期长，无法进行超参搜索，模型参数优化难度大，工作效率低下。算法框架多，不同团队对算法框架要求不一样，如TensorFlow、Pytorch、Sklearn、XGBoost等等，各自版本要求不一样，环境复杂，运维难度和工作量极大。</p><p>&nbsp;</p><p>所以我们需要解决如下一些问题——</p><p>&nbsp;</p><p>资源统筹与边缘计算</p><p></p><p>统一资源管理，将通过人工管理资源改变成机器进行资源管理，平台管理资源申请及资源调度，对不合理资源申请进行智能修正，同时采用合理的智能的调度算法对行计算资源调度，使资源达到最大化利用。</p><p></p><p>边缘计算，在公司业务全球化的大背景下，在国内不同的地区、国外不同的国家都有业务，如果把所有数据传输到一个中心机房进行计算的话数据传输压力会比较大，计算能力比较低下且数据安全性存在一定不足，而如果在每个地方维护一个中心计算集群的话建设成本高，所以我们需要边缘计算，在中心机房执行计算命令，数据与计算在边缘机房进行，以提升计算效率，降低计算成本。</p><p></p><p>对GPU进行虚化，减少GPU资源浪费。</p><p>&nbsp;</p><p>提供一站式模型训练能力</p><p>&nbsp;</p><p>开发、运行等环境模版化，达到只需几秒钟就能复制一套新环境。提供便捷的开发工具，开发人员可以快速的进行环境安装制作及代码开发、调试、发布上线。提供任务流编排功能，使用者通过组件拖拉的形式即能编制出一套复杂的训练流程提供训练任务定时调度功能，支持各种的定时任务操作（补录、忽略、重试、依赖、并发限制）。</p><p>&nbsp;</p><p>将复杂技术模版化、组件化</p><p>&nbsp;</p><p>提供超参数搜索组件，算法同学能方便快捷的进行超参数调优，提高工作效率。提供模版化如Pytorch/TensorFlow/XGBoost/Spark/Ray/Horovod/Volcano等等分布式训练组件，使用者能过简单的拖拉组件就可以完成复杂的分布式计算过程。</p><p>&nbsp;</p><p>魔方智能计算平台介绍</p><p>荔枝魔方智能计算平台面向于人工智能、大数据开发人员使用。集大数据计算、算法模型训练、任务调度、代码开发、资源调度、边缘计算等功能于一体，为推荐、搜索、风控、广告、数据分析、数据应用、智能对话等提供能力支撑。</p><p><img src=\"https://static001.geekbang.org/infoq/5a/5ad52a91a2b72ae0ed9ed3db94458d8a.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/25/258a6fd1a785df73983e17d8038476f6.png\" /></p><p></p><p></p><h2>架构设计</h2><p></p><p></p><p>技术选型</p><p></p><p>在机器学习领域，大家可能接触到最多的有Airflow/MLflow/Kubeflow等等，除了MLflow和Kubeflow之外的大部分开源框架都只是偏向于任务流编排及任务定时调度的，对于机器学习相关的支持没有或者是很弱，其中的MLFlow在机器学习领域内应用比较还是比较多的，但是MLFlow只适合于小规模团队与小规模的模型训练，对于大型分布式计算、资源统筹调度等等支持还是比较弱。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a7/a79bd13b868e353c9e1a5f4002c0a973.png\" /></p><p></p><p>&nbsp;Kubeflow是由Google开源的框架，Kubeflow旨在通过提供一种直接的方式将用于机器学习的同类最佳开源系统部署到各种基础设施，从而使机器学习工作流在Kubernetes上的部署变得简单、便携和可扩展，同时有两大IT趋势开始升温——云原生架构的主流化，以及对数据科学和机器学习的广泛投资，Kubeflow完美地定位于这两种趋势的汇合点。它是云原生设计，专为机器学习用例而设计。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2f/2fe594744ae2cd5624f14376669ed538.png\" /></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p><p>基于前面已经介绍过了我们的痛点及需要解决的问题点，通过Kubernetes的原生架构能构更好更快的集成开源组件运用到机器学习平台中，以满足业务的需要，如与Volcano集成能更好的进行资源调度，基于Kubflow提供的Train-operator快速搭建起TensorFlow/Pytorch/MXNet等分布式训练能力，基于Kubernetes我们能在上层打造更贴合用户的功能，如训练机器创建与销毁，用户只填入简单的资源需求后台就能秒级的创建出一套用户所需要的新环境出来供使用者进行开发、测试、模型训练、模型发布上线等等。</p><p>&nbsp;</p><p>但是Kubeflow也存在着很多的不足</p><p></p><p>任务流构建使用复杂、需要通过Python脚本构建任务、同时设置TASK运行过程中的参数复杂，比如磁盘挂载、资源配置等等，使用成本比较高。缺少环境开发相关组件，比如用户自定义的开发环境的开发工具等等。无法集成除Kubeflow支持以外的组件，比如集成Spark/Ray/Volcano，还比如对GPU虚化后无法应用到平台当中去。无法按分组进行资源调度管理，比如按线上机器集群进行资源调度，按训练集群进行资源调度、按项目分组进行资源调度等等。</p><p></p><h2>我们的选择</h2><p></p><p></p><p>以Kubeflow做为平台的基础，在Kubeflow的上层我们进行封装及扩展，打造集团统一计算平台服务于集团国内和海外算法模型计算相关业务。</p><p></p><p>技术架构</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ec/ec81b04abbd0dad9518bdfaf473c4921.png\" /></p><p></p><p>&nbsp;资源管理</p><p></p><p>硬件层主要是实体机器上的资源，比如磁盘、GPU\\CPU等等资源管理主要是利用Kubernetes进管理集群的资源，在存储方面选择使用Ceph来管理集群中的存储资源。</p><p>&nbsp;</p><p>Rancher</p><p></p><p>为了降低Kubernetes的安装及维护的复杂度，我们基于Rancher来搭建及管理K8S集群。</p><p>Rancher不仅可以集中管理部署在任何基础设施上的Kubernetes集群，还可以实行统一的集中式身份验证和访问控制。由于无法确定资源运行的位置，我们可以轻松地在不同的基础设施之间调用集群，并在它们之间进行资源迁移，同时更方便于K8S集群的扩容、升级、运维等等。Rancher中文官网地址：https://docs.rancher.cn/docs/rancher2.5/overview/_index</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b0/b07182b6dae708deec0b99d71fca9822.png\" /></p><p></p><p>&nbsp;</p><p>Ceph</p><p></p><p>虽然Ceph的读写性能并不高，大概只有50M-60M/秒，相对于CFS等等性能有一定距离，在立项前期发现Ceph在K8S中安装比较方便简单，能很快的集成到系统中来，还有就是Ceph通过系统挂载后，用户能像访问本地文件系统一样访问Ceph集群上的文件，使用起来也方便简单，因而当时考虑利用Ceph来放置训练任务中的配置文件及需要执行的代码，这样分布式下进行训练会变得更简单方便，训练数据可以放置在HDFS等等之类的存储集群上，这样50M-60M/秒写性能完全能满足需求。</p><p><img src=\"https://static001.geekbang.org/infoq/7b/7bd567342287deb12186fdfda1417be5.png\" /></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p><p>Kubeflow</p><p></p><p>Kubeflow中我们主要使用到了KFP/Argo/Katib/TrainingOperator/TensorFlowboard等组件。</p><p></p><p>Argo</p><p></p><p>Argo是一个开源原生容器工作流引擎，用于在Kubernetes上开发和运行应用程序。Argo Workflow流程引擎，可以编排容器流程来执行业务逻辑。</p><p><img src=\"https://static001.geekbang.org/infoq/dd/dd7610f914514584765bc1d5edf3dc6f.png\" /></p><p></p><p>KFP</p><p></p><p>Argo已经有了一整套任务流处理流程了，KubeFlow为什么还要在Argo上进行再次开发呢？首先就是Argo中的数据都是保存在ETCD中的，但是ECTD中的数据有大小的限制，数据总大小及每条记录大小在ETCD中都是有限制的，但是像流程模板，历史执行记录，这些大量的信息很明显需要一个持久化层（数据库）来记录，明显ECTD是不能满足需求的，这样就需要对这些功能进行增强，同是在ML的领域的用户界面层，KFP也做了较多的用户体验改进。包括可以查看每一步的训练输出结果，直接通过UI进行可视化的图形展示。</p><p><img src=\"https://static001.geekbang.org/infoq/2d/2d0bf5622edd70a5609f8f7eb3072a1b.png\" /></p><p></p><p>分布式训练在机器学习中是一个不可缺少的部分，模型训练大都伴随着大量的数据需要进行计算，单机的资源往往是有限的，利用多机资源分布式进模型训练是加速模型训练的一个重要的手段。</p><p>&nbsp;</p><p>核心功能解析</p><p>自定义开发环境-秒级创建Jupyter开发环境提升工作效率</p><p><img src=\"https://static001.geekbang.org/infoq/5e/5ead4dc547cab605d099dfb2b4408cd0.png\" /></p><p></p><p>&nbsp;为什么需要Jupyter+自定义容器环境：</p><p>&nbsp;</p><p>1:提供易用的IDE工具，辅助开发，提高开发效率。（在很多的开发测试环境依赖于Linux等机器环境，很多情况下的同学要么通过Linux无图形化界面进行开发，或者本地开发，然后再上传代码、配置等，这样的开发效率非常低下）</p><p>&nbsp;</p><p>2:隔离用户空间，减少开发过程中相互影响。</p><p>&nbsp;</p><p>3:隔离环境，满足不同开发需求对不同环境的要求。（如一些库对GCC版本要求较低，有些库要求高，他们之间相互影响）</p><p>&nbsp;</p><p>4:对环境做镜像，达到秒级创建新环境，相比起在实体机器上重建环境少则一天多则可能一周都搞不定一个复杂的环境。（比如机器迁移、故障等等环境重建，比如工作交接、新同学入职开发环境搭建，只要一键化就可以做到）</p><p>&nbsp;</p><p>我们通过Docker将用户的开发环境进行隔离，针对于不同种类型的环境构建出一个基于Jupyter基础镜象的开发镜像环境，这样使用者就可以通过平台选择一个自已相适应用开发镜像，一键创建出一个容器环境，用户只需要通过Web页面就可以打开Jupyter进行代码开发了。这样即能做到环境的隔离，也能做到用户之间开发空间的隔离，每个用户都可以创建自已的Jupyter容器，大家开发上互不干扰，各种环境的依赖之间也是互不干扰，如果机器迁移或者机房迁移，用户只需要一键重建环境就可以了。</p><p><img src=\"https://static001.geekbang.org/infoq/f0/f0c5dbbedf88a8213973c14819b562a8.png\" /></p><p></p><p>对于前台用户只需选择镜像、填写机器要求，比如CPU\\GPU\\内存\\磁盘信息后就能创建一个环境，对于后台来说要解决的问题如下：</p><p><img src=\"https://static001.geekbang.org/infoq/c0/c0d0d6afeea2a5d34c3b187bce539f6f.png\" /></p><p></p><p>1:根据Jupyter的镜像，创建一个pod。</p><p>2:构建Jupyter启动脚本，在容器启动时将Jupyter的进程启动起来。</p><p>3: Pod启动后用户需要能够访问到这个Pod中的Jupyter，所以需要构建一套网络访问的服务或者叫CRD，最后将让Jupyter的访问地址能够在办公网络进行访问。</p><p>&nbsp;</p><p>首先我们来看一下整个机器学习平台的网络访问结构——</p><p><img src=\"https://static001.geekbang.org/infoq/0a/0a41d82e5d8232a40330eaf72341c35c.png\" /></p><p></p><p>从外部网络需要访问到K8S内部的服务需要通过外部的负载均衡负载到K8S的一些结点上，这些结点绑定着一个静态的端口（Nodeport），通过这个端口能将请求通过kube-proxy转发到对应的istio-ingressgateway最后由Istio配置的网关及VirtualService将流量转到对应的service上，最终通过service后就通访问到容器中Jupyter的服务了。</p><p><img src=\"https://static001.geekbang.org/infoq/b0/b016589e115d6ee1893d1b30313387de.png\" /></p><p></p><p>&nbsp;Gateway的配置是静态的，平台需为了保证每个用户创建的每个Jupyter Pod都能独立进行访问，所以需要针对每个Jupyter Pod动态创建Service\\VirtualService进行绑定，最终达到可以动态创建Jupyter的效果。</p><p>&nbsp;</p><p>分布式存储-分布式训练的基石</p><p></p><p>在分布式训练过程中，训练的容器次源是由K8S进行调度分配置，工作容器被分布在集群中的哪一台机器使用者是预先不知道的，这样我们就需要有一种介质来存储训练过程中所需要的代码、配置、数据等等，以便于在训练过程中任何一个容器都可以访问它。</p><p><img src=\"https://static001.geekbang.org/infoq/19/1915c0269d70f67634e34efc96ac7d45.png\" /></p><p></p><p>在系统框架中已经介绍过了，平台采用的是Ceph做为平台的分布式存储，同时与rook进行集成部署在K8S上，Ceph包含了包括对象存储、块设备、文件系统，显然这三种模式中文件系统存储便适合平台的使用方式，主要有如下几个原因：</p><p>&nbsp;</p><p>1: Ceph文件系统能通过系统内核的方式进行挂载，使用者能像使用本地文件系统一样访问分布式文件系统，对于使用者来说无感知，使用成本几乎为0，对于那种以前都是单机模式开发的程序迁移成本会大大降低。</p><p>&nbsp;</p><p>2:文件通过操作系统内核挂载，后期如果更换文件系统对于整个平台及平台的用户是无感知的，系统扩展方便。</p><p>&nbsp;</p><p>平台按分类在分布式文件目录下创建子目录，同时按分类创建静态存储卷，比如用户空间存储目录：/xxx/xx2/user，会在K8S上创建一个PV及PVC，在woker容器创建时将容器下的目录mount到这个pvc上。</p><p><img src=\"https://static001.geekbang.org/infoq/f0/f02322d314056714b8ebe0682fe646ac.png\" /></p><p>mount的目录主要分成几种模式，一种是用户级别的目录，这个目录下的文件只有用户。自己可以访问，还有一种目录是项目组共享目录，这个目录是同属一个项目组下的用户才可以访问，另一种目录是全局共享目录，这个目如下的数据是所有用户都可以访问，每个运行的任务都会规属到个人、项目组，这样每个运行任务的容器在创建时都会将当前任务所归属的项目组、用户所属的目录挂载到运行容器中去。</p><p><img src=\"https://static001.geekbang.org/infoq/e2/e298014bbaae849b8a1c640779525116.png\" /></p><p></p><p>解决了存储的问题后，我们就能在任何容器中像访问本地文件一样访问分布式文件系统上相同文件了，这样我们写一份代码，我们不用关心容器在创建在哪台实体机器上都可以进行访问了。</p><p></p><h2>分布式训练-为百G以上级别数据进行模型训练护航</h2><p></p><p></p><p>分布式训练基础知识介绍</p><p>&nbsp;</p><p>本文所说的训练，指的是利用训练数据通过计算梯度下降的方式迭代地去优化神经网络参数，并最终输出网络模型的过程。在单次模型训练迭代中，会有如下操作：</p><p>&nbsp;</p><p>首先利用数据对模型进行前向的计算。所谓的前向计算，就是将模型上一层的输出作为下一层的输入，并计算下一层的输出，从输入层一直算到输出层为止。其次会根据目标函数，我们将反向计算模型中每个参数的导数，并且结合学习率来更新模型的参数。</p><p>&nbsp;</p><p>而并行梯度下降的基本思想便是：多个处理器分别利用自己的数据来计算梯度，最后通过聚合或其他方式来实现并行计算梯度下降以加速模型训练过程。比如两个处理器分别处理一半数据计算梯度g_1、g_2，然后把两个梯度结果进行聚合更新，这样就实现了并行梯度下降。</p><p>&nbsp;</p><p>训练并行机制</p><p>&nbsp;</p><p>模型训练并行机制有三种，但是我们最常见的方式有2种：数据并行与模型并行，其中目前工业界中基本的训练框架实现都是基于数据并行的方式。</p><p>&nbsp;</p><p>分布式训练最大的优势就是可以利用集群多机的资源，并行的进行计算，每一台机器承载着整个计算的一部分，也就是说一份大体量的工作由一堆人来做，每个人同时做其中的一小块事情，目前最常见的并行计算方式有2种：</p><p><img src=\"https://static001.geekbang.org/infoq/28/28764f2c55b1babb2b566869023ba513.png\" /></p><p></p><p>模型并行：集运行的集群中，每台机器上计算着相同的数据，但是每台机器上运行模型中的不同计算部分。</p><p>数据并行：所有机器上的模型是相同的，但是需要训练的数据按机器进行拆分，每台机器计算数据中的一部分，计算完后再将结果进行合并。</p><p>目前工业界最主流运用最广泛的模式是数据并行计算。</p><p>&nbsp;</p><p>数据并行的模型分布式计算实现架构</p><p>Parameter Server模式</p><p><img src=\"https://static001.geekbang.org/infoq/48/483759034ab322cf687c2bb77d980ddf.png\" /></p><p></p><p>PS架构下所有的参数信息都存放在参数服务器中，参数服务（PS）在集群中可以是多台，Worker机器为工作结点，Worker结点首先从PS上获取参数信息，然后根据训练数据计算梯度值，计算完成后将计算的梯度更新到PS上，PS获取Worker过来的梯度值后对梯度求平均，最后返回给到Worker。</p><p>&nbsp;</p><p>Allreduce模式</p><p><img src=\"https://static001.geekbang.org/infoq/a6/a6b71de2083365ae0cb4dc14682b8443.png\" /></p><p>AllReduce模式是所有的机器上都具有相同的模型参数信息，每台机器计算一部分数据得到一个梯度值，然后执行AllReduce操作使得所有node结点都得到其它结点上的所有梯度值，最终更新本地的梯度值，AllReduce每轮迭代都需要同步所有参数，对于网络来说是一个大的冲击，后来在2017年百度在Tensorflow上实现了基于Ring Allreduce的深度学习分布式训练Ring Allreduce，大大减少了网络的压力。</p><p><img src=\"https://static001.geekbang.org/infoq/99/992712ef4c38c17eb13f8508f454c169.png\" /></p><p>参数服务器适合的是高纬稀疏模型训练，它利用的是维度稀疏的特点，每次pull or push只更新有效的值。但是深度学习模型是典型的Dense场景，Embedding做的就是把稀疏变成稠密。所以这种pull or push的不太适合。而网络通信上更优化的Allreduce适合中等规模的深度学习。又比如由于推荐搜索领域模型的Embedding层规模庞大以及训练数据样本长度不固定等原因，导致容易出现显存不足和卡间同步时间耗费等问题，所以Allreduce架构很少被用于搜索推荐领域。</p><p>&nbsp;</p><p>分布式模型训练</p><p><img src=\"https://static001.geekbang.org/infoq/2c/2c4996384f14d630e829fa3305224d33.png\" /></p><p>上面介绍完分布式训练的一些基础知识后，我们来看平台是如何与这些框架结合进行模型训练，在机器学习平台上主要选取如下2种模式来支持深度学习模型的分布式训练:</p><p></p><p>基于RingAllReduce分布式训练</p><p></p><p>Horovod主要是基于Ring Allreduce的架构来进行分布式训练，Horovod支持TensorFlow/Pytorch/MXNet等训练框架进行模型训练，在图像、音视频、文本等等分布式训练场景下使用非常广泛，对原框架（TensorFlow/Pytorch等等）的入侵很小，使用起来简单方便，对原代码做很小的改动就能进行分布式训练。</p><p><img src=\"https://static001.geekbang.org/infoq/60/607bfd97b2dc4d5ade21c14796940ba5.png\" /></p><p>选择了使Horovod进行训练后需要有一套机制来组成Ring Allreduce通讯结构，可以看下图，这时我们需要有一套机制去创建容器，同时让他们组成一个环境环形的通讯结构。</p><p><img src=\"https://static001.geekbang.org/infoq/4d/4dc6e5dd50fb7188464997dcd6a80b7c.png\" /></p><p></p><p>我们首先来看一下Horovod的运行示例，如果是在实体机上执行的话只需要设置分布式下多台机器的SSH免登录，然后在其中一台机器上执行下面的代码，整个分布式就能正常的运行起来了。</p><p><img src=\"https://static001.geekbang.org/infoq/b2/b22cbf92d3fcbf65452789c86f9b94bd.png\" /></p><p></p><p>但是在K8S上我们的容器是动态创建的，IP地址是动态变化的，执行完成或者异常后还需要对这一批容器进行回收等等操作，这时我们就需要一套这样的机制来实现上面说的这些功能，这时KubeFlow的MPI-Operator就能派上用场了。</p><p>&nbsp;</p><p>MPI-Operator</p><p><img src=\"https://static001.geekbang.org/infoq/e3/e3567a353136ab23086dd723aa705859.png\" /></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p><p>MPI-Operator根据用户定义的CRD文件生成一个ConfigMap：</p><p><img src=\"https://static001.geekbang.org/infoq/d4/d49ec3c720be6db4ec19e5943ce5aab8.png\" /></p><p>我们可以看到这个ConfigMap里边主要是生成了三部分，我们现在主要关注的是hosTensorFlowile和kubexec.sh，MPI-Operator会创建2种角色的容器: launcher、worker，这launcher在所有的worker容器启动后调用horovodrun命令，在上面官方广档中默认是通过SSH方式向集群中的其它容器发出执行远程命令，在launcher中MPI-Operator会设置launcher的环境变量OMPI_MCA_plm_rsh_agent。</p><p><img src=\"https://static001.geekbang.org/infoq/14/14da2773639b18b6ffd860449a658d64.png\" /></p><p></p><p>这样最终在执行过程中会在launcher执行kubeexec.sh向worker发起命令执行用户脚本，同时MPI-Operator还管理运行过程当中成功与异常时容器的退出等等，这样在机器学习平台侧则需要构建MPI-Operator的CRD：</p><p>&nbsp;</p><p>1:构建文件挂载信息，将分布式存储挂载到Horovod的容器中去，以保证在任何容器中能访问到训练脚本代码和配置、训练数据等等。</p><p>2:构建资源调度规则，如结点分配规则信息。（如如果有申请到GPU的资源，那则设置worker容器都分布到GPU的结点上去，如果只需要CPU资源则设置worker分配到CPU的结点上去，同时会按照平台的资源隔离策略，如资源有按照分组进行隔离测将worker分布到当前分组所在的资源结点上去运行）。</p><p>3:设置Pod之间的亲和策略，比如是GPU机器的话尽量将容器分布到相同的结点上，减少中间的一些网络损耗。</p><p>&nbsp;</p><p>平台要解决的问题是通过上面一个简单的配置，就能实现复杂的分布式训练过程。</p><p><img src=\"https://static001.geekbang.org/infoq/ce/ce2f3187a072898cf6f5d957ddca23f7.png\" /></p><p></p><p>开始提交训练任务运行分布式任务：</p><p>&nbsp;</p><p>CPU任务执行</p><p><img src=\"https://static001.geekbang.org/infoq/ba/babbd7517d84308e8cfe480c31388e3c.png\" /></p><p></p><p>GPU任务执行</p><p><img src=\"https://static001.geekbang.org/infoq/3f/3f6c4a3c71b9670b0ef197a39eed8ac9.png\" /></p><p>提交后的效果如上，平台会设置将launcher尽量调度到CPU机器，如果没有CPU机器则调度到GPU的机器，同时只分配到CPU的资源。</p><p></p><p>基于PS架构的分布式模型训练</p><p></p><p>虽然基于Ring Allreduce的模式在训练的性能方面会比PS架构要好很多，但是上面我也有提到过在推荐、广告、搜索等这种超大规模场景及需要做在线实时训练场景下PS架构是很适应的，所以在机器学习平台对这种分布式训练场景的支持是非常有必要的。</p><p><img src=\"https://static001.geekbang.org/infoq/2d/2d87688d3c7465dc543f15eccf9514ea.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ab/ab73f9e2a92137b3b724026682d6fc9f.png\" /></p><p></p><p>PS架构下所有的训练参数信息保存在参数服务上，参数服务是集群进行部署的，这样的话在超大规模参数下单机的内存资源是无法满足训练的要求的，特别像是在一些广告场景中，大量的Embedding造成参数规模很大。</p><p>&nbsp;</p><p>PS架构的实现是基于Kubeflow的TrainingOperator来实现的，在TensorFlow的PS训练模式下：</p><p><img src=\"https://static001.geekbang.org/infoq/74/746e42d065ab07e1ec49303c549f0ee0.png\" /></p><p>从上面的图我们可以看到整个训练过程中会创建如下几种角色:</p><p>&nbsp;</p><p>ps:所有的参数存储的地方。</p><p>worker:根据训练参数计算出梯度值，然后把梯度传递给ps之后拿到了ps返回的最新参数并更新到本地并进行多轮的迭代计算。</p><p>chief:一般来说可以用来单独保存模型、代码执行点（比如执行构建Graph）、日志记录等等。比如部分代码只会在chief上运行。</p><p>&nbsp;</p><p>这样我们就可以推断出TrainingOperator需要做的事情如下：</p><p>1:创建ps/worker/chief等角色的容器</p><p>2:根据这些角色创建的Pod的IP信息创建TensorFlow_CONFIG</p><p>3:在创建容器时候设置TensorFlow_CONFIG为容器的环境变量</p><p>4:在容器启动时执行用户脚本</p><p>&nbsp;&nbsp;</p><p>TrainingOperator的整个处理流程并不是太复杂，对于机器学习平台来说就是创建TrainingOperator对应的CRD：</p><p>1:构建文件挂载信息，将分布式存储挂载到Horovod的容器中去，以保证在任何容器中能访问到训练脚本代码和配置、训练数据等等</p><p>2:设置PS及chief容器的信息，这2种容器只需要分配到CPU的机器上即可，对于worker容器根据用户设置，如果需要CPU则设置CPU资源信息，如果需要GPU则设置GPU资源需求</p><p>3:设置Node结点亲和度信息，如当前项目组下有资源，测将当前任务的容器设置要调到到当前分组的资源结点下</p><p>4:设置Pod之间的亲和策略</p><p>&nbsp;</p><p>对于使用者来说只需要通过如下简单配置加上代码中的训练脚本配合就能就行分布式的训练了，对于资源的创建、回收，网络的管理都交由平台来管理，用户只需要关注自已的训练逻辑就可以了。</p><p>&nbsp;</p><p>资源调度</p><p></p><p>在分布式计算下，我们需要申请大批量的机器进行训练，但是在大部的场景情况，无论是MPI+Horovod或者是TensorFlow PS架构下都是需要等容器创建完后整个训练过程才会开始。</p><p><img src=\"https://static001.geekbang.org/infoq/bb/bbff4a92ef5aeff3d68727d26d2f4a9a.png\" /></p><p></p><p>如上图，有一部分的worker申请到了机器了，但是另外几个worker申请不到机器，还一直处于Pending状态。</p><p><img src=\"https://static001.geekbang.org/infoq/39/3957288037c7362e53f509c30e7b47bb.png\" /></p><p></p><p>这里我们查看launcher的状态还一直处理init状态，等待所有的worker准备好了后才开始作业，这些如果一直申请不到机器，已经起来的worker的资源就一直占用并浪费掉了，特别是GPU的资源，所以我们就需要一套资源调度框架来处理这些事情，原官方有kube-batch但是kube-batch已经很多年不更新了，对于目前很多的计算框架或者一些组件会有不兼容，volcano是当前行业中比较完善的调度框架。</p><p><img src=\"https://static001.geekbang.org/infoq/e8/e880409bcd83415eec04378f74b638af.png\" /></p><p>Volcano由scheduler、Controllermanager、Admission和Vcctl组成：</p><p>Scheduler Volcano scheduler通过一系列的action和plugin调度Job，并为它找到一个最适合的节点。与Kubernetes default-scheduler相比，Volcano与众不同的地方是它支持针对Job的多种调度算法。</p><p></p><p>Controllermanager Volcano controllermanager管理CRD资源的生命周期。它主要由Queue ControllerManager、PodGroupControllerManager、VCJob ControllerManager构成。</p><p></p><p>Admission Volcano admission负责对CRD API资源进行校验。</p><p>Vcctl Volcano Vcctl是Volcano的命令行客户端工具。</p><p>&nbsp;</p><p></p><h2>展望</h2><p></p><p></p><p>荔枝集团全球化业务还在持续高速的发展中，我们还将要面对更多的挑战，在未来我们还需要持续推进基于云原生的架构设计与实践在大数据和人工智能领域的应用：</p><p></p><p>•&nbsp;随着业务的增长，资源成本也随之增长，我们需要更合理的资源调度能力，以便更大化的利用计算资源，同时需要进行GPU虚化技术研究与研发，从而更好地利用GPU资源</p><p>•&nbsp;业务的高速增长，技术团队需要沉淀更多通用化的组件，以达到快速的支撑不同业务场景的能力，如面向业务的通用个性化推荐、搜索排序组件化模型</p><p>•&nbsp;更多的业务计算组件，如：声音、视频、文本相关AI组件，大数据计算组件</p><p>•&nbsp;大规模实时模型计算与训练能力</p><p>&nbsp;</p><p>作者介绍</p><p>倪江利，荔枝集团大数据部算法平台负责人，有10余年互联网从业经验，曾就职于阿里巴巴负责淘宝搜索推荐相关算法平台开发与架构设计。</p><p>&nbsp;</p><p>（本文部分图片来源于网络，如有侵权请联系删除）</p>",
    "publish_time": "2023-02-16 17:05:22",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]