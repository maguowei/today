[
  {
    "title": "移动端浏览器性能优化探索",
    "url": "https://www.infoq.cn/article/0771c328e638482548c5dee8f",
    "summary": "<p>作者：鲁田（程禄）</p><p></p><p></p><blockquote>在移动端的页面开发过程中，经常提及页面性能优化、消除页面卡顿的话题，如何确定优化策略，我们首先应当对页面卡顿的行为有所认知。</blockquote><p></p><p></p><p></p><h1>一、前言</h1><p></p><p></p><p>页面的卡顿现象可以比较明确的分为三个类型，分别是“画面撕裂”、“丢帧不流畅”、“长时间未响应”。</p><p></p><p>“画面撕裂”现象给人直观的感觉是页面返回内容不一致，而造成这种现象的原因在于屏幕的刷新机制，屏幕的刷新遵循“Z”字刷新的方式，因此同一帧的数据在上屏时存在一定的时间差，当帧率大于刷新率时，屏幕对前一帧的数据上屏尚未结束而后台对后一帧的数据处理合成完毕，此时屏幕完成上屏的数据将会采用后一帧的数据，造成人眼同一时刻观测的画面数据来源于不同帧的现象，给人以撕裂感。</p><p></p><p>”画面丢帧“也被称为Jank现象，给人的直观感觉是画面不流畅，在动画或滚动时出现短暂停滞，而造成丢帧的原因在于屏幕每隔16ms发出一个VSync信号，在正常帧的流程中，CPU接收到VSync信号后会先通过交换指针的方式进行前后缓冲区的数据同步（该过程时耗忽略不计）然后开始新一帧数据合成，当帧率小于刷新率时，下一个VSync信号到来时可用于交换的帧数据还没有通过CPU 计算合成，此时前后缓冲区的数据不会发生交换，因此屏幕内出现了连续两帧使用同一帧数据渲染，给人以停顿和不流畅的感觉。</p><p></p><p>\"长时间未响应\"指的是画面长时间等待，等待网络请求或其他事件处理，这种情况通常并不是由于帧渲染导致的，但等待时长如果违背了RAIL模型，会严重阻塞（BLOCK）用户行为，该类型的卡顿通常会采用别的指标进行衡量。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/52/52aa6423b4de6eb296f3fe8d5129e206.png\" /></p><p></p><p>1）﻿Response响应时间：系统应当在100ms内对用户的输入作出响应，这种输入表示任何用户的交互行为，比如输入文本、点击、切换表单、开启动画等。在不阻塞用户交互行为的前提下可以对一些耗时昂贵的工作进行预运算，对于耗时 500ms以上的工作项应当通过信息反馈提前告知用户。</p><p></p><p>2）Animation动画：对于动画的交互，如touchmove、scroll等需要在16ms 内作出响应，而动画的帧率期望能够达到每秒60帧，即折算一帧16.6ms，而实际上渲染一帧的动画过程浏览器还存在着大量的样式计算、布局计算、线程调度、图层合成、光栅化等过程，因此纯JS的线程执行耗时应当控制在10ms 内。</p><p></p><p>3）Idle最大化空闲时间：空闲时间可以用来完成优先级不高的任务，通过50ms 为基准将延迟任务进行分片分组执行，目的时为了能够预留50ms的空闲时间给到主线程来对用户的输入进行即时响应，从而完成100ms内响应用户的标准。</p><p></p><p>4）Load：1s内完成站点加载。</p><p></p><p>上文中提到的很多名词概念，在此也做简单介绍。</p><p></p><p>帧率（FPS）：指的是一秒内合成帧的数量，常用FPS来描述，60FPS表示一秒内合成60帧。刷新率（Hz）：指的是一秒内屏幕的刷新次数，安卓机通常为60Hz。VSync（垂直同步）：是一种定时中断技术，时间间隔为16.6ms，VSync信号保证了画面内的数据来源同步，磨平了屏幕刷新方式带来的上下屏数据来源的差异性。通常与双缓存、三缓存技术共同解决“画面撕裂”带来的卡顿。此处介绍一个可用于测试设备是否支持VSync的在线工具—设备测试VSync。双缓存机制：通过设计两种类型的缓存器Back Buffer、Frame Buffer分别为 CPU数据处理以及屏幕读取数据服务，解决了帧渲染过程中同时存在的读写逻辑冲突。三缓存机制：CPU与GPU在Back Buffer的使用权上存在竞争关系，导致GPU 占用时间段内CPU线程处于闲置状态，从而导致合成帧耗时较长，三缓存将 CPU与GPU对缓存器的使用状态也进行了隔离。</p><p></p><p></p><h1>二、如何衡量卡顿</h1><p></p><p></p><h2>2.1&nbsp;FPS与卡顿的关系</h2><p></p><p></p><p>一般来说，我们通过页面的FPS来作为衡量页面卡顿的指标，但是用FPS来做卡顿的描述并不精确，举个例子：</p><p></p><p>1）电影播放的FPS=24,但是在电影播放过程并不会出现卡顿现象，说明了FPS低于30也不表示画面卡顿，从定义上来看FPS仅描述了一秒内的画面绘制次数，如果一秒内页面没有任何绘制的需求，FPS=0是很正常的。</p><p></p><p>2）对应的，FPS=60的页面如果在前200ms仅仅完成了首帧的渲染而剩余 800ms完成了剩余59帧的渲染，保证了一秒内的帧数，但是仍然会带来卡顿的现象。</p><p></p><p></p><h2>2.2&nbsp;新的衡量指标</h2><p></p><p></p><p>SM（SMoothes）是Android端提出的相比于FPS更加准确的衡量卡顿现象的指标，SM更好的考虑了单位时长内的有效帧数占比，SM计算公式如下：</p><p></p><p>SM = FPS * (单位时长的总帧数 - 单位时长丢帧数) / 单位时长总帧数</p><p></p><p></p><h1>三、浏览器动画渲染</h1><p></p><p></p><p>为了能够更好的跟踪动画渲染过程的卡顿，我们应该更加清晰的去认知浏览器渲染的原理和过程，动画渲染的原理大图如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dc/dc339016d9ed60d050c7ebcad0be036d.png\" /></p><p></p><p>对上图进行链路总结如下：</p><p></p><p>CPU负责处理复杂的控制逻辑以及数据逻辑，在浏览器的渲染过程中生成 DOM树、CSSOM树、样式计算、布局计算、图层生成等，最后将矢量数据提交给合成器以及GPU。GPU接受图层图块信息，并基于强大的硬件能力对图层进行分割切片、栅格化。GPU从结构上拥有更多的ALU单元，更擅长大量重复的计算以及矩阵变换，能够以流式并行的模式快速完成位图绘制，并将纹理数据存入缓存器。显示器通过VSync信号强制拉齐帧率与刷新率，当信号来临时访问前缓存器拿到最新的位图数据并用于上屏。</p><p></p><p></p><h2>3.1&nbsp;GPU扮演的角色</h2><p></p><p></p><p>我们常说的硬件加速其实是通过GPU的特性来缓解CPU的计算压力，相比于 CPU，GPU拥有更多的ALU（算数逻辑单元），其特有的流式并行计算模式在矩阵变换的计算上有天然的优势，同时采用GPU的硬件加速可以对待处理的元素进行图层提升，实现了在画布更新过程中隔离非合成元素的目的，等到生成结束后通过相应位置的替换完成图层的合成，从而减少了CPU线程内回流和重绘的计算过程。</p><p></p><p>值得注意的是，浏览器本身为我们完成了很多优化的策略，比如在使用transform、opacity属性的时候浏览器会自动开启GPU加速，因此更推荐在动画过程中通过上述属性进行处理。除此之外，通过will-change定义的CSS属性值，浏览器也会预先将其关联的元素提升到新的图层，从而避免刷新屏幕时出现回流和重绘的过程。</p><p></p><p></p><h2>3.2&nbsp;合理避免回流和重绘</h2><p></p><p></p><p>事实上，是否避免了回流和重绘的过程取决于对应的元素是否真正被提升到了合成层（Composite Layer）。即使使用了 transform、opacity 两个属性，如果浏览器不支持硬件加速导致图层没有被提升，那么在更新的过程中仍然会因此回流和重绘。</p><p></p><p>在此对常用于提升图层的方法进行罗列：</p><p></p><p>3D transforms：translate3d，translateZ等；video，canvas，iframe等元素；通过Element.animate()实现的opacity动画转换；通过СSS动画实现的opacity动画转换；position: fixed；will-change；filter；有合成层（Composite Layer）后代同时本身overflow不为visible（如果本身是因为明确的定位因素产生的SelfPaintingLayer，则需要z-index不为auto）</p><p></p><p></p><h1>四、浏览器工作流程</h1><p></p><p></p><p>到此我们明确了在浏览器动画绘制过程中CPU以及GPU扮演的角色，为了更加清晰的明确一帧内CPU与GPU负责的具体工作，我们需要对浏览器内核的工作有一定的了解。</p><p></p><p>首先，浏览器是多进程工作的，进程结构如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/80/80b72480e5daaa0514778a7a5641cdbc.png\" /></p><p></p><p>我们常说的浏览器内核其实就是渲染进程（渲染引擎）。渲染引擎将从网络层获取请求的文档内容并解析渲染，整个渲染引擎的工作流程是渐进的，渲染引擎的工作流程如图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/60/6013493919f4a97ce639e26655f84f01.jpeg\" /></p><p></p><p>对于其中的每一个部分展开解释有些复杂，本文不多做赘述。本文还是更加聚焦于画面渲染的Layout以及Painting过程，从这个角度来看，单帧内的渲染引擎主线程过程的Pipline如下图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2c/2cc790e01ccdb1e7c73e90edb7a8d9a9.png\" /></p><p></p><p>引入GPU加速计算后的主线程Pipline如下图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/92/9230ec0df197904bba2d0a822ff9d5b6.png\" /></p><p></p><p>对上述Pipline的各节点解读如下：</p><p></p><p>1）Input event Handlers代表浏览器的输入事件回调，该事件会被浏览器进程（Brower Process）捕捉，随后浏览器进程会将事件类型（如touchstart）及其坐标发送给渲染进程（Renderer Process），渲染进程通过查找事件目标并运行附加的事件侦听器来处理事件。</p><p></p><p>2）requestAnimationFrame允许定义一个回调函数，可提供给用户在当前帧布局计算以及绘制之前做一些预处理操作。</p><p></p><p>3）CPU在ParseHTML过程负责将浏览器不能识别的HTML文本转换为浏览器能识别的DOM对象。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/08/08404b9e01c6b025373157a251d5afed.png\" /></p><p></p><p>4）CPU在RecalcStyles过程会解析CSS文件，依据CSS的样式继承以及层叠规则计算DOM节点的每一个元素的具体样式，并保存在ComputedStyle结构中。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d5/d51293648d5427ecf10edcf2e22e4ef9.png\" /></p><p></p><p>5）CPU在Layout过程基于DOM Tree以及Compouted Style计算元素布局信息并生成Layout Tree（RenderObject），在该过程中不可见的DOM节点会被忽略，例如head标签下的全部内容以及display=none的DOM节点。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c1/c1e8b91e8eb86612cd694809aa82e982.png\" /></p><p></p><p>6）CPU在Update Layer Tree过程负责将相同z空间坐标的Layout Tree（RenderObject） 归并到相同的Paint Layer（RenderLayer），从而保证页面元素的合成顺序。通常情况下，并不是布局树的每个节点都包含一个图层，如果一个节点没有对应的层，那么这个节点就从属于父节点的图层，但不管怎样，最终每一个节点都会直接或者间接地从属于一个层。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9c/9cf228abcad3c465c989c932d0ee78d2.png\" /></p><p></p><p>7）CPU在Paint过程干了两件事：第一件事是完成绘制（Painting），即生成新生成/修改元素的绘制信息，包括图形信息，文本信息。第二件事是完成栅格化（Rasterization），对Painting的绘制信息进行消费，对于没有GPU加速的情况下，浏览器会通过CPU进行软件栅格化，软件渲染器没有使用GL将内容纹理块复制到后台缓冲区，而是使用 Skia（2D绘图库）的软件光栅化器来执行复制(并执行任何必要的矩阵计算和裁剪)。</p><p></p><p>8）CPU在Composite过程将图层信息提交（commit）到合成线程（Compositor Thread）中，在此线程中会对图层进行分块生成图块（图块是栅格操作的单位）同时借助GPU对额外的属性（如：will-change声明的元素，启用硬件加速的canvas）进行处理（图层变换、合成）。</p><p></p><p>9）GPU在Rasterize过程对图块纹理进行栅格化处理。</p><p></p><p>10）合成线程会在所有图层被Rasterize后打包发送到GPU进程，此时标志着一帧结束。</p><p></p><p>11）页面的所有信息在GPU内被处理后传入双缓存的Back Buffer中，下次垂直同步信号到达后互换前后缓存区位置，完成上屏。</p><p></p><p>到此，可以回答本章节开篇提出的问题，CPU给GPU传递的数据是经过布局、绘制计算的到的矢量图信息，而GPU只负责对矢量图进行像素化（光栅化）以及着色后将其存放到帧缓存区，等待下一个VSync信号的同步。</p><p></p><p></p><h1>五、解决方案</h1><p></p><p></p><p>回到移动端本身的问题，低端机面临的性能瓶颈问题往往由于其硬件能力不足导致的，如CPU性能（主频大小、Cache容量）、内核数、内存大小、DRAM大小、是够支持GPU加速以及GPU核数等。对于同样的页面逻辑，在低端机上执行，往往会带来更高的CPU占有率从而导致帧数丢失、更高的内存占有率从而带来更多的数据交换损失，而一些不支持GPU的机型中，单帧内的动画会依赖CPU进行软件渲染，这个过程会大量占用CPU主线程从而带来丢帧。</p><p></p><p>在了解低端机面临的瓶颈问题后，我们应该通过以下策略最大限度的降低性能损耗：</p><p></p><p>开启适当的硬件加速（GPU加速），合理使用CSS属性进行动画绘制，如 transform、opacity、filter等。采用will-change对比较复杂的元素处理进行单独图层的提升（切忌对所有元素使用，过量的图层会加剧GPU合成时的功耗）。最小化动画的范围，可以有效减少帧数据（位图）的大小，降低GPU访问主存的时间损耗。使用脱离文档流的方式对元素进行动画，减少回流。避免通过父级元素对子元素进行访问，样式的访问链路过程会加剧样式树计算时的时间损耗。尽可能少的访问offsetWidth、top等元素样式属性，因为这些属性会引发回流和重绘，如果必须访问时，可以进行数据缓存，同时可以在rAF阶段进行访问，因为rAF后浏览器会进行布局的recalculate。对于没有GPU加速的机型，可采用降低动画的影响范围，降低纹理的尺寸的方式等加速主线程，从而提升页面响应速度。长任务切片，将连续串行的任务通过优先级设置和任务调度的方式切割，从而减少长任务占用主线程时无法及时对用户行为作出响应。</p>",
    "publish_time": "2023-06-20 11:07:13",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "群贤毕至 华山论剑 | 鲲鹏开发者创享日·西安站暨陕西省信息技术应用创新论坛成功举办",
    "url": "https://www.infoq.cn/article/ZlAmC4GkFjk31kicgYpS",
    "summary": "<p>6 月 17 日，<a href=\"https://www.infoq.cn/article/fueoZZogkCAtF8vVFAKN\">鲲鹏</a>\"开发者创享日·西安站暨陕西省信息技术应用创新论坛成功举办。本次活动由陕西省工业和信息化厅、西安市人民政府指导，陕西省工业和信息化厅信息中心、西安高新技术产业开发区管理委员会、华为技术有限公司主办，陕西省信息技术应用创新适配中心、陕西鲲鹏生态创新中心承办，全天共吸引了来自陕西省企业代表、科研专家、高校老师及学生等 600 余人现场参加，线上直播观看人次达到 100 万。</p><p></p><p>中国科学院院士、西安交通大学教授、数峰信息科技首席科学家陶文铨，西安电子科技大学副校长刘宏伟，西安电子科技大学华山领军教授、陕西省超大规模电磁计算重点实验室主任、鲲鹏 MVP &nbsp;张玉，西北农林科技大学教务处副处长李论，西北工业大学副教授季哲，西安数峰信息科技有限责任公司总经理杨思源，华为鲲鹏计算业务总裁李义，华为陕西总经理刘珂，华为中国战略与 Marketing 部总裁卢广，华为鲲鹏计算业务副总裁陈超，<a href=\"https://xie.infoq.cn/article/93feece62a1db7df36e94364d\">华为</a>\" HPC 首席技术专家丁肇辉等国内顶尖技术大咖、科研带头人、知名企业技术专家出席了本次活动。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/23/230f2360b2820e5e53d02021919b6b07.png\" /></p><p>会上，专家演讲高屋建瓴，描绘了计算产业发展趋势和蓝图，展现了鲲鹏全栈创新技术、商业应用及人才发展等生态全景。同时一系列大动作重磅推出，全面展示“数字通经络，竞技创成效，前路共驰行”的鲲鹏产业生态发展态势，凝心聚力擘画陕西数字经济发展布局。</p><p></p><p></p><h2>鲲鹏计算性能出色 获中科院院士肯定</h2><p></p><p></p><p>中国科学院院士、西安交通大学教授、数峰信息科技首席科学家陶文铨在致辞中谈到，随着工程计算软件应用范围的扩大，计算问题的复杂性和数据规模不断的增大，传统的计算平台面临着计算能力不足和效率低下的挑战。华为鲲鹏计算全栈软硬件平台，在计算能力和性能方面表现出色，融合了先进的计算架构和高能效特性，为高性能计算领域带来了巨大突破，这是非常值得称道的。陶院士充分肯定了华为鲲鹏团队在推进中国工程计算软件的应用方面做出的贡献。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1d/1d7b52b7ab21ea7842de09b2d10f3128.png\" /></p><p></p><p></p><h2>鲲鹏生态蓬勃发展 高效能适配行业应用</h2><p></p><p></p><p>华为陕西总经理刘珂在大会上谈到，能源、<a href=\"https://xie.infoq.cn/article/5a78cf28d927e12aebef73e2a\">金融</a>\"、工业等领域头部企业开始尝试使用自主创新技术部署其业务生产系统，同时，气象、电网、航空等行业，也将逐步参与其中。在此过程中鲲鹏生态得到了蓬勃发展，涌现出了如长安计算等一批代表性高新技术企业。当前，自主创新工作已进入新的发展阶段。华为将进一步加大投入，共建繁荣陕西省自主创新生态，让自主创新产品能逐步覆盖更多用户的生产系统，让产品“可用”、“好用”，助力陕西省数字经济高质量发展。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cd/cd9db132712d07cf208c1522db357f5f.png\" /></p><p></p><p></p><h2>共建陕西鲲鹏生态 共创陕西数智未来</h2><p></p><p></p><p>华为鲲鹏计算业务副总裁陈超在《鲲鹏展翅，共创数智未来》演讲中介绍了鲲鹏生态在陕西的进展。在陕西，华为携手产业伙伴打造“ 1+1+3+N 产业“，共建陕西鲲鹏计算产业生态，鲲鹏已成为陕西国计民生行业自主创新首选技术路线。依托陕西鲲鹏生态创新中心服务了 400 多家软件生态企业，在陕西孵化了超过 600 个鲲鹏联合解决方案，并与 16 所陕西高校开展鲲鹏产学育人合作，培养了超过 300 名学习了鲲鹏根技术知识的陕西高校优秀教师和超过 5000 名本科大学生！未来，华为将进一步加大在陕西鲲鹏生态创新中心的投入，全面推进陕西新一代信息技术的应用创新与人才发展，并以技术点亮开发者创新活力，让每一个开发者的微光汇聚成熊熊火炬，照亮鲲鹏计算产业的未来！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/27/278802a176cad938e19c8cd29fcb51a6.png\" /></p><p></p><p></p><h2>鲲鹏助力高性能电磁计算创新“理论”走向“实践”释放技术价值</h2><p></p><p></p><p>西安电子科技大学华山领军教授、陕西省超大规模电磁计算重点实验室主任、鲲鹏 MVP 张玉在《高性能电磁计算创新发展》主题演讲中，重点介绍了计算电磁学主流算法概念、计算电磁学面临的挑战，概述了团队在高性能电磁计算领域不同发展阶段中的技术创新，回顾了电磁计算的理论方法、并行计算、工业软件、高性能计算适配的逐步发展历程，并展示了鲲鹏全栈基础软硬件解决方案等计算平台中的软件实际案例。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/30/302553d163b265740a65727e658f3ebe.png\" /></p><p></p><p></p><h2>产学研用一体化融合发展 助力人才培养 释放数字新动能</h2><p></p><p></p><h2>陕西省高性能计算研究院正式启动建设</h2><p></p><p></p><p>数字经济时代已全面开启，作为数字经济的“底座”，算力及工业软件能力正在成为数字经济蓬勃发展及产业升级的重要支撑，急需探索新产学研联合培养高性能计算人才新模式。本次活动中，陕西省高性能计算研究院在中国科学院院士、西安交通大学教授、数峰信息科技首席科学家陶文铨、西安电子科技大学副校长刘宏伟、陕西省西咸新区空港新城开发建设集团有限公司董事长蒙彬斌、华为鲲鹏计算业务总裁李义的共同见证下正式启动建设，这是陕西省落实产学研用一体化融合发展、数字经济建设的共识性举措，将助力鲲鹏计算产业在陕西省转化为地缘优势产业，深度融入当地产业集群，释放数字经济新动能。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c0/c05412946db9c168d1810b001f2dd37d.png\" /></p><p></p><p></p><h2>构建高性能计算生态  推动科技创新能力跨越式发展</h2><p></p><p></p><p>华为 HPC 首席技术专家丁肇辉围绕“鲲鹏高性能计算全栈技术能力”进行了《鲲鹏 HPC 软件创新提升行业科研效率》主题演讲。重点介绍鲲鹏高性能计算软件全栈，面向高性能计算系统的使用者和开发者，分享高性能计算软件的最新进展与技术创新方案。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d4/d41e3aea59e87243f62ca5c1055dfde8.png\" /></p><p></p><h2>&nbsp;</h2><p></p><p></p><h2>鲲鹏 HPC 助力无网格数值方法研究&nbsp;提升流体仿真软件计算效率</h2><p></p><p></p><p>西北工业大学副教授季哲做了《高并发计算优化案例分享》的主题演讲。介绍了课题组近两年来在针对新能源汽车复杂流体环境仿真软件开发和基于新型无网格数值方法研究方面的进展。通过开展针对鲲鹏架构的联合调优工作，本方案借助鲲鹏 HPC 架构进行了大规模并行加速，并最终使用了鲲鹏开发套件 DevKit 进行了迁移和调优，从而使迁移到鲲鹏架构上的软件模块 M2P 和底层核心数据结构均获得了更好的计算效率，使得团队可以在 50 秒内完成建模效率，同时大大降低计算仿真时间——从数周、一周降低到一天，甚至数个小时，这在极大程度上，协助了我们科研工作的进展。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ee/eea03ab2005208f3852ad6ba373bba3c.png\" /></p><p></p><p></p><h2>BoostKit 应用加速创新  让鲲鹏更好用</h2><p></p><p></p><p>华为鲲鹏计算解决方案高级工程师涂盛霞进行了《如何基于鲲鹏计算平台更快更好地进行数据处理》主题演讲，介绍了鲲鹏应用使能套件 BoostKit 通过提供丰富的应用加速能力，帮助伙伴和客户开发者，发挥鲲鹏计算平台极致性能，使鲲鹏更“好用”。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e4/e4ae26219aed758ee2c34ae3ff581aef.png\" /></p><p></p><p></p><h2>依托鲲鹏创新中心&nbsp;释放端管云产品优势&nbsp;打造华为擎云终端生态</h2><p></p><p></p><p>华为商用办公解决方案总裁刘江萍做了《华为商用终端产业发展与擎云产品创新》的报告。报告中谈到，华为终端长期坚持“以消费者为中心”和“技术创新”双轮驱动的创新战略，从硬件、软件和平台三方面持续为客户创造价值。同时，华为擎云生态已经正式入驻鲲鹏生态创新中心，面向产业、联合桌面 OS 厂商，共同使能南北向伙伴做好软硬件生态适配，致力于发挥端管云芯协同的优势，构建联合解决方案服务好全行业客户，助力产业发展。报告还深入探讨了信息技术创新产业现状、挑战和未来发展方向，并分享了华为终端的实践和思考。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d6/d6984d4d73c44e474f1457b3d88a6a20.png\" /></p><p></p><p></p><h2>自主创新 CAE 软件 赋能企业提升效率</h2><p></p><p></p><p>西安数峰信息科技有限责任公司总经理杨思源在活动现场分享了多年来数峰科技在软件开发方面已取得的自主研发经验。他谈到，计算机辅助工程（ CAE ）技术在航空、航天、海洋工程等领域都具有重大的应用需求。数峰科技在中国科学院院士陶文铨的带领下，经过多年尝试，已成功研发出一套基于有限体积法的计算流体力学及数值传热学数值模拟软件。目前，数峰科技已为大量客户提供高质高效的自主 CAE 软件。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/db/dba7a51ca2178e9fcc72f1dced19f2d8.png\" /></p><p></p><p></p><h2>校企深入合作 加快陕西计算人才培养</h2><p></p><p></p><h2>鲲鹏&amp;昇腾产教融合育人基地正式揭牌</h2><p></p><p></p><p>&nbsp;&nbsp;作为鲲鹏产业生态的重要一环，人才培育将为产业创新发展注入源源不断的动力。为打通“产学研用”渠道，加快计算人才与产业界的融合，西北农林科技大学教务处副处长李论和华为鲲鹏计算业务副总裁陈超在大会上正式为鲲鹏&amp;昇腾产教融合育人基地揭牌。未来，将构建形成由新型产业驱动的知识体系和人才体系，将该基地打造成示范标杆，加快陕西鲲鹏计算产业创新人才培养。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/df/df9ed1f4c910083c7864adf3288943e0.png\" /></p><p></p><p></p><h2>以赛促学 激发人才创新活力</h2><p></p><p></p><h2>鲲鹏应用创新大赛陕西赛区正式启动&nbsp;</h2><p></p><p></p><p>鲲鹏应用创新大赛是开发者人才培养上非常重要的组成部分，为鼓励广大开发者基于鲲鹏全栈根技术，展示高效解决产业难题技能比拼，鲲鹏应用创新大赛 2023 陕西赛区正式启动。今年陕西赛区设置三大赛道：行业应用与解决方案创新赛道、HPC 应用与解决方案创新赛道、openEuler 开源创新赛道，并提供 28 万+区域奖金池，陕西地区的企业、科研及高校开发者可在鲲鹏社区上报名参与！未来，鲲鹏应用创新大赛将成为广大开发者们开拓创新技术、展现创新方案的重要平台，同时也将是开发者们交流切磋、施展才能的舞台！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a87cc3172e4bcb30539db07dc46feae5.png\" /></p><p></p><p></p><h2>与前沿科技“相遇” 更多平台面向公众</h2><p></p><p></p><p>鲲鹏开发者创享日西安站暨陕西省信息技术应用创新论坛活动当天，还有泛政府行业技术论坛（闭门）、鲲鹏产业人才发展论坛暨第二届计算创新科教融合论坛、鲲鹏开发者·青春星享会、鲲鹏训练营、优才双选会等一系列活动，精彩纷呈。为了以更直观、更生动的方式让开发者和前沿科技“相遇”，活动还开设鲲鹏 Codelab 技术、鲲鹏社区&amp;鲲鹏俱乐部 App、自主创新商用终端等体验专区。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/40/40ddaf394d60ed2bf175c16a293d6398.png\" /></p><p></p><p></p><h2>共建陕西省高性能计算研究院  赋能产业创新发展</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c4/c4b205bd13e32b914fc6aaebf80c1daa.png\" /></p><p>鲲鹏开发者·训练营</p><p></p><p>鲲鹏开发者创享日·西安站暨陕西省信息技术应用创新论坛的成功举办，为陕西带动区域产业结构转型升级和数字经济的跨越式发展注入强劲动力。未来，鲲鹏将携手开发者和生态伙伴持续探索创新，打造由人才引领方向、创新引擎驱动的协同新优势，勇当科技与产业创新开路先锋，助力陕西成为具有全国竞争力的创新之都！</p>",
    "publish_time": "2023-06-20 12:34:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "已经在用 AIGC 写代码的人，实践得怎么样了 ｜InfoQ《极客有约》",
    "url": "https://www.infoq.cn/article/D8fRLD8POS4Nq0PGHVrH",
    "summary": "<p>Prompt 工程师是伴随 AIGC 出现的岗位，它会是今后 AI 领域的常见岗位之一吗？Prompt 工程师的能力更看重哪方面，是表达描述能力，还是技术背景？</p>\n<p>本期是《极客有约》特别栏目“天工开物”，我们邀请珠海太乙人工智能技术合伙人 &amp; 项目总监尹会生、创客贴 CTO 李晋松、Thoughtworks ArchGuard 架构师黄峰达和大家聊聊新兴岗位 Prompt 工程师和未来发展前景。</p>",
    "publish_time": "2023-06-20 13:18:19",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AI 框架的下一步演进方向，昇思 MindSpore2.0 给出了明确答案",
    "url": "https://www.infoq.cn/article/tBlt6W80WGVzx4zMToHm",
    "summary": "<p>今年，OpenAI 、微软、谷歌等 AI 大模型产品或服务陆续进入中国市场，大模型的技术讨论热度持续不减，AI 技术已经成为当下最受瞩目的 IT 技术。</p><p></p><p>我们能看到，凭借快速、精确处理多维及多模态的海量数据优势，AI 技术正在高效解决多种复杂场景下的科学和技术难题。除了帮企业和个体提升了研发效率和生产力，同时也带动了 AI4S（ AIforScience，科学智能）的发展，当前学术界普遍认为，AI4S 将会带来科研范式的变革。</p><p></p><p>近几年，无论是 AIGC、大模型，还是 AI4S，都已经进入了技术集中爆发期，技术迭代速度和研发成果都非常喜人。然而，这也对 AI 框架提出了更高的要求，比如“企业如何快速且低成本的部署多样性算法？”、“从研究到生产，如何快速进行动静态图转换？”、“大模型领域如何降低开发门槛”、“超大规模集群如何才能保持高效稳定的训练？”、“在 AI4S 领域如何用一套框架支持AI和科学计算高效表达并进行计算加速？”等等问题，这些需要 AI 技术厂商在研发过程中需要持续优化并找到解决方案。</p><p></p><p></p><h2>一、动静统一、大模型、AI4S 是 AI 框架主流发展趋势</h2><p></p><p></p><p>AI 框架是 AI 算法模型设计、训练和验证的一套标准接口、特性库和工具包，集成了算法的封装、数据的调用以及计算资源的使用，同时面向开发者提供了开发界面和高效的执行平台。作为人工智能开发环节中的基础工具，AI 框架承担着 AI 技术生态中操作系统的角色，是发展人工智能所必需的基础设施之一。</p><p></p><p>随着企业对 AI 产品应用研发、提升研发效能的诉求不断攀升，开发者对 AI 框架的依赖程度越来越高，无论是企业 AI 项目的研发，还是提升研发效能；无论是商业还是学术，项目都会建立在一个或多个开源 AI 框架上的。比如当前比较主流的开源框架有 MindSpore、TensorFlow、PyTorch、MXNet 等。</p><p></p><p>AI 产业初期的大规模研究和应用主要是在 CV 领域，以性能优先，静态图为主，后来 NLP 领域持续突破，人们在优化性能的同时也更多关注灵活性，动态图成为了主要开发方式。所以，当我们纵观这些主流开源 AI 框架的发展历程，我们可以发现，AI 框架经历了动静分离、动静结合、动静统一 3 个发展阶段，当前正是“动静统一”的主要发展阶段。</p><p></p><p>在目前主流 AI 框架的核心技术分层中，编译优化层则是 AI 框架中至为关键的部分，负责完成 AI 模型的编译优化并调度硬件资源完成计算，而“动静转换”是编译过程中“在训练期间提供更高性能但不易于使用、不灵活”的静态图和“即时执行、更容易被调试、更灵活但性能较低”的动态图的转换方式，切实影响着生产效能的提升。为满足当前市场需求，当前的 AI 框架仍需要提供更加优质的动静态图转换能力以提升后端运行高效性。目前国际主流 AI 框架研发厂商都基本已经实现了动态图开发、静态图部署的编程范式及动静态图转换的能力，不过从开发效率层面考虑，动态图与静态图的“转换与统一”仍需要持续优化。要知道，“动静统一”是 AI 框架在动静态图技术发展中最理想的状态，开发者们需要的是“能够随时根据业务需要灵活切换动态图与静态图”来提升自己的研发效能。</p><p></p><p>除了动静态图技术，在 AI 基础层，“大模型”算的上是这两年 AI 框架的话题中心。在 AI1.0 时代，AI 只停留在单一场景产品端，到了 AI2.0 时代，大模型的快速发展将有望解决“人工智能如何理解世界”的问题，让 AGI（通用人工智能）的实现有了可能，同时大模型的通用性可以激发出更多的商业场景，为企业产品应用研发和产能提效付出更多努力，大模型如今已成为上层应用的技术底座。</p><p></p><p>当我们将视野放到应用层面，我们又会发现，除了企业和商业个体，在近几十年间，AI 技术的快速发展和科学研究已经深度融合，AI4S 更成为了学术界主要进攻的课题。将人工智能和科学相结合，通过利用机器学习等 AI 技术来解决科学研究中的问题，这无疑也是一种“降本增效、生产力提升”的表现。 AIforScience 是人工智能发展的一大重要趋势已毋庸置疑，当我们走进实验室就会看到，AI 已在在改变传统科学研究方式，为生物制药、工业制造等传统研发领域带来新的生产和产业模式。</p><p></p><p></p><h2>二、AI 框架持续升级，昇思 MindSpore2.0 再次交出满意答卷</h2><p></p><p></p><p>近期 chatGPT 持续引爆大模型领域，基础的科学方面也引入 AI 能力，为科学带来了新的研究范式，同时千行百业对于 AI 的应用也进入了深水区。从今年上半年起，各厂商的 AI 框架迭代升级发布进入高发期，华为昇思也不例外。在上周五召开的“一起昇思无尽创新——人工智能框架生态峰会 2023 ”（下文称“峰会”）上，昇思也拿出了自己的看家本领，<a href=\"https://xie.infoq.cn/article/448c2e6652f4891a4b441894c\">昇思</a>\" MindSpore 的技术总经理于璠将华为近期在大模型、AI4S 方面的研究进展一一向大家做了汇报。</p><p></p><p>MindSpore 自从 2020 年3 月正式开源以来，与社区伙伴一起持续完善易用性，并且重点构建了大模型能力，并在 AI4S 领域也进行了完整的布局，完成了三个里程碑式技术突破。</p><p></p><p></p><h3>1、易用性层面</h3><p></p><p></p><p>面向北向生态，昇思 MindSpore 重点打造了基础模型开发套件以及动静统一特性。开发套件集成了数据处理、模型构建、训练流程等模块化接口和常用 SOTA 模型预训练权重，方便开发者开箱即用，其中 CV 类基础骨干模型，昇思 MindSpore 使用新的训练策略刷新了模型精度，方便开发者做下游任务。</p><p></p><p>除此之外，OCR 套件集成业界 SOTA 模型，并刷新精度，平均提升 1 个点，同时做了推理性能加速。整体端到端提速 20% ，后续华为昇思还将会陆续推出视频、3D、生成式 AI 等套件，覆盖 AI 主流场景，2.0 版本重点优化了动态图性能，整体性能提升了 2x 以上，个别场景达到 5x，同时为了符合用户习惯，把动态图作为默认执行模式。在静态图方面，昇思 MindSpore 也全面提升了 Python 语法支持度，面向生产和部署场景可以做到一键转换静态图，做到了“易用”与“性能”的兼顾。</p><p></p><p></p><h3>2、大模型层面</h3><p></p><p></p><p>昇思 MindSpore2.0 的研发进展尤为显著。昇思 MindSpore2.0 基于大模型套件降低开发成本，同时构建了大模型分布式训练推理加速能力，并且提供了高性能的分布式训推基础设施。</p><p></p><p>昇思 MindSpore2.0 强劲的四大套件展现了其一站式大模型训练、微调能力，大大降低了开发者的开发成本—— MindSporeFormers 作为 transformer 类大模型套件，预制了 GPTBloom 等大模型，用户可以实现一键训练、微调、推理，同时预制了丰富的下游任务，包括文本生成、问答、图像分类等；MindSporePet 作为低参微调套件，实现了业界典型的低参微调算法，例如 lora 等，微调 5% 参数实现全参微调结果，相比全参微调，可以降低 40% 内存开销；MindSporeRec 作为 MindSpore 推荐大模型套件，支持 TB 级推荐模型，分钟级模型更新；MindSporeRLHF 则主要是为了实现类 ChatGPT 的强化学习微调流程，支持了 rewardmodel 训练，PPO 强化学习，百行代码即可实现百亿级模型的 RLHF 训练，助力用户快速实现自己的 <a href=\"https://xie.infoq.cn/article/2328b0dab42fb1846fd5eae3a\">ChatGPT</a>\" 。</p><p></p><p>MindSpore 原生支持大模型，通过编译的方式实现了多维混合并行和多维存储及异构优化，支持了训练大模型常用的数据并行、算子级模型并行等。此外还有 MindSpore 原创的多副本并行，结合昇腾硬件高并发特性，进一步提升并行性能。并且支持多种并行模式灵活组合使用。在存储优化上，实现了全局内存复用，重计算等，进一步提高了存储利用率。值得一提的是，MindSpore 通过自动化的策略寻优，把算法和模型自动切分到集群上去执行，可大大降低大模型的开发门槛。</p><p></p><p>另外，开发者们都知道，想要充分训练一个千亿参数模型，需要在千卡集群上训练数十天，故障不可避免。于是基于此，MindSpore 还结合昇腾基础软硬件平台优化了集群稳定性，在鹏城实验室创下千卡训练 28 天无中断的记录。</p><p></p><p>除了大模型高效训练，推理成本对于大模型成功商用至关重要。模型压缩和推理优化加速是降成本的首要手段。MSLite 通过结构化剪枝，量化等压缩手段，一键实现模型体积缩小 5~10x ，推理性能提升 30%+ ；当前大模型结构主要以 Transformer 为主，Tranformer 计算在大 shape 下，如何减小访存是优化加速的关键。MS 结合 AKG 自动完成大算于是合，单层 Kernel 数量由 40+ 减少到 6 个，大算子计算主要在片上缓存进行，减少了 HBM 的数据搬运，显著提高推理性能。同时，MindSpore 也提供了 seveingAPI 供云侧部署，用户灵活选择并行策略，实现多机多卡、多 batching、多模型组合推理，用以提升算力利用率。</p><p></p><p></p><h3>3、AI4S 领域技术布局层面</h3><p></p><p></p><p>在科学计算领域中面临着很多难以求解的问题，像药物和材料设计科学研究的问题复杂度呈指数级增长，如何将 AI 技术打造为科研新范式，使昇思 MindSpore 在进行架构设计时就开始了的科学计算领域布局，过去乃至未来将持续探索并完成 AI 计算框架向 AI 融合框架的演进。</p><p></p><p>为了支撑 AI4S 领域技术创新，通过一个软件底座同时支撑传统 AI 和科学计算领域，达到高效易用AI框架构建的目的，昇思 MindSpore 做了一下 2 个层面的优化：</p><p>（1）融合编程：全面支持函数式算子调用，新增函数式 API 以及 Tensor 类 API200 个以上。</p><p>（2）融合优化：在数据层面，对接常用分布式系统数据结构如 HDFS ，性能提升 30% 。针对数据处理提供融合编排的能力，特征工程性能 2+ 倍提升。在计算层面，静态图运行时提供 Fallback 能力，支持动态输入，通过“张量计算”将非亲和操作转为张量运算，充分释放 <a href=\"https://xie.infoq.cn/article/23bc53ffabadfb1d5989f43ec\">AI 算力</a>\"。</p><p></p><p>昇思 MindSpore2.0 构建了电磁仿真、流体力学、生物计算三个套件，同时构建融合框架能力，提供函数式微分、计算图编译加速，支撑 AI4S 突破前研特性。其中 MindSporeElec 大大加速电磁仿真的效率，小到我们手上的手机或者耳机、大到无线基站的天线阵列都能实现 10 倍级效率的仿真模拟，大大提升了产品设计的效率；MindSporeFlow 是面向流体仿真的套件，它能高效模拟飞机起飞至飞行阶段中飞机机翼及机体流场的时空演化，为飞机气动设计提供价值性参考；MindSporeSPONGE 则是面向生物计算的分子模拟工具，基于此工具华为昇思联合昌平实验室等科研机构完成了蛋白质折叠的训练与推理全流程，并且在参加全球持续蛋白质结构预测竞赛 CAMEO 中成绩连续三次保持全球第一的排名。</p><p></p><p>目前，昇思 MindSpore2.0 正在作为 AI+ 科学计算融合的新一代框架，不断在效率提升、易用性、创新性等方面推动 AI 框架持续演进</p><p></p><p></p><h2>三、AI 框架开源开放，联合打造可以使能伙伴的“ AI 基础设施”</h2><p></p><p></p><p>在技术演进的长河中，硬件系统都需要软件来“使能”，所以在这个 AI2.0 时代，AI 框架高速发展，这意味着，除了对物理计算量的硬件要求外，软件的开发和调度效率也面临着巨大的挑战。在此背景之下，AI 框架既要如同汽车方向盘一般，给 AI 用户提供便捷的操作接口，也要像变速箱和传动轴一般，将算力合理高效的调度，发挥出系统最佳的性能。可以说，AI 框架作为 AI 根技术，在 AI 基础设施中承担着操作系统的关键角色。</p><p></p><p>正如昇思 MindSpore 开源社区理事长丁诚在峰会上所说的那样：“在整个 AI 技术体系中，AI 框架南向使能多样化算力，北向孵化各类创新算法模型，处于人工智能技术体系的核心中坚，是人工智能的创新源泉。”</p><p></p><p>我们看到，昇思 MindSpore 作为新时代的 AI 框架，始终坚持开源开放，自 2020 年 3 月 28 日开源以来，其社区已累计 1.3 万贡献者，474 万下载量，被评为最具创新活力的 AI 开源社区，已在 200 多所高校中开设了人工智能教学课程，有超过 900 篇顶会论文基于昇思研究和发表，并且基于昇思原生孵化的大模型已达 20 多个；同时昇思已经服务了超过 5500+ 的企业，并依托大模型和科学智能原生创新成果，成立了遥感、流体、多模态 3 大产业联合体，加速技术成果转化；同时昇思面向端边云全场景开放，已适配了国内主流的 AI 芯片和硬件设备超过 20 款。</p><p></p><p>其实我们从本次峰会上，昇思 MindSpore2.0 发布过程中就不难看出昇思 MindSpore 团队在开源和组织使能方面的努力。</p><p></p><p>比如 Pytorch 生态作为当前 AI 框架的最大生态，如何迎接 MindSpore 用户便成为了 MindSpore2.0 需要重点考虑的问题。于是昇思 MindSpore 通过提供 Pytorch 兼容套件、SAapter ，用以原生 MindSpore 框架构建完全对标 pytorch 接口能力，来提升 pytorch 生态迁移能力。目前启智社区配套 MS2.0 版本已发布 MSAdapter 工具，从已完成 70+ 主流 pytorch 模型迁移来看，模型迁移平均修改代码量&lt; 15% ，平均迁移周期从 1 人月提升到 1 人周左右。</p><p></p><p>又比如 MindSpore 从 2020 年开始孵化大模型，21 年年初和鹏城实验室联合发布了千亿参数的 NLP 大模型。同时和中科院自动化所合作发布了紫东太初、和空天院合作发布了空天灵眸大模型，和武汉大学合作发布了 luojia 遥感大模型，和商飞合作发布了东方御风大模型。去年还和鹏城实验室合作孵化了鹏城神农蛋白质大模型，入围了戈登贝尔奖。</p><p></p><p>在近 2 年半的时间里，MindSpore 和业界各大科研院所、高校、企业合作孵化了 20 多个大模型，覆盖了计算机视觉、自然语言处理、多模态、语音、科学计算、AIGC 等领域。其中有 6 个是千亿参数以上的大模型。在众多大模型实践中，MindSpore 也逐步催熟了整体的大模型解决方案，为用户提供了一站式的大模型能力。</p><p></p><p>而我们也正是通过这些积淀，才有理由相信，昇思 MindSpore 开源社区在各界伙伴的支持下，将有效把握人工智能和产业变革的机遇，在人工智能行业前沿方向的探索方面将在产业中起到模范带头作用。在昇思 MindSpore“加强人工智能基础软硬件建设，坚持开源开放，赋能千行百业”的不变追求下，人工智能技术在全产业界发展的未来值得我们期待。</p>",
    "publish_time": "2023-06-20 13:44:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "“AI孙燕姿”爆火后，Meta发布通用语音生成AI：可合成6种语言，支持多种语音功能",
    "url": "https://www.infoq.cn/article/YF1LRfH3Ttt7eZ0mBPjQ",
    "summary": "<p></p><blockquote>Meta 放大招，语音生成 AI 领域又有新研究成果了！</blockquote><p></p><p></p><h2>Meta发布语音生成AI模型Voicebox</h2><p></p><p>&nbsp;</p><p>近日，<a href=\"https://www.infoq.cn/article/j32bh1HTyBCqVTZJBpMi\">Meta AI </a>\"宣布在生成式AI语音模型领域取得了突破：开发出了首个可泛化至多种语音生成任务的模型Voicebox，无需专门训练即可达成顶尖性能表现。Meta AI 研究人员分享了多段音频样本和一篇研究论文，其中详细介绍了他们采用的方法和取得的成果。</p><p>&nbsp;</p><p></p><p></p><p>与图像及文本类生成系统一样，Voicebox能够创建多种样式的输出，包括从零开始创建输出、修改给定样本等。但与以往不同的是，Voicebox并非简单创建图片或一段文字，而是直接生成高质量的音频片段。该模型能够为括英语、法语、西班牙语、德语、波兰语和葡萄牙语在内的六种语言合成语音，同时执行噪声去除、内容编辑、风格转换和多样化样本生成等任务。</p><p>&nbsp;</p><p>在Voicebox出现之前，生成式AI语音模型需要配合精心准备的训练数据，就各项任务接受特定训练。Voicebox使用一种新的方法，可直接从原始音频和随附的转录结果中学习。与只能根据给定音频片段续写结尾的自回归模型不同，Voicebox能够修改给定样本中的任意部分。</p><p>&nbsp;</p><p>据了解，Voicebox能够出色执行各种任务，具体包括：</p><p>&nbsp;</p><p>结合上下文的文本到语音合成：使用长度仅为两秒的输入音频样本，Voicebox即可匹配样本的音频风格并据此进行文本到语音生成。后续项目有望为无法说话的人士提供语音支持，或者为游戏NPC及虚拟助手快速生成对话语音。跨语言风格转换：给定一段语音样本，外加一段英语、法语、德语、西班牙语、波兰语或葡萄牙语的文本，Voicebox即可生成对应的朗读音频。这种能力讼人兴奋，未来可以帮助使用不同母语的人们通过自然且真实的方式开展交流。语音降噪与编辑：Voicebox的上下文学习为其赋予了强大的语音生成能力，可无缝编辑音频中的片段。它能重新合成被暂时噪声干扰的语音部分，或者替换掉说错的词，而无需重新录制整段语音。用户可以找到语音中被噪声（如狗叫声）干扰的原始片段，剪切出来并指示模型重新生成。有朝一日，这种能力还可用于清洗和编辑音频，且使用过程与目前流行的图像编辑工具一样轻松便捷。多样化语音采样：利用多样化的真实数据完成学习后，Voicebox将可生成与人们的现实对话高度吻合的以上六种语言对话音频。未来，此功能可用于生成合成数据，协助提升语音助手模型的训练效果。研究结果表明，基于Voicebox生成的合成语音训练出的语音识别模型，在性能上几乎与使用真实语音的模型相当，错误率降低了1%；与以往同类文本到语音模型相比，合成语音数据训练结果的错误率更是大幅降低45%至70%。</p><p>&nbsp;</p><p>Voicebox的诞生，标志着生成式AI研究又向前迈出了重要一步。在文本、图像和视频生成等方面，具备任务泛化能力的可扩展生成式AI模型已经激发了人们对于跨任务潜在应用的浓厚兴趣。Meta AI希望音频领域未来也能掀起同样的潮流，同时继续保持深耕和探索，关注其他研究人员如何在Voicebox的基础之上寻求新的突破。</p><p></p><h2>Voicebox背后的Flow Matching技术</h2><p></p><p>&nbsp;</p><p>现有<a href=\"https://www.infoq.cn/article/YvZHq140J9Kx0*f7ll0F\">语音合成</a>\"工具的主要局限之一，在于只能就专门的任务配合准备好的数据接受训练。这些单调而干净的输入数据相对有限且难以收集，因此也导致输出结果变得同样单调。</p><p>&nbsp;</p><p>Meta AI的研究人员基于“流匹配”（Flow Matching）技术构建了Voicebox，这项技术是Meta在非自回归生成模型领域的最新进展，能够掌握文本到语音之间高度不确定的映射。非确定性映射非常重要，它使得Voicebox能够从不同的语音数据中学习，且无需对各种变化要素做详尽标注。也就是说，Voicebox能够在多样性更强、规模更大的数据之上进行训练。</p><p>&nbsp;</p><p>与当前最先进的英语模型VALL-E相比，Voicebox在可懂度（即单词错误率，前者为5.9%，Voicebox为1.9%）和音频相似度（0.580对0.681）方面均更加强大，且速度要快20倍。在跨语言风格迁移方面，Voicebox也优于领先模型YourTTS，能够将平均单词错误率从10.9%降低至5.2%，并将音频相似度从0.335提高至0.481。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/37/3711ff135510c9c9b47a6c0e781e0c6b.png\" /></p><p></p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/d7/d7c690ebe1020e8aa562f0d891812cd2.png\" /></p><p>&nbsp;</p><p>研究人员使用超过5万小时的语音录音，和来自英语、法语、西班牙语、德语、波兰语和葡萄牙语的公共有声读物转录对Voicebox进行训练。经过训练后，Voicebox能够在给定前后语音和片段转录数据时预测出语音片段。它还能学会根据上下文补全语音，从而被应用于其他语音生成任务，包括在无需重建整个输入的前提下生成音频的中间部分。</p><p></p><h2>“AI孙燕姿”爆火后，再看语音生成滥用风险</h2><p></p><p>&nbsp;</p><p>Voicebox拥有众多令人兴奋的用例，但Meta也承认其存在潜在的滥用风险，所以Meta AI的研究人员决定暂不公开Voicebox模型或代码。Meta在社交平台上公开表示：“与其他强大的人工智能创新技术一样，我们认为这项技术也可能会被滥用，造成意外伤害。”</p><p>&nbsp;</p><p>事实上，语音生成引发的<a href=\"https://www.infoq.cn/article/XmlhizwQHwaFbGaa4Orr\">滥用风险</a>\"并不少见。以华语乐坛最近爆火的“AI孙燕姿”为例，AI让孙燕姿翻红的同时，也让背后的风险显露出来。一方面，AI合成声音可能涉及侵权问题，另一方面，也可能带来一系列伦理和法律的风险。</p><p>&nbsp;</p><p>我国《民法典》第1023条第二款规定，对自然人声音的保护，参照适用肖像权保护的有关规定。第1019条第一款规定，任何组织或者个人不得以丑化、污损，或者利用信息技术手段伪造等方式侵害他人的肖像权。未经肖像权人同意，不得制作、使用、公开肖像权人的肖像。由此可见，比照对肖像的人格权保护，未经权利人的同意，也不得制作、使用、公开利用权利人的声音。</p><p>&nbsp;</p><p>此外，语音生成也会成为电信诈骗的利器。前段时间，美国和加拿大各地使用AI合成语音进行电信诈骗的案例多发，不少老年上当受骗。加拿大警方称，最近加拿大各地都有不少类似案件发生，涉案金额已达数百万加元。有受害者表示，犯罪分子使用的声音和她儿子的声音简直一模一样。在美国，类似的诈骗案件近期也呈上升趋势。</p><p>&nbsp;</p><p>作为首个能够成功执行任务的多功能、高效泛化模型，Meta AI坚信Voicebox即将开创生成式AI语音模型的新时代，但与其他强大的AI创新成果一样，这项技术同样可能因误用引发意外危害。对于语音生成带来的滥用风险，Meta也想好了对策——构建一款高效分类器，用以区分由Voicebox生成的音频和真实语音，借此缓解未来可能出现的种种风险。</p><p>&nbsp;</p><p>在论文（<a href=\"https://research.facebook.com/publications/voicebox-text-guided-multilingual-universal-speech-generation-at-scale/\">https://research.facebook.com/publications/voicebox-text-guided-multilingual-universal-speech-generation-at-scale/</a>\"）中，Meta AI研究人员还具体讲解了如何构建一款高效分类器，用以区分真实语音和Voicebox生成的音频。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://ai.facebook.com/blog/voicebox-generative-ai-model-speech/\">https://ai.facebook.com/blog/voicebox-generative-ai-model-speech/</a>\"</p><p><a href=\"http://www.xinhuanet.com/ent/20230620/85f213fc8b914b7a9ea17addc3cec01e/c.html\">http://www.xinhuanet.com/ent/20230620/85f213fc8b914b7a9ea17addc3cec01e/c.html</a>\"</p>",
    "publish_time": "2023-06-20 14:15:27",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从 Hadoop 到 Snowflake，2023年数据平台路在何方？",
    "url": "https://www.infoq.cn/article/hesXX28CV0S9RM0l8W6S",
    "summary": "<p>随着大数据技术的融合发展，企业对数据平台的要求越发多元：不仅要能够整合集成、存储、管理海量的多源异构数据，还要能够提供连通业务的多样化数据服务能力，并且能够支持不同应用、不同场景中的落地。从 Hadoop 到 Snowflake ，数据平台的发展呈现出清晰的路径，在与云的结合上也探索了丰富的技术实践。</p><p></p><p>那么，数据平台的下一次“潮涌”何时到来？中国版 Snowflake 何时出现？为了探讨问题的答案，我们策划了《极客有约》特别版——《再谈数据架构》系列直播。第一期，我们邀请到了<a href=\"https://www.yunqi.tech/\">云器科技</a>\"联合创始人 &amp; CTO 关涛、Bolt 高级技术副总裁 Xiao Guo 和 RisingWave 创始人 &amp; CEO 吴英骏博士，分别从平台服务商、用户以及投资方的不同视角分享各自的观点。</p><p></p><h1>技术演进及发展：从百花齐放到双线同归</h1><p></p><p></p><p></p><blockquote>InfoQ：数据平台经历了一个怎样的发展过程？</blockquote><p></p><p></p><p>关涛：大数据大概是从 2003 年开始发展的，开始的标志是《MapReduce》《GFS》《BigTable》三篇 paper 的发表。如果从时间维度上对比来看，数据库从七十年代起步，至今大概是 50 年的历史；大数据至今的历史是 20 年；深度学习是 2013 年左右开始发展的，至今刚好 10 年。</p><p></p><p>大数据技术的发展是个典型的“规模带来突破”的例子。如果你把两个数量级以上的数据，以相对低的成本计算起来，形成的效果可能跟以前完全不一样。这种突破是“跳变型”突破。这种模式非常多见，比如最近特别流行的大语言模型， 其本质上也属于“海量数据加海量模型规模“组成的一个跳变。</p><p></p><p>我通常会把大数据的发展分成 3 个阶段：孕育期、发展期和普惠期。</p><p></p><p>第一阶段，从 2003 年到 2013 年是孕育期。大家只听过一些耳熟能详的大厂在做大数据相关的建设，比如谷歌做搜索引擎后台数据处理。2006 年，我加入微软做的微软第一代 KV 系统，也是为了支持搜索业务。</p><p></p><p>第二阶段，之后8-10年的时间是发展期（2013-2023）。发展期有两个关键事项推动了大数据的发展：其一是以 Hadoop 为核心的开源技术；其二是云计算。云计算相关技术的发展极大程度上降低了大数据平台的建设门槛。所以，大家可以看到目前主流的大数据平台都是在 2012 年前后开始发展的，比如说刚才提到的 Redshift 是云上数仓的典型代表，Snowflake 在那时候成立，阿里巴巴大概那个时候开始做阿里云和飞天大数据平台等。</p><p></p><p>第三个阶段，我个人将其称作普惠期。普惠期的特点有两个：其一是千帆竞发后，大部分企业被淘汰，少数企业通过竞争最终占领市场，然后逐步形成规模；其二从技术角度来看，部分技术的发展趋于成熟，如批计算、流计算和分析的一些范式被固定并广泛应用。同时，一些外延的技术比如跟 AI 相关技术的会持续发展。</p><p></p><p>我认为，美国市场可能在普惠期的早期（Snowflake 等核心厂商仍然保持高速增长，年化增长率 60% 以上）；中国的市场已经到了发展期向普惠期转换的阶段。</p><p></p><p>吴英骏：数据平台是从<a href=\"https://s.geekbang.org/search/c=0/k=%E6%95%B0%E6%8D%AE%E5%BA%93/t=\">数据库</a>\"演化出来的。</p><p></p><p>上个世纪六七十年代有了数据库后，大家自然而言会考虑怎么用这些数据进行分析？比如 IBM 的 DB2 是不是能够变成一个可以做分析的平台？最早一批数据平台都是这样慢慢发展过来的。当时相对独立的数据仓库有 Teradata，它是全球最大的数据仓库公司之一，在上个世纪七八十年代就已经开始做了。</p><p></p><p>我觉得数据平台发展的一个核心标志是 Google 在 2004 年发表的 MapReduce 这篇文章。这篇文章发表之后，大家对这个领域非常关注。每个公司内部都有大量的闲置机器，那么，能不能使用这些闲置的机器、大量的闲置计算资源去做大规模的数据分析？2010 年前后，很多创业公司因此想做 MapReduce。另一方面，MapReduce 是 Google 做的一个产品，这个产品在 Uber 等公司是没有办法用的。那怎么办？开源。所以当时就有几个非常火的项目，如 Hadoop、Hive、Impala、Spark。2010 年之后，云时代来了。Snowflake 也是在云时代火起来的。因此，我觉得数据平台在美国的发展，是从单机时代开始，往上一点点发展到 MapReduce，再发展到开源，然后再发展到云上的一个过程。</p><p></p><p>Xiao Guo：我主要从应用层面说一下我的一些见解。</p><p></p><p>第一，现在自建数据中心的公司比较少。Bolt 使用的数据仓库是 Google BigQuery。以前 LinkedIn，Uber 早期的时候还要自建数据中心，现在基本都上云了。现在大部分公司都是用的这三家的数据仓库，即：Amazon Redshift、Google BigQuery、Snowflake。</p><p></p><p>第二，实时数据分析对应用层面来说非常重要。通常来说我们会把线上数据库中的数据 Stream Replication 到数据仓库里面，使用统一的数据仓库便于进行实时数据分析。有时候我们还需要工程师在数据仓库进行人工排错等等。因为这样就能不影响线上运行，成本也相对比较低。</p><p></p><p>第三， AI 和 Machine Learning。现在大部分的公司都会或多或少做一些 AI 和 Machine Learning 的应用，这就要求 data platform 要考虑到 AI 和 Machine Learning platform 的集成。</p><p></p><p>第四， Experimentation Platform。企业做增长、做应用要不停地进行实验，不停地尝试。在这种情况下，data platform 跟 experimentage platform 能否很好地集成非常关键。</p><p></p><p>第五，数据的运营。我们有个机构专门投数据相关的早期的 a 轮公司。在与众多创业公司的交流中，我们发现持续的数据一体化和高质量交付越来越受到企业重视。虽然行业内在这方面还处在比较早期的阶段，但我们的确看到了一些尝试。</p><p></p><p></p><blockquote>InfoQ：普惠的意义就是大家在做技术方案选型的时候，不管是大企业、中型企业还是小企业，都有一套可以选的技术路线方案，并且门槛不太高。那么，目前行业内有哪些不同的数据平台技术路线或者说发展方向？</blockquote><p></p><p></p><p>关涛：从企业客户视角看，目前行业内的技术路线有开源组装自建和购买商业化服务，分别代表着两类技术方向。技术路线的选择也是企业客户在技术方案选型时面临的选择题。</p><p></p><p>开源自建的技术路线，指的是用不同的开源组件拼接在一起，形成一个完整的生态。开源组件可以随业务需求修改，定制化程度高。</p><p></p><p>购买商业服务的技术路线，通常意味着企业希望数据平台做到一体化、更简单、免运维。这条技术路线比较典型的技术产品就是 Snowflake。Snowflake 统一管理企业所有的数据，提供所有通用的功能，给用户一体化的体验，对于实现降低门槛做普惠非常关键。</p><p></p><p>Xiao Guo：我所在 Bolt 这种独角兽的公司，一般来说都是比较倾向于第二条路线，即购买 SaaS 平台的服务。对于小型公司而言，SaaS 平台是比较理想的一个选择。因为这样的平台比较好用，可能很快地部署。企业可以做自己想做的产品，还不需要花费很多资源深度定制、维护平台。</p><p></p><p>随着公司增大，定制需求越来越多，一些大公司可能更倾向于自己开源，然后自己组装，这样的话会更加方便控制。</p><p></p><p>吴英骏：在 Uber 那个年代成立的公司选择自建的一个很重要的原因是，那时候技术还没有很成熟。在那个年代，他们选择自建数据平台成本很高。最近十年成立的公司，尤其 2015 年之后成立公司，已经很少选择自建数据平台了。一方面，技术已经更加成熟；另一方面，市场环境的原因导致自建成本不可控了。在这样的情况下，企业怎么会选择每年花几百万美元还都不确定能做出什么东西，而不是去买一个市面上已经有的成熟产品呢？</p><p></p><h1>分析企业真实需求，把握技术“普惠期”新机遇</h1><p></p><p></p><p></p><blockquote>InfoQ：企业对数据平台的需求及需求的演进是怎样的？</blockquote><p></p><p></p><p>Xiao Guo：首先，过去一年，美国整个经济比较疲软，所以大部分企业的业务重心从不惜一切代价求发展变成了更关注收入和成本控制。所有的公司都在要求削减成本。公司技术负责人需要看人力成本和软件成本，其中软件成本对大部分的创业公司而言，指的是云上的成本、data platform 或者 data warehouse 成本。</p><p></p><p>其次，削减成本是 bottom line，增加收入 top line 相较而言更重要。企业在选择项目时的标准是不能天马行空、不能在几年之后才会产生营收，必须要聚焦、要关注接下来的 12 个月左右能够看到营收。</p><p></p><p>再次，现在 AI 和大模型都非常非常火，大家对 AI 有非常大的兴趣。我们看到大公司比如 Amazon，他们在用大模型技术提高、优化现有的一些模型、一些业务。小公司像我们还没有完全用上大模型，不过也在考虑这件事情了。小公司一般不会建设自己的machine learning platform，而是会采购已有产品。</p><p></p><p>最后，美国企业对于数据的安全性和隐私的关注度是越来越高的。</p><p></p><p>吴英骏：我们分技术层面和商业化层面来讲。</p><p></p><p>从技术层面来讲，大数据已经发展挺久了，我认为并不存在什么真的难点。</p><p></p><p>从商业化角度来讲，我觉得现在一个很大的发展方向是效率，企业需要更加高效。高效的标志有多种，比如企业不需要自己建机房、买机器、联机调试等，只需要付钱买服务立刻就能用，方便快捷是高效；随着技术发展，原本昂贵的服务、较差的性能逐渐优化，价格便宜的同时性能越来越好，性价比高是高效；实时服务也是高效的一个标志；所有的数据平台都在往 SQL 方向发展进而提升开发效率。</p><p></p><p>总的来说，我认为目前技术层面很多问题都已经被解答了；从商业化层面，或者说从市场发展规律来讲的话，未来肯定是往效率方向去讲这个故事。</p><p></p><p>关涛：数据平台的技术从孕育期到发展期再到开始进入普惠期，这三个阶段的变化跟客户的变化也是相辅相成的。技术发展分成三个阶段，客户也分成三大类。</p><p></p><p>在孕育期，客户通常是 early-adopter，不一定是大公司，而是技术能够做到极致的玩家，人数很少，可以称作是金字塔塔尖上的那一群人。他们有很高的技术水平和动手能力，能修改开源代码，能推动技术做迭代，这是&nbsp;early-adopter。</p><p></p><p>到发展期，我们把客户归类为 Early majority。技术理念初步深入人心，市场上一大批对新技术有渴望的人会把这个技术用起来，然后会催生很多技术型的平台服务提供商。</p><p></p><p>然后是普惠期，我们把客户归类为 late majority。大家觉得用这个技术已经是一个公认的事情了。</p><p></p><p>客户需求就像一个金字塔，从最顶尖的客户需求开始向下一层一层地扩展。最开始的 adopter 侧重于 0-1，要满足从来没见过的新场景，要通过技术带来竞争的独特的差异化优势，要构建竞争门槛，所以那些技术的创新和变化是非常非常多的。在这种变化里面，开源的众筹迭代模式很重要。</p><p></p><p>再往下一点，模式就会变得固定一些，大家都这么用，然后形成了最佳实践。最佳实践累积沉淀成平台，然后平台慢慢就打磨起来，能满足多样的客户需求，让更多企业能用起来这些平台。</p><p></p><p>结合我之前的经验，我们会更细致地把客户大概分成四类。</p><p></p><p>第一类，我们叫做一线大型科技公司，在过去通常是互联网公司为主。比如市值排名前 30 的企业通常有很大的规模，有很强的技术创新的诉求，会有很多定制化的需求。这些企业一般会去选择自建。</p><p></p><p>第二类，我们叫做&nbsp;digital native，就是数据原生的公司，这种类型的公司通常规模中等，可能在 100-1000 台物理服务器的这样的一个规模。这些企业我们能看到他们越来越不考虑自建了，他们会觉得自建反而不划算。举个例子，之前国内有一家公司 A，大概需要 100 台 物理服务器做数据平台，硬件成本年化大约 300 万 / 年，如果选择自建的方式，企业要把一整套数据体系做起来大概需要 10 个模块组件，需要 4-5 人的团队来维护，人力成本大概也需要 300 万元一年。如果购买 SaaS 服务，含硬件成本也就 400 万。企业发现自建人力成本几乎和硬件成本一样高，所以这类企业慢慢开始转向购买平台服务。</p><p></p><p>第三类，我们叫做有技术能力的传统企业，典型代表比如说银行、保险，现在包括新制造比如造车企业，他们有很多的数据需求。他们技术能力很强，也有很强的付费意愿。这类型客户大部分选择购买数据平台，像银行通常不太会选择自建数据平台，一定会选择购买，因为觉得买来的商业化产品可能从安全性、稳定性的角度是有厂商负责的，有人兜底的，这个对他们很重要。</p><p></p><p>第四类企业，我们叫做传统企业，还有数字政府类的，这些企业通常是个纯粹的使用者，他们甚至都不具备构建数据平台的能力。不同类型的客户要的不一样。第一类，可能是自建和极致的定制化，中间两类的可能会购买平台型的服务。最后一类，可能他不会买平台，也不会建平台，要的是个解决方案。</p><p></p><p></p><blockquote>InfoQ：在需求这方面，中美之间有差异吗？</blockquote><p></p><p></p><p>吴英骏：我觉得肯定是有差异的。美国企业可能更加 care 的是易用性方面，而中国企业看重的是性能。</p><p>还有另外一个点是，中国的用户更加偏向于大一统的系统需求，可能是需要用一套架构解决所有问题。比如我们用微信的时候，我可能不太想希望去跳到其他平台，微信小程序就类似于转化系统；但美国由于产品实在太多了，而且它产品分工非常明确、非常细，所以对于美国来说最优的解决办法是去把这些东西拼装起来，只要你能给我一个非常简单的拼装方式，我就非常满意了。</p><p></p><p>关涛：先说技术，技术上中国和美国几乎拉平的，得益于非常频繁的技术交流，比如说今天这样的一个圆桌。</p><p></p><p>在商业生态上，国内跟美国，不同的企业可能不一样，大概有 3-7 年的差别，美国的商业生态上更关注的事情，国内可能要再晚几年才会关注到，比如安全和隐私保护，这是我个人的视角。</p><p></p><p>除此之外，中美还有几个差异点：</p><p></p><p>第一点是付费意愿的问题，美国企业更愿意为知识、为软件来付费。在国内你会发现很多小公司愿意开源自建，原因就在于软件的费用就省掉了。当然，后来大家越来越明白，可能人力资源的那部分成本比一般软件还要贵。</p><p></p><p>第二点是迁移方向的问题。刚才嘉宾举了个例子，大家觉得 Snowflake 太贵了，然后转移到自建上去，我这看到正好相反，我这边看到的在国内的特点是说，国内大多数公司把自建平台转向了 SaaS 托管化的平台，这件事的核心是公司要削减成本，公司会把那些维护这个平台的人转移到业务上去。</p><p></p><p>第三点不同是对安全的要求不相同。美国对数据隐私安全合规的要求要高一点。</p><p></p><p>第四点，我个人认为国内公司的技术好奇心更强，也更开放。你跟他谈一些新技术，给他一些新的产品，他非常愿意尝试，并能快速迭代给你。但国外可能门槛要高一点，你不达到一些成熟的标准，比如说不达到合规和稳定性的标准，很多美国的企业一定打不进去。这也是国内的技术生态发展迭代快的一个因素。</p><p>InfoQ：Snowflake 现在在大数据里面做得非常成功，这个平台它这么受欢迎的原因是什么？</p><p></p><p>Xiao Guo：作为用户，我觉得它最好的一点就是你用它的时候不用去特别去想它背后的细节。它可以提供很多功能，能帮助企业进行基础设施的复杂管理和优化。</p><p></p><p>并且，Snowflake 也是 SQL based。engineer，product，manager，product analyst 甚至 customer，所有人都可以用&nbsp;Snowflake&nbsp;很简单地去查询想要的内容，看到业务数据的一些表现。同时它可以支持任何云厂商，企业不用担心自己因为在哪个云平台上而得到有限的服务。</p><p></p><p>Snowflake 也会有一些安全的标准，在数据的加密上做得很好。再就是查询响应速度。作为一个用户来说，我最关心的是一个 query 能不能很快反馈，能不能支持很多用户同时访问等。总而言之，作为一个终端的客户，我更关注的是我自己的产品，而不是去花很多时间去想数据平台如何构建。如果一个平台让你不用去想它就能用，能让你有更多时间专注于做对自己公司而言重要的事情，还能满足公司需求，就是一个很好的平台。</p><p></p><p>吴英骏：我们经过长期访谈发现，用户用 Snowflake 是越用越爽的。用户一开始没有想付那么多钱，但是这个平台实在太好用了，所以他就一直发 query，就导致这个平台越用越贵，账单才会越来越高。但是如果要去问用户说，Snowflake 到底好在哪？他们都说不清。另外，Snowflake 的用户模型，或者说它的收费模式也非常好，好处在于说你不用去选机器，你只要告诉我你选的一个 T-shirt Size，其他东西都帮你搞定了。Snowflake 现在在往 DataCloud 方向改良，集成了相当多的东西，这些东西能让客户使用产品时一键搞定所有事情。</p><p></p><p>关涛：前面嘉宾提了很多形容词，我用一个词来形容它，叫一体化。</p><p></p><p>Snowflake 的一体化的能力其实做得非常好，使得它很容易能被很多人用起来。如果一个公司的平台建设完，但这个平台只有数据开发的那几个同学能用起来，别人要用的时候都要经过这几个人，整体效率就很低。Snowflake 的一个好处就在于也许你不是特别懂系统，也许你只是会写 SQL，你也可以把它很好地用起来。刚才说的扩展性的问题、调优的问题都被系统屏蔽到系统底层之下，你不需要管它。</p><p></p><p>这种一体化的能力，是提升业务效率，降低使用门槛的关键。让那些并不太懂技术的人，也能够很好地使用数据平台，就是 Snowflake 成功的第一个关键点。</p><p></p><p>多云或者叫云中立是 Snowflake 成功的第二个点。很多客户、特别是大客户特别看重数据平台是否会绑定在一家云上。</p><p></p><p>第三个关键点是&nbsp;Snowflake 面向云原生弹性的收费能力。对于小企业来讲，&nbsp;Snowflake 起步非常便宜。</p><p></p><p>所以让我总结 Snowflake 这个平台受欢迎的点，一个是一体化的能力，一个系统解决大多数问题；第二个是多云和云中立；第三个是弹性的收费能力降低了用户使用的门槛。</p><p></p><h1>把脉市场趋势：中国的 Snowflake 路在何方？&nbsp;</h1><p></p><p></p><p></p><blockquote>InfoQ：从投资人的角度，你如何看待数据平台技术的发展？</blockquote><p></p><p></p><p>Xiao Guo：目前我们在看一些生成式 AI 的项目，因为我们觉得数据是接下来十年或者更长久的一个巨大的最本质的推动力。大家都说接下来的十年 AI、生成式 AI 会为社会的生产力带来极大提升，而驱动 AI 最底层的就是数据。所以我觉得在接下来的十年之内，数据还有 AI 都是非常大的一个浪潮。</p><p></p><p></p><blockquote>InfoQ：一家初创公司需要具备什么样的特性，你才会考虑投资？</blockquote><p></p><p></p><p>Xiao Guo：很多方面。</p><p></p><p>早期公司我们很看重创始人的背景，因为我们投的就是偏技术的公司，创始人及创始团队需要有很强的技术实力。</p><p></p><p>第二，看产品是不是能解决市场上的一些痛点。要么企业自身已经有用户，要么市场上跟他同类型的不同阶段的公司已经有用户。初创企业，就看他们有没有愿意付费的人；比较后期的话，我们就看他有多少付费的用户。公司产品是否能解决具体的问题，拥有哪些具体的客户，对我们来说很重要。</p><p></p><p>第三，我们还要看这个赛道有多大，这个市场有多大。有的企业不仅面向科技企业推荐产品，还会向一些传统企业推销产品。随着对数据的需求不断增加，传统企业也会增加软件的采购需求。我们投资的时候，一般除了跟这个团队聊，我们也会跟他们的客户聊，问客户的使用的体验，对整个产品有什么反馈等。</p><p></p><p></p><blockquote>InfoQ：不管是从使用方的角度，还是从创业者的角度，行业内对中国版 Snowflake 的呼声从未停止。各位嘉宾怎么看这样的一个浪潮呢？</blockquote><p></p><p></p><p>吴英骏：这个我觉得应该说是叫众望所归。</p><p></p><p>现在大家都可以看到国内有很多云平台，比如说像阿里云、腾讯云、华为云包括像天翼云，包括像其他一些各种各样云平台，有这么多云平台。但是中国似乎没有一家类似于像 Snowflake 这样的独立的云平台。我相信这个赛道有很多玩家，但是我们没有见到过一家有 Snowflake 这种影响力，或者说有很多人认可的独立第三方的公司，现在目前没有。</p><p></p><p>在跟国内用户聊的时候，我发现国内用户他们都希望用多云，他们不太希望被一家云绑定。他们甚至会自己做一些迁移，就是为了防止被一家云绑定。</p><p></p><p>所以，如果这时候出现一个第三方的产品，足够好用，价格相对来说比较合理，一定有其存在的合理性。</p><p></p><p>关涛：我听到的呼声蛮多的，从我在阿里云做阿里云平台的数据平台产品的时候就能听到。主要原因大概我觉得可能分成三类。</p><p></p><p>第一，快速发展的中国云市场，带来更多需求。中国是个大市场，有很多的用户和海量数据，但是中国的云规模相对不大，中国的云跟美国的云从营收层面比，大概有 1:7 的一个比例，这个跟中国整个经济的体量并不太匹配。从这个层面，我们刚才提到的数据发展三阶段，就是从这个孕育期到发展期到普惠期，云本身也是在发展期后期到普惠期的前期。中国的云市场还有很大的发展空间。</p><p></p><p>第二，中国缺乏多云独立的数据平台服务。中国云生态很分散，大家提到美国就是三朵云了，几乎没有第四。中国除了刚才提到的阿里、腾讯、华为以外，还有像天翼、字节等等。中国的云发展的生态更分散，这个也是技术发展期的一个特征，就是百花齐放的一个样子。这种百花齐放对用户来讲确实是个问题，他希望不被锁定。</p><p></p><p>第三，从对标厂商层面看。美国三大云数仓 + 两个独立数据平台（Snowflake，Databricks） 的数据平台格局已经形成。相比起来，国内做原创数据平台技术的公司并不多，市场整体还是偏空白的状态。</p><p></p><p></p><blockquote>InfoQ：如果出现一家中国版的 Snowflake，那这家企业应该具备什么样的特质？</blockquote><p></p><p></p><p>吴英骏：我相信它肯定不是一个单纯的 copy ，肯定是需要去做本地化。在中国市场做本地化，跟在美国市场有非常多的不同。</p><p></p><p>首先，生态方面的差异。整个大数据的生态两者是不一样的，比如说美国市场是像亚马逊云科技、GCP 这些生态，在国内可能是阿里云、腾讯云这样的生态。</p><p></p><p>其次，用户需求的差异。从国内用户的角度来去考虑的话，他们相比于美国用户，对性能相信是有更高要求的。国内企业的业务量非常大且独特，像双 11 这种业务场景的流量和独特性肯定是秒杀美国黑五的。如果你做中国版 Snowfalke 只是去 copy 的话，可能意义不是特别大。</p><p></p><p>最后，用户文化的差异。在美国文化中，美国用户能够接受企业做拼装融合多种产品需求，但在中国不一样，它希望最好能做成微信的样子，一家全部能做了。</p><p></p><p>回到话题本身，我相信如果要是中国做一家 Snowflake，它需要在本土化上面做得非常强，肯定不是去 copy to China 这样的一个模式。</p><p></p><p>关涛：如果与 Snowflake 对标起来，我觉得有五个标准：</p><p></p><p>第一，它应该是多云的。</p><p></p><p>第二，它是一体化的，能用一套系统能解决用户的很多数据的问题。或许不一定解决所有问题，但它至少应该是一个高内聚、低耦合的系统。</p><p></p><p>第三，我觉得关键的是原创的技术。如果今天拿开源的技术组装成一个系统，它很难做到非常好一体化。无数的案例已经证明了这一点。Snowflake 好就好在它是一个一体化的东西，是非常耦合一体化的东西。</p><p></p><p>第四，我很同意嘉宾刚才提到的，就是不能照搬，就是如果今天照抄 Snowflake 的技术，那是 8 年前的技术。Snowflake 起步大概在八九年前，让它火起来的技术在当年是创新但在现在已经不是了。所以中国版&nbsp;Snowflake&nbsp;要有原创能力和面向新一代的技术的创新，要比 Snowflake 做得更好才可以。</p><p></p><p>第五，好的 To B 能力或者说本土化。好的 To B 能力指的是基础设施产品。除了技术以外，你要有很好的产品的包装能力，让用户用起来很“爽”；要有很好的商业服务能力，包括现场实施、安全性合规等，能够服务好客户。</p><p></p><p>所以总结下来，中国版的 Snowflake 应该有五个特征：多云、一体化、原创的技术、比 Snowflake 更新一代的创新、好的 ToB 能力。</p><p></p><p>我觉得目前国内还没有一家公司可以做到这些五点，并且已经形成影响力。我们云器希望构建这样的一些服务，这也是我们的一个目标。</p><p></p><p></p><blockquote>InfoQ：关涛老师的公司云器科技在 7.20 的时候有一个发布会，能不能请关涛老师给我们提前剧透一下？</blockquote><p></p><p></p><p>关涛：前面大家已经聊了很多，我谈下我们为什么要做这样的一家创业公司？</p><p></p><p>在美国数据平台领域，三家核心云厂商都有原创的“主力”数据平台，还有两个独立的数据平台（Snowflake、Databricks），形成 3+2 的格局。在国内，真正做原创的数据平台技术的公司并没有那么多，目前也没有一个成规模能像 Snowflake 一样的多云平台独立提供商。所以，我们希望能够做一个多云和一体化体验的数据平台，能够普惠国内的用户。所以，我们做了云器科技。</p><p></p><p>商业模式上，我们跟 Snowflake 很像，是多云独立设计、一体化极简的架构。在技术上，我们提出基于&nbsp;SingleEngine 理念的湖仓平台，很多能力会超越 Snowflake。</p><p></p><p>我们在 7 月 20 号举办首发发布会，会正式推出我们的 Lakehouse 平台，同时会有实际的客户案例展示出来。大家想要关注我们的话，可以搜索云器科技，能看到我们的官网的页面。</p><p></p><p>7 月 20 日，云器科技将首次对外举办新品发布会。云器首创以“Single-Engine”为核心理念的湖仓平台，目前已经完成了数亿元融资！为什么云器可以在当下的市场环境中获得投资方和企业客户的青睐？点击“<a href=\"https://www.yunqi.tech/summit2023\">报名</a>\"”立刻报名发布会一探究竟！</p>",
    "publish_time": "2023-06-20 14:59:38",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AIOps大规模站点可靠性工程，保障在线服务稳定运行",
    "url": "https://www.infoq.cn/article/9D2iD99q1D2ozXGtG00B",
    "summary": "<p>软件是从20世纪开始吞噬世界的，而到了21世纪的今天，它把血盆大口转向了人类。</p><p>&nbsp;</p><p>无论是金融系统、政府软件还是企业对企业应用程序，有一点是不变的：这些系统对于组织收益来说是至关重要的，甚至在某些情况下对人类安全也至关重要。在面对来自技术层面、自然和人造的逆境时，它们必须保持高可用。于是，站点可靠性工程师（或SRE）应运而生。</p><p>&nbsp;</p><p>SRE模式诞生于2003年，当时Ben Treynor Sloss<a href=\"https://sre.google/in-conversation/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODY2MjUwNDMsImZpbGVHVUlEIjoieGs4NGU1bnVHdk1rck5BUCIsImlhdCI6MTY4NjYyNDc0MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0._e4RYU8-6gaSJPv8VvDp0NDfQpQvmbAZDiBi6HSZ3OY\">组建了第一个SRE团队</a>\"：</p><p>&nbsp;</p><p></p><blockquote>从根本上说，当你要求软件工程师设计运维功能时，就是所谓的SRE……SRE基本上就是在做一直以来由运维团队完成的工作，只是使用了具备软件专业知识的工程师，并依靠这些工程师天生就倾向和擅长使用自动化来代替人类劳动的能力。</blockquote><p></p><p>&nbsp;</p><p>企业从一开始就按照各种不同的方式采用这个模型，但其本质都是一样的。这些工程师为企业的收入和不间断的业务关键型运营提供支持。</p><p>&nbsp;</p><p>招聘和培训SRE工程师是一项具有挑战性的工作。在这个基础设施和新技术不断变化的世界里，该如何可持续地扩展这些团队来确保团队的福祉和运营的连续性？答案是AIOps。</p><p>&nbsp;</p><p>AIOps（即人工智能IT运营）是一系列使用人工智能、机器学习和大数据分析来提高软件系统可靠性的技术和实践。AIOps能够降低认知负担、加强跨职能协作、减少停机时间、提高客户满意度和降低成本开销。</p><p>&nbsp;</p><p></p><h1>降低认知负担</h1><p></p><p>&nbsp;</p><p>待命工程师的精神压力来自两个方面：警报（信号噪音）和信息获取。</p><p>&nbsp;</p><p>对于曾经使用过传呼机的人来说（我们现在已经不再使用传呼机了，不是吗），当说到精神压力时，噪音与信号问题就会立即浮现在脑海中。这里存在一个有效的警报与敏感或嘈杂过头的警报之间的平衡问题。这个问题会导致一种叫做<a href=\"https://www.usenix.org/conference/srecon17europe/program/presentation/jalleda?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODY2MjUwNDMsImZpbGVHVUlEIjoieGs4NGU1bnVHdk1rck5BUCIsImlhdCI6MTY4NjYyNDc0MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0._e4RYU8-6gaSJPv8VvDp0NDfQpQvmbAZDiBi6HSZ3OY\">噪音疲劳</a>\"的症状。</p><p>&nbsp;</p><p>AIOps的一个关键好处是降低认知压力。AIOps系统可以自动识别和诊断问题，甚至可以在潜在问题发生之前做出预测。这可以降低SRE团队的认知负担，让他们能够专注于更多与业务相关的工作，而不是把时间花在故障排除上。</p><p>&nbsp;</p><p>此外，AIOps系统可以协助处理与事件分类相关的“前置问题”。监控系统收集了数百万个数据点，而与警报相关联的信息的质量取决于人。在SRE开始进行系统分类时通常会面临一个问题：</p><p>&nbsp;</p><p></p><blockquote>“我应该从哪里开始了解潜在的影响半径？”</blockquote><p></p><p>&nbsp;</p><p>AIOps系统可以分析系统状态和遥测数据中的潜在异常，提供需要关注的潜在领域和内部文档，以此来协助进行这种初始分类。</p><p>&nbsp;</p><p>SRE必须开始考虑如何在其组织中采用AIOps。这是SRE需要学习的另一种技术，它可以在降低整体认知负担方面带来指数级的积极效果。</p><p>&nbsp;</p><p></p><h1>加强跨团队职能</h1><p></p><p>&nbsp;</p><p>AIOps可以显著改善业务中的跨职能协作。在传统的IT运营模式中，不同的团队可能在相互孤立，导致在解决问题时出现沟通不足、误解和延迟。AIOps可以帮助弥合这些差距，并促进不同团队之间的协作。</p><p>&nbsp;</p><p>AIOps改善跨职能协作的一种方式是为各种IT流程提供实时的洞见和分析能力。不同的团队可以访问相同的信息，有助于改善沟通和减少误解。例如，AIOps提供的数据可以帮助IT团队和业务利益相关者识别潜在问题，并主动采取措施防止问题发生，从而获得更好的结果和更高的客户满意度。</p><p>&nbsp;</p><p>AIOps改善跨职能协作的另一种方式时自动化各种IT流程。通过自动化日常任务，AIOps可以为IT团队腾出时间来专注于战略计划，例如改进客户体验和提出创新的解决方案。这可以改善IT团队和业务利益相关者之间的协作，让他们能够共同确定可以通过实现自动化来提高效率和降低成本的领域。</p><p>&nbsp;</p><p>总的来说，AIOps可以通过提供实时洞察和分析、自动化日常任务以及支持不同团队之间的协作来改善跨职能能力。AIOps通过打破孤岛和改善IT与业务利益相关者之间的沟通来帮助企业交付更可靠、更高效的IT服务，从而获得更好的结果和更高的客户满意度。</p><p>&nbsp;</p><p></p><h1>减少停机时间</h1><p></p><p>&nbsp;</p><p>AIOps的另一个关键好处是减少停机时间。诊断系统回归问题或故障的本质就是在受限的环境中计算系统的性能。成千上万的数据输入需要人工干预，从而设计出额外的系统，根据给定的一组指标向工程师发出警报。当工程师必须在警报被触发后读取和解释呈现给他们的数据时，这个过程将进一步扩展。</p><p>&nbsp;</p><p>一些指标，如检测时间（Time-to-Detection）和解决时间（Time-to-Resolution），是对工程团队在接收、解释、分类和解决此类事件方面的有效性的综合评估。所有这些都可以通过实现AIOps系统来获得极大的改进。在关键领域，可能有必要通过人工干预来决定采取哪些行动。AIOps系统可以智能地分析它获得的数据，同时在不需要人工干预的情况下自动修复不太重要的问题，只对严重的问题发出警报。</p><p>&nbsp;</p><p></p><h1>提升客户满意度</h1><p></p><p>&nbsp;</p><p>从客户的角度来看，AIOps可以对他们所获得的服务的满意度产生重大影响。例如，AIOps可以帮助企业在问题给客户带来影响之前进行主动识别和解决。这意味着客户不太可能会遭遇服务中断或停机，从而提高服务的可用性和可靠性。此外，AIOps可以帮助企业提高处理事故的速度和准确性，从而最小化事故对客户的影响。</p><p>&nbsp;</p><p>AIOps的另一个好处是帮助企业更快地识别和解决问题，从而缩短解决问题的时间。这对于遇到关键问题或停机的客户来说尤其重要。通过更快地解决这些问题，企业可以最大限度地减少对客户的影响，降低客户流失的风险。</p><p>&nbsp;</p><p>总的来说，AIOps可以帮助企业交付更可靠和可用的IT服务，更快地处理事故，具有显著提高客户满意度的潜力。作为一名高级软件工程师，我相信AIOps是一种强大的IT运营方法，可以帮助企业在当今快节奏和竞争激烈的市场中保持领先地位。</p><p>&nbsp;</p><p></p><h1>降低成本和开销</h1><p></p><p>&nbsp;</p><p>AIOps可以帮助自动化和优化各种IT流程，包括监控、事故关联和事故处理。AIOps通过自动化这些过程来减少对人工干预的需求，从而降低了劳动力成本。此外，通过优化这些流程，AIOps可以帮助公司减少管理IT运营所需的时间和资源，从而节约总体成本。</p><p>&nbsp;</p><p>这可以帮助公司减少发生服务中断的次数，从而节约大量成本。停机时间和服务中断对企业来说代价高昂，会导致生产力、收入和客户满意度的损失。AIOps会在问题给服务带来影响之前将其检测处理并加以解决，降低了发生服务中断和停机的风险，从而为业务节约了成本。</p><p>&nbsp;</p><p>此外，AIOps可以帮助企业改进其整体IT基础设施和应用程序性能。AIOps通过为企业提供对应用程序和基础设施性能的实时洞察来优化资源使用和提升效率。这样可以减少对额外硬件和软件资源的需求，节约了成本。</p><p>&nbsp;</p><p>如果你在网上快速搜索一下，就会发现美国软件工程师的平均年薪是9万到11万美元，这大致相当于每小时47至57美元。想象一下，如果一起事故需要5个工程师花3个小时来解决，那就相当于每起事故需要花费705至855美元。如果一个月发生三起事故，每年的成本约为30780美元，这还不包括客户收入损失或失去客户信任所带来的无形成本。你可以通过问自己几个问题来粗略估计一起事故给你的公司造成了多大的损失。</p><p>&nbsp;</p><p>公司给工程师发的薪水是多少？公司一年发生多少起事故？需要多长时间才能解决这些问题？公司因事故造成的无形成本是多少？</p><p>&nbsp;</p><p>在做了这个粗略的计算之后，你很快就会明白，即使事故减少10%，也会为公司节省一笔可观的费用。</p><p>&nbsp;</p><p></p><h1>如何着手实施AIOps</h1><p></p><p>&nbsp;</p><p>事实上，对于任何一个组织来说，采用AIOps都是一个漫长的过程。然而，通过坚持不懈的努力和专注，公司可以从中获得如前所述的好处。下面是开始采用AIOps时需要注意的一些事项。</p><p>&nbsp;</p><p>制定目标：第一步是确定你希望通过AIOps来实现什么，比如减少停机时间、提升事件响应速度或优化资源利用率。评估当前的IT基础设施：在实施AIOps之前，你需要了解现有的IT基础设施，包括当前使用的工具和技术。这可以帮助你确定AIOps可以填补哪些空白，并确保AIOps过程与现有系统顺利集成。选择AIOps平台：市场上有许多可用的AIOps平台。评估不同的选项，并选择一个与自己的目标和IT基础设施相匹配的平台。主要看一下自动故障分析、异常检测和机器学习算法等功能。识别数据源：AIOps平台需要大量数据才能有效运行。确定需要收集的数据源，例如日志文件、性能指标和配置数据。制定数据策略：确定如何收集、存储和管理AIOps所需的数据，包括数据保留策略、数据安全措施和数据访问控制。训练AIOps平台：在选择了AIOps平台和数据策略之后，你需要训练平台来识别IT基础设施中的模式和异常，包括将历史数据输入平台并调整算法以优化性能。与IT运营集成：最后，你需要将AIOps过程与IT运营集成，包括为事故管理、变更管理和资源配置设置工作流。</p><p>&nbsp;</p><p></p><h1>结论</h1><p></p><p>&nbsp;</p><p>总而言之，AIOps是一系列使用人工智能、机器学习和大数据分析来提高软件系统可靠性的技术和实践。AIOps能够降低认知负担、增强跨职能协作、减少停机时间、提高客户满意度和降低成本开销。这些好处可以通过自动化事故管理流程、提供对软件系统性能的实时可见性和优化资源分配来实现。</p><p>&nbsp;</p><p></p><p>&nbsp;</p><p>原文链接：</p><p></p><p><a href=\"https://www.infoq.com/articles/aiops-reliability-engineering/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODY2MjUwNDMsImZpbGVHVUlEIjoieGs4NGU1bnVHdk1rck5BUCIsImlhdCI6MTY4NjYyNDc0MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0._e4RYU8-6gaSJPv8VvDp0NDfQpQvmbAZDiBi6HSZ3OY\">https://www.infoq.com/articles/aiops-reliability-engineering/</a>\"</p><p></p><p></p><h5>相关阅读：</h5><p></p><p></p><p><a href=\"https://xie.infoq.cn/article/5fa72696b20ee71513bab7a6a\">AIOps 还是 APM，企业用户应如何作出选择？</a>\"</p><p><a href=\"https://www.infoq.cn/article/x7ktpuN2B6N4odRsT8Zo\">AIOps 九大发展趋势</a>\"</p><p><a href=\"https://xie.infoq.cn/article/f135f07fbbf1a50f461ea7413\">值得一看的智能运维 AIOps 关键核心技术概览！</a>\"</p><p><a href=\"https://www.infoq.cn/article/2ztCijlOBIZ51I7X6tg6\">强化企业 IT 运维的五大 AIOps 策略</a>\"</p>",
    "publish_time": "2023-06-20 15:13:43",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "LangChain：2023年最潮大语言模型Web开发框架",
    "url": "https://www.infoq.cn/article/yl8eJoSfkHbOCyFzCcgw",
    "summary": "<p>LangChain是一个帮助在应用程序中使用大型语言模型（LLM）的编程框架。与生成式AI中的所有东西一样，这个项目的发展也非常迅速。2022年10月，它先是作为一款Python工具，然后在今年2月增加了对TypeScript的支持。到今年4月，它支持多种JavaScript环境，包括Node.js、浏览器、Cloudflare Workers、Vercel/Next.js、Deno和Supabase Edge Functions。</p><p>&nbsp;</p><p>那么，对于JavaScript开发者来说，他们需要了解有关LangChain的哪些方面以及如何使用LLM？在本文中，我们将通过分析LangChain作者Harrison Chase最近的两次演讲来回答这个问题。</p><p>&nbsp;</p><p>LangChain最初是一个开源项目，在GitHub上获得大量关注之后迅速转变为一家初创公司。2017年，Harrison Chase还在哈佛上大学，如今已是硅谷的一家热门初创公司的CEO，这对他来说是一次重大而迅速的跃迁。早些时候，微软首席技术官Kevin Scott在他的Build主题演讲中对Chase大加赞赏。</p><p>&nbsp;</p><p></p><h1>Chat App的风靡</h1><p></p><p>&nbsp;</p><p>不出所料，LangChain目前的主要应用是在LLM（尤其是ChatGPT）之上构建基于聊天的应用程序。正如Tyler McGinnis在bytes.dev上对LangChain调侃的那样：“聊天接口再多都不为过。”</p><p>&nbsp;</p><p>在今年早些时候的一次采访中，Chase说目前LangChain最好的一个应用场景是“基于文档的聊天”。LangChain也提供了其他功能来增强聊天体验，比如流——也就是可以逐个返回LLM输出的单词，而不是一次返回所有内容。</p><p>&nbsp;</p><p>不过Chase也指出，其他类型的接口也在迅速发展。</p><p>&nbsp;</p><p>“从长远来看，可能会有比聊天应用更好的体验。但我认为，就目前而言，这是我们不需要做很多额外工作就能够迅速起步的一种方式。我们能说聊天应用在这半年内就一定是最好的体验吗？可能不能，但我认为目前能够带来价值的东西很可能就是聊天应用。”</p><p>&nbsp;</p><p>毕竟基于LLM开发应用程序是一项新技术，这个领域的初创公司（比如LangChain）一直都在努力推出一些工具来帮助了解与LLM相关的问题。以提示词工程为例，它仍然主要依赖开发者的直觉来判断哪个提示词会更好。不过，LangChain今年引入了“追踪”等功能来帮助解决这个问题。</p><p>&nbsp;</p><p></p><h1>代理</h1><p></p><p>&nbsp;</p><p>LangChain最近引入的一个特性是“定制代理”，Chase在今年4月于旧金山举行的LLM训练营上提到了这个。他将代理定义为一种“使用语言模型作为推理引擎”来确定如何根据用户输入与外部世界发生交互的方式。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d6/d6e3242fd9f5a36faed204c1921ddeec.png\" /></p><p></p><p>Harrison Chase在LLM训练营上</p><p>&nbsp;</p><p>他举了一个与SQL数据库发生交互的例子。他说，通常我们会使用自然语言查询和将其转换为SQL查询的语言模型。我们执行查询，并将结果传给语言模型，要求它根据原始问题对其进行综合，最终得到Chase所说的“基于SQL数据库的自然语言包装器”。</p><p>&nbsp;</p><p>代理的作用是处理Chase所说的“边缘情况”，也就是LLM在上述示例中任何时候都可能出现的模糊输出。</p><p>&nbsp;</p><p>他说：“你可以通过代理来选择要使用的工具和针对工具的输入。然后你执行它，得到结果，再把结果反馈到语言模型中。然后继续这样做，直到满足停止条件。”</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/64/640cdd3a5661c57a50deb49e292850ac.png\" /></p><p></p><p>实现代理</p><p>&nbsp;</p><p>我们把代理称为“ReAct”，这与JavaScript框架React没有任何关系，“ReAct”是指“Reason + Act”。Chase表示，与其他形式的提示词工程相比，这种方法能产生“更高质量、更可靠的结果”。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/01f96f4df66deb562cef2b3da65c7ab7.png\" /></p><p></p><p>ReAct（并非React）</p><p>&nbsp;</p><p>Chase承认，代理也存在“很多挑战”，而且“大多数代理目前还没有做好生产就绪的准备。”</p><p>&nbsp;</p><p></p><h1>记忆问题</h1><p></p><p>&nbsp;</p><p>他列出的一些问题似乎都是基础的计算机问题，但在LLM中，它们更具挑战性。例如，LLM通常没有长期记忆。正如Pinecone教程中所指出的，“默认情况下，LLM是无状态的——这意味着每一个查询的处理都是独立于其他查询进行的。”</p><p>&nbsp;</p><p>LangChain在这方面为开发者提供了帮助，它将记忆等组件添加到LLM的处理过程中。实际上，对于JavaScript和TypeScript，LangChain提供了两个与记忆相关的方法：loadMemoryVariables和saveContext。第一个方法“用于从内存中检索数据（也可使用当前输入值），第二个方法用于在内存中保存数据”。</p><p>&nbsp;</p><p>Chase提到的另一种形式的代理是Auto-GPT，一种可以配置和部署自主AI代理的程序。</p><p>&nbsp;</p><p>他说：“Auto-GPT为代理和工具之间的交互提供了长期记忆，并使用检索向量作为存储（向量数据库）。”</p><p>&nbsp;</p><p></p><h1>新的LAMP技术栈？</h1><p></p><p>&nbsp;</p><p>显然，构建基于LLM的应用程序还有很多事情要做。在Build主题演讲中，微软将LangChain作为其“Copilot技术栈”的“编排”层的一部分。在微软的系统中，编排包括提示词工程和所谓的“元提示词（Meta Prompt）”。</p><p>&nbsp;</p><p>微软推出了自己的工具Semantic Kernel，功能与LangChain类似。微软还发布了一个叫作Prompt Flow的工具，微软首席技术官Kevin Scott称其为“另一种整合了LangChain和Semantic Kernel的编排机制”。</p><p>&nbsp;</p><p>需要注意的是，LangChain中的“Chain”表明它可以与其他工具互操作——不仅是各种LLM，还有其他开发框架。今年5月，Cloudflare宣布其Workers框架支持LangChain。</p><p>&nbsp;</p><p>甚至还出现了一个关于LangChain的缩略词：OPL，即OpenAI、Pinecone和LangChain。它的灵感可能来自LAMP（Linux、Apache、MySQL、PHP/Perl/Python），20世纪90年代的一个关键技术栈，Web 2.0的推动器。我们不知道OPL会不会成为一个技术术语——当然，它的组件并不都是开源的——但无论如何，这是一个好迹象，表明LangChain已经成为许多开发者个人技术栈的重要组成部分。</p><p>&nbsp;</p><p></p><h5>原文链接：</h5><p></p><p></p><p><a href=\"https://thenewstack.io/langchain-the-trendiest-web-framework-of-2023-thanks-to-ai/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODY2MjU1MjQsImZpbGVHVUlEIjoiOXB0b0FYczVQYklaakpwcyIsImlhdCI6MTY4NjYyNTIyNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.u_ktP9GD-NgR4OkoV22MjV2tYizsezmcg2VuLsxNZxA\">https://thenewstack.io/langchain-the-trendiest-web-framework-of-2023-thanks-to-ai/</a>\"</p><p></p><p></p><h5>相关阅读：</h5><p></p><p></p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MjM5ODIzNDQ3Mw==&amp;mid=2649969927&amp;idx=1&amp;sn=cc8a7cee992d36202d86ee5068fcc66e&amp;chksm=beca250189bdac17511f9649f03ab3b0c6fee72a33cb1957ff5a6017924fe10b7c7d5581eb98&amp;scene=27#wechat_redirect\">Web3当下，最佳投资就是投资自己</a>\"</p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MjM5ODIzNDQ3Mw==&amp;mid=2649969873&amp;idx=1&amp;sn=8cc0a44a1ab3255ea5973d41520a4c39&amp;chksm=beca24d789bdadc1f9085e3853dffff525aaa28a09a46c50169585b66650a1ac26ae67db9b57&amp;scene=27#wechat_redirect\">Web3的反思，不要抱怨</a>\"</p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MjM5ODIzNDQ3Mw==&amp;mid=2649970108&amp;idx=1&amp;sn=25f73abae444b3b0107873e5764ee068&amp;chksm=beca25ba89bdacacdc16a5def20ec892652e302c1119efbb6476f94d8570c6570a060065a2b0&amp;scene=27#wechat_redirect\">给Web3创业者的28个原则</a>\"</p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MjM5ODIzNDQ3Mw==&amp;mid=2649970054&amp;idx=1&amp;sn=1ccf271b4aea088d3beb777536ba2033&amp;chksm=beca258089bdac967b59fb03eaca2104a6038e99ff8483831976281428e80b4284add474346d&amp;scene=27#wechat_redirect\">和我一起学习Web3</a>\"</p>",
    "publish_time": "2023-06-20 15:13:46",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "架构师（2023 年 6 月）",
    "url": "https://www.infoq.cn/article/p2Glwcmf7h538NykMhbC",
    "summary": "<p>“用 Rust 重写”正流行。</p><p></p><p>一直以来，在 Windows 内核中的主要语言是 C，内核之外的大部分代码是 C++。但在最新的 Windows 11 Insider Preview 版本中，微软纳入了内存安全编程语言 Rust，这无疑又添了一把火。还有个人开发者用 Rust 写了类似 Kubernetes 的应用。</p><p></p><p>但同时也有开发者指出，单纯用 Rust 重写大型 C/C++ 系统组件只会引入额外的攻击面：新组件和现有代码间的外部函数接口（FFI）。在一些情况下，“安全”Rust 函数其实比原本的“不安全”C 函数更糟糕。</p><p></p><p>Rust 还是 C/C++，似乎是个问题：Rust 使用相似的语法并且可用于许多与 C++ 相同的任务，但 C++ 拥有更大的社区、更广泛的用例、更多的框架，并且得到了很多公司的认可。而由于其静态类型特性，Rust 在安全性、编写速度和防止不正确/不安全的代码方面更好。</p><p></p><p>近日，在黑客新闻上有关于选择Rust 还是 C 或 C++的讨论。</p><p></p><p>“我会选择 Rust，因为它相比 C 更符合开发者的‘人体工程学’。即使是像标准 linter 和包管理器 (Cargo) 这样的小东西，在编写惯用代码方面也大有帮助。”有开发者表示。</p><p></p><p>“C 是永远的选择。它是社区希望尽早制定规范的唯一语言，这使 C 掌握在程序员手中，而不是编译器创建者手中。”也有开发者说道。</p><p></p><p>还有“端水”的开发者说道，“把 C 学得足够好来解决 C++ 和 Rust 试图解决的痛点，C 简单但并不容易；再学习足够多的 Rust 以提高工作效率；然后学习足够的 C++ 以便与现有的大量 C++ 代码进行交互。”</p><p></p><p>作为一名开发者，你更支持哪种语言呢？</p><p></p><p>目录</p><p></p><p>热点 | Hot</p><p></p><p>纪念陈皓（左耳朵耗子）</p><p></p><p>微软 Bing Chat 全面开放，所有人可用！官宣多项重大升级，日活用户超过 1 亿</p><p></p><p>比 Python 快 35000 倍！LLVM&amp;Swift 之父宣布全新编程语言 Mojo：编程被颠覆了</p><p></p><p>从微服务转为单体架构、成本降低 90%，亚马逊内部案例引发轰动！</p><p></p><p>“TypeScript 不值得！”前端框架 Svelte 作者宣布重构代码，反向迁移到 JavaScript 引争议</p><p></p><p>访谈文章 | Interview</p><p></p><p>一个价值 70 亿美元的教训！如何避免平台工程变成“大灾难”？</p><p></p><p>云原生网关当道，三大主流厂商如何“竞技”？</p><p></p><p>案例研究 | Case Study</p><p></p><p>喜马拉雅 KV 存储演进之路</p><p></p><p>通用电气在平台工程上浪费 70 亿美元的教训</p><p></p><p>天眼查基于 Apache Doris 构建统一实时数仓实践</p><p></p><p>平安开放银行模式探索实践：从物联网金融到开放联盟</p><p></p><p>推荐文章 | Article</p><p></p><p>探索 OpenAI 平台架构</p><p></p><p>花 8 年转型微服务却得不到回报，问题出在哪儿？</p><p></p><p>云原生时代，如何建设稳定性可观测体系？</p><p></p><p>不谈技术了，聊聊车企研发效能和文化冲突问题怎么解</p><p></p><p>特别专题｜eBPF 探索与应用：如何掀起平台革命</p><p></p><p>从石器时代到成为“神”，一文讲透 eBPF 技术发展演进史</p><p></p><p>颠覆传统、应用大爆发，eBPF 何以改变 Linux？</p><p></p><p>无声的平台革命：eBPF 是如何从根本上改造云原生平台的</p><p></p><p>网易伏羲私有云基于 eBPF 的云原生网络可观测性探索与实践</p><p></p><p>特别专栏 | Video</p><p></p><p>本月，这些视频值得一看！</p><p></p><p>识别下图二维码，立即获得大语言模型</p><p><img src=\"https://static001.infoq.cn/resource/image/48/f7/48f87132b23fe3d1470e8c0c52a32cf7.jpg\" /></p><p></p>",
    "publish_time": "2023-06-20 15:38:42",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "谷歌警告自家员工：不要使用 Bard 生成的代码",
    "url": "https://www.infoq.cn/article/fQ8jWsJd2ZC4WRWQKC50",
    "summary": "<p></p><p>根据路透社消息，谷歌警告员工不要泄露机密信息或使用其 AI 聊天机器人生成的代码，包括自己正在全球推广的 <a href=\"https://www.infoq.cn/article/z30mE0bxrvItO9Mm52Nw\">Bard</a>\"。</p><p></p><p>知情人士称，谷歌母公司Alphabet 已建议员工不要将机密材料输入人工智能聊天机器人，该公司援引了长期保护信息政策。<a href=\"https://arxiv.org/pdf/2012.07805.pdf\">研究人员发现</a>\" AI 可以重现它在训练期间吸收的数据，从而造成泄漏风险。</p><p>&nbsp;</p><p>还有知情人士透露，Alphabet 提醒其工程师避免直接使用聊天机器人生成的计算机代码。该公司表示 Bard 会提出不受欢迎的代码建议。问题是可能导致错误程序或复杂、臃肿的软件。与根本不使用 AI 进行编码相比，开发人员将花费更多时间来修复这些问题。</p><p>&nbsp;</p><p><a href=\"https://www.businessinsider.com/google-ai-chatbot-bard-chatgpt-2023-2\">据Insider 报道</a>\"，到 2 月，谷歌告诉测试 Bard 的工作人员在发布前不要向 Bard 提供内部信息。现在谷歌将 Bard 推广到 180 多个国家和 40 种语言。</p><p>&nbsp;</p><p>如今，告诫自己的员工不要直接使用 Bard 生成的代码一事，打破了谷歌声称其聊天机器人可以帮助开发人员提高工作效率的说法。创建者自己由于隐私和安全风险都不使用的话，其他人该怎么相信并使用呢？</p><p>&nbsp;</p><p>前不久，谷歌准备在欧盟地区推出Bard，但是由于欧盟隐私数据监管机构提出质疑，谷歌被迫将发布日期向后推迟。爱尔兰数据保护委员会近日指出，谷歌并没有明确说明Bard服务将如何遵守欧盟地区的隐私数据保护规定。</p><p></p><p>参考链接：</p><p>https://www.reuters.com/technology/google-one-ais-biggest-backers-warns-own-staff-about-chatbots-2023-06-15/</p>",
    "publish_time": "2023-06-20 15:39:44",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "杨亦胜确认出席 ArchSummit 深圳，将分享《华为云交易平台 Ops 可观测实践》话题",
    "url": "https://www.infoq.cn/article/NrzjjsUEqSTPhqfVB3dr",
    "summary": "<p>7&nbsp;月&nbsp;21&nbsp;日&nbsp;-&nbsp;22&nbsp;日，&nbsp;在&nbsp;<a href=\"https://archsummit.infoq.cn/2023/shenzhen?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">ArchSummit&nbsp;全球架构师峰会（深圳站）</a>\"，华为云高级技术专家、研发主管杨亦胜，将于会上发表题为《华为云交易平台Ops可观测实践》的演讲，详细介绍华为云交易系统架构和监控体系及其面临的问题和挑战，分享华为云交易平台&nbsp;Ops&nbsp;可观测实践经验。</p><p></p><p>杨亦胜从&nbsp;0&nbsp;到&nbsp;1&nbsp;参与构建了华为云交易系统平台，拥有&nbsp;8&nbsp;年&nbsp;DevOps&nbsp;实践经验，熟悉业界云原生相关技能，微服务相关技术，以及云产品技术。</p><p></p><p>相信通过杨亦胜的分享，你将了解到&nbsp;Ops&nbsp;可观测实践的具体步骤和&nbsp;AI&nbsp;Ops&nbsp;高效运维的过程。</p><p></p><p>除上述议题外&nbsp;，ArchSummit&nbsp;深圳还将围绕<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1537?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">基础架构技术</a>\"、<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1532?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">DataOps、Data&nbsp;Fabric&nbsp;等高效数据开发与服务模式</a>\"、<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1534?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">Mesh&nbsp;技术实践案例</a>\"、<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1535?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">QUIC&nbsp;传输和架构优化</a>\"等进行分享。</p><p></p><p>数十位业界专家，上百个国内外一线大厂前沿技术案例，一定会给你带来很多全新的开发灵感。期待与你线下交流！&nbsp;现在购票，享&nbsp;9&nbsp;折特惠，立省&nbsp;¥880！咨询购票请联系&nbsp;18514549229（微信同手机号）</p><p><img src=\"https://static001.infoq.cn/resource/image/9d/aa/9d6a27547062ee2e089f91bdc4ba1eaa.png\" /></p><p></p>",
    "publish_time": "2023-06-20 16:19:41",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "中国开源生态图谱 2023",
    "url": "https://www.infoq.cn/article/Tv9grBa64Q3LjDDIRGKt",
    "summary": "<p></p><h3>研究背景</h3><p></p><p>近些年，代表着合作与创新的开源在国内热度居高不下，同时国内开源项目也逐渐走向国际。而开源领域一直是 InfoQ 研究中心关注的重点领域之一。2022 年 8 月，InfoQ 研究中心推出《中国开源发展研究分析 2022》。报告中分析了中国开源的宏观发展背景、现有成绩和整体发展特征，同时还推出了 InfoQ 开源项目指数，并聚焦研究了中国 TOP100 开源项目。</p><p></p><p>2022 年 12 月，InfoQ 研究中心启动了《中国开源生态图谱系列研究》工作。截至目前，InfoQ 研究中心已经发布了操作系统、数据库、人工智能、云原生四大领域的开源生态图谱报告，并完成了对于大数据、前端和中间件领域的开源项目数据研究工作。</p><p></p><p>现在，2023 年 4 月，基于之前的研究成果，InfoQ 研究中心希望通过《中国开源生态图谱 2023》的发布，以中国开源项目名录和图谱的形式，为中国开源领域提供便捷易用的工具，让国内开发者、企业、研究院、基金会等开源生态了解中国开源的项目现状，并为中国开源产品添砖加瓦。</p><p></p><p>《中国开源生态图谱 2023》内共计收录了 931 个中国开源项目，涵盖七大细分领域和生态机构，其中七大细分领域分别为操作系统、数据库、人工智能、云原生、大数据、前端、中间件，生态机构包括实验室/研究院、开源基金会、开源产业联盟、开发者社区和代码托管平台。</p><p></p><h3>目录</h3><p></p><p>中国开源生态图谱中国各技术领域生态图谱中国开源项目数据解读中国开源企业和机构名录</p><p></p><h3>中国开源生态图谱</h3><p></p><p><img src=\"https://static001.infoq.cn/resource/image/ba/37/ba7893a30d92e13c03181182fcfcc937.png\" /></p><p></p><h3>中国企业开源贡献 Top10</h3><p></p><p><img src=\"https://static001.infoq.cn/resource/image/f0/8d/f01efa4fc421da286194a204e3855f8d.png\" /></p><p></p><h3>中国 Github Top100 开源项目列表</h3><p></p><p><img src=\"https://static001.infoq.cn/resource/image/f4/c6/f445e5af6cf86a7f5c85f202cd47b1c6.png\" /></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/3e/cb/3e994ae9f00dd0052a483e9fd8cf9fcb.png\" /></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/78/59/787bbyy7b9e3942c1a98368eb1b8ca59.png\" /></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/05/cc/05506201d20857192b80efdbf70537cc.png\" /></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/c0/80/c009388360447a968fee349ce3c8f780.png\" /></p><p></p><h3>联合发布机构（按拼音字母顺序排列）</h3><p></p><p>北京开源创新委员会开源社华为开源腾讯开源联盟OpenI 启智社区字节开源</p><p></p><p>识别下图二维码，立即获得《中国开源生态图谱 2023》</p><p><img src=\"https://static001.infoq.cn/resource/image/a7/c3/a7914c06daa52286d40f6f2a55a7c5c3.jpg\" /></p><p></p>",
    "publish_time": "2023-06-20 17:12:17",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "这将是一场灾难？37年历史的PostgreSQL数据库将进行重大架构变更",
    "url": "https://www.infoq.cn/article/VVCTQbCV1rKcZoMD3TKR",
    "summary": "<p>在瞬息万变的开源世界中，软件项目来得快、去得也快。如今获得广泛追捧的工具，很可能在短时间后就被更好的成果取代，再也无人问津。但即使在这样残酷的环境下，也有不少项目能够长期保持生命力。</p><p>&nbsp;</p><p>PostgreSQL数据库系统就是其中的典型，其历史可以追溯到1986年的伯克利POSTGRES项目。经过几十年的发展，作为一款跨平台、免费和开源的数据库软件，PostgreSQL应用已经相当广泛：根据Stack Overflow 2023开发者调查数据显示，PostgreSQL甚至超越了MySQL，成为开发人员首选。</p><p>&nbsp;</p><p>对拥有如此悠久历史的大型代码库做根本性变更绝非易事，但项目开发团队正在认真考虑这种可能性，希望让PostgreSQL脱离长久以来的面向进程模型。</p><p>&nbsp;</p><p>任何PostgreSQL实例都是以大量协作进程的形式保持运行，其中包含一个用于所有接入客户端的进程。这些进程使用精心设计的库通过多个共享内存区域进行彼此通信，而这个库的作用就是在内存设置各异、映射地址不同的所有进程之间建立起复杂的数据结构。</p><p>&nbsp;</p><p>多年以来，这套模型一直兢兢业业地支撑整个项目。但随着项目发展，现实世界正在发生巨大变化。因此，PostgreSQL开发团队意识到必须尽快调整、顺应现实的潮流。</p><p></p><h4>一份提案</h4><p></p><p>今年6月初，Heikki&nbsp;Linnakangas在经过一系列线下讨论之后，发布了将PostgreSQL转为线程模型的提案。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3f/3f2f15c3c77de8b933aa3e452f2323b9.jpeg\" /></p><p></p><p>&nbsp;</p><p></p><blockquote>我觉得现在大家已经达成了强烈共识，比以往任何时候都更支持这项重大调整。实现这个目标需要投入大量精力、讨论很多细节，但团队高层对这个基本思路没有异议。&nbsp;这封电子邮件的发布，就是想把这种沉默的共识变成明确的发展路线。</blockquote><p></p><p>&nbsp;</p><p>其中简要概括了这项迁移所涉及的种种挑战，并低调地承认转化过程“肯定无法通过单一版本彻底完成”。但邮件中没有提到推动这项重大变更的原因，好在随着讨论的进行，相关信息很快得到了补充。正如Andres Freund（PostgreSQL Developer &amp; Committer，EnterpriseDB 高级数据库架构师）指出的那样：</p><p>&nbsp;</p><p></p><blockquote>我认为原有流程模型开始产生诸多限制，这个问题在大型设备上体现得尤其明显。跨进程上下文切换所带来的开销，原本就比在同一进程内的不同线程间切换要更高——我估计这种开销还将持续提升。面对大量连接，整个体系最终一定会因TLB未命中而浪费*大量*时间。这是进程模型无法跨进程共享TLB的天然属性造成的必然结果。</blockquote><p></p><p>&nbsp;</p><p>他还提到，进程模型也增加了开发成本，迫使项目不得不维护大量重复代码，包括在同一地址空间内保留本不必要的多种内存管理机制。在随后的消息中，他还补充称由于线程全部运行在同一地址空间之内，因此可以更高效地实现状态共享。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0d/0dde2702389bc40f24ddad6a317ea90d.jpeg\" /></p><p></p><p>&nbsp;</p><p>但有部分开发人员反映，Linnakangas所说的“强烈共识”可能并没有那么强烈。<a href=\"https://medium.com/i-m-h-o/the-people-of-postgres-tom-lane-b6f105889466\">Postgres 的主要贡献者</a>\"Tom Lane表示，“我认为这将是一场灾难，大量原有代码将受到影响。”他随后补充称，此次调整将带来“巨大”成本，产生“不止一个安全级bug”，也无法证明其收益超过成本投入。有人提出，目前还有其他一些高优先级工作值得早做打算。也有人担心随着进程模型被淘汰，原本基于各独立进程的隔离性将被打破，导致系统的整体健壮性受到破坏。</p><p>&nbsp;</p><p>尽管如此，大部分PostgreSQL开发者还是以谨慎乐观的态度支持、至少愿意尝试这一改动。EnterpriseDB 副总裁、首席数据库科学家，PostgreSQL主要贡献者Robert Haas表示，PostgreSQL在大型系统上的扩展性确实不佳，主要就是因为所有进程都在消耗资源。“其他很多数据库并不存在这个问题。如果不进行某种重大的架构变更，PostgreSQL将无法克服这个难题。”</p><p>&nbsp;</p><p>也许单纯转向线程模型可能还不够，但他认为这将为其他后续改进开个好头。</p><p></p><h4>从提案到现实</h4><p></p><p>将PostgreSQL服务器的核心转移至单一地址空间，几乎必然带来诸多挑战。正如Haas等研究人员所指出，其中最大的问题就是服务器“目前正频繁使用全局变量”。具体来讲，当每个服务器进程都拥有自己的集合时，全局变量就能良好运作；而在用线程加以替代时则会引发问题。根据Konstantin Knizhnik的说法，PostgreSQL服务器目前使用约2000个全局变量。</p><p>&nbsp;</p><p>开发团队随后讨论了该问题的几种解决思路。首先是将所有全局变量拉入统一的“会话状态”结构，而这套结构具备线程本地化属性。但考虑到需要创建并维护的是需要容纳2000个变量成员的复杂结构时，这个提议因为可行性太低而很快失去了吸引力。另一种方法是直接把所有全局变量放入线程本地存储内，这种方法倒是简单可行，但大量使用线程本地存储会导致性能损失，损耗转为线程模型带来的收益。Haas指出，对全局变量做明确标记（包括将其放入线程本地存储）本身也有积极的意义，可说为减少全局变量的使用开了个好头。Freund赞同这个观点，并表示即使后续没有全面转向线程模型，这项调整也将有所回报。</p><p>&nbsp;</p><p>但Freund也警告称，将全局变量转移至线程本地存储只是这项工作中最简单的部分：</p><p>&nbsp;</p><p></p><blockquote>在此之后，重新设计postmaster、定义如何处理扩展库、扩展兼容性、开发工具以实现线程化postgres、在会话生命周期内建立新的内存分配和释放机制（以往是通过退出进程实现内存释放）、保证变更的可审查性和可移植性等等，全都是更加困难的工作。</blockquote><p></p><p>&nbsp;</p><p>这里还有一个讨论热度不高、但却非常有趣的观点，即Knizhnik已经完成了PostgreSQL的线程端口。他说全局变量的问题并不是那么难以解决。他在配置数据、错误处理、信号等方面遇到的麻烦还更多。另外，支持由外部维护的扩展也是个重大挑战。可尽管如此，他还是认可转向线程模型所带来的一系列显著回报，只是提醒项目决策层在采取任何行动之前，务必要认真做好研究分析。</p><p>&nbsp;</p><p>PostgreSQL开发团队还想到了另一个复杂问题，即是否可能同时支持基于进程和基于线程两种模式。在继续支持进程模式的同时引入线程架构不仅极为困难，而且会显著增加项目的总体维护负担。但Haas坚持认为，PostgreSQL绝对不可能彻底放弃对进程模式的支持。毕竟线程在一部分用例中的性能反而更差，也有不少重要扩展无法在线程模式下正常运行。他强调称，只有在确认线程架构运行良好之后，才可能认真讨论要不要彻底放弃进程支持。</p><p>&nbsp;</p><p>目前无论是从邮件讨论还是从社交媒体平台投票结果来看，大多数PostgreSQL开发者认同架构转换的理论收益。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/68/68089e79f82d51e3d858ee5dd134247d.jpeg\" /></p><p></p><p>&nbsp;</p><p>并且，数据库管理系统Peloton早在2015年就已经尝试让PostgreSQL多线程化了。至于PostgreSQL本身，从讨论到具体实施落地还有很长的路要走，更重要的是，需要有人主动请缨、表示愿意投入时间来推进这项工作。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/39/396ad8340d81dce77e8c1397753149e1.jpeg\" /></p><p></p><p>&nbsp;</p><p>Peloton的《Postgres架构变更公告》：</p><p></p><blockquote>最初，Postgres采用的是多进程架构。其中主进程名为Postmaster，负责处理Postgres接收到的请求，以及启动、关闭等系统层面的操作。请注意，Postmaster本身并不执行这些操作，而会派生出子进程来执行操作。再有，处理用户查询的backend也是由Postmaster分叉而来。这种架构非常适合基于磁盘的数据库，因为磁盘可以作为大容量共享存储。由于peloton充当主内存数据库，多进程架构导致不同后端和peloton数据库间的信息共享变得极其困难。在早期的尝试中，我们曾考虑用共享内存让peloton从每个分叉的backend处获取查询计划和其他信息。但结果证明其性能慢得令人无法接受，因此我们最终决定将Postgres转为多线程架构！</blockquote><p></p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://news.ycombinator.com/item?id=36393030\">https://news.ycombinator.com/item?id=36393030</a>\"</p><p><a href=\"https://lwn.net/SubscriberLink/934940/3abb2d4086680b78/\">https://lwn.net/SubscriberLink/934940/3abb2d4086680b78/</a>\"</p><p><a href=\"https://github.com/cmu-db/peloton/wiki/Postgres-Modifications\">https://github.com/cmu-db/peloton/wiki/Postgres-Modifications</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651134324&amp;idx=5&amp;sn=846912161d3ce1fa4a124ad3effc3b57&amp;chksm=bdb8e1278acf683154b4cee7fe6ada0182cd6c8b95b1469c320a39c91a3f35192e66e1022bf0&amp;scene=27#wechat_redirect\">PostgreSQL 2022 调查结果发布：全球排名第四的背后是开源的力量</a>\"</p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MzIzNjUxMzk2NQ==&amp;mid=2247484045&amp;idx=1&amp;sn=3edee238b0b541f5794d7167f4b46f45&amp;chksm=e8d7fd4fdfa07459a0514e4997c4ee56171c919903ec44a3e263429f417165b227715dd9971a&amp;scene=27#wechat_redirect\">MySQL向左，PostgreSQL向右：平安科技在金融应用的技术选型</a>\"</p><p><a href=\"https://xie.infoq.cn/article/b0a3739a76c473a0d6dac6ca4\">PostgreSQL：进程结构</a>\"</p>",
    "publish_time": "2023-06-20 17:28:50",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "深度培训｜手把手教你在开源基础上构建私有大模型和知识库",
    "url": "https://www.infoq.cn/article/NhVzPOD68M4rLeiiz2vV",
    "summary": "<p>经过和大量的企业同行交流，收集大家的需求点，我们发现很多企业都对于利用开源的模型构建私有的模型，并利用大型语言模型构建私有知识应用，将企业的私有知识进行有效的萃取及使用很感兴趣。</p><p></p><p>于是在今年的 7 月和 8 月，我们在北京和上海分别策划了线下深度培训，邀请业界资深专家陈旸博士，和范煜来分享如何动手构建大模型并使用大模型开发应用。</p><p></p><p>此外，在 <a href=\"https://archsummit.infoq.cn/2023/shenzhen/track?utm_source=infoqweb&amp;utm_medium=article&amp;utm_campaign=8&amp;utm_term=0620\">7 月深圳站 ArchSummit</a>\" 会后，也将召开一场深度培训，特别邀请了去哪儿网王植萌、京东金融康阳分别从领域驱动设计和系统高可用性方面，深度解读这些技术从设计到落地的细节。</p><p></p><p></p><h4>培训主题一：基于大模型的私有知识应用开发</h4><p></p><p>陈旸 博士：阿里云 MVP，数字化转型专家。清华大学计算机博士，阿里云 MVP，腾讯云 TVP，百度 AI 比赛教练，百度 PPDE，数字化转型专家，著有《数据分析实战》《SQL 必知必会》《AIGC 行动营》</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cf/cfa244e56b93ba0b6b35c2777d912202.png\" /></p><p></p><p><a href=\"https://archsummit.infoq.cn/2023/shenzhen/training/5349?utm_source=infoqweb&amp;utm_medium=article&amp;utm_campaign=8&amp;utm_term=0620\">本工作坊</a>\"旨在帮助您掌握利用大型语言模型构建私有知识应用，将企业的私有知识进行有效的萃取及利用。共同探索大模型的潜力，并掌握如何开发个性化、安全性强的企业内部私有知识应用。</p><p></p><p>培训的提纲包括搭建私有化大模型、LangChain 开发、企业私有知识问答系统，除此之外，还会有动手实操部分，使用 LangChain 搭建本地知识智能客服，包括企业私有知识问答系统、数据解析与切分、向量数据库使用、LangChain+ChatGLM、WebUI 搭建。</p><p></p><p></p><h4>培训主题二：基于开源大模型，如何一步一步自己搭建一个自己的私有模型</h4><p></p><p>范煜老师是中国商业联合会数据分析专业委员专家，主要培训方向为大数据及 AI 领域的全场景培训。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0a/0a2dd19d4a0142063b5146f63d2d10e2.png\" /></p><p></p><p><a href=\"https://archsummit.infoq.cn/2023/shenzhen/training/5353?utm_source=infoqweb&amp;utm_medium=article&amp;utm_campaign=8&amp;utm_term=0620\">本课程</a>\"从技术和实战角度介绍了类 ChatGPT 私有模型开发过程，涉及现有的预训练模型的增量训练、指令微调、中文支持、推理模型部署、数据集格式等，一步一步指导你搭建一个自己的私有模型。</p><p></p><p>在培训的过程中，首先是搭建你自己的私有大模型，训练你自己的私有大模型，同时还会在服务器开发环境安装 LLM 权重文件，SFT 训练，模型推理服务部署。</p><p></p><p>这样的培训，可以解决企业场景应用问题，例如构建企业内部知识智能客服、开发私有知识问答系统等。将所学应用于实际工作场景中，提升工作效率和解决业务挑战。</p><p></p><p></p><h4>培训主题三：基于因果一致性的低代码交易平台</h4><p></p><p>康杨老师是京东科技金融科技群 / 架构师，目前整体负责京东支付 PaaS 化改造工作。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6a/6a8fd1bc59286851e343a8a9ba44bfd8.png\" /></p><p></p><p>在全球供应链整合和云原生、数字化转型的背景下，金融系统也在经历一场重大的历史变革，业务爆发式增⻓，包括用户数量、业务维度、系统复杂度、系统质量要求等多维问题同时出现下，如何利用更先进的企业架构等技术进行企业的数字化转型，实现业务复杂度与技术复杂度的分离，以更好支撑业务的发展，并挖掘技术 &amp; 数据的价值，更好的赋能客户。</p><p></p><p>通过<a href=\"https://archsummit.infoq.cn/2023/shenzhen/training/5346?utm_source=infoqweb&amp;utm_medium=article&amp;utm_campaign=8&amp;utm_term=0620\">本次分享</a>\"，将通过第一性原理揭示分布式系统的时空本质，以及金融级核心系统的业务本质和建模方法，介绍支持百亿交易的账务系统所面临的挑战和应对之道。</p><p></p><p></p><h4>培训主题四：领域驱动设计动手实操</h4><p></p><p>王植萌是去哪儿网高级技术总监，2013 年 5 月 8 日加入去哪儿网，目前是去哪儿网技术委员会主席，基础研发团队负责人。主要的研究方向包括：业务架构、DDD 落地实践、技术驱动业务、技术团队管理。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c6/c685916d0057a9f36e0a972be7a8084d.png\" /></p><p></p><p><a href=\"https://archsummit.infoq.cn/2023/shenzhen/training/5345?utm_source=infoqweb&amp;utm_medium=article&amp;utm_campaign=8&amp;utm_term=0620\">这次培训</a>\"，会结合之前 DDD 在去哪儿网落地的成功经验，基于 DDD 思想，从业务诉求，到问题域拆解，再到问题域到解决域过渡，并进行的实际落地过程，重点介绍领域架构设计过程及落地经验。</p><p></p><p>课程重点讲 DDD 落地实践过程：1. 战略设计过程；2. 战术设计过程；3.COLA 四层架构应用；4. 领域版本化建设。学员们在学到 DDD 全面落地后，知道如何使用领域版本化的方法承接公司战略。</p><p></p><p>扫码或<a href=\"https://archsummit.infoq.cn/2023/shenzhen/training?utm_source=infoqweb&amp;utm_medium=article&amp;utm_campaign=8&amp;utm_term=0620\">戳此查看培训日程</a>\"。如果你对某个培训主题感兴趣，或对于培训地点，培训形式有任何疑问，可以直接与票务经理联系：18514549229（微信同手机号）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/38/38b080c55e530f16d261d9b106555f3a.png\" /></p><p></p>",
    "publish_time": "2023-06-20 18:37:59",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]