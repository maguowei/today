[
  {
    "title": "亚马逊ElastiCache支持Redis 7，新特性包括Redis函数、ACL改进和分片的Pub/Sub",
    "url": "https://www.infoq.cn/article/kKNlx6vydEQE2SFJ4v3P",
    "summary": "<p>最近，亚马逊云科技宣布Amazon ElastiCache for Redis兼容Redis 7。其中包含了一些新特性，如Redis函数、ACL的改进和分片的Pub/Sub。</p><p>&nbsp;</p><p><a href=\"https://aws.amazon.com/elasticache/redis/\">Amazon ElastiCache for Redis</a>\"是一个全托管的内存缓存服务，兼容<a href=\"https://redis.io/\">Redis</a>\"和<a href=\"https://memcached.org/\">Memcached</a>\"开源引擎。开发者可以通过该服务在游戏、广告技术、电子商务、医疗保健、金融服务和物联网领域为其互联网规模的实时应用提供动力。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/02/02822016f35b50d18483f4c51db7d848.png\" /></p><p></p><p>图片来源：<a href=\"https://aws.amazon.com/elasticache/redis/\">https://aws.amazon.com/elasticache/redis/</a>\"</p><p>&nbsp;</p><p>Amazon ElastiCache for Redis在<a href=\"https://www.infoq.com/news/2020/10/redis-6-amazon-elasticache/\">两年前支持Redis 6</a>\"，现在支持今年<a href=\"https://redis.com/blog/redis-7-generally-available/\">早些时候发布</a>\"的Redis 7。在AWS管理控制台中创建集群时，Amazon ElastiCache for Redis可以支持的Redis版本范围为3.4.2到7.0。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d1/d14a1c1478243c9bcf4ac761b5821505.png\" /></p><p></p><p>&nbsp;</p><p>与Redis 7兼容性相关的重要新特性有：</p><p>支持<a href=\"https://redis.io/docs/manual/programmability/functions-intro/\">Redis函数</a>\"，并提供了一种托管体验，开发人员可以使用存储在ElastiCache集群上的应用程序逻辑执行<a href=\"https://redis.io/docs/manual/programmability/eval-intro/\">Lua脚本</a>\"，客户端不需要在每次连接时都将脚本重新发送到服务器；支持下一个版本的<a href=\"https://redis.io/docs/management/security/acl/\">Redis访问控制列表</a>\"（ACL）。对于ElastiCache for Redis 7，客户端可以在Redis中的特定键或键空间上指定多组权限；在集群模式下运行ElastiCache时，为开发人员提供了以分片的方式运行<a href=\"https://redis.io/docs/manual/pubsub/#sharded-pubsub\">Redis Pub/Sub功能</a>\"的能力。此外，通道被绑定到ElastiCache集群中的一个分片上，不需要跨分片传播通道信息，从而提高了可伸缩性。</p><p>&nbsp;</p><p>Redis技术支持经理<a href=\"https://twitter.com/elena_kolevska\">Elena Kolevska</a>\"在Redis<a href=\"https://developer.redis.com/create/redis-functions/\">文档</a>\"中提到，Redis函数是Redis 7中最具影响力的新增特性：</p><p>&nbsp;</p><p></p><blockquote>Redis函数——一个新的可编程选项，通过增加模块化、可重用性和更好的开发者体验来改进脚本。</blockquote><p></p><p>&nbsp;</p><p>此外，她还写道：</p><p>&nbsp;</p><p></p><blockquote>Redis有支持多种执行引擎的能力，所以在未来的某个版本中，我们将能够用Lua、JavaScript和更多的语言编写Redis函数，但目前（Redis v7.0）唯一支持的语言是Lua。</blockquote><p></p><p>&nbsp;</p><p>开发者可以通过修改集群或复制组并指定引擎版本为7来<a href=\"https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/VersionManagement.html\">升级集群或复制组的引擎版本</a>\"。</p><p>&nbsp;</p><p>最后，需要注意的是，<a href=\"https://www.infoq.cn/article/Z0QjFecVCY9NjsGwg1Cc\">亚马逊云科技</a>\"并不是唯一支持开源Redis缓存服务的云供应商。例如，微软提供了<a href=\"https://azure.microsoft.com/en-us/products/cache/\">Azure Cache for Redis</a>\"，<a href=\"https://learn.microsoft.com/en-us/azure/azure-cache-for-redis/cache-whats-new#redis-6-becomes-default-for-new-cache-instances\">默认支持Redis 6</a>\"。与Redis对等的特性支持到<a href=\"https://redis.io/docs/stack/json/\">RedisJSON</a>\"，还没到Redis 7。谷歌的<a href=\"https://cloud.google.com/memorystore\">Memorystore</a>\"最多<a href=\"https://cloud.google.com/memorystore/docs/redis/supported-versions\">支持到Redis 6</a>\"。</p><p>&nbsp;</p><p>Amazon ElastiCache for Redis 7在所有AWS区域（中国北京和中国宁夏除外）均可使用，其定价细节可在<a href=\"https://aws.amazon.com/elasticache/pricing/\">定价页面</a>\"找到。此外，该服务的详细信息和指南可以在<a href=\"https://docs.aws.amazon.com/elasticache/index.html\">文档首页</a>\"上找到。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/11/amazon-elasticache-redis-seven/\">https://www.infoq.com/news/2022/11/amazon-elasticache-redis-seven/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/O9jijEFIBtaaeecQCe8K\">亚马逊云科技向Well-Architected Framework添加容器透镜</a>\"</p><p><a href=\"https://www.infoq.cn/article/c56VHUx8Yi8v2uNNMwwy\">亚马逊将自有服务数据的压缩从Gzip切换为Zstd</a>\"</p>",
    "publish_time": "2022-11-30 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Java近期新闻：Spring Framework 6、JCP选举、Valhalla项目、OpenJDK更新",
    "url": "https://www.infoq.cn/article/8XzPjAwr5e6bMs3HjX9K",
    "summary": "<p></p><h4>OpenJDK</h4><p></p><p>JEP 434（<a href=\"https://openjdk.org/jeps/434\">外部函数 &amp; 内存API第二个预览版</a>\"）已从JDK 20的Candidate状态提升为Proposed to Target状态。这个JEP在<a href=\"https://openjdk.java.net/projects/panama/\">Panama</a>\"项目的支持下不断演进：JEP 424（<a href=\"https://openjdk.org/jeps/424\">外部函数 &amp; 内存API预览版</a>\"）在JDK 19中交付；JEP 419（<a href=\"https://openjdk.org/jeps/419\">外部函数 &amp; 内存API第二轮孵化</a>\"）在JDK 18中交付；以及JEP 412（<a href=\"https://openjdk.org/jeps/412\">外部函数 &amp; 内存API第一轮孵化</a>\"）在JDK 17中交付。该提案建议纳入基于前期反馈的改进，并在JDK 20中提供第二个预览版。其更新内容包括：统一MemorySegment和MemoryAddress接口，即内存地址通过零长内存段建模；增强密封接口MemoryLayout，以便与JEP 427（<a href=\"https://openjdk.org/jeps/427\">Switch模式匹配第三个预览版</a>\"）搭配使用。</p><p>&nbsp;</p><p>JEP 436（<a href=\"https://openjdk.org/jeps/436\">虚拟线程第二个预览版</a>\"）上周从Draft 8295817状态<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2022-November/007189.html\">提升</a>\"为Candidate状态。在<a href=\"https://wiki.openjdk.org/display/loom/Main\">Loom项目</a>\"的支持下，该JEP提出基于JDK 19中交付的JEP 425（<a href=\"https://openjdk.org/jeps/425\">虚拟线程预览版</a>\"）提供第二个预览版，以便有时间为这项功能的演进提供更多的反馈和经验。需要注意的是，除了少量在JDK 19中固化的JEP 425 API之外，这第二个预览版本没有提出其他任何改动。</p><p>&nbsp;</p><p>同样，JEP 437（<a href=\"https://openjdk.org/jeps/437\">结构化并发第二轮孵化</a>\"）也从Draft 8296037状态<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2022-November/007190.html\">提升</a>\"为Candidate状态。这个JEP（也是在Loom项目的支持下）提议基于在JDK19中交付的JEP 428（<a href=\"https://openjdk.org/jeps/428\">结构化并发第一轮孵化</a>\"）在JDK 20中重新孵化这个功能，以便有时间获得更多的反馈和经验。唯一的变化是更新了StructuredTaskScope类，以支持在任务范围内创建的线程对范围值的继承。这简化了跨线程共享不可变数据的过程。</p><p>&nbsp;</p><p><a href=\"https://github.com/openjdk/jtreg/#readme\">The Regression Test Harness for the OpenJDK Platform</a>\"（jtreg）7.1版<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2022-November/007204.html\">发布</a>\"，主要是修复了Bug，并改进了JUnit测试报告进度的方式。自2022年8月jtreg 7版本<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2022-August/006869.html\">发布</a>\"以来，jtreg所需的最小JDK版本为11。Oracle公司Java平台组成员<a href=\"https://www.linkedin.com/in/christian-stein-63946917b/\">Chritian Stein</a>\"表示，近期计划包括JDK-8296710的一个PR，<a href=\"https://bugs.openjdk.org/browse/JDK-8296710\">升级到到jtreg 7.1</a>\"，并在2022年11月的最后一周集成到JDK中。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/openjdk/jtreg/blob/master/CHANGELOG.md\">变更日志</a>\"。</p><p>&nbsp;</p><p>Oracle编程语言设计师<a href=\"https://www.linkedin.com/in/gavin-bierman-a0173075/\">Gavin Bierman</a>\"<a href=\"https://mail.openjdk.org/pipermail/amber-spec-observers/2022-November/003856.html\">更新</a>\"了JEP 430（<a href=\"https://openjdk.org/jeps/430\">字符串模板预览版</a>\"，当前处于Candidate状态）的<a href=\"http://cr.openjdk.java.net/~gbierman/jep430/jep430-20221115/specs/string-templates-jls.html\">规范</a>\"。</p><p>&nbsp;</p><p>Oracle JVM架构师<a href=\"https://www.linkedin.com/in/john-rose-270725/\">John Rose</a>\"提交了两份JEP草案8297156（<a href=\"https://openjdk.org/jeps/8297156\">字段初始化的底层控制</a>\"）和8297236（<a href=\"https://openjdk.org/jeps/8297236\">增强Valhalla类型统一校验</a>\"）。</p><p></p><h4>JDK 20</h4><p></p><p>JDK 20的<a href=\"https://jdk.java.net/20/\">早期访问构建</a>\"<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-20%2B24\">Build 24</a>\"于上周发布，它是Build 23的<a href=\"https://github.com/openjdk/jdk/compare/jdk-20%2B23...jdk-20%2B24\">升级</a>\"，修复了各种<a href=\"https://bugs.openjdk.org/issues/?jql=project%20%3D%20JDK%20AND%20fixversion%20%3D%2020%20and%20%22resolved%20in%20build%22%20%3D%20b22%20order%20by%20component%2C%20subcomponent\">问题</a>\"。要了解关于这个构建的更多细节，请查看<a href=\"https://jdk.java.net/20/release-notes\">发布说明</a>\"。</p><p>&nbsp;</p><p>对于<a href=\"https://openjdk.java.net/projects/jdk/20/\">JDK 20</a>\"，我们鼓励开发者通过<a href=\"https://bugreport.java.com/bugreport/\">Java Bug数据库</a>\"报告缺陷。</p><p></p><h4>Valhalla项目</h4><p></p><p>在上个版本发布三年多之后，Valhalla项目<a href=\"https://jdk.java.net/valhalla/\">早期访问构建</a>\"Build 20-valhalla+20-75（代号为LW4）面向Java社区发布，它是基于JDK 20的一个不完整版本。根据Oracle公司技术咨询人员<a href=\"https://www.linkedin.com/in/david-simms-023219a6/\">David Simms</a>\"的<a href=\"https://twitter.com/SimmsUpNorth/status/1592787002726182912?cxt=HHwWgMDTxeHV25osAAAA\">推特</a>\"，这个版本主要是实现JEP草案8277163（<a href=\"https://openjdk.org/jeps/8277163\">值对象预览版</a>\"，目前处于Submitted状态）。要了解关于这个版本的更多细节，请查看<a href=\"https://openjdk.org/projects/valhalla/early-access\">发布说明</a>\"。</p><p></p><h4>JavaFX 20</h4><p></p><p>JavaFX 20的<a href=\"https://jdk.java.net/javafx20/\">早期访问构建</a>\"<a href=\"https://github.com/openjdk/jfx/releases/tag/20%2B8\">Build 8</a>\"和<a href=\"https://github.com/openjdk/jfx/releases/tag/20%2B7\">Build 7</a>\"正式面向Java社区发布。按照设计，JavaFX应用程序开发人员可以在JDK 20上使用JavaFX 20构建和测试他们的应用程序了。</p><p></p><h4>JCP（Java Community Process）</h4><p></p><p>2022年JCP执行委员会（EC）的<a href=\"https://jcp.org/aboutJava/communityprocess/elections/2022.html\">选举</a>\"结果显示，以下成员当选或再次当选，任期两年：</p><p>批准席位：<a href=\"https://www.alibaba.com/\">阿里巴巴</a>\"、<a href=\"https://bell-sw.com/\">BellSoft</a>\"、<a href=\"https://www.bnymellon.com/\">BNY Mellon</a>\"、<a href=\"https://www.jetbrains.com/\">JetBrains</a>\"、<a href=\"https://www.microdoc.com/\">MicroDoc</a>\"和<a href=\"https://www.sap.com/\">SAP SE</a>\"当选席位：<a href=\"https://www.eclipse.org/org/foundation/\">Eclipse基金会</a>\"和<a href=\"https://www.microsoft.com/\">微软</a>\"协理席位：<a href=\"https://www.linkedin.com/in/kenfogel/\">Ken Fogel</a>\"、Java Champion和Java Champion会议组织者</p><p>新当选的执委会成员将于2022年11月29日开始任职。</p><p></p><h4>Spring Framework</h4><p></p><p><a href=\"https://www.infoq.com/news/2021/09/spring-6-spring-boot-3-overhaul/\">经过一年多的努力</a>\"，Spring团队面向Java社区<a href=\"https://spring.io/blog/2022/11/16/spring-framework-6-0-goes-ga\">发布</a>\"了4个候选版本、6个里程碑版本以及期待已久的<a href=\"https://spring.io/projects/spring-framework\">Spring Framework</a>\" 6.0 GA版本。Spring Framework 6的最低要求是JDK 17和Jakarta EE 9，它还与最近发布的Jakarta EE 10兼容，并通过<a href=\"https://micrometer.io/\">Micrometer</a>\"嵌入了可观察性，可实现度量和跟踪。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/spring-projects/spring-framework/wiki/What%27s-New-in-Spring-Framework-6.x/\">新特性列表页</a>\"。InfoQ后续将带来更详细的报道。</p><p>&nbsp;</p><p>同时，在Spring Framework 5.x版本序列中，<a href=\"https://spring.io/blog/2022/11/16/spring-framework-5-3-24-available-now\">5.3.24版本</a>\"的新特性包括：新增SimpleBeanInfoFactory类，提高自省性能；引入TestSocketUtils类，替代已弃用的SocketUtils类；减少了由ProducesRequestCondition类中定义的getProducibleMediaTypes()方法导致的LinkedHashSet类的内存分配。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/spring-projects/spring-framework/releases/tag/v5.3.24\">发布说明</a>\"。</p><p>&nbsp;</p><p><a href=\"https://spring.io/projects/spring-data\">Spring Data</a>\" 2022.0（代号Turing）<a href=\"https://spring.io/blog/2022/11/18/spring-data-2022-0-goes-ga\">发布</a>\"，新特性有：针对Graal Native Image编译的预处理和反射提示；将Spring Data Envers合并到Spring Data JPA资源库，将Spring Data R2DBC合并到Spring Data Relational资源库；完善资源库接口。依赖项升级包括Spring Framework 6.0、JDK 17和Jakarta EE 10。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/spring-projects/spring-data-commons/wiki/Spring-Data-2022.0-%28Turing%29-Release-Notes\">发布说明</a>\"。</p><p>&nbsp;</p><p>Spring Data 2021.2.6和2021.1.10版本<a href=\"https://spring.io/blog/2022/11/18/spring-data-2021-2-6-and-2021-1-10-available\">发布</a>\"，主要是修复Bug，并将依赖项升级到Spring Data子项目的相应版本，包括：<a href=\"https://spring.io/projects/spring-data-jdbc\">Spring Data JDBC</a>\"、<a href=\"https://spring.io/projects/spring-data-neo4j\">Spring Data Neo4j</a>\"、<a href=\"https://spring.io/projects/spring-data-mongodb\">Spring Data MongoDB</a>\"、<a href=\"https://spring.io/projects/spring-data-elasticsearch\">Spring Data Elasticsearch</a>\"和<a href=\"https://spring.io/projects/spring-data-couchbase\">Spring Data Couchbase</a>\"等。</p><p>&nbsp;</p><p>Spring Cloud Dataflow 2.10.0的第二个候选版本发布，主要是修复Bug，并将依赖项升级到了<a href=\"https://spring.io/projects/spring-boot\">Spring Boot</a>\"2.7.5、Spring Framework 5.3.23和<a href=\"https://spring.io/projects/spring-cloud\">Spring Cloud</a>\" 2021.0.5。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/spring-cloud/spring-cloud-dataflow/releases/tag/v2.10.0-RC2\">发布说明</a>\"。</p><p>&nbsp;</p><p><a href=\"https://spring.io/projects/spring-modulith\">Spring Modulith</a>\" 0.1的<a href=\"https://spring.io/blog/2022/11/17/spring-modulith-0-1-rc1-released\">第一个候选版本</a>\"发布，提供了与<a href=\"https://docs.spring.io/spring-modulith/docs/0.1.x/reference/html/#documentation.application-module-canvas\">模块画布</a>\"相关的新特性，如：引入Spring值类型和Bean引用；默认隐藏空行。因为要准备即将发布的Spring Boot 3.0，所以这将是唯一的候选版本。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/spring-projects-experimental/spring-modulith/releases/tag/0.1.0-RC1\">发布说明</a>\"以及<a href=\"https://www.infoq.com/news/2022/11/spring-modulith-launch/\">InfoQ的这篇新闻报道</a>\"。</p><p></p><h4>Quarkus</h4><p></p><p>Red Hat<a href=\"https://quarkus.io/blog/quarkus-2-14-1-final-released/\">发布</a>\"了Quarkus 2.14.1.Final，提供了Bug修复、文档改进，并将GraalVM/Mandrel 升级到22.3.0。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/quarkusio/quarkus/releases/tag/2.14.1.Final\">变更日志</a>\"。</p><p>&nbsp;</p><p>Quarkus 3.0.0的第一个Alpha版本是作为GA版本新特性的预览。该版本以Quarkus 2.13.3为基础，以Jakarta EE 10规范为目标，但Jakarta EE 9下的<a href=\"https://jakarta.ee/specifications/persistence/3.0/\">Jakarta Persistence 3.0</a>\"除外。因此，<a href=\"https://hibernate.org/orm/\">Hibernate ORM 5.6</a>\"仍在支持范围。其他正在进行的工作包括提供<a href=\"https://microprofile.io/\">MicroProfile</a>\" 6.0、<a href=\"https://developer.getflow.com/\">Flow API</a>\"和Hibernate ORM 6.0支持。关于发布计划的更多细节，如何试用Quarkus 3.0.0.Alpha1以及如何升级，请阅读这篇<a href=\"https://quarkus.io/blog/road-to-quarkus-3/\">博文</a>\"。</p><p></p><h4>Micronaut</h4><p></p><p>Micronaut基金会<a href=\"https://micronaut.io/2022/11/17/micronaut-framework-3-7-4-released/\">发布</a>\"了<a href=\"https://micronaut.io/\">Micronaut Framework</a>\" 3.7.4版本，提供了Bug修复、文档改进以及<a href=\"https://micronaut-projects.github.io/micronaut-security/latest/guide/\">Micronaut Security</a>\"、<a href=\"https://micronaut-projects.github.io/micronaut-aws/latest/guide/\">Micronaut AWS</a>\"和<a href=\"https://micronaut-projects.github.io/micronaut-serialization/latest/guide/\">Micronaut Serialization</a>\"的补丁版本。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/micronaut-projects/micronaut-core/releases/tag/v3.7.4\">发布说明</a>\"。</p><p></p><h4>Piranha</h4><p></p><p>Piranha 22.11.0<a href=\"https://github.com/piranhacloud/piranha/releases/tag/v22.11.0\">发布</a>\"。该版本被称为2022年11月的“Pick your distribution”版本，新特性包括：对<a href=\"https://jakarta.ee/specifications/enterprise-beans/\">Jakarta Enterprise Beans Lite</a>\"的初步支持；一个面向Piranha Micro的Jakarta EE默认数据源；为改善对不同HTTP引擎的支持而进行的重构。要了解关于这个版本的更多细节，请查看<a href=\"https://javadoc.io/doc/cloud.piranha/project/latest/index.html\">官方文档</a>\"和<a href=\"https://github.com/piranhacloud/piranha/issues?q=is%3Aissue+-label%3Awontfix+milestone%3A22.11.0+is%3Aclosed\">问题跟踪系统</a>\"。</p><p></p><h4>Eclipse Vert.x</h4><p></p><p>Eclipse Vert.x 4.3.5<a href=\"https://vertx.io/blog/eclipse-vert-x-4-3-5/\">发布</a>\"，修复了在4.3.4版本中发现的一些Bug。该版本的新特性包括：在vertx-rx中添加Vert.x Oracle客户端；一项更新，在vertx-web中使用核心HttpServerRequestWrapper类；公开新的<a href=\"https://docs.influxdata.com/influxdb/v2.5/\">InfluxDb</a>\" 2.0配置选项，以便Vert.x能够在vertx-micrometer-metrics中支持InfluxDb 2.0连接。此外，该版本还会继续支持<a href=\"https://github.com/vert-x3/vertx-virtual-threads-incubator/blob/main/README.md\">虚拟线程孵化项目</a>\"，并包含一些<a href=\"https://github.com/vert-x3/wiki/wiki/4.3.4-Deprecations-and-breaking-changes\">弃用项和破坏性更改</a>\"。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/vert-x3/wiki/wiki/4.3.5-Release-Notes\">发布说明</a>\"。</p><p></p><h4>Apache软件基金会</h4><p></p><p><a href=\"https://tomcat.apache.org/\">Apache Tomcat</a>\" <a href=\"https://www.mail-archive.com/announce@apache.org/msg07733.html\">10.1.2</a>\"和<a href=\"https://www.mail-archive.com/announce@apache.org/msg07734.html\">9.0.69</a>\"版本发布，修复了一些Bug，如：包含lambda表达式的表达式语言求值时的并发问题；修正HTTP cookies的expires属性所使用的日期格式，使用单个空格而不是单个破折号来分隔日、月和年组件，以符合RFC 6265规范。要了解更多细节，请查看<a href=\"http://tomcat.apache.org/tomcat-10.1-doc/changelog.html\">10.1.2</a>\"和<a href=\"https://tomcat.apache.org/tomcat-9.0-doc/changelog.html\">9.0.69</a>\"版本的发布说明。</p><p>&nbsp;</p><p><a href=\"https://beam.apache.org/\">Apache Beam</a>\" 2.43.0<a href=\"https://www.mail-archive.com/announce@apache.org/msg07745.html\">发布</a>\"，带来了Bug修复、新特性和功能改进，包括：支持Python 3.10；初步实现一个Runner，让开发者可以在<a href=\"https://www.dask.org/\">Dask</a>\"上运行Beam管道；为所有Java线程提供一个名称，改善调试体验；一个在Java中使用Python <a href=\"https://beam.apache.org/documentation/transforms/python/elementwise/runinference/\">RunInference</a>\"的例子。要了解关于这个版本的更多细节，请查看<a href=\"https://beam.apache.org/blog/beam-2.43.0/\">发布说明</a>\"。</p><p></p><h4>PrimeFaces</h4><p></p><p>PrimeFaces 12.0.2<a href=\"https://www.primefaces.org/primefaces-12-0-2-released/\">发布</a>\"，主要是修复Bug，并在Column&nbsp;和Columns 类中添加了exportRowspan&nbsp;和exportColspan 属性。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/primefaces/primefaces/issues?q=is%3Aissue+label%3A12.0.2+is%3Aclosed\">问题列表</a>\"。</p><p></p><h4>JHipster Lite</h4><p></p><p>JHipster Lite <a href=\"https://github.com/jhipster/jhipster-lite/releases/tag/v0.23.0\">0.23.0</a>\"版本发布：支持GraalVM Native Image；升级端到端模块依赖关系；将依赖项升级到Spring Boot 3.0.0-RC2、Angular 14.2.10、Node.js 18.12.1和npm 9.1.1。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/11/java-news-roundup-nov14-2022/\">https://www.infoq.com/news/2022/11/java-news-roundup-nov14-2022/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/h3zWfjTmoYFvhXqygxpx\">Java 近期新闻：WildFly 27、Spring 候选版本、JDK 20 的 JEP、Reactor 项目</a>\"</p><p><a href=\"https://www.infoq.cn/article/LlrBgvdmYPGNsVDOZuCZ\">用现代 Java 调整经典设计模式</a>\"</p><p><a href=\"https://www.infoq.cn/article/lpOyO0ClfYLGmmakS3is\">Error Prone 通过检测常见错误帮助改善 Java 代码</a>\"</p>",
    "publish_time": "2022-11-30 09:06:11",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "阿里已经将Serverless数据库在双11大规模落地了，这是否代表着数据库的新风向？",
    "url": "https://www.infoq.cn/article/dYhjQRtHWaeYLZ8MfCMD",
    "summary": "<p></p><blockquote>数据库是Serverless化难度极高的应用。阿里云数据库已全面向Serverless演进，进一步实现了完全自动化的扩容，为用户带来更经济的计费模式和更无感的扩容体验，让业务根据请求的繁忙程度实现平滑的全自动响应，无需人工介入......近日，InfoQ采访到了阿里云数据库团队，深入了解阿里云数据库Serverless化的具体思路及核心技术。</blockquote><p></p><p></p><h2>全面Serverless化</h2><p></p><p>&nbsp;</p><p>2012年，Iron.io的副总裁Ken Form所写的一篇名为《Why the Future of Software and Apps is Serverless》的文章提出了一个新的观点：即使云计算已经逐渐的兴起，但是大家仍然在围绕着服务器转。</p><p>&nbsp;</p><p>正是这篇文章将<a href=\"https://xie.infoq.cn/article/5ba59bbd3d6989840dfeefb88\">“Serverless”</a>\"带进了大众视野。</p><p>&nbsp;</p><p>此后，国内外的Serverless生态迅速发展了起来，诞生了比如Serverless Framework、函数计算、云函数等很多优秀的产品，越来越多的技术人开始对外分享公司内部在Serverless层面的相关实践。</p><p>&nbsp;</p><p>然而，我们很少见到数据库这一重要基础设施服务Serverless化的实战分享。</p><p>&nbsp;</p><p>究其原因，无非一个“难”字。</p><p>&nbsp;</p><p>Serverless的三大主要特征是资源解耦和服务化、自动弹性伸缩以及按使用量计费。</p><p>&nbsp;</p><p>数据库的大量状态存储很难做到类似FaaS这种即开即用的能力，FaaS本身不具备共享内存的能力也会让计算和数据库之间的资源动态扩展能力不一致，FaaS也无法承受服务器通过driver和连接池访问数据库时繁重的初始化......</p><p>&nbsp;</p><p>诸如此，数据库Serverless化一直未取得突破性的进展，这也成为了阿里云数据库研发团队势必要实现的一个小目标。</p><p>&nbsp;</p><p>在阿里巴巴内部，数据库的形态一直在不断演变。</p><p>&nbsp;</p><p>第一阶段，大量业务依赖Oracle数据库，集团内部诞生了大量优秀的DBA和Oracle ACE。</p><p>&nbsp;</p><p>第二阶段，传统的单机数据库难以匹配淘宝等业务的快速发展，团队开始探索开源的数据库方案，尝试用MySQL替换Oracle。在这个过程中，团队逐步做了异地多活等架构层面的创新。</p><p>&nbsp;</p><p>第三阶段，阿里巴巴开始对外提供公有云服务，团队将在MySQL层面积累的经验通过云的形式提供给用户，这也是如今的主流方式之一，只是这个阶段的用户普遍头痛于突发的数据库扩容需求。</p><p>&nbsp;</p><p>第四阶段，自研云原生数据库PolarDB来了，可以很好地解决上一个阶段出现的扩缩容问题。使用传统云数据库，用户需要提前购买足够支撑业务运行的数据库资源。PolarDB与底层的RDMA高性能网络、CIPU、飞天操作系统等基础设施充分融合，实现了存储计算分离、分钟级别弹性等核心云原生能力，结合ADB、DMS等产品逐渐形成了一站式全链路数据管理与服务这样一个被称为云原生数据库2.0的阶段。</p><p>&nbsp;</p><p>第五阶段，全面Serverless化，更进一步实现了秒级自动化的缩扩容，能够随用户业务请求数的增加和减少智能化“膨胀”和“缩小”，实现资源的自动“吞吐”。这种特性，能够为用户带来更经济的计费模式和更无感的扩容体验，让业务根据请求的繁忙程度实现平滑的全自动响应，无需人工介入。</p><p>&nbsp;</p><p>“过去多年，我们深入和底层基础设施结合，哪怕这个过程很痛苦。数据库on ECS 还是物理机？on ECS的一开始肯定会带来成本和性能的挑战，这就倒逼着我们必须通过技术创新解决这些问题，迈过这些坎就会发现on ECS带来的池化规模效应是巨大的，迈过去就是核心壁垒，<a href=\"https://www.infoq.cn/article/VeWtua3dTWELlL09tGv4\">Serverless亦然</a>\"。”阿里云智能数据库事业部负责人李飞飞表示。</p><p>&nbsp;</p><p>那么，在Serverless化的过程中，阿里云数据库团队迈过了哪些坎呢？&nbsp;</p><p></p><h2>数据库Serverless化的关键技术解析</h2><p></p><p></p><h3>计算、内存、存储三层解耦才能实现真正的Serverless</h3><p></p><p>&nbsp;</p><p>在此之前，阿里云自研的云原生数据库PolarDB对数据库架构进行了改造，实现了存储和计算分离，并基于此实现了一写多读，适配云架构，实现了存储池化和按量计费。</p><p>&nbsp;</p><p>但此架构下，CPU和内存依然是强绑定的，无法摆脱传统的vCPU+内存的数据库售卖模式，随着PolarDB Serverless新架构的提出，这种情况可能会出现极大改变。</p><p>&nbsp;</p><p>2021年SIGMOD大会上，阿里云发表《PolarDB Serverless: A Cloud Native Database for Disaggregated Data Centers》论文，创造性地提出了DDC（Disaggregated Data Centers）架构，实现数据库内计算、内存和存储三层资源解耦，三层资源均可以按需分层弹性，内存层支持PB级弹性扩展。</p><p>&nbsp;</p><p>在理想情况下，整个IDC形成一个多租户的大数据库，其全部的CPU，内存，存储构成三个独立的资源池。在资源池未耗尽的情况下，任何一个用户（租户）都可能任意弹性扩展任何一种资源到任何一个规格，用户为其SQL动态消耗的CPU、内存和存储买单，不需要预置任何的规格。</p><p>&nbsp;</p><p>这种情况下，CPU和内存资源因其池化其使用率会大幅度提升，云原生数据库的成本会进一步大幅降低。</p><p></p><h3>解决跨设备迁移潜在的高可用问题</h3><p></p><p>&nbsp;</p><p>在Serverless的场景下，同一台物理机上运行的数据库实例可能都需要资源扩容，此时有可能遇到物理机资源无法满足所有扩容请求的场景。当本地资源不足时，需要将计算节点实例迁移到资源充足的物理机上部署。当实例发生跨设备迁移时将可能导致迁移时间长和用户业务中断受损，因此Serverless数据库需要具备高效的高可用能力。</p><p>&nbsp;</p><p>通过自动切换、热备节点的全局预热系统、利用中间件Proxy的链接技术保证用户链接不中断、无损事务续传的方案让用户得以进行更高效的资源管理， 并且因为内存和存储中的状态与数据库节点解耦，使用Serverless架构的PolarDB节点的崩溃恢复时间比使用单机架构的PolarDB内核快5.3倍。&nbsp;</p><p></p><h3>真正高性能的多节点横向扩展</h3><p></p><p>&nbsp;</p><p>Serverless架构本身对数据库的性能会产生负面影响，毕竟数据库要从远程访问数据，因此想要高性能地多节点横向扩展不是一件容易的事情。</p><p>&nbsp;</p><p>通过Proxy技术以及数据库引擎PolarTrans事务系统利用提交时间戳技术CTS和RDMA网络在内核层面提供集群全局一致性读SCC服务，保证发往集群任意副本的读请求都可以获得全局一致性的结果；通过Scan操作会将算子尽量推送到缓存端或者远程的存储之上，降低实际计算的数据量；并依靠新的硬件解决性能瓶颈，比如阿里云的倚天710等。</p><p>&nbsp;</p><p>接下来，阿里云数据库团队还会在计算资源标准化、计费方式精确化、无感扩所容、资源快速调度、数据共享以及智能自治等层面继续优化Serverless能力。随着硬件的不断发展和计算任务的合理匹配，这种模式最终将会用户从中获得成本优势及体验优势。&nbsp;</p><p></p><h2>下一步技术规划</h2><p></p><p>&nbsp;</p><p>在日前召开的云栖大会上，阿里云数据库提出了整体向“四化”方向发展：云原生化(资源解耦、Serverless)、平台化(基于云构建数据平台能力、OpenAPI标准化)、一体化(处理分析一体化、离在线一体化、集中分布一体化、多模处理一体化)、智能化(AI for DB简化运维、In-DB ML挖掘数据价值)。</p><p>&nbsp;</p><p>数据库Serverless化是阿里云数据库团队在云原生方向的重要进展，然而这并不足以实现团队“让数据业务永远在线，数据价值不断放大”的最终愿景。达成这一点，还需要在平台化、一体化和智能化三个方向上努力，这也是团队接下来在数据库层面的技术规划。</p><p></p><h2>平台化：数据库正在逐步走向融合</h2><p></p><p>&nbsp;</p><p>今年10月份，Oracle 发布了 Oracle Database 23c Beta，这是最新版本的融合数据库，支持所有数据类型、工作负载和开发风格。</p><p>&nbsp;</p><p>这与阿里云数据库团队的理念不谋而合，但又不完全一致。</p><p>&nbsp;</p><p>如前文言，阿里云数据库诞生之初就是要与底层云平台做融合，这也是阿里云成为国内最大的数据库厂商之一的重要原因。当然，这种趋势在整个行业内越来越明显，不仅仅是数据库，即便是自动驾驶厂商也在努力向软硬件一体的平台化方向努力，这也是RDS基于倚天710芯片，PolarDB基于高性能的RDMA做存储，云原生数仓利用硬件能力做算子加速的核心逻辑。</p><p>&nbsp;</p><p>在李飞飞看来，一个独立的数据库厂商如果只是在纯软件层面进行优化，所能构建的竞争力壁垒是非常薄的，如果不去做软硬协同的创新，就很难把竞争对手甩开。也正是基于这个逻辑，李飞飞强调，“我们是阿里云数据库。这是非常重要的区别。”</p><p></p><h3>一体化：放弃分布式、集中式等执念，共生共存</h3><p></p><p>&nbsp;</p><p>在一体化层面，我们可以从三个方面来理解：处理分析一体化、离在线一体化、集中分布一体化，多模处理一体化。</p><p>&nbsp;</p><p>处理分析一体化层面，阿里云数据库团队提出了两种模式：一是云原生HTAP，PolarDB基于IMCI（In-Memory Column Index，内存列式索引) 处理轻量的分析业务；二是打通PolarDB和AnalyticDB提供一体化HTAP解决方案，让数据不需要通过部署额外的同步链路而是直接在内核层面传输，用户对此基本是无感的。</p><p>&nbsp;</p><p>离在线一体化层面，AnalyticDB已经做到一份数据同时支持在线分析和离线计算，通过智能的冷热分层和两大互相隔离的计算模型（传统的在线数据库交互式引擎和大数据引擎），并统一了计费单位、数据管道、数据管理及数据访问来实现离在线一体化。</p><p>&nbsp;</p><p>集中分布一体化层面，团队认为这两种模式均有很好的应用场景，并不存在取代关系，阿里云数据库也确实是这么做的，PolarDB- X通过将云原生数据库架构的Shared Everything+Shared Storage模式与分布式的Shared Nothing模式做融合，可以平滑地从集中式过渡到分布式，即便是应对双11大促这类超大规模数据量的并发也没有问题。</p><p>&nbsp;</p><p>李飞飞认为，集中式和分布式的边界在快速抹平，而且从用户视角看，用户也不需要关心数据库是集中式还是分布式。“我觉得未来的趋势从客户视角其实就是一体化的数据化，什么集中分布式那是你内核需要解决的问题，客户不需要关心。”</p><p>&nbsp;</p><p>多模处理一体化层面，随着数据的多样性不断增长，需要多模系统对多元异构的数据进行处理，Lindorm将时序、宽表、KV、文档等多个数据模型融合在一个平台上，提供一体化的多模数据处理能力，化繁为简，让海量数据看得见，存得起。&nbsp;</p><p></p><h3>智能化：向自动驾驶的数据库平台努力</h3><p></p><p>&nbsp;</p><p>数据库智能化或者说自治是一系列原子技术的组合，广义上包含两大类：数据库外部运维和内核技术的智能化。外部运维就是最近流行的 AIOps，内核技术则是用 AI 技术提升数据库内核的某些性能。目前学术上对后者有很多前沿研究，比如 MIT 提出过使用深度学习网络代替 B-Tree 做索引，在一些实例上取得了不错的效果；IBM 使用深度模型做 SQL 执行计划优化等。但是，目前离成熟的、大规模产品落地还有一段距离。</p><p>&nbsp;</p><p>“当前，业界的实现路径呈现‘百家争鸣，百花齐放’的状态。我们采取的策略是‘外围包围内核’， 先从 AIOps 做起，逐步进入内核智能化的领域。阿里云数据库自治服务 DAS 基于全量 SQL 和性能指标的大数据能力，深度融合人工智能和专家经验，可以分成上游的可观测技术，和下游的可控制技术两个系统。上游包括例如异常 SQL 定位，信号异常检测，针对稀疏数据或倾斜分布的高效统计采样， 还有把观测技术的结果按场景进行归类，用来驱动下游的控制。下游技术包括例如 SQL 外置优化，限流，压测，调参，弹性扩缩容，资源调度，SQL 审计等。这是一个复杂的，包含众多原子技术的体系。通过单点技术的原子能力，加上体系上的构建的丰富的产品功能，和阿里云上独有的规模化的服务，三者的结合构成飞轮效应，呈现给用户智能化的数据库自治能力，让用户聚焦在自己的业务创新和发展上。</p><p>&nbsp;</p><p>虽然距离完全的数据库自动驾驶还有很长一段距离，但目标是可期的。</p><p></p><h2>数据库的场景化爆发时代，来了</h2><p></p><p>&nbsp;</p><p>数据库是非常典型的场景化催生的产品，最早的场景便是处理银行交易。正是因为银行交易场景对数据一致性、隔离性、持久性、原子性等的强需求才催生了数据库将Transaction模型内置其中，但该场景如今已经被标准化。</p><p>&nbsp;</p><p>如今，物理世界数字化以及生物世界数字化让数据库再度站在场景化爆发的路口，数据使用的多样性在需求侧大迸发，这也是空天数据库引擎Ganos得以被广泛关注的原因，但无论是智慧城市还是元宇宙这样的诉求都不是数据库本身就可以满足的，必然需要与底层的硬件能力、云计算能力深入融合，而这种融合所带来的成本优势、性能优势已经可以从阿里云数据库产品中窥见一二。</p><p>&nbsp;</p><p>可以预见未来很长一段时间内，计算、内存、存储三层解耦的Serverless数据库以及云原生化、平台化、一体化和智能化的趋势将会成为数据库的主要形态。</p><p>&nbsp;</p><p>注：本文部分内容参考自<a href=\"https://mp.weixin.qq.com/s?__biz=MzU0NzczNjAwMw==&amp;mid=2247498007&amp;idx=1&amp;sn=fe4ab787aa66f6d39acadf95ba8c3bdb&amp;chksm=fb4b69bbcc3ce0adf216b48bd79c21c14cbf045019b4fadb23f25fb61b5abb7abaa6800160f0&amp;scene=27\">《Serverless数据库技术》</a>\"研究报告，感兴趣的读者欢迎下载报告全文。</p>",
    "publish_time": "2022-11-30 09:39:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "2022 亚马逊云科技 re:Invent：一图看尽 Day 1 重要发布",
    "url": "https://www.infoq.cn/article/ADkDkycu3lzqpHH8KKVf",
    "summary": "<p></p><p><img src=\"https://static001.infoq.cn/resource/image/fe/08/fe33745520e616ca3679317465bda608.png\" /></p><p></p>",
    "publish_time": "2022-11-30 11:56:54",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "大砍广告投放，还威胁要下架Twitter，马斯克怒向苹果开炮：宁可开战也不付30%“过路费”",
    "url": "https://www.infoq.cn/article/xRw96EdKlLucNOsmYq0p",
    "summary": "<p></p><p></p><blockquote>马斯克不怕得罪推特最大的“金主”— 苹果。</blockquote><p></p><p></p><p>就在马斯克接手Twitter、准备推动业务改造的同时，苹果公司据称放出狠话，打算在自家平台上下架Twitter。</p><p></p><p>马斯克表示，苹果一直在对App Store上各软件产品的应用内购抽取30%费用。出于“公义”，马斯克开始连发推文声讨这笔“苹果税”。</p><p></p><h2>马斯克“叫板”苹果</h2><p></p><p>马斯克跟苹果的恩怨是从本周开始的。当时这位新任CEO宣称苹果公司威胁要把Twitter从App Store中“下架”。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b3/b37691a2a328b49f04e68c80a232f9ab.jpeg\" /></p><p></p><p>马斯克还强调，苹果已经“基本停止在Twitter平台上投放广告”。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/36/36af0aec8fa5e415c2e02f7894b1ce26.jpeg\" /></p><p></p><p>马斯克在一条推文中艾特了苹果公司首席执行官蒂姆库克，询问“这是怎么回事”，要求其对他的投诉做出回应。</p><p></p><p>根据马斯克的说法，苹果并未解释其为什么会强制Twitter下架。最大的理由可能是管控，毕竟苹果之前就对Discord和Tumblr等公司发布过警告。好在Twitter上托管的成人内容、错误信息和仇恨言论还不算特别多，所以还不致被推上风口浪尖。</p><p></p><p>马斯克还暗示苹果就内容审核要求向推特施压。他发起了一场投票，询问粉丝“苹果是否应该公布可能影响用户的所有审查行为”。截至11月29日上午8时45分，已有近145万人参与投票，其中近85%的人选择“是”。</p><p></p><p>苹果CEO库克则在最近接受CBS采访时表示，“他们说会继续保持克制，希望他们能说到做到。”</p><p></p><p>马斯克最近还决定撤销特朗普、乔丹·彼得森（Jordan Peterson）和安德鲁·泰特（Andrew Tate）等争议性人士的账户封禁。他甚至公开表示，可以考虑恢复所有被禁Twitter账户。</p><p></p><p>虽然我们不太清楚苹果和Twitter到底有什么过节，但马斯克一直强调这事跟苹果打击言论自由有关。</p><p></p><p>**大致在同一时间，马斯克又开始在Twitter上讨论苹果从应用内购中抽取30%佣金的行为。**马斯克将其称为“秘密”税，或者说“苹果税”。但实际情况好像没那么秘密，毕竟各监管机构、媒体和大企业老早就讨论过这件事了。</p><p></p><p>此前，推特的绝大部分收入来自于广告。但自马斯克掌管推特以来，广告业务的情况似乎并不乐观。</p><p></p><p>监督网站 Media Matters 上周报道称，由于对 Twitter 的发展方向感到担忧，Twitter 的一半顶级广告商已经撤掉了在 Twitter 上的广告，包括梅西百货（Macy‘s）、大众汽车集团（Volkswagen Group）、通用磨坊（General Mills）等在内的多家大型品牌都在最近几周停止了在Twitter 上的广告支出。</p><p></p><p>《华盛顿邮报》<a href=\"https://www.washingtonpost.com/technology/2022/11/28/musk-apple-app-store-twitter/\">报道</a>\"称，苹果是 Twitter 上最大的广告商，2022 年第一季度，苹果在该社交网络上的广告支出为 4800 万美元，占Twitter 第一季收入的 4%。</p><p></p><p>广告数据分析公司 Pathmatics 调查显示，苹果11月10日-16日期间 Twitter 投放广告金额为131600 美元，低于 10 月 16~22 日 的220800 美元（马斯克完成收购的前一周）。</p><p></p><p>马斯克希望通过将 Twitter 验证转变为付费订阅服务来赚钱。Twitter打算推出7.99美元的Blue蓝标认证服务，马斯克当然不想苹果再从中分走一笔。毕竟马斯克为了买下Twitter已经背负起巨额债务，再把30%的收益拱手让给苹果简直就是不可能接受的打击。</p><p></p><p>即便可能失去苹果这个最大的广告主，马斯克仍不改做法，并持续针对“苹果税”接连发推文批评。马斯克甚至在Twitter上发布一个表情包，表示他宁愿与苹果“开战”也绝不支付30%的佣金。</p><p></p><p>所以说，马斯克希望人们掏钱买Twitter Blue蓝标认证，同时又对订阅抽成大加谴责？</p><p></p><p>没错。</p><p></p><p>针对下架一事，马斯克此前曾在推特上回应网友，称如果推特遭到苹果和谷歌应用商店的限制，他将自己制作一款手机。该网友称，“想必一半美国人会抛弃带有偏见、窥探个人隐私的iPhone和安卓手机。马斯克建造了通往火星的火箭，一个小小的智能手机应该很容易。”不少网友已经为这款手机取好了名字，将其称呼为“特斯拉手机（Tesla Phone）”，更有马斯克的粉丝直接表示会为了特斯拉手机放弃iPhone。</p><p></p><p>马斯克频频对苹果开炮的攻势似乎奏效了。《华盛顿邮报》的文章称，马斯克的推文成功引起立法者注意，其已开始提议立法，要取消苹果、谷歌等透过应用程序平台行使的权利。</p><p></p><h2>30%的苹果税究竟是什么？</h2><p></p><p>“苹果税”其实是坊间的习惯表达，指的是苹果对App Store上各应用产品的内购金额收取一般30%的佣金。其实谷歌在Play Store中也有类似的抽成政策。</p><p></p><p>这根本就不是秘密，好像只有马斯克自己才刚刚听说。多年以来，应用程序开发商和世界各地的监管机构一直觉得这个抽成比例有点夸张。</p><p></p><p>这是因为，如今的移动世界已经形成了“两超并行”的局面。虽然也有其他商店和操作系统，但最强大的就只有苹果和谷歌。如果你的应用程序没法登陆这两套平台，就不用指望能有多少人愿意去用。</p><p></p><p>正因为如此，苹果和谷歌掌握了设定佣金比例和开发者准则的绝对话语权。例如，一切应用内购都必须通过App Store/Google Play进行，确保二者能够在每笔交易中都分上一杯羹。</p><p></p><p>而且向用户提供苹果/谷歌以外的支付方式属于违约行为。所有在应用商店上架的公司都必须遵守苹果的规则并支付其费用，否则将面临下架或暂停。</p><p></p><p>就拿 Twitter来说，只有苹果才能决定谁可以进入 App Store。如果苹果愿意，它可以阻止 Twitter 在世界各地的 iPhone 上的下载——这对 Twitter 来说将是毁灭性的打击。</p><p></p><p>不仅如此，Apple 还可以为进入 App Store 的特权收费。按照目前的情况，Apple 可以从 Twitter 计划向部分用户收取的月费中抽取高达 30% 的资金。</p><p></p><p>那么，之前有人反抗过苹果税吗？</p><p></p><p>当然有。</p><p></p><p>之前不同规模的企业都曾明确抵制过苹果税。Spotify和Meta还公开对抽成比例表示过不满。</p><p></p><p>作为邮件管理应用Hey的开发商，Basecamp在今年6月的苹果全球开发者大会（WWDC）前几天公开了与苹果间的纠纷。该公司透露，由于没有向应用中添加直接通过App Store实现的订阅服务，苹果决定阻止该应用继续更新。</p><p></p><p>Hey公司联合创始人David Heinemeier Hansson在推文中提到，“就跟黑势力一样，苹果给我们打来了电话。他们先是砸碎了我们的窗户（阻止我们发布Bug修复更新），一句道歉的话都没有，还放言要烧掉我们的店铺（直接下架Hey应用）。”</p><p></p><p>纠纷最终得到了解决。</p><p></p><p>但2020年又闹出了更大的乱子。当时人气电子游戏《堡垒之夜》接连被苹果和谷歌下架，原因就是开发商Epic Games允许玩家绕过App Store或Google Play，直接在应用程序之内购买游戏货币。</p><p></p><p>他们还有更赤裸裸的“挑衅”——选择直接支付V-Bucks的玩家可以额外享受20%的折扣。</p><p></p><p>于是，苹果和谷歌迅速将《堡垒之夜》从应用商店中下架，称此举违反了他们的软件发布条款。</p><p></p><p>Epic这边早就为冲突做好了准备，并迅速在多个国家/地区发起反竞争行为诉讼，包括美国和澳大利亚。最终，美国的法官做出了有利于苹果的裁决，理由是App Store并不存在反竞争行为。</p><p></p><p>但在澳大利亚，竞争与消费者委员会（ACCC）的介入让事态趋于复杂，美国的诉讼程序也被迫中止。根据法庭文件，此案将在2024年继续审理。</p><p></p><h2>反垄断监管</h2><p></p><p>世界各地的监管机构也对苹果应用商店政策的反竞争性质提出了质疑。</p><p></p><p>在Basecamp摊牌的同一天，Spotify和另一家小型有声读物/电子书分销商也提起诉讼，欧盟由此展开了反垄断调查。美国司法部也在2019年开始了对苹果的调查，且目前仍未结束。</p><p></p><p>在澳大利亚，ACCC根据数字平台服务调查中期报告，开始关注App Store和Google Play对于市场竞争和消费者利益的影响。</p><p></p><p>其他针对苹果产品（包括Apple Pay等）的同类垄断调查也不在少数。</p><p></p><h2>人人都得交这30%吗？</h2><p></p><p>当然不是，苹果倒是想这样，但没能成功。</p><p></p><p>2020年8月，苹果曾发布一份在App Store内下架《堡垒之夜》的声明。在声明中，苹果声称所有应用内购的抽成比例都是相同的。</p><p></p><p>苹果在当时的声明中指出，“此次Epic Games采取了令人遗憾的行动，违反了App Store准则。此准则同样适用于全体开发商，旨在保证用户能体验到安全的软件商店。”</p><p></p><p>但就在一个月前的一场反垄断听证会上，相关信息显示出，Amazon&nbsp;Prime&nbsp;Video的首年会员订阅费就只需要分给苹果15%。</p><p></p><p>这笔交易可以追溯到2017年，当时苹果在自家Apple TV上开放了Amazon Prime Video。同地，苹果产品也能从Amazon.com网站上买到。</p><p></p><p>“作为交易条款中的一部分，苹果将Prime Video的订阅费抽成从30%降低到了15%。对于Prime Video续费用户，苹果甚至会把这15%也彻底免除。”</p><p></p><p>更离谱的是，亚马逊就可以在苹果以外使用其他支付系统——Epic Games只是做了同样的选择，却导致《堡垒之夜》被从App Store上粗暴下架。</p><p></p><h2>苹果推出15%小型企业激励计划</h2><p></p><p>在《堡垒之夜》纠纷爆发的几个月后，为了平息App Store佣金惹起的风波，苹果推出了“小型企业激励计划”。</p><p></p><p>新政策将上一自然年内收入低于100万美元的“小型”企业的抽成比例降低至15%，涵盖应用本体付费和应用内购两种情况。计划已经于2021年1月1号正式启动。</p><p></p><p>参考链接：</p><p></p><p><a href=\"https://www.smartcompany.com.au/technology/what-is-the-apple-tax-elon-musk-whining/\">https://www.smartcompany.com.au/technology/what-is-the-apple-tax-elon-musk-whining/</a>\"</p><p></p><p><a href=\"https://www.bbc.com/news/technology-63788437\">https://www.bbc.com/news/technology-63788437</a>\"</p>",
    "publish_time": "2022-11-30 14:37:42",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "腾讯汤道生：打造三大标杆，助力实体经济诞生“产业冠军”",
    "url": "https://www.infoq.cn/article/rASbCg1X7cczBEQHsQUD",
    "summary": "<p>11月30日，在2022腾讯全球数字生态大会上，腾讯集团高级执行副总裁、腾讯云与智慧产业事业群CEO 汤道生发表了主题演讲。</p><p></p><p><a href=\"https://www.infoq.cn/article/eZAVxECFU1LzzoILJOyR\">汤道生</a>\"表示，数字化是一场波澜壮阔的变革，大幕刚刚拉开。腾讯将竭尽所能，做好企业“数字化助手”。将与生态伙伴紧密携手，用领先的数字技术，为产业插上效率的“翅膀”；用数一数二的“冠军应用”，助力实体经济诞生更多的“产业冠军”，推动数实一体，创造更大的社会价值。</p><p></p><h2>关于数字化的三点思考</h2><p></p><p></p><p>汤道生在演讲中提到，<a href=\"https://www.infoq.cn/theme/161\">产业数字化</a>\"通过连接上下游，以数据度量和流程优化实现精益制造、精准营销；通过高效协作应对市场变化，捕捉新机会。既深耕本土市场，也探索海外机会，实现国内国际双循环。腾讯自己也通过数字化技术实现降本增效。三年时间，腾讯自身业务全部搬到腾讯云上运行。通过更灵活的资源调度，更敏捷的响应供需变化，光是IT成本这一项，就为公司每年节省30亿元。这也更加坚定了腾讯在产业互联网上的投入。</p><p></p><p>汤道生表示，基于腾讯自身的实践以及合作伙伴们的快速成长，腾讯对数字化的未来充满信心。在演讲中，汤道生还分享了腾讯与合作伙伴在数字化上的三点收获和思考，并介绍了几个成功的数字化案例。</p><p></p><p>1、精益制造是许多制造企业的数字化目标。</p><p></p><p>以瑞泰马钢为例。高温耐火材料生产链条长、环节复杂难优化，过去瑞泰马钢一直被高耗能、低效率所困扰。瑞泰马钢联合腾讯云能源互联网和建筑空间物联网类操作系统微瓴，打造了行业第一家“透明工厂”，让生产流程，甚至财务数据实现可视化、可优化，并给每个产品生成一个专属的二维码，从原料进厂开始，记录生产过程中消耗的每一度电、每一分钱。工作人员一旦看到某个生产环节出现了指标异常，就可以通过数据追溯，快速排查原因。“透明工厂”的实现，让生产能耗降低了10%，效率提升了12%，净利润也大幅提升。</p><p></p><p>2、利用协同工具，提高决策与执行效率。</p><p></p><p>以中交建为例。在中交建的建设任务中，项目的实施往往需要桥梁、隧道、装备等各领域团队合作，这些团队往往遍布全球各地，跨区域协作一直是个难题。疫情让这个问题更加突出。通过腾讯会议，后端专家也能远程看到现场实况。除了腾讯会议，包括企业微信、乐享、微卡在内的协同办公产品，已经成为中交建全球团队协作的必备工具。在沟通协作之外，还解决了跨领域的知识分享，跨系统的身份识别等等问题，极大提升了工作效率。</p><p></p><p>3、精准营销，识别用户需求，捕捉市场机会。</p><p></p><p>以名创优品为例。过去，名创优品通过线下店铺试销来做出判断，但是反馈周期慢，卖得好的产品，补货速度跟不上；或者销量突然下滑，后端备货来不及调整，造成大量库存。借助企业微信的C2B能力，用在线预售的方式，就能解决这个问题。</p><p></p><h2>打造产品、技术、生态三大标杆</h2><p></p><p></p><p>汤道生表示，未来，腾讯将从三个方面发力塑造标杆。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/37/fe/3744bd57a7fa03c47d73457540fb56fe.jpg\" /></p><p></p><p>一是塑造产品标杆，打造企业数字化“工具箱”。</p><p></p><p>在企业服务市场，存在很多不同的角色，比如咨询做顶层设计，集成商整合产品，做定制开发，产品厂商提供可靠稳定的产品，服务商做交付等。术业有专攻，腾讯的优势是做产品。所以，将立足“产品为王，场景为先”，在关键赛道上，打造行业数一数二的平台型产品，支持ISV伙伴通过集成腾讯产品，面向各行各业推出解决方案，更好地满足客户需求。</p><p></p><p>据了解，腾讯已联合1万多家生态伙伴，面向30多个行业推出400款产品和解决方案，实现了从云基础到行业应用的全覆盖。除了腾讯会议、企业微信、腾讯文档，腾讯在多个场景赛道，也都拥有数一数二的优秀产品。</p><p></p><p>此外，腾讯还把多年积累的开发工具、代码思维和产品经验开放出来，打造了腾讯云无服务器架构<a href=\"https://xie.infoq.cn/article/5c76ea183f1b079f5077ba46d\">Serverless</a>\"、云端开发工具Cloud Studio、设计协作平台CoDesign、协作管理平台CODING DevOps、TAPD，以及微搭低代码平台等一系列开发者工具和平台，帮助开发者更简单、高效、安全地拥抱云时代。</p><p></p><p>针对开发环节涉及到的实时音视频、AI推理、账号安全等，有较高技术门槛的能力，腾讯把它封装起来，推出了腾讯云TI平台、腾讯云视立方RT-Cube，开发者可以通过API或SDK的形式调用。</p><p></p><p>二是塑造技术标杆，构筑数实融合“硬支撑”。</p><p></p><p>数字科技面临新一轮代际跨越。云计算、AI、实时音视频与数字孪生等技术的兴起，推动了“全真互联”时代的到来。全真互联将实现数字世界与真实世界的一体融合，也将成为未来产业互联网的技术基座。</p><p></p><p>为了做好产品、服务好企业客户和开发者，腾讯将持续加大研发投入，深耕音视频、数字孪生、安全等核心技术，围绕全真互联，探索数字技术在沟通协同、研发生产、运营管理、营销服务等产业全链条中发挥潜力。</p><p></p><p>汤道生特别提到了芯片，他表示，腾讯不仅推动自研芯片为腾讯云服务降本增效，也以云计算，助力国产芯片产业链建设，通过算力、大数据、AI等，加速芯片从设计到上市的流程。比如，基于云研发流程DevOps的理念与工具，助力芯片研发的快速迭代。</p><p></p><p>由于在芯片设计的仿真测试环节中，存、算数据量都很大，腾讯与燧原科技共创了“存算分离”的混合云架构，将代码存在本地的同时，把云端算力嵌入整个设计、验证流程，高效支撑研发效能提升。帮助燧原节省了千万级IT投入，任务并发量提升了100%，整体仿真周期缩短30%。</p><p></p><p>三是塑造生态标杆，请生态伙伴“唱主角”，共创产业共赢“大空间”。</p><p></p><p>汤道生表示，产业数字化有巨大的空白有待挖掘，没有公司可以包揽数字化全部。腾讯会继续坚持生态共赢，助力不同类型的合作伙伴成长，打造成为腾讯云产品的技术专家。比如助力ISV伙伴，把腾讯核心产品，集成到各种行业应用场景中；向伙伴开放腾讯自研产品的交付服务，在品质保障的基础上，支持伙伴优先接单；提供清晰与稳定的激励政策，助力优质代理伙伴更快发展；升级千帆云市场，共享腾讯云超100亿的销售商机等等。</p><p></p><p>“时间是优秀企业的朋友，稳扎稳打、健康可持续的经营会带我们穿越周期，长期机会是留给有准备的人。”汤道生表示。</p>",
    "publish_time": "2022-11-30 14:48:28",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "腾讯云联合IDC发布2022年云上产品十大技术趋势",
    "url": "https://www.infoq.cn/article/I07cq68mRr6DHYxaCxMx",
    "summary": "<p>11月30日，在腾讯数字生态大会产品战略对谈会上，腾讯集团高级执行副总裁、云与智慧产业事业群CEO汤道生对话IDC中国区总裁霍锦洁，论道云上产品未来趋势，探讨当前数实融合趋势下的云产品战略与行业趋势。</p><p></p><p>会上，腾讯云联合IDC重磅发布了《2022年云上产品演进趋势聚焦报告》，洞见了云上产品的十大技术趋势。</p><p></p><h4>趋势一：音视频正在成为社会信息活动的主流载体</h4><p></p><p></p><p>随着5G、大数据等技术发展，<a href=\"https://www.infoq.cn/news/tZTQwRq8gv7WqKOkX1PB\">音视频</a>\"正在成为社会信息活动的主流载体，视频类数据是未来数据空间的核心构成部分。据报告，预计到2026年，全球以视频类数据为主导的非结构化数据占比将达到90.5%。音视频技术能够为各行各业提供多元化的信息传递，建立全新的互动方式，构建实时感知的时空场景，是实现“全真互联”的技术基础。</p><p></p><p>直播、点播、RTC作为通用产品和能力正在逐步向传统行业渗透。在未来虚拟与数字的世界中，视频云技术方案会持续迭代，实现融合更多AI技术特征、打造中心与边缘协同的基础架构，来打造极致高清、极致交互、极致沉浸的视频云。以腾讯云音视频云解决方案为例，腾讯正在以音视频通信基础网络、音视频通信PaaS产品线以及针对垂直场景的联合解决方案为核心，云上赋能音视频领域。</p><p></p><p>IDC数据显示，过去三年，中国视频云市场年均复合增长率保持在40%以上。腾讯云副总裁李郁韬认为，沉浸式交互、全球化、数实融合是未来音视频的三个发展趋势。首先，云厂商需要构建高性能的音视频通信、编解码和媒体处理技术；其次，伴随着中国企业出海的需求，云厂商需要做全球化的产品定位和设计；最后，视频云厂商开始关注传统行业数字化转型的需求，音视频技术开始助力实体经济安全提效。</p><p></p><h4>趋势二：云原生技术将全面支撑数据产业发展，大数据为实体经济创新提供强力引擎</h4><p></p><p></p><p>伴随数字经济的发展，尤其是产业数字化进程的加速推进，基于数据进行决策将成为未来企业的常态。根据IDC数据，到2026年，全球大数据市场的IT总投资规模将增至4491.1亿美元，实现约15.6%的复合增长率。</p><p></p><p>实体经济的发展离不开数据支持，<a href=\"https://www.infoq.cn/article/N8u6idtvtt9jgTPhaaV8\">云原生技术</a>\"将全面支撑数据产业的发展，数据治理、数智融合以及隐私计算的价值将被持续放大。数据将成为实体经济创新的燃料。腾讯云大数据将结合数据治理、数值融合和隐私计算，增强数据价值，助力实体经济的创新发展。</p><p></p><h4>趋势三：云智能后端平台与前端应用将衍生全新应用场景，推动产业智能化发展</h4><p></p><p></p><p>IDC数据显示，全球人工智能IT总投资规模在2026年将增至3014.3亿美元，五年复合增长率(CAGR)约为26.5%。人工智能赋能产业正成为主流发展趋势。人工智能将加速推动产业智能化发展，未来将基于场景衍生出全新的应用。</p><p></p><p>人工智能后端加速落地，衍生细分行业AI应用开发平台及高效模型生产工具；前端向多模态、高拟真、泛场景发展，将为用户提供真实、智能、专业的交互体验。在此背景下，腾讯云智能将融合全栈式人工智能开发服务平台与丰富的产品矩阵，运用已有沉淀IP资产，加速后端落地，衍生细分行业AI应用开发平台及高效模型生产工具。</p><p></p><p>腾讯云TI平台在原有的机器学习平台<a href=\"https://www.infoq.cn/article/k6cNeW7HiT7WAJQrAIRF\">TI-ONE</a>\"、AI应用服务平台<a href=\"https://www.infoq.cn/article/xGRkyswP9T99qDUpI8pE\">TI-Matrix</a>\"、数据标注平台TI-DataTruth三大能力平台基础上，全新发布腾讯云智能工业质检训练平台TI-AOI、腾讯云智能媒体内容中台IMCP两大能力平台，为工业质检、传媒行业转型提供了全新的、更加有效的解决方案。</p><p></p><p>腾讯云副总裁、腾讯云智能负责人、优图实验室负责人吴运声表示，随着数字化转型进程不断加速和技术应用场景的多元化，腾讯云智能在将技术落地不同产业时会面临越来越多的挑战。未来，腾讯云TI平台将持续升级，不断将平台做厚、行业做深、应用做精、生态做广，为行业合作伙伴提供优质、高效的数智化转型服务。</p><p></p><h4>趋势四： 事件驱动、合规驱动和技术驱动的安全服务将从单点走向“全域”</h4><p></p><p></p><p>在产业互联网飞速发展的背景下，安全问题不再是单一企业需要关注的问题，而是整个产业层面乃至于整个实体经济需要关注的问题。每一个企业都需要立足产业链角度，围绕各类业务场景，针对性地构建“全域”安全防御体系。</p><p></p><p>安全是产业数字化的底座；事件驱动、合规驱动和技术驱动是安全领域发展的关键动力。安全服务将深度融合业务场景，单点安全将走向“全域”安全，局部安全将走向“生态”安全。</p><p></p><p>“客户的安全需求如何得到满足、更好地抵御风险，这其实是我们做产品的第一出发点。另外，腾讯安全一直都非常重视生态体系的发展，在生态领域，我们强调三个比较重要的理念：细分能力、服务生态和被集成生态，我们所有的基于生态的思考，都是抱着共同建设、健康可持续的理念去实施的。”腾讯安全副总裁杨光夫表示。</p><p></p><h4>趋势五：基于云原生技术的云上数据库将成未来主流，为数实共进、产业创新提供关键支撑</h4><p></p><p></p><p>IDC数据显示，关系型数据库在中国数据库总体市场中的占比超60%。到2026年，中国关系型数据库软件市场规模将达到90.1亿美元。同时关系型数据库正向着分布式、 云原生、HTAP方向发展，到2026年，基于公有云的云上数据库市场规模将达到64.8亿美元，是的线下关系型数据库的2.5倍。线下部署的数据库仍有增长空间，基于云原生技术的云上数据库将成为未来主流。</p><p></p><p>同时，在数据与实体经济融合的过程中，作为数据管理的核心软件，数据库架构的先进程度将直接影响企业数字化转型的效率。未来具备弹性扩展、弹性部署、计算存储分离以及数据安全的云原生数据库将是企业数据库架构发展的必然趋势，也将为数实共进与产业创新提供关键支撑。</p><p></p><p>“在数字化的时代，作为基础软件，数据库自主可控对于企业整个的数据安全、业务稳定具有重要意义。我们只有具备这种自主可控的全方位能力后，才能践行这一个大的战略和服务。这也是一个从软件到硬件，从人才到服务上全方位的一个体现”，腾讯云副总裁刘颖表示。</p><p></p><h4>趋势六：账号连接、数据连接和业务线上化打通数字化里程“最后一公里”</h4><p></p><p></p><p>在企业数字化转型进程中，普遍存在的问题是SaaS系统间流程不畅通、数据不同步等问题。应用连接器将成为打破部门深井、提升企业效率、加速产业发展的关键组件。企业采用从账号到数据再到业务的SaaS应用连接器，打通业务应用，才能降低内耗、轻装上阵，并发挥出SaaS应用的核心价值。</p><p></p><p>开放API将实现账号连接、数据连接和业务线上化，手握数字化“最后一公里”的钥匙，可以连通账号、数据和各类线上应用模块，从而将以往割裂的场景对接起来。腾讯云应用连接器通过发挥腾讯的技术优势、C2B的触点优势以及生态优势，打通了更多场景，连接更多企业，进而推动产业互联网发展。</p><p></p><p>腾讯云副总裁答治茜认为，随着企业应用的SaaS数量越来越多，连通性会越来越重要。腾讯云希望通过一系列的连接器产品，实现自动化的连接，SaaS厂商也不用背上交付的包袱，企业无需点对点去打通产品。比如，通过腾讯云数据连接器（iPaaS），企业可以实现分钟及集成、无代码连接；通过HiFlow，非IT运维人员也可以快速连接起不同SaaS，实现工作流程自动化。</p><p></p><h4>趋势七：数智驱动的一体化CRM将成为数字化营销主流趋势</h4><p></p><p></p><p>数字化营销软件是企业实现用户精细化运营的必备应用，而CRM更是营销自动化系统中的核心。根据IDC数据，2021年中国数字化营销应用软件市场规模达到3.4亿美元，同比增长35.8%。IDC预计，到2026年，中国数字化营销应用软件市场规模将达到14亿美元。</p><p></p><p>一体化CRM将成为数字化营销主流趋势，是应对千人千面用户需求，提升全触点、全场景 与全渠道运营的“最佳利器”。数据驱动营销创新，营销拉动业务增长，业务推动企业发展，营销服务将为实体经济腾飞提供正向循环。以用户为中心的全触点、全场景、全渠道的营销服一体化将成为数字营销新趋势。</p><p></p><p>腾讯企点产品部副总经理张晔表示，和传统CRM相比，企点CRM企点提供连接、数智化运营、业务协同三个方面核心能力的升级。充分运用云计算、大数据、人工智能、实时音视频、云呼叫中心等通讯技术、社交工具，助力企业跟客户及上下游伙伴建立全面深入的数字化连接，并通过数智化、精细化、营销服一体化的全旅程运营，感知客户需求，创造个性化体验，提升从营销获客、销售转化、交易协同、售后服务到复购增购的效能。</p><p></p><h4>趋势八：视频会议将成为协同办公的核心抓手，解决“空间、终端、应用”的互联互通问题</h4><p></p><p></p><p>未来，协同办公将成为未来企业的新常态，也是提升产业效能的利器。协同办公是未来办公的必然趋势，协同办公的本质是时空协同、终端协同和应用协同。</p><p></p><p>未来企业的协同办公将突破以流程为驱动的协同模式，转变为基于视频会议为抓手的全方位协同模式。不仅突破时空限制，而且通过开放诸如智能语音识别、语义识别、实时转写等各类功能的API接口将极大提升会议效率，在全面赋能会议沟通的同时打通与线上协同文档、日历、项目管理、IM、邮箱等在内的各类应用，真正实现“空间、终端、应用”的互联互通。</p><p></p><h4>趋势九：数字孪生将为数实协同发展的新技术桥梁，激发产业价值，助力场景创新</h4><p></p><p></p><p>从“以虚仿实”到“虚实共生”， 数字孪生将为数字世界和实体世界协同发展的新技术桥梁。数字孪生从全真映射、仿真维护到反馈控制逐层发展，借助实时时空计算、泛在连接、数据驱动等特征，数字孪生能够在建筑、交通、园区、城市、工业等领域凭借更泛在的感知、更快速的网络和更智能的计算不断推动智慧建筑和智慧交通的发展。</p><p></p><p>在数字孪生逐步成熟的过程中，需要提升对物理世界感知的精准性、数据传输的实效性、大规模高并发的可承载性、智能计算以及与行业经验的结合程度等，从而更好地激发产业价值，助力场景创新。</p><p></p><h4>趋势十：云原生作为数字化转型的新底座，已经成为企业上云的默认选择</h4><p></p><p></p><p>中国云计算行业已经进入到下半场：云原生架构凭借模块化、可部署、可测试、可替换等特征和敏捷基础架构和简化运维，已经成为云计算行业下半场的主力。随着包括工业数字化、交通数字化、零售数字化等产业的发展，云原生开始以分布式云形态对外呈现，变得无处不在。</p><p></p><p>云原生作为数字化转型的新底座，已经成为企业上云的默认选择。未来新生互联网企业或将完全云原生化，云原生的理念、技术架构和开发范式将真正让企业实现“云上生长”。未来，腾讯云原生的统一资源池与调度技术将改变传统的本地化开发运维模式，从开发、计算、架构、数据和安全云原生五个发展阶段持续优化，带来极致的研发效率。</p><p></p><p>纵览十大技术趋势，数字化的能力在越来越多的行业和场景落地。产业互联网所带来的已经不仅仅是单一环节的度量与优化，还有多环节的融通，以数据激活产业模式创新。</p><p></p><p>未来，在行业数字化转型、产品短期快速迭代的现状下，企业更需要通过敏捷开发模式为行业发展寻创新、为生态发展拓空间，顺应云上发展潮流与政策利好，实现数字经济与实体经济高效融合，助推数字经济高质量发展。</p>",
    "publish_time": "2022-11-30 16:38:48",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "迈向多云时代：TT 多云架构演进与实践",
    "url": "https://www.infoq.cn/article/Y8FO3IWlVQw9Q0cm9zqO",
    "summary": "<p>随着云计算产业的发展，<a href=\"https://xie.infoq.cn/article/5f4f70f38017f2ba81a82ea50\">云计算</a>\"概念的普及和人们对云计算技术认知的加深，企业开始对云计算服务有了更多的要求，<a href=\"https://xie.infoq.cn/article/6a7c6814342365f2bc4653c26\">上云</a>\"也就成为现在很多企业的刚需，致使越来越多的企业开始架构转型。对于企业来说，业务呈现多元化、多地域、全球化的发展趋势，多云管理能很好地利用单个云的优势、某个云特有的云服务，也能很好地避免服务商锁定，企业还能根据业务、技术及性能等需求动态调整多云部署的策略，因而多云就成为了很多企业的首选解决方案。</p><p>&nbsp;</p><p>但是企业在实现多云架构的过程中依然面临很多挑战：如何解决多云厂商带来的管理复杂性问题；如何实现多云互联互通的网络方案；企业应用部署策略与多云容灾；多云可观测与安全问题等。</p><p>&nbsp;</p><p>本文整理自趣丸科技（TT语音）资深架构师黄金在<a href=\"https://qcon.infoq.cn/2022/guangzhou/\">QCon广州大会</a>\"演讲分享，主题为“<a href=\"https://qcon.infoq.cn/2022/guangzhou/presentation/4796\">迈向多云时代——TT 多云架构演进与实践</a>\"”。</p><p>&nbsp;</p><p>本次分享主要分为四个部分展开：第一部分介绍TT 上云的发展历程，第二部分讲多云的优势与挑战，第三部分分享TT 多云解决方案，第四部分是未来展望。</p><p>&nbsp;</p><p>以下是分享实录。</p><p></p><h2>TT 上云的发展历程</h2><p></p><p></p><p>TT的云端架构的发展粗略分为三个阶段，第一阶段，我们叫单云时代。第二阶段多云1.0。第三阶段多云2.0，但是这三个阶段不是相互割裂的，会有一定叠加。举个简单的例子，到目前为止我们还有一些服务处在单云时代，但同时还有很多服务已经处在多云2.0阶段，每个阶段都有它自己的一些特点。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9c/9c30c16a48795ab00545ea0803b8f72f.png\" /></p><p></p><h3>单云时代的架构</h3><p></p><p></p><p>单云时代是企业发展的初期，主要追求的是能够快速部署，快速实现，方便管理。它的特点也比较明显，所有的基础设施都在一个云里边，然而缺陷也比较明显，业务的稳定性很容易受到单个云服务商的稳定性影响。我们至少经历过4次由于云服务商升级底层网络，或者底层基础设施人为操作故障，导致整个业务的大规模受损。随着业务的发展，我们开始对云服务商的产品特性、功能以及成本有了更多的要求，引入了其他云服务商，就发展到了多云1.0时代。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/57/5739e6233836ca3aaeb30a4c6c5faf8a.png\" /></p><p></p><h3>迈向多云时代</h3><p></p><p></p><p>多云1.0时代相比单云时代也有一些特点。它在业务层上实现了一个<a href=\"https://www.infoq.cn/article/NhjgdVJTH98kBYH6fdHU\">多云容灾</a>\"。我们把业务拆分后部署在多个云上，这样单个云的故障对业务层的影响就会减弱，但这时候状态层没有做分离。做过多云、多活的都知道，状态层的分离是比较复杂的，也会给后期的维护带来困难，所以我们当时并没有在状态层去做分离。流量入口是通过固定比例去调配的，一般方式就通过DNS轮训，或者是按云服务接入商的固定比例分配。这样业务层上的失败只会影响固定比例的流量，但是状态层失败，依然会导致全部失败。随着企业不断发展壮大，我们对区域、容灾、稳定性有了更强的需求，就在多云1.0的基础上对业务架构进行了改造，从而产生了多云2.0。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fd/fd52531e294575a403f9bb311a9514d1.png\" /></p><p></p><p>相比多云1.0，多云2.0的主要的特点是在入口上做了智能调度。流量不再按照之前的方式，通过固定比例分发到某一个云。现在是通过智能调度去做健康检查，动态地剔除故障节点，保证流量始终到达健康的节点上。同时我们在状态层也做了分离，对一些稳定性要求比较高的业务来说，状态层不分离始终是个故障点。我们通过现在比较流行的云原生数据库对状态层做了分离，比如<a href=\"https://xie.infoq.cn/article/abaa474a3b5ffa3ca8907e706\">TiDB</a>\"、<a href=\"https://xie.infoq.cn/article/8002a6d92de0723a5ddacc7ec\">OceanBase</a>\"等为状态层分离带来了极大的简化，这些数据库支持跨机房的数据同步，实现起来很方便。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/82/82164a967d0526266f3055835aed82ac.png\" /></p><p></p><h2>多云的优势与挑战</h2><p></p><p></p><h3>多云架构的优势</h3><p></p><p>多云的优势总结为四个方面，稳定性，成本，创新和发展。从稳定性上说，多云能够很好地分散风险。我们能够做到多云、多活，单个云故障基本不会影响到业务。从成本上说，每个云厂商都有自己的一套定价模型，他们的产品可能相同，但价格不一样。多云可以让我们避免被云厂商锁定，可以在成本上有更加灵活的选择。一般情况下，性能一致肯定选成本最低的。成本一样肯定会选择性能最好的。从创新上说，每个云厂商都有自己的一些特色功能，或者是一些创新特性，多云可以让我们在多个云厂商之间取长补短，将这些创新点、特性应用在自己的产品上，提升产品在市场上竞争力，实现优势叠加。最后从发展上看，现在应用出海全球化已经形成趋势，大家都在做全球化，多云可以让我们灵活地选择部署区域，不受限于某个云厂商的服务能力，部署不会受限于某个区域，从而为全球化提供了助力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f1/f163c0bc2f311fc2b3c4fccda21642bf.png\" /></p><p></p><h3>多云环境以及异构的基础设施带来的挑战</h3><p></p><p></p><p>跨云互联互通。首当其冲的跨云问题就是的互联互通。在单个云的时候，联通性问题一般云厂商会帮我们去解决，而一旦跨云后就需要我们协调各供应商，共同去解决联通性问题。</p><p>&nbsp;</p><p>2.跨云应用管理问题与流量控制。第二个问题是跨云应用管理与流量控制问题，我们有多个云了，应用在多个云之间怎么去部署，流量在多个云之间怎么去做调度？</p><p>&nbsp;</p><p>3.异构基础设施带来的监控、管理问题。每个云厂商的产品都不尽相同，即使是相同的产品线，默认参数、配置也不尽相同，这都提高了后期问题排查的复杂度。</p><p>&nbsp;</p><p>举一个比较简单的例子，我们<a href=\"https://www.qingcloud.com/products/container?utm_source=baidu&amp;utm_campaign=A-%E4%BA%A7%E5%93%81-%E5%AE%B9%E5%99%A8&amp;utm_content=%E5%AE%B9%E5%99%A8%E4%BA%91-kubernetes&amp;utm_term=kubernetes%E9%9B%86%E7%BE%A4&amp;source=AD&amp;bd_vid=12174746618027694810\">Kubernetes集群</a>\"用得比较多。有一次我想统一公司内部所有的Kubernetes版本，把它统一到某个具体的版本上，但我发现根本就做不到。因为国内的云厂商有的是单版本发布的，比如1.19，1.21发版；有的是双版本发布的，比如1.20，1.22发版，这就导致永远没办法去做统一。</p><p>&nbsp;</p><p>4.多身份识别问题。每个云厂商都有自己的一套账号体系，账号体系完全没有相同性可言，而且有些产品没办法通过自己的平台管理，只能登到云厂商的平台上去管理。这时候就带来一个问题，有时候我们为了排查一个问题需要登录三个云厂商的平台，执行三种完全不同的操作，才能找到问题所在。</p><p>&nbsp;</p><p>举个例子，我们LB用得比较多，很多云厂商LB的日志是不能被用户采集的，但业务又要我们排查问题，这就只能是登陆每个云厂商平台，去看他们LB的日志，排查出问题，业务也觉得这个地方很烦琐。同时，管理三个云厂商账号，在人员离职、入职时也非常麻烦。还有像安全问题，我这里就不一一列举了，毕竟今天主题是多云，不是多云劝退指南。</p><p>&nbsp;</p><p>多云有优势也有挑战，我们应不应该选择多云？还是应该只用单云？单云的话如何解决容灾问题……归根到底还是那句话，“没有银弹。”在追求极端可用性的路上一定会带来极端的复杂度，企业要根据自己的实际发展阶段，选择适合自己的模式，不要一概而论。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b9/b99fa355de819dee9b86c1871909a7b7.png\" /></p><p></p><h2>TT 多云解决方案</h2><p></p><p></p><p>面对上述这些挑战，结合自己的思考，我们给出了一些解决方案。主要分为三个小节，第一个是多云互联互通的问题，第二个是应用管理流量控制，第三个是在跨云可观测性上的一些实践。</p><p></p><h3>多云互联互通的基础网络方案</h3><p></p><p></p><p>应对多云互联互通问题，这里分享两个方案。第一个是基于多云骨干网络建设的方案。第二个是南北向流量和高可用方案。</p><p></p><h4>基于多云的骨干网络建设</h4><p></p><p></p><p>骨干网络建设，传统的基于静态路由表的方式有什么问题呢？假设有三朵云ABC，每一朵云都有一个网段，为了实现这三朵云的互联互通，一般来说需要在每个云的接入点上配置每个网段的下一跳，通过静态路由表方式配置。假设A到B之间的物理专线断开了，那么A到B还能不能通呢？从图上看是可以通的，可以从A绕到C再到B。但实际上是不通，因为静态路由已经配置好了，178的下一跳就是B。怎么才能让它再连通起来呢？只能去改路由表，把B的下一跳改为C，从C绕到B。这种需要人为操作才能恢复的故障，极大增加了故障发生时的恢复时间。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b5/b5d005757a1955b30795d00918216125.png\" /></p><p></p><p>我们的解决方案是，把整套骨干网络基于动态路由表的方式实现。它的特点就是动态发布，动态学习。我们在每个区域上都做了一个自制体，就是AS，每个AS都有一个不同的AS号，每个AS都有一个<a href=\"https://xie.infoq.cn/article/1e0cb88c793870fdbd0201fd2\">BGP</a>\" Speaker，接入到骨干网络的BGP平面，每个BGP Speaker负责自治体内的所有VPC网段发布到平面上，其他的BGP Speaker就可以动态学习到这个VPC的路由。</p><p>&nbsp;</p><p>这样做得好处是，虽然路由表和刚才一样，但是它的性质已经完全变了，它是动态的，不需要手动配置了。静态路由表的特点就是，静态配置的路由的优先级最高，断开之后它没办法学习到新的路由。而现在动态路由就可以了，通过<a href=\"https://xie.infoq.cn/article/85f51d38d230439f320cf1785\">BFD</a>\"去做检查，可以在10秒内发现专线断开，然后就可以更新路由表，学习到新的路由。我们用的是EBGP，他特点是每一个BGP Speaker都会将自己学习到的所有路由广播出去。当B断开的时候，A就能从C学习到B的路由，通过多边专线绕行，从而保障业务的高可靠。这个方案除了能够实现多边专线绕行，还方便我们管理。</p><p>&nbsp;</p><p>举个例子，在多云的情况下，经常会出现一种调整策略，比如说在一个云部署得多，在另一个云部署得少。比如在A云增加了一个网段，之前的方式就需要在每个接入点手工配置，而现在只需要加进去，让BGP去管理新的网段，最后把路由发布到BGP平面上，其他的BGP Speaker就可以学习到这个路由，从而实现了互通。整个的VPC的初始化可以缩短到几分钟以内。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/99/993f456b508aa83d797b278a541b59b8.png\" /></p><p></p><p>接下来看一下实际骨干网络建设，看起来比刚才的那张图要稍微复杂一点。因为有了动态路由，我们主要围绕两个方面去做。第一个就是全球一张网的目标，能够实现多云能力的公用，让我们灵活选择部署区域。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b8/b86137b08bbb6e63df2aed383d7651de.png\" /></p><p>第二个就是我们做了多级链路冗余，动态路由能实现多级备份。我们在整个骨干网络平面上又做了一套VPN的数据面，如果整个物理专线全部断开，重要的流量依然可以走VPN链路，保证重要的业务不会中断。有人可能问，已经做了三角专线了，而且可以实现动态绕行，为什么还需要做VPN数据面呢？这是个惨痛的教训。国内某云厂商在配置我们的BGP平面的时候做了一个操作，输入了一个S。这个S命令相当于shutdown，导致整个网段全部中断。虽然BGP可以简化配置，但BGP配置却成为了瓶颈，一旦有人配置错将引发很大的灾难，而且恢复时间比较久。所以我们就在物理专线上又做了个VPN数据面，通过这种明细路由加聚合路由的方式，对路由做优先级，优先走专线路由，当专线路由消失的时候，就走VPN路由。在物理专线全断的情况下，保障重要流量依然能够走VPN的专线。</p><p></p><h4>南北流量高可用方案</h4><p></p><p></p><p>我们做了多云、多入口，也做了多活，那么用户的流量怎么到达服务呢？这就是南北向流量高可用的问题了。怎么找到入口？常见的方式比较简单，就是DNS。DNS的目前的做法有三种，主备域名、HTTP&nbsp; DNS，以及智能DNS，智能DNS现在比较流行。我们基于自己的业务情况选择了后面两种。考虑的主要是两方面，一方面是灵活度高，HTTP&nbsp; DNS它可以绕过Local&nbsp; DNS，对于那些要求很高的，比如说账户系统就要接入HTTP&nbsp; DNS。其他的业务接入智能DNS。相比HTTP&nbsp; DNS，智能DNS的好处是，它的改造对业务是无感知的，可以在业务完全不需要任何改造的情况下，接入智能DNS，实现故障节点剔除以及主备切换。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/21/21708ff2f289ae2452d2d3cbdea27041.png\" /></p><p></p><p>接下来看一下具体情况。刚开始DNS的整个入口是通过智能DNS解决互联网层、接入层多活以及主备切换的问题。智能DNS它可以做多种形式的健康检查，比如说7层的、4层的，通过健康检查，我们可以实现故障节点的自动剔除。除了这个方案，我们还有一套方案就是HTTP&nbsp; DNS，对于一些可用性要求高的，或者是一些重要的业务，都会要求他接入HTTP&nbsp; DNS。HTTP&nbsp; DNS也是业界比较成熟的方案，SDK也比较多，安卓跟iOS都有相应的SDK，接入SDK就可以实现绕过运营商的Local&nbsp; DNS，防止域名劫持和封堵问题。</p><p>&nbsp;</p><p>业务通过DNS之后是直接到达服务吗？肯定不是，因为还会有攻击的风险，所以下面还需要有一套高防。说到高防，我们采用本地原生高防加异地大流量高防的一套组合方案，我们叫高防的阶梯调度实现的，为什么需要这样去做？因为本地高防的特点是，它的流量比较小，比较便宜，云厂商都自带了，但它可能只能扛10~20G的流量，而异地大流量高防的流量一般比较大，一般都是TB级别的，但本地高防是走内网到达服务的，没有公网带宽的消耗，同时它时延也比较低。我们是的做法是优先本地高防，低延时和低成本。在受到攻击时，通过智能DNS的调度能力把流量调度到异地高防，通过异地高防清洗后再到达业务，实现业务的高可靠性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/962ce0de71db740773a34104ccd34ef3.png\" /></p><p></p><p>&nbsp;我们具体来看这套高防的调度方案。流量有两条路径，默认是正常的用户访问和日常的小流量攻击，智能DNS都会把它调度到默认的原生高防上，原生高防负责防护，最终流量会到达业务服务。当遭受海量攻击时，智能DNS检测到这个本地原生高防IP被封堵后，就会通过改CName的方式，将攻击流量引向异地的大容量高防，通过大流量高防进行清洗，最终业务流量到达服务的时候是没有什么风险的，可以保证遭受大量攻击的时候依然满足业务的高可靠性。这是将低成本、低时延和业务可靠性的多重结合。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0c/0ca1a13ccd268545b1dc31d27362ee68.png\" /></p><p></p><h3>基于 Kubernetes 和 lstio 多云流量调度与容灾方案</h3><p></p><p></p><h4>Kubernetes 多集群管理方案</h4><p></p><p></p><p>接下来介绍下多云应用的管理与流量控制。我们的整套方案就是基于Kubernetes和Istio实现的多云的流量调度与容灾方案。我这里分享两个方案。第一个是Kubernetes多集群的管理方案。第二个是基于Istio做的跨Region，跨Zone的东西向流量调度的方案。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/19/19e6394019b0e4bdeb2ac30acb6f873d.png\" /></p><p>第一个方案，Kubernetes的多集群管理。我们的Kubernetes是单云的，要求是做跨Zone部署，但国内可能和海外不太一样，海外的先不提。我们的应用是通过CI/CD直接发布到多个Kubernetes集群的，每个Kubernetes集群是完全独立的。这里可能和一些企业不太一样。有些企业可能是每个Kubernetes是单个Zone的。我们这样做是因为，如果一个Kubernetes一个Zone，那么所有有Zone容灾需求的业务就要部署到多个Kubernetes集群，中间可能还涉及业务改造，这就增加了管理的复杂度。</p><p></p><p>第一个方案，Kubernetes的多集群管理。我们的Kubernetes是单云的，要求是做跨Zone部署，但国内可能和海外不太一样，海外的先不提。我们的应用是通过CI/CD直接发布到多个Kubernetes集群的，每个Kubernetes集群是完全独立的。这里可能和一些企业不太一样。有些企业可能是每个Kubernetes是单个Zone的。我们这样做是因为，如果一个Kubernetes一个Zone，那么所有有Zone容灾需求的业务就要部署到多个Kubernetes集群，中间可能还涉及业务改造，这就增加了管理的复杂度。</p><p></p><p>第一个方案，Kubernetes的多集群管理。我们的Kubernetes是单云的，要求是做跨Zone部署，但国内可能和海外不太一样，海外的先不提。我们的应用是通过CI/CD直接发布到多个Kubernetes集群的，每个Kubernetes集群是完全独立的。这里可能和一些企业不太一样。有些企业可能是每个Kubernetes是单个Zone的。我们这样做是因为，如果一个Kubernetes一个Zone，那么所有有Zone容灾需求的业务就要部署到多个Kubernetes集群，中间可能还涉及业务改造，这就增加了管理的复杂度。</p><p></p><p>同时我们还有些不好的回忆。由于我们大量使用了集群伸缩的能力，每天晚上可能一下弹出40~50台机器，是比较正常的。这中间有个问题经常出现，就是某个云厂商的单个可用区没有机型了，弹不出来，会导致业务因为负载问题受损。我之前也做过单云单Zone的方案，但是我现在更偏向于采用单个Kubernetes集群，多个可用区的方案。我们一般的要求是单个Kubernetes集群至少有3个可用区。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/98/98d8739f76813a0592372dfb1c736ed4.png\" /></p><p></p><p>Kubernetes集群相互独立了，怎么做部署在多个Kubernetes集群上的应用管理呢？不可能每Kubernetes都去看，普遍的解决方案是采用多云管理平台。业务通过多云管理平台就可以实现跨集群部署应用的统一管理。</p><p></p><p>为什么我们没有用跨集群的管理工具呢？因为我用Kubernetes的时间也比较久了，大概从16年就开始接触，当时Kubernetes的版本是1.9。多集群的跨集群管理工具其实比较多，我们之所以没用主要是基于三个方面的考虑。第一方面是，我们没有跨集群调度的强需求。我之前做过一个方案，就是一个Kubernetes集群全部倒了，把业务都调度到另一个集群里面，中间遇到的问题比较多，特别是一些状态层的依赖等。解决这个问题，可以采用多集群部署。这个对我们来说并不是一个很强烈的需求，因为现在弹性能力都比较强了。我可以部署一个副本，当流量切过来时，可以通过大量扩缩容增加副本数，让业务能经受起突然到来的流量。</p><p></p><p>第二个问题就是满足一定的隔离性。我做了Kubernetes和Istio好几年了，目前没有经历过升级后整个集群全部搞挂的情况，但是云厂商会这样干的。我们在某个云厂商升级过一个集群，他告诉我，你点击一下就可以升级了。我点了一下，整个集群全挂了，所有的业务都无法访问。最后他们告诉我有Bug，这样老板肯定就不乐意了，肯定要来批评我。所以我觉得一定的隔离性还是需要的，尤其是在日常维护集群的时候，隔离性是“保命”的必备的技能。</p><p></p><p>第二个问题就是满足一定的隔离性。我做了Kubernetes和Istio好几年了，目前没有经历过升级后整个集群全部搞挂的情况，但是云厂商会这样干的。我们在某个云厂商升级过一个集群，他告诉我，你点击一下就可以升级了。我点了一下，整个集群全挂了，所有的业务都无法访问。最后他们告诉我有Bug，这样老板肯定就不乐意了，肯定要来批评我。所以我觉得一定的隔离性还是需要的，尤其是在日常维护集群的时候，隔离性是“保命”的必备的技能。</p><p></p><p>第三个问题是，虽然Kubernetes集群推出好久了，但是多集群管理还没有一个实际的标准。比如说Kubernetes社区有Fedora，V1、V2也出了。我之前用V1，我当时觉得挺好使的，用着用着，社区说V1不要了，要搞V2。可能各个方面的诉求不一样，导致Kubernetes社区，第三方社区有很多方案。我建议将来如果有了统一的实际标准后，再迁移到多云管理上。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2d/2d89630da2e729bed68e5ac8db902970.png\" /></p><p></p><h4>基于 Istio 的跨 Region Zone 的东西向流量调度</h4><p></p><p></p><p>下面要讨论的问题是多集群的流量管理。我们基于<a href=\"https://xie.infoq.cn/article/037880aa6a357444478cfbe8d\">Istio</a>\"做了一套东西向流量管理方案，Istio集群的组建方案也比较多，我们选择的方案是在同一网络下的多主架构，这个架构也是我用的最多的一个方案。每个<a href=\"https://xie.infoq.cn/article/037880aa6a357444478cfbe8d\">Istio</a>\"都能发现其他所有集群的<a href=\"https://mp.weixin.qq.com/s?__biz=MzI5ODQ2MzI3NQ==&amp;mid=2247509405&amp;idx=1&amp;sn=30a4f75d99bf9ac57ef6841354412a5f&amp;chksm=eca79cd9dbd015cf1a0b622a486b5eb36b8758277ef51d37c7916978b0b4ee878418448c3919&amp;scene=27#wechat_redirect\">Service&nbsp;endpoint</a>\"，通过xDS把其他集群的Service&nbsp; endpoint下发给本集群内的Sidecar，让应用可以跨集群访问其他集群的服务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a4/a4f9a0a22ea3f4d1df4c8b2b577e224a.png\" /></p><p></p><p>流量遵循的调度原则是什么呢？原则就是本地优先，这样的好处是时延最低，同时能满足一定的容灾性需求。做法是优先本Region本Zone，本Zone失效之后再去访问其他Region的其他Zone。所有的本Region失效后，才会去访问其他的Region。这就是我们整个的流量调度方案。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e1/e1e52cdec00efb2c71559dd8b3b7f127.png\" /></p><p></p><h3>跨云可观测性实践</h3><p></p><p></p><p>有了基础网络，以及应用层流量的高可用的方案，就可以认为这套方案是高可用了吗？业务提出了一些疑问，为什么这个IP到另外一个IP不通呢？怎么解决？这就需要一个可观测平台去解决，能够提前的去感知问题，发现问题。我们在可观测平台上踩过一些坑，这里主要分享两个方面。第一个是我们在跨云基础网络质量与可靠性检测上的一些方案，另一个是多云可观测平台的搭建思路。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5d/5db342eb9e42d20aefc27144438b5d17.png\" /></p><p></p><h4>跨云基础网络的质量与可靠性检测</h4><p></p><p></p><p>为什么要做跨云基础网络质量与可靠性检测？一旦跨云，云厂商的很多设备对我们来说都是黑盒，没办法去做深入监控。但是我们需要解决两个问题，第一个问题是通不通，业务问我这个网段到另一个网段为什么不通？第二个是质量问题，有没有时延、丢包、重传等。</p><p></p><p>1.通不通。这个问题有可能是天生的，比如网络域隔离，生产和测试要隔离。不能说要通它就会通。还有ACL的一些配置，BGP还有一个比较复杂的问题是缺路由，而且排查起来比较复杂。</p><p></p><p>2.质量问题。我们遇到的问题主要是MTU配置错误，某云厂商把MTU配置错了，结果大包一直发不出去，还有一些网络配置和一些专线容量问题。我们告诉业务，我们做了一套高可用的方案，怎么证明它高可用？业务出现了故障了，能不能先于业务之前去发现？我觉得一个很核心的问题就是在业务发现故障前，提前去感知问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/46/46e9e77165b31c18c9f7d266481997a6.png\" /></p><p></p><p>我们做了一个基于拨测的可观测平台。这是在经历过几次云厂商硬件故障，而我们又没法感知的情况下做出来的一套方案。整个拨测通过中央Servier集群，向部署在各个VPC、各个Region、各个Zone的Agent下发Target配置，Agent会根据Target配置Ping。Ping不是简单的Ping协议，还做了一些TCP层面的检测，之后把这些检测数据上报到Prometheus，从而实现任意VPC之间的连通性与质量拨测。它的缺点也比较明显，它只能实现端到端的拨测，并没有办法完全做到任意两个IP之间的网络质量监测。这套方案是不是很像PingMesh？PingMesh是我后来才知道的一个概念，我之前不太了解。我们现在也在向PingMesh的方向上去演进，通过PingMesh去检测多云之间的网络质量。</p><p></p><h4>多云应用可观测平台搭建思路</h4><p></p><p></p><p>关于多云可观测平台搭建的思路，说起来都比较简单，这里主要分析我们踩过的坑。在多云环境下可观测平台跟单云有什么不一样？主要问题是多云会涉及跨专线传输，而专线比较昂贵，成本很高；还有不同网络区域的稳定性问题，一旦跨专线了，时延就没办法很好保证。可观测平台的数据有个特点，写入量很大，实际查询量却很少。可能90%的数据根本就不会查，业务出问题了才会上去察看一下，所以大量的写流量都走专线不合适。我们的思路是就近存储，跨专线查询。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9f/9feac480a4e53ff2596d07a3481ff61b.png\" /></p><p></p><p>如图所示，我们通过Agent收集本集群内的Pod日志，存储到本云上。通过查询调度器再去根据比如说分集群、分区域查询日志，让查询走专线。这个里面我们也遇到了问题。最开始时日志采集是集中的，所有的日志都是跨专线的，我们的物理专线大概有10G，平时日志占了大概3G，当时我也觉得没什么问题，毕竟剩余还有7G，够用了，但还是出问题了。我们之前做了一个VPN备份物理专线的方案，中间做了个演练，就是把整个物理专线全部断掉，重要的流量都走VPN，但是日志不算重要，所以没走。切过去的时候没有问题，但切回来的时候就出现问题了，这个日志积累了大概半个小时的数据量，疯狂地去抢占物理专线，由于物理专线完全没有流量控制能力，从而导致业务流量受损。</p><p></p><p>最后看一下整体架构。最上层通过智能DNS做多入口的多活以及主备的切换，同时通过健康检查实现对故障节点的自动剔除。接下来就是高防层，通过DNS的智能调度能力，结合本地高防加云原生高防，实现了一套阶梯调度的方案，能够满足低成本、低时延的要求，同时又能保障业务的稳定性。经过高防的清洗后，流量就会到达企业内部，企业内部采用多Kubernetes集群，通过Istio连成一个Mesh，所有的istiod都能发现其他集群的Service  endpoint，通过xDS下发给自己集群内部的Sidecar，Sidecar实现跨集群的流量调度以及容灾。</p><p></p><p>最下面一层就是状态层的同步，做了跨数据中心、跨云厂商的DB的同步，采用了TiDB等比较常用的方案。这套集群走到了今天，还在持续演进，没有一个方案能一劳永逸，贯穿企业发展的所有阶段。比如Istio面对这种大规模集群的时候，有很多性能问题需要去解决。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/da/da21d3cb12511e3f62c8abb9c86da159.png\" /></p><p></p><h2>未来展望</h2><p></p><p></p><p>多云的问题比较多，有些问题我们没有完全解决。对未来的发展，再结合社区的方向，包括现在多云的安全问题和资源管理问题，我们做了以下两个方向的探索，第一个方向是基础设施即代码；第二个方向就是零信任网络。</p><p></p><h3>基础设施即代码</h3><p></p><p></p><h4>差异化的云服务产品对基础设施管理的冲击云原生时代的基础设施管理</h4><p></p><p></p><p>基础设施即代码，我这里面说到就是<a href=\"https://www.terraform.io/\">Terraform</a>\"。Terraform目前已经非常流行，经过我们的调研，各大云厂商都已经开始支持<a href=\"https://xie.infoq.cn/article/28ef02ca0d8f9839d4964cc12\">Terraform</a>\"了。当前在多云的环境，云服务产品的差异性对我们的基础设施管理也带来了比较大的冲击。同一个产品在每个云厂商的管理流程不一样，生命周期也可能不一样。有时候为了统一生命周期管理，会选择自己对接云厂商的API，实现生命周期的统一管理。但云厂商API完全不同，需要一个个对接，引入一个云厂商就需要对接一次。有时即使功能相同，特性也不同，像LB的很多参数都不完全一致，术语也不一致，有的叫弹性，有的叫独占。</p><p></p><p>但Terraform带来了角色的转化，之前是我们需要自己对接云厂商的API，屏蔽云厂商的API差异，为业务提供资源管理平台或稳定的服务。Terraform可以让云厂商自己去接入，我们实现一个Provider，再去通过Terraform调各个云厂商API，屏蔽之间的差。下面具体看下它帮我们解决了哪些问题。</p><p>&nbsp;</p><p>云无关。我们引入的云厂商比较多，最苦恼的就是这么多云怎么管？各个云厂商的API都不一样，OS也不一样。我们通过代码将基础设施定义好，比如环境定义，之后通过Terraform做到灵活迁移。统一的资源生命周期管理。每个云厂商都有各自的管理方式，用Terraform之后我们可以在自己内部形成统一的资源生命周期管理。快捷的环境复制与迁移。我们在多云上经常还会用到灵活调整部署策略，它为我们解决了很多问题。标准化，自动化，可视化。Terraform的这些特性为我们带来了非常可观的收益。我们定义好资源、代码，通过Git去管理，用Terraform的API自动对接内部流程，自动化管理资源的生命周期，每一次变更都通过Git去可视化，这些地方是我们觉得是比较利好的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6b/6b8182e8293d5ead660c0f508a826932.png\" /></p><p></p><h3>零信任网络</h3><p></p><p></p><p>我们先看一下传统的基于安全边界的网络有什么问题。首先，基于边界的假设是不够合理的，因为一旦边界被打破，那么内网的流量就都是不可信的。其次，传统的基于安全边界的网络只在边界做认证。第三，边界上的认证往往也都比较简单，比如基于IP、或者基于Mac地址，基于网段认证。</p><p></p><h4>多云对传统网络安全的挑战</h4><p></p><p></p><p>在多云环境下，安全问题就更加凸现了，主要有以下几个点。1. 云厂商的安全能力不相同，企业的整个安全能力就取决于最弱的那个云厂商。2. 云厂商也不可信，从而引出下一个问题。3. 所有核心数据都在云上，云上没有人是可信的。4. 在全球化的背景下，我们的边界、分布比之前更广了，数据分布在全球，攻击面就会更大。5. 在云服务商提供的便利服务下，业务可以很容易地获得公网IP，通过暴露公网LB，就可以轻松拿到公网IP，这样是没有什么安全性可言的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7d/7d926877cc3734de74ddc9fc53325a4c.png\" /></p><p></p><p>零信任网络的搭建思路主要是两个核心点：微边界和永远验证。大边界有问题，一旦突破之后里面的问题比较多，我们就要把边界细分，主要涉及三方面。</p><p></p><p>第一个是把Network重新划分，我们做了很多VPC治理工作，把网段分得更细了，这样就可以提高攻击者突破边界之后获取更大利益的困难程度。</p><p></p><p>第二个就是流量加密。我们把所有的流量都通过TLS加密，公网流量通过ATBS加密。有人说，这基本不可行，所有内网流量加密怎么可行呢？实际上很容易，因为有了Istio，Istio本身有mTLS，只需要开启它就可以实现对所有的内网流量的加密，但前提是需要全部接入进去。</p><p></p><p>第三个是威胁防护，我们现在只是基于IP或Mac地址的防护，以后会做基于多种策略的防护，比如借助AIOps的一些防护能力。</p><p></p><p>这就是以上分享的全部内容。</p><p></p><p>讲师简介：</p><p></p><p>黄金，目前任职于<a href=\"https://www.52tt.com/\">广州趣丸网络科技有限公司</a>\"，担任资深架构师，负责趣丸基础架构组。七年工作经验，五年以上基础架构与容器相关平台经验，参与过企业级容器平台从零搭建过程。目前主要工作是基于多云环境，建设企业级高可用多云基础设施。</p>",
    "publish_time": "2022-11-30 16:41:24",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "OpenBMB x 清华NLP，如何玩转大模型",
    "url": "https://www.infoq.cn/article/AEte21US64D7XQys8rdV",
    "summary": "<p>自<a href=\"https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247545391&amp;idx=2&amp;sn=26fbec5f15747e486216362b3bab15e9&amp;chksm=fbea8be0cc9d02f6fce7b3dc784842c7c0cf6731decad4c6765f6e9ed889140d35db59cfe82f&amp;scene=27#wechat_redirect\">GPT-3</a>\"发布之后，人工智能领域将越来越多的资源和关注度投向了大模型。在国内，清华大学自然语言处理实验室和智源研究院语言大模型加速技术创新中心共同支持发起了OpenBMB（Open Lab for Big Model Base）开源社区，专注于大模型的开放研究工作。作为项目主要参与者之一，清华大学计算机系博士后韩旭对这一领域有着一些独到的理解，他的研究经历与看法非常值得关注人工智能大模型研究的从业者参考。</p><p></p><p>为了帮助更多读者与观众了解人工智能大模型，InfoQ极客有约与OpenI启智社区联合推出的系列直播栏目特别邀请到了清华大学计算机系博士后韩旭作客<a href=\"https://www.google.com.hk/search?q=%E4%BD%A0%E5%A5%BD&amp;oq=%E4%BD%A0%E5%A5%BD&amp;aqs=chrome..69i57j0l5.1269j0j4&amp;sourceid=chrome&amp;ie=UTF-8\">直播</a>\"间，分享他的个人学习、研究经历，OpenBMB社区，AI学术研究路线等话题。InfoQ将本次直播的内容编辑成文，希望关注人工智能领域的读者能从中获得有益的见解。</p><p></p><h2>90后清华“学霸”的成长经历</h2><p></p><p></p><p></p><blockquote>InfoQ：您在高一时，就拿到了NOI邀请赛的金牌，因此被保送到了清华大学计算机系，从本科到博士、博士后，您的求学之路可以说非常顺利，您怎么评价自己的学习风格，您是学霸类型吗？</blockquote><p></p><p></p><p>韩旭： 我感觉我还是属于努力大于资质的人，没什么突出的特长，也没有什么短板。我蛮努力的，但对结果怎么样也不是特别执着，更在乎过程，大概是这样一种类型。</p><p></p><p></p><blockquote>InfoQ：是什么让您萌生了对计算机专业的兴趣并锁定了自然语言处理、知识图谱、预训练语言模型这几个研究方向？</blockquote><p></p><p></p><p>韩旭：我接触自然语言处理是在大一的时候。清华计算机系有一些学生计划会鼓励本科学生去接触实验室，我和班上另外三个同学去实验室做了一个叫“微博关键词“的应用，做出来后网上玩的人还挺多的。那是我第一次感觉，去分析人类语言可以做很多有趣味的事情，后面就开始接触自然语言处理的相关研究了。</p><p></p><p>研究自然语言处理后，我感觉对于人工智能来说，比较复杂的问题还是让机器理解语言，因为语言很抽象也和认知有很大关系。我当时认为机器对自然语言理解的能力弱，主要还是缺乏对知识的认识，加入知识对于计算机理解语言有很重要的作用，所以就开始研究知识图谱，把结构化的知识融入到语言理解当中。</p><p></p><p>2018年后出现了预训练语言模型，它在大量学习基础数据后能够自动吐出结构化知识，而且很规整，不需要用太多的符号规则约束，让我有了一些新的认识。我认为可以围绕预训练模型去构建以模型为基础的知识仓库，可以通过一些方法去结合特定任务的数据，把有用的知识激发出来去实现下游任务，这个会是知识图谱之后，未来一个更通用的知识使用范式。所以这几年我也把研究的重心放在大规模预训练语言模型上，把它看作一个重要的知识载体。</p><p></p><p></p><blockquote>InfoQ：我了解到，您在学业之外，在读博期间还担任清华大学计算机系的辅导员、本科生助教，也担任过计算机系学生科协主席等职位，还出版过专业书籍...感觉非常充实忙碌，比较好奇您日常是如何管理自己时间的，有没有觉得难以兼顾的情况？现在很多人会常常感到焦虑，在工作和生活中失去了平衡，不知道您是如何平衡好、安排好时间的？</blockquote><p></p><p></p><p>韩旭： 做辅导员、助教帮助学弟学妹，主要还是受到我导师和实验室前辈的影响，他们之前都在系里做过很长时间的学生工作。另外这也是清华的一个传统，清华所有辅导员都是清华自己的博士生、硕士生给学生当辅导员。</p><p></p><p>但这个确实会给自己带来蛮大的时间压力。因为我有自己的家庭，北京通勤又很费时，这样只能提升自己的工作效率，碎片时间也尽可能利用起来，每天睡觉之前把自己第二天要做什么事情提前计划出来，实在做不完就真的只能加班了。不过我一般不太熬夜，年纪比较大熬不动了，还是老老实实睡觉，第二天早点爬起来干活。娱乐可以少一点，但不能不睡觉。</p><p></p><p>关于工作和生活平衡，我做平衡的方式就是不断做计划。有时候实在特别难受，也不要给自己特别多的压力，这时候就放松一下，多睡觉、看看书、出去玩一玩，给自己一个缓冲的空间。另外对于计划我一定严格执行。我把计划列纸上，做完之后就一条条划掉。做完事情再划掉还是很有快感的，这也算一种方法，这样你就有一种完成感，也有一种下一件事情开始的感觉。</p><p></p><p>做科研本身是没有尽头的，这时候你如果不给自己设置一些节点，人真的会非常难受。另外想玩的时候就要大胆玩，这是很正常的事情，本科时候我们宿舍四个人考试前都在打游戏。核心问题不在于你玩多久，在于你不能用玩来逃避。也许很多事情不想做，但玩过后还要逼着自己做，这是没办法的事情。</p><p></p><p></p><blockquote>InfoQ：您在2017年本科毕业后直博，现在又继续攻读博士后。相信很多人会比较好奇，AI博士是一个怎样的群体？</blockquote><p></p><p></p><p>韩旭： 网上很多人感觉搞AI的都跟古代做巫师一样，就是天天调参，自己也不知道原理是什么。早期我也这样自嘲，就说自己是初级“炼丹师”，但我做多了发现其实不是这样的。</p><p></p><p>一个AI算法的模型设计、数据遴选等等是一个非常庞大的体系，不同时期大家做AI的思路也完全不一样，这背后有非常深厚的、来自各个学科的影响。比如，早期大家做AI受到上个世纪初分析哲学的影响，大家喜欢搞数理逻辑、符号推演，后面也有人去做控制论、专家系统，直到现在搞深度神经网络。</p><p></p><p>所以无论大家研究什么，背后都有各种各样的学科和复杂背景，有自然科学的甚至哲学的，最后都汇总到AI这里。我感觉，对于我们搞AI的人来说，核心还是怎么去赋予一个机器智能，并且把这个智能用在实际生活中，这是我们的终极目标。我们做的事情也就是一些通向这个目标的手段，其实也没有什么特别神秘的。</p><p></p><p></p><blockquote>InfoQ：在清华大学自然语言处理实验室（THUNLP）工作是一种什么样的体验。您在博士期间的导师是刘知远副教授，在博士后期间的导师是孙茂松教授，您平时跟两位导师是怎么相处的？</blockquote><p></p><p></p><p>韩旭： 我大一在实验室就感觉做NLP挺好的，后面就开始专注于这个研究方向。另外实验室的孙茂松、刘洋、刘知远三位老师都很好，对我留下来在实验室做研究的决定起到了很大影响。三位老师给我的感觉就是做事认真、待人谦和、非常努力，而且特别愿意帮助同学解决问题。</p><p></p><p>受老师影响，基本上就是进组之后，师兄师姐就“传帮带”。我很喜欢这种集体氛围，大家一起做一些事、互相帮助，我也愿意帮助别人、别人也帮助我，大家互相成就，挺好的。</p><p></p><p></p><blockquote>InfoQ：您刚读博不久就收获了第1篇顶会，到博士4年级时，手里已有近 30 篇 AI 顶会论文。对于很多人来说，写论文是一件挺“痛苦”的事儿，您是怎么做到如此高产的；您有曾为论文‘抓狂’过吗？</blockquote><p></p><p></p><p>韩旭： 这三十篇里面有一部分工作不是我主力做的，是我带师弟、师妹们做的。因为我是我导师的第一个学生，前面我是被师兄、师姐们领入门，现在师弟师妹就是我帮忙入门了。很多工作是我一开始跟他们一起讨论想法、实验方案等，论文是他们主力工作，我是给他们做指导打辅助的。</p><p></p><p>我本科第一篇文章就被拒了，主要是因为当时大家做知识图谱还是倾向于不用神经网络，因为它的效率和方法都存在问题。我做这件事情比较早，这个文章就感觉有点异端，老被“毙”。被毙几年后风向变了，后面这个文章就被录了。感觉在这方面，个人的努力是一方面，历史的进程可能是更重要的。</p><p></p><p>关于神经网络，它怎么被大家接受的也是一个非常有意思的话题。神经网络在上世纪80年代甚至被认为是不可行的，前辈们是怎么坚持下来做这个东西到现在的，这是更值得我们学习的。做科研，你愿意花20年，30年坚持一个你认为是对的，别人认为是不对的东西，这是非常不容易的。</p><p></p><p>另外我那时候，中顶会确实不容易，但现在就没这么难了。因为现在量也大，开国际会议本质上还是想让大家投顶会论文，互相有个见面机会聊一下，越往后论文发表更多的就变成学术交流性质。我感觉低年级同学想发论文挺合理的，保证自己毕业，让自己安心地去做后面几年更创新的工作是非常重要的事情。博士前期，做些基础工作让自己毕业不存在太大压力，博士后期可以尽情去做你感觉有意义的事情。你发表不出论文肯定不行，你发特别多论文，其实大家也不会有什么特殊的感觉。而且有时候重点也不在论文数量，更多的看论文质量吧。</p><p></p><p>我抓学术热点的方式就是“暴走式”，找一段时间大批量看很多论文。我会先找一两篇开宗立派的文章，再找哪些文章引用它们，看完之后对这个领域就能有一定的理解，就可以跳过很多琐碎工作直接看这几年大家在做什么东西。我感觉比起找学术热点，更重要的还是能厘清这个领域的发展脉络，在这个脉络上找到你能做的点，以及有意义的点。</p><p></p><h2>OpenBMB开源社区</h2><p></p><p></p><blockquote>InfoQ：本期极客有约是InfoQ与OpenI启智社区合作的。清华大学自然语言处理实验室和智源研究院语言大模型加速技术创新中心共同支持发起了OpenBMB（Open Lab for Big Model Base）开源社区，您是这个项目的主要负责人之一，请您详细介绍下，这是一个什么样的项目？OpenBMB社区的成立的背景是怎样的？</blockquote><p></p><p></p><p>韩旭： 最近一两年大模型非常出圈，大模型虽然很厉害，但并不是所有人都能用起来。我们的统计数据显示，主流会议上发表的论文大约只有4%的工作会用到规模较大的模型。大模型的参数规模带来了比较好的性能，但相应的也存在计算效率很低、计算代价很高的问题。无论是高校还是企业，都很难拿出这么多的计算资源来做大模型。</p><p></p><p>我们当时感觉大模型很重要，它很有可能是下一代的AI范式之一。因为大模型具有很强的通用性，可以把它看作是一个很大的仓库，我们可以把各种各样的知识存进去。这个仓库肯定越大越好，这样才能存下更多知识，然后就可以将知识激发出来去解决各种各样的下游任务。</p><p></p><p>但大模型的计算代价也很高，我们怎么能把大模型的计算成本降下来，让大家都能用起来，这就是我们搞开源社区的初衷。我们想要做一个开放的开源工具，让大家都能用起来，在家也能拿一块GPU运行一个相对来说比较大的模型。我们后续做的训练加速、模型压缩、高效微调等工作，也都是为了尽可能用最低的代价让大家把大模型用在各种业务场景和学术研究上。</p><p></p><p>其实现在很多同行也注意到这点，开展类似的研发工作。大家都意识到要把大模型变的实用化，必然要解决效率问题。我们也了解到，企业内部做推荐系统、搜索引擎等，更重要的是响应时间、吞吐量和计算成本等指标。大家都知道预训练模型很有用，已经把它运用在各种业务线上，但特别大的模型还没有大范围铺开，大模型的计算效率上还有很多事情需要做。我相信未来会有越来越多的大模型介入到生产生活中，现在确实还没有那么多，因为这些项技术和发现本身也才出来没多长时间。</p><p></p><p>我们的行业发展还是很快的，目前对于大模型计算效率这样的问题已经有了一些比较成熟的解决方案，能够把成本控制在比较能接受的程度以内，且性能可以维持在95%以上。围绕大模型构建应用其实有很多思路可以尝试，比如用大模型搞出一个中心基础设施，用边缘计算提供服务。</p><p></p><p></p><blockquote>InfoQ：OpenBMB社区和我们经常听到的悟道大模型团队所做的工作有什么联系？</blockquote><p></p><p></p><p> 韩旭： 我们最早也是在<a href=\"https://www.infoq.cn/article/oPXoFirFca8QvQEokIAa\">悟道</a>\"团队下面，叫悟道·文源，主要做中文模型。当时我们的模型和算法研究都是在智源的悟道团队支持下完成的。</p><p></p><p>而OpenBMB更多是从框架角度出发，不是一个偏研究性质的东西，它会偏向工程实现更多一点。当时智源的加速中心给我们很多支持和帮助，让我们去做加速方面的工作，包括开发开源系统等。</p><p></p><p></p><blockquote>InfoQ：OpenBMB社区目前的大规模预训练语言模型库与相关工具都有哪些，具体的功能是什么？</blockquote><p></p><p></p><p>韩旭： 我们在启智社区、GitHub上都已经做了系列化的开源工作，现在基本上常见的功能都有，包括训练加速、模型压缩、高效参数微调、推理加速在内的一整套流水线。我们还有一个围绕OpenBMB的模型仓库，把一些常见的开源预训练模型都集中到里面，可以支持直接调用。</p><p></p><p>下一步我们也在增加各种各样的新功能，尤其是怎么让大家能够比较简单地把这些东西用起来，这是我们下一步着重关心的一点。我们也希望不断接受大家提出来的意见，往开源系统里添加新的功能。</p><p></p><p>我们希望将来做成一个大家共同参与训练的模型，它的底层框架也是用我们已经开源的框架去实现。我们做了很多优化，这些优化都会帮助我们降低计算成本，能够以较低的代价去训练GPT-3这样的超大模型。只有我们把它做得很快之后，围绕它才能做进一步的参数微调和推理。</p><p></p><p></p><blockquote>InfoQ：大模型会不会导致更严重的数据偏见？</blockquote><p></p><p></p><p>韩旭： 如果把模型当成一个知识仓库的话，如果直接扔进去处理不好的数据，很容易出现数据偏见、数据不安全的问题。现在也有不少研究人员专门在做模型杀毒、模型安全，目的就是为了防止大规模数据上预训练可能带来的数据偏见、模型不安全等问题。这方面我们确实还需要进一步去探索。</p><p></p><p></p><blockquote>InfoQ：据了解，OpenBMB社区已入驻并将其部分模型套件开源部署至OpenI启智社区，能否详细介绍下这方面的开源进展？今年，双方还将有哪些合作？</blockquote><p></p><p></p><p>韩旭： 我们训练、压缩、微调、推理等全部流水线工具都在启智社区发布了，后面我们也会一直维护的。我们和启智社区合作的一个很重要的目标是把开源社区生态搞好，因为这对未来我们做AI以及其他相关领域的工作都是很重要的。</p><p></p><p>我们后期会依托启智社区本身的开源平台收集大家的使用体验，然后打磨我们的产品。我们的产品也会第一时间发布到启智社区上。启智社区也给了我们很好的平台支持，帮助我们把开源社区搭建出来，跟大家有更亲密的交流。</p><p></p><p>OpenBMB和我们实验室的成果都是开源的，欢迎大家过来和我们一块做研究，你不用加入我们也能用我们的框架做一些事情。你感觉有些可以改进的点，可以提交给我们，我们把它合并进去，你就算是贡献者了。当然我们更欢迎大家投简历、实习，和我们一块来做研究工作。</p><p></p><p></p><blockquote>InfoQ：超大规模模型的训练和推理会对深度学习框架带来很大的考验，对此，OpenBMB有没有提出一些比较好的解决方案？</blockquote><p></p><p></p><p>韩旭： 有几种方式，第一个就是基于设备去做混合精度。比如说大家一般都用32位浮点，我现在用16位浮点，这样不仅计算量降低了，而且能更好地利用GPU的计算单元来加速。</p><p></p><p>另外我们也做了一些算子重构和调度优化，能够把GPU和CPU都用起来，这些都是系统层面做的优化。算法层面也可以做优化，例如比较常见的模型并行、流水并行、数据并行，利用分布式的多台机器多张卡去做加速。</p><p></p><p>综合这些方案我们可以把训练成本降到很低。现在一百亿参数的模型，大约十万左右的成本能训练出一个还不错的模型出来。</p><p></p><p></p><blockquote>InfoQ：OpenBMB的技术和工具是如何解决超大规模的模型训练不稳定这一问题的？</blockquote><p></p><p></p><p>韩旭：我们的解决方案是，所有模型都是头尾共享Embedding，这样可以避免混合精度浮点计算带来的一些问题。然后是初始化，我们可以把部分参数数值的整体范围放缩下来，让模型变稳定。更“暴力“的方式就是多加一些约束策略，让模型在训练过程中不会“爆”掉。</p><p></p><p>我们发现训练大模型的坑还是挺多的，比如说大模型很容易陷入某些特别的Pattern，如果你的数据里面确实有一些难以发现的特定的Python的话。另外，如果模型数据里噪声很多的话也不太好，在训练之前还是需要对数据进行仔细清洗。</p><p></p><p>这就回到我之前说的问题，就是你看起来是个很简单的事情，实际上操作起来可能很复杂。比如，训练一个大模型，需要数据收集、数据清洗、计算加速，从各个方面上来看，这都是一个非常体系化的事情，已经不是一个人能从头到尾做完的事情。我们需要一个团队，在团队里每个人都有自己的分工，最后才能把事做成。这也是我们为什么要做开源社区，希望大家一块来做开源工作的重要因素。个别人的力量总归是小的，集体的力量会比较大一点。</p><p></p><p></p><blockquote>InfoQ：去年，预训练大模型可以说是NLP领域最为耀眼的成绩。预训练大模型在今年的发展进展如何？您觉得，什么可以算是今年NLP领域最大的技术进展/突破？</blockquote><p></p><p></p><p>韩旭： 去年大家会更多地关注参数大不大。现在的话，大家可能会感觉参数规模不是最重要的，更多地去关注功能是不是通用，模型是不是更智能、更认知。很久之前，我们一直在讨论是不是需要把知识图谱这种符号性知识和深度学习这样的数据驱动模型融合在一起。一些大模型的最新工作给了我们一个新思路，就是，数据库还是数据库，知识图谱还是知识图谱，我们不是把这些东西都学进大模型，而是让大模型能提供对各种你要做的事情的行为模式建模能力。大模型对我们的行为建模，就能学会操控各种各样的东西，这对我们未来去实现通用智能是很重要的启发。</p><p></p><h2>个人规划与对后辈的建议</h2><p></p><p></p><p></p><blockquote>InfoQ：我们最后一部分来和老师谈一谈对于未来的规划。首先一个老套的问题，老师一直以来有没有人生格言或者座右铭？有哪些话想对同侪或者后辈说的话（建议也好，共勉也好）</blockquote><p></p><p></p><p>韩旭： 因为我比较喜欢看历史书，我特别喜欢的一个历史人物是诸葛亮。从小到大我的人生格言就是诸葛亮给他儿子的一句话，静以修身，俭以养德，非淡泊无以明志，非宁静无以致远。我认为他很了不起，即使在一个黑暗时代即将来临的前夕也是向可能的光明方向走。虽然他最后没有成功，但他至少奋斗过。</p><p></p><p>我感觉我个人、我们组有多少成就都不重要，重要的是这个圈子整体有很高的水平。我做开源也是希望大家越来越多地用起来，我们一起可以为这个社区做更多努力。当然也希望大家更关注我们大模型的相关工作，也欢迎大家和我们一起来做事情。但我们更多地还是希望大家用我们的工具去做自己的工作，在自己的领域也能做出非常好的成果。</p><p></p><p></p><blockquote>InfoQ：请问老师，是不是大企业或者大研究院比在学校实验室更容易做出更有突破的成果？</blockquote><p></p><p></p><p>韩旭：公司的好处显而易见。公司资金会更多，更偏向业务，有更多的业务数据，计算资源也更多，但相应的约束也会更多。</p><p></p><p>我是在高校做博后，未来可能还是更倾向于做老师、做研究员。我总感觉在企业里面你做科研，还是会有很多很现实的压力会限制你在业界做一些事情。高校相对来说是互补的。高校计算资源没那么多，但是高校相对来说没有那么多对业务的要求，你能更多地做一些偏预研性质的东西。高校老师的经验会更足，对研究方面也会更有经验一点。</p><p></p><p>所以你在高校做研究，还是在企业做研究，两边都有局限性。你可以做个比较，选择出你想要的方案。这里没有最好的道路，可能只有适合你的才是最好的。</p><p></p><p></p><blockquote>InfoQ：接下来请老师聊一聊在学研方面，未来对自己有什么规划？是否考虑过毕业后的从业规划？</blockquote><p></p><p></p><p>韩旭： 因为我现在是博后，这段工作更多是把大模型做实用化一些，做开源社区建设，做实用化的工具。博后之后当然更倾向于找教职做老师。我还很喜欢当老师的，精神上会更愉悦一点。高校的工作节奏感觉没有企业那么明确，高校很多时候都是突然一阵子来好多事情，有时候也感觉挺累的，但是在这个过程中，尤其跟年轻同学接触的过程也还是很快乐的，我还是很愿意去当老师的。另一方面，将来也不排除去业界找工作吧，这个东西很难讲。就像我刚才说的，你得考虑个人的奋斗，也得考虑历史的进程。但从我内心来讲，我还是更愿意去做老师、做教职的。</p><p></p><h4>嘉宾介绍</h4><p></p><p></p><p>韩旭，清华大学计算机系博士后。师从孙茂松教授与刘知远副教授，主要研究方向是自然语言处理、预训练语言模型、信息抽取。在ACL、EMNLP、AAAI等自然语言处理与人工智能国际会议上发表论文20余篇，根据Google Scholar统计论文总引用超过3000次。参与开源OpenKE、OpenNRE等工具包，在GitHub上累计获超过10000星标。曾获清华大学“国家奖学金”、“蒋南翔奖学金”、“钟士模奖学金”、清华大学优秀博士学位论文等荣誉，入选2022年博士后创新人才支持计划。</p>",
    "publish_time": "2022-11-30 16:54:38",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]