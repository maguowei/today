[
  {
    "title": "微服务架构搭好了，可观测方案怎么整？| InfoQ《极客有约》",
    "url": "https://www.infoq.cn/article/5cJEWsLZdjGRSDR3WXMZ",
    "summary": "<p>差不多在五年前，分布式系统也已成熟，微服务架构尚未普及，可观测问题就已经在桎梏技术团队的工作效率。一个 To C 的软件使用问题可能由客服发起，整条支撑链路的所有技术部门，都要逐一排查接口和日志，流程非常原始，也非常低效。如果业务到达一个量级，支撑系统变多，两名研发查上两三个星期也是常事。</p>\n<p>微服务架构普及后，问题变得更加严峻。一个服务被拆分成数个黑盒的、虚拟的微服务，故障排除彻底成为一种折磨。这一切都使可观测成为 2022 年技术人必须关注的话题。</p>\n<p>本期《极客有约》，我们邀请到博睿数据创始人兼CTO 孟曦东和中信建投SVP的周洪一起聊聊可观测技术究竟是什么？</p>\n<p><strong>直播大纲：</strong></p>\n<ul>\n<li>可观测涉及的具体技术概念有哪些；</li>\n<li>技术路线是什么以及企业如何选型；</li>\n<li>有哪些值得关注的开源项目；</li>\n<li>未来发展方向</li>\n</ul>\n<p><strong>讲师介绍：</strong></p>\n<p>孟曦东，博睿数据创始人兼CTO。1998年8月至2000年3 月，任中国航空第303研究所软件工程师；2000年3月至2008年 1月，任北京千龙新闻网络传播有限责任公司技术总监；2008年2月至2016年2月，任博睿数据首席技术官；自2016年2月至今，任博睿数据董事、副总经理。</p>\n<p>周洪，中信建投SVP</p>",
    "publish_time": "2022-07-06 09:09:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "腾讯云原生数据库TDSQL-C架构探索和实践",
    "url": "https://www.infoq.cn/article/yNUvfBo8I9YpvIXWHHhc",
    "summary": "<p></p><blockquote>4 月 15 日-16 日，由 InfoQ 主办的 <a href=\"https://dive.infoq.cn/2022/beijing?utm_source=infoq&amp;utm_medium=conference\">DIVE 全球基础软件创新大会</a>\"通过云上展厅的形式成功召开。在<a href=\"https://www.infoq.cn/video/36VEZEezWd4adMNPiHqL\">腾讯云基础软件创新实践专场</a>\"，来自腾讯云的数据库专家工程师王鲁俊带来了主题为《腾讯云原生数据库 TDSQL-C 架构探索和实践》的演讲，以下为主要内容。</blockquote><p></p><p></p><p>本次分享主要分为四个部分：第一部分介绍腾讯云原生数据库 TDSQL-C 产品架构，包括产品的研发背景和架构主要特性；第二部分分享用户场景实践，针对线上真实的用户场景做一些分析和针对性实践；第三部分分享系统关键优化；第四部分分享产品未来演进。</p><p></p><h2>TDSQL-C 产品架构</h2><p></p><p></p><h4>背景</h4><p></p><p></p><p>腾讯云原生数据库最初采用的是传统架构，也就是 MySQL 实例，或者说是采用 Binlog 复制的主备方式的架构。但这种架构在现有的一些用户需求来看是有很多问题的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2b/2b94fa82d089c26ddbde841ba34db3ab.png\" /></p><p></p><p>比如存储容量。传统架构实例的存储上限受限于本地磁盘上限，一般是几百 G，或者几个 T 的量级，做扩展的成本非常高而且麻烦。当用户数据非常多时，会做分库分表，使用现有的分库分表中间件或解决方案会带来一些分布式事务的问题。</p><p></p><p>做业务的同学知道，分布式事务处理起来会比较麻烦，涉及如何应对故障，如何应对分布式事务产生的数据不一致等问题。用户在存储容量方面的需求是实例容量大于 100T，并且存储容量能够快速透明的扩展。</p><p></p><p>其次是可靠性。传统架构基于 BinLog 复制，普通的异步或者半同步的复制方式可能会丢数据，同步的复制方式性能损失会比较大。用户在可靠性方面的需求是第一不能丢数据，即 RPO 等于0；第二数据是有多副本容灾的，也就是要达到一定程度的数据可靠性。</p><p></p><p>此外还有可用性，可用性对于用户来讲就是服务有多长时间不可用，比如在传统架构发生一次 HA，或者宕机重启，这段时间服务都是不可用的。HA、恢复时间慢对用户来讲很难接受，传统架构 HA 或者副本的恢复速度可能达到了分钟级。第二个问题是基于 BinLog 复制的时候，主备副本的延迟比较高，有些可能达到分钟级，甚至达到小时级。用户希望能够快速切换 HA，实现秒级恢复，还包括回档功能，如果有副本，希望副本的延迟能够比较小，最好是秒级以下，甚至是毫秒级。</p><p></p><p>最后是可扩展性。传统架构的扩展性是非常复杂的，基于 Binlog 创建只读副本也会非常复杂，要先把原始的数据给复制过来，然后搭建主备同步，只读副本才能开始工作，这个过程至少是分钟级甚至是小时级别的。对用户来讲，他们希望当读需求有扩展性需求的时候，可以实现秒级的读副本扩展。</p><p></p><p>我们针对这四个方面的用户需求，采用了存储计算分离架构，这也是 TDSQL-C 所采纳的核心的架构想法。</p><p></p><p>简单来说，要解决存储容量和可靠性方面的问题，第一我们会用云存储，云存储之间是可以水平扩展的，理论上它的容量是无限的，而且对于每一份数据都有多副本来保证可靠性。数据分散在云存储的各个节点上，在这个基础上可以做持续备份，并行回档等功能。</p><p></p><p>在可用性方面，数据放在云存储上之后，数据的分片是可以做并行恢复的，回档也可以做并行回档。物理复制的时延一般会比基于 Binlog 的逻辑复制更低一点。</p><p></p><p>最后在可扩展性方面，共享存储的优势更加明显，当新建一个只读副本的时候，数据不需要复制一份出来，因为数据是在云存储上作为共享数据存在的，只需要把数据共享，另外再构建增量的数据复制就可以了。</p><p></p><h4>架构特性</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ed/ed86bc802975518bdbb8abb29e8c5631.png\" /></p><p></p><p>上面这张图是 TDSQL-C 的整体架构，从这个架构中我们可以看到，它整体上分为上一层的计算层和下一层的存储层。</p><p></p><p>计算层有一个读写节点，可以提供读写请求，还有多个只读节点，可以提供读请求，也就是图里边的 Master 节点和 Slave 节点。当读写请求，尤其是写请求进来以后，Master 节点也就是读写节点产生数据的修改，然后它会把修改产生的 InnoDB 的 Redo Log 下传到整个存储层，同时把 Redo Log 分发到自己的 RO 节点。</p><p></p><p>存储层负责管理数据，当产生的 Redo 日志发送到存储层之后，它可以负责 Redo 日志的回放，Segment 把它存储的页面对应的 redo 日志 apply 到自己的页面上来。整个存储层是架设在 COS 存储服务上。</p><p></p><p>TDSQL-C 的存储可以自动扩容，最大支持超过 1PB 的容量，目前我们的产品最大支持到 96CPU 和 768GiB 的规格。性能方面，只读大概能跑到一百万以上 QPS，写性能也能超过 40 万 QPS。</p><p></p><p>基于这种共享存储的架构，我们可以做到秒级故障切换，包括秒级的快照备份和回档，并且因为存储层本身可以做弹性，计算层也可以做弹性，所以可以实现一定程度的 Serverless。</p><p></p><p>此外，当需要扩展只读的时候，可以很容易的增加只读节点，TDSQL-C 现在最多可以挂 15 个只读节点，并且在读写节点和只读节点之间只有毫秒级的延迟。因为整个工程是基于 MySQL 代码库演化过来的，所以是百分之百兼容 MySQL 的。</p><p></p><h2>场景实践</h2><p></p><p></p><p>接下来，我介绍并分析几个比较典型的场景实践。</p><p></p><h4>Serverless</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/29/290f11a11e5f65b47f6d957c274cb315.png\" /></p><p></p><p>上图描述的是一些业务预测未来一段时间的数据存储或者数据计算的需求是持续上涨的，但实际上可能真实的用户需求是图中灰色的曲线。为了做好服务，用户要提前买好服务库实例，比如图中红色的折线，一开始就要准备好这种规格的数据库实例。</p><p></p><p>这种情况有一些坏处。第一，实际买的规格都是比真实需求偏大的，这就会造成存储资源或计算资源的浪费。如果某些时刻有突发的流量进来，突然对存储或者计算的资源要求非常高，就会出现机器实例资源跟不上、规格太小等情况，这会对业务造成很大的影响。</p><p></p><p>我们认为理想的情况应该是图中蓝色的曲线，这个曲线的整个资源容量跟真实业务需求的变化规律是一样的，并且总是比真实的需求稍微多一点。这样就能真正把资源充分利用起来，而且最大程度上降低成本开销。</p><p></p><p>在一些真实的例子里，我们发现有些业务是开发测试场景，业务真正上线之前，会做一些系统的测试开发，这个过程对数据库的需求频率是非常低的。还有一些像 IoT、边缘计算、SaaS 平台，他们的负载变化有非常大的规律性，白天压力比较大，但是晚上压力比较小。</p><p></p><p>TDSQL-C做到了智能极致的弹性，能够根据负载来快速启停实例。第二是按需计费，用了多少花多少，不用不付费，可以做到按秒的计量，按小时的结算。</p><p></p><h4>弹性扩容</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4c/4c4d0fa4c6dc71c43579c7e8dc85e92c.png\" /></p><p></p><p>另一个我们在线上业务中发现的实践需求是弹性扩容。有些业务每天都能产生大量的数据，比如有的业务一天产生几百 G 的数据，并且这种业务对单库的容量要求很高，通常都是几十 T，甚至上百 T 的数据。</p><p></p><p>有些场景，像开发测试场景，开发完或者某一次测试完，数据库直接就删掉了，生命周期非常短。另外有些历史库场景，历史数据存储只是存储最近一段时间的，特别老的数据直接就删除了，删除了这些数据希望空间立刻回收，不要再产生存储成本了。</p><p></p><p>TDSQL-C 可以做到按需扩容，存储根据操作页面按需扩容，如果产生的数据比较多就扩展出来，不需要预先规划好要做多少存储。第二点是自动回收，有一些空闲空间，比如数据已经删除了，这些数据实际不需要了，但是传统的 RDS 是逻辑删除的，这块可能还会继续产生费用，TDSQL-C 可以做到按实际的容量来计费。</p><p></p><h4>备份回档</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/58/58be074ef0fc1a91655c19fab2f2817b.png\" /></p><p></p><p>很多场景对备份回档要求比较高，比如金融行业，因为金融行业对数据安全关注度非常高，他们对备份的速度和备份的时效性都有很高的要求。还有像游戏业务，可能会涉及到频繁的回档，所以对备份回档的速度要求也比较高。</p><p></p><p>回档作为“后悔药”，对很多业务来讲都是很重要的一个功能，用户可能会产生一些误操作。</p><p></p><p>TDSQL-C 可以做到持续备份，存储分片可以根据备份点进行并发的独立备份，同时可以做到设定全局的一致性备份点来进行备份。此外，TDSQL-C 也可以做到并行回档，每一个分片并行回档各自的数据的全量和增量的备份，并行回放自己的日志。还有 PITR，也就是可以快速的恢复到数据库的任意时间点的数据的状态。</p><p></p><h2>系统关键优化</h2><p></p><p></p><h4>极速启停</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cd/cdaa2340765c8875d73d10089285ce15.png\" /></p><p></p><p>第一个优化就是前面提到的，如何做到极速启停，也就是支持更好的 Serverless。</p><p></p><p>这边有个测试数据，第一个测试数据叫停机时间，指的是计划内的停机时间，即主动停机。TDSQL-C 跟传统的 RDS 数据库对比，传统 RDS 数据库停机需要 26 秒，TDSQL-C 可以做到 3 秒内停机。</p><p></p><p>第二个是启动时间，就是停机之后重新把数据库实例拉起来，大概需要多少时间能够恢复起来，RDS 需要 48 秒，TDSQL-C 可以做到 4 秒就启动起来。</p><p></p><p>我们分析了一下，这 48 秒有 21 秒是在做事务恢复，也就是第三个柱状图，我们对事务系统的并行初始化、表锁恢复做了一些优化，可以把恢复时间降到一秒。</p><p></p><p>第四个指标叫性能恢复时间，这个指的是比如重启之前数据库的 QPS 大概跑到了 20 万 QPS，重启之后大概需要多长时间才能重新恢复到 20 万 QPS。这对很多业务来说都是很重要的，是恢复质量的问题。传统 RDS 在有些场景下需要 260 秒才能恢复，但是用 TDSQL-C 3 秒就能恢复了。</p><p></p><p>这里我们做了一些优化，用的独立 BP 的优化方式。Buffer Pool 跟数据库实例进程是解耦的，由这台机器上的另外一个进程来负责管理这块内存，当数据库实例重启之后，Buffer Pool 是可以继续用的，这种方式就避免了重启之后，整个 Buffer Pool 都是冷的，需要很长时间慢慢预热，省了这个过程，所以恢复时间会非常快。</p><p></p><h4>二级缓存</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d8/d8ca259c4af041bd132fc88a882d68ac.png\" /></p><p></p><p>另一个系统关键优化是二级缓存。二级缓存是 TDSQL-C 在存储计算分离架构下做的比较创新的优化，也是对架构的一个重要补充。</p><p></p><p>如此前所说，存储层是可以水平扩展的，这意味着数据量膨胀了很多倍，可能几十倍、上百倍。数据量多了，但是计算层计算节点的 Buffer cache，也就是 InnoDB 的 Buffer Pool 的容量并没有太大的变化，这就意味着需要用以前相同大小的 Buffer Pool 来服务更多的数据。</p><p></p><p>大家知道 InnoDB 的 Buffer Pool 在一定程度上承担了读缓存的作用，服务更多的数据，意味着读缓存的效率可能会下降。以前一些并不是 IO Bound 的场景，在这种数据量大了的场景下就变成 IO Bound 了，或者以前本来就是 IO Bound 的场景，IO Bound 更严重了，这样对性能影响还是比较大的。</p><p></p><p>其次，传统 RDS 的 BufferPool 和本地磁盘空间的存储中间，是没有其他硬件存储设备的。但是在存储计算分离架构下，Buffer Pool 可能跑得非常快，它的 IO 延迟很低，但数据是存放在远端的机器上的，我们这边叫 Remote IO。需要通过网络访问其他机器的 SSD，在这之间有至少两个层次的硬件存储设备，一个是 SSD，就是本机硬盘，另外一块是 Persistent Memory，就是持久化内存，这些是我们可以利用起来的。我们把这一类存储用作 secondary cache，通过这种方式能够有效的减缓 IO Bound 场景下 Buffer Pool 命中率低的问题，因为我们可以缓存很多的热数据，能够加速数据的访问。</p><p></p><p>通过测试可以看到，随着数据量的增大，整个性能提升还是比较明显的，在很多场景下性能可以提升到百分之一百以上，达到一倍多。</p><p></p><p>当然这个问题也有其他的解决方案，有些产品用的是水平扩展 DRAM，类似于我们的 Buffer Pool，就是把 Buffer Pool 放在远端的机器上，通过更好的 RDMA 来访问这部分内存，而且这个内存可能分散在多台机器上，这种方式也能减缓 IO Bound 场景的一些开销。</p><p></p><p>但相对来讲，我个人认为使用 Secondary cache 这种方式系统的整体应用成本更低一点，因为毕竟内存的成本比 SSD 的成本高的多，尤其是非易失性内存，像 3D Xpoint，慢慢流行起来之后，价格是慢慢降低的。用二级缓存的方式，整体的实例成本能够下降非常多。</p><p></p><h4>极致伸缩</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/02/02c9c97573504d8eff5fed13f8abcf76.png\" /></p><p></p><p>还有一个优化是极致伸缩，我们把存储功能下放到存储层之后，存储层会有存储池这样一个概念。</p><p></p><p>有一些逻辑跟传统 RDS 方式是类似的，比如段管理还是以 1M 的 extent 为粒度来管理。也有些逻辑有很大的差异，比如我们把存储空间的扩展，整个 offload 到存储层，整个空间都池化。当我们发现某个 extent 里面的所有页面都回收了之后，变成了一个 Free Extent，就可以物理上真正的把它删除，而不只是标记为删除。通过这种方式真正删除之后，客户的存储成本就降低下来了，也就是能够实现按需计费的能力。</p><p></p><h4>极速备份回档</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7f/7fbab1f0eef3f03892119835511deaaf.png\" /></p><p></p><p>极速备份回档的实现包含两部分：备份、回档。</p><p></p><p>此前提到，我们的数据是分散到分布式存储组件上的，分布式存储包含很多的存储节点，而且它本身还有一定的计算能力。当实例需要做备份的时候，每个存储节点都可以独自的去做备份，我们叫自治备份，它可以持续的做备份。当我们需要全局一致的备份位点时，可以由计算节点来负责协调，通过一些特殊的命令，或者日志来通知所有存储层的节点基于快照做一个统一的备份。</p><p></p><p>跟备份相反的一个操作是回档，基于备份再把实例的数据恢复到某个时间点，回档也是并行回档的，每个计算节点都可以独立的做自己的回放。</p><p></p><p>针对极速备份回档的测试数据看，1TB 的备份时间，RDS 实例需要 61 分钟，TDSQL-C 只需要 21 分钟就够了。1TB 的回档恢复时间，RDS 需要 168 分钟之多，但 TDSQL-C 22 分钟就可以恢复出来。</p><p></p><h4>Instant DDL</h4><p></p><p></p><p>还有一些优化是功能性优化，包含 Instant DDL 和并行构建索引。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/23/23788278cc53a9ece812d55310041ae8.png\" /></p><p></p><p>Instant DDL 是 MySQL 8.0 新增的一个功能，它指的是在处理新增列，或修改列类型，或删除列 DDL 的时候，可以仅仅修改原数据就直接返回。</p><p></p><p>大概的原理是，比如这张表原来有三列，现在需要新增一列，变成四列，只需要在系统表里面标记一下，这张表就从原来的三列变成了四列。之后再新写入的数据都是按四列写入的，原来的数据在磁盘上存的是三列的，新插入的数据会打上新格式数据的标记，原来的数据是没有标记的，当用户读取的时候，返回客户之前根据标记来决定。如果是旧数据，我们就给它补一个新的列，一般补默认值 default value；如果是新列就直接返回，通过这种方式就做到了O(1) 的 DDL，时间非常短。</p><p></p><h4>并行构建索引</h4><p></p><p></p><p>接下来介绍下并行构建索引，比如 create index，或者 optimize table 的时候，都会涉及到一些表的重建。</p><p></p><p>RDS 构建索引的时候，尤其是 8.0 的相对早一点的版本，都是单线程构建的。构建过程是先扫描所有的主表数据，扫描之后，根据扫描到的每一行主表数据，再根据索引信息，生成对应的索引行，这些索引行生成后存储到临时文件里面。</p><p></p><p>第二步是对这个临时文件按照索引行的索引键进行排序，一般是 mergesort，完成之后把它导入到一个空的 Btree 里，这样就完成了整个索引的构建。我们针对这块做了并行化优化，扫描主表、外排，还有把数据导入到 Btree，这三个过程都是可以并行化的。</p><p></p><p>在第一个阶段，我们基于 InnoDB 8.0 的 parallel DDL 做了并行扫描。第二步的 mergesort 我们也做了基于采样的并行化，通过这种方式来提升并行度。第三步构建 Btree 的时候，也是可以并行化的，比如产生了八万行的索引行，如果八并发，每一个并发线程负责一万行数据的构建。最后再把形成的八个子 Btree 合并成一个大的 Btree，再去压缩层高等等。我们测下来很多场景下能提升到两倍以上，还有很多场景可以提高的更多。</p><p></p><h2>未来演进</h2><p></p><p></p><p>第一个我们在探索的演进叫 Global Database。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/90/903ee83e02a04ecf2fdc9224558e0fea.png\" /></p><p></p><p>如上图所示，左边有一个 Primary 实例，这个实例读写节点产生了 Redo log，Redo log 需要分发到存储层，我们现在新增了 Log Store 模块，它负责接收和分发日志，通过这种方式，Log Store 一定程度上可以提升日志的响应速度和整体 Redo log 的 IO 吞吐，进一步提升写性能。</p><p></p><p>另外一个很重要的点是 Primary 实例跟右侧 Standby 实例可以通过各自的 Log Store 来建立数据复制的链路。通过这种方式，相当于扩展出了一个只读节点，实现读扩展，而且是跨 Region 的读，因为 Standby 可以部署在另外一个 Region 上。另外我们通过这种方式实现了跨 Region 容灾，这对于很多金融业务来讲都是刚需。</p><p></p><p>另一个我们在探索的演进是计算下推。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a6/a65258a28ee67ed65a24b548f628ba6e.png\" /></p><p></p><p>根据我们的架构，存储和计算是分开的，计算在上面，存储在下面，存储不只有存储能力，还拥有一定的计算能力，像刚才提到的备份恢复，每个节点可以独立持续的做备份，就是利用存储层计算能力的一个例子。</p><p></p><p>除此之外还有很多业务逻辑也可以通过这种方式把存储层的计算资源利用起来，第一个是页面内计算下推。比如现在要做一个有条件的扫描，扫描到了某个页面，这个页面可能有一百行数据，满足条件的有五条，可以把条件下推到存储层，直接放在存储层做过滤，只把这五条数据返回给计算层就可以了，这就避免了把这一百行全部读到计算层，在计算层再做计算，减少了中间网络带宽的消耗。</p><p></p><p>第二个是 Undo 页面间的计算下推，我们 InnoDB 是支持 MVCC 即多版本的，举个例子，我们现在启动一个只读，这个读事务快照相对比较老，比如读一小时之前的，当我现在去读的时候，发现某一行数据太新了，不是我想要的那个数据，需要找到以前的版本。</p><p></p><p>这个过程在 InnoDB 里面，需要找到这一行对应的 Undo 页面，把它的前镜像找出来，要读的是 Undo 页面记录的前镜像，这个过程如果放在计算节点做，需要把原始的页面数据加载到计算节点，然后根据读快照把 Undo 页面找出来，再把 Undo 页面应用到数据页面上，产生一个旧版本的数据。这整个过程都可以在存储层来做，我们现在也是把这个下沉下来的。</p><p></p><p>还有一个下推叫写下推。比如我就改某个页面 Header 部分的前几个字节，或者 Page Header 的某个字段，这种情况很多是盲写的，不需要读出来，直接可以更新，这种情况也是可以下推的。</p><p></p><p>计算下推在存储计算分离的架构下是很自然的一个事情，刚才讲到了存储计算分离，它的存储层带有一定的计算能力，大量的计算实际上都是可以下沉到存储层的，哪些计算可以下推并没有很明显的边界。我个人觉得除了事务之外，大部分计算型的都可以下推到存储层，甚至可以把存储层的一些计算资源当成纯粹的计算资源，不关心它是不是存数据。</p>",
    "publish_time": "2022-07-06 10:39:32",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "支撑好分期百亿放款的流程引擎-EasyFlow",
    "url": "https://www.infoq.cn/article/ZUGZT02S7EqxyrPBhfF3",
    "summary": "<p>本文主要介绍好分期自主研发的流程引擎EasyFlow，内容主要包含方案设计、最佳实践以及部分代表性的问题的解决等，希望通过本文的分享，为有相关诉求的团队提供一定的思路参考。</p><p></p><h3>一、何为 EasyFlow</h3><p></p><p></p><p>在互联网金融公司的业务实现中，总会遇到几个技术问题：如何能快速对接不同的资金渠道达到线上放款目标？如何能在合作方系统不稳定或网络异常情况下保证内部系统稳定运行？如何能将上百个差异化的流程抽象管理？如何能高效的、低资源消耗的情况下执行亿级任务？如何能在繁杂的渠道对接过程中，实现低代码化开发？</p><p></p><p>好分期是如何能快速对接 40+ 线上渠道、高效管理 150+ 差异业务流程的呢？EasyFlow 便是答案。</p><p></p><h3>二、背景</h3><p></p><p></p><p>我们选择自研EasyFlow项目主要有两方面的考虑：</p><p></p><p>流程可视化、低代码化开发</p><p></p><p>提升系统的可用性</p><p></p><h4>1. 流程可视化、低代码化开发</h4><p></p><p></p><p>传统资金对接流程采用硬编码模式来指定业务的前后依赖节点，该模式存在以下主要问题：</p><p></p><p>依赖关系使用硬编码关联，无法直观了解业务流程，前后依赖关系变更时需要重新编写代码</p><p></p><p>流程复用程度低，相似的渠道流程因细节的差异也无法进行复用</p><p></p><p>线上问题处理困难，需要编写大量SQL通过数据库的任务状态以及代码的逻辑关系才能定位问题</p><p></p><p>通过可视化的实现，不仅解决了流程的界面化的创建、策略配置，减少大量的流程类开发工作，也为实际流程运行时的运营工作提供了便捷的处理方式，可视化能将流程实际运行情况清晰的展示到界面上，使得运营人员能快速对线上问题进行定位。</p><p></p><h4>2. 提升系统可用性</h4><p></p><p></p><p>传统流程执行机制依赖数据库进行异步任务节点的存储，通过系统的quartz定时调度分批次限流进行任务的拉取执行，该模式存在以下主要问题：</p><p></p><p>对数据库的使用压力大，一般的流程类的操作是业务数据的几十倍甚至上百倍，当业务量大时，流程操作对数据库的压力就会造成灾难性的影响</p><p></p><p>三方系统、三方业务不稳定对系统的中间件影响巨大，容易造成整体的服务卡顿和资源使用的浪费</p><p></p><p>当业务量不均匀请求时，分批次执行任务容易造成资源无法充分利用</p><p></p><p>将MySQL+quartz的扫表操作转换为RabbitMQ+MySQL的业务模型，可以在一定程度上降低数据库压力；并将流程调度交给RabbitMQ管理， 充分利用集群节点解决实时性任务执行的时效性问题，减少定时拉取任务的等待间隔；考虑到实际生产环境中可能会出现因合作方系统不稳定、业务需要经过多次重试才能得到正确结果、以及网络抖动带来的一些列不确定因素，通过消息路由动态策略更新和匹配，进一步提升队列的使用率和流程的执行效率。</p><p></p><h3>三、EasyFlow 与开源流程引擎对比</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8c/8cf3de694a6a758d0859accafeb24089.png\" /></p><p></p><p>EasyFlow相比较市场主流的开源流程引擎，更小巧、精简，对于三方jar包依赖数量也略低于其他系统，能轻松的集成到各个系统中。并且对于基础数据库表的数量也进行了精简，对于部署所需的资源要求也相对较低。自研的可视化页面，简洁美观，并将流程编程升级为可视化配置，极大的降低代码维护量。</p><p></p><h3>四、EasyFlow方案设计与实现</h3><p></p><p></p><p>之前章节介绍了EasyFlow的一些特点以及解决问题的能力，但是具体是如何实现的呢？本章节会概要介绍EasyFlow流程引擎的调度算法设计、可视化编排设计以及提高队列使用率的消息路由的设计方案。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/70/7032fb625b012f750c54b78464bfbd5d.png\" /></p><p></p><p>我们选用EasyFlow的底层消息中间件时进行了多个产品的对比，结合业务实际场景的吞吐量、可靠性的要求，选取了能保证消息可靠传递、并通过复杂的路由逻辑去找到消费者的RabbitMQ作为消息驱动的策略核心，生产者通过与Broker连接并且建立信道(Channel)，将消息发送至交换器(Exchange)。然后根据Exchange 的类型，将消息路由到指定队列。 虽然从吞度量上不如Kafka的性能出众，但是基于消息队列实现业务渠道也需要考虑平替MySQL+quartz模式的可靠性，以及支持producer与queue入队之间保留路由功能的情况，我们最终选择了RabbitMQ。</p><p></p><h4>1. EasyFlow引擎核心关键定义     </h4><p></p><p></p><p>流程（Flow）:  用来定义流程的名称和编码等基本信息</p><p></p><p>任务（Task）：最底层的具体执行某一个固定动作的独立的单元。</p><p></p><p>流程节点（FlowNode）：流程编排时对应流程中的一个个的点，可以是任务也可以是流程（子流程）。其中有两个节点比较特殊，分别是开始节点（Start）和 结束节点（End），用来表示流程的开始及结束，为虚节点（该节点无实际对应的任务或流程），流程节点可以引用其他流程成为子流程</p><p></p><p>流程编排（FlowDesign）：由多个流程节点串联组成</p><p></p><p>流转条件（CondExp）：流程编排中由父节点到子节点连接而成的有向边上的条件表达式</p><p></p><h4>2. 流程执行过程</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c5/c57e185699cbd5cdda9b67386a9b88c3.png\" /></p><p></p><p>如图所示，通过可视化的流程定义，在内存中构建成BPMN业务流程图，利用图节点的指向动态创建后续流程节点实例， 通过条件表达式作为分路由的判断依据，同时对多个父节点实例的状态判断是否可以继续创建下一节点，或者是执行结束。</p><p></p><h4>3. 低代码可视化设计与实现</h4><p></p><p></p><p>EasyFlow集成mermaid-js页面渲染技术，将流程类的配置信息，渲染成可视化的流程图形，并将可视化的流程图样式尽可能像UML流程图的样式贴合，不仅将繁杂的流程数据通过可视化的方式进行了清晰的展示，也能让产品技术人员通过最熟悉的样式，进行线上流程准确性的校验。</p><p></p><p>mermaid-js是一种基于JavaScript的绘图工具，使用类似于Markdown的语法，使用户可以方便快捷地通过代码创建图表。Mermaid作为早期支持UML图表渲染较好的技术，并且多个绘图软件例如：Typora，MarkdownPad等，均使用的mermaid-js作为可视化渲染技术，所以我们也选用了这个技术。</p><p></p><p>研发人员通过标准简洁的流程创建流程以及流程执行规则配置，即可快速制定业务流程的规则。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a2/a2236ac1f753adebcffb62d5fa7feb6a.png\" /></p><p></p><p>EasyFlow规定了流程间的上下文状态定义，通过标准或个性化的规则配置，可以将业务结果与流程的执行策略紧密结合，依据每个节点执行后不同状态，自动实现流程图中差异化执行。</p><p></p><p>执行延迟配置：通过延迟条件的配置，可以在不影响消息重试的频次修改条件下，通过业务逻辑的判断，达到实际业务执行的延迟控制功能</p><p></p><p>循环次数配置：设置单个节点的重试次数，在配置范围内可以正常重试节点，达到最大重试次数时，则会暂停流程并且预警，通知相关运营人员进行人工干预</p><p></p><p>匹配条件配置：EasyFlow引入SpEL表达式解析功能，在创建配置流程节点过程中，可以设置SpEL表达式，并根据流程执行过程中的关键变量值以及调用表达式解析，进行流程分发的判断，将流程逻辑从硬编码优化为可视化界面配置。</p><p></p><p>我们引用SpEL表达式的目的是为了做流程通用化的处理与实际业务解耦。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/68/68a4eadf4432bffedde21795c3e790a4.png\" /></p><p>图1</p><p></p><p>如图1所示：在创建“担保方进件-进件审核”节点时，需要在前置任务处理成功，流程上下文_result对应的结果是true才会进行流程的处理，“审核结果回调业务方”是在前置任务_result为false时执行。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/13/135feb93ea23afbc00575c338c26f11f.png\" /></p><p>图2</p><p></p><p>如图2所示：“还款-线下-还款到资金方”需要根据流程上下文中的prepaymentFlag为false且_result为true情况下执行，“还款-回调发起方”（成功）需要根据流程上下文中的prepaymentFlag为true且_result为true时执行，“还款-回调发起方”（失败）需要根据流程上下文中的_result为false时执行。</p><p></p><p>为了能通用化处理流程引擎的动态规则匹配，并且支持匹配逻辑的扩展性，我们引用了SpEL表达式，进行灵活的规则维护和匹配工作。差异化的业务流程，不是简单的true和false就能进行业务区分的，对于复杂业务场景，可能会出现多个匹配条件共同作用，如果每新增一个判断条件都需要调整流程的判断逻辑，那就得不偿失了。通过可视化的实现以及SpEL的引入，不仅解决了流程的界面化的创建、策略制定，也为实际流程运行时的运营工作提供了便捷的处理途径，可视化能将流程实际运行情况通过状态清晰的展示到界面上，使得运营人员进行线上问题定位时一目了然。</p><p></p><h4>4. 智能消息分发路由</h4><p></p><p></p><p>消息队列存在自身的使用限制，比如并发速度受消费者单位速率的限制，死信队列会因不同的过期时间导致积压等问题，在众多差异的队列使用场景中，都会对EasyFlow的使用效率造成影响。为了应对互联网金融的差异化的业务场景，EasyFlow建立了消息路由模块，实时的针对消息规则以及业务场景进行匹配，提高流程的处理效率。</p><p></p><p>在使用EasyFlow初期，队列的部署策略如图所示</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/29/292de483db966fa851d29f7f22fc9c14.png\" /></p><p></p><p>流程消息生产到主队列，由消费者监听消费，当出现当前流程需要重试时，则会设置延迟执行时间，并发送到死信队列进行等待，当到达设置的消息执行时间后，死信队列会将消息放回主队列等待二次消费。这种模式在消息量积压不大、单笔消费速度快、消费过程对接的RPC等耗时流程相对耗时较短、以及业务场景要求的重试间隔整体固定时表现比较正常。但是随着好分期接入的资金渠道越来越多，流程的复杂性也逐步提升，各家服务的系统不稳定的问题频发，导致对消费这执行效率低，也会因消费者长时间消费占用，导致队列积压，整体流程执行暂停的重大问题。</p><p></p><p>为了将EasyFlow更好的应用于相对不稳定的业务的场景中，我们进行了流程引擎的高可用升级，将实际业务异常与队列的使用相结合，建立了消息路由的模块，更智能的针对不同异常场景的业务消息进行分发，保证流程引擎的高效运行。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2e/2e6f4d6e74468f3022aeb4ec844e3c23.png\" /></p><p></p><p>如图所示，我们之所以选择RabbitMQ作为消息中间件，就是为了使用RabbitMQ的exchage自身支持路由的特性，将消息路由节点放置在了producer发送消息后的阶段，根据消息属性，经过消息路由的路由规则判断，进行对应的topic的选择，并进行消息的分发。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/03/03deb4be2b4ee419b3e59598aac56256.png\" /></p><p></p><p>如图所示，该方案是基于业务场景高效使用消息队列的策略和实现方法，由三个模块构成：消息分发路由、路由规则维护模块、路由规则缓存。其中消息分发路由提供根据业务场景以及业务节点类型进行内部的计算，通过拉取规则缓存中的实时规则，对熔断降级、业务配置、消费耗时计算以及重试次数等不同维度，按照优先级进行快速高效的路由分发功能，经过多个规则的校验，得出最合理的队列进行消息的生产和后续的消费工作；路由规则维护模块是根据实际消息的消费过程的执行情况进行动态的规则维护，并同步到路由缓存进行规则更新；路由缓存是存储路由规则的缓存服务，该服务通过同步路由规则维护模块产生的规则变更，为消息分发路由的实时计算提供数据基础。</p><p></p><p>我们针对实际的线上业务以及其复杂度和对应的大部分异常进行兼容，并将异常场景与流程引擎引擎消息分发路由策略进行了结合。解决了如何在遵循队列执行特性的情况下，通过合理的分配路由算法，提高消息队列的执行效率的问题。在不同的业务场景或异常场景下，通过读取路由缓存的规则策略，以达到高效且稳定的实时选取最适合的发送队列，最大程度的来保障消息队列的运行效率，避免队列的阻塞积压。</p><p></p><p>根据线上业务的特殊性，每个任务的轮询时间频次是不一致的，所以我们采用对死信队列增加延迟插件的方式，解决了不同执行延迟消息的非阻塞的问题，从而增强业务系统承载能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/28/28f9ac2998a393c04353cc1d8c4bc7d9.png\" /></p><p></p><p>上面使用 DLX + TTL 的模式，消息首先会路由到一个正常的队列，根据设置的 TTL 进入死信队列，与之不同的是通过 x-delayed-message 声明的交换机，它的消息在发布之后不会立即进入队列，先将消息保存至 Mnesia ，这个插件将会尝试确认消息是否过期，首先要确保消息的延迟范围是 Delay &gt; 0, Delay =&lt; ERL_MAX_T（在 Erlang 中可以被设置的范围为 (2^32)-1 毫秒），如果消息过期通过 x-delayed-type 类型标记的交换机投递至目标队列，整个消息的投递过程也就完成了。</p><p></p><h3>五. EasyFlow在好分期的应用现状</h3><p></p><p></p><p>目前好分期资金接入系统WeFund已全面接入EasyFlow流程引擎，现阶段已管理维护 WeFund超过150+差异流程，1.5亿+流程实例创建，200亿+任务执行的场景，RabbitMQ消息量每天达1800w+，运行任务180w+，并发峰值超过1300+TPS；并且EasyFlow已经能够很好的适配复杂的业务场景，在同等资源下的资金接入工作由原有的14天缩短至7天，将业务流程的编排和策略制定实现0代码化开发，研发人员只需要专注于各家渠道的业务对接工作即可，不仅缩短了开发资源，对于测试、运营维护等工作也减少了大量的资源投入。</p><p></p><p>作者简介：</p><p></p><p>吴迪，北京微财科技有限公司产品技术高级总监</p><p>李军，北京微财科技有限公司技术总监</p><p>周正杭，北京微财科技有限公司JAVA开发资深工程师</p><p>彭伟煌，北京微财科技有限公司JAVA开发高级工程师</p><p>徐东，北京微财科技有限公司JAVA开发高级工程师</p>",
    "publish_time": "2022-07-06 10:41:23",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AI场景存储优化：云知声超算平台基于 JuiceFS 的存储实践",
    "url": "https://www.infoq.cn/article/G0i3cA6oX7YjwLVrO0C7",
    "summary": "<p>在AI场景中，文件存储中面临一些新的变化：非结构化数据、大量的小文件、训练数据读多写少等。这些变化，给存储带来新的挑战。今天我们邀请到“云知声”，一家从事语音及语言处理的AI企业，为大家分享他们的存储优化实践。全篇长达万字，想了解AI场景平台建设的伙伴们不要错过了。&nbsp;</p><p></p><h2>背景</h2><p></p><p></p><p>云知声是一家专注于语音及语言处理的技术公司。Atlas 超级计算平台是云知声的计算底层基础架构，为云知声在 AI 各个领域（如语音、自然语言处理、视觉等）的模型迭代提供训练加速等基础计算能力。Atlas 平台深度学习算力超过 57 PFLOPS（5.7 亿亿次／秒，是的你没有看错，是亿亿次），深度学习算力是衡量一个 AI 平台计算性能的核心指标。除了满足公司内部的业务需求，平台也为外部企业和院校机构提供定制化计算服务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/70/705edefa5ecb815b281d1125f1493089.png\" /></p><p></p><p>云知声&nbsp;Atlas 平台架构图</p><p>本文主要分享云知声 Atlas 超算平台（以下简称 Atlas）的存储建设历程以及基于 JuiceFS 建设高效存储的实践。</p><p></p><p></p><h2>存储建设历程</h2><p></p><p>一个性能卓越的超算平台，不仅需要充足的算力支持，也离不开高效的存储系统。结合 Atlas 上的任务特点和类型，高效存储系统应具备几个特点，如：满足多种类型的结构化与非结构化数据存储需求、兼容 POSIX 接口、海量小文件场景下具有较好的性能等。</p><p></p><p>在最早期进行 Atlas 超算平台建设的时候，我们尝试部署过 CephFS，开源版的 CephFS 在存储规模达到几千万小文件的时候，开始出现较为严重的性能问题，用户在操作文件时会遇到卡顿甚至在高 IO 的场景下整套存储系统会直接卡死，用户体验不太好。</p><p></p><p>后期，我们转到了 HPC 领域使用较为广泛的 Lustre 分布式文件存储系统， 构建了多套不同规模的 Lustre 集群，作为平台核心的存储系统，生产环境上目前主要有 40G 以太网与 100G InfiniBand 类型的集群，Lustre 分布式存储支持着用户在 Atlas 超算集群中进行数据处理、模型训练、源码编译与调试、数据归档等一系列数据操作。但是受限于 Lustre 在高并发请求下的性能瓶颈，无法满足对带宽与 IOPS 要求较高的场景需求。因此我们采用 Alluxio + Fluid 进行 IO 加速，分布式缓存给我们带来了 AI 模型训练速度上的提升以及存储系统总带宽的下降。</p><p></p><p>但是以上方案依然不是我们认为的最终方案，因此我们也在探索新的存储系统。在我们的场景上对这个新存储系统的核心需求是：</p><p>运维要足够简单：存储研发人员要能够较快的上手，运维人员后期的扩容、故障处理足够简单。Lustre 提供了IML[1]一系列的自动化部署与监控工具，在运维方面较为方便。但是由于 Lustre 的软件代码是在内核上运行，如果出现故障，问题定位就显得不那么直观，需要从内核消息这边定位，大部分操作涉及重启操作系统；数据可靠性：数据是 AI 公司宝贵的资产，算法工程师在存储上的数据要足够稳定与安全。Lustre 目前不支持文件系统级的冗余，只能通过硬件的 RAID 来抵御硬盘故障；客户端多级缓存功能：构建大规模数据存储系统（PB 量级以上）为了考虑成本数据大部分会存储在 HDD 上，为了自动区分冷热数据，并充分利用我们 GPU 服务器的接近 TB 级的内存与大量的独立 SSD 盘，我们希望具备客户端多级自动缓存功能 ，以应对高密集 I/O 的读写场景；社区活跃度：社区活跃度也是我们考虑的因素，活跃的社区在功能版本的迭代与 bug 的解决方面能有更快的响应。</p><p></p><p></p><h2>初识 JuiceFS</h2><p></p><p></p><p>云知声团队在 2021 年初了解到了 JuiceFS，并跟 Juicedata 团队进行了早期的方案对接、PoC 测试，目前 JuiceFS 已经上线到生产环境，我们也参与到 JuiceFS 开源社区的建设中。</p><p></p><h3>JuiceFS 的架构与优势</h3><p></p><p>JuiceFS 整体的架构由元数据引擎、对象存储集群以及 JuiceFS 客户端组成，其中元数据引擎与对象存储提供了多种方案供用户选择。通过 JuiceFS 存储的数据将持久化到对象存储（如 Amazon S3）中，相应的元数据可以根据场景和需求持久化到 Redis、MySQL、SQLite 以及 TiKV 等各种数据库引擎中。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c9/c96529b95cec09e2af9a1f39fd993a4c.png\" /></p><p>JuiceFS 架构图</p><p></p><p>不管是元数据引擎还是对象存储都有很多成熟的方案可以选择，如果是在公有云上使用通常也有全托管的服务开箱即用。JuiceFS 的元数据自动备份、回收站等特性一定程度上保障了数据的可靠性，避免一些意外情况导致数据丢失，当然如果是自己运维元数据引擎和对象存储依然需要做好数据备份。JuiceFS 的本地缓存特性可以自动将频繁访问的数据缓存到内存以及磁盘中，同时也会对文件的元数据进行缓存[2]。</p><p></p><h3>PoC 测试</h3><p></p><p></p><p>PoC 测试我们主要是在小规模环境上做可行性验证，关注的点是产品特性、运维方式、与上游调度、业务框架对接是否可行等。</p><p></p><p>PoC 测试环境我们搭建了一个单节点的 Redis + 3 节点的 Ceph 对象存储集群，在环境搭建方面因为 Redis 跟 Ceph 都比较成熟，部署运维方案可以参考的资料也比较全，而 JuiceFS 客户端能够以较为简单的方式对接元数据引擎跟对象存储。</p><p></p><p>业务的适配方面，JuiceFS 完全兼容 POSIX 协议，我们上层的业务可以无缝切换与对接，业务使用无感，JuiceFS 也支持以 CSI Driver 这种云原生的方式调度，与我们整个平台的技术栈契合。</p><p>在性能测试方面，我们在测试环境进行了文字识别模型的训练，实验环境为：模型采用服务器版中文识别模型 backbone 为 ResNet-18，数据整体总量是 98G 采用 LMDB 格式存储，在 6 张 NVIDIA Tesla V100 进行了三组实验，分别是：</p><p>直接在 Lustre 读在带有 200G 内存缓存的 JuiceFS 读在带有 960G SSD 缓存的 JuiceFS 上读</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/eb/eb650947e01071d246d65acc16c07e08.png\" /></p><p></p><p>耗时对比</p><p>JuiceFS 客户端拥有多级缓存功能，因而在性能测试中，在数据读方面有较大性能提升，相比 Lustre 性能有1倍以上的提升，这与我们的业务特点比较契合。</p><p>综合考虑运维方式、业务契合度以及性能表现，我们决定将 JuiceFS 带上生产。</p><p></p><p></p><h2>JuiceFS 在 Atlas 的使用场景与收益</h2><p></p><p></p><p>JuiceFS 客户端多级缓存目前主要应用在我们的文字识别、语音降噪以及语音识别场景。由于 AI 模型训练的数据读取特点是读多写少，我们充分利用 JuiceFS 客户端的缓存带来 IO 读取的加速收益。</p><p></p><p></p><h3>收益一：加速 AI模型训练</h3><p></p><p>1）语音降噪测试</p><p>降噪场景模型的测试中使用的是散文件，每个数据都是 wav 格式的小于 100k 的语音小文件，在降噪场景我们测试了数据 dataload 阶段的 I/O 数据，JuiceFS 客户端节点的内存缓存为 512G，在 500h 规模的数据下、以 40 的 batch size 进行测试。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c7/c7c8c5b72cd3c95e47612b00a0b05327.png\" /></p><p></p><p>Lustre vs. JuiceFS 每秒处理数据量对比</p><p></p><p>从测试结果来看，单从数据读取效率上，在 wav 小文件方面，JuiceFS 为 6.45 it/s，而 Lustre 为 5.15 it/s，性能提升25%。JuiceFS 有效加速了我们端到端的模型训练，整体缩短了模型的产出时间。</p><p>2）文字识别场景</p><p>在文字识别场景中，模型为 CRNN backbone 为 MobileNet v2 ，测试环境如下：</p><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1e/1e5f60d78ebedcbdfbe85cdab4d436c5.png\" /></p><p></p><p>Lustre vs. JuiceFS 每个 batch 耗时对比</p><p></p><p>在这个测试中，主要做了 JuiceFS 跟 Lustre 的速度对比，从实验的结果来看从&nbsp;Lustre 读每个 batch 耗时 1.5s，从 JuiceFS 读每个 batch 耗时为 1.1s，提升36%。从模型收敛的时间来看，从 Lustre 的 96 小时下降到 JuiceFS 的 86 小时，使用 JuiceFS 能够将 CRNN 模型的产出时间缩短 10 小时。</p><p></p><h3>收益二：加速 AI模型开发</h3><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b8/b83fe696746ab7d4685b34a900b3798e.png\" /></p><p></p><p></p><p>模型开发示意图</p><p></p><p>在算法工程师将 AI 模型训练任务正式提交到超算集群之前，其模型需要经过大量的调试，我们为用户提供了调试环境，Dev Node 跟 Atlas 正式训练集群一样都是使用相同的存储，开发节点与训练节点都挂载 JuiceFS 客户端，因此在开发机的修改能够无缝迁移到 Atlas 训练集群。</p><p></p><p>用户在开发机上可以灵活地选择开发环境，既可以在宿主机搭配 Anaconda 进行远程调试，也可以使用容器的方式运行开发环境。用户的调试模型大部分是 PyTorch 跟 TensorFlow 类型的框架，我们发现在调试的时候需要频繁地 import Python 包，例如 numpy、torch 等，这种包都是大量的小文件组成的，基于旧的存储系统，用户 import 包的耗时需要几秒或者几十秒。算法人员反馈模型调试的效率比较低。作为统一开发环境，伴随着大量的安装包导入、代码编译、日志读写、样本下载，这要求调试机既能有较高的吞吐量，又能快速处理大量小文件。</p><p></p><p>通过引入 JuiceFS，我们在开发机上挂载了 JuiceFS 客户端，客户端挂载时候使用元数据缓存以及数据读缓存机制。在元数据缓存方面，当 JuiceFS 客户端使用 open() 操作打开一个文件的时候，其文件属性（attribute）就会自动缓存在客户端内存中，只要缓存未失效则随后执行的 getattr() 跟 open() 操作都会从内存缓存中立即返回结果。在执行 read() 操作的时候文件的 chunk 和 slice 信息也会自动缓存在客户端内存。数据缓存方面我们使用内存作为缓存介质，采用该方式用户调试的 Python 包在经过第一次 import 之后会全部缓存在内存上，第二次调试的时候，直接从内存缓存读取文件。相比之前的方式，整体速度有 2-4 倍的提速 ，极大地提高了用户的调试效率，用户的体验也更加好。</p><p></p><p></p><h2>JuiceFS 在 Atlas 的使用方式</h2><p></p><p></p><p>在数据的存放管理方式上，我们采用兼容现有分布式存储系统的管理方式，JuiceFS 集群的节点也都是对接 LDAP，每个节点会通过 LDAP 的客户端与 LDAP Server 集群进行交互认证。</p><p>超算平台上的每个组归属于不同的目录，每个目录下是各自组内或者部门内的成员，不同组之间的目录是不可见的。目录的权限是基于 Linux 的权限管控机制。用户在 Atlas 集群提交训练任务的时候，集群的任务提交工具会自动读取系统上用户的 UID 与 GID 信息然后将其注入用户提交的任务 Pod 的 securityContext 字段，则 Atlas 集群上运行的容器 Pod 内所有容器的进程运行的 UID 与存储系统上的信息一致，保证权限不越界。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/06/060f1394930d28c7f26fcfd9a3abe153.png\" /></p><p></p><p>存储权限认证架构图</p><p>在数据的访问方式上，云知声目前有 2 种使用方式：</p><p>一种是通过计算节点的 HostPath 访问数据；另一种是更加云原生的方式，通过结合 Fluid + JuiceFS 对利用 JuiceFS 客户端为 Atlas 的应用提供数据的访问与加速。</p><p></p><p></p><h4>1）HostPath Volume</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7d/7de7c53f88379b269becff1b8109187c.png\" /></p><p></p><p></p><p>HostPath Volume 数据读取示意图</p><p></p><p>第 1 种还是沿用之前的访问分布式文件存储系统的方式，通过 Kubernetes HostPath 的方式直接访问本地的存储系统客户端，我们在所有的 CPU 与 GPU 计算节点都部署了 JuiceFS 的客户端，用户提交计算任务的时候需要指定 Kubernetes volume 为 HostPath 的方式，将 JuiceFS 的目录映射。这种方式的缓存管理就比较裸，在用户侧是无法对缓存进行管理的。</p><p></p><h4>2） Fluid + JuiceFS</h4><p></p><p>第 2 种方式是结合 Fluid + JuiceFS 的方式，关于如何使用的具体方式可以参考我们之前的文章（点击<a href=\"https://mp.weixin.qq.com/s?__biz=Mzg5MjUyNjExMw==&amp;mid=2247486009&amp;idx=1&amp;sn=3b226a7701cc3b3c154cee2ee3dc3602&amp;scene=21#wechat_redirect\">此处</a>\"查看）&nbsp;，这里仅对架构做个简单的说明。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c9/c95cf555973fc787c1eaaa3abe88df9e.png\" /></p><p></p><p>基于 Fluid 数据读取示意图</p><p></p><p>Fluid 会启动 JuiceFS 相关的组件包括 FUSE 跟 Worker pod，其中 FUSE Pod 提供了 JuiceFS 客户端的缓存能力，Worker Pod &nbsp;则实现了对缓存生命周期的管理，Atlas 平台的 AI 离线训练任务通过与 FUSE Pod 客户端交互，进行 AI 训练数据的读取，通过 Fluid 提供的缓存调度能力以及数据集的可观测性，平台的用户可以通过亲和调度将缓存部署在特定的计算节点上，同时用户能够直观的看到缓存的使用情况（例如缓存数据集的大小、缓存的百分比、缓存的容量等）。</p><p></p><p></p><h2>JuiceFS 存储生产环境建设</h2><p></p><p></p><h3>元数据引擎</h3><p></p><p>目前我们生产环境的元数据引擎采用 Redis，Redis 节点的系统盘做了 RAID1，同时 Redis 持久化的数据会定期同步到另一台备份节点上。Redis 的数据持久化我们采用 AOF + RDB 的方案，每秒进行一次数据持久化，相关配置如下：</p><p><code lang=\"null\">appendonly yes \nappendfsync everysec \naof-load-truncated yes</code></p><p>由于我们节点采用的是 100G InifiBand，IB 的&nbsp;网卡驱动[3]&nbsp;需要用户根据自己的操作系统版本下载对应的 ISO。目前我们的节点是采用 Kernel 5.4 的版本，由于 IB 驱动跟操作系统还有 Kernel 版本有较强的耦合性，当我们 Kernel 升级到 5.4 版本，驱动需要重新编译安装，驱动版本 MLNX_OFED_LINUX-5.5-1.0.3.2-rhel7.6-x86_64.iso 注意 GCC 的版本一定要是 GCC 9 的才行，否则编译过程会出现各种莫名其妙的问题。</p><p><code lang=\"null\"># 安装 gcc9 \nyum --enablerepo=extras install centos-release-scl-rh \nyum install devtoolset-9-gcc scl enable devtoolset-9 bash \n# 进行 IB 驱动编译 \nmount /dev/sr0 ib&nbsp;\n./mlnx_add_kernel_support.sh -m /root/ib -k (kernel 版本)</code></p><p></p><h3>对象存储</h3><p></p><p>对象存储采用自建的 Ceph 集群，Ceph 集群采用 Cephadm 进行部署，目前生产环境用的是 Octopus 版本。Cephadm 是随着 Ceph 新版本 v15.2.0（Octopus）发布的安装工具，并且不支持 Ceph 的旧版本，Cephadm 不依赖于外部配置工具，如 Ansible、 Rook 和 Salt，它通过 SSH 将管理器守护进程连接到主机来实现这一点。管理器守护进程可以添加、删除和更新 Ceph 容器。</p><p>通过 Cephadm 引导一个单节点的集群，Cephadm 会在执行 bootstrap 引导的节点部署 mgr 跟 mon 服务，当添加其他节点的时候，会自动在其中一台部署 mgr 管理节点，目前我们生产采用 2 个管理节点&nbsp; 3 个监控节点。</p><p>在 Ceph 调优方面我们借鉴了社区其他用户分享的方案，感谢携程的工程师在我们调优过程中提供的帮助 （点击<a href=\"https://mp.weixin.qq.com/s?__biz=Mzg4NTU0MzEyMg==&amp;mid=2247495811&amp;idx=2&amp;sn=475c9f9cb910f05f9eb93a8de1033e4a&amp;scene=21#wechat_redirect\">此处</a>\"查看），主要做了以下实践：</p><p>服务器层面[4]：</p><p>42Cores 256GB&nbsp;24*18T HDD&nbsp;系统盘: 2* 960G SAS SSDBlueStore关闭 NUMA升级 kernel: 5.4.146&nbsp; 开启 io_uringKernel pid max，修改 /proc/sys/kernel/pid_max</p><p></p><p>Ceph 配置方面：</p><p>Ceph RADOS：直接调用 librados 接口，不走 S3 协议&nbsp;Bucket shard关闭 pg&nbsp; 的自动调整功能OSD 日志存储（采用 bluestore，建议裸容量配比—— block : block.db : block.wal = 100:1:1，后两者建议采用 SSD 或 NVMe SSD）3 副本</p><p></p><h3>JuiceFS 客户端</h3><p></p><p>我们环境中 JuiceFS 对接的对象存储是 Ceph RADOS，JuiceFS 采用 librados 与 Ceph 进行交互，因此需要重新编译 JuiceFS 客户端，建议 librados 的版本要跟 Ceph 的对应，例如在我们的环境 Ceph 版本是 Octopus（v15.2.*），librados 的版本建议为 v15.2.*，CentOS 自带的 librados 版本比较低，因此我们可以在官网自己下载对应的包，我们的环境上只需要下载 librados2-15.2.10-0.el7.x86_64.rpm 和 librados-devel-15.2.10-0.el7.x86_64.rpm。然后运行如下命令安装：</p><p><code lang=\"null\">yum localinstall -y librad*</code></p><p>安装 librados 后即可编译 JuiceFS 客户端了（推荐 Go 1.17+ 、GCC 5.4+）：</p><p><code lang=\"null\">make juicefs.ceph</code></p><p>编译完 JuiceFS 即可创建文件系统并在计算节点进行 JuiceFS 客户端的挂载了。目前 JuiceFS 在我们的生产环境使用还是有一大部分是直接通过 Kubernetes 的 HostPath 进行挂载，因此我们在各个 GPU、CPU 节点中都挂载了 JuiceFS 客户端，并通过 systemctl 管理 JuiceFS 的挂载进程，实现开机自动挂载与故障的恢复。</p><p></p><p></p><h2>未来展望与规划</h2><p></p><p>最后归纳下 Lustre 与 JuiceFS 的特点与适用场景，企业可以根据自身的业务场景、运维能力以及存储规模做出相应的选择。</p><p>Lustre 作为老牌 HPC 领域的存储系统，为许多全球最大的超算系统提供动力，具有多年的生产环境经验。其具有符合 POSIX 标准、支持各种高性能低时延的网络，允许 RDMA 访问的优点，适用于传统 HPC 领域的高性能计算，但是在云原生场景的适配上还不够完善，目前只能采用 HostPath Volume 对接，而且其软件运行在 Linux 内核之上，对运维人员要求更高；JuiceFS 是一款云原生领域的分布式存储系统产品，提供了 CSI Driver 以及 Fluid 等方式使用能够更好地与 Kubernetes 进行结合。在运维部署方面为用户提供了更多灵活的选择，用户既可以选择在云上也可以选择私有化部署，在存储扩容运维方面较为简单。完全兼容 POSIX 标准使得深度学习的应用可以无缝迁移，但是由于后端对象存储的特点其在随机写方面会有较高的延迟，在只读的场景可以使用客户端的多级缓存进行加速较为符合我们的业务特点。</p><p></p><p>Atlas 平台未来与 JuiceFS 相关的规划是：</p><p>元数据引擎升级：TiKV 适合在 1 亿以上文件数量（最多可以支撑到百亿级文件），对性能以及数据安全都有较高要求的场景，目前我们已经完成了 TiKV 的内部测试也在积极跟进社区的进展，后续要将元数据引擎迁移到 TiKV。</p><p></p><p>基于目录（项目）的文件配额：开源版本目前还不支持基于目录的配额，目前我们每个部门是归属在 JuiceFS 的不同的目录下，需要对目录的配额做限制。JuiceFS 社区版已经在规划实现这个特性，会在 v1.0.0 之后的版本正式发布。</p><p></p><p>感谢 JuiceFS 开源社区在云知声 Atlas 计算平台高效存储建设的过程中提供的技术支持，云知声也在积极地进行内部测试，争取后续将开发的功能以及改进回馈到开源社区。</p><p></p><p>引用链接</p><p>[1] IML:&nbsp;https://whamcloud.github.io/Online-Help/docs/IML_Help_TOC.html</p><p>[2]&nbsp;https://juicefs.com/docs/zh/community/cache_management</p><p>[3] 网卡驱动：https://www.mellanox.com/products/infiniband-drivers/linux/mlnx_ofed</p><p>[4]&nbsp;https://docs.ceph.com/en/latest/start/hardware-recommendations</p><p></p><p>作者简介：</p><p>吕冬冬，云知声超算平台架构师，负责云知声大规模分布式机器学习平台架构设计与新功能演进，负责深度学习算法应用优化与 AI 模型加速。研究领域包括大规模集群调度、高性能计算、分布式文件存储、分布式缓存等。云原生开源社区爱好者。</p>",
    "publish_time": "2022-07-06 11:00:33",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Curp共识协议的重新思考",
    "url": "https://www.infoq.cn/article/qm3jUlY2iSsyyj6dWmFS",
    "summary": "<p></p><h1>共识简介</h1><p></p><p>共识协议是一种让分布式系统中多个节点保持信息一致的通信协议，即使少数节点发生故障也依然能够保证信息的准确和一致。而每当我们在讨论共识协议的时候往往会想到 classic paxos 或者 raft 协议，这两个协议是很多其他协议的基础，后续的很多协议都可以看成是它们的变种，例如 <a href=\"https://en.wikipedia.org/wiki/Paxos_(computer_science)\">Multi-Paxos</a>\"和 <a href=\"https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-2005-112.pdf\">Fast-Paxos</a>\"等等。我们今天先从这两个协议入手，先来回顾一下这两个协议是如何工作的。</p><p></p><p>首先来看 classic paxos 协议，如下图所示。Paxos 分为两个阶段（Phase)，第一个阶段是 Prepare，主要任务是在 Log 上占一个 Slot，第二个阶段为 Accept，主要是确定这个 Slot 已经明确被占用了，且在两个阶段间没有被其他人抢占。当 Client 收到绝大多数人的 Accept Ok 回复之后，说明该条记录已经被提交，在整个系统达成了共识。这里 Client 和 Proposer 可以视为一个整体，整个过程在两个阶段分别有一次消息传递，总共发生两次消息传递。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/af/84/af1dec9d961cb69756b9eaa9a2be3484.png\" /></p><p></p><p></p><p>然后我们再看 raft 协议，如下图所示。Raft 也是通过 Client 来发起，Client 向 Leader 发送请求，Leader 将请求广播给所有 Follower，当超过半数 Follower 回复消息，Leader 确定该请求被提交，然后将消息回复给 Client。这里 Client 和 Leader 之间进行了一消息传递，Leader 和 Follower 之间进行了一次消息传递，总共发生了两次消息传递。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/05/d1/05d414070cc8bce658b555b632b3a2d1.png\" /></p><p></p><p></p><p>我们发现在上述的两个协议中，想要达成共识就必须要经过两次消息传递。两次消息传递在数据中心内部还不会造成太大的影响，增大的请求延迟往往还可以接受，但是在跨数据中心的场景下，每多一次消息传递就增加几十甚至上百毫秒的延迟，所以减小消息传递的数目在跨数据中心的场景下就非常必要。</p><p></p><p>接下去大家一定会问“两次消息是必要的的吗”？回答是在 Raft 和 Classic Paxos 的条件下，两次消息传递是必须的，因为他们同时保证了两个特性：</p><p></p><p>请求一旦被commit，则不会被修改或者丢失。请求执行顺序一旦被确定，顺序也不会被修改或丢失。</p><p></p><p>想要同时保证这两个特性，一次消息传递一定不够。在 paxos 这种无 Leader 的协议中，一次消息传递只能保证绝大多数节点收到的了请求，那么第 1 个特性能够保持，但是多个请求间的顺序没有办法在多节点间保持一致，破坏了第 2 个特性。在 Raft 这种有 Leader 的协议中，一次消息传递只能让 Leader 确定执行顺序，也就是第 2 个特性，但无法保证该请求不会丢失，因为此时只有 Leader 节点获悉这个请求。</p><p></p><p>那么我们有什么办法来减少一次消息传递呢？答案是放松特性，将特性 2 中的“全局唯一执行顺序”给舍弃，改变成“相冲突的请求保证全局唯一执行顺序，无关的请求可乱序执行”。<a href=\"https://www.usenix.org/system/files/nsdi19-park.pdf\">Curp</a>\" 协议就是引入了这个思想，仅通过 1 个消息传递实现共识协议。下面这个章节我们来介绍 Curp 协议。</p><p></p><h1>Curp 共识协议</h1><p></p><p>本章我们来聊一聊 Curp 如何通过 1 个消息传递达成共识。因为细节繁琐和篇幅限制，本文不会完整讨论 Curp 共识协议的所有方面，而是摘取其中的关键点来阐述。下图为 Curp 协议的示意图：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/f0/6f/f027f3a33f73f00091e8c2ba6caa066f.jpg\" /></p><p></p><p></p><p>主要流程描述如下：</p><p></p><p>Client 向包括 Master(Leader) 的所有节点发送请求。所有服务节点都维护一个请求“等待池子”，图中的蓝色请求都在“等待池子”中，这些请求都还没有完成同步。所有服务节点收到 Client 发送来的请求后会检查当前请求和“等待池子”中的所有请求是否冲突，如果冲突，则给 Client 回复请求冲突，如果不冲突，则给 Client 回复请求不冲突。Client 在收集到不少于 (f + (f + 1)/ 2 + 1) 个“请求不冲突”回复且其中包含 Master 的回复后，认为该请求已经被 committed。否则 Client 等待 Master 将请求同步到绝大多数节点，而Master 在同步完成后会将请求移出等待池子，并且通知 Client 请求达成共识。</p><p></p><p>这里我们以问答的方式来解释 Curp 协议，方便大家理解。</p><p></p><p>Q1. Client 在收到不少于 (f + (f + 1)/ 2 + 1) 个“请求不冲突”回复且其中包含 Master 的回复后，为什么能够确认请求被 committed？A1：因为等待队池子是具有排他性质的，被绝大多数节点认可说明该请求在绝大多数的节点上不存在冲突，也阻止了后续可能冲突的请求被提交。此时即使有 f 个节点发生故障，我们仍然能够在  (f + 1) / 2 + 1 个节点上找到这个请求，请求不会丢失。这样不仅保证了这个请求一定不会丢失，还因为有之前的冲突检查，也保证了冲突请求间的执行顺序。</p><p></p><p>Q2. 上一个问题中数字 (f + (f + 1)/ 2 + 1) 很奇怪，为什么不是 f + 1？A2：共识协议最多允许 f 个节点发生故障，那么剩下的节点为 f + 1 个，最糟糕的情况中，那 f 个发生故障的节点全部包含了该请求，那么剩下的 f + 1 中还至少存在 (f + 1) / 2 + 1 个节点包含该请求，占有绝大多数，方便恢复流程将该请求恢复，防止丢失。</p><p></p><p>Q3. 是否所有的情况下 Curp 都能够在 1 个消息传递后达到共识？A3：不能保证。最好的情况是所有的请求都不互相冲突，那么所有请求都能够在一个消息传递后达到共识；最坏情况是所有的请求都相冲突，那么几乎所有请求都需要等 Master(Leader)节点完成同步后，Client 才能确认请求被 commit，这种情况就是 2 个消息传递，和 Raft 类似。</p><p></p><p>Q4. Master 同步请求的协议细节是什么？A4：Master 同步请求的方式 Raft Leader 节点一样，完全没有区别。</p><p></p><p>Q5. Curp 协议的恢复流程是如何的？A5：首先恢复流程需要选举一个新的 Master(Leader)，该流程和 Raft 一样。接下来的恢复流程可以大体分成两个模块：已经同步的请求部分，恢复流程和 Raft 协议保持一致；那些还没有被同步的请求需要从所有节点收集，当收集到 f + 1 个节点（包括新Leader自己）信息后，保留其中出现至少 (f + 1) / 2 + 1 次的请求，因为这些请求有可能已经被commit了，因此不能丢失。</p><p></p><h1>Curp 协议总结和讨论</h1><p></p><p>通过上一个章节的论述，我们不难发现 Curp 协议和 Raft 协议非常像，其中的不同点就在于“等待池子”，这个池子的目的在于给冲突的请求排序，多个冲突请求一定不能被所有节点的“池子”同时接受，此时最多只有一个请求被 commit，也有可能所有请求都需要等待 master 的同步。也就是这个改动，让协议在某些情况下有更优秀的性能表现。</p><p></p><p>所以总结一下， Curp 协议在乐观情况下一个消息传递就能达到共识，悲观情况下会退化成 Raft 协议，需要两个消息传递才能达成共识。</p><p></p><p>关于 Curp 协议的更多细节请参考原始<a href=\"https://www.usenix.org/system/files/nsdi19-park.pdf\">论文</a>\"。</p>",
    "publish_time": "2022-07-06 11:27:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]