[
  {
    "title": "开源 ML 社区的新星，Kubeflow 正式成为 CNCF 项目",
    "url": "https://www.infoq.cn/article/qtLPqywUBdDVuwXiSc6b",
    "summary": "<p><a href=\"https://www.cncf.io/\">云原生计算基金会（CNCF）</a>\"最近<a href=\"https://www.cncf.io/blog/2023/07/25/kubeflow-brings-mlops-to-the-cncf-incubator/\">宣布</a>\"，在<a href=\"https://www.cncf.io/people/technical-oversight-committee/\">技术监督委员会（TOC）</a>\"投票后，已接受<a href=\"https://www.kubeflow.org/\">Kubeflow</a>\"，用于在<a href=\"https://kubernetes.io/\">Kubernetes</a>\"上部署机器学习（ML）工作流的工具包，成为CNCF孵化项目。</p><p>&nbsp;</p><p>Kubeflow提供了一个开源的Kubernetes原生MLOps平台，用于为最流行的框架来开发和部署分布式机器学习（ML）：<a href=\"https://www.tensorflow.org/\">TensorFlow</a>\"、<a href=\"https://pytorch.org/\">PyTorch</a>\"、<a href=\"https://xgboost.readthedocs.io/en/stable/\">XGBoost</a>\"、<a href=\"https://mxnet.apache.org/versions/1.9.1/\">Apache MXNet</a>\"等等。</p><p>&nbsp;</p><p>Kubeflow由谷歌于2017年创建，自2017年以来，该社区现拥有150家公司、28K+ GitHub Stars、15+ 提交者以及15个版本。该项目分为六个半独立的小组：</p><p>&nbsp;</p><p>Notebooks工作组：负责开发界面和交互式部署环境训练Operator小组：开发并训练operator，以便在Kubernetes上进行分布式ML训练AutoML小组：开发了自动化模型开发软件KatibKubeflow Pipeline工作组：开发了将Python ML脚本转换为工作流模板的软件Manifest工作组：开发安装过程KServe项目：在Kubernetes上开发了高度可扩展的模型推理平台</p><p>&nbsp;</p><p>当前Kubeflow的架构如下图所示：</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b3/b3fda0359f4a036dedf4ba78c1adcd7d.png\" /></p><p></p><p>&nbsp;</p><p><a href=\"https://www.kubeflow.org/docs/started/architecture/\">Kubeflow架构</a>\"</p><p>&nbsp;</p><p>使用Kubeflow配置接口，可以指定工作流所需的ML工具，并且可以将其部署到各种云、本地和on-premises平台上，用于实验和生产。</p><p>&nbsp;</p><p>TOC赞助商Ricardo Rocha表示：</p><p>&nbsp;</p><p></p><blockquote>Kubernetes环境提供了可重复性、可扩展性和快速交付，使其成为运行AI和ML计划的完美场所。Kubeflow通过提供机器学习管道和MLOps来填补了这一空白，同时与其广泛的社区和其他工具及计划密切合作，以创建一个更具凝聚力的生态系统。我们很高兴看到Kubeflow项目在CNCF中的发展，并看到它在MLOps领域的进步。</blockquote><p></p><p>&nbsp;</p><p>&nbsp;</p><p>云原生计算基金会为项目定义了三个成熟度级别：沙箱阶段、孵化阶段和毕业阶段。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/014a6c279d56ccb130b582c90ad99855.png\" /></p><p></p><p>&nbsp;</p><p>项目阶段</p><p>&nbsp;</p><p>每个被提议的项目都要经过一个后备（fallback）投票过程，该过程由<a href=\"https://github.com/cncf/toc/blob/main/process/graduation_criteria.md\">TOC毕业标准</a>\"来描述：</p><p>&nbsp;</p><p></p><blockquote>一个项目需要有高于三分之二的绝对多数赞成才能被接受为孵化或毕业。如果没有绝对多数的赞成选票来支持项目进入毕业阶段，那么任何毕业的选票都会被重新计算为项目进入孵化阶段的选票。如果没有绝对多数的选票来支持项目进入孵化阶段，那么任何毕业或孵化的选票都会被重新计算为项目进入沙箱阶段的赞成选票。如果没有足够的赞成选票来支持项目进入沙盒阶段，该项目将被拒绝。</blockquote><p></p><p>&nbsp;</p><p>云原生计算基金会（CNCF）生态系统负责人Taylor D.在LinkedIn上<a href=\"https://www.linkedin.com/posts/onlydole_kubeflow-brings-mlops-to-the-cncf-incubator-activity-7089722163364016131-csGZ?trk=public_profile_like_view\">发表了一篇专门的帖子</a>\"，以庆祝Kubeflow作为孵化项目加入CNCF。</p><p>&nbsp;</p><p>&nbsp;</p><p>Kubeflow的主要替代方案是亚马逊的<a href=\"https://aws.amazon.com/sagemaker/?nc=sn&amp;loc=1\">Sagemaker</a>\"，这是由AWS完全管理的机器学习平台。</p><p></p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/08/kubeflow-cncf-project/\">https://www.infoq.com/news/2023/08/kubeflow-cncf-project/</a>\"</p>",
    "publish_time": "2023-09-13 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AI大模型背后的惊人数字：问ChatGPT 5个问题，耗水500毫升？训练一次GPT-3，碳排放量相当于开车往返月球？",
    "url": "https://www.infoq.cn/article/NuKxISZRb5sjg1lXgmeN",
    "summary": "<p>ChatGPT 的爆火掀起了 AI 大模型热潮，但科技进步始终是把双面剑，AI 大模型带来诸多便利的同时，也引发了人们关于能源消耗与环境污染的担忧。此前，曾有研究称训练 GPT-3 的碳排放量等同于开车往返月球，也有研究称训练人工智能模型比长途飞行排放的碳要多得多。</p><p>&nbsp;</p><p>能源消耗方面，构建大语言模型需要分析海量人类文章内容中蕴藏的模式，所有这些计算都要消耗大量电力并生成可观的热量。为了保持凉爽，数据中心需要泵水冷却，并将其存储在机房之外如仓库般大小的冷却塔中。</p><p>&nbsp;</p><p>近日，外媒报道称，微软用于支持 OpenAI 的技术设施需要大量用水，这些水抽取自爱荷华州中部浣熊河和得梅因河的分水岭处，被用于冷却一台强大的超级计算机。一份研究显示，ChatGPT 这类 AI 大模型耗水量惊人：用户每向 ChatGPT 提出 5-50 条提示词或问题，ChatGPT 就会消耗掉 500 毫升的水。</p><p></p><h2>问ChatGPT 5-50个问题，耗水500毫升</h2><p></p><p>&nbsp;</p><p>日前，微软在其最新环境报告中透露，从 2021 年到 2022 年，公司全球设施用水量猛增了 34%（达到近 17 亿加仑，相当于 2500 多个奥运会级别的赛级泳池）。这个数字远远高于几年前外部研究人员的统计，而背后的驱动力量自然就是 AI 构建的需求。</p><p>&nbsp;</p><p>对此，加州大学河滨分校研究员 Shaolei Ren表示，“可以合理推断，（用水量）大部分增长要归功于 AI”，包括“对生成式 AI 的大量投入以及同 OpenAI 公司的合作。”</p><p>&nbsp;</p><p>谷歌报告称用水量同比增长了 20%，Ren 认为这很大程度上也源自 AI 研究需求。当然，谷歌的用水量增长并不均匀——其俄勒冈州基础设施的用水量保持稳定，但拉斯维加斯周边地区的用量则翻了一番。爱荷华州同样成为用水大户，谷歌在这里的康瑟尔布拉夫斯数据中心消耗的水资源比其他任何地方都要多。</p><p>&nbsp;</p><p>在即将于今年晚些时候发表的论文中，Ren 研究团队估计用户每向 ChatGPT 提出 5-50 条提示词或问题，ChatGPT 就会消耗掉 500 毫升的水（具体数字取决于基础设施所在位置和季节气候）。这一估算还未包含未经测量的间接用水，例如数据中心冷却电力所对应的发电耗水。</p><p>&nbsp;</p><p>Ren 表示，“大多数人并不清楚 ChatGPT 的资源消耗情况。但如果我们不了解资源用量，就没办法帮助节约资源。”</p><p>&nbsp;</p><p>据了解，微软于 2019 年向总部位于旧金山的 OpenAI 划拨了首笔 10 亿美元投资。随后，OpenAI 正式发布了 ChatGPT。作为合作协议的一部分，微软负责为 OpenAI 提供 AI 模型训练所需要的算力。</p><p>&nbsp;</p><p>为了践行承诺，两家公司纷纷将目光投向爱荷华州的西得梅因——十多年来，这座拥有 6.8 万人口的市镇一直是微软的数据中心聚集地，负责为其云计算服务提供支持。微软的第四和第五处数据中心将于今年晚些时候在这里开放。</p><p>&nbsp;</p><p>据了解，一年中的大部分时间里，爱荷华州当地的气候都相当凉爽，微软可以直接利用室外空气来保持超级计算机正常运行，并将产生的热量直接排放出去。该公司在一份披露报告中表示，只有在温度超过 29.3 摄氏度时，他们才需要切换为水冷模式。</p><p>&nbsp;</p><p>但即便如此，当地设施在夏天的用水量仍然相当惊人。据西得梅因水厂介绍，2022 年 7 月，也就是 OpenAI 正式完成 GPT-4 训练的前一个月，微软向其爱荷华州数据中心集群泵入约 1150 万加仑的水，约占该地区总用水量的 6%。</p><p>&nbsp;</p><p>2022 年，该水厂的一份文件提到，除非微软能够“证明并落实能够显著降低峰值期用水量的技术”，否则该公司及当地政府将不再“考虑批准微软未来的数据中心项目”。因为只有这样，他们才能保障当地住宅和其他商业运营的供水需求。</p><p>&nbsp;</p><p>微软表示，他们正与水厂直接合作以解决对方反馈的问题。水厂方面则通过书面声明指出，微软一直是其良好合作伙伴，也始终在与当地官员合作，探讨如何在满足需求的同时减少水资源消耗。</p><p></p><h2>大模型的碳排放量有多少？</h2><p></p><p>&nbsp;</p><p>除了能源消耗，ChatGPT 这类 AI 大模型的碳排放量也曾引发大众担忧。此前曾有计算机科学家称，GPT-3 整个训练周期的碳排放量，相当于开车到月球再返回地球；GPT-3 一轮训练所消耗的电量，足以支撑丹麦 126 个普通家庭度过一整年。</p><p>&nbsp;</p><p>做出这一猜测的专家来自丹麦哥本哈根大学，他们开发出名为 Carbontracker 的开源工具，用于预测 AI 算法的碳足迹。Carbontracker 估计，微软数据中心内使用英伟达 GPU 构建的神经超级网络运行功率约为 19 万千瓦时，如果按照美国的平均碳排放水平计算，这将产生 8.5 万公斤（85 吨）的二氧化碳，相当于 2017 年制造一辆新车所产生的排放量。这样的排放量相当于车辆在欧洲行驶 80 万公里，基本相当于开车到月球再返回地球的总行驶距离。</p><p>&nbsp;</p><p>Carbontracker 的创造者之一、AI 电力消耗研究论文联合作者 Lasse Wolff Anthony 认为，社区必须认真对待资源消耗问题。文章提到，从 2012 年到 2018 年之间，AI 研究的能源成本增长了约 30 万倍。</p><p>&nbsp;</p><p>Anthony 在采访中表示，“二氧化碳估值是根据模型训练期间，当地发电的平均碳排放量再加上运行模型的硬件总功耗所计算得出。”“我们通过多个 API&nbsp;来跟踪碳排放强度。如果模型训练所在地区没有 API 可用时，我们则会默认取欧洲平均值，因为目前还没有免费开放的全球监测数据。这些 API 会在训练期间定期查询硬件能耗，以准确估算总体碳足迹。”</p><p>&nbsp;</p><p>当然，上述结果的前提是假设训练 GPT-3 的数据中心完全依赖于化石燃料，这跟实际情况可能有所出入。</p><p>&nbsp;</p><p>有分析认为，当前大模型的碳排放量可能被严重夸大。事实上，全球科技行业占总体温气体排放量的比例仅为 1.8%-3.9%，而其中又只有一小部分与 AI 相关。在规模层面，AI 的碳排放还远无法与航空等其他主要碳源头相提并论。相较于随时运行的汽车和飞机，训练 GPT 这类模型所对应的碳排放量绝对称不上主要矛盾。</p><p>&nbsp;</p><p>相较于随时运行的汽车和飞机，训练 GPT 这类模型所对应的碳排放量绝对称不上主要矛盾。</p><p>诚然，目前我们并不清楚到底有多少大 AI 模型正在训练当中，但如果只考虑 GPT-3 或其他规模更大的模型，那么此类模型成果总计还不到 1000 个。这里我们可以做个简单计算：</p><p>&nbsp;</p><p></p><blockquote>最近一项评估认为，训练 GPT-3 排放了 500 吨二氧化碳，Meta 的 Llama 模型则估计排放 173 吨。如果训练 1000 个这样的模型，那么总二氧化碳排放量约为 50 万吨。2019 年，商业航空业排放了约 9.2 亿吨二氧化碳，几乎是大语言模型训练的 2000 倍。而且要注意，这是一年的航空业运营对比多年来的大语言模型训练。虽然后者的环境影响值得关注，但过度夸大明显有违客观公平，需要更细致地斟酌考量。</blockquote><p></p><p>&nbsp;</p><p>当然，这里讨论的还只是模型训练阶段。模型的运行和使用同样要消耗电力并产生相关排放。根据一项分析，ChatGPT 运行一年可能会排放约 1.5 万吨二氧化碳。但另一项分析结果则乐观得多，认为约在 1400 吨左右。但无论取哪个数字，虽然没有低到忽略不计的程度，但与航空业相比仍有几个数量级的差距。</p><p>&nbsp;</p><p>需要强调的是，问题的重点并不在于探索 GPT-3 这类大模型的碳足迹，而是希望引起人们对于训练先进神经网络所消耗的巨量资源的关注。</p><p>&nbsp;</p><p>目前，不少企业已开始重视能源消耗和环境污染问题，并在制定相应解决方案。微软在一份声明中称，正在资助研究以测量 AI 开发所对应的能耗和碳足迹，“同时致力于提升大语言模型系统的训练和应用效率。”</p><p>&nbsp;</p><p>微软表示，“我们将继续监测自身排放、加快进展，同时更多使用清洁能源为数据中心供电、采购可再生能源，借此实现到 2030 年的碳负排放、水资源正循环和零浪费的可持续发展目标。”</p><p>&nbsp;</p><p>OpenAI 也回应了这些评论，称正“认真考虑”如何更好地运用宝贵算力。“我们意识到训练大模型可能会消耗电力和水资源”，因此正在努力提高效率。”</p><p></p><h2>需要建立透明的排放制度</h2><p></p><p>&nbsp;</p><p>随着 AI 系统的不断开发和应用，我们的确需要关注它对环境的影响。除了传统上行之有效的实践之外，我们还应探索出特定于生成式 AI 的减排思路。</p><p>&nbsp;</p><p>首先，透明排放将至关重要。有了这种透明度保障，我们才能监控与 AI 模型训练和使用相关的碳排放量，确保模型部署者和最终用户能够根据这些数字制定 AI 使用策略。此外，还应将 AI 相关排放纳入温室气体清单与净零目标，将此作为AI整体透明制度的组成部分。</p><p>&nbsp;</p><p>法国最近就通过一项法律，要求电信企业提交关于其可持续发展的透明度报告。类似法律未来可能要求采用 AI 技术的产品向客户报告其碳排放量，并要求模型提供商通过 API 开放碳排放数据。</p><p>&nbsp;</p><p>更高的透明度将会带来更强有力的激励措施，借此建立起愈发节能的生成式 AI 系统，同时探索新的效率提升途径。InfoQ 最近发表的一篇文章提到，微软高级软件工程师 Sara Bergman 呼吁人们关注 AI 系统的整个生命周期，并建议采用绿色软件基金会提出的工具和实践以改善 AI 系统的能源效率。具体条款包括认真考量服务器硬件与架构选择、关注时间/区域间的发电排碳量差异等。更重要的是，生成式 AI 本身也有望在提高能效当中做出独特的贡献。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://apnews.com/article/chatgpt-gpt4-iowa-ai-water-consumption-microsoft-f551fde98083d17a7e8d904f8be822c4\">https://apnews.com/article/chatgpt-gpt4-iowa-ai-water-consumption-microsoft-f551fde98083d17a7e8d904f8be822c4</a>\"</p><p><a href=\"https://www.infoq.com/articles/carbon-emissions-generative-ai/\">https://www.infoq.com/articles/carbon-emissions-generative-ai/</a>\"</p><p><a href=\"https://www.theregister.com/2020/11/04/gpt3_carbon_footprint_estimate/\">https://www.theregister.com/2020/11/04/gpt3_carbon_footprint_estimate/</a>\"</p>",
    "publish_time": "2023-09-13 14:00:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "信也科技副总裁陈磊：数据应用与数据合规如何兼顾？",
    "url": "https://www.infoq.cn/article/hSjZFzB98kH74Jrm5XJH",
    "summary": "<p>随着科技的快速进步，金融行业正在经历一场前所未有的变革。无论是客户管理、服务体验还是信贷风控，智能化的脚步已经深度渗透到每一个环节。那么，金融行业的智能应用水平如何？实时平台化的数据建设应该如何做？数据应用与数据合规如何兼顾？</p><p></p><p>在 9 月 7 日的 InfoQ 超级连麦·数智大脑直播中，极客邦科技创始人 &amp;CEO 霍太稳与信也科技副总裁<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1577\">陈磊</a>\"展开了主题为《如何处理好金融数智化过程中的数据「养料」》的讨论。</p><p></p><p>陈磊表示，为了满足金融机构在数据安全和合规性方面的需求，在满足合规要求的基础上，可以尝试以下三个方向：首先，通过多方安全计算（MPC）等隐私计算技术来确保敏感数据在安全的前提下被充分使用。其次，对数据进行分类和分级，针对不同敏感度的数据应采取不同的处理方式。最后，培养企业内部的数据安全文化是非常关键的。</p><p></p><p>以下是对话全文（经 InfoQ 进行不改变原意的编辑整理）：</p><p></p><h5>InfoQ：目前整个金融行业的智能应用水平呈现哪些特点？</h5><p></p><p></p><p>陈磊：首先，金融行业和电信业及航空业是数字化最早的领域，和其他行业相比，具有一定的先发优势。这也使得金融行业在接纳新技术方面具有相对开放的态度。例如，在信息化早期阶段，金融行业便已经开始采用小型机和大型机等先进技术。近年来，整个金融行业在智能应用方面表现出“全面开花，全链条覆盖”的特点。无论是客户管理、服务体验、信贷风控，还是企业生态化服务，都有大量典型应用。举几个例子：</p><p></p><p>在存贷汇业务方面，智能化改造极大地提升了业务效率。例如，以前申请信用卡需要一个月的审批时间，而现在审批过程快速得多。</p><p></p><p>从消费者或银行客户的角度看，服务体系也经历了大幅改造。线上服务的比例大幅提升，和移动互联网的普及有着密切关系。例如，现在有大量的 7*24 小时智能客服在线提供服务。</p><p></p><p>智能化已经深度渗透到各个生活场景中，比如，线下面部识别支付方式提升了金融服务在零售场景中的覆盖率。</p><p></p><p>总体而言，金融行业在智能应用方面虽然还在发展中，但已经达到了相当高的水平。</p><p></p><h5>InfoQ：您认为一个金融机构要进行数据管理和应用，主要有哪些难题？</h5><p></p><p></p><p>陈磊：我认为金融机构在数据管理和应用上面临的挑战主要有以下几个方面：</p><p></p><p>数据来源的多样性：金融机构的数据来源非常丰富，与信息化的发展阶段和众多服务提供商有着紧密的关系，导致数据存在多种格式和标准。因此，如何实现统一的数据规范和标准成为一个关键问题。数据安全与合规：金融行业对数据安全的要求极高，因为其中涉及大量客户的敏感信息。任何数据泄露都可能给客户带来损失，并对金融机构的声誉和持续经营带来威胁。因此，如何在确保数据安全的同时进行有效的应用，是金融机构需要深入考虑的问题。数据质量问题：与其他行业一样，金融行业也面临数据质量的挑战。尤其是那些历史遗留问题，从线下到线上转型的过程中可能导致的数据增长问题。这些问题与纯互联网起步的企业相比，会带有更多历史负载。满足多元化需求：随着用户或消费者对金融服务需求的多元化，如何满足这些多样化的需求也是金融机构面临的一个重要挑战。人才问题：对于一些中小银行，他们面临着人才梯队的问题。这些机构普遍缺乏专业的数据管理和应用人才，如何有效地利用数据，对他们来说是一个更大的挑战。</p><p></p><h5>InfoQ：企业可以从哪些方面去解决这些挑战？尤其是人才梯度的建设方面。</h5><p></p><p></p><p>陈磊：关于数据工作和数字化转型，以及<a href=\"https://www.infoq.cn/article/7d4DwesFkH9sMaXYf4pa\">智能化</a>\"转型的推动方式。实际上，这些转型不是简单地通过自下而上的方式就能完成的。最有效的推动方式是自上而下与自下而上相结合，以形成合力。关键在于，数据建设的成果必须在业务中得以体现。没有顶层的支持和规划，长期的数据建设是很难落地的。因此，顶层设计是第一要务。这通常需要董事长或行长的决策，并需要持续三到五年的努力才能见到成果。</p><p></p><p>关于数据人才的吸引问题。首先，公司或行业需要建立一种支持数据文化的氛围。在这样的环境下，不仅需要数据工程师，还需要数据分析师和算法工程师共同努力。单一角色的招聘是难以实现数字化深度应用的。</p><p></p><p>另外，持续的数字化转型还需要注重流程和规范的建设，以确保成功能够被复制。与此同时，工具和平台的建设也是关键，它能降低数据工程和数据应用的门槛，从而提高效率。</p><p></p><p>很多年前，当我们开始使用大数据技术时，上手难度和学习成本都相对较高。但在最近几年，由于平台化建设取得了显著进步，这些成本逐渐降低。</p><p></p><p>最后，我想强调的是，整个数据工作，无论是从理念还是从落地的角度来看，都是一个长期的过程。这不仅需要耐心和适当的节奏，还需要阶段性的成果来推动进程。这其中，推动者和执行者的配合和规划是至关重要的。</p><p></p><h5>InfoQ：请您分享一下信也科技在数据管理、数据应用方面的成功经验？</h5><p></p><p></p><p>陈磊：从一开始，我们的核心理念就是要将数据和算法应用于商业决策，因为只有到达决策这一层，数据的价值才能得以体现。</p><p></p><p>在金融场景中，主要有几个关注点：首先是获客，传统金融机构主要通过线下网点进行客户获取。但随着移动互联网的兴起，如何通过线上方式吸引客户成为他们新的关注焦点；其次是风控定价，这是金融的核心模块，尤其在信贷场景中，如何决定一个用户或企业的授信额度和利率是至关重要的；最后是客户服务，在用户使用金融服务后，如何长期高效地维护与客户的关系。</p><p></p><p>在数据应用体系方面，我们形成了不同的层次，包括数据层和算法层。这些层次涵盖了数据计算和存储资源、离线和实时数据仓库、业务特征存储，以及上层的算法引擎。最终，这些都会体现在数据开发平台和业务智能（BI）平台上，在这样的框架下，数据更容易被加工和应用，同时业务和技术团队也能更顺畅地利用这些数据进行交流。</p><p></p><p>在早期，由于系统尚不完善，业务的数据需求常常需要较长时间才能得到满足。这种延迟会导致商机的丧失，给业务带来巨大机会损失。</p><p></p><p>另外我们注意到在获客方面，信息流个社交媒体逐渐成为搜索引擎和电商以外重要的新渠道。为此，我们开发了一套流量管理平台，能有效整合媒体和业务转化数据，这样做不仅提高了数据的时效性和全面性，还进一步使广告投放的效果评估更加及时和准确。</p><p></p><p>当然，我们在这个过程中也遇到了不少挑战。比如，与多家广告媒体对接时，由于它们的数据格式和 API 接口差异较大，我们需要花费额外时间和精力进行标准化和归一化，这也是考验数据架构能力的。</p><p></p><p>最后，在<a href=\"https://www.infoq.cn/article/tXdg1xI1YWGYG6iGg4rj\">风控</a>\"模块方面，我们的风控系统在多年的迭代后，已经能够处理大规模特征生成，精细化客群划分以及先进算法的自适应应用。这使得每一笔信贷申请都能得到精准的审批，起到了“风险守门员”的角色。其中的一个难点是如何利用非结构化数据，例如声纹数据、图像数据和关联关系数据。以上就是我们在数据管理和应用方面的一些经验。如果您对更多细节感兴趣，欢迎来 Fcon 现场与我们进行交流。</p><p></p><h5>InfoQ：最近财政部发布文件将数据作为资产被纳入会计报表，助力推动数据要素资产化。您认为这一举措对于金融行业意味着什么，会从哪些方面影响金融业数字化进程？</h5><p></p><p></p><p>陈磊：当财政部的新文件发布后，我们第一时间进行了学习和研读。该文件特别强调，<a href=\"https://www.infoq.cn/article/fC0VKxtiIoH096FrfD3U\">数据资产</a>\"在企业财务报表中的体现将成为一项不可或缺的义务。</p><p></p><p>首先，这无疑是一个重要的里程碑。它符合国家的十四五规划，即让数据成为生产要素，并在实际业务中流通。这从顶层设计上肯定了数据的价值，并推动了数据价值的量化。</p><p></p><p>其次，这将明显提高金融机构的数据管理水平。无论数据是外部采购的，还是由自家业务生成，或是用于内部业务或外部服务，都需要在财务报表中反映其价值。这将促使金融机构更加重视数据资源，并推动数据的收集、整理和应用。</p><p></p><p>第三，这将推动数据价值的深度应用。金融机构不仅需要理解数据的价值，还需要深入挖掘和应用数据，以提高金融服务的效率和质量。</p><p></p><p>第四，这也将促进金融科技和其他企业的发展。以往企业资产的评估并不包括数据，而现在，数据将成为企业附加值的一部分，有助于企业获得更好的金融服务，进而推动企业的创新和快速发展。</p><p></p><p>最后，虽然数据资产在财务报表中的体现是一个重要步骤，但仍有很多工作需要做，比如数据确权、定价和合理分类等。这是一个非常重要的开始，我们希望与合作伙伴和业内朋友共同探讨如何在各自的业务中实施这一新政。</p><p></p><h5>InfoQ：如何平衡数据的安全、可信和合规性，同时又不过多限制数据的使用？</h5><p></p><p></p><p>陈磊：首先，为了满足金融机构对数据安全和合规性的要求，我们遵循各项监管准则。例如，若规定数据不能外流，我们会通过技术手段确保数据在可信环境中进行运算，同时保证数据不离开这一环境。这涉及到近年来比较流行的隐私计算和多方安全计算技术。这些技术目前还在金融“沙盒”测试阶段，大规模推广还需法规支持。</p><p></p><p>从业务角度看，短期内可能需要承受一定的数据价值折损，但长远来看，我们期望在技术上能有突破，以在保证数据安全的同时，更合理地使用数据。</p><p></p><p>第二点，我们需要对数据进行分类和分级。并非所有数据都是敏感信息，也不都需要通过隐私计算进行处理。目前，隐私计算效率相对较低，因此，针对不同敏感度的信息，应采取不同处理方式。对于敏感信息，可以使用隐私计算；对于非敏感信息，可以进行脱敏后合理地进行加工和计算。</p><p></p><p>第三点，无论是金融科技公司还是金融机构，都需要培养数据安全文化。一旦大家明确了安全底线，日常操作将更加安全。</p><p></p><p>总体而言，实现数据使用效率和数据安全之间的平衡需要大量的监管工作、行业研究和长期实践，以找到一个相对平衡的点。</p><p></p><h5>InfoQ：在金融数字化、智能化的过程里，实时平台化的数据建设会发挥什么样的作用？</h5><p></p><p></p><p>陈磊：在移动互联网发展和新应用出现的背景下，金融场景对实时服务的需求越来越大，对应地，对数据的实时处理需求也在增加。在这种环境下，数据平台化变得尤为重要，具体可以从以下几个方面来看：</p><p></p><p>第一点，平台化的最终目标是提高数据的质量和时效性。通过数据平台，金融机构可以实现实时的数据采集、处理和分析，从而提高数据质量和实时性。</p><p></p><p>第二点，拥有高质量的数据后，不仅能更好地支持决策，还能通过数据分析来发掘新的商业机会。一个成熟的金融数据平台能为金融机构提供更丰富、更全面的数据资源，为数据分析和挖掘提供丰富的“养料”，进而帮助业务发掘新的机会点。</p><p></p><p>第三点，平台化的优势是加强数据安全和可靠性的管理。具体来说，通过数据平台可以实现权限的统一分配、合理管控以及任务的实时监控。这不仅增强了数据的安全性，还提高了运维效率。因为实时数据服务对任务的健壮性要求很高，平台化能让我们及时发现并解决问题。</p><p></p><p>总体而言，数据平台化能为<a href=\"https://www.infoq.cn/theme/213\">金融</a>\"机构提供更高效、更可靠，以及更安全和健壮的数据服务。这最终将体现在业务增长和效率提升上。</p><p></p><h5>InfoQ：FCon 金融实时数据平台建设之路专题的亮点有哪些？</h5><p></p><p></p><p>陈磊：本次 FCon 会议我们主要关注实时数据应用，涵盖从底层框架到上层应用的广泛领域。讨论将集中在以下几个主题：</p><p></p><p>从业务角度考虑，我们会探讨实时数据服务的应用场景和价值，以及哪些场景中离线或准实时数据就足够用，无需实时服务；</p><p></p><p>关于实时数据的开发平台，我们将讨论如何保证服务的阶段性和稳定性，以及如何提高开发效率。同时，会深入到实时数仓的设计和实现，以及与离线数仓的运维难度对比；</p><p></p><p>我们还会关注实时数据服务的资源管控和任务优化，特别是在 ROI 不高的场景中，如何更有效地使用计算和存储资源；</p><p></p><p>最后，我们将集中讨论实时数据平台的设计理念、技术难题，以及组件选择等。我们也邀请了金融和金融科技行业的专家，以进行更广泛和有代表性的讨论。</p><p></p><h5>InfoQ：目前大模型在整个金融行业的应用需要注意哪些问题？</h5><p></p><p></p><p>陈磊：从年初开始，我们已经在大模型应用方面进行了一些尝试。这些初步应用主要集中在内部服务和应用。从金融行业的角度来看，大模型落地仍面临多重挑战。</p><p></p><p>首先，大模型的可控性相对较差，而金融行业对结论可靠性有很高的要求。同时，模型的逻辑或结果也需要高度可解释性；</p><p></p><p>其次，大模型在时效性方面也面临挑战，特别是在需要实时响应的场景。不过，随着底层架构和硬件能力的提升，这些问题有望得到解决；</p><p></p><p>第三，考虑到金融行业对数据安全和隐私保护有严格要求，如何在输入数据时确保用户隐私和信息安全也是一大挑战。因此，我们也在进行相关的保护措施；另一个关键问题是如何将金融行业的专业知识和数据融入大模型中。这依然是一个探索和应用阶段的问题，目标是形成一个更精准和针对性的行业模型；</p><p></p><p>从实践和行业交流来看，我们认为大模型有很大的潜力与现有的数据智能技术结合，带来颠覆性的改变。在系统和工程层面，大模型将改进设计、开发、测试以及运维流程。在算法应用层面，它将提升传统机器学习和深度学习方法，比如在文本分析和智能客服应用方面；</p><p></p><p>最终，<a href=\"https://www.infoq.cn/article/TSJbOkWweAvFh44Oo2dL\">大模型</a>\"和数据技术的结合可能实现从数据到决策的自动化流程。例如，通过对话交互界面进行大量的数据分析和洞察，甚至直接生成详细报表和决策；</p><p></p><p>总体而言，尽管短期内仍存在挑战，但随着技术和应用场景的持续迭代，我们对大模型在应用场景落地方面持有很大的信心。</p><p></p><h4>关于FCon</h4><p></p><p></p><p>首届<a href=\"https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">FCon全球金融科技大会</a>\"将于 11 月 19-20 日在上海举办。大会将围绕金融领域数字化转型挑战探索、DevOps 在金融企业落地实践、金融行业大模型应用、创新的金融科技应用、金融实时数据平台建设之路、金融安全风险管控、数据要素流通与数据合规等 10+专题进行交流。</p><p></p><p>目前大会邀请了汇丰科技中国区的代理总经理马国栋、度小满金融数据智能部总经理杨青先、蚂蚁集团副总裁 &amp; 首席技术安全官韦韬博士、恒生聚源总经理吴震操担任大会联席主席。更多嘉宾仍在邀请中......</p><p></p><p>我们诚挚地邀请您加入我们，共同探索金融科技的未来，<a href=\"https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">点击链接</a>\"即可查看全部演讲专题。</p><p></p><p>目前 <a href=\"https://fcon.infoq.cn/2023/shanghai/apply?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">5 折 优惠购票</a>\"，仅限前 100 人，咨询购票可联系：17310043226（微信同手机号）。</p>",
    "publish_time": "2023-09-13 14:02:46",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "太平洋健康险北京研发中心负责人周小三确认出席 FCon ，分享智能化服务式营销保险平台的落地实践",
    "url": "https://www.infoq.cn/article/IIbghuEOTSOOqcLMK26v",
    "summary": "<p><a href=\"https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle\">FCon 全球金融科技大会</a>\"，将于 11 月在上海召开。太平洋健康险北京研发中心负责人周小三将发表题为《<a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5495?utm_source=infoqweb&amp;utm_medium=article\">智能化服务式营销保险平台的落地实践</a>\"》主题分享，介绍全流程管家服务式营销平台的业务逻辑和整体技术架构，让你了解数据智能和人工智能如何赋能业务、服务式营销方式、公域引流和私域经营通路、用户全生命周期管家式服务建设以及用户经营、转化、裂变逻辑的经验。</p><p></p><p><a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5495?utm_source=infoqweb&amp;utm_medium=article\">周小三</a>\"，目前是太平洋健康险北京研发中心负责人，深耕保险 + 科技。曾在平安健康险移动事业部负责整体研发，科技赋能互联网保险业务数字化，推动保险产品、医疗、健康和综合金融生态业务创新，并成为行业标杆。</p><p></p><p>曾在京东安联负责数据平台（京东技术委员会数据工作组成员），科技赋能互联网场景保险业务数字化，推动保险和商城场景化融合和优势互补。曾在泰康养老职域业务事业部科技创新部总经理，科技赋能传统寿险业务流程再造数字化，推动流程标准化的数字化效率变革。他在本次会议的演讲内容如下：</p><p></p><p>演讲：智能化服务式营销保险平台的落地实践</p><p></p><p>从行业来讲，保险行业进入存量市场争夺时代，简单暴力的销售手段已经不能适应市场环境，以客户为中心，提供个性化和差异化的服务式营销成为趋势。从客户来讲，过往客户买完保险后与保司很少互动，保险服务偏线下，大部分客户感知不到保司服务，很容易脱落。</p><p></p><p>太平洋健康险秉承蓝医保”产品即服务”的理念，为用户提供售前、售中、售后全流程服务，让客户买的放心，蓝医保客户买完即可享受服务，通过多种服务陪伴客户，实现客户黏度和复购的提升。经过探索，太保健康险形成了一套以客户为中心全流程管家式服务营销解决方案，既服务用户又达到营销效果和目的。</p><p></p><p>主要涉及的创新技术：</p><p></p><p>○ 基于大数据特征计算和智能派单算法技术，对用户、线索、顾问、保险产品等多维特征计算，并结合保险场景构建特征匹配系统，达到精准转化的效果</p><p>○ 基于通用大模型技术，对保险知识大模型和保险业务操作大模型的技术探索和应用</p><p></p><p>演讲提纲：</p><p></p><p>全流程管家服务式营销平台的业务逻辑 全流程管家服务式营销平台整体技术架构介绍 </p><p>○ 基于微信生态的场景触达和用户连接 </p><p>○ 智能工单调度系统建设 </p><p>○ 基于用户画像的线索跟进体系</p><p>○ 数据智能赋能经营决策 </p><p>○ 基于人工智能提升工作效率和转化能力的探索</p><p>技术赋能业务的思考</p><p></p><p>你将获得：</p><p></p><p>○ 了解数据智能和人工智能赋能业务</p><p>○ 了解服务式营销方式</p><p>○ 公域引流和私域经营通路</p><p>○ 了解用户经营、转化、裂变逻辑的经验</p><p>○ 了解用户全生命周期管家式服务建设</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle\">DevOps&nbsp;在金融企业落地实践</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle\">金融行业大模型应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle\">创新的金融科技应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle\">金融实时数据平台建设之路</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle\">金融安全风险管控</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle\">数据要素流通与数据合规</a>\"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，前 100 人可享 5 折特惠购票，咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png\" /></p><p></p>",
    "publish_time": "2023-09-13 14:21:17",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "一文解读分布式一致性协议Paxos",
    "url": "https://www.infoq.cn/article/Bmf7QukS2rP887GHAZA3",
    "summary": "<p></p><h2>一、Paxos协议简介</h2><p></p><p></p><p>Paxos算法由Leslie Lamport在1990年提出，它是少数在工程实践中被证实的强一致性、高可用、去中心的分布式协议。Paxos协议用于在多个副本之间在有限时间内对某个决议达成共识。Paxos协议运行在允许消息重复、丢失、延迟或乱序，但没有拜占庭式错误的网络环境中，它利用“大多数 (Majority)机制”保证了2F+1的容错能力，即2F+1个节点的系统最多允许F个节点同时出现故障。</p><p></p><p></p><blockquote>拜占庭式错误释义：一般地把出现故障但不会伪造信息的情况称为“非拜占庭错误”(Non-Byzantine Fault)或“故障错误”(Crash Fault)；而伪造信息恶意响应的情况称为“拜占庭错误”(Byzantine Fault)。</blockquote><p></p><p></p><h4>1、核心概念</h4><p></p><p></p><p>Proposal：提案（提案 = 提案编号acceptNumber + 提案值acceptValue）;Proposal Number：提案编号;Proposal Value：提案值。</p><p></p><h4>2、参与角色</h4><p></p><p></p><p>Proposer（提案者）：处理客户端请求，主动发起提案；Acceptor (投票者)：被动接受提案消息，参与投票并返回投票结果给Proposer以及发送通知给Learner；Learner（学习者）：不参与投票过程，记录投票相关信息，并最终获得投票结果。</p><p></p><p>在实际的分布式业务场景中，一个服务器节点或进程可以同时扮演其中的一种或几种角色，而且在分布式环境中往往同时存在多个Proposer、多个Acceptor和多个Learner。</p><p></p><h4>3、基础逻辑</h4><p></p><p></p><p>Paxos算法是指一个或多个提案者针对某项业务提出提案，并发送提案给投票者，由投票者投票并最终达成共识的算法。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8b/8bd822a5843a79edb90089b642b9b267.jpeg\" /></p><p></p><p>“达成共识”过程的特点：</p><p>（1）、可以由一个或多个提案者参与；</p><p>（2）、由多个投票者参与；</p><p>（3）、可以发起一轮或多轮投票；</p><p>（4）、最终的共识结果是一个值，且该值为提案者提出的其中某个值。</p><p></p><h2>二、Basic Paxos</h2><p></p><p></p><h4>1、两个阶段</h4><p></p><p></p><p>Basic Paxos算法分为两个阶段：Prepare阶段和Accept阶段。</p><p></p><p>(1). Prepare阶段</p><p></p><p>该阶段又分为两个环节：</p><p></p><p>a、Proposer发起广播消息给集群中的Acceptor发送一个提案编号为n的prepare提案请求。b、Acceptor收到提案编号为n的prepare提案请求，则进行以下判断：如果该Acceptor之前接受的prepare请求编号都小于n或者之前没有接受过prepare请求，那么它会响应接受该编号为n的prepare请求并承诺不再接受编号小于n的Accept请求，Acceptor向Proposer的响应数据包含三部分内容：接受编号n的提案状态信息，之前接受过的最大提案编号和相应提案值；如果该Acceptor之前接受过至少一个编号大于n的prepare请求，则会拒绝该次prepare请求。</p><p></p><p>通过以上prepare阶段处理流程可以知道：</p><p></p><p>a、prepare请求发送时只包含提案编号，不包含提案值；b、集群中的每个Acceptor会存储自己当前已接受的最大提案编号和提案值。</p><p></p><p>假设分布式环境中有一个Proposer和三个Acceptor，且三个Acceptor都没有收到过Prepare请求，Prepare阶段示意图如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e6/e6075f7f28bab0256308c9b6a102f341.jpeg\" /></p><p></p><p>假设分布式环境中有两个Proposer和三个Acceptor，ProposerB成功发送prepare请求，在发送Accept请求时出现故障宕机，只成功给Acceptor1发送了accept请求并得到响应。当前各个Acceptor的状态分别为：Acceptor1，同意了ProposerB发送的提案编号2的Accept请求，当前提案值为：orange；Acceptor2，接受了ProposerB发送的提案编号2的Prepare请求；Acceptor3，接受了ProposerB发送的提案编号2的Prepare请求；此时ProposerA发起Prepare请求示意图如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3a/3a1993ca4fb8965cb0080937620547ad.jpeg\" /></p><p></p><p>流程说明：</p><p></p><p>a、ProposerA发起prepare(1)的请求，由于该编号小于提案编号2，所以请求被拒绝；b、ProposerA发起prepare(3)的请求，该编号大于编号2，则被接受，Accetpor1返回Promised(3,2,'orange')，表示接受编号3的提案请求，并将之前接受过的最大编号提案和提案值返回。c、Acceptor2和Acceptor3均返回Promised(3)，表示接受编号3的提案请求。</p><p></p><p>(2). Accept阶段</p><p></p><p>如果Proposer接收到了超过半数节点的Prepare请求的响应数据，则发送accept广播消息给Acceptor。如果Proposer在限定时间内没有接收到超过半数的Prepare请求响应数据，则会等待指定时间后再重新发起Prepare请求。</p><p></p><p>Proposer发送的accept广播请求包含什么内容：</p><p></p><p>a、accept请求包含相应的提案号；b、accept请求包含对应的提案值。如果Proposer接收到的prepare响应数据中包含Acceptor之前已同意的提案号和提案值，则选择最大提案号对应的提案值作为当前accept请求的提案值，这种设计的目的是为了能够更快的达成共识。而如果prepare返回数据中的提案值均为空，则自己生成一个提案值。</p><p></p><p>Acceptor接收到accept消息后的处理流程如下：</p><p></p><p>a、判断accept消息中的提案编号是否小于之前已同意的最大提案编号，如果小于则抛弃，否则同意该请求，并更新自己存储的提案编号和提案值。b、Acceptor同意该提案后发送响应accepted消息给Proposer，并同时发送accepted消息给Learner。Learner判断各个Acceptor的提案结果，如果提案结果已超过半数同意，则将结果同步给集群中的所有Proposer、Acceptor和所有Learner节点，并结束当前提案。当Acceptor之前没有接受过Prepare请求时的响应流程图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3d/3d735f96927c1b200d762a663321ac2d.jpeg\" /></p><p></p><p>当Acceptor之前已存在接受过的Prepare和Accept请求时的响应流程图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d4/d4d2780de523cb58887229dbd41d1fb3.jpeg\" /></p><p></p><p>该示例中prepare请求返回数据中已经包含有之前的提案值（1,'apple'）和（2,'banana'），Proposer选择之前最大提案编号的提案值作为当前的提案值。</p><p></p><h4>2、关于提案编号和提案值</h4><p></p><p></p><p>提案编号</p><p></p><p>在Paxos算法中并不自己生成提案编号，提案编号是由外部定义并传入到Paxos算法中的。我们可以根据使用场景按照自身业务需求，自定义提案编号的生成逻辑。提案编号只要符合是“不断增加的数值型数值”的条件即可。比如：在只有一个Proposer的环境中，可以使用自增ID或时间戳作为提案编号；在两个Proposer的环境中，一个Proposer可以使用1、3、5、7...作为其编号，另一个Proposer可以使用2、4、6、8...作为其提案编号；在多Proposer的环境中，可以为每个节点预分配固定ServerId(ServerId可为1、2、3、4...)，使用自增序号 + '.'  + ServerId或timestamp + '.' + ServerId的格式作为提案编号，比如：1.1、1.2、2.3、3.1、3.2或1693702932000.1、1693702932000.2、1693702932000.3；每个Proposer在发起Prepare请求后如果没有得到超半数响应时，会更新自己的提案号，再重新发起新一轮的Prepare请求。</p><p></p><p>提案值</p><p></p><p>提案值的定义也完全是根据自身的业务需求定义的。在实际应用场景中，提案值可以是具体的数值、字符串或是cmd命令或运算函数等任何形式，比如在分布式数据库的设计中，我们可以将数据的写入操作、修改操作和删除操作等作为提案值。</p><p></p><h4>3、最终值的选择</h4><p></p><p></p><p>Acceptor每次同意新的提案值都会将消息同步给Learner，Learner根据各个Acceptor的反馈判断当前是否已超过半数同意，如果达成共识则发送广播消息给所有Acceptor和Proposer并结束提案。在实际业务场景中，Learner可能由多个节点组成，每个Learner都需要“学习”到最新的投票结果。关于Learner的实现，Lamport在其论文中给出了下面两种实现方式：</p><p></p><p>（1）、选择一个Learner作为主节点用于接收投票结果（即accepted消息），其他Learner节点作为备份节点，Learner主节点接收到数据后再同步给其他Learner节点。该方案缺点：会出现单点问题，如果这个主节点挂掉，则不能获取到投票结果。</p><p></p><p>（2）、Acceptor同意提案后，将投票结果同步给所有的Learner节点，每个Learner节点再将结果广播给其他的Learner节点，这样可以避免单点问题。不过由于这种方案涉及很多次的消息传递，所以效率要低于上述的方案。</p><p></p><h2>三、活锁问题</h2><p></p><p></p><h4>1、什么是活锁?</h4><p></p><p></p><p>“活锁”指的是任务由于某些条件没有被满足，导致一直重复尝试，失败，然后再次尝试的过程。 活锁和死锁的区别在于，处于活锁的实体是在不断的改变状态，而处于死锁的实体表现为等待（阻塞）；活锁有可能自行解开，而死锁不能。</p><p></p><h4>2、为什么Basic-Paxos可能会出现活锁?</h4><p></p><p></p><p>由于Proposer每次发起prepare请求都会更新编号，那么就有可能出现这种情况，即每个Proposer在被拒绝时，增大自己的编号重新发起提案，然后每个Proposer在新的编号下不能达成共识，又重新增大编号再次发起提案，一直这样循环往复，就成了活锁。活锁现象就是指多个Proposer之间形成僵持，在某个时间段内循环发起preapre请求，进入Accept阶段但不能达成共识，然后再循环这一过程的现象。活锁现象示例图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6d/6d900a7ce063ef2b3f738fb88ce34328.jpeg\" /></p><p></p><h4>3、活锁如何解决？</h4><p></p><p></p><p>活锁会导致多个Proposer在某个时间段内一直不断地发起投票，但不能达成共识，造成较长时间不能获取到共识结果。活锁有可能自行解开，但该过程的持续时间可长可短并不确定，这与具体的业务场景实现逻辑、网络状况、提案重新发起时间间隔等多方面因素有关。</p><p></p><p>解决活锁问题，有以下两种常见的方法：</p><p>（1）、当Proposer接收到响应，发现支持它的Acceptor小于半数时，不立即更新编号发起重试，而是随机延迟一小段时间，来错开彼此的冲突。</p><p>（2）、可以设置一个Proposer的Leader，集群全部由它来进行提案，等同于下文的Multi-Paxos算法。</p><p></p><h2>四、Multi-Paxos</h2><p></p><p></p><p>上文阐述了Paxos算法的基础运算流程，但我们发现存在两个问题：（1）、集群内所有Proposer都可以发起提案所以Basic Paxos算法有可能导致活锁现象的发生；（2）、每次发起提案都需要经过反复的Prepare和Accept流程，需要经过很多次的网络交互，影响程序的执行效率。</p><p></p><p>考虑到以上两个问题，能不能在保障分布式一致性的前提下可以避免活锁情况的发生，以及尽可能减少达成共识过程中的网络交互，基于这种目的随即产生了Multi-Paxos算法。</p><p></p><p>首先我们可以设想一下：在多个Proposer的环境中最理想的达成共识的交互过程是什么样子的？就是这样一种情况：集群中的某个Proposer发送一次广播prepare请求并获得超半数响应，然后再发送一次广播accept请求，并获得超过半数的同意后即达成共识。但现实中多个Proposer很可能会互相交错的发送消息，彼此之间产生冲突，而且在不稳定的网络环境中消息发送可能会延迟或丢失，这种情况下就需要再次发起提案，影响了执行效率。Multi-Paxos算法就是为了解决这个问题而出现。</p><p></p><p>Multi-Paxos算法是为了在保障集群所有节点平等的前提下，依然有主次之分，减少不必要的网络交互流程。Multi-Paxos算法是通过选举出一个Proposer主节点来规避上述问题，集群中的各个Proposer通过心跳包的形式定期监测集群中的Proposer主节点是否存在。当发现集群中主节点不存在时，便会向集群中的Acceptors发出申请表示自己想成为集群Proposer主节点。而当该请求得到了集群中的大多数节点的同意后随即该Proposer成为主节点。</p><p></p><p>集群中存在Proposer主节点时，集群内的提案只有主节点可以提出，其他Proposer不再发起提案，则避免了活锁问题。由于集群中只有一个节点可以发起提案，不存在冲突的可能，所以不必再发送prepare请求，而只需要发送accept请求即可，因此减少了协商网络交互次数。</p><p></p><h2>五、Paxos应用场景示例</h2><p></p><p></p><p>上文对Paxos算法的处理流程就行了阐述，为了加深理解，下面以一个分布式数据库的使用案例来阐述Paxos算法在实际业务场景中的使用。</p><p></p><p>场景描述：分布式数据库中假设包含3个节点，客户端访问时通过轮询或随机访问的方式请求到其中的某个节点，我们要通过Paxos算法保证分布式数据库的3个节点中数据的一致性。实际的分布式数据一致性流程更为复杂，我这里为了方便阐述将这个过程进行一些简化。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c2/c2e9ab23312693a0a06d23a7e7c4c2ba.jpeg\" /></p><p></p><p>分布式数据库中的每个节点都存储三份数据，一是事务日志数据，二是DB数据，三是事务日志执行位置。事务日志表存储着数据库的操作日志记录，包括：写入Put、修改Update和删除Delete等相关的操作日志，有些文章资料将事务日志表称为状态机其实是一个意思。DB数据表存储具体的业务数据。事务日志执行位置用于记录当前节点执行到了哪一条操作记录。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f9/f9df260556436771a1010bf02db49325.jpeg\" /></p><p></p><p>整体设计思想：我们只要通过Paxos算法保证各个节点事务日志表数据一致就可以保证节点数据的一致性。</p><p></p><p>假设，当前各个节点的事务日志表和数据表均为空，现在客户端1对数据库发起写入操作请求：{'Op1','Put(a,'1')'}，这里的Op1代表操作的ID(为了简单起见，直接使用自增ID表示，该数值对应Paxos算法中的提案编号)，Put(a,'1')代表操作内容，对应Paxos中的提案值，假设该请求被随机分配到了Server1处理。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8d/8da073be6e5c1bd87fb1a9c5ec7ae14c.jpeg\" /></p><p></p><p>流程说明：</p><p>1、Server1接受到Put(a,'1')请求，并不是直接写入数据表，而是首先通过Paxos算法判断集群节点是否达成写入共识。</p><p>2、当前三个节点的OperateIndex均为0，事务日志表和数据表均为空，Server1的Proposer首先向三个节点发起Prepare(OperateIndex + 1)，即Prepare(1)请求。</p><p>3、接收到过半数的Prepare请求反馈后，发送Accept(1,'Put(a,'1')')请求，并得到Accepted请求反馈，则此时三个节点达成共识，当前三个节点的事务日志表均为：{'Op1','Put(a,'1')'}，数据表均为空。</p><p>4、达成共识后，Server1执行写入操作并更新当前节点的OperateIndex，此时Server1的OperateIndex为1，其他节点仍为0，Server1的数据表为：a = 1，另外两个节点为空，三个节点的事务日志表相同，当前写入流程结束。</p><p></p><p>假设，此时Server2节点接收到Put(b,'1')的请求，处理流程如下：</p><p>1、Server2接收到Put(b,'1')请求，由于当前Server2的OperateIndex仍为0，则首先发起Prepare(1)的请求。</p><p>2、由于当前三个节点的Acceptor的提案编号均为1，所以会拒绝Server2的Prepare(1)请求。</p><p>3、Server2未能得到超过半数的prepare响应，则会查看当前事务日志表发现已存在Op1操作，则从当前节点的事务日志表中取出相应操作并执行，然后将当前节点OperateIndex修改为1。</p><p>4、Server2随即再次发起Prepare(OperateIndex+1)，即Prepare(2)的请求。</p><p>5、此时三个节点达成共识，并更新各自的事务日志表。</p><p>6、Server2执行写入操作，此时Server1节点状态为OperateIndex：1，数据表：a=1；Server2节点状态为OperateIndex:2, 数据表：a=1和b=1；Server3的节点状态为OperateIndex：0，数据表为空；三个节点的事务日志表相同，均为：{'Op1','Put(a,'1')'}；{'Op2','Put(b,'1')'}。当前流程执行结束。</p><p></p><p>假设，此时Server3接收到Get(a)请求，处理流程如下：1、Server3接收到Get(a)请求，并不是直接查询数据表然后返回，而是要将当前节点的OperateIndex和事务日志表中的记录进行比对，如果发现有遗漏操作，则按照事务日志表的顺序执行遗漏操作后再返回。由于Get请求并不涉及对数据的写入和修改，所以理论上不需要再次发起Paxos协商。2、此时Server1节点的状态为OperateIndex：1，数据表：a=1；Server2的节点状态为OperateIndex:2,  数据表：a=1和b=1；Server3的节点状态为OperateIndex：2，数据表为a=1和b=1；三个节点的事务日志表相同，均为：{'Op1','Put(a,'1')'}；{'Op2','Put(b,'1')'}。当前流程执行结束。</p><p></p><p>执行流程示意图如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1e/1e2527823fb39bcf0d8e01ca3a922358.jpeg\" /></p><p></p><p>随着数据的不断写入，事务日志表的数据量不断增加，可以通过快照的方式，将某个时间点之前的数据备份到磁盘（注意此处备份的是数据表数据，不是事务日志数据，这样宕机恢复时直接从快照点开始恢复，可以提高恢复效率，如果备份事务日志数据，宕机恢复时需要从第一条日志开始恢复，导致恢复时间会比较长），然后将事务日志表快照前的数据清除即可。</p><p></p><h2>六、对一些问题的解释</h2><p></p><p></p><h4>1、投票过程为什么要遵循选择最大提案号的原则？</h4><p></p><p></p><p>Paxos投票虽然叫作“投票”，但其实与我们现实中的“投票”有很大的区别，因为它的运算过程中并不关心提案内容本身，而完全依据哪个提案号大就选择哪个的原则，因为只有这样才能达成共识。</p><p></p><h4>2、为什么Proposer每次发起prepare都要变更提案号？</h4><p></p><p></p><p>这个问题其实很容易理解，也是为了达成共识。假设ProposerA、ProposerB、ProposerC分别同时发起了prepare(1)、prepare(2)、prepare(3)的提案，而此时ProposerC出现故障宕机，如果ProposerA、ProposerB在后续的每一轮投票中都不变更提案号，那永远都不可能达成共识。</p><p></p><h4>3、为什么Paxos算法可以避免脑裂问题？</h4><p></p><p></p><p>Paxos算法可以避免分布式集群出现脑裂问题，首先我们需要知道什么是分布式集群的脑裂问题。脑裂是指集群出现了多个Master主节点，由于分布式集群的节点可能归属于不同的网络分区，如果网络分区之间出现网络故障，则会造成不同分区之间的节点不能互相通信。而此时采用传统的方案很容易在不同分区分别选出相应的主节点。这就造成了一个集群中出现了多个Master节点即为脑裂。而Paxos算法是必须达到半数同意才能达成共识，这就意味着如果分区内的节点数量少于一半，则不可能选出主节点，从而避免了脑裂状况的发生。</p><p></p><h2>七、开发、运维超实用工具推荐</h2><p></p><p></p><p>接下来向大家推荐一款对日常开发和运维，极具有实用价值的好帮手XL-LightHouse。</p><p></p><p>一键部署，一行代码接入，无需大数据相关研发运维经验就可以轻松实现海量数据实时统计，使用XL-LightHouse后：</p><p></p><p>再也不需要用Flink、Spark、ClickHouse或者基于Redis这种臃肿笨重的方案跑数了；再也不需要疲于应付对个人价值提升没有多大益处的数据统计需求了，能够帮助您从琐碎反复的数据统计需求中抽身出来，从而专注于对个人提升、对企业发展更有价值的事情；轻松帮您实现任意细粒度的监控指标，是您监控服务运行状况，排查各类业务数据波动、指标异常类问题的好帮手；培养数据思维，辅助您将所从事的工作建立数据指标体系，量化工作产出，做专业严谨的职场人，创造更大的个人价值；</p><p></p><p>XL-LightHouse简介</p><p></p><p>XL-LightHouse是针对互联网领域繁杂的流式数据统计需求而开发的一套集成了数据写入、数据运算、数据存储和数据可视化等一系列功能，支持超大数据量，支持超高并发的【通用型流式大数据统计平台】。XL-LightHouse目前已涵盖了常见的流式数据统计场景，包括count、sum、max、min、avg、distinct、topN/lastN等多种运算，支持多维度计算，支持分钟级、小时级、天级多个时间粒度的统计，支持自定义统计周期的配置。XL-LightHouse内置丰富的转化类函数、支持表达式解析，可以满足各种复杂的条件筛选和逻辑判断。XL-LightHouse是一套功能完备的流式大数据统计领域的数据治理解决方案，它提供了比较友好和完善的可视化查询功能，并对外提供API查询接口，此外还包括数据指标管理、权限管理、统计限流等多种功能。XL-LightHouse支持时序性数据的存储和查询。GitHub搜索XL-LightHouse了解更多！</p><p></p><p>如本文有所疏漏或您有任何疑问，欢迎访问dtstep.com与我本人沟通交流！</p><p></p><h4>作者介绍</h4><p></p><p></p><p>xl-xueling，开源项目通用型流式大数据统计系统xl-lighthouse作者，曾任职多家国内大型互联网企业，个人比较熟悉和擅长大型分布式系统的架构设计、擅长企业大数据数仓平台建设，对企业数据化运营转型有较为深入的研究和实施经验。</p>",
    "publish_time": "2023-09-13 15:20:30",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]