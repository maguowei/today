[
  {
    "title": "Java近期新闻：JDK 21、面向JDK 21的GraalVM、Apache Pinot 1.0和Eclipse Epicyro 3.0",
    "url": "https://www.infoq.cn/article/0hhqSZ0mg99KVNwGtzmG",
    "summary": "<p></p><h4>OpenJDK</h4><p></p><p>Oracle的编程语言设计师<a href=\"https://www.linkedin.com/in/dansmithjava/\">Daniel Smith</a>\"提交了<a href=\"https://openjdk.org/jeps/8316779\">值对象存储增强（预览）（Value Object Storage Enhancements (Preview)）</a>\"。在Valhalla项目下，该JEP在字段和数组组件中引入了值对象的空限制（null-restricted）存储。 “这些变量被初始化为类的初始实例，并拒绝写入空值。它们可以通过紧凑、扁平化的对象编码进行优化”。&nbsp;</p><p></p><p></p><h4>JDK 21</h4><p></p><p>Oracle<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-September/008267.html\">发布了</a>\"Java编程语言和虚拟机的<a href=\"https://jdk.java.net/21\">21</a>\"版本，其中包括15个JEP的最终特性集。关于该版本的更多信息，请参阅InfoQ的<a href=\"https://www.infoq.com/news/2023/09/java21-released/\">新闻报道</a>\"。</p><p></p><p></p><h4>JDK 22</h4><p></p><p>JDK 22早期访问版本的<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-22%2B16\">Build 16</a>\"发布，该版本是对Build 15的<a href=\"https://github.com/openjdk/jdk/compare/jdk-22%2B15...jdk-22%2B16\">更新</a>\"，包含对各种<a href=\"https://bugs.openjdk.org/issues/?jql=project%20%3D%20JDK%20AND%20fixversion%20%3D%2022%20and%20%22resolved%20in%20build%22%20%3D%20b16%20order%20by%20component%2C%20subcomponent\">问题</a>\"的修复。有关该版本的更多详情，请参阅<a href=\"https://jdk.java.net/22/release-notes\">发布说明</a>\"。</p><p>&nbsp;</p><p>Oracle的Java平台组的首席架构师<a href=\"https://www.linkedin.com/in/markreinhold\">Mark Reinhold</a>\"对<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-September/008256.html\">提议</a>\"的JDK 22发布计划没有异议，并<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-September/008269.html\">宣布了</a>\"如下的最终发布计划：</p><p>Rampdown第一阶段（fork主线）：2023年12月7日Rampdown第二阶段：2024年1月18日初始候选版本：2024年2月8日最终候选版本：2024年2月22正式发布：2024年3月19日</p><p>&nbsp;</p><p>对于<a href=\"https://openjdk.org/projects/jdk/22/\">JDK 22</a>\"，鼓励开发人员通过<a href=\"https://bugreport.java.com/bugreport/\">Java缺陷数据库</a>\"报告缺陷。</p><p></p><p></p><h4>GraalVM</h4><p></p><p>在发布<a href=\"https://www.infoq.com/news/2023/09/java21-released/\">JDK 21</a>\"的同时，Oracle Labs还发布了面向JDK 21的GraalVM。新特性包括：完全支持JDK 21；通过Profile-Guided Optimizations增强了性能；采用了新的应用程序级别的策略加快了编译时间；通过新的CLI选项--parallelism和--color改善了开发人员的体验，这两个选项分别用来在构建时指定线程数和输出颜色。关于该版本的更多详情，请参阅<a href=\"https://github.com/graalvm/graalvm-ce-builds/releases/tag/jdk-21.0.0\">发布说明</a>\"。InfoQ后续将会发布更详细的新闻报道。</p><p>&nbsp;</p><p>在通往1.0版本的过程中，Oracle Labs发布了<a href=\"https://github.com/graalvm/native-build-tools/blob/master/README.md\">Native Build Tools</a>\"的<a href=\"https://github.com/graalvm/native-build-tools/releases/tag/0.9.27\">0.9.27</a>\"版本，这是一个由插件组成的GraalVM项目，用于实现与GraalVM Native Image的互操作性。这个最新版本为面向JDK 21的GraalVM 提供了错误修复和功能增强。有关此版本的更多详情，请参阅<a href=\"https://github.com/graalvm/native-build-tools/compare/0.9.26...0.9.27\">变更日志</a>\"。&nbsp;</p><p></p><p></p><h4>Amazon Corretto</h4><p></p><p>亚马逊云科技<a href=\"https://aws.amazon.com/about-aws/whats-new/2023/09/amazon-corretto-21-generally-available/\">发布了</a>\"&nbsp;Amazon Corretto 21，这是他们的OpenJDK 21的下游发行版，可以在Linux、Windows和macOS上使用。开发人员可以在该<a href=\"https://docs.aws.amazon.com/corretto/latest/corretto-21-ug/downloads-list.html\">站点</a>\"下载这一最新版本。</p><p></p><p></p><h4>BellSoft Liberica JDK</h4><p></p><p>同样，BellSoft也<a href=\"https://bell-sw.com/blog/liberica-jdk-21-lts-release-a-lasting-foundation-for-your-java-application/\">发布了</a>\"Liberica JDK 21，这是他们的OpenJDK 21的下游发行版。开发人员可以在该<a href=\"https://bell-sw.com/pages/downloads/#/java-21-current\">站点</a>\"下载这一最新版本。</p><p></p><p></p><h4>Spring Framework</h4><p></p><p><a href=\"https://spring.io/projects/spring-boot\">Spring Boot&nbsp;</a>\"3.2.0的第三个里程碑版本提供了缺陷修复、依赖关系升级和新特性，比如，在Spring for Apache Pulsar的配置中添加了ConnectionDetails接口和@ServiceConnection注解；提供RestClientBuilderConfigurer类的实例，以便于将Spring Boot的默认配置应用于自定义的RestClient.Builder接口；移除对WebFlux插装（instrumentation）的已废弃&nbsp;ServerHttpObservationFilter类的使用。关于该版本的更多详情，请参阅<a href=\"https://github.com/spring-projects/spring-boot/releases/tag/v3.2.0-M3\">发布说明</a>\"。</p><p>&nbsp;</p><p>同样，Spring Boot的<a href=\"https://spring.io/blog/2023/09/21/spring-boot-3-1-4-available-now\">3.1.4</a>\"、<a href=\"https://spring.io/blog/2023/09/21/spring-boot-3-0-11-available-now\">3.0.11</a>\"和<a href=\"https://spring.io/blog/2023/09/21/spring-boot-2-7-16-available-now\">2.7.16</a>\"版本也对文档进行了更新和依赖性升级，为JavaVersion枚举类增加了TWENTY_ONE枚举常量，并修复了一些值得注意的缺陷，例如，在使用metadata-url查询时，Saml2RelyingPartyAutoConfiguration类会忽略在sign-request属性中设置的值；DomainSocket类中的文件描述符和套接字泄露；在使用WelcomePageHandlerMapping类的时候，无效的Accept请求HTTP头信息会产生HTTP 500&nbsp;<a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/500\">Internal Server Error</a>\"。关于这些版本的更多详情，请参阅<a href=\"https://github.com/spring-projects/spring-boot/releases/tag/v3.1.4\">3.1.4版本</a>\"、<a href=\"https://github.com/spring-projects/spring-boot/releases/tag/v3.0.11\">3.0.11版本</a>\"和<a href=\"https://github.com/spring-projects/spring-boot/releases/tag/v2.7.16\">2.7.16版本</a>\"的发布说明。</p><p>&nbsp;</p><p><a href=\"https://spring.io/projects/spring-integration\">Spring Integration</a>\"&nbsp;6.2.0的<a href=\"https://spring.io/blog/2023/09/20/spring-integration-6-2-0-milestone-3-available\">第三个里程碑版本</a>\"包含了依赖性升级和值得关注的变更，例如，重构KafkaMessageDrivenChannelAdapter类，便于将来的维护，以避免代码重复；为LockRegistry接口添加新的重载executeLocked()方法，以遵循最佳实践以及JdbcTemplate、RestTemplate和JmsTemplate类中人们所熟知的模式；支持DefaultSftpSessionFactory类的自定义实例。有关该版本的更多详情，请参阅<a href=\"https://github.com/spring-projects/spring-integration/releases/tag/v6.2.0-M3\">发布说明</a>\"。</p><p>&nbsp;</p><p><a href=\"https://spring.io/projects/spring-batch\">Spring Batch</a>\"&nbsp;5.1.0的<a href=\"https://spring.io/blog/2023/09/20/spring-batch-5-1-0-m3-available-now\">第三个里程碑版本</a>\"提供了缺陷修复、文档改进和新特性，比如，使用@EnableBatchProcessing注解和DefaultBatchConfiguration自动配置JobRegistryBeanPostProcessor类，以改进JobRegistry接口的job注册；通过@EnableBatchProcessing注解中的新参数指定数据库类型；在JdbcJobInstanceDao类中提供自定义JobKeyGenerator接口。有关该版本的更多详情，请参阅<a href=\"https://github.com/spring-projects/spring-batch/releases/tag/v5.1.0-M3\">发布说明</a>\"。</p><p>&nbsp;</p><p><a href=\"https://spring.io/projects/spring-cloud-dataflow\">Spring Cloud Dataflow</a>\"&nbsp;2.11.0的<a href=\"https://spring.io/blog/2023/09/21/spring-cloud-dataflow-2-11-0-released\">发布</a>\"提供了缺陷修复、依赖性升级并支持基于Spring Boot 3.x的流式应用、基于Spring Cloud Task 3.x的任务应用以及基于Spring Batch 5.x的批处理应用。此外，还升级了Kubernetes&nbsp;batch/v1&nbsp;cron job，这样开发人员就可以使用Kubernetes 1.25.0及以上版本。关于该版本的更多详情，请参阅<a href=\"https://github.com/spring-cloud/spring-cloud-dataflow/releases/tag/v2.11.0\">发布说明</a>\"。</p><p>&nbsp;</p><p><a href=\"https://spring.io/projects/spring-security\">Spring Security</a>\"的6.2.0-M1、6.1.4、6.0.7和5.8.7版本<a href=\"https://spring.io/blog/2023/09/18/spring-security-5-8-7-6-0-7-6-1-4-6-2-0-m1-released-including-fixes-for-cve\">发布</a>\"，修复了CVE-2023-34042，<a href=\"https://spring.io/security/cve-2023-34042\">对spring-security.xsd错误的授权（Incorrect Permission Assignment for spring-security.xsd）</a>\"，在该漏洞中，spring-security-config&nbsp;JAR压缩包中的spring-security.xsd文件是随意可写的，这可能会导致漏洞。建议开发人员升级到这些版本。有关这些版本的更多信息，请参阅<a href=\"https://github.com/spring-projects/spring-security/releases/tag/6.2.0-M3\">6.2.0-M1版本</a>\"、<a href=\"https://github.com/spring-projects/spring-security/releases/tag/6.1.4\">6.1.4版本</a>\"、<a href=\"https://github.com/spring-projects/spring-security/releases/tag/6.0.7\">6.0.7版本</a>\"和<a href=\"https://github.com/spring-projects/spring-security/releases/tag/5.8.7\">5.8.7版本</a>\"的发布说明。</p><p>&nbsp;</p><p><a href=\"https://spring.io/projects/spring-graphql\">Spring for GraphQL</a>\"的1.2.3、1.1.6和1.0.5版本<a href=\"https://spring.io/blog/2023/09/19/spring-for-graphql-1-0-5-1-1-6-1-2-3-released\">发布</a>\"，提供了缺陷修复、文档改进、依赖性升级和新特性，包括使用ConnectionTypeDefinitionConfigurer类访问访问对象类型扩展（以补充对象类型）；当Java&nbsp;Principal接口的实例不存在且未声明为Optional时，会触发Spring Security&nbsp;AuthenticationCredentialsNotFoundException，以要求进行身份验证；增强GraphQL请求体检查以防止出现HTTP 500&nbsp;Internal Server Error。这些版本分别可以与Spring Boot 3.1.4、3.0.11和2.7.16版本协同使用。关于这些版本的更多详情，请参阅<a href=\"https://github.com/spring-projects/spring-graphql/releases/tag/v1.2.3\">1.2.3版本</a>\"、<a href=\"https://github.com/spring-projects/spring-graphql/releases/tag/v1.1.6\">1.1.6版本</a>\"和<a href=\"https://github.com/spring-projects/spring-graphql/releases/tag/v1.0.5\">1.0.5版本</a>\"的发布说明。</p><p>&nbsp;</p><p><a href=\"https://spring.io/projects/spring-authorization-server\">Spring Authorization Server</a>\"&nbsp;1.2.0的第一个<a href=\"https://spring.io/blog/2023/09/19/spring-authorization-server-1-2-0-m1-available-now\">里程碑版本</a>\"包含了缺陷修复、依赖性升级和新特性，例如，注入自定义元数据以改善客户端注册功能；为OIDC提供者配置响应新提供了代码质询方法（code challenge method）；使用CodeVerifierAuthenticator类改善了日志功能。关于该版本的更多详情，请参阅<a href=\"https://github.com/spring-projects/spring-authorization-server/releases/tag/1.2.0-M1\">发布说明</a>\"。</p><p>&nbsp;</p><p><a href=\"https://spring.io/projects/spring-pulsar\">Spring for Apache Pulsar</a>\"&nbsp;1.0.0的<a href=\"https://spring.io/blog/2023/09/18/spring-for-apache-pulsar-1-0-0-m2-available-now\">第二个里程碑版本</a>\"包含了如下值得关注的变更：能够为PulsarAdministration、DefaultPulsarConsumerFactory、DefaultPulsarReaderFactory和DefaultReactivePulsarSenderFactory类添加多个customizer；将缓存提供者模块的源文件从默认的spring.pulsar.core包移至具有特定模块名称的包中，以避免与Java模块系统发生混淆。关于该版本的更多详情，请参阅<a href=\"https://github.com/spring-projects/spring-pulsar/releases/tag/v1.0.0-M2\">发布说明</a>\"。</p><p>&nbsp;</p><p><a href=\"https://spring.io/projects/spring-modulith\">Spring Modulith</a>\"的1.1.0-M1和1.0.1版本<a href=\"https://spring.io/blog/2023/09/21/spring-modulith-1-1-m1-and-1-0-1-released\">发布</a>\"，提供了缺陷修复、文档改善、依赖性升级和新特性，例如，支持通过注册@ApplicationEventListener将领域事件外部化到消息中间件中（Kafka、AMQP、JMS等）；新的Neo4j事件发布仓库；新的CompletedEventPublications、IncompleteEventPublications和EventPublicationRepository接口，用于改善对已完成和未完成事件发布的处理。关于这些版本的更多详情，请参阅<a href=\"https://github.com/spring-projects/spring-modulith/releases/tag/1.1.0-M1\">1.1.0-M1版本</a>\"和<a href=\"https://github.com/spring-projects/spring-modulith/releases/tag/1.0.1\">1.0.1版本</a>\"的发布说明。</p><p>&nbsp;</p><p></p><h4>Quarkus</h4><p></p><p><a href=\"https://quarkus.io/\">Quarkus</a>\"&nbsp;3.4.1发布了对Redis 7.2的支持，以及对<a href=\"https://quarkus.io/guides/flyway\">Flyway</a>\"扩展支持的更改，其中包括：通过将quarkus.flyway.enabled属性设置为false，可以禁用Flyway扩展的自动配置；通过将quarkus.flyway.active和quarkus.flyway..active属性分别设置为false，可以将特定数据源和某个名称的数据源设置为非活跃状态。关于该版本的更多详情，请参阅<a href=\"https://github.com/quarkusio/quarkus/releases/tag/3.4.1\">更新日志</a>\"。</p><p></p><p></p><h4>Open Liberty</h4><p></p><p>IBM<a href=\"https://openliberty.io/blog/2023/09/19/23.0.0.9.html\">发布</a>\"了<a href=\"https://openliberty.io/\">Open Liberty</a>\"&nbsp;23.0.0.9版本，该版本提供了对以下内容的支持：需要Jakarta EE 10的Spring Boot 3.0、Spring Security 6.x以及名为springBoot3的新<a href=\"https://openliberty.io/docs/latest/reference/command/server-create.html#_options\">服务器模板</a>\"；支持使用OpenID Connect令牌端点的私钥JWT认证，以及将LTPA或JWT cookie路径设置为应用程序上下文根的能力，以便于为不同的应用程序提供不同的LTPA和JWT令牌。</p><p></p><p></p><h4>Micronaut</h4><p></p><p>Micronaut基金会<a href=\"https://micronaut.io/2023/09/22/micronaut-framework-4-1-2-released/\">发布</a>\"了<a href=\"https://micronaut.io/\">Micronaut</a>\"的4.1.2版本，其中包括<a href=\"https://github.com/micronaut-projects/micronaut-core/releases/tag/v4.1.6\">Micronaut Core 4.1.6</a>\"以及对<a href=\"https://micronaut-projects.github.io/micronaut-data/latest/guide/\">Micronaut Data</a>\"模块的更新。关于该版本更多的详情，请参阅<a href=\"https://github.com/micronaut-projects/micronaut-platform/releases/tag/v4.1.2\">发布说明</a>\"。</p><p></p><p></p><h4>Hibernate</h4><p></p><p><a href=\"https://hibernate.org/orm/\">Hibernate ORM</a>\"的6.3.1.Final和6.2.9.Final版本发布，其中包含已知缺陷的修正以及查询方法和查找器（finder）方法的改善。关于这些版本的更多详情，请参阅<a href=\"https://hibernate.atlassian.net/issues/?jql=project%20%3D%20HHH%20AND%20fixVersion%20%3D%2032188\">6.3.1.Final版本</a>\"和<a href=\"https://hibernate.atlassian.net/issues/?jql=project%20%3D%20HHH%20AND%20fixVersion%20%3D%2032192\">6.2.9.Final版本</a>\"的发布说明。</p><p></p><p></p><h4>Eclipse基金会</h4><p></p><p>在OmniFishEE<a href=\"https://twitter.com/OmniFishEE/status/1702263849984885156\">推出</a>\"后不久，<a href=\"https://github.com/eclipse-ee4j/epicyro/blob/main/README.md\">Eclipse Epicyro</a>\"&nbsp;3.0作为<a href=\"https://jakarta.ee/specifications/authentication/3.0/\">Jakarta Authentication 3.0</a>\"规范的独立实现正式发布。这个新项目会为认证机制定义一个通用的底层SPI，即与调用者和容器环境交互以获取调用者凭证的控制器，并将经过认证的身份标识（比如名称和组）传递给容器。</p><p>&nbsp;</p><p></p><h4>Apache软件基金会</h4><p></p><p>实时分布式OLAP数据存储<a href=\"https://pinot.apache.org/\">Apache Pinot</a>\"&nbsp;1.0.0版本<a href=\"https://www.mail-archive.com/announce@apache.org/msg08513.html\">发布</a>\"，提供了缺陷修复、功能增强和新特性，例如，在OVER()子句中使用ORDER BY子句实现Window Functions<a href=\"https://docs.pinot.apache.org/users/user-guide-query\">查询</a>\"运行时的初步支持；如果使用LIMIT子句，SortOperator类的执行将提前终止；对基于分区的叶子阶段处理的支持。关于该版本的更多详情，请参阅<a href=\"https://github.com/apache/pinot/releases/tag/release-1.0.0\">发布说明</a>\"。InfoQ将继续跟进，以提供更详细的新闻报道。</p><p>&nbsp;</p><p></p><h4>OpenXava</h4><p></p><p><a href=\"https://openxava.org/\">OpenXava</a>\"&nbsp;7.1.6<a href=\"https://openxava.org/blog/openxava-7.1.6-released\">发布了</a>\"一些值得注意的功能修复，比如，改进了@ElementCollection和@DescriptionsList注解之间的交互；如果列表中包含baseCondition参数和IFilter接口的实例，则使用@Tab注解对列表进行过滤或排序后的分组将会失败；如果应用程序位于代理背后，则IForwardAction接口的实例将无效。关于该版本的更多详情，请参阅<a href=\"https://github.com/openxava/openxava/releases/tag/7.1.6\">发布说明</a>\"。</p><p></p><p></p><h4>Gradle</h4><p></p><p><a href=\"https://gradle.org/\">Gradle</a>\"&nbsp;8.4的第一个<a href=\"https://github.com/gradle/gradle/releases/tag/v8.4.0-RC1\">发布候选版本</a>\"提供了如下功能：鉴于Kotlin尚不支持JDK 21，因此仅在编译、测试和运行Gradle项目时提供了对JDK 21的初步支持；改进了在Windows操作系统上的编译；简化了使用ConfigurationContainer接口创建以角色为中心的Configuration接口实例的方法；改进了对<a href=\"https://docs.gradle.org/8.4-rc-1/userguide/kotlin_dsl.html\">Kotlin DSL</a>\"的支持。关于该版本的更多详情，请参阅<a href=\"https://docs.gradle.org/8.4-rc-1/release-notes.html\">发布说明</a>\"。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/09/java-news-roundup-sep18-2023/\">Java News Roundup: JDK 21, GraalVM for JDK 21, Apache Pinot 1.0, Eclipse Epicyro 3.0</a>\"</p>",
    "publish_time": "2023-10-11 00:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "KafkaFlow入门指南：构建可扩展的Kafka事件驱动应用",
    "url": "https://www.infoq.cn/article/Fzwavj3qHfpOt0Gk7sU5",
    "summary": "<p>在本文中，我们将会探讨KafkaFlow提供提供的特性。如果你正在使用.NET构建Apache Kafka生产者和消费者，那么本文将会介绍如何借助KafkaFlow来简化你的生活。</p><p></p><h2>为何要关注它？</h2><p></p><p></p><p>KafkaFlow为Confluent .NET Kafka客户端提供了一个抽象层。它使得使用、维护和测试Kafka消费者和生产者均更加容易。</p><p></p><p>假设你要为市场营销活动创建一个客户端目录（Client Catalog）。我们需要一项服务来消费那些捕获新客户端的消息。当开始设计所需的服务时，你会发现现有的服务在如何消费消息方面并不一致。</p><p></p><p>常见的情形是，团队在解决一些简单的问题（如优雅关机）时，往往会陷入困境。你会发现整个组织有四种不同的JSON序列化器实现，这只是挑战之一。</p><p></p><p>采用KafkaFlow这样的框架能够简化流程并加快开发周期。KafkaFlow拥有一系列旨在提升开发人员体验的特性：</p><p></p><p>中间件（Middleware）：KafkaFlow允许开发人员创建中间件来处理消息，从而实现对Kafka生产者/消费者管道的更多控制和定制。处理器（Handler）：引入了处理器的概念，允许开发人员将主题中的消息处理转发给专用消息类型的处理器。反序列化算法（Deserialization Algorithms）：提供了一套开箱即用的序列化和反序列化算法。多线程消费者：提供了保证消息处理顺序的多线程功能，有助于优化系统资源的使用。管理API和仪表盘：提供了API和仪表盘来管理消费者和消费者群组，可以在运行时进行暂停、恢复或倒回偏移。消费者限流：提供了一种简便的方式，为主题的消费提供优先级。接下来，我们探讨一下这些特性，看看它们在解决类似问题方面的潜力。</p><p></p><h2>KafkaFlow生产者：简化消息的生成</h2><p></p><p></p><p>我们从消息的生产者开始。</p><p></p><p>向Kafka中生成消息并不是什么高难的火箭科学。即便如此，KafkaFlow还是为Confluent的.NET Kafka客户端的生产者接口提供了更高级别的抽象，从而能够简化代码并提升可维护性。</p><p></p><p>下面是一个如何使用KafkaFlow生产者发送消息的样例：</p><p></p><p><code lang=\"java\">await _producers[\"my-topic-events\"]\n    .ProduceAsync(\"my-topic\", message.Id.ToString(), message);\n</code></p><p></p><p>这样，我们就可以向Kafka生成消息，而无需直接处理序列化或底层Kafka客户端的其他复杂问题。不仅如此，定义和管理生产者还可以通过服务配置上的流畅接口（Fluent Interface）轻松实现。</p><p></p><p><code lang=\"java\">services.AddKafka(kafka =&gt; kafka\n    .AddCluster(cluster =&gt; cluster\n        .WithBrokers(new[] { \"host:9092\" })\n        .AddProducer(\n            \"product-events\",\n            producer =&gt;\n                producer\n            ...\n        )\n    )\n);\n</code></p><p></p><p>生产者往往很简单，但也有一些常见的问题需要解决，比如压缩或序列化。我们来探讨一下。</p><p></p><h2>在KafkaFlow中自定义序列化/反序列化</h2><p></p><p></p><p>在Apache Kafka中，一个很有吸引力的特性就是与数据格式无关。但是，这就将责任转移给了生产者和消费者。如果考虑不周全，可能会导致在整个系统中出现由多种方式实现同一种结果的现象。因此，序列化显然是一个由客户端框架处理的用例。</p><p></p><p>KafkaFlow具有适用于JSON、Protobuf甚至Avro的序列化器。只需将它们添加到中间件配置中就可以使用。</p><p></p><p><code lang=\"java\">.AddProducer(producer =&gt; producer\n       ...\n       .AddMiddlewares(middlewares =&gt; middleware\n           ...\n           .AddSerializer()\n       )\n)\n</code></p><p></p><p>鉴于我们可以为消息使用自定义的序列化器/反序列化器，所以这个列表并不局限于这三种。虽然Confluent的.NET Kafka客户端已经支持自定义序列化/反序列化，但KafkaFlow通过提供更优雅的处理方式简化了这一过程。举例来说，要使用自定义序列化器，我们可以这样做：</p><p></p><p><code lang=\"java\">public class MySerializer : ISerializer\n{\n       public Task SerializeAsync(object message, Stream output, ISerializerContext context)\n       {\n             // 序列化逻辑在这里\n       }\n\n       public async Task DeserializeAsync(Stream input, Type type, ISerializerContext context)\n       {\n             // 反序列化逻辑在这里\n       }\n}\n\n// 在设置Kafka消费者/生产者的时候，注册自定义的序列化器\n\n.AddProducer(producer =&gt; producer\n       ...\n       .AddMiddlewares(middlewares =&gt; middleware\n          ...\n          .AddSerializer()\n       )\n)\n<p></p><p></p><h2>KafkaFlow中的消息处理</h2><p></p><p></p><p>消费者带来了大量的问题和可能性。第一个问题就是“如何处理消息？”</p><p></p><p>我们从最简单的方式开始。随着像MediatR这样的库的出现，CQRS和Meditor模式得到了普及，.NET开发人员习惯于将消息处理器与请求/消息接收器解耦。KafkaFlow将同样的原则引入到了Kafka消费者中。</p><p></p><p>KafkaFlow消息处理器允许开发人员定义特定的逻辑来处理来自Kafka主题的消息。按照设计，KafkaFlow的消息处理器结构能够更好地分离关注点，并使代码更整洁、更易于维护。</p><p></p><p>如下是一个消息处理器的示例：</p><p></p><p><code lang=\"java\">public class MyMessageHandler : IMessageHandler\n{\n    public Task Handle(IMessageContext context, MyMessageType message)\n    {\n        // 消息处理逻辑在这里\n    }\n}\n</code></p><p></p><p>这个处理器可以在消费者配置中进行注册：</p><p></p><p><code lang=\"java\">.AddConsumer(consumer =&gt; consumer\n...\n       .AddMiddlewares(middlewares =&gt; middlewares\n           ...\n             .AddTypedHandlers(handlers =&gt; handlers\n                     .AddHandler()\n              )\n       )\n)\n</code></p><p></p><p>通过这种方式，可以轻松地将消费者和处理器分开，从而提升了可维护性和可测性。如果你的微服务只处理具有一种消息类型的一个主题，这可能会显得引入了不必要的复杂性。在这种情况下，你可以使用中间件。</p><p></p><h3>KafkaFlow中的中间件</h3><p></p><p></p><p>KafkaFlow是面向中间件的。你可能已经注意到，在消息处理器的代码片段中提到了“中间件”。所以，你可能会问什么是中间件。</p><p></p><p>中间件使得类型化处理器（Typed Handler）成为可能。消息会被传递到一个中间件管道，该管道将会被依次调用。如果你使用过MediatR管道的话，可能会对这一概念有所了解。此外，中间件还可以用来进行一系列的转换。换句话说，给定的中间件可以将传入的消息转换到下一个中间件。</p><p></p><p>KafkaFlow中的中间件封装了处理消息的逻辑。管道是可扩展的，允许开发人员在消息处理管道中添加行为。</p><p></p><p>如下是一个中间件的样例：</p><p></p><p><code lang=\"java\">public class MyMiddleware : IMessageMiddleware\n{\n    public async Task Invoke(IMessageContext context, MiddlewareDelegate next)\n    {\n         // 预处理逻辑位于这里          \n        await next(context);          \n         // 后处理逻辑位于这里       \n    }\n}\n</code></p><p></p><p>要使用该中间件，可以在消费者配置中进行注册：</p><p></p><p><code lang=\"java\">.AddConsumer(consumer =&gt; consumer\n       ...\n       .AddMiddlewares(middlewares =&gt; middlewares\n             ...\n             .Add()\n         )\n)   \n</code></p><p></p><p>通过这种方式，开发人员就可以在消息处理管道中插入自定义逻辑，从而提供灵活性和控制力。类型化处理器是中间件的一种形式。所以，你甚至可以在没有类型化处理器的情况下处理消息，实现自己的中间件，或者也可以使用中间件来构建消息管道，在处理消息之前执行校验、丰富化等操作。</p><p></p><h2>在KafkaFlow中处理并发</h2><p></p><p></p><p>一旦开始思考基础设施的效率，你就会发现许多Kafka消费者没有得到充分利用。最常见的实现方式是单线程的，这限制了资源的利用率。因此，当我们需要扩展的时候，只能进行横向扩展，以保持所需的吞吐量。</p><p></p><p>KafkaFlow为实现基础设施的高效率带来了另外一种可选方案。KafkaFlow让开发人员可以控制单个消费者可以并发处理多少消息。它使用了Worker的理念，这些Worker可以协同消费一个主题。这一功能能够让你优化Kafka消费者，使其更好地匹配系统的能力。</p><p></p><p>如下是一个如何为消费者设置并发worker数量的样例：</p><p></p><p><code lang=\"plain\">.AddConsumer(consumer =&gt; consumer\n.Topic(\"topic-name\")\n       .WithGroupId(\"sample-group\")\n       .WithBufferSize(100)\n       .WithWorkersCount(10) // 设置worker的数量\n       .AddMiddlewares(middlewares =&gt; middlewares\n        ...\n        )\n)\n</code></p><p></p><p>即便有并发worker，KafkaFlow也能确保顺序。</p><p></p><h2>批处理</h2><p></p><p></p><p>随着规模的扩大，你将会面临延迟和吞吐量之间的权衡。为了解决这个问题，KafkaFlow有一个重要的特性，叫做“批量消费”。这个特性满足了以批量方式消费和处理来自Kafka的消息时对效率和性能的要求。在需要一起处理一组消息，而不是单个处理消息的场景下，该特性发挥着重要作用。</p><p></p><h3>什么是批量消费？</h3><p></p><p></p><p>在批量消费方式中，系统不是在收到消息后对其进行原子性地处理，而是将多条消息分组，然后一次性地对其进行处理。这种方法在处理大量数据时更为有效，尤其是在消息相互独立的情况下。批量执行操作会提高整体性能。</p><p></p><h3>KafkaFlow的批量消费方式</h3><p></p><p></p><p>KafkaFlow利用中间件系统提供批量处理功能。批量处理中间件能够让你根据批量大小或时间跨度（timespan）对消息进行分组。一旦达到其中的某个条件，中间件就会将这组消息转发给下一个中间件。</p><p></p><p><code lang=\"java\">services.AddKafka(kafka =&gt; kafka\n    .AddCluster(cluster =&gt; cluster\n        .WithBrokers(new[] { \"host:9092\" })\n        .AddConsumer(\n            consumerBuilder =&gt; consumerBuilder\n            ...\n            .AddMiddlewares(\n                middlewares =&gt; middlewares\n                    ...\n                    .BatchConsume(100, TimeSpan.FromSeconds(10))\n                    .Add()\n            )\n        )\n    )\n);\n</code></p><p></p><h3>批量消费对性能的影响</h3><p></p><p></p><p>通过批量处理，开发人员可以在基于Kafka的应用程序中实现更高的吞吐量。它可以加快处理速度，因为与启动和完成每个处理任务相关的开销会大大减少。这将全面提升系统的性能。</p><p></p><p>同时，这种方式还能减少网络I/O操作，因为数据是以更大的分块获取的，这能够进一步提高处理速度，尤其是在需要关注网络延迟的系统中。</p><p></p><h2>KafkaFlow的消费者管理</h2><p></p><p></p><p>KafkaFlow还简化了Kafka消费者管理相关的任务。通过KafkaFlow的管理API，我们可以启动、停止、暂停消费者以及倒回偏移（rewind offset）。</p><p></p><p>管理API可以在编程接口、REST API或Dashboard UI中使用。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/kafkaflow-dotnet-framework/en/resources/48figure-1-1693906634283.jpg\" /></p><p></p><p>KafkaFlow的管理仪表盘</p><p></p><h2>消费者限流</h2><p></p><p></p><p>通常，底层技术可能无法像Kafka消费者那样以相同的方式应对高负载期。这会带来稳定性的问题，而这正是限流的用武之地。</p><p></p><p>消费者限流是一种管理消息消费的方式，它能够使应用程序根据指标动态调整消息消费的速度。</p><p></p><h3>优先级</h3><p></p><p></p><p>假设你正在运行一个应用程序，希望将原子操作和批量操作分隔到不同的消费者和主题中。与批量操作相比，你可能更愿意优先处理原子操作。按照传统方式，由于消息生成的速度可能存在差异，所以管理这种差异化可能很具挑战性。</p><p></p><p>在这种情况下，消费者限流就很有价值了，它允许我们监控那些负责原子操作的消费者的滞后（lag）情况。根据这一指标，我们可以对处理批量操作的消费者实施限流，确保优先处理原子操作。</p><p></p><p>那结果是什么呢？高效、灵活和优化的消费流程。</p><p></p><p>借助KafkaFlow的流畅接口，为消费者添加限流功能是非常简单的。下面是一个简单的样例：</p><p></p><p><code lang=\"java\">.AddConsumer(\n    consumer =&gt; consumer\n        .Topic(\"bulk-topic\")\n        .WithName(\"bulkConsumer\")\n        .AddMiddlewares(\n            middlewares =&gt; middlewares\n                .ThrottleConsumer(\n                    t =&gt; t\n                        .ByOtherConsumersLag(\"singleConsumer\")\n                        .WithInterval(TimeSpan.FromSeconds(5))\n                        .AddAction(a =&gt; a.AboveThreshold(10).ApplyDelay(100))\n                        .AddAction(a =&gt; a.AboveThreshold(100).ApplyDelay(1_000))\n                        .AddAction(a =&gt; a.AboveThreshold(1_000).ApplyDelay(10_000)))\n                .AddSerializer()\n        )\n)\n</code></p><p></p><h2>KafkaFlow：展望未来</h2><p></p><p></p><p>目前，KafkaFlow在Kafka的基础上提供了一个健壮的、对开发人员友好的抽象，简化了使用.NET构建实时数据处理应用程序的过程。但是，与其他活跃的开源项目一样，KafkaFlow也在不断演进和完善。</p><p></p><p>从<a href=\"https://github.com/Farfetch/kafkaflow/issues?q=is%3Aissue+milestone%3Av3.0.0+is%3Aopen\">项目目前的发展轨迹来看</a>\"，我们可以预测几个方面的发展方向。例如，KafkaFlow可能会进一步增强其中间件系统，为消息处理提供更多的控制权和灵活性。我们可能还会看到更广泛的管理API，为开发人员提供对Kafka集群更大的控制权。</p><p></p><p>由于设计上的可扩展性，我们可以期待KafkaFlow社区会不断壮大，带来更多的贡献、创新特性、扩展和支持。随着越来越多的开发人员和组织采用KafkaFlow，我们会看到学习资源、教程、案例和其他社区内容不断涌现，这些内容可以帮助新用户入门，也可以帮助现有的用户从库中学习更多的知识。</p><p></p><h2>结论</h2><p></p><p></p><p>KafkaFlow是一个便利、对开发人员友好的工具，它简化了在.NET中使用Kafka的工作。在开发人员体验和可用性方面，它均表现出色。该框架的设计非常适合整洁、可读性强的代码。在Apache Kafka上构建应用程序时，KafkaFlow通过中间件、消息处理器以及对复杂问题的抽象，实现了清晰的分离，这有助于保持代码库的可管理性和可理解性。</p><p></p><p>除此之外，围绕KafkaFlow的社区在不断壮大。如果你正在使用Kafka并希望提高生产力和可靠性，那KafkaFlow绝对值得考虑。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/kafkaflow-dotnet-framework/\">Building Kafka Event-Driven Applications with KafkaFlow</a>\"</p></code></p>",
    "publish_time": "2023-10-11 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "广告创意领域中AIGC的应用 | InfoQ《极客有约》",
    "url": "https://www.infoq.cn/article/p56ceAHvdxwtkZN9d7ct",
    "summary": "<p>大模型出现后，许多大佬、专家都表示过“值得考虑用大模型重新构建所有行业和产品”类似观点。具体到各个行业，那么能利用大模型哪些能力解决什么样的问题，落地时存在哪些挑战，都是值得探讨的话题。</p>\n<p>本次《极客有约》我们将围绕广告创意领域中AIGC的应用，聊点真实的落地的难处。</p>",
    "publish_time": "2023-10-11 10:36:13",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "招商银行人工智能实验室研发工程师赵文婷确认出席 FCon，分享招商银行智能审查系统建设与应用",
    "url": "https://www.infoq.cn/article/GgM1xYCEZgMSSYkJCJzd",
    "summary": "<p><a href=\"https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle\">FCon 全球金融科技大会</a>\"，将于 11 月在上海召开。招商银行人工智能实验室研发工程师赵文婷将发表题为《<a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5562?utm_source=infoqweb&amp;utm_medium=article\">招商银行智能审查系统建设与应用</a>\"》主题分享，介绍招行的智能审查系统，以及智能审核技术团队相关实战经验。</p><p></p><p><a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5562?utm_source=infoqweb&amp;utm_medium=article\">赵文婷</a>\"，硕士毕业于北京航空航天大学计算机系，加入招行人工智能实验室后，长期从事语音语义理解相关算法模型研发落地工作。先后主导推进智能合同审查、智能语音质检、智能双录、智能外呼、智能协呼语义理解及 TTS 应用建设等项目，深耕自然语言处理、语音合成、声纹识别、多模态分析等技术能力。项目期间参与发表论文被 EMNLP、ACL、IEEEE Trans 等国际顶会顶刊录取，所参与团队知识工程建设相关项目曾获银保监会一等奖、人民银行二等奖，同时先后获得招行中心级年度优秀员工、年度 MVP、优秀导师等多项奖项。所推进相关技术广泛应用于招行客服、经营、风控等核心业务场景，持续推进最前沿人工智能技术在金融领域结合落地。她在本次会议的演讲内容如下：</p><p></p><p>演讲：招商银行智能审查系统建设与应用</p><p></p><p>银行业作为知识密集型领域，其各个业务场景每日能够产生大量的不同模态非结构化数据，如托管产品合同、专项债发债方案书、营销电访通话、经营客服会话等。为贯彻落实监管部门关于业务开展过程中各项规定，降低合规风险、提升服务质量，行内每年需投入大量人力做质检审查工作。</p><p></p><p>招行智能审查系统通过结合自然语言处理、语音识别、图像处理等多项 AI 技术，充分学习利用各类业务文档、规章制度等领域知识，提供了一套具有较强泛化性、可支持全量实时质检的多模态智能审核方案。审核系统致力于辅助人工开展具备较强专业性的合规审查工作，节省审核人力，提高审核效率，同时降低由审核标准不一致带来的审核风险。本次演讲将会分享招行智能审核技术团队相关实战经验。</p><p></p><p>演讲提纲：</p><p></p><p>招行智能审核系统介绍实战项目分享 </p><p>○ 托管合同智能审查 </p><p>○ 运管票据智能审查 </p><p>○ 专项债智能审查 </p><p>○ 电访微信智能审查 </p><p>○ 智能双录合规审查</p><p>总结与展望</p><p></p><p>你将获得：</p><p></p><p>○ 金融场景智能审核实战经验</p><p>○ 智能审核落地方案及应用难点</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle\">DevOps&nbsp;在金融企业落地实践</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle\">金融行业大模型应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle\">创新的金融科技应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle\">金融实时数据平台建设之路</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle\">金融安全风险管控</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle\">数据要素流通与数据合规</a>\"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，享 7 折优惠 ，立省 ￥2040！咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png\" /></p><p></p>",
    "publish_time": "2023-10-11 11:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "谷歌云为医生推出专用生成式AI工具，临床信息一键搜索",
    "url": "https://www.infoq.cn/article/WqVqVBQN4u1Uo9TvIhET",
    "summary": "<p>本周，谷歌云宣布在 Vertex AI 中引入专为医疗保健和生命科学组织量身定制的新功能，帮助医护人员从不同类型的医疗记录中，快速提取准确的临床信息。</p><p></p><p><a href=\"https://www.infoq.cn/article/0higrDEDX6Zs81dXCaSf\">医疗</a>\"保健是一个数据密集型行业，大部分医学知识都隐藏在海量的结构化和非结构化数据中，临床医生很难从中快速地找到所需的信息（如患者病例和扫描文档）。此外，出了搜索之外，要找出数据之间的相关性，还依赖于医护人员具备专业的临床知识。要将各个点联系起来并获取高质量的患者护理所需的信息是行业面临的巨大挑战。</p><p></p><p>针对这一问题，<a href=\"https://www.infoq.cn/article/AGWPQMx0Ea3FUepM1fmC\">谷歌云</a>\"推出的最新搜索工具将利用 Vertex AI 现有的跨数据源搜索功能，帮助医护人员更轻松地从不同类型的医疗记录中搜索临床信息和研究患者记录。</p><p></p><p>值得关注的是，除了 EHR（电子健康记录）内的数据之外，该搜索功能在足够精细的级别上可以涵盖整个组织生态系统中的数据，包括临床记录、扫描文档和电子健康记录等等。甚至，通过与谷歌专注于医疗保健的大型语言模型 Med-PaLM 2 配合使用，该工具还可以连接到外部资源和患者的医疗记录。</p><p></p><p>这意味着，如果医生想要了解患者的病史，他们不再需要单独阅读患者的诊疗记录、传真和电子健康记录，只要搜索“该患者在过去 12 个月内服用过哪些药物”之类的问题，就能获取患者的用药史、之前的实验室检查以及与患者的护理计划等相关的信息。</p><p></p><p>谷歌云 AI 产品管理高级总监 Lisa O’Malley 表示，新搜索功能还可用于其他关键应用，例如应用正确的计费代码，以及确定患者是否符合参加临床试验的标准。并且，还可以引用并链接到信息的原始来源，这些信息直接来自组织自己的内部数据，这有助于缓解临床医生对 AI 可能产生幻觉或不准确信息的担忧。</p><p></p><p>Vertex AI 是一个面向非机器学习开发人员的平台。该平台提供了一个简单的编排层，将企业数据与生成式基础模型以及会话 AI 和信息检索技术结合起来，可以帮助开发人员将确定性工作流与生成式输出相结合，将基于规则的流程与动态 AI 相结合，构建出可靠的应用程序。</p><p></p><p>从本周一起，客户可以注册提前访问面向医疗保健和生命科学行业的 Vertex AI Search。在此之前，谷歌云已经在与梅奥诊所（Mayo Clinic）、Hackensack Meridian Health 和 Highmark Health 等健康组织测试这项功能。</p><p></p><p>谷歌云表示，这一功能将为医护人员节省大量的时间和精力。</p><p></p><p>根据<a href=\"https://www.ama-assn.org/\">美国医学会（AMA）</a>\"的一项研究发现，医生在病人身上每花费一个小时，就会额外花费两个小时在行政工作上。研究称，医生还倾向于在工作时间之外多花一到两个小时做文书工作，而这段时间通常是他们的睡眠时间。</p><p></p><p>而通过新的搜索功能，谷歌希望减少临床医生花费在挖掘额外记录和数据库上的时间。这对于医护人员而言，意义巨大。</p><p></p><p>除了谷歌之外，越来越多的云服务商正在发力人工智能技术研发和应用，并赋能于医疗行业。</p><p></p><p>比如，微软通过生成式 AI 工具，帮助医疗保健公司协助患者、改进调度程序并为管理聊天机器人提供支持；</p><p></p><p>再比如，甲骨文宣布其最新矢量数据库将包含高度专业化的培训数据，例如电子健康记录等（这些数据将保持匿名性和私密性），同时训练专有模型，帮助医生提高诊断能力和癌症、心脏病等疾病的治疗处方。</p><p></p><p>参考链接  ：</p><p><a href=\"https://www.cnbc.com/2023/10/09/google-announces-new-generative-ai-search-capabilities-for-doctors-.html\">https://www.cnbc.com/2023/10/09/google-announces-new-generative-ai-search-capabilities-for-doctors-.html</a>\"</p><p><a href=\"https://www.forbes.com/sites/saibala/2023/10/09/google-cloud-launches-new-healthcare-generative-ai-features/?sh=64784e727e5b\">https://www.forbes.com/sites/saibala/2023/10/09/google-cloud-launches-new-healthcare-generative-ai-features/?sh=64784e727e5b</a>\"</p>",
    "publish_time": "2023-10-11 14:01:26",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "银行券商经验不完全适用，中粮信托这样构建数字化中台",
    "url": "https://www.infoq.cn/article/gCQGEgWrVX4PMNP1ohOJ",
    "summary": "<p>嘉宾｜谢胜强 中粮信托数字化中心总经理</p><p></p><p>“信托公司有自己的行业特殊性，在数字化建设上不能完全照搬银行、证券等金融机构经验，需要找到一条适合自己的路线。”谈及中粮信托数字化转型的背景，中粮信托数字化中心总经理谢胜强直言。</p><p></p><p>虽然信托与银行、保险、证券并驾齐驱，都是现代金融体系中的重要构成部分，但是其行业规模、科技资源投入却和其它三个行业相去甚远。据谢胜强介绍，根据相关统计，目前整个信托行业从业人员不到 20000人，其中在编科技人员不到 1000 人，平均下来每个信托公司的科技人员只有 10 多人。加上不同信托公司信息科技发展水平不均，不少信托公司的科技基础相对比较薄弱。</p><p></p><p>“这意味着不管是资金投入还是人员配备，多数信托公司都无法与银行、券商相比，我们必须结合自身资源禀赋，从自身的需求出发去做数字化。”</p><p></p><p>与此同时，随着资管新规的出台，信托行业开始从过去的非标品业务向标品业务转变。而在这个领域，与券商、基金公司相比，信托公司并没有优势，想在站稳脚跟，信托公司必须主动改造传统基因，在符合监管要求的前提下，创新原有的业务和运营模式。而在这个过程中，信息系统的升级挑战也随着而来——过去信托行业软件系统长期提供的都是标准功能和服务，面对创新的个性化需求，投入成本大，传统软件厂商响应意愿和效率都相对不高。</p><p></p><p>在过去的几年间，中粮信托也经常面临系统需求响应速度无法满足业务开展需要的情况。为了改变这种现状，中粮信托于 2022 年启动以打造数字化快速响应能力、赋能业务发展为主要目标的数字化 2.0 战略。</p><p></p><p>虽然整个数字化中心团队加上外包人员仅有 70 多人，但中粮信托通过自主研发搭建了技术中台，通过自主研发合作研发方式打造了业务中台，并且基于网易数帆数据开发治理平台 EasyData 构建了数据中台，从基础设施、应用架构、团队组织、服务管理体系、信息安全等各个层面推动了多维度的数字化能力建设。</p><p></p><h3>需求挖掘是数字化建设的开始</h3><p></p><p></p><p>在谢胜强看来，企业数字化建设工作主要以划分为两个部分：一是需求挖掘；二是需求实现。</p><p></p><p>首先，需求挖掘是一切工作的开始，但这也恰恰是最难的一环。一个有价值的需求的提出，要求相关人员能够打破传统的思维惯性，具备数字化思维。然而，由于业务与技术之间长期存在的巨大鸿沟，业务不了解技术，技术不熟悉业务，多数情况下任何一方都很难单独担此重任。</p><p></p><p>为此，中粮信托 2022 年开始在高度依赖信息系统的领域引入“数字化 +”联合工作组机制，即由数字化中心和运营、业务部门等组建联合工作组。具体由运营、业务部门资深人员担任组长，数字化中心资深人员担任副组长，工作组定期沟通，滚动梳理相应领域的数字化需求，形成一致目标，孵化数字化建设项目，并且定期向数字化委员会汇报进展，跟进项目开发、实施、验收及后评价。</p><p></p><p>以运营数字化联合工作组为例，他们在 2022 年孵化并落地了资金清算网关、估值自动化、合同全生命周期管理等多个数字化建设专项，使得公司估值、资金清算等运营工作效率得到极大提升。</p><p></p><p>经过充分的需求挖掘，下一步就是需求实现。这一方面有赖于人员能力的提升，另一方面也需要基础设施的升级。</p><p></p><p>针对人的问题，中粮信托过去两年里在组织架构层面进行了调整。把原来公司的“信息科技委员会”更名为“数字化委员会”，把“信息技术部”更名为“数字化中心”，从各种文化宣贯和落地细节上向数字化方向靠拢，同时，还通过适度的人员扩充、外包机制引入，实现了科技团队规模的快速扩增。目前，整个数字化中心（原“信息科技部”）拥有 11 位正式员工，以及 60 多位外包人员。</p><p></p><p>针对基础设施的问题，中粮信托对硬件、网络、安全等多个方面进行了升级，其中主机房从过去 10 数平米8 个机柜的规模，扩大到 200 多平近 40 个机柜。据谢胜强介绍，这样的配置在信托行业已经比较靠前。</p><p></p><p>更重要的是，中粮信托还在应用层面进行了大刀阔斧的架构转型，从过去各个系统各自为政的竖井式架构，转变为微服务、云原生架构。</p><p></p><p>“过去内部不同系统架构不统一且在顶层设计方面缺少统筹，不同厂商之间甚至相同厂商不同产品之间都存在重复开发、响应周期长、迭代成本高等问题。这是我们进行应用架构改造的主要原因。”谢胜强强调，中粮信托的微服务架构搭建采用模块化的设计思路，坚持解耦、复用、领域自治的基本导向，不是为了微服务而为微服务：一方面将完整、复杂的业务系统拆分成相对简单、可复用的多个逻辑单元，从而降低对开发商和自有研发团队的参与门槛，让更多只具有细分专业领域能力的开发商也可以参与进来，让专业的人做专业的事；另一方面，通过模块化编排和流程组织，快速支持各类创新业务场景。</p><p></p><p>基于这一应用架构思路，中粮信托提出了数字化中台战略，将共性需求进行抽象，打造成平台化、组件化的系统能力并共享使用，先后布局了研发管理、运营管理、金融服务、企业数据中心 2.0 四大核心基础平台。</p><p></p><h3>用 6 个月时间，自主搭建技术中台</h3><p></p><p></p><p>在中粮信托，研发管理平台被定义为“技术中台”，主要输出敏捷开发能力。</p><p></p><p>为了确保从应用底层开始的整体自主可控，同时避免市面上许多技术平台因为本身过重导致在使用过程中对信托公司普遍不太富裕的研发资源的过度消耗，加快技术响应，中粮信托选择自主搭建技术中台。</p><p></p><p>“基于之前积累的研发成本，新平台的研发过程大概花了 6 个月时间，我们讲究的是实用为主，贴近信托行业的系统研发场景进行设计。”谢胜强告诉 InfoQ 记者，“虽然资源投入有限，参与的人员只有 5 人，但是团队内部有明确的分工。比如，我们定义出一整套覆盖现有各类使用场景的前端解释性框架标准，由前端组负责桌面和移动两端的开发实现，绝大部分业务场景的交互界面均可通过后端配置实现，不用逐个进行开发。”</p><p></p><p>除此之外，为了确保整套设计体系能够兼容不同的技术栈，便于后续的灵活拓展，中粮信托的自主研发核心系统采用的是开放框架平台，并有专人负责架构融合开发。</p><p></p><p>据了解，中粮信托该研发管理平台已经于 2022 年下半年正式投产运行，核心组件包括了 Action 微服务设计框架、Action 解释型前端框架、Action 流程引擎等。结合自主研发并嵌入到 IDE 的代码生成器等工具，可以让研发人员专注于各自领域内的具体业务逻辑研发，降低研发人员技术水平要求并提高研发效率。</p><p></p><p>“其中，除了服务注册发现、流量管理、链路跟踪等常见的网关是基于开源开发的，其它的核心部分，包括网关和统一认证等等都是我们的团队结合自身需求进行的设计和开发。”谢胜强表示。</p><p></p><p>基于技术中台，中粮信托自去年开始构建业务中台——具体包括了运营管理平台和金融服务平台，主要输出平台化、组件化的系统能力。</p><p></p><p>运营管理平台面向内部员工，主要把传统 OA、CRM、TA、PM、AM(不含场内) 等系统进行拆解，并按从领域到模型再到场景的设计思路用微服务框架进行了重新组织，从而形成模块化的系统能力，并通过模块编排和流程组织，快速支持各类新的需求场景。该平台主体功能于 22 年底完成开发，23 年初开始分阶段上线，并根据内部需求持续迭代。</p><p></p><p>金融服务平台面向外部生态，主要采用与厂商合作研发相结合的方式，按照其自身定义的技术框架标准开发，确保所有的系统能力均可在受控的前提下被内外部系统开发人员根据需要自由调用，从而打破不同开发商之间的技术壁垒。该平台于 23 年二季度启动建设，目前处于集成测试阶段，计划在四季度分阶段上线并持续迭代。</p><p></p><h3>把数据中台和业务中台结合起来考虑</h3><p></p><p></p><p>整体而言，中粮信托在业务中台建设过程中采用的是基于“领域到模型再到场景”的设计框架，这使得复杂的业务逻辑被分解成众多相对简单的逻辑单元，有利于内外部细分领域专业能力、资源的整合与调度。而数据中台的建设，其中关键一步是从主题域到数据资产模型的梳理，在这个层面是可以通过工具实现大规模复用的。</p><p></p><p>“也就是说，在这个过程中，数据中台的建设和业务中台我们是一起考虑的。”</p><p></p><p>虽然中粮信托在 2018 年自主搭建了以传统数仓为主要特征的企业数据中心，但是随着数字化转型进程的推进，传统数据管理架构和数据应用开发模式渐渐难以满足越来越多的数据应用需求。</p><p></p><p>“我们把所有的数据资产模型做了整理，通过 CDC 方式把数据全部拉过来进行了分类管理和存放，按报送要求进行实时数据加工，再辅以报文组织等功能，最终实现了监管报送系统的自主研发。”谢胜强指出。</p><p></p><p>除了满足数据互通的需求，数据质量提升也是这个过程中非常重要的目标。为此，中粮信托从业务流程层面进行了全面重塑，并纳入到业务中台中。</p><p></p><p>以数据治理为例，该工作过去普遍都在数据平台中进行，但问题在于，该模式可能导致业务系统和数据平台的数据存在不一致的情况。“在中粮信托，我们要求所有的数据治理必须从源头治理，甚至把数据中台作为业务中台的一个数据服务模块。”</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/09/098d0ac46523f8955ac49530429e89ad.png\" /></p><p></p><p>换言之，在中粮信托的数据治理体系里，所有业务数据落地都有对应流程，而不是直接进入数据库。其中，针对一些在历史稽核中从未或较少发生错误的数据，可以取消或精减复核节点；而针对经常出现错误的数据，则可以增加针对性的复核节点，从而提高它们的数据质量。</p><p></p><p>与此同时，由于中粮信托将数据中台的数据资产标准模型与业务中台的标准模型进行了统一，使得数据和应用两个层面都可以实现批量创建，减少了人员投入的时间和精力。</p><p></p><p>“我们把整个数据链分成两端：一端是数据资产，在这一端先不考虑应用，只考虑信托公司经营范围之内存在哪些有价值的数据，并将这些数据准实时流动到数据中台，通过标准的数据加工处理存放到资产层；另一端是数据应用，在这个环节，所有开发人员都不允许碰源系统，只能基于标准数据资产构建数据应用。这样，就能节省大量数据采集的重复工作，也有助于确保不同数据应用之间的口径一致。”谢胜强进一步解释。</p><p></p><h2>数据技术底座的选型和磨合</h2><p></p><p></p><p>总结中粮信托在其中的成功经验，谢胜强认为，第一是准实时数据流动以支持更为广泛的数据应用场景，第二是从源头治理以保证不同平台间数据的一致性，第三是形成标准化的、符合信托行业需要的数据资产管理体系。</p><p></p><p>当然，这些经验也并非中粮信托单枪匹马趟出来的。在中粮信托数据中台搭建中，碍于技术团队规模和资源投入的局限性，他们在 2022 年采购了网易数帆的数据开发治理平台 EasyData 作为数据技术底座，通过模型复用等方式按主题域快速构建了标准数据资产模型，通过 CDC 等工具将各源系统数据准实时归集到贴源层，并利用平台离线计算、实时计算能力对贴源层数据进行加工，形成了准实时、标准化的数据资产，按不同应用场景需要加工到应用层，结合 BI 等工具平台快速构建各类数据应用，并通过数据接口服务等形成数据生产和消费闭环。</p><p></p><p>回顾技术选型的过程，谢胜强谈到，信托行业不少公司是通过整体外包的形式构建自己的数据平台，在灵活、开放、可控、复用等方面与我们对数据中台的要求不完全相符。为此，中粮信托结合自身对行业的理解，引入了网易数帆的工具平台。“我们想走出一条不同的路。”谢胜强说。</p><p></p><p>经过多方的对比和评估，中粮信托发现，网易数帆数据开发治理平台 EasyData 的数据资产管理、模型管理、元数据管理、血缘关系管理等功能比较贴合其数据中台的定位；同时，在数据应用层面，EasyData 也能提供相对完善的数据服务接口，基于中粮信托的数据标准，只要经过简单配置就可以进行数据服务的调用。</p><p></p><p>谢胜强坦言，由于中粮信托是网易数帆在信托行业首家合作的公司，因此在合作前期的两三个月时间里，双方针对数据中台的功能研发也经过了一番磨合。</p><p></p><p>“包括模型的设计、应用的开发模式、怎么分层、怎么分主题进行管理，刚开始大家理解都不一样。比如，我们需要的是数据的实时流动，而 EasyData 现有客户广泛采用的按日切片存储这些功能对我们就不适用。”谢胜强表示，这是一个不断碰撞的过程，双方在其中共创出了很多更匹配信托场景需求的功能。</p><p></p><p>以监管报送平台为例：当监管反馈报送的数据存在问题，传统做法是负责监管报送的技术人员逐一查找、修改、重新生成报文，然后再次报送。这种方式不仅效率低，而且对人的要求比较高。对此，中粮信托向网易数帆提出了新的需求，当发现数据问题，只要导入报文，就能基于数据血缘功能进行快速的数据定位和分析。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0c/0c26f10b463e5bb3ffc1d3f66a761eb4.png\" /></p><p></p><p>再以数据治理为例：虽然中粮信托从流程上设置了对问题数据的拦截，但是也不排除最后会有少量“漏网之鱼”流到数据中台。对此，网易数帆现状已经可以支持在问题发现之后，对接到业务中台并触发数据治理流程，经过业务侧的再次数据治理，再回到数据中台，从而实现准实时的数据高质量流动。</p><p></p><h3>关于技术投产比，需求部门自身要“算好账”</h3><p></p><p></p><p>毋庸置疑的是，即便是在经济环境充满不确定性，行业和企业资源也相对有限的情况下，中粮信托仍然非常看重数字化转型中的技术投入。那么，其内部是如何评估和量化数字化的价值的？</p><p></p><p>谢胜强告诉 InfoQ，在企业数字化转型的过程中，虽然很多工作无法直接估算其经济价值，但它们也是可以量化的。</p><p></p><p>比如随着自动化估值系统的上线，公司估值工作的自动化程度从过去的 30% 上升到如今的 80%，这意味着过去一个会计只能管理 60-100 个套账，现在至少可以提升到 120-200 个，这带来的是效率的提升和人力成本的降低。</p><p></p><p>当然，数字化变革背后涉及复杂的、系统化的运作，很多效益提升无法简单粗暴地归功于某个系统的上线或者某个技术的应用。因此，中粮信托强调的是需求部门自身要“算好账”，对此技术团队还在运营管理平台开发了需求管理模块，业务人员可以在线提交数字化需求，经过需求沟通、确认、审核、分析、设计、实现、测试、发布、评价等标准化需求处理流程，从而实现数字化需求的全生命周期管理。如果是需要外采的，在实现节点对接招采模块，如果是需要自研的，在实现节点对接研发管理平台。</p><p></p><p>“哪怕是一个非常简单的数字化需求，都要经过这个标准的处理流程。需求分配给谁进行开发、测试，他的单位时间成本是多少，在平台上是可以实时计算出来的，这些信息可以提供给需求部门做参考，在某种程度上也变相督促大家进行投入产出的衡量和评估。”谢胜强表示。</p><p></p><p>可以看到，信托行业的数字化转型虽然来得比其它金融细分行业要晚一些，数字化进程和路径选择有其特殊性，但彼此间也有很多相似的思路。比如，虽然可投入的资源规模不一样，但对技术价值量化的严谨考究是共识；虽然选择的技术路线可能不一样，但业技融合是共识；虽然企业业务目标不一样，但通过文化、组织、流程、人才等多条线体系化地推进数字化转型，这也是共识。</p><p></p><p>从这些角度来看，中粮信托的数字化实践历程同样值得信托之外的各行各业做参考。</p><p></p><h4>活动推荐</h4><p></p><p>首届<a href=\"https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">FCon全球金融科技大会</a>\"将于 11 月 19-20 日在上海举办。大会将围绕金融领域数字化转型挑战探索、DevOps 在金融企业落地实践、金融行业大模型应用、创新的金融科技应用、金融实时数据平台建设之路、金融安全风险管控、数据要素流通与数据合规等 10+专题进行交流。</p><p></p><p>目前大会邀请了汇丰科技中国区的代理总经理马国栋、度小满金融数据智能部总经理杨青先、蚂蚁集团副总裁 &amp; 首席技术安全官韦韬博士、恒生聚源总经理吴震操担任大会联席主席。更多嘉宾仍在邀请中......</p><p></p><p>我们诚挚地邀请您加入我们，共同探索金融科技的未来，<a href=\"https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">点击链接</a>\"即可查看全部演讲专题。</p><p></p><p>目前是 <a href=\"https://fcon.infoq.cn/2023/shanghai/apply?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">7 折特惠购票</a>\"，报名立减 ¥2040，咨询购票可联系：17310043226（微信同手机号）。</p>",
    "publish_time": "2023-10-11 14:22:06",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AutoGPT放弃向量数据库！向量数据库是小题大作的方案？",
    "url": "https://www.infoq.cn/article/0LpSixGbHNp8TlHsosRf",
    "summary": "<p>生成式 AI 促进了向量数据库的火爆，但如今的技术风向变化似乎也挺快。作为全球最著名的AI项目之一，AutoGPT宣布不再使用向量数据库，这一决定可能让不少人感到惊讶。毕竟从一开始，向量数据库就一直协助管理着AI智能体的长期记忆。</p><p>&nbsp;</p><p>那么这个基本设计思路怎么就变了？又该由哪种新方案代替？对于大模型应用来说，矢量数据库是必要的吗？</p><p>&nbsp;</p><p></p><h2>事情发展</h2><p></p><p>&nbsp;</p><p>AutoGPT是今年3月30日发布的一种“AI agent（AI智能体）”，类似的还有LlamaIndex和LangChain。AutoGPT一发布就名声大噪，上线仅 7 天就在 GitHub 上获得了 44,000 颗星。相较于之前一遍又一遍向模型输入提示词的用法，它能够自行工作、规划任务、将问题拆分成多个较小的部分、再逐个加以执行。毫无疑问，这是个雄心勃勃的计划。</p><p>&nbsp;</p><p>AutoGPT的设计思路还涉及一种以嵌入形式管理智能体记忆的方法，外加一套用于存储记忆并在必要时检索的向量数据库。从当时的角度看，向量数据库被认为是整个解决方案当中最重要的组成部分。而且其他通用人工智能（AGI）项目也纷纷采取同样的方法，例如BabyAGI。</p><p>&nbsp;</p><p>之前在默认情况下，AutoGPT支持五种存储模式：</p><p>&nbsp;</p><p>LocalCache (will be renamed to JSONFileMemory)RedisMilvusPineconeWeaviate</p><p>&nbsp;</p><p>但现在查看AutoGPT的说明文档，我们会发现一条令人惊讶的警告消息：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e8/e87796186466bed4a77744015a69ea3b.jpeg\" /></p><p></p><p>&nbsp;</p><p>AutoGPT最近刚刚经历了“向量记忆改造”，其删除了所有向量数据库实现，包括Milvus、Pinecone、Weaviate，仅保留几个负责记忆管理的类。如今，JSON文件成为存储记忆/嵌入的默认方式。</p><p>&nbsp;</p><p></p><h2>原因是向量数据库没有附加价值？</h2><p></p><p>&nbsp;</p><p>其实，AutoGPT的维护者Reinier van der Leer于今年5月份就在GitHub上询问大家对“增加不同存储方式的价值”的看法，因为他们想进行重构，并打算放弃除“本地”内存提供程序（现在称为json_file）之外的所有东西，同时努力实现Redis VectorMemoryProvider。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/11/1179fb1d6efe123490a7691034086f86.jpeg\" /></p><p></p><p>&nbsp;</p><p>有开发者对此表示赞同，认为如果后端足够好，那么没有理由保留这些向量数据库。“但我建议将pinecone（如果有优势的话，那也可以是redis）集成到自定义JSONFileMemory中。”</p><p>&nbsp;</p><p>当然也会有反对者，他们认为“向量数据库比当前的 JSON 文件内存系统更高效。它们是为此类任务而构建的，可以简化开发并减少token消耗。”Reinier对此进行了反驳，“这说法太笼统了，是否有例子或假设案例来证明这一点是正确的？”</p><p>&nbsp;</p><p>至于以后要不要恢复向量数据库，该开发团队表示这肯定不是当前的首要任务，况且他们也没发现向量数据库能带来什么特别的附加价值。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bc/bcbc2f96af2d599ec5be0e6d69606382.jpeg\" /></p><p></p><p>&nbsp;</p><p>在开发内存系统时，我们要关注数据结构，而不是存储机制。使用具有 JSON 持久性是最简单的实现方法，为实验留出了空间。</p><p>&nbsp;</p><p>&nbsp;</p><p>为什么AutoGPT一开始采用但现在又放弃向量数据库？是向量数据库的价值问题还是架构设计问题？InfoQ询问了流数据库公司 RisingWave（risingwave.com）创始人 &amp;CEO 吴英骏，他认为更多的是设计决策上的事情：</p><p>&nbsp;</p><p></p><blockquote>AutoGPT最开始采用矢量数据库进行矢量存储与查询，相信单纯是为了快速打造产品原型，缩短开发周期。选用矢量数据库进行初代产品的开发可以更快得到高效可靠的矢量存储查询功能。而如今，AutoGPT选择“放弃”矢量数据库，多半也是发现运维与使用矢量数据库的代价已经超过了其带来的好处。在这种情况下，重新自己造轮子更符合项目发展的长远收益。毕竟，在软件开发过程中，过早优化会带来极高开发成本与风险，导致软件复杂度不可控。</blockquote><p></p><p>&nbsp;</p><p>这也正如AutoGPT项目维护者Reinier所言，AutoGPT支持多个向量数据库，确实会拖慢开发速度。那么像AutoGPT这样的大模型应采用向量数据库并不是必要的吗？对于长期记忆，我们还有其他选择？</p><p>&nbsp;</p><p></p><h2>该如何选型？</h2><p></p><p>&nbsp;</p><p>早在4月份，<a href=\"https://jina.ai/news/auto-gpt-unmasked-hype-hard-truths-production-pitfalls/\">就有网友对AutoGPT最初的选择提出批评</a>\"，认为向量数据库是种“小题大做的解决方案”。他的论证过程也很简单：</p><p>&nbsp;</p><p></p><blockquote>假设大语言模型需要10秒钟才能生成一条结果，即需要存储的单条新记忆。那么我们获得10万条记忆的时间周期将为：100000 x 10秒 = 1000000秒——约等于11.57天。而即使我们用最简单的暴力算法（Numpy的点查询），整个过程也只需要几秒钟时间，完全不值得进行优化！也就是说，我们就连近似最近邻搜索都不需要，更不用说向量数据库了。</blockquote><p></p><p>&nbsp;</p><p>那么我们应该如何为自己的项目选型？吴英骏老师认为，对于任何大模型应用，是否需要选用矢量数据库，完全取决于该应用对于矢量存储与查询的依赖程度。</p><p>&nbsp;</p><p>“对于需要存储大量矢量的场景，如海量图像检索、音视频检索等，很显然使用矢量数据库可以获得更加强大、专业的功能，而对于数据量并没有那么大的场景来说，还不如使用Numpy等Python库计算来的高效、便捷。实际上，在矢量数据库这个赛道上，也分为轻量级矢量数据库以及重量级矢量数据库等，到底是选择PostgreSQL上的pgvector插件还是选择一个专用的分布式矢量数据库，也是需要对于特定应用做出具体分析之后再做出决策。”</p><p>&nbsp;</p><p>这个说法也符合如今AutoGPT项目的真实选择，使用np.dot进行嵌入比较：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f4/f47c21baa19278c36c56690708f17865.png\" /></p><p></p><p>&nbsp;</p><p>Andrej Karpathy也曾在Twitter上表达过此类观点。之前他利用OpenAI的API建了一个大模型应用，有网友问使用了什么向量数据库，Karpathy表示，不用追风一些“奇特的东西”，使用Python库中的np.array已经足够了。推文底下当即有人评论说，这种务实的观点应该传播到学术界和整个机器学习社区！</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a0/a0762e3adfa975859574d4e4c831d4b7.jpeg\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>写在最后</h2><p></p><p>&nbsp;</p><p>目前据我们所知，不采用向量数据库的也不止AutoGPT：比如GPT Engineer、GPT Pilot甚至是GitHub Copilot等都不使用向量数据库——相反，它们通过最近文件、文件系统内的邻近度或查找对特定类/函数的引用来获取相关上下文。</p><p>&nbsp;</p><p>是否选择使用向量数据库要看情况，而AutoGPT放弃向量数据库，是朝着正确方向迈出的重要一步，即专注于提供价值、而非深陷技术泥潭。</p><p>&nbsp;</p><p>会不会有一天，向量数据库又将重返AutoGPT？向量数据库到底算不算是AI技术革命中的重要组成部分？或者说，向量数据库Pinecone成为AI长期记忆方案的愿景，只是一句空洞的口号？或许也有人认为，真正的问题是像AutoGPT这样的项目并没能带来任何价值。也许目前我们能够论证的就只有这些，余下的只有靠时间来证明......</p><p>&nbsp;</p><p>延伸阅读：</p><p><a href=\"https://mp.weixin.qq.com/s/gGptu_zoT4lJbZ9-4fQzzg\">向量数据库？不要投资！不要投资！不要投资！</a>\"</p>",
    "publish_time": "2023-10-11 15:06:15",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]