[
  {
    "title": "Android Studio Giraffe 稳定版亮相，带来IntelliJ 2022.3及全新IDE外观",
    "url": "https://www.infoq.cn/article/hkqHm2GKjCFUggQ7urfA",
    "summary": "<p>&nbsp;<a href=\"https://developer.android.com/studio\">Android Studio Giraffe</a>\"现已<a href=\"https://developer.android.com/studio\">稳定</a>\"，其引入了新的IntelliJ 2022.3、新的IDE外观和感受、改进的Live Edit、Compose动画预览，等等。</p><p>&nbsp;</p><p><a href=\"https://www.infoq.com/news/2013/05/Android-Studio/\">自2013年首次发布之来</a>\"的十年里，Android Studio仍然是安卓开发的IDE。其最新版本在不同领域引入了许多更改，包括IDE增强、编码效率提升和构建系统改进等。</p><p>&nbsp;</p><p>Android Studio Giraffe采用了一个新的可选择IDE外观和风格，旨在降低视觉复杂性。它致力于简化对最常用功能的访问，同时使较复杂的功能在需要时更易于访问，但在正常使用中不那么突出。此外，它还提供了一个新的主题，使IDE的视觉效果看起来更加现代：</p><p>&nbsp;</p><p></p><blockquote>随着Giraffe的发布，我们已经开始采用新的UI，并对Android Studio进行了一些特定的更改，例如优化Android的默认主工具栏和工具窗口配置，以及刷新我们的风格图标。</blockquote><p></p><p>&nbsp;</p><p>新的IDE还包括一个更新的设备资源管理器，它可以检查任何连接设备的文件和进程，包括复制或删除文件、终止进程或将调试器附加到正在运行的进程上的可能性。</p><p>&nbsp;</p><p>在代码效率方面，Android Studio Giraffe提供了在可组合项中预览UI更改的可能性，而无需将应用程序重新部署到模拟器或物理设备上。该功能可以通过设置/编辑器/实时编辑（Settings/Editor/Live Edit）启用，并且需要Android Gradle Plugin（AGP）8.1或更高版本以及Jetpack Compose Runtime 1.3.0或更高版本的支持。</p><p>&nbsp;</p><p>与预览功能相关的是，Compose动画预览已经支持了许多其他Compose API，包括<a href=\"https://developer.android.com/jetpack/compose/animation/value-based#animate-as-state\">animate*AsState</a>\"、<a href=\"https://developer.android.com/jetpack/compose/animation/composables-modifiers#crossfade\">CrossFade</a>\"、<a href=\"https://developer.android.com/jetpack/compose/animation/value-based#rememberinfinitetransition\">rememberInfiniteTransition</a>\"和<a href=\"https://developer.android.com/jetpack/compose/animation/composables-modifiers#animatedcontent\">AnimatedContent</a>\"。动画可以播放、暂停、滑动等等。</p><p>&nbsp;</p><p>提高代码效率的最后一个帮助来自新的Android SDK升级助手。</p><p>&nbsp;</p><p></p><blockquote>新的Android SDK升级助手可以让你直接在IDE中查看升级targetSdkVersion或应用程序所针对的API级别所需的步骤。</blockquote><p></p><p>&nbsp;</p><p>该助手将显示与你选择的升级选项相关的所有信息，因此你无需要再单独浏览这些信息，并且能够突出显示每个迁移步骤的主要突破性更改。</p><p>&nbsp;</p><p>说到构建系统，你现在可以在<a href=\"https://android-developers.googleblog.com/2023/04/kotlin-dsl-is-now-default-for-new-gradle-builds.html\">Gradle构建脚本中使用Kotlin DSL</a>\"，利用它的编译时检查，可将所有项目代码整合到一种语言下。</p><p>&nbsp;</p><p></p><blockquote>此外，我们还添加了对基于TOML的Gradle Version Catalogs的实验性支持，该功能允许你在一个中心位置管理依赖项，并在模块或项目之间共享这些依赖项。</blockquote><p></p><p>&nbsp;</p><p>最后需要说明的是，Android Studio Giraffe可以在Gradle同步时显示依赖项下载信息。这将能帮助你检测存储库配置中的低效率问题。</p><p>&nbsp;</p><p>Android Studio Giraffe的内容远不止这些。如果你对完整的细节感兴趣，请不要错过官方公告。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/07/android-studio-giraffe-stable/\">https://www.infoq.com/news/2023/07/android-studio-giraffe-stable/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/twFsuxo4IQi5FIqe3OKA\">移动端性能挖掘：字节跳动iOS与安卓性能归因实践</a>\"</p><p><a href=\"https://www.infoq.cn/article/MuATtLq6R00gEssCOwzj\">Lyft如何检测生产中安卓的内存泄漏</a>\"</p>",
    "publish_time": "2023-09-20 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何利用播放器节省 20% 点播成本？",
    "url": "https://www.infoq.cn/article/Rx45QcxHI4zZCfMR5r8J",
    "summary": "<p>点播成本节省的点其实涉及诸多内容，例如 CDN、<a href=\"https://www.infoq.cn/article/Vsc9cCloJx9mCOTyURGT\">转码</a>\"、存储等，而利用播放器降本却是很多客户比较陌生的部分。火山引擎基于内部支撑抖音集团相关业务的实践，播放器恰恰是成本优化中最重要和最为依赖的部分。</p><p></p><p><a href=\"https://www.infoq.cn/article/r3J9F7CtFJyljwQWwl79\">火山引擎</a>\"的视频团队做了份数据统计，在一个很经典的视频业务中，我们在 2022 年至 2023 年大约 1 年半的时间里，针对这个业务进行了 33 次成本优化点，其中 13 次是播放器主导的优化，其余的有 12 次也是需要播放器强配合的优化，也就是说在这个业务里，75% 的成本优化是直接或间接由播放器参与，可见客户端对成本优化的关键作用。</p><p></p><p>最终我们在很多实践中也发现，通过播放器的优化可以为点播业务节省 20% 甚至更多的成本，本篇内容便将聚焦在播放器层面如何节省成本这一主题上。</p><p></p><h2>一、点播成本构成</h2><p></p><p></p><p>在视频点播的成本构成中，有很明显的二八原则：</p><p><img src=\"https://static001.geekbang.org/infoq/b7/b7a1d2eb46169bedf7939dacf12f6cbf.png\" /></p><p>CDN 带宽成本占绝对的大头，80% 都是带宽成本；其次是存储和转码成本，二者占不到 20%；额外还有一些其他的周边的成本，比如日志处理的数据成本、AI 处理的成本。</p><p></p><p>我们可以将成本的优化理解成“置换”，在点播的成本优化中，就存在 2 种“置换关系”：</p><p></p><p>第 1 种置换关系是“成本项之间的置换”，指的是「带宽-转码-存储」之间的置换。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6a/6a0b4cad5199d28bdfb5ae239aa7174c.png\" /></p><p></p><p>上图是 H.264 升级到 H.265 编码格式的例子，265 的压缩率相对比 264 要优 20%-40%，所以带宽、存储上 265 是大幅度减少；但是 265 的计算复杂度要复杂很多，所以转码成本大幅度升高。而这个图不是一个等边三角形，带宽成本要远大于转码和存储成本，所以这个置换是非常划算的。</p><p></p><p>第 2 种置换是“成本和体验的置换”，我们一般说是“跷跷板效应：</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/69/69b5518c52156b7633a99b6ecf8ab462.png\" /></p><p></p><p>例如：</p><p>我们增大缓存时长，对应体验上「卡顿率」就会降低，但是成本会增加；抖音小视频 feed 流场景，我们做预加载，这时候首屏感会更顺滑，但对应的成本是增加的；降低码率，那么体验上感到清晰度变差了，而成本就是减少的；跷跷板中间支点是技术，我们通常是希望固定体验、降低成本，依靠技术来支撑。</p><p></p><p>所以我们总在说降成本，那降的到底是什么呢？我们这里用一个很简单的乘法公式来表示：</p><p><img src=\"https://static001.geekbang.org/infoq/43/43bd4980ca1f18f0f87f459cf0ecdac8.png\" /></p><p></p><p>在过去，“单价”是非常明显的因素，大家往往选择在采购环节尽量的压低单价； 而“用量”上通常会被认为是无法改变的业务因素。但“用量”实际上是包含 2 类，一类是正常用量，确实是比较难改变的业务因素，但另一类是“浪费”，是可以被优化的。所以如何识别出浪费、降低浪费，是播放器降本的关键点。</p><p></p><p>那么造成浪费的因素有哪些呢？</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ef/ef6af0158d68eca672870783bb48158b.png\" /></p><p></p><p>例如在视频播放过程中，会包括“已播放的数据”，和“未播放但已经缓存的数据”，如果用户中途离开播放，那其中“已缓存的数据”都是浪费了。所以我们定义“浪费”是“已经缓存了、但不需要的字节数”。</p><p></p><p>从理想上来说，没有浪费是最好的；但往往业务中，浪费是非常大的，大于30%是很常见的。常见的可能带来的浪费包括了：</p><p>未播放离开向后拖拽切换档位清晰度溢出（举例：很小的手机屏幕播放4K的内容，肉眼感知不到清晰度的区别）</p><p></p><p></p><h2>二、播放器的成本优化方法</h2><p></p><p></p><p>针对上述的浪费我们进行了如下的具体优化方法：</p><p></p><h4>（一）缓存的浪费</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3d/3d28d3667236f7e52cebf1c043b11535.png\" /></p><p></p><p>承接上图的播放器缓存示意图，如果用户播放过程中离开了，那么深灰色是浪费部分。很容易就想到我们减少深灰色的部分的大小，比如把播放水位降低 1/3（也就是图中浅黄色的部分减少掉），不去缓存，那么浪费就明显的减少了。</p><p></p><p>这个就是静态水位的思路，通过减少缓存水位来减少浪费。</p><p></p><p>但是，静态水位是很难抉择的，水位大了浪费多，但是水位太小了，卡顿就会明显的增加。</p><p></p><p>这里有个马太效应，从原理上，缓存的本质是为了对抗网络的抖动的。网络稳定好时，只需要很少的缓存就足够了，但是网络好时缓存会填充的很快，大部分时间都是饱和的。反之，波动大的网络，需要更多的水位，但总的上限也有限，无法提供有效的缓存。</p><p></p><p>为此我们实现了的动态水位算法，我们根据一些因素来动态的决策缓存水位的大小：</p><p>探测用户的网络速度和稳定性，对稳定性高、速度快的，我们减少缓存；对网络速度差、稳定性差的网络，就增大缓存，这样在网络抖动时就能够有更大的缓存空间使用；根据用户的播放行为，通过数据分析道，视频观看的前期，用户离开的比例会更高，观看的后期，离开的比例就会降低，所以前期的缓存水位小一些，后期的缓存水位大一些；一些其他的因素，但目的是在每次播放时决策出一个尽量合理的缓存水位，来平衡卡顿和浪费。</p><p></p><p>决定了缓存水位大小之后，还有个细节点就是 Range 请求。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a9/a92548397903c21bd2ec05e397ec127d.png\" /></p><p></p><p>Range 是 http 协议的一个请求头，默认是“0-请求”，表示请求完整文件。</p><p></p><p>左侧的图示意，如果是单独发一个“0-请求”，那么 CDN 服务端就会持续的返回整个文件，如果在中途断开，从服务端视角来说，这些数据已经发送过去了，无论客户端是否需要，都已经计费了，就构成了浪费。</p><p></p><p>在上图，我们分成 3 段来发 Range 请求，中途断开时，是可以停止掉最后一段，那么浪费就大幅度减少了。同样，静态的 Range 是很难抉择的，Range拆分的太细会引起卡顿的提升；Range 过大了成本节省的效果又不够了。</p><p></p><p>这里我们引入目标水位的概念，就是刚刚讲的动态水位算法所决策出来的水位大小。</p><p></p><p>播放器 Range 请求的应遵循两个原则：</p><p>1. 将当前视频尽快缓存到目标水位。</p><p>2. 控制 Range 拆分的大小，避免太小的 Range 拆分。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/17/177d1c20a6f1f2475729dd93415e31b5.png\" /></p><p></p><p>上图是动态水位算法+动态 Range 拆分的效果示意图：</p><p></p><p>横轴代表时间线。纵轴上图是视频下载的大小，蓝色块代表一个 Range 请求；下图是缓存的大小，橙色的折线表示缓存随着视频文件下载和播放时间的波动情况，横着的虚线是目标水位。</p><p></p><p>我们从左到右，分析下目标水位和 Range 的关系：</p><p>第 1 条竖红线，决策出来第一条目标水位1，是启播水位，启播时的 Range 会略大于后面的 2 个 Range；第 2 条竖红线，是判断出一次水位提升，有可能是检测到网络波动，会提高目标水位到水位 2，同时做一次略大的 Range 请求来达到目标水位；第 3 条竖红线，是再次提升目标水位，到水位 3，有可能是因为观看时长增加到阈值，判断离开概率较小，所以保持高水位；后续的播放，在目标水位3随着时间波动，Range大小也会稳定些。</p><p></p><p>从最终效果上看，在任意一个时间点离开，都能够保障相对合理的浪费。</p><p></p><p>我们在不同业务上实践了很多次动态水位+动态range的AB实验，在体验指标持平或更优的前提下，带宽降低8%。</p><p></p><h4>（二）预加载的浪费</h4><p></p><p></p><p>在类似于抖音这种 feed 流下滑的场景，会提前加载好下面的视频，能够使滑动更顺畅，我们 叫“零首帧”效果，里面作用最大的就是预加载。</p><p></p><p>一般的预加载是固定几个视频，每个视频固定的大小。为了得到更好的预加载效果，会尽量多、尽量大的做预加载，也就构成了浪费。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fe/fe95e01501613611343b42477de82da9.png\" /></p><p></p><p>我们做的“精准预加载策略”，在“时机、大小、个数”上做精细化的优化：</p><p>时机上：对预加载也进行切片，这样可以区分出来一部分是紧急的，其他是不紧急的。比如图里，标记P0的是要最优先下载的，然后可以做预加载，预加载标记 P1 的部分，然后是当前视频的缓存水位，之后可以选择是否要预加载 P3 的部分。大小上：每个视频也会结合视频的长度、头大小、码率等因素计算出来需要预加载的大小个数上：按照 feed list 中的优先级依次预加载后续 N 个视频（动态计算），也会结合用户本身的行为（比如快速滑动）来动态决策。</p><p></p><p>AB 实验证明，能够提升预加载利用率 5%，对应流量成本降低约 0.8%。</p><p></p><h4>（三）清晰度的浪费</h4><p></p><p></p><p>现在的主干场景是在移动端看视频，大家都会有启播选档的策略，就是在播放启动时，决定所需要的清晰度，一般是跟随网速、码率来决策的。</p><p><img src=\"\" /></p><p>经常大家面临的场景是，在竖屏里播放横屏视频时，实际上在很窄的一个空间里进行播放，这个时候，如果依然使用完整的清晰度，那么肉眼是看不出来的清晰的。而且，通常情况下小窗播放时用户的主要关注度也并不是画面清晰度，所以就产生了实际上的清晰度浪费。</p><p></p><p>我们对应的解决策略叫“窄屏低清”，就是识别出来显示区域很窄时，播放低清晰度的视频（比如360P），当需要横屏时，再快速的切换为正常的清晰度。这里如果是 mp4 格式播放，需要转码也做些配合，支持 mp4 的帧对齐和平滑切换。</p><p></p><p>在很多应用中都是很常见的，也有常见的小窗播放，多个业务的 AB 实验都能有 3% 以上的成本收益；</p><p>另外清晰度上还有个很棒的能力，是客户端超分。随着客户端超分能力的优化，现在很大一部分机型在客户端向上超分一个档位是完全没问题的，耗电可以忽略。</p><p></p><p>对应节省成本的策略是“降档超分”，就是分发的清晰度向下降一档，然后再通过客户端超分降主观清晰度补回来。在国内当前的机型条件下，大部分业务能够有 6～8% 左右的成本收益。</p><p></p><h4>（四）异常流量的浪费</h4><p></p><p></p><p>我们根据「播放器日志是否可以识别」、「是否是正常流量」把流量分成了 4 类。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/35/355b42ef6dc4ecbae6514c8c12ecd54c.png\" /></p><p>在非常多的业务中会发现第三种情况：流量有异常浪费，比如有部分视频码率过高，可能是没转码，或者转码模版用错了。我们开始时会认为“这些都是很明显的失误，业务层小心点不就行了么？”，但后来我们做成了单独的异常流量分析模块。我们跟业务尝试分析原因，发现业务总是复杂的：</p><p>业务场景很复杂，包括短视频、长视频、主页视频、广告视频等；研发的迭代通常会带来些历史问题；并不是所有的人员都需要持续的感知成本，只要有一个环节漏掉了，那么就可能会造成很大浪费。</p><p></p><p>这里还有个问题点，如果是体验问题或者 bug，总会有用户保障，来及时发现。但成本问题，用户基本是无法发现的，发现时就比较晚了。</p><p></p><p>我们是通过端到端的日志分析来发现和避免这些浪费的。原理很简单：</p><p>在客户端对日志染色；cdn 日志里记录的，区分是否是播放器产生的、是否是我们点播的域名；对两头的日志进行比对和分析。</p><p></p><p>不仅如此，这里还有个副产物，是通过这些日志分析，识别到业务真实是被盗链了，然后做盗链的治理。</p><p></p><h2>三、数据挖掘成本优化空间</h2><p></p><p></p><p>以上是<a href=\"https://www.infoq.cn/news/iSSNhwt4qU2WuSQ6U3AM\">火山引擎</a>\"是实际业务服务过程中探索出的优化方案，但优化是不是有上限的，优化到什么水平可以达到成本和体验的平衡，更多的能力是通过数据能力持续的挖掘出来的。</p><p></p><p>先从结果上来看，我们成本优化后通常会有2个报告：</p><p>1、AB 实验报告，里面会分析对 QoE 的体验影响多少，对成本优化的影响多少，比如图中的人均播放时长增加多少，成本降低多少；做成本的 AB 实验，依赖一个工具——客户端成本指标。</p><p>2、价值回溯文档，用于核算真实收益有多少，一般发生在完整上量之后，比如1个月或2个月后。关键结果叫“万分钟播放成本”，这个对应的依赖的工具是“成本评估公式”。</p><p></p><h4>（一）客户端成本指标</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f9/f94e68e1e1c0828594268e411a16b7ca.png\" /></p><p></p><p>这张图从左往右是视频点播的数据流向。想要建设好成本埋点，有2个难点：</p><p></p><p>1、成本拟合。因为真实的计费数据是左侧 CDN 的计费日志，在右侧的客户端侧实际上是没有成本数据的，所以我们需要把数据缓存层的对成本的埋点尽量的拟合，使之尽量的对应到 CDN 的计费日志。这个过程是非常艰难的，我们通过了大量的离线校验。</p><p></p><p>2、提升可解释率。业务动作比较复杂（播放、预加载、拖拽、重播等等），举个例子，重复播放，播放层是记录2遍播放时长的，但是因为有缓存，真实的网络请求只有1遍。我们想要两份数据尽量对齐、可解释，就需要涵盖住尽量所有的业务场景。</p><p></p><p>我们当前达到了“可解释率达到 95%”，也就是说比如服务端 CDN 产生了 100Gbps 的带宽，客户端的日志能够拟合解释清楚 95%。</p><p></p><p>虽然还不到 100%，但日常来做成本优化、成本归因已经足够了。</p><p></p><p>下图是成本指标进入 AB 实验后的结果：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e3/e3f5aa2bf270087ee3e07d826556bc41.png\" /></p><p>图：核心指标</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/36/36c765358635fac3fb3cc769b770652d.png\" /></p><p>图：归因指标</p><p></p><p>成本数据进入AB实验有什么用呢？有2  点：</p><p></p><p>1、快速判断客户端的成本变化结果。大部分成本优化的能力都是伴随着策略的，不同策略有不同的结果置换关系，我们需要通过实验来确定效果。假设没有客户端的成本数据的话，我们就需要用不同的 CDN 域名来实验，这是很低效的，并且域名带宽的波动也会引起成本的波动。而在客户端成本指标进入了 AB 实验之后，大部分场景都直接看报表数字就可以了。</p><p></p><p>2、机制上可以防蜕化。业务的产品经理、分析师等角色也日常会关注到实验数据的，当成本数据也进入实验后，这些角色也可以关注到成本的变化，这样就能够防退化了。举个例子，版本升级时，只要经历了 AB 实验，就很难有成本退化的问题。</p><p></p><h4>（二）成本评估公式</h4><p></p><p></p><p>“成本评估公式” ，本质是一种单位成本的衡量方法。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3f/3faace5c96677c360f3369d5060bc21c.png\" /></p><p></p><p>我们叫“万分钟播放成本”，分子是点播的IT成本，分母是点播视频消费时长。</p><p></p><p>从技术侧来看，分子是“CDN、存储、转码等各种成本的加和”，分子是播放的时长。</p><p></p><p>这个公式很简单，但为什么要这么做呢？</p><p></p><p>因为涉及到成本优化，就会跟采购、财务团队打交道，采购、财务看到的都是每月的账单，业务用量每个月都在上下波动，导致账单每个月也都在波动。万分钟播放成本是单位成本，就可以刨除掉业务用量的影响因素，来衡量成本是否真的优化了。</p><p></p><p>拿其中的万分钟 CDN 成本来举例：</p><p><img src=\"https://static001.geekbang.org/infoq/61/614883436e1bc01a0737693d6285b3cb.png\" /></p><p></p><p>万分钟 CDN 成本的影响因子会涉及到价格、码率、浪费率、带宽流量比。</p><p></p><p>举一个真实的例子：有个客户反馈成本增加了，但是客户自己的业务用量在波动，不太好判断是什么情况。我们拆解分析万分钟 CDN 成本的具体影响因子，就发现了万分钟 CDN 成本确实是涨了 11%，主因是“码率”涨了 8%，“浪费率”增加了 5%。</p><p></p><h2>四、总结和展望</h2><p></p><p></p><h4>（一）建标准</h4><p></p><p></p><p>在服务业务的过程中，大家经常会面临一个问题，还能再降多少？极限是多少？</p><p></p><p>这些问题是很难回答的，因为每个业务的场景都不同，举例缓存浪费中，每个业务的客户中断离开的模型可能都不一样，那么建设统一的标准就很难了。</p><p></p><p>火山引擎目前通过 3 种方式来建设标准：</p><p>通过排名获取标杆：将类似场景的业务进行排名，对齐当前技术做的最好的，可以作为一种标准；离线的实验来模拟：我们做了成本的自动化测试平台，设计测试case，测试出来不同的参数的成本结果是多少，最后总结分析出来极限是多少；通过“理论公式”来推算“标准” ：举例通过“视频播放时长、中途离开比例”的关系，然后推算出理论的优化空间有多少。</p><p></p><h4>（二）做顾问</h4><p></p><p></p><p>面对的业务越来越多，降本的能力也越来越多时，就会遇到效率问题：功能这么多，应该用哪些？每个业务的场景也不一样，那么策略参数应该怎么配置呢？</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/02/029a51f266a6efd2695de7e2beb1d610.png\" /></p><p>万分钟播放成本分析和策略推荐</p><p></p><p>解决方法是做顾问。如上图所示，其是我们的一个万分钟 CDN 成本与理想万分钟成本的一个差异分析表，我们给计算出了对应的差异，然后再给出可以补足差异的策略或功能推荐。</p><p></p><p>当然，这个表只是一个总结概览，更多的内容我们会整理成“顾问服务报告”，把各个点的差异、业务分析、解决方法与业务逐一的讨论分析。总之，万分钟播放成本是一个非常简单、容易落地、价值很大的工具，大家计算下万分钟播放成本，如有调优的诉求，非常欢迎来与火山引擎交流。火山引擎视频点播<a href=\"https://www.volcengine.com/product/vod\">https://www.volcengine.com/product/vod</a>\"。</p><p></p><p></p><p></p><h4>本文作者简介</h4><p></p><p>赵春波，火山引擎视频点播产品负责人。十余年视频相关研发和产品经验。目前主要负责火山引擎视频点播的产品工作，支撑抖音、西瓜等业务的点播基础技术、体验优化和成本优化等，并将这些技术能力沉淀到火山引擎，来服务更多的行业客户。</p>",
    "publish_time": "2023-09-20 09:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "“芯经济”崛起，英特尔加速AI抢位战",
    "url": "https://www.infoq.cn/article/g43AaWaexclQ0QVlyelb",
    "summary": "<p>&nbsp;当地时间9月19日，英特尔On技术创新大会（Intel Innovation） 2023在美国加州圣何塞拉开帷幕，InfoQ有幸受邀参会并从现场发回报道。英特尔On技术创新大会是一场面向开发者的大会，更是一个了解过去一年英特尔在不同方向（包括端侧计算、数据中心、边缘计算和云计算）取得的最新进展的好方法。来自全球的上千位开发者、英特尔合作伙伴和客户亲临这场盛会，以期全面了解英特尔将以怎样的新策略、新产品应对生成式AI大爆发带来的机遇和挑战。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/90/90e9c724d5763d9bf01039c278203882.jpeg\" /></p><p>图：InfoQ记者拍摄于现场</p><p>&nbsp;</p><p>AI毫无疑问是贯穿大会首日主题演讲全程的重要关键词。围绕“让AI无处不在”这一主题，英特尔CEO帕特·基辛格在主题演讲中展示了英特尔如何在其各种硬件产品中加入AI能力，并通过开放、多架构的软件解决方案推动AI应用的普及。</p><p></p><h2>AI推动“芯经济”崛起</h2><p></p><p></p><p>基辛格在主题演讲开场表示：“AI代表着新时代的到来。AI正在催生全球增长的新时代，在新时代中，算力起着更为重要的作用，让所有人迎来更美好的未来。对开发者而言，这将带来巨大的社会和商业机遇，以创造更多可能，为世界上的重大挑战打造解决方案，并造福地球上每一个人。”</p><p>&nbsp;</p><p>基辛格提到，如今芯片形成了规模达5740亿美元的行业，并驱动着全球约8万亿美元的技术经济。世界对计算的需求呈指数级增长，而且这种需求与芯片的面积、成本和功耗成反比。简而言之，这就是摩尔定律。随后他提出了“芯经济”（Siliconomy）这一概念：“芯经济”是一个由可持续、开放、安全的算力需求所驱动的经济增长新时代。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d7/d7c9452e6c69668e55c4ad38685fd8f0.png\" /></p><p></p><p>&nbsp;更充足、更强大、更具性价比的处理能力，是经济增长的关键组成。而人工智能代表着计算的新时代，促进了“芯经济”的崛起。基辛格表示，五大超级技术力量——计算、连接、基础设施、人工智能、传感和感知，由“芯经济”推动。随后他分享了一系列AI相关的软硬件产品方案新进展和技术路线图。</p><p></p><h2>英特尔开发者云全面上线</h2><p></p><p></p><p>基辛格宣布英特尔开发者云平台自今日起全面上线。英特尔开发者云平台能够帮助开发者利用最新的英特尔软硬件创新来进行AI开发（包括用于深度学习的英特尔Gaudi2加速器），并授权他们使用英特尔最新的硬件平台，如即将在未来几周内上线的第五代英特尔至强可扩展处理器（代号为 Emerald Rapids），以及将在12月14日上线的英特尔数据中心GPU Max系列1100和1550。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0b/0bcc3821726c9b97a5348dbb7022851e.jpeg\" /></p><p></p><p>&nbsp;在使用英特尔开发者云平台时，开发者可以构建、测试并优化AI以及HPC应用程序，他们还可以运行从小规模到大规模的AI训练、模型优化和推理工作负载，以实现高性能和高效率。</p><p>&nbsp;</p><p>英特尔开发者云平台建立在支持多架构、多厂商硬件的oneAPI开放编程模型基础之上，为开发者提供硬件选择，并摆脱了专有编程模型，以支持加速计算、代码重用和满足可移植性需求。</p><p>&nbsp;</p><p>据InfoQ了解，已经有不少客户基于英特尔开发者云构建自己的AI应用，埃森哲是其中之一。</p><p>&nbsp;</p><p>此外，基辛格还在会上发布了英特尔发行版OpenVINO工具套件2023.1版，并表示Arm也将参与到OpenVINO工作中。OpenVINO是英特尔的AI推理和部署运行工具套件，在客户端和边缘平台上为开发人员提供了优质选择。该版本包括针对跨操作系统和各种不同云解决方案的集成而优化的预训练模型，包括多个生成式AI模型，例如Meta的Llama 2模型。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/ba/ba11e2415bddb323043cad33640fbc95.jpeg\" /></p><p></p><p>为了更好地将AI扩展到边缘侧，英特尔还将推出Strata项目以及边缘原生软件平台。其中边缘原生软件平台平台将于2024年推出，提供模块化构件、优质服务和产品支持。这是一种横向扩展智能边缘（intelligent edge）和混合人工智能（hybrid AI）所需基础设施的方式，并将英特尔和第三方的垂直应用程序整合在一个生态系统内。该解决方案将使开发人员能够构建、部署、运行、管理、连接和保护分布式边缘基础设施和应用程序。</p><p></p><h2>AI芯片路线图、下一代至强处理器亮相</h2><p></p><p>&nbsp;</p><p>自今年7月英特尔发布 Gaudi 2 训练加速器以来，其性能表现一直备受关注。最近的 MLPerf AI 推理<a href=\"https://www.intel.com/content/www/us/en/newsroom/news/intel-shows-strong-ai-inference-performance.html\">性能测试结果</a>\"进一步证明了 Gaudi 2性能在市场上的竞争力，其是目前市场上满足 AI 计算需求的唯一可行替代方案。基辛格披露了一台完全基于英特尔至强处理器和 4000 个英特尔 Gaudi2 AI 硬件加速器构建的大型 AI 超级计算机。这台AI超级计算机将跻身全球TOP15超算，而AI独角兽企业Stability AI 是其主要客户。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/42/42b3a7746acd443bdf203f4b69438fd6.jpeg\" /></p><p></p><p>作为第四代英特尔至强处理器的早期采用者，阿里巴巴也被邀请来为英特尔站台。阿里云首席技术官周靖人阐述了阿里巴巴如何将内置AI加速器的第四代英特尔至强可扩展处理器用于其生成式AI和大语言模型，即“阿里云通义千问大模型”。周靖人表示，英特尔技术“大幅缩短了模型响应时间，平均加速可达3倍”。</p><p>&nbsp;</p><p>面向AI计算，基辛格亮出了英特尔最新的三代AI芯片路线图，其中采用5nm制程的Gaudi 3将于2024年推出，再下一代AI芯片代号为Falcon Shores，计划于2025年推出。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/92/923adbae77bd67b27b20adf7b09001b8.png\" /></p><p></p><p>其中Gaudi 3的算力将达到Gaudi 2的两倍，网络带宽、HBM容量将达到Gaudi 2的1.5倍。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/90/9028195e64b90828118cac67c62bef38.jpeg\" /></p><p></p><p>基辛格还在演讲中预览了下一代英特尔至强处理器，并透露第五代英特尔至强处理器将于12月14日发布，届时，将在相同的功耗下为全球数据中心提高性能和存储速度。此外，具备高能效的能效核（E-core）处理器Sierra Forest将于2024年上半年上市。与第四代至强相比，拥有288核的该处理器预计将使机架密度提升2.5倍，每瓦性能提高2.4倍。紧随Sierra Forest发布的是具备高性能的性能核（P-core）处理器Granite Rapids，与第四代至强相比，其AI性能预计将提高2到3倍。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/87/874ac283e432995661e9d836ba2550b7.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/af/af67cd6efa8cbc8c2abd6284ecd32cbf.jpeg\" /></p><p></p><p>展望2025年，代号为Clearwater Forest的下一代至强能效核处理器将基于Intel 18A制程节点制造。</p><p></p><h2>迈向AI PC新时代</h2><p></p><p>&nbsp;</p><p>为了让AI的使用更加普及化，英特尔也将目光放到了个人PC上。基辛格在演讲中表示：“AI将通过云与PC的紧密协作，进而从根本上改变、重塑和重构PC体验，释放人们的生产力和创造力。我们正迈向AI PC的新时代。”</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/21/21de39187af217d96624706d2fe0cd76.jpeg\" /></p><p></p><p>这一全新的PC体验，即将在接下来推出的产品代号为Meteor Lake的英特尔酷睿Ultra处理器上得到展现。该处理器配备英特尔首款集成的神经网络处理器（NPU），用于在PC上带来高能效的AI加速和本地推理体验。基辛格透露，酷睿Ultra将在12月14日发布。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/b4/b401df224216ec1e3f752224e64dbb4b.png\" /></p><p>酷睿Ultra处理器</p><p>&nbsp;</p><p>基辛格将酷睿Ultra处理器称作英特尔客户端处理器路线图的一个转折点：该款处理器是首个采用Foveros封装技术的客户端芯粒设计。除了NPU以及Intel 4制程节点在性能功耗比上的重大进步外，这款处理器还通过集成英特尔锐炫显卡，带来独立显卡级别的性能。</p><p>&nbsp;</p><p>基辛格展示了全新AI PC的众多使用场景，并邀请宏碁首席运营官高树国上台介绍了搭载酷睿Ultra处理器的宏碁笔记本电脑。高树国表示：“我们与英特尔团队合作，通过OpenVINO工具包共同开发了一套宏碁AI库，以充分利用英特尔酷睿Ultra平台，还共同开发了AI库，最终将这款产品带给用户。”</p><p>&nbsp;</p><p>AI创业公司Rewind AI也来到现场，演示在断网的情况下，由英特尔OpenVINO驱动在PC本地运行大语言模型，与AI聊天机器人进行实时问答。</p><p></p><h2>制程、封装最新进展</h2><p></p><p></p><p>在2022年英特尔投资者大会上，英特尔公布了接下来几年间的制程发展规划。按照英特尔的计划，未来的四年间，英特尔将跨过五个制程节点。此后一年间，这个计划的进展颇受关注。</p><p>&nbsp;</p><p>在今天的主题演讲中，基辛格表示，英特尔的“四年五个制程节点”计划进展顺利，Intel 7已经实现大规模量产，Intel 4已经生产准备就绪，Intel 3也在按计划推进中，目标是2023年年底。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5b/5be4db4865e0fbd06c9547916cf21d1a.jpeg\" /></p><p></p><p>基辛格还展示了基于Intel 20A制程节点打造的英特尔Arrow Lake处理器的首批测试芯片。他表示，Arrow Lake将于2024年面向客户端市场推出。Intel 20A将是首个应用PowerVia背面供电技术和新型全环绕栅极晶体管RibbonFET的制程节点。同样将采用这两项技术的Intel 18A制程节点也在按计划推进中，将于2024年下半年生产准备就绪。</p><p>&nbsp;</p><p>此前英特尔已经官宣 Intel 18A进程的多项进展。今年4月，英特尔代工服务事业部（IFS）和Arm宣布签署协议，旨在使芯片设计公司能够利用Intel 18A制程工艺来开发低功耗计算系统级芯片（SoC）。今年7月，爱立信宣布与英特尔达成战略合作协议，将采用英特尔18A制程和制造技术为爱立信的下一代5G基础设施优化提供支持。</p><p>&nbsp;</p><p>除制程外，英特尔向前推进摩尔定律的另一路径是使用新材料和新封装技术，如玻璃基板（glass substrates）。这是英特尔刚于本周宣布的一项突破。玻璃基板将于2020年代后期推出，继续增加单个封装内的晶体管数量，助力满足AI等数据密集型高性能工作负载的需求，并在2030年后继续推进摩尔定律。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/58/5885cfc3b010843f050f867823486802.png\" /></p><p>基辛格展示玻璃基板材料</p><p>&nbsp;</p><p>英特尔还展示了基于通用芯粒高速互连开放规范（UCIe）的测试芯片封装。基辛格表示，摩尔定律的下一波浪潮将由多芯粒封装技术所推动，如果开放标准能够解决IP集成的障碍，它将很快变成现实。发起于去年的UCIe标准将让来自不同厂商的芯粒能够协同工作，从而以新型芯片设计满足不同AI工作负载的扩展需求。目前，UCIe开放标准已经得到了超过120家公司的支持。</p><p>&nbsp;</p><p>该测试芯片集成了基于Intel 3制程节点的英特尔UCIe IP芯粒，和基于TSMC N3E制程节点的Synopsys UCIe IP芯粒。这些芯粒通过EMIB（嵌入式多芯片互连桥接）先进封装技术互连在一起。英特尔代工服务（Intel Foundry Services）、TSMC和Synopsys携手推动UCIe的发展，体现了三者支持基于开放标准的芯粒生态系统的承诺。</p><p></p><h2>先进计算和前沿研究</h2><p></p><p></p><p>除了大众关注更多的软硬件进展，英特尔研究院还在诸多前沿技术方向上展开探索，包括神经拟态计算、量子计算等。在主题演讲的最后，基辛格也对这些前沿研究方向的最新进展做了介绍。</p><p>&nbsp;</p><p>基于Loihi 2第二代研究芯片和开源Lava软件框架，英特尔研究院正在推动神经拟态计算的发展。Loihi 2是性能业界领先的神经拟态研究芯片，基于Intel 4制程节点开发，每个芯片最多可包含100万个神经元。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/25/255bb82d22d783dbe72d20de51839d98.jpeg\" /></p><p></p><p>Loihi 2还具有可扩展性，8芯片Loihi 2开发板Kapoho Point，可通过堆叠满足大规模工作负载的需求。英特尔还提供开源、模块化、可扩展的Lava软件框架，助力神经拟态应用的开发。</p><p>&nbsp;</p><p>量子计算方面，今年6月，英特尔发布了包含12个硅自旋量子比特（silicon spin qubit）的全新量子芯片Tunnel Falls，继续探索量子实用性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a5/a54d095dc1771a56c9cf0d46369b418f.jpeg\" /></p><p></p><p>在英特尔的晶圆厂里，Tunnel Falls是在300毫米的硅晶圆上生产的，利用了英特尔领先的晶体管工业化制造能力，如极紫外光刻技术（EUV），以及栅极和接触层加工技术。</p><p>&nbsp;</p><p>虽然这次在主题演讲中并未提及，但也有部分开发者对于英特尔在RISC-V方向的动态十分关注。英特尔近几年一直在投资 RISC-V，去年英特尔加入了全球开放硬件标准组织 RISC-V International，该组织成员包括阿里云、谷歌、IBM、Nvidia、三星等；旗下的 Mobileye 还推出了基于 RISC-V 的 EyeQ Ultra 芯片。但今年1月份，英特尔停止Intel Pathfinder for RISC-V项目，引发了RISC-V社区对于英特尔是否会继续投入的担忧。根据InfoQ获知的最新消息，英特尔只是停止了一个针对RISC-V 的前期探路项目，并没有停止对RISC-V 的支持，而是转而继续正式支持RISC-V，相关研究工作英特尔中国团队将会重点投入。</p><p></p><h2>写在最后</h2><p></p><p></p><p>在生成式AI这波大潮之下，更多人只关注到了GPU的成功和抢手程度，但GPU可能并这波浪潮唯一的受益者。随着大模型热潮爆发，未来将有海量潜在的AI应用需求，业内有观点认为，未来运行大模型所消耗的计算量（即推理的算力规模），将超过用于训练模型的计算量。从硬件层面来看，这意味着 AI 研究的重点将转向如何降低推理成本，而这恰恰是英特尔的优势所在。在本次活动现场与英特尔高层的交流中，我们也听到了类似的观点。</p><p></p><p>训练并非生成式AI的全部，我们可以看到，英特尔正试图在AI工作流的各个环节全面发力，从训练到Fine-tuning，再到部署和推理，英特尔都有软硬件层面对应的产品和技术布局。这些布局能否帮助英特尔在生成式AI浪潮下继续取得成功，归根结底还是在于其能否很好地匹配客户需求、给客户带来足够的商业价值，这也是英特尔当前仍然面临的挑战，让我们一起拭目以待。</p>",
    "publish_time": "2023-09-20 09:33:54",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Java 近期新闻：Spring AI, Spring Modulith 1.0, Testcontainers桌面版",
    "url": "https://www.infoq.cn/article/Z9COLI6mFFhjJGskgUrS",
    "summary": "<p></p><h4>OpenJDK</h4><p></p><p>Oracle 的 Loom 项目架构师兼技术负责人 <a href=\"https://inside.java/u/RonPressler/\">Ron Pressler</a>\" <a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-August/008061.html\">提出</a>\"了 JEP 草案 8307341，《<a href=\"https://openjdk.org/jeps/8307341\">准备限制 JNI 的使用</a>\"》，提议限制使用本质上不安全的 Java 本地接口（JNI）及外部函数与内存（FFM） API 中的受限方法，后者预计于 JDK 22 中成为最终功能。从 JDK 22 开始，除非 FFM 用户在命令行中启用了不安全的本地访问，这项策略将使 Java 运行时显示使用 JNI 的相关警告。预计在 JDK 22 之后的版本中， JNI 的使用将导致异常抛出而非警告。</p><p>&nbsp;</p><p>JDK 回归测试工具 jtreg 的版本 7.3.1 已<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-August/008060.html\">发布</a>\"并准备集成至 JDK 中， 修复了 jtreg</p><p>版本 7.3 中会导致无法在 Windows 上正确设置默认环境变量的回归问题。关于该版本的更多详情，请参见<a href=\"https://github.com/openjdk/jtreg/blob/master/CHANGELOG.md\">发表说明</a>\"。</p><p></p><h4>JDK 21</h4><p></p><p><a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-21%2B35\">Build 35</a>\"&nbsp;仍是 JDK 21 <a href=\"https://jdk.java.net/20/\">早期访问构建</a>\"的当前版本。关于该版本的更多详情，请参见<a href=\"https://jdk.java.net/21/release-notes\">发布说明</a>\"。</p><p></p><h4>JDK 22</h4><p></p><p>JDK 22 <a href=\"https://jdk.java.net/22/\">早期访问构建</a>\" 的 <a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-22%2B12\">Build 12</a>\"&nbsp;也已于上周发布，主要提供对 Build 11 的<a href=\"https://github.com/openjdk/jdk/compare/jdk-22%2B11...jdk-22%2B12\">更新</a>\"及多项<a href=\"https://bugs.openjdk.org/issues/?jql=project%20%3D%20JDK%20AND%20fixversion%20%3D%2022%20and%20%22resolved%20in%20build%22%20%3D%20b12%20order%20by%20component%2C%20subcomponent\">问题</a>\"的修复。关于该版本的更多详情，请参见<a href=\"https://jdk.java.net/22/release-notes\">发布说明</a>\"。</p><p>&nbsp;</p><p>鼓励开发者们将 <a href=\"https://openjdk.org/projects/jdk/22/\">JDK 22</a>\"&nbsp;及&nbsp;<a href=\"https://openjdk.java.net/projects/jdk/21/\">JDK 21</a>\" 中的问题反馈至 <a href=\"https://bugreport.java.com/bugreport/\">Java Bug 数据库</a>\"。</p><p></p><h4>Jakarta EE</h4><p></p><p>Eclipse 基金会的 Jakarta EE 开发倡导者 <a href=\"https://se.linkedin.com/in/ivargrimstad\">Ivar Grimstad</a>\" 在每周的 Hashtag Jakarta EE&nbsp;<a href=\"https://www.agilejava.eu/\">博客</a>\"中给出了添加&nbsp;<a href=\"https://jakarta.ee/specifications/data/\">Jakarta Data</a>\"、<a href=\"https://jakarta.ee/specifications/mvc/\">Jakarta MVC</a>\"&nbsp;及 <a href=\"https://jakarta.ee/specifications/nosql/\">Jakarta NoSQL</a>\"规范至 Jakarta EE 11 平台的<a href=\"https://www.agilejava.eu/2023/08/20/hashtag-jakarta-ee-190/\">投票结果</a>\"：只有 Jakarta Data 这一项规范通过。</p><p>&nbsp;</p><p>对引入 Jakarta MVC 决定投反对票或弃权的部分评论如下：</p><p>&nbsp;</p><p></p><blockquote>这项规范成熟且目前已有人采用，但在强制使用前还应有更多供应商侧的采用。正如其他人所说的，这项规范可以被独立添加到任何配置文件中，在不限制任何人的使用的同时，还能创造更多的需求从而被添加到未来版本中，或者是给下次的版本发布计划提供一个更新的理由。我鼓励这项工作并希望它能得到进一步发展，我期望见到它最终被平台采用的一天。我认为这是对平台的一项有趣补充，它已经被添加到 GlassGish 中并且还是开箱可用的。但我们也有一些顾虑，其中就有 Jakarta MVC 是基于 Jakarta REST，而 Jakarta EE 中目前的 MVC 框架是基于 Jakarta Servlet 这一事实。以 REST 为基础的新 API 则又让事情更加混乱，毕竟 Jakarta EE 的核心就是“HTTP 处理 API”。我们希望 Jakarta Servlet 和 Jakarta REST 之间能先搭建一个共同基础，再将任何构建于 Jakarta REST 的东西接入平台。</blockquote><p></p><p>&nbsp;</p><p>对引入 Jakarta NoSQL 决定投反对票或弃权的部分评论如下：</p><p>&nbsp;</p><p></p><blockquote>目前的架构设计相比 Jakarta 平台的发布计划似乎需要更为频繁的更新，这让将其暂时排除在平台内给出了有利的论据。另外一项要求则可能是要先将 Jakarta Data 和 Jakarta Config 引入。总体来说，支持 NoSQL 是个好主意，所以这个决定在未来可能会变化。这项规范很有用并且在不远的将来也应被引入，但不是现在，它在 EE 11 时间框架内的成熟度也不明确。与供应商的 API 或运行时相比，（NoSQL）没有实际的功能，甚至可能恰恰相反：不使用专属 API 就没法使用 NoSQL 后端，在我看来这和目标南辕北辙。唯一的好处是它能在10到15行代码内完成，所以我觉得这不能让维护的负担名正言顺。</blockquote><p></p><p>&nbsp;</p><p></p><h4>BellSoft</h4><p></p><p>BellSoft 已为 Liberica JDK 17 及 OpenJDK 11 的下游发行版本提供了<a href=\"https://bell-sw.com/blog/invalid-cen-header-fixed-in-the-latest-jdk-11-and-17-updates/\">补丁发布</a>\"，其中包括对 JDK-8313765“<a href=\"https://bugs.openjdk.org/browse/JDK-8313765\">无效 CEN 头（无效 zip64 额外数据字段大小）</a>\"”这一关键问题修复，该回归问题中通过多个三方工具打开 APK、ZIP 或 JAR 文件会导致 ZipException 抛出。这一问题在 JDK-8302483“<a href=\"https://bugs.openjdk.org/browse/JDK-8302483\">改善 ZIP64 额外字段验证</a>\"”中出现，在打开 ZIP 文件时需要对 ZIP64 额外字段提供附加验证。</p><p>&nbsp;</p><p>BellSoft 同样<a href=\"https://bell-sw.com/blog/bellsoft-releases-alpaquita-containers-for-spring-boot-applications/\">推出</a>\"了基于 <a href=\"https://bell-sw.com/alpaquita-linux/\">Alpaquita Linux</a>\"且<a href=\"https://bell-sw.com/alpaquita-containers-for-spring-boot-apps/\">专为 Spring Boot 应用程序设计的 Alpaquita 容器</a>\"，前者是一款为 Java 编程语言和 <a href=\"https://bell-sw.com/libericajdk/\">Liberica JDK</a>\" 量身定做、以 <a href=\"https://www.alpinelinux.org/\">Alpine Linux</a>\" 为基础的操作系统。Alpaquita 容器于2022年9月首次<a href=\"https://bell-sw.com/blog/bellsoft-introduces-alpaquita-linux/\">推出</a>\"，其灵感来源是带有 Spring Boot 应用程序的小型容器可节省云资源这一<a href=\"https://bell-sw.com/blog/spring-container-size-why-it-is-important/\">发现</a>\"。</p><p></p><h4>Spring 框架</h4><p></p><p><a href=\"https://spring.io/projects/spring-boot\">Spring Boot</a>\"&nbsp;3.2.0 的<a href=\"https://spring.io/blog/2023/08/24/spring-boot-3-2-0-m2-available-now\">第二里程碑版本的发布</a>\"提供问题修复、文档优化，依赖升级以及新功能，其中包括：使用 jOOQ 功能判断 SQL 方言；替换已弃用的 TaskSchedulerBuilder类的新增&nbsp;ThreadPoolTaskSchedulerBuilder&nbsp;类；新增&nbsp;SimpleAsyncTaskExecutorBuilder&nbsp;类用于构建&nbsp;SimpleAsyncTaskExecutor&nbsp;类的实例。关于该版本的更多详情，请参见<a href=\"https://github.com/spring-projects/spring-boot/releases/tag/v3.2.0-M2\">发布说明</a>\"。</p><p>&nbsp;</p><p>Spring Boot 的 <a href=\"https://spring.io/blog/2023/08/24/spring-boot-3-1-3-available-now\">3.1.3</a>\"、<a href=\"https://spring.io/blog/2023/08/24/spring-boot-3-0-10-available-now\">3.0.10</a>\"&nbsp;及&nbsp;<a href=\"https://spring.io/blog/2023/08/24/spring-boot-2-7-15-available-now\">2.7.15</a>\"&nbsp;版本，均提供文档优化、依赖升级及重要问题修复，其中包括：记录检测到的非 XML 格式且带有查询参数的配置 URL；JobLauncherApplicationRunner 类的一个实例即使未执行任何任务也会返回成功退出码；添加 RabbitMQ <a href=\"https://docs.vmware.com/en/VMware-RabbitMQ-for-Tanzu-Application-Service/2.2/tanzu-rmq/GUID-smoke-tests.html\">冒烟测试</a>\"所缺的一个测试。关于这些版本的更多详情，请参见<a href=\"https://github.com/spring-projects/spring-boot/releases/tag/v3.1.3\">3.1.3 版本</a>\"、<a href=\"https://github.com/spring-projects/spring-boot/releases/tag/v3.0.10\">3.0.10 版本</a>\"及<a href=\"https://github.com/spring-projects/spring-boot/releases/tag/v2.7.15\">2.7.15 版本</a>\"的发布说明。</p><p>&nbsp;</p><p><a href=\"https://spring.io/projects/spring-modulith\">Spring Modulith</a>\" 1.0 版本 <a href=\"https://spring.io/blog/2023/08/21/spring-modulith-1-0-ga-released\">发布</a>\"，主要提供：移除 Scenario 类的实验性声明；移除 BOM 中 Spring Modulith Events 的父 POM；升级至 Spring Asciidoctor Backends 0.0.7 版本及 jMolecules 2023.1.0 版本。关于该版本的更多详情，请参见<a href=\"https://github.com/spring-projects/spring-modulith/releases/tag/1.0.0\">发布说明</a>\"。InfoQ 将跟进更为详细的报道。</p><p>&nbsp;</p><p><a href=\"https://spring.io/projects/spring-authorization-server\">Spring 授权服务器</a>\"&nbsp;1.1.2 版本<a href=\"https://spring.io/blog/2023/08/22/spring-authorization-server-1-1-2-available-now\">发布</a>\"，提供依赖升级及重要问题修复，其中包括：新增长度验证以避免无效 usercode 导致的 HTTP 500 内部服务器错误；示例测试套组 demo-authorizationserver 未能在构建流程中被一并执行；自定义表单登录类 DefaultErrorController 在抛出 NullPointerException 时缺失错误信息属性。关于该版本的更多详情，请参见<a href=\"https://github.com/spring-projects/spring-authorization-server/releases/tag/1.1.2\">发布说明</a>\"。</p><p>&nbsp;</p><p><a href=\"https://spring.io/projects/spring-batch\">Spring Batch</a>\"&nbsp;的 5.1.0-M2、5.0.3 及 4.3.9 版本现已<a href=\"https://spring.io/blog/2023/08/24/spring-batch-5-1-0-m2-5-0-3-and-4-3-9-available-now\">发布</a>\"，提供问题修复、文档优化及功能增强：在 Jackson2ExecutionContextStringSerializer 类的可信列表中新增 Java 的 ConcurrentHashMap 及 Date类；替换 mock() 方法中的 mock(Class classToMock) 方法以实现自动检测需要模拟的类或接口。5.1.0-M2 版本中新增功能包括：支持批量插入，MongoItemWriter 类中新增访问器，以便于扩展。关于这些版本的更多详情，请参见&nbsp;<a href=\"https://github.com/spring-projects/spring-batch/releases/tag/v5.1.0-M2\">5.1.0-M2 版本</a>\"、<a href=\"https://github.com/spring-projects/spring-batch/releases/tag/v5.0.3\">5.0.3 版本</a>\"及 <a href=\"https://github.com/spring-projects/spring-batch/releases/tag/4.3.9\">4.3.9 版本</a>\"的发布说明。</p><p>&nbsp;</p><p>于上周 SpringOne 大会中<a href=\"https://springone.io/sessions/intelligent-beans-with-spring-ai\">推出</a>\"的 <a href=\"https://github.com/spring-projects-experimental/spring-ai/blob/main/README.md\">Spring AI</a>\"，据称是“用于开发 AI 应用程序的 Spring 友好 API 和抽象”，开发者们可通过这段由 VMware 公司 Spring 开发倡导者 <a href=\"https://www.linkedin.com/in/joshlong/\">Josh Long</a>\" 及 高级资深工程师 <a href=\"https://www.linkedin.com/in/marklpollack/\">Mark Pollack</a>\" 带来的油管<a href=\"https://www.youtube.com/watch?v=0P8UU5vkvI8\">视频</a>\"，或是 <a href=\"https://twitter.com/asirselvasingh/status/1694435497010192502\">ACME 健身商城</a>\"应用程序了解更多详情。InfoQ 将跟进更为详细的新闻报道。</p><p></p><h4>AtomicJar</h4><p></p><p>“为数据库、消息代理、网络浏览器或任何可运行于 Docker 容器内的东西提供可抛式轻量级实例的开源框架”的 <a href=\"https://testcontainers.com/\">Testcontainers</a>\" 的制造商 <a href=\"https://www.atomicjar.com/\">AtomicJar</a>\"，<a href=\"https://www.atomicjar.com/2023/08/announcing-testcontainers-desktop-free-application/\">推出</a>\"了全新&nbsp;<a href=\"https://testcontainers.com/desktop/\">Testcontainers 桌面版</a>\"应用程序，面向 Java 社区免费使用。该版本所提供的功能包括：允许开发人员设置固定端口，以提升调试体验，连接至运行中容器，并可冻结容器避免其在调试过程中关闭。该应用还允许开发者轻松切换本地容器运行时，避免在通过 OrbStack、Colima、Rancher Desktop 或 Podman 运行 Testcontainers 时再操作 testcontainers.properties 文件。InfoQ 将跟进更为详细的新闻报道。</p><p>&nbsp;</p><p><a href=\"https://github.com/testcontainers/testcontainers-java/blob/main/README.md\">Testcontainers for Java</a>\"&nbsp;1.19.0 版本同样于上周<a href=\"https://github.com/testcontainers/testcontainers-java/releases/tag/1.19.0\">发布</a>\"，提供重大变更，其中包括：Wait 类中新增 forListeningPort(port) 方法便于检查特定端口；默认使用 SelinuxContext.SHARED 枚举； 新增 ClickHouseContainer 类实现，支持 withUsername()、withPassword()、withDatabaseName()&nbsp;及 withUrlParam() 方法。</p><p></p><h4>Open Liberty</h4><p></p><p>IBM 已<a href=\"https://openliberty.io/blog/2023/08/22/23.0.0.8.html\">发布</a>\"<a href=\"https://openliberty.io/\">Open Liberty</a>\"&nbsp;23.0.0.8 版本，主要提供：支持 OpenID Connect 客户端<a href=\"https://datatracker.ietf.org/doc/html/rfc7636\">保护授权代码授权</a>\"（PKCE），可用于避免授权码拦截攻击；修复 <a href=\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-38737\">CVE-2023-38737</a>\" 漏洞，该漏洞可导致攻击者向 Open Liberty 22.0.0.13 版本至 23.0.0.7 版本发送特制请求，导致服务器占用内存资源从而导致拒绝服务；确保 featureUtility installFeature  命令执行后会安装足够数量的功能，该命令在更新前无法保证正常工作。</p><p></p><h4>Quarkus</h4><p></p><p>红帽<a href=\"https://quarkus.io/blog/quarkus-3-3-0-released/\">发布</a>\"了 <a href=\"https://quarkus.io/\">Quarkus</a>\"&nbsp;的 3.3.0 版本，提供重要变更，其中包括：优化 <a href=\"https://quarkus.io/extensions/io.quarkus/quarkus-opentelemetry\">OpenTelemetry</a>\" 扩展；新增&nbsp;<a href=\"https://quarkus.io/extensions/io.quarkus/quarkus-smallrye-reactive-messaging-pulsar\">SmallRye Reactive Messaging Pulsar</a>\"&nbsp;扩展；可在&nbsp;<a href=\"https://quarkus.io/guides/rest-client-reactive\">REST Client Reactive</a>\" 扩展中自定义 Jackson ObjectMapper 类的功能。值得注意的是，从这一版本开始，版本名称中的 .Final 后缀将被移除，这种版本控制方式已经过时。关于该版本的更多详情，请参见<a href=\"https://github.com/quarkusio/quarkus/releases/tag/3.3.0\">发布说明</a>\"。</p><p></p><h4>MicroProfile</h4><p></p><p>在前往 MicroProfile 6.1 版本的路上，MicroProfile 工作组交付了 <a href=\"https://github.com/eclipse/microprofile-metrics/blob/main/README.adoc\">MicroProfile Metrics</a>\"&nbsp;5.1规范的<a href=\"https://github.com/eclipse/microprofile-metrics/releases/tag/5.1.0-RC1\">首个发布版本候选</a>\"，提供的重要变更包括：引入 MicroProfile 配置属性，可自定义直方图和定时器指标追踪和输出的百分比、直方图桶的统计数据；@RegistryScope 注解变更为 Qualifier；新增 mp.metrics.defaultAppName 属性用于要求标签组的统一，这一问题曾在多应用程序服务器实现中造成问题。关于该版本的更多详情，请参见<a href=\"https://download.eclipse.org/microprofile/microprofile-metrics-5.1.0-RC1/microprofile-metrics-spec-5.1.0-RC1.html#release_notes_5_1\">发布说明</a>\"。</p><p>&nbsp;</p><p>同样，<a href=\"https://github.com/eclipse/microprofile-telemetry/blob/main/README.adoc\">MicroProfile Telemetry</a>\"&nbsp;1.1 规范的<a href=\"https://github.com/eclipse/microprofile-telemetry/releases/tag/1.1-RC2\">第二发布版本候选</a>\"也已发布，提供对 <a href=\"https://opentelemetry.io/docs/instrumentation/java/\">OpenTelemetry Java</a>\"&nbsp;1.29.0 版本的依赖升级；明确 Span&nbsp;和 Baggage bean 在当前 span 或 baggage 变更时的行为；不依赖时间戳的测试实现。关于该版本的更多详情，请参见<a href=\"https://download.eclipse.org/microprofile/microprofile-telemetry-1.1-RC2/tracing/microprofile-telemetry-tracing-spec-1.1-RC2.html#_release_notes\">发布说明</a>\"。</p><p></p><h4>Micronaut</h4><p></p><p>Micronaut 基金会已交付 <a href=\"https://micronaut.io/\">Micronaut 框架</a>\"的<a href=\"https://micronaut.io/2023/08/24/micronaut-framework-4-0-5-released/\">第五维护版本</a>\"&nbsp;4.0.5，提供模块更新如下：<a href=\"https://micronaut-projects.github.io/micronaut-cassandra/latest/guide/\">Micronaut Cassandra</a>\"、<a href=\"https://micronaut-projects.github.io/micronaut-microstream/latest/guide/\">Micronaut MicroStream</a>\"、<a href=\"https://micronaut-projects.github.io/micronaut-security/latest/guide/\">Micronaut Security</a>\"、<a href=\"https://micronaut-projects.github.io/micronaut-liquibase/latest/guide/\">Micronaut Liquibase</a>\"、<a href=\"https://micronaut-projects.github.io/micronaut-flyway/latest/guide/\">Micronaut Flyway</a>\"、<a href=\"https://micronaut-projects.github.io/micronaut-gcp/latest/guide/\">Micronaut GCP</a>\"、<a href=\"https://micronaut-projects.github.io/micronaut-aws/latest/guide/\">Micronaut AWS</a>\"&nbsp;以及 <a href=\"https://micronaut-projects.github.io/micronaut-servlet/latest/guide/\">Micronaut Servlet</a>\"。关于该版本的更多详情，请参见<a href=\"https://github.com/micronaut-projects/micronaut-platform/releases/tag/v4.0.5\">发布说明</a>\"。</p><p>&nbsp;</p><p>用于 <a href=\"https://www.jhipster.tech/\">JHipster</a>\"&nbsp;的 <a href=\"https://github.com/jhipster/generator-jhipster-micronaut\">Micronaut Blueprint</a>\"&nbsp;2.0.0 版本也于上周<a href=\"https://micronaut.io/2023/08/24/micronaut-jhipster-2-0-0/\">发布</a>\"。基于 JHipster 最新稳定版本7.9.3 版本，该蓝图可为单体或微服务形式 JHipster 应用程序生成基于 Micronaut 框架 3.10.1 版本的后端服务器。</p><p></p><h4>阿帕奇软件基金会</h4><p></p><p><a href=\"https://groovy-lang.org/\">阿帕奇 Groovy</a>\"&nbsp;5.0.0 版本的<a href=\"https://www.mail-archive.com/announce@apache.org/msg08440.html\">首个 alpha 发布</a>\"提供众多问题修复、依赖升级、优化及新功能，其中包括：DefaultGroovyMethods 类中新方法 asChecked() ，用于优化对 checkedCollection()、checkedList()、checkedMap() 等 Java Collections 类中的支持；新增 @OperatorRename 注解，用于优化 AST 转换； 增加对 JEP 445，<a href=\"https://openjdk.org/jeps/445\">未命名类和实例 main 方法（预览版）</a>\"的初始支持。关于该版本的更多详情，请参见<a href=\"https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12318123&amp;version=12351227\">发布说明</a>\"。</p><p>&nbsp;</p><p>阿帕奇 Groovy <a href=\"https://www.mail-archive.com/announce@apache.org/msg08435.html\">4.0.14</a>\"&nbsp;及 <a href=\"https://www.mail-archive.com/announce@apache.org/msg08436.html\">3.0.19</a>\" 版本同样提供问题修复、依赖升级及优化，其中包括：DefaultGroovyMethods 类中定义的 collectEntries() 方法支持空参数；支持静态类型检查时元组闭包参数类型推断。关于该版本的更多详情，请参见&nbsp;<a href=\"https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12318123&amp;version=12353386\">4.0.14 版本</a>\"及 <a href=\"https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12318123&amp;version=12353387\">3.0.19 版本</a>\"的发布说明。</p><p>&nbsp;</p><p>最后，阿帕奇 Groovy 2.5.23版本的<a href=\"https://www.mail-archive.com/announce@apache.org/msg08437.html\">发布</a>\"，提供两处问题修复：优化 Closure 类中变量解析的行为；执行 Groovy 脚本时抛出 NoSuchMethodError。关于该版本的更多详情，请参见<a href=\"https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12318123&amp;version=12353077\">发布说明</a>\"。</p><p>&nbsp;</p><p><a href=\"https://tomcat.apache.org/\">阿帕奇 Tomcat</a>\"的&nbsp;<a href=\"https://www.mail-archive.com/announce@apache.org/msg08449.html\">11.0.0-M11</a>\"、<a href=\"https://www.mail-archive.com/announce@apache.org/msg08451.html\">10.1.13</a>\"、<a href=\"https://www.mail-archive.com/announce@apache.org/msg08450.html\">9.0.80</a>\"&nbsp;及 <a href=\"https://www.mail-archive.com/announce@apache.org/msg08453.html\">8.5.93</a>\"版本于上周发布，四个版本均提供重要变更，其中包括：修复阿帕奇 Tomcat 的表单验证功能导致 URL 重定向至不受信任网站的 <a href=\"https://nvd.nist.gov/vuln/detail/CVE-2023-41080\">CVE-2023-41080</a>\" 漏洞；应用程序或库同时设置了非 HTTP 500 内部服务器错误码及 jakarta.servlet.error.exception 请求属性时，在处理错误页面时不会再使用默认 HTTP 500，而使用程序提供的错误码。11.0.0-M11 版本同样包含对 HTTP 参数处理的更新，以与 <a href=\"https://jakarta.ee/specifications/servlet/6.1/\">Jakarta Servlet 6.1</a>\" API 的 ServletRequest 接口方法定义变更保持一致。关于这些版本的更多详情，请参见&nbsp;<a href=\"http://tomcat.apache.org/tomcat-11.0-doc/changelog.html\">11.0.0-M11 版本</a>\"、<a href=\"http://tomcat.apache.org/tomcat-10.1-doc/changelog.html\">10.1.13 版本</a>\"、<a href=\"https://tomcat.apache.org/tomcat-9.0-doc/changelog.html\">9.0.80 版本</a>\"及<a href=\"https://tomcat.apache.org/tomcat-8.5-doc/changelog.html\">8.5.93 版本</a>\"的发布说明。</p><p></p><h4>Grails</h4><p></p><p>Grails 基金会<a href=\"https://grails.org/blog/2023-08-25-introducing-grails-spring-security-core-6.html\">推出</a>\"了 <a href=\"https://github.com/grails/grails-spring-security-core/blob/6.0.x/README.md\">Grails Spring Security Core 插件</a>\"的 6.0.0 版本，该版本具有更高安全性、支持 Spring Security 5.8.6 版本、 Grails 6.0.0 版本兼容、优化了命令行界面、升级依赖关系，并改进了文档导航。</p><p></p><h4>JHipster</h4><p></p><p><a href=\"https://www.jhipster.tech/jhipster-lite/\">JHipster Lite</a>\" 的&nbsp;<a href=\"https://twitter.com/pascalgrimaud/status/1693565243396325500\">0.41.0</a>\"&nbsp;版本已经发布，主要提供问题修复、依赖升级及优化，其中包括：使用 JHipster&nbsp;的@ExcludeFromGeneratedCodeCoverage 注解替换 Java 的 @Generated 注解；移除 OAuth2Configuration 类中的 password() 方法；使用应用程序配置文件中的配置项执行集成测试。关于该版本的更多详情，请参见<a href=\"https://github.com/jhipster/jhipster-lite/releases/tag/v0.41.0\">发布说明</a>\"。</p><p></p><h4>Eclipse Vert.x</h4><p></p><p>Eclipse Vert.x 团队已为用于分析工作负载的实时分布式数据存储，<a href=\"https://docs.pinot.apache.org/users/clients/java\">阿帕奇 Pinot Java 客户端</a>\"<a href=\"https://vertx.io/blog/soc-vertx-pinot-client/\">推出</a>\"了全新的 <a href=\"https://github.com/reactiverse/pinot-client/blob/main/README.md\">Pinot 客户端</a>\"。这一新客户端可为 Eclipse Vert.x 应用程序查询阿帕奇 Pinot 服务器提供便利的 API。</p><p></p><h4>Yupiik</h4><p></p><p><a href=\"https://www.yupiik.io/fusion/\">Yupiik Fusion</a>\" 的 1.0.6 版本现已<a href=\"https://www.yupiik.io/blog/release-yupiik-fusion-1.0.6.html\">发布</a>\"，提供重要变更，其中包括：支持超过 255 行的嵌套式表格；可在 PartialResponse 类中自定义 JsonRpcHandler 类的 RESPONSE_HEADERS 字段；支持OffsetDateTime、ZoneOffset&nbsp;及 <a href=\"https://download.java.net/java/early_access/jdk21/docs/api/java.base/java/time/LocalDate.html\">LocalDate</a>\" 作为JSON-RPC端点的根参数。关于该版本的更多信息，请参见<a href=\"https://github.com/yupiik/fusion/releases/tag/fusion-1.0.6\">发布说明</a>\"。</p><p></p><h4>SpringOne</h4><p></p><p><a href=\"https://springone.io/\">SpringOne</a>\"&nbsp;及 VMware Explore 大会上周于内华达州拉斯维加斯的威尼斯人会展中心举行，<a href=\"https://springone.io/sessions\">大会</a>\"内容受众为应用程序开发人员、平台操作员、DevOps、SRE 及应用程序架构师。涉及的 Spring 技术包括：Spring 应用程序的平台及工具、Spring 框架、Spring Boot、Spring Security、Spring Cloud、Spring Data/Stream 以及 Spring 社区。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/08/java-news-roundup-aug21-2023/\">Java News Roundup: Introducing Spring AI, Spring Modulith 1.0, Testcontainers Desktop</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/QB87kOkWjf6jXxODkd9T\">Java 21：最新进展一览</a>\"</p><p><a href=\"https://www.infoq.cn/article/wti8XjbwvZdWSr79kOc6\">Java 近期新闻：单查询加载、GraalVM、GlassFish、JReleaser、Quarkus、Micronaut</a>\"</p>",
    "publish_time": "2023-09-20 09:59:28",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "平安人寿科技总监魏政刚确认出席 FCon ，分享 AIGC 及大模型在保险销售领域的应用",
    "url": "https://www.infoq.cn/article/jglWMMBydt4xsU4XYE7L",
    "summary": "<p><a href=\"https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle\">FCon 全球金融科技大会</a>\"，将于 11 月在上海召开。平安人寿科技总监魏政刚将发表题为《<a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5528?utm_source=infoqweb&amp;utm_medium=article\">AIGC 及大模型在保险销售领域的应用</a>\"》主题分享，介绍人工智能在金融行业里应用实践，AIGC、大模型技术落地中面临的挑战、举措及经验教训以及保险知识体系的构造。</p><p></p><p><a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5528?utm_source=infoqweb&amp;utm_medium=article\">魏政刚</a>\"，数字时代的思考者和践行者，热衷于通过数字化转型与创新，发掘内、外部业务机会，在企业发展的不同阶 段，创新、赋能企业可持续性发展。擅长团队组建、管理咨询、信息化规划、数字化战略与运营、解决方案 设计、以及数字科技（人工智能、大数据、云计算、交互、分析等）与商业价值的优化整合。在二十多年的职业生涯中，在全球范围内服务过金融、生产制造、医疗健康、生命科学、信息通信技术（ICT）、消费品、 自然资源、物流配送等行业。他在本次会议的演讲内容如下：</p><p></p><p>演讲：AIGC 及大模型在保险销售领域的应用</p><p></p><p>把握科技进步趋势，深入探索人工智能的行业应用，对 AIGC 及大模型在保险全价值链所起到的作用前瞻性的精准把握，形成了以智能拜访助手、AI 云面试、AI 跟拍、AI 画报、AI 形象制作、平安体验中心等一系列 AI 产品为基础的产品矩阵，有力赋能一线销售队伍，匹配保险客户需求，不断向价值最大化进步。</p><p></p><p>演讲提纲：</p><p></p><p>AIGC 及大模型与销售技术、保险知识的结合文字、图像、视频的转换数字人及代理人个人 IP 的打造在合规上的应用</p><p></p><p>你将获得：</p><p></p><p>○ 人工智能在金融行业里应用实践</p><p>○ AIGC、大模型技术落地中面临的挑战、举措及经验教训</p><p>○ 保险知识体系的构造等</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle\">DevOps&nbsp;在金融企业落地实践</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle\">金融行业大模型应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle\">创新的金融科技应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle\">金融实时数据平台建设之路</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle\">金融安全风险管控</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle\">数据要素流通与数据合规</a>\"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，前 100 人可享 5 折特惠购票，咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png\" /></p><p></p>",
    "publish_time": "2023-09-20 11:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "德邦基金CTO李鑫：中小金融机构数字化规划要聚焦重点、有所取舍",
    "url": "https://www.infoq.cn/article/Su6bfESLE0kA7g9waE7X",
    "summary": "<p>数字化转型是一个长期工程，其中充满各种阻力和不确定性，这如今已经是业界共识。但是，不同体量的企业在面对这一系列挑战时，其棘手程度并不相同。对<a href=\"https://www.infoq.cn/theme/200\">中小型企业</a>\"而言，由于可投入的人力、资金等资源有限，在做数字化规划时，不能直接照抄大型公司的“作业”。</p><p>&nbsp;</p><p>“大型公司由于资源更为充足，因此有更多的余量来进行全面、长远的规划。然而，中小型企业更倾向于看到短期的成效，数字化转型的重点会有所不同。在进行规划时，也需要更加聚焦。只有聚焦，才能用有限的资源更快地产生成效。”在&nbsp;9&nbsp;月&nbsp;14&nbsp;日的&nbsp;InfoQ《超级连麦·数智大脑》直播中，InfoQ&nbsp;与德邦基金CTO<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1576\">李鑫</a>\"深入探讨了中小金融机构数字化转型背后的思路和路径。</p><p>&nbsp;</p><p>李鑫介绍，德邦基金的数字化转型是一个长周期的规划，目的是通过拉长转型周期来稀释成本。在这个长期过程中，战略聚焦和持续性成为非常重要的两个方面，不仅要面对各种不确定性问题，还需要平衡成本、短期诉求、长期战略之间的矛盾。</p><p>&nbsp;</p><p>以下是对话全文（经&nbsp;InfoQ&nbsp;进行不改变原意的编辑整理）：</p><p></p><h5>InfoQ：您是如何理解数字化转型的？</h5><p></p><p></p><p>李鑫：在我看来，数字化转型的定义因行业而异。以金融企业为例，我认为数字化转型可以定义为：通过全面信息化来获取金融业务各个维度的过程数据及结果数据，并对这些数据进行联接、加工、汇总，从而在数字世界中构建金融业务的<a href=\"https://www.infoq.cn/article/N2gWCU0NhYWjmyxwwy2R\">数字孪生</a>\"，实现对金融业务的深刻洞察，进而辅助企业作出更优化的经营决策并落地，最终实现降本增效、并以极低成本规模化创设稳定绩优的金融产品，同时为客户提供更优质的服务。</p><p>&nbsp;</p><p>其中有几个关键词值得注意：首先是“全面信息化”，这是实现数字化转型的前提。只有通过全面信息化，企业才能收集到足够的数据进行后续分析和挖掘。</p><p>&nbsp;</p><p>其次是“数字孪生”，这个词最早来源于工业领域，这里指利用数据在虚拟数字世界中构建企业的一个全数字化投影模型。在这个轻量级的数字世界里，企业可以利用这个虚拟模型快速进行各种模拟、演化和分析，从而实现全面的自我洞察。</p><p>&nbsp;</p><p>基于这些洞察，企业能做出更优的决策，并对业务场景进行针对性的优化及创新。而业务场景的优化创新，必然涉及信息系统的改造，从而进一步推动信息化的升级，这样就形成了一个数字化转型的闭环体系。</p><p></p><h5>InfoQ：&nbsp;德邦基金作为一家中小金融企业，其数字化转型过程有什么差异化特点？有哪些需要注意的问题？</h5><p></p><p></p><p>李鑫：数字化转型是一个长期过程，其中充满了各种挑战和困难。因此，我们需要用长期的思维去看待这件事，同时也要保持聚焦。这个过程不仅是自上而下的，也是自下而上的。</p><p>&nbsp;</p><p>比如，在德邦基金的数字化转型规划中，我们是以十年为周期来进行规划的。由于我们是一家<a href=\"https://www.infoq.cn/article/1zd5MLr5iQOBzgAaGpOm\">中小型基金</a>\"公司，成本投入上无法与大公司相比。因此，我们会通过拉长转型周期来稀释成本。</p><p></p><p>在这个长周期中，战略聚焦和持续性成为非常重要的两个方面。我们不仅要面对各种问题和挑战，还需要平衡成本、短期诉求、长期战略之间的矛盾。</p><p>&nbsp;</p><p>对于大型公司，由于资源更为充足，因此他们有更多的余量来进行全面、长远的规划。然而，中小型公司由于成本限制，更倾向于看到短期的成效。因此，从中小公司和大公司的角度看，数字化转型的重点会有所不同。</p><p>&nbsp;</p><p>在进行规划时，中小型公司需要更加聚焦。因为只有聚焦，才能用有限的资源更快地产生成效，从而给公司一个阶段性的产出（交代）。这也涉及到技术资源和业务诉求的平衡，必须有所取舍。</p><p>&nbsp;</p><p>举例来说，现在基础资源的云化和服务化是一个主要的趋势，不同规模的公司在这方面有不同的做法。大型公司由于业务复杂，需求多样，会同时关注IaaS（基础设施即服务）层和PaaS（平台即服务）层的能力建设。而对于中小公司来说，如果走大公司的路线，所需的资金和技术投入会非常大，风险也会很高。</p><p></p><p>因此，我们更倾向于聚焦，例如重点关注IaaS这一层能力建设，而忽略PaaS这一层。同时，我们也会更倾向采购成熟、稳定、开箱即用的商用产品，而非自行从头搭建，从而缩短落地周期，降低总体建设成本。</p><p></p><h5>InfoQ：从底层来看，传统IT架构显然已经无法支撑全新的技术应用，德邦基金自身在技术架构层面遇到过哪些挑战？</h5><p></p><p></p><p>李鑫：技术的本质是为业务服务，随着业务的不断发展，原有的传统IT架构可能会逐渐显得不合时宜，也需要进行调整。</p><p>&nbsp;</p><p>数字化转型的核心是利用数字进行数字洞察和数字赋能，因此需要有足够多的充分覆盖各个业务领域的过程数据和结果数据，这也是前面所说的全面信息化的意义：通过足够多的信息系统来获取各类数据。而大量信息系统的存在，必然对企业的IT运维工作产生巨大的压力。因此，在整个数字化转型过程中，我们面临的首要挑战是如何保障大量信息系统的线上稳定运维的需求。</p><p>&nbsp;</p><p>回想早期，上线一个信息系统的时候，要采购独立的物理服务器，机房部署后再安装系统、部署各种中间件等，上线周期基本上以月为单位。这种效率完全无法满足现在业务发展及数字化转型的要求。所以，这几年基础资源云化的模式越来越普遍，金融企业目前越来越多的采用云服务，由于监管的要求，金融企业使用公有云的比例还是偏低，主要使用的是私有云或者行业云。在这个大背景下，我们也在朝云计算方向转型，打造我们自身的云运维技术体系。</p><p>&nbsp;</p><p>随着互联网基金销售业务的快速发展，用户量也在迅速增加。用户量的增加对直销系统的并发稳定性也提出了新的挑战，以往单体架构为主的销售系统已经不再适用，我们的在线销售系统也已经转向分布式架构。</p><p>&nbsp;</p><p>此外，由于数据量的增加，传统的关系型数据仓库已经难以为继。我们也引入分布式数据库来解决数据量快速膨胀的问题。</p><p></p><h5>InfoQ：有没有印象中特别深刻的挑战或困难？</h5><p></p><p></p><p>李鑫：数字化转型涉及大量数据的采集、存储、分析，需要有一个很好的数据底座来支撑。数据底座的核心是统一数仓，一个模型完善、治理良好的数仓，是进行数字化转型的关键所在，它对构建数字孪生至关重要，也是实现数字洞察和数字赋能的前提。数据底座的构建对我们这类非技术型的中小金融公司挑战还是非常大的。所以我们一开始采取的策略是\"借力\"，基于监管报送的需求，我们通过引入专业的技术供应商，构建了我们第一代的核心数仓，初步建立起完整的数据模型。在此基础上，我们建立了自己的数据服务和开发团队，通过消化吸收，将数仓运维能力和模型设计能力完全转化为我们自己的能力，并进一步将数仓升级为分布式架构，同时自行构建了数据网关和数据中台，从而完成了完全自我掌控的数据底座的建设。</p><p>&nbsp;</p><p>此外，从我个人的经验来看，金融企业在建立面向互联网C端的销售和营销应用时，也会面临严峻的挑战。互联网应用的特点是流量波动大，而根据金融监管要求，金融行业对于在线交易的用户身份、资金的合规性的检测必须非常严格，交易过程中涉及大量复杂繁琐的<a href=\"https://www.infoq.cn/article/ixcNvwClOzTSal48vR6k\">风控检测</a>\"及用户告知操作，异步处理这类常见的电商解决方案在金融场景中很难直接照搬使用，必须在合规性、易用性和资源投入之间找到一个平衡点。金融系统一旦出现故障，后果非常严重。因此，在方案选择上，考虑稳定性的同时，还需要考虑合规和监管方面的一系列要求，这对架构设计的挑战非常大。</p><p></p><h5>InfoQ：德邦基金在数字化转型方面，有哪些具体成果吗？</h5><p></p><p></p><p>李鑫：我们公司针对基金业务发展实施了一个“3+1”的数字化转型规划。“3”代表基金公司三大核心业务方面的数字化能力建设，它们分别是基金产品运营\"自动化\"，基金销售\"一体化\"，以及基金投研\"数智化\"，而“+1”则代表着IT自身的能力进化。</p><p>&nbsp;</p><p>基金产品运营\"自动化\"</p><p>&nbsp;</p><p>基金产品的运营是基金公司的基础业务，包括产品发行、审批、以及日常的估值清算和份额登记等环节，涉及的业务链条长、相关联的系统多、操作也很琐碎。在实际的数字化建设过程中，通过引入RPA等自动化技术，我们大幅降低了人工操作比例，提高了自动化程度，这不仅降低了人为操作的风险，还减少了劳动成本投入。实施后效果非常显著，单单RPA一项技术的引入，去年就为公司节省了一万多个小时的人力投入。</p><p>&nbsp;</p><p>基金销售\"一体化\"</p><p>&nbsp;</p><p>基金销售的一大特点是代销渠道众多，为了能够以大规模、低成本的方式进行营销，并且确保在不同渠道中用户能有统一的体验。就需要从公司视角出发，构建一体化的销售及营销平台，对外做统一的用户增长体系和客户画像体系，对内做统一的销售管理。正是基于这个理念，我们以CRM系统为核心，规划并逐步落地德邦基金销售业务一体化赋能平台，通过这套平台，我们对内解决销售管理问题；对外聚焦“对客管理”和“对客服务”，进而构建公司级的“用户增长体系”，实现一套平台，多端赋能。</p><p>&nbsp;</p><p>基金投研\"数智化\"</p><p>&nbsp;</p><p>在投资研究方面，为了让研究成果可衡量，过程可管理，我们打造了专业的投研一体化平台，通过系统化来提高投研效率，从而让研究工作更标准，更规范。同时引入大数据技术和AI技术以辅助研究人员开展研究工作，让其可以更高效地处理大量的市场、行情、舆情等数据，从而更快、更准确地把握市场行情和动态。系统化和数据智能化能力的打造不仅提高了投研的规范化和标准化，原来依赖个人单兵作战的投研方式通过系统和工具的赋能，也实现了向团队协同作战方式转变。</p><p></p><h5>InfoQ：德邦基金在数字化转型人才的培养上是如何考虑的？</h5><p></p><p></p><p>李鑫：数字化转型目前是一个热门话题，虽然大家都在讨论，相关案例也很多，但真正理解并能成功落地实施的企业和人才还是相对少数。同时，信息过多反而容易形成干扰，让企业难以筛选出贴合自身实际的参考方案。</p><p>&nbsp;</p><p>从我的个人经验看，成功的数字化转型需要两个方面的努力。首先，\"他山之石,可以攻玉\"，数字化转型是一个复杂的体系性工作，各行业都已经做了很多有益的探索。我们需要不断学习和借鉴同行业和跨行业的成功案例。不仅仅金融行业，工业制造和互联网行业在数字化转型方面也有比较丰富的实践经验，可以作为我们的有益参考。</p><p>&nbsp;</p><p>其次，理解业务是数字化转型的核心。如果你对企业业务不了解，那么进行的数字化转型规划将缺乏根基，难以有效地推动业务发展。</p><p>&nbsp;</p><p>综合来看，成功的数字化转型需要负责操盘的人员既有全面丰富的数字化方面的专业知识，又要深刻理解企业业务。只有这样，才能制定出切实有效的数字化转型规划，并在实施落地过程中不断纠偏，以保证大方向的正确。所以，在这两个方向加强人才培养在企业数字化转型中是至关重要的。</p><p></p><h5>InfoQ：在FCon大会《创新的金融科技应用》专题上，会邀请哪些重磅专家、围绕哪些话题进行分享？</h5><p></p><p>&nbsp;</p><p>李鑫：根据规划，我们主要聚焦几个关键领域。首先是人机协同的金融投研，特别是人工智能和数据挖掘在此领域的应用；其次是智能投顾和智能营销，包括精准营销和沉浸式社区构建；第三是通过科技辅助高质量的金融产品创新和优化产品运营。</p><p>&nbsp;</p><p>当然我们也关注全面的金融合规，包括数据合规、行为合规，以及前沿科技在金融安全和防洗钱方面的应用。此外，数据安全、隐私保护和可信的数字身份也是我们的关注重点。在新兴技术方面，我们正在探索Web&nbsp;3.0，以及区块链和NFT如何能助力金融创新的话题。</p><p></p><h4>关于 FCon</h4><p></p><p></p><p>首届<a href=\"https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">FCon全球金融科技大会</a>\"将于 11 月 19-20 日在上海举办。大会将围绕金融领域数字化转型挑战探索、DevOps 在金融企业落地实践、金融行业大模型应用、创新的金融科技应用、金融实时数据平台建设之路、金融安全风险管控、数据要素流通与数据合规等 10+专题进行交流。</p><p></p><p>目前大会邀请了汇丰科技中国区的代理总经理马国栋、度小满金融数据智能部总经理杨青先、蚂蚁集团副总裁 &amp; 首席技术安全官韦韬博士、恒生聚源总经理吴震操担任大会联席主席。更多嘉宾仍在邀请中......</p><p></p><p>我们诚挚地邀请您加入我们，共同探索金融科技的未来，<a href=\"https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">点击链接</a>\"即可查看全部演讲专题。</p><p></p><p>目前 <a href=\"https://fcon.infoq.cn/2023/shanghai/apply?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">5 折 优惠购票</a>\"，仅限前 100 人，咨询购票可联系：17310043226（微信同手机号）。</p>",
    "publish_time": "2023-09-20 13:56:32",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "2023-09-20：用go语言，保证一定是n*n的正方形，实现从里到外转圈打印的功能 如果n是奇数，中心点唯一，比如 a b c d e f g h i e是中心点，依次打印 : e f i h ...",
    "url": "https://www.infoq.cn/article/32dbb711f8386a57feaf5f200",
    "summary": "<p>2023-09-20：用go语言，保证一定是n*n的正方形，实现从里到外转圈打印的功能</p><p></p><p>如果n是奇数，中心点唯一，比如</p><p></p><p>a b c</p><p></p><p>d e f</p><p></p><p>g h i</p><p></p><p>e是中心点，依次打印 : e f i h g d a b c</p><p></p><p>如果n是偶数，中心点为最里层2*2的右下点</p><p></p><p>比如</p><p></p><p>a b c d e f</p><p></p><p>g h i j k l</p><p></p><p>m n o p q r</p><p></p><p>s t u v w x</p><p></p><p>y z 0 1 2 3</p><p></p><p>4 5 6 7 8 9</p><p></p><p>最里层是</p><p></p><p>o p</p><p></p><p>u v</p><p></p><p>v是中心点，依次打印 : v u o p q w ....</p><p></p><p>来自<a href=\"https://b23.tv/Zho7gh0\">左程云</a>\"。</p><p></p><p>答案2023-09-20：</p><p></p><h1>大体步骤如下：</h1><p></p><p>1.定义一个函数print，接收一个二维字节切片m作为参数。2.获取二维切片m的长度n。3.设置四个变量a, b, c, d为(n-1)/2, (n-1)/2, n/2, n/2，分别表示每一层的起始点和终止点。4.使用循环，从最外层到最内层逐层打印。4.a.在每一层中，调用函数loop打印当前层的内容。5.在循环结束后，打印换行符。</p><p></p><p>函数loop的过程如下：1.判断如果a和c相等，表示只有一个元素，直接打印该元素并返回。2.对于其他情况，依次打印当前层的四个边。2.a. 从起始点的下一行开始，按列打印边界元素，即从上到下。2.b. 从终止点的左侧列开始，按行打印边界元素，即从右到左。2.c. 从终止点的上一行开始，按列打印边界元素，即从下到上。2.d. 从起始点的右侧列开始，按行打印边界元素，即从左到右。</p><p></p><p>在主函数main中，定义了几个测试用例，分别为不同大小的二维字节切片m，然后调用print函数进行打印。</p><p></p><p>总的时间复杂度为O(n^2)，其中n为输入二维切片m的大小。</p><p></p><p>总的额外空间复杂度为O(1)，没有使用额外空间。</p><p></p><h1>go完整代码如下：</h1><p></p><p><code lang=\"go\">package main\n\nimport \"fmt\"\n\nfunc print(m [][]byte) {\n  n := len(m)\n  for a, b, c, d := (n-1)/2, (n-1)/2, n/2, n/2; a &gt;= 0; a, b, c, d = a-1, b-1, c+1, d+1 {\n    loop(m, a, b, c, d)\n  }\n  fmt.Println()\n}\n\nfunc loop(m [][]byte, a, b, c, d int) {\n  if a == c {\n    fmt.Printf(\"%c \", m[a][b])\n  } else {\n    for row := a + 1; row &lt;= c; row++ {\n      fmt.Printf(\"%c \", m[row][d])\n    }\n    for col := d - 1; col &gt;= b; col-- {\n      fmt.Printf(\"%c \", m[c][col])\n    }\n    for row := c - 1; row &gt;= a; row-- {\n      fmt.Printf(\"%c \", m[row][b])\n    }\n    for col := b + 1; col &lt;= d; col++ {\n      fmt.Printf(\"%c \", m[a][col])\n    }\n  }\n}\n\nfunc main() {\n  map1 := [][]byte{{'a'}}\n  print(map1)\n\n  map2 := [][]byte{{'a', 'b'}, {'c', 'd'}}\n  print(map2)\n\n  map3 := [][]byte{{'a', 'b', 'c'}, {'d', 'e', 'f'}, {'g', 'h', 'i'}}\n  print(map3)\n\n  map4 := [][]byte{{'a', 'b', 'c', 'd'}, {'e', 'f', 'g', 'h'}, {'i', 'j', 'k', 'l'}, {'m', 'n', 'o', 'p'}}\n  print(map4)\n\n  map5 := [][]byte{{'a', 'b', 'c', 'd', 'e'}, {'f', 'g', 'h', 'i', 'j'}, {'k', 'l', 'm', 'n', 'o'}, {'p', 'q', 'r', 's', 't'}, {'u', 'v', 'w', 'x', 'y'}}\n  print(map5)\n\n  map6 := [][]byte{{'a', 'b', 'c', 'd', 'e', 'f'}, {'g', 'h', 'i', 'j', 'k', 'l'}, {'m', 'n', 'o', 'p', 'q', 'r'}, {'s', 't', 'u', 'v', 'w', 'x'}, {'y', 'z', '0', '1', '2', '3'}, {'4', '5', '6', '7', '8', '9'}}\n  print(map6)\n}\n</code></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0f/0fa3602affd14f6d396706c646d8d4e1.png\" /></p><p></p><h1>rust完整代码如下：</h1><p></p><p><code lang=\"rust\">fn print(m: &amp;[Vec]) {\n    let n = m.len() as i32;\n    let mut a = (n - 1) / 2;\n    let mut b = (n - 1) / 2;\n    let mut c = n / 2;\n    let mut d = n / 2;\n    while a &gt;= 0 {\n        loop2(&amp;m, a, b, c, d);\n        a -= 1;\n        b -= 1;\n        c += 1;\n        d += 1;\n    }\n    println!();\n}\n\nfn loop2(m: &amp;[Vec], a: i32, b: i32, c: i32, d: i32) {\n    if a == c {\n        print!(\"{} \", m[a as usize][b as usize]);\n    } else {\n        for row in a + 1..=c {\n            print!(\"{} \", m[row as usize][d as usize]);\n        }\n        for col in (b..=d - 1).rev() {\n            print!(\"{} \", m[c as usize][col as usize]);\n        }\n        for row in (a..=c - 1).rev() {\n            print!(\"{} \", m[row as usize][b as usize]);\n        }\n        for col in b + 1..=d {\n            print!(\"{} \", m[a as usize][col as usize]);\n        }\n    }\n}\n\nfn main() {\n    let map1: Vec&gt; = vec![vec!['a']];\n    print(&amp;map1);\n\n    let map2: Vec&gt; = vec![vec!['a', 'b'], vec!['c', 'd']];\n    print(&amp;map2);\n\n    let map3: Vec&gt; = vec![\n        vec!['a', 'b', 'c'],\n        vec!['d', 'e', 'f'],\n        vec!['g', 'h', 'i'],\n    ];\n    print(&amp;map3);\n\n    let map4: Vec&gt; = vec![\n        vec!['a', 'b', 'c', 'd'],\n        vec!['e', 'f', 'g', 'h'],\n        vec!['i', 'j', 'k', 'l'],\n        vec!['m', 'n', 'o', 'p'],\n    ];\n    print(&amp;map4);\n\n    let map5: Vec&gt; = vec![\n        vec!['a', 'b', 'c', 'd', 'e'],\n        vec!['f', 'g', 'h', 'i', 'j'],\n        vec!['k', 'l', 'm', 'n', 'o'],\n        vec!['p', 'q', 'r', 's', 't'],\n        vec!['u', 'v', 'w', 'x', 'y'],\n    ];\n    print(&amp;map5);\n\n    let map6: Vec&gt; = vec![\n        vec!['a', 'b', 'c', 'd', 'e', 'f'],\n        vec!['g', 'h', 'i', 'j', 'k', 'l'],\n        vec!['m', 'n', 'o', 'p', 'q', 'r'],\n        vec!['s', 't', 'u', 'v', 'w', 'x'],\n        vec!['y', 'z', '0', '1', '2', '3'],\n        vec!['4', '5', '6', '7', '8', '9'],\n    ];\n    print(&amp;map6);\n}\n</code></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bb/bbf9b024dc29593bfed48b633034536e.png\" /></p><p></p><h1>c++完整代码如下：</h1><p></p><p><code lang=\"cpp\">#include\n#include\n\nusing namespace std;\n\nvoid loop(vector&gt; m, int a, int b, int c, int d);\n\nvoid print(vector&gt; m) {\n    int n = m.size();\n    for (int a = (n - 1) / 2, b = (n - 1) / 2, c = n / 2, d = n / 2; a &gt;= 0; a--, b--, c++, d++) {\n        loop(m, a, b, c, d);\n    }\n    cout &lt;&lt; endl;\n}\n\nvoid loop(vector&gt; m, int a, int b, int c, int d) {\n    if (a == c) {\n        cout &lt;&lt; m[a][b] &lt;&lt; \" \";\n    }\n    else {\n        for (int row = a + 1; row &lt;= c; row++) {\n            cout &lt;&lt; m[row][d] &lt;&lt; \" \";\n        }\n        for (int col = d - 1; col &gt;= b; col--) {\n            cout &lt;&lt; m[c][col] &lt;&lt; \" \";\n        }\n        for (int row = c - 1; row &gt;= a; row--) {\n            cout &lt;&lt; m[row][b] &lt;&lt; \" \";\n        }\n        for (int col = b + 1; col &lt;= d; col++) {\n            cout &lt;&lt; m[a][col] &lt;&lt; \" \";\n        }\n    }\n}\n\nint main() {\n    vector&gt; map1 = { {'a'} };\n    print(map1);\n\n    vector&gt; map2 = { {'a', 'b'}, {'c', 'd'} };\n    print(map2);\n\n    vector&gt; map3 = { {'a', 'b', 'c'}, {'d', 'e', 'f'}, {'g', 'h', 'i'} };\n    print(map3);\n\n    vector&gt; map4 = { {'a', 'b', 'c', 'd'}, {'e', 'f', 'g', 'h'}, {'i', 'j', 'k', 'l'}, {'m', 'n', 'o', 'p'} };\n    print(map4);\n\n    vector&gt; map5 = { {'a', 'b', 'c', 'd', 'e'},\n                                 {'f', 'g', 'h', 'i', 'j'},\n                                 {'k', 'l', 'm', 'n', 'o'},\n                                 {'p', 'q', 'r', 's', 't'},\n                                 {'u', 'v', 'w', 'x', 'y'} };\n    print(map5);\n\n    vector&gt; map6 = { {'a', 'b', 'c', 'd', 'e', 'f'},\n                                 {'g', 'h', 'i', 'j', 'k', 'l'},\n                                 {'m', 'n', 'o', 'p', 'q', 'r'},\n                                 {'s', 't', 'u', 'v', 'w', 'x'},\n                                 {'y', 'z', '0', '1', '2', '3'},\n                                 {'4', '5', '6', '7', '8', '9'} };\n    print(map6);\n\n    return 0;\n}\n</code></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/62/62f820532e31f163fbd3700c9e620359.png\" /></p><p></p><h1>c完整代码如下：</h1><p></p><p><code lang=\"c\">#include \n\n\nvoid loop(char** m, int a, int b, int c, int d);\n\nvoid print(char** m, int n) {\n    for (int a = (n - 1) / 2, b = (n - 1) / 2, c = n / 2, d = n / 2; a &gt;= 0; a--, b--, c++, d++) {\n        loop(m, a, b, c, d);\n    }\n    printf(\"\\n\");\n}\n\nvoid loop(char** m, int a, int b, int c, int d) {\n    if (a == c) {\n        printf(\"%c \", m[a][b]);\n    }\n    else {\n        for (int row = a + 1; row &lt;= c; row++) {\n            printf(\"%c \", m[row][d]);\n        }\n        for (int col = d - 1; col &gt;= b; col--) {\n            printf(\"%c \", m[c][col]);\n        }\n        for (int row = c - 1; row &gt;= a; row--) {\n            printf(\"%c \", m[row][b]);\n        }\n        for (int col = b + 1; col &lt;= d; col++) {\n            printf(\"%c \", m[a][col]);\n        }\n    }\n}\n\nint main() {\n    char* map1[] = { \"a\" };\n    int n1 = sizeof(map1) / sizeof(char*);\n    print(map1, n1);\n\n    char* map2[] = { \"ab\", \"cd\" };\n    int n2 = sizeof(map2) / sizeof(char*);\n    print(map2, n2);\n\n    char* map3[] = { \"abc\", \"def\", \"ghi\" };\n    int n3 = sizeof(map3) / sizeof(char*);\n    print(map3, n3);\n\n    char* map4[] = { \"abcd\", \"efgh\", \"ijkl\", \"mnop\" };\n    int n4 = sizeof(map4) / sizeof(char*);\n    print(map4, n4);\n\n    char* map5[] = { \"abcde\", \"fghij\", \"klmno\", \"pqrst\", \"uvwxy\" };\n    int n5 = sizeof(map5) / sizeof(char*);\n    print(map5, n5);\n\n    char* map6[] = { \"abcdef\", \"ghijkl\", \"mnopqr\", \"stuvwx\", \"yz0123\", \"456789\" };\n    int n6 = sizeof(map6) / sizeof(char*);\n    print(map6, n6);\n\n    return 0;\n}\n</code></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/51/512ae91bae89a2df4dc8401dce6b8bc5.png\" /></p><p></p>",
    "publish_time": "2023-09-20 10:56:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "OpenAI放大招“对打”谷歌Gemini：全力筹备多模态大模型，并发布新指令语言模型",
    "url": "https://www.infoq.cn/article/g4L1Y5SPGGUiX1BB4l2t",
    "summary": "<p></p><blockquote>这场大模型时代的较量，谁能笑到最后？</blockquote><p></p><p>&nbsp;</p><p>自去年年底通过 ChatGPT 惊艳全球以来，OpenAI 一直保持着惊人的产品发布速度，通过迅如闪电的“组合拳”保持该公司在 AI 领域建立的统治地位与领导者形象。</p><p>&nbsp;</p><p>但其他科技巨头绝不可能坐视 OpenAI 一家独大。谷歌已经公布大语言模型 Gemini，计划于今年秋季首次与广大用户见面，且有报道称该模型已经在接受指定企业客户的测试。从目前的情况看，谷歌有可能后来居上、实现反超。</p><p>&nbsp;</p><p>面对挑战，OpenAI 连续放大招，除了发布新指令语言模型 GPT-3.5-turbo-instruct，还计划推出多模态大模型 GPT-Vision 与 Gobi。据一位未公开身份的知情人士透露，OpenAI 在积极将多模态功能（类似于 Gemini 将要提供的功能）纳入 GPT-4。</p><p></p><h2>新语言模型InstructGPT-3.5</h2><p></p><p>&nbsp;</p><p>近日，OpenAI 推出 GPT-3.5-turbo-instruct，这是一款新的指令语言模型，效率可以与聊天优化的 GPT-3.5 Turbo 模型相媲美。</p><p>&nbsp;</p><p>指令模型属于大语言模型的一种，会在使用一大量数据进行预训练之后，再通过人类反馈（RLHF）做进一步完善。在此过程中，会由人类负责评估模型根据用户提示词生成的输出，对结果做改进以达成目标效果，再将更新后的素材用于进一步训练。</p><p>&nbsp;</p><p>因此，指令模型能够更好地理解并响应人类的查询预期，减少错误并缓解有害内容的传播。从OpenAI 的测试结果来看，尽管体量仅为后者的百分之一，但人们明显更喜欢拥有 13 亿参数的 InstructGPT 模型，而非拥有 1750 亿参数的 GPT 模型。</p><p>&nbsp;</p><p>据了解，GPT-3.5-turbo-instruct 的成本与性能同其他具有 4K 上下文窗口的 GPT-3.5 模型相同，使用的训练数据截止于 2021 年 9 月。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/80/809370ea78382a5c5d269aafb39437aa.png\" /></p><p></p><p>GPT-3.5-turbo-instruct 将取代一系列现有 Instruct 模型，外加 text-ada-001、text-babbage-001 和 text-curie-001。这三款 text-davinci 模型将于 2024 年 1 月 4 日正式停用。</p><p>&nbsp;</p><p>OpenAI 表示，GPT-3.5-turbo-instruct 的训练方式与之前的其他 Instruct 模型类似。该公司并未提供新 Instruct 模型的细节或基准，而是参考了 2022 年 1 月发布的 InstructGPT，即 GPT-3.5 模型的实现基础。</p><p>&nbsp;</p><p>OpenAI 称，GPT-4 拥有超越 GPT-3.5 的复杂指令遵循能力，生成的结果也比 GPT-3.5 质量更高；但 GPT-3.5 也有自己的独特优势，例如速度更快且运行成本更低。GPT-3.5-turbo-instruct 并非聊天模型，这一点与原始 GPT-3.5 有所区别。具体来讲，与之前的聊天应用模型不同，GPT-3.5-turbo-instruct 主要针对直接问答或文本补全进行优化。</p><p>&nbsp;</p><p>速度方面，OpenAI 称 GPT-3.5-turbo-instruct 速度与 GPT-3.5-turbo 基本相当。</p><p>&nbsp;</p><p>下图为 OpenAI 设计的 Instruct 指令模型与 Chat 聊天模型之间的区别。这种固有差异自然会对提示词的具体编写产生影响。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/11/11e71f7bd469918f32333d59db603e8b.webp\" /></p><p></p><p>OpenAI 负责开发者关系的Logan Kilpatrick称，这套新的指令模型属于向 GPT-3.5-turbo 迁移当中的过渡性产物。他表示其并不属于“长期解决方案”。已经在使用微调模型的用户，需要根据新的模型版本做重新微调。目前微调功能只适用于 GPT-3.5，GPT-4 的微调选项计划于今年晚些时候发布。</p><p></p><h2>多模态大模型GPT-Vision与Gobi</h2><p></p><p>&nbsp;</p><p>除了 GPT-3.5-turbo-instruct，OpenAI 近日还计划发布多模态大模型 GPT-Vision，以及一个代号为“Gobi”的更强大的多模态大模型。</p><p>&nbsp;</p><p>据悉，GPT-Vision 在 3 月份的 GPT-4 发布期间首次预览，是 OpenAI 融合文本和视觉领域的雄心勃勃的尝试。虽然该功能最初实际用例仅限于 Be My Eyes 公司，这家公司通过其移动应用帮助视力障碍或失明用户进行日常活动。</p><p>&nbsp;</p><p>GPT-Vision 有潜力重新定义创意内容生成的界限。想象一下使用简单的文本提示生成独特的艺术品、徽标或模因。或者考虑一下对有视觉障碍的用户的好处，他们可以通过自然语言查询与视觉内容交互并理解视觉内容。该技术还有望彻底改变视觉学习和教育，使用户能够通过视觉示例学习新概念。</p><p>&nbsp;</p><p>如今，OpenAI 正准备将这项名为 GPT-Vision 的功能开放给更广泛的市场受众。</p><p>&nbsp;</p><p>此外，据 The Information 报道，OpenAI 即将发布代号为“Gobi”的下一代多模态大语言模型，希望借此击败谷歌并继续保持市场领先地位。目前，Gobi 的训练还没有开始，有评论认为其有机会成为 GPT-5。</p><p>&nbsp;</p><p>报道称，OpenAI 之所以耗费大量时间来推出 Gobi，主要是担心新的视觉功能会被坏人利用，例如通过自动解决验证码来冒充人类，或者通过人脸识别追踪人们。但现在，OpenAI 的工程师们似乎想到办法来缓解这个安全问题了。</p><p></p><h2>OpenAI CEO：GPT-5尚未出现，计划将多模态功能纳入GPT-4</h2><p></p><p>&nbsp;</p><p>据了解，多模态大语言模型的本质是一种先进 AI 系统，能够理解和处理多种数据形式，包括文本和图像。与主要处理文本内容的传统语言模型不同，多模态大语言模型能够同时对文本加视觉类内容进行分析和生成。</p><p>&nbsp;</p><p>也就是说，这类模型可以解释图像、理解上下文并生成包含文本和视觉输入的响应结果。多模态大模型还拥有极高的通用性，适用于从自然语言理解到图像解释的诸多应用，借此提供更广泛的信息处理能力。</p><p>&nbsp;</p><p>报道指出，“这些模型能够处理图像和文本，例如通过查看用户绘制的网站外观草图来生成网站构建代码，或者根据文本分析结果输出可视化图表。如此一来，普通用户也能快速理解内容含义，不必再向拥有技术背景的工程师们求助。”</p><p>&nbsp;</p><p>OpenAI 首席执行官 Sam Altman 在最近的采访中表示，尽管 GPT-5 尚未出现，但他们正计划对 GPT-4 进行各种增强。而开放多模态支持功能，也许就是这项计划的一部分。</p><p>&nbsp;</p><p>在上周接受《连线》采访时，谷歌 CEO 桑达尔·皮查伊表达了他对于谷歌当前 AI 江湖地位的信心，强调其仍掌握着技术领先优势、并在创新与责任方面求取平衡的审慎战略。他也对 OpenAI&nbsp;ChatGPT 的深远意义表示认可，称赞其拥有良好的产品-市场契合度、让用户对 AI 技术做好了准备。但他同时强调，谷歌在产品信任和负责态度方面会采取更加谨慎的立场。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://the-decoder.com/openai-releases-new-language-model-instructgpt-3-5/\">https://the-decoder.com/openai-releases-new-language-model-instructgpt-3-5/</a>\"</p><p><a href=\"https://www.theinformation.com/articles/openai-hustles-to-beat-google-to-launch-multimodal-llm\">https://www.theinformation.com/articles/openai-hustles-to-beat-google-to-launch-multimodal-llm</a>\"</p><p><a href=\"https://aibeat.co/openai-multimodal-llm-gpt-vision-google/\">https://aibeat.co/openai-multimodal-llm-gpt-vision-google/</a>\"</p>",
    "publish_time": "2023-09-20 14:56:32",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]