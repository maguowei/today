[
  {
    "title": "微软全新Azure应用服务计划，提升性能与扩展能力",
    "url": "https://www.infoq.cn/article/gbwNW5kVIMRx1aZvg9sI",
    "summary": "<p>微软最近宣布在 Azure 应用服务（Azure App Service）的 Premium v3 (Pv3) 服务层推出两项新产品，并于 Isolated v2 服务层进行了扩展。</p><p></p><p><a href=\"https://azure.microsoft.com/en-us/products/app-service\">Azure 应用服务</a>\"是一个基于 HTTP 的服务，可托管使用 .NET、.NET Core、Java、Ruby、Node.js、PHP 和 Python 等语言编写的 Web 应用程序、REST API 和移动后端。此外，它还提供自动缩放和高可用性、支持 Windows 和 Linux 两种操作系统，并支持从 GitHub、Azure DevOps 或任何 Git 存储库的自动化部署。</p><p></p><p>目前，应用服务可支持 Pv3 服务层，为企业提供了一系列新的面向内存优化的 P*mv3 计划，其中包括 P1mv3、P2mv3、P3mv3 等。这些计划在带来了内存配置增加的灵活性的同时，不需要额外的核心费用。此外，这些计划的虚拟核心数从 P1mv3 的两个核心、16GB RAM（相较 P1v3 的两个核心、8GB RAM）到 P5mv3 的32个核心、256GB RAM 不等。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d2/d20322f5b2548e6c2561f2e822ef3e4b.png\" /></p><p>来源：<a href=\"https://learn.microsoft.com/en-us/azure/app-service/app-service-configure-premium-tier\">https://learn.microsoft.com/en-us/azure/app-service/app-service-configure-premium-tier</a>\"</p><p></p><p>除了面向内存优化的计划外，Premium v3 还可提供一种性价比较高的 P0v3 计划。据微软称，与标准计划或 Premium v2 (Pv2) 计划相比，P0v3 计划在近似的月租费用下提供了显见更高的性能。此外，该公司还<a href=\"https://azure.microsoft.com/nl-nl/blog/new-azure-app-service-plans-fuel-greater-choice-and-savings/\">表示</a>\"，P0v3 计划可允许客户使用&nbsp;<a href=\"https://azure.microsoft.com/en-us/pricing/offers/savings-plan-compute/#benefits-and-features\">Azure 节省计划</a>\"和预留实例 (RI) 定价，这些定价仅适用于 Premium v3 服务层，可为客户节省高达55%的费用，比按使用量计费的计划更为划算。</p><p></p><p>此外，Azure 应用服务的成本管理<a href=\"https://learn.microsoft.com/en-us/azure/app-service/overview-manage-costs#production-workloads\">文档</a>\"提到：</p><p></p><p></p><blockquote>事实上，Premium V3 (最高的非隔离层) 是以成本效益最高的方式为您的应用程序提供大规模服务的方式。为了进一步节省成本，您可以在&nbsp;<a href=\"https://learn.microsoft.com/en-us/azure/app-service/overview-manage-costs#azure-reservations\">Premium V3 预留实例</a>\"上获得更进一步的折扣。</blockquote><p></p><p></p><p>除了 Premium 计划外，微软还为对安全性和合规性要求更为严格的企业提供了<a href=\"https://learn.microsoft.com/en-us/azure/app-service/environment/overview\">应用服务环境</a>\"&nbsp;(ASE)，这一环境允许客户对其应用程序网络的进出流量进行精确控制。与共享的多租户服务不同，应用服务环境专门用于托管来自单个客户的应用程序，且其背后是 Isolated v2 (Iv2) 计划。</p><p></p><p>Isolated v2 (Iv2) 计划现已扩展了三种新的计划：I4v2、I5v2 和 I6v2，其计算选项从16个虚拟核心和64 GB 内存到多达64个虚拟核心和256 GB 内存不等。</p><p></p><p>Azure 应用服务的定价和可用性详情可参见其<a href=\"https://azure.microsoft.com/en-us/pricing/details/app-service/windows/\">定价页面</a>\"。此外，微软在 Premium V3 的<a href=\"https://learn.microsoft.com/en-us/azure/app-service/app-service-configure-premium-tier#premiumv3-availability\">相关文档</a>\"中指出，其可用性将不断扩展至更多的 Azure 区域。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/04/new-azure-app-service-plans/\">Microsoft Offers More App Service Plans Choices</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/HdhHwuPQk4FCdPBpmdlP\">Azure CTO： Rust 已登陆 Windows 11 内核</a>\"</p><p><a href=\"https://www.infoq.cn/article/4114G9FlqZFEyTzQ53mq\">微软发布Azure Cosmos DB for PostgreSQL</a>\"</p><p></p>",
    "publish_time": "2023-06-01 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "社交泛娱乐出海作战地图",
    "url": "https://www.infoq.cn/article/IN02LFpmjr3Wdk8G7d2T",
    "summary": "<p>在企业出海从粗放式走向精细化的趋势下，企业对海外目标群体、交互方式、运营和服务等方面有更具体、更细颗粒度的认知需求，以便更快、更稳地做好本地化运营和服务。</p>\n<p>为了满足企业的精细化出海需求，融云重磅推出<a href=\"https://www.infoq.cn/form/?id=1604&amp;utm_source=wz&amp;sign=iq_6475a2839c791\">《社交泛娱乐出海作战地图》</a>（下文“出海作战地图”）。“出海作战地图”包括<strong>“出海动因＆历程”“重点市场布局”“重点赛道突围”“痛点与挑战”“出海从０到1”</strong>五大模块。你可以从这五大板块中了解到：</p>\n<ul>\n<li>首次出海，如何选择海外第一站？</li>\n<li>有哪些创新技术可以帮助企业出海？</li>\n<li>怎么制定海外本地化战略？</li>\n<li>如何选择更高效、更具性价比的海外营销方案？</li>\n<li>海外安全合规风险如何提前规避？</li>\n<li>……</li>\n</ul>\n<p>针对<strong>东南亚、中东、非洲、拉美、欧美 5 大重点市场的 64 个国家</strong>，“出海作战地图”从<strong>经济&amp;人口、政策环境、互联网基础、宗教文化、市场机会与赛道</strong>等方面帮助出海人体系化梳理出海思路。</p>\n<p>值得注意的是，“出海作战地图”还针对<strong>约会交友、社区、音频社交、视频社交、游戏社交、虚拟社交及 AIGC 新技术</strong>带来的新业态，对社交泛娱乐重点赛道进行了微观层面的详细拆解。</p>\n<p><a href=\"https://www.infoq.cn/form/?id=1604&amp;utm_source=wz&amp;sign=iq_6475a2839c791\">《出海作战地图》</a>还凝结了 200+ 位出海实战家的宝贵经验，从赛道/品类选择、目标地区适配、用户增长、变现模式、本地化运营、跨国团队管理等方面全方位呈现了“出海从 0 到 1”的实用方法论。</p>\n<p>更多精彩内容，点击“<a href=\"https://www.infoq.cn/form/?id=1604&amp;utm_source=wz&amp;sign=iq_6475a2839c791\">下载</a>”即可<strong>免费获取</strong>完整<strong>纸质版</strong>《社交泛娱乐出海作战地图》！</p>",
    "publish_time": "2023-06-01 09:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "一图在手出海不愁！完整纸质版《社交泛娱乐出海作战地图》免费领！",
    "url": "https://www.infoq.cn/article/Mk1N15ZlcNXYLpXqHe3e",
    "summary": "<p>经过近几年的发展，如今的互联网出海已经是截然不同的命题。从粗放到精细，企业出海的风浪越来越猛烈。</p><p></p><p>如何契合自己的基因选择出海赛道和地区？</p><p>如何打造有获客抓手的独特出海产品？</p><p>如何在海外拿下第一个客户？</p><p>……</p><p></p><p>融合200+实战家一线宝贵经验，融云近期重磅推出了<a href=\"http://gk.link/a/124t0\">《社交泛娱乐出海作战地图》</a>\"（下简称“出海作战地图”），通过“出海动因＆历程”“重点市场布局”“重点赛道突围”“痛点与挑战”“出海从０到1”五大模块，帮助出海人体系化梳理思路。</p><p></p><p>比白皮书形式更精炼省流，比知识类信息更实用有效，《出海作战地图》是社交泛娱乐出海不可多得的宝藏工具。出品方融云特别为InfoQ粉丝开通了免费申领通道，扫描下方二维码即可获取完整纸质版地图！</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/2d/cd/2d119be38638eb2dcbc2652170972acd.png\" /></p><p></p><p>《出海作战地图》纸质版实物长约1米，折叠起来方便携带，展开贴挂醒目亮眼，使用场景十分丰富。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/e4/8b/e48414b22b020103e43bbde58c11ac8b.png\" /></p><p>实物图全景图</p><p><img src=\"https://static001.infoq.cn/resource/image/a6/b2/a62d1393byy4e4fc80646695e12fbdb2.jpg\" /></p><p>实物图折叠版</p><p>在内容上，它通过5个模块体系化地对社交泛娱乐出海进行了全局知识梳理，具体又内含7个赛道、64个国家的产品和市场分析。并且，出海开发者面对的痛点挑战和从0到1实用指南模块的内容也具有操作性和借鉴意义。</p><p></p><p>BTW，《出海作战地图》将在6月2日于广州举办的“<a href=\"https://xie.infoq.cn/article/b15b07a4492f903b56ba93d32\">WICC · 社交泛娱乐出海嘉年华</a>\"”进行线下首发，感兴趣的朋友可以移步融云的官方公众号【融云全球互联网通信云】回复【WICC】报名，现场参会的同学也可以领取纸质版地图。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/cd/11/cdfe558d129c1ce57736c49e84ec9811.png\" /></p><p></p><h1>竞争不留余地，出海从哪下手？</h1><p></p><p></p><p>针对东南亚、中东、非洲、拉美、欧美5大重点市场的64个国家，《出海作战地图》从经济&amp;人口、政策环境、互联网基础、宗教文化、市场机会与赛道等方面进行了全要素宏观层面分析。</p><p></p><p>针对约会交友、社区、音频社交、视频社交、游戏社交、虚拟社交及AIGC新技术带来的新业态，《出海作战地图》对社交泛娱乐重点赛道进行了微观层面的详细拆解。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/f0/9e/f0903dbe3c965e51f4da26965700b49e.png\" /></p><p></p><p>二者结合，为出海人打造建立全局认知的第一知识图谱。</p><p></p><p>产业的发展总是遵循从粗放到精细，从岁月静好到卷生卷死的发展路径，这适用于几乎所有市场的所有品类。</p><p></p><p>普世的、基础的社交需求已经被先入为主的国际巨头解决，机会缝隙只存在于更聚焦、更复杂的需求，比如更细分的目标群体、创新的交互方式、升级的运营和服务。</p><p></p><p>明确产品定位，饱和赛道寻找用户未被满足的细分需求作为进入点，勇于集中资源打穿市场，是在巨头林立的竞争局势中立足的关键。</p><p></p><p>利用好新技术带动的产业浪潮，则是当前的另一条显性路径。在这方面，AI绘画工具<a href=\"https://www.midjourney.com/\">Midjourney</a>\"提供了一个参考思路。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/50/fb/505cba91a42ab4e5af574a2e34ec4ffb.png\" /></p><p></p><p>这个只有11人的团队做出的产品，上线不到一年已经实现了近1500万用户和1亿美元营收，成了谈论AIGC无法绕开的代表性公司。</p><p></p><p>不同于自建网站或App，它在实时社区Discord中以频道的形式提供服务。</p><p></p><p>1.5亿月活的Discord，对Midjourney来说首先是一个流量充沛的绝佳获客渠道。</p><p></p><p>其次，在Discord完整的社区生态上，Midjourney将即时交流的社交体验与AIGC服务相结合，频道更像是一个AI绘画的大型社交场所，也让它在庞大的用户需求中快速迭代产品。</p><p></p><p>这是实时社区Discord体验的神奇之处，也是融云超级群这个构建类Discord实时社区第一选择PaaS产品的灵活之处。</p><p></p><h1>Think Global, Act Local</h1><p></p><p></p><p>“相当于中国的哪一年？”</p><p></p><p>当我们讨论出海地区的发展阶段，这是一个最常被提及的问题。</p><p></p><p>这其实自带了一种心理暗示、前提假设，认为某个地区的发展曲线与中国一样，我们已经创造和见证的故事可以在别处如期上演。可事实并非如此，具体到某一个赛道、某一群用户的生意，事情就会变得复杂起来，既有市场相对成熟的模式复制到一个新兴市场里往往行不通。</p><p></p><p>这一点，从<a href=\"http://gk.link/a/124t0\">《出海作战地图》</a>\"对东南亚市场的梳理分析就清晰可见。作为一个多语言、多民族、多宗教信仰的地区，东南亚复杂的文化环境让本地化变得更加困难。如果带着简单的“降维打击”心态落地东南亚，可想而知只会“碰一鼻子灰”。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/37/5f/3731dafe7caff6b55833a13fd09c235f.png\" /></p><p></p><p>每个市场、每个群体都呈现出不一样的发展阶段和动态需求，所有看似有效的成熟攻略，都只是“刻舟求剑”。</p><p></p><p>我们在国内互联网产品、用户体验和运营等方面积累的经验，要放置于当地与具体市场进行碰撞融合，甚至形成新业态。</p><p></p><p>比如，电商与短视频在中国代表着移动互联网两个不同阶段的潮水流向，而在东南亚几乎是并驾齐驱。电商的爆发期叠加了短视频直播的红利期，电商出海就要更多考虑如何有效利用这些媒体的红利。这样的本地化问题，贯穿于业务发展的全程。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/31/f7/3137533b9cyy817cc0332633429f4bf7.png\" /></p><p></p><p>根据《出海作战地图》的梳理，数据合规和本地化治理、交互体验、政治宗教文化、底层技术和服务等本地化难题，共同讲述着全球化=无数细微本地化叠加的现实挑战。</p><p></p><h1>善用专业服务，避免无谓出血点</h1><p></p><p></p><p>今年聊出海，Temu是一个不容忽视的品牌。它在美国超级碗豪掷1400万美元投放了一条30秒的广告，“Shop Like a Billionaire”的广告词像帮我砍一刀一样迅速传播。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/20/21/20e9489fcb0b1ca19956afdae9c1f221.png\" /></p><p></p><p>略微反常识的是，鲜少在美国上演的低价策略居然收效不错。据Sensor Tower统计，美国应用商店2023年3月前三周下载量排名，Temu居首位。</p><p></p><p>在极致性价比的产品战略下，Temu迅速超过了亚马逊、沃尔玛等本土电商。可见，看似稳固的市场格局里，也并没有巨头把知名度彻底转变为忠诚度。</p><p></p><p>不过，Temu的表现绝不仅仅得益于低价策略和社交裂变营销方式，底层其实是包括仓储物流、中国制造、交易平台等组成的整体生态正在走向世界。可以说，如果没有产业链的成熟，Temu和Shein的成功都将无法如此顺利。</p><p></p><p>所以，业务扩张的局限绝对不仅仅在于业务本身，还会囿于产业资源、生态和秩序。而在社交泛娱乐领域，这一点目前可谓“天时”已备。</p><p></p><p>在中国工程师红利的影响下，社交泛娱乐出海经历了几轮迭代，如今已经形成了相对完整的生态链条，迸发出蓬勃的势能。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/2d/e4/2d4f75d7302efb75c4f5d1a7ecfae2e4.png\" /></p><p></p><p><a href=\"http://gk.link/a/124t0\">《出海作战地图》</a>\"梳理了社交泛娱乐涉及到的主要三方服务，强调把专业的事情交给专业的人，利用好经过时间和场景考验的三方服务，避免在这些要害处造成无谓失血点。</p><p></p><p>以出海必须面对的通信网络难题为例，中东语聊房产品OHLA的CTO沈翔曾分享，语聊房出海会遇到一些国内想象不到的问题，网络环境就是关卡之一。“在中东，可能两个相隔仅10公里的用户，就会面对网络环境的巨大差异。”</p><p></p><p>OHLA的选择，就是把复杂的通信问题交给融云来处理。正如蜻蜓游戏总经理何杰在融云“社交泛娱乐出海赋能会”上所说，“一定要懂得借力，充分利用融云三方服务的专业性。”</p><p></p><p>他还从成本角度更直白地算了一笔账，像IM、RTC这样的必备通信能力，如果自研，前期开发、测试以及上线后的运维等各种问题会非常多。“几千台服务器，几十个运维人员，不光是经济成本，管理的成本也会非常高。”</p><p></p><p>而融云从2016年便伴随中国开发者的出海步伐开启全球化布局，在重点地区积累了丰富的服务经验，其全新升级的全球通信网SD-CAN V4，可以通过多链路、多协议、智能竞速、动态混淆、智能心跳、网络记忆及多地区统一调度等手段来完成不同地区的调度优化，形成了庞大、无拥塞的全球网络。</p><p></p><p>再说合规问题，流量规模、占用用户时间成为社交泛娱乐商业形态的基本盘，持续合规地获取、留存用户的能力决定了应用生命线的长短。这不仅考验出海创业者的认知和资源整合能力，对应变能力也是一种挑战，毕竟像iOS更新隐私规则这样的行业性变革也不是偶尔有之的小概率事件。</p><p></p><p>《出海作战地图》以知识产权合规、海外运营法务合规、苹果/GP商店合规、数据隐私合规、产品内容合规、海外广告买量及变现合规几大方面呈现安全合规全景图，基本上囊括了业务开展在合规方面的所有问题，你可以对照地图一一检查自己的业务。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/2f/f1/2fdefcf7cd941243a6d035effb1e65f1.png\" /></p><p></p><p>包含以上难点在内，《出海作战地图》还从赛道/品类选择、目标地区适配、用户增长、变现模式、本地化运营、跨国团队管理等方面全方位呈现了“出海从0 到1”的实用方法论。</p><p></p><p>当然，市场浩瀚如烟，一张地图很难做到尽善尽美，但我觉得，它只要能激发你一点灵感和新思路，那就值得！点击<a href=\"http://gk.link/a/124t0\">此处</a>\"或扫描下方二维码，立刻免费获取完整纸质版《社交泛娱乐出海作战地图》！</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/42/1f/42b7fae9fb0dd8cda3132280c381801f.png\" /></p><p></p><p></p><p></p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-06-01 09:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "QCon金融行业闭门会：数据治理是管理问题，还是技术问题？",
    "url": "https://www.infoq.cn/article/2SKxCHfga7XBmatYS0oW",
    "summary": "<p>在5月26日，<a href=\"https://qcon.infoq.cn/2023/guangzhou/schedule\">QCon全球开发者大会（广州站）</a>\"顺利落地，在现场，InfoQ 特别策划了五场闭门会，主题分别为《企业在 LLM、AIGC 浪潮下的研发探索》《DevOps vs 平台工程，必要性和 ROI 探讨》《破解成本优化后的稳定性问题》《业务出海之架构、合规、运营》《金融行业数据治理经验分享》，本文为《金融行业数据治理经验分享》研讨纪要整理～</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/71/71ac65d4f2dca76a9f3343485e4acd06.jpeg\" /></p><p></p><p>出席此次闭门会参会嘉宾如下：</p><p>主持人：Yolanda&nbsp;InfoQ&nbsp;极客传媒总经理</p><p>李杨，平安资管科技平台交易系统团队开发组负责人王劲，数果智能创始人兼&nbsp;CEO&nbsp;周程伟，链融科技CTO，TGO&nbsp;深圳会员李龙，众安国际Fundamental&nbsp;Tech&nbsp;VP</p><p></p><h4>针对不同监管部门发布的不同标准，你们如何应对？</h4><p></p><p>李龙提到，首先是内部需要有理解监管，而且为业务目标共同努力的联合团队；第二点，需要实时了解监管动态；第三，落地的时候，需要充分的保护好企业，进行相关证明材料、法律意见的存档，例如数据跨境风险，在监管政策上，内地和香港的政策有一定差异，这里的数据处理和合规风险需要非常慎重，留好记录，确保业务合规开展。</p><p>&nbsp;</p><p>李杨指出，保险投资公司与银行有一些不同之处，他服务对象包括平安集团的保险资金以及第三方资金。由于可能涉及大规模的投资交易，监管机构担心某些操作造成不正常市场波动，为遵守监管要求，将风控措施嵌入到内部系统中。公司内部风控要求会更加严格，以避免违反监管规定。</p><p>&nbsp;</p><p>他们还有内部评级和事中监控系统，用于监控交易员执行交易时是否触发监管或者内部的一些要求。如果超过设置的某些阈值，系统会提醒交易员。一般来说公司的要求会高于监管既定的阈值以避免引起不必要的风险。与此同时，我们公司注重合规文化，常常进行合规宣传以及相应的学习。</p><p>&nbsp;</p><p>周程伟谈到不同监管部门存在不同的标准，尤其在跨境交易方面。然而，国内监管机构的标准在逻辑上是一致的，且核心逻辑是非标和综合规则。虽然不同行业可能存在一些差异。随着监管对金融科技的加强，进行某些操作变得越来越困难，需要大量的沟通和解释。在个人信息保护方面，涉及敏感信息的处理更加严格。另外，金融领域的监管目前还没有明确分工，但企业需要建立合规和数据管理体系。</p><p>&nbsp;</p><p>王劲也发表了自己的观点，他认为“作为乙方单位，我们在为甲方提供服务时，也感受到金融监管对数据安全和个人隐私的重视程度，尤其在与银行和其他金融机构合作时。监管部门对APP数据采集的要求非常高，包括数据分析和分类的明确要求，以及加密算法保护用户身份证、电话和银行卡等敏感信息。在数据分析过程中，数据脱敏是常用的方法，确保数据的安全性和隐私性。整个行业对数据安全和隐私的要求越来越严格，不仅限于金融领域，包括央企在内的各个行业也高度重视数据资产的安全。</p><p></p><h4>如何解决数据孤岛？</h4><p></p><p>&nbsp;</p><p>李杨率先谈到：很多企业声称正在进行数字化转型，解决数据孤岛和数据联通的问题，但实际上数字化转型对于任何企业来说都是较大的挑战。“我认为数据孤岛是必然会产生的，并且会持续存在。业务部门往往相对独立，构建了各自的业务系统，导致出现隔离和数据孤岛的问题。”他认为解决数据孤岛问题是一项困难的任务，特别是在组织不够痛时。他也指出数据孤岛问题可能永远存在，只能不同企业缓解的程度不一样。无法完全解决，处于on the way的状态。因为组织架构和业务系统支持的效率等因素影响着解决该问题的难度。他认为企业应该建立统一的数据中心和数据服务中台，以提高数据的一致性和故障处理能力。</p><p>&nbsp;</p><p>王劲谈到，数据治理在数据资源和数据库方面并不是最新的概念，而是从数仓时代开始逐渐形成的。然而，许多公司在进行数据治理时存在一个重要问题，就是过于关注治理而忽视了从业务出发的重要性。数据治理必须回归到业务场景，并从一个业务场景的角度全面治理数据，否则即使在数据层面上取得了一些成果，也无法解决实际业务问题。因此，数据治理需要由业务牵头，并将技术服务于业务需求。另外，关注数据指标是实现数据治理的关键，指标是离业务最近的，通过围绕指标展开数据治理，将指标相关的数据汇总起来，可以解决数据孤岛、数据质量等问题。</p><p>&nbsp;</p><p>周程伟提到了数据孤岛的问题正在逐渐变好，解决数据孤岛是一个动态变化的过程。于此同时，他也谈到，规范化的产品研发和数据管理流程可以解决现有问题。管理科学和数据质量是需要解决的关键问题，但在传统企业中很难做到完美。</p><p>&nbsp;</p><p>李龙则强调了数据与组织架构的关系。他认为数据的最终形态取决于组织架构，他强调数据的统一口径和标准，并指出数据科学部门的独立性和与业务部门的协作。同时他也认为CEO和CTO在解决数据与组织架构问题上起关键作用，必须通过合理的设计来解决这个问题。他还提到了众安保险和数据科学应用中心的数据团队在公司文化中的重要性，以及数据在业务增量中的作用。</p><p>&nbsp;</p><p></p><h4>数据质量参差不齐，大家如何解决？</h4><p></p><p>&nbsp;</p><p>王劲认为数据质量的关键在于回归到业务平台。从业务角度出发，大家需要确定基于特定场景和业务的数据指标体系，进行梳理和定义。通过分析，将整个数据链路串联起来，并在每个节点实现管控和监控。数据质量参差不齐的情况下，出现故障或问题往往需要花费大量时间和资源进行排查。因此，确保数据质量需要建立一个闭环的监督体系，以业务为中心，实现数据活动和关键节点的快速定位。在技术层面上，可以采用多数据源的比对和检查，以及监控系统的建立。此外，指标的偏离度和数据的准确性、及时性、完整性也是数据质量的重要考虑因素。</p><p>&nbsp;</p><p>李杨谈到数据治理涉及数据质量、数据标准和数据安全。其中，数据质量指标包括一致性、完备性、完整性、及时性和有效性等。通过交叉验证和调度平台生成数据质量报告，满足对数据质量的要求和监控。从技术层面来看，实现并不复杂，通过调度和手工制定规则来完成。然而，我们需要确保能够清楚地收集业务关心的数据指标，并生成及时准确的数据指标，这是一个比较重要但也比较困难的任务。另外，数据分为OLAP和OLTP对于OLTP型数据，对数据的及时性监控更为重要。现有的基础设施能否满足对OLTP型数据质量的监控是一个难点。</p><p>&nbsp;</p><p>王劲在这里提出了疑问，他认为在考虑数据质量时，不能仅从技术角度出发，而应该从业务结果的角度去倒推。数据质量问题是与业务密切相关的，例如，如果每天的交易量应该达到1000亿，但实际只有800亿，这涉及到了数据质量的问题。数据的质量与业务是紧密相连的，不能将其分开看待。</p><p>&nbsp;</p><p>李龙最后谈到，在进行原始数据定义和口径梳理时，需要意识到不同部门可能有不同的口径定义。建模团队应该能够发现这些不同的口径，并将其整合起来，避免分析过程中的冲突和重复。这一点非常重要。在这个基础上，通过数据质量的监控规则和机制来保证数据的准确性。同时，业务部门也应自觉地发现问题，并促使解决。数据团队在此过程中扮演着收口的角色，不是简单地新增数据，而是通过识别相同数据中的不同问题，避免冗余。</p><p>&nbsp;</p><p>活动推荐：</p><p>2023 年 9 月 3 - 5 日，在北京·富力万丽酒店，<a href=\"https://qcon.infoq.cn/202309/beijing/\"> QCon 全球软件开发大会（北京站）</a>\"已开启，现已开启售票，提前订票，可享受7折早鸟价，购票参会可以直接电话 / 微信联系票务经理 18514549229。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e2/e2cc6621bc634e6d3fcacee922604626.jpeg\" /></p><p></p>",
    "publish_time": "2023-06-01 11:23:23",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "设计模式详解之策略模式",
    "url": "https://www.infoq.cn/article/0f0f1b453827b2c5ccb624ade",
    "summary": "<p>作者：刘文慧</p><p></p><p></p><blockquote>策略模式是一种应用广泛的行为型模式，核心思想是对算法进行封装，委派给不同对象来管理，本文将着眼于策略模式进行分享。</blockquote><p></p><p></p><p></p><h1>一、概述</h1><p></p><p></p><p>我们在进行软件开发时要想实现可维护、可扩展，就需要尽量复用代码，并且降低代码的耦合度，而设计模式就是一种可以提高代码可复用性、可维护性、可扩展性以及可读性的解决方案。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2c/2c43fd4658dc701e2fd3454a7b9ef25b.png\" /></p><p></p><p>大家熟知的23种设计模式，可以分为创建型模式、结构型模式和行为型模式三大类。其中，行为型模式可用于描述程序中多个类和多个对象如何协作完成复杂的任务，涉及不同对象间的职责分配、算法的抽象化。策略模式是一种应用广泛的行为型模式，本文将着眼于策略模式进行学习分享。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d8/d805432b933071c16e18bbb7f6c340cc.png\" /></p><p></p><p></p><h1>二、基本概念</h1><p></p><p></p><p>策略模式的核心思想是对算法进行封装，委派给不同对象来管理。这样，我们就可以定义一系列算法，将每个算法封装到具有公共接口的一系列具体策略类中，从而使它们可以灵活替换，并让算法可以在不影响到客户端的情况下发生变化。同时，策略模式仅仅封装算法（包括添加、删除），但其并不决定在何时使用何种算法，算法的选择由客户端来决定。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8f/8f84a735c560abc5c71773d8cd935541.png\" /></p><p></p><p>比如，我们旅游时可以选择的出行策略有很多种：自行车、汽车、火车、飞机，每种出行策略都有各自的使用方法，只要能到目的地，我们可以随意更换各种策略。再比如我们去逛商场，商场会有很多促销活动：满减、返利等，这些促销方式本质上都是一些算法，而算法本身也是一种策略，随时都可以互相替换，针对同一件商品，今天满500减50、明天满300返100购物券，这些策略之间同样可以互换。</p><p></p><p>那么，我们应该如何使用策略模式呢？下面将从结构和使用步骤两个层面，对策略模式进行概念性介绍。</p><p></p><p></p><h2>2.1 结构</h2><p></p><p></p><p>策略模式包含三种类，分别是抽象策略类、具体策略类、环境类，它们各自负责完成特定任务，并且相互之间存在紧密的联系。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0d/0d393a8aa06e63280dd2fb6394675d73.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b3/b345cd0fb7722573433afc4230e35d3a.png\" /></p><p></p><h2>2.2 使用</h2><p></p><p></p><p>有了上述的基本概念，我们将策略模式的使用步骤概括为：</p><p></p><p>step1：创建抽象策略类，为具体策略定义好一个公共接口；step2：创建具体策略类，其通过接口来实现抽象策略类，同时封装了具体的算法；step3：创建环境类，持有一个抽象策略类的引用，提供给客户端调用。</p><p></p><p></p><h1>三、使用示例</h1><p></p><p></p><p>除了双11购物狂欢节，每年都会打造很多其他的促销活动。试想一下，如果每种大促活动都使用一种促销模式，未免太过枯燥，于用户、商家、平台而言都不友好。因此，为了提升用户购买体验、突出商家营销特点，需要面向不同大促活动使用不同的策略进行促销。这里以促销策略为例，简单分析策略模式如何使用。</p><p></p><p></p><h2>3.1 代码实现</h2><p></p><p></p><p><code lang=\"text\">//step1:定义抽象策略角色（Strategy）：所有促销活动的共同接口\npublic interface Strategy {  \n    void show();\n}\n​\n//step2:定义具体策略角色（Concrete Strategy）：不同类型的具体促销策略\n//618大促活动 A\npublic class ConcreteStrategyA implements Strategy {\n    @Override\n    public void show() {\n        System.out.println(\"618大促\");\n    }\n}\n​\n//99大促活动 B\npublic class ConcreteStrategyB implements Strategy {\n    @Override\n    public void show() {\n        System.out.println(\"99大促\");\n    }\n}\n​\n//双11大促活动 C\npublic class ConcreteStrategyC implements Strategy {\n    @Override\n    public void show() {\n        System.out.println(\"双11大促\");\n    }\n}\n​\n//step3:定义环境角色（Context）：把促销活动推送给用户，这里可理解为淘宝平台\npublic class Context{\n    //持有抽象策略的引用\n    private Strategy myStrategy;\n    //生成构造方法，让平台根据传入的参数（type）选择促销活动\n    public Context(Strategy strategyType) {\n        this.myStrategy = strategyType;\n    }\n    //向用户展示促销活动\n    public void taoPlatformShow(String time) {\n        System.out.println(time + \"的促销策略是:\");\n        myStrategy.show();\n    }\n}\n​\n//step4:客户端调用,需事先明确所有每种策略类如何使用\npublic class StrategyPattern{\n  public static void main(String[] args){\n        Context_TaoPlatform context;\n    \n        String time1 = \"9月\";\n        Strategy strategyB = new ConcreteStrategyB();\n        context = new Context(strategyB);\n        context.taoPlatformShow(time1);\n    \n        String time2 = \"11月\";\n        Strategy strategyC = new ConcreteStrategyC();\n        context = new Context(strategyC);\n        context.taoPlatformShow(time2);\n    \n        String time3 = \"6月\";\n        Strategy strategyA = new ConcreteStrategyA();\n        context = new Context(strategyA);\n        context.taoPlatformShow(time3);\n  }   \n}</code></p><p></p><p></p><h2>3.2 结果输出</h2><p></p><p></p><p><code lang=\"text\">9月的促销策略是：\n99大促\n11月的促销策略是：\n双11大促\n6月的促销策略是：\n618大促</code></p><p></p><p></p><h2>3.3 UML图</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/17/170a1b20f7352bc7d952f9a874470619.png\" /></p><p></p><p></p><h2>3.4 与简单工厂模式的区别</h2><p></p><p></p><p>从上面的代码示例及类图可以看出来，策略模式和上一篇文章中介绍的简单工厂模式很像，两者主要区别在于Context类和工厂类。为了方便对比，我们把这两个类的代码单独拎出来看看：</p><p></p><p><code lang=\"text\">public class Context_TaoPlatform{\n    //持有抽象策略的引用\n    private Strategy myStrategy;\n    //生成构造方法，让平台根据传入的参数（type）选择促销活动\n    public TaoPlatform(Strategy strategyType) {\n        this.myStrategy = strategyType;\n    }\n    //向用户展示促销活动\n    public void taoPlatformShow(String time) {\n        System.out.println(time + \"的促销策略是:\");\n        myStrategy.show();\n    }\n}</code></p><p></p><p><code lang=\"text\">public class Factory{\n    public static Shirt exhibit(String ShirtName){\n        switch(ShirtName){\n            case \"女款衬衫\":\n                return new WomenShirt();\n            case \"男款衬衫\":\n                return new MenShirt();\n            default:\n                return null;\n        }\n    }\n}</code></p><p></p><p>首先看一下接收参数：工厂类Factory中的exhibit()方法接收字符串，返回一个Shirt对象；环境类Context_TaoPlatform初始化时需要接收一个Strategy对象。也就是说：工厂类中是根据接收的条件创建一个相应的对象，而Context类接收的是一个对象，可以调用方法去执行此对象的方法。</p><p></p><p>举个例子：笔有很多种，假设有一个工厂专门负责生产不同用途的笔。</p><p></p><p>工厂模式：根据用户给出的目的来生产不同用途的笔，如：要写毛笔字就生产毛笔、要写钢笔字就生产钢笔。即根据用户给出的某种属性，生产能做出相应行为的一种对象返回给用户，重点在于创建何种对象。</p><p></p><p>策略模式：用工厂生产的笔去出做对应的行为，如：用毛笔写毛笔字、用钢笔写钢笔字。即根据用户给出的某种对象，执行相应的方法，重点在于选择何种行为。</p><p></p><p></p><h1>四、JDK源码赏析</h1><p></p><p></p><p>这里以Comparator比较器为例，通过分析其源码实现来深入理策略模式。</p><p></p><p>在JDK中，我们调用数组工具类Arrays的一个排序方法sort()时，可以使用默认的排序规则（升序），也可以自定义一种排序的规则，即自定义实现升序或降序的排序。源码如下：</p><p></p><p><code lang=\"text\">public class Arrays{\n    public static  void sort(T[] a, Comparator<!--? super T--> c) {\n        if (c == null) {\n            //若没有传入Comparator接口的实现类对象，调用默认的升序排序方法\n            sort(a);\n        } else {\n            if (LegacyMergeSort.userRequested)\n                //jdk5及之前的传统归并排序，新版本中LegacyMergeSort.userRequested默认false\n                legacyMergeSort(a, c);\n            else\n                //改进后的归并排序\n                TimSort.sort(a, 0, a.length, c, null, 0, 0);\n        }\n    }\n}</code></p><p></p><p>此时我们需要传入两个参数：一个是待排序的数组，另一个则是Comparator接口的实现类对象。其中，Comparator接口是一种函数式接口，该接口中定义了一个抽象方法int compare(T o1, T o2)，用于定义具体的排序规则。这里Comparator接口就是策略模式中的抽象策略接口，它定义了一个排序算法，而具体策略（具体的排序算法）将由用户来定义，那么Arrays就是一个环境类，sort() 方法可以传入一个策略c ，让Arrays根据这个策略进行排序任务。</p><p></p><p><code lang=\"text\">public class demo {\n    public static void main(String[] args) {\n​\n        Integer[] data = {12, 2, 3, 2, 4, 5, 1};\n        // 实现降序排序\n        Arrays.sort(data, new Comparator() {\n             // 排序策略 降序\n            public int compare(Integer o1, Integer o2) {\n                return o2 - o1;\n            }\n        });\n        System.out.println(Arrays.toString(data)); //[12, 5, 4, 3, 2, 2, 1]\n    }\n}</code></p><p></p><p>在上面这个测试类中，我们在调用Arrays.sort()方法时，第二个参数传递的是Comparator接口的子实现类对象。由此可见，Comparator充当的是抽象策略角色，而具体的子实现类充当的是具体策略角色，环境角色类  Arrays应该持有抽象策略的引用来调用。那么，Arrays.sort()方法究竟有没有使用Comparator子实现类中的compare()方法？下面再看看TimSort.sort()方法，源码如下：</p><p></p><p><code lang=\"text\">class TimSort {\n    static  void sort(T[] a, int lo, int hi, Comparator<!--? super T--> c,\n                         T[] work, int workBase, int workLen) {\n        assert c != null &amp;&amp; a != null &amp;&amp; lo &gt;= 0 &amp;&amp; lo &lt;= hi &amp;&amp; hi &lt;= a.length;\n​\n        int nRemaining  = hi - lo;\n        if (nRemaining &lt; 2)\n            return;  // Arrays of size 0 and 1 are always sorted\n​\n        // If array is small, do a \"mini-TimSort\" with no merges\n        if (nRemaining &lt; MIN_MERGE) {\n            int initRunLen = countRunAndMakeAscending(a, lo, hi, c);\n            binarySort(a, lo, hi, lo + initRunLen, c);\n            return;\n        }\n        ...\n    }   \n        \n    private static  int countRunAndMakeAscending(T[] a, int lo, int hi,Comparator<!--? super T--> c) {\n        assert lo &lt; hi;\n        int runHi = lo + 1;\n        if (runHi == hi)\n            return 1;\n​\n        // Find end of run, and reverse range if descending\n        if (c.compare(a[runHi++], a[lo]) &lt; 0) { // Descending\n            while (runHi &lt; hi &amp;&amp; c.compare(a[runHi], a[runHi - 1]) &lt; 0)\n                runHi++;\n            reverseRange(a, lo, runHi);\n        } else {                              // Ascending\n            while (runHi &lt; hi &amp;&amp; c.compare(a[runHi], a[runHi - 1]) &gt;= 0)\n                runHi++;\n        }\n        return runHi - lo;\n    }\n}</code></p><p></p><p>上面的代码最后会执行到countRunAndMakeAscending()方法中，在执行判断语句时调用了compare()方法。那么如果只用了compare()方法，在调用Arrays.sort()方法时只要传具体compare()重写方法的类对象。</p><p></p><p></p><h1>五、优缺点及适用场景</h1><p></p><p></p><p></p><h2>5.1 优点</h2><p></p><p></p><p>具体策略类之间可自由切换，由于具体策略类都实现同一个抽象策略接口，所以它们之间可以自由切换。支持“开闭原则”，扩展增加一个新策略时只需添加一个具体策略类即可，基本不需要改变原有的代码。避免使用多重条件选择语句（if else），充分体现面向对象设计思想。</p><p></p><p></p><h2>5.2 缺点</h2><p></p><p></p><p>客户端必须知道所有的具体策略类，并理解不同具体策略的区别、自行决定使用哪一个策略类。策略模式将产生很多具体策略类，在一定程度上增加了系统中类的个数（可通过使用享元模式在一定程度上减少对象数量）。</p><p></p><p></p><h2>5.3 适用场景</h2><p></p><p></p><p>一个系统需要动态地在几种算法中选择一种时，可将每个算法封装到具体策略类中。一个类定义了多种行为，并且这些行为在这个类的操作中以多个条件语句的形式出现，可将每个条件分支移入它们各自的策略类中以代替这些条件语句，就能避免使用难以维护的多重条件选择语句，并体现面向对象涉及的概念。系统中各算法彼此完全独立，且要求对客户隐藏具体算法的实现细节，提高算法的保密性与安全性。多个类只区别在表现行为不同，可以使用策略模式，在运行时动态选择具体要执行的行为。</p><p></p><p></p><h1>六、总结</h1><p></p><p></p><p>策略模式是一个比较容易理解和使用的设计模式，它仅封装算法，方便新算法插入系统中、老算法从系统中退休。本文在分析策略模式的缺点时提到，策略模式并不决定在何时使用何种算法，算法选择由客户端来决定，虽然这在一定程度上提高了系统的灵活性，但客户端需要理解所有具体策略类之间的区别，以便选择合适的算法，增加了客户端的使用难度。</p><p></p><p>策略模式和工厂模式有一定相似之处，在于它们的模式结构，因此有时候会让人混淆不清。实际上，这两者之间存在较多差异：工厂模式是创建型模式，作用是创建对象，它关注对象如何创建，主要解决的是资源的统一分发，将对象的创建完全独立出来，让对象的创建和具体的使用客户无关；策略模式是行为型模式，作用是让一个对象在许多行为中选择一种行为，它关注行为如何封装，通过定义策略族来实现策略的灵活切换与扩展，并让策略的变化独立于使用策略的客户。</p><p></p><p>另外，很多场景下策略模式和工厂模式可以结合使用，共同发挥优势起到相辅相成的作用。比如，策略模式的缺点之一是用户必须清楚所有的具体策略算法，这样具体策略难免暴露出去，并且要由上层模块初始化，这与迪米特法则相悖（最少知识原则），而上层模块和底层模之间的解耦，可以让工厂模式来完成。两者结合之后，对于上层模块而言不需要知道每种具体策略，只要通过Context就可以实现策略模式。</p>",
    "publish_time": "2023-06-01 11:34:34",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "用大模型自动做笔记、提取PPT、整理访谈，阿里云AI新产品“通义听悟”开放公测",
    "url": "https://www.infoq.cn/article/4cPPoYQh4LjQxQ2LG3P2",
    "summary": "<p>6月1日，阿里云宣布通义大模型进展，聚焦音视频内容的AI新品“通义听悟”正式上线，开放公测。公测期间，用户可领取100小时以上听悟免费转写时长。</p><p></p><p>继史无前例的大降价后，阿里云送出人人都能用上的AI“大礼包”。此前国内语音厂商AI转写定价达19.8元每小时，而听悟用户可通过每日登陆等多种任务领取免费转写时长。公测期间，阿里云官方微博、微信及各大平台社区还会发放大量20小时转写口令码，用户获得的福利权益可累加，一年内有效，免费时长可高达100小时以上，市场价值上千元。</p><p></p><p>据悉，通义听悟接入了通义千问大模型的理解与摘要能力，可成为用户工作学习中的得力AI助手，帮助随时随地高效完成对音视频内容的转写、检索、摘要和整理，比如用大模型自动做笔记、整理访谈、提取PPT等。</p><p>&nbsp;</p><p>“换一种方式，让音视频可以被轻松阅读、整理和分享。”阿里云CTO周靖人介绍，听悟是一款工作学习AI助手，它瞄准具有高知识附加值的音视频内容场景，比如开会、上课、访谈、培训、面试、直播、看视频、听播客等，能通过大模型等最新AI技术快速提炼和沉淀知识。&nbsp;&nbsp;&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6e/6e269340cdae42e9f79d59040c6ca661.png\" /></p><p></p><p>据悉，听悟融合了十多项AI功能，可以全面提升知识从音视频向图文形态转化的效率。除了“听力好”，能高准确度生成会议记录、区分不同发言人，这个AI助手“悟性也高”，大模型可以一秒给音视频划分章节并形成摘要、总结全文及每个发言人观点、整理关注重点和待办事项。大模型一键提取PPT、针对多个音视频内容向AI提问、概括特定段落等功能近期也将上线。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/41/41b1ea1eed6865d127861616b096d901.png\" /></p><p>通义听悟可自动为音视频生成全文摘要、章节概括、发言总结</p><p>&nbsp;</p><p>针对一些细分场景，听悟还设置了不少“宝藏功能”：打开Chrome插件，外语学习者和听障人士可以借助双语悬浮字幕条随时随地看无字幕视频，日程冲突时，听悟还可成为职场人士的“开会替身”，在静音情况下入会AI可代为记录会议、整理要点；转写结果可下载为字幕文件，方便新媒体从业者视频后期制作；听悟梳理的问答回顾可以让记者、分析师、律师、HR等群体整理访谈更高效。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/63/63cc804911ab4a5514effaf2a17078ce.png\" /></p><p>通义听悟Chrome插件将在近期对所有用户开放下载</p><p>&nbsp;</p><p>此外，听悟与阿里云盘打通，一键就能转写云盘上的音视频内容，公测期间注册的听悟用户后续还将获得更大的阿里云盘存储空间，在云盘内在线播放视频时也可自动出字幕。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/35/35581c4b0552ebc37aceb535cefc31bd.png\" /></p><p>通义听悟支持一键导入阿里云盘音视频文件</p><p>&nbsp;</p><p>周靖人介绍，听悟集成了阿里最先进的语音和语言技术。其内置阿里新一代工业级语音识别模型，识别准确率在多个权威中文数据集上名列第一；融合自研语音语义多模态说话人算法，能对10人以上说话场景进行角色区分；接入通义千问大模型后，能够对上万字的音视频内容进行摘要总结，事实准确与要点完备性国内领先，支持跨多音视频内容的精准问答理解。</p><p>&nbsp;</p><p>据了解，听悟除个人版本外，还有企业应用。此前，听悟企业版已在阿里集团内部被广泛使用，帮助减少了大量会议记录和整理的工作，受到好评。同时，听悟的能力也可嵌进各类音视频平台，形成实时字幕、智能摘要等，典型应用如钉钉的“钉闪记”背后便集成了听悟。未来听悟还将在夸克APP、阿里云盘等端口提供服务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7b/7b64431ec8ca1562311e7a5980f48a04.png\" /></p><p>“钉闪记”背后集成通义听悟</p>",
    "publish_time": "2023-06-01 11:36:50",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "防止AI胡说八道！OpenAI公布最新大模型训练方法，监督AI像人类一样思考",
    "url": "https://www.infoq.cn/article/RL7iFW2SqO0Ppv4msCsL",
    "summary": "<p></p><blockquote>当 AI 一本正经地胡说八道时，需要用“魔法”打败“魔法”。</blockquote><p></p><p></p><h2>OpenAI正寻求新方法对抗“AI幻觉”</h2><p></p><p></p><p>据 CNBC 报道，本周三，<a href=\"https://www.infoq.cn/article/3TR13Qp694BJ8TeOi1xV\">OpenAI</a>\" 宣布计划采取一种新的AI模型训练方法，以解决“AI幻觉”难题。</p><p></p><p>“AI幻觉”指的是聊天机器人用编造的信息进行回应，这是AI的自信反应。当模型有“幻觉”（输出欺骗性数据的倾向）时，其使用的的训练数据并不能证明输出的合理性。比如，ChatGPT或Bard等模型有时看似在滔滔不绝陈述事实，但实际内容却是“一本正经胡说八道”。</p><p></p><p>OpenAI研究人员在报道中写道，“**即使是最先进的模型也很容易生成虚假信息——在不确定情况时，它们往往表现出捏造事实的倾向。**这种幻觉在需要多步推理的领域尤其严重，其中一个环节上的逻辑错误就足以破坏整个解答过程。”</p><p></p><p>OpenAI为幻觉问题提出了新的策略：在AI模型训练当中设置新的奖励机制，不仅奖励其获得正确的最终结论，更要奖励它们在得出答案的过程中做出的每个正确推理步骤。</p><p></p><p>研究人员表示，这种方法被称为**“过程监督”**，而非“结果监督”。由于能够鼓励模型更多遵循人类的“思维”方法链，所以过程监督方法也许能提高AI输出的可解释性。</p><p></p><p>OpenAI公司数学生成（mathgen）研究员Karl Cobbe在采访中指出，“检测和缓解模型中的逻辑错误或者幻觉，将是构建高一致性AGI（通用人工智能）的关键一步。”虽然OpenAI之前没有发明出过程监督方法，但如今亡羊补牢，为时未晚。“这项研究的动机在于解决幻觉问题，使得模型具备解决挑战性推理问题的强大能力。”</p><p></p><p>Cobbe还提到，OpenAI已经发布一套附带数据集，其中包含80万个人类标注，用于训练研究论文中描述的这套模型。</p><p></p><h2>解决“AI幻觉”难题任重道远</h2><p></p><p></p><p>随着AI技术得到广泛应用，“AI幻觉”带来的潜在问题也开始浮现，并引发大众担忧。</p><p></p><p>以谷歌2月发布<a href=\"https://www.infoq.cn/article/ZYGe5iB6eDSZhuJEJxUa\">Bard</a>\"时的宣传为例，这款聊天机器人对詹姆斯·韦伯太空望远镜做出了错误描述。最近，ChatGPT又在纽约联邦法院一份文件中引述了“不存在的”案件，涉案律师可能因此面临处罚。</p><p></p><p>美国律师Steven A. Schwartz向ChatGPT求助，想要为自己诉哥伦比亚国家航空一案找点支持案例，ChatGPT却给出了根本不存在的判例建议。Schwartz声称他“没有意识到ChatGPT给出的内容可能是假的”。但从他跟机器人的聊天记录来看，他还是保持了一丝怀疑，想要进一步检查这些信息。但很遗憾，他选择询问ChatGPT来确认内容真实性，系统则再次做出误导，向他保证这些虚构判例完全真实合法。</p><p></p><p>此前在接受《纽约时报》采访时，OpenAI 的联合创始人 Ilya Stutskever曾坦言AI幻觉是个大问题，但很有可能被“治愈”：我们现在的做法是雇人教会 ChatGPT 如何表现。你只需要与它互动，它就能从你的反应中推断出你想要的东西，比如，你对输出结果不满意。因此，它应该在下一次做些不同的事情。我认为这种方法很有可能（a quite a high chance）完全解决幻觉的问题。</p><p></p><p>随着OpenAI 最新AI模型训练方法的公布，如何解决“AI幻觉”难题再次引发讨论。</p><p></p><p>电子隐私信息中心高级顾问兼AI与人权项目负责人Ben Winters对OpenAI的训练方法表示怀疑，称实际效果要在检查了完整的数据集和随附示例后才能确定。</p><p></p><p>Winters强调，“我只是觉得单凭这一种措施，不足以在实际应用场景当中显著降低AI生成错误信息和不正确结果的问题……另外，他们会不会把研究成果全面纳入产品也非常重要。如果不是，这反而会引发其他严重问题，比如操纵模型有选择地向公众发布信息。”</p><p></p><p>考虑到还不清楚OpenAI论文有没有经过同行评审或者其他形式的评审，布朗大学技术责任中心主任Suresh Venkatasubramanian认为这项研究的意义更多在于初步观察，而非实际应用。</p><p></p><p>Venkatasubramanian指出，“在对此给予肯定之前，首先得等待这项成果在研究领域得到证实。这个世界上，很多结果总会定期出现。因为大语言模型的工作方式总体上并不稳定，所以在某一种设置、模型和上下文中起效的东西，很可能在另一种设置、模型和上下文中毫无作用。人们最担心的「幻觉」，其实是模型可能捏造的引用和参考资料。但文中没有能解决这个问题的证据。……我不是说一定解决不了，只是说这篇论文缺乏相关证据。”</p><p></p><h2>在强调ChatGPT局限性方面，OpenAI做得还不够</h2><p></p><p></p><p>OpenAI能够意识ChatGPT的“AI幻觉”问题，但在强调ChatGPT局限性方面，OpenAI做得还不够。</p><p></p><p>在ChatGPT的主页上，OpenAI发布的一条警告内容称“可能偶尔会产生不正确信息”，这也是其系统功能和局限性部分的九条须知之一。但这条警告内容放在任何信息源上都同样适用，对于ChatGPT这样一种强大、身处炒作大潮的风口浪尖且容易被严重误解的技术成果，OpenAI在引导用户方面做得还远远不够，OpenAI应该投入更多精力，明确强调ChatGPT无法稳定区分事实和“幻觉”。</p><p></p><p>据The Verge报道，过去几个月间，很多人都被ChatGPT的“胡说八道”所愚弄和影响。值得庆幸的是，大多数案例都微不足道，几乎没有造成负面冲击，ChatGPT最多也就是捏造了一篇新闻报道、一篇学术论文或者一本不存在的书。但在个别案例中，ChatGPT的错误信息确实可能引发严重后果。</p><p></p><p>今年5月，得克萨斯州农工大学的一位教授就使用聊天机器人检查学生是不是在靠AI写水文章。ChatGPT倒是非常热情，表示所有论文都是由AI生成的，但却拿不出什么真凭实据。教授深信不疑而且大为光火，威胁要让学生们挂科甚至毕不了业，好在最终大家发现了这个错误。</p><p></p><p>这些事件并不会彻底毁掉人们对于ChatGPT等聊天机器人的期待和认可。只要配合正确的场景和适当的保护措施，这些AI工具仍然能在信息检索等任务中发挥巨大作用。目前也有各种有趣的研究正在推进，表明此类系统也许能在未来更好地尊重客观事实。</p><p></p><p>但当下，这类AI产品的局限性需要引起人们足够的重视。企业需要向大众强调AI产品的局限性，媒体也需要承担相应的报道责任。</p><p></p><p>干预措施并不需要特别复杂，但必须得有。比如，为什么ChatGPT无法识别用户想要的是事实性依据，并提醒对方“请注意检查信息来源”？在用户要求它判断特定文本是否由AI生成时，ChatGPT为什么就不能明确表示“对不起，我没有能力做出判断”？</p><p></p><p>当然，OpenAI一直在努力改进这些问题。自ChatGPT推出以来，它已经变得越来越坦率、会直言自己存在局限性。最经典的表述就是“作为一个AI语言模型，我……”。但不一致问题仍然存在，比如，当问它“你能检测出AI生成的文本吗？”它回答说“检测结果不一定准确。”但向它输入了一大段内容，并提出同样的问题时，它只是简单回答“是的，这段文字是由AI生成的。”</p><p></p><p>此外，当要求ChatGPT提供一份测量专业书籍推荐清单时，它给出的答案共有10本书，其中不少质量很高，但有2本则是完全虚构的。如果不是在刻意检查，可能根本就不会注意到这个问题。当用户和ChatGPT交流多了，并且验证后就会发现，ChatGPT这类AI产品经常“胡说八道”。</p><p></p><p>面对这样的现状，“可能偶尔会产生不正确信息”之类的免责声明显然远远不够。</p><p></p><p>参考链接：</p><p></p><p><a href=\"https://www.cnbc.com/2023/05/31/openai-is-pursuing-a-new-way-to-fight-ai-hallucinations.html\">https://www.cnbc.com/2023/05/31/openai-is-pursuing-a-new-way-to-fight-ai-hallucinations.html</a>\"</p><p><a href=\"https://www.theverge.com/2023/5/30/23741996/openai-chatgpt-false-information-misinformation-responsibility\">https://www.theverge.com/2023/5/30/23741996/openai-chatgpt-false-information-misinformation-responsibility</a>\"</p>",
    "publish_time": "2023-06-01 14:36:38",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "先别急着“用Rust重写”，可能没有说的那么安全",
    "url": "https://www.infoq.cn/article/owKFXuJPdF86O0D5wR6C",
    "summary": "<p></p><blockquote>如果各位朋友还没试过 Rust，这里建议您——赶紧去试！还没用过 Rust cat、grep 和 find？不开玩笑，“一试倾心”说的就是 Rust。太忙了，没时间？不行，这事特别重要，一定要用 Rust 把原有代码资产重写一遍！一次重写，终身受益。你的系统将更快、更安全！</blockquote><p></p><p></p><p>上面的描述是不是感觉有些熟悉？没错，最近一段时间，“用 Rust 重写”正在以传销般的方式席卷整个开发领域。据说当前因内存缺陷引发的浏览器和内核漏洞占比高达 60% 到 70%，于是系统开发者们越来越倾向选择内存安全语言，更具体地讲，转向 <a href=\"https://www.infoq.cn/article/o2QRFPElEpOgvLPe5qzI\">Rust</a>\"。</p><p></p><p>这是因为 Rust 承诺又快又安全，能针对低级系统实现必要的抽象类型，包括与操作系统的交互、底层内存管理和并发性等。这些天然优势再辅以生态工具支持，共同让 Rust 发展壮大，成为<a href=\"https://www.infoq.cn/article/svgbVIxXhcDF5MQVk3Tv\">亚马逊</a>\"和<a href=\"https://www.infoq.cn/article/UpEHUe43yhWZaictYG0u\">谷歌</a>\"等科技大厂的宠儿。</p><p></p><p>诚然，Rust 有不少独特优势，但它的类型也着实令人头痛。一旦搞错，我们就得被迫退回到 C，反而失去了重写想要追求的结果。</p><p></p><h3>用 Rust 重写的问题</h3><p></p><p></p><p>很多朋友并不清楚，单纯用内存安全语言重写大型 C/C++ 系统组件只会引入额外的攻击面：新组件和现有代码间的外部函数接口（FFI）。实际上，与 Rust 交互会让情况变得更糟。这里考虑以下 C 函数代码：</p><p></p><p><code lang=\"cs\">1 void add_twice(int *a, int *b) {\n2  *a += *b;\n3  *a += *b;\n4 }\n</code></p><p></p><p>这部分有点奇怪，它会对整型指针就地执行算术运算，所以我们才希望把它重写为更安全的 Rust 形式：</p><p></p><p><code lang=\"properties\">#[no_mangle]\npub extern \"C\"\nfn add_twice(a: &amp;mut i32, b: &amp;i32) {\n4  *a += *b;\n5  *a += *b;\n6 }\n</code></p><p></p><p>但遗憾的是，Rust 和 C 对于其中的 a 和 b 分别做出了不同假设，而且从 C 调用 add_twice(&amp;bar, &amp;bar) 会导致未定义行为。这是因为 Rust 编译器会将 add_twice 优化成a += 2*b。（在 Rust 中，a 和 b 不允许存在别名）。另外，这种优化会引入新的内存不安全错误。如果 C 程序使用 add_twice 来更新内存相关数据（例如将缓冲区的大小加倍 2 次），则“安全”Rust 函数其实比原本的“不安全”C 函数更糟糕。</p><p></p><p>这个例子之所以值得关注，是因为原始 C 代码和 Rust 代码都通过了各自的编译器，没有任何报错。然而，C 和 Rust 代码联合体静默调用了未定义的行为，结合具体的架构、Rust 版本和 LLVM 版本，这有可能引发内存安全问题。</p><p></p><p>在实践当中，这个问题不涉及人为因素，而且很难加以预防。</p><p></p><p>从本质上讲，Rust 和 C/C++ 是不能直接交互的——它们在类型、内存管理和控制流方面都采取了截然不同的方法。结果就是，如果手动编写“胶水”代码，就很可能打破隐式假设（例如调用约定和数据表示）、关键不变量（例如内存和类型安全、同步和资源处理协议），并跨过语言边界引入未定义的行为错误，例如展开恐慌（unwinding panics）、整型表示错误、为枚举和标记的联合体类型静默创建无效值等。</p><p></p><p>其实这个问题不仅困扰 Rust，FFI 是出了名的棘手且极易引发错误，即使 Rust 也难以将其“驯服”。这种不安全性其实不可避免，而且开发者目前缺乏编写安全 FFI 的基础性技术和工具，因此贸然使用 Rust 重写代码可能会引入新的错误和漏洞。</p><p></p><p>下面，我们将着眼于现实场景下用 Rust 重写大型 C/C++ 系统组件的案例，并聊聊开发者在编写 FFI 代码时可能引入哪些新的类型错误和问题。</p><p></p><p>Rust 和 C 间的不匹配，往往导致 FFI 边界处出现大量不安全代码——这令开发者很难安全将组件移植为 Rust 形式。更要命的是，哪怕是精通 Rust 和 Modula 3 系统架构的开发者，也几乎无法回避这些麻烦。</p><p></p><p>当然，Rust 绝不是不能用，也有像𝑅³这类细化类型系统扩展 Rust FFI 的边界，两者相结合足以消除验证工具所带来的各种规范和证明负担，同时几乎解决了 FFI 错误，真正让 Rust 发挥其内存安全优势。</p><p></p><h3>具体有哪些安全问题</h3><p></p><p></p><p>在本节中，我们将具体探讨在实际场景下将 C/C++ 组件移植至 Rust 所引发的安全漏洞。因为我们主要关注 FFI 层的 bug，所以暂不讨论 C/C++ 代码中那些不影响移植代码的原始 bug。换言之，我们假定原始代码本身符合内存安全要求，只考虑两段代码间 FFI 层处可能出现的内存不安全和未定义行为。</p><p></p><p>我们假定开发者是出于善意而移植代码，只是因移植 bug 而将格式错误或 bug 传递给了 FFI，例如指针和缓冲区长度的不正确值。由于 C/C++ 程序和 Rust 库之间会共享内存，所以对于来自 Rust 库的此类输入的任何不正确处理，都可能在整个程序中引发内存安全错误。</p><p></p><p>我们分析了两个网络协议库的 Rust 实现，分别为 TLS 库 rusTLS 和 HTTP 库 Hyper，以及二者的 FFI。这些库及其 C 绑定都处于活跃开发状态，目前已被集成在 Curl 当中，完全可以作为 C-Rust FFI 的理想研究案例。我们还考虑了其他一些项目：Encoding_C，一个编码标准的 Rust 实现，用于取代 Firefox 中的 C++ 实现；Ockam，一个安全的端到端通信库；Artichoke，Ruby 语言的 Rust 实现；以及 Rust 语言团队发现的其他一些核心挑战。</p><p></p><p>我们将本节内的问题划分成以下几类：首先是内存时空安全；其次是异常问题中的一类常见错误——跨 FFI 边界展开堆栈属于未定义行为，因此可能构成难以察觉的严重故障；第三是类型安全和 Rust 关键不变量相关的错误，包括别名、指针安全假设和引用可变性。最后，我们还将讨论其他几类未定义行为。</p><p></p><h4>时空安全问题</h4><p></p><p></p><p>Rust、C 和 C++ 采用的内存管理方法存在着本质区别。Rust 的类型系统会静态跟踪对象的生命周期和所有权，C 语言要求程序员手动管理内存，而 C++ 虽然提供内存安全抽象，但也允许自由将其与原始指针加以混合。</p><p></p><p>更重要的是，在将 C/C++ 系统迁移至 Rust 时，开发者必须通过 FFI 层来协调这些差异，其困难程度可见一斑。例如，跨 FFI 边界共享指针会引发跨语言内存管理问题，其中一种语言分配的指针会被另一种语言所释放。而当 C 和 Rust 代码试图共享内存所有权时，情况将变得更为复杂。</p><p></p><p>rusTLS 允许客户端创建证书验证器，并在服务器配置间共享这些验证器。为了实现共享，rusTLS 会使用原子引用计数器（Arc）来表示这些验证器，以便在不再引用验证器时自动回收相应的内存。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/83/8332c63fc2525c0ce6385bdfc0bf9ca3.png\" /></p><p></p><p>C/C++ 与 Rust 交互时可能引发的几种内存安问题类型</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/df/dfd5c31dbf9195a1455642f48794e968.png\" /></p><p></p><p>图一：rusTLS FFI 函数中的安全问题示例。异常安全：（1）如果克隆操作耗尽内存，则可引发跨 FFI 边界展开。时间安全：（2）和（3）可能因不正确的函数参数或重复函数调用而导致 use-after-free 和 double-fee 错误。</p><p></p><p>因为 rusTLS 会通过其 FFI 公开指向这些对象的指针，所以需要过图一中的 rustls_client_cert_verifier_free 函数将其显式弃用。该函数会以不安全方式从原始指针重建 Arc 引用并立即将其删除，从而减少引用计数。更重要的是，这个函数的期望计数为 1（即调用方的副本），所以如果使用得当，这个函数应该会同时删除指针引用的对象。但调用方可能会滥用该函数，例如两次释放同一指针或重新使用释放过的指针，因此导致引用计数错误，最终在 rusTLS 本应“安全”的部分引入 double-free 和 use-after-free 漏洞。</p><p></p><p>目前 rusTLS 还无法检测到 double-free：读取“freed”Arc 引用的计数会首先触发未定义行为 [rustls-#32]。此外，TLS 库的 C 实现不一定会依靠特定 API 来释放这些对象（及其引用的对象），而可能仅要求客户端使用标准的 free 函数。在系统直接用 rusTLS 替换此类 C 实现，很容易引发跨语言内存损坏并在系统中引入新的内存漏洞。</p><p></p><h4>异常安全</h4><p></p><p></p><p>Rust 会通过展开堆栈并在过程中调用析构函数（destructor）的方式来处理不可恢复的错误（通常用 panic! 宏或者任意数量的 panicing 函数调用来表示，例如 unwrap 或整数加法）。请注意，跨 FFI 边界的展示会被认定为未定义行为。</p><p></p><p>尽管目前 Rust 社区还存在争论，但 FFI 确实应明确处理恐慌（panic）以保证异常安全——理想情况下，应将故障告知调用方。但 Rust 并未为此提供任何特殊支持，因此实际效果完全取决于开发者是否在代码中强制执行安全保障。</p><p></p><p>例如，rusTLS 会通过 ffi_panic_boundary! 宏打包易出错的顶级外部（参见图一），它会捕捉一切展开的 panic 并将默认值返回给调用方。由于 Rust 中的许多基础操作都可能引发崩溃，因此极易错误必要的处理过程。至于显式 bug，请注意图一中的 rustls_client_cert_verifier_new 并不属于异常安全，因为对 RootCertStore 的克隆可能会触发未经处理的内存不足 panic 并跨 FFI 展开。</p><p></p><h4>Rust 不变量与类型安全</h4><p></p><p></p><p>Rust 代码往往高度依赖类型系统所保证的不变量，借此确保内存安全和代码正确性。由于 C/C++ 程序通常不遵循相同的不变量，因此 C/C++ 在与 Rust 代码交互时可能引发冲突，这类问题在重写后尤其多见。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/78/78199572e36546c44e3c45846b1e6726.png\" /></p><p></p><p>图二：来自 encoding_c 库的 FFI 函数可能受到无别名违规的影响。Rust 要求 src_slice 和 dest_slice 不能有码名，但代码本身不会对此做检查。</p><p></p><p>函数 decode_to （参见图二）将不可变切片（immutable slice）的内容解码成了可变切片（mutable slice）。Rust 别名规则将确保这些切片没有别名，从而实现编译优化。但通过不安全函数 fram_raw_parts 和 from_raw_parts_mu 重建切片时，decoder_decode_to_utf8 不会检查或保障这些条件。打包器会使用与 C 兼容的等效类型（指原始指针及其长度等效）替换缓冲区切片，从而导致类型别名。这可能引发 Rust FFI 中的未定义行为和 LLVM 的不合理优化。</p><p></p><h4>其他未定义行为</h4><p></p><p></p><p>还有其他一些更加“玄幻”的未定义行为，主要涉及不同语言的细节和架构 ABI（应用程序二进制接口）的特殊约定。</p><p></p><p>胶水代码。以上讨论示例中的一个常见问题，就是胶水代码需要使用不安全的 API 来重构 Rust 抽象。不安全函数的存在，导致安全责任从编译器被转移给了开发者，需要独立于应用程序之外重新设计这些接口，从而满足接口内必须包含的关键假设。然而，大多数此类假设（例如指针的生命周期、所有权和边界等）都无法在运行时上验证，Rust 也不提供检查所需的构造函数，因此 FFI 函数会以隐含方式信任调用方并假设输入有效。但这种信任明显站不住脚：FFI 代表着安全 Rust 组件同抽象 / 不受信代码间的边界。因此，调用方代码完全有可能传递无效输入并轻松击溃 Rust 的安全保障。这不仅令 Rust 重写丧失了安全保护意义，也给跨语言攻击创造了理想条件。ABI 兼容性。ABI 级优化同样可能在 C/C++/Rust 系统中引发问题，其中各组件是使用不同编译器和可能互不兼容的优化方式进行编译的。以 64 位架构为例，编译器可能将连续的 32 位函数参数打包进同一个 64 位寄存器内，借此减少寄存器压力。然而，如果相应的编译器不是以相同的方式打包函数输入，则跨语言函数调用可能会引发未定义行为。例如，虽然 C 的 size_t 和 Rust 的 u32 类型都是 32 位，但只有 C 编译器能同时对二者打包、rustc 就不行。</p><p></p><h4>结束语</h4><p></p><p></p><p>总之，随着 Rust 代码的日益普及，其他语言与 Rust 之间的交互也将同时创造新的攻击面，而目前我们手动编写的 Rust FFI 代码极易引入内存安全漏洞。期待能有好的方法和工具来帮助开发人员编写出安全的 FFI 代码，真正兑现 Rust 语言做出的安全保证和承诺。</p><p></p><p>原文链接：</p><p></p><p><a href=\"https://goto.ucsd.edu/~rjhala/hotos-ffi.pdf\">https://goto.ucsd.edu/~rjhala/hotos-ffi.pdf</a>\"</p><p></p><p>声明：本文为 InfoQ 翻译，未经许可禁止转载。</p><p></p><p>好文推荐</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651170615&amp;idx=1&amp;sn=fb774993f3de147d7378996c321759a3&amp;chksm=bdb85f648acfd672f9d2e75e5e2fb38f8eda1eb6b4ae7ace605685e9cf215e6eb8b93b5a9cca&amp;scene=21#wechat_redirect\">连代码都没写就敢要融资：被ChatGPT带火的向量数据库，带来了一大波造富神话</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651170429&amp;idx=1&amp;sn=b98af3bd14c9f97f1aa07f0f839bb3ec&amp;chksm=bdb85e2e8acfd738a998df3c66563cc2005b5db57c7057884645284650f0c2a8e47f8cfe01ac&amp;scene=21#wechat_redirect\">《2023 大语言模型综合能力测评报告》出炉：以文心一言为代表的国内产品即将冲出重围</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651170370&amp;idx=1&amp;sn=75256fb5d804d57c8387ff9914dab245&amp;chksm=bdb85e118acfd707fcb7d9a4c83ac1e158fa271b14abe573765299c894b71c8cc55ced6b0e02&amp;scene=21#wechat_redirect\">免费版“Github Copilot”，编程能力还翻倍？！谷歌硬刚微软，推出全新Colab编程平台</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651170234&amp;idx=1&amp;sn=efe169627d1a41fc773c86dc288bfdee&amp;chksm=bdb85de98acfd4ff4bf22db05d13cd3ed1cde112f3bd1c4fa1fd40b5fa70160c06e75c61a662&amp;scene=21#wechat_redirect\">百度回应 Bing 成中国桌面搜索第一；阿里回应大裁员传闻；文心一言市场负责人怒怼科大讯飞｜Q资讯</a>\"</p><p></p>",
    "publish_time": "2023-06-01 14:54:10",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "SeaTunnel毕业！首个国人主导的数据集成项目成为Apache顶级项目",
    "url": "https://www.infoq.cn/article/6f8aa42e9d769020ff1b58092",
    "summary": "<p></p><p></p><p></p><blockquote>北京时间 2023 年 6 月 1 日，全球最大的开源软件基金会 Apache Software Foundation（以下简称 ASF）正式宣布 Apache SeaTunnel 毕业成为 Apache 顶级项目(TLP, Top Level Project)。这是首个由国人主导并贡献到 ASF 的大数据集成领域的顶级项目，这一里程碑的达成标志着 SeaTunnel 在开源软件开发领域的突破，并为其在技术、社区合作和开放创新方面的卓越表现获得了广泛认可。</blockquote><p></p><p></p><p>Apache SeaTunnel 原名 Waterdrop，在 2021 年 10 月更名为 SeaTunnel 并申请加入 Apache孵化器。目前 Apache SeaTunnel 已发布 40+个版本，并在大量企业生产实践中使用，包括 J.P.Morgan、字节跳动、Stey、中国移动、富士康、腾讯云、国双、中科大数据研究院、360、Shoppe、Bilibili、新浪、搜狗、唯品会等企业，广泛应用于海量异构数据集成、CDC 数据同步，SaaS 数据集成以及多源数据处理等场景中。</p><p></p><p>2021 年 12 月 9 日， Apache SeaTunnel 以全票通过的优秀表现正式成为 Apache 孵化器项目。之后在导师 Jean-Baptiste Onofré、Kevin Ratnasekera、Willem Ning Jiang、 Ted Liu、Guo William、Zhenxu Ke、Lidong Dai 的指导下，由孵化器管理委员会成员进行辅导和孵化。</p><p></p><p>2023 年 5 月 17 日，Apache 董事会通过 Apache SeaTunnel 毕业决议，结束了为期 18 个月的孵化，正式确定 Apache SeaTunnel 成为 Apache 顶级项目。</p><p></p><p>Apache 官方博客发布了 Apache SeaTunnel 毕业的消息：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/82/82a63065f2e6af1f3120911482d71423.png\" /></p><p></p><p>图1：Apache 官网截图</p><p></p><h1>关于 Apache SeaTunnel</h1><p></p><p>Apache SeaTunnel 是新一代高性能、分布式、海量数据集成工具，支持上百种数据源 ( Database/Cloud/SaaS ) 支持海量数据的实时 CDC 和批量同步，可以稳定高效地同步万亿级数据。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1c/1c2772ff3c8318f61333c00af5b43d52.png\" /></p><p></p><p>图2：Apache SeaTunnel 技术架构图</p><p></p><p>作为超高性能分布式数据集成工具，Apache SeaTunnel 整体的特征和优势包括：支持上百种数据源、传输速度快、准确率高；降低复杂性，基于 API 开发的连接器能兼容离线同步、实时同步、全量同步、增量同步、CDC 实时同步等多种场景；简单易用，提供可拖拽和类 SQL 语言界面，节省开发者更多时间 ，提供了作业可视化管理、调度、运行和监控能力。加速低代码和无代码工具的集成 ；简单易维护，支持单机 &amp; 集群部署，如果选择 SeaTunnel Zeta 引擎部署，无需依赖 Spark、Flink 等大数据组件。</p><p></p><p>在社区发展方面，Apache SeaTunnel 在 ASF 孵化期间，从最开始的几万行代码发展到现在 25 万行代码，共计创建了 2920+ 个 PR，合并 2850+ 个 PR。目前，SeaTunnel 在 GitHub 上 Star 数达 5.1 k+，社区达到 5000+ 人规模，贡献者 180+ 人。</p><p></p><p>在用户方面，Apache SeaTunnel 现已广泛应用于互联网、金融、零售、出行、智能家居、云服务等各行各业中，在海量数据集成、实时异构数据同步、数据聚合以及多源数据聚集等场景中，可高效地处理数万亿条规模以上的数据。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b1/b1d4ac2ff11a63c0128415475a0cb5fc.png\" /></p><p></p><p>图3：Apache SeaTunnel 用户（部分）</p><p></p><h1>新起点，新征程！</h1><p></p><p>从刚开始寥寥无几的贡献者，到如今拥有庞大的用户群体和蓬勃发展的社区，Apache SeaTunnel 和其他从零开始的项目一样，经历的挑战和压力来自方方面面，包括技术架构重构 、开源社区协作等，正是在众多 SeaTunnel 贡献者日日夜夜的坚持和努力之下，Apache SeaTunnel 才得以顺利从 Apache 孵化器毕业，成为 Apache顶级项目(Top Level Project)。</p><p></p><p>SeaTunnel使命就是连通全球的各种数据源，让简单易用的海量数据同步的能力传播到全世界。</p><p></p><p>为了完成这个使命，在社区的共同努力之下，项目已经创下了许多重要里程碑，不仅获得了数百家企业用户的支持，在数据集成领域也广受认可。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c4/c4e9bfb43d37cbed3307c92d5def1c72.png\" /></p><p></p><p>图4：Apache SeaTunnel 发展里程碑</p><p></p><p>2017 年开源，项目开源，当时名为 Waterdrop，在腾讯、新浪等企业生产中使用；2021 年 12 月，进入 Apache 孵化器，并更名为 Apache SeaTunnel；2022 年 3 月，发布首个 Apache 版本，受到用户的热烈反响；2022 年 10 月，发布第一个重大版本 2.2.0，实现了 SeaTunnel Zeta 引擎，并完成跨引擎的连接器支持；2022 年 12 月支持重要功能 CDC 同步，连接器个数突破 100+；2023 年，实现支持 Flink 1.15 和 Spark 3，Zeta 引擎支持 CDC 整库同步和多表同步，以及 Schema Evolution 和自动建表等；2023 年 6 月 1 日，ASF 正式宣布 Apache SeaTunnel 毕业；......</p><p></p><p>未来，Apache SeaTunnel 还有更多目标等待实现......</p><p></p><p>18 个月的孵化中，Apache SeaTunnel 取得的进步肉眼可见，不断扩大的社区群体，不断提升的社群活跃度，来自老用户和新用户的信赖和认可，多次登上 GitHub Trending 榜单、引起 InfoQ、HackerNews 等技术媒体平台和媒体的热烈讨论和报道，都在见证着这个项目从小到大的发展。</p><p></p><p>在孵化期间，Apache SeaTunnel 也获得了诸多荣誉：</p><p></p><p>2022 年中国开源云联盟优秀项目开源中国 2022 年度优秀开源技术团队2022 年度 OSC 中国开源项目评选中被选为「中国开源社区健康案例」.......</p><p></p><p>在 ASF 的支持下，Apache SeaTunnel 团队通过开放协作和社区贡献，不断完善项目的技术和功能。在 7 位 Mentor 的帮助下，Apache SeaTunnel 社区共加入了 28 位 Commiter、18 位 PMC，也在社区的共同努力下发布了 8 个 Apache Releases。通过透明的开发过程和开源的代码管理，Apache SeaTunnel 项目在社区中获得了广泛的参与，共同克服了社区的建立和本土化、精力分配、团队协作和社区成长等重重困难和挑战，优化迭代项目自身的同时，也壮大了了社群的力量。感谢给予无私支持和帮助的各位导师、贡献者、用户以及 Apache 孵化器的支持。</p><p></p><p>成为 Apache 顶级项目对于 Apache SeaTunnel 来说意义重大。首先，ASF 的顶级项目是在社区共识和专家评审的基础上评定的，代表着项目在技术质量、社区治理和可持续性方面的卓越表现。Apache SeaTunnel 的成功毕业是对其社区不懈努力和创新精神的认可。</p><p></p><p>其次，成为 ASF 顶级项目将为 Apache SeaTunnel 带来更多的资源和支持。ASF 的全球社区将为 Apache SeaTunnel 项目提供开发者、用户和贡献者的广泛网络，促进项目的快速增长和可持续发展。Apache SeaTunnel 将获得 ASF 的品牌背书，进一步增强其在行业中的声誉和影响力。</p><p></p><p>最重要的是，Apache SeaTunnel 成为 ASF 顶级项目将进一步推动开源创新在数据集成领域的发展。SeaTunnel 项目通过开放的合作和共享知识，为数据集成解决方案提供了有价值的参考，其开源的代码和先进的技术将激发更多创新，并有望为全球数据集成技术带来积极变革。</p><p></p><p>然而，这也仅是 Apache SeaTunnel 新的起点，我们的征途是星辰大海！在此呼吁热衷于开源和致力于中国开源项目走向世界的同侪，让我们共同努力，把 Apache SeaTunnel 这样具有代表性的诞生于中国的优秀开源项目推向更广阔的国际舞台，让中国开源力量形成合力，让中国开源发扬光大！</p><p></p><h1>毕业寄语</h1><p></p><p>在这个重要的时刻，各大开源组织、友邻社区和我们的用户也纷纷发来了最真挚的祝福和对 Apache SeaTunnel 的厚望，在此感谢大家对于 Apache SeaTunnel 社区的大力支持(排名不分先后, 按收到时间排列)！</p><p></p><p>❤️温馨提示：文章末尾有福利活动，不要错过❤️</p><p></p><p>来自 Mentor 的寄语：</p><p></p><p>Congratulations on graduating from the Apache Software Foundation incubator! As the project champion, I am thrilled to see the progress SeaTunnel has made and the achievements SeaTunnel has accomplished during the incubation. During the incubation, SeaTunnel PPMC has demonstrated strong community-building skills, a commitment to open source best practices, and an ability to deliver quality software. These qualities are essential for any successful open source project and I have no doubt that you will continue to excel in these areas as a top-level Apache project. I am proud to have been a part of your journey and I look forward to seeing your continued success as a top-level Apache project. Congratulations once again and best of luck in your future endeavors!</p><p></p><p>—Willem Jiang，ASF Board Director &amp;ASF Incubator Mentor</p><p></p><p>First of all, I congratulate the SeaTunnel community for passing this important milestone of any open source project, which is becoming a Top level project for Apache. I have been part of this project as an Apache Incubator mentor, it is so gratifying to see the community growth achieved while following Apache ‘Community over Code’ practices. I am proud to say not only the SeaTunnel community was able to make major releases packed with features, most importantly they created such a welcoming environment for any new contributor who wishes to join the community. I wish very best for the next chapter of the project in the years to come and excel as one of leading open source projects in the Data Integration space.</p><p></p><p>—Kevin Ratnasekera，ASF Member / ASF Incubator Mentor</p><p></p><p>2021 年 12 月初，当 SeaTunnel 进入 ASF 项目孵化器时，我给了一段贺词 “初心涓滴成流 (Waterdrop) ，志向海纳百川 (SeaTunnel)”。十八个月之后，Apache SeaTunnel 顺利毕业成为 ASF 顶级项目，我的期许是：Apache SeaTunnel【启航星辰大海】!</p><p></p><p>—刘天栋 Ted，ASF Member, Incubator PMC &amp; Mentor</p><p></p><p>现在全球数据计算引擎，AI 引擎都在爆发式增长，SeaTunnel 项目解决了简单高效地将传统数据库、云存储、SaaS 等数据源输入到数据仓库、AI 和各种目标源当中，祝愿 SeaTunnel 成为顶级项目后真的实现“连接万源，同步如飞！”</p><p></p><p>—郭炜，ASF Member, Incubator PMC &amp; Mentor</p><p></p><p>来自开源组织的祝福：</p><p></p><p>It is a great honor to witness the journey of Apache SeaTunnel from entering the Apache incubator to graduating as an independent top Apache project. Community developers and contributors are really working hard to develop a steady stream, spreading awareness and onboarding more users. The project is on the road to a virtuous circle of development. I am hopeful that the project and its community will continue to add more value to society and the public through their efforts and contribution.</p><p></p><p>—Priya Sharma, Apache ComDev PMC member</p><p></p><p>恭喜 SeaTunnel 顺利毕业，毕业不代表着终点，在如今数据要素如火如荼的时代背景下，希望SeaTunnel 后续多多完善上下游开源软件的集成兼容，共同做大数据集成生态，帮助用户降低数据使用门槛。</p><p></p><p>—耿航，NextArch 基金会TOC、SODA 基金会 AC 委员、CCF 开源发展委员会执委</p><p></p><p>祝贺 SeaTunnel 顺利毕业，很高兴又见到来自中国的开源项目通过 Apache 软件基金会的孵化。Apache 软件基金会在开源文化传承、开源精神传播和开源项目孵化上对全世界有着突出的贡献，近年来 Apache 软件基金会的中国成员十分活跃，先后成立了 ALC 北京和 ALC 深圳社区，积极参与中国开源生态建设，持续促进产业发展。</p><p></p><p>衷心希望 Apache SeaTunnel 继承并发扬开源精神，在开放治理和开源合规领域成为其他开源项目的榜样，同时衷心祝愿 SeaTunnel 社区早日发展壮大，取得更大的商业成就。</p><p></p><p>—宋可为，中国开源软件推进联盟副秘书长、北京开源创新委员会常务副主任</p><p></p><p>祝贺 Apache SeaTunnel 顺利毕业！Apache SeaTunnel 曾经在孵化器讨论阶段就已经引起了诸多关注，在后面一年多的孵化过程中，大家都看到了 Apache SeaTunnel 的成长以及未来的潜力。毕业亦是新的起点，希望 Apache SeaTunnel 再接再厉，在数据处理领域书写属于自己的故事。</p><p></p><p>—红薯，开源中国创始人</p><p></p><p>来自友邻社区的祝福：</p><p></p><p>祝贺 Apache SeaTunnel 成功从 Apache 基金会毕业成为顶级项目，这意味着在产品打磨、社区建设、生态合作上都取得了良好的成果，祝愿 Apache SeaTunnel 不断成长，在数据集成场景中发挥更大的作用。</p><p></p><p>—乔嘉林，Apache IoTDB PMC、ASF Member</p><p></p><p>祝贺 Apache SeaTunnal 成功毕业，源自中国的 ASF 顶级项目又多了一员，这是一个非常值得庆祝的里程碑。作为一个优秀的数据集成开源项目，SeaTunnal 在孵化的过程中聚集开发者和用户，提供了丰富的数据集成能力，逐步创建了一个多元的社区。希望 SeaTunnal 未来能够继续保持优秀的表现，为开源社区带来更多的价值和贡献！</p><p></p><p>—张超，Apache InLong PMC Chair、腾讯大数据数据集成负责人</p><p></p><p>衷心祝贺 SeaTunnel 顺利毕业 ，成为 Apache 正式项目。这是对 SeaTunnel 团队能力和产品技术的认可，也对未来提出更高期望。感谢 SeanTunnel 同阿里云存储产品特别是对象存储，表格存储合作中的优异表现和快速响应。期待在未来帮助更多用户高效，安全，方便的进行数据流转，提升数据使用的效率，助力用户数据价值挖掘。</p><p></p><p>—蔡亮伟，阿里云智能资深产品运营专家</p><p></p><p>恭喜 SeaTunnel 顺利毕业成为Apache的正式项目，证明了 SeaTunnel 的产品品质得到了市场和开发者的充分认可，期待在数据库数据库集成、调度方面持续增强功能，特别是作为PolarDB 开源生态合作伙伴为云数据库 PolarDB 用户提供优质的产品体验。</p><p></p><p>—德哥，阿里云数据库 PolarDB 开源社区负责人</p><p></p><p>SeaTunnel 经过一年多的孵化，日前顺利从 Apache 孵化器毕业，成为又一个国人牵头主导的 Apache 顶级开源项目，代表了 Apache Way 以及开源文化在中国的崛起。祝 SeaTunnel 越走越远，不但支持更多数据同步特性，也能吸纳更多地区的社区贡献者，为各国用户创造更多价值。</p><p></p><p>—史少锋，Apache Kylin PMC Chair、ASF Member</p><p></p><p>恭喜 SeaTunnel 项目成功从 Apache 基金会毕业！SeaTunnel 在数据实时同步方面的表现给客户和生态伙伴留下深刻印象。此次 SeaTunnel 从 Apache 毕业是一个重要的里程碑，也是是所有社区成员、贡献者和支持者智慧的结晶。希望这个项目持续打磨和迭代，为更多的用户带来价值，在未来的发展中取得辉煌的成就！</p><p></p><p>—常雷，Apache HAWQ PMC Chair、偶数科技创始人兼CEO</p><p></p><p>恭喜 Apache SeaTunnel 顺利毕业。从最开始的 Connetor V1 到 V2，再到自研引擎，很高兴看到 SeaTunnel 在 Apache 孵化器中如此快速的发展。愿 Apache SeaTunnel 能够成为 DevOp 领域的中流砥柱，成为大数据领域不可或缺的一环。同时希望用户和开发者加入到 SeaTunnel 生态中，共赢互利。</p><p></p><p>—Mingyu Chen，ASF Member &amp; Apache Doris PMC Chair</p><p></p><p>Congratulations on the successful graduation of the Apache SeaTunnel project from the Apache Incubator and becoming one of the top-level projects of the ASF. Your hard work and dedication to open source and dev-eco have paid off, and we are thrilled to see the project reach this significant milestone. We wish you all the best in your future endeavors and look forward to seeing the continued growth and success of the Apache SeaTunnel project.</p><p></p><p>—Nadia Jiang, Co-Founder of Answer.dev, SegmentFault 思否 COO</p><p></p><p>祝贺 Apache Seatunnel 顺利毕业，迈过这个标志性的里程碑。祝 Apache Seatunnel 不断向前，社区不断壮大，越来越优秀，为开源爱好者提供更好的平台，为用户提供更大的价值。</p><p></p><p>—翟佳，Apache Pulsar PMC member，ASF Member</p><p></p><p>祝贺 Apache SeaTunnel 顺利毕业，Apache SeaTunnel 在过去的一年中茁壮成长，帮助大量用户很好的解决数据迁移问题。不仅如此，Apache SeaTunnel 在生态上下游上保持着非常开放的心态，和大量的上下游产品进行了深度的合作。Apache 毕业是完成在 Apache 成长过程中一个重要的里程碑，但也是一个新的起点，未来在数据流转上写下自己浓重的一笔, 也祝Apache SeaTunnel 未来更上一层楼。</p><p></p><p>—封仲淹(Longda Feng)，Apache Storm PMC &amp; OceanBase 开源负责人</p><p></p><p>Hurray! 🎊🎉Apache seaTunnel is now a top-level project!</p><p></p><p>Congratulations to the Apache SeaTunnel community on becoming a top-level project within the Apache Software Foundation! This remarkable achievement is a testament to the hard work, dedication, and innovation of the SeaTunnel community.</p><p></p><p>As Apache SeaTunnel continues to grow and develop, we wish it ongoing success in shaping the future of data integration and Synchronize. Keep up the fantastic work, and may the project continue to thrive and make a lasting impact in the open-source ecosystem!</p><p></p><p>—Surag v v，Digital Marketing Executive at styava.dev</p><p></p><p>恭喜 Apache SeaTunnel 顺利毕业为 Apache 顶级项目，一个成熟开源社区是贡献者无数个日夜默默的努力的结果。Apache SeaTunnel  作为一个高性能的数据集成平工具，让海量数据的实时同步与转换变得更加容易，给许多企业和用户带来了巨大的价值。期待 Apache SeaTunnel 社区能够坚持 Apache Way 理念不断壮大，给更多用户带来更多价值，在广阔深邃的海洋继续远行，越来越好。</p><p></p><p>—林添毅，Apache Kvrocks PPMC 成员</p><p></p><p>祝贺 Apache SeaTunnel 顺利从 Apache 孵化器毕业！最近几年在数据同步领域涌现出了很多优秀的开源项目，也证明了数据同步的重要性和价值，Apache SeaTunnel 无疑是这其中非常有竞争力的产品之一。祝 Apache SeaTunnel 能够越走越远，也祝愿中国开源事业蒸蒸日上！</p><p></p><p>—李本超，Apache Calcite PMC</p><p></p><p>很高兴看到国内第一个 Apache 基金会数据集成项目 SeaTunnel 能够顺利毕业，作为一个云原生数据集成工具，SeaTunnel 不仅很好地解决了企业多种数据源导致的数据孤岛问题，而且为复杂场景的数据同步提供了全新的解决方案。SeaTunnel 的顺利毕业也为 Apache Way 在中国的推广画下浓墨重彩的一笔，未来祝愿 SeaTunnel 社区能够越来越好，收获更多开发者及最终用户。</p><p></p><p>—杜恒，ASF Member, Apache RocketMQ PMC</p><p></p><p>祝贺 Apache SeaTunnel 从孵化器顺利毕业，成为 Apache 顶级项目！非常高兴看到持续有中国本土起源的项目成为 Apache 顶级项目，也祝愿 Apache SeaTunnel 蒸蒸日上，能够吸引更多的开发者和用户，建设更加多样化的社区，并且和其他 Apache 开源项目一起，打造更加繁荣的开源大数据技术生态！</p><p></p><p>—李钰，ASF Member，Apache Flink &amp; HBase PMC</p><p></p><p>SeaTunnel作为一款卓越的数据集成工具，融合了多种数据源，为用户提供了高效、精准的数据处理服务。我衷心祝愿SeaTunnel项目团队在Apache基金会的大家庭中取得更多的成就，在这个新的阶段继续保持优秀的工作，并为开源社区做出更多令人瞩目的成果。再次恭喜SeaTunnel项目团队！</p><p></p><p>—于雨，Apache Dubbo PMC, Dubbogo 社区负责人，Pika 负责人</p><p></p><p>非常高兴看到SeaTunnel 高效孵化毕业，成为Apache顶级项目！这一重要里程碑，展示了Seatunnel 社区对Apache Way 的长期坚持与实践成果，及其一站式数据集成工具的产品定位和功能实现，带来的强大生命力和吸引力。期待 SeaTunnel 在数据集成相关领域，继续为我们带来更加便捷和强大的功能！</p><p></p><p>—邸帅，Apache Linkis PMC Chair</p><p></p><p>首先要恭喜 Apache SeaTunnel 历经一年半时间顺利毕业成为 ASF 顶级项目，这是 SeaTunnel项目孵化的结束，也是下一个里程碑的重要开始。衷心希望 SeaTunnel 社区继续坚持 Apache Way，弘扬开源精神，为开源社区特别是大数据领域继续贡献力量。</p><p></p><p>—章剑锋 (Jeff Zhang)，ASF Member, Incubator PMC &amp; Mentor</p><p></p><p>祝贺 SeaTunnel 从 Apache 孵化毕业 ，成为正式项目。SeaTunnel 为大数据生态增加了一份新活力，同时也充分连接、融合了上下游的新产品和新趋势。SeaTunnel 从孵化到毕业的过程，也让关注它的伙伴同时实践、体会了 The Apache Way 的精神和方法。祝 SeaTunnel 社区越来越有活力。</p><p></p><p>—苏锐，JuiceFS 社区创始成员</p><p></p><p>毫无疑问，在当下建立一个活跃的开源社区是充满机遇和挑战的。Apache Seatunnel 至今经历了无数次的优化和迭代，表现出了强大的生命力和韧性。愿这个优秀的数据集成工具继续壮大，为更多的用户和企业提供更大的价值。愿 Apache SeaTunnel 持续发展，收获更多的关注和认可。希望你们的团队能够秉持 Apache way，坚持不懈，继续为开源社区贡献力量。</p><p></p><p>—吴涛，Apache Pegasus PPMC，RisingWave Labs 产品经理</p><p></p><p>In DataOps Poland we believe that Data has a lot of value. As we are big fans of Data we support Open Source projects, especially those from the Data Engineering field. It is a big deal to watch how Apache SeaTunnel is growing and climbing on ladder popularity. Apache SeaTunnel made another big step and became a top Open Source project of the Apache Foundation. Hats off to contributors, developers and the whole community for making so huge progress. Thank you for your time, dedication and involvement in the Data Integration movement.</p><p></p><p>—Tomasz Gintowt &amp; Filip Dzieciol, DataOps Poland</p><p></p><p>成为 Apache 顶级项目是 SeaTunnel 历史上的一个重要里程碑。这不仅证明了它在技术上的优秀表现，更体现了社区对它的认可和信任。希望 SeaTunnel 社区继续努力，保持高质量的代码和开放的社区氛围，与其他开源项目紧密合作，共同推动开源技术的进步和发展。</p><p></p><p>—张亮，Apache ShardingSphere PMC Chiar</p><p></p><p>Apache SeaTunnel 正迈入成熟阶段，这一富有创新精神的开源项目为大数据集成领域开创新纪元。在开源社区的齐心协力下，SeaTunnel 逐渐脱颖而出。让我们期待 SeaTunnel 在全球范围内壮大声誉，吸引更多开发者加入社区，共同推进项目向前。致力于提升用户体验，SeaTunnel 将不断创新技术和解决方案，协助企业挖掘数据价值，实现商业目标。让我们共同期待 SeaTunnel 的辉煌未来，携手推动行业创新和繁荣！</p><p></p><p>— 金嘉怡, Apache Druid PMC</p><p></p><p>祝贺 Apache SeaTunnel 顺利毕业成为 ASF 顶级项目。作为一个优秀的开源数据集成工具，TDengine 已经与之对接。希望我们一道为开源社区努力，给更多的用户和企业创造价值。</p><p></p><p>—陶建辉，涛思数据创始人</p><p></p><p>祝贺 Apache SeaTunnel 成功从 Apache 孵化器毕业，成为 ASF 的顶级项目。SeaTunnel 在我司大数据链路中扮演着重要角色，承担了湖仓与各种存储系统之间的数据处理与同步，我们也见证了 SeaTunnel 一路以来的快速成长。寄语未来，希望 SeaTunnel 在毕业之后继续努力、践行 Apache Way 打造开放、多元化的社区。</p><p></p><p>—杨华，Apache Hudi / Kyuubi PMC member，T3 出行大数据平台研发负责人</p><p></p><p>Apache SeaTunnel 自从进入Apache孵化器以来，秉承 Apache Way，社区非常繁荣，持续为开发者和企业提供了非常大的价值。</p><p></p><p>祝贺顺利毕业成为 Apache 顶级项目，愿 Apache SeaTunnel 不忘初心，勇敢前行，越来越好！</p><p></p><p>—肖宇，ASF Member，Apache ShenYu VP</p><p></p><p>恭喜顺利毕业成为Apache顶级项目，SeaTunnel 是Apache大数据生态非常优秀的开源项目，支持海量数据的实时同步和转换，是新一代高效数据集成工具。</p><p></p><p>—陈亮，ASF Member， Apache CarbonData VP</p><p></p><p>恭喜Apache SeaTunnel 顺利毕业！SeaTunnel做为一款高性能数据集成框架，自开源以来，以其灵活易用、易扩展等特点吸引了一大批社区用户与开发者来使用和贡献。希望SeaTunnel社区再接再厉，迈向新高度。</p><p></p><p>—ASF Member， LF AI &amp; Data 基金会董事会主席，Apache Hadoop PMC，堵俊平</p><p></p><p>热烈祝贺 SeaTunnel 顺利毕业，起于中国的 Apache 顶级项目再添一名“强将”。从 2018 年写下第一行代码，到 2021 年加入 Apache 孵化器，再到今天成为顶级项目，SeaTunnel 在开源的世界里如鱼得水，迎来了更多的贡献者、更多的用户，期待 SeaTunnel 未来能够真正实现“连接万库，同步如飞”，也将自身的经验分享给更多的开发者，让中国更多的开源项目、开源开发者走向并活跃于国际舞台！</p><p></p><p>—唐小引，CSDN&amp;《新程序员》执行总编</p><p></p><p>来自用户代表的反馈：</p><p></p><p>Shopee DI 支持着海量的数据以及非常多类型的数据摄入，其中一些长尾需求多样且多变，SeaTunnel 让我们能够快速响应这些需求并且让用户自助创建，因为它非常容易使用，为我们产品化这些需求赢得了时间。此外我们也使用 SeaTunnel 持续重构集成已有的功能，这提高了我们的开发效率，简化了代码管理。</p><p></p><p>—汪洋，Shopee 高级数据工程师</p><p></p><p>在游族网络，我们需要实时接入游戏业务数据到数据中心和离线迁移流转各个存储中的数据。在采用 SeaTunnel 之前，我们使用过各种各样的实时采集工具和离线迁移工具，工具种类繁多，维护困难，也不可够稳定。引入 SeaTunnel 后，提升了我们的实时接入任务质量，减少了离线迁移工具的维护成本。目前我们已经将 80% 的实时接入任务和离线迁移任务都改为使用SeaTunnel 实现。</p><p></p><p>—张晓栋，游族网络高级大数据开发工程师</p><p></p><h1>解锁特殊礼品</h1><p></p><p>为纪念 Apache SeaTunnel 项目发展的里程碑时刻，社区特别为大家准备了特殊的礼物🎁</p><p></p><p>2023 年 6 月 1 日— 6 月 7 日（为期一周），转发本文至朋友圈，累计获得 20 个点赞，并提交朋友圈截图凭证至表单 http://whaleops.mikecrm.com/EdViyLt ，填写集赞截图和邮寄地址，即可获得 Apache SeaTunnel 社区文化衫 1 件。</p><p></p><h1>致谢</h1><p></p><p>感谢各大媒体、社区及行业同仁在技术领域传播这一振奋人心的消息，排名不分前后：ALC北京、ALC深圳、安徽开发者、北京长风信息技术产业联盟、CSDN、DataFun、大数据技术与架构、大数据梦想家、大数据杂货铺、大数据流动、涤生大数据、麒思妙想、锋哥聊数仓、HBase、开源江湖、开源社、OpenTEKr、示说网、中国通信学会、志明与数据、渠成社区、PowerData、InfoQ</p><p></p><h1>关注 Apache SeaTunnel</h1><p></p><p>SeaTunnel 官网: https://seatunnel.apache.org/下载地址：https://seatunnel.apache.org/downloadGitHub 地址: https://github.com/apache/seatunnel贡献指南: https://seatunnel.apache.org/community/contribution_guide/contribute</p><p></p><h1>加入我们</h1><p></p><p>国内用户：SeaTunnel 微信公众号: SeaTunnel加入微信用户群请添加微信号: seatunnel1海外用户：Twitter: https://twitter.com/ASFSeaTunnel博客: https://medium.com/@apache-seatunnelSlack：https://join.slack.com/t/apacheseatunnel/shared_invite/zt-1kcxzyrxz-lKcF3BAyzHEmpcc4OSaCjQ</p>",
    "publish_time": "2023-06-01 14:56:46",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]