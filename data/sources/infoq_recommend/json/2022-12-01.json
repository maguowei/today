[
  {
    "title": "腾讯云技术实践精选集 2022",
    "url": "https://www.infoq.cn/article/RuveM045ptfTNKwfeq6c",
    "summary": "<p>2022 年，数字化转型成为了全行业关注的焦点，数字经济的价值进一步凸显。云计算作为数字时代的关键要素之一，正从单一云向多云、混合云战略过渡；分布式云服务也进入了高速发展的黄金期；随着 Docker、K8s 等容器技术的流行，云原生正成为云计算的新赛场，也成为企业数字化转型发展的“默认选项”、新底座；除此之外，人工智能、边缘计算等技术的普及进一步加速了云计算技术的变革。无论是数字原生行业还是非数字原生行业，云计算在行业数字化解决方案、产业链数据流转、资源动态配置、业务创新等方面正产生着难以估量的价值。</p>\n<p>对于腾讯的技术团队来讲，2022年也是一个重要的技术里程碑之年。<span class=\"orange\"><strong>历经三年，包括 QQ、微信、王者荣耀、腾讯会议等亿级用户规模的腾讯自研业务已全面上云，集群规模突破 5000 万核，累计节省成本超 30 亿，这使得腾讯打造出国内最大规模的云原生实践。</strong></span></p>\n<p>如何把这些亿级业务全部搬到云上并实现云原生改造？腾讯云做了大量的技术优化和革新，比如：</p>\n<ul>\n<li>在容器调度领域 ，通过混部技术将资源利用率提升到 65%；</li>\n<li>在数据库领域，通过存算分离技术，打造了国内第一款云原生 Serverless 数据库；</li>\n<li>在安全领域，借助云原生技术本身的可观测性手段，创新地与安全结合，打造了更贴合云原生技术的专业安全防护能力等等。</li>\n</ul>\n<p>为此也沉淀了一份 6 万多字的《腾讯大规模云原生技术实践案例集》，包括 10 多个国民级应用的上云实践，可扫描封底二维码下载阅读。</p>\n<p>除了赋能自研业务外，腾讯云还将上述诸多产品或服务以及配套的基础软件、底层技术等开放给百万级的外部客户，全部基于公有云模式开发运营，赋能千行百业，也造就了一大批金融、游戏、企业服务、智能制造、教育等场景下的最佳实践。</p>\n<p>此外，为了解决客户上云、用云的成本之忧，腾讯云基于内外云原生成本管理最佳实践，并结合行业优秀案例，提出了一套体系化的云原生上云成本优化方法论和最佳实践路径，发布了两个业界“标准”：《云原生最佳实践路线图》和《降本之源 · 云原生成本管理白皮书》，旨在帮助企业改善用云成本，充分发挥云原生的效能和价值。</p>\n<p>2022 年，是不平凡的一年，感恩来自行业、伙伴、团队的力量推动着我们勇往直前。在今年，我们参与了 DIVE 2022 北京站、ArchSummit 2022 深圳站、QCon 2022 广州站、ArchSummit 2022 北京站、ArchSummit 2022 杭州站等多场大会，与 1000+ 位技术人邂逅并分享心得。</p>\n<p>此外，这也是腾讯云连续两年推出《腾讯云技术实践精选集》，去年 2021 版精选集共 4 万多字，全网带来 7000 多次下载。<span class=\"orange\"><strong>2022 版的精选集总字数近 10 万，尤其首次收录了“腾讯自研业务大规模云原生实践”系列内容，全面解密腾讯如何锤炼腾讯云。</strong></span></p>\n<p>每一次相遇，都难能可贵，每一场交流，都价值满满，遂整理成文，共享丰沃。</p>\n<p>展望 2023 ，愿与诸君携手同行，共攀技术新峰！</p>\n<h1>目录</h1>\n<h2>第一部分  腾讯自研业务大规模云原生实践</h2>\n<ul>\n<li>如何管理超千万核资源的容器规模</li>\n<li>50W+ 小程序开发者背后的数据库降本增效实践</li>\n<li>拥抱云原生，数十万规模 GPU 卡的利用率极致优化之路</li>\n<li>TDSQL-PG 数据库在微信支付的应用实践</li>\n<li>将云原生进行到底：腾讯百万级别容器云平台实践揭秘</li>\n<li>云原生安全可观测性探索与实践</li>\n<li>大规模代码中引入供应链漏洞的分析技术前瞻</li>\n</ul>\n<h2>第二部分  大数据与云数据库技术探索及实践</h2>\n<ul>\n<li>腾讯云大数据 TBDS 在私有化场景万节点集群的实践</li>\n<li>PB 级数据秒级分析，腾讯云原生湖仓 DLC 架构揭秘</li>\n<li>CDW PG 大规模在线数仓技术构架分享</li>\n<li>云原生数据库管控探索和实践</li>\n<li>腾讯云原生数据库 TDSQL-C 架构探索和实践</li>\n<li>金融级分布式数据库 TDSQL 升级版引擎架构和关键技术介绍</li>\n<li>国产金融级分布式数据库在金融核心场景的探索实践</li>\n<li>腾讯云 MongoDB 智能诊断及性能优化实践</li>\n<li>腾讯云数据库云上 SaaS 生态演进</li>\n</ul>\n<h2>第三部分  云成本优化与研发提效</h2>\n<ul>\n<li>企业上云，云上资源整体成本优化管理如何做？</li>\n<li>企业如何利用云厂商能力构建自己的分布式云？</li>\n<li>从混部到 Serverless 化，腾讯自研业务的稳定性及云原生成本优化实践</li>\n<li>Serverless 时代下，企业微服务的降本思考与实践</li>\n<li>腾讯课堂面向协作的 DevOps 流程设计与实践</li>\n</ul>\n<h2>第四部分  中间件与基础设施</h2>\n<ul>\n<li>Kafka Stream - 的进化探索：流式 Serverless 计算</li>\n<li>JVMTI Agent在中间件领域的应用</li>\n<li>区块链如何支撑 Web 3.0</li>\n<li>腾讯操作系统的创新之路</li>\n<li>腾讯明眸媒体处理实践</li>\n</ul>",
    "publish_time": "2022-12-01 01:55:37",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何用Go语言构建、测试和部署可扩展的REST API",
    "url": "https://www.infoq.cn/article/LdimuNAoab0ZHpmVDKOf",
    "summary": "<p></p><h2>引言</h2><p></p><p>在本文中，我们将了解如何使用<a href=\"https://gin-gonic.com/\">gin</a>\"框架创建一个简单的Golang应用程序。我们还将学习如何使用持续部署工具<a href=\"https://circleci.com/\">CircleCI</a>\"实现自动化测试和部署。</p><p>&nbsp;</p><p>Go是一种静态类型的开源编程语言，由谷歌工程师创建，其唯一的目的是简化复杂的软件开发过程和架构。它的主要特性包括：高性能网络、并发性和易用性。Go中广泛使用了Goroutine。Goroutine是一个在程序中与其他Goroutine并行运行的函数。当需要同时做几件事时，Goroutine会很有用。举例来说，谷歌、Cloudflare、MongoDB、Netflix和Uber几家公司都使用了Go。</p><p>&nbsp;</p><p><a href=\"https://gin-gonic.com/\">Gin</a>\"是一个基于Go的高性能HTTP Web框架，可以用来构建微服务和Web应用程序。Gin的主要优势在于，它使得开发人员可以创建高效、可扩展的应用程序，而且不必编写大量的样板代码。它生成的代码简洁、易于阅读。它还内置了路由、用于处理功能的中间件、日志记录器和Web服务器。</p><p></p><h2>构建一个简单的CRUD API</h2><p></p><p>我们将为学院俱乐部的学生管理工具创建一个简单的API。完成后，俱乐部主席将能够新增学生及检索所有学生。如果想完全按照本教程来操作，则需要做好以下准备：</p><p>安装Go，了解该语言的基本知识；了解测试，知道如何编写测试；一个GitHub账号；一个CircleCI账号；一个Heroku账号。</p><p>&nbsp;</p><p>请注意，如果你想使用Heroku的免费帐户进行试验，那么Heroku很快就会将其停用。不过，这里描述的过程可以很容易地应用于其他大多数云托管平台。</p><p></p><h3>构建一个CRUD应用程序</h3><p></p><p>这个简单的学院俱乐部API只有两个功能：将学生添加为会员和查看所有会员；没有什么复杂的东西！我们将用到POST和GET请求。我们不会连接任何数据库，如MongoDB或MySQL。但是，我们将使用本地存储并默认在数据库中创建一个学生。每当服务器重启时，就会自动添加这个学生。</p><p>&nbsp;</p><p>让我们开始吧。首先，我们将创建一个项目文件夹，并命名为stup -api。在这个文件夹中，我们将初始化Golang程序并安装所需的所有依赖。</p><p><code lang=\"go\">mkdir stud-api\ncd stud-api</code></p><p>接下来，我们将初始化go.mod文件，并安装所需的所有依赖：</p><p><code lang=\"go\">go mod init stud-api\ncd stud-api\ngo get -u github.com/gin-gonic/gin github.com/rs/xid github.com/stretchr/testify </code></p><p><a href=\"http://github.com/rs/xid\">Github.com/rs/xid</a>\"是一个用于创建惟一标识的库。在这个项目中，我们将用它自动为每个新学生生成一个ID。我们将用<a href=\"http://github.com/stretchr/testify\">github.com/stretchr/testify</a>\"包测试各个端点。</p><p>&nbsp;</p><p>下面开始讨论API。简单起见，我们只创建一个名为main.go的文件。这个文件将包含struct 、API控制器、服务和路由。我们将创建三个端点：</p><p>一个发送欢迎消息的欢迎函数；一个将学生添加到数据库的CreateStudent()&nbsp;函数；一个返回数据库中所有已注册学生的GetStudents()函数。</p><p>&nbsp;</p><p>下面在新创建的main.go文件中导入三个包：HTTP包、xID包和gin包。接下来，编写一个main()函数，其中将包含所有的API路由。然后，另外创建一个函数WelcomeMessage()，在调用相关的路由时，它会打印一条简单的消息。</p><p><code lang=\"go\">package main\nimport (\n\"net/http\"\n\"github.com/gin-gonic/gin\"\n\"github.com/rs/xid\"\n)\n\n\nfunc main() {\n//设置路由\nrouter := gin.Default()\nrouter.GET(\"/\", WelcomeMessage)\nrouter.Run()\n}\n//欢迎消息\nfunc WelcomeMessage(c *gin.Context) {\nc.JSON(http.StatusOK, gin.H{\"message\": \"Hey boss!\"})\n}</code></p><p>现在，可以使用下面的命令来启动服务器，看看到目前为止我们都做了什么：</p><p><code lang=\"go\">go run main.go</code></p><p>如果运行成功，则CLI将显示“Hey boss!”。这个简单的函数就创建完成了。现在我们将继续讨论数据库和struct 。</p><p>&nbsp;</p><p>我们将构建一个简单的Student struct ，它接受三个参数：学生姓名、学院和年级，并在用户成功添加到数据库时为其生成一个ID。</p><p><code lang=\"go\">//定义学生结构\ntype Student struct {\nID         string `json:\"id\"`\nName       string `json:\"name\"`\nDepartment string `json:\"department\"`\nLevel      string `json:\"level\"`\n}</code></p><p>现在，我们创建下本地数据库，它将存储我们传递给服务器的三个值以及生成的ID。我们将数据库命名为Students，其中会包含一个学生的默认数据，而新创建的任何学生都会添加到这里。</p><p><code lang=\"go\">//学生数据库\nvar students = []Student{\n{\nID:         \"10000xbcd3\",\nName:       \"Alicia Winds\",\nDepartment: \"Political Science\",\nLevel:      \"Year 3\",\n},\n}</code></p><p>好了，数据库设计就完成了，现在我们编写下CreateStudent()函数以及与其交互的路由。</p><p><code lang=\"go\">//新建一个学生账号\nfunc CreateStudent() gin.HandlerFunc {\nreturn func(c *gin.Context) {\nvar newStudent Student\nif err := c.BindJSON(&amp;newStudent); err != nil {\nc.JSON(http.StatusBadRequest, gin.H{\n\"Status\":  http.StatusBadRequest,\n\"Message\": \"error\",\n\"Data\":    map[string]interface{}{\"data\": err.Error()}})\nreturn\n}\n//生成一个学生ID\nnewStudent.ID = xid.New().String()\nstudents = append(students, newStudent)\nc.JSON(http.StatusCreated, newStudent)\n}\n\n\n}</code></p><p>现在将与该函数交互所需的路由添加到main()函数。</p><p><code lang=\"go\">func main() {\n-------------\nrouter.POST(\"/createStudent\", CreateStudent())\n-------------\n}</code></p><p>要测试到目前为止所做的工作，请启动服务器，并在Postman或任何其他环境中测试端点（localhost:8080/createStudent）。在消息体中传递姓名、学院和年级，就会自动生成一个具有惟一ID的新用户。请注意，这是一个非持久化数据库。</p><p>&nbsp;</p><p>现在，让我们创建最后一个函数。我们将使用它来获取俱乐部数据库中的所有学生。这个请求是一个简单的GET函数，它将搜索学生数据库并返回其中的所有内容。</p><p><code lang=\"go\">func GetStudents() gin.HandlerFunc {\nreturn func(c *gin.Context) {\n//获取数据库中的所有学生\nc.JSON(http.StatusOK, students)\n}\n}</code></p><p>最后，我们将创建与新建函数进行交互的路由。我们将把它加入主函数，和其他路由放在一起。</p><p><code lang=\"go\">func main() {\n------------------\nrouter.GET(\"/students\", GetStudents())\nrouter.Run()\n}</code></p><p>也使用Postman测试一下！为此，我们需要启动服务器并访问端点localhost:8080/students。我们所需要做的就是使用HTTP谓词GET，不需要包含任何消息体或查询参数。运行成功后，它将返回数据库中的所有学生。这样，这个简单的CRUD API就完成了！</p><p></p><h2>编写简单的本地测试</h2><p></p><p>在这一节中，我们将对已创建的端点进行单元测试。目标是确保每个函数的行为都符合预期。为了测试这些函数，我们将使用<a href=\"https://github.com/stretchr/testify\">testify</a>\"包。此外，我们必须新建一个文件new_test.go。我们将要编写的各种测试都将放在这个文件中。在主目录的根目录中创建完新文件后，我们需要导入几个包。</p><p><code lang=\"go\">func main() {\n------------------\nrouter.GET(\"/students\", GetStudents())\nrouter.Run()\n}</code></p><p>在testify中，执行简单的断言和模拟都很容易。在Go中，testing.T对象作为assert函数的第一个参数传入。然后，assert函数会返回一个bool值，说明断言是否成功。<a href=\"https://github.com/stretchr/testify\">testify mock</a>\"包提供了一种快速创建模拟对象的方法，在编写测试代码时可以用它代替实际的对象。</p><p>&nbsp;</p><p>现在，我们将设置一个路由，并为欢迎消息编写一个简单的测试。如下所示，在这个测试中，assert函数将使用变量的相等比较来确定测试参数是否与模拟响应相匹配。</p><p><code lang=\"go\">func SetRouter() *gin.Engine {\nrouter := gin.Default()\nreturn router\n}\n\n\nfunc TestWelcomeMessage(t *testing.T) {\nmockResponse := `{\"message\":\"Hey boss!\"}`\nr := SetRouter()\nr.GET(\"/\", WelcomeMessage)\nreq, _ := http.NewRequest(\"GET\", \"/\", nil)\nw := httptest.NewRecorder()\nr.ServeHTTP(w, req)\nresponseData, _ := ioutil.ReadAll(w.Body)\nassert.Equal(t, mockResponse, string(responseData))\nassert.Equal(t, http.StatusOK, w.Code)\n}</code></p><p>接下来，我们将使用模拟数据为createStudent()函数编写一个简单的测试。还是使用xID包来生成Student ID，我们会收到一个说明测试是否成功的bool值。</p><p><code lang=\"go\">func TestCreateStudent(t *testing.T) {\nr := SetRouter()\nr.POST(\"/createStudent\", CreateStudent())\nstudentId := xid.New().String()\nstudent := Student{\nID:         studentId,\nName:       \"Greg Winds\",\nDepartment: \"Political Science\",\nLevel:      \"Year 4\",}\njsonValue, _ := json.Marshal(student)\nreq, _ := http.NewRequest(\"POST\", \"/createStudent\", bytes.NewBuffer(jsonValue))\nw := httptest.NewRecorder()\nr.ServeHTTP(w, req)\nassert.Equal(t, http.StatusCreated, w.Code)}</code></p><p>最后，我们将针对GetStudents()函数编写最后一个测试。</p><p><code lang=\"go\">func TestGetStudents(t *testing.T) {\nr := SetRouter()\nr.GET(\"/students\", GetStudents())\nreq, _ := http.NewRequest(\"GET\", \"/students\", nil)\nw := httptest.NewRecorder()\nr.ServeHTTP(w, req)\nvar students []Student\njson.Unmarshal(w.Body.Bytes(), &amp;students)\nassert.Equal(t, http.StatusOK, w.Code)\nassert.NotEmpty(t, students)\n}</code></p><p>我们已经完成了所有的测试，现在可以在本地运行了。这很简单，只需执行下面这行命令：</p><p><code lang=\"go\">GIN_MODE=release go test -v</code></p><p>下面是最终结果：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c8/c89269c1ab1abe45d5b1c8055955e19b.png\" /></p><p></p><p></p><h2>利用持续开发实现测试自动化</h2><p></p><p><a href=\"https://circleci.com/\">CircleCI</a>\"是一个用于持续集成和交付的平台，可用于DevOps实践。在本文中，我们将使用这个CI/CD工具实现测试自动化并将代码部署到服务器上。我们先从使用CircleCI自动化测试开始说起。</p><p>&nbsp;</p><p>确保你有一个CircleCI帐户（正如准备工作部分所介绍的那样），并且已经成功地将代码推送到GitHub。检查CircleCI仪表板，确保项目存储库是可见的。</p><p>&nbsp;</p><p>现在，在项目目录中，创建文件夹.circleci和配置文件config.yml，该文件将包含自动化测试所需的命令。</p><p></p><h2>配置config.yaml</h2><p></p><p>该文件包含自动化Heroku部署和测试所需的所有配置。我们暂时不关注Heroku部分，因为我们更感兴趣的是帮助实现自动化测试的代码。该文件包含检出并运行测试的Go orb和作业。在将下面的代码添加到配置文件后，我们需要将其重新推送到GitHub。</p><p><code lang=\"go\">workflows:\n  heroku_deploy:\n    jobs:\n      - build\n      - heroku/deploy-via-git:  \n          requires:\n            - build\n          filters:\n            branches:\n              only: main\njobs:\n  build:\n    working_directory: ~/repo\n    docker:\n      - image: cimg/go:1.17.10\n    steps:\n      - checkout\n      - restore_cache:\n          keys:\n            - go-mod-v4-{{ checksum \"go.sum\" }}\n      - run:\n          name: Install Dependencies\n          command: go get ./...\n      - save_cache:\n          key: go-mod-v4-{{ checksum \"go.sum\" }}\n          paths:\n            - \"/go/pkg/mod\"\n      - run:\n          name: Run tests\n          command: go test -v</code></p><p>完成这一步之后，返回CircleCI仪表板并选择我们的项目。然后，单击它旁边的Setup按钮，并选择我们正在使用的分支。当我们点击Setup按钮时，程序将开始运行。构建成功的话应该可以看到如下所示的信息（向下滚动到运行测试的部分）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dc/dcd8ecfbdd26422690454f942590e501.png\" /></p><p></p><p>就是这样！我们成功地构建了一个简单的API，创建了本地测试，并实现了测试过程自动化。这个自动化过程意味着，每次向GitHub存储库上的分支推送时，管道都会尝试运行测试。</p><p></p><h2>使用CircleCI自动部署到Heroku</h2><p></p><p>首先是配置Heroku。如果你还没有Heroku帐户，就需要创建一个。为了方便部署和自动化，你还需要将GitHub配置文件连接到Heroku帐户。上述工作完成之后，需要在项目文件夹中创建一个Procfile（是的，没有扩展名），并向其中添加以下内容：</p><p><code lang=\"go\">web: app</code></p><p>之后，推送到GitHub。现在，快速看一下之前创建的config.yaml文件，分析下第一部分。可以看到，我们导入了Heroku orb，其中还有一个工作流，里面是一个在主存储库中构建和部署代码的作业。</p><p>&nbsp;</p><p>回到Heroku仪表板，我们必须首先在Heroku上创建一个项目，并获取API密钥（可以从帐户设置中找）。我们需要把这个密钥添加到我们的CircleCI项目。为此，在CircleCI上导航到现有项目并选择项目设置。然后转到环境变量部分，添加下面这两个东西：</p><p>HEROKU_APP_NAME，值为stud-api&nbsp;（应用程序名称）；HEROKU_API_KEY&nbsp;，值为我们刚刚从Heroku获取的密钥。</p><p>&nbsp;</p><p>我们已经成功地配置了我们的CircleCI项目，可以向Heroku持续部署了。如果没什么问题，在CircleCI仪表板上，我们应该可以看到下面这样一条说明构建已经成功的消息：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/94/94ab3fc91daeedd7c2f24286909ac969.png\" /></p><p></p><p>返回Heroku仪表板并检索项目URL，看看我们都做了什么。这里，URL是：<a href=\"https://stud-app-api.herokuapp.com/\">https://stud-app-api.herokuapp.com/</a>\"。你可以将想要测试的路由附加到URL末尾来测试所有的功能。例如，测试获取所有学生的端点：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4e/4eb298655ea8ae784774f6ec8fd9287a.png\" /></p><p></p><p></p><h2>小结</h2><p></p><p>持续开发使开发人员能够更快地创建更好的产品。持续集成和开发工具通过自动化操作简化了整个过程，减少了所需的时间或专业知识。CI/CD工具通过自动化从测试到应用程序快速部署之间的所有事情，帮助我们逐步提高产品质量。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/build-deploy-scalable-golang-api/\">https://www.infoq.com/articles/build-deploy-scalable-golang-api/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/jfkZ7LHF1HbONN2sPOyw\">REST 如何站到了自己的对立面？</a>\"</p><p><a href=\"https://xie.infoq.cn/article/abaa53f80114223d2940f439d\">什么是 RESTful，REST api 设计时应该遵守什么样的规则？</a>\"</p>",
    "publish_time": "2022-12-01 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "一年覆盖九种语言上千服务，作业帮 Service Mesh 如何大规模落地？",
    "url": "https://www.infoq.cn/article/98SQPazzQUxMglZx28Yq",
    "summary": "<p>2019 年底，<a href=\"https://www.infoq.cn/article/gNzSTfhgs8xzRlYgciEv\">作业帮</a>\"技术栈比较多元且业务复杂度较高：使用最多的语言为 PHP 和 Golang，约占到总模块数量的 60% 左右；此外还有大量的系统使用 NodeJs、Java、C++、lua、python 编写等，即使是同样的技术栈，也会因为业务特点、团队特点，技术栈上呈现出较大差异；工具型产品侧重客户端，服务端技术偏保守。产业互联网业务，领域驱动，大量使用微服务架构，但由于没有统一的标准，各自团队也在自研服务治理体系的基础设施。</p><p></p><p>语言栈多元后，业务间的沟通协作就变得困难。跨语言的微服务框架难以落地统一的服务治理标准，致使业务服务治理参差不齐，大大限制了业务的快速迭代和稳定性。</p><p></p><p>同时作业帮的服务调用方式比较多样化，有 HTTP、gRPC、自研协议等，治理难度非常大，不同的 RPC 协议也会导致服务间通信困难。作业帮当时已有数千个服务，且服务间请求链路较长，一次请求的深度可能就超过一百多、甚至数百。</p><p></p><p>此时，已经完成容器化进程的作业帮开始着手调研服务治理技术，希望借助 <a href=\"https://xie.infoq.cn/article/7cb4393bd2828d5300edb31ec\">Service Mesh</a>\" 技术，来解决当时复杂的服务治理问题。</p><p></p><p>同年，为了适应云原生发展，作业帮进行了组织架构调整，将运维、安全、数据库、架构研发和部分通用中台等统一归纳到了基础架构团队。Service Mesh 的工作也落到了基础架构团队头上。</p><p></p><p>解决复杂治理问题最大的“拦路虎”是：业务既渴望使用新技术，但又担忧会带来高昂的使用成本，因此宁愿原地停留也不进行升级。那么，作业帮基础架构团队是如何解决这一问题的呢？这次，InfoQ 有幸采访了基础架构团队负责人董晓聪和架构研发团队负责人吕亚霖，为我们详细阐述了作业帮的实践思路和效果。</p><p></p><h3>全自研 Mesh</h3><p></p><p></p><p>“基础架构团队在进行服务治理时，既要保证稳定性，还要能够帮助业务提升效率。”董晓聪总结道。具体来说，团队的核心目标就是让 Service Mesh 接管服务治理里大量的非功能逻辑，实现服务的流量控制、可观测性和安全韧性，并且通过能力下沉，让业务透明、无感地接入。</p><p></p><p>但面对当前市面上各种开源产品，基础架构团队在前期充分调研后，认为这些产品都不太能满足作业帮的需求，因此选择了一条全自研的路。</p><p></p><h4>数据面，更看重性能</h4><p></p><p></p><p>数据面上，作业帮更倾向追求极致的性能，而对扩展性的需求并不迫切。这是由于作业帮内部的链路较长（上百 span），对业务来说哪怕是单次请求毫秒级的损失，整体上都会带来较大的影响。</p><p></p><p>对于主流产品<a href=\"https://www.infoq.cn/article/aulwXCUFJctf5FK5zYzu\"> Envoy</a>\"，作业帮基础架构团队不太认同它的插件模式。“插件机制引入主要是为了降低开发难度，虽然能有效降低研发成本，但是性能较差，同时提供的隔离也不彻底。”作业帮架构研发团队负责人吕亚霖说道。</p><p></p><p>因此，基础架构团队用 C++ 自己实现数据面，初期按需求紧迫程度支持了三类协议：第一类是 RPC 数据面，负责服务通信；第二类是对象存储数据面，负责对象存储资源的鉴权管理、流控、分发及性能提升；第三类是加解密数据面，负责提供安全和数据加密的能力。这三种数据面的协议差异性很大，分别对应了 RPC 通信协议、文件读写流协议、加解密协议，且对性能要求极为苛刻。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/51/518b0f6597c8c67dccb482683d2a941a.png\" /></p><p></p><p>整体上，基础架构团队主要针对 RPC 协议，采用了 Mesh-proxy 代理方式。对于入流量，直接通过 UDS 转发给了 Server，Server 需要支持 UDS 监听；对于出流量，则与 Istio 类似，用 iptable 拦截，不过团队另用 eBPF 做了优化。</p><p></p><p>吕亚霖表示，iptable 出流量拦截过程复杂，带来了不少的性能损失，因此团队使用 eBPF 优化内核网络劫持，在 Sock Map 进行映射、省掉中间环节，就可以极大提升劫持性能。eBPF 优化的前提是系统内核是 5.X 版本以上，作业帮使用的是 5.10 版本，主要是 5.10 版本解决了 CO-RE 有利于后期的升级维护，而 Istio 为了适应大部分客户内核低版本情况并没有支持。</p><p></p><p>根据作业帮此前的测试，以 Envoy 官方数据为例，在 QPS 为 1000 下，Envoy 在模式的 v2-stats-wasm_both 下 P90 响应时间是 2.25 毫秒，相比于 baseline 测试结果，添加了 Envoy 边车之后 P90 时延增加了 1.3 毫秒，且随着并发加大逐步恶化。作业帮自研数据面实测添加了 mesh 边车之后 P90 时延增长比这个数据降低了 0.38 毫秒，随着并发加大比较稳定。当 QPS 从 1000 加到 10000 时，平均响应时间减少 0.4 毫秒。另外在 CPU 耗损上，在 QPS 为 1000 的情况下，Envoy 耗损 0.54 核，作业帮的数据面损耗 0.09 核。这项测试也验证了作业帮数据面的可用性。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/16/1688eb90c29aa220e469724c0543cd7e.png\" /></p><p></p><p>事实上，从立项到数据面研发完成，基础架构团队只用了两个月左右的时间。“我们是把问题进行了拆解和聚焦，使用了云原生 Kubernetes 的基座，初期只对 RPC 类流量做了 mesh 劫持。同时聚焦数据面性能本身。”作业帮基础架构负责人董晓聪说道。</p><p></p><h4>控制面，纳入统一管控平台</h4><p></p><p></p><p>控制面上，作业帮本身有完整的运维管控体系，即包含服务注册发现相关，还有服务感知的一系列能力。所以作业帮并没有单独做一个 Service Mesh 的控制面，而是基于已有体系扩展，直接实现进行流量管控、通信协议、安全等。</p><p></p><p>对于作业帮来说，管控面是 DevOps 理念的落地，能更好的贴合自身研发流程和组织管理，比如：统一鉴权、工单体系、审计体系等。</p><p></p><p>对于 Service Mesh 的控制面，作业帮并没有引入类 Istio 在 Service Mesh 的实现服务注册发现，而是使用原生的 Kubernetes 的注册发现。作业帮基础架构团队认为，在大型的复杂工程中，架构设计的核心目标是复杂度降维，而将服务注册发现引入到 Service Mesh 却是在将复杂度升维，Kubernetes 的服务发现是 node 级别，而 Istio 的服务发现是 pod 级别，服务发现数据是数量级的提升。而对于升维带来的更强计算力和内存需求等问题也没有给出很好的解决方案。比如 Istio 的 xDS 使用全量下发策略，会把整个网格内所有服务发现数据同步给 proxy 边车，这会带来一系列的问题。</p><p></p><p>另外根据团队观察，很多公司在接入的时候，精力被耗在了 xDS 对接上，从原有协议向 xDS 转换过程中也充斥着各种各样的问题。</p><p></p><p>基于以上考虑，作业帮并没有使用 xDS 来提供发现机制，而是沿用了 Kubernetes 里注册发现方式，通过 eBPF 来优化 service，也具备路由决策等能力。在基础架构团队看来，这种方式更加轻量级，也与 Kubernetes 社区的结合更为紧密。</p><p></p><p>另外在安全性方面，团队进行了认证授权、网络拦截等；观测性上，全量埋下了分布式追踪，支持日志的统一观测和监控等。</p><p></p><p>在作业帮基础架构团队看来，用不用某个协议只是看其能否满足实际需求或者是否认可它的模式。用 xDS 的好处是会有统一标准，但 xDS 能否成为事实标准，还有待时间的检验。</p><p></p><p>吕亚霖表示，目前将 xDS 当作标准还有一些风险。“xDS 成为标准的前提是升维带来的复杂度被其他方面拆解掉，但它现在的降维手段并不是一个通用方案，我们在看到新方案出来之前是不会跟进的。”不过团队也会继续观望，关键还是要看其能否在大型企业的大规模复杂场景下落地。</p><p></p><h3>超预期的推广速度</h3><p></p><p></p><p>研发完成后，基础架构团队开始了“边放量、边灰度、边优化”的循环。对作业帮来说，基础架构团队涵盖了不同方向的小组，团队内就可以完成闭环测试，然后再向业务推广。</p><p></p><p>实际上，Mesh 在作业帮内部的推广速度远超基础架构团队的预期。据悉，目前作业帮 Mesh 覆盖率已经超过 80%，涵盖了 C++、Python、PHP、Go、Java 等语言栈。董晓聪表示背后的核心原因有多个，一是流量管控和观测，真正帮助到了业务，二是 Mesh 是相对无感接入，三是 Mesh 落地提升了研发效率。</p><p></p><p>流量管控和观测方面：主要实现了流量管控、安全（认证授权）、可观测性（日志统计、全量分布式追踪）。流量管控上实现了很多业务期待的功能，比如自适应限流。很多情况下业务需要熔断限流，但是不太可能每个服务都进行压测配置限流阈值，同时业内的自适应限流算法与流量以及自身资源相关，也无法实现因下游服务容量问题时主动限流。作业帮将机器学习应用于该领域，实现了智能的流控，当通用模型不适合某些特定流量场景时，也提供基于过去半年的数据，学习和训练特有模型。</p><p></p><p>接入相对无感：业务几乎不需要改造，只需要兼容 listen uds，其他由基础架构直接升级，然后进行放量观察即可。改造成本极低。</p><p></p><p>研发效率方面：在原来的微服务开发模式下，模块非常多，业务进行联调和测试的效率非常低。比如联调要经过 CI/CD、发布到测试环境、验证等一系列复杂的过程，而微服务里改动一个需求可能就要改动几十个模块。一个研发每次改动就要重复一遍上述过程。而 Service Mesh 在研发阶段的作用就是使研发可以直接在本地启动服务，并且这个本地服务可以无缝的和远程的 Kubernetes 测试集群中的各个其它服务实现互相调用，免去了复杂的 CI/CD 流程。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/73/733f51abdd4227ad9a6c338455149b6b.png\" /></p><p></p><p>“一个业务线里面有一两个服务用了发现效率提升非常明显后，会形成很好的口碑效应，之后该业务其他研发会主动找过来要求升级。”吕亚霖表示。据悉，作业帮内部研发主动升级的比例在 50% 左右。</p><p></p><p>不过在推广过程中，基础架构团队也踩过坑。一次灰度放量时，某业务线使用了不规范的 HTTP 协议，但 Mesh 拦截 RPC 流量是按标准协议处理的，所以就产生了冲突，该问题影响了服务间的通信。</p><p></p><p>“这也让我们认识到，多语言栈下的协议确实没有那么规范，而这种不规范更多是因为各个语言，在协议实现层面上的差异导致。”董晓聪说道，“同时也展现了 Service Mesh 这项技术的意义，即接管服务治理里大量的非功能逻辑，实现标准化。”</p><p></p><p>除了这次事故，其他方面都远远超过了团队的预期，甚至由于需求变多，团队不得不投入更多的人力。</p><p></p><p>同时这次 Mesh 落地实践也让基础架构团队深刻体验到了内核研发能力的重要性。</p><p></p><p>“服务的各种小问题会特别容易摧毁业务线对你的信任。问题多了，哪怕是他业务的问题也会怀疑是 Service Mesh 的问题。”吕亚霖表说道，“这些问题都要及时解决，但在这个过程中，团队发现最后这些问题大部分需要在内核层面定位和配合解决。比如业务反馈平响多了几毫秒或者毛刺率变高，都需要在内核底层进行追踪定位，需要基础架构团队有一套分析定位内核的工具，同时内核追踪需要和业务的分布式追踪关联，才能快速定位解决问题。</p><p></p><p>总体来看，作业帮 Service Mesh 的落地收益比还是很不错的。作业帮基础架构团队只投入了两个专职人力，进行 Service Mesh 的研发和迭代。推广上持续了一年。通过 Mesh 的协议升级，带来了性能和稳定性的提升，比如 PHP、python 很多都是 HTTP1.0 的短链，团队通过 mesh 层进行协议协商升级，在业务无感的情况下将 HTTP 升级到了 2.0，减少网络建连、提升了网络传输速率。同时 Service Mesh 的落地带来了治理能力的大幅提升，全量的分布式追踪、完善的监控报警，以及在协议实现上的标准和统一。</p><p></p><h3>结束语</h3><p></p><p></p><p>虽然如此，吕亚霖提醒道，业务体量不大的时候跟风上 Service Mesh 并不会带来太多收益，甚至可能使整体产品的迭代变慢。多语言栈、链路比较长、业务要求比较高的情况更适合接入 Mesh。</p><p></p><p>“真正落地的时候你就会知道适不适合了，真正引入 Mesh 后发现推广不下去，本质上就说明了不适合。一项技术非常匹配时，推广便是一件水到渠成的事情。”吕亚霖说道。</p><p></p><p>另外，企业真的要接入 Mesh，也没有必要自研。自研对企业的研发能力要求会比较高。首先，Mesh 自研对 C++ 工程师的研发能力要求很高，但如今很多公司大多是 Java 工程师做基础架构。其次，根据作业帮基础架构团队的经验，团队要有内核研发和定位的能力，对于一些小公司来说可能并不具备这样的条件。</p><p></p><p>对于当前自研的选择，吕亚霖表示，这是有很多前提条件的。“比如 97% 的容器化、整体内核升到了 5.10、多语言栈、业务链条复杂、对时延敏感等，我们会觉得自研会更有优势。一旦这些前提不在了，自研就不见得比选择现有产品更好。”</p><p></p><p>嘉宾介绍：</p><p></p><p>董晓聪，作业帮基础架构负责人</p><p>吕亚霖，作业帮基础架构 - 架构研发团队负责人</p><p></p><p></p>",
    "publish_time": "2022-12-01 09:36:13",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "火山引擎公开课",
    "url": "https://www.infoq.cn/article/xUq5Q66QSwsTU4G3sLQx",
    "summary": "<p>目前，大数据、“云”相关技术逐渐成熟，处于大规模落地应用实践的喷发期，有人称现在这两个技术都要被提“烂”了，几乎每家都在做，无论是传统企业寻求数字化转型之路，还是互联网行业寻找新的业务增长点，都想要在这两者身上找到突破口。企业想要通过“云”完成降本增效和技术创新，通过大数据技术完成数据治理、数据分析等可以促进业务侧增长的任务。</p>\n<p>然而，当企业在应用了云和大数据等热门技术后会发现，企业规模扩大到一定程度后，不仅要考虑短时间内业务增长问题，而且还要能够找到持续实现业务增长的方式，“从 0 到 1 容易，从 1 到 100 不容易”。本视频便从“云”和“数据”两个方面给出了增长解决方案。</p>\n<h2><strong>视频大纲</strong></h2>\n<h4>《低成本也能稳增长，三招实现“数据驱动”的业务增长》</h4>\n<p>1 什么是低成本稳增长<br />\n2 如何实现低成本稳增长<br />\n2.1 构建用户画像，实现精细化运营<br />\n2.2 数据分析，驱动科学决策<br />\n2.3 A/B实验，用户增长的秘密武器<br />\n3 数据驱动业务增长背后的故事<br />\n3.1 火山引擎VeDI数智平台<br />\n3.2 A/B实验平台<br />\n3.3 智能数据洞察平台<br />\n3.4 客户数据平台</p>\n<h4>《亿级流量场景下的火山引擎边缘云应用实践》</h4>\n<p>1 超大规模流量场景面临的挑战</p>\n<p>2 火山引擎边缘云流量场景全链路解决方案<br />\n2.1 便捷的流量接入<br />\n2.2 高效的内容分发网络<br />\n2.3强大的边缘云基础设施<br />\n3 最佳实践</p>",
    "publish_time": "2022-12-01 10:39:48",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "2022 亚马逊云科技 re:Invent：一图看尽 Day 2 重要发布",
    "url": "https://www.infoq.cn/article/h2KIBbX6lPI0b8Fj0Reb",
    "summary": "<p></p><p><img src=\"https://static001.infoq.cn/resource/image/d2/e3/d268yyea5d05981804e04878c70947e3.png\" /></p><p></p>",
    "publish_time": "2022-12-01 11:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "聊聊云计算和 re:Invent 的现在和未来",
    "url": "https://www.infoq.cn/article/gYjPO4eITE4OIEteRFSC",
    "summary": "<p>云计算的出现给不同国家的开发者带来了哪些不一样的改变？对于re:Invent的未来，开发者们有着怎样的期待？日本开发者表示：希望现场能多点座位，因为那些高人气的会议会迅速爆满，手慢根本抢不到座位。的确，re:Invent 的人气真的太旺了！你对这场云计算盛会的未来有着怎样的期待呢？</p>",
    "publish_time": "2022-12-01 12:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "郭华：每一个人都不简单，每一瓶酒才放光彩——华润雪花的数字化人才观 ｜ 数字人才蓄能季高端论坛",
    "url": "https://www.infoq.cn/article/sCrEs13sPIU5xUTwVNkT",
    "summary": "<p>企业数字化转型过程中，IT 团队想要胜任领头羊角色，首先需要完成自我变革。重塑观念、行为和协作方式，与业务深度链接，才能发挥出技术的核心价值。IT 团队要如何助力企业实现数据驱动、科技驱动的业务增长？应该具备怎样的数字化能力？如何适应数字化组织的变革？您可以从「数字人才蓄能季高端论坛」的分享中探寻答案。</p>\n<p>极客时间企业版和培训杂志共同举办「数字人才蓄能季高端论坛」，吸引了上万名观众线上参会。论坛上华润雪花的信息化、数字化负责人 郭华分享了雪花转型升级过程中，公司人员规模缩减 50% 的挑战下，如何通过“补短板、提质量、增效益”，打造专业分工明确的数字化人才梯队，构建作战型团队构成的、灵活的、充分数字化的组织，成就雪花啤酒华丽蜕变。极客邦科技 COO 司巧蕾发布了“极客时间专项 IT 核心人才发展计划”，提供研测学考评一体化培训体验，助力企业打造卓越 IT 团队。极客时间内容总监李佳也带来了技术人才岗位能力模型搭建方法论和案例分享。</p>",
    "publish_time": "2022-12-01 12:03:03",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何破解Web3的「存力」难题？",
    "url": "https://www.infoq.cn/article/1pIQYNvrZlyCILUsWbMf",
    "summary": "<p>作者 | 蚂蚁链 LETUS 技术负责人 田世坤</p><p></p><h2>写在前面</h2><p></p><p></p><p>文字产生以前，结绳记事是人类用来存储知识和信息的主要方式。此后，从竹简、纸张的发明，到工业时代的磁盘存储，再到信息时代的数据库，存储方式不断革新，“存力”不断提高。</p><p></p><p>11 月 3 日，在 2022 云栖大会上，蚂蚁链历经 4 年技术攻关与测试验证的区块链存储引擎 LETUS（Log-structured Efficient Trusted Universal Storage）正式发布。</p><p></p><p>这一款面向区块链可信数据存储的技术产品，不仅用来解决当前蚂蚁链及区块链产业的规模化发展问题，也面向 Web3 时代提供“可信存力”支撑。</p><p></p><p>我们认为，随着大量的数据和数字资产在数字化世界里流转，可信数据的“存力”将如同电力网络的承载力一样重要。</p><p></p><p>本文希望通过对 LETUS 的深入技术解读，回答读者们普遍关心的关键问题：LETUS 是什么？主要解决哪些问题？为什么坚持用“可验证结构”？为什么要自研？以及未来要走向何处？</p><p></p><h3>背景是什么？</h3><p></p><p></p><p>从 2009 年序号为 0 的创世块诞生至今已过去十多年，“中本聪”依然神秘，但区块链技术的发展却因为公链、token、开源的推动，没有丝毫神秘感。</p><p></p><p>经过几代技术演进，在比特币的 UTXO 模型基础上诞生了应用更为广泛、支持可编程智能合约的区块链技术：通过密码学、共识算法、虚拟机、可信存储等技术，多个参与方执行相同的“指令”，来完成同一个业务逻辑，如账户转账，或者合约调用，维护不可篡改和不可伪造的业务数据。</p><p></p><p>简单讲，可将这类账本数据库，看作一个去中心化防作恶、防篡改的复制状态机，所执行的是智能合约描述的业务逻辑，而状态机通过日志 (区块数据）产生新的状态（状态数据）：</p><p></p><p>区块数据：包括交易、回执、世界状态 Root Hash 等信息，和数据库系统中的日志类似，但是块之间由 Hash 锚定防篡改，并且不会删除。（区块数据记录的是区块链上发生的每一笔交易，如：Alice 向 Bob 转账 xx）</p><p></p><p>状态数据：记录账户、资产、业务合约数据等状态信息，和数据库系统中表数据类似，需要实现可验证可追溯。（状态数据记录的是区块链上每个账户或智能合约的当前状态，如：Bob 账户剩余 xx）</p><p></p><p>链上数据的特点可以总结为以下三个：</p><p></p><p>持续增长：从创世块开始，账本数据随交易持续增长，保留周期长；</p><p></p><p>多版本：交易修改状态数据产生新版本，系统提供历史版本查询和验证功能；</p><p></p><p>可验证：交易和账户状态通过 Merkle 根哈希（Merkle Root Hash）锚定在区块头，通过 SPV（simple payment verification，简单支付证明）提供存在性证明；</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ac/aca3339ae8b6b7e66ce54267b795e30e\" /></p><p></p><p>区块链应用通过可验证数据结构（Authenticated Data Structure，如 Merkle tree）实现可验证和可追溯。我们认为，Web3“存力”一个非常重要的要素是可验证，而今天我们看到的区块链存储瓶颈大多来源于可验证结构 ADS（如 Merkle tree）的低效存取和查询，这正是蚂蚁链 LETUS 重点攻克的难题。</p><p></p><h2>我们要什么？</h2><p></p><p></p><p>随着时间推移和链上交易的增加，对存储容量的要求也不断增长，随之而来的是区块数据存储成本的大幅提升；与此同时，链上状态数据规模也持续增加，可验证数据结构持续膨胀，导致交易性能随账户规模提升和历史状态数据增加而持续下降。</p><p></p><p>2019 年，蚂蚁链上线了一个供应链金融业务，大家特别兴奋。但是，这种兴奋并没有维持多久，随着程序跑的时间越来越长，问题慢慢暴露出来。</p><p></p><p>供应链金融是面向 ToB 的，不像 ToC 端随时都有数据，可能会在某个时刻（比如每天晚上）有一笔状态数据非常大的交易进来，跑了一个星期后发现性能越来越慢。</p><p></p><p>链平台 TPS 的衰减和存储直接相关，而与共识、虚拟机都无关，随着业务合约持续写入数据，存储性能大幅衰减。</p><p></p><p>如果要在技术上长时间支持亿级账户规模、每天能稳定支撑亿级交易量，存储的规模和性能问题必须要攻克。</p><p></p><p>期间，团队也曾试过各种技术方法对他进行优化，得到一些缓解。但多次尝试之后发现，随着数量增加而出现的性能衰减，是一个绕不开的瓶颈，需要从本质上解决。</p><p></p><p>我们需要从问题表象分析背后的原因。</p><p></p><p>区块链应用通过可验证数据结构实现可验证和可追溯，但是可验证数据结构会带来读写放大（问题 1）和数据局部性（问题 2）。</p><p></p><p>而存储系统为了实现数据管理，需要对数据分页 / 分层、排序，如 KV 数据库基于 LSM-tree 将数据分层有序存储，而 MySQL 之类的数据库将数据分页，也会基于 B-tree 数据结构来排序索引。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ed/ed3ba1385d8e84b7e38fb857308689d4\" /></p><p></p><p>业界现有的实现方式，大多采用基于 LSM 架构的通用 Key-Value 数据库，在数据库之上运行一个独立 Merkle 树来实现可验证，如：</p><p></p><p>以太坊：MPT(Merkle Patricia &nbsp;Tree)+LevelDB</p><p></p><p>Diem：JMT(Jellyfish Merkle Tree)+RocksDB</p><p></p><p>背后的核心矛盾为：</p><p></p><p>Merkle 树每次状态数据修改，即使只改一个 KV，也需要从叶子节点到根节点，每一层节点都重新编码后，写到 KV 数据库，例如上图中 Alice 给 Bob 转账，需要写入 Merkle 树的 2 个叶子节点和 3 个中间节点，最坏情况需要写入数十个中间节点；</p><p></p><p>Merkle 树的节点的 key 完全随机 (如对内容算 hash，再以 hash 为 key)，数据局部性（data locality）非常不友好，如 RocksDB 里为了让 Level 内 sst 文件有序，即使没有垃圾依然需要层层进行数据压实（compaction），从而消耗了大部分的磁盘读写带宽；</p><p></p><p>数据规模越大，Merkle 树本身的层数越多，需要额外写入的 key-value 越多，DB 里的数据量越多，后台数据管理的代价越大（如 compaction 流量），消耗大量的磁盘和 CPU 资源。</p><p></p><p>除此之外，吞吐、延时等存储性能（问题 3）、持续增长下的存储成本（问题 4）、单机存储下的规模瓶颈（问题 5）也都是需要解决的问题。</p><p></p><h2>面临什么挑战？</h2><p></p><p></p><p>在过去几年的快速发展中，区块链的业务场景对交易吞吐量和响应时间要求越来越高，很多技术也被推动迭代发展，如 PBFT、HoneyBadger、MyTumbler 等高性能共识算法，BTN 等网络基础设施，JIT 加持的 WASM 虚拟机、以及高效的并行执行技术。</p><p></p><p>但比较而言，存储的性能对区块链平台整体性能影响非常大。对面向 2C 场景的数字藏品类业务（如鲸探，需支持秒杀），交易 TPS 与延时要求极为苛刻；而对需要在链上保存大量数据的存证类业务，大容量存储带来的成本又十分可观。</p><p></p><p>要支撑业务的长期可持续发展，我们归纳出区块链存储面临的核心挑战：</p><p></p><p>规模：业务账户规模可达数 10 亿，状态数据和历史版本规模分别需要支撑到十亿、千亿级；</p><p></p><p>性能：转账交易需求可达十万级 TPS、百毫秒级延时，要求性能不能受制于单机瓶颈，数据规模持续增长下性能不衰减；</p><p></p><p>成本：随着交易增长，存储容量持续增加，存储空间占用、节点间带宽占用居高不下。业务持续增长要求低成本存储。</p><p></p><p>这些问题在行业内很普遍。业界技术路线主要分三条：</p><p></p><p>路线 A：弱化可验证可追溯，如 HyperLedger Fabric 1.0 开始不支持可验证和多版本，保存读写集、只持久化最新版本状态数据；</p><p></p><p>路线 B：优化 KV 数据库存储，如实现键值分离、hash 索引的 KV 数据库等 (BadgerDB、ParityDB)，接入通用分布式数据库 (MySQL) 等；</p><p></p><p>路线 C：优化 Merkle 树，交易 ID 作为版本、树结构稀疏化，如 Diem JMT。</p><p></p><p>根据公开信息，目前区块链产品中主流的 MPT + LevelDB、JMT + RocksDB、MySQL 等存储架构，没有能全部解决上述 5 个问题的方案，难以在支持多版本和可验证的同时，满足 10 亿级账户规模下的高性能、易扩展、低成本的业务要求。</p><p></p><h2>我们做到了什么？</h2><p></p><p></p><p>我们自研了一套区块链存储引擎 LETUS(Log-structured Efficient Trusted Universal Storage)，保证完整的可验证、多版本能力，既满足区块数据不可篡改、可追溯、可验证等要求，也提供对合约数据友好访问、存储规模可分片扩展，高性能低成本等特性。同时也满足通用性，统一管理区块数据、状态数据。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/16/16f4996a2c66203f6eae5c2c61a74f22\" /></p><p></p><p>4 年前不敢想象的能力现在具备了（以下数据为统一环境下的测试结果）</p><p></p><p>大规模：通过存储集群扩展支持十亿账户规模，TPS 超过 12 万，交易平均时延低于 150ms；高性能：存储层 IO 吞吐相比以太坊 MPT + LevelDB 等架构提升 10~20 倍，IO 延迟降低 90% 以上。链平台在 7x24 高压力压测中，端到端 TPS 不随数据量增加而衰减；低成本：相比 MPT + LevelDB 架构，磁盘带宽减少 95%、空间占用减少 60%；相比于 Diem JMT + RocksDB 架构，磁盘带宽减少约 60%、空间占用降低约 40%；进一步降成本方案，供用户选用：</p><p>a. 针对区块数据容量与成本持续增长，提供智能控温分层存储能力，并应用于存证等业务降低约 70% 存储成本，同时也降低运维成本。</p><p>b. 针对状态数据的历史版本容量与成本持续增长，提供范围扫描的批量裁剪能力，实现历史版本状态数据的裁剪和后台空间回收，在十亿账户规模时，使用链原生存储可以减少近 90% 状态存储空间。</p><p></p><p>但这背后是一个技术架构的跨越，从下图左边的可验证数据结构 +KV 数据库架构，升级为现在的 LETUS 存储引擎，架构更简洁，系统更高效。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d6/d6f36bc6f97a77af1727cc47c80c8e99\" /></p><p></p><p>如 Alice 给 Bob 转账，只需要写增量数据，不需要写入 7 个 Merkle 树节点，数据局部性更友好，如 Alice 和 Bob 的账户数据，按区块号有序，不再 hash 随机。</p><p></p><h2>怎么做到的？</h2><p></p><p></p><p>图片回顾这四年，主要经历的三个大的阶段。</p><p></p><h3>阶段一：开源思路优化</h3><p></p><p></p><p>第一年里，为了满足业务急迫诉求，我们需要在有限时间内，实现亿级账户规模和交易 TPS。先从已有系统入手，深度优化了状态树，基于开源 MPT 到自研 FDMT，同时调优 RocksDB 数据库、增加并发、提升介质性能。</p><p></p><p>一系列优化措施缓解了问题，但依然无法根本解决，例如数据规模增加后，写放大依然有几十倍，数据在底层存储里依然随机分布。</p><p></p><h3>阶段二：自研存储引擎</h3><p></p><p></p><p>为了能彻底解决上述所有问题，我们不得不重新思考存储引擎的设计。</p><p></p><h4>核心设计</h4><p></p><p></p><p>针对读写放大（问题 1）、数据局部性（问题 2）和性能（问题 3），我们结合区块链特征，如可验证数据结构的读写行为、链上数据的多版本诉求、只追加和不可篡改等，重新设计存储引擎的架构分层、关键组件、索引数据结构：</p><p></p><p>根据区块链特征，我们根据可验证数据结构的读写行为、链上数据的多版本诉求，重新设计存储引擎的架构分层、关键组件、索引数据结构：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/09/09d0649ac73a74f4ff866fc3616eaf7e\" /></p><p></p><p>将可验证特性下推到存储引擎内部，由内置的 Version-based（区块号）多版本 Merkle 树提供可验证可追溯，并且直接操作文件，从而缩短 IO 路径；</p><p></p><p>将可验证特性下推到存储引擎内部，由内置的 Version-based（区块号）多版本 Merkle 树提供可验证可追溯，并且直接操作文件，从而缩短 IO 路径；</p><p></p><p>多版本 Merkle 树的 Node 聚合为 page，提升磁盘友好性，page 存储采用 Delta-encoding 思想避免 in-place 更新（结合 Bw-tree 思路），状态数据修改时主要保存增量，定期保存基线，从而减少写放大，也减少了空间占用；</p><p></p><p>为 page 存储实现 Version-based 的存储与检索，索引 page 都按区块号有序写入、在索引文件里有序总局，核心数据结构为 B 树变种，从而实现有序数据 locality；</p><p></p><p>利用区块链场景数据的追加写、Immutable 特点，架构上采用 Log-Structured 思想，通过日志文件来组织数据；</p><p></p><p>数据与索引分离，数据按区块号有序写入数据文件，通过异步 IO、协程并发等提升系统并发度，索引多模，区块 &amp; 状态通用，除 Merkle 树支持状态数据，实现有序 B 树支持区块数据；</p><p></p><p>当前最新版本 Merkle 树优先在内存里缓存或者全部缓存，链上合约执行时，如果存在则直接读取，不需要访问 page 来重放，从而加速合约执行。</p><p></p><p>基于些核心设计，实现了成本降低的同时性能提升，链平台交易 TPS、延时等性能指标不会随着数据规模的提升而衰减。</p><p></p><p></p><h4>降成本</h4><p></p><p></p><p>虽然存储资源占用大幅降低后，但是链上数据依然面临持续增长带来的高成本问题（问题 4）。</p><p></p><p>基于 LETUS 架构的后台数据治理框架，我们能很方便的扩展实现数据迁移 / 压缩 / 垃圾回收等治理策略，基于这些策略，为用户提供进一步降成本能力，并针对自己的业务特点来选择使用：</p><p></p><p>（1）智能控温分层存储：存储介质按照性能、成本分层，通过智能控温调度数据在不同介质的分布量，将冷数据后台自动迁移到廉价介质（如 NAS），降低存储整体成本，并实现容量扩展，不受单盘空间限制。</p><p></p><p>（2）范围扫描的批量裁剪：对于历史版本 Merkle 树和状态对象，基于版本有序性与内置 Merkle 树，让用户可以指定目标区块号范围裁剪，通过 Page 边界扫描，批量索引与数据裁剪、垃圾回收实现存储空间释放，进一步降低状态数据成本。</p><p></p><h4>规模扩展</h4><p></p><p></p><p>针对问题 5，LETUS 采用分布式存储架构，实现单个共识参与方计算和存储分离，计算层和存储层可分别部署独立集群，通过高性能网络通讯框架进行数据读写访问。</p><p></p><p>为了对海量状态数据进行灵活的数据分片，并且保证各个区块链的参与方 hash 计算的一致性，将数据切片为 256 个最小存储单元（msu），并将一个或者多个 msu 构成一个状态数据分片（partition），将所有数据分片调度到多个物理机器。从而实现规模弹性扩展，解决了单机存储的容量瓶颈和带宽瓶颈。</p><p></p><h3>阶段三：生产落地</h3><p></p><p></p><p>为了全面落地铺开的同时让业务平稳运行，能够开着飞机换引擎，在这几年的研发过程里，我们充分准备、循序渐进的分阶段落地：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/27/27c805677fee7ad148ef5b842fc7467d\" /></p><p></p><p>2021 年 5 月，基于 LETUS 存储引擎的区块数据冷热分层，在版权存证业务灰度上线，存储成本降低 71%，解决容量瓶颈并降低运维成本。</p><p></p><p>2021 年 8 月，基于 LETUS 存储引擎的状态数据，在数字藏品平台“鲸探”双写灰度上线，并成功支撑秒杀场景；</p><p></p><p>2022 年 2-6 月，LETUS 引擎的历史状态数据裁剪、存储服务架构升级等生产 ready，在数字藏品和版权存证等业务全面落地，并从灰度双写切为单写；LETUS 单写意味着对硬件资源要求大幅下降，我们将“鲸探”生产环境的云资源全面降配，降配后链平台性能水位提升 200%，同时存储成本下降 75%。</p><p></p><h2>总结与展望</h2><p></p><p></p><p>蚂蚁一直坚持“成熟一个开放一个”的技术战略。同样的，LETUS 不只为蚂蚁链定制，也同样给其他联盟链、公链提供高性能、低成本的支持。</p><p></p><p>蚂蚁链坚持技术自研，确保在共识协议、智能合约、网络传输、存储引擎、跨链技术、区块链隐私计算等领域处于全球领先水平。我们始终认为，坚持技术自主研发是建立长期可持续竞争力的关键。</p><p></p><p>在“可信存力”这条赛道上，我们也需要为进一步的技术壁垒提前布局，如合约结构化查询语言，为链上合约实现结构化 + 可验证的查询能力, 提升开发者体验；Fast-Sync 与节点多形态，提升组网效率和节点成本灵活性；以及 Web3 等潜在的技术生态。</p><p></p><p>技术创新永远在路上。接下来，继续沿着硬核技术方向突破，啃一些硬骨头，持续为整个价值互联网提供可靠的、可持续的存力。</p>",
    "publish_time": "2022-12-01 12:36:33",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "OpenStack已死？最新报告显示OpenStack部署呈爆发式增长，整体规模超4000万",
    "url": "https://www.infoq.cn/article/xb600VAYhlzQcjuvAKeN",
    "summary": "<p></p><p>&nbsp;在业内人士质疑 <a href=\"https://www.infoq.cn/article/Z8p-Se31uh0NrLNHt5BT\">OpenStack</a>\"（世界第四大开源项目）是否已死之际，OpenInfra 基金会近日<a href=\"https://www.openstack.org/user-survey/2022-user-survey-report\">测得的数据</a>\"显示，生产中的 OpenStack 内核数量达到前所未有的 4000 万，同比 2021 年增长了 60%，自 2020 年以来增长了 166%。官方认为，该增长是对混合云环境和Kubernetes集成支持的依赖程度增加带来的。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/b5/b5a134634d339663547e432f0719e828.png\" /></p><p></p><p>&nbsp;OpenStack表示，各种规模的组织都在进行扩展来满足最终用户的需求。如LINE是日本的一款即时通讯服务，在日本每月有1.76亿活跃用户。他们的云由OpenStack提供支持，其内核数量增加到了400万个，比2021年增加了150%。Workday是一家基于云计算的财务管理、人力资本管理和学生信息系统软件供应商，今年其OpenStack内核数量再次翻了一番，达到284万个。据悉，全球超过300个数据中心由OpenStack 驱动的公有云支持。</p><p>&nbsp;</p><p>另外，作为 OpenInfra 标准，Linux OpenStack Kubernetes Infrastructure (LOKI) 正在以越来越快的速度在生产中实现。Kubernetes 现在集成在超过 85% 的 OpenStack 部署中：73% 通过 vanilla Kubernetes，另外 12% 通过 Red Hat 的Kubernetes 发行版<a href=\"https://xie.infoq.cn/article/d6672373174b4a0ee3288127a\">OpenShift</a>\"。</p><p>&nbsp;</p><p>Red Hat 也是 OpenStack 的支持者。Red Hat 产品管理经理 Maria Bracho 表示：“在过去的几年里，越来越多的客户在不同的部署模型中同时使用 OpenStack 和 OpenShift。在 Red Hat，我们做了大量的工作来确保这些平台可以一起使用，用户不需要在一个平台或另一个平台之间做出选择，而是可以自由、坚定地选择最适合当前和未来工作负载的配置。”&nbsp;</p><p>&nbsp;</p><p>OpenStack 和 Kubernetes 生产集成的增长进一步体现在，使用 Magnum（用于容器编排的 OpenStack 服务）运行生产工作负载的用户增加到 21%（去年仅为 16%）。</p><p>&nbsp;</p><p>OpenStack 通常用于混合云。根据 Flexera 报告，80% 的受访者正在采取公有云和私有云同时使用的混合云策略。这一趋势也反映在了 OpenStack 的用户调查中：运行混合云环境和 OpenStack 部署的受访者从 77% 上升到 80%。</p><p>&nbsp;</p><p>Octavia的采用率增加，为越来越多部署了OpenStack的混合云环境提供支持。为了实现工作负载在不同云环境之间的平稳过渡，越来越多的运营商转向使用开源的负载均衡方案 Octavia， Octavia 可以与 OpenStack 配合使用。几乎一半的生产部署都在使用 Octavia，比去年增加了 11%。</p><p>&nbsp;</p><p>OpenInfra 基金会总经理 Thierry Carrez&nbsp;表示，“随着OpenStack部署以惊人的数量持续增长，OpenStack社区正在证明它不仅活得很好，还为组织提供了无可争辩的价值。”</p>",
    "publish_time": "2022-12-01 12:42:09",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "云基础设施性能再提升！re:Invent Day1 重大发布一览",
    "url": "https://www.infoq.cn/article/CLHBFwbSNzSYG4PhYeZH",
    "summary": "<p>re:Invent Day1 ，亚马逊云科技高级副总裁 Peter DeSantis 带来以云性能为核心的多项重要发布！一场开发者们的聚会还在继续～</p>",
    "publish_time": "2022-12-01 12:42:42",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "1年巨亏100亿美元，亚马逊Alexa成烧钱“无底洞”，语音助手为什么不赚钱？",
    "url": "https://www.infoq.cn/article/QNcQ16QQRGK7tQhOqeU9",
    "summary": "<p></p><blockquote>从亚马逊Alexa聊起，语音助手为什么就不赚钱？留给大型科技公司语音助手的时间是不是不多了？</blockquote><p></p><p></p><p>近日，有报道称亚马逊的<a href=\"https://www.infoq.cn/article/gsEel0fax469NrUARbjp\">Alexa语音助手</a>\"和智能音箱业务总亏损已达100亿美元。值此消息发布之际，Alexa的几位竞争对手也纷纷表示日子难过，需要找到靠谱的办法让自家产品开始盈利。</p><p></p><p>从Alexa和其他几款语音助手的现状来看，用技术让人眼前一亮简单，但把这种技术转化为能赚钱的业务却是无限艰难。如今科技企业正忙于裁员、为即将到来的经济大衰退做准备，这些看着酷炫但却无助于进项的产品必须尽快找到价值定位，否则必然被无情抛弃，以省下资源来抵御寒冬。</p><p></p><h2>处于危机中的 Alexa</h2><p></p><p></p><p>当前，亚马逊正在经历着公司历史上最大规模的裁员，计划削减约 1 万个工作岗位。受冲击最严重的部门之一是亚马逊的 Alexa 语音助手。显然，该部门在这家电子商务巨头已经失宠。</p><p></p><p>Business Insider 在一篇报道中详细描述了“语音助手和亚马逊大型硬件部门的迅速衰落”。</p><p></p><p><a href=\"https://www.infoq.cn/article/2017/12/Alexa-amazon-bussiness\">Alexa </a>\"是一个开创性的语音助手，诞生已有近 10 年，谷歌和苹果都在很大程度上模仿了它。然而，Alexa 从未设法创造出可持续的收入流，所以 Alexa 并没有真正赚到钱。</p><p></p><p>Alexa 部门与亚马逊 Prime 视频同属于“全球数字”集团。按照 Business Insider 的说法，该部门仅在 2022 年第一季度就亏损了 30 亿美元，其中“绝大多数”亏损都是因为 Alexa。显然，这是其他部门亏损总和的两倍。该报道称，硬件团队今年预计将亏损 100 亿美元。听起来，亚马逊已经厌倦了烧钱。</p><p></p><p>Business Insider 在报道前采访了该公司硬件团队的 12 名现任和前任员工，他们将 Alexa 描述为“一个处于危机中的部门”。几乎所有利用 Alexa 变现的计划都失败了，其中一名前员工称，Alexa 是“想象力的巨大失败”和“一个浪费掉的机会”。11月的裁员说明他们多年来试图扭转局面的努力并未取得实质性的成果。</p><p></p><p>据报道，在亚马逊，Alexa 是前首席执行官杰夫·贝佐斯的“宠物项目”，当时它获得了巨大的发展空间。2019 年，他们召开了一次全员危机会议，试图扭转亏损问题，但无果而终。到 2019 年底，Alexa 的招聘工作冻结，从 2020 年前后开始，贝佐斯对该项目失去了兴趣。当然，亚马逊现在有了一位全新的首席执行官安迪·贾西，显然，他对保护 Alexa 不感兴趣。</p><p></p><p>报道称，尽管 Alexa Echo 系列是“亚马逊上最畅销的产品之一，但大多数设备都是按成本价出售的。”对于其商业模式，一份内部文件是这样描述的：“我们希望在人们使用我们的设备时赚钱，而不是在他们购买我们的设备时赚钱。”</p><p></p><p>不过，这个计划从未真正实现过。</p><p></p><p>他们希望在用户使用 Alexa 的间隙插播广告，通过这种方式引导人们通过语音在亚马逊上购物。但是，没有多少人愿意信任一个 AI 产品，不看图片或阅读评论就花钱或购买商品。报道称，到 Alexa 实验的第四年，“Alexa 每周收到 10 亿次交互，但其中大多数对话都是播放音乐或询问天气之类的简单命令。”这些简单对话是无法盈利的。</p><p></p><p>亚马逊还试图围绕 Alexa 技术与一些公司开展合作，让用户通过一个语音指令就可以购买达美乐的披萨或叫辆优步，而在这个过程中，亚马逊可以获取佣金。报道称：“由于使用不多，到 2020 年，该团队已停止发布销售目标。”该团队还试图将 Alexa 描绘成一个光环产品，吸引那些更有可能在亚马逊购物的用户，即使他们不通过语音购物，但对这一理论的研究发现，这些用户的经济贡献往往达不到预期。</p><p></p><p>在给员工的一份公开声明中，贾西表示，公司对 Alexa 的发展仍然“有信心”，但这是在大幅削减 Alexa 团队之后。一名员工告诉 Business Insider，目前，“对于这款硬件设备的未来，尚没有明确的指示”，而且由于硬件不赚钱，也没有明确的动机来不断迭代这个深受大众喜爱的产品。这种方向性的缺失给了在亚马逊内部颇受争议的 Astro 机器人 机会。实际上，这个价值 1000 美元的机器人就是一个带轮子的 Alexa。根据 Business Insider 的追踪调查，Alexa 目前在美国语音助手大战中排名第三，谷歌的 Assistant 有 8150 万用户，苹果的 Siri 有 7760 万用户，Alexa 有 7160 万用户。</p><p></p><p>下面，我们来看看已有8年历史的亚马逊Alexa到底做对了什么，又有哪些遗憾。</p><p></p><h2>技术不错，但还不够好</h2><p></p><p></p><p>一系列技术创新，使得亚马逊Alexa这样的语音助手能够实现10到15年前根本无法想象的理解能力。</p><p></p><p>自动语音识别持续发展，助手可以在各种背景噪音下准确采集指令、解析用户口音。由深度神经网络（包括Trasnformers、RNN和LSTM等）驱动的自动语言处理系统，则让语音助手能够将语音内的不同细微差别映射至对应的指令，允许用户用灵活多变的方式下达类似的要求。另外，各种应用平台、API等已经能让语音助手遍历网络上的大量信息，再把指令跟应用程序功能对接起来。</p><p></p><p>这一切听起来都很美，但如今的语音助手仍有着明确的功能边界。在大多数情况下，亚马逊Alexa只能完成简单的任务，例如设置闹钟、播放音乐、播报天气和在网上搜索简单信息等。这些功能要么指向性很强，根本就没多少犯错的空间，要么就是敏感性很低，哪怕做错了也没多大影响。</p><p></p><p>但如果我们想要执行某些敏感、需要多次交互或者具有多模实质的任务，语音助手的可靠性就会急剧下降。</p><p></p><p>例如，当我们想要网购（这也是亚马逊最初为Alexa规划的重要用例之一）时，就属于典型的敏感任务，因为其中涉及金钱，用户不希望出错。另外，网购操作比较复杂，其中往往涵盖多个步骤，用户希望看到自己买了什么，参考其他建议和类似的选项。这一切在纯语音界面上显然很难实现。出于类似的理由，日程安排和会议规划等预期用途在语音助手上也基本没能铺开。</p><p></p><h2>语音助手无法创造可盈利的商业模式</h2><p></p><p></p><p>好了，现在我们有了一款很酷的语音助手，能够非常准确地执行某些特定任务，而在其他场景下虽然也做尝试，但表现平平。在这样的前提下，我们要怎么靠它赚钱？</p><p></p><p>具体选项无非以下几种。</p><p></p><p>首先就是销售硬件，例如亚马逊Echo、苹果HomePod或者谷歌Nest之类的智能音箱。</p><p></p><p>在这种情况下，语音助手技术的商业价值就直接取决于设备价格、所能售出的设备数量以及客户更换这类设备的频率。换言之，这种商业模式跟智能手机很像，人们每隔几年就会掏几大千去买下一代iPhone或者Pixel手机。</p><p></p><p>但那可是手机，智能音箱缺少催人升级换代的动力。第一，人们不想为这些音箱支付很高的溢价，毕竟本身使用频率就不高；第二，智能音箱的升级空间也不大，一个麦克风、一个喇叭、再加个显示屏，也就差不多了；最后，用于支持语音助手的云服务也有升级和维护成本。所以综合来讲，用户对智能音箱的使用会给厂商带来持续存在的成本，并在日积月累后逐步超过当初销售音箱所创造的利润。</p><p></p><p>第二种思路就是出售服务。在这种情况下，用户需要按月或按年付费才能使用手机或智能音箱上的语音助手。但让人单独付费真的很难，产品必须具有明确的价值才能说服用户为此买单。为了让这种商业模式取得成功，产品必须能够解决某些业界尚未解决的难题，或者创造足够直观的附加价值，进而与产品/市场相契合。遗憾的是，亚马逊Alexa和其他语音助手都达不到这样的高度，单独收费更是痴心妄想。</p><p></p><p>最后，有些朋友可能还指望着将亚马逊Alexa当成吸引用户购买其他产品的渠道，比如前面提到的网购操作界面。但语音助手天然就不适合这类操作，所以Alexa没法提供理想的购物体验。用户显然更愿意在手机或电脑上操作购物软件，那样更直观也更顺畅。</p><p></p><p>总而言之，从科学和工程的角度看，亚马逊Alexa确实令人印象深刻&nbsp;。但从产品和业务的角度看，它也确实不具备变现的条件。</p><p></p><h2>下一代语音助手会是什么样子？</h2><p></p><p></p><p>第一代语音助手的思路还是不错的，即将声音作为计算机操作界面，但却无法创造可盈利的商业模式。类似的情况在1990年代的VR头显（价格太高、体验太差）和2010年代的AR眼镜（同样是价格太高，在功能上支撑不起这样的成本）也曾出现过。</p><p></p><p>如今Alexa和Siri之所以还存在，就是因为其背后是两家财力极为雄厚的企业。双方可以不断砸钱进去，在承受亏损的同时慢慢摸索商业模式和技术可能性。</p><p></p><p>那么，下一代语音助手又将朝哪个方向前进？也许有以下几种可能。</p><p></p><p>首先，等待<a href=\"https://www.infoq.cn/article/6J7vxg0J25cMzWRoMQkU\">AI技术</a>\"的发展让语音助手愈发强大，从而为更多应用场景提供支持（例如主动式语音助手，由它在必要时主动询问意见，而非靠指令被动激活）。</p><p></p><p>另一种方案就是将现有通用型语音助手转化为面向特定场景的专业助手。如此一来，我们就能把语音助手集成到应用场景的上下文和工作流中，让它们有能力处理步骤更多、复杂度更高的任务。这种形式有望建立起B2B商业模式，特别是在那些需要大量手动操作的行业（例如制造业、饭店和酒店等）中，可以尝试用语音助手降本增效。正如第二代谷歌眼镜在手工领域获得了不错的市场认可，这类业务场景的附加价值也将远超普通消费级市场。</p><p></p><p>目前还很难确定未来的智能音箱到底还需不需要显示屏。毕竟我们的大部分日常事务都涉及视觉元素，而纯语音助手在应用上还有很多局限。技术发展应该会给出答案。</p><p></p><p>总之，目前亚马逊还没有放弃Alexa的打算。但无论如何，现有语音助手的能力极限已经明确，是时候朝着下一代技术方案进军了。</p><p></p><p>原文链接：</p><p><a href=\"https://arstechnica.com/gadgets/2022/11/amazon-alexa-is-a-colossal-failure-on-pace-to-lose-10-billion-this-year/\">https://arstechnica.com/gadgets/2022/11/amazon-alexa-is-a-colossal-failure-on-pace-to-lose-10-billion-this-year/</a>\"</p><p><a href=\"https://bdtechtalks.com/2022/11/28/amazon-alexa-revenue/\">https://bdtechtalks.com/2022/11/28/amazon-alexa-revenue/</a>\"</p>",
    "publish_time": "2022-12-01 13:40:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "亚马逊云科技 CEO 倾情分享，系列重磅产品发布！",
    "url": "https://www.infoq.cn/article/Db2Bb03cBij3IAzjT81g",
    "summary": "<p>亚马逊云科技 CEO 现场阐述云战略，系列重磅产品发布！</p>",
    "publish_time": "2022-12-01 15:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "全网都是数字人，鹅厂的数智人有何不同？",
    "url": "https://www.infoq.cn/article/zZ5AV78D35mL34eaG44O",
    "summary": "<p></p><p></p><blockquote>一个智慧与颜值并存的数智人是如何“养成”的？</blockquote><p></p><p></p><p>在元宇宙风潮之下，数字人先火了。近两年，国内数字人项目呈现井喷态势。IDC预计，到2026年中国AI数字人市场规模将达到102.4亿元。作为时下最热的技术话题，我们判断，开发者有必要对数字人技术有完整的认知和理解。</p><p></p><p>在此背景下，InfoQ 特别策划了《数字人基础技术解析》专题。本专题将首先对数字人做概要介绍，紧接着围绕数字人的技术、应用落地等维度分别做解读。我们将收集来自国内业界一流团队的最佳实践，供读者参考。</p><p></p><p>本文是本专题的技术&amp;实践篇。近日，腾讯云智能数智人产品总经理陈磊接受了InfoQ专访，详细介绍了腾讯云智能在数智人上的技术探索和应用落地实践。</p><p></p><h2>“数智人”和“数字人”</h2><p></p><p></p><h3>市场升温</h3><p></p><p>近两年，尤其是在今年，数字人火出了天际。陈磊认为，这种火热主要基于两方面因素助推。</p><p></p><p>一方面，得益于多项技术的发展，云计算、5G、音视频技术、人工智能技术、渲染技术等都在不断地发展和突破，让虚拟人在制作和应用环节大大提效、简化；在虚拟人的落地和行业扩展上，不再只是从前传统的“中之人”方式，只面向影视、娱乐行业输出，而是在各种各样的行业加速落地。</p><p></p><p>另一方面，从行业的维度看，全球科技巨头纷纷对元宇宙加大投入，例如Facebook改名Meta，宣布All In 元宇宙；英伟达推出元宇宙基础模拟和协作平台Omniverse；EPIC的MetaHuman等加速元宇宙基建进程... 这些都是强烈的市场信号。而被广泛认为是人机交互新入口的数字人乘着这股东风率先起势，从技术发展、市场应用双轨运行的发展情况来看，虚拟数字人行业进入了快速发展的轨道。</p><p></p><h3>腾讯布局“数智人”</h3><p></p><p>嗅到这样的产业趋势后，2021年，腾讯云智能围绕对话式AI，升级研发推进“数智人”业务，陈磊主要负责该业务团队的产品和研发。</p><p></p><p>在去年的腾讯数字生态大会上，腾讯首次公布了云智能的战略架构，整体面向管理者、生产者、开发者、用户四大人群，提供决策、协作、创新和服务四大核心能力。陈磊表示，数智人是腾讯云智能的一个重要的组成部分。数智人以服务于人作为价值理念，实现智慧与颜值兼备，为企业创造价值，为用户提供有温度的服务。</p><p></p><p>与市面上流行的“数字虚拟人”，“AI数字人”、“数字人”等概念不同，腾讯云智能对数字人的命名倾向于“数智人”。</p><p></p><p>“腾讯的理解是，通常说的数字虚拟人，AI数字人等概念，更侧重好看的皮囊，但数智人本身面向企业服务时需要两个维度，既要有好看的皮囊，还要有有趣的灵魂。腾讯把数智人定位在“交互智能入口级”相关的应用，技术上包括感知、驱动、决策等链路，应用上链接了整个腾讯丰富的内容与服务生态。依赖这种生态，我们打磨了平台能力。在具体场景应用时我们也可以结合行业里的知识图谱，从智能维度做升维，让客户打造出具有自主IP、智能决策和生动交互的AI数字人，实现数字人到数智人的进化”陈磊解释。</p><p></p><p>在12月1日举办的腾讯数字生态大会上，《数字人产业发展趋势报告2023》发布并指出，AI驱动的数字人。通过 AI 建立人与大数据的连接，提高效率并满足人情感交流需求 ，提升用户体验，将成为人机交互新入口。</p><p></p><p>“目前使用文字或语音交互的场景都可用 AI 数字人软着陆的方式替代，不需要改变原有的业务逻辑和商业模式 ，大众接受成本较低。与此同时，数字人作为企业的数字资产 ，是对员工工作的增强，具有生产力的属性，可以进一步释放生产力，同时降本增效。未来数字人将根据不同行业的业务特点和应用场景进行更深度结合， 孵化千行千面的数字员工 ，提供智能化服务。”</p><p></p><h2>如何打造“智慧”与“颜值”兼备的数智人？</h2><p></p><p></p><h3>多项技术作支撑，AI技术是核心</h3><p></p><p>去年11月，腾讯云智能发布了数智人产品矩阵，包括3D写实、3D半写实、3D卡通、2D真人、2D卡通五种风格的数智人产品。</p><p></p><p>这些多样风格的产品主要基于形象的写实度和应用场景维度划分，可以定制化不同的角色，满足各类场景服务需求，可承担资讯播报、文旅导览、座席客服、多语种主播、手语主播等角色。</p><p></p><p>这些全能的功能背后，由一系列技术在支撑。3D写实数字人提供交互服务时，需要很强的渲染技术，包括端渲染技术、云端渲染技术等。形象表现力层面，需要很强的算力和渲染支撑。在应用维度，音视频、5G等更快的网络技术可以帮助数智人加速应用落地。</p><p></p><p>陈磊介绍，数智人是AI综合类的应用，从形象生成到交互、决策、驱动、服务等环节都会应用到AI技术。</p><p></p><p>腾讯云智能数智人集合了腾讯公司内部多个团队的优势AI能力，例如在数字人生产环节，在人像建模方面，通过优图实验室的相关AI技术，可以做到凭借几张照片就快速生成写实级的人脸；在动作绑定环节，例如将动作从A数智人迁移到B数智人，可以利用IEG的NExT Studios团队的动作和表情迁移工具，快速绑定，相比于传统的需要用动捕设备从零开始采集动作大大提升了生产效能；对话式AI，由云小微语音AI技术支撑；多情感驱动能力，由AI Lab的相关支持等等。此外，如果面向多维终端，终端渲染性能不够的时候，云渲染或云游戏相关的技术可以实现，即使在云端渲染，但能实现实时交互性无感知，延迟性很低....</p><p></p><p>虚拟数字人的发展需要一个全域的技术支撑。腾讯的优势在于，每一个单点的技术维度，都有团队在多种应用场景中，做持续的深耕跟突破，因此在数智人构建的每一个维度都已经建立起很强的技术壁垒，这也是腾讯做数智人的优势所在。与此同时，这些技术都在腾讯云的技术架构下，通过云智能数智人整体对外输出，助力行业升级。</p><p></p><h3>多模态交互</h3><p></p><p>多模态交互是数智人背后的核心技术支撑，各家都在强调这项技术。</p><p></p><p>陈磊介绍，与业内同类产品相比，腾讯云智能数智人在该项技术上拥有多项差异化优势。</p><p></p><p>具体而言，腾讯云智能数智人融合了ASR、TTS、NLP、计算机视觉、知识图谱等全栈式的AI底层能力。相对来说，在中小企业里面，具备全栈式能力的还是少数。而且，如何更好地将这些全栈型能力整合在一起更富有挑战。将这些能力融合在一起，才能让数智人拥有强大的表现力、识别力和感知理解能力。</p><p></p><p>此外，腾讯云智能数智人目前支持34个语种，包括各种方言，翻译超过11个语种。在多个垂直行业，有46万个垂直行业的不同场景的热词库，在多业务场景里能让数智人做到“听得清、听得懂、会表达”。</p><p></p><p>在实时交互上，与行业相比，腾讯云智能数智人图像生成首帧延时小于600ms, 行业同类产品图像生成首帧延时大于1s、1.5s。</p><p></p><p>陈磊介绍，低延迟这这一效果的实现，依赖全链路的优化。一般分三步，第一步是图像生成：生成每帧视频内容；第二步是链路传输：把视频通过音视频技术传输；第三步，设备终端播放。其中在第一步，团队采用了模型裁剪、蒸馏技术，加速推理方式，快速提升了生成数智人的图像生成能力；第二步中应用到的音视频传输链路技术素来是腾讯的强项，公司音视频实验室为此提供了很多技术能力，将所有核心环节的能力打通串联后，才实现了600毫秒以内的延迟效果；第三步，在多设备的终端播放中，腾讯也有配套的编解码播放器。</p><p></p><h3>音视频技术</h3><p></p><p>当涉及到一些写实数智人时，对算力的要求会比较高。如果普通大众使用，很可能在手机上根本跑不起来。</p><p></p><p>但手机端又是数智人的一个很重要的应用端口，有一些客户希望自己的数智人与用户进行互动或服务。这个过程会涉及到云端渲染的能力以及音视频传输的能力。用户手机中的网络环境、带宽场景等各不相同，如何保证实时流畅的、低延迟的交互，就需要应用到音视频技术。</p><p></p><h3>小模型训练方案：以小胜大</h3><p></p><p>与业内一些数字人产品多采用大模型方案不同。在训练方案上，腾讯云智能数智人更偏爱小模型，采用了 5亿级别的小参数量的多语言预训练模型“神农MShenNonG”。</p><p></p><p>陈磊介绍，腾讯云智能在一些场景下也构建了百亿或千亿级的超大模型，但在实际应用中发现，考虑到在应用过程中部署的便利性和部署成本因素，仍需要对模型参数量进行控制。以千亿级别的超大模型为例，训练时间长，从训练到落地需要很长的周期，而且如果当客户偶然有小范围的数据变化时，需要不断滚动模型。总而言之，周期、成本等对应用上线带来了较大挑战。</p><p></p><p>针对亿级别这种参数小规模的多语言训练模型，也需要做数据量控制。对此，腾讯云智能数智人团队综合运用了混合编码的数据增强，基于多尺度的多语言信息融合，将语种和语义做对比等策略性尝试。</p><p></p><p>模型虽小但智能化程度一点不差。数智人构建采用小模型的训练方案具有诸多优点。在数据层面，腾讯云智能研究团队进行了混合编码数据的构造方式，利用双语对齐的词典和句子检索工具，能构造出大量多语言混合的训练数据。此外，在模型层面，团队还做了一些特殊工作，如可插拔，基于多尺度的多语言信息的融合技术，对低频词汇建模等。在低资源语种方面，小数据、小模型能解决很多问题。在训练层面，相比于传统的市场上一般需要一个月以上的模型迭代周期，神农MShenNonG只需十天左右就能快速达成模型的迭代。</p><p></p><p>陈磊认为，未来，在数智人的模型训练方案上，将逐渐呈现融合趋势。如果企业具有足够大量的数据或足够大的场景，大模型方案是优选。但现实是，在实际应用场景下，很多时候没有那么多数据，也缺乏算力资源，在迭代周期上也不允许时间战线拉得很长。因此，未来会是大模型与小模型融合的趋势。</p><p></p><h2>数智人走进现实</h2><p></p><p></p><h3>数智人形象生产平台</h3><p></p><p>过去一年，云智能数智人团队发现，数智人在行业应用时，落地场景和行业非常广泛，实现规模化的批量生产显得越来越重要。在行业场景越来越多的情况下，如何持续、快速地实现行业落地，比较大的挑战是怎么样能快速地生产出数智人，且用低成本高效率的服务把它送到客户的场景里去。</p><p></p><p>因此，在数智人生产维度上，团队重点打造了数智人形象生产平台，通过自动化的生产管线，提升面向行业的数智人的供给效能，降低生产周期。</p><p></p><p>关于数智人形象生产平台的具体运作流程。以面向传媒落地的2D交互数智人为例，传统的数智人的生产方式是，找主播在录影棚录制形象视频，且线下会对视频数据做很多手工处理，整个构建流程需要花1-2个月时间。有了管线后，可以通过AI技术来处理视频数据，如自动做AI人像分割，人与背景分离，自动拆帧，以提升交互表现力，在拆解后还可以对形象做美颜，进行各种数据增强，如美白、去痣、眼神对齐等影视级交互技术。</p><p></p><p>一般而言，客户定制一个3D写实数智人的流程包括人物设定，原画设计，建模，绑定，服装、发饰、渲染，再加上驱动和多模态交互等环节。</p><p></p><p>AI技术可以对上面各个环节实现降本增效。如在建模环节，比传统CG建模时间节省不少， 以前需要月级别时间，现在通过人像生成技术，周级别就能搞定。在建模成本上也有了很大降低，写实类的数字人，普通公司建模成本仍很高，腾讯云智能数智人的建模成本已显著降低，例如在建模维度上已基本不需要过多成本，只需要配一些头发加衣服，成本可以缩减一半以上。</p><p></p><p>但值得注意的是，目前在数智人建模技术上仍存在挑战。对于超写实数字人这个类别，通用建模的能力和标准还无法做到特别完美，当前技术上还达不到超写实的自动生成技术，主要还是采用传统方式，如在头发制作环节，多数依赖传统CG公司手工制作。现在AI在头发生成技术上也在做探索，但目前还没达到可落地应用的阶段。比如，基于同一个衣服作为基底的模版，在上面换纹理，可以降低成本，但如果是一件全新的衣服，且是柔性材质，也还依赖外部能力供给。</p><p></p><p>但对于2D真人数字人，通过这套生产管线，即便是一个不懂AI技术的员工也可以自主跑通这套流程，大大降低了制作门槛。构建时间压缩到了天级别，且管线在并发维度不存在卡点，比之前大大提速。</p><p></p><h3>应用在金融、传媒等多个领域</h3><p></p><p>据介绍，在应用环节，腾讯云智能数智人团队最初重点关注金融、传媒等典型场景的典型应用，之后再做单点切入。今年，团队一方面在行业服务或企业服务维度上做更多垂直或场景的提升。另一方面关注交互智能入口维度。数智人定位在交互智能入口级的应用。如常常能看到数智人在银行迎宾、理财知识讲解等场景下应用，其背后的逻辑主要是让服务的“体感温度”得到较大提升。</p><p></p><p>目前腾讯云智能数智人已在金融、政务、传媒、文旅、交通等多行业广泛落地。</p><p></p><p>如在应用服务上，在中信建投应用里，腾讯云智能数智人是在证券行业首个落地的交互型数智人；在手语维度上，3D手语数智人聆语担任冰雪赛事手语解说翻译官；在文旅领域，打造了国博的虚拟形象代言人艾雯雯；在汽车领域，将交互型的数智人做了体感升级；在与一汽大众的合作中，将虚拟人与虚拟空间结合做更新形式的体验式服务的改进，大幅提升用户体验。</p><p></p><p>陈磊介绍，数智人的落地行业适配，一般分为两个阶段，第一是基于既有行业的数据积累，构建垂直领域的预训练模型；第二，针对一些特殊项目，数智人具备可以提供第三方知识的能力，或基于客户的小样本数据再训练的能力，将这两点结合起来就能把整体的数智人企业服务做得更好。</p><p></p><p>比如，面向行业做深度的企业服务，融入对话式AI，从前台疑问解答、产品推荐到售后客户服务，再结合智能对话能力做会话洞察，最终可以横跨整个生命周期。这要求数智人服务同时具备行业深度和场景深度，结合对话式AI模型的训练能力做行业增值与提效。</p><p></p><p>例如在金融场景，腾讯已在某金融机构落地了3000+以上的数智人客户服务，辅助传统人工客服工作，由数智人+对话式AI帮助解答用户问题。</p><p></p><p>腾讯云智能数智人在不同的行业实际应用时，对领域知识的要求也较高，在不同的行业构建行业知识图谱。通过神农MShenNonG对话模型快速迁移、进驻到一个行业，在进驻行业后又帮客户快速打造出面向自己行业的模型。</p><p></p><h3>应用难点</h3><p></p><p>但整体上来看，数智人在行业落地还存在不少难点。如行业知识沉淀储备不够，或者内容不够规范完备。对此，腾讯云智能数智人团队在构建知识生产的工具，提升知识生产的效率与效应。此外，在行业拓展时，腾讯云智能数智人团队走的一个方向是通过NLP的能力，快速训练模型的能力，让数智人掌握住更好的领域技能。</p><p></p><p>另一个难点是算力。虚拟人对算力有较强的要求，随着算力提升，数智人整体的表现力将直线上升。表现力包括形象渲染的逼真度，表情的逼真度，驱动技术、感知技术、决策智能的技术的呈现效果。在数智人的一些内容生产环节，以及数智人与虚拟空间结合的一些技术，对算力的要求都很强。如腾讯数智人跟虚拟空间结合时，一个虚拟空间会有几十G的渲染资源要做加载。3D超写实的数智人一般会有20万 ～ 30万面片的mesh，这些都需要很强的算力。</p><p></p><p>此外，腾讯云智能数智人希望通过AI驱动技术，把数智人放到企业服务场景下为企业做增效服务，这些都对算力有一定要求。当企业的写实类数智人面向用户做规模化服务时，有时需要大规模并发，因为客户或客群整体规模大，也需要很高的弹性或云计算的空间。</p><p></p><p>在这层，腾讯云智能团队做了很多技术优化，首先在渲染维度上，通过云游戏的技术或音视频的链路实现成本降低。还结合云端混合渲染，与客服做深度绑定，结合云端的混合渲染的模式降低服务成本。</p><p></p><h3>商业模式</h3><p></p><p>尽管虚拟人的发展仍在早期，但业界关于其商业模式的讨论已提上日程，腾讯云智能数智人目前在商业模式上也进行了一些探索。</p><p></p><p>当前腾讯云智能数智人主要服务于B端企业用户，且通过服务B端的客户连接服务到C端用户（B2C），通过数智人提升企业服务的质量，企业也可以通过数智人做用户运营，提升服务用户的体验。</p><p></p><p>据陈磊观察，从数智人发展趋势上看，面向企业的服务以及周期分为以下几种。第一帮助企业做形象代言人打造。第二，当企业里有形象代言人时，在一些营销场景，如广告落地转化、应用，数智人会带来很强的吸睛效应。此外，腾讯云智能在与一汽大众的合作中，探索了虚拟数智人与虚拟空间结合的形式，通过一种新的方式助力客户提升留资。还有的企业用数字人做日常用户运营，如偏直播方向，有真人驱动或AI驱动的方式，面向自身客户运营做直播，这些工具能扩大私域运营的手段方式。此外，数智人还可以围绕用户服务生命周期做精细化的企业服务，如客服场景、对话场景等，当前在每一个维度都有一些比较好的实践落地。</p><p></p><h2>数智人和全真互联</h2><p></p><p></p><h3>人机交互的下一个范式</h3><p></p><p>陈磊表示，腾讯将数智人定位成交互智能的重要入口。今年7月，腾讯云智能与腾讯研究院、创业黑马联合发布的“数智人十大趋势”中提到，无论是身份型的数智人，还是融合了语言理解表达或学习交互能力的服务型数智人，从在线服务到场景体验，数智人都是人机交互相对典型的一个好的范式和入口。</p><p></p><p>而且，从整体的内外部趋势看，数智人会进入大规模的应用期，加速转化为现实生产力，无论是消费级还是企业服务赛道都能创造很大的商业价值。</p><p></p><h3>全真互联世界的数智人</h3><p></p><p>数字虚拟人的话题度很大程度上与元宇宙分不开。元宇宙是近两年的顶流概念。一种说法认为，腾讯所提的全真互联是对元宇宙的另一种表述。</p><p></p><p>陈磊表示，腾讯希望用IOT、AI、云计算等技术，将真实世界和虚拟世界做全面的感知、链接，用数智融合的创新技术满足各行业升级转型的需求。</p><p></p><p>数智人是AI技术具像化的一种展现形式。一个AI综合的应用需要不断整合各种创新AI，包括背后的决策智能的大数据，云计算的技术、音视频技术等，本质上，数智人是技术层面对全真互联的探索。</p><p></p><p>陈磊列举了一些数智人未来在全真互联的应用场景。</p><p></p><p>例如，去银行办理业务，现在用户要去线下的物理银行的窗口办理，但如果是全真互联的形式，用户坐在家里，用电脑或AR就可以通过自己的身份进入场景中，进入银行展厅后可以获得营销服务，这些服务就由企业的数智人提供，包括营销推荐、推荐后实时互动，银行开卡业务等。将交互服务做了升级，节约了用户线下去实体网点办理的时间，提升效率。在类似这样的交互入口中，数智人会起到很大作用。</p><p></p><p>值得注意的是，在面向企业服务的场景，如果企业数智人自身在一些智能化场景里有足够的行业积累和知识图谱，在AI技术的加持下，数智人就可以通过自适应、自学习，不断提升服务能力，实现在全真互联中为用户提供更好的服务。</p><p></p><p>采访嘉宾介绍：</p><p></p><p>陈磊，腾讯云智能数智人产品总经理。先后参与负责QQ浏览器、腾讯翻译君、腾讯同传、腾讯云智能数智人等产品的研发工作。</p><p></p>",
    "publish_time": "2022-12-01 15:01:16",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "初创公司想要聊天机器人，但80%缺乏关于对话式人工智能的知识",
    "url": "https://www.infoq.cn/article/sQH37LsxTC3YbJrzwXPW",
    "summary": "<p>本文最初发布于readwrite博客。</p><p></p><p><a href=\"https://readwrite.com/the-ultimate-guide-to-conversational-ai-in-2022/\">对话式人工智能</a>\"市场正在急剧增长，训练新的大型生成模型，扩大技术栈，并为市场带来更多先进的产品。到2030年，其市场规模<a href=\"https://www.grandviewresearch.com/industry-analysis/conversational-ai-market-report\">预计将达</a>\"420亿美元左右。对话式AI产品背后的技术也变得越来越复杂。</p><p></p><p>这并不奇怪——科技巨头在研发上投入了大量资金。例如，OpenAI项目（由埃隆·马斯克及其他科技明星在2015年创建）获得了10亿美元的捐赠，在接下来的三年又额外从微软<a href=\"https://techcrunch.com/2019/07/22/microsoft-invests-1-billion-in-openai-in-new-multiyear-partnership/\">筹集</a>\"了10亿美元。</p><p></p><p>与此同时，除了GPT-3（Generative Pre-Trained Transformer 3）等大型生成模型外，现代而又先进的ConvAI应用范围还很有限。尽管有许多“玩具”项目使用了GPT-3，也有一些聊天产品使用了GPT-3及类似模型，但其他方面的进展应用还没有那么广泛。如今，小公司该如何从技术发展中受益并实现自己的人工智能助手？</p><p></p><h2>期望与现实</h2><p></p><p>DeepPavlov.ai团队开发的开源对话式AI技术栈旨在加速和简化聊天机器人和人工智能助手的开发。2022年6月，我们向在其业务中使用会话式AI的初创公司了解了他们使用这项技术的预期结果。</p><p></p><p>我们采访了20位初创公司的创始人和首席技术官，他们来自教育科技、金融科技、自动化和咨询市场。所有人都提到，聊天机器人为其细分市场带来了无可争辩的好处，包括让业务更加顺畅。</p><p></p><p>结果显示，初创公司希望<a href=\"https://readwrite.com/the-ultimate-guide-to-conversational-ai-in-2022/\">ConvAI</a>\"能带来实质性的结果，其中包括提高客户接触的遏制率，提高呼叫中心的人员效率，以及借机削减运营成本。但与此同时，近80%的受访者提到，在实施和开发聊天机器人时遇到了困难。</p><p></p><p>早些时候，RASA也研究了<a href=\"https://readwrite.com/increase-your-website-conversions-by-3x-with-conversational-ai-chatbot/\">会话式AI在客户服务领域的应用</a>\"现状。他们指出，这项技术主要带来了两方面的业务优势：自动与客户进行双向自然语言对话的能力，以及通过分析对话了解客户需求的能力。</p><p></p><p>这些结论与Gartner的全球研究结果一致。Gartner表示，小型企业可以通过<a href=\"https://readwrite.com/artificial-intelligence-in-customer-support-what-ai-means-for-your-chatbots/\">使用聊天机器人取代人工</a>\"来节省工资和培训费用。</p><p></p><p>投资聊天机器人的主要成果包括通过虚拟助手增加客户联系次数，改善客户体验，同时提高销售经理的效率，获得额外的商业机会。</p><p></p><h2>采用障碍</h2><p></p><p>现代ConvAI采用的瓶颈是初创公司的创始人对技术机遇缺乏清晰、深刻的理解。他们不是很清楚自己需要聊天机器人（特别是NLP分类器）提供什么功能。这一点，他们在回答我们的提问时提到了。</p><p></p><p>一半的受访者表示，聊天机器人可以在与客户对话时帮助他们提取人类语音中的意图和特征。另一个普遍的需求，大约占45%，是提取命名实体。而10%的人则表示，他们需要<a href=\"https://readwrite.com/how-ecommerce-businesses-can-take-advantage-of-ai/\">对人类语音的情感特征进行分类</a>\"。</p><p></p><p>由此可以看出，对话式AI创建者的设想通常是多么模糊。大多数人（80%）不理解先进的对话式AI和聊天机器人对他们的业务都意味着什么。因此，这限制了他们实施此类技术。</p><p></p><p>此外，对话式AI平台支持的领域、模式和行业越多就越复杂，就越难为普通的初创公司市场参与者所使用。</p><p></p><p>因此，无论是技术的创造，还是让它变得可理解，都对未来对话式AI的蓬勃发展至关重要。在初创公司开展会话式AI培训可以帮助他们填补知识空白。</p><p></p><h2>让初创公司可以从对话式AI受益</h2><p></p><p>只有科技巨头、实验室、开发人员和初创公司之间展开对话，聊天机器人及其可用性才会有一个更好的未来。</p><p></p><p>Alexa Prize挑战赛就是一个很好的例子。大赛为团队提供了一个在安全空间里测试技术并进行数千次对话的机会，让他们可以获得独特的发现。</p><p></p><p>例如，去年，其中就有一个团队<a href=\"https://hai.stanford.edu/news/how-create-better-chatbot-conversations\">了解到</a>\"，有10%的用户与机器人交谈超过10分钟，并试图通过提出个性化问题来建立关联性联系，甚至容忍了机器人的古怪行为。</p><p></p><p>毫无疑问，亚马逊在鼓励开发人员增加Alexa技能或以它们为基础构建ConvAI解决方案方面做得很好。但由于其核心技术是闭源的，其进一步应用受到了限制。</p><p></p><h3>另一种方法是借助开源ConvAI解决方案提供的强大功能。</h3><p></p><p>RASA正在用它的开源框架支持面向任务的聊天机器人开发。但是，使用该技术开发多功能AI助手仍然是一个挑战。作为一个诞生于学术界的项目，DeepPavlov的团队希望可以促进其开源应用。</p><p></p><p>我们的目标是帮助目标用户（包括中小型企业）简化复杂产品的开发，提升他们的开发速度。</p><p></p><h3>人工智能可以为初创公司带来巨大收益</h3><p></p><p>不过，有一件很重要的事是先开展相当数量的培训。为了最大化<a href=\"https://readwrite.com/are-customer-service-chatbots-worth-the-hype/\">聊天机器人和虚拟助手的收益</a>\"，初创公司应该知道预期交付成果是什么，以及如何针对他们特有的情况开发这项技术。</p><p></p><p>市场玩家要意识到，技术的进步应易于理解和使用。</p><p></p><p>声明：本文为InfoQ翻译，未经许可禁止转载。</p><p></p><p>原文链接：<a href=\"https://readwrite.com/startups-want-chatbots-but-80-lack-knowledge-about-conversational-ai\">https://readwrite.com/startups-want-chatbots-but-80-lack-knowledge-about-conversational-ai</a>\"</p>",
    "publish_time": "2022-12-01 15:30:14",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "专访火山引擎 | 探秘抖音同款实时音视频技术，RTC如何从优秀走向卓越",
    "url": "https://www.infoq.cn/article/yaV5V1R0iuUvpbrBIJYq",
    "summary": "<p>社交娱乐、直播点播、在线教育办公等场景的广泛应用，催生 RTC 技术的快速发展。从曾经炙手可热的概念到如今逐步走向完善，当前 RTC 的发展已逐步进入从90分到100分的精进阶段，而越是到达这个阶段，每向前一步越是不易。</p><p></p><p>极端恶劣的环境下如何优化用户的音视频体验？全球化背景下，如何保证实时性并且进一步降低延时？在不损失用户体验的前提下，如何实现降本增效？<a href=\"https://xie.infoq.cn/article/c6643121834044c6b3312a249\">火山引擎</a>\" RTC 从 2017 年开始为抖音提供实时音视频服务，经历了过亿级 DAU 的产品的持续打磨与完整检验，将其沉淀的关于音画质提升、架构设计、抗弱网、机型适配等技术成果打包成「抖音同款 RTC」产品及服务。</p><p></p><p>近期，QCon 全球软件开发大会 InfoQ 有幸采访到了火山引擎 RTC 产品负责人杨若扬，带大家探秘抖音同款实时音视频技术。</p><p></p><p></p><p></p><p>InfoQ：若扬老师您好，欢迎您来到 Qcon，很高兴采访到您，首先请您先做一个自我介绍并介绍一下火山引擎。</p><p>&nbsp;</p><p>杨若扬：大家好，我是杨若扬，我目前就职于字节跳动，在负责火山引擎 RTC 产品线。火山引擎它是字节跳动旗下的一个云服务的平台，火山引擎把字节跳动在它快速发展的过程中所积累下来的技术能力，技术能力增长的方法和工具开放给外部的企业，帮助企业去实现快速的增长。</p><p>&nbsp;</p><p>InfoQ：近年来 RTC 在快速地发展，您认为 RTC 目前是处于怎样的发展阶段呢？以及它面临的挑战有哪些？</p><p>&nbsp;</p><p>杨若扬：我认为 RTC 目前属于一个从 90 分到 100 分这样的一个不断精进的阶段。主要体现在我们对于两个极致方面的追求。一个是在针对恶劣环境不断地去适应。所谓的恶劣环境是指那种极端的弱网或者是极端的弱设备。我们要追求让尽量多的用户，哪怕他的网络不是很好，也能够去获得比较好的视频体验，这就需要我们不断地去打磨更强的算法。</p><p>&nbsp;</p><p>另一个是来自于业务侧不断提升的需求。比如说业务需要做云游戏，要做 K 歌合唱或者是远程的操控，这就需要更低的延时。再比如说业务需要做那种 720 度的全景视频实时传输，就是需要 4K 到 8K 分辨率，以及 30 帧到 60 帧的帧率。这就意味着它的传输的数据量会非常的庞大，这也就对我们的传输算法有了更高的挑战。</p><p>&nbsp;</p><p>InfoQ：这一阶段技术上有哪些最新的突破呢？</p><p>&nbsp;</p><p>杨若扬：技术突破在于所谓可以用的技术非常多，但是我们会关注如何去选择和应用这些技术。这里我想分享的是我们的一个方法论。就是不断地通过实验和数据观察来挑选真正能解决我们上面这些问题的技术，简单说，就是我们常说的<a href=\"https://xie.infoq.cn/article/e35695130afe61976824ad25e\"> A/B Test</a>\"。因为只有真正能够让业务实现增长的技术，我们才认为它是一个有价值的演进方向。</p><p>&nbsp;</p><p>InfoQ：了解。您刚刚也提到对于 RTC 技术来说，保证实时性是一个非常关键的技术点。尤其是全球化这个背景下，火山引擎是如何保证实时性呢？</p><p>&nbsp;</p><p>杨若扬：保证实时性主要是去解决延时的问题。我们解决延时包含两个方面，一方面我们会去搭建一个<a href=\"https://www.infoq.cn/video/xbX8fzoD0bplTMH1big6\">全球的实时传输网络</a>\"，通过软件定义的网络以及我们分布全球的传输节点，来提升中心网络、核心网络的传输速度。另一方面，是我们所谓的最后一公里的网络，就是用户自己的网络和自己的设备上面连接到我们的边缘节点的这一段，这一段相对是不可控的，所以它只能依赖我们的传输算法。</p><p>&nbsp;</p><p>说到全球化，基于上面这个架构我认为有三个关键的突破。第一，是我们的多中心的网络架构，多中心能够让我们在全球范围内保证达到最快的访问路径。第二，是边缘下沉，我们让尽量多的计算在边缘完成，这样它就会减少全球网络同步的带来的延时的消耗。第三，我们称之为统一接入，就是我们会把信令和媒体去使用同一个网络连接。这样一个是可以大大的降低网络连接上最后 1 公里网络的损耗，同时也能够让媒体和信令达到一个更好的一个同步性。</p><p>&nbsp;</p><p>InfoQ：在全球化的这个场景下，非常典型的一个场景就是近期的世界杯，抖音在最近推出了「边看边聊世界杯」的一个玩法，能够支持百万人同时在线，并且支持多人在麦，能结合这一场景聊聊火山引擎在多人互动架构上是怎么演进的吗？</p><p>&nbsp;</p><p>杨若扬：RTC 的多人互动其实要克服一个核心的挑战就是信令风暴。因为 RTC 的推拉流的关系非常复杂，所以我们会提供一个信令，通过信令的管理能力去降低开发的复杂度。但这样复杂度由我们来解决。这个信令风暴核心的挑战在于，一个是增加观众的人数，一个是增加开麦的人数。</p><p>&nbsp;</p><p>第一阶段我们是通过一个隐身用户架构去让观众的人数能够达到 100 万。第二阶段我们是通过我们核心的一个技术即服务端的音频选流，让开麦主播人数能够达到 1000。第三阶段，我们是在千人开麦的基础上，我们演进到了万人上麦。但是这里面开麦的人数和主播人数其实没办法两边同时都达到一个最佳的、最高的状态。因此我们第四个阶段，我们现在是把信令的管理和音视频流进行一个更深度的一个解耦。这样两边都能同时达到一个最佳的状态，观众的人数未来就可以达到没有上限。</p><p>&nbsp;</p><p>InfoQ：在抖音的业务中有大量涉及音视频的特效，在互动特效算法与音视频的结合上面，火山引擎有哪些经验可以跟大家分享一下？</p><p>&nbsp;</p><p>杨若扬：其实视频特效和 RTC。从需求侧来说是非常常见的组合，抖音上的这些特效本身也做得非常的有趣，质量也非常高。但是它带来一个很大的挑战，这两块都是性能消耗的大户。也就说会有很多的用户，如果在手机上要同时跑特效和 RTC 它的性能就会扛不住，就会达不到最好的效果。</p><p>&nbsp;</p><p>我们分析下来，其实它这两块都是音视频，所以我们认为它会有很强的融合，优化空间会非常大。因此我们研究之后，找到了至少三个方向的优化。</p><p>&nbsp;</p><p>第一，就是我们会减少音视频的拷贝的次数，这个其实是对于性能降低的最直接的优化。</p><p>&nbsp;</p><p>第二，是统一降级。RTC 会有性能降级，如果检测到这个设备的性能不够，它会去做一些降级。其实特效也会去做。但是如果说特效和 RTC 它不是采用共同的降级策略的话，它其实是没有办法达到一个最佳的效果。并且 RTC 其实是在特效之后的，所以如果是分离的话，可能 RTC 拿到的数据和它所剩下的性能已经不够他去做降级了。因此我们把它整合在一起，达到一个统一降级的策略，就可以让 RTC 和特效能够同时达到一个最佳的一个适配性。</p><p>&nbsp;</p><p>第三，我认为是共用算法。用现在很多特效里面其实都会用到一些算法，最主要的可能是个人脸的检测。RTC 也会用到一些比如说人脸的这样的算法。如果是两套算法，虽然可能都是检测人脸，但是它始终在检测上会有没有对齐的问题，就会让它效果打折。我们共用一套算法，这些效果也能够同时达到最佳的效果。</p><p>&nbsp;</p><p>InfoQ：火山引擎也是一直说要推动 RTC 从 90 分到 100 分，今年有一些什么样新的技术和新的功能上线呢？</p><p>&nbsp;</p><p>杨若扬：除了我们专题里讲的，如何帮助抖音追求极致，其实我们还为字节旗下的其他的很多业务做了很多的创新。首先我们为飞书做了屏幕共享，屏幕共享大家都了解，我们做了屏幕共享的智能编码模式。其实屏幕共享的视频画面内容会比我们平时拍脸的画面内容要复杂很多。所以我们针对它的内容去决定，实时地去调整它的分辨率和帧率。也就说根据它的内容在需要高清的时候我们会让它高清，它需要实时的时候我们会让它更流畅，这是我们在屏幕共享上的一个创新。</p><p>&nbsp;</p><p>另外我们还给 PICO 做了一个 8K FOV 的视频传输。还有我想讲一个我们针对汽车平行驾驶，我们提供了一个纯视频的一个超低延时的视频传输的一个策略。</p><p>&nbsp;</p><p>今年汽车上的 RTC 应用突然涌现出来，一方面是智能驾驶的概念现在落地了。就会要求 RTC 有几个特性，最主要是低延时，它通过低延时可以做一些远程的操控，但目前的远程操控可能主要还是集中在一些非驾驶的应用上。第二个就是它的视频的传输，你可以在汽车之外看到车载的摄像头给你传过来的视频画面。</p><p>&nbsp;</p><p>InfoQ：您认为火山引擎 RTC 和业界其他方案相比最大的优势是什么，能否总结一下？</p><p>&nbsp;</p><p>杨若扬：我总结下来，我认为是四个字，就是业务视角。业务视角可以从三个方面去体现。我觉得首先是数据驱动。我们所做的 RTC 的指标，从来不是为了去证明我们的技术有多厉害，而是说我们会把我们的指标和业务的指标进行联动。刚才我提到我们做 A/B Test，我们的目标最终还是帮业务去实现增长。我认为这是我们最大的区别，我们是从业务的角度去驱动优化方向的。</p><p>&nbsp;</p><p>第二，我认为是全链路优化。因为从业务角度来看，业务其实只会关注最终的结果，而 RTC 它的全链路其实非常长，链路上的每一个环节的好坏都会影响最终的效果。因此我们不会去放弃任何一个环节的优化，比如我们从视频采集开始，我们就对画质进行优化。</p><p>&nbsp;</p><p>第三，我认为是最佳实践。因为 RTC 目前的使用方式还是非常复杂的，有些时候你要达到一个最佳的效果，其实是需要业务的实现去解决的。但我们从来不会认为那一部分的工作完全是业务的工作，我们会去充分理解业务的需求，帮助业务去设计一套实现集成的方案，帮助他们一起去实现，并且一起去观察最终的效果。这是我认为我们最大的不同。</p><p>&nbsp;</p><p>InfoQ：了解，您刚才也提到了业务驱动这样一个关键词，业务驱动的话与用户体验是强相关的，用户体验在业界来说是不太好衡量的，你们在衡量用户体验这方面有哪些创新？</p><p>&nbsp;</p><p>杨若扬：你说的没错， RTC 衡量用户体验的指标业内还是没有形成标准。我们一般都会去用 QoS 指标，但其实 QoS 指标也没有统一。首先我们在定义 QoS 指标的时候，我们会去以用户的行为为颗粒度，这样确保我们的 QoS 不是纯粹反映我们的一些技术上的片段，它还是会去和用户的一些行为去结合。这样的指标它会比较客观。但它也会有一个问题，就是它始终无法覆盖所有的用户的体验的情况，总会有一些用户体验不好的问题，其实是落在指标定义之外的。</p><p>&nbsp;</p><p>因此我们也会去看另外一个指标，我们叫 QoE，QoE 会由很多的数据来源组成，其中很大的一部分就来源于用户的主观的评价。用户的主观评价它的特点就是真实的反映用户的体验，但是它有一个问题就是它会存在幸存者偏差。一定会有很大一部分的用户其实体验不好了，但是他不做任何的反馈。基于这样的两个特点，我们去设计了一套基于 QoS 和 QoE 的一个联动的数据分析方法。我们是通过 QoE 来去验证和打磨 QoS 的指标，让我们的 QoS 指标不断地能够去更加真实地去反映我们之前所遗漏掉的那些用户的体验。然后我们再用 QoS 指标去消除幸存者偏差的问题，这是业界独创的一套数据分析的方法。</p><p>&nbsp;</p><p>InfoQ：在保障用户体验的前提下，有没有一些降低成本的考量呢？尤其是现在的经济形势其实不是特别好。</p><p>&nbsp;</p><p>杨若扬：因为 RTC 的成本主要来源于云端的资源的应用，如果降低云端资源的成本，它就势必会带来 RTC 的体验下降。但是其实降本我们认为也是并不是没有办法的。我们充分研究之后，发现其实从 RTC 的技术架构方案上去做降本的优化，它所带来的收益远远大于我们在资源上的降低。</p><p>&nbsp;</p><p>举个例子，我们有很多的云端后处理，像云端录制和云端的截图、云端的转直播等等。这些云端的后处理很多时候往往会同时使用。我们会对这个任务进行合并，这样会大大地减少云端拉流的数量，这个减少的数量是成倍的。成倍地减少了拉流的数量，它就会成倍地去减少对资源的运用。这种类型的降本我们认为它是非常有效的。</p><p>&nbsp;</p><p>除此以外，我们还有端云一体、合流转推，还有消除静音帧、消除黑帧等等。这一类我们统称为技术方案的降本。通过实践，技术方案的降本在帮助抖音的实践过程中，在用量没有下降的情况下，我们最终帮抖音节省的 RTC 的成本大概是原来的 50%。</p><p>&nbsp;</p><p>InfoQ：面向未来 RTC 会朝什么方向发展呢？以及火山引擎在未来的发展上有什么样的规划呢？</p><p>&nbsp;</p><p>杨若扬：首先 RTC 未来的方向它一定是会朝着更低的延时、更加的高清、更加的流畅这些方向去演进。除此以外，我认为目前 RTC 行业还有一个很大的一个痛点没有解决，其实刚才也都提到过，它的使用复杂和它的指标标准问题。其实归根结底是因为目前 RTC 还没有形成标准协议。所以我认为未来的 RTC 还会往标准化去发展。</p><p>&nbsp;</p><p>因此，火山引擎 RTC 现在也在引领一个全新的 RTC 概念。就是基于标准协议的 RTC，我们推出的是 WTN 这样的一个概念，WebRTC 传输网络。它是能够使用标准的 RTC 协议，采用国际标准去适应更多的 RTC 的开发。也能够让更多的 RTC 开发者参与进来，并且未来我相信还能够实现不同厂商之间的 RTC 的互联互通，这样会形成一个众人拾柴火焰高的这样的一个行业局面，也能够让 RTC 往一个更好的方向去发展。</p><p></p>",
    "publish_time": "2022-12-01 15:45:16",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "我们弃用 Firebase了",
    "url": "https://www.infoq.cn/article/C1zBldcVfLXkRaYYk2Dh",
    "summary": "<p>我们已经在Firebase上发布了10几款应用程序，几乎用到了该平台每个方面的特性，并设计了一个可以实现优雅扩展的手册。可以说，事实已经证明，Firebase对K-Optional Software而言是非常宝贵的工具。</p><p></p><p>就在2022年3月，我们的开发人员还在为<a href=\"https://github.com/FirebaseExtended/experimental-extensions/issues/74\">Firebase Extensions等创新</a>\"欢呼。遗憾的是，过去几个月的三个主要变化破坏了开发体验，因此，在新项目中，K-Optional将转向其他替代方案。</p><p></p><h2>Firebase：好的地方</h2><p></p><p></p><p>这个归谷歌所有的平台即服务（PaaS）使构建者做出了多项基础设施决策：内容交付网络、NoSQL数据库事件处理程序和网络拓扑等等。的确，纯从性能上讲，在AWS/Azure/ GCP上构建的定制化原生服务包优于Firebase套件。但是，当我们考虑到开发时间和维护成本时，Firebase通常是一个合乎逻辑的选择。</p><p></p><p><a href=\"https://firebase.google.com/docs/database\">Firebase实时数据库</a>\"最初给人的感觉相当具有革命性，特别是在<a href=\"https://mailarchive.ietf.org/arch/msg/ietf-announce/7dYVwa6pABzztQO4gTIHx3MYRGo/\">WebSockets</a>\"被广泛接受或<a href=\"https://germano.dev/sse-websockets/\">Server-Sent Events</a>\"出现之前。你可以编写实现实时数据同步的应用程序，而且不需要开发大量的传输逻辑。那些在自制即时通讯应用程序中使用了长轮询请求的的用户肯定会喜欢它。</p><p></p><p>事实上，Firebase有许多方面是我们喜欢的：</p><p></p><p>使用Firestore，许多客户端状态管理方面的挑战都不复存在，特别是与数据新鲜度有关的问题。免费就可拥有的实时体验。Firestore的文档/集合架构：它迫使人们仔细考虑数据建模。它还反映了一个直观的导航方案。Firestore中的关系数据也是如此。<a href=\"https://mongoosejs.com/docs/populate.html\">与MongoDB不同</a>\"，它不可能远程执行任何类似于SQL连接的操作。因此，开发人员必须接受NoSQL的精神，提前分发关系数据。Firebase套件可以帮助我们快速构建可扩展的原型，处理来自客户端的数据连接，在发布到生产环境之前强化安全规则，并对敏感逻辑使用Firebase Functions。<a href=\"https://firebase.google.com/docs/firestore/security/get-started\">云Firestore安全规则</a>\"写起来很有趣，在考虑客户端-服务器安全方面，这是一个可靠的模型。开箱即用的身份验证很不错。（不过，在我们看来，其内置的Firebase邮件验证体验很糟糕）。实际上，我们发现，在CI/CD方面，Firebase Hosting比AWS S3 + Cloudfront更简单，因为它提供了一个简单的命令可以对存储库做这方面的设置。</p><p></p><h2>Firebase：不那么好的地方</h2><p></p><p></p><p>另一方面，Firebase也有不少地方让我们犹豫：</p><p></p><p>Firebase要求使用谷歌/GSuite登录——<a href=\"https://koptional.com/articles/software-start-up-system-essentials#a-note-on-decentralization\">我们喜欢分散我们的供应商和服务</a>\"。Firebase Hosting不提供细粒度的文件控制：你可以部署整个应用程序，也可以什么都不部署。也许不常见，但我们在静态页面生成和调试CDN问题上遇到了限制。Firestore索引的创建速度非常缓慢，而且不优雅，比创建同等的Algolia索引花费的时间要长得多。由于是闭源的，你不能默认以为Firebase始终存在（像<a href=\"https://www.notion.so/Why-we-re-moving-away-from-Firebase-Draft-1-fc15033152dd484cb9f3c5d75d27954a\">Parse</a>\"一样），依赖于特定的API版本也不可靠。因此，你也不能真正地在本地运行Firebase。当然，也有<a href=\"https://firebase.google.com/docs/emulator-suite\">Firebase模拟器</a>\"，但它们很慢，也很难调试，而且普遍存在不足；经常会在负载不是很大的情况下出现意料之外的失败，而你可能期望有一个能够承受足够负载的、健壮的本地环境。Firebase CLI限制相当严格：对于像启用Firestore这么简单的事情，你也只能通过仪表板完成，而不能通过命令行。firebase login:ci有意禁止传递认证密钥。我喜欢执行firebase login:ci | xargs -I {} gh secret set FIREBASE_TOKEN --body=\"{}\" ，但唉，其前后都还有其他的命令。（见下面我们使用的一种丑陋的变通方案）附注：说到Firebase CLI的限制，下面是两个我们经常使用的解决方案，或许对你有用。</p><p></p><h3>提取机器可读的CI token</h3><p></p><p>是的，我喜欢将CI token直接传递到我的秘密管理器。</p><p></p><p><code lang=\"plain\">citokenRaw=$(firebase login:ci)\ncitoken=$(echo \"$citokenRaw\" | tail -n 3 | head -n 1)\n</code></p><p></p><h3>将Web配置加入.env文件</h3><p></p><p></p><p>下面这几行代码会下载一个Firebase Web片段，并将其转换为适合.env文件的内容。这个Web片段会将站点配置为使用特定的Firebase应用程序，并借助环境变量使我们可以跨项目保留脚手架。</p><p></p><p><code lang=\"plain\"># 丑陋 丑陋 丑陋 \n\nfbKeysObject=$(    firebase apps:list  --project=$FB_PROJECT --non-interactive --json     | fx '.result[0].appId' | xargs -I {} firebase apps:sdkconfig WEB {}     |  sed '/{/,/}/!d '      | sed -r  's/;|firebase.initializeApp|(|)//g'     )\n\n# 构建一个.env文件\necho \"$fbKeysObject\" | jq '.projectId' | xargs -I {} echo \"REACT_APP_FB_PROJECT_ID=\"\"{}\" &gt; .env\necho \"$fbKeysObject\" | jq '.appId' | xargs -I {} echo \"REACT_APP_FB_APP_ID=\"\"{}\" &gt;&gt; .env\necho \"$fbKeysObject\" | jq '.storageBucket' | xargs -I {} echo \"REACT_APP_FB_STORAGE_BUCKET=\"\"{}\" &gt;&gt; .env\necho \"$fbKeysObject\" | jq '.locationId' | xargs -I {} echo \"REACT_APP_FB_LOCATION_ID=\"\"{}\" &gt;&gt; .env\necho \"$fbKeysObject\" | jq '.apiKey' | xargs -I {} echo \"REACT_APP_FB_API_KEY=\"\"{}\" &gt;&gt; .env\necho \"$fbKeysObject\" | jq '.authDomain' | xargs -I {} echo \"REACT_APP_FB_AUTH_DOMAIN=\"\"{}\" &gt;&gt; .env\necho \"$fbKeysObject\" | jq '.messagingSenderId' | xargs -I {} echo \"REACT_APP_FB_MESSAGE_SENDER_ID=\"\"{}\" &gt;&gt; .env\n</code></p><p></p><p>附注结束。综上所述，Firebase存在的大多数问题都来自谷歌所有权，它们让我很恼火。而最近的事态发展引发了我们的反思……</p><p></p><h2>不祥之兆</h2><p></p><p>Firebase近期的三个发展变化让我们确信，未来属于<a href=\"https://supabase.com/\">Supabase</a>\"这样的工具。</p><p></p><h3>GCP偏向之一：通过移除Firebase的特性迫使人们迁移到GCP</h3><p></p><p>在过去的几个月中，Firebase去掉了仪表板中的Cloud Function日志。如果需要，则可以通过他们提供的链接在Google Cloud Console仪表板中查看。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/35/35bb6eac7210e3c5ea082ef5d6693dab.png\" /></p><p></p><p>如果这可以定制，那对我来说会是一种帮助。</p><p></p><p>我还注意到，无法在Firebase Storage仪表板上下载文件了；必须导航到单独的GCP平台。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8b/8bb8ed317ad9c126181fef5882be724b.png\" /></p><p></p><p>我无法在Firebase 仪表板上下载这个文件。这不符合直觉，“打开”竟然不让我下载。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9a/9a643cdb69afb1246aee532a3b047fd7.png\" /></p><p></p><p>直接从Google Cloud Console下载。</p><p></p><p>GCP似乎正在蚕食Firebase开发环境。</p><p></p><p>从运营的角度来看，这是合理的。但是，简化Firebase的云体验会使它失去大部分的价值；我们客户并不想了解GCP。在最近的Firebase项目中，我在想我们是否应该推出自定义的服务。我相信，谷歌不会介意开发人员放弃Firebase而单纯使用GCP。</p><p></p><h3>近期Cloud Function部署的速率限制</h3><p></p><p></p><p>Cloud Function CI/CD降级。<a href=\"https://firebase.google.cn/docs/functions/quotas?hl=zh-cn\">Firebase对Cloud Function部署强制执行每100秒80次调用的配额</a>\"。据我所知，这个配额已经存在有一段时间了。</p><p></p><p><a href=\"https://github.com/firebase/firebase-tools/issues/3919\">但最近，Cloud Function部署在达到这个配额后开始悄然失败。</a>\"这很棘手，因为80个端点并不算多，而且<a href=\"https://github.com/firebase/firebase-tools/issues/2606\">Firebase至今没有提供一种简洁的方法，让我们可以只部署更改后的Cloud Function</a>\"。</p><p></p><p>对于这个问题，K-Optional Software几乎在同一时间收到了多个关于项目（不是我们的项目）的咨询请求，一切都表明，是API的突然变化造成了麻烦。</p><p></p><p>我考虑了以下两种变通方法：</p><p></p><p>使用单个基于事件名称调用条件逻辑（如使用事件分派器）的Cloud Function。那看起来像是一个名为dispatcherFunction的函数，根据eventName切换到相应内部函数的调用。逐步形成一种约定，其中每个Cloud Function都对应于它自己的文件。在CI代码中，过滤掉未更改的文件，并部署与已更改的文件相对应的函数。不用说，这两种变通方法都有很多需要改进的地方。将路由逻辑塞进端点牺牲了可读性和HTTP层缓存，而且这种脚手架方法无助于现有的大型项目。</p><p></p><h3>GCP偏向之二</h3><p></p><p></p><p>最后，Firebase越来越多地引导用户使用GCP获取基本服务。在过去的几个月里，<a href=\"https://github.com/FirebaseExtended/action-hosting-deploy/issues/203\">开发人员偶尔会反馈由于缺少权限而导致Firebase Hosting失败</a>\"。<a href=\"https://www.notion.so/Github-Action-Firebase-Hosting-Deploy-Failure-Error-HTTP-Error-403-Permission-cloudfunctions-fu-515b11fa1004420eae2b758e819696db\">我们的团队上周也开始报告这个问题</a>\"。为什么Firebase Hosting会需要Cloud Function&nbsp;list 授权，这让我很困惑。无论如何，Google Cloud Console是添加此权限的唯一方法。</p><p></p><p>尽管Firebase开发有所下降，但我最近还是经常在这个权限仪表板上看到自己。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fd/fd44978acdf33958d885468f087dfae3.png\" /></p><p></p><p>根据<a href=\"https://firebase.google.com/docs/functions/manage-functions#deploy_functions\">Cloud Function部署文档</a>\"：Firebase错误只能在Google Cloud上解决。</p><p></p><h2>Supabase</h2><p></p><p>最近，作为考察过程的一部分，我们在Supabase上开发了一些小项目。其开发体验令人愉快，特别是<a href=\"https://supabase.com/docs/guides/auth/row-level-security\">行级安全</a>\"，那与Firestore规则类似，但更为强大。Supabase正基于Deno开发他们的<a href=\"https://deno.com/blog/supabase-functions-on-deno-deploy\">无服务器函数套件</a>\"，这表明他们对优秀的技术很重视。</p><p></p><p>我们喜欢Supabase使用的<a href=\"https://www.postgresql.org/\">PostgreSQL</a>\"。我们计划在可伸缩性方面做更多的研究，因为SQL数据库不能像NoSQL数据库那样增长。尽管如此，Supabase来的正是时候。</p><p></p><p>声明：本文为InfoQ翻译，未经许可禁止转载。</p><p></p><p>原文链接：</p><p></p><p><a href=\"https://koptional.com/article/why-we%E2%80%99re-moving-away-from-firebase\">https://koptional.com/article/why-we%E2%80%99re-moving-away-from-firebase</a>\"</p>",
    "publish_time": "2022-12-01 15:46:30",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "顺丰科技：在变局中寻找物流供应链“最优解”",
    "url": "https://www.infoq.cn/article/ZSUbLiwtLQNym9NXy65a",
    "summary": "<p>在物流行业，顺丰几乎是时效的代名词。如果手上有一个急件，希望以最快的速度送达目的地，想必多数人都会优先选择顺丰。</p><p></p><p>那么，顺丰是如何做到的？据了解，一个货品从发件人处送到收件人手中，每个环节的数据信息都会被精准记录，通过件量预测、分仓管理、路线规划和分析，可以针对网点选址、快递员的排班、车辆的分配调度、货运飞机航线规划等等，给出“最优解”。</p><p></p><p>但值得注意的是，这个“最优解”是处于不断变化中的。尤其是在受到不确定因素不断干扰的市场环境下，更多突发的状况需要被纳入其中进行考量。比如，一旦某城市进入停摆，物流仓储和配送如何才能继续有序运行？</p><p></p><p><a href=\"https://www.infoq.cn/article/OjvA417BcOsBWbT3yMVX\">顺丰科技</a>\"大数据总监林国强在最新一期的InfoQ《超级连麦.数智大脑》中介绍，面对天气、环境等各种突发情况，顺丰会基于运筹优化技术，通过数字仿真平台进行计划预测，找到其中的最佳解决方案，然后反向指导物理世界的流程执行和策略调整，对<a href=\"https://www.infoq.cn/theme/161\">供应链</a>\"各个链条和全环节进行优化。</p><p></p><p>无疑，在这背后，数据和算法是关键抓手，构建数据标准、数据质量和数据价值体系是基本前提。但是，林国强还强调，技术工具在其中并不能解决一切问题，对企业来说，更重要的是围绕数据确立相应的制度和组织。而这些，正是顺丰自身从信息化、<a href=\"https://www.infoq.cn/article/iKiSHHDJWSZgA4Ujz9ci\">数字化</a>\"到如今智能化几次关键转型中，总结的切身经验。</p><p></p><p></p><blockquote>本期 InfoQ《超级连麦. 数智大脑》，由顺丰科技大数据总监林国强，对话极客邦科技创始人兼 CEO 霍太稳（Kevin），和 InfoQ 极客传媒数字化主编高玉娴，一起探讨顺丰是如何在变幻莫测的市场环境中，寻找物流供应链“最优解”的。内容有删减，感兴趣的同学可进入“霍太稳视频号”或“InfoQ 视频号”观看直播回放。  </blockquote><p></p><p></p><h2>通过仿真模拟寻找“最优解”，应对各种突发</h2><p></p><p></p><h4>InfoQ：由于经济和疫情不确定性，全球供应链正在向安全和容灾方向发展，这对供应链各环节提出哪些新需求？</h4><p></p><p></p><p>林国强：首先跟大家分享一个数据，今年年初上海疫情爆发之后，所有跟顺丰有接触的品牌方很多都提出希望建设自己的容灾仓。因为在上海从3月到6月的封控期间，虽然电商平台上有大量的订单涌进来，但是因为大部分品牌方的电商总仓都设在上海，导致仓的出入库和配送受到了较大的影响，电商业务急需解决这一问题。</p><p></p><p>过去，通常是一些涉密程度比较高的行业，或者比较重要的物资，企业会针对性去建容灾仓。但这轮疫情之后，我们发现一些普通的快消零售、美妆、3C制造等行业也都在建容灾仓。并且，他们还提出了很多具体要求，比如，把容灾仓分布在5个城市，假设其中有2个城市物流受到影响，至少还要保证80%的供给率。</p><p></p><p>这些要求对于顺丰而言实际上是新的挑战，对此，我们主要基于物流大数据的底层建设，结合<a href=\"https://xie.infoq.cn/article/3ff766bc85f3c7312c4afd99c\">运筹学</a>\"相关的仿真能力，去满足企业的诉求。一方面，顺丰拥有全国各城市的交通相关数据；另一方面，顺丰还拥有各个城市的仓干配（仓储、干线运输、配送）流通数据。在这基础上，我们可以把整个仿真物流网络构建起来，模拟在40%的受控情况下，能否满足80%的线上订单响应率。这就是我们目前正在做的事情，也是很多企业在经历了疫情之后，提出来的一些新思路。</p><p></p><h4>InfoQ：在这个过程中，涉及对大量人、车、货等资源的调配，我们是如何利用数字化技术搞定这个问题的？</h4><p></p><p></p><p>林国强：顺丰有遍布全国的中大型中转场，全国的自营网点大约有2万个左右，有40多万小哥，若干自营及外包干支线车辆。快递方面，以今年<a href=\"https://www.infoq.cn/article/Ji9QhA4qbX8Tf63BRkpc\">双11</a>\"为例，每天订单量成倍增长。在这样的体量之上，如果人员排班、车辆调度等工作全靠人工经验去指派，工作量可想而知，并且，还可能造成巨大的资源浪费或者物流时效问题。</p><p></p><p>对此，顺丰有一个非常核心的能力，称为“件量预测”（*在接收快递件量预测请求后，根据待预测场地对应的高峰时间窗口信息以及历史货量信息等信息，构建时间序列，从而将快递件量预测转化为对应的总量时间序列和比例时间序列的预测）。</p><p></p><p>以双11高峰期为例，假设我们接到的订单量是数千万票，这些快递件数量就会被细化到每个网点，预测每个网点的进出数量，同时，通过查看网点现有的车辆情况，向网点管理员建议，下个时间段需要增加多少班车、多少人员等等。此外，包括网点选址、路径调度等信息，都会由总部经过数据分析，直接指派给各网点负责人，为他们提供数据决策支撑，从而应对配送高峰期间的时效要求。</p><p></p><h4>InfoQ：面对天气、环境这些突发因素的变化，顺丰是如何应对的？</h4><p></p><p></p><p>林国强：以顺丰为例，一票货品从下飞机到出机场，如何保证所有流程的时效最高？首先，我们要非常清楚当天天气对航班的影响；其次，航班落地的时候应该选择哪个航道、进入哪个停机位，停机位附近的车辆如何合理调度；再者，这票件应该走哪条路径最优，转运方式怎么才能最合理等等。</p><p></p><p>这意味着，其中每一个环节的数据不仅要拿到，还要打通。并且，这个过程中，如果发生任何异常，比如天气、机器故障等等，我们会通过<a href=\"https://www.infoq.cn/article/lz4xxpqPCadNj181bCwP\">数字仿真</a>\"平台进行计划预测，找到其中的最优解，然后反向指导物理世界的流程执行和策略调整。</p><p></p><h2>重视制度和组织，逐步化解转型阻力</h2><p></p><p></p><h4>InfoQ：回过头来看，顺丰的供应链数字化转型经历了哪些重要阶段和关键里程碑？</h4><p></p><p></p><p>林国强：第一个阶段是信息化，大概在十年前，顺丰主要使用的是SAP ERP系统+Oracle数据库的传统技术体系；</p><p></p><p>第二个阶段是数字化，大概五年前，我们自主研发了大数据平台，包括报表、管理决策、业财一体、用户洞察、市场营销等功能模块都是自研的，对SAP、Oracle的一些系统做了替换；</p><p></p><p>第三个阶段是智能化，比如刚刚讲到的“件量预测”以及智能调度等等，包括我们最近在湖北鄂州做的航空物流枢纽协同调度、仓网规划、路径规划，全都实现智能化的升级。</p><p></p><h4>InfoQ：在这几个关键转折点，顺丰是否遇到过什么样的障碍或阻力？</h4><p></p><p></p><p>林国强：这个过程确实不是一帆风顺的。比方说早期数字化主要是由大数据中心主导的，这意味着我们要从各个业务系统中拉取数据、做报表分析，从而支撑业务运营。最初一两年，大家还是比较认可的。但是，到了第三四年的时候，我们发现，大家的认可度逐渐降低。很多人开始提出来，这似乎是大数据中心自己的事情，跟自己的工作没关系。</p><p></p><p>除此之外，大数据中心的团队规模也逐渐满足不了业务部门的需求。当时大数据中心只有200-300的团队，却要面对3000多个业务数据接口人每天各种各样的数据报表需求，导致很多诉求无法及时满足。</p><p></p><p>后来，我们通过制度和组织去逐步规范了这些工作流程。比如，从3000多个业务数据接口人中，选择一部分人员作为我们的数据Partner，由他们主要负责数据应用层面的工作，大数据中心则主要负责数据基座的搭建工作。相当于我们对业务人员做了一定的培训，让他们能够更容易地使用数据工具，更快速地响应自己的业务分析诉求。</p><p></p><p>另一个挑战来自于<a href=\"https://xie.infoq.cn/article/6cadb8669646d839423aa1f32\">数据质量</a>\"体系。在前期，大数据中心团队在推数据质量和数据标准的时候，发现很难落地。后期我们开始由一把手去主导数据质量和数据标准的贯彻落实，再往下，由各个业务线系统方面的负责人作为每个板块的负责人，逐层落地了这件事。</p><p></p><h4>InfoQ：这背后还涉及对整个技术架构的改造，这一挑战也是巨大的，顺丰当初做这件事情，是出于什么样的考量和需求？</h4><p></p><p></p><p>林国强：事实上，对顺丰来说，过去我们去做这件事是“被逼无奈”。拿Oracle来说，即便是在<a href=\"https://xie.infoq.cn/article/8d81995107acf4834dd1da803\">Oracle RAC</a>\"环境下，能够扩展的节点也是非常有限的，比如，当我们扩展到五个节点，随后再继续扩展的性能就是线性下降的，一般来说，Oracle架构每天的数据承载量不会超过100 TB。</p><p></p><p>但是，当时顺丰的业务增长是非常庞大的，每天大概有200-300 TB的数据量，如果还用传统的架构根本扛不住。</p><p></p><p>举个例子，基于传统架构，最早我们能保证每天早上6:00之前把报表发给管理层，但是，随着业务增长，我们发现，每天都要等到下午13:00-14:00才能把前一天的报表分析出来，这就会耽误管理决策。比如当天的调度怎么做、营销策略怎么做、财务怎么做优化等等，决策的时效性很难满足。</p><p></p><p>这意味着，如果我们不去做技术架构革新，就没办法支撑业务的高速发展。</p><p></p><h4>InfoQ：是否可以总结一下，顺丰在面临种种变化时，我们的成功经验是什么？</h4><p></p><p></p><p>林国强： 出发点无非是两个维度——第一，做了这件事情之后，能带来的商业增长是什么；第二，能不能实现降本增效。</p><p></p><p>举例来说，顺丰业务运营中主要的成本有两方面，一是人的成本，二是车的成本。所以，当初我们通过业财一体化，实现了对快递收、转、运、派等所有环节，大概120多个标准节点的分析，找到每个作业节点对应的成本，以及其中的优化空间。最后，整体评估下来，大概节省了数十亿的成本。对物流行业来说是非常大的成本节约了。</p><p></p><p>当然，在这个过程中，技术得拉上业务，不能只用数据去说服对方，而是双方共同去设计，测算出最好的模式。比如，当我们对所有作业节点做完拆解之后，就会拉上财务、运营的人员一起去看哪一些作业节点是可以被取代的，一起持续地去优化流程，减少成本浪费。</p><p></p><h2>挖掘数据价值，技术工具不能解决一切问题</h2><p></p><p></p><h4>InfoQ：您怎么看数据治理在顺丰数字化转型中的价值？</h4><p></p><p></p><p>林国强：数据治理在顺丰是非常核心的项目，具体来说，数据治理包括了几个方面。一是数据标准，二是数据质量，三是数据价值。换句话说，这三个维度就是衡量一个企业数据治理做得好不好的关键。</p><p></p><p>对于顺丰来说，数据治理的范围包括整个集团层面的所有数据的统一治理。比如，我们会统一进行标准制定，统一做质量台账分析，并把台账推送到对应负责人，形成闭环。而对于数据价值，我们也会进行统一识别，比如那些被访问最多、最热、应用最广的数据，就属于高价值数据，要继续保留；相反，对于低价值的数据，就要被清理。</p><p></p><h4>InfoQ：顺丰的数据质量体系包括了哪些关键环节？</h4><p></p><p></p><p>林国强：从工具层面，我们主要做了两个事情：</p><p></p><p>第一，不断提升<a href=\"https://xie.infoq.cn/article/0c0eae0b445ddd9538e7b1703\">数据血缘</a>\"分析的能力。这里的数据血缘分析不只停留在简单的Hadoop层面，而是从ETL开始，到数据湖、末端的各个数据库，再到最终应用的调用，从数据生产到消费的所有环节中涉及到的血缘关系，并且，所有数据都要精确到字段级别；</p><p></p><p>第二，针对血缘里的每一个数据项，都要能够去做质量的分析。比如，能够分析数据的波动率，分析字段的空置率、异常率等等，据此形成相关的质量台账，并且这个质量台账还能根据血缘反推到底是系统端的问题，还是中间分析算法的问题，对应到相应的责任人，针对性解决问题，形成质量闭环。</p><p></p><h4>InfoQ：想要充分发挥数据的价值，除了数据打通之外，还有很多前提条件。是否可以介绍一下在这方面，企业比较容易踩的“坑”有哪些？</h4><p></p><p></p><p>林国强：关于数据，最大的“坑”就是认为工具能够解决一切问题。在所需的各个因素中，工具往往是最不重要的，更重要的反而是围绕数据的制度和组织。</p><p></p><p>首先，企业里有没有相应的制度能够驱动大家为你提供数据，如果只靠工具去驱动这件事，甚至，数据团队需要去请求业务部门给自己开放数据、校正数据质量，那么成功率几乎为零。</p><p></p><p>其次，企业要成立跟数据相关的组织。比如，在数据治理过程中，谁是第一负责人？业务部门在其中的角色定位是什么？不同部门需要各自承担什么责任？等等。所有的这些内容都要形成固定的组织流程，并且有对应的制度做保障。</p><p></p><p>当然对顺丰来说，我们也不是一次性做到位，我们也是从最初的“用工具打天下”，到现在的“用制度打天下”，这是一个循序渐进的过程。</p><p></p><h4>InfoQ：在今年ArchSummit全球架构师峰会深圳站，您分享了顺丰科技正在通过存算分离、实时数仓、多云融合等核心技术，实现弹性伸缩和多云统一架构，这样的架构设计是基于前端业务的哪些具体需求提出的？</h4><p></p><p></p><p>林国强：首先，顺丰的业务现在已经覆盖全球，按照GDPR的合规要求，我们必须在每个地方建数据中心。这就延伸出来一个问题，在全球这么多数据中心的情况下，怎么去做统一的数据开发和数据管理？所以，我们就去构建了<a href=\"https://www.infoq.cn/article/Y5UQP6EH5tWhzD9OCRQw\">数据湖</a>\"，基于混合云的架构，它能够帮我们实现整个基础设施的统筹，无论是阿里云、腾讯云还是AWS等等，其中的数据都能做到统一管理。</p><p></p><p>其次，随着双11、双12等各种大促活动的常态化，对于快消零售、物流等行业，都存在业务的波峰和波谷。这意味着，我们不能按照传统的IT思维去做支撑——比如，波峰是平时5倍的业务量，就去建一个对应的数据中心。这会造成极大浪费，因为平时根本用不到那么多资源。而当我们使用数据湖实现存算分离和弹性伸缩之后，它就可以支持我们在业务波峰的时候调用公有云资源，高峰期结束后，再恢复到私有云资源。这样一来，既能够保证数据安全合规，又能实现对公有云弹性资源的合理利用。</p><p></p><h2>“现场有神灵”，懂行业非常关键</h2><p></p><p></p><h4>InfoQ：极客邦从最早做线下大会，到上线极客时间体系化培训课程，背后是基于什么样的思考和初衷？看到了市场上什么样的需求和趋势？</h4><p></p><p></p><p>霍太稳：最早我们通过InfoQ技术社区和一系列的<a href=\"https://archsummit.infoq.cn/2022/beijing?utm_source=infoq&amp;utm_medium=conference\">线下大会</a>\"，和业界探讨和分享技术的发展趋势。在这个过程中，虽然有人能从中体会到技术的重要性，但是我们很难深入企业业务现场，真正了解企业的痛点。</p><p></p><p>后来，我们开始做极客时间，目的其实就是希望通过面向技术人员的技能提升，提供体系化的课程，同时，也帮助企业培养对应的数字化人才。这时候，我们慢慢发现自己离企业更近了，能够更加设身处地地为大家提供服务，解决大家在人才培养方面的问题，这实际上也是一种价值的延伸。</p><p></p><h4>InfoQ：顺丰科技是顺丰数字化的主力军，我们内部的数字化人才培养是怎么做的？</h4><p></p><p></p><p>林国强：人才培养方面主要分对内和对外。</p><p></p><p>对于内部科技<a href=\"https://www.infoq.cn/video/sCrEs13sPIU5xUTwVNkT\">人才培养</a>\"，我们的一般做法，是让所有新入职人员先去航空物流机场、配送网点等一线现场实践一段时间，不管他是高管，还是普通工作人员。在实践过程中，大家往往就会发现很多远程无法发现的问题，然后对应进行流程优化和技术开发。并且，在开发完成后，他还会再回到现场进行复盘，去验证这项技术是不是真的对一线工作人员的工作带来了赋能。</p><p></p><p>而对外的人才培养，主要是商业增长的部分。在顺丰，会通过孵化器，甄选内部比较优秀的技术产品，由顺丰帮助实现商业模式落地，对外提供技术服务，实现商业创收。</p><p></p><p>霍太稳：极客邦《<a href=\"https://www.infoq.cn/album/79\">行知数字中国</a>\"》最新一期的节目，我们采访了<a href=\"https://www.infoq.cn/video/sVz55QCL2muze0GQtZA2?utm_source=album_info&amp;utm_medium=article\">麦当劳中国</a>\"CIO陈世宏，据他介绍，他们入职麦当劳后的第一件事，也是先到麦当劳餐厅做两周的服务员。通过这种方式，他们作为技术负责人能快速地了解公司的业务流程和一线员工的具体需求，确保后续在做技术决策的时候能够更贴合一线需求，而不是拍脑门决定。所以，深入一线现场，这会慢慢变成对技术人员的一个刚性要求。</p><p></p><h4>InfoQ：很多企业表示在数字人才培养过程中，数据相关的人才比较紧缺，对于这方面的个人能力提升，您有什么建议吗？</h4><p></p><p></p><p>林国强：以数据产品经理和数据开发这两个角色为例，他们本身的行业属性还是非常强的，也就是说，他们不可能去做所有的行业的事情。通常来说，他们会在某一两个行业比较擅长，熟知行业所处上下游供应商的相关数据，以及对应的数据质量、数据的关键价值，并且能够善用行业中的大数据工具。如果有个数据产品经理说，所有行业的数据工作他都能干，说明他的竞争力是有限的。</p><p></p><p>反过来看，对于这一领域的从业者，除了熟悉数据治理体系和技术能力之外，懂行业是非常关键的。只有这样，你才能知道技术和数据具体在哪个场景能发挥作用，能带来什么实际业务增长或者成本降低。比如说物流行业最关键的是降本，那你要能快速了解，物流行业最大的成本在哪里，以及如何通过数据去减少对应场景的成本。只有这样，你才能成为企业真正需要的数据人才。</p><p></p><p>霍太稳：这也是为什么我们一直是鼓励技术人员深入行业的原因，互联网行业不是数字化转型的主战场，数字化的主战场一定是在那些数字化基础相对比较薄弱的实体企业。很多技术人在互联网呆久了，觉得这个地方自由、薪酬高，又有很多的前沿技术，所以不愿意做出改变。但是，这个世界已经变了，如果大家还停留在固有认知上，对于自身的成长并不是好事。希望大家能够走出原来的圈子，换一个场景，发挥我们的价值。</p><p></p><h4>嘉宾介绍</h4><p></p><p></p><p>林国强，顺丰科技大数据总监。负责顺丰集团大数据科技融通、大数据产业化赋能和大数据生态建设。对快消零售行业和县域经济有深入研究和实践，理解行业痛点和科技创新的链接点，在行业中落地过多个头部客户数字化转型案例，助力客户实现主营业务增收、供应链成本优化和管理数字化。</p><p></p><p>霍太稳，极客邦科技创始人兼 CEO，InfoQ 中国创始人，极客时间创始人，TGO 鲲鹏会发起人。2007 年创立 InfoQ 中国，2014 年创立极客邦科技，2015 年发起 TGO 鲲鹏会，2017 年创立在线职业教育学习品牌极客时间，2019 年开创极客时间企业版，拓展企业服务市场。</p>",
    "publish_time": "2022-12-01 15:52:34",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "腾讯发布数字孪生云，四大核心技术加速万物孪生",
    "url": "https://www.infoq.cn/article/lz4xxpqPCadNj181bCwP",
    "summary": "<p>12月1日，在 2022 腾讯全球数字生态大会上，腾讯数字孪生产品部总经理苏奎峰全面介绍了腾讯在<a href=\"https://www.infoq.cn/article/E5tCw3er7AaU99Zfwvfu\">数字孪生</a>\"领域技术布局，并向业内首次发布了数字孪生云平台。</p><p></p><p>苏奎峰表示，数字孪生是数字化转型的深化阶段和未来愿景，是对物理实体的数字化表达，支持构建全生命周期、全价值链的数据链路，并为“人在环”提供了一个沉浸式操作交互环境，将无法保存的业务经验进行数字化，并提供了保存、复制和升级优化的能力。腾讯数字数字孪生云具备全息映射、仿真推演、分析预测、实时交互等能力，全栈技术体系能够快速适配各个行业，满足业务数字化转型的降本增效需求，为建立以数据为核心驱动要素的产业升级提供了有力支撑。</p><p></p><p>腾讯在过去场景的实践中积累了众多技术和经验，致力于为行业提供平台型能力，并基于游戏科技、云计算/云渲染、人工智能、模拟仿真、全息感知以及音视频传输等核心技术，打造了数字孪生云平台，重点解决全过流程及决策可视、决策优化、跨时空在场协同以及泛在触达等问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/83/838fec698bd038ba7b6409556f1372ad.png\" /></p><p></p><p>该平台是一个云化的、开放的孪生场景构建平台，配套了多种能力与工具，可以提供给行业用户或生态伙伴，他们可以在此基础上进行孪生应用快速搭建和业务创新。这一平台将有效助力行业低门槛、低成本开发孪生应用，实现效率上的飞越，让数字孪生应用更轻、更快。</p><p></p><p>具体而言，腾讯数字孪生云具备全真映射、实时计算、数据驱动、泛在连接的四大能力特点。</p><p></p><p>全真映射方面，基于实时物联感知、三维精准还原、音视频传输以及高保真渲染等能力，实现物理世界到<a href=\"https://www.infoq.cn/article/Wvo3SEOyc5MsvbqCVLgl\">虚拟世界</a>\"的实时、精准映射，从而保证腾讯数字孪生云能够更精准、快捷的构建对物理世界实时映射。</p><p></p><p>实时计算方面，依托云边端分布式协同架构，实现大规模的并行计算，构建对人、机、物、空间等对象的可计算能力。结合仿真推演和泛在智能，辅助用户进行决策。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f6/f684d7b0cb8ba556ec0c0363af3463fe.png\" /></p><p></p><p>数据驱动方面，以海量真实数据为驱动，通过全面融合多源数据和模型来提升仿真推演和预测分析精度和效率。</p><p></p><p>泛在连接方面，基于云渲染能力，实现用户通过多种设备随时随地访问孪生应用系统，还可以实现多用户同时在线，突破时空的物理约束，基于上帝视角的在场实时协同，从而大幅提升业务协同效率。腾讯将数字孪生与企业微信打通，实现了办公协同与业务协同的有效连接。基于人工智能算法和游戏化交互，可以实现更智能的连接和更高效的人机交互。</p><p></p><p>会上，腾讯还重磅发布《腾讯数字孪生云白皮书》，从多个维度分析和洞察数字孪生最新的前沿应用趋势，对数字孪生技术框架、应用场景、实施策略等做了重点呈现。据了解，《腾讯数字孪生云白皮书》由腾讯多个部门联合撰写，从多个维度分析和洞察数字孪生最新的前沿应用趋势，展现科技发展的脉络与前景。</p><p></p><p>白皮书提到，数字孪生作为产业<a href=\"https://www.infoq.cn/article/3gYhtdjYmaXFds6qBlui\">数字化</a>\"核心技术之一，正伴随着产学研用各界的研究以及政策环境、用户需求等变化加速演进，目前在交通、建筑、能源、工业等典型行业已经落地服务，行业需进一步完善数字孪生数据、模型、产品等标准体系，未来，构建开源创新生态、激发开源活力、打造超大规模数字孪生将成为重要方向。</p><p></p><p>面对科技创新的新要求、数实创新的新命题、产业共进的新格局，腾讯将持续利用数字孪生为产业提供数字化底座，开放更多工具能力，万物孪生逐步照进现实。</p>",
    "publish_time": "2022-12-01 15:59:51",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "霍太稳：以数字人才培养 激发企业发展新动能 ｜ 数字人才蓄能季高端论坛",
    "url": "https://www.infoq.cn/article/Q7iEvAi0XxZdtkcFgHlB",
    "summary": "<p>企业数字化转型过程中，IT 团队想要胜任领头羊角色，首先需要完成自我变革。重塑观念、行为和协作方式，与业务深度链接，才能发挥出技术的核心价值。IT 团队要如何助力企业实现数据驱动、科技驱动的业务增长？应该具备怎样的数字化能力？如何适应数字化组织的变革？您可以从「数字人才蓄能季高端论坛」的分享中探寻答案。</p>\n<p>极客时间企业版和培训杂志共同举办「数字人才蓄能季高端论坛」，吸引了上万名观众线上参会。论坛上华润雪花的信息化、数字化负责人 郭华分享了雪花转型升级过程中，公司人员规模缩减 50% 的挑战下，如何通过“补短板、提质量、增效益”，打造专业分工明确的数字化人才梯队，构建作战型团队构成的、灵活的、充分数字化的组织，成就雪花啤酒华丽蜕变。极客邦科技 COO 司巧蕾发布了“极客时间专项 IT 核心人才发展计划”，提供研测学考评一体化培训体验，助力企业打造卓越 IT 团队。极客时间内容总监李佳也带来了技术人才岗位能力模型搭建方法论和案例分享。</p>",
    "publish_time": "2022-12-01 17:17:07",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]