[
  {
    "title": "腾讯云技术实践精选集 2022",
    "url": "https://www.infoq.cn/article/RuveM045ptfTNKwfeq6c",
    "summary": "<p>2022 年，数字化转型成为了全行业关注的焦点，数字经济的价值进一步凸显。云计算作为数字时代的关键要素之一，正从单一云向多云、混合云战略过渡；分布式云服务也进入了高速发展的黄金期；随着 Docker、K8s 等容器技术的流行，云原生正成为云计算的新赛场，也成为企业数字化转型发展的“默认选项”、新底座；除此之外，人工智能、边缘计算等技术的普及进一步加速了云计算技术的变革。无论是数字原生行业还是非数字原生行业，云计算在行业数字化解决方案、产业链数据流转、资源动态配置、业务创新等方面正产生着难以估量的价值。</p>\n<p>对于腾讯的技术团队来讲，2022年也是一个重要的技术里程碑之年。<span class=\"orange\"><strong>历经三年，包括 QQ、微信、王者荣耀、腾讯会议等亿级用户规模的腾讯自研业务已全面上云，集群规模突破 5000 万核，累计节省成本超 30 亿，这使得腾讯打造出国内最大规模的云原生实践。</strong></span></p>\n<p>如何把这些亿级业务全部搬到云上并实现云原生改造？腾讯云做了大量的技术优化和革新，比如：</p>\n<ul>\n<li>在容器调度领域 ，通过混部技术将资源利用率提升到 65%；</li>\n<li>在数据库领域，通过存算分离技术，打造了国内第一款云原生 Serverless 数据库；</li>\n<li>在安全领域，借助云原生技术本身的可观测性手段，创新地与安全结合，打造了更贴合云原生技术的专业安全防护能力等等。</li>\n</ul>\n<p>为此也沉淀了一份 6 万多字的《腾讯大规模云原生技术实践案例集》，包括 10 多个国民级应用的上云实践，可扫描封底二维码下载阅读。</p>\n<p>除了赋能自研业务外，腾讯云还将上述诸多产品或服务以及配套的基础软件、底层技术等开放给百万级的外部客户，全部基于公有云模式开发运营，赋能千行百业，也造就了一大批金融、游戏、企业服务、智能制造、教育等场景下的最佳实践。</p>\n<p>此外，为了解决客户上云、用云的成本之忧，腾讯云基于内外云原生成本管理最佳实践，并结合行业优秀案例，提出了一套体系化的云原生上云成本优化方法论和最佳实践路径，发布了两个业界“标准”：《云原生最佳实践路线图》和《降本之源 · 云原生成本管理白皮书》，旨在帮助企业改善用云成本，充分发挥云原生的效能和价值。</p>\n<p>2022 年，是不平凡的一年，感恩来自行业、伙伴、团队的力量推动着我们勇往直前。在今年，我们参与了 DIVE 2022 北京站、ArchSummit 2022 深圳站、QCon 2022 广州站、ArchSummit 2022 北京站、ArchSummit 2022 杭州站等多场大会，与 1000+ 位技术人邂逅并分享心得。</p>\n<p>此外，这也是腾讯云连续两年推出《腾讯云技术实践精选集》，去年 2021 版精选集共 4 万多字，全网带来 7000 多次下载。<span class=\"orange\"><strong>2022 版的精选集总字数近 10 万，尤其首次收录了“腾讯自研业务大规模云原生实践”系列内容，全面解密腾讯如何锤炼腾讯云。</strong></span></p>\n<p>每一次相遇，都难能可贵，每一场交流，都价值满满，遂整理成文，共享丰沃。</p>\n<p>展望 2023 ，愿与诸君携手同行，共攀技术新峰！</p>\n<h1>目录</h1>\n<h2>第一部分  腾讯自研业务大规模云原生实践</h2>\n<ul>\n<li>如何管理超千万核资源的容器规模</li>\n<li>50W+ 小程序开发者背后的数据库降本增效实践</li>\n<li>拥抱云原生，数十万规模 GPU 卡的利用率极致优化之路</li>\n<li>TDSQL-PG 数据库在微信支付的应用实践</li>\n<li>将云原生进行到底：腾讯百万级别容器云平台实践揭秘</li>\n<li>云原生安全可观测性探索与实践</li>\n<li>大规模代码中引入供应链漏洞的分析技术前瞻</li>\n</ul>\n<h2>第二部分  大数据与云数据库技术探索及实践</h2>\n<ul>\n<li>腾讯云大数据 TBDS 在私有化场景万节点集群的实践</li>\n<li>PB 级数据秒级分析，腾讯云原生湖仓 DLC 架构揭秘</li>\n<li>CDW PG 大规模在线数仓技术构架分享</li>\n<li>云原生数据库管控探索和实践</li>\n<li>腾讯云原生数据库 TDSQL-C 架构探索和实践</li>\n<li>金融级分布式数据库 TDSQL 升级版引擎架构和关键技术介绍</li>\n<li>国产金融级分布式数据库在金融核心场景的探索实践</li>\n<li>腾讯云 MongoDB 智能诊断及性能优化实践</li>\n<li>腾讯云数据库云上 SaaS 生态演进</li>\n</ul>\n<h2>第三部分  云成本优化与研发提效</h2>\n<ul>\n<li>企业上云，云上资源整体成本优化管理如何做？</li>\n<li>企业如何利用云厂商能力构建自己的分布式云？</li>\n<li>从混部到 Serverless 化，腾讯自研业务的稳定性及云原生成本优化实践</li>\n<li>Serverless 时代下，企业微服务的降本思考与实践</li>\n<li>腾讯课堂面向协作的 DevOps 流程设计与实践</li>\n</ul>\n<h2>第四部分  中间件与基础设施</h2>\n<ul>\n<li>Kafka Stream - 的进化探索：流式 Serverless 计算</li>\n<li>JVMTI Agent在中间件领域的应用</li>\n<li>区块链如何支撑 Web 3.0</li>\n<li>腾讯操作系统的创新之路</li>\n<li>腾讯明眸媒体处理实践</li>\n</ul>",
    "publish_time": "2022-12-01 01:55:37",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何用Go语言构建、测试和部署可扩展的REST API",
    "url": "https://www.infoq.cn/article/LdimuNAoab0ZHpmVDKOf",
    "summary": "<p></p><h2>引言</h2><p></p><p>在本文中，我们将了解如何使用<a href=\"https://gin-gonic.com/\">gin</a>\"框架创建一个简单的Golang应用程序。我们还将学习如何使用持续部署工具<a href=\"https://circleci.com/\">CircleCI</a>\"实现自动化测试和部署。</p><p>&nbsp;</p><p>Go是一种静态类型的开源编程语言，由谷歌工程师创建，其唯一的目的是简化复杂的软件开发过程和架构。它的主要特性包括：高性能网络、并发性和易用性。Go中广泛使用了Goroutine。Goroutine是一个在程序中与其他Goroutine并行运行的函数。当需要同时做几件事时，Goroutine会很有用。举例来说，谷歌、Cloudflare、MongoDB、Netflix和Uber几家公司都使用了Go。</p><p>&nbsp;</p><p><a href=\"https://gin-gonic.com/\">Gin</a>\"是一个基于Go的高性能HTTP Web框架，可以用来构建微服务和Web应用程序。Gin的主要优势在于，它使得开发人员可以创建高效、可扩展的应用程序，而且不必编写大量的样板代码。它生成的代码简洁、易于阅读。它还内置了路由、用于处理功能的中间件、日志记录器和Web服务器。</p><p></p><h2>构建一个简单的CRUD API</h2><p></p><p>我们将为学院俱乐部的学生管理工具创建一个简单的API。完成后，俱乐部主席将能够新增学生及检索所有学生。如果想完全按照本教程来操作，则需要做好以下准备：</p><p>安装Go，了解该语言的基本知识；了解测试，知道如何编写测试；一个GitHub账号；一个CircleCI账号；一个Heroku账号。</p><p>&nbsp;</p><p>请注意，如果你想使用Heroku的免费帐户进行试验，那么Heroku很快就会将其停用。不过，这里描述的过程可以很容易地应用于其他大多数云托管平台。</p><p></p><h3>构建一个CRUD应用程序</h3><p></p><p>这个简单的学院俱乐部API只有两个功能：将学生添加为会员和查看所有会员；没有什么复杂的东西！我们将用到POST和GET请求。我们不会连接任何数据库，如MongoDB或MySQL。但是，我们将使用本地存储并默认在数据库中创建一个学生。每当服务器重启时，就会自动添加这个学生。</p><p>&nbsp;</p><p>让我们开始吧。首先，我们将创建一个项目文件夹，并命名为stup -api。在这个文件夹中，我们将初始化Golang程序并安装所需的所有依赖。</p><p><code lang=\"go\">mkdir stud-api\ncd stud-api</code></p><p>接下来，我们将初始化go.mod文件，并安装所需的所有依赖：</p><p><code lang=\"go\">go mod init stud-api\ncd stud-api\ngo get -u github.com/gin-gonic/gin github.com/rs/xid github.com/stretchr/testify </code></p><p><a href=\"http://github.com/rs/xid\">Github.com/rs/xid</a>\"是一个用于创建惟一标识的库。在这个项目中，我们将用它自动为每个新学生生成一个ID。我们将用<a href=\"http://github.com/stretchr/testify\">github.com/stretchr/testify</a>\"包测试各个端点。</p><p>&nbsp;</p><p>下面开始讨论API。简单起见，我们只创建一个名为main.go的文件。这个文件将包含struct 、API控制器、服务和路由。我们将创建三个端点：</p><p>一个发送欢迎消息的欢迎函数；一个将学生添加到数据库的CreateStudent()&nbsp;函数；一个返回数据库中所有已注册学生的GetStudents()函数。</p><p>&nbsp;</p><p>下面在新创建的main.go文件中导入三个包：HTTP包、xID包和gin包。接下来，编写一个main()函数，其中将包含所有的API路由。然后，另外创建一个函数WelcomeMessage()，在调用相关的路由时，它会打印一条简单的消息。</p><p><code lang=\"go\">package main\nimport (\n\"net/http\"\n\"github.com/gin-gonic/gin\"\n\"github.com/rs/xid\"\n)\n\n\nfunc main() {\n//设置路由\nrouter := gin.Default()\nrouter.GET(\"/\", WelcomeMessage)\nrouter.Run()\n}\n//欢迎消息\nfunc WelcomeMessage(c *gin.Context) {\nc.JSON(http.StatusOK, gin.H{\"message\": \"Hey boss!\"})\n}</code></p><p>现在，可以使用下面的命令来启动服务器，看看到目前为止我们都做了什么：</p><p><code lang=\"go\">go run main.go</code></p><p>如果运行成功，则CLI将显示“Hey boss!”。这个简单的函数就创建完成了。现在我们将继续讨论数据库和struct 。</p><p>&nbsp;</p><p>我们将构建一个简单的Student struct ，它接受三个参数：学生姓名、学院和年级，并在用户成功添加到数据库时为其生成一个ID。</p><p><code lang=\"go\">//定义学生结构\ntype Student struct {\nID         string `json:\"id\"`\nName       string `json:\"name\"`\nDepartment string `json:\"department\"`\nLevel      string `json:\"level\"`\n}</code></p><p>现在，我们创建下本地数据库，它将存储我们传递给服务器的三个值以及生成的ID。我们将数据库命名为Students，其中会包含一个学生的默认数据，而新创建的任何学生都会添加到这里。</p><p><code lang=\"go\">//学生数据库\nvar students = []Student{\n{\nID:         \"10000xbcd3\",\nName:       \"Alicia Winds\",\nDepartment: \"Political Science\",\nLevel:      \"Year 3\",\n},\n}</code></p><p>好了，数据库设计就完成了，现在我们编写下CreateStudent()函数以及与其交互的路由。</p><p><code lang=\"go\">//新建一个学生账号\nfunc CreateStudent() gin.HandlerFunc {\nreturn func(c *gin.Context) {\nvar newStudent Student\nif err := c.BindJSON(&amp;newStudent); err != nil {\nc.JSON(http.StatusBadRequest, gin.H{\n\"Status\":  http.StatusBadRequest,\n\"Message\": \"error\",\n\"Data\":    map[string]interface{}{\"data\": err.Error()}})\nreturn\n}\n//生成一个学生ID\nnewStudent.ID = xid.New().String()\nstudents = append(students, newStudent)\nc.JSON(http.StatusCreated, newStudent)\n}\n\n\n}</code></p><p>现在将与该函数交互所需的路由添加到main()函数。</p><p><code lang=\"go\">func main() {\n-------------\nrouter.POST(\"/createStudent\", CreateStudent())\n-------------\n}</code></p><p>要测试到目前为止所做的工作，请启动服务器，并在Postman或任何其他环境中测试端点（localhost:8080/createStudent）。在消息体中传递姓名、学院和年级，就会自动生成一个具有惟一ID的新用户。请注意，这是一个非持久化数据库。</p><p>&nbsp;</p><p>现在，让我们创建最后一个函数。我们将使用它来获取俱乐部数据库中的所有学生。这个请求是一个简单的GET函数，它将搜索学生数据库并返回其中的所有内容。</p><p><code lang=\"go\">func GetStudents() gin.HandlerFunc {\nreturn func(c *gin.Context) {\n//获取数据库中的所有学生\nc.JSON(http.StatusOK, students)\n}\n}</code></p><p>最后，我们将创建与新建函数进行交互的路由。我们将把它加入主函数，和其他路由放在一起。</p><p><code lang=\"go\">func main() {\n------------------\nrouter.GET(\"/students\", GetStudents())\nrouter.Run()\n}</code></p><p>也使用Postman测试一下！为此，我们需要启动服务器并访问端点localhost:8080/students。我们所需要做的就是使用HTTP谓词GET，不需要包含任何消息体或查询参数。运行成功后，它将返回数据库中的所有学生。这样，这个简单的CRUD API就完成了！</p><p></p><h2>编写简单的本地测试</h2><p></p><p>在这一节中，我们将对已创建的端点进行单元测试。目标是确保每个函数的行为都符合预期。为了测试这些函数，我们将使用<a href=\"https://github.com/stretchr/testify\">testify</a>\"包。此外，我们必须新建一个文件new_test.go。我们将要编写的各种测试都将放在这个文件中。在主目录的根目录中创建完新文件后，我们需要导入几个包。</p><p><code lang=\"go\">func main() {\n------------------\nrouter.GET(\"/students\", GetStudents())\nrouter.Run()\n}</code></p><p>在testify中，执行简单的断言和模拟都很容易。在Go中，testing.T对象作为assert函数的第一个参数传入。然后，assert函数会返回一个bool值，说明断言是否成功。<a href=\"https://github.com/stretchr/testify\">testify mock</a>\"包提供了一种快速创建模拟对象的方法，在编写测试代码时可以用它代替实际的对象。</p><p>&nbsp;</p><p>现在，我们将设置一个路由，并为欢迎消息编写一个简单的测试。如下所示，在这个测试中，assert函数将使用变量的相等比较来确定测试参数是否与模拟响应相匹配。</p><p><code lang=\"go\">func SetRouter() *gin.Engine {\nrouter := gin.Default()\nreturn router\n}\n\n\nfunc TestWelcomeMessage(t *testing.T) {\nmockResponse := `{\"message\":\"Hey boss!\"}`\nr := SetRouter()\nr.GET(\"/\", WelcomeMessage)\nreq, _ := http.NewRequest(\"GET\", \"/\", nil)\nw := httptest.NewRecorder()\nr.ServeHTTP(w, req)\nresponseData, _ := ioutil.ReadAll(w.Body)\nassert.Equal(t, mockResponse, string(responseData))\nassert.Equal(t, http.StatusOK, w.Code)\n}</code></p><p>接下来，我们将使用模拟数据为createStudent()函数编写一个简单的测试。还是使用xID包来生成Student ID，我们会收到一个说明测试是否成功的bool值。</p><p><code lang=\"go\">func TestCreateStudent(t *testing.T) {\nr := SetRouter()\nr.POST(\"/createStudent\", CreateStudent())\nstudentId := xid.New().String()\nstudent := Student{\nID:         studentId,\nName:       \"Greg Winds\",\nDepartment: \"Political Science\",\nLevel:      \"Year 4\",}\njsonValue, _ := json.Marshal(student)\nreq, _ := http.NewRequest(\"POST\", \"/createStudent\", bytes.NewBuffer(jsonValue))\nw := httptest.NewRecorder()\nr.ServeHTTP(w, req)\nassert.Equal(t, http.StatusCreated, w.Code)}</code></p><p>最后，我们将针对GetStudents()函数编写最后一个测试。</p><p><code lang=\"go\">func TestGetStudents(t *testing.T) {\nr := SetRouter()\nr.GET(\"/students\", GetStudents())\nreq, _ := http.NewRequest(\"GET\", \"/students\", nil)\nw := httptest.NewRecorder()\nr.ServeHTTP(w, req)\nvar students []Student\njson.Unmarshal(w.Body.Bytes(), &amp;students)\nassert.Equal(t, http.StatusOK, w.Code)\nassert.NotEmpty(t, students)\n}</code></p><p>我们已经完成了所有的测试，现在可以在本地运行了。这很简单，只需执行下面这行命令：</p><p><code lang=\"go\">GIN_MODE=release go test -v</code></p><p>下面是最终结果：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c8/c89269c1ab1abe45d5b1c8055955e19b.png\" /></p><p></p><p></p><h2>利用持续开发实现测试自动化</h2><p></p><p><a href=\"https://circleci.com/\">CircleCI</a>\"是一个用于持续集成和交付的平台，可用于DevOps实践。在本文中，我们将使用这个CI/CD工具实现测试自动化并将代码部署到服务器上。我们先从使用CircleCI自动化测试开始说起。</p><p>&nbsp;</p><p>确保你有一个CircleCI帐户（正如准备工作部分所介绍的那样），并且已经成功地将代码推送到GitHub。检查CircleCI仪表板，确保项目存储库是可见的。</p><p>&nbsp;</p><p>现在，在项目目录中，创建文件夹.circleci和配置文件config.yml，该文件将包含自动化测试所需的命令。</p><p></p><h2>配置config.yaml</h2><p></p><p>该文件包含自动化Heroku部署和测试所需的所有配置。我们暂时不关注Heroku部分，因为我们更感兴趣的是帮助实现自动化测试的代码。该文件包含检出并运行测试的Go orb和作业。在将下面的代码添加到配置文件后，我们需要将其重新推送到GitHub。</p><p><code lang=\"go\">workflows:\n  heroku_deploy:\n    jobs:\n      - build\n      - heroku/deploy-via-git:  \n          requires:\n            - build\n          filters:\n            branches:\n              only: main\njobs:\n  build:\n    working_directory: ~/repo\n    docker:\n      - image: cimg/go:1.17.10\n    steps:\n      - checkout\n      - restore_cache:\n          keys:\n            - go-mod-v4-{{ checksum \"go.sum\" }}\n      - run:\n          name: Install Dependencies\n          command: go get ./...\n      - save_cache:\n          key: go-mod-v4-{{ checksum \"go.sum\" }}\n          paths:\n            - \"/go/pkg/mod\"\n      - run:\n          name: Run tests\n          command: go test -v</code></p><p>完成这一步之后，返回CircleCI仪表板并选择我们的项目。然后，单击它旁边的Setup按钮，并选择我们正在使用的分支。当我们点击Setup按钮时，程序将开始运行。构建成功的话应该可以看到如下所示的信息（向下滚动到运行测试的部分）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dc/dcd8ecfbdd26422690454f942590e501.png\" /></p><p></p><p>就是这样！我们成功地构建了一个简单的API，创建了本地测试，并实现了测试过程自动化。这个自动化过程意味着，每次向GitHub存储库上的分支推送时，管道都会尝试运行测试。</p><p></p><h2>使用CircleCI自动部署到Heroku</h2><p></p><p>首先是配置Heroku。如果你还没有Heroku帐户，就需要创建一个。为了方便部署和自动化，你还需要将GitHub配置文件连接到Heroku帐户。上述工作完成之后，需要在项目文件夹中创建一个Procfile（是的，没有扩展名），并向其中添加以下内容：</p><p><code lang=\"go\">web: app</code></p><p>之后，推送到GitHub。现在，快速看一下之前创建的config.yaml文件，分析下第一部分。可以看到，我们导入了Heroku orb，其中还有一个工作流，里面是一个在主存储库中构建和部署代码的作业。</p><p>&nbsp;</p><p>回到Heroku仪表板，我们必须首先在Heroku上创建一个项目，并获取API密钥（可以从帐户设置中找）。我们需要把这个密钥添加到我们的CircleCI项目。为此，在CircleCI上导航到现有项目并选择项目设置。然后转到环境变量部分，添加下面这两个东西：</p><p>HEROKU_APP_NAME，值为stud-api&nbsp;（应用程序名称）；HEROKU_API_KEY&nbsp;，值为我们刚刚从Heroku获取的密钥。</p><p>&nbsp;</p><p>我们已经成功地配置了我们的CircleCI项目，可以向Heroku持续部署了。如果没什么问题，在CircleCI仪表板上，我们应该可以看到下面这样一条说明构建已经成功的消息：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/94/94ab3fc91daeedd7c2f24286909ac969.png\" /></p><p></p><p>返回Heroku仪表板并检索项目URL，看看我们都做了什么。这里，URL是：<a href=\"https://stud-app-api.herokuapp.com/\">https://stud-app-api.herokuapp.com/</a>\"。你可以将想要测试的路由附加到URL末尾来测试所有的功能。例如，测试获取所有学生的端点：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4e/4eb298655ea8ae784774f6ec8fd9287a.png\" /></p><p></p><p></p><h2>小结</h2><p></p><p>持续开发使开发人员能够更快地创建更好的产品。持续集成和开发工具通过自动化操作简化了整个过程，减少了所需的时间或专业知识。CI/CD工具通过自动化从测试到应用程序快速部署之间的所有事情，帮助我们逐步提高产品质量。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/build-deploy-scalable-golang-api/\">https://www.infoq.com/articles/build-deploy-scalable-golang-api/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/jfkZ7LHF1HbONN2sPOyw\">REST 如何站到了自己的对立面？</a>\"</p><p><a href=\"https://xie.infoq.cn/article/abaa53f80114223d2940f439d\">什么是 RESTful，REST api 设计时应该遵守什么样的规则？</a>\"</p>",
    "publish_time": "2022-12-01 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "一年覆盖九种语言上千服务，作业帮 Service Mesh 如何大规模落地？",
    "url": "https://www.infoq.cn/article/98SQPazzQUxMglZx28Yq",
    "summary": "<p>2019 年底，<a href=\"https://www.infoq.cn/article/gNzSTfhgs8xzRlYgciEv\">作业帮</a>\"技术栈比较多元且业务复杂度较高：使用最多的语言为 PHP 和 Golang，约占到总模块数量的 60% 左右；此外还有大量的系统使用 NodeJs、Java、C++、lua、python 编写等，即使是同样的技术栈，也会因为业务特点、团队特点，技术栈上呈现出较大差异；工具型产品侧重客户端，服务端技术偏保守。产业互联网业务，领域驱动，大量使用微服务架构，但由于没有统一的标准，各自团队也在自研服务治理体系的基础设施。</p><p></p><p>语言栈多元后，业务间的沟通协作就变得困难。跨语言的微服务框架难以落地统一的服务治理标准，致使业务服务治理参差不齐，大大限制了业务的快速迭代和稳定性。</p><p></p><p>同时作业帮的服务调用方式比较多样化，有 HTTP、gRPC、自研协议等，治理难度非常大，不同的 RPC 协议也会导致服务间通信困难。作业帮当时已有数千个服务，且服务间请求链路较长，一次请求的深度可能就超过一百多、甚至数百。</p><p></p><p>此时，已经完成容器化进程的作业帮开始着手调研服务治理技术，希望借助 <a href=\"https://xie.infoq.cn/article/7cb4393bd2828d5300edb31ec\">Service Mesh</a>\" 技术，来解决当时复杂的服务治理问题。</p><p></p><p>同年，为了适应云原生发展，作业帮进行了组织架构调整，将运维、安全、数据库、架构研发和部分通用中台等统一归纳到了基础架构团队。Service Mesh 的工作也落到了基础架构团队头上。</p><p></p><p>解决复杂治理问题最大的“拦路虎”是：业务既渴望使用新技术，但又担忧会带来高昂的使用成本，因此宁愿原地停留也不进行升级。那么，作业帮基础架构团队是如何解决这一问题的呢？这次，InfoQ 有幸采访了基础架构团队负责人董晓聪和架构研发团队负责人吕亚霖，为我们详细阐述了作业帮的实践思路和效果。</p><p></p><h3>全自研 Mesh</h3><p></p><p></p><p>“基础架构团队在进行服务治理时，既要保证稳定性，还要能够帮助业务提升效率。”董晓聪总结道。具体来说，团队的核心目标就是让 Service Mesh 接管服务治理里大量的非功能逻辑，实现服务的流量控制、可观测性和安全韧性，并且通过能力下沉，让业务透明、无感地接入。</p><p></p><p>但面对当前市面上各种开源产品，基础架构团队在前期充分调研后，认为这些产品都不太能满足作业帮的需求，因此选择了一条全自研的路。</p><p></p><h4>数据面，更看重性能</h4><p></p><p></p><p>数据面上，作业帮更倾向追求极致的性能，而对扩展性的需求并不迫切。这是由于作业帮内部的链路较长（上百 span），对业务来说哪怕是单次请求毫秒级的损失，整体上都会带来较大的影响。</p><p></p><p>对于主流产品<a href=\"https://www.infoq.cn/article/aulwXCUFJctf5FK5zYzu\"> Envoy</a>\"，作业帮基础架构团队不太认同它的插件模式。“插件机制引入主要是为了降低开发难度，虽然能有效降低研发成本，但是性能较差，同时提供的隔离也不彻底。”作业帮架构研发团队负责人吕亚霖说道。</p><p></p><p>因此，基础架构团队用 C++ 自己实现数据面，初期按需求紧迫程度支持了三类协议：第一类是 RPC 数据面，负责服务通信；第二类是对象存储数据面，负责对象存储资源的鉴权管理、流控、分发及性能提升；第三类是加解密数据面，负责提供安全和数据加密的能力。这三种数据面的协议差异性很大，分别对应了 RPC 通信协议、文件读写流协议、加解密协议，且对性能要求极为苛刻。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/51/518b0f6597c8c67dccb482683d2a941a.png\" /></p><p></p><p>整体上，基础架构团队主要针对 RPC 协议，采用了 Mesh-proxy 代理方式。对于入流量，直接通过 UDS 转发给了 Server，Server 需要支持 UDS 监听；对于出流量，则与 Istio 类似，用 iptable 拦截，不过团队另用 eBPF 做了优化。</p><p></p><p>吕亚霖表示，iptable 出流量拦截过程复杂，带来了不少的性能损失，因此团队使用 eBPF 优化内核网络劫持，在 Sock Map 进行映射、省掉中间环节，就可以极大提升劫持性能。eBPF 优化的前提是系统内核是 5.X 版本以上，作业帮使用的是 5.10 版本，主要是 5.10 版本解决了 CO-RE 有利于后期的升级维护，而 Istio 为了适应大部分客户内核低版本情况并没有支持。</p><p></p><p>根据作业帮此前的测试，以 Envoy 官方数据为例，在 QPS 为 1000 下，Envoy 在模式的 v2-stats-wasm_both 下 P90 响应时间是 2.25 毫秒，相比于 baseline 测试结果，添加了 Envoy 边车之后 P90 时延增加了 1.3 毫秒，且随着并发加大逐步恶化。作业帮自研数据面实测添加了 mesh 边车之后 P90 时延增长比这个数据降低了 0.38 毫秒，随着并发加大比较稳定。当 QPS 从 1000 加到 10000 时，平均响应时间减少 0.4 毫秒。另外在 CPU 耗损上，在 QPS 为 1000 的情况下，Envoy 耗损 0.54 核，作业帮的数据面损耗 0.09 核。这项测试也验证了作业帮数据面的可用性。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/16/1688eb90c29aa220e469724c0543cd7e.png\" /></p><p></p><p>事实上，从立项到数据面研发完成，基础架构团队只用了两个月左右的时间。“我们是把问题进行了拆解和聚焦，使用了云原生 Kubernetes 的基座，初期只对 RPC 类流量做了 mesh 劫持。同时聚焦数据面性能本身。”作业帮基础架构负责人董晓聪说道。</p><p></p><h4>控制面，纳入统一管控平台</h4><p></p><p></p><p>控制面上，作业帮本身有完整的运维管控体系，即包含服务注册发现相关，还有服务感知的一系列能力。所以作业帮并没有单独做一个 Service Mesh 的控制面，而是基于已有体系扩展，直接实现进行流量管控、通信协议、安全等。</p><p></p><p>对于作业帮来说，管控面是 DevOps 理念的落地，能更好的贴合自身研发流程和组织管理，比如：统一鉴权、工单体系、审计体系等。</p><p></p><p>对于 Service Mesh 的控制面，作业帮并没有引入类 Istio 在 Service Mesh 的实现服务注册发现，而是使用原生的 Kubernetes 的注册发现。作业帮基础架构团队认为，在大型的复杂工程中，架构设计的核心目标是复杂度降维，而将服务注册发现引入到 Service Mesh 却是在将复杂度升维，Kubernetes 的服务发现是 node 级别，而 Istio 的服务发现是 pod 级别，服务发现数据是数量级的提升。而对于升维带来的更强计算力和内存需求等问题也没有给出很好的解决方案。比如 Istio 的 xDS 使用全量下发策略，会把整个网格内所有服务发现数据同步给 proxy 边车，这会带来一系列的问题。</p><p></p><p>另外根据团队观察，很多公司在接入的时候，精力被耗在了 xDS 对接上，从原有协议向 xDS 转换过程中也充斥着各种各样的问题。</p><p></p><p>基于以上考虑，作业帮并没有使用 xDS 来提供发现机制，而是沿用了 Kubernetes 里注册发现方式，通过 eBPF 来优化 service，也具备路由决策等能力。在基础架构团队看来，这种方式更加轻量级，也与 Kubernetes 社区的结合更为紧密。</p><p></p><p>另外在安全性方面，团队进行了认证授权、网络拦截等；观测性上，全量埋下了分布式追踪，支持日志的统一观测和监控等。</p><p></p><p>在作业帮基础架构团队看来，用不用某个协议只是看其能否满足实际需求或者是否认可它的模式。用 xDS 的好处是会有统一标准，但 xDS 能否成为事实标准，还有待时间的检验。</p><p></p><p>吕亚霖表示，目前将 xDS 当作标准还有一些风险。“xDS 成为标准的前提是升维带来的复杂度被其他方面拆解掉，但它现在的降维手段并不是一个通用方案，我们在看到新方案出来之前是不会跟进的。”不过团队也会继续观望，关键还是要看其能否在大型企业的大规模复杂场景下落地。</p><p></p><h3>超预期的推广速度</h3><p></p><p></p><p>研发完成后，基础架构团队开始了“边放量、边灰度、边优化”的循环。对作业帮来说，基础架构团队涵盖了不同方向的小组，团队内就可以完成闭环测试，然后再向业务推广。</p><p></p><p>实际上，Mesh 在作业帮内部的推广速度远超基础架构团队的预期。据悉，目前作业帮 Mesh 覆盖率已经超过 80%，涵盖了 C++、Python、PHP、Go、Java 等语言栈。董晓聪表示背后的核心原因有多个，一是流量管控和观测，真正帮助到了业务，二是 Mesh 是相对无感接入，三是 Mesh 落地提升了研发效率。</p><p></p><p>流量管控和观测方面：主要实现了流量管控、安全（认证授权）、可观测性（日志统计、全量分布式追踪）。流量管控上实现了很多业务期待的功能，比如自适应限流。很多情况下业务需要熔断限流，但是不太可能每个服务都进行压测配置限流阈值，同时业内的自适应限流算法与流量以及自身资源相关，也无法实现因下游服务容量问题时主动限流。作业帮将机器学习应用于该领域，实现了智能的流控，当通用模型不适合某些特定流量场景时，也提供基于过去半年的数据，学习和训练特有模型。</p><p></p><p>接入相对无感：业务几乎不需要改造，只需要兼容 listen uds，其他由基础架构直接升级，然后进行放量观察即可。改造成本极低。</p><p></p><p>研发效率方面：在原来的微服务开发模式下，模块非常多，业务进行联调和测试的效率非常低。比如联调要经过 CI/CD、发布到测试环境、验证等一系列复杂的过程，而微服务里改动一个需求可能就要改动几十个模块。一个研发每次改动就要重复一遍上述过程。而 Service Mesh 在研发阶段的作用就是使研发可以直接在本地启动服务，并且这个本地服务可以无缝的和远程的 Kubernetes 测试集群中的各个其它服务实现互相调用，免去了复杂的 CI/CD 流程。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/73/733f51abdd4227ad9a6c338455149b6b.png\" /></p><p></p><p>“一个业务线里面有一两个服务用了发现效率提升非常明显后，会形成很好的口碑效应，之后该业务其他研发会主动找过来要求升级。”吕亚霖表示。据悉，作业帮内部研发主动升级的比例在 50% 左右。</p><p></p><p>不过在推广过程中，基础架构团队也踩过坑。一次灰度放量时，某业务线使用了不规范的 HTTP 协议，但 Mesh 拦截 RPC 流量是按标准协议处理的，所以就产生了冲突，该问题影响了服务间的通信。</p><p></p><p>“这也让我们认识到，多语言栈下的协议确实没有那么规范，而这种不规范更多是因为各个语言，在协议实现层面上的差异导致。”董晓聪说道，“同时也展现了 Service Mesh 这项技术的意义，即接管服务治理里大量的非功能逻辑，实现标准化。”</p><p></p><p>除了这次事故，其他方面都远远超过了团队的预期，甚至由于需求变多，团队不得不投入更多的人力。</p><p></p><p>同时这次 Mesh 落地实践也让基础架构团队深刻体验到了内核研发能力的重要性。</p><p></p><p>“服务的各种小问题会特别容易摧毁业务线对你的信任。问题多了，哪怕是他业务的问题也会怀疑是 Service Mesh 的问题。”吕亚霖表说道，“这些问题都要及时解决，但在这个过程中，团队发现最后这些问题大部分需要在内核层面定位和配合解决。比如业务反馈平响多了几毫秒或者毛刺率变高，都需要在内核底层进行追踪定位，需要基础架构团队有一套分析定位内核的工具，同时内核追踪需要和业务的分布式追踪关联，才能快速定位解决问题。</p><p></p><p>总体来看，作业帮 Service Mesh 的落地收益比还是很不错的。作业帮基础架构团队只投入了两个专职人力，进行 Service Mesh 的研发和迭代。推广上持续了一年。通过 Mesh 的协议升级，带来了性能和稳定性的提升，比如 PHP、python 很多都是 HTTP1.0 的短链，团队通过 mesh 层进行协议协商升级，在业务无感的情况下将 HTTP 升级到了 2.0，减少网络建连、提升了网络传输速率。同时 Service Mesh 的落地带来了治理能力的大幅提升，全量的分布式追踪、完善的监控报警，以及在协议实现上的标准和统一。</p><p></p><h3>结束语</h3><p></p><p></p><p>虽然如此，吕亚霖提醒道，业务体量不大的时候跟风上 Service Mesh 并不会带来太多收益，甚至可能使整体产品的迭代变慢。多语言栈、链路比较长、业务要求比较高的情况更适合接入 Mesh。</p><p></p><p>“真正落地的时候你就会知道适不适合了，真正引入 Mesh 后发现推广不下去，本质上就说明了不适合。一项技术非常匹配时，推广便是一件水到渠成的事情。”吕亚霖说道。</p><p></p><p>另外，企业真的要接入 Mesh，也没有必要自研。自研对企业的研发能力要求会比较高。首先，Mesh 自研对 C++ 工程师的研发能力要求很高，但如今很多公司大多是 Java 工程师做基础架构。其次，根据作业帮基础架构团队的经验，团队要有内核研发和定位的能力，对于一些小公司来说可能并不具备这样的条件。</p><p></p><p>对于当前自研的选择，吕亚霖表示，这是有很多前提条件的。“比如 97% 的容器化、整体内核升到了 5.10、多语言栈、业务链条复杂、对时延敏感等，我们会觉得自研会更有优势。一旦这些前提不在了，自研就不见得比选择现有产品更好。”</p><p></p><p>嘉宾介绍：</p><p></p><p>董晓聪，作业帮基础架构负责人</p><p>吕亚霖，作业帮基础架构 - 架构研发团队负责人</p><p></p><p></p>",
    "publish_time": "2022-12-01 09:36:13",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "火山引擎公开课",
    "url": "https://www.infoq.cn/article/xUq5Q66QSwsTU4G3sLQx",
    "summary": "<p>目前，大数据、“云”相关技术逐渐成熟，处于大规模落地应用实践的喷发期，有人称现在这两个技术都要被提“烂”了，几乎每家都在做，无论是传统企业寻求数字化转型之路，还是互联网行业寻找新的业务增长点，都想要在这两者身上找到突破口。企业想要通过“云”完成降本增效和技术创新，通过大数据技术完成数据治理、数据分析等可以促进业务侧增长的任务。</p>\n<p>然而，当企业在应用了云和大数据等热门技术后会发现，企业规模扩大到一定程度后，不仅要考虑短时间内业务增长问题，而且还要能够找到持续实现业务增长的方式，“从 0 到 1 容易，从 1 到 100 不容易”。本视频便从“云”和“数据”两个方面给出了增长解决方案。</p>\n<h2><strong>视频大纲</strong></h2>\n<h4>《低成本也能稳增长，三招实现“数据驱动”的业务增长》</h4>\n<p>1 什么是低成本稳增长<br />\n2 如何实现低成本稳增长<br />\n2.1 构建用户画像，实现精细化运营<br />\n2.2 数据分析，驱动科学决策<br />\n2.3 A/B实验，用户增长的秘密武器<br />\n3 数据驱动业务增长背后的故事<br />\n3.1 火山引擎VeDI数智平台<br />\n3.2 A/B实验平台<br />\n3.3 智能数据洞察平台<br />\n3.4 客户数据平台</p>\n<h4>《亿级流量场景下的火山引擎边缘云应用实践》</h4>\n<p>1 超大规模流量场景面临的挑战</p>\n<p>2 火山引擎边缘云流量场景全链路解决方案<br />\n2.1 便捷的流量接入<br />\n2.2 高效的内容分发网络<br />\n2.3强大的边缘云基础设施<br />\n3 最佳实践</p>",
    "publish_time": "2022-12-01 10:39:48",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "2022 亚马逊云科技 re:Invent：一图看尽 Day 2 重要发布",
    "url": "https://www.infoq.cn/article/h2KIBbX6lPI0b8Fj0Reb",
    "summary": "<p></p><p><img src=\"https://static001.infoq.cn/resource/image/d2/e3/d268yyea5d05981804e04878c70947e3.png\" /></p><p></p>",
    "publish_time": "2022-12-01 11:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "聊聊云计算和 re:Invent 的现在和未来",
    "url": "https://www.infoq.cn/article/gYjPO4eITE4OIEteRFSC",
    "summary": "<p>云计算的出现给不同国家的开发者带来了哪些不一样的改变？对于re:Invent的未来，开发者们有着怎样的期待？日本开发者表示：希望现场能多点座位，因为那些高人气的会议会迅速爆满，手慢根本抢不到座位。的确，re:Invent 的人气真的太旺了！你对这场云计算盛会的未来有着怎样的期待呢？</p>",
    "publish_time": "2022-12-01 12:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "郭华：每一个人都不简单，每一瓶酒才放光彩——华润雪花的数字化人才观 ｜ 数字人才蓄能季高端论坛",
    "url": "https://www.infoq.cn/article/sCrEs13sPIU5xUTwVNkT",
    "summary": "<p>企业数字化转型过程中，IT 团队想要胜任领头羊角色，首先需要完成自我变革。重塑观念、行为和协作方式，与业务深度链接，才能发挥出技术的核心价值。IT 团队要如何助力企业实现数据驱动、科技驱动的业务增长？应该具备怎样的数字化能力？如何适应数字化组织的变革？您可以从「数字人才蓄能季高端论坛」的分享中探寻答案。</p>\n<p>极客时间企业版和培训杂志共同举办「数字人才蓄能季高端论坛」，吸引了上万名观众线上参会。论坛上华润雪花的信息化、数字化负责人 郭华分享了雪花转型升级过程中，公司人员规模缩减 50% 的挑战下，如何通过“补短板、提质量、增效益”，打造专业分工明确的数字化人才梯队，构建作战型团队构成的、灵活的、充分数字化的组织，成就雪花啤酒华丽蜕变。极客邦科技 COO 司巧蕾发布了“极客时间专项 IT 核心人才发展计划”，提供研测学考评一体化培训体验，助力企业打造卓越 IT 团队。极客时间内容总监李佳也带来了技术人才岗位能力模型搭建方法论和案例分享。</p>",
    "publish_time": "2022-12-01 12:03:03",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何破解Web3的「存力」难题？",
    "url": "https://www.infoq.cn/article/1pIQYNvrZlyCILUsWbMf",
    "summary": "<p>作者 | 蚂蚁链 LETUS 技术负责人 田世坤</p><p></p><h2>写在前面</h2><p></p><p></p><p>文字产生以前，结绳记事是人类用来存储知识和信息的主要方式。此后，从竹简、纸张的发明，到工业时代的磁盘存储，再到信息时代的数据库，存储方式不断革新，“存力”不断提高。</p><p></p><p>11 月 3 日，在 2022 云栖大会上，蚂蚁链历经 4 年技术攻关与测试验证的区块链存储引擎 LETUS（Log-structured Efficient Trusted Universal Storage）正式发布。</p><p></p><p>这一款面向区块链可信数据存储的技术产品，不仅用来解决当前蚂蚁链及区块链产业的规模化发展问题，也面向 Web3 时代提供“可信存力”支撑。</p><p></p><p>我们认为，随着大量的数据和数字资产在数字化世界里流转，可信数据的“存力”将如同电力网络的承载力一样重要。</p><p></p><p>本文希望通过对 LETUS 的深入技术解读，回答读者们普遍关心的关键问题：LETUS 是什么？主要解决哪些问题？为什么坚持用“可验证结构”？为什么要自研？以及未来要走向何处？</p><p></p><h3>背景是什么？</h3><p></p><p></p><p>从 2009 年序号为 0 的创世块诞生至今已过去十多年，“中本聪”依然神秘，但区块链技术的发展却因为公链、token、开源的推动，没有丝毫神秘感。</p><p></p><p>经过几代技术演进，在比特币的 UTXO 模型基础上诞生了应用更为广泛、支持可编程智能合约的区块链技术：通过密码学、共识算法、虚拟机、可信存储等技术，多个参与方执行相同的“指令”，来完成同一个业务逻辑，如账户转账，或者合约调用，维护不可篡改和不可伪造的业务数据。</p><p></p><p>简单讲，可将这类账本数据库，看作一个去中心化防作恶、防篡改的复制状态机，所执行的是智能合约描述的业务逻辑，而状态机通过日志 (区块数据）产生新的状态（状态数据）：</p><p></p><p>区块数据：包括交易、回执、世界状态 Root Hash 等信息，和数据库系统中的日志类似，但是块之间由 Hash 锚定防篡改，并且不会删除。（区块数据记录的是区块链上发生的每一笔交易，如：Alice 向 Bob 转账 xx）</p><p></p><p>状态数据：记录账户、资产、业务合约数据等状态信息，和数据库系统中表数据类似，需要实现可验证可追溯。（状态数据记录的是区块链上每个账户或智能合约的当前状态，如：Bob 账户剩余 xx）</p><p></p><p>链上数据的特点可以总结为以下三个：</p><p></p><p>持续增长：从创世块开始，账本数据随交易持续增长，保留周期长；</p><p></p><p>多版本：交易修改状态数据产生新版本，系统提供历史版本查询和验证功能；</p><p></p><p>可验证：交易和账户状态通过 Merkle 根哈希（Merkle Root Hash）锚定在区块头，通过 SPV（simple payment verification，简单支付证明）提供存在性证明；</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ac/aca3339ae8b6b7e66ce54267b795e30e\" /></p><p></p><p>区块链应用通过可验证数据结构（Authenticated Data Structure，如 Merkle tree）实现可验证和可追溯。我们认为，Web3“存力”一个非常重要的要素是可验证，而今天我们看到的区块链存储瓶颈大多来源于可验证结构 ADS（如 Merkle tree）的低效存取和查询，这正是蚂蚁链 LETUS 重点攻克的难题。</p><p></p><h2>我们要什么？</h2><p></p><p></p><p>随着时间推移和链上交易的增加，对存储容量的要求也不断增长，随之而来的是区块数据存储成本的大幅提升；与此同时，链上状态数据规模也持续增加，可验证数据结构持续膨胀，导致交易性能随账户规模提升和历史状态数据增加而持续下降。</p><p></p><p>2019 年，蚂蚁链上线了一个供应链金融业务，大家特别兴奋。但是，这种兴奋并没有维持多久，随着程序跑的时间越来越长，问题慢慢暴露出来。</p><p></p><p>供应链金融是面向 ToB 的，不像 ToC 端随时都有数据，可能会在某个时刻（比如每天晚上）有一笔状态数据非常大的交易进来，跑了一个星期后发现性能越来越慢。</p><p></p><p>链平台 TPS 的衰减和存储直接相关，而与共识、虚拟机都无关，随着业务合约持续写入数据，存储性能大幅衰减。</p><p></p><p>如果要在技术上长时间支持亿级账户规模、每天能稳定支撑亿级交易量，存储的规模和性能问题必须要攻克。</p><p></p><p>期间，团队也曾试过各种技术方法对他进行优化，得到一些缓解。但多次尝试之后发现，随着数量增加而出现的性能衰减，是一个绕不开的瓶颈，需要从本质上解决。</p><p></p><p>我们需要从问题表象分析背后的原因。</p><p></p><p>区块链应用通过可验证数据结构实现可验证和可追溯，但是可验证数据结构会带来读写放大（问题 1）和数据局部性（问题 2）。</p><p></p><p>而存储系统为了实现数据管理，需要对数据分页 / 分层、排序，如 KV 数据库基于 LSM-tree 将数据分层有序存储，而 MySQL 之类的数据库将数据分页，也会基于 B-tree 数据结构来排序索引。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ed/ed3ba1385d8e84b7e38fb857308689d4\" /></p><p></p><p>业界现有的实现方式，大多采用基于 LSM 架构的通用 Key-Value 数据库，在数据库之上运行一个独立 Merkle 树来实现可验证，如：</p><p></p><p>以太坊：MPT(Merkle Patricia &nbsp;Tree)+LevelDB</p><p></p><p>Diem：JMT(Jellyfish Merkle Tree)+RocksDB</p><p></p><p>背后的核心矛盾为：</p><p></p><p>Merkle 树每次状态数据修改，即使只改一个 KV，也需要从叶子节点到根节点，每一层节点都重新编码后，写到 KV 数据库，例如上图中 Alice 给 Bob 转账，需要写入 Merkle 树的 2 个叶子节点和 3 个中间节点，最坏情况需要写入数十个中间节点；</p><p></p><p>Merkle 树的节点的 key 完全随机 (如对内容算 hash，再以 hash 为 key)，数据局部性（data locality）非常不友好，如 RocksDB 里为了让 Level 内 sst 文件有序，即使没有垃圾依然需要层层进行数据压实（compaction），从而消耗了大部分的磁盘读写带宽；</p><p></p><p>数据规模越大，Merkle 树本身的层数越多，需要额外写入的 key-value 越多，DB 里的数据量越多，后台数据管理的代价越大（如 compaction 流量），消耗大量的磁盘和 CPU 资源。</p><p></p><p>除此之外，吞吐、延时等存储性能（问题 3）、持续增长下的存储成本（问题 4）、单机存储下的规模瓶颈（问题 5）也都是需要解决的问题。</p><p></p><h2>面临什么挑战？</h2><p></p><p></p><p>在过去几年的快速发展中，区块链的业务场景对交易吞吐量和响应时间要求越来越高，很多技术也被推动迭代发展，如 PBFT、HoneyBadger、MyTumbler 等高性能共识算法，BTN 等网络基础设施，JIT 加持的 WASM 虚拟机、以及高效的并行执行技术。</p><p></p><p>但比较而言，存储的性能对区块链平台整体性能影响非常大。对面向 2C 场景的数字藏品类业务（如鲸探，需支持秒杀），交易 TPS 与延时要求极为苛刻；而对需要在链上保存大量数据的存证类业务，大容量存储带来的成本又十分可观。</p><p></p><p>要支撑业务的长期可持续发展，我们归纳出区块链存储面临的核心挑战：</p><p></p><p>规模：业务账户规模可达数 10 亿，状态数据和历史版本规模分别需要支撑到十亿、千亿级；</p><p></p><p>性能：转账交易需求可达十万级 TPS、百毫秒级延时，要求性能不能受制于单机瓶颈，数据规模持续增长下性能不衰减；</p><p></p><p>成本：随着交易增长，存储容量持续增加，存储空间占用、节点间带宽占用居高不下。业务持续增长要求低成本存储。</p><p></p><p>这些问题在行业内很普遍。业界技术路线主要分三条：</p><p></p><p>路线 A：弱化可验证可追溯，如 HyperLedger Fabric 1.0 开始不支持可验证和多版本，保存读写集、只持久化最新版本状态数据；</p><p></p><p>路线 B：优化 KV 数据库存储，如实现键值分离、hash 索引的 KV 数据库等 (BadgerDB、ParityDB)，接入通用分布式数据库 (MySQL) 等；</p><p></p><p>路线 C：优化 Merkle 树，交易 ID 作为版本、树结构稀疏化，如 Diem JMT。</p><p></p><p>根据公开信息，目前区块链产品中主流的 MPT + LevelDB、JMT + RocksDB、MySQL 等存储架构，没有能全部解决上述 5 个问题的方案，难以在支持多版本和可验证的同时，满足 10 亿级账户规模下的高性能、易扩展、低成本的业务要求。</p><p></p><h2>我们做到了什么？</h2><p></p><p></p><p>我们自研了一套区块链存储引擎 LETUS(Log-structured Efficient Trusted Universal Storage)，保证完整的可验证、多版本能力，既满足区块数据不可篡改、可追溯、可验证等要求，也提供对合约数据友好访问、存储规模可分片扩展，高性能低成本等特性。同时也满足通用性，统一管理区块数据、状态数据。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/16/16f4996a2c66203f6eae5c2c61a74f22\" /></p><p></p><p>4 年前不敢想象的能力现在具备了（以下数据为统一环境下的测试结果）</p><p></p><p>大规模：通过存储集群扩展支持十亿账户规模，TPS 超过 12 万，交易平均时延低于 150ms；高性能：存储层 IO 吞吐相比以太坊 MPT + LevelDB 等架构提升 10~20 倍，IO 延迟降低 90% 以上。链平台在 7x24 高压力压测中，端到端 TPS 不随数据量增加而衰减；低成本：相比 MPT + LevelDB 架构，磁盘带宽减少 95%、空间占用减少 60%；相比于 Diem JMT + RocksDB 架构，磁盘带宽减少约 60%、空间占用降低约 40%；进一步降成本方案，供用户选用：</p><p>a. 针对区块数据容量与成本持续增长，提供智能控温分层存储能力，并应用于存证等业务降低约 70% 存储成本，同时也降低运维成本。</p><p>b. 针对状态数据的历史版本容量与成本持续增长，提供范围扫描的批量裁剪能力，实现历史版本状态数据的裁剪和后台空间回收，在十亿账户规模时，使用链原生存储可以减少近 90% 状态存储空间。</p><p></p><p>但这背后是一个技术架构的跨越，从下图左边的可验证数据结构 +KV 数据库架构，升级为现在的 LETUS 存储引擎，架构更简洁，系统更高效。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d6/d6f36bc6f97a77af1727cc47c80c8e99\" /></p><p></p><p>如 Alice 给 Bob 转账，只需要写增量数据，不需要写入 7 个 Merkle 树节点，数据局部性更友好，如 Alice 和 Bob 的账户数据，按区块号有序，不再 hash 随机。</p><p></p><h2>怎么做到的？</h2><p></p><p></p><p>图片回顾这四年，主要经历的三个大的阶段。</p><p></p><h3>阶段一：开源思路优化</h3><p></p><p></p><p>第一年里，为了满足业务急迫诉求，我们需要在有限时间内，实现亿级账户规模和交易 TPS。先从已有系统入手，深度优化了状态树，基于开源 MPT 到自研 FDMT，同时调优 RocksDB 数据库、增加并发、提升介质性能。</p><p></p><p>一系列优化措施缓解了问题，但依然无法根本解决，例如数据规模增加后，写放大依然有几十倍，数据在底层存储里依然随机分布。</p><p></p><h3>阶段二：自研存储引擎</h3><p></p><p></p><p>为了能彻底解决上述所有问题，我们不得不重新思考存储引擎的设计。</p><p></p><h4>核心设计</h4><p></p><p></p><p>针对读写放大（问题 1）、数据局部性（问题 2）和性能（问题 3），我们结合区块链特征，如可验证数据结构的读写行为、链上数据的多版本诉求、只追加和不可篡改等，重新设计存储引擎的架构分层、关键组件、索引数据结构：</p><p></p><p>根据区块链特征，我们根据可验证数据结构的读写行为、链上数据的多版本诉求，重新设计存储引擎的架构分层、关键组件、索引数据结构：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/09/09d0649ac73a74f4ff866fc3616eaf7e\" /></p><p></p><p>将可验证特性下推到存储引擎内部，由内置的 Version-based（区块号）多版本 Merkle 树提供可验证可追溯，并且直接操作文件，从而缩短 IO 路径；</p><p></p><p>将可验证特性下推到存储引擎内部，由内置的 Version-based（区块号）多版本 Merkle 树提供可验证可追溯，并且直接操作文件，从而缩短 IO 路径；</p><p></p><p>多版本 Merkle 树的 Node 聚合为 page，提升磁盘友好性，page 存储采用 Delta-encoding 思想避免 in-place 更新（结合 Bw-tree 思路），状态数据修改时主要保存增量，定期保存基线，从而减少写放大，也减少了空间占用；</p><p></p><p>为 page 存储实现 Version-based 的存储与检索，索引 page 都按区块号有序写入、在索引文件里有序总局，核心数据结构为 B 树变种，从而实现有序数据 locality；</p><p></p><p>利用区块链场景数据的追加写、Immutable 特点，架构上采用 Log-Structured 思想，通过日志文件来组织数据；</p><p></p><p>数据与索引分离，数据按区块号有序写入数据文件，通过异步 IO、协程并发等提升系统并发度，索引多模，区块 &amp; 状态通用，除 Merkle 树支持状态数据，实现有序 B 树支持区块数据；</p><p></p><p>当前最新版本 Merkle 树优先在内存里缓存或者全部缓存，链上合约执行时，如果存在则直接读取，不需要访问 page 来重放，从而加速合约执行。</p><p></p><p>基于些核心设计，实现了成本降低的同时性能提升，链平台交易 TPS、延时等性能指标不会随着数据规模的提升而衰减。</p><p></p><p></p><h4>降成本</h4><p></p><p></p><p>虽然存储资源占用大幅降低后，但是链上数据依然面临持续增长带来的高成本问题（问题 4）。</p><p></p><p>基于 LETUS 架构的后台数据治理框架，我们能很方便的扩展实现数据迁移 / 压缩 / 垃圾回收等治理策略，基于这些策略，为用户提供进一步降成本能力，并针对自己的业务特点来选择使用：</p><p></p><p>（1）智能控温分层存储：存储介质按照性能、成本分层，通过智能控温调度数据在不同介质的分布量，将冷数据后台自动迁移到廉价介质（如 NAS），降低存储整体成本，并实现容量扩展，不受单盘空间限制。</p><p></p><p>（2）范围扫描的批量裁剪：对于历史版本 Merkle 树和状态对象，基于版本有序性与内置 Merkle 树，让用户可以指定目标区块号范围裁剪，通过 Page 边界扫描，批量索引与数据裁剪、垃圾回收实现存储空间释放，进一步降低状态数据成本。</p><p></p><h4>规模扩展</h4><p></p><p></p><p>针对问题 5，LETUS 采用分布式存储架构，实现单个共识参与方计算和存储分离，计算层和存储层可分别部署独立集群，通过高性能网络通讯框架进行数据读写访问。</p><p></p><p>为了对海量状态数据进行灵活的数据分片，并且保证各个区块链的参与方 hash 计算的一致性，将数据切片为 256 个最小存储单元（msu），并将一个或者多个 msu 构成一个状态数据分片（partition），将所有数据分片调度到多个物理机器。从而实现规模弹性扩展，解决了单机存储的容量瓶颈和带宽瓶颈。</p><p></p><h3>阶段三：生产落地</h3><p></p><p></p><p>为了全面落地铺开的同时让业务平稳运行，能够开着飞机换引擎，在这几年的研发过程里，我们充分准备、循序渐进的分阶段落地：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/27/27c805677fee7ad148ef5b842fc7467d\" /></p><p></p><p>2021 年 5 月，基于 LETUS 存储引擎的区块数据冷热分层，在版权存证业务灰度上线，存储成本降低 71%，解决容量瓶颈并降低运维成本。</p><p></p><p>2021 年 8 月，基于 LETUS 存储引擎的状态数据，在数字藏品平台“鲸探”双写灰度上线，并成功支撑秒杀场景；</p><p></p><p>2022 年 2-6 月，LETUS 引擎的历史状态数据裁剪、存储服务架构升级等生产 ready，在数字藏品和版权存证等业务全面落地，并从灰度双写切为单写；LETUS 单写意味着对硬件资源要求大幅下降，我们将“鲸探”生产环境的云资源全面降配，降配后链平台性能水位提升 200%，同时存储成本下降 75%。</p><p></p><h2>总结与展望</h2><p></p><p></p><p>蚂蚁一直坚持“成熟一个开放一个”的技术战略。同样的，LETUS 不只为蚂蚁链定制，也同样给其他联盟链、公链提供高性能、低成本的支持。</p><p></p><p>蚂蚁链坚持技术自研，确保在共识协议、智能合约、网络传输、存储引擎、跨链技术、区块链隐私计算等领域处于全球领先水平。我们始终认为，坚持技术自主研发是建立长期可持续竞争力的关键。</p><p></p><p>在“可信存力”这条赛道上，我们也需要为进一步的技术壁垒提前布局，如合约结构化查询语言，为链上合约实现结构化 + 可验证的查询能力, 提升开发者体验；Fast-Sync 与节点多形态，提升组网效率和节点成本灵活性；以及 Web3 等潜在的技术生态。</p><p></p><p>技术创新永远在路上。接下来，继续沿着硬核技术方向突破，啃一些硬骨头，持续为整个价值互联网提供可靠的、可持续的存力。</p>",
    "publish_time": "2022-12-01 12:36:33",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "OpenStack已死？最新报告显示OpenStack部署呈爆发式增长，整体规模超4000万",
    "url": "https://www.infoq.cn/article/xb600VAYhlzQcjuvAKeN",
    "summary": "<p></p><p>&nbsp;在业内人士质疑 <a href=\"https://www.infoq.cn/article/Z8p-Se31uh0NrLNHt5BT\">OpenStack</a>\"（世界第四大开源项目）是否已死之际，OpenInfra 基金会近日<a href=\"https://www.openstack.org/user-survey/2022-user-survey-report\">测得的数据</a>\"显示，生产中的 OpenStack 内核数量达到前所未有的 4000 万，同比 2021 年增长了 60%，自 2020 年以来增长了 166%。官方认为，该增长是对混合云环境和Kubernetes集成支持的依赖程度增加带来的。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/b5/b5a134634d339663547e432f0719e828.png\" /></p><p></p><p>&nbsp;OpenStack表示，各种规模的组织都在进行扩展来满足最终用户的需求。如LINE是日本的一款即时通讯服务，在日本每月有1.76亿活跃用户。他们的云由OpenStack提供支持，其内核数量增加到了400万个，比2021年增加了150%。Workday是一家基于云计算的财务管理、人力资本管理和学生信息系统软件供应商，今年其OpenStack内核数量再次翻了一番，达到284万个。据悉，全球超过300个数据中心由OpenStack 驱动的公有云支持。</p><p>&nbsp;</p><p>另外，作为 OpenInfra 标准，Linux OpenStack Kubernetes Infrastructure (LOKI) 正在以越来越快的速度在生产中实现。Kubernetes 现在集成在超过 85% 的 OpenStack 部署中：73% 通过 vanilla Kubernetes，另外 12% 通过 Red Hat 的Kubernetes 发行版<a href=\"https://xie.infoq.cn/article/d6672373174b4a0ee3288127a\">OpenShift</a>\"。</p><p>&nbsp;</p><p>Red Hat 也是 OpenStack 的支持者。Red Hat 产品管理经理 Maria Bracho 表示：“在过去的几年里，越来越多的客户在不同的部署模型中同时使用 OpenStack 和 OpenShift。在 Red Hat，我们做了大量的工作来确保这些平台可以一起使用，用户不需要在一个平台或另一个平台之间做出选择，而是可以自由、坚定地选择最适合当前和未来工作负载的配置。”&nbsp;</p><p>&nbsp;</p><p>OpenStack 和 Kubernetes 生产集成的增长进一步体现在，使用 Magnum（用于容器编排的 OpenStack 服务）运行生产工作负载的用户增加到 21%（去年仅为 16%）。</p><p>&nbsp;</p><p>OpenStack 通常用于混合云。根据 Flexera 报告，80% 的受访者正在采取公有云和私有云同时使用的混合云策略。这一趋势也反映在了 OpenStack 的用户调查中：运行混合云环境和 OpenStack 部署的受访者从 77% 上升到 80%。</p><p>&nbsp;</p><p>Octavia的采用率增加，为越来越多部署了OpenStack的混合云环境提供支持。为了实现工作负载在不同云环境之间的平稳过渡，越来越多的运营商转向使用开源的负载均衡方案 Octavia， Octavia 可以与 OpenStack 配合使用。几乎一半的生产部署都在使用 Octavia，比去年增加了 11%。</p><p>&nbsp;</p><p>OpenInfra 基金会总经理 Thierry Carrez&nbsp;表示，“随着OpenStack部署以惊人的数量持续增长，OpenStack社区正在证明它不仅活得很好，还为组织提供了无可争辩的价值。”</p>",
    "publish_time": "2022-12-01 12:42:09",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "云基础设施性能再提升！re:Invent Day1 重大发布一览",
    "url": "https://www.infoq.cn/article/CLHBFwbSNzSYG4PhYeZH",
    "summary": "<p>re:Invent Day1 ，亚马逊云科技高级副总裁 Peter DeSantis 带来以云性能为核心的多项重要发布！一场开发者们的聚会还在继续～</p>",
    "publish_time": "2022-12-01 12:42:42",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]