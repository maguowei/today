[
  {
    "title": "龙蜥社区开源 coolbpf技术实践",
    "url": "https://www.infoq.cn/article/IielSpCwjf6Owd6jMBef",
    "summary": "<p></p><h2>引言</h2><p></p><p></p><p>BPF 是一个新的动态跟踪技术，目前这项技术正在深刻的影响着我们的生产和生活。BPF 在四大应用场景发挥着巨大作用：</p><p></p><p>系统故障诊断：它可以动态插桩透视内核。网络性能优化：它可以对接收和发送的网络包做修改和转发。系统安全：它可以监控文件打开和关闭从而做出安全决策等。性能监控：它可以查看函数耗费时间从而知道性能瓶颈点。</p><p></p><p>BPF 技术也是随着 Linux 内核的发展而发展的，Linux 内核版本经历了 3.x 向 4.x 到 5.x 演进，eBPF 技术的支持也是从 4.x 开始更加完善起来，特别是 5.x 内核也增加了非常多的高级特性。但是云上服务器有大量的 3.10 内核版本是不支持 eBPF 的，为了让我们现有的 eBPF 工具在这些存量机器得以运行，我们移植了 BPF 到低版本内核，同时基于 libbpf 的 CO-RE 能力，保证一个工具可运行在 3.x/4.x/5.x 的低、中、高内核版本。</p><p></p><p>BPF 的开发方式有很多，当前比较热门的有：</p><p></p><p>1）纯 libbpf 应用开发：借助 libbpf 库加载 BPF 程序到内核的方式：这种开发方式不仅效率低，没有基础库封装，所有必备步骤和基础函数都需要自己摸索。</p><p></p><p>2）借助 BCC等开源项目：开发效率高、可移植性好，并且支持动态修改内核部分代码，非常灵活。但存在部署依赖 Clang/LLVM 等库； 每次运行都要执行 Clang/LLVM 编译，严重消耗 CPU、内存等资源，容易与其它服务争抢。</p><p></p><p>coolbpf 项目，以 CO-RE（Compile Once-Run Everywhere）为基础实现，保留了资源占用低、可移植性强等优点，还融合了 BCC 动态编译的特性，适合在生产环境批量部署所开发的应用。coolbpf 开创了一个新的思路，利用远程编译的思想，把用户的BPF程序推送到远端的服务器并返回给用户.o或.so，提供高级语言如 Python/Rust/Go/C 等进行加载，然后在全量内核版本安全运行。用户只需专注自己的功能开发，不用关心底层库（如 LLVM、python 等）安装、环境搭建，给广大 BPF 爱好者提供一种新的探索和实践。</p><p></p><h2>一、BPF 开发方式对比</h2><p></p><p></p><p>BPF 经历了传统的 setsockopt 方式的 sock filter 报文过滤，到如今使用 libbpf CO-RE 方式进行监控和诊断功能的开发，是和 eBPF 与硬件紧密结合的优秀的指令集能力及 libbpf 通用库的开源开放分不开的，让我们一同回顾一下 BPF 的开发方式，并在此基础上推出基于远程编译思想为核心的 coolbpf，它站在了巨人的肩膀上，进行了资源优化、简洁编程和效率提升。</p><p></p><h4>1、原始阶段</h4><p></p><p></p><p>在 BPF 还叫伯克利报文过滤(cBPF)的时候，它通过 sock filter 将原始的 BPF 指令码，利用 setsockopt 加载到内核，通过 setsockopt 加载到内核，通过在 packet_rcv 调用 runfilter 运行这段程序来进行报文过滤。这种方式，BPF 字节码的生成非常原始，类似于手工编写汇编程序，过程是非常痛苦的。</p><p></p><p><code lang=\"python\">static struct sock_filter filter[6] = {\n { OP_LDH, 0, 0, 12          }, // ldh [12]\n { OP_JEQ, 0, 2, ETH_P_IP    }, // jeq #0x800, L2, L5\n { OP_LDB, 0, 0, 23          }, // ldb [23]\n { OP_JEQ, 0, 1, IPPROTO_TCP }, // jeq #0x6, L4, L5\n { OP_RET, 0, 0, 0           }, // ret #0x0\n { OP_RET, 0, 0, -1,         }, // ret #0xffffffff\n};\nint main(int argc, char **argv)\n{\n…\n struct sock_fprog prog = { 6, filter };\n …\n sock = socket(AF_PACKET, SOCK_RAW, htons(ETH_P_ALL));\n …\n if (setsockopt(sock, SOL_SOCKET, SO_ATTACH_FILTER, &amp;prog, sizeof(prog))) {\n  return 1;\n }\n…\n }</code></p><p></p><h4>2、保守阶段</h4><p></p><p></p><p>例子为 samples/bpf 下面的 sockex1_kern.c 和 sockex1_user.c，代码分为两部分，通常命名为 xxx_kern.c 和 xxx_user.c，前者加载到内核空间中执行，后者在用户空间执行。BPF 程序编写完成后就通过 Clang/LLVM 进行编译，xxx_user.c 里显式的去加载生成的 xxx_kernel.o 文件。这种方式虽然使用了编译器支持自动生成了 BPF 字节码，但代码组织和 BPF 加载方式比较保守，用户需要写非常多的重复代码。</p><p></p><p><code lang=\"python\">struct {\n    __uint(type, BPF_MAP_TYPE_ARRAY);\n    __type(key, u32);\n    __type(value, long);\n    __uint(max_entries, 256);\n} my_map SEC(\".maps\");\n\nSEC(\"socket1\")\nint bpf_prog1(struct __sk_buff *skb)\n{\n    int index = load_byte(skb, ETH_HLEN + offsetof(struct iphdr, protocol));\n    long *value;\n\n    if (skb-&gt;pkt_type != PACKET_OUTGOING)\n        return 0;\n\n    value = bpf_map_lookup_elem(&amp;my_map, &amp;index);\n    if (value)\n        __sync_fetch_and_add(value, skb-&gt;len);\n\n    return 0;\n}\nchar _license[] SEC(\"license\") = \"GPL\";</code></p><p></p><p><code lang=\"python\">int main(int ac, char **argv)\n{\n    struct bpf_object *obj;\n    struct bpf_program *prog;\n    int map_fd, prog_fd;\n    char filename[256];\n    int i, sock, err;\n    FILE *f;\n\n    snprintf(filename, sizeof(filename), \"%s_kern.o\", argv[0]);\n\n    obj = bpf_object__open_file(filename, NULL);\n    if (libbpf_get_error(obj))\n        return 1;\n\n    prog = bpf_object__next_program(obj, NULL);\n    bpf_program__set_type(prog, BPF_PROG_TYPE_SOCKET_FILTER);\n\n    err = bpf_object__load(obj);\n    if (err)\n        return 1;\n\n    prog_fd = bpf_program__fd(prog);\n    map_fd = bpf_object__find_map_fd_by_name(obj, \"my_map\");\n    ...\n }</code></p><p></p><h4>3、BCC 初始阶段</h4><p></p><p></p><p>BCC 的出现打破了保守的开发方式，出色的运行时编译和基础库封装能力，极大的降低了开发难度，有了不少迷妹，然后开始攻城略地，类似资本的快速扩张。用户只需要在 Python 程序里 attach 一段 prog ，然后进行数据分析和处理，缺点是必须在生产环境上安装 Clang 和 python 库，运行时有 CPU 资源瞬时冲高，导致出现加载 BPF 程序后问题不复现的可能。</p><p></p><p><code lang=\"python\">int trace_connect_v4_entry(struct pt_regs *ctx, struct sock *sk)\n{\n  if (container_should_be_filtered()) {\n    return 0;\n  }\n\n  u64 pid = bpf_get_current_pid_tgid();\n  ##FILTER_PID##\n  u16 family = sk-&gt;__sk_common.skc_family;\n  ##FILTER_FAMILY##\n\n  // stash the sock ptr for lookup on return\n  connectsock.update(&amp;pid, &amp;sk);\n\n  return 0;\n}</code></p><p></p><p><code lang=\"python\"># initialize BPF\nb = BPF(text=bpf_text)\nif args.ipv4:\n    b.attach_kprobe(event=\"tcp_v4_connect\", fn_name=\"trace_connect_v4_entry\")\n    b.attach_kretprobe(event=\"tcp_v4_connect\", fn_name=\"trace_connect_v4_return\")\nb.attach_kprobe(event=\"tcp_close\", fn_name=\"trace_close_entry\")\nb.attach_kretprobe(event=\"inet_csk_accept\", fn_name=\"trace_accept_return\")</code></p><p></p><h4>4、BCC 高级阶段</h4><p></p><p></p><p>BCC 风靡一时，俘获了不少开发者。由于时代在进步，需求也在变。libbpf 横空出世及 CO-RE 思想盛行，BCC 自己也在变革，开始借助 BTF 的方式支持重定位，希望同一套程序在任何 Linux 系统都能顺利运行。然而，有些结构体在不同内核版本上，或者成员名字变了、或者成员的含义变了（从微秒变成了毫秒），这种方式就需要程序处理。在 4.x 等中版本内核上，还需要通过 debuginfo 生成独立的 BTF 文件，过程还是相当复杂。</p><p></p><p><code lang=\"python\">SEC(\"kprobe/inet_listen\")\nint BPF_KPROBE(inet_listen_entry, struct socket *sock, int backlog)\n{\n    __u64 pid_tgid = bpf_get_current_pid_tgid();\n    __u32 pid = pid_tgid &gt;&gt; 32;\n    __u32 tid = (__u32)pid_tgid;\n    struct event event = {};\n\n    if (target_pid &amp;&amp; target_pid != pid)\n        return 0;\n\n    fill_event(&amp;event, sock);\n    event.pid = pid;\n    event.backlog = backlog;\n    bpf_map_update_elem(&amp;values, &amp;tid, &amp;event, BPF_ANY);\n    return 0;\n}</code></p><p></p><p><code lang=\"python\">#include \"solisten.skel.h\"\n...\nint main(int argc, char **argv)\n{\n    ...\n    libbpf_set_strict_mode(LIBBPF_STRICT_ALL);\n    libbpf_set_print(libbpf_print_fn);\n\n    obj = solisten_bpf__open();\n    obj-&gt;rodata-&gt;target_pid = target_pid;\n    err = solisten_bpf__load(obj);\n    err = solisten_bpf__attach(obj);\n    pb = perf_buffer__new(bpf_map__fd(obj-&gt;maps.events), PERF_BUFFER_PAGES,\n                  handle_event, handle_lost_events, NULL, NULL);\n    ...\n}</code></p><p></p><h4>5、资源共享阶段</h4><p></p><p></p><p>BCC 虽然也支持了 CO-RE，但是仍然存在代码相对固定，无法动态配置的问题，同时还需要搭建编译工程。coolbpf 把编译资源放到一台服务器上，提供远程编译能力，大家共享远程服务器资源，只需要把 bpf.c 推送到远端服务器，这台服务器会开动马达，加速输出 .o 和 .so。不管用户使用 Python 还是 Go 语言、Rust 或 C 语言，只需要在程序 ini t的时候加载这些 .o 或 .so 就可以把 BPF 程序 attach 到内核的hook 点，然后专注于处理来自 BPF 程序输出的信息，进行功能开发。</p><p></p><p>coolbpf 把 BTF 制作、代码编译、数据处理、功能测试集一身，生产效率大幅提升，使BPF 开发进入一个更优雅境界：</p><p></p><p>开箱即用：内核侧仅提供 bpf.c 即可，完全剥离出内核编译工程。复用编译成果：本地侧无编译过程，不存在库依赖和 CPU、内存等资源消耗问题。自适应不同版本差异：更适合在集群多个不同内核版本共存的场景。</p><p></p><p><code lang=\"python\">先在本地安装coolbpf，里面带的命令会把xx.bpf.c发送到编译服务器编译。\npip install coolbpf\n\n...\nimport time\nfrom pylcc.lbcBase import ClbcBase\n\nbpfPog = r\"\"\"\n#include \"lbc.h\"\n\nSEC(\"kprobe/wake_up_new_task\")\nint j_wake_up_new_task(struct pt_regs *ctx)\n{\nstruct task_struct* parent = (struct task_struct *)PT_REGS_PARM1(ctx);\n\nbpf_printk(\"hello lcc, parent: %d\\n\", _(parent-&gt;tgid));\nreturn 0;\n}\n\nchar _license[] SEC(\"license\") = \"GPL\";\n\"\"\"\n\nclass Chello(ClbcBase):\n    def __init__(self):\n        super(Chello, self).__init__(\"hello\", bpf_str=bpfPog)\n        while True:\n            time.sleep(1)\n            \n            if __name__ == \"__main__\":\n                hello = Chello()\n    pass</code></p><p></p><h2>二、coolbpf 功能及架构</h2><p></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/14/d7/140274599a4c750e6b60d06aec1c82d7.jpg\" /></p><p></p><p>前面分析了 BPF 的开发方式，coolbpf 借助远程编译把开发和编译这个过程进一步优化，总结一下它当前包含的 6 大功能：</p><p></p><p>1）本地编译服务，基础库封装：客户使用本地容器镜像编译程序，调用封装的通用函数库简化程序编写和数据处理。</p><p></p><p>本地编译服务，把同样的库和常用工具放在容器镜像里，编译时直接到容器里面编译。我们使用如下镜像进行编译，用户也可以通过 docker 自己搭建容器镜像。</p><p></p><p></p><blockquote>容器镜像：registry.cn-hangzhou.aliyuncs.com/alinux/coolbpf:latest</blockquote><p></p><p></p><p>用户可以 pull 这个镜像进行本地编译，一些常用的库和工具，通过我们提供的镜像就已经包含在里面，省去了构建环境的繁杂。</p><p></p><p>2）远程编译服务：接收 bpf.c，生成 bpf.so 或 bpf.o，提供给高级语言进行加载，用户只专注自己的功能开发，不用关心底层库安装、环境搭建。</p><p></p><p>远程编译服务，目前用户开发代码时只需要 pip install coolbpf，程序就会自动到我们的编译服务器进行编译。你也可以参考 compile/remote-compile/lbc/ 自己搭建编译服务器（我们后面会陆续开源这个编译服务器源码），过程可能会比较复杂。这样搭建好的服务器，你可以个人使用或者在公司提供给大家一起使用。</p><p></p><p>3）高版本特性通过 kernel module 方式补齐到低版本，如 ring buffer 特性，backport BPF 特性到 3.10 内核。</p><p></p><p>由于存量 3.10 内核的服务器依然很多，为了让同一个 BPF 程序也能运行在低版本内核，为了维护方便且不用修改程序代码，只需要 install 一个 ko，就可以支持 BPF，让低版本也享受到了 BPF 的红利。</p><p></p><p>4）BTF 的自动生成和全网最新内核版本爬虫。自动发现最新的 CentOS、ubuntu、Anolis 等内核版本，自动生成对应的 BTF。</p><p></p><p>要具备一次编译多处运行 CO-RE 能力，没有 BTF 是行不通的。coolbpf 不仅提供一个制作 BTF 的工具，还会自动发现和制作最新内核版本的 BTF，以供大家下载和使用。</p><p></p><p>5）各内核版本功能测试自动化，工具编写后自动进行安装测试，保障用户功能在生产环境运行前预测试。</p><p></p><p>没有上线运行过的BPF程序和工具，一定概率上是存在风险的。coolbpf提供一套自动化测试流程，在大部分内核环境都预先进行基本的功能测试，保证工具真正运行在生产环境时不会出大问题。</p><p></p><p>6）Python、Rust、Go、C 等高级语言支持。</p><p></p><p>目前 coolbpf 项目支持使用 Python、Rust、Go 及 C 语言的用户程序开发，不同语言开发者都能在自己最擅长的领域发挥最大的优势。</p><p></p><p>总之，coolbpf 使得 BPF 程序和应用程序开发在一个平台上闭环解决了，有效提升了生产力，覆盖了当前主流的开发语言，适合更多的 BPF 爱好者入门学习，也适合系统运维人员高效开发监控和诊断程序。</p><p></p><p>下图为 coolbpf 的功能和工具支持情况，欢迎更多优秀 BPF 工具加入：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/91/bc/91040f6b42f064cb0a09668c0c45c2bc.jpg\" /></p><p></p><h2>三、实践说明</h2><p></p><p></p><p>coolbpf 目前包含 pylcc、rlcc、golcc 和 clcc，以及 glcc 子目录，分别是高级语言Python、Rust 和 Go 语言支持远程和本地编译的能力，glcc（g 代表 generic)是通过将高版本的 BPF 特性移植到低版本，通过 kernel module 的方式在低版本上运行。下面我们分别简单介绍它的使用。</p><p></p><h4>1、pylcc(基于 Python 的 LCC）</h4><p></p><p></p><p>pylcc 在 libbpf 基础上进行封装，将复杂的编译工程交由容器执行。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/eb/53/eba903bf5eab7f5ff0c3e87022424353.jpg\" /></p><p></p><p>代码编写非常简洁，只需要三步就能完成，pyLCC 技术关键点：</p><p></p><p>1）执行 pip install coolbpf 安装</p><p></p><p>2）xx.bpf.c 的编写:</p><p></p><p><code lang=\"python\">bpfPog = r\"\"\" \n#include \"lbc.h\"\nLBC_PERF_OUTPUT(e_out, struct data_t, 128);\nLBC_HASH(pid_cnt, u32, u32, 1024);\nLBC_STACK(call_stack,32);</code></p><p></p><p>3）xx.py 编写，只需要这一步，程序就可以运行起来。用户关注从内核收到的数据进行分析就可以:</p><p></p><p><code lang=\"python\">importtimefrompylcc.lbcBaseimportClbcBase\nclassPingtrace(ClbcBase):def__init__(self):super(Pingtrace, self).__init__(\"pingtrace\")</code></p><p></p><p>bpf.c 里需要主动包含 lbc.h，它告知远程服务器的行为，本地不需要有这个文件。其内容如下：</p><p></p><p><code lang=\"python\">#include \"vmlinux.h\"\n#include \n#include \n#include \n#include </code></p><p></p><h4>2、rlcc(基于 Rust 的 LCC）</h4><p></p><p></p><p>Rust 语言支持远程编译和本地编译的能力。通过在 makefile 中使用 coolbpf 的命令把 bpf.c 发送到服务端，服务端返回 .o，这个与 Python 和 C 返回 .so 有很大区别，Rust 自己处理通用的 load、attach 的过程。其他类似于 Python 的开发，不再赘述。</p><p></p><p><code lang=\"python\">编译example流程:\nSKEL_RS=1 cargo build --release 生成 rust skel 文件;\nSKEL_RS=0 cargo build --release 无需在生成 rust skel 文件;\n默认 SKEL_RS 为 1.\n\n编译rexample流程:\nrexample 使用了远程编译功能，具体编译流程如下:\n运行命令 mkdir build &amp; cd build 创建编译目录;\n运行命令 cmake .. 生成 Makefile 文件;\n运行命令 make rexample;\n运行 example 程序: ../lcc/rlcc/rexample/target/release/rexample.</code></p><p></p><p><code lang=\"python\">fn main() -&gt; Result&lt;()&gt;{\n    let opts = Command::from_args();\n    let mut skel_builder = ExampleSkelBuilder::default();\n    if opts.verbose {\n        skel_builder.obj_builder.debug(true);\n    }\n    \n    bump_memlock_rlimit()?;\n    let mut open_skel = skel_builder.open()?;\n    \n    let mut skel = open_skel.load()?;\n    skel.attach()?;\n    let perf = PerfBufferBuilder::new(skel.maps_mut().events())\n    .sample_cb(handle_event)\n    .lost_cb(handle_lost_events)\n    .build()?;\n    \n    loop {\n        perf.poll(Duration::from_millis(100))?;\n    }\n}</code></p><p></p><h4>3、glcc(generic LCC，高版本特性移植到低版本)</h4><p></p><p></p><p>背景：</p><p></p><p>目前基于 eBPF 编写的程序只能在高版本内核（支持 eBPF 的内核）上运行，无法在不支持 eBPF 功能的内核上运行。线上有很多 Alios 或者 CentOS 低版本内核需要维护。存量 BPF 工具或项目代码，希望不做修改能跨内核运行。</p><p></p><p>为此我们提出了一种在低版本内核运行 eBPF 程序的方法，使得二进制程序无需任何修改即可在不支持 BPF 的内核上运行。</p><p></p><p>下面从架构上梳理，低版本内核运行 BPF 的可能。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/8d/3d/8da350a7f5ea80e2b62f10fd81b2393d.jpg\" /></p><p></p><p>Hook 是一个动态库，由于低版本内核不支持 bpf() 的系统调用，原来在用户态创建 map、创建 prog 以及很多 helper 函数（如 bpf_update_elem 等）将不能运行，Hook 提供一个动态机制，把这些系统调用转成 ioctl 命令，设置到一个叫 ebpfdriver 的 kernel module，通过他进行创建一些数据结构模拟 map 和 prog，同时注册 kprobe 和 tracepoint 的 handler。这样有数据到来时，就会运行注册在 kprobe 和 tracepoint 的回调。</p><p></p><p>运行机制见下图：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/da/9d/da9320dfce5e266b35106fd9c4e0e99d.jpg\" /></p><p></p><p>利用 Hook 程序将 BPF 的 syscall 转换成 ioctl 形式，将系统调用参数传递给 eBPF 驱动，包含以下功能：</p><p></p><p><code lang=\"python\">#define IOCTL_BPF_MAP_CREATE _IOW(';', 0, union bpf_attr *)\n#define IOCTL_BPF_MAP_LOOKUP_ELEM _IOWR(';', 1, union bpf_attr *)\n#define IOCTL_BPF_MAP_UPDATE_ELEM _IOW(';', 2, union bpf_attr *)\n#define IOCTL_BPF_MAP_DELETE_ELEM _IOW(';', 3, union bpf_attr *)\n#define IOCTL_BPF_MAP_GET_NEXT_KEY _IOW(';', 4, union bpf_attr *)\n#define IOCTL_BPF_PROG_LOAD _IOW(';', 5, union bpf_attr *)\n#define IOCTL_BPF_PROG_ATTACH _IOW(';', 6, __u32)\n#define IOCTL_BPF_PROG_FUNCNAME _IOW(';', 7, char *)\n#define IOCTL_BPF_OBJ_GET_INFO_BY_FD _IOWR(';', 8, union bpf_attr *)</code></p><p></p><p>eBPF 驱动收到 Ioctl 请求，会根据 cmd 来进行相应的操作，如：</p><p>A. IOCTL_BPF_MAP_CREATE：创建map。B. IOCTL_BPF_PROG_LOAD：加载 eBPF 字节码，进行字节码的安全验证和 jit 生成机器码。C. IOCTL_BPF_PROG_ATTACH：将该eBPF程序attach到指定的内核函数，利用register_kprobe 和 tracepoint_probe_register 功能完成 eBPF 程序的 attach。</p><p></p><p>另外，高版本的一些特性，比如 ringbuff，也可以通过 ko 等方式用在低版本。像  clcc 和 golcc 的使用方式，请参考 coolbpf 的 github 链接（见文末），这里不在赘述。</p><p></p><h2>四、总结</h2><p></p><p></p><p>coolbpf 当前具备以上 6 大功能，其目的是简化开发和编译过程，让用户专注自己的功能开发，使得广大 BPF 爱好者快速入门，快速编写自己的功能程序而不用担心环境问题。今天我们把这套系统开源，让它服务更多人，以提升他们的生产力，促进社会进步，让更多人参与到这个项目建设中来，形成一股合力，突破一项技术。</p><p></p><p>我们的远程编译服务，解决的是生产力的效率问题；低版本的 BPF 支持，解决的是困扰各个开发者的同一个 bin 文件如何在多内核版本无差别运行的目的，同时也希望更多人参与进来共同提高，让云计算产业和企业服务的兄弟姐妹们全面享受到 BPF 技术的红利。</p><p></p><p>龙蜥社区系统运维 SIG（Special Interest Group）致力于打造一个集主机管理、配置部署、监控报警、异常诊断、安全审计等一系列功能的自动化运维平台，coolbpf 是社区的一个子项目，目标是提供一个编译和开发平台，解决 BPF 在不同系统平台的运行和生产效率提升问题。</p><p></p><p></p><blockquote>欢迎更多开发者加入系统运维 SIG:网址：https://openanolis.cn/sig/sysom邮件列表：sysom@lists.openanolis.cncoolbpf 链接：git@github.com:aliyun/coolbpf.git</blockquote><p></p>",
    "publish_time": "2022-07-04 10:27:46",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从货币到资产，数字货币/资产的架构设计",
    "url": "https://www.infoq.cn/article/uk3hK2z6Us8yvUj3fa5a",
    "summary": "<p>加密货币、稳定币、央行数字货币、资产代币化……数字货币究竟是什么？从货币到资产，架构如何设计？交易如何实现？对行业将产生哪些深远的影响？本次演讲将从金融行业的角度，分享区块链和数字货币技术对行业带来的影响，为你介绍现阶段常见的结构。</p>\n<p>另外，美的、微众银行、福特汽车等企业都来大会演讲啦，快来<a href=\"http://gk.link/a/11siC\">ArchSummit深圳站一睹为快～</a></p>",
    "publish_time": "2022-07-04 10:57:04",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "基于 LogMiner 和 Debezium 构建可用于生产实践的 Oracle 实时数据采集工具",
    "url": "https://www.infoq.cn/article/pGakNSLI9xUfEj9HtOlT",
    "summary": "<p>实时数据采集（又称为“变化数据捕获”Change Data Capture，下文又称CDC、实时抽数）在实时计算、跨库实时同步等领域具有极高的应用价值。相较于其他数据库，Oracle由于其闭源特性，目前缺乏免费且好用的解决方案。尽管Oracle提供了LogMiner接口且被以Debezium为代表的优秀开源方案所使用，但应用于生产实践时，Debezium相较于Oracle官方付费工具OGG，具有如下硬伤：</p><p></p><p>只能对主库CDC，无法用于ADG备库（参见<a href=\"https://issues.redhat.com/browse/DBZ-3866\">DBZ-3866</a>\"）。由于LogMiner的设计初衷为对Redo logs的诊断工具而非专门的CDC工具，故并未对持续运行进行任何效率、开销等优化，直接运用于主库势必会对主库业务正常运行造成影响。这对于应用Oracle的典型企业（银行、电信等要求高可靠性的公司）实则不可接受。抽取性能受限。按照<a href=\"https://www.oracle.com/a/ocom/docs/techpaper-goldengate-advantage-july2021.pdf\">Oracle官方的说法</a>\"，在每秒钟几百个事务时就会遇到较大的延迟和内存问题。Debezium框架由于其实现，实际解析速度比这个数值更低。</p><p></p><p>为此，笔者通过深入研究LogMiner原理和Debezium源码，在其基础上进行改进，使其真正可用于生产实践。</p><p></p><p>说明：笔者的实验环境为Oracle 11g和Debezium 1.5.4。但通过核对Oracle最新官方文档（21c）和Debezium最新源码（截至2022年6月21日最新版1.9.4），本文所涉及的方案对11g-21c的Oracle，以及Debezium1.5.4以上版本均适用（文中涉及到的Debezium源码均为1.5.4版本，非1.5.4版本的具体代码细节需根据文中原理自行定位）。限于篇幅本文对Debezium基础使用不做介绍，读者可参考<a href=\"https://debezium.io/documentation/reference/1.9/connectors/oracle.html\">官方文档</a>\"了解其基本配置和用法。</p><p></p><h2>一、LogMiner抽数的基本过程</h2><p></p><p>&nbsp;</p><p>限于篇幅仅简要介绍其五个基本步骤，详细说明可参阅<a href=\"https://docs.oracle.com/en/database/oracle/oracle-database/21/sutil/oracle-logminer-utility.html\">Oracle官方文档</a>\"：</p><p>1）构造字典文件：EXEC DBMS_LOGMNR_D.BUILD(OPTIONS=&gt; DBMS_LOGMNR_D.STORE_IN_REDO_LOGS);</p><p>2）添加Redo Logs：EXEC DBMS_LOGMNR.ADD_LOGFILE(LOGFILENAME =&gt; '/oracle/logs/log2.f', OPTIONS=&gt; DBMS_LOGMNR.ADDFILE);</p><p>3）开启LogMiner：EXEC DBMS_LOGMNR.START_LOGMNR(startScn =&gt; '..', endScn =&gt; '..');</p><p>4）查询V$LOGMNR_CONTENTS视图获取Redo信息并处理</p><p>5）查询当前的活跃Online Redo Log是否有变化，如果无变化则跳转到第3）步，如果有变化则关闭LogMiner（EXEC SYS.DBMS_LOGMNR.END_LOGMNR）并跳转回第1）步。</p><p></p><h2>二、ADG备库抽数原理</h2><p></p><p></p><p>为了介绍从ADG备库CDC方案，在此先对<a href=\"https://docs.oracle.com/en/database/oracle/oracle-database/21/admin/managing-the-redo-log.html\">Oracle对Redo Logs的管理</a>\"和<a href=\"https://www.oracle.com/a/tech/docs/adg-vs-storage-mirroring.pdf\">ADG的原理</a>\"简介如下：</p><p></p><p>Online Redo Logs记录Oracle中的一切变化信息，由至少2个（组）预分配的文件构成。LGWR（LoG WriteR）进程循环写入这些文件，每次仅往其中一个（组）Online Redo Log写入变化信息，每一条信息对应一个单调递增的SCN（System Change Number）。当该Online Redo Log写满，或者被显式调用ALTER SYSTEM SWITCH LOGFILE（强制切换Online Redo Log），或者写入时间超过ARCHIVE_LAG_TARGET参数值，则LGWR切换到下一个（组）Online Redo Log写入变化信息。同时，上一个（组）Online Redo Log会由归档进程ARCn将其内容写入新的Archived Redo Log。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4b/4bd895a244df6cc938ab7e10642bdbb3.png\" /></p><p>图源：<a href=\"https://docs.oracle.com/en/database/oracle/oracle-database/21/admin/managing-the-redo-log.html\">Oracle 官方文档</a>\"</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a2/a203f9c9d3ce8871dd8ce9250e7490e7.png\" /></p><p>图源：<a href=\"https://docs.oracle.com/en/database/oracle/oracle-database/21/admin/managing-the-redo-log.html\">Oracle 官方文档</a>\"</p><p></p><p>ADG为了保证同步效率，选择了仅仅同步恢复Oracle事务所需的信息（即Redo记录）。为了免受磁盘I/O状态影响，Redo记录在尚未落地至主库Online Redo Log文件时，即直接从内存中实时传送至备库，备库收到这些Redo信息后便将其实际应用于物理库中。备库中RFS（Remote File Server）进程负责将收到的Redo信息同步写入Standby Redo Logs。当主库发生Online Redo Log切换时，RFS进程同步进行Standby Redo Log切换，将新的Redo信息写入下一个（组）Standby Redo Log，并由归档进程ARCn将上一个（组）Standby Redo Log内容写入Archived Redo Log。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ec/ec304d2685db84bb614888a84ce84e74.png\" /></p><p>图源：《<a href=\"https://www.oracle.com/a/tech/docs/adg-vs-storage-mirroring.pdf\">Oracle Active Data Guard versus Storage Remote Mirroring</a>\"》</p><p></p><p>由上可知：</p><p>数据抽取时Online Redo Logs和Archived Redo Logs缺一不可。前者用于获取最新的实时数据，后者用于在抽取速度跟不上数据库变化速度时，保证能够无遗漏地获取所有变化数据。ADG备库中，Standby Redo Logs + Archived Redo Logs，具有和主库Online Redo Logs + Archived Redo Logs相同的内容。</p><p></p><h2>三、ADG备库抽数实践</h2><p></p><p></p><p>根据上述原理，我们可对LogMiner抽数步骤进行调整如下：</p><p></p><h3>1. 备库新建单独Oracle实例</h3><p></p><p></p><p>使用DBCA工具（推荐）或者CREATE DATABASE语句（参数复杂，不推荐）在ADG备库所在物理机新建单独的Oracle实例。假设新建的数据库服务名为logmnr，原备库的服务名为datadg。（后文将详述为什么需要新建logmnr库进行抽数而不是直接在datadg上抽数，以及为什么要在备库所在物理机上新建logmnr库）。后续的过程需关注每一步是在datadg实例上做，还是在logmnr实例上做。</p><p></p><h3>2. 创建平面（Flat）字典文件</h3><p></p><p></p><p>在datadg实例上，使用DBMS_LOGMNR_D.BUILD命令创建字典文件：</p><p>EXECUTE DBMS_LOGMNR_D.BUILD(DICTIONARY_LOCATION=&gt;'/home/oracle/logmnr', DICTIONARY_FILENAME=&gt;'dictionary.ora',OPTIONS=&gt; DBMS_LOGMNR_D.STORE_IN_FLAT_FILE);</p><p>注意自Oracle 12c起往后的版本，dictionary_location需替换为目录对象，具体参见官方文档说明。</p><p></p><h3>3. 筛选Standby Redo Logs和Archived Redo Logs。</h3><p></p><p></p><p>在datadg实例上筛选。Archived Redo Logs的筛选逻辑和Debezium框架内置实现相同，读者可直接参考io.debezium.connector.oracle.logminer.SqlUtils类中archiveLogsQuery方法实现。Standby Redo Logs的筛选逻辑如下（可参考<a href=\"https://docs.oracle.com/en/database/oracle/oracle-database/21/refrn/V-STANDBY_LOG.html\">V$STANDBY_LOG的字段说明</a>\"理解下述逻辑）：</p><p>SELECT MIN(F.MEMBER) AS FILE_NAME, L.LAST_CHANGE# AS LAST_CHANGE, F.GROUP#, L.FIRST_CHANGE# AS FIRST_CHANGE, 'CURRENT' as STATUS FROM V$STANDBY_LOG L, V$LOGFILE F WHERE F.GROUP# = L.GROUP# AND (L.ARCHIVED='NO' or L.STATUS='ACTIVE') GROUP BY F.GROUP#, L.LAST_CHANGE#, L.FIRST_CHANGE#, L.STATUS ORDER BY 3;</p><p></p><h3>4. DBMS_LOGMNR添加Redo Logs</h3><p></p><p></p><p>在logmnr实例上，使用DBMS_LOGMNR.ADD_LOGFILE添加第3）步所筛选出的Redo Logs。（注意：我们第1步中选择在ADG备库所在的物理机上创建新的Oracle实例，就是为了能使该实例能正常读取这些Redo Logs）</p><p></p><h3>5. DBMS_LOGMNR开启LogMiner</h3><p></p><p></p><p>在logmnr实例上，使用DBMS_LOGMNR.START_LOGMNR开启LogMiner，并查询V$LOGMNR_CONTENTS视图获取Redo信息并处理。</p><p></p><h3>6. 判断跳转步骤</h3><p></p><p></p><p>在datadg实例上，查询当前的活跃Standby Redo Logs是否有变化。无变化则循环执行第5步，否则关闭LogMiner（EXEC SYS.DBMS_LOGMNR.END_LOGMNR）并跳转到第2步。</p><p></p><h2>四、ADG备库抽数相关问题</h2><p></p><p></p><h3>1. 为什么需要新建单独的Oracle实例logmnr进行抽数？</h3><p></p><p></p><p>笔者尝试过直接在datadg上进行抽数（即上一章节的所有步骤均在datadg上执行），在执行到查询V$LOGMNR_CONTENTS步骤时，发现查询会卡死无法继续。</p><p>为此，笔者按照如下步骤开启Oracle 10046 Trace（SQL_TRACE）：</p><p>alter session set tracefile_identifier='10046';</p><p>alter session set timed_statistics = true;</p><p>alter session set statistics_level=all;</p><p>alter session set max_dump_file_size = unlimited;</p><p>alter session set events '10046 trace name context forever,level 12';</p><p></p><p>并重新将所有步骤在datadg中执行，执行到查询V$LOGMNR_CONTENTS步骤时，观察在Trace目录下（select value from v$diag_info where name='Diag Trace'），10046文件中会持续输出以下内容：</p><p></p><p>*** 2022-06-27 15:06:04.528</p><p>WAIT #139654617260408: nam='enq: WL - contention' ela= 30000095 name|mode=1464598531 log # / thread id #=2001421497 sequence #=972043434 obj#=-1 tim=1656313564528578</p><p>WAIT #139654617260408: nam='ARCH wait for archivelog lock' ela= 140 p1=0 p2=0 p3=0 obj#=-1 tim=1656313564528712</p><p>*** 2022-06-27 15:06:34.537</p><p>WAIT #139654617260408: nam='enq: WL - contention' ela= 30008500 name|mode=1464598531 log # / thread id #=2001421497 sequence #=972043434 obj#=-1 tim=1656313594537263</p><p>WAIT #139654617260408: nam='ARCH wait for archivelog lock' ela= 149 p1=0 p2=0 p3=0 obj#=-1 tim=1656313594537402</p><p></p><p>由于ADG备库中的相关进程对这些Redo Logs文件加锁处理，使得LogMiner进程无法同时对其进行操作。但由于这种加锁仅限于这些进程所在的Oracle实例（即datadg）而非该实例所在的操作系统（物理机），故在同一物理机上创建新的Oracle实例可解决该问题。</p><p></p><h3>2. 字典文件是做什么用的？为什么需要采用Flat File？</h3><p></p><p></p><p>字典文件用于将表名、字段名等元信息的物理表示转换为逻辑表示。如果在DBMS_LOGMNR.START_LOGMNR步骤中不指定字典文件，则得到的Redo SQL将会类似于下面这样：</p><p></p><p>update \"UNKNOWN\".\"OBJ# 1456235\" set \"COL 64\" = HEXTORAW('3330383339') where \"COL 1\" = HEXTORAW('313330323230313038333835383436') and ...... and ROWID = 'AAFjhrAA6AANcSoAAF';</p><p></p><p>Oracle提供了三种访问字典文件的方式：直接使用online catalog，将字典文件导出至Redo Log，将字典文件导出至Flat File（即单独的字典文件）。由于我们选择在单独的Oracle实例中抽数，无法获取online catalog，故只能选择第二种或第三种方式。尽管Oracle官方不推荐第三种方式（所以Debezium中并未内置支持），但该方式的效率实测比第二种高出不少（经笔者实测，采用第二种方法会将数据延迟由几秒钟放大至3-5分钟），且在我们的生产实践中并未观察到Oracle官方声称的不一致现象（因为生产系统鲜少有对存量表和字段的删除、插入等DDL操作），故推荐将字典文件存储于Flat File。</p><p></p><h2>五、提升Debezium框架抽数速度</h2><p></p><p></p><p>按照上文的原理和基本步骤，笔者对Debezium框架进行了修改，成功实现了对Oracle ADG备库的数据抽取。但又出现了新的问题：</p><p></p><p>抽取速度过低，实际发送至Kafka的速度仅为约60条/秒。对于大事务（譬如一个更新了几十万条记录的update语句）会报内存溢出，无法继续抽数。</p><p></p><p>形成该问题的原因有二：</p><p>l&nbsp; LogMiner的设计初衷为对Redo logs的诊断工具而非专门的CDC工具，故对抽取效率并未做优化。</p><p>l&nbsp; Debezium框架仅考虑到功能的正确实现，并未考虑到对抽取效率的调优。</p><p>据此，笔者通过排查程序运行堵点，采用分发器模式对源代码进行重构，并对部分逻辑进行优化，最终使大事务时的解析速度从原先的60条/秒提升至3000条/秒以上。</p><p></p><h3>1. Debezium解析V$LOGMNR_CONTENTS的过程</h3><p></p><p></p><p>V$LOGMNR_CONTENTS中记录了按照SCN顺序排列的变化信息。需要注意的是，对于DML类操作，变化信息是基于行的（譬如一个UPDATE语句更新了100条记录，那么LGWR进程会实际上往Redo Log中写入100条UPDATE语句，每条语句仅更新一行，V$LOGMNR_CONTENTS中也会实际上存储100条DML记录）。</p><p></p><p>Debezium在调用完毕DBMS_LOGMNR.START_LOGMNR后，依次进行如下操作：（详见io.debezium.connector.oracle.logminer包下LogMinerStreamingChangeEventSource和LogMinerQueryResultProcessor类）：</p><p></p><p>1）读取V$LOGMNR_CONTENTS并将结果记于ResultSet。</p><p>2）若ResultSet中仍有内容，读取新的记录并判断类型。</p><p>3）如果是DML操作，那么将操作内容暂存于Transaction中；如果是COMMIT操作，那么将Transaction暂存内容组装为Kafka Connect支持的格式并发送；如果是ROLLBACK操作，那么将Transaction暂存内容丢弃。</p><p>4）跳回第2）步继续执行，直到ResultSet全部内容读取结束。</p><p></p><p>需要注意的是，在Debezium中，以上过程全部为主线程串行执行。这种方式具有如下问题：</p><p></p><p>所有的操作均为单线程顺序执行，一方面单线程执行没有充分挖掘并发效率，另一方面，顺序执行将本地CPU密集操作（步骤2）-3））和数据库密集操作（步骤1））分开，造成资源的严重浪费。所有Redo记录顺序处理，无法预知当前处理的DML操作所对应的Transaction将要被COMMIT还是ROLLBACK，故无法将Redo信息直接发送至Kafka Connect，需多一步组装暂存的过程，不仅耗时还可能出现如下文所说的内存溢出的问题。</p><p></p><h3>2. 架构优化</h3><p></p><p></p><p>根据上节分析，笔者采用分发器模式，对Debezium整体框架进行了优化，下图为架构设计：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b4/b486e3e7ee7491ba2ccc15aba5495642.png\" /></p><p></p><p>对该架构说明如下：</p><p></p><p>1）Oracle对LogMiner做了非常严格的资源限制，每个Logminer进程资源消耗都不能超过1个CPU核心。因而当我们开启多个LogMiner进程同时挖掘时，可以观察到挖掘速度会有明显提升。但为了保证开启多进程后不影响Redo信息的处理顺序，我们需要维护一个SCN队列，代表每个START_LOGMNR操作的起始SCN。Redo信息分发器需要按照该顺序进行Redo信息分发。</p><p></p><p>每个LogMiner进程需要将查询V$LOGMNR_CONTENTS结果进行存储的原因，一是查询该视图的时间开销较大，不能直接让Redo信息分发器查询；二是暂存后LogMiner进程可以继续向后挖掘，不需要等待Redo信息分发器的后续处理。</p><p></p><p>2）Redo信息分发器按照SCN顺序，对每一条Redo信息，拿到Transaction ID后直接将其派发到Transaction处理线程池的对应Transaction线程。特别地，如果这条Redo信息操作类型为COMMIT，那么将对应Transaction线程的commitSCN置为该条信息的SCN，并且将该SCN加入CommitSCN队列；如果这条Redo信息操作类型为ROLLBACK，那么将对应Transaction线程的rollbackSignal置为1。</p><p></p><p>每个Transaction线程在处理信息时，如果rollbackSignal为1，那么直接结束处理过程；如果CommitSCN不为空且等于CommitSCN队头元素，则将当前解析完毕的信息直接发送至Kafka Connect，否则通过对象流方式暂存，稍后再实际发送。</p><p></p><h3>3. 需要关注的问题（一）——通过对象流暂存解析后Redo信息</h3><p></p><p></p><p>Debezium截至目前最新版本，均在内存中暂存操作类型为DML的Redo解析信息（具体可见Io.debezium.connector.oracle.logminer.TransactionalBuffer类中的内部类Transaction，其使用List直接存储解析后DML信息）。对于尚未提交的大事务，直接将DML信息存储于内存中极易发生内存溢出（笔者实测当一个update语句更新30万条记录时即可让开辟2G内存的Debezium进程因内存溢出而崩溃）。</p><p></p><p>解决方式是使用对象流方式，将待提交信息序列化存储于文件中。需要注意：</p><p></p><p>为了防止内存泄露，不要将所有待提交事务转储于同一个文件中，可以譬如每1000条记录切换一个文件。对象流读取/写入需要I/O开销，在处理DML记录和COMMIT事件阶段，应分别启动专门的写入线程和读取线程，并采用生产者/消费者模式，构造缓冲区队列，对待写入或已读取的DmlEvent进行管理。</p><p>&nbsp;</p><p></p><h3>4. 需要关注的问题（二）——修正Debezium中过于繁冗的解析</h3><p></p><p></p><p>Io.debezium.relational.RelationalChangeRecordEmitter类中的emitCreateRecord/emitReadRecord/emitUpdateRecord/emitDeleteRecord中，均执行了tableSchema.valueFromColumnData方法。在笔者的排查中，该方法是除LogMiner本身执行效率外，实际发送至Kafka的速度过慢的最大性能瓶颈。</p><p></p><p>该方法所做的是将LogMiner解析后的记录转换为Kafka Connect能够识别的记录。通过阅读LogMiner的解析器io.debezium.connector.oracle.logminer.parser.LogMinerDmlParser源码可知，该解析器事实上将所有字段都转换成了String类型。由于String类型一定可被Kafka Connect正确识别，笔者选择了在RelationalChangeRecordEmitter的子类io.debezium.connector.oracle.logminer.LogMinerChangeRecordEmitter中，对相关的方法进行重写，省去调用tableSchema.valueFromColumnData的过程，直接将已解析的字段传递给Kafka Connect。</p><p></p><h2>六、结束语</h2><p></p><p></p><p>本文阐述了针对Debezium做适应性优化和改造的方法，使其能够对主库无影响的情况下针对Oracle备库进行抽数，并将抽取速度提升至生产实际可用的程度。对于一般应用系统可作为替代Oracle OGG的“免费”且“好用”的方案选择。</p><p></p><h5>作者介绍：</h5><p></p><p>丁杨，现任职于中国农业银行研发中心，在大数据领域具有多年研发经验，现主要负责流批一体化计算在银行业务领域的应用研究。</p>",
    "publish_time": "2022-07-04 15:35:50",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "首个冲刺科创板的国产数据库：78岁老教授打磨四十年，每一行代码都自主研发",
    "url": "https://www.infoq.cn/article/KaIIi6FxILSFeQAT430Q",
    "summary": "<p></p><p>整理 | 褚杏娟、Tina</p><p></p><p>2022 年 6 月 29 日，科创板受理武汉<a href=\"https://www.dameng.com/\">达梦数据库</a>\"股份有限公司上市申请。</p><p></p><p>根据招股书，本次发行股份全部为新股，原股东不公开发售股份。本次拟公开发行股票数量不超过 1,900.00 万股，且不低于发行后公司总股本的 25%。发行后总股本不超过 7,600.00 万股。其中，招商证券为其保荐机构，华英证券为联席主承销商。</p><p></p><p>据招股书显示，达梦本次募资主要用于集群数据库管理系统升级项目、高性能分布式关系数据库管理系统升级项目、新一代云数据库产品建设项目、达梦中国数据库产业基地和达梦研究院建设项目 。</p><p></p><p>达梦数据库实际控制人为冯裕才，其通过实际控制的梦裕科技、曙天云、得特贝斯、数聚云、惠梦源、数安科技、梦达惠佳、数聚通等合伙企业，拥有发行人 28.0847% 的表决权，但达梦不存在控股股东。发行前后的股本结构变化如下：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d0/d0deb15753976b1acce31e17f2171b1a.png\" /></p><p></p><p></p><h2>党政、能源、金融等，撑起营收高速增长</h2><p></p><p></p><p></p><h4>主营业务收入的年化复合增长率达到 57.07%</h4><p></p><p></p><p>招股书显示，达梦数据库近三年营收分别为 7.43 亿、4.5 亿、3.02 亿；净利润为 4.38 亿、1.44 亿、8375 万。报告期内，公司主营业务收入的年化复合增长率达到 57.07%。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/8c/8cf3373e1dad7af7335ffcf2f8a65d1f.png\" /></p><p></p><p>达梦数据库的主要产品及服务包括软件产品使用授权、数据及行业解决方案和运维服务，其中前两个为收入的主要来源。2019 年到 2021 年，软件产品使用授权方式收入占主营业务收入比重分别为 69.32%、82.42%、86.57%。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/45/45adb6fbd68620e25733a1e8f0828e80.png\" /></p><p></p><p>据悉，达梦数据库的客户包括建设银行、交通银行、光大银行、兴业银行、广发银行、国 开行、中国人寿、邮储银行、中国人保、国家电网、中国航信、中国移动、中国烟草、国家市场监督管理总局、各级人民检察院、各级人民法院、国家发改委、 国家移民局、证监会、上交所、深交所等，涵盖党政、金融、能源、电信等数十个领域。</p><p></p><p>其中，达梦数据库在党政领域内的软件产品使用授权业务收入持续大幅增长，复合增长率达到 94.43%。2021 年度，达梦数据库在金融行业获得的收入取得突破性增长，较 2020 年度增长 7,052.99 万元，增长幅度超过 1,000.00%。</p><p></p><p>当前，达梦数据库的前五大客户分别为中建信息、湖北省司法厅、四川中达联科软件科技有限责任公司、广州诚踏信息科技有限公司和中国电子科技集团有限公司。其中，中建信息在 2021 年的销售金额占当年营业收入的 30.12%。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/98/98a17416ca63d96478969f74694b891b.png\" /></p><p></p><p>根据招股书，达梦数据相对于其他国内传统数据库厂商均具备一定优势。2019 至 2021 年，中国国产数据库管理软件企业经营业绩情况列示如下：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a5/a5fe938818cdb7e8f45f3bce991235f2.png\" /></p><p></p><p></p><h4>研发费用呈增长趋势</h4><p></p><p></p><p>期间费用方面，销售费用占比最高，其次为研发费用。达梦数据库近三年的研发费用分别为 6256 万、9660 万、1.18 亿，呈增长趋势，研发费用率分别为 20.74%、21.46% 和 15.86%。</p><p></p><p>其中，职工薪酬是公司研发费用中最主要的支出。截至 2021 年 12 月 31 日，公司共有研发人员 332 名，占公司员工人数比例为 31.35%。报告期内，研发人员薪酬分别为 4,310.72 万元、5,158.56 万元及 8,781.74 万元，同比增长分别为 19.67% 和 70.24%。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/99/995be6e30eb4d329d1486db8ede8e0f5.png\" /></p><p></p><p>根据招股书，达梦数据库近三年的数据财务数据如下：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a9/a96085c861c1e8d950c4333576599b52.jpeg\" /></p><p></p><p></p><h2>老教授的国产梦</h2><p></p><p></p><p>达梦数据库的背后，是一位 78 岁中国老教授的数据库国产梦。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ba/ba991e78c0c919b0b402cc0f952fb2bd.png\" /></p><p></p><p>“达梦就是达到<a href=\"http://m.cnhubei.com/content/2021-07/15/content_13933490.html\">梦想的意思</a>\"。”达梦实际控制人、创始人冯裕才曾说。“有人说我是教授，也有人说我是商人。我觉得定位都不准确，我认为我是一位坚持近 40 年，做自主可控国产基础软件的‘追梦者’，是一位痛并快乐着的‘创业者’，也是数据库中国梦的‘坚守者’。”</p><p></p><p>1944 年出生于江苏的冯裕才，本科就读于哈尔滨工程学院导弹工程系，也就是日后的国防科技大学。1976 年进入华中科技大学，从计算机系助教做起，先后成为讲师、副教授、教授、博士生导师，直至 2011 年 3 月从华科退休。冯裕才在华科教了 35 年书，达梦数据库也正是在这所高校诞生。</p><p></p><p>冯裕才开始探索数据库要追溯到 1978 年。<a href=\"http://jxt.hubei.gov.cn/fbjd/xxgkml/jgzn/nsjg/rjhxxfwyc/qyfc/201912/t20191226_1796233.shtml\">当时</a>\"，武钢投资 50 亿元从日本引进设备，建造“一米七”热轧钢材自动化生产线。为了防止技术泄密，日方在调试安装完设备后，把足足三卡车的技术资料当场销毁。冯裕才在现场目睹了这一幕，内心感到巨大的屈辱，痛下决心一定要研发出中国人自己的数据库系统。</p><p></p><p>1982 年，冯裕才“啃”完朋友从美国寄回来的 300 多篇英文原版论文，逐渐熟悉了数据库系统各子部件的工作原理及使用方法，开始着手准备数据库管理系统的研发工作，并成立了自己的研发小组。历经六年，他们终于在 1988 年成功研制了我国第一个自主版权的“数据库管理系统 CRDS”。1992 年，冯裕才带领课题组，拿下了国家部委一个 400 万元预算的数据库项目，华科也决定将其团队升格为“华中理工大学达梦数据库多媒体研究所”。2000 年，达梦公司正式成立，承担着实现数据库国产的使命。</p><p></p><p></p><h4>自主可控，每一行代码都自己研发</h4><p></p><p></p><p>虽然当时中国的学术界开始研究数据库，但是美国的工业界已经开始研发关系型数据库，差距就此拉开。而自 90 年代开始，Oracle、Sybase、DB2、Informix 等产品纷纷进入中国，并且占据了垄断地位。国内数据库行业是一个百亿级大市场，但当时甲骨文等国外软件占有 95% 的市场。</p><p></p><p>国内大多数数据库开发企业采用拿来主义，利用国外的开源技术。为打破国外技术封锁，规避使用开源技术可能存在的安全和版权风险，冯裕才坚持源代码 100% 自主研发。每一行代码都是自己研发，只有这样才能完全拥有自主知识产权，掌握数据库领域的核心关键技术。</p><p></p><p>自主可控数据库的研发具有极大挑战，数据库开发是个高端技术行业，不是短暂的时间就能掌握核心开发技术。数据库体量是很大的，通常在 1000 万到 2000 万源代码，这样大的规模的数据库的开发的维护，按照国外软件工程的计算，每个工程师每年维护的源码大概在 1 万行左右，就意味着至少有 1000 到 2000 个人了解熟悉它。</p><p></p><p>长期以来，达梦产品在国家相关测试中几乎每年都是第一名，但到 2003 年，达梦数据库的成绩一下子掉下来了。一个很重要的原因是达梦一直坚持完全自主研发，而其它同类产品则开始从自主研发向开源转变。冯裕才认为使用开源，短期内产品各方面可能会有显著提升，但由于没有经历过这样一个发展过程，无论是研发队伍、人才还是技术掌握都会有所欠缺，所以其根基是不牢固的。“一个企业在它所研究的行业里，如果未能拥有自主知识产权和核心技术，那么就会对企业的核心竞争力造成很大挑战。这是一个企业生死攸关的大问题，在数据库行业尤其如此。”</p><p></p><p></p><h4>信息安全重于一切</h4><p></p><p></p><p>数据库的安全也是极其重要的，以前根据美国法律，高于国家安全级别二级（最高五级）的数据库产品不允许对中国销售，这就决定了国内市场上的国外数据库产品<a href=\"https://web.archive.org/web/20160202051850/http://www.wehdz.gov.cn/xwdt/mtjj/60524.htm\">安全级别不高</a>\"。此外，还很难确保国外产品中不含“逻辑炸弹”和“后门”，可能给信息安全带来极大威胁。</p><p></p><p>“2008 年，国家电网遭到黑客攻击，至今未能查到攻击来源。”冯裕才说。“在信息时代，数据库如同人体的神经中枢，一旦瘫痪，后果不堪设想。”</p><p></p><p>达梦在快速发展下，不仅成为首批获得国家“双软”认证的软件企业，唯一获得自主原创认证的数据库企业，产品还通过 EAL4+ 级审核，达到了目前国产数据库最高安全级别。</p><p></p><p>2000 年后，关键行业开始采取去“IOE”的行动，随后国家新一代智能电网建设引入达梦数据库。目前，达梦数据库在<a href=\"https://www.dameng.com/view_3504.html\">国家电网调度领域</a>\"市场占有率超 80%，在南方电网调度领域市场占有率达 90%。为电网行业数字化转型、众多核心生产系统提供了重要支撑。</p><p></p><p>大数据浪潮到来之后，达梦公司又逐渐转为致力于数据库管理系统与大数据平台的研发、销售和服务，提出了新的做全栈数据产品及解决方案提供商的理念。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/2b/2b8f9a31d6e566ce043558c88b925c3d.png\" /></p><p></p><p>从最开始的单机数据库，达梦随着时代发展出了云数据库产品，基于自研的关系型数据库软件 DM8（包含标准版、企业版、安全版），集数据存储、备份、高可用、迁移、监控、优化、安全等功能为一体。</p><p></p><p>在政府、企业、高校几十年来的支持下，达梦从最早的党政办公系统的国产化，后来逐步进入党政核心业务系统，以及企业核心交易，包括电网、能源、航空等行业的核心业务应用。近几年又逐步进入了金融、运营商等高端市场，已经几乎触及了数据库业内的最高端市场。</p><p></p><p>历经 40 余年积累沉淀，达梦产品现已广泛应用于国家重大核心领域，并连续多年在国产数据库市场排名第一。</p><p></p><p>随着招股书的提交，达梦也有望成为“国产数据库第一股”。回顾历史，我们能够看到，数据库产业要想实现发展超越，产学研用必须要同步推进，才有可能消除短板、加速生长。国产数据库虽然发展很慢，但已经逐渐打磨成形，具备一战之力。</p><p></p><p>今日好文推荐</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651124631&amp;idx=1&amp;sn=becf531639d6cf236ab0a29e6e614773&amp;chksm=bdb90bc48ace82d285e7e3391952cb79a38371202533460331cd205fcdab144027bc31834a06&amp;scene=21#wechat_redirect\">为什么 Rust 是初创公司的绝佳选择?</a>\"</p><p></p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651124630&amp;idx=1&amp;sn=6c6860915b83b729912272fde173d9cd&amp;scene=21#wechat_redirect\">达梦冲刺国产数据库第一个 IPO；特斯拉自动驾驶部门裁员约 200 人；微信推出图片大爆炸功能｜Q 资讯</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651124439&amp;idx=1&amp;sn=17589635c517723b03526ae7f23e3f18&amp;chksm=bdb90a848ace8392f9b925c1bc45b2542e50c4cc2cd1b5ecb12f9913df4ceef9b5584cbcf373&amp;scene=21#wechat_redirect\">从 IE 到 Edge：我们跟微软浏览器团队聊了聊 Web 的过去和未来 | 中国卓越技术团队访谈录</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651124152&amp;idx=1&amp;sn=d658cb736dc1b0501da34dbcdc2c343b&amp;chksm=bdb909eb8ace80fd7f8df9b34f95035e5dcf0042a52b03462e057b6392d8afde570fea0ddd86&amp;scene=21#wechat_redirect\">尤雨溪向 React 推荐自己研发的 Vite，网友：用第三方工具没有任何意义</a>\"</p><p></p>",
    "publish_time": "2022-07-04 16:08:31",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "SRS 5.0：如何实现 SRT 协程化",
    "url": "https://www.infoq.cn/article/x6jZTzXP4bZQlMxpLIlT",
    "summary": "<p>协程是现代服务器的核心技术，能极大简化逻辑和提升维护性；SRT是逐渐在取代RTMP推流的新协议，但它有自己的IO框架；只有实现了SRT的协程化，才能成为SRS的核心的成熟的协议，这是SRS 5.0迈出的第一步，也是至关重要的一步。</p><p></p><p>SRS 5.0从2022年初启动以来，经过摸索和探讨，确定了以媒体网关作为核心方向，详细请看<a href=\"https://mp.weixin.qq.com/s/Rq3NuZKdMr2_Dmiki72RFw\">SRS 5.0核心问题定义和解法</a>\"。</p><p></p><p>SRT作为主播/广播推流领域广泛采用的协议，而Web浏览器却不支持播放SRT流，这恰恰是媒体网关的核心价值，可以将SRT转成RTMP/HLS/WebRTC后，实现广播领域的Web超低延迟方案，还可以把SRT强大的跨国传输能力用起来。</p><p></p><p>而这些美好愿景的基础，就是这次要介绍的：改造SRT支持协程化(Coroutine Native SRT)。这是SRS 5.0至关重要的一步，也是具备深远影响的一步，详细代码请参考<a href=\"https://github.com/ossrs/srs/pull/3010\">PR#3010</a>\"。</p><p></p><p>我们先了解下详细的背景介绍。</p><p></p><h2>Introduction</h2><p></p><p></p><p>在直播推流领域，RTMP是事实上的工业标准，广泛使用，也是直播源站之间兼容性最好的协议。</p><p></p><p>随着场景的丰富和直播的发展， 几个比较严重的问题逐渐暴露出来：</p><p></p><p>TCP推流在长距离传输下，受丢包以及RTT抖动影响非常大，效果很差。RTMP协议不支持多音轨，以及H265、AV1等一系列新的编解码。Adobe已经放弃RTMP协议，很多年没有更新了，未来也不会更新。</p><p></p><p>为了解决这些问题，2018年左右，广播电视领域开始广泛应用SRT协议推流，越来越多的推流设备和平台都支持了SRT协议。</p><p></p><p>SRS在2019年底，SRS 4.0支持了SRT推流，目前存在以下的问题：</p><p></p><p>SRT在SRS上使用多线程+异步实现，某些异常导致的程序Crash，难以排查。SRT在SRS实现是异步方式，代码复杂，维护难度高。HTTP回调，SRT播放不生效；SRT推流依赖转RTMP后，RTMP触发的回调。SRT无法直接转WebRTC，而是先转RTMP再转WebRTC，导致延迟高。</p><p></p><p>这些问题的核心原因，是由于SRT使用了独立的异步IO和多线程，无法和SRS已有的ST协程结合起来。</p><p></p><p>要彻底解决这个问题，必须将SRT协程化，和SRS使用同一套ST协程框架。SRS 5.0已经完成，详细代码请参考<a href=\"https://github.com/ossrs/srs/pull/3010\">PR#3010</a>\"，这是非常重要的一个功能。</p><p></p><p>在介绍SRT协程化之前，先介绍下什么是协程化，我们看下ST的TCP协程化(Coroutine Native)，这是最好的例子。</p><p></p><h2>Coroutine Native TCP</h2><p></p><p>首先，非协程化的代码，也就是epoll驱动的异步代码，大概逻辑是这样：</p><p></p><p><code lang=\"cpp\">int fd = accept(listen_fd); // Got a TCP connection.\n\nint n = read(fd, buf, sizeof(buf));\nif (n == -1) {\n  if (errno == EAGAIN) { // Not ready\n    return epoll_ctl(fd, EPOLLIN); // Wait for fd to be ready.\n  }\n  return n; // Error.\n}\n\nprintf(\"Got %d size of data %p\", n, buf);\n</code></p><p></p><p></p><blockquote>Note: 为了方便表达关键逻辑，我们使用示意代码，具体代码可以参考epoll的示例代码。</blockquote><p></p><p></p><p>一般read是业务逻辑，读出来的数据也是业务数据，但是这里却需要在EAGAIN时调用epoll这个底层框架处理fd。这就是把底层逻辑和业务逻辑混合在一起，导致难以维护。</p><p></p><p></p><blockquote>Note: 尽管NGINX包装了一层框架，但是本质上并不能解决这个异步回调问题，当fd没有准备好必须返回当前函数，所以导致很多状态需要保存和恢复，在复杂的逻辑中状态机也变得非常复杂。</blockquote><p></p><p></p><p>下面我们看协程化的逻辑会是怎样的，同样以上面代码为例：</p><p></p><p><code lang=\"cpp\">st_netfd_t fd = st_accept(listen_fd); // Got a TCP connection\n\nint n = st_read(fd, buf, sizeof(buf));\nif (n == -1) {\n    return n; // Error.\n}\n\nprintf(\"Got %d size of data %p\", n, buf);\n</code></p><p></p><p>简单的看，就是没有EAGAIN，看起来要么读取到了数据，要么就是出现了错误，不会出现fd没有准备好的情况。这就给整个业务逻辑带来了非常好的体验，因为不需要保存状态了，不会反复的尝试读取。</p><p></p><p>同样用epoll，为何st_read就没有EAGAIN呢？这就是协程化，不是没有，只是在底下处理了这个事件。我们看st_readv这个函数：</p><p></p><p><code lang=\"cpp\">ssize_t st_read(_st_netfd_t *fd, void *buf, size_t nbyte) {\n    while ((n = read(fd-&gt;osfd, buf, nbyte)) &lt; 0) {\n        if (errno == EINTR)\n            continue;\n        if (!_IO_NOT_READY_ERROR) // Error, if not EAGAIN.\n            return -1;\n\n        /* Wait until the socket becomes readable */\n        if (st_netfd_poll(fd, POLLIN) &lt; 0) // EAGAIN\n            return -1;\n    }\n    \n    return n;\n}\n</code></p><p></p><p>很明显在EAGAIN时，会调用st_netfd_poll。在st_netfd_poll函数里，会将当前协程切换出让，调度线程执行下一个协程。并且在未来某个时刻，会因为IO事件到达或者超时错误，而将当前协程恢复。</p><p></p><p></p><blockquote>Note: 由于协程切换和恢复，都是在这个函数中实现的，对于上层调用的代码，看起来没有发生什么，所以就不仅没有EAGAIN这个错误消息，也不会返回上一层函数，当然也不需要保存状态和恢复状态。</blockquote><p></p><p></p><p>我们可以总结下，如何协程化任何协议的思路：</p><p></p><p>直接对API进行一次调用，如果成功，那么直接返回。如果API返回失败，检查错误，非IO等待的错误直接返回。将当前协程出让，调度器运行其他协程，直到该FD上的事件返回或者超时；如果超时，则返回错误；如果事件到达，则重复上面的步骤。</p><p></p><p>我们可以按照这个思路将SRT进行协程化(Coroutine Native)。</p><p></p><h2>Coroutine Native SRT</h2><p></p><p>我们以srt_recvmsg函数的协程化为例，这个函数类似TCP的read函数，定义如下：</p><p></p><p><code lang=\"cpp\">SRT_API int srt_recvmsg (SRTSOCKET u, char* buf, int len);\n</code></p><p></p><p>我们同样，提供一个SrsSrtSocket::recvmsg的函数，类似st_read函数，实现如下：</p><p></p><p><code lang=\"cpp\">srs_error_t SrsSrtSocket::recvmsg(void* buf, size_t size, ssize_t* nread) {\n  while (true) {\n    int ret = srt_recvmsg(srt_fd_, (char*)buf, size);\n    if (ret &gt;= 0) { // Receive message ok.\n      recv_bytes_ += ret; \n      *nread = ret;\n      return err;\n    }\n    \n    // Got something error, return immediately.\n    if (srt_getlasterror(NULL) != SRT_EASYNCRCV) {\n      return srs_error_new(ERROR_SRT_IO, \"srt_recvmsg\");\n    }\n    \n    // Wait for the fd ready or error, switch to other coroutines.\n    if ((err = wait_readable()) != srs_success) { // EAGAIN.\n      return srs_error_wrap(err, \"wait readable\");\n    }\n  }\n  \n  return err;\n}\n</code></p><p></p><p>可以看到和st_read非常类似，在wait_readable中也会实现协程的切换和恢复，只是我们使用st_cond_t条件变量来实现：</p><p></p><p><code lang=\"cpp\">srs_error_t SrsSrtSocket::wait_readable() {\n  srt_poller_-&gt;mod_socket(this, SRT_EPOLL_IN);\n  srs_cond_timedwait(read_cond_);\n}\n</code></p><p></p><p></p><blockquote>Note: 这里先修改了epoll侦听的事件SRT_EPOLL_IN，等待fd可读后，再等待条件变量触发。</blockquote><p></p><p></p><p>而触发这个条件变量的函数，是在SrsSrtPoller::wait，实现如下：</p><p></p><p><code lang=\"cpp\">srs_error_t SrsSrtPoller::wait(int timeout_ms, int* pn_fds) {\n  int ret = srt_epoll_uwait(srt_epoller_fd_, events_.data(), events_.size());\n  for (int i = 0; i &lt; ret; ++i) {\n    if (event.events &amp; SRT_EPOLL_IN) {\n      srt_skt-&gt;notify_readable();\n    }\n  }\n}\n\nvoid SrsSrtSocket::notify_readable() {\n  srs_cond_signal(read_cond_);\n}\n</code></p><p></p><p>这样就完全做到了将SRT API协程化，其他的API比如srt_sendmsg, srt_connnect, srt_accept也是类似的操作。</p><p></p><p>下面我们对比下，协程化(Coroutine Native)之后，和原始的回调(Callback)的区别。</p><p></p><h2>Coroutine Native PK Callback</h2><p></p><p>将SRT 协程化以后， 业务逻辑和底层代码分离，上层的代码逻辑清晰明了。</p><p></p><p>先看看accept这个逻辑，之前也是由epoll触发的事件处理，创建srt_conn这个数据结构：</p><p></p><p><code lang=\"cpp\">while (run_flag) {\n  int ret = srt_epoll_wait(_pollid, read_fds, &amp;rfd_num, write_fds);\n  for (int index = 0; index &lt; rfd_num; index++) {\n    SRT_SOCKSTATUS status = srt_getsockstate(read_fds[index]);\n    srt_handle_connection(status, read_fds[index], \"read fd\");\n  }\n}\n\nvoid srt_server::srt_handle_connection(SRT_SOCKSTATUS status, SRTSOCKET input_fd) {\n  if (status == SRTS_LISTENING) {\n    conn_fd = srt_accept(input_fd, (sockaddr*)&amp;scl, &amp;sclen);\n    _handle_ptr-&gt;add_newconn(conn_fd, SRT_EPOLL_IN);\n  }\n}\n\nvoid srt_handle::add_newconn(SRT_CONN_PTR conn_ptr, int events) {\n    _push_conn_map.insert(std::make_pair(conn_ptr-&gt;get_path(), conn_ptr));\n    _conn_map.insert(std::make_pair(conn_ptr-&gt;get_conn(), conn_ptr));\n    int ret = srt_epoll_add_usock(_handle_pollid, conn_ptr-&gt;get_conn(), &amp;events);\n}\n</code></p><p></p><p></p><blockquote>Note: 创建的srt_conn本身就是保存在全局数据结构之中，在后续的回调事件中持续修改和变更这个数据结构。</blockquote><p></p><p></p><p>我们对比下协程化之后的业务逻辑，收到会话之后启动处理协程：</p><p></p><p><code lang=\"cpp\">srs_error_t SrsSrtListener::cycle() {\n  while (true) {\n    srs_srt_t client_srt_fd = srs_srt_socket_invalid();\n    srt_skt_-&gt;accept(&amp;client_srt_fd);\n    \n    srt_server_-&gt;accept_srt_client(srt_fd);\n  }\n}\n\nsrs_error_t SrsSrtServer::accept_srt_client(srs_srt_t srt_fd) {\n  fd_to_resource(srt_fd, &amp;srt_conn);\n  conn_manager_-&gt;add(srt_conn);\n  srt_conn-&gt;start();\n}\n</code></p><p></p><p></p><blockquote>Note: 虽然有全局变量维护srt_conn，但这里不会关注到epoll的处理，而是由协程主导的执行逻辑，而不是由回调主导的逻辑。</blockquote><p></p><p></p><p>回调主导的逻辑，维护和了解代码时，必须要从epoll回调事件开始看，而且不同事件都在修改srt_conn这个对象的状态，要了解对象生命周期是很有难度的。而协程主导的逻辑，它的生命周期是在协程中，收到srt_conn就启动协程处理它，后续的读写也在协程中。</p><p></p><p>我们继续看srt_conn的读处理逻辑，之前直接使用原生SRT的read函数，同样是由epoll的事件触发回调：</p><p></p><p><code lang=\"cpp\">while (run_flag) {\n  int ret = srt_epoll_wait(_pollid, read_fds, &amp;rfd_num, write_fds);\n  for (int index = 0; index &lt; rfd_num; index++) {\n    SRT_SOCKSTATUS status = srt_getsockstate(read_fds[index]);\n    srt_handle_data(status, read_fds[index], \"read fd\");\n  }\n}\n\nvoid srt_handle::handle_srt_socket(SRT_SOCKSTATUS status, SRTSOCKET conn_fd) {\n  auto conn_ptr = get_srt_conn(conn_fd);\n  int mode = conn_ptr-&gt;get_mode();\n  if (mode == PUSH_SRT_MODE &amp;&amp; status == SRTS_CONNECTED) {\n    handle_push_data(status, path, subpath, conn_fd);\n  }\n}\n\nvoid srt_handle::handle_push_data(SRT_SOCKSTATUS status, SRTSOCKET conn_fd) {\n  srt_conn_ptr = get_srt_conn(conn_fd);\n  if (status != SRTS_CONNECTED) { // Error.\n    close_push_conn(conn_fd);\n    return;\n  }\n\n  ret = srt_conn_ptr-&gt;read_async(data, DEF_DATA_SIZE);\n  if (ret &lt;= 0) { // Error.\n    if (srt_getlasterror(NULL) != SRT_EASYNCRCV) {\n      return;\n    }\n    close_push_conn(conn_fd);\n    return;\n  }\n\n  srt2rtmp::get_instance()-&gt;insert_data_message(data, ret, subpath);\n}\n</code></p><p></p><p></p><blockquote>Note: 在回调中我们需要处理各种状态，而这个srt_conn的状态变化，是由各种回调决定的，很难一次了解到这个会话的主要处理逻辑。</blockquote><p></p><p></p><p>我们看看SRT协程化之后，这个业务逻辑是怎样写的：</p><p></p><p><code lang=\"cpp\">srs_error_t SrsMpegtsSrtConn::do_publishing() {\n  while (true) {\n    ssize_t nb = 0;\n    if ((err = srt_conn_-&gt;read(buf, sizeof(buf), &amp;nb)) != srs_success) {\n      return srs_error_wrap(err, \"srt: recvmsg\");\n    }\n    \n    if ((err = on_srt_packet(buf, nb)) != srs_success) {\n      return srs_error_wrap(err, \"srt: process packet\");\n    }\n  }\n}\n</code></p><p></p><p></p><blockquote>Note: 这里srt_conn的生命周期非常明确，它的状态就是直接在这里返回错误，对于这个会话来说，这就是它的主循环，不会因为read而导致进入SRT的epoll大循环，我们在维护时也不用关注这个异步事件触发和处理。</blockquote><p></p><p></p><p>再次强调一次，维护代码时，我们需要了解的信息量是非常不同的。在基于异步回调的逻辑中，我们在回调函数中，是需要关注目前对象有哪些状态，修改了哪些状态，其他异步事件又有哪些影响。而基于协程的逻辑中，没有这些状态，协程的创建和执行，就是线性的，或者说这些状态就是在协程的函数调用中。</p><p></p><p></p><blockquote>Note: 为何异步回调的状态就不能在函数调用中呢？因为异步回调的堆栈中不能保存srt_conn的状态，它本质上就是一个协程，保存的是epoll的循环的状态。而协程是根据每个srt_conn所创建的，它的堆栈中保存的都是这个对应的srt_conn的状态。</blockquote><p></p><p></p><p>这本质上，是由于异步回调的状态，只能保存在全局数据结构之中。而协程的状态，是可以保存在各个局部变量之中，每个函数的局部变量，都是这个协程所独有的，协程没有结束前都可以使用。</p><p></p><h2>What is the Next</h2><p></p><p>SRS虽然完成了SRT协程化，并没有解决所有的问题。后续的计划包括：</p><p></p><p>SRT直接转WebRTC，低延迟直播的另外一种方式。某些服务器之间的长链路可以将TCP替换为SRT传输， 比如跨国的RTMP 转发。SRT工具链的完善，比如<a href=\"https://github.com/ossrs/srs-bench\">srs-bench</a>\"，支持压测SRT流。</p><p></p><p>欢迎加入SRS开源社区，一起做好一个流媒体服务器，让全世界都来白嫖。</p><p></p><h2>One More Thing</h2><p></p><p>有些朋友也很好奇，真正商用的视频云的SRT，和开源的SRT的服务器，有什么区别，都做过哪些优化。</p><p></p><p></p><blockquote>Note: 由于开源服务器侧重标准协议和兼容性，有些优化并不适合在开源项目中实现，所以在云计算的商业化服务器和开源服务器，一定是存在很大差异的。就算是Linux系统，其实云计算的Linux内核，和开源的Linux内核，也有很大的差异。</blockquote><p></p><p></p><p>腾讯云在SRT的实战中积累很多经验，请参考之前分享的文章：</p><p></p><p><a href=\"https://mp.weixin.qq.com/s/UTYkqFaprGnqw37FgPDYzw\">技术解码 | 腾讯视频云直播推流再升级，支持多路径传输</a>\"<a href=\"https://mp.weixin.qq.com/s/Zcuwk-wlisZzthZB_ucCxg\">毫秒级跨洋传输延迟，腾讯云音视频连续6年保障英雄联盟总决赛直播</a>\"<a href=\"https://mp.weixin.qq.com/s/YaqLzafUQ5MSGA1ulEb3VQ\">技术解码 | 斗鱼同款的SRT技术是如何对抗推流抖动的？</a>\"<a href=\"https://mp.weixin.qq.com/s/60GagRTvLGpKzBWRF2ucfA\">技术解码 | SRT和RIST协议综述</a>\"</p><p></p><p>其中，最为严重的是SRT重传率过高、限带宽下表现不如TCP/QUIC等，腾讯云针对这些问题，做了几个优化：</p><p></p><p>SRT重传乱序度自适应：当接收到乱序报文，首次发起重传时，会根据当前的乱序度，等待N个包之后才发起重传。原生SRT这个乱序度是固定值，我们修改成为根据网络乱序情况自适应。SRT传输参数优化：通过对参数优化，减少了一半的重传率。加入了BBR拥塞控制算法：原生SRT拥塞控制非常弱，评估的带宽波动也非常大。我们加入了BBR拥塞控制算法，针对性的解决了这个问题。强化了SRT多链路传输，增加了带宽聚合的模式：原生SRT只有backup，broadcast两种多链路传输模式，我们针对直播场景增加了auto模式，能够做到讲多个网卡的带宽聚合后进行直播，并智能动态选择链路。</p><p></p><p></p><blockquote>Note: 腾讯云音视频在音视频领域已有超过21年的技术积累，持续支持国内90%的音视频客户实现云上创新，独家具备 RT-ONE™ 全球网络，在此基础上，构建了业界最完整的 PaaS 产品家族，并通过腾讯云视立方 RT-Cube™ 提供All in One 的终端SDK，助力客户一键获取众多腾讯云音视频能力。腾讯云音视频为全真互联时代，提供坚实的数字化助力。</blockquote><p></p><p></p><p></p><h5>作者介绍：</h5><p></p><p></p><p>肖志宏 (hondaxiao) 腾讯云工程师，全球TOP1开源音视频服务器SRS TOC。</p><p></p><p>杨成立 (Winlin) 腾讯云工程师，全球TOP1开源音视频服务器SRS作者，音视频服务器和视频云领域超过13年经验。</p>",
    "publish_time": "2022-07-04 16:24:02",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "小扎警告员工：不想干可以走；游戏新贵米哈游踩雷信托；京东腾讯再续前缘；微软发出最后通碟：Windows8.1 的用户尽快升级 | 架构周报",
    "url": "https://www.infoq.cn/article/p9ImSBYCMx3h8HfFXXYV",
    "summary": "<p>整理｜闫园园</p><p>&nbsp;</p><p></p><blockquote>本周架构视点：想解除QQ账号限制，用户还要深刻认识自己的问题；京东腾讯再续前缘：未来三年强强手；游戏新贵米哈游踩雷信托；整改近一年，BOSS直聘等3家网络平台恢复新用户注册；扎克伯格警告员工：不想干可以走；台积电公开披露员工薪酬：全球员工中位数约46万，总裁魏哲家年薪近9000万；行程卡“摘星”，去哪儿网：火车票搜索量猛涨，国际机票搜索达2年来顶峰；微软发出最后通碟：Windows8.1 的用户尽快升级；拼多多电脑网页版上线：无砍一刀无团购；Vim 9.0 发布：带来了百倍速度新脚本语言；Firefox 102 已发布：支持自动删除 URL 中跟踪器；Vue 2.7 发布。</blockquote><p></p><p></p><h2>万万没想到</h2><p></p><p></p><h4>想解除QQ账号限制，用户还要深刻认识自己的问题</h4><p></p><p>&nbsp;</p><p>近期，大量QQ用户反馈遭遇了账号被盗的情况，不少受此影响而被封禁的用户为了找回账号选择向QQ客服进行申诉。而在账号解封成功的通知短信中，腾讯方面却声称：用户存在违规行为，综合评估对方已深刻认识到自己的问题，并承诺后续严格遵守QQ规范，不再违规，决定为用户解除帐号限制。</p><p>&nbsp;</p><p>据悉，有不少用户为了解封账号，上传了手持身份证的照片，并签署一份“QQ个人账号合规使用承诺书”，其中的内容包括“我已认真阅读《QQ号码规则》，充分认识并承认我利用QQ实施了违规行为，对其他用户和平台造成了不良的影响……我郑重承诺我不再实施前述行为。”</p><p></p><h4>京东腾讯再续前缘：未来三年强强联手</h4><p></p><p>&nbsp;</p><p>29日，两大互联网巨头<a href=\"https://www.tencent.com/\">腾讯</a>\"与京东，在经历“分红式减持”后宣布再续“前缘”，签订为期三年的战略合作协议。</p><p>&nbsp;</p><p>根据协议，未来三年腾讯将继续在其微信平台上向京东提供一级和二级访问入口以提供流量支持，且双方有意在通信、技术服务、营销及广告以及会员服务等多个领域合作。</p><p>&nbsp;</p><p>京东还表示，有关合作的价值预期将于未来三年以现金及京东股份相结合的形式支付或投放。作为总对价的一部分，京东将向腾讯发行价值最高2.2亿美元A类普通股。此外，京东表示将在人工智能、信息安全等领域与腾讯展开合作。</p><p></p><h4>游戏新贵米哈游踩雷信托</h4><p></p><p>&nbsp;</p><p>据青海网上法院公告显示，2022年7月25日，西宁市城中区人民法院将依法公开审理<a href=\"https://www.mihoyo.com/\">米哈游</a>\"诉五矿信托纠纷一案。同时起诉五矿信托的还有另一家游戏公司—上海莉莉丝网络科技有限公司（下称“莉莉丝”）。</p><p>&nbsp;</p><p>此前，“时代财经”报道，有多位投资者通过招商银行购买的五矿信托-鼎兴产品出现到期后无法兑付情况。米哈游与莉莉丝踩雷信托或与此有关。</p><p></p><h4>整改近一年，BOSS直聘等3家网络平台恢复新用户注册</h4><p></p><p>&nbsp;</p><p>本周，BOSS直聘<a href=\"https://weibo.com/bosszhipin?sudaref=www.baidu.com\">发布</a>\"公告称，近一年来，公司认真配合国家网络安全审查，严肃对待审查中发现的安全问题，进行了全面整改。经报网络安全审查办公室同意，即日起恢复“BOSS直聘”的新用户注册。BOSS直聘称，后续，公司将采取有效措施，切实保障平台设施安全和大数据安全。</p><p>&nbsp;</p><p>2021年7月5日，网信办宣布，对“BOSS直聘”等启动网络安全审查，为配合网络安全审查工作，防范风险扩大，审查期间“BOSS直聘”停止新用户注册。</p><p></p><h4>扎克伯格警告员工：不想干可以走</h4><p></p><p>&nbsp;</p><p><a href=\"https://about.facebook.com/\">Meta</a>\" 首席执行官马克·扎克伯格 ( Mark Zuckerberg ) 在最近的一次内部问答活动上，向该公司员工发出了措辞严厉的警告，要求他们为近期历史上最严重的经济衰退之一做好准备。</p><p>&nbsp;</p><p>上周，扎克伯格告诉员工，他希望加大对他们的压力。他说：“如果一定要我打赌，我会说这可能是近年来我们看到的最严重的衰退之一。”</p><p></p><h4>台积电公开披露员工薪酬：全球员工中位数约46万，总裁魏哲家年薪近9000万</h4><p></p><p>&nbsp;</p><p>据台湾“中央社”消息，台积电公布2021年度永续报告书，披露去年全球员工总体薪酬的中位数约新台币206万元（约合人民币46.35万元），总裁魏哲家的薪酬约为中位数的194倍（约合人民币8991.9万元）。其中，台湾厂区的员工平均年薪242.5万新台币，约合54.6万人民币，中位数年薪为185.1万新台币。</p><p>&nbsp;</p><p>台积电指出，公司整体薪酬包括本薪、津贴、现金奖金及酬劳。以台湾地区新进硕士毕业工程师为例，去年平均整体薪酬高于200万新台币；直接员工去年平均整体薪酬高于100万新台币，每月平均收入约当台湾基本工资的4倍。</p><p>&nbsp;</p><p>报告显示，台积电目前面临着员工流失的难题，其中新人离职率高达17.6%，而去年的平均离职率6.8%，符合5-10%的区间。对于这一问题，台积电解释有两方面原因，一个是科技行业增长迅速，人才竞争激烈，流动性提高，另外就是台积电去年的人才招募数量超过以往，所以新人离职率也提升了。据统计，台积电去年全球共有1.2683万名新进员工，截至去年底，全球共计6.5152万位员工。</p><p></p><h4>行程卡“摘星”，去哪儿网：火车票搜索量猛涨，国际机票搜索达2年来顶峰</h4><p></p><p>&nbsp;</p><p>据去哪儿平台数据显示，自全国行程卡“摘星” 消息发布半小时后，平台上国际机票瞬时搜索量翻倍，达到近两年以来该平台国际机票搜索量最高峰。</p><p>&nbsp;</p><p>同时，平台机票搜索量在30分钟内上升60%，酒店搜索量翻番，火车票搜索量上涨最多达到1.5倍。</p><p></p><h2>IT 科技资讯</h2><p></p><p></p><h4>微软发出最后通碟：Windows8.1 的用户尽快升级</h4><p></p><p>&nbsp;</p><p><a href=\"https://www.microsoft.com/zh-cn\">微软</a>\"近日对目前仍停留在 Windows 8.1 的用户发出提醒，表示该系统即将停止支持。微软表示 Windows 8.1 桌面操作系统将在 2023 年 1 月 10 日之后停止技术援助和软件更新。也就是说这些用户还有半年的时间升级到 Windows 11 或者支持的 Windows 10 版本。</p><p></p><h4>拼多多电脑网页版上线：无砍一刀无团购</h4><p></p><p>&nbsp;</p><p>近日，有网友发现，拼多多官方推出了电脑端网页版「<a href=\"https://youhui.pinduoduo.com/\">拼多多优惠商城</a>\"」。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/11/11e1752db79f4c7f06a617bf277d80ce.png\" /></p><p></p><p>从主界面可以看到，拼多多优惠商城适配了电脑端的网页排版，提供各种商品分类，支持搜索，可以查看商品详情页。</p><p>&nbsp;</p><p>值得注意的是，拼多多网页商城并不支持直接下单付款，而是需要微信扫码付款，可能是相关功能尚未开发完善。</p><p></p><h4>Vim 9.0 发布：带来了百倍速度新脚本语言</h4><p></p><p>&nbsp;</p><p>经过多年的逐步改进，Vim 现在推出了两年来首个重大更新，向前迈出了一大步。在这个版本中除了若干变化外，还带来了一个新的脚本语言 Vim9 脚本。</p><p>&nbsp;</p><p>Vim9 脚本的首要目标是极大地提升性能，可带来一到两个数量级（10~100 倍）的执行速度提升；次要目标是避免 Vim 特有的结构，使之更接近于常用的编程语言，如 JavaScript、TypeScript 和 Java 等。</p><p>&nbsp;</p><p>不过，虽然 Vim9 和 Vim 之前支持的脚本语言存在一些不兼容，但旧的脚本仍然可以继续工作，不会像 Python 2 那样。</p><p></p><h4>Firefox 102 已发布：支持自动删除 URL 中跟踪器</h4><p></p><p>&nbsp;</p><p>Mozilla 最近<a href=\"https://www.mozilla.org/en-US/firefox/102.0/releasenotes/\">发布</a>\"了 Firefox 102 正式版，包含一些新功能，比如，可删除部分 URL 上各种服务和网站跟踪用户内容的选项。</p><p>&nbsp;</p><p>Firefox 102 带来了“查询参数剥离”的新功能，当用户单击链接时，它会自动删除跟踪 URL 参数。例如，Facebook 使用“fbclid=”查询来知晓有人点击了特定的 URL。Firefox 现在删除了该查询，以及 Olytics、Vero、HubSpot、Marketo 和 Drip 的其他跟踪器。</p><p>&nbsp;</p><p>新功能是严格跟踪保护规则的一部分，默认情况下处于禁用状态。要启用它，请导航到 Firefox 设置 &gt; 隐私和安全，然后在增强跟踪保护设置中打开严格。</p><p></p><h4>Vue 2.7 发布</h4><p></p><p>&nbsp;</p><p>Vue 2.x 最后一个版本 Vue 2.7，代号 \"Naruto\"（火影忍者）正式<a href=\"https://blog.vuejs.org/posts/vue-2-7-naruto.html\">发布</a>\"。</p><p>&nbsp;</p><p>按照发布计划，Vue 2.7 是 2.x 的最后一个次要版本，也是 LTS 版本，获得官方提供的&nbsp;18 个月技术支持。这就意味着，Vue 2 将在 2023 年底结束生命周期。</p><p>&nbsp;</p><p>Vue 2.7 从 Vue 3 向后移植了一些最重要的功能，包括：</p><p>Composition APISFC&nbsp;</p>",
    "publish_time": "2022-07-04 17:29:47",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "跨境支付平台 XTransfer 的低代码实践：如何与其他中台融合是核心",
    "url": "https://www.infoq.cn/article/4Kit4g9LF3TX4JrJ4MS2",
    "summary": "<p>采访嘉宾 | XTransfer高级技术总监田天、技术专家皇志豪</p><p>编辑 | 闫园园</p><p>&nbsp;</p><p>据中商情报网 2022 年中国跨境支付市场规模及投融资情况预测分析，近期国内支持政策接连出台，促使跨境电商发展迅速。在此背景下，跨境支付市场也迎来爆发，具体数据显示，预计 2022 年中国第三方跨境支付市场规模将达 12953.42 亿元。</p><p>&nbsp;</p><p>跨境电商的快速发展使得跨境支付平台赛道备受关注。一般来说，跨境电商在交易模式上分为 B2B 和 B2C 。其中，相较于&nbsp;B2C，B2B 模式交易流程更复杂，这对B2B跨境支付的产品体验提出了更高的要求，因此，对于 B2B 跨境支付平台来说，前端的打造显得尤为重要。</p><p>&nbsp;</p><p>近期，InfoQ 采访了 XTransfer（上海夺畅网络技术有限公司），XTransfer 通过分享前端方向的演进过程，带来了其设计驱动开发（Design Driven Development）的概念及相关实践经验。</p><p>&nbsp;</p><p>XTransfer 创立于 2017 年7月，聚焦于 B2B 跨境支付，为从事B2B跨境电商出口的中小微企业提供提供跨境支付及风控服务。</p><p></p><h2>XTransfer 前端发展的两个阶段</h2><p></p><p>&nbsp;</p><p>早期，XTransfer 整体技术发展经历了从 0 到 1 的过程。随着业务的拓展和产品的升级，前端方向的演进也经历了两个阶段：</p><p>&nbsp;</p><p>第一阶段：XTransfer 聚焦于 to B 业务，相继推出了 PC 端和 APP 端产品。这时，前端方向更多专注于核心功能的实现，包括收款、转账、提现、换汇等；第二阶段：随着业务的拓展，更多产品推出，形成满足企业用户需求的产品体系。在支持原有产品功能的基础上，前端方向开始更加注重提升整个产品体系的用户体验。</p><p>&nbsp;</p><p>在这两个阶段中，为了满足具体要求，前端的技术架构也随之发生了变化：</p><p>&nbsp;</p><p>在 XTransfer 产品网站推出第一版时，React 的一个 SPA 应用，就能够支撑起平台的业务需求。随着业务线的不断拓展，单页应用无法承载越来越庞大的业务，“当时整个前端打包最慢的时候，大概要一个小时。”田天回忆道。在这种情况下，XTransfer 团队开始着手对前端整体架构进行优化，“我们应用了微前端架构，拆分成多个应用，再加上一系列打包优化，目前打包速度已经控制在 10 分钟以内”。</p><p>&nbsp;</p><p>然而，虽然前端团队已经在技术架构上做出了改变来应对需求的变化，但前文提到 B2B 模式本身交易流程非常复杂，使得前端架构的构建过程中依然会面临诸多挑战，这些挑战大多来自以下两个方面：</p><p>&nbsp;</p><p>业务侧。第一，多产品化。虽然 XTransfer 平台专注做 to B 业务，但随着本身产品越来越丰富，同样会面临着 与to C 业务一样的多产品化问题。第二，需求复杂化。随着企业用户的增多，用户的不同习惯和需求对原本积累的开发模式造成了很大的冲击。</p><p>&nbsp;</p><p>技术侧。随着产品的快速增加，原有的开发模式遇到了困难。原本小而精的团队可以不断打磨用户体验，但随着产品的不断发展，如何在保证质量的基础上快速开发，是团队的重要课题。与 to C 业务不同的是，to B 业务并不能依靠简单的堆代码、堆人、堆团队的方式去解决这个问题。原因在于 to B业务面对的用户是同一类型的用户，不同产品要保证类似的功能复杂度，否则用户会明显感受到质量下降，从而带来比较差的用户体验。所以，在原来产品的技术沉淀难以在新产品上快速复制的情况下，对于团队的整体交付能力也提出了大的挑战。</p><p></p><h2>设计驱动开发（Design Driven Development）介绍</h2><p></p><p>&nbsp;</p><p>为了解决上述问题， XTransfer 提出了设计驱动开发（Design Driven Development，本文中简称 DDD）的概念。</p><p>&nbsp;</p><p>什么是 DDD ？DDD 是 XTransfer 以前端页面功能设计为核心，自研的一套以低代码的方式生成功能页面的前端页面开发框架。其核心能力是通过自定义字段生成表单和页面，UI 设计师和运营人员可以通过拖拽的方式定制需要的页面模版，快速生成功能页面。</p><p>&nbsp;</p><p>“我们to B业务的产品，整个开发质量是稳定的，对业务也会有一定的沉淀。从中，其实能够提炼出一些标准的开发流程、开发模板和交互设计。”在谈及提出DDD概念的初衷时，田天表示。</p><p>&nbsp;</p><p>同时，田天介绍，在设计其他金融或数字化产品时，一些场景例如风控校验、营销内容等也是必要开发的，且开发流程也类似。所以，从这些场景中抽象出来开发流程，其实可以沉淀成低代码的基础设施，包括做一些可替换的组件。“在这些抽象之上，我们甚至可以提炼出整个业务的标准前端模式，让前端模式具象化，且能够落地，这也就是 DDD 实践的一些案例。”</p><p></p><h4>设计思路</h4><p></p><p>&nbsp;</p><p>在设计 DDD 时，首先 XTransfer 前端团队已明确的是，无法做一个在所有场景都通用的低代码平台。“低代码本身是为了降本增效，如果追求所有场景适用，反而会增加更多复杂流程。”皇志豪谈到。</p><p>&nbsp;</p><p>从底层实现来说，前端页面是由结构、表现、行为构成，其中，结构和表现可以利用 UI 组件予以抽象，但行为的抽象却是困难的，尤其是在复杂的业务场景中抽象。因此，从软件开发的角度来看，为了平衡复杂度和效率，低代码是在特定场景内的模型抽象。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f5/f5b4cf74f7f1374f17bfbc52d1cc6187.png\" /></p><p></p><p>“我们逐渐把某些场景内的模型抽象出来”，操作人员不需要了解开发知识，简单拖拉拽自定义 UI 组件的方式构建出描述页面排版、内容、样式、属性的 JSON&nbsp;Schema，持久化保存在服务端，当对应页面需要展示时，直接获取持久化存储的Schema数据并通过渲染器渲染到页面。</p><p></p><h4>实践之路</h4><p></p><p>&nbsp;</p><p>首先，在 DDD 技术选型中，XTransfer 前端团队采用了 Formily + Craft.js，Formily 是阿里开源的统一表单解决方案，Craft.js 是一款拖拽式的 JS 框架。</p><p>&nbsp;</p><p>为什么会选择这两个方案？皇志豪表示，在早期的开发过程中，团队遇到了一个特定场景，即用户在 XTransfer 的安信成CRM系统中录入客户信息。系统本身提供了一系列的常用字段供用户使用，但依然存在部分&nbsp;CRM 用户有更多的特定信息需要录入，且不同行业客户的需求点各有不同，而这就需要团队提供动态的字段以及动态表单的抽象模型。因此，在业务场景的驱动下，前端团队开始着手调研多种方案去解决这个问题，包括现有开源方案以及自建等。</p><p>&nbsp;</p><p>“经历一系列方案筛选之后，我们觉得 Formily+ Craft.js&nbsp;就是理想型的表单解决方案。”皇志豪介绍道。他表示 Formily 能够提供抽象 Form 表单的能力，而 Craft.js 的页面画布与拖拽组件结合的能力，也是团队在完成DDD构想必不可少的构件。对于&nbsp;Craft.js，目前在国内应用的还比较少，“但不妨碍它作为一个很好的构建低代码平台的工具”，皇志豪表示。</p><p>&nbsp;</p><p>总的来说，Formily + Craft.js 可以提供给用户一个拖拽式生成表单的体验，因此也成为 XTransfer 平台自定义表单的技术选型。同时，围绕DDD核心逻辑，XTransfer还有更多前端应用场景可以被适配，在做好组件的抽取与粘合、控制复杂度与灵活性、提供安全隔离的基础上，DDD将在更多方向上有拓展与演化的空间，例如，在跨境领域，涉及国际化多语言、多客户端的场景开发，可有效提升研发效率，降低开发成本。</p><p>&nbsp;</p><p>当然，在选型过程中，早期 XTransfer 前端团队也考虑到了自建方案，并曾自研了一套自定义表单，但进行调研时，团队经过对比最终选择了已经相对较为成熟的Formily 。田天对此表示，前端这个领域，需要结合众家之长，形成自己一套独特的开发思路、方法和框架。</p><p></p><h4>应用现状</h4><p></p><p>&nbsp;</p><p>目前，DDD 的应用场景主要分为三方面，分别为对用户、对运营者以及对开发者：</p><p>&nbsp;</p><p>用户方向。即上文提到的用户在 XTransfer 的安信成&nbsp;CRM 系统中录入客户信息，用户可以在 CRM 系统中自己操作生成页面，选择使用哪些 label 和表单。运营方向。在内部运营平台上，运营者可以通过拖、拉、拽等方式生成营销模板，营销模板里可以配置不同的营销活动。开发者方向。除了上述应用场景之外，开发者方面可以预先定义好相关组件，通过拖拉拽的方式，快速去生成页面的整体框架，再做细节的微调。</p><p>&nbsp;</p><p>“在功能的支持上，对用户来说，不会给他们提供太强的灵活度，相对来说比较标准化，但是对于内部开发者和运营人员来说，功能就相对比较复杂了。”田天补充道。</p><p>&nbsp;</p><p>可以看到，现阶段 DDD 已经成为构建 XTransfer 平台的重要工具。但众所周知，低代码平台更多的还是前端生成页面的能力，因此，在应用过程中会有后端权限管理、数据安全、风控等功能点嵌入到其中。而如何将 DDD 与其他中台能力结合起来，成为团队面临的一个重要技术挑战。</p><p>&nbsp;</p><p>对此，田天坦言，现阶段这部分也在逐步完善中，“第一阶段前端生成页面，同时我们也在考虑，哪些服务能力可以同时嵌进去，比如其他中台服务承载的权限管控等如何与 DDD 结合，也是团队目前正在重点关注的。”</p><p></p><h2>未来规划</h2><p></p><p>&nbsp;</p><p>谈及未来，除了要不断完善 DDD 与其他中台的整合能力，前端团队对于 DDD 也有着更多期望，这里两位嘉宾也与大家分享了 DDD 中长期规划：</p><p>&nbsp;</p><p>首先，扩大应用场景，例如可以将其应用在页面表单的拖拉拽预生成与搭建、营销活动的配置化生成平台、智能建站等多个场景中。</p><p>&nbsp;</p><p>其次，降低复杂度，使用流程标准化。对于非开发人员来说，用起来会更加简单、方便。</p><p>&nbsp;</p><p>“长期来看，我们想把它做成一个纯粹的平台，真正覆盖更多的场景。”田天表示，目前搭建好 DDD 只是 XTransfer 团队的第一步，真正想让其达到标准化还有很长的路要走，需要不断提高其一系列周边能力，比如监控能力、性能问题定位能力等。“只有解决这些问题，DDD 平台才能更稳健，用起来会更方便，也能够帮助 XTransfer 持续提升用户体验。”</p><p>&nbsp;</p><p>除此之外，在采访中，两位嘉宾也与我们交流了 XTransfer 平台整个大前端领域未来的规划：</p><p>&nbsp;</p><p>第一，产品层面。将平台沉淀的经验推广到更多端，包括H5、APP、小程序，以及目前相对投入占比较少的桌面端。</p><p>&nbsp;</p><p>第二，战略层面。为了满足海外业务拓展的需求，实现用同一套流程、组件库和开发模式去适应不同国家用户习惯和产品方案。</p><p>&nbsp;</p><p>第三，开发者层面。持续优化开发体验，包括多端复用、升级新工具、技术栈，不断丰富前端基建等，以便给开发人员更好的体验。</p><p></p><h2>写在最后</h2><p></p><p>&nbsp;</p><p>当下，数字化转型浪潮来袭，产品需求不断增加。如果所有产品都要从头开发，极大的工作量也会成为开发者们的重要挑战，因此也产生了降低开发门槛、简化开发流程的诉求。DDD 作为 XTransfer 团队自研框架，目前已帮助其在保障用户体验的前提下，整体提升了前端研发的开发效率、体验，对于跨境支付行业来说，也是一次重要的尝试和突破。</p><p>&nbsp;</p><p>当然，也正如两位嘉宾在采访中谈到，现阶段的 DDD 也只是开始，真正想达到标准化，还有很长的路要走，仍需要持续不断地解决很多周边问题，包括如何嵌入后端权限管理、数据安全、风控等功能点等。不过在此过程中，团队积累的经验或许能够给更多支付及金融行业产品的构建带来启示，未来，InfoQ 也将持续关注。</p><p></p><h5>嘉宾介绍：</h5><p></p><p>&nbsp;</p><p>田天</p><p>现担任 XTransfer 高级技术总监，主要负责 XTransfer 智能金融研发部管理工作，致力于打造智能化的中小微外贸企业跨境金融服务平台。在 IT、金融和互联网领域有近 20 年的从业经验。</p><p>&nbsp;</p><p>皇志豪</p><p>现担任 XTransfer 技术专家，主要负责 XTransfer 前端研发工作，经历 XTransfer 前端体系从零到一的搭建，领导了多项核心技术在 XTransfer 前端的落地。</p>",
    "publish_time": "2022-07-04 17:32:44",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]