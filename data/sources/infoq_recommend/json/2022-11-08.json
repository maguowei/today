[
  {
    "title": "架构师（2022年11月）",
    "url": "https://www.infoq.cn/article/57l28ax6StEFl4TKSZ61",
    "summary": "<h2>卷首语：专访“MySQL 之父”：要拥有一份能做一辈子的开发工作，需要给自己积累名望</h2>\n<p>“热爱”，是贯穿于“MySQL 之父” Monty 过往 40 年编程人生的关键词。</p>\n<p>60 岁的 Monty 现在仍在写代码，每周保持 60 个小时的高工作强度。他说，等到 80 岁时，才会考虑将工作缩短到 35 小时。编程这事儿，他还要干一辈子。</p>\n<h4>二十年磨一剑</h4>\n<p>InfoQ：您在 34 岁时开发出了 MySQL。从接触编程到开发出 MySQL，这段时间可真不短，您都做了哪些工作？</p>\n<p>Monty：我从 18 岁的时候就开始编写 MySQL 的最早一批代码了，这部分代码主要是 MySQL 内存控制方面的，所以最早的开发工作可以追溯到 1982 年左右。</p>\n<p>后来的开发工作都是以之前的成果为基础。在此期间，我也开发过不少硬件驱动程序，设计了一款不错的处理器，还做过很多游戏。</p>\n<p>InfoQ：这么长的开发历程，是什么让您一直坚持了下来？</p>\n<p>Monty：我想，是热爱。我喜欢做开发，我特别喜欢解决问题的感觉，特别是在开发 MySQL 和 MariaDB 的过程中。而且，我参与了开源，帮助很多人走向成功。我觉得这一切都能让人始终保持热情。</p>\n<p>InfoQ：从您写下第一行代码到开发出 MySQL，花费了近二十年时间。但目前市场上也有不少企业投入过十年甚至十五年来开发软件，但最终成果从来没能真正流行起来。你怎么看待这样的现实？</p>\n<p>Monty：我确实是用了快二十年才开发出 MySQL，但当时我没有想到未来这个软件会发展成什么样子。我将我的软件卖给了北欧最大的一家电脑公司，但后来，我的软件成了整个平台上最受欢迎的产品。</p>\n<p>你提到的这种情况也的确存在，很多公司耗时耗力，最终却一无所获。MySQL 的成功是与时代背景分不开的。当时互联网已经得到广泛认可，每个人都需要这样的数据库，用它创建互联网所需要的数据。当时那些技术巨头还不看好互联网，所以这是个有待开发的蓝海市场。</p>\n<p>其实只要意识到需求的存在，其他的就都好办了，所以我从 94 年开始正式编写MySQL。最终成果的发布大概是在 95 年末，也就是说，我们用了短短两年就开发出了 MySQL 的第一个版本，成为当时的新兴支撑性产品。</p>\n<p>InfoQ：技术圈内，您被誉为“编程天才”，您怎么看待这样的称呼？</p>\n<p>Monty：我觉得差不多，我在编程方面确实有点小天赋。</p>\n<p>InfoQ：我想不只是编程这一个领域吧，您在创业方面也很成功啊。</p>\n<p>Monty：嗯，我在企业家、开源倡导者、程序员和架构师几个角色上表现得都还可以。</p>\n<p>InfoQ：您是否会认为，如果一个人想在某个领域取得卓越的成就，天赋是不是比努力更重要？</p>\n<p>Monty：那是肯定的。毕竟在编程行业，一个优秀的程序员要胜过十个普通的程序员。这种优秀，源自天赋、努力工作，更源自想要了解一切的学习精神。</p>\n<p>所以在前二十年里，我每天基本上就是学习计算机、学习硬件、学习如何高效编程，学习怎么让计算机发挥出一切性能。有了这样的底子，我才能真正开始做自己的事。</p>\n<h4>转管理，不是程序员的尽头</h4>\n<p>InfoQ：从 MySQL 到 MariaDB，您已经证明了自己是位成功的企业家。但不是所有技术人员都能成长为管理者，在这方面您能不能分享一点经验？</p>\n<p>Monty：我觉得大多数开发人员就适合当开发者。</p>\n<p>我知道，一直都有些开发者屈服于现实，转而去做管理岗。但根据我的观察，他们大多数人的编程才能其实比管理才能要强得多。很多人就是为了钱，管理岗的收入应该是比开发者要高一些。</p>\n<p>但我觉得他们的天赋主要还是体现在开发上，最好能坚持下去，依靠自己的才能走向成功。</p>\n<p>InfoQ：您在 34 岁，也就是快接近中年时才开发出 MySQL。但在中国市场，35 岁以上的开发者往往会考虑转向管理岗。您怎么看待这种现象？</p>\n<p>Monty：我认为不应该这样。因为好程序员，特别是优秀的程序员其实更难找。虽然管理岗的薪水可能稍高一点，但却很容易被取代。所以只要大家有天赋，最好能坚持在技术的道路上走下去。</p>\n<p>至于 MySQL 这边，其实我从来不想当 CEO。我想做的是 CTO，负责技术方面的工作，毕竟我的天赋就在技术上。我觉得自己没有那份成为优秀全职管理者的天分。</p>\n<p>我把一生都投入到写代码上，我喜欢这活儿，也正是编程让我成为了独一无二的人。</p>\n<p>InfoQ：如您所说，转到管理岗后，就会得到更多资源，比如晋升机会更大、薪酬更高。相比于技术理想，这是很现实的考量，毕竟大部分人要养家糊口，您怎么看呢？</p>\n<p>Monty：我觉得很多企业在职业设计上都有这种错误。所以在 MySQL 和 MariaDB，我觉得与其靠让大家做管理来提升薪水，不如让他们承担起更多责任。有时候，职位的重要性比单纯的高薪水更有吸引力。这可以算是另一种思路吧。</p>\n<p>大家当然应该为自己的编程事业规划一条职业发展道路，但没必要把转管理岗当成唯一的方向。企业不需要那么多经理，而且在开始裁员的时候，管理岗都是最先倒霉的。毕竟经理人很容易替代，但优秀的程序员不可替代。他们掌握着企业最需要的代码知识，所以只要代码在，那岗位就在。</p>\n<h4>编程 40 年，如何保持技术前瞻性？</h4>\n<p>InfoQ：您的编程经历大概有四十年了。在这么长的从业过程中，您是怎么保持自己的技术前瞻性的？</p>\n<p>Monty：我的办法是信任客户。我的想法一直很坚定，那就是跟客户合作、解决问题，了解他们未来可能遇上的新问题，再共同将其克服。</p>\n<p>所以只要有了良好而且足够广泛的用户群体，比如 MySQL 和 MariaDB 建立起的客户基础，那他们就能告诉我，未来会走向哪里。</p>\n<p>我在等待未来的到来，同时也成为造就未来的一部分。所以，认真倾听客户意见，与他们合作，自然就能了解最新的技术。跟客户距离越近，我们就越了解功能需求，并据此安排自己的工作。</p>\n<p>对于开发者，我们要做的是为他们提供正确的技术、让他们满意。总之，只要明确了需要解决的问题，技术选型自然就会容易得多。</p>\n<p>InfoQ：那您会常跟社区中的开发者讨论技术问题吗？</p>\n<p>Monty：我经常参与技术会议，在那里跟与会者们交流。这也算是一种探讨吧。</p>\n<p>另外，在接触世界各国的客户，比如中国的客户时，也可以跟内部员工讨论关于 MySQL 和 MariaDB 的问题。他们代表的就不是客户，而是社区成员。所以我会认真倾听。</p>\n<p>InfoQ：对于想要学习 MariaDB 或 MySQL 的中国开发者，您有什么建议吗？</p>\n<p>Monty：首先应该积极参与到社区当中，帮助他人、改进实现。如果你需要某项功能，就想办法着手开发，并随时向 MariaDB 基金会寻求帮助。我们可以帮助大家，告诉你具体该怎么做。你审查过自己的代码吗？你也可以参与审查其他贡献者的代码，这就是实实在在的开源贡献。</p>\n<p>而要想成为一名出色的程序员，拥有一份能做一辈子的开发工作，那最好能让自己积累起名望，让自己在开源世界拥有一席之地。有了这些积累，就不是你找工作，而是工作来找你了。保持住好奇心，积极探索事情是如何运作的，这样我们就会变得更好，对企业的价值也越大。</p>\n<p>本文节选自InfoQ《专访“MySQL 之父”：我曾创造 MySQL，也将颠覆 MySQL》，作者：李冬梅。</p>\n<p><strong>目录</strong></p>\n<p><strong>热点 | Hot</strong></p>\n<p>DevOps 已死，平台工程才是未来</p>\n<p>上云“被坑”十年终放弃，寒冬里第一轮“下云潮”要来了？</p>\n<p>那位用 Rust 重写数据库的创始人来复盘了：删除 27 万行 C++ 代码，值吗</p>\n<p><strong>理论派 | Theory</strong></p>\n<p>字节大规模微服务语言发展之路</p>\n<p>去哪儿网 Service Mesh 落地实践：100% 容器化打底，业务友好是接入关键</p>\n<p><strong>推荐文章 | Article</strong></p>\n<p>新一波 JavaScript Web 框架</p>\n<p>字节跳动开源 BitSail：重构数据集成引擎，走向云原生化、实时化</p>\n<p><strong>观点 | Opinion</strong></p>\n<p>当“增加人员”不足以解决问题，你就该考虑应用“微前端”了</p>",
    "publish_time": "2022-11-08 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Docker 发布首个支持 WebAssembly 支持工具预览版",
    "url": "https://www.infoq.cn/article/fc9kVXeSj3gylssSHFMD",
    "summary": "<p>在KubeCon NA 2022大会的<a href=\"https://youtu.be/3j915xoDovs\">云原生Wasm活动日</a>\"中，Docker宣布与CNCF Wasm运行时项目<a href=\"https://github.com/WasmEdge/WasmEdge\">WasmEdge</a>\"合作推出<a href=\"https://www.docker.com/blog/docker-wasm-technical-preview/\">Docker+Wasm技术预览</a>\"。只需一个命令docker compose up，Docker开发人员就可以立即构建、分享和运行一个完整的Wasm应用程序。</p><p>&nbsp;</p><p>Wasm最初是作为Web浏览器的安全沙盒开发的。近年来，作为VM和Linux容器（LXC）的一个安全、轻量级、快速、可移植的替代方案，它在服务器端找到了许多应用场景——这一领域最初是由Docker开创的。</p><p>&nbsp;</p><p>Second State提供了一个<a href=\"https://github.com/second-state/microservice-rust-mysql\">标准的Docker+Wasm演示应用程序</a>\"。这是一个数据库驱动的Web应用程序，它包含一个用于运行整个Web服务（微服务）的WasmEdge“容器”，以及两个用于运行支持服务的Linux容器（一个用于MySQL数据库，一个用于为前端UI提供静态HTML页面的NGINX）。这三个容器在同一个网络中并行运行，共同组成一个应用程序。微服务用Rust编写，并编译成Wasm。它有一个高性能（非阻塞）的HTTP服务器、一个事件处理程序（处理HTTP请求的业务逻辑）和一个MySQL数据库客户端。整个“容器化”的微服务只有3MB，而相比之下，数据库和NGINX的Linux容器则有数百MB。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2c/2c6238b0c85c353ea41e674e43e5f6bf.png\" /></p><p></p><p>图片来源：<a href=\"https://www.docker.com/blog/docker-wasm-technical-preview/\">Docker+Wasm技术预览简介</a>\"</p><p>&nbsp;</p><p><a href=\"https://github.com/docker/compose\">Docker Compose</a>\"不仅能将Wasm应用程序和容器一样运行，还会将Rust源代码构建为Wasm。开发人员甚至不需要安装Rust编译器工具链，因为Docker也已将整个构建环境容器化。Docker + Wasm是一个单独的工具，负责构建和运行Wasm应用程序。</p><p>&nbsp;</p><p>随着Docker发起了容器革命（导致了云原生时代的到来），Docker<a href=\"https://docs.docker.com/desktop/wasm/#running-a-multi-service-application-with-wasm\">在“多运行时”世界</a>\"中支持Wasm的努力变得特别有意义。</p><p></p><p></p><blockquote>Docker+Wasm的发布非常有意义。我们不再生活在单运行时的世界中，我们有Linux容器、Windows容器和Wasm容器。OCI可以打包它们，@docker可以构建和运行它们。—— Docker联合创始人<a href=\"https://twitter.com/solomonstre/status/1584817684172005376\">Solomon Hykes</a>\"</blockquote><p></p><p></p><p>Docker+Wasm背后的技术主要来自开源社区。例如，Docker依赖一个名为<a href=\"https://github.com/second-state/runwasi\">runwasi</a>\"的Containerd shim（<a href=\"https://github.com/deislabs/runwasi\">最初由微软的DeisLabs创建</a>\"）来启动WasmEdge并执行Wasm程序。</p><p>&nbsp;</p><p>开源工作已远远超出了Docker。例如，Red Hat团队已经<a href=\"https://opensource.com/article/22/10/wasm-containers\">将Wasm运行时支持集成到OCI运行时crrun</a>\"中。这<a href=\"https://wasmedge.org/book/en/use_cases/kubernetes.html\">使得整个Kubernetes栈能够完美支持WasmEdge应用</a>\"。事实上，在KubeCon活动的前几天，Liquid Reply团队已经演示了使用WasmEdge的<a href=\"https://github.com/KWasm/podman-wasm\">Podman+Wasm</a>\"。</p><p>&nbsp;</p><p>KubeCon活动上还演示了其他Wasm应用，包括：<a href=\"https://github.com/WasmEdge/wasmedge_hyper_demo/tree/main/server-tflite\">AI推理</a>\"应用、<a href=\"https://github.com/second-state/dapr-wasm\">基于Dapr的微服务</a>\"和<a href=\"https://github.com/second-state/MEGA\">流式管道中的数据处理功能</a>\"。现在，开发人员可以使用Docker+Wasm轻松地构建、分享和运行这些应用程序了。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/11/docker-webassembly/\">https://www.infoq.com/news/2022/11/docker-webassembly/</a>\"</p>",
    "publish_time": "2022-11-08 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "解读Gartner 2023 年十大战略技术趋势",
    "url": "https://www.infoq.cn/article/QeEpTFuWHJC2s7k8K7Rv",
    "summary": "<p>前不久，Gartner对外发布了<a href=\"https://www.infoq.cn/article/RPeJFB2plzMHEvWQkpmS\">企业机构在 2023 年需要探索的十大战略技术趋势</a>\"。根据Gartner的调研，全球绝大部分的CEO都认为2023年全球经济可能会出现衰退。因此，整份报告以“如何应对未来的不确定性”为主题，从业务目标的角度试图理清楚“三大主题、十大方向”，进而帮助企业渡过难关。本文，InfoQ试图通过Gartner分析师的分享为大家解读这十大技术趋势的具体含义。</p><p></p><h2>主题一：优化</h2><p></p><p></p><h3>1.数字免疫系统</h3><p></p><p>“数字免疫系统”的概念最早于上世纪90年代被提出，当时指的是一套完全自动化的防病毒解决方案。但是今天的“数字免疫系统”指的是一套用来构建稳定系统的软件工程方法、技术和实践。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f7/f75e43eecba896211bd1f8b06c10467d.png\" /></p><p></p><p>在传统的软件工程领域，我们主要依靠一套基于测试的软件质量体系来保证软件的健壮性。而今天光靠测试已经不够了，“数字免疫系统”意味着通过给向数字免疫系统“打疫苗”这种类似的手段，来提高系统的健壮性。当然，这确实并不是单个技术，而是包含六大核心模块的一套组合打法。这六大核心模块分别是可观测性、人工智能增强测试、混沌工程、自动修复、站点可靠性工程以及应用供应链安全。</p><p>&nbsp;</p><p>以下为部分模块介绍：</p><p>&nbsp;</p><p>（1）可观测性</p><p>&nbsp;</p><p><a href=\"https://www.infoq.cn/theme/134\">可观测性</a>\"的概念起源于几十年前的“控制论”，其含义是通过检验一个系统外部输出的数据或信息去推断或者衡量系统内部状态，这样的系统称之为“可观测的系统”，这种方法叫作“可观测性”。</p><p>&nbsp;</p><p>（2）混沌工程</p><p></p><p>“混沌工程”的理念最早是由互联网公司Netflix（奈飞）创造的，其含义是在系统里面放进一只捣乱的猴子，这只捣乱的猴子在系统中上窜下跳直到搞挂系统。我们会用这种方法测试系统的不确定性，或者说通过传统方式无法检测出的隐患。“混沌工程”在实践过程中与传统的测试会共用很多测试工具，例如错误注入工具等。但是这两者之间的思想是有本质区别的，因为传统测试主要基于“预设条件输出”的方法来判断测试是否出错。也就是说，测试时需要对所有可能出现的情况进行预估、预评判，而混沌工程则是在没有预设条件的情况下逐步测试系统的稳定性以及系统未知的脆弱。</p><p>&nbsp;</p><p>（3）站点可靠性工程</p><p>&nbsp;</p><p>这是谷歌提出来的理念，其思想是用软件工程的方法解决复杂的运维问题。在传统的运维模式下，很多工作是通过人工操作来完成的，而“站点可靠性工程”强调通过开发一些自动化工具来替代人工操作。谷歌公司的运维团队（SRE）要求平时的运维工作要限制在50%的时间以内，另外50%的时间开发一些自动化的工具用来减少人工干预。这种模式不仅降低了人力成本，而且解决了运维与开发之间的一些矛盾。</p><p></p><h3>2.应用可观测性</h3><p></p><p>&nbsp;</p><p>“可观测性原理”是通过观察系统外部输出的信息来判断系统内部的状态，进而优化系统，当我们将这种理念从单纯的“IT观察”或者“IT监控”的角度推广到企业运营中去的时候，我们将其叫作“应用可观测性”。</p><p>&nbsp;</p><p>企业中每一个决策的发生都会产生相应的数据结果。即使我们不知道决策是什么，或者即使决策的执行和计划有出入，但最终都会通过数据的形式反馈给我们真实的数据结果。当我们收集到这些输出的反馈数据结果以后，可以叠加“场景信息”，通过行业知识和对行业的理解，对数据进行解读，应用AI分析的方法给决策提供建议，实际上就是为了优化决策。优化完决策之后，这个决策会被再次执行，生成更多数据，我们就可以此创作出反馈循环进而做出更加精准的数据驱动决策。</p><p></p><h3>3.AI信任、风险与安全管理</h3><p></p><p>&nbsp;</p><p>如今，AI的应用变得越来越广泛。对于AI应用、AI模型背后的“可解释性”或者说“公平性”，实际上存在一些问题。比如，一些互联网电商巨头可以通过AI系统追踪每一名物流仓储部门员工的工作效率，统计每一名员工的“摸鱼时间”，然后自动生成解雇指令。用这种AI程序的方法去决定一个人的招聘或者解雇，不禁让人疑惑应用的算法是否公平。</p><p>&nbsp;</p><p>事实上，许多企业机构未做好管理 AI 风险的充分准备。Gartner 在美国、英国和德国开展的一项调查显示，41%的企业机构曾经历过 AI 隐私泄露或安全事件。但该调查也发现积极管理 AI 风险、隐私和安全的企业机构在 AI 项目中取得了更好的成果。与未积极管理这些功能的企业机构的 AI 项目相比，在这些企业机构中有更多的 AI 项目能够从概念验证阶段进入到生产阶段并实现更大的业务价值。</p><p>&nbsp;</p><p>企业机构必须使用新的功能来保证模型的可靠性、可信度、安全性和数据保护。AI 信任、风险和安全管理（TRiSM）需要来自不同业务部门的参与者共同实施新的措施。</p><p></p><h2>主题二：扩展</h2><p></p><p></p><h3>4.行业云平台</h3><p></p><p>&nbsp;</p><p>“行业云平台”本质上是一种新的“云服务”模式，这与传统模式的区别在于：我们一般会把“云服务”分成三层（IaaS层、PaaS层、SaaS层）。常见的应用方法是在IaaS层和PaaS层之上构建自己的应用，这是一种路径。另外一种路径是直接采购一站式的SaaS解决方案，这样就不需要担心基础设施的事情、反正厂商已经做了定制化的方案。</p><p>&nbsp;</p><p>“行业云平台”本质上是在这两者当中找到一个新的细分市场，结合了现在公有云的IaaS+PaaS层，然后以此作为技术底座，其上的SaaS部分并不是给企业提供一个一站式的方案，而更像是把SaaS里面具体化的定制化方案拆解开来变成可重复使用的业务功能模块，企业根据此做自定义的研发，这种模式比今天的“IaaS+PaaS模式”多了更多业务功能，但是比今天的SaaS模式更加灵活，实际上是介于这两种模式之间的一种新的“云服务模式”。</p><p></p><h3>5.平台工程</h3><p></p><p><a href=\"https://www.infoq.cn/article/7porVp7qVF03BVc2tDd6\">“平台工程”实际上是DevOps的补充形式。</a>\"DevOps之所以形成是因为企业希望将“运维”和“开发”两件事情融合起来。在这个过程中，有些企业应用DevOps比较成功，另外一些企业在应用DevOps的时候走了弯路。有些组织会把DevOps理解成：让开发人员去负责运维的工作。这种模式最大的问题在于给开发人员的负担太重了，因为许多开发人员并不太想处理这些运维的问题，也不太想去碰复杂的基础设施。更何况有些时候对于企业来说，开发周期是比较稀缺的资源。</p><p>&nbsp;</p><p>如果企业面临上述问题，可以尝试使用“平台工程”这样一种新的架构。“平台工程”本质上是通过工具和流程，为企业的软件开发团队提供自助开发门户或者叫“内部开发平台”，该平台实际上可以涵盖应用程序的整个生命周期，由专门的平台工程团队创建和维护，开发人员提交代码后，由平台上的自动化工具负责做自动化发布。对开发人员而言，这样可以避免在运维流程过多介入，同时不需要触碰底层的基础设施。</p><p></p><h3>6.无线价值实现</h3><p></p><p>由于没有一项技术能够占据主导地位，企业将使用一系列无线解决方案来满足办公室 Wi-Fi、移动设备服务、低功耗服务以及无线电连接等所有场景的需求。Gartner 预测，到 2025 年，60%的企业将同时使用五种以上的无线技术。</p><p>&nbsp;</p><p>“无线价值实现”本质上指现在各种各样的无线协议变得越来越成熟，甚至已经可以给我们带来一些落地的商业价值。当然，这种商业价值很多时候还是以一种比较碎片化的形式出现，不是“一站式的解决方案”，更多的是一些垂直的碎片化方案。&nbsp;</p><p></p><h2>主题三：开拓</h2><p></p><p></p><h3>7.超级应用</h3><p></p><p>“超级应用”实际上是从中国传出来的技术趋势，最大的案例是支付宝和微信。这些超级应用都有巨量的用户、流量以及很强的小程序生态。这种趋势也被众多西方国家仿效，很多企业在复制这种模式。</p><p></p><h3>8.自适应AI</h3><p></p><p>&nbsp;</p><p>“自适应AI”本意是传统的AI系统需要面对不断变化的环境，具体要求为：一是模型训练好以后，由于外部环境不断改变，模型是否可以继续应用到不断变化的环境中；二是模型训练好以后，需要添加更多的训练数据迭代模型，但是我们现在看到很多的训练数据都是一些小数据而非大数据；三是希望模型最后在推理的时候产生一些个性化的结果，而非一般化的结果。这三个新的要求实际上对AI模型来说是希望模型训练和推理逐渐走向在线训练、在线推理。</p><p>&nbsp;</p><p>“在线推理”比较好理解，各大短视频或者电商APP会结合用户兴趣持续推荐可能感兴趣的内容；“在线训练”是指背后的AI模型需要实时更新，只有实时更新才能更好响应进一步输入的工作，进而让训练和推理形成正向循环，这个叫作“自适应AI”。</p><p></p><h3>9.元宇宙</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bf/bfbe36bf48ecc188ced22af269ceabc6.png\" /></p><p></p><p>Gartner定义的“元宇宙”是一个“虚拟共享空间”，这个“虚拟共享空间”有五个不同的维度（五个属性）：Persistent（持久性）；Immersive（沉浸式）；Device-independent，实际上是和设备无关的，现在看到的AR/VR眼镜只是早期“元宇宙”进入的一个端口；Not beowned by a singlvendor，不会被某一家厂商所垄断；Virtual economy，一个虚拟经济体，不只单纯的是一个游戏，更多的是跟物理世界平行的一个商业的数字世界。</p><p>&nbsp;</p><p>Meta的实践不是“元宇宙”所有的内涵，因为Meta走的技术路线更像是一个VR路线，而Gartner定义的“元宇宙”是一个“虚实结合”的路线，Gartner有三个“T”：Transform、Transport、Transact。Transport的意思是将人传送到数字世界，VR更像是Transport；Transform的意思是将数字世界拉到物理世界里面，类似于AI的路径；Transact的意思是元宇宙不是另外一个更加高级的游戏，很大程度上是我们另外一种生活方式。</p><p>&nbsp;</p><p>很多时候，我们会认为“元宇宙”这样的一个趋势离我们好像有点远，但是实际上也并不完全是这样，一些新的商业模式还是比较有希望的，比如“数字人”、“工业元宇宙平台”等。</p><p>&nbsp;</p><p>以“工业元宇宙平台”为例，西门子和英伟达联手创作了“工业元宇宙平台”。西门子作为制造业的巨头有很多制造业的经验可以用来输出，通过这种类似于系统化的或者是IT化的方式赋能其它行业，而英伟达主要提供算力资源。“工业元宇宙”实际上面对的场景非常复杂，可能是工厂中的一条流水线需要改造，在改造的过程中传统做法是把现在的流水线停掉，然后再改造、试运行、投产，这个过程实际上浪费了大量的金钱和时间成本，如果可以做一个数字化的平台，高度模拟和仿真现有流水线的情况，并且在“数字世界”里将流水线先改造，做一些虚拟制造或者做模拟制造，模拟测试没问题之后再对物理空间中的真正流水线开始动手改造，效率会提高很多，时间也会省很多，成本也会降很多。</p><p>&nbsp;</p><p>“工业元宇宙”的商业逻辑是合理的，但可能存在行业化的问题，这取决于厂商本身是做什么的，如果跨到不太熟悉的行业，难度会非常高。</p><p></p><h3>10.可持续的技术</h3><p></p><p>&nbsp;</p><p>“可持续性”这件事情实际上是全球很多企业都在谈的一个问题，这个问题对于中国的客户、企业或者场景来说，很多时候讲的是“双碳”。实际上我们做“双碳”也要看怎么做，做“双碳”不仅仅是为了保护环境，更多是为了保证能源安全。能源安全的自主可控实际上是一个很大的国家战略问题。很多企业其实在做“绿色数据中心”有关的事情，如果眼光放长远去看，利用一些可持续的技术主动把“碳”减下来，减下来的“碳”可能会变成企业另外一个收入来源。</p><p>&nbsp;</p><p>在其他条件同等的情况下，注重“双碳”层面投入的企业也更有可能获得企业和投资者的青睐。</p>",
    "publish_time": "2022-11-08 11:15:29",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "乾象投资：基于JuiceFS 构建云上量化投研平台",
    "url": "https://www.infoq.cn/article/owwaIZuU262HfUFFy8pd",
    "summary": "<p>乾象投资 Metabit Trading 成立于2018年，是一家以人工智能为核心的科技型量化投资公司。核心成员毕业于 Stanford、CMU、清北等高校。目前，管理规模已突破 30 亿元人民币。</p><p></p><p>Metabit 非常重视基础平台的建设，有一支强大的 Research Infrastructure 团队。团队试图打破在单机上进行研发的壁垒，利用云计算进行更高效、安全的工具链研发。</p><p></p><h2>01 量化的研究都在做什么</h2><p></p><p>作为一家成立时间不久的量化投资机构，我们在对基础存储平台进行选型时，会受到这样两方面的因素的影响：公司成立的时间比较短，没有太多技术上的历史负担，在做技术选择时，更偏向于使用更现代的技术栈；同时，量化投资中使用到的机器学习场景中的特性也会影响到技术的选择。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/02/0294b00d99531d907ac7273bcd8fba13.png\" /></p><p></p><p>上图是我们研究场景中和机器学习关联最紧密的策略研究模式的简化示意图。首先，在模型训练之前需要对原始数据做特征提取。金融数据的信噪比特别低，如果直接使用原始的数据进行训练，得到的模型噪音会非常大。原始数据除了行情数据，即大家经常会看到的市场上的股价、交易量之类的数据，也包括一些非量价的数据，比如研报、财报、新闻、社交媒体等之类的非结构化数据，研究人员会通过一系列的变换提取出特征，再进行 AI 模型训练。</p><p></p><p>模型训练会产出模型以及信号，信号是对未来价格趋势的判断；信号的强度意味着策略导向性的强度。量化研究员会根据这些信息去优化投资组合，从而形成交易的实时仓位。这个过程中会考虑横向维度（股票）的信息来进行风险控制，例如某一行业的股票不要过度持仓。当仓位策略形成之后，量化研究员会去模拟下单，而后得到实时仓位对应的盈亏信息，从而了解到这个策略的收益表现，以上就是一个量化研究的完整流程。</p><p></p><h3>量化研究业务特点</h3><p></p><p></p><p>研究需求产生大量突发任务：高弹性&nbsp;</p><p>在策略研究的过程中，量化研究员会产生策略想法，他们会通过实验去验证自己的想法。伴随着研究人员新想法的出现，计算平台就会产生大量的突发任务，因此我们对计算的弹性伸缩能力的要求很高。</p><p></p><p>研究任务多样化：灵活性</p><p>从上面的例子可以看到，整个流程涵盖了非常多不同的计算任务，例如：</p><p>特征提取，时序数据上的计算；模型训练，经典的机器学习的模型训练场景；投资组合优化，会涉及到最优化问题的任务；策略回测，读入行情的数据，再对策略的表现去做模拟撮合，得到仓位对应的表现。</p><p>整个过程任务的种类是非常多样化的，对计算的要求也很不一样。</p><p></p><p>研究内容需要保护：模块化，隔离&nbsp;</p><p></p><p>研究员的投研内容是公司的重要 IP（知识产权）。为了保护这些知识产权，公司的研究平台会将每个策略研究环节抽象成包含标准输入输出和评价方式的模块。例如对模型的研究，输入标准的特征值，输出预测的信号和模型。通过对模块之间进行隔离，研究平台可以有效保护 IP 的安全性。在进行存储平台建设时，需要针对模块化这个需求做相应的设计。</p><p></p><h3>量化研究数据特点</h3><p></p><p></p><p>大量任务的输入来自于相同的数据，比如上文提到的回测，量化研究员需要对历史策略去做大量的回测，同样的仓位使用不同的参数去测试，观察它们表现；或者特征提取，经常有一些基础特征和新特征的组合，其中大量的数据是来自于相同的数据源。</p><p></p><p>以 A 股的股票为例：A股市场十年的分钟K线历史行情，5000/2股票240分钟250天10年8字节*20列=240GB，整体10年的数据量大约是 240G。</p><p></p><p>如果使用更细力度的数据，数据量就会更大，一般来说原始数据不会超过 100TB 的范围。在大数据时代这算不上是特别大的数据量，但是当大量的计算任务去同时去访问这些数据，这种场景就对数据存储的有一些要求。</p><p></p><p>另外，量化投研过程中伴随着大量的突发任务，研究团队希望能将这些任务的结果存储起来，因此会产生大量 archive 数据，但这些数据的访问频率很低。</p><p></p><h3>量化研究计算任务特点</h3><p></p><p>基于以上特点，如果以传统的机房方式，是很难去满足我们的计算需求，因此把计算搬到云计算平台对我们来讲是一个相对合适的技术选择。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/05/057d5601c903af4b82957113baa40d5e.png\" /></p><p>第一，突发任务多，弹性非常大。上图是我们某个集群近期的运行实例数据。可以看到在多个时间段里，整个集群实例都是被打满的状态，但是同时整个计算集群的规模也会有 scale 到 0 的时候。量化机构的计算任务和研究员的研发的进度是有很大关联的，波峰波谷的差距会非常大，这也是离线研究任务的特点。</p><p></p><p>第二，“技术爆炸”，很难准确预估何时会产生算力需求。“技术爆炸”是科幻小说《三体》的概念，对应到我们这就是我们的研究模式和算力的需求会发生飞跃式进步，我们很难准确预估算力需求的变化。我们在&nbsp;2020 年年初的时候，研究的实际用量和预估用量都非常小，但是当研究团队提出的一些新的研究方法思路之后，会在某个瞬间突然对算力产生非常大的需求。而容量规划是在建设传统机房的规划时候非常重要的一件事情。</p><p></p><p>第三，现代 AI 生态，几乎是搭载在云原生平台上的。我们做了很多创新的技术尝试，包括现在非常流行的 MLOps，将整套 pipeline 串联起来，再去做机器学习训练的流水线；现在很多的分布式的训练任务的支持，都是面向云原生去做了很多的开发工作，这也使得我们把整个计算任务放到云上成为一个很自然的选择。</p><p></p><h2>02 量化平台存储需求</h2><p></p><p></p><p>根据上面业务和计算的需求，可以比较容易的去推导出来我们对存储平台的需求。</p><p>计算与存储不均衡。上文提到计算任务会有很大的突增，计算量会很容易会达到非常高的水平。而热数据的增长量并没有那么快，这就意味着我们需要去做存算分离。为热数据，比如行情的数据，提供高吞吐的访问。上百个任务同时访问数据，对它吞吐要求非常高。为冷数据提供低成本存储。量化研究需要大量 archive 数据，也要为这些数据提供相对低成本的存储。文件类型/需求多样性即 POSIX 兼容性。我们有很多不同的计算任务，这些计算任务对文件的类型的需求是非常多样的，例如CSV、Parquet 等，有一些研究场景还有更灵活的定制开发的需求，这就意味着在选型的时候不能够对文件存储方式做严格限制，因此 POSIX 的兼容性对于存储平台选型是一个很关键的考量因素。IP保护：数据共享与数据隔离。我们 IP 保护的需求，不仅是计算任务上需要做这样的隔离，在数据上也是需要支持这样的隔离能力；同时对行情数据这类相对公开的数据，还需要支持研究员的获取方式是便捷的。AI 生态，在云的平台上去做各种任务的调度。这也是较为基础的一个使用需求，因此存储上也是需要对 Kubernetes 做很好的支持。模块化即中间结果存储/传输。计算任务模块化的场景，导致我们会对中间结果的存储跟传输也有需求。举个简单的例子，在特征计算过程中会生成比较大量的特征数据，这些数据会立刻用于被训练的节点上，我们需要一个中间存储介质去做缓存。</p><p></p><h2>03 存储方案选型</h2><p></p><p></p><h3>非 POSIX 兼容方案</h3><p></p><p></p><p>最初，我们尝试了很多对象存储的方案，也就是非 POSIX 的方案。对象存储有很强的扩容能力，而且成本非常的低，但是对象存储的问题也很明显。最大的问题就是没有 POSIX 兼容性。对象存储的使用方式跟文件系统有比较大的区别，如果把对象存储直接作为接口面向研究员，对他们来讲使用有很大的难度，便利性也有很大的限制。</p><p></p><p>除此之外，很多云厂商的对象存储有请求限制。例如，阿里云会对整个帐号的 OSS 带宽做限制。对于普通的业务场景这通常是可以接受的，但是突发性任务会在瞬时产生非常大的带宽需求，仅仅使用对象存储很难去支撑这类场景。</p><p></p><p>另一个方案是 HDFS ，我们在 HDFS 上面并没有做太多测试。首先，我们所采用的技术栈对 Hadoop 没有太强的依赖；同时， HDFS 对 AI 训练的产品的支持并没有特别突出，而且 HDFS 没有完整的 POSIX 兼容性，这对我们的使用场景会有一些限制。</p><p><img src=\"https://static001.geekbang.org/infoq/14/1491b9a378c69faf86c14106da1fca11.png\" /></p><p></p><h3>云上 POSIX 兼容方案</h3><p></p><p></p><p>上文中提到的业务特点决定了我们对 POSIX 兼容性有很强的需求，而且技术平台是基于公有云来进行的，因而我们将存储选型的范围确定为：云上兼容 POSIX。</p><p></p><p>云厂商会提供一些方案，比如像阿里云的 NAS，AWS EFS 之类；另外一类是像阿里云的 CPFS 方案，AWS 的 FSx 方案。这两类文件系统的吞吐是与容量强绑定的，当容量越大的时候，吞吐会越大，跟 NAS 的存储性质是直接相关的。这样的方案，在面对小量的热数据的时候不太友好，需要额外的优化才能达到比较好的表现。另外 CPFS 或者阿里云上的极速型 NAS，对低延时的读取很友好，但缺点是成本比较高。</p><p></p><p>就各自官网展示的价格，我们做了个对比。各类高性能 NAS 产品的成本大概是 1500-2000元/TB/月，JuiceFS 整体的成本会低很多，因为 JuiceFS 的底层存储是对象存储 。JuiceFS 的成本分成这样几个部分：对象存储的存储费用；JuiceFS 云服务的费用；以及SSD 缓存产生的成本。综合来看，JuiceFS 的整体成本远低于 NAS 和其他方案的成本。</p><p></p><p>在吞吐方面，早期做了一些测试，当节点数量比较少的时候，直接用 CPFS 跟做 JuiceF 对比，同时读取性能不会有很大的差异。但是当节点数变大之后，因为 NAS 类文件系统有带宽限制，读取时间整体都拉长了，而 JuiceFS 只要做好缓存集群的部署，可以非常轻松的支撑下来，并且没有太大的开销，下图场景是部署了总带宽约为 300Gb 左右的集群。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3c/3cac3b7902e46f3120ff5b0a73075186.png\" /></p><p>除了成本和吞吐以外，在技术选型时， JuiceFS 对上文提到的功能 Full POSIX、权限控制、Qos、Kubernetes 都能够比较好的支持；</p><p></p><p>值得一提的是JuiceFS 的缓存集群能力，它能够实现灵活的缓存加速。最开始时，我们使用计算节点做本地缓存，这是一个挺常见的做法。存算分离之后，希望计算节点有一些数据可以本地化，JuiceFS 这方面功能的支持是比较完善的，对于空间的占用、百分比的限制等都做得很完善。我们部署了独立的缓存集群去服务一些热数据，只要在使用之前去做缓存预热就可以了。在使用过程中，我们发现不同的计算集群资源的利用率差别很大，集群中有一些大带宽的机器，大部分时候都是用来做单节点的计算，这也就意味着机器的网络的资源基本上是没有怎么用到，而且还有一些闲置的磁盘，因此就在这些机器上去部署了缓存节点，把闲置的网络带宽给利用了起来。最终使得我们在同一个集群中，实现了一个带宽非常大的缓存集群。</p><p></p><p>目前 ，JuiceFS 被用在了以下生产场景：</p><p>计算任务的文件系统，应用于热数据输入；日志/ artifact 输出；Pipeline 数据中转：数据特征生成之后，需要中转到模型训练中，训练过程中也会有数据中转的需求，Fluid+ JuiceFS Runtime 作为中间的缓存集群来使用。</p><p></p><p>未来，我们将继续探索云原生、AI技术，用以进行更高效、安全的工具链研发和基础技术平台建设。</p><p></p><p>作者简介：&nbsp;</p><p>李健弘， Metabit Trading- Engineering manager of Research infra，专注于在量化研究领域搭建机器学习平台和高性能计算平台。在加入 Metabit Trading 之前，曾在 Facebook 担任高级工程师。</p>",
    "publish_time": "2022-11-08 11:37:46",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "开放域多轮、多模态融合、拟人化情感...智能对话技术的下半场究竟在哪儿？",
    "url": "https://www.infoq.cn/article/YXCoqIWRvZhCDw1tU6Wf",
    "summary": "<p>随着智能化产品深入生产生活，智能对话应用需求爆发，像小布、小度、小爱、天猫精灵等智能语音助手、智能家居、智能机器人等产品备受终端用户欢迎；像智能客服等产品则是当下企业必选的营销工具。如今企业和用户的多样化需求，也对智能对话技术提出了许多挑战，比如开放域多轮、多模态融合、拟人化情感等等。</p><p>&nbsp;</p><p>于是近几年，工业界陆续提出了“对话即服务”、“对话即平台”等概念，越来越多的国内外厂商开始深度投入到智能对话技术的探索与研发中。</p><p>&nbsp;</p><p>然而，智能对话是一个对技术水平要求较高的领域，对数据质量、处理效率等都有着比较高的开发要求；另一方面，目前很多已经搭建起来的对话逻辑复用和迁移难度比较高，开发者面临着繁琐的工作量，开发成本高，这也间接提高了智能对话的使用成本。</p><p>&nbsp;</p><p>那面对这些问题，当下学术界和工业界都有哪些解决方案？在“智能对话”相关技术研发方面都有哪些探索？</p><p>&nbsp;</p><p>为了赋能更多关注该领域的开发者，<a href=\"https://www.infoq.cn/article/ukt2jWfS2FVcegveGCUY\">OPPO </a>\"邀请了学术界、工业界多位技术专家，围绕智能对话展开了内容策划，并定于 2022 年 11 月 19 日下午，在北京中粮置地广场落地主题为《畅谈“智能对话”，共启“交互未来”》的 OGeek 小布沙龙，与众多开发者共同探讨智能对话的演进方向，探索人机交互的精彩未来。</p><p>&nbsp;</p><p>很多开发者都有关注上个月举行的<a href=\"https://www.infoq.cn/album/85\"> 2022 OGeek 技术峰会</a>\"，所以对 OGeek 这个技术沙龙品牌并不陌生。“OGeek Day”是由<a href=\"https://www.infoq.cn/article/SpBOGrQXJdZQSpOK8eAF\"> OPPO </a>\"数智工程系统主办的行业技术沙龙品牌，旨在为技术爱好者搭建一个技术交流和分享的开放平台。沙龙主要围绕“科技为人、以善天下”的技术理念，聚焦于为智能终端提供安全高效的数据、算力、算法、云服务方面的前沿技术，打造技术互动的行业生态，探索技术在行业应用的实践、突破及未来发展方向。</p><p>&nbsp;</p><p>本次 OGeek 小布沙龙更是精彩无限，各位开发者绝不能错过。沙龙大佬云集，分享嘉宾全员博士，OPPO 小布助手首席研究员杨振宇博士作为本次沙龙的内容出品人，邀请了清华大学计算机科学与技术系长聘副教授黄民烈博士、百度主任研发工程师牛正雨博士、OPPO 小布助手算法专家索宏彬博士作为内容分享嘉宾；沙龙内容全程硬核，分享主题从学术研究到企业技术实践，将给到场的开发者奉上一次技术的饕餮盛宴。</p><p>&nbsp;</p><p>以下为本次 OGeek 小布沙龙的内容安排：</p><p></p><h2>14:00-14:20 开场：畅谈“智能对话”，共启“交互未来”</h2><p></p><p></p><p>演讲嘉宾履历简介：杨振宇博士，OPPO 小布助手首席研究员，CCF 高级会员，曾在国防科大等高校任教，学术论文代表作单篇他引超过 800 次，入选 ESI Top 0.1%。近年来主要从事自然语言处理、对话式 AI 相关算法研究与落地应用工作，2018 年加入 OPPO 主导 NLP 与对话相关工作，帮助公司级战略产品小布助手实现月活突破 1.4 亿。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/54/2e/547edb8f8a36ca3a11df28af59c6042e.png\" /></p><p></p><p></p><h2>14:20-15:05 主题分享：预训练对话大模型</h2><p></p><p></p><p>演讲嘉宾履历简介：黄民烈博士，清华大学计算机科学与技术系长聘副教授，国家杰出青年科学基金获得者，智能技术与系统实验室副主任。主要研究方向为自然语言生成、对话系统、阅读理解等。曾获得中国人工智能学会吴文俊人工智能科技进步奖一等奖（第一完成人），中文信息学会汉王青年创新奖，阿里巴巴创新合作研究奖。发表国际顶级会议或期刊论文超过 100 篇，获得专利授权 10 余项，5 次获得国际主流会议的最佳论文或提名（IJCAI、ACL、SIGDIAL 等），著有国内第一本关于自然语言生成的著作《现代自然语言生成》。研发对话系统平台 ConvLab 和 ConvLab2，首个中文开放域对话预训练模型 CDial-GPT，中文开源对话模型 EVA，首个情感对话机器人 Emohaa。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/9b/3c/9b0f9e153c1cc312a239b5dc17589f3c.png\" /></p><p></p><p></p><h2>15:05-15:50 主题分享：百度文心 PLATO 对话技术的探索及应用</h2><p></p><p></p><p>演讲嘉宾履历简介：牛正雨博士，现任百度自然语言处理部主任架构师，负责通用对话方向（北京团队）的技术研发与应用。曾参与百度知识图谱构建、搜索 query 分析等项目，至今已发表学术论文四十余篇，作为项目成员曾获得 2017 年度中国电子学会科技进步一等奖。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/97/2e/973c5c707f6dbf1a42722f565cc5c82e.png\" /></p><p></p><p></p><h2>16:05-16:50 主题分享：OPPO 小布语音交互技术实践</h2><p></p><p></p><p>演讲嘉宾履历简介：索宏彬博士，OPPO 小布助手算法专家，CCF 会员，曾在中国科学院、联想研究院、阿里达摩院工作，学术论文发表超过 40 篇，语音技术专利 30 项。近年来主要从事个性化语音交互、语音唤醒、语音识别和副语言属性识别算法研究与落地应用工作，2022 年加入 OPPO 主导语音技术研发工作，帮助公司级战略产品小布助手实现月交互突破 30 亿次。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/e6/4b/e62a8761b5de21b3b5527388a46b614b.png\" /></p><p></p><p></p><h2>16:50-17:50 圆桌对话：智能对话技术的“下半场”在哪？</h2><p></p><p></p><p>届时来自学术界与工业界的多位博士将一起探讨以下话题：</p><p>&nbsp;</p><p>关于智能对话技术的研究与探索，目前学术界和工业界的侧重点分别是什么？当前 B 端企业和 C 端用户对于“智能对话”产品的核心需求分别有哪些？目前智能对话领域最大的“技术挑战”是什么？如何应对这个挑战？XR 等硬件设备的发展和元宇宙概念的火爆，将对智能对话等“人机交互”领域产生怎样的影响？在你们看来，下一代“人机交互”的理想形态是怎么样的？“智能对话”未来在里面会扮演怎样的角色？如果只选一个，未来 2～3 年内，您觉得智能对话等人工交互领域最有前景的方向是什么？为什么？</p><p>&nbsp;</p><p></p><h2>17:50-18:00 闭幕：Time for communication</h2><p></p><p>&nbsp;</p><p>智能对话的实现逻辑，简单来说，就是依赖知识图谱对输入的文字进行实体和关系等语义的识别与理解，通过深度学习（包括各种序列学习）的框架得到候选输出、通过推理来做最后回答的排序和过滤来实现最后的输出，而技术专家们就是基于此进行了技术探索和迭代。</p><p>&nbsp;</p><p>届时，在现场听了一下午技术专家们深度干货内容演讲的你，肯定会有一大堆问题想要提问吧！所以，我们除了在每个演讲后为各位准备了 QA 时间，在最后闭幕阶段也准备了惊喜小环节。</p><p>&nbsp;</p><p>话不多说，2022 年 11 月 19 日下午，来北京中粮置地广场与各位大佬面对面交流吧！点击链接 <a href=\"http://gk.link/a/11O0y\">http://gk.link/a/11O0y</a>\" 即刻报名本次活动~</p>",
    "publish_time": "2022-11-08 11:47:26",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "YouTube数据库如何保存巨量视频文件？",
    "url": "https://www.infoq.cn/article/vWjmBcohJQy767eM48Q0",
    "summary": "<p>本文最初发表于<a href=\"https://scaleyourapp.com/youtube-database-how-does-it-store-so-many-videos-without-running-out-of-storage-space/\">scaleyourapp.com网站</a>\"，经原作者<a href=\"https://www.linkedin.com/in/shivang-sarawagi-b7b5881b/\">Shivang Sarawagi</a>\"授权由InfoQ中文站翻译分享。</p><p></p><p>YouTube是仅次于谷歌的第二大热门网站。在2019年5月，每分钟会有超过500小时的视频内容上传到该平台。</p><p></p><p>该视频共享平台有超过20亿的用户，<a href=\"https://www.youtube.com/about/press/\">每天有超过10亿小时的视频被播放</a>\"，产生数十亿的浏览量。这些都是令人难以置信的数字。</p><p></p><p>本文会对YouTube使用的<a href=\"https://www.infoq.cn/topic/database\">数据库</a>\"和后端数据基础设施进行深入讲解，它们使得该视频平台能够存储如此巨量的数据，并能扩展至数十亿的用户。</p><p></p><p>那我们就开始吧。</p><p></p><h2>1.引言</h2><p></p><p></p><p>YouTube的旅程开始于2005年。随着这家由风险资本资助的技术初创公司不断取得成功，它于2006年11月被谷歌以16.5亿美元收购。</p><p></p><p>在被谷歌收购之前，它们的团队由以下人员组成：</p><p></p><p>两名系统管理员两名可扩展性软件架构师两名特性开发人员两名网络工程师一名DBA</p><p></p><h2>2.后端基础设施</h2><p></p><p></p><p>YouTube的后端微服务是由<a href=\"https://www.python.org/\">Python</a>\"、<a href=\"https://www.infoq.cn/topic/database\">数据库</a>\"、<a href=\"https://www.infoq.cn/topic/hardware\">硬件</a>\"、Java（使用了<a href=\"https://github.com/google/guice\">Guice框架</a>\"）和Go编写的。用户界面是使用<a href=\"https://www.infoq.cn/topic/javascript\">JavaScript</a>\"编写的。</p><p></p><p>主要的数据库是由Vitess支撑的MySQL，<a href=\"https://vitess.io/\">Vitess</a>\"是一个数据库集群系统，用于MySQL的水平扩展。另外，使用Memcache实现缓存并使用Zookeeper进行节点的协调。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/da/da35bae7c2d019d6049c823d366cddff.jpeg\" /></p><p></p><p>流行的视频通过CDN来提供，而一般的、较少播放的视频则从数据库中获取。</p><p></p><p>每个视频在上传的时候，都会赋予一个唯一的标识符并且会由一个批处理job进行处理，该job会运行多个自动化的过程，比如生成缩略图、元数据、视频脚本、编码、设置货币化状态等。</p><p></p><p>VP9 &amp; H.264/MPEG-4 AVC高级视频编码（Advanced Video Coding codecs）<a href=\"https://youtube-eng.googleblog.com/2015/04/vp9-faster-better-buffer-free-youtube.html\">会用于视频压缩</a>\"，它能够使用其他编码器一半的带宽来编码HD和4K质量的视频。</p><p></p><p>视频流则是使用基于<a href=\"https://en.wikipedia.org/wiki/Dynamic_Adaptive_Streaming_over_HTTP\">HTTP协议的动态自适应流</a>\"（Dynamic Adaptive Streaming），这是一种自适应比特率的流媒体技术，能够从传统的HTTP Web服务器上实现高质量的视频流。通过这种技术，内容可以按照不同的比特率提供给观众。YouTube客户端会根据观看者的互联网连接速度自动适应视频渲染，从而尽可能减少缓冲时间。</p><p></p><p>我曾经在一篇专门的文章中讨论过YouTube的视频转码过程，参见“<a href=\"https://scaleyourapp.com/youtube-architecture-how-does-it-serve-high-quality-videos-with-low-latency/\">YouTube是如何以低延迟提供高质量视频的</a>\"”。</p><p></p><p>所以，这里对<a href=\"https://scaleyourapp.com/an-insight-into-the-backend-infrastructure-of-a-modern-digital-bank-monzo-architecture/\">平台的后端技术有一个快速的介绍</a>\"。YouTube主要使用的数据库是MySQL。现在，我们了解一下YouTube的工程团队为什么觉得有必要编写Vitess？他们在最初的MySQL环境中面临的问题是什么，使他们在此基础上实现了一个额外的框架？</p><p></p><h2>3.为何需要Vitess</h2><p></p><p></p><p>网站最初只有一个数据库实例。随着网站的发展，为了满足日益增长的QPS（每秒查询次数）需求，开发人员不得不对数据库进行水平扩展。</p><p></p><h3>3.1 主-从副本</h3><p></p><p></p><p>副本会添加到主数据库实例中。读取请求会被路由到主数据库和副本上，以减少主数据库的负载。添加副本有助于缓解瓶颈，增加读取的吞吐量，并增加系统的持久性。</p><p></p><p>主节点处理写入的流量，主节点和副本节点同时处理读取流量。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b2/b23c802655630d1a3b2722cfee5b2066.jpeg\" /></p><p></p><p>但是，在这种场景中，有可能会从副本中读取到陈旧的数据。如果在主节点将信息更新到副本之前，一个请求读取了副本的数据，那么观看者就会得到陈旧的数据。</p><p></p><p>此时，主节点和副本节点的数据是不一致的。在这种情况下，不一致的数据是主节点和副本节点上特定视频的观看次数。</p><p></p><p>其实，这完全没有问题。观众不会介意观看次数上略微有点不一致，对吧？更重要的是，视频能够在他们的浏览器中渲染出来。</p><p></p><p>主节点和副本节点之间的数据最终会是一致的。</p><p></p><p>因此，工程师们觉得非常开心，观众们也非常开心。随着副本的引入，事情进展顺利。</p><p></p><p>网站继续受到欢迎，QPS继续上升。主-从副本策略现在很难跟上网站流量的增长了。</p><p></p><p>那现在该怎么办？</p><p></p><h3>3.2 分片</h3><p></p><p></p><p>下一个策略就是对数据库进行分片（shard）。分片是除了主-从副本、主-主副本、联盟和反范式化（de-normalization） 之外，扩展关系型数据库的方式之一。</p><p></p><p>数据库分片并不是一个简单的过程。它大大增加了系统的复杂性，并使得管理更加困难。</p><p></p><p>但是，数据库必须要进行分片，以满足QPS的增长。在开发人员将数据库分片后，数据会被分散到多台机器上。这增加了系统写入的吞吐量。现在，不再是只有一个主实例处理写入，写入操作可以在多台分片的机器上进行。</p><p></p><p>同时，每台机器都创建了单独的副本，以实现冗余和吞吐。</p><p></p><p>该平台的受欢迎程度持续上升，大量的数据被内容创作者不断添加到数据库中。</p><p></p><p>为了防止机器故障或者外部未知事件造成的数据丢失或服务不可用，此时需要在系统中添加灾难管理的功能了。</p><p></p><h3>3.3 灾难管理</h3><p></p><p></p><p>灾难管理指的是在面临停电和自然灾害（如地震、火灾）时的应急措施。它需要进行冗余，并将用户数据备份到世界不同地理区域的数据中心。丢失用户数据或服务不可用是不允许的。</p><p></p><p>在世界范围内拥有多个数据中心也有助于YouTube减少系统延迟，因为用户请求会被路由到最近的数据中心，而不是路由到位于不同大陆的原始服务器。</p><p></p><p>现在，你可以想象基础设施会变得多复杂。</p><p></p><p>经常会有未经优化的全表扫描导致整个数据库瘫痪。数据库必须进行保护，防止受到不良查询的影响。所有的服务器都需要被跟踪以确保服务的高效性。</p><p></p><p>开发人员需要有一个系统来抽象系统的复杂性，能够让他们解决可扩展性的挑战，并以最小的成本管理该系统。这一切促使YouTube开发了Vitess。</p><p></p><h2>4.Vitess：用于水平扩展MySQL数据库集群的系统</h2><p></p><p></p><p><a href=\"https://vitess.io/\">Vitess</a>\"是一个运行于MySQL之上的数据库集群系统，能够使MySQL进行水平扩展。它有内置的分片特性，能够让开发人员扩展数据库，而不必在应用中添加任何的分片逻辑。这类似于NoSQL的做法。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0d/0dd75137933e562f92fe66aeba673724.jpeg\" /></p><p></p><p>Vitess架构，<a href=\"https://vitess.io/docs/overview/architecture/\">图片来源</a>\"</p><p></p><p>Vitess还会自动处理故障转移和备份。它能够管理服务器，通过智能重写资源密集型的查询和实现缓存来提高数据库性能。除了YouTube，该框架还被业界的其他知名厂商使用，如GitHub、Slack、Square、New Relic等。</p><p></p><p>当你需要ACID事务和强一致性的支持，同时又希望像NoSQL数据库一样快速扩展关系型数据库时，Vitess就会大显身手。</p><p></p><p>在YouTube，每个MySQL连接都有2MB的开销。每一个连接都有可计算出来的成本，而且随着连接数量的增加，还必须增加额外的RAM。</p><p></p><p>通过基于Go编程语言并发支持构建的连接池，Vitess能够以很低的成本管理这些连接。它使用Zookeeper来管理集群，并使其保持最新状态。</p><p></p><h2>5.部署到云中</h2><p></p><p></p><p>Vitess是云原生的，很适合云中部署，因为就像云的模式一样，容量是逐步添加到数据库的。它可以作为一个Kubernetes感知（Kubernetes-aware）的云原生分布式数据库运行。</p><p></p><p>在YouTube，Vitess在容器化环境中运行，并使用Kubernetes作为容器编排工具。</p><p></p><p>在如今的计算时代，每个大规模的服务都在分布式环境的云中运行。<a href=\"https://scaleyourapp.com/a-super-helpful-guide-to-avoiding-cloud-vendor-lock-in-when-running-your-service-on-cloud/\">在云中运行服务</a>\"有许多好处。</p><p></p><p><a href=\"https://cloud.google.com/\">Google Cloud Platform</a>\"是一套云计算服务，它的基础设施与谷歌内部的终端用户产品（如谷歌搜索和YouTube）所用的基础设施是相同的。</p><p></p><p>每个大规模的在线服务都有一个多样化（polyglot）的持久性架构，因为某一种数据模型，无论是关系型还是NoSQL，都无法处理服务的所有使用场景。</p><p></p><p>在为本文展开的研究中，我无法找到YouTube所使用的具体谷歌云数据库的清单，但我非常肯定它会使用GCP的特有产品，如Google Cloud Spanner、Cloud SQL、Cloud Datastore、Memorystore等来运行服务的不同特性。</p><p></p><p><a href=\"https://scaleyourapp.com/google-database-how-do-google-services-store-petabyte-exabyte-scale-data/\">这篇文章详细介绍了其他谷歌服务所使用的数据库，如Google Adwords、Google Finance、Google Trends等。</a>\"</p><p></p><h2>6.CDN</h2><p></p><p></p><p>YouTube使用<a href=\"https://cloud.google.com/cdn/\">谷歌的全球网络</a>\"进行低延迟、低成本的内容传输。借助全球分布的POP边缘点，它能够使客户能够更快地获取数据，而不必从原始服务器获取。</p><p></p><p>所以，到此为止，我已经谈到了YouTube使用的数据库、框架和技术。现在，该谈一谈存储问题了。</p><p>YouTube是如何存储如此巨大的数据量的呢（每分钟上传500小时的视频内容）？</p><p></p><h2>7.数据存储：YouTube是如何存储如此巨大的数据量的呢？</h2><p></p><p></p><p>视频会存储在谷歌数据中心的硬盘中。这些数据由Google File System和BigTable管理。</p><p></p><p><a href=\"https://en.wikipedia.org/wiki/Google_File_System\">GFS Google File System</a>\"是谷歌开发的一个分布式文件系统，用于管理分布式环境中的大规模数据。</p><p><a href=\"https://cloud.google.com/bigtable/\">BigTable</a>\"是一个建立在Google File System上的低延迟分布式数据存储系统，用于处理分布在成千上万台机器上的PB级别的数据。60多个谷歌产品都使用了它。</p><p></p><p>因此，视频被存储在硬盘中。关系、元数据、用户偏好、个人资料信息、账户设置、从存储中获取视频所需的相关数据等都存储在MySQL中。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/34/3492f237b0ce0d7c491fa7504033788f.jpeg\" /></p><p></p><p></p><h3>7.1 即插即用的商用服务器</h3><p></p><p></p><p>谷歌数据中心拥有同质化的<a href=\"https://www.infoq.cn/topic/hardware\">硬件</a>\"，软件则是内部构建的，管理成千上万的独立服务器集群。</p><p></p><p>谷歌部署的服务器，能够增强数据中心的存储能力，它们都是商用服务器（commodity server），也被称为商用现成的服务器（commercial off-the-shelf server）。这些服务器价格低廉，可广泛使用和大量购买，并能以最小的成本和代价替换或配置数据中心的相同<a href=\"https://www.infoq.cn/topic/hardware\">硬件</a>\"。</p><p></p><p>随着对额外存储需求的增加，新的商用服务器会被插入到系统中。</p><p></p><p>出现问题后，<a href=\"https://en.wikipedia.org/wiki/Commodity_computing\">商用服务器</a>\"通常会被直接替换，而不是进行修理。它们不是定制的，与运行定制的服务器相比，使用它们能够使企业在很大程度上减少基础设施成本。</p><p></p><h3>7.2 为数据中心设计的存储磁盘</h3><p></p><p></p><p>YouTube每天都需要超过一个PB的新存储。旋转硬盘驱动器是主要的存储介质，因为其成本低，可靠性高。</p><p></p><p>SSD固态硬盘比旋转磁盘具有更高的性能，因为它们是基于半导体的，但大规模使用固态硬盘并不划算。</p><p>它们相当昂贵，也容易随着时间的推移逐渐丢失数据。这使得它们不适合用于归档数据的存储。</p><p></p><p>另外，谷歌正在开发一个适用于大规模数据中心的新磁盘系列。</p><p></p><p>有五个关键指标可用来判断为数据存储而构建的<a href=\"https://www.infoq.cn/topic/hardware\">硬件</a>\"的质量：</p><p></p><p>硬件应该有能力支持秒级的高速度输入输出操作。它应该符合组织规定的安全标准。与普通存储硬件相比，它应该有更高的存储容量。硬件采购成本、电力成本和维护费用应该都是可以接受的。磁盘应该是可靠的，并且延迟是稳定的。</p>",
    "publish_time": "2022-11-08 12:00:16",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "eBPF 技术实践：加速容器网络转发，耗时降低60%+",
    "url": "https://www.infoq.cn/article/8YXcO6DmQPr6JwOsqKIL",
    "summary": "<p></p><p></p><p>Linux 具有功能丰富的网络协议栈，并且兼顾了非常优秀的性能。但是，这是相对的。单纯从网络协议栈各个子系统的角度来说，确实做到了功能与性能的平衡。不过，当把多个子系统组合起来，去满足实际的业务需求，功能与性能的天平就会倾斜。</p><p></p><p>容器网络就是非常典型的例子，早期的容器网络，利用 bridge、netfilter + iptables （或 lvs）、veth 等子系统的组合，实现了基本的网络转发；然而，性能却不尽如人意。原因也比较明确：受限于当时的技术发展情况，为了满足数据包在不同网络 namespace 之间的转发，当时可以选择的方案只有 bridge + veth 组合；为了实现 POD 提供服务、访问 NODE 之外的网络等需求，可以选择的方案只有 netfilter + iptables（或 lvs）。这些组合的技术方案增加了更多的网络转发耗时，故而在性能上有了更多的损耗。</p><p></p><p>然而，eBPF 技术的出现，彻底改变了这一切。eBPF 技术带来的内核可编程能力，可以在原有漫长转发路径上，制造一些“虫洞”，让报文快速到达目的地。针对容器网络的场景，我们可以利用 eBPF，略过 bridge、netfilter 等子系统，加速报文转发。</p><p></p><p>下面我们以容器网络为场景，用实际数据做支撑，深入分析 eBPF 加速容器网络转发的原理。</p><p></p><p></p><h2>网络拓扑</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a5/a5cb4dcda3e91c7899659de5c14957a5\" /></p><p></p><p>如图，两台设备 Node-A/B 通过 eth1 直连，网段为 192.168.1.0/24。Node-A/B 中分别创建容器 Pod-A/B，容器网卡名为 ve0，是 veth 设备，网段为 172.17.0.0/16。Node-A/B 中分别创建桥接口 br0，网段为 172.17.0.0/16，通过 lxc0（veth 设备）与 Pod-A/B 连通。在 Node、Pod 网络 namespace 中，分别设置静态路由；其中，Pod 中静态路由网关为 br0，Node 中静态路由网关为对端 Node 接口地址。为了方便测试与分析，我们将 eth1 的网卡队列设置为 1，并且将网卡中断绑定到 CPU0。</p><p></p><p><code lang=\"shell\"># ethtool -L eth1 combined 1\n# echo 0 &gt; /proc/irq/$(cat /proc/interrupts | awk -F ':' '/eth1/ {gsub(/ /,\"\"); print $1}')/smp_affinity_list\n</code></p><p></p><p></p><h2>bridge</h2><p></p><p></p><p>bridge + veth 是容器网络最早的转发模式，我们结合上面的网络拓扑，分析一下网络数据包的转发路径。</p><p></p><p>在上面网络拓扑中，eth1 收到目的地址为 172.17.0.0/16 网段的报文，会经过路由查找，走到 br0 的发包流程。br0 的发包流程，会根据 FDB 表查找目的 MAC 地址归属的子接口，如果没有查找到，就洪泛（遍历所有子接口，发送报文）；否则，选择特定子接口，发送报文。在本例中，会选择 lxc0 接口，发送报文。lxc0 口是 veth 口，内核的实现是 veth 口发包，对端（peer）的 veth 口就会收包。在本例中，Pod-A/B 中的 ve0 口会收到报文。至此，完成收包方向的主要流程。当报文从 Pod-A/B 中发出，会先在 Pod 的网络 namespace 中查找路由，假设流量从 Pod-A 发往 Pod-B，那么会命中我们之前设置的静态路由：172.17.0.200 via 172.17.0.1 dev ve0，最终报文会从 ve0 口发出，目的 MAC 地址为 Node-A 上面 br0 的地址。ve0 口是 veth 口，和收包方向类似，对端的 veth 口 lxc0 会收到报文。lxc0 口是 br0 的子接口，由于报文目的 MAC 地址为 br0 的接口地址，报文会经过 br0 口上送到 3 层协议栈处理。3 层协议栈会查找路由，命中我们之前设置的静态路由：172.17.0.200 via 192.168.1.20 dev eth1，最终报文会从 eth1 口发出，发给 Node-B。至此，完成发包方向的主要流程。</p><p></p><p>上面的流程比较抽象，我们用 perf ftrace 可以非常直观地看到报文都经过了哪些内核协议栈路径。</p><p></p><p></p><h3>收包路径</h3><p></p><p></p><p><code lang=\"shell\"># perf ftrace -C0 -G '__netif_receive_skb_list_core' -g 'smp_*'\n</code></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ca/cada96c1a8714f73c4485de8e2b45abc\" /></p><p></p><p>如图，收包路径主要经历路由查找、桥转发、veth 转发、veth 收包等阶段，中间多次经过 netfilter 的 hook 点。最终调用 enqueue_to_backlog 函数，数据包暂存到每个 &nbsp;CPU 私有的 input_pkt_queue 中，一次软中断结束，总耗时 79us。但是报文并没有到达终点，后续软中断到来时，会有机会调用 process_backlog，处理每个 CPU 私有的 input_pkt_queue，将报文丢入 Pod 网络 namespace 的协议栈继续处理，直到将报文送往 socket 的队列，才算是到达了终点。综上，收包路径要消耗 2 个软中断，才能将报文送达终点。</p><p></p><p></p><h3>发包路径</h3><p></p><p></p><p><code lang=\"shell\"># perf ftrace -C0 -G '__netif_receive_skb_core' -g 'smp_*'\n</code></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d2/d22d6497990159cd926df63c37383df4\" /></p><p></p><p>如图，发包路径主要经历 veth 收包、桥上送、路由查找、物理网卡转发等阶段，中间多次经过 netfilter 的 hook 点 。最终调用网卡驱动发包函数，一次软中断结束，总耗时 62us。</p><p></p><p></p><h3>分析</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/2b/2b21055d67126e0d8acd326f72622359\" /></p><p></p><p>由 perf ftrace 的结果可以看出，利用 bridge + veth 的转发模式，会多次经历 netfilter、路由等子系统，过程非常冗长，导致了转发性能的下降。</p><p></p><p>我们接下来看一下，如何用 eBPF 跳过非必须的流程，加速网络转发。</p><p></p><p>首先，我们先看一下内核协议栈主要支持的 eBPF hook 点，在这些 hook 点我们可以注入 eBPF 程序，实现具体的业务需求。</p><p></p><p>我们可以看到，与网络转发相关的 hook 点主要有 XDP（eXpress Data Path）、TC（Traffic Control）、LWT（Light Weight Tunnel）等。</p><p></p><p>针对于容器网络转发的场景，比较合适的 hook 点是 TC。因为 TC hook 点是协议栈的入口和出口，比较底层，eBPF 程序能够获取非常全面的上下文（如：socket、cgroup 信息等），这点是 XDP 没有办法做到的。而 LWT 则比较靠上层，报文到达这个 hook 点，会经过很多子系统（如：netfilter）。</p><p></p><p></p><h3>加速收包路径</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/13/13e24ef49d8acf71ebf08e0e8b1a31cd\" /></p><p></p><p>如图，在 eth1 的 TC hook 点（收包方向）挂载 eBPF 程序。</p><p></p><p><code lang=\"apache\"># tc qdisc add dev eth1 clsact\n# tc filter add dev eth1 ingress bpf da obj ingress_redirect.o sec classifier-redirect\n</code></p><p></p><p>eBPF 程序如下所示，其中 lxc0 接口的 index 为 2。bpf_redirect 函数为内核提供的 helper 函数，该函数会将 eth1 收到的数据包，直接转发至 lxc0 接口。</p><p></p><p><code lang=\"cs\">SEC(\"classifier-redirect\") \nint cls_redirect(struct __sk_buff *skb) { \n   /* The ifindex of lxc0 is 2 */    \n   return bpf_redirect(2, 0); \n}\n</code></p><p></p><p></p><h3>加速发包路径</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ff/ff8ae5dc8839c2abbf983bd4be5afa3e\" /></p><p></p><p>如图，在 lxc0 的 TC hook 点（收包方向）挂载 eBPF 程序。</p><p></p><p><code lang=\"apache\"># tc qdisc add dev lxc0 clsact \n# tc filter add dev lxc0 ingress bpf da obj egress_redirect.o sec classifier-redirect\n</code></p><p></p><p>eBPF 程序如下所示，其中 eth1 接口的 index 为 1。bpf_redirect 函数会将 lxc0 收到的数据包，直接转发至 eth1 接口。</p><p></p><p><code lang=\"cs\">SEC(\"classifier-redirect\") \nint cls_redirect(struct __sk_buff *skb) {\n    /* The ifindex of eth1 is 1 */    \n    return bpf_redirect(1, 0); \n}\n</code></p><p></p><p></p><h3>分析</h3><p></p><p></p><p>由上面的操作可以看到，我们直接跳过了 bridge 的转发，利用 eBPF 程序，将 eth1 与 lxc0 之间建立了一个快速转发通路。下面我们用 perf ftrace 看一下加速效果。</p><p></p><p></p><h3>收包路径</h3><p></p><p></p><p><code lang=\"shell\"># perf ftrace -C0 -G '__netif_receive_skb_list_core' -g 'smp_*'\n</code></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d3/d3799f37fb4ea08e688908a1f3675811\" /></p><p></p><p>如图，在收包路径的 TC 子系统中，由 bpf_redirect 函数设置转发信息（ lxc0 接口 index），由 skb_do_redirect 函数直接调用了 lxc0 接口的 veth_xmit 函数；略过了路由、bridge、netfilter 等子系统。</p><p></p><p>最终调用 enqueue_to_backlog 函数，数据包暂存到每个 CPU 私有的 input_pkt_queue 中，一次软中断结束，总耗时 43us；比 bridge 转发模式的 79us，耗时减少约 45%。</p><p></p><p>但是，收包路径仍然要消耗 2 个软中断，才能将报文送达终点。</p><p></p><p></p><h3>发包路径</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e5/e58978b32a3307432e7e950f190026ea\" /></p><p></p><p>如图，在发包路径的 TC 子系统中，由 bpf_redirect 函数设置转发信息（ eth1 接口 index ），由 skb_do_redirect 函数直接调用了 eth1 接口的 xmit 函数；略过了路由、bridge、netfilter 等子系统。</p><p></p><p>最终调用网卡驱动发包函数，一次软中断结束，总耗时 36us，相比 bridge 模式 62us，耗时减少了约 42%。</p><p></p><p></p><h3>小结</h3><p></p><p></p><p>由 perf ftrace 的结果可以看出，利用 eBPF 在 TC 子系统注入转发逻辑，可以跳过内核协议栈非必须的流程，实现加速转发。收发两个方向的耗时分别减少 40% 左右，性能提升非常可观。</p><p></p><p>但是，我们在收包路径上面仍然需要消耗 2 个软中断，才能将报文送往目的地。接下来我们看，如何利用 redirect peer 技术来优化这个流程。</p><p></p><p></p><h2>TC redirect peer</h2><p></p><p></p><p></p><h3>加速收包路径</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/39/39764b8fa6d8d82ae597c633086d5c5c\" /></p><p></p><p>如图，在 eth1 的 TC hook 点（收包方向）挂载 eBPF 程序。</p><p></p><p><code lang=\"apache\"># tc qdisc add dev eth1 clsact \n# tc filter add dev eth1 ingress bpf da obj ingress_redirect_peer.o sec classifier-redirect\n</code></p><p></p><p>eBPF 程序如下所示，其中 lxc0 接口的 index 为 2。bpf_redirect_peer 函数为内核提供的 helper 函数，该函数会将 eth1 收到的数据包，直接转发至 lxc0 接口的 peer 接口，即 ve0 接口。</p><p></p><p><code lang=\"cs\">SEC(\"classifier-redirect\") \nint cls_redirect(struct __sk_buff *skb) {\n    /* The ifindex of lxc0 is 2 */    \n    return bpf_redirect_peer(2, 0); \n}\n</code></p><p></p><p></p><h3>分析</h3><p></p><p></p><p>由于 bpf_redirect_peer 会直接将数据包转发到 Pod 网络 namespace 中，避免了 enqueue_to_backlog 操作，节省了一次软中断，性能理论上会有提升。我们用 perf ftrace 验证一下。</p><p></p><p><code lang=\"shell\"># perf ftrace -C0 -G '__netif_receive_skb_list_core' -g 'smp_*\n</code></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/82/82ecc195b8bed7d2dce30c0b4abd6c0d\" /></p><p></p><p>如图，在收包路径的 TC 子系统中，由 bpf_redirect_peer 函数设置转发信息（ lxc0 接口 index），由 skb_do_redirect 函数调用 veth_peer_dev 查找 lxc0 的 peer 接口，设置 skb-&gt;dev = ve0，返回 EAGAIN 给 tcf_classify 函数。</p><p></p><p>tcf_classify 函数会判断 skb_do_redirect 的返回值，如果是 EAGAIN，则触发 __netif_receive_skb_core 函数伪递归调用（通过 goto &nbsp;实现）。这样，就非常巧妙地实现了网络 namespace 的切换（在一次软中断上下文中）。</p><p></p><p>最终，通过 tcp_v4_rcv 函数到达报文的终点，整个转发流程耗时 75us。从上面的函数耗时可以看到，ip_list_rcv 函数相当于 Pod 网络 namespace 的耗时，本文描述的 3 种转发模式，这段转发路径是相同的。所以，将 ip_list_rcv 函数耗时减去，转发耗时约为 14us（这里还忽略了 2 次软中断调度的时间）。比 TC redirect 模式的 43us、bridge 模式的 79us，转发耗时分别减少为 67%、82%。</p><p></p><p></p><h2>总&nbsp; &nbsp; 结</h2><p></p><p></p><p>本文以容器网络为例，对比了 3 种容器网络转发模式的性能差异。通过 perf ftrace 的函数调用关系以及耗时情况，详细分析了导致性能差异的原因。我们演示了仅仅通过几行 eBPF 代码，就可以大大缩短报文转发路径，加速内核网络转发的效率，网络转发耗时最多可减少 82%。</p><p></p><p>目前 eBPF 技术在开源社区非常流行，在 tracing、安全、网络等领域有广泛应用，我们可以利用这项技术做很多有意思的事情。感兴趣的朋友可以加入我们，一起讨论交流。</p><p></p><p>作者简介：</p><p></p><p>王栋栋，字节跳动系统技术与工程团队内核工程师，10 年系统工程师工作经验，关注 Linux networking、eBPF 等领域。目前在字节跳动，主要负责 eBPF、内核网络协议栈相关的开发工作。</p><p></p><p>今日好文推荐</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651145285&amp;idx=1&amp;sn=791730395977460f56a581fb18edeef0&amp;chksm=bdb8bc168acf35000bc2cd3c7581eb7b8f6b49b17a1f66fc91244fd332a22ec295bea090e00b&amp;scene=21#wechat_redirect\"></a>\"<a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651145623&amp;idx=1&amp;sn=27d5efdb4fc484f3ee25feea8d66152d&amp;chksm=bdb8bdc48acf34d21467412f6927ad9aa846e1760d0766364b4c345571b7a5dff72841ddc695&amp;scene=21#wechat_redirect\">每天中午都是一次“秒杀”，从 IT 视角看麦当劳中国数字化</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651145285&amp;idx=1&amp;sn=791730395977460f56a581fb18edeef0&amp;chksm=bdb8bc168acf35000bc2cd3c7581eb7b8f6b49b17a1f66fc91244fd332a22ec295bea090e00b&amp;scene=21#wechat_redirect\">对话iPod之父：这不是互联网最坏的年代</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651145274&amp;idx=1&amp;sn=49bc3312f3ec258b4872627632cc4321&amp;chksm=bdb8bc698acf357f76a8007924d40d9da527578d226fc19c1dc94886ba557ddb279901b66f44&amp;scene=21#wechat_redirect\">“羊了个羊”背后公司清仓式分红10亿元；Meta元宇宙部门今年已亏94亿美元；微软称GitHub年收入10亿美元｜Q资讯</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651145179&amp;idx=1&amp;sn=4316dc7006bed68e0022e1ec44b6c7f8&amp;chksm=bdb8bb888acf329eafb85b618128aae5fc5d802607fd670267ec4bbf1cb0c7014e7dede7f2cc&amp;scene=21#wechat_redirect\">全面审查Twitter代码、当场炒掉CEO等众多高管：马斯克正式入主Twitter</a>\"</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/93/93a6e30a75e8e663d639c54513765ef5.gif\" /></p><p></p>",
    "publish_time": "2022-11-08 12:00:56",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]