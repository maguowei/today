[
  {
    "title": "架构师（2022年11月）",
    "url": "https://www.infoq.cn/article/57l28ax6StEFl4TKSZ61",
    "summary": "<h2>卷首语：专访“MySQL 之父”：要拥有一份能做一辈子的开发工作，需要给自己积累名望</h2>\n<p>“热爱”，是贯穿于“MySQL 之父” Monty 过往 40 年编程人生的关键词。</p>\n<p>60 岁的 Monty 现在仍在写代码，每周保持 60 个小时的高工作强度。他说，等到 80 岁时，才会考虑将工作缩短到 35 小时。编程这事儿，他还要干一辈子。</p>\n<h4>二十年磨一剑</h4>\n<p>InfoQ：您在 34 岁时开发出了 MySQL。从接触编程到开发出 MySQL，这段时间可真不短，您都做了哪些工作？</p>\n<p>Monty：我从 18 岁的时候就开始编写 MySQL 的最早一批代码了，这部分代码主要是 MySQL 内存控制方面的，所以最早的开发工作可以追溯到 1982 年左右。</p>\n<p>后来的开发工作都是以之前的成果为基础。在此期间，我也开发过不少硬件驱动程序，设计了一款不错的处理器，还做过很多游戏。</p>\n<p>InfoQ：这么长的开发历程，是什么让您一直坚持了下来？</p>\n<p>Monty：我想，是热爱。我喜欢做开发，我特别喜欢解决问题的感觉，特别是在开发 MySQL 和 MariaDB 的过程中。而且，我参与了开源，帮助很多人走向成功。我觉得这一切都能让人始终保持热情。</p>\n<p>InfoQ：从您写下第一行代码到开发出 MySQL，花费了近二十年时间。但目前市场上也有不少企业投入过十年甚至十五年来开发软件，但最终成果从来没能真正流行起来。你怎么看待这样的现实？</p>\n<p>Monty：我确实是用了快二十年才开发出 MySQL，但当时我没有想到未来这个软件会发展成什么样子。我将我的软件卖给了北欧最大的一家电脑公司，但后来，我的软件成了整个平台上最受欢迎的产品。</p>\n<p>你提到的这种情况也的确存在，很多公司耗时耗力，最终却一无所获。MySQL 的成功是与时代背景分不开的。当时互联网已经得到广泛认可，每个人都需要这样的数据库，用它创建互联网所需要的数据。当时那些技术巨头还不看好互联网，所以这是个有待开发的蓝海市场。</p>\n<p>其实只要意识到需求的存在，其他的就都好办了，所以我从 94 年开始正式编写MySQL。最终成果的发布大概是在 95 年末，也就是说，我们用了短短两年就开发出了 MySQL 的第一个版本，成为当时的新兴支撑性产品。</p>\n<p>InfoQ：技术圈内，您被誉为“编程天才”，您怎么看待这样的称呼？</p>\n<p>Monty：我觉得差不多，我在编程方面确实有点小天赋。</p>\n<p>InfoQ：我想不只是编程这一个领域吧，您在创业方面也很成功啊。</p>\n<p>Monty：嗯，我在企业家、开源倡导者、程序员和架构师几个角色上表现得都还可以。</p>\n<p>InfoQ：您是否会认为，如果一个人想在某个领域取得卓越的成就，天赋是不是比努力更重要？</p>\n<p>Monty：那是肯定的。毕竟在编程行业，一个优秀的程序员要胜过十个普通的程序员。这种优秀，源自天赋、努力工作，更源自想要了解一切的学习精神。</p>\n<p>所以在前二十年里，我每天基本上就是学习计算机、学习硬件、学习如何高效编程，学习怎么让计算机发挥出一切性能。有了这样的底子，我才能真正开始做自己的事。</p>\n<h4>转管理，不是程序员的尽头</h4>\n<p>InfoQ：从 MySQL 到 MariaDB，您已经证明了自己是位成功的企业家。但不是所有技术人员都能成长为管理者，在这方面您能不能分享一点经验？</p>\n<p>Monty：我觉得大多数开发人员就适合当开发者。</p>\n<p>我知道，一直都有些开发者屈服于现实，转而去做管理岗。但根据我的观察，他们大多数人的编程才能其实比管理才能要强得多。很多人就是为了钱，管理岗的收入应该是比开发者要高一些。</p>\n<p>但我觉得他们的天赋主要还是体现在开发上，最好能坚持下去，依靠自己的才能走向成功。</p>\n<p>InfoQ：您在 34 岁，也就是快接近中年时才开发出 MySQL。但在中国市场，35 岁以上的开发者往往会考虑转向管理岗。您怎么看待这种现象？</p>\n<p>Monty：我认为不应该这样。因为好程序员，特别是优秀的程序员其实更难找。虽然管理岗的薪水可能稍高一点，但却很容易被取代。所以只要大家有天赋，最好能坚持在技术的道路上走下去。</p>\n<p>至于 MySQL 这边，其实我从来不想当 CEO。我想做的是 CTO，负责技术方面的工作，毕竟我的天赋就在技术上。我觉得自己没有那份成为优秀全职管理者的天分。</p>\n<p>我把一生都投入到写代码上，我喜欢这活儿，也正是编程让我成为了独一无二的人。</p>\n<p>InfoQ：如您所说，转到管理岗后，就会得到更多资源，比如晋升机会更大、薪酬更高。相比于技术理想，这是很现实的考量，毕竟大部分人要养家糊口，您怎么看呢？</p>\n<p>Monty：我觉得很多企业在职业设计上都有这种错误。所以在 MySQL 和 MariaDB，我觉得与其靠让大家做管理来提升薪水，不如让他们承担起更多责任。有时候，职位的重要性比单纯的高薪水更有吸引力。这可以算是另一种思路吧。</p>\n<p>大家当然应该为自己的编程事业规划一条职业发展道路，但没必要把转管理岗当成唯一的方向。企业不需要那么多经理，而且在开始裁员的时候，管理岗都是最先倒霉的。毕竟经理人很容易替代，但优秀的程序员不可替代。他们掌握着企业最需要的代码知识，所以只要代码在，那岗位就在。</p>\n<h4>编程 40 年，如何保持技术前瞻性？</h4>\n<p>InfoQ：您的编程经历大概有四十年了。在这么长的从业过程中，您是怎么保持自己的技术前瞻性的？</p>\n<p>Monty：我的办法是信任客户。我的想法一直很坚定，那就是跟客户合作、解决问题，了解他们未来可能遇上的新问题，再共同将其克服。</p>\n<p>所以只要有了良好而且足够广泛的用户群体，比如 MySQL 和 MariaDB 建立起的客户基础，那他们就能告诉我，未来会走向哪里。</p>\n<p>我在等待未来的到来，同时也成为造就未来的一部分。所以，认真倾听客户意见，与他们合作，自然就能了解最新的技术。跟客户距离越近，我们就越了解功能需求，并据此安排自己的工作。</p>\n<p>对于开发者，我们要做的是为他们提供正确的技术、让他们满意。总之，只要明确了需要解决的问题，技术选型自然就会容易得多。</p>\n<p>InfoQ：那您会常跟社区中的开发者讨论技术问题吗？</p>\n<p>Monty：我经常参与技术会议，在那里跟与会者们交流。这也算是一种探讨吧。</p>\n<p>另外，在接触世界各国的客户，比如中国的客户时，也可以跟内部员工讨论关于 MySQL 和 MariaDB 的问题。他们代表的就不是客户，而是社区成员。所以我会认真倾听。</p>\n<p>InfoQ：对于想要学习 MariaDB 或 MySQL 的中国开发者，您有什么建议吗？</p>\n<p>Monty：首先应该积极参与到社区当中，帮助他人、改进实现。如果你需要某项功能，就想办法着手开发，并随时向 MariaDB 基金会寻求帮助。我们可以帮助大家，告诉你具体该怎么做。你审查过自己的代码吗？你也可以参与审查其他贡献者的代码，这就是实实在在的开源贡献。</p>\n<p>而要想成为一名出色的程序员，拥有一份能做一辈子的开发工作，那最好能让自己积累起名望，让自己在开源世界拥有一席之地。有了这些积累，就不是你找工作，而是工作来找你了。保持住好奇心，积极探索事情是如何运作的，这样我们就会变得更好，对企业的价值也越大。</p>\n<p>本文节选自InfoQ《专访“MySQL 之父”：我曾创造 MySQL，也将颠覆 MySQL》，作者：李冬梅。</p>\n<p><strong>目录</strong></p>\n<p><strong>热点 | Hot</strong></p>\n<p>DevOps 已死，平台工程才是未来</p>\n<p>上云“被坑”十年终放弃，寒冬里第一轮“下云潮”要来了？</p>\n<p>那位用 Rust 重写数据库的创始人来复盘了：删除 27 万行 C++ 代码，值吗</p>\n<p><strong>理论派 | Theory</strong></p>\n<p>字节大规模微服务语言发展之路</p>\n<p>去哪儿网 Service Mesh 落地实践：100% 容器化打底，业务友好是接入关键</p>\n<p><strong>推荐文章 | Article</strong></p>\n<p>新一波 JavaScript Web 框架</p>\n<p>字节跳动开源 BitSail：重构数据集成引擎，走向云原生化、实时化</p>\n<p><strong>观点 | Opinion</strong></p>\n<p>当“增加人员”不足以解决问题，你就该考虑应用“微前端”了</p>",
    "publish_time": "2022-11-08 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Docker 发布首个支持 WebAssembly 支持工具预览版",
    "url": "https://www.infoq.cn/article/fc9kVXeSj3gylssSHFMD",
    "summary": "<p>在KubeCon NA 2022大会的<a href=\"https://youtu.be/3j915xoDovs\">云原生Wasm活动日</a>\"中，Docker宣布与CNCF Wasm运行时项目<a href=\"https://github.com/WasmEdge/WasmEdge\">WasmEdge</a>\"合作推出<a href=\"https://www.docker.com/blog/docker-wasm-technical-preview/\">Docker+Wasm技术预览</a>\"。只需一个命令docker compose up，Docker开发人员就可以立即构建、分享和运行一个完整的Wasm应用程序。</p><p>&nbsp;</p><p>Wasm最初是作为Web浏览器的安全沙盒开发的。近年来，作为VM和Linux容器（LXC）的一个安全、轻量级、快速、可移植的替代方案，它在服务器端找到了许多应用场景——这一领域最初是由Docker开创的。</p><p>&nbsp;</p><p>Second State提供了一个<a href=\"https://github.com/second-state/microservice-rust-mysql\">标准的Docker+Wasm演示应用程序</a>\"。这是一个数据库驱动的Web应用程序，它包含一个用于运行整个Web服务（微服务）的WasmEdge“容器”，以及两个用于运行支持服务的Linux容器（一个用于MySQL数据库，一个用于为前端UI提供静态HTML页面的NGINX）。这三个容器在同一个网络中并行运行，共同组成一个应用程序。微服务用Rust编写，并编译成Wasm。它有一个高性能（非阻塞）的HTTP服务器、一个事件处理程序（处理HTTP请求的业务逻辑）和一个MySQL数据库客户端。整个“容器化”的微服务只有3MB，而相比之下，数据库和NGINX的Linux容器则有数百MB。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2c/2c6238b0c85c353ea41e674e43e5f6bf.png\" /></p><p></p><p>图片来源：<a href=\"https://www.docker.com/blog/docker-wasm-technical-preview/\">Docker+Wasm技术预览简介</a>\"</p><p>&nbsp;</p><p><a href=\"https://github.com/docker/compose\">Docker Compose</a>\"不仅能将Wasm应用程序和容器一样运行，还会将Rust源代码构建为Wasm。开发人员甚至不需要安装Rust编译器工具链，因为Docker也已将整个构建环境容器化。Docker + Wasm是一个单独的工具，负责构建和运行Wasm应用程序。</p><p>&nbsp;</p><p>随着Docker发起了容器革命（导致了云原生时代的到来），Docker<a href=\"https://docs.docker.com/desktop/wasm/#running-a-multi-service-application-with-wasm\">在“多运行时”世界</a>\"中支持Wasm的努力变得特别有意义。</p><p></p><p></p><blockquote>Docker+Wasm的发布非常有意义。我们不再生活在单运行时的世界中，我们有Linux容器、Windows容器和Wasm容器。OCI可以打包它们，@docker可以构建和运行它们。—— Docker联合创始人<a href=\"https://twitter.com/solomonstre/status/1584817684172005376\">Solomon Hykes</a>\"</blockquote><p></p><p></p><p>Docker+Wasm背后的技术主要来自开源社区。例如，Docker依赖一个名为<a href=\"https://github.com/second-state/runwasi\">runwasi</a>\"的Containerd shim（<a href=\"https://github.com/deislabs/runwasi\">最初由微软的DeisLabs创建</a>\"）来启动WasmEdge并执行Wasm程序。</p><p>&nbsp;</p><p>开源工作已远远超出了Docker。例如，Red Hat团队已经<a href=\"https://opensource.com/article/22/10/wasm-containers\">将Wasm运行时支持集成到OCI运行时crrun</a>\"中。这<a href=\"https://wasmedge.org/book/en/use_cases/kubernetes.html\">使得整个Kubernetes栈能够完美支持WasmEdge应用</a>\"。事实上，在KubeCon活动的前几天，Liquid Reply团队已经演示了使用WasmEdge的<a href=\"https://github.com/KWasm/podman-wasm\">Podman+Wasm</a>\"。</p><p>&nbsp;</p><p>KubeCon活动上还演示了其他Wasm应用，包括：<a href=\"https://github.com/WasmEdge/wasmedge_hyper_demo/tree/main/server-tflite\">AI推理</a>\"应用、<a href=\"https://github.com/second-state/dapr-wasm\">基于Dapr的微服务</a>\"和<a href=\"https://github.com/second-state/MEGA\">流式管道中的数据处理功能</a>\"。现在，开发人员可以使用Docker+Wasm轻松地构建、分享和运行这些应用程序了。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/11/docker-webassembly/\">https://www.infoq.com/news/2022/11/docker-webassembly/</a>\"</p>",
    "publish_time": "2022-11-08 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "解读Gartner 2023 年十大战略技术趋势",
    "url": "https://www.infoq.cn/article/QeEpTFuWHJC2s7k8K7Rv",
    "summary": "<p>前不久，Gartner对外发布了<a href=\"https://www.infoq.cn/article/RPeJFB2plzMHEvWQkpmS\">企业机构在 2023 年需要探索的十大战略技术趋势</a>\"。根据Gartner的调研，全球绝大部分的CEO都认为2023年全球经济可能会出现衰退。因此，整份报告以“如何应对未来的不确定性”为主题，从业务目标的角度试图理清楚“三大主题、十大方向”，进而帮助企业渡过难关。本文，InfoQ试图通过Gartner分析师的分享为大家解读这十大技术趋势的具体含义。</p><p></p><h2>主题一：优化</h2><p></p><p></p><h3>1.数字免疫系统</h3><p></p><p>“数字免疫系统”的概念最早于上世纪90年代被提出，当时指的是一套完全自动化的防病毒解决方案。但是今天的“数字免疫系统”指的是一套用来构建稳定系统的软件工程方法、技术和实践。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f7/f75e43eecba896211bd1f8b06c10467d.png\" /></p><p></p><p>在传统的软件工程领域，我们主要依靠一套基于测试的软件质量体系来保证软件的健壮性。而今天光靠测试已经不够了，“数字免疫系统”意味着通过给向数字免疫系统“打疫苗”这种类似的手段，来提高系统的健壮性。当然，这确实并不是单个技术，而是包含六大核心模块的一套组合打法。这六大核心模块分别是可观测性、人工智能增强测试、混沌工程、自动修复、站点可靠性工程以及应用供应链安全。</p><p>&nbsp;</p><p>以下为部分模块介绍：</p><p>&nbsp;</p><p>（1）可观测性</p><p>&nbsp;</p><p><a href=\"https://www.infoq.cn/theme/134\">可观测性</a>\"的概念起源于几十年前的“控制论”，其含义是通过检验一个系统外部输出的数据或信息去推断或者衡量系统内部状态，这样的系统称之为“可观测的系统”，这种方法叫作“可观测性”。</p><p>&nbsp;</p><p>（2）混沌工程</p><p></p><p>“混沌工程”的理念最早是由互联网公司Netflix（奈飞）创造的，其含义是在系统里面放进一只捣乱的猴子，这只捣乱的猴子在系统中上窜下跳直到搞挂系统。我们会用这种方法测试系统的不确定性，或者说通过传统方式无法检测出的隐患。“混沌工程”在实践过程中与传统的测试会共用很多测试工具，例如错误注入工具等。但是这两者之间的思想是有本质区别的，因为传统测试主要基于“预设条件输出”的方法来判断测试是否出错。也就是说，测试时需要对所有可能出现的情况进行预估、预评判，而混沌工程则是在没有预设条件的情况下逐步测试系统的稳定性以及系统未知的脆弱。</p><p>&nbsp;</p><p>（3）站点可靠性工程</p><p>&nbsp;</p><p>这是谷歌提出来的理念，其思想是用软件工程的方法解决复杂的运维问题。在传统的运维模式下，很多工作是通过人工操作来完成的，而“站点可靠性工程”强调通过开发一些自动化工具来替代人工操作。谷歌公司的运维团队（SRE）要求平时的运维工作要限制在50%的时间以内，另外50%的时间开发一些自动化的工具用来减少人工干预。这种模式不仅降低了人力成本，而且解决了运维与开发之间的一些矛盾。</p><p></p><h3>2.应用可观测性</h3><p></p><p>&nbsp;</p><p>“可观测性原理”是通过观察系统外部输出的信息来判断系统内部的状态，进而优化系统，当我们将这种理念从单纯的“IT观察”或者“IT监控”的角度推广到企业运营中去的时候，我们将其叫作“应用可观测性”。</p><p>&nbsp;</p><p>企业中每一个决策的发生都会产生相应的数据结果。即使我们不知道决策是什么，或者即使决策的执行和计划有出入，但最终都会通过数据的形式反馈给我们真实的数据结果。当我们收集到这些输出的反馈数据结果以后，可以叠加“场景信息”，通过行业知识和对行业的理解，对数据进行解读，应用AI分析的方法给决策提供建议，实际上就是为了优化决策。优化完决策之后，这个决策会被再次执行，生成更多数据，我们就可以此创作出反馈循环进而做出更加精准的数据驱动决策。</p><p></p><h3>3.AI信任、风险与安全管理</h3><p></p><p>&nbsp;</p><p>如今，AI的应用变得越来越广泛。对于AI应用、AI模型背后的“可解释性”或者说“公平性”，实际上存在一些问题。比如，一些互联网电商巨头可以通过AI系统追踪每一名物流仓储部门员工的工作效率，统计每一名员工的“摸鱼时间”，然后自动生成解雇指令。用这种AI程序的方法去决定一个人的招聘或者解雇，不禁让人疑惑应用的算法是否公平。</p><p>&nbsp;</p><p>事实上，许多企业机构未做好管理 AI 风险的充分准备。Gartner 在美国、英国和德国开展的一项调查显示，41%的企业机构曾经历过 AI 隐私泄露或安全事件。但该调查也发现积极管理 AI 风险、隐私和安全的企业机构在 AI 项目中取得了更好的成果。与未积极管理这些功能的企业机构的 AI 项目相比，在这些企业机构中有更多的 AI 项目能够从概念验证阶段进入到生产阶段并实现更大的业务价值。</p><p>&nbsp;</p><p>企业机构必须使用新的功能来保证模型的可靠性、可信度、安全性和数据保护。AI 信任、风险和安全管理（TRiSM）需要来自不同业务部门的参与者共同实施新的措施。</p><p></p><h2>主题二：扩展</h2><p></p><p></p><h3>4.行业云平台</h3><p></p><p>&nbsp;</p><p>“行业云平台”本质上是一种新的“云服务”模式，这与传统模式的区别在于：我们一般会把“云服务”分成三层（IaaS层、PaaS层、SaaS层）。常见的应用方法是在IaaS层和PaaS层之上构建自己的应用，这是一种路径。另外一种路径是直接采购一站式的SaaS解决方案，这样就不需要担心基础设施的事情、反正厂商已经做了定制化的方案。</p><p>&nbsp;</p><p>“行业云平台”本质上是在这两者当中找到一个新的细分市场，结合了现在公有云的IaaS+PaaS层，然后以此作为技术底座，其上的SaaS部分并不是给企业提供一个一站式的方案，而更像是把SaaS里面具体化的定制化方案拆解开来变成可重复使用的业务功能模块，企业根据此做自定义的研发，这种模式比今天的“IaaS+PaaS模式”多了更多业务功能，但是比今天的SaaS模式更加灵活，实际上是介于这两种模式之间的一种新的“云服务模式”。</p><p></p><h3>5.平台工程</h3><p></p><p><a href=\"https://www.infoq.cn/article/7porVp7qVF03BVc2tDd6\">“平台工程”实际上是DevOps的补充形式。</a>\"DevOps之所以形成是因为企业希望将“运维”和“开发”两件事情融合起来。在这个过程中，有些企业应用DevOps比较成功，另外一些企业在应用DevOps的时候走了弯路。有些组织会把DevOps理解成：让开发人员去负责运维的工作。这种模式最大的问题在于给开发人员的负担太重了，因为许多开发人员并不太想处理这些运维的问题，也不太想去碰复杂的基础设施。更何况有些时候对于企业来说，开发周期是比较稀缺的资源。</p><p>&nbsp;</p><p>如果企业面临上述问题，可以尝试使用“平台工程”这样一种新的架构。“平台工程”本质上是通过工具和流程，为企业的软件开发团队提供自助开发门户或者叫“内部开发平台”，该平台实际上可以涵盖应用程序的整个生命周期，由专门的平台工程团队创建和维护，开发人员提交代码后，由平台上的自动化工具负责做自动化发布。对开发人员而言，这样可以避免在运维流程过多介入，同时不需要触碰底层的基础设施。</p><p></p><h3>6.无线价值实现</h3><p></p><p>由于没有一项技术能够占据主导地位，企业将使用一系列无线解决方案来满足办公室 Wi-Fi、移动设备服务、低功耗服务以及无线电连接等所有场景的需求。Gartner 预测，到 2025 年，60%的企业将同时使用五种以上的无线技术。</p><p>&nbsp;</p><p>“无线价值实现”本质上指现在各种各样的无线协议变得越来越成熟，甚至已经可以给我们带来一些落地的商业价值。当然，这种商业价值很多时候还是以一种比较碎片化的形式出现，不是“一站式的解决方案”，更多的是一些垂直的碎片化方案。&nbsp;</p><p></p><h2>主题三：开拓</h2><p></p><p></p><h3>7.超级应用</h3><p></p><p>“超级应用”实际上是从中国传出来的技术趋势，最大的案例是支付宝和微信。这些超级应用都有巨量的用户、流量以及很强的小程序生态。这种趋势也被众多西方国家仿效，很多企业在复制这种模式。</p><p></p><h3>8.自适应AI</h3><p></p><p>&nbsp;</p><p>“自适应AI”本意是传统的AI系统需要面对不断变化的环境，具体要求为：一是模型训练好以后，由于外部环境不断改变，模型是否可以继续应用到不断变化的环境中；二是模型训练好以后，需要添加更多的训练数据迭代模型，但是我们现在看到很多的训练数据都是一些小数据而非大数据；三是希望模型最后在推理的时候产生一些个性化的结果，而非一般化的结果。这三个新的要求实际上对AI模型来说是希望模型训练和推理逐渐走向在线训练、在线推理。</p><p>&nbsp;</p><p>“在线推理”比较好理解，各大短视频或者电商APP会结合用户兴趣持续推荐可能感兴趣的内容；“在线训练”是指背后的AI模型需要实时更新，只有实时更新才能更好响应进一步输入的工作，进而让训练和推理形成正向循环，这个叫作“自适应AI”。</p><p></p><h3>9.元宇宙</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bf/bfbe36bf48ecc188ced22af269ceabc6.png\" /></p><p></p><p>Gartner定义的“元宇宙”是一个“虚拟共享空间”，这个“虚拟共享空间”有五个不同的维度（五个属性）：Persistent（持久性）；Immersive（沉浸式）；Device-independent，实际上是和设备无关的，现在看到的AR/VR眼镜只是早期“元宇宙”进入的一个端口；Not beowned by a singlvendor，不会被某一家厂商所垄断；Virtual economy，一个虚拟经济体，不只单纯的是一个游戏，更多的是跟物理世界平行的一个商业的数字世界。</p><p>&nbsp;</p><p>Meta的实践不是“元宇宙”所有的内涵，因为Meta走的技术路线更像是一个VR路线，而Gartner定义的“元宇宙”是一个“虚实结合”的路线，Gartner有三个“T”：Transform、Transport、Transact。Transport的意思是将人传送到数字世界，VR更像是Transport；Transform的意思是将数字世界拉到物理世界里面，类似于AI的路径；Transact的意思是元宇宙不是另外一个更加高级的游戏，很大程度上是我们另外一种生活方式。</p><p>&nbsp;</p><p>很多时候，我们会认为“元宇宙”这样的一个趋势离我们好像有点远，但是实际上也并不完全是这样，一些新的商业模式还是比较有希望的，比如“数字人”、“工业元宇宙平台”等。</p><p>&nbsp;</p><p>以“工业元宇宙平台”为例，西门子和英伟达联手创作了“工业元宇宙平台”。西门子作为制造业的巨头有很多制造业的经验可以用来输出，通过这种类似于系统化的或者是IT化的方式赋能其它行业，而英伟达主要提供算力资源。“工业元宇宙”实际上面对的场景非常复杂，可能是工厂中的一条流水线需要改造，在改造的过程中传统做法是把现在的流水线停掉，然后再改造、试运行、投产，这个过程实际上浪费了大量的金钱和时间成本，如果可以做一个数字化的平台，高度模拟和仿真现有流水线的情况，并且在“数字世界”里将流水线先改造，做一些虚拟制造或者做模拟制造，模拟测试没问题之后再对物理空间中的真正流水线开始动手改造，效率会提高很多，时间也会省很多，成本也会降很多。</p><p>&nbsp;</p><p>“工业元宇宙”的商业逻辑是合理的，但可能存在行业化的问题，这取决于厂商本身是做什么的，如果跨到不太熟悉的行业，难度会非常高。</p><p></p><h3>10.可持续的技术</h3><p></p><p>&nbsp;</p><p>“可持续性”这件事情实际上是全球很多企业都在谈的一个问题，这个问题对于中国的客户、企业或者场景来说，很多时候讲的是“双碳”。实际上我们做“双碳”也要看怎么做，做“双碳”不仅仅是为了保护环境，更多是为了保证能源安全。能源安全的自主可控实际上是一个很大的国家战略问题。很多企业其实在做“绿色数据中心”有关的事情，如果眼光放长远去看，利用一些可持续的技术主动把“碳”减下来，减下来的“碳”可能会变成企业另外一个收入来源。</p><p>&nbsp;</p><p>在其他条件同等的情况下，注重“双碳”层面投入的企业也更有可能获得企业和投资者的青睐。</p>",
    "publish_time": "2022-11-08 11:15:29",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "乾象投资：基于JuiceFS 构建云上量化投研平台",
    "url": "https://www.infoq.cn/article/owwaIZuU262HfUFFy8pd",
    "summary": "<p>乾象投资 Metabit Trading 成立于2018年，是一家以人工智能为核心的科技型量化投资公司。核心成员毕业于 Stanford、CMU、清北等高校。目前，管理规模已突破 30 亿元人民币。</p><p></p><p>Metabit 非常重视基础平台的建设，有一支强大的 Research Infrastructure 团队。团队试图打破在单机上进行研发的壁垒，利用云计算进行更高效、安全的工具链研发。</p><p></p><h2>01 量化的研究都在做什么</h2><p></p><p>作为一家成立时间不久的量化投资机构，我们在对基础存储平台进行选型时，会受到这样两方面的因素的影响：公司成立的时间比较短，没有太多技术上的历史负担，在做技术选择时，更偏向于使用更现代的技术栈；同时，量化投资中使用到的机器学习场景中的特性也会影响到技术的选择。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/02/0294b00d99531d907ac7273bcd8fba13.png\" /></p><p></p><p>上图是我们研究场景中和机器学习关联最紧密的策略研究模式的简化示意图。首先，在模型训练之前需要对原始数据做特征提取。金融数据的信噪比特别低，如果直接使用原始的数据进行训练，得到的模型噪音会非常大。原始数据除了行情数据，即大家经常会看到的市场上的股价、交易量之类的数据，也包括一些非量价的数据，比如研报、财报、新闻、社交媒体等之类的非结构化数据，研究人员会通过一系列的变换提取出特征，再进行 AI 模型训练。</p><p></p><p>模型训练会产出模型以及信号，信号是对未来价格趋势的判断；信号的强度意味着策略导向性的强度。量化研究员会根据这些信息去优化投资组合，从而形成交易的实时仓位。这个过程中会考虑横向维度（股票）的信息来进行风险控制，例如某一行业的股票不要过度持仓。当仓位策略形成之后，量化研究员会去模拟下单，而后得到实时仓位对应的盈亏信息，从而了解到这个策略的收益表现，以上就是一个量化研究的完整流程。</p><p></p><h3>量化研究业务特点</h3><p></p><p></p><p>研究需求产生大量突发任务：高弹性&nbsp;</p><p>在策略研究的过程中，量化研究员会产生策略想法，他们会通过实验去验证自己的想法。伴随着研究人员新想法的出现，计算平台就会产生大量的突发任务，因此我们对计算的弹性伸缩能力的要求很高。</p><p></p><p>研究任务多样化：灵活性</p><p>从上面的例子可以看到，整个流程涵盖了非常多不同的计算任务，例如：</p><p>特征提取，时序数据上的计算；模型训练，经典的机器学习的模型训练场景；投资组合优化，会涉及到最优化问题的任务；策略回测，读入行情的数据，再对策略的表现去做模拟撮合，得到仓位对应的表现。</p><p>整个过程任务的种类是非常多样化的，对计算的要求也很不一样。</p><p></p><p>研究内容需要保护：模块化，隔离&nbsp;</p><p></p><p>研究员的投研内容是公司的重要 IP（知识产权）。为了保护这些知识产权，公司的研究平台会将每个策略研究环节抽象成包含标准输入输出和评价方式的模块。例如对模型的研究，输入标准的特征值，输出预测的信号和模型。通过对模块之间进行隔离，研究平台可以有效保护 IP 的安全性。在进行存储平台建设时，需要针对模块化这个需求做相应的设计。</p><p></p><h3>量化研究数据特点</h3><p></p><p></p><p>大量任务的输入来自于相同的数据，比如上文提到的回测，量化研究员需要对历史策略去做大量的回测，同样的仓位使用不同的参数去测试，观察它们表现；或者特征提取，经常有一些基础特征和新特征的组合，其中大量的数据是来自于相同的数据源。</p><p></p><p>以 A 股的股票为例：A股市场十年的分钟K线历史行情，5000/2股票240分钟250天10年8字节*20列=240GB，整体10年的数据量大约是 240G。</p><p></p><p>如果使用更细力度的数据，数据量就会更大，一般来说原始数据不会超过 100TB 的范围。在大数据时代这算不上是特别大的数据量，但是当大量的计算任务去同时去访问这些数据，这种场景就对数据存储的有一些要求。</p><p></p><p>另外，量化投研过程中伴随着大量的突发任务，研究团队希望能将这些任务的结果存储起来，因此会产生大量 archive 数据，但这些数据的访问频率很低。</p><p></p><h3>量化研究计算任务特点</h3><p></p><p>基于以上特点，如果以传统的机房方式，是很难去满足我们的计算需求，因此把计算搬到云计算平台对我们来讲是一个相对合适的技术选择。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/05/057d5601c903af4b82957113baa40d5e.png\" /></p><p>第一，突发任务多，弹性非常大。上图是我们某个集群近期的运行实例数据。可以看到在多个时间段里，整个集群实例都是被打满的状态，但是同时整个计算集群的规模也会有 scale 到 0 的时候。量化机构的计算任务和研究员的研发的进度是有很大关联的，波峰波谷的差距会非常大，这也是离线研究任务的特点。</p><p></p><p>第二，“技术爆炸”，很难准确预估何时会产生算力需求。“技术爆炸”是科幻小说《三体》的概念，对应到我们这就是我们的研究模式和算力的需求会发生飞跃式进步，我们很难准确预估算力需求的变化。我们在&nbsp;2020 年年初的时候，研究的实际用量和预估用量都非常小，但是当研究团队提出的一些新的研究方法思路之后，会在某个瞬间突然对算力产生非常大的需求。而容量规划是在建设传统机房的规划时候非常重要的一件事情。</p><p></p><p>第三，现代 AI 生态，几乎是搭载在云原生平台上的。我们做了很多创新的技术尝试，包括现在非常流行的 MLOps，将整套 pipeline 串联起来，再去做机器学习训练的流水线；现在很多的分布式的训练任务的支持，都是面向云原生去做了很多的开发工作，这也使得我们把整个计算任务放到云上成为一个很自然的选择。</p><p></p><h2>02 量化平台存储需求</h2><p></p><p></p><p>根据上面业务和计算的需求，可以比较容易的去推导出来我们对存储平台的需求。</p><p>计算与存储不均衡。上文提到计算任务会有很大的突增，计算量会很容易会达到非常高的水平。而热数据的增长量并没有那么快，这就意味着我们需要去做存算分离。为热数据，比如行情的数据，提供高吞吐的访问。上百个任务同时访问数据，对它吞吐要求非常高。为冷数据提供低成本存储。量化研究需要大量 archive 数据，也要为这些数据提供相对低成本的存储。文件类型/需求多样性即 POSIX 兼容性。我们有很多不同的计算任务，这些计算任务对文件的类型的需求是非常多样的，例如CSV、Parquet 等，有一些研究场景还有更灵活的定制开发的需求，这就意味着在选型的时候不能够对文件存储方式做严格限制，因此 POSIX 的兼容性对于存储平台选型是一个很关键的考量因素。IP保护：数据共享与数据隔离。我们 IP 保护的需求，不仅是计算任务上需要做这样的隔离，在数据上也是需要支持这样的隔离能力；同时对行情数据这类相对公开的数据，还需要支持研究员的获取方式是便捷的。AI 生态，在云的平台上去做各种任务的调度。这也是较为基础的一个使用需求，因此存储上也是需要对 Kubernetes 做很好的支持。模块化即中间结果存储/传输。计算任务模块化的场景，导致我们会对中间结果的存储跟传输也有需求。举个简单的例子，在特征计算过程中会生成比较大量的特征数据，这些数据会立刻用于被训练的节点上，我们需要一个中间存储介质去做缓存。</p><p></p><h2>03 存储方案选型</h2><p></p><p></p><h3>非 POSIX 兼容方案</h3><p></p><p></p><p>最初，我们尝试了很多对象存储的方案，也就是非 POSIX 的方案。对象存储有很强的扩容能力，而且成本非常的低，但是对象存储的问题也很明显。最大的问题就是没有 POSIX 兼容性。对象存储的使用方式跟文件系统有比较大的区别，如果把对象存储直接作为接口面向研究员，对他们来讲使用有很大的难度，便利性也有很大的限制。</p><p></p><p>除此之外，很多云厂商的对象存储有请求限制。例如，阿里云会对整个帐号的 OSS 带宽做限制。对于普通的业务场景这通常是可以接受的，但是突发性任务会在瞬时产生非常大的带宽需求，仅仅使用对象存储很难去支撑这类场景。</p><p></p><p>另一个方案是 HDFS ，我们在 HDFS 上面并没有做太多测试。首先，我们所采用的技术栈对 Hadoop 没有太强的依赖；同时， HDFS 对 AI 训练的产品的支持并没有特别突出，而且 HDFS 没有完整的 POSIX 兼容性，这对我们的使用场景会有一些限制。</p><p><img src=\"https://static001.geekbang.org/infoq/14/1491b9a378c69faf86c14106da1fca11.png\" /></p><p></p><h3>云上 POSIX 兼容方案</h3><p></p><p></p><p>上文中提到的业务特点决定了我们对 POSIX 兼容性有很强的需求，而且技术平台是基于公有云来进行的，因而我们将存储选型的范围确定为：云上兼容 POSIX。</p><p></p><p>云厂商会提供一些方案，比如像阿里云的 NAS，AWS EFS 之类；另外一类是像阿里云的 CPFS 方案，AWS 的 FSx 方案。这两类文件系统的吞吐是与容量强绑定的，当容量越大的时候，吞吐会越大，跟 NAS 的存储性质是直接相关的。这样的方案，在面对小量的热数据的时候不太友好，需要额外的优化才能达到比较好的表现。另外 CPFS 或者阿里云上的极速型 NAS，对低延时的读取很友好，但缺点是成本比较高。</p><p></p><p>就各自官网展示的价格，我们做了个对比。各类高性能 NAS 产品的成本大概是 1500-2000元/TB/月，JuiceFS 整体的成本会低很多，因为 JuiceFS 的底层存储是对象存储 。JuiceFS 的成本分成这样几个部分：对象存储的存储费用；JuiceFS 云服务的费用；以及SSD 缓存产生的成本。综合来看，JuiceFS 的整体成本远低于 NAS 和其他方案的成本。</p><p></p><p>在吞吐方面，早期做了一些测试，当节点数量比较少的时候，直接用 CPFS 跟做 JuiceF 对比，同时读取性能不会有很大的差异。但是当节点数变大之后，因为 NAS 类文件系统有带宽限制，读取时间整体都拉长了，而 JuiceFS 只要做好缓存集群的部署，可以非常轻松的支撑下来，并且没有太大的开销，下图场景是部署了总带宽约为 300Gb 左右的集群。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3c/3cac3b7902e46f3120ff5b0a73075186.png\" /></p><p>除了成本和吞吐以外，在技术选型时， JuiceFS 对上文提到的功能 Full POSIX、权限控制、Qos、Kubernetes 都能够比较好的支持；</p><p></p><p>值得一提的是JuiceFS 的缓存集群能力，它能够实现灵活的缓存加速。最开始时，我们使用计算节点做本地缓存，这是一个挺常见的做法。存算分离之后，希望计算节点有一些数据可以本地化，JuiceFS 这方面功能的支持是比较完善的，对于空间的占用、百分比的限制等都做得很完善。我们部署了独立的缓存集群去服务一些热数据，只要在使用之前去做缓存预热就可以了。在使用过程中，我们发现不同的计算集群资源的利用率差别很大，集群中有一些大带宽的机器，大部分时候都是用来做单节点的计算，这也就意味着机器的网络的资源基本上是没有怎么用到，而且还有一些闲置的磁盘，因此就在这些机器上去部署了缓存节点，把闲置的网络带宽给利用了起来。最终使得我们在同一个集群中，实现了一个带宽非常大的缓存集群。</p><p></p><p>目前 ，JuiceFS 被用在了以下生产场景：</p><p>计算任务的文件系统，应用于热数据输入；日志/ artifact 输出；Pipeline 数据中转：数据特征生成之后，需要中转到模型训练中，训练过程中也会有数据中转的需求，Fluid+ JuiceFS Runtime 作为中间的缓存集群来使用。</p><p></p><p>未来，我们将继续探索云原生、AI技术，用以进行更高效、安全的工具链研发和基础技术平台建设。</p><p></p><p>作者简介：&nbsp;</p><p>李健弘， Metabit Trading- Engineering manager of Research infra，专注于在量化研究领域搭建机器学习平台和高性能计算平台。在加入 Metabit Trading 之前，曾在 Facebook 担任高级工程师。</p>",
    "publish_time": "2022-11-08 11:37:46",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "开放域多轮、多模态融合、拟人化情感...智能对话技术的下半场究竟在哪儿？",
    "url": "https://www.infoq.cn/article/YXCoqIWRvZhCDw1tU6Wf",
    "summary": "<p>随着智能化产品深入生产生活，智能对话应用需求爆发，像小布、小度、小爱、天猫精灵等智能语音助手、智能家居、智能机器人等产品备受终端用户欢迎；像智能客服等产品则是当下企业必选的营销工具。如今企业和用户的多样化需求，也对智能对话技术提出了许多挑战，比如开放域多轮、多模态融合、拟人化情感等等。</p><p>&nbsp;</p><p>于是近几年，工业界陆续提出了“对话即服务”、“对话即平台”等概念，越来越多的国内外厂商开始深度投入到智能对话技术的探索与研发中。</p><p>&nbsp;</p><p>然而，智能对话是一个对技术水平要求较高的领域，对数据质量、处理效率等都有着比较高的开发要求；另一方面，目前很多已经搭建起来的对话逻辑复用和迁移难度比较高，开发者面临着繁琐的工作量，开发成本高，这也间接提高了智能对话的使用成本。</p><p>&nbsp;</p><p>那面对这些问题，当下学术界和工业界都有哪些解决方案？在“智能对话”相关技术研发方面都有哪些探索？</p><p>&nbsp;</p><p>为了赋能更多关注该领域的开发者，<a href=\"https://www.infoq.cn/article/ukt2jWfS2FVcegveGCUY\">OPPO </a>\"邀请了学术界、工业界多位技术专家，围绕智能对话展开了内容策划，并定于 2022 年 11 月 19 日下午，在北京中粮置地广场落地主题为《畅谈“智能对话”，共启“交互未来”》的 OGeek 小布沙龙，与众多开发者共同探讨智能对话的演进方向，探索人机交互的精彩未来。</p><p>&nbsp;</p><p>很多开发者都有关注上个月举行的<a href=\"https://www.infoq.cn/album/85\"> 2022 OGeek 技术峰会</a>\"，所以对 OGeek 这个技术沙龙品牌并不陌生。“OGeek Day”是由<a href=\"https://www.infoq.cn/article/SpBOGrQXJdZQSpOK8eAF\"> OPPO </a>\"数智工程系统主办的行业技术沙龙品牌，旨在为技术爱好者搭建一个技术交流和分享的开放平台。沙龙主要围绕“科技为人、以善天下”的技术理念，聚焦于为智能终端提供安全高效的数据、算力、算法、云服务方面的前沿技术，打造技术互动的行业生态，探索技术在行业应用的实践、突破及未来发展方向。</p><p>&nbsp;</p><p>本次 OGeek 小布沙龙更是精彩无限，各位开发者绝不能错过。沙龙大佬云集，分享嘉宾全员博士，OPPO 小布助手首席研究员杨振宇博士作为本次沙龙的内容出品人，邀请了清华大学计算机科学与技术系长聘副教授黄民烈博士、百度主任研发工程师牛正雨博士、OPPO 小布助手算法专家索宏彬博士作为内容分享嘉宾；沙龙内容全程硬核，分享主题从学术研究到企业技术实践，将给到场的开发者奉上一次技术的饕餮盛宴。</p><p>&nbsp;</p><p>以下为本次 OGeek 小布沙龙的内容安排：</p><p></p><h2>14:00-14:20 开场：畅谈“智能对话”，共启“交互未来”</h2><p></p><p></p><p>演讲嘉宾履历简介：杨振宇博士，OPPO 小布助手首席研究员，CCF 高级会员，曾在国防科大等高校任教，学术论文代表作单篇他引超过 800 次，入选 ESI Top 0.1%。近年来主要从事自然语言处理、对话式 AI 相关算法研究与落地应用工作，2018 年加入 OPPO 主导 NLP 与对话相关工作，帮助公司级战略产品小布助手实现月活突破 1.4 亿。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/54/2e/547edb8f8a36ca3a11df28af59c6042e.png\" /></p><p></p><p></p><h2>14:20-15:05 主题分享：预训练对话大模型</h2><p></p><p></p><p>演讲嘉宾履历简介：黄民烈博士，清华大学计算机科学与技术系长聘副教授，国家杰出青年科学基金获得者，智能技术与系统实验室副主任。主要研究方向为自然语言生成、对话系统、阅读理解等。曾获得中国人工智能学会吴文俊人工智能科技进步奖一等奖（第一完成人），中文信息学会汉王青年创新奖，阿里巴巴创新合作研究奖。发表国际顶级会议或期刊论文超过 100 篇，获得专利授权 10 余项，5 次获得国际主流会议的最佳论文或提名（IJCAI、ACL、SIGDIAL 等），著有国内第一本关于自然语言生成的著作《现代自然语言生成》。研发对话系统平台 ConvLab 和 ConvLab2，首个中文开放域对话预训练模型 CDial-GPT，中文开源对话模型 EVA，首个情感对话机器人 Emohaa。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/9b/3c/9b0f9e153c1cc312a239b5dc17589f3c.png\" /></p><p></p><p></p><h2>15:05-15:50 主题分享：百度文心 PLATO 对话技术的探索及应用</h2><p></p><p></p><p>演讲嘉宾履历简介：牛正雨博士，现任百度自然语言处理部主任架构师，负责通用对话方向（北京团队）的技术研发与应用。曾参与百度知识图谱构建、搜索 query 分析等项目，至今已发表学术论文四十余篇，作为项目成员曾获得 2017 年度中国电子学会科技进步一等奖。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/97/2e/973c5c707f6dbf1a42722f565cc5c82e.png\" /></p><p></p><p></p><h2>16:05-16:50 主题分享：OPPO 小布语音交互技术实践</h2><p></p><p></p><p>演讲嘉宾履历简介：索宏彬博士，OPPO 小布助手算法专家，CCF 会员，曾在中国科学院、联想研究院、阿里达摩院工作，学术论文发表超过 40 篇，语音技术专利 30 项。近年来主要从事个性化语音交互、语音唤醒、语音识别和副语言属性识别算法研究与落地应用工作，2022 年加入 OPPO 主导语音技术研发工作，帮助公司级战略产品小布助手实现月交互突破 30 亿次。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/e6/4b/e62a8761b5de21b3b5527388a46b614b.png\" /></p><p></p><p></p><h2>16:50-17:50 圆桌对话：智能对话技术的“下半场”在哪？</h2><p></p><p></p><p>届时来自学术界与工业界的多位博士将一起探讨以下话题：</p><p>&nbsp;</p><p>关于智能对话技术的研究与探索，目前学术界和工业界的侧重点分别是什么？当前 B 端企业和 C 端用户对于“智能对话”产品的核心需求分别有哪些？目前智能对话领域最大的“技术挑战”是什么？如何应对这个挑战？XR 等硬件设备的发展和元宇宙概念的火爆，将对智能对话等“人机交互”领域产生怎样的影响？在你们看来，下一代“人机交互”的理想形态是怎么样的？“智能对话”未来在里面会扮演怎样的角色？如果只选一个，未来 2～3 年内，您觉得智能对话等人工交互领域最有前景的方向是什么？为什么？</p><p>&nbsp;</p><p></p><h2>17:50-18:00 闭幕：Time for communication</h2><p></p><p>&nbsp;</p><p>智能对话的实现逻辑，简单来说，就是依赖知识图谱对输入的文字进行实体和关系等语义的识别与理解，通过深度学习（包括各种序列学习）的框架得到候选输出、通过推理来做最后回答的排序和过滤来实现最后的输出，而技术专家们就是基于此进行了技术探索和迭代。</p><p>&nbsp;</p><p>届时，在现场听了一下午技术专家们深度干货内容演讲的你，肯定会有一大堆问题想要提问吧！所以，我们除了在每个演讲后为各位准备了 QA 时间，在最后闭幕阶段也准备了惊喜小环节。</p><p>&nbsp;</p><p>话不多说，2022 年 11 月 19 日下午，来北京中粮置地广场与各位大佬面对面交流吧！点击链接 <a href=\"http://gk.link/a/11O0y\">http://gk.link/a/11O0y</a>\" 即刻报名本次活动~</p>",
    "publish_time": "2022-11-08 11:47:26",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "YouTube数据库如何保存巨量视频文件？",
    "url": "https://www.infoq.cn/article/vWjmBcohJQy767eM48Q0",
    "summary": "<p>本文最初发表于<a href=\"https://scaleyourapp.com/youtube-database-how-does-it-store-so-many-videos-without-running-out-of-storage-space/\">scaleyourapp.com网站</a>\"，经原作者<a href=\"https://www.linkedin.com/in/shivang-sarawagi-b7b5881b/\">Shivang Sarawagi</a>\"授权由InfoQ中文站翻译分享。</p><p></p><p>YouTube是仅次于谷歌的第二大热门网站。在2019年5月，每分钟会有超过500小时的视频内容上传到该平台。</p><p></p><p>该视频共享平台有超过20亿的用户，<a href=\"https://www.youtube.com/about/press/\">每天有超过10亿小时的视频被播放</a>\"，产生数十亿的浏览量。这些都是令人难以置信的数字。</p><p></p><p>本文会对YouTube使用的<a href=\"https://www.infoq.cn/topic/database\">数据库</a>\"和后端数据基础设施进行深入讲解，它们使得该视频平台能够存储如此巨量的数据，并能扩展至数十亿的用户。</p><p></p><p>那我们就开始吧。</p><p></p><h2>1.引言</h2><p></p><p></p><p>YouTube的旅程开始于2005年。随着这家由风险资本资助的技术初创公司不断取得成功，它于2006年11月被谷歌以16.5亿美元收购。</p><p></p><p>在被谷歌收购之前，它们的团队由以下人员组成：</p><p></p><p>两名系统管理员两名可扩展性软件架构师两名特性开发人员两名网络工程师一名DBA</p><p></p><h2>2.后端基础设施</h2><p></p><p></p><p>YouTube的后端微服务是由<a href=\"https://www.python.org/\">Python</a>\"、<a href=\"https://www.infoq.cn/topic/database\">数据库</a>\"、<a href=\"https://www.infoq.cn/topic/hardware\">硬件</a>\"、Java（使用了<a href=\"https://github.com/google/guice\">Guice框架</a>\"）和Go编写的。用户界面是使用<a href=\"https://www.infoq.cn/topic/javascript\">JavaScript</a>\"编写的。</p><p></p><p>主要的数据库是由Vitess支撑的MySQL，<a href=\"https://vitess.io/\">Vitess</a>\"是一个数据库集群系统，用于MySQL的水平扩展。另外，使用Memcache实现缓存并使用Zookeeper进行节点的协调。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/da/da35bae7c2d019d6049c823d366cddff.jpeg\" /></p><p></p><p>流行的视频通过CDN来提供，而一般的、较少播放的视频则从数据库中获取。</p><p></p><p>每个视频在上传的时候，都会赋予一个唯一的标识符并且会由一个批处理job进行处理，该job会运行多个自动化的过程，比如生成缩略图、元数据、视频脚本、编码、设置货币化状态等。</p><p></p><p>VP9 &amp; H.264/MPEG-4 AVC高级视频编码（Advanced Video Coding codecs）<a href=\"https://youtube-eng.googleblog.com/2015/04/vp9-faster-better-buffer-free-youtube.html\">会用于视频压缩</a>\"，它能够使用其他编码器一半的带宽来编码HD和4K质量的视频。</p><p></p><p>视频流则是使用基于<a href=\"https://en.wikipedia.org/wiki/Dynamic_Adaptive_Streaming_over_HTTP\">HTTP协议的动态自适应流</a>\"（Dynamic Adaptive Streaming），这是一种自适应比特率的流媒体技术，能够从传统的HTTP Web服务器上实现高质量的视频流。通过这种技术，内容可以按照不同的比特率提供给观众。YouTube客户端会根据观看者的互联网连接速度自动适应视频渲染，从而尽可能减少缓冲时间。</p><p></p><p>我曾经在一篇专门的文章中讨论过YouTube的视频转码过程，参见“<a href=\"https://scaleyourapp.com/youtube-architecture-how-does-it-serve-high-quality-videos-with-low-latency/\">YouTube是如何以低延迟提供高质量视频的</a>\"”。</p><p></p><p>所以，这里对<a href=\"https://scaleyourapp.com/an-insight-into-the-backend-infrastructure-of-a-modern-digital-bank-monzo-architecture/\">平台的后端技术有一个快速的介绍</a>\"。YouTube主要使用的数据库是MySQL。现在，我们了解一下YouTube的工程团队为什么觉得有必要编写Vitess？他们在最初的MySQL环境中面临的问题是什么，使他们在此基础上实现了一个额外的框架？</p><p></p><h2>3.为何需要Vitess</h2><p></p><p></p><p>网站最初只有一个数据库实例。随着网站的发展，为了满足日益增长的QPS（每秒查询次数）需求，开发人员不得不对数据库进行水平扩展。</p><p></p><h3>3.1 主-从副本</h3><p></p><p></p><p>副本会添加到主数据库实例中。读取请求会被路由到主数据库和副本上，以减少主数据库的负载。添加副本有助于缓解瓶颈，增加读取的吞吐量，并增加系统的持久性。</p><p></p><p>主节点处理写入的流量，主节点和副本节点同时处理读取流量。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b2/b23c802655630d1a3b2722cfee5b2066.jpeg\" /></p><p></p><p>但是，在这种场景中，有可能会从副本中读取到陈旧的数据。如果在主节点将信息更新到副本之前，一个请求读取了副本的数据，那么观看者就会得到陈旧的数据。</p><p></p><p>此时，主节点和副本节点的数据是不一致的。在这种情况下，不一致的数据是主节点和副本节点上特定视频的观看次数。</p><p></p><p>其实，这完全没有问题。观众不会介意观看次数上略微有点不一致，对吧？更重要的是，视频能够在他们的浏览器中渲染出来。</p><p></p><p>主节点和副本节点之间的数据最终会是一致的。</p><p></p><p>因此，工程师们觉得非常开心，观众们也非常开心。随着副本的引入，事情进展顺利。</p><p></p><p>网站继续受到欢迎，QPS继续上升。主-从副本策略现在很难跟上网站流量的增长了。</p><p></p><p>那现在该怎么办？</p><p></p><h3>3.2 分片</h3><p></p><p></p><p>下一个策略就是对数据库进行分片（shard）。分片是除了主-从副本、主-主副本、联盟和反范式化（de-normalization） 之外，扩展关系型数据库的方式之一。</p><p></p><p>数据库分片并不是一个简单的过程。它大大增加了系统的复杂性，并使得管理更加困难。</p><p></p><p>但是，数据库必须要进行分片，以满足QPS的增长。在开发人员将数据库分片后，数据会被分散到多台机器上。这增加了系统写入的吞吐量。现在，不再是只有一个主实例处理写入，写入操作可以在多台分片的机器上进行。</p><p></p><p>同时，每台机器都创建了单独的副本，以实现冗余和吞吐。</p><p></p><p>该平台的受欢迎程度持续上升，大量的数据被内容创作者不断添加到数据库中。</p><p></p><p>为了防止机器故障或者外部未知事件造成的数据丢失或服务不可用，此时需要在系统中添加灾难管理的功能了。</p><p></p><h3>3.3 灾难管理</h3><p></p><p></p><p>灾难管理指的是在面临停电和自然灾害（如地震、火灾）时的应急措施。它需要进行冗余，并将用户数据备份到世界不同地理区域的数据中心。丢失用户数据或服务不可用是不允许的。</p><p></p><p>在世界范围内拥有多个数据中心也有助于YouTube减少系统延迟，因为用户请求会被路由到最近的数据中心，而不是路由到位于不同大陆的原始服务器。</p><p></p><p>现在，你可以想象基础设施会变得多复杂。</p><p></p><p>经常会有未经优化的全表扫描导致整个数据库瘫痪。数据库必须进行保护，防止受到不良查询的影响。所有的服务器都需要被跟踪以确保服务的高效性。</p><p></p><p>开发人员需要有一个系统来抽象系统的复杂性，能够让他们解决可扩展性的挑战，并以最小的成本管理该系统。这一切促使YouTube开发了Vitess。</p><p></p><h2>4.Vitess：用于水平扩展MySQL数据库集群的系统</h2><p></p><p></p><p><a href=\"https://vitess.io/\">Vitess</a>\"是一个运行于MySQL之上的数据库集群系统，能够使MySQL进行水平扩展。它有内置的分片特性，能够让开发人员扩展数据库，而不必在应用中添加任何的分片逻辑。这类似于NoSQL的做法。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0d/0dd75137933e562f92fe66aeba673724.jpeg\" /></p><p></p><p>Vitess架构，<a href=\"https://vitess.io/docs/overview/architecture/\">图片来源</a>\"</p><p></p><p>Vitess还会自动处理故障转移和备份。它能够管理服务器，通过智能重写资源密集型的查询和实现缓存来提高数据库性能。除了YouTube，该框架还被业界的其他知名厂商使用，如GitHub、Slack、Square、New Relic等。</p><p></p><p>当你需要ACID事务和强一致性的支持，同时又希望像NoSQL数据库一样快速扩展关系型数据库时，Vitess就会大显身手。</p><p></p><p>在YouTube，每个MySQL连接都有2MB的开销。每一个连接都有可计算出来的成本，而且随着连接数量的增加，还必须增加额外的RAM。</p><p></p><p>通过基于Go编程语言并发支持构建的连接池，Vitess能够以很低的成本管理这些连接。它使用Zookeeper来管理集群，并使其保持最新状态。</p><p></p><h2>5.部署到云中</h2><p></p><p></p><p>Vitess是云原生的，很适合云中部署，因为就像云的模式一样，容量是逐步添加到数据库的。它可以作为一个Kubernetes感知（Kubernetes-aware）的云原生分布式数据库运行。</p><p></p><p>在YouTube，Vitess在容器化环境中运行，并使用Kubernetes作为容器编排工具。</p><p></p><p>在如今的计算时代，每个大规模的服务都在分布式环境的云中运行。<a href=\"https://scaleyourapp.com/a-super-helpful-guide-to-avoiding-cloud-vendor-lock-in-when-running-your-service-on-cloud/\">在云中运行服务</a>\"有许多好处。</p><p></p><p><a href=\"https://cloud.google.com/\">Google Cloud Platform</a>\"是一套云计算服务，它的基础设施与谷歌内部的终端用户产品（如谷歌搜索和YouTube）所用的基础设施是相同的。</p><p></p><p>每个大规模的在线服务都有一个多样化（polyglot）的持久性架构，因为某一种数据模型，无论是关系型还是NoSQL，都无法处理服务的所有使用场景。</p><p></p><p>在为本文展开的研究中，我无法找到YouTube所使用的具体谷歌云数据库的清单，但我非常肯定它会使用GCP的特有产品，如Google Cloud Spanner、Cloud SQL、Cloud Datastore、Memorystore等来运行服务的不同特性。</p><p></p><p><a href=\"https://scaleyourapp.com/google-database-how-do-google-services-store-petabyte-exabyte-scale-data/\">这篇文章详细介绍了其他谷歌服务所使用的数据库，如Google Adwords、Google Finance、Google Trends等。</a>\"</p><p></p><h2>6.CDN</h2><p></p><p></p><p>YouTube使用<a href=\"https://cloud.google.com/cdn/\">谷歌的全球网络</a>\"进行低延迟、低成本的内容传输。借助全球分布的POP边缘点，它能够使客户能够更快地获取数据，而不必从原始服务器获取。</p><p></p><p>所以，到此为止，我已经谈到了YouTube使用的数据库、框架和技术。现在，该谈一谈存储问题了。</p><p>YouTube是如何存储如此巨大的数据量的呢（每分钟上传500小时的视频内容）？</p><p></p><h2>7.数据存储：YouTube是如何存储如此巨大的数据量的呢？</h2><p></p><p></p><p>视频会存储在谷歌数据中心的硬盘中。这些数据由Google File System和BigTable管理。</p><p></p><p><a href=\"https://en.wikipedia.org/wiki/Google_File_System\">GFS Google File System</a>\"是谷歌开发的一个分布式文件系统，用于管理分布式环境中的大规模数据。</p><p><a href=\"https://cloud.google.com/bigtable/\">BigTable</a>\"是一个建立在Google File System上的低延迟分布式数据存储系统，用于处理分布在成千上万台机器上的PB级别的数据。60多个谷歌产品都使用了它。</p><p></p><p>因此，视频被存储在硬盘中。关系、元数据、用户偏好、个人资料信息、账户设置、从存储中获取视频所需的相关数据等都存储在MySQL中。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/34/3492f237b0ce0d7c491fa7504033788f.jpeg\" /></p><p></p><p></p><h3>7.1 即插即用的商用服务器</h3><p></p><p></p><p>谷歌数据中心拥有同质化的<a href=\"https://www.infoq.cn/topic/hardware\">硬件</a>\"，软件则是内部构建的，管理成千上万的独立服务器集群。</p><p></p><p>谷歌部署的服务器，能够增强数据中心的存储能力，它们都是商用服务器（commodity server），也被称为商用现成的服务器（commercial off-the-shelf server）。这些服务器价格低廉，可广泛使用和大量购买，并能以最小的成本和代价替换或配置数据中心的相同<a href=\"https://www.infoq.cn/topic/hardware\">硬件</a>\"。</p><p></p><p>随着对额外存储需求的增加，新的商用服务器会被插入到系统中。</p><p></p><p>出现问题后，<a href=\"https://en.wikipedia.org/wiki/Commodity_computing\">商用服务器</a>\"通常会被直接替换，而不是进行修理。它们不是定制的，与运行定制的服务器相比，使用它们能够使企业在很大程度上减少基础设施成本。</p><p></p><h3>7.2 为数据中心设计的存储磁盘</h3><p></p><p></p><p>YouTube每天都需要超过一个PB的新存储。旋转硬盘驱动器是主要的存储介质，因为其成本低，可靠性高。</p><p></p><p>SSD固态硬盘比旋转磁盘具有更高的性能，因为它们是基于半导体的，但大规模使用固态硬盘并不划算。</p><p>它们相当昂贵，也容易随着时间的推移逐渐丢失数据。这使得它们不适合用于归档数据的存储。</p><p></p><p>另外，谷歌正在开发一个适用于大规模数据中心的新磁盘系列。</p><p></p><p>有五个关键指标可用来判断为数据存储而构建的<a href=\"https://www.infoq.cn/topic/hardware\">硬件</a>\"的质量：</p><p></p><p>硬件应该有能力支持秒级的高速度输入输出操作。它应该符合组织规定的安全标准。与普通存储硬件相比，它应该有更高的存储容量。硬件采购成本、电力成本和维护费用应该都是可以接受的。磁盘应该是可靠的，并且延迟是稳定的。</p>",
    "publish_time": "2022-11-08 12:00:16",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "eBPF 技术实践：加速容器网络转发，耗时降低60%+",
    "url": "https://www.infoq.cn/article/8YXcO6DmQPr6JwOsqKIL",
    "summary": "<p></p><p></p><p>Linux 具有功能丰富的网络协议栈，并且兼顾了非常优秀的性能。但是，这是相对的。单纯从网络协议栈各个子系统的角度来说，确实做到了功能与性能的平衡。不过，当把多个子系统组合起来，去满足实际的业务需求，功能与性能的天平就会倾斜。</p><p></p><p>容器网络就是非常典型的例子，早期的容器网络，利用 bridge、netfilter + iptables （或 lvs）、veth 等子系统的组合，实现了基本的网络转发；然而，性能却不尽如人意。原因也比较明确：受限于当时的技术发展情况，为了满足数据包在不同网络 namespace 之间的转发，当时可以选择的方案只有 bridge + veth 组合；为了实现 POD 提供服务、访问 NODE 之外的网络等需求，可以选择的方案只有 netfilter + iptables（或 lvs）。这些组合的技术方案增加了更多的网络转发耗时，故而在性能上有了更多的损耗。</p><p></p><p>然而，eBPF 技术的出现，彻底改变了这一切。eBPF 技术带来的内核可编程能力，可以在原有漫长转发路径上，制造一些“虫洞”，让报文快速到达目的地。针对容器网络的场景，我们可以利用 eBPF，略过 bridge、netfilter 等子系统，加速报文转发。</p><p></p><p>下面我们以容器网络为场景，用实际数据做支撑，深入分析 eBPF 加速容器网络转发的原理。</p><p></p><p></p><h2>网络拓扑</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a5/a5cb4dcda3e91c7899659de5c14957a5\" /></p><p></p><p>如图，两台设备 Node-A/B 通过 eth1 直连，网段为 192.168.1.0/24。Node-A/B 中分别创建容器 Pod-A/B，容器网卡名为 ve0，是 veth 设备，网段为 172.17.0.0/16。Node-A/B 中分别创建桥接口 br0，网段为 172.17.0.0/16，通过 lxc0（veth 设备）与 Pod-A/B 连通。在 Node、Pod 网络 namespace 中，分别设置静态路由；其中，Pod 中静态路由网关为 br0，Node 中静态路由网关为对端 Node 接口地址。为了方便测试与分析，我们将 eth1 的网卡队列设置为 1，并且将网卡中断绑定到 CPU0。</p><p></p><p><code lang=\"shell\"># ethtool -L eth1 combined 1\n# echo 0 &gt; /proc/irq/$(cat /proc/interrupts | awk -F ':' '/eth1/ {gsub(/ /,\"\"); print $1}')/smp_affinity_list\n</code></p><p></p><p></p><h2>bridge</h2><p></p><p></p><p>bridge + veth 是容器网络最早的转发模式，我们结合上面的网络拓扑，分析一下网络数据包的转发路径。</p><p></p><p>在上面网络拓扑中，eth1 收到目的地址为 172.17.0.0/16 网段的报文，会经过路由查找，走到 br0 的发包流程。br0 的发包流程，会根据 FDB 表查找目的 MAC 地址归属的子接口，如果没有查找到，就洪泛（遍历所有子接口，发送报文）；否则，选择特定子接口，发送报文。在本例中，会选择 lxc0 接口，发送报文。lxc0 口是 veth 口，内核的实现是 veth 口发包，对端（peer）的 veth 口就会收包。在本例中，Pod-A/B 中的 ve0 口会收到报文。至此，完成收包方向的主要流程。当报文从 Pod-A/B 中发出，会先在 Pod 的网络 namespace 中查找路由，假设流量从 Pod-A 发往 Pod-B，那么会命中我们之前设置的静态路由：172.17.0.200 via 172.17.0.1 dev ve0，最终报文会从 ve0 口发出，目的 MAC 地址为 Node-A 上面 br0 的地址。ve0 口是 veth 口，和收包方向类似，对端的 veth 口 lxc0 会收到报文。lxc0 口是 br0 的子接口，由于报文目的 MAC 地址为 br0 的接口地址，报文会经过 br0 口上送到 3 层协议栈处理。3 层协议栈会查找路由，命中我们之前设置的静态路由：172.17.0.200 via 192.168.1.20 dev eth1，最终报文会从 eth1 口发出，发给 Node-B。至此，完成发包方向的主要流程。</p><p></p><p>上面的流程比较抽象，我们用 perf ftrace 可以非常直观地看到报文都经过了哪些内核协议栈路径。</p><p></p><p></p><h3>收包路径</h3><p></p><p></p><p><code lang=\"shell\"># perf ftrace -C0 -G '__netif_receive_skb_list_core' -g 'smp_*'\n</code></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ca/cada96c1a8714f73c4485de8e2b45abc\" /></p><p></p><p>如图，收包路径主要经历路由查找、桥转发、veth 转发、veth 收包等阶段，中间多次经过 netfilter 的 hook 点。最终调用 enqueue_to_backlog 函数，数据包暂存到每个 &nbsp;CPU 私有的 input_pkt_queue 中，一次软中断结束，总耗时 79us。但是报文并没有到达终点，后续软中断到来时，会有机会调用 process_backlog，处理每个 CPU 私有的 input_pkt_queue，将报文丢入 Pod 网络 namespace 的协议栈继续处理，直到将报文送往 socket 的队列，才算是到达了终点。综上，收包路径要消耗 2 个软中断，才能将报文送达终点。</p><p></p><p></p><h3>发包路径</h3><p></p><p></p><p><code lang=\"shell\"># perf ftrace -C0 -G '__netif_receive_skb_core' -g 'smp_*'\n</code></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d2/d22d6497990159cd926df63c37383df4\" /></p><p></p><p>如图，发包路径主要经历 veth 收包、桥上送、路由查找、物理网卡转发等阶段，中间多次经过 netfilter 的 hook 点 。最终调用网卡驱动发包函数，一次软中断结束，总耗时 62us。</p><p></p><p></p><h3>分析</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/2b/2b21055d67126e0d8acd326f72622359\" /></p><p></p><p>由 perf ftrace 的结果可以看出，利用 bridge + veth 的转发模式，会多次经历 netfilter、路由等子系统，过程非常冗长，导致了转发性能的下降。</p><p></p><p>我们接下来看一下，如何用 eBPF 跳过非必须的流程，加速网络转发。</p><p></p><p>首先，我们先看一下内核协议栈主要支持的 eBPF hook 点，在这些 hook 点我们可以注入 eBPF 程序，实现具体的业务需求。</p><p></p><p>我们可以看到，与网络转发相关的 hook 点主要有 XDP（eXpress Data Path）、TC（Traffic Control）、LWT（Light Weight Tunnel）等。</p><p></p><p>针对于容器网络转发的场景，比较合适的 hook 点是 TC。因为 TC hook 点是协议栈的入口和出口，比较底层，eBPF 程序能够获取非常全面的上下文（如：socket、cgroup 信息等），这点是 XDP 没有办法做到的。而 LWT 则比较靠上层，报文到达这个 hook 点，会经过很多子系统（如：netfilter）。</p><p></p><p></p><h3>加速收包路径</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/13/13e24ef49d8acf71ebf08e0e8b1a31cd\" /></p><p></p><p>如图，在 eth1 的 TC hook 点（收包方向）挂载 eBPF 程序。</p><p></p><p><code lang=\"apache\"># tc qdisc add dev eth1 clsact\n# tc filter add dev eth1 ingress bpf da obj ingress_redirect.o sec classifier-redirect\n</code></p><p></p><p>eBPF 程序如下所示，其中 lxc0 接口的 index 为 2。bpf_redirect 函数为内核提供的 helper 函数，该函数会将 eth1 收到的数据包，直接转发至 lxc0 接口。</p><p></p><p><code lang=\"cs\">SEC(\"classifier-redirect\") \nint cls_redirect(struct __sk_buff *skb) { \n   /* The ifindex of lxc0 is 2 */    \n   return bpf_redirect(2, 0); \n}\n</code></p><p></p><p></p><h3>加速发包路径</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ff/ff8ae5dc8839c2abbf983bd4be5afa3e\" /></p><p></p><p>如图，在 lxc0 的 TC hook 点（收包方向）挂载 eBPF 程序。</p><p></p><p><code lang=\"apache\"># tc qdisc add dev lxc0 clsact \n# tc filter add dev lxc0 ingress bpf da obj egress_redirect.o sec classifier-redirect\n</code></p><p></p><p>eBPF 程序如下所示，其中 eth1 接口的 index 为 1。bpf_redirect 函数会将 lxc0 收到的数据包，直接转发至 eth1 接口。</p><p></p><p><code lang=\"cs\">SEC(\"classifier-redirect\") \nint cls_redirect(struct __sk_buff *skb) {\n    /* The ifindex of eth1 is 1 */    \n    return bpf_redirect(1, 0); \n}\n</code></p><p></p><p></p><h3>分析</h3><p></p><p></p><p>由上面的操作可以看到，我们直接跳过了 bridge 的转发，利用 eBPF 程序，将 eth1 与 lxc0 之间建立了一个快速转发通路。下面我们用 perf ftrace 看一下加速效果。</p><p></p><p></p><h3>收包路径</h3><p></p><p></p><p><code lang=\"shell\"># perf ftrace -C0 -G '__netif_receive_skb_list_core' -g 'smp_*'\n</code></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d3/d3799f37fb4ea08e688908a1f3675811\" /></p><p></p><p>如图，在收包路径的 TC 子系统中，由 bpf_redirect 函数设置转发信息（ lxc0 接口 index），由 skb_do_redirect 函数直接调用了 lxc0 接口的 veth_xmit 函数；略过了路由、bridge、netfilter 等子系统。</p><p></p><p>最终调用 enqueue_to_backlog 函数，数据包暂存到每个 CPU 私有的 input_pkt_queue 中，一次软中断结束，总耗时 43us；比 bridge 转发模式的 79us，耗时减少约 45%。</p><p></p><p>但是，收包路径仍然要消耗 2 个软中断，才能将报文送达终点。</p><p></p><p></p><h3>发包路径</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e5/e58978b32a3307432e7e950f190026ea\" /></p><p></p><p>如图，在发包路径的 TC 子系统中，由 bpf_redirect 函数设置转发信息（ eth1 接口 index ），由 skb_do_redirect 函数直接调用了 eth1 接口的 xmit 函数；略过了路由、bridge、netfilter 等子系统。</p><p></p><p>最终调用网卡驱动发包函数，一次软中断结束，总耗时 36us，相比 bridge 模式 62us，耗时减少了约 42%。</p><p></p><p></p><h3>小结</h3><p></p><p></p><p>由 perf ftrace 的结果可以看出，利用 eBPF 在 TC 子系统注入转发逻辑，可以跳过内核协议栈非必须的流程，实现加速转发。收发两个方向的耗时分别减少 40% 左右，性能提升非常可观。</p><p></p><p>但是，我们在收包路径上面仍然需要消耗 2 个软中断，才能将报文送往目的地。接下来我们看，如何利用 redirect peer 技术来优化这个流程。</p><p></p><p></p><h2>TC redirect peer</h2><p></p><p></p><p></p><h3>加速收包路径</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/39/39764b8fa6d8d82ae597c633086d5c5c\" /></p><p></p><p>如图，在 eth1 的 TC hook 点（收包方向）挂载 eBPF 程序。</p><p></p><p><code lang=\"apache\"># tc qdisc add dev eth1 clsact \n# tc filter add dev eth1 ingress bpf da obj ingress_redirect_peer.o sec classifier-redirect\n</code></p><p></p><p>eBPF 程序如下所示，其中 lxc0 接口的 index 为 2。bpf_redirect_peer 函数为内核提供的 helper 函数，该函数会将 eth1 收到的数据包，直接转发至 lxc0 接口的 peer 接口，即 ve0 接口。</p><p></p><p><code lang=\"cs\">SEC(\"classifier-redirect\") \nint cls_redirect(struct __sk_buff *skb) {\n    /* The ifindex of lxc0 is 2 */    \n    return bpf_redirect_peer(2, 0); \n}\n</code></p><p></p><p></p><h3>分析</h3><p></p><p></p><p>由于 bpf_redirect_peer 会直接将数据包转发到 Pod 网络 namespace 中，避免了 enqueue_to_backlog 操作，节省了一次软中断，性能理论上会有提升。我们用 perf ftrace 验证一下。</p><p></p><p><code lang=\"shell\"># perf ftrace -C0 -G '__netif_receive_skb_list_core' -g 'smp_*\n</code></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/82/82ecc195b8bed7d2dce30c0b4abd6c0d\" /></p><p></p><p>如图，在收包路径的 TC 子系统中，由 bpf_redirect_peer 函数设置转发信息（ lxc0 接口 index），由 skb_do_redirect 函数调用 veth_peer_dev 查找 lxc0 的 peer 接口，设置 skb-&gt;dev = ve0，返回 EAGAIN 给 tcf_classify 函数。</p><p></p><p>tcf_classify 函数会判断 skb_do_redirect 的返回值，如果是 EAGAIN，则触发 __netif_receive_skb_core 函数伪递归调用（通过 goto &nbsp;实现）。这样，就非常巧妙地实现了网络 namespace 的切换（在一次软中断上下文中）。</p><p></p><p>最终，通过 tcp_v4_rcv 函数到达报文的终点，整个转发流程耗时 75us。从上面的函数耗时可以看到，ip_list_rcv 函数相当于 Pod 网络 namespace 的耗时，本文描述的 3 种转发模式，这段转发路径是相同的。所以，将 ip_list_rcv 函数耗时减去，转发耗时约为 14us（这里还忽略了 2 次软中断调度的时间）。比 TC redirect 模式的 43us、bridge 模式的 79us，转发耗时分别减少为 67%、82%。</p><p></p><p></p><h2>总&nbsp; &nbsp; 结</h2><p></p><p></p><p>本文以容器网络为例，对比了 3 种容器网络转发模式的性能差异。通过 perf ftrace 的函数调用关系以及耗时情况，详细分析了导致性能差异的原因。我们演示了仅仅通过几行 eBPF 代码，就可以大大缩短报文转发路径，加速内核网络转发的效率，网络转发耗时最多可减少 82%。</p><p></p><p>目前 eBPF 技术在开源社区非常流行，在 tracing、安全、网络等领域有广泛应用，我们可以利用这项技术做很多有意思的事情。感兴趣的朋友可以加入我们，一起讨论交流。</p><p></p><p>作者简介：</p><p></p><p>王栋栋，字节跳动系统技术与工程团队内核工程师，10 年系统工程师工作经验，关注 Linux networking、eBPF 等领域。目前在字节跳动，主要负责 eBPF、内核网络协议栈相关的开发工作。</p><p></p><p>今日好文推荐</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651145285&amp;idx=1&amp;sn=791730395977460f56a581fb18edeef0&amp;chksm=bdb8bc168acf35000bc2cd3c7581eb7b8f6b49b17a1f66fc91244fd332a22ec295bea090e00b&amp;scene=21#wechat_redirect\"></a>\"<a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651145623&amp;idx=1&amp;sn=27d5efdb4fc484f3ee25feea8d66152d&amp;chksm=bdb8bdc48acf34d21467412f6927ad9aa846e1760d0766364b4c345571b7a5dff72841ddc695&amp;scene=21#wechat_redirect\">每天中午都是一次“秒杀”，从 IT 视角看麦当劳中国数字化</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651145285&amp;idx=1&amp;sn=791730395977460f56a581fb18edeef0&amp;chksm=bdb8bc168acf35000bc2cd3c7581eb7b8f6b49b17a1f66fc91244fd332a22ec295bea090e00b&amp;scene=21#wechat_redirect\">对话iPod之父：这不是互联网最坏的年代</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651145274&amp;idx=1&amp;sn=49bc3312f3ec258b4872627632cc4321&amp;chksm=bdb8bc698acf357f76a8007924d40d9da527578d226fc19c1dc94886ba557ddb279901b66f44&amp;scene=21#wechat_redirect\">“羊了个羊”背后公司清仓式分红10亿元；Meta元宇宙部门今年已亏94亿美元；微软称GitHub年收入10亿美元｜Q资讯</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651145179&amp;idx=1&amp;sn=4316dc7006bed68e0022e1ec44b6c7f8&amp;chksm=bdb8bb888acf329eafb85b618128aae5fc5d802607fd670267ec4bbf1cb0c7014e7dede7f2cc&amp;scene=21#wechat_redirect\">全面审查Twitter代码、当场炒掉CEO等众多高管：马斯克正式入主Twitter</a>\"</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/93/93a6e30a75e8e663d639c54513765ef5.gif\" /></p><p></p>",
    "publish_time": "2022-11-08 12:00:56",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "服务 50+ 业务线，Apache Pulsar 在科大讯飞 SRE 的探索与实践",
    "url": "https://www.infoq.cn/article/shEoMkPI0tzUP5FiiAF4",
    "summary": "<p></p><p>本文整理自 8 月 Apache Pulsar Meetup 上的分享。科大讯飞是中国最大的智能语音技术提供商，在中文语音合成、语音识别、口语评测等多项技术上拥有国际领先的成果。2022 年 3 月，科大讯飞正式将 Pulsar 上线。本文将介绍经历一年多的测试与评估，科大讯飞为何选择 Pulsar；如何利用 SRE 保障体系将 Pulsar 从 0 到 1 落地；内部的监控与参数优化与 Pulsar 使用过程中可能出现的一系列问题及相应的解决方案。</p><p></p><p></p><h2>业务简介</h2><p></p><p></p><p>科大讯飞股份有限公司是亚太地区知名的智能语音和人工智能上市企业。自成立以来，科大讯飞一直从事智能语音、自然语言理解、计算机视觉等核心技术研究并保持了国际前沿技术水平。目前讯飞云对接了集团内部的各条业务线，包括个性化、计量授权、语音与字幕的非实时转写、AI 办公、语音云、集团云、开放平台等。其中 Pulsar 主要提供高可用、低延时的消息中间件能力。数据通过 Web API 和 SDK 的方式接入 MQ，经过消息的削峰填谷与上下游打通，从而满足业务快速增长的需求。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/90/909f31a16fdcb71e7dfd2d0a58f01440.png\" /></p><p></p><p>服务的保障层分为运营管理和服务保障平台。运营管理平台主要对申请的集群与业务进行统一管理；服务保障平台主要对脚本、指标、告警策略等方面进行管理。团队要求中间件具有为业务提供高吞吐和海量级数据服务的能力。目前，Pulsar 每天处理的数据量在十亿级别，还肩负多个跨可用区的数据同步工作。</p><p></p><p>MQ 有以下服务保障难点：</p><p></p><p>业务流量上涨十几倍，集群在流量洪峰时出现不稳定情况；集群扩容业务的感知数据在新老节点上有平衡问题；跨可用区数据同步时延及幂等性问题；维护多套集群、tickets 复杂度较高。</p><p></p><p>MQ 对高效 SRE 也有迫切需要：</p><p></p><p>接入 MQ 业务线的更多服务需要梯级保障（50+ 业务线）；更高的端对端消息写入及数据同步延时要求；业务接入 MQ 需要流程化和规范化；需要提升持续服务业务的能力；降本增效需求。</p><p></p><p>基于以上需求，团队一直在寻找合适的消息中间件产品来承载业务，通过内部多轮调研及评审，最终选择了 Apache Pulsar。</p><p></p><p></p><h2>Apache Pulsar 在讯飞的演进</h2><p></p><p></p><p>首先，团队选择 <a href=\"https://www.infoq.cn/article/LKBS54VlX2VtC9phdN0B\">Apache Pulsar</a>\" 主要考虑到以下优势：</p><p></p><p>业务收敛，多个小的集群的流量可以聚合至 Pulsar；减少运维工作量，提高生产效率，让业务聚焦于数据而非服务；集群服务存算分离，扩展性高，计算节点无状态性；多租户的友好支持，便于服务通过租户对业务进行隔离；高效率的跨地域复制数据同步能力；提供多个语言的 SDK，接入度及社区活跃度高。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/35/35238a919d19ad03ec7854358d367e11.png\" /></p><p></p><p><a href=\"https://www.infoq.cn/article/ZyNHQsXPD0N7VwHcUbTT\">Apache Pulsar </a>\"在讯飞内部的演进经历了几个阶段，上图为 Pulsar 在科大讯飞的演进过程。2021 年 7 月，讯飞内部进行了 Pulsar 的调研综述，包括技术调研、可行性调研和落地实施调研。2021 年 9 月，团队进行了 Pulsar 内部压测，验证 Pulsar 是否满足流量规划的需求。2022 年 2 月，团队开始针对压测过程中出现的问题进行性能、配置和架构等方面的调优工作。2022 年 3 月，讯飞内部上线了 Pulsar 的第一个发布版本。</p><p></p><p></p><h2>服务保障体系</h2><p></p><p></p><p>团队一直在思考该使用怎样的方式来保障 Pulsar 在集团内部的稳定性和高可用性。为此团队引入了服务分级保障的概念。目前团队根据业务线的需求设置了四级服务保障：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/48/489978a7b87e1748ac2e16f6d9c97419.png\" /></p><p></p><p></p><blockquote>测量周期：季度测算方法：可用性&nbsp;%&nbsp;=（服务总时长-累计影响时长）/&nbsp;服务总时长数据来源：PaaS 监控系统</blockquote><p></p><p></p><p></p><h3>利用 SRE 保障体系进行落地</h3><p></p><p></p><p>SRE（Site Reliability Engineering），顾名思义是站点可靠性工程。SRE 团队使用软件作为工具，来管理系统、解决问题并实现运维任务自动化。SRE 在创建可扩展和高度可靠的软件系统时十分重要。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/2e/2ec8b112a9e4d6e9c2fd78c0768379a7.png\" /></p><p></p><p>上图是讯飞云内部结合经验沉淀的 SRE 流程。它分为 MTBF（故障平均间隔时间）和 MTTR（故障平均修复时间）两个部分。MTTR 又分为故障发现、定位、处理和恢复的流程。本次分享中主要针对容量评估、架构设计、监控告警和服务限流其中几个模块，讲解 SRE 的保障理念。</p><p></p><p></p><h3>架构设计</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b0/b0fbc8ab19a31d24dd1178e464293796.png\" /></p><p></p><p>目前 Pulsar 采用多可用区的部署模式。客户端通过 VIP 接入服务，数据进入 Broker 层进行 Topic-Ownership 找到主题所在的节点，Broker 返回客户端通知当前连接所在的 Owner-Broker。下方是 BookKeeper 集群存储层。元数据存储采用 ZooKeeper 集群。多可用区之间通过跨地域复制能力进行数据同步。整体架构为混部模式，以保障 Broker 和 Bookie 交互 ZooKeeper 时的读写低延迟。</p><p></p><p></p><h3>容量规划与流量评估</h3><p></p><p></p><p>在集群接入时需要做好流量评估，观察集群容量能否满足流量需求。具体来说，团队会根据业务增长的规模（50+ 业务线）进行规划，并根据现有接入业务线申请总流量进行评估。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/0f/0ff76a621164b8a8d33610943cd97b81.png\" /></p><p></p><p>上图为业务接入示例。业务反馈对应 Topic 在<a href=\"https://www.infoq.cn/article/0LRhleM5wpzgJwaRuprC\"> Pulsar </a>\"数据增长的结果，比如 Topic 从稳定、缓慢增长到暴涨所体现出的问题；带宽读写速率的大小；单条消息大小；是否存在峰值如重大活动；业务数据是否涉及跨机房复制；消息积压告警阈值等。中间件内部发生消息积压是无法避免的，所以有必要把对应策略同步业务方，及时消除积压。</p><p></p><p>团队会通过容量模型对部署架构进行验证。下图为验证环境：三台配置相同的物理器，每台都部署了 ZooKeeper、Bookie 和 Broker 组件，模拟实时生产和消费。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/4d/4dff93e6b4f1a133f6d13a5198fccf83.png\" /></p><p></p><p>在实践过程中，上述容量模型会经过以下场景的测试：</p><p></p><p>场景一：只生产不消费，异步刷盘，Journal 和 Ledger 盘单独挂载，持续时间 30 分钟。可以看到随着消息量增长，各项延迟指标都有所增加。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f7/f7bf80dc022b1a6bda42a159bfcca747.png\" /></p><p></p><p>场景二：只生产不消费，同步刷盘，Journal 和 Ledger 盘单独挂载，持续时间 30 分钟。可以看到各项延迟指标相比异步刷盘场景要高。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a5/a580f29bd19b6799729911f646bca91d.png\" /></p><p></p><p>团队提出了以下硬件规划建议：</p><p></p><p>物理机，48 core CPU、256G 内存、万兆网卡；每台机器规划六块 SSD，为 ZooKeeper、Journal 和 Ledger 单独设置磁盘，让 Journal 盘在大流量写入时有冗余；ZooKeeper 的 log、datalogs 盘独立 SSD，保障 ZooKeeper 读写低延迟；Bookie 的 journalDirectories 独立挂载两块 SSD，提高 Journal 写盘及刷内存表并发能力；Bookie 的 ledgerDirectories 独立挂载三块 SSD，减少 Ledger 在切换期间时延。</p><p></p><p></p><h3>Pulsar 监控告警链路</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/1c/1c2ff0829382c3ffb424e166a29128cb.png\" /></p><p></p><p>上述告警链路主要借助内部 PaaS 平台的微服务来模块化和清晰化整个告警流程，每个模块专职专责。自上而下，链路包括 PaaS-Agent 感知服务、PaaS-Collector 数据收集服务、PaaS-Probe 集群可用性采集服务、PaaS-Alert 告警模块等。数据从 PaaS-Agent 的节点服务器服务出发，经过 Collector 收集、Prometheus 采集到最终的 PaaS-Alert 进行精筛，对比当前阈值是否满足预期。</p><p></p><p>该链路支持：</p><p></p><p>多可用区互监控；基础信息多可用区同步；集群信息自动同步；默认告警策略自动添加；默认告警规则自动下发；告警策略规则自由定义；短信、邮件和微信告警；秒级延迟；月、周、天报表。</p><p></p><p>告警链路使用的核心指标有：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/13/138cd25d6dba2017349ae26ace041c03.png\" /></p><p></p><p>其中星号为重点关注指标。其中：</p><p></p><p>Broker 端指标监控 Topic 流量，用以调整 Broker 端负载的均衡；Bookie 端指标监控 Journal 及 Ledger 数据刷盘情况，排查数据读写问题；ZooKeeper 端指标监控兜底监控整个集群元数据读写延迟状态。</p><p></p><p>下图是一些监控指标的实践展示：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d4/d47c1461fbd67233912c7da1f9d172d8.png\" /></p><p></p><p>下图是具体的告警策略，仅供参考：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/87/879748dbce12cb294abdb3f917a4589e.png\" /></p><p></p><p></p><h3>服务限流</h3><p></p><p></p><p>良好的服务限流策略可以预防突发流量击垮集群。具体而言，限流策略会根据业务提供的申请表内容评估峰值流量，调整生产者流量限制在可控区间；更好地利用集群磁盘及网卡资源，保障集群稳定性。</p><p></p><p>我们对一些 Namespace 进行限流操作。如下图左侧，需要限制生产者总流量为 50M，多余的部分会被拒绝，从而更好地保障集群；如下图右侧，需要限制所有 Topic 的生产者流量为 20M。不同的总流量数值都是根据业务评估得出。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/74/7434a2cc43d85e04c9f7057e850219ca.png\" /></p><p></p><p></p><h2>遇到的问题与解决方案</h2><p></p><p></p><p>在实践中团队还发现了一些问题，在此与大家分享我们的解决方案。</p><p></p><p></p><h4>问题一：在特定业务需要写入单条消息容量较大情况下，Bookie 出现了 readOnly 模式。</h4><p></p><p></p><p>原因：Broker 服务与 Bookie 服务限制消息大小不一致，导致客户端发送的消息在 Broker 端正常，但发送到 Bookie 端被拒绝，触发 Broker 重试机制。</p><p></p><p>解决方法：配置参数调整 dispatcherMaxReadSizeBytes、nettyMaxFrameSizeBytes。</p><p></p><p></p><h4>问题二：ZooKeeper 的 data、datalog 盘与 Bookie 的 Journal 及 Ledger 盘混用，读写性能、集群稳定性不佳。</h4><p></p><p></p><p>原因：Bookie 的 Journal 及 Ledger 盘读写 IO 出现高水位情况，导致 ZooKeeper 读写延迟升高。</p><p></p><p>解决方法：将 ZooKeeper 的数据盘与 Bookie 读写数据盘进行物理隔离，专盘专责。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ec/ecad1e02ea85d5350103cbc65e210175.png\" /></p><p></p><p></p><h4>问题三：集群中某些 Broker 节点流量不均衡，造成集群内其他机器较为繁忙。</h4><p></p><p></p><p>原因：现阶段 Broker 触发 load-balancer 策略，统计单台节点 heap、direct-heap、cpu、bindwithIn、bindWithOut 的使用比例，取其中一个最大值与默认阈值 85% 对比。</p><p></p><p>解决方法：基于权重的负载均衡策略，修改 loadBalancerLoadSheddingStrategy。</p><p></p><p></p><h4>问题四：高吞吐业务场景下，遇到 broker-direct-memory-OOM 时进程停止。</h4><p></p><p></p><p>原因：底层 Bookie 写入变慢，导致大量消息堆积在 Broker 的堆外内存，直至 OOM。</p><p></p><p>解决方法：生产环境下，不能保证底层 Bookie 始终写入低延迟，在 Broker 层针对特定 Namespace 或 Topic 开启限流策略。</p><p></p><p></p><h4>问题五：业务提出是否可以提供统一 IP 供客户端访问?</h4><p></p><p></p><p>原因：serviceUrl 配置列表太长，扩容 Broker 节点，业务需要同步修改配置文件。</p><p></p><p>解决方法：结合业界成熟的 VIP 方案，搭建 Keepalived + HAProxy 高可用架构。</p><p></p><p></p><h2>未来规划</h2><p></p><p></p><p>科大讯飞团队的计划后续部署 Apache Pulsar 服务的认证授权功能，来进一步提高系统安全性；实现同城双中心，保障集团更多业务接入 Apache Pulsar 时更加高效稳定。团队也会尝试将 Pulsar 与更多大数据组件（Apache Flink、Apache Spark 等）结合，完善生态。目前讯飞云基于 Docker 进行部署，缺少调度。因此团队也在探索如何在 Kubernetes 中应用 Apache Pulsar，做到开箱即用，来降低部署难度。</p><p></p><p>作者介绍：</p><p></p><p>刘侃，科大讯飞软件开发工程师，主要负责科大讯飞 -AI 云平台消息中间件 Pulsar 的落地，以及对应 SRE 服务保障工作。</p><p></p><p>活动推荐</p><p></p><p>11 月 19-20 日 Apache Pulsar 社区年度盛会来啦！点击链接，报名 Pulsar 社区线上年度峰会：<a href=\"http://gk.link/a/11O2K\">http://gk.link/a/11O2K</a>\"</p><p></p><p></p><p></p>",
    "publish_time": "2022-11-08 12:17:49",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "以斗鱼直播流为例，谈谈高并发架构实践细节｜InfoQ大会早班车第26期",
    "url": "https://www.infoq.cn/article/VBUyLObAK07FFMoNK440",
    "summary": "<p>直播是斗鱼的核心业务，直播流是其中的重中之重。本次大会早班车邀请到斗鱼架构师李奇老师，来一起探究斗鱼高可用、高并发架构实践细节。</p>",
    "publish_time": "2022-11-08 12:36:01",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "面向现代数据基础设施的新兴架构",
    "url": "https://www.infoq.cn/article/GwjITb19gaUjWaGqge4S",
    "summary": "<p></p><p>自从我们在 2020 年底发布了一套参考架构以来，数据基础设施行业的增长势头有增无减。在过去的一年里，几乎所有的关键行业指标都创下了历史新高，新的产品类别出现的速度超过了大多数数据团队可以合理跟踪的速度。甚至连基准战争和广告牌之争也卷土重来。</p><p></p><p>为了帮助数据团队紧跟行业内发生的变化，我们在这篇文章中发布了一套最新的<a href=\"https://www.infoq.cn/article/ZX7RP0GEQOMrRaFtvMuO\">数据基础设施</a>\"。它们展示了当前分析和运营系统的最佳栈，这是我们在过去一年中从众多运营商那里收集的。每个架构蓝图都包括自上一版本以来的变化摘要。</p><p></p><p>我们也会尝试解释为什么会发生这些变化。我们认为，核心数据处理系统在过去一年中保持了相对稳定，而支持工具和应用程序则迅速激增。我们探讨的假设是，平台开始在数据生态系统中显现，这有助于解释我们在数据栈的演变中看到的特殊模式。</p><p></p><p></p><h2>更新的参考架构</h2><p></p><p></p><p>在我们深入了解细节之前，先看看下面的最新架构图。这些图是在领先的数据从业者的帮助下绘制的，基于他们在内部运行的内容和他们对新部署提出的建议。</p><p></p><p>第一个视图展示了所有数据基础设施用例的统一概述：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/17/177899bef0e290abf25abac4901e2436.jpeg\" /></p><p></p><p>注：不包括 OLTP、日志分析和 SaaS 分析应用程序。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e0/e0e7c3422b78c40c463cd5d1cda519b4.jpeg\" /></p><p></p><p>第二个视图放大了机器学习，它是一个复杂的、越来越独立的工具链。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a7/a76843f939ac03a03765109eacdc726c.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a7/a76843f939ac03a03765109eacdc726c.jpeg\" /></p><p></p><p>在本文的其余部分中，我们将讨论自数据栈第一版以来发生了哪些变化，并探讨潜在的根本原因。</p><p></p><p></p><h2>改&nbsp; &nbsp;变</h2><p></p><p></p><p></p><h3>未改变的是：核心的稳定</h3><p></p><p></p><p>尽管在过去的一年里，数据基础设施的活动非常狂热，但令人惊讶的是——在某些方面——变化如此之小。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/87/875ab59b26b042e3789835c3fc98a3a4.jpeg\" /></p><p></p><p>在我们的第一篇文章中，我们区分了支持数据驱动决策的分析系统和支持数据驱动产品的运营系统。然后，我们将这些类别映射到三种模式或蓝图，通常由领先的数据团队实施。</p><p></p><p>其中一个关键问题是这些架构模式是否会趋同。但一年过去了，似乎并没有发生这种情况。</p><p></p><p>特别是，分析和运营生态系统都继续蓬勃发展。像 Snowflake 这样的云数据仓库发展迅速，主要集中在 SQL 用户和商业智能用例。但其他技术的采用也在加速，例如，像 Databricks 这样的数据仓库，正在比以往更快地增加客户。我们采访的许多数据团队证实，异构性很可能在数据栈中继续存在。</p><p></p><p>其他核心数据系统——即摄取和转换——已被证明是类似的持久性。这在现代商业智能模式中尤其明显，其中 Fivetran 和 DBT（或类似技术）的结合已经变得几乎无处不在。但这在某种程度上，运营系统也是如此，在那里出现了 Databricks/Spark、Confluent/Kafka 和 Astronomer/Airflow 等事实标准。</p><p></p><p></p><h3>新的内容：寒武纪大爆发</h3><p></p><p></p><p>在过去一年里，围绕着稳定的核心，数据栈得到了迅速的发展。概括地说，我们在两个领域看到了最多的活动：</p><p></p><p>旨在支持关键数据流程和工作流的新工具，如数据发现、可观察性或机器学习模型审计。新的应用程序，允许数据团队和业务用户以新的、更强大的方式从数据中产生价值，如数据工作区、反向 ETL 和机器学习应用框架。</p><p></p><p>我们还看到了一些新技术的引入，这些技术旨在增强核心数据处理系统。值得注意的是，围绕分析生态系统中的度量层和操作系统的湖仓一体（Lakehouse）模式，人们一直在进行激烈的争论，这两者都在向有用的定义和体系结构靠拢。</p><p></p><p></p><h3>更新的蓝图</h3><p></p><p></p><p></p><h4>蓝图 1：现代商业智能</h4><p></p><p></p><p>适用于各种规模公司的云原生商业智能</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/1d/1d8c5033530344776c71aa27ad2b664b.jpeg\" /></p><p></p><p>注：自 2020 年架构的第一版以来，深色框表示新的或者有意义的改变；浅色框表示基本上保持不变。灰色框被认为与这个蓝图不太相关。</p><p></p><p>未改变的是：</p><p></p><p>数据复制（如 Fivetran）、云数据仓库（如 Snowflake）和基于 SQL 的数据建模（使用 dbt）的组合继续构成这种模式的核心。对这些技术的采用已经有了显著的增长，促进了新竞争对手（如 Airbyte 和 Firebolt）的融资和早期成长。仪表板仍然是输出层中最常用的应用程序，包括 Looker、 Tableau、 PowerBI 和 Superset 等新进入者。</p><p></p><p>新的内容：</p><p></p><p>度量层（一个在数据仓库之上提供标准定义集的系统）引起了人们的极大兴趣。这已经引起了激烈的争论，包括它应该具有什么功能，哪些供应商应该拥有它，以及它应该遵循什么规范。到目前为止，我们已经看到了几个可靠的纯产品（如 Transform 和 Supergram），并通过 dbt 扩展到这一类别。反向 ETL 供应商的增长意义重大，特别是 Hightouch 和 Census。这些产品的目的是更新运营系统，如客户关系管理（CRM）或企业资源规划（ERP），使用从数据仓库中获得的输出和见解。数据团队对新的应用程序表现出更强的兴趣，以增强他们的标准仪表板，特别是数据工作区（如 Hex）。广义而言，新的应用程序可能是云数据仓库日益标准化的结果——一旦数据结构清晰且易于访问，数据团队自然希望利用它做更多的事情。数据发现和可观测性公司激增并筹集了大量资金（特别是 Monte Carlo 和 Bigeye）。虽然这些产品的好处是显而易见的——即更可靠的数据管道和更好的协作——但由于客户发现了相关的用例和预算，采用这些产品仍然相对较早。（技术说明：虽然在数据发现方面有几家可靠的新供应商——例如 Select Star、 Metaphor、 Stemma、 Secoda 和 Castor ——但我们一般都将处于种子阶段的公司排除在图表之外。）</p><p></p><p></p><h4>蓝图 2：多模态数据处理</h4><p></p><p></p><p>不断发展的数据湖支持分析和操作用例，也称为 Hadoop 难民的现代基础设施</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e5/e5f37c82fad11caa2f90c80a709bdc68.jpeg\" /></p><p></p><p>注 ：自 2020 年架构的第一版以来，深色框表示新的或者有意义的改变；浅色框表示基本上保持不变。灰色框被认为与这个蓝图不太相关。</p><p></p><p>未改变的是：</p><p></p><p>数据处理（如 Databricks、Starburst 和 Dremio）、传输（如 Confluent 和 Airflow）和存储（AWS）方面的核心系统继续快速增长，并构成了该蓝图的主干。多模态数据处理在设计上仍保持多样性，允许公司在分析和运营数据应用程序中采用最适合其特定需求的系统。</p><p></p><p>新的内容：</p><p></p><p>人们对湖仓一体架构的认识越来越清晰。我们已经看到这种方法得到了众多供应商（包括 AWS、Databricks、谷歌云、Starburst 和 Dremio）和数据仓库先驱者的支持。湖仓一体的基本价值是将健壮的存储层与一系列健壮的数据处理引擎（如 Spark、Presto、Druid/Clickhouse、Python 库等）配对。存储层本身正在得到升级。虽然像 Delta、Iceberg 和 Hudi 这样的技术并不新鲜，但它们正被加速采用，并被构建到商业产品中。其中一些技术（特别是 Iceberg）也与云数据仓库（如 Snowflake）进行了互操作。如果异构性继续存在，这可能会成为多模态数据栈的一个关键部分。在流处理（即实时分析数据处理）的采用可能会增加。虽然像 Flink 这样的第一代技术仍未成为主流，但具有更简单编程模型的新加入者（如 Materialize 和 Upsolver）正在获得早期采用，而且，据说现有的 Databricks 和 Confluent 公司的流处理产品的使用也开始加速。</p><p></p><p></p><h4>蓝图 3：人工智能和机器学习</h4><p></p><p></p><p>用于机器学习开发、测试、模型运行的堆栈</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/be/be1de968632f96b95b1cc95a0cd3151f.jpeg\" /></p><p></p><p>注：自 2020 年架构的第一版以来，深色框表示新的或者有意义的改变；浅色框表示基本上保持不变。灰色框被认为与这个蓝图不太相关。</p><p></p><p>未改变的是：</p><p></p><p>与 2020 年相比，今天的模型开发工具大体相似，包括主要的云供应商（如 Databricks 和 AWS），机器学习框架（如 XGBoost 和 PyTorch），以及实验管理工具（如 Weights &amp; Biases 和 Comet）。实验管理已经有效地将模型可视化和调整作为独立的类别。建立和操作一个机器学习栈是复杂的，需要专门的知识。这个蓝图不适合胆小的人——而且对于许多数据团队来说，人工智能的生产仍然具有挑战性。</p><p></p><p>新的是什么：</p><p></p><p>机器学习行业正在以数据为中心的方法进行整合，强调复杂的数据管理而不是增量的建模改进。这有几个方面的影响：数据标签的快速增长（如 Scale 和 Labelbox）和对闭环数据引擎的兴趣不断增加，这在很大程度上是模仿特斯拉的 Autopilot 数据管道。对于批处理和实时用例，更多地采用特性存储（例如 Tecton），作为以协作方式开发生产级机器学习数据的一种手段。低代码机器学习解决方案（如 Continual 和 MindsDB）重新引起了人们的兴趣，这些解决方案至少部分地自动化了机器学习建模过程。这些新的解决方案侧重于将新用户（即分析师和软件开发人员）引入机器学习市场。使用预训练模型正在成为默认，特别是在自然语言处理中，并为 OpenAI 和 Hugging Face 等公司提供了支持。这里仍有围绕微调、成本和扩展的有意义的问题需要解决。机器学习的运营工具（有时被称为 MLops）正变得越来越成熟，围绕机器学习监控构建，成为最需要的用例和即时预算。与此同时，一系列新的运营工具正在出现，其中尤其包括验证和审计，最终市场仍有待确定。人们越来越关注开发者如何将机器学习模型无缝集成到应用程序中，包括通过预构建的 API（如 OpenAI）、矢量数据库（如 Pinecone）和更多的意见框架。</p><p></p><p></p><h2>数据平台假说</h2><p></p><p></p><p>总结一下：在过去的一年中，数据基础设施栈在核心系统中表现出了极大的稳定性，并且支持工具和应用程序的快速增长。为了帮助解释为什么会发生这种情况，我们在这里介绍数据平台的概念。</p><p></p><p></p><h4>什么是平台？</h4><p></p><p></p><p>“平台”这个词在数据生态系统中被过度使用，通常被内部团队用来描述他们的整个技术栈，或者被供应商用来销售松散连接的产品套件。</p><p></p><p>在更广泛的软件领域，平台是其他开发者可以在上面构建的东西。平台本身提供的价值通常是有限的——例如，大多数用户对访问 Windows 或 iOS 的内部结构没有兴趣。但它们提供了一系列的好处，如通用的编程接口和庞大的安装基础，使开发者能够构建和发布用户最终关心的应用程序。</p><p></p><p>从行业的角度来看，平台的决定性特征是有影响力的平台供应商和大量第三方开发者之间在技术上和经济上的相互依赖。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/30/304d4ea4fa1082950a3814d0bb267194.jpeg\" /></p><p></p><p></p><h4>什么是数据平台？</h4><p></p><p></p><p>从历史上看，数据堆栈显然不适合平台的定义。例如，ETL、数据仓库和报告供应商之间存在着相互依赖，但集成模型倾向于一对一，而不是一对多，并且得到专业服务的大量补充。</p><p></p><p>根据我们采访的一些数据专家的说法，这种情况可能会开始改变。</p><p></p><p>平台假说认为，数据堆栈的“后端”——大致定义为数据摄取、存储、处理和转换——已经开始围绕一组相对较小的基于云的供应商进行整合。因此，客户数据被收集在一套标准的系统中，而且供应商正在大力投资，使这些数据容易被其他开发者访问——作为 Databricks 等系统的基本设计原则，以及通过 SQL 标准和 Snowflake 等系统的定制计算 API。</p><p></p><p>反过来，“前端”开发人员已经利用这种单点集成的优势，构建了一系列新的应用程序。他们依靠数据仓库 / 湖仓一体的干净、连接的数据，而不担心它是如何到达那里的基本细节。一个客户可以在一个核心数据系统的基础上购买和构建许多应用程序。我们甚至开始看到传统的企业系统，如财务或产品分析，正在以“仓库原生”的架构进行重建。</p><p></p><p>图片可能看起来是这样的：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/dd/ddbc5f5f76277332e82b40fd9663beaf.jpeg\" /></p><p></p><p>要明确的是，这并不意味着 OLTP 数据库或其他重要的后端技术将在不久的将来消失。但与 OLAP 系统的原生集成可能会成为应用程序开发的一个重要组成部分。而随着时间的推移，越来越多的业务逻辑和应用功能可能会过渡到这种模式。我们可能会看到一大类新产品建立在这个数据平台上。</p><p></p><p></p><h4>数据应用的出现？</h4><p></p><p></p><p>数据平台假说仍有很大争议。然而，我们看到复杂的垂直 SaaS 解决方案作为水平层在数据平台之上实施的情况正在增加。因此，虽然是早期，我们认为在数据堆栈中发生的变化至少与平台的想法是一致的。</p><p></p><p>有很多原因，例如，像 Snowflake 和 Databricks 这样的公司已经成为数据栈的稳定部分，包括伟大的产品，有能力的销售团队和低摩擦的部署模式。但也有一种情况是，他们的黏性被平台的动力所加强——一旦客户用这些系统之一建立和 / 或整合了一系列的数据应用，通常就没有意义了。</p><p></p><p>对于近年来新的数据基础设施产品的激增，我们也可以提出类似的论点。对这一趋势的典型解释是，大量的数据、不断增加的企业预算和大量的风险投资资金。但这些事情可以说几十年来都是真的。我们现在看到这么多新产品出现的原因可能与平台有关——也就是说，让一个新的数据应用被采用从来没有这么容易，而适当地维护平台也从来没有这么重要。</p><p></p><p>最后，平台假说在竞争态势方面提供了一些预测能力。在规模上，平台可能是非常有价值的。今天，核心数据系统供应商可能正在积极竞争，不仅仅是为了当前的预算，而是为了长期的平台地位。如果你相信数据摄取和转换公司是新兴数据平台的核心部分，那么这些公司令人瞠目结舌的估值——或者对新类别如度量层或反向 ETL 的激烈争论——也会更有意义。</p><p></p><p></p><h2>展望未来</h2><p></p><p></p><p>我们仍然处于定义分析和运营数据平台的早期阶段，而且平台的各个部分都在不断变化。因此，作为一个类比，它可能比作为一个严格的定义更有用。但它可能是一个有用的工具，可以从噪音中过滤信号，并帮助培养对市场发展方式的认识。数据团队现在拥有更多的工具、资源和组织动力，比数据库发明以来的任何时候（可能）都多。我们非常期待看到应用层在新兴平台之上的发展。</p><p></p><p>作者简介：</p><p></p><p>Matt Bornstein，a16z 的负责人，专注于企业公司。此前，Matt 创立了几家小公司，并为 Blumberg Capital、 LinkedIn 和 Monitor Group 工作。Jennifer Li，a16z 的合伙人，专注于企业公司。在加入该公司之前，她曾在 AppDynamics 和 Solvvy 担任产品经理。Martin Casado，a16z 的普通合伙人，他投资于企业公司。此前，他是 Nicira（被 VMware 收购）的共同创始人和 CTO，也是软件定义网络运动的创始人。</p><p></p><p>原文链接：</p><p></p><p><a href=\"https://future.com/emerging-architectures-modern-data-infrastructure\">https://future.com/emerging-architectures-modern-data-infrastructure</a>\"</p><p></p><p>声明：本文为InfoQ翻译，未经许可禁止转载。</p><p></p>",
    "publish_time": "2022-11-08 12:43:15",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "veImageX 演进之路：我用图像压缩算法为公司省了30%成本",
    "url": "https://www.infoq.cn/article/ruW1ETT3VhEVvE6YKe24",
    "summary": "<p></p><h2>前言</h2><p></p><p></p><p>日前，第五届深度学习图像压缩挑战赛（以下将简称“ CLIC 大赛”）比赛结果公布，首次参赛的火山引擎视频云多媒体实验室夺得视频压缩赛道第一名。压缩技术对于图像、视频应用十分重要。在保证同样主观质量的前提下，如何将图像压缩到更小体积便于互联网信息传输，火山引擎视频云团队不断突破压缩技术“天花板”。</p><p></p><p>字节跳动从公司成立之初就建设了图像处理平台，起初主要服务于今日头条APP的图文资源，随着业务扩展，逐步服务于抖音图集、短视频封面、图虫等几乎用户看到的所有图片展示场景；火山引擎视频云团队将字节跳动图像处理的实践，整理为《veImageX演进之路》系列，将从产品应用、后端技术、前端技术、算法、客户端SDK 详细解读字节跳动背后的图像技术。</p><p></p><p>veImageX是火山引擎基于字节内部服务实践，推出的图像一站式解决方案 ，覆盖上传、存储、处理、分发、展示、质量监控全链路应用。</p><p></p><p>一张图片从上传到在用户端消费展示，主要包括带宽、存储、计算三大部分资源的消耗，成本大概占比7:2:1，甚至带宽占比更高，因此针对带宽的节省优化是重要一环。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/91/913368c8151f3b7babbc5aeedd15fa4a.png\" /></p><p>veImageX架构简图</p><p></p><p>veImageX可以简化理解为包括三大组件：分发组件（CDN）、存储组件、基础媒体处理组件，组件有效组装到一起形成一整套解决方案。降带宽的本质是通过压缩降低传输的文件大小：图像在未压缩之前体积都很大，因此我们将目标设定为在保持用户主观体验不受损的前提下降低图像传输的体积，我们选择了基于HEIF自研的图像编解码算法来压缩体积。</p><p></p><p>为不降低应用性能，需要考虑耗时+带宽+画质等多个因子：对性能的影响主要是用户加载耗时（图片加载排队耗时、图片网络耗时、图片解码耗时），对成本影响主要是用户传输流量或者CDN分发带宽，对画质影响主要是画质清晰度和美学等指标；</p><p></p><p>基于以上思路，我们以下图为例，来看各环节我们是如何优化的：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/df/df924940103ebbe90bc7be0ac79a46b8.png\" /></p><p></p><h2>双端图像压缩</h2><p></p><p>●&nbsp;体积对比</p><p>线上图像以各种形式存在：iOS 主要是jpeg格式、Android端以webp为主，以典型的jpeg、png、webp为例，实验室多次抽样验证发现，转换到我们自研的HEIF图片格式，体积可以节省30%以上。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/59/59ee5b3d5738a615aefeb3596bf17fef.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/94/945036a3ff91ab34abc00dd9eb95b61f.png\" /></p><p>备注：黄色部分为自研图片格式，蓝色部分为原图格式</p><p></p><p>●&nbsp;画质对比评估</p><p>压缩体积是大目标，保证画质不受影响是第一要义；在画质评估阶段，我们选取了一些客观指标以及我们自己训练的无参考的清晰度评估方式（VQScore算法），对图像清晰度和美学进行整体评估：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c3/c307ef9e225bc663ea9fb560bfe1a0a4.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/41/41375fd39b4e1e977c01179138194e93.png\" /></p><p>左图：q值是在自研算法下调教数值对清晰度的影响 右图：q值是在自研算法下调教数值对清晰度的影响</p><p>通过如上图可以看出，新算法压缩并不会带来很大的画质波动，基本和压缩前对比差异不大。</p><p></p><p>●&nbsp;解码性能对比</p><p>要保证用户侧的加载耗时，必须要考虑新的算法在客户端解码的性能，而「按照我们的设计预期用户的解码耗时的增加值」需要小于「由于文件体积的减少带来的耗时」才能保证影响加载耗时变大，我们调研开源的一些图片解码性能，发现业界其他解码器一张图像解码耗时在150MS~250MS 之间，开源实现暂时无法达到要求，于是我们做了一些自行调教：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3a/3afb0652e2b7a70b2f95d502d63cbe87.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0f/0f6f0c04f825aaaf71d769f8932b7fea.png\" /></p><p></p><p>实验室下：自研解码和开源解码性能对比，耗时越低越好，单位:ms，其中绿色为自研解码</p><p></p><p>经过如上调教，我们基本可以将图片的解码耗时控制在对齐webp的解码耗时时间；</p><p>●&nbsp;实验设计：</p><p>秉承科学严谨的原则，我们选择实验验证时，需要充分考虑对照组和实验组变量尽量减少:(veImageX图像压缩访问方式是极简的，只需要将原来的url之后追加一个图像目标模板即可如下表格中隐去了真实的业务信息）</p><p></p><p></p><p>●&nbsp;数据论证：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ec/ec6dab7615ca93f7779d62e8e51d4601.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/64/640f28df83cfcfb30de60477c8820ce1.png\" /></p><p></p><p>经过线上实验，随机选取了一组流量进入实验过程，经过一段时间运行，我们发现 p-xx-a 的域名带宽和p-xx-b的域名带宽形成显著差异；我们从流量上计算（2.53PB-1.71PB)/2.53PB*100 = 32.4%,因此评判，在严格的和webp对比下，带来至少 30%的带宽节省验证符合预期；</p><p></p><p>当然，除了自行验证之外，我们也尝试过将线上其他格式（无需区分webp、jpg）与线上自研格式对比，节省比例更优；</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cc/cc5e086ce143df040f99f90113ad80f0.png\" /></p><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0c/0c4cf5214436b9a726de7a920a3b5e62.png\" /></p><p></p><p></p><p>验证数据参考</p><p></p><h2>通用的“集智瘦身”</h2><p></p><p></p><p>降成本是一个演进过程，在Android 和iOS 双端端原生解决了带宽问题后，在H5端运行，自研算法解码端面临在浏览器兼容性和性能支持的问题。因此我们需要考虑，无需集成客户端SDK的方式能够带来体积的节省，这里我们研发了“集智瘦身”的方式；这个设计初衷是为了解决业务方接入推广难、集成SDK覆盖难等难题，同时还要满足成本节省的目的。</p><p></p><p>集智瘦身的原理是通过深度学习的方式对传统webp、jpeg甚至png等格式进行瘦身压缩，而不需要集成客户端解码库。</p><p></p><p>相比于自研编码方式需要集成SDK之外，集智瘦身的接入简单很多，只需要将域名指向到veImageX服务就可以享受降本服务。</p><p></p><p>●&nbsp;演进方式A：有些业务线在实际推进过程中虽然比较复杂，但仍然可以按照veImageX 定义的 ~tplv 模板的方式来应用，因为我们将此算法内置到模板中可以自由选择，不限定任意格式，同时在web与chrome场景下也可以选择avif+webp+集智瘦身的方式来使用：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/86/863d182ff02868934178abd3751cd116.png\" /></p><p>&nbsp;&nbsp;这种方式，不需要SDK的接入，只需要服务端改造veImageX的模板即可，改成指定的格式，配合自适应的模式来实现H5端的降本；</p><p></p><p>●&nbsp;演进方式B：随着推动过程中，我们发现仍然有些什么都不能修改的业务，针对这样的业务，我们支持了只需要改动DNS就可以实现\"集智瘦身\"的方案。当然，图像经过处理之后文件的MD5值会发生变化，因此需要确认业务方没有对文件的MD5进行校验；</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fb/fb2ebbb6d3895739437b56aa21eab892.jpeg\" /></p><p>&nbsp;&nbsp;这种方案，对业务的侵入性几乎没有，会根据线上真实的图像做判断，合适的图像自动进行瘦身处理，通过动态监测线上图像输入前后的画质变化确保对用户体验没有影响。</p><p></p><p></p><h2>总结</h2><p></p><p>veImageX算法降本除了在如上两大场景应用之外，压缩方面也做了很多尝试，在对比传统webp场景下 可以节省30%+体积，启用自适应质量压缩可以带来至少7%的体积节省；同时在webp、jpeg等传统格式切换veIamgeX 调教后的自适应压缩质量可带来5~10%的压缩，集智瘦身可以带来15%~20%的节省，在不区分图像格式混合切量的前提下可以带来约50-80%的成本节省。</p><p></p><p></p><h2>写在最后</h2><p></p><p>针对不同的终端、不同的业务场景通过算法减少文件的体积，在节省服务商的传输带宽之外，也可以降低用户消费端流量的消耗，提升用户的加载速度。</p><p></p><p>图片加载是目前几乎所有的APP都具备的基础能力，目前火山引擎veImageX已经将上述方法形成端到端的解决方案输出给全行业，帮助每一个互联网企业用更低的成本达到更好的图片加载效果。除了商务降本之外，也可以用更“绿色”的算法降本，为行业降本增效提供了一种创新可能性。</p><p></p><p>了解更多veImageX，点击官网地址：https://www.volcengine.com/products/imagex，欢迎使用~</p><p></p><p>作者简介：</p><p>张锡平，火山引擎视频云veImageX产品负责人</p>",
    "publish_time": "2022-11-08 13:28:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "veImageX演进之路：HEIF图片编码压缩与优化",
    "url": "https://www.infoq.cn/article/xzyhEkFLyVu8izr63sMc",
    "summary": "<p>字节跳动在公司成立之初就建设了图像处理平台，起初主要服务于今日头条APP的图文资源。随着业务扩展，逐步开始服务抖音图集、短视频封面、图虫等几乎用户能看到的所有图片展示场景。火山引擎视频云团队将字节跳动图像处理的实践，整理为《veImageX演进之路》系列，将从产品应用、后端技术、前端技术、算法、客户端SDK，详细解读字节跳动背后的图像技术。</p><p></p><p>veImageX是火山引擎基于字节跳动内部服务实践，推出的图像一站式解决方案 ，覆盖上传、存储、处理、分发、展示、质量监控全链路应用。</p><p></p><h1>前言</h1><p></p><p>压缩技术对于图像、视频应用十分重要。在保证同样主观质量的前提下，如何将图像压缩到更小体积便于互联网信息传输，火山引擎视频云团队便在不断突破压缩技术“天花板”。</p><p></p><p>目前互联网任何应用、网站网页都离不开加载图像。HEIF是一种图像处理领域高效编码压缩的图片格式，在节省成本和画质平衡角度，一直备受广大用户青睐。图片格式从最早期的JPEG、无损压缩PNG、压缩效率较高的WEBP，到追求更高压缩效率的HEIF、AVIF，都在各个场景有着广泛的应用。相比其他几种图片格式，HEIF格式提供了较多的灵活性，可以支持更多的图片特性，比如透明通道、深度图、缩略图等辅助图像信息，也可以在不破坏原有图像的情况下进行图像编辑、裁剪、旋转、图形叠加。除此之外，HEIF容器支持封装多张图片序列动画，结合不同的编码压缩方式可以达到很高的压缩效率。高压缩率能够有效节省传输成本，提高加速速度，提升用户体验。</p><p></p><h2>HEIF图片</h2><p></p><p>HEIF是基于公开的国际标准ISO standard定义的图片文件格式，它是一种封装容器，文件中除了必要的文件信息，还可以添加各种图像编辑信息。因为和编码方式相互独立，所以在编码器的选择上更加灵活，可以根据实际需求适配。字节跳动使用的自研BVC编码器，在压缩效率和编码速度上优势明显。目前已经覆盖了超过 50% 的业务场景，取得了不错的业务收益。</p><p></p><h2>HEIF封装格式</h2><p></p><p>HEIF图片格式组成如下图，它由若干个box组成，文件属性和数据都存储在box结构中，对于静态图来说，必须包含的主要box类型有ftyp、meta、mdat：</p><p>●&nbsp;ftyp（file type）描述了文件封装的类型，比如heic、heix、hevc等</p><p>●&nbsp;meta box是媒体信息的描述，指明文件中子box的相互关联关系、编码流在文件中的相对位置、色彩信息和其他图像属性信息，其中包括但不限于以下几种，可以根据业务需要添加自定义信息。</p><p>○&nbsp;图像基础信息：宽高、相对比例、解码器配置等；</p><p>○&nbsp;色彩信息（colr）：包括ICC profile、NCLX等类型的色彩信息，使得图像在显示设备上正确的渲染；</p><p>○&nbsp;裁剪区域（crop）：自定义显示区域，在解封装后可根据区域裁剪最终显示的图像；</p><p>○&nbsp;图像旋转（irot）：0、90、180或270度；</p><p>○&nbsp;图像镜像（imir）：自定义图像是否镜像显示。</p><p>●&nbsp;mdat box中存储了各种类型的编码压缩数据，主流的编码器有H.264、H.265、AV1等，字节采用的是内部自研的BVC CPU+FPGA方案。输出的码流主要包含：</p><p>○&nbsp;master image：完整可显示的主体图像；</p><p>○&nbsp;thumbnails：缩略图，一般用于快速预览，渐进式加载等场景；</p><p>○&nbsp;Auxillary：辅助图，例如透明通道或者深度信息等；</p><p>○&nbsp;Derived：最终导出的图，可自定义显示效果 ；</p><p>○&nbsp;Equivalent：可选图，可用作最终显示的素材。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ff/ffd8a2e1ea92b260e7435b218a79f2ca.png\" /></p><p>HEIF封装格式</p><p></p><h2>veImageX基于HEIF特性和算法优化</h2><p></p><p>HEIF因其灵活高效的封装和编码方式，使得特性支持上更加便利。目前字节HEIF中已支持的功能有：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/68/686bc8173210d9875e6da4793e5e93c0.png\" /></p><p></p><p></p><h3>HEIF缩略图的应用</h3><p></p><p>HEIF特性在业务场景中的应用 以缩略图为例说明。HEIF缩略图是在原图的基础上封装了一个较小尺寸的图像以用作快速预览等场景。目前字节已经用HEIF缩略图实现了图片渐进加载的功能。该功能主要体现在用户可感知耗时的优化，提升用户体验。例如：在用户网络状况不佳时，加载完缩略图后，及时显示缩略图，图片加载完成后再显示原图。预览的渐进式效果如下，用户先看到图片整体轮廓的模糊效果，直到图片完全加载出来。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4c/4c5e8c66578d892d56afdf9f60aafe5f.gif\" /></p><p></p><h3>HEIF分块编码</h3><p></p><p>HEIF文件可以封装图片序列，考虑到大图的并行处理，内存消耗、裁剪等方面的性能，使用Tile编码可以有效优化以上问题。另外业务中也存在一些超长大图，分辨率超过手机厂商支持范围，导致系统接口解码显示异常等情况，可以使用Tile编码解决此类问题。</p><p></p><p>Tile编码是将一张较大的原图按照一定的尺寸分成若干个小块，分别对小块进行独立编码，再对编码数据进行一定规则的封装，在解码端解码后按照原规则拼接成大图，将冗余数据裁剪到原图分辨率进行显示。</p><p>●&nbsp;编码：把大图分成若干个Tile，宽高设置相同，一般移动端设备编码的Tile大小设置为512x512；每个Tile单独编码，输出Tile压缩后数据进行后续封装。</p><p>●&nbsp;封装：封装层需要增加grid infe和每个Tile单独对应一个infe； 增加iref-&gt;dimg索引； 增加idat存放grid信息； iloc记录Tile文件的偏移信息； grid的ispe 存放实际宽高。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4d/4db082a49cf73a4f4ccd693294c90901.png\" /></p><p></p><p>Tile示意图</p><p>自适应调整Tile尺寸</p><p>Tile编码方案解决上述问题的同时也带来了文件体积的增长，主要由于：</p><p>●&nbsp;Tile编码区域大于原图宽高，一般固定Tile尺寸后，最后一行或一列不足512的会Padding，存在一部分冗余数据；</p><p>●&nbsp;分块编码效率问题 ；</p><p>●&nbsp;封装格式中需要记录的信息增多，导致文件大小增长。</p><p></p><p>经过测试，固定512x512的Tile尺寸Grid编码后比正常编码文件大小平均增加22.40%，文件大小增长主要是冗余数据编码引入。</p><p></p><p>为了优化这部分体积，设计了自适应的Tile尺寸方案，根据原图分辨率自适应划分Tile大小。自适应方案测试后，相比正常编码的文件体积平均增加1.91%，避免冗余浪费。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e5/e525070b91e9650f969c6d1533c17d8e.png\" /></p><p></p><p></p><h3>HEIF图片ROI编码</h3><p></p><p>在图片实际应用中，人眼对于一张图片每个区域的关注程度不同。比如人脸、文字、图像中心区域等等往往是人眼关注的重点，而对天空、草地、图像背景区域的画质要求次之。针对人眼视觉特性，HEIF图片增加了显著性检测和基于检测区域的编码压缩，结合显著性检测对用户感兴趣区域进行画质提升，保证码率平稳的情况下提升用户感官体验。</p><p></p><p>ROI（Region Of Interest）编码是基于显著性区域进行优化的编码压缩方式，即对于图像中识别到的感兴趣区域和非感兴趣区域在编码算法上进行优化，提高ROI区域质量，降低量化参数程度，增加比特数分配；对于非ROI区域，在保证主观画质的情况下，减少比特数分配。</p><p></p><p>一张图片需要ROI编码时，先经过ROI检测算法，识别到图片中的显著性区域（一般不超过10个区域），将ROI坐标区域按照一定的规则封装后传到编码器内部。编码器根据区域重新分配各个区域的比特数，在保证主观画质的基础上，提升ROI区域画质。算法最终经过专家测评和盲测，画质满足需求，已经应用到实际业务中。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6b/6b4c4e8ca549110eb73953da9089ce44.png\" /></p><p>ROI编码部分流程图</p><p></p><h2>HEIF编码压缩技术</h2><p></p><p>目前图像处理为了满足低存储成本，同时满足多种分辨率、样式等适配问题。一般情况下需要实时或者准实时处理，HEIF格式使用字节自研的BVC编码器，初期CPU计算方案成本较高，同时在体验层面图像压缩编码耗时也相对较高。为了减少链路的耗时，火山引擎推出了节省计算成本的FPGA异构方案。结合FPGA和CPU编码的优势，ImageX在HEIF编码方案上设计了FPGA+CPU方案，FPGA方案提供了高速的压缩编码体验。由于FPGA的硬件方面限制，需要CPU方案兼容和适配其他限制外使用场景。CPU提供了高效的编码压缩体验，可以选择不同的画质档位，根据业务需求选择合适的编码参数。编码器正在持续的升级优化，希望提供更好的压缩性能和编码速度。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/09/0913b52074af353cf2a7453adabadc0b.png\" /></p><p>FPGA&amp;CPU编码调用流程</p><p></p><p></p><h3>FPGA-based HEIF编码方案</h3><p></p><p>HEIF编码在提升压缩率的同时，因其复杂度高，也需要消耗更多CPU计算资源。为了降低HEIF格式的编码计算成本，ImageX采用了FPGA异构架构，整体成本约为CPU方案的10%。</p><p>●&nbsp;在性能方面，单台FPGA server的处理能力是CPU server的15+倍，编码延时方面，FPGA方案不到CPU的十分之一。由于FPGA方案的延时大大降低，在所有分辨率的图片上都可以使用同步处理，避免了CPU方案对大分辨异步处理而降级的情况，从而节省回源带宽和用户感知延时</p><p>●&nbsp;在编码效率上，FPGA编码效率和CPU方案的常用档位基本持平，可以在高速编码的同时，得到高效的编码质量。</p><p></p><p></p><h3>HEIF压缩性能对比</h3><p></p><p>HEIF vs. WEBP</p><p>选取一定数量的图片针对WEBP和HEIF图片测试，在相同画质下HEIF动静图相比WEBP码率节省约50%。HEIF能够在对齐主客观画质的情况下，可以节省更多的文件体积。整体对比效果如下所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9e/9e8a4e9bbf77cb629b4684aed0fb5ffc.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/29/29031cd05d78d1bdf7f7e732fb5f684d.png\" /></p><p></p><p>图片内容简单、平坦区域较多的场景，WEBP有较多的块效应、色带等失真，HEIF图片可以保持更好的画质、压缩失真较少、清晰度更高。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/97/9748dc14bdcc7305411c7175ebfcde59.png\" /></p><p>WEBP 12k vs. HEIF 7k</p><p>对于复杂图像，HEIF图片纹理细节保留较多，边缘清晰，无明显毛刺；原图色彩还原度好，无明显色偏。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b3/b3b335ff8659a634a6992e32ff1c2606.png\" /></p><p>WEBP 60k vs. HEIF 39k</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1a/1a6661fa264753a8579cd22cfd1c2f46.png\" /></p><p>src vs. WEBP 67k vs. HEIF 38k</p><p>HEIF vs. AVIF</p><p>经过测试对比得出如下数据，在客观指标相同或稍高时，HEIF相比AVIF快速档位有约10%的体积节省。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b9/b9154bdbecc86eb56df3361274541114.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b2/b2ff1c064ddca55f0bbff6f389bc5240.png\" /></p><p></p><h2>HEIF自适应</h2><p></p><p>为了满足用户图片清晰度需求，图片的体积也随之提升，消耗的带宽也越来越大。如何在有限的网络带宽下，兼顾画质和体积对于提升用户的画质体验就显得尤为重要。基于以上考虑，团队设计了图片自适应算法策略，在主观画质保持不变的基础上，节省了带宽成本。</p><p></p><h3>算法介绍</h3><p></p><p>互联网中图片内容丰富多样，固定的编码参数并不能灵活的对不同种类内容提供适合的画质体验。自适应算法基于图片内容的统计特性，针对不同类型图片制定参数自适应调整策略。</p><p></p><p>首先，选择合适数量的测试图片数据集，分析图片的基本信息，文件格式、宽高、文件大小、有参/无参画质、指标用户模版配置等，统计线上图片目前的画质情况，制定合适的基准作为后续调整策略的参照；其次，由于线上图片格式种类较多，自适应算法选择统一的预编码方式，获取预编码后的特征作为模型输入，针对图片编码难易程度、分辨率等对图片进行统计分类，得到图片的分类信息；最后，对每个分类的图片进行RD曲线预测，根据当前用户配置期望确定质量阈值，该阈值根据预编码阶段的特征自适应调整。</p><p></p><p>在调整过程中，质量较低的图片需要提升质量参数，质量达标并高于预期时，则在主观画质不变的基础上，减小文件体积。从效果上看，自适应算法调整后，图片画质有提升，质量相对稳定，失真严重的图片减少，用户画质体验提升的同时，可以节省带宽成本。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1b/1bc64b787ace0604864c2f1442ba289d.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4c/4c9e66c688ad756e07efe8d2c29c320f.jpeg\" /></p><p></p><h3>码率节省</h3><p></p><p>随机选取5000张图片，测试自适应的码率节省，相比固定编码参数的图片大小，自适应约节省10%的体积，当然在火山引擎的veImageX设计中JPEG、WEBP 等其他格式也可以应用该算法。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ab/abeb271519e47f52c596cb9ad601b852.png\" /></p><p></p><p></p><h3>主观效果</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/36/362d77369e9a3c8100e933fe9ac62627.png\" /></p><p></p><p>HEIF 234k vs. Adaptive HEIF 174k</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f5/f56a091636577ebd13e4b7cc252b001f.png\" /></p><p>HEIF 30k vs. Adaptive HEIF 22k</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1b/1b63601277e3b013049e0b85c71d7cb3.png\" /></p><p></p><p>HEIF 42k vs. Adaptive HEIF 29k</p><p></p><h2>HEIF解码</h2><p></p><p>HEIF格式因其高效的压缩效率，优质的画质体验和丰富灵活的图像内容备受关注，之所以没有普及使用主要是终端的兼容性问题。近年来越来越多的设备厂商支持了系统HEIF解码，推动HEIF生态的完善，但还是有较多场景不支持HEIF的解码渲染。因此，火山引擎设计了客户端的HEIF解码方案，采用自研的BVC解码器，解码速度较开源方案有较大程度的优化，解决了各端系统兼容问题。图片SDK根据机型做了系统和自研解码的适配，保证机型性能的同时提升用户流畅的观看体验。此外，图片SDK还提供了图片访问指标上报能力，可以在veImageX控制台方便查看相关图片业务指标，对业务实验、问题定位等提供了便利的手段。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5c/5c54ba71f89a13650930e920bdbe19f0.png\" /></p><p></p><p></p><h2>小结</h2><p></p><p>HEIF图片在高效的编码压缩算法基础上叠加了一系列算法优化策略，以更低的成本得到优质的图片质量。火山引擎希望通过不断的探索和持续优化算法策略，为用户带来更惊喜的图片画质体验。同时，火山引擎也期望通过图像压缩技术降低企业用户的互联网传输带宽，提升用户加载体验，加快互联网传输速度，协同对整个社会产生价值。</p><p></p><p>目前以上编解码算法的优化已经集成到火山引擎veImageX产品中，点击阅读原文了解更多。</p><p>https://www.volcengine.com/products/imagex<a href=\"https://www.volcengine.com/activity/imagex/?utm_source=wechat&amp;utm_medium=article&amp;utm_term=wx_readmore&amp;utm_campaign=20220728&amp;utm_content=imagex\">/?utm_source=wechat&amp;utm_medium=article&amp;utm_term=wx_readmore&amp;utm_campaign=20221027&amp;utm_content=imagex</a>\"</p><p></p><p>作者简介：</p><p>李蒙蒙, 火山引擎视频云veImageX 核心图像算法工程师。</p><p>张锡平，火山引擎视频云veImageX 产品负责人。</p>",
    "publish_time": "2022-11-08 13:47:42",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "见证历史！数学家张益唐北大讲座：本质上已证明“零点猜想”，111页论文已公开",
    "url": "https://www.infoq.cn/article/3HlT22mMTe2ETLpLc9oQ",
    "summary": "<p></p><blockquote>有数论学者表示，张益唐有关朗道-西格尔零点猜想的论文结果意义重大，使得以前的很多结果从假设性结果变成了确定性结果。</blockquote><p></p><p></p><h2>张益唐在北大作“零点猜想”学术报告</h2><p></p><p></p><p>11 月 8 日上午 9 点，数学家张益唐在北京大学作“关于朗道-西格尔零点猜想”学术报告。张益唐表示，在本质上，他已经证明了朗道-西格尔零点猜想。只是像他此前关于孪生素数猜想的研究结果一样，其结果可以被改进。最新研究突破将有很多应用，带来很多定理。</p><p></p><p>换句话说，张益唐的最新论文表明，在特定范围内，朗道-西格尔零点不存在。在这一情况下，朗道-西格尔零点猜想正确或成立。（郎道-西格尔零点猜想要回答的核心问题就是：是否存在朗道-西格尔零点？）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fc/fcde5c21192facf7ea6d692b319d6592.png\" /></p><p></p><p>资料显示，张益唐是加利福尼亚大学圣塔芭芭拉分校教授、山东大学潘承洞数学研究所所长、北京大学闵嗣鹤数论研究中心名誉主任、北京大学客座教授，曾在孪生<a href=\"https://xie.infoq.cn/article/29462e0ad0cba8f6b7115a4f3\">素数</a>\"猜想的研究中取得里程碑式的突破进展，受邀在 2014 年首尔国际数学家大会上做特邀报告，获罗夫·肖克奖-数学奖、弗兰克·奈尔森·科尔数论奖、麦克阿瑟天才奖等诸多奖项。</p><p></p><p>事实上，在张益唐之前，有很多数论专家都曾做过相关研究，但均没有成功。</p><p></p><p>关于攻克朗道-西格尔零点猜想的意义和重要性，张益唐的同事、数论学家 Stopple 曾说，如果张益唐能对此作出证明，那么加上他的上一份成就（关于孪生素数猜想的研究），在某种意义上，（其概率）就像是同一个人被闪电劈中两次。“如果他从未成名，那么做出这项工作也会让他跟上次一样被世界瞩目。”</p><p></p><p>究竟什么是朗道-西格尔零点猜想？为什么张益唐的研究成果能让数学界为之一震？</p><p></p><h4>朗道-西格尔零点猜想</h4><p></p><p></p><p>朗道-西格尔零点猜想的名字来源于两位著名的数学家：朗道和西格尔。朗道是德国数学家希尔伯特在数论领域的继承人，西格尔是朗道曾指导过的博士生，西格尔曾发现了一类特殊的函数—— L 函数理论中的西格尔零点现象。</p><p></p><p>作为<a href=\"https://xie.infoq.cn/article/782a360860be9e1eb8e4f3579\">数学界</a>\"知名难题之一，朗道-西格尔零点猜想主要是想解决 L 函数是否存在异常零点这一问题，它是解决很多数论问题的瓶颈，并与已经悬置 160 多年的著名数学难题“<a href=\"https://mp.weixin.qq.com/s?__biz=MzA4NTU2MTg3MQ==&amp;mid=2655165431&amp;idx=1&amp;sn=a9a1c253eb8aaddd87cfdb83753e34e4&amp;chksm=84603c97b317b5810fb49fbc8b921f7bb65b1a8e7f7fb13400a72fc1d5ba16e552a593fd94b9&amp;scene=27#wechat_redirect\">黎曼猜想</a>\"”相关。</p><p></p><p>据《中国科学报》介绍，简单说，如果存在朗道-西格尔零点，那么黎曼猜想就是错的；如果朗道-西格尔零点不存在，则不会和黎曼猜想发生冲突。</p><p></p><p>也就是说，一旦证明了朗道-西格尔零点猜想，就可以取得很多新突破，简化和加强很多经典数论结果。无论是哪种结果，无疑都是数学史上里程碑式的事件。</p><p></p><h2>111 页论文证明“零点猜想”</h2><p></p><p></p><p>早在今年 10 月中旬，就有消息称“数学家张益唐已经攻克朗道-西格尔零点猜想”。</p><p></p><p>据悉，在 10 月 15 日北京大学大纽约地区校友会举办的“我的数学历程”线上活动中，张益唐提到，他已做完朗道-西格尔零点猜想相关工作，将于 11 月初发表论文。“我最近在数学上又作出了一个应该说是很大的成果。可以说是弱一点的形式，但本质上已经是解决了朗道-西格尔零点（猜想）问题。解析数论的同行会知道，这个问题的解决，可能比孪生素数猜想的意义更大。”</p><p></p><p>11 月 5 日，有消息称张益唐攻克朗道-西格尔零点猜想的论文已完成。11 月 7 日，该文论在 arXiv 上正式对外公开。网站信息显示，该论文提交时间为 2022 年 11 月 4 日。据悉，该论文的标题是《离散均值估计和朗道-西格尔零点》（Discrete mean estimates and the Landau-Siegel Zero），共 111 页，由 18 个部分组成。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/84/842f9baa6fade7813e8cfe055e88b0df.png\" /></p><p></p><p>据山东大学官微报道，11 月 5 日，张益唐教授曾面向山大师生作了一场关于朗道-西格尔零点猜想的线上学术报告，张益唐教授在报告中首先介绍了朗道-西格尔零点，以及它与算术级数中素数分布的关系。</p><p></p><p>张益唐教授从狄利克雷 L-函数和黎曼 zeta 函数讲起，介绍它们在算术级数中的素数分布和素数定理中的作用。随后，张益唐教授介绍了他在朗道-西格尔零点猜想研究方面的创新思想。张益唐教授在最新预印本论文里证明了，模 D 的实原特征 L-函数在区间</p><p><img src=\"https://static001.geekbang.org/infoq/c1/c1dd749fe5d07cd1dbd0431ddb9dd8a2.png\" /></p><p>内没有实零点，这里 c 是绝对实效正常数。如果把这里的 2024 换成 1，就得到原始形式的朗道-西格尔零点猜想。2024 虽然大于 1，但在数学意义上，与 1 并没有实质性的差别。</p><p></p><p>也就是说，在这一区间内，朗道-西格尔零点不存在。</p><p></p><p>早在 2007 年，张益唐就曾做过朗道-西格尔零点问题的研究。</p><p></p><p>2007 年，张益唐在 arXiv 上刊发了“On the Landau-Siegel Zeros Conjecture”（关于朗道-西格尔零点猜想）的研究，不过彼时，该研究还存在一些“瑕疵”。时隔 15 年后，张益平再次上传有关朗道-西格尔零点猜想的论文。</p><p></p><p>对于这篇最新的研究论文， 英国数学家、牛津大学数学研究所退休教授 Roger Heath-Brown FRS 表示，“好好研读这篇论文需要很长时间，所以我现在还不能说它是否正确。但它写得很清楚，而且策略明智。”</p><p></p><p>有数论学者对澎湃新闻表示，“新论文尚未完整证明朗道-西格尔零点不存在，所以张益唐现阶段并没有完整解决朗道-西格尔零点猜想。同时，从张益唐的论文来看，其当前研究路线很可能无法最终解决朗道-西格尔零点猜想。”该数论学者认为，虽然这个结果证明不了朗道-西格尔零点猜想，但其“强度”已经足以在极大范围上排除西格尔零点。这种范围对于解析数论学者来说，足够将其应用到数论问题中，并得到大量有意义的结论。</p><p></p><p>该数论学者进一步解释道，以往的很多论文，要假设朗道-西格尔零点猜想成立（即假设西格尔零点不存在）；张益唐的新论文虽然没有排除掉西格尔零点存在的可能性，但其排除掉的范围足够涵盖很多以往论文所需的范围。这使得以前的很多结果从假设性结果变成了确定性结果。</p><p></p><p>此外，该数论学者表示，论文从 2007 年版的 54 页扩到现在 2022 年版的 111 页，审稿会是一个大工作。“像这种论文，即使是顶尖的专业人士，把论文全部细节推一遍也得几个月，所以很难很快下定论。”</p>",
    "publish_time": "2022-11-08 14:19:21",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "谈谈开源操作系统根社区建设和相关人才培养",
    "url": "https://www.infoq.cn/article/p3SG8QKMLh45Pyl0I6Ny",
    "summary": "<p>前段时间，我受邀成为欧拉开源社区的首批顾问专家，我也在视频中表达了自己对开源和操作系统的一些看法，今天受梁冰女士的邀请再来谈谈我对开源操作系统根社区建设和相关人才培养的理解。</p><p></p><h2>操作系统根社区建设需步步为营</h2><p></p><p>根社区，一般指基于&nbsp;Linux&nbsp;内核和周边开源组件进行构建，不依赖上游发行版的社区体系，在此之上还可以衍生出不同分支或下游社区。</p><p></p><p>近年来，我们对建立国内根社区的愿望越来越强烈，当前国内基于Linux开源系统的根社区都在国外，上游开源社区的“断供”会让下游系统的产品体验与安全受到影响。</p><p></p><p>我们常常说国内操作系统要想发展起来，最重要就是生态建设。但从另外一个维度来看，技术过硬才是基础，才是让企业和用户参与根社区项目发展的重要动力。此外，根社区还得积极与开源基金会协作，将社区转起来，这里的“转起来”就包括是不是符合开源价值观，以召集更多志同道合的开发者让社区可持续运营下去。</p><p></p><p>在根社区的建设上，openEuler是当前国内布局非常周全的操作系统之一，深谙开源之道。成立早期，我就曾了解过openEuler社区的开放治理机制，SIG组是其中很关键的一步，这些SIG组的核心成员主导SIG的治理，推动交付成果输出并尽可能让其成为openEuler发行版的一部分，这让整个社区可以持续不断的创新。有一些SIG组本身并不与操作系统强相关，这也是openEuler的应用场景越来越丰富的原因之一。</p><p></p><p>在技术上，面向多样性计算的操作系统在全球范围内还是存在广泛诉求的，具体的技术特点从openEuler&nbsp;22.09&nbsp;版本中可以看到，InfoQ也在第一时间对该版本进行了报道。简单来说，根社区的建设需要联合上下游制定出符合发展趋势的社区架构，吸引更多优秀的企业和开发者加入，让社区驱动该架构不断向前演进。这是一件需要艰难而且需要长期规划的事情，但我们已经看到国内很多操作系统都参与其中，有了一个很好的开端。</p><p></p><p>只有根社区发展起来，才能帮助我们解决卡脖子的问题，解决供应链安全方面的问题，解决软硬件更好适配的问题。</p><p></p><h2>人才培养的体系当更健全</h2><p></p><p>前不久的欧拉操作系统生态大会上，openEuler开源社区理事长江大勇提到，希望集合产、学、研、用力量，通过“生态构建、技术评测、产业聚集、技术创新、人才培养和行业创新”六大服务平台体系打穿生态服务的最后一公里，推进欧拉技术路线在区域落地，构建根植区域生态的自循环、自发展的生态系统。</p><p>对这六大服务平台体系，我深以为然。当前的全球大环境促使企业在数字化转型的过程中拥抱国产操作系统在内的基础软件，最近几年这种趋势越来越强烈，相关的政策已经出台，资本也在不断的关注，但人才、技术和生态构建还处于发展中，我们在这方面也有一些自己的思考。</p><p></p><p>我国从事国产基础软件研究和开发的专业人才奇缺。</p><p></p><p>虽然国内每年高校毕业生有&nbsp;700-900&nbsp;万，加上高职高专等毕业生，每年毕业生规模超过千万。但是，真正去做操作系统、数据库和中间件等基础软件领域的人非常少，大部分的人都去做应用开发，比如开发&nbsp;APP，据业内专家表示，国内真正能进行内核开发的人不超过&nbsp;1000&nbsp;人。并且，有些高校的计算机学院甚至把操作系统从必修课变成选修课，能进行系统教学的老师也非常少。此外，从研究所来看，国内真正有软件研究的机构也很少，除了中科院软件所有几百人，其他做基础软件的理论研究和技术创新的机构屈指可数。</p><p></p><p>正所谓，根深才能叶茂。缺少人才，国产基础软件产业就发展不起来，无法进行创新。</p><p></p><p>一直以来，极客邦科技都专注在为数字化人才提供各种专业服务，这其中就包括基础软件开发的数字人才。过去&nbsp;15&nbsp;年，我们也不断的为基础软件领域的客户提供服务，尤其是&nbsp;2017&nbsp;年发布极客时间&nbsp;APP&nbsp;后，我们所能提供的产品和服务也更加多元化了：基于岗位的体系化培训和基于问题与具体场景的培训，这两种培训方式是我们服务大量客户之后，实践出来的最有效方式。依托着我们&nbsp;20&nbsp;多个岗位能力模型和体系化课程，以解决问题为导向和以实践为驱动，为数字人才提供大量的专业培训课程和专业的产品、服务，希望为更多数字人才的成长发展提供帮助。接下来，极客邦科技也会和欧拉开源社区一道，在合适的时机推出&nbsp;openEuler&nbsp;操作系统相关的内容，一起推动国产基础软件产业的持续发展，也为国家数字经济的发展贡献力量。</p>",
    "publish_time": "2022-11-08 15:11:02",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "误报警数降低90%以上，华为发布智慧机场光感围界解决方案",
    "url": "https://www.infoq.cn/article/Lit2P3yMmO0bMKXQv6mF",
    "summary": "<p>11月7日，在华为全联接大会 2022 上，华为发布智慧机场光感围界解决方案。该方案是华为在本次大会上发布的<a href=\"https://www.infoq.cn/news/APV0tYBQq8hC2xc5fWFm\">十大场景化解决方案</a>\"之一，基于分布式光纤传感、融合视频技术、并联合民航二所等行业伙伴打造而成。</p><p></p><p>机场围界安全是机场安防的头等大事，人员入侵会对航空器形成重大安全隐患。据华为机场与轨道军团副总裁周欣介绍，每个机场都有围栏，约有20-30公里，目前业界采用的主要是振动光缆、光纤作围界。但这种方案存在两大痛点，一是产生大量的误报警，每天有几百次误报警甚至上千次，如果遇到台风天气根本没法使用。二是这种振动电缆和振动传感器都有局限性，20公里要分成几十甚至上百个小区间，这就导致维护工作量特别大，为了维护这套设备每年要花费几百万人民币，这套系统的维护成本（OPEX）非常高。</p><p></p><p>华为所提供的智慧机场光感围界解决方案，能更准确地识别风雨或人的振动。周欣表示，该方案主要有以下改善点：首先，误报警数量降低90%以上，误报率&lt;1次/Km/天；二是精度，20公里的围界精度可以做到米级；第三，维护非常简单，因为整个围界用一两套光纤就能解决。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ce/ce960bc3db29be470568b3c415dc585e.png\" /></p><p></p><p>周欣进一步介绍道，华为的光纤传感方案的优势有二：一方面得益于华为在光通信技术方面的技术能力，像光的相干噪声一致和oDSP算法，光纤上有任何振动都能读取采样回来；二是采用AI的算法能把它识别出来。“第一是采样能力，第二是识别能力。这两个能力使得华为的方案能够比行业现有方案的误报率提升10倍以上，并且大大降低维护成本”，周欣还透露，目前该方案正准备在成都双流机场和昆明长水机场做测试。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cc/cc1ad7b0843300e2a307aaccb97e44c4.png\" /></p><p>华为智慧机场光感围界解决方案架构</p><p></p><h2>成立军团</h2><p></p><p>过去一年时间，华为成立了20个军团。军团是帮助华为快速适应外部复杂局势及新型作战模式的一种组织手段。目的在于用“一支队伍服务好一个行业”，让技术不难选不难用。华为要求军团下沉到行业现场，了解实际情况。</p><p></p><p>华为机场与轨道军团成立于2022年3月30日，前身为华为企业BG全球交通业务部，已服务交通行业26年。据介绍，截至目前，华为已服务于全球四十多个国家和地区的100+机场和航司、全球七十多个城市的15万公里铁路、300+条城市轨道线路。</p><p></p><p>“华为公司成立军团，至少从机场和轨道军团对公司业务的理解，我们希望从两个方面，一方面是对内缩短管理链条，因为华为公司将近20万人的公司，对内也存在着效率提升的问题，所以公司也希望军团的成立，能带来从客户到我们公司的技术能力之间实现快速的连接，缩短中间的消耗。”据华为公司副总裁、机场与轨道军团CEO李俊风介绍，华为另一方面是希望军团能达到横向整合资源的目标，从研发到营销到销售与服务等所有的能力，都能快速地为一个行业和客户提供价值。</p><p></p><p>2021年，<a href=\"https://www.infoq.cn/article/mSGjH12TWxFaNJvpWuje\">华为研发投入达1427亿元</a>\"。李俊风进一步说道，通过军团的整理，有望让华为公司的价值能真正给行业带来业务应用的价值。</p><p></p><p>那么，为什么把机场与轨道放在一起？在华为看来，未来十年，交通不再仅仅是铁路、公路、航空几个垂直领域独立的客货运输，而是围绕旅客出行、货物运输形成的海陆空铁一体化综合大交通。未来的综合立体交通网建设，需要民航、地铁和铁路各交通子行业通过数字化转型，打破过去的行业壁垒和区域壁垒，实现交通数据的互联互通和共享。</p><p></p><h2>机场与轨道行业数字化</h2><p></p><p>李俊风指出，机场与轨道行业的数字化包含两部分，基础设施数字化与业务流程数字化，二者缺一不可，有了基础设施，才能把整个业务流程固化到IT流程里面。</p><p></p><p>华为目前更多做的是在基础设施数字化这块。据周欣介绍，华为研发分两部分，一是产品线，包括无线、光、数通、计算、存储、云等等，负责研发ICT产品，解决关键技术并研究未来3-5年的技术；此外，还有2012实验室，研究未来5-10年的关键技术。这样的布局体现公司多路径、多梯次探索的技术战略。军团基于产品线和2012实验室的关键技术基础上，联合包括机场、空管、航司、城轨以及铁路在内的行业伙伴打造解决方案。</p><p></p><p>目前，华为给机场与轨道行业带来的ICT解决方案主要包括四个层面，一是重建感知，把5G技术、光通信技术、机器视觉技术、以及终端鸿蒙等技术扩展到各个行业，包括机场与轨道行业，来重建感知。二是塑造联接，通过无线、光、数据通信、云技术等等。三是重构平台，包括云技术、物联网平台、AI的技术、视频分析技术、安全技术，这些技术可以在整个云平台上构筑行业价值和竞争力。四是在最上层构筑一些场景化的解决方案，主要针对行业关键的问题，特别是重大课题，华为利用自己的ICT技术，联合伙伴一起帮客户解决。</p><p></p><p>谈及行业面临的挑战，周欣认为，“行业最大的挑战是不知道用什么样的ICT技术能解决问题。”他解释道，“像华为这样的ICT厂商最大的问题是不知道这个技术能够解决客户的什么问题。还有伙伴，伙伴通常都是行业出身，是两边都知道一些，但这些伙伴他们对ICT技术也不了解，所以三方不了解的时候我们该怎么办，这是很大的挑战。”</p><p></p><p>因此，华为跟机场与轨道的伙伴尝试的合作方式是“联创”。他指出，深圳机场其实是一个联创的样板点。“我们把工程师派到一线跟客户坐到一起讨论、理解他们的场景是什么，然后把他们的场景问题翻译成为或者把它抽象成为华为能解决的问题，然后再跟伙伴一起解决行业的问题。所以这实际上是一个跟伙伴怎么定义问题然后再解决问题的过程，这是一方面。”</p><p></p><p>另一方面，包括2012实验室在内的华为的很多专家，也会直接到一线跟客户交流、讨论，“他们带着技术直接跟客户讨论，这样的话做到创新的闭环，看到问题、理解问题、去想解决方案是什么。”</p><p></p><p>目前，华为机场与轨道军团的合作案例包括深圳机场数字化转型、南非Transnet铁路全光骨干网络建设、武汉地铁数字化、深圳地铁6/10号线搭建5G+城轨云架构等等。</p><p></p><p>周欣强调，华为还是会聚焦在ICT数字化技术，把对于产业和技术的理解，结合行业场景，和行业伙伴一起来打造适配行业的ICT解决方案、</p>",
    "publish_time": "2022-11-08 15:40:01",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "龙蜥社区理事长马涛：进一步释放底层算力，打造面向云时代的操作系统",
    "url": "https://www.infoq.cn/article/doRlMHDEOOOpK9McCZ95",
    "summary": "<p></p><blockquote>在 2022 云栖大会龙蜥操作系统峰会上，龙蜥社区理事长、阿里云研究员马涛发表主题演讲，本文为演讲内容整理。</blockquote><p></p><p></p><p>首先要感谢一下中国软协陈宝国秘书长以及浙江软协王小号秘书长，两位对龙蜥的祝福以及对龙蜥未来的展望让我对龙蜥充满了信心。还要感谢一下今天到场的各位理事代表、各位合作伙伴代表、各位开发爱好者、所有在线上观看龙蜥操作系统峰会的开发者们，大家上午好！</p><p></p><p>我们相信操作系统将成为数字产业支柱算力来源，龙蜥社区是近两年业界发展最为强劲的一大操作系统开源社区，因为它做对了两件事：</p><p>一是“开放算力”，龙蜥社区短期目标是开发龙蜥操作系统作为 CentOS 替代，助力广大用户无缝迁移。并且，基于阿里云、统信软件等社区多年来的技术沉淀，面向广大用户进一步释放底层算力。二是“云启未来”，龙蜥社区的长期使命是，与生态合作伙伴联手，共同打造一个面向云时代的操作系统，协同产业上下游能力和诉求，建立统一的开源操作系统生态。</p><p></p><p>这也是今天我演讲的主题“开放算力，云启未来”的由来。</p><p></p><h2>开放算力，云启未来</h2><p></p><p></p><p>首先，我认为龙蜥社区对于算力的支持是当前国内和国际社区里面最全的。无论是对像 Intel、AMD、Arm 等国际芯片厂商的支持，还是对像龙芯、兆芯、飞腾等国内芯片厂商的支持，龙蜥对于国内外主流芯片支撑的能力都是领先的。其次，我们认为对于一个操作系统开源社区而言，开放是非常重要的。因为龙蜥足够开放、平等、中立，所以在过去的一年里发展速度极快。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ac/ac30cabecbccab61ff5c2fc63cc8ae4c.png\" /></p><p></p><p>在过去的一年里，龙蜥操作系统下载量已经达到 230 万，装机量超过 300 万。龙蜥社区当前有 21 家理事单位和近 250 家的生态合作伙伴，尤其是近来刚加入社区的<a href=\"https://xie.infoq.cn/article/b537afdd713044e641edf869d\">&nbsp;4 家新晋理事单位</a>\"，都能为社区的发展带来很大的帮助。其中三家是服务器厂商的浪潮信息、中科曙光、新华三，他们的加盟极大扩展了龙蜥社区在整机以及服务器方面的生态板块；另一家是麒麟软件，也是国内非常领先的操作系统厂商，麒麟软件的加入将与龙蜥社区协同推动国产操作系统产业的发展。</p><p></p><p>大家可能会问“为什么龙蜥社区在短短 2 年的时间内能够有如此跨越式的发展？”我认为这与社区的使命、愿景、以及信念准则都是息息相关的。龙蜥的使命和愿景是社区持续长期发展的方向，就是为中国整个软件产业的发展出一份力。下面我想重点展开龙蜥社区的信念和准则，这也是在第二届理事大会上经过在场所有理事单位投票选出来的四个关键词，分别是开放、平等、协作和创新。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/59/5924ef894e5cd8ddcc85b4f992461b78.png\" /></p><p></p><p>第一个是开放。我们认为龙蜥社区对所有企业都是开放的，社区不会对加入的企业有任何强制性要求，开放的核心是希望操作系统产业链上的企业都能够加入到龙蜥社区，一起为整个龙蜥社区的发展献策献力。</p><p></p><p>第二个是平等。我们认为一个社区能够平等地发展，不是体现在口号上，而是体现在它做的每一件事情上。这里给大家举一个例子，在龙蜥社区第一届理事大会上，阿里云作为理事长单位提出一个提案，依然被理事大会投票否决。龙蜥社区理事大会的投票机制是这样的，出席单位数量需要超过三分之二，每家单位可投出一票，针对每个提案需要一半以上企业投赞成票才可通过。因此，即使是作为理事长单位的阿里云，或者是作为副理事长单位的统信软件，投票时依然是一票，不存在权重高低。</p><p></p><p>第三个是协作和创新。核心是我们认为整个操作系统产业链非常长，涉及到从底层芯片、服务器、操作系统，到上层应用，需要链条上的所有人能够一起协作。创新是龙蜥社区能够持续发展的一个动力源头，引领整个社区甚至操作系统产业的发展。</p><p></p><p>基于社区的使命愿景和信念准则，接下来我将详细为大家展开龙蜥社区在过去 1 年做的一些比较重要的工作。</p><p><img src=\"https://static001.geekbang.org/infoq/fa/fa1f13c1de754208bf32c74fdc137b8f.png\" /></p><p></p><p>第一个是技术生态。去年我们发布了<a href=\"https://www.infoq.cn/article/78JbM9167QeRUW38rPBY\">龙腾计划</a>\"，希望从技术、产品、商业三个方面来整体地提升社区合作伙伴价值，作为一个操作系统开源社区，我们将通过生态发展以及技术协作，让龙蜥操作系统具备非常大的技术竞争力，这是社区发展的基本盘。</p><p></p><p>第二个是产品生态，核心希望通过产品方案的推广，包括产品的交叉认证和技术服务，来实现社区所有的合作伙伴和理事单位的产品生态繁荣。</p><p></p><p>第三个是商业生态。我们认为所有参与到社区里面做开源的企业，一定要能够找到自己的合理的商业模式。为什么 Linux 以及 Linux 内核，能够成为国际上较为成功的商业开源项目？核心还是参与的公司和的个人都能够从社区开发中拿到自己的利益。我们希望通过龙腾计划为理事单位和合作伙伴能够找到一条方便实现自己商业价值的途径。</p><p></p><p>值得一提的是，一年前，我们发布了《OpenAnolis 龙蜥社区技术创新白皮书》，对龙蜥社区在技术发展和创新上的思路以及围绕思路的初步探索进行了系统性的展示。2022 年是龙蜥社区在产业落地的一年，为让大家看到龙蜥社区每一年扎扎实实的突破，我们正式发布<a href=\"https://openanolis.cn/assets/static/openanoliswhitepaper.pdf\">《2022 龙蜥社区全景白皮书》</a>\"。此次白皮书涵盖 6 大章节，包括社区伙伴风采展、社区技术演进、原生技术概览、“龙蜥+”精选方案与案例、社区运营风采展。白皮书 2.0 版本更加注重社区温度、热度、亮度三位一体的全景呈现，也会侧重展示社区成立以来的沉淀和积累，包括覆盖政务、电信、金融等多个领域的迁移产品和解决方案。希望通过这本全景白皮书让大家对龙蜥社区有更加全面的了解。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1c/1c92ff7f20a186a8e225a139383edcc0.png\" /></p><p></p><p>在合作伙伴价值之外，龙蜥社区注重产品供应链和软件供应链的锻造，其背后主要是人才培养的工作。其实对于操作系统整个产业而言，人才是非常重要的，但在过去一段时间里国内相关人才储备和教育存在短板，还有很大的提升空间。对于龙蜥如何去做好人才培养？我们也定义了自己的人才供应链计划，将通过三个工作来推动龙蜥人才供应链的发展。</p><p></p><p>第一个是龙蜥实验室，操作系统本身的学习曲线比较陡峭，如何让广大开发者、爱好者、高校同学，能够更加方便的去使用 Linux 的操作系统和资源，我们基于“看得见、摸得着”的理论，打造了位于龙蜥官网上的龙蜥实验室，让用户通过简单的点击就可以拿到一个龙蜥操作系统环境，帮助他更好地了解龙蜥和应用 Linux 操作系统。</p><p></p><p>第二个是龙蜥高校行，是一个与高校之间的线下长期互动，通过线下和线上的教学来帮助大学生们更好地了解操作系统的研发。除此之外，龙蜥社区积极参与各大赛事，为大赛设计赛题、提供导师、培训技 术、参与评审等，将产业发展思考融入赛事，加强操作系统领域人才 的培养。上半年，龙蜥社区走进了北大开源实践课，为多所高校生介 绍培训龙蜥操作系统，参与了中科院开源之夏、阿里巴巴编程之夏、 教育部产学合作协同育人项目、大学生系统能力大赛操作系统设计 赛、“互联网”大学生创新创业大赛等等，在学术研究、课程合作、 赛事赞助等多方面保持与高校的密切合作。</p><p></p><p>第三个是龙蜥大讲堂，过去很多同学学习 Linux 或者操作系统时，他们遇到很大的问题就是课程非常枯燥。那<a href=\"https://www.infoq.cn/video/87RUvdjZHzF1bRrCVpLi\">龙蜥大讲堂</a>\"有什么不一样呢？我们还是希望能够对于一些专题进行展开，同时对于一些现实中同学们会遇到的问题去进行实战讲解，这样一方面让同学们在实战中更易理解，另一方面是让大家更有代入感，也更容易实操。另外，我们还在做一个《龙蜥开发者说》的栏目，邀请很多一线的开发者现身说法“如何参与龙蜥社区”，让大家对整个龙蜥社区的开发和运营更加有体感，也更加容易参与。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cd/cdb11588717626659fd4994dd4d1b035.png\" /></p><p></p><p>除人才之外，对龙蜥社区而言，产业技术的持续演进也十分重要，包含了软件供应链、伙伴供应链，以及龙蜥生产线等概念。我们认为软件供应链更多解决的是生产资料的问题。龙蜥社区的理事单位、生态伙伴，以及高校和科研机构一直在共建软件供应链安全的项目，通过对漏洞信息库，包括代码版本的信息库、代码安全的信息库、CBE、安全中心的建设，希望能够帮助我们所有参与龙蜥社区的企业，解决掉在软件供应链安全方面的一些问题和困扰。在解决了生产资料的问题之后，另外一个就是要解决生产关系的问题。前面我也提到了整个操作系统的产业链条是很长的，龙蜥社区集合了云厂商、芯片厂商、服务器厂商、应用厂商等等产业上下游多重角色，希望通过龙蜥社区生态形成一条完整的全链路的解决方案，帮助企业用户更好地解决一些生产过程中遇到的问题。</p><p></p><p>在解决了生产资料和生产关系以后，我们如何去提高我们的生产力呢？其实龙蜥社区也提供了一整套比较完整的工具去帮助企业用户。比如说针对广大开发者的开发者平台服务，针对日常测试问题的<a href=\"http://mp.weixin.qq.com/s?__biz=Mzg4MTMyMTUwMQ==&amp;mid=2247493153&amp;idx=1&amp;sn=934df601ea5c2de5e5fefbabf4fb1a4e&amp;chksm=cf651553f8129c45b54d705b5fb21377eaca1ba0baa94421051fb335ef793ce30c76d8fd9c96&amp;scene=21#wechat_redirect\">一站式测试服务平台</a>\"，针对在发行版编译过程当中遇到的环境构建方面的问题，我们也提供了 ABS 系统……我们通过一整套社区基础设施来帮助企业用户真正实现软件包选型的合规，构建的自动，发布和运维是规范和有流程的。龙蜥社区通过全面提升整个生产线的能力，来支撑企业技术的持续演进。</p><p></p><h2>&nbsp;应“云”而生，下一代龙蜥操作系统</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f0/f04c01d4b472df3fce77189544d5e3e9.png\" /></p><p>对于龙蜥社区未来的发展，下一代操作系统的打造是一个非常重要的工作。我将重点向大家介绍一下&nbsp;Anolis OS 23。在云栖大会技术主会场上，阿里巴巴合伙人、阿里云基础产品负责人蒋江伟也提到龙蜥社区联合生态企业共同打造并发布了 Anolis OS 23 的公测版。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8c/8c4a2ed7d983dcd76c1da47713ccf6d9.png\" /></p><p></p><p>Anolis OS 23 是非常庞大的社区下一代操作系统，值得关注的有两个非常核心的点：</p><p></p><p>第一：社区第一次尝试通过分层分类理论指导操作系统的研发工作来打造Anolis OS 23，其中，分层分类理论是由龙蜥社区副理事长单位统信软件发起和主导的。在统信软件的主导下，社区的理事单位都积极地参与到一些理论的论证以及实验工作，我们希望通过分层分类的理论能够解决掉操作系统研发过程中的协同问题，以及操作系统产业的合作问题。</p><p></p><p>第二：我们通过整个社区所有的 SIG（Special Interest Group ）小组来支撑社区操作系统的发展，从上图大家可以看到目前社区里快速发展的 SIG 小组还是非常多的，无论是在内核技术、系统安全、基础设施等领域我们都做了非常多的工作。希望通过龙蜥社区的技术创新，联合所有理事单位和生态伙伴实现协同，能够帮助下一代龙蜥操作系统可以更好地解决掉产业以及将来可能会面临的一些问题，能够真正实现一个面向下一代的全场景的操作系统。</p><p></p><p>最后想给大家讲一下我们认为的未来是什么样子的。我们希望龙蜥社区能够和所有的理事单位、和所有的伙伴一起，共同在开源的道路上推进中国操作系统产业的发展。同时，我也非常有信心在大家共同努力下，一定能够共同打造国产操作系统未来的新丰碑！谢谢大家！</p>",
    "publish_time": "2022-11-08 17:51:43",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "7*24 小时河道治理监测，AI 技术如何才能有的放矢？",
    "url": "https://www.infoq.cn/article/72iGlK6NDdldRLSo0Uly",
    "summary": "<p>河道是水生态环境的重要载体，具有输送和储存水资源的功能。但是，随着城市化、工业化的发展，大量的生活污水、工业污水排入了城市河道之中，不仅破坏了河道的生态系统，也可能危害居民身体健康。</p><p></p><p>此外，由于城市河道一直处于无人管理的状态，没有全面地进行疏通整治，河道中的垃圾、污水、淤泥等造成河道的堵塞，加上没有合理的规划，很容易诱发水体富营养化甚至洪涝等灾害。</p><p></p><p>近年来，随着人们对生态问题的日益重视，河道治理也变得愈加重要。</p><p></p><p>然而，长期以来，城市河道治理工作需要依赖于人工巡查或者人工监控的方式，假设要24小时监管几十个甚至上百处河道，只依赖人工，很容易存在工作量大、信息遗漏、实时性差等各种问题。而如此繁重的工作量、全天无休的工作时长、海量的数据信息和及时的信息同步需求，恰恰是<a href=\"https://www.infoq.cn/article/MQ0BZcA5TUaNbT7hIEm2\">数字化</a>\"技术的“强项”——包括 AI 在内的各种技术正在被应用于城市河道治理过程中。</p><p></p><h2>面对复杂场景，通用 AI 技术“捉襟见肘”</h2><p></p><p></p><p>具体来说，河道治理主要是针对排污、垃圾等行为进行监测，及时进行清理，保护河流的生态环境；同时监测水位和排水口溢流的情况，当雨季来临时，可以及时对河道进行疏导，防止洪灾的发生；在日常，还需要对河道周边进行监测，防止有人靠近河边危机生命安全。</p><p></p><p>在这些场景下，通过 <a href=\"https://www.infoq.cn/article/YPbD1WQVSdrX9XiBVjcT\">AI</a>\" 技术进行河道治理，主要是利旧既有的摄像头，使用AI自动识别河道治理的相关任务。这一方面可以节省大量的人工投入，减少巡检、监控人员的工作量，另一方面，还能全天候进行监控，避免人为遗漏，达到真正的降本增效。</p><p></p><p>以深圳河流水质科技管控项目为例：该项目中管控的对象包括207条重点河流、1467个小微黑臭水体、5000多个沿河排水口，其中全部重点河流要做到一日一巡一测。2019年，通过与万科物业（<a href=\"https://www.infoq.cn/article/zijfOa2ZMW3MPUqVFAOJ\">万物云</a>\"前身）合作，在全市主要河流布设了132套高清摄像头、122个自动监测微站，建立了含陆（人工巡查、手持设备）、海（无人船、微站、流量计）、空（无人机、摄像头）“三军”和一支“特种部队”（应急巡查）的全覆盖、空地结合、人机结合、立体交叉的监测网络，全面采集水环境数据信息。</p><p></p><p>万物云目前主要包含了 Space（空间）、Tech（科技）和 Grow（成长）三大模块，聚焦的 AI 河道治理场景包括：岸堤塌陷、人员落水、人员垂钓、河岸垃圾、河面漂浮物、水质异常、排水口溢流等。</p><p></p><p>但是，其中，并不是每一个场景的落地都一蹴而就。比如，万物云提出的河道治理方案中大多采用了<a href=\"https://www.infoq.cn/article/MDuweEQy7Qr1FNHFXzfN\">目标检测</a>\"的方法，涉及对人员垂钓、人员入侵、漂浮物等容易识别的场景，同时，也存在一些比较复杂的场景，不能通过通用的 AI 技术去解决，或者做不到覆盖所有的情况，例如：排水口溢流。</p><p></p><p>由于摄像头一般安装距离较远，排水口的监控画面比较小，加上排水口存在数量多、形状不一、分布点位广泛等特点，河道排水口溢流检测对于 AI 技术是一个具有挑战性的应用场景。</p><p></p><p>目前常用的目标检测算法存在局限性，只能识别明显的排水管及排水坝，如：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/ab/83/ab5e1204ea8677350b4dcde11029be83.png\" /></p><p></p><p>对于地面涵洞以及被水淹末情况下的排水口无法进行识别，如：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/48/28/48dc7d4663c0781db4d466565c92fe28.png\" /></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/66/65/6672d5252eb4e3014e89bfb79f36cb65.png\" /></p><p></p><p>因此，如何有效全面的检测所有类型排水口就成为了一个棘手的难题。</p><p></p><h2>用“图像语义分割+预设区域”检测方法解决复杂问题</h2><p></p><p></p><p>为了解决排水口溢流检测的复杂问题，万物云团队做了大量的实验，提出了一种图像语义分割结合预设区域的河道排水口溢流检测方法：通过深度学习方法，利用语义分割算法分割出河道水体，结合摄像头画面上的预设区域（排水口区域），再用后处理方法计算出水体面积的占比，从而可以判断出排水口是否发生了溢流。</p><p></p><p>与常规的目标检测方法相比，以上提出的整套方案可以解决排水口在被淹没等特殊情况下难以检测的问题，覆盖了不同场景下的排水口溢流检测。</p><p></p><p>具体做法是：首先在摄像头画面中设定一个mask预选区域，把图像中的排水口位置框出来；然后对整张图像进行语义分割，得到水体的像素位置；接着使用传统图像处理方法把mask区域中的水体面积占比计算出来。当连续多帧图像的mask区域的水体面积占比都大于特定阈值时，则判断这个排水口发生了流溢，触发告警。</p><p></p><p>实施步骤分三步：设置排水口预设区域、语义分割检测水体、计算预设区域内的水体面积占比。</p><p></p><p>第一，设置排水口预设区域：先设置好要关注的区域，通过判断此区域是否有水来决定排水口是否溢流。如下图：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/83/5d/83eefb38b6c571232b2199a76a80825d.png\" /></p><p></p><p>第二，<a href=\"https://www.infoq.cn/video/S5BEM3wyGS3BzqypJ6kE\">语义</a>\"分割检测水体：使用轻量级语义分割网络，对图像中的水体进行分割。如下图：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/2f/63/2f2268bb407900d0c181b23fece28063.png\" /></p><p></p><p>第三，结合语义分割图和预设区域，计算预设区域内的水体面积占比：根据多边形的坐标点，计算出预设区域的面积S1；把分割图和预设区域结合，利用像素值去计算预设区域内的水体面积S2；计算水体面积在预设区域内的占比S2/S1，当面积占比大于阈值则判断排水口发生了溢流。如下图：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/9d/2f/9dfe68e06feae18eaa0d0631c049802f.png\" /></p><p></p><p>整体算法流程如下图：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/5f/a2/5f267c24c251e9659a9ab0b66daf60a2.png\" /></p><p></p><p>通过这种图像语义分割结合预设区域的方法，不再局限于明显的“洞口型”排水口，可以实现不同场景下的各类型排水口的溢流检测，泛化应用场景。</p><p></p><h2>10个河道治理场景，7*24 小时 AI 智能监测</h2><p></p><p></p><p>2022年5月31日，由万物云算法团队研发的AI河道治理方案正式上线，在深圳百余条河道进行试运行。目前，已经实现了在“垂钓检测”、“人员入侵”、“水质异常”、“水位预警”、“排水口溢流”等10个河道场景的 7*24 小时 <a href=\"https://www.infoq.cn/article/APV0tYBQq8hC2xc5fWFm\">AI 智能监测</a>\"，极大减轻人工巡逻及盯屏等繁重工作。</p><p></p><p>在这个过程中，万物云的算法团队通过智慧化手段，重塑了空间服务效率和体验，为河道治理提供了强力支撑，建立了起动态化、可视化、可监督的系统，实现了对深圳河流水体全天候、全覆盖、无死角的精细化动态管控，助力深圳成为全国黑臭水体治理示范城市。</p><p></p><p>首先是最直观的人力成本，深圳河流水质科技管控项目在 1km² 的范围上节约5人左右的投入，核算约50%的成本，在长久时间线上至少节约60%以上的人力成本；其次是时间的成本，从之前的10h/人天的人工盯屏，变成了 7*24 小时的无间断监测；此外，利用智能手段监测，自动识别、自动告警的业务闭环，极大的简化了繁琐的流程，相比于人工的现场巡查和告警，效率提升 75%+。另外，值得一提的是，万物云的 AI 方案几乎95%以上是可复制的，边界成本极低，相对于人工招聘、培训、上岗等环节来说， AI 方案上线和落地更快。</p><p></p><p>当然，对于河道治理而言，深圳只是一个开始；对于生态保护而言，河道治理只是一个开始。有效的河流治理将助力恢复受损地区的生态环境，提高河道自我净化能力；而河道的清洁化，将助力实现河流生态环境的可持续发展，有效防止生态环境的持续恶化，促进整个社会的生态环境可持续性。</p><p></p><p></p><blockquote>作者介绍：姚钊盈、苏红梅、袁戟、郑泽涛，来自万物云DTC-机器智能产品部。团队自组建一年来，在德国慕尼黑工业大学（Technische Universitaet Muenchen）博士、万物云数据与技术中心算法负责人袁戟博士的带领下，以云端视觉、边端视觉以及运筹优化三个方向作为主要研究方向，开展算法研发工作，为万物云远程运营、智慧工地、城区巡航（无人机）、河道治理等其他应用和场景赋予AI能力，并通过智慧工单、保洁和运维的智能调度等算法实现AI能力的沉淀。</blockquote><p></p>",
    "publish_time": "2022-11-08 18:48:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]