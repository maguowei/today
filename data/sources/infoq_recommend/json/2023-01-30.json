[
  {
    "title": "职业“倦怠”期开发者如何转变心态",
    "url": "https://www.infoq.cn/article/2pPSUdJjyrCRJOyFYr4t",
    "summary": "<p>大约有<a href=\"https://haystack-books.s3.amazonaws.com/Study+to+understand+the+impact+of+COVID-19+on+Software+Engineers+-+Full+Report.pdf\">83%的开发者</a>\"都称自己有倦怠感，他们工作中很多因素都阻碍了灵活的心态。而事实上，软件开发者往往是无限循环的、不断逼迫的死线的代名词。编程是项充满创造力的职业，但我们的大多时间都在处理影响生产力的困难任务上，这些任务不仅夺走了我们每日工作的快乐，还留下了满腹挫败。</p><p>&nbsp;</p><p>在最后一秒解决缺陷、死守既定的时限，这些常常让开发者倍感压力，但不断发展的数字世界也是另一个焦虑感的来源。</p><p>&nbsp;</p><p>业界新出现的技术常常会在一夜之间成为软件开发者必备的技能项，而要想在飞速发展的行业中取得成功，我们最好能时刻掌握业内最新工具。</p><p>&nbsp;</p><p>这点是指导开发团队的首席技术官（CTO）或高级领导需要协助的方面，改变旧的模式，激起增长心态，并帮助开发者变得更敏捷、更灵活。换句话说，就是变换心态。</p><p>&nbsp;</p><p>这个流行词在多个行业中都有使用，在像是<a href=\"https://hbr.org/2013/08/how-to-shift-a-mindset-in-your\">HBR</a>\"和<a href=\"https://www.forbes.com/sites/forbesagencycouncil/2022/04/08/the-power-of-the-changing-mindset/?sh=391e84dc492e\">福布斯</a>\"之类的刊物中也曾被提及。其理念在于，当我们处于一个发展如此之快的世界中，我们不能再被动接收变化，而要去掌握先机。在亚当·格兰特的书《重新思考》中曾写道：</p><p>&nbsp;</p><p></p><blockquote>“……我们需要和思考一样，花费同样多的时间在重新思考上。”</blockquote><p></p><p>&nbsp;</p><p>在本文中，我们将探讨软件工程团队所面临的障碍，以及要如何培养心态的改变。</p><p></p><h2>常见的误区</h2><p></p><p>在软件工程中谈论心态时，人们常常赞同的一种说法是：</p><p>&nbsp;</p><p></p><blockquote>“团队是否强大取决于其最弱的成员。”</blockquote><p></p><p>&nbsp;</p><p>一位负能量的团队成员消极怠工会给工作带来麻烦，致使团队其他成员士气低迷，积极性下降。留心这些成员，他们会为未完成的工作找接口、不接收自己的无能，并且还会让其他人也质疑自己的工作，从而让生产力飞速下降。</p><p>&nbsp;</p><p>而同样众所周知的是，公司自动化程度越高，开发者便越可能从工作中解放，抽出时间专注开发益于客户的数字创新。这正是BOS框架背后的理念之一，骄傲地说，我也是产品其中工程师之一。</p><p>&nbsp;</p><p>不过，目前很多开发者还是受困于排障等大量的手动任务中。像是代码编辑器、故障追踪器，还有让应用程序自动化部署运维的Kubernetes，类似的工具有很多，但企业迟迟未能接受。</p><p>&nbsp;</p><p>另一个影响因素是不切实际的死线，不仅影响了软件工程师的生活工作平衡，也对工程师们的积极性有极其消极的影响。对开发者而言，最好的投资就是自身的发展，尤其是在当前这个不断发展的技术领域。但工作加班和手动任务的重压之下，难怪开发者会没有动力学习新技能。</p><p>&nbsp;</p><p>综上这些因素都会影响开发人员的心态转换。那么领导团队能对此做些什么呢？</p><p></p><h2>鼓励求知若渴的文化</h2><p></p><p>微软的CEO，Satya Nadella提出的“<a href=\"https://cdn2.hubspot.net/hubfs/1927708/GrowthMindset_CSCollection_US_FN%20(2).pdf?__hstc=80578952.ccc32591d2a8ad08f21ba7ee8f9333c0.1666196011273.1666196011273.1666196011273.1&amp;__hssc=80578952.3.1666196011273&amp;__hsfp=4082474608&amp;hsCtaTracking=812a2c84-17c5-488f-be1c-54b59531beea%7C80c7f209-cd86-48a7-99c4-d97d5055a0ec\">科技巨头以持续学习为新重点的文化刷新</a>\"”，改变了员工的行为习惯。他称这是从“万事通”向“万事学”的转变。</p><p>&nbsp;</p><p>当每时每刻都有新鲜的人才出现时，那些拥有业内十年以上开发经验的“老古董”如果不提升自己的水平，很可能就会被后浪拍死在沙滩上。</p><p>&nbsp;</p><p>因此，在领导工程团队时，我们必须鼓励团队成员不断成长，将学习加入日常工作。从测试、教程和游戏开始，最终为开发者提供在不同技术栈上工作的机会。这是扩展团队知识的必要路线。</p><p>&nbsp;</p><p>举例来说，如果有位员工拿到了AWS认证的架构师资格，那这很好。在我们公司，我们会鼓励员工同样尝试其他云平台，以<a href=\"https://podcasts.apple.com/om/podcast/critical-skills-that-every-engineer-should-master/id1462366641?i=1000579439291\">更好地巩固自己在架构上的能力</a>\"。当然，这一切要建立在双方的意向上，不能强加给员工。</p><p>&nbsp;</p><p>因此，如果团队过度沉迷于单个工具，而不愿尝试其他方案，团队可能很快便被时代抛下，并阻碍公司的创新。而鼓励求知若渴文化的公司，意味着开发者会永远走在时代前沿，并为用户和利益相关者们找到最优的解决方案。</p><p></p><h2>从初创环境中学习</h2><p></p><p>大公司或企业或许不会期望开发者同时掌握多个技术栈，但初创公司不同。那么我们能从这些环境中学到什么呢？</p><p>&nbsp;</p><p>走在时代潮流之前的<a href=\"https://www.youtube.com/watch?v=a5b4nn3ZEVU\">史蒂夫·乔布斯</a>\"通过<a href=\"https://www.youtube.com/watch?v=a5b4nn3ZEVU\">像初创公司一样管理苹果</a>\"，改善了合作和团队精神。他称苹果为“全球最大的初创公司”，是可以无需监工或创立公司委员会，都能信任公司同事履行自己的承诺。</p><p>&nbsp;</p><p>在初创或小型公司中工作的最大优势在于，你可以身兼多职并了解公司各个方面。我在大学毕业后便以软件工程实习生的身份加入了现在的公司，并一直工作至今。在过去的十年间，我接触过很多技术，从网页和移动端开发到数据库、IoT应用，以及数据科学项目无所不有。我的经历让我很快构建了对多种技术栈的基础知识库，并能发现各类技术间的细微差别。</p><p></p><p>开发者常常会沉迷于特定工具，并想拿这个工具解决所有问题。但如果你手里只有一把锤子，那么所有东西在你眼里都只是钉子。在初创公司工作对开发者来说是个令人激动的机会，你可以从草稿开始，提出疯狂的主意，试图解决复杂问题，并成为团队的一份子。</p><p>&nbsp;</p><p>这和普通公司员工不同，你会成为构建公司未来的一份子。在这种环境下的开发者往往不再是孤狼，他们会学会在各个部门之间进行有效的沟通。</p><p>&nbsp;</p><p>因此，当在开发团队中建立心态转变时，可以向初创公司寻找灵感，并将求职简历中在初创公司工作过的经历看作是加分项。而如果你已经在初创公司工作了，那么学无止境，向你的竞争对手看齐。</p><p></p><h2>给处理问题设立一个期限</h2><p></p><p>给团队和自己一个解决特定问题的时间窗口，在窗口之后就去解决别的问题。开发者心态抑郁往往是因为他们在困难问题上折磨了好几小时，或被进展迟缓的bug卡住很久。</p><p>&nbsp;</p><p>他们常说，“这是工作的一部分”。但我有个明确的规定：如果团队在一个问题上工作超过了四小时，让他们出去溜一圈，然后带着转换好的心态回来继续工作。如果他们散心回来又花了四个小时而进展缓慢，那么就去向同事求助，肯定会有人能解决的。如果开发者们能学会寻求并接受其他团队成员的建议，那么这也将会激发心态的转变。</p><p>&nbsp;</p><p>这也是为什么开发者和工程师永远不应该只爱上一种编程语言或技术，他们应当不断前进。不断寻找问题的多种解法，那么你将没有上限，这是对工程师的基本期望。</p><p></p><h2>相信人人有责的方法</h2><p></p><p>开发团队中的所有人都应当相信工作所在组织的使命和远景，不仅如此，也还应对文化建立和维护的机会和机遇抱有同样的关注。这是有赖于每一位开发人员贡献的共同责任。</p><p>&nbsp;</p><p>一个默认的规则是，公司有义务为每位员工直接提供机会。我会永远感激我的前辈激励我挑战自我并尝试新事物，尤其是在国防部培训空军的软件开发和数据科学方面。</p><p>&nbsp;</p><p>团队成员总会有合适的时机遇见绝佳的机会。</p><p>&nbsp;</p><p>然而，自上而下的文化构建方法并不是万能的。我所相信的是<a href=\"https://hbr.org/2021/02/company-culture-is-everyones-responsibility\">建立人人有责的组织文化</a>\"，文化应当是被接受，而不仅仅是由领导所确立。员工同样应当表达出探索意愿及冒险精神，这才是好员工与杰出员工之间的差距。</p><p>&nbsp;</p><p>在采用远程办公之前，我们会每周五都在办公区选一位团队成员，分享软件开发、科技、云端、CI/CD，任何领域内的任何话题的科普。这会让开发者们走出自己的舒适区，也能让团队成员每周都学到一些新知识。</p><p>&nbsp;</p><p>团队领导也不应期望开发者仅遵循一个文化的条例。领导应当对资源进行分配，确保所有员工都对这种文化有理解，有批判，会维护文化的原则并对其进行补充。如此一来，我们也鼓励了开发者对这种文化的批判思考，促进了心态的转换。</p><p></p><h2>建立业务影响为先的心态</h2><p></p><p>培养<a href=\"https://hackernoon.com/the-secrets-to-building-a-world-class-software-engineering-team-to-create-cutting-edge-products\">以业务影响为优先</a>\"的心态同样会为工程团队带来改变，这是BOS框架成功的主要支柱之一，也是我所接受的培训理念。换句话说，这意味着一种集成文化的建立，开发者不仅要对工程本身有理解，同时也要对业务有认知，能够将技术看作是<a href=\"https://www.techopedia.com/pursuing-a-job-in-devops-what-every-engineer-must-know-in-2022/2/34867\">实现业务成果</a>\"的工具。</p><p>&nbsp;</p><p>这是因为拥有创业心态的工程师会希望在完成任务的同时做得对。当然，这也只是个夸张说法，但工程师大多都是完美主义者，但企业家却没时间过度思考，后者更倾向于授权，并只在必要的时间学习。工程团队不能忘记自己的项目最终是有商业目的的。</p><p>&nbsp;</p><p>工程负责人必须为每个项目构建商业案例，让非技术人员以及商业利益相关人都能参与并为决策提出自己的想法。同时，开发者也应与商业利益相关人、同僚，以及其他部门的同事相沟通，以实现技术带来的商业影响。如此一来，弥补了产品利益相关人与开发团队之间的鸿沟不仅帮助我在职业生涯中取得进展，也让我更容易适应新的角色。</p><p>&nbsp;</p><p>开发者可能会陷入无尽的循环，上一次学习新东西或影响公司文化时也不知道是猴年马月的了。因此，在公司内成功建立心态的转换对打破职业生涯瓶颈是非常重要的，这会让团队成员处于流程的核心，打破长久不变的技术栈，并鼓励不断地进步。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/developer-challenges-mindset/\">The Most Common Developer Challenges That Prevent a Change Mindset—and How to Tackle Them</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/58jKuW7dDZ0K7qt9hpL7\">团队已不堪重负，如何“分而治之”</a>\"</p><p><a href=\"https://www.infoq.cn/article/JCB92DRfLZF7SaNhlBsL\">团队交付的速度变慢了，我该怎么办？</a>\"</p><p><a href=\"https://www.infoq.cn/article/Mm3ESuhEcwIy7F7eMYfg\">软件项目管理中价值流反馈回路的意义</a>\"</p>",
    "publish_time": "2023-01-30 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "2022，Meta最难过的一年",
    "url": "https://www.infoq.cn/article/673lWz81ClJ4wK0DygAg",
    "summary": "<p></p><p></p><p></p><blockquote>通过扎克伯格的问答录音和内部调查结果，我们得以真实感受到Meta的困境给每位员工造成的切身影响。</blockquote><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b9/b9469c7ce74de9f4f185296d73405d8c.png\" /></p><p></p><p>在Meta 2022年最后一次公司全体问答会议开始之际，扎克伯格以失望但却依然坚定的语气打开了话题。</p><p></p><p>在外媒Recode拿到的会议录音中，扎克伯格表示“我们根据对业务发展形势的判断制定了2022年运营计划，但事态显然并没有按照我们预期的方向推进。”</p><p></p><p>这位科技巨头的掌门人明显弱化了事态的严重程度。</p><p></p><h2>有史以来最艰难的一年</h2><p></p><p>2022年可谓Meta有史以来最艰难的一年——不是因为之前曾经出现过的丑闻，而是在经历了连续18年看似不可阻挡的增长之后，公司股价同比下跌了65%。</p><p></p><p>这一年间，随着利率上升、通货膨胀率急剧增长以及动荡的宏观经济形势，整个科技行业的价值预期都受到了冲击。但在前五大科技巨头当中，Meta的估值跌幅位列榜首。</p><p></p><p>华尔街分析师们将原因归咎于该公司的特有问题：来自TikTok的竞争令其难以招架，苹果新出台的隐私政策致使其广告销售放缓，而扎克伯格孤注一掷式的年均100亿美元虚拟/增强现实与元宇宙投入也没能得到资方的信任。</p><p></p><p>扎克伯格称自己已经有计划来扭转这股可怕的衰退。他将继续打造元宇宙，但大部分精力将集中在改进Meta的核心社交媒体业务（Facebook与Instagram）身上，同时会寻求新的方法来扩展公司广受欢迎、但利润贡献较低的消息收发应用。他把话挑明，Meta的员工需要比以往任何时候都更加努力地工作。</p><p></p><p>“我对前景仍然保持乐观。但2022年给我们敲响了警钟，事情不会永远如你所愿，你不能认为顺风顺水是理所当然。所以，我们必须真正全力以赴。”</p><p></p><p>Recode采访了十多位Meta员工——有些是现任员工，有些在去年已经离开了公司。他们讲述了公司内部面临挑战时的焦虑与乐观情绪。包括高级主管和普通工程师在内，这些消息人士告诉Recode，如今的Meta公司越来越注重效率，在企业文化层面也开始愈发严格地限制员工间的意见往来。</p><p></p><p>与此同时，Meta的成员们也确实比以往任何时候都更具竞争力。有些人对变化表示欢迎，但总体来讲，受到近期裁员、股价下跌和公司过度关注元宇宙等因素的影响，Meta的整体士气不及以往。（为了避免公开发言影响到职业发展，本文将隐去消息人士的真实姓名。）</p><p></p><p>一位在Meta工作多年的员工表示，“最让人担心的是：如果股价继续下跌，我们的信心该靠什么来支撑？”此人对Meta的长期规划（例如开发轻量化增强现实眼镜）其实非常期待，只是不清楚Meta要多久之后才能靠这类产品创造出新的收入增长点。“我不知道这些产品什么时候才能变成现实。”</p><p></p><p>Recode还拿到一份去年10月的内部调查报告，其中基本反映出员工的观点：只有28%的受访员工对公司未来持乐观态度，58%的员工对公司整体仍然比较认可。</p><p></p><p>调查结果出炉之际，裁员传闻已经在四处流传，Meta公司的招聘计划也被暂时叫停。在这项调查中，只有31%的员工表示对公司领导团队很有信心，较去年5月的上一次调查下降了11%。尽管如此，员工们在某些方面仍然比较乐观：74%的员工对领导层的“既定愿景”表示满意，82%的员工对Meta的使命定位表示认可，84%的员工则对自己的经理感到满意。</p><p></p><p>作为对调查结果的回应，Meta公司发言人向Recode发出如下声明：“反馈是我们企业文化的核心部分，调查的目标是了解我们哪里做得好、哪里还需要改进。我们对未来的道路保持乐观，也感谢每天为公司使命而不懈奋斗的全体员工。”</p><p></p><p>有几位员工告诉Recode，他们期待明年Meta的情况会有所好转。目前也有不少迹象让人充满希望：Facebook用户群体在去年的首次下滑后重新恢复增长；人们使用Reels的时间有所增加（Meta针对TikTok推出的同类产品）；公司的股价已经较2022年11月的最低点上涨了40%。而，这家科技巨头想要重回巅峰，无疑还有很长的路要走。</p><p></p><p>Meta产品的总用户规模超37.1亿人，占世界总人口的近一半。这也使其成为迄今为止全球最大的社交媒体企业。Facebook和Instagram等应用塑造了我们的文化、经济和政治规范。这家公司的命运，特别是能否重获投资者和员工的信心，将决定其能否继续在人们的日常生活中占据主导地位。而一旦失败，这份巨大的权力将被拱手让予TikTok等不断壮大的竞争对手。</p><p></p><h2>努力重拾“斗争”文化</h2><p></p><p>随着今年Meta核心业务的增长放缓，公司开始做出一系列艰难的决定，包括削减某些工作岗位和员工福利，并开始限制员工在企业内的讨论内容。虽然这激怒了一部分员工，但公司领导层认为这是不美好、但却必须实施的修正举措。</p><p></p><p>扎克伯格在年终总结中表示，“我希望大家在2023年关注的头号大事，就是把公司重新带回那种昂扬向上、充满斗志的文化轨道上。有了这种文化，我们才能保持精简、行事高效。而裁员就是实现精简的第一步，后续我们还有很多工作要做。”</p><p></p><p>去年11月，Meta史无前例地一口气裁掉11000人，约占员工总数的13%，被裁者遍及公司内各个部门（当然，招聘等部门的裁员比例明显更高）。**这家科技巨头在2020年和2021年大举招聘27000多名员工之后，到裁员前员工总数已超80000人。**而在这半年各大科技巨头的裁员行动中，Meta的精简力度也远超同侪。</p><p></p><p>Meta公司CEO Andrew “Boz”Bosworth在12月的采访中表示，“这段经历不只是2022年中的低谷，甚至可以说是我整个职业生涯中的最低谷。”</p><p></p><p>在最近的员工问答大会上，扎克伯格告诉大家，Meta在未来几个月内将进一步限制员工出差、减少办公室免费餐食供应和合并办公场所，借此削减更多成本。他感谢了员工“在这段艰难坎坷的时期”所表现出的韧性和出色的执行力，但也再次呼吁员工们不断提高行动速度和工作效率。他在去年就曾反复传达过同样的信息，但不少在疫情期间拼命工作的员工对此表达了不满。</p><p></p><p>一位今年刚刚离开Meta的前员工说，“他总跟我们讲，说我们被Meta给宠坏了。”</p><p></p><p>在会上，扎克伯格暗示Meta公司对员工们宽容太久了，特别是在新冠疫情之初。当时公司专注于“更灵活地”支持员工，如今他在会上将其定性为“一段不正常的时期”。</p><p></p><p>有员工取笑Meta在内部员工讨论组中不断呼吁加大工作强度。有个员工就经常在群组中发表情包和笑话，将此举称为“胡扯淡”；另一位员工则在7月的帖子中呼吁人们“加大力度摸鱼”。</p><p></p><p>文中模仿扎克伯格和其他高管的口吻写道，“「加大力度」并非新鲜事物。但在上周的「胡扯淡」会上，我们已经看到，每个人都可以做点什么，从而在这个经济和业务充满不确定性的时期下保持前进。”</p><p></p><p>如今的领导层明显开始将重点从灵活性转向了执行效率，并推动新的指导方针以确保员工们“加大力度”，包括限制他们在工作中所能讨论的话题。长期以来，Meta一直允许员工在内部各Workplace团体中自由分享政治观点和对管理层的批评。虽然公司文化并不像竞争对手谷歌那样开放，但Meta的宽容度确实远超大部分同等规模的非技术企业。</p><p></p><p>去年12月初，该公司制定了一项新的“社区参与期望”政策（CEE），限制员工在Workplace等Meta内部消息平台上的发言内容。新政策禁止员工讨论敏感的政治、健康或法律问题，例如堕胎和枪支管制等，除非与其工作职能直接相关。</p><p></p><p>Meta人力资源主管Lori Goler在一份内部备忘录中写道，“过去几年来，我们看到大量讨论引发的混乱和精力分散。这让我们整个工作社群筋疲力尽，无法正常工作。”</p><p></p><p>新规还要求员工向特定团队或人员“给予适当反馈”，而不再允许做出笼统的负面陈述。一名员工表示，作为回应，部分员工转而私下散布口头批评、或者将观点发布到不受经理监管的平台，例如Signal或Blind。</p><p></p><p>一位员工表示，“整个公司似乎每周都在让员工失望。”但考虑到2023年的财务现状，恐怕让员工“失望”的决定还将持续涌来。</p><p></p><p>在12月的全体员工问答大会上，有人向扎克伯格提问“2023年，公司会采取哪些举措来鼓舞员工士气、提振公司文化？”</p><p></p><p>扎克伯格停顿了一下，给出了“胜利”这样一个简短的回答。说完后他自己也笑了。虽然扎克伯格承认Meta股价下跌正影响到员工的个人财务状况（Meta员工的大部分工资都是以股票支付的），但他还是强调本阶段的主要目标是改善业务表现。</p><p></p><p>“我知道，这不是那种传统意义上鼓舞士气的倡议。但我们所做的一切都是为了夺取胜利。我们来这就是为了赢，为了达成公司的使命，并取得良好的业务成果。”</p><p></p><p>醒醒吧，Meta人们！</p><p></p><p>过去几个月的残酷经历，让Meta员工们逐渐适应了新的现实。至少当下，Meta已无法在市场上大杀四方。</p><p></p><p>Meta股价的暴跌一直是员工的痛处，也是人们抱怨的共同焦点。</p><p></p><p>根据从Meta内部员工留言板Workplace上流出的截图，员工发布了不少表情包，嘲笑Meta在10月粗略收益报告发布后遭遇的股价大跌。一名员工还开发了机器人，能计算出员工入职时股价与当前股价间的差值。8月Workplace上的一张图片写道，“你的股价比最初持有时下降了71.1%。”另有员工发布了三张小熊维尼表情，其中一个代表亚马逊、一个代表谷歌，最后一个代表Meta——在股权稀释后的相对股价最低，配图文字是“找不同”。</p><p></p><p>对很多员工来说，不断下滑的财务业绩也动摇了他们继续待在Meta公司的决心。</p><p></p><p>一位今年刚离开公司的前员工表示，“有些人其实觉得留在Meta有违内心的道德判断，但又不愿放弃丰厚的薪酬。然后突然之间，这点牵挂也没了。”</p><p></p><p>有人说，目前Meta的员工士气达到了2018年Cambridge Analytica丑闻以来的最低水平。当时Meta曾面临大量批评，有报道称其允许第三方在未经用户同意的情况下，收集数百万用户数据并将结果用于政治宣传。</p><p></p><p>**一位现任员工坦言，“要么求心安，要么求财，两样总要占上一样。**而现在，本来就对Facebook行为不满的人们对道德问题的批判性更强了。”</p><p></p><p>但问题在于，不止是Meta，整个硅谷都在发生巨变。当初，Meta员工可以轻松跳槽到谷歌、苹果或者亚马逊等其他科技巨头。但随着整体经济形势的衰退，所有这些企业在过去一年间都放缓甚至直接叫停了人员招聘。</p><p></p><p>Meta员工也担心公司会继续裁员——毕竟扎克伯格自己在最近的问答大会上也没有排除这种可能性。</p><p></p><p>“我想向大家澄清一下，希望我们前一轮裁员已经足够，不用再搞新一轮的全公司裁员。但谁也无法预测未来，如果继续出现非常严重的衰退，那我们可能还得重新审视这个问题。”</p><p></p><h2>竞争、办公室政治和重组</h2><p></p><p>长期以来，Meta一直是家以量化指标为导向、极具市场竞争力的公司。其基于排名的绩效评估同产品指标密切相关，直接决定着员工的职业轨迹。如今资源有限，多位现任和前任员工都反映公司出现了一种更加残酷的文化。人员重组和对未来继续裁员的恐惧，无疑对这种文化起到了火上浇油的作用。</p><p></p><p>也有些员工想得很开，他们认为Meta这种重组和专注于绩效指标的作法就是科技巨头的常态。在其他跟Meta同等体量的公司里，“这一直就是各个部门的惯例”。</p><p></p><p>另一位于去年离职的前雇员则认为问题没这么简单，“Facebook是我待过的办公室政治色彩最浓的企业，说10倍严重也不为过。人们都在背后相互捅刀子，而且努力在经理面前表现自己。”</p><p></p><p>随着公司结构的转变，很多员工希望能转移到优先级更高的项目中去。比如Meta拿来跟TikTok直接抗衡的Reels以及元宇宙相关项目。</p><p></p><p>一位前雇员指出，“Reality Labs的工作岗位成了抢手的香饽饽。特别是元宇宙产品小组那边，体现得尤其明显。即使是负责隐私或政策方面的工作，大家的想法也是「一定要挤进元宇宙的隐私组、元宇宙的政策组」。”</p><p></p><p>有员工表示，那些远离高优先级项目的员工会产生强烈的被裁员、至少是被边缘化的危机感。“对于那些工作内容不太要紧的团队，大家的日子过得着实艰难。每个人都想用更少的钱做更多的事，免得在新一年里被公司「优化」掉。大家还担心Meta会从社会影响方面的团队下手，比如青年、福祉和慈善捐赠方面的部门，所以只能谨小慎微地保持最低限度运转。”</p><p></p><p>今年，部分身处AR/VR关键团队的Meta员工也感受到了新文化带来的压力。</p><p></p><p>曾任Meta虚拟现实执行顾问的行业巨子约翰·卡马克于12月下旬选择离职，并在现已公开的辞别信中写道，虽然他相信Meta对AR/VR技术的坚定愿景，但认为公司在执行效率方面存在问题。</p><p></p><p>“我们拥有的人员和资源多得离谱，但却不断在自我破坏和浪费精力。没必要粉饰太平，我认为组织运营效率连我预期线的一半都达不到。”</p><p></p><p>Recode采访的几位员工均表示，卡马克对Meta组织效率问题的坦率点评在公司内引起了轰动。其中一位表示，他们担心“Meta顽症已深，就连卡马克这样的人都无力解决。”但卡马克并没有回应Recode的置评请求。</p><p></p><p>卡马克在信中明确提到，虽然高层提出了明确的意愿，领导班子也很难切实引导Meta这艘大船驶上既定航线。</p><p></p><p>一位前任员工提到，“扎克伯格自己怎么想已经不重要了，因为他面前的最大障碍是官僚主义。在他之下，有20层人事结构都完全不关心什么元宇宙梦想，他们关心的只有员工人数和如何在下一轮「优化」中幸存下来。”</p><p></p><p>虽然Meta的减员增效举措面临重重困难，但不少员工仍然表示支持，希望能借此帮助公司重新回归正轨。</p><p></p><p>有员工表示，过去几个月来，扎克伯格牵头的领导班子在确定优先事务方面表现“相当好”、“透明度更高”，“执行深度也是前所未有”。这名员工认为裁员是为了“激励员工”将个人意愿与公司使命统一起来，将资源真正投入到值得探索的领域。</p><p></p><p>这位员工强调，“裁员当然不是好事。但我认为从长远来看，由此产生的凝聚力可能会对公司有利。”</p><p></p><h2>意想不到的胜利与长期元宇宙愿景</h2><p></p><p>虽然坏消息一个接一个，但Meta在这一年中也不乏高光时刻&nbsp;。</p><p></p><p>2022年，Meta面临的公共丑闻比往年要少。但这可能要部分归功于马斯克戏剧性地接管了Twitter，Sam Bankman-Fried的FTX交易所又突然垮台，全球媒体的注意力都被这两件大事给吸引了过去。无论如何，Meta终于不再像前几年那样动不动就搞出个大新闻。</p><p></p><p>即使是在对扎克伯格元宇宙梦想持怀疑态度的员工当中，不少人也看到了支持这一愿景的技术正在发展落地。人们对增强现实（AR）技术的潜力尤其兴奋，相信该技术在未来能拿出比VR头显轻巧很多的产品——比如带有计算机功能的轻量化智能眼镜。</p><p></p><p>一位前雇员承认，“在我看来，元宇宙这个概念很受欢迎。我没想到人们真的会接受「Meta」这个新名称，并热切期待我们能搞出点大动静。我原以为人们会把一切都当成扎克伯格的宣传噱头。”</p><p></p><p>目前，Meta旗下最接近AR成熟形态的产品Quest Pro（号称是「混合现实」）对大多数用户来说仍价格昂贵，毕竟每款头显价格达1500美元。Meta可能还要几年才能开发出价格更实惠的突破性AR设备。但也必须承认，扎克伯格仍然是最有能力实现这一突破、而且愿意长期投资的技术领导者之一。</p><p></p><p>Meta公司CTO Bosworth在去年12月的采访中表示，“扎克伯格有着卓越的前瞻性，相信这项技术终将流行并得到数十亿人的认可。他有意愿、也有韧性承受一切随之而来的批评和抨击。从他以往的表现来看，这是毫无疑问的。”</p><p></p><p>**许多员工也认为，扎克伯格身为领导者的一大核心优势，就是他是唯一一位继续主导科技巨头行政权、拥有董事会控制能力和免受解雇这项基本豁免权的硅谷创始人。**就是说，他可以逆舆论而动，做出短期内可能对股东有风险、但最终能够支撑长期业务的重大决策。十年之前，不少行业专家都认为扎克伯格为收购Instagram开出的收购价太高，但事实最终证明这是科技史上最成功的收购之一。</p><p></p><p>社交媒体业务顶级分析师、Evercore公司高级董事总经理Mark Mahaney评论道，“扎克伯格总能制定出一年、三年、五年和十年期计划。对管理者来说，表达自己的长期经营策略是件好事，也能保证公司的运营理念不会被华尔街的贪婪短视而过度左右。”</p><p></p><p>话虽如此，但长期看好Meta的Mahaney也有自己的疑虑，“Meta会不会成为下一个雅虎？未来使用Facebook的用户会越来越少吗？”</p><p></p><p>不少Meta员工也在问自己同样的问题。对于那些相信扎克伯格眼光的并决定与Meta共存亡的坚守派来说，这可能是个打败怀疑论者的最好机会。</p><p></p><p>在问答大会末尾，为了回应大家关于员工调查中“令人担忧”的结果所反映出的信心缺失问题，扎克伯格号召员工们要向好处看。他说现在股价较低，所以一旦未来估值回暖，员工们将获益更多。</p><p></p><p>扎克伯格总结道，“我也不知道投资者们什么时候才会认定Meta的努力已经取得成功。可能会是2023年，可能就在下周，也可能还要再等几年时间。”</p><p></p><p>原文链接：</p><p></p><p><a href=\"https://www.vox.com/recode/2023/1/11/23547490/meta-facebook-mark-zuckerberg-stock-employees-morale-survey-2022-year\">https://www.vox.com/recode/2023/1/11/23547490/meta-facebook-mark-zuckerberg-stock-employees-morale-survey-2022-year</a>\"</p>",
    "publish_time": "2023-01-30 09:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "科技圈啪啪打脸！当初的那些美好像极了一个巴掌",
    "url": "https://www.infoq.cn/article/7xZB7zfVs1kp61iK5UzU",
    "summary": "<p>&nbsp;</p><p></p><blockquote>2022年，每个人都不好过，不是每个人都可以实现当初的雄心壮志，无论有意还是无意。我们简单列了一些“打脸”事件，背后的原因不尽相同，但最终只有一个意思：且行且珍惜。</blockquote><p></p><p>&nbsp;</p><p></p><h4>白烧了1400亿后，自己打自己的脸</h4><p></p><p>&nbsp;</p><p>2021年北京时间10月29日凌晨1点，被业界人士称为“VR圈春晚”的Facebook Connect 大会在一众期待中举行。会上，扎克伯格将Facebook正式更名为Meta，股票代码也将从12月1日起由“FB”更改为“MVRS”。这场发布会除了公布两款机型的代号之外，并没有其他的产品更新。扎克伯格和高管们花了两个小时去描绘遥不可及的“元宇宙”：每个人都可以在元宇宙世界里拥有一个化身……</p><p>&nbsp;</p><p>大厂“all in”元宇宙带来的影响是巨大的。2022年，元宇宙成为当之无愧的科技“热词”，企业不说自己沾点元宇宙业务的话就像变成了时代弃儿。而凭一己之力掀起元宇宙风口的扎克伯格也真的花了真金白银去投资。</p><p>&nbsp;</p><p>根据科技投资公司 Altimeter Capital 创始人兼CEO <a href=\"https://cointelegraph.com/news/zuckerberg-s-100b-metaverse-gamble-is-super-sized-and-terrifying-shareholder-says\">Brad Gerstner</a>\" 所述，该公司已宣布每年向其元宇宙项目投资 100 亿至 150 亿美元，包括 AR/VR 技术和 Horizo​​n World。但这些投资“可能需要 10 年才能产生结果”&nbsp;Gerstner表示。</p><p>&nbsp;</p><p>但现阶段 Meta还是有成果的，我们一起看看：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f6/f6d665bc54d26623f2c1e0fb7240ecb0.png\" /></p><p></p><p>&nbsp;</p><p>2022年8月，招克伯格第一次发了自己的元宇宙形象。该照片一出，网友直呼“恐怖”，有人表示画质还不如1997年的 PC 游戏。</p><p>&nbsp;</p><p>“我知道我此前发布的照片非常基础，它是为了庆祝上线而拍摄的。Horizon Worlds的画质会更加好，并且改进速度非常快。”扎克伯格说道。但咱就说，首次亮相也别这么“将就”好不～</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/94/946ddc2c818013191d0e4d86185f3a7d.png\" /></p><p></p><p>&nbsp;</p><p>后来的改进版本，但也就好了那么一点。</p><p>&nbsp;</p><p>2022年7月底，Meta 公布了2022年第二季度财报。包括 AR（增强现实）和 VR（虚拟现实）相关硬件、软件和内容在内的元宇宙相关业务 Reality Labs 收入4.52亿美元，为去年二季度以来最近四个季度最低水平，当季亏损28亿美元，第一季度亏损29.6亿美元。自2021年初以来，其负责元宇宙业务的Reality Labs 部门亏损累计近200亿美元(约合1416亿元人民币)。</p><p>&nbsp;</p><p>同年9月，彭博社报道称，由于在元宇宙业务上的投入，扎克伯格2022年身家缩水一半多，达710亿美元（近5000亿元人民币），是彭博亿万富翁指数追踪的超级富豪中缩水最多的。</p><p>&nbsp;</p><p>巨大的亏损也让扎克伯格面临着越来越大的反对声音，甚至其内部员工都看不下去了。不过，他在去年12月辩解称，公司对于元宇宙的押注“不是我们正在做的大部分工作”。</p><p>&nbsp;</p><p>“我们大约80%的投资，还略多一点，投向了核心业务以及与之相关的广告业务，也就是我们所称的应用家族，包括脸书、Instagram、WhatsApp Messenger。然后，不到20%的投资用于Reality Labs。因此，在相当长一段时间内，我们仍要做，并且会继续做的绝大多数事情是朝着社交媒体发展，直到元宇宙规模变得更大。”扎克伯格表示。</p><p>&nbsp;</p><p>“可以辩论一下20%对这个押注来说是不是太多了，但这不是我们正在做的大部分工作。”扎克伯格称。他还对 Reality Labs 的支出进行了分解，其中40%用于VR投资，大约一半用于建立长期项目：“可以在世界上显示全息图像的普通眼镜。”</p><p>&nbsp;</p><p>但值得注意的是，去年11月扎克伯格发布全员信，确认公司将裁员逾11000人，裁员人数约占其员工总数的13%，其中包括Reality Labs。</p><p>&nbsp;</p><p>实际上裁员也有征兆。去年3月，扎克伯格宣布削减部分员工福利，包括取消洗衣、干洗、免费晚餐供应等服务；7月，他预警称公司正在经历“在近期历史上见过的最严重的衰退之一”；10月，他又警告说2023年大多数团队规模将保持不变或缩小。</p><p>&nbsp;</p><p></p><h4>业务越多，越会被“混合双打”</h4><p></p><p>&nbsp;</p><p>2022年的马斯克在“打脸”这件事上可谓是被特斯拉和推特“混合双打”。</p><p>&nbsp;</p><p>一方面，马斯克收购推特的“剧情”就很跌宕，在收与不收之间横跳。</p><p>&nbsp;</p><p>2022年1月，马斯克开始几乎每天分批次购买推特的股票，到了4月份，马斯克已斥资约30亿美元，购入7350万股、占比9.1%的推特股票，成为推特的单一最大股东。</p><p>&nbsp;</p><p>这时推特还是很欢迎马斯克的。推特首席执行官Parag Agrawal邀请了马斯克加入董事会，认为他会为董事会带来巨大价值，当然条件是马斯克的持股不能超过14.9%。但马斯克毫不领情，公开发文称：“推特快死了吗？”，这一举动彻底恶化了马斯克与推特董事会的关系。推特董事会开始反对收购，并称将使用“毒丸计划”等来抵御恶意收购。</p><p>&nbsp;</p><p>但已经进入法律流程的收购并没有因此搁置。4月25日，马斯克与推特董事会达成收购协议。在投资银行摩根士丹利的牵头下，马斯克获得了255亿美元债务和保证金贷款融资。</p><p>&nbsp;</p><p>5月初，马斯克透露改变推特的计划，称将撤销推特对美国前总统唐纳德·特朗普的禁令。但不久，马斯克又要&nbsp;“暂时搁置”收购推特。他声称，推特鼓吹有2.38亿可货币化的日活用户，但实际能真正看到广告的用户数量可能低于6500万。</p><p>&nbsp;</p><p>或是出于不甘愿“被溜”这么久，或是终于可以把“烫手山芋”送出去，这时的推特是不可能让马斯克轻易抽身而去的。7月，推特起诉马斯克，迫使他完成了交易。10月初，马斯克再次表示会收购推特，而推特称要在收到款项后才完成交易。一系列博弈完毕后，马斯克在10月底带着一个“水槽”正式入主推特，这次收购花掉了他440亿美元。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8d/8d27e8e30e14631a677394fc9a84f199.png\" /></p><p></p><p>&nbsp;</p><p>马斯克接手前，推特尽管营收放缓，但还是增长的，也不存在财务危机。但马斯克的杠杆收购平白为其带来了 130 亿美元的巨额债务和每年约 12.9 亿美元的利息成本，这比推特去年赚的还要多。</p><p>&nbsp;</p><p>之后发生的事情大家也知道，裁掉了75%的员工、拖欠房租、拍卖家具、让员工“硬核”且自费卫生纸……关键是，马斯克雄心勃勃地要让推特“言论自由”，为了盈利又急于推出付费认证功能导致推特上骗子横行，因此现在已经有500多家广告商被吓跑了，这让本就不富裕的家庭雪上加霜。</p><p>&nbsp;</p><p>终于在12月，马斯克表示，“一旦找到蠢到可以接任这个工作的人后，我就辞去 CEO 职务！之后，我将负责管理软件和服务器团队。”他发起的“是否继续推特CEO”的投票有1750 万参与，57.5%的人希望他离开。</p><p>&nbsp;</p><p>另一方面，为了堵上买推特欠下的债，马斯克“疯狂”卖特斯拉的股票。据报道，马斯克收购推特融资的首期利息最早或在今年1月底到期。随着日子的临近，马斯克又开始“变卖”特斯拉了。</p><p>&nbsp;</p><p>2022年11月，马斯克卖特斯拉股票换来40亿美元，并承诺“不会再卖特斯拉”。但转眼到了12月，马斯克三天内抛售了特斯拉股票2200 万股，套现 36 亿美元，全年累计抛售了价值 400 亿美元的特斯拉股票。</p><p>&nbsp;</p><p>特斯拉在2021年市值破万亿，当时的马斯克也是激动万分，并对2022年充满信心：交付量的年平均增长率达到50%，今年交付150万辆汽车！但现实的残酷来得如此之快，特斯拉全年交付131万辆，同比增长40%。更为要命的是，特斯拉股价在2022年大跌65%，市值蒸发约6750亿美元，马斯克也成为历史上第一个身价缩水2000亿美元的人。</p><p>&nbsp;</p><p>在交付数据不及预期的同时，特斯拉也发生高层人事变动。特斯拉全球副总裁、大中华区负责人朱晓彤接管北美地区的销售、服务和交付工作。据悉，朱晓彤的新职务与马斯克对推特的收购案存在联系，投资者对马斯克过度投入收购和管理推特不满。</p><p>&nbsp;</p><p>连续15年战胜标普的传奇价值投资者Bill&nbsp;Miller曾表示，由于新能源汽车行业竞争日益激烈，他正在做空特斯拉的股票。“如果股价上涨，我会做空更多股票。”</p><p>&nbsp;</p><p>据报道，特斯拉的订单池从去年7月之后开始下滑，仅五个月时间，特斯拉全球订单池从47.6万辆下滑至16.3万辆，中国市场更是从9月份之后出现了断崖式的下滑。为促进销售，特斯拉也打起了“价格战”。今年1月，特斯拉国产车型大幅降价，Model 3起售价22.99万元，Model Y起售价25.99万元，创下历史最低价格。</p><p>&nbsp;</p><p>而在现在年终冲量的关键时期，特斯拉却宣布上海工厂停产。另外在去年6月，特斯拉还关闭了位于加州圣马特奥的自动驾驶系统部门，并裁减200多个时薪制岗位。</p><p>&nbsp;</p><p>2022年，自动驾驶行业迎来了前所未有的信任危机，特斯拉也面临着各种调查。9月份，有车主对特斯拉提起集体诉讼，称特斯拉“涉嫌在其自动驾驶、增强型自动驾驶和完全自动驾驶（FSD）技术上误导公众”。11月份，美国司法部对特斯拉展开刑事调查，调查目标则是Autopilot的命名与营销方式是否存在夸大成分，以及对其辅助驾驶技术功能是否存在不实表述。2023年1月，特斯拉一名高级工程师的证词显示，特斯拉2016年用于宣传其自动驾驶技术的一段视频是伪造的，为了展示该系统不具备的红灯停车和绿灯加速等功能。</p><p>&nbsp;</p><p>本来想大干一场的特斯拉和马斯克，被现实狠狠打了一巴掌。</p><p>&nbsp;</p><p></p><h4>“绿茶”起来，不要“脸面”</h4><p></p><p>&nbsp;</p><p>11 月 17 日，暴雪中国官方微博发布公告称，随着与网之易公司现有授权协议的到期，自 2023 年 1 月 24 日 0 点起，所有《魔兽世界》《魔兽争霸 III：重制版》《星际争霸》系列，《炉石传说》《风暴英雄》《守望先锋》及《暗黑破坏神 III》国服游戏都将停止运营。《暗黑破坏神：不朽》的联合开发与发行则由两家公司另外的协议所涵盖。</p><p>&nbsp;</p><p>该消息一出，迅速引起了国内玩家不满。“你全家桶我都买了，你就这么对待你的粉丝？”“什么时候有集体诉讼记得拍我一下”“退钱！！”两天后才开放评论区的暴雪中国微博下都是愤懑不满的声音。</p><p>&nbsp;</p><p>很快，丁磊在网易 2022 年第三季度财报电话会上也做了回应称，网易非常希望继续代理暴雪游戏，并为此付出了非常多的努力。但过去一段时间，整个谈判过程难度其实远超出了网易方面的预期。对于一些涉及可持续运营、中国市场及玩家核心利益的关键性合作条款，动视暴雪的要求是不可接受的。对于中国玩家，网易会尽全力做好善后工作，为玩家服务到最后一刻，保障玩家的消费者权益和信息安全。</p><p>&nbsp;</p><p>有知情人士表示，双方合作终止的主要原因是价格未能谈妥。这位人士透露，暴雪方分成较 2019-2022 合约期 50% 以上营收和净利润进一步提高，且暴雪游戏定价将采取全球同步策略，而此前国服定价较全球其他地区普遍低约 20%。暴雪还要求网易按照《暗黑破坏神：不朽》模式，研发暴雪其他 IP 手游全球发行，但网易只享有中国区市场营收分成。同时，暴雪还要求网易缴纳巨额保证金或预付费用来担保第 2 条的完成，否则将被“处罚”。知情人士坦言，若该续约条件属实，暴雪无异于在要求网易“打白工”。</p><p>&nbsp;</p><p>另外据彭博社的报道，有知情人士透露，除了财务条款之外，暴雪与网易终止合作的关键症结还在于，“知识产权的所有权”和“对中国各地数百万玩家数据的控制”。</p><p>&nbsp;</p><p>网易游戏全球投资及合作总裁朱原在领英上发文称，“当一切都尘埃落定、内幕被揭开之时，开发者和玩家们将对 ‘一个傻瓜能造成多大的伤害’ 产生全新级别的认知。”</p><p>&nbsp;</p><p>如果事情到此结束，这就只是一个合作破裂的新闻，也没什么“打脸”一说。但偏偏在今年1月17日，暴雪中国微博突然发布公告说，曾向网易寻求协助，希望能将合约顺延六个月，但遭到拒绝，因此暴雪将遵照停服公告，于1月23日中止国服游戏服务。</p><p>&nbsp;</p><p>有网友翻译了下暴雪的意思：我们虽然分手了，但是我还没找到下家，再凑合半年，等我找到下家再把你踹了。</p><p>&nbsp;</p><p>本想“卖惨”的暴雪再次收获了一片骂声。“我还以为是接盘侠谈好了发文，结果是：主动提离婚后，让前任继续服侍我6个月，人家不干我写小作文挂他，这咋好意思写得出来的。”网友评价道。“看到大家都在骂暴雪，我也就放心了。”</p><p>&nbsp;</p><p>网易这次也是直接刚回去了，晚上就在官微发布声明称，“我方认为，暴雪的这种提议——包括今天突发的声明——是蛮横的、不得体的且不符合商业逻辑的。其过分的自信中并未考虑这种予取予求、骑驴找马、离婚不离身的行为，将玩家和网易置于了何地。”</p><p>&nbsp;</p><p>据悉，基于此前“分手”消息，目前网易暴雪团队的大部分员工已被解雇或重新分配，该团队此前有不到100人规模，大部分为运营人员。该子公司最终将保留了10人规格的骨干团队，在交易到期后处理客户服务以及技术问题，持续时间为6个月。</p><p>&nbsp;</p><p>网易人也是懂“内涵”的。据悉，当天的网易咖啡厅推出了“暴雪绿茶”，订价13，很快便售罄了。此外，根据网友放出的图片，网易食堂还推出了“暴雪绿茶油菜”、“暴雪绿茶小趴菜”和“暴雪绿茶盖菜”。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6c/6cf16788239f90e1e85ccb122c80f24f.png\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>而关于“网易想要IP控制权”的传闻，网易也做了回应，“作为代理公司，网易从未寻求暴雪游戏或其他合作伙伴的IP控制权，在过去十四年的长期合作过程中，网易对任何暴雪IP的使用和授权都是按照合同条款，并取得了暴雪的同意和审批。与其他合作伙伴的IP合作也都是基于此原则。”</p><p>&nbsp;</p><p></p><h4>一味追求风口，总会被现实打脸</h4><p></p><p>&nbsp;</p><p>2022年，NFT数字藏品终于冲出区块链圈子，闯进了“艺术圈”和“科技圈”。周杰伦旗下潮牌「PHANTACi」和Ezek平台联名推出首款NFT「Phanta Bear」，全球限量仅1万个，开卖即秒杀，瞬间进账1000万美元。</p><p>&nbsp;</p><p>NFT数字藏品的价值如何评定？人的意识。只要有足够多的人认为某个数字藏品值那个价格，它就值得那个价格。比如。年初一位日本女优通过NFT平台出售自己的数字化作品，轻松获得数十个ETH（当时ETH单个价值最高可达3000美元）。</p><p>&nbsp;</p><p>随着 NFT 热度不断上涨，国内不少公司都在尝试进入这个市场，其中包括腾讯。2021年，腾讯推出了NFT交易软件幻核，隶属于腾讯PCG，为该部门的创新业务。不过需要说明的是，我国数字藏品与海外NFT有本质区别，最主要的就是弱化了NFT的金融属性。</p><p>&nbsp;</p><p>2022年5月，原腾讯新闻负责人王诗沐调任PCG社交平台与应用线，负责幻核等业务。不过，幻核也成为国内第一家倒下去的数藏平台。</p><p>&nbsp;</p><p>8月16日上午，幻核发布公告称，自当日起，幻核将停止数字藏品发行，所有通过其平台购买数字藏品的用户，皆可自行选择继续持有或发起退款申请。波场创始人孙宇晨还在推特高调发声“蹭热度”，希望收购幻核。</p><p>&nbsp;</p><p>关停早有预兆。7月份时候就有媒体报道，腾讯正计划裁撤幻核业务，该消息已传达至幻核方面工作人员。随后，腾讯回应称，运营一切照旧，正筹备App新版本，因此新藏品发售将延后。同月，腾讯新闻App宣布关闭数字藏品售卖服务。</p><p>&nbsp;</p><p>据报道，幻核自成立以来的销售额已超过 8000 万元，其中 2022 年 4 月的月度销售额近 2000 万元。虽然有人认为“幻核”的退场还算体面，不过其退款承诺至今还没有兑现。有网友戏称，“这是下一个小黄车”。</p><p>&nbsp;</p><p>实际上，幻核只是腾讯众多关停业务的其中之一。去年12月，马化腾在内部大会上重点批评了幻核所在PCG业务板块。他表示，过去由于友商带跑，腾讯盲目去做简单的跟随，结果被带偏方向，做出来的东西效果也是不尽如人意，“看到别人增重，我们就跟着增，结果发现增的是脂肪，打不过对手”。</p><p>&nbsp;</p><p>“你活都活不下去，要靠别人续命，（结果）周末还能休闲地去打球”，马化腾说道，“如果你连创业压力都没有的话，那这个压力我们上面给，好吧。”他表示如果不能自己自负盈亏，那留给这些业务的时间也就不多了。</p><p>&nbsp;</p><p>据悉，腾讯今年至少关停及下架 App 应用 16 款，包括幻核、QQ 影音、看点快报、搜狗地图、腾讯 WiFi 管家等一众知名产品。倘若再加上 29 款被裁撤的游戏，则至少关停了 45 个项目。</p><p>&nbsp;</p><p>纵使“站在风口上，猪都能飞起来”，但当各种“黑天鹅”来临，这场风能否继续吹就未可知了。</p><p>&nbsp;</p><p></p><h4>汽车圈的“贾跃亭”</h4><p></p><p>&nbsp;</p><p>一度自称“汽车界小米学徒”的奇点汽车，整整八年，没量产出一辆车。</p><p>&nbsp;</p><p>奇点汽车成立于2014年，造车新势力开始萌芽的一年。创始人沈海寅曾就职于360公司，在自己的造车梦遭到周鸿祎反对后，毅然从360离职创业。</p><p>&nbsp;</p><p>靠着一堆PPT合概念，沈海寅给投资人画了好大的一张饼，也凭此先后拿到了超过170亿的融资。他曾公开表示，造车是男人的终极梦想，马斯克是自己的偶像，小米模式是他的方法论。他要用互联网思维造一辆性能超越特斯拉，价格低于特斯拉的车。&nbsp;&nbsp;</p><p>&nbsp;</p><p>不过，这么多年过去了，我们始终没有看到一辆车。给投资人画饼的三座生产基地，更是哪个都没有建成。</p><p>&nbsp;</p><p>2022年12月，安徽奇点智能<a href=\"https://nev.ofweek.com/\">新能源汽车</a>\"有限公司被铜陵市铜官区人民法院强制执行325万元，公司累计被执行金额已经超686万元。近日，奇点汽车关联公司智车优行科技（北京）有限公司新增一则被执行人信息，执行标的477万，关联案件为阿尔特汽车股份有限公司与该公司承揽合同纠纷。</p><p>&nbsp;</p><p>2022年7月份，奇点汽车被爆拖欠员工工资，并且时间最长的已经有1年半，执行仲裁的员工有150多人。为追回欠款，帝维汽车工程技术(上海)有限公司直接向法院申请奇点汽车北京分公司强制破产重组。</p><p>&nbsp;</p><p>与此同时，去年6月底，北京法院审判信息网公布一份民事判决书，判令奇点汽车支付原告中汽研一笔64.9万的测试开发费用。与奇点汽车这些年获得的170亿元融资来说，64.9万只是凤毛麟角，但却从2020年8月拖到了现在。</p><p>&nbsp;</p><p>数据显示，当前智车优行的相关法律诉讼已经高达27起，关联风险172处，董事长沈海寅处于限制高消费的状态当中。</p><p>&nbsp;</p><p>面对供应商与讨薪员工们的怒火，奇点汽车仍嘴硬地表示会“在本轮融到资后第一时间支付完成”补偿，但估计早没人信了。所以，奇点，你们的170亿到底花哪里了？</p>",
    "publish_time": "2023-01-30 09:41:15",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "盘点2022年最会“搞钱”的十家AI公司",
    "url": "https://www.infoq.cn/article/U2caWQbsUQKDVbpluHzu",
    "summary": "<p></p><blockquote>“寒冬”之下，“搞钱”才是硬道理。</blockquote><p></p><p></p><p>2022 年，<a href=\"https://www.infoq.cn/article/rggHjzaBfCVPV5hxTF7H\">AIGC</a>\"（Artificial Intelligence Generated Content，人工智能生成内容）概念的火爆出圈让 AI 领域显得格外热闹。</p><p></p><p>8 月 22 日，AI 界的“神笔马良”、绘画神器 Stable Diffusion 横空出世，用户随意输入自己想要的文字描述，就能得到相应的图像结果；12 月，OpenAI 发布了一个全新的聊天机器人模型 ChatGPT，它能写小说、写代码、写论文……就像是一个无所不知的虚拟体，能回答各种问题，而且总能给到让人满意，甚至超过预期的答案。</p><p></p><p>2022 年，自动驾驶热度依旧，但资本不再冒进，更聚焦在商业场景确定性高的自动驾驶项目上；2022 年，全球智能语音产业规模达 351.2 亿美元，保持 33.1% 的高速增长，我国智能语音市场达 341 亿元，同比增长 13.4%……</p><p></p><p>2022 年，多重因素使然，国内 AI 赛道融资情况并不乐观。IT 桔子数据显示，2021 年国内 AI 领域风险融资事件数达到 832 起，而 2022 年仅有 400 起（数据截止到 2022 年 11 月 10 日），与上一年年同期相比下降 50%。融资金额规模也经历“腰斩”，2021 年国内 AI 行业总体融资交易额达到 2187.9 亿元，而 2022 年只有 770.4 亿元（数据截止到 2022 年 11 月 10 日），与去年同期相比下降 61%。</p><p></p><p>但与此同时，据 IT 桔子数据统计，截止到 2022 年 11 月 10 日，国内还是有 24 家 AI 公司获得 1 亿美元以上融资。这也说明，资本市场对 AI 赛道仍然抱有热情。</p><p></p><h2>2022 年，国内斩获巨额融资的10 家 AI 公司</h2><p></p><p></p><p>InfoQ 根据公开数据梳理出了 2022 年国内斩获巨额融资的 10 家 AI 公司。数据显示，这 10 家 AI 公司在 2022 年总计融资超 140 亿元人民币。</p><p></p><h4>黑芝麻智能：募资总规模超 5 亿美元，传考虑赴香港 IPO 上市</h4><p></p><p></p><p>2022 年 8 月 8 日，全球自动驾驶计算芯片企业黑芝麻智能宣布完成由武岳峰科创领投的 C+ 轮融资，兴业银行集团、广发信德、汉能基金、北拓一诺资本、新鼎资本、之路资本、扬子江基金等机构跟投。至此，黑芝麻智能完成 C 轮和 C+ 轮全部融资，募资总规模超 5 亿美元。</p><p></p><p>根据黑芝麻智能官网显示，公司于 2016 年成立，是行业领先的车规级自动驾驶计算芯片各平台研发企业，专注于大算力芯片与平台等技术领域的高科技研发。黑艺麻智能能够提供完整的自动驾驶、车路协同解决方案包括基于车规级设计、学习型图像处理、低功耗精准感知的自动驾驶感知计算芯片和自动驾驶计算平台，支撑自动驾驶产业链相关产品方案的快速产业化落地。公司的核心产品包括华山系列自动驾驶芯片、瀚海 ADSP(Autonomous Driving Solution Platform) 自动驾驶中间件平台。</p><p></p><p>据彭博社 2023 年 1 月报道，黑芝麻智能考虑进行香港 IPO，募资规模可能约为 2 亿美元。消息指出，黑芝麻智能与中金公司以及华泰国际就股票发行的准备工作进行合作，预计最快首季度递交初步招股书，IPO 最早可能在今年下半年进行，融资金额和银行参与情况等细节可能仍会有变。报道称中金和华泰国际的代表不予置评，黑芝麻智能的代表没有回复置评。</p><p></p><h4>文远知行：融资 4 亿美元，投后估值达 44 亿美元，沈向洋是其早期投资人</h4><p></p><p></p><p>2022 年 3 月，L4 级别自动驾驶公司<a href=\"https://www.infoq.cn/article/ZVygOmjY9wtk866Ligz7\">文远知行</a>\"宣布完成新一轮超 4 亿美元融资，投后估值达 44 亿美元。此轮投资方包括广汽集团、博世、中阿产业投资基金、凯雷投资集团。除广汽集团外，其余投资方均为文远知行的新股东。</p><p></p><p>据悉，文远知行前身为景驰科技，公司成立于 2017 年，创始人是“自动驾驶第一人”王劲，前微软全球执行副总裁、知名 AI 大牛沈向洋曾是公司早期投资人。公开资料显示，文远知行总部位于广州，在中国北京、上海、深圳、郑州、南京、武汉、安庆、圣何塞设立分部，团队规模超过 800 人。文远知行聚焦与车企、平台方的铁三角战略合作，形成无人驾驶出租车（Robotaxi）、小巴（Mini Robobus）和同城货运车（Robovan）三大产品矩阵。</p><p></p><h4>镁伽科技：融资 3 亿美元，用智能自动化解决生命科学行业痛点</h4><p></p><p></p><p>2022 年 6 月 15 日，镁伽科技宣布完成 3 亿美元 C 轮融资。自 2016 年成立至今，镁伽为生命科学行业提供了一整套自动化解决方案，从简单的操作台工作流程自动化，到大型系统流程应用中处理复杂步骤的全自动解决方案，并延伸至赋能 AI 药物研发服务的下一代生命科学基础设施和系统。</p><p></p><p>公开信息显示，镁伽科技成立于 2016 年，公司专注于机器人和人工智能技术的研发并将其深度融合于行业应用，为客户提供先进的智能自动化产品与解决方案。同时结合自主研发的通用型智能生物实验室——镁伽鲲鹏实验室的科研能力，赋能新药研发、细胞基因治疗、类器官以及合成生物学等领域的智能自动化变革。此外，镁伽还是半导体领域制造和测试装备的创新者，拥有众多成熟可靠的产品和解决方案。</p><p></p><p>据介绍，镁伽拥有近千名跨领域的人才团队，研发人员占比 60%，累计申请专利超过 300 项。中国总部位于苏州，国际总部位于新加坡，同时在美国、英国、日本设有研发中心，在中国北京、上海及深圳设有分支机构。</p><p></p><h4>小马智行：融资数亿美元，估值达 85 亿美元</h4><p></p><p></p><p>2022 年 3 月 7 日，自动驾驶公司<a href=\"https://www.infoq.cn/article/6CKT512SXPfvcyfXRsrX\">小马智行</a>\"（Pony.ai）宣布完成 D 轮融资的首次交割，整体估值达 85 亿美元。本轮估值较上轮融资提升约 65%，同时公司现金流达到近 10 亿美元。</p><p></p><p>公开信息显示，小马智行成立于 2016 年底，由彭军和楼天城共同创立，是全球首家在中美均推出自动驾驶出行服务（Robotaxi）的公司，总部位于广州。</p><p></p><p>本轮融资资金将用于团队扩充、技术研发、Robotaxi 及自动驾驶卡车（Robotruck）车队规模扩大及全球测试与运营、自动驾驶技术量产以及商业化部署等业务领域，从而推动乘用车和商用车领域的自动驾驶商业化进程和量产化落地。</p><p></p><h4>赢彻科技：融资 1.88 亿美元，L3 级别自动驾驶卡车量产落地</h4><p></p><p></p><p>2022 年 2 月，自动驾驶卡车技术与运营公司<a href=\"https://www.infoq.cn/article/x*TO9sqkiEFia1VwVBam\">嬴彻科技</a>\"已完成 1.88 亿美元的 B+ 轮股权融资。此轮融资由红杉中国、君联资本联合领投，跟投方包括周大福企业有限公司、沄柏资本以及智慧供应链及供应链金融企业 - 物产中大集团产业投资，现有股东美团、蔚来资本、斯道资本、博华资本等跟投。</p><p></p><p>与融资消息一同透露的是，嬴彻科技已联合主机厂伙伴在 2021 年底实现 L3 级别自动驾驶卡车的前装量产，并与多家行业头部货主在多条线路上开展常态化的商业运营。</p><p></p><p>公开信息显示，嬴彻科技成立于 2018 年，业务聚焦于干线物流场景，坚持“全栈自研 + 量产驱动 + 深度运营”的核心策略，自主研发全栈 L3 和 L4 级自动驾驶技术，和汽车产业紧密合作，为物流客户提供更安全、更高效的自动驾驶技术和新一代 TaaS (Transportation-as-a-Service) 货运网络。</p><p></p><h4>剂泰医药：融资 1.5 亿美元，专注 AI 制药</h4><p></p><p></p><p>2022 年 4 月 6 日，专注于 AI 药物及递送系统开发的剂泰医药（METiS Pharmaceuticals 正式宣布连续完成两轮融资，融资金额共计 1.5 亿美元。两轮融资由人保资本、国寿股权领投，红杉中国、五源资本、招银国际、光速中国、Monolith、峰瑞资本等新老股东跟投，华兴资本担任独家财务顾问。</p><p></p><p>剂泰医药是由麻省理工 (MIT) 的顶尖科学家创建, 并由深圳晶泰科技孵化，公司聚焦于药物递送、制剂研发赛道，是全球首个 AI 驱动的药物制剂开发初创公司。</p><p></p><p>技术团队由美国工程学院院士陈红敏顾问牵头, 结合 MIT 人工智能实验室专家, 打造具临床差异化的制剂新药。药物开发团队及顾问委员会具有诺华、J&amp;J 和赛诺菲等顶尖药企的新药开发经历, 具备丰富的经验将新药从实验室带到临床, 并通过 FDA 获批上市。</p><p></p><p>公司的核心平台为 AiTEM，切入临床前的制剂优化等环节，能够高通量药物递送制剂，生成处方及工艺大数据，以及分子模拟及人工智能模型预测药物物理及动力学性质。</p><p></p><h4>Rokid：一年融资 4 轮超 13 亿元，全球首家品牌旗舰店落地杭州</h4><p></p><p></p><p>2022 年，AR 智能眼镜品牌 Rokid 完成了 4 轮融资，融资总金额超 13 亿元。其中 9 月、11 月连续获得投资 3 次，投资方包括复星集团、网龙网络、睿成投资等等。</p><p></p><p>公开资料显示，Rokid 是一家专注于人机交互技术的产品平台公司。Rokid 作为行业的探索者、领跑者，目前致力于 AR 眼镜等软硬件产品的研发及以 YodaOS 操作系统为载体的生态构建。</p><p></p><p>2022 年 12 月，Rokid 全球首家品牌旗舰店正式落地杭州有“全国数字生活第一街区”之称的文三数字生活街区。该旗舰店集品牌展示、产品体验、互动交流等功能于一体，将展示 Rokid 最新系列 AR 产品，为消费者提供沉浸式场景化的产品体验空间。</p><p></p><h4>所托瑞安：融资超 13 亿元，跻身智能驾驶行业独角兽序列。</h4><p></p><p></p><p>2022 年 3 月 28 日，所托瑞安宣布完成超 13 亿人民币的 B 轮融资。本轮融资由中国领先的私募股权投资机构平安资本战略领投、所托瑞安 A 轮股东 SK 中国继续追加投资，嘉实、河南投资集团等机构跟投。</p><p></p><p>所托瑞安被认为是中国商用车“渐进式”智能驾驶的践行者，此前已获得招商银行和招银租赁高达 20 亿元的授信金额。本次融资完成后，所托瑞安的估值已接近百亿人民币规模，顺利跻身智能驾驶行业的独角兽序列。</p><p></p><h4>小冰：融资 10 亿元，将启动数字员工产品线技术升级</h4><p></p><p></p><p>2022 年 11 月 7 日，<a href=\"https://www.infoq.cn/article/mYaQiUC4C4al61Z2wO1T\">小冰公司</a>\"宣布，近日已完成总额 10 亿元新融资，将用于加速 AI Being 小冰框架技术研发，推动数字员工普及，并对旗下人工智能数字员工（AI Being Employee）产品线启动年度升级。</p><p></p><p>小冰公司前身为微软人工智能小冰团队，2020 年分拆为独立技术研发实体，实现完全本土化。小冰框架是全球实际落地及完备度最高的 AI Being 基础框架，覆盖中国、日本、印度尼西亚等国 6.6 亿在线用户、10 亿台第三方智能设备和 9 亿内容观众，商业客户覆盖全球，其中在智能车机领域渗透率超过 60%，在 AIGC 领域的商业化成果也已广泛应用于金融、文化、纺织、旅游等垂直领域。</p><p></p><h4>纵目科技：融资 10 亿元，拟在科创板上市</h4><p></p><p></p><p>2022 年 3 月 28 日，纵目科技宣布完成超过 10 亿元人民币的 E 轮融资，由东阳冠定领投，远海基金、临芯资本、佐誉资本、复朴资本、青岛元盈、泰有资本及老股东湖州环太湖集团和创徒投资跟投。</p><p></p><p>公开信息显示，纵目科技成立于 2013 年，总部位于上海张江国际科创中心，在上海、北京、厦门、深圳、重庆、美国密西根 Novi 市以及德国斯图加特都设有研发中心，生产制造中心位于厦门、湖州、东阳（在建）。纵目科技是自动驾驶（Autonomous Driving）和高级汽车辅助驾驶（Advanced Driving Assistance System）产品及技术供应商，拥有领先的算法能力、完整的系统设计能力和车规级别的生产制造能力。目前，公司已经形成了从基础研发到量产应用的完整产业链，当前核心业务涵盖智能驾驶系统、智能传感器和智慧城市产品及服务三大部分。</p><p></p><p>最新消息显示，纵目科技拟在科创板上市，申请已于 2022 年 11 月 23 日获受理。</p>",
    "publish_time": "2023-01-30 10:18:30",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "科学家被ChatGPT骗了",
    "url": "https://www.infoq.cn/article/U5xfFfPULVbkDSLR3PAQ",
    "summary": "<p></p><blockquote>根据最新研究，学者们可能会被 <a href=\"https://www.infoq.cn/article/FRcz5vjOvl3bM2d57opX\">ChatGPT</a>\" 所欺骗，他们误以为 ChatGPT 生成的虚假科学摘要来自顶级研究期刊上发表的真实医学论文。</blockquote><p></p><p></p><p>本文最初发布于 The Register。</p><p></p><h2>学者难以识别人工智能生成的假论文摘要</h2><p></p><p></p><p>近日，美国西北大学领导的一个研究小组使用 <a href=\"https://www.infoq.cn/article/ZWixRo76hFsOw38tRHNF\">OpenAI</a>\" 开发的文本生成工具，基于一篇真实科学论文的标题，采用五种不同的医学期刊风格生成了 50 篇摘要。</p><p></p><p>4 名学者参加了一项测试，他们被分为两组，每组两人。测试通过电子抛硬币的方式来决定将人工智能生成的摘要交给每组中的哪一名审核员。如果一名研究人员拿到的是真摘要，那么另一名研究人员拿到的就是假摘要，反之亦然。每个人都审阅了 25 篇科学摘要。</p><p></p><p>审核员能够识别出 68% 由人工智能生成的假摘要，和 86% 来自真实论文的原始摘要。换句话说，他们被成功欺骗，将 32% 的人工智能生成的摘要识别为真摘要，将 14% 的真摘要识别为假摘要。</p><p></p><p>该研究的第一作者、西北大学专攻肺病学的医生和科学家 Catherine Gao 说，这表明 ChatGPT 相当有说服力。她在一份声明中写道，“我们的审核员知道他们收到的部分摘要是假的，所以他们非常警惕”。</p><p></p><p>“事实上，我们的审核员还是在 32% 的时间里漏掉了人工智能生成的摘要，这表明这些摘要真的很好。我估计，如果有人偶然看到了其中一份生成的摘要，那么他们不一定能识别出那是由人工智能写的。”</p><p></p><h2>大型语言模型生成的文本为什么能骗倒众人？</h2><p></p><p></p><p>像 ChatGPT 这样的<a href=\"https://www.infoq.cn/article/AWWsrfb54zTvglZ0I5qS\">大型语言模型</a>\"使用从互联网上抓取的大量文本进行训练。经过学习后，它们会通过预测在给定的句子中哪些词更有可能出现来生成文本，而且生成的文本语法准确。这并不奇怪，即使是学者也会上当受骗，相信人工智能生成的摘要是真的。</p><p></p><p>大型语言模型擅长生成具有清晰结构和模式的文本，科学摘要通常采用类似的格式，而且可能相当模糊。</p><p></p><p>Gao 说：“我们的审核员评论说，区分真假摘要非常困难。ChatGPT 生成的摘要非常有说服力……当编造数值时，它甚至知道患者群体应该有多大。”例如，一篇关于高血压的假摘要描述了一项有数万名参与者的研究，而一篇关于猴痘的研究涉及的患者则较少。</p><p></p><p>Gao 认为，像 ChatGPT 这样的工具将使靠出版研究成果获利的造纸厂更容易炮制虚假科学论文。她补充说，“如果其他人试图以这些不正确的研究为基础进行科学研究，那可能真的很危险”。</p><p></p><p>不过，使用这些工具也有好处。这项研究的合作者、芝加哥大学医学副教授 Alexander Pearson 说，它们可以帮助母语非英语的科学家更好地写作和分享他们的工作。</p><p></p><p>人工智能比人类更擅长检测机器文本。例如，免费的 GPT-2 输出检测器能够以超过 50% 的置信区间从 50 篇由语言模型生成的论文中猜出 33 篇。研究人员认为，提交的论文应该通过这些探测器的检测，科学家应该公开使用这些工具。</p><p></p><p>Gao 告诉 The Register，“我们在撰写自己的摘要或手稿时没有使用 ChatGPT，因为这是否可接受在学术界还没有清晰的边界。例如，国际机器学习大会已经制定了一项政策，禁止使用它，不过他们承认，讨论仍在继续，并澄清说，在‘编辑或打磨’时使用是可以的。”</p><p></p><p>不过，已经有一些团体开始使用它来辅助写作，有些人还把它列为合著者。我认为，使用 ChatGPT 来辅助写作是可以的，重要的是，这样做的时候要明确标示 ChatGPT 辅助编写的那部分手稿。我们将来使用或不使用 LLM 来辅助撰写论文，取决于科学界最终达成的共识。”</p><p></p><p>原文链接：</p><p></p><p><a href=\"https://www.theregister.com/2023/01/11/scientists_chatgpt_papers/\">https://www.theregister.com/2023/01/11/scientists_chatgpt_papers/</a>\"</p>",
    "publish_time": "2023-01-30 12:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "长江存储被曝大裁员，员工购买福利房或遭索赔最高百万！网友：被裁后公司待你如垃圾，心都碎了！",
    "url": "https://www.infoq.cn/article/6CjBjAYJfNDRWbm9Vfbv",
    "summary": "<p></p><blockquote>长江存储这波裁员操作，在网上引发了轩然大波。</blockquote><p></p><p>&nbsp;</p><p>1月29日消息，据业内人士爆料，国内知名的半导体大厂长江存储1月开始大量裁员了。且由于福利房价格问题，部分员工或面临高额房屋差价赔偿。</p><p>&nbsp;</p><p>长江存储科技有限公司成立于2016年7月，总部位于武汉，由紫光集团、中国国家集成电路产业投资基金、湖北省集成电路产业投资基金、湖北科投在武汉新芯的基础上组建成立。据估计，长江存储目前是世界第六大NAND闪存制造商，排名在三星、<a href=\"https://www.infoq.cn/article/7gWZcTyHG4VPE3OyXVJC\">SK海力士</a>\"、铠侠、西部数据和美光(Micron)之后。</p><p></p><h2>员工爆料长江存储大裁员，公司要求赔偿福利房差价</h2><p></p><p>&nbsp;</p><p>近日，一名自称在<a href=\"https://www.infoq.cn/article/AIQbE0ABKAhuoeeWuAsw\">长江存储</a>\"干了四年多，并且买了员工福利房的网友在知乎平台爆料，1月16日接到裁员通知，并要求过年收假后上班第一天开始一个月内完成交接走人。同时，其还被要求支付职工福利费所购住房的差价，估计要支付几十万到上百万的违约金。</p><p>&nbsp;</p><p>据悉，长江存储有福利房，员工买房签了绑定协议，要求在公司干满五年，不然赔偿当初市场调查价（一万四千多一平）和给员工优惠的价格的差价，按户型面积绑定50万至100万不等，且协议没有写明公司主动裁员是否赔偿的事宜。</p><p>&nbsp;</p><p>有员工表示，<a href=\"https://www.infoq.cn/article/AIQbE0ABKAhuoeeWuAsw\">长江存储</a>\"国际社区所在的地段，有三个商品房小区的价格可以参考。世茂十里星河是地段最好的正地铁房，实际成交价在1.1万元左右；硅谷小镇毛坯房是地段第二好的，成交价大约在1万元上下，还送车位；中海光谷东麓的精装修房成交价约为1.2万元。按照内部员工的说法，长江存储的绑定价定到了1.45万元左右，卖给员工是9000元左右，如果员工被裁员就得赔偿给公司每平5500元左右。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/80/8047f12c7c38ce55cd1e81b356afafee.png\" /></p><p></p><p>&nbsp;也有在职的长江存储员工表示，长江存褚自被列入实体清单后，公司发展遇到了困境，要裁员也能理解，但公司的一些做法让人很难接受。</p><p>&nbsp;</p><p>该名员工称，“公司目前在走绩效低分路子，绩效低分、年终奖不发，公司走和员工协商离职的路线，这样公司就不是裁员或者辞退员工了，是员工自愿拿赔偿离职，也就是所谓的‘协商离职’。如果买房的员工接受了公司协商离职，那么以后公司可以宣称你是主动离职的，不是公司主动裁员、辞退的。 在房子绑定协议赔偿金掰扯的时候，员工将失去了公司主动辞退的证据，将必赔公司房子钱。然而公司HR和领导都在对员工威逼利诱，想着法子骗员工想让员工接受拿赔偿协商离职路子，把员工往火坑里推。”</p><p></p><h2>网友评论：被裁后公司待你如垃圾，心都碎了！</h2><p></p><p>&nbsp;</p><p>关于被裁掉员工的公司福利房的事情，员工寻问了长存科服的负责人，回复是只有未装修的可以退，只要装修了，必须赔几十万到上百万不等的违约金，而且三年内赔完，否则法院见。</p><p>&nbsp;</p><p>对于长江存储的此等做法，匿名网友在知乎平台吐槽称，“企业效益不好时裁员很正常，但是对于明明是公司违约还要员工赔钱，如此霸王条款是不是太过分了？”</p><p>&nbsp;</p><p></p><blockquote>长存的员工房位置偏，定价高，就算拿在手里也卖不出去，如果没有为半导体奉献终身的理想，谁愿意买这房啊？对于刚工作的员工来说，把挣的工资再掏空家里的钱，都放到了房子里，天天加班到深夜，结果被裁了，公司把你当垃圾一样对待，心都碎了！</blockquote><p></p><p>&nbsp;</p><p>不过也有被裁员工表示，从长存离开不是一件坏事，很多人在外面发展都挺好。被裁员不是自己的能力问题，毕竟面试能通过的人，能在里面高薪工作的人，学历和能力都不差。企业被制裁经营不佳，大环境下行，要裁员，这是没有办法的。但是也希望公司能办得体面一些，拿出自己的担当，善待应届生和老员工，好聚好散。</p><p></p><h2>武汉第二家工厂建设计划或将推迟</h2><p></p><p>&nbsp;</p><p>长江存储此番大规模裁员，是公司经营状况不佳的缩影。据集微网消息，由于采购<a href=\"https://www.infoq.cn/article/z9DfpZCh0femWpQ6awVp\">供应链</a>\"中断，长江存储可能推迟在武汉的第二家晶圆厂的建设。</p><p>&nbsp;</p><p>据南华早报报道，清华大学集成电路学院教授魏少军上周在论坛上赞扬了长江存储的技术创新，但警告说，在美国对向中国出口尖端半导体技术实施制裁后，中国需要将重点转移到成熟的技术开发上。</p><p>&nbsp;</p><p>外国芯片专家表示，长江存储实现技术进步和批量生产的能力将受到其无法免费获得美国芯片制造工具和服务的阻碍。</p><p>&nbsp;</p><p>研究机构<a href=\"https://www.infoq.cn/article/yfk3blm256QT7GJHCs1v\">TrendForce</a>\"也在一份研究报告中指出，如果没有关键设备供应商的支持，长江存储现在在其最新的3D NAND闪存技术Xtacking 3.0的开发中面临着巨大的技术障碍。尤其是提高128层和232层工艺的良率对中国内存制造商来说将极具挑战性。</p><p>&nbsp;</p><p>另一位行业专家、华为前技术人员称，长江存储并不缺乏光刻系统，因为它在实施限制之前已购买数台光刻系统，但挑战在于泛林集团等供应商的蚀刻工具。这些工具对于复杂的3D NAND晶圆制造工艺至关重要。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.zhihu.com/question/579189179\">https://www.zhihu.com/question/579189179</a>\"</p><p><a href=\"https://www.163.com/dy/article/HS8FVSCJ0511DT6P.html?f=post1603_tab_news\">https://www.163.com/dy/article/HS8FVSCJ0511DT6P.html?f=post1603_tab_news</a>\"</p>",
    "publish_time": "2023-01-30 14:20:17",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "我用 Rust 改写了自己的C++项目：这两个语言都很折磨人！",
    "url": "https://www.infoq.cn/article/gWoHTU1gilTd2jRvrSqf",
    "summary": "<p></p><p></p><blockquote>C++漫长的构建时间可谓臭名昭著，编程圈的“我的代码在编译”只是个段子，但C++让这个段子长盛不衰。</blockquote><p></p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f6/f6855b212d651b2541cd86e41fe43613.png\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>谷歌Chromium规模的项目在新硬件上的构建时间<a href=\"https://textslashplain.com/2020/02/02/my-new-chromium-build-pc/\">长达一小时</a>\"，而在老硬件上的构建时间更是<a href=\"https://randomascii.wordpress.com/2020/03/30/big-project-build-times-chromium/\">达到了六个小时</a>\"。虽然也有海量的<a href=\"https://chromium.googlesource.com/chromium/src/+/HEAD/docs/windows_build_instructions.md#Faster-builds\">调整方案</a>\"能加速构建速度，还有不少削减构建内容但<a href=\"https://chromium.googlesource.com/playground/chromium-org-site/+/refs/heads/main/chromium-os/build/improving-build-times.md\">极易出错的捷径</a>\"供人选择，再加上数千美元的云计算能力，Chromium的构建时间仍是接近十分钟。这点我完全无法接受，人们每天都是怎么干活的啊？</p><p>&nbsp;</p><p>有人说Rust也是一样，构建时间同样令人头疼。但事实就是如此，还是这仅仅是一种反Rust的宣传手段？在构建时间方面Rust和C++究竟谁能更胜一筹呢？</p><p>&nbsp;</p><p>构建速度和运行时性能对我来说非常重要。构建测试的周期越短，我编程就越高效、越快乐。我会不遗余力地让我的软件速度更快，让我的客户也越快乐。因此，我决定亲自试试Rust的构建速度到底怎么样，计划如下：</p><p>&nbsp;</p><p>找一个C++项目把项目中的一部分单独拿出来逐行将C++代码重写为Rust优化C++和Rust项目的构建对比两个项目的构建测试时间</p><p>&nbsp;</p><p>我的猜想如下（有理有据的猜测，但不是结论）：</p><p>&nbsp;</p><p>Rust的代码行数比C++少。C++中多数函数和方法都需要声明两次：一次在header里，一次在实现文件里。但Rust不需要，因此代码行数会更少C++的完整构建时间比Rust长（Rust更胜一筹）。在每个.cpp文件里，都需要重新编译一次C++的#include&nbsp;功能和模板，虽然都是并行运行，但并行不等于完美。Rust的增量构建时间比C++长（C++更胜一筹）。Rust一个crate（独立可编译单元）一编译，但C++是按文件编译。因此代码每次变动，Rust要读取的比C++多。·</p><p>&nbsp;</p><p>对此，大家怎么看呢？我在推特上的投票结果如下：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/95/9569654b9f2a02669758ee1995174d8d.png\" /></p><p></p><p>&nbsp;</p><p>42%的人认为C++会赢，35%同意“看情况”，另外17%的则觉得Rust会让我们大吃一惊。</p><p>&nbsp;</p><p>那么结果到底如何呢？下面让我们进入正题。</p><p>&nbsp;</p><p></p><h2>编写C++和Rust的测试对象</h2><p></p><p></p><h3>找个项目</h3><p></p><p>考虑到我未来一个月都要花在重写代码上，什么样的代码最合适？我认为得满足以下几点：</p><p>&nbsp;</p><p>很少或不用第三方依赖（标准库可以使用）；能在Linux和macOS上运行（我不怎么管Windows上的构建时间）；大量测试套组（不然我没法确定Rust代码的正确性）；FFI（外部函数接口）、指针、标准或自定义容器、功能类和函数、I/O、并发、泛型、宏、SIMD（单指令多数据流）、继承等等，多少都有使用。</p><p>&nbsp;</p><p>其实答案也很简单，直接找我前几年一直在做的项目就行。我用的是一个JavaScript词法分析器，<a href=\"https://quick-lint-js.com/\">quick-lint-js</a>\"项目。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/8b/8b23a474a21eb51f465cd7e24e8de370.png\" /></p><p></p><p>quick-lint-js的吉祥物Dusty</p><p>&nbsp;</p><p></p><h3>截取C++代码</h3><p></p><p>&nbsp;</p><p>quick-lint-js项目中C++部分的代码行数超过10万，要把这些全改成Rust得花上我半年时间，不如只关注JavaScript词法分析部分，其中涉及项目中的：</p><p>&nbsp;</p><p>诊断系统翻译系统（用于诊断）各种内存分配器和容器（如bump分配器、适用于SIMD的字符串）各种功能类函数（如UTF-8解码器、SIMD内在包装器）测试的辅助代码（如自定义断言宏）C的API</p><p>&nbsp;</p><p>可惜这部分代码里不涉及并发或I/O，我测试不了Rust里async/await的编译时间开销，但这只是quick-lint-js项目里的一小部分，所以我还不用太担心。</p><p>&nbsp;</p><p>我首先把所有的C++代码都复制到新项目里，然后删掉已知与词法分析无关的部分，比如分析器和LSP服务器。我甚至一不小心删多了代码，最后不得不重新把这些代码添了回去。在我不断截代码的过程中，C++的测试一直保持了通过状态。</p><p>&nbsp;</p><p>在彻底将quick-lint-js项目中涉及词法分析的部分全截出来之后，项目中C++的代码大约有1.7万行。</p><p></p><p>&nbsp;</p><p></p><h3>重写代码</h3><p></p><p>&nbsp;</p><p>至于要怎么重写这上千行的C++代码，我选择按部就班：</p><p>&nbsp;</p><p>找一个适合转换的模块；复制黏贴代码、测试、搜索替换并修改部分语法、继续运行cargo（Rust的构建系统和包管理器）测试直到构建测测试都通过；如果这个模块依赖另一个模块，那就找到被依赖的模块，继续进行第二步，然后再回到现在这个模块；如果还有模块没转换，再回到第一步。</p><p>&nbsp;</p><p>主要影响Rust和C++构建时间的问题在于，C++的诊断系统是通过大量代码生成、宏、constexpr（常量表达式）实现的，而我在重写Rust版时，则用了代码生成、proc宏、普通宏以及一点点const实现。传闻proc宏速度很慢，也有说是因为代码质量太差导致的proc宏速度慢。希望我写的proc宏还可以（祈祷～）。</p><p>&nbsp;</p><p>我写完才发现，原来Rust项目比C++项目还要大，Rust代码17.1k行，而C++只有16.6k行。</p><p>&nbsp;</p><p></p><p>&nbsp;</p><p></p><h2>优化Rust构建</h2><p></p><p>&nbsp;</p><p>构建时间很重要，因为我在截取C++代码之前就已经做好了C++项目构建时间的优化，所以我现在只需要对Rust项目的构建时间做同样的优化即可。以下是我觉得可能会优化Rust构建时间的条目：</p><p>&nbsp;</p><p>更快的链接器Cranelift后端编译器和链接器标志工作区与测试布局区分最小化依赖功能cargo-nextest使用PGO自定义工具链</p><p>&nbsp;</p><p></p><h4>更快的链接器</h4><p></p><p>&nbsp;</p><p>我第一步要做的是分析构建，我用的是<a href=\"https://doc.rust-lang.org/beta/unstable-book/compiler-flags/self-profile.html\">-Zself-profile rustc标志</a>\"。在这个标志所生成的两个文件里，其中一个文件中的run_linker阶段颇为突出：</p><p>&nbsp;</p><p></p><p>第一轮-Zself-profile结果</p><p>&nbsp;</p><p>之前我通过向<a href=\"https://github.com/rui314/mold\">Mold链接器</a>\"的转换成功优化了C++的构建时间，那这套对Rust能否行得通？</p><p>&nbsp;</p><p>Linux：链接器性能几乎一致。（数据越小越好）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/68/68df4580b3154ab77570c918bad746d5.png\" /></p><p></p><p></p><p>可惜，Linux上虽然确实有提升，但效果不明显。那macOS上的优化又表现如何？在macOS上默认链接器的替代品有两种，lld和zld，效果如下：</p><p>&nbsp;</p><p>macOS：链接器性能几乎不变。（数据越小越好）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fe/fe6c8c73efcdb7eca2c3b942e22b93e5.png\" /></p><p></p><p>&nbsp;可以看出，macOS上替换默认链接器的效果同样不明显，我怀疑这可能是因为Linux和macOS上的默认链接器对我的小项目而言已经做到了最好，这些优化后的链接器（Mold、lld、zld）在大型项目上效果非常好。</p><p>&nbsp;</p><p></p><h4>Cranelift后端</h4><p></p><p>&nbsp;</p><p>让我们再回到<a href=\"https://doc.rust-lang.org/beta/unstable-book/compiler-flags/self-profile.html\">-Zself-profile</a>\"的另一篇报告上，LLVM_module_­codegen_emit_obj和LLVM_passes阶段颇为突出：</p><p></p><p>-Zself-profile的第二轮结果</p><p>&nbsp;</p><p>传闻可以把rustc的后端从LLVM换成Cranelift，于是我又用<a href=\"https://github.com/bjorn3/rustc_codegen_cranelift\">rustc Cranelift后端</a>\"重新构建了一遍，-Zself-profile结果看起来不错：</p><p>&nbsp;</p><p></p><p>使用Cranelife的-Zself-profile第二轮结果</p><p>&nbsp;</p><p>可惜，在实际的构建中Cranelife比LLVM慢。</p><p>&nbsp;</p><p>Rust后端：默认LLVM比Cranelift强。（测试于Linux，数据越小越好）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/16/169a32ce659c5150158daaff43642790.png\" /></p><p></p><p>&nbsp;</p><p>2023年1月7日更新：rustc 的 Cranelift 后端维护者bjorn3帮我看了下为什么Cranelift在我的项目上效果不佳：可能是rustup的开销导致的。如果绕过这部分Cranelife效果可能会有提升，上图中的结果没有采用任何措施。</p><p>&nbsp;</p><p></p><h4>编译器和链接器标志</h4><p></p><p>&nbsp;</p><p>编译器里有一堆可以加快（或减缓）构建速度的选项，让我们一一试过：</p><p>&nbsp;</p><p>-Zshare-generics=y&nbsp;(rustc) (Nightly only)-Clink-args=-Wl,-s&nbsp;(rustc)debug = false&nbsp;(Cargo)debug-assertions = false&nbsp;(Cargo)incremental = true&nbsp;且 incremental = false&nbsp;(Cargo)overflow-checks = false&nbsp;(Cargo)panic = 'abort'&nbsp;(Cargo)lib.doctest = false&nbsp;(Cargo)lib.test = false&nbsp;(Cargo)</p><p>&nbsp;</p><p>rustc标志：快速构建优于调试构建。（测试于Linux，数据越小越好）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b4/b4f27588913e75bdf2d9ee8b5c3b8264.png\" /></p><p></p><p>&nbsp;</p><p>注：图中的“quick, -Zshare-generics=y”与“quick, incremental=true”且启用“-Zshare-generics=y”标志相等同，其余柱状图没有标识“-Zshare-generics=y”是因为没有启用该标志，后者意味着需要nightly rust编译器。</p><p>&nbsp;</p><p>上图中使用的多数选项都有文档可查，但我还没找到有人写过加-s的链接。子命令-s将包括Rust标准库静态链接在内的所有调试信息全部剥离，让链接器做更少的工作，从而减少链接时间。</p><p>&nbsp;</p><p></p><h4>工作区与测试布局</h4><p></p><p>&nbsp;</p><p>在文件的物理位置问题上，Rust和Cargo都提供了部分灵活性。对我的项目而言，以下是三种合理布局：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f7/f726f8c259f4f84fc1e4f3b92e09f164.png\" /></p><p></p><p>&nbsp;</p><p>理论上来说，如果我们把代码拆成多个crate，cargo就可以并行化rustc的调用。鉴于我的Linux机器上有一个32线程的CPU，macOS机器上有一个10线程的CPU，并行化应该可以降低构建时间。</p><p>&nbsp;</p><p>对一个crate而言，Rust项目中的测试有很多可运行的地方：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/87/871b42b11b348e36d9d2cf788019ed16.png\" /></p><p></p><p>&nbsp;由于依赖周期的存在，我没办法做“源码文件内的测试”这个布局的基准，但其他布局组合里我都做了基准：</p><p>&nbsp;</p><p>Rust完整构建：工作区布局最快。（测试于Linux，数据越小越好）</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/04/049eaf9ed425f3953d6b1ff2a7f20d0a.png\" /></p><p></p><p>&nbsp;Rust增量构建：最佳布局不明。（测试于Linux，数据越小越好）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/90/90e2912e380023cae041fdcfd08975f6.png\" /></p><p></p><p>&nbsp;</p><p>工作区设置中，无论是分成多个可执行测试（many test exes），还是合并成一个可执行测试，似乎都能斩获头筹。所以后续我们还是按照“工作区+多个可执行文件”的配置吧。</p><p></p><h4>最小化依赖功能</h4><p></p><p>&nbsp;</p><p>多个crate的拆分支持可选功能，而部分可选功能都是默认启用的，具体功能可以通过cargo tree命令查看：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b9/b9bf7d9c2c77871a7fb5fab19c7efb89.png\" /></p><p></p><p>&nbsp;</p><p>让我们把crate之一，libc中的std功能关掉，测试后再看看构建时间有没有变化。</p><p>&nbsp;</p><p>Cargo.toml</p><p><code lang=\"null\"> [dependencies]\n+libc = { version = \"0.2.138\", default-features = false }\n-libc = { version = \"0.2.138\" }</code></p><p></p><p>关掉libc功能后没有任何变化。（测试于Linux，数据越小越好）</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a9/a90f5fb32af9e85a7756b3771b159c1a.png\" /></p><p></p><p>&nbsp;构建时间没有任何变化，有可能std功能实际没什么大影响。不管怎么说，让我们进入下一个环节。</p><p>&nbsp;</p><p></p><h4>cargo-nextest</h4><p></p><p>作为一款据说“比cargo测试快60%”的工具，<a href=\"https://nexte.st/\">cargo-nextest</a>\"对于我这个代码中44%都是测试的项目来说非常合适。让我们来对比下构建和测试时间：</p><p>&nbsp;</p><p>Linux：cargo-nextest减慢了测试速度。（数据越小越好）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/96debaae2b7cc567da01c13765648264.png\" /></p><p></p><p>&nbsp;</p><p>在我的Linux机器上，cargo-nextest帮了倒忙，虽然输出不错，不过……</p><p>&nbsp;</p><p>示例cargo-nextest测试输出：</p><p><code lang=\"null\">PASS [   0.002s]        cpp_vs_rust::test_locale no_match\nPASS [   0.002s]     cpp_vs_rust::test_offset_of fields_have_different_offsets\nPASS [   0.002s]     cpp_vs_rust::test_offset_of matches_memoffset_for_primitive_fields\nPASS [   0.002s] cpp_vs_rust::test_padded_string as_slice_excludes_padding_bytes\nPASS [   0.002s]     cpp_vs_rust::test_offset_of matches_memoffset_for_reference_fields\nPASS [   0.004s] cpp_vs_rust::test_linked_vector push_seven</code></p><p>&nbsp;</p><p>那macOS上怎么说？</p><p>&nbsp;</p><p>macOS：cargo-nextest加快了构建测试。（数据越小越好）</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/1f/1f7fe678613d8873e5f25dd05efb7b68.png\" /></p><p></p><p>&nbsp;</p><p>在我的MacBook pro上，cargo-nextest确实提高了构建测试的速度。但为什么Linux上没有呢？难道是和硬件有关？</p><p>&nbsp;</p><p>在下面测试中，我会在macOS上使用cargo-nextest，但Linux上的测试不用。</p><p>&nbsp;</p><p></p><h4>使用PGO自定义工具链</h4><p></p><p>&nbsp;</p><p>我发现C++编译器的构建如果用配置文件引导的优化（PGO，也称作FDO），会有明显的性能提升。因此，让我们试试用PGO优化Rust工具链的同时，也用LLVM BOLT加上-Ctarget-cpu=native进一步优化rustc。</p><p>&nbsp;</p><p>Rust工具链：自定义工具链是最快的。（测试于Linux，数据越小越好）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0b/0b852c548b2777b82a1ba6aef03ad8ed.png\" /></p><p></p><p>&nbsp;</p><p>如果你好奇的话，可以看看这段工具链构建脚本。可能不适用于你的机器，但只要我能运行就行：<a href=\"https://github.com/quick-lint/cpp-vs-rust/blob/953429a4d92923ec030301e5b00face1c13bb92b/tools/build-toolchains.sh\">https://github.com/quick-lint/cpp-vs-rust/blob/953429a4d92923ec030301e5b00face1c13bb92b/tools/build-toolchains.sh</a>\"</p><p>&nbsp;</p><p>与C++编译器相比，通过rustup发布的Rust工具链似乎已经是优化完成的结果。PGO加上BOLT的组合只带来了不到10%的性能提升。但有提升就是好的，所以在后续与C++的竞争中我们会继续使用这个速度最快的工具链。</p><p>&nbsp;</p><p>我第一次搭建的Rust自定义工具链比Nightly还要慢2%，我在Rust config.toml的各种选项中反复调整，不断交叉检查Rust的CI构建脚本以及我自己的脚本，最终在好几天的挣扎后才让这二者性能持平。在我最终润色这篇文章时，我进行了rustup更新，拉取git项目，并重头又建了一遍工具链。结果这次我的自定义工具链速度更快了！有可能是我在Rust仓库里提交错了代码……</p><p>&nbsp;</p><p></p><h2>优化C++构建</h2><p></p><p>&nbsp;</p><p>在最初的C++项目quick-lint-js中，我已经用常见的手段优化了编译时间，比如用PCH、禁用异常和RTTI、调整编译标志、删除非必要#include、将代码从头中移出、外置模板实例等方法。但此外还有一些C++编译器和链接器我没试过，在我们进入C++和Rust的对比之前，先从这些里面挑出最适合我们的。</p><p>&nbsp;</p><p>Linux：自定义Clang是最快的工具链。（数据越小越好）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bc/bc278d3f06321c38a0f9cfd61714ccd4.png\" /></p><p></p><p>&nbsp;很明显，Linux上的GCC是个特例，而Clang的表现则要好上很多。我自定义构建的Clang（和Rust工具链一样，也是用PGO和BOLT构建的）相较于Ubuntu的Clang，显著优化了构建时间，而libstdc++的构建略快于平均libc++的速度。</p><p>&nbsp;</p><p>那我的自定义Clang加上libstdc++在C++和Rust的对比中表现如何呢？</p><p>&nbsp;</p><p>macOS：Xcode是最快的工具链。（数据越小越好）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8d/8dcac7b9621973a291fed60136095d6a.png\" /></p><p></p><p>&nbsp;在macOS上，搭配Xcode的Clang工具链似乎要比LLVM网站上的Clang工具链优化得更好。</p><p>&nbsp;</p><p></p><h4>C++20模块</h4><p></p><p>&nbsp;</p><p>我的C++代码用的是#include，但如果用C++20中新增加的import又会怎么样呢？C++20的模块是不是理论上来说应该会让编译速度超级快？</p><p>&nbsp;</p><p>我在项目了尝试过C++20 模块，但直到2023年的1月3日，Linux上的CMake模块支持过于实验性质了，我甚至连“hello world”都没跑起来。</p><p>&nbsp;</p><p>或许2023年中C++20模块会大放异彩，对于我这种超级在意构建时间的人来说，真是这样就太好了。但目前为止，我还是继续用经典C++的#include和Rust做对比吧。</p><p>&nbsp;</p><p></p><h2>对比C++和Rust的构建时间</h2><p></p><p>&nbsp;</p><p>通过把C++项目改写成Rust，并尽可能地优化Rust的构建时间后，问题来了：C++和Rust究竟谁更快呢？</p><p>&nbsp;</p><p>很可惜，答案是“看情况”！</p><p>&nbsp;</p><p>Linux：Rust部分情况下构建速度超越C++。（数据越小越好）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c6/c673b441aea09bfd65badd311a97773b.png\" /></p><p></p><p>&nbsp;在我的Linux机器上，部分情况下Rust的构建速度确实优于C++，但也有速度持平或逊于C++的情况。在增量lex的基准上，我们修改了大量源码，Clang比rustc速度快，但在其他增量基准上，rustc又会反超Clang。</p><p>&nbsp;</p><p>macOS：C++构建速度通常快于Rust。（数据越小越好）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8f/8fd7a2a12609b2d791883f78b650cd95.png\" /></p><p></p><p>&nbsp;但我的macOS机器上情况却截然不同。C++的构建速度常常快上Rust许多。在增量测试utf-8的基准，我们修改中等数量测试文件，rustc编译速度会略微超过Clang，但在包括全量构建等其他基准上，Clang很明显效果要更好。</p><p>&nbsp;</p><p></p><h3>超过17k行代码</h3><p></p><p>&nbsp;</p><p>我基准测试的项目只有17k行代码，算是小型项目，那么对超过10万行代码的大型项目来说，又是什么情况呢？</p><p>&nbsp;</p><p>我把最大的模块，也就是词法分析器的代码复制粘贴了8、16以及24遍，分别用来测试。因为我的基准里也包括了运行测试的时间，我觉得构建时间即使是对于那些能瞬间构建完的项目，也应该会线性增长。</p><p>&nbsp;</p><p></p><p>&nbsp;</p><p>倍数扩大后C++完整构建优于Rust。（测试于Linux，数据越小越好）</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7d/7d9fdafc8eabd41f77c347d845f0cda8.png\" /></p><p></p><p>&nbsp;</p><p>倍数扩大后C++增量构建优于Rust。（测试于Linux，数据越小越好）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/89/89bf2c5d3feb24dcfc8be5fdd84b9302.png\" /></p><p></p><p>&nbsp;</p><p>Rust和Clang确实都是线性扩大，这点很好。</p><p>&nbsp;</p><p>正如预期中一样，修改C++的头文件，也就是增量diag-type会大幅影响构建时间。而由于Mold链接器的存在，其他增量基准中构建时间的扩展系数很低。</p><p>&nbsp;</p><p>Rust构建的扩展性让我很失望，即使只是增量utf-8测试的基准，无关文件的加入也不应该让它的构建时间如此受影响。测试所用的crate布局时“工作区且多个可执行测试”，因此utf-8测试应该能独立编译可执行文件。</p><p></p><h2>结论</h2><p></p><p>&nbsp;</p><p>编译时间对Rust而言算是问题吗？答案是肯定的。虽然也有一些可以加快编译速度的提示和技巧，但却没有效果非常显著的数量级改进，这让我在开发Rust时非常高兴。</p><p>&nbsp;</p><p>Rust的编译时间和C++相比呢？确实也很糟。至少对我的编码风格来说，Rust在大型项目上开发的编译时间甚至更加远比C++还要糟糕。</p><p>&nbsp;</p><p>再回过头看看我当初的假设，几乎全军覆没：</p><p>&nbsp;</p><p>Rust改写版代码行数比C++多；在全量构建上，C++相比Rust在1.7万行代码上构建时间相似，在10万行代码上构建时间要少；在增量构建上，Rust相比C++在部分情况构建时间要短，在1.7万行上构建时间要长，在10万行代码上构建时间甚至更长。</p><p>&nbsp;</p><p>我不爽吗？确实。在改写过程中，我不断学习着Rust相关的知识，比如proc marco能替代三个不同代码生成器，简化构建流水线，让新开发者们日子更好过。但我完全不想念头文件，以及Rust的工具类真的很好用，特别是Cargo、rustup以及miri。</p><p>&nbsp;</p><p>但我决定不把quick-lint-js项目中剩下的代码也改成Rust，但如果Rust的构建时间能有明显优化，或许我会改变主意。当然，前提是我还没被<a href=\"https://ziglang.org/\">Zig</a>\"迷走心神。</p><p>&nbsp;</p><p></p><h2>附注</h2><p></p><p></p><h3>源码</h3><p></p><p>删减后的C++<a href=\"https://github.com/quick-lint/cpp-vs-rust\">项目源码</a>\"、移植版Rust（包括不同的项目布局）、代码生成脚本和基准测试脚本、GPL-3.0及以上。</p><p>&nbsp;</p><p></p><h4>Linux机器</h4><p></p><p>名称：strapurp</p><p>CPU：AMD Ryzen 9 5950X (PBO; stock clocks) (32 threads) (x86_64)</p><p>RAM：G.SKILL F4-4000C19-16GTZR 2x16 GiB (overclocked to 3800 MT/s)</p><p>操作系统：Linux Mint 21.1</p><p>内核：Linux strapurp 5.15.0-56-generic #62-Ubuntu SMP Tue Nov 22 19:54:14 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux</p><p>Linux性能治理器：schedutil</p><p>CMake：版本3.19.1</p><p>Ninja：版本1.10.2</p><p>GCC：版本12.1.0-2ubuntu1~22.04</p><p>Clang（Ubuntu）：版本14.0.0-1ubuntu1</p><p>Clang （自定义）：版本15.0.6（Rust fork; 代码提交<a href=\"https://github.com/rust-lang/llvm-project/tree/3dfd4d93fa013e1c0578d3ceac5c8f4ebba4b6ec\">3dfd4d93fa013e1c0578­d3ceac5c8f4ebba4b6ec</a>\"）</p><p>libstdc++ for Clang：版本11.3.0-1ubuntu1~22.04</p><p>Rust稳定版：1.66.0 (69f9c33d7 2022-12-12)</p><p>Rust Nightly：版本1.68.0-nightly (c7572670a 2023-01-03)</p><p>Rust（自定义）：版本1.68.0-dev (c7572670a 2023-01-03)</p><p>Mold：版本0.9.3 (ec3319b37f653dccfa4d­1a859a5c687565ab722d)</p><p>binutils：版本2.38</p><p>&nbsp;</p><p></p><h4>macOS 机器</h4><p></p><p>名称：strammer</p><p>CPU：Apple M1 Max (10 threads) (AArch64)</p><p>RAM：Apple 64 GiB</p><p>操作系统：macOS Monterey 12.6</p><p>CMake：版本3.19.1</p><p>Ninja：版本1.10.2</p><p>Xcode Clang：Apple clang 版本14.0.0 (clang-1400.0.29.202) (Xcode 14.2)</p><p>Clang 15：版本15.0.6 (LLVM.org website)</p><p>Rust稳定版：1.66.0 (69f9c33d7 2022-12-12)</p><p>Rust Nightly：版本1.68.0-nightly (c7572670a 2023-01-03)</p><p>Rust（自定义）：版本1.68.0-dev (c7572670a 2023-01-03)</p><p>lld：版本15.0.6</p><p>zld：代码提交 d50a975a5fe6576ba0fd­2863897c6d016eaeac41</p><p>&nbsp;</p><p></p><h4>基准</h4><p></p><p>用deps的构建和测试</p><p>C++：cmake -S build -B . -G Ninja &amp;&amp; ninja -C build quick-lint-js-test &amp;&amp; build/test/quick-lint-js-test&nbsp;计时</p><p>Rust：cargo fetch&nbsp;未计时，再用&nbsp;cargo test&nbsp;计时</p><p>&nbsp;</p><p>不用deps的构建和测试</p><p>C++：cmake -S build -B . -G Ninja &amp;&amp; ninja -C build gmock gmock_main gtest&nbsp;未计时, 再用ninja -C build quick-lint-js-test &amp;&amp; build/test/quick-lint-js-test&nbsp;计时</p><p>Rust：cargo build --package lazy_static --package libc --package memoffset\"&nbsp;未计时, 再用cargo test&nbsp;计时</p><p>&nbsp;</p><p>增量diag-types</p><p>C++：构建和测试未计时，随后修改diagnostic-types.h，再用ninja -C build quick-lint-js-test &amp;&amp; build/test/quick-lint-js-test</p><p>Rust：构建和测试未计时，修改diagnostic_types.rs后，cargo test</p><p>&nbsp;</p><p>增量lex</p><p>同增量diag-types，但使用lex.cpp/lex.rs</p><p>&nbsp;</p><p>增量utf-8测试</p><p>同增量，但使用test-utf-8.cpp/test_utf_8.rs</p><p>&nbsp;</p><p>每个可执行基准均采用12个样本，弃置前两个，基准仅显示最后十个样本的平均性能。误差区间展示最小与最大样本间区别。</p><p></p><p></p><p>原文链接：</p><p></p><p><a href=\"https://quick-lint-js.com/blog/cpp-vs-rust-build-times/\">https://quick-lint-js.com/blog/cpp-vs-rust-build-times/</a>\"</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-01-30 14:38:59",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "数百程序员专门教AI写代码、40个bug能修复31个，“取代程序员”这次要成真了？",
    "url": "https://www.infoq.cn/article/eGbSZBSKWEDxspQq8FLh",
    "summary": "<p>AI 在回答问题和编写代码方面已经变得相当出色。在一项新的研究课题中，ChatGPT尝试查找示例代码中的bug并给出修复建议。其表现远超现有程序，成功修复了40个bug中的31个。AI开始显现出强大的能力，一些人又开始担心程序员会失业了，在软件开发和编程中的历史中，这又是一次“狼来了”的故事吗？</p><p>&nbsp;</p><p></p><h2>ChatGPT现可查找并修复代码中的bug</h2><p></p><p>&nbsp;</p><p>最近几周，AI新贵ChatGPT迎来了一系列评测挑战。一项最新研究来自约翰内斯古腾堡大学和伦敦大学学院的计算机科学研究人员，他们发现ChatGPT能够从示例代码中发现错误并加以修复，且整体表现优于现有同类程序。</p><p>&nbsp;</p><p>研究人员将这40段bug代码提交至四种不同的代码修复系统，分别为ChatGPT、Codex、CoCoNut和Standard APR。在ChatGPT上，他们只需询问“这段代码有什么问题？”再将代码内容复制粘贴至聊天框内即可。在首轮测试中，ChatGPT的表现跟其他程序相差不大。ChatGPT解决了其中19个问题，Codex解决了21个，CoCoNut解决了19个，Standard APR解决了7个。研究人员发现ChatGPT给出的答案与Codex最为相似，“这倒是正常，毕竟ChatGPT和Codex来自同一语言模型家族。”</p><p>&nbsp;</p><p>但在收到首批答案之后，ChatGPT的强大能力开始表现出来，随后势如破竹般解决了31个问题，轻松超越了其他只能提供静态答案的同类工具。</p><p>&nbsp;</p><p>研究人员在报告中写道，“ChatGPT的一大核心优势，在于我们会在对话中直接交互，更详细地描述需求。我们发现，对于大部分请求，ChatGPT会要求提供关于问题和bug的更多细节信息。在向ChatGPT提供提示信息之后，其成功率得以进一步提高，修复了全部40个bug中的31个，成绩可谓一骑绝尘。”</p><p>&nbsp;</p><p>他们还发现，ChatGPT能够快速解决的某些问题，在其他程序上往往需要反复拉扯。“ChatGPT在修复bug时似乎表现出较高的不一致性。但对最终用户来说，只要多执行几次应该就能得到有价值的结果。”</p><p>&nbsp;</p><p>例如，当研究人员提交下图问题时，他们预期的答案是将n^=n-1替换为n&amp;=n-1。但ChatGPT给出的回应是“我无法判断程序中是否存在bug，请提供关于预期行为的更多信息。”经过研究人员的提示，ChatGPT在第三次回复中成功发现了问题。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9b/9b0684f026c83df6a8626fe2ffd86915.png\" /></p><p></p><p>&nbsp;</p><p>但在我们尝试将同样的问题输入给ChatGPT时，它的回答却截然不同。ChatGPT这次并未要求提供预期行为，而是在猜测我们想要达成怎样的效果。ChatGPT一直在根据用户输入进行学习，它似乎已经理解了这段代码的用途——也许就是从当初研究人员们的提示中学习而来。我们的验证交流与研究报告不同，而且下一次再试可能也不相同。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f7/f7efb66e7678713dd3b4078a314ce897.png\" /></p><p></p><p>&nbsp;</p><p>目前，帮助软件工程师查找和修复bug的产业已经汇聚起6亿美元的体量。此次研究的成功，也许将重新定义这块可观的业务市场。Sentry等流行平台已经成为软件团队的标配工具，通过发布问题报告和提供修复建议，大大增强开发者们编写高质量代码的能力。</p><p>&nbsp;</p><p></p><h2>OpenAI召集数百程序员，教AI写代码</h2><p></p><p>&nbsp;</p><p>无论是bug修复软件开发商还是软件工程师自己，显然都注意到了这波堪称历史转折点的趋势。ChatGPT 的所有者OpenAI也在不断增强AI的编程能力，根据 Semafor 的一份报告，OpenAI 在过去6个月中加大招聘力度，已经在全球范围内悄悄聘请了上千名承包商来培训其AI学习软件工程。&nbsp;</p><p>&nbsp;</p><p>在这近 1000 名承包商中，约 60% 的人负责“数据标记”，即创建大量图像、音频剪辑和其他信息，用于训练 AI 工具或自动驾驶系统；另外 40% 则是程序员，主要负责为 OpenAI 的模型创建数据以学习软件工程任务。</p><p>&nbsp;</p><p>此前，OpenAI从 GitHub 上抓取代码来训练其模型，而且OpenAI于2021年8月推出的产品Codex，已经可以实现将自然语言转换为工作代码，现在该公司的招聘热潮表明它正在进一步推进该技术，甚至有可能为一些程序员岗位创造出一个替代工具。&nbsp;</p><p>&nbsp;</p><p>Semafor 采访了南美的一位工程师，他表示自己参加了 OpenAI 的面试，该过程包含了五小时的无偿编码测试。这个测试有两个部分组成：对于一个给出的编码问题，OpenAI要求他用书面英语解释他将如何处理这个问题，并给出一个具体解决方案；查找 AI 代码中的错误并提供有关如何修复错误的解释。这位工程师告诉 Semafor，他认为公司希望将人类的思维过程输入到其人工智能技术中。&nbsp;</p><p>&nbsp;</p><p>事实上，据 Insider 最近的报道，一些亚马逊员工已经开始使用 ChatGPT来帮助编码。亚马逊内部的 Slack 消息显示，ChatGPT 已经被亚马逊用于许多不同的工作职能中，包括回答面试问题、编写软件代码和创建培训文档等。</p><p>&nbsp;</p><p>一名员工在 Slack 上表示，亚马逊 Amazon Web Services（AWS）云部门已经成立了一个小型工作组，以更好地了解人工智能对其业务的影响。通过测试，该团队发现 ChatGPT 在回答 AWS 客户支持问题方面“做得非常好”。此外，人工智能工具在创建培训文档方面也“非常出色”，在企业战略问题方面“非常强大”。另外，这名员工还在 Slack 上称，ChatGPT 在为 AWS Aurora 数据库工程师编写故障排除指南和回答“困难的”支持问题方面也“非常出色”，它还能够“弄清客户的公司目标”。</p><p>&nbsp;</p><p></p><h2>现在还取代不了程序员，那将来呢？</h2><p></p><p>&nbsp;</p><p>随着数百名程序员齐心协力“教”模型如何编写基本代码，ChatGPT 背后的技术可能会朝着一种新的软件开发方向发展，就像重型设备对建筑行业一样，给软件行业带来变革意义。</p><p>&nbsp;</p><p>而且自从ChatGPT 能力开始显现后，“程序员要失业了”、“取代程序员”之类的声音已经不绝于耳。大多数人对此嗤之以鼻，毕竟过去几十年来，我们听够了类似的声音，云服务、无服务器计算、低代码和无代码......每个技术浪潮的到来，都有人喊出“程序员要被替代了！”</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cf/cfa45170d21f4c229a845901391c5a09.jpeg\" /></p><p></p><p>&nbsp;</p><p>但还是有相当“激进”的声音，认为这次“替代程序员”并不是又一个“狼来了的故事”。</p><p>&nbsp;</p><p>今年一月份的ACM 通讯发表了一篇名为“编程的终结”的文章，预测在人工智能驱动的未来“编程将过时”。作者Matt Welsh是 Fixie.ai 的首席执行官兼联合创始人，他曾是哈佛大学计算机科学教授、谷歌工程总监、苹果工程主管。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6d/6d5ab59ad026ac741f5a5138a27d6ea6.jpeg\" /></p><p></p><p>&nbsp;</p><p></p><blockquote>我相信“编写程序”的传统想法正在走向灭绝，事实上，除了非常专业的应用程序之外，我们所知道的大多数软件将被经过训练而不是编程的人工智能系统所取代。在需要“简单”程序的情况下（毕竟，并非所有内容都需要在GPU集群上运行数千亿个参数的模型），这些程序本身将由AI生成，而不是手动编码。</blockquote><p></p><p>&nbsp;</p><p></p><blockquote>未来的工程师只需敲击几下键盘，就能启动一个包含四亿亿亿参数的模型实例，这个模型已经对人类知识的全部范围（或是部分）进行了编码，并随时准备执行机器要求的任何任务。让机器做自己想做的事，大部分脑力工作将是提出正确的示例、正确的训练数据和正确的方法来评估训练过程。</blockquote><p></p><p>&nbsp;</p><p></p><blockquote>我认为计算机科学作为一个领域正处于一个相当大的动荡之中，我们中很少有人真正做好了准备。</blockquote><p></p><p>&nbsp;</p><p>“我认为现在的争论主要围绕这些人工智能模型将在多大程度上彻底改变软件行业，”Welsh在一个视频采访中说，“这更多是一个程度的问题，而不是它到底会不会发生……”</p><p>&nbsp;</p><p>我们认为，现在ChatGPT取代程序员是不太可能的，但是也许下一代开发人员必须习惯人工智能，毕竟让AI帮助我们编程就在不远的未来。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.pcmag.com/news/watch-out-software-engineers-chatgpt-is-now-finding-fixing-bugs-in-code\">https://www.pcmag.com/news/watch-out-software-engineers-chatgpt-is-now-finding-fixing-bugs-in-code</a>\"</p><p><a href=\"https://www.businessinsider.com/openai-chatgpt-contractors-train-ai-software-engineering-autonomous-vehicles-report-2023-1\">https://www.businessinsider.com/openai-chatgpt-contractors-train-ai-software-engineering-autonomous-vehicles-report-2023-1</a>\"</p><p><a href=\"https://cacm.acm.org/magazines/2023/1/267976-the-end-of-programming/fulltext\">https://cacm.acm.org/magazines/2023/1/267976-the-end-of-programming/fulltext</a>\"</p>",
    "publish_time": "2023-01-30 15:15:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "音视频技术持续进击，直播互动场景会如何“进化”？",
    "url": "https://www.infoq.cn/article/wSkRAHQ7Mtuu2YefM4ue",
    "summary": "<p>采访嘉宾 | 李凯</p><p>整理 | 任传英</p><p>&nbsp;</p><p>小到远程会议、直播娱乐，大到元宇宙话题中对于未来互动方式的讨论，音视频技术与我们生活方式的变革息息相关。目前，音视频赛道的技术突破，也给直播互动带来了很多新的玩法和形式。音视频领域有哪些重要的突破？人们对于直播互动有哪些新的需求？音视频技术攻克技术难题有哪些思路可以借鉴？</p><p>&nbsp;</p><p>1 月 4 日，ZEGO 即构科技视频处理工程师李凯现身 InfoQ 极客有约，结合自己丰富的职业经历，给出了很多关于音视频技术发展、突破以及直播互动玩法持续“进化”等方面的思考和见解。&nbsp;以下内容节选自<a href=\"https://www.infoq.cn/video/QlsziKdTXqzhwruZhSW3\">当天的分享</a>\"，InfoQ 做了不改变原意的编辑：</p><p>&nbsp;</p><p></p><blockquote>采访嘉宾：李凯，ZEGO 即构科技视频处理工程师，主要负责视频处理相关业务、极轻量级模型设计及推理框架优化。从业视频处理 18 年以来，工作涉及单/多摄像机采集及拼接、摄像机 3A、基于传统和 AI 的视频增强处理、极轻量级模型设计及推理框架优化、多投影仪弧幕自动拼接系统、裸眼立体显示等。累计署名专利 120+篇。</blockquote><p></p><p></p><h2>嘉宾介绍</h2><p></p><p>&nbsp;</p><p>InfoQ：请李凯老师介绍一下自己，可以着重聊聊工作经历。</p><p>&nbsp;</p><p>李凯：我目前在即构科技工作，主要负责视频处理相关业务、技术研发以及 AI 推理引擎优化的工作。工作 18 年以来，做过端到端涉及到的很多业务和技术领域，举例来讲，在 2007 年做了基于深度摄像机裸眼立体视觉显示系统；也做过比较小众的业务，比如说十几个摄像机投影到一个弧形幕上自动拼接的校正系统。总的来说，一直在视频处理领域，在传统技术、基于 AI 的视频增强处理技术，以及包括摄像头 3A 的一些算法方面都有涉足。这些年也申请了一些专利，署名专利 120 多篇。</p><p>&nbsp;</p><p>InfoQ：音视频技术的演进和迭代非常快，基于您过往数十年的从业经历，您有哪些印象比较深刻的技术突破点，可以选几个分享一下吗？</p><p>&nbsp;</p><p>李凯：从早期看，音视频都是朝着更加高清、更加流畅、更加实时的方向不断去演进，再往前发展有 3 个技术趋势：</p><p>&nbsp;</p><p>第一：沉浸感，即面部的五官、声音的传达让用户有沉浸体验；</p><p>第二：高保真，即在虚拟空间中，通过全息投影或者虚拟远程控制的真人形象；</p><p>第三：强交互，元宇宙社交领域中强调强交互，同时我们与客户和用户交流时，也会涉及到强交互。</p><p>&nbsp;</p><p>基于这 3 个技术发展的方向，举两个印象比较深的例子。</p><p>&nbsp;</p><p>第一个是在 2007 年，我们基于深度摄像机裸眼立体显示系统，做了一个端到端的 demo，主要目标是希望能够从立体显示器中，仅仅通过裸眼看到立体、真实人物形象。</p><p>&nbsp;</p><p>第二个是在 2020 年，即构的一个客户做了具有强互动属性的伪 AI 直播，简单来说，就是将类似 VIPKID（一节课成本 250 元）的真人直播做成录播，学生可以与老师实时互动交流，与直播课程的体验相同，小朋友在这个过程中也可以感受强互动的学习体验。这个技术的好处也显而易见——降低了课程的成本（伪 AI 直播成本一节课 5 元），同时也能给用户带来非常好的体验，这些都是技术进步带来的变革，让不少经济欠发达的地区也能享受高品质的课程服务。</p><p></p><h2>直播互动新场景及面临的技术挑战</h2><p></p><p>&nbsp;</p><p>InfoQ：2020 年被称作元宇宙元年，近几年元宇宙的概念也被广泛讨论，今年还出现了元宇宙直播间之类的新场景，您观察到还有哪些比较有趣的应用场景，可以展开聊聊。</p><p>&nbsp;</p><p>李凯：对于我个人而言可能无法去定义有趣，但是客户对所谓“有趣”是最有发言权的。目前即构强调为用户搭建更多、更好的设施来服务客户，这也是从用户以及客户的需求出发的。</p><p>&nbsp;</p><p>在客户的反馈过程中，这两个场景比较典型：第一个是强社交的场景，在元宇宙空间里一切虚拟化，人与人之间一对一的沟通交流以及多人在虚拟空间中的强社交需求非常多，这种交流包括五官的感知、空间音频的临场感，以及语音交互、肢体交互、表情交互等；第二个是娱乐互动的场景，比如游戏娱乐、直播娱乐、点播等等，这些场景的应用前期大多由游戏厂商参与。</p><p>&nbsp;</p><p>InfoQ：业内预测元宇宙直播可能会成为直播的下一个风口，您对这个预测怎么看？元宇宙直播会成为风口，背后的依据是什么？</p><p>&nbsp;</p><p>李凯：2020 年开始我们投入高保真数字人研发，2022 年在国际期刊发表文章，即构一直在研究直播技术，再加上程序员对行业的观察，我认为高保真虚拟数字人直播会成为一种趋势。同时，基于人脸三维重建，肢体动作的捕捉、驱动、渲染、合成，以及智能交互等数字人技术的发展，会使得数字人的制作成本极大降低，让更多的用户体验到高保真虚拟数字人的直播。</p><p>&nbsp;</p><p>虚拟数字人最大的优势是什么？答案是“可控”。不同于真人直播中可能要面对主播跳槽、单飞的情况，虚拟人主播服从一切指令。另外，在<a href=\"https://xie.infoq.cn/article/8095e0ed0b45fa524e313451a\">元宇宙直播间</a>\"，我们可以为用户搭建、定制随时切换的场景，搭建成本也非常低，通过数字化技术，特别是基于 NeRF 技术的发展，能给用户提供全新的体验。</p><p>&nbsp;</p><p>InfoQ：如今，用户对直播的沉浸式体验、高清分辨率之类的要求越来越高，除此之外，用户在新型直播互动场景中的需求还有什么样的特征，对哪些功能的要求更多？</p><p>&nbsp;</p><p>李凯：在和客户实际的交流中，我们有一种体会，那就是用户需要的是强悍的基础能力，能够在移动端的覆盖面更广，因此我们也在强调高保真，或者说高清、流畅、实时。但是在移动端仅仅实现高清实时的难度都是非常高的，比如说某个客户用到我们的超分技术，需要在移动端实现实时超分，将 540P 超分到 1080P，目前能做到这一点的公司并不多；再比如，安卓的某些机型能不能跑 540P？这些都是比较实际的问题，也反映了企业有没有能力将超分、甚至插帧、倍帧技术做得更好。</p><p>&nbsp;</p><p>所以回归到问题本身，由于用户或者说客户是在付费体验，我们能不能加强他们的技术能力？以东南亚、印度的客户为例，他们的帧率可能只有七八帧，且机器性能比较差的情况下，能不能在移动端实现插帧？这是第一个重要的特征。第二，从客户、用户的角度来讲，他们在使用产品的时候，不仅想要听得见和看得清，与对方 1 个人或者更多人互动交流，更进一步的是想感受这个人就坐在身边，好像在面对面说话的强互动过程，这也是即构未来想要推出的加强交互的技术。</p><p>&nbsp;</p><p>InfoQ：新型直播互动场景非常受到关注，像沉浸式直播、同屏互动这些场景中，给音视频技术带来了哪些挑战？哪些能力还需要提升？</p><p>&nbsp;</p><p>李凯：像刚刚提到的强交互，对于实时性也就是抗弱网的能力要求很高，同时，音视频、空间相关的技术也需要做好，这两点是比较基础的要求。另外，还涉及到语音交互以及动作的交互，比如说自己的动作反馈出去之后，对方的动作能不能立刻反馈回来，这才是强交互的过程。</p><p>&nbsp;</p><p>刚刚说到的都是软件对软件的场景，那么如果要在硬件上，比如说一个和真人大小相同的大屏幕上实现，这样的体验感、交流感会更强。还有跨屏互动，这个场景比较常见，两个人一左一右，那么左边的人抛一个东西，能不能到右边，右边的人能否通过视觉，或者是带一个手套来感觉到，这样的空间交流也很有挑战。</p><p>&nbsp;</p><p>实际上，以上都是我们想象出来的画面，想要真正实现还是任重道远的，目前我们用的更多的是移动端的 4G 场景，但如果 5G 真正被普及开来，时延、高清应该也不会有太大的问题，而是会往交互空间临场感、语音方面去发展，相信一定会有更多的应用和玩法。</p><p>&nbsp;</p><p>InfoQ：以虚拟直播的场景为例，大家对主播还有直播的场景的真实度有很高的要求，这其中涉及到哪些技术来支撑？</p><p>&nbsp;</p><p>李凯：在这个领域，即构和我们的友商一直在路上，想把这个能力做得更好，这样的竞争对于生态圈和用户来说都是一件好事。实际上，我们在这个生态圈中，更强调向更高清、更流畅、更实时的方向不断精进，包括音视频互动、场景化 AI 降噪方面的技术能力，比如说家里小朋友上网课的时候，厨房很吵，这涉及到主动降噪和空间 3D 音效的技术。再具体来讲，比如沉浸式音频技术，即基于声道的音频（Channel-based Audio，CBA）、基于对象的音频（Object-based Audio，OBA）和基于场景的音频（Scene-based Audio，SBA），把这些核心底层的算法做好，能给普通用户带来完全不一样的体验。</p><p></p><h2>实时互动 RTI 能力解读</h2><p></p><p>&nbsp;</p><p>InfoQ：今年 10 月，即构提出了实时互动 RTI 来总结概括 ZEGO 的能力，这项能力应该怎么理解？</p><p>&nbsp;</p><p>李凯：作为即构的成员，首先要向所有友商致敬，其实所有概念的提出，都是为了能够将生态圈做得更好。当我们将 RTC 能力健全之后，在 RTC 的基础能力之上，叠加基于 RTC 的增值服务业务。实时互动 RTI（Real-Time Interaction）,代表一切还原现实甚至超越现实的实时互动场景下，所需要用到的产品和技术能力综合，除了核心的 RTC、IM、直播之外，还包括 Avatar、AI 视觉、状态同步等，这样的生态圈需要我们和友商一起做好。</p><p></p><p>实时互动 RTI 的技术综合主要包括更高清、更流畅、更实时，沉浸感、高保真、强交互，视频技术包括：（移动端实时插帧、客户端实时超分、主体分割与传输、弱光增强）、身临其境的音质（场景化 AI 降噪、空间音频、范围语音）、无限玩法&amp;场景（万人连麦、多人的状态同步等） 等丰富的维度方面。</p><p></p><p>下面来举一个具体应用的例子，我们的一款产品叫做小艺帮，是基于实时 RTC 的实时考试增值业务，主要提供给教育行业的客户。这个服务之所以存在，是因为高校已经不满足于产品仅有互动交流和点击屏幕进行考试的功能，而是需要更多的服务，比如说监控考生有没有作弊、有没有第三方答题、有没有人在考生的镜头前后，或者会不会有某个位置会存在作弊的可能。另外，在考试监控或者学习系统中，能不能在学生弹钢琴或者唱歌时实时打分或者纠错，告诉他们哪里做的不好，以上都是基于 RTC 做的增值服务业务，其实也有友商在做相同的事情，我们在共同精进这方面的技术。</p><p>&nbsp;</p><p>因为我们最典型的用户场景是基于移动端，前面讲到基于移动端的插帧、超分、抠图，忽然想到<a href=\"https://xie.infoq.cn/article/5b4119f95ea9817fc3bce360a\">低照度</a>\"光线增强技术，也就是在黑暗的房间视频时，当灯光关掉，如何看清楚用户的脸。当时东南亚客户提出要求：在灯光关掉、屏幕很暗时，要看清用户的脸，并且要保证 720P 30 帧的帧率，这在技术上存在非常大的挑战。不过后来我们攻克了这个难点，用 2 毫秒 720P 低照度增强解决这个问题，虽然低照度增强会带来一点噪声，但用户还是很满意的。</p><p>&nbsp;</p><p>即构在 AI 方面的能力，也有一些例子，比如说在<a href=\"https://xie.infoq.cn/article/838a6faafe4e3b1ee2dccc992\">超分</a>\"方面，我们的目标是尽可能覆盖更多机型，目前搭载骁龙 660 处理器的手机分辨率 640×480 两倍到 1280×960 大概 52 毫秒；搭载骁龙 855 处理器的手机分辨率 640×480 两倍到 1280×960 大概 20 毫秒，近期，我们的某个大客户需要用到 960×540 超分到 1080P，我们也能满足他们的实时场景需求。</p><p>&nbsp;</p><p>还有大家印象中可能比较简单的绿幕抠图其实也有很多技术难点，绿幕最典型的问题是颜色溢出，而客户提出了新的要求，既要保证时效，又要保证颜色不能溢出。这里面涉及到能不能抗噪、能不能将褶皱抠除干净，这些问题看起来简单，但是实际处理很有挑战，我们通过大小只有约 5KB 的三四个卷积模型满足了客户的要求，将大家认为简单但却没有做到很好的技术又深入挖掘把它做好。</p><p>&nbsp;</p><p>刚刚提到的 AI 语音降噪、人声检测、空间音频、万人连麦以及多人状态同步等等的探索，也是即构在丰富技术生态、增强用户在各个维度的体验的探索，同时也能提升即构方方面面的基础能力和增值服务能力。</p><p>&nbsp;</p><p>InfoQ：目前实时互动 RTI 在画质、音质以及玩法和场景方面都有非常突出的优势，想了解即构在实现这些能力的过程中，都遇到了哪些技术挑战？</p><p>&nbsp;</p><p>李凯：刚刚聊到的技术点，有基于传统技术的，也有基于深度学习技术的，下面举一个基于深度学习技术的例子——超分。</p><p>&nbsp;</p><p>超分的问题可以从哪些方面入手来解决？首先要明确，如果深度学习模型想在安卓机型运行起来，模型不能大。这是因为模型大、算子多的情况下，再好的深度学习推理引擎也无法提升速度；同时，模型大会占用过多的内存，超分是“增值业务”，RTC 才是基础能力，要避免内存占用大的情况发生。但是模型太小，超分效果会降下来，这就是问题所在，因此模型怎样设计，用知识蒸馏还是大模型训练小模型，这是模型设计方面的问题。</p><p>&nbsp;</p><p>第二是关于数据，在了解业务详细情况下，将数据蜕化的过程模拟出来，就能使超分上一个档次，甚至比使用小模型的效果更直接。</p><p>&nbsp;</p><p>最后，是模型训练、模型推理的量化问题，涉及到压缩、模型编译的工作，像专门针对超分做推理引擎优化，这是端到端的流程，需要有不同方面的技术人来把这个技术点做好，在这方面大厂可能会面临难以将跨部门资源集成起来的问题，很多厂商推理引擎优化是一个独立的部门，数据、模型设计、移动开发可能都分属不同的部门，如何将系统工程的力量整合起来，快速构建模型，在这个问题上，即构也在不断完善优化，希望给用户更好的体验。</p><p>&nbsp;</p><p>InfoQ：有没有更多具体案例可以给我们分享一下，RTI 能解决什么问题、适用于哪些场景？</p><p>&nbsp;</p><p>李凯：在互动直播场景里，语聊房、虚拟空间等都会用到 RTI 技术。以语聊房为例，它为用户提供一个匿名分享的交流空间，但是传统语聊房的匿名功能会带来一个问题，那就是用户构成会非常复杂，可能会有各种各样的背景噪声。另外，语聊房上麦人数有限，怎样构建情绪沟通以及肢体、姿态的沟通？对此，即构做了很多事情，包括降噪、空间音效、高保真技术的应用，同时，基于即构 Avatar 虚拟形象把人体动作、表情驱动起来，美化声音甚至情绪，实现比传统语聊房更佳的沟通体验。另外通过实时互动 RTI 可以突破传统 RTC 上麦人数的限制，让更多人自由发声。</p><p></p><h2>未来展望</h2><p></p><p>&nbsp;</p><p>InfoQ：基于元宇宙概念描绘的画面，以及音视频技术的进步，您认为未来还会出现哪些新的现象或者需求？</p><p>&nbsp;</p><p>李凯：目前已经可以看到一些场景和布局了，很典型的就是自动驾驶、远程巡检或者诊断，我了解到在工业 4.0 里面，带一个 VR 眼镜就能在工厂中远程指导用户，或者远程会诊；车险远程定损，目前定损需要按照定损员指示拍指定的位置，而远程定损则只需要工作人员带上 VR 眼镜，用户按照指示用手机绕着车拍，实时互动，效率会提升很多；此外教育信息化、远程签证方面也可能有应用。我认为 RTC 基础能力做到足够好、5G 网络发展足够好的情况下，还会出现很多现在无法想象的应用场景，包括智能机器人，人类可以通过监控智能机器人，让他们做事情，我记得日本有一个机器人可以自己盖房子，随着技术的发展，这些应用会超出我们的想象。</p><p>&nbsp;</p><p>InfoQ：围绕刚刚您提到的技术趋势，即构在后续有哪些考虑和布局？</p><p>&nbsp;</p><p>李凯：技术的发展最终是要解决客户的问题，因此即构会把客户的需求和痛点记在心上，尽可能地提升基础能力。就像前面说到的，在前瞻性的技术上我们一直都有研究和投入。2022 年我们在国际期刊 TOMM 上也发表了文章，在与 RTC 相关的音视频技术、基于 AI 高保真技术、人脸三维重建，以及高保真 NeRF 等方向上，我们都有投入和研究。同时我们也希望储备自己的能力，希望随着硬件的普及化以及技术成本逐渐降低，我们能很快地给用户提供一个解决用户痛点的方案，与友商一起共建生态圈。</p><p></p><h2>互动 Q&amp;A</h2><p></p><p>&nbsp;</p><p>InfoQ：个人理解像语音降噪这类技术大公司都做标准化了，一般的公司很难做起来，如何破局呢？</p><p>&nbsp;</p><p>李凯：这是一个好问题。聊语音降噪就会涉及到深度学习的内容，我们在一个场景下用数据去训练，但是换一个场景效果不一定好，举一个典型的例子就是，当时我们用第三方语音识别，而第三方语音识别中数据库来源均为成人的声音，但是用户的场景是儿童语音场景，因此识别率非常低，只有 70-80%；当把儿童声音的数据库加进来之后，识别率提升到 90%，这是非常典型的情况。AI 目前的泛化能力是有限的，很多情况下大厂希望做到标准化，也就是在某个场景训练的数据可以用到其他场景，但是目前是做不到的，只能够在特定的场景实现，因此这也给了我们很多中小厂商和大厂 PK，甚至可以做得比大厂更好的机会点。</p><p>&nbsp;</p><p>InfoQ：做了两年驱动开发，想转行进音视频，从哪些技术入手，有什么建议吗？</p><p>&nbsp;</p><p>李凯：其实我也是转行的，我刚毕业的时候在南昌大学当了一年数学老师，后来转行做码农，刚开始做算法相关的工作，后来转到了音视频行业中，刚开始做传统音视频处理技术，后来做 AI 技术，然后做框架推理引擎优化、设计模型。我的建议是如果想要转行，先把音视频技术中某些单点做好，或者能够把别人的 demo 跑通，去理解代码和算法，然后基于用户的场景优化这个算法。第二是将不同厂商的优缺点对比琢磨透，选择好路线和自己的定位，先把单个技术点做好，再拓展做其他的东西。</p>",
    "publish_time": "2023-01-30 15:48:06",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Java 自动化探针技术的核心原理和实践",
    "url": "https://www.infoq.cn/article/JYWWVhcGCWL7vGK1RIap",
    "summary": "<p></p><h2>JVMTI 技术</h2><p></p><p>JVM 在设计之初，就考虑到了虚拟机状态的监控、程序 Debug、线程和内存分析等功能。</p><p>&nbsp;</p><p>在JDK1.5 之前，JVM规范就定义了JVMPI（Java Virtual Machine Profiler Interface）也就是JVM分析接口以及JVMDI(Java Virtual Machine Debug Interface)也就是JVM调试接口，JDK1.5 以及以后的版本，这两套接口合并成了一套，也就是Java Virtual Machine Tool Interface，就是JVMTI 。通过JVMTI 可以探查JVM内部的一些运行状态，甚至控制JVM应用程序的执行。</p><p>&nbsp;</p><p>JVMTI 大体声明支持以下功能：</p><p></p><p>1. Java Heap与GC</p><p>获取所有类的信息，对象信息，对象引用关系，Full GC开始/结束，对象回收事件等。</p><p></p><p>2. 线程与堆栈</p><p>获取所有线程的信息，线程组信息，控制线程（start,suspend,resume,interrupt…）, </p><p>Thread Monitor(Lock)，得到线程堆栈，控制出栈，方法强制返回，方法栈本地变量等。</p><p></p><p>3. Class &amp; Object &amp; Method &amp; Field 元信息</p><p>Class信息，符号表，方法表，fields信息，Method信息等，Object信息。</p><p>redefine class（hotswap）, retransform class 这里看到JVMTI 设计强大地方，他可以重新定义类对象！后面会聊到。</p><p></p><p>4. 工具类</p><p>线程CPU 消耗，ClassLoader路径修改，系统属性获取等。</p><p>&nbsp;</p><p>这里需要注意的是：</p><p>&nbsp;</p><p>JVMTI是一套JVM的接口规范，不同的JVM实现方式可以不同，有的JVM提供了拓展性的功能，比如 openJ9，当然也可能存在JVM不提供这个接口的实现。JVMTI提供的是Native方式调用的API，也就是常说的JNI方式。JVMTI接口用C/C++的语言提供，最终以动态链接库的形式由JVM加载并运行</p><p>&nbsp;</p><p>使用JNI方式调用JVMTI接口访问目标虚拟机的大体流程图如下：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/35/35961ac0e257ecd62409a5390b01639d.png\" /></p><p></p><p>&nbsp;</p><p>其中，jvmti.h头文件中定义了 JVMTI 接口提供的方法，我们简单看看 JDK 7 里面源代码一些重要方法：</p><p>&nbsp;</p><p></p><blockquote><a href=\"https://github.com/openjdk-mirror/jdk7u-jdk/blob/master/src/share/javavm/export/jvmti.h\">https://github.com/openjdk-mirror/jdk7u-jdk/blob/master/src/share/javavm/export/jvmti.h</a>\"</blockquote><p></p><p></p><p><code lang=\"java\">  /*   64 : Get Method Name (and Signature) */\n  jvmtiError (JNICALL *GetMethodName) (jvmtiEnv* env,\n    jmethodID method,\n    char** name_ptr,\n    char** signature_ptr,\n    char** generic_ptr);\n\n\n  /*   65 : Get Method Declaring Class */\n  jvmtiError (JNICALL *GetMethodDeclaringClass) (jvmtiEnv* env,\n    jmethodID method,\n    jclass* declaring_class_ptr);\n\n\n  /*   66 : Get Method Modifiers */\n  jvmtiError (JNICALL *GetMethodModifiers) (jvmtiEnv* env,\n    jmethodID method,\n    jint* modifiers_ptr);</code></p><p>&nbsp;</p><p>JVMTI API 里序号 64、65 方法是从JVM中获取程序定义所有方法和相关类。66 比较有意思了，它获取修改后的方法，这说明借助JVMTI 可以动态修改Java 程序的方法。</p><p>&nbsp;</p><p><code lang=\"java\">  /*   152 : Retransform Classes */\n  jvmtiError (JNICALL *RetransformClasses) (jvmtiEnv* env,\n    jint class_count,\n    const jclass* classes);</code></p><p>&nbsp;</p><p>序号 152 是一个非常重要的方法，JVMTI的 RetransformClasses函数来完成类的重定义过程，这也说明 JVMTI 可以修改Java程序整个类。</p><p>&nbsp;</p><p><code lang=\"java\">// class_count - pre-checked to be greater than or equal to 0\n// class_definitions - pre-checked for NULL\njvmtiError JvmtiEnv::RedefineClasses(jint class_count, const jvmtiClassDefinition* class_definitions) {\n//TODO: add locking\n  VM_RedefineClasses op(class_count, class_definitions, jvmti_class_load_kind_redefine);\n  VMThread::execute(&amp;op);\n  return (op.check_error());\n} /* end RedefineClasses */</code></p><p></p><p>JVMTI 服务有两种打开方式：</p><p>&nbsp;</p><p>在Java进程启动的时候通过 -agentpath:=方式启动，path-to-agent 对应的JVMTI 接口实现的动态库文件的绝对路径，后面可以追加JVMTI 程序需要的参数。Linux动态库文件的后缀为 .so；运行时挂载 Attach ，然后加载JVMTI 接口实现的动态库文件。</p><p>&nbsp;</p><p>JVMTI 的Agent、Attach 用C、C++编写，具体感兴趣想实践的朋友可以看看下面的例子：<a href=\"https://github.com/liuzhengyang/jvmti_examples\">https://github.com/liuzhengyang/jvmti_examples</a>\"</p><p>&nbsp;</p><p>用 C、C++ 实现JVMTI 功能对大部分 Java 工程师的确强人所难。于是，Sun 公司出了 Java Agent，一个用Java 实现JVMTI 的方案，方案相当优雅和容易上手。</p><p></p><p></p><h2>Java Agent 技术由来</h2><p></p><p>&nbsp;</p><p>Java Agent 直译为 Java 代理，中文圈也流行另外一个称呼 Java 探针 Probe 技术。</p><p>&nbsp;</p><p>它在 JDK1.5 引入，是一种可以动态修改 Java 字节码的技术。Java 类编译后形成字节码被 JVM 执行，在 JVM 在执行这些字节码之前获取这些字节码的信息，并且通过字节码转换器</p><p>ClassFileTransformer 对这些字节码进行修改，以此来完成一些额外的功能。</p><p>&nbsp;</p><p>Java Agent 是一个不能独立运行 jar 包，它通过依附于目标程序的 JVM 进程，进行工作。</p><p>&nbsp;</p><p><code lang=\"java\">//Java Agent 和目标进程一起启动模式\njava -javaagent:myagent.jar=mode=test Test</code></p><p>&nbsp;</p><p>Agent 启动拦截提供以下两种方式。</p><p>&nbsp;</p><p>一种是程序运行前：在Main方法执行之前，通过一个叫 premain方法来执行</p><p>启动时需要在目标程序的启动参数中添加 -javaagent参数，Java Agent 内部通过注册 ClassFileTransformer ，这个转化器在Java 程序 Main方法前加了一层拦截器。在类加载之前，完成对字节码修改。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6c/6cc4e0b481ec7a2c0527111f6526a778.png\" /></p><p></p><p>Premain 完整工作流程图</p><p>&nbsp;</p><p>另一种是程序运行中修改，需通过JVM中 Attach技术实现，Attach的实现也是基于 JVMTI</p><p>总结下，Java Agent 具备以下的能力：</p><p>&nbsp;</p><p>Java Agent 能够在加载 Java 字节码之前拦截并对字节码进行修改;Java Agent 能够在 Jvm 运行期间修改已经加载的字节码。</p><p>&nbsp;</p><p></p><h3>Java Agent 的价值</h3><p></p><p>&nbsp;</p><p>Java Agent 有着成熟的技术架构和对字节码通用的重写能力。它应用场景非常广泛：</p><p>&nbsp;</p><p>IDE 的调试功能，例如 Eclipse、IntelliJ IDEA；热部署功能，例如 JRebel、XRebel、spring-loaded；各种线上诊断工具，例如 Btrace、Greys，国内阿里的 Arthas；各种性能分析工具，例如 Visual VM、JConsole 等；全链路性能检测工具，例如 OpenTelemetry、Skywalking、Pinpoint等。</p><p>&nbsp;</p><p>接下来，我们用案例实现性能检测工具的 Java Agent 探针。</p><p>&nbsp;</p><p></p><h3>Java Agent 和 JVMTI 关系</h3><p></p><p>&nbsp;</p><p>我们大致了解下Java Agent 底层源代码实现过程：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/31/3165f240fe60107db60db50b7ae4d2a6.png\" /></p><p></p><p>&nbsp;</p><p>首先弄清几个概念。</p><p></p><h4>JVMTIAgent</h4><p></p><p>&nbsp;</p><p>JVMTIAgent 是一个动态库，它可以利用JVMTI暴露出的一些接口来实现一些特殊的功能。我们常用Eclipse、Idea等IDE 工具代码调试就是利用它。Java Agent 也是利用了其中一个JVMTIAgent 来实现的。在Linux里面，这个库叫做libinstrument.so，在BSD系统中叫做libinstrument.dylib，该动态链接库在{JAVA_HOME}/jre/lib/目录下。因为源代码里面add_init_agent函数里面传递进去的是一个叫做 instrument的字符串，所以也称它为instrument 动态库，对应启动Agent 称为 Instrument Agent。</p><p>&nbsp;</p><p></p><h4>Instrument 动态链接库</h4><p></p><p>&nbsp;</p><p>Instrument 支持使用Java Instrumentation API 来编写Java Agent。</p><p>&nbsp;</p><p>Java Instrumentation : 在Jdk1.5 后，Java语言中提供的调用动态库的 Java API 接口 。</p><p></p><p>在Instrument 中有一个非常重要的类称为：JPLISAgent（Java Programming Language Instrumentation Services Agent），它的作用是初始化所有通过Java Instrumentation API编写的Agent。很容易猜到，Java Instrumentation API 其实就是底层调用JVMTI。</p><p>&nbsp;</p><p>JVMTIAgent 包含这个几个基本函数：</p><p><code lang=\"java\">JNIEXPORT jint JNICALL\nAgent_OnLoad(JavaVM *vm, char *options, void *reserved);\n \nJNIEXPORT jint JNICALL\nAgent_OnAttach(JavaVM* vm, char* options, void* reserved);\n\n\nJNIEXPORT void JNICALL\nAgent_OnUnload(JavaVM *vm); </code></p><p>&nbsp;</p><p>Agent_OnLoad如果Agent是在目标JVM 启动时加载(通过VM 参数 -agentpath:=方式)，在启动过程中会去执行Agent 里Agent_OnLoad函数；Agent_OnAttach如果Agent 通过Attach 方法启动，执行Attach 的JVM会给目标JVM 进程发送Load 命令来加载 Agent，在加载过程中调用就是Agent_OnAttach函数；Agent_OnUnload在Agent 做卸载的时候调用。</p><p>&nbsp;</p><p>Instrument 实现了Agent_OnLoad和Agent_OnAttach 两方法，所以 Java Agent 既可以在JVM启动时，也就是加载 Java 字节码之前启动，也可以在 JVM 运行时启动，这很有价值。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c4/c4d707f9c2da6a4bd7bb7e786f902edc.png\" /></p><p></p><p>大致画了一下 Java Agent 和 JVMTI 的关系</p><p></p><h3>Java Instrument Package</h3><p></p><p>上面提到实现Agent 需要 Instrument 动态链接库支持。Java 语言中也提供了调用动态库的 Java API 接口 Instrumentation。有了 Instrumentation，开发者可以轻松使用Java语言操作字节码，来实现Java Agent 相关功能，Instrument Package 大致结构：</p><p>&nbsp;</p><p><code lang=\"java\">java.lang.instrument.*\njava.lang.instrument.Instrumentation;\npublic interface Instrumentation {}</code></p><p></p><h4>Instrumentation 工作原理</h4><p></p><p>&nbsp;</p><p>SUN工具包(sun.instrument.InstrumentationImpl)编写了一些Native 方法，JDK里提供了这些Native方法的实现类(jdk\\src\\share\\instrument\\JPLISAgent.c)，通过JNI 方式访问JVMTI提供的方法，这些方法就是定义在jvmti.h头文件中。</p><p>&nbsp;</p><p></p><h4>Instrumentation 核心功能</h4><p></p><p>&nbsp;</p><p>Instrumentation 接口有一个最重要方法 addTransformer，它用于添加多个ClassFileTransformer。类似下面 Java Agent 实现的例子：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/25/25a7b706bc822f82c8bcf1b25e6e6924.png\" /></p><p></p><p>&nbsp;</p><p>ClassFileTransformer 中文类转换器，ClassFileTransformer提供了tranform()方法，用于对加载的类进行增强重定义，返回新的类字节码流。</p><p>&nbsp;</p><p>Instrumentation 有一个TransformerInfo 数组保存ClassFileTransformer，像拦截器链表一样，顺序的进行字节码的重定义。</p><p>&nbsp;</p><p><code lang=\"java\">// 说明：添加ClassFileTransformer\n// 第一个参数：transformer，类转换器\n// 第二个参数：canRetransform，经过transformer转换过的类是否允许再次转换\nvoid Instrumentation.addTransformer(ClassFileTransformer transformer, boolean canRetransform)\n\n\n// 说明：对类字节码进行增强，返回新的类字节码定义\n// 第一个参数：loader，类加载器\n// 第二个参数：className，内部定义的类全路径\n// 第三个参数：classBeingRedefined，待重定义/转换的类\n// 第四个参数：protectionDomain，保护域\n// 第五个参数：classfileBuffer，待重定义/转换的类字节码（不要直接在这个classfileBuffer对象上修改，需拷贝后进行）\n// 注：若不进行任何增强，当前方法返回null即可，若需要增强转换，则需要先拷贝一份classfileBuffer，在拷贝上进行增强转换，然后返回拷贝。\nbyte[] ClassFileTransformer.transform(ClassLoader loader, String className, Class classBeingRedefined, ProtectionDomain protectionDomain, byte classfileBuffer)</code></p><p>&nbsp;</p><p>下面我们写Java Agent时候，就会实现这两个重要的方法。</p><p>&nbsp;</p><p>通过 Instrument API 方式使用到了JVMTI提供部分功能，对开发者来说，主要提供的是对JVM加载的类字节码进行增强操作，等价于有了全局、动态修改Java程序代码的能力。</p><p>&nbsp;</p><p></p><h3>总结</h3><p></p><p>&nbsp;</p><p>到这里，是不是想到：我们是否可以通过Agent 在所有类方法中插入额外的字节码，这些字节码功能就是获取程序内部数据，然后上报给某个地方。是的，我们很多通用的Java 监控、Debug、日志记录工具就是基于它来实现的。而且，插入的字节码是附加的，这些更变不会修改原来程序正常逻辑和状态，只是会有一些性能损耗，对应用程序本身基本是安全可靠的。</p><p>&nbsp;</p><p></p><h4>JVMTI 方式 和 Java Instrument 对比</h4><p></p><p></p><p></p><p></p><h2>Agent启动方式</h2><p></p><p></p><h3>程序运行前加载</h3><p></p><p>&nbsp;</p><p>目标JVM 启动时指定-javaagent:xxx.jar参数来启动 Java Agent, 这里 xxx.jar 是探针的JAR包. 比如 OpenTelemetry 运行Java 探针的指令：</p><p><code lang=\"java\">java -javaagent:path/to/opentelemetry-javaagent.jar \\\n     -jar myapp.jar</code></p><p>&nbsp;</p><p>程序启动时，优先加载Java Agent，执行里面的 premain方法。这个时候，其实大部分的类没有被加载。</p><p>&nbsp;</p><p></p><h4>Jar 打包规则</h4><p></p><p>&nbsp;</p><p>探针的 JAR包需要做以下配置。</p><p>&nbsp;</p><p>JAR包里MANIFEST.MF文件添加一个Premain-Class属性，指定一个实现了premain方法的类，加入Can-Redefine-Classes 和 Can-Retransform-Classes 选项</p><p>MANIFEST.MF 大致如下配置：</p><p><code lang=\"java\">PreMain-Class: AgentMain\nCan-Redefine-Classes: true\nCan-Retransform-Classes: true</code></p><p>&nbsp;</p><p>premain 方法声明：</p><p><code lang=\"java\">// JVM启动时调用，其执行时Class 还未加载到JVM\npublic static void premain(String agentArgs, Instrumentation inst);\npublic static void premain(String agentArgs);</code></p><p>&nbsp;</p><p>下面是我们实现premain 方法的一个测试类：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/72/72894bb92001a165bacd66ca72c5df21.png\" /></p><p></p><p>&nbsp;</p><p></p><h3>Premain 方法工作原理</h3><p></p><p></p><p>目标JVM 启动时，运行JNI 的 Agent_OnLoad 函数，执行如下步骤：</p><p>&nbsp;</p><p>创建 InstrumentationImpl 对象；监听 ClassFileLoadHook 事件；调用 InstrumentationImpl 的 loadClassAndCallPremain 方法，此方法里去Agent Jar 包中找到MANIFEST.MF声明的Premain-Class类，执行类里面的 premain方法；premain方法里面，我们可以调用Java Instrumentation API 完成字节码增强功能。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/07/072ee6032330d6cf9bb2086dbda6b37b.png\" /></p><p></p><h3>复习Java Byte-code 字节码概念</h3><p></p><p>&nbsp;</p><p>维基百科字节码中文解释：</p><p>&nbsp;</p><p></p><blockquote>字节码（英语：Bytecode）通常指的是已经经过<a href=\"https://zh.wikipedia.org/wiki/%E7%BC%96%E8%AF%91\">编译</a>\"，但与特定<a href=\"https://zh.wikipedia.org/wiki/%E6%A9%9F%E5%99%A8%E7%A2%BC\">机器代码</a>\"无关，需要<a href=\"https://zh.wikipedia.org/wiki/%E7%9B%B4%E8%AD%AF%E5%99%A8\">解释器</a>\"转译后才能成为<a href=\"https://zh.wikipedia.org/wiki/%E6%A9%9F%E5%99%A8%E7%A2%BC\">机器代码</a>\"的<a href=\"https://zh.wikipedia.org/wiki/%E4%B8%AD%E9%96%93%E8%AA%9E%E8%A8%80\">中间代码</a>\"。字节码通常不像<a href=\"https://zh.wikipedia.org/wiki/%E6%BA%90%E7%A2%BC\">源码</a>\"一样可以让人阅读，而是<a href=\"https://zh.wikipedia.org/wiki/%E7%B7%A8%E7%A2%BC\">编码</a>\"后的数值常量、引用、指令等构成的序列。&nbsp;字节码主要为了实现特定软件运行和软件环境、与硬件环境无关。字节码的实现方式是通过<a href=\"https://zh.wikipedia.org/wiki/%E7%B7%A8%E8%AD%AF%E5%99%A8\">编译器</a>\"和<a href=\"https://zh.wikipedia.org/wiki/%E8%99%9B%E6%93%AC%E6%A9%9F%E5%99%A8\">虚拟机</a>\"。编译器将源码编译成字节码，特定平台上的虚拟机将字节码转译为可以直接执行的指令。字节码的典型应用为<a href=\"https://zh.wikipedia.org/zh-cn/Java_bytecode\">Java bytecode</a>\"。</blockquote><p></p><p></p><p></p><blockquote>&nbsp;</blockquote><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ba/bad56c59c8bd3d856b4bc9b40a3d6140.png\" /></p><p></p><p>Java 程序运行原理</p><p>&nbsp;</p><p>Java Byte-code: Java语言写出的源代码首先需要编译成class文件，即字节码文件，然后被JVM加载并运行，每个class文件具有如下固定的数据格式：</p><p>&nbsp;</p><p><code lang=\"java\">ClassFile {\n    u4             magic;           // 魔数，固定为0xCAFEBABE\n    u2             minor_version;   // 次版本\n    u2             major_version;   // 主版本，常见版本：52对应1.8，51对应1.7，其他依次类推\n    u2             constant_pool_count;                     // 常量池个数\n    cp_info        constant_pool[constant_pool_count-1];    // 常量池定义\n    u2             access_flags;    // 访问标志：ACC_PUBLIC, ACC_INTERFACE, ACC_ABSTRACT等\n    u2             this_class;      // 类索引\n    u2             super_class;     // 父类索引\n    u2             interfaces_count;\n    u2             interfaces[interfaces_count];\n    u2             fields_count;\n    field_info     fields[fields_count];\n    u2             methods_count;\n    method_info    methods[methods_count];\n    u2             attributes_count;\n    attribute_info attributes[attributes_count];\n}</code></p><p>&nbsp;</p><p>class文件总是一个魔数开头，后面跟着版本号，然后就是常量定义、访问标志、类索引、父类索引、接口个数和索引表、字段个数和索引表、方法个数和索引表、属性个数和索引表。</p><p></p><p></p><h3>字节码增强技术</h3><p></p><p>&nbsp;</p><p>Agent 本质是通过操作字节码，动态修改运行时Java对象。</p><p>&nbsp;</p><p>我们把一类对现有字节码进行修改或者动态生成全新字节码文件的技术叫做字节码增强技术。</p><p>字节码增强技术的实现有很多方式，简单整理下目前比较成熟的一些操作字节码的框架。</p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/79/792d4f67257afe73ebc78044e9cd2213.png\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>JDK动态代理运行期动态的创建代理类，只支持接口；ASM一个 Java 字节码操控框架。它能够以二进制形式修改已有类或者动态生成类。不过ASM在创建class字节码的过程中，操纵的级别是底层JVM的汇编指令级别，这要求ASM使用者要对class组织结构和JVM汇编指令有一定的了解；Javassist一个开源的分析、编辑和创建Java字节码的类库（源码级别的类库）。Javassist是Jboss的一个子项目，其主要的优点，在于简单，而且快速。直接使用Java编码的形式，而不需要了解虚拟机指令，就能动态改变类的结构，或者动态生成类；Byte Buddy是一个较高层级的抽象的字节码操作工具，相较于ASM 而言。Byte Buddy 本身也是基于 ASM API 实现的。Byte Buddy以出色的性能，被著名的框架和工具（例如Mockito，Hibernate，Jackson，Google的Bazel构建系统等）使用。</p><p></p><h4>ASM</h4><p></p><p></p><p>ASM 可以直接产生二进制.class文件，也可以在类被加载入 Java 虚拟机之前动态改变类行为（也就是生成的代码可以覆盖原来的类也可以是原始类的子类）。ASM 从类文件中读入信息后，能够改变类行为，分析类信息，甚至能够根据用户要求生成新类。</p><p>&nbsp;</p><p>不过ASM在创建class字节码的过程中，操纵的级别是底层JVM的汇编指令级别，这要求ASM使用者要对class 组织结构和JVM汇编指令有一定的了解。ASM提供了两组API: Core API 和Tree API，Core API是基于访问者模式来操作类的，而Tree是基于树节点来操作类的。</p><p></p><p>简单写一个ASM 运行例子：</p><p><code lang=\"java\">public class ASMDemo extends ClassLoader{\n    public static  T getProxy(Class clazz) throws Exception {\n\n        ClassReader classReader = new ClassReader(clazz.getName());\n        ClassWriter classWriter = new ClassWriter(classReader, ClassWriter.COMPUTE_MAXS);\n        classReader.accept(new ClassVisitor(ASM5, classWriter) {\n            @Override\n            public MethodVisitor visitMethod(int access, final String name, String descriptor, String signature, String[] exceptions) {\n                // 方法过滤\n                if (!\"hi\".equals(name))\n                    return super.visitMethod(access, name, descriptor, signature, exceptions);\n                final MethodVisitor methodVisitor = super.visitMethod(access, name, descriptor, signature, exceptions);\n                return new AdviceAdapter(ASM5, methodVisitor, access, name, descriptor) {\n                    @Override\n                    protected void onMethodEnter() {\n                        // 执行指令；获取静态属性\n                        methodVisitor.visitFieldInsn(Opcodes.GETSTATIC, \"java/lang/System\", \"out\", \"Ljava/io/PrintStream;\");\n                        // 加载常量 load constant\n                        methodVisitor.visitLdcInsn(\"方法名: \"+name + \"  你被代理了，By ASM！\");\n                        // 在进入方法前，修改class，打印提示\n                        methodVisitor.visitMethodInsn(Opcodes.INVOKEVIRTUAL, \"java/io/PrintStream\", \"println\", \"(Ljava/lang/String;)V\", false);\n                        super.onMethodEnter();\n                    }\n                };\n            }\n        }, ClassReader.EXPAND_FRAMES);\n        byte[] bytes = classWriter.toByteArray();\n        return (T) new ASMDemo().defineClass(clazz.getName(), bytes, 0, bytes.length).newInstance();\n    }\n}  \n</code></p><p></p><p>我们通过ASM动态代理一个简单的测试接口和实现类：</p><p>&nbsp;</p><p><code lang=\"java\">public class HelloImpl implements Hello{\n    @Override\n    public String hi(String msg) {\n        return (\"hello \" + msg);\n    }}\npublic interface Hello {\n    public String hi(String msg);}</code></p><p>&nbsp;</p><p>写一个测试程序，通过ASM 代理模式，增强字节码后调用方法的效果：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/64/64e251f0c7193e21d6ccbf621391a9ec.png\" /></p><p></p><p>&nbsp;</p><p>当然，基于ASM开发门槛比较高一些，你必须了解一定汇编原理和指令。</p><p></p><h4>Javassist</h4><p></p><p></p><p>Javassist是一个开源的分析、编辑和创建Java字节码的类库。是由东京工业大学的数学和计算机科学系的 Shigeru Chiba （千叶滋）所创建的。它已加入了开放源代码JBoss 应用服务器项目，通过使用Javassist对字节码操作为JBoss实现动态\"AOP\"框架。</p><p>&nbsp;</p><p>Javassist 其主要的优点，在于简单，而且快速。直接使用Java编码的形式，而不需要了解虚拟机指令，就能动态改变类的结构，或者动态生成类。</p><p></p><p>参考文档：</p><p><a href=\"http://www.javassist.org/\">http://www.javassist.org/</a>\"<a href=\"https://github.com/jboss-javassist/javassist\">https://github.com/jboss-javassist/javassist</a>\"</p><p></p><p>下面我们有一个完整Java 探针实例用Javassist来实现。</p><p>&nbsp;</p><p></p><h4>Byte Buddy</h4><p></p><p>&nbsp;</p><p>Byte Buddy是致力于解决字节码操作和 Instrumentation API 的复杂性的开源框架。Byte Buddy 所声称的目标是将显式的字节码操作隐藏在一个类型安全的领域特定语言背后。通过使用 Byte Buddy，任何熟悉 Java 编程语言的人都容易地进行字节码操作。</p><p>&nbsp;</p><p>官网的示例展现了如何生成一个简单的类，这个类是 Object 的子类，并且重写了 toString 方法，用来返回“Hello World!”与原始的 ASM 类似，intercept 会告诉 Byte Buddy 为拦截到的指令提供方法实现。</p><p>&nbsp;</p><p><code lang=\"java\">Class<!--?--> dynamicType = new ByteBuddy()\n  .subclass(Object.class)\n  .method(ElementMatchers.named(\"toString\"))\n  .intercept(FixedValue.value(\"Hello World!\"))\n  .make()\n  .load(getClass().getClassLoader())\n  .getLoaded();\nSystem.out.println(dynamicType.getSimpleName());\n// 输出：Object$ByteBuddy$ilIxkTl1</code></p><p>Demo 来源 bytebuddy.net</p><p></p><p></p><h4>字节码增强工具对比</h4><p></p><p></p><p></p><p>&nbsp;</p><p></p><h3>一个完整的Java Agent探针实现过程</h3><p></p><p></p><h4>目标&nbsp;</h4><p></p><p></p><p></p><blockquote>实现一个简单性能工具，通过探针统计Java程序所有方法的执行时间。</blockquote><p></p><p>&nbsp;</p><p>1. 构建 Maven 项目工程，添加 MANIFEST.MF , 目录大致如下。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/00/001e6aef7748821312744723afa07800.png\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>在 MANIFEST.MF 文件中定义Premain-Class属性，指定一个实现类。类中实现了Premain方法，这就是Java Agent 在类加载启动入口。</p><p>&nbsp;</p><p><code lang=\"java\">Manifest-Version: 1.0\nPremain-Class: com.laziobird.MyAgentDemo\nAgent-Class: com.laziobird.MyAgentDemo\nCan-Redefine-Classes: true\nCan-Retransform-Classes: true</code></p><p>&nbsp;</p><p>Premain-Class包含Premain方法的类；Can-Redefine-Classes为true时表示能够重新定义Class；Can-Retransform-Classes为true时表示能够重新转换Class，实现字节码替换。</p><p>&nbsp;</p><p>2. 构建Premain方法。</p><p>&nbsp;</p><p><code lang=\"java\">public class MyAgentDemo {\n    // JVM 启动时，Agent修改字节码\n    public static void premain(String args, Instrumentation inst) {\n        System.out.println(\" premain agent loaded !\");\n        inst.addTransformer(new PreMainTransformerDemo());\n        System.out.println(\" agent addTransformer start !\");\n    }\n ....   \n}</code></p><p>&nbsp;</p><p>我们实现Premain方法类叫 MyAgentDemo，里面添加一个类转化器 PreMainTransformerDemo，这个转化器具体来实现统计方法调用时间。</p><p>&nbsp;</p><p>3. 编写类转换器。</p><p>&nbsp;</p><p>在编写类转化器时，我们通过Javassist 来具体操作字节码，首先pom.xml 里面添加依赖：</p><p><code lang=\"java\">\n   org.javassist\n   javassist\n   3.25.0-GA\n</code></p><p>&nbsp;</p><p>接下来具体实现：</p><p><code lang=\"java\">public class PreMainTransformerDemo implements ClassFileTransformer{\n   final static String prefix = \"\\nlong startTime = System.currentTimeMillis();\\n\";\n   final static String postfix = \"\\nlong endTime = System.currentTimeMillis();\\n\";\n   @Override\n   public byte[] transform(ClassLoader loader, String className, Class<!--?--> classBeingRedefined,\n                           ProtectionDomain protectionDomain, byte[] classfileBuffer){\n       // className 默认格式 com/laziobird 替换 com.laziobird\n       className = className.replace(\"/\", \".\");\n       //java自带的方法不进行处理,不是特别类的方法也不处理\n       if(className.startsWith(\"java\") || className.startsWith(\"sun\")|| !className.contains(\"com.laziobird\")){\n           return null;\n       }\n       CtClass ctclass = null;\n       try {\n           // 使用全称,用于取得字节码类&lt;使用javassist&gt;\n           ctclass = ClassPool.getDefault().get(className);\n           for(CtMethod ctMethod : ctclass.getDeclaredMethods()){\n               String methodName = ctMethod.getName();\n               // 新定义一个方法叫做比如sayHello$old\n               String newMethodName = methodName + \"$old\";\n               // 将原来的方法名字修改\n               ctMethod.setName(newMethodName);\n               // 创建新的方法，复制原来的方法，名字为原来的名字\n               CtMethod newMethod = CtNewMethod.copy(ctMethod, methodName, ctclass, null);\n               // 构建新的方法体\n               StringBuilder bodyStr = new StringBuilder();\n               bodyStr.append(\"{\");\n               bodyStr.append(\"System.out.println(\\\"==============Enter Method: \" + className + \".\" + methodName + \" ==============\\\");\");\n               //方法执行前，定义一个时间变量，记录方法开始前时间\n               bodyStr.append(prefix);\n               bodyStr.append(newMethodName + \"($);\\n\");// 调用原有代码，类似于method();($)表示所有的参数\n               //定义方法完成时间变量\n               bodyStr.append(postfix);\n               //方法完成后，运算方法执行时间\n               bodyStr.append(\"System.out.println(\\\"==============Exit Method: \" + className + \".\" + methodName + \" Cost:\\\" +(endTime - startTime) +\\\"ms \" + \"===\\\");\");\n               bodyStr.append(\"}\");\n               // 新方法字节码替换原来的方法字节码\n               newMethod.setBody(bodyStr.toString());\n               ctclass.addMethod(newMethod);// 增加新方法\n           }\n           //返回新的字节流\n           return ctclass.toBytecode();\n       } catch (Exception e) {\n           e.printStackTrace();\n       }\n       return null;\n   }</code></p><p>&nbsp;</p><p>这段程序等价于：把指定Java类下所有方法进行了如下转换，重新生成字节码加载执行。</p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8a/8a90dbd42ece50a407fc530f3608c78a.png\" /></p><p></p><p>&nbsp;</p><p>4. 打包生成Java Agent的Jar包。</p><p>&nbsp;</p><p>在pom.xml配置好maven assembly，进行编译打包。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/05/05932c9f193e1b18849e69ebd45c09d3.png\" /></p><p></p><p>&nbsp;</p><p>5. 写一个Java测试程序，验证探针是否生效。</p><p>&nbsp;</p><p>类AgentTest 有两个简单方法test、testB。</p><p>&nbsp;</p><p>为了演示，其中testB 调用了另外一个类ClassC 的 methodD方法。</p><p>&nbsp;</p><p>可以看到，类包名是 com.laziobird，刚才的Agent 只会对com.laziobird 的类起作用。</p><p>&nbsp;</p><p><code lang=\"java\">package com.laziobird;\npublic class AgentTest {\n    public void test() {\n        System.out.println(\"hello the method: agentTest.test \");\n    }\n    public void testB() {\n        ClassC c = new ClassC();\n        c.methodD();\n        System.out.println(\"hello the method: agentTest.testB \");\n    }\n    public static void main(String[] args) {\n        AgentTest agentTest = new AgentTest();\n        agentTest.test();\n        agentTest.testB();\n    }\n}\npackage com.laziobird;\npublic class ClassC {\n    public void methodD(){\n        try {\n            System.out.println(\" methodD start!\");\n            Thread.sleep(500);\n        } catch (InterruptedException e) {\n            throw new RuntimeException(e);\n        }\n    }\n}</code></p><p>&nbsp;</p><p>我们给测试程序打成可执行的Jar包，Jar 指定默认运行的类是 AgentTest 。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b6/b6e9c79d96981a8ba03cd2da415218a1.png\" /></p><p></p><p>&nbsp;</p><p>运行测试程序，通过-javaagent启动我们写的 Java Agent 探针。</p><p><code lang=\"java\">java -javaagent:/path/agentdemo/target/javaagent-demo-0.0.1-SNAPSHOT-jar-with-dependencies.jar  \n-jar  /path/gitproject/TestAgentDemo/out/artifacts/TestAgentDemo_jar/TestAgentDemo.jar</code></p><p></p><h4>运行效果</h4><p></p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/21/21f0e57daf9b6ae6a58ede6bf04f8f5c.png\" /></p><p></p><p>&nbsp;</p><p></p><h2>程序运行时加载</h2><p></p><p>&nbsp;</p><p>在JDK1.6 版本中，Java Agent 支持了可以在JVM运行时动态修改 Java 字节码的能力。这种能力需要JVM Attach 来实现。</p><p>&nbsp;</p><p>JVM Attach：简单来说就是JVM提供一种JVM进程间通信的机制。它能让一个进程传命令给另外一个进程，并让它执行内部的一些操作。</p><p>&nbsp;</p><p>常见场景，比如做故障定位时，有可能我们觉得某些Java 的线程程序卡住了。于是想把一个JVM进程的线程Dump出来。那么我们会跑一个JStack的进程，然后传进程Id 参数，告诉Jstack指定哪个进程进行线程Dump。Attach 机制完成两个进程间如何通信和传输协议的定义。</p><p>&nbsp;</p><p></p><h3>JVM Attach 实现原理</h3><p></p><p>&nbsp;</p><p>存在一个Attach Listener 线程，监听其他JVM的Attach 请求，其通信方式基于socket，JVM Attach机制底层从Kernel 到 Application 层完整流程图。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/44/442a193579a7cf08d2d011dcbb003d2d.png\" /></p><p></p><p>&nbsp;</p><p>具体C语言源代码实现，可以参考李嘉鹏这篇深入分享：</p><p><a href=\"http://lovestblog.cn/blog/2014/06/18/jvm-attach/?spm=ata.13261165.0.0.26d52428n8NoAy\">http://lovestblog.cn/blog/2014/06/18/jvm-attach/?spm=ata.13261165.0.0.26d52428n8NoAy</a>\"</p><p>&nbsp;</p><p></p><h3>Agentmain 工作原理</h3><p></p><p>&nbsp;</p><p>Java Agent在运行时和启动时加载机制其实很像，主要区别在Agent 进行字节码增强前，对于拦截入口不同而已。一个叫Premain，一个叫Agentmain 。 这一点很好理解：启动时，Agent 直接通过启动参数-javaagent吸附于当前JVM 进程。运行时加载，其实当前JVM进程已经启动了。这时借助另一个JVM进程通信，调用Attach API 再把Agent 启动起来。后面的字节码修改和重加载的过程那就是一样的。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dd/dd3f9c8351c1dfc6e3fa3a86dd8928f0.png\" /></p><p></p><p></p><h4>运行时Java Agent 配置</h4><p></p><p>和启动时代理类似：</p><p>&nbsp;</p><p>JAR包的MANIFEST.MF清单文件中定义Agent-Class属性，指定一个实现类。加入Can-Redefine-Classes和 Can-Retransform-Classes 选项；JAR包中包含清单文件中定义的这个类，类中包含agentmain方法，方法逻辑自己实现JAR包内对应的MANIFEST.MF有如下配置：</p><p><code lang=\"java\">Agent-Class: com.laziobird.MyAgentDemo\nCan-Redefine-Classes: true\nCan-Retransform-Classes: true</code></p><p>&nbsp;</p><p>需要注意：agentmain方式由于是采用Attach 机制，被代理的目标程序VM 已经先于Agent 启动，其所有类已经被加载完成。这个时候需要执行 Instrumentation 的</p><p>retransformClasses方法让类进入重新转换，重定义的过程：它会激活类执行ClassFileTransformer列表中的回调，完成字节码操作，最后让类加载器重新加载。</p><p></p><p></p><h3>Attach Agentmain 和 PreMain 对比</h3><p></p><p>1. 字节码增强的限制。</p><p>&nbsp;</p><p>虽然运行时Agent可以在JVM 运行时动态的修改某个类的字节码，但是为了保证JVM的正常运行，新定义的类相较于原来的类需要满足：</p><p></p><p>父类是同一个实现的接口数也要相同，并且是相同的接口类访问符必须一致字段数和字段名要一致新增或删除的方法必须是private static/final的可以修改方法内部代码</p><p></p><p></p><p>2. 显式调用重定义方法。</p><p>&nbsp;</p><p>因为JVM启动时，字节码 Class文件已经提前生成好再进行Class Load过程。但是JVM 运行后，把已经加载后的类动态修改 redefine an already loaded class，我们修改完类定义后，显式在内存中进行重加载 reload Class。</p><p>&nbsp;</p><p>Java Agent 显式给我们提供了retransformClasses方法，下面我摘取它的详细说明。</p><p>&nbsp;</p><p><code lang=\"java\">void retransformClasses(Class<!--?-->... classes) {}\n/**\nReturns whether or not the current JVM configuration supports redefinition of classes. The ability to redefine an already loaded class is an optional capability of a JVM. Redefinition will only be supported if the Can-Redefine-Classes manifest attribute is set to true in the agent JAR file (as described in the package specification) and the JVM supports this capability. During a single instantiation of a single JVM, multiple calls to this method will always return the same answer.**/</code></p><p>&nbsp;</p><p></p><h3>一个基于Attach的Java Agent 探针实现过程</h3><p></p><p></p><h3>目标</h3><p></p><p></p><p></p><blockquote>实现一个简单性能工具，通过Java Agent 探针统计Java应用程序下所有方法的执行时间。</blockquote><p></p><p>&nbsp;</p><p>1. 还是之前 Maven 项目工程，在 MANIFEST.MF 文件中定义Agentmain-Class属性，指定一个实现类。类中实现了Agentmain方法，这就是Java Agent 在JVM运行时加载的启动入口：</p><p><code lang=\"java\">Agent-Class: com.laziobird.MyAgentDemo</code></p><p>&nbsp;</p><p>2. 构建Agentmain方法。</p><p>&nbsp;</p><p><code lang=\"java\">public class MyAgentDemo {\n  // JVM运行时，Agent修改字节码\n  public static void agentmain(String args, Instrumentation inst) {\n      System.out.println(\" agentmain agent loaded !\");\n      Class[] allClass = inst.getAllLoadedClasses();\n      for (Class c : allClass) {\n          inst.addTransformer(new AgentMainTransformerDemo(), true);\n          try {\n          //agentmain 是JVM运行时，需要调用 retransformClasses 重定义类 ！！\n          inst.retransformClasses(c);\n               } catch (UnmodifiableClassException e) {\n                 throw new RuntimeException(e); }\n          }    }\n ....   \n}</code></p><p>&nbsp;</p><p>我们在类 MyAgentDemo实现agentmain方法，里面添加一个类转化器AgentMainTransformerDemo，这个转化器插入实现统计方法调用时间的字节码片段。</p><p>&nbsp;</p><p><code lang=\"java\">public class AgentMainTransformerDemo implements ClassFileTransformer {\n    @Override\n    public byte[] transform(ClassLoader loader, String className, Class<!--?--> classBeingRedefined,\n                            ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException {\n        className = className.replace(\"/\", \".\");\n        //这次我们用另外一种简洁API方法修改字节码\n        if (className.contains(\"com.laziobird\")) {\n            try {\n                // 得到类信息\n                CtClass ctclass = ClassPool.getDefault().get(className);\n                for (CtMethod ctMethod : ctclass.getDeclaredMethods()) {\n                    // 方法内部声明局部变量\n                    ctMethod.addLocalVariable(\"start\", CtClass.longType);\n                    // 方法前插入Java代码片段\n                    ctMethod.insertBefore(\"start = System.currentTimeMillis();\");\n                    String methodName = ctMethod.getLongName();\n                    ctMethod.insertAfter(\"System.out.println(\\\"\" + methodName + \" cost: \\\" + (System\" +\n                            \".currentTimeMillis() - start));\");\n                    // 方法结束尾部插入Java代码片段\n                    return ctclass.toBytecode();\n                }\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n        }\n        return null;\n    }\n}</code></p><p>&nbsp;</p><p>3. 重新打包生成新的Jar包。</p><p>&nbsp;</p><p>运行 maven assembly，进行编译打包。</p><p>&nbsp;</p><p>4. 写测试的Java程序。</p><p>&nbsp;</p><p>类AgentAttachTest 定义一个方法，为了方便查看Attach 效果，我们让JVM 主进程一直循环执行这个方法。同时为了区分，通过随机数改变方法的运行时间。这样看到探针每次统计结果也不同。类的包名是com.laziobird，Agent 只会对com.laziobird 的类起作用。</p><p>&nbsp;</p><p><code lang=\"java\">public void test(int x) {\n    try {\n        long sleepTime = x*1000;\n        Thread.sleep(sleepTime);\n        System.out.println(\"the method: AgentAttachTest.test | sleep time = \" + sleepTime+ \"ms\");\n    } catch (InterruptedException e) {\n        throw new RuntimeException(e);\n    }\n}\npublic static void main(String[] args) {\n    AgentAttachTest agentTest = new AgentAttachTest();\n    while (1==1){\n        int x = new Random().nextInt(10);\n        agentTest.test(x);\n    }\n}</code></p><p>&nbsp;</p><p>5. 编写一个演示 Attach 通信的JVM 程序，用于启动 Agent。</p><p>&nbsp;</p><p><code lang=\"java\">public class AttachJVM {\n    public static void main(String[] args) throws IOException, AttachNotSupportedException, AgentLoadException, AgentInitializationException {\n        // 获取运行中的JVM列表\n        List vmList = VirtualMachine.list();\n        // 我们编写探针的Jar包路径\n        String agentJar = \"/Users/jiangzhiwei/eclipse-workspace/agentdemo/target/javaagent-demo-0.0.1-SNAPSHOT-jar-with-dependencies.jar\";\n        for (VirtualMachineDescriptor vmd : vmList) {\n            // 找到测试的JVM\n            System.out.println(\"vmd name: \"+vmd.displayName());\n            if (vmd.displayName().endsWith(\"AgentAttachTest\")) {\n                // attach到目标ID的JVM上\n                VirtualMachine virtualMachine = VirtualMachine.attach(vmd.id());\n                // agent指定jar包到已经attach的JVM上\n                virtualMachine.loadAgent(agentJar);\n                virtualMachine.detach();\n}}}}</code></p><p></p><h3>运行效果</h3><p></p><p>&nbsp;</p><p>1.&nbsp;运行测试的Java程序，为了方便，也可以不用打成Jar运行。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/34/34ee2f4a11939dea653bfbe05e2f9cfa.png\" /></p><p></p><p>&nbsp;</p><p>2.&nbsp;我们启动Attach 的JVM程序。它主要动作：</p><p></p><p>通过Attach API，找到要监听的JVM进程，我们称为VirtualMachine；VirtualMachine 借助Attach API 的LoadAgent方法将Agent 加载进来。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/61/6198a1fcd1e09b01b51889c98047e8e6.png\" /></p><p></p><p>&nbsp;</p><p>3.&nbsp;Agent 开始工作！我们回过头来看看探针在测试程序的运行效果。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2e/2ec027879f7f708a522095b28e3cb053.png\" /></p><p></p><p>&nbsp;</p><p>我们手写Java 探针在JVM 运行时也能动态改变字节码。</p><p></p><h2>Github 案例地址</h2><p></p><p>&nbsp;</p><p>为了方便大家上手实践，我贡献案例到Github，其实基于Java Agent 性能诊断工具、链路分析的Java 探针基本都是类似实现，大部分区别在于字节码增强实现的差异。</p><p>&nbsp;</p><p>当然，要求更高的性能和底层功能，可以直接编写C、C++的JVMT 动态链接库。</p><p>&nbsp;</p><p></p><blockquote>探针实现<a href=\"https://github.com/laziobird/java-agent-demo\">https://github.com/laziobird/java-agent-demo</a>\"测试程序<a href=\"https://github.com/laziobird/java-agent-demo/tree/main/Agentdemo\">https://github.com/laziobird/java-agent-demo/tree/main/Agentdemo</a>\"Attach 用例<a href=\"https://github.com/laziobird/java-agent-demo/tree/main/TestAgentDemo\">https://github.com/laziobird/java-agent-demo/tree/main/TestAgentDemo</a>\"本文的教程<a href=\"https://github.com/laziobird/java-agent-demo/tree/main/JVMAttach/\">https://github.com/laziobird/java-agent-demo/tree/main/JVMAttach</a>\"</blockquote><p></p><p>&nbsp;</p><p></p><h2>作者介绍</h2><p></p><p>蒋志伟，爱好技术的架构师，先后就职于阿里、Qunar、美团，前pmcaffCTO，现任Opentelemetry中国社区发起人，欢迎关注Github项目<a href=\"https://github.com/open-telemetry/docs-cn\">https://github.com/open-telemetry/docs-cn</a>\"。</p><p>&nbsp;</p><p>欢迎大家关注“Opentelemetry”公众号，这是中国区唯一官方技术公众号。</p>",
    "publish_time": "2023-01-30 19:03:49",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]