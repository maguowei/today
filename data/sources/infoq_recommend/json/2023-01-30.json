[
  {
    "title": "职业“倦怠”期开发者如何转变心态",
    "url": "https://www.infoq.cn/article/2pPSUdJjyrCRJOyFYr4t",
    "summary": "<p>大约有<a href=\"https://haystack-books.s3.amazonaws.com/Study+to+understand+the+impact+of+COVID-19+on+Software+Engineers+-+Full+Report.pdf\">83%的开发者</a>\"都称自己有倦怠感，他们工作中很多因素都阻碍了灵活的心态。而事实上，软件开发者往往是无限循环的、不断逼迫的死线的代名词。编程是项充满创造力的职业，但我们的大多时间都在处理影响生产力的困难任务上，这些任务不仅夺走了我们每日工作的快乐，还留下了满腹挫败。</p><p>&nbsp;</p><p>在最后一秒解决缺陷、死守既定的时限，这些常常让开发者倍感压力，但不断发展的数字世界也是另一个焦虑感的来源。</p><p>&nbsp;</p><p>业界新出现的技术常常会在一夜之间成为软件开发者必备的技能项，而要想在飞速发展的行业中取得成功，我们最好能时刻掌握业内最新工具。</p><p>&nbsp;</p><p>这点是指导开发团队的首席技术官（CTO）或高级领导需要协助的方面，改变旧的模式，激起增长心态，并帮助开发者变得更敏捷、更灵活。换句话说，就是变换心态。</p><p>&nbsp;</p><p>这个流行词在多个行业中都有使用，在像是<a href=\"https://hbr.org/2013/08/how-to-shift-a-mindset-in-your\">HBR</a>\"和<a href=\"https://www.forbes.com/sites/forbesagencycouncil/2022/04/08/the-power-of-the-changing-mindset/?sh=391e84dc492e\">福布斯</a>\"之类的刊物中也曾被提及。其理念在于，当我们处于一个发展如此之快的世界中，我们不能再被动接收变化，而要去掌握先机。在亚当·格兰特的书《重新思考》中曾写道：</p><p>&nbsp;</p><p></p><blockquote>“……我们需要和思考一样，花费同样多的时间在重新思考上。”</blockquote><p></p><p>&nbsp;</p><p>在本文中，我们将探讨软件工程团队所面临的障碍，以及要如何培养心态的改变。</p><p></p><h2>常见的误区</h2><p></p><p>在软件工程中谈论心态时，人们常常赞同的一种说法是：</p><p>&nbsp;</p><p></p><blockquote>“团队是否强大取决于其最弱的成员。”</blockquote><p></p><p>&nbsp;</p><p>一位负能量的团队成员消极怠工会给工作带来麻烦，致使团队其他成员士气低迷，积极性下降。留心这些成员，他们会为未完成的工作找接口、不接收自己的无能，并且还会让其他人也质疑自己的工作，从而让生产力飞速下降。</p><p>&nbsp;</p><p>而同样众所周知的是，公司自动化程度越高，开发者便越可能从工作中解放，抽出时间专注开发益于客户的数字创新。这正是BOS框架背后的理念之一，骄傲地说，我也是产品其中工程师之一。</p><p>&nbsp;</p><p>不过，目前很多开发者还是受困于排障等大量的手动任务中。像是代码编辑器、故障追踪器，还有让应用程序自动化部署运维的Kubernetes，类似的工具有很多，但企业迟迟未能接受。</p><p>&nbsp;</p><p>另一个影响因素是不切实际的死线，不仅影响了软件工程师的生活工作平衡，也对工程师们的积极性有极其消极的影响。对开发者而言，最好的投资就是自身的发展，尤其是在当前这个不断发展的技术领域。但工作加班和手动任务的重压之下，难怪开发者会没有动力学习新技能。</p><p>&nbsp;</p><p>综上这些因素都会影响开发人员的心态转换。那么领导团队能对此做些什么呢？</p><p></p><h2>鼓励求知若渴的文化</h2><p></p><p>微软的CEO，Satya Nadella提出的“<a href=\"https://cdn2.hubspot.net/hubfs/1927708/GrowthMindset_CSCollection_US_FN%20(2).pdf?__hstc=80578952.ccc32591d2a8ad08f21ba7ee8f9333c0.1666196011273.1666196011273.1666196011273.1&amp;__hssc=80578952.3.1666196011273&amp;__hsfp=4082474608&amp;hsCtaTracking=812a2c84-17c5-488f-be1c-54b59531beea%7C80c7f209-cd86-48a7-99c4-d97d5055a0ec\">科技巨头以持续学习为新重点的文化刷新</a>\"”，改变了员工的行为习惯。他称这是从“万事通”向“万事学”的转变。</p><p>&nbsp;</p><p>当每时每刻都有新鲜的人才出现时，那些拥有业内十年以上开发经验的“老古董”如果不提升自己的水平，很可能就会被后浪拍死在沙滩上。</p><p>&nbsp;</p><p>因此，在领导工程团队时，我们必须鼓励团队成员不断成长，将学习加入日常工作。从测试、教程和游戏开始，最终为开发者提供在不同技术栈上工作的机会。这是扩展团队知识的必要路线。</p><p>&nbsp;</p><p>举例来说，如果有位员工拿到了AWS认证的架构师资格，那这很好。在我们公司，我们会鼓励员工同样尝试其他云平台，以<a href=\"https://podcasts.apple.com/om/podcast/critical-skills-that-every-engineer-should-master/id1462366641?i=1000579439291\">更好地巩固自己在架构上的能力</a>\"。当然，这一切要建立在双方的意向上，不能强加给员工。</p><p>&nbsp;</p><p>因此，如果团队过度沉迷于单个工具，而不愿尝试其他方案，团队可能很快便被时代抛下，并阻碍公司的创新。而鼓励求知若渴文化的公司，意味着开发者会永远走在时代前沿，并为用户和利益相关者们找到最优的解决方案。</p><p></p><h2>从初创环境中学习</h2><p></p><p>大公司或企业或许不会期望开发者同时掌握多个技术栈，但初创公司不同。那么我们能从这些环境中学到什么呢？</p><p>&nbsp;</p><p>走在时代潮流之前的<a href=\"https://www.youtube.com/watch?v=a5b4nn3ZEVU\">史蒂夫·乔布斯</a>\"通过<a href=\"https://www.youtube.com/watch?v=a5b4nn3ZEVU\">像初创公司一样管理苹果</a>\"，改善了合作和团队精神。他称苹果为“全球最大的初创公司”，是可以无需监工或创立公司委员会，都能信任公司同事履行自己的承诺。</p><p>&nbsp;</p><p>在初创或小型公司中工作的最大优势在于，你可以身兼多职并了解公司各个方面。我在大学毕业后便以软件工程实习生的身份加入了现在的公司，并一直工作至今。在过去的十年间，我接触过很多技术，从网页和移动端开发到数据库、IoT应用，以及数据科学项目无所不有。我的经历让我很快构建了对多种技术栈的基础知识库，并能发现各类技术间的细微差别。</p><p></p><p>开发者常常会沉迷于特定工具，并想拿这个工具解决所有问题。但如果你手里只有一把锤子，那么所有东西在你眼里都只是钉子。在初创公司工作对开发者来说是个令人激动的机会，你可以从草稿开始，提出疯狂的主意，试图解决复杂问题，并成为团队的一份子。</p><p>&nbsp;</p><p>这和普通公司员工不同，你会成为构建公司未来的一份子。在这种环境下的开发者往往不再是孤狼，他们会学会在各个部门之间进行有效的沟通。</p><p>&nbsp;</p><p>因此，当在开发团队中建立心态转变时，可以向初创公司寻找灵感，并将求职简历中在初创公司工作过的经历看作是加分项。而如果你已经在初创公司工作了，那么学无止境，向你的竞争对手看齐。</p><p></p><h2>给处理问题设立一个期限</h2><p></p><p>给团队和自己一个解决特定问题的时间窗口，在窗口之后就去解决别的问题。开发者心态抑郁往往是因为他们在困难问题上折磨了好几小时，或被进展迟缓的bug卡住很久。</p><p>&nbsp;</p><p>他们常说，“这是工作的一部分”。但我有个明确的规定：如果团队在一个问题上工作超过了四小时，让他们出去溜一圈，然后带着转换好的心态回来继续工作。如果他们散心回来又花了四个小时而进展缓慢，那么就去向同事求助，肯定会有人能解决的。如果开发者们能学会寻求并接受其他团队成员的建议，那么这也将会激发心态的转变。</p><p>&nbsp;</p><p>这也是为什么开发者和工程师永远不应该只爱上一种编程语言或技术，他们应当不断前进。不断寻找问题的多种解法，那么你将没有上限，这是对工程师的基本期望。</p><p></p><h2>相信人人有责的方法</h2><p></p><p>开发团队中的所有人都应当相信工作所在组织的使命和远景，不仅如此，也还应对文化建立和维护的机会和机遇抱有同样的关注。这是有赖于每一位开发人员贡献的共同责任。</p><p>&nbsp;</p><p>一个默认的规则是，公司有义务为每位员工直接提供机会。我会永远感激我的前辈激励我挑战自我并尝试新事物，尤其是在国防部培训空军的软件开发和数据科学方面。</p><p>&nbsp;</p><p>团队成员总会有合适的时机遇见绝佳的机会。</p><p>&nbsp;</p><p>然而，自上而下的文化构建方法并不是万能的。我所相信的是<a href=\"https://hbr.org/2021/02/company-culture-is-everyones-responsibility\">建立人人有责的组织文化</a>\"，文化应当是被接受，而不仅仅是由领导所确立。员工同样应当表达出探索意愿及冒险精神，这才是好员工与杰出员工之间的差距。</p><p>&nbsp;</p><p>在采用远程办公之前，我们会每周五都在办公区选一位团队成员，分享软件开发、科技、云端、CI/CD，任何领域内的任何话题的科普。这会让开发者们走出自己的舒适区，也能让团队成员每周都学到一些新知识。</p><p>&nbsp;</p><p>团队领导也不应期望开发者仅遵循一个文化的条例。领导应当对资源进行分配，确保所有员工都对这种文化有理解，有批判，会维护文化的原则并对其进行补充。如此一来，我们也鼓励了开发者对这种文化的批判思考，促进了心态的转换。</p><p></p><h2>建立业务影响为先的心态</h2><p></p><p>培养<a href=\"https://hackernoon.com/the-secrets-to-building-a-world-class-software-engineering-team-to-create-cutting-edge-products\">以业务影响为优先</a>\"的心态同样会为工程团队带来改变，这是BOS框架成功的主要支柱之一，也是我所接受的培训理念。换句话说，这意味着一种集成文化的建立，开发者不仅要对工程本身有理解，同时也要对业务有认知，能够将技术看作是<a href=\"https://www.techopedia.com/pursuing-a-job-in-devops-what-every-engineer-must-know-in-2022/2/34867\">实现业务成果</a>\"的工具。</p><p>&nbsp;</p><p>这是因为拥有创业心态的工程师会希望在完成任务的同时做得对。当然，这也只是个夸张说法，但工程师大多都是完美主义者，但企业家却没时间过度思考，后者更倾向于授权，并只在必要的时间学习。工程团队不能忘记自己的项目最终是有商业目的的。</p><p>&nbsp;</p><p>工程负责人必须为每个项目构建商业案例，让非技术人员以及商业利益相关人都能参与并为决策提出自己的想法。同时，开发者也应与商业利益相关人、同僚，以及其他部门的同事相沟通，以实现技术带来的商业影响。如此一来，弥补了产品利益相关人与开发团队之间的鸿沟不仅帮助我在职业生涯中取得进展，也让我更容易适应新的角色。</p><p>&nbsp;</p><p>开发者可能会陷入无尽的循环，上一次学习新东西或影响公司文化时也不知道是猴年马月的了。因此，在公司内成功建立心态的转换对打破职业生涯瓶颈是非常重要的，这会让团队成员处于流程的核心，打破长久不变的技术栈，并鼓励不断地进步。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/developer-challenges-mindset/\">The Most Common Developer Challenges That Prevent a Change Mindset—and How to Tackle Them</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/58jKuW7dDZ0K7qt9hpL7\">团队已不堪重负，如何“分而治之”</a>\"</p><p><a href=\"https://www.infoq.cn/article/JCB92DRfLZF7SaNhlBsL\">团队交付的速度变慢了，我该怎么办？</a>\"</p><p><a href=\"https://www.infoq.cn/article/Mm3ESuhEcwIy7F7eMYfg\">软件项目管理中价值流反馈回路的意义</a>\"</p>",
    "publish_time": "2023-01-30 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "2022，Meta最难过的一年",
    "url": "https://www.infoq.cn/article/673lWz81ClJ4wK0DygAg",
    "summary": "<p></p><p></p><p></p><blockquote>通过扎克伯格的问答录音和内部调查结果，我们得以真实感受到Meta的困境给每位员工造成的切身影响。</blockquote><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b9/b9469c7ce74de9f4f185296d73405d8c.png\" /></p><p></p><p>在Meta 2022年最后一次公司全体问答会议开始之际，扎克伯格以失望但却依然坚定的语气打开了话题。</p><p></p><p>在外媒Recode拿到的会议录音中，扎克伯格表示“我们根据对业务发展形势的判断制定了2022年运营计划，但事态显然并没有按照我们预期的方向推进。”</p><p></p><p>这位科技巨头的掌门人明显弱化了事态的严重程度。</p><p></p><h2>有史以来最艰难的一年</h2><p></p><p>2022年可谓Meta有史以来最艰难的一年——不是因为之前曾经出现过的丑闻，而是在经历了连续18年看似不可阻挡的增长之后，公司股价同比下跌了65%。</p><p></p><p>这一年间，随着利率上升、通货膨胀率急剧增长以及动荡的宏观经济形势，整个科技行业的价值预期都受到了冲击。但在前五大科技巨头当中，Meta的估值跌幅位列榜首。</p><p></p><p>华尔街分析师们将原因归咎于该公司的特有问题：来自TikTok的竞争令其难以招架，苹果新出台的隐私政策致使其广告销售放缓，而扎克伯格孤注一掷式的年均100亿美元虚拟/增强现实与元宇宙投入也没能得到资方的信任。</p><p></p><p>扎克伯格称自己已经有计划来扭转这股可怕的衰退。他将继续打造元宇宙，但大部分精力将集中在改进Meta的核心社交媒体业务（Facebook与Instagram）身上，同时会寻求新的方法来扩展公司广受欢迎、但利润贡献较低的消息收发应用。他把话挑明，Meta的员工需要比以往任何时候都更加努力地工作。</p><p></p><p>“我对前景仍然保持乐观。但2022年给我们敲响了警钟，事情不会永远如你所愿，你不能认为顺风顺水是理所当然。所以，我们必须真正全力以赴。”</p><p></p><p>Recode采访了十多位Meta员工——有些是现任员工，有些在去年已经离开了公司。他们讲述了公司内部面临挑战时的焦虑与乐观情绪。包括高级主管和普通工程师在内，这些消息人士告诉Recode，如今的Meta公司越来越注重效率，在企业文化层面也开始愈发严格地限制员工间的意见往来。</p><p></p><p>与此同时，Meta的成员们也确实比以往任何时候都更具竞争力。有些人对变化表示欢迎，但总体来讲，受到近期裁员、股价下跌和公司过度关注元宇宙等因素的影响，Meta的整体士气不及以往。（为了避免公开发言影响到职业发展，本文将隐去消息人士的真实姓名。）</p><p></p><p>一位在Meta工作多年的员工表示，“最让人担心的是：如果股价继续下跌，我们的信心该靠什么来支撑？”此人对Meta的长期规划（例如开发轻量化增强现实眼镜）其实非常期待，只是不清楚Meta要多久之后才能靠这类产品创造出新的收入增长点。“我不知道这些产品什么时候才能变成现实。”</p><p></p><p>Recode还拿到一份去年10月的内部调查报告，其中基本反映出员工的观点：只有28%的受访员工对公司未来持乐观态度，58%的员工对公司整体仍然比较认可。</p><p></p><p>调查结果出炉之际，裁员传闻已经在四处流传，Meta公司的招聘计划也被暂时叫停。在这项调查中，只有31%的员工表示对公司领导团队很有信心，较去年5月的上一次调查下降了11%。尽管如此，员工们在某些方面仍然比较乐观：74%的员工对领导层的“既定愿景”表示满意，82%的员工对Meta的使命定位表示认可，84%的员工则对自己的经理感到满意。</p><p></p><p>作为对调查结果的回应，Meta公司发言人向Recode发出如下声明：“反馈是我们企业文化的核心部分，调查的目标是了解我们哪里做得好、哪里还需要改进。我们对未来的道路保持乐观，也感谢每天为公司使命而不懈奋斗的全体员工。”</p><p></p><p>有几位员工告诉Recode，他们期待明年Meta的情况会有所好转。目前也有不少迹象让人充满希望：Facebook用户群体在去年的首次下滑后重新恢复增长；人们使用Reels的时间有所增加（Meta针对TikTok推出的同类产品）；公司的股价已经较2022年11月的最低点上涨了40%。而，这家科技巨头想要重回巅峰，无疑还有很长的路要走。</p><p></p><p>Meta产品的总用户规模超37.1亿人，占世界总人口的近一半。这也使其成为迄今为止全球最大的社交媒体企业。Facebook和Instagram等应用塑造了我们的文化、经济和政治规范。这家公司的命运，特别是能否重获投资者和员工的信心，将决定其能否继续在人们的日常生活中占据主导地位。而一旦失败，这份巨大的权力将被拱手让予TikTok等不断壮大的竞争对手。</p><p></p><h2>努力重拾“斗争”文化</h2><p></p><p>随着今年Meta核心业务的增长放缓，公司开始做出一系列艰难的决定，包括削减某些工作岗位和员工福利，并开始限制员工在企业内的讨论内容。虽然这激怒了一部分员工，但公司领导层认为这是不美好、但却必须实施的修正举措。</p><p></p><p>扎克伯格在年终总结中表示，“我希望大家在2023年关注的头号大事，就是把公司重新带回那种昂扬向上、充满斗志的文化轨道上。有了这种文化，我们才能保持精简、行事高效。而裁员就是实现精简的第一步，后续我们还有很多工作要做。”</p><p></p><p>去年11月，Meta史无前例地一口气裁掉11000人，约占员工总数的13%，被裁者遍及公司内各个部门（当然，招聘等部门的裁员比例明显更高）。**这家科技巨头在2020年和2021年大举招聘27000多名员工之后，到裁员前员工总数已超80000人。**而在这半年各大科技巨头的裁员行动中，Meta的精简力度也远超同侪。</p><p></p><p>Meta公司CEO Andrew “Boz”Bosworth在12月的采访中表示，“这段经历不只是2022年中的低谷，甚至可以说是我整个职业生涯中的最低谷。”</p><p></p><p>在最近的员工问答大会上，扎克伯格告诉大家，Meta在未来几个月内将进一步限制员工出差、减少办公室免费餐食供应和合并办公场所，借此削减更多成本。他感谢了员工“在这段艰难坎坷的时期”所表现出的韧性和出色的执行力，但也再次呼吁员工们不断提高行动速度和工作效率。他在去年就曾反复传达过同样的信息，但不少在疫情期间拼命工作的员工对此表达了不满。</p><p></p><p>一位今年刚刚离开Meta的前员工说，“他总跟我们讲，说我们被Meta给宠坏了。”</p><p></p><p>在会上，扎克伯格暗示Meta公司对员工们宽容太久了，特别是在新冠疫情之初。当时公司专注于“更灵活地”支持员工，如今他在会上将其定性为“一段不正常的时期”。</p><p></p><p>有员工取笑Meta在内部员工讨论组中不断呼吁加大工作强度。有个员工就经常在群组中发表情包和笑话，将此举称为“胡扯淡”；另一位员工则在7月的帖子中呼吁人们“加大力度摸鱼”。</p><p></p><p>文中模仿扎克伯格和其他高管的口吻写道，“「加大力度」并非新鲜事物。但在上周的「胡扯淡」会上，我们已经看到，每个人都可以做点什么，从而在这个经济和业务充满不确定性的时期下保持前进。”</p><p></p><p>如今的领导层明显开始将重点从灵活性转向了执行效率，并推动新的指导方针以确保员工们“加大力度”，包括限制他们在工作中所能讨论的话题。长期以来，Meta一直允许员工在内部各Workplace团体中自由分享政治观点和对管理层的批评。虽然公司文化并不像竞争对手谷歌那样开放，但Meta的宽容度确实远超大部分同等规模的非技术企业。</p><p></p><p>去年12月初，该公司制定了一项新的“社区参与期望”政策（CEE），限制员工在Workplace等Meta内部消息平台上的发言内容。新政策禁止员工讨论敏感的政治、健康或法律问题，例如堕胎和枪支管制等，除非与其工作职能直接相关。</p><p></p><p>Meta人力资源主管Lori Goler在一份内部备忘录中写道，“过去几年来，我们看到大量讨论引发的混乱和精力分散。这让我们整个工作社群筋疲力尽，无法正常工作。”</p><p></p><p>新规还要求员工向特定团队或人员“给予适当反馈”，而不再允许做出笼统的负面陈述。一名员工表示，作为回应，部分员工转而私下散布口头批评、或者将观点发布到不受经理监管的平台，例如Signal或Blind。</p><p></p><p>一位员工表示，“整个公司似乎每周都在让员工失望。”但考虑到2023年的财务现状，恐怕让员工“失望”的决定还将持续涌来。</p><p></p><p>在12月的全体员工问答大会上，有人向扎克伯格提问“2023年，公司会采取哪些举措来鼓舞员工士气、提振公司文化？”</p><p></p><p>扎克伯格停顿了一下，给出了“胜利”这样一个简短的回答。说完后他自己也笑了。虽然扎克伯格承认Meta股价下跌正影响到员工的个人财务状况（Meta员工的大部分工资都是以股票支付的），但他还是强调本阶段的主要目标是改善业务表现。</p><p></p><p>“我知道，这不是那种传统意义上鼓舞士气的倡议。但我们所做的一切都是为了夺取胜利。我们来这就是为了赢，为了达成公司的使命，并取得良好的业务成果。”</p><p></p><p>醒醒吧，Meta人们！</p><p></p><p>过去几个月的残酷经历，让Meta员工们逐渐适应了新的现实。至少当下，Meta已无法在市场上大杀四方。</p><p></p><p>Meta股价的暴跌一直是员工的痛处，也是人们抱怨的共同焦点。</p><p></p><p>根据从Meta内部员工留言板Workplace上流出的截图，员工发布了不少表情包，嘲笑Meta在10月粗略收益报告发布后遭遇的股价大跌。一名员工还开发了机器人，能计算出员工入职时股价与当前股价间的差值。8月Workplace上的一张图片写道，“你的股价比最初持有时下降了71.1%。”另有员工发布了三张小熊维尼表情，其中一个代表亚马逊、一个代表谷歌，最后一个代表Meta——在股权稀释后的相对股价最低，配图文字是“找不同”。</p><p></p><p>对很多员工来说，不断下滑的财务业绩也动摇了他们继续待在Meta公司的决心。</p><p></p><p>一位今年刚离开公司的前员工表示，“有些人其实觉得留在Meta有违内心的道德判断，但又不愿放弃丰厚的薪酬。然后突然之间，这点牵挂也没了。”</p><p></p><p>有人说，目前Meta的员工士气达到了2018年Cambridge Analytica丑闻以来的最低水平。当时Meta曾面临大量批评，有报道称其允许第三方在未经用户同意的情况下，收集数百万用户数据并将结果用于政治宣传。</p><p></p><p>**一位现任员工坦言，“要么求心安，要么求财，两样总要占上一样。**而现在，本来就对Facebook行为不满的人们对道德问题的批判性更强了。”</p><p></p><p>但问题在于，不止是Meta，整个硅谷都在发生巨变。当初，Meta员工可以轻松跳槽到谷歌、苹果或者亚马逊等其他科技巨头。但随着整体经济形势的衰退，所有这些企业在过去一年间都放缓甚至直接叫停了人员招聘。</p><p></p><p>Meta员工也担心公司会继续裁员——毕竟扎克伯格自己在最近的问答大会上也没有排除这种可能性。</p><p></p><p>“我想向大家澄清一下，希望我们前一轮裁员已经足够，不用再搞新一轮的全公司裁员。但谁也无法预测未来，如果继续出现非常严重的衰退，那我们可能还得重新审视这个问题。”</p><p></p><h2>竞争、办公室政治和重组</h2><p></p><p>长期以来，Meta一直是家以量化指标为导向、极具市场竞争力的公司。其基于排名的绩效评估同产品指标密切相关，直接决定着员工的职业轨迹。如今资源有限，多位现任和前任员工都反映公司出现了一种更加残酷的文化。人员重组和对未来继续裁员的恐惧，无疑对这种文化起到了火上浇油的作用。</p><p></p><p>也有些员工想得很开，他们认为Meta这种重组和专注于绩效指标的作法就是科技巨头的常态。在其他跟Meta同等体量的公司里，“这一直就是各个部门的惯例”。</p><p></p><p>另一位于去年离职的前雇员则认为问题没这么简单，“Facebook是我待过的办公室政治色彩最浓的企业，说10倍严重也不为过。人们都在背后相互捅刀子，而且努力在经理面前表现自己。”</p><p></p><p>随着公司结构的转变，很多员工希望能转移到优先级更高的项目中去。比如Meta拿来跟TikTok直接抗衡的Reels以及元宇宙相关项目。</p><p></p><p>一位前雇员指出，“Reality Labs的工作岗位成了抢手的香饽饽。特别是元宇宙产品小组那边，体现得尤其明显。即使是负责隐私或政策方面的工作，大家的想法也是「一定要挤进元宇宙的隐私组、元宇宙的政策组」。”</p><p></p><p>有员工表示，那些远离高优先级项目的员工会产生强烈的被裁员、至少是被边缘化的危机感。“对于那些工作内容不太要紧的团队，大家的日子过得着实艰难。每个人都想用更少的钱做更多的事，免得在新一年里被公司「优化」掉。大家还担心Meta会从社会影响方面的团队下手，比如青年、福祉和慈善捐赠方面的部门，所以只能谨小慎微地保持最低限度运转。”</p><p></p><p>今年，部分身处AR/VR关键团队的Meta员工也感受到了新文化带来的压力。</p><p></p><p>曾任Meta虚拟现实执行顾问的行业巨子约翰·卡马克于12月下旬选择离职，并在现已公开的辞别信中写道，虽然他相信Meta对AR/VR技术的坚定愿景，但认为公司在执行效率方面存在问题。</p><p></p><p>“我们拥有的人员和资源多得离谱，但却不断在自我破坏和浪费精力。没必要粉饰太平，我认为组织运营效率连我预期线的一半都达不到。”</p><p></p><p>Recode采访的几位员工均表示，卡马克对Meta组织效率问题的坦率点评在公司内引起了轰动。其中一位表示，他们担心“Meta顽症已深，就连卡马克这样的人都无力解决。”但卡马克并没有回应Recode的置评请求。</p><p></p><p>卡马克在信中明确提到，虽然高层提出了明确的意愿，领导班子也很难切实引导Meta这艘大船驶上既定航线。</p><p></p><p>一位前任员工提到，“扎克伯格自己怎么想已经不重要了，因为他面前的最大障碍是官僚主义。在他之下，有20层人事结构都完全不关心什么元宇宙梦想，他们关心的只有员工人数和如何在下一轮「优化」中幸存下来。”</p><p></p><p>虽然Meta的减员增效举措面临重重困难，但不少员工仍然表示支持，希望能借此帮助公司重新回归正轨。</p><p></p><p>有员工表示，过去几个月来，扎克伯格牵头的领导班子在确定优先事务方面表现“相当好”、“透明度更高”，“执行深度也是前所未有”。这名员工认为裁员是为了“激励员工”将个人意愿与公司使命统一起来，将资源真正投入到值得探索的领域。</p><p></p><p>这位员工强调，“裁员当然不是好事。但我认为从长远来看，由此产生的凝聚力可能会对公司有利。”</p><p></p><h2>意想不到的胜利与长期元宇宙愿景</h2><p></p><p>虽然坏消息一个接一个，但Meta在这一年中也不乏高光时刻&nbsp;。</p><p></p><p>2022年，Meta面临的公共丑闻比往年要少。但这可能要部分归功于马斯克戏剧性地接管了Twitter，Sam Bankman-Fried的FTX交易所又突然垮台，全球媒体的注意力都被这两件大事给吸引了过去。无论如何，Meta终于不再像前几年那样动不动就搞出个大新闻。</p><p></p><p>即使是在对扎克伯格元宇宙梦想持怀疑态度的员工当中，不少人也看到了支持这一愿景的技术正在发展落地。人们对增强现实（AR）技术的潜力尤其兴奋，相信该技术在未来能拿出比VR头显轻巧很多的产品——比如带有计算机功能的轻量化智能眼镜。</p><p></p><p>一位前雇员承认，“在我看来，元宇宙这个概念很受欢迎。我没想到人们真的会接受「Meta」这个新名称，并热切期待我们能搞出点大动静。我原以为人们会把一切都当成扎克伯格的宣传噱头。”</p><p></p><p>目前，Meta旗下最接近AR成熟形态的产品Quest Pro（号称是「混合现实」）对大多数用户来说仍价格昂贵，毕竟每款头显价格达1500美元。Meta可能还要几年才能开发出价格更实惠的突破性AR设备。但也必须承认，扎克伯格仍然是最有能力实现这一突破、而且愿意长期投资的技术领导者之一。</p><p></p><p>Meta公司CTO Bosworth在去年12月的采访中表示，“扎克伯格有着卓越的前瞻性，相信这项技术终将流行并得到数十亿人的认可。他有意愿、也有韧性承受一切随之而来的批评和抨击。从他以往的表现来看，这是毫无疑问的。”</p><p></p><p>**许多员工也认为，扎克伯格身为领导者的一大核心优势，就是他是唯一一位继续主导科技巨头行政权、拥有董事会控制能力和免受解雇这项基本豁免权的硅谷创始人。**就是说，他可以逆舆论而动，做出短期内可能对股东有风险、但最终能够支撑长期业务的重大决策。十年之前，不少行业专家都认为扎克伯格为收购Instagram开出的收购价太高，但事实最终证明这是科技史上最成功的收购之一。</p><p></p><p>社交媒体业务顶级分析师、Evercore公司高级董事总经理Mark Mahaney评论道，“扎克伯格总能制定出一年、三年、五年和十年期计划。对管理者来说，表达自己的长期经营策略是件好事，也能保证公司的运营理念不会被华尔街的贪婪短视而过度左右。”</p><p></p><p>话虽如此，但长期看好Meta的Mahaney也有自己的疑虑，“Meta会不会成为下一个雅虎？未来使用Facebook的用户会越来越少吗？”</p><p></p><p>不少Meta员工也在问自己同样的问题。对于那些相信扎克伯格眼光的并决定与Meta共存亡的坚守派来说，这可能是个打败怀疑论者的最好机会。</p><p></p><p>在问答大会末尾，为了回应大家关于员工调查中“令人担忧”的结果所反映出的信心缺失问题，扎克伯格号召员工们要向好处看。他说现在股价较低，所以一旦未来估值回暖，员工们将获益更多。</p><p></p><p>扎克伯格总结道，“我也不知道投资者们什么时候才会认定Meta的努力已经取得成功。可能会是2023年，可能就在下周，也可能还要再等几年时间。”</p><p></p><p>原文链接：</p><p></p><p><a href=\"https://www.vox.com/recode/2023/1/11/23547490/meta-facebook-mark-zuckerberg-stock-employees-morale-survey-2022-year\">https://www.vox.com/recode/2023/1/11/23547490/meta-facebook-mark-zuckerberg-stock-employees-morale-survey-2022-year</a>\"</p>",
    "publish_time": "2023-01-30 09:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "科技圈啪啪打脸！当初的那些美好像极了一个巴掌",
    "url": "https://www.infoq.cn/article/7xZB7zfVs1kp61iK5UzU",
    "summary": "<p>&nbsp;</p><p></p><blockquote>2022年，每个人都不好过，不是每个人都可以实现当初的雄心壮志，无论有意还是无意。我们简单列了一些“打脸”事件，背后的原因不尽相同，但最终只有一个意思：且行且珍惜。</blockquote><p></p><p>&nbsp;</p><p></p><h4>白烧了1400亿后，自己打自己的脸</h4><p></p><p>&nbsp;</p><p>2021年北京时间10月29日凌晨1点，被业界人士称为“VR圈春晚”的Facebook Connect 大会在一众期待中举行。会上，扎克伯格将Facebook正式更名为Meta，股票代码也将从12月1日起由“FB”更改为“MVRS”。这场发布会除了公布两款机型的代号之外，并没有其他的产品更新。扎克伯格和高管们花了两个小时去描绘遥不可及的“元宇宙”：每个人都可以在元宇宙世界里拥有一个化身……</p><p>&nbsp;</p><p>大厂“all in”元宇宙带来的影响是巨大的。2022年，元宇宙成为当之无愧的科技“热词”，企业不说自己沾点元宇宙业务的话就像变成了时代弃儿。而凭一己之力掀起元宇宙风口的扎克伯格也真的花了真金白银去投资。</p><p>&nbsp;</p><p>根据科技投资公司 Altimeter Capital 创始人兼CEO <a href=\"https://cointelegraph.com/news/zuckerberg-s-100b-metaverse-gamble-is-super-sized-and-terrifying-shareholder-says\">Brad Gerstner</a>\" 所述，该公司已宣布每年向其元宇宙项目投资 100 亿至 150 亿美元，包括 AR/VR 技术和 Horizo​​n World。但这些投资“可能需要 10 年才能产生结果”&nbsp;Gerstner表示。</p><p>&nbsp;</p><p>但现阶段 Meta还是有成果的，我们一起看看：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f6/f6d665bc54d26623f2c1e0fb7240ecb0.png\" /></p><p></p><p>&nbsp;</p><p>2022年8月，招克伯格第一次发了自己的元宇宙形象。该照片一出，网友直呼“恐怖”，有人表示画质还不如1997年的 PC 游戏。</p><p>&nbsp;</p><p>“我知道我此前发布的照片非常基础，它是为了庆祝上线而拍摄的。Horizon Worlds的画质会更加好，并且改进速度非常快。”扎克伯格说道。但咱就说，首次亮相也别这么“将就”好不～</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/94/946ddc2c818013191d0e4d86185f3a7d.png\" /></p><p></p><p>&nbsp;</p><p>后来的改进版本，但也就好了那么一点。</p><p>&nbsp;</p><p>2022年7月底，Meta 公布了2022年第二季度财报。包括 AR（增强现实）和 VR（虚拟现实）相关硬件、软件和内容在内的元宇宙相关业务 Reality Labs 收入4.52亿美元，为去年二季度以来最近四个季度最低水平，当季亏损28亿美元，第一季度亏损29.6亿美元。自2021年初以来，其负责元宇宙业务的Reality Labs 部门亏损累计近200亿美元(约合1416亿元人民币)。</p><p>&nbsp;</p><p>同年9月，彭博社报道称，由于在元宇宙业务上的投入，扎克伯格2022年身家缩水一半多，达710亿美元（近5000亿元人民币），是彭博亿万富翁指数追踪的超级富豪中缩水最多的。</p><p>&nbsp;</p><p>巨大的亏损也让扎克伯格面临着越来越大的反对声音，甚至其内部员工都看不下去了。不过，他在去年12月辩解称，公司对于元宇宙的押注“不是我们正在做的大部分工作”。</p><p>&nbsp;</p><p>“我们大约80%的投资，还略多一点，投向了核心业务以及与之相关的广告业务，也就是我们所称的应用家族，包括脸书、Instagram、WhatsApp Messenger。然后，不到20%的投资用于Reality Labs。因此，在相当长一段时间内，我们仍要做，并且会继续做的绝大多数事情是朝着社交媒体发展，直到元宇宙规模变得更大。”扎克伯格表示。</p><p>&nbsp;</p><p>“可以辩论一下20%对这个押注来说是不是太多了，但这不是我们正在做的大部分工作。”扎克伯格称。他还对 Reality Labs 的支出进行了分解，其中40%用于VR投资，大约一半用于建立长期项目：“可以在世界上显示全息图像的普通眼镜。”</p><p>&nbsp;</p><p>但值得注意的是，去年11月扎克伯格发布全员信，确认公司将裁员逾11000人，裁员人数约占其员工总数的13%，其中包括Reality Labs。</p><p>&nbsp;</p><p>实际上裁员也有征兆。去年3月，扎克伯格宣布削减部分员工福利，包括取消洗衣、干洗、免费晚餐供应等服务；7月，他预警称公司正在经历“在近期历史上见过的最严重的衰退之一”；10月，他又警告说2023年大多数团队规模将保持不变或缩小。</p><p>&nbsp;</p><p></p><h4>业务越多，越会被“混合双打”</h4><p></p><p>&nbsp;</p><p>2022年的马斯克在“打脸”这件事上可谓是被特斯拉和推特“混合双打”。</p><p>&nbsp;</p><p>一方面，马斯克收购推特的“剧情”就很跌宕，在收与不收之间横跳。</p><p>&nbsp;</p><p>2022年1月，马斯克开始几乎每天分批次购买推特的股票，到了4月份，马斯克已斥资约30亿美元，购入7350万股、占比9.1%的推特股票，成为推特的单一最大股东。</p><p>&nbsp;</p><p>这时推特还是很欢迎马斯克的。推特首席执行官Parag Agrawal邀请了马斯克加入董事会，认为他会为董事会带来巨大价值，当然条件是马斯克的持股不能超过14.9%。但马斯克毫不领情，公开发文称：“推特快死了吗？”，这一举动彻底恶化了马斯克与推特董事会的关系。推特董事会开始反对收购，并称将使用“毒丸计划”等来抵御恶意收购。</p><p>&nbsp;</p><p>但已经进入法律流程的收购并没有因此搁置。4月25日，马斯克与推特董事会达成收购协议。在投资银行摩根士丹利的牵头下，马斯克获得了255亿美元债务和保证金贷款融资。</p><p>&nbsp;</p><p>5月初，马斯克透露改变推特的计划，称将撤销推特对美国前总统唐纳德·特朗普的禁令。但不久，马斯克又要&nbsp;“暂时搁置”收购推特。他声称，推特鼓吹有2.38亿可货币化的日活用户，但实际能真正看到广告的用户数量可能低于6500万。</p><p>&nbsp;</p><p>或是出于不甘愿“被溜”这么久，或是终于可以把“烫手山芋”送出去，这时的推特是不可能让马斯克轻易抽身而去的。7月，推特起诉马斯克，迫使他完成了交易。10月初，马斯克再次表示会收购推特，而推特称要在收到款项后才完成交易。一系列博弈完毕后，马斯克在10月底带着一个“水槽”正式入主推特，这次收购花掉了他440亿美元。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8d/8d27e8e30e14631a677394fc9a84f199.png\" /></p><p></p><p>&nbsp;</p><p>马斯克接手前，推特尽管营收放缓，但还是增长的，也不存在财务危机。但马斯克的杠杆收购平白为其带来了 130 亿美元的巨额债务和每年约 12.9 亿美元的利息成本，这比推特去年赚的还要多。</p><p>&nbsp;</p><p>之后发生的事情大家也知道，裁掉了75%的员工、拖欠房租、拍卖家具、让员工“硬核”且自费卫生纸……关键是，马斯克雄心勃勃地要让推特“言论自由”，为了盈利又急于推出付费认证功能导致推特上骗子横行，因此现在已经有500多家广告商被吓跑了，这让本就不富裕的家庭雪上加霜。</p><p>&nbsp;</p><p>终于在12月，马斯克表示，“一旦找到蠢到可以接任这个工作的人后，我就辞去 CEO 职务！之后，我将负责管理软件和服务器团队。”他发起的“是否继续推特CEO”的投票有1750 万参与，57.5%的人希望他离开。</p><p>&nbsp;</p><p>另一方面，为了堵上买推特欠下的债，马斯克“疯狂”卖特斯拉的股票。据报道，马斯克收购推特融资的首期利息最早或在今年1月底到期。随着日子的临近，马斯克又开始“变卖”特斯拉了。</p><p>&nbsp;</p><p>2022年11月，马斯克卖特斯拉股票换来40亿美元，并承诺“不会再卖特斯拉”。但转眼到了12月，马斯克三天内抛售了特斯拉股票2200 万股，套现 36 亿美元，全年累计抛售了价值 400 亿美元的特斯拉股票。</p><p>&nbsp;</p><p>特斯拉在2021年市值破万亿，当时的马斯克也是激动万分，并对2022年充满信心：交付量的年平均增长率达到50%，今年交付150万辆汽车！但现实的残酷来得如此之快，特斯拉全年交付131万辆，同比增长40%。更为要命的是，特斯拉股价在2022年大跌65%，市值蒸发约6750亿美元，马斯克也成为历史上第一个身价缩水2000亿美元的人。</p><p>&nbsp;</p><p>在交付数据不及预期的同时，特斯拉也发生高层人事变动。特斯拉全球副总裁、大中华区负责人朱晓彤接管北美地区的销售、服务和交付工作。据悉，朱晓彤的新职务与马斯克对推特的收购案存在联系，投资者对马斯克过度投入收购和管理推特不满。</p><p>&nbsp;</p><p>连续15年战胜标普的传奇价值投资者Bill&nbsp;Miller曾表示，由于新能源汽车行业竞争日益激烈，他正在做空特斯拉的股票。“如果股价上涨，我会做空更多股票。”</p><p>&nbsp;</p><p>据报道，特斯拉的订单池从去年7月之后开始下滑，仅五个月时间，特斯拉全球订单池从47.6万辆下滑至16.3万辆，中国市场更是从9月份之后出现了断崖式的下滑。为促进销售，特斯拉也打起了“价格战”。今年1月，特斯拉国产车型大幅降价，Model 3起售价22.99万元，Model Y起售价25.99万元，创下历史最低价格。</p><p>&nbsp;</p><p>而在现在年终冲量的关键时期，特斯拉却宣布上海工厂停产。另外在去年6月，特斯拉还关闭了位于加州圣马特奥的自动驾驶系统部门，并裁减200多个时薪制岗位。</p><p>&nbsp;</p><p>2022年，自动驾驶行业迎来了前所未有的信任危机，特斯拉也面临着各种调查。9月份，有车主对特斯拉提起集体诉讼，称特斯拉“涉嫌在其自动驾驶、增强型自动驾驶和完全自动驾驶（FSD）技术上误导公众”。11月份，美国司法部对特斯拉展开刑事调查，调查目标则是Autopilot的命名与营销方式是否存在夸大成分，以及对其辅助驾驶技术功能是否存在不实表述。2023年1月，特斯拉一名高级工程师的证词显示，特斯拉2016年用于宣传其自动驾驶技术的一段视频是伪造的，为了展示该系统不具备的红灯停车和绿灯加速等功能。</p><p>&nbsp;</p><p>本来想大干一场的特斯拉和马斯克，被现实狠狠打了一巴掌。</p><p>&nbsp;</p><p></p><h4>“绿茶”起来，不要“脸面”</h4><p></p><p>&nbsp;</p><p>11 月 17 日，暴雪中国官方微博发布公告称，随着与网之易公司现有授权协议的到期，自 2023 年 1 月 24 日 0 点起，所有《魔兽世界》《魔兽争霸 III：重制版》《星际争霸》系列，《炉石传说》《风暴英雄》《守望先锋》及《暗黑破坏神 III》国服游戏都将停止运营。《暗黑破坏神：不朽》的联合开发与发行则由两家公司另外的协议所涵盖。</p><p>&nbsp;</p><p>该消息一出，迅速引起了国内玩家不满。“你全家桶我都买了，你就这么对待你的粉丝？”“什么时候有集体诉讼记得拍我一下”“退钱！！”两天后才开放评论区的暴雪中国微博下都是愤懑不满的声音。</p><p>&nbsp;</p><p>很快，丁磊在网易 2022 年第三季度财报电话会上也做了回应称，网易非常希望继续代理暴雪游戏，并为此付出了非常多的努力。但过去一段时间，整个谈判过程难度其实远超出了网易方面的预期。对于一些涉及可持续运营、中国市场及玩家核心利益的关键性合作条款，动视暴雪的要求是不可接受的。对于中国玩家，网易会尽全力做好善后工作，为玩家服务到最后一刻，保障玩家的消费者权益和信息安全。</p><p>&nbsp;</p><p>有知情人士表示，双方合作终止的主要原因是价格未能谈妥。这位人士透露，暴雪方分成较 2019-2022 合约期 50% 以上营收和净利润进一步提高，且暴雪游戏定价将采取全球同步策略，而此前国服定价较全球其他地区普遍低约 20%。暴雪还要求网易按照《暗黑破坏神：不朽》模式，研发暴雪其他 IP 手游全球发行，但网易只享有中国区市场营收分成。同时，暴雪还要求网易缴纳巨额保证金或预付费用来担保第 2 条的完成，否则将被“处罚”。知情人士坦言，若该续约条件属实，暴雪无异于在要求网易“打白工”。</p><p>&nbsp;</p><p>另外据彭博社的报道，有知情人士透露，除了财务条款之外，暴雪与网易终止合作的关键症结还在于，“知识产权的所有权”和“对中国各地数百万玩家数据的控制”。</p><p>&nbsp;</p><p>网易游戏全球投资及合作总裁朱原在领英上发文称，“当一切都尘埃落定、内幕被揭开之时，开发者和玩家们将对 ‘一个傻瓜能造成多大的伤害’ 产生全新级别的认知。”</p><p>&nbsp;</p><p>如果事情到此结束，这就只是一个合作破裂的新闻，也没什么“打脸”一说。但偏偏在今年1月17日，暴雪中国微博突然发布公告说，曾向网易寻求协助，希望能将合约顺延六个月，但遭到拒绝，因此暴雪将遵照停服公告，于1月23日中止国服游戏服务。</p><p>&nbsp;</p><p>有网友翻译了下暴雪的意思：我们虽然分手了，但是我还没找到下家，再凑合半年，等我找到下家再把你踹了。</p><p>&nbsp;</p><p>本想“卖惨”的暴雪再次收获了一片骂声。“我还以为是接盘侠谈好了发文，结果是：主动提离婚后，让前任继续服侍我6个月，人家不干我写小作文挂他，这咋好意思写得出来的。”网友评价道。“看到大家都在骂暴雪，我也就放心了。”</p><p>&nbsp;</p><p>网易这次也是直接刚回去了，晚上就在官微发布声明称，“我方认为，暴雪的这种提议——包括今天突发的声明——是蛮横的、不得体的且不符合商业逻辑的。其过分的自信中并未考虑这种予取予求、骑驴找马、离婚不离身的行为，将玩家和网易置于了何地。”</p><p>&nbsp;</p><p>据悉，基于此前“分手”消息，目前网易暴雪团队的大部分员工已被解雇或重新分配，该团队此前有不到100人规模，大部分为运营人员。该子公司最终将保留了10人规格的骨干团队，在交易到期后处理客户服务以及技术问题，持续时间为6个月。</p><p>&nbsp;</p><p>网易人也是懂“内涵”的。据悉，当天的网易咖啡厅推出了“暴雪绿茶”，订价13，很快便售罄了。此外，根据网友放出的图片，网易食堂还推出了“暴雪绿茶油菜”、“暴雪绿茶小趴菜”和“暴雪绿茶盖菜”。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6c/6cf16788239f90e1e85ccb122c80f24f.png\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>而关于“网易想要IP控制权”的传闻，网易也做了回应，“作为代理公司，网易从未寻求暴雪游戏或其他合作伙伴的IP控制权，在过去十四年的长期合作过程中，网易对任何暴雪IP的使用和授权都是按照合同条款，并取得了暴雪的同意和审批。与其他合作伙伴的IP合作也都是基于此原则。”</p><p>&nbsp;</p><p></p><h4>一味追求风口，总会被现实打脸</h4><p></p><p>&nbsp;</p><p>2022年，NFT数字藏品终于冲出区块链圈子，闯进了“艺术圈”和“科技圈”。周杰伦旗下潮牌「PHANTACi」和Ezek平台联名推出首款NFT「Phanta Bear」，全球限量仅1万个，开卖即秒杀，瞬间进账1000万美元。</p><p>&nbsp;</p><p>NFT数字藏品的价值如何评定？人的意识。只要有足够多的人认为某个数字藏品值那个价格，它就值得那个价格。比如。年初一位日本女优通过NFT平台出售自己的数字化作品，轻松获得数十个ETH（当时ETH单个价值最高可达3000美元）。</p><p>&nbsp;</p><p>随着 NFT 热度不断上涨，国内不少公司都在尝试进入这个市场，其中包括腾讯。2021年，腾讯推出了NFT交易软件幻核，隶属于腾讯PCG，为该部门的创新业务。不过需要说明的是，我国数字藏品与海外NFT有本质区别，最主要的就是弱化了NFT的金融属性。</p><p>&nbsp;</p><p>2022年5月，原腾讯新闻负责人王诗沐调任PCG社交平台与应用线，负责幻核等业务。不过，幻核也成为国内第一家倒下去的数藏平台。</p><p>&nbsp;</p><p>8月16日上午，幻核发布公告称，自当日起，幻核将停止数字藏品发行，所有通过其平台购买数字藏品的用户，皆可自行选择继续持有或发起退款申请。波场创始人孙宇晨还在推特高调发声“蹭热度”，希望收购幻核。</p><p>&nbsp;</p><p>关停早有预兆。7月份时候就有媒体报道，腾讯正计划裁撤幻核业务，该消息已传达至幻核方面工作人员。随后，腾讯回应称，运营一切照旧，正筹备App新版本，因此新藏品发售将延后。同月，腾讯新闻App宣布关闭数字藏品售卖服务。</p><p>&nbsp;</p><p>据报道，幻核自成立以来的销售额已超过 8000 万元，其中 2022 年 4 月的月度销售额近 2000 万元。虽然有人认为“幻核”的退场还算体面，不过其退款承诺至今还没有兑现。有网友戏称，“这是下一个小黄车”。</p><p>&nbsp;</p><p>实际上，幻核只是腾讯众多关停业务的其中之一。去年12月，马化腾在内部大会上重点批评了幻核所在PCG业务板块。他表示，过去由于友商带跑，腾讯盲目去做简单的跟随，结果被带偏方向，做出来的东西效果也是不尽如人意，“看到别人增重，我们就跟着增，结果发现增的是脂肪，打不过对手”。</p><p>&nbsp;</p><p>“你活都活不下去，要靠别人续命，（结果）周末还能休闲地去打球”，马化腾说道，“如果你连创业压力都没有的话，那这个压力我们上面给，好吧。”他表示如果不能自己自负盈亏，那留给这些业务的时间也就不多了。</p><p>&nbsp;</p><p>据悉，腾讯今年至少关停及下架 App 应用 16 款，包括幻核、QQ 影音、看点快报、搜狗地图、腾讯 WiFi 管家等一众知名产品。倘若再加上 29 款被裁撤的游戏，则至少关停了 45 个项目。</p><p>&nbsp;</p><p>纵使“站在风口上，猪都能飞起来”，但当各种“黑天鹅”来临，这场风能否继续吹就未可知了。</p><p>&nbsp;</p><p></p><h4>汽车圈的“贾跃亭”</h4><p></p><p>&nbsp;</p><p>一度自称“汽车界小米学徒”的奇点汽车，整整八年，没量产出一辆车。</p><p>&nbsp;</p><p>奇点汽车成立于2014年，造车新势力开始萌芽的一年。创始人沈海寅曾就职于360公司，在自己的造车梦遭到周鸿祎反对后，毅然从360离职创业。</p><p>&nbsp;</p><p>靠着一堆PPT合概念，沈海寅给投资人画了好大的一张饼，也凭此先后拿到了超过170亿的融资。他曾公开表示，造车是男人的终极梦想，马斯克是自己的偶像，小米模式是他的方法论。他要用互联网思维造一辆性能超越特斯拉，价格低于特斯拉的车。&nbsp;&nbsp;</p><p>&nbsp;</p><p>不过，这么多年过去了，我们始终没有看到一辆车。给投资人画饼的三座生产基地，更是哪个都没有建成。</p><p>&nbsp;</p><p>2022年12月，安徽奇点智能<a href=\"https://nev.ofweek.com/\">新能源汽车</a>\"有限公司被铜陵市铜官区人民法院强制执行325万元，公司累计被执行金额已经超686万元。近日，奇点汽车关联公司智车优行科技（北京）有限公司新增一则被执行人信息，执行标的477万，关联案件为阿尔特汽车股份有限公司与该公司承揽合同纠纷。</p><p>&nbsp;</p><p>2022年7月份，奇点汽车被爆拖欠员工工资，并且时间最长的已经有1年半，执行仲裁的员工有150多人。为追回欠款，帝维汽车工程技术(上海)有限公司直接向法院申请奇点汽车北京分公司强制破产重组。</p><p>&nbsp;</p><p>与此同时，去年6月底，北京法院审判信息网公布一份民事判决书，判令奇点汽车支付原告中汽研一笔64.9万的测试开发费用。与奇点汽车这些年获得的170亿元融资来说，64.9万只是凤毛麟角，但却从2020年8月拖到了现在。</p><p>&nbsp;</p><p>数据显示，当前智车优行的相关法律诉讼已经高达27起，关联风险172处，董事长沈海寅处于限制高消费的状态当中。</p><p>&nbsp;</p><p>面对供应商与讨薪员工们的怒火，奇点汽车仍嘴硬地表示会“在本轮融到资后第一时间支付完成”补偿，但估计早没人信了。所以，奇点，你们的170亿到底花哪里了？</p>",
    "publish_time": "2023-01-30 09:41:15",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "盘点2022年最会“搞钱”的十家AI公司",
    "url": "https://www.infoq.cn/article/U2caWQbsUQKDVbpluHzu",
    "summary": "<p></p><blockquote>“寒冬”之下，“搞钱”才是硬道理。</blockquote><p></p><p></p><p>2022 年，<a href=\"https://www.infoq.cn/article/rggHjzaBfCVPV5hxTF7H\">AIGC</a>\"（Artificial Intelligence Generated Content，人工智能生成内容）概念的火爆出圈让 AI 领域显得格外热闹。</p><p></p><p>8 月 22 日，AI 界的“神笔马良”、绘画神器 Stable Diffusion 横空出世，用户随意输入自己想要的文字描述，就能得到相应的图像结果；12 月，OpenAI 发布了一个全新的聊天机器人模型 ChatGPT，它能写小说、写代码、写论文……就像是一个无所不知的虚拟体，能回答各种问题，而且总能给到让人满意，甚至超过预期的答案。</p><p></p><p>2022 年，自动驾驶热度依旧，但资本不再冒进，更聚焦在商业场景确定性高的自动驾驶项目上；2022 年，全球智能语音产业规模达 351.2 亿美元，保持 33.1% 的高速增长，我国智能语音市场达 341 亿元，同比增长 13.4%……</p><p></p><p>2022 年，多重因素使然，国内 AI 赛道融资情况并不乐观。IT 桔子数据显示，2021 年国内 AI 领域风险融资事件数达到 832 起，而 2022 年仅有 400 起（数据截止到 2022 年 11 月 10 日），与上一年年同期相比下降 50%。融资金额规模也经历“腰斩”，2021 年国内 AI 行业总体融资交易额达到 2187.9 亿元，而 2022 年只有 770.4 亿元（数据截止到 2022 年 11 月 10 日），与去年同期相比下降 61%。</p><p></p><p>但与此同时，据 IT 桔子数据统计，截止到 2022 年 11 月 10 日，国内还是有 24 家 AI 公司获得 1 亿美元以上融资。这也说明，资本市场对 AI 赛道仍然抱有热情。</p><p></p><h2>2022 年，国内斩获巨额融资的10 家 AI 公司</h2><p></p><p></p><p>InfoQ 根据公开数据梳理出了 2022 年国内斩获巨额融资的 10 家 AI 公司。数据显示，这 10 家 AI 公司在 2022 年总计融资超 140 亿元人民币。</p><p></p><h4>黑芝麻智能：募资总规模超 5 亿美元，传考虑赴香港 IPO 上市</h4><p></p><p></p><p>2022 年 8 月 8 日，全球自动驾驶计算芯片企业黑芝麻智能宣布完成由武岳峰科创领投的 C+ 轮融资，兴业银行集团、广发信德、汉能基金、北拓一诺资本、新鼎资本、之路资本、扬子江基金等机构跟投。至此，黑芝麻智能完成 C 轮和 C+ 轮全部融资，募资总规模超 5 亿美元。</p><p></p><p>根据黑芝麻智能官网显示，公司于 2016 年成立，是行业领先的车规级自动驾驶计算芯片各平台研发企业，专注于大算力芯片与平台等技术领域的高科技研发。黑艺麻智能能够提供完整的自动驾驶、车路协同解决方案包括基于车规级设计、学习型图像处理、低功耗精准感知的自动驾驶感知计算芯片和自动驾驶计算平台，支撑自动驾驶产业链相关产品方案的快速产业化落地。公司的核心产品包括华山系列自动驾驶芯片、瀚海 ADSP(Autonomous Driving Solution Platform) 自动驾驶中间件平台。</p><p></p><p>据彭博社 2023 年 1 月报道，黑芝麻智能考虑进行香港 IPO，募资规模可能约为 2 亿美元。消息指出，黑芝麻智能与中金公司以及华泰国际就股票发行的准备工作进行合作，预计最快首季度递交初步招股书，IPO 最早可能在今年下半年进行，融资金额和银行参与情况等细节可能仍会有变。报道称中金和华泰国际的代表不予置评，黑芝麻智能的代表没有回复置评。</p><p></p><h4>文远知行：融资 4 亿美元，投后估值达 44 亿美元，沈向洋是其早期投资人</h4><p></p><p></p><p>2022 年 3 月，L4 级别自动驾驶公司<a href=\"https://www.infoq.cn/article/ZVygOmjY9wtk866Ligz7\">文远知行</a>\"宣布完成新一轮超 4 亿美元融资，投后估值达 44 亿美元。此轮投资方包括广汽集团、博世、中阿产业投资基金、凯雷投资集团。除广汽集团外，其余投资方均为文远知行的新股东。</p><p></p><p>据悉，文远知行前身为景驰科技，公司成立于 2017 年，创始人是“自动驾驶第一人”王劲，前微软全球执行副总裁、知名 AI 大牛沈向洋曾是公司早期投资人。公开资料显示，文远知行总部位于广州，在中国北京、上海、深圳、郑州、南京、武汉、安庆、圣何塞设立分部，团队规模超过 800 人。文远知行聚焦与车企、平台方的铁三角战略合作，形成无人驾驶出租车（Robotaxi）、小巴（Mini Robobus）和同城货运车（Robovan）三大产品矩阵。</p><p></p><h4>镁伽科技：融资 3 亿美元，用智能自动化解决生命科学行业痛点</h4><p></p><p></p><p>2022 年 6 月 15 日，镁伽科技宣布完成 3 亿美元 C 轮融资。自 2016 年成立至今，镁伽为生命科学行业提供了一整套自动化解决方案，从简单的操作台工作流程自动化，到大型系统流程应用中处理复杂步骤的全自动解决方案，并延伸至赋能 AI 药物研发服务的下一代生命科学基础设施和系统。</p><p></p><p>公开信息显示，镁伽科技成立于 2016 年，公司专注于机器人和人工智能技术的研发并将其深度融合于行业应用，为客户提供先进的智能自动化产品与解决方案。同时结合自主研发的通用型智能生物实验室——镁伽鲲鹏实验室的科研能力，赋能新药研发、细胞基因治疗、类器官以及合成生物学等领域的智能自动化变革。此外，镁伽还是半导体领域制造和测试装备的创新者，拥有众多成熟可靠的产品和解决方案。</p><p></p><p>据介绍，镁伽拥有近千名跨领域的人才团队，研发人员占比 60%，累计申请专利超过 300 项。中国总部位于苏州，国际总部位于新加坡，同时在美国、英国、日本设有研发中心，在中国北京、上海及深圳设有分支机构。</p><p></p><h4>小马智行：融资数亿美元，估值达 85 亿美元</h4><p></p><p></p><p>2022 年 3 月 7 日，自动驾驶公司<a href=\"https://www.infoq.cn/article/6CKT512SXPfvcyfXRsrX\">小马智行</a>\"（Pony.ai）宣布完成 D 轮融资的首次交割，整体估值达 85 亿美元。本轮估值较上轮融资提升约 65%，同时公司现金流达到近 10 亿美元。</p><p></p><p>公开信息显示，小马智行成立于 2016 年底，由彭军和楼天城共同创立，是全球首家在中美均推出自动驾驶出行服务（Robotaxi）的公司，总部位于广州。</p><p></p><p>本轮融资资金将用于团队扩充、技术研发、Robotaxi 及自动驾驶卡车（Robotruck）车队规模扩大及全球测试与运营、自动驾驶技术量产以及商业化部署等业务领域，从而推动乘用车和商用车领域的自动驾驶商业化进程和量产化落地。</p><p></p><h4>赢彻科技：融资 1.88 亿美元，L3 级别自动驾驶卡车量产落地</h4><p></p><p></p><p>2022 年 2 月，自动驾驶卡车技术与运营公司<a href=\"https://www.infoq.cn/article/x*TO9sqkiEFia1VwVBam\">嬴彻科技</a>\"已完成 1.88 亿美元的 B+ 轮股权融资。此轮融资由红杉中国、君联资本联合领投，跟投方包括周大福企业有限公司、沄柏资本以及智慧供应链及供应链金融企业 - 物产中大集团产业投资，现有股东美团、蔚来资本、斯道资本、博华资本等跟投。</p><p></p><p>与融资消息一同透露的是，嬴彻科技已联合主机厂伙伴在 2021 年底实现 L3 级别自动驾驶卡车的前装量产，并与多家行业头部货主在多条线路上开展常态化的商业运营。</p><p></p><p>公开信息显示，嬴彻科技成立于 2018 年，业务聚焦于干线物流场景，坚持“全栈自研 + 量产驱动 + 深度运营”的核心策略，自主研发全栈 L3 和 L4 级自动驾驶技术，和汽车产业紧密合作，为物流客户提供更安全、更高效的自动驾驶技术和新一代 TaaS (Transportation-as-a-Service) 货运网络。</p><p></p><h4>剂泰医药：融资 1.5 亿美元，专注 AI 制药</h4><p></p><p></p><p>2022 年 4 月 6 日，专注于 AI 药物及递送系统开发的剂泰医药（METiS Pharmaceuticals 正式宣布连续完成两轮融资，融资金额共计 1.5 亿美元。两轮融资由人保资本、国寿股权领投，红杉中国、五源资本、招银国际、光速中国、Monolith、峰瑞资本等新老股东跟投，华兴资本担任独家财务顾问。</p><p></p><p>剂泰医药是由麻省理工 (MIT) 的顶尖科学家创建, 并由深圳晶泰科技孵化，公司聚焦于药物递送、制剂研发赛道，是全球首个 AI 驱动的药物制剂开发初创公司。</p><p></p><p>技术团队由美国工程学院院士陈红敏顾问牵头, 结合 MIT 人工智能实验室专家, 打造具临床差异化的制剂新药。药物开发团队及顾问委员会具有诺华、J&amp;J 和赛诺菲等顶尖药企的新药开发经历, 具备丰富的经验将新药从实验室带到临床, 并通过 FDA 获批上市。</p><p></p><p>公司的核心平台为 AiTEM，切入临床前的制剂优化等环节，能够高通量药物递送制剂，生成处方及工艺大数据，以及分子模拟及人工智能模型预测药物物理及动力学性质。</p><p></p><h4>Rokid：一年融资 4 轮超 13 亿元，全球首家品牌旗舰店落地杭州</h4><p></p><p></p><p>2022 年，AR 智能眼镜品牌 Rokid 完成了 4 轮融资，融资总金额超 13 亿元。其中 9 月、11 月连续获得投资 3 次，投资方包括复星集团、网龙网络、睿成投资等等。</p><p></p><p>公开资料显示，Rokid 是一家专注于人机交互技术的产品平台公司。Rokid 作为行业的探索者、领跑者，目前致力于 AR 眼镜等软硬件产品的研发及以 YodaOS 操作系统为载体的生态构建。</p><p></p><p>2022 年 12 月，Rokid 全球首家品牌旗舰店正式落地杭州有“全国数字生活第一街区”之称的文三数字生活街区。该旗舰店集品牌展示、产品体验、互动交流等功能于一体，将展示 Rokid 最新系列 AR 产品，为消费者提供沉浸式场景化的产品体验空间。</p><p></p><h4>所托瑞安：融资超 13 亿元，跻身智能驾驶行业独角兽序列。</h4><p></p><p></p><p>2022 年 3 月 28 日，所托瑞安宣布完成超 13 亿人民币的 B 轮融资。本轮融资由中国领先的私募股权投资机构平安资本战略领投、所托瑞安 A 轮股东 SK 中国继续追加投资，嘉实、河南投资集团等机构跟投。</p><p></p><p>所托瑞安被认为是中国商用车“渐进式”智能驾驶的践行者，此前已获得招商银行和招银租赁高达 20 亿元的授信金额。本次融资完成后，所托瑞安的估值已接近百亿人民币规模，顺利跻身智能驾驶行业的独角兽序列。</p><p></p><h4>小冰：融资 10 亿元，将启动数字员工产品线技术升级</h4><p></p><p></p><p>2022 年 11 月 7 日，<a href=\"https://www.infoq.cn/article/mYaQiUC4C4al61Z2wO1T\">小冰公司</a>\"宣布，近日已完成总额 10 亿元新融资，将用于加速 AI Being 小冰框架技术研发，推动数字员工普及，并对旗下人工智能数字员工（AI Being Employee）产品线启动年度升级。</p><p></p><p>小冰公司前身为微软人工智能小冰团队，2020 年分拆为独立技术研发实体，实现完全本土化。小冰框架是全球实际落地及完备度最高的 AI Being 基础框架，覆盖中国、日本、印度尼西亚等国 6.6 亿在线用户、10 亿台第三方智能设备和 9 亿内容观众，商业客户覆盖全球，其中在智能车机领域渗透率超过 60%，在 AIGC 领域的商业化成果也已广泛应用于金融、文化、纺织、旅游等垂直领域。</p><p></p><h4>纵目科技：融资 10 亿元，拟在科创板上市</h4><p></p><p></p><p>2022 年 3 月 28 日，纵目科技宣布完成超过 10 亿元人民币的 E 轮融资，由东阳冠定领投，远海基金、临芯资本、佐誉资本、复朴资本、青岛元盈、泰有资本及老股东湖州环太湖集团和创徒投资跟投。</p><p></p><p>公开信息显示，纵目科技成立于 2013 年，总部位于上海张江国际科创中心，在上海、北京、厦门、深圳、重庆、美国密西根 Novi 市以及德国斯图加特都设有研发中心，生产制造中心位于厦门、湖州、东阳（在建）。纵目科技是自动驾驶（Autonomous Driving）和高级汽车辅助驾驶（Advanced Driving Assistance System）产品及技术供应商，拥有领先的算法能力、完整的系统设计能力和车规级别的生产制造能力。目前，公司已经形成了从基础研发到量产应用的完整产业链，当前核心业务涵盖智能驾驶系统、智能传感器和智慧城市产品及服务三大部分。</p><p></p><p>最新消息显示，纵目科技拟在科创板上市，申请已于 2022 年 11 月 23 日获受理。</p>",
    "publish_time": "2023-01-30 10:18:30",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "科学家被ChatGPT骗了",
    "url": "https://www.infoq.cn/article/U5xfFfPULVbkDSLR3PAQ",
    "summary": "<p></p><blockquote>根据最新研究，学者们可能会被 <a href=\"https://www.infoq.cn/article/FRcz5vjOvl3bM2d57opX\">ChatGPT</a>\" 所欺骗，他们误以为 ChatGPT 生成的虚假科学摘要来自顶级研究期刊上发表的真实医学论文。</blockquote><p></p><p></p><p>本文最初发布于 The Register。</p><p></p><h2>学者难以识别人工智能生成的假论文摘要</h2><p></p><p></p><p>近日，美国西北大学领导的一个研究小组使用 <a href=\"https://www.infoq.cn/article/ZWixRo76hFsOw38tRHNF\">OpenAI</a>\" 开发的文本生成工具，基于一篇真实科学论文的标题，采用五种不同的医学期刊风格生成了 50 篇摘要。</p><p></p><p>4 名学者参加了一项测试，他们被分为两组，每组两人。测试通过电子抛硬币的方式来决定将人工智能生成的摘要交给每组中的哪一名审核员。如果一名研究人员拿到的是真摘要，那么另一名研究人员拿到的就是假摘要，反之亦然。每个人都审阅了 25 篇科学摘要。</p><p></p><p>审核员能够识别出 68% 由人工智能生成的假摘要，和 86% 来自真实论文的原始摘要。换句话说，他们被成功欺骗，将 32% 的人工智能生成的摘要识别为真摘要，将 14% 的真摘要识别为假摘要。</p><p></p><p>该研究的第一作者、西北大学专攻肺病学的医生和科学家 Catherine Gao 说，这表明 ChatGPT 相当有说服力。她在一份声明中写道，“我们的审核员知道他们收到的部分摘要是假的，所以他们非常警惕”。</p><p></p><p>“事实上，我们的审核员还是在 32% 的时间里漏掉了人工智能生成的摘要，这表明这些摘要真的很好。我估计，如果有人偶然看到了其中一份生成的摘要，那么他们不一定能识别出那是由人工智能写的。”</p><p></p><h2>大型语言模型生成的文本为什么能骗倒众人？</h2><p></p><p></p><p>像 ChatGPT 这样的<a href=\"https://www.infoq.cn/article/AWWsrfb54zTvglZ0I5qS\">大型语言模型</a>\"使用从互联网上抓取的大量文本进行训练。经过学习后，它们会通过预测在给定的句子中哪些词更有可能出现来生成文本，而且生成的文本语法准确。这并不奇怪，即使是学者也会上当受骗，相信人工智能生成的摘要是真的。</p><p></p><p>大型语言模型擅长生成具有清晰结构和模式的文本，科学摘要通常采用类似的格式，而且可能相当模糊。</p><p></p><p>Gao 说：“我们的审核员评论说，区分真假摘要非常困难。ChatGPT 生成的摘要非常有说服力……当编造数值时，它甚至知道患者群体应该有多大。”例如，一篇关于高血压的假摘要描述了一项有数万名参与者的研究，而一篇关于猴痘的研究涉及的患者则较少。</p><p></p><p>Gao 认为，像 ChatGPT 这样的工具将使靠出版研究成果获利的造纸厂更容易炮制虚假科学论文。她补充说，“如果其他人试图以这些不正确的研究为基础进行科学研究，那可能真的很危险”。</p><p></p><p>不过，使用这些工具也有好处。这项研究的合作者、芝加哥大学医学副教授 Alexander Pearson 说，它们可以帮助母语非英语的科学家更好地写作和分享他们的工作。</p><p></p><p>人工智能比人类更擅长检测机器文本。例如，免费的 GPT-2 输出检测器能够以超过 50% 的置信区间从 50 篇由语言模型生成的论文中猜出 33 篇。研究人员认为，提交的论文应该通过这些探测器的检测，科学家应该公开使用这些工具。</p><p></p><p>Gao 告诉 The Register，“我们在撰写自己的摘要或手稿时没有使用 ChatGPT，因为这是否可接受在学术界还没有清晰的边界。例如，国际机器学习大会已经制定了一项政策，禁止使用它，不过他们承认，讨论仍在继续，并澄清说，在‘编辑或打磨’时使用是可以的。”</p><p></p><p>不过，已经有一些团体开始使用它来辅助写作，有些人还把它列为合著者。我认为，使用 ChatGPT 来辅助写作是可以的，重要的是，这样做的时候要明确标示 ChatGPT 辅助编写的那部分手稿。我们将来使用或不使用 LLM 来辅助撰写论文，取决于科学界最终达成的共识。”</p><p></p><p>原文链接：</p><p></p><p><a href=\"https://www.theregister.com/2023/01/11/scientists_chatgpt_papers/\">https://www.theregister.com/2023/01/11/scientists_chatgpt_papers/</a>\"</p>",
    "publish_time": "2023-01-30 12:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "长江存储被曝大裁员，员工购买福利房或遭索赔最高百万！网友：被裁后公司待你如垃圾，心都碎了！",
    "url": "https://www.infoq.cn/article/6CjBjAYJfNDRWbm9Vfbv",
    "summary": "<p></p><blockquote>长江存储这波裁员操作，在网上引发了轩然大波。</blockquote><p></p><p>&nbsp;</p><p>1月29日消息，据业内人士爆料，国内知名的半导体大厂长江存储1月开始大量裁员了。且由于福利房价格问题，部分员工或面临高额房屋差价赔偿。</p><p>&nbsp;</p><p>长江存储科技有限公司成立于2016年7月，总部位于武汉，由紫光集团、中国国家集成电路产业投资基金、湖北省集成电路产业投资基金、湖北科投在武汉新芯的基础上组建成立。据估计，长江存储目前是世界第六大NAND闪存制造商，排名在三星、<a href=\"https://www.infoq.cn/article/7gWZcTyHG4VPE3OyXVJC\">SK海力士</a>\"、铠侠、西部数据和美光(Micron)之后。</p><p></p><h2>员工爆料长江存储大裁员，公司要求赔偿福利房差价</h2><p></p><p>&nbsp;</p><p>近日，一名自称在<a href=\"https://www.infoq.cn/article/AIQbE0ABKAhuoeeWuAsw\">长江存储</a>\"干了四年多，并且买了员工福利房的网友在知乎平台爆料，1月16日接到裁员通知，并要求过年收假后上班第一天开始一个月内完成交接走人。同时，其还被要求支付职工福利费所购住房的差价，估计要支付几十万到上百万的违约金。</p><p>&nbsp;</p><p>据悉，长江存储有福利房，员工买房签了绑定协议，要求在公司干满五年，不然赔偿当初市场调查价（一万四千多一平）和给员工优惠的价格的差价，按户型面积绑定50万至100万不等，且协议没有写明公司主动裁员是否赔偿的事宜。</p><p>&nbsp;</p><p>有员工表示，<a href=\"https://www.infoq.cn/article/AIQbE0ABKAhuoeeWuAsw\">长江存储</a>\"国际社区所在的地段，有三个商品房小区的价格可以参考。世茂十里星河是地段最好的正地铁房，实际成交价在1.1万元左右；硅谷小镇毛坯房是地段第二好的，成交价大约在1万元上下，还送车位；中海光谷东麓的精装修房成交价约为1.2万元。按照内部员工的说法，长江存储的绑定价定到了1.45万元左右，卖给员工是9000元左右，如果员工被裁员就得赔偿给公司每平5500元左右。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/80/8047f12c7c38ce55cd1e81b356afafee.png\" /></p><p></p><p>&nbsp;也有在职的长江存储员工表示，长江存褚自被列入实体清单后，公司发展遇到了困境，要裁员也能理解，但公司的一些做法让人很难接受。</p><p>&nbsp;</p><p>该名员工称，“公司目前在走绩效低分路子，绩效低分、年终奖不发，公司走和员工协商离职的路线，这样公司就不是裁员或者辞退员工了，是员工自愿拿赔偿离职，也就是所谓的‘协商离职’。如果买房的员工接受了公司协商离职，那么以后公司可以宣称你是主动离职的，不是公司主动裁员、辞退的。 在房子绑定协议赔偿金掰扯的时候，员工将失去了公司主动辞退的证据，将必赔公司房子钱。然而公司HR和领导都在对员工威逼利诱，想着法子骗员工想让员工接受拿赔偿协商离职路子，把员工往火坑里推。”</p><p></p><h2>网友评论：被裁后公司待你如垃圾，心都碎了！</h2><p></p><p>&nbsp;</p><p>关于被裁掉员工的公司福利房的事情，员工寻问了长存科服的负责人，回复是只有未装修的可以退，只要装修了，必须赔几十万到上百万不等的违约金，而且三年内赔完，否则法院见。</p><p>&nbsp;</p><p>对于长江存储的此等做法，匿名网友在知乎平台吐槽称，“企业效益不好时裁员很正常，但是对于明明是公司违约还要员工赔钱，如此霸王条款是不是太过分了？”</p><p>&nbsp;</p><p></p><blockquote>长存的员工房位置偏，定价高，就算拿在手里也卖不出去，如果没有为半导体奉献终身的理想，谁愿意买这房啊？对于刚工作的员工来说，把挣的工资再掏空家里的钱，都放到了房子里，天天加班到深夜，结果被裁了，公司把你当垃圾一样对待，心都碎了！</blockquote><p></p><p>&nbsp;</p><p>不过也有被裁员工表示，从长存离开不是一件坏事，很多人在外面发展都挺好。被裁员不是自己的能力问题，毕竟面试能通过的人，能在里面高薪工作的人，学历和能力都不差。企业被制裁经营不佳，大环境下行，要裁员，这是没有办法的。但是也希望公司能办得体面一些，拿出自己的担当，善待应届生和老员工，好聚好散。</p><p></p><h2>武汉第二家工厂建设计划或将推迟</h2><p></p><p>&nbsp;</p><p>长江存储此番大规模裁员，是公司经营状况不佳的缩影。据集微网消息，由于采购<a href=\"https://www.infoq.cn/article/z9DfpZCh0femWpQ6awVp\">供应链</a>\"中断，长江存储可能推迟在武汉的第二家晶圆厂的建设。</p><p>&nbsp;</p><p>据南华早报报道，清华大学集成电路学院教授魏少军上周在论坛上赞扬了长江存储的技术创新，但警告说，在美国对向中国出口尖端半导体技术实施制裁后，中国需要将重点转移到成熟的技术开发上。</p><p>&nbsp;</p><p>外国芯片专家表示，长江存储实现技术进步和批量生产的能力将受到其无法免费获得美国芯片制造工具和服务的阻碍。</p><p>&nbsp;</p><p>研究机构<a href=\"https://www.infoq.cn/article/yfk3blm256QT7GJHCs1v\">TrendForce</a>\"也在一份研究报告中指出，如果没有关键设备供应商的支持，长江存储现在在其最新的3D NAND闪存技术Xtacking 3.0的开发中面临着巨大的技术障碍。尤其是提高128层和232层工艺的良率对中国内存制造商来说将极具挑战性。</p><p>&nbsp;</p><p>另一位行业专家、华为前技术人员称，长江存储并不缺乏光刻系统，因为它在实施限制之前已购买数台光刻系统，但挑战在于泛林集团等供应商的蚀刻工具。这些工具对于复杂的3D NAND晶圆制造工艺至关重要。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.zhihu.com/question/579189179\">https://www.zhihu.com/question/579189179</a>\"</p><p><a href=\"https://www.163.com/dy/article/HS8FVSCJ0511DT6P.html?f=post1603_tab_news\">https://www.163.com/dy/article/HS8FVSCJ0511DT6P.html?f=post1603_tab_news</a>\"</p>",
    "publish_time": "2023-01-30 14:20:17",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "我用 Rust 改写了自己的C++项目：这两个语言都很折磨人！",
    "url": "https://www.infoq.cn/article/gWoHTU1gilTd2jRvrSqf",
    "summary": "<p></p><p></p><blockquote>C++漫长的构建时间可谓臭名昭著，编程圈的“我的代码在编译”只是个段子，但C++让这个段子长盛不衰。</blockquote><p></p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f6/f6855b212d651b2541cd86e41fe43613.png\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>谷歌Chromium规模的项目在新硬件上的构建时间<a href=\"https://textslashplain.com/2020/02/02/my-new-chromium-build-pc/\">长达一小时</a>\"，而在老硬件上的构建时间更是<a href=\"https://randomascii.wordpress.com/2020/03/30/big-project-build-times-chromium/\">达到了六个小时</a>\"。虽然也有海量的<a href=\"https://chromium.googlesource.com/chromium/src/+/HEAD/docs/windows_build_instructions.md#Faster-builds\">调整方案</a>\"能加速构建速度，还有不少削减构建内容但<a href=\"https://chromium.googlesource.com/playground/chromium-org-site/+/refs/heads/main/chromium-os/build/improving-build-times.md\">极易出错的捷径</a>\"供人选择，再加上数千美元的云计算能力，Chromium的构建时间仍是接近十分钟。这点我完全无法接受，人们每天都是怎么干活的啊？</p><p>&nbsp;</p><p>有人说Rust也是一样，构建时间同样令人头疼。但事实就是如此，还是这仅仅是一种反Rust的宣传手段？在构建时间方面Rust和C++究竟谁能更胜一筹呢？</p><p>&nbsp;</p><p>构建速度和运行时性能对我来说非常重要。构建测试的周期越短，我编程就越高效、越快乐。我会不遗余力地让我的软件速度更快，让我的客户也越快乐。因此，我决定亲自试试Rust的构建速度到底怎么样，计划如下：</p><p>&nbsp;</p><p>找一个C++项目把项目中的一部分单独拿出来逐行将C++代码重写为Rust优化C++和Rust项目的构建对比两个项目的构建测试时间</p><p>&nbsp;</p><p>我的猜想如下（有理有据的猜测，但不是结论）：</p><p>&nbsp;</p><p>Rust的代码行数比C++少。C++中多数函数和方法都需要声明两次：一次在header里，一次在实现文件里。但Rust不需要，因此代码行数会更少C++的完整构建时间比Rust长（Rust更胜一筹）。在每个.cpp文件里，都需要重新编译一次C++的#include&nbsp;功能和模板，虽然都是并行运行，但并行不等于完美。Rust的增量构建时间比C++长（C++更胜一筹）。Rust一个crate（独立可编译单元）一编译，但C++是按文件编译。因此代码每次变动，Rust要读取的比C++多。·</p><p>&nbsp;</p><p>对此，大家怎么看呢？我在推特上的投票结果如下：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/95/9569654b9f2a02669758ee1995174d8d.png\" /></p><p></p><p>&nbsp;</p><p>42%的人认为C++会赢，35%同意“看情况”，另外17%的则觉得Rust会让我们大吃一惊。</p><p>&nbsp;</p><p>那么结果到底如何呢？下面让我们进入正题。</p><p>&nbsp;</p><p></p><h2>编写C++和Rust的测试对象</h2><p></p><p></p><h3>找个项目</h3><p></p><p>考虑到我未来一个月都要花在重写代码上，什么样的代码最合适？我认为得满足以下几点：</p><p>&nbsp;</p><p>很少或不用第三方依赖（标准库可以使用）；能在Linux和macOS上运行（我不怎么管Windows上的构建时间）；大量测试套组（不然我没法确定Rust代码的正确性）；FFI（外部函数接口）、指针、标准或自定义容器、功能类和函数、I/O、并发、泛型、宏、SIMD（单指令多数据流）、继承等等，多少都有使用。</p><p>&nbsp;</p><p>其实答案也很简单，直接找我前几年一直在做的项目就行。我用的是一个JavaScript词法分析器，<a href=\"https://quick-lint-js.com/\">quick-lint-js</a>\"项目。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/8b/8b23a474a21eb51f465cd7e24e8de370.png\" /></p><p></p><p>quick-lint-js的吉祥物Dusty</p><p>&nbsp;</p><p></p><h3>截取C++代码</h3><p></p><p>&nbsp;</p><p>quick-lint-js项目中C++部分的代码行数超过10万，要把这些全改成Rust得花上我半年时间，不如只关注JavaScript词法分析部分，其中涉及项目中的：</p><p>&nbsp;</p><p>诊断系统翻译系统（用于诊断）各种内存分配器和容器（如bump分配器、适用于SIMD的字符串）各种功能类函数（如UTF-8解码器、SIMD内在包装器）测试的辅助代码（如自定义断言宏）C的API</p><p>&nbsp;</p><p>可惜这部分代码里不涉及并发或I/O，我测试不了Rust里async/await的编译时间开销，但这只是quick-lint-js项目里的一小部分，所以我还不用太担心。</p><p>&nbsp;</p><p>我首先把所有的C++代码都复制到新项目里，然后删掉已知与词法分析无关的部分，比如分析器和LSP服务器。我甚至一不小心删多了代码，最后不得不重新把这些代码添了回去。在我不断截代码的过程中，C++的测试一直保持了通过状态。</p><p>&nbsp;</p><p>在彻底将quick-lint-js项目中涉及词法分析的部分全截出来之后，项目中C++的代码大约有1.7万行。</p><p></p><p>&nbsp;</p><p></p><h3>重写代码</h3><p></p><p>&nbsp;</p><p>至于要怎么重写这上千行的C++代码，我选择按部就班：</p><p>&nbsp;</p><p>找一个适合转换的模块；复制黏贴代码、测试、搜索替换并修改部分语法、继续运行cargo（Rust的构建系统和包管理器）测试直到构建测测试都通过；如果这个模块依赖另一个模块，那就找到被依赖的模块，继续进行第二步，然后再回到现在这个模块；如果还有模块没转换，再回到第一步。</p><p>&nbsp;</p><p>主要影响Rust和C++构建时间的问题在于，C++的诊断系统是通过大量代码生成、宏、constexpr（常量表达式）实现的，而我在重写Rust版时，则用了代码生成、proc宏、普通宏以及一点点const实现。传闻proc宏速度很慢，也有说是因为代码质量太差导致的proc宏速度慢。希望我写的proc宏还可以（祈祷～）。</p><p>&nbsp;</p><p>我写完才发现，原来Rust项目比C++项目还要大，Rust代码17.1k行，而C++只有16.6k行。</p><p>&nbsp;</p><p></p><p>&nbsp;</p><p></p><h2>优化Rust构建</h2><p></p><p>&nbsp;</p><p>构建时间很重要，因为我在截取C++代码之前就已经做好了C++项目构建时间的优化，所以我现在只需要对Rust项目的构建时间做同样的优化即可。以下是我觉得可能会优化Rust构建时间的条目：</p><p>&nbsp;</p><p>更快的链接器Cranelift后端编译器和链接器标志工作区与测试布局区分最小化依赖功能cargo-nextest使用PGO自定义工具链</p><p>&nbsp;</p><p></p><h4>更快的链接器</h4><p></p><p>&nbsp;</p><p>我第一步要做的是分析构建，我用的是<a href=\"https://doc.rust-lang.org/beta/unstable-book/compiler-flags/self-profile.html\">-Zself-profile rustc标志</a>\"。在这个标志所生成的两个文件里，其中一个文件中的run_linker阶段颇为突出：</p><p>&nbsp;</p><p></p><p>第一轮-Zself-profile结果</p><p>&nbsp;</p><p>之前我通过向<a href=\"https://github.com/rui314/mold\">Mold链接器</a>\"的转换成功优化了C++的构建时间，那这套对Rust能否行得通？</p><p>&nbsp;</p><p>Linux：链接器性能几乎一致。（数据越小越好）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/68/68df4580b3154ab77570c918bad746d5.png\" /></p><p></p><p></p><p>可惜，Linux上虽然确实有提升，但效果不明显。那macOS上的优化又表现如何？在macOS上默认链接器的替代品有两种，lld和zld，效果如下：</p><p>&nbsp;</p><p>macOS：链接器性能几乎不变。（数据越小越好）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fe/fe6c8c73efcdb7eca2c3b942e22b93e5.png\" /></p><p></p><p>&nbsp;可以看出，macOS上替换默认链接器的效果同样不明显，我怀疑这可能是因为Linux和macOS上的默认链接器对我的小项目而言已经做到了最好，这些优化后的链接器（Mold、lld、zld）在大型项目上效果非常好。</p><p>&nbsp;</p><p></p><h4>Cranelift后端</h4><p></p><p>&nbsp;</p><p>让我们再回到<a href=\"https://doc.rust-lang.org/beta/unstable-book/compiler-flags/self-profile.html\">-Zself-profile</a>\"的另一篇报告上，LLVM_module_­codegen_emit_obj和LLVM_passes阶段颇为突出：</p><p></p><p>-Zself-profile的第二轮结果</p><p>&nbsp;</p><p>传闻可以把rustc的后端从LLVM换成Cranelift，于是我又用<a href=\"https://github.com/bjorn3/rustc_codegen_cranelift\">rustc Cranelift后端</a>\"重新构建了一遍，-Zself-profile结果看起来不错：</p><p>&nbsp;</p><p></p><p>使用Cranelife的-Zself-profile第二轮结果</p><p>&nbsp;</p><p>可惜，在实际的构建中Cranelife比LLVM慢。</p><p>&nbsp;</p><p>Rust后端：默认LLVM比Cranelift强。（测试于Linux，数据越小越好）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/16/169a32ce659c5150158daaff43642790.png\" /></p><p></p><p>&nbsp;</p><p>2023年1月7日更新：rustc 的 Cranelift 后端维护者bjorn3帮我看了下为什么Cranelift在我的项目上效果不佳：可能是rustup的开销导致的。如果绕过这部分Cranelife效果可能会有提升，上图中的结果没有采用任何措施。</p><p>&nbsp;</p><p></p><h4>编译器和链接器标志</h4><p></p><p>&nbsp;</p><p>编译器里有一堆可以加快（或减缓）构建速度的选项，让我们一一试过：</p><p>&nbsp;</p><p>-Zshare-generics=y&nbsp;(rustc) (Nightly only)-Clink-args=-Wl,-s&nbsp;(rustc)debug = false&nbsp;(Cargo)debug-assertions = false&nbsp;(Cargo)incremental = true&nbsp;且 incremental = false&nbsp;(Cargo)overflow-checks = false&nbsp;(Cargo)panic = 'abort'&nbsp;(Cargo)lib.doctest = false&nbsp;(Cargo)lib.test = false&nbsp;(Cargo)</p><p>&nbsp;</p><p>rustc标志：快速构建优于调试构建。（测试于Linux，数据越小越好）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b4/b4f27588913e75bdf2d9ee8b5c3b8264.png\" /></p><p></p><p>&nbsp;</p><p>注：图中的“quick, -Zshare-generics=y”与“quick, incremental=true”且启用“-Zshare-generics=y”标志相等同，其余柱状图没有标识“-Zshare-generics=y”是因为没有启用该标志，后者意味着需要nightly rust编译器。</p><p>&nbsp;</p><p>上图中使用的多数选项都有文档可查，但我还没找到有人写过加-s的链接。子命令-s将包括Rust标准库静态链接在内的所有调试信息全部剥离，让链接器做更少的工作，从而减少链接时间。</p><p>&nbsp;</p><p></p><h4>工作区与测试布局</h4><p></p><p>&nbsp;</p><p>在文件的物理位置问题上，Rust和Cargo都提供了部分灵活性。对我的项目而言，以下是三种合理布局：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f7/f726f8c259f4f84fc1e4f3b92e09f164.png\" /></p><p></p><p>&nbsp;</p><p>理论上来说，如果我们把代码拆成多个crate，cargo就可以并行化rustc的调用。鉴于我的Linux机器上有一个32线程的CPU，macOS机器上有一个10线程的CPU，并行化应该可以降低构建时间。</p><p>&nbsp;</p><p>对一个crate而言，Rust项目中的测试有很多可运行的地方：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/87/871b42b11b348e36d9d2cf788019ed16.png\" /></p><p></p><p>&nbsp;由于依赖周期的存在，我没办法做“源码文件内的测试”这个布局的基准，但其他布局组合里我都做了基准：</p><p>&nbsp;</p><p>Rust完整构建：工作区布局最快。（测试于Linux，数据越小越好）</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/04/049eaf9ed425f3953d6b1ff2a7f20d0a.png\" /></p><p></p><p>&nbsp;Rust增量构建：最佳布局不明。（测试于Linux，数据越小越好）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/90/90e2912e380023cae041fdcfd08975f6.png\" /></p><p></p><p>&nbsp;</p><p>工作区设置中，无论是分成多个可执行测试（many test exes），还是合并成一个可执行测试，似乎都能斩获头筹。所以后续我们还是按照“工作区+多个可执行文件”的配置吧。</p><p></p><h4>最小化依赖功能</h4><p></p><p>&nbsp;</p><p>多个crate的拆分支持可选功能，而部分可选功能都是默认启用的，具体功能可以通过cargo tree命令查看：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b9/b9bf7d9c2c77871a7fb5fab19c7efb89.png\" /></p><p></p><p>&nbsp;</p><p>让我们把crate之一，libc中的std功能关掉，测试后再看看构建时间有没有变化。</p><p>&nbsp;</p><p>Cargo.toml</p><p><code lang=\"null\"> [dependencies]\n+libc = { version = \"0.2.138\", default-features = false }\n-libc = { version = \"0.2.138\" }</code></p><p></p><p>关掉libc功能后没有任何变化。（测试于Linux，数据越小越好）</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a9/a90f5fb32af9e85a7756b3771b159c1a.png\" /></p><p></p><p>&nbsp;构建时间没有任何变化，有可能std功能实际没什么大影响。不管怎么说，让我们进入下一个环节。</p><p>&nbsp;</p><p></p><h4>cargo-nextest</h4><p></p><p>作为一款据说“比cargo测试快60%”的工具，<a href=\"https://nexte.st/\">cargo-nextest</a>\"对于我这个代码中44%都是测试的项目来说非常合适。让我们来对比下构建和测试时间：</p><p>&nbsp;</p><p>Linux：cargo-nextest减慢了测试速度。（数据越小越好）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/96debaae2b7cc567da01c13765648264.png\" /></p><p></p><p>&nbsp;</p><p>在我的Linux机器上，cargo-nextest帮了倒忙，虽然输出不错，不过……</p><p>&nbsp;</p><p>示例cargo-nextest测试输出：</p><p><code lang=\"null\">PASS [   0.002s]        cpp_vs_rust::test_locale no_match\nPASS [   0.002s]     cpp_vs_rust::test_offset_of fields_have_different_offsets\nPASS [   0.002s]     cpp_vs_rust::test_offset_of matches_memoffset_for_primitive_fields\nPASS [   0.002s] cpp_vs_rust::test_padded_string as_slice_excludes_padding_bytes\nPASS [   0.002s]     cpp_vs_rust::test_offset_of matches_memoffset_for_reference_fields\nPASS [   0.004s] cpp_vs_rust::test_linked_vector push_seven</code></p><p>&nbsp;</p><p>那macOS上怎么说？</p><p>&nbsp;</p><p>macOS：cargo-nextest加快了构建测试。（数据越小越好）</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/1f/1f7fe678613d8873e5f25dd05efb7b68.png\" /></p><p></p><p>&nbsp;</p><p>在我的MacBook pro上，cargo-nextest确实提高了构建测试的速度。但为什么Linux上没有呢？难道是和硬件有关？</p><p>&nbsp;</p><p>在下面测试中，我会在macOS上使用cargo-nextest，但Linux上的测试不用。</p><p>&nbsp;</p><p></p><h4>使用PGO自定义工具链</h4><p></p><p>&nbsp;</p><p>我发现C++编译器的构建如果用配置文件引导的优化（PGO，也称作FDO），会有明显的性能提升。因此，让我们试试用PGO优化Rust工具链的同时，也用LLVM BOLT加上-Ctarget-cpu=native进一步优化rustc。</p><p>&nbsp;</p><p>Rust工具链：自定义工具链是最快的。（测试于Linux，数据越小越好）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0b/0b852c548b2777b82a1ba6aef03ad8ed.png\" /></p><p></p><p>&nbsp;</p><p>如果你好奇的话，可以看看这段工具链构建脚本。可能不适用于你的机器，但只要我能运行就行：<a href=\"https://github.com/quick-lint/cpp-vs-rust/blob/953429a4d92923ec030301e5b00face1c13bb92b/tools/build-toolchains.sh\">https://github.com/quick-lint/cpp-vs-rust/blob/953429a4d92923ec030301e5b00face1c13bb92b/tools/build-toolchains.sh</a>\"</p><p>&nbsp;</p><p>与C++编译器相比，通过rustup发布的Rust工具链似乎已经是优化完成的结果。PGO加上BOLT的组合只带来了不到10%的性能提升。但有提升就是好的，所以在后续与C++的竞争中我们会继续使用这个速度最快的工具链。</p><p>&nbsp;</p><p>我第一次搭建的Rust自定义工具链比Nightly还要慢2%，我在Rust config.toml的各种选项中反复调整，不断交叉检查Rust的CI构建脚本以及我自己的脚本，最终在好几天的挣扎后才让这二者性能持平。在我最终润色这篇文章时，我进行了rustup更新，拉取git项目，并重头又建了一遍工具链。结果这次我的自定义工具链速度更快了！有可能是我在Rust仓库里提交错了代码……</p><p>&nbsp;</p><p></p><h2>优化C++构建</h2><p></p><p>&nbsp;</p><p>在最初的C++项目quick-lint-js中，我已经用常见的手段优化了编译时间，比如用PCH、禁用异常和RTTI、调整编译标志、删除非必要#include、将代码从头中移出、外置模板实例等方法。但此外还有一些C++编译器和链接器我没试过，在我们进入C++和Rust的对比之前，先从这些里面挑出最适合我们的。</p><p>&nbsp;</p><p>Linux：自定义Clang是最快的工具链。（数据越小越好）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bc/bc278d3f06321c38a0f9cfd61714ccd4.png\" /></p><p></p><p>&nbsp;很明显，Linux上的GCC是个特例，而Clang的表现则要好上很多。我自定义构建的Clang（和Rust工具链一样，也是用PGO和BOLT构建的）相较于Ubuntu的Clang，显著优化了构建时间，而libstdc++的构建略快于平均libc++的速度。</p><p>&nbsp;</p><p>那我的自定义Clang加上libstdc++在C++和Rust的对比中表现如何呢？</p><p>&nbsp;</p><p>macOS：Xcode是最快的工具链。（数据越小越好）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8d/8dcac7b9621973a291fed60136095d6a.png\" /></p><p></p><p>&nbsp;在macOS上，搭配Xcode的Clang工具链似乎要比LLVM网站上的Clang工具链优化得更好。</p><p>&nbsp;</p><p></p><h4>C++20模块</h4><p></p><p>&nbsp;</p><p>我的C++代码用的是#include，但如果用C++20中新增加的import又会怎么样呢？C++20的模块是不是理论上来说应该会让编译速度超级快？</p><p>&nbsp;</p><p>我在项目了尝试过C++20 模块，但直到2023年的1月3日，Linux上的CMake模块支持过于实验性质了，我甚至连“hello world”都没跑起来。</p><p>&nbsp;</p><p>或许2023年中C++20模块会大放异彩，对于我这种超级在意构建时间的人来说，真是这样就太好了。但目前为止，我还是继续用经典C++的#include和Rust做对比吧。</p><p>&nbsp;</p><p></p><h2>对比C++和Rust的构建时间</h2><p></p><p>&nbsp;</p><p>通过把C++项目改写成Rust，并尽可能地优化Rust的构建时间后，问题来了：C++和Rust究竟谁更快呢？</p><p>&nbsp;</p><p>很可惜，答案是“看情况”！</p><p>&nbsp;</p><p>Linux：Rust部分情况下构建速度超越C++。（数据越小越好）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c6/c673b441aea09bfd65badd311a97773b.png\" /></p><p></p><p>&nbsp;在我的Linux机器上，部分情况下Rust的构建速度确实优于C++，但也有速度持平或逊于C++的情况。在增量lex的基准上，我们修改了大量源码，Clang比rustc速度快，但在其他增量基准上，rustc又会反超Clang。</p><p>&nbsp;</p><p>macOS：C++构建速度通常快于Rust。（数据越小越好）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8f/8fd7a2a12609b2d791883f78b650cd95.png\" /></p><p></p><p>&nbsp;但我的macOS机器上情况却截然不同。C++的构建速度常常快上Rust许多。在增量测试utf-8的基准，我们修改中等数量测试文件，rustc编译速度会略微超过Clang，但在包括全量构建等其他基准上，Clang很明显效果要更好。</p><p>&nbsp;</p><p></p><h3>超过17k行代码</h3><p></p><p>&nbsp;</p><p>我基准测试的项目只有17k行代码，算是小型项目，那么对超过10万行代码的大型项目来说，又是什么情况呢？</p><p>&nbsp;</p><p>我把最大的模块，也就是词法分析器的代码复制粘贴了8、16以及24遍，分别用来测试。因为我的基准里也包括了运行测试的时间，我觉得构建时间即使是对于那些能瞬间构建完的项目，也应该会线性增长。</p><p>&nbsp;</p><p></p><p>&nbsp;</p><p>倍数扩大后C++完整构建优于Rust。（测试于Linux，数据越小越好）</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7d/7d9fdafc8eabd41f77c347d845f0cda8.png\" /></p><p></p><p>&nbsp;</p><p>倍数扩大后C++增量构建优于Rust。（测试于Linux，数据越小越好）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/89/89bf2c5d3feb24dcfc8be5fdd84b9302.png\" /></p><p></p><p>&nbsp;</p><p>Rust和Clang确实都是线性扩大，这点很好。</p><p>&nbsp;</p><p>正如预期中一样，修改C++的头文件，也就是增量diag-type会大幅影响构建时间。而由于Mold链接器的存在，其他增量基准中构建时间的扩展系数很低。</p><p>&nbsp;</p><p>Rust构建的扩展性让我很失望，即使只是增量utf-8测试的基准，无关文件的加入也不应该让它的构建时间如此受影响。测试所用的crate布局时“工作区且多个可执行测试”，因此utf-8测试应该能独立编译可执行文件。</p><p></p><h2>结论</h2><p></p><p>&nbsp;</p><p>编译时间对Rust而言算是问题吗？答案是肯定的。虽然也有一些可以加快编译速度的提示和技巧，但却没有效果非常显著的数量级改进，这让我在开发Rust时非常高兴。</p><p>&nbsp;</p><p>Rust的编译时间和C++相比呢？确实也很糟。至少对我的编码风格来说，Rust在大型项目上开发的编译时间甚至更加远比C++还要糟糕。</p><p>&nbsp;</p><p>再回过头看看我当初的假设，几乎全军覆没：</p><p>&nbsp;</p><p>Rust改写版代码行数比C++多；在全量构建上，C++相比Rust在1.7万行代码上构建时间相似，在10万行代码上构建时间要少；在增量构建上，Rust相比C++在部分情况构建时间要短，在1.7万行上构建时间要长，在10万行代码上构建时间甚至更长。</p><p>&nbsp;</p><p>我不爽吗？确实。在改写过程中，我不断学习着Rust相关的知识，比如proc marco能替代三个不同代码生成器，简化构建流水线，让新开发者们日子更好过。但我完全不想念头文件，以及Rust的工具类真的很好用，特别是Cargo、rustup以及miri。</p><p>&nbsp;</p><p>但我决定不把quick-lint-js项目中剩下的代码也改成Rust，但如果Rust的构建时间能有明显优化，或许我会改变主意。当然，前提是我还没被<a href=\"https://ziglang.org/\">Zig</a>\"迷走心神。</p><p>&nbsp;</p><p></p><h2>附注</h2><p></p><p></p><h3>源码</h3><p></p><p>删减后的C++<a href=\"https://github.com/quick-lint/cpp-vs-rust\">项目源码</a>\"、移植版Rust（包括不同的项目布局）、代码生成脚本和基准测试脚本、GPL-3.0及以上。</p><p>&nbsp;</p><p></p><h4>Linux机器</h4><p></p><p>名称：strapurp</p><p>CPU：AMD Ryzen 9 5950X (PBO; stock clocks) (32 threads) (x86_64)</p><p>RAM：G.SKILL F4-4000C19-16GTZR 2x16 GiB (overclocked to 3800 MT/s)</p><p>操作系统：Linux Mint 21.1</p><p>内核：Linux strapurp 5.15.0-56-generic #62-Ubuntu SMP Tue Nov 22 19:54:14 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux</p><p>Linux性能治理器：schedutil</p><p>CMake：版本3.19.1</p><p>Ninja：版本1.10.2</p><p>GCC：版本12.1.0-2ubuntu1~22.04</p><p>Clang（Ubuntu）：版本14.0.0-1ubuntu1</p><p>Clang （自定义）：版本15.0.6（Rust fork; 代码提交<a href=\"https://github.com/rust-lang/llvm-project/tree/3dfd4d93fa013e1c0578d3ceac5c8f4ebba4b6ec\">3dfd4d93fa013e1c0578­d3ceac5c8f4ebba4b6ec</a>\"）</p><p>libstdc++ for Clang：版本11.3.0-1ubuntu1~22.04</p><p>Rust稳定版：1.66.0 (69f9c33d7 2022-12-12)</p><p>Rust Nightly：版本1.68.0-nightly (c7572670a 2023-01-03)</p><p>Rust（自定义）：版本1.68.0-dev (c7572670a 2023-01-03)</p><p>Mold：版本0.9.3 (ec3319b37f653dccfa4d­1a859a5c687565ab722d)</p><p>binutils：版本2.38</p><p>&nbsp;</p><p></p><h4>macOS 机器</h4><p></p><p>名称：strammer</p><p>CPU：Apple M1 Max (10 threads) (AArch64)</p><p>RAM：Apple 64 GiB</p><p>操作系统：macOS Monterey 12.6</p><p>CMake：版本3.19.1</p><p>Ninja：版本1.10.2</p><p>Xcode Clang：Apple clang 版本14.0.0 (clang-1400.0.29.202) (Xcode 14.2)</p><p>Clang 15：版本15.0.6 (LLVM.org website)</p><p>Rust稳定版：1.66.0 (69f9c33d7 2022-12-12)</p><p>Rust Nightly：版本1.68.0-nightly (c7572670a 2023-01-03)</p><p>Rust（自定义）：版本1.68.0-dev (c7572670a 2023-01-03)</p><p>lld：版本15.0.6</p><p>zld：代码提交 d50a975a5fe6576ba0fd­2863897c6d016eaeac41</p><p>&nbsp;</p><p></p><h4>基准</h4><p></p><p>用deps的构建和测试</p><p>C++：cmake -S build -B . -G Ninja &amp;&amp; ninja -C build quick-lint-js-test &amp;&amp; build/test/quick-lint-js-test&nbsp;计时</p><p>Rust：cargo fetch&nbsp;未计时，再用&nbsp;cargo test&nbsp;计时</p><p>&nbsp;</p><p>不用deps的构建和测试</p><p>C++：cmake -S build -B . -G Ninja &amp;&amp; ninja -C build gmock gmock_main gtest&nbsp;未计时, 再用ninja -C build quick-lint-js-test &amp;&amp; build/test/quick-lint-js-test&nbsp;计时</p><p>Rust：cargo build --package lazy_static --package libc --package memoffset\"&nbsp;未计时, 再用cargo test&nbsp;计时</p><p>&nbsp;</p><p>增量diag-types</p><p>C++：构建和测试未计时，随后修改diagnostic-types.h，再用ninja -C build quick-lint-js-test &amp;&amp; build/test/quick-lint-js-test</p><p>Rust：构建和测试未计时，修改diagnostic_types.rs后，cargo test</p><p>&nbsp;</p><p>增量lex</p><p>同增量diag-types，但使用lex.cpp/lex.rs</p><p>&nbsp;</p><p>增量utf-8测试</p><p>同增量，但使用test-utf-8.cpp/test_utf_8.rs</p><p>&nbsp;</p><p>每个可执行基准均采用12个样本，弃置前两个，基准仅显示最后十个样本的平均性能。误差区间展示最小与最大样本间区别。</p><p></p><p></p><p>原文链接：</p><p></p><p><a href=\"https://quick-lint-js.com/blog/cpp-vs-rust-build-times/\">https://quick-lint-js.com/blog/cpp-vs-rust-build-times/</a>\"</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-01-30 14:38:59",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "数百程序员专门教AI写代码、40个bug能修复31个，“取代程序员”这次要成真了？",
    "url": "https://www.infoq.cn/article/eGbSZBSKWEDxspQq8FLh",
    "summary": "<p>AI 在回答问题和编写代码方面已经变得相当出色。在一项新的研究课题中，ChatGPT尝试查找示例代码中的bug并给出修复建议。其表现远超现有程序，成功修复了40个bug中的31个。AI开始显现出强大的能力，一些人又开始担心程序员会失业了，在软件开发和编程中的历史中，这又是一次“狼来了”的故事吗？</p><p>&nbsp;</p><p></p><h2>ChatGPT现可查找并修复代码中的bug</h2><p></p><p>&nbsp;</p><p>最近几周，AI新贵ChatGPT迎来了一系列评测挑战。一项最新研究来自约翰内斯古腾堡大学和伦敦大学学院的计算机科学研究人员，他们发现ChatGPT能够从示例代码中发现错误并加以修复，且整体表现优于现有同类程序。</p><p>&nbsp;</p><p>研究人员将这40段bug代码提交至四种不同的代码修复系统，分别为ChatGPT、Codex、CoCoNut和Standard APR。在ChatGPT上，他们只需询问“这段代码有什么问题？”再将代码内容复制粘贴至聊天框内即可。在首轮测试中，ChatGPT的表现跟其他程序相差不大。ChatGPT解决了其中19个问题，Codex解决了21个，CoCoNut解决了19个，Standard APR解决了7个。研究人员发现ChatGPT给出的答案与Codex最为相似，“这倒是正常，毕竟ChatGPT和Codex来自同一语言模型家族。”</p><p>&nbsp;</p><p>但在收到首批答案之后，ChatGPT的强大能力开始表现出来，随后势如破竹般解决了31个问题，轻松超越了其他只能提供静态答案的同类工具。</p><p>&nbsp;</p><p>研究人员在报告中写道，“ChatGPT的一大核心优势，在于我们会在对话中直接交互，更详细地描述需求。我们发现，对于大部分请求，ChatGPT会要求提供关于问题和bug的更多细节信息。在向ChatGPT提供提示信息之后，其成功率得以进一步提高，修复了全部40个bug中的31个，成绩可谓一骑绝尘。”</p><p>&nbsp;</p><p>他们还发现，ChatGPT能够快速解决的某些问题，在其他程序上往往需要反复拉扯。“ChatGPT在修复bug时似乎表现出较高的不一致性。但对最终用户来说，只要多执行几次应该就能得到有价值的结果。”</p><p>&nbsp;</p><p>例如，当研究人员提交下图问题时，他们预期的答案是将n^=n-1替换为n&amp;=n-1。但ChatGPT给出的回应是“我无法判断程序中是否存在bug，请提供关于预期行为的更多信息。”经过研究人员的提示，ChatGPT在第三次回复中成功发现了问题。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9b/9b0684f026c83df6a8626fe2ffd86915.png\" /></p><p></p><p>&nbsp;</p><p>但在我们尝试将同样的问题输入给ChatGPT时，它的回答却截然不同。ChatGPT这次并未要求提供预期行为，而是在猜测我们想要达成怎样的效果。ChatGPT一直在根据用户输入进行学习，它似乎已经理解了这段代码的用途——也许就是从当初研究人员们的提示中学习而来。我们的验证交流与研究报告不同，而且下一次再试可能也不相同。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f7/f7efb66e7678713dd3b4078a314ce897.png\" /></p><p></p><p>&nbsp;</p><p>目前，帮助软件工程师查找和修复bug的产业已经汇聚起6亿美元的体量。此次研究的成功，也许将重新定义这块可观的业务市场。Sentry等流行平台已经成为软件团队的标配工具，通过发布问题报告和提供修复建议，大大增强开发者们编写高质量代码的能力。</p><p>&nbsp;</p><p></p><h2>OpenAI召集数百程序员，教AI写代码</h2><p></p><p>&nbsp;</p><p>无论是bug修复软件开发商还是软件工程师自己，显然都注意到了这波堪称历史转折点的趋势。ChatGPT 的所有者OpenAI也在不断增强AI的编程能力，根据 Semafor 的一份报告，OpenAI 在过去6个月中加大招聘力度，已经在全球范围内悄悄聘请了上千名承包商来培训其AI学习软件工程。&nbsp;</p><p>&nbsp;</p><p>在这近 1000 名承包商中，约 60% 的人负责“数据标记”，即创建大量图像、音频剪辑和其他信息，用于训练 AI 工具或自动驾驶系统；另外 40% 则是程序员，主要负责为 OpenAI 的模型创建数据以学习软件工程任务。</p><p>&nbsp;</p><p>此前，OpenAI从 GitHub 上抓取代码来训练其模型，而且OpenAI于2021年8月推出的产品Codex，已经可以实现将自然语言转换为工作代码，现在该公司的招聘热潮表明它正在进一步推进该技术，甚至有可能为一些程序员岗位创造出一个替代工具。&nbsp;</p><p>&nbsp;</p><p>Semafor 采访了南美的一位工程师，他表示自己参加了 OpenAI 的面试，该过程包含了五小时的无偿编码测试。这个测试有两个部分组成：对于一个给出的编码问题，OpenAI要求他用书面英语解释他将如何处理这个问题，并给出一个具体解决方案；查找 AI 代码中的错误并提供有关如何修复错误的解释。这位工程师告诉 Semafor，他认为公司希望将人类的思维过程输入到其人工智能技术中。&nbsp;</p><p>&nbsp;</p><p>事实上，据 Insider 最近的报道，一些亚马逊员工已经开始使用 ChatGPT来帮助编码。亚马逊内部的 Slack 消息显示，ChatGPT 已经被亚马逊用于许多不同的工作职能中，包括回答面试问题、编写软件代码和创建培训文档等。</p><p>&nbsp;</p><p>一名员工在 Slack 上表示，亚马逊 Amazon Web Services（AWS）云部门已经成立了一个小型工作组，以更好地了解人工智能对其业务的影响。通过测试，该团队发现 ChatGPT 在回答 AWS 客户支持问题方面“做得非常好”。此外，人工智能工具在创建培训文档方面也“非常出色”，在企业战略问题方面“非常强大”。另外，这名员工还在 Slack 上称，ChatGPT 在为 AWS Aurora 数据库工程师编写故障排除指南和回答“困难的”支持问题方面也“非常出色”，它还能够“弄清客户的公司目标”。</p><p>&nbsp;</p><p></p><h2>现在还取代不了程序员，那将来呢？</h2><p></p><p>&nbsp;</p><p>随着数百名程序员齐心协力“教”模型如何编写基本代码，ChatGPT 背后的技术可能会朝着一种新的软件开发方向发展，就像重型设备对建筑行业一样，给软件行业带来变革意义。</p><p>&nbsp;</p><p>而且自从ChatGPT 能力开始显现后，“程序员要失业了”、“取代程序员”之类的声音已经不绝于耳。大多数人对此嗤之以鼻，毕竟过去几十年来，我们听够了类似的声音，云服务、无服务器计算、低代码和无代码......每个技术浪潮的到来，都有人喊出“程序员要被替代了！”</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cf/cfa45170d21f4c229a845901391c5a09.jpeg\" /></p><p></p><p>&nbsp;</p><p>但还是有相当“激进”的声音，认为这次“替代程序员”并不是又一个“狼来了的故事”。</p><p>&nbsp;</p><p>今年一月份的ACM 通讯发表了一篇名为“编程的终结”的文章，预测在人工智能驱动的未来“编程将过时”。作者Matt Welsh是 Fixie.ai 的首席执行官兼联合创始人，他曾是哈佛大学计算机科学教授、谷歌工程总监、苹果工程主管。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6d/6d5ab59ad026ac741f5a5138a27d6ea6.jpeg\" /></p><p></p><p>&nbsp;</p><p></p><blockquote>我相信“编写程序”的传统想法正在走向灭绝，事实上，除了非常专业的应用程序之外，我们所知道的大多数软件将被经过训练而不是编程的人工智能系统所取代。在需要“简单”程序的情况下（毕竟，并非所有内容都需要在GPU集群上运行数千亿个参数的模型），这些程序本身将由AI生成，而不是手动编码。</blockquote><p></p><p>&nbsp;</p><p></p><blockquote>未来的工程师只需敲击几下键盘，就能启动一个包含四亿亿亿参数的模型实例，这个模型已经对人类知识的全部范围（或是部分）进行了编码，并随时准备执行机器要求的任何任务。让机器做自己想做的事，大部分脑力工作将是提出正确的示例、正确的训练数据和正确的方法来评估训练过程。</blockquote><p></p><p>&nbsp;</p><p></p><blockquote>我认为计算机科学作为一个领域正处于一个相当大的动荡之中，我们中很少有人真正做好了准备。</blockquote><p></p><p>&nbsp;</p><p>“我认为现在的争论主要围绕这些人工智能模型将在多大程度上彻底改变软件行业，”Welsh在一个视频采访中说，“这更多是一个程度的问题，而不是它到底会不会发生……”</p><p>&nbsp;</p><p>我们认为，现在ChatGPT取代程序员是不太可能的，但是也许下一代开发人员必须习惯人工智能，毕竟让AI帮助我们编程就在不远的未来。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.pcmag.com/news/watch-out-software-engineers-chatgpt-is-now-finding-fixing-bugs-in-code\">https://www.pcmag.com/news/watch-out-software-engineers-chatgpt-is-now-finding-fixing-bugs-in-code</a>\"</p><p><a href=\"https://www.businessinsider.com/openai-chatgpt-contractors-train-ai-software-engineering-autonomous-vehicles-report-2023-1\">https://www.businessinsider.com/openai-chatgpt-contractors-train-ai-software-engineering-autonomous-vehicles-report-2023-1</a>\"</p><p><a href=\"https://cacm.acm.org/magazines/2023/1/267976-the-end-of-programming/fulltext\">https://cacm.acm.org/magazines/2023/1/267976-the-end-of-programming/fulltext</a>\"</p>",
    "publish_time": "2023-01-30 15:15:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]