[
  {
    "title": "谷歌开源 AI 微调方法： Distilling Step-by-Step",
    "url": "https://www.infoq.cn/article/P2agXGEtoLNotk2Eb8xP",
    "summary": "<p>华盛顿大学和谷歌研究中心的一个团队最近开源了 <a href=\"https://blog.research.google/2023/09/distilling-step-by-step-outperforming.html\">Distilling Step-by-Step</a>\"（逐步蒸馏），一种用于微调规模较小的语言模型的技术。与标准微调相比，逐步蒸馏需要的训练数据更少，并且生成的模型更小，但模型性能却优于参数规模是它 700 倍的小样本提示大型语言模型 （LLM）。</p><p>&nbsp;</p><p>虽然 LLM 一般可以在提示较少的情况下在多种任务上有良好的表现，但由于其内存和算力要求过高，模型的托管是比较有挑战的。规模较小的模型在微调后也可以有良好的表现，但这需要工程师手动创建针对具体任务优化的数据集。逐步蒸馏的关键思想是使用 LLM 自动生成一个小型微调数据集，其中的数据有一个输入和一个输出标签，以及选择这个输出标签的“理由”。微调过程会训练这个小模型来预测输出标签并生成对应的理由。在 NLP 基准上评估时，小型微调模型的性能优于 540B PaLM 模型，同时仅需要这个基准测试的全部微调数据的 80%。据谷歌称：</p><p></p><p></p><blockquote>我们展示了，逐步蒸馏既减少了构建针对特定任务的较小模型所需的训练数据集规模，也减少了实现甚至超越小样本提示 LLM 的性能水平所需的模型大小。总的来说，逐步蒸馏提出了一种可以高效利用资源的范例，可以解决模型大小和所需训练数据之间的权衡问题。</blockquote><p></p><p></p><p>研究表明，增加 LLM 中的参数规模可以提高其性能，目前最先进的模型（例如 PaLM）拥有数百亿个参数。然而，这些大型模型价格昂贵，且难以用于推理，因为它们需要多个并行连接的 GPU 才能把这么多参数保存在内存里。最近的研究开发出了规模稍小的模型（例如 Meta 的 Llama 2），其性能表现差不多，但参数少了一个数量级；然而，这些小一些的模型还是很庞大，需求的算力也很高。</p><p>&nbsp;</p><p>要做出在特定任务上表现良好的小模型的一种方法，是使用针对具体任务收集的数据集来微调小规模语言模型。虽然这个数据集可能相对较小（大约有数千个示例），但其数据收集起来可能还是费时费钱。另一种选择是知识蒸馏，也就是使用大型模型作为较小模型的老师。 InfoQ 最近报道了谷歌开发的一项<a href=\"https://www.infoq.com/news/2023/01/google-llm-self-improvement/\">技术</a>\"，使用 PaLM LLM 来创建训练数据集，最后生成的微调模型的性能可与规模大 10 倍的 LLM 相媲美。</p><p>&nbsp;</p><p>逐步蒸馏确实需要微调数据集，但它减少了创建高性能模型所需的数据量。源数据集通过思维链提示输入 PaLM LLM，要求模型给出其答案的理由。输出结果是修正后的微调数据集，其中包含原始输入和答案以及理由。这个较小的目标模型经过微调来执行两项任务：回答原始问题并生成理由。</p><p>&nbsp;</p><p>谷歌使用四个 NLP 基准测试评估了他们的技术，每个基准都包含一个微调数据集。他们使用逐步蒸馏来修正这些数据集，并使用了参数不到 1B 的微调 T5 模型。他们发现，这些模型在仅使用数据集的一小部分数据的情况下，性能就比基线微调模型要好；在某些情况下只要 12.5% 的数据就有这样的表现。他们还发现，他们的 770M 参数模型在 ANLI 基准测试中的性能优于大它 700 倍的 540B 参数 PaLM，同时只需要 80% 的微调数据集数据。</p><p>&nbsp;</p><p>在 X（以前的 Twitter）上关于这项工作的讨论中，人工智能企业家 Otto von Zastrow 写道：</p><p></p><p></p><blockquote>这些结果非常厉害。我会把这种办法叫做合成数据生成，而不是蒸馏，我真的很好奇，如果你根据每个示例问题的合成理由来训练原始的 LLM 会发生什么事情。</blockquote><p></p><p></p><p>逐步蒸馏的源代码和训练数据集可在 <a href=\"https://github.com/google-research/distilling-step-by-step\">GitHub</a>\" 上获取。 Google Cloud 的 Vertex AI 平台还提供该算法的非公开预览。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/10/google-distillation/\">https://www.infoq.com/news/2023/10/google-distillation/</a>\"</p>",
    "publish_time": "2023-11-08 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "中国卓越技术团队访谈录 & 架构师特刊：软件产品中的AIGC",
    "url": "https://www.infoq.cn/article/Ba7kqNscXOQoaZAduZsz",
    "summary": "<h2>封面故事</h2>\n<ul>\n<li>我，一个 95 后，从阿里辞职与贾扬清去硅谷创业</li>\n</ul>\n<p>“建议大家不要被大模型束缚住。实际落地时，除了大模型外，还可以充分利用许多已存在的深度学习模型或传统模型。例如在图像处理方面，卷积神经网络（CNN）实际上可能比大模型更适用。”</p>\n<h2>独家对话·大模型领航者</h2>\n<ul>\n<li>被时代选中的智谱AI：成为OpenAI，超越OpenAI</li>\n</ul>\n<p>在创业早期，智谱AI不会强迫自己去接复杂的客户需求，因为这些需求很可能让团队陷入其中无法自拔。“更复杂的问题需要暂时搁置、等到能力更成熟时再解决。”智谱AI会坦诚自己的能力在什么水平上，在该水平上可以创造什么样的价值。</p>\n<ul>\n<li>丢掉LangChain、像Docker一样编排大模型应用程序：这支十余人的年轻创业团队如何在2个月做出一个LLMOps平台？</li>\n</ul>\n<p>“在创业初期，一些朋友和投资人认为市场潜力巨大，但竞争也激烈。云服务提供商、大模型公司以及机器学习和运营的公司都进入这个领域。我们的挑战在于如何应对竞争。”</p>\n<ul>\n<li>是全部重做还是融合改造？揭秘京东云言犀升级全过程</li>\n</ul>\n<p>大模型对一些传统技术确实有影响。因为LLM之前的模型几乎全都是专项的，任务越窄，表现越好。对于更通用、泛化的任务来说，大模型带来的效果确实是颠覆性的。</p>\n<h2>AIGC 实践前沿</h2>\n<ul>\n<li>文生图大型实践：揭秘百度搜索AIGC绘画工具的背后故事</li>\n</ul>\n<p>这是一个巨大的变革，从过去用户在全网寻找图像，转变为结合了查找图像和生成图像两种方式，以满足用户更具体的需求，这也在一定程度上鼓励用户更主动地表达他们真正的需求。</p>\n<ul>\n<li>AIGC 编程：代码编程模型的应用与挑战</li>\n</ul>\n<p>大型模型帮助程序员编写代码是一项很有价值的技术，但从商业角度来看，它并不一定是一个特别有利可图的生意。</p>\n<p>AIGC算法揭秘及产业落地应用分享</p>\n<p>使用大模型在某种程度上为我们提供了更多的可能性，但也引入了更多的复杂性。没有一个通用的模板或规则来告诉我们应该使用哪个模型。</p>\n<ul>\n<li>广告创意领域中AIGC的应用</li>\n</ul>\n<p>随着AI能力的提升，人们需要深入使用并掌握它。像fine-tuning、LangChain等我不会推荐，我会鼓励周围的人去深入使用AIGC，重点在于使用，好的AGI只需要被编译一次。</p>\n<h2>管理能力进阶</h2>\n<ul>\n<li>影响力打造：一位前 Twitter 8 年技术主管总结的经验教训</li>\n<li>日常沟通之道：走向果敢</li>\n<li>科技巨头是如何迷失方向的？探讨大型科技企业的问责制度</li>\n</ul>\n<h2>文章推荐</h2>\n<ul>\n<li>大模型部署昂贵的原因：用最贵的模型处理最基本任务，犹如“让兰博基尼送披萨”</li>\n<li>2023 年 AI 与开源行业：今年第一篇盘点文章出炉了</li>\n<li>ChatGPT 已成为2023年最大金矿，大家是怎么靠它挣到钱的？</li>\n</ul>",
    "publish_time": "2023-11-08 09:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Apache Doris 2.0 如何实现导入性能提升 2-8 倍",
    "url": "https://www.infoq.cn/article/8kEox8KdpTjOh4s1gRH4",
    "summary": "<p>数据导入吞吐是 OLAP 系统性能的重要衡量标准之一，高效的数据导入能力能够加速数据实时处理和分析的效率。随着<a href=\"http://doris.apache.org/\"> Apache Doris</a>\" 用户规模的不断扩大， 越来越多用户对数据导入提出更高的要求，这也为 Apache Doris 的数据导入能力带来了更大的挑战。</p><p></p><p>为提供快速的数据写入支持，Apache Doris 存储引擎采用了类似 LSM Tree 结构。在进行数据导入时，数据会先写入 Tablet 对应的 MemTable 中，MemTable 采用 SkipList 的数据结构。当 MemTable 写满之后，会将其中的数据刷写（Flush）到磁盘。数据从 MemTable 刷写到磁盘的过程分为两个阶段，第一阶段是将 MemTable 中的行存结构在内存中转换为列存结构，并为每一列生成对应的索引结构；第二阶段是将转换后的列存结构写入磁盘，生成 Segment 文件。</p><p></p><p>具体而言，Apache Doris 在导入流程中会把 BE 模块分为上游和下游，其中上游 BE 对数据的处理分为 Scan 和 Sink 两个步骤：首先 Scan 过程对原始数据进行解析，然后 Sink 过程将数据组织并通过 RPC 分发给下游 BE。当下游 BE 接收数据后，首先在内存结构 MemTable 中进行数据攒批，对数据排序、聚合，并最终下刷成数据文件（也称 Segment 文件）到硬盘上来进行持久化存储。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d4/d42ba7c3789fe212c67c8382350dbf46.png\" /></p><p></p><p>而我们在实际的数据导入过程中，可能会出现以下问题：</p><p></p><p>因上游 BE 跟下游 BE 之间的 RPC 采用 Ping-Pong 的模式，即下游 BE 一个请求处理完成并回复到上游 BE 后，上游 BE 才会发送下一个请求。如果下游 BE 在 MemTable 的处理过程中消耗了较长的时间，那么上游 BE 将会等待 RPC 返回的时间也会变长，这就会影响到数据传输的效率。当对多副本的表导入数据时，需要在每个副本上重复执行 MemTable 的处理过程。然而，这种方式使每个副本所在节点都会消耗一定的内存和 CPU 资源，不仅如此，冗长的处理流程也会影响执行效率。</p><p></p><p>为解决以上问题，我们在刚刚发布不久 Apache Doris 2.0 版本中（https://github.com/apache/doris/tree/2.0.1-rc04 ），对导入过程中 MemTable 的攒批、排序和落盘等流程进行优化，提高了上下游之间数据传输的效率。此外我们在新版本中还提供 “单副本导入” 的数据分发模式，当面对多副本数据导入时，无需在多个 BE 上重复进行 MemTable 工作，有效提升集群计算和内存资源的利用率，进而提升导入的总吞吐量。</p><p></p><h1>MemTable 优化</h1><p></p><p></p><h2>01  写入优化</h2><p></p><p></p><p>在 Aapche Doris 过去版本中，下游 BE 在写入 MemTable 时，为了维护 Key 的顺序，会实时对 SkipList 进行更新。对于 Unique Key 表或者 Aggregate Key 表来说，遇到已经存在的 Key 时，将会调用聚合函数并进行合并。然而这两个步骤可能会消耗较多的处理时间，从而延迟 RPC  响应时间，影响数据写入的效率。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ef/ef6c90e63726cbf189a4dac894d0577b.png\" /></p><p></p><p>因此我们在 2.0 版本中对这一过程进行了优化。当下游 BE 在写入 MemTable 时，不再实时维护 MemTable 中 Key 的顺序，而是将顺序的保证推迟到 MemTable 即将被下刷成 Segment 之前。此外，我们采用更高效的 pdqsort 来替代 std::sort ，实现了缓存友好的列优先排序方式，并取得了更好的排序性能。通过上述两种手段来保证 RPC 能够被及时响应。</p><p></p><h2>02  并行下刷</h2><p></p><p></p><p>在导入过程中，当下游 BE 将一个 MemTable  写入一定大小之后，会把 MemTable 下刷为 Segment 数据文件来持久化存储数据并释放内存。为了保证前文提到的 Ping-Pong RPC 性能不受影响，MemTable 的下刷操作会被提交到一个线程池中进行异步执行。</p><p></p><p>在 Apache Doris 过去版本中，对于 Unique Key 的表来说，MemTable 下刷任务是串行执行的，原因是不同 Segment 文件之间可能存在重复 Key，串行执行可以保持它们的先后顺序，而 Segment 序号是在下刷任务被调度执行时分配的。同时，在 Tablet 数量较少无法提供足够的并发时，串行下刷可能会导致系统的 IO 资源无法重复被利用。而在 Apache Doris 2.0 版本中，由于我们将 Key 的排序和聚合操作进行了后置，除了原有的 IO 负载以外，下刷任务中还增加了 CPU 负载（即后置的排序和聚合操作）。此时若仍使用串行下刷的方式，当没有足够多 Tablet 来保证并发数时，CPU 和 IO 会交替成为瓶颈，从而导致下刷任务的吞吐量大幅降低。</p><p></p><p>为解决这个问题，我们在下刷任务提交时就为其分配 Segment 序号，确保并行下刷后生成的 Segment 文件顺序是正确的。同时，我们还对后续 Rowset 构建流程进行了优化，使其可以处理不连续的 Segment 序号。通过以上改进，使得所有类型的表都可以并行下刷 MemTable，从而提高整体资源利用率和导入吞吐量。</p><p></p><h2>03  优化效果</h2><p></p><p></p><p>通过对 MemTable 的优化，面对不同的导入场景，Stream Load 的吞吐量均有不同幅度的提升（详细对比数据可见下文）。这项优化不仅适用于Stream Load ，还对 Apache Doris 支持的其他导入方式同样有效，例如 Insert Into、Broker Load、S3 Load 等，均在不同程度提升了导入的效率及性能。</p><p></p><h1>单副本导入</h1><p></p><p></p><h2>01  原理和实现</h2><p></p><p></p><p>在过去版本中，当面对多副本数据写入时，Apache Doris 的每个数据副本均需要在各自节点上进行排序和压缩，这样会造成较大的资源占用。为了节约 CPU 和内存资源，我们在 Apache Doris 在 2.0 版本中提供了单副本导入的能力，该能力会从多个副本中选择一个副本作为主副本（其他副本为从副本），且只对主副本进行计算，当主副本的数据文件都写入成功后，通知从副本所在节点直接接拉取主副本的数据文件，实现副本间的数据同步，当所有从副本节点拉取完后进行返回或超时返回（大多数副本成功即返回成功）。该能力无需一一在节点上进行处理，减少了节点的压力，而节约的算力和内存将会用于其它任务的处理，从而提升整体系统的并发吞吐能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/10/10f6e87b64f6c1731a0c3c1841aceb35.jpeg\" /></p><p></p><h2>02  如何开启</h2><p></p><p>FE 配置：</p><p></p><p><code lang=\"text\">enable_single_replica_load = true\n</code></p><p></p><p>BE 配置：</p><p></p><p><code lang=\"text\">enable_single_replica_load = true\n</code></p><p></p><p>环境变量（insert into）</p><p></p><p><code lang=\"text\">SET  experimental_enable_single_replica_insert=true;\n</code></p><p></p><h2>03  优化效果</h2><p></p><p></p><p>对于单并发导入来说，单副本数据导入可以有效降低资源消耗。单副本导入所占的内存仅为三副本导入的 1/3（单副本导入时只需要写一份内存，三副本导入时需要写三份内存）。同时从实际测试可知，单副本导入的 CPU 消耗约为三副本导入的 1/2，可有效节约 CPU 资源。对于多并发导入来说，在相同的资源消耗下，单副本导入可以显著增加任务吞吐。同时在实际测试中，同样的并发导入任务， 三副本导入方式耗时 67 分钟，而单副本导入方式仅耗时 27 分钟，导入效率提升约 2.5 倍。具体数据请参考后文。</p><p></p><h1>性能对比</h1><p></p><p></p><p>测试环境及配置：</p><p></p><p>3 个 BE (16C 64G)，每个 BE 配置 3 块盘 （单盘读写约 150 MB/s）1 个 FE，共享其中一个 BE 的机器</p><p></p><p>原始数据使用 TPC-H SF100 生成的 Lineitem 表，存储在 FE 所在机器的一个独立的盘上（读约 150 MB/s）。</p><p></p><h2>01  Stream Load（单并发）</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/3e/3e3266cd4a7d540af44ec9fd4b007de4.png\" /></p><p></p><p>以上述列举的单并发场景来说，Apache Doris 2.0 版本整体的导入性能比 1.2.6 版本提升了 2-7 倍；在多副本前提下，开启新特性单副本导入，导入性能提升了 2-8 倍。</p><p></p><h2>02  INSERT INTO （多并发）</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/de/de06ecae8973af9677b86655f5d91621.png\" /></p><p></p><p>以上述列举的多并发场景来说，Apache Doris 2.0 版本整体比 1.2.6 版本有小幅提升；开启新特性单副本导入后，对在多副本提导入性能提升效果明显，导入速度较 1.2.6 版提升约 50% 。</p><p></p><h1>结束语</h1><p></p><p></p><p>社区一直致力于提升 Apache Doris 导入性能这一核心能力，为用户提供更佳的高效分析体验，通过在 2.0 版本对 Memtable、单副本导入等能力进行优化，导入性能相较于之前版本已经呈现数倍提升。未来我们还将在 2.1 版本中持续迭代，结合 MemTable 的优化方法、单副本优化资源能效理念，以及基于 Streaming RPC 优化后的 IO 模型和精简的 IO 路径对导入性能进一步优化，同时减少导入对查询性能的影响，为用户提供更加卓越的数据导入体验。</p><p></p><p># 作者介绍：</p><p></p><p>陈凯杰，<a href=\"https://selectdb.com/\">SelectDB </a>\"高级研发工程师</p><p></p><p>张正宇，SelectDB 资深研发工程师</p>",
    "publish_time": "2023-11-08 09:51:42",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AIGC时代，AI Agent的商业模式和创新机会 ｜InfoQ《极客有约》",
    "url": "https://www.infoq.cn/article/xLSmwEFmDqpIafLzN3io",
    "summary": "<p>后AIGC时代，AI Agent无疑是一个新沸点。AI Agent（人工智能体）是一种能够感知环境、进行决策和执行动作的智能实体。不同于传统的人工智能，AI Agent 具备通过独立思考、调用工具去逐步完成给定目标的能力。</p>\n<p>AI Agent 和大模型的区别在于，大模型与人类之间的交互是基于prompt 实现的，用户prompt 是否清晰明确会影响大模型回答的效果。而AI Agent的工作仅需给定一个目标，它就能够针对目标独立思考并做出行动。</p>\n<p>从原理上说，AI Agent的核心驱动力是大模型，在此基础上增加规划（Planning）、记忆（Memory）和工具使用（Tool Use）三个关键组件。那么，这种智能体的出现为行业发展传递出了什么样的讯号？将带来哪些机遇和变革？是不是下一个超级app的机会？&nbsp;国内哪些公司有可能跑出？</p>",
    "publish_time": "2023-11-08 10:48:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "“算”赋千行，“智”启新程，天翼云多项成果惊艳亮相，邀您共鉴！",
    "url": "https://www.infoq.cn/article/7wdgYqK7JYVvdEay5hON",
    "summary": "<p> 近年来，我国数字化基础设施建设不断完善，人工智能产业蓬勃发展，成为当下驱动经济社会转型升级的重要力量。为抢抓人工智能发展的重大机遇，构筑我国人工智能发展先发优势，国家陆续出台了多项政策，将人工智能列为国家战略性新兴产业，鼓励人工智能行业发展与创新。</p><p></p><p>在此背景下，智算作为人工智能时代的关键生产力要素，需求呈爆发式增长。为推进算力基础设施高质量发展，充分发挥算力对数字经济的驱动作用，近日，工业和信息化部、中央网信办、教育部等六部门联合印发《算力基础设施高质量发展行动计划》明确提出，结合人工智能产业发展和业务需求，重点在西部算力枢纽及人工智能发展基础较好地区集约化开展智算中心建设，逐步合理提升智能算力占比。根据IDC报告显示，预计到2026年，中国智能算力的年复合平均增长率达到52.3%，是三倍于通用算力规模的增长速度。</p><p></p><p> 面对激增的智算需求，天翼云作为云服务国家队，从多方位升级算力基础设施，为人工智能产业发展夯实算力底座，加速科技普惠。技术方面，天翼云始终坚持科技创新，不断攻克关键核心技术，以云操作系统为核心，从底层基础软硬件技术，到上层高阶云能力，实现了全栈技术的自主可控。基础设施方面，天翼云不断完善“2+4+31+X”云网融合资源布局，构建了“集中化+区域化+属地化+边缘化”的云网基础设施，积极推进算力普惠发展；天翼云建设的新一代智算中心在算力、算效、资源利用率等方面不断追求极致，降低大模型训练、推理、部署、应用门槛。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ce/ce40fa919dc071d54806d97739a0aef3.png\" /></p><p></p><p> 人工智能浪潮下，天翼云凭借项目沉淀、技术积累，打造智能计算平台，依托分布式架构云底座和充沛的计算、存储、网络资源，为大模型训练、智能推荐、无人驾驶、生命科学、NLP等业务场景提供智算、超算、通算多样化算力服务，激发数字经济发展新活力。同时，天翼云在通用算力资源全国布局的基础上，科学规划建设智能算力，不断夯实国云智算底座，构建AI时代强大基石。</p><p></p><p> 当今社会，科技高速发展，每一轮技术变革无不渗透在我们的日常生活中。站在大算力、大模型、大数据的“高起点”上，天翼云致力于以科技创新服务千行百业，加速算力普惠民生。为进一步推动人工智能应用落地，加速生产生活方式智慧变革，11月10日—13日，以“数字科技 焕新启航”为主题的2023数字科技生态大会即将启幕。</p><p></p><p> 届时，天翼云将亮相大会主论坛及多个分论坛，重磅发布智算领域科技创新最新成果，并带来云电脑等产品的最新升级，同时在展区，天翼云也将从科技创新、算力底座、产业引领等层面，系统性展示领先的云能力和实践成果，以国云筑基，携手业界共创智算新时代</p>",
    "publish_time": "2023-11-08 11:16:07",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "火山引擎金融解决方案负责人王建军确认出席 FCon，分享金融数字化升级：让智慧带来生产力",
    "url": "https://www.infoq.cn/article/0Mh7GIzC3GdmtAQGW0Jw",
    "summary": "<p><a href=\"https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle\">FCon 全球金融科技大会</a>\"，将于 11 月在上海召开。火山引擎金融解决方案负责人王建军将发表题为《<a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5606?utm_source=infoqweb&amp;utm_medium=article\">金融数字化升级：让智慧带来生产力</a>\"》主题分享，介绍国内外大模型发展及应用现状、火山引擎在金融行业的探索实践，以及大模型在未来行业的应用。</p><p></p><p><a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5606?utm_source=infoqweb&amp;utm_medium=article\">王建军</a>\"，10 年以上人工智能及数字化实践经验，2020 年加入字节跳动，曾服务于德勤咨询、第四范式等企业，推动过数十家金融机构的数字化转型和人工智能应用实践。他在本次会议的演讲内容如下：</p><p></p><p>演讲：大模型：让智慧带来生产力</p><p></p><p>通过观察海外大模型领先应用实践，结合国内产业生产效率痛点，明确大模型应用蓝图，及围绕蓝图展开的探索与实践。</p><p></p><p>演讲提纲：</p><p></p><p>海内外大模型风起云涌；大模型能力范畴和典型应用分析；围绕金融行业的探索实践；展望未来。</p><p></p><p>你将获得：</p><p></p><p>○ 了解到国内外大模型发展及应用现状；</p><p>○ 了解火山引擎在金融行业的探索实践；</p><p>○ 共同畅想大模型未来行业应用。</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle\">DevOps&nbsp;在金融企业落地实践</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle\">金融行业大模型应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle\">创新的金融科技应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle\">金融实时数据平台建设之路</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle\">金融安全风险管控</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle\">数据要素流通与数据合规</a>\"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！大会 8 折优惠报名倒计时仅剩 3 天，现在购票立减￥1360。咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png\" /></p><p></p>",
    "publish_time": "2023-11-08 11:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "平安银行数据研发治理一体化平台实践",
    "url": "https://www.infoq.cn/article/RZJDKpFIZ7erv9EuYiVd",
    "summary": "<p>金融大数据体系错综复杂，随着业务数据爆炸式增长以及公众对数据关注度的不断提高，体系化的数据治理变得至关重要。然而，传统治理方法存在落地难、效果差、难衡量等问题。</p><p></p><p>在<a href=\"https://archsummit.infoq.cn/202307/shenzhen/\"> ArchSummit 全球架构师峰会（深圳站）</a>\"上，平安银行数据资产管理及研发中心 / 数据及 AI 平台团队负责人廖晓格，深入探讨了金融数据体系的复杂性以及如何有效地进行智能化数据治理。他强调了构建金融级数据研发治理一体化平台的重要性，并分享了如何将数据治理体系落地到研发流程中，实现数据价值最大化的方法。本文为演讲整理，期待对你有所启发。</p><p></p><p>在11月19-20日举办的<a href=\"https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">FCon全球金融科技大会</a>\"上，廖晓格还将带来《金融级数据研发DataOps落地实践》的主题分享。敬请关注！</p><p></p><p>以下是ArchSummit深圳站演讲全文（经 InfoQ 进行不改变原意的编辑整理）：</p><p></p><p>今天分享的主题涵盖了金融行业在数据治理过程中遇到的困难与挑战、开发治理一体化平台体系的构建，以及如何进行数据虚拟化的未来展望。随着数据爆炸式增长，各行各业都面临着庞大而复杂的数据、存储成本的剧增、计算复杂度的增加、数据安全隐患等问题，这些挑战归结起来即安全、提效、降本；安全视角，如何保证数据安全分析和应用，以及敏感数据如何不泄露；提效层面，如何提升数据研发效率、如何打破不同部门、组织间的数据孤岛，提升数据融合价值应用；降本层面，如何精准量化数据成本与价值、如何量化分析数据 ROI 价值；</p><p></p><p>除此之外，对金融行业来说，大量分析师在工作期间随时会对海量数据进行分析，如何保证大数据平台 7x24 小时稳定运行至关重要；在数据测试方面，传统的方法是将生产数据脱敏后迁移到测试环境，但这一过程复杂高又难以形成闭环，并且可能有数据安全隐患；在数据时效方面，未来实时数仓的需求会日益增长；若希望数据被有效管理，成为有用的资产，形成数据生态，那数据治理就成为重中之重。</p><p></p><h4>数据治理目标</h4><p></p><p></p><p>数据治理的目标是希望能在确保数据安全及成本价值最大化的前提下，将数据治理与数据研发过程融合，实现治理线上化、治理标准化、治理智能化；将治理方法论与平台工具相结合，实现治理线上化；将数据治理涉及的多个平台、不同角色、流程、标准等融合并集成统一的数据研发治理能力工具，实现治理标准流程；更进一步，我们追求数据治理的智能化，通过内置规则和策略，实现自动识别安全隐患、敏感数据等，提升数据治理效果。而实现“三化”的同时，也不能忘记降低数据成本。</p><p></p><p>数据治理的最终目标是实现核心数据资产的自动沉淀，并为内外部提供稳定、高效的数据服务，实现最大化数据价值。</p><p><img src=\"https://static001.geekbang.org/infoq/38/383dba904283f20bc1446e136c125be4.png\" /></p><p></p><p>金融机构数据治理体系，即一套标准、一个平台、一套治理、一套资产；</p><p></p><p>基层是数据治理标准，数据治理团队需要制定相应的治理方案与治理规划。除此之外，数据研发的流程和规范的标准化也是数据治理的重中之重。</p><p>数据研发治理一体化平台融合研发全流程，在数据需求阶段，我们通常会进行影响分析和数据架构评审，以确保数据治理标准得以贯彻落实。在数据研发阶段，我们重点关注源数据治理、数据血缘和数据质量治理，以确保数据的质量和一致性。此外，指标研发阶段，我们还定义了指标规范、度量规范和维度属性规范，以提供更简单的数据使用路径，满足业务需求。当进入数据应用阶段时，我们采用统一的报表服务和 OneService 服务，为外部提供统一的数据服务，以提高数据服务效率。</p><p></p><p>在治理过程中，除了配置规则外，我们的重点是对开发流程进行贯标落地，确保数据质量的可靠性以及数据价值的评估。同时，我们还需要持续跟踪和监控规范的执行情况，关注数据应用的成本和效益，维护数据的健康度，通过评估每个数据表和指标的价值和成本，及时清除低价值或高成本的数据，从而提高数据治理的效率和准确性。</p><p></p><h4>开发治理一体化解决方案</h4><p></p><p></p><p>在数据治理方面，数据开发治理一体化平台重视规范与研发过程的融合，为确保统一性和高效性，所有数据研发规范都已纳入我们的数据治理体系中进行集成设计。在制定规范时，我们始终坚持先深入设计，后向外提供服务，以数据服务和数据指标驱动我们的数据研发流程。目前我们的数据开发流程覆盖数据同步集成、批流数据加工、指标研发等，我们致力于将数据治理规范真实落地于每一步的数据研发中，确保数据研发与数据治理的紧密结合。此外，通过全流程的数据研发，我们成功塑造了银行的核心数据资产，其中包括业务元数据、数据模型、数据表、指标和 API 等。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/61/6196f2caa5301429e9d55b0241b8a6cf.png\" /></p><p></p><p>具体看一下数据治理融入研发流程在每个阶段中的重点设计。</p><p></p><p>在设计阶段，对数据标准、数据架构、数据治理、元数据等进行规范化定义；对模型事实表、维度表进行设计 / 注册；在研发阶段，在数据集成时，我们将自动标识敏感字段，并在清洗阶段对其进行加密或逻辑脱敏处理；在数据研发时，需要构建完整的元数据资产，包括基础元数据和业务元数据。在发布阶段会对数据进行全流程自动测试，确保数据质量。而运营阶段的核心则是评估数据的成本与价值，最大化数据的 ROI。</p><p><img src=\"https://static001.geekbang.org/infoq/5f/5fe92e669e68231d881ee3fea8979141.png\" /></p><p></p><p>数据模型设计阶段，元数据是基础能力核心，遵循数仓分层、元数据命名规范、数据标准落标等，通过开发治理工具执行。</p><p></p><p>元数据从产生到应用会经过采集层、逻辑层；其中采集区的作用是能够面向自动构建出技术元数据和业务元数据，为逻辑元数据构建提供基础元数据。业务元数据源于业务逻辑和业务管理诉求，而技术元数据则覆盖库 / 表 / 字段、数据血缘等技术细节。</p><p></p><p>为方便场景端使用，我们建立了元数据逻辑层，供资产运营人员进行数据目录挂载、资产分类、资产生命周期管理等工作。其中，资产管理环节还包括资产打标、属性标注和业务流程标识，从而形成完整的业务数据地图，并向外部提供元数据服务，确保数据安全、数据权限，并实现元数据考核应用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b3/b309c6c54fe8376296ff0d4784e3e3f1.png\" /></p><p></p><p>在元数据的全生命周期过程中，我们基于行内统一数据标准规范，对元数据进行强制检查，确保元数据可用、可管、可控，包括①数据分层强制约束，包括 ODS 层、DWD 层和 ADS 层，确保数仓的严格管理，防止跨层访问；②我们为业务归宿设定标识；③命名规范自动化。我们设置了特定的词根，使得当用户命名字段时，相关的英文字段能被自动识别；④码值落标线上化。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/48/48ca464e2d7dbdaedfbb9d5b5ac511f3.png\" /></p><p></p><p>我们也非常重视血缘治理能力，整个平台 99% 的表级字段级血缘都是通过平台自动生成。在金融数仓体系里，数据加工链路复杂，上下游作业影响，重复链路等都会影响数据研发和运维效率；我们目前在 2 个过程中会进行血缘治理，其一是数据研发过程中的血缘链路治理，主要包括血缘层级依赖检查和分层依赖检查，血缘层级依赖检查包括目标作业与 DW 层作业的血缘层级深度，对于层级链路太深（15 层），禁止上线，调整脚本优化链路关系；分层依赖检查依据 ODS-DWD-ADS 分层规范，禁止进行跨层依赖；</p><p></p><p>其二是运营过程治理，包括运营时效治理和运营成本治理，运营时效根据高保作业的时效和运行时间要求，依据血缘关系自动线上化链路监测，并分析延迟影响并及时启动异常 noc；运营成本治理通过血缘链路关系计算数据热度，并针对冷数据自动实现下线管理，减少集群存储和计算成本。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9e/9ead062ab2c337bd4c6126c182876d92.png\" /></p><p></p><p>另外血缘治理也帮助我们对所有作业的脚本进行自动解析并生成依赖关系，支持数据作业自动调度。</p><p>其中值得关注的是，①依赖关系长度：对于那些依赖关系特别长的情况，我们会检查其时效性。如发现依赖过长，我们会对其进行优化。②使用频次：通过血缘分析，我们可以观察到各表的使用情况。对于那些三个月未被访问或访问频次较低的表，我们会进行成本治理。③依赖并发：在调度过程中，我们控制并发并定义调度流程，确保数据开发者不必担心表与表之间的依赖关系。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c9/c9429b972657882ec4cb8c5b427a5d23.png\" /></p><p></p><p>数据质量治理涵盖事前校验、事中核验、事后复盘的闭环治理；</p><p></p><p>事前，我们在数据开发流程中支持自动 / 人工为表和字段设置一定监控规则，如唯一键的监测以及字段内容的监控。事中，依据母表跑批执行成果，自动执行监控检查，如发现监控异常直接进行预警，针对数据异常严重可能会造成下游数据应用场景事故的，会直接阻断整个数据处理流程，对于这些异常阻断，平台会自动告警并跟踪。事后，由质量监控平台追踪质量问题并复盘。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/39/391fb6837f42d7836cae0e4ecf0e4562.png\" /></p><p></p><p>开发测试一体化也是数据治理的重要工具。在数据测试验证场景下，很多公司可能会将数据复制到测试环境，但这样就断裂了数据链路，无法形成闭环，数据安全也无法保证。因此，我们希望所有的数据研发都能在生产环境下完成，包括研发、测试、发布等全流程数据研发过程，直接解决测试难点及问题，并且基于平台资源隔离能力以及安全保障，实现数据全线上化开发，提升数据敏捷度的同时又能保证数据质量。研发、验证、测试过程全部基于生产环境数据安全保护伞进行数据使用，确保数据安全的同时兼顾数据的高保测试。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ab/ab49588abacadf830344fc6a76eb85f7.png\" /></p><p></p><p>最后，在数据安全方面，对于全行数据安全保护也从事前、事中、事后三个视角进行安全管理。</p><p></p><p>事前，我们会协同安全 / 风险专员设定一系列安全规范；事中，我们执行多种安全技术措施，如数据加密、数据脱敏、敏感客群保护、数据外发规则以及实施智能阻断措施，确保整体数据受到充分保护；事后，我们设定规则引擎，对平台的所有访问记录进行自动审查。通过这一机制，一旦发现存在安全隐患的访问记录，平台会自动触发报警。例如，若某用户频繁查询某个特定客户，且该客户信息属于敏感字段或敏感客群，我们会立即阻断此类查询。</p><p></p><p>此外，我们的平台提供统一的 SQL 引擎进行数据查询。在此引擎中，我们执行血缘分析、权限判断等操作。最重要的是，当引擎识别到敏感数据时，会先进行脱敏处理，然后再为用户提供结果。</p><p></p><p>接下来详细介绍一下敏感数据发现的过程；在数据处理流程中，当业务数据被采集至大数据平台后，通过规则算法和人工标注，能够准确地识别到贴源层中的所有敏感字段，接着在 MID 层进行标准化自动敏感打标，并依赖血缘关系将这些敏感标记向下游传递。应用端查询数据时，根据敏感标识对访问的敏感字段及敏感脱敏类型进行加密、脱敏处理。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/57/578469ce185b4e361e8e2fb55bea0eb0.png\" /></p><p></p><p>举个例子，采集表 A 中存在高度敏感的字段，身份证号、姓名和邮箱，我们会采取物理加密措施；而在数据查询、使用时，我们首先通过内部规则库自动识别并标记敏感字段。随后，我们通过血缘关系将这些标识传递至下游的依赖表中，比如识别到数据表 A 中存在敏感字段，根据下游依赖关系，我们识别到数据表 B 中同样存在敏感字段，并自动完成安全打标和打标继承；在此基础上，我们会进一步通过人工复核确认这些标识是否与业务标准相符。复核结束后，相关数据表便可以上线并对外提供服务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/9679738e176436a5a4274b7f591acc1c.png\" /></p><p></p><p>随着大数据平台的发展，表字段的加密方式可能会发生变化。但是，对于整个平台来说，不可以频繁改变字段的加密方式。如果一个字段在多个表中广泛使用，并且其加密方式更改，这会带来非常大影响。</p><p></p><p>为解决这一问题，我们通过对元数据标注的方式来进行加密。例如，如果一个手机号最初采用 A 方式加密，但后续这种加密方式改为 B，我们会对每个表的分区进行标注，并在最终的查询结果中，统一所有不同加密方式的数据到最新的加密格式，再对外提供统一的查询能力，这种技术方案将对业务造成的影响降到最低，也不需要对历史数据进行跑批更新，这种能力可以为平台节省巨大的大数据“翻数”成本。</p><p></p><p>以 MapReduce 为例讲解下基于元数据的加密方案，编译阶段会通过 MapReduceCompiler 访问元数据信息，并将其存储在特定文件中。在运行阶段，每个操作单位会读取这些信息，并根据最新的加密算法加密数据。在 PostExecutionHook 阶段，任何写入操作都会被再次写回到原表，并在元数据上打上标签，标示其元数据的加密方式。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c4/c4f75ff298c7aab5950330df04d6a905.png\" /></p><p></p><p>举个例子，当表字段采用特定的加密算法如 IDX 时，我们会在作业执行期间生成相应的元数据信息。这些信息被序列化并存储。在执行作业时，系统会读取并根据最新的加密算法对所有分区进行统一加密，再进行 SQL 统计。执行结果完成后，系统会更新分区的元数据标签，确保数据的完整性和安全性。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ef/ef92bfcbc39200e035709fc45cb76066.png\" /></p><p></p><p>金融机构在数据分析和加工过程中，即便数据已经统一脱敏处理，但数据的运营权限仍然由各个业务方独立管理和权限分配。由于不同业务部门间的理解差异或者经营竞争意识等，比如银行内部的信用卡、消金及汽融业务，其借贷产品十分相似，导致很多数据难以自由流通。为了解决这一问题，我们在大数据平台上构建了沙箱安全屋环境。该环境能自动对数据进行抽样，用户可以无需申请权限即可访问所有业务方的数据。为了保证数据安全，我们确保沙箱中的数据只能进入，不能输出，并且将数据分析与应用之间是完全隔离的，这样就能实现数据流通共享，并且加速数据分析的效率。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/79/795b1d0c798ed9f526f48b24f9006ba7.png\" /></p><p></p><p>当用户提交 SQL 执行时，系统首先识别是否为沙箱环境。如果是，该请求无需经过权限控制，即用户无需申请数据权限就可以进行数据分析。当然为确保数据安全，我们会对数据执行统一脱敏采样，并改写提交的 SQL。执行后的结果仅能保存在沙箱环境中。若数据想要迁回到生产环境，系统会自动识别并进行拦截，确保数据只能进入沙箱，不能导出；在跑批流程中，我们首先从生产库读取数据，接着在沙箱中对数据进行脱敏抽样，然后将其写入沙箱环境。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/57/57114e22cdf68cc8ef14ab4bcd662894.png\" /></p><p></p><p>数据成本价值管理目前处于探索阶段，现阶段我们是从数据价值和数据成本两方面进行评估管理，逆向推动成本治理；数据价值方面，我们依据表在各个业务流程和标签、模型、报表中的使用情况，如标签调用量及业务场景使用量，来进行系统价值回流和人工标注，基于不同维度进行加权计算，最终输出每个表的价值分。数据成本方面，我们针对大数据底层的每张表都单独计算存储成本和数据计算量化成本，从而确定每张表的数据成本。</p><p><img src=\"https://static001.geekbang.org/infoq/b3/b369bbd401fee7d5ff36a4574eebc608.png\" /></p><p></p><p>最后，让我们看一下数据资产沉淀的过程；在数据研发过程中，依赖元数据治理规范工具检测通过的数据，接口推送至数据资产平台生产数据资产；这些资产再由数据开发人员进行进一步加工和认定；数据资产平台对认定后的资产进行自动分类盘点，资产编目；最终，我们为外部提供数据目录导航、数据资产搜索等，满足数据资产应用需求。</p><p></p><h4>未来展望</h4><p></p><p>尽管进行了大量的数据研发工作，但公司在数据价值最大化的问题上仍存在困难，对于整个大数据平台，数据应用和治理仍是存在很多的疑问点，例如，两张表的内容相似度达到九十几个百分点，我们是否应该合并它们？数据开发工程师和数据架构师负责定义数仓分层，包括 ODS 层、DWD 层、DWS 层等，但这些定义是否真正考虑了用户的需求？对于金融公司的数据标准，有些由咨询公司为其制定了标准，但这些标准是否适用于所有业务场景仍然是未知的。</p><p></p><p>未来，我们计划借助逻辑数仓的概念，实现数据价值最大化。改变原先从下往上构建数仓的模式，构建以“客户为中心”自动化构建数仓，我们希望通过用户的实际使用行为，自动化生成数据仓库的物化表。我们期望数据开发工程师只需定义业务逻辑，而所有存储的控制权由平台持有。我们希望通过构建逻辑数据仓库来优化大数据平台的 DAG。我们的目标是通过这种方法大幅度解决数据治理的不敏捷问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/38/384521e1e2fe3f62bd8b9bef80caf3df.png\" /></p><p>目前，我们的数据仓库主要是物化落地的实体物理表，我们打算将所有物理表转化为虚拟表。通过分析用户访问的日志，我们能够对这些虚拟表进行 SQL 解析和算子转换。基于这些分析，我们会将使用频度较高的虚拟表物化，并将其与原始的虚拟表关联起来，这样对于用户来说体验没有变化，但是实际技术存储方案是最优化的解决。这种策略实质上是依据用户的实际使用模式来构建数据仓库的流程，这意味着，数据开发工程师只需专注于业务指标的处理，平台会自动决定是否将表持久化、是否合并表以及如何持久化。尽管用户端无感，但从平台的角度，表的具体存储位置和数量都是动态的、不确定的；且这种策略确保了用户查询和批处理的时效性，实现真正的自主数据治理。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/04/04b05c3bb51beb420c78c3f6ba23245c.png\" /></p><p></p><p>举例来说，当用户进行 API 查询、标签、指标、特征和报表等行为时，我们首先通过逻辑数据仓库为外部提供服务，同时记录这些逻辑数据仓库的访问频次和标记规则等。试想一下只要在数据仓库中修改一个字段或合并两个相似的表，所需的工作量都是巨大的。但对于逻辑数据仓库来说，其表格可以无限扩展，并且是非常轻量级的，你可以随心所欲地修改它。尽管在初期我们可能会损失一些计算资源，但在后期，我们会通过物化能力，确保时效性并更高效地为外部提供服务。</p><p></p><p>当符合物化规则后，我们会分析整体的 SQL 依赖关系，并进一步细化这些 SQL 关系，诸如将 SQL 拆分为更小的算子、输出内容、where 条件以及它所依赖的表等。我们将优化这些大型或选定表集的 DAG，并将其物化为物理表。然后，在物理层与逻辑层之间进行映射。对于用户来说，他们访问的表仍然保持不变，但存储的控制权由我们的平台持有。</p><p></p><p>嘉宾介绍：</p><p>廖晓格，平安银行数据资产管理及研发中心 / 数据及 AI 平台团队负责人，大数据及 AI 领域资深专家，十多年大数据及 AI 平台研发经验，曾在 PPTV、eBay、携程、华为负责大数据平台研发及优化工作，开源领域爱好者、熟悉 Hadoop 生态、Kubernetes 开源生态和架构设计、精通大数据相关组件技术，承担大数据基础平台、数据中台及 AI 平台建设等重要项目。</p><p></p><h4>活动推荐：</h4><p></p><p></p><p>11 月 19-20 日，首届 <a href=\"https://fcon.infoq.cn/2023/shanghai/\">FCon 全球金融科技大会</a>\"将落地上海。届时，廖晓格老师也会到场与大家交流并分享【金融级数据研发 DataOps 落地实践】，诚挚的邀请您参加本次盛会，期待您可以从他们的交流中获得启迪。</p><p><img src=\"https://static001.geekbang.org/infoq/29/299542233835dfef085279a72d6458d7.png\" /></p><p></p><p>目前为 8 折优惠购票最后 3 天，咨询购票请联系：17310043226（微信同手机号）。</p>",
    "publish_time": "2023-11-08 11:37:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]