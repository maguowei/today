[
  {
    "title": "谷歌开源 AI 微调方法： Distilling Step-by-Step",
    "url": "https://www.infoq.cn/article/P2agXGEtoLNotk2Eb8xP",
    "summary": "<p>华盛顿大学和谷歌研究中心的一个团队最近开源了 <a href=\"https://blog.research.google/2023/09/distilling-step-by-step-outperforming.html\">Distilling Step-by-Step</a>\"（逐步蒸馏），一种用于微调规模较小的语言模型的技术。与标准微调相比，逐步蒸馏需要的训练数据更少，并且生成的模型更小，但模型性能却优于参数规模是它 700 倍的小样本提示大型语言模型 （LLM）。</p><p>&nbsp;</p><p>虽然 LLM 一般可以在提示较少的情况下在多种任务上有良好的表现，但由于其内存和算力要求过高，模型的托管是比较有挑战的。规模较小的模型在微调后也可以有良好的表现，但这需要工程师手动创建针对具体任务优化的数据集。逐步蒸馏的关键思想是使用 LLM 自动生成一个小型微调数据集，其中的数据有一个输入和一个输出标签，以及选择这个输出标签的“理由”。微调过程会训练这个小模型来预测输出标签并生成对应的理由。在 NLP 基准上评估时，小型微调模型的性能优于 540B PaLM 模型，同时仅需要这个基准测试的全部微调数据的 80%。据谷歌称：</p><p></p><p></p><blockquote>我们展示了，逐步蒸馏既减少了构建针对特定任务的较小模型所需的训练数据集规模，也减少了实现甚至超越小样本提示 LLM 的性能水平所需的模型大小。总的来说，逐步蒸馏提出了一种可以高效利用资源的范例，可以解决模型大小和所需训练数据之间的权衡问题。</blockquote><p></p><p></p><p>研究表明，增加 LLM 中的参数规模可以提高其性能，目前最先进的模型（例如 PaLM）拥有数百亿个参数。然而，这些大型模型价格昂贵，且难以用于推理，因为它们需要多个并行连接的 GPU 才能把这么多参数保存在内存里。最近的研究开发出了规模稍小的模型（例如 Meta 的 Llama 2），其性能表现差不多，但参数少了一个数量级；然而，这些小一些的模型还是很庞大，需求的算力也很高。</p><p>&nbsp;</p><p>要做出在特定任务上表现良好的小模型的一种方法，是使用针对具体任务收集的数据集来微调小规模语言模型。虽然这个数据集可能相对较小（大约有数千个示例），但其数据收集起来可能还是费时费钱。另一种选择是知识蒸馏，也就是使用大型模型作为较小模型的老师。 InfoQ 最近报道了谷歌开发的一项<a href=\"https://www.infoq.com/news/2023/01/google-llm-self-improvement/\">技术</a>\"，使用 PaLM LLM 来创建训练数据集，最后生成的微调模型的性能可与规模大 10 倍的 LLM 相媲美。</p><p>&nbsp;</p><p>逐步蒸馏确实需要微调数据集，但它减少了创建高性能模型所需的数据量。源数据集通过思维链提示输入 PaLM LLM，要求模型给出其答案的理由。输出结果是修正后的微调数据集，其中包含原始输入和答案以及理由。这个较小的目标模型经过微调来执行两项任务：回答原始问题并生成理由。</p><p>&nbsp;</p><p>谷歌使用四个 NLP 基准测试评估了他们的技术，每个基准都包含一个微调数据集。他们使用逐步蒸馏来修正这些数据集，并使用了参数不到 1B 的微调 T5 模型。他们发现，这些模型在仅使用数据集的一小部分数据的情况下，性能就比基线微调模型要好；在某些情况下只要 12.5% 的数据就有这样的表现。他们还发现，他们的 770M 参数模型在 ANLI 基准测试中的性能优于大它 700 倍的 540B 参数 PaLM，同时只需要 80% 的微调数据集数据。</p><p>&nbsp;</p><p>在 X（以前的 Twitter）上关于这项工作的讨论中，人工智能企业家 Otto von Zastrow 写道：</p><p></p><p></p><blockquote>这些结果非常厉害。我会把这种办法叫做合成数据生成，而不是蒸馏，我真的很好奇，如果你根据每个示例问题的合成理由来训练原始的 LLM 会发生什么事情。</blockquote><p></p><p></p><p>逐步蒸馏的源代码和训练数据集可在 <a href=\"https://github.com/google-research/distilling-step-by-step\">GitHub</a>\" 上获取。 Google Cloud 的 Vertex AI 平台还提供该算法的非公开预览。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/10/google-distillation/\">https://www.infoq.com/news/2023/10/google-distillation/</a>\"</p>",
    "publish_time": "2023-11-08 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "中国卓越技术团队访谈录 & 架构师特刊：软件产品中的AIGC",
    "url": "https://www.infoq.cn/article/Ba7kqNscXOQoaZAduZsz",
    "summary": "<h2>封面故事</h2>\n<ul>\n<li>我，一个 95 后，从阿里辞职与贾扬清去硅谷创业</li>\n</ul>\n<p>“建议大家不要被大模型束缚住。实际落地时，除了大模型外，还可以充分利用许多已存在的深度学习模型或传统模型。例如在图像处理方面，卷积神经网络（CNN）实际上可能比大模型更适用。”</p>\n<h2>独家对话·大模型领航者</h2>\n<ul>\n<li>被时代选中的智谱AI：成为OpenAI，超越OpenAI</li>\n</ul>\n<p>在创业早期，智谱AI不会强迫自己去接复杂的客户需求，因为这些需求很可能让团队陷入其中无法自拔。“更复杂的问题需要暂时搁置、等到能力更成熟时再解决。”智谱AI会坦诚自己的能力在什么水平上，在该水平上可以创造什么样的价值。</p>\n<ul>\n<li>丢掉LangChain、像Docker一样编排大模型应用程序：这支十余人的年轻创业团队如何在2个月做出一个LLMOps平台？</li>\n</ul>\n<p>“在创业初期，一些朋友和投资人认为市场潜力巨大，但竞争也激烈。云服务提供商、大模型公司以及机器学习和运营的公司都进入这个领域。我们的挑战在于如何应对竞争。”</p>\n<ul>\n<li>是全部重做还是融合改造？揭秘京东云言犀升级全过程</li>\n</ul>\n<p>大模型对一些传统技术确实有影响。因为LLM之前的模型几乎全都是专项的，任务越窄，表现越好。对于更通用、泛化的任务来说，大模型带来的效果确实是颠覆性的。</p>\n<h2>AIGC 实践前沿</h2>\n<ul>\n<li>文生图大型实践：揭秘百度搜索AIGC绘画工具的背后故事</li>\n</ul>\n<p>这是一个巨大的变革，从过去用户在全网寻找图像，转变为结合了查找图像和生成图像两种方式，以满足用户更具体的需求，这也在一定程度上鼓励用户更主动地表达他们真正的需求。</p>\n<ul>\n<li>AIGC 编程：代码编程模型的应用与挑战</li>\n</ul>\n<p>大型模型帮助程序员编写代码是一项很有价值的技术，但从商业角度来看，它并不一定是一个特别有利可图的生意。</p>\n<p>AIGC算法揭秘及产业落地应用分享</p>\n<p>使用大模型在某种程度上为我们提供了更多的可能性，但也引入了更多的复杂性。没有一个通用的模板或规则来告诉我们应该使用哪个模型。</p>\n<ul>\n<li>广告创意领域中AIGC的应用</li>\n</ul>\n<p>随着AI能力的提升，人们需要深入使用并掌握它。像fine-tuning、LangChain等我不会推荐，我会鼓励周围的人去深入使用AIGC，重点在于使用，好的AGI只需要被编译一次。</p>\n<h2>管理能力进阶</h2>\n<ul>\n<li>影响力打造：一位前 Twitter 8 年技术主管总结的经验教训</li>\n<li>日常沟通之道：走向果敢</li>\n<li>科技巨头是如何迷失方向的？探讨大型科技企业的问责制度</li>\n</ul>\n<h2>文章推荐</h2>\n<ul>\n<li>大模型部署昂贵的原因：用最贵的模型处理最基本任务，犹如“让兰博基尼送披萨”</li>\n<li>2023 年 AI 与开源行业：今年第一篇盘点文章出炉了</li>\n<li>ChatGPT 已成为2023年最大金矿，大家是怎么靠它挣到钱的？</li>\n</ul>",
    "publish_time": "2023-11-08 09:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Apache Doris 2.0 如何实现导入性能提升 2-8 倍",
    "url": "https://www.infoq.cn/article/8kEox8KdpTjOh4s1gRH4",
    "summary": "<p>数据导入吞吐是 OLAP 系统性能的重要衡量标准之一，高效的数据导入能力能够加速数据实时处理和分析的效率。随着<a href=\"http://doris.apache.org/\"> Apache Doris</a>\" 用户规模的不断扩大， 越来越多用户对数据导入提出更高的要求，这也为 Apache Doris 的数据导入能力带来了更大的挑战。</p><p></p><p>为提供快速的数据写入支持，Apache Doris 存储引擎采用了类似 LSM Tree 结构。在进行数据导入时，数据会先写入 Tablet 对应的 MemTable 中，MemTable 采用 SkipList 的数据结构。当 MemTable 写满之后，会将其中的数据刷写（Flush）到磁盘。数据从 MemTable 刷写到磁盘的过程分为两个阶段，第一阶段是将 MemTable 中的行存结构在内存中转换为列存结构，并为每一列生成对应的索引结构；第二阶段是将转换后的列存结构写入磁盘，生成 Segment 文件。</p><p></p><p>具体而言，Apache Doris 在导入流程中会把 BE 模块分为上游和下游，其中上游 BE 对数据的处理分为 Scan 和 Sink 两个步骤：首先 Scan 过程对原始数据进行解析，然后 Sink 过程将数据组织并通过 RPC 分发给下游 BE。当下游 BE 接收数据后，首先在内存结构 MemTable 中进行数据攒批，对数据排序、聚合，并最终下刷成数据文件（也称 Segment 文件）到硬盘上来进行持久化存储。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d4/d42ba7c3789fe212c67c8382350dbf46.png\" /></p><p></p><p>而我们在实际的数据导入过程中，可能会出现以下问题：</p><p></p><p>因上游 BE 跟下游 BE 之间的 RPC 采用 Ping-Pong 的模式，即下游 BE 一个请求处理完成并回复到上游 BE 后，上游 BE 才会发送下一个请求。如果下游 BE 在 MemTable 的处理过程中消耗了较长的时间，那么上游 BE 将会等待 RPC 返回的时间也会变长，这就会影响到数据传输的效率。当对多副本的表导入数据时，需要在每个副本上重复执行 MemTable 的处理过程。然而，这种方式使每个副本所在节点都会消耗一定的内存和 CPU 资源，不仅如此，冗长的处理流程也会影响执行效率。</p><p></p><p>为解决以上问题，我们在刚刚发布不久 Apache Doris 2.0 版本中（https://github.com/apache/doris/tree/2.0.1-rc04 ），对导入过程中 MemTable 的攒批、排序和落盘等流程进行优化，提高了上下游之间数据传输的效率。此外我们在新版本中还提供 “单副本导入” 的数据分发模式，当面对多副本数据导入时，无需在多个 BE 上重复进行 MemTable 工作，有效提升集群计算和内存资源的利用率，进而提升导入的总吞吐量。</p><p></p><h1>MemTable 优化</h1><p></p><p></p><h2>01  写入优化</h2><p></p><p></p><p>在 Aapche Doris 过去版本中，下游 BE 在写入 MemTable 时，为了维护 Key 的顺序，会实时对 SkipList 进行更新。对于 Unique Key 表或者 Aggregate Key 表来说，遇到已经存在的 Key 时，将会调用聚合函数并进行合并。然而这两个步骤可能会消耗较多的处理时间，从而延迟 RPC  响应时间，影响数据写入的效率。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ef/ef6c90e63726cbf189a4dac894d0577b.png\" /></p><p></p><p>因此我们在 2.0 版本中对这一过程进行了优化。当下游 BE 在写入 MemTable 时，不再实时维护 MemTable 中 Key 的顺序，而是将顺序的保证推迟到 MemTable 即将被下刷成 Segment 之前。此外，我们采用更高效的 pdqsort 来替代 std::sort ，实现了缓存友好的列优先排序方式，并取得了更好的排序性能。通过上述两种手段来保证 RPC 能够被及时响应。</p><p></p><h2>02  并行下刷</h2><p></p><p></p><p>在导入过程中，当下游 BE 将一个 MemTable  写入一定大小之后，会把 MemTable 下刷为 Segment 数据文件来持久化存储数据并释放内存。为了保证前文提到的 Ping-Pong RPC 性能不受影响，MemTable 的下刷操作会被提交到一个线程池中进行异步执行。</p><p></p><p>在 Apache Doris 过去版本中，对于 Unique Key 的表来说，MemTable 下刷任务是串行执行的，原因是不同 Segment 文件之间可能存在重复 Key，串行执行可以保持它们的先后顺序，而 Segment 序号是在下刷任务被调度执行时分配的。同时，在 Tablet 数量较少无法提供足够的并发时，串行下刷可能会导致系统的 IO 资源无法重复被利用。而在 Apache Doris 2.0 版本中，由于我们将 Key 的排序和聚合操作进行了后置，除了原有的 IO 负载以外，下刷任务中还增加了 CPU 负载（即后置的排序和聚合操作）。此时若仍使用串行下刷的方式，当没有足够多 Tablet 来保证并发数时，CPU 和 IO 会交替成为瓶颈，从而导致下刷任务的吞吐量大幅降低。</p><p></p><p>为解决这个问题，我们在下刷任务提交时就为其分配 Segment 序号，确保并行下刷后生成的 Segment 文件顺序是正确的。同时，我们还对后续 Rowset 构建流程进行了优化，使其可以处理不连续的 Segment 序号。通过以上改进，使得所有类型的表都可以并行下刷 MemTable，从而提高整体资源利用率和导入吞吐量。</p><p></p><h2>03  优化效果</h2><p></p><p></p><p>通过对 MemTable 的优化，面对不同的导入场景，Stream Load 的吞吐量均有不同幅度的提升（详细对比数据可见下文）。这项优化不仅适用于Stream Load ，还对 Apache Doris 支持的其他导入方式同样有效，例如 Insert Into、Broker Load、S3 Load 等，均在不同程度提升了导入的效率及性能。</p><p></p><h1>单副本导入</h1><p></p><p></p><h2>01  原理和实现</h2><p></p><p></p><p>在过去版本中，当面对多副本数据写入时，Apache Doris 的每个数据副本均需要在各自节点上进行排序和压缩，这样会造成较大的资源占用。为了节约 CPU 和内存资源，我们在 Apache Doris 在 2.0 版本中提供了单副本导入的能力，该能力会从多个副本中选择一个副本作为主副本（其他副本为从副本），且只对主副本进行计算，当主副本的数据文件都写入成功后，通知从副本所在节点直接接拉取主副本的数据文件，实现副本间的数据同步，当所有从副本节点拉取完后进行返回或超时返回（大多数副本成功即返回成功）。该能力无需一一在节点上进行处理，减少了节点的压力，而节约的算力和内存将会用于其它任务的处理，从而提升整体系统的并发吞吐能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/10/10f6e87b64f6c1731a0c3c1841aceb35.jpeg\" /></p><p></p><h2>02  如何开启</h2><p></p><p>FE 配置：</p><p></p><p><code lang=\"text\">enable_single_replica_load = true\n</code></p><p></p><p>BE 配置：</p><p></p><p><code lang=\"text\">enable_single_replica_load = true\n</code></p><p></p><p>环境变量（insert into）</p><p></p><p><code lang=\"text\">SET  experimental_enable_single_replica_insert=true;\n</code></p><p></p><h2>03  优化效果</h2><p></p><p></p><p>对于单并发导入来说，单副本数据导入可以有效降低资源消耗。单副本导入所占的内存仅为三副本导入的 1/3（单副本导入时只需要写一份内存，三副本导入时需要写三份内存）。同时从实际测试可知，单副本导入的 CPU 消耗约为三副本导入的 1/2，可有效节约 CPU 资源。对于多并发导入来说，在相同的资源消耗下，单副本导入可以显著增加任务吞吐。同时在实际测试中，同样的并发导入任务， 三副本导入方式耗时 67 分钟，而单副本导入方式仅耗时 27 分钟，导入效率提升约 2.5 倍。具体数据请参考后文。</p><p></p><h1>性能对比</h1><p></p><p></p><p>测试环境及配置：</p><p></p><p>3 个 BE (16C 64G)，每个 BE 配置 3 块盘 （单盘读写约 150 MB/s）1 个 FE，共享其中一个 BE 的机器</p><p></p><p>原始数据使用 TPC-H SF100 生成的 Lineitem 表，存储在 FE 所在机器的一个独立的盘上（读约 150 MB/s）。</p><p></p><h2>01  Stream Load（单并发）</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/3e/3e3266cd4a7d540af44ec9fd4b007de4.png\" /></p><p></p><p>以上述列举的单并发场景来说，Apache Doris 2.0 版本整体的导入性能比 1.2.6 版本提升了 2-7 倍；在多副本前提下，开启新特性单副本导入，导入性能提升了 2-8 倍。</p><p></p><h2>02  INSERT INTO （多并发）</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/de/de06ecae8973af9677b86655f5d91621.png\" /></p><p></p><p>以上述列举的多并发场景来说，Apache Doris 2.0 版本整体比 1.2.6 版本有小幅提升；开启新特性单副本导入后，对在多副本提导入性能提升效果明显，导入速度较 1.2.6 版提升约 50% 。</p><p></p><h1>结束语</h1><p></p><p></p><p>社区一直致力于提升 Apache Doris 导入性能这一核心能力，为用户提供更佳的高效分析体验，通过在 2.0 版本对 Memtable、单副本导入等能力进行优化，导入性能相较于之前版本已经呈现数倍提升。未来我们还将在 2.1 版本中持续迭代，结合 MemTable 的优化方法、单副本优化资源能效理念，以及基于 Streaming RPC 优化后的 IO 模型和精简的 IO 路径对导入性能进一步优化，同时减少导入对查询性能的影响，为用户提供更加卓越的数据导入体验。</p><p></p><p># 作者介绍：</p><p></p><p>陈凯杰，<a href=\"https://selectdb.com/\">SelectDB </a>\"高级研发工程师</p><p></p><p>张正宇，SelectDB 资深研发工程师</p>",
    "publish_time": "2023-11-08 09:51:42",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AIGC时代，AI Agent的商业模式和创新机会 ｜InfoQ《极客有约》",
    "url": "https://www.infoq.cn/article/xLSmwEFmDqpIafLzN3io",
    "summary": "<p>后AIGC时代，AI Agent无疑是一个新沸点。AI Agent（人工智能体）是一种能够感知环境、进行决策和执行动作的智能实体。不同于传统的人工智能，AI Agent 具备通过独立思考、调用工具去逐步完成给定目标的能力。</p>\n<p>AI Agent 和大模型的区别在于，大模型与人类之间的交互是基于prompt 实现的，用户prompt 是否清晰明确会影响大模型回答的效果。而AI Agent的工作仅需给定一个目标，它就能够针对目标独立思考并做出行动。</p>\n<p>从原理上说，AI Agent的核心驱动力是大模型，在此基础上增加规划（Planning）、记忆（Memory）和工具使用（Tool Use）三个关键组件。那么，这种智能体的出现为行业发展传递出了什么样的讯号？将带来哪些机遇和变革？是不是下一个超级app的机会？&nbsp;国内哪些公司有可能跑出？</p>",
    "publish_time": "2023-11-08 10:48:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "“算”赋千行，“智”启新程，天翼云多项成果惊艳亮相，邀您共鉴！",
    "url": "https://www.infoq.cn/article/7wdgYqK7JYVvdEay5hON",
    "summary": "<p> 近年来，我国数字化基础设施建设不断完善，人工智能产业蓬勃发展，成为当下驱动经济社会转型升级的重要力量。为抢抓人工智能发展的重大机遇，构筑我国人工智能发展先发优势，国家陆续出台了多项政策，将人工智能列为国家战略性新兴产业，鼓励人工智能行业发展与创新。</p><p></p><p>在此背景下，智算作为人工智能时代的关键生产力要素，需求呈爆发式增长。为推进算力基础设施高质量发展，充分发挥算力对数字经济的驱动作用，近日，工业和信息化部、中央网信办、教育部等六部门联合印发《算力基础设施高质量发展行动计划》明确提出，结合人工智能产业发展和业务需求，重点在西部算力枢纽及人工智能发展基础较好地区集约化开展智算中心建设，逐步合理提升智能算力占比。根据IDC报告显示，预计到2026年，中国智能算力的年复合平均增长率达到52.3%，是三倍于通用算力规模的增长速度。</p><p></p><p> 面对激增的智算需求，天翼云作为云服务国家队，从多方位升级算力基础设施，为人工智能产业发展夯实算力底座，加速科技普惠。技术方面，天翼云始终坚持科技创新，不断攻克关键核心技术，以云操作系统为核心，从底层基础软硬件技术，到上层高阶云能力，实现了全栈技术的自主可控。基础设施方面，天翼云不断完善“2+4+31+X”云网融合资源布局，构建了“集中化+区域化+属地化+边缘化”的云网基础设施，积极推进算力普惠发展；天翼云建设的新一代智算中心在算力、算效、资源利用率等方面不断追求极致，降低大模型训练、推理、部署、应用门槛。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ce/ce40fa919dc071d54806d97739a0aef3.png\" /></p><p></p><p> 人工智能浪潮下，天翼云凭借项目沉淀、技术积累，打造智能计算平台，依托分布式架构云底座和充沛的计算、存储、网络资源，为大模型训练、智能推荐、无人驾驶、生命科学、NLP等业务场景提供智算、超算、通算多样化算力服务，激发数字经济发展新活力。同时，天翼云在通用算力资源全国布局的基础上，科学规划建设智能算力，不断夯实国云智算底座，构建AI时代强大基石。</p><p></p><p> 当今社会，科技高速发展，每一轮技术变革无不渗透在我们的日常生活中。站在大算力、大模型、大数据的“高起点”上，天翼云致力于以科技创新服务千行百业，加速算力普惠民生。为进一步推动人工智能应用落地，加速生产生活方式智慧变革，11月10日—13日，以“数字科技 焕新启航”为主题的2023数字科技生态大会即将启幕。</p><p></p><p> 届时，天翼云将亮相大会主论坛及多个分论坛，重磅发布智算领域科技创新最新成果，并带来云电脑等产品的最新升级，同时在展区，天翼云也将从科技创新、算力底座、产业引领等层面，系统性展示领先的云能力和实践成果，以国云筑基，携手业界共创智算新时代</p>",
    "publish_time": "2023-11-08 11:16:07",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "火山引擎金融解决方案负责人王建军确认出席 FCon，分享金融数字化升级：让智慧带来生产力",
    "url": "https://www.infoq.cn/article/0Mh7GIzC3GdmtAQGW0Jw",
    "summary": "<p><a href=\"https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle\">FCon 全球金融科技大会</a>\"，将于 11 月在上海召开。火山引擎金融解决方案负责人王建军将发表题为《<a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5606?utm_source=infoqweb&amp;utm_medium=article\">金融数字化升级：让智慧带来生产力</a>\"》主题分享，介绍国内外大模型发展及应用现状、火山引擎在金融行业的探索实践，以及大模型在未来行业的应用。</p><p></p><p><a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5606?utm_source=infoqweb&amp;utm_medium=article\">王建军</a>\"，10 年以上人工智能及数字化实践经验，2020 年加入字节跳动，曾服务于德勤咨询、第四范式等企业，推动过数十家金融机构的数字化转型和人工智能应用实践。他在本次会议的演讲内容如下：</p><p></p><p>演讲：大模型：让智慧带来生产力</p><p></p><p>通过观察海外大模型领先应用实践，结合国内产业生产效率痛点，明确大模型应用蓝图，及围绕蓝图展开的探索与实践。</p><p></p><p>演讲提纲：</p><p></p><p>海内外大模型风起云涌；大模型能力范畴和典型应用分析；围绕金融行业的探索实践；展望未来。</p><p></p><p>你将获得：</p><p></p><p>○ 了解到国内外大模型发展及应用现状；</p><p>○ 了解火山引擎在金融行业的探索实践；</p><p>○ 共同畅想大模型未来行业应用。</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle\">DevOps&nbsp;在金融企业落地实践</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle\">金融行业大模型应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle\">创新的金融科技应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle\">金融实时数据平台建设之路</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle\">金融安全风险管控</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle\">数据要素流通与数据合规</a>\"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！大会 8 折优惠报名倒计时仅剩 3 天，现在购票立减￥1360。咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png\" /></p><p></p>",
    "publish_time": "2023-11-08 11:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "平安银行数据研发治理一体化平台实践",
    "url": "https://www.infoq.cn/article/RZJDKpFIZ7erv9EuYiVd",
    "summary": "<p>金融大数据体系错综复杂，随着业务数据爆炸式增长以及公众对数据关注度的不断提高，体系化的数据治理变得至关重要。然而，传统治理方法存在落地难、效果差、难衡量等问题。</p><p></p><p>在<a href=\"https://archsummit.infoq.cn/202307/shenzhen/\"> ArchSummit 全球架构师峰会（深圳站）</a>\"上，平安银行数据资产管理及研发中心 / 数据及 AI 平台团队负责人廖晓格，深入探讨了金融数据体系的复杂性以及如何有效地进行智能化数据治理。他强调了构建金融级数据研发治理一体化平台的重要性，并分享了如何将数据治理体系落地到研发流程中，实现数据价值最大化的方法。本文为演讲整理，期待对你有所启发。</p><p></p><p>在11月19-20日举办的<a href=\"https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">FCon全球金融科技大会</a>\"上，廖晓格还将带来《金融级数据研发DataOps落地实践》的主题分享。敬请关注！</p><p></p><p>以下是ArchSummit深圳站演讲全文（经 InfoQ 进行不改变原意的编辑整理）：</p><p></p><p>今天分享的主题涵盖了金融行业在数据治理过程中遇到的困难与挑战、开发治理一体化平台体系的构建，以及如何进行数据虚拟化的未来展望。随着数据爆炸式增长，各行各业都面临着庞大而复杂的数据、存储成本的剧增、计算复杂度的增加、数据安全隐患等问题，这些挑战归结起来即安全、提效、降本；安全视角，如何保证数据安全分析和应用，以及敏感数据如何不泄露；提效层面，如何提升数据研发效率、如何打破不同部门、组织间的数据孤岛，提升数据融合价值应用；降本层面，如何精准量化数据成本与价值、如何量化分析数据 ROI 价值；</p><p></p><p>除此之外，对金融行业来说，大量分析师在工作期间随时会对海量数据进行分析，如何保证大数据平台 7x24 小时稳定运行至关重要；在数据测试方面，传统的方法是将生产数据脱敏后迁移到测试环境，但这一过程复杂高又难以形成闭环，并且可能有数据安全隐患；在数据时效方面，未来实时数仓的需求会日益增长；若希望数据被有效管理，成为有用的资产，形成数据生态，那数据治理就成为重中之重。</p><p></p><h4>数据治理目标</h4><p></p><p></p><p>数据治理的目标是希望能在确保数据安全及成本价值最大化的前提下，将数据治理与数据研发过程融合，实现治理线上化、治理标准化、治理智能化；将治理方法论与平台工具相结合，实现治理线上化；将数据治理涉及的多个平台、不同角色、流程、标准等融合并集成统一的数据研发治理能力工具，实现治理标准流程；更进一步，我们追求数据治理的智能化，通过内置规则和策略，实现自动识别安全隐患、敏感数据等，提升数据治理效果。而实现“三化”的同时，也不能忘记降低数据成本。</p><p></p><p>数据治理的最终目标是实现核心数据资产的自动沉淀，并为内外部提供稳定、高效的数据服务，实现最大化数据价值。</p><p><img src=\"https://static001.geekbang.org/infoq/38/383dba904283f20bc1446e136c125be4.png\" /></p><p></p><p>金融机构数据治理体系，即一套标准、一个平台、一套治理、一套资产；</p><p></p><p>基层是数据治理标准，数据治理团队需要制定相应的治理方案与治理规划。除此之外，数据研发的流程和规范的标准化也是数据治理的重中之重。</p><p>数据研发治理一体化平台融合研发全流程，在数据需求阶段，我们通常会进行影响分析和数据架构评审，以确保数据治理标准得以贯彻落实。在数据研发阶段，我们重点关注源数据治理、数据血缘和数据质量治理，以确保数据的质量和一致性。此外，指标研发阶段，我们还定义了指标规范、度量规范和维度属性规范，以提供更简单的数据使用路径，满足业务需求。当进入数据应用阶段时，我们采用统一的报表服务和 OneService 服务，为外部提供统一的数据服务，以提高数据服务效率。</p><p></p><p>在治理过程中，除了配置规则外，我们的重点是对开发流程进行贯标落地，确保数据质量的可靠性以及数据价值的评估。同时，我们还需要持续跟踪和监控规范的执行情况，关注数据应用的成本和效益，维护数据的健康度，通过评估每个数据表和指标的价值和成本，及时清除低价值或高成本的数据，从而提高数据治理的效率和准确性。</p><p></p><h4>开发治理一体化解决方案</h4><p></p><p></p><p>在数据治理方面，数据开发治理一体化平台重视规范与研发过程的融合，为确保统一性和高效性，所有数据研发规范都已纳入我们的数据治理体系中进行集成设计。在制定规范时，我们始终坚持先深入设计，后向外提供服务，以数据服务和数据指标驱动我们的数据研发流程。目前我们的数据开发流程覆盖数据同步集成、批流数据加工、指标研发等，我们致力于将数据治理规范真实落地于每一步的数据研发中，确保数据研发与数据治理的紧密结合。此外，通过全流程的数据研发，我们成功塑造了银行的核心数据资产，其中包括业务元数据、数据模型、数据表、指标和 API 等。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/61/6196f2caa5301429e9d55b0241b8a6cf.png\" /></p><p></p><p>具体看一下数据治理融入研发流程在每个阶段中的重点设计。</p><p></p><p>在设计阶段，对数据标准、数据架构、数据治理、元数据等进行规范化定义；对模型事实表、维度表进行设计 / 注册；在研发阶段，在数据集成时，我们将自动标识敏感字段，并在清洗阶段对其进行加密或逻辑脱敏处理；在数据研发时，需要构建完整的元数据资产，包括基础元数据和业务元数据。在发布阶段会对数据进行全流程自动测试，确保数据质量。而运营阶段的核心则是评估数据的成本与价值，最大化数据的 ROI。</p><p><img src=\"https://static001.geekbang.org/infoq/5f/5fe92e669e68231d881ee3fea8979141.png\" /></p><p></p><p>数据模型设计阶段，元数据是基础能力核心，遵循数仓分层、元数据命名规范、数据标准落标等，通过开发治理工具执行。</p><p></p><p>元数据从产生到应用会经过采集层、逻辑层；其中采集区的作用是能够面向自动构建出技术元数据和业务元数据，为逻辑元数据构建提供基础元数据。业务元数据源于业务逻辑和业务管理诉求，而技术元数据则覆盖库 / 表 / 字段、数据血缘等技术细节。</p><p></p><p>为方便场景端使用，我们建立了元数据逻辑层，供资产运营人员进行数据目录挂载、资产分类、资产生命周期管理等工作。其中，资产管理环节还包括资产打标、属性标注和业务流程标识，从而形成完整的业务数据地图，并向外部提供元数据服务，确保数据安全、数据权限，并实现元数据考核应用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b3/b309c6c54fe8376296ff0d4784e3e3f1.png\" /></p><p></p><p>在元数据的全生命周期过程中，我们基于行内统一数据标准规范，对元数据进行强制检查，确保元数据可用、可管、可控，包括①数据分层强制约束，包括 ODS 层、DWD 层和 ADS 层，确保数仓的严格管理，防止跨层访问；②我们为业务归宿设定标识；③命名规范自动化。我们设置了特定的词根，使得当用户命名字段时，相关的英文字段能被自动识别；④码值落标线上化。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/48/48ca464e2d7dbdaedfbb9d5b5ac511f3.png\" /></p><p></p><p>我们也非常重视血缘治理能力，整个平台 99% 的表级字段级血缘都是通过平台自动生成。在金融数仓体系里，数据加工链路复杂，上下游作业影响，重复链路等都会影响数据研发和运维效率；我们目前在 2 个过程中会进行血缘治理，其一是数据研发过程中的血缘链路治理，主要包括血缘层级依赖检查和分层依赖检查，血缘层级依赖检查包括目标作业与 DW 层作业的血缘层级深度，对于层级链路太深（15 层），禁止上线，调整脚本优化链路关系；分层依赖检查依据 ODS-DWD-ADS 分层规范，禁止进行跨层依赖；</p><p></p><p>其二是运营过程治理，包括运营时效治理和运营成本治理，运营时效根据高保作业的时效和运行时间要求，依据血缘关系自动线上化链路监测，并分析延迟影响并及时启动异常 noc；运营成本治理通过血缘链路关系计算数据热度，并针对冷数据自动实现下线管理，减少集群存储和计算成本。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9e/9ead062ab2c337bd4c6126c182876d92.png\" /></p><p></p><p>另外血缘治理也帮助我们对所有作业的脚本进行自动解析并生成依赖关系，支持数据作业自动调度。</p><p>其中值得关注的是，①依赖关系长度：对于那些依赖关系特别长的情况，我们会检查其时效性。如发现依赖过长，我们会对其进行优化。②使用频次：通过血缘分析，我们可以观察到各表的使用情况。对于那些三个月未被访问或访问频次较低的表，我们会进行成本治理。③依赖并发：在调度过程中，我们控制并发并定义调度流程，确保数据开发者不必担心表与表之间的依赖关系。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c9/c9429b972657882ec4cb8c5b427a5d23.png\" /></p><p></p><p>数据质量治理涵盖事前校验、事中核验、事后复盘的闭环治理；</p><p></p><p>事前，我们在数据开发流程中支持自动 / 人工为表和字段设置一定监控规则，如唯一键的监测以及字段内容的监控。事中，依据母表跑批执行成果，自动执行监控检查，如发现监控异常直接进行预警，针对数据异常严重可能会造成下游数据应用场景事故的，会直接阻断整个数据处理流程，对于这些异常阻断，平台会自动告警并跟踪。事后，由质量监控平台追踪质量问题并复盘。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/39/391fb6837f42d7836cae0e4ecf0e4562.png\" /></p><p></p><p>开发测试一体化也是数据治理的重要工具。在数据测试验证场景下，很多公司可能会将数据复制到测试环境，但这样就断裂了数据链路，无法形成闭环，数据安全也无法保证。因此，我们希望所有的数据研发都能在生产环境下完成，包括研发、测试、发布等全流程数据研发过程，直接解决测试难点及问题，并且基于平台资源隔离能力以及安全保障，实现数据全线上化开发，提升数据敏捷度的同时又能保证数据质量。研发、验证、测试过程全部基于生产环境数据安全保护伞进行数据使用，确保数据安全的同时兼顾数据的高保测试。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ab/ab49588abacadf830344fc6a76eb85f7.png\" /></p><p></p><p>最后，在数据安全方面，对于全行数据安全保护也从事前、事中、事后三个视角进行安全管理。</p><p></p><p>事前，我们会协同安全 / 风险专员设定一系列安全规范；事中，我们执行多种安全技术措施，如数据加密、数据脱敏、敏感客群保护、数据外发规则以及实施智能阻断措施，确保整体数据受到充分保护；事后，我们设定规则引擎，对平台的所有访问记录进行自动审查。通过这一机制，一旦发现存在安全隐患的访问记录，平台会自动触发报警。例如，若某用户频繁查询某个特定客户，且该客户信息属于敏感字段或敏感客群，我们会立即阻断此类查询。</p><p></p><p>此外，我们的平台提供统一的 SQL 引擎进行数据查询。在此引擎中，我们执行血缘分析、权限判断等操作。最重要的是，当引擎识别到敏感数据时，会先进行脱敏处理，然后再为用户提供结果。</p><p></p><p>接下来详细介绍一下敏感数据发现的过程；在数据处理流程中，当业务数据被采集至大数据平台后，通过规则算法和人工标注，能够准确地识别到贴源层中的所有敏感字段，接着在 MID 层进行标准化自动敏感打标，并依赖血缘关系将这些敏感标记向下游传递。应用端查询数据时，根据敏感标识对访问的敏感字段及敏感脱敏类型进行加密、脱敏处理。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/57/578469ce185b4e361e8e2fb55bea0eb0.png\" /></p><p></p><p>举个例子，采集表 A 中存在高度敏感的字段，身份证号、姓名和邮箱，我们会采取物理加密措施；而在数据查询、使用时，我们首先通过内部规则库自动识别并标记敏感字段。随后，我们通过血缘关系将这些标识传递至下游的依赖表中，比如识别到数据表 A 中存在敏感字段，根据下游依赖关系，我们识别到数据表 B 中同样存在敏感字段，并自动完成安全打标和打标继承；在此基础上，我们会进一步通过人工复核确认这些标识是否与业务标准相符。复核结束后，相关数据表便可以上线并对外提供服务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/9679738e176436a5a4274b7f591acc1c.png\" /></p><p></p><p>随着大数据平台的发展，表字段的加密方式可能会发生变化。但是，对于整个平台来说，不可以频繁改变字段的加密方式。如果一个字段在多个表中广泛使用，并且其加密方式更改，这会带来非常大影响。</p><p></p><p>为解决这一问题，我们通过对元数据标注的方式来进行加密。例如，如果一个手机号最初采用 A 方式加密，但后续这种加密方式改为 B，我们会对每个表的分区进行标注，并在最终的查询结果中，统一所有不同加密方式的数据到最新的加密格式，再对外提供统一的查询能力，这种技术方案将对业务造成的影响降到最低，也不需要对历史数据进行跑批更新，这种能力可以为平台节省巨大的大数据“翻数”成本。</p><p></p><p>以 MapReduce 为例讲解下基于元数据的加密方案，编译阶段会通过 MapReduceCompiler 访问元数据信息，并将其存储在特定文件中。在运行阶段，每个操作单位会读取这些信息，并根据最新的加密算法加密数据。在 PostExecutionHook 阶段，任何写入操作都会被再次写回到原表，并在元数据上打上标签，标示其元数据的加密方式。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c4/c4f75ff298c7aab5950330df04d6a905.png\" /></p><p></p><p>举个例子，当表字段采用特定的加密算法如 IDX 时，我们会在作业执行期间生成相应的元数据信息。这些信息被序列化并存储。在执行作业时，系统会读取并根据最新的加密算法对所有分区进行统一加密，再进行 SQL 统计。执行结果完成后，系统会更新分区的元数据标签，确保数据的完整性和安全性。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ef/ef92bfcbc39200e035709fc45cb76066.png\" /></p><p></p><p>金融机构在数据分析和加工过程中，即便数据已经统一脱敏处理，但数据的运营权限仍然由各个业务方独立管理和权限分配。由于不同业务部门间的理解差异或者经营竞争意识等，比如银行内部的信用卡、消金及汽融业务，其借贷产品十分相似，导致很多数据难以自由流通。为了解决这一问题，我们在大数据平台上构建了沙箱安全屋环境。该环境能自动对数据进行抽样，用户可以无需申请权限即可访问所有业务方的数据。为了保证数据安全，我们确保沙箱中的数据只能进入，不能输出，并且将数据分析与应用之间是完全隔离的，这样就能实现数据流通共享，并且加速数据分析的效率。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/79/795b1d0c798ed9f526f48b24f9006ba7.png\" /></p><p></p><p>当用户提交 SQL 执行时，系统首先识别是否为沙箱环境。如果是，该请求无需经过权限控制，即用户无需申请数据权限就可以进行数据分析。当然为确保数据安全，我们会对数据执行统一脱敏采样，并改写提交的 SQL。执行后的结果仅能保存在沙箱环境中。若数据想要迁回到生产环境，系统会自动识别并进行拦截，确保数据只能进入沙箱，不能导出；在跑批流程中，我们首先从生产库读取数据，接着在沙箱中对数据进行脱敏抽样，然后将其写入沙箱环境。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/57/57114e22cdf68cc8ef14ab4bcd662894.png\" /></p><p></p><p>数据成本价值管理目前处于探索阶段，现阶段我们是从数据价值和数据成本两方面进行评估管理，逆向推动成本治理；数据价值方面，我们依据表在各个业务流程和标签、模型、报表中的使用情况，如标签调用量及业务场景使用量，来进行系统价值回流和人工标注，基于不同维度进行加权计算，最终输出每个表的价值分。数据成本方面，我们针对大数据底层的每张表都单独计算存储成本和数据计算量化成本，从而确定每张表的数据成本。</p><p><img src=\"https://static001.geekbang.org/infoq/b3/b369bbd401fee7d5ff36a4574eebc608.png\" /></p><p></p><p>最后，让我们看一下数据资产沉淀的过程；在数据研发过程中，依赖元数据治理规范工具检测通过的数据，接口推送至数据资产平台生产数据资产；这些资产再由数据开发人员进行进一步加工和认定；数据资产平台对认定后的资产进行自动分类盘点，资产编目；最终，我们为外部提供数据目录导航、数据资产搜索等，满足数据资产应用需求。</p><p></p><h4>未来展望</h4><p></p><p>尽管进行了大量的数据研发工作，但公司在数据价值最大化的问题上仍存在困难，对于整个大数据平台，数据应用和治理仍是存在很多的疑问点，例如，两张表的内容相似度达到九十几个百分点，我们是否应该合并它们？数据开发工程师和数据架构师负责定义数仓分层，包括 ODS 层、DWD 层、DWS 层等，但这些定义是否真正考虑了用户的需求？对于金融公司的数据标准，有些由咨询公司为其制定了标准，但这些标准是否适用于所有业务场景仍然是未知的。</p><p></p><p>未来，我们计划借助逻辑数仓的概念，实现数据价值最大化。改变原先从下往上构建数仓的模式，构建以“客户为中心”自动化构建数仓，我们希望通过用户的实际使用行为，自动化生成数据仓库的物化表。我们期望数据开发工程师只需定义业务逻辑，而所有存储的控制权由平台持有。我们希望通过构建逻辑数据仓库来优化大数据平台的 DAG。我们的目标是通过这种方法大幅度解决数据治理的不敏捷问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/38/384521e1e2fe3f62bd8b9bef80caf3df.png\" /></p><p>目前，我们的数据仓库主要是物化落地的实体物理表，我们打算将所有物理表转化为虚拟表。通过分析用户访问的日志，我们能够对这些虚拟表进行 SQL 解析和算子转换。基于这些分析，我们会将使用频度较高的虚拟表物化，并将其与原始的虚拟表关联起来，这样对于用户来说体验没有变化，但是实际技术存储方案是最优化的解决。这种策略实质上是依据用户的实际使用模式来构建数据仓库的流程，这意味着，数据开发工程师只需专注于业务指标的处理，平台会自动决定是否将表持久化、是否合并表以及如何持久化。尽管用户端无感，但从平台的角度，表的具体存储位置和数量都是动态的、不确定的；且这种策略确保了用户查询和批处理的时效性，实现真正的自主数据治理。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/04/04b05c3bb51beb420c78c3f6ba23245c.png\" /></p><p></p><p>举例来说，当用户进行 API 查询、标签、指标、特征和报表等行为时，我们首先通过逻辑数据仓库为外部提供服务，同时记录这些逻辑数据仓库的访问频次和标记规则等。试想一下只要在数据仓库中修改一个字段或合并两个相似的表，所需的工作量都是巨大的。但对于逻辑数据仓库来说，其表格可以无限扩展，并且是非常轻量级的，你可以随心所欲地修改它。尽管在初期我们可能会损失一些计算资源，但在后期，我们会通过物化能力，确保时效性并更高效地为外部提供服务。</p><p></p><p>当符合物化规则后，我们会分析整体的 SQL 依赖关系，并进一步细化这些 SQL 关系，诸如将 SQL 拆分为更小的算子、输出内容、where 条件以及它所依赖的表等。我们将优化这些大型或选定表集的 DAG，并将其物化为物理表。然后，在物理层与逻辑层之间进行映射。对于用户来说，他们访问的表仍然保持不变，但存储的控制权由我们的平台持有。</p><p></p><p>嘉宾介绍：</p><p>廖晓格，平安银行数据资产管理及研发中心 / 数据及 AI 平台团队负责人，大数据及 AI 领域资深专家，十多年大数据及 AI 平台研发经验，曾在 PPTV、eBay、携程、华为负责大数据平台研发及优化工作，开源领域爱好者、熟悉 Hadoop 生态、Kubernetes 开源生态和架构设计、精通大数据相关组件技术，承担大数据基础平台、数据中台及 AI 平台建设等重要项目。</p><p></p><h4>活动推荐：</h4><p></p><p></p><p>11 月 19-20 日，首届 <a href=\"https://fcon.infoq.cn/2023/shanghai/\">FCon 全球金融科技大会</a>\"将落地上海。届时，廖晓格老师也会到场与大家交流并分享【金融级数据研发 DataOps 落地实践】，诚挚的邀请您参加本次盛会，期待您可以从他们的交流中获得启迪。</p><p><img src=\"https://static001.geekbang.org/infoq/29/299542233835dfef085279a72d6458d7.png\" /></p><p></p><p>目前为 8 折优惠购票最后 3 天，咨询购票请联系：17310043226（微信同手机号）。</p>",
    "publish_time": "2023-11-08 11:37:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "阿里云CTO周靖人：API和模型级别开放大模型能力，做to C 产品不是目标",
    "url": "https://www.infoq.cn/article/zptXlfRaUrtvBoE8bYmu",
    "summary": "<p>10月31日，阿里云正式发布千亿级参数大模型通义千问2.0。官方数据显示，在10个权威测评中，通义千问2.0综合性能超过GPT-3.5，正在加速追赶GPT-4。此外，阿里云还发布了智能编码助手通义灵码等行业应用大模型。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cc/cc23cc39efb9acd3e61f3863210bbba1.jpeg\" /></p><p>&nbsp;</p><p>针对阿里云的大模型策略，阿里云CTO周靖人在接受记者采访时表示，“我们的目标并不是做toC的产品，而是希望更多地把模型的能力开放出来，让更多开发者、合作伙伴使用。”</p><p>&nbsp;</p><p>据周靖人介绍，阿里云的定位是“服务好各种各样在AI时代的创业者、开发者和企业客户等。通过多层技术能力，包括AI基础设施、模型等能力，最好地支持开发者和客户，帮助他们解决在创业、落地、创新等方面的问题。”</p><p>&nbsp;</p><p>具体来讲，模型创业公司希望使用到最先进的AI基础设施；企业客户希望将开源模型与自己产品做二次结合，这类产品包括通义千问等开源模型、帮助企业做模型定制的阿里云百炼等；还有关注业务系统的开发者，通过简单的API集成到自己业务体系中。</p><p>&nbsp;</p><p>周靖人表示，这次AI技术变革的实质是一次技术体系的全面升级。对云计算来说，主要包括以下纬度：第一，系统优化，即如何利用模型能力优化复杂庞大的分布式系统，让它真正变成一个“自动驾驶的云”；第二，用模型帮助提升开发效率，即让用云这件事本身变得更加智能；第三，以模型为中心打造最好的AI基础设施，提供低成本、一站式的模型训练、微调、推理等服务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9f/9f74a49d11d71efa482b001ac1473b48.jpeg\" /></p><p>&nbsp;</p><p>“而云厂商既要懂AI，又要懂云计算，才能在这次竞争里取得一个重要的战略性优势。”周靖人表示。具体来说，云厂商要做的事情就是让用户以更低的成本使用模型来提供服务。</p><p>&nbsp;</p><p>“今天基础设施的目标，特别是模型推理方面，不单是提升延迟等各个方面的性能，同时还要能够降低使用成本。在这方面，我们还有大量的工作需要做。”周靖人表示，阿里云不是简单开发界面的开放，而是API级别、模型级别的开放。用户可以借这些产品发挥更大的想象空间，做更多业务的创新。</p><p>&nbsp;</p><p>周靖人呼吁，大家要给这个领域一些时间。“毕竟从国内来讲，整个产业的变化是从今年开始的，甚至到了3、4月份，大家才陆陆续续发模型。在这方面，我们的确比海外要晚，海外拥有至少一年的先发优势，甚至更长的时间。”</p><p>&nbsp;</p><p>不过，周靖人表示，国内也在快速地追赶中。短短半年时间内，国内模型生态已经慢慢发展起来了。模型的生态发展起来，一定代表了算力发展得起来。</p><p>&nbsp;</p>",
    "publish_time": "2023-11-08 12:17:25",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "“2023深圳国际金融科技大赛暨微众银行2024校园招聘宣讲会”走进深大：AI、区块链、产品经理的未来在何方？",
    "url": "https://www.infoq.cn/article/NjkLsroBG4rfmaAYdu13",
    "summary": "<p>在金融科技发展的过程中，人才培养是举足轻重的关键一环。为了推进深圳市金融科技人才高地建设工作，并向高校学子提供一个展示自身知识、能力和创意的平台，深圳大学微众银行金融科技学院与微众银行联合举办了“<a href=\"https://www.infoq.cn/news/9AYU96ZSPoCZ6kyClK94\">2023 深圳国际金融科技大赛（FinTechathon）——西丽湖金融科技大学生挑战赛</a>\"”（下文称“大赛”）。</p><p></p><p>在本次大赛赛程中，大赛组委会特别设置了技术公开课以让同学们更加了解大赛及人工智能、区块链、金融产品经理的发展现状。继 10 月 25 日<a href=\"https://www.infoq.cn/article/ZKeta6LLZD97sHwPv2UC\">第一场线上技术公开课</a>\"圆满开课，为了让同学们能够更直接、更近距离地了解大赛内容，11 月 3 日，大赛组委会联动微众银行人力资源部门共同走进<a href=\"https://www.infoq.cn/video/atB6FuOvpIQGQPWLX0Eo\">深圳大学</a>\"，在线下组织了一场 2023 深圳国际金融科技大赛的第二场技术公开课暨微众银行 2024 校园招聘宣讲会。此次活动将金融科技大赛、企业招聘和高校教育结合在一起，形成了一个良好的产学研合作模式，将高校培养成果嫁接至高质量人才输送链路之中，为学生提供实践和就业的机会的同时，将学术成果有效转化为实际产业解决方案。</p><p></p><p>本次宣讲会邀请到了深大微众金融科技学院党委书记刘山海书记、深大微众金融科技学院院长助理祁涵及微众银行的多位专家来到现场，围绕大赛赛题、赛制和微众银行 2024 校招内容展开宣讲。以下为本期公开课直播精华内容整理：</p><p></p><p></p><h2>一、深大微众金融科技学院院长助理祁涵再次介绍大赛规则及流程</h2><p></p><p></p><p>2023 深圳国际金融科技大赛—— 西丽湖金融科技大学生挑战赛致力于推动国内外高校学生探索金融科技领域的技术应用创新，促进政、学、企三方交流，全面提高学生的创新能力、实践能力和就业竞争力。</p><p>作为 2023 年深圳市金融科技节的重要一环，本届大赛在深圳市地方金融监督管理局、深圳市福田区人民政府、深圳市南山区人民政府战略指导下，由深圳大学、微众银行、深圳香蜜湖国际金融科技研究院等多方联合举办。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b2/b2f51f27c732fb8f013d743bc29fb043.png\" /></p><p></p><p>本届大赛将通过初赛、复赛在各赛道分别遴选出 10 支队伍进入决赛角逐，并设置总额超过 69 万人民币的赛事奖金及参赛专属区块链数字证书，以奖励各赛道获得一等奖、二等奖、三等奖的队伍及成员。此外，本次大赛还邀请了学术和企业界的众多资深专家为参赛选手答疑解难——特邀国家统计局原副局长许宪春、微众银行首席智能官杨强、中国人民银行研究局原局长张健华等担任学术顾问，评委嘉宾来自微众银行及国内各大顶尖高校。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f5/f52bd2e8110a8dbb969698a29a8a0175.png\" /></p><p></p><p>据祁涵介绍，本届大赛所有参赛队员必须是全日制在校大学生（包括本科生、研究生和博士生），须以团队形式参赛，每支队伍人数 2~5 人，每人只能参加一支队伍，必须要独立完成题目，最后产品的知识产权归参赛选手所有，大赛不收取任何报名费用，决赛期间的队伍食宿及往返交通费用由组委会统一安排。</p><p></p><p></p><h2>二、微众银行区块链高级架构师周禄：区块链赛道高分秘籍</h2><p></p><p></p><p>周禄在宣讲最开始就强调，区块链赛道的参赛项目需要基于 FISCO BCOS 平台及微众区块链系列开源技术设计并开发一个区块链系统，以解决 ESG 相关的某个行业或场景的痛点或问题。具体来说，选手可以将区块链技术应用于大湾区一体化、双碳、乡村振兴、公共服务等 ESG 领域。过往赛事中，有一些作品的创意就非常值得参考。比如 2019 年大赛区块链赛道第一名作品就基于 FISCO BCOS 构建了一个排污权许可区块链交易平台，配合交易纠纷仲裁、黑名单、监督审计等链上机制，健全、活化市场，实现企业、政府、公众在环保排污上的三权制衡、多元共治，以辅助排污政策制定，共建污水治理生态循环。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/86/861dcbc86a0af420dde7ecfcff970638.png\" /></p><p></p><p>2020 年区块链赛道第二名作品 WeHelp 则基于微众银行社会治理框架“善度”，使用区块链底层平台 FISCO BCOS、分布式身份解决方案 WeIdentity 等区块链技术，加速求救与救援的匹配。项目还采用可共享的分布式账本记录善行，保证数据公信力，解决求助过程中的信任问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b2/b2221f7277edb82f51bb676863e5ccf9.png\" /></p><p></p><p>2021 年区块链赛道第三名作品《亿点爱》旨在通过区块链构建公益众筹平台，利用隐私保护技术实现安全可信存储，保护用户个人隐私的同时，有效预防虚假筹款和善款被挪用等问题，以此促进互联网公益行业健康有序地发展。</p><p></p><p>周禄总结了上述获奖作品的特点第一就是应用方向符合 ESG 命题，其次就是充分理解了区块链的特性，并融入应用场景；以上述获奖作品为参考，周禄继续讲解了本届大赛中获得高分的锦囊。</p><p></p><p>参赛作品要赢得评委青睐，首先要选择适合区块链应用场景的正确方向。ESG 指环境、社会和治理，其本质是一种价值观，鼓励企业更多重视财务数据以外的贡献，在保护环境、有利社会和加强治理方面创造价值。而区块链是传递信任的机器，可以大幅降低信任成本；同时区块链可以保护隐私，避免个人数据泄露；区块链还是激励相容的，很容易设计激励机制；区块链的交易记录可全程追溯、可信可验证，这也是它的一大优势。而正是因为具备了这些特性，区块链技术很适合用于 ESG 实践。</p><p></p><p>此外，周禄还为同学们讲解了开发区块链应用的基本步骤。区块链应用的架构包括了用户、分布式应用 DAPP、服务接口 API、智能合约和底层平台，其中 DAPP 可以是命令行、网页、手机或 PC 应用，通过接口和平台通信；服务接口采用通用 JSON 格式 RPC 调用；智能合约采用 Solidity 语言编写；底层平台包含网络、共识、加密和存储等模块。</p><p></p><p>同学们在开发区块链应用时，可以首先使用大赛官方提供的快速建链工具搭建区块链，然后使用业务模版开发 Solidity 合约，并通过交互式控制台的 SDK 部署合约，使用 SDK 开发业务，通过 RPC 协议交互，这里的交互语言没有限制。最后部署业务系统，发起查询和上链交易。这些工作要在团队内分工合作，提高效率。</p><p></p><p>参赛选手要善用各类区块链组件，微众区块链全部开源，提供了众多组件供公众使用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/97/97690f91de649a76fe37f04bb4e68101.png\" /></p><p></p><p>大赛官方还提供了大量代码仓库（https://github.com/FISCO-BCOS/FISCO-BCOS），包含很多参考 demo 和开源项目，选手可以直接克隆研究。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/68/68870ba93cf861429ca6fa9a514a8e81.png\" /></p><p></p><p>官方的黑客松目录收集了基于 FISCO BCOS 开发的，参与各种大赛的优秀案例，包括每个案例的项目介绍、设计文档、源代码等，供选手参考。周禄推荐各位选手充分利用上述资源，在比赛中取得佳绩。</p><p></p><p></p><h2>三、微众银行个人直通银行部室经理金虎光：银行线上场景的交互式智能柜台服务</h2><p></p><p></p><p>本届大赛产品经理赛道的赛题是《银行线上场景的交互式智能柜台服务》，金虎光在解析赛题时表示，参赛选手应当基于对话式交互的应用进行银行产品方案设计，实现对客户全场景的陪伴式交互，为客户提供智能、便捷、懂用户、有温度的线上银行服务（可选择微众银行 APP、微众银行 We2000 小程序或其他银行产品作为产品框架进行设计）。设置该赛题的背景是银行业传统的线下柜台服务帮助实现银行职员与客户之间的互动，可以处理较为复杂和个性化的问题，更容易发展信任关系，但由于网点服务存在地点和工作时间限制服务效率比较低。近年来兴起的银行线上远程服务则希望通过各种技术手段为客户带来随时随地、方便快捷的体验，同时尽可能做到像线下一样可以处理复杂、个性化的问题。从电话银行到网上银行、银行 APP 再到虚拟数字人服务，银行正在努力将线上数字银行打造成新的增长点，提升金融服务体验和质量，提升客户经营质效。</p><p></p><p>如今各家银行的线上服务都已经包括了几乎所有银行服务功能，但随着功能指数级增长，客户的线上交互也变得非常复杂。每家银行都有多个 APP，如何让客户更方便地找到所需功能是银行面临的普遍挑战。金虎光提到，评委们希望看到参赛选手的创新想法，展现出如何在功能、场景、信息繁多的背景下让用户更加便捷地体验线上银行服务。</p><p></p><p>最近火热的生成式 AI 技术可以贯穿从市场、销售到运营、研发、风控的所有银行服务，带来许多创新性的体验。金虎光建议选手可以选择某一个垂直场景或服务，或基于一揽子服务模式来利用生成式 AI 改进交互形式。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/11/1128d3ad32ef06751999b20f30492ff8.png\" /></p><p></p><p>例如作品可以为投资小白用户基于生成式 AI 技术分析、总结投研报告，辅助投资决策。选手还可以参考智能投顾、智能客服、远程面签等技术和场景拓展思路，发挥创意。例如招行 APP 左上角的小猫就会根据用户行为提供实时建议，APP 中的 AI 小招机器人则利用数字人模式提供了智能财富管理顾问服务；百信银行则探索利用虚拟空间模式服务线上用户等等。</p><p></p><p>微众银行也在做相关探索。例如用户可以在微众银行 APP 中与虚拟小 weiWE 机器人对话获得服务，或者使用微众银行小程序快速完成操作。金虎光建议，参赛同学可以选择微众银行 APP 或小程序，亦或是任何自己熟悉的银行 APP 作为底层框架来设计作品。</p><p></p><p>针对产品经理赛道的参赛规则，金虎光也做了详细解读。本赛道中，评委主要考虑以下四个维度为作品打分：</p><p>创新性：参赛作品具备创意亮点，用新思维解决现有问题，或探索新的行业模式，有望开拓新的产业运作模式，市场空间等。商业价值：参赛作品所面向的场景和用户有一定代表性，且作品能够很好地结合实际应用场景解决所描述场景痛点；参赛作品有良好的社会价值，运作合法合规，或具备一定商业价值、成长性和可持续性，值得规模化推广。完整性及可行性：进行有效的竞品、市场及用户分析，并总结产品相对竞品的优劣势、可借鉴及可创新之处，了解用户需求，针对用户痛点提出对应解决方案；有完整的产品设计方案，包括设计背景、产品流程、功能模块说明等，产品架构设计完整，产品流程可形成闭环。技术先进性：可清晰阐述使用的技术，技术有一定先进或创新性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b9/b9b56b49f06ebd08c59291ac2eb5f881.png\" /></p><p></p><p>同时还需要注意的是，参赛作品一定要“有需求、有场景”，同时技术是可落地的，尤其要避免创意大而空的问题，要注重实际的创意内涵。与此同时，因为银行的金融交易非常关注安全性，所以作品一定要考虑必要的安全、核身和信息保护环境，理解银行产品背后的相关设计。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/56/56908a6e25ce3a93ec23fa9448cbfc54.png\" /></p><p></p><p>金虎光还提醒同学们，参赛作品需提供完整的产品设计文档，建议包括市场及竞品分析、用户调研、产品分析和产品设计说明。初赛需提供产品设计文档（Doc 格式），复赛和决赛还需提供作品展示文档（PPT 格式）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f5/f5f39f7ae9b9a27d9dcdc5174809e6e1.png\" /></p><p></p><p></p><h2>四、微众银行人工智能资深研究员、FATE 开源社区技术委员会成员范涛：人工智能赛道讲解</h2><p></p><p></p><p>范涛首先介绍了基于微众人工智能技术开源的 FATE 项目。这是目前国内最大的联邦学习开源项目和社区之一。FATE 不仅提供了底层框架，还提供了很多应用组件。选手须基于该平台构建人工智能产品，可以充分利用 FATE 提供的各类算法和组件。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5d/5ddedbc44d28162945c216cfdc791716.png\" /></p><p></p><p>本赛道命题为开放式，作品可基于 AI 联邦学习开源平台 FATE，设计纵向联邦学习、横向联邦学习或者联邦大模型创新性产品或算法，包括并不限于联合风控，联合营销，智能权益定价，数据交易定价等场景。项目须使用 FATE 开源技术实现，选手须将实现代码提交至 Github 供评委考核。评委基于作品的产品实现完备性、创新性和商业价值打分：</p><p>产品实现完备性占 40% 分数，考察作品在技术层面的复杂度和实现完成度。完备性包括可行性分析、方案设计文档、代码实现、测试报告等方面。创新性占 40% 分数，考察作品在设计层面的新颖度。创新性包括但不限于全新的场景痛点，用新的算法或技术手段，有效综合利用多个技术组件从而产生新的效能。商业价值考察作品在人工智能领域中的综合价值。综合价值包括但不限于作品与实际产业的贴合度、是否有效解决真实行业痛点、是否有效地发挥了联邦学习的实用价值等。</p><p></p><p>选手须组队参赛，个人可先报名，由平台协助组队；初赛作品于 11 月 27 日截止提交，包含作品介绍（PPT 格式）、技术文档（Doc 格式）、作品展示材料（包括但不限于作品部分 demo 或演示视频等）。12 月 5 日大赛公布决赛入围名单，16-17 日在深圳举办线下 36 小时封闭马拉松，选手对初赛提交作品进行开发和完善，并做现场路演答辩。</p><p></p><p>除了赛程相关的信息，范涛还向同学们解读了横向联邦学习、纵向联邦学习和联邦大模型三大技术栈：</p><p>横向联邦学习是指每个终端都有一些同质数据，但每一方都有数据隐私保护需求，仅靠自己的数据不足以构建较好的模型，所以希望综合多方数据构建模型，本质上是扩充数据样本来提升模型效果和稳健性的方法，适用于参与者数据特征重叠较多，而样本 ID 重叠较少的情况。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/82/821713d23a19373d8feb8a34f18024ff.png\" /></p><p></p><p>纵向联邦学习在金融领域应用非常广泛。它通过引用第三方数据与金融数据结合来提升风控、营销等场景的效果，本质上是通过扩充特征维度来提升模型效果，适用于参与者样本重叠较多的情况。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/15/157d0219eec8cfabb4b7fa7e65d3c274.png\" /></p><p></p><p>大模型技术与联邦迁移学习有很多结合点，后者也是大模型领域的新兴范式。通过联邦迁移学习，大模型可以和本地私有数据结合，成为适合本地数据的中小模型。该课题是本届大赛的新增部分，范涛推荐选手关注。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9e/9ef4d47d97602fb405fcfbfaef48c6a8.png\" /></p><p></p><p>范涛最后介绍了 2022、2020、2019 年人工智能赛道名列前茅的一些作品，他希望参赛选手参考这些优秀案例，设计出令人称赞的高分作品：</p><p>2022 年：一等奖作品是面向真人体验感知的系统，通过横向联邦学习场景综合多人信息去做感知应用；二等奖作品是将联邦学习应用于工业智能，如火焰检测、工业设备缺陷检测等场景；三等奖作品是纵向联邦学习应用于电网的场景。2021 年：一等奖作品是心理健康预测监控系统，综合用户的文本、图像、社交媒体数据心理健康行为预测平台；二等奖作品是基于 FATE 构建的联邦营销一站式平台，可以综合多企业数据来做更精准的营销。三等奖作品横向联邦场景来做保险经纪人，通过 F ATE 平台保护用户隐私。2019 年：一等奖作品是横向联邦学习场景，通过车载行为数据对车险定价；二等奖作品基于联邦做了联邦图形预算法，联合多个银行的交易网络，在不泄露隐私数据的前提下预测欺诈用户；三等奖作品是基于联邦学习平台做个人数据定价，形成新的数据交易模式。</p><p></p><p></p><h2>五、写在最后</h2><p></p><p></p><p>除了以上干货内容，深大微众金融科技学院党委书记刘海山书记在本次宣讲会开场时就为同学们加油鼓气。刘书记希望参赛学生能够积极探索金融科技领域的技术应用创新，将创新成果转化为实际应用，向金融科技行业提供更有价值的技术解决方案，为深圳乃至全国的金融科技发展贡献力量。</p><p></p><p>在本次宣讲会的校招环节，微众银行零售存款部总经理邢海鹏整体介绍了微众银行的业务和技术。据其介绍，微众银行是全国首家数字银行，2019 年与深圳大学合作成立了深大微众金融科技学院。微众银行在 IT 方面的投入营收占比超过了 9%，科技人员占比超过 50%，微众银行在 AI、区块链、云计算、大数据等方面都有大量投入，并取得了一系列行业领先的成果。</p><p></p><p>微众银行人力资源部室资深经理杨帆详细介绍了微众银行的人才结构——银行员工平均年龄 33 岁，本科及以上学历超过 99%，人才来源也非常多元化。校招生身份入职的微众银行的同学，可以获得专属“私塾学习计划”，并为校招生设置了一年的培养期。</p><p></p><p>2024 年微众银行校园招聘主要分为技术研发、数据算法、产品业务、综合职能、财富管理五大类别，具体的招聘详情可以根据下列途径进行了解 ↓</p><p><img src=\"https://static001.infoq.cn/resource/image/96/fb/96ee25124fde526ded7913138c2199fb.png\" /></p><p></p>",
    "publish_time": "2023-11-08 13:58:46",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]