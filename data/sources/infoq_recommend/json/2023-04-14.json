[
  {
    "title": "字节开源基于 Rust 打包工具 Rspack，比 Webpack 快了10倍",
    "url": "https://www.infoq.cn/article/quSeDMzURbsu8eysjKPZ",
    "summary": "<p>字节跳动近期与 <a href=\"https://valor-software.com/\">Valor 软件</a>\"开源了 <a href=\"https://valor-software.com/press-release/rs-pack-rust-based-web-bundler\">Rspack</a>\"，这是一款由 Rust 编写的&nbsp;Web 捆绑，意在用更快、更直接的方式取代 Webpack。部分早期基准测试表明，Rspack 的冷启动时间有十倍的提升。字节跳动对其的开发主要为缓解 Rspack 在部分场景下生产构建时间长达十分钟至半小时，冷启动时间可超数分钟的问题。为降低迁移成本并维持 Webpack 配置机制所提供的灵活性和生产优化，Rspack 的<a href=\"https://github.com/web-infra-dev/rspack\">功能</a>\"设计如下：</p><p>&nbsp;</p><p></p><blockquote>快速启动：基于 Rust 的飞快构建速度，为你带来极致的开发体验。&nbsp;模块热替换 (HMR)：内置增量编译机制让 HMR 速度飞快的同时 ，也完全能胜任大型应用的开发&nbsp;与 Webpack 的互操作性：与 Webpack 架构和生态系统相兼容，无需重新建立生态系统&nbsp;内含电池：开箱即用的 TypeScript、JSX、CSS、CSS Modules、Sass 等支持&nbsp;生产优化：内置多项默认优化策略，如摇树优化、最小化等等&nbsp;框架无关：不受限于任何前端框架，确保足够的灵活性</blockquote><p></p><p>&nbsp;</p><p>速度的观测结果取决于设备、项目结构及规模。字节跳动是通过公开可用的 <a href=\"https://webpack.github.io/benchmark/\">Webpack 基准测试工具</a>\"，于<a href=\"https://github.com/web-infra-dev/bundler-benchmark\">自定义代码库</a>\"中进行的基准测试。基准测试结果显示 Rspack 冷启动时间经过开发优化，相较使用 Babel 的 Webpack <a href=\"https://www.rspack.dev/misc/benchmark.html#data\">提升了十倍有余</a>\"，增量构建时间<a href=\"https://www.rspack.dev/misc/benchmark.html#data-1\">提升三倍</a>\"。Nx 在其他代码库中也<a href=\"https://www.youtube.com/watch?v=jGTE7xAcg24\">展示了类似的结果</a>\"：</p><p>&nbsp;</p><p></p><blockquote>我们自行进行了初步的统计，也看到了一些很赞的改善。对大型组件而言，Rspack 的部署时间比 Webpack 快四倍，开发服务器的启动速度比目前 Webpack 的实现快五倍，总体生产构建的速度有了四倍的提升。</blockquote><p></p><p>&nbsp;</p><p>Rspack 虽然只在近期才开源，但其开发时长已有一年了。但不管怎么说，该项目仍处于早期阶段，缺乏许多 Webpack 的功能。Rspack 团队强调他们计划进一步加强对 Webpack 生态系统的支持：</p><p>&nbsp;</p><p></p><blockquote>Rspack 与 Webpack 的配置模式和 Loader 架构，人们可无缝使用熟悉的 Loader，如babel-loader、less-loader、sass-loader 等等。我们的长期目标是为完全支持最为常用的 Loader，包括更为复杂的 vue-loader 等情况。但要想实现 Webpack 的全部功能，我们还任重而道远。我们会基于社区反馈排列优先级，所以请告诉我们您的需求！</blockquote><p></p><p>&nbsp;</p><p>Rspack 最初是由字节跳动内部开发团队发起，<a href=\"https://internaldeveloperplatform.org/what-is-an-internal-developer-platform/#:~:text=An%20Internal%20Developer%20Platform%20%28IDP%29%20is%20built%20by%20a%20platform,away%20context%20and%20underlying%20technologies.\">内部开发者平台</a>\"或一般平台工程团队正逐渐成为企业 DevOps 实践的一部分。</p><p>&nbsp;</p><p>越来越多的 Web 工具链开始使用 Rust 来大幅提升其性能。热门的 Parcel 捆绑于<a href=\"https://parceljs.org/blog/parcel-css/\">去年宣发</a>\"了一款使用 Rust 编写的新 CSS 解析器、编译器、粉碎器（比基于 JavaScript 的 CSSNano 快百倍，比基于 Go 的 ESBuild 快三倍）。两年前，Parcel 2 便已经<a href=\"https://www.infoq.com/news/2021/09/parcel-2-rust-faster-javascript/\">用 Rust 对其 JavaScript 编译器进行了重写</a>\"（构建性能提升十倍）前端工具链 Rome 于几个月前<a href=\"https://www.infoq.com/news/2022/11/rome-v10-stable-release-linter/\">发布了一款基于 Rust 的新代码质量规则和格式化器</a>\"，相比&nbsp;<a href=\"https://eslint.org/\">ESLint</a>\"&nbsp;和 <a href=\"https://prettier.io/\">Prettier</a>\" 有一至二个数量级的提升。<a href=\"https://github.com/rolldown-rs/rolldown\">Rolldown</a>\" 是另一项进行中的项目，可提供与 Rollup 相兼容的 API。</p><p>&nbsp;</p><p><a href=\"https://webpack.js.org/\">Webpack</a>\"、<a href=\"https://parceljs.org/\">Parcel</a>\"、<a href=\"https://rollupjs.org/\">Rollup</a>\"，这些均是用于构建 Web 应用程序的最热门捆绑器。Rspack 是在 MIT 许可下发布的开源软件，欢迎反馈，但也应遵守<a href=\"https://github.com/web-infra-dev/rspack/blob/main/CONTRIBUTING.md\">贡献指南</a>\"和<a href=\"https://github.com/web-infra-dev/rspack/blob/main/CODE_OF_CONDUCT.md\">行为准则</a>\"。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/04/rust-rspack-webpack-compatible/\">New Rust-Based Web Bundler Rspack Touts up to 10X Speed Improvement over Webpack</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/KJRrxY9aTGfM33L2XSGx\">Vite 4 发布，用更快的 SWC 替换了 Babel</a>\"</p><p><a href=\"https://www.infoq.cn/article/iKecr1k4eQMMpCaaXEDr\">Webpack 创始人推出比 Webpack“快 700 倍”的 Turbopack，基于 Rust 编写</a>\"</p><p></p>",
    "publish_time": "2023-04-14 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Web框架Astro 2.0发布，在静态和动态渲染之外提供了混合渲染能力",
    "url": "https://www.infoq.cn/article/YMYGqq5x3i5P6klPGRkf",
    "summary": "<p>Web框架Astro最近发布了<a href=\"https://astro.build/blog/astro-2/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODE0NTI0NzIsImZpbGVHVUlEIjoic2QyejVUd0FLSGdpVFdBayIsImlhdCI6MTY4MTQ1MjE3MiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo4NjM1Mzc3OX0.BuctF_SltTxXOIKfhgJ9AV3fJnNLrdxVAh4W8W-8_LE\">2.0版本</a>\"，在原先的静态和动态服务器渲染功能之上提供了新的混合渲染功能。混合渲染可用于渲染特定页面，以此来获得更高的渲染性能。</p><p></p><p>Astro Web框架旨在普及一种叫作“<a href=\"https://docs.astro.build/en/concepts/islands/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODE0NTI0NzIsImZpbGVHVUlEIjoic2QyejVUd0FLSGdpVFdBayIsImlhdCI6MTY4MTQ1MjE3MiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo4NjM1Mzc3OX0.BuctF_SltTxXOIKfhgJ9AV3fJnNLrdxVAh4W8W-8_LE\">组件岛</a>\"”的前端架构，这也是Astro推出混合渲染的动机：</p><p></p><p></p><blockquote>在将近一年的时间里，Astro都只允许用户在静态（SSG）和服务器（SSR）渲染之间二选一。静态网站提供了令人难以置信的性能，但缺少为不同请求按需生成HTML的能力。Astro 2.0的混合渲染把这两种渲染能力结合在了一起。将静态和动态内容混合在一起可以带来新的可能性：1. 提高热度页面的渲染性能；2. 提高大型站点的构建性能；3. 向已有的静态站点中加入API。</blockquote><p></p><p></p><p>在之前的版本中，使用Astro的开发人员必须在静态渲染（针对静态的、内容主导的网站）或服务器端渲染之间做出选择。有了混合渲染，开发人员可以在构建时预渲染特定的页面或服务器端点，无需放弃已部署的服务器。</p><p></p><p>大型网站通常有适合使用预渲染技术生成内容的部分，也有需要在请求时生成内容的部分。例如，电子商务网站会预先渲染主页和各种以营销为重点的内容，而产品、价格或折扣页面则使用服务器端渲染，以呈现最新可用的数据。这种混合方法可能会降低渲染网页所需的计算资源量和相关的成本。</p><p></p><p>对于使用<a href=\"https://jamstack.org/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODE0NTI0NzIsImZpbGVHVUlEIjoic2QyejVUd0FLSGdpVFdBayIsImlhdCI6MTY4MTQ1MjE3MiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo4NjM1Mzc3OX0.BuctF_SltTxXOIKfhgJ9AV3fJnNLrdxVAh4W8W-8_LE\">Jamstack</a>\"的大型站点，比较有价值的是<a href=\"https://www.smashingmagazine.com/2021/04/incremental-static-regeneration-nextjs/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODE0NTI0NzIsImZpbGVHVUlEIjoic2QyejVUd0FLSGdpVFdBayIsImlhdCI6MTY4MTQ1MjE3MiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo4NjM1Mzc3OX0.BuctF_SltTxXOIKfhgJ9AV3fJnNLrdxVAh4W8W-8_LE\">增量静态生成</a>\"，这是由应用程序框架Next.js推广的一种渲染方式。</p><p></p><p>Astro新版本还提供了重新设计的错误叠加，改进了对开发阶段模块热加载的支持，并使用了<a href=\"https://www.infoq.com/news/2022/12/vite-4-faster-swc?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODE0NTI0NzIsImZpbGVHVUlEIjoic2QyejVUd0FLSGdpVFdBayIsImlhdCI6MTY4MTQ1MjE3MiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo4NjM1Mzc3OX0.BuctF_SltTxXOIKfhgJ9AV3fJnNLrdxVAh4W8W-8_LE\">新发布的Vite 4.0</a>\"来构建内容。</p><p></p><p>Astro是一个旨在为以内容为中心的网站提升用户体验的Web框架。为此，Astro尽可能少向客户端发送JavaScript，确保页面的交互性是可用的。对于完全静态的页面，根本不发送JavaScript。Astro为此提出了“组件岛”架构。Web页面被划分为静态HTML内容，其中穿插着称为Astro岛的交互式UI组件。组件岛是独立渲染的，可以使用任意的UI框架（例如，React、Preact、Svelte、Vue、Solid、Lit）。</p><p></p><p>Astro宣称自己是“专为速度而设计的一体化Web框架”。其基准测试（基于<a href=\"https://developer.chrome.com/docs/crux/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODE0NTI0NzIsImZpbGVHVUlEIjoic2QyejVUd0FLSGdpVFdBayIsImlhdCI6MTY4MTQ1MjE3MiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo4NjM1Mzc3OX0.BuctF_SltTxXOIKfhgJ9AV3fJnNLrdxVAh4W8W-8_LE\">Chrome用户体验报告[CrUX]</a>\"、<a href=\"https://httparchive.org/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODE0NTI0NzIsImZpbGVHVUlEIjoic2QyejVUd0FLSGdpVFdBayIsImlhdCI6MTY4MTQ1MjE3MiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo4NjM1Mzc3OX0.BuctF_SltTxXOIKfhgJ9AV3fJnNLrdxVAh4W8W-8_LE\">The HTTP Archive</a>\"和<a href=\"https://discuss.httparchive.org/t/new-dashboard-the-core-web-vitals-technology-report/2178?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODE0NTI0NzIsImZpbGVHVUlEIjoic2QyejVUd0FLSGdpVFdBayIsImlhdCI6MTY4MTQ1MjE3MiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo4NjM1Mzc3OX0.BuctF_SltTxXOIKfhgJ9AV3fJnNLrdxVAh4W8W-8_LE\">核心Web重要技术报告</a>\"）报告显示，Astro的性能优于其他Web框架（Sveltekit、Gatsby、Remix、WordPress、Next、Nuxt）。</p><p></p><p>Astro是一个采用了MIT许可的<a href=\"https://github.com/withastro/astro?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODE0NTI0NzIsImZpbGVHVUlEIjoic2QyejVUd0FLSGdpVFdBayIsImlhdCI6MTY4MTQ1MjE3MiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo4NjM1Mzc3OX0.BuctF_SltTxXOIKfhgJ9AV3fJnNLrdxVAh4W8W-8_LE\">开源项目</a>\"。欢迎开发者参与<a href=\"https://github.com/withastro/astro/blob/main/CONTRIBUTING.md?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODE0NTI0NzIsImZpbGVHVUlEIjoic2QyejVUd0FLSGdpVFdBayIsImlhdCI6MTY4MTQ1MjE3MiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo4NjM1Mzc3OX0.BuctF_SltTxXOIKfhgJ9AV3fJnNLrdxVAh4W8W-8_LE\">贡献和反馈</a>\"。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/04/astro-2-hybrid-rendering/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODE0NTI0NzIsImZpbGVHVUlEIjoic2QyejVUd0FLSGdpVFdBayIsImlhdCI6MTY4MTQ1MjE3MiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo4NjM1Mzc3OX0.BuctF_SltTxXOIKfhgJ9AV3fJnNLrdxVAh4W8W-8_LE\">https://www.infoq.com/news/2023/04/astro-2-hybrid-rendering/</a>\"</p><p></p><p></p><h5>相关阅读：</h5><p></p><p><a href=\"https://xie.infoq.cn/article/65c7f0e0e3d4a90e8d80bae35\">Web 前端开发最好用的几个 WebGL 框架</a>\"</p><p><a href=\"https://xie.infoq.cn/article/f7361f9f4afc55b8f99727c3d\">Web、移动端、桌面端自动化测试工具或框架推荐</a>\"</p><p><a href=\"https://xie.infoq.cn/article/170673a775bec8d1e407bb035\">Web 前端设计开发工具集（JS 框架、CSS 预处理）</a>\"</p><p><a href=\"https://xie.infoq.cn/article/3e869b0b353cd3d810f493e27\">传统 Web 框架部署与迁移</a>\"</p>",
    "publish_time": "2023-04-14 14:10:09",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何检查 Docker 镜像是否存在漏洞",
    "url": "https://www.infoq.cn/article/Z8128Ope7MVzfAgLNH9F",
    "summary": "<p></p><blockquote>定期检查管道中的漏洞是非常重要的。执行步骤之一是对你的 Docker 镜像进行漏洞扫描。在本文中，你将学习如何执行漏洞扫描，如何修复漏洞，以及如何将其添加到你的 Jenkins 管道中。</blockquote><p></p><p>&nbsp;</p><p>在几年前的一篇<a href=\"https://mydeveloperplanet.com/2019/02/13/check-docker-images-for-vulnerabilities-with-anchore-engine/\">博文</a>\"中，描述了如何扫描 Docker 镜像的漏洞。<a href=\"https://mydeveloperplanet.com/2019/02/27/anchore-container-image-scanner-jenkins-plugin/\">后续的博文</a>\"展示了如何将扫描添加到 Jenkins 管道中。然而，之前博文中使用的 Anchore Engine 已经<a href=\"https://anchore.com/blog/announcing-anchore-engine-1-0/\">不被支持</a>\"了，我认为另一个解决方案是使用由 Anchore 提供的 <a href=\"https://github.com/anchore/grype\">grype</a>\"。</p><p>&nbsp;</p><p>如今，我们必须保持最新的安全修复措施。许多安全漏洞是<a href=\"https://cve.mitre.org/\">公开</a>\"的，可以很容易地被利用。因此，为尽量减少被攻击，尽快修复安全漏洞是必须的。但如何跟上这个步伐呢？你主要关注的是业务，不希望有一个全职工作来修复安全漏洞。这就是为什么自动扫描你的应用程序和你的 Docker 镜像很重要。Grype 可以帮助扫描 Docker 镜像、检查操作系统的漏洞，也会检查特定语言的包，如 Java JAR 文件的漏洞，并会报告它们。它还可以扫描文件和目录，因此可以用来扫描你的源代码。</p><p>&nbsp;</p><p>在本文中，我创建了一个包含 Spring Boot 应用程序的有漏洞的 Docker 镜像，并将安装和使用 grype，以便扫描镜像并修复漏洞。本文中使用的资源可以在 <a href=\"https://github.com/mydeveloperplanet/mygrypeplanet\">GitHub</a>\" 上找到。</p><p>&nbsp;</p><p>了解本文，所需的前提条件是：</p><p>&nbsp;</p><p>基本的 Linux 知识基本的 Docker 知识基本的 Java 和 Spring Boot 知识</p><p>&nbsp;</p><p></p><h2>易受攻击的应用程序</h2><p></p><p>&nbsp;</p><p>打开 <a href=\"https://start.spring.io/\">Spring Initializr</a>\"，选择 Maven 构建、Java 17、Spring Boot 2.7.6，以及 Spring Web 依赖。这不会是一个非常脆弱的应用程序，因为 Spring 已经确保你使用最新的 Spring Boot 版本。因此，将 Spring Boot 的版本改为 2.7.0。可以用以下命令构建 Spring Boot 应用程序，它将为你创建 jar 文件：</p><p>&nbsp;</p><p><code lang=\"null\">$ mvn clean verify</code></p><p>&nbsp;</p><p>你要扫描一个 Docker 镜像，因此需要创建一个 Dockerfile。你将使用一个非常基本的 Dockerfile，它只包含创建镜像所需的最低指令。如果你想创建生产就绪的 Docker 镜像，请阅读《<a href=\"https://mydeveloperplanet.com/2022/11/30/docker-best-practices/\">Docker 最佳实践</a>\"》（Docker Best Practices）和《<a href=\"https://mydeveloperplanet.com/2022/12/14/spring-boot-docker-best-practices/\">Spring Boot Docker 最佳实践</a>\"》（Spring Boot Docker Best Practices）。</p><p>&nbsp;</p><p><code lang=\"null\">FROM eclipse-temurin:17.0.1_12-jre-alpine\nWORKDIR /opt/app\nARG JAR_FILE\nCOPY target/${JAR_FILE} app.jar\nENTRYPOINT [\"java\", \"-jar\", \"app.jar\"]</code></p><p>&nbsp;</p><p>在撰写本文时，Java 17 的最新 eclipse-temurin 基础镜像是 17.0.5_8 版本。同样，使用较旧的才能使其易受攻击。</p><p>&nbsp;</p><p>为了构建 Docker 镜像，将使用 Spotify 的 dockerfile-maven-plugin 的分支。因此，将下面的代码片段添加到 pom 文件中。</p><p>&nbsp;</p><p><code lang=\"null\">\n  com.xenoamess.docker\n  dockerfile-maven-plugin\n  1.4.25\n  \n    mydeveloperplanet/mygrypeplanet\n    ${project.version}\n    \n      ${project.build.finalName}.jar\n    \n  \n</code></p><p>&nbsp;</p><p>使用该插件的好处是，你可以轻松地重复使用配置。创建 Docker 镜像只需一条 Maven 命令即可完成。</p><p>&nbsp;</p><p>可以通过调用以下命令来构建 Docker 镜像：</p><p>&nbsp;</p><p><code lang=\"null\">mvn dockerfile:build</code></p><p>&nbsp;</p><p>现在，你已经准备好开始使用 grype 了。</p><p>&nbsp;</p><p></p><h2>安装</h2><p></p><p>&nbsp;</p><p>可以通过执行以下脚本来安装 grype：</p><p>&nbsp;</p><p><code lang=\"null\">$ curl -sSfL https://raw.githubusercontent.com/anchore/grype/main/install.sh | sh -s -- -b /usr/local/bin</code></p><p>&nbsp;</p><p>通过执行以下命令验证安装：</p><p>&nbsp;</p><p><code lang=\"null\">$ grype version\nApplication:          grype\nVersion:              0.54.0\nSyft Version:         v0.63.0\nBuildDate:            2022-12-13T15:02:51Z\nGitCommit:            93499eec7e3ce2704755e9f51457181b06b519c5\nGitDescription:       v0.54.0\nPlatform:             linux/amd64\nGoVersion:            go1.18.8\nCompiler:             gc\nSupported DB Schema:  5</code></p><p>&nbsp;</p><p></p><h2>扫描镜像</h2><p></p><p>&nbsp;</p><p>扫描 Docker 镜像的方法是调用 grype，然后是 docker:，表示你想从 Docker 守护程序、镜像和标签中扫描一个镜像。</p><p>&nbsp;</p><p><code lang=\"null\">$ grype docker:mydeveloperplanet/mygrypeplanet:0.0.1-SNAPSHOT\nApplication:          grype\nVersion:              0.54.0\nSyft Version:         v0.63.0\n Vulnerability DB        [updated]\n Loaded image            \n Parsed image            \n Cataloged packages      [50 packages]\n Scanned image           [42 vulnerabilities]\nNAME              INSTALLED  FIXED-IN   TYPE          VULNERABILITY        SEVERITY \nbusybox           1.34.1-r3  1.34.1-r5  apk           CVE-2022-28391       High      \njackson-databind  2.13.3                java-archive  CVE-2022-42003       High      \njackson-databind  2.13.3                java-archive  CVE-2022-42004       High      \njackson-databind  2.13.3     2.13.4     java-archive  GHSA-rgv9-q543-rqg4  High      \njackson-databind  2.13.3     2.13.4.1   java-archive  GHSA-jjjh-jjxp-wpff  High      \njava              17.0.1+12             binary        CVE-2022-21248       Low       \njava              17.0.1+12             binary        CVE-2022-21277       Medium    \njava              17.0.1+12             binary        CVE-2022-21282       Medium    \njava              17.0.1+12             binary        CVE-2022-21283       Medium    \njava              17.0.1+12             binary        CVE-2022-21291       Medium    \njava              17.0.1+12             binary        CVE-2022-21293       Medium    \njava              17.0.1+12             binary        CVE-2022-21294       Medium    \njava              17.0.1+12             binary        CVE-2022-21296       Medium    \njava              17.0.1+12             binary        CVE-2022-21299       Medium    \njava              17.0.1+12             binary        CVE-2022-21305       Medium    \njava              17.0.1+12             binary        CVE-2022-21340       Medium    \njava              17.0.1+12             binary        CVE-2022-21341       Medium    \njava              17.0.1+12             binary        CVE-2022-21360       Medium    \njava              17.0.1+12             binary        CVE-2022-21365       Medium    \njava              17.0.1+12             binary        CVE-2022-21366       Medium    \nlibcrypto1.1      1.1.1l-r7             apk           CVE-2021-4160        Medium    \nlibcrypto1.1      1.1.1l-r7  1.1.1n-r0  apk           CVE-2022-0778        High      \nlibcrypto1.1      1.1.1l-r7  1.1.1q-r0  apk           CVE-2022-2097        Medium    \nlibretls          3.3.4-r2   3.3.4-r3   apk           CVE-2022-0778        High      \nlibssl1.1         1.1.1l-r7             apk           CVE-2021-4160        Medium    \nlibssl1.1         1.1.1l-r7  1.1.1n-r0  apk           CVE-2022-0778        High      \nlibssl1.1         1.1.1l-r7  1.1.1q-r0  apk           CVE-2022-2097        Medium    \nsnakeyaml         1.30                  java-archive  GHSA-mjmj-j48q-9wg2  High      \nsnakeyaml         1.30       1.31       java-archive  GHSA-3mc7-4q67-w48m  High      \nsnakeyaml         1.30       1.31       java-archive  GHSA-98wm-3w3q-mw94  Medium    \nsnakeyaml         1.30       1.31       java-archive  GHSA-c4r9-r8fh-9vj2  Medium    \nsnakeyaml         1.30       1.31       java-archive  GHSA-hhhw-99gj-p3c3  Medium    \nsnakeyaml         1.30       1.32       java-archive  GHSA-9w3m-gqgf-c4p9  Medium    \nsnakeyaml         1.30       1.32       java-archive  GHSA-w37g-rhq8-7m4j  Medium    \nspring-core       5.3.20                java-archive  CVE-2016-1000027     Critical  \nssl_client        1.34.1-r3  1.34.1-r5  apk           CVE-2022-28391       High      \nzlib              1.2.11-r3  1.2.12-r0  apk           CVE-2018-25032       High      \nzlib              1.2.11-r3  1.2.12-r2  apk           CVE-2022-37434       Critical </code></p><p>&nbsp;</p><p>这个输出告诉你什么？</p><p>&nbsp;</p><p>NAME：易受攻击的包的名称INSTALLED：安装的是哪个版本FIXED-IN：在哪个版本中修复了漏洞TYPE：依赖项的类型，例如 JDK 的二进制等VULNERABILITY：漏洞的标识符；通过此标识符，你可以获得有关 CVE 数据库中漏洞的更多信息SEVERITY：不言自明，可以是可忽略、低、中、高或严重</p><p>&nbsp;</p><p>当你仔细观察输出结果时，你会发现并非每个漏洞都有确认的修复方法。那么，在这种情况下，你该怎么办呢？Grype 提供了一个选项，以便只显示已经确认修复的漏洞。添加--only-fixed 标志就可以了。</p><p>&nbsp;</p><p><code lang=\"null\">$ grype docker:mydeveloperplanet/mygrypeplanet:0.0.1-SNAPSHOT --only-fixed\n Vulnerability DB        [no update available]\n Loaded image            \n Parsed image            \n Cataloged packages      [50 packages]\n Scanned image           [42 vulnerabilities]\n \nNAME              INSTALLED  FIXED-IN   TYPE          VULNERABILITY        SEVERITY \nbusybox           1.34.1-r3  1.34.1-r5  apk           CVE-2022-28391       High      \njackson-databind  2.13.3     2.13.4     java-archive  GHSA-rgv9-q543-rqg4  High      \njackson-databind  2.13.3     2.13.4.1   java-archive  GHSA-jjjh-jjxp-wpff  High      \nlibcrypto1.1      1.1.1l-r7  1.1.1n-r0  apk           CVE-2022-0778        High      \nlibcrypto1.1      1.1.1l-r7  1.1.1q-r0  apk           CVE-2022-2097        Medium    \nlibretls          3.3.4-r2   3.3.4-r3   apk           CVE-2022-0778        High      \nlibssl1.1         1.1.1l-r7  1.1.1n-r0  apk           CVE-2022-0778        High      \nlibssl1.1         1.1.1l-r7  1.1.1q-r0  apk           CVE-2022-2097        Medium    \nsnakeyaml         1.30       1.31       java-archive  GHSA-3mc7-4q67-w48m  High      \nsnakeyaml         1.30       1.31       java-archive  GHSA-98wm-3w3q-mw94  Medium    \nsnakeyaml         1.30       1.31       java-archive  GHSA-c4r9-r8fh-9vj2  Medium    \nsnakeyaml         1.30       1.31       java-archive  GHSA-hhhw-99gj-p3c3  Medium    \nsnakeyaml         1.30       1.32       java-archive  GHSA-9w3m-gqgf-c4p9  Medium    \nsnakeyaml         1.30       1.32       java-archive  GHSA-w37g-rhq8-7m4j  Medium    \nssl_client        1.34.1-r3  1.34.1-r5  apk           CVE-2022-28391       High      \nzlib              1.2.11-r3  1.2.12-r0  apk           CVE-2018-25032       High      \nzlib              1.2.11-r3  1.2.12-r2  apk           CVE-2022-37434       Critical </code></p><p>&nbsp;</p><p>请注意，Java JDK 的漏洞已经消失，尽管 Java 17 JDK 存在一个较新的更新。然而，这可能不是一个大问题，因为其他（非 java-archive）的漏洞显示基础镜像已经过时了。</p><p>&nbsp;</p><p></p><h2>修复漏洞</h2><p></p><p>&nbsp;</p><p>在这种情况下，修复漏洞是很容易的。首先，你需要更新 Docker 基础镜像。改变 Docker 镜像中的第一行：</p><p>&nbsp;</p><p><code lang=\"null\">FROM eclipse-temurin:17.0.1_12-jre-alpine</code></p><p>&nbsp;</p><p>改成：</p><p>&nbsp;</p><p><code lang=\"null\">FROM eclipse-temurin:17.0.5_8-jre-alpine</code></p><p>&nbsp;</p><p>构建镜像并再次运行扫描：</p><p>&nbsp;</p><p><code lang=\"null\">$ mvn dockerfile:build\n...\n$ grype docker:mydeveloperplanet/mygrypeplanet:0.0.1-SNAPSHOT --only-fixed\n Vulnerability DB        [no update available]\n Loaded image            \n Parsed image            \n Cataloged packages      [62 packages]\n Scanned image           [14 vulnerabilities]\nNAME              INSTALLED  FIXED-IN  TYPE          VULNERABILITY        SEVERITY \njackson-databind  2.13.3     2.13.4    java-archive  GHSA-rgv9-q543-rqg4  High      \njackson-databind  2.13.3     2.13.4.1  java-archive  GHSA-jjjh-jjxp-wpff  High      \nsnakeyaml         1.30       1.31      java-archive  GHSA-3mc7-4q67-w48m  High      \nsnakeyaml         1.30       1.31      java-archive  GHSA-98wm-3w3q-mw94  Medium    \nsnakeyaml         1.30       1.31      java-archive  GHSA-c4r9-r8fh-9vj2  Medium    \nsnakeyaml         1.30       1.31      java-archive  GHSA-hhhw-99gj-p3c3  Medium    \nsnakeyaml         1.30       1.32      java-archive  GHSA-9w3m-gqgf-c4p9  Medium    \nsnakeyaml         1.30       1.32      java-archive  GHSA-w37g-rhq8-7m4j  Medium </code></p><p>&nbsp;</p><p>正如你在输出中所看到的，只有 java-archive 的漏洞仍然存在。其他漏洞已经被解决了。</p><p>&nbsp;</p><p>接下来，修复 Spring Boot 依赖性漏洞，在 POM 中将 Spring Boot 的版本从 2.7.0 更改为 2.7.6。</p><p>&nbsp;</p><p><code lang=\"null\">\n  org.springframework.boot\n  spring-boot-starter-parent\n  2.7.6\n   <!-- lookup parent from repository -->\n</code></p><p>&nbsp;</p><p>构建 JAR 文件，构建 Docker 镜像，然后再次运行扫描：</p><p>&nbsp;</p><p><code lang=\"null\">$ mvn clean verify\n...\n$ mvn dockerfile:build\n...\n$ grype docker:mydeveloperplanet/mygrypeplanet:0.0.1-SNAPSHOT --only-fixed\n Vulnerability DB        [no update available]\n Loaded image            \n Parsed image            \n Cataloged packages      [62 packages]\n Scanned image           [10 vulnerabilities]\nNAME       INSTALLED  FIXED-IN  TYPE          VULNERABILITY        SEVERITY \nsnakeyaml  1.30       1.31      java-archive  GHSA-3mc7-4q67-w48m  High      \nsnakeyaml  1.30       1.31      java-archive  GHSA-98wm-3w3q-mw94  Medium    \nsnakeyaml  1.30       1.31      java-archive  GHSA-c4r9-r8fh-9vj2  Medium    \nsnakeyaml  1.30       1.31      java-archive  GHSA-hhhw-99gj-p3c3  Medium    \nsnakeyaml  1.30       1.32      java-archive  GHSA-9w3m-gqgf-c4p9  Medium    \nsnakeyaml  1.30       1.32      java-archive  GHSA-w37g-rhq8-7m4j  Medium </code></p><p>&nbsp;</p><p>所以，你修复了 jackson-databind 的漏洞，但没有修复 snakeyaml 的漏洞。那么，snakeyaml 1.30 是在哪个依赖中被使用的？你可以通过 Maven 的 dependency:tree 命令来了解。为简洁起见，这里只显示部分输出：</p><p>&nbsp;</p><p><code lang=\"null\">$ mvnd dependency:tree\n...\n com.mydeveloperplanet:mygrypeplanet:jar:0.0.1-SNAPSHOT\n[INFO] +- org.springframework.boot:spring-boot-starter-web:jar:2.7.6:compile\n[INFO] |  +- org.springframework.boot:spring-boot-starter:jar:2.7.6:compile\n[INFO] |  |  +- org.springframework.boot:spring-boot:jar:2.7.6:compile\n[INFO] |  |  +- org.springframework.boot:spring-boot-autoconfigure:jar:2.7.6:compile\n[INFO] |  |  +- org.springframework.boot:spring-boot-starter-logging:jar:2.7.6:compile\n[INFO] |  |  |  +- ch.qos.logback:logback-classic:jar:1.2.11:compile\n[INFO] |  |  |  |  \\- ch.qos.logback:logback-core:jar:1.2.11:compile\n[INFO] |  |  |  +- org.apache.logging.log4j:log4j-to-slf4j:jar:2.17.2:compile\n[INFO] |  |  |  |  \\- org.apache.logging.log4j:log4j-api:jar:2.17.2:compile\n[INFO] |  |  |  \\- org.slf4j:jul-to-slf4j:jar:1.7.36:compile\n[INFO] |  |  +- jakarta.annotation:jakarta.annotation-api:jar:1.3.5:compile\n[INFO] |  |  \\- org.yaml:snakeyaml:jar:1.30:compile\n...</code></p><p>&nbsp;</p><p>输出显示，这个依赖是 spring-boot-starter-web 依赖的一部分。那么，你如何解决这个问题呢？严格来说，Spring 必须要解决这个问题。但如果你不想等待解决方案，你可以自己解决。</p><p>&nbsp;</p><p>解决方案 1: 不需要依赖项。这是最简单的解决方案，风险也低。只需在 pom 中从 spring-boot-starter-web 依赖项中排除该依赖项即可。</p><p>&nbsp;</p><p><code lang=\"null\">\n  org.springframework.boot\n  spring-boot-starter-web\n  \n    \n      org.yaml\n      snakeyaml\n    \n  \n</code></p><p>&nbsp;</p><p>构建 JAR 文件，构建 Docker 镜像，然后再次运行扫描：</p><p>&nbsp;</p><p><code lang=\"null\">$ mvn clean verify\n...\n$ mvn dockerfile:build\n...\n$ grype docker:mydeveloperplanet/mygrypeplanet:0.0.1-SNAPSHOT --only-fixed\n Vulnerability DB        [no update available]\n Loaded image            \n Parsed image            \n Cataloged packages      [61 packages]\n Scanned image           [3 vulnerabilities]\nNo vulnerabilities found</code></p><p>&nbsp;</p><p>再也没发现任何漏洞了。</p><p>&nbsp;</p><p>解决方案 2：你确实需要这个依赖关系。你可以通过 pom 中的 dependencyManagement 来替换这个过渡性依赖。这就有点麻烦了，因为更新后的横向依赖没有经过 spring-boot-starter-web 依赖的测试。你要不要这样做，需要权衡一下。在 pom 中添加以下部分。</p><p>&nbsp;</p><p><code lang=\"null\">\n  \n    \n      org.yaml\n      snakeyaml\n      1.32\n    \n  \n</code></p><p>&nbsp;</p><p>构建 JAR 文件，构建 Docker 镜像，然后再次运行扫描：</p><p>&nbsp;</p><p><code lang=\"null\">$ mvn clean verify\n...\n$ mvn dockerfile:build\n...\n$ grype docker:mydeveloperplanet/mygrypeplanet:0.0.1-SNAPSHOT --only-fixed\n Vulnerability DB        [no update available]\n Loaded image            \n Parsed image            \n Cataloged packages      [62 packages]\n Scanned image           [3 vulnerabilities]\nNo vulnerabilities found</code></p><p>&nbsp;</p><p>同样，再也没发现漏洞了。</p><p>&nbsp;</p><p>解决方案 3：这是在你不想做任何事情或是否有误报通知时的解决方案。创建一个 .grype.yaml 文件，在其中排除高严重性的漏洞，然后用 --config 标志执行扫描，后面是包含排除项的 .grype.yaml 文件。</p><p>&nbsp;</p><p>.grype.yaml 文件如下所示：</p><p>&nbsp;</p><p><code lang=\"null\">ignore:\n  - vulnerability: GHSA-3mc7-4q67-w48m</code></p><p>&nbsp;</p><p>再次运行扫描：</p><p>&nbsp;</p><p><code lang=\"null\">$ grype docker:mydeveloperplanet/mygrypeplanet:0.0.1-SNAPSHOT --only-fixed\n Vulnerability DB        [no update available]\n Loaded image            \n Parsed image            \n Cataloged packages      [62 packages]\n Scanned image           [10 vulnerabilities]\nNAME       INSTALLED  FIXED-IN  TYPE          VULNERABILITY        SEVERITY \nsnakeyaml  1.30       1.31      java-archive  GHSA-98wm-3w3q-mw94  Medium    \nsnakeyaml  1.30       1.31      java-archive  GHSA-c4r9-r8fh-9vj2  Medium    \nsnakeyaml  1.30       1.31      java-archive  GHSA-hhhw-99gj-p3c3  Medium    \nsnakeyaml  1.30       1.32      java-archive  GHSA-9w3m-gqgf-c4p9  Medium    \nsnakeyaml  1.30       1.32      java-archive  GHSA-w37g-rhq8-7m4j  Medium </code></p><p>&nbsp;</p><p>High 漏洞就不再显示了。</p><p>&nbsp;</p><p></p><h2> 持续集成</h2><p></p><p>&nbsp;</p><p>现在你知道如何手动扫描你的 Docker 镜像了。然而，你可能想把扫描镜像作为持续集成管道的一部分。在本节中，将提供一个使用 Jenkins 作为 CI 平台时的解决方案。</p><p>&nbsp;</p><p>要回答的第一个问题是，当发现漏洞时，你将如何得到通知。到现在为止，你只能通过查看标准输出来注意到这些漏洞。这不是一个 CI 管道的解决方案。你想得到通知，这可以通过失败的构建来实现。Grype 有 --fail-on 标志来达到这个目的。你可能不想在发现严重程度为 negligible 的漏洞时让管道失败。</p><p>&nbsp;</p><p>让我们看看当你手动执行这个时，会发生什么。首先，在 Spring Boot 应用程序和 Docker 镜像中再次引入漏洞。</p><p>&nbsp;</p><p>构建 JAR 文件，构建 Docker 镜像，用标志 --fail-on 运行扫描。</p><p>&nbsp;</p><p><code lang=\"null\">$ mvn clean verify\n...\n$ mvn dockerfile:build\n...\n$ grype docker:mydeveloperplanet/mygrypeplanet:0.0.1-SNAPSHOT --only-fixed --fail-on high\n...\n1 error occurred:\n        * discovered vulnerabilities at or above the severity threshold</code></p><p>&nbsp;</p><p>这里没有显示所有的输出，只显示了重要的部分。而且，正如你所看到的，在输出的最后，显示了一条信息，表明扫描产生了一个错误。这将导致你的 Jenkins 管道失败，因此，开发人员会被通知出了问题。</p><p>&nbsp;</p><p>为了将其添加到您的 Jenkins 管道中，有几个选项。这里选择创建 Docker 镜像，并从 Maven 中执行 grype Docker 扫描。grype 没有单独的 Maven 插件，但你可以使用 exec-maven-plugin 来实现这一目的。在 POM 的 build-plugins 部分添加以下内容。</p><p>&nbsp;</p><p><code lang=\"null\">\n  \n    \n      org.codehaus.mojo\n      exec-maven-plugin\n      3.1.0\n      \n        grype\n          \n            docker:mydeveloperplanet/mygrypeplanet:${project.version}\n            --scope\n            all-layers\n            --fail-on\n            high\n            --only-fixed\n            -q\n          \n      \n    \n  \n</code></p><p>&nbsp;</p><p>这里添加了两个额外的标志：</p><p>&nbsp;</p><p>--scope all-layers。这将扫描 Docker 镜像中涉及的所有层。--q：这将使用安静的日志，只显示漏洞和可能出现的故障。</p><p>&nbsp;</p><p>你可以用下面的命令来调用它：</p><p>&nbsp;</p><p><code lang=\"null\">$ mvnd exec:exec</code></p><p>&nbsp;</p><p>你可以把它添加到你的 Jenkinsfile 中的 withMaven 包装器中：</p><p>&nbsp;</p><p><code lang=\"null\">withMaven() {\n  sh 'mvn dockerfile:build dockerfile:push exec:exec'\n}</code></p><p></p><h2>结论</h2><p></p><p>&nbsp;</p><p>在本文中，你了解了如何通过 grype 来扫描你的 Docker 镜像。Grype 有一些有趣的、用户友好的特性，允许你有效地将它们添加到你的 Jenkins 管道中，另外安装 grype 也很容易。与 Anchor Engine 相比，Grype 绝对是一个很大的改进。</p><p>&nbsp;</p><p>作者简介：</p><p>&nbsp;</p><p>Gunter Rotsaert，系统工程师，居住在荷兰的比利时人。</p><p>&nbsp;</p><p>原文链接：</p><p>https://mydeveloperplanet.com/2023/01/18/how-to-check-docker-images-for-vulnerabilities/</p>",
    "publish_time": "2023-04-14 14:22:24",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "2023 年 MQTT 协议的 7 个技术趋势｜描绘物联网的未来",
    "url": "https://www.infoq.cn/article/OFjBYLjJ08OSw8Z4dgZB",
    "summary": "<p></p><blockquote>本文作者Zaiming（Stone）Shi：EMQX 欧洲研发中心负责人，拥有多年大规模分布式 MQTT 消息系统开发经验，致力于与 EMQ 斯德哥尔摩研发团队一起将 EMQX 打造成为全球最优秀的 MQTT broker。</blockquote><p></p><p></p><p>MQTT 是物联网消息传输标准协议，其采用极其轻量级的发布订阅消息模型，以可扩展、可靠且高效的方式连接物联网设备。</p><p></p><p>自 1999 年 IBM 发布 MQTT 以来已经过去了二十多年，而自 2012 年 EMQ 在 GitHub 上发布开源 MQTT 消息服务器 EMQX，也已经过去了十年。如今，我们来到了各类新兴技术飞速进步的 2023 年，随着 MQTT 在物联网中的使用规模不断增长，场景更加多样化，我们可以预见在 MQTT 技术领域中将会出现以下 7 个发展趋势。</p><p></p><h2>MQTT over QUIC</h2><p></p><p></p><p>QUIC（Quick UDP Internet Connections）是由 Google 开发的一种新的传输协议，运行于 UDP 之上，旨在减少建立新连接所带来的延迟，提高数据传输速率，并解决 TCP 的一些限制。</p><p></p><p>下一代互联网协议 HTTP/3 使用了 QUIC 作为底层传输协议，为网络应用带来了比 HTTP/2 更低的时延和更好的加载体验。</p><p></p><p>MQTT over QUIC&nbsp;是自 2017 年 MQTT 5.0 规范发布以来 MQTT 协议中最具创新性的进展。凭借多路复用、更快的连接建立和迁移等优势特性，其具有成为下一代 MQTT 协议标准的潜力。</p><p></p><p>MQTT 5.0 定义了三种传输类型：TCP、TLS 和 WebSocket。在物联网安全最佳实践中，MQTT over TLS/SSL 广泛用于生产环境以保护客户端和 Broker 之间的通信。然而它速度慢、延迟高，需要 3.5 个 RTT，即 TCP 3 次握手以及 TLS 4 次握手才能建立新的&nbsp;MQTT 连接。</p><p></p><p>与 MQTT over TLS/SSL 相比，MQTT over QUIC 更快且延迟更低，在初次建立连接时仅需 1 RTT，并可以利用 0 RTT 连接恢复的特性来加速重连。QUIC 协议栈可以针对各种用例进行定制，例如在不稳定网络环境下，或是客户端到服务器更低延迟通信的场景。它能够在诸如移动网络下的车联网（IoV）以及要求极低时延的工业物联网（IIoT）场景下发挥重要作用，并有效提升其使用体验。</p><p></p><p>开源 MQTT 消息服务器 EMQX 在其最新的&nbsp;<a href=\"http://mp.weixin.qq.com/s?__biz=Mzg3NjAyMjM0NQ==&amp;mid=2247489945&amp;idx=1&amp;sn=e11ff5b1564f7cad9bfb9cfed158232c&amp;chksm=cf39c6bff84e4fa9bf5b77b4d9f9909355a3249d0897ebbb83db823d75ed58b36d1631c12960&amp;scene=21#wechat_redirect\">5.0 版本</a>\"中引入了&nbsp;<a href=\"http://mp.weixin.qq.com/s?__biz=Mzg3NjAyMjM0NQ==&amp;mid=2247490587&amp;idx=1&amp;sn=504f9abdefb87331e2cf04b7572f69f0&amp;chksm=cf39c33df84e4a2b867a941f405ccb9499fe59eeea66ed5fd8e4d8583c77602555b5f3b2a31c&amp;scene=21#wechat_redirect\">MQTT over QUIC 支持</a>\"，是全球首个支持 MQTT over QUIC 的 MQTT 消息服务器。目前 EMQ 正以 OASIS MQTT 技术委员会成员身份积极推进 MQTT over QUIC 的标准化落地，可以预见在不久的将来，MQTT 也将和 HTTP/3 一样使用 QUIC 作为其主要传输层。</p><p><img src=\"https://static001.geekbang.org/infoq/3c/3c35f625cb47495af7917b8a69533f6e.png\" /></p><p></p><h1>MQTT Serverless</h1><p></p><p></p><p>云计算中 Serverless 模式的兴起标志着应用的设计、开发、部署和运行方式发生了突破性的范式转变。这种模式下开发者将能够专注于应用的业务逻辑，无需管理基础设施，从而提高敏捷性、可扩展性和成本效益。</p><p></p><p>Serverless 模式的 MQTT 消息服务器将是 2023 年的一种前沿架构创新。传统的物联网应用需要数分钟甚至数小时才能在云上或在企业私有环境中部署 MQTT 消息服务，相比之下，Serverless MQTT 只需点击几下就能快速完成 MQTT 服务的部署。</p><p></p><p>除了极快的部署速度，Serverless MQTT 更大的价值在于其无可比拟的灵活性：根据用户需求对资源进行无缝扩展，以及与这种弹性架构相匹配的按量计费定价模式。Serverless MQTT 有望推动 MQTT 更广泛的应用，降低运营成本，激发不同行业的创新协作。我们甚至可能看到每个物联网和工业物联网开发者都能拥有一个免费的 Serverless MQTT 消息服务器。</p><p></p><p>2023 年 3 月，EMQX Cloud 推出了全球首个&nbsp;<a href=\"http://mp.weixin.qq.com/s?__biz=Mzg3NjAyMjM0NQ==&amp;mid=2247490852&amp;idx=1&amp;sn=211a7a59300021c5db4cc17a12a07c34&amp;chksm=cf39c202f84e4b140d1985696db8324dfbf8d02143cb4a875c0a29f41cf52ec8f39553047e65&amp;scene=21#wechat_redirect\">Serverless MQTT 服务</a>\"，为用户提供了 5 秒极速部署和更灵活的计费方式，帮助用户以更低的成本高效开发物联网应用。</p><p></p><h1>MQTT 多租户架构</h1><p></p><p></p><p>多租户架构是实现 Serverless MQTT 服务的一个重要基础。来自不同用户或租户的物联网设备可以连接到同一个大规模的 MQTT 集群，同时保持其数据和业务逻辑与其他租户隔离。</p><p></p><p>在 SaaS 应用中多租户架构很常见，即一个应用为多个客户或租户服务。其通常有两种以下不同的实现方式：</p><p></p><p>租户隔离： 向每个租户提供一个单独的应用实例，在服务器或虚拟机上运行。数据库隔离： 多个租户共享一个应用实例，但每个租户有自己的数据库模式，以确保数据隔离。</p><p></p><p>在 MQTT Broker 的多租户架构中，每个设备和租户都有一个单独的、隔离的命名空间，包括一个独特的主题前缀和访问控制列表（ACL），用来定义用户可以发布或订阅哪些主题。</p><p></p><p>多租户 MQTT 消息服务器能够减少管理开销，并灵活支持复杂场景或大规模物联网应用场景。例如，一个大型组织中的部门和应用可以作为不同的租户使用同一个 MQTT 集群。</p><p></p><h2>MQTT Sparkplug 3.0</h2><p></p><p></p><p>MQTT Sparkplug 是由 Eclipse 基金会设计的开放标准规范，其最新版本为 MQTT Sparkplug 3.0，它定义了工业设备的统一数据接入规范，能够通过 MQTT 协议连接各类工业传感器、动作执行器、可编程逻辑控制器（PLC）和网关。</p><p></p><p>MQTT Sparkplug 3.0 于 2022 年 11 月发布，具有以下关键的新功能和改进：</p><p></p><p>MQTT 5.0 支持：增加了对 MQTT 5.0 的支持，包括共享订阅、消息过期和流量控制等新功能。优化的数据传输：对数据传输进行了优化，使用更紧凑的数据编码和压缩算法。扩展的数据模型：引入了一个扩展的数据模型，它允许更详细的设备信息通信，还支持配置数据和设备元数据等其他信息的传输。更高的安全性：包括对安全性的若干改进，如支持双向 TLS 认证、优化的访问控制机制等。简化的设备管理：包括自动设备注册和发现，简化设备配置，以及改进诊断等。</p><p></p><p>MQTT Sparkplug 旨在简化不同工业设备间的连接和通信，实现高效的工业数据采集、处理和分析。随着新版本的发布，MQTT Sparkplug 3.0 将会在工业物联网领域得到更广泛的应用。</p><p></p><h1>MQTT 统一命名空间</h1><p></p><p></p><p>统一命名空间（Unified Namespace）是一个建立在面向工业物联网和工业 4.0 的&nbsp;MQTT Broker&nbsp;上的解决方案架构。它为 MQTT 主题提供了一个统一的命名空间，并为消息和结构化数据提供了一个集中的存储库。</p><p></p><p>统一命名空间使用中央 MQTT Broker ，以星形拓扑结构连接工业设备、传感器和应用程序，如 SCADA、MES 和 ERP。统一命名空间以事件驱动的架构极大简化了工业物联网应用的开发。</p><p></p><p>在传统的工业物联网系统中，OT 和 IT 系统通常是分开的，其数据、协议和工具均独立运行。通过采用统一命名空间，可以让 OT 和 IT 系统更有效地交换数据，最终实现物联网时代 OT 和 IT 的统一。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c2/c268f6e3682be66b5fd88d178f9af45c.png\" /></p><p></p><p>如今，通过 EMQ 提供的开源 MQTT 消息服务器 EMQX&nbsp;或&nbsp;NanoMQ，结合工业协议网关软件 Neuron，用户将可以构建一个由 IT 界最先进技术支持的统一命名空间架构。</p><p></p><h2>MQTT 跨域集群</h2><p></p><p></p><p>MQTT 跨域集群（MQTT Geo-Distribution）是一个创新架构，允许部署在不同地区或云上的 MQTT Broker 作为一个单集群一起工作。通过跨域集群，MQTT 消息可以在不同地区的 MQTT Broker 之间自动同步和传输。</p><p></p><p>有两种方法可以实现 MQTT 跨域集群：</p><p></p><p>单集群，多地区： 单个 MQTT 集群，每个节点在不同地区运行。多集群，多云： 分布在不同云中的多个 MQTT 集群连接在一起。</p><p></p><p>我们可以将这两种方法结合，在跨区域部署的 MQTT Broker 之间创建一个可靠的物联网数据基础设施。通过 MQTT 跨域集群，企业可以建立一个跨多云的全球 MQTT 接入网络。不管所处的物理位置在哪里，设备和应用都能从最近的节点接入实现相互通信。</p><p><img src=\"https://static001.geekbang.org/infoq/08/0855404b6c3526ee6c7decc1111fc602.png\" /></p><p></p><h2>MQTT Streams</h2><p></p><p></p><p>MQTT Streams 是 MQTT 协议备受期待的一项扩展能力，能够在 MQTT Broker 内实时处理海量、高频的数据流。这在发布订阅模式消息传输的基础上进一步增强了传统 MQTT Broker 的能力。通过 MQTT Streams，客户端可以像 Apache Kafka 一样将 MQTT 消息以流的形式进行生产和消费，从而实现历史消息回放。这对事件驱动的处理尤为重要，可以确保最终的数据一致性、可审计和合规性。</p><p></p><p>流处理对于从物联网设备产生的大量数据中实时挖掘商业价值至关重要。以前，这一过程通过一个过时且复杂的大数据堆栈实现，需要 MQTT Broker 与 Kafka、Hadoop、Flink 或 Spark 进行集成。</p><p></p><p>而通过内置的流处理，MQTT Streams 简化了物联网数据处理架构，提高了数据处理效率和响应时间，并为物联网提供了一个统一的消息传递和流处理平台。通过消息去重、消息重放和消息过期等功能，MQTT Streams 实现了高吞吐量、低时延和容错，使其成为基于 MQTT 的物联网应用中实时数据流处理的强大工具。</p><p></p><h2>结语</h2><p></p><p></p><p>总的来说，MQTT 的这 7 个技术趋势反映了新兴技术的进步以及它们在推动物联网发展进程中的重要作用。</p><p></p><p>作为一个发展了二十多年的标准消息传输协议，MQTT 的重要性正在持续增长。随着物联网在各行业被越来越广泛地应用，MQTT 协议也在不断发展以应对新的挑战，满足更低延迟的连接、更便捷的 MQTT 服务部署、复杂场景或大规模物联网应用下灵活管理以及工业设备接入的需求。作为庞大物联网的神经系统，在 2023 年及更远的未来，MQTT 必将在工业物联网和车联网等关键领域中发挥重要作用。</p>",
    "publish_time": "2023-04-14 15:09:15",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Apache Doris在叮咚买菜的应用实践",
    "url": "https://www.infoq.cn/article/ki6J7ArN9UT4uWNyRJoO",
    "summary": "<p></p><blockquote>随着叮咚买菜业务的发展，不同的业务场景对数据分析提出了不同的需求，他们希望引入一款实时 OLAP 数据库，构建一个灵活的多维实时查询和分析的平台，统一数据的接入和查询方案，解决各业务线对数据高效实时查询和精细化运营的需求。经过调研选型，最终引入 Apache Doris 作为最终的 OLAP 分析引擎，Doris 作为核心的 OLAP 引擎支持复杂地分析操作、提供多维的数据视图，在叮咚买菜数十个业务场景中广泛应用。</blockquote><p></p><p></p><p>作者｜叮咚买菜资深数据工程师 韩青</p><p></p><p>叮咚买菜创立于 2017 年 5 月，是一家专注美好食物的创业公司。叮咚买菜专注吃的事业，为满足更多人“想吃什么”而努力，通过美好食材的供应、美好滋味的开发以及美食品牌的孵化，不断为人们提供美好生活的解决方案，致力让更多人吃得新鲜、吃得省心、吃得丰富、吃得健康......以更美好的舌尖体验，为现代家庭创造美味与幸福感。</p><p></p><h1>业务需求</h1><p></p><p></p><p>随着叮咚买菜业务的发展，不同的业务场景对数据分析提出了不同的需求，这些需求最终被数据看板、实时 Ad-Hoc、行为分析、B/C 端业务平台和标签平台等系统应用所承载，为实现这些系统应用，叮咚大数据希望引入一款实时 <a href=\"https://mp.weixin.qq.com/s?__biz=MzIzNjUxMzk2NQ==&amp;mid=2247484167&amp;idx=1&amp;sn=5194af725cd9d0142021f3f489a86a08&amp;chksm=e8d7fcc5dfa075d37ad7af13166bf3aa47c41ec4e048f24704034e4f452881266da5706592a2&amp;scene=27#wechat_redirect\">OLAP 数据库</a>\"，旨在提供一个灵活的多维实时查询和分析的平台，统一数据的接入和查询方案，解决各业务线对数据高效实时查询和精细化运营的需求。基于上述诉求，我们希望所引入的数据库具备以下能力：</p><p></p><p>可以实时高效地分析和使用数据；可以支持明细数据、汇总数据两种不同的数据查询方式；可以对入库后的数据即席选择维度和条件查询，实时/近实时返回结果</p><p></p><h1>选型和对比</h1><p></p><p>我们主要对比了 Apache Doris 和 <a href=\"https://www.infoq.cn/article/E6qLkOx9rqTEKOKqT9vT\">ClickHouse</a>\" 两款市面上最常见的开源 OLAP 引擎，在选型过程中我们主要考虑以下几个方面：</p><p></p><p>支持标准 SQL，无需投入额外的时间适应和学习新的 SQL 方言、直接用标准 SQL 即可直接查询，最大化降低使用门槛；支持 Join 操作，方便事实表与维度表进行关联查询，在应对维度更新时具有更高的灵活性、无需对处理后的宽表进行重刷；支持高并发查询，系统面临多条业务线的同时使用，因此需要有比较强的并行查询能力，以更好满足业务需求；支持离线和实时导入，可与已有技术栈轻松对接，支持多个<a href=\"https://archsummit.infoq.cn/2023/shanghai/track/1523\">数据</a>\"源或<a href=\"https://archsummit.infoq.cn/2023/shanghai/track/1523\">大数据</a>\"组件的离线和实时导入，以更好适配不同使用场景；支持大数据量的明细数据查询，以满足不同业务用户灵活多变的分析需求；</p><p></p><p>经过详尽的技术调研，在我们的大多数业务场景中都需要明细<a href=\"https://www.infoq.cn/article/zy2eQoRFqg01d8seZj48\">数据</a>\"级别的查询、高并发的点查和大数据量的 Join，这几个方面 Apache Doris 相较于 ClickHouse 均更胜一筹，因此我们决定使用 Apache Doris 来搭建新的架构体系。</p><p></p><h1>架构体系</h1><p></p><p>在整体架构中，各个组件承载着特定的功能，Elasticsearch 主要负责存储标签系统的数据，HBase 是实时数仓的维表层，<a href=\"https://www.infoq.cn/article/dassaX2O2WqvGjqpbXlf\">MySQL </a>\"用于存储业务系统的数据存储，Kafka 主要存储实时数据，Spark 主要提供 Ad-Hoc 查询的计算集群服务，而 Apache Doris 作为核心的 OLAP 引擎支持复杂地分析操作、提供多维的数据视图。</p><p></p><p>离线部分： 数据从业务库通过 DataX 导入到数据仓库 ODS 层，经过层层处理输出到 Doris 中，上层 BI 系统链接到 Doris 进行报表展示。实时部分： 数据通过 Flink 消费<a href=\"https://www.infoq.cn/article/CpfvECIb5gWdditBBYy7\"> Kafka </a>\"中的数据，进行相应的逻辑处理后，输出到 Doris 或者 HDFS 中，供应用层使用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/36/36d2b0037faa697ab787c42bfa4cd7e4.png\" /></p><p></p><p>在数据应用的 OLAP 层中，Doris 应用方案如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/41/418989c63add5f0cca3b04ba586c28b8.png\" /></p><p></p><p>模型创建规范化： 采用流程审批的方式进行数据建模，根据具体的业务场景来搭建 Duplicate，Unique Key 和 Aggregate 模型，并按照用户提供的数据量设置合适的 Bucket 数目，做好模型归属关系。数据入口的统一： <a href=\"https://archsummit.infoq.cn/2023/shanghai/track/1497\">数据</a>\"的流入主要有实时和离线两种，实时数据用 Flink 任务从 Kafka 消费数据，逻辑处理流入 Doris ；离线数据通过 Broker Load 方式从 Hive 中将数据灌入 Doris 中。服务对外出口的统一： 对外服务主要通过两种方式暴露接口，一种是使用 JDBC 直连，上层系统配置 Doris 集群的 FE 的连接信息直连 Doris；另一种是业务通过内部的 One API 服务配置业务接口使用 Doris。业务 SQL 的优化治理：  通过采集 Doris FE 的审计日志，以此来对 SQL 的性能进行分析优化，以及对 Doris 服务进行治理。</p><p></p><h1>应用实践</h1><p></p><p>叮咚买菜目前已经将 OLAP 引擎统一为 Apache Doris 广泛应用于业务场景中，我们将 Doris 集群拆分成了四个集群，分别支持核心报表、行为分析与算法应用、B/C 端业务和实时<a href=\"https://archsummit.infoq.cn/2023/shanghai/track/1497\">数据</a>\"，根据不同业务场景的业务量及数据规模，集群的资源配置也不尽相同。目前总的机器规模达数十台，以行为分析场景为例，单个集群近 20 个节点、 <a href=\"https://archsummit.infoq.cn/2023/shanghai/track/1523\">存储数据</a>\"量超过百 TB，每日新增数据量达数十亿条 。</p><p></p><p>接下来分享 Apache Doris 在叮咚买菜常见业务场景中的应用实践及使用经验。</p><p></p><h2>实时数据分析</h2><p></p><p>从下方数仓模型图可知，数据通过 Flink 作业进行逻辑处理，在不同层级 Kafka 中进行流转加工，经过数据汇总层之后，应用层需要一个组件来存储结果数据，该组件一般是从 <a href=\"https://www.infoq.cn/article/3xtSDtHUgTKRsyw3kZXH\">MySQL 数据库</a>\"、KV 存储和 OLAP 引擎三者中选择其一。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bd/bda0c74c8eb5ba5ea630a1540080f23f.png\" /></p><p></p><p>考虑到我们的结果数据大多以计算指标数据居多，缺乏维度数据，因此应用层的组件需要具备高效、低延迟的数据 Join 能力。基于以上因素，我们最终选择 Apache Doris 作为实时数仓和实时业务的数据应用层，Doris 可以有效降低数据处理延时，提高查询效率。</p><p></p><p>比如在销量计划项目中，该项目需要每日实时写入大量预测数据，并且这些数据需要较低时延提供给分析师进行及时对比分析、修改该预测值，并提供到供应链端。因修改预测值会影响到系统调拨，所以选用的存储必须是要具有高吞吐低延迟特性，Doris 完全符合该要求。从销量计划的整个数据生产及处理链路来看，使用 Doris 后，最慢 2 秒内可以看到最新的数据。</p><p></p><p>当前公司已经有数十个实时业务需求接入到 Doris 中，随着业务的不断发展，这个数字也在慢慢增加。</p><p></p><h2>B 端业务查询取数</h2><p></p><p>在实际的使用中，通常会有 B 端业务或系统需要从数据仓库中取数的需求，比如自研 Pylon 系统（主要用来基于用户偏好的数据查询）会根据 UID 查询用户画像信息。在这种场景下，通常需要进行复杂的模型关联，同时要求在秒级或者毫秒级返回查询结果。</p><p></p><p>使用前：我们最初使用 Spark 的 JDBC 方式来直接查询数据仓库 Hive 表数据，由于存放用户标签数据的 Hive 表的数据量有几千万体量，通过 Spark JDBC 方式要耗费几分钟才能查出结果，同时还存在 Yarn 调度耗时较高的问题，有时会因为队列资源紧张产生延迟，导致一个普通的查询甚至需要十几分钟才能跑出结果，用户的体验度非常不好。使用后：经过我们对数据链路的改造，将 Hive 的用户标签数据离线灌入 Doris 中，再用同样的 SQL 查询，Doris 的性能在绝大多数场景下比 Spark 要好很多，可以在秒级别得到返回结果。</p><p></p><h2>标签系统</h2><p></p><p>最初我们的标签数据存放在 ES 中，但是随着业务的扩展、下游业务越来越多，标签数据规模急速膨胀，策略规则不断增加变化，标签系统遭遇严重的性能瓶颈。</p><p></p><p>聚合和 Join 查询的性能低人群圈选花费时间近 20 分钟ES 导入慢、查询性能低</p><p></p><p>为解决以上问题，我们目前正在尝试使用 Doris 来替换 ES，希望通过 Doris 解决上述问题，选择 Doris 主要考虑以下三点：</p><p></p><p>1、分布式 Join 大大提升查询效率</p><p></p><p>原有商品 ID 和仓库 ID 通过嵌套类型存储在 ES 中，替换为 Doris 存储之后，需要将复杂的嵌套类型拆解为两张表来做表级关联，同时可以试用 Doris 的多种分布式的 Join 提高查询得性能。Doris 的分布式 Join 主要有 Shuffle Join、Broadcast Join 和 Colocate Join。</p><p></p><p>其中 Colocate Join 查询性能是最好的，旨在为某些 Join 查询提供本地性优化，来减少数据在节点间的传输耗时、加速查询，另外我们在该场景下基本均为千万级的表。综合来看，Colocate Join 比较符合场景与需求，最终决定使用 Colocate Join方式提升 Join 性能。</p><p></p><p>如何使用： 标签数据的使用主要涉及到两张大表的 Join，建表时需要设置相同的 Distributed Key、相同的 Bucket数、相同的副本数，还要将两个表通过 colocate_with 属性划分到一个组 Colocation Group(CG)。</p><p></p><p><code lang=\"sql\"> CREATE TABLE `profile_table` (\n`pdate` date NULL COMMENT \"null\", \n`product_mongo_id` varchar(4000) NULL COMMENT \"商品ID\", \n`station_id` varchar(4000) NULL COMMENT \"仓id\", \n ......\n ) ENGINE=OLAP\nUNIQUE KEY(`pdate`,\n`product_mongo_id`, `station_id`)\nCOMMENT \"OLAP\"\nPARTITION BY RANGE(`pdate`)()\nDISTRIBUTED BY \nHASH(`product_mongo_id`) BUCKETS 7\nPROPERTIES (\"colocate_with\" = \"profile_table\",\"in_memory\" = \"false\",\"storage_format\" = \"V2\") \n</code></p><p></p><p><code lang=\"sql\">CREATE TABLE \n`station_info_table` ( `product_mongo_id` varchar(4000) NULL COMMENT \"商品id\", `station_id` varchar(4000)NULL \nCOMMENT \"站点id\", \n`snapshot` date NULL COMMENT \"日期\", \n`product_id` bigint(20) NULL COMMENT \"商品id\", ......) \nENGINE=OLAPUNIQUE KEY(`product_mongo_id`, `station_id`, `snapshot`)\nCOMMENT \"OLAP\"\nPARTITION BY RANGE(`snapshot`)()\nDISTRIBUTED BY \nHASH(`product_mongo_id`) BUCKETS 7\nPROPERTIES (\"colocate_with\" = \"profile_table\",\"in_memory\" = \"false\",\"storage_format\" = \"V2\") \n</code></p><p></p><p>比如我们有这样一条查询语句：</p><p></p><p><code lang=\"sql\">select count(psp.product_mongo_id) from profile_table psp \nleft join station_info_table psi on psp.product_mongo_id=psi.product_mongo_id and psp.station_id=psi.station_id\nwhere psp.pdate='2023-03-16' and psp.four_category='特色醋' and psp.brand_name='宝鼎天鱼' and psp.weight_unit='ml' and psp.pmg_name='粮油调味组';\n</code></p><p></p><p>经过使用 Colocate Join 方式优化后，可以达到毫秒级的查询效果。接下来我们介绍一下 Colocate Join 的查询性能高的原因有哪些呢？</p><p></p><p>A. 数据导入时保证数据本地性</p><p></p><p>Doris 的分区方式如下所示，先根据分区字段 Range 分区，再根据指定的 Distributed Key Hash 分桶。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/77/77fdac459684eff37399dab29b33f91f.png\" /></p><p></p><p>所以我们在数据导入时保证本地性的核心思想就是两次映射，对于 Colocate Tables，我们保证相同 Distributed Key 的数据映射到相同的 Bucket Seq，再保证相同 Bucket Seq 的 Buckets 映射到相同的 BE。可以同查看执行计划查看是否使用了Colocate Join：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c3/c3182a0acd8c81417a735339303826d4.png\" /></p><p></p><p>对于 HashJoinFragment，由于 Join 的多张表有了数据本地性保证，所以可以去掉 Exchange Node，避免网络传输，将 ScanNode 直接设置为 Hash Join Node 的 Child。</p><p></p><p>B. 查询调度时保证数据本地性</p><p></p><p>查询调度的目标： 一个 Colocate Join 中所有 ScanNode 中所有 Bucket Seq 相同的 Buckets 被调度到同一个 BE。查询调度的策略：第一个 ScanNode 的 Buckets 随机选择 BE，其余的 ScanNode 和第一个 ScanNode 保持一致。</p><p></p><p>C. 数据 Balance 后保证数据本地性</p><p></p><p>新增一个 Daemon 线程专门处理 Colocate Table 的 Balance，并让正常的 Balance 线程不处理 Colocate Table 的 Balance。正常 Balance 的粒度是 Bucket，但是对于 Colocate Table，必须保证同一个 Colocate Group 下所有 Bucket 的数据本地性，所以 Balance 的单位是 Colocate Group。</p><p></p><p>2、高效简易的array_contains函数</p><p></p><p>在做人群圈选时，有以下类似的 Json 结构[{\"K1\":\"V1\",\"K2\":200},{\"k1\":\"v2\",\"k2\":300}]，当配置 k1=v1,k2=200，只要该 Value 里的 Json 项有一项满足全部条件就会被圈出来，我们可以借助 Doris 1.2 版本中的 array_contains 数组函数处理，将 Json 转化为 Array 数组处理。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f6/f63af61f666fb30096f96a76e3fa957e.jpeg\" /></p><p></p><p>3、Broker Load 加速数据导入效率</p><p></p><p>Doris Broker Load 是一种高效、稳定的数据导入方式，它可以将数据分成多个分片，然后将每个分片分配给不同的 Broker 节点进行处理，我们使用 Broker Load 将标签数据从 Hive 导入 Doris 中，有效提高了数据导入的效率和稳定性。</p><p></p><h2>BI 数据看板</h2><p></p><p>我们商业智能分析使用的 BI 分析平台主要是帆软和自研的阿尔法 BI，底层使用 Doris 来存储数据，目前用来做报表的 Doris 表数量已达到了 3000 多张，四个 Doris 集群的日 UV 1000+ ，PV 达到十几万，由于 Doris 可以达到毫秒级响应速度、支持高并发查询，因此单集群的 QPS 可以达到达到 120次/秒，符合我们的要求。</p><p></p><h2>OLAP 多维分析</h2><p></p><p>随着业务的增长，我们在运营的过程中我们常常有一些疑问：最近三个月哪个品类的下单量最高？变化趋势如何？各个时段人均下单是多少？某个区域，发生购买行为的年龄段分布是怎样的？......而想要获得结果，必须根据用户行为日志进行事件分析。</p><p></p><p>目前我们的用户行为数据日均增量为 20亿+，高峰期 100亿+，为了更好的进行事件分析，我们需要保留半年的数据，也就是几千亿的数据量。 我们使用 Doris 来存储如此庞大的数据量，在应对复杂的分析场景时可以达到分钟级的响应。在多维分析的过程中， 往往也伴随着大数据量的复杂查询，接下来分享如何使用 Doris 应对：</p><p></p><p>1、 Bitmap 去重</p><p></p><p>业务使用过程中需要分析用户参与情况以及活跃程度，考查进行初始行为后的用户中，有多少人会进行后续行为，这时候一般都是使用留存分析模型实现此类需求。该模型使用中有去重操作，计算周期有某天/某周/某月/最近三个月等，由于每天的埋点数据量都能达到几十亿，高峰期 100 亿，在这个情况下，使用 count(distinct)性能太差、甚至查询超时（或超过设置的时间），而如果使用 Bitmap 来可以成倍的缩短查询时间。</p><p></p><p><code lang=\"text\">select\nevent_id,\ndate,\ncount(distinct uid) as count\nfrom event\nwhere \ndt&gt;='2022-06-01' and dt&lt;'2022-06-06' and event_id in (......) group by event_id, str_to_date(dt,'%Y-%m-%d');\n</code></p><p></p><p>使用 Bitmap 优化 SQL 后</p><p></p><p><code lang=\"text\">select\nevent_id,\ndate,\nbitmap_count(uid) as count\nfrom event\nwhere \ndt&gt;='2022-06-01' and dt&lt;'2022-06-06' and event_id in (......) group by event_id, str_to_date(dt,'%Y-%m-%d');\n</code></p><p></p><p>使用中需要注意 Bitmap 函数在 Apache Doris 中仍然需要先把数据汇聚到一个 FE 节点才能执行计算，并不能充分发挥分布式计算的优势，在数据量大到一定的情况下， Bitmap 函数并不能获得比 COUNT(DISTINCT) 更好的性能，上述实例之所以能达到预期结果是由于做了分组计算。</p><p></p><p>如果处理大数据量的全量去重，在建表时将 Bitmap 列的值按照 Range 划分，不同 Range 的值存储在不同的分桶中，保证了不同分桶的 Bitmap 值是正交的。当查询时，先分别对不同分桶中的正交 Bitmap 进行聚合计算，然后顶层节点直接将聚合计算后的值合并汇总并输出，从而解决顶层单节点计算瓶颈问题。</p><p></p><p>2、前缀索引和 Bloom Filter 索引</p><p></p><p>Doris 主要支持两类索引：内建的智能索引（包括前缀索引）和创建的二级索引（包括 Bloom Filter 索引和 Bitmap 倒排索引）。实际使用时我们会用到前缀索引和 Bloom Filter 索引来提高查询效率。</p><p></p><p>前缀索引</p><p></p><p>Aggregate、Unique 和 Duplicate 三种数据模型中，底层的数据存储是按照各自建表语句中 AGGREGATE KEY、UNIQUE KEY 和 DUPLICATE KEY 指定的列进行排序存储的。前缀索引即在排序的基础上实现的一种根据给定前缀列、快速查询数据的索引方式，实现方式是将一行数据的前 36 个字节作为这行数据的前缀索引，当遇到 VARCHAR 类型时，前缀索引会直接截断。</p><p></p><p>比如我们要查询按照日期和 event_id 分组的去重人数，建表语句如下：</p><p></p><p><code lang=\"text\">CREATE TABLE ubs_event_log_small_event (\nevent_id int(11) NULL COMMENT \"事件id\",\ndt datetime NOT NULL COMMENT \"事件时间\",\nuid char(128) NULL COMMENT \"用户id\",\ndict_id int(11) NULL COMMENT \"用户id字典值\",\nos varchar(24) NULL COMMENT \"操作系统\",\n......\ndict_id_bitmap bitmap BITMAP_UNION NULL COMMENT \"bitmap用户id\"\n) ENGINE=OLAP\nAGGREGATE KEY(event_id, dt, uid, dict_id, os, ......)\nCOMMENT \"用户行为事件表\"\nPARTITION BY RANGE(dt)\n()\nDISTRIBUTED BY HASH(dt, event_id, uid) BUCKETS 64\n</code></p><p></p><p>SQL 查询的 Where 条件一般遵循建表的 AGGREGATE 模型的 KEY 的顺序，这样可以命中 Doris 内置的前缀索引。</p><p></p><p><code lang=\"text\">SELECT \nCONCAT(\nTO_DATE(dt), \n' 00:00:00'\n) AS tm, \nevent_id, \nBITMAP_UNION_COUNT(dict_id_bitmap) AS UNIQ_1908_1 \nFROM \nkepler.ubs_event_log_small_event \nWHERE event_id = 1908 AND \ndt &gt;= '2023-03-26' \nAND dt &lt; '2023-04-05'\nAND \nos IN (1, 2)\nGROUP BY \n1, \n2;\n</code></p><p></p><p>Bloom Filter 索引</p><p></p><p>针对大数据量的事件表进行查询时我们会设置 bloom_filter_columns，加快查询效率：</p><p></p><p><code lang=\"text\">alter table datasets set(\"bloom_filter_columns\" = \"area_name, is_booking, user_source, source_first_order......\");\n</code></p><p></p><p>查询语句中 where 条件有以上设置的字段就会命中该索引。</p><p></p><p><code lang=\"text\">SELECT * FROM datasets WHERE area_name=\"****\" AND is_booking=0 \n</code></p><p></p><p>3、物化视图</p><p></p><p>为了获得更粗粒度的聚合数据，Doris 允许在建表语句创建出来的 Base 表的基础上，创建若干 Rollup 表。</p><p></p><p>例如上表 ubs_event_log_small_event，我们可以对 dt，event_id，dict_id_bitmap 建立 Rollup 物化视图，这样 Rollup 只包含三列： dt，event_id，dict_id_bitmap 。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/66/6613c20a24a1473018652d7afcf40035.png\" /></p><p></p><p>这时再进行上述查询就会命中这个 Rollup，从而只扫描极少的数据量就可以完成此次聚合查询。</p><p></p><h1>优化经验</h1><p></p><p></p><h2>Broker Load 导数任务流程化</h2><p></p><p>为了 Doris 使用更加便捷，我司在内部自研的叮咚大数据平台上对整个过程进行流程化；从建模到配置 Broker Load 导数任务再到导数任务调度均进行了调整，具体优化如下所述：</p><p></p><p>建模过程： 需要用户发起建模流程申请，填写需求内容、具体建模语句、预估数据量大小、数据保留时长、所需相关权限账号等信息，足够完整的信息可以在审批时获得建模过程中的元数据信息以及选择更合适的数据模型。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/68/6842ff5a378c032c7c1a01caf57c5e15.png\" /></p><p></p><p>Broker Load 导数任务配置： 为了提高用户使用效率、降低使用门槛，我们通过 Mapping 映射和自动化配置方式，自动生成导数任务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7d/7d862ae75d4d76a8ec15a000ed55ea8b.png\" /></p><p></p><p>导数任务调度： 配置完 Broker Load 导数任务，就可以由用户根据需求配置小时或者天级别的调度，这样整个 Doris 数据导入流程，就可以由用户配置自动完成。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6f/6f69dd7c00c84bf262b7b9e1fd8286b4.png\" /></p><p></p><h1>总结与展望</h1><p></p><p>Apache Doris 作为叮咚买菜整体架构体系中的核心 OLAP 分析引擎，不论是作为数仓数据看板类的应用层、还是作为实时数据汇总结果接入层、或是作为 B/C 端服务数据提供方，均能够很好的满足业务需求。除此之外，Doris 使得我们无需在存储选型上耗费过多时间，大大缩短了开发的周期；同时，Doris 支持 MySQL 协议和标准 SQL ，大大降低内部人员的使用成本和门槛。未来，我们希望使用 Doris 支撑内部更多的业务场景，更大范围了提升工作效率。我们也会紧跟社区步伐，积极使用推出的新版本特性，以更好解决场景需求，提升业务效果。</p><p></p><p></p>",
    "publish_time": "2023-04-14 15:30:43",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "ChatGPT已过时？Auto-GPT迅速走红，无需人类插手自主解决复杂任务，GitHub标星5万",
    "url": "https://www.infoq.cn/article/XBsThbej4O7u2EbTqlzS",
    "summary": "<p>ChatGPT之所以能风靡全球，很大程度上要归功于其简单的功能框架。作为一款AI聊天机器人，它唯一的作用就是生成令人信服的自然语言文本、顺畅回应用户的提问。</p><p></p><p>但AI聊天机器人的使用体验，往往由用户设计提示词的水平所决定。有鉴于此，新型应用Auto-GPT应运而生，它允许AI自主行动 — 即实现“自我提示”，并彻底改变我们对于这项技术的看法和感受。对于这一工具，有外媒的标题甚至称，“<a href=\"https://archsummit.infoq.cn/2023/shanghai/track/1503\">ChatGPT</a>\" 已经过时”。</p><p></p><p>Auto-GPT项目地址：<a href=\"https://github.com/Torantulino/Auto-GPT\">https://github.com/Torantulino/Auto-GPT</a>\"</p><p></p><h2>Auto-GPT是什么？</h2><p></p><p><a href=\"https://github.com/Torantulino/Auto-GPT\">Auto-GPT</a>\"是一款开源Python应用程序，由开发者用户Significant Gravitas于2023年3月30日发布至GitHub。该应用程序以GPT-4为基础，允许AI“自主”行动，无需用户详尽提示每个动作。大家可以为Auto-GPT制定一个总体目标，再由它逐步采取行动以实现目标。这就是“AI智能体”概念的来源 — 使用互联网资源以完全独立的方式在PC上执行操作，不再需要一步步接受提示和引导。</p><p></p><p>GitHub上还发布了一个简单示例，展示Auto-GPT 如何浏览网络并为“即将到来的下一个节假日”准备聚餐食谱。这时Auto-GPT会化身“大厨Chef-GPT”，帮助用户在网上搜索正确答案。之后，它会将食谱以文件的形式保存在用户计算机内。</p><p></p><p>就功能本身来看，这似乎算不上什么创新大事件。但Auto-GPT代表用户搜索互联网并执行文件保存操作的能力，已经让这款<a href=\"https://archsummit.infoq.cn/2023/shanghai/track/1503\">AI</a>\"远远超越了简单的聊天机器人。</p><p></p><h2>Auto-GPT是如何工作的？</h2><p></p><p>Auto-GPT的迷人之处，在于它能够对AI的运行步骤做拆分，真正把GPT模型出色的文本生成能力转化为可用功能。Auto-GPT把整个过程分解成“思考”、“推理”和“评价”几个环节，准确告知用户AI正在做什么、为什么这么做。在前面的Chef-GPT示例中，它的“思考”方式如下：“我将搜索即将到来的节假日，据此创建出独特的食谱。”而“推理”部分，则是“只要确定了节假日的具体内容，就能确定食谱的相应设计。”</p><p></p><p>至于“评价”环节，Auto-GPT会对所做工作表达一些担忧和限制。可以看到，Auto-GPT正在以完全自主的方式一步步达成用户指定的目标。</p><p></p><p>Auto-GPT还拥有其他一些神奇的能力，包括长/短期记忆和集成ElevenLabs提供的文本到语音实现。所有这些功能的结合，让Auto-GPT在感受上更像是能与人类真正互动的<a href=\"https://www.infoq.cn/article/H3KecCxpmOmrgCo3QJlr\">AI智能体</a>\"。</p><p></p><h2>Auto-GPT用例</h2><p></p><p>人们正在发掘Auto-GPT的各种可能用例。虽然目前仍处于起步阶段，但因为它属于纯开源项目，所以任何人都可以尝试这款工具。Twitter上就出现了一个简单的“Ecommerce-GPT”示例，其目标是自主开发和运营电子商务业务，旨在帮助用户增加净资产。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/80/808638695d53116c80acdcfd14ef89f3.png\" /></p><p></p><p>我的Auto-GPT来自@SigGravitas，正在开发电子商务业务。它决定检索互联网以寻找商业创意，并将结果保存在文件中以供后续参考。</p><p></p><p>另一个有趣的用例出现在编码领域。Twitter上的一位用户想出了“Robo-GPT”，负责分析、重写并保存程序代码。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/be/be3111b4c02ba5ad61aec592af37a823.png\" /></p><p></p><p>今天我编写了Auto-GPT的变体Robo-GPT，希望让代码更干净、依赖关系更简单。它目前的功能还不像Auto-GPT那么完备，但希望它能易于理解、运行和更新。</p><p></p><p>类似的例子还有很多，也许这款AI智能体最终将帮助我们创建网站、组织社交媒体活动等等。</p><p></p><p>与此同时，具备类似功能的竞争系统也纷纷亮相，包括微软Jarvis和BabyAGI。这些方案都允许GPT“自我提示”并实现自主行动。</p><p></p><h2>如何使用Auto-GPT</h2><p></p><p>与其他GitHub项目一样，<a href=\"https://github.com/Torantulino/Auto-GPT.git\">Auto-GPT</a>\"的设置过程不只是下载文件或者访问网站。在上手之前还需要满足一些重要的前提条件，比如安装有Python 3.8（或更高版本）、OpenAI API密钥和Pinecone API密钥。如果希望使用可选的文本转语音功能，还需要用到ElevenLabs API。</p><p></p><p>用户可以在Auto-GPT GitHub页面上找到相关链接及其他重要信息。在满足以上三项要求后，单击“Code”并下载Zip文件。当然，用户也也可以通过Git应用程序获取这些文件。</p><p></p><p>首先打开命令行程序，例如PowerShell，并在其中输入“git clone <a href=\"https://github.com/Torantulino/Auto-GPT.git\">https://github.com/Torantulino/Auto-GPT.git</a>\"”以克隆代码仓库。</p><p></p><p>第二步是在PowerShell中输出“cd ‘Auto-GPT'”以导航至项目目录。之后，输入“pip install -r requirements.txt”来安装所需的依赖项。最后，将文件“.env.template”重命名为“.env”并填写您的&nbsp;OpenAI API 密钥。</p><p></p><p>在安装完成之后，Auto-GPT的实际使用其实非常简单。它会要求用户先为机器人命名，之后再提供想达成的目标。它甚至提供两个示例，引导朝着正确的方向前进。</p><p></p><h2>Auto-GPT实现通用人工智能了吗？</h2><p></p><p>不少AI爱好者把Auto-GPT视为通往人工通用智能（AGI）的第一步。确实，Auto-GPT表现出了推理和通过多个自主步骤达成目标的能力，其长/短期记忆机制也让它能够不断学习更多新鲜事物。</p><p></p><p>但很多人仍然认为，一系列相互关联的提示并不能让系统真正获得“智能”；也有人坚称，人类的大部分智能和行为就是以这种方式实现的。</p><p></p><p>无论是AGI的开端、还是AI标准化道路上的重要一步，Auto-GPT的出现必然引发新的哲学思考。这些运行在互联网上、活动在数字世界中的AI智能体，究竟是不是“智能生物”？也许只有时间能给出答案。</p><p></p><p>参考链接：</p><p></p><p><a href=\"https://www.digitaltrends.com/computing/what-is-auto-gpt/\">https://www.digitaltrends.com/computing/what-is-auto-gpt/</a>\"</p>",
    "publish_time": "2023-04-14 15:44:18",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Meta又开源一个实用AI工具，可将涂鸦变动画",
    "url": "https://www.infoq.cn/article/G5xBP7eWGPPth0iMZsZe",
    "summary": "<p>4月14日，Meta公司对外开源了一个<a href=\"https://archsummit.infoq.cn/2023/shanghai/track/1503\">AI</a>\"工具，该工具可以将人们的涂鸦变成现实动画。该公司希望通过将动画绘图作为开源项目提供，其他开发人员将能够创造新的、更丰富的体验。</p><p></p><p>工具地址：<a href=\"https://developers.facebook.com/blog/post/2023/04/13/meta-os-animated-drawings/\">https://developers.facebook.com/blog/post/2023/04/13/meta-os-animated-drawings/</a>\"</p><p></p><p>Fundamental AI Research（FAIR）团队最初于 2021 年发布了<a href=\"https://sketch.metademolab.com/\">该工具的网络版。</a>\"它要求用户上传单个类人角色的绘图或选择一个演示图。如果用户使用自己的涂鸦，将会出现一份问询同意书，询问 Meta 是否可以使用用户的绘图来帮助训练其模型。Meta设置该问卷的人性化之处在于，即使用户不同意，也可以继续使用该工具。</p><p>&nbsp;</p><p>网络版地址：<a href=\"https://sketch.metademolab.com/\">https://sketch.metademolab.com/</a>\"</p><p>&nbsp;</p><p>接下来，用户需要调整捕获框的大小，使其紧贴创作。该工具为用户提供了一支笔和橡皮擦，可以在调整关节的位置之前调整绘图。用户会看到草图的动画版本。用户可以从四种类别的各种预设动画中进行选择：舞蹈、滑稽、跳跃和行走。</p><p>&nbsp;</p><p>动画绘图利用对象检测模型、姿势估计模型和基于图像处理的分割方法来捕获绘图的数字版本。然后它使用传统的计算机图形技术对图像进行变形和动画处理。</p><p>&nbsp;</p><p>在几个月内演示上线，用户已授予 <a href=\"https://www.infoq.cn/article/WTGeuldhgMYP96V9FHdN\">Meta </a>\"许可，可以将超过 160 万张图像用于训练目的。有些人上传了公司标志、动漫人物、鱼和毛绒动物的图像，尽管该工具规定只有人物形象才能工作。</p><p>&nbsp;</p><p>除了对包含声音效果和文本叠加的更深入工具集的请求外，人们上传到该工具的一系列图像表明人们对更广泛的绘图到动画体验有着广泛的兴趣。在某种程度上，这导致 Meta <a href=\"https://archsummit.infoq.cn/2023/shanghai/track/1503\">开源</a>\"了该项目的源代码，其中包含约 18万张图纸的数据集。“通过将模型和代码作为开源发布，该项目为开发人员提供了一个构建和扩展项目的起点，在开源社区中培养了创新和协作的文化，”Meta 在博客文章中写道。</p><p>&nbsp;</p>",
    "publish_time": "2023-04-14 16:19:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "滴滴自动驾驶发布 Robotaxi 概念车；智己汽车发布 D.L.P. 人工智能模型；毫末智行发布自动驾驶生成式大模型 | 汽车技术新闻速览（4.12-4.14）",
    "url": "https://www.infoq.cn/article/KKaEhGYQizY2t1SKJbxi",
    "summary": "<p>智己汽车发布 D.L.P. 人工智能模型；国产 3D 游戏引擎 Cocos 与福特达成合作打造全新汽车智能座舱；毫末智行发布自动驾驶生成式大模型；滴滴自动驾驶发布 Robotaxi 概念车……一文速览汽车技术领域新动态！</p><p>&nbsp;</p><p></p><h4>智己汽车发布 D.L.P. 人工智能模型</h4><p></p><p></p><p>近日，智己汽车正式发布行业首个 D.L.P. 人工智能模型。据悉，智己和 Momenta 从第一性原理出发，基于领先的 D.L.P. 人工智能模型，采集大量人类驾驶数据进行训练。通过构建具备亿级数据量产能力的决策规划数据-模型产线，在车端采用 <a href=\"https://www.infoq.cn/article/ZG3J9h*cW7mJAK0NXwos\">Transformer</a>\" 架构，高效理解场景和他车行为，显著提高复杂环境变化的预判能力，进而提前规划智能驾驶行为，避免不舒适体感的产生，让智己 IM AD 实现更像人的跟车间距、线性起步响应、无顿挫舒适感等优质体验，大幅降低接管里程，总体类人性相比规则算法获得阶越性提升，打造行业第一梯队的智驾体验。以更像人的智驾体验为目标，智己汽车开辟全新开发范式，与全球头部的智能驾驶算法玩家 Momenta 联合开发、双向赋能，共同探索智能驾驶高阶新未来。</p><p>&nbsp;</p><p></p><h4>智行者获东风猛士科技 917 车型高阶自动驾驶量产定点，合作车型第三季度量产</h4><p></p><p></p><p>4 月 13 消息，智行者科技官方微信公众号更新文章，宣布获得了东风旗下豪华电动越野品牌猛士科技 917 车型量产项目定点，双方合作车型预计今年第三季度实现量产。据了解，本次项目合作中，智行者为猛士科技 917 车型提供了软硬件一体的 L2+ 自动驾驶系统。具体来看，这一方案包含城市领航、高速领航、记忆泊车、自主代客泊车等 25 项功能，是目前行业内功能最完备的量产自动驾驶方案；同时，架构最高可支持 L3 级别自动驾驶功能，具有高度扩展性。在硬件配置方面，该方案采用了全国产核心计算芯片，AI 算力最高可达 512TOPS，配置 1-3 个激光雷达，达到 L3 级别系统算力及冗余设计需求。除此之外，智行者还在感知、决策规划等算法模块进行了创新升级。其中，感知模块中，智行者采用了时空联合的多任务融合感知模型，有效提升了感知区域范围；同时，该方案采用了强交互时空联合决策规划方案，让车辆行为更加专业化、拟人化，通行能力及车辆舒适性大幅提升。</p><p>&nbsp;</p><p></p><h4>国产 3D 游戏引擎 Cocos 与福特达成合作，打造全新汽车智能座舱</h4><p></p><p></p><p>近日，国产游戏引擎开发商 Cocos 与福特达成合作。根据合作协议，Cocos 与福特将围绕<a href=\"https://www.infoq.cn/article/NqoID3LoDUaxxW7iDOmu\">智能座舱</a>\"解决方案展开深度合作。Cocos 表示，基于 Cocos 3D 实时渲染引擎，Cocos 可为汽车提供由车载人机交互界面，自动辅助驾驶可视化，车载虚拟形象，车载游戏，音乐播放器等应用构成的 Cocos HMI 智能座舱解决方案。据介绍，Cocos HMI 基于 Cocos 引擎轻量高效的优势，同等水平的画面表现下，Cocos 能实现资源消耗量最低；同样的资源消耗量，Cocos 可提供最佳的视觉体验。此外，Cocos HMI 基于 Cocos 引擎的跨平台能力，该方案可运行于多种芯片，并适配于 Android、Linux、QNX 等主流车机系统，帮助主机厂实现低、中、高端车型的全覆盖。借助 Cocos 高效的工具链，Cocos HMI 不仅能够提供统一的技术栈和开发标准，并且内置成熟稳定、经商业化项目验证的核心应用开发模板。</p><p></p><h4>&nbsp;</h4><p></p><p></p><h4>毫末智行发布自动驾驶生成式大模型</h4><p></p><p></p><p>近日，毫末智行发布自动驾驶生成式大模型“雪湖·海若”，通过引入驾驶数据建立 RLHF(人类反馈强化学习)技术，对自动驾驶认知决策模型进行持续优化，最终实现端到端自动驾驶。据介绍，“雪湖·海若”通过引入驾驶数据建立 RLHF 技术，对自动驾驶认知决策模型进行持续优化，最终目标是实现端到端自动驾驶，现阶段主要用于解决自动驾驶的认知决策问题。目前，“雪湖·海若”实现了模型架构与参数规模的升级，参数规模达到 1200 亿，预训练阶段引入 4000 万公里量产车驾驶数据。目前，“雪湖·海若”已正式对外开放，开启对限量首批客户的合作，北京交通大学计算机与信息技术学院、高通、火山引擎、华为云、京东科技、四维图新、魏牌新能源、英特尔等已经加入。</p><p></p><h4>&nbsp;</h4><p></p><p></p><h4>滴滴自动驾驶发布 Robotaxi 概念车</h4><p></p><p>4 月 13 日<a href=\"https://www.infoq.cn/article/lrmj5i5ytQIhirewUoOr\">滴滴自动驾驶</a>\"开放日上，滴滴自动驾驶发布 Robotaxi 概念车：DiDi NEURON。据了解，DiDi NEURON 独创了车内机械臂，可以实现车内外的多种服务，如提行李、递水、叫醒等，最大程度优化乘坐体验与运营需求。空间上，DiDi NEURON 去掉驾驶位，最大限度释放了乘坐空间。车内大屏交互系统有会议、游戏、街景介绍、氛围选择等功能，将出行过程与丰富的场景结合。此外，滴滴出行 CTO 兼自动驾驶 CEO 张博介绍，目前最新版的滴滴出行 APP 已可在上海、广州的指定区域内，实现混合派单。即起终点均在区域内的订单，用户能在滴滴 APP 上直接看到“自动驾驶”选项并叫车，体验滴滴自动驾驶带来的服务体验。</p><p>&nbsp;</p><p></p><h4>滴滴发布国内首个 2K 图像级高精度激光雷达“北曜 Beta”，量产无人车 2025 年接入网络</h4><p></p><p></p><p>4 月 13 日，滴滴自动驾驶在正式推出“北曜 Beta”激光雷达和三域融合计算平台“ Orca 虎鲸”两款核心硬件。据了解，北曜 Beta 是国内首个 2K 图像级高精度激光雷达，由滴滴自动驾驶和激光雷达北醒公司联合设计；Orca 虎鲸则是一个量产化的三域融合计算平台，由滴滴自动驾驶研发，集成了智驾域、座舱域和网联域。此外，滴滴自动驾驶 COO 孟醒还公布了自动驾驶量产新进展。滴滴自动驾驶正在结合新能源整车企业能力，共同定义和量产无人驾驶新能源网约车，已在 Robotaxi 产品定义、车型平台选择及座舱与智驾系统开发等方面合作。首款车型将于 2025 年接入滴滴共享出行网络，实现全天候、规模化的混合派单。</p><p>&nbsp;</p><p></p><h4>小马智行全新一代 Robotaxi 车型在北京首发上路，极端天气下自动驾驶能力大幅提升</h4><p></p><p></p><p>4 月 14 日，小马智行官方微信公众号更新文章，宣布小马智行全新一代 Robotaxi 车型成功在北京首发上路。这批车辆基于丰田赛那 Autono-Maas（S-AM）车型打造，目前已累计超过 50000 公里的道路测试里程。据了解，此次成功上路的小马智行 Robotaxi 车型搭载了小马智行第六代自动驾驶硬件系统。其中传感器套件使用了性能更稳定、成本更低的车规级量产部件，包含 4 个固态激光雷达、3 个补盲激光雷达、3 个毫米波雷达，以及 11 个摄像头。此外，通过自研的传感器清洁系统，新一代 Robotaxi 车辆在雨、雪、雾、沙尘等各类复杂极端天气下的表现也得到大幅提升。</p>",
    "publish_time": "2023-04-14 16:42:05",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "百信银行发布首个 3D 数字营业厅；农行发布投行智能顾问服务系统 | 金融科技新闻速览（4.12-4.14）",
    "url": "https://www.infoq.cn/article/IQTGpP8ubIt1mku0uBtR",
    "summary": "<p>微众银行持续推出无障碍服务；百信银行发布行业首个 3D 数字营业厅“零度空间”； 农行发布投行智能顾问服务系统；艾融软件完成大语言模型金融解决方案……一文速览金融科技领域新动态！</p><p></p><p></p><h4>微众银行持续为更多听障、视障用户带来便利，金融服务更贴心</h4><p></p><p></p><p><a href=\"https://www.infoq.cn/article/OJaT*6JGmhfqp2ipBYm2\">微众银行</a>\"持续推出无障碍服务，让更多听障、视障用户都可以享有获得金融服务的权益。据了解，微众银行微粒贷是全国范围内第一家增设手语视频客服的银行金融产品，2016 年，微粒贷团队专为听障用户增设了远程视频身份核验流程，并聘请专职手语专家组建了一支手语服务团队，也为视频手语服务搭建了专门的网络设备。手语服务打破了声音的障碍，保障了听障用户的金融权益，让听障用户获得服务便利的同时，能够感受到被理解、被尊重、被信任。针对视障用户的金融需求，微众银行持续优化“微众银行 App 无障碍版”，结合光线活体、AI 语音合成、手机震动传感器和加速度传感器等技术，建立了无障碍人脸和身份证识别系统。无障碍人脸系统通过振动频率告知视障客户人脸偏离程度，通过语音告知客户如何移动手机，待移动至正确位置即可完成核验，避免了传统人脸识别过程所需的点头、眨眼、读数字等辅助核验动作。</p><p></p><p></p><h4>百信银行发布行业首个 3D 数字营业厅“零度空间”</h4><p></p><p></p><p>4 月 11 日，<a href=\"https://www.infoq.cn/article/dF33USbOt*Ps6v3djoef\">百信银行</a>\"正式推出全新交互体验的 3D 数字营业厅“零度空间”。据了解，“零度空间”革新了传统银行的服务交互模式，在生成式人工智能技术的驱动下，通过构建更有趣的 3D 数字空间、打造更好玩的内容互动社区、营造更愉悦的金融体验三大产品亮点，为年轻用户提供全新的沉浸式数字金融服务。用户从百信银行 APP 首页进入“零度空间”，可以定制个性化、多模态的数字分身，实现与数字员工 AIYA 交流互动、购买专属理财产品、观看数字人直播、逛 α 星轮抽奖等全新极致体验。这既是百信银行对未来银行的一次全新探索，也是 AIGC 技术在数字银行的一次创新应用。</p><p></p><p></p><h4>兴业银行新专利：以深度学习模型驱动数字人肢体动作生成</h4><p></p><p></p><p>近日，兴业银行和兴业数金于 2022 年 9 月 30 日申请的一项名为“基于深度学习模型驱动数字人肢体动作生成方法及系统”的专利公布，其涉及人工智能技术领域。据了解，与现有技术相比，该发明的有益效果在于：一是训练了一个可进行肢体动作分类的深度学习模型，在数字人播报时，通过文本和肢体动作的关联关系，可自适应地指导数字人肢体动作生成，并对识别效果进行自动完善，提高数字人肢体动作的多样性和感官性。二是为数字人引入符合播报文本的肢体动作手段，增加多模态数字人的表达能力，使数字人更拟人化，同时增加人机交互友好性。三是根据公开的视频数据自动建立文本和肢体动作标签的对应关系，解决以往需要大量的人工标注的问题，降低成本的同时提高质量并增强最终呈现的效果。</p><p></p><p></p><h4>农行发布投行智能顾问服务系统</h4><p></p><p></p><p>近日，<a href=\"https://www.infoq.cn/article/TVocv80lDp1Y9BOkDY8H\">中国农业银</a>\"行在京发布投行智能顾问服务系统——农银思享。据悉，农银思享平台是农业银行围绕企业投融资与经营管理需求打造的一站式线上融智服务平台，在对资讯研报、财务诊断、风险预警、撮合交易、投融资辅导等常规功能优化完善的基础上，率先推出 ESG 咨询、产业解析与智能撰写等创新功能，组成 8 大功能模块，全方位赋能企业战略规划、经营管理、投融决策、低碳转型等多元应用场景。农业银行相关负责人表示，农业银行将抓住全球新一轮科技革命的历史性机遇，持续纵深推进数字化转型，加快打造科技引领、数据赋能的数字经营新模式，为深化数字乡村建设、支持实体经济发展、服务数字中国建设提供智能安全的金融科技力量。</p><p></p><p></p><h4>艾融软件：已经完成大语言模型金融解决方案，并细化到部分具体金融场景落地实施方案</h4><p></p><p></p><p>近日，艾融软件接受调研时表示，公司已经完成了基于自主可控、可平滑升级、精准匹配银行需求的大语言模型金融解决方案，并细化到部分具体金融场景落地实施方案。在与部分银行交流过程中，相关解决方案得到了极大的认可，相关合作落地事宜正在积极推进中。</p>",
    "publish_time": "2023-04-14 16:42:07",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Twitter裁掉了八成员工，现仅剩1500人！马斯克：我很痛苦",
    "url": "https://www.infoq.cn/article/646d32tsTQk61TlvyTQk",
    "summary": "<p>4月12日，据外媒报道，<a href=\"https://www.infoq.cn/article/1jdi4LDTycjblozS8QwV\">Twitter CEO 马斯克</a>\"在接受BBC采访时表示，在过去的6个月中，解雇 Twitter 的大部分员工是他自接管公司以来不得不做的“最艰难的事情之一”。</p><p>&nbsp;</p><p>这位亿万富文在接受采访期间谈到了他对 Twitter 的管理以及对言论自由的观点。</p><p>&nbsp;</p><p>马斯克表示，在他去年 11 月接管该平台时，该公司拥有约 7800 名员工，他上任后裁掉了6500人，现在仅剩下1500名员工。</p><p>&nbsp;</p><p>“让这么多人离开很难吗？”&nbsp;BBC记者提问道。</p><p>&nbsp;</p><p>“是的，一点都不好玩，很痛苦。”马斯克立即回答。</p><p>&nbsp;</p><p>因为公司经营不善导致的裁员是无可避免的。但<a href=\"https://www.infoq.cn/article/oajLcUpF45Vk3L68KDTZ\">马斯克</a>\"通知员工被辞退的方式一直被网友诟病。许多在 2022 年底卷入马斯克大规模裁员的前 Twitter 员工表示，当<a href=\"https://mp.weixin.qq.com/s?__biz=MzA4NTU2MTg3MQ==&amp;mid=2655219481&amp;idx=1&amp;sn=2f36f12d41c587fbd92d1e2b8b4cc8d9&amp;chksm=8461c879b316416fc9e9a7f788e043cabdc43a531c5ce548c43e069095adef8725ecb991294f&amp;scene=27#wechat_redirect\"> Twitter </a>\"突然将他们锁定在笔记本电脑之外时，他们才发现自己失去了工作。</p><p>&nbsp;</p><p>就这一问题，记者又询问马斯克是否觉得他或经理人有必要亲自与下岗员工交谈时，马斯克回复称“与这么多人交谈在身体上是不可能的”。</p><p>&nbsp;</p><p>这位亿万富翁表示，在他接管公司时，Twitter 有“四个月的生命”，大规模裁员是遏制“30 亿美元的负现金流情况”的“严厉”必要措施。</p>",
    "publish_time": "2023-04-14 17:26:39",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从寻找就业到创造就业 | ArchSummit",
    "url": "https://www.infoq.cn/article/bZhkeuVld4DYjJJsGdgJ",
    "summary": "<p>你好，我是热罐，80年创业者，一个懂商业的码农。</p><p></p><p>今天看到一条新闻说上海某双一流高校毕业生整体就业率只有15%，研究生也就17%。这么算下来，再念3年研究生不过只是延迟就业而已。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/15/15e1a833183dd578d62dc1419008c54d.png\" /></p><p></p><p>就目前形势来看，找工作变得越来越难。互联网大厂正在不断裁员，国企和民企也不怎么招人，甚至连外卖骑手和滴滴司机都在趋于饱和。企业正在通过削减工作岗位来降低运营成本，家庭和个人也在增加存款和削减消费，以防备未来可能出现的风险。</p><p></p><p>让我们来看看2023年第一季度的金融数据：M2余额是281.46万亿，比2022年底增加了15.03万亿；贷款余额增加10.6万亿；存款余额增加&nbsp;15.39 万亿，其中住户存款9.9万亿。整体而言就是央行第一季度印的钱和多存的钱大体相当，加上3月CPI环比跌了0.3%，整个经济有通缩的风险。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/15/15a570c741bd25f76fceda9f1010bd84.png\" /></p><p></p><p></p><p>和2015年相比，目前的经济形势好像更需要“大众创新、万众创业”。市场上的职位越来越少，政府也没有那么多公务员的岗位，再加上像GPT-4这种生成式人工智能（AIGC）技术的飞速发展，更是让初级就业市场雪上加霜。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a803a7f1baaee3984a2b9db7c80fd07d.png\" /></p><p></p><p></p><h4>创业者的思考</h4><p></p><p></p><p>既然环境不能改变，那就适应环境。如果没有就业，那就创造就业！</p><p></p><p>不管是做个小买卖，还是开公司创业，其实都可以创造就业。这不仅能解决自己的就业问题，还能给其他人提供机会。</p><p></p><p>我认为要成长为“创造就业”的人：需要拥有一个前提，经历三个阶段。</p><p></p><p>一个前提：创业精神。创业精神是一种不怕挑战，永于开拓的精神。在这种精神的感召下，创业者不会拘泥于现有的框架，也不会按部就班、亦步亦趋，而是勇敢地走在“无人区”。当然，创业者也必须要有一定承担风险和挑战的能力和决心。</p><p></p><p>第一阶段：个人成长。这个阶段主要是不断提高个人能力，包括基本的技能，生存能力，与人沟通的能力等等。从念书开始一直到大学毕业，有时候还要延伸到工作的最初几年。在这个阶段主要的任务是不断学习新的知识和能力，关注在个人成长上，对自己负责。我把这个阶段叫作“觉己”。</p><p></p><p>第二阶段：资源成长。在这个阶段个人能力主要关注在软技能上，包括沟通能力、组织能力、商业能力、领导力等等。创业者需要构建自己的资源圈，不管是一起工作的同事、管理的小团队，面对的客户还是合作伙伴都是资源的一部分。很多人从这个阶段起就可以开始选择创业了，当然还需要在第三阶段经历更多的历练。这个阶段主要关注在团队成长和资源的扩展，对他人负责。我把这个阶段叫作”觉他“。</p><p></p><p>第三阶段：企业成长。这个阶段是企业家的终身追求。对经济形势、国家政策、商业机会的判断和努力“不犯错”是走向成功的关键。这个阶段也是创造大量就业的阶段。这不仅是对自己和家庭的一种贡献，更是对整个社会和国家的一种贡献。企业家通过提供就业机会，可以帮助更多的人实现自我价值和人生梦想，同时也可以推动社会和经济的发展。创造就业不仅是一种经济活动，更是一种社会责任和使命。我把这个阶段叫作“觉天“。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f5/f5047a08db74c81e3f7eca021f54c134.png\" /></p><p></p><p></p><p>当然，每个人有不同的经历和优势，人生的道路也各不相同。</p><p></p><p>如果大家对走上创业之路有兴趣，欢迎大家报名参加我在4月21日到4月22日极客传媒InfoQ举办的全球架构师峰会ArchSummit上的演讲：“<a href=\"https://archsummit.infoq.cn/202304/shanghai/presentation/5239\">技术人如何走上创业之路，实现人生价值</a>\"”。具体时间是4月22日16:00-16:45。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/c2/a8/c2f97306acfbbb2d22d185ebef44c4a8.jpg\" /></p><p></p><p>想了解更多ArchSummit日程信息，欢迎扫描上方二维码。欢迎一起线下交流。</p><p></p><p>嘉宾介绍：</p><p><a href=\"https://archsummit.infoq.cn/202304/shanghai/presentation/5239\">郝峻晟</a>\"，曾在微软、EMC等公司担任软件研发工程师及主管的职位。曾创建了上海云角信息技术有限公司，被上市公司收购，并担任上市公司 CTO、副总裁及云业务集团总裁等职位。作为一名软件工程师，创业者和企业管理者，郝峻晟在软件开发、云计算和企业管理上拥有丰富的经验，在 IT 行业里耕耘多年。</p><p></p><p>拥有上海交通大学计算机本科和硕士学位，中欧 EMBA 硕士学位和五道口金融 EMBA 硕士（在读），此外还在数家私募基金担任有限合伙人和投资决策委员，多家被投资公司担任法人和董事职位。著有《漫谈云上管理：云计算商业模式和数字化转型》书籍，同时还是公众号“热罐小角”的作者。</p>",
    "publish_time": "2023-04-14 17:43:42",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]