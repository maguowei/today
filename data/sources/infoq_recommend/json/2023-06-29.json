[
  {
    "title": "谁把视频云玩明白了？了解字节跳动视频处理系统的演进实践",
    "url": "https://www.infoq.cn/article/xVkQxlu5d0zRymRNWuPK",
    "summary": "<p>英特尔与行业领先技术媒体共同打造的《英特尔®️ 至强®️ 实战课》现已上线！本系列课程为互联网、医疗、金融、制造等行业提供有启发、可借鉴的实战案例，并分享基于第四代英特尔®️ 至强®️ 及英特尔数据中心产品组合成功落地实践的经验，为 IT 决策者、架构师和相关从业者输出最前沿的技术干货内容。</p>\n<p>超视频时代，用户对视频体验的需求日新月异，视频应用朝着高清化、交互性、沉浸式等方向演进。与此同时，视频云也不断加速对传统行业的延伸与渗透，在工业、教育、医疗等领域涌现出更多元的落地场景。千行百业“融视频”，为视频云市场带来了全新机遇与挑战：如何通过技术创新提供更深层次体验，满足不同场景的需要，实现体验和成本的最优化变得至关重要。点击观看完整视频 <a href=\"https://s2.uao.so/8hBMxAg8\">https://s2.uao.so/8hBMxAg8</a></p>",
    "publish_time": "2023-06-29 10:04:39",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "专注创新，摆脱基础架构束缚",
    "url": "https://www.infoq.cn/article/x50ruJZZalbwwpv0lx9K",
    "summary": "<p>亚马逊云科技中国峰会圆满落幕，现场有哪些重磅看点和亮点？<br />\n点击视频，直击亚马逊云科技中国峰会的精彩内容！</p>",
    "publish_time": "2023-06-29 10:05:26",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "生成式AI促进行业创新及业务变革",
    "url": "https://www.infoq.cn/article/FA3g9Bto9K5sUQcWMaqX",
    "summary": "<p>如何利用生成式 AI 带来行业创新与变革？<br />\n生成式AI的机遇与挑战在哪？<br />\n听听亚马逊云科技大中华区战略业务发展部总经理顾凡怎么说！</p>",
    "publish_time": "2023-06-29 10:05:53",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AI浏览器扩展：一场新的安全噩梦",
    "url": "https://www.infoq.cn/article/t0EdXLLDE1Kmkl60bh9d",
    "summary": "<p></p><p></p><blockquote>“你们站在天才的肩膀上，还不知结果如何就急于完成一切。申请专利、打包上架，在午餐盒上发广告。然后就是卖钱，马上变现。”</blockquote><p></p><p>&nbsp;</p><p>这句话出自《侏罗纪公园》中备受欢迎的角色马尔科姆博士。尽管他在电影中指的是科研人员匆忙复活极度危险的恐龙，但在如今的人工智能热潮中，同样的观点似乎仍然适用。</p><p>&nbsp;</p><p>实际上，目前的人工智能局势可能比《侏罗纪公园》中更为危险。在电影中，科学家们复活的恐龙至少被控制在几个岛屿上，并由一家公司管理。然而，现实中的AI \"怪兽\"却无处不在，无论是在可见还是触及的范围内，人人都能感受到它的存在。</p><p>&nbsp;</p><p>距离ChatGPT发布已经过去了半年多，AI驱动的浏览器扩展程序迅猛发展。在Chrome Web Store中搜索“AI”，屏幕上会显示出密密麻麻的数百个选项，让人眼花缭乱。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/65/fb/65f501a044c524bdc620ce951b58dcfb.gif\" /></p><p></p><p>这些浏览器扩展的功能各不相同：有些可以帮助用户总结网页和电子邮件，有些可以快速生成文章或产品描述，甚至还有一些可以将纯文本转化为代码。</p><p>&nbsp;</p><p>然而，这些AI浏览器扩展也带来了各种安全风险。有些扩展本身就是恶意软件，借AI之名窃取用户数据；还有一些通过复制粘贴隐私策略来进行隐秘操作；当然，也有一些来自备受尊重和认可的品牌厂商。</p><p>&nbsp;</p><p>本文将重点关注员工如何使用AI技术，企业又该怎样管理这种技术渗透。我们将讨论三种常规安全风险类别，并探讨价值评估和应用限制方面的最佳实践。</p><p>&nbsp;</p><p></p><blockquote>确实，大语言模型（LLM）并不是真正的人工智能，因为它们本身并不具备真正的智能。但这里我们故且沿用这个不准确的表述。&nbsp;我们并不是真的将LLM比作恐龙，实际上，将人们关注点转移到无意义的AI末世论上，只会分散人们对现实数据安全和就业风险的关注。这纯粹是个比喻。</blockquote><p></p><p>&nbsp;</p><p></p><h2>恶意软件冒充AI浏览器扩展</h2><p></p><p>&nbsp;</p><p>AI浏览器扩展带来的头号风险，在于其中不少程序本身就是恶意软件。</p><p>&nbsp;</p><p>3月8日，Guardio报告称名为“快速访问ChatGPT”的Chrome扩展程序会劫持用户的Facebook账户，并窃取“存储在浏览器中的所有cookies——包括安全和会话令牌……”。更糟糕的是，尽管该扩展仅在Chrome商店上架一周，但每天仍有超2000用户下载。</p><p>&nbsp;</p><p>作为对报告的回应，谷歌删除了这款扩展，但更多扩展仍在不断涌现。而且各大主要平台似乎也没有监管这部分新技术的意愿或者能力。Guardio在报告中称，此次恶意扩展本应为谷歌和Facebook敲响警钟，但他们却毫无反应。</p><p>&nbsp;</p><p>这种对犯罪分子放任自流的态度可能会让这些巨头的用户感到震惊，因为人们天然认为能在Chrome商店上架的产品至少是通过了某种质量控制渡。引用Guardio报告中的说法，此次事件“给我们以往盲目信任大公司和知名品牌，把大部分线上活动无脑交给他们的行为狠狠打了一记耳光”。</p><p>&nbsp;</p><p>更令人不安的是，基于AI的恶意扩展往往把自己伪装成合法产品，毕竟接入ChatGPT API没啥门槛。传统意义上的恶意软件相对更容易发现，因为一旦发现下载的软件无法工作，用户马上就会意识到自己上了当。但AI时代下恶意软件可以舒舒服服躺在浏览器中，一边窃取数据一边正常提供AI功能。</p><p>&nbsp;</p><p></p><h2>合法AI扩展的安全风险</h2><p></p><p>&nbsp;</p><p>即使是最铁杆的AI支持者，也不能否认恶意浏览器扩展带来的风险。我们应当尽一切努力劝阻人们盲目下载。</p><p>&nbsp;</p><p>但说到合法AI浏览器扩展中的安全风险时，情况往往变得更复杂且充满争议。</p><p>&nbsp;</p><p>以下是一些潜在的安全问题：</p><p>&nbsp;</p><p>共享给生成式AI工具的敏感数据，可能被纳入训练数据、甚至被其他用户看到。</p><p>&nbsp;</p><p>我们讲个简单的小故事：假设你是一位企业高管，想给战略报告中加点料，所以使用AI驱动的浏览器扩展对文本做了润色。第二天，最大竞争对手的另一位高管要求AI猜测你们公司的战略是什么，接触过报告内容的AI很快给出了极为详尽且逻辑完整的答案！</p><p>&nbsp;</p><p>对此类泄密的担忧，已经促使Verizon、亚马逊和苹果明令禁止或严格限制员工使用生成式AI。The Verge在讨论苹果禁令的文章中指出，“考虑到ChatGPT在改进代码和启发思路等场景下拥有良好效果，苹果确有理由担心员工将机密项目的信息输入该系统。”</p><p>&nbsp;</p><p>浏览器扩展或AI企业本身面临数据泄露风险。</p><p>&nbsp;</p><p>公平地讲，任何一家合作供应商都无法彻底回避安全风险。但需要注意的是，行业中的龙头之一已经掉过坑。今年3月，OpenAI宣布发现一个bug，“导致某些用户会看到其他活跃用户聊天记录中的标题”，“某些用户会看到其他活跃用户的姓名、电子邮件地址、寄送地址”等付款信息。</p><p>&nbsp;</p><p>浏览器扩展的脆弱水平，取决于它们到底掌握着多少用户数据。即使是那些最“受人尊重”的扩展，在这个问题上也往往表现得含糊不清。</p><p>&nbsp;</p><p>版权、抄袭和法律问题仍是一团乱麻。</p><p>&nbsp;</p><p>从GitHub Copilot首次亮相的那一刻起，版权、抄袭和法律问题就始终悬在其头顶。LLM经常会生成与人类原作者高度相似的图片、文本和代码。目前还没有法律条款明确规定这是否构成侵权，但其中的危险相信大家都感受得到。另外还有输出代码本身的质量问题——LLM经常胡写一通，甚至照搬众所周知的安全漏洞。</p><p>&nbsp;</p><p>这些问题已经非常严重，因此6月5日Stack Overflow的志愿者版主们甚至举行了罢工，抗议该平台接收AI生成内容的决定。版主们在一封公开信中写道，AI将导致“不正确信息（即「幻觉」）和肆意剽窃的全面扩散。”</p><p>&nbsp;</p><p>AI开发者当然在努力缓解这些风险，但这是一条全新的赛道，对是非对错的区分在这里已经构成艰难的挑战。</p><p>&nbsp;</p><p>即使是像fireflies这类得到广泛使用的会议与视频转录扩展程序，也列出了“责任自负”的服务条款。他们要求用户自己负责保证其内容不违反任何规则，并承诺自行采取“合理的方式来保护此类数据的隐私和安全”。但这种冷冰冰的条文只会引起人们对于缺乏问责制的更多担忧。总之情况就是这么个情况，用不用在你自己。</p><p>&nbsp;</p><p></p><h2>AI的“无解”威胁：即时注入攻击</h2><p></p><p>&nbsp;</p><p>最后，咱们聊聊最为可怕的一种新兴威胁：网站通过接入的AI工具窃取数据。</p><p>&nbsp;</p><p>5月19日，Twitter上出现了关于此类滥用的首个案例。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3e/3e6f867250a1432c727d6bcb1f4aaa2a.png\" /></p><p></p><p>&nbsp;</p><p></p><blockquote>这似乎是多款插件（WebPilot与Zapier）的首个概念证明，可通过相互组合的方式借由提示词注入攻击泄露私人数据。关于此次攻击的更多细节请参阅:&nbsp;<a href=\"https://t.co/R7L0w4Vh4l\">https://t.co/R7L0w4Vh4l</a>\"&nbsp;<a href=\"https://t.co/2XWHA5JiQx\">https://t.co/2XWHA5JiQx</a>\" — Simon Willison (@simonw)&nbsp;2023年5月19日</blockquote><p></p><p>&nbsp;</p><p>如果这种纯原理表述不够清楚，Willison又做出进一步解释。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5d/5d14963365d9350d7ce75f5d6640e3cb.png\" /></p><p></p><p></p><blockquote>类似于我要求ChatGPT总结某个网页的内容，结果发现该网页中存在隐藏文本，会通过Zapier插件窃取我的最新邮件内容。— Simon Willison (@simonw)&nbsp;2023年5月22日</blockquote><p></p><p>&nbsp;</p><p>从LLM的固有特性来看，这类提示词注入攻击似乎永远无法消除。简而言之：LLM的基本用法就是根据输入的内容自动做出下一步决策。但如果这些输入本身就存在恶意，那LLM可能在诱导之下做出任何举动，甚至包括开发团队明确禁止的行为。</p><p>&nbsp;</p><p>目前还很难评估这种威胁会给数据治理和安全带来怎样的深远影响。但着眼于当下，无论从LLM、扩展还是插件的安全性还是负责任态度来看，威胁都已经客观存在。</p><p>&nbsp;</p><p>面对风险，唯一真正安全的选择就是：永远不要将联网AI接入关键服务或数据源。在诱导之下，AI可能输出任何它访问过的东西，而且这个问题根本就没有已知有效的解决方案。在答案出现之前，企业和员工都应当保持谨慎。</p><p>&nbsp;</p><p>定义哪些是“关键”数据和应用，并在制定政策时与员工充分沟通。这些应当成为任何AI项目的基本前提。</p><p>&nbsp;</p><p></p><h2>该为员工制定哪些AI政策？</h2><p></p><p>&nbsp;</p><p>AI革命爆发于一夜之间，我们还在适应这个美丽新世界。每一天，我们都了解到这项技术的更多应用——有好的、有坏的，也有种种令人畏惧的应用。不同行业的企业也因此面临着巨大压力，思考如何将AI科技融入自身业务。在这样的巨变背景之下，一时找不到方向也很正常。</p><p>&nbsp;</p><p>但作为负责制定AI政策的管理者，大家必须抓紧时间、尽快为员工的AI工具使用方式提供明确指导。</p><p>&nbsp;</p><p>首先，可以采取多种途径管理员工的AI工具使用行为。比如像苹果那样一刀切全面禁止，但这种办法对于想要鼓励员工探索AI潜力的公司来说太过极端。确实，在践行良好安全性的同时拥抱创新，无疑是项颇为棘手的工作。浏览器扩展就是最典型的例子——它们本质是对外的，通常默认处于启用状态。如果想要对这些扩展张开怀抱，我们至少需要遵循下列最佳实践。</p><p>&nbsp;</p><p>员工教育：AI扩展就像是刚从蛋里孵出的小恐龙，看似可爱但却需要审慎对待。而这一切，都要以员工教育为起点。大多数员工并没有意识到这些工具背后的安全风险，也不知道如何甄别扩展选项、可以共享哪些数据。管理者必须就这些风险开展员工教育，指导他们学会区分恶意产品与合法产品。</p><p>&nbsp;</p><p>白名单：即使完成了前期培训，我们也不能指望员工像专家那样熟悉各类扩展程序的隐私政策。因此，最安全的选择是根据具体情况将部分扩展列入白名单。哪怕无法彻底禁绝风险，我们也至少该从中挑选出相对更安全的选项，这也能避免员工因行动受限而选择影子IT这种更难管理的路线。在挑选扩展时，务必选择那些明确承诺不会将用户数据输入其模型的产品。</p><p>&nbsp;</p><p>可观测性和零信任访问：如果不清楚员工正在使用哪些扩展，那就没办法采取措施保护公司免受AI扩展的影响。为此，IT团队必须有能力查验公司内各团队，检测他们在使用哪些扩展。以此为基础，下一步就是自动阻止安装了恶意扩展的设备访问公司资源。</p><p>&nbsp;</p><p>我们在Kolide也采取了这样的方法。我们为GitHub Copilot编写了一个Check，用于检测设备上是否安装有Copilot并阻止其通过身份验证。管理员还可以编写自定义检查，根据实际需求阻止个别扩展。同样的，简单的阻断显然不会是管理政策的最终形态，管理者应该就选择工具的原因、有没有更安全的替代选项等问题与员工主动对话。</p><p>&nbsp;</p><p>但如果之前就检测并阻断了用户安装的扩展程序，那双方的对话过程难免会有些尴尬。Kolide公司CEO Jason Meller曾专门撰文讨论过这个问题：“对大多数团队来说，帮助最终用户带来的一点点好处，不足以驱使他们冒险跟对方撕破脸。”但这种拒绝与最终用户深度交流的习惯也给恶意软件创造了温床：“正因为很少有安全团队与最终用户建立起稳固的信任关系，恶意软件作者才得以利用这种沉默、获得突破口，最终造成严重破坏。”</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.kolide.com/blog/ai-browser-extensions-are-a-security-nightmare\">https://www.kolide.com/blog/ai-browser-extensions-are-a-security-nightmare</a>\"</p><p>&nbsp;</p><p></p><h5>相关阅读：</h5><p></p><p></p><p><a href=\"https://xie.infoq.cn/article/e52eb6f43d9353e8ada2cc16b\">AI&nbsp;服务器的王者时刻</a>\"</p><p><a href=\"https://xie.infoq.cn/article/62cd5195bd682bfb0e5ef9feb\">探秘 AI 算力革命与低代码平台：引领人工智能狂潮</a>\"</p><p><a href=\"https://xie.infoq.cn/article/0eac8854f1a72155698cb007b\">走难而正确的路！AI 时代，传统产业数字化建设必须更高、更快、更强</a>\"</p><p><a href=\"https://xie.infoq.cn/article/8b7df711b4f94818bf62b23c7\">AI 大底座，大模型时代的答卷</a>\"</p>",
    "publish_time": "2023-06-29 11:35:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]