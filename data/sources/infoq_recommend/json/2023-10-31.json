[
  {
    "title": "空间小程序: Web 开发者的下一个增长曲线？",
    "url": "https://www.infoq.cn/article/Cj9r10fBw460GHSRu1bO",
    "summary": "<p>YodaOS 首个版本发布于 19 年，它当时定位于开源智能音箱解决方案，笔者当时就作为 YodaOS 应用框架的核心维护者，为 JavaScript 开发者提供了内置的 JavaScript 语音应用框架。</p><p></p><p>时过境迁，智能音箱逐渐淡出了人们的焦点，似乎在语音助手领域的场景与 Web 生态并没那么契合，带屏音箱也让解决方案重新回到了 AOSP（Android）的生态。</p><p></p><p>而我兜兜转转 4 年过去，又回到了 Rokid，我仍然希望为 Web 开发者们找到一些有趣又足够支撑起工程师们生存的下一个增长曲线，于是便有了今天的 YodaOS JSAR —— 空间小程序。</p><p></p><p>几年时间，YodaOS 从原来的智能音箱操作系统（基于 Linux）升级为 YodaOS Master，后者是用于空间计算（AR/MR/XR）场景的操作系统，技术底座也从原来的 Linux Kernel 变为 AOSP，而 YodaOS JSAR 则是在这个系统之上构建的一套面向 Web 开发者的应用框架，可以说 YodaOS JSAR 是之前 YodaOS JavaScript Application Framework 的延续，从原来开发一个语音技能应用升级到空间小程序的开发。</p><p></p><p>就在不久前，笔者受邀参加了 OpenJS World 2023 在上海的一次小型分享会：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c5/c514ee58cbec4cdfd6976eea90a16242.png\" /></p><p></p><p>OpenJS World 2023 上海站研讨会</p><p></p><p>本文将结合这次研讨会上分享的内容做一次文字版本的输出，以期望给本文读者了解 YodaOS JSAR 的全貌以及背后的思考逻辑。</p><p></p><p></p><h2>空间与空间计算</h2><p></p><p></p><p>作为背景补充，首先来了解什么是空间。</p><p></p><p>在增强现实（AR）的场景中，空间是指现实世界中的一个区域，这个区域可以是一个平面，也可以是一个立体的物体。用户通过空间小程序来获取空间的信息，比如空间的大小、空间的位置、空间的旋转角度等等，而在一般的 AR 应用开发中，我们都会使用一个场景来承载空间。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/30/30ce0dc6d7cf1829e83e7543edb9fe6c.png\" /></p><p></p><p>来自 Wolvic 技术文档</p><p></p><p>如上图，来自 Wolvic 的技术文档，它描述了一个浏览器在空间中的设计，可以看到浏览器之前的 Tab 现在变为了一系列环绕在用户周围的虚拟屏幕（网页），这样用户只需要通过转头即可切换要浏览的网页或应用，而功能菜单则位于虚拟屏幕的上下，可以通过手柄或者手势进行交互。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a4/a47e48755ddfdf12a7e6606269c483d6.png\" /></p><p></p><p>来自 YodaOS-Master 系统真机录制</p><p></p><p>而 YodaOS Master 系统也有同样的设计，用户可以在系统中打开不同的窗口，每个窗口对应一个网页或者安卓应用，用户通过手势或射线来与窗口和功能菜单进行交互。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e5/e51d7e2534861631c56eb2b32a62869c.png\" /></p><p></p><p>来自 Wolvic 技术文档</p><p></p><p>用户空间描述起来就如同上图一样：用户位于空间的中心，围绕着用户的是一个圆柱曲面，用户可以将曲面中的一部分作为一块虚拟屏幕用于显示一个网页或应用，用户通过转头来切换要使用的应用。</p><p></p><p></p><h2>空间小程序</h2><p></p><p></p><p>读者熟知的小程序一般是微信小程序，开发者通过开发小程序可以在用户无需下载应用的情况下，在微信中使用一些即开即用的功能，比如：点外卖、酒店预定、网约车等。</p><p></p><p>那空间小程序是什么呢？先来看一个演示视频：</p><p></p><p></p><blockquote><a href=\"https://ar.rokidcdn.com/web-assets/pages/yodaos-jsar-demo.mp4%EF%BC%88%E8%BF%99%E9%87%8C%E6%98%AF%E8%A7%86%E9%A2%91%EF%BC%89\">https://ar.rokidcdn.com/web-assets/pages/yodaos-jsar-demo.mp4（这里是视频）</a>\"</blockquote><p></p><p></p><p>可以看到除了在上一小节中看到的屏幕外，还在空间中有一些可交互的 3D 物体，这就是空间小程序。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b3/b3e92b49547a3e6ec05d6b9e348e420f.png\" /></p><p></p><p>因此，空间小程序就是在原有的空间中，在屏幕之外添加一些可交互的 3D 物体，并且每个可交互物体之间是独立运行的。这就需要空间小程序具备以下特性：</p><p></p><p>安全性从平面到立体从窗口到空间</p><p></p><h2>为什么选择 Web</h2><p></p><p></p><p>单从空间小程序的技术实现来说，并不一定要选择 Web，像 Lua、Python 或是其他脚本语言都可以完成，这次除了我自己对于 Web 的一腔热血外，也需要一些特别的技术优势。</p><p></p><p>Web 技术从 1993 年 HTML 1.0 发布以来，从原来的文档分享，到信息站点，再到现在的 Web 应用，我们可以抽取到大家愿意使用 Web 技术的特点就是安全性和便捷性，而这两者相辅相成、互相成就。</p><p></p><p>因此 YodaOS JSAR 希望基于安全性和便捷性设计的空间应用框架，以此来让开发者和用户可以在独立的空间应用之外，可以做一些简单、有趣、便捷的“空间小程序”，它可以很容易被分享（当然安全性是前提）和传播。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/8b/8b1ce4c107a2eb19622097821abb258a.png\" /></p><p></p><p></p><h2>新三剑客</h2><p></p><p></p><p>在空间计算时代，YodaOS JSAR 给出了 Web 的新解决方案，即新的三件套 —— XSML、SCSS 和 TypeScript。</p><p></p><p></p><h3>XSML</h3><p></p><p></p><p>它对应于 HTML，全称是 eXtensible Spatial Markup Language，即可拓展空间标记语言。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5d/5d854159bc0d591dac1fcd8e20b7ae76.png\" /></p><p></p><p>XSML 代码示例</p><p></p><p>上图是 XSML 的代码示例，熟悉 HTML 的开发者一定不陌生，几乎和今天的 HTML 类似，区别仅在于一些标签的差异，比如：</p><p></p><p> 变成了  变成了 </p><p></p><p>以下便是一些 YodaOS JSAR 新增的标签：</p><p></p><p>引用 3D 模型创建一个立方体创建一个平面创建一个球体创建一个胶囊形状创建一个圆环创建一个 3D 包围盒，类似于</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a7/a7bbe330297f7c748a2d0821039fbdbe.png\" /></p><p></p><p>上图的狮子就是通过 XSML 描述生成的：</p><p></p><p>源代码：<a href=\"https://github.com/M-CreativeLab/jsar-gallery-flatten-lion/blob/main/lib/lion.xsml\">https://github.com/M-CreativeLab/jsar-gallery-flatten-lion/blob/main/lib/lion.xsml</a>\"在线演示：<a href=\"https://jsar.netlify.app/playground?url=https://raw.githubusercontent.com/M-CreativeLab/jsar-gallery-flatten-lion/main/lib/lion.xsml\">https://jsar.netlify.app/playground?url=https://raw.githubusercontent.com/M-CreativeLab/jsar-gallery-flatten-lion/main/lib/lion.xsml</a>\" （请确保你本地可以访问 raw.githubusercontent.com 域名）</p><p></p><p></p><blockquote>如需了解完整的 XSML 说明，可访问：<a href=\"https://jsar.netlify.app/zh-CN/manual/latest/basic-concepts/intro-xsml\">https://jsar.netlify.app/zh-CN/manual/latest/basic-concepts/intro-xsml</a>\"</blockquote><p></p><p></p><p></p><h3>SCSS</h3><p></p><p></p><p>它对应于 CSS，全称是 Spatial Cascading Style Sheet，即空间层叠样式表。SCSS 语法完全继承自 CSS，使用方式也相同：</p><p></p><p>通过选择器选择对应的元素设置样式</p><p></p><p>比如：</p><p></p><p><code lang=\"css\">@material red {\n  diffuse-color: #ff2200;\n}\n\n#box {\n  rotation: 0 0 180;\n  position: 0 1 0;\n  material: \"red\";\n}\n</code></p><p></p><p>可以看到现在设置的不再是原来 CSS 的样式，而是面向 3D 空间设计的旋转、位置和材质等。通过 SCSS 可以非常容易和自然的布局空间样式，相较于脚本的方式更直观。</p><p></p><p></p><blockquote>如需了解完整的 SCSS 说明，可访问：<a href=\"https://jsar.netlify.app/zh-CN/manual/latest/basic-concepts/intro-scss\">https://jsar.netlify.app/zh-CN/manual/latest/basic-concepts/intro-scss</a>\"</blockquote><p></p><p></p><p></p><h3>TypeScript</h3><p></p><p></p><p>随着 Deno 和 Bun 这样的服务端运行时都默认支持了 TypeScript，YodaOS JSAR 也选择了 TypeScript 作为原生的支持语言，它在运行时内置了一个 TypeScript 编译器，在解释&nbsp;</p>",
    "publish_time": "2023-10-31 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Java近期新闻：外部函数和内存API、OpenJDK JEP、Apache Tomcat CVE",
    "url": "https://www.infoq.cn/article/gxV6VXEQ1tV41E0k6vRb",
    "summary": "<p></p><h4>OpenJDK</h4><p></p><p>&nbsp;</p><p>在结束了评审之后，JEP 454（外部函数和内存API）从Proposed to Target<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-October/008357.html\">进入</a>\"到了Targeted（JDK 22）状态。该JEP建议在经历了两轮孵化和三轮预览之后确定这个特性：在JDK 17中交付的JEP 412（<a href=\"https://openjdk.org/jeps/412\">外部函数和内存API(孵化器)</a>\"）、在 JDK 18中交付的JEP 419（<a href=\"https://openjdk.org/jeps/419\">外部函数和内存API(第二轮孵化器)</a>\"）、在 JDK 19中交付的JEP 424（<a href=\"https://openjdk.org/jeps/424\">外部函数和内存API(预览)</a>\"）、在 JDK 20中交付的JEP 434（<a href=\"https://openjdk.org/jeps/434\">外部函数和内存API(第二次预览)</a>\"），以及在JDK 21 GA版本中交付的JEP 442（<a href=\"https://openjdk.org/jeps/442\">外部函数和内存API(第三次预览)</a>\"）。自上一个版本以来的改进包括：新的Enable-Native-Access manifest属性，允许可执行JAR包中的代码调用受限制的方法而无需使用——Enable-Native-Access标志；允许客户端通过编程的方式构建C函数描述符，避免使用特定于平台的常量；改进了对本地内存中可变长度数组的支持；支持多字符集本地字符串。InfoQ将会继续跟进报道。</p><p>&nbsp;</p><p>JEP 460（<a href=\"https://openjdk.org/jeps/460\">Vector API(第七轮孵化器)</a>\"）已从JEP Draft 8315945进入到Candidate状态。这个JEP整合了针对前六轮孵化的增强：在JDK 21 GA版本中交付的JEP 448（ <a href=\"https://openjdk.org/jeps/448\">Vector API (第六轮孵化器)</a>\"）在JDK 20中交付的JEP 438（<a href=\"https://openjdk.org/jeps/438\">Vector API (第五轮孵化器)</a>\"）、在JDK 19中交付的JEP 426（<a href=\"https://openjdk.org/jeps/426\">Vector API (第四轮孵化器)</a>\"、在JDK 18中交付的JEP 417（<a href=\"https://openjdk.java.net/jeps/417\">Vector API (第三轮孵化器)</a>\"、在JDK 17中交付的JEP 414（<a href=\"https://openjdk.java.net/jeps/414\">Vector API (第二轮孵化器)</a>\"）、在JDK 16中作为<a href=\"https://openjdk.java.net/jeps/11\">孵化器模块</a>\"发布的JEP 338（<a href=\"https://openjdk.java.net/jeps/338\">Vector API (孵化器)</a>\"）。JEP 448最重要的变化包括对<a href=\"https://docs.oracle.com/en/graalvm/enterprise/20/docs/reference-manual/compiler/#graalvm-compiler\">JVM编译器接口</a>\" (JVMCI)的增强，以支持Vector API的值。</p><p>&nbsp;</p><p>JEP Draft 8315398（<a href=\"https://openjdk.org/jeps/8315398\">隐式声明类和实例主方法(第二次预览)</a>\"），即之前的未命名类和实例主方法(预览)、灵活主方法和匿名主类(预览)和隐式类和增强的主方法(预览)，根据前一轮<a href=\"https://openjdk.java.net/jeps/12\">预览</a>\"，即JEP 445（<a href=\"https://openjdk.org/jeps/445\">未命名类和实例主方法(预览)</a>\"）的反馈进行了增强。这个JEP建议“让学生可以在不需要理解太多语言特性的前提下编写他们的第一个程序。”2022年9月，Oracle的Java语言架构师<a href=\"https://www.linkedin.com/in/briangoetz/\">Brian Goetz</a>\"为此撰写了<a href=\"https://openjdk.org/projects/amber/design-notes/on-ramp\">“Paving the on-ramp”</a>\"一文。Oracle技术委员会成员<a href=\"https://www.linkedin.com/in/gavin-bierman-a0173075/\">Gavin Bierman</a>\"已<a href=\"https://mail.openjdk.org/pipermail/amber-dev/2023-May/008065.html\">发布</a>\"<a href=\"https://cr.openjdk.org/~gbierman/jep445/jep445-20230502/specs/unnamed-classes-instance-main-methods-jls.html\">规范文档</a>\"初稿，供Java社区评审。关于JEP 445的更多细节可以在InfoQ的其他<a href=\"https://www.infoq.com/news/2023/05/beginner-friendly-java/\">报道</a>\"中找到。</p><p>&nbsp;</p><p>Oracle技术委员会成员<a href=\"https://www.linkedin.com/in/gavin-bierman-a0173075/\">Gavin Bierman</a>\"对JEP 447（<a href=\"https://openjdk.org/jeps/447\">super()的前置语句(预览)</a>\"）的<a href=\"https://cr.openjdk.org/~gbierman/jep447/jep447-20230927/specs/statements-before-super-jls.html\">规范文档</a>\"进行了<a href=\"https://mail.openjdk.org/pipermail/amber-spec-observers/2023-October/004127.html\">更新</a>\"。JEP 447提议允许在构造函数的this()或super()之前出现不引用正在创建的实例的语句，并保留构造函数现有的安全性和初始化保证。</p><p>&nbsp;</p><p></p><h4>JDK 22</h4><p></p><p>&nbsp;</p><p>JDK 22<a href=\"https://jdk.java.net/22/\">早期访问构建版本</a>\"的<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-22%2B19\">Build 19</a>\"提供了针对Build 18的<a href=\"https://github.com/openjdk/jdk/compare/jdk-22%2B18...jdk-22%2B19\">更新</a>\"，其中包括对各种<a href=\"https://bugs.openjdk.org/issues/?jql=project%20%3D%20JDK%20AND%20fixversion%20%3D%2022%20and%20%22resolved%20in%20build%22%20%3D%20b19%20order%20by%20component%2C%20subcomponent\">问题</a>\"的修复。关于该构建版本的更多细节可以在<a href=\"https://jdk.java.net/22/release-notes\">版本说明</a>\"中找到。</p><p>&nbsp;</p><p>对于<a href=\"https://openjdk.org/projects/jdk/22/\">JDK 22</a>\"，开发人员可以向<a href=\"https://bugreport.java.com/bugreport/\">Java Bug Database</a>\"报告错误。</p><p>&nbsp;</p><p></p><h4>Spring Framework</h4><p></p><p>&nbsp;</p><p><a href=\"https://spring.io/projects/spring-framework\">Spring Framework</a>\" 6.1.0的<a href=\"https://spring.io/blog/2023/10/12/spring-framework-6-1-rc1-released\">第一个候选发行版</a>\"包含了一些问题修复、文档改进、依赖项升级和新特性，例如：为改进对CRaC的支持，将<a href=\"https://docs.spring.io/spring-framework/docs/6.1.0-RC1/javadoc-api/org/springframework/http/client/reactive/ReactorResourceFactory.html\">`ReactorResourceFactory`</a>\"类从org.springframework.http.client包移到了 org.springframework.http.client包中；允许为<a href=\"https://docs.spring.io/spring-framework/docs/6.1.0-RC1/javadoc-api/org/springframework/web/client/RestClient.html\">`RestClient`</a>\"接口实现<a href=\"https://docs.spring.io/spring-framework/docs/6.1.0-RC1/javadoc-api/org/springframework/http/client/observation/ClientRequestObservationConvention.html\">`ClientRequestObservationConvention`</a>\"接口；在<a href=\"https://docs.spring.io/spring-framework/docs/6.1.0-RC1/javadoc-api/org/springframework/context/event/ApplicationListenerMethodAdapter.html\">`ApplicationListenerMethodAdapter`</a>\"类中公开shouldHandle(ApplicationEvent)方法，用于检查监听器是否对某个事件感兴趣。关于该版本的更多细节可以在<a href=\"https://github.com/spring-projects/spring-framework/releases/tag/v6.1.0-RC1\">版本说明</a>\"中找到。</p><p>&nbsp;</p><p>类似的，Spring Framework 6.0.13已<a href=\"https://spring.io/blog/2023/10/12/spring-framework-6-0-13-available-now\">发布</a>\"，其中包含了问题修复、文档改进、依赖项升级和新特性，如：改进了针对<a href=\"https://docs.spring.io/spring-framework/reference/core/expressions.html\">Spring表达式语言</a>\"中因重复文本大小计算而导致的溢出的诊断；为注解了<a href=\"https://docs.spring.io/spring-framework/docs/6.1.0-RC1/javadoc-api/org/springframework/context/annotation/Configuration.html\">`@Configuration`</a>\" 的CGLIB代理类重新引入<a href=\"https://docs.spring.io/spring-framework/docs/6.1.0-RC1/javadoc-api/org/springframework/cglib/reflect/FastClass.html\">`FastClass`</a>\" 类。关于该版本的更多细节可以在<a href=\"https://github.com/spring-projects/spring-framework/releases/tag/v6.0.13\">版本说明</a>\"中找到。</p><p>&nbsp;</p><p><a href=\"https://spring.io/projects/spring-data\">Spring Data</a>\" 2023.1.0<a href=\"https://spring.io/blog/2023/10/13/spring-data-2023-1-goes-rc1\">第一个候选版本</a>\"（代号为Vaughn）的特新包括：支持JDK 21；通过配置Java<a href=\"https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/concurrent/Executor.html\">`Executor`</a>\" 接口来使用虚拟线程；支持Kotlin<a href=\"https://kotlinlang.org/docs/inline-classes.html\">值类</a>\"；对CRaC优化进行了初步探索；文档迁移到了<a href=\"https://docs.antora.org/antora/latest/\">Antora</a>\"。关于该版本的更多细节可以在<a href=\"https://github.com/spring-projects/spring-data-commons/wiki/Spring-Data-2023.1-%28Vaughan%29-Release-Notes\">版本说明</a>\"中找到。</p><p>&nbsp;</p><p>Spring Data各个<a href=\"https://spring.io/blog/2023/10/13/spring-data-2023-0-5-2022-0-11-and-2021-2-17-released\">服务版本</a>\"（2023.0.5、2022.0.11和2021.2.17）的依赖子项目升级包括：Spring Data Commons 3.1.5、3.0.11和2.7.17；Spring Data MongoDB 4.1.5、4.0.11和3.4.17；Spring Data Elasticsearch 5.1.5、5.0.11和4.4.17；Spring Data Neo4j 7.1.7、7.0.11和6.3.17。这些版本分别包含在即将发布的Spring Boot 3.1.5、3.0.12和2.7.17中。</p><p>&nbsp;</p><p><a href=\"https://spring.io/projects/spring-shell\">Spring Shell</a>\" 3.2.0<a href=\"https://spring.io/blog/2023/10/13/spring-shell-3-2-0-m2-is-now-available\">第二个里程碑版本</a>\"提供了实验性的新终端UI和其他值得注意的变化，如：新的<a href=\"https://github.com/spring-projects/spring-shell/blob/main/spring-shell-core/src/main/java/org/springframework/shell/component/view/control/ViewCommand.java\">`ViewCommand`</a>\"类，为<a href=\"https://github.com/spring-projects/spring-shell/blob/main/spring-shell-core/src/main/java/org/springframework/shell/component/view/control/View.java\">`View`</a>\"接口提供更高级别的指令；改进了<a href=\"https://github.com/spring-projects/spring-shell/blob/main/spring-shell-core/src/main/java/org/springframework/shell/component/view/control/ButtonView.java\">`ButtonView`</a>\"和<a href=\"https://github.com/spring-projects/spring-shell/blob/main/spring-shell-core/src/main/java/org/springframework/shell/component/view/control/DialogView.java\">`DialogView`</a>\"类的实现。关于该版本的更多细节，包括新终端UI的演示，可以在<a href=\"https://github.com/spring-projects/spring-shell/releases/tag/v3.2.0-M2\">版本说明</a>\"中找到。</p><p>&nbsp;</p><p></p><h4>Micronaut</h4><p></p><p>&nbsp;</p><p>Micronaut基金会<a href=\"https://micronaut.io/2023/10/10/micronaut-framework-4-1-4-released/\">发布</a>\"了<a href=\"https://micronaut.io/\">Micronaut框架</a>\"的4.1.4版本，包含<a href=\"https://github.com/micronaut-projects/micronaut-core/releases/v4.1.9\">Micronaut Core 4.1.9</a>\"和模块更新：<a href=\"https://micronaut-projects.github.io/micronaut-serialization/snapshot/guide/\">Micronaut Serialization</a>\"、 <a href=\"https://micronaut-projects.github.io/micronaut-aws/snapshot/guide/\">Micronaut AWS</a>\"、<a href=\"https://micronaut-projects.github.io/micronaut-email/snapshot/guide/\">Micronaut Email</a>\"、<a href=\"https://micronaut-projects.github.io/micronaut-data/snapshot/guide/\">Micronaut Data</a>\"、<a href=\"https://micronaut-projects.github.io/micronaut-maven-plugin/latest/\">Micronaut Maven Plugin</a>\"、<a href=\"https://micronaut-projects.github.io/micronaut-sql/snapshot/guide/\">Micronaut SQL Libraries</a>\"和<a href=\"https://micronaut-projects.github.io/micronaut-discovery-client/latest/guide/\">Micronaut Discovery Client</a>\"。关于该版本的更多细节可以在<a href=\"https://github.com/micronaut-projects/micronaut-platform/releases/tag/v4.1.4\">版本说明</a>\"中找到。</p><p>&nbsp;</p><p></p><h4>Quarkus</h4><p></p><p>&nbsp;</p><p>Red Hat<a href=\"https://quarkus.io/blog/quarkus-3-4-3-released/\">发布</a>\"了<a href=\"https://quarkus.io/\">Quarkus</a>\"的3.4.3版本，主要解决了<a href=\"https://nvd.nist.gov/vuln/detail/CVE-2023-44487\">CVE-2023-44487</a>\"，一个与Tomcat HTTP/2实现有关的问题，容易受到<a href=\"https://www.securityweek.com/rapid-reset-zero-day-exploited-to-launch-largest-ddos-attacks-in-history/\">快速重置攻击</a>\"，进而出现<a href=\"https://www.mail-archive.com/announce@apache.org/msg08557.html\">拒绝服务</a>\"，通常表现为OutOfMemoryError。除此之外，还有文档方面的改进和一些值得注意的修复，如：调用响应式REST客户端被挂起（因接收到导致资源无法被释放的无效块响应）；被转换为原生构建的Quarkus应用程序（使用了Picocli和JAX-RS）消费SSE时抛出ClassNotFoundException；允许MicroProfile<a href=\"https://github.com/eclipse/microprofile-rest-client/blob/main/api/src/main/java/org/eclipse/microprofile/rest/client/annotation/ClientHeaderParam.java\">`@ClientHeaderParam`</a>\"注解覆盖“User-Agent”标头参数。关于此版本的更多细节可以在<a href=\"https://github.com/quarkusio/quarkus/releases/tag/3.4.3\">changelog</a>\"中找到。</p><p>&nbsp;</p><p></p><h4>Micrometer</h4><p></p><p>&nbsp;</p><p><a href=\"https://github.com/micrometer-metrics/micrometer/blob/main/README.md\">Micrometer Metrics</a>\"1.12.0-RC1、1.11.5、1.10.12和1.9.16分别带来了依赖项升级和错误修复：在运行Spring Boot应用程序时<a href=\"https://github.com/micrometer-metrics/micrometer/blob/main/micrometer-observation/src/main/java/io/micrometer/observation/ObservationRegistry.java\">`ObservationRegistry.NOOP`</a>\"接口的实例为空；调用定义在<a href=\"https://github.com/micrometer-metrics/micrometer/blob/main/micrometer-observation/src/main/java/io/micrometer/observation/Observation.java\">`Observation`</a>\" 接口内部类Context的computeIfAbsent()方法时抛出<a href=\"https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/ConcurrentModificationException.html\">`ConcurrentModificationException`</a>\" 。版本1.12.0-RC1中的新特性包括：将Jakarta Messaging规范的增强移到新模块micrometer-jakarta9；<a href=\"https://www.vmware.com/products/aria-operations-for-applications.html\">Wavefront</a>\"集成支持VMware <a href=\"https://docs.vmware.com/en/VMware-Cloud-services/index.html\">CSP</a>\"认证系统。关于这些版本的更多细节可以在<a href=\"https://github.com/micrometer-metrics/micrometer/releases/tag/v1.12.0-RC1\">1.12.0-RC1</a>\"、<a href=\"https://github.com/micrometer-metrics/micrometer/releases/tag/v1.11.5\">1.11.5</a>\"、<a href=\"https://github.com/micrometer-metrics/micrometer/releases/tag/v1.10.12\">1.10.12</a>\"和<a href=\"https://github.com/micrometer-metrics/micrometer/releases/tag/v1.9.16\">1.9.16</a>\"的版本说明中找到。</p><p>&nbsp;</p><p>类似的，<a href=\"https://github.com/micrometer-metrics/tracing/blob/main/README.md\">Micrometer Tracing</a>\"的1.2.0-RC1、1.1.6和1.0.11版本也包含了依赖项升级和错误修复，如：在Gradle构建中应用更广泛的<a href=\"https://github.com/openzipkin/zipkin-reporter-java/blob/master/README.md\">Zipkin Reporter</a>\"来解决依赖问题；在<a href=\"https://github.com/micrometer-metrics/tracing/blob/main/micrometer-tracing/src/main/java/io/micrometer/tracing/contextpropagation/ObservationAwareSpanThreadLocalAccessor.java\">`ObservationAwareSpanThreadLocalAccessor`</a>\"类中设置了作用域时可以进行覆盖。1.2.0-RC1版本的新特性包括：为改进框架的配置，在匹配<a href=\"https://github.com/micrometer-metrics/micrometer/blob/main/micrometer-core/src/main/java/io/micrometer/core/aop/TimedAspect.java\">`TimeAspect`</a>\"类时将<a href=\"https://github.com/micrometer-metrics/tracing/blob/main/micrometer-tracing/src/main/java/io/micrometer/tracing/annotation/SpanTagAnnotationHandler.java\">`SpanTagAnnotationHandler`</a>\"类定义为可选的；io.opentelemetry:opentelemetry-semconv改为io.opentelemetry.semconv:opentelemetry-semconv，因为OpenTelemetry已经弃用了旧的<a href=\"https://opentelemetry.io/docs/concepts/semantic-conventions/\">语义约定</a>\"模块，使用了一个具有不同Maven坐标的新模块。关于这些版本的更多细节可以在<a href=\"https://github.com/micrometer-metrics/tracing/releases/tag/v1.2.0-RC1\">1.2.0-RC1</a>\"、<a href=\"https://github.com/micrometer-metrics/tracing/releases/tag/v1.1.6\">1.1.6</a>\"和<a href=\"https://github.com/micrometer-metrics/tracing/releases/tag/v1.0.11\">1.0.11</a>\"的版本说明中找到。</p><p>&nbsp;</p><p></p><h4>Apache软件基金会</h4><p></p><p>&nbsp;</p><p><a href=\"https://tomcat.apache.org/\">Apache Tomcat</a>\"团队披露了四个影响版本11.0.0-M1至11.0.0-M11、10.1.0-M1至10.1.13、9.0.0-M1至9.0.80和8.5.0至8.5.93的CVE。</p><p>&nbsp;</p><p><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2023-42795\">CVE-2023-42795</a>\"，在回收各种内部对象（包括请求和响应）时出现的信息暴露问题，即一些错误可能导致Tomcat跳过回收过程的某些部分，旧对象在被下一个请求/响应重用之前发生<a href=\"https://www.mail-archive.com/announce@apache.org/msg08559.html\">信息泄漏</a>\"。<a href=\"https://nvd.nist.gov/vuln/detail/CVE-2023-45648\">CVE-2023-45648</a>\"，攻击者在反向代理后面通过发送特制的无效标头促使Tomcat将单个请求视为多个请求，从而导致<a href=\"https://www.mail-archive.com/announce@apache.org/msg08558.html\">请求夹带</a>\"。之前提到的<a href=\"https://nvd.nist.gov/vuln/detail/CVE-2023-44487\">CVE-2023-44487</a>\"。<a href=\"https://nvd.nist.gov/vuln/detail/CVE-2023-42794\">CVE-2023-42794</a>\"，<a href=\"https://commons.apache.org/proper/commons-fileupload/\">Commons FileUpload</a>\"包的Tomcat内部分支包含了一个未发布的针对Windows的重构，如果一个Web应用程序为上传的文件打开了一个流，但未能关闭流就会出现该漏洞。由于磁盘已满，该文件将永远不会从磁盘上删除，从而可能导致<a href=\"https://www.mail-archive.com/announce@apache.org/msg08556.html\">拒绝服务</a>\"。该CVE仅影响Tomcat 9.0.70至9.0.80和8.5.85至8.5.93。</p><p>&nbsp;</p><p>这些受影响版本的用户需要采取以下缓解措施之一：至少升级到Apache Tomcat的版本<a href=\"https://www.mail-archive.com/announce@apache.org/msg08554.html\">11.0.0-M12</a>\"、<a href=\"https://www.mail-archive.com/announce@apache.org/msg08552.html\">10.1.14</a>\"、<a href=\"https://www.mail-archive.com/announce@apache.org/msg08555.html\">9.0.81</a>\"和<a href=\"https://www.mail-archive.com/announce@apache.org/msg08553.html\">8.5.94</a>\"。</p><p>&nbsp;</p><p><a href=\"https://kafka.apache.org/\">Apache Kafka</a>\" 3.6.0<a href=\"https://www.mail-archive.com/announce@apache.org/msg08561.html\">版本</a>\"包含了错误修复、改进和新功能，例如：支持<a href=\"https://developer.confluent.io/learn/kraft/\">Kafka Raft</a>\" (KRaft)的委托令牌；将Kafka集群从ZooKeeper元数据系统迁移到KRaft元数据系统的能力；将<a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage\">分级存储</a>\"作为早期访问功能。关于该版本的更多细节可以在<a href=\"https://downloads.apache.org/kafka/3.6.0/RELEASE_NOTES.html\">版本说明</a>\"中找到。</p><p>&nbsp;</p><p><a href=\"https://camel.apache.org/\">Apache Camel</a>\" 4.1.0<a href=\"https://www.mail-archive.com/announce@apache.org/msg08563.html\">版本</a>\"包含了错误修复、依赖项升级和新特性，如：捕获启动事件并按照人类可读的格式报告时间；新的<a href=\"https://camel.apache.org/components/next/thymeleaf-component.html\">Camel Thymeleaf</a>\"模板组件，作为对现有<a href=\"https://camel.apache.org/components/4.0.x/freemarker-component.html\">Camel Freemarker</a>\"和<a href=\"https://camel.apache.org/components/4.0.x/velocity-component.html\">Camel Velocity</a>\"组件的补充；一个新的命令，按照<a href=\"https://cyclonedx.org/\">CycloneDX</a>\"格式为给定的JBang项目生成SBOM。关于该版本的更多细节可以在<a href=\"https://camel.apache.org/releases/release-4.1.0/\">版本说明</a>\"中找到。</p><p>&nbsp;</p><p></p><h4>Eclipse Vert.x</h4><p></p><p>&nbsp;</p><p>Eclipse <a href=\"https://vertx.io/\">Vert.x</a>\" 4.4.6<a href=\"https://vertx.io/blog/eclipse-vert-x-4-4-6/\">版本</a>\"包含了依赖项升级和一些值得注意的变更，如：升级到<a href=\"https://netty.io/news/2023/10/10/4-1-100-Final.html\">Netty 4.1.100.Final</a>\"，解决了上述的CVE-2023-44487；修复<a href=\"https://github.com/eclipse-vertx/vertx-sql-client/blob/master/vertx-pg-client/src/main/java/io/vertx/pgclient/data/Money.java\">`Money`</a>\" 类，弃用Money(long,int)构造函数，转而使用Money(Number)；不再支持curl命令中的空Host标头，这个空标头会抛出NullPointerException。关于该版本的更多细节可以在<a href=\"https://github.com/vert-x3/wiki/wiki/4.4.6-Release-Notes\">版本说明</a>\"和<a href=\"https://github.com/vert-x3/wiki/wiki/4.4.6-Deprecations-and-breaking-changes\">弃用和重大变更说明</a>\"中找到。</p><p>&nbsp;</p><p></p><h4>Reactor</h4><p></p><p>&nbsp;</p><p><a href=\"https://github.com/reactor/reactor/blob/main/README.md\">Reactor</a>\" 2023.0.0的<a href=\"https://github.com/reactor/reactor/releases/tag/2023.0.0-RC1\">第一个候选版本</a>\"包含对reactor-core 3.6.0-RC1、reactor-pool 1.0.3和reactor-netty 1.1.12的依赖项升级。2023.0.0-RC1版本也进行了调整，其中reactor-kafka 1.3.21、 reactor-addons 3.5.1和reactor-kotlin-extensions 1.2.2保持不变。关于该版本的更多细节可以在<a href=\"https://github.com/reactor/reactor/compare/2023.0.0-M3...2023.0.0-RC1\">变更日志</a>\"中找到。</p><p>&nbsp;</p><p>类似的，Reactor 2022.0.12，<a href=\"https://github.com/reactor/reactor/releases/tag/2022.0.12\">第十二个维护版本</a>\"包含了对reactor-core 3.5.11、reactor-netty 1.1.12和reactor-pool 1.0.3的依赖项升级。2022.0.11版本也进行了调整，其中reactor-kafka 1.3.21、reactor-addons 3.5.1和reactor-kotlin-extensions 1.2.2保持不变。关于该版本的更多细节可以在<a href=\"https://github.com/reactor/reactor/compare/2022.0.11...2022.0.12\">变更日志</a>\"中找到。</p><p>&nbsp;</p><p></p><h4>JHipster Lite</h4><p></p><p>&nbsp;</p><p><a href=\"https://www.jhipster.tech/jhipster-lite/\">JHipster Lite</a>\"0.44.0版本已经<a href=\"https://twitter.com/pascalgrimaud/status/1711764842917281880\">发布</a>\"，其中包含问题修复、依赖项升级和新功能（增强），如：在JDK 21的某些构建版本中启用；修复了在<a href=\"https://github.com/jhipster/jhipster-lite/blob/main/src/main/resources/generator/server/springboot/broker/kafka/KafkaPropertiesTest.java.mustache\">`KafkaPropertiesTest`</a>\" 类中使用Java <a href=\"https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/HashMap.html\">`HashMap`</a>\"类的问题；为改善导航体验，在横向屏幕上显示小地图。关于该版本的更多细节可以在<a href=\"https://github.com/jhipster/jhipster-lite/releases/tag/v0.44.0\">版本说明</a>\"中找到。</p><p>&nbsp;</p><p></p><h4>Piranha</h4><p></p><p>&nbsp;</p><p><a href=\"https://piranha.cloud/\">Piranha</a>\" 23.10.0<a href=\"https://github.com/piranhacloud/piranha/releases/tag/v23.10.0\">版本</a>\"包含了一些显著变化，如：依赖项和插件升级；修复了<a href=\"https://github.com/piranhacloud/piranha/blob/current/arquillian/jarcontainer/src/main/java/cloud/piranha/arquillian/jarcontainer/PiranhaJarContainer.java\">`PiranhaJarContainer`</a>\" 类中的代码坏味道；修复漏洞、技术债务、安全和可靠性问题。关于该版本的更多细节可以在其官方<a href=\"https://javadoc.io/doc/cloud.piranha/project/latest/index.html\">文档</a>\"和<a href=\"https://github.com/piranhacloud/piranha/issues?q=is%3Aissue+-label%3Awontfix+milestone%3A23.10.0+is%3Aclosed\">问题跟踪器</a>\"中找到。</p><p>&nbsp;</p><p></p><h4>RefactorFirst</h4><p></p><p>&nbsp;</p><p><a href=\"https://improving.com/\">Improving</a>\"（一家提供培训、咨询、招聘和项目服务的公司）首席软件咨询顾问<a href=\"https://www.linkedin.com/in/jimbethancourt/\">Jim Bethancourt</a>\"宣布发布<a href=\"https://github.com/jimbethancourt/RefactorFirst/blob/main/README.md\">RefactorFirst</a>\" 0.5.0-M1。该版本包含了许多依赖项升级和新特性，如：新的RefactorFirst命令行；将HTML、CSV和JSON报告重构成各自的模块。值得注意的是，RefactorFirst现在需要JDK 11来解决<a href=\"https://nvd.nist.gov/vuln/detail/CVE-2023-4759\">CVE-2023-4759</a>\"，这是<a href=\"https://www.eclipse.org/jgit/\">JGit</a>\" 6.6.0以下版本存在的一个漏洞，攻击者可以使用特制git存储库中的符号链接将文件写入工作树之外的位置。因此，该项目也被移到GitHub上新创建的RefactorFirst目录中。关于该版本的更多细节可以在<a href=\"https://github.com/refactorfirst/RefactorFirst/releases/tag/0.5.0-M1\">版本说明</a>\"中找到。</p><p>&nbsp;</p><p></p><h4>摩洛哥Devoxx大会</h4><p></p><p>&nbsp;</p><p><a href=\"https://devoxx.ma/\">摩洛哥Devoxx大会</a>\"在<a href=\"https://www.hilton.com/en/hotels/agatmhi-hilton-taghazout-bay-beach-resort-and-spa/\">Hilton Taghazout Bay Beach Resort &amp; Spa</a>\"举办，来自Java社区的<a href=\"https://devoxx.ma/speakers/\">演讲者</a>\"发表了<a href=\"https://devoxx.ma/talks-by-tracks/\">主题</a>\"演讲，包括：架构、数据与人工智能、开发实践、DevOps与云计算，以及安全。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/10/java-news-roundup-oct09-2023/\">https://www.infoq.com/news/2023/10/java-news-roundup-oct09-2023/</a>\"</p>",
    "publish_time": "2023-10-31 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "平安银行金融科技部数据资产管理及研发中心数据及 AI 团队负责人廖晓格确认出席 FCon，分享金融级数据研发 DataOps 落地实践",
    "url": "https://www.infoq.cn/article/ip9mWGAGQoOSr6CX2Mvs",
    "summary": "<p><a href=\"https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle\">FCon 全球金融科技大会</a>\"，将于 11 月在上海召开。平安银行金融科技部数据资产管理及研发中心数据及 AI 团队负责人廖晓格将发表题为《<a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5596?utm_source=infoqweb&amp;utm_medium=atricle\">金融级数据研发 DataOps 落地实践</a>\"》主题分享，从数据研发全生命周期管理角度出发，介绍如何解决安全、提效、降本等方面的行动，以及一些已有的成效，给出一些已有的成效借鉴。</p><p></p><p><a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5596?utm_source=infoqweb&amp;utm_medium=atricle\">廖晓格</a>\"，平安银行数据资产管理及研发中心 / 数据及 AI 平台团队负责人，大数据及 AI 领域资深专家，十多年大数据及 AI 平台研发经验，曾在 PPTV、eBay、携程、华为负责大数据平台研发及优化工作，开源领域爱好者、熟悉 Hadoop 生态、Kubernetes 开源生态和架构设计、精通大数据相关组件技术，承担大数据基础平台、数据中台及 AI 平台建设等重要项目。他在本次会议的演讲内容如下：</p><p></p><p>演讲：金融级数据研发 DataOps 落地实践</p><p></p><p>金融数据体系极其复杂，内部关系错综复杂，伴随业务数据越来越多、数据全民意识越来越强，体系化的数据治理已成为不得不交的作业；而现实告诉我们，面对难找、难理解、不敢用、用不起的海量数据，传统的治理措施面临难以落地、落地效果不佳、效果难以量化等困局。海量敏感数据、质量管理、监控和告警等治理，以及数字化转型过程中稳定高效的对外高质量的提供数据服务，都成为了关键问题。</p><p></p><p>构建金融级数据研发 DataOps 一体化平台将会是一个破局点，将数据治理体系落地到研发流程中，保证数据价值最大化，降低数据应用成本，结合 DMMA 方法论与工具，让治理工作潜移默化到每个数据研发工作成员的日常工作流程中。始终以业务价值最大化为目标，对数据研发全生命周期进行管理，更好的服务业务需求，并且能将全行核心数据资产沉淀到平台上。</p><p></p><p>本次分享将从数据研发全生命周期管理角度，从数据采集、数据建模、数据加工、数据测试、数据发布、数据应用等阶段出发，来达到沉淀金融核心数据资产，介绍整体 DataOps 架构设计，介绍如何解决安全、提效、降本等方面的行动，以及一些已有的成效，给出与会者一些已有的成效借鉴。</p><p></p><p>演讲提纲：</p><p></p><p>金融数据的问题与挑战金融 DataOps 体系介绍</p><p>○ 数据研发全生命周期介绍</p><p>○ 指标研发</p><p>○ 数据应用</p><p>○ 数据治理及数据安全</p><p>未来展望</p><p></p><p>你将获得：</p><p></p><p>了解实现金融级数据研发 DataOps 落地经验，如何保护金融敏感数据安全，如何将数据治理方法论落地在数据研发全流程，如何实现流批一体，保证离在线数据口径一致，如何提升数据研发效率，降低数据使用门槛，降低数据成本。</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle\">DevOps&nbsp;在金融企业落地实践</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle\">金融行业大模型应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle\">创新的金融科技应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle\">金融实时数据平台建设之路</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle\">金融安全风险管控</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle\">数据要素流通与数据合规</a>\"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，享 8 折优惠 ，立省 ￥1360！咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png\" /></p><p></p>",
    "publish_time": "2023-10-31 11:39:07",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "阿里巴巴蔡崇信：打造AI时代最开放的云",
    "url": "https://www.infoq.cn/article/vhxShreOOrO3h2JbLHd1",
    "summary": "<p>&nbsp;</p><p>10月31日上午，2023云栖大会在杭州云栖小镇开幕。阿里巴巴集团董事会主席蔡崇信在开幕式上致辞，他表示，目前中国80%的科技企业、国内一半的大模型公司都跑在阿里云上。而阿里巴巴要打造“AI时代最开放的云”。</p><p>&nbsp;</p><p>蔡崇信表示，随着人工智能（AI）大模型技术的迅速发展，智能化时代正在开启，AI将成为各行各业的新型生产力，并对算力提出更高要求。从底层算力到AI平台再到模型服务，阿里巴巴加大研发投入，推动阿里云进行全面的技术升级和创新。“我们要打造AI时代最开放的云。”蔡崇信说道。</p><p>&nbsp;</p><p>云计算是数字经济乃至全社会重要的基础设施，据介绍，目前全国80%的科技企业和超过一半的AI大模型公司跑在阿里云上。10月闭幕的杭州亚运会核心系统100%跑在云上，成为首届“云上亚运”，创造了亚运历史。</p><p>&nbsp;</p><p>蔡崇信用几个“第一”概括了阿里云的历程与理念：“从2009年阿里云计算写下第一行代码开始，阿里巴巴就希望让计算成为像水和电一样的公共服务，成就更多开发者和企业。阿里巴巴是全球第一家把自身所有业务都搬上云的大型互联网公司。从PC时代到移动互联网时代，再到AI时代，阿里巴巴对‘客户第一’的坚守始终不变。”</p><p>&nbsp;</p><p>蔡崇信在致辞中强调最多的词是“开放”。蔡崇信说：“我们坚信，不开放就没有生态，没有生态就没有未来。同时，我们要始终攀登技术高峰，只有站在更先进、更稳定的技术能力之上，才有更大的开放底气。”</p><p>&nbsp;</p><p>据了解，去年的云栖大会上，阿里云发布了AI开源社区“魔搭”。短短一年时间，魔搭汇聚了280万开发者、2300多个优质模型，模型下载量超过1亿，成为中国规模最大、最活跃的AI开发者社区，为数字经济“以开放促发展”理念提供了一个鲜活案例。蔡崇信寄望通过这朵“AI时代最开放的云”，让开发AI、使用AI变得更加容易和便宜，帮助各行各业、特别是中小企业，把AI转化为巨大的生产力。</p>",
    "publish_time": "2023-10-31 11:55:18",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "首次采用3nm制程、比M1 Max快80%！苹果亮相M3芯片，最高搭载40核GPU",
    "url": "https://www.infoq.cn/article/BmDYQcg9gvzd9OIyjZrT",
    "summary": "<p>10月31日，以“Scary Fast（快得吓人）”为主题对苹果新品发布会如约而至。在此次发布会上，Apple 宣布推出全新MacBook Pro 系列，采用全新 M3 芯片系列：M3、M3 Pro 和 M3 Max。据悉，M3系列芯片采用3nm制程工艺，在CPU和GPU方面都有了重大改进。这三款3nm制程芯片能满足不同用户的需求。</p><p></p><h2>苹果亮相M3系列芯片：3nm制程工艺，最高搭载40核GPU</h2><p></p><p>&nbsp;</p><p>搭载M3 的全新 14 英寸 MacBook Pro 不仅能完成日常基本任务，而且在专业应用程序和游戏中也能提供良好的持续性能，现在起价为 1,599 美元；搭载M3 Pro 的 14 英寸和 16 英寸 MacBook Pro 提供更强大的性能和额外的统一内存支持，为开发者、设计人员和研究人员等用户提供更流畅的任务支持；&nbsp;搭载M3 Max 的 14 英寸和 16 英寸 MacBook Pro 提供突破计算极限的性能和功能。配备 M3 Max 的 MacBook Pro 配备强大的 GPU 和CPU，并支持高达 128GB 的​​统一内存，可为机器学习编程人员、3D 艺术家和视频编辑等用户提供跨专业应用程序的极端工作流程和多任务处理；</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/e6/e665affb2a1266e3e3d71325948de5e5.png\" /></p><p></p><p>M3 系列中的每个芯片都采用统一的内存架构，这是 Apple 芯片的标志。这可提供高带宽、低延迟的良好运行。在定制封装内拥有单个内存池意味着芯片中的所有技术都可以访问相同的数据，而无需在多个内存池之间进行复制，从而进一步提高性能和效率，并减少大多数系统所需的内存量的任务。此外，对高达 128GB 内存的支持解锁了以前在笔记本电脑上无法实现的工作流程，例如人工智能开发人员使用具有数十亿参数的更大变压器模型。</p><p>&nbsp;</p><p>据苹果介绍，基础版的M3包括一个8核CPU、10核GPU、4个性能核心、4个效率核心，支持24GB统一内存和一个外置显示器。M3还拥有 250 亿个晶体管——比 M2 多 50 亿个。它拥有采用下一代架构的 10 核 GPU，图形性能比 M1 快 65%。</p><p>&nbsp;</p><p>M3 Pro具有12核CPU、18核GPU、6个性能核心、6个效率核心，由 370 亿个晶体管组成，GPU 比 M1 Pro 快 40%。对统一内存的支持高达 36GB，使用户能够在外出时在 MacBook Pro 上处理更大的项目。苹果公司表示，M3 Pro单线程性能比 M1 Pro 提升高达 30%。</p><p>&nbsp;</p><p>M3 Max将晶体管数量推至 920 亿个，具有16核CPU、40核GPU、12个性能核心、4个效率核心。苹果公司表示，M3 Max&nbsp;GPU 的速度比 M1 Max 快 50%，并且支持高达 128GB 的​​统一内存，使 AI 开发人员能够使用具有数十亿参数的更大 Transformer 模型。16核CPU拥实现了比M1 Max快80%的性能。</p><p>&nbsp;</p><p>“Apple芯片彻底重新定义了 Mac 体验。其架构的每个方面都是为了性能和能效而设计的。”Apple 硬件技术高级副总裁 Johny Srouji 说道。“凭借 3 纳米技术、下一代 GPU 架构、更高性能的 CPU、更快的神经引擎以及对更统一内存的支持，M3、M3 Pro 和 M3 Max 是迄今为止为个人电脑打造的最先进的电脑芯片。”</p><p></p><h2>相比前两代芯片，M3芯片有哪些升级？</h2><p></p><p>在亮相最新款M3系列芯片之前，M系列芯片采用的是台积电公司的5纳米制程技术，但M3芯片升级采用了台积电最新的3纳米制程芯片技术。更小的节点尺寸对应更高的晶体管密度，有助于提升能效与性能。3纳米芯片将带来高达35%的能效提升，从而延长M系列Mac电脑的电池续航。</p><p>&nbsp;</p><p>苹果芯片代工伙伴台积电也是目前极少数一家能够制造3纳米芯片的厂商之一。有传闻称即便是台积电，目前其最新制程技术的良品率也刚刚超过55%。苹果转向3纳米，也标志着自2020年5纳米M1芯片问世以来进行的首次节点更新，带来了超越当初M2迭代的性能提升。</p><p>&nbsp;</p><p>M3 系列芯片中的下一代 GPU 代表了 Apple 芯片图形架构的最大飞跃。与传统 GPU 不同，它具有动态缓存功能，可以实时分配硬件中本地内存的使用。通过动态缓存，每个任务仅使用所需的确切内存量。</p><p>&nbsp;</p><p>据苹果透露，这项技术是业界首创，对开发人员透明，也是新 GPU 架构的基石。它显着提高了 GPU 的平均利用率，从而显著提高了对GPU要求最苛刻的专业应用程序和游戏的性能。</p><p>&nbsp;</p><p>借助 M3 系列芯片，硬件加速光线追踪首次出现在 Mac 上。光线追踪对光与场景交互时的属性进行建模，使应用程序能够创建极其逼真且物理精确的图像。再加上新的图形架构，专业应用程序的速度可达 M1 系列芯片的 2.5 倍。游戏开发人员可以使用光线追踪来获得更准确的阴影和反射，从而创建深度沉浸式环境。此外，新的 GPU 为 Mac 带来了硬件加速的网格着色，为几何处理提供了更强大的功能和效率，并在游戏和图形密集型应用程序中实现了视觉上更复杂的场景。这一创新的GPU架构实现了所有这些增强功能和功能。事实上，M3 GPU 能够以近一半的功耗提供与 M1 相同的性能，并且在峰值时性能提高高达 65%。</p><p>&nbsp;</p><p>相比于M2系列芯片，M3 也有着显著的提升。下面是两款芯片的规格比较：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a9/a9e0e1832bf44452370f6a91b5e0176d.jpeg\" /></p><p>此外，在此次发布会上，苹果还推出新款24英寸、搭载M3芯片的iMac，起售价10999元，将于下周上市。</p><p></p><p>参考链接：</p><p><a href=\"https://www.macrumors.com/guide/m3/\">https://www.macrumors.com/guide/m3/</a>\"</p><p><a href=\"https://www.apple.com/newsroom/2023/10/apple-unveils-m3-m3-pro-and-m3-max-the-most-advanced-chips-for-a-personal-computer/\">https://www.apple.com/newsroom/2023/10/apple-unveils-m3-m3-pro-and-m3-max-the-most-advanced-chips-for-a-personal-computer/</a>\"</p><p><a href=\"https://www.apple.com/newsroom/2023/10/apple-unveils-new-macbook-pro-featuring-m3-chips/\">https://www.apple.com/newsroom/2023/10/apple-unveils-new-macbook-pro-featuring-m3-chips/</a>\"</p>",
    "publish_time": "2023-10-31 13:38:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "中小银行如何构建智能风控体系？明确业务需求比盲目求新更重要",
    "url": "https://www.infoq.cn/article/a1uk0eGDAxBQN8F8AcFY",
    "summary": "<p>随着客户需求的演变以及金融机构与客户互动方式的刷新，传统的风控手段开始失效，<a href=\"https://www.infoq.cn/theme/200\">中小银行</a>\"的风控体系也必须相应做出迭代与升级。但和大型金融机构相比，中小银行在资源、人才、业务规模等方面都不具优势，在业务发展和推进数字化过程中，面临着一系列特有挑战。</p><p></p><p>在日前的《超级连麦·数智大脑》直播中，InfoQ 与重庆工程学院大数据与人工智能学院院长<a href=\"https://www.infoq.cn/article/eDq0AVuIVKZwgJoCMV41?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">李钦</a>\"深入探讨了《<a href=\"https://www.infoq.cn/video/oXX1AvBczGb9eDTqScIm\">中小银行智能风控体系是如何构建的</a>\"》。他强调，在这一现状之下，构建智能化风控体系首先必须明确业务战略，顶层设计和规划非常关键，同时实施过程要确保重点突出，优先级安排符合业务实际需求。</p><p></p><p>另外，还要注重建立容错机制，以避免机构走入常见的误区。此外，健全的数据管理是构建这一体系的基石。在此基础上，整合系统和工具、完善策略和模型以及关注宏观经济风险，都是确保风控体系的关键因素。</p><p></p><p>在李钦看来，大数据和人工智能技术在风险管理领域的应用已经相当深入，与此同时，大模型、AIGC 等新兴技术也正逐步崭露头角。尽管它们目前还处于探索阶段，但未来的发展潜力无疑是巨大的。</p><p></p><p>以下是对话全文（经 InfoQ 进行不改变原意的编辑整理）：</p><p></p><h3>中小银行发展现状与数字化挑战</h3><p></p><p></p><h5>InfoQ：是否可以从您的视角介绍一下我国中小银行目前整体的发展现状？</h5><p></p><p></p><p>李钦：中小银行当前面临的发展现状和挑战大致有以下几方面：</p><p></p><p>资产质量下降：受到国内外经济形势影响，中小银行的资产质量明显下降。特别是那些以服务小微企业和长尾人群为主的银行，这种趋势更为明显；</p><p></p><p>资产规模增长放缓：大多数中小银行的资产规模增长已经放缓，有的甚至停滞不前，但也有少数逆势而上，资产规模增长迅速；</p><p></p><p>产品同质化严重：</p><p>在小微领域，尽管许多银行都视之为战略目标，但实际上他们提供的产品如税贷、订单贷、流水贷等在功能上高度相似，导致产品同质化问题尤为突出。对于 C 端用户，中小银行受限于其获客能力，流量基本被大型互联网平台所控制，议价空间小，缺少自主品牌。也导致他们在这一方面的产品同质化问题可能更加严重。</p><p></p><p>人才和思维方式的问题：中小银行在人才战略、思维方式转变上存在显著的短板。例如，很多中小银行虽然会进行战略思考，但其战略方针可能更换频繁，反映出管理层的思路并不统一。同时，由于动力不足、思维方式转变不及时以及某些地方性的限制，导致它们在人才招聘、人才储备和人才战略规划方面存在不足。</p><p></p><h5>InfoQ：基于这些现状，中小银行在推进数字化过程中面临着哪些独特挑战？又有什么新的发展机会？</h5><p></p><p></p><p>李钦：在过去的几年里，中小银行在追求数字化转型时，主要选择了以 C 端作为突破口。这为它们创造了一个与流量丰富的互联网平台合作的窗口期。</p><p></p><p>然而，这种模式下，许多银行往往只起到了资金提供者的角色，大部分关键业务流程如获客、营销、品牌运营和风控等都被互联网平台所控制。这导致中小银行在这种合作中丧失了定价权，获得的收益相对较低，而风险承担却相对较大，存在明显的风险与收益不匹配的现象。</p><p></p><p>但未来，中小银行的<a href=\"https://www.infoq.cn/article/Su6bfESLE0kA7g9waE7X\">新的发展机会</a>\"或将集中在产业互联网领域。与 C 端不同，B 端的每个行业和垂直领域都有其独特之处，这使得它不易被单一的公司或企业类型所垄断。此外，新技术与特定产业的深度结合将会为金融产品创新提供新的机会。</p><p></p><p>为此，中小银行应当挖掘自己的地域和行业特色，深入研究产业互联网，以此为基础创新并打造出真正具有竞争力的产品。这不仅能够帮助中小银行弥补在 C 端的短板，还可以让它们在 B 端市场上获得更大的话语权。</p><p></p><h3>风控体系的演化与痛点</h3><p></p><p></p><h5>InfoQ：风控是金融业务的命脉，近年来金融环境和金融业务范畴也日益复杂多变，在风控层面会面临哪些新的难题？</h5><p></p><p></p><p>李钦：风控分为两个层次：管理层面与技术层面。</p><p></p><p>首先，从管理层面看，当前的宏观经济形势较为复杂，使得中长期的判断变得困难。许多中小银行在风控上过于强技术层面，忽视了从宏观经济趋势出发去调整资产结构的重要性。风控在较高的层次上，应当首先考虑宏观经济的趋势，并根据这一趋势提前布局资产结构，积极主动调整如何投放节奏。这可能比单纯针对具体产品或客户级的风控更为关键。</p><p></p><p>其次，防范系统性风险是另一个重要议题。技术层面的风控虽然能够解决具体操作中的问题，但在更宏观的层次上，我们还需识别未来是否存在某些领域的系统性风险。</p><p></p><p>另外，从产品设计的角度看，传统金融机构在设计产品时更多是出于自己的角度，提供给客户的选择相对有限。但近年来，金融行业逐渐追求为客户提供“千人千面”的定制化产品，这无疑给金融机构带来了新的挑战。更重要的是，在产品设计时，若未充分考虑风控的需求，如所需数据、流程设计等，这可能会导致产品在后期的风控中出现问题。</p><p></p><p>在<a href=\"https://www.infoq.cn/article/ixcNvwClOzTSal48vR6k\">风控管理</a>\"中，客户级的风险管理是另一个重要环节。特别是对于线上业务，客户级风控主要从两个方面展开，反欺诈和风险策略模型。然而，在进行客户级风险管理时，常面临的问题是缺乏数据、技术支持、专业的模型人员或风险策略分析人员。这些因素可能阻碍建立一个健全的风控体系。为应对这些挑战，我们在过往的实践中，逐步搭建了一套完善的风险管理体系，并计划在 11 月的 FCon 大会议进行详细介绍。</p><p></p><h5>InfoQ：风控手段一直都有，但为何它们在现在的金融业务环境中失效？</h5><p></p><p></p><p>李钦：首先是客户本身的变化，过去，金融服务可能主要针对优质人群。但随着普惠金融的推进，目标逐渐转向服务更多的“长尾”客户。这部分客户往往可能连基本的征信记录都缺乏，导致他们在选择金融服务时，能够获取到的服务有限。为满足这种新的客户群体，我们需要引入新的技术，收集更多的数据维度，以更有效地进行风险管理；</p><p></p><p>其次是与客户的交互方式的变化，与客户的互动方式已从面对面的交流转向线上互动。这种线上的交互方式，尽管带来了便捷性，但同时也引入了新的风险。例如，金融机构不仅要面临信用风险，欺诈风险也日益凸显。由于我们无法面对面与客户接触，可能会遇到如假冒身份、提供虚假资料或伪造数据的风险。甚至有些人可能利用系统的漏洞，对风控体系进行攻击。这都是新技术应用在风险管理中可能引发的新问题。</p><p></p><h5>InfoQ：智能风控本质上是结合大数据和人工智能等新技术来提升金融业务的风险识别与处理能力。那么，金融机构具体如何利用这些技术来加强其风控体系呢？</h5><p></p><p></p><p>李钦：首先，大数据技术提供了数据存储、计算和数据处理能力，可以用于开发和应用算法、图像、语音和非结构化数据等，以提高风险管理的效率和准确性。在风险管理中，我们通常需要外部购买一些数据来识别多头风险，例如短期内多次申请贷款或信用卡的行为。这些数据可以从侧面反映客户对资金需求的量或是客户是否成功申请，从而提供关于客户信用风险的信息。</p><p></p><p>通过将大数据技术和人工智能技术结合起来，我们可以更准确地识别和评估客户的风险，并采取相应的措施来管理和控制风险。当然，反欺诈分析也已广泛运用人脸识别和知识图谱技术。大数据和人工智能技术在风险管理中的应用已相当成熟，而像 <a href=\"https://www.infoq.cn/article/tXdg1xI1YWGYG6iGg4rj\">AIGC </a>\"和 ChatGPT 这样的新技术也逐渐被引入，尽管目前处于初级阶段，未来将会有很大的空间。</p><p></p><p>其次，像数据采集和模型优化有许多的方式，例如与征信机构的合作，尤其是如何深度挖掘人民银行征信数据，因为它在金融领域的质量和相关度最高。当然，也有许多中小银行与科技公司联手，推出定制模型和数据产品。</p><p></p><h5>InfoQ：新技术的引入会不会影响客户体验，如何在保持业务风险可控的同时，确保良好的客户体验呢？</h5><p></p><p></p><p>李钦：客户体验与业务发展并不矛盾。当客户体验不佳时，因逆向选择现象业务风险会增加，因为好客户可能因为操作麻烦而选择退出，而坏客户不在意这些繁琐。另外，客户体验在设计额度和利率时都极为关键。我们的经验是，应该尽量简化客户的操作并避免给他们带来理解上的困扰，同时给到合理的定价和额度。</p><p></p><p>当前，许多机构，尤其是城商和农商体系，往往将各部门任务严格划分，如产品、风控、市场和运营各自为阵，这可能导致整体视角的缺失，从而设计出的产品可能面临不可预见的问题。因此，现代的互联网金融产品运营应当采用项目小组的方式，从产品设计开始，集结风控、科技等多方人员参与，确保从整体角度考虑产品的每个环节。</p><p></p><h3>智能风控体系搭建思路与路径</h3><p></p><p></p><h5>InfoQ：随着大模型的引入，它将如何影响或颠覆当前 AI 所执行的任务？</h5><p></p><p></p><p>李钦：在当前金融环境下，数据分析和风险建模的专家们因其高技能和专业性得到了普遍的认同，相应的薪资待遇也相当吸引人。然而，随着大模型和先进算法的出现，许多传统的、标准化的数据处理工作在未来有可能被<a href=\"https://www.infoq.cn/news/D5BW4LdBUGislXBCOFIZ\">大模型</a>\"所替代。</p><p></p><p>事实上，一些银行已经提出并尝试实施了“数字员工”的概念，这种应用最初主要体现在与客户的交互服务和催收过程中。在我看来，只要某项工作可以被抽象和标准化，如数据准备、样本标记和算法选择等，它们都有可能被自动化技术取代。</p><p></p><p>尽管如此，目前在信用风险领域，大模型的应用仍相对有限，多数机构更偏好于使用逻辑回归和基于决策树的集成算法，原因在于这些方法更易于解释和部署，且具有较好的稳定性。</p><p></p><p>可以预见，随着数据的不断增多和计算能力的提升，超大规模的模型在未来将得到更广泛的应用。除了信用风险领域外，如声誉风险管理，大模型可以帮助机构更有效地监控网络上的负面信息，如敏感词汇、图片和文字。此外，催收领域和与客户的实时交互也是大模型应用的重要方向。</p><p></p><h5>InfoQ：在推进智能风控的过程中，您认为金融机构最容易遇到的挑战或误区是什么？</h5><p></p><p></p><p>李钦：金融行业在推进智能风控时，确实面临着不少挑战。</p><p></p><p>首先，缺乏顶层设计是许多银行的通病。为了快速上线业务，很多银行在科技层面忽视了系统架构的规划，导致后期数据规范不统一、系统交互复杂，给后续的分析、建模和监管报送带来巨大困扰。因此，业务前期的数据规范和系统架构设计至关重要。</p><p></p><p>其次，团队管理也是一大难题。数字化风控涉及的核心能力分散在多个团队中，如科技部、业务部门、风险管理部和产品部等，需要这些团队能够紧密合作，形成敏捷的工作小组，共同面对和解决问题。</p><p></p><p>另外，容错机制的建立也不容忽视。互联网产品推出后不一定立即成功，因此应为其提供一定的试错机会和成本，让其有更多的尝试空间。金融机构在产品运营时，通常为产品设定一个最高的风险承受额度，超出此额度则认为产品的成功几率低，可能会考虑退出。</p><p></p><p>最后，机构在风控建设上常面临的挑战是目标不明确和资源分配不当。虽有大框架，但缺乏明确的实施进度和水平标准。这导致各团队频繁沟通，争取资源，却可能忽视真正重要和紧急的任务，增加了内部的消耗和跨部门的沟通成本。因此，建议机构应明确目标和优先级，集中资源处理关键问题。</p><p></p><h5>InfoQ：对于一个金融机构，特别是中小型银行，如何构建与其定位相匹配的战略顶层设计？</h5><p></p><p></p><p>李钦：在风险管理中，金融机构应综合考虑多个方面。</p><p></p><p>第一，数据管理是基石，包括如何有效地采集数据、进行存储、后续的数据清洗、加工、指标化和变量化。</p><p></p><p>第二，有了稳固的数据基础，接下来是系统和工具层面。这里不仅包括决策引擎，还有分析工具和建模环境等，确保风控人员能够轻松调取数据并进行分析。</p><p></p><p>第三，策略和模型层面是至关重要的。这要求有一套完整的、科学的风险处置策略，并与团队的专业能力及策略方法论相结合，实现策略的高效开发、优化和迭代。</p><p></p><p>第四，金融机构往往涉及多个参与者，如流量提供者、担保公司等，因此合作机构风险管理也不容忽视。这需要对合作机构的风险特点有深入了解，并设定相应的管理策略。</p><p></p><p>第五，产品风险管理是确保每款金融产品的风险处于可控范围内的关键，包括对产品可能出现的风险进行预警、分析和干预。第六，考虑到宏观经济的影响，金融机构还应关注宏观经济风险，如何根据这些风险制定策略，确定资产组合等。</p><p></p><h5>InfoQ：您认为，在现有的框架体系中，大模型将会在顶层设计的哪一部分发挥作用？</h5><p></p><p></p><p>李钦：大模型相对于传统的小模型有明显的区别。小模型主要处理结构化数据，计算复杂度相对较低，而模型样本量通常只在几十万至上百万的范围内。相比之下，大模型的参数数量庞大，能够处理更复杂的数据格式。尽管两者在高层次逻辑上基本一致，但大模型在数据处理层面与现有模型有很大的差异。</p><p></p><p>此外，模型构建是一个复杂的过程，涉及到算法选择、模型训练环境和数据来源等多个环节。因此，大模型不仅会影响数据处理层面，还与数据层和系统工具层存在紧密的交互关系，两者之间相互影响。</p><p></p><h5>InfoQ：对于中小银行，在构建您提及的风控管理体系时，应特别关注哪些问题？</h5><p></p><p></p><p>李钦：首先，中小银行在搭建风控体系时，首先必须明确业务战略。同时<a href=\"https://www.infoq.cn/article/GItTCDMzzSsxMcojWydF\">顶层设计和规划</a>\"非常关键，同时实施过程要确保重点突出，优先级安排符合业务实际需求。</p><p></p><p>另外，非常重要的是在认知层面，风险管理不仅是风险管理部门的责任。一个普遍的误解是，当风险发生或不良率上升时，只有风险管理部门需要对此负责。实际上，组织协调和业务风险是业务全流程的责任，需要整个团队的认知和配合。</p><p></p><p>在具体实施中，风险能力有多个组成板块，这将我在 11 月 FCon 大会中的重点分享内容。我们基于历史经验，提出了一套智能风控能力的评价标准，具有很高的科学性，期待在会议中与大家分享，帮助解决中小银行的实际问题。</p><p></p><h4>关于 FCon</h4><p></p><p>首届<a href=\"https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">FCon全球金融科技大会</a>\"将于 11 月 19-20 日在上海举办。本次大会已邀请到工商银行、招商银行、汇丰银行、兴业银行、中信银行、北京银行、平安人寿、度小满、蚂蚁集团等业界知名银行以及金融机构的大咖，前来分享大模型、 Web 3.0 、隐私计算、数字货币、区块链等前沿技术在金融领域的落地案例。</p><p></p><p>我们诚挚地邀请您加入我们，共同探索金融科技的未来，<a href=\"https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">点击链接</a>\"即可查看全部演讲专题。</p><p></p><p>目前是 <a href=\"https://fcon.infoq.cn/2023/shanghai/apply?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">8折特惠购票</a>\"，报名立减 ¥1360，咨询购票可联系：17310043226（微信同手机号）。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/e2/ca/e205602269fc52b1557a8c4a4e7b91ca.png\" /></p><p></p>",
    "publish_time": "2023-10-31 14:38:19",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "程序员的私人助理：Amazon CodeWhisperer",
    "url": "https://www.infoq.cn/article/TprcKvXyB5fsKgC4SaLx",
    "summary": "<p>编程是一项有趣而又富有挑战性的工作，但是也会遇到很多困难和繁琐的任务。有没有一种方法可以让编程变得更容易，更快，更安全呢？答案是有的，那就是 AI 辅助编程。</p><p></p><p>在这篇文章中，我将介绍一款由亚马逊推出的 AI 辅助编程工具——<a href=\"https://www.infoq.cn/article/JcIQOLpgqVK3AAgQxNQt?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">Amazon CodeWhisperer</a>\"，它是如何帮助开发者提高生产力和代码质量的，以及我使用它的一些体验和感受。</p><p></p><p>Amazon CodeWhisperer 是在 2021 年 12 月正式推出的一款 AI 代码生成器，它是基于亚马逊内部使用的 AI 编程助手的经验和技术而开发的。推出之际，Amazon 邀请了一些开发者参与一个生产力挑战，结果显示使用 CodeWhisperer 的开发者比不使用的开发者更有可能成功完成任务，并且平均速度快了 57%。</p><p></p><p>推出后受到了很多开发者和企业的欢迎和好评，例如 Accenture 就使用 CodeWhisperer 来提高开发者的生产力，包括新人培训，编写样板代码，使用陌生的语言，以及检测安全漏洞等方面。</p><p></p><p>而现在，亚马逊更是大方的开放了个人免费套餐，在个人开发过程中享受 AI 辅助编程的快感。使用下来的体验就像多了一个秘书，而自己从程序员的角色变成了半个产品经理的角色：我只需要口述我想要的功能，它就能帮我生成初版的代码，稍微修改就能实际运行。真正解放了人的思想。</p><p></p><p>它目前支持 15 种编程语言，包括 Python，Java，JavaScript 等，以及多种 IDE，包括 VS Code，IntelliJ IDEA，AWS Cloud9 等。你只需要免费注册并下载 CodeWhisperer 插件，安装到你喜欢的 IDE 中，然后就可以开始使用了。</p><p></p><p>我以 Goland 为例，只需插件市场搜索“CodeWhisperer”进行安装以及登录，便可开始使用了。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f2/f2661b09aa6dcb87cc44f7b80964f5da.png\" /></p><p>​</p><p>插件市场搜索 CodeWhisperer，安装完成后，左下角会有一个 AWS toolkit 的工具栏，点击它并且登录。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bc/bc79a255e5f36461fd687630692b86ab.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cd/cdb46af8d1dc6e8a4c89f9cd11dc3c72.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/24/24090b58e3b54d55c94081aa340c188c.png\" /></p><p>授予权限，权限授予之后，左下角 CodeWhisperer 显示可用状态时，就可以开始编码，享受 AI 辅助编程的快感了。</p><p><img src=\"https://static001.geekbang.org/infoq/de/de77c9f7c8eaf9dadef10866e0201935.png\" /></p><p>​</p><p>比如很经典的斐波那契数列，只需要描述一下函数功能，接下来的事情就是 Tab 键自动输入代码了。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/49/494f69fd1887b906b77650f121704f92.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1a/1a8b32d509fc68c47bd0a7744c4cb5c7.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/21/21d567be03fe567fd2de7146143c6cfa.png\" /></p><p>​</p><p>共计一行描述，三次 Tab 键，完成了首次 AI 编程辅助。整个使用过程非常简单和自然，你只需要在 IDE 中写下你想要实现的功能的注释，例如“创建一个列表”，“连接到数据库”，“发送一封邮件”等，CodeWhisperer 就会自动给出多个代码建议，你可以选择接受或者继续编写自己的代码。</p><p></p><p>CodeWhisperer 会根据你的代码风格和命名习惯，生成符合你的习惯的代码。你还可以使用 CodeWhisperer 来扫描你的代码，检测并修复安全漏洞，以及跟踪开源代码的来源和许可信息。</p><p></p><p>很多人可能认为程序员的核心能力是写代码，其实并不是。真正的价值是思考，是写代码之前的苦思冥想，最终实现则是水到渠成的事情。而 Amazon CodeWhisperer 带来了什么呢，个人认为其中最主要的是可以提高开发者的生产力和代码质量。使用 CodeWhisperer，可以：</p><p></p><p>节省时间和精力，避免编写重复和繁琐的代码，快速完成编程任务。提高代码的可读性和可维护性，遵循编码规范和最佳实践，减少错误和 bug。更高效地使用 AWS 服务，获取符合 AWS API 的代码建议，轻松构建云端应用。增强代码的安全性，及时发现和修复安全漏洞，防止数据泄露和攻击。代码负责任，跟踪开源代码的来源和许可信息，避免版权纠纷和法律风险。</p><p></p><p>欢迎大家使用，提高程序员的幸福感！</p>",
    "publish_time": "2023-10-31 16:09:46",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AIGC 时代，如何提升端侧算力利用效率？",
    "url": "https://www.infoq.cn/article/vieTybwOJv3JKQZvgmrJ",
    "summary": "<p>ChatGPT 的爆火掀起了 AI 大模型热潮，也进一步拉动了算力需求的爆发，面对呈指数级增长的算力需求，如何用得起、用得上、用得好算力成为大家普遍关心的问题。那么，在大规模 AI 模型训练中，如何保证算力的高效利用？有哪些技术或方法可以提升训练的效率和稳定性？AIGC 应用如何下沉到终端？近日，InfoQ《极客有约》邀请到了英特尔中国技术部总经理高宇，为大家分享《AIGC 时代，如何提升端侧算力利用效率？》。</p><p></p><p>以下为访谈实录，完整视频参看：<a href=\"https://www.infoq.cn/video/w4UPiNImmKac6OSgpEiP\">https://www.infoq.cn/video/w4UPiNImmKac6OSgpEiP</a>\"</p><p></p><p>姜雨生：欢迎大家来到 InfoQ 极客有约，我是今天的特邀主持人，微软软件工程师姜雨生。本期直播，我们邀请到了英特尔中国技术部总经理高宇老师来给我们做分享。今天的直播主题是《AIGC 时代，如何提升端侧算力利用效率？》。先请高宇老师给大家做一个简单的介绍。</p><p></p><p>高宇：InfoQ 的朋友们，大家晚上好。我是高宇（Gary Gao），来自英特尔中国，负责英特尔中国技术支持团队的工作。今天，我非常荣幸与大家分享关于在端侧实现 AIGC 的热门话题。</p><p></p><h2>生成式 AI 技术的发展与挑战</h2><p></p><p></p><p>姜雨生：去年推出的 ChatGPT 引起了广泛关注，掀起了大型 AI 模型的热潮，企业和个人对算力的需求呈现出爆发性增长。这轮 AI 算力需求的爆发给您带来最大的感受是什么？行业发生了哪些变化？</p><p></p><p>高宇：这一轮生成式 AI 热潮确实代表了技术上的一个重大突破，无论是给消费者、商业客户还是数据科学家，都带来了巨大的潜力和影响。从去年 ChatGPT 3.5 正式发布以来，它展示出的智能和生成文本的能力让整个学术界、消费市场和最终用户都感到震惊。在短时间内，ChatGPT 3.5 已成为全球最受欢迎的应用之一，这一成就令人印象深刻。我认为，它对整个行业的影响可以从正面和挑战两个维度来分析。</p><p></p><p>从正面来看，首先，生成式 AI 极大地改善了用户体验。以前的搜索引擎和智能问答系统在知识方面相对固定，而生成式 AI 具有强大的学习和涌现能力，这是以前所没有的。因此，用户体验得到了显著改善。</p><p></p><p>其次，它激发了学术界和企业界对这项技术的研究兴趣。在过去的半年里，全球企业和知名的学术机构都大量投入到生成式 AI 的研究中。这种巨大的资金和智力投入使我们相信未来几年生成式 AI 的发展将非常迅猛，因为许多人都在进行相关研究和突破。</p><p></p><p>第三，我们看到生成式 AI 目前主要应用于人机对话，但我们更看好它在各种行业中，尤其是垂直行业中的应用潜力。例如，目前人们正在探讨用于医疗领域的大型模型，专为银行系统设计的大型模型，甚至为金融等垂直行业开发的模型。因此，我们对它在这些领域的应用前景非常期待。</p><p></p><p>当然，大型模型的出现和生成式 AI 的发展确实带来了一些重要挑战。在这方面，我们可以总结为以下几点。</p><p></p><p>首先，几乎所有大型科技公司都加入到了这个浪潮中。因此，这个领域的应用进展非常迅速，有时候可能会出现一些重复性工作，甚至资源浪费。</p><p></p><p>第二，数据隐私和可靠性是一个重大问题。个人数据的保护以及互联网上的开源内容如何得到保护都是重要考虑因素。此外，还涉及到更深层次的问题，例如对问题的解释、价值观的取向和正确判断等，这些都是全新的挑战。</p><p></p><p>英特尔倡导的 AI 不仅关注性能和能力，还强调负责任的 AI。这也是领先厂商共同的理念，即人工智能的发展应该以对社会负责任的态度为基础。总之，生成式 AI 对我们行业带来了重要冲击，后续我们可以深入探讨这些挑战的细节。</p><p></p><h2>算力成本居高不下，如何找到破解之法？</h2><p></p><p></p><p>姜雨生：无论是模型训练还是模型调用，计算资源的需求都在不断增加。这背后伴随着高昂的成本，对许多企业而言，这成为了业务扩展的一道巨大障碍。您怎么看算力贵这一现象？随着技术的发展，算力贵的现状会有所改善吗？</p><p></p><p>高宇：目前，大家都不得不承认算力成本有待解决。因此，大家都对这个行业的情况非常关注。我们可以分析一下导致算力成本上升的原因。</p><p></p><p>首先，运行生成实验，特别是训练模型所需的 GPU 性能相对较高，因此整个 GPU 以及 GPU 卡的成本较高，它需要更大的 GPU 芯片来提供更高的算力。此外，它还需要更快的内存，通常采用 HBM（High Bandwidth Memory，高带宽内存）内存架构，这也增加了成本。再加上需要用 8 卡互联的训练机，整机的物料成本非常昂贵，这是导致成本高昂的原因之一。</p><p></p><p>第二，与之前提到的问题相关，现在几乎所有人都涌入了这个行业，导致了短期内供大于求的情况。一度出现了 GPU 卡供不应求的情况，这已经从去年年底开始，需求量大但供应相对不足。</p><p></p><p>第三，整个大型 GPU 服务器或智算中心的运营成本极高，包括场地和能源消耗。一个标准的 GPU 服务器机柜功耗至少为 30 千瓦，而大多数数据中心机柜通常只能达到 10 千瓦到 20 千瓦之间，无法满足 30 千瓦的要求，这也增加了成本因素。</p><p></p><p>当然，我们还需要考虑一点，因为生成式 AI 仍处于早期阶段，所以在许多算法优化和资源利用方面还有改进的空间。因此，有望在未来降低算力成本。</p><p></p><p>姜雨生：在目前算力贵这个方向，英特尔目前有哪些相关的解决方案，这面方便给我们大概介绍一下吗？</p><p></p><p>高宇：我们需要思考一个根本性问题，即如何应对昂贵的算力这一行业性的难题。我们有几个想法，虽然稍后我们还会谈及产品方面的问题，但现在我们首先想从行业角度提出一些大的思路。</p><p></p><p>首先，我们认为当前的推理部分应该更加分布式和层次化，充分利用云、边缘和终端的不同层次来部署推理算力，以充分发挥算力性能。具体来说，我们的建议是在云端进行大规模的训练，这是云侧的任务。此外，云侧适合大集群训练，部署超大型模型，例如 ChatGPT 等超过 100 亿的模型。第三，云侧适合部署高并发的场景，即当用户数量庞大时，需要同时满足所有客户的需求，这也需要云端来实现。</p><p></p><p>对于不属于以上几种情况的 AI 推理算力，我们建议将其下沉到边缘侧。如今，运营商和企业都拥有许多边缘侧数据中心，虽然这些数据中心规模较小，机器配置的算力相对较低，但足以支持多种类型的大型模型的推理。根据我们的判断，大约在 10 亿到 30 亿之间的模型可以考虑部署在边缘侧，因为边缘侧可以使用性能稍微较低端的 GPU 卡或 CPU 进行推理，性能足够。此外，在边缘侧部署可以提供更好的低延迟体验，成本也较低。</p><p></p><p>下沉的第二步就是把它部署在端侧。我们认为一些规模较小的模型，比如小于 10 亿参数的模型，经过一定的优化和量化，以及低精度的比特量化后，完全可以部署到个人计算机（PC）或虚拟私有云（VPC）等设备上。将其部署到端侧带来两个明显的好处。首先，它的性能延迟是最低的，因为不需要经过网络传输，减少了任何网络延迟。此外，边缘侧部署还有一个重要的优势，即对个人隐私的最大程度保护，因此数据泄露的风险几乎不存在。因此，从大的原则上讲，我们希望将大型模型转化为云、边缘和终端三层协同的架构，这应该是未来发展的趋势之一。</p><p></p><p>姜雨生：有观众提问，在算力优化方面，我们业界还有没有一些通用的方案？</p><p></p><p>高宇：我们了解到，在当前的研究领域中，一个备受关注的通用方案是针对低比特量化的优化。目前，大多数部署在云端的模型采用的是 FP16（16 位浮点数）的精度。然而，如果要将模型部署在边缘侧或终端侧，通常的做法是首先将其量化为 INT8（8 位整数），然后可以进一步将其量化为更低比特位，如 INT5、INT4 或 INT3，这都是可能的，而且我们看到在这方面行业已经取得了一些显著的进展。</p><p></p><h2>AIGC 应用如何下沉到终端？</h2><p></p><p></p><p>姜雨生：我认为开发者会积极采用 AIGC 的大型模型，因为这是未来的趋势。在过去，我们主要在云服务器上运行 AIGC 应用，包括我自己目前使用的一些 Azure 云上的产品。但云端 AI 也存在延迟和各种限制等方面的一些短板。那么，AIGC 应用有下沉到终端的可行性吗？</p><p></p><p>高宇：根据我们目前的研究成果，我可以告诉大家，针对英特尔的最新平台，也就是第 13 代（以及后续推出的第14代，采访时第14代酷睿尚未发布）酷睿处理器家族，我们已经取得了非常不错的优化结果。这个平台不仅适用于笔记本电脑，还包括台式机。我相信许多开发者和用户在购买电脑时都会选择最新的酷睿平台。</p><p></p><p>以第 13 代酷睿平台为例，我们的优化结果可以使模型从 7 亿参数到 18 亿参数都能够流畅运行。特别是在 7 亿到 13 亿参数范围内，性能效果非常出色，即使超过 13 亿参数，模型也可以运行，尽管速度稍慢，但我们认为基本上也可以满足用户的需求。当然，我们目前的优化主要是在 CPU 上进行的，但下一步我们将充分发挥平台内的集成显卡（IGPU）能力，以进一步提升速度。</p><p></p><p>此外，对于未来，我想提到最近引起广泛关注的一项重要消息，那就是我们披露了英特尔即将发布的下一代平台，内部代号为 Meteor Lake，正式品牌叫做 Core Ultra。这个平台不仅具有强大的 CPU 算力，还将 GPU 算力提高了一倍，因此GPU算力非常强大。另外，它还内置了专用的 AI 加速器（NPU），可以提供超过 11 tops 的峰值算力。因此，在下一代平台上，我们将能够充分利用三种计算资源，包括 CPU、GPU 和 NPU 的算力，以实现更出色的性能。这是我们下一代平台的亮点，敬请期待。</p><p></p><p>姜雨生：英特尔之前提出在 PC 端侧跑 AIGC 应用，具体是如何实现的？在软硬件层面是如何提升算力利用效率，实现算力优化的？</p><p></p><p>高宇：我来简要介绍一下我们目前正在发布的开源框架，它叫做 BigDL，是专门为英特尔的处理器和 GPU 开发的一个低比特量化框架。感兴趣的观众可以进入在 GitHub(https://github.com/intel-analytics/BigDL)上查看，下载我们的 BigDL 开源代码，进行实验。</p><p></p><p>BigDL 有一些显著特点。首先，它支持低比特量化，从 INT8 到 INT5、INT4、INT3 等各种低比特的数据精度，从而提供更好的性能，并减少内存占用。这一点尤其重要，因为在边缘计算领域，除了性能挑战之外，内存也相对较低，所以低比特量化是解决这个问题的一种方法。</p><p></p><p>此外，BigDL 支持多种平台，包括英特尔的各种 CPU 系列，从 Xeon 处理器到酷睿处理器等。它还支持英特尔的各种 GPU 系列，包括英特尔 Flex 系列用于数据中心的专用显卡以及英特尔锐炫（ Arc） 系列面向消费者的显卡。</p><p></p><p>姜雨生：我也确实感受到了在个人电脑上运行大型模型以及进行内容生成的可能性，特别是在我的个人电脑上装备了这些硬件的情况下。实际上，我也想了解一下一些相关的技术，如果要大规模普及，关键的主要指标可能是颠覆，即用户在他们的实际工作和生活中所体验到的变革。那么AI 能够在端侧带给用户哪些具体的体验提升？</p><p></p><p>高宇：从我们现在的观察来看，大型模型在端侧用户领域可能有几个可能的应用场景。首先，大型模型可以成为每个用户的个人超级助手。这种大型模型可以在云端运行，同时也可以通过我们刚刚提到的低比特量化技术在个人电脑上运行，从而提供更好的用户体验。这是第一个应用场景。</p><p></p><p>第二，它可以用于文档处理，包括提取文档的核心思想和纠正文档中的语法错误等任务。对于这种应用场景，更适合将模型部署在端侧，因为许多文档包含一些个人属性，用户可能不愿意将其上传到云端。</p><p></p><p>第三，我们观察到大型模型，特别是 Diffusion 模型，在图像生成方面具有出色的能力，这对于许多设计师来说是一个强大的工具。许多图形、图像和三维设计公司积极采用 Stable Diffusion 以及相关衍生模型，以帮助设计师生成各种图片和画面，从而实现事半功倍的效果。</p><p></p><p>姜雨生：将 AIGC 相关应用以预装软件的方式适配到未来的电脑中，是否是 PC 创新的一个新方向？它对于 PC 应用效率的提升是否有着大幅超越以往的预期？</p><p></p><p>高宇：当然，答案是肯定的。在未来的个人电脑上，无论是笔记本还是台式机，它们的算力已经足以支持像 7 到 13 亿级别的大型语言模型在本地运行。这种潜力已经存在，接下来我们可以期待不同的商业模式的出现。</p><p></p><p>首先，我们可能会看到一些商业软件集成了中小型大语言模型，将其变成了生成式人工智能的专业商业软件。这些软件还有可能集成了 Stable Diffusion 等功能，从而成为一种可用于文本生成和其他工作流程的商业软件。因此，可以期待在桌面平台上出现集成生成式人工智能能力的商业软件，这是一个可能的落地方式。</p><p></p><p>另外一种方式是鼓励更多的 OEM 制造商，也就是个人电脑的品牌制造商，为自己的产品开发专门针对硬件优化的生成式人工智能软件，并将其预装在他们的电脑上，以提高最终用户的体验，使电脑更易于使用和更具趣味性。这种辅助性软件可以提升用户的使用体验，增加趣味性，我认为这也是一个非常有潜力的方向。</p><p></p><h2>端侧运行大模型存在哪些挑战？</h2><p></p><p></p><p>姜雨生：有观众提问，端侧跑这些大模型有没有一些难点我也比较关注这个问题，端侧跑大模型有没有一些相对不适用的场景或内容？</p><p></p><p>高宇：端侧与云侧相比，目前存在两大限制。首先，端侧的计算能力明显不如云端强大。这是显而易见的。第二，端侧的内存相对有限。当前，笔记本电脑和 PC 的主流配置通常为 16GB 内存。明年我们可能会看到更多配置为 32GB 内存的 PC，但即使是 32GB 内存，相对于云端来说，内存仍然有限。因此，端侧需要应对以下两个主要挑战。</p><p></p><p>首先，模型的参数量需要受限，通常在 130 亿以下。其次，必须进行低比特量化，这是一种必不可少的手段。经常有人问一个常见的问题，即将一个 FP16 模型量化为 INT4 后，精度损失似乎很大，这对大型模型的性能会产生什么影响？我们目前的基本结论是，在大型语言模型的情况下，从 FP16 到 INT4 后，回答问题的质量会略微下降，但下降幅度并不是很大。如果我们使用评分机制，原来的模型可能是 85 分的模型，经过量化后，可能会下降到 82 分左右，所以大致是一个个位数的质量下降。但是在内存方面，收益是非常大的，这是一个权衡。</p><p></p><p>然而，对于 Stable Diffusion 模型而言，如果将 FP16 量化为 INT8，整个图像生成的质量下降会比较大。因此，对于运行稳定扩散模型的端侧，我们仍然坚持使用 FP16。幸运的是， Stable Diffusion 模型的参数量不是很大，因此即使在端侧，FP16 的性能也完全可以胜任。</p><p></p><p>姜雨生：在端侧执行一些生成式内容和场景时，精确度并不是特别重要，尤其是对于一些模型复杂度不太高的情况来说，这种方式会更加合适。下一步，英特尔有哪些技术探索和产品规划呢？有哪些技术难题是我们在未来需要解决的？</p><p></p><p>高宇：对于英特尔未来的产品规划，目前英特尔在生成式 AI 领域有几个主要的产品家族，可以从云端、边缘和端侧三个维度来介绍。</p><p></p><p>在云端，英特尔的关键产品是 Gaudi2，这是 英特尔Habana最新推出的产品。Gaudi2 具有非常高的算力性能，它还具有大容量的显存，目前 Gaudi2 的配置为 96GB 的 HBM2 显存，因此可以容纳更多的模型。此外，英特尔还推出了专门针对中国市场定制的 Gaudi2 中国版本。云端英特尔还有一款产品叫做 Xeon HBM，它是一款针对大模型推理而设计的 CPU，内置了 64GB 的 HBM2 高速内存，这对于大型语言模型的推理性能提升非常有帮助。</p><p></p><p>边缘侧，英特尔推出了两款显卡产品，一款是英特尔 Flex 系列，另一款是锐炫（ Arc） 系列。Flex 系列是为数据中心和服务器设计的无风扇 GPU 产品，而 Arc 系列则是面向消费者市场的显卡，在算力方面也非常强大，可以满足边缘侧推理的要求。这些产品将为边缘侧大模型推理和 Stable Diffusion 提供强大的支持。</p><p></p><p>总的来说，英特尔在生成式 A I领域有一系列强大的产品，覆盖了云端、边缘和端侧，为不同应用场景提供了多样化的解决方案。</p><p></p><p>姜雨生：有观众提问，端侧模型跟云端模型有可以配合的方式吗？</p><p></p><p>高宇：端侧模型和云端模型可以进行协同配合，一种可能流行的做法是由端侧模型进行问题的初步预判断。这个端侧模型可以是相对轻量级的，用于判断用户问题的导向方向。如果这个初步判断结果显示性能足以在端侧大模型上运行，那么模型可以在端侧执行。但如果判断需要更强大的计算能力，那么就可以将任务传递到云端进行更大型的模型推理。这种方式可能比较容易实现，因为它避免了对同一个模型进行拆分，尽管拆分模型也是一种可能的方式，但会更加复杂。</p><p></p><p>姜雨生：如果希望在个人电脑上运行之前所描述模型相关的内容，最低配置要求如何？</p><p></p><p>高宇：关于个人电脑的配置，主要取决于您的耐心和使用场景，当然这是个半开玩笑，但基本上，为了达到基本的用户体验要求，我们建议以下配置：</p><p></p><p>处理器（CPU）：最好选择第 13/14 代酷睿处理器，尤其是选择 I7 或更高级别的型号。如果有预算，并且想要更出色的性能，选择 I9 处理器会更好，正如我在之前的演示视频中展示的那样。内存（RAM）：至少 16GB RAM 是起点，但更好的选择是 32GB RAM。此外，要注意内存的速度，因为现在的内存，尤其是 DDR5 内存，速度范围从入门级的 5677 MHz，一直提升到高达 7233 MHz。内存速度越快，性能表现通常越好。再次强调，大型模型通常对内存带宽要求较高，因此提高内存带宽会带来更大的性能收益。散热设计：除了硬件配置，还要考虑系统的散热设计。良好的散热设计可以让 CPU 在 Turbo 模式下更长时间地运行，从而提高性能表现。</p><p></p><p>选择适合需求的个人电脑配置是一个综合考虑的过程。明年新发布的电脑新品通常会公布其运行大型模型的性能指标，用户可以根据厂商提供的指标来选择适合自己需求的配置，这应该会更准确地满足你的期望。</p><p></p><p>当然了，我认为目前大模型仍然存在一些挑战，尤其是在处理模型的一些幻觉问题方面，这个问题在整个行业中仍然是一个难点，需要不断攻克。</p><p></p><h4>嘉宾介绍</h4><p></p><p></p><p>特邀主持：</p><p></p><p>姜雨生，微软软件工程师，负责微软资讯业务与 GPT 集成，曾负责微软广告团队基础设施搭建与维护工作。</p><p></p><p>嘉宾：</p><p></p><p>高宇，英特尔中国技术部总经理，负责领导英特尔中国从端到云的产品技术使能和方案支持工作，对中国IT产业和生态链、以及前沿技术发展趋势有着深入的洞察和见解。&nbsp;</p>",
    "publish_time": "2023-10-31 16:12:45",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "15年技术沉淀，起底阿里核心搜索引擎 Havenask 演进之路",
    "url": "https://www.infoq.cn/article/ult2LYNeMbLDVwzhSr0P",
    "summary": "<p></p><h2>阿里开源搜索引擎&nbsp;Havenask&nbsp;的技术演进</h2><p></p><p></p><p>我们正处于信息爆炸式增长的时代，如何在信息海洋里迅速定位到目标信息成为人们关心的问题。搜索引擎作为互联网和应用的关键入口，向来是兵家必争之地。</p><p></p><p>然而在人们简单的搜索行为背后，对搜索引擎技术实际有诸多挑战：以电商场景为例，当遇到双11等大促活动时，百万级&nbsp;QPS&nbsp;的高并发访问，对千亿级商品&nbsp;&amp;&nbsp;订单数据、保单&nbsp;&amp;&nbsp;物流类数据时效性要求极高，那么搜索引擎该如何做到毫秒级时效？还有为了更准确理解人们的搜索意图，对搜索算法的要求越来越高，搜索引擎该如何做到算法分钟级迭代？这些都是技术上需要直面的挑战。</p><p></p><p>近年来，随着大数据技术、深度学习等&nbsp;AI&nbsp;技术的发展，搜索引擎能够更智能地帮助人们快速、准确地获取信息，我们对信息的处理能力也随之逐步提高。</p><p></p><p>阿里自研大规模分布式搜索引擎&nbsp;Havenask&nbsp;便是集大成者，基于阿里搜索十多年来的技术沉淀，Havenask&nbsp;目前广泛应用于阿里巴巴和蚂蚁集团内众多业务，如淘宝搜索和推荐、&nbsp;蚂蚁人脸支付、优酷视频搜索、阿里妈妈广告检索等。Havenask&nbsp;支持算法高效快速迭代，内置性能优异的向量检索能力；做到毫秒级查询性能，并拥有稳定性保障&nbsp;；支持单应用实例千亿级别数据，确保百万&nbsp;TPS&nbsp;高时效性。</p><p></p><p>2022&nbsp;年&nbsp;12&nbsp;月，阿里将&nbsp;Havenask&nbsp;开源，在几个月时间里&nbsp;Star&nbsp;数已超过&nbsp;1000+。为何&nbsp;Havenask&nbsp;有这样优异的表现，在短时间内获得众多开发者的喜爱？下面我们从&nbsp;Havenask&nbsp;的技术演进谈起，让大家更加深入了解&nbsp;Havenask&nbsp;以及未来更多可能性。</p><p></p><p>传送门：++https://github.com/alibaba/havenask++</p><p></p><h2>01&nbsp;Havenask&nbsp;技术演进之路</h2><p></p><p>回顾&nbsp;Havenask&nbsp;从内部自研技术走向成熟，这一路走来可分为以下阶段：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/85/85f3025dbedec2a27678b2160ae2f23d.png\" /></p><p></p><p>第一阶段：1999&nbsp;年~2008&nbsp;年，以解决各业务部门的搜索需求为主</p><p></p><p>阿里搜索技术最早可追溯&nbsp;1999&nbsp;年，起源于雅虎搜索技术，基于&nbsp;Apache&nbsp;Module&nbsp;的单机版搜索引擎，支撑淘宝、B2B&nbsp;等子公司的搜索业务需求。</p><p></p><p>第二阶段：2009&nbsp;年~2011&nbsp;年，重构搜索系统，开启自研大规模分布式高性能搜索引擎时代</p><p></p><p>自&nbsp;2008&nbsp;年起，开始构建阿里统一的搜索系统，内部代号为“iSearch”，它代表完全由阿里自研的搜索技术全新启航。iSearch&nbsp;迅速迭代&nbsp;iSearch3.0、iSearch3.2……2009&nbsp;年演进到&nbsp;iSearch4.5&nbsp;版本，也就是&nbsp;HA3（Havenask）最早的雏形。</p><p></p><p>2009&nbsp;年，Havenask&nbsp;开始逐步统一各子公司版本，去除&nbsp;Apache&nbsp;Module。2011&nbsp;年，彻底完成搜索系统的重构，HA3（Havenask）全部替代老的雅虎搜索系统，开始极致性能时代。</p><p></p><p>第三阶段：2012&nbsp;年~2018&nbsp;年，完成阿里内部搜索系统的“大统一”，进入快速迭代时代</p><p></p><p>2013年，HA3（Havenask）完成阿里集团各个业务搜索系统的“大统一”，不仅版本再次合并，还将&nbsp;B2B、淘宝等搜索团队统一整合，以产品化、规模化的方式支撑起整个集团的搜索业务。</p><p></p><p>2018&nbsp;年，随着深度学习技术的广泛应用，同时迎来信息流推荐机遇，HA3（Havenask）快速迭代，逐步形成一套以搜索引擎、在线推理引擎等为主的&nbsp;AI&nbsp;工程技术体系“AI·OS”。（OS”代表“Online&nbsp;Serving”&nbsp;）</p><p></p><p>第四阶段：2018&nbsp;年~至今，对外开源，技术普惠</p><p></p><p>2022&nbsp;年，阿里将搜索引擎&nbsp;Havenask&nbsp;开源，为更多用户提供更高性能、更低成本、更便捷易用的搜索服务。</p><p></p><p>总的来说，Havenask&nbsp;的发展是遵循先解决内部业务应用需求，再从核心业务延伸到其他业务，随着技术发展潮流不断向前演变，从单一的搜索引擎到大数据深度学习在线服务体系&nbsp;AI·OS&nbsp;的重要组成部分，打造成统一平台提供更强大的能力支撑，继而逐步开源对外，普惠开发者，这和阿里其他技术产品的发展思路是一脉相传的。</p><p></p><h2>02&nbsp;Haveansk&nbsp;架构优势</h2><p></p><p>从定位来看，Havenask&nbsp;作为阿里巴巴自主研发的大规模分布式搜索引擎，支撑起淘宝、天猫、菜鸟、优酷阿里整体的搜索业务，并扛得住双&nbsp;11&nbsp;大促活动。这背后，离不开底层架构设计，让&nbsp;Havenask&nbsp;有了坚实的技术基底。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/33/33f354cadf938d9f305d845ffdf35a82.png\" /></p><p></p><p>从架构来看，Havenask&nbsp;由四个核心模块组成：</p><p></p><p>索引系统**（Build**&nbsp;Service）。通常搜索引擎需要对原始数据构建索引，才能在提供服务时实现高性能。这部分在&nbsp;Havenask&nbsp;是支持全量、增量、实时流的复杂分布式流计算系统。</p><p></p><p>在线集群**（Havenask**&nbsp;**Runtime）****。**在线系统支持不同的数据规模分列查询，不同的查询并发做多副本。在系统里设计有类似于大脑的复杂角色，可以自动做查询处理、调度查询节点、数据节点等。如果出现机器坏了的情况，在线系统可自动识别这些情况，来保证系统的高可用。</p><p></p><p>消息中间件（Swift）。消息中间件用于实时数据传递，处理后的文档传递，是&nbsp;Havenask&nbsp;实现毫秒级时效性，支撑海量数据实时更新的基石。消息中间件&nbsp;Swift&nbsp;不仅可以用在&nbsp;Havenask&nbsp;系统中，也可以单独部署使用，与其他开源中间相比具有明显的性能和成本优势。</p><p></p><p>管控系统（Hape）。为了方便开发人员的日常运维，Havenask&nbsp;对管控运维的&nbsp;API&nbsp;进行了封装，提供方便实用的运维工具&nbsp;Hape&nbsp;，使用它开发人员可以方便的对表和集群进行管理。</p><p></p><p>据阿里巴巴智能引擎事业部云服务负责人、Havenask&nbsp;开源项目负责人郭瑞杰博士介绍，在架构设计上，Havenask&nbsp;更具备适合工业级业务场景的特性：</p><p></p><p>1、通过灵活稳定的扩展方式支持业务多样化需求，轻松应对数据规模和流量规模的快速增长；</p><p></p><p>2、通过领先的实时索引技术，提供性能出色的亚秒级实时搜索能力，通过对实时索引的不断自动整理优化，保证搜索性能持续优异；</p><p></p><p>3、传统倒排索引技术和&nbsp;AI&nbsp;时代普遍应用的向量检索技术深度结合，端到端极致性能优化，支持千亿级别文档或高维向量的极低延迟计算。</p><p></p><p>人们进行商品搜索时，由于每个人有不同的喜好，搜索引擎需实现个性化和智能化，以准确召回商品。当用户开始进行搜索时，往往是用关键词或一段自然语言的描述，搜索引擎先采用&nbsp;NLP&nbsp;技术理解和拆分成关键词，再根据关键词的语义相关性，采用向量等多路召回方式，返回有可能是用户想要找的商品信息，再对商品做粗排，粗排后收敛到集合里，再做精排，这个过程中&nbsp;Havenask&nbsp;使用了大量机器学习算法进行优化，以实现较好的用户体验。</p><p></p><p>这对搜索引擎有较高的性能要求，Havenask&nbsp;利用前置化思想，并发完成多路召回，实现非常小的延迟效果。另外在算法上，Havenask&nbsp;支持离线计算转在线计算、在线计算转离线计算做优化，还支持模型的实时更新以保证在离线的一致性。如此一来，算法工程师可以用更复杂的召回策略来做&nbsp;A/B&nbsp;测试验证效果，如果效果可以的话，可以实现分钟级上线。</p><p></p><p>在拍照搜图场景中，以淘宝拍照购物“拍立淘”为例，用户通过手机拍摄实物或通过相册照片搜索，就能搜索同款或相似商品。&nbsp;Havenask&nbsp;利用向量进行图片搜索，完成向量索引存储并将向量化后的图片与向量索引比对召回，实现高精度图片搜索。上述能力得益于&nbsp;Havenask&nbsp;和达摩院向量库&nbsp;Proxima&nbsp;深度结合，并进行端到端能力优化，支持百亿甚至千亿级别的高维度向量的低延迟计算。</p><p></p><p>总体来看，Havenask&nbsp;区别于其他产品的特点主要体现在两大场景中：一是大数据检索场景，实现亚秒级的时效性和极致的性能优化，达到较高的性价比。二是在&nbsp;AI&nbsp;场景上，Havenask&nbsp;实现异步高并发、超低召回延迟，提供在离线一致性保障机制，以及高性能高维度向量计算能力。</p><p></p><p>即使在双11特殊场景里，数据更新量突然爆增至十倍、百倍，Havenask&nbsp;仍能保证时效性在亚秒级。在查询上，单集群到近百万&nbsp;QPS&nbsp;时，Havenask&nbsp;确保查询延迟毫秒级别。另外，Havenask&nbsp;足够弹性，针对双11的流量急速变化，集群一键平滑扩缩容，变更对业务0影响，灵活应对流量峰谷。</p><p></p><h2>03&nbsp;Havenask&nbsp;开源开放，普惠开发者</h2><p></p><p>Havenask&nbsp;起源于阿里内部搜索业务需求，如今作为核心搜索引擎在阿里内部广泛应用，那么团队为什么选择将&nbsp;Havenask&nbsp;对外开源？</p><p></p><p>郭瑞杰表示，Havenask&nbsp;围绕着电商场景演化出来，在阿里核心头部业务、中台业务等均广泛使用。希望通过开源的方式让广大开发者参与进来，让&nbsp;Havenask&nbsp;迭代更快走得更远。以开源&nbsp;Elasticsearch&nbsp;为例，在十年时间中，Elasticsearch&nbsp;因为开源发展迅速，Havenask&nbsp;也期待通过开源吸引更多开发者参与进来，一起联合共创。</p><p></p><p>再者，近年来国际形势变幻莫测，人们对国产化替代诉求与日俱增。期望自主研发的&nbsp;Havenask&nbsp;能帮助一些企业实现国产化替代，让更多开发者和企业以更低的成本实现业务创新。</p><p></p><p>不仅如此，Havenask&nbsp;还提供商业版本来支持企业实现搜索场景、推荐场景、大模型应用场景创新。</p><p></p><p>“&nbsp;Havenask&nbsp;自开源后，在尚未开展过多活动的情况下，Star&nbsp;数快速突破&nbsp;1000，对我们来说还挺意外的，这也让我们坚定了后续持续建设开源&nbsp;Havenask&nbsp;的信心。”郭瑞杰说。</p><p></p><p>Havenask&nbsp;作为&nbsp;AI·OS&nbsp;体系的重要部分，沉淀了阿里&nbsp;10&nbsp;多年的搜索技术，整体系统庞大，采取逐步开源的形式对外开放，从2022年首发时的单机预览版，到如今刚刚发布的的分布式正式版，已经完成了&nbsp;Havenask&nbsp;几乎全部核心代码的开源。</p><p></p><p>在2023年9月份最新发布的&nbsp;Havenask&nbsp;1.0.0&nbsp;分布式版本中，支持读写分离与读写统一两种部署架构，可以分别满足开发者不同业务场景的需求，同时分布式版本提供基于机器资源池的集群自动化管理能力、动态表管理能力，降低开发者集群运维的成本；并且集成了自研的消息中间件，支持更完善的实时数据更新能力。</p><p></p><p>据郭瑞杰透露，在后续的版本中，&nbsp;Havenask&nbsp;会更聚焦开发者的真实使用场景，特别是大数据检索和智能检索等领域不断构建&nbsp;Havenask&nbsp;的开源生态，让&nbsp;Havenask&nbsp;更加广泛的应用在更多业务中，解决开发者面临的性能、成本、稳定性等核心问题。</p><p></p><p>与此同时，Havenask&nbsp;还开源了&nbsp;Havenask-federation（简称Fed）项目（<a href=\"https://github.com/alibaba/havenask-federation\">https://github.com/alibaba/havenask-federation</a>\"），在&nbsp;Havenask&nbsp;和&nbsp;Elasticsearch&nbsp;之间架起一条桥梁，方便&nbsp;Elasticsearch&nbsp;开源生态用户，快速迁移和扩展，实现优势互补。</p><p></p><h2>04&nbsp;Next&nbsp;Big&nbsp;Thing</h2><p></p><p>最近技术人话题离不开热门的&nbsp;ChatGPT，ChatGPT&nbsp;一经发布，大家认为被最早被颠覆的是搜索引擎。传统搜索引擎&nbsp;+&nbsp;ChatGPT&nbsp;将产生巨大化学反应，或将改写搜索引擎的产品形态。ChatGPT&nbsp;能更好地理解人们的搜索意图，为用户提供汇总答案，提供更准确的搜索结果，还能以自然语言来搜索，让搜索体验有质的提升。</p><p></p><p>郭瑞杰表示，有了&nbsp;ChatGPT&nbsp;能力加持，不仅在&nbsp;to&nbsp;C&nbsp;端搜索引擎发生巨变，在&nbsp;to&nbsp;B&nbsp;端也将催化诞生颠覆性的产品形态。其中&nbsp;to&nbsp;B&nbsp;端和&nbsp;to&nbsp;C&nbsp;端搜索引擎稍有差异，to&nbsp;B&nbsp;搜索引擎是面向企业，主要搜企业数据，而不是搜全网数据，更多的是围绕企业数据来提供更智能和更准确的答案。</p><p></p><p>针对不同行业的用户想基于大模型能力完成业务创新，Havenask&nbsp;除了在底层传统搜索引擎技术上提供帮助，也正在做如下两个方面的能力增强，并持续开源：一是向量检索。在大模型时代下，向量检索技术是大模型应用创新的基石，我们正在构建新的向量检索引擎&nbsp;VectorStore，预计性能大幅超越&nbsp;Milvus，期望能提供给开发者更高性能、更低成本的向量检索方案；二是大模型推理加速。将全面支持各种&nbsp;LLM（qwen、chatglm、baichuan、xverse、interlm、llama、falcon、mpt、starcoder&nbsp;等）的推理加速，支持量化、多机多卡分布式、上下文&nbsp;cache&nbsp;等多种特性，预计性能超越&nbsp;vllm&nbsp;15%，期望给开发者提供更低成本的大模型推理服务。</p><p></p><p>现在，我们看到阿里已先行一步：在&nbsp;2023&nbsp;阿里云峰会上，正式推出大语言模型“通义千问”，并宣布阿里所有产品未来将接入“通义千问”，进行全面改造。例如在网购场景，用户如果想开生日&nbsp;party，通义千问可以帮助生成生日活动方案和购物清单。</p><p></p><p>期待后续&nbsp;Havenask&nbsp;与“通义千问”联合创新，为人们带来更好地搜索体验，帮助企业和开发者量身定做适合业务发展的智能搜索服务，促进业务飞速增长，共享科技红利。</p><p></p><p>此外，基于&nbsp;Haveansk&nbsp;与“通义千问”打造的AI搜索产品——OpenSearch&nbsp;LLM&nbsp;智能问答版，也已在阿里云上为企业级开发者提供全托管、免运维的一站式对话式搜索服务，欢迎企业级开发者们试用。</p><p></p><p>心动不如行动，欢迎立即体验：</p><p></p><p>Havenask&nbsp;开源项目地址：<a href=\"https://github.com/alibaba/havenask\">https://github.com/alibaba/havenask</a>\"</p><p></p><p>Havenask-federation&nbsp;开源项目地址：<a href=\"https://github.com/alibaba/havenask-federation\">https://github.com/alibaba/havenask-federation</a>\"</p><p></p><p>OpenSearch&nbsp;LLM&nbsp;智能问答版：<a href=\"https://www.aliyun.com/activity/bigdata/opensearch/llmsearch?spm=5176.7946605.J_4098459070.4.15b38651FlNqqw\">https://www.aliyun.com/activity/bigdata/opensearch/llmsearch?spm=5176.7946605.J_4098459070.4.15b38651FlNqqw</a>\"</p><p></p><p>钉钉扫码加入Havenask开源官方技术交流群：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/78/78c5cfa61c64a55cdeb0655ac7eb2849.png\" /></p><p></p><p>近期活动预告：</p><p></p><p>2023年11月1日13:10-13:25，杭州云栖大会&nbsp;B3-4&nbsp;馆，Havenask&nbsp;开源正式版发布演讲</p><p></p><p>2023年11月1日14:40-15:10，杭州云栖大会&nbsp;C&nbsp;区舞台，Havenask&nbsp;开源细节与案例分享</p><p></p><p>欢迎开发者前往会场参加，或通过线上渠道收看关注</p><p></p><p>嘉宾介绍：郭瑞杰博士，2008年加入阿里巴巴，深耕阿里搜索领域开发十余年，先后负责&nbsp;iSearch4.5、问天2、问天3等多个搜索架构及产品的设计与开发工作，现任阿里巴巴智能引擎事业部云服务负责人，阿里云计算平台事业部搜索推荐云服务负责人，Havenask&nbsp;开源项目负责人。</p>",
    "publish_time": "2023-10-31 16:47:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]