[
  {
    "title": "基础设施即代码：只是漂移管理还不够",
    "url": "https://www.infoq.cn/article/wV78kwciwMAqeVxtAlfy",
    "summary": "<p></p><h2>什么是配置漂移？</h2><p></p><p>随着公司的发展，软件生产和交付系统往往会变得越来越复杂。随着而来也会发生配置上的经常变更。</p><p>&nbsp;</p><p>在最理想的情况下，变更会以良好的方式进行全面跟踪。但是，我们的生产环境并不完美，比如其中的许多修改都没有记录。如果是无关紧要的修改，那么对系统的影响会很小。如果这些修改导致系统变得不稳定，那么就会出现所谓的“配置漂移”。</p><p>&nbsp;</p><p>当新建并合并分支，以及将其他多个变更提交到主分支时产生某种冲突时，就会出现漂移。在小型团队中，开发人员可以及时告知同事他提交了变更。而在较大的团队中，分叉（fork）和合并之间的变更数量可能非常多，产生的冲突数量以及解决冲突耗费的时间都会更多。</p><p>&nbsp;</p><p>也许，代码漂移是最常见的漂移类型，但由于现如今软件架构和依赖关系的复杂性，配置漂移也很常见。开发人员可能会在分支创建完成后在过渡环境或预生产环境中新建一张表。可能会新建一个lambda表达式，或是更新SQS配置。如果开发人员的环境发生漂移，那么代码在旧版本上可能运行正常，但合并到经过更新的环境就会出问题。在一些简单的场景，这可能不会立即发生问题，但随着复杂性增加，应用场景越来越多，问题可能就出现了。大量的调试和返工在所难免，进而导致发布时间延期。在接下来的几节中，我们将介绍几种配置漂移的管理方法。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/04/04553074a4ad28fccadcdc598147b0f6.png\" /></p><p></p><p>图1 代码漂移示例</p><p></p><h2>配置漂移的影响</h2><p></p><p>代码会在多个环境中“传播”，从个人工作站到共享开发、测试、QA、过渡以及生产环境。如果其中某些环境之间存在不一致，就会导致安全漏洞和部署问题。如果你要处理的应用程序和服务需要遵从严格的法规或标准，那么开发过程就会面临风险。</p><p>&nbsp;</p><p>确保软件开发生命周期中各个环境共享相似的配置是一项非常费时的工作，这需要多个部门的配合。有时候，团队要花数周时间为不同阶段配置不同的环境。</p><p>&nbsp;</p><p>员工经常会对他们的环境做些小修改，但不会将它们传递给生产环境。这类配置漂移通常不为人所注意，但也会造成严重影响。如果长时间不注意，它们就会导致应用程序出问题，软件工程师可能要花费数小时来追踪并修复。他们需要排查代码和环境问题，找出可能导致异常行为的原因，而这些时间原本可以花在更有效率的事请上。</p><p>&nbsp;</p><p>随着时间流逝，产品开发生命周期延长。除了宕机外，这是环境漂移最常见的后果之一。<a href=\"https://blogs.gartner.com/andrew-lerner/2014/07/16/the-cost-of-downtime/\">Gartner 2014年发表的一篇文章</a>\"提到，IT公司每宕机1分钟平均损失约5600美元。</p><p>&nbsp;</p><p>此外，这类事件会导致开发停顿，开发人员不得不立即放下手头的工作，切换环境并着手解决事件。这种中断可能会导致代码Bug，因为我们的思路被中断了，有些想法可能会遗漏。这样就有恶性循环的风险。</p><p>&nbsp;</p><p>配置漂移会影响员工满意度，导致与开发体验相关的指标下降。</p><p></p><h2>减少漂移的方法</h2><p></p><p>配置漂移多少有些不可避免。不过有许多方法可以减少配置漂移。在接下来的内容中，我们将探讨漂移管理的一些实用方法。</p><p></p><h3>建立清晰的流程，并做好文档记录</h3><p></p><p>在处理配置漂移时，应该优先确定一套清晰的变更管理策略和流程。在许多情况下，人为错误是漂移的主要原因，可能是因为没有遵守流程，也可能是因为没有和其他团队沟通好。设计良好的变更管理策略可以保证所有必要的测试都已进行，并且可以保证在正式批准应用于生产环境之前，有某个有权限的人评审并评估这些变更的影响，从而降低产生副作用及未知问题的风险。你要记录好应该做哪些变更，什么时候做，以及在什么系统上做。</p><p>&nbsp;</p><p>应用基础设施变更的方法越少越好，最理想的情况是，只有一个通道可以进行更改，不管是应用、开发、过渡还是生产环境。</p><p>&nbsp;</p><p>除了推送变更的通道外，还需清晰地定义好权限并严格执行，将审批/发布权限授予一组预先选定的人，他们经验最丰富，而且根据以往的情况看最值得信任。</p><p>&nbsp;</p><p>任何不符合标准的情况都可能导致配置漂移。</p><p></p><h3>实现基础设施即代码（IaC）</h3><p></p><p>遵循<a href=\"https://en.wikipedia.org/wiki/Infrastructure_as_code\">基础设施即代码原则</a>\"并使用类似Terraform这样的解决方案，是消除配置漂移最有效的方法之一。</p><p>&nbsp;</p><p>使用代码定义环境，而不是通过手动变更来同步环境，这本身就容易出错。代码很清晰，而且在任意数量的资源上应用/运行都一样，没有漏掉什么东西或颠倒操作顺序的风险。</p><p>&nbsp;</p><p>借助代码版本控制（如<a href=\"https://www.github.com/\">Git</a>\"），基础设施即代码平台还可以提供详细的记录，包括现在和以前的配置，解决了修改没记录的问题，这还有一个额外的好处就是留下审计线索。像Terraform、Pulumi和Ansible这样的工具就是设计用来管理配置的，可以用它们识别漂移并发出信号，有时甚至还能自动纠错——这样，你就有可能在变更真正影响系统之前将其纠正过来。</p><p>&nbsp;</p><p>和任何工具一样，效果取决于你的用法。使用一款像Terraform这样的工具本身并不能使你所在的公司免疫配置漂移。还是要设计好流程，而且每个人都要遵守；即使所有的部署都依赖IaC，在某些情况下（如添加、移除或修改远程资源）还是会发生漂移。你也无法保证所有部署都通过IaC，因为在许多情况下，仍然可能使用CLI、API或Web浏览器手动部署。</p><p>&nbsp;</p><p>在Terraform 中，检测潜在漂移最简单的方法是重新计算并评估Terraform预期状态的计划：如果计划为空，则基础设施状态符合预期，什么都没变；如果计划中有需要采取的步骤（而且你也没有修改代码），则表示有来自其他通道的变更导致了配置差异。有时候，这可以自动修复，系统可以立刻回到预期状态，但你至少应该查下差异是怎么出现的——对流程做相应地调整，避免同样的事情再发生。</p><p>&nbsp;</p><p>在共享和发布容器化应用程序时，基础设施即代码显得更加有用。虽然容器镜像包含运行所需的所有代码和软件依赖，但一旦部署到云上，它常常需要额外的基础设施元素来实现可扩展性以及提高可靠性（如负载均衡器、监控、日志等）。</p><p>&nbsp;</p><p>在将应用程序成功部署到云上之后，你需要确保它流畅地运行，而且限制特定受众访问。也就是说，你需要围绕容器镜像重建所有基础设施，而完成这项工作最简单的方法就是使用描述所有必要配置的IaC模板。</p><p>&nbsp;</p><p>注意，环境间（如开发和生产）的差异对容器化应用程序的行为和可靠性有很大的影响。这是由包括数据库、服务在内的所有云原生资源所致，它们都位于应用程序之外，但对于其正常运行至关重要。从这个意义上讲，IaC让变更可再现且可预测，保证过渡环境与生产环境非常相似，生产环境代码部署和基础设施变更的风险大幅降低，而效率则有很大的提升。</p><p></p><h3>规程与IaC的优缺点比较</h3><p></p><p>频繁重复手动执行变更步骤（不同的人在多次执行时都要严格遵守）很容出错。意外事件一定会发生——不是“是否”的问题，而是“什么时候”和“什么方式”以及“多么经常”的问题。</p><p>&nbsp;</p><p>运行速度快、每次都能一致应用的已测试代码可以消除大部分问题，但最终，这都归于强大的流程，即变更管理。要制定策略，强制使用IaC，屏蔽应用变更的其他方式，还要确保所有团队成员都遵循质量相关的流程。最终，测试、代码评审、影响评估以及审批都归结为UI中的几次按钮点击或是CLI工具中的一次命令执行，但是，在这些最终动作发生之前开展的底层工作非常重要，仍然是由人手动完成的。</p><p>&nbsp;</p><p>IaC让你可以做得更好，消除问题，减少意外事件，加快前进步伐，但实际怎么用还是取决于你。</p><p></p><h3>使用环境即服务（EaaS）解决漂移</h3><p></p><p>变更管理和自动化将帮你创建并扩大业务规模，并建立以简单明了的流程为基础的工程文化。而环境即服务解决方案可以帮助你恰当地实施这一切。</p><p>&nbsp;</p><p>在文章开头，我们介绍过配置漂移对工程团队的严重影响：花费数小时排查代码和环境故障，试图找出意外行为的潜在原因。此外，静态环境更容易发生配置漂移，因为它们是可变的——为了达到某个状态，将更改应用到当前状态，但这个当前状态可能并不是每次都像我们期望的那样。从零开始创建不可改变的环境，肯定可以减少阻力，大大降低遇到错误的概率。</p><p>&nbsp;</p><p>从这个意义上讲，环境即服务解决方案可以对很多工程团队产生巨大影响，让他们可以无缝地访问测试及开发环境，把省下的时间增加到实际的产品开发中。随着时间的推移，工程团队将变得更加独立，也更加专注于产品。</p><p></p><h2>总结</h2><p></p><p>在可预见的未来，配置漂移仍然不可避免。而市场上正在实施的一些配置管理方法，如自动对比环境的当前配置和基线配置，能缓解配置漂移的副作用。EaaS解决方案，配合IaC和良好的变更管理，可以帮助你预防漂移，缩短开发周期。借助合适的网勾（Webhook），我们可以识别代码或基础设施变更。通过维护每个环境的状态，可以知道它是否发生了漂移，并决定是否触发一次自动更新。我们希望任何生产环境都不出现漂移。但是，生产环境服务于在线客户，通常需要满足特定的服务等级协议（SLA），而且有维护窗口，因此，这些环境会有手动触发的更新，或是持续部署调度器触发的更新。</p><p>&nbsp;</p><p>作者简介：</p><p>Roxana Ciobanu是Bunnyshell的联合创始人兼首席技术官。她是一名云爱好者，热衷于保障高可用性、性能调优和云架构安全。她曾担任DevOps和解决方案架构师，实现了云技术与运营和开发的完美结合。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/iac-configuration-drift/\">Infrastructure as a Code—Why Drift Management Is Not Enough</a>\"</p>",
    "publish_time": "2022-08-26 08:56:11",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "风靡全网的Web 3，到底是个啥？",
    "url": "https://www.infoq.cn/article/jsf43rxkftgecP5aQCNG",
    "summary": "<p>作者 | 刘燕，王强</p><p></p><p>近一年多来，技术圈最热门的话题一定少不了Web 3的身影。Web 3的追捧者将它视为互联网的未来，但更多人仍然对这一概念感到云里雾里。</p><p></p><p>Web 3的定义与落地时间都充满争议，甚至有人指责它只是又一次技术炒作。那么，究竟该如何理解Web 3？Web 3能否实现支持者的预期？针对这一话题，《InfoQ·极客有约》特别策划了一场「共话Web 3」专题直播。</p><p></p><p>本场专题直播共组织了两场线上圆桌论坛，邀请多位对Web 3有深入研究的专家共同探讨这一新晋技术概念，希望帮助国内开发者和感兴趣的朋友更好地了解Web 3。</p><p></p><p>第一场圆桌对话的主题是《爆火的Web 3，到底是什么》，本场主持人是MRS联合创始人，《人工智障》系列作者Mingke，对话凯云实验室（KEN Labs）CTO杨威理（William），腾讯云区块链资深架构师梁永甫两位嘉宾。</p><p></p><p>本文将圆桌对话的精华内容整理如下，以飨读者。</p><p></p><p></p><blockquote>主持人Mingke：从区块链到金融科技，从去中心化到元宇宙，今天的技术世界有很多新概念、新名词。它们之间的关系错综复杂，很容易让人感到迷惑。最近流行的Web 3是之前多个概念的整合与升级，但究竟什么是Web 3还并没有一个相对统一的准确定义。那么各位能否从自己的理解出发，尝试对Web 3下一个定义？</blockquote><p></p><p></p><p>梁永甫 ： 我个人认为Web 3并不是一种单纯而具体的技术。它可能是一种趋势，或者一个时代的一个代名词，其中包含了非常多的内容，包括未来可能出现的一些新的应用或技术类型都会包含在这个大范围之内。所以，Web 3是一个包含各种各样的技术、应用的抽象集合。</p><p></p><p>另一个角度讲，如果说Web 1是可读，Web 2是可读、可写，那么Web 3就是可读、可写、可运维。这是大家最容易认可的一种定义，因为它不是特别具体，也就容易取得共识。</p><p></p><p>我们先把视角转到互联网上。互联网本身包含了服务端和用户端两大部分。从这个角度来看Web 3和 Web 2的区别，会发现Web 3在构造和提供服务时是一个相对分布式、去中心化的系统。 在这样的系统中提供的服务是生态型的，也就是所有人都可以提供自己擅长的内容，这些内容组合在一起可以为用户带来完整的、比现有服务更完善的产品。正因如此，Web 3需要用区块链来构建去中心化的基础设施，从而建设这样的生态。</p><p></p><p>在用户端，Web 3的重点在于“可拥有”。 所谓“可拥有”是指用户对数据和资产的控制权更大，很多内容会交给用户来控制。在用户体验和交互层面，Web 3还会从现有的文字、图片、视频升级到VR、AR为主流选项。</p><p></p><p>杨威理： Web 3诞生之初的愿景是互联网之父Tim Berners-Lee提出的“语义网”的概念。所谓语义网，是指数据在整个互联网层面实现互联，使分散在各处的数据能够彼此交流和共同更新，例如用户只需要修改一次账户信息，他在所有网站的账户就都会同步更新等等。这样以来，互联网上的信息就会更加准确和智能。</p><p></p><p>为了实现这一目标，Web 3的先驱者提出的方案就是用一个去中心化的项目来存储包括身份信息在内的用户数据。通过这种方式，数据的所有权会交还到用户手中，从而改善数据隐私问题。但今天所提的Web 3和语义网的概念还是有区别的。虽然两者的目的都是要重塑互联网，解决数据孤岛问题，给用户更多控制权，但Web 3会更看重数据的不可修改性，而语义网并不把不可修改作为核心的关注点。</p><p></p><p></p><blockquote>主持人Mingke：既然两位都没有对Web 3下一个非常精确的定义，没有明确Web 3究竟应该具备哪些特性，那么我们该如何定义基于Web 3的原生应用？究竟哪种应用可以说是完全基于Web 3的特性开发出来的？还是说这种Web 3原生应用其实是并不存在的？</blockquote><p></p><p></p><p>梁永甫：我认为在刚才提到的用户体验、数据归属权和服务提供方式三个层面上，只要应用在一个层面上满足新一代的特征（VR/AR、用户控制更多数据、去中心化提供服务），就可以称它为Web 3应用。 或者说，并不是说这三种特征全部满足才叫Web 3应用。在互联网向Web 3进化的道路上，我们可能会见证许许多多新技术的诞生。这些技术会一点点改变这三个层面的应用形态，但这些层面不可能一步到位、一次性全部升级完成。所以在这个过程中，只要满足了一个层面的升级特征，就应该说这个应用是Web 3应用。</p><p></p><p>在这个进化过程中也会出现一些负面产物，有人会用一些应用来做一些不好的事情。但我们要意识到，整个Web 3的概念是中性的、包容的，是一个趋势、演进过程和未来方向，不能因为某一个应用好坏和成败来评判整个Web 3。</p><p></p><p>杨威理： 我们内部也经常有讨论，探讨Web 3，或者说下一代互联网中的用户会有哪些需求。这些需求中的大部分应该是新型的需求，与我们今天的日常应用场景是不一样的。比如我们每天看视频、刷微博、玩抖音，这些应用的用户可能并不在乎自己发的抖音是存放在中心化还是去中心化的网络上。他们在乎的可能是去中心化的应用是否能为抖音用户带来更好的经济回报。内容创作者也会关注Web 3能否带来一些变革，能否在广告和打赏这样的主流收益方式之外创造更多可能性。</p><p></p><p>所以我们非常感兴趣的是，Web 3的时代互联网应用能否延伸到更多领域。我们认为这是非常重要的，尤其是Web 3能否创造出一批比较扎实的需求场景，既能有稳定的商业模式，又能为用户带来真正的价值。 我认为这才是下一代互联网标志性的特性或者事件，有了这样的场景才会有真正的Web 3变革，否则这个名词就只能停留在概念上。</p><p></p><p></p><blockquote>主持人Mingke：很多人感兴趣的是，现在究竟有没有一些能够让普通用户感知到的Web 3应用，比如说更加去中心化的即时通讯应用这样的案例。能否请两位分享一下类似的案例，或者对这样的产品做一些评价？</blockquote><p></p><p></p><p>杨威理：目前我们看到很多Web 2时代的应用团队和公司在尝试将Web 2的应用类型迁移到去中心化网络上。比如说有团队在做去中心化的YouTube，他们提供了一些工具让用户可以将视频同步到去中心化的平台上。同时他们还提供了新的创作收益机制。这种方式并不一定带来颠覆的效果，就比如说微信的用户并不会因为某个类似的通讯应用是去中心化的就去选择后者。究竟终端用户需要的是怎样的应用形态，这个问题还是见仁见智。所以，目前的Web 3生态还是处于相对早期的状态，还是处在一个“建设时代”。</p><p></p><p>以存储为例，我们有去中心化的存储方案，但还不够强大，跟主流的云平台还不足以抗衡，还需要长期发展。在这样的背景下就会催生很多应用，它们的目的是帮助这些基础设施能够在现阶段表现得更好。这些服务的模式多多少少还是带有Web 2时代商业模式的影子，但大家依旧可以通过它们开始体验Web 3的基础设施。</p><p></p><p>梁永甫： 从一个更大的角度来说，所谓数字化是要做什么？数字化过程中的每一阶段，数字化的内容是不一样的。在每一个阶段，我们不会关注之前已经数字化的内容，而是会关注还没有被数字化的事物。比如说Web 2时代，很多资产是没办法数字化的。但有了区块链之后，这些资产的数字化道路就被打通了，所以新技术让数字化跨入一个新的阶段。</p><p></p><p>换句话说，数字化是一种增量式的发展过程，Web 2提供的是Web 1的增量服务，而不是要颠覆Web 1的事物；Web 3也不会颠覆Web 2的模式，而是会创造一种全新的模式，通过去中心化的服务方式创造很多之前没法创造出来的事物。这就是Web 3时代的一个标志。</p><p></p><p></p><blockquote>主持人Mingke：很多人也在问，Web 3能够提供哪些独有的能力？比如说一个应用在Web 2时代做不到的事情，到了Web 3时代就可以实现了吗？</blockquote><p></p><p></p><p>杨威理： 从应用的层面来讲不好谈，我可以换个角度，从经济利益分配这个角度来聊聊。拿YouTube举例来说，用户在平台上发视频后，通过广告收入来获取回报。谷歌从YouTube获得的广告收益中分一部分给创作者，但这块收益并不是一般的内容创作者可以议价的。</p><p></p><p>但在去中心化的网络机制之下，这个经济模型发生了改变。平台并不存在一个中心化的实体来分发收益，相当于我们就像在菜市场卖菜一样可以自己定价。创作者可以有相对自由的运营空间，在这种空间之下每个内容创作者得到的回报也会更高。如果我们还是以传统的Web 2的模式去思考这个问题，我觉得我们很难做出比Web 2时代更好的应用；除非我们衍生出一个全新的需求，或者创造出全新的、这些大厂商无法支持的技术，但这样的概率也是很小的。</p><p></p><p>所以一方面来说我们要从用户需求层面去挖掘，另外可能是在经济模型上推动变革，才能让消费者去主动选择。否则用户还是会倾向于使用他最习惯的一些Web 2应用。</p><p></p><p></p><blockquote>主持人Mingke：从这个角度来讲，是不是可以说，短期看来我们还看不到具备非常明显的Web 3特征的应用？</blockquote><p></p><p></p><p>杨威理： 在国内环境中，我至少目前没有看到有很明显特征的应用出现。</p><p></p><p></p><blockquote>主持人Mingke：这里引出一个问题 —— Web 3需要怎样的土壤才能更好地发展？除了技术，还有经济、生态，以及开发者和消费者的思维等角度来看，什么样的土壤更适合发展Web 3？</blockquote><p></p><p></p><p></p><p> 杨威理： 这里有一个挺有趣的现象可以和大家分享一下，最近我们发现在印度以及非洲的一些国家，Web3的接受度、流行度非常高。我们可以从这个现实来思考一下，或许能够从侧面解答上面的问题。</p><p></p><p>首先，非洲国家的数字货币在全球是发展最快的。一方面是因为当地用户采用数字货币可以很便利地转账和国际汇款，另一方面也因为非洲国家的银行服务相对落后、货币不稳定、信用体系建设不完善。方方面面的因素决定了他们无法提供一个非常稳定的基础金融服务。所以采用这种低成本运营和维护的数字货币作为替代解决方案，对他们来说是个不错的选择。而且这些国家经济相对落后，需要快速发展，数字货币恰好满足了他们的需求。</p><p></p><p></p><blockquote>主持人Mingke：听上去有点像当年的电子支付在中国的普及过程。中国用户跳过了信用卡时代，直接迈入了移动支付世界。永甫老师又是怎么看待这个话题的？哪些环境特征适合Web 3的成长？</blockquote><p></p><p></p><p>梁永甫：我认为Web 3的成长与大环境的变化并不是强相关的。 比如说现在Web 3最流行的应用是NFT，那么无论在国外还是国内，用户都可以买到NFT，从而体验到Web 3应用。从这个角度来看，我们需要思考的还是Web 3究竟能够给用户带来什么价值。比如说非洲用户没有微信和支付宝，他们就会通过Web 3数字货币来满足自己的支付需求。我们需要挖掘Web 3能够给用户创造的各种场景，这个才是最重要的。至于监管环境之类的因素影响并不是很大，称不上是一种决定性的因素。</p><p></p><p>杨威理： 就梁老师提到的NFT这个话题，我认为我们可以从中做一些思考。比如说Twitter现在开始对接NFT，用户可以购买NFT作为自己的头像。这听起来并不是一种刚需，但我认为这是一个起点。或许这些NFT创作物，将来就是我们每个人在元宇宙或者虚拟世界里的个人表现形式。随着我们大家的生活方式越来越多地映射到元宇宙当中，这些NFT就有了真正的使用价值。</p><p></p><p></p><blockquote>主持人Mingke：就去中心化这个话题，我想到了一段历史。在互联网发展早期，电子邮箱协议是开放的，人人都可以用这个协议来搭建自己的邮箱体系，大家遵循相同的协议就可以互通。但并不是所有人都会这个技术，所以我们有了Gmail这样的邮箱服务。自然而然，这样的服务就成了中心化的平台。从这个角度上来讲，这种中心化的过程让更多的人享受了技术成果，两位老师是如何看待这个问题呢？</blockquote><p></p><p></p><p>梁永甫：不管未来的互联网是什么样的形式，最核心的部分还是要给用户创造价值、提供服务。 有些服务可能更适合去中心化的形式，还有一些依旧是中心化的形式更好。所以我们还是要从用户需求出发，看看用户究竟想要什么产品，这种产品适合哪一种形式，哪一种形式更好，我们就选择哪一种。我们要挖掘那些更适合去中心化形式的应用，这就是Web 3时代，我们需要重点去做的事情。</p><p></p><p>杨威理： 我认为大趋势并不是说在一个战场上拼杀得你死我活。中心化有它的好处和优势，去中心化也自然有它的不凡之处。我们还是以电子邮件为例，像谷歌提供的Gmail方便大家使用，同时也提供了很不错的存储空间，所以我们基本上不需要操心垃圾邮件的的空间占用问题。这是因为谷歌提供了一些补贴，其他一些小厂商很难提供这样的补贴，所以就需要收取一些费用，自然很难与谷歌竞争。</p><p></p><p>那么在中心化的邮件服务领域里有没有去中心化的可能性呢？举个例子，我们是否能够构建一个去中心化的邮件服务器网络，通过一定的激励机制激励邮件服务器节点稳定提供服务？我们或许无法保证用户可以免费使用，但至少可以做到更低的成本，甚至让用户自己都可以参与建设服务器节点来抵扣一些开支。 总之Web 3给我们带来了很多不同的玩法，也是大家乐意去探索的一个很重要的领域。</p><p></p><p></p><blockquote>主持人Mingke：最后这个话题，请两位嘉宾分享一下自己对下一代网络的看法。网络是由节点和边组成的，需要有协议让点与点能够连接起来。下一代网络的组成形态可能是非常多样的，那么下一代网络的节点、边和协议会有哪些变化，和现有节点等又有哪些区别？</blockquote><p></p><p></p><p>梁永甫： 还是拿邮箱通讯为例。邮箱通讯是点对点的，比如我们通过一个邮箱服务器通讯，我跟你通信只有我们两个能看到。这意味着这个网络连接在数据层面是双向的，或者说是线状的。</p><p></p><p>但实际上，在未来我们想要构建的是一个真正的网状网络。比如说区块链上的一笔转账交易，不仅转账双方能看到，网络中的其他所有人也都能看得到。这是非常大的变化。</p><p></p><p>比如说现在买房要先找中介，再经过房管局登记再付款，那么未来要构建的是中介、房管局和买家卖家是多方共同参与交互网络。比如说我找了一个中介，房管局知道了，房主也知道了；我跟他签了一个协议说我要买房了，那么房管局那边知道了，银行那边也知道了，到时候就可以直接去放款了。这个形式可以改变我们提供服务的方式，我只要做一个动作其他人就全都能看到，其他人各自做自己的事情就好，最后房子过户的过程就顺利完成了。我认为这种网状网络是真正的变革，可能会激发一些新的服务形式。目前来看，可能区块链是用来构建这种基础设施的一个比较好的选择。</p><p></p><p>杨威理： 我基本上也赞同。另外补充一点，目前Web 3的话题里大家关注比较多的就是去中心化的身份验证。 比如我们向警察出示驾照，多多少少会展示一些个人隐私数据。那么如何在不揭露自己这些隐私数据的同时能证明自己是有驾照的？这就是去中心化身份验证机制要做的事情，在Web 3社区里也已经看到一些相关的产品和服务。</p><p></p><p>从技术实现层面来讲，Web 3应用通常的做法是设置一个钱包。 用户个人的身份信息会存储在一个安全的网络之上，而需要公开展示的驾驶记录、病历之类的信息由相关机构颁发。颁发的这些数据并不留存在用户自己的钱包里，但用户有这个数据的密钥。当用户要出示这些信息的时候，可以向别人分享这个密钥，并让授权机构去验证。用户自己不需要构建服务器、节点平台这些基础设施，他只需要把自己的身份信息以及关键的密钥信息存储在自己可控的安全存储上即可，比如说软硬件形式的数字钱包里面。</p><p></p><p></p><blockquote>主持人Mingke：在某种意义上来讲，上面由第三方提供的服务不只是针对一个人，应该是提供给多个人，那是不是就形成了一个服务对很多用户的中心化场景呢？</blockquote><p></p><p></p><p>杨威理： 我觉得这些场景还不算中心化，因为我们可以认为它是一个软件服务的供应商，大家都是通过去中心化的协议来提供服务。</p><p></p><p>梁永甫：去中心化并不意味着什么东西都要我自己去做，我还是需要别人给我提供服务的。另外服务也不等于中心化，所有的服务都由一方提供才是是中心化 ，比如说有人给我提供了存储服务，有人给我提供了基于钱包的身份服务，那么存储和身份对用户而言是一个完整的服务，也就是说这么一个完整的服务的不同部分是由不同的厂商给我提供，从这个角度看，这个服务反而是去中心化的。</p><p></p><p>主持人Mingke： 非常感谢两位来分享对Web 3的看法，我们这一场的讨论就到这里。接下来的第二场圆桌讨论主题是《Web 3的核心基础设施》，下一篇文章将总结第二场讨论的内容供读者品鉴。</p>",
    "publish_time": "2022-08-26 10:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "特斯拉公布自研超算Dojo更多细节：计算模块为专为大型机器学习模型训练而生，可编程性决定成败",
    "url": "https://www.infoq.cn/article/7iTKNGigN3SLheqHNrtA",
    "summary": "<p></p><blockquote>早前在回答为什么要<a href=\"https://www.infoq.cn/article/fysqkmvmp9fuen02ibvj\">自研超算 Dojo </a>\"时，马斯克曾表示，“解决自动驾驶的唯一方法是解决现实世界中的 AI 问题，无论是硬件还是软件，而这也是特斯拉正在做的事情。除非一家公司具有很强的 AI 能力以及超强算力，否则很难解决自动驾驶难题。”</blockquote><p></p><p></p><h2>特斯拉公布自研超算 Dojo 细节</h2><p></p><p></p><p>近日，在 Hot Chips 34 大会上，特斯拉公布了大量<a href=\"https://www.theregister.com/2022/08/24/tesla_supercomputer_dojo/\">自研超算 Dojo 的细节</a>\"，并发布了两个有关 Dojo AI 超级计算机的深入演示。</p><p></p><p>本质上，Dojo 是一种可组合的规模化超级计算机，与我们熟悉的五百强超算系统不同，Dojo 是一套完全可定制架构，全面涵盖计算、网络、输入/输出（I/O）芯片，乃至指令集架构（ISA）、供电、封装和冷却。所有这些都服务于同一个目标：大规模运行定制化机器学习训练算法。</p><p></p><p>据了解，Dojo 发布于 2021 年 8 月特斯拉 AI Day，特斯拉硬件工程高级总监、Dojo 项目负责人 Ganesh Venkataramanan 当时曾上台就 Dojo 的主要性能进行了展示。</p><p></p><p>Ganesh Venkataramanan 表示，马斯克想要一台超快的训练计算机来训练 Autopilot。因此，Project Dojo 诞生了。Dojo 架构拥有一个大规模计算平面，极高宽带和低延迟。作为 Dojo 架构的重要组成部分，D1 芯片采用 7 纳米制造工艺，处理能力为每秒 1024 亿次。</p><p></p><p>Venkataramanan 认为，将一组这样的芯片放置在单个“训练片”上，以提供每秒九千万亿次的计算能力，并将 120 个芯片放在多个服务器机柜上，达到每秒超过 1 千万亿次的计算能力。这些芯片可以帮助训练模型来识别特拉斯汽车摄像头中收集到的各种物品。训练模型需要大量的计算工作。</p><p></p><p>在近期举办的 Hot Chips 34 大会上，Venkataramanan 在主题演讲中称，“现实世界中，海量数据的处理只能通过机器学习技术来实现，而由此支撑起的应用场景则包括自然语言处理、基于视觉设计的自动驾驶、与日常环境交互的机器人技术等。”</p><p></p><p>他同时承认，传统的分布式工作负载扩展方法并不能跟上机器学习对于处理速度的需求。时至今日，摩尔定律已经帮不上多大的忙，CPU 加 GPU 的组合、或者是极少数配备专用 AI 加速器的方案，也远未达到人们对于大规模 AI/ML 训练系统的性能预期。</p><p></p><h2>Dojo 的三明治式数据中心</h2><p></p><p></p><p>Venkataramanan 表示，“在过去，我们会先制造芯片，再把它纳入封装、部署进印刷电路板、接入系统，最后把系统安装在机架内。”问题在于，每当数据从芯片移向封装、或者由封装移出时，都会产生相应的延迟和带宽损失。</p><p></p><p>为了克服这些限制，Venkataramanan和他的团队决定从零起步、重新设计。“在当初接受马斯克的面试时，他就问我能不能在CPU和GPU之外，给AI场景一个新的答案。我们整个团队一直在为此而努力。”</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/20/20fcc1763837ad781263a77f765a8afb.png\" /></p><p></p><p>于是，Dojo训练单元应运而生。这是一个独立的计算集群，体积约为1.5立方英尺，能够在15 kW液冷封装中实现每秒556万亿次FP32浮点运算。每个单元都配备有11 GB的SRAM，并在整个堆栈中以自定义传输协议通过9&nbsp;TB/s结构实现互连。</p><p></p><p>Venkataramanan介绍称，“这个训练单元以前所未有的集成度，把计算机中的内存、电源、通信等机制整合了起来，无需任何额外交换设备。”</p><p></p><p>这个训练单元的核心就是 Dojo D1，一款包含500亿个晶体管的芯片，采用台积电7纳米制程工艺。特斯拉表示，每块D1芯片能够在400瓦最大散热功率下实现每秒22万亿次的FP32浮点运算。此外，该芯片还能支持包括自定义计算在内的其他多种浮点运算。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/83/83bb1f2812b1d6639ec2963fb21ebab5.png\" /></p><p></p><p>Venkataramanan表示，“从每平方毫米的晶体管密度来看，Dojo D1可能是当前最先进的技术成果。”</p><p></p><p>特斯拉将25块D1裸片用台积电的代工技术封装起来，由此“以极低延迟与极高带宽实现了对大量计算元件的集成”。然而，片上系统设计和垂直堆叠架构，也在供电层面带来了新的挑战。</p><p></p><p>根据Venkataramanan的介绍，目前大多数加速器都会将电源直接放置在芯片附近。他解释称，虽然也能通过验证，但这种方法使得加速器的大部分区域只能专门放置这些组件。而Dojo则反其道而行，选择直接通过芯片底部传输电力。</p><p></p><h2>组装成形</h2><p></p><p></p><p>“我们可以用这个训练单元构建起整个数据中心甚至是整栋服务器大楼，但训练单元只是计算的部分，我们还得考虑资源的实际交付。”</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7f/7ff849ded2643da665e8bc593720a6f4.png\" /></p><p></p><p>为此，特斯拉开发出Dojo接口处理器（DIP），负责充当主机CPU和训练处理器间的桥梁。DIP还可以提供共享高带宽内存（HBM）与高速400 Gb/s网卡。每个DIP包含32 GB HBM，最多能够将五块DIP卡以900 GB/s的速度接入同一训练单元，因此主机总传输速率达4.5 TB/s、单个单元&nbsp;HBM容量可达160 GB。</p><p></p><p>特斯拉的V1双单元配置方案就一口气用上了150块D1芯片，能够支持四块主机CPU、每台主机配备五块DIP卡，号称能实现百亿亿次BF16或CFP8性能。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f3/f3c9a55dcac89f582dec1c603ecb6660.png\" /></p><p></p><p>Venkataramanan称该架构帮助特斯拉成功克服了英伟达与AMD等传统加速器中的固有限制。“传统加速器的工作原理，是将整个模型部署到各个加速器内、多次复制，让数据流经每个加速器。但随着模型体量越来越大，结果会怎么样？这些加速器的内存可能不足以存放完整模型，到时候就没有训练效果可言了。”</p><p></p><p>这其实并不是新问题。英伟达的NV-switch就能够跨多个GPU实现内存池化。然而，Venkataramanan认为这不仅增加了复杂性，而且引入了额外的延迟与带宽损失。“我们从设计之初就考虑到了这一点，所以我们的计算模块和每块裸片都是专为大型机器学习模型的训练而生。”</p><p></p><h2>可编程性将直接决定Dojo的成败</h2><p></p><p></p><p>很明显，这样一套专门的计算架构需要与之配套的特殊软件堆栈。Venkataramanan和他的团队也意识到，可编程性将直接决定Dojo的成败。</p><p></p><p>“在我们设计这些系统时，最关注的问题就是软件的编程便捷性。研究人员可不会坐等我们手动编写出新内核之后，再尝试运行新算法，人家直接就换架构了。”</p><p></p><p>为此，特斯拉放弃了使用内核的思路，开始围绕编译器设计Dojo架构。“我们决定使用PiTorch，创建出中间层以通过并行化扩展底层硬件。底层的一切都是编译代码，这也是保证软件堆栈适应未来所有工作负载的唯一方法。”</p><p></p><p>尽管一直在强调软件灵活性，但Venkataramanan也承认他们的平台目前只能在实验室内支持特斯拉自己的工作负载。</p><p></p><p>他总结道，“我们首先得关注内部客户的需求。马斯克已经公开表示，这些成果将随时间推移逐步向其他研究人员开放，但我们还没有制定具体的开放时间表。”</p>",
    "publish_time": "2022-08-26 14:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "一文详解门限签名的技术原理与落地实践",
    "url": "https://www.infoq.cn/article/XUr1mzVlo4WGcGSEDz1T",
    "summary": "<p></p><h2>什么是门限签名</h2><p></p><p>&nbsp;</p><p><a href=\"https://www.infoq.cn/topic/Blockchain\">区块链技术</a>\"与签名<a href=\"https://www.infoq.cn/topic/Algorithm\">算法</a>\"缔结颇深，从安全、效率到流通，签名算法都在影响着区块链网络的特性及稳定。个人及机构对账户密钥管理的需求逐渐强烈，也催生出一批相关应用，对于用户而言，管理签名其实就是管理密钥。而在多链的情况下，多签或许不是密钥管理的最佳选择——用多签通过合约的方式来管理密钥，使用成本高，<a href=\"https://www.infoq.cn/topic/Security\">安全风险</a>\"高。除了多签技术之外，在区块链世界中逐渐兴起的门限签名技术也是一种重要的共识工具。</p><p>&nbsp;</p><p>门限签名（Threshold Signature Scheme，TSS）是数字签名的一个重要分支，它是一种基于安全多方计算（Secure Multi-Party Computation，MPC）的密码学技术，也是 MPC 密钥管理的重要研究方向。</p><p>&nbsp;</p><p>门限签名特点是一个签名一定是由一个私钥产生，然而这个私钥不会被任何人完整掌握，而是会以某种方式分成很多碎片，这些碎片可以被多人同时持有，然后通过 MPC 协议，保证这些碎片不需要全部被拼起来就可以直接产生一个合法的签名。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c5/c56eea8b820b95341fa8bf6cbe95dd00.jpeg\" /></p><p>图1 区块链上的 MPC 门限签名技术</p><p></p><p>在与区块链的结合应用中，门限签名的优势在于签名的生成是通过链下的 MPC 协议产生的，其结果是更加安全，避免了合约被黑客攻击的风险。因为门限签名与合约模块是完全解耦的，合约不需要理解签名的协议，它只要确认签名的有效性，这与传统的合约验签模式完全一致的。此外，合约的设计策略可以更加灵活，因为除了验签外的大部分流程都搬到了链下，使用方可以根据场景制定自己的碎片管理策略。</p><p></p><p>另一个重要的应用场景是密钥管理。基于 MPC 的密钥管理，一方面可以安全地存储密钥，单一或者小批量碎片的丢失，不会对该密钥的安全性有任何影响；另一方面是让个人或者企业能够更方便、更安全、满足业务逻辑地使用密钥。</p><p></p><h2>门限签名的算法原理与落地实践</h2><p></p><p>&nbsp;</p><p>目前针对门限签名的研究机构数量在递增，但已达到产品级标准的不多，本次我们以Open TSS 为例详解门限签名。</p><p>&nbsp;</p><p>Open TSS由 LatticeX Foundation 发起和支持，理论依据来源于发表在顶级密码会议（Asiacrypt 2021）的论文 <a href=\"https://eprint.iacr.org/2022/297\">DMZ+21</a>\"，目前Open TSS最新协议代码库正式开源上线，代码采用安全高效的Rust实现，支持一站式ECDSA MPC密钥生成(Keygen)、MPC签名(Sign)。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/57/5784c8414e6f56930d890265ffa150d6.jpeg\" /></p><p></p><p>可以看到当前版本（0.1.2）支持 <a href=\"https://en.wikipedia.org/wiki/Elliptic_Curve_Digital_Signature_Algorithm\">ECDSA</a>\"，其他算法如 EdDSA、BLS 等将很快被整合。下面我们介绍基于 [DMZ+21] 的多方 ECDSA。</p><p></p><h3>多方ECDSA</h3><p></p><p>ECDSA 被广泛用于密码货币，如 BTC、Ethereum（secp256k1曲线）等。</p><p></p><p>多方 ECDSA 协议（{ t, n }-门限签名方案），它允许 n 个参与方联合生成一个共同的公共验证密钥，以及 n 份相应的秘密签名密钥，并允许任何至少由 t + 1 个参与方组成的子集安全地分布式签署一个给定的消息，而 t 个或更少的参与方组成的集合则不能进行签名。</p><p></p><p>本库中的多方 ECDSA 协议是基于类群实现的。它目前包括两个协议：</p><p>密钥生成，用于创建秘密分片。签名，用于使用秘密分片来生成签名。这可以分为两个阶段，离线和在线。离线阶段与要签名的信息无关，可以提前计算。只需将信息（和离线阶段的输出）传递给在线阶段，就可以很快得到签名。</p><p></p><h3>功能使用</h3><p></p><p>目前，ECDSA 由两个功能模块组成，包括密钥生成、签名，签名功能分为离线阶段与在线阶段。</p><p>在使用上，对于上面的每个功能，只需要三个步骤。这里假设 (t, n) = (1, 3)，参与方的 id 为 1， 2， 3，分别以 P1，P2，P3 表示。</p><p></p><h3>密钥生成</h3><p></p><p>第1步。新建一个 KeyGenPhase 对象。</p><p><code lang=\"javascript\">let partyid = \"1\".to_string(); // P2, P3 are similar. let params = Parameters {\nthreshold: 1,\nshare_count: 3,\n};\nlet party_ids = vec![\"1\".to_string(), \"2\".to_string(), \"3\".to_string()];\nlet mut keygen = KeyGenPhase::new(partyid, params, &amp;Some(party_ids)).unwrap();</code></p><p>第2步。通过调用 process_begin 开始，它返回下一轮要发送的信息。</p><p><code lang=\"javascript\">let sending_msg: SendingMessages = keygen.process_begin().unwrap();</code></p><p>根据 SendingMessages 的类型（广播，P2P等）和内容，我们可以将索引（from）和消息（msg）一起打包发送给其他参与者。</p><p><code lang=\"javascript\">match sending_msg { SendingMessages::BroadcastMessage(msg) =&gt; {\n// broadcast the msg to all(including self).\n}\nSendingMessages::P2pMessage(msg) =&gt; {\n// send according to the k,v in the msg. k is the index which v will to be sent to.\n}\nSendingMessages::SubsetMessage(msg) =&gt; {\n// send according to the k in the party_ids or subset(used in sign phase). k is the in\n}\n_ =&gt; {}\n}</code></p><p>第3步: 通过 msg_handler 处理消息。</p><p>当收到消息后，会得到 recv_from 和 recv_msg，然后把它们传给 msg_handler，它返回一个结果或下一轮要发送的消息。</p><p><code lang=\"javascript\">loop {\n// let (recv_from, recv_msg) = According to the last round of SendingMessages let recv_from = \"\".to_string();\nlet recv_msg = vec![0u8];\nlet sending_msg = keygen.msg_handler(recv_from, &amp;recv_msg).unwrap(); match sending_msg {\nSendingMessages::KeyGenSuccessWithResult(msg) =&gt; {\n// got the keygen result break;\n}\n_ =&gt; {\n// other sending messages, ref Step 2.\n}\n}\n}</code></p><p>一旦收到 SendingMessages::KeyGenSuccessWithResult ，就表示此阶段完成。这里是一个密钥生成的样例：</p><p><code lang=\"javascript\">{\n\"index\": \"1\", \"participants\": [\n\"1\",\n\"2\",\n\"3\"\n],\n\"pubkey\": {\n\"pk\": [ \"10ec64d0a73c134c53ed764e86743397bab3bb06bdbbd638321b87eda9c6614e\", \"6b7df1b8b41c41fc69fef0d87fc8ee9d01c021936d3b44cd62883894cd60de14\"\n],\n\"share_pks\": {\n\"1\": [\n\"7a39ace81396d9c65dfb8f4c8ebdf3d5850447e129edbac052558b483b01ba52\", \"d942c292f40e65715f722b1db87d0ceaa122f9d6457eacffbd021653b0a6f65\"\n], \"2\": [\n\"6b31a24d2705971d18fffbdc2edbf4e97d01c2b4aea75df2a01566f03c269804\", \"5f94b59a0a97d604e356ca21c27b64c0f5dfc4e8315e4be8179c5292a8b6d015\"\n], \"3\": [\n\"79a7c9632cbfd98f890d9d4670ac301fda42db178b9b8ec2a2860e44488130da\", \"af7d69f73529d8235ae6dc9f896bd81830777ff9667d9ab1fc5b37599c712378\"\n]\n}\n},\n\"privkey\": {\n\"cl_sk\": \"1b557b69c49c0715403f618907a051c012adc57e9ea6b17aa912d68b6056b1d24b5c10a36269ac03 \"ec_sk\": \"a23ae304a46c36bbf52e1373daa4446dda3f3b1b721a77c84a2ec86f54e6970c\",\n\"share_sk\": \"f869bd11e46d036cdd81ad9940c9d510d24114bba12edfa626a966677058ff5a\"\n}\n}</code></p><p></p><h3>签名-离线阶段</h3><p></p><p>第1步。与密钥生成类似，新建一个 SignPhase 对象。</p><p><code lang=\"javascript\">let partyid = \"1\".to_string(); // P2, P3 are similar. let params = Parameters {\nthreshold: 1,\nshare_count: 3,\n};\nlet subset = vec![\"1\".to_string(), \"2\".to_string()]; // The set of parties that involved in si let keygen_result = \"\".to_string(); // The output of KeyGen\nlet mut signoffline = SignPhase::new(partyid, params, &amp;subset, &amp;keygen_result).unwrap();</code></p><p>这里的 subset 就是参与签名的各方集合，是所有参与密钥生成的一个子集。</p><p>第2步、第3步：与密钥生成一样。当收到 SendingMessages::SignOfflineSuccessWithResult ，就表示此阶段完成。</p><p></p><h3>签名-在线阶段</h3><p></p><p>第1步。类似的，新建一个 SignPhaseOnline 对象。</p><p><code lang=\"javascript\">let offline_result = \"\".to_string(); // The output of SignOffline\nlet message_bytes = vec![0u8; 32]; // The hash value of the message to be signed, 32 bytes. let \nmut signonline = SignPhaseOnline::new(&amp;offline_result, message_bytes).unwrap();</code></p><p>第2步、第3步：与密钥生成、签名离线阶段一样。当收到SendingMessages::SignOnlineSuccessWithResult ，就表示此阶段完成。</p><p>从安全角度考虑，离线阶段的结果只能使用一次。整个在线阶段只需要几毫秒即可完成。</p><p></p><p>这里是一个签名的样例：</p><p><code lang=\"javascript\">{\n\"s\": \"14af6f72d8bd26faccd75ff092544d15a3dce5d97e897773b515cd70ab0453e7\", \"r\": \"3687024517eb44de2cfaa6166866c9bd2587090317a4d12521b571c7509319b4\",\n\"recid\": 0\n}</code></p><p>一份<a href=\"https://github.com/LatticeX-Foundation/opentss/multi_party_ecdsa/src/protocols/multi_party/dmz21/local.rs\">本地代码</a>\"显示了如何使用这些功能。参考<a href=\"https://github.com/LatticeX-Foundation/opentss/docs/ECDSA.md\">这里</a>\"了解更详细的使用说明。</p><p></p><h3>性能表现</h3><p></p><p>我们来看看OpenTSS的性能如何，与最先进的协议进行比较。为了进行公平的比较，我们用 Rust 实现了两个多方 ECDSA，包括我们的协议和 [<a href=\"https://eprint.iacr.org/2020/084.pdf\">CCL+20</a>\"] 中的协议。椭圆曲线是 secp256k1，类群的判别式的位长选择为 1827，这确保了我们的协议具有 128 位的安全性。运行时间是在 Intel(R) Core(TM) i7-9700K @ 3.6GHz 的单核上测量的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f1/f1b9eafde795277e822f2368a38d7ee6.jpeg\" /></p><p></p><p>如上表（来自论文第 7 节）所示，进行了具体比较。与基本上基于 [<a href=\"https://eprint.iacr.org/2019/114.pdf\">GG18</a>\"] 的 [CCL+20] 相比，可以看到OpenTSS的多方 ECDSA 协议的改进是非常明显的。它主要体现在密钥生成阶段。</p><p></p><p>在计算复杂度方面，OpenTSS的多方 ECDSA 协议比 [CCL+20] 中的协议在 κ = 40(κ = 128) 时的密钥生成阶段快 4 倍（12 倍），这在理论（详见论文）和具体方面都可以看到。OpenTSS构造的签名阶段比 [CCL+20] 中的略好，在具体方面大约快 10%。</p><p></p><p>在通信方面，由于OpenTSS消除了昂贵的交互式设置阶段的需要，OpenTSS的协议在密钥生成阶段优于 [CCL+20] 中的协议，其差异根据参与方的数量 n 和门限 t 而变化。虽然在签名阶段通信开销稍大，但OpenTSS的解决方案仍然是同一数量级的。</p><p></p><h2>总结</h2><p></p><p>可以看出，门限签名协议将成为众多机构持续投入研究的方向、为开源社区做贡献、在不远的将来，相信以Open TSS为代表的产品将向区块链安全技术服务商的方向发展，为区块链钱包、托管企业提供底层架构服务。</p><p></p><p>Open TSS项目地址：<a href=\"https://github.com/LatticeX-Foundation/opentss%E3%80%82\">https://github.com/LatticeX-Foundation/opentss</a>\"<a href=\"https://github.com/LatticeX-Foundation/opentss%E3%80%82\">。</a>\"</p><p></p><p>参考文献</p><p>1. <a href=\"https://eprint.iacr.org/2022/297\">Promise Σ-protocol: How to Construct Efficient Threshold ECDSTSSA from Encryptions Based on Class Groups.</a>\"</p><p></p><p>相关课程：</p><p><a href=\"https://www.infoq.cn/video/kHp21mRk7rBxWQ8KDyhA\">ZK 训练营第一课：ZKP 密码学基础知识</a>\"</p><p><a href=\"https://www.infoq.cn/video/DMUmGWpLVqL21TDZ04bu\">ZK 训练营第二课：ZKP 经典协议</a>\"</p><p><a href=\"https://www.infoq.cn/video/9VrhU74b6JYO9Yk6aeXj\">ZK 训练营第三课：ZKP 电路应用导论</a>\"</p><p><a href=\"https://www.infoq.cn/video/ERqbLpof2kk6ZyNfDmww\">ZK 训练营第四课：基于 ZK 协议的机器学习隐私保护设计</a>\"</p>",
    "publish_time": "2022-08-26 14:52:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "圆桌对话：如何协同构建统一生态？",
    "url": "https://www.infoq.cn/article/KQ7eA197Jew6cgsphj68",
    "summary": "<p></p><blockquote>在&nbsp;<a href=\"https://xie.infoq.cn/article/250a610f1def4b3cd8331006b\">2022 开放原子全球开源峰会</a>\"上，三大运营商代表集结龙蜥专场圆桌环节，共同参与讨论了“如何协同构建统一生态”这一话题，本文为圆桌对话内容实录。陈绪（主持人）：龙蜥社区运营委员会主席、阿里云技术战略总监刘澎：中国开源软件推进联盟副主席兼秘书长、中国科学院软件所研究员肖微：联通软件研究院副总架构师张涛：天翼云产品与生态部高级产品经理严海双：移动云操作系统研发专家</blockquote><p></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/bc/1f/bc86facbf630ff6e40b57d678d714b1f.png\" /></p><p></p><p></p><h4>陈绪：各位都是代表国内领先云厂商的生态专家，为什么说统一生态对各自业务的发展起到非常重要的作用？可否举例说明？</h4><p></p><p></p><p>肖微：从联通来讲，我们近期发布的新战略叫“强基固本、守正创新、融合开放”，这个战略里面把开放作为很重要的内容，也当作联通的定位。我们对内建设服务联通数字化转型的整个 IT 系统，对外敏捷赋能千行百业，打造智慧的行业解决方案。</p><p></p><p>在整个过程中，不管是内部的 IT系统建设，还是对外输出的时候，都会联合整个产业的生态伙伴一起做。既然邀请大家参与进来，我们就一定要去统一标准。“车同轨，书同文”，一定大家要在统一标准上有一个良好的分工进行协同。如果没有一个统一生态，一个社区或者一个标准去做的话，大家可能就会出现七国八制的现象，一方面是资源的浪费，更重要的还是影响效率。</p><p></p><p>张涛：首先龙蜥社区是国内基础软件领域的龙头社区，有众多合作伙伴共同参与，特别是理事单位的一些重要参与和支持。在中国电信集团云改数转战略要求下，电信天翼云在行业拓展中也面临着各种行业场景化的建设。为了支持云业务的发展，天翼云和龙蜥社区在产品特性、内核规划、重要技术领域等方面都有共享和交流，存在非常多的契合点。跟刚才联通肖微总提到的一样，我们也是想推动建立统一生态，服务整个产业链或者中国电信天翼云自己业务的发展。</p><p></p><p>严海双：我的理解是统一生态最关键的就是基础软件的统一。比如操作系统、数据库等基础设施都属于这一类，因为各行业领域应用的性能、安全性都是建立在基础软件能力上的，所以我认为基础软件如果不统一也会制约产业链上下游技术创新。因此我们想借助于国内开源社区，尤其像龙蜥社区生态能够去构建我们的基础软件体系。移动云基于龙蜥操作系统也发布了移动云的操作系统，融合了移动云自己一些创新能力，针对移动云基础设施也做了很多优化和特性，在统一生态这块会与社区进一步共享。</p><p></p><p>刘澎：统一生态是由软件决定的。我们在开源软件里头有重要的三个许可证，第一个许可证是以 BSD、MIT 所决定的许可证，我们比喻它就是一棵大树的根，它们对软件产生的约束非常松，是吸收营养的一个。第二个许可证大家也很清楚，Apache 许可证，它最典型的东西就是安卓操作系统，那个操作系统是一棵大树的树冠，必须开枝散叶。</p><p></p><p>现在龙蜥社区遵循的是 GPL 许可证，GPL 许可证为什么要严格，它是一个最基本也是最关键的工业基础之间的基础件，所以它必须是统一的。为什么？如果一棵大树长出好几个杈来，这个树枝必须有杈，树干不能有杈。我对这个问题研究了很长时间，一开始觉得是左和右的问题，后来经过多年的研究才清楚不是左和右的问题，是整个生态对工业的要求，有吸取营养的，要特别宽松，开枝散叶的必须相对宽松，但是也要有相对集中的。龙蜥是一个上游的社区，所以它必须是 GPL 许可证，必须统一起来，否则社会成本极高。要统一中国基础电信业的操作系统，就要建立竞争关系，在一个小生态里各自产生创新，再汇聚在一处。</p><p></p><h4>陈绪：在 2020 年 12 月份，CentOS 宣布即将停服，想问各位嘉宾 CentOS 的停服对我们刚才提到的统一生态建设带来哪些挑战？</h4><p></p><p></p><p>刘澎：我觉得机会到了，该是我们中国开源软件蓬勃发展的时候了，对国际开源社区提供的共享产生压力。这次断供造成了中国后起之秀的接班，但是现在还不能完全替代它，但是找到了第一次全面接盘的机会，所以我们对龙蜥社区寄有很强烈的希望。</p><p></p><p>严海双：CentOS 停服带来的影响确实比较大，刚才听了很多的分享也讲了为应对 CentOS 停服未来要做哪些事，我认为 CentOS 停服带来的挑战有以下三点。</p><p></p><p>首先，我觉得最大的问题就是业务应用方案要考虑如何更换操作系统，还有如何保证存量业务平滑地迁移到国产化操作系统版本上来。有没有一款比较强大的工具来帮我们做到比如原地的迁移，或者滚动式的集群式迁移升级等。</p><p></p><p>其次，在生态构建方面，我们认为不能因为 CentOS 停服就把原来 CentOS 生态里的软件完全否定掉，我们还是希望能和 CentOS 原有的一些生态保持兼容性，能让用户以很小的成本迁移到最新的国产化版本上来。</p><p></p><p>最后，在开源社区治理方面，<a href=\"https://www.infoq.cn/article/CoA8RIxpRFfmPjgiWkmV\">CentOS 停服</a>\"也能给大家带来一些思考，社区还是希望转向共治共建的策略。就像两天前参加的龙蜥理事会上很多理事也提出来对龙蜥宣言的修改，社区治理还是要有书面的规范，类似社区技术路线变动这种重大的议题都需要比较公开公正的策略来做。</p><p></p><p>张涛：其实从去年开始 CentOS 停服在整个业内引起了很大的反响，因为它涉及到了过往很多 IT 信息基础设施的底层设计。这块为什么会产生这么大的影响，因为大家都有共识，就是服务器操作系统是很多业务架构软件侧的载体，因为 CentOS 本身的社区和产品的成熟度，以及它在发展历程当中形成的软硬件生态强联合的机制，包括各种认证和授权，无论是大家自己的 IT 信息国产化建设，或者是面向各行业的 IT 建设，我们都会面临在不同场景中存在迁移困难的问题。</p><p></p><p>这个问题的解法，除了每一家专门攻坚自己的技术侧外，还需要中国人有一个自己的社区把整个产品生态做大起来，未来中国才可能出现完全替代 CentOS 的技术形态。</p><p></p><p>肖微：针对 CentOS 停服这件事情，我们刚开始的时候还是蛮担心的，因为整个需要迁移的量还是非常大的，但是我们很快就开始做试点研究，联合龙蜥社区还有国内开源社区的 ISV 共同做这件事情。经过二年的试点尝试，在&nbsp;CentOS 替代的技术处理上还是挺有信心的。接下来更大的挑战可能就是工作量，服务器总量还是非常多，软件业务系统非常复杂，这对我们来说是第一个直接挑战。</p><p></p><p>第二个挑战是这件事带来的思考，我们开始反省整个联通对开源软件的引入，开始思考不管是国外的开源软件还是国内的软件哪些是能投入到生产长期使用的，哪些是有风险的。于是，我们去年联合一些机构开始做开源的治理，包括开源软件的安全，这个事情可能比 CentOS 停服处理更长远一些。</p><p></p><h4>陈绪：在座的各位嘉宾都是龙蜥社区的最初理事代表单位成员，尽管在业务上大家有所竞争，但是大家联合组建龙蜥社区理事单位这样一个机构是出于什么目的，同时这样的协同对大家有何意义？您对有竞争的厂商在一起组建这样一个联盟有什么样的想法？</h4><p></p><p></p><p>刘澎：是否组建联盟是由产业位置决定的。像我刚才谈安卓谈了非常长时间，才终于清楚安卓里面有一个 Linux 核，外面有两张皮，驱动和 UI 界面。产业位置是由它的许可证决定的，因为它在应用层界面不是在内核界面。龙蜥现在做的是把业内核心力量都联合起来的，这是一个工业基础件，不能有两个。只有工业基础件的一致，这样才能节约整个社会成本。什么地方不能一致？到了上面不能一致，要不然没有先进性，大家都用一个东西，就像每天餐厅就只有一道菜。所以说，大家炒的菜可以不同，但是炒菜的锅必须是一致的。</p><p></p><p>严海双：我们作为最先加入龙蜥社区的理事单位，去年跟社区签署了协议，原先的设想也是跟社区一样可以实现共建共治共享的理念，来打造 Linux 开源操作操作系统和创新平台。我们基于 Linux 社区版本做二次开发，发布移动云自己的企业定制版，也是想融合拉通移动云里面的底层基础设施资源，向下统一基础技术架构，最小化底层硬件差异，向上赋能各个产品业务创新。</p><p></p><p>张涛：我们电信天翼云也是，作为最初的理事成员单位，在去年很早的时候加入到龙蜥社区。我想说两点想法，第一，天翼云作为一家主要从事云服务研发的厂商，操作系统在云计算研发体系中是一个非常重要的环节，并且天翼云也是以全栈自主研发为目标的企业，在整个公司业务发展中也是一直秉承着拥抱开源、拥抱技术这样的目标，这跟龙蜥社区的文化比较契合。第二，作为国内比较重要的云计算厂商，也会积极参与把相关能力贡献到社区里，这也是作为天翼云这家公司的责任与担当。</p><p></p><p>肖微：联通作为首批加入龙蜥社区的理事，有两点考虑。第一个，操作系统是云非常重要的生态。因为操作系统向下管理整个硬件，向上承载适配着数据库、AI、中间件等众多软件。第二个，龙蜥社区成立时成员的设置非常好，里面既包括云的企业，也包括了操作系统企业、芯片企业，成员配置是非常齐全的，整个社区成立时就是以开放、中立、平等的原则。龙蜥未来的发展是非常可观，这是我们加入的一个原因。</p><p></p><p>当然更直接的原因有三点：第一点是 CentOS 停服，龙蜥操作系统替代方案是一个非常好的选择。第二点是我们在做联通云的时候，云本身对操作系统有非常多的需求，一般来说应用系统和操作系统只要能把程序 run 起来，或者性能有一定的优化就可以了，但是云不一样，比如云用到很多新的特性，包括 IO 的优化、虚拟化等等，都是需要操作系统内核来支撑的。因此，我们希望在使用操作系统的场景和诉求上，在社区里相互协作和支撑。第三点，国家近两年颁布了很多“网络安全”、“数据安全”等法律，联通在落实这些条款的时候，引进了大量国产芯片，比如 Arm、国产 X86 等，还有国产数据库。我们引进来国产芯片和数据库之后，迫切需要有一个非常好的操作系统来去做适配，因此联通积极投身龙蜥社区的建设，希望能够在社区里面把软硬件结合起来。</p><p></p><h4>陈绪：最后的时间给到四位，请提出对龙蜥社区的希望，以及如何更好地建设统一的协同生态。</h4><p></p><p></p><p>刘澎：这个命题很大。我们还是高度地寄希望于龙蜥社区能成为中国技术软件领域创新的领头羊。谢谢大家。</p><p></p><p>严海双：我们也将会借助于移动云的能力和优势，将与龙蜥社区继续合作，共享能力积累，共建创新平台。</p><p></p><p>张涛：国产技术软件目前迎来发展黄金期，同时也面临很多的困难和阻力，也希望在龙蜥社区大家的共同努力下拥抱开源，分享各自的能力，将整个中国技术软件体系进行进一步的提升和加强。</p><p></p><p>肖微：寄语谈不上，对社区提一些想法，我觉得应用上还是保持开放，技术上进行务实地去做创新。对于每一个参与者来说在社区里面找到自己的定位，最后每个人在社区里进行贡献，每个人也有收益。</p>",
    "publish_time": "2022-08-26 14:53:18",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "分布式数据库技术发展趋势及选型与标准思考 | 数据库Talk Show",
    "url": "https://www.infoq.cn/article/aFGc1l02v39SsT1XSEAU",
    "summary": "<p>随着信息技术的迅猛发展，各行各业产生的数据量呈爆炸式增长，传统集中式数据库的局限性在面对大规模数据处理中逐渐显露，从而分布式数据库应运而生。分布式数据库是在集中式数据库的基础上发展起来的，是分布式系统与传统数据库技术结合的产物，具有透明性、数据冗余性、易于扩展性等特点，还具 备高可靠、高可用、低成本 等方面的优势，能够突破传统数据库的瓶颈。</p>\n<p>分布式数据库目前已应用到金融、电信等大数据行业，未来将走向更广阔的领域。本次“数据库 Talk Show”活动将围绕分布式数据库技术路线和产业现状，分析分布式数据库的技术特点以及面临的问题与挑战，对 企业如何进行数据库选型 互动讨论。</p>",
    "publish_time": "2022-08-26 15:00:37",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "【DBA100人】李建明：一名普通DBA的14年技术之路与成长智慧",
    "url": "https://www.infoq.cn/article/Yx2W8Y27mZ9G5eurg5ze",
    "summary": "<p>“DBA100人”专访计划是<a href=\"https://xie.infoq.cn/article/3c4e351e08cde87a0010c2fcd\">OceanBase</a>\"围绕资深DBA进行的人物专访活动，旨在通过人物故事、职业发展经历以及日常工作中遇到的技术难题和实践案例，未来对技术趋势的想法，希望他们的成长之道能够给到各行业DBA一些建议和思考。</p><p></p><p>编者按</p><p></p><p></p><blockquote>DBA如何快速定位故障？如何做好性能优化？如何做好技术选型与技术体系建设？今天《DBA 100人》第1期带你了解一位拥有十多年职场经验的资深数据库专家&amp;运维人——云南某银行信息科技部运维中心经理，他曾负责主机、中间件、数据库的维护；参与银行核心系统、支付系统的开发；领导运维体系、应急容灾体系、监控体系的建设，希望他的经验能给你带来参考价值。</blockquote><p></p><p></p><p>2001年，这个问题对于正在报考大学志愿的李建明而言，一无所知。和许多因为“喜欢玩电脑”和觉得“编程有趣”的人不同，李建明高中时都不曾接触计算机，只因那时计算机还未在全国校园普及，他只曾听人说起，学计算机能在毕业后找到一份不错的工作。</p><p></p><p>就这样，李建明成为中国第一批学习<a href=\"https://xie.infoq.cn/article/36be05f6ca2e730118d6d8cd8\">信息安全技术</a>\"的本科生，在校期间还兼职开发了办公软件、论坛、博客等，第一次感受到了编程的乐趣：“我很享受这种从无到有，一步一步把产品做出来的过程”。由于信息安全技术的知识比较宽泛，对于想在计算机领域稳扎稳打的李建明而言必须深入工程，打好编码的底层基础。因此，他在报考研究生时选择了系统分析与集成专业。对于专业的选择，李建明认为一个重要的判断因素是“未来这条路是宽还是窄，通俗地说就是未来择业时，你所选方向的市场需求量是大还是小？还可以结合自己的兴趣考虑，在自己感兴趣的领域或许会更加顺利。”</p><p></p><p>这次选择，为李建明进入数据库领域，成为一名<a href=\"https://www.infoq.cn/article/W9usxEG4ciJGKhwo6j94\">DBA</a>\"埋下了伏笔。</p><p></p><p></p><h3>成长中的DBA：快速定位故障，清楚系统运行机制</h3><p></p><p></p><p>2008年，研究生毕业的李建明入职正值电子化改革高速发展期的某信用社，参与核心系统和支付系统的维护与开发工作。早在2004年，国务院要求深化农村信用社改革，某信用社响应国家号召，在2005年成立了<a href=\"https://aiqicha.baidu.com/detail/compinfo?pid=xlTM-TogKuTwnlLzyUKB*OLVwqAlmfhBtwmd&amp;rq=es&amp;pd=ee&amp;from=ps\">科技结算中心</a>\"，建设了信息系统，此举也为客户带来了更方便、快捷的金融服务。但不断上涨的交易量给系统带来了挑战，系统稳定性的保障难度不断加码。</p><p></p><h4>“快”是一大挑战</h4><p></p><p></p><p>信用社信息系统的搭建正是由李建明所在的科技结算中心负责，因此，从入职起他就一边负责系统的维护，一边优化系统，工作之余还自学DBA相关的知识。作为系统维护人员，李建明需要在系统出错时，及时定位故障并快速修复。而要做到“快”，对于初入职的“技术小白”而言却很有挑战。</p><p></p><p>李建明的办法是搞清楚系统运行机制、执行流程。当系统报错时就可以很快地查询到哪些账务是错误的，以及这种错误会在什么情况下出现。</p><p></p><p>一般来说，运维人员会觉得应用系统永远都是缺文档的。开发人员可能不会将文档写得全面。因此，运维人员在维护系统时就需要多钻研。比如，了解系统架构与业务架构及其技术实现路径，了解系统表结构就能基本掌握业务结构，了解操作系统的命令就能掌握系统的结构。此外，还要进一步学习系统组件，如钻研数据库的表结构。</p><p></p><p>通过不断地深入了解系统各个层面以及不断向上层探索，逐渐清楚系统的运行机制与执行流程，并在一次又一次的假设问题与验证答案中掌握真理。当“实验”做得足够多时，自然就能掌握快速定位故障并修复故障的能力。除此以外，李建明花了七八个月的时间通读系统主要的源代码。这段时间的钻研与自学，不仅使李建明可以在系统出错时快速找到问题，也让他的技术能力与代码质量都得到了迅速提升。</p><p></p><p>2010年，李建明也因为两年的优秀表现，正式成为了一名系统管理员兼数据库管理员（DBA），负责系统的稳定与高效运行，并管理和维护数据库、操作系统、应用软件、中间件等。“当时有两个系统管理员，只要出现技术故障，我们都需要介入处理”。而他在这两年对系统的钻研与探索，使他对系统基本了如指掌，对新的工作任务得心应手。</p><p></p><h4>摸索、踩坑、学习</h4><p></p><p></p><p>这些问题对于一个成熟的DBA而言都不算难。但对于成长中的DBA而言，需要不断在实践中摸索、踩坑、学习。</p><p></p><p>例如，数据库连接池出现故障时，经验较少的DBA可能会认为是连接数量不够，于是不断创建更多的连接，当连接池占满时也没能解决问题。因为连接池满只是一种现象，解决根本问题还需从现象看本质。在一些情况下，确实存在业务量过大的原因，但在大多数情况下，业务量不会突然增大，连接池满的原因可能是新业务不高效，导致连接池堵塞或者连接池没有及时释放。这时，一味地加连接只是延缓系统堵塞，并不能从本质解决问题。</p><p></p><p>再例如，发生长事务问题导致业务中断时，对原理不熟悉的DBA只会傻傻地等待事务回滚。但积累一定经验后，就会知道，其实可以通过不断增加事务日志文件，来保证业务正常运行的过程中将事务回滚完成。</p><p></p><p>“系统管理员的工作，让我对软件系统有了更深入的了解。从理论到实践，积累了丰富的故障处理及性能优化经验，提升了技术自信心”，李建明如是说。同时，他总结了保障系统稳定性及定位故障、优化性能的经验。</p><p></p><p>作为DBA，保障系统稳定性是重中之重，李建明认为需要做好三项工作。</p><p></p><p>第一，预防，即关注网络、存储、计算资源，以及操作系统等基础架构的规划。确保基础框架保持相对的统一。</p><p></p><p>第二，在系统正常运行时，注重从业务视角观察系统运行是否有异常，是否处于亚健康状态，做好预警、应急等方面的可观测性建设，完善容灾体系和标准化操作管理。</p><p></p><p>第三，应急，即通过系统架构定位故障，再结合监控系统辅助分析问题。对于故障定位与性能优化，可从三方面开展：</p><p></p><p>1）确认系统架构和业务架构，站在全局的角度排查问题；2）关注各种指标，如常见的CPU内存、I/O、负载、业务量，业务的成功率、响应时间等；3）在压力场景下，从前到后排除每个模块的性能表现，或者是一些活动的概要信息和详细信息，包括当前系统正在做的一些操作。比如调用了什么函数，执行了什么SQL，以及每一个线程正在执行什么函数，甚至关注网络传输包的响应效率和网络延迟等问题。</p><p></p><p>此外，为了避免各模块负责人之间推卸责任，需要有一个技术融合的团队，在应急时每个人都能统管全局，快速上手处理问题。</p><p></p><h3>经验丰富的DBA：数据库选型不求最贵，只求最好</h3><p></p><p></p><p>在某信用社的十年，李建明从懵懵懂懂的应届生成为了经验老到的系统管理员与高级工程师，该信用社的电子系统也从支撑上百万账务交易量发展为支撑上千万账务交易量。如果说信用社是李建明职业生涯的基石，是培养他职业技能的摇篮，那么银行就是他十年职业技能与经验的高级试炼场。</p><p></p><p>自2018年李建明加入云南某银行，负责运维团队的管理与运维体系、应急容灾体系、监控体系的建设。另外，在2021年参与了一项看似离DBA很遥远的工作：数据库选型。</p><p></p><p>不以业务为基础的选型就是耍流氓，想做好技术选型，首先要对市场中哪些数据库可以作为备选有一定的了解。李建明认为，一款优秀的数据库产品应该像Informix一样稳定、简洁，同时又能像Oracle一样拥有丰富的内置系统表，且具备高性能特性。还应该达到<a href=\"https://xie.infoq.cn/article/09cd09f843321bf85af6e666d\">ACID</a>\"（Atomicity、Consistency、Isolation、Durability，即或称不可分割性）、原子性、一致性、隔离性、持久性）的要求，另外，保证应用的透明性是不可或缺的能力。数据库还应该给予DBA足够的掌控感，让DBA看到他和数据库交互的过程中使用了什么工具、消耗了多少CPU、用了多长时间，以及做过哪些操作。</p><p></p><p>其次，针对业务特性，选择“最优解”。以李建明当前所在的银行行业更换数据库时的技术选型为例。</p><p></p><p>大部分银行都会使用较为成熟的<a href=\"https://www.oracle.com/\">Oracle数据库</a>\"，使用Oracle的好处在于其文档、书籍等资料较全，工具丰富且生态成熟，遇到问题时能复用他人的解决方案或比较快速地找到懂Oracle的开发者。但随着银行数据量的日益庞大，Oracle的数据处理能力显得捉襟见肘，在做异地多活的时候也显现出了短板，Oracle的全局缓存机制会使A客户的数据跑在A中心，B客户的数据跑在B中心，如果交叉跑会导致性能极大地衰减。另外，硬件投入成本、软件使用成本都在不断增加。可替换数据库谈何容易，李建明所在的银行在数据库选型上陷入两难境地。</p><p></p><p>其实银行真正需要的是一个性能更好且成本更低的数据库，能够灵活地扩容、缩容，在业务量较低时减少节点，在应对交易峰值时增加节点。将对于传统的集中式数据库Oracle，<a href=\"https://pingcap.com/zh/contact-us-now/?utm_source=baidu&amp;utm_medium=cpc&amp;utm_campaign=pccp&amp;utm_term=000013&amp;bd_vid=11423408266213868641\">分布式数据库</a>\"似乎是新的选择方向。</p><p></p><p>从系统角度而言，对比目前市面上优秀的分布式数据库，李建明认为，数据库的架构应该由其本身决定，而不是由上层应用和DBA总关注它的数据分布机制，就这一点，便能够排除一些数据库选项，OceanBase数据库由于其一体化的架构占据了优势。从扩、缩容角度而言，有数据库级、表级、行级的弹性，数据库级别的扩、缩容不够细致，而行级的扩、缩容对于当前业务交易量而言还用不到，因此，表级扩、缩容的OceanBase便是不错的选择，且OceanBase的三地五中心能够做到不丢失数据。从性能角度和成熟案例这两方面来看，经历过大型活动考验的数据库产品，OceanBase较为出众，已经稳定支撑了十年的“双11”活动，并经过支付宝、网商银行等的验证。而且在性能测试时，达到了8000 TPS（每秒事务处理量）。</p><p></p><p>由于云南某银行是在传统的核心系统基础上使用分布式数据库。因此在综合考虑后，认为OceanBase是更适合的选择。参与了此次数据库选型的李建明总结了四点经验：</p><p></p><p>第一，国产数据库当前的产品和技术实力也在逐步提升，可以作为选型考虑的一部分。</p><p></p><p>第二，面对日益庞大的数据量，分布式数据库是较好的选择。</p><p></p><p>第三，选择分布式数据库时，考虑数据库的ACID。</p><p></p><p>第四，考虑对应用的改造程度及兼容度。考虑数据库的性能、体量以及对硬件的兼容度。</p><p></p><h3>给 DBA 的七个成长建议</h3><p></p><p></p><p>在采访的最后，谈及一名优秀的DBA应该具备哪些素质或能力时，李建明根据自己十多年的职场经验，分享了他的看法并给出了七个建议：</p><p></p><p>具备扎实的数据库理论功底。比如数据库系统的概论、数据库的核心概念、分布式数据库原理等，理论能为工作中的实践提供宏观指导。</p><p></p><p>熟悉软件开发基础知识和技术架构。DBA或许不需要写好代码。但如果他不熟悉代码，比如不知道代码怎么写出来的、怎么做负载均衡，怎么连接数据库，以及不清楚常见的框架，那么他可能在排查问题时只会说“我觉得数据库没有问题”，更不能站在全局角度保障系统的稳定性。</p><p></p><p>熟悉操作系统的操作及性能调优。数据库最终还是要跑在操作系统上。对于操作系统的操作熟练度可以通过日常工作积累，而对于性能调优，可以通过阅读官方文档中的说明来掌握，比如了解参数的意义和修改参数会带来的影响，并在日常工作中多动手。</p><p></p><p>熟练的数据库运维操作。尤其要经过高并发、大数据量的洗礼。操作的熟练度更多是靠量的积累。至于能不能碰到高并发场景，由所在企业的业务决定。比如支撑小的业务量的Oracle数据库，很多时候按照默认参数就可以运行得很好。DBA不会遇到较大挑战，顶多是扩展存储空间。因此难以积累这方面的经验。</p><p></p><p>越是难懂的理论，越应该努力掌握。对于众多的技术知识，先做到学会其中一个知识点并达到一定深度后再横向发展，如果你熟悉多项技能，且每项技能只停留在表层，那么你在技术领域很难到达高层次。</p><p></p><p>保持对知识的好奇心，坚持终身学习。对于技术人而言，想学习IT理论可以阅读技术书籍；有针对性地学习系统的实操经验可以用极客时间；学习专业领域的技术知识，可以阅读厂商的官方文档；遇到“疑难杂症”时可以浏览CSDN；对于学科类与常识性的内容，就用得到App；研究强理论、学术型的知识可以翻看论文。</p><p></p><p>培养自己的逆向思维和结构化思考能力。打破思维惯性想象多种可能性，尤其是向两个极端方向去思考。不断问问题，推翻自己的假设并验证新的假设。</p><p></p><p>如果能给年轻时的自己一些建议，李建明表示“吾生有涯而知无涯，要舍得放弃，找到自己最感兴趣或者最擅长的方向，下笨功夫、练就必杀技。还要多学一些跨学科的基本原理，拓宽自我的知识面，提升多维思考能力，并且要勤于思考、有计划的多动手。”与众多数据库从业者共勉。</p><p></p><h4>嘉宾介绍</h4><p></p><p></p><p>李建明</p><p></p><p>目前在云南某银行担任信息科技部运维中心经理。拥有系统分析师、Elasticsearch认证工程师、Kubernetes认证管理员、DevOps Master、Oracle认证专家、OceanBase认证专家等资质。</p>",
    "publish_time": "2022-08-26 15:02:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何使用先验策略有效地初始化强化学习？",
    "url": "https://www.infoq.cn/article/vv20yMM4XN008IhBAV5P",
    "summary": "<p><a href=\"https://www.infoq.cn/article/BKD5NPspBroTswFsLU61\">强化学习</a>\"可以用于训练一种策略，使其能够在试错的情况下来完成任务，但强化学习面临的最大挑战就是，如何在具有艰难探索挑战的环境中从头学习策略。比如，考虑到 <a href=\"https://github.com/aravindr93/hand_dapg/\">adroit manipulation 套件</a>\"中的 door-binary-v0 环境所描述的设置，其中强化学习智能体必须在三维空间中控制一只手来打开放在它前面的门。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/08/01/083fa7a4fca698e42ca8yyb976c51101.gif\" /></p><p></p><p>由于智能体没有收到任何中间奖励，它无法衡量自己离完成任务有多远，所以只能在空间里随机探索，直至门被打开为止。鉴于这项任务所需的时间以及对其进行精准的控制，这种可能性微乎其微。</p><p></p><p>对于这样的任务，我们可以通过使用先验信息来规避对状态空间的随机探索。这种先验信息有助于智能体了解环境的哪些状态是好的，应该进一步探索。</p><p></p><p>我们可以利用离线数据（即由人类演示者、脚本策略或其他强化学习智能体收集的数据），对策略进行训练，并将之用于初始化新的强化学习策略。如果采用神经网络来表达策略，则需要将预训练好的神经网络复制到新的强化学习策略中。这一过程使得新的强化学习策略看起来就像是预训练好的。但是，用这种幼稚的方式来进行新的强化学习通常是行不通的，尤其是基于值的强化学习方法，如下所示。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/f3/a6/f39cc3a3289d3dbyy667f08968957ba6.jpg\" /></p><p>用离线数据在 antmaze-large-diverse-v0 D4RL 环境中对一种策略进行预训练（负向步骤对应预训练）。然后，我们使用该策略来初始化 actor-crittic 的微调（从第 0 步开始的正向步骤），以该预训练的策略作为初始 actor。crittic 是随机初始化的。由于未经训练的 critic 提供了一个糟糕的学习信号，并导致良好的初始策略被遗忘，所以 actor 的性能会立即下降，并且不会恢复。</p><p></p><p>有鉴于此，我们在“跳跃式强化学习”（Jump-Start Reinforcement Learning，JSRL）中，提出了一种可以利用任意一种与现存在的策略对任意一种强化学习算法进行初始化的元算法。</p><p></p><p>JSRL 在学习任务时采用了两种策略：一种是指导策略，另一种是探索策略。探索策略是一种强化学习策略，通过智能体从环境中收集的新经验进行在线训练，而指导策略是一种预先存在的任何形式的策略，在在线训练中不被更新。在这项研究中，我们关注的是指导策略从演示中学习的情景，但也可以使用许多其他类型的指导策略。JSRL 通过滚动指导策略创建了一个学习课程，然后由自我改进的探索策略跟进，其结果是与竞争性的 IL+RL 方法相比较或改进的性能。</p><p></p><h2>JSRL 方法</h2><p></p><p></p><p>指导策略可以采取任何形式：它可以是一种脚本化的策略，一种用于强化学习训练的策略，甚至是一个真人演示者。唯一的要求是，指导策略要合理（也就是优于随机探索），而且可以根据对环境的观察来选择行动。理想情况下，指导策略可以在环境中达到较差或中等的性能，但不能通过额外的微调来进一步改善自己。然后，JSRL 允许我们利用这个指导策略的进展，从而提到它的性能。</p><p></p><p>在训练开始时，我们将指导策略推出一个固定的步骤，使智能体更接近目标状态。然后，探索策略接手，继续在环境中行动以达到这些目标。随着探索策略性能的提高，我们逐渐减少指导策略的步骤，直到探索策略完全接管。这个过程为探索策略创建了一个起始状态的课程，这样在每个课程阶段，它只需要学习达到之前课程阶段的初始状态。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/f9/a0/f9efc5940a8555119a562e7fa0afe7a0.gif\" /></p><p></p><p>这个任务是让机械臂拿起蓝色木块。指导策略可以将机械臂移动到木块上，但不能将其拾起。它控制智能体，直到它抓住木块，然后由探索策略接管，最终学会拿起木块。随着探索策略的改进，指导策略对智能体的控制越来越少。 </p><p></p><h2>与 IL+RL 基线的比较</h2><p></p><p></p><p>由于 JSRL 可以使用先前的策略来初始化强化学习，一个自然的比较是<a href=\"https://arxiv.org/pdf/1811.06711.pdf\">模仿</a>\"和强化学习（IL+RL）方法，该方法在离线数据集上进行训练，然后用新的在线经验对预训练的策略进行微调。我们展示了 JSRL 在 <a href=\"https://github.com/rail-berkeley/d4rl\">D4RL</a>\" 基准任务上与具有竞争力的 IL+RL 方法的比较情况。这些任务包括模拟的机器人控制环境，以及来自人类演示者的离线数据集、计划者和其他学到的策略。在 D4RL 任务中，我们重点关注困难的蚂蚁迷宫和 <a href=\"https://vikashplus.github.io/P_Hand.html\">adroit dexterous manipulation</a>\" 环境。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/75/a6/75a868631292bb6556e2fb43dfe65ca6.jpg\" /></p><p></p><p>对于每个实验，我们在一个离线数据集上进行训练，然后运行在线微调。我们与专门为每个环境设计的算法进行比较，这些算法包括 AWAC、IQL、CQL 和行为克隆。虽然 JSRL 可以与任何初始指导策略或微调算法结合使用，但我们使用我们最强大的基线——IQL，作为预训练的指导和微调。完整的 D4RL 数据集包括每个蚂蚁迷宫任务的一百万个离线转换。每个转换是一个格式序列（S, A, R, S'），它指定了智能体开始时的状态（S），智能体采取的行动（A），智能体收到的奖励（R），以及智能体在采取行动 A 后结束的状态（S'）。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/1a/ec/1acfe8886b2f34aa3720ac94e14986ec.jpg\" /></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/f5/42/f512df76ce3ddf90db60d4d2ef7ecb42.jpg\" /></p><p></p><p>在 D4RL 基准套件的 antmaze-medium-diverse-v0 环境中的平均得分（最大值=100）。即使在有限的离线转换的情况下，JSRL 也可以改进。 </p><p></p><h2>基于视觉的机器人任务</h2><p></p><p></p><p>由于维度的限制，在复杂的任务中使用离线数据特别困难，比如基于视觉的机器人操纵。连续控制动作空间和基于像素的状态空间的高维度，给 IL+RL 方法带来了学习良好策略所需的数据量方面的扩展挑战。为了研究 JSRL 如何适应这种环境，我们重点研究了两个困难的仿生机器人操纵任务：无差别抓取（即，举起任何物体）和实例抓取（即，举起特定的目标物体）。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/f7/c5/f77320102cb18b474d6d575c670373c5.jpg\" /></p><p></p><p>一个仿生机械臂被放置在一张有各种类别物体的桌子前。当机械臂举起任何物体时，对于无差别的抓取任务，会给予稀疏的奖励。对于实例抓取任务，只有在抓取特定的目标物体时，才会给予稀疏的奖励。\n</p><p>我们将 JSRL 与能够扩展到复杂的基于视觉的机器人环境的方法进行比较，如 QT-Opt 和 AW-Opt。每种方法都可以获得相同的成功演示的离线数据集，并被允许运行多达 10 万步的在线微调。</p><p></p><p>在这些实验中，我们使用行为克隆作为指导策略，并将 JSRL 与 QT-Opt 相结合进行微调。QT-Opt+JSRL 的组合比其他所有方法改进得更快，同时获得了最高的成功率。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/c4/ca/c45f1c3a5d56c8806b1f02a19900e7ca.jpg\" /></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/c0/2d/c0dfbd98c54a46ba0b713e6962dac72d.jpg\" /></p><p></p><p>使用 2 千次成功演示，无差别和实例抓取环境的平均抓取成功率。</p><p></p><h2>结语</h2><p></p><p></p><p>我们提出了 JSRL，它是一种利用任何形式的先验策略来改进初始化强化学习任务的探索的方法。我们的算法通过在预先存在的指导策略中滚动，创建了一个学习课程，然后由自我改进的探索策略跟进。探索策略的工作被大大简化，因为它从更接近目标的状态开始探索。随着探索策略的改进，指导策略的影响也随之减弱，从而形成一个完全有能力的强化学习策略。在未来，我们计划将 JSRL 应用于 Sim2Real 等问题，并探索我们如何利用多种指导策略来训练强化学习智能体。</p><p></p><p>原文链接：</p><p>https://ai.googleblog.com/2022/04/efficiently-initializing-reinforcement.html</p>",
    "publish_time": "2022-08-26 16:18:53",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "新浪微博从 Kafka 到 Pulsar 的演变",
    "url": "https://www.infoq.cn/article/ic2tSdHdZ8KKf4u9SsYp",
    "summary": "<p></p><p></p><p>新浪公司是一家服务于中国及全球华人社群的领先网络媒体公司。其业务涵盖新浪媒体、微博和新浪金融。新浪通过门户网站新浪网、新浪移动、新浪财经以及社交媒体平台微博组成的数字媒体网络，帮助广大用户获得专业媒体、机构和个人创作的多媒体内容并与他人进行兴趣分享和社交互动。</p><p></p><p>其中，微博是人们在线创作、分享和发现内容的中国领先社交媒体平台。新浪微博于 2009 年上线，是中国头部、流行的社交媒体平台，提供在线创作、分享和发现优质内容的服务。据微博 2022 年第一季度财报，微博月活跃用户为 5.82 亿，日活跃用户为 2.52 亿，平台日均处理万亿级消息。</p><p></p><p></p><h2>日均万亿消息，Kafka 运维遇挑战</h2><p></p><p></p><p>新浪现有 Kafka 集群主要处理来自新浪新闻、微博等的数据，数据类型包括特征日志、订单数据、广告曝光、埋点 / 监控 / 服务日志等。这些数据经过 Kafka 在线集群、广告专用集群、日志集群、离线集群和机器学习训练等集群的处理后，会用于推荐训练、HDFS 落地、离线数仓、实时监控、数据报表和实时分析等生产目的。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5f/5f8e9be5005e352bcab07fca25b397e6.png\" /></p><p></p><p>新浪在使用和运维 Kafka 集群的过程中，遇到的痛点有：</p><p></p><p>Kafka 运维较困难，突发热点事件时扩容节点无法自动均衡。在高流量峰值场景下，经常遇到了磁盘和 broker 达到瓶颈的情况。Kafka 可以轻松扩容 broker，然而集群扩容时新增 broker 无法自动承载流量，需要较为复杂的人工运维操作。磁盘数据分布不均，topic 分区流量分布不均。随着业务波动，一些承载较大流量的 topic 下线后，其所在 broker 的流量和磁盘数据存储也会下降，类似情况多次发生后 topic 分区流量和磁盘数据分布就会失衡，需要人工干预来 rebalance 流量。迁移分区带来数据移动，容易造成问题。流量 rebalance 需要迁移分区，相当于增加副本，在热点事件爆发、资源紧张时会造成更严重的后果。新浪单集群每日有万亿级以上消息写入，涉及到非常多的业务方与多语言客户端，因此迁移到其他消息队列较为困难。一些重要业务有很多作者不详的重要老代码，源码因故丢失，难以处理、迁移和改造。</p><p></p><p></p><h2>借助 KoP，落地 Pulsar</h2><p></p><p></p><p>团队希望能有一个消息队列可以解决 Kafka 存在的这些问题，同时业务方只需简单修改配置，替换 Kafka 的 broker list 即可迁移。基于这样的背景，团队调研了存算分离架构的 Apache Pulsar，可以很好地解决上述挑战。Pulsar 的 bookie 和 broker 是分离的，而扩容时 bookie 可以自动承接新流量；broker 只承担一些元数据的计算工作，所以需要做 rebalance 时速度很快，无需数据移动。</p><p></p><p>在调研 Pulsar 的过程中团队发现了 KoP 这个开源项目。KoP 是开源项目 Kafka-on-Pulsar 的缩写，Kafka 用户可借助 KoP 插件无缝迁移到 Pulsar，充分利用 Pulsar 的诸多功能特性，以降低迁移成本（GitHub 地址：<a href=\"https://github.com/streamnative/kop%EF%BC%89%E3%80%82KoP\">https://github.com/streamnative/kop）。KoP</a>\" 实质上就是用 Pulsar 提供的 Protocol Handler 机制来对接 Kafka 数据。当 Kafka 集群写入数据时，通过基于 Kafka Protocol Handler 来操作。KoP 复用了 Pulsar 的 topic lookup 机制和抽象的 Managed Ledger 存储层，将数据通过 bookie client 直接发送到 bookie 集群中，如下图：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/00/00c9e393dfb08c770e42e5a664f7b641.png\" /></p><p></p><p>通过 KoP 协议可以落地 Pulsar 并原生支持新浪现有的 Kafka 客户端，也可以解决新浪 Kafka 团队在 Kafka 上的运维痛点。于是团队开始调研和实践 KoP 组件。在此过程中，团队也遇到了一些问题，其中一个主要挑战就是 KoP 低版本兼容性问题。</p><p></p><p></p><h2>部署问题与解决方案</h2><p></p><p></p><p></p><h3>KoP 低版本兼容性问题</h3><p></p><p></p><p>新浪 Kafka 集群中一些较重要的集群仍在使用较老的 Kafka 版本（如 0.10），因此在调研与实践中需要兼容较老版本的客户端。KoP 只支持 1.0 及以后的版本。经过总结，团队发现了以下细节问题并给出对应解决方案。</p><p></p><p></p><h3>低版本认证不兼容</h3><p></p><p></p><p>客户端需要通过认证才可以访问新浪的认证集群，与服务端交互。在 Kafka 1.0 版本之前，客户端与服务端的认证交互是通过 V0 版本的 SaslHandshakeRequest 请求完成的，之后的 token 信息由 SASL tokens（不需要 Kafka request headers）包装，这是一些不透明的数据包。所以团队需要在 KoP 中手动处理这些数据包才能完成认证工作。</p><p></p><p>在 Kafka 1.0 版本之后，认证交互通过 V1 版本的 SaslHandshakeRequest 请求完成，token 信息则由 SaslAuthenticateRequest 请求封装。KoP 处理时会直接解析 token 的协议头。KoP 的低版本认证不兼容问题主要出现在 token 信息这个层面，团队需要通过重构来避免 KoP 直接解析令牌的协议头，从而顺利处理旧版本的不透明数据包。详细代码参见 GitHub。(<a href=\"https://github.com/streamnative/kop/pull/676\">https://github.com/streamnative/kop/pull/676</a>\")。</p><p></p><p></p><h3>日志协议兼容性问题</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7b/7b67ad764cd4702c976c33f2de23a3e6.png\" /></p><p></p><p>以上是 Kafka 消息协议的几个版本示意，从左至右分别为 V0、V1、V2。Kafka 0.10 版本之前使用 V0 版消息协议，0.10 版本改用 V1 版，0.11 之后改用 V2 版。V1 版本相比 V0 版本新增了时间戳；V2 版本改动较大，从 message set 变成了 RecordBatch，后者内部还封装了很多 Record。上图中各个方框内都是协议中的关键字段。V2 版本开始内部消息都使用相对位移，RecordBatch 的元数据部分只需放置起始的绝对位移。</p><p></p><p>于是不同版本之间生产消费时就会存在日志协议兼容性问题。例如一个高版本的生产者生产消息后，低版本的消费者是无法解析新版日志协议的，自然只会报错而无法消费。为此需要引入跨版本消息转换功能，才能让低版本读取高版本的消息。但如果生产者是低版本，消费者是高版本，由于协议是向下兼容的，所以数据消费不会存在问题，不需要转换。</p><p></p><p>那么 KoP 是如何处理生产者请求的呢？Kafka 客户端发来生产者请求时，KoP 解析请求后，Handler 线程会调用 ReplicaManager 主键，追加 Kafka 的 Records。这个主键与 Kafka 中的副本管理器是对应的，做了映射。</p><p></p><p><code lang=\"css\">io.streamnative.pulsar.handlers.kop.storage.ReplicaManager#appendRecords\n</code></p><p></p><p>每个分区对应一个 PartitionLog，映射了 Kafka 里面的 loggingScala 类对应，每一个 KoP broker 中都有一个 PartitionLogManager 来管理 PartitionLog。要将 Kafka Records 处理为消息写入 Bookie，这里的问题就是如何从 Records 编码成 Messages。</p><p></p><p><code lang=\"css\">io.streamnative.pulsar.handlers.kop.storage.PartitionLog#appendRecords\n</code></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/eb/eb92cbf4e0a0372ac665081bd564fc86.png\" /></p><p></p><p>PartitionLog 在追加 Kafka 的 Records 时，会执行 EntryFormatter 的 encode 过程 io.streamnative.pulsar.handlers.kop.format.EntryFormatter#encode。编码之后会通过 Pulsar broker 的 Persistenttopic 组件 org.apache.pulsar.broker.service.persistent.PersistentTopic#publishMessage来 publishMessage。在 EntryFormat 过程中将 Kafka Records 转换为 Pulsar 消息。然后用存储层 ManagedLedger 将消息发布为 Bookie 可识别的 entry 写入 Bookie。这里的关键就是 EntryFormat 编码过程。下图引据了 entryFormat 的官网介绍，可以看到其取值可选 kafka、mixed_kafka 和 pulsar，默认为 Pulsar。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e0/e095f1aa89c189eca328ac8d99581381.png\" /></p><p></p><p>在了解转换过程之前还需了解 Pulsar Message 协议。协议中一部分信息专注于元数据，message payload 字段中包含实际数据，每个 message 中有多条消息，与 RecordBatch 类似。单条消息还有自己的元数据。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/2c/2c39dcda17f696365a1f47952e1ff21b.png\" /></p><p></p><p>从 Kafka 请求转换为 Pulsar 消息要做协议转换。当 entryFormat=kafka（取值为 kafka） 时，主要会设置 publish time、num messages、properties（标识 message 的 entryFormat 类型，解码阶段需要），最后 payload 部分就是将整个 RecordBatch 通过 Persistent Topic 组件发送到 Broker。这里 Pulsar 的客户端无法识别解析 RecordBatch。</p><p></p><p>如果要用 KoP 将 Kafka 集群数据迁移到 Pulsar，就需要用到 entryFormat=pulsar。它会遍历 Kafka 的 RecordBatch 和内部的 Record 信息一一对应设置能够对应的 Message Metadata 和 Single Message Metadata，从而转换为 Pulsar 消息发布到 bookie。</p><p></p><p>要解决兼容性问题就要专注于 EntryFormat，根据生产者和消费者的版本情况进行消息的转换。转换会出现性能损耗，此处注意消费者版本较高时可以将转换过程交给消费者处理来节省性能。</p><p></p><p></p><h2>新特性改进介绍：元数据事件管理器</h2><p></p><p></p><p></p><h3>引入原因一：元数据不一致</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b9/b91e733e772a996769047a8c7bb98371.png\" /></p><p></p><p>上图是一个两节点的 KoP 集群，客户端生产的 topic 的分区 0，位于 broker1 中。客户端的引导地址是 broker1 和 broker2。现在客户端要发送元数据请求给 broker2，broker2 会响应 metadata response。在 KoP 之前的处理逻辑中复用了 Topic lookup 机制，broker2 返回的 response 中不会包含自身的信息，只有分区所在的 broker1 的信息。然后客户端会向 broker1 分区的 leader 节点发送生产者请求。</p><p></p><p>Broker1 挂掉后，分区 0 会容错到 Broker2 上。于是 broker2 成为分区 0 的 owner。这时客户端向 broker1 发送元数据请求失败，又因为自身没有 broker2 的处理逻辑，所以元数据就无法路由到 broker2 上，出现元数据超时问题。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7e/7ea7c4cad9ae406ed54239fda183864b.png\" /></p><p></p><p></p><h3>引入原因二：Group 残留无效 topic 状态</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5b/5b786ee893b421357f20061309b7d116.png\" /></p><p></p><p>如上图，通过 KoP 消费 topic 时，消费的组元数据信息都会记到 coordinator 中，用 ./bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group my-group --describe可以看到描述的消费信息。当 topic 下线并删除时（./bin/kafka-topics.sh --bootstrap-server localhost:9092 —topic test —delete），再去描述组信息就会返回原数据超时异常。因为 admin 客户端执行删除命令时，请求到达 KoP Cluster，KoP broker 会通过 PulsarAdmin 删除 topic。Pulsar Cluster 处理删除请求时，会发送到所有分区的 owner broker 上，后者负责删除 topic 信息并移除 topic。</p><p></p><p>但因为 Group 元数据信息位于 coordinator 中，其 owner broker 和 topic owner broker 不在一起，所以删除后者时无法清除前者，就会出现残留。问题发生原因是 Group Coordinator 里面有 Group 元数据信息记录了消费分区，客户端在获取分区时 commit offset 会记录 Lag 值，Kafka 当前生产的消息位移。之后获取 topic 信息，但是由于 topic 已经删除，因此会一直返回 onload partition 错误。命令工具不断重复尝试获取元数据直到 Request Timeout 超时并暴露超时。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e9/e9bbfd05a1bfe47865cf07834966ef14.png\" /></p><p></p><p>上述问题的核心原因在于 KoP Broker 属于无状态服务，一致性无法得到很好的保障，所以需要引入一个基于 MetadataStore 的元数据事件处理器， 对应的是 Pulsar ZooKeeper。Broker 上线时会触发 Listener 事件，其他 broker 会监听该事件并处理元数据变更。删除 topic 时会触发 topic 删除事件，其他 broker 会响应事件，coordinator 会将对应的元数据信息移除，解决残留问题。</p><p></p><p></p><h2>总结</h2><p></p><p></p><p>本文介绍了新浪微博通过使用 KoP 落地 Pulsar 来解决大规模 Kafka 集群运维的痛点。新浪微博在 KoP 支持 Kafka 0.9 与 0.10 版本客户端，并引入元数据事件管理器解决版本兼容与日志协议兼容的问题。作为 KoP Maintainer，截至目前，沈文兵已给 KoP 提交 42 个 PR，合并 36 个。未来他会继续参与 KoP 的维护和开发工作。</p><p></p><p>目前 KoP 功能日趋完善，Kafka 的大部分功能都已经在 KoP 中得到实现。如果大家在工作中面对 Kafka 运维的痛点，非常推荐大家通过 KoP 组件搭建解决方案。</p><p></p><p>作者简介：</p><p></p><p>沈文兵，新浪微博数据平台研发工程师，主要负责 Kafka 和 Pulsar 的运维研发工作。开源项目爱好者，Apache Pulsar/BookKeeper/Kafka Contributor，KoP（Kafka-on-Pulsar）Maintainer。</p><p></p><p></p>",
    "publish_time": "2022-08-26 16:43:05",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Oracle首席执行官Larry Ellison陷入新官司：吹过的牛，变成了砸自己脚的石头",
    "url": "https://www.infoq.cn/article/jto6vBKxHMejW3OdYJqD",
    "summary": "<p></p><p></p><p></p><blockquote>甲骨文已经收集了 50 亿用户的详细资料，并借此拿下 424 亿美元的巨额年收入。</blockquote><p></p><p></p><p>作为<a href=\"https://www.iccl.ie/news/class-action-against-oracle/\">爱尔兰公民自由委员会（ICCL）</a>\"的高级研究员，Johnny Ryan 博士联合另外两位代表，于上周五以原告身份在美国发起新的集体诉讼，力求打击甲骨文监控全球客户设备的行为。</p><p></p><p>Johnny Ryan 博士表示，“甲骨文侵犯了全球数十亿人的隐私。这是一家财富五百强企业，但却一直在跟踪全球用户的动向和行为，这无疑是在玩火。我们正在采取行动，希望阻止甲骨文的监控举动。”</p><p></p><p></p><h2>事关 50 亿人？</h2><p></p><p></p><p>即使你不关注甲骨文，这也不意味着甲骨文不关注你。</p><p></p><p>甲骨文涉足很多领域，从<a href=\"https://www.infoq.cn/article/8bvqZ4PBFS3mqpQE98dA\">数据库管理</a>\"到 Java 开发工具包，还运营着一个非常宽泛的“数据市场”，基于广告技术交易“公开透明的受众数据”。</p><p></p><p>在 Johnny Ryan 博士发起的诉讼中，他们声称甲骨文是跟踪与数据行业中的一股中坚力量，该公司称其共收集了 50 亿用户的详细资料，并借此拿下 424 亿美元的巨额年收入。也就是说，这其中很可能有你的数据，因为如果真是“50 亿人”，那代表着甲骨文拥有世界一半以上的人口的个人资料。</p><p></p><p>甲骨文收集的个人资料包括姓名、家庭住址、电子邮件、线上与线下购买记录、线下活动轨迹、收入、爱好和政治观点等。相关记录的详细程度令人咋舌：甲骨文某数据库中，就记录了一名德国男子使用预付借记卡在电竞博彩网站上下注 10 欧元的操作。</p><p></p><p>这起诉讼还包括另外两名原告，人权和隐私中心的研究主任 Michael Katz-Lacabe 和马里兰大学计算机科学教授 Jennifer Golbeck 博士。他们表示，在此次诉讼中，他们代表的是被甲骨文侵犯了隐私权的全球互联网用户。</p><p></p><p>Johnny Ryan 博士引用了 Oracle 首席执行官 Larry Ellison 在 2016 年 OpenWorld 会议上的主题演讲，在此期间 Larry Ellison 吹嘘甲骨文的 ID Graph 中总共有 50 亿人（视频地址：https ://vimeo.com/ 741108673）。</p><p></p><p>Larry Ellison 在台上打趣道：“地球上有多少人？70 亿? 还有 20 亿… 这吓坏了律师”。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/dc/dcb177846b06864e63d4ef21c4f64f58.png\" /></p><p></p><p><a href=\"https://www.iccl.ie/wp-content/uploads/2022/08/File-Stamped-2022-08-19-Oracle-Complaint.pdf\">根据诉讼文本</a>\"，甲骨文旗下 BlueKai 数据管理平台，包含的 ID Graph 工具可帮助营销人员“将不同营销渠道和设备身份与一个客户联系起来”，具有“识别互联网用户，并具有将数据匹配到个人的能力，包括甲骨文定义的所谓‘匿名’数据。”</p><p></p><p>原告辨称，所有这些信息都是通过 Oracle 自己的互联网技术套件收集的，包括 cookie、跟踪像素、设备识别和跨设备跟踪，以及来自第三方的购买数据。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c4/c43e6a902b000f198666b3da57eaac05.png\" /></p><p></p><p>Oracle 将其 ID Graph 描述为“支持所有 Oracle 数据云解决方案”，使 Oracle 的客户能够“无缝地跟踪个人”。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/04/0491cc59e4fccd827ff80d005b814832.png\" /></p><p></p><p>在诉讼中，还特地提到“Larry Ellison 表示他们拥有 50 亿人的数据”。并称甲骨文正在运行“全球监控机器” 。更为重要的是，甲骨文在未经用户同意的情况下收集了这些数据，甚至使用代理来绕过隐私控制，并且还将其出售以获取利润。</p><p></p><p></p><h2>Oracle 最初曾是 CIA 项目</h2><p></p><p></p><p>诉讼材料中，ICCL 还指出，甲骨文的商业模式涉及公民安全，Oracle 这个名字其实源自 1977 年美国中央情报局（CIA）的一个项目代号，而且 CIA 也成为后来甲骨文公司的首位客户。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5a/5a8c90f729bf82effa26b658f217e43b.png\" /></p><p></p><p>常见的报道，一般只会说甲骨文公司成立于“1970 年代后期”，“销售多种面向大中型企业的运营管理软件”。没错，这些都是真的，但这些文章的作者好像总是在回避一些关系。说得更明白一点，要不是甲骨文曾帮助美国建立起现代监控工具体系，Larry Ellison 根本成不了如今的豪商巨贾。</p><p></p><p>“意识到市场对商业数据库产品的潜在需求，Ellison 创立了一家公司，并于 1977 年正式定名为甲骨文。”大家看到的基本都是这套说辞吧？但问题是，真正催生出 Oracle 的契机，是“CIA 想要一套关系数据库”。</p><p></p><p>据称，Ellison 一直相信联邦政府早晚会需要统一的大型国家数据库。在 9/11 袭击事件发生后的几个月里，他开始大力鼓吹建设统一的国安数据库，把所有国民身份证和虹膜扫描信息全都存储进去。于是在 2002 年 1 月的《纽约时报》上，Ellison 表示“我们美国人要想阻止恐怖分子的肆虐，最重要的一步就是把众多政府数据库内的所有信息，全部转移到单一且全面的国家安全数据库当中。”</p><p></p><p>Ellison 解释道，“创建这样一套数据库在技术上并不困难。我们要做的就是把信息从成百上千个独立执法数据库那边，复制到统一的国家安全数据库当中。整个过程大概只需要几个月。利用这套国家安全数据库，就能把各种生物特征组合起来，通过指纹、手印、虹膜扫描等指标快速检测出虚报身份的家伙。”</p><p></p><p>Ellison 全力以赴，建立起了这套无所不包的数据库，甚至还“免费赠送”了大部分基础设施技术。当然，他肯定不会忘记向政府收取额外的服务和系统维护费用。</p><p></p><p>正如 Jeffrey Rosen 在 2004 年的著作《赤裸的人群：在焦虑时代下重获安全和自由》（The Naked Crowd: Reclaiming Security and Freedom in an Anxious Age）中提到，9/11 之后，甲骨文的业务迎来了一波繁荣期。Rosen 解释道，2003 年联邦政府合同金额约 25 亿美元，在甲骨文总体许可收入中占比 23%。</p><p></p><p>Rosen 还讲述了自己跟甲骨文人员会面的情景，其中的 David Carney 曾经是 CIA 的三号人物。在为 CIA 效力 32 年后，Carney 决定退休并被甲骨文聘为信息保障中心负责人。而这处保障中心，是在 9/11 袭击事件后所匆匆建立。</p><p></p><p>Rosen 在书中提到：</p><p></p><p></p><blockquote>Carney 问道，“我想想怎么说才能显得不那么冷血。总之，不得不承认，9/11 事件让生意变得更好做了。在 9/11 之前，我们得费尽心力宣扬威胁和风险。”在袭击发生前，公共和私营部门的领导者根本就没那个耐心听取安全简报，“但现在，他们争着想要解决方案！”</blockquote><p></p><p></p><p>毕竟 Ellison 本人在与 Rosen 的会面中还骄傲地宣称，“基本上，Oracle 数据库在持续跟踪一切。你的银行账户、支票余额、储蓄数据等等，全都在 Oracle 数据库里。还有你的机票预订信息、在亚马逊上买过的书，Yahoo! 上的个人资料等等也一样。”</p><p></p><p>对此，也有前甲骨文员工在 Hacker News 上评论道，“CIA 遇到的问题”不一定是“需要更好的数据库技术”，因为 Oracle 的使命是“在 Oracle 系统上处理或存储世界上所有数据以及数据的每一个比特”。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/83/833624fa6adf253bed293fda5ea85626.png\" /></p><p></p><p>负责此次案件的则是 Lieff Cabraser，一家专打大型科技企业隐私侵权官司的律师事务所。这起诉讼指控甲骨文违反了《联邦电子通信隐私法》、《加利福尼亚州宪法》、《加利福尼亚州侵犯隐私法》、竞争法和普通法。</p><p></p><p>但正如 TechCrunch 指出的那样，类似的隐私诉讼过去一直很难找到立足点。作为市值 2270 亿美元的科技行业巨头，甲骨文也将获得一流的法律援助。</p><p></p><p>所以，这里唯一可以确定的是，这个案子不会很快得到解决，对于三位原告来说注定前路艰难。</p><p></p><p>参考资料：</p><p></p><p><a href=\"https://www.iccl.ie/news/class-action-against-oracle/\">https://www.iccl.ie/news/class-action-against-oracle/</a>\"</p><p></p><p><a href=\"https://www.iccl.ie/wp-content/uploads/2022/08/File-Stamped-2022-08-19-Oracle-Complaint.pdf\">https://www.iccl.ie/wp-content/uploads/2022/08/File-Stamped-2022-08-19-Oracle-Complaint.pdf</a>\"</p><p></p><p><a href=\"https://gizmodo.com/larry-ellisons-oracle-started-as-a-cia-project-1636592238\">https://gizmodo.com/larry-ellisons-oracle-started-as-a-cia-project-1636592238</a>\"</p><p></p><p><a href=\"https://news.ycombinator.com/item?id=325969\">https://news.ycombinator.com/item?id=325969</a>\"</p><p></p><p>今日好文推荐</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651136964&amp;idx=1&amp;sn=7194bafae913e9f65729e8e785d171c6&amp;chksm=bdb8db978acf5281fc47cd4ff8ad9946e0a0ceb74723e77284679d91145b436bdb221b3b9328&amp;scene=21#wechat_redirect\">“扯淡的 DevOps，我们开发者根本不想做运维！”</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651136462&amp;idx=1&amp;sn=b6672b7596b07c88eec8a5d192dd0d60&amp;chksm=bdb8d99d8acf508bc9f304aa500ef1cdc77b35c82e58d4f2c28d09a038606749038afb727e6f&amp;scene=21#wechat_redirect\">Java 正在卷土重来？别开玩笑了，它明明一直很火</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651136412&amp;idx=1&amp;sn=b33c7def8015bb53392c87014d1796ff&amp;chksm=bdb8d9cf8acf50d97492459f2a717a3eee5d9ea0b62ebc0f0a84e79c566ce936dc538247bfab&amp;scene=21#wechat_redirect\">数十位研发发声：研发效能度量，别玩成了一场数字游戏</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651136411&amp;idx=1&amp;sn=755562dc966a6c9b7d125d6e964af863&amp;chksm=bdb8d9c88acf50de3d2a270a75f42d7c2e0250a6e203141ba7e913998ea601e22635f8e20f7a&amp;scene=21#wechat_redirect\">“华为 30 岁以下员工仅占 28%”上热搜；腾讯二季度净利腰斩，员工减少超 5500 人；百度网盘回应人工审核用户照片 | Q 资讯</a>\"</p><p></p><p>活动推荐</p><p></p><p>后疫情时代，企业应该如何提升数字营销效率？做数字营销，怎样才能避免“无效花钱”？~ 神策数据创始人兼 CEO 桑文锋对话极客邦创始人霍太稳，霍太稳视频号直播间为你揭晓答案，快来点击预约吧！</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/6c/6c6c579296a72b9d1442dce367f1c407.jpeg\" /></p><p></p>",
    "publish_time": "2022-08-26 17:08:43",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "理想汽车：从 Hadoop 到云原生的演进与思考",
    "url": "https://www.infoq.cn/article/yOse9OblQT4zTMl1RaEw",
    "summary": "<p>云原生架构下，基于 Hadoop 技术栈搭建数据平台应该如何改造？</p><p></p><p>理想汽车大数据平台涉及的组件多，&nbsp;在从 Hadoop 到云原生演进的过程中边探索，边实践，积累了不少一手经验；同时，他们率先在对象存储上使用 JuiceFS，实现平台级文件共享、跨平台使用海量数据等场景。</p><p></p><p>作者简介：</p><p>聂磊，理想汽车大数据架构师， 从事大数据工作 10 年；大数据架构工作 6 年；对主流大数据技术有深入的理解；目前主要在推进大数据云原生和湖仓一体技术方案在理想汽车的落地。</p><p></p><p></p><h2>理想汽车在Hadoop时代的技术架构</h2><p></p><p></p><p>首先简单回顾下大数据技术的发展，基于我个人的理解，将大数据的发展分了4个时期：</p><p>第一个时期：2006 年到 2008 年。2008 年左右，Hadoop 成为了 Apache 顶级项目，并正式发布了 1.0 版本，它的基础主要是基于谷歌的三驾马车，GFS、MapReduce、BigTable 去定义的。</p><p></p><p>第二个时期：2009 年到 2013 年阶段。雅虎、阿里、Facebook 等企业对大数据的应用越来越多。2013 年底 Hadoop 正式发布 2.0 版本。我有幸在 2012 年的时候开始接触大数据，用 Hadoop 1.0 加 Hive 的模式体验了下，当时感觉很神奇的，大数据用几台机器就可以快速解决原来用 SQL Server 或者 MySQL 解决不了的问题。</p><p></p><p>第三阶段：2014 年到 2019 年，这段时间发展的非常快，期间 Spark、Flink 都成为了 Apache 顶级项目。在这个快速爬升期的过程中，我们还尝试用过 Storm，后来 Storm 就被 Flink 所替代了。</p><p></p><p>第四阶段：从 2020 年至今，2020 年 Hudi 从 Apache 毕业成为顶级项目之后，我个人理解数据湖进入到整个发展的成熟期，到了大数据的数据湖 2.0 阶段。数据湖主要三个特点，首先是统一、开放式的存储，其次是开放式的格式，以及丰富的计算引擎。</p><p><img src=\"https://static001.geekbang.org/infoq/63/635432e34ff8cf66ef836eafb1b4c261.png\" /></p><p>整体的发展过程中，大数据主要是有几个特点，就是大家常说的四个“V”：规模性（Volume）、高速性（Velocity）、多样性（Variety）、价值性（Value）。现在还有第五个“V”（Veracity），数据的准确性和可信赖度。数据的质量是一直被人诟病的，希望行业里能有一套标准把数据湖的质量去做提升，这个可能是数据湖 2.0 出现的标准，因为出现了 Hudi、Iceberg 这些项目，都是想把整个数据湖的管理做好。</p><p></p><p>个人觉得 Hadoop 是大数据的一个代名词，但是大数据并不只有 Hadoop。大数据是在发展过程中由多个组件整合之后形成的一套解决大量数据加工处理和使用的解决方案。这几年，大家基本上认为 Hadoop 是在走下坡路的，首先是 Hadoop 商业化公司 Cloudera 和 Hortonworks 的合并和退市，原来的商业模式无法延续；也面临着快速增长的云供应商在成本和易用性上的挑战，以及 Hadoop 本身生态系统的日益复杂。</p><p></p><h3>理想汽车大数据平台当前架构</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/d9/d96bd6d1ac11b2e6a67457fb8123e8f3.png\" /></p><p>在这个阶段，理想汽车的大数据平台如上图所示。理想汽车用了很多开源的组件。</p><p>传输层：Kafka 和 Pulsar 。平台构建初期整体都用的 Kafka，Kafka 的云原生能力比较差，Pulsar 在设计之初就是按照云原生架构设计的，并且有一些非常适合 IoT 场景的能力，和我们的业务场景也比较匹配，所以我们近期引进了 Pulsar；</p><p></p><p>存储层是 HDFS + JuiceFS；</p><p></p><p>计算层目前的主要的计算引擎是 Spark 、Hive 和 Flink，这些计算引都是跑在现在的 Yarn 上。三个计算引擎是通过 Apache Linkis 去管理的，Linkis 是微众银行开源的，目前我们对 Linkis 用的也是比较重的；</p><p></p><p>图片的右侧数据库，第一个 MatrixDB ，它是一个商业版的时序数据库，TiDB 主打做 OLTP 和 OLAP 的混合场景，目前我们主要用它来做 TP 的场景。StarRocks 负责 OLAP 的场景；</p><p></p><p>ShardingSphere，是想要用它的 Database Plus 的概念去把底下的数据库统一的去做一个网关层的管理。目前还在探索阶段，有很多新增特性我们都很感兴趣；</p><p></p><p>Thanos 是一个云原生的监控方案，我们已经将组件、引擎和机器的监控都整合到 Thanos 方案里；</p><p></p><p>应用层是四个主要的中台产品，包括数据应用、数据开发、数据集成和数据治理。</p><p></p><h3>特点</h3><p></p><p>大家通过大数据平台的现状可以发现一些特点：</p><p>第一，整个方案的组件是比较多的，用户对这些组件的依赖性强，且组件之间互相的依赖性也比较强。建议大家在未来组件选型的时候尽量选择云原生化比较成熟的组件；第二，我们的数据是有明确的波峰波谷。出行场景一般都是早高峰晚高峰，周六周日人数会比较多；第三个特点，我们数据的热度基本上都是最热的，一般只访问最近几天或者最近一周的数据。但是产生了大量的数据，有的时候可能需要大量回溯，因而数据也需要长久的保存，这样对数据的利用率就差了很多。最后，整个数据体系目前从文件层面看缺少一些有效的管理手段。从建设至今，基本上还是以 HDFS 为主，有大量的无用数据存在，造成了资源的浪费，这是我们亟待解决的问题。</p><p></p><h3>大数据平台的痛点</h3><p></p><p>第一，组件多，部署难度高、效率低。围绕 Hadoop 的大数据组件有 30 多个，常用的也有 10 几个之多。有些组件之间有强依赖和弱依赖，统一的配置和管理变得非常复杂。</p><p></p><p>第二，机器成本和维护成本比较高。为了业务的稳定运行，离线和实时集群进行了分开部署。但上面提到的业务特点，我们业务波峰波谷现象明显，整体利用率不高。集群组件繁多需要专门人员管理和维护。</p><p></p><p>第三，跨平台数据共享能力。目前跨集群共享数据只能通过 DistCp 方式同步到其他 Hadoop 集群。无法方便快捷的同步到其他平台和服务器上。</p><p></p><p>第四，数据的安全和隐私合规。基于不同的数据安全需求，普通用户通过 Ranger 进行管理，特殊安全需求只能通过构建不同集群并设置单独 VPC 策略的方式来满足，造成很多数据孤岛和维护成本。</p><p></p><p></p><p></p><h2>理想汽车云原生的演进与思考</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c2/c28241495088cac9ce5608a283e14c1f.png\" /></p><p>首先，先简单分享一下我个人理解的云原生：</p><p></p><p>第一，云原生是在云计算的基础上衍生出来的。现在大家用的如阿里云、 AWS、腾讯云、百度云等云厂商，最开始提供的都是 IaaS 层的技术服务，帮企业把存储、计算、网络这些这些最基础的东西封装好统一管理，企业只需要在上面申请服务器就可以了。申请了服务器之后，这些服务器还是由云厂商来管理的，也就是大家传统的上云操作。</p><p></p><p>云原生离不开云计算，笼统地说，云原生属于云计算的 PaaS 层服务，主要是面向开发者的一类应用。云原生必须在云上安装，是一种基于云计算的软件开发应用方式。云+原生，云即云计算，原生则是摒弃传统的运维开发框架，通过容器化、DevOps，还有微服务架构实现应用弹性伸缩和自动化部署，充分利用云计算资源实现在最少的空间里做最大的事。也能解决我们目前大数据系统的一些痛点，比如扩展性和维护性都比较差，需要大量人力与时间等。</p><p><img src=\"https://static001.geekbang.org/infoq/90/901755fe7fd8bdb3c9b560b3cc2fe940.png\" /></p><p>上图简单列了一下云原生的几个时间点</p><p>第一个阶段， AWS 提出了云原生的概念，并且在 2006 年推出了 EC2，这个阶段是服务器阶段，上文提到的云计算阶段；</p><p></p><p>第二个阶段，云化阶段，主是在开源 Docker 发布和谷歌开源了 Kuberneters 之后。Kubernetes 是一个轻便的和可扩展的开源平台，用于管理容器化应用和服务。通过 Kubernetes 能够进行应用的自动化部署和扩缩容；</p><p></p><p>第三个阶段，2015 年的时候成立了 CNCF 基金会，在主推云原生概念，帮助云原生整体发展的更好。最后是 Knative 的开源，Knative 一个很重要的目标就是制定云原生、跨平台的 Serverless 编排标准。衍生到现在，已经是云原生 2.0 阶段，即 Serverless 这个阶段。我个人理解大数据的发展应该也是朝着 Serverless 的方向去发展。比如现在 AWS 整个在线的服务基本上都做到了 Serverless。</p><p></p><h3>大数据云原生架构</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/f4/f4beae6b1eed1dbd54e79eeab48774fc.png\" /></p><p>接下来介绍一下理想汽车大数据平台在云原生化之后组件发生的变化：</p><p>存储层，云原生化之后所有的存储基本上都是对象存储了。上面的架构图引出了 Lustre，下文会详细介绍。大家可以理解为「云存储」这一层主要是以 JuiceFS 来管理对象存储和 Lustre 并行分布式文件系统（注：由于 Lustre 的单副本问题，我们目前也在考虑使用云服务商提供的并行文件系统产品）；</p><p></p><p>容器层，主要是在计算、存储、网络之上，全部都用 Kubernetes 加 Docker 来替代，所有的组件都是在这上面生长出来的；</p><p></p><p>组件部分，首先是大数据计算框架，我们可能会废弃掉 Hive，直接沿用 Spark 和 Flink，通过 Hudi 去做数据湖 2.0 的底层能力支撑并逐步替换HDFS；</p><p></p><p>中间件部分，除了 Pulsar 以外还有 Kafka，目前 Kafka 的云原生化做的并不是特别好，我个人更倾向于用 Pulsar 去替换 Kafka。目前线上已经使用Linkis适配了所有Spark引擎，后面会进行Flink的适配和整合。ShardingSphere 在 5.1.2 版本刚刚支持云原生，我们会按计划进行场景验证和能力探索；</p><p></p><p>数据库层，还是 TiDB、StarRocks、MatrixDB，目前这三个数据库已经有云原生的能力，它们都支持对象存储。但这一块还没有单独去测过，我们目前用的还都是物理机。因为对于数据库来说，当前对象存储提供的IO能力还无法满足数据库的性能要求，会使得数据库的整体性能大打折扣；</p><p></p><p>运维方面，由 Thanos 方案多加了一个 Loki，主要是做云原生的日志收集。但是 Loki 和 Thanos 只是其中两个，未来我理解应该会朝着阿里开源的SREWorks能力看齐，把整个的质量成本效率和安全全部都封在综合运维能力里边，这样就可以把整个的云原生管理起来；</p><p></p><p>可观测性，云原生领域最近比较热门的概念。现在大家做的组件，有一些是在有热度之后，才开始发展云原生的，它并不是一开始生在云上，它只是后面希望长在云上。这种情况下它会遇到一些问题，第一个问题，就是没有全面的可见性的监控。我们考虑后续如何把这些组件整体的出一个方案，在所有组件上到云原生后可以有效的监控。</p><p></p><p>总结一下，我个人觉得大数据未来的云原生基本上就是：</p><p>1.&nbsp;统一使用云原生的存储作为所有组件（包括数据库）的底层存储;</p><p>2.&nbsp;所有组件都运行在容器中;</p><p>3. 使用 Serverless 架构服务上层应用。</p><p></p><p>但是这样也给目前的数据平台产品带来挑战，就是如何设计具备 Serverless</p><p>能力的产品来给用户使用。</p><p></p><h3>大数据云原生的优势</h3><p></p><p>第一点，存算分离，弹性伸缩。使用物理机部署 Hadoop 之后，如果需要扩容缩容还需要去联系运营商，并且可能会有很长的周期，存算分离很好地解决了这个问题。其次是按需付费，不用购买闲置资源，目前我们整个的业务场景的数据是有波峰波谷的，波峰的时候需要准备机器，波谷的时候需要撤机器，但现在是做不到的。现在我们基本上是把所有的机器都堆到波峰，波峰的时候能满足需求，稳定不失败，但它在波谷的时候最少 12 个小时左右是闲置的，这种情况下资源也是要付费的。云原生之后我们就可以不用再为此买单了。</p><p></p><p>第二点，自动化部署和可运维性。Kubernetes 是支持 DevOps 集成化的部署方案的。这样我们的组件整体可以实现快速的部署（比如通过 Helm chart），把组件运维的能力下沉到云原生平台上，这样大数据就不需要考虑组件运维场景了。</p><p></p><p>第三点，对象存储。对象存储是云计算推出的最核心最主要的产品。对象存储的好处不言而喻了，易扩展，存储空间无上下限，单价比较低，而且对象存储还分为低频存储、归档存储等多种存储类型，进一步降低存储成本，数据就可以存更长时间。同时成本可控，高可靠，操作复杂性低也都是对象存储的优势。</p><p></p><p>第四点，安全和合规性。云原生之后可以实现专用命名空间，多租户隔离，远程认证。目前我们做到的基本上都是网络层面上的隔离，HDFS的文件管理大家公认的方案是Ranger。通过 Ranger 去管理 HDFS 的目录权限，也能管理如 Hive server、HBase、Kafka 的一些权限，但是相对而言这些权限都会偏弱一些。</p><p></p><p>还有一个方案是 Kerberos，整个大数据组件的安全性会提高很多，但是它有很多的成本，它任何一个请求都要去验证。这个方案目前我们没有使用过，和我们的集群环境和场景有关系，我们基本上都是内网的，并不对外提供服务。如果大家做的大数据项目需要对外网提供一些服务，还是需要有强认证，不然数据很容易泄露。</p><p></p><h3>大数据云原生的难点</h3><p></p><p>大数据云原生的难点同样也是存在的。</p><p></p><p>第一，大数据相关的组件是比较多的，同时 Kubernetes 的更新比较快，组件和组件之间交叉之后，兼容性、复杂性和扩展性，都会存在问题。</p><p></p><p>第二，资源的分配和再分配。Kubernetes 是通用的容器资源调度工具，很难满足不同大数据组件的资源使用场景。大数据场景下资源使用会比较大，请求频率高，每次启动的 pod 的数又会比较多，这种情况下，目前没有什么好的方案。目前我们正在看 Fluid 这个方案，Fluid 也实现了 JuiceFS 的 runtime，这个也是我们后边要去深入调研的，Fluid 目前宣称是可以支持大数据和 AI 的，并不是只有 AI 的场景，因为大数据和 AI 的场景是比较像的，都是数据密集型的操作，Fluid 在计算效率和数据抽象管理方面是有了一些突破性的进展。</p><p></p><p>第三点，对象存储也是有一些劣势的。对象存储的劣势是元数据操作性能低、和大数据组件兼容性差、最终一致性等问题。</p><p></p><p>最后一点，就是数据密集型应用。存算分离模式无法满足大数据、AI 等数据密集型应用在计算运行效率、数据抽象管理方面的需求。</p><p></p><p></p><h2>JuiceFS在云原生方案的探索和落地</h2><p></p><p></p><p>在 JuiceFS 开源之前我们就已经关注并做了一些落地的测试，开源版上线之后，我们就马上上线使用了。上线的时候也遇到了一些权限的问题和几个小的 bug，社区非常给力，快速地帮我们都解决了。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/22/223775cb24633bb747d55e15f69a3148.png\" /></p><p>要下线 HDFS 是因为它的扩展性差，同时我们的数据量比较大，HDFS 的存储成本比较高。在存储了几批数据后，物理机的空间就不够了，而且需要的计算非常多。当时我们的业务发展还在初期，为了尽可能从数据中获得价值，我们要保留尽可能多的数据。而且 HDFS 需要三副本，我们后来改成两副本，但是两副本还是有风险的。</p><p></p><p>在这个基础上，我们深度测试了 JuiceFS，测试完成之后，我们很快就把 JuiceFS 引到我们的线上环境。把一些比较大的表从 HDFS 迁移到 JuiceFS 里，缓解了我们的燃眉之急。</p><p></p><p>我们对 JuiceFS 比较看重的三点：</p><p>第一，&nbsp;JuiceFS 是多协议兼容。完全兼容 POSIX、HDFS 和 S3 协议 ，目前用下来都是百分百兼容的，没有遇到任何问题。</p><p></p><p>第二，跨云的能力。当企业有一定规模之后，为了避免系统性风险，都不会只使用一个云服务商。不会绑在一个云上，都会是多云操作的。这种情况下，JuiceFS 的跨云数据同步的能力就起到了作用。</p><p></p><p>第三，云原生的场景。JuiceFS 支持 CSI，目前 CSI 这个场景我们还没有用，我们基本上都是用 POSIX 去挂载的，但是使用 CSI 的方式会更简单更兼容，我们现在也正在往云原生上去发展，但整个的组件还没有真正上到 Kubernetes。</p><p></p><h3>JuiceFS 在理想汽车的应用</h3><p></p><p></p><h4>场景1：从 HDFS 将数据持久化到对象存储</h4><p></p><p><img src=\"https://static001.geekbang.org/infoq/7c/7c8a4101487927bbb0ad2fb57893b044.png\" /></p><p>JuiceFS 开源之后，我们就开始尝试把 HDFS 上的数据同步到 JuiceFS。开始同步的时候是使用 DistCp，结合 JuiceFS 的 Hadoop SDK 同步非常方便，整体迁移比较顺利。之所以要把数据从 HDFS 迁移到 JuiceFS 上，是因为遇到了一些问题。</p><p></p><p>第一，&nbsp;HDFS 的存算耦合设计扩展性差&nbsp;，这个是没有办法解决的。我个人从一开始接触大数据的认知就是大数据是必须要部署在物理机上的，而不是在云主机。包括后来云厂商推出的各类 EMR 系统，其实是在对 Hadoop 进行封装，最近一两年这些 EMR 系统都在逐渐去 Hadoop 化。</p><p></p><p>第二，HDFS 难以适配云原生化。现在的 HDFS 很难适配云原生，因为它比较重，虽然社区一直在着重发力去做云原生，但是我个人认为 Hadoop 的发展趋势在走下坡路，未来应该以对象存储为主。</p><p></p><p>第三，对象存储也有一些弊病，它不能很好的适配 HDFS API，由于网络等原因性能跟本地盘比也相差很多，另外 list 目录等元数据操作也很慢。我们通过 JuiceFS 做一些加速，测下来性能非常可观，在有缓存的情况下基本上可以媲美本地盘，基于此我们快速地将当前的场景直接切换到 JuiceFS 上。</p><p></p><h4>场景2：平台级别的文件共享</h4><p></p><p><img src=\"https://static001.geekbang.org/infoq/bf/bf93ff0ead0b35b792b29dd2101b0200.png\" /></p><p>我们目前的整个调度系统、实时系统、开发平台的共享文件的数据全部都是存在 HDFS 上的，后续如果要是停止使用HDFS ，需要把这些数据迁移走。目前的方案是用 JuiceFS 对接对象存储，通过应用层的服务，全部以 POSIX 的方式挂载上去，大家就可以无感地去请求 JuiceFS 里的文件。</p><p></p><p>JuiceFS 在这个场景满足了我们大部分的应用需求，但还有些小场景存在问题。最初的设想是会把 Python 环境之类的都放进去，后来发现实操难度太大，因为 Python 环境里边有大量的小文件，加载的时候还是会有问题。类似 Python 环境这种包含大量碎文件的场景还是需要存储在本地盘来操作。后续我们准备挂一块块存储，专门来做这件事。</p><p></p><p>分享几个我们之前使用 HDFS 遇到的问题：</p><p></p><p>第一个，当 NameNode 压力大或 Full GC 时会有下载失败的情况，目前暂时没有一个完美的方案解决。我们的方案是尽量加内存，或者在下载包的时候加一些重试，避一避它的高峰期，但是这种情况下很难完全解决 HDFS 的问题，因为它终究是 Java 写的，GC 的场景是没有办法避免的。</p><p></p><p>第二个，在跨系统里面去使用 HDFS 的时候，比如我们有两个集群，现在要用一个集群去共享文件，基本上是不现实的，因为需要开通网络，来把两个集群之间打通或者应用上打通，这样安全性是没有办法保证的。目前我们基本上就是两个集群是独立各自维护自己的共享文件。现在实时平台（如 Flink 平台）已经切换到 JuiceFS 上了，目前还是非常顺利，没有遇到什么问题。</p><p></p><p>第三个，目前我们有大量的物理机部署，物理机部署都是单集群的，没有容灾的策略，如果哪天机房出了一些灾难性的问题，我们整个服务就不可用了。但是对象存储它本身是跨机房，是同一个 region 里面，应该都是有最少三个副本，云厂商帮我们做到了备份。后续，我们可能会发展多云，希望通过 JuiceFS 去共享一些高级别的文件、核心的数据库，包括一些核心的备份文件，在多云里面去做备份。这样就实现了多云、多 region、多地域，就可以解决现在单点容灾的问题。</p><p></p><h4>场景3：海量数据跨平台使用</h4><p></p><p><img src=\"https://static001.geekbang.org/infoq/b2/b27b4f9b398014dac0e8e017e30c2d00.png\" /></p><p>另外一个场景，平台和平台之间全部都是通过 JuiceFS 去共享海量数据。我们这边的共享的数据中第一类是路试车的数据，路试车会有大量的视频语音图像数据上传，这些数据上传了之后会直接进到 JuiceFS 里，方便下游去做一些同步和共享，包括一些数据的筛查，再拿到 PFS 就是并行文件系统，其下面挂载的是 SSD。这样可以让 GPU 利用率更高一些，因为对象存储的能力是相对比较弱的，不然 GPU 的能力就会有大量浪费。</p><p></p><p>剩下的数据类型包括车辆上报的一些用于分析的日志，埋点数据，还有一些国家平台需要的车辆相关的信号数据，这些数据都会进到数仓里面去做一些分析。也会对这些数据做一些特征数据提取，给算法团队去做模型训练，或者做一些 NLP 的检索和其他的更多场景。</p><p></p><h4>新场景：云原生存储加速 - Lustre 作为读缓存 （测试中）</h4><p></p><p><img src=\"https://static001.geekbang.org/infoq/cc/cce05c49f9b66a4be86f6c6b652eccb0.png\" /></p><p>现在我们正在测的是另外一个场景是在对象存储层挂一个 Lustre 去给 JuiceFS 去做读缓存，通过 Lustre 的缓存来帮助 JuiceFS 来提高读取速度和缓存命中率。</p><p></p><p>这样可以有一个好处是我们现在用的都是物理机，它是有物理盘的，物理盘可以用来缓存数据。但是因为计算任务在多个节点执行，缓存的命中率不太高。这是因为社区版 JuiceFS 目前还不支持 P2P 的分布式缓存，只支持单节点的本地缓存，每一个节点可能会读很多数据。这种情况下也给计算节点造成了一些磁盘的压力，因为缓存会占用一定的磁盘空间。</p><p></p><p>目前我们的方案是通过 Lustre 来作为 JuiceFS 的读缓存。具体来说是根据需要缓存的数据大小，将一个容量大概是 20~30TB 的 Lustre 文件系统挂载到计算节点本地，然后将这个 Lustre 挂载点作为 JuiceFS 的缓存目录。这种情况下 JuiceFS 读完数据之后，可以异步缓存到 Lustre 里。这个方案可以有效解决缓存命中率不高的问题，大幅度提高读取性能。</p><p></p><p>如果我们在 Spark 场景往对象存储里直接写数据的时候，会有带宽和 QPS 的限制，如果写入得太慢，上游的任务可能会发生抖动，在这种情况下可以通过 JuiceFS 的写缓存功能把数据先写到 Lustre 里，再异步写到对象存储，这个方案在某些场景下是适用的。但是有一个问题是 Lustre 并不是一个云原生的方案，它对于用户来说是有感知的，用户在启动 pod 的时候需要显式写一个命令把它挂载上去。因此后面我们也希望对 JuiceFS 做一些改造，自动去识别对象存储和 Lustre，然后自动实现一些缓存的机制，这样就不需要用户来感知 Lustre 的存在。</p><p></p><p>目前这个方案的 PoC 已经完成，通过了基础测试，接下来我们会在生产环境做大量的压测，预计今年 Q3 应该可以正式上线覆盖一些边缘业务。</p><p></p><h3>JuiceFS 在大数据云原生的整体方案</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/50/50da116e73125a205e4de0f70621dfd0.png\" /></p><p>从整体方案的架构图可以看到，目前 JuiceFS 客户端提供的三种方式我们都有用到。</p><p></p><p>如上图左半部分所示，我们会有独立的 Spark、Flink 集群，我们通过 CSI Driver 的方式将 JuiceFS 直接挂载到整个集群上，这样用户启动 Spark 和 Flink 的时候，就完全感知不到 JuiceFS 到存在了，计算任务的读写都是通过对象存储来完成。</p><p></p><p>这部分目前有一个有关 shuffle 的问题。因为 Spark 任务在计算过程中的 shuffle 阶段需要大量的数据落盘，这其间产生的大量文件读写请求对于底层存储的性能要求较高。Flink 相对来说好一些，因为它是流式的，不需要大量的落盘。未来我们希望 JuiceFS 可以直接写到 Lustre 里，但是这样就需要在 JuiceFS 里做一些改造，通过客户端集成的方式，让 JuiceFS 直接读写 Lustre，这对于用户来说就无感知了，也能提升 shuffle 阶段的读写性能。</p><p></p><p>上图右半部分的应用有两个场景。</p><p></p><p>一个是简单查询一下 JuiceFS 的数据，例如通过 HiveJDBC 来进行数据预览，这个场景可以通过 S3 网关访问 JuiceFS。</p><p></p><p>第二个是大数据平台和 AI 平台联动的场景。比方说 AI 平台的同事在日常工作中需要经常读取样本数据、特征数据等，而这些数据通常是由大数据平台上的 Spark 或者 Flink 任务产生的，并且已经存储到了 JuiceFS 里。为了不同的平台之间能够共享数据，在 AI 平台的 pod 启动时，会通过 FUSE 的方式将 JuiceFS 直接挂载到 pod 里，这样 AI 平台的同事就可以通过 Jupyter 直接访问 JuiceFS 里的数据做一些模型的训练，而不用像传统的架构那样在不同平台之间重复拷贝数据，提高了跨团队的协作效率。</p><p></p><p>因为 JuiceFS 使用 POSIX 标准的用户、用户组进行权限控制，同时容器启动默认是 root 用户，导致权限不好管控。因此我们对 JuiceFS 做了一个改造，通过一个认证 token 来挂载文件系统，这个 token 里面包含元数据引擎的连接信息和其他一些权限控制信息。在某些需要同时访问多个 JuiceFS 文件系统的场景，我们使用 JuiceFS S3 网关并结合 IAM 策略做统一的权限管理。</p><p></p><h3>目前使用 JuiceFS 遇到的一些难题</h3><p></p><p>第一点，基于用户和用户组的权限管理功能比较简单，在某些场景容器启动默认为 root 用户，权限不好管控。</p><p></p><p>第二点，关于 JuiceFS Hadoop SDK 的配置优化。目前我们对 JuiceFS Hadoop SDK 进行优化的手段主要有三个配置：juicefs.prefetch、juicefs.max-uploads&nbsp;和&nbsp;juicefs.memory-size。其中在调优&nbsp;juicefs.memory-size&nbsp;配置的过程中遇到了一些问题，这个配置的默认值是 300MB，官方的建议是 设置默认值 4 倍大小的堆外内存，也就是 1.2GB。目前我们大部分任务都是配置到 2GB 的堆外内存，但是有些任务即使配置了超过 2GB 的内存也偶尔会写入失败（HDFS 可以稳定写入）。不过这个并不一定是 JuiceFS 的问题，也有可能是 Spark 或者对象存储的原因导致。因此目前我们也在计划把 Spark 和 JuiceFS 深度适配以后，再一步一步来找原因，争取把这些坑都趟过去，在保证任务稳定的情况下把内存降下来。</p><p></p><p>第三点，由于整体架构（JuiceFS + 对象存储 + Lustre）变得复杂，可能的故障点变多，任务的稳定性可能会有一些下降，需要其它容错机制保障。例如 Spark 任务在 shuffle write 阶段可能会有类似「lost task」这样的报错，目前还没有定位到具体的错误原因。</p><p></p><p>前面提到的 JuiceFS + 对象存储 + Lustre 的架构组合一定程度上提升了读写性能，但同时也使得架构更加复杂，相应地增加了一些可能的故障点。比如说 Lustre 没有很强的容灾副本能力，如果 Lustre 突然挂了一个节点，正在运行的任务到底能不能稳定地继续读写 Lustre 里面的数据，或者 Lustre 里的数据意外丢失了，是否还能稳定的去 JuiceFS 里通过对象存储重新拉出来，这个目前是不确定的，目前我们在也在做这种灾难性的测试。</p><p></p><p></p><h2>未来和展望</h2><p></p><p></p><h3>基于 Flink + Hudi + JuiceFS 的实时数据湖方案</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/28/28eba758dcd6a2634f342bd591cbc215.png\" /></p><p>近期我们要做的一个是 Flink+ Hudi + JuiceFS 的实时数据湖方案。上图中左边是数据源，通过 Flink 、Kafka/Pulsar，把数据实时地写到 Hudi 里，同时 Hudi 的数据会落到 JuiceFS 里替换我们目前的实时数仓。</p><p></p><h3>大数据云原生的远期规划</h3><p></p><p>最后，介绍一下理想汽车大数据云原生的远期规划，也是一个展望。</p><p></p><p>第一点是统一的数据管理和治理系统。我们认为数据湖 2.0 时代，最大的需要解决的问题就是把数据湖 1.0 场景中的数据沼泽的问题解决掉。但现在好像并没有一个比较好的统一元数据管理、数据目录管理、数据安全管控的开源产品，类似 AWS Glue、AWS Lake Formation。目前我们在做一个「起源系统」的项目，这个系统第一步就是把上面的数据库、对象存储里边所有的元数据做统一的目录管理，统一的安全管控，以及统一的数据管理，这块儿我们正摸索着往前走。</p><p></p><p>第二点是更快、更稳定、更低成本的底层存储能力。目前所有的场景最大的难点是在对象存储上，对象存储的优势是稳定、低成本，同时对象存储也在持续迭代。就目前而言我觉得如果大数据云原生要发展，对象存储必须是要在确保稳定的前提下提供更好的性能。</p><p></p><p>同时 S3 可能宣称支持强一致性了，但是目前我理解基于对象存储的架构设计，可能很难能实现强一致性，或者说它为了实现强一致性，势必要牺牲一些东西，这可能是一个需要权衡的问题。JuiceFS 原生支持强一致性，这个功能对于大数据平台来说非常友好。</p><p></p><p>第三点，更智能、更高效、更易用的查询引擎。引申一下前面提到的对湖仓一体的思考，目前湖仓一体还是在发展初期 ，可能还需要经历 5~10 年的发展过程。Databricks、微软都在尝试做数据湖上的向量化 MPP 引擎，希望能把湖仓一体架构推起来。这可能是一个未来的发展方向，但是短时间内好像并没有办法用一个引擎来满足所有场景的需求。</p><p></p><p>我们目前的架构基本上是配备了所有的查询引擎，比如 Spark、Flink、关系型数据库（面向 OLTP 的场景）、时序数据库、OLAP 数据库。原则上还是谁优用谁，我们上层再通过统一的中间件去做管理。再比如 Snowflake，它现在虽然已经支持了同时查询结构化和半结构化的数据，但是未来像人工智能涉及的的非结构化数据（如图片、语音、视频）到底应该怎么支持，目前还是不太清楚。不过我认为这肯定是以后的一个发展方向，理想汽车也有类似的人工智能场景，所以我们会与各个业务方一起去探索和共建。</p><p></p><p>最后，整个大数据发展的最终目标还是要以最低的成本、最高的性能完成数据分析，从而实现真正的商业价值。</p>",
    "publish_time": "2022-08-26 17:58:26",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "阿里在开源领域又有哪些新动向？来首届阿里开源开放周找答案！",
    "url": "https://www.infoq.cn/article/3rBcBW7v2z46Wv6LVoX6",
    "summary": "<p></p><p>随着开源的价值受到认可和推崇，越来越多的企业走上了“开源之路”。其中，阿里巴巴在十几年开源的沉淀中，从开源软件的使用者、贡献者，成长为开源软件的开拓者，已经成为国内开源走在前面的厂商之一。&nbsp;</p><p>&nbsp;</p><p>据了解，阿里累计有&nbsp;3000&nbsp;多个开源项目、3&nbsp;万多位全球贡献者，也收获了全球开发者&nbsp;100&nbsp;多万个&nbsp;star，开源的数量和活跃度，一直都处于前列。根据《中国开源十年洞察报告》，阿里已经连续十年蝉联中国厂商开源活跃度、影响力双第一。InfoQ&nbsp;近期发布的《中国开源发展研究分析&nbsp;2022》研究报告显示，阿里&nbsp;11&nbsp;大开源项目上榜中国开源项目&nbsp;Top30&nbsp;榜单，占比超过三分之一；此外，在企业端对开源的赋能维度上，阿里巴巴在国内厂商中综合得分排名第一。</p><p>&nbsp;</p><p>8&nbsp;月&nbsp;22-24&nbsp;日，阿里巴巴首届开源开放周以线上的形式亮相，邀请了业界顶尖技术专家学者，与阿里开源领军人和头部项目代表共同探讨开源领域的最佳实践和新机遇。本次开源开放周，在主论坛之外，还特设了&nbsp;5&nbsp;大分论坛，聚焦操作系统、数据库、云原生、大数据、终端&nbsp;5&nbsp;个领域，帮助开源人探索技术开放生态的更多可能。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/80/80238e548fcaffac9af3136409d4bede.png\" /></p><p></p><p></p><h2>一、开源生态与未来</h2><p></p><p></p><p>开源发展至今，已经成为基础软件的重要创新源头，云时代下，也给开源带来了新的软件开发模式和商业模式。本次开源开放周，主论坛聚焦「开源生态与未来」，探讨开源生态的新技术和趋势，展望云与开源的更多可能。</p><p>&nbsp;</p><p>开源从早期理想主义的自由软件，发展到当前开源生态的多元化、商业模式的多元化，其已成为基础软件的源头。阿里巴巴开源委员会分管委员蒋江伟在主题为《阿里开源的动与势》的演讲中分享到，阿里巴巴开源的历史，可以划分为使用、贡献、开拓三个阶段。阿里在创业早起就大量使用开源软件，阿里技术的发展也根植于开源的沃土中。因此，当阿里在大规模互联网系统和云的研发中，积累了越来越多的技术经验，解决了越来越多的新问题之后，也积极地将自身的实践以开源软件的形态回馈到社区中。</p><p></p><p>随着历史的发展以及阿里在开源侧实践的深入，阿里巴巴对开源的认知也一直在演进。阿里认为，开源+云计算共同构成了数字世界的根，站在用户的视角，云平台与开源社区的有效合作，赋予了用户灵活的选择权。而阿里巴巴开源的独特的生命力在于“三位一体”，三位一体是指阿里自用的技术、社区开源的技术和阿里云对客户提供的技术是一个版本&nbsp;——“三位一体”的方式使得自研、开源与云计算商业形成血脉相通的整体。阿里通过集团业务自行验证，再对外开源的策略，构建起一个良性的开源生态。也是随着阿里巴巴对开源认知的升级，蒋江伟宣布，近期阿里对开源委员会和开源办公室经历了一轮升级，开源委员会作为负责制定阿里开源战略的组织，新设置了9位领域副主席，把基础软件领域的开源共建作为阿里开源的重心，明确了四大重点开源方向：操作系统、数据库、大数据与云原生。</p><p>&nbsp;</p><p>随后，MongoDB&nbsp;副总裁&nbsp;Matt&nbsp;Asay&nbsp;带来了《MongoDB&nbsp;助力开发者实现高效开发》的分享，分享中&nbsp;Matt&nbsp;Asay&nbsp;表示：“在云时代，开源技术的好处就是，只要建立在像&nbsp;MongoDB&nbsp;这样的通用开源技术上，使用者就可以从一个云移动到另一个云，从一个数据中心移动到另一个数据中心……在不同的环境中使用MongoDB，给使用者提供了选择的自由。”</p><p>&nbsp;</p><p>bilibili&nbsp;技术委员会主席毛剑，也带来了《B&nbsp;站在云原生与开源方向的探索与实践》的主题分享，他提到：“为什么我们会如此关注云原生或者开源的社区和生态？最核心的一个点就是，我们在享受云原生社区的技术输出时，可以选择不同的组件，使业务开发更高效；同时，当我们使用开源组件遇到问题或者&nbsp;bug&nbsp;时，我们可以做技术的输入，因为这些问题大家可能都会遇到，所以我修掉一些&nbsp;bug、提供一些&nbsp;feature，让更多人受益，这其实就是云原生或者说开源社区一个大的作用——让更多的人参与到项目之中”。</p><p>&nbsp;</p><p>那么在未来，云与开源的结合为开源生态提供了哪些新的可能性？在《数字世界已来，开源生态与未来》的圆桌讨论环节，阿里巴巴邀请到中国信息通信研究院云计算与大数据研究所副所长栗蔚，上海交通大学长聘教授、人工智能研究院总工程师、上海白玉兰开源开放研究院执行院长金耀辉，Apache&nbsp;软件基金会首位华人董事、Tetrate&nbsp;创始工程师吴晟，与阿里巴巴开源委员会秘书长、开源办公室负责人王晶昱共同展望了云与开源的更多可能。</p><p>&nbsp;</p><p>王晶昱在讨论中分享说：“未来，云计算能够帮助开源软件实现更好的服务延伸，从而创造更好的服务；在此过程中，又可以反哺云计算公司，让其有更好的&nbsp;Runtime&nbsp;Hosting；同时还能够帮助它的客户快速处理他们遇到问题，以上三方都将基于云和开源的结合受益。”</p><p></p><p>栗蔚表示，开源与云计算的结合，在未来会成为软件开发流水线或工程化的基础设施，继而实现互相促进融合的过程。吴晟也做了进一步的补充，他表示，云服务商作为最终向用户售卖服务的人，有责任去支撑用户最终的需求、问题，云厂商收集到的用户资料越多，基础数据源就越大，从而通过数据分析论证提出的解决方案是否合理，优化方向是否正确。</p><p></p><p>当谈及云与开源的联系时，金耀辉认为，中国有一大批开源的参与者，都是从云计算开始的。当社区由技术型主导变成服务型主导时，开发者更关心服务怎样交付以及&nbsp;DevOps&nbsp;等新兴事物，其整个过程都需要开源。因此，无论是开源社区的引入，还是目前开源的服务生态，二者都应是相辅相成、相互促进的关系。</p><p></p><h2>二、云时代开源操作系统的技术实践</h2><p></p><p>&nbsp;</p><p>目前，阿里巴巴构建了完整的云原生底层系统——袋鼠，其在计算、存储网络等操作系统的核心组件方面都有非常深入地研究。分论坛出品人、阿里巴巴开源技术委员会副主席、龙蜥社区理事长马涛在致辞中表示，云原生时代，操作系统在机密计算、存储、网络以及大规模机器运维方面均面临挑战，阿里巴巴在云场景下积累了丰富的经验，这些经验也将通过龙蜥社区让用户使用起来：</p><p></p><p>在机密计算方面，龙蜥操作系统开源社区和&nbsp;Intel、海光一起构建了完整的精密计算体系，帮助客户、用户更好地使用计算资源；在存储方面，龙蜥操作系统开源社区构建了包括&nbsp;Nydus、EROFS、FScache&nbsp;等一整套的操作系统存储方案，通过整套方案帮助用户更好地使用云上各种各样的存储资源，同时，通过操作系统内核，无缝地支撑完整的镜像加速，这也是在业界一个非常巨大的创新；在网络方面，通过将阿里云&nbsp;eRDMA（弹性&nbsp;RDMA）与龙蜥社区&nbsp;SMC-R，两项技术的结合，可以让用户非常方便地使用&nbsp;RDMA&nbsp;技术，为应用提供加速；在大规模机器运维方面，龙蜥社区成立了跟踪诊断&nbsp;SIG&nbsp;以及系统运维&nbsp;SIG，汇集了阿里巴巴、统信、Intel&nbsp;等各家公司的优秀工程师在运维方面的经验，希望这些经验通过龙蜥社区让用户使用起来，让大家面对大规模机器运维时不再有难言之隐。</p><p></p><p>在「云时代开源操作系统的技术实践」分论坛中，阿里和龙蜥社区携业内技术专家共同带来了技术实践思考。阿里云资深技术专家、Cloud&nbsp;Hypervisor&nbsp;技术委员会刘奖，Intel安全产品专家、龙蜥社区机密计算&nbsp;SIG&nbsp;Maintainer&nbsp;张顺达，字节跳动&nbsp;Linux&nbsp;内核研发高级工程师尹欣等，带来了云时代开源操作系统及其背后的技术实践，面向开发者全面分享了云原生、内核、网络、机密计算、运维等方面的技术落地与演进，共同探讨了在龙蜥社区和龙蜥操作系统上的实践与规划。</p><p></p><h2>三、数据库开源生态与应用实践</h2><p></p><p>&nbsp;</p><p>数据库与操作系统、中间件并称为系统软件的“三架马车”，是企业&nbsp;IT&nbsp;系统不可或缺的组件，也是互联网应用级企业信息管理系统存储数据和管理数据的核心平台。加速“数据库开源”，搭建生态将是关键壁垒。</p><p></p><p>阿里巴巴集团副总裁、阿里云数据库事业部负责人李飞飞在致辞中谈到，计算机与信息技术领域一些核心的突破，越来越多由开源社区驱动，具体到数据库系统来说，也是如此。但是，放眼全世界，还没有一个非常活跃、成熟的云原生数据库开源社区。因此，2021&nbsp;年&nbsp;5&nbsp;月，阿里将云原生数据库产品&nbsp;PolarDB&nbsp;进行开源，一共开源了两个版本，分别是&nbsp;PolarDB-X&nbsp;和&nbsp;PolarDB&nbsp;for&nbsp;PG，开放对接底层云原生框架、基于&nbsp;K8s&nbsp;容器部署、对接共享存储等能力，同时期待有更多人加入社区，共同推动云原生分布式数据库的高速发展。</p><p></p><p>在「数据库开源生态与应用实践」分论坛中，阿里云数据库开源负责人王远从开源数据库&nbsp;PolarDB&nbsp;的角度出发，论述如何打造具有世界影响力的云原生数据库开源社区。王远谈到，阿里云数据库的开源策略主要有四点：一是要与现有生态比如&nbsp;PostgreSQL、MySQL、Redis&nbsp;兼容；二是百分之百开放，即开源的数据库要与阿里云的数据库完全一致；三是打造具有国际影响力的团队，引领社区决策；四是以身作则，反哺社区，打造开源共建文化。</p><p></p><p>接下来，阿里云数据库资深技术专家楼江航、张广舟分别带来了PolarDB-X、PolarDB&nbsp;for&nbsp;PG开源技术的规划和展望；此外，韵达科技业务中台总监李波涛及莲子数据硬件系统首席架构师许长魁，也带来了他们在业务环境中应用阿里云开源数据库PolarDB的探索和实践经验。</p><p></p><h2>四、云原生开源技术演进与生态发展</h2><p></p><p>&nbsp;</p><p>十余年来，阿里云一直坚定地拥抱开源，通过与开源社区共建标准，推动国产自研技术快速发展。开源也在深刻的改变着云计算，让云计算越来越标准化，使用门槛越来越低、触手可得。阿里云在云原生领域拥有&nbsp;30+&nbsp;开源项目，覆盖容器编排调度、分布式应用架构、分布式应用治理等方向。据阿里巴巴研究员、阿里云智能云原生应用平台负责人丁宇介绍，阿里云在云原生领域拥有&nbsp;10个&nbsp;CNCF&nbsp;项目，2个&nbsp;Apache&nbsp;顶级项目，外部&nbsp;Contributor&nbsp;超过&nbsp;2000&nbsp;人，Star&nbsp;数量超过&nbsp;25&nbsp;万，服务了百万开发者。</p><p></p><p>其中&nbsp;Apache&nbsp;RocketMQ&nbsp;是国内首个互联网中间件&nbsp;Apache&nbsp;顶级项目，成为国内消息领域的事实标准，超过&nbsp;75%&nbsp;的头部互联网公司在生产实践中使用&nbsp;RocketMQ；Apache&nbsp;Dubbo是微服务框架中影响力最大、采用率最高的国产框架，在全球化和影响力两大维度，入选&nbsp;Apache&nbsp;开源项目第一方阵。</p><p>&nbsp;</p><p>面向云原生时代，为了更好地实现应用交付管理，阿里云开源了&nbsp;KubeVela：以应用为中心，重新定义研发、运维和基础设施之间的协作方式，开发者可以通过&nbsp;KubeVela建设通用的应用交付运维平台。在Serverless&nbsp;领域，阿里云开源了&nbsp;Serverless&nbsp;开发者平台——&nbsp;Serverless&nbsp;Devs，这也是业内首个支持主流&nbsp;Serverless&nbsp;框架的云原生平台。开发者可以一键体验多云&nbsp;Serverless&nbsp;产品，极速部署&nbsp;Serverless&nbsp;应用，大幅研发提效。</p><p></p><p>今年，阿里云在云原生领域持续突破，又发布了两大开源项目：一个是云原生混部系统&nbsp;Koordinator，它基于阿里巴巴内部超大规模混部实践而来，为用户打造云原生场景下接入成本最低、混部效率最佳的标准化解决方案。第二个是阿里云联合&nbsp;bilibili、字节跳动、Nacos社区、Dubbo社区共同发起的微服务治理规范项目&nbsp;OpenSergo，致力于异构微服务治理，让更多微服务互联互通。</p><p></p><p>在「云原生开源技术演进与生态发展」分论坛中，来自阿里、Apache&nbsp;Dubbo，以及&nbsp;OpenSergo&nbsp;&amp;&nbsp;Sentinel&nbsp;社区的嘉宾，聚焦云原生领域热门开源项目，全面展示了云原生开源项目的技术实践与生态建设，帮助开发者全面拥抱云原生。</p><p></p><h2>五、大数据+AI&nbsp;一体化趋势下的开源生态</h2><p></p><p>&nbsp;</p><p>开源软件是整个数字世界的基石，尤其在基础软件领域，互联网的快速发展和崛起离不开开源技术的普及，同时也加速了企业走向互联网化和数字化。作为「大数据+AI&nbsp;一体化趋势下的开源生态」分论坛的出品人，阿里巴巴研究员、阿里巴巴开源大数据平台负责人、Apache&nbsp;Flink&nbsp;中文社区发起人王峰表示，近&nbsp;10&nbsp;年来，阿里巴巴在内部和业界，持续推动开源理念的践行。</p><p></p><p>同时，作为大数据方向的从业者，王峰观察到，在大数据领域的开源生态中，目前比较火的方向有实时离线一体化、流批一体化、数据湖存算分离引起的湖仓一体化，以及大数据+AI&nbsp;一体化等，在开源社区中，这些方向也有越来越多的贡献者参与其中。</p><p></p><p>在本场分论坛中，阿里巴巴邀请了阿里云、快手、网易云音乐的技术专家，分享他们在生产环境中，在流批一体、深度学习，以及数据平台提效降本方面的探索和实践。</p><p></p><h2>六、阿里巴巴终端体系持续走向开源</h2><p></p><p>&nbsp;</p><p>随着技术的演进、前端和客户端越来越强的相互渗透、Web&nbsp;的开放性和高效迭代，客户端技术的即时体验和原生能力要求在持续升级。在这样的技术背景下，今年伊始，阿里巴巴推动了前端和客户端体系的融合，使终端工程领域正式走到了台前。&nbsp;</p><p></p><p>本次「阿里巴巴终端体系持续走向开源」分论坛，是阿里巴巴终端委员会对外的首场开源分享。大淘宝技术跨端技术部负责人、阿里巴巴终端委员会委员舒文亮在出品人致辞中谈到，从宏观的行业视角来看，随着互联网设施的完善，终端设备的规模和类型在爆炸式地增长，各种信息载体持续涌现，比如沉浸式的&nbsp;VR&nbsp;设备、实时呼应的车机语音硬件、智能家居的&nbsp;IoT&nbsp;设备等在不断的扩展终端的定义，用户的体验被空前的满足支撑，而这些体验的技术眼花缭乱，背后的行业标准和厂商生态也在互相的追赶；在中观的层面，站在阿里的角度，今年年初阿里内部推动了前端、客户端体系的融合，让终端技术走向台前，同时，作为推崇开源精神的阿里巴巴前端和客户端技术，将持续保持在开源项目上的投入。&nbsp;</p><p></p><p>此外，阿里巴巴高级技术专家、XQUIC&nbsp;开源项目负责人刘彦梅，阿里巴巴前端技术专家、OpenSumi&nbsp;开源负责人吴丹武，阿里巴巴终端工程师、大淘宝终端框架负责人刘晨凌，阿里巴巴高级前端技术专家、阿里低代码引擎负责人廉洁，也在分论坛中围绕面向终端用户的基础网络（XQUIC）、面向开发者的&nbsp;IDE&nbsp;定制化研发框架（OpenSumi）、终端应用研发框架（ICE）、面向扩展设计的企业级低代码开放技术体系（LowCodeEngine）等实践经验进行了分享。</p><p></p><h2>写在最后</h2><p></p><p>&nbsp;</p><p>通过&nbsp;2022&nbsp;首届阿里巴巴开源开放周&nbsp;Alibaba&nbsp;Open&nbsp;Source&nbsp;Week，阿里巴巴向业界分享了很多自身在开源中积累的实践经验，以及社区治理经验；同时，也通过自身链接了业内的技术专家及开源社区的负责人等，为开发者、开源爱好者们带来了极具价值和意义的内容。我们期待阿里巴巴为业界提供更多好的开源项目、最佳实践等内容，也期待第二届阿里巴巴开源开放周的到来！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2e/2e5ba0be357676a951b551c9675c6153.png\" /></p><p></p><p>如果您想了解阿里巴巴开源开放周更多精彩内容，欢迎来阿里巴巴开源官网：https://opensource.alibaba.com/collection/osweek2022&nbsp;查看完整回放、获取分享资料。</p>",
    "publish_time": "2022-08-26 18:00:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]