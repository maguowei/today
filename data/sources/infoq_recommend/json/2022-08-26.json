[
  {
    "title": "基础设施即代码：只是漂移管理还不够",
    "url": "https://www.infoq.cn/article/wV78kwciwMAqeVxtAlfy",
    "summary": "<p></p><h2>什么是配置漂移？</h2><p></p><p>随着公司的发展，软件生产和交付系统往往会变得越来越复杂。随着而来也会发生配置上的经常变更。</p><p>&nbsp;</p><p>在最理想的情况下，变更会以良好的方式进行全面跟踪。但是，我们的生产环境并不完美，比如其中的许多修改都没有记录。如果是无关紧要的修改，那么对系统的影响会很小。如果这些修改导致系统变得不稳定，那么就会出现所谓的“配置漂移”。</p><p>&nbsp;</p><p>当新建并合并分支，以及将其他多个变更提交到主分支时产生某种冲突时，就会出现漂移。在小型团队中，开发人员可以及时告知同事他提交了变更。而在较大的团队中，分叉（fork）和合并之间的变更数量可能非常多，产生的冲突数量以及解决冲突耗费的时间都会更多。</p><p>&nbsp;</p><p>也许，代码漂移是最常见的漂移类型，但由于现如今软件架构和依赖关系的复杂性，配置漂移也很常见。开发人员可能会在分支创建完成后在过渡环境或预生产环境中新建一张表。可能会新建一个lambda表达式，或是更新SQS配置。如果开发人员的环境发生漂移，那么代码在旧版本上可能运行正常，但合并到经过更新的环境就会出问题。在一些简单的场景，这可能不会立即发生问题，但随着复杂性增加，应用场景越来越多，问题可能就出现了。大量的调试和返工在所难免，进而导致发布时间延期。在接下来的几节中，我们将介绍几种配置漂移的管理方法。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/04/04553074a4ad28fccadcdc598147b0f6.png\" /></p><p></p><p>图1 代码漂移示例</p><p></p><h2>配置漂移的影响</h2><p></p><p>代码会在多个环境中“传播”，从个人工作站到共享开发、测试、QA、过渡以及生产环境。如果其中某些环境之间存在不一致，就会导致安全漏洞和部署问题。如果你要处理的应用程序和服务需要遵从严格的法规或标准，那么开发过程就会面临风险。</p><p>&nbsp;</p><p>确保软件开发生命周期中各个环境共享相似的配置是一项非常费时的工作，这需要多个部门的配合。有时候，团队要花数周时间为不同阶段配置不同的环境。</p><p>&nbsp;</p><p>员工经常会对他们的环境做些小修改，但不会将它们传递给生产环境。这类配置漂移通常不为人所注意，但也会造成严重影响。如果长时间不注意，它们就会导致应用程序出问题，软件工程师可能要花费数小时来追踪并修复。他们需要排查代码和环境问题，找出可能导致异常行为的原因，而这些时间原本可以花在更有效率的事请上。</p><p>&nbsp;</p><p>随着时间流逝，产品开发生命周期延长。除了宕机外，这是环境漂移最常见的后果之一。<a href=\"https://blogs.gartner.com/andrew-lerner/2014/07/16/the-cost-of-downtime/\">Gartner 2014年发表的一篇文章</a>\"提到，IT公司每宕机1分钟平均损失约5600美元。</p><p>&nbsp;</p><p>此外，这类事件会导致开发停顿，开发人员不得不立即放下手头的工作，切换环境并着手解决事件。这种中断可能会导致代码Bug，因为我们的思路被中断了，有些想法可能会遗漏。这样就有恶性循环的风险。</p><p>&nbsp;</p><p>配置漂移会影响员工满意度，导致与开发体验相关的指标下降。</p><p></p><h2>减少漂移的方法</h2><p></p><p>配置漂移多少有些不可避免。不过有许多方法可以减少配置漂移。在接下来的内容中，我们将探讨漂移管理的一些实用方法。</p><p></p><h3>建立清晰的流程，并做好文档记录</h3><p></p><p>在处理配置漂移时，应该优先确定一套清晰的变更管理策略和流程。在许多情况下，人为错误是漂移的主要原因，可能是因为没有遵守流程，也可能是因为没有和其他团队沟通好。设计良好的变更管理策略可以保证所有必要的测试都已进行，并且可以保证在正式批准应用于生产环境之前，有某个有权限的人评审并评估这些变更的影响，从而降低产生副作用及未知问题的风险。你要记录好应该做哪些变更，什么时候做，以及在什么系统上做。</p><p>&nbsp;</p><p>应用基础设施变更的方法越少越好，最理想的情况是，只有一个通道可以进行更改，不管是应用、开发、过渡还是生产环境。</p><p>&nbsp;</p><p>除了推送变更的通道外，还需清晰地定义好权限并严格执行，将审批/发布权限授予一组预先选定的人，他们经验最丰富，而且根据以往的情况看最值得信任。</p><p>&nbsp;</p><p>任何不符合标准的情况都可能导致配置漂移。</p><p></p><h3>实现基础设施即代码（IaC）</h3><p></p><p>遵循<a href=\"https://en.wikipedia.org/wiki/Infrastructure_as_code\">基础设施即代码原则</a>\"并使用类似Terraform这样的解决方案，是消除配置漂移最有效的方法之一。</p><p>&nbsp;</p><p>使用代码定义环境，而不是通过手动变更来同步环境，这本身就容易出错。代码很清晰，而且在任意数量的资源上应用/运行都一样，没有漏掉什么东西或颠倒操作顺序的风险。</p><p>&nbsp;</p><p>借助代码版本控制（如<a href=\"https://www.github.com/\">Git</a>\"），基础设施即代码平台还可以提供详细的记录，包括现在和以前的配置，解决了修改没记录的问题，这还有一个额外的好处就是留下审计线索。像Terraform、Pulumi和Ansible这样的工具就是设计用来管理配置的，可以用它们识别漂移并发出信号，有时甚至还能自动纠错——这样，你就有可能在变更真正影响系统之前将其纠正过来。</p><p>&nbsp;</p><p>和任何工具一样，效果取决于你的用法。使用一款像Terraform这样的工具本身并不能使你所在的公司免疫配置漂移。还是要设计好流程，而且每个人都要遵守；即使所有的部署都依赖IaC，在某些情况下（如添加、移除或修改远程资源）还是会发生漂移。你也无法保证所有部署都通过IaC，因为在许多情况下，仍然可能使用CLI、API或Web浏览器手动部署。</p><p>&nbsp;</p><p>在Terraform 中，检测潜在漂移最简单的方法是重新计算并评估Terraform预期状态的计划：如果计划为空，则基础设施状态符合预期，什么都没变；如果计划中有需要采取的步骤（而且你也没有修改代码），则表示有来自其他通道的变更导致了配置差异。有时候，这可以自动修复，系统可以立刻回到预期状态，但你至少应该查下差异是怎么出现的——对流程做相应地调整，避免同样的事情再发生。</p><p>&nbsp;</p><p>在共享和发布容器化应用程序时，基础设施即代码显得更加有用。虽然容器镜像包含运行所需的所有代码和软件依赖，但一旦部署到云上，它常常需要额外的基础设施元素来实现可扩展性以及提高可靠性（如负载均衡器、监控、日志等）。</p><p>&nbsp;</p><p>在将应用程序成功部署到云上之后，你需要确保它流畅地运行，而且限制特定受众访问。也就是说，你需要围绕容器镜像重建所有基础设施，而完成这项工作最简单的方法就是使用描述所有必要配置的IaC模板。</p><p>&nbsp;</p><p>注意，环境间（如开发和生产）的差异对容器化应用程序的行为和可靠性有很大的影响。这是由包括数据库、服务在内的所有云原生资源所致，它们都位于应用程序之外，但对于其正常运行至关重要。从这个意义上讲，IaC让变更可再现且可预测，保证过渡环境与生产环境非常相似，生产环境代码部署和基础设施变更的风险大幅降低，而效率则有很大的提升。</p><p></p><h3>规程与IaC的优缺点比较</h3><p></p><p>频繁重复手动执行变更步骤（不同的人在多次执行时都要严格遵守）很容出错。意外事件一定会发生——不是“是否”的问题，而是“什么时候”和“什么方式”以及“多么经常”的问题。</p><p>&nbsp;</p><p>运行速度快、每次都能一致应用的已测试代码可以消除大部分问题，但最终，这都归于强大的流程，即变更管理。要制定策略，强制使用IaC，屏蔽应用变更的其他方式，还要确保所有团队成员都遵循质量相关的流程。最终，测试、代码评审、影响评估以及审批都归结为UI中的几次按钮点击或是CLI工具中的一次命令执行，但是，在这些最终动作发生之前开展的底层工作非常重要，仍然是由人手动完成的。</p><p>&nbsp;</p><p>IaC让你可以做得更好，消除问题，减少意外事件，加快前进步伐，但实际怎么用还是取决于你。</p><p></p><h3>使用环境即服务（EaaS）解决漂移</h3><p></p><p>变更管理和自动化将帮你创建并扩大业务规模，并建立以简单明了的流程为基础的工程文化。而环境即服务解决方案可以帮助你恰当地实施这一切。</p><p>&nbsp;</p><p>在文章开头，我们介绍过配置漂移对工程团队的严重影响：花费数小时排查代码和环境故障，试图找出意外行为的潜在原因。此外，静态环境更容易发生配置漂移，因为它们是可变的——为了达到某个状态，将更改应用到当前状态，但这个当前状态可能并不是每次都像我们期望的那样。从零开始创建不可改变的环境，肯定可以减少阻力，大大降低遇到错误的概率。</p><p>&nbsp;</p><p>从这个意义上讲，环境即服务解决方案可以对很多工程团队产生巨大影响，让他们可以无缝地访问测试及开发环境，把省下的时间增加到实际的产品开发中。随着时间的推移，工程团队将变得更加独立，也更加专注于产品。</p><p></p><h2>总结</h2><p></p><p>在可预见的未来，配置漂移仍然不可避免。而市场上正在实施的一些配置管理方法，如自动对比环境的当前配置和基线配置，能缓解配置漂移的副作用。EaaS解决方案，配合IaC和良好的变更管理，可以帮助你预防漂移，缩短开发周期。借助合适的网勾（Webhook），我们可以识别代码或基础设施变更。通过维护每个环境的状态，可以知道它是否发生了漂移，并决定是否触发一次自动更新。我们希望任何生产环境都不出现漂移。但是，生产环境服务于在线客户，通常需要满足特定的服务等级协议（SLA），而且有维护窗口，因此，这些环境会有手动触发的更新，或是持续部署调度器触发的更新。</p><p>&nbsp;</p><p>作者简介：</p><p>Roxana Ciobanu是Bunnyshell的联合创始人兼首席技术官。她是一名云爱好者，热衷于保障高可用性、性能调优和云架构安全。她曾担任DevOps和解决方案架构师，实现了云技术与运营和开发的完美结合。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/iac-configuration-drift/\">Infrastructure as a Code—Why Drift Management Is Not Enough</a>\"</p>",
    "publish_time": "2022-08-26 08:56:11",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "风靡全网的Web 3，到底是个啥？",
    "url": "https://www.infoq.cn/article/jsf43rxkftgecP5aQCNG",
    "summary": "<p>作者 | 刘燕，王强</p><p></p><p>近一年多来，技术圈最热门的话题一定少不了Web 3的身影。Web 3的追捧者将它视为互联网的未来，但更多人仍然对这一概念感到云里雾里。</p><p></p><p>Web 3的定义与落地时间都充满争议，甚至有人指责它只是又一次技术炒作。那么，究竟该如何理解Web 3？Web 3能否实现支持者的预期？针对这一话题，《InfoQ·极客有约》特别策划了一场「共话Web 3」专题直播。</p><p></p><p>本场专题直播共组织了两场线上圆桌论坛，邀请多位对Web 3有深入研究的专家共同探讨这一新晋技术概念，希望帮助国内开发者和感兴趣的朋友更好地了解Web 3。</p><p></p><p>第一场圆桌对话的主题是《爆火的Web 3，到底是什么》，本场主持人是MRS联合创始人，《人工智障》系列作者Mingke，对话凯云实验室（KEN Labs）CTO杨威理（William），腾讯云区块链资深架构师梁永甫两位嘉宾。</p><p></p><p>本文将圆桌对话的精华内容整理如下，以飨读者。</p><p></p><p></p><blockquote>主持人Mingke：从区块链到金融科技，从去中心化到元宇宙，今天的技术世界有很多新概念、新名词。它们之间的关系错综复杂，很容易让人感到迷惑。最近流行的Web 3是之前多个概念的整合与升级，但究竟什么是Web 3还并没有一个相对统一的准确定义。那么各位能否从自己的理解出发，尝试对Web 3下一个定义？</blockquote><p></p><p></p><p>梁永甫 ： 我个人认为Web 3并不是一种单纯而具体的技术。它可能是一种趋势，或者一个时代的一个代名词，其中包含了非常多的内容，包括未来可能出现的一些新的应用或技术类型都会包含在这个大范围之内。所以，Web 3是一个包含各种各样的技术、应用的抽象集合。</p><p></p><p>另一个角度讲，如果说Web 1是可读，Web 2是可读、可写，那么Web 3就是可读、可写、可运维。这是大家最容易认可的一种定义，因为它不是特别具体，也就容易取得共识。</p><p></p><p>我们先把视角转到互联网上。互联网本身包含了服务端和用户端两大部分。从这个角度来看Web 3和 Web 2的区别，会发现Web 3在构造和提供服务时是一个相对分布式、去中心化的系统。 在这样的系统中提供的服务是生态型的，也就是所有人都可以提供自己擅长的内容，这些内容组合在一起可以为用户带来完整的、比现有服务更完善的产品。正因如此，Web 3需要用区块链来构建去中心化的基础设施，从而建设这样的生态。</p><p></p><p>在用户端，Web 3的重点在于“可拥有”。 所谓“可拥有”是指用户对数据和资产的控制权更大，很多内容会交给用户来控制。在用户体验和交互层面，Web 3还会从现有的文字、图片、视频升级到VR、AR为主流选项。</p><p></p><p>杨威理： Web 3诞生之初的愿景是互联网之父Tim Berners-Lee提出的“语义网”的概念。所谓语义网，是指数据在整个互联网层面实现互联，使分散在各处的数据能够彼此交流和共同更新，例如用户只需要修改一次账户信息，他在所有网站的账户就都会同步更新等等。这样以来，互联网上的信息就会更加准确和智能。</p><p></p><p>为了实现这一目标，Web 3的先驱者提出的方案就是用一个去中心化的项目来存储包括身份信息在内的用户数据。通过这种方式，数据的所有权会交还到用户手中，从而改善数据隐私问题。但今天所提的Web 3和语义网的概念还是有区别的。虽然两者的目的都是要重塑互联网，解决数据孤岛问题，给用户更多控制权，但Web 3会更看重数据的不可修改性，而语义网并不把不可修改作为核心的关注点。</p><p></p><p></p><blockquote>主持人Mingke：既然两位都没有对Web 3下一个非常精确的定义，没有明确Web 3究竟应该具备哪些特性，那么我们该如何定义基于Web 3的原生应用？究竟哪种应用可以说是完全基于Web 3的特性开发出来的？还是说这种Web 3原生应用其实是并不存在的？</blockquote><p></p><p></p><p>梁永甫：我认为在刚才提到的用户体验、数据归属权和服务提供方式三个层面上，只要应用在一个层面上满足新一代的特征（VR/AR、用户控制更多数据、去中心化提供服务），就可以称它为Web 3应用。 或者说，并不是说这三种特征全部满足才叫Web 3应用。在互联网向Web 3进化的道路上，我们可能会见证许许多多新技术的诞生。这些技术会一点点改变这三个层面的应用形态，但这些层面不可能一步到位、一次性全部升级完成。所以在这个过程中，只要满足了一个层面的升级特征，就应该说这个应用是Web 3应用。</p><p></p><p>在这个进化过程中也会出现一些负面产物，有人会用一些应用来做一些不好的事情。但我们要意识到，整个Web 3的概念是中性的、包容的，是一个趋势、演进过程和未来方向，不能因为某一个应用好坏和成败来评判整个Web 3。</p><p></p><p>杨威理： 我们内部也经常有讨论，探讨Web 3，或者说下一代互联网中的用户会有哪些需求。这些需求中的大部分应该是新型的需求，与我们今天的日常应用场景是不一样的。比如我们每天看视频、刷微博、玩抖音，这些应用的用户可能并不在乎自己发的抖音是存放在中心化还是去中心化的网络上。他们在乎的可能是去中心化的应用是否能为抖音用户带来更好的经济回报。内容创作者也会关注Web 3能否带来一些变革，能否在广告和打赏这样的主流收益方式之外创造更多可能性。</p><p></p><p>所以我们非常感兴趣的是，Web 3的时代互联网应用能否延伸到更多领域。我们认为这是非常重要的，尤其是Web 3能否创造出一批比较扎实的需求场景，既能有稳定的商业模式，又能为用户带来真正的价值。 我认为这才是下一代互联网标志性的特性或者事件，有了这样的场景才会有真正的Web 3变革，否则这个名词就只能停留在概念上。</p><p></p><p></p><blockquote>主持人Mingke：很多人感兴趣的是，现在究竟有没有一些能够让普通用户感知到的Web 3应用，比如说更加去中心化的即时通讯应用这样的案例。能否请两位分享一下类似的案例，或者对这样的产品做一些评价？</blockquote><p></p><p></p><p>杨威理：目前我们看到很多Web 2时代的应用团队和公司在尝试将Web 2的应用类型迁移到去中心化网络上。比如说有团队在做去中心化的YouTube，他们提供了一些工具让用户可以将视频同步到去中心化的平台上。同时他们还提供了新的创作收益机制。这种方式并不一定带来颠覆的效果，就比如说微信的用户并不会因为某个类似的通讯应用是去中心化的就去选择后者。究竟终端用户需要的是怎样的应用形态，这个问题还是见仁见智。所以，目前的Web 3生态还是处于相对早期的状态，还是处在一个“建设时代”。</p><p></p><p>以存储为例，我们有去中心化的存储方案，但还不够强大，跟主流的云平台还不足以抗衡，还需要长期发展。在这样的背景下就会催生很多应用，它们的目的是帮助这些基础设施能够在现阶段表现得更好。这些服务的模式多多少少还是带有Web 2时代商业模式的影子，但大家依旧可以通过它们开始体验Web 3的基础设施。</p><p></p><p>梁永甫： 从一个更大的角度来说，所谓数字化是要做什么？数字化过程中的每一阶段，数字化的内容是不一样的。在每一个阶段，我们不会关注之前已经数字化的内容，而是会关注还没有被数字化的事物。比如说Web 2时代，很多资产是没办法数字化的。但有了区块链之后，这些资产的数字化道路就被打通了，所以新技术让数字化跨入一个新的阶段。</p><p></p><p>换句话说，数字化是一种增量式的发展过程，Web 2提供的是Web 1的增量服务，而不是要颠覆Web 1的事物；Web 3也不会颠覆Web 2的模式，而是会创造一种全新的模式，通过去中心化的服务方式创造很多之前没法创造出来的事物。这就是Web 3时代的一个标志。</p><p></p><p></p><blockquote>主持人Mingke：很多人也在问，Web 3能够提供哪些独有的能力？比如说一个应用在Web 2时代做不到的事情，到了Web 3时代就可以实现了吗？</blockquote><p></p><p></p><p>杨威理： 从应用的层面来讲不好谈，我可以换个角度，从经济利益分配这个角度来聊聊。拿YouTube举例来说，用户在平台上发视频后，通过广告收入来获取回报。谷歌从YouTube获得的广告收益中分一部分给创作者，但这块收益并不是一般的内容创作者可以议价的。</p><p></p><p>但在去中心化的网络机制之下，这个经济模型发生了改变。平台并不存在一个中心化的实体来分发收益，相当于我们就像在菜市场卖菜一样可以自己定价。创作者可以有相对自由的运营空间，在这种空间之下每个内容创作者得到的回报也会更高。如果我们还是以传统的Web 2的模式去思考这个问题，我觉得我们很难做出比Web 2时代更好的应用；除非我们衍生出一个全新的需求，或者创造出全新的、这些大厂商无法支持的技术，但这样的概率也是很小的。</p><p></p><p>所以一方面来说我们要从用户需求层面去挖掘，另外可能是在经济模型上推动变革，才能让消费者去主动选择。否则用户还是会倾向于使用他最习惯的一些Web 2应用。</p><p></p><p></p><blockquote>主持人Mingke：从这个角度来讲，是不是可以说，短期看来我们还看不到具备非常明显的Web 3特征的应用？</blockquote><p></p><p></p><p>杨威理： 在国内环境中，我至少目前没有看到有很明显特征的应用出现。</p><p></p><p></p><blockquote>主持人Mingke：这里引出一个问题 —— Web 3需要怎样的土壤才能更好地发展？除了技术，还有经济、生态，以及开发者和消费者的思维等角度来看，什么样的土壤更适合发展Web 3？</blockquote><p></p><p></p><p></p><p> 杨威理： 这里有一个挺有趣的现象可以和大家分享一下，最近我们发现在印度以及非洲的一些国家，Web3的接受度、流行度非常高。我们可以从这个现实来思考一下，或许能够从侧面解答上面的问题。</p><p></p><p>首先，非洲国家的数字货币在全球是发展最快的。一方面是因为当地用户采用数字货币可以很便利地转账和国际汇款，另一方面也因为非洲国家的银行服务相对落后、货币不稳定、信用体系建设不完善。方方面面的因素决定了他们无法提供一个非常稳定的基础金融服务。所以采用这种低成本运营和维护的数字货币作为替代解决方案，对他们来说是个不错的选择。而且这些国家经济相对落后，需要快速发展，数字货币恰好满足了他们的需求。</p><p></p><p></p><blockquote>主持人Mingke：听上去有点像当年的电子支付在中国的普及过程。中国用户跳过了信用卡时代，直接迈入了移动支付世界。永甫老师又是怎么看待这个话题的？哪些环境特征适合Web 3的成长？</blockquote><p></p><p></p><p>梁永甫：我认为Web 3的成长与大环境的变化并不是强相关的。 比如说现在Web 3最流行的应用是NFT，那么无论在国外还是国内，用户都可以买到NFT，从而体验到Web 3应用。从这个角度来看，我们需要思考的还是Web 3究竟能够给用户带来什么价值。比如说非洲用户没有微信和支付宝，他们就会通过Web 3数字货币来满足自己的支付需求。我们需要挖掘Web 3能够给用户创造的各种场景，这个才是最重要的。至于监管环境之类的因素影响并不是很大，称不上是一种决定性的因素。</p><p></p><p>杨威理： 就梁老师提到的NFT这个话题，我认为我们可以从中做一些思考。比如说Twitter现在开始对接NFT，用户可以购买NFT作为自己的头像。这听起来并不是一种刚需，但我认为这是一个起点。或许这些NFT创作物，将来就是我们每个人在元宇宙或者虚拟世界里的个人表现形式。随着我们大家的生活方式越来越多地映射到元宇宙当中，这些NFT就有了真正的使用价值。</p><p></p><p></p><blockquote>主持人Mingke：就去中心化这个话题，我想到了一段历史。在互联网发展早期，电子邮箱协议是开放的，人人都可以用这个协议来搭建自己的邮箱体系，大家遵循相同的协议就可以互通。但并不是所有人都会这个技术，所以我们有了Gmail这样的邮箱服务。自然而然，这样的服务就成了中心化的平台。从这个角度上来讲，这种中心化的过程让更多的人享受了技术成果，两位老师是如何看待这个问题呢？</blockquote><p></p><p></p><p>梁永甫：不管未来的互联网是什么样的形式，最核心的部分还是要给用户创造价值、提供服务。 有些服务可能更适合去中心化的形式，还有一些依旧是中心化的形式更好。所以我们还是要从用户需求出发，看看用户究竟想要什么产品，这种产品适合哪一种形式，哪一种形式更好，我们就选择哪一种。我们要挖掘那些更适合去中心化形式的应用，这就是Web 3时代，我们需要重点去做的事情。</p><p></p><p>杨威理： 我认为大趋势并不是说在一个战场上拼杀得你死我活。中心化有它的好处和优势，去中心化也自然有它的不凡之处。我们还是以电子邮件为例，像谷歌提供的Gmail方便大家使用，同时也提供了很不错的存储空间，所以我们基本上不需要操心垃圾邮件的的空间占用问题。这是因为谷歌提供了一些补贴，其他一些小厂商很难提供这样的补贴，所以就需要收取一些费用，自然很难与谷歌竞争。</p><p></p><p>那么在中心化的邮件服务领域里有没有去中心化的可能性呢？举个例子，我们是否能够构建一个去中心化的邮件服务器网络，通过一定的激励机制激励邮件服务器节点稳定提供服务？我们或许无法保证用户可以免费使用，但至少可以做到更低的成本，甚至让用户自己都可以参与建设服务器节点来抵扣一些开支。 总之Web 3给我们带来了很多不同的玩法，也是大家乐意去探索的一个很重要的领域。</p><p></p><p></p><blockquote>主持人Mingke：最后这个话题，请两位嘉宾分享一下自己对下一代网络的看法。网络是由节点和边组成的，需要有协议让点与点能够连接起来。下一代网络的组成形态可能是非常多样的，那么下一代网络的节点、边和协议会有哪些变化，和现有节点等又有哪些区别？</blockquote><p></p><p></p><p>梁永甫： 还是拿邮箱通讯为例。邮箱通讯是点对点的，比如我们通过一个邮箱服务器通讯，我跟你通信只有我们两个能看到。这意味着这个网络连接在数据层面是双向的，或者说是线状的。</p><p></p><p>但实际上，在未来我们想要构建的是一个真正的网状网络。比如说区块链上的一笔转账交易，不仅转账双方能看到，网络中的其他所有人也都能看得到。这是非常大的变化。</p><p></p><p>比如说现在买房要先找中介，再经过房管局登记再付款，那么未来要构建的是中介、房管局和买家卖家是多方共同参与交互网络。比如说我找了一个中介，房管局知道了，房主也知道了；我跟他签了一个协议说我要买房了，那么房管局那边知道了，银行那边也知道了，到时候就可以直接去放款了。这个形式可以改变我们提供服务的方式，我只要做一个动作其他人就全都能看到，其他人各自做自己的事情就好，最后房子过户的过程就顺利完成了。我认为这种网状网络是真正的变革，可能会激发一些新的服务形式。目前来看，可能区块链是用来构建这种基础设施的一个比较好的选择。</p><p></p><p>杨威理： 我基本上也赞同。另外补充一点，目前Web 3的话题里大家关注比较多的就是去中心化的身份验证。 比如我们向警察出示驾照，多多少少会展示一些个人隐私数据。那么如何在不揭露自己这些隐私数据的同时能证明自己是有驾照的？这就是去中心化身份验证机制要做的事情，在Web 3社区里也已经看到一些相关的产品和服务。</p><p></p><p>从技术实现层面来讲，Web 3应用通常的做法是设置一个钱包。 用户个人的身份信息会存储在一个安全的网络之上，而需要公开展示的驾驶记录、病历之类的信息由相关机构颁发。颁发的这些数据并不留存在用户自己的钱包里，但用户有这个数据的密钥。当用户要出示这些信息的时候，可以向别人分享这个密钥，并让授权机构去验证。用户自己不需要构建服务器、节点平台这些基础设施，他只需要把自己的身份信息以及关键的密钥信息存储在自己可控的安全存储上即可，比如说软硬件形式的数字钱包里面。</p><p></p><p></p><blockquote>主持人Mingke：在某种意义上来讲，上面由第三方提供的服务不只是针对一个人，应该是提供给多个人，那是不是就形成了一个服务对很多用户的中心化场景呢？</blockquote><p></p><p></p><p>杨威理： 我觉得这些场景还不算中心化，因为我们可以认为它是一个软件服务的供应商，大家都是通过去中心化的协议来提供服务。</p><p></p><p>梁永甫：去中心化并不意味着什么东西都要我自己去做，我还是需要别人给我提供服务的。另外服务也不等于中心化，所有的服务都由一方提供才是是中心化 ，比如说有人给我提供了存储服务，有人给我提供了基于钱包的身份服务，那么存储和身份对用户而言是一个完整的服务，也就是说这么一个完整的服务的不同部分是由不同的厂商给我提供，从这个角度看，这个服务反而是去中心化的。</p><p></p><p>主持人Mingke： 非常感谢两位来分享对Web 3的看法，我们这一场的讨论就到这里。接下来的第二场圆桌讨论主题是《Web 3的核心基础设施》，下一篇文章将总结第二场讨论的内容供读者品鉴。</p>",
    "publish_time": "2022-08-26 10:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "特斯拉公布自研超算Dojo更多细节：计算模块为专为大型机器学习模型训练而生，可编程性决定成败",
    "url": "https://www.infoq.cn/article/7iTKNGigN3SLheqHNrtA",
    "summary": "<p></p><blockquote>早前在回答为什么要<a href=\"https://www.infoq.cn/article/fysqkmvmp9fuen02ibvj\">自研超算 Dojo </a>\"时，马斯克曾表示，“解决自动驾驶的唯一方法是解决现实世界中的 AI 问题，无论是硬件还是软件，而这也是特斯拉正在做的事情。除非一家公司具有很强的 AI 能力以及超强算力，否则很难解决自动驾驶难题。”</blockquote><p></p><p></p><h2>特斯拉公布自研超算 Dojo 细节</h2><p></p><p></p><p>近日，在 Hot Chips 34 大会上，特斯拉公布了大量<a href=\"https://www.theregister.com/2022/08/24/tesla_supercomputer_dojo/\">自研超算 Dojo 的细节</a>\"，并发布了两个有关 Dojo AI 超级计算机的深入演示。</p><p></p><p>本质上，Dojo 是一种可组合的规模化超级计算机，与我们熟悉的五百强超算系统不同，Dojo 是一套完全可定制架构，全面涵盖计算、网络、输入/输出（I/O）芯片，乃至指令集架构（ISA）、供电、封装和冷却。所有这些都服务于同一个目标：大规模运行定制化机器学习训练算法。</p><p></p><p>据了解，Dojo 发布于 2021 年 8 月特斯拉 AI Day，特斯拉硬件工程高级总监、Dojo 项目负责人 Ganesh Venkataramanan 当时曾上台就 Dojo 的主要性能进行了展示。</p><p></p><p>Ganesh Venkataramanan 表示，马斯克想要一台超快的训练计算机来训练 Autopilot。因此，Project Dojo 诞生了。Dojo 架构拥有一个大规模计算平面，极高宽带和低延迟。作为 Dojo 架构的重要组成部分，D1 芯片采用 7 纳米制造工艺，处理能力为每秒 1024 亿次。</p><p></p><p>Venkataramanan 认为，将一组这样的芯片放置在单个“训练片”上，以提供每秒九千万亿次的计算能力，并将 120 个芯片放在多个服务器机柜上，达到每秒超过 1 千万亿次的计算能力。这些芯片可以帮助训练模型来识别特拉斯汽车摄像头中收集到的各种物品。训练模型需要大量的计算工作。</p><p></p><p>在近期举办的 Hot Chips 34 大会上，Venkataramanan 在主题演讲中称，“现实世界中，海量数据的处理只能通过机器学习技术来实现，而由此支撑起的应用场景则包括自然语言处理、基于视觉设计的自动驾驶、与日常环境交互的机器人技术等。”</p><p></p><p>他同时承认，传统的分布式工作负载扩展方法并不能跟上机器学习对于处理速度的需求。时至今日，摩尔定律已经帮不上多大的忙，CPU 加 GPU 的组合、或者是极少数配备专用 AI 加速器的方案，也远未达到人们对于大规模 AI/ML 训练系统的性能预期。</p><p></p><h2>Dojo 的三明治式数据中心</h2><p></p><p></p><p>Venkataramanan 表示，“在过去，我们会先制造芯片，再把它纳入封装、部署进印刷电路板、接入系统，最后把系统安装在机架内。”问题在于，每当数据从芯片移向封装、或者由封装移出时，都会产生相应的延迟和带宽损失。</p><p></p><p>为了克服这些限制，Venkataramanan和他的团队决定从零起步、重新设计。“在当初接受马斯克的面试时，他就问我能不能在CPU和GPU之外，给AI场景一个新的答案。我们整个团队一直在为此而努力。”</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/20/20fcc1763837ad781263a77f765a8afb.png\" /></p><p></p><p>于是，Dojo训练单元应运而生。这是一个独立的计算集群，体积约为1.5立方英尺，能够在15 kW液冷封装中实现每秒556万亿次FP32浮点运算。每个单元都配备有11 GB的SRAM，并在整个堆栈中以自定义传输协议通过9&nbsp;TB/s结构实现互连。</p><p></p><p>Venkataramanan介绍称，“这个训练单元以前所未有的集成度，把计算机中的内存、电源、通信等机制整合了起来，无需任何额外交换设备。”</p><p></p><p>这个训练单元的核心就是 Dojo D1，一款包含500亿个晶体管的芯片，采用台积电7纳米制程工艺。特斯拉表示，每块D1芯片能够在400瓦最大散热功率下实现每秒22万亿次的FP32浮点运算。此外，该芯片还能支持包括自定义计算在内的其他多种浮点运算。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/83/83bb1f2812b1d6639ec2963fb21ebab5.png\" /></p><p></p><p>Venkataramanan表示，“从每平方毫米的晶体管密度来看，Dojo D1可能是当前最先进的技术成果。”</p><p></p><p>特斯拉将25块D1裸片用台积电的代工技术封装起来，由此“以极低延迟与极高带宽实现了对大量计算元件的集成”。然而，片上系统设计和垂直堆叠架构，也在供电层面带来了新的挑战。</p><p></p><p>根据Venkataramanan的介绍，目前大多数加速器都会将电源直接放置在芯片附近。他解释称，虽然也能通过验证，但这种方法使得加速器的大部分区域只能专门放置这些组件。而Dojo则反其道而行，选择直接通过芯片底部传输电力。</p><p></p><h2>组装成形</h2><p></p><p></p><p>“我们可以用这个训练单元构建起整个数据中心甚至是整栋服务器大楼，但训练单元只是计算的部分，我们还得考虑资源的实际交付。”</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7f/7ff849ded2643da665e8bc593720a6f4.png\" /></p><p></p><p>为此，特斯拉开发出Dojo接口处理器（DIP），负责充当主机CPU和训练处理器间的桥梁。DIP还可以提供共享高带宽内存（HBM）与高速400 Gb/s网卡。每个DIP包含32 GB HBM，最多能够将五块DIP卡以900 GB/s的速度接入同一训练单元，因此主机总传输速率达4.5 TB/s、单个单元&nbsp;HBM容量可达160 GB。</p><p></p><p>特斯拉的V1双单元配置方案就一口气用上了150块D1芯片，能够支持四块主机CPU、每台主机配备五块DIP卡，号称能实现百亿亿次BF16或CFP8性能。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f3/f3c9a55dcac89f582dec1c603ecb6660.png\" /></p><p></p><p>Venkataramanan称该架构帮助特斯拉成功克服了英伟达与AMD等传统加速器中的固有限制。“传统加速器的工作原理，是将整个模型部署到各个加速器内、多次复制，让数据流经每个加速器。但随着模型体量越来越大，结果会怎么样？这些加速器的内存可能不足以存放完整模型，到时候就没有训练效果可言了。”</p><p></p><p>这其实并不是新问题。英伟达的NV-switch就能够跨多个GPU实现内存池化。然而，Venkataramanan认为这不仅增加了复杂性，而且引入了额外的延迟与带宽损失。“我们从设计之初就考虑到了这一点，所以我们的计算模块和每块裸片都是专为大型机器学习模型的训练而生。”</p><p></p><h2>可编程性将直接决定Dojo的成败</h2><p></p><p></p><p>很明显，这样一套专门的计算架构需要与之配套的特殊软件堆栈。Venkataramanan和他的团队也意识到，可编程性将直接决定Dojo的成败。</p><p></p><p>“在我们设计这些系统时，最关注的问题就是软件的编程便捷性。研究人员可不会坐等我们手动编写出新内核之后，再尝试运行新算法，人家直接就换架构了。”</p><p></p><p>为此，特斯拉放弃了使用内核的思路，开始围绕编译器设计Dojo架构。“我们决定使用PiTorch，创建出中间层以通过并行化扩展底层硬件。底层的一切都是编译代码，这也是保证软件堆栈适应未来所有工作负载的唯一方法。”</p><p></p><p>尽管一直在强调软件灵活性，但Venkataramanan也承认他们的平台目前只能在实验室内支持特斯拉自己的工作负载。</p><p></p><p>他总结道，“我们首先得关注内部客户的需求。马斯克已经公开表示，这些成果将随时间推移逐步向其他研究人员开放，但我们还没有制定具体的开放时间表。”</p>",
    "publish_time": "2022-08-26 14:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]