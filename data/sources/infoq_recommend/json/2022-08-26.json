[
  {
    "title": "基础设施即代码：只是漂移管理还不够",
    "url": "https://www.infoq.cn/article/wV78kwciwMAqeVxtAlfy",
    "summary": "<p></p><h2>什么是配置漂移？</h2><p></p><p>随着公司的发展，软件生产和交付系统往往会变得越来越复杂。随着而来也会发生配置上的经常变更。</p><p>&nbsp;</p><p>在最理想的情况下，变更会以良好的方式进行全面跟踪。但是，我们的生产环境并不完美，比如其中的许多修改都没有记录。如果是无关紧要的修改，那么对系统的影响会很小。如果这些修改导致系统变得不稳定，那么就会出现所谓的“配置漂移”。</p><p>&nbsp;</p><p>当新建并合并分支，以及将其他多个变更提交到主分支时产生某种冲突时，就会出现漂移。在小型团队中，开发人员可以及时告知同事他提交了变更。而在较大的团队中，分叉（fork）和合并之间的变更数量可能非常多，产生的冲突数量以及解决冲突耗费的时间都会更多。</p><p>&nbsp;</p><p>也许，代码漂移是最常见的漂移类型，但由于现如今软件架构和依赖关系的复杂性，配置漂移也很常见。开发人员可能会在分支创建完成后在过渡环境或预生产环境中新建一张表。可能会新建一个lambda表达式，或是更新SQS配置。如果开发人员的环境发生漂移，那么代码在旧版本上可能运行正常，但合并到经过更新的环境就会出问题。在一些简单的场景，这可能不会立即发生问题，但随着复杂性增加，应用场景越来越多，问题可能就出现了。大量的调试和返工在所难免，进而导致发布时间延期。在接下来的几节中，我们将介绍几种配置漂移的管理方法。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/04/04553074a4ad28fccadcdc598147b0f6.png\" /></p><p></p><p>图1 代码漂移示例</p><p></p><h2>配置漂移的影响</h2><p></p><p>代码会在多个环境中“传播”，从个人工作站到共享开发、测试、QA、过渡以及生产环境。如果其中某些环境之间存在不一致，就会导致安全漏洞和部署问题。如果你要处理的应用程序和服务需要遵从严格的法规或标准，那么开发过程就会面临风险。</p><p>&nbsp;</p><p>确保软件开发生命周期中各个环境共享相似的配置是一项非常费时的工作，这需要多个部门的配合。有时候，团队要花数周时间为不同阶段配置不同的环境。</p><p>&nbsp;</p><p>员工经常会对他们的环境做些小修改，但不会将它们传递给生产环境。这类配置漂移通常不为人所注意，但也会造成严重影响。如果长时间不注意，它们就会导致应用程序出问题，软件工程师可能要花费数小时来追踪并修复。他们需要排查代码和环境问题，找出可能导致异常行为的原因，而这些时间原本可以花在更有效率的事请上。</p><p>&nbsp;</p><p>随着时间流逝，产品开发生命周期延长。除了宕机外，这是环境漂移最常见的后果之一。<a href=\"https://blogs.gartner.com/andrew-lerner/2014/07/16/the-cost-of-downtime/\">Gartner 2014年发表的一篇文章</a>\"提到，IT公司每宕机1分钟平均损失约5600美元。</p><p>&nbsp;</p><p>此外，这类事件会导致开发停顿，开发人员不得不立即放下手头的工作，切换环境并着手解决事件。这种中断可能会导致代码Bug，因为我们的思路被中断了，有些想法可能会遗漏。这样就有恶性循环的风险。</p><p>&nbsp;</p><p>配置漂移会影响员工满意度，导致与开发体验相关的指标下降。</p><p></p><h2>减少漂移的方法</h2><p></p><p>配置漂移多少有些不可避免。不过有许多方法可以减少配置漂移。在接下来的内容中，我们将探讨漂移管理的一些实用方法。</p><p></p><h3>建立清晰的流程，并做好文档记录</h3><p></p><p>在处理配置漂移时，应该优先确定一套清晰的变更管理策略和流程。在许多情况下，人为错误是漂移的主要原因，可能是因为没有遵守流程，也可能是因为没有和其他团队沟通好。设计良好的变更管理策略可以保证所有必要的测试都已进行，并且可以保证在正式批准应用于生产环境之前，有某个有权限的人评审并评估这些变更的影响，从而降低产生副作用及未知问题的风险。你要记录好应该做哪些变更，什么时候做，以及在什么系统上做。</p><p>&nbsp;</p><p>应用基础设施变更的方法越少越好，最理想的情况是，只有一个通道可以进行更改，不管是应用、开发、过渡还是生产环境。</p><p>&nbsp;</p><p>除了推送变更的通道外，还需清晰地定义好权限并严格执行，将审批/发布权限授予一组预先选定的人，他们经验最丰富，而且根据以往的情况看最值得信任。</p><p>&nbsp;</p><p>任何不符合标准的情况都可能导致配置漂移。</p><p></p><h3>实现基础设施即代码（IaC）</h3><p></p><p>遵循<a href=\"https://en.wikipedia.org/wiki/Infrastructure_as_code\">基础设施即代码原则</a>\"并使用类似Terraform这样的解决方案，是消除配置漂移最有效的方法之一。</p><p>&nbsp;</p><p>使用代码定义环境，而不是通过手动变更来同步环境，这本身就容易出错。代码很清晰，而且在任意数量的资源上应用/运行都一样，没有漏掉什么东西或颠倒操作顺序的风险。</p><p>&nbsp;</p><p>借助代码版本控制（如<a href=\"https://www.github.com/\">Git</a>\"），基础设施即代码平台还可以提供详细的记录，包括现在和以前的配置，解决了修改没记录的问题，这还有一个额外的好处就是留下审计线索。像Terraform、Pulumi和Ansible这样的工具就是设计用来管理配置的，可以用它们识别漂移并发出信号，有时甚至还能自动纠错——这样，你就有可能在变更真正影响系统之前将其纠正过来。</p><p>&nbsp;</p><p>和任何工具一样，效果取决于你的用法。使用一款像Terraform这样的工具本身并不能使你所在的公司免疫配置漂移。还是要设计好流程，而且每个人都要遵守；即使所有的部署都依赖IaC，在某些情况下（如添加、移除或修改远程资源）还是会发生漂移。你也无法保证所有部署都通过IaC，因为在许多情况下，仍然可能使用CLI、API或Web浏览器手动部署。</p><p>&nbsp;</p><p>在Terraform 中，检测潜在漂移最简单的方法是重新计算并评估Terraform预期状态的计划：如果计划为空，则基础设施状态符合预期，什么都没变；如果计划中有需要采取的步骤（而且你也没有修改代码），则表示有来自其他通道的变更导致了配置差异。有时候，这可以自动修复，系统可以立刻回到预期状态，但你至少应该查下差异是怎么出现的——对流程做相应地调整，避免同样的事情再发生。</p><p>&nbsp;</p><p>在共享和发布容器化应用程序时，基础设施即代码显得更加有用。虽然容器镜像包含运行所需的所有代码和软件依赖，但一旦部署到云上，它常常需要额外的基础设施元素来实现可扩展性以及提高可靠性（如负载均衡器、监控、日志等）。</p><p>&nbsp;</p><p>在将应用程序成功部署到云上之后，你需要确保它流畅地运行，而且限制特定受众访问。也就是说，你需要围绕容器镜像重建所有基础设施，而完成这项工作最简单的方法就是使用描述所有必要配置的IaC模板。</p><p>&nbsp;</p><p>注意，环境间（如开发和生产）的差异对容器化应用程序的行为和可靠性有很大的影响。这是由包括数据库、服务在内的所有云原生资源所致，它们都位于应用程序之外，但对于其正常运行至关重要。从这个意义上讲，IaC让变更可再现且可预测，保证过渡环境与生产环境非常相似，生产环境代码部署和基础设施变更的风险大幅降低，而效率则有很大的提升。</p><p></p><h3>规程与IaC的优缺点比较</h3><p></p><p>频繁重复手动执行变更步骤（不同的人在多次执行时都要严格遵守）很容出错。意外事件一定会发生——不是“是否”的问题，而是“什么时候”和“什么方式”以及“多么经常”的问题。</p><p>&nbsp;</p><p>运行速度快、每次都能一致应用的已测试代码可以消除大部分问题，但最终，这都归于强大的流程，即变更管理。要制定策略，强制使用IaC，屏蔽应用变更的其他方式，还要确保所有团队成员都遵循质量相关的流程。最终，测试、代码评审、影响评估以及审批都归结为UI中的几次按钮点击或是CLI工具中的一次命令执行，但是，在这些最终动作发生之前开展的底层工作非常重要，仍然是由人手动完成的。</p><p>&nbsp;</p><p>IaC让你可以做得更好，消除问题，减少意外事件，加快前进步伐，但实际怎么用还是取决于你。</p><p></p><h3>使用环境即服务（EaaS）解决漂移</h3><p></p><p>变更管理和自动化将帮你创建并扩大业务规模，并建立以简单明了的流程为基础的工程文化。而环境即服务解决方案可以帮助你恰当地实施这一切。</p><p>&nbsp;</p><p>在文章开头，我们介绍过配置漂移对工程团队的严重影响：花费数小时排查代码和环境故障，试图找出意外行为的潜在原因。此外，静态环境更容易发生配置漂移，因为它们是可变的——为了达到某个状态，将更改应用到当前状态，但这个当前状态可能并不是每次都像我们期望的那样。从零开始创建不可改变的环境，肯定可以减少阻力，大大降低遇到错误的概率。</p><p>&nbsp;</p><p>从这个意义上讲，环境即服务解决方案可以对很多工程团队产生巨大影响，让他们可以无缝地访问测试及开发环境，把省下的时间增加到实际的产品开发中。随着时间的推移，工程团队将变得更加独立，也更加专注于产品。</p><p></p><h2>总结</h2><p></p><p>在可预见的未来，配置漂移仍然不可避免。而市场上正在实施的一些配置管理方法，如自动对比环境的当前配置和基线配置，能缓解配置漂移的副作用。EaaS解决方案，配合IaC和良好的变更管理，可以帮助你预防漂移，缩短开发周期。借助合适的网勾（Webhook），我们可以识别代码或基础设施变更。通过维护每个环境的状态，可以知道它是否发生了漂移，并决定是否触发一次自动更新。我们希望任何生产环境都不出现漂移。但是，生产环境服务于在线客户，通常需要满足特定的服务等级协议（SLA），而且有维护窗口，因此，这些环境会有手动触发的更新，或是持续部署调度器触发的更新。</p><p>&nbsp;</p><p>作者简介：</p><p>Roxana Ciobanu是Bunnyshell的联合创始人兼首席技术官。她是一名云爱好者，热衷于保障高可用性、性能调优和云架构安全。她曾担任DevOps和解决方案架构师，实现了云技术与运营和开发的完美结合。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/iac-configuration-drift/\">Infrastructure as a Code—Why Drift Management Is Not Enough</a>\"</p>",
    "publish_time": "2022-08-26 08:56:11",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "风靡全网的Web 3，到底是个啥？",
    "url": "https://www.infoq.cn/article/jsf43rxkftgecP5aQCNG",
    "summary": "<p>作者 | 刘燕，王强</p><p></p><p>近一年多来，技术圈最热门的话题一定少不了Web 3的身影。Web 3的追捧者将它视为互联网的未来，但更多人仍然对这一概念感到云里雾里。</p><p></p><p>Web 3的定义与落地时间都充满争议，甚至有人指责它只是又一次技术炒作。那么，究竟该如何理解Web 3？Web 3能否实现支持者的预期？针对这一话题，《InfoQ·极客有约》特别策划了一场「共话Web 3」专题直播。</p><p></p><p>本场专题直播共组织了两场线上圆桌论坛，邀请多位对Web 3有深入研究的专家共同探讨这一新晋技术概念，希望帮助国内开发者和感兴趣的朋友更好地了解Web 3。</p><p></p><p>第一场圆桌对话的主题是《爆火的Web 3，到底是什么》，本场主持人是MRS联合创始人，《人工智障》系列作者Mingke，对话凯云实验室（KEN Labs）CTO杨威理（William），腾讯云区块链资深架构师梁永甫两位嘉宾。</p><p></p><p>本文将圆桌对话的精华内容整理如下，以飨读者。</p><p></p><p></p><blockquote>主持人Mingke：从区块链到金融科技，从去中心化到元宇宙，今天的技术世界有很多新概念、新名词。它们之间的关系错综复杂，很容易让人感到迷惑。最近流行的Web 3是之前多个概念的整合与升级，但究竟什么是Web 3还并没有一个相对统一的准确定义。那么各位能否从自己的理解出发，尝试对Web 3下一个定义？</blockquote><p></p><p></p><p>梁永甫 ： 我个人认为Web 3并不是一种单纯而具体的技术。它可能是一种趋势，或者一个时代的一个代名词，其中包含了非常多的内容，包括未来可能出现的一些新的应用或技术类型都会包含在这个大范围之内。所以，Web 3是一个包含各种各样的技术、应用的抽象集合。</p><p></p><p>另一个角度讲，如果说Web 1是可读，Web 2是可读、可写，那么Web 3就是可读、可写、可运维。这是大家最容易认可的一种定义，因为它不是特别具体，也就容易取得共识。</p><p></p><p>我们先把视角转到互联网上。互联网本身包含了服务端和用户端两大部分。从这个角度来看Web 3和 Web 2的区别，会发现Web 3在构造和提供服务时是一个相对分布式、去中心化的系统。 在这样的系统中提供的服务是生态型的，也就是所有人都可以提供自己擅长的内容，这些内容组合在一起可以为用户带来完整的、比现有服务更完善的产品。正因如此，Web 3需要用区块链来构建去中心化的基础设施，从而建设这样的生态。</p><p></p><p>在用户端，Web 3的重点在于“可拥有”。 所谓“可拥有”是指用户对数据和资产的控制权更大，很多内容会交给用户来控制。在用户体验和交互层面，Web 3还会从现有的文字、图片、视频升级到VR、AR为主流选项。</p><p></p><p>杨威理： Web 3诞生之初的愿景是互联网之父Tim Berners-Lee提出的“语义网”的概念。所谓语义网，是指数据在整个互联网层面实现互联，使分散在各处的数据能够彼此交流和共同更新，例如用户只需要修改一次账户信息，他在所有网站的账户就都会同步更新等等。这样以来，互联网上的信息就会更加准确和智能。</p><p></p><p>为了实现这一目标，Web 3的先驱者提出的方案就是用一个去中心化的项目来存储包括身份信息在内的用户数据。通过这种方式，数据的所有权会交还到用户手中，从而改善数据隐私问题。但今天所提的Web 3和语义网的概念还是有区别的。虽然两者的目的都是要重塑互联网，解决数据孤岛问题，给用户更多控制权，但Web 3会更看重数据的不可修改性，而语义网并不把不可修改作为核心的关注点。</p><p></p><p></p><blockquote>主持人Mingke：既然两位都没有对Web 3下一个非常精确的定义，没有明确Web 3究竟应该具备哪些特性，那么我们该如何定义基于Web 3的原生应用？究竟哪种应用可以说是完全基于Web 3的特性开发出来的？还是说这种Web 3原生应用其实是并不存在的？</blockquote><p></p><p></p><p>梁永甫：我认为在刚才提到的用户体验、数据归属权和服务提供方式三个层面上，只要应用在一个层面上满足新一代的特征（VR/AR、用户控制更多数据、去中心化提供服务），就可以称它为Web 3应用。 或者说，并不是说这三种特征全部满足才叫Web 3应用。在互联网向Web 3进化的道路上，我们可能会见证许许多多新技术的诞生。这些技术会一点点改变这三个层面的应用形态，但这些层面不可能一步到位、一次性全部升级完成。所以在这个过程中，只要满足了一个层面的升级特征，就应该说这个应用是Web 3应用。</p><p></p><p>在这个进化过程中也会出现一些负面产物，有人会用一些应用来做一些不好的事情。但我们要意识到，整个Web 3的概念是中性的、包容的，是一个趋势、演进过程和未来方向，不能因为某一个应用好坏和成败来评判整个Web 3。</p><p></p><p>杨威理： 我们内部也经常有讨论，探讨Web 3，或者说下一代互联网中的用户会有哪些需求。这些需求中的大部分应该是新型的需求，与我们今天的日常应用场景是不一样的。比如我们每天看视频、刷微博、玩抖音，这些应用的用户可能并不在乎自己发的抖音是存放在中心化还是去中心化的网络上。他们在乎的可能是去中心化的应用是否能为抖音用户带来更好的经济回报。内容创作者也会关注Web 3能否带来一些变革，能否在广告和打赏这样的主流收益方式之外创造更多可能性。</p><p></p><p>所以我们非常感兴趣的是，Web 3的时代互联网应用能否延伸到更多领域。我们认为这是非常重要的，尤其是Web 3能否创造出一批比较扎实的需求场景，既能有稳定的商业模式，又能为用户带来真正的价值。 我认为这才是下一代互联网标志性的特性或者事件，有了这样的场景才会有真正的Web 3变革，否则这个名词就只能停留在概念上。</p><p></p><p></p><blockquote>主持人Mingke：很多人感兴趣的是，现在究竟有没有一些能够让普通用户感知到的Web 3应用，比如说更加去中心化的即时通讯应用这样的案例。能否请两位分享一下类似的案例，或者对这样的产品做一些评价？</blockquote><p></p><p></p><p>杨威理：目前我们看到很多Web 2时代的应用团队和公司在尝试将Web 2的应用类型迁移到去中心化网络上。比如说有团队在做去中心化的YouTube，他们提供了一些工具让用户可以将视频同步到去中心化的平台上。同时他们还提供了新的创作收益机制。这种方式并不一定带来颠覆的效果，就比如说微信的用户并不会因为某个类似的通讯应用是去中心化的就去选择后者。究竟终端用户需要的是怎样的应用形态，这个问题还是见仁见智。所以，目前的Web 3生态还是处于相对早期的状态，还是处在一个“建设时代”。</p><p></p><p>以存储为例，我们有去中心化的存储方案，但还不够强大，跟主流的云平台还不足以抗衡，还需要长期发展。在这样的背景下就会催生很多应用，它们的目的是帮助这些基础设施能够在现阶段表现得更好。这些服务的模式多多少少还是带有Web 2时代商业模式的影子，但大家依旧可以通过它们开始体验Web 3的基础设施。</p><p></p><p>梁永甫： 从一个更大的角度来说，所谓数字化是要做什么？数字化过程中的每一阶段，数字化的内容是不一样的。在每一个阶段，我们不会关注之前已经数字化的内容，而是会关注还没有被数字化的事物。比如说Web 2时代，很多资产是没办法数字化的。但有了区块链之后，这些资产的数字化道路就被打通了，所以新技术让数字化跨入一个新的阶段。</p><p></p><p>换句话说，数字化是一种增量式的发展过程，Web 2提供的是Web 1的增量服务，而不是要颠覆Web 1的事物；Web 3也不会颠覆Web 2的模式，而是会创造一种全新的模式，通过去中心化的服务方式创造很多之前没法创造出来的事物。这就是Web 3时代的一个标志。</p><p></p><p></p><blockquote>主持人Mingke：很多人也在问，Web 3能够提供哪些独有的能力？比如说一个应用在Web 2时代做不到的事情，到了Web 3时代就可以实现了吗？</blockquote><p></p><p></p><p>杨威理： 从应用的层面来讲不好谈，我可以换个角度，从经济利益分配这个角度来聊聊。拿YouTube举例来说，用户在平台上发视频后，通过广告收入来获取回报。谷歌从YouTube获得的广告收益中分一部分给创作者，但这块收益并不是一般的内容创作者可以议价的。</p><p></p><p>但在去中心化的网络机制之下，这个经济模型发生了改变。平台并不存在一个中心化的实体来分发收益，相当于我们就像在菜市场卖菜一样可以自己定价。创作者可以有相对自由的运营空间，在这种空间之下每个内容创作者得到的回报也会更高。如果我们还是以传统的Web 2的模式去思考这个问题，我觉得我们很难做出比Web 2时代更好的应用；除非我们衍生出一个全新的需求，或者创造出全新的、这些大厂商无法支持的技术，但这样的概率也是很小的。</p><p></p><p>所以一方面来说我们要从用户需求层面去挖掘，另外可能是在经济模型上推动变革，才能让消费者去主动选择。否则用户还是会倾向于使用他最习惯的一些Web 2应用。</p><p></p><p></p><blockquote>主持人Mingke：从这个角度来讲，是不是可以说，短期看来我们还看不到具备非常明显的Web 3特征的应用？</blockquote><p></p><p></p><p>杨威理： 在国内环境中，我至少目前没有看到有很明显特征的应用出现。</p><p></p><p></p><blockquote>主持人Mingke：这里引出一个问题 —— Web 3需要怎样的土壤才能更好地发展？除了技术，还有经济、生态，以及开发者和消费者的思维等角度来看，什么样的土壤更适合发展Web 3？</blockquote><p></p><p></p><p></p><p> 杨威理： 这里有一个挺有趣的现象可以和大家分享一下，最近我们发现在印度以及非洲的一些国家，Web3的接受度、流行度非常高。我们可以从这个现实来思考一下，或许能够从侧面解答上面的问题。</p><p></p><p>首先，非洲国家的数字货币在全球是发展最快的。一方面是因为当地用户采用数字货币可以很便利地转账和国际汇款，另一方面也因为非洲国家的银行服务相对落后、货币不稳定、信用体系建设不完善。方方面面的因素决定了他们无法提供一个非常稳定的基础金融服务。所以采用这种低成本运营和维护的数字货币作为替代解决方案，对他们来说是个不错的选择。而且这些国家经济相对落后，需要快速发展，数字货币恰好满足了他们的需求。</p><p></p><p></p><blockquote>主持人Mingke：听上去有点像当年的电子支付在中国的普及过程。中国用户跳过了信用卡时代，直接迈入了移动支付世界。永甫老师又是怎么看待这个话题的？哪些环境特征适合Web 3的成长？</blockquote><p></p><p></p><p>梁永甫：我认为Web 3的成长与大环境的变化并不是强相关的。 比如说现在Web 3最流行的应用是NFT，那么无论在国外还是国内，用户都可以买到NFT，从而体验到Web 3应用。从这个角度来看，我们需要思考的还是Web 3究竟能够给用户带来什么价值。比如说非洲用户没有微信和支付宝，他们就会通过Web 3数字货币来满足自己的支付需求。我们需要挖掘Web 3能够给用户创造的各种场景，这个才是最重要的。至于监管环境之类的因素影响并不是很大，称不上是一种决定性的因素。</p><p></p><p>杨威理： 就梁老师提到的NFT这个话题，我认为我们可以从中做一些思考。比如说Twitter现在开始对接NFT，用户可以购买NFT作为自己的头像。这听起来并不是一种刚需，但我认为这是一个起点。或许这些NFT创作物，将来就是我们每个人在元宇宙或者虚拟世界里的个人表现形式。随着我们大家的生活方式越来越多地映射到元宇宙当中，这些NFT就有了真正的使用价值。</p><p></p><p></p><blockquote>主持人Mingke：就去中心化这个话题，我想到了一段历史。在互联网发展早期，电子邮箱协议是开放的，人人都可以用这个协议来搭建自己的邮箱体系，大家遵循相同的协议就可以互通。但并不是所有人都会这个技术，所以我们有了Gmail这样的邮箱服务。自然而然，这样的服务就成了中心化的平台。从这个角度上来讲，这种中心化的过程让更多的人享受了技术成果，两位老师是如何看待这个问题呢？</blockquote><p></p><p></p><p>梁永甫：不管未来的互联网是什么样的形式，最核心的部分还是要给用户创造价值、提供服务。 有些服务可能更适合去中心化的形式，还有一些依旧是中心化的形式更好。所以我们还是要从用户需求出发，看看用户究竟想要什么产品，这种产品适合哪一种形式，哪一种形式更好，我们就选择哪一种。我们要挖掘那些更适合去中心化形式的应用，这就是Web 3时代，我们需要重点去做的事情。</p><p></p><p>杨威理： 我认为大趋势并不是说在一个战场上拼杀得你死我活。中心化有它的好处和优势，去中心化也自然有它的不凡之处。我们还是以电子邮件为例，像谷歌提供的Gmail方便大家使用，同时也提供了很不错的存储空间，所以我们基本上不需要操心垃圾邮件的的空间占用问题。这是因为谷歌提供了一些补贴，其他一些小厂商很难提供这样的补贴，所以就需要收取一些费用，自然很难与谷歌竞争。</p><p></p><p>那么在中心化的邮件服务领域里有没有去中心化的可能性呢？举个例子，我们是否能够构建一个去中心化的邮件服务器网络，通过一定的激励机制激励邮件服务器节点稳定提供服务？我们或许无法保证用户可以免费使用，但至少可以做到更低的成本，甚至让用户自己都可以参与建设服务器节点来抵扣一些开支。 总之Web 3给我们带来了很多不同的玩法，也是大家乐意去探索的一个很重要的领域。</p><p></p><p></p><blockquote>主持人Mingke：最后这个话题，请两位嘉宾分享一下自己对下一代网络的看法。网络是由节点和边组成的，需要有协议让点与点能够连接起来。下一代网络的组成形态可能是非常多样的，那么下一代网络的节点、边和协议会有哪些变化，和现有节点等又有哪些区别？</blockquote><p></p><p></p><p>梁永甫： 还是拿邮箱通讯为例。邮箱通讯是点对点的，比如我们通过一个邮箱服务器通讯，我跟你通信只有我们两个能看到。这意味着这个网络连接在数据层面是双向的，或者说是线状的。</p><p></p><p>但实际上，在未来我们想要构建的是一个真正的网状网络。比如说区块链上的一笔转账交易，不仅转账双方能看到，网络中的其他所有人也都能看得到。这是非常大的变化。</p><p></p><p>比如说现在买房要先找中介，再经过房管局登记再付款，那么未来要构建的是中介、房管局和买家卖家是多方共同参与交互网络。比如说我找了一个中介，房管局知道了，房主也知道了；我跟他签了一个协议说我要买房了，那么房管局那边知道了，银行那边也知道了，到时候就可以直接去放款了。这个形式可以改变我们提供服务的方式，我只要做一个动作其他人就全都能看到，其他人各自做自己的事情就好，最后房子过户的过程就顺利完成了。我认为这种网状网络是真正的变革，可能会激发一些新的服务形式。目前来看，可能区块链是用来构建这种基础设施的一个比较好的选择。</p><p></p><p>杨威理： 我基本上也赞同。另外补充一点，目前Web 3的话题里大家关注比较多的就是去中心化的身份验证。 比如我们向警察出示驾照，多多少少会展示一些个人隐私数据。那么如何在不揭露自己这些隐私数据的同时能证明自己是有驾照的？这就是去中心化身份验证机制要做的事情，在Web 3社区里也已经看到一些相关的产品和服务。</p><p></p><p>从技术实现层面来讲，Web 3应用通常的做法是设置一个钱包。 用户个人的身份信息会存储在一个安全的网络之上，而需要公开展示的驾驶记录、病历之类的信息由相关机构颁发。颁发的这些数据并不留存在用户自己的钱包里，但用户有这个数据的密钥。当用户要出示这些信息的时候，可以向别人分享这个密钥，并让授权机构去验证。用户自己不需要构建服务器、节点平台这些基础设施，他只需要把自己的身份信息以及关键的密钥信息存储在自己可控的安全存储上即可，比如说软硬件形式的数字钱包里面。</p><p></p><p></p><blockquote>主持人Mingke：在某种意义上来讲，上面由第三方提供的服务不只是针对一个人，应该是提供给多个人，那是不是就形成了一个服务对很多用户的中心化场景呢？</blockquote><p></p><p></p><p>杨威理： 我觉得这些场景还不算中心化，因为我们可以认为它是一个软件服务的供应商，大家都是通过去中心化的协议来提供服务。</p><p></p><p>梁永甫：去中心化并不意味着什么东西都要我自己去做，我还是需要别人给我提供服务的。另外服务也不等于中心化，所有的服务都由一方提供才是是中心化 ，比如说有人给我提供了存储服务，有人给我提供了基于钱包的身份服务，那么存储和身份对用户而言是一个完整的服务，也就是说这么一个完整的服务的不同部分是由不同的厂商给我提供，从这个角度看，这个服务反而是去中心化的。</p><p></p><p>主持人Mingke： 非常感谢两位来分享对Web 3的看法，我们这一场的讨论就到这里。接下来的第二场圆桌讨论主题是《Web 3的核心基础设施》，下一篇文章将总结第二场讨论的内容供读者品鉴。</p>",
    "publish_time": "2022-08-26 10:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "特斯拉公布自研超算Dojo更多细节：计算模块为专为大型机器学习模型训练而生，可编程性决定成败",
    "url": "https://www.infoq.cn/article/7iTKNGigN3SLheqHNrtA",
    "summary": "<p></p><blockquote>早前在回答为什么要<a href=\"https://www.infoq.cn/article/fysqkmvmp9fuen02ibvj\">自研超算 Dojo </a>\"时，马斯克曾表示，“解决自动驾驶的唯一方法是解决现实世界中的 AI 问题，无论是硬件还是软件，而这也是特斯拉正在做的事情。除非一家公司具有很强的 AI 能力以及超强算力，否则很难解决自动驾驶难题。”</blockquote><p></p><p></p><h2>特斯拉公布自研超算 Dojo 细节</h2><p></p><p></p><p>近日，在 Hot Chips 34 大会上，特斯拉公布了大量<a href=\"https://www.theregister.com/2022/08/24/tesla_supercomputer_dojo/\">自研超算 Dojo 的细节</a>\"，并发布了两个有关 Dojo AI 超级计算机的深入演示。</p><p></p><p>本质上，Dojo 是一种可组合的规模化超级计算机，与我们熟悉的五百强超算系统不同，Dojo 是一套完全可定制架构，全面涵盖计算、网络、输入/输出（I/O）芯片，乃至指令集架构（ISA）、供电、封装和冷却。所有这些都服务于同一个目标：大规模运行定制化机器学习训练算法。</p><p></p><p>据了解，Dojo 发布于 2021 年 8 月特斯拉 AI Day，特斯拉硬件工程高级总监、Dojo 项目负责人 Ganesh Venkataramanan 当时曾上台就 Dojo 的主要性能进行了展示。</p><p></p><p>Ganesh Venkataramanan 表示，马斯克想要一台超快的训练计算机来训练 Autopilot。因此，Project Dojo 诞生了。Dojo 架构拥有一个大规模计算平面，极高宽带和低延迟。作为 Dojo 架构的重要组成部分，D1 芯片采用 7 纳米制造工艺，处理能力为每秒 1024 亿次。</p><p></p><p>Venkataramanan 认为，将一组这样的芯片放置在单个“训练片”上，以提供每秒九千万亿次的计算能力，并将 120 个芯片放在多个服务器机柜上，达到每秒超过 1 千万亿次的计算能力。这些芯片可以帮助训练模型来识别特拉斯汽车摄像头中收集到的各种物品。训练模型需要大量的计算工作。</p><p></p><p>在近期举办的 Hot Chips 34 大会上，Venkataramanan 在主题演讲中称，“现实世界中，海量数据的处理只能通过机器学习技术来实现，而由此支撑起的应用场景则包括自然语言处理、基于视觉设计的自动驾驶、与日常环境交互的机器人技术等。”</p><p></p><p>他同时承认，传统的分布式工作负载扩展方法并不能跟上机器学习对于处理速度的需求。时至今日，摩尔定律已经帮不上多大的忙，CPU 加 GPU 的组合、或者是极少数配备专用 AI 加速器的方案，也远未达到人们对于大规模 AI/ML 训练系统的性能预期。</p><p></p><h2>Dojo 的三明治式数据中心</h2><p></p><p></p><p>Venkataramanan 表示，“在过去，我们会先制造芯片，再把它纳入封装、部署进印刷电路板、接入系统，最后把系统安装在机架内。”问题在于，每当数据从芯片移向封装、或者由封装移出时，都会产生相应的延迟和带宽损失。</p><p></p><p>为了克服这些限制，Venkataramanan和他的团队决定从零起步、重新设计。“在当初接受马斯克的面试时，他就问我能不能在CPU和GPU之外，给AI场景一个新的答案。我们整个团队一直在为此而努力。”</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/20/20fcc1763837ad781263a77f765a8afb.png\" /></p><p></p><p>于是，Dojo训练单元应运而生。这是一个独立的计算集群，体积约为1.5立方英尺，能够在15 kW液冷封装中实现每秒556万亿次FP32浮点运算。每个单元都配备有11 GB的SRAM，并在整个堆栈中以自定义传输协议通过9&nbsp;TB/s结构实现互连。</p><p></p><p>Venkataramanan介绍称，“这个训练单元以前所未有的集成度，把计算机中的内存、电源、通信等机制整合了起来，无需任何额外交换设备。”</p><p></p><p>这个训练单元的核心就是 Dojo D1，一款包含500亿个晶体管的芯片，采用台积电7纳米制程工艺。特斯拉表示，每块D1芯片能够在400瓦最大散热功率下实现每秒22万亿次的FP32浮点运算。此外，该芯片还能支持包括自定义计算在内的其他多种浮点运算。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/83/83bb1f2812b1d6639ec2963fb21ebab5.png\" /></p><p></p><p>Venkataramanan表示，“从每平方毫米的晶体管密度来看，Dojo D1可能是当前最先进的技术成果。”</p><p></p><p>特斯拉将25块D1裸片用台积电的代工技术封装起来，由此“以极低延迟与极高带宽实现了对大量计算元件的集成”。然而，片上系统设计和垂直堆叠架构，也在供电层面带来了新的挑战。</p><p></p><p>根据Venkataramanan的介绍，目前大多数加速器都会将电源直接放置在芯片附近。他解释称，虽然也能通过验证，但这种方法使得加速器的大部分区域只能专门放置这些组件。而Dojo则反其道而行，选择直接通过芯片底部传输电力。</p><p></p><h2>组装成形</h2><p></p><p></p><p>“我们可以用这个训练单元构建起整个数据中心甚至是整栋服务器大楼，但训练单元只是计算的部分，我们还得考虑资源的实际交付。”</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7f/7ff849ded2643da665e8bc593720a6f4.png\" /></p><p></p><p>为此，特斯拉开发出Dojo接口处理器（DIP），负责充当主机CPU和训练处理器间的桥梁。DIP还可以提供共享高带宽内存（HBM）与高速400 Gb/s网卡。每个DIP包含32 GB HBM，最多能够将五块DIP卡以900 GB/s的速度接入同一训练单元，因此主机总传输速率达4.5 TB/s、单个单元&nbsp;HBM容量可达160 GB。</p><p></p><p>特斯拉的V1双单元配置方案就一口气用上了150块D1芯片，能够支持四块主机CPU、每台主机配备五块DIP卡，号称能实现百亿亿次BF16或CFP8性能。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f3/f3c9a55dcac89f582dec1c603ecb6660.png\" /></p><p></p><p>Venkataramanan称该架构帮助特斯拉成功克服了英伟达与AMD等传统加速器中的固有限制。“传统加速器的工作原理，是将整个模型部署到各个加速器内、多次复制，让数据流经每个加速器。但随着模型体量越来越大，结果会怎么样？这些加速器的内存可能不足以存放完整模型，到时候就没有训练效果可言了。”</p><p></p><p>这其实并不是新问题。英伟达的NV-switch就能够跨多个GPU实现内存池化。然而，Venkataramanan认为这不仅增加了复杂性，而且引入了额外的延迟与带宽损失。“我们从设计之初就考虑到了这一点，所以我们的计算模块和每块裸片都是专为大型机器学习模型的训练而生。”</p><p></p><h2>可编程性将直接决定Dojo的成败</h2><p></p><p></p><p>很明显，这样一套专门的计算架构需要与之配套的特殊软件堆栈。Venkataramanan和他的团队也意识到，可编程性将直接决定Dojo的成败。</p><p></p><p>“在我们设计这些系统时，最关注的问题就是软件的编程便捷性。研究人员可不会坐等我们手动编写出新内核之后，再尝试运行新算法，人家直接就换架构了。”</p><p></p><p>为此，特斯拉放弃了使用内核的思路，开始围绕编译器设计Dojo架构。“我们决定使用PiTorch，创建出中间层以通过并行化扩展底层硬件。底层的一切都是编译代码，这也是保证软件堆栈适应未来所有工作负载的唯一方法。”</p><p></p><p>尽管一直在强调软件灵活性，但Venkataramanan也承认他们的平台目前只能在实验室内支持特斯拉自己的工作负载。</p><p></p><p>他总结道，“我们首先得关注内部客户的需求。马斯克已经公开表示，这些成果将随时间推移逐步向其他研究人员开放，但我们还没有制定具体的开放时间表。”</p>",
    "publish_time": "2022-08-26 14:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "一文详解门限签名的技术原理与落地实践",
    "url": "https://www.infoq.cn/article/XUr1mzVlo4WGcGSEDz1T",
    "summary": "<p></p><h2>什么是门限签名</h2><p></p><p>&nbsp;</p><p><a href=\"https://www.infoq.cn/topic/Blockchain\">区块链技术</a>\"与签名<a href=\"https://www.infoq.cn/topic/Algorithm\">算法</a>\"缔结颇深，从安全、效率到流通，签名算法都在影响着区块链网络的特性及稳定。个人及机构对账户密钥管理的需求逐渐强烈，也催生出一批相关应用，对于用户而言，管理签名其实就是管理密钥。而在多链的情况下，多签或许不是密钥管理的最佳选择——用多签通过合约的方式来管理密钥，使用成本高，<a href=\"https://www.infoq.cn/topic/Security\">安全风险</a>\"高。除了多签技术之外，在区块链世界中逐渐兴起的门限签名技术也是一种重要的共识工具。</p><p>&nbsp;</p><p>门限签名（Threshold Signature Scheme，TSS）是数字签名的一个重要分支，它是一种基于安全多方计算（Secure Multi-Party Computation，MPC）的密码学技术，也是 MPC 密钥管理的重要研究方向。</p><p>&nbsp;</p><p>门限签名特点是一个签名一定是由一个私钥产生，然而这个私钥不会被任何人完整掌握，而是会以某种方式分成很多碎片，这些碎片可以被多人同时持有，然后通过 MPC 协议，保证这些碎片不需要全部被拼起来就可以直接产生一个合法的签名。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c5/c56eea8b820b95341fa8bf6cbe95dd00.jpeg\" /></p><p>图1 区块链上的 MPC 门限签名技术</p><p></p><p>在与区块链的结合应用中，门限签名的优势在于签名的生成是通过链下的 MPC 协议产生的，其结果是更加安全，避免了合约被黑客攻击的风险。因为门限签名与合约模块是完全解耦的，合约不需要理解签名的协议，它只要确认签名的有效性，这与传统的合约验签模式完全一致的。此外，合约的设计策略可以更加灵活，因为除了验签外的大部分流程都搬到了链下，使用方可以根据场景制定自己的碎片管理策略。</p><p></p><p>另一个重要的应用场景是密钥管理。基于 MPC 的密钥管理，一方面可以安全地存储密钥，单一或者小批量碎片的丢失，不会对该密钥的安全性有任何影响；另一方面是让个人或者企业能够更方便、更安全、满足业务逻辑地使用密钥。</p><p></p><h2>门限签名的算法原理与落地实践</h2><p></p><p>&nbsp;</p><p>目前针对门限签名的研究机构数量在递增，但已达到产品级标准的不多，本次我们以Open TSS 为例详解门限签名。</p><p>&nbsp;</p><p>Open TSS由 LatticeX Foundation 发起和支持，理论依据来源于发表在顶级密码会议（Asiacrypt 2021）的论文 <a href=\"https://eprint.iacr.org/2022/297\">DMZ+21</a>\"，目前Open TSS最新协议代码库正式开源上线，代码采用安全高效的Rust实现，支持一站式ECDSA MPC密钥生成(Keygen)、MPC签名(Sign)。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/57/5784c8414e6f56930d890265ffa150d6.jpeg\" /></p><p></p><p>可以看到当前版本（0.1.2）支持 <a href=\"https://en.wikipedia.org/wiki/Elliptic_Curve_Digital_Signature_Algorithm\">ECDSA</a>\"，其他算法如 EdDSA、BLS 等将很快被整合。下面我们介绍基于 [DMZ+21] 的多方 ECDSA。</p><p></p><h3>多方ECDSA</h3><p></p><p>ECDSA 被广泛用于密码货币，如 BTC、Ethereum（secp256k1曲线）等。</p><p></p><p>多方 ECDSA 协议（{ t, n }-门限签名方案），它允许 n 个参与方联合生成一个共同的公共验证密钥，以及 n 份相应的秘密签名密钥，并允许任何至少由 t + 1 个参与方组成的子集安全地分布式签署一个给定的消息，而 t 个或更少的参与方组成的集合则不能进行签名。</p><p></p><p>本库中的多方 ECDSA 协议是基于类群实现的。它目前包括两个协议：</p><p>密钥生成，用于创建秘密分片。签名，用于使用秘密分片来生成签名。这可以分为两个阶段，离线和在线。离线阶段与要签名的信息无关，可以提前计算。只需将信息（和离线阶段的输出）传递给在线阶段，就可以很快得到签名。</p><p></p><h3>功能使用</h3><p></p><p>目前，ECDSA 由两个功能模块组成，包括密钥生成、签名，签名功能分为离线阶段与在线阶段。</p><p>在使用上，对于上面的每个功能，只需要三个步骤。这里假设 (t, n) = (1, 3)，参与方的 id 为 1， 2， 3，分别以 P1，P2，P3 表示。</p><p></p><h3>密钥生成</h3><p></p><p>第1步。新建一个 KeyGenPhase 对象。</p><p><code lang=\"javascript\">let partyid = \"1\".to_string(); // P2, P3 are similar. let params = Parameters {\nthreshold: 1,\nshare_count: 3,\n};\nlet party_ids = vec![\"1\".to_string(), \"2\".to_string(), \"3\".to_string()];\nlet mut keygen = KeyGenPhase::new(partyid, params, &amp;Some(party_ids)).unwrap();</code></p><p>第2步。通过调用 process_begin 开始，它返回下一轮要发送的信息。</p><p><code lang=\"javascript\">let sending_msg: SendingMessages = keygen.process_begin().unwrap();</code></p><p>根据 SendingMessages 的类型（广播，P2P等）和内容，我们可以将索引（from）和消息（msg）一起打包发送给其他参与者。</p><p><code lang=\"javascript\">match sending_msg { SendingMessages::BroadcastMessage(msg) =&gt; {\n// broadcast the msg to all(including self).\n}\nSendingMessages::P2pMessage(msg) =&gt; {\n// send according to the k,v in the msg. k is the index which v will to be sent to.\n}\nSendingMessages::SubsetMessage(msg) =&gt; {\n// send according to the k in the party_ids or subset(used in sign phase). k is the in\n}\n_ =&gt; {}\n}</code></p><p>第3步: 通过 msg_handler 处理消息。</p><p>当收到消息后，会得到 recv_from 和 recv_msg，然后把它们传给 msg_handler，它返回一个结果或下一轮要发送的消息。</p><p><code lang=\"javascript\">loop {\n// let (recv_from, recv_msg) = According to the last round of SendingMessages let recv_from = \"\".to_string();\nlet recv_msg = vec![0u8];\nlet sending_msg = keygen.msg_handler(recv_from, &amp;recv_msg).unwrap(); match sending_msg {\nSendingMessages::KeyGenSuccessWithResult(msg) =&gt; {\n// got the keygen result break;\n}\n_ =&gt; {\n// other sending messages, ref Step 2.\n}\n}\n}</code></p><p>一旦收到 SendingMessages::KeyGenSuccessWithResult ，就表示此阶段完成。这里是一个密钥生成的样例：</p><p><code lang=\"javascript\">{\n\"index\": \"1\", \"participants\": [\n\"1\",\n\"2\",\n\"3\"\n],\n\"pubkey\": {\n\"pk\": [ \"10ec64d0a73c134c53ed764e86743397bab3bb06bdbbd638321b87eda9c6614e\", \"6b7df1b8b41c41fc69fef0d87fc8ee9d01c021936d3b44cd62883894cd60de14\"\n],\n\"share_pks\": {\n\"1\": [\n\"7a39ace81396d9c65dfb8f4c8ebdf3d5850447e129edbac052558b483b01ba52\", \"d942c292f40e65715f722b1db87d0ceaa122f9d6457eacffbd021653b0a6f65\"\n], \"2\": [\n\"6b31a24d2705971d18fffbdc2edbf4e97d01c2b4aea75df2a01566f03c269804\", \"5f94b59a0a97d604e356ca21c27b64c0f5dfc4e8315e4be8179c5292a8b6d015\"\n], \"3\": [\n\"79a7c9632cbfd98f890d9d4670ac301fda42db178b9b8ec2a2860e44488130da\", \"af7d69f73529d8235ae6dc9f896bd81830777ff9667d9ab1fc5b37599c712378\"\n]\n}\n},\n\"privkey\": {\n\"cl_sk\": \"1b557b69c49c0715403f618907a051c012adc57e9ea6b17aa912d68b6056b1d24b5c10a36269ac03 \"ec_sk\": \"a23ae304a46c36bbf52e1373daa4446dda3f3b1b721a77c84a2ec86f54e6970c\",\n\"share_sk\": \"f869bd11e46d036cdd81ad9940c9d510d24114bba12edfa626a966677058ff5a\"\n}\n}</code></p><p></p><h3>签名-离线阶段</h3><p></p><p>第1步。与密钥生成类似，新建一个 SignPhase 对象。</p><p><code lang=\"javascript\">let partyid = \"1\".to_string(); // P2, P3 are similar. let params = Parameters {\nthreshold: 1,\nshare_count: 3,\n};\nlet subset = vec![\"1\".to_string(), \"2\".to_string()]; // The set of parties that involved in si let keygen_result = \"\".to_string(); // The output of KeyGen\nlet mut signoffline = SignPhase::new(partyid, params, &amp;subset, &amp;keygen_result).unwrap();</code></p><p>这里的 subset 就是参与签名的各方集合，是所有参与密钥生成的一个子集。</p><p>第2步、第3步：与密钥生成一样。当收到 SendingMessages::SignOfflineSuccessWithResult ，就表示此阶段完成。</p><p></p><h3>签名-在线阶段</h3><p></p><p>第1步。类似的，新建一个 SignPhaseOnline 对象。</p><p><code lang=\"javascript\">let offline_result = \"\".to_string(); // The output of SignOffline\nlet message_bytes = vec![0u8; 32]; // The hash value of the message to be signed, 32 bytes. let \nmut signonline = SignPhaseOnline::new(&amp;offline_result, message_bytes).unwrap();</code></p><p>第2步、第3步：与密钥生成、签名离线阶段一样。当收到SendingMessages::SignOnlineSuccessWithResult ，就表示此阶段完成。</p><p>从安全角度考虑，离线阶段的结果只能使用一次。整个在线阶段只需要几毫秒即可完成。</p><p></p><p>这里是一个签名的样例：</p><p><code lang=\"javascript\">{\n\"s\": \"14af6f72d8bd26faccd75ff092544d15a3dce5d97e897773b515cd70ab0453e7\", \"r\": \"3687024517eb44de2cfaa6166866c9bd2587090317a4d12521b571c7509319b4\",\n\"recid\": 0\n}</code></p><p>一份<a href=\"https://github.com/LatticeX-Foundation/opentss/multi_party_ecdsa/src/protocols/multi_party/dmz21/local.rs\">本地代码</a>\"显示了如何使用这些功能。参考<a href=\"https://github.com/LatticeX-Foundation/opentss/docs/ECDSA.md\">这里</a>\"了解更详细的使用说明。</p><p></p><h3>性能表现</h3><p></p><p>我们来看看OpenTSS的性能如何，与最先进的协议进行比较。为了进行公平的比较，我们用 Rust 实现了两个多方 ECDSA，包括我们的协议和 [<a href=\"https://eprint.iacr.org/2020/084.pdf\">CCL+20</a>\"] 中的协议。椭圆曲线是 secp256k1，类群的判别式的位长选择为 1827，这确保了我们的协议具有 128 位的安全性。运行时间是在 Intel(R) Core(TM) i7-9700K @ 3.6GHz 的单核上测量的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f1/f1b9eafde795277e822f2368a38d7ee6.jpeg\" /></p><p></p><p>如上表（来自论文第 7 节）所示，进行了具体比较。与基本上基于 [<a href=\"https://eprint.iacr.org/2019/114.pdf\">GG18</a>\"] 的 [CCL+20] 相比，可以看到OpenTSS的多方 ECDSA 协议的改进是非常明显的。它主要体现在密钥生成阶段。</p><p></p><p>在计算复杂度方面，OpenTSS的多方 ECDSA 协议比 [CCL+20] 中的协议在 κ = 40(κ = 128) 时的密钥生成阶段快 4 倍（12 倍），这在理论（详见论文）和具体方面都可以看到。OpenTSS构造的签名阶段比 [CCL+20] 中的略好，在具体方面大约快 10%。</p><p></p><p>在通信方面，由于OpenTSS消除了昂贵的交互式设置阶段的需要，OpenTSS的协议在密钥生成阶段优于 [CCL+20] 中的协议，其差异根据参与方的数量 n 和门限 t 而变化。虽然在签名阶段通信开销稍大，但OpenTSS的解决方案仍然是同一数量级的。</p><p></p><h2>总结</h2><p></p><p>可以看出，门限签名协议将成为众多机构持续投入研究的方向、为开源社区做贡献、在不远的将来，相信以Open TSS为代表的产品将向区块链安全技术服务商的方向发展，为区块链钱包、托管企业提供底层架构服务。</p><p></p><p>Open TSS项目地址：<a href=\"https://github.com/LatticeX-Foundation/opentss%E3%80%82\">https://github.com/LatticeX-Foundation/opentss</a>\"<a href=\"https://github.com/LatticeX-Foundation/opentss%E3%80%82\">。</a>\"</p><p></p><p>参考文献</p><p>1. <a href=\"https://eprint.iacr.org/2022/297\">Promise Σ-protocol: How to Construct Efficient Threshold ECDSTSSA from Encryptions Based on Class Groups.</a>\"</p><p></p><p>相关课程：</p><p><a href=\"https://www.infoq.cn/video/kHp21mRk7rBxWQ8KDyhA\">ZK 训练营第一课：ZKP 密码学基础知识</a>\"</p><p><a href=\"https://www.infoq.cn/video/DMUmGWpLVqL21TDZ04bu\">ZK 训练营第二课：ZKP 经典协议</a>\"</p><p><a href=\"https://www.infoq.cn/video/9VrhU74b6JYO9Yk6aeXj\">ZK 训练营第三课：ZKP 电路应用导论</a>\"</p><p><a href=\"https://www.infoq.cn/video/ERqbLpof2kk6ZyNfDmww\">ZK 训练营第四课：基于 ZK 协议的机器学习隐私保护设计</a>\"</p>",
    "publish_time": "2022-08-26 14:52:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "圆桌对话：如何协同构建统一生态？",
    "url": "https://www.infoq.cn/article/KQ7eA197Jew6cgsphj68",
    "summary": "<p></p><blockquote>在&nbsp;<a href=\"https://xie.infoq.cn/article/250a610f1def4b3cd8331006b\">2022 开放原子全球开源峰会</a>\"上，三大运营商代表集结龙蜥专场圆桌环节，共同参与讨论了“如何协同构建统一生态”这一话题，本文为圆桌对话内容实录。陈绪（主持人）：龙蜥社区运营委员会主席、阿里云技术战略总监刘澎：中国开源软件推进联盟副主席兼秘书长、中国科学院软件所研究员肖微：联通软件研究院副总架构师张涛：天翼云产品与生态部高级产品经理严海双：移动云操作系统研发专家</blockquote><p></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/bc/1f/bc86facbf630ff6e40b57d678d714b1f.png\" /></p><p></p><p></p><h4>陈绪：各位都是代表国内领先云厂商的生态专家，为什么说统一生态对各自业务的发展起到非常重要的作用？可否举例说明？</h4><p></p><p></p><p>肖微：从联通来讲，我们近期发布的新战略叫“强基固本、守正创新、融合开放”，这个战略里面把开放作为很重要的内容，也当作联通的定位。我们对内建设服务联通数字化转型的整个 IT 系统，对外敏捷赋能千行百业，打造智慧的行业解决方案。</p><p></p><p>在整个过程中，不管是内部的 IT系统建设，还是对外输出的时候，都会联合整个产业的生态伙伴一起做。既然邀请大家参与进来，我们就一定要去统一标准。“车同轨，书同文”，一定大家要在统一标准上有一个良好的分工进行协同。如果没有一个统一生态，一个社区或者一个标准去做的话，大家可能就会出现七国八制的现象，一方面是资源的浪费，更重要的还是影响效率。</p><p></p><p>张涛：首先龙蜥社区是国内基础软件领域的龙头社区，有众多合作伙伴共同参与，特别是理事单位的一些重要参与和支持。在中国电信集团云改数转战略要求下，电信天翼云在行业拓展中也面临着各种行业场景化的建设。为了支持云业务的发展，天翼云和龙蜥社区在产品特性、内核规划、重要技术领域等方面都有共享和交流，存在非常多的契合点。跟刚才联通肖微总提到的一样，我们也是想推动建立统一生态，服务整个产业链或者中国电信天翼云自己业务的发展。</p><p></p><p>严海双：我的理解是统一生态最关键的就是基础软件的统一。比如操作系统、数据库等基础设施都属于这一类，因为各行业领域应用的性能、安全性都是建立在基础软件能力上的，所以我认为基础软件如果不统一也会制约产业链上下游技术创新。因此我们想借助于国内开源社区，尤其像龙蜥社区生态能够去构建我们的基础软件体系。移动云基于龙蜥操作系统也发布了移动云的操作系统，融合了移动云自己一些创新能力，针对移动云基础设施也做了很多优化和特性，在统一生态这块会与社区进一步共享。</p><p></p><p>刘澎：统一生态是由软件决定的。我们在开源软件里头有重要的三个许可证，第一个许可证是以 BSD、MIT 所决定的许可证，我们比喻它就是一棵大树的根，它们对软件产生的约束非常松，是吸收营养的一个。第二个许可证大家也很清楚，Apache 许可证，它最典型的东西就是安卓操作系统，那个操作系统是一棵大树的树冠，必须开枝散叶。</p><p></p><p>现在龙蜥社区遵循的是 GPL 许可证，GPL 许可证为什么要严格，它是一个最基本也是最关键的工业基础之间的基础件，所以它必须是统一的。为什么？如果一棵大树长出好几个杈来，这个树枝必须有杈，树干不能有杈。我对这个问题研究了很长时间，一开始觉得是左和右的问题，后来经过多年的研究才清楚不是左和右的问题，是整个生态对工业的要求，有吸取营养的，要特别宽松，开枝散叶的必须相对宽松，但是也要有相对集中的。龙蜥是一个上游的社区，所以它必须是 GPL 许可证，必须统一起来，否则社会成本极高。要统一中国基础电信业的操作系统，就要建立竞争关系，在一个小生态里各自产生创新，再汇聚在一处。</p><p></p><h4>陈绪：在 2020 年 12 月份，CentOS 宣布即将停服，想问各位嘉宾 CentOS 的停服对我们刚才提到的统一生态建设带来哪些挑战？</h4><p></p><p></p><p>刘澎：我觉得机会到了，该是我们中国开源软件蓬勃发展的时候了，对国际开源社区提供的共享产生压力。这次断供造成了中国后起之秀的接班，但是现在还不能完全替代它，但是找到了第一次全面接盘的机会，所以我们对龙蜥社区寄有很强烈的希望。</p><p></p><p>严海双：CentOS 停服带来的影响确实比较大，刚才听了很多的分享也讲了为应对 CentOS 停服未来要做哪些事，我认为 CentOS 停服带来的挑战有以下三点。</p><p></p><p>首先，我觉得最大的问题就是业务应用方案要考虑如何更换操作系统，还有如何保证存量业务平滑地迁移到国产化操作系统版本上来。有没有一款比较强大的工具来帮我们做到比如原地的迁移，或者滚动式的集群式迁移升级等。</p><p></p><p>其次，在生态构建方面，我们认为不能因为 CentOS 停服就把原来 CentOS 生态里的软件完全否定掉，我们还是希望能和 CentOS 原有的一些生态保持兼容性，能让用户以很小的成本迁移到最新的国产化版本上来。</p><p></p><p>最后，在开源社区治理方面，<a href=\"https://www.infoq.cn/article/CoA8RIxpRFfmPjgiWkmV\">CentOS 停服</a>\"也能给大家带来一些思考，社区还是希望转向共治共建的策略。就像两天前参加的龙蜥理事会上很多理事也提出来对龙蜥宣言的修改，社区治理还是要有书面的规范，类似社区技术路线变动这种重大的议题都需要比较公开公正的策略来做。</p><p></p><p>张涛：其实从去年开始 CentOS 停服在整个业内引起了很大的反响，因为它涉及到了过往很多 IT 信息基础设施的底层设计。这块为什么会产生这么大的影响，因为大家都有共识，就是服务器操作系统是很多业务架构软件侧的载体，因为 CentOS 本身的社区和产品的成熟度，以及它在发展历程当中形成的软硬件生态强联合的机制，包括各种认证和授权，无论是大家自己的 IT 信息国产化建设，或者是面向各行业的 IT 建设，我们都会面临在不同场景中存在迁移困难的问题。</p><p></p><p>这个问题的解法，除了每一家专门攻坚自己的技术侧外，还需要中国人有一个自己的社区把整个产品生态做大起来，未来中国才可能出现完全替代 CentOS 的技术形态。</p><p></p><p>肖微：针对 CentOS 停服这件事情，我们刚开始的时候还是蛮担心的，因为整个需要迁移的量还是非常大的，但是我们很快就开始做试点研究，联合龙蜥社区还有国内开源社区的 ISV 共同做这件事情。经过二年的试点尝试，在&nbsp;CentOS 替代的技术处理上还是挺有信心的。接下来更大的挑战可能就是工作量，服务器总量还是非常多，软件业务系统非常复杂，这对我们来说是第一个直接挑战。</p><p></p><p>第二个挑战是这件事带来的思考，我们开始反省整个联通对开源软件的引入，开始思考不管是国外的开源软件还是国内的软件哪些是能投入到生产长期使用的，哪些是有风险的。于是，我们去年联合一些机构开始做开源的治理，包括开源软件的安全，这个事情可能比 CentOS 停服处理更长远一些。</p><p></p><h4>陈绪：在座的各位嘉宾都是龙蜥社区的最初理事代表单位成员，尽管在业务上大家有所竞争，但是大家联合组建龙蜥社区理事单位这样一个机构是出于什么目的，同时这样的协同对大家有何意义？您对有竞争的厂商在一起组建这样一个联盟有什么样的想法？</h4><p></p><p></p><p>刘澎：是否组建联盟是由产业位置决定的。像我刚才谈安卓谈了非常长时间，才终于清楚安卓里面有一个 Linux 核，外面有两张皮，驱动和 UI 界面。产业位置是由它的许可证决定的，因为它在应用层界面不是在内核界面。龙蜥现在做的是把业内核心力量都联合起来的，这是一个工业基础件，不能有两个。只有工业基础件的一致，这样才能节约整个社会成本。什么地方不能一致？到了上面不能一致，要不然没有先进性，大家都用一个东西，就像每天餐厅就只有一道菜。所以说，大家炒的菜可以不同，但是炒菜的锅必须是一致的。</p><p></p><p>严海双：我们作为最先加入龙蜥社区的理事单位，去年跟社区签署了协议，原先的设想也是跟社区一样可以实现共建共治共享的理念，来打造 Linux 开源操作操作系统和创新平台。我们基于 Linux 社区版本做二次开发，发布移动云自己的企业定制版，也是想融合拉通移动云里面的底层基础设施资源，向下统一基础技术架构，最小化底层硬件差异，向上赋能各个产品业务创新。</p><p></p><p>张涛：我们电信天翼云也是，作为最初的理事成员单位，在去年很早的时候加入到龙蜥社区。我想说两点想法，第一，天翼云作为一家主要从事云服务研发的厂商，操作系统在云计算研发体系中是一个非常重要的环节，并且天翼云也是以全栈自主研发为目标的企业，在整个公司业务发展中也是一直秉承着拥抱开源、拥抱技术这样的目标，这跟龙蜥社区的文化比较契合。第二，作为国内比较重要的云计算厂商，也会积极参与把相关能力贡献到社区里，这也是作为天翼云这家公司的责任与担当。</p><p></p><p>肖微：联通作为首批加入龙蜥社区的理事，有两点考虑。第一个，操作系统是云非常重要的生态。因为操作系统向下管理整个硬件，向上承载适配着数据库、AI、中间件等众多软件。第二个，龙蜥社区成立时成员的设置非常好，里面既包括云的企业，也包括了操作系统企业、芯片企业，成员配置是非常齐全的，整个社区成立时就是以开放、中立、平等的原则。龙蜥未来的发展是非常可观，这是我们加入的一个原因。</p><p></p><p>当然更直接的原因有三点：第一点是 CentOS 停服，龙蜥操作系统替代方案是一个非常好的选择。第二点是我们在做联通云的时候，云本身对操作系统有非常多的需求，一般来说应用系统和操作系统只要能把程序 run 起来，或者性能有一定的优化就可以了，但是云不一样，比如云用到很多新的特性，包括 IO 的优化、虚拟化等等，都是需要操作系统内核来支撑的。因此，我们希望在使用操作系统的场景和诉求上，在社区里相互协作和支撑。第三点，国家近两年颁布了很多“网络安全”、“数据安全”等法律，联通在落实这些条款的时候，引进了大量国产芯片，比如 Arm、国产 X86 等，还有国产数据库。我们引进来国产芯片和数据库之后，迫切需要有一个非常好的操作系统来去做适配，因此联通积极投身龙蜥社区的建设，希望能够在社区里面把软硬件结合起来。</p><p></p><h4>陈绪：最后的时间给到四位，请提出对龙蜥社区的希望，以及如何更好地建设统一的协同生态。</h4><p></p><p></p><p>刘澎：这个命题很大。我们还是高度地寄希望于龙蜥社区能成为中国技术软件领域创新的领头羊。谢谢大家。</p><p></p><p>严海双：我们也将会借助于移动云的能力和优势，将与龙蜥社区继续合作，共享能力积累，共建创新平台。</p><p></p><p>张涛：国产技术软件目前迎来发展黄金期，同时也面临很多的困难和阻力，也希望在龙蜥社区大家的共同努力下拥抱开源，分享各自的能力，将整个中国技术软件体系进行进一步的提升和加强。</p><p></p><p>肖微：寄语谈不上，对社区提一些想法，我觉得应用上还是保持开放，技术上进行务实地去做创新。对于每一个参与者来说在社区里面找到自己的定位，最后每个人在社区里进行贡献，每个人也有收益。</p>",
    "publish_time": "2022-08-26 14:53:18",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "分布式数据库技术发展趋势及选型与标准思考 | 数据库Talk Show",
    "url": "https://www.infoq.cn/article/aFGc1l02v39SsT1XSEAU",
    "summary": "<p>随着信息技术的迅猛发展，各行各业产生的数据量呈爆炸式增长，传统集中式数据库的局限性在面对大规模数据处理中逐渐显露，从而分布式数据库应运而生。分布式数据库是在集中式数据库的基础上发展起来的，是分布式系统与传统数据库技术结合的产物，具有透明性、数据冗余性、易于扩展性等特点，还具 备高可靠、高可用、低成本 等方面的优势，能够突破传统数据库的瓶颈。</p>\n<p>分布式数据库目前已应用到金融、电信等大数据行业，未来将走向更广阔的领域。本次“数据库 Talk Show”活动将围绕分布式数据库技术路线和产业现状，分析分布式数据库的技术特点以及面临的问题与挑战，对 企业如何进行数据库选型 互动讨论。</p>",
    "publish_time": "2022-08-26 15:00:37",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "【DBA100人】李建明：一名普通DBA的14年技术之路与成长智慧",
    "url": "https://www.infoq.cn/article/Yx2W8Y27mZ9G5eurg5ze",
    "summary": "<p>“DBA100人”专访计划是<a href=\"https://xie.infoq.cn/article/3c4e351e08cde87a0010c2fcd\">OceanBase</a>\"围绕资深DBA进行的人物专访活动，旨在通过人物故事、职业发展经历以及日常工作中遇到的技术难题和实践案例，未来对技术趋势的想法，希望他们的成长之道能够给到各行业DBA一些建议和思考。</p><p></p><p>编者按</p><p></p><p></p><blockquote>DBA如何快速定位故障？如何做好性能优化？如何做好技术选型与技术体系建设？今天《DBA 100人》第1期带你了解一位拥有十多年职场经验的资深数据库专家&amp;运维人——云南某银行信息科技部运维中心经理，他曾负责主机、中间件、数据库的维护；参与银行核心系统、支付系统的开发；领导运维体系、应急容灾体系、监控体系的建设，希望他的经验能给你带来参考价值。</blockquote><p></p><p></p><p>2001年，这个问题对于正在报考大学志愿的李建明而言，一无所知。和许多因为“喜欢玩电脑”和觉得“编程有趣”的人不同，李建明高中时都不曾接触计算机，只因那时计算机还未在全国校园普及，他只曾听人说起，学计算机能在毕业后找到一份不错的工作。</p><p></p><p>就这样，李建明成为中国第一批学习<a href=\"https://xie.infoq.cn/article/36be05f6ca2e730118d6d8cd8\">信息安全技术</a>\"的本科生，在校期间还兼职开发了办公软件、论坛、博客等，第一次感受到了编程的乐趣：“我很享受这种从无到有，一步一步把产品做出来的过程”。由于信息安全技术的知识比较宽泛，对于想在计算机领域稳扎稳打的李建明而言必须深入工程，打好编码的底层基础。因此，他在报考研究生时选择了系统分析与集成专业。对于专业的选择，李建明认为一个重要的判断因素是“未来这条路是宽还是窄，通俗地说就是未来择业时，你所选方向的市场需求量是大还是小？还可以结合自己的兴趣考虑，在自己感兴趣的领域或许会更加顺利。”</p><p></p><p>这次选择，为李建明进入数据库领域，成为一名<a href=\"https://www.infoq.cn/article/W9usxEG4ciJGKhwo6j94\">DBA</a>\"埋下了伏笔。</p><p></p><p></p><h3>成长中的DBA：快速定位故障，清楚系统运行机制</h3><p></p><p></p><p>2008年，研究生毕业的李建明入职正值电子化改革高速发展期的某信用社，参与核心系统和支付系统的维护与开发工作。早在2004年，国务院要求深化农村信用社改革，某信用社响应国家号召，在2005年成立了<a href=\"https://aiqicha.baidu.com/detail/compinfo?pid=xlTM-TogKuTwnlLzyUKB*OLVwqAlmfhBtwmd&amp;rq=es&amp;pd=ee&amp;from=ps\">科技结算中心</a>\"，建设了信息系统，此举也为客户带来了更方便、快捷的金融服务。但不断上涨的交易量给系统带来了挑战，系统稳定性的保障难度不断加码。</p><p></p><h4>“快”是一大挑战</h4><p></p><p></p><p>信用社信息系统的搭建正是由李建明所在的科技结算中心负责，因此，从入职起他就一边负责系统的维护，一边优化系统，工作之余还自学DBA相关的知识。作为系统维护人员，李建明需要在系统出错时，及时定位故障并快速修复。而要做到“快”，对于初入职的“技术小白”而言却很有挑战。</p><p></p><p>李建明的办法是搞清楚系统运行机制、执行流程。当系统报错时就可以很快地查询到哪些账务是错误的，以及这种错误会在什么情况下出现。</p><p></p><p>一般来说，运维人员会觉得应用系统永远都是缺文档的。开发人员可能不会将文档写得全面。因此，运维人员在维护系统时就需要多钻研。比如，了解系统架构与业务架构及其技术实现路径，了解系统表结构就能基本掌握业务结构，了解操作系统的命令就能掌握系统的结构。此外，还要进一步学习系统组件，如钻研数据库的表结构。</p><p></p><p>通过不断地深入了解系统各个层面以及不断向上层探索，逐渐清楚系统的运行机制与执行流程，并在一次又一次的假设问题与验证答案中掌握真理。当“实验”做得足够多时，自然就能掌握快速定位故障并修复故障的能力。除此以外，李建明花了七八个月的时间通读系统主要的源代码。这段时间的钻研与自学，不仅使李建明可以在系统出错时快速找到问题，也让他的技术能力与代码质量都得到了迅速提升。</p><p></p><p>2010年，李建明也因为两年的优秀表现，正式成为了一名系统管理员兼数据库管理员（DBA），负责系统的稳定与高效运行，并管理和维护数据库、操作系统、应用软件、中间件等。“当时有两个系统管理员，只要出现技术故障，我们都需要介入处理”。而他在这两年对系统的钻研与探索，使他对系统基本了如指掌，对新的工作任务得心应手。</p><p></p><h4>摸索、踩坑、学习</h4><p></p><p></p><p>这些问题对于一个成熟的DBA而言都不算难。但对于成长中的DBA而言，需要不断在实践中摸索、踩坑、学习。</p><p></p><p>例如，数据库连接池出现故障时，经验较少的DBA可能会认为是连接数量不够，于是不断创建更多的连接，当连接池占满时也没能解决问题。因为连接池满只是一种现象，解决根本问题还需从现象看本质。在一些情况下，确实存在业务量过大的原因，但在大多数情况下，业务量不会突然增大，连接池满的原因可能是新业务不高效，导致连接池堵塞或者连接池没有及时释放。这时，一味地加连接只是延缓系统堵塞，并不能从本质解决问题。</p><p></p><p>再例如，发生长事务问题导致业务中断时，对原理不熟悉的DBA只会傻傻地等待事务回滚。但积累一定经验后，就会知道，其实可以通过不断增加事务日志文件，来保证业务正常运行的过程中将事务回滚完成。</p><p></p><p>“系统管理员的工作，让我对软件系统有了更深入的了解。从理论到实践，积累了丰富的故障处理及性能优化经验，提升了技术自信心”，李建明如是说。同时，他总结了保障系统稳定性及定位故障、优化性能的经验。</p><p></p><p>作为DBA，保障系统稳定性是重中之重，李建明认为需要做好三项工作。</p><p></p><p>第一，预防，即关注网络、存储、计算资源，以及操作系统等基础架构的规划。确保基础框架保持相对的统一。</p><p></p><p>第二，在系统正常运行时，注重从业务视角观察系统运行是否有异常，是否处于亚健康状态，做好预警、应急等方面的可观测性建设，完善容灾体系和标准化操作管理。</p><p></p><p>第三，应急，即通过系统架构定位故障，再结合监控系统辅助分析问题。对于故障定位与性能优化，可从三方面开展：</p><p></p><p>1）确认系统架构和业务架构，站在全局的角度排查问题；2）关注各种指标，如常见的CPU内存、I/O、负载、业务量，业务的成功率、响应时间等；3）在压力场景下，从前到后排除每个模块的性能表现，或者是一些活动的概要信息和详细信息，包括当前系统正在做的一些操作。比如调用了什么函数，执行了什么SQL，以及每一个线程正在执行什么函数，甚至关注网络传输包的响应效率和网络延迟等问题。</p><p></p><p>此外，为了避免各模块负责人之间推卸责任，需要有一个技术融合的团队，在应急时每个人都能统管全局，快速上手处理问题。</p><p></p><h3>经验丰富的DBA：数据库选型不求最贵，只求最好</h3><p></p><p></p><p>在某信用社的十年，李建明从懵懵懂懂的应届生成为了经验老到的系统管理员与高级工程师，该信用社的电子系统也从支撑上百万账务交易量发展为支撑上千万账务交易量。如果说信用社是李建明职业生涯的基石，是培养他职业技能的摇篮，那么银行就是他十年职业技能与经验的高级试炼场。</p><p></p><p>自2018年李建明加入云南某银行，负责运维团队的管理与运维体系、应急容灾体系、监控体系的建设。另外，在2021年参与了一项看似离DBA很遥远的工作：数据库选型。</p><p></p><p>不以业务为基础的选型就是耍流氓，想做好技术选型，首先要对市场中哪些数据库可以作为备选有一定的了解。李建明认为，一款优秀的数据库产品应该像Informix一样稳定、简洁，同时又能像Oracle一样拥有丰富的内置系统表，且具备高性能特性。还应该达到<a href=\"https://xie.infoq.cn/article/09cd09f843321bf85af6e666d\">ACID</a>\"（Atomicity、Consistency、Isolation、Durability，即或称不可分割性）、原子性、一致性、隔离性、持久性）的要求，另外，保证应用的透明性是不可或缺的能力。数据库还应该给予DBA足够的掌控感，让DBA看到他和数据库交互的过程中使用了什么工具、消耗了多少CPU、用了多长时间，以及做过哪些操作。</p><p></p><p>其次，针对业务特性，选择“最优解”。以李建明当前所在的银行行业更换数据库时的技术选型为例。</p><p></p><p>大部分银行都会使用较为成熟的<a href=\"https://www.oracle.com/\">Oracle数据库</a>\"，使用Oracle的好处在于其文档、书籍等资料较全，工具丰富且生态成熟，遇到问题时能复用他人的解决方案或比较快速地找到懂Oracle的开发者。但随着银行数据量的日益庞大，Oracle的数据处理能力显得捉襟见肘，在做异地多活的时候也显现出了短板，Oracle的全局缓存机制会使A客户的数据跑在A中心，B客户的数据跑在B中心，如果交叉跑会导致性能极大地衰减。另外，硬件投入成本、软件使用成本都在不断增加。可替换数据库谈何容易，李建明所在的银行在数据库选型上陷入两难境地。</p><p></p><p>其实银行真正需要的是一个性能更好且成本更低的数据库，能够灵活地扩容、缩容，在业务量较低时减少节点，在应对交易峰值时增加节点。将对于传统的集中式数据库Oracle，<a href=\"https://pingcap.com/zh/contact-us-now/?utm_source=baidu&amp;utm_medium=cpc&amp;utm_campaign=pccp&amp;utm_term=000013&amp;bd_vid=11423408266213868641\">分布式数据库</a>\"似乎是新的选择方向。</p><p></p><p>从系统角度而言，对比目前市面上优秀的分布式数据库，李建明认为，数据库的架构应该由其本身决定，而不是由上层应用和DBA总关注它的数据分布机制，就这一点，便能够排除一些数据库选项，OceanBase数据库由于其一体化的架构占据了优势。从扩、缩容角度而言，有数据库级、表级、行级的弹性，数据库级别的扩、缩容不够细致，而行级的扩、缩容对于当前业务交易量而言还用不到，因此，表级扩、缩容的OceanBase便是不错的选择，且OceanBase的三地五中心能够做到不丢失数据。从性能角度和成熟案例这两方面来看，经历过大型活动考验的数据库产品，OceanBase较为出众，已经稳定支撑了十年的“双11”活动，并经过支付宝、网商银行等的验证。而且在性能测试时，达到了8000 TPS（每秒事务处理量）。</p><p></p><p>由于云南某银行是在传统的核心系统基础上使用分布式数据库。因此在综合考虑后，认为OceanBase是更适合的选择。参与了此次数据库选型的李建明总结了四点经验：</p><p></p><p>第一，国产数据库当前的产品和技术实力也在逐步提升，可以作为选型考虑的一部分。</p><p></p><p>第二，面对日益庞大的数据量，分布式数据库是较好的选择。</p><p></p><p>第三，选择分布式数据库时，考虑数据库的ACID。</p><p></p><p>第四，考虑对应用的改造程度及兼容度。考虑数据库的性能、体量以及对硬件的兼容度。</p><p></p><h3>给 DBA 的七个成长建议</h3><p></p><p></p><p>在采访的最后，谈及一名优秀的DBA应该具备哪些素质或能力时，李建明根据自己十多年的职场经验，分享了他的看法并给出了七个建议：</p><p></p><p>具备扎实的数据库理论功底。比如数据库系统的概论、数据库的核心概念、分布式数据库原理等，理论能为工作中的实践提供宏观指导。</p><p></p><p>熟悉软件开发基础知识和技术架构。DBA或许不需要写好代码。但如果他不熟悉代码，比如不知道代码怎么写出来的、怎么做负载均衡，怎么连接数据库，以及不清楚常见的框架，那么他可能在排查问题时只会说“我觉得数据库没有问题”，更不能站在全局角度保障系统的稳定性。</p><p></p><p>熟悉操作系统的操作及性能调优。数据库最终还是要跑在操作系统上。对于操作系统的操作熟练度可以通过日常工作积累，而对于性能调优，可以通过阅读官方文档中的说明来掌握，比如了解参数的意义和修改参数会带来的影响，并在日常工作中多动手。</p><p></p><p>熟练的数据库运维操作。尤其要经过高并发、大数据量的洗礼。操作的熟练度更多是靠量的积累。至于能不能碰到高并发场景，由所在企业的业务决定。比如支撑小的业务量的Oracle数据库，很多时候按照默认参数就可以运行得很好。DBA不会遇到较大挑战，顶多是扩展存储空间。因此难以积累这方面的经验。</p><p></p><p>越是难懂的理论，越应该努力掌握。对于众多的技术知识，先做到学会其中一个知识点并达到一定深度后再横向发展，如果你熟悉多项技能，且每项技能只停留在表层，那么你在技术领域很难到达高层次。</p><p></p><p>保持对知识的好奇心，坚持终身学习。对于技术人而言，想学习IT理论可以阅读技术书籍；有针对性地学习系统的实操经验可以用极客时间；学习专业领域的技术知识，可以阅读厂商的官方文档；遇到“疑难杂症”时可以浏览CSDN；对于学科类与常识性的内容，就用得到App；研究强理论、学术型的知识可以翻看论文。</p><p></p><p>培养自己的逆向思维和结构化思考能力。打破思维惯性想象多种可能性，尤其是向两个极端方向去思考。不断问问题，推翻自己的假设并验证新的假设。</p><p></p><p>如果能给年轻时的自己一些建议，李建明表示“吾生有涯而知无涯，要舍得放弃，找到自己最感兴趣或者最擅长的方向，下笨功夫、练就必杀技。还要多学一些跨学科的基本原理，拓宽自我的知识面，提升多维思考能力，并且要勤于思考、有计划的多动手。”与众多数据库从业者共勉。</p><p></p><h4>嘉宾介绍</h4><p></p><p></p><p>李建明</p><p></p><p>目前在云南某银行担任信息科技部运维中心经理。拥有系统分析师、Elasticsearch认证工程师、Kubernetes认证管理员、DevOps Master、Oracle认证专家、OceanBase认证专家等资质。</p>",
    "publish_time": "2022-08-26 15:02:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何使用先验策略有效地初始化强化学习？",
    "url": "https://www.infoq.cn/article/vv20yMM4XN008IhBAV5P",
    "summary": "<p><a href=\"https://www.infoq.cn/article/BKD5NPspBroTswFsLU61\">强化学习</a>\"可以用于训练一种策略，使其能够在试错的情况下来完成任务，但强化学习面临的最大挑战就是，如何在具有艰难探索挑战的环境中从头学习策略。比如，考虑到 <a href=\"https://github.com/aravindr93/hand_dapg/\">adroit manipulation 套件</a>\"中的 door-binary-v0 环境所描述的设置，其中强化学习智能体必须在三维空间中控制一只手来打开放在它前面的门。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/08/01/083fa7a4fca698e42ca8yyb976c51101.gif\" /></p><p></p><p>由于智能体没有收到任何中间奖励，它无法衡量自己离完成任务有多远，所以只能在空间里随机探索，直至门被打开为止。鉴于这项任务所需的时间以及对其进行精准的控制，这种可能性微乎其微。</p><p></p><p>对于这样的任务，我们可以通过使用先验信息来规避对状态空间的随机探索。这种先验信息有助于智能体了解环境的哪些状态是好的，应该进一步探索。</p><p></p><p>我们可以利用离线数据（即由人类演示者、脚本策略或其他强化学习智能体收集的数据），对策略进行训练，并将之用于初始化新的强化学习策略。如果采用神经网络来表达策略，则需要将预训练好的神经网络复制到新的强化学习策略中。这一过程使得新的强化学习策略看起来就像是预训练好的。但是，用这种幼稚的方式来进行新的强化学习通常是行不通的，尤其是基于值的强化学习方法，如下所示。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/f3/a6/f39cc3a3289d3dbyy667f08968957ba6.jpg\" /></p><p>用离线数据在 antmaze-large-diverse-v0 D4RL 环境中对一种策略进行预训练（负向步骤对应预训练）。然后，我们使用该策略来初始化 actor-crittic 的微调（从第 0 步开始的正向步骤），以该预训练的策略作为初始 actor。crittic 是随机初始化的。由于未经训练的 critic 提供了一个糟糕的学习信号，并导致良好的初始策略被遗忘，所以 actor 的性能会立即下降，并且不会恢复。</p><p></p><p>有鉴于此，我们在“跳跃式强化学习”（Jump-Start Reinforcement Learning，JSRL）中，提出了一种可以利用任意一种与现存在的策略对任意一种强化学习算法进行初始化的元算法。</p><p></p><p>JSRL 在学习任务时采用了两种策略：一种是指导策略，另一种是探索策略。探索策略是一种强化学习策略，通过智能体从环境中收集的新经验进行在线训练，而指导策略是一种预先存在的任何形式的策略，在在线训练中不被更新。在这项研究中，我们关注的是指导策略从演示中学习的情景，但也可以使用许多其他类型的指导策略。JSRL 通过滚动指导策略创建了一个学习课程，然后由自我改进的探索策略跟进，其结果是与竞争性的 IL+RL 方法相比较或改进的性能。</p><p></p><h2>JSRL 方法</h2><p></p><p></p><p>指导策略可以采取任何形式：它可以是一种脚本化的策略，一种用于强化学习训练的策略，甚至是一个真人演示者。唯一的要求是，指导策略要合理（也就是优于随机探索），而且可以根据对环境的观察来选择行动。理想情况下，指导策略可以在环境中达到较差或中等的性能，但不能通过额外的微调来进一步改善自己。然后，JSRL 允许我们利用这个指导策略的进展，从而提到它的性能。</p><p></p><p>在训练开始时，我们将指导策略推出一个固定的步骤，使智能体更接近目标状态。然后，探索策略接手，继续在环境中行动以达到这些目标。随着探索策略性能的提高，我们逐渐减少指导策略的步骤，直到探索策略完全接管。这个过程为探索策略创建了一个起始状态的课程，这样在每个课程阶段，它只需要学习达到之前课程阶段的初始状态。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/f9/a0/f9efc5940a8555119a562e7fa0afe7a0.gif\" /></p><p></p><p>这个任务是让机械臂拿起蓝色木块。指导策略可以将机械臂移动到木块上，但不能将其拾起。它控制智能体，直到它抓住木块，然后由探索策略接管，最终学会拿起木块。随着探索策略的改进，指导策略对智能体的控制越来越少。 </p><p></p><h2>与 IL+RL 基线的比较</h2><p></p><p></p><p>由于 JSRL 可以使用先前的策略来初始化强化学习，一个自然的比较是<a href=\"https://arxiv.org/pdf/1811.06711.pdf\">模仿</a>\"和强化学习（IL+RL）方法，该方法在离线数据集上进行训练，然后用新的在线经验对预训练的策略进行微调。我们展示了 JSRL 在 <a href=\"https://github.com/rail-berkeley/d4rl\">D4RL</a>\" 基准任务上与具有竞争力的 IL+RL 方法的比较情况。这些任务包括模拟的机器人控制环境，以及来自人类演示者的离线数据集、计划者和其他学到的策略。在 D4RL 任务中，我们重点关注困难的蚂蚁迷宫和 <a href=\"https://vikashplus.github.io/P_Hand.html\">adroit dexterous manipulation</a>\" 环境。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/75/a6/75a868631292bb6556e2fb43dfe65ca6.jpg\" /></p><p></p><p>对于每个实验，我们在一个离线数据集上进行训练，然后运行在线微调。我们与专门为每个环境设计的算法进行比较，这些算法包括 AWAC、IQL、CQL 和行为克隆。虽然 JSRL 可以与任何初始指导策略或微调算法结合使用，但我们使用我们最强大的基线——IQL，作为预训练的指导和微调。完整的 D4RL 数据集包括每个蚂蚁迷宫任务的一百万个离线转换。每个转换是一个格式序列（S, A, R, S'），它指定了智能体开始时的状态（S），智能体采取的行动（A），智能体收到的奖励（R），以及智能体在采取行动 A 后结束的状态（S'）。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/1a/ec/1acfe8886b2f34aa3720ac94e14986ec.jpg\" /></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/f5/42/f512df76ce3ddf90db60d4d2ef7ecb42.jpg\" /></p><p></p><p>在 D4RL 基准套件的 antmaze-medium-diverse-v0 环境中的平均得分（最大值=100）。即使在有限的离线转换的情况下，JSRL 也可以改进。 </p><p></p><h2>基于视觉的机器人任务</h2><p></p><p></p><p>由于维度的限制，在复杂的任务中使用离线数据特别困难，比如基于视觉的机器人操纵。连续控制动作空间和基于像素的状态空间的高维度，给 IL+RL 方法带来了学习良好策略所需的数据量方面的扩展挑战。为了研究 JSRL 如何适应这种环境，我们重点研究了两个困难的仿生机器人操纵任务：无差别抓取（即，举起任何物体）和实例抓取（即，举起特定的目标物体）。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/f7/c5/f77320102cb18b474d6d575c670373c5.jpg\" /></p><p></p><p>一个仿生机械臂被放置在一张有各种类别物体的桌子前。当机械臂举起任何物体时，对于无差别的抓取任务，会给予稀疏的奖励。对于实例抓取任务，只有在抓取特定的目标物体时，才会给予稀疏的奖励。\n</p><p>我们将 JSRL 与能够扩展到复杂的基于视觉的机器人环境的方法进行比较，如 QT-Opt 和 AW-Opt。每种方法都可以获得相同的成功演示的离线数据集，并被允许运行多达 10 万步的在线微调。</p><p></p><p>在这些实验中，我们使用行为克隆作为指导策略，并将 JSRL 与 QT-Opt 相结合进行微调。QT-Opt+JSRL 的组合比其他所有方法改进得更快，同时获得了最高的成功率。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/c4/ca/c45f1c3a5d56c8806b1f02a19900e7ca.jpg\" /></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/c0/2d/c0dfbd98c54a46ba0b713e6962dac72d.jpg\" /></p><p></p><p>使用 2 千次成功演示，无差别和实例抓取环境的平均抓取成功率。</p><p></p><h2>结语</h2><p></p><p></p><p>我们提出了 JSRL，它是一种利用任何形式的先验策略来改进初始化强化学习任务的探索的方法。我们的算法通过在预先存在的指导策略中滚动，创建了一个学习课程，然后由自我改进的探索策略跟进。探索策略的工作被大大简化，因为它从更接近目标的状态开始探索。随着探索策略的改进，指导策略的影响也随之减弱，从而形成一个完全有能力的强化学习策略。在未来，我们计划将 JSRL 应用于 Sim2Real 等问题，并探索我们如何利用多种指导策略来训练强化学习智能体。</p><p></p><p>原文链接：</p><p>https://ai.googleblog.com/2022/04/efficiently-initializing-reinforcement.html</p>",
    "publish_time": "2022-08-26 16:18:53",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "新浪微博从 Kafka 到 Pulsar 的演变",
    "url": "https://www.infoq.cn/article/ic2tSdHdZ8KKf4u9SsYp",
    "summary": "<p></p><p></p><p>新浪公司是一家服务于中国及全球华人社群的领先网络媒体公司。其业务涵盖新浪媒体、微博和新浪金融。新浪通过门户网站新浪网、新浪移动、新浪财经以及社交媒体平台微博组成的数字媒体网络，帮助广大用户获得专业媒体、机构和个人创作的多媒体内容并与他人进行兴趣分享和社交互动。</p><p></p><p>其中，微博是人们在线创作、分享和发现内容的中国领先社交媒体平台。新浪微博于 2009 年上线，是中国头部、流行的社交媒体平台，提供在线创作、分享和发现优质内容的服务。据微博 2022 年第一季度财报，微博月活跃用户为 5.82 亿，日活跃用户为 2.52 亿，平台日均处理万亿级消息。</p><p></p><p></p><h2>日均万亿消息，Kafka 运维遇挑战</h2><p></p><p></p><p>新浪现有 Kafka 集群主要处理来自新浪新闻、微博等的数据，数据类型包括特征日志、订单数据、广告曝光、埋点 / 监控 / 服务日志等。这些数据经过 Kafka 在线集群、广告专用集群、日志集群、离线集群和机器学习训练等集群的处理后，会用于推荐训练、HDFS 落地、离线数仓、实时监控、数据报表和实时分析等生产目的。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5f/5f8e9be5005e352bcab07fca25b397e6.png\" /></p><p></p><p>新浪在使用和运维 Kafka 集群的过程中，遇到的痛点有：</p><p></p><p>Kafka 运维较困难，突发热点事件时扩容节点无法自动均衡。在高流量峰值场景下，经常遇到了磁盘和 broker 达到瓶颈的情况。Kafka 可以轻松扩容 broker，然而集群扩容时新增 broker 无法自动承载流量，需要较为复杂的人工运维操作。磁盘数据分布不均，topic 分区流量分布不均。随着业务波动，一些承载较大流量的 topic 下线后，其所在 broker 的流量和磁盘数据存储也会下降，类似情况多次发生后 topic 分区流量和磁盘数据分布就会失衡，需要人工干预来 rebalance 流量。迁移分区带来数据移动，容易造成问题。流量 rebalance 需要迁移分区，相当于增加副本，在热点事件爆发、资源紧张时会造成更严重的后果。新浪单集群每日有万亿级以上消息写入，涉及到非常多的业务方与多语言客户端，因此迁移到其他消息队列较为困难。一些重要业务有很多作者不详的重要老代码，源码因故丢失，难以处理、迁移和改造。</p><p></p><p></p><h2>借助 KoP，落地 Pulsar</h2><p></p><p></p><p>团队希望能有一个消息队列可以解决 Kafka 存在的这些问题，同时业务方只需简单修改配置，替换 Kafka 的 broker list 即可迁移。基于这样的背景，团队调研了存算分离架构的 Apache Pulsar，可以很好地解决上述挑战。Pulsar 的 bookie 和 broker 是分离的，而扩容时 bookie 可以自动承接新流量；broker 只承担一些元数据的计算工作，所以需要做 rebalance 时速度很快，无需数据移动。</p><p></p><p>在调研 Pulsar 的过程中团队发现了 KoP 这个开源项目。KoP 是开源项目 Kafka-on-Pulsar 的缩写，Kafka 用户可借助 KoP 插件无缝迁移到 Pulsar，充分利用 Pulsar 的诸多功能特性，以降低迁移成本（GitHub 地址：<a href=\"https://github.com/streamnative/kop%EF%BC%89%E3%80%82KoP\">https://github.com/streamnative/kop）。KoP</a>\" 实质上就是用 Pulsar 提供的 Protocol Handler 机制来对接 Kafka 数据。当 Kafka 集群写入数据时，通过基于 Kafka Protocol Handler 来操作。KoP 复用了 Pulsar 的 topic lookup 机制和抽象的 Managed Ledger 存储层，将数据通过 bookie client 直接发送到 bookie 集群中，如下图：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/00/00c9e393dfb08c770e42e5a664f7b641.png\" /></p><p></p><p>通过 KoP 协议可以落地 Pulsar 并原生支持新浪现有的 Kafka 客户端，也可以解决新浪 Kafka 团队在 Kafka 上的运维痛点。于是团队开始调研和实践 KoP 组件。在此过程中，团队也遇到了一些问题，其中一个主要挑战就是 KoP 低版本兼容性问题。</p><p></p><p></p><h2>部署问题与解决方案</h2><p></p><p></p><p></p><h3>KoP 低版本兼容性问题</h3><p></p><p></p><p>新浪 Kafka 集群中一些较重要的集群仍在使用较老的 Kafka 版本（如 0.10），因此在调研与实践中需要兼容较老版本的客户端。KoP 只支持 1.0 及以后的版本。经过总结，团队发现了以下细节问题并给出对应解决方案。</p><p></p><p></p><h3>低版本认证不兼容</h3><p></p><p></p><p>客户端需要通过认证才可以访问新浪的认证集群，与服务端交互。在 Kafka 1.0 版本之前，客户端与服务端的认证交互是通过 V0 版本的 SaslHandshakeRequest 请求完成的，之后的 token 信息由 SASL tokens（不需要 Kafka request headers）包装，这是一些不透明的数据包。所以团队需要在 KoP 中手动处理这些数据包才能完成认证工作。</p><p></p><p>在 Kafka 1.0 版本之后，认证交互通过 V1 版本的 SaslHandshakeRequest 请求完成，token 信息则由 SaslAuthenticateRequest 请求封装。KoP 处理时会直接解析 token 的协议头。KoP 的低版本认证不兼容问题主要出现在 token 信息这个层面，团队需要通过重构来避免 KoP 直接解析令牌的协议头，从而顺利处理旧版本的不透明数据包。详细代码参见 GitHub。(<a href=\"https://github.com/streamnative/kop/pull/676\">https://github.com/streamnative/kop/pull/676</a>\")。</p><p></p><p></p><h3>日志协议兼容性问题</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7b/7b67ad764cd4702c976c33f2de23a3e6.png\" /></p><p></p><p>以上是 Kafka 消息协议的几个版本示意，从左至右分别为 V0、V1、V2。Kafka 0.10 版本之前使用 V0 版消息协议，0.10 版本改用 V1 版，0.11 之后改用 V2 版。V1 版本相比 V0 版本新增了时间戳；V2 版本改动较大，从 message set 变成了 RecordBatch，后者内部还封装了很多 Record。上图中各个方框内都是协议中的关键字段。V2 版本开始内部消息都使用相对位移，RecordBatch 的元数据部分只需放置起始的绝对位移。</p><p></p><p>于是不同版本之间生产消费时就会存在日志协议兼容性问题。例如一个高版本的生产者生产消息后，低版本的消费者是无法解析新版日志协议的，自然只会报错而无法消费。为此需要引入跨版本消息转换功能，才能让低版本读取高版本的消息。但如果生产者是低版本，消费者是高版本，由于协议是向下兼容的，所以数据消费不会存在问题，不需要转换。</p><p></p><p>那么 KoP 是如何处理生产者请求的呢？Kafka 客户端发来生产者请求时，KoP 解析请求后，Handler 线程会调用 ReplicaManager 主键，追加 Kafka 的 Records。这个主键与 Kafka 中的副本管理器是对应的，做了映射。</p><p></p><p><code lang=\"css\">io.streamnative.pulsar.handlers.kop.storage.ReplicaManager#appendRecords\n</code></p><p></p><p>每个分区对应一个 PartitionLog，映射了 Kafka 里面的 loggingScala 类对应，每一个 KoP broker 中都有一个 PartitionLogManager 来管理 PartitionLog。要将 Kafka Records 处理为消息写入 Bookie，这里的问题就是如何从 Records 编码成 Messages。</p><p></p><p><code lang=\"css\">io.streamnative.pulsar.handlers.kop.storage.PartitionLog#appendRecords\n</code></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/eb/eb92cbf4e0a0372ac665081bd564fc86.png\" /></p><p></p><p>PartitionLog 在追加 Kafka 的 Records 时，会执行 EntryFormatter 的 encode 过程 io.streamnative.pulsar.handlers.kop.format.EntryFormatter#encode。编码之后会通过 Pulsar broker 的 Persistenttopic 组件 org.apache.pulsar.broker.service.persistent.PersistentTopic#publishMessage来 publishMessage。在 EntryFormat 过程中将 Kafka Records 转换为 Pulsar 消息。然后用存储层 ManagedLedger 将消息发布为 Bookie 可识别的 entry 写入 Bookie。这里的关键就是 EntryFormat 编码过程。下图引据了 entryFormat 的官网介绍，可以看到其取值可选 kafka、mixed_kafka 和 pulsar，默认为 Pulsar。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e0/e095f1aa89c189eca328ac8d99581381.png\" /></p><p></p><p>在了解转换过程之前还需了解 Pulsar Message 协议。协议中一部分信息专注于元数据，message payload 字段中包含实际数据，每个 message 中有多条消息，与 RecordBatch 类似。单条消息还有自己的元数据。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/2c/2c39dcda17f696365a1f47952e1ff21b.png\" /></p><p></p><p>从 Kafka 请求转换为 Pulsar 消息要做协议转换。当 entryFormat=kafka（取值为 kafka） 时，主要会设置 publish time、num messages、properties（标识 message 的 entryFormat 类型，解码阶段需要），最后 payload 部分就是将整个 RecordBatch 通过 Persistent Topic 组件发送到 Broker。这里 Pulsar 的客户端无法识别解析 RecordBatch。</p><p></p><p>如果要用 KoP 将 Kafka 集群数据迁移到 Pulsar，就需要用到 entryFormat=pulsar。它会遍历 Kafka 的 RecordBatch 和内部的 Record 信息一一对应设置能够对应的 Message Metadata 和 Single Message Metadata，从而转换为 Pulsar 消息发布到 bookie。</p><p></p><p>要解决兼容性问题就要专注于 EntryFormat，根据生产者和消费者的版本情况进行消息的转换。转换会出现性能损耗，此处注意消费者版本较高时可以将转换过程交给消费者处理来节省性能。</p><p></p><p></p><h2>新特性改进介绍：元数据事件管理器</h2><p></p><p></p><p></p><h3>引入原因一：元数据不一致</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b9/b91e733e772a996769047a8c7bb98371.png\" /></p><p></p><p>上图是一个两节点的 KoP 集群，客户端生产的 topic 的分区 0，位于 broker1 中。客户端的引导地址是 broker1 和 broker2。现在客户端要发送元数据请求给 broker2，broker2 会响应 metadata response。在 KoP 之前的处理逻辑中复用了 Topic lookup 机制，broker2 返回的 response 中不会包含自身的信息，只有分区所在的 broker1 的信息。然后客户端会向 broker1 分区的 leader 节点发送生产者请求。</p><p></p><p>Broker1 挂掉后，分区 0 会容错到 Broker2 上。于是 broker2 成为分区 0 的 owner。这时客户端向 broker1 发送元数据请求失败，又因为自身没有 broker2 的处理逻辑，所以元数据就无法路由到 broker2 上，出现元数据超时问题。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7e/7ea7c4cad9ae406ed54239fda183864b.png\" /></p><p></p><p></p><h3>引入原因二：Group 残留无效 topic 状态</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5b/5b786ee893b421357f20061309b7d116.png\" /></p><p></p><p>如上图，通过 KoP 消费 topic 时，消费的组元数据信息都会记到 coordinator 中，用 ./bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group my-group --describe可以看到描述的消费信息。当 topic 下线并删除时（./bin/kafka-topics.sh --bootstrap-server localhost:9092 —topic test —delete），再去描述组信息就会返回原数据超时异常。因为 admin 客户端执行删除命令时，请求到达 KoP Cluster，KoP broker 会通过 PulsarAdmin 删除 topic。Pulsar Cluster 处理删除请求时，会发送到所有分区的 owner broker 上，后者负责删除 topic 信息并移除 topic。</p><p></p><p>但因为 Group 元数据信息位于 coordinator 中，其 owner broker 和 topic owner broker 不在一起，所以删除后者时无法清除前者，就会出现残留。问题发生原因是 Group Coordinator 里面有 Group 元数据信息记录了消费分区，客户端在获取分区时 commit offset 会记录 Lag 值，Kafka 当前生产的消息位移。之后获取 topic 信息，但是由于 topic 已经删除，因此会一直返回 onload partition 错误。命令工具不断重复尝试获取元数据直到 Request Timeout 超时并暴露超时。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e9/e9bbfd05a1bfe47865cf07834966ef14.png\" /></p><p></p><p>上述问题的核心原因在于 KoP Broker 属于无状态服务，一致性无法得到很好的保障，所以需要引入一个基于 MetadataStore 的元数据事件处理器， 对应的是 Pulsar ZooKeeper。Broker 上线时会触发 Listener 事件，其他 broker 会监听该事件并处理元数据变更。删除 topic 时会触发 topic 删除事件，其他 broker 会响应事件，coordinator 会将对应的元数据信息移除，解决残留问题。</p><p></p><p></p><h2>总结</h2><p></p><p></p><p>本文介绍了新浪微博通过使用 KoP 落地 Pulsar 来解决大规模 Kafka 集群运维的痛点。新浪微博在 KoP 支持 Kafka 0.9 与 0.10 版本客户端，并引入元数据事件管理器解决版本兼容与日志协议兼容的问题。作为 KoP Maintainer，截至目前，沈文兵已给 KoP 提交 42 个 PR，合并 36 个。未来他会继续参与 KoP 的维护和开发工作。</p><p></p><p>目前 KoP 功能日趋完善，Kafka 的大部分功能都已经在 KoP 中得到实现。如果大家在工作中面对 Kafka 运维的痛点，非常推荐大家通过 KoP 组件搭建解决方案。</p><p></p><p>作者简介：</p><p></p><p>沈文兵，新浪微博数据平台研发工程师，主要负责 Kafka 和 Pulsar 的运维研发工作。开源项目爱好者，Apache Pulsar/BookKeeper/Kafka Contributor，KoP（Kafka-on-Pulsar）Maintainer。</p><p></p><p></p>",
    "publish_time": "2022-08-26 16:43:05",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]