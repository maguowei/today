[
  {
    "title": "Spring Boot 3将于2022年11月发布，延迟了对Java模块系统的支持",
    "url": "https://www.infoq.cn/article/5VMP2p3hLyEKpYIILxLr",
    "summary": "<p>在2022 JAX伦敦会议上，来自Spring的高级首席软件工程师Oliver Drotbohm做了一个非常及时的演讲，题目为<a href=\"https://jaxlondon.com/java-core-jvm-languages/spring-boot-3-and-spring-framework-6-a-new-generation\">Spring Boot 3 and Spring Framework 6 – A New Generation</a>\"。Drotbohm分享了Spring Framework 6和Spring Boot 3的预计发布日期，也就是会在2022年的11月底。他还指出，<a href=\"https://www.infoq.com/news/2022/09/spring-boot-migrator/\">最近发布</a>\"的Spring Boot Migrator项目能够将Spring Boot 2.7应用迁移至3.0版本，并能将Spring Boot 2.6应用迁移至2.7版本。迁移至Spring Boot 3是必要的，因为Spring Framework 6使用了Jakarta EE 9，支持jakarta.*<a href=\"https://www.infoq.com/news/2020/10/the-road-to-jakartaee-9/\">包命名空间</a>\"。</p><p></p><p>Drothbohm重申了这些版本的其他支柱性特性，包括使用JDK 17作为新的基线、对Spring Boot中<a href=\"https://www.infoq.com/news/2020/10/the-road-to-jakartaee-9/\">基于GraalVM实现原生Java</a>\"的开箱即用支持，以及基于Micrometer的内置可观测性。SpringOne计划于2022年12月6日至8日举行，该会议将会是成为Spring Framework 6和Spring Boot 3的发布平台。</p><p></p><p>Drotbohm没有讨论在Spring Framework 6中对Java Platform Module System（JPMS）的支持，<a href=\"https://www.infoq.com/news/2021/09/spring-6-spring-boot-3-overhaul\">去年InfoQ曾经首次报道过这个问题</a>\"。他随后向InfoQ证实，Spring Framework 6.0不会提供对JPMS的完整支持，但可能会在后续版本中实现：</p><p></p><p></p><blockquote>Spring Framework 6.0密切关注AOT和GraalVM原生镜像，以优化基于Spring的应用的部署。同时，我们的模块系统计划尚无法构建迁移至完整的JPMS模块描述符。在过去一年中，很少有人提出这样的要求。着眼未来，从长远来看，对应用/框架级别的模块来讲，基于jlink的模块约束方式可能会被基于GraalVM风格的独立可达性分析所取代。也就是说，&nbsp;<a href=\"https://www.infoq.com/news/2022/06/project-leyden-delays-aot\">OpenJDK的Leyden项目</a>\"旨在为其标准化的静态镜像方式重用模块系统的概念和工具，所以对于Spring Framework 6.x来说，更深入的模块系统调整依然是我们长期技术战略的一部分。</blockquote><p></p><p></p><p>作为目前的生产版本，Spring Framework 5.3和Spring Boot 2.7将会获得免费支持，直到2023年5月，在此之后，会提供扩展的商业支持，直到2025年8月。即将推出的Spring Framework 6和Spring Boot 3版本将获得一年的免费支持，直到2023年11月，然后是扩展商业支持，直到2025年2月。</p><p></p><p>Spring Boot 3一年的支持周期保持了与最近的Spring Boot版本相一致。VMware明确表示，Spring Framework用户应该更快升级到6.x版本，这一点InfoQ在去年曾经报道过：</p><p></p><p></p><blockquote>我们强烈鼓励Spring Framework 6用户加入我们的功能发布流，另外，不要期望长期停留在6.0.x版本上，而是希望让6.1、6.2等版本的升级成为常规使用模式的一部分。</blockquote><p></p><p></p><p>其他Java框架的升级速度甚至更快。例如，Quarkus大约每月发布一次<a href=\"https://quarkus.io/blog/tag/release/\">功能更新</a>\"，中间还有缺陷修复版本。</p><p></p><p>Drotbohm还对Spring Framework 6和Spring Boot 3的可观测性提出了新的见解。尽管Spring套件项目会基于Micrometer，但对于开发者来说，可观测性将更多地体现在基础设施层面（如对REST控制器的请求）。</p><p></p><p>Spring目前包括22个项目，支持大量的第三方库。Drotbohm指出，Spring Framework 6和Spring Boot 3在发布时可能不会提供对所有项目和库的原生Java与可观测性支持。未来的Spring版本将对此进行完善。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/10/spring-boot-3-jax-london/\">Spring Boot 3 Ships November 2022, Delays Java Module Support</a>\"</p>",
    "publish_time": "2022-10-19 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "倪光南：用好开源模式，聚焦RISC-V架构",
    "url": "https://www.infoq.cn/article/fAulr19Ues2ECIAEidgC",
    "summary": "<p>近日，中国工程院院士倪光南在《数字世界专刊》撰文指出，一直以来，我国芯片产业在“主流CPU”架构上受制于人，整体生态上与国际先进水平还有很大差距。<a href=\"https://www.infoq.cn/article/x4JNvgz3R55boVWr3ujy\">RISC-V</a>\"精简指令集采用开源模式、其架构先进、易于定制、生态也尚处于发展初期，这为我国万物智联时代掌握芯片产业发展主动权提供了发展机会。</p><p>&nbsp;</p><p>倪光南建议应积极抓住时代机遇，以全球视野谋划我国芯片产业发展，聚焦开源RISC-V架构，统筹规划、集中力量面向我国“主流CPU”领域，筑牢基础软件根基，加速推进其生态建设，推动全世界芯片产业新格局的到来。</p><p>&nbsp;</p><p>在文章中，倪光南分析了目前国内CPU主流技术路线以及开源RISC-V架构的优势。</p><p>&nbsp;</p><p>据其介绍，目前国内市场上存在六七种<a href=\"https://xie.infoq.cn/article/0ef1d7de419b71aa01e25ba03\">CPU架构</a>\"，但这并非长久之计。因为CPU架构具有很强的垄断性，长期以来，占据世界芯片主要市场份额的CPU（或称为“主流CPU”）只有<a href=\"https://www.infoq.cn/article/JjUNd4N551OmoQiV7zM2\">x86</a>\"和ARM两种架构，这种情况大概率还会持续下去。由此可见，目前多种国产CPU架构并存，未来可能会造成资源分散，低水平重复。如果不能及时改变这种状况，若干年后，中国将缺乏能在全球市场上与x86和ARM两家竞争的CPU架构，从而在“主流CPU”方面仍将受制于人。为此，我国发展芯片产业时，要从全球视野谋划和思考国产CPU架构发展的技术路线。</p><p>&nbsp;</p><p>倪光南表示，目前国内CPU技术路线大致有两种思路，值得商榷：</p><p>&nbsp;</p><p></p><blockquote>一种思路是“单打独斗”。“单打独斗”即主要依托本国架构进行发展。其好处是较易实现自主可控，并能满足国内若干应用领域的需求。但要在世界市场上与上述“主流CPU”相抗衡，我国CPU在技术方面，特别是在生态方面还存在着很大的差距，而这种状况不是凭主观愿望在短时期里所能改变的。作为对比，即使是新兴的、挟有众多后发优势的RISC-V架构也历经十多年“折腾”，才取得今天全球范围的繁荣发展。很难设想，一些有历史包袱的、较老的CPU，还能有足够时间和空间，从“主流CPU”激烈竞争的夹缝中脱颖而出。&nbsp;另一种思路是“从众跟随”。即跟着外国的架构走。国内也有企业在基于x86、ARM、Power等外国掌控的架构进行发展，其好处是可以利用已经成熟的生态，但坏处是很难实现自主可控。当前国际环境错综复杂，归根到底随时可能面临ISA（指令集架构）知识产权的制约，难以规避各种制裁和限制。</blockquote><p></p><p>&nbsp;</p><p>倪光南认为，开源RISV-V的出现顺应未来新一代信息技术的需求。RISC-V精简指令集采用开源模式、其架构先进、易于定制、人才培养便捷，研发周期短，大大降低芯片产业门槛，这些都使其后续发展具备强大生命力。</p><p>&nbsp;</p><p>最后，倪光南强调，我国要从战略上用好开源模式，聚焦开源RISC-V架构，充分发挥我国超大规模市场优势和人才优势，统筹推进RISC-V生态建设，与世界开源同行协同努力，最终使RISC-V架构能在世界CPU市场与x86和ARM三足鼎立，通过增加对开源社区贡献的方式逐步将“主流CPU”发展自主权牢牢掌握在自己手中，同时为世界科技创新贡献中国智慧和中国方案。</p>",
    "publish_time": "2022-10-19 10:14:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "观远CTO张进：追求极致，用数据驱动决策变革",
    "url": "https://www.infoq.cn/article/rJgB03Bauu187xi1yubJ",
    "summary": "<p>张进，观远数据联合创始人 &amp;CTO，<a href=\"https://tgo.infoq.cn/join\">TGO 鲲鹏会</a>\" (杭州）学员，拥有十余年数据分析与商业智能行业经验；</p><p>法国 UTC 数据挖掘硕士，曾就职于全球顶尖 BI 公司微策略（MicroStrategy）及蚂蚁金服集团旗下公司支付宝，2016 年作为联合创始人创立观远数据，负责产品研发。</p><p></p><p>1996 年，Gartner 机构对 BI-Business Intelligence（商务智能）重新定义，让<a href=\"https://xie.infoq.cn/article/3a5bb4f98ee38502d2d45cd0a\"> BI </a>\"技术步入全面商用时代。近年来，数字经济加速深化，企业的数字化转型进入深水区。在此背景下,BI 产品作为激活数据资产的便捷工具开始受到广泛关注。</p><p></p><p>2016 年，算法、<a href=\"https://www.infoq.cn/video/Yxq6QiXCKgp4Q4l8vL7O\">算力</a>\"、大数据浪潮三合一，形成了确定性的技术变革。伴随着科技洪流，观远数据正式成立。提及当初的创业决定，张进坦言并没有过多犹豫。张进与观远 CEO 苏春园相识十余年，二人不仅是工作中伙伴，更是生活上的朋友。「Chase（苏春园）是我早年毕业后，乃至现在持续的 mentor，所以只要他决定创业，我义无反顾。」在公司中，苏春园负责公司战略方向的制定，就像一艘大船的总舵手，引领航向；张进作为 CTO 则会结合自己在产品和技术方面的思考与观察，给到决策建议。</p><p></p><p>回望六年，我国商业智能软件市场规模迅猛增长，BI 逐渐成为现代企业信息化、数字化转型中的重要组成部分与催化剂。观远数据的一站式智能分析平台也经历层层迭代，不断向全面化、系统化发展。作为行业亲历者，张进也始终坚持思考与总结的习惯。</p><p></p><p></p><h1>极致追求，洞察用户价值</h1><p></p><p></p><p>在近六年的创业历程中，张进保持着“流水不争先，争的是滔滔不绝”的心态。取得成就并不自傲，因为在他眼中，很多成就的取得是团队或客户给到的灵感，功劳属于大家。创业维艰，碰到挫折和挑战时，拓宽眼界与视角也能够提升心理阈值。「一两天的情绪低落很正常，但不要把自己击垮。我曾在许多经典书籍中看到前辈们的鲜活案例与方法，某些阶段势必会经历颠簸，因此也就少了几分焦虑，在坎坷中积蓄力量，尽快走出来，向前看。」</p><p></p><p>工作日趋繁忙，张进认为不存在所谓“work life balance”的状态，更重要的是把握好每段时间的质量。他保持着阅读和学习的习惯，并总结了自己的一套方法和规律。在他看来，最核心的一点在于不要盲目学习，要带着问题出发，进行主题阅读，系统归因。虽然行业和技术发展很快，但很多问题背后的本质和底层逻辑是亘古不变的。企业大都在关注未来世界可能会发生的变化，但在做整体战略设计时，往往需要关注未来 10 年、20 年，不变的是什么，这个“不变”才能成为公司的战略锚点。例如在数据分析 BI 领域，客户会不断追求效率更高的操作体验，在数据量很大的情况下持续快速响应，在高并发状态下实现存储和底层架构良好适配，维持高性能、高稳定。这在过去乃至未来几十年，都是始终不变的。</p><p></p><p>作为产品技术人，张进始终将乔布斯奉为自己的精神导师和学习的榜样，乔布斯对于极致用户体验的产品追求，也给了张进许多鼓舞与启发。谈及最近正在阅读的一本书《Build》，其作者正是乔布斯的工作伙伴——iPod 之父 Tony Fadell。书中的许多观点，包括如何构建好的团队、是否持续怀有打造极致产品的初心、产品思考策略与挑战等，都给张进带来了很大启发。</p><p></p><p>作为 CTO，张进主要负责产品创新和技术研发两大板块，包括产品方向、市场策略，以及底层技术的使用和落地。他现在还保持着“走出去，和客户深入聊”的习惯，因为只有这样，才能真正知道客户想什么，要什么。创业之初，张进和苏春园共同拜访潜在客户，面对对方公司的 CEO 和业务高管，当时的“窘境”令张进记忆犹新。「客户提出的大多问题都是真实的场景和需求，当时我的认知里几乎只有技术相关，不知如何开口，所以只能坐在旁边点头微笑，心里干着急。所以结束后我也蛮沮丧，明明知道技术优势与特点，但真正碰到客户场景，却不能把自己的产品讲明白。」在 ToB 领域，采购负责人也许并不是真正使用产品的人，却要为产品买单，所以需要在交流中洞察企业的背后逻辑。此后，张进便抓住一切机会和客户交流，根据每次遇到的问题思考迭代，不断提升自己的表达和翻译技术的能力。</p><p></p><p>在观远，张进也提倡产品与技术人员多接触真实业务场景，不要闭门造车。「研究纯技术的时间比例要控制在 20% 以内，80% 的时间应该是主动跟客户交流。」张进认为，技术人应该以实现伟大的产品为目标，而不是抱着新技术自嗨。「最近在极客时间上看完了毕大师的访谈，他也提到了技术人最大的问题，就是比较容易陷入技术情怀。对于 ToB 领域，客户往往关注的是产品能否在成本最低的情况下解决所遇到的问题，而不是使用了哪些高新技术，所以本质一定要解决客户痛点。」</p><p></p><p></p><h1>大道至简，让业务用起来</h1><p></p><p></p><p>企业对数据驱动决策的需求促使了 BI 的诞生，支撑管理决策也就成了 BI 最核心的目的。人们对数据的需求层层递进，从数字本身，到可视化展现，再到交互式分析，接下来就要结合预测能力在若干种不同方案中进行权衡和取舍。</p><p></p><p>在传统 BI 时代，企业级数据更多是 IT 强管控，将汇总的数据制作成报表，层层下发给一线经理。这时巨大的挑战在于业务团队的逻辑和 IT 团队会大有不同，例如业务部门主要关注的同比、环比、MTD 等指标，IT 团队翻译成技术语言就是一个窗口函数。但数字背后是业务实际遇到的问题或者需要追踪的业务状况，所以二者之间会有隐形的知识鸿沟，数据仓库也无法满足不断变化的业务需求。这时面向业务的 BI 应运而生。业务用户可以自助加工数据，快速分析，过程中无需技术人员长期参与，大大缩短了业务用户与数据之间的距离。</p><p></p><p>发展至今，智能 BI 时代已来。从刚开始的专业人士操作的报表，到复杂度降低的适用于分析师的敏捷 BI，再到进一步拉低门槛的面向所有业务用户的智能 BI，都需要依靠强大的基础设施和底层技术。业务一线往往利用数据可以更好地解决业务问题，但无法投入大量时间学习面向分析师的复杂 BI 产品，因此易用性也正是观远的产品理念和优势之一。「在客户进行产品选型时，尽管是没有技术和分析师背景的业务人员，也能在半天内完全上手。这种快速的价值呈现，真正实现了让业务用起来，用数据赋能企业。」</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1f/1f6a0023323e9e4637220fb918f7a862.png\" /></p><p></p><p>中国的移动端渗透率居全球首位，Mobile BI 也是观远产品中的重要组成部分。传统的 Mobile BI 大多采用原生 APP 开发，周期较长；或用代码制作 HTML 页面形式嵌入，配置较复杂。观远数据识别到这个痛点后，做出了和龙头 OA（钉钉、企业微信、飞书） 融合的移动轻应用。利用拖拽式的方法快速制作移动数据应用，进而分发给广泛的一线业务用户。张进也分享道，在曾经的客户回访中，有位业务用户一天内制作并分发了 20 个移动轻应用，相比之前两周才能做一个应用，效率数倍提升，有效帮助各业务部门快速找到问题、解决问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7c/7c274018905239564ee08ead3a356f68.jpeg\" /></p><p></p><p>企业级架构是观远 BI 的第二大优势。云原生时代，产品背后的架构能否适配大数据基建，显得尤为重要。观远数据利用<a href=\"https://mp.weixin.qq.com/s?__biz=MzI5ODQ2MzI3NQ==&amp;mid=2247502489&amp;idx=1&amp;sn=099b6e0026d3af8135648dec3a0957d3&amp;chksm=eca7f3dddbd07acb6cc66bfa6097825af69dc726f2a616be28b02740f4c9e9b635dc36905b91&amp;scene=27#wechat_redirect\"> K8s</a>\"、容器化编排的整套体系，能够将 BI 融合到企业本身的底层基建体系内，解决复杂的企业问题。「观远一定是在这个层面做得最顺畅的服务商。」张进自信地表示。</p><p></p><p>场景化也是观远 BI 的优势之一。AI 是先进生产力，需要叠加某个行业或场景才能真正落地。例如零售消费领域的门店智能配补货，消费品领域的智能需求预测，银行业的 AI 增强化平衡计分卡等，和现实场景的强绑定，与 BI 相结合才能不断挖掘企业数据的价值。面向不同角色、不同业务关键场景的分析实践，能够帮助企业快速落地业务所需的数据应用，解决实际问题。</p><p></p><p>大势所趋，许多企业正在经历数字化转型的“爬坡阶段”。作为数字化服务企业，能够利用数字化产品贴合用户不同诉求，让产能效率更高，为企业持续赋能，是观远所关注的。在观远服务的客户中，一家水果零售企业的管理效率令张进很有感触。</p><p></p><p>「一款新品水果上市后，各门店销量数据实时回传，总部根据数据甄别，发现有一个门店销量很高。于是马上安排人员到店走访，发现他们果肉切口的露出比其他门店大了 30%，从视觉上就会提高顾客的购买欲。商品部则马上进行摆台 SOP 的迭代，从而使得所有门店的销量得到连带提升。」数据不会说谎，数字化会让业务由人力驱动转为数据驱动，使企业更高频地追踪优化点，从而实现降本增效。</p><p></p><p>在张进深耕 To B 市场多年的经验总结中，企业对于产品的选择往往是效果&gt;效率&gt;体验。企业是一个军队、一个营利性组织，要在市场上拼杀取得成果，盈利效果一定是放在首位，其次是产品帮助企业的运作效率提升，最后是和效果、效率等无关的 nice-to-have 体验。这也是 ToB 和 ToC 产品有较大区别的部分。</p><p></p><p>传统软件的售卖方式大多只卖产品、授权费和维保，但以 Salesforce 为首推出的订阅制方式已成为主流。把选择权交给客户，这就会倒逼软件公司不断迭代，秉承客户价值第一的理念，为科技的全生命旅程负责。所以观远数据建立了客户成功体系，用持续运营的思维关注企业，利用云巡检的方法，不仅关注 CPU 内存、负载、磁盘等技术指标数据，更关注行为数据，帮助企业发掘没有被很好利用的数据资产，使业务用户体会到产品价值，陪伴企业长期发展。</p><p></p><p>六年来，观远数据每年都会在进行产品的功能迭代，“Simplicity is the ultimate sophistication”。「不是每次更新都要叠加几十、上百个功能，更多的是对于同样的场景和客户痛点，有没有更便捷高效的解决方案。甚至在某个阶段我们会砍掉某些功能模块，做加法是容易的，做减法更难。」</p><p></p><p></p><h1>从数据中找答案</h1><p></p><p></p><p>虽然“啤酒尿布”的神话将 BI 送入主流视野，但从国际市场来看，其渗透率只有 30%，我国更是个位数。张进认为，如果能让 70%-80% 的业务由数据来决策，让关注数据成为工作习惯，就能真正实现赋能企业，让用户实现更高质量的决策与分析。「BI 只是眼下的符号或标签，我们还是要追随客户的价值和痛点，不断思考分析与决策链路中的潜在机会点，匹配需求的刚性与技术的成熟度。」</p><p></p><p>谈及 BI 行业未来的发展趋势与展望，张进认为，「BI 只是一个符号，企业的核心需求是分析与决策。所以未来的智能分析与决策平台会完整覆盖从战略层到运营层，打通数据决策全链路，观远正为之努力。」首先是决策助手，对于战略决策领域，在信息不完备、方向模糊的情况下，利用故事陈述、交互问答等方式辅助管理层进行决策。第二种场景是沉浸分析，在战术类决策领域，利用仿真测算、AI 增强分析等技术，在人机协同决策时可以让效率变得更高。最后，对于执行层面的决策，在信息完备、领域知识清晰的情况下，很多企业级决策则可以全部交由机器人完成，当然背后也需要图谱技术、推理引擎等支撑。</p><p></p><p>10 月 25-26 日，观远数据将举办主题为”让业务用起来“的智能决策峰会暨产品发布会，全新的“云上直播”模式，20+ 重磅嘉宾，2 天 4 场不间断持续输出深度干货内容。张进也将从行业经验及技术趋势角度带来分享，并正式发布智能分析平台 5.0 版本，进一步推进场景化，让企业共享数据价值与创新实践。</p><p></p><p>道阻且长，行则将至。怀着“追求极致用户体验，打造真正有价值的产品”初心的张进，致力于带领观远与 BI 行业共生，利用技术能力与深度洞察，实现价值增长。</p><p></p><p></p><h1>关于 TGO 鲲鹏会</h1><p></p><p></p><p>TGO 鲲鹏会是极客邦旗下科技领导者聚集和交流的组织，学员由 CTO、架构师、技术 VP、具有技术背景的 CEO 等组成，目前已经在北京、上海、深圳、广州、杭州、成都、硅谷、南京、台北、厦门、武汉、苏州等 12 个城市定期举办学习活动。</p><p>TGO 鲲鹏会采用了“学员共建”的组织形式，希望通过“共建、自治”的方式维护各城市的健康发展，为学员提供必要的服务，帮助学员个人更好地学习和成长，助力学员企业之间更好地合作与交流。加入 TGO 鲲鹏会，全方位提升自身价值，成为卓越科技领导者！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4c/4c5129d041d7023b2c328ccaa1b96277.png\" /></p><p></p>",
    "publish_time": "2022-10-19 11:48:07",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "探寻技术之美，云上如何自由构建",
    "url": "https://www.infoq.cn/article/sg5kFlsPyTzrCt2CXCEr",
    "summary": "<p>谈及技术，人们很少将其与美感联系在一起，而一旦这么做，神奇的事情就发生了......</p><p></p><p>最早在技术与美感之间建立连接的是《计算机程序设计艺术》一书的作者高德纳 (Donald Knuth)，他发现技术和艺术存在共同之处。他说：“计算机编程是一门艺术……一个潜意识地将自己视为艺术家的程序员会喜欢他所做的事情，并且会做得更好。”</p><p></p><p>在近期举办的“亚马逊云科技中国峰会”的 DEV DAY 上，我们再次领略了云时代的技术之美。作为技术构建的基础平台，计算机硬件与软件的发展历程也是通过抽象追求技术之美的历程。这其中包含了如何让开发变得更加简单和高效的内在逻辑，以及自由构建的要素和方法，相信能带给开发者们一些全新的启发。</p><p></p><p></p><h2>始于抽象，如何理解技术之美</h2><p></p><p></p><p>高德纳在《计算机程序设计艺术》中曾提到，程序员的心理特征主要是具备在不同的抽象层次之间转换的能力，从低层到高层，能看小的细节，也能看大的整体。可见，抽象是开发者需要具备的关键能力。</p><p>该如何定义抽象？UCCA 尤伦斯当代艺术中心副馆长、UCCA 集团艺术总监尤洋尝试用三个关键词去涵盖抽象。第一，上下文（Context），抽象源自某种渊源，离不开历史追溯的上下文；第二，技术（Technical），艺术家在创作抽象作品时候，如果关注科技，没有科学技术、计算机技术的支持，很难完成作品；第三，共构（Symbiosis），抽象离不开观众，在艺术家构思的路径之中，会影射作为观众的我们。</p><p></p><p>重新回到技术领域，不难发现艺术与技术有关抽象上的共通之处。<a href=\"https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247568591&amp;idx=2&amp;sn=ca14b392d884f73f7379e539e18c1d46&amp;chksm=fbeb7500cc9cfc16050268fbe68f2e29f722c83af6b70f24978f18f2f1cd8a26b2f70c9a5ce9&amp;scene=27#wechat_redirect\">编程语言</a>\"的发展就是通过不断抽象实现技术之美的有效例证。</p><p></p><p>八十年代，C 语言得到长足应用和发展，支持了大多数操作系统的编写，而操作系统是我们得以持续抽象的重要基础。九十年代，互联网日新月异，由于需要更高层次的抽象，大批围绕 Web 的解释性高级语言涌现。移动互联网时代，GO 语言、Rust 语言以及针对大数据、机器学习的一大批新语言出现，更简洁和更高效成为现阶段编程语言的目标。</p><p></p><p>不过本质上看，编程语言仍是开发者改变世界的表达方式，抽象让这种表达更加精准和具象。2008 年图灵奖得主 Barbara Liskov 提出，我们希望从一个抽象中得到的是一种机制，它允许表达相关的细节和抑制不相关的细节。在面向对象的编程理念成为共识后，Liskov 的研究涉足了网络计算，专注表达方式的抽象。此时的 Liskov 一定没有想到，表达对象本身即将经历翻天覆地的变化。</p><p></p><p></p><h2>云原生时代的开发革命，亚马逊云科技做对了什么？</h2><p></p><p></p><p>从局域网，到互联网，再到云时代。随着摩尔定律大行其道，产业浪潮一浪高过一浪，业务节奏越来越快，开发者表达的对象逐步变成了云上的基础设施。这时，复杂、繁琐、笨重，在更高的维度上再次涌现。</p><p></p><p></p><h4>建立更简单、更自由、更高效的云上世界</h4><p></p><p></p><p>2006 年 3 月 14 日，亚马逊云科技（Amazon Web Services）的第一款产品对象存储 Amazon S3应运而生，同年还发布了虚拟主机服务 Amazon EC2、和消息队列服务 SQS。这就把存储、计算、中间件抽象成为网络服务，以 API 的方式提供给开发者，通过全球分布式的架构，为开发者提供了按需获取资源的基础平台，这样的平台后来被称为“云”。</p><p></p><p>后来，亚马逊云科技通过不断对虚拟机、容器、无服务器抽象，简化底层复杂性，减少基础设施的感知和适配工作。</p><p></p><p>2011 年，亚马逊云科技发布 Amazon ElasticBeanstalk，实现了自动化部署负载均衡、虚拟机实例以及数据库实例，隐藏了底层集群的复杂度。随着软件的抽象层次不断提高，架构构建的方式也在发生很大的改变——容器化已经成为云端构建的主流。2014 年亚马逊云科技发布了容器服务&nbsp; Amazon ECS。当时，Kubernetes 还没有大行其道，亚马逊云科技选择自己构建框架来管理 Docker 容器；后来，Kubernetes 逐步成熟稳定，并成为很多客户管理容器的首选，亚马逊云科技拥抱开源社区，发布了托管的 Kubernetes 服务<a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651031261&amp;idx=3&amp;sn=482ff41821695e946e4b21fb34608be3&amp;chksm=bdbe7e8e8ac9f7980ecd969fa9ab9cf6bcded26b7ad034168963f2afcb7516b882f83f8944d0&amp;scene=27#wechat_redirect\"> Amazon&nbsp; EKS</a>\"；2017年发布的Amazon Fargate更进一步，完全托管了运行容器集群的服务器节点，提供基于容器颗粒度的按需部署和自动扩展的能力，让用户关注的计算单元完全抽象到容器层级。</p><p></p><p>除了 Amazon ECS 的发布外，2014 年还有另一款服务的发布也引发了技术圈的无数关注，它就是 Amazon Lambda。事实证明，亚马逊云科技对 <a href=\"https://www.infoq.cn/article/MLKyYvB6dhjMeMB9WZtj\">Serverless </a>\"的投入及预判没有错。如今，无服务器计算已成为云原生时代的共识，大幅提升了云原生的技术美感。</p><p></p><p>Mobvista 技术副总裁 &amp; 首席架构师、亚马逊云科技 Data Hero 蔡超提到，他们在集团的游戏数据分析统计系统上选择迁移到了无服务器架构，利用 Amazon Lambda 简化了开发，提高了迭代速度，并将维护成本降低了 50% 。</p><p></p><p>经过 16 年的发展，亚马逊云科技的服务从 3 个增长到了 200 多个。在技术抽象和发展的历程中，蕴含着与艺术非常类似的逻辑——基于真实的需求进行构建。即使计算环境不断抽象，开发者依旧需要管理数据库、大数据、机器学习等诸多服务类别，解决资源生命周期各个环节的自动化。资源管理代码应运而生。</p><p></p><p>亚马逊云科技的服务都提供 Restful API。2011 年亚马逊云科技发布 Amazon CloudFormation，支持客户用声明格式的 JSON 代码来描述云上资源，后来又支持 YAML 格式。至 2019 年，亚马逊云科技陆续发布了命令行、IDE 工具、SDK 进一步抽象了 API 操作，让开发者可以使用更熟悉的 Shell 脚本、IDE 集成开发环境以及编程语言来管理云上资源，并重磅发布 Amazon CDK，让开发者可以使用命令式的编程方式去编写管理代码。去年，亚马逊云科技发布 Amazon Cloud Control API，让开发者采用自定义 API 的方式灵活管理亚马逊云科技和合作伙伴的第三方服务。值得一提的是，Amazon CDK 的出现如同面向对象在资源管理领域的重生，带来了巨大的效率提升，具有里程碑的意义。至此，对于云资源管理的编程友好达到全新的高度，而不断抽象的成就是技术之美在云资源管理旅程最好的体现。</p><p></p><p></p><h4>用技术之美成就自由构建</h4><p></p><p></p><p>云原生时代，亚马逊云科技通过不断抽象，探索出技术之美的实现路径。然而，技术之美在未来又该如何帮助开发者更自由、便捷地构建自己的业务系统呢？亚马逊云科技大中华区解决方案架构部总监代闻将其归结为架构典范之美、组件抽象之美、流程灵动之美三个方面。</p><p></p><p>关于架构之美，以亚马逊电商为例。2001 年之前，亚马逊电商采用的是单体式架构，在业务增长的过程中，单体式架构很快遇到瓶颈。2002 年亚马逊开始着手微服务架构改造，涉及技术、流程、组织等多个方面。截至 2020 年，亚马逊电商内部已有 10 万微服务运行。随着微服务的兴起，领域驱动设计驱动设计（Domain-Driven Design ）中相关的模块化服务设计方法论六边形架构得到了广泛的应用。在这个架构设计中任何一个服务的代码逻辑都面向特定领域，对外提供服务端接口。在去年的 re:Invent 上，亚马逊的 CTO Werner Vogels 也分享了亚马逊设计 API 的六条最佳实践。</p><p></p><p>API 永远存在永远不要破坏向后兼容性从客户场景出发，逆向工作创建具有显式有据可查故障模式的 API创建服务于明确目标的自描述 API不惜一切代价避免泄露实现细节</p><p></p><p>如今，云原生应用的架构充分利用按需交付、全球部署、弹性和更高级别的云服务，大大提高了开发人员的工作效率、业务敏捷性、可扩展性、可用性、资源利用率和成本优化。代闻认为，云原生是一个相对的概念，因为云服务本身就在不断演进中。在一个时间点上，如何选用合适的组件，就成为云原生架构落地最基础的一步。</p><p></p><p>亚马逊云科技经过多年发展，在虚拟机、容器、无服务器三个层面都提供了相应的服务支撑，在这三个抽象层次的计算能力也渗透到了各个服务类别中。如今，开发者不仅可以选择应用代码所在的运行环境的抽象层级，还可以根据业务场景选择需要调用的云资源的抽象层级，让不同抽象层级的应用代码和云服务彼此之间无任何阻碍地互相调用，从而真正实现自由构建。</p><p></p><p>有了好的架构、适合的组件，灵动的开发流程让应用得以顺利落地。代闻表示，在构建阶段，快速搭建和验证架构，快速交付 MVP 是非常重要的；治理阶段的关键在于，如果保持良好的可观测性，从而管理数据并且适时的应用安全策略；在应用落地之后，进入到持续的迭代阶段，自动化的部署、更多的组件服务化，以及运维的自动化和智能化转变为核心。在整个历程中，亚马逊云科技提供了一系列的服务和工具，帮助开发者灵活、动态地实现开发流程，让技术之美不止停留在探讨和设计阶段，而是贯穿应用的整个生命周期。</p><p></p><p></p><h2>面向未来，携手开发者共同成长</h2><p></p><p></p><p>技术抽象与自由构建让软件开发变得更加方便，开源让技术能力得以普及。如今的现代化应用程序中，我们大量地采用开源服务，亚马逊云科技近年来也在持续通过托管的开源服务加速企业在现代化应用程序上的构建和运营。</p><p></p><p>“我们开源的三大支柱实际上是来自于社区、代码和文化。本身亚马逊的这种文化实际上给了开源社区非常多的指导，我们的员工、用户，也不断地在社区里头去贡献出来他们自己的代码，把他们的一些经验和实践，变成了共享的资源，能够去加速其他客户的迭代和更新。”亚马逊云科技的现代化应用服务产品总监陈展凌表示。可见，开发者社区建设是亚马逊云科技一直以来非常关注的事情。</p><p></p><p>10 月 14 日的 DEV DAY 上，亚马逊云科技也上线了面向中国的亚马逊云科技开发者官网，定位世界级的开发者社区，为国内开发者链接全球资源，帮助国内开发者的内容走向全球。</p><p></p><p>那么，什么才是一个成功的开发者社区？在亚马逊云科技 Community Builder、Juniper 中国区创新事业部资深架构师范桂飓看来，开发者社区是一个有清晰定位、有客户画像、能够解决客户痛点需求的平台型产品，因此，一个成功的开发者社区就需要找准定位，在服务开发者的过程中具有“Serve it and deserve it”的精神。亚马逊云科技 User Group Leader、永乐拾光创始人李欣表示，一个成功的开发者社区是一个专业的、开放的、包容的，能够帮助开发者实现个人价值的平台。从开发者社区对于技术公司的价值维度，亚马逊云科技 Hero、SphereEx 联合创始人 &amp; CTO 潘娟认为，开发者社区是一个公司产品直接沟通开发者的重要渠道，社区内的良性反馈能够帮助公司厘清产品定位，建立技术品牌，帮助公司吸纳贤才。</p><p></p><p>行业发展早期，一些头部公司通过开发者社区的建设也推动了技术的落地。亚马逊云科技资深开发者运营专家郭悦认为，开发者社区的建设，让这些头部公司有了头雁效应，不仅担起了企业责任还提升了品牌形象。“一个技术公司，通过开发者社区，能够把产品与人，公司与人交流的这种行为，变成了人与人交流的一种行为，我觉得这会让一个技术公司看起来更有温度。”</p><p></p><p>一个重视开发者真正诉求的开发者社区才能拥有长久的生命力。那么，开发者社区怎么高效服务开发者？Zilliz 合伙人兼技术总监、LF AI &amp; Data 基金会技术咨询委员会成员栾小凡看来，首先要有很好的服务体验；其次要有足够多优质的内容，并能够帮助建立开发者之间的联系；最后要通过规则激励 UGC 内容的产生，让有潜力的开发者留在社区里，真正成为社区生态的一部分。潘娟则认为，本土化是开发者社区需要关注的事情之一。据她观察，国外的开发者更加注重自身开源经历的打造，将此看作自身的素质能力，国内开发者参与开源课题更多是兴趣使然。在潘娟看来，做好本土化的文化建设，能更加柔和地吸引开发者到社区当中。</p><p></p><p>亚马逊云科技中国开发者网站优先思考的正是本土化、全球性和开放性。其设计包含专栏、视频、问答、社区、活动、大赛六大核心板块，面向不同职业技能阶段的开发者设计不同的形式或内容呈现。一方面，亚马逊云科技全球的客户案例和开发者的分享，都将在亚马逊云科技开发者官网翻译分享给中国的开发者；另一方面，亚马逊云科技在官网上吸纳了很多海外技术大咖，加入社区进行本土化的内容创作。此外，亚马逊云科技鼓励开发者主动运营社区，希望通过双向互动让社区更加活跃、更加健康。毕竟，一个开源开放的社区，才会更有生命力。</p><p></p><p>开发者群体在亚马逊云科技眼中有着特殊的分量。DEV DAY 也始终以开发者为中心。今年是 DEV DAY 植根中国的第七年，亚马逊云科技创新地以技术之美为主题，带领大家探索云时代的开发规律，并分享前沿技术和云上最佳实践，帮助开发者更好地了解云计算，沉浸式地体验云计算技术的魅力。</p><p></p><p><a href=\"https://dev.amazoncloud.cn/\">亚马逊云科技中国开发者网站</a>\"</p>",
    "publish_time": "2022-10-19 13:50:01",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "只需10美元，AI就能“复活”已故亲人",
    "url": "https://www.infoq.cn/article/exy7ANYQwFEAixcJHrgK",
    "summary": "<p></p><blockquote>AI 让已故的亲人、朋友可以换种方式陪在自己身边，但，这真的是个好选择吗？</blockquote><p></p><p></p><p>去年，美国男子 Joshua Barbeau 用 AI “复活”已故未婚妻的故事感动了无数人，但这件事本身也伴随着不小的争议。</p><p></p><p>据英国《镜报》报道，2012 年，Barbeau 的未婚妻 Jessica Pereira 因肝病去世。8 年后，Barbeau 偶然发现了一个名为 Project December 的网站，该网站可以使用 AI 生成<a href=\"https://www.infoq.cn/article/an-interactive-history-of-chatbots\">聊天机器人</a>\"，用户只需上传一些旧短信样本，聊天机器人就能模仿其写作风格。</p><p></p><p>于是，思念亡故未婚妻过度的 Barbeau 提供了未婚妻的聊天记录和 Facebook 信息，并将机器人命名为未婚妻的名字“Jessica”，开始和其聊天。机器人能够精准地模仿 Jessica 的语气和风格，这让 Barbeau 觉得自己是真的在和已故未婚妻聊天。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/52/528ab5a10f4454093e4688eb1cbb2387.png\" /></p><p></p><p>这段历经十年但最终有缘无份的感情在 AI 上得以延续，一经报道感动了无数人，甚至有报道称环球电视已经买下这个故事，打算制作独家电视剧集。同时，也有越来越多的用户涌向 Project December 网站，期望模拟已故之人，打造属于自己的聊天机器人。</p><p></p><p>据了解，Project December 网站依托于 <a href=\"https://www.infoq.cn/article/mfxhTz8IAtav8CN4oYLR\">OpenAI </a>\"的 <a href=\"https://www.infoq.cn/article/9cb21vxX8tfDP3Kk6yqw\">GPT-3</a>\"，由独立游戏制作人 Jason Rohrer 创建。他原本打算让用户花上 5 美元来感受一下跟虚拟对象交谈是什么体验，在 Barbeau 的故事传开之前，他从来没想到人们会用 Project Decembe 来模拟已故之人。</p><p></p><p>同时，用 AI 模拟已故之人这件事本身也引发了巨大的争议，并引发了 OpenAI 的担忧。</p><p></p><p>OpenAI 方面认为 Project December 存在一定隐患：聊天机器人可能会被滥用或对人们造成伤害。对此，OpenAI 在去年与 Jason Rohrer 进行了视频会议，但效果并不理想。</p><p></p><h2>可以“复活”已故之人的Project December重新启动</h2><p></p><p></p><p>2021 年 9 月 1 日，OpenAI 给 Jason Rohrer 下了最终“判决”：“我们将在 9 月 2 日上午 10 点终止您的 APl 访问。”这意味着，Project December 网站将无法继续创建聊天机器人。</p><p></p><p>而近日，Project December 宣布重新启动，专门作为与逝者重新联络的工具。用户可以花 10 美元来创建聊天机器人，找回当初那种熟络的交流感觉。</p><p></p><p>Jason Rohrer 在采访中表示，“在听到 Barbeau 的故事之后，我发现Project December 社区中出现了大量同样的诉求，所以我决定为这样一个特定目标而服务。我想为大家打造更好的成果，希望他们能够从中得到所需的帮助。”“构建这样一种前沿、疯狂甚至颇有科幻色彩的东西确实非常有趣。作为创作者，这对我个人来说也很有吸引力。”</p><p></p><p>据了解，用户要想使用 Project December 为已故之人创建聊天机器人，需要填写一份关于想要模拟和交谈者的问卷，并提供对方的姓名、年龄和爱好，外加具体记忆和事实。Project December 会利用这些信息让整个对话更具个性，进而提升聊天机器人的可信度。</p><p></p><p>值得一提的是，由于 OpenAI 出于安全考虑关闭了 Jason Rohrer 的开发者账户，因此他没法继续使用 GPT-3 自然语言模型，而是采用了 Al21 Lab 语言模型支持。</p><p></p><h2>用 AI 模拟逝者，好坏参半</h2><p></p><p></p><p>事实上，用 AI 模拟逝者并不是什么新鲜事，早在 2017 年，微软就为一种利用 AI“复活”逝者的聊天机器人申请了专利。很多初创公司也已经在这一方向上发力，比如 Replika 和 HereAfter AI，前者是一款能够与人聊天的 AI 机器人，后者则记录人们的生活故事，并用这些故事创建一个嵌入智能音箱的人类“复制品”。</p><p></p><p>亚马逊的个人数字助手 Alexa 也能模仿人们的声音，在在今年夏季 re:MARS 大会上播放的一段视频中，有个孩子问：“Alexa，能像奶奶那样给我讲《绿野仙踪》的故事吗？”于是机器就开始以奶奶的语音语调讲起故事来。</p><p></p><p>此外，还有 AI 工具如 <a href=\"https://www.infoq.cn/article/XV44AZfQf8f5PJjMms4f\">Deep Nostalgia</a>\" 等会根据逝者过去的照片制作动画，让人物眨眼、微笑。</p><p></p><p>在技术上，用 AI 模拟逝者不是难事，但在伦理上，这种形式还存在一定的<a href=\"https://www.theregister.com/2022/10/15/would_you_pay_10_to/\">争议</a>\"。</p><p></p><p>比如，有人认为，让已故的人眨眼和微笑多少有点诡异。对此，照片软件 MyHeritage 在官方公告中写道，“有些人喜欢 Deep Nostalgia 的功能并沉醉于其中，也有些人觉得它令人毛骨悚然而且非常抗拒。事实上，结果确实可能引发争议，每个人都对这项技术有着自己的看法。但我们开发功能的初衷仅为缅怀前人，让自己能再次与他们对话。”</p><p></p><p>Alexa AI 首席科学家 Rohit Prasad 则表示，个性化技术是一种在人与机器之间建立信任的方法。在他看来，“很多人在新冠疫情期间失去了自己的挚爱”，这似乎是在暗指 Alexa 想用模仿已故亲人或好友的方式抚慰用户情感。</p><p></p><p>另一家总部位于洛杉矶的 StoryFile 公司，曾为一生推动大屠杀历史教育而奋斗的 Marina Smith 制作葬礼视频。在悼念者提问时，机器学习算法能从 Smith 预先录制好的视频中选择最适合的片段，让她如同在现场般与人们顺畅交谈。这种用算法重现逝者的作法看似癫狂怪异，但对于思想开放、勇于尝试的人们，却不失为一种有效的慰藉方式。</p><p></p><p>一位 Project December 用户就坦言，他在用该软件跟逝者交谈之前犹豫了很久，总觉得这事“有点犯忌讳”。但他发现，最终体验“非常治愈”。而且他的母亲前段时间刚刚被送进了临终关怀中心，不知道母亲去世后他是否会尝试跟模拟 AI 对话。</p><p></p><p>作为 Project December 的创建者，Jason Rohrer 也多次测试过 Project December，并将聊天机器人设置成自己熟悉的已故亲友，包括祖父母、阿姨和年幼时的钢琴老师。他说这让自己有机会重新感受他们、找回那段已经泛黄的记忆。</p><p></p><p>我们到底应该如何看待用 AI 模拟逝者？</p><p></p><p>对此，意大利都灵大学哲学家及专注于数字文化中的死亡问题的作家 Davide Sisto 表示，在某些方面，通过 AI 技术“复活”的虚拟数字人物只是人类历史上人们寻求与逝者保持联系或交流方式的一种延伸。“虽然照片可以用静态的方式代替死者，但当今的 AI 技术赋予了逝者数字化的‘永生’能力。”但要真正让人类接受逝者或“活着”的人类“复制品”存在于我们的生活中，可能还需要一段时间。</p><p></p><p>此外，伍斯特大学教授 Maggi Savin-Baden 与英国达登聊天机器人制造公司首席执行官兼作家 David Burden 合著了一本关于数字化“永生”的书，并制作了一个以自己为原型的虚拟人物形象，她让那些不认识她的同行们和虚拟的自己交流，然后再和她本人交流。结果是，“他们说，（虚拟形象）有些特征感觉很像我，有些则完全不像。所以这项技术仍然好坏参半。”</p>",
    "publish_time": "2022-10-19 14:03:46",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "中国工商银行基于eBPF技术的云原生可观测图谱探索与实践",
    "url": "https://www.infoq.cn/article/iZBMUMOvkY3JJdHADgBX",
    "summary": "<p></p><p>在互联网金融时代，各大银行业务量呈爆发性增长态势，业务模式更新迭代更加频繁，传统的 IT 架构越来越无法应对新业务形态所带来的巨大冲击与挑战。<a href=\"https://www.infoq.cn/topic/CloudNative\">云原生</a>\"相关技术使业务应用呈现微服务众多、多语言开发、多通信协议等典型特征，调用链路日益复杂，监控数据爆发性增长，传统监控方式已无法适应云原生场景。</p><p></p><p>在这个背景下，中国工商银行积极开展云原生可观测图谱的探索和实践，针对可观测体系中的痛难点，通过深入研究内核新技术，进一步完善云原生技术版图。</p><p></p><h3>业界云原生可观测体系痛点</h3><p></p><p></p><p><a href=\"https://www.infoq.cn/article/i0CftJvEiF8mbisle4NJ\">中国工商银行</a>\"早期基于业界对可观测性“三大支柱”（监控指标（Metrics）、日志（Logging）和链路（Tracing））的定义（如图 1 所示），建设了云监控、日志中心和全息监控等运维支撑平台，初步构建了可观测体系，支撑云上应用监控报警和分析诊断能力。随着运维架构转型，开发及运维部门对节点网络拓扑、监控指标、故障定位、性能调优等方面提出了更高的要求。为此，中国工商银行对业界云原生可观测性相关前沿技术进行了深入探索与研究。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/49/49be85b393cb3df16adca7b2aa9dab7c.jpeg\" /></p><p></p><p>图1 可观测三大支柱</p><p></p><p>云原生基金会的项目全景图（CNCF Landscape）根据项目特点与价值，将提供可观测性能力的项目分为了监控（Monitoring）、追踪（Tracing）、日志（Logging）三类（如图 2 所示）。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/90/9095ce4c7cb673ad9755000013dc6939.jpeg\" /></p><p></p><p>图2 CNCF Landscape</p><p></p><p>利用这些产品的组合，我们可以比较快速地搭建一个可观测性系统。但是从业界实践来看，这样组装的系统普遍存在两大类痛点：</p><p></p><p>缺乏全局性的系统和网络拓扑关系：云原生分布式网络相较于传统网络，应用节点间网络访问过程经过多层的映射转化后，网络拓扑关系更加复杂，传统监控工具链缺乏以容器、虚机、负载均衡器等系统节点为维度的网络调用链路监控拓扑数据，并且未将抓取的网络信息与 Kubernetes 资源信息结合，无法呈现应用容器间、网络关键组件的网络拓扑，无法形成有效的可观测性图谱。数据采集方式不具备普适性且内核态指标采集能力不足：传统的数据采集方式通常有两种，一是采用 SDK 集成的方式，随应用版本部署；二是采用 Agent 的方式，采集特定埋点的数据指标。但是基于这两种方式实现的节点拓扑关系，都依赖应用方进行适配改造，埋点的数据采集又局限于特定语言和技术栈。而在云原生环境中，多语言应用、不同通信协议共存的情况下，存在适配工作量极大、应用感知明显的问题。此外，当前指标采集方面还普遍缺失对部分内核资源的细粒度监控能力，影响对问题的深入分析和调优。</p><p></p><h3>中国工商银行在可观测图谱的技术选型</h3><p></p><p></p><p>要解决容器场景下的系统层网络链路拓扑缺失和内核资源监控不完善的问题，可观测性系统必须设法获取到相关资源的统计信息。但内核通过文件系统或系统调用暴露出的信息有限，单纯从用户态切入无法抓取这些信息，只有从内核本身调用的过程中获取调用信息才可以补足相关能力。具体而言，即需要对应的内核 Tracepoint 或者函数执行 hook 调用抓取相关的信息，并上报到用户态监控程序中。这样的内核技术选型很少，从调研结果来看，目前只有两种技术能达成上述目标，一是内核模块编程技术，二是 eBPF 技术。</p><p></p><p>对于内核模块编程技术而言，获取内核数据需通过在对应的跟踪点（Tracepoint）或者系统函数调用时执行钩子（Hook）操作来抓取相关信息，并通过 netlink 套接字、sysfs(/sys)、sysctl(/proc/sys) 或 procfs(/proc) 等方式与监控进程进行通信并上传采集的数据。对于普通开发，内核模块编程技术难度较大，且极易造成系统稳定性问题。</p><p></p><p><a href=\"https://xie.infoq.cn/article/34d62a334c9af2134e1ab0b02\">eBPF</a>\"（extended Berkeley Packet Filter）是一种能够在内核运行沙箱程序的技术，提供了一套在内核事件和用户程序事件发生时安全注入代码的机制，使得非内核开发人员也可以对内核进行控制。随着内核的发展，eBPF 逐步从最初的数据包过滤扩展到了网络、内核、安全、跟踪等领域，并且它的功能特性还在快速发展中。早期的 BPF 被称为经典 BPF（简称 cBPF），正是这种功能扩展使得现在的 BPF 被称为扩展 BPF（简称 eBPF）。相对来说，它是一种安全高效的内核技术，它的出现本质上是为了解决内核迭代速度慢和系统需求快速变化的矛盾，在对内核无侵入的前提下，往内核中动态地插入一段自己的代码，实现自定义监控及跟踪能力，极大地降低了用户获取内核态丰富观测指标的门槛（如图 3 所示）。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/43/437a95d9d25cd0b942c7883b67e294c2.jpeg\" /></p><p></p><p>图3 eBPF技术初印象</p><p></p><p>内核模块编程技术和 eBPF 技术的详细对比（如表 1 所示）</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ad/ad2745c10c19a312622262074fce830c.png\" /></p><p></p><p>表1 内核模块编程技术与eBPF技术对比</p><p></p><p>由此可见，利用 eBPF 技术进行内核开发相比内核模块编程技术拥有诸多优势，包括更严格的安全检查、更稳定的 API、较高的内核开发能力、更优的数据结构与通信性能以及支持平滑升级等。同时，各大互联网公司均采用 eBPF 技术在可观测方面进行了实践，如阿里云提出了一种立足于容器界面和底层操作系统，向上关联应用性能监测的可观测性解决思路，通过 eBPF 技术无侵入地采集多语言、多网络协议的各项指标，实现了一站式可观测性平台；字节跳动通过内核的 eBPF 采集机制获取基于连接层面细粒度的内核网络监控指标，为多种运维场景提供支持。</p><p></p><p>综上，中国工商银行综合考虑技术优势、发展趋势等多个方面，最终选择基于 eBPF 技术进行内核相关的可观测功能开发，弥补当前网络拓扑和内核资源监控能力的不足，完善云原生场景下的可观测图谱。</p><p></p><h3>中国工商银行基于 eBPF 技术的云原生图谱的实践与应用</h3><p></p><p></p><p>在容器化场景下，需要采集的内核数据种类多样，为了更好地通过 eBPF 提升对系统节点间网络调用和内核资源的云原生监控能力，我们引入了 eBPF 探针无侵入式地部署在宿主机上采集相关系统调用信息及应用间互访的网络通信报文, 通过关联容器元数据信息后进行数据聚合压缩入库，并以此构建以云上拓扑自动发现为入口的可观测图谱，支持以节点系统网络性能指标分析为核心的一体化监控能力。中国工商银行的可观测图谱可以分为：内核态指标采集、网络拓扑分析、云上可观测图谱三部分（如图 4 所示）：</p><p></p><p>内核态指标采集：在宿主机部署 eBPF 探针实时采集云上应用访问数据，结合容器元数据，提供云上应用东西向访问关系的原始数据以及网络通信报文。网络拓扑分析：负责分析处理节点之间的调用关系，系统调用分析模块则负责处理应用系统调用的分类、聚合与信息关联。云上可观测图谱：提供面向业务和运维场景的可视化分析能力，以云上拓扑发现为入口提供面向应用和运维场景的可视化分析能力，支持联动全息监控、云监控以及日志中心进行关联分析，形成云原生可观测图谱。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/1d/1de384db0a1d0ebd6c6d6bd7b3f60f35.jpeg\" /></p><p></p><p>图4 eBPF可观测图谱架构</p><p></p><p></p><h4>内核态指标采集</h4><p></p><p></p><p>将 eBPF 探针通过 daemonset 的形式无侵入式地部署在宿主机上，负责采集容器网络报文、系统调用、资源使用详情信息，同时从 master 获取容器关联信息。（如图 5 所示）</p><p></p><p>负载业务间的网络信息采集：eBPF 探针采集不同网络环境下的网络通信报文等数据，以支持分析并展示负载间网络通信关系链与通信情况，包括带宽、TPS、平均响应时间、建联失败率、错误率等。负载的系统调用与资源监控的采集：高资源消耗系统调用、异常卡死系统调用；用户态与内核态资源使用情况的采集与展示，例如 cpu、内存、磁盘 io、半连接数、全连接数、页错误、文件句柄使用量、SWAP 内存使用量、inodes 使用量及可用量等。负载的容器元数据采集：eBPF 探针通过集群 master 获取集群以及容器元数据信息，对相关数据进行过滤、填充、采集、收集。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/83/83b324e43c435c8fc8030ab1e29a10ac.jpeg\" /></p><p></p><p>图5 内核态指标采集</p><p></p><h4>网络调用分析</h4><p></p><p></p><p>接收 eBPF 探针采集的指标数据，采用分类聚合算法与 Kubernetes 元数据进行关联分析、聚合存储，形成完整的节点间调用网络拓扑关系数据，同时为规则匹配报警提供支撑（如图 6 所示）。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d4/d457ce09e6c86f47b71ddea86863c616.jpeg\" /></p><p></p><p>图6 网络调用分析</p><p></p><h4>云上可观测图谱</h4><p></p><p></p><p>基于内核态指标采集和节点间调用网络拓扑分析的入库数据，构建面向用户的可观测图谱，具备丰富的系统调用指标及网络性能指标关联查询能力，面向一线问题支持人员和开发人员，提供了以下常见应用场景：</p><p></p><h5>应用拓扑感知</h5><p></p><p></p><p>在当前分布式服务的架构下，发生问题后进行分析定位是一个非常复杂的过程，不仅要求问题分析人员对全局应用有大致了解，还需熟知各个应用的特性、调用关系、部署方式。而应用拓扑感知（如图 7 所示）则提供了一个非常强大的功能：通过无侵入式采集的数据建立节点间全局的调用拓扑关系，在异常应用定位时，可以让问题一线人员非常快速的感知存在网络问题的节点。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/37/3720837549d6b8c4d996ca344b7c1af7.png\" /></p><p></p><p>图7 全局应用拓扑感知</p><p></p><p></p><h5>链路追踪分析</h5><p></p><p></p><p>区别于传统的分布式追踪，基于 eBPF 的链路追踪不止能跟踪某次调用，还具有无入侵、语言框架无关的特性，请求如果包含了分布式追踪 TraceID，也能自动识别，方便联动分布式监控平台进行排查。对某次请求来说，可以精确看到接收、处理、回应、耗时的数据，方便问题排查人员从问题节点定位到问题接口，从而进一步辅助问题的解决。（如图 8 所示）。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/86/862051908b57a3df9b0e3e51e8f0a2d4.jpeg\" /></p><p></p><p>图8 单次请求信息</p><p></p><p></p><h5>网络性能监测</h5><p></p><p></p><p>通过监测 HTTP 请求、平均响应时间、建链失败率、全连接半连接队列等网络指标辅助定位节点及链路访问连通性或性能问题。（如图 9 所示）。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/93/93c58e68d17fc99ecdb3ac8b180e2ad2.jpeg\" /></p><p></p><p>图9 网络性能监测</p><p></p><p></p><h5>黄金指标分析</h5><p></p><p></p><p>黄金指标是谷歌针对大量分布式监控实践的经验总结，4 个黄金指标可以在服务级别帮助衡量终端用户体验、服务终端、业务影响层面的问题。可观测平台层支持请求数、响应时间、错误率、慢调用情况，整体反映应用健康状态，快速评估故障影响，节约故障定位时间（如图 10 所示）。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b8/b8c46ba5e4ce5a4ae3022b8a11f6b081.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b8/b8c46ba5e4ce5a4ae3022b8a11f6b081.jpeg\" /></p><p></p><p>图10 黄金指标-平均响应时间</p><p></p><p></p><h5>上下游关联分析</h5><p></p><p></p><p>在现有的云原生环境中，应用间的拓扑非常复杂，除了提供全局的拓扑感知，快速定位问题节点后，对于问题分析人员来说，如何在具体问题节点尽可能收集更多的信息变成了关键所在。可观测平台不仅可以高亮显示问题节点的上下游（如图 11 所示），还关联了告警信息、黄金指标、Kubernetes 元信息等，在一个页面就可以提供问题分析人员多维度的展示，有助于加速问题排查。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/93/93c75c146198e96c2a1ec442b81aa051.jpeg\" /></p><p></p><p>图11 高亮显示上下游</p><p></p><p></p><h5>规则告警与压缩</h5><p></p><p></p><p>对于一个可观测平台来说，及时可靠的告警是发现问题“第一现场”最重要的功能，平台提供了预设模板的告警规则设定，支持通过选择告警检测对象、配置触发条件、设置告警内容和通知人员三步设置。告警检测方面，平台支持 Pod、节点、组件、工作负载、应用等五层丰富指标的告警，同时支持通过对指标进行逻辑运算来完成告警配置。告警规则配置方面，平台已经预设了模板，用自然化语言的方式，方便监控人员个性化的配置。最终经过压缩上报，精细化告警发送，减少一线处理人员的告警处理数量。</p><p></p><p></p><h3>未来展望</h3><p></p><p></p><p>中国工商银行将继续深入推进 eBPF 技术研究工作，积极探索云原生可观测性最佳实践，将云原生可观测图谱打造成为开发及运维人员面对系统异常时进行问题定位、分析、系统调优的首选工具。随着 eBPF 技术的应用场景被不断挖掘，业界涌现的各类开源产品已经覆盖安全、网络、跟踪与性能分析、观测与监控等领域。中国工商银行将持续关注业界 eBPF 技术及开源社区发展动态，进一步拓展 eBPF 技术在其它领域的能力并挖掘行内的落地场景。</p><p></p><p></p>",
    "publish_time": "2022-10-19 14:31:12",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AI 应用的全流程存储加速方案技术解析和实践分享",
    "url": "https://www.infoq.cn/article/bbbe1fedde2f90558f5ace81a",
    "summary": "<p>AI 应用对存储系统的挑战是全面的，从离应用最近的数据计算如何加速，到离应用最远的数据存储如何管理，到数据存储和数据计算之间如何高效流通，再到不同应用之间的资源调度如何协调 …… 这其中每一个环节的低效，都有可能拖累最终的 AI 任务的最终完成时间，让 AI 应用在一直等待数据，多个 AI 应用之间无法高效并发。</p><p></p><p>本次分享，将以存储系统为视角，对 AI 应用加速中的全部流程进行展开，分析其中关键节点和讲解相应技术，并分享百度智能云在 AI IaaS 建设上的最佳实践，加速 AI 应用。以上内容将为大家在做 AI 存储的方案设计、技术选型、工程实践等方面上提供最前沿的参考。</p><p></p><p>本文整理自 InfoQ《公开课》，文末附带 Q&amp;A 和视频回看链接。  </p><p></p><p></p><h1>1.&nbsp;开场</h1><p></p><p>今天的分享内容主要分为三个部分：</p><p></p><p>第一部分简单梳理一下企业的&nbsp;AI&nbsp;训练基础设施的发展历程，通过展现云原生&nbsp;AI&nbsp;训练的一个完整流程，总结出和其中存储相关的问题。第二个部分对这些问题做一些简单的分析，分享一下百度智能云是思考和分析这些问题的。最后一个部分介绍百度智能云的沧海存储在高性能领域的全流程加速的方案，在这个方案里会对上述存储问题有完整的解答。</p><p></p><h1>2. AI&nbsp;训练中的存储问题</h1><p></p><p>企业的&nbsp;AI&nbsp;训练基础设施是怎样一步一步发展到今天的模样的呢？这个发展过程其实经历了&nbsp;4&nbsp;个阶段：</p><p></p><p>阶段一：一开始企业训练的模型和数据量都不太大，最关心的是训练的性能，对计算之外的其它部分关注比较少，基础设施是怎么能快速跑起来怎么来。这一阶段主要是单机的训练，存储使用本地资源，如内存和本地盘。阶段二：等到模型、数据量变大之后，单机训练就不能满足企业的需求，企业开始多机训练。对于存储，一方面数据集可能大到单机无法存储，另外一方面数据集需要方便地被多机共享。这个阶段，一个便捷和省心的选择就是去购买商用的网络存储。阶段三：等到企业用户的训练规模、业务规模继续不断的增长之后，购买了越来越多的机器。从企业的角度来讲，希望能够充分地把计算资源利用率提高上来。企业在这一阶段引入训练平台解决这个问题，让不同业务的训练能够最大限度的并行跑在训练平台上。这个阶段对存储的需求产生了分化。一方面，数据量大了之后，企业成本敏感，大量的数据需要大容量低成本的存储。另一方面，对于训练的时候需要的那部分数据，还是希望存储的性能能够满足训练的要求，这一部分仍然是一个高性能存储的需求。这个阶段企业的规模已经相对比较大了，有足够的动力去自研或基于开源方案二次开发整个存储体系。阶段四：进入云时代，企业尝试把已经比较成熟的体系往云上搬，所以看起来云时代的&nbsp;AI&nbsp;训练基础设施架构就是阶段三的翻版，对于存储而言，仍然是“大容量存储&nbsp;+&nbsp;高性能存储”的组合。但是这里其实已经发生了比较重要的一个变化，就是它的数据流向和阶段三时代是不一样的，这在后面的部分有详细的介绍。</p><p></p><p>现在来看今天的云原生&nbsp;AI&nbsp;训练基础设施，最底层是数据湖存储，定位是大容量、高吞吐、高吞吐、低成本、高可靠的存储底座，是企业进行数据流转的核心。</p><p></p><p>在数据湖之上，针对&nbsp;AI&nbsp;训练的高性能需求，提供一个加速层作为数据湖存储的补充，弥补数据湖存储在支撑高性能计算时性能不足的问题。靠近计算的位置有训练平台、各类&nbsp;AI&nbsp;框架，和硬件基础设施。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5d/5d49384436b6747dfe17a51498c10602.png\" /></p><p></p><p>如果我们仔细观察企业的&nbsp;AI&nbsp;训练基础设施的发展过程，会发现其中的存储问题是不断的累加的，每一个阶段之前的问题仍然存在，但又出现的新的问题。</p><p></p><p>例如，在阶段一阶段二的时候，主要关心的是训练效率，这时候对存储的要求是不能拖计算的后端，必须能支撑好计算，这个问题无论是什么时候都是最核心的问题。因此，云原生时代面临的存储问题，涵盖了之前所有阶段的问题，我们只需要分析这一个阶段即可得到所有的疑惑和答案。</p><p></p><p>需要注意的是，从最开始的本地盘，到后来的商用网络存储、冷热分层、数据湖，存储在这个发展过程中呈现出来的一个大趋势就是，存储离计算的距离越来越远。这就导致今天我们去做一个云原生的&nbsp;AI&nbsp;训练，会经历一个很长的流程：</p><p></p><p>云原生时代的业务数据首先是集中积累到数据湖存储中，这里就包括未来用于训练的数据。我们面临的第一个问题就是数据湖存储如何选型，以保证能够可靠的存放企业的海量数据，这就是“ ①海量数据”问题。准备训练前，因为数据湖存储不能满足训练时的性能要求，所以训练数据需要转移到一个速度更快的加速层中，这个转移过程就是“ ②数据流转”问题。临近训练，训练平台负责协调训练要求的各类资源，这里当然也包括存储资源，那么存储和调度器如何才能配合好，产生了“ ③资源调度”问题。经历了漫长的流程链之后，终于可以跑训练了，这个时候存储要达到一个什么样的性能，才不至于成为计算的瓶颈，这是“ ④计算加速”问题。</p><p></p><p>上面的流程梳理下来是“ ①海量数据&nbsp;-&gt;&nbsp;②数据流转&nbsp;-&gt;&nbsp;③资源调度&nbsp;-&gt;&nbsp;④计算加速”这样一个顺序，但后面的部分会按照“ ④计算加速&nbsp;-&gt;&nbsp;③资源调度&nbsp;-&gt;&nbsp;①海量数据&nbsp;-&gt;&nbsp;②数据流转”这样的顺序讲述，从大家最关注的计算加速问题讲起。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/25/25c5ce92a17a6e17199e0be01d4caff6.png\" /></p><p></p><h1>3.&nbsp;关键问题分析和解决思路</h1><p></p><p></p><h2>3.1&nbsp;计算加速</h2><p></p><p>在分析这个问题之前，让我们通过一个简单的例子来了解一下一个典型的训练究竟长什么样：</p><p></p><p>训练的计算会经过很多很多轮，每一轮称为一个&nbsp;epoch，每一轮&nbsp;epoch&nbsp;重复以下过程：首先，为了让算法达到比较好的鲁棒性、加快收敛速度，把整个训练使用的数据集随机打散，类似于我们打牌前先把牌洗一遍，这个过程称之为&nbsp;shuffle。至于样本集包含哪些样本，是从存储系统读取的。shuffle&nbsp;确定了数据集样本的读取顺序，接下来，数据会进一步分成很多个批次（batch），算法接下来就读取一个&nbsp;batch&nbsp;训练一次，直到整个样本集都处理完。这个过程涉及到大量的读操作。一次训练持续的时间可能非常长，数个小时甚至数天数个月都有可能。所有的机器都没有办法保证在训练的过程百分之百没有故障发生，故障发生后，用户不会想从头开始计算，能恢复到一个较近时间点，从那个时间点重新开始计算是最理想的。因此需要有故障恢复的机制，通常的做法是周期性的把训练的状态保存下来，故障发生后，加载保存的状态继续计算。这个机制叫&nbsp;checkpoint。checkpoint&nbsp;对存储系统来说是写操作。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/33/33ca1b522060dae8d8d02866a289d1d4.png\" /></p><p></p><p>从上面的分析，可以看到和存储有关的操作包含&nbsp;3&nbsp;种，shuffle、读&nbsp;batch、checkpoint，前两者是读，后者是写。那么这些操作究竟对训练产生什么影响呢？</p><p></p><p>为了解答这个问题，在下图中列出一个简单的公式。衡量存储在这个过程中间是不是好，我们需要看的是整个训练过程中，真正用于计算的那部分时间在总时间中所占的比例。这个比例越高，说明存储的影响就越小。在不考虑其它因素、假设计算时间不变的情况下，这就是要求让存储的影响时间变短。</p><p></p><p>checkpoint&nbsp;不一定每个&nbsp;epoch&nbsp;都保存，且是对存储系统比较友好的顺序大&nbsp;I/O，整体耗时占比较小，一般分析时会忽略它的影响。当然，这里的结论不绝对，如果遇到&nbsp;checkpoint&nbsp;慢的情况，可以做细致的分析。</p><p></p><p>读操作的部分，我们首先看&nbsp;shuffle。前面说到&nbsp;shuffle&nbsp;需要把整个数据集做一次打散，在这个打散完成前，其实是是没有数据可以计算的，也就意味着这是一个纯粹等待的时间。这个时间从根本上无法完全消除，只能通过更高效的实现方法、更好的存储性能，把它在整体时间中的占比降到一个可接受的比例。</p><p></p><p>接下来看读&nbsp;batch&nbsp;的部分。对于&nbsp;“读&nbsp;batch&nbsp;然后训练”&nbsp;这个不断重复的过程，现代的一些训练框架其实已经做了很多的优化，目前在大部分框架里，“读&nbsp;batch”&nbsp;的这个过程，由所谓的&nbsp;Data Loader&nbsp;模块来完成，它的思路是让读的过程和计算本身并行起来。这对&nbsp;GPU&nbsp;训练的效果更明显一些。</p><p></p><p>在GPU训练中，计算和读数据的工作分别是由&nbsp;GPU&nbsp;和&nbsp;CPU&nbsp;来完成的，在&nbsp;GPU&nbsp;忙于一个&nbsp;batch&nbsp;的计算的时候，CPU&nbsp;其实是空出来的，可以提前开始读取后面一个或多个&nbsp;batch&nbsp;的数据。整个过程呈现出一种流水线的感觉。第一个&nbsp;batch&nbsp;开始读的时候还没有数据可以计算，只能等待，但是从第二个&nbsp;batch&nbsp;开始，花费在存储上的时间如果短于前一个&nbsp;batch&nbsp;计算的时间，就可以被计算完全掩盖掉。因此，这个阶段对于存储的要求是快到不拖累计算、读等待时间接近&nbsp;0&nbsp;即可。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9f/9f8a721a34ad4a6057dbb135a30e164f.png\" /></p><p></p><p>具体到这两个阶段，我们可以拿起放大镜再仔细观察一下这里到底包含哪些操作。</p><p></p><p>在&nbsp;shuffle&nbsp;阶段，需要把样本集包含哪些样本列出来，一种典型的朴素实现是将所有的样本按照目录分类存放，我们就可以通过文件系统提供的&nbsp;ls&nbsp;功能来枚举目录获取完整的文件列表，这时候就产生了大量的 open、getdents、close&nbsp;操作，这些操作都可以归类为元数据操作。</p><p></p><p>多个&nbsp;Data Loader&nbsp;会启动多个进程，读取这个&nbsp;batch&nbsp;所有的样本文件，对于每一个文件都是&nbsp;“ open -&gt; stat -&gt; read -&gt; close”&nbsp;这样的流程，其中&nbsp;open、stat、close&nbsp;是元数据操作，read&nbsp;是数据操作。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f0/f0eefc9f5575db1b412d32afdda2b910.png\" /></p><p></p><p>我们很容易观察到一个现象，对于一个样本数量确定的数据集，元数据操作的数量是确定的，只有&nbsp;read&nbsp;操作可能会因为文件大小而变化，对于较小的（几百&nbsp;KB&nbsp;以下）文件，一次&nbsp;read&nbsp;操作就可以完成，对于较大的文件（数&nbsp;MB&nbsp;以上），需要调用多次&nbsp;read。因此，样本大小影响了元数据操作耗时的占比，元数据操作的耗时占比进一步决定了元数据还是数据对训练的影响更大。</p><p></p><p>根据一些统计的结果，可以发现很多训练的样本集面临的情况是，样本数量非常大，但样本的平均大小又很小。以&nbsp;ImageNet&nbsp;数据集为例，整个数据集包含几百万（ImageNet 1K）、上千万（ImageNet 22k）的图片，平均一个图片大小仅为一百多&nbsp;KB。这个大小对存储系统来说是非常小的。</p><p></p><p>因此，很多&nbsp;AI&nbsp;训练都面临海量小文件的问题。如果大家对存储系统的架构有一定了解，就会知道，在一个存储系统里，元数据的扩展性和性能是远比数据部分差的。这个结论无论对单机的存储系统还是分布式的存储系统都成立。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/84/841c1d6ae2ef8b8d93e3b7fe37915124.png\" /></p><p></p><p>那应该如何来解决这里面临的计算加速问题呢？</p><p></p><p>假设要解决的这个问题是我们的敌人，我们要打败它，有几个方向可以尝试的方向：</p><p></p><p>方向一：我发现敌人太强大了，能不能削弱它的实力，让它变得更弱呢</p><p></p><p>前面说到海量小文件场景的关键是元数据操作的占比较高，同时也说到，元数据操作的性能在存储系统里是更差的。那么我们是不是能把较难的元数据操作转化成更容易的数据操作呢，如果能做到这一点，就可以把问题简化。</p><p></p><p>这里采用的优化措施主要是软件层面的。对于&nbsp;shuffle，可以为样本集维护一个单独的列表文件，或者采用更合适的元数据系统。对于读数据，可以通过&nbsp;TFRecord、HDF5&nbsp;等打包格式，对小文件进行打包，变成大文件。这些操作的核心都是将元数据操作转化成更容易优化的数据操作。这类优化措施的主要缺点是需要用户改变使用习惯。</p><p></p><p>方向二：不管敌人有多强大，让我自己变得更强肯定没错</p><p></p><p>硬件层面，就是开启&nbsp;“买买买”&nbsp;模式，花更多的钱，使用更高规格更快的硬件来支撑训练。例如，存储介质方面使用更多的内存、更快更多的&nbsp;SSD&nbsp;硬盘等，网络方面升级到&nbsp;100G/200G&nbsp;的高速&nbsp;TCP/RDMA&nbsp;网络。</p><p></p><p>软件方面，对软件架构做一些升级来提高整个软件系统的扩展能力，缩短软件栈的&nbsp;I/O&nbsp;路径长度。这里大家可能有一定了解的方案就是并行文件系统，这一类文件系统通过&nbsp;hash、stripe&nbsp;等方式将元数据和数据尽可能地分散到更多的节点上，以此来提高元数据和数据的并发处理性能。这类系统同时还会实现私有的内核客户端，请求直接发送给存储节点，以此来缩短&nbsp;I/O&nbsp;路径。</p><p></p><p>方向三：在我们和敌人相对实力不变的情况下，想办法让敌人离我更近，让同等力道的拳头对敌人造成更大的伤害</p><p></p><p>这样的方法同样包含硬件和软件上的一些方法。</p><p></p><p>硬件方面，我们可以在组网的时候让计算节点和存储节点在物理上靠得更近。这件事情和硬件升级本身是独立的，因为如果仅仅是升级硬件，一次操作还是需要跨越很多跳交换机，效率同样会受到影响。对于单机而言，GPU Direct Storage&nbsp;这样的技术，可以让&nbsp;GPU&nbsp;直接去读取存储系统上的数据，消除掉一部分&nbsp;CPU&nbsp;处理的开销，本质上是抄了一个近道，少绕了一些路。</p><p></p><p>软件方面，可以做的一点是让需要访问的数据能够尽可能的搬到计算节点本地，或者和计算节点比较近的地方。这就是缓存的思路，通过利用计算节点本地的冗余的内存、磁盘资源，让一些请求在缓存里处理掉，会比直接访问存储系统的性能更好。</p><p></p><p>到目前为止，我们的这些优化思路里，已经提出来两个比较重要的软件方案，一个是并行文件系统，一个是缓存。接下来再稍微展开介绍一下这两类系统。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b0/b0a34e9dc3b6dfb66962558a08f32734.png\" /></p><p></p><p>并行文件系统和其它种类的文件系统有什么样的差别呢？今天我们去查看公有云厂商的官网，可以发现文件存储产品通常分为两类：</p><p></p><p>第一类系统是&nbsp;NAS。这是一种对标&nbsp;NetApp&nbsp;这类传统厂商提供的网络文件存储产品，提供标准的 NFS、SMB&nbsp;协议访问能力，产品形态上是&nbsp;serverless&nbsp;的。这样一类产品的一个特点就是标准，NFS&nbsp;和&nbsp;SMB&nbsp;协议是得到业界认可的标准协议，用户使用时没有兼容性负担和学习成本，主流操作系统也会内置支持，基本上是开箱即用的状态。但这类存在的一个最大缺点就是，为了去兼容标准的协议，需要在处理路径上引入专门的协议处理节点，这些节点负责将请求转化为存储节点可以理解的内部格式。这种架构有两个影响性能的问题。第一个问题是让请求的处理链条变得更长，让延时变大。第二个问题是协议处理节点本身可能成为处理瓶颈，影响并发度。</p><p></p><p>第二类系统是并行文件系统。并行文件系统走了和&nbsp;NAS&nbsp;相反的路线，专门针对特定的高性能场景去做一些极致的优化。这类系统通常会放弃或弱化对标准协议的兼容性，取而代之，实现私有的客户端协议，通常运行在内核态。业务的请求进入客户端后，迅速、直接发往后端的存储节点。这种设计让软件上的&nbsp;I/O&nbsp;路径达到最短，充分利用后端节点、设备的并行处理能力。这类系统的代表有&nbsp;Lustre、BeeGFS、GPFS，和百度智能云PFS。</p><p></p><p>简单总结一下，想要兼容性更好，选择&nbsp;NAS&nbsp;类的产品，想要性能更高，选择并行文件系统产品。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ba/ba48d0a69897f17d31c7fe34ebd01ef0.png\" /></p><p></p><p>从我们之前的分析可以看出，AI&nbsp;场景下对数据集的使用是只读的。因此，对于&nbsp;AI&nbsp;训练场景，缓存是一个非常好的优化手段。具体做法是将数据缓存到计算节点本地或临近节点的内存、磁盘上，达到就近访问的效果。缓存系统在&nbsp;cache miss&nbsp;的情况下需要从远端存储系统读取数据，性能是比较低的，训练中应该尽量避免这样的情况。</p><p></p><p>目前，本领域业界主流的缓存解决方案分为两大类。一类是&nbsp;Alluxio&nbsp;这类相对比较纯粹的缓存系统，不改变数据的格式，忠实地做一个数据的搬运工。另外一类是近些年比较热门的云原生文件系统，如&nbsp;JuiceFS，这类系统在对象存储之上重新定义了一层数据结构，数据只能通过系统本身访问。无论是哪一类系统，提升计算侧性能的本质仍然是缓存。阿里云&nbsp;JindoFS、百度智能云&nbsp;RapidFS&nbsp;都是兼有这两类缓存系统能力的统一解决方案，用户可以根据自己的实际需求选择不同的工作模式。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cd/cd6ba3e9bf6cd3b71be39ea3784b16a5.png\" /></p><p></p><p>目前为止，已经提到了并行文件系统和缓存两大类软件解决方案，那么困扰选择恐惧症患者的问题来了，它们究竟有什么区别，该怎么选。</p><p></p><p>并行文件系统主要是面向高性能场景（传统&nbsp;HPC、AI&nbsp;场景）优化，提供了对&nbsp;POSIX&nbsp;标准文件系统接口的完整支持，所以大部分通用文件系统的需求，同样可以用这类文件系统来满足。从长远的发展趋势看，并行文件系统的依然是去兼容&nbsp;POSIX，将文件系统的标准能力做大做强做好用。</p><p></p><p>缓存系统的实现则相对灵活很多，完全是为有限的特定场景定制的一类系统，目前在云上的主要服务场景是&nbsp;AI&nbsp;和大数据存算分离。这类系统的一个重要发展趋势是继续探索一些非标准的能力，和上层的框架、生态加强融合。</p><p></p><p>所以，整体上来看，并行文件系统可以适用于需要标准文件系统的场景，缓存系统是配合对象存储使用的定制系统，这两个方案只是在&nbsp;AI&nbsp;场景下产生重叠。如果业务尚未没有完成云原生的改造，或者强依赖文件系统的一些语义（如多进程并发写同一文件），并行文件系统是更省心的选择。如果业务已经是数据湖为核心的云原生架构，在&nbsp;AI&nbsp;的场景下，可以尝试缓存系统。</p><p></p><p>从长远看，这两类系统更多的是互补的关系：</p><p></p><p>性能方面：虽然说缓存系统通常是用来加速一些相对较慢的存储系统，但并不能排除可以用来进一步加速并行文件系统。例如，元数据请求即使通过并行文件系统处理比较快，但仍然产生很多轮的网络访问开销，如果能在其上叠加一层元数据缓存，对提高性能也是很有帮助的。功能方面：缓存系统可以更好的实现一些非标准的能力，配合一个标准的高速文件系统，可以有一些好玩的用法，这些用法其实也是业界探索的方向。例如，前面提到一种优化&nbsp;shuffle&nbsp;的方法是使用文件列表替代&nbsp;ls，缓存系统完全可以实现一种功能，将列表映射成文件系统目录的结构，并缓存下来，而数据访问继续由并行文件系统处理。这样的方式可以让之前的训练代码继续使用，不感知其中的变化。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/57/5713dcbb52b7457f494211c6cb0d1a32.png\" /></p><p></p><h2>3.2&nbsp;资源调度</h2><p></p><p>所有的训练平台都存在一个终极的梦想，就是让计算资源利用率维持在一个较高的水位。这个水位如果能到&nbsp;60%+、70%+&nbsp;是一个很了不起的事情。这儿有些同学可能不能理解，平时的训练很容易达到&nbsp;90%+&nbsp;的利用率呀，为什么上了训练平台就下降了呢？</p><p></p><p>主要的原因是在一个完整的训练流程里，除了计算的部分，还有很多其它的操作和步骤，训练之间也可能存在串行、并行等关系。这些操作如果调度上处理不好，让计算资源处于等待的状态，就会拉低整体的利用率。此外，还有低峰期这样的因素进一步拉低利用率。</p><p></p><p>本文讲的是存储相关的问题，不会涉及计算侧的相关优化。如果想要了解计算优化的部分，可以看一下我的两位同事之前做的很精彩的分享，链接如下：</p><p></p><p>百度智能云技术站：<a href=\"http://mp.weixin.qq.com/s?__biz=MzkxOTM4MTM3Ng==&amp;mid=2247483836&amp;idx=1&amp;sn=2dce3f0d8beac24284b8dd7e6197d0fb&amp;chksm=c1a3b553f6d43c45be97e97b4ab535c52ed212fcb8c999a53ea04de453aa948501290e19d76f&amp;scene=21#wechat_redirect\">双引擎 GPU 容器虚拟化，用户态和内核态的技术解析和实践分享</a>\"InfoQ&nbsp;直播回放：<a href=\"https://www.infoq.cn/video/RBZSKsgqf0dBI5fC5dL7\">https://www.infoq.cn/video/RBZSKsgqf0dBI5fC5dL7</a>\"</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/81/81b14216bf395560ef93920c6696ad25.png\" /></p><p></p><p>回到我们今天的主题，存储这部分在平台化训练和云原生训练阶段面临的问题是一致的。在这两个阶段，我们会发现很多时候数据的来源是速度较慢的大容量存储或者数据湖。这就导致在真正开始训练前，需要一个数据准备的阶段，将数据搬到速度更快的存储里。</p><p></p><p>我们来看一个简化的例子，Task 1&nbsp;和&nbsp;Task 2&nbsp;申请同一批&nbsp;GPU&nbsp;资源，数据准备时间和&nbsp;GPU&nbsp;计算时间一样长。</p><p></p><p>如果不在调度上做优化，直接按照算力需求，将任务作为整体调度，即下图中的调度策略&nbsp;1，那么&nbsp;Task 1&nbsp;和 Task 2&nbsp;只能串行执行，中间有很长的时间被数据等待浪费掉了，整个时间段的&nbsp;GPU&nbsp;利用率平均下来只有 46%。这样的情况显然是不理想的。</p><p></p><p>让我们换一个角度看这个问题。回想一下&nbsp;Data Loader&nbsp;是如何解决让读数据和计算并行的，显然这里的问题也是类似的。我们完全可以让数据准备的时间和训练的时间并行起来。如图中的调度策略&nbsp;2&nbsp;展示的那样，在Task 1&nbsp;训练的期间，就可以开始&nbsp;Task 2&nbsp;的数据准备工作。在这个例子里，刚好&nbsp;Task 2&nbsp;的数据准备时间都可以被隐藏掉。这个调度策略可以让整体的&nbsp;GPU&nbsp;利用率提升到&nbsp;62%。</p><p></p><p>这里的思路具有一定的普适性，对于优化其它的资源利用率问题也有参考意义，本质上就是让不产生竞争的环节最大可能的并行运行，达到工厂流水线的效果。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6f/6f5936c78243a3d1e12ff3fb362c4c30.png\" /></p><p></p><p>思路有了，具体应该怎么做呢。有聪明人在开源社区已经先行了一步，实现了一个基于该思路的项目 Fluid。Fluid&nbsp;自称是一个数据集编排跟加速的这样一个框架，其核心思想就是上面描述的流水线调度。</p><p></p><p>Fluid&nbsp;把数据集的准备工作从整个流程里单独抽取了出来，利用底层的&nbsp;K8s&nbsp;分配需要的资源，例如缓存系统需要的内存和磁盘资源。资源分配出来后，可以选择性的发起元数据和数据的预热工作。等预热工作完成之后，再由&nbsp;K8s&nbsp;调度计算资源运行训练任务。训练任务可以选择是否亲和，所谓亲和是让缓存的节点和计算的节点是同一批节点，这个能带来什么样的好处待会儿会讲到。训练完成后，用户可以视情况而定决定何时回收 Fluid&nbsp;占用的资源，这个过程和计算也是独立的。</p><p></p><p>目前，社区对&nbsp;Fluid&nbsp;的定位仍然是围绕缓存系统展开的，但我们认为数据准备在&nbsp;AI&nbsp;训练里是一个普遍的问题，同样的原理也适用于并行文件系统和其它存储系统。从这个角度看，Fluid&nbsp;的适用范围可以超出社区对它的定位。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/88/88fcedf748ba70d7b9b5a22eb3e6e92b.png\" /></p><p></p><p>在这个问题的最后，对&nbsp;Fluid&nbsp;的亲和调度稍微展开再介绍下。亲和性调度主要对缓存系统有帮助，体现在两个方面。</p><p></p><p>第一个好处是性能方面的。计算节点和缓存节点是同一批节点，保证了计算节点访问缓存数据的物理路径是比较优的。同时，部分数据通过本地就可以满足，不再需要网络访问。</p><p></p><p>第二个好处是容错方面的。缓存系统和并行文件系统最大的一个差别是本身的容错能力较弱，缓存节点故障，就意味着其上的缓存数据失效。如果没有亲和调度，即使能够从远端重新拉取数据，也需要忍受一段时间的性能下降，这段时间会拉低计算资源的利用率。有了亲和调度之后，缓存节点和计算节点同时失效，在恢复计算任务前有机会先恢复缓存数据，就规避了性能退化的问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/60/601e0183c07ede6674864518601f3d75.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/58/58354fe55629fb403fbff121bf850e61.png\" /></p><p></p><h2>3.3&nbsp;海量数据</h2><p></p><p>前面我们的关注点主要在&nbsp;AI&nbsp;训练部分，这部分对存储的性能有极致的要求。但如果我们放眼去观察一下所有&nbsp;AI&nbsp;相关的流程，包括数据集管理、项目管理、预处理这些，会发现除了训练和预测，其它的流程对高性能并没有一个很强的诉求，它们的需求归纳下来是一个高吞吐、可共享、大容量、高可靠的存储系统。</p><p></p><p>在考虑到企业中存在其它各种业务，这些业务可能是&nbsp;AI&nbsp;的数据集来源，也可能是&nbsp;AI&nbsp;的使用方，这个存储系统需要能够方便地和这些业务进行数据交流。综合来看，统一的数据湖存储是最佳选择。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7b/7b3dcb8e63e094bdc1e75598d7ad9ce2.png\" /></p><p></p><p>有必要指出的一点就是，选择数据湖的背后，是业务间的数据流转方式已经发生了翻天覆地的变化。在云原生之前，不同类型的业务处于信息孤岛的状态，大数据的业务使用&nbsp;HDFS，高性能计算使用并行文件系统，数仓系统自己保存数据。系统&nbsp;B&nbsp;需要使用系统&nbsp;A&nbsp;的数据，需要把数据从系统&nbsp;&nbsp;A&nbsp;里导出来一份。这种点对点的数据交流显然是比较低效和繁琐的。</p><p></p><p>数据湖、存算分离这些概念的兴起，让业界达成一个共识，那就是建设统一的数据湖存储底座，围绕数据存储进行数据流转，可以有效的解决系统间数据流转的问题。对这部分内容感兴趣的同学可以阅读“百度智能云技术站”公众号的的数据湖系列专题文章。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8e/8e4a1d36254d32dfbe55646062bbfc7b.png\" /></p><p></p><p>大家认可的数据湖存储候选系统有两个，一个是大数据领域使用较多的&nbsp;HDFS，一个是起源自&nbsp;AWS S3&nbsp;的对象存储。</p><p></p><p>HDFS&nbsp;主要有两个模块，分别是用来提供元数据服务的&nbsp;NameNode，和用来存储数据的&nbsp;DataNode。HDFS&nbsp;的元数据是按照树形结构来组织的，即所谓的层级命名空间。这种元数据组织方式的特点就是除了根目录外，每一个文件或者目录，都从属于一个父目录，从根目录往下看，就像是一颗倒挂的树。HDFS&nbsp;的数据一般是&nbsp;3&nbsp;副本保存的。</p><p></p><p>对象存储的架构主要分为三个部分。首先因为对象存储提供的接口形式是标准的&nbsp;HTTP，需要一些&nbsp;Web Service&nbsp;服务器来处理接口调用。Web Service&nbsp;服务器处理的过程中会根据请求的类型拆分成元数据请求和数据请求，分别交由相关的子系统来负责：</p><p></p><p>元数据子系统：在实现上一般基于分布式&nbsp;KV&nbsp;或&nbsp;NewSQL&nbsp;，提供平坦命名空间。平坦命名空间的特点是其中的每一个对象（等价于&nbsp;HDFS&nbsp;中的文件或目录）没有从属关系，互相独立。数据子系统。数据子系统：使用纠删码（Erasure Coding，EC）技术存储数据，它的原理是将原始数据切成&nbsp;N&nbsp;个等大小的块，并计算出&nbsp;P&nbsp;个冗余的校验块。这些数据块和校验块存储到不同的节点上，只要有不少于&nbsp;N&nbsp;个块存活，就能恢复出来完整的数据。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/30/30098d6d05731fea26ab12873cb52260.png\" /></p><p></p><p>我们来简单地从几个方面对比一下这两个系统：</p><p></p><p>成本：对象存储的成本要比&nbsp;HDFS&nbsp;低很多，因为以下几个原因：首先是副本数。HDFS&nbsp;自己有&nbsp;3&nbsp;副本，直接搬到云上使用云磁盘搭建，还存在副本放大问题。因为云磁盘本身也有&nbsp;3&nbsp;副本，叠加起来其实是&nbsp;9&nbsp;副本的开销。与之比较，对象存储的纠删码可以做到 1.5&nbsp;副本甚至更低。这部分的成本就差出来很多。其次，云厂商的对象存储对不同冷热程度的数据使用不同的纠删码配置和存储介质，最冷的数据可以存储到磁带中，磁带比&nbsp;HDFS&nbsp;使用的机械硬盘成本更低。最后，HDFS&nbsp;的数据湖是存算一体架构。所谓存算一体是说，同样一批机器既用来跑计算，也用来跑存储。这个架构的优势是可以实现亲和调度，调度的时候让计算任务直接跑到数据所在的节点上，和我们前面说的缓存亲和调度异曲同工。但这也带来了一个问题，就是计算必须和存储同步扩容，现实中很难做到刚好匹配，必然会存在一类资源的浪费。这个问题在对象存储存算分离数据湖架构上不存在，对象存储服务只提供纯粹的存储能力，计算资源是客户按需购买的，计算需求不存在的时候甚至可以不买计算资源，非常灵活。采用存算分离架构，用户可以避免很多计算资源的浪费。扩展性：层级命名空间和平坦命名空间相比，扩展性要差很多：这里主要就是因为层级命名空间需要维护父子关系。HDFS&nbsp;为了简化这个关系的维护，使用了单点 NameNode&nbsp;的设计，数据还直接放在内存里，这导致这个单点很难扩展，性能上限也比较低，通常一个系统只能保存数亿文件，几十&nbsp;PB&nbsp;的数据。虽然社区后来推出了&nbsp;Federation&nbsp;的功能，但没有本质上解决问题。对象存储则不同，平坦命名空间里的每个对象天然没有任何关联，可以作为独立的个体对待，关联性的打破让扩展性更容易做。云厂商的对象存储服务因此可以做到一个集群&nbsp;EB&nbsp;级的容量，万亿条元数据，比&nbsp;HDFS&nbsp;大很多。可用性&amp;可靠性：HDFS&nbsp;是一个单机房的服务，同一个数据只能容忍&nbsp;2&nbsp;个副本出现问题。对象存储可以部署到多个机房，EC&nbsp;编码也可以容忍更多的块丢失，如&nbsp;18 + 6&nbsp;的编码可以容忍&nbsp;6&nbsp;个块故障，这些保证了对象存储能够提供更好的可用性和可靠性保障，完胜&nbsp;HDFS。吞吐：大家对数据湖比较关注的性能指标就是吞吐，这个指标和集群规模是强相关的，集群的节点数越多，磁盘数量越多，能够提供的吞吐就越高。云厂商的对象存储在这方面有天然的优势，一方面集群规模要大很多，另外一方面其中很多数据的访问频率非常低，不会对需要高吞吐的数据产生挤兑，性能容易得到保障。生态：两个系统都是接受度比较高的。对象存储缺乏对&nbsp;rename、边写边读等特性的支持，使得它目前还不能满足部分大数据的场景需求。不过云厂商也在积极的解决这些问题，例如百度智能云推出了&nbsp;RapidFS&nbsp;和&nbsp;BOS&nbsp;层级&nbsp;Namespace&nbsp;作为补充。</p><p></p><p>经过这样的对比，可以得到一个简单直观的结论就是在对象存储是数据湖存储的首选。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/52/52a6d44c03576df98631afd5fdcfd95e.png\" /></p><p></p><h2>3.4&nbsp;数据流转</h2><p></p><p>数据湖存储成为整个数据流转的&nbsp;C&nbsp;位之后，带来的最大的一个变化就是数据流向完全逆转了。在传统的架构里，大容量的冷数据存储和高性能存储是分别维护的，对于&nbsp;AI&nbsp;训练的部分，数据的存储、生产、消费都发生在高性能存储中，自成体系，只有转冷的数据才会考虑转移到大容量存储中去。比例较小的反向数据流转（从大容量存储到高性能存储）通过工具来解决。</p><p></p><p>但到了数据湖里，数据湖存储才是最全量、最权威的数据来源，大部分情况下，数据的第一个落脚点是数据湖，然后才会到高性能的加速层。在存算分离架构中，加速层本身都只是临时的存在，其中的数据生命周期和计算资源同步，略早于计算资源的创建而生成，计算资源销毁时同步删除。这就导致数据湖到加速层的数据同步成为一个高频、核心的需求，需要花大力气解决。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/62/62671c25d46468388ede29814a725913.png\" /></p><p></p><p>很容易想到的是一种比较朴素的方案，经常被大家用来做数据同步和迁移。简单的讲，这个方案就是准备一个中转机，在同一台机器上把数据湖存储和加速层高性能存储都挂载上，然后使用&nbsp;cp&nbsp;或&nbsp;rsync&nbsp;之类的工具来搬迁数据。</p><p></p><p>大家如果使用过这样一类方法，会很容易发现存在一些问题：</p><p></p><p>第一个问题是同步速度慢。这里受到很多环节的限制，中转机的硬件配置、存储系统单客户端的并发度等等因素。文件系统层也有很多冗余开销，这些冗余开销主要来自元数据，对于读的那方，每个文件都需要&nbsp;open、stat、close，对于写的那方，每个文件需要&nbsp;open、setattr、close。前面分析训练效率的时候提过这类操作对海量小文件非常不友好，但通过&nbsp;cp、rsync&nbsp;无法优化掉这些开销。第二个问题是同步策略不可定制，在有一些场景下，我们可能会希望只做元数据的同步，或一些特定条件数据的同步。例如，一些训练里文件都很大，训练任务对延时不敏感，数据湖存储就足以满足吞吐的要求，这时候只需要元数据的缓存。cp&nbsp;和&nbsp;rsync&nbsp;这样的工具无法满足要求。这种方法在处理增量同步的时候也比较低效，需要对比全量的文件列表，而对象存储是支持通知机制的，如果能利用这一点能够极大地改善增量同步的效率。第三个问题是和调度器的集成困难。朴素的方案在实现上采用脚本和命令行工具实现，复杂的环境下稳定性比较差，状态的获取和解析也不是很灵活。如果操作系统环境变化了，没测试过，真正使用的时候可能会发现跑不起来。这些问题导致和调度器集成时会遇到各种各样的问题，需要人工介入排查，维护成本极高。最后一个问题是这种方式同步成功还好，同步失败后需要善后，处理残留的垃圾，这些也需要介入或者半人工的方式来处理。</p><p></p><p>上述诸多因素的叠加，让朴素方案在云原生时代显得非常的笨重和低效。我们认为，加速层的存储系统内置数据同步的能力才是解决这一关键问题的正确思路。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9d/9dcd9a31e941f9f8caa21498146b07f3.png\" /></p><p></p><p>在系统内部实现，可以解决朴素方案存在的各类问题。</p><p></p><p>对于同步速度慢的问题，充分利用系统的多个节点去并发的同步数据，缩短中间环节，不给中间商赚差价的机会。</p><p></p><p>至于哪些数据同步，哪些不同步，在系统内部很灵活，容易实现各种各样的策略。</p><p></p><p>调度器方面可以结合前面说的&nbsp;Fluid&nbsp;框架，将同步的发起、状态的展示、容错做到完全自动化。</p><p></p><p>垃圾回收的问题也同样可以在&nbsp;Fluid&nbsp;的框架内解决掉，由&nbsp;Fluid&nbsp;的机制保证资源自动释放。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8a/8a31e6f655e10fc8b88c8fb7e5f6d2c7.png\" /></p><p></p><h1>4.&nbsp;百度沧海·存储全流程存储加速方案</h1><p></p><p><a href=\"https://cloud.baidu.com/solution/canghai.html?track=infoq01\">百度沧海·存储</a>\"根据上面的分析，推出一整套高性能存储的解决方案。</p><p></p><p>方案的数据湖部分由<a href=\"https://cloud.baidu.com/product/bos.html?track=infoq01\">对象存储&nbsp;BOS</a>\"&nbsp;来承担，除了前文分析的大容量、高吞吐、低成本的特点，还内置了分级存储和智能生命周期功能。分级存储是进一步细分对象存储数据冷热降低成本的手段，配合智能生命周期可以让业务在更高的性能和更低的总持有成本之间取得平衡。</p><p></p><p>支撑训练的部分由专门的加速层来完成。这一层首先从网络环境保证存储和计算是离得比较近的，让存储能够达到最好的性能。在这基础上，包含两个软件产品，一个是<a href=\"https://cloud.baidu.com/product/pfs.html?track=infoq01\">并行文件系统&nbsp;PFS</a>\"，一个是数据湖存储加速 RapidFS。每个&nbsp;PFS&nbsp;实例部署在托管的裸金属&nbsp;BBC&nbsp;上，或者虚拟机&nbsp;BCC&nbsp;上，无论是哪种模式，使用的硬件性能均有定量保证。每个&nbsp;RapidFS&nbsp;实例的资源则来自计算节点本地的内存和磁盘。PFS&nbsp;和&nbsp;RapidFS&nbsp;均支持&nbsp;Bucket Link&nbsp;实现数据湖数据的自动同步，同时也支持&nbsp;Fluid&nbsp;调度器。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f2/f2b033ddd166fe3790aab08ffcc63e57.png\" /></p><p></p><p>在我们的方案里，对之前讨论的问题都有解答，具体如下：</p><p></p><p>海量数据：由&nbsp;BOS&nbsp;及周边生态解决。数据流转：PFS&nbsp;和&nbsp;RapidFS&nbsp;内置的&nbsp;Bucket Link&nbsp;能力支持自动从数据湖同步数据。资源调度：PFS&nbsp;和&nbsp;RapidFS&nbsp;均支持&nbsp;Fluid&nbsp;调度器，使用方式接近，用户可灵活切换。数据加速：PFS&nbsp;和&nbsp;RapidFS&nbsp;作为数据湖加速层，采用高速硬件，近计算部署的方式保证性能。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1c/1cb9553b8b955d80c9277052f8d47769.png\" /></p><p></p><p>最后简单看一下&nbsp;PFS&nbsp;和&nbsp;RapidFS&nbsp;在实际支持用户训练时候的效果。在这个例子里，有三组数据，分别是基于&nbsp;RapidFS、PFS、对象存储直接来做 GPU训练。可以看出，当&nbsp;RapidFS&nbsp;和&nbsp;PFS&nbsp;使用 Bucket Link&nbsp;做完数据预热之后，可以保证训练期间的&nbsp;GPU&nbsp;利用率打满。基于对象存储直接来做这个训练的话，中间很大一部分时间是消耗在数据的读取上，整个&nbsp;GPU&nbsp;利用率在一个非常低的水位上。通过这样一个实验，我们大致能够看到 RapidFS&nbsp;跟&nbsp;PFS&nbsp;在计算加速这一块的效果。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c8/c80779a99b0049f4d0920bca18d7e76f.png\" /></p><p></p><h1>Q&amp;A</h1><p></p><p>问题&nbsp;1：为什么对象存储能让存算分离？HDFS&nbsp;不可以？这个不是取决于计算和存储的架构吗？</p><p></p><p>所有的技术选型都离不开当年的大背景。</p><p></p><p>存算一体架构本身在过去是非常棒的设计。当时的网络没有那么快，存算一体可以让计算和存储获得更好的亲和性，极大的降低了网络上的数据传输量开销。但随着数据量的爆炸式增长和网络速度的改善，存算一体架构的问题逐渐暴露出来了。</p><p></p><p>首先，存储和计算对资源的需求不匹配，扩容时很容易导致其中一种资源的浪费。</p><p></p><p>其次，网络速度的改善让数据传输变得很快，亲和性的重要性降低。</p><p></p><p>第三，HDFS&nbsp;本身的扩展性缺陷也暴露出来了，不能支撑上百亿文件。对象存储作为云厂商提供的一种存储服务，解决了扩展性的问题，成本也比自建&nbsp;HDFS&nbsp;更低廉。</p><p></p><p>更重要的是，对象存储让用户的计算资源和存储资源可以解耦，完全可以按需使用，计算资源的成本也降低了。</p><p></p><p>这些优势综合下来，让对象存储成为存算分离架构的首选。</p><p></p><p>使用&nbsp;HDFS&nbsp;来做存算分离架构，它的扩展性和成本会比对象存储差很多。HDFS&nbsp;当然也在解决这个问题，但其设计的下一代&nbsp;OZone&nbsp;实际上就是对象存储。</p><p></p><p>问题&nbsp;2：在进行存储系统选型的时候，你们会优先考虑什么？</p><p></p><p>不同的存储系统有各自适用的场景，最重要的是调研清楚这个存储系统服务哪些业务，这些业务的访问模式是什么样的。例如，大数据业务顺序读写比较多，且多为大文件，所以它对存储的要求主要在吞吐方面。要满足吞吐的要求，就不一定需要很快的硬件，通过堆机械硬盘，同样可以达到很高的吞吐。再例如，如果你的业务访问元数据访问非常频繁，或者产生很多的随机小&nbsp;I/O，这时候就需要考虑高速的硬件，软件架构也需要有针对性的优化。我们需要先从业务的访问模式了解它关注哪些方面的功能和性能，然后再去做存储硬件和软件系统的选型。</p><p></p><p>问题&nbsp;3：如何将本地存储与公有云存储打通？</p><p></p><p>公有云厂商的数据打通基本都是通过对象存储来满足的。只要网络是通的，用户可以通过&nbsp;SDK、FUSE、命令行工具等多种方式使用对象存储。如果需要进行数据同步和迁移，纯软件的方案有类似&nbsp;rsync&nbsp;的工具。数据量比较大的情况，百度智能云还可以提供一种叫<a href=\"https://cloud.baidu.com/product/cloudflow.html?track=infoq01\">月光宝盒</a>\"的硬件，类似一个很大的移动硬盘，用户可以把数据拷贝进去，邮寄到百度智能云的机房，在百度内网完成数据的上传。更多的方法大家可以去&nbsp;BOS&nbsp;的官网了解。</p><p></p><p>问题&nbsp;4：Ceph、HDFS&nbsp;的区别是什么？</p><p></p><p>在回答它们的区别之前，先看看它们的共同点，它们的共同点是都可以归类为所谓的软件定义存储。在它们出现之前，存储软件都是跑在磁盘阵列这种专业的硬件之上的，依靠硬件来解决数据可靠性的问题，但 Ceph、HDFS&nbsp;可以跑在通用服务器上，数据可靠性由软件本身保证，这是一个巨大的改变。</p><p></p><p>它们的区别在于定位不一样。HDFS&nbsp;是专门面向大数据设计的，针对大数据的业务特点，实现了&nbsp;POSIX&nbsp;标准的一个子集。Ceph&nbsp;包含&nbsp;3&nbsp;个子系统，分别是文件存储&nbsp;CephFS、块存储&nbsp;RBD、对象存储&nbsp;RGW，其中 CephFS&nbsp;和&nbsp;HDFS&nbsp;有些类似，但对&nbsp;POSIX&nbsp;标准的兼容程度要比&nbsp;HDFS&nbsp;高很多。例如随机写、hardlink&nbsp;这样的能力没有被&nbsp;HDFS&nbsp;支持，但&nbsp;CephFS&nbsp;就支持。</p><p></p><p>问题&nbsp;5：请问一下&nbsp;AI&nbsp;训练预读时，存储系统可以知道预读的文件有哪些吗？</p><p></p><p>存储系统需要框架主动去读取才知道预取的是哪些文件。目前业界在做的一个探索就是让存储和框架配合，通过一些非标准的接口让存储系统提前知道某个计算节点需要那些数据，这样就可以在框架真正读之前就将这些数据搬运到计算节点本地了。这个思路可以进一步把&nbsp;shuffle&nbsp;也卸载给存储来做。</p><p></p><p>问题&nbsp;6：请问一下百度沧海&nbsp;RapidFS&nbsp;是&nbsp;POSIX&nbsp;部分兼容的吗？</p><p></p><p>是的，兼容的是&nbsp;HDFS&nbsp;接口。RapidFS&nbsp;有两个模式，一种定位是缓存，和&nbsp;Alluxio&nbsp;比较接近，只实现缓存加速能力，对&nbsp;HDFS&nbsp;的兼容性和底层对象存储完全对齐，不提供&nbsp;rename&nbsp;原子性、边写边读这样一些特性的支持。另外一种模式是云原生文件系统，和&nbsp;JuiceFS&nbsp;类似，在对象存储之上重新组织数据，提供完整的&nbsp;HDFS&nbsp;兼容性。</p><p></p><p>问题&nbsp;7: RDMA&nbsp;技术相比直接用高性能&nbsp;SSD&nbsp;有优势吗？</p><p></p><p>这两个不应该拿来比较谁替代谁，是鱼和熊掌可以兼得的关系。高性能场景下，RDMA&nbsp;搭配机械硬盘，效果不会好。反之，SSD&nbsp;盘搭配万兆的&nbsp;TCP&nbsp;网络效果也不好。高性能场景关注端到端的延时表现，需要叠加了网络的贡献和存储介质的贡献。</p><p></p><p>问题&nbsp;8:&nbsp;写更多的场景应该使用&nbsp;PFS&nbsp;吗？</p><p></p><p>是的，特别是存在大量随机写的情况。PFS&nbsp;的定位是一个完整兼容&nbsp;POSIX&nbsp;的文件系统，而&nbsp;RapidFS&nbsp;是一个缓存服务，和&nbsp;HDFS&nbsp;比较接近，对随机写的支持很弱。</p><p></p><p>本次线上分享回看链接：<a href=\"https://www.infoq.cn/video/TIyuf3Xc9F7UjYa32UoY\">https://www.infoq.cn/video/TIyuf3Xc9F7UjYa32UoY</a>\"</p><p></p><p>- - - - - - - - - - END - - - - - - - - - -</p><p>请关注微信公众号“百度智能云技术站”</p><p>以免错过后续精彩内容</p>",
    "publish_time": "2022-10-19 13:50:58",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "将信用卡号存储在调试日志中，中国快时尚平台Shein母公司因安全意识薄弱被罚190万美元",
    "url": "https://www.infoq.cn/article/20vsgCpbKSB9iDwtACff",
    "summary": "<p>&nbsp;</p><p>10月13日，中国快时尚品牌Shein(希音)和Romwe(葇薇)的母公司Zoetop Business Company, Ltd.(卓天商务有限公司)与美国纽约州总检察长莱蒂蒂亚·詹姆斯(Letitia James，又译詹乐霞)的办公室达成协定，将向纽约州支付190万美元的罚款，原因是该公司未能妥善处理波及全球数千万消费者个人信息的泄露事件，并谎报了数据泄露的严重程度。</p><p>&nbsp;</p><p>Zoetop于2018年6月遭到黑客攻击，3900万个Shein账户和700万个Romwe账户被盗，一些用户的信用卡信息以及包括姓名、电子邮件地址和帐户密码在内的个人信息遭到泄露，并被黑客在相关论坛上出售。关于账户密码，“Zoetop 用散列密码的方法，因此很容易被破解，攻击者可以通过这种方法识别原始的、未散列的密码，”纽约的调查发现。</p><p>&nbsp;</p><p>而且，该调查 [<a href=\"https://ag.ny.gov/sites/default/files/2022.10.12_zoetop_nyag_aod_final_-_fully_executed.pdf\">PDF</a>\"]还发现，每当交易遇到错误时，Zoetop 会将人们的信用卡号以纯文本形式存储在调试日志中。因此，当入侵者在 2018 年 6 月闯入该零售商的计算机时，他们也许能够在该文件中找到近 30,000 个订单的信用卡完整的详细信息。</p><p>&nbsp;</p><p>Zoetop 直到大约一个月后才意识到它的系统已被入侵。2018 年 7 月 18 日左右，一家主要的信用卡网络和另一家发卡银行联系了Zoetop，表明 Zoetop 的系统已被渗透，信用卡数据被盗。随后，Zoetop 聘请了一家网络安全公司，证实了此次泄露。</p><p>&nbsp;</p><p>在 2018 年调查结束时，这家大型零售商淡化了安全漏洞，没有强制重置密码，也没有联系所有受影响的 Shein 购物者。相反，Zoetop 只向一小部分受感染用户发送消息，大多数受到影响的消费者甚至不知道自己的信息已被泄露。Zoetop 还在新闻稿中声称有 642 万客户受到影响。</p><p>&nbsp;</p><p>最重要的是，根据纽约股份公司的说法：Zoetop 没有定期进行外部漏洞扫描，也没有定期监控或审查审计日志以识别安全事件。190万美元，大约是 300,000 件Shein出售的衣服，而&nbsp;Shein 品牌价值1000 亿美元，因此，这笔支出大概不会对这家大型零售商带来任何影响，正如一些人所说，这只是做生意的成本。</p><p>&nbsp;</p>",
    "publish_time": "2022-10-19 15:59:32",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "SUSE 推出业界首个自适应 Linux 平台原型",
    "url": "https://www.infoq.cn/article/682eb5e4f00a810c2d61f8162",
    "summary": "<p></p><h4>自适应 Linux 平台原型</h4><p></p><p></p><p>作为下一代的 Linux 平台，自适应 Linux 平台（Adaptable Linux Platform，下文简称ALP）的首个原型已经上线！该平台由 SUSE 推出，旨在让用户专注于他们的工作负载，从硬件和应用层抽离出来。通过使用虚拟机和容器技术，ALP 可以让工作负载独立于代码流。</p><p>&nbsp;</p><p>SUSE 已将其引入开源社区，并开始设计和构建一个以应用程序为中心、安全且灵活的新平台。</p><p></p><p></p><h4>ALP 的首个原型“Les Droites”</h4><p></p><p></p><p>SUSE 将 ALP 的首个原型命名为“Les Droites”，它具有以下特点：</p><p>软件：通过使用预装的 Salt 和软件仓库中的 Ansible，用户可以灵活敏捷地配置和管理 ALP 系统。硬件支持：ALP 的架构基线设置为 x86_64-v2，我们正在考虑通过 hwcaps 功能支持 x86_64-v3 和未来有可能的 v4 版本。全盘加密 ：Les Droites 带有全盘加密 (Full Disk Encryption，FDE) 的原型。尽管它可能不是最终的解决方案，但我们希望展示当前状态；当然，我们也希望听取社区意见。FDE 在硬盘驱动器上加密硬件，访问时会加密和解密；为 ALP 架构寻找和实施最佳解决方案对于项目至关重要。为了在早期版本中更轻松地进行测试和探索，Les Droites 在 SELinux 方面更加宽松；SELinux 也将被整合到未来的版本中。Podman 和 K3s 可以用作容器运行时。容器化的工作负载。</p><p>&nbsp;</p><p>尽管一些工作负载仍处于开发阶段并遵循 ALP 设计原则，但一些组件已经容器化，例如 GDM 或 Yast2；而其他组件未来也将容器化，例如 Cockpit。</p><p>&nbsp;</p><p>在 ALP 中，这些新的容器化的服务被称为 WORKLOADS。</p><p>&nbsp;</p><p>工程工作组一直在对 YaST 容器化进行一些改进，例如获得更好的 cockpit 指标、对事务性 ALP 安装的监控和 ALP 中的 YaST 设计或安全策略。</p><p>&nbsp;</p><p></p><h4>自我管理</h4><p></p><p></p><p>APL 旨在尽可能地减少干预，因此使用了一些自我管理功能，允许它识别稳定的快照，并在为系统打补丁后发现一些意外行为时进行回滚。这样才能确保 ALP 能够根据工作负载和系统本身的使用情况来应用补丁，从而保持系统的合规性。</p><p>&nbsp;</p><p>ALP 带有自我管理功能和零接触的原型，并将在下一个版本中完全实现这些功能。</p><p>&nbsp;</p><p></p><h4>零接触方法</h4><p></p><p></p><p>ALP 采用了零接触的环境、部署和配置，因此更易于设置。ALP 拥有自我修复、自我调整和自我更新的优势，这些关键特性也赋予了其自我解释的能力；对系统的更改会触发一种机制来对更改进行解读，因此不再需要额外的解释。</p><p>&nbsp;</p><p>ALP 实现了零接触。系统可以在没有干预的情况下部署、配置，对系统进行操作，这让 ALP 可以在边缘设备上运行工作负载。这将有助于实现操作系统即服务 (OSaaS)。</p><p>&nbsp;</p><p>ALP 能够确保系统符合最新的安全标准和所需的补丁级别，这是通过结合使用“热补丁“和“高可用”的功能来实现的。用户只需配置补丁的修补时间和修复的粒度，自我管理功能就能确保系统符合所需的安全标准。</p><p>&nbsp;</p><p>这些自我管理功能是可配置的，并具有以下粒度级别：</p><p>安全和定期更新安全更新重要的安全更新仅下载和手动安装没有自动更新</p><p>&nbsp;</p><p>用户可以依据这些粒度设置最佳安装计划。</p><p>&nbsp;</p><p></p><h4>自我修复</h4><p></p><p></p><p>自我管理意味着系统可以识别自身最后的稳定状态，并对意外行为或错误事件做出反应，以便回滚之前的更改。当操作系统或应用程序处于修复或更改过程中时，自我修复功能可以确保系统正常工作。</p><p>&nbsp;</p><p>ALP 使用自我修复功能来检测意外行为并返回到最后已知的稳定状态。</p><p>&nbsp;</p><p>自我修复功能不是操作系统的新组件。SUSE 已经为 MicroOS 提供了运行状况检查器，这些检查器可以用于插件的定制开发，详细功能请查看文档：https://documentation.suse.com/sle-micro/5.2/pdf/article-administration-slemicro_color_en.pdf</p><p>&nbsp;</p><p></p><h4>PoC</h4><p></p><p></p><p>PoC 应考虑以下方面：</p><p>时间框架：根据当前的开发进度，PoC 应在短期内完成（3 个月）。增值：PoC 必须包括 ALP 带来的额外价值，并区分清楚 ALP 和 SLE 带来的价值。协同共享：可以与合作伙伴和其他相关者共享 PoC 信息，市场研究人员也应包括在内。基线：ALP 应被视为 PoC 的基线，以避免内部分层。需要明确的是，PoC 不能使用 SLE + k3s的方式构建，而应将 ALP 作为基本概念，在 ALP 之上构建。限定场景：ALP 是一个概念原型，并不适用于所有场景；PoC 无需适用于所有场景或平台。</p><p>&nbsp;</p><p></p><h4>结论</h4><p></p><p>ALP 的首个原型拥有诸多特性，它将以全新的方式构建下一代的 Linux，例如隔离工作负载、充分利用现代 CPU 功能以及优化硬件性能等。</p><p>&nbsp;</p><p>用户普遍认为，在使用以应用程序为中心的、容器和虚拟化等技术时，非侵入式的系统更新将干扰常规操作。如今，从安全补丁和系统定期更新，到仅下载补丁并实施手动安装，用户都可以通过 ALP 来决定何时以何种粒度修补系统。</p>",
    "publish_time": "2022-10-19 16:34:44",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "开发者如何应对当前与未来挑战？英特尔 On 技术创新峰会给出了答案",
    "url": "https://www.infoq.cn/article/UL7BT2Cp5V96gsruK6tx",
    "summary": "<p>随着国内数字化转型的进程不断加快，软硬件协同成为了开发者以及企业寻求技术突破的重要基石。尤其在可持续发展的大趋势下，以软件定义, 芯片增强为基础的端到端数字基础架构也成为英特尔发展的核心命题。</p><p></p><p>10 月 18 日 -19 日，这场由英特尔举办、面向软硬件开发者和技术生态打造的年度盛会——英特尔 On 技术创新峰会中国在线会议成功举办。在会上，英特尔 CEO 帕特·基辛格将过去提到的<a href=\"https://www.infoq.cn/article/wU2FMRIL7ZtRJffY4XVW\">“四大超级技术力量”</a>\"融入了传感和感知，并重新定义了“五大超级力量”，即计算、连接、基础设施、人工智能以及传感和感知。</p><p></p><p>在超级力量的驱动之下，英特尔也重新思考市场对芯片设计和制造的需求，帕特·基辛格表示，代工模式也必须进化，英特尔和英特尔代工服务将开创系统级代工的时代。这一模式由四个主要部分组成：晶圆制造、封装、软件和开放的芯粒生态系统。</p><p></p><p>此外，聚焦于开发者当前及未来的挑战，英特尔还展示了一系列全新软硬件产品和服务，以帮助庞大的开发者生态系统应对挑战并实现新一代的创新。</p><p></p><h2>聚集解决开发者遇到的六大挑战</h2><p></p><p></p><p>在开幕主题演讲中，<a href=\"https://www.infoq.cn/article/07JFquThmH4DbC9iMqIx\">帕特·基辛格</a>\"提出了开发者所面临的挑战：如开发周期紧张；AI 模型开发门槛过高；游戏开发复杂；创造性开发耗时；不同种类的工作无法跨设备互通等问题。在提出挑战的同时，英特尔也提供了一系列解决方案：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/13/1397710a39c713dcd922ca92ff0645e5.png\" /></p><p></p><p>英特尔开发者云平台（Intel Developer Cloud）即将扩展支持全新技术：据悉，将推出限量测试版，包括第四代英特尔至强可扩展处理器（Sapphire Rapids）、英特尔 Habana® Gaudi®2、IPU 最新成果等等。</p><p></p><p>更快速、更轻松地构建计算机视觉 AI 模型：为了解决人工智能模型开发缓慢、昂贵等问题，英特尔建立了一个计算机视觉平台——英特尔 Geti 计算机视觉平台（此前代号为 Sonoma Creek），让开发者能够有效地协作和构建模型，加速企业实现数字化转型。通过数据上传、标注、模型训练和再训练的单一接口，英特尔 Geti 计算机视觉平台可以助力开发团队减少模型开发所需时间，并降低 AI 开发技术门槛及开发成本。</p><p></p><p>台式机处理器性能的新标准：第 13 代英特尔® 酷睿™ 台式机处理器家族的旗舰产品 i9 13900K 上市，它充分利用了能效核和性能核的混合架构，能效核和性能核在高性能混合架构中相互配合，可提供卓越的多线程性能，能在游戏体验、直播体验等方面给用户带来更好地提升。</p><p></p><p>多种设备，同一体验：英特尔多设备协同技术（Intel® Unison™）是全新的软件解决方案，可促进开放生态系统的发展，首次实现了手机（Android/iOS）和电脑之间的无缝交互，包括文件传输、短信、电话和手机通知等功能。据了解，宏基、惠普、联想等合作伙伴将发布支持该技术的新款笔记本电脑。</p><p></p><h2>以开放性赋能开发者</h2><p></p><p></p><p>英特尔首席技术官 Greg Lavender 在会上提到：“Evans Data Group 于 2021 年末开展的“全球开发者调查”结果显示，在全球 2,500 万名开发者中，有 90% 的开发者在使用英特尔开发或为英特尔平台优化的软件。”</p><p></p><p>英特尔不仅在固件、BIOS 和软件栈的基础层提供了多种软件创新设计，还为整个开源生态系统提供了涵盖所有主流技术的优化代码，并与 ISV（独立软件开发商）和商业合作伙伴保持着紧密协作，以使他们的产品可以在英特尔的整个处理器产品家族上（CPU/GPU/FPGA ）上流畅运行。</p><p></p><p>据悉，英特尔即将发布 2023 版英特尔 oneAPI 工具包，该工具包总共包含 42 种不同的工具，这些工具包全面支持第四代英特尔®至强® 可扩展处理器、英特尔数据中心、锐炫™GPU 以及 Agilex™FPGA。</p><p></p><p>同时，英特尔宣布在六个教育和研究机构新增成立 oneAPI 卓越中心，包括北京大学软件与微电子学院、英国科学与技术设施理事会、以色列理工学院、与劳伦斯利弗莫尔国家实验室合作的犹他大学、加州大学圣地亚哥分校和柏林楚泽研究所，以拓展 oneAPI 对重要应用的支持，同时还将开发更多的 oneAPI 课程。</p><p></p><p>对于希望以快速、高效及特定行业方式打造 AI 解决方案的开发者，英特尔发布了三套用于医疗行业的全新 AI 参考套件，将能够帮助临床医生检查医疗代码分类、识别医学影像异常，简化报销审查。</p><p></p><p>总而言之，英特尔一直在秉承着开放的理念，大力推动开源、开放的生态系统协作。从另一个角度来说，软件开源优先原则也在很大程度上促进了开源生态在英特尔架构平台的健康发展。这种面向软件开发的开放式方法以及英特尔所推动的硬件标准化，能够加速生态及全体的发展和创新。</p><p></p><h2>英特尔在 GPU 领域有哪些重要进展？</h2><p></p><p></p><p>在算力需求暴增的当下，高性能 GPU 不仅变成了驱动新兴行业发展的算力基石，也成为了英特尔实现增长的重要引擎。在本次英特尔 On 技术创新峰会上，帕特·基辛格分享了英特尔在 GPU 领域的不同进展，其中，英特尔®数据中心 GPU（代号为 Ponte Vecchio）与集成高带宽内存的 Sapphire Rapids，一起构成了极光超级计算机的核心计算引擎。目前，英特尔已将安装有这两款芯片的刀片式服务器交付给阿贡国家实验室。</p><p></p><p>英特尔数据中心 GPU Flex 系列：这款产品可处理各种与之相关的工作负载，包括视觉云任务、媒体转码、云游戏以及人工智能推理和训练。这款 GPU 集成了基于硬件的 AV1 编码器，实现了 30% 以上的码率提升。在单个平台还可以支持更多路视频流，云服务提供商可以通过各种方式利用这款解决方案获得显著的收益。同时它提供了开放和全栈式的 API 支持。目前，Flex 系列不仅支持 oneAPI，还支持 TensorFlow、OpenVINO 和 PyTorch 等其他框架。</p><p></p><p>英特尔锐炫 GPU，面向游戏玩家：英特尔致力于通过锐炫显卡家族为游戏玩家提供价格与性能平衡之选。据了解，英特尔锐炫™ A770 已于 10 月 12 日（美国）以 329 美元的零售价上市。</p><p></p><h2>写在最后</h2><p></p><p></p><p>纵观整场大会，我们看到了英特尔在开放生态上的努力和投入，无论是芯片、系统、应用还是软件堆栈等各个层级，都在贯彻“助力开发者加速创新”的主线。就如同英特尔首席技术官 Greg Lavender 所说：“我们是开发者社区的忠实成员，通过共同创新和协作，英特尔软硬件的广度和深度将为所有人带来源源不断的机会。”</p><p></p><p>未来，软硬件开发者将在英特尔提供的产品与服务之下，迎来怎么样的技术创新？让我们共同期待。</p><p>想要了解更多英特尔 On 技术创新峰会的精彩内容？<a href=\"https://event.intel.cn/intelon2022#/?tc=w16mwjlqp6\">即刻点击链接观看大会视频</a>\"，进一步了解英特尔最新的创新技术。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c5/c5afec09df50317b7d944eb2ad842aae.jpeg\" /></p><p></p>",
    "publish_time": "2022-10-19 17:19:41",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "编程神器Copilot逐字抄袭他人代码？GitHub 回应：相似，但不同......",
    "url": "https://www.infoq.cn/article/INY1NFPzkCR0p6KhLe4a",
    "summary": "<p>自面世后就饱受争议的 GitHub Copilot 编程神器最近又遭遇舆论风暴。</p><p></p><p>日前，德州农工大学的一位计算机科学教授Tim Davis在<a href=\"https://twitter.com/docsparse/status/1581461734665367554\">推特上发文</a>\"称， GitHub Copilot 在没有标注来源也没有 LGPL 许可的情况下，输出了大量应该受版权保护的代码。</p><p></p><p>Tim Davis 还发了自己和 GitHub Copilot 在稀疏矩阵转置、稀疏矩阵加法的代码对比，并表示两者几乎一模一样，高度雷同。Tim Davis 的推文引发热议，System76 技术总监认为这算是GitHub Copilot 非法洗代码行为。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a2/a20e2f5aec5db6e9595378594593f6b4.png\" /></p><p>左边是该名教授的代码，右边是GitHub Copilot的。</p><p></p><p>对此，GitHub Copilot 的发明者 Alex Graveley <a href=\"https://twitter.com/alexgraveley/status/1581762356207841281\">回应</a>\"道，Tim Davis 写的代码和 Copilot 产生的代码不同，“相似，但不同”。他还提到，如果有人能提供一种方法可以自动识别代码是由某一方衍生出来的，那就可以申请专利了。</p><p></p><p>Alex Graveley 表示，到目前为止 GitHub Copilot 已被指控了诸多问题，包括剽窃代码、引入漏洞、代码不完美、太分散注意力、甚至让人变笨等等。他强调道，“我认为程序员永远不会被取代。Copilot 使人们的工作效率更高。”</p><p></p><h2>起诉 GitHub Copilot</h2><p></p><p><a href=\"https://www.infoq.cn/article/t8IQeLNmRP6sx8uVtSDO\">Copilot&nbsp;</a>\"是一款 AI 结对编程工具，它的主要定位是提供代码补全与建议功能。它是 Visual Studio Code 的一个插件，可根据当前文件的内容和当前光标位置为你自动生成代码。而版权问题是 Copilot&nbsp;从一推出就面临的挑战，人们质疑它在 GitHub 上发布的公开代码上进行训练的合法性。</p><p></p><p>除了 Alex Graveley 的“怒怼”，这两天在 HackerNews 上引起热议的还有<a href=\"https://githubcopilotinvestigation.com/\">另一篇内容</a>\"《也许你并不在乎 GitHub Copilot 在未经许可之下使用你的开源代码，但如果 Copilot 要抹除整个开源社区，你又将作何感想？》，这篇文章来源于一位名叫 Matthew Butterick 的律师，同时他也是一名程序员。</p><p></p><p>作为程序员，Matthew 从 1998 年起就在专业参与开源软件贡献，期间还在 Red Hat 工作过两年。最近，他又成了 Racket 的贡献者。他写过文章宣传 Lisp，也出过介绍编程语言开发的书，还发布过不少开源软件，包括专门用来出版线上书籍的Pollen，以及他自己在工作中经常使用的 AI 软件。</p><p></p><p>今年 6 月，在 GitHub Copilot 正式推出的时候，Matthew 写了一篇关于Copilot 违法问题的文章。而最近，Matthew 决定采取下一步行动，重新激活了自己的加州律师协会会员资格，并和几位律师发起了新的项目——针对 GitHub Copilot 违反对开源作者及最终用户的法律义务一事开展调查，并考虑进行诉讼。</p><p></p><h2>Copilot的问题在哪？</h2><p></p><p></p><p>首先要说明的是，Copilot 跟传统自动补全功能有何区别？简单来讲，Copilot 由 Codex 进行支持，而 Codex 则是由 OpenAI 构建并授权给微软的 AI 系统（微软常被称为「OpenAI的非官方所有者」）。Copilot 能根据用户输入的文本 prompt 提供建议，而且与只能提示细节建议的传统工具不同，Copilot 可以提供更大的代码块，包括函数的完整主体。</p><p></p><p>但作为底层 AI 系统，Codex 是怎么被训练出来的？据 OpenAI 的介绍，Codex 接受了“数以千万计的公共repo”的训练，其中当然包括 GitHub 上的代码。微软的说辞则较为含糊，只提到“数十亿行公共代码”。不过 Copilot 研究员 Eddie Aftandilian 最近已经在播客中证实，Copilot 确实是“由 GitHub 上的公共 repo 训练而成”。</p><p></p><p>Matthew 认为，“Copilot 在系统训练与系统使用方面都存在法律问题。”</p><p></p><h4>系统训练</h4><p></p><p></p><p>绝大多数开源软件包是在授权许可之下发布的，在授予用户一定权利的同时也要求其承担一定义务（例如保留源代码的精确属性）。而这种授权的合法实现方式，就是由软件作者在代码中声明版权。</p><p></p><p>因此，要想使用开源软件，大家就必须做出选择：</p><p></p><p>要么遵守许可证所规定的义务；要么使用那些属于许可证例外的代码（即版权法所规定的「合理使用」情形）。如果微软和 OpenAI 决定基于各 repo 的开源许可来使用这些训练素材，那就得发布大量属性（attribution），这已经算是各类开源许可的底线要求。但截至目前，大家都还没有看到任何属性声明。</p><p></p><p>微软和 OpenAI 必须找到“合理使用”的理由。GitHub 前 CEO Nat Firedman 就曾在 Copilot 的技术预览会上提到，“在公开数据上训练（机器学习）系统属于合理使用的范畴。”</p><p></p><p>然而，软件自由保护组织（SFC）明显不同意他的观点，并要求微软方面提供能支持其立场的证据。保护组织负责人 Bradley Kuhn 指出：</p><p></p><p></p><blockquote>我们曾在 2021 年 6 月私下询问过 Firedman 和其他几位微软/GitHub代表，要求他们为 GitHub 的公开法律立场提供可靠的参考依据……但他们什么都拿不出来。</blockquote><p></p><p></p><p>事实上，目前全美还没有哪个判例能够直接解决 AI 训练中的“合理使用”问题。另外，所有涉及“合理使用”的案例均权衡了大量相关因素。即使法院最终判定某些类型的 AI 训练属于“合理使用”，也不代表其他类型的训练就能“无脑照办”。就目前来看，还不知道 Copilot 和 Codex 到底合不合法，微软和 OpenAI 其实也说不准。</p><p></p><h4>系统使用</h4><p></p><p>虽然没法确定“合理使用”最终要怎么在 AI 训练中落地，但可以想象，其结果并不会影响到 Copilot 用户。为什么呢？因为用户只是在使用 Copilot 提供的代码，而这部分代码的版权和许可状态同样模糊不清。</p><p></p><p>微软倒是有自己的说法。2021年，Nat Friedman 曾声称 Copilot 的输出结果归属于操作者，其性质与使用编译器一样。但 Copilot 已经暗暗给用户挖好了坑。</p><p></p><p>微软将 Copilot 输出描述为一系列代码“建议”，并强调不会对这些建议“主张任何权利”。但与此同时，微软也不会对由此生成的代码的正确性、安全性或延伸出的知识产权问题做任何保证。所以只要接纳了 Copilot 的建议，那这些问题就都要由用户自己承担：</p><p></p><p></p><blockquote>您需要对自己代码的安全性和质量负责。我们建议您在使用由 GitHub Copilot 生成的代码时，采取与使用其他一切非本人所编写代码相同的防范措施，包括严格测试、IP（知识产权）扫描和安全漏洞跟踪。</blockquote><p></p><p></p><p>这样一来，可能会产生什么纠葛？用户控诉，就像上文中 Tim Davis 控诉的这起抄代码事件。</p><p></p><p>理论上，Copilot 使用他的代码，当然会产生相应的许可遵守义务。但从 Copilot 的设计来看，用户完全接触不到代码的来源、作者和许可证。</p><p></p><p>从这个角度看，Copilot 的代码检索方法就像一颗烟雾弹，下面掩盖的是另一种真相：Copilot 本身，只是连通海量开源代码的一套替代接口。只要用上它，用户可能就需要承担起代码原作者提出的许可义务。</p><p></p><p>意识到这一点，Nat Firedman 所谓 Copilot“就像是编译器”的说法就会变得不靠谱。毕竟编译器只会改变代码形式，但绝不会注入新的知识产权属性。</p><p></p><h2>Copilot 对于开源社区意味着什么？</h2><p></p><p></p><p>Matthew 认为，通过将 Copilot 当作海量开源代码的替代接口，微软不仅借此切断了开源作者与用户之间的法律关系，甚至建立起新的“围墙花园”——阻止程序员接触传统开源社区，从而消除了他们为之贡献的可能性。随着时间推移，这势必会让开源社区变得愈发贫乏。</p><p></p><p>用户的注意力和参与方向将逐渐朝着 Copilot 转移，最终彻底告别开源项目本身——告别源代码repo、告别问题跟踪器、告别邮件列表、告别讨论板。这样的变化必将给开源带来痛苦、甚至永远无法挽回的损失。</p><p></p><p>“包括我自己在内的开源开发者之所以提出抗议，所图的绝不是钱。我们只是不想让自己的努力贡献被白白浪费掉。开源软件的核心在于人，在于由人组成的用户、测试者和贡献者社区。正是因为有了这样的社区，我们才能以超越自身的方式改进软件，让工作充满乐趣。”Matthew 进一步说道，Copilot 向开源软件注入了自私的基因：我想要什么，你就得给我什么。</p><p></p><p>他最后强调道：“我们反对的绝不是 AI 辅助编程工具，而是微软在 Copilot 当中的种种具体行径。其实微软完全可以把Copilot做得更开发者友好一些——比如邀请大家自愿参加，或者由编程人员有偿对训练语料库做出贡献。但截至目前，口口声声自称热爱开源的微软根本没做过这方面的尝试。另外，如果大家觉得 Copilot 效果挺好，那主要也是因为底层开源训练数据的质量过硬。Copilot 其实是在从开源项目那边吞噬能量，而一旦开源活力枯竭，Copilot 也将失去发展的依凭。”</p><p></p><p>参考链接：</p><p><a href=\"https://githubcopilotinvestigation.com/\">https://githubcopilotinvestigation.com/</a>\"</p><p><a href=\"https://twitter.com/docsparse/status/1581461734665367554\">https://twitter.com/docsparse/status/1581461734665367554</a>\"</p><p><a href=\"https://devclass.com/2022/10/17/github-copilot-under-fire-as-dev-claims-it-emits-large-chunks-of-my-copyrighted-code/\">https://devclass.com/2022/10/17/github-copilot-under-fire-as-dev-claims-it-emits-large-chunks-of-my-copyrighted-code/</a>\"</p>",
    "publish_time": "2022-10-19 18:04:37",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "81% 的 IT 团队被公司高层指示要减少或停止云支出",
    "url": "https://www.infoq.cn/article/mMtEqAXuvF7Weml1GROL",
    "summary": "<p>根据Wanclouds的一项<a href=\"https://wanclouds.net/resources/reports/2022_Cloud_Cost_Optimization_Outlook.pdf\">新研究</a>\"，81% 的 IT 管理者表示，随着成本飙升和市场下行，他们的最高管理层已经指示他们要减少或不承担额外的云支出。调查结果显示，在过去的五年中，<a href=\"https://www.infoq.cn/article/vS5Dy4ZjNg57bkGohJ9c\">云计算行业</a>\"蓬勃发展，并且很多企业在疫情之初开始进行数字化转型，云计算这两年也是“风生水起”。但如今，随着有关经济衰退的讨论持续升温，企业的云计算支出可能会有所减少——总之，在过去的两个季度里，企业的计划被打乱了。</p><p></p><p>由于市场动荡，通货膨胀和利率的上升，以及对潜在经济衰退的担忧，给企业带来了越来越大的财务和运营压力。因此，在<a href=\"https://www.infoq.cn/article/A7aMYdry8qfHpSu44t5j\">云计算支出</a>\"被拿出来细看之后，许多公司正在重新评估他们的“数字化雄心”，质疑是否在以最有效的方式用掉云费用。据报道，苹果公司每月花在亚马逊云计算上的费用超过3000万美元。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f5/f54ed9926e94fb9e698e828d4598d5aa.png\" /></p><p></p><p>Wanclouds的报告《2022年下半年云计算成本和优化展望》中，探讨了 IT 团队目前面临的这一挑战，以及他们面临的来自高层和财务部门的财务压力。</p><p></p><p>报告指出，IT 决策者正在采取行动控制成本，39% 的人指出他们已经决定将大量的云消耗和高性能工作负载迁移或留在本地，还有 29% 的人表示他们在2022年上半年由于价格贵而更换了公有云厂商。</p><p></p><p>行业对混合云和多云基础设施的支持程度，也对云支出的可见性和追踪提出了挑战，因为混合云和多云基础设施的管理可能更加复杂。</p><p></p><p>例如，随着容器越来越多地被用作混合云战略的首选平台，70% 的采用 Kubernetes 的企业表示它增加了他们的整体云支出。此外，每 10 位 IT 管理者中，只有略多于 4 位表示他们今天对整个云环境的成本和消耗是有了解的。</p><p></p><p>参考链接：</p><p><a href=\"https://venturebeat.com/data-infrastructure/report-81-of-it-teams-directed-to-reduce-or-halt-cloud-spending-by-c-suite/\">https://venturebeat.com/data-infrastructure/report-81-of-it-teams-directed-to-reduce-or-halt-cloud-spending-by-c-suite/</a>\"</p>",
    "publish_time": "2022-10-19 19:17:10",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]