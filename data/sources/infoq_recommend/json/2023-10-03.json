[
  {
    "title": "最好的Go框架就是不用框架？",
    "url": "https://www.infoq.cn/article/mUsFwe8rprGl9V5Sh2a9",
    "summary": "<p>&nbsp;撰写本文时，我已经领导Go团队好多年了。我从初学者那里听到的最常见的问题是：我应该使用什么框架？</p><p>&nbsp;</p><p>在使用Go的过程中最糟糕的事情之一就是遵循其它编程语言的方法。其它语言已经建立了“默认”框架：Java的默认框架是Spring，Python的默认框架是Django和Flask，Ruby的默认框架是Rails，C#的默认框架是ASP.NET，Node的默认框架是Express，PHP的默认框架是Symfony和Laravel。而Go不同：没有默认框架。</p><p>&nbsp;</p><p>更有趣的是，许多人建议你根本不应该（在Go中）使用框架。他们疯了吗？</p><p>&nbsp;</p><p></p><h2>Go语言的哲学</h2><p></p><p>&nbsp;</p><p>Go框架是存在的，但没有一个Go框架提供项其它语言框架那样的功能集。这点短期内不会改变。你可能认为这是因为Go生态系统比较“年轻”。但是还有一个更重要的因素。Go是围绕Unix哲学构建的：</p><p>&nbsp;</p><p>一个程序只做一件事并把它做好。程序间协同工作。编写程序来处理文本流，因为这是一个通用接口。</p><p>&nbsp;</p><p>这个理念来自B编程语言（C语言的前身）的设计者肯·汤普森（Ken Thompson），他也是Go语言的设计者。</p><p>&nbsp;</p><p>在实践中，Unix哲学倾向于构建小而美的软件，而不是大而全的软件。你可以在你的终端中看到这些例子。例如：cat example.txt | sort | uniq 。cat 从文件中读取文本，sort 对行进行排序，uniq 删除重复行。所有命令都是独立的且只做一件事。这直接来自Unix哲学。得益于这样的设计，你可以独立开发比较小的自治命令。</p><p>&nbsp;</p><p>在Go中，Unix哲学在标准库中随处可见。最好的例子是应用最广泛的接口：io.Reader 和io.Writer 。最好的库都遵循这种哲学。</p><p>&nbsp;</p><p>框架的设计违背这种哲学理念。通常，它们试图在一个框架内涵盖所有可能的用例。它们不是为了与其它工具一起使用而设计的，而且通常无法复用。这意味着不可能将开发成果转移到其它不兼容的框架。如果框架的采用率很低（或者就是死了），那所有的努力都白费了。</p><p>&nbsp;</p><p></p><h2>对你来说，什么是重要的</h2><p></p><p>&nbsp;</p><p>每个技术决策都有权衡，你的选择要对你和你的项目更有意义。</p><p>&nbsp;</p><p>当你在从事一个短期项目（比如用时不到一周且用完即扔的概念验证项目）时，有些方案是有意义的。在这种情况下，最关键的因素是你能多快地完成它。但是如果你在从事一个持续很长时间的项目，并且你要与多人一起协作，那么这个决定的影响是巨大的。</p><p>&nbsp;</p><p>对于大多数项目，最重要的参数是：</p><p>&nbsp;</p><p>你能以多快的速度启动项目从长远来看，你能以多快的速度开发项目对于未来的变化，项目的灵活度（这与前两点紧密相关）。</p><p>&nbsp;</p><p>让我们开始评估我们的决定。</p><p>&nbsp;</p><p></p><h3>节省时间</h3><p></p><p>&nbsp;</p><p>框架最大的好处之一就是节省时间。运行一个命令就可以得到一个功能齐全的项目。框架通常提供一个固定结构的项目，而且如果你不知道如何做，它会有很大帮助。但与大多数其他技术决策一样，它不是没有代价的。</p><p>&nbsp;</p><p>随着时间的推移，当项目增长时，你会很快触及框架在约定和限制方面的墙壁。框架作者的需求跟你的需求可能有所不同。框架创建者采取的决策可能适用于简单的CRUD应用程序，但无法处理更复杂的场景。如果继续使用，很容易就为了克服一个框架限制而迅速失去在项目启动上节省的所有时间。随着时间的推移，这可能会导致团队遇到很多挫折。</p><p>&nbsp;</p><p>几年前，我在一家使用Go框架（我会略过框架名称）的初创公司工作。这家公司正在成长并创建新的服务。随着时间的推移，当我们想要支持的复杂用例越多时，我们就感到越痛苦。这个框架也是严重Bugs的来源。不幸的是，摆脱这个框架并不容易。</p><p>&nbsp;</p><p>有一次，一些框架组件变得无法维护，与生态系统的其它部分不可兼容。我们被迫摆脱这个框架，而这个框架已经与整个系统紧密耦合。将其从数十个服务中移除是一个不小的任务，这需要一个跨团队的计划、需要多人数月的时间和努力，才能摆脱这个框架。即使这个项目最后成功了，我也不认为整个事情是成功的。如果有人更早做出不同的决定，所有花费的时间可以被利用得更好。整个项目都不是必要的。许多公司对开发团队缺乏信任也就并不令人奇怪了。</p><p>&nbsp;</p><p>这是一个很好的例子，表明了一个小小的决定会在数年后变成一个代价高昂的需要“救援”的项目。</p><p>&nbsp;</p><p></p><p><img src=\"https://uploader.shimo.im/f/nvIfdlEShDJNYzu2.png!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU4MDc1NjQsImZpbGVHVUlEIjoidlZxUk1qalZ4R0M4ZzkzeSIsImlhdCI6MTY5NTgwNzI2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyNDM2MDc5MH0.QJqf80ffAIWs5K7QCIaZHfE1yYtdgOn7IxgYC5sRYR0\" /></p><p></p><p></p><h3>项目的可维护性</h3><p></p><p>衡量项目的可维护性是一个有争议的话题——很难比较两个项目的可维护性。有些人说框架很棒，他们没有感到使用框架的痛苦。对其他人来说，框架可能是长期以来最大的噩梦。有些项目比其他项目更具挑战性，许多人认为与框架较劲只是工作的一部分。这就是为什么很难客观地衡量框架对项目可维护性的影响。</p><p>&nbsp;</p><p>幸运的是，我们可以用一点科学知识来理解它。基于科学研究的《Accelerate： The Science of Lean Software and DevOps》一书，聚焦于找出表现最好和表现最差的团队的特点。对我们来说重要的是，良好性能的最重要的一个因素就是松耦合架构。</p><p>&nbsp;</p><p>我领导的团队经常问我，“如何知道我们的架构是松耦合的”，最简单的方法之一是确保应用程序的部件可以轻易替换或删除。如果你的应用程序的部件很难删除，那么你的应用程序就是紧耦合的。这样的紧耦合会导致牵一发而动全身，引发多米诺效应。</p><p>&nbsp;</p><p>为什么松耦合架构如此重要？需要承认，我们都是人，即使经过了最好的调研，我们也会犯错。当你选择了错误的库或框架，应该很容易替换而不需要重写整个项目。如果我们想要节省时间，我们应该考虑从长期来看有什么帮助，而不仅仅是在项目开始时。</p><p>&nbsp;</p><p>请考虑一个场景，当你想要完全删除一个框架时，需要重写大量代码吗？它可以在多个服务上独立运行吗？如果不行，那么你需要花些精力将框架和核心逻辑分开。但是，这会牺牲框架一开始时带来的“省时”。</p><p>&nbsp;</p><p></p><h2>备选方案？构建服务时不用框架</h2><p></p><p>&nbsp;</p><p>你可能会觉得，在没有框架的情况下构建服务需要很长时间，尤其是如果你之前使用其它编程语言。我理解这一点，几年前当我开始用Go写程序时，我也有相同的感受。但是，不用框架并不意味着你自己需要构建一切东西，有许多经过验证的库会提供你需要的功能。</p><p>&nbsp;</p><p>这意味着，你需要在调研上多花一点儿精力。如果你正在阅读本文，那你就已经在调研了！几个小时的调研时间在整个项目的生命周期中几乎不值一提。你这样做所带来的灵活性，很快会将你调研所花的时间“挣”回来。</p><p>&nbsp;</p><p>如果你决定不使用框架，应该怎么办？一开始最大的障碍可能是如何构建一个服务。最简单的方法是一开始将所有东西放到一个文件中。你可以简单地开始，推迟一些决定，然后随着时间的推移演化你的项目。</p><p>&nbsp;</p><p>如果有示例项目可以作为参考，那么这会很有帮助。你可以看看我在<a href=\"https://www.youtube.com/watch?v=6Zgi5nUPf70\">GoRemoteFest</a>\"&nbsp;–&nbsp;<a href=\"https://github.com/roblaszczak/goremotefest-livecoding\">github.com/roblaszczak/goremotefest-livecoding</a>\"上的演讲“让我们用Watermill在15分钟内构建一个事件驱动应用程序”所用的项目。这个示例项目只需要两个外部库就可以运行了。</p><p>&nbsp;</p><p>请随意copy这个代码库并根据你的需要调整，我确信这个示例不会有你项目所需的全部的库。我们发布了一篇文章介绍可以用来构建Go服务的Go库清单。这些库我们已经用了几年了，还解释了我们为什么使用这些库，以及如何识别类似的库是好还是坏。</p><p>&nbsp;</p><p>文章链接：</p><p><a href=\"https://threedots.tech/post/list-of-recommended-libraries/\">https://threedots.tech/post/list-of-recommended-libraries/</a>\"</p><p>&nbsp;</p><p>当你的项目变得越来越复杂，而且你已经知道了你的库是如何协同工作的，那么你就可以开始重构它了。最后，你可能不需要那些看起来很关键的框架功能。得益于此，你可以得到一个更简单的项目并进行更少的调研。</p><p>&nbsp;</p><p></p><h2>总结</h2><p></p><p>&nbsp;</p><p>决定如何构建服务不是你应该走捷径的地方。从长远来看，做出错误的决定会对你的时间产生非常负面的影响。它会对团队的速度产生负面影响，更重要的是会影响士气。</p><p>&nbsp;</p><p>在做出错误的决定后，你很快就会陷入沉没成本谬论的陷阱。与其成为解决自己制造的问题的英雄，我们应该避免制造这些问题。</p><p>&nbsp;</p><p>&nbsp;</p><p>作者介绍：</p><p>&nbsp;</p><p><a href=\"https://twitter.com/roblaszczak\">Robert Laszczak</a>\" 是<a href=\"http://slashid.dev/\">SlashID</a>\"的首席工程师、三点实验室（<a href=\"https://threedotslabs.com/\">Three Dots Labs</a>\"）的联合创始人、<a href=\"https://github.com/ThreeDotsLabs/watermill\">Watermill</a>\"库的创建者。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://threedots.tech/post/best-go-framework/\">The Best Go framework: no framework?</a>\"</p>",
    "publish_time": "2023-10-03 07:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "新型威胁：探索LLM攻击对网络安全的冲击",
    "url": "https://www.infoq.cn/article/dGfCQZjo2v6rAicehPmd",
    "summary": "<p>来自<a href=\"https://www.cmu.edu/\">卡内基梅隆大学（CMU）</a>\"的研究人员发布了<a href=\"https://llm-attacks.org/\">LLM Attacks</a>\"，这是一种可以针对各种大型语言模型（LLM）构建对抗性攻击的算法，包括<a href=\"https://chat.openai.com/\">ChatGPT</a>\"、<a href=\"https://claude.ai/\">Claude</a>\"和<a href=\"https://bard.google.com/\">Bard</a>\"。这些自动生成的攻击，在GPT-3.5和GPT-4上的成功率为84%，在<a href=\"https://www.infoq.com/news/2023/06/google-palm2-bard/\">PaLM-2</a>\"上的成功率为66%。</p><p>&nbsp;</p><p>与大多数“越狱”攻击通过试错手工构建不同，CMU的团队设计了一个三步流程来自动生成提示后缀，它们可以绕过LLM的安全机制，导致有害的响应。而且，这些提示还是可转移（transferrable）的，也就是说，一个给定的后缀通常可以用于许多不同的LLM，甚至是闭源模型。为了衡量算法的有效性，研究人员创建了一个名为AdvBench的基准测试；在此基准测试上进行评估时，LLM攻击对Vicuna的成功率为88%，而基线对抗算法的成功率为25%。根据CMU团队的说法：</p><p></p><p></p><blockquote>最令人担忧的也许是，目前尚不清楚LLM提供商是否能够完全修复此类行为。在过去的10年里，在计算机视觉领域，类似的对抗性攻击已经被证明是一个非常棘手的问题。有可能深度学习模型根本就无法避免这种威胁。因此，我们认为，在增加对此类人工智能模型的使用和依赖时，应该考虑到这些因素。</blockquote><p></p><p>&nbsp;</p><p>随着ChatGPT和GPT-4的发布，<a href=\"https://arxiv.org/abs/2305.13860\">出现了许多破解这些模型的技术</a>\"，其中就包括可能导致模型绕过其保护措施并输出潜在有害响应的提示。虽然这些提示通常是通过实验发现的，但LLM Attacks算法提供了一种自动创建它们的方法。第一步是创建一个目标令牌序列：“Sure, here is (content of query)”，其中“content of query”是用户实际输入的提示，要求进行有害的响应。</p><p>&nbsp;</p><p>接下来，该算法会查找可能导致LLM输出目标序列的令牌序列，基于贪婪坐标梯度（GCG）算法为提示生成一个对抗性后缀。虽然这确实需要访问LLM的神经网络，但研究团队发现，在许多开源模型上运行GCG所获得的结果甚至可以转移到封闭模型中。</p><p>&nbsp;</p><p>在<a href=\"https://www.cmu.edu/news/stories/archives/2023/july/researchers-discover-new-vulnerability-in-large-language-models\">CMU发布的一条介绍其研究成果的新闻</a>\"中，论文合著者Matt Fredrikson表示：</p><p></p><p></p><blockquote>令人担忧的是，这些模型将在没有人类监督的自主系统中发挥更大的作用。随着自主系统越来越真实，我们要确保有一种可靠的方法来阻止它们被这类攻击所劫持，这将非常重要……现在，我们根本没有一个令人信服的方法来防止这种事情的发生，所以下一步，我们要找出如何修复这些模型……了解如何发动这些攻击通常是建立强大防御的第一步。</blockquote><p></p><p>&nbsp;</p><p>论文第一作者、<a href=\"https://twitter.com/andyzou_jiaming/status/1684766184871546881\">CMU博士生Andy Zou在推特上谈到了这项研究</a>\"。他写道：</p><p></p><p></p><blockquote>尽管存在风险，但我们认为还是应该把它们全部披露出来。这里介绍的攻击很容易实现，以前也出现过形式类似的攻击，并且最终也会被致力于滥用LLM的团队所发现。</blockquote><p></p><p>&nbsp;</p><p><a href=\"https://twitter.com/DavidSKrueger/status/1684904671914115072\">剑桥大学助理教授David Krueger回复了Zou的帖子</a>\"，他说：</p><p></p><p></p><blockquote>在图像模型中，10年的研究和成千上万的出版物都未能找出解决对抗样本的方法，考虑到这一点，我们有充分的理由相信，LLM同样会如此。</blockquote><p></p><p>&nbsp;</p><p>在Hacker News上关于这项工作的讨论中，<a href=\"https://news.ycombinator.com/item?id=36921808\">有一位用户指出</a>\"：</p><p></p><p></p><blockquote>别忘了，本研究的重点是，这些攻击不需要使用目标系统来开发。作者谈到，攻击是“通用的”，他们的意思是说，他们可以在自己的计算机上完全使用本地模型来生成这些攻击，然后将它们复制并粘贴到GPT-3.5中，并看到了有意义的成功率。速率限制并不能帮你避免这种情况，因为攻击是在本地生成的，而不是用你的服务器生成的。你的服务器收到的第一个提示已经包含了生成好的攻击字符串——研究人员发现，在某些情况下，即使是对GPT-4，成功率也在50%左右。</blockquote><p></p><p>&nbsp;</p><p>GitHub上提供了代码，你可以在AdvBench数据上重现<a href=\"https://github.com/llm-attacks/llm-attacks\">LLM Attacks实验</a>\"。项目网站上还提供了几个对抗性攻击的<a href=\"https://llm-attacks.org/\">演示</a>\"。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/08/llm-attack/\">https://www.infoq.com/news/2023/08/llm-attack/</a>\"</p>",
    "publish_time": "2023-10-03 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AI、ML、数据工程新闻汇总：Stable Chat、Vertex AI、ChatGPT 及 Code Llama",
    "url": "https://www.infoq.cn/article/NL4liAf7mSLGhMcI1I9q",
    "summary": "<p></p><h3>Stability AI 发布 Stable Chat</h3><p></p><p></p><p>新颖的 AI 聊天平台 <a href=\"https://www.infoq.com/news/2023/08/stable-chat/?topicPageSponsorship=b2206c17-c7cf-47e8-aee9-0514a0817c31\">Stable Chat</a>\"，以用户对话体验的稳定性与一致性为设计重点。由 <a href=\"https://stability.ai/blog/stable-chat-research-defcon-ai-village\">Stability AI</a>\" 开发，该平台意在通过可靠而非创造性生成或不可预测的回答，降低以 AI 为驱动力的对话中可能出现的错误信息和误解。</p><p>&nbsp;</p><p>这一方式可用于医疗保健和客户支持等关键领域。在这些领域中，保持沟通的清晰性和正确性至关重要。该平台对稳定性独树一帜的关注，使其成为 AI 聊天机器人和对话代理行业不断发展的新亮点。</p><p></p><h3>Vertex AI 搜索与对话已全面上线</h3><p></p><p></p><p>谷歌云的<a href=\"https://www.infoq.com/news/2023/09/vertex-ai-search-conversation/\">Vertex AI 搜索与对话</a>\"服务已正式全面上线。这项开发技术可使企业利用 AI 驱动的搜索和对话功能增强其应用程序，促进与用户更为直观且高效的互动。凭借语义搜索和自然语言理解等功能，Vertex AI 搜索与对话服务允许企业构建智能搜索引擎与对话代理，提供相关性更高的信息并与用户进行自然的对话。</p><p>&nbsp;</p><p>此次发布标志着各行业在利用 AI 与机器学习技术提供客户体验与推动创新方面迈出了重要的一步。</p><p></p><h3>OpenAI 推出 ChatGPT 企业服务</h3><p></p><p></p><p>OpenAI 已推出&nbsp;<a href=\"https://www.infoq.com/news/2023/09/openai-chatgpt-enterprise/\">ChatGPT 企业订阅服务</a>\"，意在帮助企业在各类应用中充分利用其强大的语言模型。该服务提供为职业定制的强化语言能力，其中包括更强的安全功能和访问控制。借助 ChatGPT 企业服务，企业可利用其对自然语言的理解和生成，强化用户支持、实现任务自动化并开发定制的人工智能解决方案，同时还能维护数据隐私及合规性。</p><p>&nbsp;</p><p>OpenAI 此举表明了其致力于满足企业需求并扩大 AI 语言模型在商业环境中的应用。</p><p></p><h3>OpenAI 将 GPT-3.5 Turbo 面向开发者开放使用</h3><p></p><p></p><p>OpenAI 推出其语言模型的高级迭代版本，<a href=\"https://www.infoq.com/news/2023/08/got-3-5-fine-tuning/\">GPT-3.5 Turbo</a>\"。新版本允许用户根据特定任务需求，通过微调定制并调整模型。</p><p>&nbsp;</p><p>OpenAI 同时还公布了 <a href=\"https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates\">API 定价结构的更新</a>\"，使开发人员在实验和部署以 GPT-3.5 Turbo 驱动的应用程序时更具成本效益。</p><p></p><h3>Meta 开源 Code Llama</h3><p></p><p></p><p>Meta 所推出的新颖 AI 工具 <a href=\"https://www.infoq.com/news/2023/09/meta-code-llama/\">Code Llama</a>\"，意在协助开发者提升代码编写效率。<a href=\"https://about.fb.com/news/2023/08/code-llama-ai-for-coding/\">Code Llama</a>\" 采用大语言模型和深度学习技术理解并生成代码，可简化编码过程从而提升开发人员的工作效率。</p><p>&nbsp;</p><p>该工具是对快速发展的 AI 驱动开发工具的重要补充，进一步体现了 Meta 对推进 AI 技术的承诺。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/09/ai-ml-data-news-september4-2023/\">AI, ML, Data Engineering News Roundup: Stable Chat, Vertex AI, ChatGPT and Code Llama</a>\"</p>",
    "publish_time": "2023-10-03 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]