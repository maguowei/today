[
  {
    "title": "远程办公，技术领导如何帮助开发者克服倦怠",
    "url": "https://www.infoq.cn/article/2SxkCMkwhdjjcRximWFe",
    "summary": "<p>出于显而易见的原因，在过去的两年多时间里，技术公司的员工团队在地理位置上愈发分散，因此也带来了新的压力。大环境在不断发展，但工作仍然需要完成。在这种背景下，技术领导者怎样才能为软件开发的未来做好准备，为团队提供所需的工具和资源，让开发人员保持良好心态，高效且尽可能无压力地继续工作呢？</p><p>&nbsp;</p><p>随着新冠疫情导致的新日常工作模式，许多开发人员已经适应了需要在混合或居家办公环境中<a href=\"https://www.infoq.cn/article/VW0JtzTW3TrOTX7yDUq7\">远程工作</a>\"的现状，他们已经习惯了尽量避免干扰以实现更好的工作与生活平衡，同时保持甚至提高生产力。</p><p>&nbsp;</p><p>另一方面，仍有少数人认为，只有在传统的办公环境中工作、团队成员共享办公空间，才能让开发人员及其团队发挥出最佳水平。这种环境设置当然会有优势，但是，当劳动力的趋势明显向分布式模式发展时，也会持续增加企业房屋租金和日常消耗费用。</p><p>&nbsp;</p><p>开发人员的职业倦怠一直是个值得关注的问题，即使我们的工作方式与先前已不再相同，但问题依旧存在。疲劳和倦怠可能会出现在任何工作领域，对领导者而言，关键是找到合适的方法帮助团队减少甚至避免工作相关的压力，以面对不断变化的工作方式。</p><p></p><h2>拥抱线上社交工具</h2><p></p><p>在这个新的工作时代，上至 CEO 在内的所有团队成员都必须具备“读懂虚拟房间”的能力，根据在线互动和对话的语气内容，了解开发者所想所感。并意识到通过 Slack、Zoom、Teams 等协作工具的沟通，与真正面对面坐在同一张桌子上交流的不同。</p><p>&nbsp;</p><p>尽管人们可以培训领导者在这种环境下有效管理的必要技能，但同时新兴的<a href=\"https://www.infoq.cn/topic/TGO\">领导方式</a>\"也在崛起。虽然团队成员之间的交流大多是虚拟进行的，但他们会把同理心和情感联系放在首位。通过留意社交网络中的蛛丝马迹也可以帮助领导者确定成员是否过于疲劳。</p><p>&nbsp;</p><p>现代通信手段的确有助于提高工作成效和效率，但好的领导者要能够通过分析团队成员在这些通信工具中的行为，从而在团队成员最需要的时候提供支持。管理者可以采用的方法有以下这些。</p><p>&nbsp;</p><p>定期开展一对一会议。这些会议对了解团队动力和士气非常重要。如果领导者面临挫败感、失败感或者无助感，这些状态通常会传染到团队成员之中。而如果领导们合作愉快、士气高涨，积极性很高，那么团队的成员也很可能如此。打破负面情绪的循环。很多开发人员会发现自己不时沉浸在消极的想法中，在未来这可能会是常态现象，但并不代表这种情况很健康。“如果这件事搞砸了……”，常常会有人在内心疯狂纠结要如何面对那个不存在的现实。反馈优先。每一个人都应该得到不断的反馈，了解自己年度绩效评估的理由，无论是积极评价还是消极评价。事实上，在保持团队参与度和确保所有人都在向一致方向奋斗的目标中，持续的反馈比年度反馈报告要有效得多。领导会更希望看到的是，工程经理和总监借助工具每周都进行辅导和反馈，而不是忍受积压的工作并为每年的审查而持续焦虑。确立正确的管理风格。每一位团队成员对自己直系领导的期盼会有所不同。领导需要明白自己每一位成员的需要才能有针对性地应对：有的人需要一个合作者，有的人需要一个导师，有的人需要一个任务管理者，而有的人天生对权威不屑一顾。注意，有的人所需要的领导者可能无法让其在工作中发挥出最佳水平。这一点很重要，领导者甚至可以问问团队成员，看看他们想要什么。透明引领信赖。作为一名经理，我优先考虑的事项是把自己的工作内容分享出来。这不仅能帮助工程师们了解我的工作背景以及我所操心的问题，而且还有助于让我们的关系更融洽。对于一部分人来说，这是建立信任的重要因素。</p><p>&nbsp;</p><p>随着时间的推移，领导者与团队成员之间的关系会愈发紧密，领导会更善于识别需要更多支持或休息的团队成员。请记住，虽然技术领导是一项技术类工作，但究其根本，这也是一份以人为本的工作。</p><p></p><h2>完善异步交流</h2><p></p><p>随着越来越多的团队分散在全球各地，我们需要利用对团队所有成员来说都“正常”的工作时间来举办会议；对西海岸的人来说基本是上午，欧洲则是下午。这样，既让开发人员能拥有大量不受干扰的工作时间，又保障了组织首选协作工具的沟通流。</p><p>&nbsp;</p><p>对开发人员来说，没有会议干扰的工作时间越长越好。他们可以利用这些时间专注编写代码、构建应用程序，或者将注意力转移到任何可能出现的问题并进行解决。这不仅组织的生产力会得到提升，还助力增长了团队的士气。当人们花费精力解决了复杂的问题后，总会收获价值感，他们会认为自己的工作更有价值、更有吸引力，我们不应忽视这一点。事实上，这在很大程度上也是人们不换工作甚至不会转职的原因。</p><p>&nbsp;</p><p>减少会议次数很好，但必要的沟通和协作仍需要进行，这样开发人员才能更有效地完成他们的工作。异步沟通的需求由此诞生，而随着团队成员在物理位置上变得更加分散，这点也愈发重要。以下是同步与异步沟通之间的简单对比。</p><p>&nbsp;</p><p>同步沟通。团队成员的地理位置相近，如同一城市、州或时区，即使需要通过 Zoom 或 Teams，团队也可以快速组织一次会议来解决问题。这些团队通常负责同一组代码，并经常实时合作。他们所面临的主要挑战之一是如何准确定位及共享他们的设计或逻辑背后的理由。异步沟通。随着越来越多的团队由跨州、跨时区及跨大陆的成员组成，这种类型的沟通需求正在急剧增长。由于这类团队几乎不可能在必要时约一个快速会议，他们更需要异步的方法和工具，清楚地传达和记录任务目标，以可搜索的形式保持重要信息流动。他们所要面临的挑战在于如何打破因成员分布在世界各地而自然形成的信息孤岛。有效的异步通信既能使开发人员独立工作，又可拥有充分可见性。操作得当的情况下，这种方法可以防止瓶颈出现，保持代码流畅，并减少可能导致倦怠的不必要压力。</p><p>&nbsp;</p><p>这两种沟通方式都是有效且成效显著的，大多数人可能都没有怎么尝试过异步沟通的方式。实施最佳实践，并随着时间的推移不断发展，让团队始终保持共识，减少无效沟通带来的挫折感。</p><p>&nbsp;</p><p>在 InfluxData，公司的团队分散在世界各地且完全远程办公，为了有效营造团结氛围，全公司每天都会举行的“站立会议”。每一位员工都会参加这个十分钟的 Zoom 会议，分享来自各个部门的公告和最新进展，为员工加油鼓劲或表彰工作纪念日。“站立会议”帮助公司在新冠疫情的大环境下保持强大的企业文化，让分布在各地的团队都参与进来，为共同的目标奋斗。</p><p></p><h2>认真对待工作与生活的平衡</h2><p></p><p>随着工作与家庭生活的不断融合，“工作与生活的平衡”可以说是有些重弹老调了。但我们需要重新理解这个概念，以帮助开发团队避免倦怠。家庭工作泾渭分明的日子基本已经成为了过去式，但对于开发人员来说，非工作期间完全脱离工作依然很重要。</p><p>&nbsp;</p><p>在疫情爆发最初阶段，团队几乎是被迫居家办公时，很多人仍试图在“上班”时仍保持明显的家庭与工作的分隔，即使他们的“办公室”只是通过 Zoom 等会议软件的虚拟背景展示。然而，随着我们逐渐适应这种方式，团队成员更愿意分享自己的家庭生活。我们认识了同事们的孩子或宠物，甚至可能更多家庭情况，这也有助于增长团队在个人层面上的联系。</p><p>&nbsp;</p><p>更进一步讲，目前许多开发人员即使是在工作日也会负责起家庭日常。在工作之余分神做饭、遛狗，或者是接孩子放学都是常有的事。自我保养也包含在内，例如在附近短途散步或慢跑、参加线上瑜伽课程，等等，以在一天的工作之中略做放松。全新的远程办公文化使开发人员更加健康快乐，这也是很多人不愿意或者抗拒回到疫情前的办公室办公的主要原因之一。</p><p>&nbsp;</p><p>企业文化在协助团队成员保持健康快乐的心态方面有着不可或缺的作用。企业领导人和管理人员需要尊重团队成员健康工作和生活平衡，这样才能达到双赢的局面；员工可以收获快乐并提升效率，企业则能够在近年来竞争愈发激烈的就业市场上留住人才。</p><p></p><h2>总结</h2><p></p><p>综上，随着开发人员的工作方式不断演变，组织的战略和管理方式也应不断发展，以最大限度地减少开发团队的压力，避免团队成员陷入完全倦怠期。成功的组织是能够制定计划，并随着时间的推移不断将计划完善以适应开发人员需求的组织。这不仅是一个好的商业战略方案，也是一个以人为本的理念。</p><p>&nbsp;</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/guide-avoid-burnout/\">The IT Leader’s Guide to Helping Developers Avoid Burnout</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MzA4NTU2MTg3MQ==&amp;mid=2655159792&amp;idx=1&amp;sn=6905f0ddae406e45b9d81e9da4e408a9&amp;chksm=84602290b317ab86c608164264b0984a08d1c145ef14f142b920e2adf96c2379300031a08ea4&amp;scene=27#wechat_redirect\">创业团队的项目管理，如何面向开发人员优化</a>\"</p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MzAxNDU2MTU5MA==&amp;mid=208297748&amp;idx=1&amp;sn=f82dcecc8126cfc801530683df5c8a00&amp;chksm=120f874d25780e5b260a22247798ee6812e9d7c86d12805b664104fd3acbe0562305862c7e67&amp;scene=27#wechat_redirect\">开发人员转型到管理者必须学会的 7 件事</a>\"</p><p><a href=\"https://xie.infoq.cn/article/28b9b8248b2cefba1594ab88e\">如何优化组织结构? 如何助力疫情中的企业?</a>\"</p>",
    "publish_time": "2022-08-30 09:37:08",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "腾讯百亿级大规模内容处理系统探究",
    "url": "https://www.infoq.cn/article/mBhlvB5bielufFYf98QT",
    "summary": "<p></p><h2>1. 背景介绍</h2><p></p><p></p><p>腾讯内容处理中台是打通腾讯内容生产、内容处理、内容分发、内容变现等内容生态闭环的核心基础服务。作为衔接内容生产端和内容消费端的关键路径，旨在通过智能化、规模化的人机协同内容处理和内容审核等关键技术方案，对内容供给端产生的各种形态内容如视频、图文、商品、评论等，进行安全化、标准化、算法化等流水线工业化处理，并将处理后的内容统一分发到腾讯视频、QQ 浏览器、腾讯新闻等多端渠道，为不同的用户群体提供更好、更高效的内容服务体验。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ed/edec358070ddcd6077205a1abd2f66d0.png\" /></p><p></p><p>图 1-1 内容生态概览图</p><p></p><p></p><h2>2. 问题和挑战</h2><p></p><p></p><p>腾讯内容处理中台作为工业化内容处理技术基座，面对多元化的业务渠道以及海量复杂多样的内容处理诉求，需要不断抽象业务模型，构建高效稳定的场景化内容处理审核服务拓扑链路，来满足内容生态各种内容处理场景。因此，我们需要重点解决解决以下几个关键核心问题。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d5/d5cd233df6a855398da83671026c9e03.png\" /></p><p></p><p>图 2-1 内容处理中台关键问题</p><p></p><p>问题 1：百亿级的异构元数据内容物料接入</p><p></p><p>由于腾讯每个渠道产品都有自身产品的内容类型及内容调性需求，比如视频、图文、音频、直播、商品、评论、账号、标签等，面对这样多态性的内容，需要进行标准模板化处理，并提供业务场景化的内容预处理机制，同时为了能够唯一识别内容，从中台视角，需要提供内容中台的统一内容 ID 以及和各业务渠道映射关联的 ID-Mapping 服务。</p><p></p><p>问题 2：单链路数百个算子微服务低代码乐高式编排</p><p></p><p>由于腾讯各个渠道业务既有通用公共内容处理逻辑诉求，又有各自个性化的内容处理逻辑诉求，且内容处理服务链路通常涉及到 AI 能力和审核等多个服务提供方和多种协同模式的编排。因此，如何支持快速集成到端到端处理流程，提高研发效率，降低搭建内容处理流程成本，成为内容中台架构的核心关键之一。内容中台需要对系统进行高度的抽象化处理，通过可插拔的插件模式进行标准化，并提供高度灵活的低代码形态多元化内容处理服务编排能力。</p><p></p><p>问题 3：每日数十亿次任务毫秒级优先级可靠调度执行</p><p></p><p>面对每天数千万的各类图文、视频等海量内容处理需求，需要在数千个内容编排任务链路上在线流式运行，保障数十亿次任务调度毫秒级的延迟，并保障存储资源的低成本诉求，对我们构建消息队列系统、调度系统、运行系统、存储系统等都形成了较大挑战。同时，在面对复杂内容处理系统，如何构建全链路运行优化机制也十分重要，只有这样才能为腾讯内部各个渠道业务方提供高效稳定的定制化内容分发服务。</p><p></p><p>问题 4：端到端的可观测性和服务稳定性</p><p></p><p>系统中每一条内容处理流程接入数百个处理能力，每一个能力的处理容量，可用性，服务方式都不一样，如何保障系统在各种协同系统故障时能够快速发现、定位、解决问题，以及如何应对突发流量，提升系统稳定性等问题都对系统提出了更高的要求。</p><p></p><h2>3. 系统详解</h2><p></p><p></p><h3>3.1 整体架构</h3><p></p><p></p><p>为了更好地理解内容处理中台工作的交互流程，下面将从业务架构图和技术架构图对内容生态领域工业化处理中台进行简要的介绍。</p><p></p><h4>3.1.1 业务架构图</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/6c/6c549bcdc64a6e53a241952b4245ec42.png\" /></p><p></p><p>图 3-1 内容处理中台业务架构图</p><p></p><p>内容处理工业化业务架构和我们熟悉的传统工厂流水线生产模式极为相似。我们从端到端将整个内容工业流水线生命周期分为了 7 大子系统：接入系统、消息系统、存储系统、组件系统、编排系统、调度系统、运行系统等。同时对关键核心功能进行了关键解耦，以满足腾讯内部各渠道对内容原料的复杂多变的私有化处理需求，支持多渠道高效分发。</p><p></p><h4>3.1.2 技术架构图</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/99/99f523115f0c0cbb065cd35c5d260073.png\" /></p><p></p><p>图 3-2 内容处理中台技术概览图</p><p></p><p>接入系统：针对问题 1，主要解决腾讯内部各渠道多形态内容物料的自动化接入适配问题，支持对内容进行预处理，比如筛选、合并等。同时，为了保障内容物料在内容处理中台的唯一性，中台对内容进行唯一识别码赋值。基于统一的内容 ID 体系，内容作为最基本的数据单元在各系统间流转和调度，中台也以内容为核心视角来构建业务。</p><p></p><p>插件系统：针对问题 2，主要解决内容处理服务能力原子化和标准化的问题，使用户能够在全链路复用、共享、扩展内容处理能力，同时大幅降低业务使用方的开发成本。通过对服务处理能力的协议抽象，有效地避免了对基础内容处理功能的重复建设，比如常见的内容算法服务、内容工具服务等；同时，也对内容处理服务提出了标准化的服务范式，提供零开发组件导入，组件同步执行、异步执行的能力。</p><p></p><p>编排系统：针对问题 2，主要解决用户构建内容处理链路的易用性、高效性问题，低代码 + 代码化多元化模式构建内容处理工业化流水线工作。</p><p></p><p>Pipeline 模式：适合更低的熟悉成本、更快的开发，基于算子插件组成 stage，stage 内部的多个插件并行执行，多个 stage 之间串行流转构成内容处理链路。同时，我们提供基于 YAML 构建任务拓扑、更好的编码体验、代码式多版本管理。DAG 模式：适合较低的开发成本、较好的业务理解，基于有向无环图，构建业务场景化内容处理服务分支链路，让开发同学可以有更清晰的业务认知。</p><p></p><p>调度系统：针对问题 3，主要解决日均数十亿次任务调度的低延迟、优先级队列等问题，并建设智能反压机制。</p><p></p><p>运行系统：针对问题 3，主要解决全链路端到端，涵盖请求智能路由、弹性执行、代理执行、执行流控、状态微批持久化、结果共享等核心运行优化机制。</p><p></p><p>存储系统：主要解决内容处理的列更新场景以及宽表存储问题，同时，在降本提效的基础上，基于多租户机制，建设私有和共有的存储服务。</p><p></p><p>观测系统：针对问题 4，主要解决多系统融合后的可观测性，包括对内容粒度和工程质量的核心指标秒级观测洞察等。</p><p></p><p>相关术语</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/8c/8c1ee25e05cf9a747d609081056776c0.png\" /></p><p></p><h3>3.2 接入系统</h3><p></p><p></p><p>为了应对百亿级的异构元数据内容物料接入的挑战，针对多元化的腾讯各业务渠道的内容数据，接入系统主要需要解决的是数据标准化处理与自动化接入的问题，并把业务内容及其原始属性转化为星航系统能够标记、识别和处理的元素。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/78/7802488fffbee0e915459f51edf2d620.png\" /></p><p></p><p>图 3-3 接入系统流程</p><p></p><p>为更好的支撑复杂业务场景以及敏捷接入需求，接入系统在设计实现上具备了以下能力要素：</p><p></p><p>标准化：针对常用的内容形式制定了不同内容类型的标准化协议，最大程度提高星航管线间的能力复用以及降低数据理解成本；可扩展：在标准化协议之上保留了可扩展性，业务可以通过追加附加协议定制个性化的数据字段，满足标准字段外的业务个性化需求；低代码：JSON 协议定义的高度可扩展性以及 JsonPath 解析的灵活性以及完备的数据 schema 和校验，实现业务接入特征的配置化解析；自动化：提供管理端，业务方按照约定的方式自助录入内容接入以及特征定义，节约对接运营成本；</p><p></p><h4>3.2.1 内容类型</h4><p></p><p></p><p>由于腾讯内部不同渠道业务的调性定位不同，接入系统需要高度抽象，统一处理不同类型的内容信息。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/61/61a6e630dec2f0c6e6c1773215d613e3.png\" /></p><p></p><p>图 3-4 各业务的内容类型</p><p></p><h4>3.2.2 内容 ID 体系</h4><p></p><p></p><p>由于历史发展原因，各渠道业务线的内容 ID 体系不一，ID 存在生成方案不统一、长短不一、ID 可能冲突的问题。内容中台作为内容的桥梁，需要对各渠道的 ID 进行标准化映射到星航平台内容统一 ID，并进行统一管理。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/1d/1d8d87db8211b2b68786ae29cff4222c.png\" /></p><p></p><p>图 3-5 内容中台 ID 和各渠道业务 ID 映射体系</p><p></p><p>为便于腾讯各业务层面的内容运营管理，内容处理中台的内容 ID 中，希望能够日期信息方便数据管理和定位；同时，系统层面上，需满足以下要求：</p><p></p><p>全局唯一：全局唯一不能重复趋势递增：日期相关，尽量保障数据的有序性低延迟：接口耗时低，毫秒级别高可用：底层服务，系统可用性要求高容量：亿级 / 天</p><p></p><p>基于底层组件的稳定性以及运维成本考虑，我们选择分布式数据库自增的方式。为了规避 DB 取号段的过程消耗网络耗时影响请求响应，采用双 buffer 的方式，程序内存有两个号段缓存区 segment。当前号段已下发特定百分比时，如果下一个号段未更新，则另启一个更新线程去更新下一个号段。当前号段全部下发完后，如果下个号段准备好了则切换到下个号段为当前 segment 接着下发，循环往复。</p><p></p><h3>3.3 插件系统</h3><p></p><p></p><p>插件是内容处理平台编排的核心组件之一，它是对算法特征、质量特征、策略逻辑、人工审核处理等的原子化微服务或者云函数能力抽象，插件包含了插件 ID、版本、微服务的服务名、输入、输出、分类等重要属性。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b5/b5b1caea6e945c803b48fa3caf4878d7.png\" /></p><p></p><p>图 3-6 插件的分类和示例</p><p></p><p>在业务层面上，插件主要分为：算法特征、质量特征、策略逻辑、人工审核等类型；在平台层面上，为了适配不同性能的插件，按照耗时长短分成同步插件、异步插件。异步插件包含发送插件与查询插件。</p><p></p><h4>3.3.1 开发模式</h4><p></p><p></p><p>对于业务使用方，研发效率的关键主要包括插件开发和管线编排等链路环节，插件主要包括两大类：自定义协议插件和代理协议插件（普通插件、脚本插件、函数插件）。因此，我们在插件开发模式的道路上也做了大量的探索和迭代演进。</p><p></p><p>3.3.1.1 代理协议插件</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ca/caafbd9c17c6e2701270fe52051147b3.png\" /></p><p></p><p>图 3-7 代理协议插件开发模式演进</p><p></p><p>普通模式</p><p></p><p>普通插件的创建流程主要分为如下 7 个步骤：</p><p></p><p>开发部署；熟悉 RPC 开发框架，了解星航插件协议；代码开发、同步 git 仓库；服务创建、审批、编译、发布、测试；注册插件；编排管线；管线执行；</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/02/020da51f995c89e0adc17ca53ac92155.png\" /></p><p></p><p>图 3-8 普通插件开发模式</p><p></p><p>对于普通开发模式，内容处理中台本身无需介入管线开发者的开发和部署环节，只要开发者实现了上文提到的插件协议即可。但是，普通模式存在一定的优化空间，因为创建一个功能简单的插件，也需要上述多个步骤，导致创建普通插件成本相对较高。</p><p></p><p>脚本模式</p><p></p><p>在许多轻量的内容处理业务场景中，我们可能只需要一些对内容进行简单的逻辑处理。为了优化普通插件开发的成本，星航提供了一种用户仅需提供业务处理逻辑代码，无需关注创建插件的过程中无需了解协议、编译、部署、扩缩容等问题的脚本开发模式。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/4d/4d3ba2d91f281e27d6fd55f331a05166.png\" /></p><p></p><p>图 3-9 脚本插件开发模式</p><p></p><p>如下图创建一个简单的 echo demo，创建插件的过程中，用户只需要关注业务代码，极大简化了插件的创建流程，而且修改代码后逻辑可直接生效，没有延迟。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5b/5b35b04b9a8f767e012b500abb929ee4.png\" /></p><p></p><p>图 3-10 脚本插件开发 UI 示例</p><p></p><p>函数模式</p><p></p><p>对于脚本插件模式，由于是基于 Go + 脚本语言实现，主要存在 2 类问题：</p><p></p><p>a）脚本插件存在调试困难、适用于简单的需求场景、外部系统交互不易实现等缺点；</p><p></p><p>b）脚本插件多任务处理流中共享代码逻辑，因此，逻辑更新、结果共享都存在一定的局限性。</p><p></p><p>基于以上问题，我们参考云原生时代的解决方案，实现了函数插件。用户仅需关注业务代码，平台侧根据用户提供的代码信息，完成从函数到服务完全自动的 CICD【函数 -&gt;可编译的服务 -&gt; 镜像 -&gt; 发布 -&gt; 运行扩缩容】。具体流程如下图：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b7/b794b9915a29e27c8471f8e0243ff3b1.png\" /></p><p></p><p>图 3-11 函数插件开发模式</p><p></p><p>3.3.1.2 自定义协议插件</p><p></p><p>由于开发环境和历史因素，部分渠道业务的插件能力使用了自定义协议，为了不额外增加开发部署代理协议插件模式的适配层服务，需要解决快速导入渠道自定义插件服务的共性问题。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/75/75dada765d87b8f33fe5faf0119f0f51.png\" /></p><p></p><p>图 3-12 自定义协议插件流程示例</p><p></p><p>PB 协议除开常用的静态引用，还存在动态解析执行的方式，因此中台可以提供服务 PB 协议的注册、解析功能。具体的操作与执行步骤如下：</p><p></p><p>‍插件开发者，首先在平台注册自定义的 PB 协议，中台协议代理保存并动态预反射解析协议；插件开发者创建新插件时，引用新协议，并配置插件协议与自定义协议的字段 JsonPath 映射关系列表‍；中台的执行器在调用插件代理时，协议代理会按照 JsonPath 映射关系，把插件协议的请求转换成自定义协议的请求，进而继续调用 PB 中指定的 RPC 接口；中台获得响应后，采用类似的方式，把自定义协议的响应再转换成插件协议的响应。最终执行器拿到了插件协议的响应，继续调用后续插件。</p><p></p><p>对于插件开发者来说，整个过程是自助化、配置化的，没有开发协议转换代码与转换服务，可以达到快速导入自定义协议服务的目的。</p><p></p><h4>3.3.2 调试模式</h4><p></p><p></p><p>插件创建成功后，为了便捷地验证接口与功能的正确性，插件支持在线模式的调试。按照预定义的插件输入参数列表进行填充输入参数，通过随机选择后台任一节点方式，即可获取插件的响应结果。另外，还支持生产环境下的插件灰度调试功能：先灰度发布少量服务节点，再到页面指定灰度节点进行请求调试。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/91/9124416da2fb96622168358c0bdb9eee.png\" /></p><p></p><p>图 3-13 在线调试示例</p><p></p><h4>3.3.3 运营模式</h4><p></p><p></p><p>开放是协作的基石，足够开放，才可以让协作足够顺畅。为了解决内容生态基建能力的复用性和扩展性，我们采用多方共建维护的运营模式，打造了算法插件市场，连接腾讯内部多个部门的职能，共同营造现代化的内容处理链路。比如：插件开发者在机器学习平台训练算法模型并部署服务后，可以直接注册成插件。再当试跑数据满足准召指标后，即可被引入到插件市场。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/02/02ba06b7dbd56fa327afa8427ff62b21.png\" /></p><p></p><p>图 3-14 插件运营模式</p><p></p><p>当前 30 多个团队参与共建，插件累计达到数千个。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/0c/0cf6d48aa375c3043f8b4bc842cbec6c.png\" /></p><p></p><p>图 3-15 插件市场线上示例</p><p></p><h3>3.4 编排系统</h3><p></p><p></p><p>为了应对单链路数百个算子微服务低代码乐高式编排的挑战，内容处理中台提供了两种编排模式：pipeline 模式链式编排，适合比较简单的业务场景；DAG 模式有向无环图编排，适合分支较多、比较复杂的业务场景。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/bf/bf2caaf1f01d82c29bd9bfab9ffb9408.png\" /></p><p></p><p>图 3-16 任务编排拓扑类型</p><p></p><p>值得注意的是，每个管线允许多个编排版本的存在，内容会根据灰度比例进入不同版本的编排，实现不同的流程。</p><p></p><h4>3.4.1 Pipeline</h4><p></p><p></p><p>3.4.1.1 管线</p><p></p><p>管线的基本元素有 Materials（内容源）、Triggers（触发事件）、Stage（阶段）、Task（任务 / 插件）、Deliverpoint（交付点）、Deliverables（交付物），其含义为</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/52/524f2b2711b7e069e3dcf0340a86b065.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c5/c5310e0d7ff6bdde9cca91792f817f57.png\" /></p><p></p><p>图 3-17 Pipeline 编排模式示意图</p><p></p><p>3.4.1.2 插件集</p><p></p><p>对于流程比较简单的业务，我们提供了插件集模式（Pipelite）。插件集是简化版的管线功能，将整个管线流程封装成一个同步接口，用户通过 RPC 调用的方式输入内容材料（Materials），接口输出内容特征（Deliverables）。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/91/91c5eedc232a7baa7a9f7408023ed816.png\" /></p><p></p><p>图 3-18 插件集示意图</p><p></p><p>管线和插件集的区别如下：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/20/205f3c9be832011806d1e56a499294e2.png\" /></p><p></p><h4>3.4.2 DAG</h4><p></p><p></p><p>我们基于 BPMN（Business Process Model and Notation）2.0 标准，构建了管线编排的 DAG 模式，用于支持比较复杂的业务模型。主要的元素有：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/11/115315596a71f66301fc47167a472eec.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/38/38fd674d732165e0304ea6c2c55d711a.png\" /></p><p></p><p>图 3-19 DAG 编排模式示例</p><p></p><p>上图为线上一个基础的 DAG 管线，内容通过事件网关区分不同事件流程，在不同的分支上进行处理，最后汇总到结束点。</p><p></p><h3>3.5 消息系统</h3><p></p><p></p><p>消息是调度系统运转的催化剂，内容处理系统整个生命周期中产生大量数十亿级的消息信号，如业务内容类消息、外部干预类消息、系统工程类消息信号等。因此，需要一个统一的消息系统来及时可靠地处理这些海量消息。</p><p></p><h4>3.5.1 设计目标</h4><p></p><p></p><p>消息系统需要从多方面保障其服务质量，主要包括如下：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/52/52bec8e736744a161e5b5be68a9bb714.png\" /></p><p></p><p>（1）消息需要保证可靠性，特别是发文消息还需要保证时序性；</p><p></p><p>（2）不同类型的消息对时效性要求不同，需要分级处理消息队列；</p><p></p><p>（3）整体消息量非常大，需要保证处理及时；</p><p></p><p>（4）推送失败时，需要重试但不能阻塞后续消息；</p><p></p><h4>3.5.2 技术架构</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/07/073b06d228ad6f24e4526b5e17c4d43e.png\" /></p><p></p><p>图 3-20 消息系统架构</p><p></p><p>（1）消息接入服务：作为接入层，负责消息的接入和校验等工作，并根据消息类型路由到不同的消息队列。通过为不同的业务分配不同的 topic 进行业务隔离，创建多分区来提高吞吐量。同时为了保证同一个内容的消息的时序性，使用星航平台统一内容 ID，作为 key 保证哈希到同一个分区。</p><p></p><p>（2）消息处理服务：负责持续消费消息队列，根据消息类型调用对应的服务。其中对外部干预类消息的处理，需要考虑一条消息会干预多个管线中的同一条内容。例如，外部检测到一篇文章的热度达到了阈值，需要干预多条管线中的这篇文章都跳转到人审环节，这时需要并发调用多个管线的状态跳转服务。如果对有些管线处理失败了，需要将这条消息以及这次各个管线处理的结果，都发送到延时队列，用于下次重试时不重复处理。使用延时队列，能够避免阻塞消息队列里后面的消息。而对于延时策略，使用指数退避算法（Exponential Backoff），根据失败次数延长下次调度时间，失败次数每增加 1 次，延时时长增加 1 倍，同时为了避免同时到期，还在延时上增加一个波动值。另外还考虑到，如果延时一直增加，当接收服务的故障恢复时无法及时感知，因此会延迟递增到设定值后会周期性重头计算。</p><p></p><p>（3）状态跳转服务：每个管线有对应的状态跳转服务，接收外部干预类消息，判断管线中的内容应该跳转到哪个步骤，并更新存储状态，然后存储代理发送调度消息到消息队列，供调度系统进行调度。</p><p></p><h3>3.6 调度系统</h3><p></p><p></p><p>对于每日数十亿次任务毫秒级优先级可靠调度执行的挑战，调度系统是内容处理链路的核心子系统之一，它需要保障每天千万级内容数十亿次任务的高效调度处理工作，由多个任务单元组成，任务单元之间存在时间先后顺序和前后依赖关系，本质是一个任务链路编排是一个工作流，需要由调度系统对多个工作流进行管理和调度。</p><p></p><p>对工作流的描述方式，常用的有 FSM（Finite State Machine，有限状态机）和 DAG（Directed Acyclic Graph，有向无环图）。这两种方式各有优缺点，适用的场景有所不同。</p><p></p><p>FSM 为每个步骤设定一个状态，每个步骤可以有多个任务并行执行，步骤之间顺序执行，也能跳转到指定步骤重复执行。FSM 适合处理过程简单，状态明确的内容处理场景。</p><p></p><p>DAG 是每个节点一个状态，能描述复杂的依赖关系，还支持子图减少重复执行步骤，但所有节点的状态集合才能表示当前的状态，不便于观测。DAG 适合处理过程复杂，条件繁多的内容处理场景。</p><p></p><p>目前星航调度系统支持这两种工作流模型，跟据当前的状态执行对应的任务步骤，然后更新状态和结果属性，记录执行的事件流水，方便全链路观测。</p><p></p><h4>3.6.1 设计目标</h4><p></p><p></p><p>（1）调度任务以内容为粒度，任务量大，时效性要求高；</p><p></p><p>（2）需要支持内容级别的调度优先级；</p><p></p><p>（3）需要支持分布式调度，动态调配资源，并支持业务隔离；</p><p></p><p>（4）能够对每条内容进行全链路观测。</p><p></p><h4>3.6.2 技术架构</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/19/19e00dffffdab27e4aec33c3a7cd6486.png\" /></p><p></p><p>图 3-21 工作流调度系统示意图</p><p></p><p>Scheduler：任务调度模块，负责从存储模块获取任务分配给执行器。</p><p></p><p>Executor：执行器模块，负责从调度模块获取任务，从元数据中心获取工作流配置，调用相关插件进行计算，最后将结果写回存储模块。</p><p></p><p>Storage：加工存储模块，存储内容处理任务状态属性和事件流水。</p><p></p><p>MetaCenter：元数据中心，存储用户编排的工作流配置和管线其他相关元数据。</p><p></p><p>Plugin：插件，统一封装业务方提供的原子化的计算能力。</p><p></p><h4>3.6.3 执行机制</h4><p></p><p></p><p>3.6.3.1 优先调度队列</p><p></p><p>内容处理的调度，需要考虑任务量大，时效性要求高，还要能按内容优先级进行调度。借鉴流式处理方式，调度流程使用消息队列进行传输任务。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/bb/bb161df91df1e3456dea35df24940330.png\" /></p><p></p><p>图 3-22 调度系统流程示意</p><p></p><p>加工存储模块，记录每条任务的状态和执行结果，在收到新增和更新的请求后，会将需要调度的任务发送到 kakfa 任务队列。这种方式比起常规的轮询任务的方式，时效性更高，并且能减少重复的任务发送。为了增加系统可靠性，当任务队列集群不稳定或故障时，会将任务发送到补偿队列，保障任务不丢失。调度队列服务，不断地从任务队列和补偿队列中消费任务，计算每个任务的动态优先级，然后送入 redis 优先级队列。动态优先级的计算，结合了业务指定优先级和调度因素（如状态变更时间和失败次数等），保证高优内容及时处理的同时，避免长时间失败导致影响低优任务的处理。优先级队列为每个执行器模块的 worker 建一个子队列，一个管线配置多个 worker，每个 worker 只从对应的子队列获取任务。任务入队服务使用一致性哈希算法，计算每个任务哈希到对应管线的某个子队列，当 worker 动态调整数量时，会重新计算，动态均衡。子队列方案比起常规的高低级双队列方案，优先级粒度更小，减少争抢，调度效率更高。延时队列，对失败任务进行延时调度，减少无效调度，降低对插件计算服务的压力。任务分配服务，接收执行器模块的请求，从对应的优先级队列中返回任务，可以控制分配速率。</p><p></p><p>3.6.3.2 动态流控反压</p><p></p><p>调度系统还考虑了动态流控，当任务大量执行失败时，自动减少对故障环节的压力，帮助快速恢复。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/10/10afc288a02cd2f00683c847ab6e0383.png\" /></p><p></p><p>图 3-23 动态流控示意</p><p></p><p>当插件服务故障持续发生，待调度任务不断增加，监控到优先级队列积压到一定阈值时，会启用反压机制（Back Pressure）。一方面调度队列服务会减少任务入队速度，一方面任务分配服务减少初始任务的分配，先消化处理中的任务，降低执行模块的负担。等故障恢复后，越来越多的任务由于执行成功，会进入正常优先级队列，再快速恢复处理速度。动态流控的效果主要如下：</p><p></p><p>对故障插件减少平均 60+% 的无效调度，利于插件服务恢复。对插件的调用峰值减少 60%，避免发生雪崩。故障恢复后，10 分钟内整体调度速度恢复正常。</p><p></p><p>目前，星航管线调度系统，实现了分布式高可用、秒级调度延迟、动态优先级、动态流控、多租户管理等多种特性，支持了腾讯内容开放平台、腾讯新闻、腾讯视频、小世界等二十多个重要业务上百条管线，每天处理千万级内容量，累计处理近百亿级内容量。</p><p></p><h3>3.7 运行系统</h3><p></p><p></p><h4>3.7.1 Pipeline</h4><p></p><p></p><p>Pipeline 执行引擎基于 FSM（finite-state machine）有限状态机实现，每个 stage 对应一个状态。正常情况下，每执行完一个 stage, 状态 +1。当某个阶段的插件执行失败时，状态在原地流转。流程运行异常时会进入拦截状态，停止流转。被拦截的内容收到触发消息后，可以再次激活流程。流程运行结束后进入完成状态。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/80/80dff9bbb184dd00148de792ef6a6157.png\" /></p><p></p><p>图 3-24 Pipeline 执行机制流程示意</p><p></p><p>由于我们支持 Pipeline 的多版本管理和执行，运行系统需要对并发执行进行控制。在一些场景下，两个执行器会拿到同一个内容的任务，我们用数据版本 row_version 作为乐观锁进行并发控制。当执行器 A 和执行器 B 同时拿到 row_version = 1 的某条任务时，先提交的执行器会将这条任务的 row_version 改为 2。此时后完成的执行器 B 便无法提交成功了。并发执行机制确保了任务只会在一个执行器里执行，避免数据写脏。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a7/a7d6e7d85fad2cf9d957b4b43255eefb.png\" /></p><p></p><p>图 3-25 Pipeline 多版本并发执行控制</p><p></p><h4>3.7.2 DAG</h4><p></p><p></p><p>DAG 引擎的设计理念是一个纯抽象、可复用、与业务逻辑无关的引擎，驱动流程在 DAG 图上的流转。将业务逻辑通过开放接口的形式，交给业务系统实现。主要模块包含以下部分：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b6/b64c800122c70ec2f61ecaa14e83bc01.png\" /></p><p></p><p>图 3-26 DAG 执行机制流程示意</p><p></p><h4>3.7.3 插件代理</h4><p></p><p></p><p>由于各渠道业务提供的插件服务的性能与耗时存在较大差异，但被调用的流程相似，因此需要引入插件代理。插件代理对插件行为进行抽象，屏蔽实现方式，统一插件的调用流程。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/34/349ddc1662c51466d05e3e11e58edcd9.png\" /></p><p></p><p>图 3-27 插件代理示意</p><p></p><p>插件代理向上面向执行引擎时，插件代理屏蔽各类插件实现细节，表现出一致性；向下面向插件时，提供全局统一的缓存、限流能力，转发流量到各类具体插件或插件中间件。</p><p></p><p>插件的标准协议，使用自描述结构表征每个字段，并使用 Protocol Buffers 新增的 Map 类型包裹全部业务字段，从而定义出通用的插件协议。</p><p></p><p>3.7.3.1 插件共享</p><p></p><p>由于多个管线可能引入相同的内容源，插件在这些管线被引用时，会导致相同内容的特征会重复计算，浪费大量机器资源，因此需要引入插件共享机制。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/eb/eb6f64f986fc30277470b87fb26c3e02.png\" /></p><p></p><p>图 3-28 插件结果共享示意</p><p></p><p>插件共享用于多个管线之间共享相同内容的能力特征。用户在插件上，可以配置是否开启缓存共享、缓存主键、有效期等参数。当内容处理中台的管线之间存在重复内容时，对于用户开启了共享功能的插件，如果没有命中某条内容的缓存，则调用插件开发者提供的特征能力服务，获取特征能力结果并创建缓存。其他管线如果命中了缓存，则优先使用缓存的特征能力结果，不再调用特征能力服务。通过对插件共享，实现了能力特征的跨管线复用，节省了机器计算资源（CPU、GPU）。</p><p></p><p>3.7.3.2 流量控制</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/1b/1ba006a8d73f36bad96654b5830d2226.png\" /></p><p></p><p>图 3-29 流量控制示意</p><p></p><p>当前线上每天有十亿级别的插件流量，每个插件的计算能力都有极限，如何平衡在线系统的插件流量和离线系统的插件流量是个值得思考的问题。</p><p></p><p>平台采用流量分级机制，对管线的流量进行实时采集、实时计算，评估出主要业务所需的插件流量配额。并将剩余的插件流量配额（增量桶）分配给离线任务，配额的计算窗口秒级动态调整。</p><p></p><p>3.7.3.3 同步异步</p><p></p><p>对于执行引擎而言，所有插件都被统一成了同步调用过程。插件模型主要有以下几种分类：</p><p></p><p>（1）同步插件：短耗时服务只需要注册一个插件。执行器同步阻塞调用插件指定的服务。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/cd/cd47157040f3aabc0e73ff4d83f48775.png\" /></p><p></p><p>图 3-30 同步插件</p><p></p><p>（2）异步发送与查询插件：异步插件都包含发送与查询两个步骤，需要注册两个插件。执行器通过发送插件，把任务发送给业务。执行器再通过查询插件，查询任务结果。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/fc/fc902ae47da7ca7db5b2f1e0264e85af.png\" /></p><p></p><p>图 3-31 异步发送与查询插件</p><p></p><p>（3）异步发送与回调插件：业务把结果回调给中台，中台统一存，执行器到存储中查询结果。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c3/c3473ce127bc1e8b8ce4c1a988992daa.png\" /></p><p></p><p>图 3-32 异步发送与回调插件</p><p></p><p>（4）同步转异步插件：由于业务处理视频时，较多特征能力耗时都会较长，如果使用第二种异步插件模型，那么会迫使业务重复开发多个异步系统，增加特征上线周期与难度。因此，内容处理中台提供了同步转异步中间件，把业务的同步服务在管线上转换成异步服务。执行器把任务通过发送插件发给同步转异步中间件系统，它再调度任务并实际调用业务的同步服务，并把返回的结果写入到内容处理中台存储，执行器再到中台存储查询任务结果。最终达到了业务只需要提供同步特征服务，即可快速上线。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/81/815fc065680673f53a72db867342ff52.png\" /></p><p></p><p>图 3-33 同步转异步插件</p><p></p><h4>3.7.4 状态管理</h4><p></p><p></p><p>管线的执行流程往往很长，为了提高执行效率、减少存储压力，平台采取状态连续执行，结果合并回写的方案进行状态管理。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d8/d8f9bb0f8437bd5ccad4a868fa150902.png\" /></p><p></p><p>图 3-34 执行过程状态持久化</p><p></p><p>状态的回写时机包括：流程进行到分发点流程执行结束插件执行失败连续执行超过 N 个状态</p><p></p><h4>3.7.5 干预机制</h4><p></p><p></p><p>区别于常规的 workflow 工作流系统，星航所面临的内容处理流程诉求更加复杂多样，诸如特定插件结果变更以及批量洗数据等。有些应用场景业务希望有触发信号干预影响系统的流转走向图，当业务信号发生时流程跳转到指定位置运转。另外一些应用场景业务希望对大规模内容数据进行数据清洗，同时要求对常规的增量内容处理流程不受影响。对此，星航提供了不同的干预能力以覆盖不同的业务需求场景。</p><p></p><p>特定内容信号触发器</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d1/d164702671d89459a2f7cbf62f338e00.png\" /></p><p></p><p>图 3-35 星航系统信号干预触发示例</p><p></p><p>特定内容的信号触发可以通俗理解成编程语言中的“goto”语句。星航允许用户自定义触发器并在管线特定位置配置引入触发器，当业务方通过回调触发器 Callback API 发送触发信号后，系统通过事件接入模块存储该信号并对关联触发器的管线进行信号广播；调度服务接收到触发信号后把内容对应调度状态重置成目标状态并进行进一步调度处理。业务可以自由定义回调信号对应的附加数据以用于流程控制。</p><p></p><p>大规模数据回溯处理</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c6/c62e2ea1885779bd67642eaf68a89cc0.png\" /></p><p></p><p>图 3-36 大规模数据回溯示例</p><p></p><p>星航提供的大规模数据回溯处理能力根植于“轻量级”管线即插件集能力之上，通过旁路任务队列接收数据回溯任务数据，基于插件集调度处理获取回溯结果之后在回写至对应管线，在节约了数据回溯存储成本的同时也避免了对常规增量内容的流程影响。</p><p></p><p>管理端干预能力</p><p></p><p>除了前面提到的信号触发器以及大规模数据回溯能力，星航还在管理端内置了内容干预入口，方便用户对少量数据进行状态干预处理。</p><p></p><h3>3.8 存储系统</h3><p></p><p></p><h4>3.8.1 设计目标</h4><p></p><p></p><p>内容属性宽表 schema 需要灵活扩展，同时需要对字段进行规范管理；需要提供单个内容的详细处理流水供业务查询追溯；需要支持 PB 级的数据存储，以及对内容万级 qps 的在线读写能力，以及较高的可用性；需要支持不同业务个性化的关键字段的检索需求；需要有离线 + 实时数仓提供给业务进行各种查询分析；在降本的背景下还需要平衡好资源成本。</p><p></p><h4>3.8.2 解决方案</h4><p></p><p></p><p>实际场景中，业务数据主要分为两类：</p><p></p><p>以内容 id 为主键的属性数据，既包括业务原料库中的数据（比如标题 / 封面等），也包括内容加工的产出特征（比如机器分类标签 / 人审结果等）；内容每个步骤的变更流水，时序数据。</p><p></p><p>综合考虑，采用了以 HBase 为主要存储，辅以 ES/Clickhouse 等组件的异构存储系统，中间利用 Kafka 进行数据同步。写操作时，先更新 HBase 属性表，成功后写结构化的事件日志到 Kafka，后续再异步消费 Kafka+ 查属性快照的方式将数据同步到后续各个存储。综合考虑性能和业务数据特点，此处 HBase+Kafka 双写的模式实现上不保证原子性，仅对 Kafka 增加了一个容灾集群，当两个集群都失败时需要主调方进行重试。如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/69/69c91c12bd2cf0d8346e2ed1e79964f2.png\" /></p><p></p><p>图 3-37 存储数据流示意图</p><p></p><p>HBase 具有高性能 / 高可用 / 低成本 / 列易扩展的优势，比较适合平台的场景。根据两类数据的特点，使用了两个不同的集群提供服务：</p><p></p><p>HBase 属性宽表。需要同时支持较高随机读写，故而该集群使用了高性能 SSD 硬盘，开启自带的内存缓存；同时利用 rs group 来区分核心 / 非核心业务，做到互不影响 ;HBase 事件流水表。写量极大，存储量大，但是读量极少，主要用于运营展示页面流水查询，故而选择廉价磁盘型机器搭建集群，能够很好的满足写多读少低成本的需求；</p><p></p><p>由于在内容接入时已经为不同业务生成了星航平台内容统一 ID，从其生成的机制看，经过稍加转换便能保证很好的随机性，从而避免了 HBase 分区的数据倾斜</p><p></p><p>为了支持除星航平台内容统一 ID 之外的其他关键字段的检索（比如标题、作者、分类、标签等等），目前会根据每个业务的配置，把其需要检索的字段入到 ES，从 ES 检索出数据后，根据需要再从 HBase 中查询完整的属性。这里设计上的几个优化点：</p><p></p><p>尽量只存储需要检索的字段，以便减少存储量，降低 ES 成本根据不同业务规模，按季 / 月 / 天分索引，同时采用冷热分离的设置，有定时任务定期将热索引落冷，减少集群整体成本根据需要预先配置好索引模板（比如让字段名形如 *_ik 的字段值自动分词），针对实际业务数据特点设置的配置肯定会优于 ES 自动生成的配置不同业务可配置 Jsonpath 规则，定义 HBase 到 ES 字段的解析映射逻辑，以满足不同业务可配置化的检索需求</p><p></p><p>同时，这里也会异步消费事件 Kafka，将属性 + 事件数据写到离线数仓和实时数仓，离线数仓主要采用司内统一的大数据平台，实时数仓则是选择 Clickhouse 大宽表，作为后续衍生的各种平台分析 + 监控功能的数据底座。</p><p></p><h3>3.9 监控系统</h3><p></p><p></p><p>对于端到端的可观测性和服务稳定性的挑战，复杂系统的可观测性是非常重要的问题。平台的监控不仅包含核心系统的可观测性，也包括外围业务系统的可观测。这里分为 Metrics（指标）、Tracing（链路）、Logging（日志）三部分来介绍。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d8/d82924d88e185818768201639564db89.png\" /></p><p></p><p>图 3-38 管线监控示意图</p><p></p><h2>4. 系统效果</h2><p></p><p></p><p>本文基于腾讯内部多个渠道的对内容的场景需求，高度抽象并深度优化内容处理中台架构，端到端地对系统进行了解耦设计和优化开发，有效地支持了内容生态的业务场景。</p><p></p><h3>4.1 技术效果</h3><p></p><p></p><p>接入效率：强大的接入能力，累计处理百亿级内容数据，支持自定义和模板化的近 10 种异构内容接入，管线创建实现自举，接入周期从 1 周降低至 2 个小时。研发效率：端到端的效率优化，提供三种不同的高效插件开发模式和在线调试模式，支持 30 多个团队的自定义协议和代理协议进行高效封装算法、业务逻辑等数千个算子插件的微服务；算法能力引入从天级别降低至 1 小时，引入百余个算法插件算子；链路编排，提供低代码乐高式自助化编排，支持任意复杂的内容处理链路拓扑编排、调试与上线，整体链路迭代的交付周期从月级别降低到天级别。运行效率：每天数十亿的消息信号，高效的延迟队列补偿保障，水平扩展优先级队列处理机制；融合统一 Pipeline 和 DAG 的调度架构，辅以智能反压稳定性保障；插件共享，每天缓存命中数亿次，为业务节省万余核 CPU、千余张 GPU。基于插件的共享机制和执行状态微批持久化等多种执行优化方案，和列式低成本存储机制，支撑起每日千万级的高效内容处理加工。维护效率：全链路秒级业务内容视角和平台工程视角健康性和追踪性可观测能力。管线的故障恢复、资源伸缩、流量调控通过自动驾驶模块统一管理。目前故障自动处理率 75%+，自愈率 75%+，平均故障恢复时间 2.4 分钟。</p><p></p><h3>4.2 业务效果</h3><p></p><p></p><h4>4.2.1 内容分发</h4><p></p><p></p><p>内容处理中台高效支持了腾讯视频、腾讯新闻、QQ 浏览器、微视、腾讯体育等 10+ 个业务的高效的内容特征级粒度任意链路节点结果进行高效分发。图文处理端到端 P95 耗时下降 59%，视频处理端到端 P95 耗时下降 96%，分发服务最大数据延迟小于 3s，可用率&gt;99.9%。</p><p></p><p>中台提供了事件流订阅和内容特征获取两种内容分发能力。平台上流转的内容定义成一个 doc，一个完整的 doc 包含了两部分字段，一部分来自输入字段，一部分来自链路中编排的能力，随编排逻辑动态变化。在运行过程中，doc 中的字段值随着处理流程的调度执行逐渐被写入。</p><p></p><p>实际生产环境的内容处理链路通常比较复杂，整体耗时在分钟级完成，除了在链路执行成功和中止之外，往往需要实时感知中间态的关键结果产出，因此平台提供了自定义分发点的能力，支持在流程中任意执行阶段进行内容分发，即在流程的任意阶段向变更事件流中写入一次 doc 数据。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/26/266f42529709503204988154388e2801.png\" /></p><p></p><p>图 4-1 内容分发示意图</p><p></p><p>通过内容特征服务可以获取到最新的 doc 特征，但是由于需要调用方发起请求，因此会有实时性的问题，通常只在一次性查询的场景使用。事件流订阅支持按行按列（即内容维度和特征维度）的规则过滤，对接收方提供 at least once 的变更数据投递和最终一致性保证，使用方可以实时感知自身关注的内容和关键处理过程。</p><p></p><h4>4.2.2 内容审核</h4><p></p><p></p><p>内容审核是星航平台的重要使用场景，也是当前内容行业必不可少的业务环节，结合团队自研的通航审核平台，业务可以快速搭建人机协同的内容审核链路。并只需要专注在具体业务场景的需求上，整体交付周期缩短 90% 以上。</p><p></p><p>一般业务都会有“机审 + 人审”的流程需求，通常采用机审在前，人审在后的方式，这样可以尽量减少人力成本。在人审过程中往往需要采用人机协同的方式，使用星航平台可以便捷的将算法计算结果打通到通航平台，在通航平台内部实现人机协同，提高审核效率。这个过程中只需要编排相应的算法插件并调整送审插件的参数而无需开发。</p><p></p><p>相较于传统的开发方式，搭建一条新的审核链路的成本大大降低，开发者可以从重复的工作中解放出来。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/df/df39b74790b030d6fd32effb57c1a755.png\" /></p><p></p><p>图 4-2 内容审核示意图</p><p></p><p>需要注意的是，内容审核相比机器计算具有耗时更长、计算成本更高、结果可变更的特点。为了让审核过程不阻塞内容处理流程，同时可以更好的响应审核结果。内容审核使用异步插件与触发器相结合的方式接入星航。</p><p></p><p>对于先发后审的业务场景，星航平台提供流量触发器的方式并结合规则引擎，实现灵活的送审策略定制，包括流量触发、算法模型触发等。同时基于规则引擎，业务可以控制内容流向的审核队列或者目录，不同的队列之间可以采用串联或者并联的方式，视业务需求而定。内容进入通航后，不同队列或者目录内的任务由专业审核人员进行审核，达到质量和效率的最优配置。</p><p></p><h2>5. 未来展望</h2><p></p><p></p><p>未来，我们将从全链路 TCO 成本出发，以降本提效为目标，从开发效率、运行效率等路径视角，进一步深挖技术给内容业务可能带来的价值。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/32/32e4ad92a84698587025df6456ecdab0.png\" /></p><p></p><p>图 5-1 未来工作方向概要</p><p></p><h3>5.1 插件开发效率</h3><p></p><p></p><p>提升心流式插件开发体验，插件作为根基角色，进一步深度探索低代码 + 函数插件极速开发流程，以云原生函数服务 FAAS 为基础，打造全链路自动化开发、提交、编译、部署、实验、上线、洞察等更成熟的开发方案，让开发者只专注对业务核心逻辑开发。</p><p></p><h3>5.2 智能链路效率</h3><p></p><p></p><h4>5.2.1 智能编排</h4><p></p><p></p><p>提高任务链路编排效率，探索低代码化 + 智能化编排模式，当前开发者可以基于插件开发业务场景的服务编排任务，但存在两个问题，一方面，如果相同或者类似算法插件多，开发者面临选择问题；另一方面，插件和插件之间还存在着依赖血缘关系，面临熟悉成本。所以，后面我们将探索以业务场景诉求为出发点，智能化整合相关插件，提供插件逻辑视图模块化能力，用户直接从业务功能级出发选择插件模块，无需直接通过插件到拓扑的编排，提高开发效率。</p><p></p><h4>5.2.2 路由寻优</h4><p></p><p></p><p>提高系统稳定性并降低系统平响，优化网络请求路由算法，当前一些基础的路由算法不能够满足我们的业务场景，引入网络请求更灵活的 Locality-aware 路由算法，并融合多维度系统特征和业务的实时特征，构建路由权重模型，从资源实际能力角度处理业务请求；同时，我们还将基于全链路效果视角，进一步探索 N3 算法（N 个最近邻居）在路由权重的应用优化。</p><p></p><h4>5.2.3 弹性伸缩</h4><p></p><p></p><p>持续降低内容处理成本，除了系统级资源自动伸缩，我们将从业务本身视角进行物理资源的智能化伸缩，比如，失败率，mttr，业务的某些请求阈值等视角，并通过上文提及的血缘关系，进行水平或者级联等多策略资源伸缩，提高的服务质量，保障用户体验。</p><p></p><h3>5.3 任务运行效率</h3><p></p><p></p><p>提高 CPU 资源利用率和并发能力，在早期系统通过配置及反压的方案上，为了更灵活地动态适配请求的波峰波谷，引入 actor 响应式编程，通过对 actor 的自动伸缩更好利用计算资源，智能化处理计算需求。</p><p></p><h2>6. 结语</h2><p></p><p></p><p>移动互联网内容生态繁荣而复杂多样，内容作为移动时代的信息知识载体，对于不同业务场景，我们往往面对着各种各样的业务和技术挑战，因此，我们将在内容生态业务场景的基础上，不断用技术创新去驱动降本提效，并持续优化内容中台用户体验。</p><p></p><p>作者简介：</p><p></p><p>李欣，腾讯内容处理中台总监，负责内容处理中台的产品规划、技术研发和团队管理工作。</p><p></p><p>王冬，腾讯内容处理中台技术负责人，熟悉后端架构领域、大数据领域的技术产品化工作。</p><p></p><p>蒋靖，腾讯内容处理中台后端开发负责人，关注内容处理、流程引擎、微服务治理等技术方向。</p><p></p><p>施驭，腾讯内容处理中台后端研发工程师，关注云原生、微服务、高并发架构领域技术。</p><p></p><p>李湘军，腾讯内容处理中台后端研发工程师，专注于高并发、高吞吐场景的架构设计与研发。</p><p></p><p>唐伟，腾讯内容处理中台后端研发工程师，关注内容处理业务方向的分布式调度与计算方向。</p><p></p><p>李会珠，腾讯内容处理中台后端研发工程师，海量后端服务设计开发经验。</p><p></p><p>贾洪强，腾讯内容处理中台后端开发负责人，关注关系和非关系型存储中间件方向。</p><p></p><p>刘斌，腾讯内容处理中台后端研发工程师，关注消息队列、云原生领域等技术方向。</p><p></p><p>黎帆，腾讯内容处理中台后端研发工程师，关注大数据，分布式存储等方向。</p><p></p><p>陈昇辉，腾讯内容处理中台后端研发工程师，关注微服务、领域驱动设计等方向。</p><p></p><p>李瀚，腾讯内容处理中台前端开发负责人，长期关注 React/Node 相关技术方向。</p><p></p><p>最后，感谢 kyler、richard、gemini 等的大力支持，以及腾讯内容处理中台团队和相关业务团队每一位成员的共同付出。</p>",
    "publish_time": "2022-08-30 09:56:24",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "去掉 jQuery 后，我们的网站性能起飞，速度快了 17%",
    "url": "https://www.infoq.cn/article/koVBVMOUEzirP1iZWpww",
    "summary": "<p>今年 3 月，英国公共部门信息网站 <a href=\"https://www.gov.uk/\">GOV.UK</a>\" 前端开发主管 Matt Hobbs <a href=\"https://twitter.com/TheRealNooshu/status/1507346592612896768\">宣布</a>\"该公司删除了 jQuery 作为所有前端应用程序的依赖项。近期，GOV.UK 高级前端开发工程师 Andy Sellick 发布了两篇博文详细论述该网站删除 jQuery 的原因、具体操作以及带来的影响。</p><p>&nbsp;</p><p>GOV.UK 是英国政府的在线主页，这意味着它需要适用于所有用户，不论他们的设备、连接速度如何。因此，开发团队也一直在寻找改进性能和用户体验的方法。</p><p>&nbsp;</p><p></p><h2>我们如何在 GOV.UK 上移除 jQuery</h2><p></p><p>&nbsp;</p><p>GOV.UK 主要由静态页面组成，JavaScript 主要用于进行分析、cookie 和小型用户界面交互。其中，<a href=\"https://xie.infoq.cn/article/75af33f56d01e34c51d0336fc\">jQuery</a>\" 被广泛应用在网站中，比如面向公众的脚本和测试文件部分。当然应用大多使用了 jQuery 的诸多特性，特别是 <a href=\"https://xie.infoq.cn/article/6398ab61a5ee83ae4d31b9d74\">Ajax</a>\" 部分。</p><p>&nbsp;</p><p>使用 jQuery 的缺点是它必须包含在页面资源中，这会减慢网站的加载速度，GOV.UK 的页面大小不一，但主页约为 246 kB ，其中 32 kB 为 jQuery。并且 GOV.UK 在之前还使用的是旧版本的 jQuery。于是，开发团队评估了项目情况之后，做出一个重大决定——与其升级新版 jQuery，不如直接将它从项目中删除。</p><p>&nbsp;</p><p>首先，开发团队不再在 GOV.UK 中引入任何新的 jQuery。</p><p>&nbsp;</p><p>其次，团队中前端开发者和后端开发者都投入到这份工作中。虽然后端开发者通常并不会编写大量 JavaScript ，但经过培训，他们意识到这项任务的重要性并且很快取得了重要进步。</p><p>&nbsp;</p><p>经过一系列努力，开发团队很快发现整个应用程序基本完成了移除 jQuery 的任务，并且他们从中还发现这个额外的努力可能会将项目的开发直接缩短几年的时间。那么，这一改变对于用户来说又意味着什么呢？</p><p>&nbsp;</p><p></p><h2>去掉 jQuery 究竟影响有多大</h2><p></p><p>&nbsp;</p><p></p><h4>图像数据与压缩数据</h4><p></p><p>&nbsp;</p><p>上面提到，jQuery库是一个被压缩和缩小到只有32KB的JavaScript。虽然与几兆字节大小的图像相比，它看起来并不大。但是，从性能的角度来看，当它出现在每一个网页上时，已经相当于大量数据。另外，图像数据和压缩的JavaScript数据之间有很大的区别。浏览器和设备处理这两种数据的方式非常不同。</p><p>&nbsp;</p><p>JavaScript被称为“阻塞渲染”资源，浏览器在遇到JavaScript时会经历一个多步骤的过程，包括下载、解压、解析和执行。这一切都需要消耗设备的CPU和内存。根据设备和网络连接的不同，这些任务可能会非常缓慢和消耗能量。</p><p>&nbsp;</p><p>问题是，在这个过程中，向设备屏幕绘制像素的任务必须暂停，直到JavaScript执行完成。完成后，浏览器可以继续为页面的其余部分绘制像素。</p><p>&nbsp;</p><p>相反，图像和图像数据不是“阻塞渲染”的，也就是说，在并行下载额外的图像数据时，网页的其他部分可以正常绘制。因此，一个32KB的图像比32KB的压缩JavaScript对性能的影响要小得多，对于使用较慢、较老、较便宜的低配置设备的用户来说尤其如此。</p><p>&nbsp;</p><p></p><h4>拯救低配置设备</h4><p></p><p>&nbsp;</p><p>低配置设备通常指旧的笔记本电脑和平板电脑，或者“经济型”移动设备（通常是数据流量有限的Android设备）。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/29/72/29f2c8ee64daf790b4fd97f0e2a0d172.png\" /></p><p></p><p>值得一提的是，目前开发团队从用户设备收集的匿名真实用户监控（Real User Monitoring，RUM）数据显示，GOV.UK已经是一个非常快的网站。但分布图（见上图）也显示，有些用户的页面加载时间高达2.35秒。仔细检查了这些用户的RUM性能数据，团队发现：</p><p>&nbsp;</p><p>75%的用户来自英国；35%的用户使用Android设备；在屏幕上显示第一个页面像素大约需要2秒（即初始渲染）。</p><p>&nbsp;</p><p>从上面的统计数据来看，可以认为很多Android用户使用的是CPU速度和内存容量都很有限的低配置设备。基于这样的假设，删除32KB的压缩JavaScript会对性能产生什么影响？</p><p>&nbsp;</p><p></p><h4>对性能影响进行测试</h4><p></p><p>&nbsp;</p><p>“基于实验室”的性能测试在这个时候起到了很大的作用。开发团队每天使用特定的模拟设备和连接速度测试GOV.UK的页面。因为他们每天都重复这些测试，所以能够监测网站所做出的变更对于用户来说究竟产生了怎样的影响。</p><p>&nbsp;</p><p>例如，对于一个使用低配置设备和2G移动网络访问统一福利金起始页的模拟用户，可以从图中清楚地看到去掉jQuery前后的性能对比。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/61/45/617420827fc1dae57b762552864ce345.png\" /></p><p></p><p>之所以选择统一福利金页面，是因为这个页面是GOV.UK访问次数最多的页面。如上图所示，页面将像素完全绘制到屏幕上所需的时间（视觉完成度）从11.3秒下降到9.4秒（速度提升了17%）。</p><p>&nbsp;</p><p>除了在视觉完成度方面的改进，页面加载时间的改进也很明显。从下图可以看出，页面完全加载时间从20.42秒下降到18.75秒（缩短了8%），页面加载总时间从19.44秒下降到17.75秒（缩短了9%）。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/59/0a/591211c0cbd47e9e9ac922afdc34580a.png\" /></p><p></p><p>最后，页面交互性能指标也有显著的改进。交互性指标对用户来说很重要，因为它们决定了用户何时可以开始与页面发生交互。从下图可以看出，交互时间从11.34秒下降到9.43秒（缩短了17%），设备第一次CPU空闲（First CPU Idle）从11.32秒下降到9.42秒（缩短了17%）。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/f8/1b/f8d6e5eaae74a6b6525104344a2e441b.png\" /></p><p></p><p></p><h2>写在最后</h2><p></p><p>&nbsp;</p><p>jQuery 于 2006 年推出，一度曾在 JavaScript 世界里风头无两。但事实上，近些年对于“jQuery 是否已死”的讨论却从未停止。2018 年，GitHub 宣布从 GitHub.com<a href=\"https://mp.weixin.qq.com/s?__biz=MzUxMzcxMzE5Ng==&amp;mid=2247489258&amp;idx=1&amp;sn=e8e98c56f277ff33acecdf059bf9a0a1&amp;chksm=f951a3a9ce262abfa1113a4f6ce6cbd740d3fb87e09a8f8290e298e224a4e1ee038d1c087fa8&amp;token=1416664194&amp;lang=zh_CN&amp;scene=21#wechat_redirect\"></a>\"的前端代码中完全移除了 jQuery，除此之外， jQuery 的主要用武之地之一，著名的 CSS 框架 Bootstrap 在最新版本中也<a href=\"https://www.infoq.cn/article/4NCf6s8mHQENrcUQMQN5\">停用了 jQuery</a>\"。</p><p>&nbsp;</p><p>不过即便 jQuery 在近些年不再受到欢迎，但据 <a href=\"https://www.wappalyzer.com/technologies/javascript-libraries\">Wappalyzer 的分析报告</a>\"显示，在所有使用了 JavaScript 库的网站中，jQuery 仍然占据着超过 34% 的比例。可见，jQuery 在许多场景中仍然是非常有帮助的，当然如果你想把 Web 应用的性能优化到极致，正如 GOV.UK 团队实践的那样，jQuery 并不可取。</p><p>&nbsp;</p><p>只能说，jQuery 从始至终都更适合那些重内容而非功能的网站。</p><p>&nbsp;</p><p>延伸阅读：</p><p>&nbsp;</p><p><a href=\"https://www.infoq.cn/article/fH1V7lhk2KzDNvNlBVP5\">jQuery已“死”？为清除技术债，我们删掉了前端所有jQuery依赖</a>\"</p><p>&nbsp;</p><p>参考链接：</p><p>&nbsp;</p><p><a href=\"https://insidegovuk.blog.gov.uk/2022/08/11/how-and-why-we-removed-jquery-from-gov-uk/\">https://insidegovuk.blog.gov.uk/2022/08/11/how-and-why-we-removed-jquery-from-gov-uk/</a>\"</p><p>&nbsp;</p><p><a href=\"https://insidegovuk.blog.gov.uk/2022/08/15/the-impact-of-removing-jquery-on-our-web-performance/\">https://insidegovuk.blog.gov.uk/2022/08/15/the-impact-of-removing-jquery-on-our-web-performance/</a>\"</p><p>&nbsp;</p><p><a href=\"https://tehub.com/a/8zSJjaGliy\">https://tehub.com/a/8zSJjaGliy</a>\"</p>",
    "publish_time": "2022-08-30 10:16:28",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Spring Authorization Server计划2022年11月发布1.0版本",
    "url": "https://www.infoq.cn/article/yjpqLbHMuAm0GyaXAOY0",
    "summary": "<p>在<a href=\"https://spring.io/projects/spring-authorization-server\">引入</a>\"Java社区仅仅两年之后，<a href=\"https://spring.io/projects/spring-authorization-server\">Spring Authorization Server</a>\"就<a href=\"https://spring.io/blog/2022/07/28/spring-authorization-server-is-going-1-0\">计划</a>\"在2022年11月份1.0 GA版本。Spring Authorization Server项目取代了业已<a href=\"https://spring.io/blog/2022/06/01/spring-security-oauth-reaches-end-of-life\">结束生命周期</a>\"的<a href=\"https://spring.io/projects/spring-security-oauth\">Spring Security OAuth</a>\"项目。Spring Authorization Server项目由Spring Security团队领导，为Spring应用提供了<a href=\"https://oauth.net/2.1/\">OAuth 2.1</a>\"&nbsp;Authorization Server的支持。</p><p></p><p>该项目基于<a href=\"https://spring.io/projects/spring-security\">Spring Security</a>\"&nbsp;6.0，依赖于<a href=\"https://www.infoq.com/news/2021/09/spring-6-spring-boot-3-overhaul/\">Spring Framework 6.0</a>\"，至少需要Java 17和Tomcat 10/Jetty 11。该项目的公开API和配置依然在改进之中，这可能会给使用它的应用带来破坏性的变更。</p><p>GitHub上的<a href=\"https://github.com/spring-projects/spring-authorization-server/milestones\">Milestones</a>\"页面显示了各种即将发布的里程碑版本和发布候选版本，这些版本将会推进Spring Authorization Server 1.0版本的正式发布。另外，Spring Authorization Server 0.4.0将会基于Spring Security 5.x和Java 8发布。</p><p></p><p>Spring Security OAuth是在十年前首次推出的，后来发展成了一个流行的项目，支持OAuth规范的大部分内容。它是各种项目中OAuth方案的基础，涵盖OAuth的消费者和供应者，如<a href=\"https://github.com/cloudfoundry/uaa\">CloudFoundry用户账户和认证</a>\"（UAA）。它同时支持OAuth 1.0和2.0，而1.0现在已经过时了。令人遗憾的是，该实现并不支持一些特定的用户场景，它的实现有很大一部分是由Spring团队编写的。</p><p></p><p>为了支持OAuth 2.0，Spring Authorization Server是完全从头编写的，它基于<a href=\"https://connect2id.com/products/nimbus-oauth-openid-connect-sdk\">Nimbus</a>\"库，支持更多的特性，比如<a href=\"https://auth0.com/docs/secure/tokens/json-web-tokens/json-web-token-claims\">JSON Web Token</a>\"（JWT） claims、<a href=\"https://auth0.com/docs/authenticate/protocols/openid-connect-protocol#what-is-openid-connect-oidc-\">OpenID Connect</a>\"（OIDC）和反应式编程。</p><p>VMWare Tanzu为Spring Authorization Server提供了<a href=\"https://tanzu.vmware.com/support/oss\">开源软件支持</a>\"和<a href=\"https://tanzu.vmware.com/spring-runtime\">商业支持</a>\"。</p><p></p><p>Spring项目欢迎来自社区的贡献，并建议阅读Spring Authorization Server的<a href=\"https://github.com/spring-projects/spring-authorization-server/blob/main/CONTRIBUTING.adoc\">贡献文档</a>\"。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/08/spring-authorization-server-1-0/\">Spring Authorization Server 1.0 Planned for November 2022</a>\"</p>",
    "publish_time": "2022-08-30 11:01:49",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "我同情所有的Scrum团队，因为他们经常被指导得死去活来",
    "url": "https://www.infoq.cn/article/Vd3rNRQjziCvDrxl93SC",
    "summary": "<p></p><blockquote>公司领导层是 Scrum 团队前进的绊脚石。</blockquote><p></p><p></p><h2>“敏捷只适用于团队”是一种错误观念</h2><p></p><p>&nbsp;</p><p>我同情所有的 Scrum 团队，他们尽其所能使他们的 <a href=\"https://xie.infoq.cn/article/255c56b6783c071da4b6af844\">Scrum </a>\"发挥作用，但却受到了管理层的阻挠。我遇到过许多团队，他们非常了解 Scrum 的理念，并且通常会在头几个月中取得巨大的进展。但很快，一切就戛然而止了。</p><p>&nbsp;</p><p>公司领导层是 Scrum 团队前进的绊脚石。更糟糕的是，这个团队还会因为停滞不前而受到指责。所以，他们要么被派到其他的培训机构，要么就是聘请外部教练来提高团队的水平。而与此同时，“房间里的大象”却没有被提及。管理者和企业的领袖们还是老样子，因为“敏捷只适用于团队”，这对他们没有任何的影响。</p><p>&nbsp;</p><p>“敏捷只适用于团队”是一种严重的错误观念，而且会造成很大的伤害。不仅团队在创造高价值产品方面受到限制，心态也会有所变化。他们觉得自己被束缚了，会感到失望、沮丧，这可不是工作中最好的心态。</p><p>&nbsp;</p><p>Scrum 团队通常在自我管理方面非常出色，但他们在许多方面都被组织所束缚。</p><p></p><h2>被束缚的 Scrum 团队</h2><p></p><p></p><h4>Scrum 团队需要决定做什么、如何做、何时做</h4><p></p><p>&nbsp;</p><p>在复杂的工作中，有一个很大的特点就是你不能提前预知哪些东西能给你带来最大的价值。</p><p>&nbsp;</p><p></p><blockquote>“在复杂的环境中，会发生什么是未知的。”&nbsp;——《<a href=\"https://scrumguides.org/scrum-guide.html#scrum-team\">Scrum 指南</a>\"》2020</blockquote><p></p><p>&nbsp;</p><p>你需要迈出一小步，从这一步中学到一些东西，再决定下一步该怎么做。团队需要有创意地协作来迈出这一步，以实现下一阶段的产品增长。</p><p>&nbsp;</p><p>这就是为什么 Scrum 团队应该决定做什么、如何做和何时做。产品负责人是决定产品 Backlog 顺序的人，这也是 Scrum 团队的唯一工作来源。这是 Scrum 的一个基本要素。</p><p>&nbsp;</p><p>但是，这并不意味着管理者和 Scrum 团队之外的其他人员能绕开产品负责人，向 Scrum 团队提出请求或指令，这样毫无意义。但在实际中，这也是常有的事，最终会影响到团队在处理复杂问题时的反应。</p><p></p><h4>不能过度依赖工作计划</h4><p></p><p>&nbsp;</p><p>与告诉团队做什么几乎同样具有破坏性的是，允许团队创建自己的计划，但告诉他们要坚持这些计划，并把精力投入到工作中。</p><p>&nbsp;</p><p>承诺本身是一件好事，它甚至是 Scrum 五大价值观之一。但是在复杂的环境中，团队不可能对一个详细的基于产出的计划做出承诺。你不知道要达到目的，必须要做些什么。</p><p>&nbsp;</p><p>更重要的是，如果按计划交付全部的产出，也不会获得成功，你不知道你所创造的东西能否达到你的目的。构建产品增量的全部意义，就是要知道你是否已经朝着你的目标迈进了一步。</p><p>&nbsp;</p><p>团队依然可以作出承诺，但是要在接下来实现自己的目标。Scrum 团队将 Sprit 的目标视为 Sprint 的一项承诺，他们有产品目标作为他们的长期承诺。</p><p>&nbsp;</p><p>那些告诉团队要把精力投入到他们计划的管理者们，实际上就是要求团队忘记从自己所创造的东西中吸取经验教训。管理者认为这个时间是可以预测的，这种想法会给 Scrum 的有效性带来灾难。这一点，Scrum 团队中的所有人都心知肚明。</p><p></p><h4>解决组织障碍</h4><p></p><p>&nbsp;</p><p>Scrum 团队并不是孤立地工作，他们属于一个组织的一部分，他们必须与该组织的文化、程序、规则和条例打交道。这很合理，但许多 Scrum 团队会挑战现状，他们需要寻求更好的方式来完成自己的工作，并取得成效。这就意味着，Scrum 团队必须要处理好组织中的各种障碍。</p><p>&nbsp;</p><p>比如，一些组织内部的文化也许并不符合 Scrum 的理念，程序、规则和条例可能会阻止团队迅速地对他们所做的事情做出反馈。如果这是阻碍团队前进的因素，那么就应该做出改变。如果管理者和企业领袖忽略或者拒绝做出改变，Scrum 团队就会不可避免地碰壁。</p><p>&nbsp;</p><p>Scrum 团队将达到一个不能再提高的程度，当他们无法再提高时，也很难继续取得进展。</p><p></p><h4>改变领导层的想法</h4><p></p><p>&nbsp;</p><p>上面几个例子讲的都是管理者和企业领袖怎样妨碍 Scrum 团队有效工作。但是在大部分时间里，Scrum Master 和敏捷教练的关注点都只在团队上，他们得到了大量的培训和教练指导，或是被投入到另外一个敏捷转型中去。</p><p>&nbsp;</p><p>你不能尝试说服那些相信敏捷的人，他们要么已经加入了你的阵营，要么对实际的执行情况感到心灰意冷，愈发怀疑。</p><p>&nbsp;</p><p>在这种情况下，Scrum Master（和其他敏捷教练）应该专注于解决经理和公司领导的想法。如果问题出在这些人身上，进展受到阻碍是由于他们对于敏捷的认识有误，那就把矛头对准他们。</p><p>&nbsp;</p><p>对管理者和企业领袖们进行指导。将 Scrum 的实施范围扩大到他们。毕竟，Scrum 团队能否取得成功，管理者和利益相关者是关键。（延伸阅读：《<a href=\"https://medium.com/serious-scrum/managers-can-make-or-break-your-scrum-teams-their-influence-is-essential-7acfeed8a417\">经理可以决定你的 Scrum 团队的成败——他们的影响力至关重要</a>\"》）</p><p>&nbsp;</p><p>你可以通过以下方式改变管理者和企业领袖对敏捷的认识：</p><p>&nbsp;</p><p>创建并交流愿景。把愿景和企业的目标结合起来。建立起一种互信的氛围。承认 Scrum Master 是一个同时支持组织的领导者。了解自我管理和跨职能团队的重要意义。帮助组织进行变革，排除阻碍 Scrum 团队发展的因素。</p><p>&nbsp;</p><p>领导层需要设定目标，让 Scrum 团队摆脱束缚，其余的问题将迎刃而解。</p><p>&nbsp;</p><p>作者介绍：</p><p>&nbsp;</p><p>Willem-Jan Ageling，作家、编辑，Serious Scrum 的创始人。喜欢写关于价值最大化的文章。</p><p>&nbsp;</p><p>原文链接：</p><p>&nbsp;</p><p>https://medium.com/serious-scrum/scrum-teams-are-often-coached-to-death-while-the-problems-are-with-management-60ac93bb0c1c</p>",
    "publish_time": "2022-08-30 14:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "圆桌对话：中国操作系统到底有没有角力世界舞台的实力？",
    "url": "https://www.infoq.cn/article/EJFlBj7fvB40J3EXVjkp",
    "summary": "<p></p><blockquote><a href=\"https://www.infoq.cn/theme/141\">操作系统</a>\"是计算机的灵魂所在，更是现代社会数字经济转型的关键。随着国内科技力量的壮大，当出现如 CentOS 停服等机遇时，会进一步助推国内操作系统发展。如今国内开源操作系统遍地开花，我们到底有没有角力国际舞台的实力呢？在&nbsp;<a href=\"https://xie.infoq.cn/article/250a610f1def4b3cd8331006b\">2022 开放原子全球开源峰会</a>\"上，多位专家共同参与讨论了“中国操作系统到底有没有角力世界舞台的实力”这一话题，本文为圆桌对话内容实录。王兴宇（主持人）：Linux 中国开源社区创始人杨勇：龙蜥社区技术委员会主席、阿里云操作系统技术总监杨继国：龙蜥社区理事、Intel 技术总监&nbsp;王洪虎：龙蜥社区技术委员、龙芯中科操作系统研发总监&nbsp;陈鲍孜：龙蜥社区技术委员、飞腾操作系统负责人王戍靖：中科方德高级副总裁&nbsp;</blockquote><p></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/90/db/904de049fc0e9d43dfec5b59d137a1db.png\" /></p><p></p><h2>一</h2><p></p><p></p><p>王兴宇：如今国内的各个开源操作系统百花齐放，但是与国际厂商相比，大家认为我们目前的强项在哪里，弱项在哪里？</p><p></p><p>王戍靖：近年来国内操作系统开源社区发展迅速，但发展时间短，与国际社区相比有一定差距。操作系统社区基于大量基础技术，包括芯片、编译、开发工具等基础技术领域，也包括大数据、人工智能、云计算等新兴技术方向，需要长期培育积累和技术创新。</p><p></p><p>有利条件是中国开源处于快速发展阶段，中国开发者数量增长快，据 GitHub 2021 年数据统计，中国开发者数量已增至&nbsp;700 多万，排名全球第二，贡献了&nbsp;550 万个开源项目；另外，我国数字经济转型升级推动信息产业持续增长，新兴技术领域也在迅速发展。以上都为国内开源操作系统社区发展提供了坚实的基础和动力。</p><p></p><p>陈鲍孜：从主导具体的开源项目看，国内操作系统社区的发展还是有欠缺的，毕竟我们参与的时间比较短。但国内的开发人员不管从数量还是活跃程度方面，在国际上即使不是最好的，也算处在了第一梯队之上。我和国外开发者进行过一些交流。他们有一个观点，即如果一个国家制造业强大，那么制造业就是做操作系统或者系统软件的动力。从这个层面来看，我认为我们的潜力和需求动力并不比国际差。</p><p></p><p>杨继国：中国现在的操作系统社区处于高速发展的时期，说到不足的地方，第一点：因为我们的发展时间没有那么久，所以缺乏创新积累。一个操作系统社区能够长期发展的很重要的一点就是原创，需要有自己的特色。中国有一个很大的优势就是开发者很多，对开源来说开发者是一个整个社区开源创新的基石。我看过相关报道，中国开源开发者从数量上来讲在世界上处于一个比较领先的地位，我们怎么样把这些开发者转化成开源社区持续创新的动力，这是很重要的一个问题，我觉得还需要时间。</p><p></p><p>第二点：国际上游社区对我们的影响。因为操作系统有上游和下游的关系，上游社区会带动一些科技的发展包括创新。同时下游社区不仅仅兼容上游的技术，很多时候也能反过来影响上游社区，像国际上大的厂商有能力能够去影响上游开源，中国的操作系统开源社区也可以通过不断创新去扩大影响力。因为我们有能源、电力、金融等各行各业的参与，有非常强而切实的需求，所以我相信我们能把这些需求的影响代入到上游社区。</p><p></p><p>王洪虎：我觉得这个问题应该从两个方面来看，首先，相对国外来说我们的时机和发展历程确实相对短一些，客观来讲确实存在一些差距。但是另一方面，我们也应该看到一些希望，比如今天演讲中讲到我们提升了原创的东西，国内的社区已经具备这种创新能力，还不止是局部一个点，而是各个层面都有。说明我们至少在有短板的前提下，在有差距的情况下也能够发现一些局部的创新。随着国内多元化市场的不断实践，在这个过程中会产生大量的创新基石和土壤。未来，我相信随着国内各行各业的蓬勃发展，我们在上游社区的声音和力量会越来越强大。</p><p></p><p>杨勇：我简单说一下观察到的一个现象，CNCF 中国人孵化的项目非常多，比如说国内 PingCAP 这样优秀的项目，包括阿里也有一些项目在 CNCF 中，包括像龙蜥社区参与的&nbsp;Nydus 项目和 Confidential Containers 项目。所以新的领域、新的机会、新的需求不断出现的时候，这是我们难得的机会，也是一个很好的突破点。</p><p></p><p>但在内核领域或者编译器等发展比较成熟的领域，我们的顶尖人才保有量确实是不够的，原因是历史积累造成的，因为过去这个产业基本上发展得不够，但是今天国内无论对芯片还是<a href=\"https://www.infoq.cn/article/QguHG8yPXkAe4SeiBDh5\">操作系统</a>\"整体产业的投入是比前几年要大得多的。“板凳要坐十年冷的精神”要坚持下去，我认为新一代程序员会快速成长起来。</p><p></p><h2>二</h2><p></p><p></p><p>王兴宇：感谢各位老师的发言，总结下来我们确实在有些地方还发展得比较慢，但是长处在于我们确实有大量的程序员，根据调查来看中国在 GitHub上的注册用户比例相当高。同样我们拥有更广阔的用户市场，就会有更多的行业需求，这样的发展趋势下我国的规模优势就会发挥出来。目前来看确实如几位老师所说，我们在尖端的项目上还缺少足够有影响力的话语权，但是现在已经在逐渐多点开花，多点释放，未来可期。</p><p></p><p>杨勇：吸引国际厂商合作，我觉得对龙蜥社区来说是一个很大的命题。我们能看到龙蜥把芯片、云厂商、OSV 厂商等拉到一起去发生合作，最近又把服务器厂商拉了进来，实际上这是一个滚雪球的过程。这件事情本质上是需求和供给，合作的本质也是双赢，社区需要思考清楚几个问题“世界领先厂商加入到社区他想要获得什么，以及我们社区能给到什么”，这是一个很重要的话题。</p><p></p><p>我认为社区合作一方面要有自己的商业本质在里面，因为今天这个市场里的开发者以机构为主，以组织为主；另一方面是社区文化，社区还是要有一个比较开放透明的机制，整体社区的运作是非常开放平等的，这个很重要。总结来说，第一点是内在的驱动力，第二点是阻力摩擦力小。</p><p></p><p>王洪虎：从芯片角度讲，能够吸收国际厂商的参与，一方面需要对方对我们的创新感兴趣，并且从我们这儿能得到他想要得到的东西，这是吸引力。另外一方面，从龙芯角度讲，我们提供一个新的架构支持，这本身就是创造一个新的需求，要在龙蜥社区有支撑的架构，这里面方方面面的事情是非常多的。随着将来龙蜥架构走向国际，自然会有更广范围的爱好者和机构参与，这里面也会产生对国际爱好者开发者的需求。</p><p></p><p>杨继国：像龙蜥社区能吸引国际参与者保持比较强的兴趣，有几个方面原因，第一个我们能继续保持透明、开放、公正的原则，这点是非常重要的，无论从技术发展还是从社区的推广治理角度来说，这点是能保持和国际社区接轨，吸引众多人参与的重要原因。当然龙蜥社区做得非常好，第一次参加理事会就发现这个社区保持非常好的传统，一直发扬下去。</p><p></p><p>第二点中国开发者的人群非常大，我们希望通过努力能把更多的开发者吸引到社区里来，能保持这个社区的多样性，鼓励大家多多创新。</p><p></p><p>第三点我想对于这个社区的开发者来说，我们在做这个社区的开发包括架构设计，一定要有一个社区文化，比如在 Intel，我们在做架构设计的时候应该考虑到用户的架构设计应该能适应更多的架构，而且有更多的包容性，不仅仅只做芯片。对整个社区发展来说，更加中立更加有包容性的社区是很重要的，这一点我觉得是国际社区发展的成功关键，实际上能对中国社区也是如此。</p><p></p><p>陈鲍孜：我认为社区的发展，本质上在于参与社区的开发者解决自己的问题。每一个社区项目都是由社区的开发者驱动。开发者首先自己要能够长期地生存并发展下去。只有当社区开发者在解决自己问题，他才有源源不断的动力来维系这个项目。当社区开发者解决的自身问题是共性问题的时候，自然就能吸引到那些有着相同兴趣爱好或者相同诉求的人一起参与到这个项目里来。</p><p></p><p>这时候，如果我们的社区有比较好的机制、比较开放的文化、比较好的规则的话，我认为无论开发者是来自国际还是国内，社区自然会自发地运作起来。实现这个目标，我觉得一方面是需要有过程，另一方面也取决于当前需要做的事情自身的难点和所解决的痛点，取决于当前事情是否具有普适性。从时间的角度，如果项目能做得足够长，那总有一天会解决大家共有的痛点，届时开发者自然会参与进来。</p><p></p><p>王戍靖：大家都提到社区开放和公正，这是运营社区的一个基础条件。一个开源社区能获得包括国际开源社区在内的各界广泛关注，我认为不仅在于社区自身影响力大，SIG 组的技术创新方向的设立也是一个关键因素。社区如果基于产业和市场需求，关注有哪些重要的技术问题亟需解决，主动引导、推进 SIG 组设立，这样参与社区的机构和个人会有内在驱动力去投入，为技术创新做贡献。</p><p></p><h2>三</h2><p></p><p></p><p>王兴宇：感谢各位老师的意见分享。我觉得如何吸引国外的开源社区，国外的厂商参与我们，首先，固然我们要有开放包容的状态。其次，我们要更加的接纳国外开源社区人员的习惯，比如他们用的语言，我们是不是有更国际化的语言。最后，还有刚才王戍靖老师说的 SIG 组情况，我们一般把 SIG 翻译成“专门兴趣”，但是也有另外一种说法是“特别利益”，第二种说法这里面确实关乎他的利益，如果我们能给他提供关乎他利益的东西，他自然会参与。</p><p></p><p>除了要“请进来”还要“走出去”，中国的操作系统要有中国的特色，但也应该是一个国际的操作系统，不仅能满足国内的用户，而且也能满足东亚地区人群需求，甚至中欧地区人群需求。这种情况下，我们如何能让中国开源社区发展起来，具有国际影响力，并得到国际市场的欢迎呢？</p><p></p><p>王戍靖：中国处于数字经济转型升级阶段，信息产业蓬勃发展，涌现了大量行业需求和市场空间，给国内操作系统开源社区提供了发展特定技术方向并引领技术发展的机遇。比如，龙蜥社区定位在要打造云计算的原生生态社区，以此为目标，可以聚拢大批软硬件生态厂商，逐步形成社区特色、并推动形成有影响力的软硬件行业标准，实现与国际相关标准接轨、兼容。随着中国开源社区持续发展，社区开源版本以及针对特定地区需求衍生的操作系统商业发行版在国内、国际市场上不断推广应用，中国操作系统开源社区在国内、国际上影响力会不断提升。</p><p></p><p>陈鲍孜：我觉得走出去这件事可分几步看。一方面，当社区吸引了足够多海外开发者时，它基本就能算走出去了。从另一个角度看，我们的衍生发行版是不是能走出去，取决于我们衍生出来的发行版所在行业是不是能够有效地走出去。我们所说的操作系统大多数时候是一个宽泛的概念。如果我们不专门讨论操作系统内核或者操作系统其他某个特定的技术模块时，操作系统更多时候是泛指支撑应用的载体。如果我们的应用能走出去，同时我们的衍生版本能够贴合应用场景，满足应用需求，那么届时我们的基础软件社区也就走出去了。</p><p></p><p>杨继国：我想我们中国的操作系统包括社区能走出去，我想有三点，第一点我们要有自己的特色，取代 CentOS 只是第一步，顺应环境的发展，本身社区要有自己的长远发展，包括操作系统的架构设计、能够解决一些痛点的业务等。</p><p></p><p>第二点是生态，因为国外生态和中国生态有很多不一样的地方，如果我们想走向国际舞台，很重要的一方面是要能吸引更多的国外厂商参与，比如 OSV，因为欧洲和美国都不一样，每个地区都有自己的 OSV 也好，SV 也好，包括 VEM，这些国际化厂商的生态伙伴的加入，对于国际化很重要，因为每一个生态伙伴都覆盖了相当大的范围，只不过是不同类型的。</p><p></p><p>第三点与国际上游社区的紧密合作，这个也是非常重要的一点。因为国家的科技发展对第三社区有很大的依赖性。</p><p></p><p>王洪虎：关于走出去，我想有三个方面要重点考虑，第一要能走出去首先要具备走出去的能力，第一个操作系统是社区发行版，这个发行版应该具备发行版所应该具备的基本能力，比如稳定性，因为我们做一个面向云计算的操作系统社区版，稳定性和长期维护性对用户来说是非常重要的一项。</p><p></p><p>第二个方面我们要走出去，实际上要落实到一个一个的软件包，以一个的具体软件的形式走出去。像刚才杨总讲地要往上游社区贡献相当多的自己的原创性的优化的补丁，自己原创性的软件，要走到国际性的像内核这样的社区去，随着这个进程走出去的软件包越来越多，自然发行版社区也就走出去了。走出去是为了要解决用户的需求，我们走出去用户发现没有任何作用，实际上也是走不出去的。</p><p></p><p>我们走出去首先要考虑用户对我的需求是什么，用户的痛点是什么，比如 CentOS 停服全世界面临同样的问题，我们既然能在国内解决这个问题，国际上也能解决这个问题，从我们自己的发展来讲，我们能满足用户的需求能力。</p><p></p><p>第三方面还要考虑刚才上一个话题里聊到的开放协作、创新、平等，这正好也是龙蜥社区的理念，我们以这种理念走出去，世界才能接受我们。</p><p></p><h2>四</h2><p></p><p></p><p>王兴宇：其实说起“走出去”的话题，我印象中比较深刻的就是龙芯，龙芯近一两年不断向上游向内核，比如向 GCC 提交自己的补丁，也得到了国际社区的认可，能支持、能理解、能看到你的东西，这是很好的。另外像王戍靖老师说的，我们确实要针对它的需求做下游的发行版，可能中国人对这方面的需求或者认知跟其他国家不一样，能不能给它做不同的下游发行版。</p><p></p><p>下面最后一个问题，对于如今中国开源操作系统市场大家又竞争又合作，这种情况称之为“竞合”，如何能开展良性竞争生态？</p><p></p><p>杨勇：如果是没有竞争的市场，要么你是新进来的先驱者，要么这个市场里已经看不到机会了。我觉得有竞争不是坏事。国内操作系统的生态都是 Linux 的生态，大家在这个大的生态里面有一些共同的合作基础。我相信不管有多少社区，我们要做的事情是让我们的生态伙伴和开发者，以更低的成本接入到这个大的生态合作中来。我认为龙蜥社区在合作方面将来要把标准和有利于大家共同利益的东西推到上游，或者变成一个行业标准。这方面是一个非常的的合作机会。我认为因为云计算存在很多的不确定性，就必然带来竞争，竞争就带来大家高水平的成长和发展。在这种不确定性下我觉得多一种的竞争对整个产业是有利的，因为谁都不知道未来会演进向哪里。</p><p></p><p>王洪虎：竞争在各行各业都存在着，IT 行业尤其激烈，竞争可以使行业内取长补短，相互促进，假如说没有竞争会怎样，估计肯定不会发展到现在这个样子。</p><p></p><p>从龙蜥社区本身来讲，我们是一个技术社区，并不是一个商业组织，更多是从技术层面考虑问题。怎么样解决技术层面能解决的问题，这是龙蜥社区要考虑的，比如解决行业云计算领域或者 CentOS 停服这类的技术问题。从这个角度讲技术本身没有限定一家使用，刚才杨总讲的是提交到内核社区里的，我们龙芯也是提交到内核社区里的，提交出去之后并不是说这个补丁仅限于某个社区使用，其他不能使用，没有那么狭隘。再一个从龙芯开放协作的发展理念讲，我们发展竞争合作关系都是从局部来讲，但是在大的方向上我们在共同推进技术的进步，这是一个更大的格局。</p><p></p><p>杨继国：现在从中国的操作系统来看更多推动这个市场进一步扩大。因为我自己做操作系统做了二十几年，我们都是做这行做了很久，我们刚开始做这个行业的时候很多的工作，包括做了很多的开发也好，大家对技术管线没那么关注。现在突然赶上这个时期，行业的需求突然增加了，大家对操作系统、基础软件各行业关注非常大，我们在无论是互联网行业还是政企，还是运营商电信行业，操作系统处在非常快速的发展时期。有些标志就是会有投资公司给你递名片，说明资本已经关注这个行业，这个行业处在一个起飞的前沿。</p><p></p><p>当下，我们社区应该怎么样把蛋糕做大，能把 Linux 操作系统基础软件精准推广是重中之重。回到竞争的话题，其实技术上永远有竞争，国际上也是这样的。从 Linux 的发展来看技术竞争，本质是共同推动技术的发展，以前技术受到时代局限性，新的技术会取代旧技术，不同公司通过不断演进合作和竞争都能促进发展，这个对整个的操作系统发展是有利的。</p><p></p><p>陈鲍孜：开源软件不仅是技术架构，其发展模式也存在层次。不同的发行版会根据自身定位以及需求选择不同层面的重点。社区的发展是以技术驱动为主的。不同发行版之间在发展技术上并没有太大的矛盾。大家目的都是为了把整个 Linux 大生态做好。所以从技术方面说，我不认为国内存在很多排他性竞争。更多情况大家是在相互促进。</p><p></p><p>从市场竞争结果来看，不同发行版的发展也会根据所处行业及需求去进行选择，从而提供更丰富的多样性，而不是产生排他性。现在几乎行行业业都在使用 Linux 发行版，我们不能要求每一个用户都采用相同的平台或者相同的技术路线。那样不太现实。这就给大家留出了足够的空间去开发多样性的内容，在宏观上也能促进整个 Linux 大生态的发展。</p><p></p><p>王戍靖：目前国内处在操作系统开源社区快速发展阶段，竞争和合作必然存在。国内开源操作系统社区基于不同定位逐步形成社区特色，社区基础版的发行版本在满足用户需求和服务用户过程中，也会进一步发展出社区的技术优势。通过社区之间的相互借鉴、交流合作，可以共同推动国内操作系统技术和产业进步。</p><p></p><p>王兴宇：经过多年的努力，这些问题确实能得到完善，能看到以当前为主的操作系统已经很完善了，目前已经覆盖很多的行业，逐渐摆脱了对国际的依赖，我们现在在服务器上有相当多的进步，距离国际舞台还是有一段的距离。像前面提到的，我们在一些基础性的尖端性的重要的地方还是有一些欠缺，还需要国内各大操作系统厂商和社区形成合力，更多的厂商加入到发展行业中，共同上演中国操作系统技术逆袭世界的创举。</p>",
    "publish_time": "2022-08-30 14:14:26",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Rust 治好了我的精神内耗",
    "url": "https://www.infoq.cn/article/fv9V1223JwRI9I2ULfl1",
    "summary": "<p></p><p>九年来，我一直用<a href=\"https://jaspervdj.be/hakyll/\">Hakyll</a>\"作为静态站点的生成工具。再往前追溯，我主要用的是Jekyll，动态页面大概是用Perl加Mojolicious和PHP加Kohana来实现。但我对这些只有模糊的印象，当时还没有git，所以很多开发痕迹都找不到了。</p><p></p><p>如今，我终于下定决心，打算转向自己用<a href=\"https://www.infoq.cn/article/o2QRFPElEpOgvLPe5qzI\">Rust</a>\"亲手编写的自定义站点生成器。通过此番重写，我主要是想解决以下三个问题：</p><p></p><p>第一，越来越慢的速度。在我的低配笔记本电脑上，完整站点的重建大概要75秒（不涉及编译，单纯只是站点生成）。我这博客上一共只有240篇帖子，所以应该不至于这么慢才对。虽然已经配备了不错的缓存系统，并且只在编辑期间对帖子变更执行更新的watch命令，但整个执行速度还是太慢了。</p><p></p><p>第二，外部依赖项。虽然站点生成器本身是用Haskell编写的，但除了众多Haskell库之外，其中还包含其他依赖项。我的博客助手脚本是用Perl编写的，我使用sassc进行sass转换，还使用Python的pygments实现语法高亮，并使用s3cmd将生成的站点上传至S3。管理和更新这么多依赖项真的很烦人，我想摆脱麻烦，专心回归到博客内容上来。</p><p></p><p>第三，设置问题。跟大量依赖项相关，我的博客网站有时候会宕机，必须得花时间调试和修复。有时候我脑子里刚有点灵感，系统就崩溃了，必须赶紧把网站生成器换掉。</p><p></p><p>有些朋友可能会问，这么简单的网站还有什么可崩溃的？主要还是更新的锅，往往会以意想不到的方式引发问题。例如：</p><p></p><p>在更新GHC之后，它无法找到cabal包。在运行Haskell二进制文件时，系统提示：</p><p></p><p></p><blockquote>[ERROR] Prelude.read: no parse（只出现在台式机上，在我的低配笔记本上倒是运行良好。）</blockquote><p></p><p></p><p>或者是以下Perl错误：</p><p></p><p></p><blockquote>Magic.c: loadable library and perl binaries are mismatched (got handshake key 0xcd00080, needed 0xeb00080)（只出现在笔记本上，在台式机上运行良好。）</blockquote><p></p><p></p><p>当Hakyll的不同版本间发生Pandoc参数变更时，就会破坏Atom提要中的代码渲染效果。我知道这些并不是太大的问题，可我只希望轻轻松松写个博文，所以能正常运行才是头号目标。</p><p></p><h2>Haskell 引发了我的精神内耗</h2><p></p><p>其实我还挺喜欢Haskell的，特别是它纯函数的部分。另外，我也很喜欢Hakyll对站点配置使用的声明性方法。以生成静态（即独立页面）为例：</p><p></p><p><code lang=\"plain\">match \"static/*.markdown\" $ do\n    route   staticRoute\n    compile $ pandocCompiler streams\n        &gt;&gt;= loadAndApplyTemplate \"templates/static.html\" siteCtx\n        &gt;&gt;= loadAndApplyTemplate \"templates/site.html\" siteCtx\n        &gt;&gt;= deIndexUrls\n</code></p><p></p><p>就算看不懂$&nbsp;和&nbsp;&gt;&gt;=分别代表什么，仍然能看出我们是在从&nbsp;static/&nbsp;文件夹中查找文件，再把这些文件发送至pandocCompiler&nbsp;（以转换原始的markdown格式）、再发送至模板，之后取消索引urls（以避免链接以index.html结尾）。</p><p></p><p>多么简单，多么明了！</p><p></p><p>但我已经很多年没用过Haskell了，所以每当需要在网站上添加稍微复杂点的功能，都需要耗费巨大的精力。</p><p></p><p>例如，我想在帖子中添加下一篇/上一篇的链接，却难以轻松实现。最后，我不得不拿出时间重新学习了Haskell和Hakyll。即使如此，我琢磨出的解决方案也非常慢，是依靠线性搜索来查找下一篇/上一篇帖子。直到现在，我也不知道要怎么以正确的设置方式通过Hakyll实现这个功能。</p><p></p><p>相信各位大牛肯定有好办法，但对我来说这么一项小功能耗费的精神也太多了，着实受不了。</p><p></p><h2>为什么选择Rust？</h2><p></p><p></p><p>我喜欢用Rust，偏好基本足以决定这类业余项目的实现方法。Rust的性能很强，文本转换应该也正是它所擅长的任务。Cargo让人非常省心。在安装了Rust之后，就可以执行cargo build并等待运行结果。为什么要重新发明轮子？因为我想发挥主观能动性，试试自己能编写出怎样的静态站点生成器。这事应该不是特别难，我能借助它完全控制自己的博客网站，享受远超现成生成器的功能灵活性。当然，我也知道cobalt这类工具能配合任意语言对页面进行灵活的类型转换。我只是想在灵活之余，享受一下解决问题的乐趣。</p><p></p><p>关于实施的细节，因受篇幅所限，我没办法在文章中完整回顾整个构建过程。感兴趣的朋友可以点击此处（<a href=\"https://github.com/treeman/jonashietala\">https://github.com/treeman/jonashietala</a>\"）查看项目源代码。</p><p></p><h4>将“硬骨头”各个击破</h4><p></p><p></p><p>起初，我很担心没法重现自己熟悉的各种Hakyll功能，例如模板引擎、多种语言的语法高亮显示，或者自动重新生成编辑的页面并充当文件服务器的watch命令，有了它我才能边写作边在浏览器中查看帖子。</p><p></p><p>但事实证明，每块“硬骨头”都有对应的理想的工具。下面来看我使用的几个效果拔群的库：</p><p></p><p>使用tera作为模板引擎。它比Hakyll更强大，因为它能执行循环等复杂操作：</p><p></p><p><code lang=\"plain\"></code></p><div class=\"post-footer\"><code lang=\"plain\">\n  <nav class=\"tag-links\">\n      Posted in {% for tag in tags %}{% if loop.index0 &gt; 0 %}, {% endif %}<a href=\"https://www.infoq.cn/article/%7B%7B%20tag.href%20%7D%7D\">{{ tag.name }}</a>{% endfor %}.\n  </nav>\n</code></div><code lang=\"plain\">\n</code><p></p><p></p><p>使用pulldown-cmark来解析Markdown。对于Markdown的标准语法规范CommonMark，pulldown-cmark的表现真的很棒。虽然速度更快，但它的支持范围不像Pandoc那么广泛，所以我还得配合其他功能进行支持性扩展。这个问题稍后再谈。用syntect实现语法高亮，能够支持Sublime Text语法。用yaml-front-matter解析帖子中的元数据。用grass作为纯Rust中的Sass编译器。用axum创建负责在本地托管站点的静态文件服务器。用hotwatch监控文件变更，这样就能在文件内容变化时更新页面。用scraper解析生成的html。我的某些测试和特定转换中需要用到。用rust-s3将生成的站点上传至S3存储端。即使有了这些库，我的Rust源文件本身还是超过了6000行。必须承认，Rust代码可能有点冗长，再加上我自己的水平也不高，但这个项目的编写工作量还是比预期要多不少。（但好像软件项目都是这样……）</p><p></p><h4>Markdown转换</h4><p></p><p>虽然在帖子里只使用标准markdown能免去这一步，但多年以来我的帖子已经涉及大量pulldown-cmark无法支持的功能和扩展，所以只能亲手编码来解决。</p><p></p><h4>预处理</h4><p></p><p>我设置了一个预处理步骤，用以创建包含多个图像的图形。这是个通用的处理步骤，具体形式如下：</p><p></p><p><code lang=\"plain\">::: \n\n:::\n</code></p><p></p><p>我将它用于不同类型的图像集合，例如Flex,&nbsp;Figure&nbsp;以及&nbsp;Gallery。下面来看示例：</p><p></p><p><code lang=\"plain\">::: Flex\n/images/img1.png\n/images/img2.png\n/images/img3.png\n \nFigcaption goes here\n:::\n</code></p><p></p><p>它会被转换为：</p><p></p><p><code lang=\"plain\"></code></p><figure class=\"flex-33\"><code lang=\"plain\">\n<img src=\"https://www.infoq.cn/images/img1.png\" />\n<img src=\"https://www.infoq.cn/images/img2.png\" />\n<img src=\"https://www.infoq.cn/images/img3.png\" />\n<figcaption>Figcaption goes here</figcaption>\n</code></figure><code lang=\"plain\">\n</code><p></p><p></p><p>这是怎么实现的？当然是用正则表达式啦！</p><p></p><p><code lang=\"plain\">use lazy_static::lazy_static;\nuse regex::{Captures, Regex};\nuse std::borrow::Cow;\n \nlazy_static! {\n    static ref BLOCK: Regex = Regex::new(\n        r#\"(?xsm)\n        ^\n        # Opening :::\n        :{3}\n        \\s+\n        # Parsing id type\n        (?P\\w+)\n        \\s*\n        $\n \n        # Content inside\n        (?P.+?)\n \n        # Ending :::\n        ^:::$\n        \"#\n    )\n    .unwrap();\n}\n \npub fn parse_fenced_blocks(s: &amp;str) -&gt; Cow {\n    BLOCK.replace_all(s, |caps: &amp;Captures| -&gt; String {\n        parse_block(\n            caps.name(\"id\").unwrap().as_str(),\n            caps.name(\"content\").unwrap().as_str(),\n        )\n    })\n}\n \nfn parse_block(id: &amp;str, content: &amp;str) -&gt; String {\n    ...\n}\n</code></p><p></p><p>（图像和图形解析部分太长了，所以咱们直接跳过好了。）</p><p></p><h4>扩展pulldown-cmark</h4><p></p><p>我还用自己的转换扩展了pulldown-cmark：</p><p></p><p><code lang=\"plain\">// Issue a warning during the build process if any markdown link is broken.\nlet transformed = Parser::new_with_broken_link_callback(s, Options::all(), Some(&amp;mut cb));\n// Demote headers (eg h1 -&gt; h2), give them an \"id\" and an \"a\" tag.\nlet transformed = TransformHeaders::new(transformed);\n// Convert standalone images to figures.\nlet transformed = AutoFigures::new(transformed);\n// Embed raw youtube links using iframes.\nlet transformed = EmbedYoutube::new(transformed);\n// Syntax highlighting.\nlet transformed = CodeBlockSyntaxHighlight::new(transformed);\nlet transformed = InlineCodeSyntaxHighlight::new(transformed);\n// Parse `{ :attr }` attributes for blockquotes, to generate asides for instance.\nlet transformed = QuoteAttrs::new(transformed);\n// parse `{ .class }` attributes for tables, to allow styling for tables.\nlet transformed = TableAttrs::new(transformed);\n</code></p><p></p><p>我以前也做过标题降级和嵌入裸YouTube链接之类的尝试，实现起来相当简单。不过现在想想，在预处理或后处理步骤中嵌入YouTube链接可能会更好。</p><p></p><p>Pandoc能够支持向任意元素添加属性和类，这可太实用了。所以下面这部分：</p><p></p><p><code lang=\"plain\">![](/images/img1.png){ height=100 }\n</code></p><p></p><p>可以转换成这个样子：</p><p></p><p><code lang=\"plain\"></code></p><figure><code lang=\"plain\">\n  <img height=\"100\" src=\"https://www.infoq.cn/images/img1.png\" />\n</code></figure><code lang=\"plain\">\n</code><p></p><p></p><p>这项功能随处都有用到，所以我决定在Rust中重新实现，只是这次要用一种不那么笼统和老套的方式。</p><p></p><p>我在Pandoc中用到的另一项冲突功能，就是评估html标签内的markdown。现在的呈现效果有问题：</p><p></p><p><code lang=\"plain\"></code></p><aside><code lang=\"plain\">\nMy [link][link_ref]\n</code></aside><code lang=\"plain\">\n</code><p></p><p></p><p>我起初是打算在通用预处理步骤中实现这项功能的，但后来我总会忘记引用链接。因此在以下示例中：</p><p></p><p><code lang=\"plain\">::: Aside\nMy [link][link_ref]\n:::\n \n[link_ref]: /some/path\n</code></p><p></p><p>link&nbsp;就不再被转化为链接了，所有解析都只在:::内完成。</p><p></p><p><code lang=\"plain\">&gt; Some text\n{ :notice }\n</code></p><p></p><p>这样会调用一个通知解析器，它会在以上示例中创建一个&nbsp;</p><aside>标签（而非&nbsp;<blockquote>&nbsp;标签），同时保留已解析的markdown。<p></p><p></p><p>虽然现有crate会使用syntect添加代码高亮，但我还是自己编写了一个功能，把它打包在<code>标签中以支持内联代码高亮。例如，“Inside row:&nbsp;let&nbsp;x&nbsp;=&nbsp;2;”会显示为：</code></p><p></p><p><code><code lang=\"plain\">Inside row: `let x = 2;`rust\n</code></code></p><p></p><h4><code>性能提升</code></h4><p></p><p></p><p><code>我没花太多时间来优化性能，但还是发现了两个性能要点。</code></p><p></p><p><code>首先，如果使用syntect并包含自定义语法，那就应该把SyntaxSet压缩为二进制格式。</code></p><p></p><p><code>另一点就是使用rayon实现并行化渲染。所谓渲染，就是指markdown解析、应用模板和创建输出文件的过程。Rayon的强大之处，在于它在执行这项任务时的效率只受限于CPU性能，而且易用性非常好（只要代码结构正确）。下面是渲染的简化示例：</code></p><p></p><p><code><code lang=\"plain\">fn render(&amp;self) -&gt; Result&lt;()&gt; {\n    let mut items = Vec::new();\n \n    // Add posts, archives, and all other files that should be generated here.\n    for post in &amp;self.content.posts {\n        items.push(post.as_ref());\n    }\n \n    // Render all items.\n    items\n        .iter()\n        .try_for_each(|item| self.render_item(*item))\n}\n</code></code></p><p></p><p><code>要实现并行化，我们只需要将iter()&nbsp;更改为&nbsp;par_iter()：</code></p><p></p><p><code><code lang=\"plain\">use rayon::iter::{IntoParallelRefIterator, ParallelIterator};\n \nitems\n    .par_iter() // This line\n    .try_for_each(|item| self.render_item(*item))\n</code></code></p><p></p><p><code>这就成了，非常简单！</code></p><p></p><p><code>我也承认，这里的性能提升非常有限，真正的性能改善主要还是来自我使用的库。例如，我的旧站点使用由Python编写的外部pygments进程来实现语法高亮，而现在的替代方案是Rust编写的高亮器。后者不仅速度快得多，而且并行化难度也更低。</code></p><p></p><h4><code>健全性检查</code></h4><p></p><p><code>维护自己的网站，我才发现原来开发项目这么容易出错。比如一不留神就链接到了不存在的页面或图像，或者没有使用[my link][todo]来定义链接引用，而且在发布前还总是忘记更新。</code></p><p></p><p><code>所以，除了测试watch命令等基本功能之外，我还解析了整个站点，并检查所有内部链接是否存在且正确（也会验证/blog/my-post#some-title中的some-title部分）。外部链接也是要检查的，但我在这里使用的是手动命令。</code></p><p></p><p><code>在文章的开头，我列出了自己之前的一些设置问题。下面咱们就看看具体解决得怎么样。在生成过程中，我也采取了比较严苛的检查标准，尽可能避免遗漏各种稀奇古怪的错误。</code></p><p></p><h2><code>效果如何？</code></h2><p></p><p><code>在文章的开头，我列出了之前设置中的一些问题。下面咱们就一起来看具体解决得怎么样。</code></p><p></p><p><code>性能方面现在，还是那台低配笔记本电脑，完整的站点重建（不包含编译时间）只需要4秒。性能一下子提升了18倍，这个成绩算是相当不错了。当然，这里面肯定还有进步空间——比如，我使用rayon处理文件IO，如果采取异步机制肯定还能再优化一些；而且我也没有使用缓存系统，所以每次构建时都得重新生成所有文件（但通过观察，我发现构建过程还挺智能的）。</code></p><p></p><p><code>请注意，我不是说Rust就一定比Haskell更快，这里比较的只是两种具体实现。相信肯定有高手能在Haskell中实现同样的速度提升。</code></p><p></p><p><code>单一依赖现在我的所有功能都在Rust中实现，不需要安装和维护任何外部脚本/工具。Cargo不添麻烦只要在系统里用上Rust，cargo build就永远服服帖帖、不添麻烦。我觉得这可能就是低调的Rust最突出的优势之一——build系统不给人找事。</code></p><p></p><p><code>大家用不着手动查找丢失的依赖项，牺牲某些子功能来实现跨平台，或者在构建系统自动拉取更新时造成破坏。往椅子里一躺，等着代码编译完成就行。</code></p><p></p><h2><code>Rust 治好了我的精神内耗</code></h2><p></p><p><code>虽然我发现在Rust当中，创建系列文章或者上一篇/下一篇链接之类的功能确实更轻松，但我并不是想说Rust就比Haskell更简单易用。我的意思是，Rust对我个人来说比Haskell更容易理解。</code></p><p></p><p><code>而其中最大的区别，很可能在于实践经验。我最近一直在用Rust，而从小十年前使用Haskell完成网站创建以来，我就几乎没跟Haskell打过什么交道。所以如果我也十年不接触Rust，那再次使用起来肯定也是痛苦万分。</code></p><p></p><p><code>总体来说，我对自己的这次尝试非常满意。这是个好玩又有益的项目，虽然工作量超出了我的预期，但也确实消除了长期困扰我的老大难问题。希望我的经历对各位有所帮助。</code></p><p></p><p><code>原文链接：</code></p><p></p><p><code><a href=\"https://www.jonashietala.se/blog/2022/08/29/rewriting_my_blog_in_rust_for_fun_and_profit/\">https://www.jonashietala.se/blog/2022/08/29/rewriting_my_blog_in_rust_for_fun_and_profit/</a>\"</code></p></blockquote></aside>",
    "publish_time": "2022-08-30 14:20:15",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "用技术支撑企业的发展，“用友 BIP 3”升级企业数智平台",
    "url": "https://www.infoq.cn/article/9ejcKHgV8iJ8wSXvCI56",
    "summary": "<p>8月27日，由用友主办的2022全球商业创新大会在广州市广交会展馆隆重召开。会上，用友BIP重磅升级，发布里程碑式新品“用友BIP 3”，标志着用友商业创新平台发展到第三个阶段。</p><p>&nbsp;</p><p>与此同时，用友网络副总裁罗小江在技术峰会上深度解读了<a href=\"https://www.infoq.cn/article/sacsOsJo6xUxlCb7l4hc\">用友iuap平台</a>\"最新特性，以及如何帮助企业实现技术与业务的深度融合、落地数智化转型。</p><p></p><h2>企业需要怎样的数智化新底座？</h2><p></p><p>&nbsp;</p><p>在新技术层出不穷的市场环境下，对企业中的IT技术团队提出了更高的要求，即能否快速地驾驭数智化技术。然而，考虑到业务的发展，技术团队往往没有过多地精力去探索新技术，所以底层的技术平台则需要承担起屏蔽技术复杂性的责任。</p><p>&nbsp;</p><p>据用友网络副总裁罗小江介绍，用友iuap通过三大平台和三大中台的开放连接能力，不断与外界产生连接，获取外部的能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a7/a70a5d2fc0928b9515ece09d9ca1b324.png\" /></p><p></p><p>其中，技术平台是企业数智化<a href=\"https://www.infoq.cn/article/Bm6sq1L4UcNIp4UZpe3D\">云原生技术</a>\"支撑，基于容器云、DevOps、服务治理，智能监控与运维等技术及体系，提供自动化工具链、一体化监控运维、中间件适配、信创技术栈等能力，支撑了业务领域创新。</p><p>&nbsp;</p><p>业务中台基于微服务、中台化架构，把通用的企业服务功能提炼封装为可复用、可扩展、可运营的中台能力，同时，环境配置数据迁移支撑了BIP客户交付快速上线。数据中台是企业数智化数据治理、加工、分析的能力总成，并构建全社会安全可信电子数据。智能中台是企业数智化大脑，通过AI平台+算法+知识图谱技术，以统一的智能交互方式和智能服务，提升BIP核心竞争力，为客户创造价值，降本增效。</p><p>&nbsp;</p><p>低代码开发平台YonBuilder时企业数智化应用构建器 ，实现ISV、IT管理、业务主管、实施、开发人员等多角色工具链应用开发。连接集成平台YonLinker是企业数智化连接集成器，建立标准集成模型，提供云端集成设计中心，共享集成资产基于统一的、能穿透多方网络的混合云网关，为客户提供安全、稳健、开箱即用的混合云集成服务。</p><p></p><h2>让技术与业务深度融合</h2><p></p><p>&nbsp;</p><p>从信息化到数智化的过程中，数智化是推动企业本体的变革，这就要求企业不能只是把数据搬到线上，更多地需要基于数据，智能化地帮助企业实现整体变革，让企业实现从传统业务到创新业务的跨越式变革。据罗小江介绍，用友iuap平台有基础数据以及外部数据，并且可以通过原子服务进行赋能，业务体系能够保障业务底层地有效拉通，再基于低代码以及组装式App 便构建了真正意义上的业务场景。站在企业视角，用友iuap平台保证了技术的中立性，让企业感受云原生的体验，并更好地进行解耦、适配。</p><p>&nbsp;</p><p>首先，帮助企业构建柔性的平台架构能力，如状态架构、多组织、特征体系等等；其次，从流程驱动到数据驱动，提供相应的数据融合能力；最后，从技术普惠的视角出发，基于低代码平台把技术能力传输到业务人员当中去，让更多人参与业务的创新。此外，当一家企业要走向产业和社会化时，它的开放连接性决定未来奔跑的速度，开放连接的能力也是在平台构建时要重点考量的因素。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/8e/8e5cd8c6a4f0e6e8194ede7baf3e3803.png\" /></p><p></p><p>在企业数智化技术峰会中，浙江明日控股集团股份有限公司CIO沈琪敏分享了明日控股与用友合作的历史，基于用友iuap平台的合作，首次在外贸及大宗贸易行业实现中台架构应用突破，打破传统基于全封闭、紧耦合的供应链管理思路的业务系统规划思路。据沈琪敏介绍，明日控股将在未来实现ERP管控平台，完善业、财、资、税、档一体化流程，探索更多与用友BIP平台的场景联动，提升供应链效率。</p><p>&nbsp;</p><p>相信在用友iuap平台的不断创新与突破下，企业将更快速地提升数智化技术的驾驭能力，实现开放共享的生态连接，赋能企业、生态、 社会，成为数智企业，实现商业创新。</p>",
    "publish_time": "2022-08-30 15:26:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]