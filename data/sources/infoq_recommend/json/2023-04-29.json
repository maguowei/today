[
  {
    "title": "软件技术栈商品化：应用优先的云服务如何改变游戏规则",
    "url": "https://www.infoq.cn/article/RcpX4N8e6DUHIaG4eNTM",
    "summary": "<p>云服务的发展影响了开发人员构建分布式应用程序的方式。在QCon伦敦大会上，<a href=\"https://www.diagrid.io/\">Diagrid</a>\"公司的产品经理<a href=\"https://qconlondon.com/speakers/bilginibryam\">Bilgin Ibryam</a>\"谈到了原生云技术（如Dapr）与以开发者为中心的云服务之间的重叠。</p><p>&nbsp;</p><p>Ibryam从如何看待从单体到微服务的转变以及接下来会发生什么开始。此外，他还讨论了基础设施将如何以云服务的形式发生演变，以及它将如何改变架构。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/98/98d464f485615d4c080125d7543e7779.png\" /></p><p></p><p>&nbsp;</p><p>在演讲中，他从基础设施和应用程序趋势的角度讨论了在云计算时代之前或云计算早期、计算优先的云和应用优先的云时代构建应用程序的不同阶段（时间线）。</p><p>&nbsp;</p><p>Ibryam先是讨论云计算早期或云计算之前的时代，也就是单体应用程序时代。在那个时代，云计算还没有成为主流，微服务还没有出现。开发人员必须使用任何可以实现业务逻辑的一切东西，如异步交互（消息传递）、打包程序和缓存。此外，Dev团队负责的应用程序层和由Ops团队管理的基础设施之间也存在区别。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e2/e21e0d3bf43b2a168f7ea7d465442e22.png\" /></p><p></p><p>&nbsp;</p><p>接下来，Ilryam讨论了早期云计算时代之后的内部架构。2010年之后，人们对应用程序开发重新产生了兴趣，随后出现了一些主要的软件开发趋势，直到今天仍然具有影响力。人们可以使用<a href=\"https://en.wikipedia.org/wiki/C4_model\">C4模型</a>\"或<a href=\"https://en.wikipedia.org/wiki/4%2B1_architectural_view_model\">4+1架构模型视图</a>\"来可视化和描述架构，这为他们提供了不同的方法来观察架构。Ibryam采用了更直接的方法，将架构分为两个层次：内部架构和外部架构。内部应用程序架构由开发人员构建，他们可以完全控制所有的东西，包括应用程序不同的层，或者如他所说的——容器镜像中的所有内容。从Ops角度来看，它就是一个黑盒。外部应用程序架构是与应用程序交互的所有内容的集合，包括消息代理、数据库，甚至是云服务。Ops让它变得可靠、可观察，等等。他讨论了一些影响单体应用程序开发的架构设计方法，例如领域驱动设计、六边形架构、洋葱架构和干净架构（Clean Architecture）。随后出现的12因素（12-Factor）应用和微服务原则让单体应用架构变成了一种反模式。</p><p>&nbsp;</p><p>在早期的云时代之后是计算优先云，在这个时代，单体应用程序开始向微服务转变。内部应用程序架构的变化和云的出现导致了应用程序及其基础设施之间的分离集成。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/45/4599469166a7215bb4d017bc3f717abd.png\" /></p><p></p><p>&nbsp;</p><p>在讨论“计算优先”时，Ilbryam详细介绍了应用程序内部架构和云提供的计算。它是应用程序和计算机之间的契约（集成绑定），无论是容器、函数还是无服务器应用程序。它发生在双方的API（操作调用，如资源需求、部署、配置和度量）之间。通常由Ops团队负责。</p><p>&nbsp;</p><p>接下来，Ilbryam再次讨论了随着云计算的出现，应用程序外部架构如何随着时间的推移而发生变化。然后再次提到了应用程序绑定的概念，只是这次说的是位于应用程序之上的云服务（由开发人员负责），而不是底层的基础设施。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/66/662995815ca8b055fa146b3fc9e6b980.png\" /></p><p></p><p>&nbsp;</p><p>面向云服务的集成绑定可以移动到另一层，比如分布式应用程序运行时（Dapr）。作为对比，Ibryam提到了Google Cloud Event Arc、AWS EventBridge和Azure Event Grid，它们都是特定于云的，而Camel是语言无关的，Dapr则是两者兼而有之。</p><p>&nbsp;</p><p>最后，Ibryam谈到了应用优先的云，网络服务正变得越来越以应用为中心，并诞生了集成云：为开发人员构建的托管服务的集合。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/46/46637c88214864283f2f523cafb73c37.png\" /></p><p></p><p>&nbsp;</p><p>应用优先的生态系统将提供与事件处理服务（如Azure Eventgrid）的异步绑定、与服务（如AWS Step Functions）的有状态绑定、与服务（如Vercel Edge Middleware）的同步绑定，以及与计算服务（如AWS ECS、Azure Container Apps和Google Cloud Run）的计算绑定。通信将采用遵循OpenAPI规范的API进行。</p><p>&nbsp;</p><p>最后，Ibryam总结他演讲的关键要点：</p><p>专注于区分业务逻辑，重用无区别的商品化功能。使用支持标准可移植性的开放计算和开放集成绑定。可移植性与应用程序无关，它是关于模式、实践、工具和人。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/03/application-first-cloud-services/\">https://www.infoq.com/news/2023/03/application-first-cloud-services/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/F9zxSTY7TPYYmEJD1waQ\">不只是黑盒测试：测试工程师如何识别和消除代码坏气味？</a>\"</p><p><a href=\"https://www.infoq.cn/article/XYlKxH5f3GjBflH31z9h\">ThoughtWorks CTO：2025 年之前，我们会看到架构的演进，但不会看到革命</a>\"</p><p><a href=\"https://www.infoq.cn/article/9ivZNYc9J4Hrs7fPKH7y\">有状态自动扩展系统的设计模式提议</a>\"</p><p></p>",
    "publish_time": "2023-04-29 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "百度 Prometheus 大规模业务监控实战",
    "url": "https://www.infoq.cn/article/JlETQhxP7ozJYjkiWNPO",
    "summary": "<p></p><blockquote>本文整理自 <a href=\"https://qcon.infoq.cn/2023/beijing\">2022 QCon北京站</a>\" 百度资深研发工程师张柳青的分享<a href=\"https://qcon.infoq.cn/2023/beijing/presentation/4525\">《Prometheus 大规模业务监控实战》</a>\"。</blockquote><p></p><p></p><p>云原生在业界的发展非常迅猛且有广泛的应用，Prometheus 作为云原生可观测中关键的技术之一，在百度集团内部，以及金融等客户中也逐步规模化应用。我本次将介绍百度云原生团队在大客户量级监控场景下所遇到的问题和解决方案。</p><p>&nbsp;</p><p></p><h2>百度监控发展史</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d1/d1f31cf8ddbaf5e8152400401dc94033.png\" /></p><p></p><p>&nbsp;</p><p>百度的监控发展历史大致分为四代。</p><p></p><h3>统一监控平台时代与开放监控平台时代</h3><p></p><p>百度最初的监控平台始于2007年百度首次成立的专门运维平台研发团队，各个业务的运维监控统一由监控平台提供能力。在统一监控平台研发完成上线后，原先由各个业务自建脚本化监控采集逐步归拢到统一建设的平台中。</p><p>在统一监控平台一段时间的发展过后，我们发现由单一的运维研发小组构建监控平台并不容易。我们需要适配各类业务的不同监控需求、接口、数据源。因此，在2012年，我们构建了一个新的监控平台以支持自定义与标准化能力。</p><p>一是用户可通过监控平台所支持各类型可配置、可自定义方式，以标准化接口的形式将数据统一接入；二是提供不同语言、框架的监控指标标准库，由各个业务自行在程序中集成，从而直接对接到监控平台之中。</p><p></p><h3>智能监控时代</h3><p></p><p>随着监控系统的不断完善，各业务接入的指标逐渐增加完善。但在这个过程中，我们定位故障的效率却没有提升。我们发现所收集的指标并不是全部都有用的，用处最大的是业务类型黄金指标，如请求量、交易量、错误率、响应时间，这些指标可以从业务的层面真正反映出程序是否正常。与之相反，资源类的指标很难反映业务真实状态，某台机器的CPU异常业务可能已经自行容灾，或者业务很早就异常了但资源类指标没有任何变化。</p><p>于是在2014年，我们提出了基于业务指标特征构建的监控系统，即智能监控系统。围绕业务监控，我们核心工作围绕两个方面开展：</p><p>智能异常监测。业务指标与传统指标不同，不能限定一个固定的告警阈值，业务在不同时间段都会有波峰波谷及各种特殊情况，因此，我们基于机器学习、同环比分析，对历史数据进行学习，预测指标趋势与异常阈值，帮助发现业务指标是否真正异常。智能故障诊断。借助业务的多维度特征，如接口信息、交易量、错误码、用户信息等维度，逐层分析和推断故障根因。</p><p></p><h3>云原生可观测时代</h3><p></p><p>业界内云原生技术在2019年已进入了较为广泛的使用，百度内部也有大量业务开始了云原生架构升级。在这一阶段，我们的监控平台面临了极大的挑战。我们要对原有监控系统进行几乎是颠覆性的改造，才能支持云原生的各类型服务发现、新数据模型、数据协议等。</p><p>但同时云原生所提出的两点也与我们之前的发展思路不谋而合：</p><p>第一是监控标准化。Prometheus 及 OpenTelemetry 定义了一系列的监控标准方案，其中包括指标、Trace、日志等等，实现了业界数据的广泛互通。这点非常重要，我们通过暴露 Prometheus 的监控接口，用 OpenTelemetry 的客户端输出 Trace、日志信息，节约了大量用于业务兼容适配的人力资源。第二则是根因故障定位的进一步探索，加深指标、Trace 等标准规范的关联分析能力。</p><p></p><h2>Prometheus 业务监控遇到的挑战</h2><p></p><p></p><h3>业务监控在 Prometheus 中的落地场景</h3><p></p><p>业务监控的重要性远超资源监控，是监控指标中的 Top 1。业务指标可落地的场景总结如下：</p><p>故障管理场景。其准确率要远高于资源指标，其多维度属性应能够支撑故障分析及根因定位需求。容量管理场景。基于业务指标如请求量及响应时间等数据，评估模块容量是否应扩缩容；联动扩缩容平台，实现服务的自动扩缩容。性能分析场景。依据业务指标中区分接口、阶段等响应时间及请求量数据对应用的性能分析优化。运营分析场景。可对流量成分进行分析，可用于AB对比实验等场景。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/69/696674995f97dd3cc4dc4cd1d4ccd1bc.png\" /></p><p></p><p>&nbsp;</p><p>在已有完善的监控系统前提下，我们仍选择使用 Prometheus 是因为其指标类型天然适合业务监控场景：</p><p>Counter 以及基于 Counter 的复合指标类型、Histogram、Summary 等，很适合表达请求量、响应时间、交易量等指标，其多维度指标模型也可适用于业务指标中众多的数据维度表达。通过 PromQL 强大的数据分析能力，结合 Grafana 等数据可视化组件，上层业务得以快速地对数据进行分析，实时动态调整分析视图。将业务指标与下层各类资源、容器监控，以及移动端上指标统一汇总分析。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e0/e07d78f94175288718556a97e990d841.png\" /></p><p></p><p></p><h3>大规模业务监控在 Prometheus 架构下的挑战</h3><p></p><p>业务监控与普通资源监控不同，这类场景主要提出了几点诉求：</p><p>高性能，其中又区分以下几点：</p><p>指标承载能力。业务的大量维度致使指标规模巨大化，客户的极端场景中甚至可能出现每秒亿级的指标量。查询分析能力。以极强的数据分析及性能才能支撑全局动态分析请求量在多个维度内的对比关系。数据存储能力。业务监控中常常需要进行历史数据对比，尤其是地图类型业务，有时是数月，有时是几年，甚至也有业务需要对五年前五一假期期间数据进行对比。</p><p>高可用。集群需尽可能自恢复单节点故障。在面对集群级别的整体故障后，应能进行人工止损及快速切换。准确性。在大部分监控场景下虽然不具备多少关注度，但在金融类型或其他关注交易量的用户中，他们对准确性有极其严苛的要求。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c0/c07e12472a11a2888881e353bf302e6b.png\" /></p><p></p><p></p><h3>Prometheus 的标准开源方案</h3><p></p><p>Prometheus 作为单机引擎，拥有集采集、存储、查询、计算、报警于一体的设计，非常适合于部署和运维。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/98/98cb3dec44fe4d363400f94523052f85.png\" /></p><p></p><p>&nbsp;</p><p>受限于单机的采集能力，Prometheus 无法采集过多端口，单机的性能也限制了本地存储量仅又单机本身的磁盘可用。此外，在高可用方面，如果单机故障，则采集失效；如果磁盘故障，则数据丢失无法恢复。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d6/d69b872d25b1225d0b4cc0bc37cdbb34.png\" /></p><p></p><p>&nbsp;</p><p>由官方提供的联邦集群方案，让上层的中央 Prometheus 在采集端进行数据汇总，采用双采双存方案，使用负载均衡器进行可用性切换，从而实现更高的可用性。该方案中的中央 Prometheus Server 仍是单机方案，因此同样会存在存储、写入、性能的瓶颈及存储量方面的挑战。高可用方案中的单个集群故障期间的数据仍是丢失且无法恢复的。</p><p>&nbsp;</p><p></p><h2>大规模 Prometheus 业务监控解决方案</h2><p></p><p>基于开源的方案无法有效解决我们所面对的问题，下面从三个角度入手，更详细地解释我们的考量方向。</p><p>&nbsp;</p><p></p><h3>高性能 Prometheus 实践</h3><p></p><p>我们要如何应对指标的采集量级？方案一是通过集群扩展，但集群资源有限度；方案二则是提升集群性能，但这种方案所带来的提升也是有上限的。</p><p>&nbsp;</p><p></p><h4>指标降维</h4><p></p><p>我们首先对用户对这些指标的使用进行了分析。业务指标巨大的量级有两部分组成，一是实例，大业务场景中模块内可能部署了上千实例，百度集团内部也有上万实例的极端情况；二是业务指标的维度，交易码、错误码、请求量、用户来源省份、运营商等各类用于分析定位的维度，其结果也有十万级别的指标量。</p><p>&nbsp;</p><p>但在实际应用中，我们发现用户并不需要如此大量的指标。物理维度的故障意味着某台机器的指标异常、某个数据中心整体故障、某个机房存在问题等等，纯业务的故障则是接口异常、交易类型异常等场景，故障很少会在物理维度与业务维度交叉的某一个维度。</p><p>&nbsp;</p><p>对此，我们的第一个解决思路是去掉叉乘维度，通过增加预计算，将原始指标转换为实例级或业务级聚合指标。通过这种方式，将原先的乘法指标量级变为加法指标量级，在应用中发送至后端的指标量减少了90%以上。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ed/ed304d3c40087daf2f3c01bd7fdf94e1.png\" /></p><p></p><p>&nbsp;</p><p>需要注意的是，针对Counter类型指标的聚合处理。由于Counter指标有重置的情况，故直接加和是没有意义的，故需要使用rate()算子将Counter转换为Gauge指标，再使用sum进行加和。</p><p>&nbsp;</p><p></p><h4>采集层聚合计算瓶颈优化</h4><p></p><p>采集层预聚合的方法，在实际的应用中，会发现 CPU、内存使用率暴涨，导致整体采集性能下降。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/43/436ed4c157910f964d4c38d597605c4f.png\" /></p><p></p><p></p><p>问题在于预聚合的实现方式。 Prometheus 实现预聚合的方式是周期性加载全量数据进行运算，会在计算周期到到达的一瞬间会致使 CPU 和内存量的激增。</p><p>&nbsp;</p><p>对此，我们通过一个 Adapter 服务以 sidecar 形式伴随 Prometheus 采集端进行预聚合处理。在 Prometheus 正常采集完成写入 wal 文件后，我们通过对该文件的读取获得最新数据。通过实现累加计数器，将周期性计算转变为流式计算，有效降低降低 CPU、内存占用。</p><p>&nbsp;</p><p>至于我们为什么选用 wal 而非 remote-write？这是因为 remote-write 需要对数据序列化和反序列化，而通过 wal 文件则可以将这部分开销导致的性能损失也抹消掉。</p><p>&nbsp;</p><p></p><h4>采集端任务负载均衡</h4><p></p><p>目前，我们已经可以让后端接收到真正有用的数据了。但就如之前所讲，单一的采集端无法承载所有指标的采集，我们需要借助集群，用基于分片的方式采集所有指标。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/79/79e725878f185b004df7b8b34f36f3a3.png\" /></p><p></p><p>&nbsp;</p><p>这一阶段难点在于分片。分片一般以探测目标数为基础，但在实际的应用中，不同的业务模块产出指标量级不同，带来采集端的负载严重不均。针对这个问题，我们利用主动的探测服务探测应用所产出的指标量，并基于该指标量动态分配每个 Prometheus 所采集的目标，实现按照指标量进行负载均衡。</p><p>&nbsp;</p><p></p><h4>流式计算</h4><p></p><p>业务指标中存在很多需要数据分析的场景，我们可能仍需要面对十万、甚至百万级别数据量的聚合计算问题。一般场景下这类性能问题可通过预计算解决，将一次性查询计算时的资源消耗拆分为多个周期进行。</p><p>&nbsp;</p><p>但 Prometheus 周期性的查询存储的预计算实现方式，在指标量级到达一定程度时仍有可能造成存储服务的宕机。</p><p>&nbsp;</p><p>针对这种情况，我们的解决方案思路与先前类似：将预先计算环节从 Prometheus 中移出。为此，我们通过 Flink 实现了流式计算引擎，读取 Prometheus 配置的所有 Recording Rule 并将其生效在 Flink 计算引擎内，真正为存储引擎减负。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e7/e72323580b9a935568c74fa098199abf.png\" /></p><p></p><p></p><p>那么要如何在 Flink 计算引擎中实现 Prometheus 的算子？如果我们仅仅还原 Prometheus 的原有实现，就没有带来任何性能方面的提升。因此，我们需要基于流式计算以及 Flink 特点对 Prometheus 的算子进行改造。</p><p>&nbsp;</p><p>所做的改造有三种：</p><p>基于 groupby 对聚合计算拆分。根据 groupby 结果维度进行并行化哈希计算，将计算分散到 Flink 集群中。若 groupby 之后无法进一步拆分的数据仍然很多，则在所有 Flink 集群中首先执行本地数据聚合计算，再将计算结果汇总，避免造成局部热点。通过实现 sum()、sum(rate()) 等累加算子，每次仅加算对应数据到计数器中，而不是缓存所有数据，将内存、计算开销分摊。</p><p>&nbsp;</p><p></p><h4>时序数据降采样</h4><p></p><p>业务数据对比往往要用到历史数据。直接执行大跨度查询必定导致存储系统宕机；此外，大量数据存储会导致不必要的高磁盘成本。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/39/39618fa4480845bf4db3a3036bcbd666.png\" /></p><p></p><p>&nbsp;</p><p>我们为此所设计的降采样方案中包含五分钟或一小时这两个降采样级别，根据用户查询的时间范围动态选择需要查询的数据。我们也可以基于不同采样级别或特定指标配置存储有效期，从而降低磁盘成本。</p><p>&nbsp;</p><p>在这套方案中我们需要让 Prometheus 的算子与降采样方案进行适配。常用 over_time 类型算子（sum_over_time、count_over_time 等）一般会用于 Gauge 指标，而降采样中实际存储的是周期内对应算子值（sum、count、avg、max、min 等），在对应算子输入时降采样会查询对应值以确保最终统计数据的精确性。至于 Counter 类型算子（Increase、rate 函数等），因为直接将 Counter 值存储毫无意义，因此我们在此需要存储 Counter 的增量值，从而在算子输入时通过增量值返回准确的数据。</p><p>&nbsp;</p><p></p><h3>高可用 Prometheus 实践</h3><p></p><p></p><h4>采集层高可用容灾</h4><p></p><p>高可用一方面在于集群内组件的高可用，能够在故障后自动恢复，从而减少人为干预。我们的 Flink、Kafka，还是实际存储、远程存储，均是分布式解决方案，单实例故障后可自动容灾，因此不需要过多地关注。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/46/467ae0071028285e061bb261a1153a1a.png\" /></p><p></p><p>&nbsp;</p><p>至于采集端，我们通过双采，以单发模式（主备模式）向后端发送数据，借用 Kubernetes 的 Lease 组件进行选主，每个 Prometheus 上的 sidecar 对实时数据的接入情况进行汇报，若无实时数据则判定该实例故障，从而进行切主。</p><p></p><h4>计算与存储高可用保障</h4><p></p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/83/83f4d1b8bcbaa350d6d1f37197a2ce9b.png\" /></p><p></p><p>&nbsp;</p><p>虽然Kafka、Flink、TSDB 都是高可用，但却并不能保证数据不会遗失。因此，在 Flink 或TSDB宕机恢复后，我们还会基于已经引入的 Kafka 实现数据重传。因为 Flink 进行计算时会周期产出数据，如果通过 Kafka 重传的数据不满一周期，那么我们将向前推移多个周期并丢弃第一周期数据，从而保证最终计算数据在多次执行后均能保持一致性。</p><p></p><h4>两地三中心高可用</h4><p></p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/37/37b6c89f997dc66485c9eb780877818a.png\" /></p><p></p><p></p><p>为保证整体集群的无故障，我们与金融行业客户一同构建了“两地三中心”方案。在同城构建两套中心，数据同时发往两套中心且其中数据完全一致，实现同城双活。单中心故障的情况下，通过切换最终仪表盘查询入口以获取最新正确数据。异地保障则配合客户业务，搭建一套实时存活灾备集群，在业务流量切换至异地灾备中心时，通过灾备中心监控服务对其监控。</p><p>&nbsp;</p><p></p><h3>Prometheus 的数据准确性保障</h3><p></p><p>通常监控的应用场景中对准确性没有过多的要求，更多还是要靠其发现故障。但在金融之类场景中，则往往对准确性有极其严苛的要求。那么 Prometheus 能做到这点吗？根据官方文档， Prometheus 不适用于需求百分百精确性的场景。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ff/fffd81364b7e87af9729fbffbc1a1950.png\" /></p><p></p><p></p><p>Prometheus 的误差主要来自两个方面。</p><p>客户端程序生成相关计数器在进程推出重启后，我们无法即使拉取到内存中未采集到的数据。对此，我们只能提高采集周期，用更频繁的指标采集来减少数据损失。其次，Prometheus 本身的算子实现也可能导致误差出现。这种算子带来的误差，是我们重点要解决的问题。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/94/949869cdb73df23b1861209d6caed14a.png\" /></p><p></p><p>&nbsp;</p><p>Prometheus 的 increase/rate 首点忽略会导致数据不准。举例来说，上图进程中的两条曲线中，我们首先在进程启动时收到五次失败请求，在第20秒时收到10次成功请求，在第20秒时收到五次失败请求，可以看出 Exporter 所吐出的数据随时间变化情况。</p><p>&nbsp;</p><p>我们期望能获得10次失败10次成功，共计20次总请求数，但 Prometheus 实际计算会得出5，这是因为每条曲线的第一个点都被忽略了。成功率的计算同理，我们期望的成功率为50%，但最终计算却是0%，因为成功曲线首次收到的10次成功请求没有被统计到。</p><p>&nbsp;</p><p>在某些场景下，这一问题会被扩大化。正常服务的运行中很少会发生错误，而错误一旦发生则必定是第一次出现，那么这次数据 Prometheus 虽然能采集到，但我们却看不到，导致故障的漏报或延迟。</p><p>&nbsp;</p><p>Prometheus 的首点忽略主要为解决在应用启动后进行监控采集，采集到 Counter 的中间值问题，此时采集到的是业务自启动开始到当前的累加值，并不只有当前周期的数据，因此 Prometheus 会对其忽略。对此，我们的解决方案针对 Prometheus 的这个策略，我们将应用 Target 采集状态记录下来，Target 第一次采集之后，所有点都可判断为是正常新增点。基于正确新增点，我们将首点减0即可得到当前点的增量。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/26/26ea8a3a2df77f9e1c28a7c5b8b40f7b.png\" /></p><p></p><p>&nbsp;</p><p>除此之外， Prometheus 中还存在许多近似计算。以 increase/rate 为例，其计算过程包含的拟合计算可能导致统计数据中实际的正整数被以小数形式输出，甚至可能损失精度。对此，我们可以将 Counter 类型数据转换为 Gauge 类型，再使用 over_time 类型算子计算以避免误差。</p><p>&nbsp;</p><p>此外，sum_over_time 实际是双向闭区间统计，对于定期从 Prometheus 采集数据并自行进行汇总计算的报表系统来说，中间叠加的部分会很多。解决方法是可以新增单向闭区间算子，业务上使用新的算子来进行计算。</p><p>&nbsp;</p><p></p><h2>总结</h2><p></p><p>在 Prometheus 的解决方案中主要介绍了三部分：</p><p>在高性能部分重点提出了数据降维、动态分片采集、流式计算、存储降采样方案在高可用方面介绍了集群的高可用，以及两地三中心的跨集群高可用方案在数据准确性方面，我们探讨了 Prometheus 算子带来的误差及可能解决方案</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0e/0e97f401e73f19145568d0b02326aacf.png\" /></p><p></p><p></p><p>这些方案不仅可以有机整合为整体，也能单独应用。希望能抛砖引玉，给大家带来一些 Prometheus 应用过程中解决问题的思路。</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/QFFPRKN7a6y3L1Q7geIh\">Cloudflare 如何大规模运行&nbsp;Prometheus</a>\"</p><p><a href=\"https://www.infoq.cn/article/oYwQ87sSzZcPq7JMH34W\">可行监控方案之&nbsp;Prometheus&nbsp;和 Sensu</a>\"</p><p><a href=\"https://www.infoq.cn/article/CkjHGXEl7ro_69FXFSpV\">Prometheus&nbsp;监控系统最佳实践与常见陷阱（英文演讲）</a>\"</p>",
    "publish_time": "2023-04-29 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Service Mesh的未来在于网络",
    "url": "https://www.infoq.cn/article/TjhrjrA2ljJE5irdBRrg",
    "summary": "<p>长期以来，服务网格（Service Mesh）一直被认为是云原生的未来，能够实现一些新的特性，比如金丝雀部署、故障转移和mTLS，同时还能支持一些“传统的”网络特性，如流量路由、可观测性、错误处理和故障排查等。</p><p></p><p>服务网格承诺将网络安全、服务发现和渐进式的交付实践（如蓝/绿和金丝雀部署）转变成开发人员的自助服务接口。但是，当我们从营销炒作转到实际实现时，会发现完全不同的情况。</p><p></p><p>在最近的<a href=\"https://www.cncf.io/blog/2022/05/17/service-meshes-are-on-the-rise-but-greater-understanding-and-experience-are-required/\">CNCF服务网格调查</a>\"中，人们反映采用它的主要障碍在于缺乏工程专业知识和经验、架构和技术的复杂性，以及缺少指导、蓝图和最佳实践。</p><p></p><p>为了辅助理解新技术，通常更容易的做法是将新模式与现有的特性和功能关联起来，以构建一个共同的词汇表和起点。在服务网络中，可以类比的就是网络。</p><p></p><p>如果将服务网格看做分布式计算中的网络层，那么我们就可以从传统网络的建立、实施和采用中学到很多经验。</p><p></p><p>以此作为跳板，我将深入介绍我们在构建<a href=\"https://isovalent.com/blog/post/cilium-service-mesh/\">Cilium服务网格</a>\"时的经验，以及服务网格嵌入到网络栈中之后会如何演进的启示。</p><p></p><p>我们将会发现，正如<a href=\"https://www.cdotrends.com/story/15316/why-service-mesh-should-fade-out-sight\">David Mooter</a>\"所言，“服务网格的未来会作为一种网络特性，而不是一类产品，并尽可能远离开发人员的视线和思维，这会是一件好事儿”。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/service-mesh-networking/en/resources/11-ebpf-servicemesh-1677099659242.jpeg\" /></p><p></p><p>图1：服务网格将会成为网络栈的另一部分</p><p></p><h2>TCP/IP从实现到进入内核空间的工作和胜利</h2><p></p><p>在深入介绍未来之前，我们先跳回过去，了解分布式网络是如何形成的。在分布式网络中，最大和最著名的例子是TCP/IP。虽然我们今天已经对此习以为常，但是情况并非总是如此的。</p><p></p><p>在它成为互联网的基石之前，<a href=\"https://en.wikipedia.org/wiki/Internet_protocol_suite\">TCP/IP</a>\"最初是作为<a href=\"https://en.wikipedia.org/wiki/DARPA\">DARPA</a>\"的一个附属项目开始的。在“协议大战（Protocol Wars，<a href=\"https://en.wikipedia.org/wiki/Protocol_Wars\">TCP/IP与OSI</a>\"）”期间，众多的工程师、公司，甚至国家都在争论使用哪种通信协议来连接计算机网络。OSI被很多组织实现了“标准化”，包括美国国防部（DoD）。但是，随着越来越多的公司开始连接网络，TCP/IP快速成为人们连接计算机和网络的新兴标准，因为它早就已经实现了（包括BSD中的开源实现），并且业已可以使用。人们优先考虑的是可用的技术，并采用今天就能实现的技术，而不是所谓的“选定”的解决方案。</p><p></p><p>这些相互竞争的用户空间（user-space）实现，最终让位于内核中的TCP/IP栈的实现。现在，如果给大多数的运维团队提供一个不包含TCP/IP的内核，那将是一件非常离谱的事情，因为TCP/IP已经被视为网络的基础组成部分，任何人都可以依赖它。因为它在数以亿计的设备上运行着，<a href=\"https://en.wikipedia.org/wiki/Linux_kernel\">Linux内核</a>\"实现已经发现并修复了在用户空间重写自己的TCP/IP时可能遇到的边缘情况。人们再一次选择了可行并且能够理解的技术。</p><p></p><p>即便是一些特殊的使用场景，如延迟或性能敏感的工作负载，实现自己的TCP/IP栈也没有了足够的动力。你可以在Cloudflare的博客中看到这种进展，他们从编写<a href=\"https://blog.cloudflare.com/kernel-bypass/\">“内核旁路（kernel bypass）”</a>\"转变成了<a href=\"https://blog.cloudflare.com/why-we-use-the-linux-kernels-tcp-stack/\">“我们为何使用Linux内核的TCP栈”</a>\"。Linux TCP栈有很多关键特性和非常好的调试能力。要想和这个丰富的生态系统进行竞争，还需要很多年时间。由于这些原因，用户空间的网络不太可能成为主流。</p><p></p><p>人们对于像网络这样的关键应用，始终希望有可靠的技术，而且在任何地方均可使用。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/service-mesh-networking/en/resources/4image-2-1677099659242.jpeg\" /></p><p></p><p>图2：TCP/IP之所以能够获胜，是因为它已经实现了</p><p></p><h2>eBPF能够强化内核网络的能力</h2><p></p><p></p><p>Cloudflare并没有停留在仅仅使用Linux TCP/IP栈上。“<a href=\"https://ebpf.io/\">eBPF</a>\"正在吞噬软件”似乎成为了新的格言。而且，他们并不是独行者。自2017年以来，进入Facebook数据中心的所有流量均要经过eBPF，而谷歌的大部分流量也是如此。实际上，<a href=\"https://ebpf.io/case-studies\">如今有大量的公司</a>\"正在生产环境中使用eBPF。如果我们说，人们想要稳定的技术，那么他们为何转向eBPF来满足其网络需求呢？</p><p></p><p>由于Linux内核在数以亿计的设备中被广泛采用，因此，进行变更，尤其是像对网络这样的核心功能进行变更，是不能掉以轻心的。一旦做出变更，供应商还需要数年的时间来测试和采用新的内核版本，才能投入面向终端用户的生产环境。但是，向 <a href=\"https://cilium.io/blog/2018/04/17/why-is-the-kernel-community-replacing-iptables/\">iptables</a>\"这样的传统网络技术并不能满足动态云原生环境的需求。</p><p></p><p>谷歌、Facebook、Cloudflare和其他公司转向eBPF，这是因为它有助于解决他们大规模网络的问题。从增加数据包的吞吐量，到DDoS缓解和持续采样（profiling），eBPF使他们能够几乎实时地将所有功能添加到内核网络中。他们现在可以同时为数十亿用户提供服务，<a href=\"https://blog.cloudflare.com/26m-rps-ddos/\">缓解每秒钟2600万次的DDoS攻击</a>\"，而无需手动设置服务器名称和iptables规则。现在，它随着<a href=\"https://cilium.io/\">Cilium</a>\"得到了广泛采用，Cilium是一个基于eBPF的容器网络接口（<a href=\"https://www.cni.dev/\">CNI</a>\"，Container Network Interface），成为了所有主流云供应商的默认CNI。</p><p></p><p>eBPF已经成为了内核网络的新标准，因为它带来了超强的能力，使网络能够动态增加新的特性，并支持扩展以满足用户的需求。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/service-mesh-networking/en/resources/2image-3-1677099659242.jpeg\" /></p><p></p><p>图3：网络转移到了内核中</p><p></p><h2>如今的服务网格</h2><p></p><p></p><p>到目前为止，我们已经阐明，人们采用某项技术是因为它解决了一个直接的需求，而不是从上到下的需求。这自然会引出一个问题，服务网格解决了什么问题？</p><p></p><p>简而言之，<a href=\"https://glossary.cncf.io/service-mesh/\">服务网格</a>\"就相当于现在分布式计算中的动态链接器。在传统的编程中，要包含另外一个模块，将会涉及到将一个库导入到IDE中，在部署时，操作系统的动态链接器在运行时会将我们的程序与这个库连接在一起。链接器还会处理库发现、安全验证和建立连接等问题。</p><p></p><p>在云原生环境中，我们如今的“库”就是一个对其他微服务的网络跳转。寻找“库”并建立安全连接就是服务网格的问题。与之类似，对于动态链接器，只有一份库的副本，对于服务网格，每个节点只有一个Envoy或eBPF程序。对开发或运维团队来说，考虑动态链接器是没有太大意义的，那么他们为何要关心复杂的服务网格呢？</p><p></p><p>服务网格已经成为了一流的基础设施，因为它们有助于在应用层解决动态分布式计算环境中长期存在的复杂问题。但是，服务网格并不应该因此就固步自封。</p><p></p><p>即便不深入研究上面调查所列出的问题，服务网格也有额外的问题，它们只能通过网络来解决。由于服务通常使用应用层（<a href=\"https://en.wikipedia.org/wiki/OSI_model#Layer_7:_Application_layer\">OSI第7层</a>\"）协议，如HTTP，可观测性数据往往被限制在该层。然而，问题的根本原因可能在另外一层，而这层通常对可观测工具是不透明的。我们赖以连接基础设施的服务网格突然看不到发生了什么。它必须做出改变。</p><p></p><h2>将服务网格嵌入到网络中</h2><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/service-mesh-networking/en/resources/3image-4-1677099659242.jpeg\" /></p><p></p><p>图4：将服务网格转移到内核中</p><p></p><p>服务网格是为了解决云原生领域的网络问题而创建的，但是正如前文所述，它也有自己的问题。我们想要的是两全其美的效果，“传统网络”为我们提供第3-4层的可观测性、上下文和控制，服务网格则处理第7层的API通信。</p><p></p><p>幸运的是，我们已经看到这两个层正在逐渐走到一起，而且随着eBPF的出现，这种趋势只会加速实现。如果将服务网格连接至网络中，那么我们就能够在所有的网络层上拥有完整的上下文和控制，并改善环境搭建、运维和问题排查。我们以Isitio和Cilium Service Mesh为例，深入了解它们是如何实现这一目标的。</p><p></p><h2>Istio</h2><p></p><p></p><p>Istio正在实现服务网格向网络方向发展。借助<a href=\"https://merbridge.io/docs/overview/\">Merbridge</a>\"和<a href=\"https://istio.io/latest/blog/2022/introducing-ambient-mesh/\">Ambient Mesh</a>\"，Istio正在努力增加更多的网络功能，并减少对sidecar实现网络功能的依赖。</p><p></p><p>Merbridge通过使用eBPF取代iptables来加速Istio的网络。“使用eBPF能够极大的简化内核对流量的处理，使服务间的通信更加高效”。Merbridge没有依赖sidecar的网络栈，而是使用eBPF将数据包从sidecar传递到pod，以及从sidecar传递到sidecar，而不需要经过它们的整个网络栈。Merbridge通过将网络从服务网格转移到内核来加速网络传输。</p><p></p><p>Istio最近还推出了<a href=\"https://istio.io/latest/blog/2022/introducing-ambient-mesh/\">Ambient Mesh</a>\"，这是一个无sidecar的服务网格，目的是减少sidecar造成的运维复杂性、资源利用率低和流量中断。Ambient Mesh将L7的处理转移到每个命名空间的“waypoint proxy”，并尽可能利用第4层处理。这会将“服务网格功能”转移到更低的网络层，只有在其他方式不可行的情况下，才会依赖服务网格。将服务网格添加到网络中减少了资源和运维的开销。</p><p></p><h2>Cilium服务网格</h2><p></p><p></p><p>在为Cilium工作时，我们也看到了将服务网格转移至网络中的趋势。Cilium的“第一个服务网格”只是与Istio的集成。Cilium实现了CNI第3-4层的网络和网络策略，而Istio处理第7层的功能。基于这些经验，我们意识到，Cilium对网络实际发生的情况能够有更多的了解，并且有更好的原语（primitive）来控制网络，因为它在内核中运行，能够看到机器上发生的所有事情。</p><p></p><p>同时，终端用户的请求也能看到Cilium增加的一些特性，而这些特性通常是关联到服务网格上的，比如多集群网格和egress网关，因为网络团队认为它们只是应用程序联网的方式而已。当整体来看的时候，我们发现Cilium已经建成了80%的“服务网格”。只不过，它们是Cilium已包含的网络的一些常规组成部分。</p><p></p><p>内核中唯一缺少的部分是更高级的第7层功能，如HTTP解析和mTLS，这些功能目前被委托到了用户空间中。然而，eBPF可以将更多的这种特性转移到内核中。Cilium的下一个发布版本将会包含mTLS，并且业界已经有多个使用eBPF的HTTP解析的实现。虽然不是所有的功能都能在eBPF中实现，Cilium将继续为第7层场景的子集提供Envoy，但是有了eBPF之后，很多服务网格的特性现在已经转移到了各种网络中。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/service-mesh-networking/en/resources/2image-5-1677099659242.jpeg\" /></p><p></p><p>图5：从第1层到第7层的eBPF服务网格</p><p></p><h2>嵌入服务网格后的网络栈将会如何发展</h2><p></p><p></p><p>随着服务网格成为网络的一部分，合并后的优势主要体现在标准化、集成和运维方面。</p><p></p><p>首先，我们可以通过将服务网格和网络结合在一起，实现标准化和跨层的传播上下文。在Kubernetes中，通过Gateway API，我们可以看到这一点正在变成现实。OCI为容器运行时提供了一个标准，并能根据需要互换容器运行时，与之类似，Gateway API提供了一个标准的方式来实现Kubernetes中的网络。标准化允许消费者为自己选择最好的实现方式，在这种情况下，将网络和服务网格结合到一个连接层将会更加容易。</p><p></p><p>其次，一旦实现标准化，一个集成的生态系统就可以开始成长起来。对于增加新的或额外的特性，生态系统是一种很好的方式，因为它们提供了一致的集成点。更重要的是，标准化会推进与传统工作负载环境的集成，特别是与网络的集成。根据我们与客户合作的经验，企业会需要企业级的网络。这意味着，除了简单的HTTP请求之外，还需要额外的协议和复杂的网络拓扑结构。能够集成到这些具有不同要求的环境中，是确保服务网格在未来的网络中还能长足发展的重要原因。</p><p></p><p>最后，没有人喜欢调试网络。为什么要将它分为两个独立的层，而且在出错时，这两个层以及它们之间的接口都需要进行调试呢？将服务网格与网络结合起来，这会使得运行、运维和调试都更加容易，因为所有的上下文和问题都在同一个地方，而不是泄露到其他抽象层中。我认为，我们可以确信地说，平台连接的管理和运维将会完全由平台和网络团队负责。在网络连接的每一层都能讲述一个完整的连接故事，这对于网络和服务网格未来的组合将会至关重要。</p><p></p><p>虽然关于组合网络和服务网格的最佳实施方案依然还在争论中，但是当它实现后，将会有许多令人兴奋的机会出现在我们面前。使用OCI将容器标准化之后，我们就可以创建新的运行时、将容器添加到注册中心以供发现，并且能够在生产环境中编排它们。今天，运行容器并没有什么特别之处，仅仅是计算的一部分而已。</p><p></p><p>我期待同样的事情也能发生在服务网格上。它是网络的另一个组成部分，使我们能够为微服务、应用程序和工作负载提供从第1层到第7层的完整连接，它只需完成自己的工作就可以。作为网络的一部分，服务网格会有一个光明的未来，尽可能远离开发人员的视线和思维，这是一件好事儿。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/service-mesh-networking/\">The Future of Service Mesh Is Networking</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/video/fi42NCGpVkJSDm2MXUbB\">Service&nbsp;Mesh&nbsp;的演化与未来|InfoQ 大咖说</a>\"</p><p><a href=\"https://www.infoq.cn/article/Q0e8wDgwRNTcmNb2PDJo\">Service&nbsp;Mesh&nbsp;发展趋势：云原生中流砥柱</a>\"</p><p><a href=\"https://www.infoq.cn/article/MVdj3mA9oY85je8Zymi6\">美团点评的 Service&nbsp;Mesh&nbsp;实践及落地难点解析</a>\"</p>",
    "publish_time": "2023-04-29 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]