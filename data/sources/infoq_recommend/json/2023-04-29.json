[
  {
    "title": "软件技术栈商品化：应用优先的云服务如何改变游戏规则",
    "url": "https://www.infoq.cn/article/RcpX4N8e6DUHIaG4eNTM",
    "summary": "<p>云服务的发展影响了开发人员构建分布式应用程序的方式。在QCon伦敦大会上，<a href=\"https://www.diagrid.io/\">Diagrid</a>\"公司的产品经理<a href=\"https://qconlondon.com/speakers/bilginibryam\">Bilgin Ibryam</a>\"谈到了原生云技术（如Dapr）与以开发者为中心的云服务之间的重叠。</p><p>&nbsp;</p><p>Ibryam从如何看待从单体到微服务的转变以及接下来会发生什么开始。此外，他还讨论了基础设施将如何以云服务的形式发生演变，以及它将如何改变架构。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/98/98d464f485615d4c080125d7543e7779.png\" /></p><p></p><p>&nbsp;</p><p>在演讲中，他从基础设施和应用程序趋势的角度讨论了在云计算时代之前或云计算早期、计算优先的云和应用优先的云时代构建应用程序的不同阶段（时间线）。</p><p>&nbsp;</p><p>Ibryam先是讨论云计算早期或云计算之前的时代，也就是单体应用程序时代。在那个时代，云计算还没有成为主流，微服务还没有出现。开发人员必须使用任何可以实现业务逻辑的一切东西，如异步交互（消息传递）、打包程序和缓存。此外，Dev团队负责的应用程序层和由Ops团队管理的基础设施之间也存在区别。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e2/e21e0d3bf43b2a168f7ea7d465442e22.png\" /></p><p></p><p>&nbsp;</p><p>接下来，Ilryam讨论了早期云计算时代之后的内部架构。2010年之后，人们对应用程序开发重新产生了兴趣，随后出现了一些主要的软件开发趋势，直到今天仍然具有影响力。人们可以使用<a href=\"https://en.wikipedia.org/wiki/C4_model\">C4模型</a>\"或<a href=\"https://en.wikipedia.org/wiki/4%2B1_architectural_view_model\">4+1架构模型视图</a>\"来可视化和描述架构，这为他们提供了不同的方法来观察架构。Ibryam采用了更直接的方法，将架构分为两个层次：内部架构和外部架构。内部应用程序架构由开发人员构建，他们可以完全控制所有的东西，包括应用程序不同的层，或者如他所说的——容器镜像中的所有内容。从Ops角度来看，它就是一个黑盒。外部应用程序架构是与应用程序交互的所有内容的集合，包括消息代理、数据库，甚至是云服务。Ops让它变得可靠、可观察，等等。他讨论了一些影响单体应用程序开发的架构设计方法，例如领域驱动设计、六边形架构、洋葱架构和干净架构（Clean Architecture）。随后出现的12因素（12-Factor）应用和微服务原则让单体应用架构变成了一种反模式。</p><p>&nbsp;</p><p>在早期的云时代之后是计算优先云，在这个时代，单体应用程序开始向微服务转变。内部应用程序架构的变化和云的出现导致了应用程序及其基础设施之间的分离集成。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/45/4599469166a7215bb4d017bc3f717abd.png\" /></p><p></p><p>&nbsp;</p><p>在讨论“计算优先”时，Ilbryam详细介绍了应用程序内部架构和云提供的计算。它是应用程序和计算机之间的契约（集成绑定），无论是容器、函数还是无服务器应用程序。它发生在双方的API（操作调用，如资源需求、部署、配置和度量）之间。通常由Ops团队负责。</p><p>&nbsp;</p><p>接下来，Ilbryam再次讨论了随着云计算的出现，应用程序外部架构如何随着时间的推移而发生变化。然后再次提到了应用程序绑定的概念，只是这次说的是位于应用程序之上的云服务（由开发人员负责），而不是底层的基础设施。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/66/662995815ca8b055fa146b3fc9e6b980.png\" /></p><p></p><p>&nbsp;</p><p>面向云服务的集成绑定可以移动到另一层，比如分布式应用程序运行时（Dapr）。作为对比，Ibryam提到了Google Cloud Event Arc、AWS EventBridge和Azure Event Grid，它们都是特定于云的，而Camel是语言无关的，Dapr则是两者兼而有之。</p><p>&nbsp;</p><p>最后，Ibryam谈到了应用优先的云，网络服务正变得越来越以应用为中心，并诞生了集成云：为开发人员构建的托管服务的集合。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/46/46637c88214864283f2f523cafb73c37.png\" /></p><p></p><p>&nbsp;</p><p>应用优先的生态系统将提供与事件处理服务（如Azure Eventgrid）的异步绑定、与服务（如AWS Step Functions）的有状态绑定、与服务（如Vercel Edge Middleware）的同步绑定，以及与计算服务（如AWS ECS、Azure Container Apps和Google Cloud Run）的计算绑定。通信将采用遵循OpenAPI规范的API进行。</p><p>&nbsp;</p><p>最后，Ibryam总结他演讲的关键要点：</p><p>专注于区分业务逻辑，重用无区别的商品化功能。使用支持标准可移植性的开放计算和开放集成绑定。可移植性与应用程序无关，它是关于模式、实践、工具和人。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/03/application-first-cloud-services/\">https://www.infoq.com/news/2023/03/application-first-cloud-services/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/F9zxSTY7TPYYmEJD1waQ\">不只是黑盒测试：测试工程师如何识别和消除代码坏气味？</a>\"</p><p><a href=\"https://www.infoq.cn/article/XYlKxH5f3GjBflH31z9h\">ThoughtWorks CTO：2025 年之前，我们会看到架构的演进，但不会看到革命</a>\"</p><p><a href=\"https://www.infoq.cn/article/9ivZNYc9J4Hrs7fPKH7y\">有状态自动扩展系统的设计模式提议</a>\"</p><p></p>",
    "publish_time": "2023-04-29 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "百度 Prometheus 大规模业务监控实战",
    "url": "https://www.infoq.cn/article/JlETQhxP7ozJYjkiWNPO",
    "summary": "<p></p><blockquote>本文整理自 <a href=\"https://qcon.infoq.cn/2023/beijing\">2022 QCon北京站</a>\" 百度资深研发工程师张柳青的分享<a href=\"https://qcon.infoq.cn/2023/beijing/presentation/4525\">《Prometheus 大规模业务监控实战》</a>\"。</blockquote><p></p><p></p><p>云原生在业界的发展非常迅猛且有广泛的应用，Prometheus 作为云原生可观测中关键的技术之一，在百度集团内部，以及金融等客户中也逐步规模化应用。我本次将介绍百度云原生团队在大客户量级监控场景下所遇到的问题和解决方案。</p><p>&nbsp;</p><p></p><h2>百度监控发展史</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d1/d1f31cf8ddbaf5e8152400401dc94033.png\" /></p><p></p><p>&nbsp;</p><p>百度的监控发展历史大致分为四代。</p><p></p><h3>统一监控平台时代与开放监控平台时代</h3><p></p><p>百度最初的监控平台始于2007年百度首次成立的专门运维平台研发团队，各个业务的运维监控统一由监控平台提供能力。在统一监控平台研发完成上线后，原先由各个业务自建脚本化监控采集逐步归拢到统一建设的平台中。</p><p>在统一监控平台一段时间的发展过后，我们发现由单一的运维研发小组构建监控平台并不容易。我们需要适配各类业务的不同监控需求、接口、数据源。因此，在2012年，我们构建了一个新的监控平台以支持自定义与标准化能力。</p><p>一是用户可通过监控平台所支持各类型可配置、可自定义方式，以标准化接口的形式将数据统一接入；二是提供不同语言、框架的监控指标标准库，由各个业务自行在程序中集成，从而直接对接到监控平台之中。</p><p></p><h3>智能监控时代</h3><p></p><p>随着监控系统的不断完善，各业务接入的指标逐渐增加完善。但在这个过程中，我们定位故障的效率却没有提升。我们发现所收集的指标并不是全部都有用的，用处最大的是业务类型黄金指标，如请求量、交易量、错误率、响应时间，这些指标可以从业务的层面真正反映出程序是否正常。与之相反，资源类的指标很难反映业务真实状态，某台机器的CPU异常业务可能已经自行容灾，或者业务很早就异常了但资源类指标没有任何变化。</p><p>于是在2014年，我们提出了基于业务指标特征构建的监控系统，即智能监控系统。围绕业务监控，我们核心工作围绕两个方面开展：</p><p>智能异常监测。业务指标与传统指标不同，不能限定一个固定的告警阈值，业务在不同时间段都会有波峰波谷及各种特殊情况，因此，我们基于机器学习、同环比分析，对历史数据进行学习，预测指标趋势与异常阈值，帮助发现业务指标是否真正异常。智能故障诊断。借助业务的多维度特征，如接口信息、交易量、错误码、用户信息等维度，逐层分析和推断故障根因。</p><p></p><h3>云原生可观测时代</h3><p></p><p>业界内云原生技术在2019年已进入了较为广泛的使用，百度内部也有大量业务开始了云原生架构升级。在这一阶段，我们的监控平台面临了极大的挑战。我们要对原有监控系统进行几乎是颠覆性的改造，才能支持云原生的各类型服务发现、新数据模型、数据协议等。</p><p>但同时云原生所提出的两点也与我们之前的发展思路不谋而合：</p><p>第一是监控标准化。Prometheus 及 OpenTelemetry 定义了一系列的监控标准方案，其中包括指标、Trace、日志等等，实现了业界数据的广泛互通。这点非常重要，我们通过暴露 Prometheus 的监控接口，用 OpenTelemetry 的客户端输出 Trace、日志信息，节约了大量用于业务兼容适配的人力资源。第二则是根因故障定位的进一步探索，加深指标、Trace 等标准规范的关联分析能力。</p><p></p><h2>Prometheus 业务监控遇到的挑战</h2><p></p><p></p><h3>业务监控在 Prometheus 中的落地场景</h3><p></p><p>业务监控的重要性远超资源监控，是监控指标中的 Top 1。业务指标可落地的场景总结如下：</p><p>故障管理场景。其准确率要远高于资源指标，其多维度属性应能够支撑故障分析及根因定位需求。容量管理场景。基于业务指标如请求量及响应时间等数据，评估模块容量是否应扩缩容；联动扩缩容平台，实现服务的自动扩缩容。性能分析场景。依据业务指标中区分接口、阶段等响应时间及请求量数据对应用的性能分析优化。运营分析场景。可对流量成分进行分析，可用于AB对比实验等场景。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/69/696674995f97dd3cc4dc4cd1d4ccd1bc.png\" /></p><p></p><p>&nbsp;</p><p>在已有完善的监控系统前提下，我们仍选择使用 Prometheus 是因为其指标类型天然适合业务监控场景：</p><p>Counter 以及基于 Counter 的复合指标类型、Histogram、Summary 等，很适合表达请求量、响应时间、交易量等指标，其多维度指标模型也可适用于业务指标中众多的数据维度表达。通过 PromQL 强大的数据分析能力，结合 Grafana 等数据可视化组件，上层业务得以快速地对数据进行分析，实时动态调整分析视图。将业务指标与下层各类资源、容器监控，以及移动端上指标统一汇总分析。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e0/e07d78f94175288718556a97e990d841.png\" /></p><p></p><p></p><h3>大规模业务监控在 Prometheus 架构下的挑战</h3><p></p><p>业务监控与普通资源监控不同，这类场景主要提出了几点诉求：</p><p>高性能，其中又区分以下几点：</p><p>指标承载能力。业务的大量维度致使指标规模巨大化，客户的极端场景中甚至可能出现每秒亿级的指标量。查询分析能力。以极强的数据分析及性能才能支撑全局动态分析请求量在多个维度内的对比关系。数据存储能力。业务监控中常常需要进行历史数据对比，尤其是地图类型业务，有时是数月，有时是几年，甚至也有业务需要对五年前五一假期期间数据进行对比。</p><p>高可用。集群需尽可能自恢复单节点故障。在面对集群级别的整体故障后，应能进行人工止损及快速切换。准确性。在大部分监控场景下虽然不具备多少关注度，但在金融类型或其他关注交易量的用户中，他们对准确性有极其严苛的要求。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c0/c07e12472a11a2888881e353bf302e6b.png\" /></p><p></p><p></p><h3>Prometheus 的标准开源方案</h3><p></p><p>Prometheus 作为单机引擎，拥有集采集、存储、查询、计算、报警于一体的设计，非常适合于部署和运维。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/98/98cb3dec44fe4d363400f94523052f85.png\" /></p><p></p><p>&nbsp;</p><p>受限于单机的采集能力，Prometheus 无法采集过多端口，单机的性能也限制了本地存储量仅又单机本身的磁盘可用。此外，在高可用方面，如果单机故障，则采集失效；如果磁盘故障，则数据丢失无法恢复。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d6/d69b872d25b1225d0b4cc0bc37cdbb34.png\" /></p><p></p><p>&nbsp;</p><p>由官方提供的联邦集群方案，让上层的中央 Prometheus 在采集端进行数据汇总，采用双采双存方案，使用负载均衡器进行可用性切换，从而实现更高的可用性。该方案中的中央 Prometheus Server 仍是单机方案，因此同样会存在存储、写入、性能的瓶颈及存储量方面的挑战。高可用方案中的单个集群故障期间的数据仍是丢失且无法恢复的。</p><p>&nbsp;</p><p></p><h2>大规模 Prometheus 业务监控解决方案</h2><p></p><p>基于开源的方案无法有效解决我们所面对的问题，下面从三个角度入手，更详细地解释我们的考量方向。</p><p>&nbsp;</p><p></p><h3>高性能 Prometheus 实践</h3><p></p><p>我们要如何应对指标的采集量级？方案一是通过集群扩展，但集群资源有限度；方案二则是提升集群性能，但这种方案所带来的提升也是有上限的。</p><p>&nbsp;</p><p></p><h4>指标降维</h4><p></p><p>我们首先对用户对这些指标的使用进行了分析。业务指标巨大的量级有两部分组成，一是实例，大业务场景中模块内可能部署了上千实例，百度集团内部也有上万实例的极端情况；二是业务指标的维度，交易码、错误码、请求量、用户来源省份、运营商等各类用于分析定位的维度，其结果也有十万级别的指标量。</p><p>&nbsp;</p><p>但在实际应用中，我们发现用户并不需要如此大量的指标。物理维度的故障意味着某台机器的指标异常、某个数据中心整体故障、某个机房存在问题等等，纯业务的故障则是接口异常、交易类型异常等场景，故障很少会在物理维度与业务维度交叉的某一个维度。</p><p>&nbsp;</p><p>对此，我们的第一个解决思路是去掉叉乘维度，通过增加预计算，将原始指标转换为实例级或业务级聚合指标。通过这种方式，将原先的乘法指标量级变为加法指标量级，在应用中发送至后端的指标量减少了90%以上。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ed/ed304d3c40087daf2f3c01bd7fdf94e1.png\" /></p><p></p><p>&nbsp;</p><p>需要注意的是，针对Counter类型指标的聚合处理。由于Counter指标有重置的情况，故直接加和是没有意义的，故需要使用rate()算子将Counter转换为Gauge指标，再使用sum进行加和。</p><p>&nbsp;</p><p></p><h4>采集层聚合计算瓶颈优化</h4><p></p><p>采集层预聚合的方法，在实际的应用中，会发现 CPU、内存使用率暴涨，导致整体采集性能下降。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/43/436ed4c157910f964d4c38d597605c4f.png\" /></p><p></p><p></p><p>问题在于预聚合的实现方式。 Prometheus 实现预聚合的方式是周期性加载全量数据进行运算，会在计算周期到到达的一瞬间会致使 CPU 和内存量的激增。</p><p>&nbsp;</p><p>对此，我们通过一个 Adapter 服务以 sidecar 形式伴随 Prometheus 采集端进行预聚合处理。在 Prometheus 正常采集完成写入 wal 文件后，我们通过对该文件的读取获得最新数据。通过实现累加计数器，将周期性计算转变为流式计算，有效降低降低 CPU、内存占用。</p><p>&nbsp;</p><p>至于我们为什么选用 wal 而非 remote-write？这是因为 remote-write 需要对数据序列化和反序列化，而通过 wal 文件则可以将这部分开销导致的性能损失也抹消掉。</p><p>&nbsp;</p><p></p><h4>采集端任务负载均衡</h4><p></p><p>目前，我们已经可以让后端接收到真正有用的数据了。但就如之前所讲，单一的采集端无法承载所有指标的采集，我们需要借助集群，用基于分片的方式采集所有指标。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/79/79e725878f185b004df7b8b34f36f3a3.png\" /></p><p></p><p>&nbsp;</p><p>这一阶段难点在于分片。分片一般以探测目标数为基础，但在实际的应用中，不同的业务模块产出指标量级不同，带来采集端的负载严重不均。针对这个问题，我们利用主动的探测服务探测应用所产出的指标量，并基于该指标量动态分配每个 Prometheus 所采集的目标，实现按照指标量进行负载均衡。</p><p>&nbsp;</p><p></p><h4>流式计算</h4><p></p><p>业务指标中存在很多需要数据分析的场景，我们可能仍需要面对十万、甚至百万级别数据量的聚合计算问题。一般场景下这类性能问题可通过预计算解决，将一次性查询计算时的资源消耗拆分为多个周期进行。</p><p>&nbsp;</p><p>但 Prometheus 周期性的查询存储的预计算实现方式，在指标量级到达一定程度时仍有可能造成存储服务的宕机。</p><p>&nbsp;</p><p>针对这种情况，我们的解决方案思路与先前类似：将预先计算环节从 Prometheus 中移出。为此，我们通过 Flink 实现了流式计算引擎，读取 Prometheus 配置的所有 Recording Rule 并将其生效在 Flink 计算引擎内，真正为存储引擎减负。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e7/e72323580b9a935568c74fa098199abf.png\" /></p><p></p><p></p><p>那么要如何在 Flink 计算引擎中实现 Prometheus 的算子？如果我们仅仅还原 Prometheus 的原有实现，就没有带来任何性能方面的提升。因此，我们需要基于流式计算以及 Flink 特点对 Prometheus 的算子进行改造。</p><p>&nbsp;</p><p>所做的改造有三种：</p><p>基于 groupby 对聚合计算拆分。根据 groupby 结果维度进行并行化哈希计算，将计算分散到 Flink 集群中。若 groupby 之后无法进一步拆分的数据仍然很多，则在所有 Flink 集群中首先执行本地数据聚合计算，再将计算结果汇总，避免造成局部热点。通过实现 sum()、sum(rate()) 等累加算子，每次仅加算对应数据到计数器中，而不是缓存所有数据，将内存、计算开销分摊。</p><p>&nbsp;</p><p></p><h4>时序数据降采样</h4><p></p><p>业务数据对比往往要用到历史数据。直接执行大跨度查询必定导致存储系统宕机；此外，大量数据存储会导致不必要的高磁盘成本。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/39/39618fa4480845bf4db3a3036bcbd666.png\" /></p><p></p><p>&nbsp;</p><p>我们为此所设计的降采样方案中包含五分钟或一小时这两个降采样级别，根据用户查询的时间范围动态选择需要查询的数据。我们也可以基于不同采样级别或特定指标配置存储有效期，从而降低磁盘成本。</p><p>&nbsp;</p><p>在这套方案中我们需要让 Prometheus 的算子与降采样方案进行适配。常用 over_time 类型算子（sum_over_time、count_over_time 等）一般会用于 Gauge 指标，而降采样中实际存储的是周期内对应算子值（sum、count、avg、max、min 等），在对应算子输入时降采样会查询对应值以确保最终统计数据的精确性。至于 Counter 类型算子（Increase、rate 函数等），因为直接将 Counter 值存储毫无意义，因此我们在此需要存储 Counter 的增量值，从而在算子输入时通过增量值返回准确的数据。</p><p>&nbsp;</p><p></p><h3>高可用 Prometheus 实践</h3><p></p><p></p><h4>采集层高可用容灾</h4><p></p><p>高可用一方面在于集群内组件的高可用，能够在故障后自动恢复，从而减少人为干预。我们的 Flink、Kafka，还是实际存储、远程存储，均是分布式解决方案，单实例故障后可自动容灾，因此不需要过多地关注。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/46/467ae0071028285e061bb261a1153a1a.png\" /></p><p></p><p>&nbsp;</p><p>至于采集端，我们通过双采，以单发模式（主备模式）向后端发送数据，借用 Kubernetes 的 Lease 组件进行选主，每个 Prometheus 上的 sidecar 对实时数据的接入情况进行汇报，若无实时数据则判定该实例故障，从而进行切主。</p><p></p><h4>计算与存储高可用保障</h4><p></p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/83/83f4d1b8bcbaa350d6d1f37197a2ce9b.png\" /></p><p></p><p>&nbsp;</p><p>虽然Kafka、Flink、TSDB 都是高可用，但却并不能保证数据不会遗失。因此，在 Flink 或TSDB宕机恢复后，我们还会基于已经引入的 Kafka 实现数据重传。因为 Flink 进行计算时会周期产出数据，如果通过 Kafka 重传的数据不满一周期，那么我们将向前推移多个周期并丢弃第一周期数据，从而保证最终计算数据在多次执行后均能保持一致性。</p><p></p><h4>两地三中心高可用</h4><p></p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/37/37b6c89f997dc66485c9eb780877818a.png\" /></p><p></p><p></p><p>为保证整体集群的无故障，我们与金融行业客户一同构建了“两地三中心”方案。在同城构建两套中心，数据同时发往两套中心且其中数据完全一致，实现同城双活。单中心故障的情况下，通过切换最终仪表盘查询入口以获取最新正确数据。异地保障则配合客户业务，搭建一套实时存活灾备集群，在业务流量切换至异地灾备中心时，通过灾备中心监控服务对其监控。</p><p>&nbsp;</p><p></p><h3>Prometheus 的数据准确性保障</h3><p></p><p>通常监控的应用场景中对准确性没有过多的要求，更多还是要靠其发现故障。但在金融之类场景中，则往往对准确性有极其严苛的要求。那么 Prometheus 能做到这点吗？根据官方文档， Prometheus 不适用于需求百分百精确性的场景。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ff/fffd81364b7e87af9729fbffbc1a1950.png\" /></p><p></p><p></p><p>Prometheus 的误差主要来自两个方面。</p><p>客户端程序生成相关计数器在进程推出重启后，我们无法即使拉取到内存中未采集到的数据。对此，我们只能提高采集周期，用更频繁的指标采集来减少数据损失。其次，Prometheus 本身的算子实现也可能导致误差出现。这种算子带来的误差，是我们重点要解决的问题。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/94/949869cdb73df23b1861209d6caed14a.png\" /></p><p></p><p>&nbsp;</p><p>Prometheus 的 increase/rate 首点忽略会导致数据不准。举例来说，上图进程中的两条曲线中，我们首先在进程启动时收到五次失败请求，在第20秒时收到10次成功请求，在第20秒时收到五次失败请求，可以看出 Exporter 所吐出的数据随时间变化情况。</p><p>&nbsp;</p><p>我们期望能获得10次失败10次成功，共计20次总请求数，但 Prometheus 实际计算会得出5，这是因为每条曲线的第一个点都被忽略了。成功率的计算同理，我们期望的成功率为50%，但最终计算却是0%，因为成功曲线首次收到的10次成功请求没有被统计到。</p><p>&nbsp;</p><p>在某些场景下，这一问题会被扩大化。正常服务的运行中很少会发生错误，而错误一旦发生则必定是第一次出现，那么这次数据 Prometheus 虽然能采集到，但我们却看不到，导致故障的漏报或延迟。</p><p>&nbsp;</p><p>Prometheus 的首点忽略主要为解决在应用启动后进行监控采集，采集到 Counter 的中间值问题，此时采集到的是业务自启动开始到当前的累加值，并不只有当前周期的数据，因此 Prometheus 会对其忽略。对此，我们的解决方案针对 Prometheus 的这个策略，我们将应用 Target 采集状态记录下来，Target 第一次采集之后，所有点都可判断为是正常新增点。基于正确新增点，我们将首点减0即可得到当前点的增量。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/26/26ea8a3a2df77f9e1c28a7c5b8b40f7b.png\" /></p><p></p><p>&nbsp;</p><p>除此之外， Prometheus 中还存在许多近似计算。以 increase/rate 为例，其计算过程包含的拟合计算可能导致统计数据中实际的正整数被以小数形式输出，甚至可能损失精度。对此，我们可以将 Counter 类型数据转换为 Gauge 类型，再使用 over_time 类型算子计算以避免误差。</p><p>&nbsp;</p><p>此外，sum_over_time 实际是双向闭区间统计，对于定期从 Prometheus 采集数据并自行进行汇总计算的报表系统来说，中间叠加的部分会很多。解决方法是可以新增单向闭区间算子，业务上使用新的算子来进行计算。</p><p>&nbsp;</p><p></p><h2>总结</h2><p></p><p>在 Prometheus 的解决方案中主要介绍了三部分：</p><p>在高性能部分重点提出了数据降维、动态分片采集、流式计算、存储降采样方案在高可用方面介绍了集群的高可用，以及两地三中心的跨集群高可用方案在数据准确性方面，我们探讨了 Prometheus 算子带来的误差及可能解决方案</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0e/0e97f401e73f19145568d0b02326aacf.png\" /></p><p></p><p></p><p>这些方案不仅可以有机整合为整体，也能单独应用。希望能抛砖引玉，给大家带来一些 Prometheus 应用过程中解决问题的思路。</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/QFFPRKN7a6y3L1Q7geIh\">Cloudflare 如何大规模运行&nbsp;Prometheus</a>\"</p><p><a href=\"https://www.infoq.cn/article/oYwQ87sSzZcPq7JMH34W\">可行监控方案之&nbsp;Prometheus&nbsp;和 Sensu</a>\"</p><p><a href=\"https://www.infoq.cn/article/CkjHGXEl7ro_69FXFSpV\">Prometheus&nbsp;监控系统最佳实践与常见陷阱（英文演讲）</a>\"</p>",
    "publish_time": "2023-04-29 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Service Mesh的未来在于网络",
    "url": "https://www.infoq.cn/article/TjhrjrA2ljJE5irdBRrg",
    "summary": "<p>长期以来，服务网格（Service Mesh）一直被认为是云原生的未来，能够实现一些新的特性，比如金丝雀部署、故障转移和mTLS，同时还能支持一些“传统的”网络特性，如流量路由、可观测性、错误处理和故障排查等。</p><p></p><p>服务网格承诺将网络安全、服务发现和渐进式的交付实践（如蓝/绿和金丝雀部署）转变成开发人员的自助服务接口。但是，当我们从营销炒作转到实际实现时，会发现完全不同的情况。</p><p></p><p>在最近的<a href=\"https://www.cncf.io/blog/2022/05/17/service-meshes-are-on-the-rise-but-greater-understanding-and-experience-are-required/\">CNCF服务网格调查</a>\"中，人们反映采用它的主要障碍在于缺乏工程专业知识和经验、架构和技术的复杂性，以及缺少指导、蓝图和最佳实践。</p><p></p><p>为了辅助理解新技术，通常更容易的做法是将新模式与现有的特性和功能关联起来，以构建一个共同的词汇表和起点。在服务网络中，可以类比的就是网络。</p><p></p><p>如果将服务网格看做分布式计算中的网络层，那么我们就可以从传统网络的建立、实施和采用中学到很多经验。</p><p></p><p>以此作为跳板，我将深入介绍我们在构建<a href=\"https://isovalent.com/blog/post/cilium-service-mesh/\">Cilium服务网格</a>\"时的经验，以及服务网格嵌入到网络栈中之后会如何演进的启示。</p><p></p><p>我们将会发现，正如<a href=\"https://www.cdotrends.com/story/15316/why-service-mesh-should-fade-out-sight\">David Mooter</a>\"所言，“服务网格的未来会作为一种网络特性，而不是一类产品，并尽可能远离开发人员的视线和思维，这会是一件好事儿”。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/service-mesh-networking/en/resources/11-ebpf-servicemesh-1677099659242.jpeg\" /></p><p></p><p>图1：服务网格将会成为网络栈的另一部分</p><p></p><h2>TCP/IP从实现到进入内核空间的工作和胜利</h2><p></p><p>在深入介绍未来之前，我们先跳回过去，了解分布式网络是如何形成的。在分布式网络中，最大和最著名的例子是TCP/IP。虽然我们今天已经对此习以为常，但是情况并非总是如此的。</p><p></p><p>在它成为互联网的基石之前，<a href=\"https://en.wikipedia.org/wiki/Internet_protocol_suite\">TCP/IP</a>\"最初是作为<a href=\"https://en.wikipedia.org/wiki/DARPA\">DARPA</a>\"的一个附属项目开始的。在“协议大战（Protocol Wars，<a href=\"https://en.wikipedia.org/wiki/Protocol_Wars\">TCP/IP与OSI</a>\"）”期间，众多的工程师、公司，甚至国家都在争论使用哪种通信协议来连接计算机网络。OSI被很多组织实现了“标准化”，包括美国国防部（DoD）。但是，随着越来越多的公司开始连接网络，TCP/IP快速成为人们连接计算机和网络的新兴标准，因为它早就已经实现了（包括BSD中的开源实现），并且业已可以使用。人们优先考虑的是可用的技术，并采用今天就能实现的技术，而不是所谓的“选定”的解决方案。</p><p></p><p>这些相互竞争的用户空间（user-space）实现，最终让位于内核中的TCP/IP栈的实现。现在，如果给大多数的运维团队提供一个不包含TCP/IP的内核，那将是一件非常离谱的事情，因为TCP/IP已经被视为网络的基础组成部分，任何人都可以依赖它。因为它在数以亿计的设备上运行着，<a href=\"https://en.wikipedia.org/wiki/Linux_kernel\">Linux内核</a>\"实现已经发现并修复了在用户空间重写自己的TCP/IP时可能遇到的边缘情况。人们再一次选择了可行并且能够理解的技术。</p><p></p><p>即便是一些特殊的使用场景，如延迟或性能敏感的工作负载，实现自己的TCP/IP栈也没有了足够的动力。你可以在Cloudflare的博客中看到这种进展，他们从编写<a href=\"https://blog.cloudflare.com/kernel-bypass/\">“内核旁路（kernel bypass）”</a>\"转变成了<a href=\"https://blog.cloudflare.com/why-we-use-the-linux-kernels-tcp-stack/\">“我们为何使用Linux内核的TCP栈”</a>\"。Linux TCP栈有很多关键特性和非常好的调试能力。要想和这个丰富的生态系统进行竞争，还需要很多年时间。由于这些原因，用户空间的网络不太可能成为主流。</p><p></p><p>人们对于像网络这样的关键应用，始终希望有可靠的技术，而且在任何地方均可使用。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/service-mesh-networking/en/resources/4image-2-1677099659242.jpeg\" /></p><p></p><p>图2：TCP/IP之所以能够获胜，是因为它已经实现了</p><p></p><h2>eBPF能够强化内核网络的能力</h2><p></p><p></p><p>Cloudflare并没有停留在仅仅使用Linux TCP/IP栈上。“<a href=\"https://ebpf.io/\">eBPF</a>\"正在吞噬软件”似乎成为了新的格言。而且，他们并不是独行者。自2017年以来，进入Facebook数据中心的所有流量均要经过eBPF，而谷歌的大部分流量也是如此。实际上，<a href=\"https://ebpf.io/case-studies\">如今有大量的公司</a>\"正在生产环境中使用eBPF。如果我们说，人们想要稳定的技术，那么他们为何转向eBPF来满足其网络需求呢？</p><p></p><p>由于Linux内核在数以亿计的设备中被广泛采用，因此，进行变更，尤其是像对网络这样的核心功能进行变更，是不能掉以轻心的。一旦做出变更，供应商还需要数年的时间来测试和采用新的内核版本，才能投入面向终端用户的生产环境。但是，向 <a href=\"https://cilium.io/blog/2018/04/17/why-is-the-kernel-community-replacing-iptables/\">iptables</a>\"这样的传统网络技术并不能满足动态云原生环境的需求。</p><p></p><p>谷歌、Facebook、Cloudflare和其他公司转向eBPF，这是因为它有助于解决他们大规模网络的问题。从增加数据包的吞吐量，到DDoS缓解和持续采样（profiling），eBPF使他们能够几乎实时地将所有功能添加到内核网络中。他们现在可以同时为数十亿用户提供服务，<a href=\"https://blog.cloudflare.com/26m-rps-ddos/\">缓解每秒钟2600万次的DDoS攻击</a>\"，而无需手动设置服务器名称和iptables规则。现在，它随着<a href=\"https://cilium.io/\">Cilium</a>\"得到了广泛采用，Cilium是一个基于eBPF的容器网络接口（<a href=\"https://www.cni.dev/\">CNI</a>\"，Container Network Interface），成为了所有主流云供应商的默认CNI。</p><p></p><p>eBPF已经成为了内核网络的新标准，因为它带来了超强的能力，使网络能够动态增加新的特性，并支持扩展以满足用户的需求。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/service-mesh-networking/en/resources/2image-3-1677099659242.jpeg\" /></p><p></p><p>图3：网络转移到了内核中</p><p></p><h2>如今的服务网格</h2><p></p><p></p><p>到目前为止，我们已经阐明，人们采用某项技术是因为它解决了一个直接的需求，而不是从上到下的需求。这自然会引出一个问题，服务网格解决了什么问题？</p><p></p><p>简而言之，<a href=\"https://glossary.cncf.io/service-mesh/\">服务网格</a>\"就相当于现在分布式计算中的动态链接器。在传统的编程中，要包含另外一个模块，将会涉及到将一个库导入到IDE中，在部署时，操作系统的动态链接器在运行时会将我们的程序与这个库连接在一起。链接器还会处理库发现、安全验证和建立连接等问题。</p><p></p><p>在云原生环境中，我们如今的“库”就是一个对其他微服务的网络跳转。寻找“库”并建立安全连接就是服务网格的问题。与之类似，对于动态链接器，只有一份库的副本，对于服务网格，每个节点只有一个Envoy或eBPF程序。对开发或运维团队来说，考虑动态链接器是没有太大意义的，那么他们为何要关心复杂的服务网格呢？</p><p></p><p>服务网格已经成为了一流的基础设施，因为它们有助于在应用层解决动态分布式计算环境中长期存在的复杂问题。但是，服务网格并不应该因此就固步自封。</p><p></p><p>即便不深入研究上面调查所列出的问题，服务网格也有额外的问题，它们只能通过网络来解决。由于服务通常使用应用层（<a href=\"https://en.wikipedia.org/wiki/OSI_model#Layer_7:_Application_layer\">OSI第7层</a>\"）协议，如HTTP，可观测性数据往往被限制在该层。然而，问题的根本原因可能在另外一层，而这层通常对可观测工具是不透明的。我们赖以连接基础设施的服务网格突然看不到发生了什么。它必须做出改变。</p><p></p><h2>将服务网格嵌入到网络中</h2><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/service-mesh-networking/en/resources/3image-4-1677099659242.jpeg\" /></p><p></p><p>图4：将服务网格转移到内核中</p><p></p><p>服务网格是为了解决云原生领域的网络问题而创建的，但是正如前文所述，它也有自己的问题。我们想要的是两全其美的效果，“传统网络”为我们提供第3-4层的可观测性、上下文和控制，服务网格则处理第7层的API通信。</p><p></p><p>幸运的是，我们已经看到这两个层正在逐渐走到一起，而且随着eBPF的出现，这种趋势只会加速实现。如果将服务网格连接至网络中，那么我们就能够在所有的网络层上拥有完整的上下文和控制，并改善环境搭建、运维和问题排查。我们以Isitio和Cilium Service Mesh为例，深入了解它们是如何实现这一目标的。</p><p></p><h2>Istio</h2><p></p><p></p><p>Istio正在实现服务网格向网络方向发展。借助<a href=\"https://merbridge.io/docs/overview/\">Merbridge</a>\"和<a href=\"https://istio.io/latest/blog/2022/introducing-ambient-mesh/\">Ambient Mesh</a>\"，Istio正在努力增加更多的网络功能，并减少对sidecar实现网络功能的依赖。</p><p></p><p>Merbridge通过使用eBPF取代iptables来加速Istio的网络。“使用eBPF能够极大的简化内核对流量的处理，使服务间的通信更加高效”。Merbridge没有依赖sidecar的网络栈，而是使用eBPF将数据包从sidecar传递到pod，以及从sidecar传递到sidecar，而不需要经过它们的整个网络栈。Merbridge通过将网络从服务网格转移到内核来加速网络传输。</p><p></p><p>Istio最近还推出了<a href=\"https://istio.io/latest/blog/2022/introducing-ambient-mesh/\">Ambient Mesh</a>\"，这是一个无sidecar的服务网格，目的是减少sidecar造成的运维复杂性、资源利用率低和流量中断。Ambient Mesh将L7的处理转移到每个命名空间的“waypoint proxy”，并尽可能利用第4层处理。这会将“服务网格功能”转移到更低的网络层，只有在其他方式不可行的情况下，才会依赖服务网格。将服务网格添加到网络中减少了资源和运维的开销。</p><p></p><h2>Cilium服务网格</h2><p></p><p></p><p>在为Cilium工作时，我们也看到了将服务网格转移至网络中的趋势。Cilium的“第一个服务网格”只是与Istio的集成。Cilium实现了CNI第3-4层的网络和网络策略，而Istio处理第7层的功能。基于这些经验，我们意识到，Cilium对网络实际发生的情况能够有更多的了解，并且有更好的原语（primitive）来控制网络，因为它在内核中运行，能够看到机器上发生的所有事情。</p><p></p><p>同时，终端用户的请求也能看到Cilium增加的一些特性，而这些特性通常是关联到服务网格上的，比如多集群网格和egress网关，因为网络团队认为它们只是应用程序联网的方式而已。当整体来看的时候，我们发现Cilium已经建成了80%的“服务网格”。只不过，它们是Cilium已包含的网络的一些常规组成部分。</p><p></p><p>内核中唯一缺少的部分是更高级的第7层功能，如HTTP解析和mTLS，这些功能目前被委托到了用户空间中。然而，eBPF可以将更多的这种特性转移到内核中。Cilium的下一个发布版本将会包含mTLS，并且业界已经有多个使用eBPF的HTTP解析的实现。虽然不是所有的功能都能在eBPF中实现，Cilium将继续为第7层场景的子集提供Envoy，但是有了eBPF之后，很多服务网格的特性现在已经转移到了各种网络中。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/service-mesh-networking/en/resources/2image-5-1677099659242.jpeg\" /></p><p></p><p>图5：从第1层到第7层的eBPF服务网格</p><p></p><h2>嵌入服务网格后的网络栈将会如何发展</h2><p></p><p></p><p>随着服务网格成为网络的一部分，合并后的优势主要体现在标准化、集成和运维方面。</p><p></p><p>首先，我们可以通过将服务网格和网络结合在一起，实现标准化和跨层的传播上下文。在Kubernetes中，通过Gateway API，我们可以看到这一点正在变成现实。OCI为容器运行时提供了一个标准，并能根据需要互换容器运行时，与之类似，Gateway API提供了一个标准的方式来实现Kubernetes中的网络。标准化允许消费者为自己选择最好的实现方式，在这种情况下，将网络和服务网格结合到一个连接层将会更加容易。</p><p></p><p>其次，一旦实现标准化，一个集成的生态系统就可以开始成长起来。对于增加新的或额外的特性，生态系统是一种很好的方式，因为它们提供了一致的集成点。更重要的是，标准化会推进与传统工作负载环境的集成，特别是与网络的集成。根据我们与客户合作的经验，企业会需要企业级的网络。这意味着，除了简单的HTTP请求之外，还需要额外的协议和复杂的网络拓扑结构。能够集成到这些具有不同要求的环境中，是确保服务网格在未来的网络中还能长足发展的重要原因。</p><p></p><p>最后，没有人喜欢调试网络。为什么要将它分为两个独立的层，而且在出错时，这两个层以及它们之间的接口都需要进行调试呢？将服务网格与网络结合起来，这会使得运行、运维和调试都更加容易，因为所有的上下文和问题都在同一个地方，而不是泄露到其他抽象层中。我认为，我们可以确信地说，平台连接的管理和运维将会完全由平台和网络团队负责。在网络连接的每一层都能讲述一个完整的连接故事，这对于网络和服务网格未来的组合将会至关重要。</p><p></p><p>虽然关于组合网络和服务网格的最佳实施方案依然还在争论中，但是当它实现后，将会有许多令人兴奋的机会出现在我们面前。使用OCI将容器标准化之后，我们就可以创建新的运行时、将容器添加到注册中心以供发现，并且能够在生产环境中编排它们。今天，运行容器并没有什么特别之处，仅仅是计算的一部分而已。</p><p></p><p>我期待同样的事情也能发生在服务网格上。它是网络的另一个组成部分，使我们能够为微服务、应用程序和工作负载提供从第1层到第7层的完整连接，它只需完成自己的工作就可以。作为网络的一部分，服务网格会有一个光明的未来，尽可能远离开发人员的视线和思维，这是一件好事儿。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/service-mesh-networking/\">The Future of Service Mesh Is Networking</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/video/fi42NCGpVkJSDm2MXUbB\">Service&nbsp;Mesh&nbsp;的演化与未来|InfoQ 大咖说</a>\"</p><p><a href=\"https://www.infoq.cn/article/Q0e8wDgwRNTcmNb2PDJo\">Service&nbsp;Mesh&nbsp;发展趋势：云原生中流砥柱</a>\"</p><p><a href=\"https://www.infoq.cn/article/MVdj3mA9oY85je8Zymi6\">美团点评的 Service&nbsp;Mesh&nbsp;实践及落地难点解析</a>\"</p>",
    "publish_time": "2023-04-29 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "被ChatGPT带火的大模型，如何实际在各行业落地？",
    "url": "https://www.infoq.cn/article/xiFWKht6NdjACd91Be6V",
    "summary": "<p></p><p>ChatGPT“军备竞赛”已渐入高潮，大型科技公司间的 AI 竞赛日趋白热化。ChatGPT 爆火也让大模型成为热门，已有多位 AI 大牛宣布杀入该领域创业。</p><p></p><p>今年2月，InfoQ 发起了极客有约特别栏目之《极客圆桌派：狂飙的 ChatGPT 》，一起探讨了 ChatGPT 到底“是什么”和“为什么”的问题。</p><p></p><p>一个月后，InfoQ 联合微软举办了《极客圆桌派：ChatGPT 点燃 AI 狂潮》直播活动，邀请了 4 位技术大咖再聊 ChatGPT，聚焦 ChatGPT 的价值核心。我们试图回答这样一些问题：</p><p></p><p>ChatGPT 到底能为企业和开发者带来什么？企业如何借力和追赶 LLM/ChatGPT 创造出实际价值？ChatGPT 所卷起的 AI 大模型热潮将如何影响开发者和企业？ChatGPT 背后的伦理挑战和风险问题又该如何应对？</p><p></p><p>以下为本次直播的精华内容，经编辑：</p><p></p><h2>嘉宾介绍</h2><p></p><p></p><blockquote>主持人Mingke：我是 Mingke，今天我将与各位嘉宾一起围坐在圆桌前，讨论 ChatGPT 和大型语言模型风暴的话题，一起探讨未来的发展方向。开始讨论之前，我们先相互介绍一下。</blockquote><p></p><p></p><p>张大卫： 我是竞智科技 GamesMind 创始人兼CEO。我之前在微软亚洲研究院，主要研究深度学习、知识图谱和推荐系统。GamesMind 致力于在游戏开发、营销、美术和剧情等方面，运用AI和AIGC技术，帮助游戏厂商创作更出色的游戏。</p><p></p><p>郝杰： 我是郝杰，现任明略科技集团的CTO。之前服务于东芝、58同城和OPPO，一直致力于语音和NLP领域的研发工作。明略科技致力于利用AI和AIGC技术，为各行各业的客户提供营销智能和营运智能方面的服务和产品。</p><p></p><h2>ChatGP：那些神话，争议与误解</h2><p></p><p></p><p></p><blockquote>主持人Mingke：在讨论之前我想了解一下，最近大家都接收到了关于ChatGP和模型的哪些奇奇怪怪的说法，周围的人和媒体会有哪些不同的声音让你觉得是误区？</blockquote><p></p><p></p><p>郝杰： 最近我们频繁接触客户，他们希望使用ChatGPT来改善自己的产品和服务质量，但同时也提出了一些担忧。他们担心在各自的垂直领域中引入这样的技术后，可能会导致出现偏激或误导性质的内容，因此需要确保ChatGPT的输出质量。 此外，他们也担心上传自己的知识到ChatGPT平台上会降低他们原有的门槛，因为目前ChatGPT还无法私有化部署。</p><p></p><p>明略作为客户和ChatGPT之间的桥梁，需要确保这座桥梁既安全可靠，又符合客户的实际需求。我们可以借鉴大模型训练的优秀算法，为客户定制出一些中小型的模型，并且确保这些模型也能展现出ChatGPT的智能特性。</p><p></p><p>我们经常与各方面的投资人讨论ChatGPT，但我并没有觉得他们对ChatGPT有太多的误解。相反，我认为他们学习和跟进的速度非常快。有些投资公司非常懂技术，他们甚至已经学习了相关论文并深入分析了ChatGPT的整体架构，对这个话题也有深入的理解和研究。</p><p></p><p>张大卫：现在的投资机构，尤其是投资前沿领域，如AI等科技行业的机构，非常注重对这些领域的了解。他们积极地查看最新的新闻和论文，对其中的细节也有一定的了解。然而，他们可能会偶尔存在一些偏差，客户方面也可能会表现出奇怪或者不同寻常的行为，这既可能是来自于客户本身，也可能是由于各种误解和想法，比如针对 ChatGPT 或者大型模型的一些担忧和恐惧，等等。</p><p></p><p>我接触到的情况中，很多人受到新闻和其他因素的影响，担心 ChatGPT、AIGC或者大型模型会取代他们的职业。甚至有些人不愿去深入了解，就对这些事情抱有抵触情绪。</p><p></p><p>比如一些内容创作者，他们依赖于自己的文案写作或者艺术创作能力，而 ChatGPT 有时可能会写出比他们更好的文案，甚至有时会体现出超越人类的能力。这类工作者目前的情况是：一是担心他们自己的工作会被取代，二是开始组织反对运动。这种情况本质上取决于人们对新事物的接受程度，以及担心实际就业问题所带来的各种观点和偏见。</p><p></p><h2>ChatGPT在AI生态系统中所处的位置</h2><p></p><p></p><p></p><blockquote>主持人Mingke：与之前比较火的元宇宙等技术不同的是，ChatGPT 的背后比较复杂，需要更长时间去理解它能够做出什么东西来。在这种模糊的背景下，我们今天来讨论企业与 ChatGPT 的关系。希望今天的讨论可以帮助我们更清晰地理解大语言模型、 ChatGPT、AIGC之间的关系，以及它们在企业中的应用。</blockquote><p></p><p></p><p>郝杰： 从生态系统的角度来看，我们现在处于一个巨大的软件和人工智能互联网生态系统中。我将这个生态系统理解为一种“圈层结构”。目前，OpenAI 和微软是处于“圆心”的两个主要角色，因为它们在这个生态系统中占据了制高点，率先推出了参数超多的千亿级别的大型模型，以及围绕这些大型模型所开发的非常优秀的产品。</p><p></p><p>就 ChatGPT 而言，Chat是一种产品，也是一种交互方式。GPT 是一种模型，一种不太显式的、不像知识库或知识图谱一样的新型知识表示方式，它是一个巨大的隐式知识库，包含了地球上的各种知识。 你可以通过 ChatGPT 平台来使用这个模型，并与它交互，使用聊天、对话或简单的问答形式展开。这种通用的交互方式可以涵盖全人类。此外，它的知识也非常通用，包括各种领域、各种行业的百科知识。</p><p></p><p>在这个生态系统中，明略科技应该处于比较靠近内层的中间层。比我们还要靠近“圆心”的是那些肩负发布大型模型使命的大公司。明略作为提供ToB服务的公司，处于生态系统的中间层，我们需要关注“圆心”，也需要关注更外围的下游。我们想利用 ChatGPT和大模型的通用性，为客户提供广泛的服务，满足多样化的任务和场景需求。</p><p></p><p>如果将企业比作一个人，那么现在AI企业都有很多顾虑，害怕被同行超越。如果竞争对手在大模型上走得更快，很容易超越自己。同时，企业也很担心下游客户可能会先行采用其他服务，导致中间层服务提供商被抛弃。</p><p></p><p>很多客户可能会认为，门槛这么低了，我们就不需要你们了，我们自己可以解决。那我们该如何应对呢？其实我们与客户保持着频繁的沟通。明略现在向客户提供的是一个灵活可调的模型即服务框架。因为目前许多公司无法应对超大模型，我们比较务实，从客户的实际情况出发，为他们定制中小型模型，并训练出他们需要的模型，享受到大模型的好的效果。</p><p></p><p>张大卫： ChatGPT的出现证明了通过数据和模型的结合，可以实现很多看似不可能完成的任务。新一代GPT-4是一个多模态模型，可以处理文本、图像等多种数据。这些都让人感到非常兴奋，因为这意味着我们有更多的机会去探索和实现更多的事情。以前有人担心AI的发展可能会受到限制，但现在看来，我们有更多的机会去发现和创造。</p><p></p><p>大模型为垂直领域带来了很多机会，但有些具体的深入问题需要结合具体领域的情况和知识来解决。 大模型的出现使得处理客户需求和知识的事情变得更加容易，并提高了客户的接受程度，从而带来了更多机会和收益，这对整个行业都有积极影响。</p><p></p><h2>iPhone时刻还是网景时刻？</h2><p></p><p></p><p></p><blockquote>主持人Mingke：由于大模型技术的多样性，它可以为许多应用程序的产生提供可能性。有人认为这是一个 iPhone 时刻，大量的应用程序将随之产生，甚至催生一些新的创业公司来基于大模型进行各种领域的应用开发。但也有人担忧，如果它是一个 iPhone 时刻，那么这是否意味着它的基础设施将来也将是中心化的，由几个主要的玩家掌控？相反，万维网框架刚刚出现，网景公司开始崛起时，HTML、HTTP、URL 等技术都已经定义好了，但它没有被任何一个公司所拥有，基础设施是开放和免费的，因此各种应用程序并不归属于某个公司，也不需要缴纳各种税。对于大语言模型来说，它将更像是一个 iPhone 时刻，还是网景时刻？</blockquote><p></p><p></p><p>郝杰：我认为当前既是 iPhone 时刻，也是网景时刻。我相信世界会朝着越来越开放的方向发展。在我和 ChatGPT 聊天时，我问它预测未来大模型的发展，是否只有一个像它这样的模型？它非常友好而谦虚地表示会有很多百花齐放的模型。</p><p></p><p>我认为我们很快就会进入网景时代。我预测大模型会发展成像 iPhone、三星、华为、小米和 OPPO 这样的少数几家非常商业化和闭源的公司，同时也会有很多开源的大模型和算法陆续开放，就像网景时代一样，这种趋势已经初现端倪。</p><p></p><p>张大卫： 我也认为目前正处于一个像 iPhone 那样划时代的时刻。然而，我认为最终情况可能不会仅仅是像微软这样的一家公司。现在无论国内还是国外都发布了各种各样的模型，例如微软自己的研究院也发布了像 Kosmos-1 模型。在图像领域也是如此，例如之前的 Mid Journey 或者 DALL· E，都表现得非常出色。因此，我认为未来的发展趋势更可能是一个类似于网景时代的全面发展。</p><p></p><h2>中国企业的大模型之路</h2><p></p><p></p><p></p><blockquote>主持人Mingke：中国特色的大模型会如何诞生？我们可以简要地探讨一下。在国内哪些大型企业比较适合建立大模型？是不是只能是几个大型企业或一些创业公司联合，才有可能建立自己的大模型？此外，多大规模的模型可以被称为大模型？</blockquote><p></p><p></p><p>郝杰： 我认为有两到三种建立大型模型的路径。第一种是依靠大型企业，如国内的BAT和华为等，因为它们拥有充足的财力并已经准备好推出这些模型。第二种是从中等规模的模型入手，这对于一些不太大的公司如明略科技等独角兽公司来说是可行的。这些公司可以从垂直领域出发，率先建立中等规模的模型，类似亿级或十亿级参数的GPT-2。第三条路径是通过突破工程难题，利用摩尔定律来降低大型模型的训练成本。 虽然这是一个挑战，但是已经有一些公司正在致力于解决这个问题，我相信随着时间的推移，训练成本会逐渐降低。</p><p></p><p>关于模型评估，我向客户介绍的是“四大一小”评估标准。通用性分为四个方面：产品交互方面通用，只要会说话，就能与其进行交互；其次，像 GPT 一样的大型模型可以看作是通用知识库。第三方面是多任务泛化能力，这是因为模型具有任务的通用性。第四个方面是大型模型的通用性。以前我们做 AI 是将模型对齐到少数算法工程师的想法、交叉熵损失函数或最大最小风险策略等上面。现在，像 ChatGPT 这样的大型模型，通过基于人类反馈的强化学习等核心技术，将其效果对齐到全人类上。因为人类可以给它评分。</p><p></p><p>张大卫： 所谓的大模型其实是一个相对的概念。我们应该关注一个模型的泛化能力，即其所能学习或实现的能力。OpenAI发现，模型参数和训练数据的规模是很重要的，训练数据越大，参数就越大，这样最终可以带来像模型“开悟”这样的境界或效果。否则，你只是在无意义地堆积参数或训练数据。</p><p></p><p>在模型对齐的过程中，1000个人来做标注已经是相当不错的水平。我们不一定非得让1000个人对所有数据进行标注。相反，我们可以使用算法进行初步筛选，并对一些有疑问的数据进行标注。我们可以随机选择一些人进行标记，如果大多数人标记结果一致，那么数据就通过了。如果标记结果不一致，我们可以再随机选择几个人进行标注。通过算法和一些策略，我们可以更有效地利用人力，而不是盲目增加人数。</p><p></p><p>不过从大型企业或责任方的角度来看，1000个人并不足够。一个典型的例子就是不同省市、不同种族或不同性别的人希望在社会中有自己的一席之地。在AI领域中，我们需要一定比例的数据来代表这些人群或者他们的声音。这是一个非常重要的方向。</p><p></p><p></p><blockquote>主持人Mingke：评价这种大型语言模型时，我们需要关注其在多个任务上的泛化能力以及是否具有中国特色。但，我们也需要考虑到这个大型语言模型是应该面向全球开发，还是应该专门为中国市场而设计？你们怎么看待这个问题？</blockquote><p></p><p></p><p>郝杰 ： 在评价大型语言模型时，除了刚才提到的四个维度，我认为还需要运用辩证法，追求参数少的模型。如果在四个维度上大家的表现都差不多，我反而更倾向于选择参数最少的模型，因为这对于明略的客户来说意味着部署成本最低，维护和迭代也更容易。在学术界中，我们称之为“参数效率”。参数效率是我们评价大型语言模型的一个重要原则。</p><p></p><p>在生态圈中，各个企业都有自己的打算。除了OpenAI、微软等大公司，其他企业可能并不太关注多样性和泛化能力这些因素，只要其主营业务上的大型或中型模型表现足够好就可以，因为他们并没有承担为全人类进行泛化任务的使命，这只是极少数企业长期致力于的事情。</p><p></p><p>张大卫： 以往，由于算法、算力和数据来源的限制，人们普遍使用英文作为研究的开端。英文数据量足够多，效果也足够好。之后，我们才会将研究拓展到其他语言。模型通过英文数据和样本高效地学习各种“常识”（比如说，微软是一家公司），然后我们可以将这些学到的知识应用到其他语言中。前沿的一些技术也可以将不同语言的数据混在一起，提高研究的效率和质量。当然，如果我们只做一些具体领域的研究，或者只涉及一种特定语言，也是可行的。</p><p></p><h2>大模型如何落地到各行业？</h2><p></p><p></p><p></p><blockquote>主持人Mingke：郝杰老师，你会选择微软还是OpenAI，在合规的情况下？</blockquote><p></p><p></p><p>郝杰： 微软拥有全球所有网页的索引，而垂直领域中的玩家有自己特色的知识沉淀，可能是一个数据库、一个标签库或一个知识图谱。明略可以帮助将私有的知识与ChatGPT进行互搏，从而使客户的数据飞轮更好地运转。</p><p></p><p>ChatGPT的价值在于其背后的两个核心深度学习算法：强化学习和利用指令进行微调，这两种算法都是有监督的。我们帮助客户训练中小型模型，**这些模型在垂直领域上的效果通常会超过ChatGPT。**我们为客户提供可扩展的模型作为服务的框架。</p><p></p><p>关于大语言模型和垂直领域模型的结合，其实有多种方法进行耦合配合。其中一种方法是利用两个核心算法进行有监督的微调，但可能需要更多的客户数据。另一种方法是将客户的知识库嵌入到大模型中，因为大模型可以处理各种不同类型的知识，只要它们被嵌入到相同的连续向量空间中。我们还可以嵌入多模态、跨领域和跨语言的知识，只要它们被约定嵌入到相同的语义空间中即可。</p><p></p><p>张大卫：以前大家曾尝试使用符号逻辑等方法，但现在逐渐采用嵌入的思路，将垂直领域的知识图谱等内容嵌入进去，这也是一个合理的思路。</p><p></p><p>在游戏这样的垂直领域中我们也有一些具体的做法。例如，在绘画时可以使用像 AIGC 这样的生成模型，基于 Prompt 来生成图像。但对于美术人员或其他专业人员来说，将他们的专业知识与该系统融合在一起是非常困难的，因为它不像对话系统或知识系统那样，可以将知识以嵌入的方式添加进去。</p><p></p><p>举个例子，在美术行业中，可能会有一些专用的语义表，其中指定了某些RGB 值代表了某种语义，例如沙滩或人。我们可以将这些专业知识通过研发能力嵌入到生成模型中，这样专业人员在使用该模型时，可以直接使用沙滩的代号配合系统进行精准生成，而不需要花费大量精力去画出它。</p><p></p><p>我们可以将一些具体领域的专业知识，例如游戏领域、美术领域或其他娱乐领域的知识，以这种方式嵌入到大型模型或现有的 AIGC 模型中。</p><p></p><p></p><blockquote>主持人Mingke：在我们的操作和实践中，是否曾遇到需要与符号进行对接的情况？比如将生成模型与符号进行对接？在企业中，高度可控性是非常重要的，高可解释性对于业务逻辑是至关重要的。过去，我们要求关键任务的准确性达到100%。但现在，即使与人类的一致性相比，高可解释性也非常重要，尤其是对于监督学习这种用概率来表达逻辑的过程而言，这种类型的问题如何处理？</blockquote><p></p><p></p><p>张大卫： 根据目前的研究趋势，这种情况比较少见，虽然也有一些结合使用的研究，但总体而言还不普遍。在当前的实践中，还没有出现这样的操作。以前基于符号逻辑的研究会更加普遍，但现在相对较少。</p><p></p><p>郝杰： 明略科技在知识图谱方面具有丰富的经验，特别是在消费类行业，如美妆、3C、汽车、大健康等领域。我们积累了比较完整、完备的知识库和知识图谱，知识图谱的知识表达形式更加高级，具有实体和连接，并且可以进行逻辑推理。图谱中的实体和关系决定了基于图谱生成的文章或图片的专业性和逻辑性。对于营销类短文的生成，明略科技离不开知识图谱，它能够保证文章的可解释性、专业性和逻辑性。在生成之后也会使用ChatGPT这样的大型模型进行润色，以满足客户的多重需求，包括风格修改和客户特殊要求等。 这种方法不仅兼顾了多个维度的需求，让客户放心使用。</p><p></p><p>在当前的生态环境下，完全依靠神经网络、深度学习解决所有问题是很困难的。例如，敏感信息的过滤并不需要大型模型来学习。由于敏感信息是动态变化的，每天都会有新的敏感词出现，因此可以将这个模块集成到搜索引擎或者客户的数据平台中。这个模块可以采用规则和词表进行处理，而不必依赖于完全连接主义的大型模型。这个问题可能是多边形的，需要因地制宜地选择解决方案。</p><p></p><p></p><blockquote>主持人Mingke：对于服务或动态业务，例如银行，可以使用大模型来实现全面的业务动态化，而不是只限于知识。假设有两种类型的机器人，一种是Web 1.0机器人，也称为聊天机器人，它主要用于回答用户问题或从知识图谱中获取信息，但不连接业务系统。另一种是Web 2.0机器人，也称为代理机器人，其目的不是回答用户问题，而是使用自然语言来操作业务系统并将业务系统返回的状态转换为自然语言后返回给用户。如果银行要将所有业务都封装成这样的机器人，一次性完成这样的任务将非常痛苦。在监督学习中，需要训练多个模型来处理不同的任务。但是，如果要处理多个业务，可能会遇到模型能力不足、分发能力不足等问题。在这种情况下，ChatGPT可以是一种可行的解决方案。如果银行开放其业务端口，ChatGPT可能是一种有效的解决方案。如果客户有这方面需求，该怎么解决？</blockquote><p></p><p></p><p>郝杰： 我们确实也有金融行业的银行客户。通常银行要求所有系统都私有化部署，这意味着系统不能离开银行大门，但是它们需要一些连接器和API管理，将现有的各个系统、数据库、CRM系统以及BI系统整合在一起。 一个特殊之处是，我们国内的许多行业都要求其大型模型、营销、销售和服务系统等都进行私有化部署，这是由于它们行业自身的特性所决定的。</p><p></p><p>这种情况很容易导致项目利润率非常低，甚至可能亏损。因此，对于这类客户，我们提供的策略是一个灵活、可扩展的模型训练服务，以帮助他们充分利用自身积累的数据，训练适合他们的模型。并不是一定要部署高成本的大型模型，因为他们也需要考虑成本问题。</p><p></p><p>还有一个例子是微软的小冰，它是一个中等规模的模型，在思维链、智慧涌现方面也不比拥有千亿参数的 ChatGPT 差。小冰的思维链已经对接了实际业务场景中的一些动作，形成了闭环。这样做基于人类反馈的强化学习的训练，可以获得更多、更有价值的样本。相较于让1000个人进行标注，这种方法更加高效。这也印证了我们一直坚持从中小模型入手，为垂直业务提供服务的理念。此外，斯坦福大学的杨迪一团队也发表了文章，经过广泛的评测，证明了在监督下进行 fine-tuning 后，中小型的模型大多数时候都可以取得比 ChatGPT 更好的效果。这进一步证实了我们的观点。</p><p></p><p>张大卫：以前在将对话机器人与具体业务进行对接时，你会发现业务接口内容非常繁琐，技术只占了一小部分，更多的是业务上的各种复杂需求。这也导致了郝杰老师所说的问题，即只有把接口告诉AI或者将相关信息提供给它，AI才能学习和自动完成任务。</p><p></p><p></p><blockquote>主持人Mingke：以静态文本的形式呈现模型，相对于专业领域模型或大型模型，或者是中等规模模型的结合，您认为哪种模型结构更具有未来性？从类似小冰或ChatGPT这样的结构来看，您认为哪一种更有前途？</blockquote><p></p><p></p><p>张大卫： 我认为，考虑到技术和商业两方面是必要的。从技术角度来看，大型模型的参数和数据越多，它们可以从趋势上学到更多的东西，因此在技术趋势方面，大型模型在本质上可能更好一些。从商业角度来看，我们需要根据具体情况来考虑。在一些垂直领域、银行等领域，他们可能拥有自己的模型，独立开发一个模型也是可行的。但是在一些实际场景中，我们倾向于使用大型模型，然后添加一些小型模型、网络层或附加层等等。这种商业模式的实现方式可能因不同场景而异。</p><p></p><p>在大型模型技术发展的今天，我们可以使用大型模型加上客户提供的小型模型来生成客户需要的资源。客户只需提供少量数据，就可以在很短的时间内得到符合自己公司风格或特色的图像、资源、甚至剧本或剧情。因此，在商业模式上，大型模型加上客户提供的小型模型是一种更可行、更可接受的方案。因此，综合考虑技术和商业两个角度，我们可以更好地回答大型模型和小型模型哪个更好的问题。</p><p></p><p>郝杰： 我认为这两条路可能最终会走向同一个方向，尽管它们现在存在差异。这是因为“大”和“小”是相对的概念。</p><p></p><p>除了将大型模型应用于传统的业务产品之外，也会出现一些基于大型模型的 native 应用产品和服务。目前，我们已经看到了像AIGC以Midjourney为代表的一类图像生成应用产品的兴起，未来还将出现一些视觉视频生成的应用产品。ChatGPT的出现也带动了许多文本生成公司的涌现，这些公司可能以前根本不存在，而现在它们的业务完全围绕着大型模型展开。这些公司的共同特点是它们能够生成内容，这可能包括生成、创意甚至心理咨询等方面的内容。与我之前提到的分析和识别业务不同，这些 native 应用程序是直接生成内容的。因此，AIGC代表了一类基于大型模型native 应用程序的应用产品。</p><p></p><h2>哪些职业可能被AI替代？</h2><p></p><p></p><blockquote>主持人Mingke：大模型涉及到了一些需要特定知识类型的工作，以及一些需要重复脑力的自动化或半自动化任务。从这个角度来看，哪些工作或工作流程中的环节容易被机器所替代？</blockquote><p></p><p></p><p>张大卫： 在游戏行业，AI对美术设计提出了巨大的挑战。目前，有些初学者或水平有限的人员的绘画水平无法与AI相比，甚至效率远低于AI。因此，对于游戏公司的主美来说，他们需要对整个美术有一个审美标准和整体风格的把控。对于其他一些基础美术，AIGC可能会部分取代人类。</p><p></p><p>在创作中有很多枯燥或重复的部分。在这个过程中，AI机器可以大大压缩创作的时间。 例如，我们可以将创意或想法、文字或简单的线稿或草图输入，AI可以快速生成数十张或数百张图像，供客户选择。客户可以选取自己喜欢的素材进行加工或修改。AI可以完成很多枯燥乏味的工作，例如主美画草稿，基础美术涂色和完善画面等。AI可以帮助人类降低探索成本。例如，在图像创作方面，AI可以一次生成多个美术素材，在剧本方面，可以一次生成多个分支。虽然AI可能无法完全代替人类，但它可以给人类提供创意和灵感，大大缩短创作时间。</p><p></p><p>郝杰：我们各行各业客户的老板们普遍有降低成本、提高效率的诉求。然而，我个人的看法是，虽然在各行各业中，有些艺术或手艺类工作的差异可能相对较大，但总体而言，在面对大型模型和通用人工智能的冲击时，行业之间的差异应该是相对平等的。</p><p></p><p>在科学领域中，大型模型原生应用的场景也包括各种科学领域，例如超导材料、生命科学、医学和生物医疗等领域，这些领域很可能是大型模型大显身手的场景。OpenAI正在做着不可思议的事情，将地球上所有的知识都装入一个模型中，虽然看似昂贵，但实际上反过来说，这是非常便宜的，对于惠及全人类来说是非常便宜的。未来，它的发展方向应该是惠及所有行业。它的目标不是让某些人失业，而是让他们更强大，让设计师、厨师和化妆师等更轻松地修炼到大师级别。</p>",
    "publish_time": "2023-04-29 16:22:01",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]