[
  {
    "title": "最高法判决引发热议：国内首例GPL侵权案背后的开源与创新之争｜讨论",
    "url": "https://www.infoq.cn/article/QbzYObG5FaaWa4JYx2Md",
    "summary": "<p>近日，最高人民法院发布了一则关于开源软件著作权纠纷案的判决，引发了业内人士的广泛关注和热议。该案中，被告公司基于 GPLv2 协议提出了不侵权抗辩，但最终被法院认定为侵权。关于本案详细报道，请移步InfoQ 报道文章“<a href=\"https://www.infoq.cn/article/PLtyHpFh4tXuJqs0yjWs\">最高人民法院：这份判决给软件开发者吃了定心丸？</a>\"”</p><p></p><p>本案的争议焦点在于，软件开发者自身存在一定程度上的违反 GPLv2 协议，是否就一定不享有新研发软件著作权呢？</p><p></p><p>支持者认为， 该判决有助于明确开源软件的法律地位，确保了开发者的劳动成果得到应有的尊重和保护。它强调了即使在开源环境下，开发者对其作品的独创性贡献仍然享有著作权，这有助于激励创新和保护知识产权。开源协议并非凌驾于法律之上的“免责条款”，开发者不能以此为借口侵犯他人著作权。此外，判决也有助于规范市场行为，防止不正当竞争，维护公平的市场秩序。</p><p></p><p>反对者则担心， 这样的判决可能会对开源社区的开放性和协作精神产生负面影响。他们认为，开源软件的核心价值在于自由分享和共同进步，如果对违反开源协议的行为过于严苛，可能会限制开发者的自由，抑制社区的活力和创新。此外，过于严格的法律约束可能会让一些潜在的开发者和企业对参与开源项目产生顾虑，从而影响开源软件的整体发展。</p><p></p><p>小编认为， 最高人民法院的判决在一定程度上确实为开源软件的著作权保护提供了指导原则，尤其是在区分软件开发者违反GPLv2协议与他人侵犯其著作权行为的独立性方面。这有助于软件开发者在遵守开源协议的同时，保护自己的合法权益。判决强调了在软件尚未被开源的情况下，软件开发者基于其独创性贡献享有的著作权不应受到不合理的限制。该判决在一定程度上平衡了软件开发者权益保护与开源社区建设之间的关系，具有积极意义。</p><p></p><p>但同时，该判决也存在一些值得探讨的地方。例如，GPLv2协议涉及的技术细节和法律解释往往非常复杂，特别是在判断软件是否构成“衍生作品”（derivative work）时，需要对软件的源代码进行深入的技术分析，而本案的案卷材料可能尚不充分。最高人民法院的判决具有重要的指导意义，但在具体案件中，如何将判决原则应用到其他类似情况，可能还需要进一步的司法实践和案例积累。</p><p></p><p>关于本案判决对开源软件著作权保护的影响，你的看法是什么呢，欢迎投票或评论分享。</p><p></p><p></p><p></p><p></p><p>欢迎加入 InfoQ 读者技术交流群，与志同道合的朋友一起探讨知识，交流经验。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/e6/36/e64f5643365f9a9fedd63326ff5de736.png\" /></p><p></p>",
    "publish_time": "2024-02-20 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Sora生成的视频太真实？那是你遇到造假了",
    "url": "https://www.infoq.cn/article/1M4s64scpG5ifvX7qfAT",
    "summary": "<p></p><p><img src=\"https://static001.infoq.cn/resource/image/2b/3c/2b9dd247c1dea290fe83f6f2996b033c.gif\" /></p><p></p><p></p><p>视频发布者“No Context Brits”表示这是 Sora 生成的，提示词是：Brit gets hit by a bus then goes for a pint。那么你认为，上面视频是真的还是 AI 生成的？</p><p></p><p></p><p></p><p>这个问题的答案，我们留到最后揭晓。</p><p></p><h3>现实真的不存在了吗？</h3><p></p><p></p><p>当大家都在说 Sora 颠覆行业的时候，Sora 究竟能颠覆多少？我们由易到难，看看 Sora 制作的视频，可以达到什么级别。</p><p></p><h4>风景</h4><p></p><p></p><p>风景类视频制作可以说是入门级，画面细节要求相对少一些，构图、运镜相对比较重要。而 Sora 确实能制作出纪录片里常用到的运镜方式，构图也是参照了构图规则的：</p><p><img src=\"https://static001.infoq.cn/resource/image/c4/fa/c4b91174f7fcd49fff4d3d898d548ffa.gif\" /></p><p></p><p></p><p></p><p>可以简单看下《地球脉动》第二季第一集的开头片段：</p><p><img src=\"https://static001.infoq.cn/resource/image/52/3f/52ea660833f22fcc53acb89e1ff3363f.gif\" /></p><p></p><p>同时，与视频生成领域的其他同行比，Sora 在真实性、连续性上的进步也是很明显的：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b9/b915114aec59b9b33722cf28523d2b13.gif\" /></p><p></p><p></p><h4>动物</h4><p></p><p></p><p>在 OpenAI Sora 研发成员 Aditya Ramesh 发出的一个关于一只蚂蚁“在蚁巢内部移动的视角镜头”的视频里，Sora 给出了如下效果：</p><p></p><p></p><p>这个视频犯了基础的认知错误：里面的蚂蚁只有四条腿，真实世界里的是六条腿。杨立昆（Yann LeCun）也直接指出了这一点，但仍止不住网友对视频效果的赞叹。</p><p></p><p>题外话：Aditya 与 LeCun 也有一段缘分。据 LeCun 爆料，Aditya 本科就读于纽约大学，并参加过其实验室的一些项目。</p><p></p><p>下面这只“飞入海底的蝴蝶”，虽然没有尊重基本事实（毕竟蝴蝶没入海底怕是飞不起来），但如果是特效，那还是可以的：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/30/30f9e5da5c031b147db08da2eaf758ff.gif\" /></p><p></p><p>一只寻找庇护所的流浪猫：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7e/7e1f77c38386a684b9fac9a58a7d6775.gif\" /></p><p></p><p>在单只动物的相对简单的场景里，Sora 表现还是不错的。</p><p></p><h4>人物</h4><p></p><p></p><p>在最新发布的 Sora 生成视频里，有一个体现人类惊讶表情的视频，但效果不太好：鲨鱼在离沙滩特别近的沙滩出现，女人夸张的惊讶……“那个女人比鲨鱼更让我害怕，制作恐怖电影可能是 Sora 的最佳用途。”网友评价。另外，这个视频的逻辑还需要提示词输入进行调整，比如男人的无动于衷。</p><p></p><p></p><p></p><p></p><p>下面这个老人过生日的视频应该很多人见过，效果相对还是相对丝滑一些的，虽然老人吹蜡烛时，烛光动也没动……</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f6/f626e0dfcdfcb287a054cf25273c626d.gif\" /></p><p></p><p>这个猫和主人互动的视频里，猫挠到主人鼻子时，鼻子的变化给人感觉像一张纸。另外，她不疼吗？！</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/37/37c73c5a1a23529e109be29afd6d5c0a.gif\" /></p><p></p><p>更复杂一些的场景，我们看看 Sora 的一镜到底：</p><p></p><p></p><p></p><p></p><p>“几乎完美。但是吹毛求疵，这里的视角不太好。看起来用餐的人坐在一个小型市场旁边。”有敏锐的网友指出：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/82/8227305e455b1c73737aa477818b6b30.png\" /></p><p></p><p>“大多数人身上都发现了人工制品和某种程度的幻觉。”复杂场景下，Sora 还是做不到完美。</p><p></p><h4>特效</h4><p></p><p></p><p>特效视频就不存在真实性问题了，视觉效果是重要的衡量因素。</p><p></p><p>Sora 研发团队 Bill Peebles 发布了一只“科技犬”视频：未来控制论德国牧羊犬的特写镜头，展示了其引人注目的棕色和黑色皮毛…</p><p></p><p></p><p></p><p>一位数字艺术方面的从业者表示，“这看起来比我们见过的任何 CGi 都更真实。迫不及待地希望能够尽快将视频制作变为 3D 模型，这样我们就可以在游戏中拥有这些资源和动画。”也有网友调侃道，“本次拍摄中没有动物受伤。”</p><p></p><p>Bill 还发布了另一个特效视频：“一座巨大的大教堂里全是猫。放眼望去，到处都是猫。一个男人走进大教堂，向坐在王座上的巨型猫王鞠躬。”在经过网友增加旁白和配音后，便是这样的：</p><p></p><p></p><p>旁白 @ChatGPTapp</p><p>配音者 @elevenlabsio</p><p>音乐由 @suno_ai_</p><p></p><p>如果有一天，OpenAI 能够直接将视觉效果和听觉效果一起输出，那又会是震惊行业的一件大事。可以看下，网友给 Sora 视频加上视觉效果是什么样的：</p><p></p><p></p><p></p><p></p><p>Sora 研发团队另一位重要成员 Tim Brooks 用 Sora 让沙盒游戏《我的世界》拥有了“有史以来最华丽的高分辨率 8k 纹理包”：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a5/a50113c3cc591d5d61279e30906d18cb.gif\" /></p><p></p><p>同时，Tim 还让《我的世界》视频融合进摩托车视角，“这个功能有如此大的创造潜力”Tim 说道。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3c/3ceb4b6f9f3445481a1817101d47b7b3.png\" /></p><p></p><p>其实效果已经不错，有网友建议可以在提示中加上“光线追踪、光晕、后期特效”等，这样效果可能会更好。</p><p></p><p>下面是一个 Sora 改变视频的风格和环境的例子，一辆跑车穿梭在水底、恐龙乐园、像素世界等等场景中：</p><p></p><p></p><p></p><p>“一只鸭子走在波士顿的街道”，如果更加复杂一些，会不会有漫威的感觉？</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e5/e5fc56900721b672725e46414c1c4cf2.gif\" /></p><p></p><p>“在叶子上行驶的火车”，叶子的脉络还真是跟清晰的，当然也有网友认为这种视频没有什么用，更多是一种数字垃圾。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/da/daf9db1bda75b14a536c74ece4a20013.gif\" /></p><p></p><p></p><h3>谢赛宁：Sora 跟我没关系</h3><p></p><p></p><p>Sora 能有上面的效果，主要得益于 DiT 架构和 Spacetime Patch。</p><p></p><p>其中，Spacetime Patch 建立在 GoogleDeepMind 对 NaViT（原生分辨率视觉 Transformer）和 ViT（视觉 Transformer）的早期研究基础上。Patch 可以理解为 Sora 的基本单元，类比 Token。Sora 处理一系列的 Patch，并预测出序列中的下一个 Patch。</p><p></p><p>Sora 团队发现补丁是一种高度可扩展且有效的表示形式，因此通过 Spacetime Patch 将视频视为补丁序列，捕捉视觉数据使模型能够从更准确的表达中学习。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/07/076c9f430f3eac29557102a07de46702.png\" /></p><p></p><p>从 OpenAI 的技术报告可知，Sora 的作者团队有 13 位成员，如今被报道最多的核心成员包括研发负责人 Tim Brooks、William Peebles、系统负责人 Connor Holmes 等。</p><p></p><p>其中，Tim Brooks 是 DALL-E 3 作者之一，GitHub 5.7k️星项目 InstructPix2Pix 作者，博士毕业于 UC Berkeley 的伯克利人工智能研究所 BAIR。Tim 曾在谷歌为 Pixel 手机摄像头提供 AI 算法，也在英伟达负责过视频生成模型的研究。</p><p></p><p>William Peebles 也来自 UC Berkeley，去年（2023 年）刚刚获得博士学位。据悉，William 和谢赛宁合作，研发了 DiT。也因为这个关系，毕业于上海交大的天才少年谢赛宁被报道为是 Sora 的研发者之一。谢赛宁本人对此强烈否认：“一点关系都没有”。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/13/13a3f99c9c6993f85cb16137b008b013.jpeg\" /></p><p></p><p>Connor Holmes 则曾在 Colorado School of Mines、微软工作过，在 LLM、BE RT 风格的编码器、RNN 和 UNets 方面有丰富经验。“我期待解决在扩展深度学习工作负载以进行推理和训练时系统效率低下的问题。”他在自己的领英上说道。此外，Sora 团队的不少成员都是 DALL-E 3 的作者，包括两位华人 Li Jing 和 Yufei Guo。</p><p></p><p></p><h3>结束语</h3><p></p><p></p><p>“如何加入红队？我可以帮助测试”有积极参与的人，也有不喜欢生成视频的人：“我看视频，不是想看虚拟的世界，而是想通过镜头去看自己不了解的真实的世界。”</p><p></p><p>现在网上也出现了很多声称是 Sora 生成的视频，但其实并不是。比如下面这个女团视频声称是Sora生成的，但真实性存疑。</p><p></p><p></p><p></p><p>来源：https://twitter.com/ViLettuce/status/1758976415150559638</p><p></p><p>还比如下面视频的发布者“víty”表示这个“女生吃面包时与他人发生争执”视频是 Sora 生成的，提示词是：𝘞𝘩𝘪𝘵𝘦 𝘸𝘰𝘮𝘢𝘯 𝘦𝘢𝘵𝘴 𝘣𝘳𝘦𝘢𝘥，𝘢𝘶𝘯𝘵 𝘣𝘪𝘵𝘤𝘩𝘴𝘭𝘢𝘱、𝘸𝘩𝘪𝘵𝘦 𝘸𝘰𝘮𝘢𝘯 𝘭𝘢𝘶𝘨𝘩𝘴、𝘱𝘪𝘢𝘯 𝘰𝘥𝘶𝘩𝘩，𝘩𝘰𝘶𝘴𝘦𝘦𝘷𝘪𝘤𝘵𝘪𝘰𝘯，𝘤𝘰𝘰𝘭𝘣𝘢𝘴𝘴𝘰𝘶𝘵 𝘳𝘰𝘮𝘶𝘴𝘪𝘤。</p><p></p><p>但有网友指出，这个视频并非 Sora 生成的，而是来源于一部名为《Ti Ti Ti》的肥皂剧。看过这部剧的朋友可以出来说说～</p><p></p><p></p><p>来源：<a href=\"https://twitter.com/vvvorvvtorvitor/status/1758654081176866906\">https://twitter.com/vvvorvvtorvitor/status/1758654081176866906</a>\"</p><p></p><p>回到文章最初问到的问题，其实帖子下面也引起了网友的各种讨论，有人说是真的，有人说是生成的。而真正的答案就是：那是真实的视频。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/46/464a491c0577c42dacd774797cf8de72.png\" /></p><p></p><p>出自外媒 The Guardian 在 2017 年的报道：</p><p></p><p><a href=\"https://www.theguardian.com/global/video/2017/jun/27/man-hit-by-bus-in-reading-survives-without-injury-video\">https://www.theguardian.com/global/video/2017/jun/27/man-hit-by-bus-in-reading-survives-without-injury-video</a>\"</p><p></p><p>你猜对了吗？</p><p></p><p>参考链接：</p><p></p><p><a href=\"https://twitter.com/minchoi/status/1758831971726225591\">https://twitter.com/minchoi/status/1758831971726225591</a>\"</p><p><a href=\"https://twitter.com/NoContextBrits/status/1759212202853040265\">https://twitter.com/NoContextBrits/status/1759212202853040265</a>\"</p><p><a href=\"https://openai.com/research/video-generation-models-as-world-simulators\">https://openai.com/research/video-generation-models-as-world-simulators</a>\"</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f9/f9e4f42a4db5c560a5e031ced2a5ac56.png\" /></p><p></p><p></p><p></p>",
    "publish_time": "2024-02-20 12:21:42",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Sora 横空出世，给科技型企业带来的 3 点启示 | Q 推荐",
    "url": "https://www.infoq.cn/article/JaYGkUL3slZtQIivxcWQ",
    "summary": "<p>开工第一周，OpenAI 发布的“文生视频”（text-to-video）的工具，Sora ， 可谓刷爆各个平台。Sora 的出现，或意味着 AGI（通用人工智能）实现将从 10 年缩短到 1 年。从 ChatGPT 到 Midjournery 再到 Sora ，每一次新技术的出现便会有相关从业者的开始焦虑。然而，面对层出不穷的 AI 技术，作为科技型企业又该如何应对呢？</p><p></p><p>培养前瞻性思维，坚持技术创新：Sora 的推出强调了持续技术创新的重要性，对科技型企业来说，这意味着需要不断探索和实验新技术，以维持在竞争激烈的市场中的领先地位。夯实技术基础，稳步实现 AI 融合：建立现实的技术应用视角，避免对热点技术抱有不切实际的高期望，而忽视了技术应用的现实挑战和局限性。持续学习和适应，打造成长型团队：Sora 展示了技术的快速进步，对科技型企业来说，这意味着需要在组织内建立持续学习和适应新技术的文化，以便快速响应行业变化和技术升级。据《麻省理工科技评论》报道，具备成长型思维的团队在面对 AI 变革时，其创新能力和业务增长速度均超过其他团队。例如，谷歌的 DeepMind 团队正是因为其成长型思维和强大的创新能力，成功研发出了 AlphaGo 等颠覆性 AI 技术，为企业带来了巨大的商业价值。</p><p></p><p>应对科技企业培养成长型团队的需求，极客时间企业版推出“领跑 2024，企业数字化人才培养福利活动”，精选了涵盖 AI 大模型应用、数字化转型实战、领导力与企业管理策略等多元维度的在线课程。这些课程不仅由行业专家亲自授课，还结合了丰富的实战案例和前沿的技术动态，确保技术团队能够学到最实用、最前沿的知识。</p><p></p><p>即日起至活动结束，参与活动的企业可以免费获得 100 个学员账号！团队成员可以在 2 月底之前，自由选择平台上的 6 门课程进行深度学习。立即扫码，提升团队整体实力，无惧迎接 AI 时代挑战。</p><p>↓↓↓扫描下图二维码参加活动↓↓↓</p><p><img src=\"https://static001.geekbang.org/infoq/e4/e4c5fae03a44b50caf660c0e96065a68.png\" /></p><p></p><p>培养 AIGC 应用能力</p><p>从系统实战到应用开发，探索 AI 大模型无限可能</p><p>掌握生产级 AI 系统研发能力</p><p>手把手带你用 LLM 提升研发效率</p><p>一站式掌握硬件、理论、LangChain 开发框架和项目实战技能</p><p>全面解析微调技术理论，掌握大模型微调核心技能</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5e/5eaa08a89078e7b3b4d8dd62cb0b16f0.png\" /></p><p></p><p>完善岗位专项技能体系</p><p>行业大咖规划职业进阶学习路径</p><p>全方位提升实战技能，补足能力短板</p><p>从工作应用出发，紧跟前沿技术发展和行业趋势</p><p>涵盖从基础知识到高级应用的全链路学习</p><p>按学习路径选课</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/be/be08f4c52878faad45a41cd8e2afb9bf.png\" /></p><p></p><p>按专项技能选课</p><p><img src=\"https://static001.geekbang.org/infoq/bf/bff22496a674fb9eca8a0ab2adf1797f.png\" /></p><p></p><p>提升技术对业务的驱动</p><p>向推动软件创新和变革的从业者学习</p><p>轻松获取源于实践、有效验证的优质内容</p><p>为项目汲取可落地的想法</p><p>验证企业软件开发路线图</p><p>掌握技术与业务创新深度融合的前沿案例</p><p>1400+ 顶尖技术团队实战案例</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6c/6c6e847069b59052dbf8363c7bbf3f08.png\" /></p><p></p><p>领跑 2024，数字化人才培养福利</p><p>6000 小时精选课程，</p><p>AI 大模型等前沿课程，</p><p>创新产品开发、架构设计等专业课程，</p><p>数字化领导力、数字化管理等领导课程，</p><p>数据分析等实用课程......</p><p>↓↓↓扫描下图二维码参加活动↓↓↓</p><p><img src=\"https://static001.geekbang.org/infoq/53/53485585ad6b50a70ddabad8d16bd69b.png\" /></p><p></p>",
    "publish_time": "2024-02-20 14:51:17",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "字节跳动辟谣推出中文版Sora：还无法完善产品落地，距离国外模型有很大差距",
    "url": "https://www.infoq.cn/article/Suc3VpjPiSq6PfukWxZm",
    "summary": "<p>今日有消息称，在Sora引爆文生视频赛道之前，国内的字节跳动也推出了一款颠覆性视频模型——Boximator。与Gen-2、Pink1.0等模型不同的是，Boximator可以通过文本精准控制生成视频中人物或物体的动作。</p><p>&nbsp;</p><p>对此，字节跳动相关人士向媒体回应称，Boximator是视频生成领域控制对象运动的技术方法研究项目，目前还无法作为完善的产品落地，距离国外领先的视频生成模型在</p><p>&nbsp;</p><p>根据介绍，Boximator 可以通过文本精准控制生成视频中人物或物体的动作。例如，“小猫把自己藏进杯子里了”：</p><p></p><p></p><p></p><p></p><p>“由像素组成的角色正在跳舞”：</p><p></p><p></p><p></p><p></p><p></p><p>“一个红衣女孩用头骨遮住了脸”：</p><p></p><p></p><p></p><p></p><p>“一名年轻女子转过头，露出了她的侧脸”：</p><p></p><p></p><p></p><p></p><p>“蜘蛛侠向镜头摆动”：</p><p></p><p></p><p></p><p>根据论文介绍，Boximator使⽤ 3D U-Net 架构构建在视频扩散模型之上。3D U-Net 由交替的卷积块和注意⼒块构成。每个块包含两个组件：⼀个空间组件，负责将各个视频帧作为单独的图像进⾏处理；另外一个是时间组件，⽀持跨帧信息交换。</p><p>&nbsp;</p><p>为了实现对视频中物体、人物的动作控制，Boximator 使用了“软框”和“硬框”两种约束方法。其中，硬框可精确定义目标对象的边界框，软框则定义一个对象可能存在的区域, 形成一个宽松的边界框。</p><p>&nbsp;</p><p>控制模块可以将框约束的编码与视频帧的视觉编码结合，用来指导视频的精准动作生成。包含框编码器和自注意力层两大块。</p><p>&nbsp;</p><p>论文地址：<a href=\"https://arxiv.org/abs/2402.01566\">https://arxiv.org/abs/2402.01566</a>\"</p><p>&nbsp;</p><p>下面是研发人员给出的Gen-2、Pink1.0 和Boximator 的对比：</p><p></p><p></p><p></p><p></p><p></p><p>&nbsp;根据其<a href=\"https://boximator.github.io/\">在Github</a>\"上的信息，Boximator演示网站正在开发中，将在未来 2-3 个月内推出。</p><p></p>",
    "publish_time": "2024-02-20 14:57:11",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]