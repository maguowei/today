[
  {
    "title": "基于契约的开发：通过明确需求优化软件开发流程",
    "url": "https://www.infoq.cn/article/g6D7e4ki76V3dRBWkrrK",
    "summary": "<p>独立开发和部署单个微服务的能力是成功采用微服务策略最关键的指标。然而，大多数团队在部署微服务之前必须经历大量的集成测试。这是因为集成测试已经成为识别微服务之间兼容性问题的必要条件，因为单元和组件或API测试没有覆盖微服务之间的交互。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/15/1501bd86ea9dbb41a22fc9fceb57e36e.png\" /></p><p></p><p>&nbsp;</p><p>首先，集成测试是一种发现兼容性问题的后期反馈机制。修复这些问题的成本随着发现时间的推移而成倍增加（如上图底部的热图所示）。</p><p>&nbsp;</p><p>此外，这可能会导致客户端和服务端团队做大量的返工工作，严重影响特性交付的可预测性，因为团队不得不兼顾常规的特性开发和集成错误修复。</p><p>&nbsp;</p><p>集成环境可能非常脆弱。由于两个组件或服务之间的兼容性问题，即使是单个中断的交互也会导致整个环境受到损害，这意味着即使是其他不相关的功能和微服务也无法测试。</p><p>&nbsp;</p><p>这给生产交付造成了阻碍，即使是对关键问题的修复，而且会让整个交付过程陷入停顿，我们称之为“集成地狱”。</p><p>&nbsp;</p><p></p><h2>集成测试——了解这头野兽</h2><p></p><p>&nbsp;</p><p>在终结集成测试之前，我们先来了解它到底是什么。这个词经常被用在不恰当的地方。</p><p>&nbsp;</p><p>测试应用程序不仅仅是测试每个函数、类或组件的逻辑。应用程序的功能是这些单独的逻辑片段与其对应部分交互产生的结果。如果两个组件之间的服务边界或API没有理清楚，就会导致通常所说的集成问题。例如，如果函数A只使用一个参数调用函数B，而函数B需要两个必填的参数，那么这两个函数之间就存在集成或兼容性问题。这种快速的反馈有助于我们尽早纠正并立即解决问题。</p><p>&nbsp;</p><p>然而，当我们在微服务级别（服务边界位于HTTP、消息传递或事件级别）识别兼容性问题时，单元和组件或API测试都无法立即识别出任何偏离或违反服务边界的行为。微服务必须与所有实际对应的服务一起测试，才能验证是否存在中断的交互。这些被广泛地（在某种程度上错误地）归类为集成测试。</p><p>&nbsp;</p><p>集成测试这个词被用来描述很多类型的检查：</p><p>&nbsp;</p><p>两个或多个组件之间的兼容性；工作流测试——涉及交互编排的整个功能；与其他依赖项（如存储、消息传递基础设施等）的交互；还有更多，生产基础设施的端到端测试除外。</p><p>&nbsp;</p><p>需要明确说明的是，当我们说终结“集成测试”时，我们说的是消除对“集成测试”的依赖，不要将其作为识别微服务之间兼容性问题的唯一方法。但其他东西，例如工作流测试，可能仍然是必要的。</p><p></p><h2>确定拐点——知道从哪里下手</h2><p></p><p>&nbsp;</p><p>当所有代码都属于一个单体，方法签名可能就可以作为服务边界的API规范。我们可以通过编译时检查等机制强制执行方法签名检查，从而为开发人员提供早期反馈。</p><p>&nbsp;</p><p>然而，当一个服务的组件被拆分为多个微服务，服务边界变为接口（如HTTP REST API）时，这种早期的反馈就不会有了。在之前作为方法签名进行文档化的API规范现在需要被显式地文档化，描述清楚正确的调用方法。如果API文档不是机器可解析的，还可能会导致团队之间的沟通混乱。</p><p>&nbsp;</p><p>如果没有良好文档化的服务边界：</p><p>&nbsp;</p><p>只能使用近似模拟的服务端来构建客户端，而手动模拟和存根技术通常会导致存根过期的问题，即存根无法真正表示服务端。对于服务端来说，无法模拟客户端。</p><p>&nbsp;</p><p>这意味着我们必须采用缓慢的串行化开发风格，即在开始开发另一个组件之前必须等待其中一个组件构建完成。如果需要快速发布特性，这就不是一种高效的方法。</p><p>&nbsp;</p><p>转向微服务后，我们失去了两个关键的能力：</p><p>&nbsp;</p><p>清楚地表示两个组件之间服务边界的API规范；强制执行描述服务边界的API规范。</p><p>&nbsp;</p><p>我们需要另一种方法来弥补这两方面的缺失。</p><p></p><h2>API规范</h2><p></p><p>&nbsp;</p><p>如果想要恢复清晰且按照机器可解析的方式来表示API签名的能力，采用API规范标准（如OpenAPI或AsyncAPI）就变得至关重要。虽然这增加了开发人员创建和维护这些规范的工作量，但利大于弊。</p><p>&nbsp;</p><p>尽管如此，API规范，顾名思义，也只是有助于描述API签名。在开发过程中，为了获得早期的反馈，又该如何强制执行它们呢？这一部分仍然是缺失的。</p><p></p><h2>代码/文档生成——无效且不可持续</h2><p></p><p>&nbsp;</p><p>我们可以认为，我们可以通过代码生成技术来生成和维护API规范。从表面上看，如果代码是基于规范生成的，就不会偏离规范。</p><p>&nbsp;</p><p>然而，这里存在一些难点：</p><p>&nbsp;</p><p>正在进行中的开发——大多数代码生成工具/技术为服务器端和客户端代码生成脚手架，并要求我们在这个脚手架/模板中填写业务逻辑。问题是，当规范发生变化时，我们通常需要重新生成脚手架，从旧版本的代码中提取业务逻辑，并再次粘贴到新的脚手架中，这增加了犯人为错误的可能性。数据类型不匹配——代码生成工具/技术必须支持每一种编程语言。在多语言环境中，生成的脚手架在不同编程语言之间的数据类型（或其他东西）可能不一致。如果我们为一种编程语言生成文档（基于服务端代码生成API规范），然后利用生成的规范进一步为客户端代码生成脚手架，这将进一步加剧这种情况的恶化。</p><p>&nbsp;</p><p>数据类型不匹配——代码生成工具/技术必须支持每一种编程语言。在多语言环境中，生成的脚手架在不同编程语言之间的数据类型（或其他东西）可能不一致。如果我们为一种编程语言生成文档（基于服务端代码生成API规范），然后利用生成的规范进一步为客户端代码生成脚手架，这将进一步加剧这种情况的恶化。</p><p>&nbsp;</p><p>总的来说，代码生成和文档生成只能满足有限的场景。虽然它们最初可能通过生成代码为团队提供快捷的构建应用程序的方法，但这种技术的持续成本会让团队不堪重负。</p><p>&nbsp;</p><p>因此，我们需要另一种方法来执行API规范。</p><p></p><h2>契约驱动开发——API规范作为可执行契约</h2><p></p><p>&nbsp;</p><p>方法签名可以由编译器强制执行，在开发人员偏离方法签名时向他们提供早期反馈。那么API也能实现类似的效果吗？</p><p>&nbsp;</p><p>契约测试就是实现这种效果的一种尝试。<a href=\"https://docs.pact.io/\">Pact.io的文档</a>\"中写道：</p><p>&nbsp;</p><p></p><blockquote>契约测试是一种测试集成点的技术，它会单独检查每个应用程序，确保它们发送或接收的消息符合记录在“契约”中的内容。</blockquote><p></p><p>&nbsp;</p><p>不过需要注意的是，契约测试本身也包含了几种方式，例如客户端驱动的契约测试（<a href=\"https://pact.io/\">Pact.io</a>\"）、服务端驱动的契约测试（生产者契约测试方法中的<a href=\"https://spring.io/projects/spring-cloud-contract\">Spring云契约</a>\"）、双向契约测试（<a href=\"https://pactflow.io/\">Pactflow.io</a>\"）等等。在大多数这些测试方法中，API契约是独立于API规范的文档。例如，在Pact.io中，JSON就是API契约。Spring云契约也有用于定义契约的DSL。与其维护两个不同的工件（可能会导致不同步），不如利用API规范本身作为API契约，在开发人员偏离API规范导致客户端出现问题时为他们提供早期反馈，这样会不会更好？</p><p>&nbsp;</p><p><a href=\"https://specmatic.in/\">Specmatic</a>\"就是这样做的。Specmatic是一个开源的基于契约驱动开发的工具。它将客户端和服务端之间的交互划分为独立可验证的单元。考虑下面两个微服务之间的交互，目前只在更大级别的测试环境中进行验证。</p><p>&nbsp;</p><p><code lang=\"null\">ServiceA &lt;-&gt; ServiceB</code></p><p>&nbsp;</p><p>CDD可以将这种交互分解成连续的组成部分：</p><p>&nbsp;</p><p><code lang=\"null\">ServiceA &lt;-&gt; Contract as Stub {API spec of ServiceB}\n             Contract as Test {API spec of ServiceB} &lt;-&gt; ServiceB</code></p><p>&nbsp;</p><p>现在我们来仔细研究一下。</p><p>&nbsp;</p><p>左边：ServiceA =&gt; <a href=\"https://specmatic.in/#contract-as-stub\">Contract as Stub</a>\"我们为客户端（ServiceA）模拟服务端（ServiceB），这样客户端应用程序开发就可以独立于服务端进行。由于Contract as Stub（智能Mock）是基于双方约定的API规范，因此能够真正作为服务端（ServiceB）的Mock，它会在客户端（ServiceA）调用API并偏离API规范时给出反馈/抛出错误。右边：<a href=\"https://specmatic.in/#contract-as-test\">Contract as Test</a>\" =&gt; ServiceB为服务端（ServiceB）模拟客户端（ServiceA），并验证响应是否符合双方约定的API规范。Contract as Test将在服务端（ServiceB）应用程序开发人员偏离规范时立即向他们提供反馈。</p><p>&nbsp;</p><p>既然我们可以在组件级别让客户端（ServiceA）和服务端（ServiceB）应用程序遵守API规范，同时又可以独立构建，那么就没有必要将它们部署在一起来测试它们的交互。这样我们就不需要再依赖集成测试来识别兼容性问题。</p><p>&nbsp;</p><p><a href=\"https://specmatic.in/\">Specmatic</a>\"就是这样利用API规范作为<a href=\"https://specmatic.in/#executable-contracts\">可执行契约</a>\"。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1d/1d4b65ae3b3faa062a53b314ce9a1494.png\" /></p><p></p><p></p><h2>契约即代码</h2><p></p><p>&nbsp;</p><p>这里的关键是API规范本身，它可以让API提供者和使用者分离并独立地驱动各自组件的开发和部署，同时保持所有组件的一致性。</p><p>&nbsp;</p><p>为了成功地进行契约驱动开发，我们需要采用API优先的方法，即API提供者和使用者需要先协作设计和记录API规范。这意味着他们需要使用现代的可视化编辑器之一，如Swagger、Postman、Stoplight等来编写API规范，在开始独立构建各自的部分之前专注于API设计，并确保所有利益相关者保持同步。</p><p>&nbsp;</p><p>习惯于基于代码生成API规范的团队可能会对这种先编写API规范的反向流程感到不适应。CDD需要类似测试驱动开发的心态转变。在进行测试驱动开发时，我们需要通过先手写测试来指导/驱动代码设计。类似地，在CDD中，我们需要先手工编写API规范，然后使用Specmatic等工具将它们转换为可执行的契约测试。</p><p>&nbsp;</p><p>我发现，对于基于代码生成API规范的方法来说，API设计处于次要地位，变得更像是事后的想法，或者是偏向于客户端或服务端。此外，由于发布时间的压力，在采用API规范优先的方式时，我们能够并行独立开发客户端和服务端组件，而基于代码生成API规范这种方式是不可能做到这一点的（客户端必须等待服务端代码完成并生成了规范）。</p><p>&nbsp;</p><p>在就公共API规范达成了共识之后，让这些API规范有一个单一的真实来源就变得非常重要。如果这些规范出现了多个副本，会导致客户端和服务端团队在实现方面出现分歧。</p><p>&nbsp;</p><p>CDD建立在三个基础支柱之上。“契约即存根（Contract as Stub）”和“契约即测试（Contract as Test）”让客户端和服务端团队保持一致，但将一切联系在一起的粘合剂是第三个支柱——“<a href=\"https://specmatic.in/#contract-as-code\">中央契约存储库</a>\"”。</p><p>&nbsp;</p><p>API规范是机器可解析的代码，所以还有什么地方比版本控制系统更适合存储它们的呢？将它们存储在版本控制系统（如Git）中，我们就可以通过添加Pull/Merge请求过程来为它们的构建过程增加一些严格性。理想情况下，Pull/Merge请求应该包括以下步骤：</p><p>&nbsp;</p><p>语法检查，确保一致性；<a href=\"https://specmatic.in/#backward-compatibility\">向后兼容性</a>\"检查，确定是否有任何重大变更；最后的评审和合并。</p><p>&nbsp;</p><p>强烈建议将规范存储在同一个中心位置，这适用于大多数情况（甚至是大型企业）。除非绝对有必要，否则不建议跨多个存储库存储规范。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/33/33ad3c54b25ca7a4fe03e186a2e61d53.png\" /></p><p></p><p>&nbsp;</p><p>等到规范被存储到了中央存储库中，它们就可以被：</p><p>&nbsp;</p><p>客户端和服务端团队使用，分别进行独立的开发；发布到API网关。</p><p></p><h2>集成测试的终结</h2><p></p><p>&nbsp;</p><p>我们已经消除了对通过集成测试来识别应用程序兼容性问题的需求，那么系统测试和工作流测试呢？</p><p>&nbsp;</p><p>CDD为更大级别的测试环境铺平了道路，因为所有兼容性问题都在开发的更早阶段（在本地和CI等环境中）被识别出来，在这些环境中修复问题的成本要低得多。我们可以通过系统测试和工作流测试在稳定的更大级别的环境中验证复杂的编排问题。另外，由于我们已经不需要通过集成测试来识别兼容性问题，在更大级别的环境中测试套件的总体运行时间也缩短了。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/47/4766b5a4916e83a558b3caa59f785364.png\" /></p><p></p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/contract-driven-development/\">https://www.infoq.com/articles/contract-driven-development/</a>\"</p>",
    "publish_time": "2023-03-14 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AI开源如何吞噬AI",
    "url": "https://www.infoq.cn/article/akfrB58CcSlQkaAbqLwG",
    "summary": "<p>本文最初发布于swyx的个人博客。</p><p></p><p>GPT-2的周期为6个月：</p><p></p><p>2019年2月，OpenAI宣布了GPT-2，但说它太危险了，尚不能全部发布，并从非营利性改组为有限营利（capped-profit）。到了8月，两名硕士生公开克隆了它，并命名为OpenGPT-2。到了11月，经过谨慎地分阶段发布，OpenAI发布了他们的1.5B参数模型。&nbsp;</p><p></p><p>GPT-3的周期为10个月：</p><p>2020年5月：OpenAI将GPT-3以论文形式发布，并在2020年6月发布了封测版API。2020年7月：EleutherAI成为一个真正开放的OpenAI替代品。2020年9月：授予微软“GPT-3独家许可”。2021年1月：EleutherAI发布了The Pile，他们800GB的数据集。2021年3月：EleutherAI发布了他们开放的GPT-Neo 1.3B和2.7B模型。2021年11月：OpenAI将API从等待列表中移除。2022年5月：Meta面向研究人员发布了OPT-175B（包括日志和一个开放许可）。2022年6月：Yandex在Apache-2许可下发布YaLM-100B。2022年7月：HuggingFace在RAIL许可下发布BLOOM-176B。</p><p></p><p>Text-to-Image的周期为两（？）年（GANs的整个历史达10年之久）：</p><p></p><p>2020年6月：OpenAI在博客上介绍了Image GPT。2020年12月：Patrick Esser等人发表论文Taming Transformers for High-Resolution Image Synthesis（又称VQGAN，大幅改进了2019年的VQVAEs）。2021年1月：OpenAI宣布了第一代DALL-E的结果并开源CLIP。2021年5月：OpenAI宣布，他们发现扩散模型在图像合成中击败了GANs。2021年12月：CompVis小组发布了使用潜在扩散模型合成的高分辨率图像，以及原始存储库CompVis/latent-diffusion。2021年12月：OpenAI发布了GLIDE：利用文本引导扩散模型实现逼真的图像生成和编辑。2022年3月：Midjourney推出封测版。2022年4月：OpenAI宣布推出DALL-E 2，并提供受限“研究预览”。2022年5月：谷歌发布他们的Imagen论文（在3天时间内用PyTorch实现）。2022年7月：DALL-E 2通过OpenAI的UI/API提供公开测试版（有等待名单）。2022年7月：Midjourney也通过他们的Discord宣布了一个完全开放的测试版。2022年8月：Stable Diffusion &nbsp;1.4公开发布，遵循OpenRAIL-M许可。模型和代码来自CompVis + Runway，Stability AI提供资金以增加计算能力。2022年9月：OpenAI将DALL-E 2移出等待名单。2022年10月更新：Runway发布Stable Diffusion 1.5版，存在一定的争议性。2022年11月更新：Stability发布Stable Diffusion 2.0。</p><p></p><p>当然，上面这个时间线是经过仔细筛选的；如果把扩散模型（2015年）和Transformer模型（2017年）从学术论文发表到开发的历史以及GANs之前的工作都考虑进来，那么这个故事要长得多。还可以看下Stable Diffusion在RunwayML的研究起源，以及2021年12月，Emad在与Elad Gil的聊天中对CC12M的突破性进展的描述。</p><p></p><p>但更有趣的是此后发生的事情。9月份，OpenAI发布音频转文本模型Whisper，遵循MIT许可，没有设置API付费墙。当然，音频转文本领域的滥用空间比较小，但也有不少人猜测，人们对Stable Diffusion发布的反应影响了开源决策。</p><p></p><p></p><h2>Dreambooth：社区掌控方向</h2><p></p><p></p><p>足够先进的社区是有魔力的。研究人员和资金充足的团队一直都非常擅长创建新的基础模型（FM），但提供产品化用例和优化模型的最后一英里则是开源社区非常擅长的工作。</p><p></p><p>在这方面，最可量化的例子发生在最近的Dreambooth循环中（通过主题的少样本分析对text-to-image进行微调以插入场景）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/60/6021a7ba48528342ec5115cd72a34e9a.png\" /></p><p></p><p>Dreambooth是一个值得考虑的优化目标，因为你不仅要下载一个模型并运行它，还要在自己的样本图像上运行微调训练，但最初的移植需要大量的内存，以至于对大多数人来说，不可能在自己的机器上运行。</p><p>&nbsp;是Corridor Digital的家伙们让它在YouTube上走红。</p><p></p><p>Twitter形式的时间线：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cd/cde0bb9e4e4d6b4cef03cae450ac271f.png\" /></p><p></p><p>可以看出，为了那些在自己机器上运行模型的人，开源社区在12天内完成了开源移植，然后在随后的25天内将系统要求降低了79%。</p><p></p><p></p><blockquote>更新：10月8日，系统需求再次降低，变成8GB。</blockquote><p></p><p></p><p>大部分优化工作都发生在GitHub上，由Xavier Xiao（来自新加坡的生成式模型和优化博士，就职于AWS AI）和Shivam Shrirao（驻印度的高级计算机视觉工程师）完成，并得到来自意大利的Matteo Serva的帮助。两人与原Dreambooth团队都没有关系。&nbsp;</p><p></p><p>低处的果实都摘完了，使得一些人开始担心收益递减，但还是存在一些概念验证，将Stable Diffusion缩小到可以在手机上运行（之前已降至10GB甚至5GB——消费级卡的内存为6-12GB，iDevices有统一内存）。</p><p></p><p>这可能是开源人工智能模型优化的圣杯，因为这样一来，图像生成实际上就不再受云经济和利润动机的限制了。</p><p></p><p></p><blockquote>2022年10月更新：这里有一个开源实现：https://github.com/madebyollin/maple-diffusion&nbsp;</blockquote><p></p><p></p><p></p><h2>开源做了哪些研究人员未做的事</h2><p></p><p></p><p>虽然在这3个新的text-to-image模型中，Stable Diffusion是出现最晚的，但在社区的帮助下，它在影响力和应用方面都远远超过了另外两个与其存在竞争关系的text-to-image模型Midjourney和DALL-E。</p><p>这就为其他形式的人工智能（音乐、生物、语言模型）如何开源（才有可能创造新的机会）提供了一个有用的、具有推广价值的路线图。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e7/e7c4506cebe804193942e3e655d18130.png\" /></p><p>&nbsp;</p><p>以下是提高所需技术技能的一个大致顺序：</p><p></p><p></p><h4>改进文档</h4><p></p><p></p><p>原始的CompVis README对于初学者而言并不友好社区合力创建：R*tard指南和常规指南博客推特主题YouTube演练谷歌专栏带注释的网站和图示说明</p><p></p><p></p><h4>分享 Prompt</h4><p></p><p></p><p>Prompt工程是一种后天技能，在GPT3发布3年后，有人仍然用它得出了令人惊讶的结果（1、2）；这意味着LLM有很大的潜力（不只是结果），而我们尚处于初级探索阶段对于分享Prompt，每个社区现在都有了成熟完备的方法，以此为基础，我们可以建立Prompt库，大幅减少寻找Prompt的耗时（从大于30秒到不足300毫秒，减少了2个数量级！），降低Prompt工程的学习难度。社区也是利用这种方法摸索已知的难题，如如何生成真实的手和Negative Prompt的重要性。</p><p>&nbsp;</p><p></p><h4>创建新的 UI 及改进可访问性</h4><p></p><p></p><p>由于Stable Diffusion“只是”一个Python脚本，人们可以根据自己的需要创建自己的UI，而不必受Stability AI自己的Dreambooth所束缚。AUTOMATIC1111已经成为社区中最重要的Web UI，它提供了大量的功能，可谓集社区发现的SD使用智慧之大成。由于ML社区偏爱Windows，所以开源社区已经实现了大量在M1 Macs或许还有iPhone上运行的技巧（如上所述）。通常，SD UI是独立的应用程序，但新的交付模式使它们可以作为现有工作流程的一部分来使用，在Photoshop、Figma、GIMP，甚至是VR里面。</p><p>&nbsp;</p><p></p><h4>以创造性的方式扩展现有特性，开创新的用例</h4><p></p><p></p><p>我不清楚谁首先发明了Inpainting和Outpainting技术（它最初是在DALL-E的公告中被提及，但是在像这样的开源UI被创建出来后，它才真正被广泛使用）更多：超高分辨率Outpainting，3D世界与其他工具/技术搭配使用是成熟创新的另一个来源：“反向Prompt工程”也就是使用图像进行Prompt（使用CLIP Interrogator）使用txt2mask来增强Inpainting多个后处理步骤，包括使用Real-ESRGAN、TECOGAN、GFPGAN、VQGAN等（如AUTOMATIC1111中的“hires fix”)创建一个GRPC服务器（用于与Stability AI通信）为txt2music、music2img等新模式做准备</p><p></p><h4>优化内核</h4><p></p><p></p><p>（如上所述）最大限度地减少Stable Diffusion和Dreambooth占用的内存将Stable Diffusion的速度提高了50%</p><p></p><p>一个有趣但重要的切入点——大部分AI/ML的东西都是用Python编写的，而Python作为一种分发机制是很不安全的。也就是说，“开源人工智能”的兴起也将伴随“开源人工智能安全”需求的日益增加。</p><p></p><h2>AI 开源的未来</h2><p></p><p></p><p>整个过程让人不禁联想到开源是如何吞噬Software 1.0的：</p><p></p><p>版本控制：从Bitkeeper到Git语言：从Java工具链到Python、JavaScript和Rust集成开发环境（IDE）：从[许多相当不错的IDE]到VS Code占据60%以上的市场份额数据库：从Oracle/IBM到Postgres/MySQL</p><p></p><p>Anders Hejlsberg是Turbo Pascal、TypeScript等5种语言之父，他有一句名言：未来，不开源的语言是不会取得成功的。或许，对于技术栈中越来越多的东西，你都可以说同样的话。</p><p></p><p>我们很容易得出这样的结论，在Software 2.0/3.0中也会出现同样的情况，但还存在一些问题。</p><p></p><p></p><h4>问题 1: 经济诱因</h4><p></p><p></p><p>对于经济学家来说，希望基础模型开源发布是违反直觉的。据估计，训练GPT-3的成本在460万到1200万美元之间，还不包括人工成本和失败的尝试（现在，一些创业公司声称已将其降低到45万）。即使是Stable Diffusion令人印象深刻的60万美元成本（Emad暗示真实数值要低得多，但也说他们的实验成本是13倍（200万A100小时）），在没有投资回收计划的情况下，也不是什么可以随意忽视或放弃的东西。</p><p>从OpenAI通过API盈利的轨迹来看，每个人都明白AI经济的发展趋势：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1e/1e3041791285287a10db2af87909130c.png\" /></p><p></p><p>（如果Research &gt; Infra可能会有争议，所以让它们大致相等，就迁就我一下吧）</p><p></p><p>但作为非经济行为体，Stability AI的既定目标是既压低拥有专有基础模型研究的经济价值，又扩大人工智能的总体TAM：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bb/bb64c11ac4800d2ff5142102304e28b7.png\" /></p><p>这是由Stan Shih提出的关于行业价值分布的微笑曲线模型，Ben Thompson也做过广泛的讨论。</p><p></p><p>最大的问题是Stability公司打算如何为自己融资——1亿美元的A轮融资为他们争取了一些时间，但在我们真正知道Stability公司打算如何赚钱之前，这个生态系统不会真正稳定下来。</p><p></p><p></p><blockquote>来自Emad的回应：“商业模式很简单，规模和服务与普通COSS类似，但有一些附加价值。</blockquote><p></p><p></p><p></p><h4>问题 2：许可</h4><p></p><p></p><p>根据最坚定的开源倡导者的说法，对于开源一词，我们整篇文章中的用法都是错误的。严格地说，一个项目只有在遵循OSI批准的少数许可之一的情况下才是开源的。与此同时，几乎没有一个“开源AI”模型或衍生品需要许可，诚信问题完全被忽略：</p><p></p><p>https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/24</p><p></p><p>https://github.com/divamgupta/diffusionbee-stable-diffusion-ui/issues/5</p><p></p><p>https://github.com/breadthe/sd-buddy/discussions/20</p><p></p><p></p><blockquote>2022年10月更新：InvokeAI是一个例外，它遵循MIT许可。</blockquote><p></p><p></p><p>Stable Diffusion自己发布了一个新的CreativeML Open RAIL-M许可（RAIL代表Responsible AI，由一个独立的团队创建），用于管理模型权重（要花60万美金才能获得），其中某些部分与OSI批准的许可兼容，但也有些不兼容的用例限制。如果你与法律部门和OSI的人打过交道，就会知道这是行不通的，这种许可分歧没有法律先例可依。</p><p></p><p>StabilityAI已经清楚地表明，你可以将其产品用于商业目的，他们甚至公开支持Midtravel使用StabilityDiffusion，但当有一天，赌注扩大1000倍时，法律细节就开始变得重要了。</p><p></p><p></p><blockquote>来自HuggingFace人工智能顾问Carlos Muñoz Ferrandis的说明：“Meta发布的OPT175（LLM）、BB3（聊天机器人）和SEER（计算机视觉）许可类似于RAIL（包括用例限制），仅用于研究目的（许可证有2个取决于模型的变体）。”</blockquote><p></p><p></p><p>OpenAI Whisper是我所知道的第一个模型、权重和代码都遵循MIT许可（简单、\"真正开源\"）的例子。</p><p></p><p></p><blockquote>Emad更正道：“除了Stable Diffusion，我们支持的所有模型都已经在MIT许可下发布了，例如，花了120万A100小时的OpenCLIP。”时间敏感提示：如果你很关心许可，则可以关注下GitHub和开源研究所10月18日组织的讨论和一个专家组。你也可以联系Tidelift总顾问Luis Villa。</blockquote><p></p><p></p><h4>问题 3：“开源”了什么？</h4><p></p><p></p><p>撇开OSI的批准不谈，到目前为止，我们有意忽略了另一个问题，那就是“开源”到底意味着什么。</p><p>&nbsp;在传统的Software 1.0时代，“开源”意味着代码库开源，但不一定是基础设施设置的细节，也不一定是代码所积累/操作的数据。换句话说，开放代码并不意味着开放基础设施或开放数据（虽然不是必须的，但在实践中，通常至少会有一些关于如何自托管的基本指南）。</p><p></p><p>在Software 2.0时代，数据收集变得非常重要，并开始主导代码（被简化为模型架构）。像ImageNet这样的开放数据集帮助培养了整整一代ML工程师，最明显的动力来自Kaggle比赛，当然还有ImageNet挑战赛本身（在这项赛事中，AlexNet和CNN推动了整个领域向深度学习的融合）。通过半同态加密，你甚至可以屏蔽数据以创建像Numerai这样的系统——不是严格意义上的开放，但也足够开放，无聊的数据科学家可以摆弄下这些假数字，赚点外快。不过，权重通常是不开放的，因为那是训练成本最高的内容。</p><p>有了Software 3.0和已知的Chinchilla缩放曲线，LLM和FM成了人们在单一大型语料库上进行的一次性大规模投资。</p><p></p><p>“开源AI”运动正在用几种不同的方式来解决这个问题：</p><p></p><p>开放数据集：例如，LAION-5B和The Pile。这些数据集已经针对Waifus、日语、中文和俄语进行了修改。开放模型：通常通过研究论文发布——如果提供了足够的细节，人们就可以自己重新实现，就像GPT3和Dreambooth那样。开放权重：这个新的潮流源于HuggingFace的BigScience（发布了BLOOM），然后由Stability AI应用于text-to-image，并由OpenAI Whisper接续（其经济性在问题1中讨论过）。开放接口：不只提供了可供调用的API，就像OpenAI在GPT3中所做的那样，而是直接提供了对代码的访问，为的是方便用户修改和编写他们自己的CLI、UI和其他任何他们想要的东西。开放Prompt：用户（像Riley Goodside）和研究人员（像Aran Komatsuzaki）分享了Prompt技术的突破，释放了FM的潜力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8f/8fc46224bee65ef7bbac4d8e378ce1e5.png\" /></p><p></p><p>上述内容的确切顺序会根据实际的进展和背景的变化而变化，但这感觉对吗？</p><p></p><h3>开源 AI 研究所？</h3><p></p><p>关于“开源 ”人工智能的所有这些方面，开源促进会（Open Source Initiative）可能确实没有考虑到，而开源AI文化最基础的举措之一是创建一个有预期、规范和法律先例可循的可信标准。这是Hugging Face和Stability AI的机会，但也许已经有其他组织这样做了，只是我还没有发现。</p><p></p><p></p><h4>延伸阅读</h4><p></p><p>另一条延伸到2021年11月的时间线我的大多数笔记都是在公共场合做的；我会在GitHub上实时更新我的想法</p><p></p><p>原文链接：https://lspace.swyx.io/p/open-source-ai</p>",
    "publish_time": "2023-03-14 09:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "被全球追捧的ChatGPT，在实际AI应用场景表现如何？",
    "url": "https://www.infoq.cn/article/jYshx1P5gCpuCtLZReAP",
    "summary": "<p>作者 |&nbsp;詹坤林，58技术委员会AI分会主席，TEG—AI Lab 负责人</p><p>策划 | 刘燕</p><p></p><p>本文内容为2023年2月14在58技术委员会AI分会AI技术沙龙《ChatGPT科普和应用初探》上的分享总结。</p><p></p><p>OpenAI在2022年11月30日发布了ChatGPT，它是一个基于大模型技术实现的通用聊天机器人，它可以用来写作、翻译、润色句子、做事实性问答、执行文本分类/实体抽取/阅读理解/文本摘要等各类NLP任务，甚至可以写SQL、写代码，几乎无所不能。</p><p></p><p>ChatGPT自发布之后一直大火至今，引起行业震动，我们也持续在跟进ChatGPT，体验其功能，了解其技术原理，并基于爬虫技术封装了ChatGPT API，在实际NLP应用场景下对比了ChatGPT和自研技术的效果。</p><p></p><p>本文从应用角度出发，给出一些对ChatGPT的思考。</p><p></p><p></p><h2>一、GPT 到 ChatGPT 的演进</h2><p></p><p></p><p>Google于2017年在《Attention Is All You Need》一文中发布了Transformer，此后对NLP、语音、CV等AI领域产生了深远影响。2018年6月，OpenAI发布了GPT（Generative Pre-Training）[1]——基于Transformer Decoder结构和无监督预训练方法实现的生成式预训练语言模型，也即GPT-1。</p><p></p><p>2018年10月，Google发布了BERT（Bidirectional Encoder Representation from Transformers）[2]，BERT是基于Transformer Encoder结构的预训练语言模型，在多项NLP任务上取得SOTA效果，开启了自然语言处理「预训练+微调」的新范式，是自然语言处理发展史上的里程碑。</p><p></p><p>BERT自发布之后在学术界和工业界均产生了重大影响，大量论文和应用基于BERT实现，谷歌学术上BERT的论文引用数也远超GPT，近几年大模型技术火热，国内外发布的大部分大模型也是基于BERT技术路线来实现。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/61/61177c0d22f67361a3c883b7e66ac439.png\" /></p><p></p><p>OpenAI持续升级优化GPT，于2019年2月发布了GPT-2[3]，于2020年6月发布了拥有1750亿参数的超大模型GPT-3[4]，轰动一时，GPT-3不需要像BERT那样针对特定任务做微调（Fine-tune），一个大模型即可在一系列自然语言处理任务上取得优秀的效果，结合Few-Shot少样本学习能力，在部分任务上甚至接近或者达到当时的SOTA效果。</p><p></p><p>使用BERT执行某个具体场景下的NLP任务如文本分类时，需要人工标注该场景下的一定量数据，然后微调得到一个文本分类模型应用于分类，即重新更新了模型，对于不同的任务均要这样做。</p><p></p><p>而使用GPT-3执行NLP任务时，不需要重新更新模型，只需要向其发送一句提示（Prompt）例如「请给这段文字分类，类别标签有A、B、C」即可完成分类，或者可以使用少量标注数据作为例子告诉模型，能够取得更优的效果，在这一点上GPT-3要比BERT更加易用。值得说明的是，自GPT-3开始，OpenAI没有像GPT-1、GPT-2那样发布开源代码，而是以API的形式提供商业化服务，具体见&nbsp;https://openai.com/api。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/de/de7dc38fc0a3f2f5f607aba07963375a.png\" /></p><p></p><p>BERT和ChatGPT执行任务的区别</p><p></p><p>ChatGPT是从GPT-3发展而来的，符尧等人在《拆解追溯 GPT-3.5 各项能力的起源》一文[10]中总结了GPT-3到GPT-3.5的进化树，GPT-3在OpenAI API中的模型名称为Davinci（达芬奇），之后经历在代码上训练、指令微调、RLHF（Reinforcement Learning from Human Feedback，基于人类反馈的强化学习）等过程，进化成ChatGPT，详细内容可参见文章[10]，这里不再赘述。</p><p></p><p>2022年11月，OpenAI除了发布ChatGPT之外，还发布了text-davinci-003模型，两者都是在text-davinci-002模型的基础上使用RLHF方法训练得到的，ChatGPT实际上不仅是一个单独的模型，而是一个完整的Web聊天机器人产品，其内部调用的模型假设也称作ChatGPT。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/81/81ef0a8c27a07d771d0e9762eb44ebec.png\" /></p><p></p><p>GPT-3到GPT-3.5的进化树.&nbsp;符尧等.&nbsp;2022.12.11</p><p></p><p>OpenAI当前并未公布ChatGPT论文，只在官网发布了一篇BLOG[9]，BLOG中讲到「We trained this model using Reinforcement Learning from Human Feedback (RLHF), using the same methods as&nbsp;InstructGPT, but with slight differences in the data collection setup」，ChatGPT模型训练采用了RLHF方法，和2022年3月发布的InstrutGPT[8]一致，仅是数据采集上有一些差异，当前介绍ChatGPT技术原理的文章均是介绍InstrutGPT。</p><p></p><p>RLHF并非是一个全新的方法，InstrutGPT论文里有讲到该方法参考了2020年9月发布的文章《Learning to summarize from human feedback》[7]和2017年6月发布的文章《Deep reinforcement learning from human preferences》[12]，文章[7]又参考了2019年9月发布的文章《Fine-Tuning Language Models from Human Preferences》[6]，由此可见，OpenAI在RLHF方法上有持续的沉淀积累，ChatGPT的诞生也并非一蹴而就。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/87/870ea4dd8365c6c734a00f0d3b0efe1f.png\" /></p><p>ChatGPT训练过程. 2022.11.30</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/af/aff78c1c84f74cff97fbcd4a45b309b7.png\" /></p><p></p><p>InstructGPT训练过程. 2022.3</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/23/237e08bb06c060ef2b7a5eab668eb359.png\" /></p><p></p><p>Learning to summarize from human feedback. 2020.9</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/15/15e6d7fe7b120acaf792575b90db6946.png\" /></p><p></p><p>Fine-Tuning Language Models from Human Preferences. 2019.9</p><p></p><p></p><h2>二、GPT API 说明</h2><p></p><p></p><p>当前，在OpenAI发布的GPT API中可以调用上文GPT-3到GPT-3.5的进化树中除ChatGPT模型之外的所有模型，用户可以在API Playgroud里选择模型版本进行体验，也可以编写程序调用API来进行批量实验，如下图所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/82/82fe58ffc00efb2c789fd6bf03f6eca7.png\" /></p><p>GPT API&nbsp;Playground</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b5/b559998712b477885c3276dcebc5e464.png\" /></p><p></p><p>GPT&nbsp;API 当前支持的模型</p><p></p><p>ChatGPT是以一个Web聊天机器人的形态发布的，用户需要登录网站进行体验，OpenAI目前还未发布ChatGPT API，但OpenAI API官网显示不久后将发布「ChatGPT is coming to our API soon, sign up to stay updated」。目前业界有一些声称基于ChatGPT的聊天机器人工具，均是以非官方API来实现的，例如可以基于爬虫技术来访问ChatGPT官网，封装成ChatGPT API，并注册大量ChatGPT账号，以保证支持一定的访问量。</p><p></p><p>ChatGPT官网对访问频率有限制，且官网时不时会因为用户请求过多无法访问，这样的API不是很稳定，只能在一些离线场景应用。值得一提的是，目前ChatGPT提供了付费账号，价格为20美元/月，经测试，付费账号和免费账号在访问频率上并没有多大差别，只是付费账号的服务响应会相对稳定一些，若是个人使用，直接使用免费账号即可。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/75/75e79252deabf69c574f022b32e693e3.png\" /></p><p>ChatGPT官网</p><p></p><p>GPT API按照输入输出的token数量收费，价格为0.02美元/1000tokens，一个token大概是0.75个英文单词，一个中文汉字为两个token，这里包括请求API的token（Prompt）和API返回的token（Completion），一个GPT账号会免费赠送18美元的额度，有效期为3个月。未来ChatGPT API 收费方式很可能也和此相同。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9f/9fb063837acbf01ec1b205464b60886f.png\" /></p><p>GPT API 收费说明</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/00/00fbeefc1a2bf6c78b24d0cdf542a1f9.png\" /></p><p></p><p>平台针对每次请求输入和输出token计数</p><p></p><p>从GPT-3到GPT-3.5的进化树中可以看到text-davinci-003模型和ChatGPT模型均是在text-davinci-002模型的基础上使用RLHF方法训练得到，都在2022年11月发布，两者的差别可能是针对不同类型人工反馈数据调优上的差异，ChatGPT模型是应用于对话聊天，会基于线上对话数据调优，在上下文多轮对话、拟人化等能力上可能更强，text-davinci-003基于GPT API上用户反馈数据（如上述Playground）调优，在相关任务上的效果和ChatGPT相比可能差异不大，如后文有实验在评论情感分类任务上二者效果相当。因此，用户可以直接在GPT API中使用text-davinci-003模型来搭建相关应用。</p><p></p><p></p><h2>三、GPT-3&nbsp;训练成本</h2><p></p><p></p><p>GPT-3拥有1750亿参数，模型训练需要消耗大量资源，OpenAI并未公开过GPT系列大模型训练和推理消耗的具体费用，我们可以从其他材料中获得一些信息。</p><p></p><p>2020年5月，文章[12]中讲到微软在Azure上为OpenAI搭建了独立的超级计算机系统，包含28.5万个CPU核和1万张GPU卡（当时为V100）：The supercomputer developed for OpenAI is a single system with more than 285,000 CPU cores, 10,000 GPUs and 400 gigabits per second of network connectivity for each GPU server。2020年6月发布的GPT-3模型应该是在该系统上训练得到。</p><p></p><p>英伟达在2021年4月发表的《Efficient Large Scale Language Model Training on GPU Clusters》[13] 文章中有预估不同参数规模的大模型训练需要消耗的资源和时间：使用1024张80G显存的A100卡训练1750亿参数的GPT-3模型，需要训练34天。</p><p></p><p>这些都是2-3年前之前的费用说明，根据相关材料介绍，当前训练GPT-3的费用更低 ，文章《<a href=\"http://mp.weixin.qq.com/s?__biz=MzU5ODY2MTk3Nw==&amp;mid=2247490676&amp;idx=1&amp;sn=f3f98a7b3b0670e4274dd681dcb44430&amp;chksm=fe419242c9361b5425dd7205f30ceba365dbb05ee0a6f6d8a676357b1295fc341c7371a33860&amp;scene=21#wechat_redirect\">ChatGPT背后的经济账</a>\"》讲到「对于大公司而言，训练LLM（即使是从头开始）的成本并不高，如今，在公有云中训练GPT-3仅需花费约140万美元」。</p><p></p><p></p><h2>四、ChatGPT的应用</h2><p></p><p></p><p>ChatGPT可以用来写作、翻译、润色句子、做事实性问答、写SQL、写代码、执行文本分类/实体抽取/阅读理解/文本摘要等各类NLP任务，相关案例不一一赘述，这里仅讨论在智能写稿、智能客服、智能外呼实际产品场景下我们对ChatGPT的应用尝试，相关实验对比结果基于我们自主封装的ChatGPT API完成。</p><p></p><p></p><h3>智能写稿：</h3><p></p><p></p><p>我们从2018年开始就有落地智能写稿，利用机器自动生成一些稿件应用于各类场景，如自动生成二手车车源介绍文章，可参见《<a href=\"http://mp.weixin.qq.com/s?__biz=MzA5OTQ1MDQ4Mw==&amp;mid=2456197989&amp;idx=1&amp;sn=e1c68a4129e236249f08bb488d695083&amp;chksm=87101079b067996f64f63242a6b30c1eb97a720afb23a5b8cca2a7600707ab4169b89a20fef6&amp;scene=21#wechat_redirect\">58智能写稿机器人实践</a>\"》。原始生成方法是基于优质车源帖子数据，利用模板填充和文本生成技术自动生成文章，生成的文章较短且生硬，我们使用ChatGPT来润色这些文章，向ChatGPT发送prompt提示「请润色下面这段文字，字数在400字以内」即可完成该任务，通过ChatGPT润色的文章可读性极佳。此外，我们也尝试直接拿车源属性字段来让ChatGPT写作，例如向ChatGPT发送提示「请以下面这些关键词写一篇400字的文章」，最终ChatGPT也能生成可读性较好的结果。我们都知道ChatGPT在一些常识性问题上会犯错误，可能会生成一些错误内容，而我们是基于优质车源帖子数据来生成文章，车源帖子首先是真的，最终生成的内容也是真实可用的。</p><p></p><p>在本地服务（黄页）业务下，客户（商家）需要定期下线旧帖子，重新发布新贴子，由于商家平时工作繁忙，往往没有时间发帖，因此平台提供了代客发帖服务，人工来帮助其发帖。2022年我们上线了AI自动发帖功能，节省了30+人力。AI自动发帖的大概逻辑是基于旧帖子正文内容和帖子用户评价，自动生成新帖标题和更新正文内容。在更新帖子正文内容这里，需要筛选出用户优质评价，并将评价提炼成一小段文字，再插入到帖子正文头部，以\"口碑亮点\"模块来展示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/26/266d0ce882227337738bbc73392d9294.jpeg\" /></p><p>帖子正文口碑亮点</p><p></p><p>我们的原始方案是使用微调的BERT模型来识别评论正负向情感，先挑出正向评论，然后基于抽取式方法生成最终的评论短语。我们将ChatGPT应用于该场景，首先使用ChatGPT来识别评论正负向情感，然后继续用ChatGPT将正向评论润色成最终的\"口碑亮点\"，取得了很好的效果。</p><p></p><p>评论正负向情感识别是一个常见的NLP任务，我们直接向ChatGPT发送Prompt提示「对下面的评论进行分类，类别有正向、其他，[商家很专业，很有耐心]属于什么类别？」，这里没有给其提供任何先验知识和例子，即Zero-Shot，它也能获得不错的效果，比BERT微调模型略低，我们继续实验Few-Shot，告诉其分类标准并给予了一些样例，如下图所示，识别效果明显提升，超过BERT微调模型，可见ChatGPT十分强大。在前文GPT API章节我们有讲到2022年11月同期发布的text-davinci-003模型和ChatGPT模型在部分NLP任务上可能差异不大，这里我们也进行了验证，在评论情感识别任务上二者差异不大。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/45/45530dbb1f3537c128f5e30518824ac7.png\" /></p><p>ChatGPT在评论正负向情感识别任务上的效果</p><p><img src=\"https://static001.geekbang.org/infoq/02/026b876c82d0c6e00fbcb8d67e7ba494.png\" /></p><p>ChatGPT Few-Shot</p><p></p><p>此外，在SEO场景我们也进行了探索，使用ChatGPT生成一些SEO场景需要的内容，尽管ChatGPT会生成一些事实性错误的内容，但通过优化Prompt可以使得生成的结果基本可用，并结合人工审核、人工改写，最终能够得到符合SEO需求的内容。</p><p></p><p></p><h3>智能客服：</h3><p></p><p></p><p>当前网上很多人都说ChatGPT可以直接拿来做智能客服，能够让一些客服或者销售人员下岗，很多人都信以为真，实际并非如此。智能客服是当下发展非常成熟的产品，各大企业都有应用，能够提高客服人效，<a href=\"https://mp.weixin.qq.com/s?__biz=MzU1NTMyOTI4Mw==&amp;mid=2247485955&amp;idx=1&amp;sn=b35805cfc98f50f3c9b7dc629a90c2ed&amp;scene=21#wechat_redirect\">58同城是2017年开始打造的智能客服</a>\"。这是智能客服的基本原理：企业维护了一套业务问答知识库，即一些业务问题和答案的集合，若用户在使用APP时遇到相关问题，他会在智能客服聊天窗口里输入问题进行咨询，机器会自动理解用户输入的问题，从问答知识库中找到那条和用户输入语义相同的问题，即文本匹配或文本分类，然后把该问题的答案返回给用户。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c2/c212613f8bd543d81cf172c10f27f40b.png\" /></p><p>智能客服基本原理</p><p></p><p>智能客服的核心是构建问答知识库和文本匹配，问答知识库里的问题是线上用户遇到的真实业务问题，答案是客服运营人员人工整理的答案，而文本匹配是一项传统的NLP技术。很明显，客服场景的问答知识库是企业独有的，ChatGPT没有学习过这些数据，对于用户咨询它不可能给出正确答案。部分业务方也给我们提过使用ChatGPT代替现有智能客服系统的想法，我们抽取了一定量线上真实用户的输入，并交给ChatGPT回答，最终证实了在业务问题上它会一本正经的\"胡说八道\"。当然，如果我们将问答知识库数据全部提交给ChatGPT做微调（Fine-tune），它也能回答得较好，但目前ChatGPT还不提供微调功能，GPT-3 API提供了微调功能。</p><p></p><p>尽管ChatGPT不能直接拿来做智能客服，但是我们可以用它来做智能客服中的文本匹配任务，我们在近期接入的一个新业务场景下实验了ChatGPT，可以类似下图这样向ChatGPT发送Prompt，Zero-Shot的效果较差，若在Prompt里给每个标准问题增加少量扩展问法就能有较好的效果提升，但要超过自研模型还需在Prompt上做更多优化工作。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c8/c8587b209129768d40a1dc5bfb2b2943.png\" /></p><p>ChatGPT文本匹配效果</p><p><img src=\"https://static001.geekbang.org/infoq/4e/4ef8686f164fff8c2521d81184f8f9e1.png\" /></p><p>用ChatGPT做文本匹配Prompt示例</p><p></p><p>智能客服的问答知识库是持续更新的，因为随着产品功能的持续更新升级，线上用户会遇到新的操作问题，这些新问题会被挖掘出来加入到问答知识库中，并通过持续的数据标注来积累这些新问题的扩展问法。往往新问题上线初期扩展问法较少，模型对新问题识别效果较差，这里也可以在新问题产生时直接使用ChatGPT来为每个新问题生成若干扩展问法（数据增强），再加入模型训练，使得模型对新问题有较好的识别效果。我们在一个新接入的场景下也进行了实验对比，针对新增的六条新问题，使用ChatGPT为每条新问题生成数十条扩展问法，然后训练模型，这相比不做数据增强的模型效果有明显提升。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b8/b8c860a6cd6c132eb8d322c2c4db8ca3.png\" /></p><p>自研模型 + ChatGPT数据增强后效果</p><p></p><p>在招聘业务赶集直招「微聊反向邀约」场景，在C端用户和B端企业微聊沟通时，我们应用了智能客服留资机器人，具体介绍可参见《<a href=\"http://mp.weixin.qq.com/s?__biz=MzA5OTQ1MDQ4Mw==&amp;mid=2456205375&amp;idx=1&amp;sn=705e8f440489e5b175fae84f9935daf9&amp;chksm=87103323b067ba3599d904d4174f7c29dcd4cb32ecda95c7e81a668f18600e0dae6c59cda401&amp;scene=21#wechat_redirect\">一份AI中台产品应用手册</a>\"》，当C端用户向B端企业发起微聊沟通时，若B端企业不在线，则由机器人和C端用户对话，在对话结束后若识别到用户有高求职意向，则调用智能双呼能力（可参见《<a href=\"http://mp.weixin.qq.com/s?__biz=MzA5OTQ1MDQ4Mw==&amp;mid=2456205272&amp;idx=1&amp;sn=59a583ce733baa3667b51813b9f297d6&amp;chksm=87103cc4b067b5d23faad453350aa328f3ad1b239e15070fdb7f85f67c072bc1d23a860b90b1&amp;scene=21#wechat_redirect\">智能语音机器人四种人机协同能力介绍</a>\"》）提醒B端企业，B端企业接听后可以一键直连C端用户，从而双方可以直接电话沟通。这里机器人需要基于微聊对话记录识别用户求职意向，我们也实验了ChatGPT，通过优化Prompt，ChatGPT在F1-Score上超过了自研模型。但是这是一个重准确率的业务场景，因为需要保证B端企业连接的用户尽量是实际求职者，但如何通过调整Prompt来控制ChatGPT的准确率和召回率，目前还没找到行之有效的方法，而自研模型要做到这一点很简单。</p><p><img src=\"https://static001.geekbang.org/infoq/c4/c4e23660684e9aa401d5bd58b8a55f23.png\" /></p><p>用ChatGPT做对话意图识别</p><p></p><h3>智能外呼：</h3><p></p><p></p><p>智能外呼是人机实时语音对话场景，电话沟通语音会被语音识别引擎实时转写成文本，然后交给NLP模型进行语义理解，本质上和微聊文本对话没有差别，也会执行上述文本分类、文本匹配、对话意图识别任务，ChatGPT应用类似。</p><p></p><p>人机语音对话相对微聊文本对话来讲延时更敏感，即需要NLP模型快速返回识别结果，耗时一般要求在数十到上百毫秒之间，因为人和机器在实时对话过程中若机器反应慢，例如数秒才响应，人会明显感觉到停顿，用户体验差，可能会直接挂断电话，影响转化效果，而在一些微聊智能客服场景下，为了让用户感觉到背后不是机器人，会故意让机器人回答慢一点，在程序中做一些延时回复操作。当前ChatGPT和GPT API的推理延时并不低，平均耗时在数秒级别，直接应用ChatGPT来做人机语音对话中的NLP模块不可取。</p><p></p><p>我们使用ChatGPT离线实验了近期上线的一个语音对话场景下的槽位提取（实体抽取），识别对话内容中的地点和服务类别槽位，这里直接使用Zero-Shot，向ChatGPT发送提示「请抽取这段话中的省、城市、区县和服务类别」，从实验结果看ChatGPT表现不错。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1d/1d0520ebb3ea3510a5d3c34a28e9b396.png\" /></p><p>ChatGPT槽位提取效果</p><p></p><h2>五、个人思考</h2><p></p><p></p><p>ChatGPT在一个大模型里可以完成众多任务，而且效果都很不错，前所未见，令人惊叹。毫无疑问，ChatGPT能够在各类岗位上辅助人工，提升人效，但能否完全替代某类岗位，还需时间验证，以NLP工程师岗位为例，企业若想使用ChatGPT代替NLP工程师，至少需要考虑以下几点：</p><p></p><p>识别效果是否可控。NLP场景一般都会有准确率、召回率的侧重，需要通过调整模型来控制这两项指标，自研模型很容易做到，若使用ChatGPT，则只能通过调整Prompt来控制，如何编写Prompt来控制准确率、召回率，目前还没看到行之有效的方法。推理性能是否符合应用需求。大模型的推理性能与硬件资源、模型加速手段相关，性能和投入成正比，当前ChatGPT推理较慢，无法满足一些延时要求高的应用场景，例如智能外呼，未来这里可能需要和企业定制化。值得一提的是，当前NewBing体验版的搜索也非常缓慢，用户体验不佳，这也是微软和OpenAI需要解决的痛点。ROI的精确衡量。企业需要评估某个应用场景下使用ChatGPT API的花费是否比人力成本低，即将发布的ChatGPT API可能也和GPT-3 API一样按照token收费，它包括了输入和输出的token，真正接入使用时需要对Prompt和生成结果做精细化控制，编写Prompt也是一项挑战。</p><p></p><p>当前，ChatGPT在国内还不能直接访问，未来就算对国内开放，但各大企业与其合作会很敏感，国内企业的大量数据若流入ChatGPT会有很大风险。中国很有必要做出自己的ChatGPT，当下国内大厂和一些创业公司正在努力，也许在不久的将来，国内ChatGPT解决上述问题后，真的不再需要那么多NLP算法工程师。</p><p></p><p>参考文献：</p><p></p><p>[1] GPT1：Improving Language Understanding by Generative Pre-Training. https://openai.com/blog/language-unsupervised/ 2018.6</p><p>[2] BERT：Pre-training of Deep Bidirectional Transformers for Language Understanding. 2018.10</p><p>[3] GPT2：Language Models are Unsupervised Multitask Learners.</p><p>https://openai.com/blog/better-language-models/&nbsp;2019.2</p><p>[4] GPT3：Language Models are Few-Shot Learners. https://arxiv.org/abs/2005.14165 2020.5</p><p>[5] GPT3 API：https://openai.com/blog/openai-api/ 2020.6</p><p>[6] Fine-Tuning Language Models from Human Preferences.&nbsp;https://arxiv.org/abs/1909.08593&nbsp;2019.9</p><p>[7] Learning to summarize from human feedback. &nbsp;https://openai.com/blog/learning-to-summarize-with-human-feedback/&nbsp;2020.9</p><p>[8] InstructGPT：Training language models to follow instructions with human feedback. https://arxiv.org/abs/2203.02155 2022.3</p><p>[9] ChatGPT: Optimizing Language Models for Dialogue.&nbsp;https://openai.com/blog/chatgpt/&nbsp;2022.11.30</p><p>[10] How does GPT Obtain its Ability? Tracing Emergent Abilities of Language Models to their Sources. https://yaofu.notion.site/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1 符尧等. 2022.12.11. 中文版：拆解追溯 GPT-3.5 各项能力的起源. 2022.12.18. https://yaofu.notion.site/GPT-3-5-360081d91ec245f29029d37b54573756</p><p>[11] Deep reinforcement learning from human preferences.&nbsp;https://arxiv.org/abs/1706.03741&nbsp;2017.6</p><p>[12] Microsoft announces new supercomputer, lays out vision for future AI work.&nbsp;https://news.microsoft.com/source/features/ai/openai-azure-supercomputer/&nbsp;2020.5.19</p><p>[13] Efficient Large Scale Language Model Training on GPU Clusters.&nbsp;https://arxiv.org/abs/2104.04473&nbsp;2021.4</p><p>[14] OpenAI API.&nbsp;https://openai.com/api</p>",
    "publish_time": "2023-03-14 10:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]