[
  {
    "title": "构建可持续架构的三大秘籍",
    "url": "https://www.infoq.cn/article/2U4xKaxTl3ftG4WI4jEs",
    "summary": "<p>软件工程师必须在已经做出架构决策的情况下才能进行开发。我们可以在新的微服务中使用Python而不是Java吗？在开发新的前端库时，我们可以使用另一个捆绑器吗？我是否应该与经理或其他团队在代码库结构问题上达成一致？</p><p></p><p>在设计REST API时应该使用snake_case还是camelCase来命名API？公司需要建立一个明确的框架来做出这些决策、需要谁参与，以及在哪里可以找到关于已经做出的决策的信息。</p><p></p><p>制定一个正确的框架非常重要，因为它将定义不同的团队将拥有多大程度的自由和自主权。这应该与公司在特定阶段试图建立的业务需求和公司文化相一致。</p><p></p><p>这可能会影响人们如何看待不同的领导角色、经理和个人贡献者在技术决策中的作用，以及不同职业级别的赋能水平。不同的公司需要根据其组织边界、成熟度和需求选择不同的负责人和不同程度的团队自主权，但框架应该提供非常相似的构建块。</p><p></p><p>在本文中，我将基于最近在不同规模的组织中工作的经验分享用来制定架构决策的框架应该提供的关键构建块。这些构建块包括内部技术雷达、技术标准和架构决策记录（ADR）。</p><p></p><p></p><h1>建立自己的技术雷达</h1><p></p><p></p><p>有些人可能知道Thoughtworks，他们建立了自己的<a href=\"https://www.thoughtworks.com/radar?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODQ0ODY0OTcsImZpbGVHVUlEIjoicVV2TUFPSUl3c0V6ck1sNSIsImlhdCI6MTY4NDQ4NjE5NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.-DRomq4lUleBIOWsVGq38sCGHfirSIlBRdrIMxe_lZc\">技术雷达</a>\"。Thoughtworks与行业内的客户一起捕获和发布他们所看到的东西。</p><p></p><p>类似地，你也可以<a href=\"https://www.thoughtworks.com/radar/byor?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODQ0ODY0OTcsImZpbGVHVUlEIjoicVV2TUFPSUl3c0V6ck1sNSIsImlhdCI6MTY4NDQ4NjE5NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.-DRomq4lUleBIOWsVGq38sCGHfirSIlBRdrIMxe_lZc\">建立自己的技术雷达</a>\"，用于捕获公司使用或计划使用的不同的技术、工具和方法的成熟度。技术雷达是公司当前正在使用和期望使用的技术栈的可视化表示。</p><p></p><p>你需要定义不同的阶段——评估、试验、采用和保留，以及技术应该如何经历这些阶段的过程。</p><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/65/65fae12cb5aa90efcc163670247ed4d7.webp\" /></p><p></p><p><a href=\"https://radar.thoughtworks.com/?sheetId=https%3A%2F%2Fraw.githubusercontent.com%2Fhey-car%2Ftech-radar%2Fmaster%2Ftech-radar.csv&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODQ0ODY0OTcsImZpbGVHVUlEIjoicVV2TUFPSUl3c0V6ck1sNSIsImlhdCI6MTY4NDQ4NjE5NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.-DRomq4lUleBIOWsVGq38sCGHfirSIlBRdrIMxe_lZc\">heycar的技术雷达示例</a>\"</p><p></p><p>在heycar，我们定义了以下这些阶段。首先，新技术处于评估（Assess）阶段，也就是说它们正在被评估。我们在评估阶段进行概念验证（PoC），并生成在我们的环境中使用这些技术的优缺点清单。然后，我们与各自的内部团队或可能与之发生交互的团队讨论结果。如果论证清单和概念验证足够令人信服，那么下一步就进入可控的试验期。在试验期，新技术只被用于生产环境的单一用例。如果这一步成功，我们就宣布新技术已被采用，并为其他团队的进一步使用打开绿灯。如果新技术取代了以前使用的技术，可能需要发出信号。于是我们定义了“保留（Hold）”阶段——对于那么不打算再使用并且有了替代方案的技术。</p><p></p><p>技术雷达可以帮助团队了解技术前景，并就使用哪些技术做出明智的决策。如果你保持技术雷达是最新的，公司里的每一个人就都会知道正在使用的技术的最新状态及其对业务的影响。</p><p></p><p></p><h1>引入内部技术标准</h1><p></p><p></p><p>第二个部分是引入技术标准。技术雷达捕获技术、平台、工具、语言和框架，以及它们在整个组织中的采用程度，但这些可能还无法满足所有的需求。为系统的不同部分建立一致的实践会有所裨益。例如，你可能希望所有的日志都使用相同的格式，并包含相同的信息。或者，如果你正在使用REST API，可能想要一些关于API设计和使用的约定，比如使用什么标头或如何命名。此外，如果你正在使用多种类似的技术，那么为何时该使用何种技术提供指导可能会很有帮助。技术标准定义了在公司内部选择和使用技术的规则。它们确保了一致性，降低以次优方式采用新技术所带来的风险，并在整个组织范围内推动保持一致性。</p><p></p><p>应该由谁来负责制定和维护这些标准？技术标准应由相关领域的跨职能专家团队负责制定和维护。技术标准需要进行定期的评审，并根据需要进行更新，以跟上技术领域的变化。应该鼓励团队遵循这些标准，并就其有效性提供反馈。格式可以不同，但最好可以提供详细的解释和代码示例。它可以是正式的，并遵循一些格式（如<a href=\"https://www.rfc-editor.org/rfc/rfc7990.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODQ0ODY0OTcsImZpbGVHVUlEIjoicVV2TUFPSUl3c0V6ck1sNSIsImlhdCI6MTY4NDQ4NjE5NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.-DRomq4lUleBIOWsVGq38sCGHfirSIlBRdrIMxe_lZc\">RFC格式框架</a>\"），也可以是随意的，这取决于具体的偏好和工程文化。<a href=\"http://opensource.zalando.com/restful-api-guidelines/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODQ0ODY0OTcsImZpbGVHVUlEIjoicVV2TUFPSUl3c0V6ck1sNSIsImlhdCI6MTY4NDQ4NjE5NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.-DRomq4lUleBIOWsVGq38sCGHfirSIlBRdrIMxe_lZc\">Zalando的RESTful API和事件指南</a>\"是共享内部技术标准的一个很好的例子。除了API标准之外，你可能还想引入日志记录和监控、部署和QA标准。</p><p></p><p>你可以基于内部标准建立质量检验关卡，例如测试覆盖率检查、检查命名约定或格式的集成代码linter、验证架构或代码库结构的适应性函数 （Fitness Functions）。自动检查、在新人加入时使用标准、代码评审或结对编程的组合将有助于确保标准被遵循并为我们带来价值。除了检查是否符合标准，这也是一个讨论平台工程价值的机会。不要只是简单地告诉人们他们做错了什么，而要让他们在一开始就做对。</p><p></p><p></p><h1>架构决策记录（ADR）实践</h1><p></p><p></p><p>架构决策框架的第三个构建块是创建ADR或<a href=\"https://cwiki.apache.org/confluence/display/GEODE/Lightweight+RFC+Process?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODQ0ODY0OTcsImZpbGVHVUlEIjoicVV2TUFPSUl3c0V6ck1sNSIsImlhdCI6MTY4NDQ4NjE5NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.-DRomq4lUleBIOWsVGq38sCGHfirSIlBRdrIMxe_lZc\">轻量级RFC</a>\"。ADR是记录架构决策及其推理过程的一种方式。它们提供了重要决策的历史记录，并帮助团队理解为什么选择了特定的方法。ADR应该由负责做出架构决策的团队创建。它们应该包括正在解决什么问题、有哪些替代方案、做出的决策以及背后的原因等信息。它们是不可变的文档。在重新审视给定的决策时，通常需要创建一个新的文档。ADR实践正变得越来越流行，因此<a href=\"https://docs.aws.amazon.com/prescriptive-guidance/latest/architectural-decision-records/welcome.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODQ0ODY0OTcsImZpbGVHVUlEIjoicVV2TUFPSUl3c0V6ck1sNSIsImlhdCI6MTY4NDQ4NjE5NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.-DRomq4lUleBIOWsVGq38sCGHfirSIlBRdrIMxe_lZc\">AWS</a>\"和<a href=\"https://cloud.google.com/architecture/architecture-decision-records?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODQ0ODY0OTcsImZpbGVHVUlEIjoicVV2TUFPSUl3c0V6ck1sNSIsImlhdCI6MTY4NDQ4NjE5NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.-DRomq4lUleBIOWsVGq38sCGHfirSIlBRdrIMxe_lZc\">GCP</a>\"等主要云供应商已将其添加到各自的文档中。</p><p></p><p>技术雷达和技术标准为技术决策提供指导和预期边界，ADR则捕获推理过程并记录特定的一次性决策——创建新服务或包、引入新技术或主要架构变更的原因。ADR通常被保存在一个集中式的存储库或文档工具中，所有相关团队都可以访问它们。它们还可以帮助新团队成员快速了解整体架构和重大决策背后的原因。</p><p></p><p>ADR评审有多种目的——评审决策和分享知识。每一个受决策影响的人都会参与到ADR评审中，但如果可以与更多人分享，它还有助于提高整个组织的整体架构意识。此外，ADR可用于在内部收集更多的反馈。有时候，一些工程师可能在过去解决过类似的问题，只是现在没有在做相关的工作。</p><p></p><p>与前两个构建块一样，每个组织在最终确定ADR时的最终发言权以及哪些决策被认为足够重要而需要使用ADR的过程都是不同的。为了避免重复，你可以在做出新的主要系统变更时使用ADR来就特定的设计决策达成一致，而在决定使用何种编程语言、工具和实践时则采用技术雷达和技术标准。有了内部技术雷达和技术标准，采用ADR就应该是一个简单而直接的实践，因为最实质性的技术选择和原则已经达成了一致。</p><p></p><p></p><h1>结论</h1><p></p><p></p><p>技术雷达、技术标准和ADR共同构成了一种架构决策框架，这个框架为制定架构决策提供了清晰且一致的方法，降低了采用新技术的风险，并提供了决策历史记录。通过建立架构决策框架，团队可以确保他们的技术栈与他们的业务目标保持一致，并且他们的团队拥有做出明智决策所需的信息和指南。</p><p></p><p>团队所拥有的自由度，以及改变技术雷达、技术标准或ADR的过程，将塑造组织的工程文化。一些组织的目标是实现彻底的团队自治，而一些组织的目标则是保持高度的一致性。例如，一种可能的方法是让高级技术人员参与技术雷达和标准的制定，为进一步的技术决策提供指导，并将ADR留给负责实现软件功能的团队。你可以采用这种架构决策框架，并根据公司的需要做出调整。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/framework-architectural-decisions/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODQ0ODY0OTcsImZpbGVHVUlEIjoicVV2TUFPSUl3c0V6ck1sNSIsImlhdCI6MTY4NDQ4NjE5NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.-DRomq4lUleBIOWsVGq38sCGHfirSIlBRdrIMxe_lZc\">https://www.infoq.com/articles/framework-architectural-decisions/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/RcpX4N8e6DUHIaG4eNTM\">软件技术栈商品化：应用优先的云服务如何改变游戏规则</a>\"</p><p><a href=\"https://www.infoq.cn/article/XYlKxH5f3GjBflH31z9h\">ThoughtWorks CTO：2025 年之前，我们会看到架构的演进，但不会看到革命</a>\"</p><p><a href=\"https://www.infoq.cn/article/T4PEt15NU2JUk1VWhTMv\">避免成为“象牙塔”架构师：架构师和组织之间的关系</a>\"</p>",
    "publish_time": "2023-05-25 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "德勤、东亚银行、南京钢铁、宁德核电讲述数字人才技能重塑之路 | DTDS预约报名",
    "url": "https://www.infoq.cn/article/AMK0k7K4HMK9JQVPfNRD",
    "summary": "<p>每一次时代变迁，都伴随着社会劳动力结构和人才技能的颠覆。</p><p></p><p>随着数字化时代的到来，企业需要优化其人才技能结构，以适应不断变化的市场需求。企业从迈开数字化转型的第一步开始，就已经踏入了无人区。过去的经验不再适用于当下，只有不断地探索新的商业模式和运营模式，重新定义业务流程和管理方式，建立强大的数字化能力，才能走向数字化未来。</p><p></p><p>企业的数字化探索需要以人才技能重构为起点和支撑。如果企业的能力无法满足外界需求，业务只能缓慢增长，受限于现有的思维视野，创新能量也将难以在组织内形成，企业必将错失发展机遇。拥有一支兼具数字化素养、跨领域技能和创新精神的人才队伍，才能够在数字化竞争中立于不败之地。</p><p></p><p>数字化时代正在拓宽岗位的边界，未来人才发展的趋势逐渐将“岗位”导向转变为以“技能”为核心。因此，岗位即将走向终结，技能将替代岗位成为员工和工作的连接点。然而，随着技术发展的日新月异，技能的半衰期正在缩短，这意味着弥合技能差距的时间将显著变长。当前，世界正面临着重新培养员工技能的紧迫挑战。</p><p></p><p>在数字化时代，企业需要不断更新自己的人才战略，以适应快速变化的市场需求和技术发展，赢得数字化时代的竞争优势。以“人才为本，数智蝶变”为主题的 DTDS 全球数字人才发展线上峰会将于 5 月 30 日举行，届时来自德勤、东亚银行、南京钢铁、宁德核电等处于行业领先地位的数字化企业，将分享他们如何通过人才技能重塑，推动数字化转型进程，实现企业发展与人才发展的良性循环。</p><p></p><p>极客时间企业版将在本次 DTDS 峰会上发布AI未来教育学习产品，并推出与培训杂志合作《中国企业数字人才发展白皮书》完整版解读，观看直播的用户都可获得原版白皮书。</p><p></p><p>扫描下方海报上的二维码或<a href=\"https://app.jingsocial.com/microFrontend/leadGeneration/jsf-leads/list/webinar/P8KAMuAA7DmVHnBydPuGL8/a7oymLNUReJh4EuJEhkrFV\">点击链接</a>\"，即可报名参与精彩环节↓↓</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9b/9b1e005b008cb65e11db83141efa7630.png\" /></p><p></p>",
    "publish_time": "2023-05-25 10:32:02",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "无声的平台革命：eBPF 是如何从根本上改造云原生平台的",
    "url": "https://www.infoq.cn/article/R7bTrXMAvI6JsmVZ6QaY",
    "summary": "<p></p><h3>摘要</h3><p></p><p>eBPF 已在云原生生态环境中众多项目和产品中的底层使用，通过实现丰富的云原生上下文，eBPF 使内核具备进入云原生条件。eBPF 所创造的悄无声息的基础设施运动，使其随处可见，且实现了许多先前不可能实现的新用例。&nbsp;eBPF 已经在互联网规模的生产环境与生产验证中，于全球数百万服务器和设备上全天候运行超过五年。eBPF 在操作系统层实现了新的抽象，为平台团队提供了云原生网络、安全和可观测性的高级能力，以安全地定制操作系统，满足其工作负载的需求。扩展操作系统内核是一个艰难而漫长的过程，应用一个变化可能需要数年时间才能完成。但现在随着 eBPF 的应用，这种开发者-消费者的反馈循环几乎是即时可用的，变化可以优雅地推送到生产中，而不必重新启动或改变应用程序或其配置。未来十年的基础设施软件将由平台工程师来定义，他们可以使用 eBPF 和基于 eBPF 的项目来为更高层次的平台创建合适的抽象概念。以 eBPF 为驱动的 Cilium 等开源项目，在网络、可观测性和安全性上，已经开创并将这种基础设施运动带入到了 Kubernetes 和云原生中。</p><p>&nbsp;</p><p></p><p></p><p>Kubernetes 和云原生的出现至今已经将近十年了，在这段时间内，我们见证了软件基础设计领域的项目与创新的寒武纪大爆发。在实验与深夜努力中，我们认识到了生产中大规模运行这些系统时，有什么是可行的，又有什么是不可行的。在这些基础项目和关键经验的帮助下，平台团队开始将创新带向了堆栈，但堆栈能跟得上他们的速度吗？</p><p>&nbsp;</p><p>随着应用设计开始向以 API 为驱动的微服务转变，以及基于 Kubernetes 的平台工程、网络、安全的兴起，Kubernetes 对传统网络和安全模式的打破，让团队追赶的步伐变得吃力。上云的转变至少让我们见证了相似技术的海量变化，但 Linux 将“云上”打包，开启世上最为流行的服务，则是完全改写了数据中心基础设施和开发者工作流程的规则。我们如今所处的境况也是类似，云原生领域基础设施的出现如雨后春笋，不是人人都清楚这股潮流前进的方向，看看 <a href=\"https://landscape.cncf.io/\">CNCF 的情况</a>\"就知道了；我们的服务通过 Linux 内核上的分布式系统与彼此通信，但其中许多功能和子系统在设计之初就没有考虑到云原生。</p><p>&nbsp;</p><p>基础设施软件的未来十年将由平台工程师来定义，他们将利用这些基础设施构件，正确地为更为高层的平台搭建抽象。建筑工程师利用水电、建筑材料搭建供人类使用的建筑，而平台工程师则利用硬件和软件基础设施，搭建可用开发者安全可靠地部署软件，在大规模下仍能以最小劳动量频繁且可预测地进行高影响力改动的平台。对于云原生年代的下一步发展，平台工程师团队必要能提供、连接且可观察的可扩展、动态、可用且高性能的环境，让开发者能全心全意集中于业务代码逻辑。许多支撑这类工作负载的 Linux 内核构件都已经有十多年的历史了，它们需要新的抽象才能跟得上云原生世界的需求。但好消息是，这些构件已经能满足上诉的诉求，并也已经在最大规模的生产环境中经过了多年的验证。</p><p>&nbsp;</p><p><a href=\"https://ebpf.io/\">eBPF</a>\" 通过允许开发者们以安全、高性能、可扩展的方式动态编程内核，从而创建了云原生抽象和云原生世界所需的新构件。在不修改内核源码或加载内核模块的前提下，eBPF 可安全且高效地扩展云原生和内核的其他功能，将内核本体从单体应用转换至具备丰富云原生环境的多模块化架构，从而解锁了创新。这些能力允许我们安全地抽象 <a href=\"https://kernel.org/\">Linux 内核</a>\"，并以紧密的反馈循环对这一层进行迭代和创新，从而准备好进入云原生的世界。随着 Linux 内核新能力的加入，平台团队已经具备进入云原生世界后的第二步，他们或许也在不知不觉中在项目里采用了 eBPF。这四一场无声的 eBPF 革命，重塑着平台与云原生世界的形象，而在本文中，我们将讲述它的故事。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>出于兴趣和利润的数据包过滤扩展</h2><p></p><p>自从<a href=\"https://www.tcpdump.org/papers/bpf-usenix93.pdf\">1992</a>\"年的 BSD 数据包过滤（BPF）起，eBPF 这项技术已经有了数十年了历史。在当时，Van Jacobson 试图对网络问题进行诊断，但当年现有的网络过滤都过于缓慢，为此，他的实验室设计并创建了 libpcap、tcpdump。以及 BPF 为所需功能提供后端。BPF 的设计使其能快速、高效，且易于验证地在内核中运行，但其功能仅仅包含对 IP 地址和端口号等简单数据包的头字段进行只读过滤。随着时间的推移和网络技术的发展，“经典”BPF（cBPF）的局限性更为突出，具体来说，它的无状态性导致其在复杂数据包操作上束手束脚，对开发者而言也是难于扩展。</p><p>&nbsp;</p><p>尽管限制重重，这种围绕 cBPF 的高层级概念仍是为将来的创新提供了灵感和平台，即通过一个最小可验证指令集允许内核证明用户所提的应用程序安全性，并能够在内核中运行这些程序。在2014年，一项新技术<a href=\"https://lore.kernel.org/netdev/1396029506-16776-1-git-send-email-dborkman@redhat.com/\">加入</a>\" Linux 内核，极大地扩展了 BPF（“eBPF”因此得名）的指令集，为我们带来了一个更为灵活且更为强大的版本。在最初，取代内核中的 cBPF 引擎并不是目标，因为 eBPF 是通用的概念，可被用于网络之外的许多地方。但在当时，将这项新技术融入主流内核的确是一条可行的道路，这也是 <a href=\"https://lore.kernel.org/lkml/alpine.LFD.2.00.1001251002430.3574@localhost.localdomain/\">Linus Torvalds 这段话</a>\"的背景：</p><p>&nbsp;</p><p></p><blockquote>和疯子们一起工作对我来说不是问题，他们只需要用不那么疯狂的论点短小精悍地向我推销他们的疯狂想法。在我问他们要杀手级功能时，我希望他们能说服我这些推销的东西首先要对主流来说的确有用。换句话说，任何疯狂的新功能都应该被牢牢包裹在一个“特洛伊木马”中，第一眼看上去至少要明显觉得不错。</blockquote><p></p><p>&nbsp;</p><p>简单来说，这段话是对 Linux 内核开发模式中“根本”机制的描述，与 eBPF 融入 Linux 的方式不谋而合。为实现增量形式的优化，第一步自然是取代内核中 cBPF 的基础设施以提高其i性能，随后再一步步地在其基础上暴露并改进全新的 eBPF 技术。自此之后，早期的 eBPF 发展有了两条并行前进的路线，即网络与跟踪。以 eBPF 为中心的每一个被合并至内核的新功能都解决了这类用例下的切实生产需求，这一需求至今仍然适用。而 <a href=\"https://github.com/iovisor/bcc\">bcc</a>\"、<a href=\"https://github.com/iovisor/bpftrace\">bpftrace</a>\",、<a href=\"https://github.com/cilium/cilium\">Cilium</a>\"&nbsp;等项目则是早在 eBPF 生态系统搭建成功并成为主流之前，变开始协助塑造了 eBPF 基础设施的核心构件。如今的 eBPF 是一项通用技术，可在内核等特权环境中运行沙盒程序，这与“BSD”、“数据包”，或“过滤器”已经没有什么共同点了，如今的 eBPF 只是个缩写的，代指操作系统内核根据用户需求安全地扩展和定制的技术革命。</p><p>&nbsp;</p><p>具备运行复杂但安全程序能力的 eBPF 已经是一个极为强大的平台，可用堆栈更为高层的云原生环境丰富 Linux 内核，从而执行更优的策略决策、更有效地处理数据、让操作与其源头更为接近，也更为迅速地进行迭代和创新。简言之，我们将不再是修补、重构，或是推出新内核变动，而是削减基础设施工程师们的反馈循环，让 eBPF 程序可以在无需重启服务或中断数据处理的情况下进行即时更新。eBPF 的多功能性也使其在网络之外的其他领域也有应用，在安全、可观察性、跟踪等方面，eBPF 可被用于实时监测并分析系统事件。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>加速中的内核实验与进化</h2><p></p><p>从 cBPF 向 eBPF 不仅改变了我们的现状，也影响了我们即将构建的。从简单的数据包过滤发展到通用沙盒运行时，eBPF 在网络、可观察性、安全性、跟踪和剖析方面开创了许多新用例。作为 Linux 内核中的通过计算引擎，eBPF 允许我们对内核中发生的任何事情挂钩、观察，并采取行动，与网页浏览器中的插件很是类似。其中的一些关键功能设计允许了 eBPF 对创新能力的加速，从而为云原生世界创建性能更强的可定制系统。</p><p>&nbsp;</p><p>首先，eBPF 能够挂钩在内核中任何地方，并修改功能和自定义行为的是不需要对内核源码修改的，这意味着从用户提出需求到具体实施的时间将从以年为单位缩减为几天。由于 Linux 内核被数十亿的设备所广泛采用，导致上游的改动并不轻松。举例来说，假设我们想要一个观察应用的新方式，并能够从内核中提取指标，那么我们首先要做的是说服整个内核社群这个主意不错，并且是对所有运行 Linux 的人而言都不错，然后才能开始实施，并最终在几年后才能真正用得上这个功能。但随着 eBPF 的出现，我们能直接不重启机器就把这个观察功能写成代码，并在不影响其他人的前提下根据自身特定的工作负载需求对内核定制化。“eBPF 非常有用，其真正强大的点在于它能让人们自行定制化代码，除非特地要求否则这些代码是不会被启用的，”<a href=\"https://www.zdnet.com/article/linus-torvalds-talks-about-coming-back-to-work-on-linux/\">Linus Torvalds</a>\" 说。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3f/3fc8f67cf709d9fa309bdb4f249eb8ea.jpeg\" /></p><p></p><p>图配文：</p><p>应用程序开发者：我想要这个功能观察我的应用—— 哈喽，内核开发者！请把这个新功能加到 Linux 内核中！—— 好啊，给我一年时间让我说服整个社群这是个对所有人都好的功能一年后…… 完事了，主流内核已经可以支持了但我想把这个加到我的 Linux 版本里……五年后…… —— 好消息，我们的 Linux 版本已经可以提供带有你需要功能的内核了—— 但我的需求已经变了啊……</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e5/e5856205f7a256e699f255c35561d2ac.jpeg\" /></p><p></p><p>图配文：</p><p>应用开发者：我想要这个新功能观察我的应用</p><p>eBPF 开发者：行！内核现在没有这个功能，让我拿 eBPF 快速搞定</p><p>几天后……</p><p>这个是我们包含这个功能的 eBPF 项目版本，顺带一提，你还不用重启机器</p><p>&nbsp;</p><p>其次，由于对程序执行的安全性验证，eBPF 的开发者们可以在无需担忧内核崩溃或其他不稳定因素而继续进行创新。开发者和最终用户都能更自信地说自己送上生产的代码是稳定且可用的。对平台团队和 SRE 而言，使用 eBPF 也是安全地在生产环境中排障的关键因素。</p><p>&nbsp;</p><p>在应用程序准备投产时，eBPF 程序无需中断工作负载或重启节点便可添加至运行时，从而极大地减轻了平台更新维护所需的工作量，也减少了因版本更新出错导致工作负载中断的风险，这对大规模项目而言是个极大的好处。JIT 编译让 eBPF 程序具备了接近本地的执行速度，将上下文从用户空间转移到内核空间则允许用户跳过不需要或未使用的内核部分，进而提升其性能。然而，与用户空间中的完全跳过内核不同，eBPF 仍可利用全部的内核基础设施和构件而不用重新发明轮子。eBPF 可以挑选内核中的最优部分，结合自定义业务逻辑，从而解决特定问题。最后，运行时可修改内核行为以及跳过部分堆栈的能力，为开发者创建了一个极短的反馈循环，进而允许在网络堵塞控制和内核中进程调度等方面进行试验。</p><p>&nbsp;</p><p>eBPF 从经典的数据包过滤中成长，并在传统用例中进行的的大飞跃，解锁了内核中资源使用优化、添加自定义业务逻辑等许多新的可能性。eBPF 让我们可加速内核创新、创建新抽象、大幅提升性能，不仅缩短了在生产负载中新增功能的时间、风险、开销，甚至在某些情况下让不可能<a href=\"https://sessionize.com/download/syahfej~KQRCkDB3zgNUj5nhrujno9.pdf~Borkmann%20-%20eBPF%20innovations%20in%20cloud%20native.pdf\">成为可能</a>\"。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>数据包与日常：eBPF 在谷歌、Meta 和 Netflix 的应用</h2><p></p><p>在见识到 eBPF 如此之多的优点后，人们不禁要问了，eBPF 是否能在现实世界中实现？答案是肯定的。Meta 和谷歌坐拥部分世界上最大的数据中心、Netflix 占据互联网流量中的15%，这些公司都已在生产中使用 eBPF 多年，其结果不言而喻。</p><p>&nbsp;</p><p>Meta 是第一家将 eBPF 及其负载均衡项目&nbsp;<a href=\"https://engineering.fb.com/2018/05/22/open-source/open-sourcing-katran-a-scalable-network-load-balancer/\">Katran</a>\" 大规模投产的公司。自2017年起，所有进入 Meta 数据中心的包都是通过 eBPF 处理的，那可是不少猫猫图片呢。Meta 也将 eBPF 用于许多更高级的用例，如最近的调度器效率优化，可将<a href=\"https://lore.kernel.org/bpf/20230128001639.3510083-1-tj@kernel.org/\">吞吐量提升15%</a>\"，对该公司的规模而言这是个极大的提升和资源节约。谷歌也利用 eBPF 的<a href=\"https://www.youtube.com/watch?v=XFJw37Vwzcc&amp;t=38s\">运行时安全性和可观测性</a>\"处理其多数的数据中心流量，谷歌云的用户也是默认使用基于 eBPF 的数据平面进行联网。安卓操作系统支持了70%的移动设备，拥有遍布190多国家的25亿活跃用户，其中<a href=\"https://twitter.com/breakawaybilly/status/1640292221772595201\">几乎所有的网络数据包都接触过 eBPF</a>\"。<a href=\"https://www.brendangregg.com/Slides/reInvent2019_BPF_Performance_Analysis/\">Netflix 在很大程度上依赖于 eBPF 对其机群进行性能监控和分析</a>\"，而 Netflix 的工程师也创造了 bpftrace 等 eBPF 工具，绘制基于 eBPF 收集器的 On-CPU 和 Off-CPU 火焰图，为生产服务器排障的可见性方面带来了重大飞跃，</p><p>&nbsp;</p><p>eBPF 的有效性的显而易见的，在过去的十年中一直为“互联网规模”的公司带来大量收益，这些收益也应该转换为其他人所用。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>eBPF 的演变：让云原生速度和规模成为可能</h2><p></p><p>在云原生时代初期，GIFEE（谷歌为其他所有人提供的基础设施）是个流行词，但因为不是所有人都在用谷歌或谷歌的基础设施，这个词已经不再热门。人们希望能用简单的解决方案解决问题，这也是 eBPF 脱颖而出的原因。云原生环境是为“在现代且动态的环境中运行可扩展应用程序”，其中可扩展和动态是 eBPF 成为云原生革命所需的内核演变关键。</p><p>&nbsp;</p><p>Linux 内核一如既往地是云原生平台构建的基础，应用现在只需使用套接字作为数据源和接收器，网络作为通信总线。但云原生所需的是目前 Linux 内核中所无法提供的新抽象，cgroups（CPU、内存处理）、命名空间（net、mount、pid）、SELinux、seccomp、netfiler、netlink、AppArmor、auditd、perf 等等这些构件远比云原生这个名字的出现早诞生了数十年，这些构件不总是在一起使用，有些也不甚灵活，缺乏对 Pod 或任何更高级别服务抽象的认知，且完全依赖 iptables 联网。</p><p>&nbsp;</p><p>对于平台团队而言，为云原生环境提供的开发者工具，很可能还被囿于这个云原生环境无法被有效表达的盒子里。在未来，没有合适的工具平台团队也将无从下手。eBPF 则是允许工具从无到有地重建 Linux 内核中的抽象概念，而这些新抽象则会解锁下一次云原生创新的潮流，为云原生的革命奠定方向。</p><p>&nbsp;</p><p>举例来说，传统的网络下，数据包是由内核处理的，经过数层网络堆栈对所有数据包的检查后方能到达目的地。这一过程无疑会带来极高的开销和处理时长，对含有大量数据包的大规模云环境而言则更是如此。与之相反，eBPF 允许在内核中插入自定义代码，并在每个数据包经过网络堆栈时执行，带来了更为有效且更具针对性的网络流量处理，减少开销并提升性能。Cilium 的基准测试表明，从 iptables 切换至 eBPF&nbsp;<a href=\"https://cilium.io/blog/2018/04/17/why-is-the-kernel-community-replacing-iptables/\">提升了六倍吞吐量</a>\"，从基于 IPVS 的负载均衡器切换至以 eBPF 为驱动，不仅使 <a href=\"https://cilium.io/blog/2022/04/12/cilium-standalone-L4LB-XDP/\">Seznam.cz</a>\"&nbsp;的吞吐量增加了一倍，CPU 使用率也减少72倍。eBPF 不是在旧的抽象概念上缝缝补补，而是实现了巨大优化改进。</p><p>&nbsp;</p><p>与其前身不同，eBPF 的优化没有仅仅停留在网络层面。作为通用计算环境且可挂载到内核的任何位置，eBPF 的优化也扩展到了可观测性、安全等更多领域。“我认为云原生中安全性的未来将会是基于 eBPF 技术的，这是一种全新且强大的获取内核可见性的方式，过去想做到这一点是很难的，”云原生计算基金会的 CTO <a href=\"https://www.infoq.com/news/2023/02/cloudnative-securitycon-na-2023/\">Chris Aniszczyk</a>\" 说过，“在应用和基础设施监控的交界处，（eBPF）可以为团队提供一个检测、缓解和问题解决的，更为全面的方式。”</p><p>&nbsp;</p><p>eBPF 以云原生的速度和规模，让人们可以连接、观察并保护应用程序。“随着应用程序逐渐向着以云原生模式为驱动的基于 API 的服务集合，所有应用的安全性、可靠性、可观测性、性能都将从根本上依赖于以 eBPF 为驱动的全新连接层”，Isovalent 的联合创始人 Dan Wendlandt 说，“它将成为新云原生基础设施堆栈中的一个关键层。”</p><p>&nbsp;</p><p>eBPF 的革命正在改变云原生，而其中最好的部分已经得到了实现。</p><p></p><h2>&nbsp;</h2><p></p><p></p><h2>无声的 eBPF 革命已经成为平台的一部分了</h2><p></p><p>虽然 eBPF 的好处显而易见，但这种过于底层的形式意味着缺乏 Linux 内核开发经验的平台团队还需要一个更为友好的接口。这也是 eBPF 的魔力所在，eBPF 如今已经在多个运行云原生平台的工具中存在，或许你已经在不知不觉中用过它了。通过任何主流云供应商的 Kubernetes 集群启动，都是通过 Cilium 用到了 eBPF；通过 Pixie 的观测性实施或 Parca 的连续分析，也都用到了eBPF。</p><p>&nbsp;</p><p>eBPF 这股强有力的浪潮正在改变软件行业。Marc Andreessen 那句著名的“软件正在吞噬世界”已经被 <a href=\"https://blog.cloudflare.com/cloudflare-architecture-and-how-bpf-eats-the-world/\">Cloudflare</a>\" 玩笑似地改成了“eBPF 正在吞噬世界”。然而，eBPF 的成功不在于让所有开发者得知其存在，而是在当开发者们对更快的网络、毫不费力的监控及可观测性，以及更易使用且安全的解决方案之中。曾用过 eBPF 编程的开发者可能不足1%，但却能让其他99%的人受益。在各类项目和产品通过 Linux 内核上游代码或 Linux 内核模块编写，从而为开发者们提供大幅度的体验优化时，eBPF 将完全占领世界。我们已经踏上了这条通往现实的大路。</p><p>&nbsp;</p><p>eBPF 彻底改变了现在与将来基础设施平台的构建方式，实现了许多全新的云原生用例，这些用例在过去很难或根本不可能实现。平台工程师能在 eBPF 的帮助下安全且高效地扩展 Linux 内核能力，让快速创新成为可能。为适应云原生世界的需求，新的抽象和构件得以创建，开发人员也能更轻松地大规模部署软件。</p><p>&nbsp;</p><p>eBPF 的大规模投产已有半个世纪之久，也已被证明是一种安全、高性能、可扩展的动态内核编程方式。悄无声息的 eBPF 革命已经扎根，并在云原生生态系统及其他领域的产品和项目中得到应用。随着 eBPF 的出现，平台团队已做好进入云原生时代下一阶段的准备，他们可以配置、连接、观察并保护可扩展的、动态可用高性能环境，从而使开发人员将精力集中于业务逻辑的编程。</p><p>&nbsp;</p><p>查看英文原文：<a href=\"https://www.infoq.com/articles/ebpf-cloud-native-platforms/\">The Silent Platform Revolution: How eBPF Is Fundamentally Transforming Cloud-Native Platforms</a>\"</p><p></p><p>延伸阅读：</p><p><a href=\"https://www.infoq.cn/article/5xvC1Ic6BdLQYju6YWV0\">颠覆传统、应用大爆发，eBPF 何以改变 Linux？</a>\"</p><p><a href=\"https://www.infoq.cn/video/ApKtMSeNvMzDFkleWIUs\">eBPF 技术探索 SIG：eBPF在低版本内核如何跑起来？</a>\"</p><p><a href=\"https://www.infoq.cn/article/aTNxsFTCNjmUEByxxh49\">从安全视角看，革命性的 eBPF 是“天使”还是“恶魔”？</a>\"</p>",
    "publish_time": "2023-05-25 11:53:03",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "《卫报》优化了移动推送通知投递架构",
    "url": "https://www.infoq.cn/article/Pl7VVWNBer6xozYjmmqp",
    "summary": "<p>《卫报》（The Guardian）的技术团队<a href=\"https://www.theguardian.com/info/2022/dec/15/our-journey-towards-the-fastest-breaking-news-service\">已经在着手加快移动推送通知的速度，以改善读者的体验。</a>\"针对并发性进行优化的原始架构一直受到通知投递延迟的困扰。工程师们利用改进的可观测性，通过实验获得了显著的成果。</p><p></p><p>《卫报》的读者可以使用移动应用程序访问内容，并可以通过注册以推送通知的形式接收突发新闻提醒。其背后的<a href=\"https://en.wikipedia.org/wiki/Event-driven_architecture\">事件驱动架构（EDA）</a>\"自2009年以来一直在运行，但随着时间的推移，通知投递的时间有所增加，对某些用户来说，通知投递时间需要五分钟以上。</p><p></p><p>《卫报》的全栈开发人员<a href=\"https://www.linkedin.com/in/francesca-hammond-044a3a21/\">Francesca Hammond</a>\"表示，该团队的目标是在两分钟内向90%的预期受众发送通知，这一目标被称为“90in2”。</p><p></p><p>支持推送通知投递的解决方案利用了一系列的技术。一个与<a href=\"https://www.playframework.com/\">Scala Play应用程序</a>\"对话的内部突发新闻工具触发推送通知投递。<a href=\"https://aws.amazon.com/lambda/\">AWS Lambda</a>\"函数使用来自<a href=\"https://aws.amazon.com/sqs/\">AWS SQS</a>\"的队列消息，负责从自托管的<a href=\"https://www.postgresql.org/\">PostgreSQL</a>\"数据库中获取通知注册，并将其发送到谷歌和苹果的推送通知平台。</p><p></p><p><img src=\"https://imgopt.infoq.com/news/2023/05/guardian-push-architecture/en/resources/14009-1684154406937.png\" /></p><p></p><p>来源：&nbsp;<a href=\"https://www.theguardian.com/info/2022/dec/15/our-journey-towards-the-fastest-breaking-news-service\">https://www.theguardian.com/info/2022/dec/15/our-journey-towards-the-fastest-breaking-news-service</a>\"</p><p></p><p>该团队使用<a href=\"https://www.elastic.co/what-is/elk-stack\">ELK栈</a>\"改进了整个过程的可观测性，这对于识别瓶颈至关重要。</p><p></p><p>他们认为检索通知注册是造成延迟的主要瓶颈。进一步的调查发现存在大量的数据库连接错误，从而导致处理时间过长。为了解决这个问题，团队引入了<a href=\"https://aws.amazon.com/rds/proxy/\">RDS代理</a>\"，这样lambda函数就不会直接连接到数据库，从而避免了触达数据库的连接限制。</p><p></p><p>查询执行时间过长被认为是延迟的另一个原因。在判定查询计划是正确的之后，为了进一步提高数据库性能，一个完整的真空进程删除了“死行”（数据库仍保留的逻辑删除行），并将数据库从版本10升级到了版本13，该版本允许使用更强大的AWS Gravitron2处理器。</p><p></p><p>团队通过创建一个新的RDS实例来升级数据库，以最大限度地减少切换过程中的停机时间。他们设置了逻辑复制来持续同步数据，而应用程序服务则使用旧实例。在切换时，团队更新服务以使用新实例，并立即禁用逻辑复制。</p><p></p><p><img src=\"https://imgopt.infoq.com/news/2023/05/guardian-push-architecture/en/resources/11368-1684154406937.jpg\" /></p><p></p><p>来源：&nbsp;<a href=\"https://www.theguardian.com/info/2022/dec/15/our-journey-towards-the-fastest-breaking-news-service\">https://www.theguardian.com/info/2022/dec/15/our-journey-towards-the-fastest-breaking-news-service</a>\"</p><p></p><p>在持久层之外，开发人员发现，负责向苹果/谷歌平台<a href=\"https://www.infoq.cn/article/v2uz7mktFbRXTuSoy6KU\">提交通知的lambda函数</a>\"需要长达六分钟的时间才能完成接收人数超过80万的突发新闻。</p><p></p><p>该团队通过部署潜在的优化并观察结果进行了几次实验，每次都需要决定更改的保留和恢复。基于这些实验，他们增加了运行在lambda函数中的Scala应用程序的线程池大小，以提高并行性。此外，他们还将lambda函数可用的内存和CPU数量设置为<a href=\"https://docs.aws.amazon.com/lambda/latest/operatorguide/computing-power.html\">支持的最大值</a>\"，从而缩短了函数的执行时间。</p><p></p><p>Hammond写道，继续之前，团队正在进行评估：</p><p></p><blockquote>我们还没做完呢！我们认为，为了实现90in2的目标，可能需要对我们的架构进行更大的更改，特别是考虑到向200多万订阅者发送更大的通知时。由于所需更改的性质，我们想尝试实施RFC风格的流程，以便在开始开发之前收集想法和反馈。</blockquote><p></p><p></p><p>《卫报》的核心通知平台是<a href=\"https://github.com/guardian/mobile-n10n\">开源的</a>\"。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/05/guardian-push-architecture/\">https://www.infoq.com/news/2023/05/guardian-push-architecture/</a>\"</p>",
    "publish_time": "2023-05-25 12:03:54",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "商汤集团联合创始人杨帆确认出席QCon广州，分享大模型浪潮下，商汤的布局与思考",
    "url": "https://www.infoq.cn/article/tYCWuepWdeDjaOtqg8IR",
    "summary": "<p>5&nbsp;月&nbsp;26&nbsp;日本周五，在即将到来的&nbsp;<a href=\"https://qcon.infoq.cn/2023/guangzhou/schedule?utm_source=infoq&amp;utm_medium=arti&amp;utm_campaign=full&amp;utm_term=0523&amp;utm_content=tanghaitao\">QCon&nbsp;全球软件开发大会·广州站</a>\"上，商汤集团联合创始人、大装置事业群总裁杨帆将于会上发表题为《大模型浪潮下，商汤的布局与思考》主题分享，在&nbsp;AIGC&nbsp;高速发展的当下，与全球开发者见面。</p><p></p><p>杨帆毕业于清华大学，曾就职于微软，自2014年11月起担任商汤科技副总裁，主要负责本集团的战略规划及企业发展。同时，他也是深圳证券交易所的行业专家、清华大学人工智能国际治理研究院战略合作及发展委员会副会长。</p><p></p><p>而杨帆所在的商汤科技成立于&nbsp;2014&nbsp;年，并于&nbsp;2021&nbsp;年在香港挂牌上市，近十年间始终是&nbsp;AI&nbsp;领域的焦点企业。商汤科技是第一家将人脸支付技术集成至地铁售票系统中的公司，也为北京大兴机场提供了智能旅客安检系统，进一步将&nbsp;AI&nbsp;落地至产业。2023年4月10日，商汤科技董事长兼CEO徐立分享了以“大模型+大算力”推进AGI（通用人工智能）发展的战略布局，并公布了商汤在该战略下的“日日新SenseNova”大模型体系，推出自然语言处理、内容生成、自动化数据标注、自定义模型训练等多种大模型及能力，包括自然语言处理模型“<a href=\"https://baike.baidu.com/item/%E5%95%86%E9%87%8F/62873734?fromModule=lemma_inlink\">商量</a>\"”（SenseChat）、文生图模型“<a href=\"https://baike.baidu.com/item/%E7%A7%92%E7%94%BB/62878315?fromModule=lemma_inlink\">秒画</a>\"”和数字人视频生成平台“<a href=\"https://baike.baidu.com/item/%E5%A6%82%E5%BD%B1/62878406?fromModule=lemma_inlink\">如影</a>\"”（SenseAvatar）等。</p><p></p><p>相信杨帆来到大会现场，一定能带给大家关于&nbsp;AIGC&nbsp;时代最务实、前沿的研发思考与实践经验。同时，极客邦科技也在努力为大家提供更多的&nbsp;AIGC&nbsp;相关内容，满足大家对于精品资讯、资料、课程的需求。</p><p></p><p></p><h4>InfoQ&nbsp;AIGC&nbsp;专题</h4><p></p><p>其中，InfoQ&nbsp;推出专题，每日实时跟进全球ç动态资讯：<a href=\"https://www.infoq.cn/theme/187\">AIGC，下一个即将爆发的万亿级AI技术风口_技术洞察_技术趋势_大厂实践_InfoQ精选专题</a>\"。InfoQ&nbsp;还另外组织了数场线上专家研讨，期待为大家带来关于&nbsp;AIGC&nbsp;发展的深入解读：</p><p><a href=\"https://www.infoq.cn/video/TXoCTL6MCpZWm2BKaesc\">极客圆桌派：狂飙的&nbsp;ChatGPT&nbsp;｜InfoQ《极客有约》_AI_InfoQ&nbsp;中文站_InfoQ精选视频</a>\"<a href=\"https://www.infoq.cn/video/So2yItKrdYsDZpEG7DjS\">极客圆桌派：ChatGPT点燃AI狂潮&nbsp;|&nbsp;InfoQ《极客有约》_AI_InfoQ&nbsp;中文站_InfoQ精选视频</a>\"<a href=\"https://www.infoq.cn/video/AeU15OmkT2IWQ56ekExt\">我们是如何探索把ChatGPT推到企业级应用的？|&nbsp;InfoQ《极客有约》_AI_InfoQ&nbsp;中文站_InfoQ精选视频</a>\"</p><p>详情请关注《InfoQ&nbsp;极客有约第一季》内容合集：<a href=\"https://www.infoq.cn/theme/188\">《极客有约》2023年&nbsp;第一季_技术洞察_技术趋势_大厂实践_InfoQ精选专题</a>\"</p><p>六月，InfoQ&nbsp;将拜访国内主流大模型研发团队，深入&nbsp;AIGC&nbsp;在产业中的落地实践，持续为大家带来深度报道。</p><p></p><p></p><h4>极客时间&nbsp;AIGC&nbsp;系列课</h4><p></p><p>在&nbsp;3&nbsp;月中旬，极客时间一次性发布四门AIGC&nbsp;公开课，其中包括句子互动公司创始人兼&nbsp;CEO&nbsp;李佳芮的<a href=\"https://time.geekbang.org/opencourse/videointro/100541101\">《ChatGPT从0到1》</a>\"、新加坡科研局高级研究员黄佳的《<a href=\"https://time.geekbang.org/opencourse/videointro/100541201\">ChatGPT和预训练模型实战课</a>\"》、优频科技有限公司&nbsp;CTO&nbsp;的《<a href=\"https://time.geekbang.org/opencourse/videointro/100541301\">Stable&nbsp;Diffusion：零基础学会&nbsp;AI&nbsp;绘画</a>\"》以及NebulaGraph软件工程师古思为的《<a href=\"https://time.geekbang.org/opencourse/videointro/100540901\">GitHub&nbsp;Copilot&nbsp;实践课</a>\"》</p><p></p><p>与此同时，&nbsp;bothub&nbsp;创始人、布奇托网络科技创始人兼&nbsp;CTO&nbsp;徐文浩，在极客时间开设了课程<a href=\"https://time.geekbang.org/column/intro/100541001?tab=catalog\">《AI&nbsp;大模型之美》</a>\"，是「极客时间&nbsp;AIGC&nbsp;未来教育系列课程」之一，聚焦于让大家充分认识、使用&nbsp;OpenAI、Stable&nbsp;Diffusion&nbsp;等开发工具，实现自主可用的&nbsp;AIGC&nbsp;应用，现已有&nbsp;1.8w&nbsp;人加入学习。</p><p></p><p>珠海太乙人工智能技术合伙人尹会生，则在极客时间开办了《<a href=\"https://u.geekbang.org/subject/intro/100550301\">21&nbsp;天&nbsp;AIGC&nbsp;行动营</a>\"》。都说&nbsp;AIGC&nbsp;会淘汰掉某些岗位，但有许多同学已经在这里率先成为&nbsp;AIGC&nbsp;时代的高效工作者，AIGC&nbsp;变成了他们手中的效率提升工具。</p><p></p><p>6&nbsp;月还将有重磅的&nbsp;AIGC&nbsp;主题训练营与大家见面，聚焦&nbsp;AIGC&nbsp;与企业私域数据结合，开发为企业特别定制的&nbsp;AIGC&nbsp;服务，相信也契合了很多研发小伙伴的实际工作。</p><p></p><p>希望这一系列的内容更新，结合本次&nbsp;QCon&nbsp;大会的重磅专家分享，能在&nbsp;AIGC&nbsp;时代，为你带来不一样的启发。</p><p></p><p>最后，有一个好消息告诉你，在本次QCon&nbsp;全球软件开发大会·广州站上，我们策划了<a href=\"https://www.infoq.cn/article/trIhrtiR6hSGFwT8i8mC\">五场闭门会</a>\"，详细信息可点击超链查看。众多大咖将围绕&nbsp;AIGC、金融行业数据治理、业务出海等问题进行深入探讨。</p><p></p><p>会议开幕倒计时最后一天，欢迎线下来交流，购票可直接电话&nbsp;/&nbsp;微信联系票务经理瑞丽&nbsp;18514549229。</p><p><img src=\"https://static001.infoq.cn/resource/image/12/a4/12c0874108efc1131e652689e07dbca4.jpg\" /></p><p></p>",
    "publish_time": "2023-05-25 12:06:19",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "免费版“Github Copilot”，编程能力还翻倍？！谷歌硬刚微软，推出全新Colab编程平台",
    "url": "https://www.infoq.cn/article/atGCf0aK8qAv4JRMAwVV",
    "summary": "<p>最近，谷歌宣布Google Colaboratory（Colab）即将加入全新的 AI 编码功能，包括代码生成、代码补全、代码聊天机器人。</p><p>&nbsp;</p><p>而且，最重要的是，与GitHub <a href=\"https://www.infoq.cn/article/kxARbquFMCbx39KPoTxY\">Copilot</a>\" 每月 10 美元的订阅费用相比，谷歌全新的AI编码功能将完全免费！</p><p>&nbsp;</p><p>Colab 是 Google Research 的一款类似 Jupyter Notebook 的产品。Python 程序开发人员可以使用它来编写和执行随机 Python 程序代码，只需要一个Web 浏览器即可。简而言之，Colab 是Jupyter Notebook的云托管版本。另外，Colab还提供对谷歌强大计算资源（包括存储、内存、 GPU 和 TPU）的免费访问，并能与 Jupyter Notebooks 和 GitHub 等流行工具集成。</p><p>&nbsp;</p><p><a href=\"https://www.infoq.cn/article/hNs2LxvloB4jaBQEwEL1\">谷歌</a>\"表示目前已经有超过 700 万人在使用 Colab&nbsp;，而随着AI编程功能的加入，各方面只会越来越好。</p><p>&nbsp;</p><p>即将加入全新的AI编程功能由新“文生代码”模型Codey提供支持，支持20多种编程语言，包括Go、Java、Javascript和Typescript等。谷歌表示，该模型“擅长 Python 和 JavaScript 等流行的编程语言，但也可以生成 Prolog、Fortran 和 Verilog 等语言的专用代码。”</p><p>&nbsp;</p><p>此举被视为谷歌正面硬刚微软Github Copilot。谷歌透露，这些新功能将在未来几个月内逐步推出，付费用户将先行体验，然后免费用户和其他地区的用户也将很快获得使用权限。</p><p>&nbsp;</p><p></p><h2>强大的编程功能</h2><p></p><p>&nbsp;</p><p>谷歌表示，Codey 基于 PaLM 2 构建，已针对大量高质量代码数据进行微调，将显着提高编程速度、质量和理解力。</p><p>&nbsp;</p><p>在代码生成方面，可通过自然语言来生成更大的代码块，也可以根据注释或提示编写整个函数。</p><p>&nbsp;</p><p>在新的 Colab 版本中，会有一个全新的“生成”按钮，用户可以在那里用自然语言输入任何想要的内容，之后，AI 就会根据这段文本提示来生成相应代码。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/32/32e653fcd21b68c16028c6c631ed5749.gif\" /></p><p></p><p></p><p>&nbsp;</p><p></p><h3>代码补全</h3><p></p><p>&nbsp;</p><p>在输入代码时，Colab 还会根据上下文，为接下来的代码提供建议。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d3/d374c96483fb0bf17382e4a52ac25c99.png\" /></p><p></p><p>&nbsp;</p><p></p><h3>集成聊天机器人</h3><p></p><p>此外，谷歌还将在 Colab 中加入编程专用的聊天机器人。用户可以直接与 AI 对话，来获得有关调试、文档、学习新的概念以及其他问题上的帮助。例如“我如何从 Google 表格导入数据？” 或“如何过滤 Pandas DataFrame？”</p><p>&nbsp;</p><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/013aeb13cb00e416e1fea39833e6eaa5.gif\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>AI编程竞争加剧，免费才是“硬道理”？</h2><p></p><p>&nbsp;</p><p>根据Sourcegraph的<a href=\"https://about.sourcegraph.com/big-code/big-code-in-ai-era\">一份调查报告</a>\"显示，95% 的受访开发人员已经在使用 AI 工具编写代码，例如 GitHub Copilot、ChatGPT以及其它AI编程工具，该报告针对不同行业和地区的 500 多名软件开发人员和工程师。</p><p>&nbsp;</p><p>GPT-4 等大型语言模型 ( LLM ) 可以建议代码片段、回答技术问题，甚至可以编写简单应用程序。Forrester Research 副总裁兼首席分析师 Mike Gualtieri 预计人工智能工具将对软件开发产生“巨大影响”：“我认为保守地说这将使开发人员的工作效率提高一倍，甚至更多。”</p><p>&nbsp;</p><p>这些生产力的提高也意味着科技行业的大规模变革。尽管之前微软的 GitHub Copilot 和亚马逊的 Amazon CodeWhisperer 已经推出了有限的功能集，但去年 ChatGPT 的发布开启了 AI 代码生成的新纪元。所以，现在云厂商之间又展开了一场关于AI编程方面的竞赛，以赢得开发人员的支持。</p><p>&nbsp;</p><p>之前， Bard 和 ChatGPT都展示了自家大模型的代码生成能力，但开发人员更需要的是在 IDE 中使用 AI。于是，微软在3月份推出了在开发环境中嵌入 GPT-4 的 GitHub Copilot X，并且它最终将被集成到 Visual Studio——微软的 IDE 中。在 IDE 中的Copilot X 将能够生成、解释和评论代码，还具有调试、编写单元测试和识别漏洞等功能。</p><p>&nbsp;</p><p>为了不被其云竞争对手超越，今年4 月份，AWS 宣布其所谓的实时 AI 编码伴侣全面上市。Amazon CodeWhisperer 与一系列 IDE 集成，即 Visual Studio Code、IntelliJ IDEA、CLion、GoLand、WebStorm、Rider、PhpStorm、PyCharm、RubyMine 和 DataGrip，或原生集成在 AWS Cloud9 和 AWS Lambda 控制台中。虽然预览版适用于 Python、Java、JavaScript、TypeScript 和 C#，但一般版本扩展了对大多数语言的支持。Amazon 的主要区别也是在于它对个人用户免费提供，而 GitHub Copilot 目前是基于订阅的，只有教师、学生和开源项目的维护者除外。</p><p>&nbsp;</p><p>而谷歌这一边，则不断扩展Bard的编程能力。 Bard 刚发布的时候还缺乏与 OpenAI 的 ChatGPT 、微软的 Bing Chat 同等的编码能力。在今年Google I/O 大会上，谷歌宣布Bard引进了新一代的PaLM 2，增强了Bard的能力，让用户可以使用 20 多种编程语言进行编码，包括 C++、Go、Java、Javascript 和 Python。现在，让Colab加入全新的 AI 编码功能也是谷歌应对竞争必然会采取的行动。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5a/5a9416b9cb1c8f2b6ffe2fdd7ccbd099.png\" /></p><p></p><p>&nbsp;</p><p>另一方面，市场上也出现了越来越多的可以替换替代 Copilot的人工智能编码工具，但需要付费使用的不在少数。谷歌的“免费”形式，或许是缩小与微软之间的差距的有效手段。</p><p>&nbsp;</p><p>谷歌在博客中说道，“只要能联网，就能免费用。”并且谷歌即将在Colab中推出更多功能和改进，这将有助于提升用户在数据和 ML 工作流程中集成体验。</p><p>&nbsp;</p><p>根据谷歌的说法，对这些功能的访问将在未来几个月内逐步推出，美国的付费用户可以先开始体验，然后免费用户将可以使用。其他地区的用户也将在不久之后就能体验到这些功能。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://blog.google/technology/developers/google-colab-ai-coding-features/\">https://blog.google/technology/developers/google-colab-ai-coding-features/</a>\"</p><p><a href=\"https://blog.ecosystm360.com/googles-ai-code-generator-takes-on-github-copilot/\">https://blog.ecosystm360.com/googles-ai-code-generator-takes-on-github-copilot/</a>\"</p><p>&nbsp;</p>",
    "publish_time": "2023-05-25 12:33:05",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "参数是ChaGPT的近6倍！英特尔公布AI大模型Aurora genAI，具备1万亿参数",
    "url": "https://www.infoq.cn/article/bx7SvZNNgOd63b2hI1yz",
    "summary": "<p></p><blockquote>模型参数越大就越好吗？</blockquote><p></p><p></p><h2>英特尔公布AI大模型Aurora genAI，具备1万亿参数</h2><p></p><p></p><p> wccftech 报道，英特尔近日公布了旗下生成式 AI 大模型 <a href=\"https://www.infoq.cn/article/EDSy8OCKbCRc9TiB48PI\">Aurora genAI</a>\"。</p><p></p><p>据悉，Aurora genAI 参数量高达1万亿，其开发依赖于 Megatron 和 DeepSpeed 框架，这些结构增强了模型的强度和容量。而 ChatGPT 模型参数量是 1750 亿，这也意味着，Aurora genAI 的参数量是<a href=\"https://www.infoq.cn/article/3TR13Qp694BJ8TeOi1xV\">ChatGPT</a>\" 的近6倍。</p><p></p><p>据悉，Aurora genAI 模型是英特尔是与阿贡国家实验室和 HPE 合作开发的，它是一个纯粹以科学为中心的生成式 AI 模型，将被用于各类科学应用，包括分子和材料设计、乃至涵盖数百万来源的综合知识素材，据此为系统生物学、高分子化学、能源材料、气候科学和宇宙学等提供值得探索的实验设计思路。这些模型还将用于加速癌症及其他疾病的相关生物过程的识别速度，并为药物设计提供靶点建议。</p><p></p><p>除了科研之外，Aurora genAI 还具有在自然语言处理、机器翻译、图像识别、语音识别、金融建模等商业领域的应用潜力。</p><p></p><p>阿贡实验室副主任 Rick Stevens 介绍称，“这个项目希望充分利用 Aurora 超级计算机的全部潜力，为能源部各实验室的下游科学研究和其他跨机构合作计划提供资源。”</p><p></p><p>根据介绍，Aurora genAI 模型将由生物学、化学、材料科学、物理学、医学等学科的常规文本、代码、科学文本和结构化数据训练而成。阿贡实验室正带头组织国际合作以推进该项目，参与方包括英特尔、HPE、能源部各下辖实验室、美国及其他国际性高校、非营利组织，以及RIKEN等国际合作伙伴。</p><p></p><p>Aurora genAI 模型将运行在英特尔为阿拉贡国家实验室开发的Aurora超算上，其性能达到了200亿亿次，是当前TOP500超算冠军Frontier的2倍。近日，英特尔和阿贡国家实验室还公布了Aurora的安装进度、系统规格和早期性能测试结果：</p><p></p><p>英特尔已完成Aurora超级计算机1万多块刀片服务器的交付。Aurora的完整系统采用HPE Cray EX超算架构，将拥有63744个GPU和21248个CPU，辅以1024个DAOS存储节点。Aurora还将配备HPE Slingshot高性能以太网络。早期性能结果显示，Aurora超算系统在实际科学和工程负载上具有领先性能，性能表现比AMD MI250 GPU高出2倍，在QMCPACK量子力学应用程序上的性能比H100提高20%，且能够在数百个节点上保持近线性的算力扩展。作为ChaGPT的有力竞争者，Aurora genAI 的公布预示着AI大模型赛道又迎来了新的重磅玩家，并极有可能在未来对各种科学领域产生重大影响。不过目前，Aurora genAI 更像是处于概念阶段，英特尔的目标是到 2024 年完成 Aurora genAI 模型的构建。</p><p></p><p>对于英特尔的万亿参数AI大模型Aurora genAI，有网友表示：“我不相信仅仅增加参数数量就能改进模型，我认为我们不应该发布新闻稿追逐增加参数数量。我在研究中还发现，较大的模型通常不会表现得更好，但由于不负责任的营销，这变得越来越难以向非技术人员解释。如果我们对这些营销放任不管，我们会让很多人失望，并降低大家对AI未来增长潜力的信心——我们不想要另一个 AI 寒冬。训练这些大型模型会产生巨大的环境成本，而且理解、使用和控制这些非常大的模型（即使作为研究人员）也变得更加困难。”</p><p></p><h2>AI军备竞赛进入“万亿参数模型”对抗时代？</h2><p></p><p></p><p>近几年，随着AI大模型赛道持续升温，越来越多的科技巨头加入进来，并不断打破参数规模记录。</p><p></p><p>2021年1月，谷歌大脑团队重磅推出超级语言模型Switch Transformer，该模型有1.6万亿个参数，是当时规模最大的NLP模型。同年6月，智源研究院发布悟道2.0，该系统参数数量已超过1.75万亿，是当时全球最大的大规模智能模型系统。同年11月，阿里达摩院发布多模态大模型 M6，其参数已从万亿跃迁至 10 万亿，是当时全球最大的 AI 预训练模型。</p><p></p><p>有分析指出，中美AI军备竞赛的核心战场正是万亿级预训练模型。打造千万亿参数规模的预训练模型是人类的一个超级工程，可能会对国家甚至人类社会产生重大影响。</p><p></p><p>那么，模型参数越大就越好吗？</p><p></p><p>鹏城实验室网络智能部云计算所副所长相洋曾在接受InfoQ采访时指出：</p><p></p><p></p><blockquote>我们最初见到的一些模型是几万个参数，后来就到了几亿、几十亿、百亿、千亿，还有可能上万亿。目前从事实来说，的确是模型越大数据越多，且质量越好，带来的性能是越高的。但是我个人认为，这个提升曲线可能会有一个瓶颈期，到了瓶颈或者平台期的时候，它的上升速度可能就会缓慢，或者说基本就达到稳定了。就目前而言，可能我们还没有到达平台期。所以说，“<a href=\"https://www.infoq.cn/article/LBhYJYr63GysNIKZCgzI\">模型参数越大越好</a>\"”这个说法在一定程度上是成立的。</blockquote><p></p><p></p><p>但是，判断一个大模型是否优秀，不能只看参数，还要看实际表现。模型得出来的任务效果好，我们就可以认为这个模型是个好模型。参数不是问题，当机器无论是在存储还是计算能力都足够强的时候，大模型也可以变成小模型。</p><p></p><p>此外，还要考虑模型的可解释能力，以及是否容易受噪声的攻击。如果该模型有一定的解释能力，那这个模型就是一个好模型；如果该模型不易被噪声数据或是其他因素影响的话，那这个模型也是一个好模型。</p>",
    "publish_time": "2023-05-25 14:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "ChatGPT 造富“神话”：大四学生放弃大厂去创业，半年后月收入45万",
    "url": "https://www.infoq.cn/article/fMNHfgbHA0UqBlx7k4SD",
    "summary": "<p>&nbsp;</p><p>面对铺天盖地的OpenAI ChatGPT，有人走马观花，有人却利用它赚了不少。</p><p>&nbsp;</p><p>有这样一个大学生，前脚还在Meta和Tesla等大厂实习，半年后，其创办的聊天机器人公司就已经稳定月收6.4万美元（约合45万人民币），而且自首次上线以来，业务流量从未下滑缩水。为了满足巨大需求，他还雇用了两名员工。虽然他没能通过所有大学考试，但这时候的Yasser已经无所谓了。</p><p>&nbsp;</p><p></p><h2>“大厂的生活对我来说太保守”</h2><p></p><p>&nbsp;</p><p>Yasser 来自埃及，2019年才搬到加拿大读本科。刚上大学的时候，Yasser也不知道自己想干什么，他身边有很多同学都想去FAANG那几家大厂，受其影响，Yasser 也开始朝着这个的目标努力。</p><p>&nbsp;</p><p>大三和大四时，Yasser 在Tesla和Meta实习。“每段实习的开头都很美好，免费的食物、按摩椅、才华横溢的同事等等，一切都令人超级兴奋。但随着时间推移，我感觉自己其实在重复同一天的生活。这样的生活当然也不错，却再也激发不出兴奋的情绪。我意识到，大厂的生活对我来说太保守、太清晰了。我从实习中学会了很多，但这段经历让我下定决心做独立技术人。”Yasser 说道。</p><p>&nbsp;</p><p>Yasser一直在做副业，虽然都没怎么赚到钱，但Indie Hackers播客上那些成功故事始终在激励着他。随着学业推进，Yasser不再单纯关注怎么进大厂，而是更多思考该开发哪些副业项目。</p><p>&nbsp;</p><p>“我在实践中发现自己是那种愿意努力工作的人，创业对我来说最令人兴奋、也最有收获。”到了大四，Yasser对AI的应用产生了浓厚兴趣。他看到Pieter Levels这样的个人创业者开发出了很酷的AI产品，并深受启发。Yasser 开始试用OpenAI API，并感受到了其中巨大的潜力。</p><p>&nbsp;</p><p>“Chatbase的市场定位并不复杂，我也没做过验证或者商业调查。毕竟AI这个领域才刚刚诞生，对我来说‘用ChatGPT处理数据’肯定有搞头，能帮助许许多多用户解决实际需求。”Yasser表示。</p><p>&nbsp;</p><p></p><h2>放弃课业去创业</h2><p></p><p>&nbsp;</p><p>Chatbase 最初其实是想做成一款处理PDF的ChatGPT工具，这是Yasser当时想到的最直观的用例。比如用户可以上传一份PDF，然后让ChatGPT总结一下其中的内容。</p><p>&nbsp;</p><p>这个版本的MVP大概用掉了Yasser两个月时间。2023年2月2号，Yasser把它<a href=\"https://twitter.com/yasser_elsaid_/status/1621954428105379846\">发布给了Twitter</a>\"上的全部16个关注者，结果一下子就火了。</p><p>&nbsp;</p><p>Yasser甚至都没做计费页面，任何人都可以上传任意数量的文档、发送任意数量的消息。感受到其中巨大的商机，Yasser马上中止了在校课业，把所有时间和精力都集中在Chatbase上。“我知道，自己绝对不能错过这个机会。”</p><p>&nbsp;</p><p>最后，Yasser有两门课没过，但他认为这绝对值得！</p><p>&nbsp;</p><p>Chatbase.co是一款为网站构建自定义ChatGPT界面的工具，用户只需上传文档或添加到网站的链接，就可以获得一个类似ChatGPT的聊天机器人，并将它作为小组件添加到网站上。</p><p>&nbsp;</p><p>Yasser用React、Next.js和Supabase来构web应用。Yasser 还在应用的AI部分使用了OpenAI的API、Langchain还有Pinecone。付款部分用的是Stripe。目前这套技术栈运行得不错，但后续Yasser可能需要做些调整来控制成本，比如尝试不同的Vector数据库或者托管选项。</p><p>&nbsp;</p><p>对于Chatbase最初能够快速获得关注的原因，Yasser 认为，Chatbase可能是第一个“用ChatGPT处理数据”的SaaS工具，这本身就是个巨大的优势，所以快速传播也在情理之中。用户可以灵活上传自己的文档，并跟AI对话来提取其中的亮点。</p><p>&nbsp;</p><p>“再说现在AI和ChatGPT这么火，我不用刻意宣传也能获得足够的热度。我发过几条推文，传播<a href=\"https://twitter.com/yasser_elsaid_/status/1622315953479421963\">效果都挺好</a>\"，后来，AI领域有影响力的名人也<a href=\"https://twitter.com/rowancheung/status/1633868758530883584\">开始转发</a>\"。”Yasser说道。</p><p>&nbsp;</p><p>这波宣传攻势帮Yasser吸引到了第一批客户，但问题是这肯定不足以支撑起长期业务战略。现在太多同类工具跟Chatbase占据相同的生态位，AI名人们也不可能没完没了地推荐同质化工具。所以，Yasser还想出了其他一些吸引客户的办法：</p><p>&nbsp;</p><p>在Indie Hackers网站上发布Product Hunt。在Reddit子论坛上发帖（再好的工具，也不如讲个精彩的故事）。在Indie Hackers上保持活跃。把Chatbase提交给各种AI产品目录。</p><p>&nbsp;</p><p>所以在产品上线之后，业务流量也一直保持着增长。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/76/76623b72673a09aa938758967a09ba38.png\" /></p><p></p><p></p><h2>“不着急找工作”</h2><p></p><p>&nbsp;</p><p>Chatbase是一项订阅服务，提供四种不同选项。大多数订户最初选择的都是最低配（主要是为了测试聊天机器人），但后面快速分流——要么选择更好的套餐，要么直接转身走人。Yasser的大部分收入来自每月399美元的套餐。</p><p>&nbsp;</p><p>Chatbase使用Stripe来处理订阅付款，目前来看效果不错：</p><p>&nbsp;</p><p>2月7日：月收0美元；2月11日：月收400美元；2月16日：月收900美元；2月28日：月收3000美元；3月15日：月收10000美元；5月13日：月收64000美元。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/c4/c41bbd5e1ba42c3f042439efc23e078f.png\" /></p><p></p><p>目前，Chatbase的月度经常性收入是64000美元。Yasser认为，这种疯狂的增长当然要归功于AI尚处于市场应用早期，围绕ChatGPT掀起的炒作热浪也尚未褪去。Yasser也不确定这样的温度还能持续多久，毕竟现在已经有大量工具在提供类似的服务，而且科技巨头也已经纷纷下场。</p><p>&nbsp;</p><p>“但对创业者来说，最好的产品肯定离不开健康的市场竞争。如果根本不存在竞争，要么就是你特别天才、发现了别人都没想到的业务，要么就是你开发的东西别人根本就不需要。只有存在竞争，才能证明这是一条前景光明的道路。”Yasser说道。</p><p>&nbsp;</p><p>Yasser表示，Chatbase会继续贯彻“用ChatGPT处理数据”的宗旨。“我会根据客户反馈添加更多功能，这也是立足个人数据建立自定义AI聊天机器人的简单方法，可以通过网站或者API轻松进行交互。”</p><p>&nbsp;</p><p>短期之内，Yasser表示自己应该不会像应届生那样忙着找工作，相反会把所有精力都集中在Chatbase身上。Yasser刚刚雇用了两名员工来帮助编写新功能和提供客户支持，估计后续团队规模会增长至五到六个人。</p><p>&nbsp;</p><p>Yasser现在最担心的还是竞争会不会快速激烈化，也不知道这个领域未来会是什么样子。这是个全新的世界，颠覆性变革随时可能出现（比如OpenAI突然出台新规定），所有AI工具的发展轨迹都会因此而改变。</p><p>&nbsp;</p><p></p><h2>为了德配其位，每天工作12个小时</h2><p></p><p>&nbsp;</p><p>Yasser坦诚道，目前为止，最大的挑战就是说服自己全身心投入到没有即时回报的副业当中。“在迈过这道坎后，接下来就无所谓失败了。即使Chatbase没能得到大家的肯定，我也会从中学到很多、体验很多，人生也多了一段精彩的历程。”</p><p>&nbsp;</p><p>Yasser声称自己很少思考再来一次、不同选择什么的，“因为如今的我就是由当初一个个决定塑造出来的。我觉得自己现在这样挺好。”</p><p>&nbsp;</p><p>在创业过程中，Yasser觉得自己最重要的就是多听其他成功创业者的故事。这些故事告诉他，想靠副业每月赚1万美元并不是不可能，每天都有人达成这个目标。只要能紧跟新的技术和趋势，就能比其他人更快找到机会。只要能把握住这些机会，哪怕只把握住其中一个，就足以走向成功。</p><p>&nbsp;</p><p>“就个人而言，我是在正确的时间做了正确的事情。我对AI应用很感兴趣，正好有时间做业余项目，而且很快就发现了有价值的用例。当然，我的推文属于意外走红。为了德配其位，我会非常努力地工作（每天工作12个小时），只为抓住这个宝贵的机会。”Yasser说道。</p><p>&nbsp;</p><p>对其他刚刚起步的技术人，Yasser也给出了下面几条建议：</p><p>&nbsp;</p><p>尽快行动。我们已经受够繁文缛节了，快点完成基础MVP版本并推出，这非常重要。可以的话多做几次发布。只要是对应用程序进行了重大更改，就要像发布新产品一样自豪地对外展示。公开整个开发过程。经验表明，开发过程中的每篇新帖都有机会大范围传播，甚至最终改变自己的生活。另外，大家还可以在过程中结识到很酷、志同道合的朋友。收入数字没必要公开，发布的主要是开发过程中的点点滴滴。目前Twitter仍然是搞宣传的最佳平台，但考虑到TikTok的热度和发布类内容的缺失，那边可能也有很好的机会。多跟社区互动。关注成功的独立技术人，编写内容、分享经验，跟自己身边的独立技术人交朋友。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.indiehackers.com/post/how-a-college-student-reached-64-000-mo-in-6-months-by-being-an-ai-first-mover-ba7981f6e1\">https://www.indiehackers.com/post/how-a-college-student-reached-64-000-mo-in-6-months-by-being-an-ai-first-mover-ba7981f6e1</a>\"</p>",
    "publish_time": "2023-05-25 14:43:41",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "设计模式详解之工厂模式",
    "url": "https://www.infoq.cn/article/4b8e7ce446d58c79337a476c3",
    "summary": "<p>作者：刘文慧</p><p></p><p></p><blockquote>本文将着眼于工厂模式，从简单工厂模式、工厂方法模式和抽象工厂模式出发，展开学习和深入探讨。</blockquote><p></p><p>​</p><p></p><h1>一、概述</h1><p></p><p></p><p>我们在进行软件开发时要想实现可维护、可扩展，就需要尽量复用代码，并且降低代码的耦合度，而设计模式就是一种可以提高代码可复用性、可维护性、可扩展性以及可读性的解决方案。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2c/2c43fd4658dc701e2fd3454a7b9ef25b.png\" /></p><p></p><p>大家熟知的23种设计模式，可以分为创建型模式、结构型模式和行为型模式三大类。其中，创建型模式是对类的实例化过程进行抽象，从而将对象的创建和使用分离开。工厂模式属于创建型模式的范畴，本文将着眼于工厂模式，从简单工厂模式、工厂方法模式和抽象工厂模式出发，展开学习和深入探讨。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ff/ffcfc20ce05a1b56cb28f99c012d7849.jpeg\" /></p><p></p><p></p><h1>二、基本概念</h1><p></p><p></p><p>工厂模式的核心思想就是把创建对象和使用对象解藕，由工厂负责对象的创建，而用户只能通过接口来使用对象，这样就可以灵活应对变化的业务需求，方便代码管理、避免代码重复。</p><p></p><p>假设我们在工作中需要将产品a升级为产品A ，如果创建对象的工作是由用户来做，也就是用户通过new a()的形式创建对象，那么为了应对新的产品升级需求，我们还需要找到所有相关代码并将它们改为new A()，这对于淘宝下的很多庞大工程而言就是一项极为繁琐的工作；而通过应用工厂模式，将所有对象创建工作交由工厂管理时，我们就可以直接在工厂中将return new a()改为return new A()，用户仍然可以调用 factory.createProduct(）方法而无须更改原本的代码。这样工厂可以通过复用来减少重复代码量，并且用户无需关注创建对象的逻辑。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/01a68a7cdc0b70b0b4d3804e5563c277.jpeg\" /></p><p></p><p>工厂模式在Java程序员的工作中可以说是无处不在：我们最常用的Spring就是一个Bean工厂，IOC通过BeanFactory对Bean进行管理（可参考上面这张类图）；我们使用的日志框架slf4j使用了工厂方法模式；JDK的Calendar使用了简单工厂模式……</p><p></p><p>下面本文将结合基本概念和具体示例来详细分析常用的几种工厂模式。</p><p></p><p></p><h2>2.1&nbsp;简单工厂模式</h2><p></p><p></p><p>顾名思义，简单工厂模式是最简单的一种工厂模式，它定义了一个负责生产对象的工厂类，使用者可以根据不同参数来创建并返回不同子类，这些子类都共用一个接口（即父类）。</p><p></p><p></p><h3>结构</h3><p></p><p></p><p>简单工厂模式包含三种类，分别是抽象产品类、具体产品类、工厂类，下面分别对各类及它们之间的关系作进一步说明。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1b/1b261298ee8cd83e22e009a7b7b0a6bb.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7b/7b5c26207877c382f0488fab450b44d2.jpeg\" /></p><p></p><p></p><h3>使用</h3><p></p><p></p><p>有了上述的基本概念，我们将简单工厂模式的使用步骤概括为：</p><p></p><p>step1：创建抽象产品类，并为具体产品定义好一个接口；step2：创建具体产品类，其通过接口来继承抽象产品类，同时也要定义计划生产的每一个具体产品；step3：创建工厂类，其创建的静态方法可以对传入的不同参数做出响应；step4：外界使用者就能调用工厂类的静态方法了，通过传入不同参数来创建不同具体产品类的实例。</p><p></p><p>下面以淘宝服装店铺的商品展示销售进行阐释，比如一个衬衫专卖店需要在淘宝上展示旗下商品，我们可以把所有衬衫都分别单独定义一个类，这样就可以随意添加或修改某一个新的衬衫类型，并使用Fcatory类来判断要创建哪一个衬衫类型的对象，即：先声明一个父类对象的变量，再根据用户输入的参数判断新建什么具体的衬衫类型对象。</p><p></p><p>代码实现</p><p></p><p><code lang=\"null\">//step1:创建抽象产品类，定义具体产品的公共接口\npublic abstract class Shirt{\n    public abstract void Show();\n}\n​\n//step2:创建具体产品类（继承抽象产品类），定义生产的具体产品\n//具体产品类A，女款衬衫\npublic class WomenShirt extends Shirt{\n    @Override\n    public void Show(){\n        System.out.println(\"展示女款衬衫\");\n    }\n}\n//具体产品类B，男款\npublic class MenShirt extends Shirt{\n    @Overside\n    public void Show(){\n        System.out.println(\"展示男款衬衫\")；\n        }\n}\n​\n//step3:创建工厂类，通过静态方法处理不同传入参数，从而创建不同具体产品类的实例\npublic class Factory{\n    public static Shirt Exhibit(String ShirtName){\n        switch(ShirtName){\n            case \"女款衬衫\":\n                return new WomenShirt();\n            case \"男款衬衫\":\n                return new MenShirt();\n            default:\n                return null;\n        }\n    }\n}\n​\n//step4:外界调用工厂类的静态方法，传入不同参数创建不同具体产品类的实例\npublic class SimpleFactoryPattern{\n    public static void main(String[] args){\n        Factory exhibitFactory = new Factory();\n        //用户搜索女款衬衫\n        try{\n            //调用工厂类的静态方法，传入参数并创建实例\n            exhibitFactory.Exhibit(\"女款衬衫\").Show();\n        }catch(NullPointerException e){\n            System.out.println(\"没有找到商品\");\n        }\n        //用户搜索男款裤子\n        try{\n            exhibitFactory.Exhibit(\"男款裤子\").Show();\n        }catch(NullPointerException e){\n            System.out.println(\"没有找到商品\");\n        }\n        //用户搜索男款衬衫\n        try{\n            exhibitFactory.Exhibit(\"男款衬衫\").Show();\n        }catch(NullPointerException e){\n            System.out.println(\"没有找到商品\");\n        }\n    }\n}</code></p><p></p><p>结果输出</p><p></p><p><code lang=\"null\">展示女款衬衫\n没有找到商品\n展示男款衬衫</code></p><p></p><p>UML图</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fc/fc56385e8cd671cdedf723fe7d77ac5b.jpeg\" /></p><p></p><p></p><h3>优缺点</h3><p></p><p></p><p>优点</p><p></p><p>1）将对象的使用和创建过程分离开，实现解藕。客户端不需要关注对象是谁创建的、怎么创建的，只要通过工厂中的静态方法就可以直接获取其需要的对象。</p><p></p><p>2）将初始化实例的工作放到工厂里执行，代码易维护， 更符合面向对象的原则，做到面向接口编程，而不是面向实现编程。</p><p></p><p>缺点</p><p></p><p>1）工厂类中需要选择创建具体某个对象，所以一旦添加新产品则必须要对工厂中的选择逻辑进行修改，导致工厂逻辑过于复杂，违背开闭原则。</p><p></p><p>2）工厂类集合了所有实例（具体产品）的创建逻辑，一旦这个工厂不能正常工作，整个系统都会受到影响。</p><p></p><p>3）静态方法不能被继承和重写，会造成工厂角色无法形成基于继承的等级结构。</p><p></p><p></p><h3>适用场景</h3><p></p><p></p><p>具体产品类较少时，使用简单工厂模式可以实现生产者与消费者的分离，而且也不会在工厂类中设定太复杂的判断逻辑。使用者只知道传入工厂类的参数，不关心如何创建对象的逻辑时。</p><p></p><p></p><h2>2.2 工厂方法模式</h2><p></p><p></p><p></p><h3>结构</h3><p></p><p></p><p>工厂方法模式包含四种类，分别是抽象产品类、具体产品类、抽象工厂类、具体工厂类，下面分别对各类以及它们之间的关系作进一步说明。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/79/79f1e3953ec7d71d76dfd3d24f25b02a.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c8/c8b53d93faf4914e86d713f8b70a301b.jpeg\" /></p><p></p><p></p><h3>使用</h3><p></p><p></p><p>根据上述概念，下面将抽象工厂模式的使用步骤概括如下：</p><p></p><p>step1：创建抽象工厂类，定义具体工厂的公共接口；step2：创建抽象产品类，定义具体产品的公共接口；step3：创建具体产品类（继承抽象产品类），定义生产的具体产品；step4：创建具体工厂类（继承抽象工厂类），定义创建相应具体产品实例的方法；step5：外界调用具体工厂类的方法，创建不同具体产品类的实例。</p><p></p><p>还是以淘宝店铺下的宝贝分类展示功能举例，假如该服装店除男款衬衫和女款衬衫外，还要新增一个衬衫类型如中性衬衫，按照简单工厂模式我们依然可以继承Shirt抽象父类，override衬衫类型，然后在Fcatory中添加新分支，然而这样虽然扩展了衬衫类型，却对Fcatory类进行了修改，不符合“开放扩展、关闭修改”的开闭原则。为了应对这种需求变化，我们可以使用工厂方法模式，提取出一个工厂父类接口Fcatory，并创建各衬衫类型的工厂子类WomenShirtFactory、MenShirtFactory、NeutralShirtFactory，并分别使用对应的工厂子类来判断要创建哪一衬衫类型的对象。</p><p></p><p>代码实现&nbsp;</p><p></p><p><code lang=\"null\">//step1:创建抽象工厂类，定义具体工厂的公共接口\npublic abstract class Factory{\n    public abstract Shirt Exhibit();\n}\n​\n//step2:创建抽象产品类，定义具体产品的公共接口\npublic abstract class Shirt{\n    public abstract void Show();\n}\n​\n//step3:创建具体产品类（继承抽象产品类），定义生产的具体产品\n//具体产品类A，女款衬衫\npublic class WomenShirt extends Shirt{\n    @Override\n    public void Show(){\n        System.out.println(\"展示女款衬衫\");\n    }\n}\n//具体产品类B，男款衬衫\npublic class MenShirt extends Shirt{\n    @Overside\n    public void Show(){\n        System.out.println(\"展示男款衬衫\")；\n    }\n}\n​\n//step4:创建具体工厂类，定义创建具体产品实例的方法\n//具体工厂类A，展示女款衬衫类商品  \npublic class WomenShirtFactory extends Factory{\n   @Overside\n    public Shirt Exhibit(){\n        return new WomenShirt()；\n    }\n}\n//具体工厂类B，展示男款衬衫类商品\npublic class MenShirtFactory extends Factory{\n   @Overside\n    public Shirt Exhibit(){\n        return new MenShirt()；\n    }\n}\n​\n//step5:外界调用具体工厂类的方法，创建不同具体产品类的实例\npublic class FactoryPattern{\n    public static void main(String[] args){\n        //用户在店铺搜索女款衬衫\n        Factory exhibitWomenShirtFactory = new WomenShirtFactory();\n        exhibitWomenShirtFactory.Exhibit().Show();\n        \n        //用户在店铺搜索男款衬衫\n        Factory exhibitMenShirtFactory = new MenShirtFactory();\n        exhibitMenShirtFactory.Exhibit().Show();       \n    }\n}</code></p><p></p><p>结果输出</p><p></p><p><code lang=\"null\">展示女款衬衫\n展示男款衬衫</code></p><p></p><p>UML图</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2e/2ee4a170a4c9e25fc3250f4712428f9f.jpeg\" /></p><p></p><p></p><h3>优缺点</h3><p></p><p></p><p>优点</p><p></p><p>1）符合开闭原则。新增一种产品时，只需要增加相应的具体产品类和工厂子类即可，可方便的生产或切换产品，而无须像简单工厂模式那样修改工厂类的判断逻辑，具有更高的扩展性 。</p><p></p><p>2）符合单一职责原则。每个具体工厂类只负责创建对应的具体产品，而简单工厂中的工厂类存在复杂的switch逻辑判断。</p><p></p><p>3）相比于简单工厂模式，使用的不是静态方法，可形成基于继承的等级结构。</p><p></p><p>缺点</p><p></p><p>1）一个具体工厂只能创建一种具体产品。添加新产品时，除增加新产品类外，还要提供与之对应的具体工厂类，类的个数成对增加，在一定程度上增加了系统复杂度；同时有更多的类需要编译和运行，给系统带来额外开销。</p><p></p><p>2）由于考虑到系统的可扩展性，需要引入抽象层，在客户端代码中均使用抽象层进行定义，增加了系统的抽象性和理解难度，且在实现时可能需要用到DOM、反射等技术，增加了系统的实现难度。</p><p></p><p>3）虽然保证了工厂方法内的对修改关闭，但对于使用工厂方法的类，如果要更换另外一种产品，仍然需要修改实例化的具体工厂类。</p><p></p><p>4）难以对父类接口进行修改，因为一旦修改接口，就必须要对众多的帮忙子类进行修改。</p><p></p><p></p><h3>适用场景</h3><p></p><p></p><p>一个类不确定它所必须创建的对象的类。在工厂方法模式中，客户端不需要知道具体产品类的类名，只需要知道所对应的工厂即可。</p><p></p><p>你期望获得较高的扩展性。</p><p></p><p>一个类希望由它的子类来指定它所创建的对象。在工厂方法模式中，对于抽象工厂类只需提供一个创建产品的接口，而由其子类来确定具体要创建的对象，利用面向对象的多态性和里氏替换原则，在程序运行时，子类对象将覆盖父类对象，从而使系统更容易扩展。</p><p></p><p>当类将创建对象的职责委托给多个工厂子类的中的某一个，且用户知道将要使用哪一个工厂子类。</p><p></p><p></p><h2>2.3&nbsp;抽象工厂模式</h2><p></p><p></p><p>抽象工厂模式，提供一个创建一系列相关或相互依赖对象的接口，而无须指定它们的具体类。抽象工厂模式与工厂方法模式最大的区别：抽象工厂中每个具体工厂可以创建多类具体产品；而工厂方法每个具体工厂只能创建一类具体产品。</p><p></p><p></p><h3>结构</h3><p></p><p></p><p>工厂方法模式包含五种类，分别是抽象产品族类、抽象产品类、具体产品类、抽象工厂类、具体工厂类，下面分别对各类以及它们之间的关系作进一步说明：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a7/a7d4d52e02ad9fd282b6e70bfe8d4184.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e1/e177a473ae49e0e0af32826191b95dfe.jpeg\" /></p><p></p><p></p><h3>使用</h3><p></p><p></p><p>根据上述概念，下面将工厂方法模式的使用步骤概括如下：</p><p></p><p>step1：创建抽象工厂类，定义具体工厂的公共接口；step2：创建抽象产品族类，定义抽象产品的公共接口；step3：创建抽象产品类（继承抽象产品族类），定义具体产品的公共接口；step4：创建具体产品类（继承抽象产品类），定义生产的具体产品；step5：创建具体工厂类（继承抽象工厂类），定义创建相应具体产品实例的方法；step6：外界调用具体工厂类的方法，创建不同具体产品类的实例。</p><p></p><p>这里继续以网店销售服装举例，假设上述衬衫淘宝专卖店的运营总部还有一家裤子淘特专卖店，随着用户需求变化，淘宝用户也要购买裤子，同时淘特用户要购买衬衫，那么我们可以使用抽象工厂模式升级这两个店铺，令淘宝店铺展示销售衬衫+裤子，淘特店铺展示销售裤子+衬衫。</p><p></p><p>代码实现</p><p></p><p><code lang=\"null\">//step1:创建抽象工厂类，定义具体工厂的公共接口\npublic abstract class Factory{\n    public abstract Clothing ExhibitShirt();\n    public abstract Clothing ExhibitTrousers();\n}\n​\n//step2:创建抽象产品族类，定义抽象产品的公共接口\npublic abstract class Clothing{\n    public abstract void Show();\n}\n​\n//step3:创建抽象产品类，定义具体产品的公共接口\n//衬衫抽象类\npublic abstract class Shirt extends Clothing{\n    @Override\n    public abstract void Show();\n}\n//裤子抽象类\npublic abstract class Trousers extends Clothing{\n    @Override\n    public abstract void Show();\n}\n​\n//step4:创建具体产品类（继承抽象产品类），定义生产的具体产品\n//衬衫产品类A，淘宝衬衫\npublic class TBShirt extends Shirt{\n    @Override\n    public void Show(){\n        System.out.println(\"展示淘宝店铺衬衫\");\n    \n}\n//衬衫产品类B，淘特衬衫\npublic class TTShirt extends Shirt{\n    @Overside\n    public void Show(){\n        System.out.println(\"展示淘特店铺衬衫\")；\n    }\n}\n//裤子产品类A，淘宝裤子\npublic class TBTrousers extends Trousers{\n    @Override\n    public void Show(){\n        System.out.println(\"展示淘宝店铺裤子\");\n    }\n}\n//裤子产品类B，淘特裤子\npublic class TTTrousers extends Trousers{\n    @Overside\n    public void Show(){\n        System.out.println(\"展示淘特店铺裤子\")；\n    }\n}\n​\n//step5:创建具体工厂类，定义创建具体产品实例的方法\n//淘宝工厂类A，展示衬衫+裤子  \npublic class TBFactory extends Factory{\n    @Overside\n    public Clothing ExhibitShirt(){\n        return new TBShirt()；\n    }\n    @Overside\n    public Clothing ExhibitTrousers(){\n        return new TBTrousers()；\n    }\n}\n//淘特工厂类B，展示裤子+衬衫\npublic class TTFactory extends Factory{\n    @Overside\n    public Clothing ExhibitShirt(){\n        return new TTShirt()；\n    }\n    @Overside\n    public Clothing ExhibitTrousers(){\n        return new TTTrousers()；\n    }\n}\n​\n//step6:外界实例化具体工厂类，调用工厂类中创建不同目标产品的方法，创建不同具体产品类的实例\npublic class AbstractFactoryPattern{\n    public static void main(String[] args){\n        TBFactory exhibitTBFactory = new TBFactory();\n        TTFactory exhibitTTFactory = new TTFactory();\n        //淘宝用户搜索衬衫\n        exhibitTBFactory.ExhibitShirt().Show();\n        //淘宝用户搜索衬衫\n        exhibitTBFactory.ExhibitTrousers().Show();\n        //淘特用户搜索衬衫\n        exhibitTTFactory.ExhibitShirt().Show();\n        //淘特用户搜索衬衫\n        exhibitTTFactory.ExhibitTrousers().Show();     \n    }\n}</code></p><p></p><p>结果输出</p><p></p><p><code lang=\"null\">展示淘宝店铺衬衫\n展示淘宝店铺裤子\n展示淘特店铺衬衫\n展示淘特店铺裤子</code></p><p></p><p>UML图</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/52/521109d65b12c9c975d3c0d707035a69.jpeg\" /></p><p></p><p></p><h3>优缺点</h3><p></p><p></p><p>优点</p><p></p><p>1）降低耦合度。抽象工厂模式将具体产品的创建延迟到具体工厂类中，这样将对象的创建封装起来，可以减少客户端与具体产品类之间的依赖，从而降低系统耦合度，有利于后期的维护和扩展。</p><p></p><p>2）符合开闭原则。新增一种产品类时，只需增加相应的具体产品类和工厂子类即可，简单工厂模式需要修改工厂类的判断逻辑。</p><p></p><p>3）符合单一职责原则。每个具体工厂类只负责创建对应的产品，简单工厂模式中的工厂类需要进行复杂的 switch 逻辑判断。</p><p></p><p>4）不使用静态工厂方法，可以形成基于继承的等级结构。</p><p></p><p>5）便于添加更换产品族。因为具体产品都是由具体工厂创建的，所以在更换产品族的时候只要简单修改具体工厂即可。</p><p></p><p>6）具体产品的创建过程和客户端隔离。客户端通过操作抽象产品接口实现操作具体产品实例，具体产品的类名不会出现在客户端中。</p><p></p><p>缺点</p><p></p><p>1）难以支持新种类产品的变化。这是因为抽象工厂接口中已经确定了可被创建的产品集合，如果需要添加新产品，此时就必须去添加抽象产品接口，还要在抽象工厂接口中添加新方法，并在所有具体工厂中实现该新方法。这样就会改变抽象工厂类以及所有具体工厂子类的改变，违背开闭原则。</p><p></p><p>2）类图有点复杂，可读性没有工厂方法模式高。</p><p></p><p></p><h3>适用场景</h3><p></p><p></p><p>系统不要求依赖产品类实例如何被创建、组合和表达，这点也是所有工厂模式应用的前提。系统要求提供一个产品类的库，所有产品以同样的接口出现，客户端不需要依赖具体实现。系统中有多个产品族，但每次只使用其中某一族产品。（切换产品族只需修改具体工厂对象即可）</p><p></p><p></p><h1>三、总结</h1><p></p><p></p><p>简单工厂模式：让一个工厂类负责创建所有对象；但没有考虑后期扩展和维护，修改违背开闭原则，静态方法不能被继承。</p><p></p><p>工厂方法模式：主要思想是继承，修改符合开闭原则；但每个工厂只能创建一种类型的产品。</p><p></p><p>抽象工厂模式：主要思想是组合，本质是产品族，实际包含了很多工厂方法，修改符合开闭原则；但只适用于增加同类工厂这种横向扩展需求，不适合新增功能方法这种纵向扩展。</p><p></p><p>其实这三种工厂模式在形式和特点上都非常相似，甚至存在一定的内在联系，而且最终目的都是解耦。在使用时，我们不必去在意这个模式到底工厂方法模式还是抽象工厂模式，因为它们之间也是可以灵活转变的。</p><p></p><p>比如你原本使用的是工厂方法模式，加入一个新方法后就可能会让具体产品类构成不同等级结构中的产品族，代码结构就变成抽象工厂模式了；而对于抽象工厂模式，当减少一个或多个具体产品类时，使原有产品族只剩下一个产品后，代码结构也就转变成了工厂方法模式。</p>",
    "publish_time": "2023-05-25 14:53:44",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "作业帮多云多活架构的探索和实践",
    "url": "https://www.infoq.cn/article/k4E7IXHOgihMNSEoUz9w",
    "summary": "<p>在前段时间，作业帮基础架构负责人董晓聪在 <a href=\"https://archsummit.infoq.cn/2023/shenzhen/\">ArchSummit 架构师峰会</a>\"上介绍了多云多活架构探索话题，引起了现场观众的热议，大家对作业帮多云架构方案选型、技术体系各层建设很感兴趣，现场听众和董晓聪积极互动交流。</p><p>&nbsp;</p><p>以下是演讲实录，介绍作业帮为什么要进行多云架构探索，多云架构模式的选择，以及架构的各个层次建设实践经验。</p><p></p><p>作业帮成立于 2015 年，是一家致力于用科技手段助力普惠教育的公司。公司主要大的业务板块可以分成两块，一块是作业帮App，是一款面向于 K12 的学习辅助工具平台，是一款典型的流量互联网的产品。另一块是作业帮直播课，典型的产业互联网的产品，涵盖了教育的诸多链条，如教研、教务、教学、辅导等。除此之外，公司在智能硬件等一些其他方面也有一些积极的探索和布局。</p><p></p><p>了解完作业帮业务特点，我们再来看作业帮的技术现状。作业帮的技术状况可以归纳为两点，规模化和复杂化。规模化是指作业帮的线上服务数量比较多，有数千个。这么多的服务又对应数万的服务实例，这么多的服务实例是跑在数十万的计算核心之上，整体的规模相对是比较大。</p><p>&nbsp;</p><p>复杂化这块是指作业帮的技术栈比较的多元。在虚机架构时代，在线业务以 PHP 为主要的语言，通过云原生改造，开始以 Golang 为主要的开发语言。但是除了这两门语言，像 Python、NodeJS、Java、C++以及 Lua等语言在一些场景里面也有广泛的分布，整体的技术栈特别的多元。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ef/efdeb05aa60bf028ba31fc5b954e20c3.png\" /></p><p></p><p>作业帮从创立之初就base在云之上，也充分享受了云计算的红利。但是随着业务的发展，我们慢慢遇到了单云架构的瓶颈，它主要集中在稳定性和成本这两方面。先来讲一下稳定性，这么多年随着国内云厂商技术的不断地发展，其稳定性可以达到很高的水平，但仍会出现一些零星的故障，这些故障对企业的经营会造成一定的影响，而作业帮对稳定性要求是比较高的，在我看来甚至可以用苛刻来形容。我之前在传统的互联网以及互联网金融行业都有待过，在我看来作业帮对稳定性的要求是最高的。</p><p></p><p>为什么会这样？我总结如下的原因，就是我们原来在传统的互联网，虽然一直在强调用户体验至上，但我们实际上离用户是比较远的，用户在我们眼里更多还是 UV、PV 这样的数字。而在线教育不一样，我们的辅导老师通过实时音视频的技术和用户是面对面的在一起，用户的任何问题可以更直接真切地反馈到我们这边来。再有教育是对连贯性要求比较高的场景，我们的服务时间又聚焦在每天的一两个小时里面，任意分钟级别的故障都可能会对学生的学业造成巨大的影响，所以我们对稳定性的要求只能更高，单机群多实例、单云多可用区远远无法满足我们对稳定性的追求。</p><p></p><p>再来讲一下成本这个方面，云服务成本在各大互联网公司里面也是居于成本支出的top。尤其是近几年，这个问题就会更加凸显出来。相信不少管理者，大家在近半年到一年里面都会面临的这样选择，你到底是去优化服务器还是去缩减人头。相信大家的选择更多还是想通过用技术的方案去进行降本，而在云服务这里，企业想持续的享受到物美价廉的服务，就需要有两家及以上的供应商。基于以上这些原因，所以作业帮开始探索多云架构。</p><p>&nbsp;</p><p>那么什么是多云架构？我们可以这样来定义，如果一家企业它使用了两家及以上的 IaaS 或 PaaS 的供应商，我们就可以称它的架构为多云架构。广义来看，混合云也是属于多云的范畴。多云架构有什么优势？除了我们前面讲到的稳定性和成本优势外，还有数据主权、特殊服务访问的优势。</p><p></p><p>数据主权就是企业为了保护不同用户群体的数据安全而做的多云选择，后面也会有详细示例的讲解。然后再就是特殊服务访问，这个比较好理解，每个云上都会有一些比较优势的服务，比如像阿里云的 Hologres，在大数据实时计算这里就是一款有竞争力的一款产品。以上就是多云的一些优势，那么多云的它的构建的模式是单一的吗？是固定的吗？我们通过跟多家云厂商、企业的交流，发现多云的模式可以定义为如下几种。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f0/f08c6b8c61b95a692d3214df0045d50e.png\" /></p><p></p><p>第一种的话就是主备模式，我们能看到左侧这边是互联网的通用架构。用户的流量通过 DNS 的调度，到达云机房的网络接入层，再路由到对应的服务。再经过一系列微服务的调用，最终会落到对数据存储的请求。选择主备模式，就是企业将数据库备份以及对象存储的归档，开始存储到另外一家云上，可能还会有一些基于此的衍生计算。选择主备模式最直接的好处就是，当原有的云机房出现了不可恢复的故障的时候，企业不至于血本无归，至少数据是可以恢复的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ab/abc1248f51062ff9b77a3bccd0a11275.png\" /></p><p></p><p>第二个是弹性模式，这个模式是企业往前又更进了一步，不光是把一些数据存储放到另外一家云上，也开始把一些核心服务部署在另外一家云上。在这种模式下，通过 DNS 流量调度就可实现流量的调度。主要的应用场景是什么呢？互联网业务都有明显的波峰跟波谷，波峰的资源使用量可能是波谷的一倍、两倍、数倍，甚至是几个数量级的差异。而企业一直在为波峰买单，并不划算。这个时候有一家新的云厂商愿意以比较合适的价格来去承担部分弹性的流量。比如像峰值 30% 的容量，这样原机房只需要去维持 70% 的容量，整体的资源利用率就可以得到极大的提升。再有就是通过弹性云可以承担一部分非预期的流量，更好地为业务保驾护航。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b1/b1565bc4502596963d7392fba5f77668.png\" /></p><p></p><p>再有就是业务切分的模式，大多数公司会有统一的部门来去承接基础设施，但是有些公司因为经营考虑，使用了事业部或者是子公司的模式。在这种模式下，子公司又会因为商务策略的考虑，去选择不同的云厂商。不同业务使用的是不同域名，通过 DNS 调度就可以将其路由到不同的云机房，以此实现流量的分发。在这种模式下，虽然企业应用了多云，但是之前期望的稳定性的收益就相对较少了。在这种模式下，不同云上的服务跟数据是不一样的，只有把所有云上的数据跟服务集中在一起才是完整的一份。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e4/e4f377f4581401cbe91d570efd19d7fb.png\" /></p><p></p><p>下面讲一下数据主权模式，前面讲了它的定义，现在再来举下具体的例子。相信大家都或多或少接触过一些出海的业务。当这些出海业务做得比较大之后，就会受到当地的政府的数据合规的一些要求，比如像欧盟、美国，它都会要求企业必须把用户的核心数据存储在本国，这样的话就会导致数据出现了分区，更有甚者对企业所使用的云厂商也有一定要求，以此形成了数据主权的多云。在一些私有化交付的项目里面，也会出现一些类似的情景。在数据主权多云模式下，每个云上的服务是一模一样的，表结构也都是一样的，但数据是有不同的，只有所有云上的数据组合起来才是企业完整的数据。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/59/590bb062f900b37d01896d43f840fcce.png\" /></p><p></p><p>最后讲一下多活模式，通过 DNS 的流量分配，将不同比例的流量分配到不同的云机房。在每云机房里面，实现所有服务的对等部署以及流量的完整的闭环。当某个云出现故障的时候，企业只需要通过DNS把用户流量调度走即可。</p><p></p><p>多活模式是稳定性跟成本最理想的方案，那企业应该在所有的场景下都去选择这种方案吗？其实并不是，像多活这个模式，其实是有技术挑战的，它的技术挑战主要集中在稳定性、成本和效率。说到这里大家也可能比较奇怪，刚才我们提到了多活模式是稳定性跟成本的最优选择，为什么它会又会有稳定性跟成本的问题呢？首先我们要明确一个原则，就是复杂性不会平白无故的消失，而只是被转移了。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/28/288c68a3bc0d4aa9ac63b6e7ebba3f81.png\" /></p><p></p><p>多活架构能够带来这么多的好处，在于它对架构本身的要求特别高，单云的等量部署以及服务闭环还是很难实现的事情。如果个企业只有几十个服务或者小几百个服务的话，通过人工的方式还是可以达成的。如果企业的服务数量比较多，大几百个，上几千个，落地的难度就会很大。大家可以想象一下，在几千个服务的情况下，核心链路就会涉及到几十、上百个的服务，而在这些服务当中只要有任意服务，只做了单云部署而没有做多云部署，那么就会导致多云架构的稳定性可能还不如单云架构。最坏情况下整体的故障率不是每个云故障率的乘积，而是每个云的故障率的之和。再有就是多云之间架设的网络，肯定没有云厂商 region 与 region 之间的网络质量更高，所以数据脑裂的可能性也会是加剧。</p><p></p><p>正是由于稳定性达不到很高的标准，所以业务方就只能去加大冗余。在原来单云架构下，服务只需要部署100%的容量。在采用多云架构后，每个云应该有 50%或者60%的容量，但是因为稳定性做不到，所以业务就会在每个云上加大冗余，如部署 80% 的容量。这样整体的资源使用量就会较之前多出不少，造成成本的浪费。</p><p></p><p>效率方面，多活模式就是要把不同云的管控面拉齐。虽然云厂商的提供的IaaS能力看上去一样，如 LB、Nat、VPC、EIP 等等，但实际上还是有功能差异的。为了实现相同效果，可能一个云上只需要一款产品即可，而另外云需要两个产品结合才能去实现类似的效果。多云管控平台就要对上游屏蔽这种差异。为了实现不同云服务的等量部署，完整闭环，很多特化服务就不再能使用了。再有就是商务谈判和云服务运维也会随着云厂商的增加而同比增加。</p><p></p><p>虽然有这些困难，但作业帮还是坚定的选择走多活多云的路线。我们整体的架构全貌可以归纳为以下。大的架构层次可以分为应用层和资源层。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bb/bb0689ddd87d08100d09b7c3bd7e75f3.png\" /></p><p></p><p>资源层的话包含计算、存储、网络。以 Docker + K8s 为代表的容器技术，通过容器镜像、作业编排、作业调度、资源管理，实现底层资源对上层应用的透明。上层的应用层又可以分成基础组件和业务应用。基础组件包括各种数据存储、网关、消息队列、大数据、安全等组件。上层的业务应用想要跑得更快，还需要一层服务治理的体系，整体的服务治理体系以服务的注册发现为基础，包含服务通信、服务观测以及流量管控。在作业帮的多云架构里面，每一层次每一实体都会有涉及，今天只选取一些相对比较重点的，跟大家一起分享，它们分别是资源层的网络以及基础组件中的数据存储，还有东西向流量治理。</p><p></p><p>网络是多云互联互通的基础。作业帮早期也走了一些弯路，最终我们选择了多云组网的方案。链路层面有多方面冗余。我们在不同方位接入两家专线供应商。一边是在亦庄方位接入，而另一边是在顺义方位连通。在这两条链路上，我们通过BGP+ECMP实现了链路的负载均衡，以及当单条线路出现故障的时候，可以实现秒级别的自动切换。在这样的网络架构中只有专线供应商和云厂商的网络设备，我们缺乏感知和管控的能力。所以我们在专线供应商的接入处租用了CPE设备，实现更好的感知和管控。这个CPE设备在云故障演练、跨云流量排查等方面发挥的重要作用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/97/9722b4fc6bbfcdfe0f200070e694e4a7.png\" /></p><p></p><p>提到数据存储，就不能不说经典的CAP理论。讲的是在分布式系统中一致性、可用性和分区容错这些能力不能同时具备。要么不接收分区容错，退化为单机系统，选择CA。要么，追求强一致性，选择CP。要么保证服务可用，选择AP。那么在企业具体业务场景中我们是应该进行怎样的选择呢。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/89/8924bf8a997a649266082f3953bb023f.png\" /></p><p></p><p>结合 MySQL 的经典主从架构来介绍一下，像 Redis ES 也是是类似的方案。业务应用不是直接去访问数据存储的 cluster 节点，而是通过数据存储的 Proxy 中间件去进行访问。通过数据存储的 Proxy 有如下优势？可以对上游屏蔽底下的细节，提升了易用性、扩展性以及稳定性。在数据存储的中间件中有较为丰富的路由策略，对于写流量，都是路由到主库。对于读请求，会根据底下从节点的负载情况、主从延时情况进行流量的分发。当主从延时超过一定程度的时候，会把这个从节点从proxy中摘除。除了上述数据链路中的保证外，还会有 HA 的一套方案去检测主节点，以实现故障时的自动切换。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2d/2dd32bca3830615fdf05e938375944e7.png\" /></p><p></p><p>在这样相同的架构模式下，也会因为业务的不同选择而呈现出不同的 CAP 的选型。对于交易的核心链路，它对一致性要求比较高，很多读请求不能接受延时，所以业务上进行强制读主，保证一致性和可用性。在这种情况下，事实上已经退化成主备的模式，也就是 CA 的模式。而大多数业务都要追求可用性，选择 AP 的模式，以作业帮 APP 的批改场景为例，有两块核心的数据，一块是用户批改的历史记录，另一块是题库的数据。用户的批改记录在客户端上有一定的缓存。而题库数据是通过生产工艺生产出来的，本身就不是那么的实时。所以这样的业务场景中，如果主库出现了故障，或者是主从间出现了同步延时，在一两个小时的况下，从库完全不需要摘除，照样可以给业务给用户提供较稳定的服务。</p><p></p><p>上面讲的这些选型更多还是在系统的故障时候的自动选择，在真正出现故障的时候，我们还会通过人工介入去缩短故障影响时间。当从库出现问题的情况，将流量调度到主库所在的云上。而当主库所在的云出现故障的话，先将从库进行提主，然后再进行流量的切换，虽然可能会带来一部分用户数据的不一致，但可以为绝大多数用户提供正常服务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3b/3b84bb91c64db42a98bde9346e23c8fb.png\" /></p><p></p><p>再来讲一下单元化的架构，整体的架构和上面提到的类似，不一样点是在这单元里面，读写请求都是闭环的，不会去跨单元请求。如果只是这样，每个单元就只有自己的数据了。再通过 DTS 就可以把其他单元的差量数据同步过来，这样每个单元就具备全量的数据。多数公司在做单元化的时候，会优先选择 Passport 这样的业务。因为 Passport 有这么几点好处：</p><p></p><p>一、它是所有用户产品业务的基础，其他业务想要去做单元化都会对 Passport 有依赖。</p><p>二、Passport 天然可按照用户 ID 进行切分。</p><p>三、Passport的提交并发量比较低，不管是用户登陆还是信息修改都不是高频操作。</p><p></p><p>所以哪怕按照地域去进行单元化问题也不大，也不会产生冲突。而作业帮选择的场景不同，我们选择了直播课课堂和运维平台两个场景。直播课堂是天然按照业务单元进行切分的。在单个课堂内，师生之间是需要做强互动，但在不同课堂间不需要有在线的交互，只需要有离线的大数据统一的汇总分析即可。</p><p></p><p>再有一块就是运维平台，我们通过单元化来提升整体的稳定性。当我们出现单云故障的时候，我们要通过 DNS 或者自研 DoH 去调度流量调度 。由于域名众多，我们使用自建的预案平台进行操作。预案平台除了和云厂商API交互外，还有自身的权威数据。如果这个数据存储选择了主从的架构，当真正出现故障的时候，故障止损还要先依赖于 DBA 进行预案平台的主从切换，然后才能够去执行预案，这样就就串行依赖了，故障恢复的时间就会被大大的拉长。所以在这块我们通过单元化的方案，每一边都是可以进行预案操作的，大大缩短了故障的影响时间。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d9/d9c6c259ea25b133aca77e2a82224bc6.png\" /></p><p></p><p>最后介绍下东西向流量治理，这块也是最复杂的，多数公司的技术选型也是从这里开始出现差异的。作业帮在虚机架构的时候就开始探索多云架构，将核心服务部署到另一家云厂商上。但存在较多问题，如服务很难做到对等的部署，虚机的部署成本较高，维护成本，如调整容量等成本也较高。所以运维和研发较难维持下去。再者，有部分服务只能单例部署。服务无法做到对等部署后，流量自然做不到单云闭环。除了部署的问题外，以下问题也是阻碍流量闭环的原因。如服务注册发现机制的不统一，作业帮有名字服务，但因为多语言栈支持的不够友好，如 NodeJS、Python 等语言就直接选择 DNS+LB 的方式来进行负载均衡，绕过统一的注册发现机制。</p><p></p><p>在流量治理这块还面临一个问题，一方面我们是希望跨云流量能从架构层面被严格约束起来，但另一方面，因为上述诸多问题，又要具备临时或永久的灵活跨云调度能力。一定程度上是矛盾的。在部署和流量治理上均不到完美的情况下，多数企业会选择通过演练，以 QA 的验收来达成多云多活的效果。作业帮早期也是选择的这条方案。但实践了几次后发现这条道路很难走通。通过全公司级别的演练来发现核心链路中的跨云问题，成本过高。而且业务是在不断迭代的，解决了这块，又会引入新的问题，墒增的问题无法避免。即使可控制到单部门的演练，问题依旧存在。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/38/38312efdf7154738f0a4851b7e182153.png\" /></p><p></p><p>作业帮针对这块设计了一套理想方案，我们将一个云上的应用分成两部分，一部分是互通区域，另一部分是受限区域。两者的不同在于，互通区域中的应用可以做跨云通信，而受限区的服务不可以，只能通过互通区域中转。将业务应用都放置到受限区域，互通区域都是基础架构提供或者认证的组件。这样就可以实现灵活性和严格性的兼容。以业务服务 RPC 调用为例子，两个云上的业务服务无法直接通信，而是需要在云上的东西向网关配置发现规则，才能实现通信。在此架构下，我们允许允许一定程度的不对等部署、跨云流量但一切都要在基础架构框架内，可感知、可管控。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dd/dd97c02da4d2cb81b911f11c60b69981.png\" /></p><p></p><p>好的服务注册发现机制的选择可以大幅度避免跨云的流量，当这个问题量级缩小一到两个数量级后，我们治理的难度也会大幅到下降。治理的第一步就是能够度量这些跨云的流量。由于PHP、Golang 都是走标准框架的，我们早期通过服务 RPC 配置来度量。但对于小众语言栈和不规范的服务通信方式就无能为力了。我们在多云专线间上线 CPE 后，通过 CPE 这个管控面就可以获取五元组数据。但由于容器 Pod IP 是变化的，对于分析 IP 具体是哪一个服务有一定困难。所以我们结合上了 EBPF 。作业帮上线容器集群的所有机器内核更新到5.10及以上，利用 EBPF 的特性，我们可以获取所有网络包的信息，再结合 etcd 当中的服务注册信息，就可以反解出服务名。通过多维度数据组合，就能最大程度上度量出跨云的流量。</p><p></p><p>跨云治理是一个较漫长的工作，需要有完备的平台支撑，避免一次性的任务。所以我们也开发了对应的平台，向研发开放，方便其自行优化。而基础架构关注top的跨云流量治理进度。当跨云流量治理到一个相对较低的水平后，就要将大坝合拢，做常态化断网。从 CPE 上做 ACL 策略，禁止容器应用网段的通信。对于长尾的虚机服务，在其入向的安全组做流量拦截。在这种网络架构下，业务的跨云流量就只能通过我们指定的通路，东西向网关来流转了。墒增的问题得到根本性的治理。</p><p></p><p>最后就是这套架构的持续运营了，对于短时间无法改造完的，我们持续跟进其进度，逐步将其从跨云白名单剔除。对于业务临时的需求，明确原由后，添加临时的白名单。完成这种架构后，作业帮仍会进行周期的断网演练，但不再需要一个月那么频繁，半年进行一次即可，主要用来发现架构的隐藏问题以及预案的执行流程。以上的话就是作业帮多云架构的整体建设，我们又是如何将建设的成果应用于具体的实战当中。首先就是我们多云的迁移能力得到了大幅度的提升。在刨除冷启动外，几千个服务，包括对应的数据存储，我们可在 3 个月之内迁移到一朵新的云上。具体迁移的 SOP 可以划分为以下几点。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d0/d0ac9db38d70b1e18ec7e0b74fc5d4ad.png\" /></p><p></p><p>第一块的话就是冷启动，我们要在数据面以及控制面上跟新的云厂商去磨合标准，具体选择哪几款主力机型？作业帮对 K8s、内核、Serverless 都有一些自己的一些要求，需要云厂商进行一定的适配。在控制面上，除了对接管控 API 外，很重要的一块就是账单 API 的对接，不然这后续对账的成本就会居高不下。接下来就开始服务的部署。整个服务部署的流量也是按照 IaaS、PaaS、SaaS 逐层开展。先去规划好对应的网络、VPC，设置对应的 LB、NAT 等，准备好相关的机器，然后进行数据存储的迁移，因为数据的规模较大，整个同步的周期也较长。在数据同步快接近尾声的时候开始去进行其他组件部署，不管是 K8s 的各种插件、网关、消息队列等等。完成这些之后开始进行业务服务的部署。</p><p></p><p>这一切准备好后，就要开始进行流量的迁移了。首先验证的自测流量，既要通过功能测试，也要保证通过性能压测，保障新云服务的稳定性。下一步就是通过 DoH/DNS 等机制逐步放量，1%、10%、20%等等。最终完成预期流量迁移。这一切完成后，两边运行一段时间后，就要开始进行收尾治理，将老云当中的冗余流量逐步下掉。至此才算是迁云完满达成。上面讲的是迁移一朵新云的 SOP，我们更多时候是做不同云上的流量调度，这个的话基本上几天就可以完成。正是因为有了这样的能力，所以作业帮才可以持续地享受到物美价廉的云服务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/26/26dbf9feac6567f0bf6a6ae57196f9bd.png\" /></p><p></p><p>再来介绍下单云故障演练。只有在演练中能达标，面对真正故障时才能更有底气。故障模拟要尽量的真实，单云故障就要做到既不能接收到南北向的用户流量，也无法东西向和其他云进行通信。为了避免影响用户，我们将南北向用户的模拟限定在工区。在云机房1的接入层拒止作业帮工区的流量，这样就可以模拟出用户无法访问云机房1。然后在 CPE 添加 ACL 策略，拒止云机房1和云机房2的通信，这样就模拟出东西向的故障。这里还有一个待完善点，我们只是把应用层的东西向流量禁止了，数据存储间的流量还是先豁免了，主从间仍可以同步。不然就会带来脑裂的问题。为了一次故障演练，修复上千个集群的数据成本还是太高。</p><p>&nbsp;</p><p>整个故障注入的操作和生效时间控制在5min内。完成之后开启第二步，执行预案。通过预案平台将作业帮的流量全都指向到云机房2。预案平台有不同机房的入口地址，数据存储也选择的单元化模式，这样运维不需要前置环节就可以直接操作预案。5分钟内完成业务域名的切流。10分钟内实现P90流量的收敛。测试就可以开始进行功能回归了，主要针对F0、F1功能，一般1-2小时就可以完成，研发在过程中关注相关报警。当顺利完成一边云的验证后，再重复整个流程，模拟云机房2故障的情况。通过故障的演练，有效保障我们的SLA，系统的稳定性得到大幅度提升。时至今日，作业帮的多云架构仍在持续迭代当中。我们下一步的展望主要聚焦在以下几个方面：</p><p>&nbsp;</p><p>单元化的进一步深入。当主库所在的云出现故障时，还需要进行数据存储的提主操作，这个操作本身较重。而单元化是更优的解法。阿里这块的建设还是走的比较前沿，交易链路中库存数据也实现了单元化改造。不断精细化控制爆炸半径，让故障演练更加的真实，将数据存储也能参与进来。应用服务可以按照部门来快速展开。服务感知体系的单元化改造。这个在真正故障的时候至关重要，当前监控已实现了分区，链路追踪、日志等也在规划当中。</p><p>&nbsp;</p><p>【活动推荐】</p><p></p><p>7 月 21 - 22 日，<a href=\"https://archsummit.infoq.cn/2023/shenzhen/\">ArchSummit（深圳站）全球架构师峰会</a>\"，将在深圳·博林天瑞喜来登酒店举办，会议将围绕架构技术实践展开分享，例如：智能化数据治理、可持续软件、DataOps、Data Fabric 等高效数据开发与服务模式、Mesh 技术实践案例、QUIC 传输和架构优化、跨境数据安全与合规等。</p><p></p><p>现在购票，享八折优惠，立减 ¥1760，咨询购票可联系：18514549229</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/c7/d2/c7e682d386f62f3685fcc149d3b612d2.jpg\" /></p><p></p>",
    "publish_time": "2023-05-25 15:21:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "倒计时4天，稳保行动·深圳站沙龙完整日程公布！",
    "url": "https://www.infoq.cn/article/KpVAKEbFK7cNQti5tDgf",
    "summary": "<p>由中国信通院混沌工程实验室主办，华为云计算有限公司、腾讯云计算(北京)有限责任公司协办的混沌工程实验室深圳站沙龙即将于2023年5月27日9:30隆重举行。</p><p></p><p>本文发布完整活动日程，供参会者参考。</p><p></p><p>中国信通院自2020年起开始研究稳定性保障工作，并构建了以可观测性、混沌工程、SRE等关键技术为代表的行业标准体系，从稳定性建设者、稳定性赋能者以及云服务稳定运行能力三个维度，为企业系统稳定性保障能力建设起到了重要推动作用；基于以上研究成果支持了工信部稳定运行政策文件的制定，全程全面支撑工信部在全国范围内推行的“稳保行动”，推广“稳定性保障”方法论；与此同时，中国信通院还持续服务行业，搭建技术交流平台，举办稳保主题沙龙，提升企业价值。</p><p>深圳站沙龙将深入探索业务系统的稳定行保障，提升业务系统韧性。沙龙邀请了国内多个行业的头部企业和社区的系统稳定性专家参与，为参会者搭建了交流学习平台，以期共同交流实践经验，提升行业内对系统稳定性的认知和实践。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d0/d0315619b3a8f38a45611751b2c03fa4.jpeg\" /></p><p></p><p>本次活动内涵丰富，亮点突出，从多个角度诠释了“稳保”这一主题：</p><p></p><p>01.资深专家云集，突围业务发展瓶颈</p><p>本次活动行业专家云集，华为云、腾讯云等多位知名企业专家将就混沌工程、可观测性、SRE等热点议题展开深入探讨，共谋发展良策，交流技术经验，突围业务发展瓶颈。</p><p></p><p>02.活动丰富，多维度涵盖稳定性保障领域热点</p><p>本次活动内容丰富多彩，共设有7个议题和1场圆桌讨论，涵盖了多个关键领域。我们将从多个维度对国家政策和行业关注的热点进行深入解读，旨在打造一场最具前瞻性和青年朝气的行业活动。</p><p></p><p>03.多家知名企业参与，引领产学研用合作发展生态</p><p>本次活动上，来自金蝶、货拉拉、平安银行、安信证券等多行业用户代表，他们将带来最新的“稳保”实践成果，启发行业发展新趋势。</p><p></p><p></p><p>线下参会者将有机会获赠“深圳站”勋章及中国信通院“稳保”系列研究报告，欢迎报名！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/19/19d3ef1e2ee09f5bc7837959365bf10b.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4c/4c2211bfd59d9144e039790729870c35.png\" /></p><p></p><p>相关工作请联系：</p><p>中国信通院&nbsp;云大所&nbsp;云计算部</p><p>王老师&nbsp;wanghaiqing@caict.ac.cn</p><p>高老师&nbsp;gaojixiang@caict.ac.cn</p><p></p><p></p><p>混沌工程实验室 简介</p><p></p><p>混沌工程实验室由中国信通院牵头成立于2021年，目前已经吸引近百家成员加入。混沌工程实验室以保障企业云上系统稳定性、提升服务连续性、促进业务高质量发展为目标，构建了针对稳定性建设者、稳定性赋能者以及云服务稳定运行能力的稳定性保障标准体系，为我国系统稳定性保障能力建设起到了重要推动作用。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/18/18930086910846d0fb158eb3e1339a50.jpeg\" /></p><p></p>",
    "publish_time": "2023-05-25 15:31:15",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]