[
  {
    "title": "构建可持续架构的三大秘籍",
    "url": "https://www.infoq.cn/article/2U4xKaxTl3ftG4WI4jEs",
    "summary": "<p>软件工程师必须在已经做出架构决策的情况下才能进行开发。我们可以在新的微服务中使用Python而不是Java吗？在开发新的前端库时，我们可以使用另一个捆绑器吗？我是否应该与经理或其他团队在代码库结构问题上达成一致？</p><p></p><p>在设计REST API时应该使用snake_case还是camelCase来命名API？公司需要建立一个明确的框架来做出这些决策、需要谁参与，以及在哪里可以找到关于已经做出的决策的信息。</p><p></p><p>制定一个正确的框架非常重要，因为它将定义不同的团队将拥有多大程度的自由和自主权。这应该与公司在特定阶段试图建立的业务需求和公司文化相一致。</p><p></p><p>这可能会影响人们如何看待不同的领导角色、经理和个人贡献者在技术决策中的作用，以及不同职业级别的赋能水平。不同的公司需要根据其组织边界、成熟度和需求选择不同的负责人和不同程度的团队自主权，但框架应该提供非常相似的构建块。</p><p></p><p>在本文中，我将基于最近在不同规模的组织中工作的经验分享用来制定架构决策的框架应该提供的关键构建块。这些构建块包括内部技术雷达、技术标准和架构决策记录（ADR）。</p><p></p><p></p><h1>建立自己的技术雷达</h1><p></p><p></p><p>有些人可能知道Thoughtworks，他们建立了自己的<a href=\"https://www.thoughtworks.com/radar?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODQ0ODY0OTcsImZpbGVHVUlEIjoicVV2TUFPSUl3c0V6ck1sNSIsImlhdCI6MTY4NDQ4NjE5NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.-DRomq4lUleBIOWsVGq38sCGHfirSIlBRdrIMxe_lZc\">技术雷达</a>\"。Thoughtworks与行业内的客户一起捕获和发布他们所看到的东西。</p><p></p><p>类似地，你也可以<a href=\"https://www.thoughtworks.com/radar/byor?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODQ0ODY0OTcsImZpbGVHVUlEIjoicVV2TUFPSUl3c0V6ck1sNSIsImlhdCI6MTY4NDQ4NjE5NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.-DRomq4lUleBIOWsVGq38sCGHfirSIlBRdrIMxe_lZc\">建立自己的技术雷达</a>\"，用于捕获公司使用或计划使用的不同的技术、工具和方法的成熟度。技术雷达是公司当前正在使用和期望使用的技术栈的可视化表示。</p><p></p><p>你需要定义不同的阶段——评估、试验、采用和保留，以及技术应该如何经历这些阶段的过程。</p><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/65/65fae12cb5aa90efcc163670247ed4d7.webp\" /></p><p></p><p><a href=\"https://radar.thoughtworks.com/?sheetId=https%3A%2F%2Fraw.githubusercontent.com%2Fhey-car%2Ftech-radar%2Fmaster%2Ftech-radar.csv&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODQ0ODY0OTcsImZpbGVHVUlEIjoicVV2TUFPSUl3c0V6ck1sNSIsImlhdCI6MTY4NDQ4NjE5NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.-DRomq4lUleBIOWsVGq38sCGHfirSIlBRdrIMxe_lZc\">heycar的技术雷达示例</a>\"</p><p></p><p>在heycar，我们定义了以下这些阶段。首先，新技术处于评估（Assess）阶段，也就是说它们正在被评估。我们在评估阶段进行概念验证（PoC），并生成在我们的环境中使用这些技术的优缺点清单。然后，我们与各自的内部团队或可能与之发生交互的团队讨论结果。如果论证清单和概念验证足够令人信服，那么下一步就进入可控的试验期。在试验期，新技术只被用于生产环境的单一用例。如果这一步成功，我们就宣布新技术已被采用，并为其他团队的进一步使用打开绿灯。如果新技术取代了以前使用的技术，可能需要发出信号。于是我们定义了“保留（Hold）”阶段——对于那么不打算再使用并且有了替代方案的技术。</p><p></p><p>技术雷达可以帮助团队了解技术前景，并就使用哪些技术做出明智的决策。如果你保持技术雷达是最新的，公司里的每一个人就都会知道正在使用的技术的最新状态及其对业务的影响。</p><p></p><p></p><h1>引入内部技术标准</h1><p></p><p></p><p>第二个部分是引入技术标准。技术雷达捕获技术、平台、工具、语言和框架，以及它们在整个组织中的采用程度，但这些可能还无法满足所有的需求。为系统的不同部分建立一致的实践会有所裨益。例如，你可能希望所有的日志都使用相同的格式，并包含相同的信息。或者，如果你正在使用REST API，可能想要一些关于API设计和使用的约定，比如使用什么标头或如何命名。此外，如果你正在使用多种类似的技术，那么为何时该使用何种技术提供指导可能会很有帮助。技术标准定义了在公司内部选择和使用技术的规则。它们确保了一致性，降低以次优方式采用新技术所带来的风险，并在整个组织范围内推动保持一致性。</p><p></p><p>应该由谁来负责制定和维护这些标准？技术标准应由相关领域的跨职能专家团队负责制定和维护。技术标准需要进行定期的评审，并根据需要进行更新，以跟上技术领域的变化。应该鼓励团队遵循这些标准，并就其有效性提供反馈。格式可以不同，但最好可以提供详细的解释和代码示例。它可以是正式的，并遵循一些格式（如<a href=\"https://www.rfc-editor.org/rfc/rfc7990.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODQ0ODY0OTcsImZpbGVHVUlEIjoicVV2TUFPSUl3c0V6ck1sNSIsImlhdCI6MTY4NDQ4NjE5NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.-DRomq4lUleBIOWsVGq38sCGHfirSIlBRdrIMxe_lZc\">RFC格式框架</a>\"），也可以是随意的，这取决于具体的偏好和工程文化。<a href=\"http://opensource.zalando.com/restful-api-guidelines/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODQ0ODY0OTcsImZpbGVHVUlEIjoicVV2TUFPSUl3c0V6ck1sNSIsImlhdCI6MTY4NDQ4NjE5NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.-DRomq4lUleBIOWsVGq38sCGHfirSIlBRdrIMxe_lZc\">Zalando的RESTful API和事件指南</a>\"是共享内部技术标准的一个很好的例子。除了API标准之外，你可能还想引入日志记录和监控、部署和QA标准。</p><p></p><p>你可以基于内部标准建立质量检验关卡，例如测试覆盖率检查、检查命名约定或格式的集成代码linter、验证架构或代码库结构的适应性函数 （Fitness Functions）。自动检查、在新人加入时使用标准、代码评审或结对编程的组合将有助于确保标准被遵循并为我们带来价值。除了检查是否符合标准，这也是一个讨论平台工程价值的机会。不要只是简单地告诉人们他们做错了什么，而要让他们在一开始就做对。</p><p></p><p></p><h1>架构决策记录（ADR）实践</h1><p></p><p></p><p>架构决策框架的第三个构建块是创建ADR或<a href=\"https://cwiki.apache.org/confluence/display/GEODE/Lightweight+RFC+Process?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODQ0ODY0OTcsImZpbGVHVUlEIjoicVV2TUFPSUl3c0V6ck1sNSIsImlhdCI6MTY4NDQ4NjE5NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.-DRomq4lUleBIOWsVGq38sCGHfirSIlBRdrIMxe_lZc\">轻量级RFC</a>\"。ADR是记录架构决策及其推理过程的一种方式。它们提供了重要决策的历史记录，并帮助团队理解为什么选择了特定的方法。ADR应该由负责做出架构决策的团队创建。它们应该包括正在解决什么问题、有哪些替代方案、做出的决策以及背后的原因等信息。它们是不可变的文档。在重新审视给定的决策时，通常需要创建一个新的文档。ADR实践正变得越来越流行，因此<a href=\"https://docs.aws.amazon.com/prescriptive-guidance/latest/architectural-decision-records/welcome.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODQ0ODY0OTcsImZpbGVHVUlEIjoicVV2TUFPSUl3c0V6ck1sNSIsImlhdCI6MTY4NDQ4NjE5NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.-DRomq4lUleBIOWsVGq38sCGHfirSIlBRdrIMxe_lZc\">AWS</a>\"和<a href=\"https://cloud.google.com/architecture/architecture-decision-records?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODQ0ODY0OTcsImZpbGVHVUlEIjoicVV2TUFPSUl3c0V6ck1sNSIsImlhdCI6MTY4NDQ4NjE5NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.-DRomq4lUleBIOWsVGq38sCGHfirSIlBRdrIMxe_lZc\">GCP</a>\"等主要云供应商已将其添加到各自的文档中。</p><p></p><p>技术雷达和技术标准为技术决策提供指导和预期边界，ADR则捕获推理过程并记录特定的一次性决策——创建新服务或包、引入新技术或主要架构变更的原因。ADR通常被保存在一个集中式的存储库或文档工具中，所有相关团队都可以访问它们。它们还可以帮助新团队成员快速了解整体架构和重大决策背后的原因。</p><p></p><p>ADR评审有多种目的——评审决策和分享知识。每一个受决策影响的人都会参与到ADR评审中，但如果可以与更多人分享，它还有助于提高整个组织的整体架构意识。此外，ADR可用于在内部收集更多的反馈。有时候，一些工程师可能在过去解决过类似的问题，只是现在没有在做相关的工作。</p><p></p><p>与前两个构建块一样，每个组织在最终确定ADR时的最终发言权以及哪些决策被认为足够重要而需要使用ADR的过程都是不同的。为了避免重复，你可以在做出新的主要系统变更时使用ADR来就特定的设计决策达成一致，而在决定使用何种编程语言、工具和实践时则采用技术雷达和技术标准。有了内部技术雷达和技术标准，采用ADR就应该是一个简单而直接的实践，因为最实质性的技术选择和原则已经达成了一致。</p><p></p><p></p><h1>结论</h1><p></p><p></p><p>技术雷达、技术标准和ADR共同构成了一种架构决策框架，这个框架为制定架构决策提供了清晰且一致的方法，降低了采用新技术的风险，并提供了决策历史记录。通过建立架构决策框架，团队可以确保他们的技术栈与他们的业务目标保持一致，并且他们的团队拥有做出明智决策所需的信息和指南。</p><p></p><p>团队所拥有的自由度，以及改变技术雷达、技术标准或ADR的过程，将塑造组织的工程文化。一些组织的目标是实现彻底的团队自治，而一些组织的目标则是保持高度的一致性。例如，一种可能的方法是让高级技术人员参与技术雷达和标准的制定，为进一步的技术决策提供指导，并将ADR留给负责实现软件功能的团队。你可以采用这种架构决策框架，并根据公司的需要做出调整。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/framework-architectural-decisions/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODQ0ODY0OTcsImZpbGVHVUlEIjoicVV2TUFPSUl3c0V6ck1sNSIsImlhdCI6MTY4NDQ4NjE5NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.-DRomq4lUleBIOWsVGq38sCGHfirSIlBRdrIMxe_lZc\">https://www.infoq.com/articles/framework-architectural-decisions/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/RcpX4N8e6DUHIaG4eNTM\">软件技术栈商品化：应用优先的云服务如何改变游戏规则</a>\"</p><p><a href=\"https://www.infoq.cn/article/XYlKxH5f3GjBflH31z9h\">ThoughtWorks CTO：2025 年之前，我们会看到架构的演进，但不会看到革命</a>\"</p><p><a href=\"https://www.infoq.cn/article/T4PEt15NU2JUk1VWhTMv\">避免成为“象牙塔”架构师：架构师和组织之间的关系</a>\"</p>",
    "publish_time": "2023-05-25 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "德勤、东亚银行、南京钢铁、宁德核电讲述数字人才技能重塑之路 | DTDS预约报名",
    "url": "https://www.infoq.cn/article/AMK0k7K4HMK9JQVPfNRD",
    "summary": "<p>每一次时代变迁，都伴随着社会劳动力结构和人才技能的颠覆。</p><p></p><p>随着数字化时代的到来，企业需要优化其人才技能结构，以适应不断变化的市场需求。企业从迈开数字化转型的第一步开始，就已经踏入了无人区。过去的经验不再适用于当下，只有不断地探索新的商业模式和运营模式，重新定义业务流程和管理方式，建立强大的数字化能力，才能走向数字化未来。</p><p></p><p>企业的数字化探索需要以人才技能重构为起点和支撑。如果企业的能力无法满足外界需求，业务只能缓慢增长，受限于现有的思维视野，创新能量也将难以在组织内形成，企业必将错失发展机遇。拥有一支兼具数字化素养、跨领域技能和创新精神的人才队伍，才能够在数字化竞争中立于不败之地。</p><p></p><p>数字化时代正在拓宽岗位的边界，未来人才发展的趋势逐渐将“岗位”导向转变为以“技能”为核心。因此，岗位即将走向终结，技能将替代岗位成为员工和工作的连接点。然而，随着技术发展的日新月异，技能的半衰期正在缩短，这意味着弥合技能差距的时间将显著变长。当前，世界正面临着重新培养员工技能的紧迫挑战。</p><p></p><p>在数字化时代，企业需要不断更新自己的人才战略，以适应快速变化的市场需求和技术发展，赢得数字化时代的竞争优势。以“人才为本，数智蝶变”为主题的 DTDS 全球数字人才发展线上峰会将于 5 月 30 日举行，届时来自德勤、东亚银行、南京钢铁、宁德核电等处于行业领先地位的数字化企业，将分享他们如何通过人才技能重塑，推动数字化转型进程，实现企业发展与人才发展的良性循环。</p><p></p><p>极客时间企业版将在本次 DTDS 峰会上发布AI未来教育学习产品，并推出与培训杂志合作《中国企业数字人才发展白皮书》完整版解读，观看直播的用户都可获得原版白皮书。</p><p></p><p>扫描下方海报上的二维码或<a href=\"https://app.jingsocial.com/microFrontend/leadGeneration/jsf-leads/list/webinar/P8KAMuAA7DmVHnBydPuGL8/a7oymLNUReJh4EuJEhkrFV\">点击链接</a>\"，即可报名参与精彩环节↓↓</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9b/9b1e005b008cb65e11db83141efa7630.png\" /></p><p></p>",
    "publish_time": "2023-05-25 10:32:02",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "无声的平台革命：eBPF 是如何从根本上改造云原生平台的",
    "url": "https://www.infoq.cn/article/R7bTrXMAvI6JsmVZ6QaY",
    "summary": "<p></p><h3>摘要</h3><p></p><p>eBPF 已在云原生生态环境中众多项目和产品中的底层使用，通过实现丰富的云原生上下文，eBPF 使内核具备进入云原生条件。eBPF 所创造的悄无声息的基础设施运动，使其随处可见，且实现了许多先前不可能实现的新用例。&nbsp;eBPF 已经在互联网规模的生产环境与生产验证中，于全球数百万服务器和设备上全天候运行超过五年。eBPF 在操作系统层实现了新的抽象，为平台团队提供了云原生网络、安全和可观测性的高级能力，以安全地定制操作系统，满足其工作负载的需求。扩展操作系统内核是一个艰难而漫长的过程，应用一个变化可能需要数年时间才能完成。但现在随着 eBPF 的应用，这种开发者-消费者的反馈循环几乎是即时可用的，变化可以优雅地推送到生产中，而不必重新启动或改变应用程序或其配置。未来十年的基础设施软件将由平台工程师来定义，他们可以使用 eBPF 和基于 eBPF 的项目来为更高层次的平台创建合适的抽象概念。以 eBPF 为驱动的 Cilium 等开源项目，在网络、可观测性和安全性上，已经开创并将这种基础设施运动带入到了 Kubernetes 和云原生中。</p><p>&nbsp;</p><p></p><p></p><p>Kubernetes 和云原生的出现至今已经将近十年了，在这段时间内，我们见证了软件基础设计领域的项目与创新的寒武纪大爆发。在实验与深夜努力中，我们认识到了生产中大规模运行这些系统时，有什么是可行的，又有什么是不可行的。在这些基础项目和关键经验的帮助下，平台团队开始将创新带向了堆栈，但堆栈能跟得上他们的速度吗？</p><p>&nbsp;</p><p>随着应用设计开始向以 API 为驱动的微服务转变，以及基于 Kubernetes 的平台工程、网络、安全的兴起，Kubernetes 对传统网络和安全模式的打破，让团队追赶的步伐变得吃力。上云的转变至少让我们见证了相似技术的海量变化，但 Linux 将“云上”打包，开启世上最为流行的服务，则是完全改写了数据中心基础设施和开发者工作流程的规则。我们如今所处的境况也是类似，云原生领域基础设施的出现如雨后春笋，不是人人都清楚这股潮流前进的方向，看看 <a href=\"https://landscape.cncf.io/\">CNCF 的情况</a>\"就知道了；我们的服务通过 Linux 内核上的分布式系统与彼此通信，但其中许多功能和子系统在设计之初就没有考虑到云原生。</p><p>&nbsp;</p><p>基础设施软件的未来十年将由平台工程师来定义，他们将利用这些基础设施构件，正确地为更为高层的平台搭建抽象。建筑工程师利用水电、建筑材料搭建供人类使用的建筑，而平台工程师则利用硬件和软件基础设施，搭建可用开发者安全可靠地部署软件，在大规模下仍能以最小劳动量频繁且可预测地进行高影响力改动的平台。对于云原生年代的下一步发展，平台工程师团队必要能提供、连接且可观察的可扩展、动态、可用且高性能的环境，让开发者能全心全意集中于业务代码逻辑。许多支撑这类工作负载的 Linux 内核构件都已经有十多年的历史了，它们需要新的抽象才能跟得上云原生世界的需求。但好消息是，这些构件已经能满足上诉的诉求，并也已经在最大规模的生产环境中经过了多年的验证。</p><p>&nbsp;</p><p><a href=\"https://ebpf.io/\">eBPF</a>\" 通过允许开发者们以安全、高性能、可扩展的方式动态编程内核，从而创建了云原生抽象和云原生世界所需的新构件。在不修改内核源码或加载内核模块的前提下，eBPF 可安全且高效地扩展云原生和内核的其他功能，将内核本体从单体应用转换至具备丰富云原生环境的多模块化架构，从而解锁了创新。这些能力允许我们安全地抽象 <a href=\"https://kernel.org/\">Linux 内核</a>\"，并以紧密的反馈循环对这一层进行迭代和创新，从而准备好进入云原生的世界。随着 Linux 内核新能力的加入，平台团队已经具备进入云原生世界后的第二步，他们或许也在不知不觉中在项目里采用了 eBPF。这四一场无声的 eBPF 革命，重塑着平台与云原生世界的形象，而在本文中，我们将讲述它的故事。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>出于兴趣和利润的数据包过滤扩展</h2><p></p><p>自从<a href=\"https://www.tcpdump.org/papers/bpf-usenix93.pdf\">1992</a>\"年的 BSD 数据包过滤（BPF）起，eBPF 这项技术已经有了数十年了历史。在当时，Van Jacobson 试图对网络问题进行诊断，但当年现有的网络过滤都过于缓慢，为此，他的实验室设计并创建了 libpcap、tcpdump。以及 BPF 为所需功能提供后端。BPF 的设计使其能快速、高效，且易于验证地在内核中运行，但其功能仅仅包含对 IP 地址和端口号等简单数据包的头字段进行只读过滤。随着时间的推移和网络技术的发展，“经典”BPF（cBPF）的局限性更为突出，具体来说，它的无状态性导致其在复杂数据包操作上束手束脚，对开发者而言也是难于扩展。</p><p>&nbsp;</p><p>尽管限制重重，这种围绕 cBPF 的高层级概念仍是为将来的创新提供了灵感和平台，即通过一个最小可验证指令集允许内核证明用户所提的应用程序安全性，并能够在内核中运行这些程序。在2014年，一项新技术<a href=\"https://lore.kernel.org/netdev/1396029506-16776-1-git-send-email-dborkman@redhat.com/\">加入</a>\" Linux 内核，极大地扩展了 BPF（“eBPF”因此得名）的指令集，为我们带来了一个更为灵活且更为强大的版本。在最初，取代内核中的 cBPF 引擎并不是目标，因为 eBPF 是通用的概念，可被用于网络之外的许多地方。但在当时，将这项新技术融入主流内核的确是一条可行的道路，这也是 <a href=\"https://lore.kernel.org/lkml/alpine.LFD.2.00.1001251002430.3574@localhost.localdomain/\">Linus Torvalds 这段话</a>\"的背景：</p><p>&nbsp;</p><p></p><blockquote>和疯子们一起工作对我来说不是问题，他们只需要用不那么疯狂的论点短小精悍地向我推销他们的疯狂想法。在我问他们要杀手级功能时，我希望他们能说服我这些推销的东西首先要对主流来说的确有用。换句话说，任何疯狂的新功能都应该被牢牢包裹在一个“特洛伊木马”中，第一眼看上去至少要明显觉得不错。</blockquote><p></p><p>&nbsp;</p><p>简单来说，这段话是对 Linux 内核开发模式中“根本”机制的描述，与 eBPF 融入 Linux 的方式不谋而合。为实现增量形式的优化，第一步自然是取代内核中 cBPF 的基础设施以提高其i性能，随后再一步步地在其基础上暴露并改进全新的 eBPF 技术。自此之后，早期的 eBPF 发展有了两条并行前进的路线，即网络与跟踪。以 eBPF 为中心的每一个被合并至内核的新功能都解决了这类用例下的切实生产需求，这一需求至今仍然适用。而 <a href=\"https://github.com/iovisor/bcc\">bcc</a>\"、<a href=\"https://github.com/iovisor/bpftrace\">bpftrace</a>\",、<a href=\"https://github.com/cilium/cilium\">Cilium</a>\"&nbsp;等项目则是早在 eBPF 生态系统搭建成功并成为主流之前，变开始协助塑造了 eBPF 基础设施的核心构件。如今的 eBPF 是一项通用技术，可在内核等特权环境中运行沙盒程序，这与“BSD”、“数据包”，或“过滤器”已经没有什么共同点了，如今的 eBPF 只是个缩写的，代指操作系统内核根据用户需求安全地扩展和定制的技术革命。</p><p>&nbsp;</p><p>具备运行复杂但安全程序能力的 eBPF 已经是一个极为强大的平台，可用堆栈更为高层的云原生环境丰富 Linux 内核，从而执行更优的策略决策、更有效地处理数据、让操作与其源头更为接近，也更为迅速地进行迭代和创新。简言之，我们将不再是修补、重构，或是推出新内核变动，而是削减基础设施工程师们的反馈循环，让 eBPF 程序可以在无需重启服务或中断数据处理的情况下进行即时更新。eBPF 的多功能性也使其在网络之外的其他领域也有应用，在安全、可观察性、跟踪等方面，eBPF 可被用于实时监测并分析系统事件。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>加速中的内核实验与进化</h2><p></p><p>从 cBPF 向 eBPF 不仅改变了我们的现状，也影响了我们即将构建的。从简单的数据包过滤发展到通用沙盒运行时，eBPF 在网络、可观察性、安全性、跟踪和剖析方面开创了许多新用例。作为 Linux 内核中的通过计算引擎，eBPF 允许我们对内核中发生的任何事情挂钩、观察，并采取行动，与网页浏览器中的插件很是类似。其中的一些关键功能设计允许了 eBPF 对创新能力的加速，从而为云原生世界创建性能更强的可定制系统。</p><p>&nbsp;</p><p>首先，eBPF 能够挂钩在内核中任何地方，并修改功能和自定义行为的是不需要对内核源码修改的，这意味着从用户提出需求到具体实施的时间将从以年为单位缩减为几天。由于 Linux 内核被数十亿的设备所广泛采用，导致上游的改动并不轻松。举例来说，假设我们想要一个观察应用的新方式，并能够从内核中提取指标，那么我们首先要做的是说服整个内核社群这个主意不错，并且是对所有运行 Linux 的人而言都不错，然后才能开始实施，并最终在几年后才能真正用得上这个功能。但随着 eBPF 的出现，我们能直接不重启机器就把这个观察功能写成代码，并在不影响其他人的前提下根据自身特定的工作负载需求对内核定制化。“eBPF 非常有用，其真正强大的点在于它能让人们自行定制化代码，除非特地要求否则这些代码是不会被启用的，”<a href=\"https://www.zdnet.com/article/linus-torvalds-talks-about-coming-back-to-work-on-linux/\">Linus Torvalds</a>\" 说。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3f/3fc8f67cf709d9fa309bdb4f249eb8ea.jpeg\" /></p><p></p><p>图配文：</p><p>应用程序开发者：我想要这个功能观察我的应用—— 哈喽，内核开发者！请把这个新功能加到 Linux 内核中！—— 好啊，给我一年时间让我说服整个社群这是个对所有人都好的功能一年后…… 完事了，主流内核已经可以支持了但我想把这个加到我的 Linux 版本里……五年后…… —— 好消息，我们的 Linux 版本已经可以提供带有你需要功能的内核了—— 但我的需求已经变了啊……</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e5/e5856205f7a256e699f255c35561d2ac.jpeg\" /></p><p></p><p>图配文：</p><p>应用开发者：我想要这个新功能观察我的应用</p><p>eBPF 开发者：行！内核现在没有这个功能，让我拿 eBPF 快速搞定</p><p>几天后……</p><p>这个是我们包含这个功能的 eBPF 项目版本，顺带一提，你还不用重启机器</p><p>&nbsp;</p><p>其次，由于对程序执行的安全性验证，eBPF 的开发者们可以在无需担忧内核崩溃或其他不稳定因素而继续进行创新。开发者和最终用户都能更自信地说自己送上生产的代码是稳定且可用的。对平台团队和 SRE 而言，使用 eBPF 也是安全地在生产环境中排障的关键因素。</p><p>&nbsp;</p><p>在应用程序准备投产时，eBPF 程序无需中断工作负载或重启节点便可添加至运行时，从而极大地减轻了平台更新维护所需的工作量，也减少了因版本更新出错导致工作负载中断的风险，这对大规模项目而言是个极大的好处。JIT 编译让 eBPF 程序具备了接近本地的执行速度，将上下文从用户空间转移到内核空间则允许用户跳过不需要或未使用的内核部分，进而提升其性能。然而，与用户空间中的完全跳过内核不同，eBPF 仍可利用全部的内核基础设施和构件而不用重新发明轮子。eBPF 可以挑选内核中的最优部分，结合自定义业务逻辑，从而解决特定问题。最后，运行时可修改内核行为以及跳过部分堆栈的能力，为开发者创建了一个极短的反馈循环，进而允许在网络堵塞控制和内核中进程调度等方面进行试验。</p><p>&nbsp;</p><p>eBPF 从经典的数据包过滤中成长，并在传统用例中进行的的大飞跃，解锁了内核中资源使用优化、添加自定义业务逻辑等许多新的可能性。eBPF 让我们可加速内核创新、创建新抽象、大幅提升性能，不仅缩短了在生产负载中新增功能的时间、风险、开销，甚至在某些情况下让不可能<a href=\"https://sessionize.com/download/syahfej~KQRCkDB3zgNUj5nhrujno9.pdf~Borkmann%20-%20eBPF%20innovations%20in%20cloud%20native.pdf\">成为可能</a>\"。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>数据包与日常：eBPF 在谷歌、Meta 和 Netflix 的应用</h2><p></p><p>在见识到 eBPF 如此之多的优点后，人们不禁要问了，eBPF 是否能在现实世界中实现？答案是肯定的。Meta 和谷歌坐拥部分世界上最大的数据中心、Netflix 占据互联网流量中的15%，这些公司都已在生产中使用 eBPF 多年，其结果不言而喻。</p><p>&nbsp;</p><p>Meta 是第一家将 eBPF 及其负载均衡项目&nbsp;<a href=\"https://engineering.fb.com/2018/05/22/open-source/open-sourcing-katran-a-scalable-network-load-balancer/\">Katran</a>\" 大规模投产的公司。自2017年起，所有进入 Meta 数据中心的包都是通过 eBPF 处理的，那可是不少猫猫图片呢。Meta 也将 eBPF 用于许多更高级的用例，如最近的调度器效率优化，可将<a href=\"https://lore.kernel.org/bpf/20230128001639.3510083-1-tj@kernel.org/\">吞吐量提升15%</a>\"，对该公司的规模而言这是个极大的提升和资源节约。谷歌也利用 eBPF 的<a href=\"https://www.youtube.com/watch?v=XFJw37Vwzcc&amp;t=38s\">运行时安全性和可观测性</a>\"处理其多数的数据中心流量，谷歌云的用户也是默认使用基于 eBPF 的数据平面进行联网。安卓操作系统支持了70%的移动设备，拥有遍布190多国家的25亿活跃用户，其中<a href=\"https://twitter.com/breakawaybilly/status/1640292221772595201\">几乎所有的网络数据包都接触过 eBPF</a>\"。<a href=\"https://www.brendangregg.com/Slides/reInvent2019_BPF_Performance_Analysis/\">Netflix 在很大程度上依赖于 eBPF 对其机群进行性能监控和分析</a>\"，而 Netflix 的工程师也创造了 bpftrace 等 eBPF 工具，绘制基于 eBPF 收集器的 On-CPU 和 Off-CPU 火焰图，为生产服务器排障的可见性方面带来了重大飞跃，</p><p>&nbsp;</p><p>eBPF 的有效性的显而易见的，在过去的十年中一直为“互联网规模”的公司带来大量收益，这些收益也应该转换为其他人所用。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>eBPF 的演变：让云原生速度和规模成为可能</h2><p></p><p>在云原生时代初期，GIFEE（谷歌为其他所有人提供的基础设施）是个流行词，但因为不是所有人都在用谷歌或谷歌的基础设施，这个词已经不再热门。人们希望能用简单的解决方案解决问题，这也是 eBPF 脱颖而出的原因。云原生环境是为“在现代且动态的环境中运行可扩展应用程序”，其中可扩展和动态是 eBPF 成为云原生革命所需的内核演变关键。</p><p>&nbsp;</p><p>Linux 内核一如既往地是云原生平台构建的基础，应用现在只需使用套接字作为数据源和接收器，网络作为通信总线。但云原生所需的是目前 Linux 内核中所无法提供的新抽象，cgroups（CPU、内存处理）、命名空间（net、mount、pid）、SELinux、seccomp、netfiler、netlink、AppArmor、auditd、perf 等等这些构件远比云原生这个名字的出现早诞生了数十年，这些构件不总是在一起使用，有些也不甚灵活，缺乏对 Pod 或任何更高级别服务抽象的认知，且完全依赖 iptables 联网。</p><p>&nbsp;</p><p>对于平台团队而言，为云原生环境提供的开发者工具，很可能还被囿于这个云原生环境无法被有效表达的盒子里。在未来，没有合适的工具平台团队也将无从下手。eBPF 则是允许工具从无到有地重建 Linux 内核中的抽象概念，而这些新抽象则会解锁下一次云原生创新的潮流，为云原生的革命奠定方向。</p><p>&nbsp;</p><p>举例来说，传统的网络下，数据包是由内核处理的，经过数层网络堆栈对所有数据包的检查后方能到达目的地。这一过程无疑会带来极高的开销和处理时长，对含有大量数据包的大规模云环境而言则更是如此。与之相反，eBPF 允许在内核中插入自定义代码，并在每个数据包经过网络堆栈时执行，带来了更为有效且更具针对性的网络流量处理，减少开销并提升性能。Cilium 的基准测试表明，从 iptables 切换至 eBPF&nbsp;<a href=\"https://cilium.io/blog/2018/04/17/why-is-the-kernel-community-replacing-iptables/\">提升了六倍吞吐量</a>\"，从基于 IPVS 的负载均衡器切换至以 eBPF 为驱动，不仅使 <a href=\"https://cilium.io/blog/2022/04/12/cilium-standalone-L4LB-XDP/\">Seznam.cz</a>\"&nbsp;的吞吐量增加了一倍，CPU 使用率也减少72倍。eBPF 不是在旧的抽象概念上缝缝补补，而是实现了巨大优化改进。</p><p>&nbsp;</p><p>与其前身不同，eBPF 的优化没有仅仅停留在网络层面。作为通用计算环境且可挂载到内核的任何位置，eBPF 的优化也扩展到了可观测性、安全等更多领域。“我认为云原生中安全性的未来将会是基于 eBPF 技术的，这是一种全新且强大的获取内核可见性的方式，过去想做到这一点是很难的，”云原生计算基金会的 CTO <a href=\"https://www.infoq.com/news/2023/02/cloudnative-securitycon-na-2023/\">Chris Aniszczyk</a>\" 说过，“在应用和基础设施监控的交界处，（eBPF）可以为团队提供一个检测、缓解和问题解决的，更为全面的方式。”</p><p>&nbsp;</p><p>eBPF 以云原生的速度和规模，让人们可以连接、观察并保护应用程序。“随着应用程序逐渐向着以云原生模式为驱动的基于 API 的服务集合，所有应用的安全性、可靠性、可观测性、性能都将从根本上依赖于以 eBPF 为驱动的全新连接层”，Isovalent 的联合创始人 Dan Wendlandt 说，“它将成为新云原生基础设施堆栈中的一个关键层。”</p><p>&nbsp;</p><p>eBPF 的革命正在改变云原生，而其中最好的部分已经得到了实现。</p><p></p><h2>&nbsp;</h2><p></p><p></p><h2>无声的 eBPF 革命已经成为平台的一部分了</h2><p></p><p>虽然 eBPF 的好处显而易见，但这种过于底层的形式意味着缺乏 Linux 内核开发经验的平台团队还需要一个更为友好的接口。这也是 eBPF 的魔力所在，eBPF 如今已经在多个运行云原生平台的工具中存在，或许你已经在不知不觉中用过它了。通过任何主流云供应商的 Kubernetes 集群启动，都是通过 Cilium 用到了 eBPF；通过 Pixie 的观测性实施或 Parca 的连续分析，也都用到了eBPF。</p><p>&nbsp;</p><p>eBPF 这股强有力的浪潮正在改变软件行业。Marc Andreessen 那句著名的“软件正在吞噬世界”已经被 <a href=\"https://blog.cloudflare.com/cloudflare-architecture-and-how-bpf-eats-the-world/\">Cloudflare</a>\" 玩笑似地改成了“eBPF 正在吞噬世界”。然而，eBPF 的成功不在于让所有开发者得知其存在，而是在当开发者们对更快的网络、毫不费力的监控及可观测性，以及更易使用且安全的解决方案之中。曾用过 eBPF 编程的开发者可能不足1%，但却能让其他99%的人受益。在各类项目和产品通过 Linux 内核上游代码或 Linux 内核模块编写，从而为开发者们提供大幅度的体验优化时，eBPF 将完全占领世界。我们已经踏上了这条通往现实的大路。</p><p>&nbsp;</p><p>eBPF 彻底改变了现在与将来基础设施平台的构建方式，实现了许多全新的云原生用例，这些用例在过去很难或根本不可能实现。平台工程师能在 eBPF 的帮助下安全且高效地扩展 Linux 内核能力，让快速创新成为可能。为适应云原生世界的需求，新的抽象和构件得以创建，开发人员也能更轻松地大规模部署软件。</p><p>&nbsp;</p><p>eBPF 的大规模投产已有半个世纪之久，也已被证明是一种安全、高性能、可扩展的动态内核编程方式。悄无声息的 eBPF 革命已经扎根，并在云原生生态系统及其他领域的产品和项目中得到应用。随着 eBPF 的出现，平台团队已做好进入云原生时代下一阶段的准备，他们可以配置、连接、观察并保护可扩展的、动态可用高性能环境，从而使开发人员将精力集中于业务逻辑的编程。</p><p>&nbsp;</p><p>查看英文原文：<a href=\"https://www.infoq.com/articles/ebpf-cloud-native-platforms/\">The Silent Platform Revolution: How eBPF Is Fundamentally Transforming Cloud-Native Platforms</a>\"</p><p></p><p>延伸阅读：</p><p><a href=\"https://www.infoq.cn/article/5xvC1Ic6BdLQYju6YWV0\">颠覆传统、应用大爆发，eBPF 何以改变 Linux？</a>\"</p><p><a href=\"https://www.infoq.cn/video/ApKtMSeNvMzDFkleWIUs\">eBPF 技术探索 SIG：eBPF在低版本内核如何跑起来？</a>\"</p><p><a href=\"https://www.infoq.cn/article/aTNxsFTCNjmUEByxxh49\">从安全视角看，革命性的 eBPF 是“天使”还是“恶魔”？</a>\"</p>",
    "publish_time": "2023-05-25 11:53:03",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "《卫报》优化了移动推送通知投递架构",
    "url": "https://www.infoq.cn/article/Pl7VVWNBer6xozYjmmqp",
    "summary": "<p>《卫报》（The Guardian）的技术团队<a href=\"https://www.theguardian.com/info/2022/dec/15/our-journey-towards-the-fastest-breaking-news-service\">已经在着手加快移动推送通知的速度，以改善读者的体验。</a>\"针对并发性进行优化的原始架构一直受到通知投递延迟的困扰。工程师们利用改进的可观测性，通过实验获得了显著的成果。</p><p></p><p>《卫报》的读者可以使用移动应用程序访问内容，并可以通过注册以推送通知的形式接收突发新闻提醒。其背后的<a href=\"https://en.wikipedia.org/wiki/Event-driven_architecture\">事件驱动架构（EDA）</a>\"自2009年以来一直在运行，但随着时间的推移，通知投递的时间有所增加，对某些用户来说，通知投递时间需要五分钟以上。</p><p></p><p>《卫报》的全栈开发人员<a href=\"https://www.linkedin.com/in/francesca-hammond-044a3a21/\">Francesca Hammond</a>\"表示，该团队的目标是在两分钟内向90%的预期受众发送通知，这一目标被称为“90in2”。</p><p></p><p>支持推送通知投递的解决方案利用了一系列的技术。一个与<a href=\"https://www.playframework.com/\">Scala Play应用程序</a>\"对话的内部突发新闻工具触发推送通知投递。<a href=\"https://aws.amazon.com/lambda/\">AWS Lambda</a>\"函数使用来自<a href=\"https://aws.amazon.com/sqs/\">AWS SQS</a>\"的队列消息，负责从自托管的<a href=\"https://www.postgresql.org/\">PostgreSQL</a>\"数据库中获取通知注册，并将其发送到谷歌和苹果的推送通知平台。</p><p></p><p><img src=\"https://imgopt.infoq.com/news/2023/05/guardian-push-architecture/en/resources/14009-1684154406937.png\" /></p><p></p><p>来源：&nbsp;<a href=\"https://www.theguardian.com/info/2022/dec/15/our-journey-towards-the-fastest-breaking-news-service\">https://www.theguardian.com/info/2022/dec/15/our-journey-towards-the-fastest-breaking-news-service</a>\"</p><p></p><p>该团队使用<a href=\"https://www.elastic.co/what-is/elk-stack\">ELK栈</a>\"改进了整个过程的可观测性，这对于识别瓶颈至关重要。</p><p></p><p>他们认为检索通知注册是造成延迟的主要瓶颈。进一步的调查发现存在大量的数据库连接错误，从而导致处理时间过长。为了解决这个问题，团队引入了<a href=\"https://aws.amazon.com/rds/proxy/\">RDS代理</a>\"，这样lambda函数就不会直接连接到数据库，从而避免了触达数据库的连接限制。</p><p></p><p>查询执行时间过长被认为是延迟的另一个原因。在判定查询计划是正确的之后，为了进一步提高数据库性能，一个完整的真空进程删除了“死行”（数据库仍保留的逻辑删除行），并将数据库从版本10升级到了版本13，该版本允许使用更强大的AWS Gravitron2处理器。</p><p></p><p>团队通过创建一个新的RDS实例来升级数据库，以最大限度地减少切换过程中的停机时间。他们设置了逻辑复制来持续同步数据，而应用程序服务则使用旧实例。在切换时，团队更新服务以使用新实例，并立即禁用逻辑复制。</p><p></p><p><img src=\"https://imgopt.infoq.com/news/2023/05/guardian-push-architecture/en/resources/11368-1684154406937.jpg\" /></p><p></p><p>来源：&nbsp;<a href=\"https://www.theguardian.com/info/2022/dec/15/our-journey-towards-the-fastest-breaking-news-service\">https://www.theguardian.com/info/2022/dec/15/our-journey-towards-the-fastest-breaking-news-service</a>\"</p><p></p><p>在持久层之外，开发人员发现，负责向苹果/谷歌平台<a href=\"https://www.infoq.cn/article/v2uz7mktFbRXTuSoy6KU\">提交通知的lambda函数</a>\"需要长达六分钟的时间才能完成接收人数超过80万的突发新闻。</p><p></p><p>该团队通过部署潜在的优化并观察结果进行了几次实验，每次都需要决定更改的保留和恢复。基于这些实验，他们增加了运行在lambda函数中的Scala应用程序的线程池大小，以提高并行性。此外，他们还将lambda函数可用的内存和CPU数量设置为<a href=\"https://docs.aws.amazon.com/lambda/latest/operatorguide/computing-power.html\">支持的最大值</a>\"，从而缩短了函数的执行时间。</p><p></p><p>Hammond写道，继续之前，团队正在进行评估：</p><p></p><blockquote>我们还没做完呢！我们认为，为了实现90in2的目标，可能需要对我们的架构进行更大的更改，特别是考虑到向200多万订阅者发送更大的通知时。由于所需更改的性质，我们想尝试实施RFC风格的流程，以便在开始开发之前收集想法和反馈。</blockquote><p></p><p></p><p>《卫报》的核心通知平台是<a href=\"https://github.com/guardian/mobile-n10n\">开源的</a>\"。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/05/guardian-push-architecture/\">https://www.infoq.com/news/2023/05/guardian-push-architecture/</a>\"</p>",
    "publish_time": "2023-05-25 12:03:54",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "商汤集团联合创始人杨帆确认出席QCon广州，分享大模型浪潮下，商汤的布局与思考",
    "url": "https://www.infoq.cn/article/tYCWuepWdeDjaOtqg8IR",
    "summary": "<p>5&nbsp;月&nbsp;26&nbsp;日本周五，在即将到来的&nbsp;<a href=\"https://qcon.infoq.cn/2023/guangzhou/schedule?utm_source=infoq&amp;utm_medium=arti&amp;utm_campaign=full&amp;utm_term=0523&amp;utm_content=tanghaitao\">QCon&nbsp;全球软件开发大会·广州站</a>\"上，商汤集团联合创始人、大装置事业群总裁杨帆将于会上发表题为《大模型浪潮下，商汤的布局与思考》主题分享，在&nbsp;AIGC&nbsp;高速发展的当下，与全球开发者见面。</p><p></p><p>杨帆毕业于清华大学，曾就职于微软，自2014年11月起担任商汤科技副总裁，主要负责本集团的战略规划及企业发展。同时，他也是深圳证券交易所的行业专家、清华大学人工智能国际治理研究院战略合作及发展委员会副会长。</p><p></p><p>而杨帆所在的商汤科技成立于&nbsp;2014&nbsp;年，并于&nbsp;2021&nbsp;年在香港挂牌上市，近十年间始终是&nbsp;AI&nbsp;领域的焦点企业。商汤科技是第一家将人脸支付技术集成至地铁售票系统中的公司，也为北京大兴机场提供了智能旅客安检系统，进一步将&nbsp;AI&nbsp;落地至产业。2023年4月10日，商汤科技董事长兼CEO徐立分享了以“大模型+大算力”推进AGI（通用人工智能）发展的战略布局，并公布了商汤在该战略下的“日日新SenseNova”大模型体系，推出自然语言处理、内容生成、自动化数据标注、自定义模型训练等多种大模型及能力，包括自然语言处理模型“<a href=\"https://baike.baidu.com/item/%E5%95%86%E9%87%8F/62873734?fromModule=lemma_inlink\">商量</a>\"”（SenseChat）、文生图模型“<a href=\"https://baike.baidu.com/item/%E7%A7%92%E7%94%BB/62878315?fromModule=lemma_inlink\">秒画</a>\"”和数字人视频生成平台“<a href=\"https://baike.baidu.com/item/%E5%A6%82%E5%BD%B1/62878406?fromModule=lemma_inlink\">如影</a>\"”（SenseAvatar）等。</p><p></p><p>相信杨帆来到大会现场，一定能带给大家关于&nbsp;AIGC&nbsp;时代最务实、前沿的研发思考与实践经验。同时，极客邦科技也在努力为大家提供更多的&nbsp;AIGC&nbsp;相关内容，满足大家对于精品资讯、资料、课程的需求。</p><p></p><p></p><h4>InfoQ&nbsp;AIGC&nbsp;专题</h4><p></p><p>其中，InfoQ&nbsp;推出专题，每日实时跟进全球ç动态资讯：<a href=\"https://www.infoq.cn/theme/187\">AIGC，下一个即将爆发的万亿级AI技术风口_技术洞察_技术趋势_大厂实践_InfoQ精选专题</a>\"。InfoQ&nbsp;还另外组织了数场线上专家研讨，期待为大家带来关于&nbsp;AIGC&nbsp;发展的深入解读：</p><p><a href=\"https://www.infoq.cn/video/TXoCTL6MCpZWm2BKaesc\">极客圆桌派：狂飙的&nbsp;ChatGPT&nbsp;｜InfoQ《极客有约》_AI_InfoQ&nbsp;中文站_InfoQ精选视频</a>\"<a href=\"https://www.infoq.cn/video/So2yItKrdYsDZpEG7DjS\">极客圆桌派：ChatGPT点燃AI狂潮&nbsp;|&nbsp;InfoQ《极客有约》_AI_InfoQ&nbsp;中文站_InfoQ精选视频</a>\"<a href=\"https://www.infoq.cn/video/AeU15OmkT2IWQ56ekExt\">我们是如何探索把ChatGPT推到企业级应用的？|&nbsp;InfoQ《极客有约》_AI_InfoQ&nbsp;中文站_InfoQ精选视频</a>\"</p><p>详情请关注《InfoQ&nbsp;极客有约第一季》内容合集：<a href=\"https://www.infoq.cn/theme/188\">《极客有约》2023年&nbsp;第一季_技术洞察_技术趋势_大厂实践_InfoQ精选专题</a>\"</p><p>六月，InfoQ&nbsp;将拜访国内主流大模型研发团队，深入&nbsp;AIGC&nbsp;在产业中的落地实践，持续为大家带来深度报道。</p><p></p><p></p><h4>极客时间&nbsp;AIGC&nbsp;系列课</h4><p></p><p>在&nbsp;3&nbsp;月中旬，极客时间一次性发布四门AIGC&nbsp;公开课，其中包括句子互动公司创始人兼&nbsp;CEO&nbsp;李佳芮的<a href=\"https://time.geekbang.org/opencourse/videointro/100541101\">《ChatGPT从0到1》</a>\"、新加坡科研局高级研究员黄佳的《<a href=\"https://time.geekbang.org/opencourse/videointro/100541201\">ChatGPT和预训练模型实战课</a>\"》、优频科技有限公司&nbsp;CTO&nbsp;的《<a href=\"https://time.geekbang.org/opencourse/videointro/100541301\">Stable&nbsp;Diffusion：零基础学会&nbsp;AI&nbsp;绘画</a>\"》以及NebulaGraph软件工程师古思为的《<a href=\"https://time.geekbang.org/opencourse/videointro/100540901\">GitHub&nbsp;Copilot&nbsp;实践课</a>\"》</p><p></p><p>与此同时，&nbsp;bothub&nbsp;创始人、布奇托网络科技创始人兼&nbsp;CTO&nbsp;徐文浩，在极客时间开设了课程<a href=\"https://time.geekbang.org/column/intro/100541001?tab=catalog\">《AI&nbsp;大模型之美》</a>\"，是「极客时间&nbsp;AIGC&nbsp;未来教育系列课程」之一，聚焦于让大家充分认识、使用&nbsp;OpenAI、Stable&nbsp;Diffusion&nbsp;等开发工具，实现自主可用的&nbsp;AIGC&nbsp;应用，现已有&nbsp;1.8w&nbsp;人加入学习。</p><p></p><p>珠海太乙人工智能技术合伙人尹会生，则在极客时间开办了《<a href=\"https://u.geekbang.org/subject/intro/100550301\">21&nbsp;天&nbsp;AIGC&nbsp;行动营</a>\"》。都说&nbsp;AIGC&nbsp;会淘汰掉某些岗位，但有许多同学已经在这里率先成为&nbsp;AIGC&nbsp;时代的高效工作者，AIGC&nbsp;变成了他们手中的效率提升工具。</p><p></p><p>6&nbsp;月还将有重磅的&nbsp;AIGC&nbsp;主题训练营与大家见面，聚焦&nbsp;AIGC&nbsp;与企业私域数据结合，开发为企业特别定制的&nbsp;AIGC&nbsp;服务，相信也契合了很多研发小伙伴的实际工作。</p><p></p><p>希望这一系列的内容更新，结合本次&nbsp;QCon&nbsp;大会的重磅专家分享，能在&nbsp;AIGC&nbsp;时代，为你带来不一样的启发。</p><p></p><p>最后，有一个好消息告诉你，在本次QCon&nbsp;全球软件开发大会·广州站上，我们策划了<a href=\"https://www.infoq.cn/article/trIhrtiR6hSGFwT8i8mC\">五场闭门会</a>\"，详细信息可点击超链查看。众多大咖将围绕&nbsp;AIGC、金融行业数据治理、业务出海等问题进行深入探讨。</p><p></p><p>会议开幕倒计时最后一天，欢迎线下来交流，购票可直接电话&nbsp;/&nbsp;微信联系票务经理瑞丽&nbsp;18514549229。</p><p><img src=\"https://static001.infoq.cn/resource/image/12/a4/12c0874108efc1131e652689e07dbca4.jpg\" /></p><p></p>",
    "publish_time": "2023-05-25 12:06:19",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "免费版“Github Copilot”，编程能力还翻倍？！谷歌硬刚微软，推出全新Colab编程平台",
    "url": "https://www.infoq.cn/article/atGCf0aK8qAv4JRMAwVV",
    "summary": "<p>最近，谷歌宣布Google Colaboratory（Colab）即将加入全新的 AI 编码功能，包括代码生成、代码补全、代码聊天机器人。</p><p>&nbsp;</p><p>而且，最重要的是，与GitHub <a href=\"https://www.infoq.cn/article/kxARbquFMCbx39KPoTxY\">Copilot</a>\" 每月 10 美元的订阅费用相比，谷歌全新的AI编码功能将完全免费！</p><p>&nbsp;</p><p>Colab 是 Google Research 的一款类似 Jupyter Notebook 的产品。Python 程序开发人员可以使用它来编写和执行随机 Python 程序代码，只需要一个Web 浏览器即可。简而言之，Colab 是Jupyter Notebook的云托管版本。另外，Colab还提供对谷歌强大计算资源（包括存储、内存、 GPU 和 TPU）的免费访问，并能与 Jupyter Notebooks 和 GitHub 等流行工具集成。</p><p>&nbsp;</p><p><a href=\"https://www.infoq.cn/article/hNs2LxvloB4jaBQEwEL1\">谷歌</a>\"表示目前已经有超过 700 万人在使用 Colab&nbsp;，而随着AI编程功能的加入，各方面只会越来越好。</p><p>&nbsp;</p><p>即将加入全新的AI编程功能由新“文生代码”模型Codey提供支持，支持20多种编程语言，包括Go、Java、Javascript和Typescript等。谷歌表示，该模型“擅长 Python 和 JavaScript 等流行的编程语言，但也可以生成 Prolog、Fortran 和 Verilog 等语言的专用代码。”</p><p>&nbsp;</p><p>此举被视为谷歌正面硬刚微软Github Copilot。谷歌透露，这些新功能将在未来几个月内逐步推出，付费用户将先行体验，然后免费用户和其他地区的用户也将很快获得使用权限。</p><p>&nbsp;</p><p></p><h2>强大的编程功能</h2><p></p><p>&nbsp;</p><p>谷歌表示，Codey 基于 PaLM 2 构建，已针对大量高质量代码数据进行微调，将显着提高编程速度、质量和理解力。</p><p>&nbsp;</p><p>在代码生成方面，可通过自然语言来生成更大的代码块，也可以根据注释或提示编写整个函数。</p><p>&nbsp;</p><p>在新的 Colab 版本中，会有一个全新的“生成”按钮，用户可以在那里用自然语言输入任何想要的内容，之后，AI 就会根据这段文本提示来生成相应代码。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/32/32e653fcd21b68c16028c6c631ed5749.gif\" /></p><p></p><p></p><p>&nbsp;</p><p></p><h3>代码补全</h3><p></p><p>&nbsp;</p><p>在输入代码时，Colab 还会根据上下文，为接下来的代码提供建议。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d3/d374c96483fb0bf17382e4a52ac25c99.png\" /></p><p></p><p>&nbsp;</p><p></p><h3>集成聊天机器人</h3><p></p><p>此外，谷歌还将在 Colab 中加入编程专用的聊天机器人。用户可以直接与 AI 对话，来获得有关调试、文档、学习新的概念以及其他问题上的帮助。例如“我如何从 Google 表格导入数据？” 或“如何过滤 Pandas DataFrame？”</p><p>&nbsp;</p><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/013aeb13cb00e416e1fea39833e6eaa5.gif\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>AI编程竞争加剧，免费才是“硬道理”？</h2><p></p><p>&nbsp;</p><p>根据Sourcegraph的<a href=\"https://about.sourcegraph.com/big-code/big-code-in-ai-era\">一份调查报告</a>\"显示，95% 的受访开发人员已经在使用 AI 工具编写代码，例如 GitHub Copilot、ChatGPT以及其它AI编程工具，该报告针对不同行业和地区的 500 多名软件开发人员和工程师。</p><p>&nbsp;</p><p>GPT-4 等大型语言模型 ( LLM ) 可以建议代码片段、回答技术问题，甚至可以编写简单应用程序。Forrester Research 副总裁兼首席分析师 Mike Gualtieri 预计人工智能工具将对软件开发产生“巨大影响”：“我认为保守地说这将使开发人员的工作效率提高一倍，甚至更多。”</p><p>&nbsp;</p><p>这些生产力的提高也意味着科技行业的大规模变革。尽管之前微软的 GitHub Copilot 和亚马逊的 Amazon CodeWhisperer 已经推出了有限的功能集，但去年 ChatGPT 的发布开启了 AI 代码生成的新纪元。所以，现在云厂商之间又展开了一场关于AI编程方面的竞赛，以赢得开发人员的支持。</p><p>&nbsp;</p><p>之前， Bard 和 ChatGPT都展示了自家大模型的代码生成能力，但开发人员更需要的是在 IDE 中使用 AI。于是，微软在3月份推出了在开发环境中嵌入 GPT-4 的 GitHub Copilot X，并且它最终将被集成到 Visual Studio——微软的 IDE 中。在 IDE 中的Copilot X 将能够生成、解释和评论代码，还具有调试、编写单元测试和识别漏洞等功能。</p><p>&nbsp;</p><p>为了不被其云竞争对手超越，今年4 月份，AWS 宣布其所谓的实时 AI 编码伴侣全面上市。Amazon CodeWhisperer 与一系列 IDE 集成，即 Visual Studio Code、IntelliJ IDEA、CLion、GoLand、WebStorm、Rider、PhpStorm、PyCharm、RubyMine 和 DataGrip，或原生集成在 AWS Cloud9 和 AWS Lambda 控制台中。虽然预览版适用于 Python、Java、JavaScript、TypeScript 和 C#，但一般版本扩展了对大多数语言的支持。Amazon 的主要区别也是在于它对个人用户免费提供，而 GitHub Copilot 目前是基于订阅的，只有教师、学生和开源项目的维护者除外。</p><p>&nbsp;</p><p>而谷歌这一边，则不断扩展Bard的编程能力。 Bard 刚发布的时候还缺乏与 OpenAI 的 ChatGPT 、微软的 Bing Chat 同等的编码能力。在今年Google I/O 大会上，谷歌宣布Bard引进了新一代的PaLM 2，增强了Bard的能力，让用户可以使用 20 多种编程语言进行编码，包括 C++、Go、Java、Javascript 和 Python。现在，让Colab加入全新的 AI 编码功能也是谷歌应对竞争必然会采取的行动。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5a/5a9416b9cb1c8f2b6ffe2fdd7ccbd099.png\" /></p><p></p><p>&nbsp;</p><p>另一方面，市场上也出现了越来越多的可以替换替代 Copilot的人工智能编码工具，但需要付费使用的不在少数。谷歌的“免费”形式，或许是缩小与微软之间的差距的有效手段。</p><p>&nbsp;</p><p>谷歌在博客中说道，“只要能联网，就能免费用。”并且谷歌即将在Colab中推出更多功能和改进，这将有助于提升用户在数据和 ML 工作流程中集成体验。</p><p>&nbsp;</p><p>根据谷歌的说法，对这些功能的访问将在未来几个月内逐步推出，美国的付费用户可以先开始体验，然后免费用户将可以使用。其他地区的用户也将在不久之后就能体验到这些功能。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://blog.google/technology/developers/google-colab-ai-coding-features/\">https://blog.google/technology/developers/google-colab-ai-coding-features/</a>\"</p><p><a href=\"https://blog.ecosystm360.com/googles-ai-code-generator-takes-on-github-copilot/\">https://blog.ecosystm360.com/googles-ai-code-generator-takes-on-github-copilot/</a>\"</p><p>&nbsp;</p>",
    "publish_time": "2023-05-25 12:33:05",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "参数是ChaGPT的近6倍！英特尔公布AI大模型Aurora genAI，具备1万亿参数",
    "url": "https://www.infoq.cn/article/bx7SvZNNgOd63b2hI1yz",
    "summary": "<p></p><blockquote>模型参数越大就越好吗？</blockquote><p></p><p></p><h2>英特尔公布AI大模型Aurora genAI，具备1万亿参数</h2><p></p><p></p><p> wccftech 报道，英特尔近日公布了旗下生成式 AI 大模型 <a href=\"https://www.infoq.cn/article/EDSy8OCKbCRc9TiB48PI\">Aurora genAI</a>\"。</p><p></p><p>据悉，Aurora genAI 参数量高达1万亿，其开发依赖于 Megatron 和 DeepSpeed 框架，这些结构增强了模型的强度和容量。而 ChatGPT 模型参数量是 1750 亿，这也意味着，Aurora genAI 的参数量是<a href=\"https://www.infoq.cn/article/3TR13Qp694BJ8TeOi1xV\">ChatGPT</a>\" 的近6倍。</p><p></p><p>据悉，Aurora genAI 模型是英特尔是与阿贡国家实验室和 HPE 合作开发的，它是一个纯粹以科学为中心的生成式 AI 模型，将被用于各类科学应用，包括分子和材料设计、乃至涵盖数百万来源的综合知识素材，据此为系统生物学、高分子化学、能源材料、气候科学和宇宙学等提供值得探索的实验设计思路。这些模型还将用于加速癌症及其他疾病的相关生物过程的识别速度，并为药物设计提供靶点建议。</p><p></p><p>除了科研之外，Aurora genAI 还具有在自然语言处理、机器翻译、图像识别、语音识别、金融建模等商业领域的应用潜力。</p><p></p><p>阿贡实验室副主任 Rick Stevens 介绍称，“这个项目希望充分利用 Aurora 超级计算机的全部潜力，为能源部各实验室的下游科学研究和其他跨机构合作计划提供资源。”</p><p></p><p>根据介绍，Aurora genAI 模型将由生物学、化学、材料科学、物理学、医学等学科的常规文本、代码、科学文本和结构化数据训练而成。阿贡实验室正带头组织国际合作以推进该项目，参与方包括英特尔、HPE、能源部各下辖实验室、美国及其他国际性高校、非营利组织，以及RIKEN等国际合作伙伴。</p><p></p><p>Aurora genAI 模型将运行在英特尔为阿拉贡国家实验室开发的Aurora超算上，其性能达到了200亿亿次，是当前TOP500超算冠军Frontier的2倍。近日，英特尔和阿贡国家实验室还公布了Aurora的安装进度、系统规格和早期性能测试结果：</p><p></p><p>英特尔已完成Aurora超级计算机1万多块刀片服务器的交付。Aurora的完整系统采用HPE Cray EX超算架构，将拥有63744个GPU和21248个CPU，辅以1024个DAOS存储节点。Aurora还将配备HPE Slingshot高性能以太网络。早期性能结果显示，Aurora超算系统在实际科学和工程负载上具有领先性能，性能表现比AMD MI250 GPU高出2倍，在QMCPACK量子力学应用程序上的性能比H100提高20%，且能够在数百个节点上保持近线性的算力扩展。作为ChaGPT的有力竞争者，Aurora genAI 的公布预示着AI大模型赛道又迎来了新的重磅玩家，并极有可能在未来对各种科学领域产生重大影响。不过目前，Aurora genAI 更像是处于概念阶段，英特尔的目标是到 2024 年完成 Aurora genAI 模型的构建。</p><p></p><p>对于英特尔的万亿参数AI大模型Aurora genAI，有网友表示：“我不相信仅仅增加参数数量就能改进模型，我认为我们不应该发布新闻稿追逐增加参数数量。我在研究中还发现，较大的模型通常不会表现得更好，但由于不负责任的营销，这变得越来越难以向非技术人员解释。如果我们对这些营销放任不管，我们会让很多人失望，并降低大家对AI未来增长潜力的信心——我们不想要另一个 AI 寒冬。训练这些大型模型会产生巨大的环境成本，而且理解、使用和控制这些非常大的模型（即使作为研究人员）也变得更加困难。”</p><p></p><h2>AI军备竞赛进入“万亿参数模型”对抗时代？</h2><p></p><p></p><p>近几年，随着AI大模型赛道持续升温，越来越多的科技巨头加入进来，并不断打破参数规模记录。</p><p></p><p>2021年1月，谷歌大脑团队重磅推出超级语言模型Switch Transformer，该模型有1.6万亿个参数，是当时规模最大的NLP模型。同年6月，智源研究院发布悟道2.0，该系统参数数量已超过1.75万亿，是当时全球最大的大规模智能模型系统。同年11月，阿里达摩院发布多模态大模型 M6，其参数已从万亿跃迁至 10 万亿，是当时全球最大的 AI 预训练模型。</p><p></p><p>有分析指出，中美AI军备竞赛的核心战场正是万亿级预训练模型。打造千万亿参数规模的预训练模型是人类的一个超级工程，可能会对国家甚至人类社会产生重大影响。</p><p></p><p>那么，模型参数越大就越好吗？</p><p></p><p>鹏城实验室网络智能部云计算所副所长相洋曾在接受InfoQ采访时指出：</p><p></p><p></p><blockquote>我们最初见到的一些模型是几万个参数，后来就到了几亿、几十亿、百亿、千亿，还有可能上万亿。目前从事实来说，的确是模型越大数据越多，且质量越好，带来的性能是越高的。但是我个人认为，这个提升曲线可能会有一个瓶颈期，到了瓶颈或者平台期的时候，它的上升速度可能就会缓慢，或者说基本就达到稳定了。就目前而言，可能我们还没有到达平台期。所以说，“<a href=\"https://www.infoq.cn/article/LBhYJYr63GysNIKZCgzI\">模型参数越大越好</a>\"”这个说法在一定程度上是成立的。</blockquote><p></p><p></p><p>但是，判断一个大模型是否优秀，不能只看参数，还要看实际表现。模型得出来的任务效果好，我们就可以认为这个模型是个好模型。参数不是问题，当机器无论是在存储还是计算能力都足够强的时候，大模型也可以变成小模型。</p><p></p><p>此外，还要考虑模型的可解释能力，以及是否容易受噪声的攻击。如果该模型有一定的解释能力，那这个模型就是一个好模型；如果该模型不易被噪声数据或是其他因素影响的话，那这个模型也是一个好模型。</p>",
    "publish_time": "2023-05-25 14:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]