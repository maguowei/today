[
  {
    "title": "云原生网关当道，三大主流厂商如何“竞技”？",
    "url": "https://www.infoq.cn/article/k3ssXQGz0pq4pHaLbdWd",
    "summary": "<p>&nbsp;</p><p></p><blockquote>云几乎给每项基础设施都带来了冲击，网关也不例外。近期，云原生网关概念也越来越被大家热议。那么，究竟云原生网关需要具备哪些特点？主流网关产品如何适应云原生？网关标准统一是否必要？云原生网关未来如何发展？&nbsp;4 月 24 日，我们邀请到了企业用户代表UU跑腿研发工程师王德冲，三位网关行业代表Higress发起人、阿里云微服务负责人<a href=\"https://www.infoq.cn/video/62uOgU5QxeUyitu4I9iw\">李艳林（彦林）</a>\"，API7.ai 联合创始人 &amp; CEO、Apache APISIX PMC 主席<a href=\"https://www.infoq.cn/video/INTyom2MkKjziUttDhXT\">温铭</a>\"和 F5 NGINX 资深架构师<a href=\"https://www.infoq.cn/video/RVjO8JuqI6EbA0D7Dirw\">易久平</a>\"，一起聊聊网关的那些事儿。&nbsp;以下内容根据直播内容整理，在不改变原意基础上进行了删减。<a href=\"https://www.infoq.cn/video/ryz7FSgVC3FdSzpFfalm\">点击链接可直接观看回放内容。</a>\"</blockquote><p></p><p>&nbsp;</p><p></p><h2>三大产品，如何应对业务需求？</h2><p></p><p>&nbsp;</p><p>王德冲：首先，想请各位针对UU跑腿的一个场景来提出自己的解决方案。</p><p>&nbsp;</p><p>具体是这样的：UU跑腿已经是云原生架构了，但作为一家配送平台，UU跑腿有大量的客户需要通过网关接入平台，同时也有大量的后端服务需要接入网关，因此确保网关的稳定性和可靠性是非常重要的，这样才能保障业务的持续性和客户的满意度。在这样的需求背景下，APISIX、NGINX 和 Higress 会分别用怎样的方式来帮助企业达成目标呢？</p><p>&nbsp;</p><p>李艳林（彦林）：我了解到UU跑腿业务是线上线下结合的。因此，相比于一般的纯线上业务，对于稳定性的要求会更高一些。我认为这是可以理解的。随着整个业务逐渐上云，整个行业对可靠性的要求会越来越高，特别是网关作为整个公司的入口，如果出现问题就会带来非常大的损失。我们在做Higress的过程中也是更加关注稳定性。我想分享一些想法。</p><p>&nbsp;</p><p>首先，我们的架构和内核使用了Envoy和Istio，它们的好处是将数据面和控制面解耦。这意味着，如果控制面出现问题，数据面不会受到影响。这种分离有效地避免了控制面的安全和稳定性问题对数据面的影响。在内核上，我们使用了一种称为Wasm的沙箱扩展机制。如果扩展逻辑代码出现问题，WASM沙箱会做很好的隔离，不会影响整个网关的主业务。这种设计可以在一定程度上控制整个系统的爆炸半径。</p><p>&nbsp;</p><p>其次，关于UU跑腿和阿里巴巴的IOT设备，因为在线上线下结合的过程中，这些设备对稳定性有更高的要求，特别是在多端情况下。如果在一般情况下去更新规则、路由或证书插件，连接可能会发生抖动。但由于 Higress 采用了 Envoy 内核，所有规则变更都是热更新的，因此对长连接都是非常友好的，不会抖动。这将显著提高在线业务的连续性和稳定性。</p><p>&nbsp;</p><p>最后，简单介绍一下Higress。虽然我们在2022年7月的云栖大会上开源了它，但在阿里云内部，我们已经孵化云原生网关大概三到四年了。最初，它是为了解决阿里电商和蚂蚁之间的互通问题，让RPC可以直接调用并使用GRPC协议。经过三四年的验证，包括在双十一等大促和成千上万家企业的验证，它现在非常稳定。在这些基础上，Higress 主要关注一些推空保护和其他细节方面的功能。</p><p>&nbsp;</p><p>易久平：首先，我赞同从业务视角出发来讨论技术问题。UU跑腿这种场景，线上线下结合，对稳定性要求较高，这是所有互联网应用的通用需求。我们通常会关注性能、稳定性和安全性。从 NGINX 的角度来看，我们一直致力于优化数据面、提升性能，这也是 NGINX 长期发展的核心思路。</p><p>&nbsp;</p><p>在性能方面，整个 NGINX 的性能口碑在业界应该是毋庸置疑的。在稳定性方面，我们更关注一些可观测性的能力。当然，商业版本和开源版本在可观测性方面有差异。商业版本的可观测性比开源版本更强，因为我们可以自己定制监控指标，而开源版本只提供基本的仪表盘。</p><p>&nbsp;</p><p>从稳定性角度看，NGINX流量的出入口监控指标是非常完整和清晰的，无论是面向上游还是下游，可以很容易地定位问题。此外，通过输出日志做分布的链路跟踪，可以解决完整监控的需求。这些监控指标可以很容易地与监控平台集成，实现整个稳定性的保障。</p><p>&nbsp;</p><p>另外，实现自动化的运维和扩缩容也是非常重要的。在云原生体系里面，我们可以通过与 API Server 做集成，使用 Kubernetes 的原生风格做运维配置，这套体系就解决了一些功能性问题。当然，自动化运维也带来了一些问题，比如在动态环境下经常需要扩缩容和发版本，这可能会造成一些问题。不过，商业版本有一些 API 的动态更新能力，可以很好地解决这些问题。在开源版本中，可能还倾向于使用配置文件做Reload。但是，通过 Ingress Controller 的实现，这个问题已经被解决了，不用再手动配置和Reload，这个动作已经被自动化实现了。</p><p>&nbsp;</p><p>另外还有一个重要的方面是安全性，这在 NGINX 产品体系中非常受到关注。在云原生体系中，安全通常涉及零信任和 WAAP 应用防护等方面。零信任通常涉及认证、授权、加密和解密等功能，包括SSL/TLS证书的单向和双向认证。我们还提供了诊断功能。这些功能都可以通过网关来实现。</p><p>&nbsp;</p><p>此外，我们还可以从 WAAP 的视角来看待安全性问题。NGINX 提供了商业版的 NGINX App&nbsp;Protect 模块，支持WAF、七层DDoS防护，机器人防御和 API&nbsp;安全。因此，从整个安全体系建设的角度来看，我们可以提供完整的安全能力。综合来看，通过这几个核心能力，我们可以解决UU跑腿的性能、稳定性和安全性问题。</p><p>&nbsp;</p><p>温铭：从高可用方面看，我们可以从两个方面进行考虑：架构和功能。在架构方面，我们通常采用DP（数据平面）和CP（控制平面）分离的架构，每个DP都是无状态的，可以随意地进行扩缩容。如果CP宕机了，不会影响DP的正常运行，同样，如果DP宕机了，也不会影响其他DP的正常运行。这种架构能够保证我们的业务具备弹性扩缩容的能力，同时也能够减少客户端的感知。</p><p>&nbsp;</p><p>在功能方面，我们要确保业务具备高可用性，就需要实现一些功能，例如灰度发布、蓝绿发布、探测后端节点健康状况、内置API熔断和服务熔断等。从架构和功能两个方面保证业务的高可用性。</p><p>&nbsp;</p><p>此外，我们还需要关注基础组件的质量，这些基础组件是用户看不到的。这些组件包括代码质量、自动化的CI/CD、端对端测试、混沌测试等。在APISIX中，我们内置了大量的测试案例代码，包括单元测试、E2E测试、混沌测试，以及一些基准测试等，从而保证APISIX具备高可用性。</p><p>&nbsp;</p><p></p><h2>企业需要怎样的网关？</h2><p></p><p>&nbsp;</p><p>王德冲：除了刚才提到的，现在企业对网关产品还有哪些要求？现在网关产品已经解决了哪些问题？还有哪些需求未被满足？</p><p>&nbsp;</p><p>温铭：API的全生命周期是从API的设计开始，然后经过Mock和测试环境，最终到达生产环境。在API的生命周期中可能会涉及到一些后期的操作，比如DevPortal，等等。很多网关产品主要在API生命周期的中间环节发挥作用。</p><p>&nbsp;</p><p>在这个环节中，网关产品管控着生产环境中的流量。与此同时，它们可能不会像Postman那样在开发阶段进行一些前期工作。但是这些网关产品能够通过API、Swagger等方式进行集成。至于后期的DevPortal部分，它们主要负责API的发布和“货币化”。有些API网关的厂商会提供这样的服务。</p><p>&nbsp;</p><p>对于APISIX来说，我们主要处在生命周期的中间环节，更准确地说是处在中间的底层。因为用户使用API网关主要是为了进行互联网业务、金融类业务或者IOT业务。我们更关注的是提供底层的基础设施，让大家可以接入OpenAPI、Swagger和Consumer等，从而让大家可以消费API。我们还提供一些底层的功能，比如CV限流、限速以及计费等等。这就是我们对自己定位，我们为上层的整个生态提供能力，并开放各种标准的接口供大家使用。</p><p>&nbsp;</p><p>李艳林（彦林）：这个话题很有意思，它实际上关乎人们对整个网关未来的定位和趋势判断。从阿里云的角度来看，我们认为客户最关注的是网关的安全问题。事实上，阿里巴巴最初开发网关也是为了解决安全问题，因为我们希望能够通过一个统一的入口来解决安全问题。</p><p>&nbsp;</p><p>以前我在外部也遇到很多客户的应用因为一些问题而被攻击，导致整个风险极大。因此，网关的第一个重要作用就是建立统一的安全防线。Higress在这方面提供了一些WAF插件、认证插件，以及黑白名单机制，可以为企业数字化升级过程中保驾护航。</p><p>&nbsp;</p><p>我认为，无论是国内还是海外，安全都是网关的首要问题。虽然国内许多人关注高可用性，但海外很多人更加注重安全性，特别是像纳斯达克这样的金融机构和中央情报局等机构，它们都在某些公有云上运行，并且非常注重应用安全和基础设施安全。</p><p>&nbsp;</p><p>其次，我想谈谈高可用和稳定性。其实，大家最关心的问题可能是我们的网关稳定性如何、能否帮助我们解决高可用问题。在这方面，Higress做了一个深度集成，使用阿里云的Sentinel，在入口提供整体的降级防护能力，以防止业务雪崩。今年我们搞了很多次大促、海外业务等爆发性增长，当流量达到峰值时，建立防护线以防止异常流量打垮整个系统非常重要。特别是对于像UU跑腿这样有高峰值场景的业务，保障业务的整体意义更加重大。</p><p>&nbsp;</p><p>过去两年，我在做海外网关竞品分析时发现，最早的架构可能是SLB+ECS（单体应用架构），包括云服务都是这样的架构。随着微服务的兴起，人们开始使用API网关等工具来管理微服务，并将其集成到服务网格体系中。在Serverless时代，每个领域都有独立的入口，并且运营数据是独立统计的。这种架构演进也带来了问题。例如，我们今年做了一个标杆客户，需要挂三层网关，相当于在单体到微服务、再到Kubernetes 的过程中添加了网关层，导致整个访问链路多层网关，最终影响RT和运维效率。</p><p>&nbsp;</p><p>我看到UU跑腿之前也在处理协议的转换，将 HTTP 转换为 DUBBO，需要加一个网关，这样代价太大了。因此，Higress定位是支持多种后端服务负载模式的统一，包括单体微服务、Kubernetes和整个服务器的负载均衡。我们将后端的能力暴露到北向，进行服务发现，并将整个微服务网关、流量网关和安全网关三合一，以便高效地解决业务问题。这样，用户的业务和运维成本，以及资源成本都会大幅降低。我们发现客户非常认可这种做法。</p><p>&nbsp;</p><p>在网关的标准方面，我最近在研究时发现，有三个标准，分别是协议标准（HTTP 加 RESTFUL），文档标准（Swagger），以及路由标准（Kubernetes Ingress / Gateway API）。Kubernetes推出了路由标准，并通过Higress逐渐将路由标准统一起来，这是非常好的事情。此外，开源社区正在推动Gateway API的完善，这将进一步统一路由标准。我们希望通过开源标准的建立来推进整个产业的发展。类似于Linux标准、MySQL标准等，网关标准的建立对于未来云计算的发展是至关重要的。未来，我们相信这些需求，包括API管理的更多能力，能够更好地跨越云、混合云和多云。这是我思考的一些问题，希望对大家有帮助。</p><p>&nbsp;</p><p>易久平：关于这个事情，NGINX的思路是不设统一的标准。从我们公司的产品战略来看，我们将场景分成了三个大类。第一类是连接应用程序，这种场景可以定位为传统的面向软负载均衡或反向代理。在此基础上，我们会添加一些安全功能，流量路由等。这种使用场景在整个技术架构下都很有价值，无论是放在数据中心入口还是放在跨Kubernetes集群入口，或者是跨技术架构的入口上，都有其存在的价值。</p><p>&nbsp;</p><p>另一个场景是连接API，我们将这个场景定位在更细的API级别。类似于其他API网关，我们将其分为数据面和控制面。同时，我们通过一些开发者门户暴露API，并提供API文档，使开发者能够更方便地查看API文档。我们还提供了一个门户来管理这些API策略，例如限流限速策略，以便将这些策略下发到API网关上。</p><p>&nbsp;</p><p>第三个场景是连接Kubernetes。在云原生体系中，有Ingress、Gateway&nbsp;API和Service Mesh等场景。我们将这些场景定位为放在Kubernetes入口或某个服务入口上。</p><p>&nbsp;</p><p>在这三个场景下，我们会添加安全功能。连接应用程序、连接API和连接Kubernetes，然后在其上叠加安全，是我们产品建设的核心思想。通过这种方式，我们可以实现南北向和东西向流量的调度和安全。</p><p>&nbsp;</p><p></p><h2>专家眼中的云原生网关</h2><p></p><p>&nbsp;</p><p>王德冲：各位认为，一个优秀的云原生网关产品应该是什么样子的？</p><p>&nbsp;</p><p>易久平：我的观点是，云原生的核心技术包括容器化、微服务、服务网格、不可变基础设施和管理API生命周期。当我们谈论这些技术特点时，云原生网关更多地强调在Kubernetes集群的入口。然而在整个云原生体系中，这个过程不是一蹴而就的，存在着新老兼容或者多集群同时存在的情况，需要考虑多集群之间是主备高可用还是多活高可用等。因此，不同的场景对网关的要求是不一样的，因此可能更适合放在Kubernetes集群的入口，也可能更适合放在Kubernetes集群外部。</p><p>&nbsp;</p><p>我认为，云原生网关无论以什么形式存在于云原生体系中，都需要解决两个问题。首先，它必须与云原生体系融合。其次，它需要能服务好云原生体系。帮助应用实现灵活的扩缩容、可观测性以及快速变更而不影响业务，这是最关键的点。</p><p>&nbsp;</p><p>温铭：我更多的是从生态的角度来看，因为在云原生生态系统中有很多开源项目，比如 CNCF 中就包含了很多开源项目。这些项目能够在云原生中以开源为主体，与各种开源项目进行协作和集成，例如在容器中运行并由 Kubernetes 进行调度。随着企业迁移到公有云、混合云和多云架构，应用程序能够在任何环境中进行部署，实现了边界的模糊化，用户不必再关心底层基础设施。因此，我认为云原生的优势更多地体现在生态系统上，而在功能方面，大家都差不多，无论是可观测性、可扩展性还是其他方面的功能，在大多数情况下都没有太大差异。</p><p>&nbsp;</p><p>王德冲：大家未来1年在云原生网关的规划是什么样的？</p><p>&nbsp;</p><p>温铭： APISIX 经历了几个阶段。最初，我们突出的是性能。接着，我们关注稳定性。而现在，我们更加注重让 APISIX 更加易用。在过去的几年中，APISIX 由全球五六百个开发者共同贡献，迅速发展成为一个顶级开源项目。</p><p>&nbsp;</p><p>APISIX 拥有很多功能和插件，大概有 100 多个插件和各种功能。虽然它功能齐全，但是它距离好用还有很大的差距。因此，我们未来一年的主要目标是让 APISIX 更加易用，让用户可以更轻松进行各种配置和插件的安装和使用，使其成为一个更加顺手的开源项目。</p><p>&nbsp;</p><p>李艳林（彦林）：我们一直参与阿里容器化的架构演进。这个过程中，我们发现云原生网关应该具备四个特点：标准化、高集成、热更新和易扩展。为什么呢？</p><p>&nbsp;</p><p>首先，我们期望代码可以跨云、混合云、私有云和公有云运行，而不受厂商的限制。比如，采用某个厂商的实现时，如果需要切换到另一个厂商，不会因为厂商差异而出现问题。因此，标准化非常重要，它解除了厂商的绑定。Ingress 标准、Gateway API 标准和容器标准等构成了云原生的基础。</p><p>&nbsp;</p><p>在此基础之上，我们强调云原生网关应该具备高集成特点。作为一家以公有云为主的厂商，我们的思路与专有云为主的厂商有所不同。我们提到高集成，是因为我们发现在传统架构中，通常有三层：前端安全网关 WAF、中间流量网关 Nginx 、后端微服务网关 SpringCloud Gateway。例如，我曾遇到一位客户在面对超时问题时需要拉三拨人去查，判断到底是WAF超时，还是Nginx 或SpringCloud Gateway超时，这样的部署资源成本很高，而且排查链路效率非常低。</p><p>&nbsp;</p><p>我们认为“合久必分，久必合”。为什么有这个想法？因为我们是从第一性原理出发，阿里内部并没有那么多网关，为什么今天会有三个？其实是为了简化架构，更好地拆分模块和职能，但实际上这不符合用户的利益。用户的实际利益在于成本，包括运维成本和部署成本。因此，我们认为大部分客户可能都需要高集成，包括像阿里、快手、抖音和腾讯等头部厂商。这些大厂也需要拆分，拆分逻辑包括四层和七层，上层使用SRB，下层可能使用原生网关，上层承担流量，下层负责路由转发。但对于大部分中小客户，一层就足够了。例如，我们的客户已经有数百万连接和几百万TPS的数据，但只需要一层就足以应对。这显然降低了整个运维和部署成本。</p><p>&nbsp;</p><p>第三个是热更新。实际上，我们认为 Kubernetes 带来的一个核心变化是业务频繁调度。如果调度频繁，后端发布和规则变更需要快速联动，尤其是在存在长连接和 IOT设备的情况下，连接的抖动是不可接受的。因此，热更新在确保连接稳定性方面非常必要。随着基础设施和使用场景的不断变化，包括线上线下结合、IOT设备等，热更新的重要性会越来越突出。</p><p>&nbsp;</p><p>第四个，易扩展性也是重要的一点。我们发现许多客户在网关上都进行了定制，主要包括安全和路由方面的定制，甚至包括存储方面的定制，这是因为不同公司在安全定制方面的策略不同。因此，易扩展性非常重要。我们采用了多语言热更新等机制，使得我们的网关可以更好地支持定制需求。因此，我们认为在未来，这四个能力：易用性、高集成、热更新和易扩展性，将是原生网关必备的。</p><p>&nbsp;</p><p>在今天的原生网关定位和发展过程中，我们围绕着四个关键点展开，以差异化能力为目标。大家都知道，像APISIX和 NGINX这样的巨头拥有非常强的护城河，所以我们需要构建差异化能力，围绕着这四个关键点进行。目前，我们已经完成了整个原生网关的布局，接下来会在易用性和 Gateway API 的标准化上继续探索。</p><p>&nbsp;</p><p>我们的思路与温铭的思路可能有些不同。他们认为 API 网关或云原生网关是基础能力，但我发现云原生网关与 API 网关的区别在于云原生网关多了一个 API的层次。这是非常重要的，因为有了 API，我们可以利用其自动化测试、调用和安全审计的能力，这对于未来结合人工智能非常重要。我们意识到，如果只做底层的原生网关和基本的路由能力，就无法获取服务和 API 的元数据，这将限制我们在增加更多功能时的扩展能力。因此，我们最近在内部探索一种可能的演进方向。</p><p>&nbsp;</p><p>我们已经完成了阿里巴巴的Nacos和DUBBO生态的整合，包括在灰度发布方面集成了Kubernetes OpenKruise，这为我们打造更多的生态扩展奠定了基础。尽管我们目前的插件相对于NGINX或APISIX来说较少，但我们采用的是整个服务网格的架构，可以复用一套扩展机制来快速构建统一控制东西南北流量的能力。我们正在不断积累这些能力。我们相信通过插件市场，可以一起扩展整个上下游，包括API管理和安全等能力，这样就能为客户提供一站式的网关解决方案，而不需要过多地研究其他技术。</p><p>&nbsp;</p><p></p><h2>云原生网关演化思路</h2><p></p><p>&nbsp;</p><p>王德冲：作为产品提供方，大家都是如何进行自己的产品演化的？各位认为，社区推动与企业推动，哪个更重要？</p><p>&nbsp;</p><p>李艳林（彦林）：这个话题很有趣。我之前看到一篇文章，讲的是《开源与商业的关系》。我认为，今天的开源与商业关系正处在一个非常重要的阶段，就像中国的软件市场一样。例如，你的手机里有多少款软件是付费的呢？这反映了中国人民对软件付费的态度。如果没有人为软件付费，软件的持续发展就会受到威胁。因此，开源与商业之间的关系非常重要，就像如今社区与企业之间的关系一样。</p><p>&nbsp;</p><p>有点像之前的360互联网模式，其中大部分人免费使用，只有1%的人付费。这种模式可以使开源与商业相互促进，从而实现持续的发展。如果没有这个正循环，一些项目就很难维持下去，例如早期的Dubbo 以及现在的Spring Cloud Netflix ，每公司都有自己的KPI，如果项目没有持续发展，就会面临失败的风险。今天我们能够在这里交流，说明我们背后有一个力量在支持着我们。但是如果没有这个力量，这些事情就会变得更加困难。</p><p>&nbsp;</p><p>我们需要不断地加强社区投入，促进生态建设。我们都知道，在数字化时代、云时代，开源就是标准。我们通过开源软件构建了整个开源标准，然后借助众人的力量推动它的使用场景和通用性，然后达到最佳状态，这样我们才能把整个领域做大、扩大这个蓄水池。这其实是一种互联网经营模式，当这个蓄水池足够大之后，我们才能继续生存下去。只有这样，我们才能更好地回馈社区。</p><p>&nbsp;</p><p>不过，如今开源的诉求与商业的要求还是有所区别：开源更关注易用性、生态；商业版本则更关心产品的稳定性、安全性、高可用性和兜底服务能力。</p><p>&nbsp;</p><p>阿里巴巴是开源、商业和内部三位一体。我们通过开源软件打磨产品的易用性和生态、和扩展性，而商业上更关注企业级特性，如稳定性和安全性，我们在阿里内部的场景打磨高可用性和高性能。这几个方面是相辅相成的，大家都明白开源到商业、社区到企业的闭环非常重要，这也是我们能够生存下去的关键。</p><p>&nbsp;</p><p>易久平：彦林老师刚才的分享非常到位，NGINX 的整体思路也是如此。目前，我们已经加强了去年提出的开源战略思想，即要扩大开源，包括开源功能和更多控制面、数据面商业能力的开放。我们正在将我们的开源社区扩大，并将源代码管理放到更大众化的代码仓库上，以便让更多人参与其中。公司的定位是希望能够扩大开源社区，为开源社区做出更多的贡献、提高装机量，让更多的人使用和参与，来改善生态。</p><p>&nbsp;</p><p>其他方面，我们希望通过提供企业化能力来减少开源使用的成本，同时提供点对点的商业支持、销售商业产品和提供SaaS服务。目前我们的SaaS服务可以放在公有云上，也可以用我们自己的分布式云平台。</p><p>&nbsp;</p><p>温铭：APISIX 是一个由 Apache 软件基金会赞助的顶级开源项目。绝大部分功能都是由开源社区贡献的。最初的技术架构和底层算法是由一些开发者创建的。社区驱动了很多插件和生态，以及修复了很多由使用者报告的问题。因此，社区对于 APISIX 的发展和完善做出了很大的贡献。如果你对某个功能感兴趣，比如在使用 Clickhouse 进行日志分析时想要做一些集成，就可以在社区寻求帮助。虽然我们可能不理解这些贡献者为什么会这么做，但是他们为 APISIX 的发展做出了重要的贡献。</p><p>&nbsp;</p><p>对于项目维护者来说，有些功能我们可能不太理解用户的具体使用场景，比如支持 MQTT 或 GraphSQL，因为这些场景在我们的使用中并没有遇到过。但随着用户声音越来越多，维护者们也会意识到这些新需求的存在，从而推动新功能的开发。这也是 APISIX 功能不断增强的原因，即主要是由社区驱动。</p><p>&nbsp;</p><p>商业公司则更多是由商业客户驱动，他们往往面临更大规模、高并发等复杂的情况，发现了开源用户不容易发现的 Bug 或风险，从而对 APISIX 进行优化和改进，我们企业版的 APISEVEN会提供一些更丰富的企业级的功能。</p><p>&nbsp;</p><p>王德冲：云原生网关可以在企业数字化升级中发挥什么样的作用？</p><p>&nbsp;</p><p>温铭：数字化转型听起来似乎是一个高大上、高层次的话题，但如果你和企业客户交流得多就会发现，中国企业距离数字化还很远，很多系统之间还没有完全实现良好的对接。</p><p>&nbsp;</p><p>其实数字化就是所有数据能否通过 API 进行查询，而这些 API 是否能够相互连接。我们现在使用的互联网和各种视频软件，甚至我们使用的办公软件，本质上都是通过 API 将数据从一个地方转移到另一个地方，然后再相互传递。对于企业来说也是一样，数字化就是将企业的各个孤立的服务通过 API 等方式连接在一起，从而提高效率。因此，数字化中很重要的一部分就是将不联网的服务变成联网服务，再将联网服务变成相互交换信息、数据的方式，这样才能提高效率。</p><p>&nbsp;</p><p>易久平：我之前查询了一下数字化转型的含义，因为我觉得这个名词对于很多人来说，虽然听过很多次，但并不一定真正理解。一个比较形象的解释是，我们正在从信息化时代转向数字化时代。在信息化时代，我们的生活大部分轨迹还是线下的，只是偶尔通过线上渠道进行协助，完成一些常见的活动，比如购物或就医等。而在数字化时代，我们在线下完成的事情较少，大部分活动发生在线上。在这个背景下，我们对应用的复杂度、API数量、系统稳定性和安全性的要求更高。我之前举过一个例子，特别是在上海去年封控期间，核酸检测系统崩溃后，人们冒着感染风险在外排队。你会发现，随着数字化转型程度的提高，对系统稳定性和安全性的要求也越来越高。</p><p>&nbsp;</p><p>从网关的角度来看，我们作为连接客户端和服务端的中间载体，作为统一的入口，安全性和稳定性尤为重要。从网关的重要性程度来看，这一点毫无疑问地得到体现。</p><p>&nbsp;</p><p>李艳林（彦林）：大家对数字化的理解大概是这样的：首先有一个网站，其次有一个大盘。不知道大家是否看过在朋友圈中转发的“灵隐寺的大盘”，一般来说，传统公司对数字化的需求可能就是有一个网站和一个大盘；对于已经进行了数字化升级的公司来说，它们需要从传统架构过渡到云原生架构。</p><p>&nbsp;</p><p>第一类用户需要快速构建企业级、高可用、安全的入口，我们可以帮助他们实现这个目标。第二类客户，也是我们目前关注的重点客户，因为他们通常是传统架构，希望升级到微服务和云原生架构。最简单的方法是在前面加一个网关。有了网关，传统的应用可以继续使用传统的负载方式，而微服务可以使用微服务负载方式，这样就能快速进入云原生时代。</p><p>&nbsp;</p><p>那么，如何实现新老系统之间的互联互通呢？云原生网关充当了统一的控制中心，可以控制流量和管理新旧系统之间的互动。举个例子，可以实现上云和下云之间的互通，不同业务域之间的跨域互通，通过网关来快速解决新老系统之间的连接和升级。这样一来，新的IDC和老的IDC之间可以快速连接和升级，从而加快整个数字化升级和创新的速度。</p><p>&nbsp;</p><p>因为大家都知道，当一个IT系统变得越来越复杂时，采用微服务架构可以释放出更大的研发效率红利，尤其在海外更为明显。这也是为什么海外要推崇Serverless架构，从微服务走向Serverless，因为人力成本是最高的，所以要尽可能降低运维和开发成本。所以，对我们来说，这意味着我们可以加快企业的创新速度。</p><p>&nbsp;</p><p>另外一个我最近研究的课题是关于上云和数字化过程的。实际上，它可以分为两个部分：业务数字化和业务智能化。在第一个阶段，我们的云原生网关可以帮助用户快速将单体应用、微服务应用以及整个 Kubernetes等多种负载快速地将后端服务能力输送到客户端，这是我们的第一个价值所在。</p><p>&nbsp;</p><p>第二个价值在于如何快速将后端的数据能力和AI能力输送到客户端。这个问题也非常重要，包括之前提到的GraphQL等。在研究中，我发现通过低代码和快速的方式将后端的数据能力快速输出到客户端非常有意义。从业务智能化的升级过程来看，我们的网关可以快速将后端的AI能力输送到手机端，这样就可以帮助企业快速将后端能力输出到客户端和生态系统。</p><p>&nbsp;</p><p>提到API领域，通过服务的货币化将调用、生态全部整合起来，也具有很大的意义。在海外，这种做法已经得到了很好的发展，而我相信国内未来也会成为趋势。为什么这样判断？因为国外的人力成本较高，所以他们更倾向于使用别人的服务而不是自己开发，而国内则相对较少。但随着中国数字化水平的提升，程序员的工资持续上涨，API化仍然是未来的趋势，这是第二个可能性，即我们能够帮助企业快速将后端能力输出到客户端。</p><p>&nbsp;</p><p>第三个价值在于网关本身。云原生网关在入口处建立安全和高可用的防线非常重要，因为近年来行业内出现了数据泄漏和稳定性问题，网关作为一个关键位置具有致命的意义。</p><p>&nbsp;</p><p></p><h2>网关会被取代吗？</h2><p></p><p>&nbsp;</p><p>王德冲：当前的网关行业处于什么阶段？为什么？对于想要进入这个市场的开发者来说还有哪些机会？ 门槛高不高？</p><p>&nbsp;</p><p>李艳林(彦林)：我的判断是这样的，现在正是传统网关向云原生网关迅速发展的爆发期。首先，我们可以看到容器已经成为基础设施的主要架构，而Kubernetes通过网关构建了一个标准，这实际上是行业发展的基础。第二点是，从CNCF报告和整个行业动态来看，云原生网关和API网关在过去三年里增长了一倍以上，每年都在持续增加，增长速度非常快。我最近做分享时仔细数了一下，在CNCF里大约有二三十个项目涉及这个领域。在这个领域有这么多的参与者，说明这是一个机会，吸引了许多人涉足。</p><p>&nbsp;</p><p>在这个领域中，我进行了一些分析。大约有40%的项目是基于NGINX内核构建的，而35%的项目是基于Envoy内核构建的。可以说，Envoy与NGINX占据了75%的网关实现市场份额，这确实是两个主要的主流力量。</p><p>&nbsp;</p><p>温铭：我认为，如果仅从公司业务场景分析的话，构建一个API网关并不是很难的事情，不管是基于开源项目还是从头开始开发，门槛都不算高。例如，APISIX最早版本我们只用了两三个月时间就完成了，它包含了基础组件并能够正常运行。</p><p>&nbsp;</p><p>然而，从只能供自己使用的工具，到真正能够应对数百万QPS、每天处理数百亿请求、处理数百亿到千亿次API调用的工业级可用工具，是一条漫长的路。这其中并不仅仅是技术挑战，更关键的是，是否能够遇到足够多的场景和客户来验证这一过程。因此，APISIX大概花费了几年时间才逐步稳定下来。如果你看一两年前的APISIX，经常会遇到CPU利用率达到百分之百或者内存溢出等问题，这些问题在GitHub的issue中也有很多用户提到。但是，通过不断踩坑，APISIX逐渐变得更加稳定。因此，我认为构建一个轮子并不困难，真正的挑战是将其打造成一个可靠的工业级产品。</p><p>&nbsp;</p><p>我认为真正的挑战可能不是来自技术，可能并非另一个API网关，而是其他完全不同的产品将我们这些厂商挤出市场。因此，我们经常需要考虑这些变量来自哪里。比如，现在非常火的ChatGPT大模型，我一直在思考它对我们当前从事技术中间件和网关开发的影响，是否会在某一天让用户不再需要我们，而用全新的产品取而代之？</p><p>&nbsp;</p><p>易久平：我也看过一些报道，例如艾瑞咨询在2021年关于《人工智能API经济》的一篇报道中提到，通过API发布基于人工智能的核心能力，包括像ChatGPT这样的服务。实际上，很多人都将其作为客户端与服务端进行交互，这种情况下只要有客户端和服务端的存在，API网关就会有价值。因此，从这个角度来看，我们不太可能被替代。</p><p>&nbsp;</p><p>正如之前彦林分享的，许多网关更多地关注业务场景或部署环境的适配。这导致了一个现象，就是在过去的二十多年中，NGINX在开源生态方面似乎没有太多进展。尽管有很多人编写了一些扩展模块和功能，但包括官方仓库在内，仍然停留在那个以HG开头的域名下。为什么会出现这样的结果呢？实际上，这是有原因的，因为在开发数据面的核心能力时，对稳定性和性能有相当高的要求。如果你没有保护好作为入口的门，就会给应用带来很大的风险，可能会意外引入漏洞（CVE）。</p><p>&nbsp;</p><p>当然，这并不意味着开放社区可以将其扩大为商业社区的借口。但总的来说，这也说明了仍然存在一定的门槛，如果真的要从事相关工作并非那么简单。</p><p>&nbsp;</p><p>另外，从控制面或业务场景的支撑角度来看，这个领域是不断创新的。针对不同的行业、协议和应用可能有不同的要求，例如流媒体协议和各种物联网协议可能不同，因此在这个层面上进行创新，并将其与业务场景相结合是很常见的。在某个垂直领域做一些API网关的创新可能会有一定的机会，但这也要看具体情况。</p><p>&nbsp;</p><p></p><h2>统一标准，重要吗？</h2><p></p><p>&nbsp;</p><p>王德冲：当前，网关行业的发展面临着哪些问题？如何保证网关生态的长期健康发展？</p><p>&nbsp;</p><p>李艳林（彦林）：从整个行业的角度来看，现在的标准正在逐渐建立，但还没有完全稳定下来。目前实践方面相对来说已经比较集中，大约占了75%的份额，但还有35%是比较分散的长尾部分。我们希望行业标准能够统一，让大家都能达成共识。比如，MySQL、PostgreSQL、Oracle等数据库在市场上占有较大份额，加上其他一些常见的网关产品，可能占据了90%左右的市场份额，这种收敛的趋势对整个产业会有积极的影响。我们需要共同推动这些标准的发展，加快标准的形成。</p><p>&nbsp;</p><p>未来，我认为网关在安全和Serverless领域都有巨大的挑战和机遇。首先，对于开发者而言，他们在软件开发过程中首先关注的是研发效率，其次是扩展性，然后是稳定性，最后才是安全性。但实际上，随着数字资产的增大，包括像俄罗斯和乌克兰战争这样的事件，我们会发现各种攻击和防御正在不断增加。这些安全威胁的加大将带来巨大的变数和机遇。例如，能否利用人工智能自动进行攻击和防御，这都是攻防之间的问题。谁能够利用人工智能和算力快速构建防护壁垒？包括阿里云自身在内也在进行相关探索。</p><p>&nbsp;</p><p>其次，将网关发展到极致，实现服务化也是一个有趣的方向。当前的四层网关和云厂商的第二层网关基本上都是基于特定内核构建的。而对于我们的七层网关来说，原生网关应该具备流量付费和弹性调整能力，以适应资源需求的变化。将网关无服务化将会是一个有意义的发展方向。我们一直在对网络进行抽象，从四层到七层再到网关实质上是网络一层层向上抽象，对开发者越来越易用。未来，能否实现网关的无服务化和极致弹性是一个重要的挑战。</p><p>&nbsp;</p><p>目前看来，网关行业处于一个非常有前景的阶段，市场需求强劲，各家企业都在争相进入，并通过共同努力来推动行业的发展。</p><p>&nbsp;</p><p>温铭：我同意彦林之前提到的观点，当前的情况可以描述为百家争鸣，这其实是一个最好的状态。大家都非常重视网关领域，无论是使用方还是开发者，都希望能够做出更好的网关产品。因此，许多开发者、大公司和创业公司都希望在这个领域分一杯羹，我认为这是一个非常好的现象。</p><p>&nbsp;</p><p>关于标准的问题，我对此并不像彦林那样乐观。我认为建立标准是一件比较困难的事情。一旦建立了标准，例如从NGINX到Envoy，很可能不愿意打破现有的标准，更多的是希望能够达成共识，例如大家普遍认可Gateway API。但要实现从一个API网关无痛迁移到另一个API网关仍然是比较困难的。</p><p>&nbsp;</p><p>易久平：我认为参与标准的制定是非常重要的，因为在应用场景方面，不论是Higress还是Gateway API，都存在一些不足之处。作为Kubernetes集群的入口，它需要满足各种API网关的需求。特别是在国内，有一些典型的需求，比如全链路灰度发布。那么我们是否可以将这些需求直接纳入到Gateway API的规范中呢？类似这样的场景都可以推动标准的发展。</p><p>&nbsp;</p><p>就像我们看到的情况，包括NGINX已经实现了Ingress Controller，但我们也发现为了支持许多高级功能，用户需要扩展自定义资源（CRD）等，相当于自定义了一些扩展。在这种背景下，对于用户来说，迁移的成本就会增加，因为很多厂商并没有完全按照标准实现他们的网关。这样一来，如果要进行替换，就必须要支持那些CRD的功能后才能进行切换。类似这样的情况可能会持续存在。如果有一个相对完整、通用性强、能够支持大多数业务场景的规范被定义出来，那对于开发者和使用者来说是非常有利的，可以促进网关产品的切换，并推动整个网关市场的发展。</p><p>&nbsp;</p><p>总结一下，我认为参与标准制定对于发展网关领域非常重要，因为它可以解决一些现有解决方案的不足，并推动创新和市场发展。</p><p>&nbsp;</p><p></p><h2>云原生网关的未来</h2><p></p><p>&nbsp;</p><p>王德冲：最后，请大家分别总结下未来云原生网关的发展趋势？</p><p>&nbsp;</p><p>温铭：我认为云原生网关的发展趋势更多是生态系统的健全性和开发者的便利性。大家已经不再仅仅关注QPS和功能，因为大家基本都已经采用了基于Envoy的解决方案，所以在功能性上差异并不大。</p><p>&nbsp;</p><p>相反，人们越来越关注以下几个方面：首先，它是否真的易于使用、是否确实在混合云或私有云环境下提供了相同的体验；其次，是否能够方便地集成更多的生态系统。作为一个中间件，网关需要连接各种下游终端和协议，并与各种云服务、SaaS服务、公司内部服务及其他项目连接。所以，能否构建一个强大的生态系统是非常重要的。</p><p>&nbsp;</p><p>易久平：我认为整个网关的发展必须与业务应用形态的变化相符合。我一直在分析网关的发展过程，发现它的演进一直与应用形态的变化相伴随。在当前的云原生体系中，开发者变得更为重要，因为开发者更注重管理自己的API和应用。从这个角度来看，开发者习惯于通过扩展和参与来完成很多事情。这与温铭老师的观点类似，我们希望扩大开发生态系统，让人们可以基于这个生态系统进行集成扩展。</p><p>&nbsp;</p><p>从云生态系统角度看，云生态系统一直在发展，不同的技术点正在逐渐形成规范。对于网关来说，它必须首先融入整个云原生生态系统，因此必须实现各种规范，包括监控规范、API网关规范和部署扩展规范等。其次，要为云原生服务，并支持云原生应用形态的变化，包括从微服务到服务网格，再到未来的无服务器。因此，在各方面不断提升支持是必要的，最终目标是提升用户体验。对于终端用户来说，用户体验好就是要安全、稳定和可靠，这就是所谓的良好体验。</p><p>&nbsp;</p><p>李艳林（彦林）：这块我可以给大家一些建议。首先，未来云原生网关的发展趋势应该朝着标准化、高集成、易扩展和热更新的方向不断加强。我们推测，Ingress 和 Gateway API可能会成为API路由的标准，这个标准可能不会受个人主观意愿的影响。</p><p>&nbsp;</p><p>第二个趋势是，对于一些小中型客户来说，Higress 对于一些简单的4层路由和7层简单路由可能足够了，但对于一些中大型客户来说，他们可能对于复杂的API管理和路由有更多需求，未来可能会朝这个方向发展。我注意到在群里也有人提问，当API变得复杂并且规模扩大时，如何进行API管理和治理，我们可以在以后讨论这个问题。</p><p>&nbsp;</p><p>第三个趋势是统一东西南北流量。我们采用Envoy内核，可以看到东西南北流量的统一加速趋势。无论是从北向进来的流量，还是跨安全域、跨业务域、跨区域的东西向流量，包括sidecar之间的流量，因为采用Envoy内核，我们在统一东西南北流量方面具有一些优势。当然，我也看到一些尝试将NGINX用作sidecar内核的设计，包括APISIX也在进行这方面的尝试。我认为大家的思路都很好，核心本质是大家都认为统一东西南北流量控制是一个重要的方向。</p><p>&nbsp;</p><p>第四个趋势可能是关于AI领域的探索，AI的入口到底是谁？包括在阿里内部以及与其他合作伙伴进行的一些尝试。未来的AI能力和大模型能力都是基于容器作为基础设施进行输出的，对于连接的稳定性、高可用性以及流量防护也有较高的要求。所以，我相信在未来的AI探索领域中，探索AI的入口将是值得的。</p><p>&nbsp;</p><p>最后，根据CNCF的数据，我认为以NGINX、Envoy为内核可能是未来原生网关的关键实现。我也相信Higress在未来一年会有爆发性增长，加速推动原生网关的认知建立，这只是我大致的判断。</p>",
    "publish_time": "2023-05-29 09:35:10",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "大语言模型综合能力测评报告 2023",
    "url": "https://www.infoq.cn/article/vWO39J1tlb9xlSaIJoI6",
    "summary": "<h3>研究背景</h3>\n<p>2022 年年末以来，人工智能大模型成为技术领域乃至全球创新领域最炙手可热的话题。以 ChatGPT 引领的大模型产品发展日新月异，有预测数据显示，到 2030 年，AIGC 的市场规模或将超过万亿人民币。2023 年国内主要厂商也相继推出自研的大语言模型产品，另外国内也推出了大量的大语言模型应用，逐步构建起基于中文语言特色的大语言模型生态。<br />\n<img alt=\"\" src=\"https://static001.infoq.cn/resource/image/62/02/627bb129b9df54275169a17e75b9a002.png\" /></p>\n<p>InfoQ 研究中心本次针对大语言模型产品的研发要素、大语言模型产品的核心特征进行研究， 并选取语言模型准确性、数据基础、模型和算法的能力、安全和隐私四个大维度，拆分出语义理解、语法结构、知识问答、逻辑推理、代码能力、上下文理解、语境感知、多语言能力、多模态能力、数据基础、模型和算法的能力、安全和隐私 12 个细分维度，分别对ChatGPT、Claude、Sage、天工3.5、文心一言、通义千问、讯飞星火、Moss、ChatGLM、vicuna-13B进行了超过 3000+ 道题的评测。另外，本次研究特别关注了技术视角中大模型产品的编程能力，提高了问题的权重和比例；同时也专门设置了关于中文语境的特色测试题目， 如方言测试、中文特色推理、对对联等题目。InfoQ 研究中心希望可以通过本次测评帮助更多技术领域同仁获得对于中外大模型产品能力的逻辑认知，以帮助大家在 AGI 创业方向选择、工作实际应用等方面获得最新认知。</p>\n<h3>研究结论</h3>\n<p><img alt=\"\" src=\"https://static001.infoq.cn/resource/image/e9/48/e991efc8c59437a674eyye48f1a78948.png\" /></p>\n<h3>目录</h3>\n<ul>\n<li>大语言模型发展背景</li>\n<li>大语言模型产品核心能力解读</li>\n<li>大语言模型产品测评结果和特征</li>\n<li>大语言模型产品未来发展展望</li>\n</ul>\n<p>未来， InfoQ 研究中心还将继续持续关注大模型领域的持续发展，也欢迎各位行业内的专家就本报告的内容进行交流和讨论。下半年， InfoQ 研究中心还将推出关于大模型应用的研究报告， 欢迎正在该领域耕耘的厂商报名参与案例的制作和报告的研发工作。</p>",
    "publish_time": "2023-05-29 10:41:47",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "通过TCP/IP每分钟发送数十亿条消息",
    "url": "https://www.infoq.cn/article/R7eVHqJKuHGdxYVEXE9Z",
    "summary": "<p>这个问题最常见的解决方案是定义一种可以被不同进程（甚至不同编程语言）理解的“规范”数据表示，并在发送数据之前将其转换为这种格式，然后在接收到数据后再转换为接收方自己的格式。现在已经有几种这样的“有线格式”，从基于文本的标准，如YAML、JSON或XML，到二进制格式，如<a href=\"https://www.infoq.com/protocolbuffers/\">Protobuf</a>\"。</p><p></p><p>在<a href=\"https://chronicle.software/\">Chronicle公司</a>\"，我们开发了许多库来支持基于低延迟消息传递的应用程序，主要用于金融服务行业。我们为来自世界各地的客户提供定制的解决方案开发和咨询服务，其中大多数客户来自金融领域。</p><p></p><p>其中一个库是<a href=\"https://chronicle.software/wire/\">Chronicle Wire</a>\"，它为Java对象的内部JVM表示和持久化状态（或与其他Java进程通信的格式）之间提供了高性能转换。</p><p></p><p>Chronicle Wire源于<a href=\"https://chronicle.software/queue/\">Chronicle Queue</a>\"项目。在每秒数百万条消息的规模下，Chronicle Queue可以为同一机器不同JVM之间的消息传递提供个位数的微秒级延迟，或者为不同的机器之间提供数十微秒的稳定延迟。Wire现在成为Chronicle开发的大多数软件组件的关键组成部分，从用于组件之间对象状态的序列化和反序列化，到用于管理这些组件配置的高效模型。</p><p></p><p>随着软件架构越来越多地转向分布式、基于事件驱动，我们希望扩展Chronicle Wire的使用场景，支持组件之间的TCP/IP互连。本文将对此特性进行基本的概述，并提供一些如何使用这些特性的简单示例。</p><p></p><p>我们已经看到了一些令人吃惊的性能数据——例如，Peter Lawrey的文章“<a href=\"https://chronicle.software/java-is-very-fast/\">如果不创建很多对象，Java其实非常快</a>\"”提供的一个基准测试显示，在一台机器上构建的环回TCP/IP网络每分钟能够传递超过40亿个事件。</p><p></p><p>我们将其与其他类似的数据交换技术（特别是Jackson和BSON）进行了基准测试比较。在处理100字节消息的测试中，使用Chronicle Wire，每条消息的99.99可用性处理时间约为10.5微秒，而使用Jackson/BSON则为1400微秒，这是一个显著的差异。</p><p></p><p>我们将在本文中介绍一些相关的关键概念。我们正在将这些特性设计得既灵活又高效，以后的文章将会展示一些更高级的用例。</p><p></p><h2>什么是Chronicle Wire</h2><p></p><p>Chronicle Wire作为应用程序和字节流之间的一个层，充当数据的源或接收器。Wire序列化Java对象的状态并将其放到字节流中，或者从字节流中读取字节序列并基于消息中携带的信息将其反序列化成Java对象。</p><p></p><p>我们来看一个简单的例子。我们将模拟Java对象的持久化，将对象的状态序列化到Wire，然后再读取成对象。我们将使用一个叫作Person的类。</p><p></p><p><code lang=\"java\">public class Person extends SelfDescribingMarshallable {\n   private String name;\n   @NanoTime\n   private long timestampNS;\n   @Base85\n   private long userName;\n\n   …\n}\n</code></p><p></p><p>这个类的完整代码可以在Chronicle Wire的<a href=\"https://github.com/OpenHFT/Chronicle-Wire/blob/ea/src/test/java/net/openhft/chronicle/wire/examples/Person.java\">Github代码库</a>\"中找到。</p><p></p><p>父类型SelfDescribingMarshallable包含与Wire交互所必需的功能——它大致相当于Java序列化所使用的java.io.Serializable接口，不过它更强大并且不存在安全缺陷。SelfDescribingMarshallable对象不需要额外的东西来支持编组和解组——比如XML的模式或Protobuf（或SBE）的代码生成器。此外，这个接口还提供了Java数据对象方法equals()、hashcode()和toString()的实现。</p><p></p><p>Chronicle Wire使用@NanoTime注解将属性值编码为时间戳，使用@Base85注解编码短字符串来节省空间。这两个注解还提供了从紧凑的内部表示到友好的字符串表示的转换。</p><p></p><p>我们来创建一个Chronicle Wire实例，它将使用Java堆中的一个内存区域将对象编组成YAML并解组。</p><p></p><p><code lang=\"java\">Wire yWire = Wire.newYamlWireOnHeap();\n</code></p><p></p><p>创建和初始化Person实例：</p><p></p><p><code lang=\"java\">Person p1 = new Person()\n       .name(\"George Ball\")\n       .timestampNS(CLOCK.currentTimeNanos())\n       .userName(Base85.INSTANCE.parse(\"georgeb\"));\nSystem.out.println(\"p1: \" + p1);\n</code></p><p></p><p>我们使用了重载方法和链式方法而不是get…()和set…()方法来访问和修改对象属性。代码打印出了Person对象的初始化状态，调用了父类SelfDescribingMarshallable的toString()方法：</p><p></p><p><code lang=\"java\">p1: !Person {\n  name: George Ball,\n  timestampNS: 2022-11-11T10:11:26.1922124,\n  userName: georgeb\n}\n</code></p><p></p><p>现在我们将对象序列化到Wire。因为创建的Wire使用了YAML，所以可以很容易显示其中的内容：</p><p></p><p><code lang=\"java\">Wire yWire = Wire.newYamlWireOnHeap();\np1.writeMarshallable(yWire);\nSystem.out.println(yWire);\n</code></p><p></p><p>我们可以看到被序列化的属性：</p><p></p><p><code lang=\"java\">name: George Ball\ntimestampNS: 2022-11-11T10:11:54.7071341\nuserName: georgeb\n</code></p><p></p><p>现在我们可以创建一个空的Person实例，然后用从Wire中回读的属性值来填充它，并将其打印出来：</p><p></p><p><code lang=\"java\">Person p2 = new Person();\np2.readMarshallable(yWire);\nSystem.out.println(\"p2: \" + p2);\n</code></p><p></p><p>从输出可以看到，新创建的对象的状态是对的：</p><p></p><p><code lang=\"java\">p2: !Person {\n  name: George Ball,\n  timestampNS: 2022-11-11T10:13:29.388,\n  userName: georgeb\n}\n</code></p><p></p><p>完整的代码可以在Chronicle Wire的<a href=\"https://github.com/OpenHFT/Chronicle-Wire/blob/ea/src/test/java/net/openhft/chronicle/wire/examples/Person.java\">Github代码库</a>\"中找到。</p><p></p><h2>MethodWriter和MethodReader</h2><p></p><p>通常，使用Wire序列化和反序列化的对象都是与我们的应用程序相关的某种类型的数据。如果使用Chronicle Queue作为消息传输，那么这些对象将构成消息的有效负荷，我们把它们叫作数据传输对象（Data Transfer Object，DTO）。</p><p></p><p>我们也可以从不同的角度来看待这个功能。序列化的Person对象包含了YAML格式的属性：</p><p></p><p><code lang=\"java\">name: George Ball\ntimestampNS: 2022-11-11T10:11:54.7071341\nuserName: georgeb\n</code></p><p></p><p>如果再进一步，我们可以使用Wire编码和发送请求来调用带有参数的方法。由于消息传输的单向性，这些方法必须是viod的，即不能返回值。我们假设有一个可以操作Person对象的接口，暂时还没有提供方法的实现：</p><p></p><p><code lang=\"java\">public interface PersonOps {\n   void addPerson(Person p);\n}\n</code></p><p></p><p>为简单起见，这里只指定了一个方法。它只接受一个Person类型的参数，并将其添加到集合中。根据前面的示例，我们或许会将这个类的实例编码为：</p><p></p><p><code lang=\"java\">addPerson: {\n  name: George Ball,\n  timestampNS: 2022-11-11T10:11:54.7071341,\n  userName: georgeb\n}\n</code></p><p></p><p>然后解码为方法调用的形式：</p><p></p><p><code lang=\"java\">personOps.addPerson(\n       Marshallable.fromString(Person.class, \"\" +\n               \"name: Alice Smithl\\n\" +\n               \"timestampNS: 2022-11-11T10:11:54.7071341\\n\" +\n               \"userName: alices\\n\"));\n</code></p><p></p><p>Chronicle Wire提供了这种对方法调用进行编码和解码的能力。发送方使用MethodWriter类，接收方使用MethodReader类。</p><p></p><p>例如，对于上面显示的PersonOps类，我们可以创建一个MethodWriter：</p><p></p><p><code lang=\"java\">final PersonOps personOps = yWire.methodWriter(PersonOps.class);\n</code></p><p></p><p>methodWriter将返回一个包含addPerson()存根实现的接口实例，用于将调用请求编码到Wire。我们可以这样调用这个方法：</p><p></p><p><code lang=\"java\">personOps.addPerson(p1);\n\npersonOps.addPerson(new Person()\n       .name(\"Bob Singh\")\n       .timestampNS(CLOCK.currentTimeNanos())\n       .userName(Base85.INSTANCE.parse(\"bobs\")));\n</code></p><p></p><p>如果我们看一下Wire，将会看到调用请求被编码成消息：</p><p></p><p><code lang=\"java\">addPerson: {\n  name: Alice Smith,\n  timestampNS: 2022-11-11T10:11:54.7071341,\n  userName: alices\n}\n...\naddPerson: {\n  name: George Ball,\n  timestampNS: 2022-11-11T10:28:47.466,\n  userName: georgeb\n}\n...\naddPerson: {\n  name: Bob Singh,\n  timestampNS: 2022-11-11T10:28:48.3001121,\n  userName: bobs\n}\n...\n</code></p><p></p><p>在接收端，我们可以创建一个MethodReader对象，它将提供在解码时被调用的方法的实现：</p><p></p><p><code lang=\"java\">MethodReader reader = yWire.methodReader(\n       (PersonOps) p -&gt; System.out.println(\"added \" + p));\n</code></p><p></p><p>当消息被读取和解码时，这个方法将被调用：</p><p></p><p><code lang=\"java\">for (int i = 0; i &lt; 3; i++)\n   reader.readOne();\n</code></p><p></p><p>当方法被调用时，我们将看到System.out.println()的输出：</p><p></p><p><code lang=\"java\">added !Person {\n  name: Alice Smith,\n  timestampNS: 2022-11-11T10:11:54.7071341,\n  userName: alices\n}\n\nadded !Person {\n  name: George Ball,\n  timestampNS: 2022-11-11T10:28:47.466,\n  userName: georgeb\n}\n\nadded !Person {\n  name: Bob Jones,\n  timestampNS: 2022-11-11T10:28:48.3001121,\n  userName: bobj\n}\n</code></p><p></p><p>这看起来非常强大，因为它为我们提供了一种高度灵活和高效的方式来编码事件或消息，并将它们与处理程序关联起来。Wire编码的灵活性都是可用的——文本格式或二进制格式——正如Wire许多不同类型的底层传输一样。</p><p></p><p>接下来，我们来了解一下基于TCP/IP网络通信的Wire传输将带来怎样的可能性。</p><p></p><h2>概念简介</h2><p></p><p>新的功能基于以下三个抽象概念。</p><p></p><h3>Channel</h3><p></p><p>Chronicle Channel是对两个组件之间的双向点对点连接的抽象。在创建Channel时指定的通道类型定义了底层传输的类型。初始实现使用异步套接字或连接同一进程内两个端点的内部通道来支持TCP/IP，主要目标是支持更高级的传输，如GRPC、REST或WebSocket等。</p><p></p><p>Channel在两个组件之间来回传输被打包成Chronicle Wire消息的Event。初始实现支持TCP/IP或“本地”（进程内）通道，但也可以为不同的传输定义Chennel类型。</p><p></p><h3>Context</h3><p></p><p>Context是Channel的管理容器，负责管理Channel的配置和生命周期。</p><p></p><h3>Handler</h3><p></p><p>Handler是与Channel绑定在一起的组件，它定义了如何处理传入的事件，以及如何传输传出（结果）事件。这样可以实现各种形式的会话管理。框架提供了许多预定义的Handler，也支持自定义。</p><p></p><p>在建立连接时，一个Handler会与Channel相关联，通常由连接的“发起者”（即客户端）指定。</p><p></p><h2>使用Channel</h2><p></p><p>我们来看一些实际的示例。</p><p></p><h3>示例1：Hello, World</h3><p></p><p>一般来说，第一个示例是简单地打印“Hello”消息。代码注释中的编号表示关键点，并与下面的列表对应：</p><p></p><p><code lang=\"java\">public class Channel1ReadWrite {\n\n   private static final String URL = System.getProperty(\"url\", \"tcp://:3334\");                                        // ===&gt; (1)\n\n   public static void main(String[] args) {\n\n       try (ChronicleContext context = ChronicleContext.newContext(URL).name(\"Channel1\");                // ===&gt; (2)\n           ChronicleChannel channel = context.newChannelSupplier(new EchoHandler()).get()) {\n\n           Jvm.startup().on(Channel1.class, \"Channel set up on port: \" + channel.channelCfg().port());\n\n           Says says = channel.methodWriter(Says.class);                                                                      // ===&gt; (3)\n           says.say(\"Well hello there\");\n\n           StringBuilder eventType = new StringBuilder();                                                                       // ===&gt; (4)\n           String text = channel.readOne(eventType, String.class);\n           Jvm.startup().on(Channel1.class, \"&gt;&gt;&gt;&gt; \" + eventType + \": \" + text);\n\n       }\n   }\n}\n</code></p><p></p><p>创建Channel的关键参数是一个URL字符串。目前只支持TCP/IP作为传输机制，但未来会支持更多的传输机制。这个字符串在Chronicle Channel中的含义如下表所示。</p><p></p><p></p><p></p><p>我们使用try-with-resources来确保所有创建的组件在使用完以后都会被关闭。首先，我们创建Context，用于管理Channel的生命周期和配置。Context提供了一个工厂方法，可以用来创建新的Channel。在请求新的Channel时，我们指定使用哪个Handler来处理传入的事件。在本例中，我们使用EchoHandler，顾名思义，它会将事件发送回发送方。</p><p></p><p>为连接设置服务器端套接字所需的工作都由工厂方法完成，它返回的Channel可以被我们使用。</p><p></p><p>TCP/IP是全双工协议，所以我们获得的Channel是双向的。我们可以通过Channel发送事件，使用下面的类生成的MethodWriter：</p><p></p><p><code lang=\"java\">public interface Says extends Syncable {\n   void say(String say);\n}\n\n…\n\nSays says = channel.methodWriter(Says.class);\nsays.say(\"Well hello there\");\n…\n</code></p><p></p><p>然后，我们可以使用Chronicle Wire从通道读取回传的事件并将其显示出来。当运行这个简单的示例时，我们可以看到这样的输出：</p><p></p><p><code lang=\"java\">[main] INFO run.chronicle.wire.channel.demo1.Channel1 - Channel set up on port: 3334\n[main] INFO run.chronicle.wire.channel.demo1.Channel1 - &gt;&gt;&gt;&gt; say: Well hello there\n</code></p><p></p><h3>示例2：客户端和服务器端分离</h3><p></p><p>第一个示例太过简单，因为它将客户端和服务器端的功能都放在同一个进程里。这对于测试或调试来说可能比较方便，但现在我们希望将它们分离到各自的进程中。我们来看看分离之后的服务器：</p><p></p><p><code lang=\"java\">public class ChannelService {\n   static final int PORT = Integer.getInteger(\"port\", 4441);\n\n   public static void main(String[] args) throws IOException {\n       System.setProperty(\"port\", \"\" + PORT); // set if not set.\n       ChronicleGatewayMain.main(args);\n   }\n}\n</code></p><p></p><p>由于我们使用了辅助类ChronicleGatewayMain，代码变得非常简短。辅助类封装了设置服务器端（Channel接收器）、移除模板代码和尽可能多地使用默认设置的功能。</p><p></p><p>客户端的代码如下所示，注释中的编号表示关键点：</p><p></p><p><code lang=\"java\">public class ChannelClient {\n\n   private static final String URL = System.getProperty(\"url\", \"tcp://localhost:\" + ChannelService.PORT);        // ===&gt; (1)\n\n   public static void main(String[] args) {\n\n       try (ChronicleContext context = ChronicleContext.newContext(URL).name(\"ChannelClient\");                  // ===&gt; (2)\n            ChronicleChannel channel = context.newChannelSupplier(new EchoHandler()).get()) {\n\n           Jvm.startup().on(ChannelClient.class, \"Channel set up on port: \" + channel.channelCfg().port());\n           Says says = channel.methodWriter(Says.class);                                                                             // ===&gt; (3)\n           says.say(\"Well hello there\");\n\n           StringBuilder eventType = new StringBuilder();\n           String text = channel.readOne(eventType, String.class);\n\n           Jvm.startup().on(ChannelClient.class, \"&gt;&gt;&gt;&gt; \" + eventType + \": \" + text);\n       }\n   }\n}\n</code></p><p></p><p>URL字符串包含了主机名和端口号，它告诉创建通道的逻辑我们正在初始化客户端通道。根据URL字符串格式创建客户端Context。在从客户端Context创建通道时，我们指定了在接收端使用哪个Handler。通道建立起来之后，剩下的代码与第一个示例中的代码一样。当客户端和服务器端应用程序同时运行起来时，输出如下所示：</p><p></p><p><code lang=\"java\">[main] INFO run.chronicle.wire.channel.demo2.ChannelClient - Channel set up on port: 4441\n[main] INFO run.chronicle.wire.channel.demo2.ChannelClient - &gt;&gt;&gt;&gt; say: Well hello there\n</code></p><p></p><h3>示例3：简单的请求/响应交互</h3><p></p><p>前面我们已经了解如何使用Wire的MethodReader和MethodWriter来实现请求进程外方法调用。现在，我们可以扩展这个示例，演示使用基于TCP/IP通道的Wire来实现类似于远程过程调用的服务请求/响应处理能力。</p><p></p><p>服务本身很简单，只提供了一个方法——我们的目的是演示构造服务和访问服务所需的步骤。</p><p></p><p>这个例子涉及四个部分：</p><p></p><p>Service——根据输入和输出的消息类型实现业务逻辑。Channel Handler——将服务连接到底层的Channel。Service Driver——作为服务器端的入口点，创建和配置服务和Channel Handler。Client——一个单独的应用程序，创建和发送请求，并接收响应。</p><p></p><h4>Service</h4><p></p><p>服务提供了一个可以处理受支持请求的接口，其定义为：</p><p></p><p><code lang=\"java\">public interface PersonOps {\n   void addPerson ( Person p );\n}\n</code></p><p></p><p>Person类与之前定义的一样。</p><p></p><p>Chronicle中的消息传递是单向的，所以服务API的方法是void的。因此，我们需要为响应消息定义第二个接口：</p><p></p><p><code lang=\"java\">public interface ResponseSender {\n   void respond(ReqStatus status);\n}\n</code></p><p></p><p>ReqStatus类表示方法是否执行成功，其定义为：</p><p></p><p><code lang=\"java\">public enum ReqStatus {\n   OK,\n   ERROR\n}\n</code></p><p></p><p>这两个接口连接在一起形成了一个处理传入请求的Handler：</p><p></p><p><code lang=\"java\">public class PersonOpsProcessor implements PersonOpsHandler {\n   private transient ResponseSender responder;                                                  // ===&gt; (1)\n   public PersonOpsProcessor responder(ResponseSender responseSender) {        // ===&gt; (2)\n       this.responder = responseSender;\n       return this;\n   }\n   @Override\n   public void addPerson(Person p) {                                                                  // ===&gt; (3)\n       responder.respond(ReqStatus.OK);\n   }\n}\n</code></p><p></p><p>这个字段将保存对该服务的输出的引用。在本例中，ResponseSender是通过setter方法注入的，当然也可以通过构造函数注入。实现了PersonOps接口中的方法，为简单起见，它只发送一个成功的状态响应。</p><p></p><h4>Channel Handler</h4><p></p><p>根据之前的概念简介，Channel Handler的职责是处理在其关联通道上传递的消息/事件。</p><p></p><p>对于本例，我们需要定义一个类，它将通道上的传入消息分派给服务的Handler，并将服务输出连接到通道：</p><p></p><p><code lang=\"java\">public class PersonSvcHandler extends AbstractHandler {                  // ===&gt; (1)\n   private final PersonOpsHandler personOpsHandler;                                                       // ===&gt; (2)\n   public PersonSvcHandler(PersonOpsHandler personOpsHandler) {                                  // ===&gt; (3)\n       this.personOpsHandler = personOpsHandler;\n   }\n   public void run(ChronicleContext context, ChronicleChannel channel) {                           // ===&gt; (4)\n       channel.eventHandlerAsRunnable(\n           personOpsHandler.responder(channel.methodWriter(ResponseSender.class))\n       ).run();\n   }\n   @Override\n   public ChronicleChannel asInternalChannel(ChronicleContext context,                             // ===&gt; (5)\n                                                                          ChronicleChannelCfg channelCfg) {\n       throw new UnsupportedOperationException(\"Internal Channel not supported\");\n   }\n}\n</code></p><p></p><p>基类实现了通用的平台功能，子类将为我们的服务提供定制的逻辑。对Handler实现类的引用。PersonOpsHandler是通过构造函数注入的。当发起一个新的通道连接时，就会启动一个Handler，并初始化必要的MethodReader和MethodWriter对象。这些逻辑被封装在run()方法中，每个发起的通道连接都会执行这一步。在这个示例类中，我们显式禁止创建在内部通道运行的Handler。</p><p></p><h4>Service Driver</h4><p></p><p>完成了这些步骤后，编写服务的驱动类就简单了，与之前的例子或多或少相同，就是使用ChronicleGatewayMain类来创建配置通道。</p><p></p><p><code lang=\"java\">public class PersonSvcMain {\n   static final int PORT = Integer.getInteger(\"port\", 7771);\n   public static void main(String... args) throws IOException {\n       System.setProperty(\"port\", \"\" + PORT);\n       ChronicleGatewayMain.main(args);\n   }\n}\n</code></p><p></p><h4>Client</h4><p></p><p>要实现一个简单的Person服务客户端，我们可以创建一个通道，然后向服务发出请求。</p><p></p><p><code lang=\"java\">public class PersonClient {\n   private static final String URL = System.getProperty(\"url\", \"tcp://localhost:\" + PersonSvcMain.PORT);                           // ===&gt; (1)\n   public static void main(String[] args) {\n       try (ChronicleContext context = ChronicleContext.newContext(URL)) {\n           ChronicleChannel channel = context.newChannelSupplier(new PersonSvcHandler(new PersonOpsProcessor()))      // ===&gt; (2)\n                                                               .get();\n           final PersonOps personOps = channel.methodWriter(PersonOps.class);                                                               // ===&gt; (3)\n           Person thePerson = new Person()\n                                                   .name(\"George\")\n                                                   .timestampNS(SystemTimeProvider.CLOCK.currentTimeNanos())\n                                                   .userName(Base85.INSTANCE.parse(\"georgeb\")));\n;\n           personOps.addPerson(thePerson);\n           StringBuilder evtType = new StringBuilder();\n           ReqStatus response = channel.readOne(evtType, ReqStatus.class);\n           Jvm.startup().on(PersonClient.class, \" &gt;&gt;&gt; \" + evtType + \": \" + response);\n       }\n   }\n}\n</code></p><p></p><p>默认情况下，URL的端口号与服务器中配置的端口号一样。创建Channel，注入自定义Handler实例。在创建好以后，我们就可以使用Channel的MethodWriter方法来生成存根方法，这些方法将向服务发送序列化的事件。</p><p></p><h2>总结</h2><p></p><p>Chronicle Wire增加了一些新功能，允许通过TCP/IP与其他组件通信。本文介绍了Wire实现这些功能的基本思想，并提供了一些简单的示例。</p><p></p><p>这种快速高效的通信在分布式服务架构中还有很多应用场景。除了本文的示例之外，Chronicle Wire的<a href=\"https://github.com/OpenHFT/Chronicle-Wire\">GitHub项目库</a>\"中还提供了其他示例。</p><p></p><h1>作者简介</h1><p></p><p>George Ball目前在Chronicle公司的技术文档组工作，致力于构建Chronicle低延迟Java库和框架文档。在此之前，他是摩根士丹利Java平台工程团队的一员，在公司的Java基础设施向云端迁移过程中增强Java库，并改善开发者体验。他在分布式系统方面有超过35年的经验，特别是在JVM生态系统方面。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/billions-messages-minute/\">https://www.infoq.com/articles/billions-messages-minute/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/hGEXgDo8C2wPTok21NUf\">TCP协议已不适用现今的数据中心</a>\"</p><p><a href=\"https://www.infoq.cn/article/0v4hIYUxAH6QQXB8LkBh\">性能提升 57% ，SMC-R 透明加速 TCP 实战解析</a>\"</p><p></p><p></p>",
    "publish_time": "2023-05-29 11:08:02",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "官宣！华为开发者大会2023 ( Cloud ) 将于7月7日正式揭幕",
    "url": "https://www.infoq.cn/article/8QUMWY0Bmmjw9LET42WD",
    "summary": "<p>今天，华为开发者大会 2023（HDC.Cloud 2023&nbsp;)正式官宣：大会将于 7 月 7 日在东莞拉开帷幕，同时在全球 10 余个国家、中国 30 多个城市设有分会场，邀请全球开发者共同探讨AI浪潮之下的新机会和新可能。大会将重点呈现华为云在“AI for Industries”方面的最新进展。</p><p></p><p>作为一场面向全球开发者的年度盛会，HDC.Cloud 致力于为全球开发者打造一个思想碰撞、技术交流、实操竞技的技术殿堂，让开发者全面了解并掌握最新的技术动态，为未来的技术创新开拓更广阔的空间。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/70/55/701f3d316d4ecfc84bfc6cf84441d655.png\" /></p><p></p><p>本届大会以“每一个开发者都了不起”为主题，将带来以下丰富议程和内容：</p><p></p><p>200+ 场开发者活动：大会设置了主题演讲、高峰论坛、专题论坛、开放演讲、圆桌讨论、“扫地僧”见面会、CodeLabs 训练营&amp;极客挑战赛、嘉年华等 200+ 场开发者活动，为开发者打造收获知识、思想碰撞、实操竞技的一站式深度体验<a href=\"https://xie.infoq.cn/article/a9ded0fa8550bcda30f3ff36c\">之旅</a>\"。最前沿的技术和最佳行业实践分享：数百位来自<a href=\"https://xie.infoq.cn/article/4949bc570c9157723894fb1ce\">华为</a>\"云、客户、合作伙伴的顶级专家，将围绕 AI、大数据、数据库、PaaS、aPaaS、媒体服务、云原生、安全、物联网、区块链、开源等各个领域的技术热点、最佳实践以及发展趋势等进行深入解读和分享。与“扫地僧”的近距离交流机会：大会期间将举办多场华为“扫地僧”见面会、技术圆桌等活动。开发者可以和身怀绝技的华为神秘“扫地僧”、行业大师进行面对面的思想交流和碰撞，近距离感受技术文化。丰富的动手实践和竞技比拼：大会现场还将设置丰富的&nbsp;Codelabs 训练营、极客挑战赛以及<a href=\"https://xie.infoq.cn/article/1c5088eb930fc3efbcbeb37fb\">云开发者</a>\"大赛等竞技活动，让开发者可以动手实践，充分参与，一展身手。</p><p></p><h2>会议日程</h2><p></p><p>2023.7.7&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 主题演讲</p><p>2023.7.8-9&nbsp;&nbsp;&nbsp; 高峰论坛/技术论坛/生态论坛/CodeLabs训练营/极客挑战赛/扫地僧见面会/互动展区/开发者嘉年华</p><p></p><p>主会场：东莞篮球中心（主题演讲）+ 华为溪流背坡村</p><p>国内分会场：深圳、北京、贵安、成都、杭州、大连、厦门、南京、杭州、济南、青岛等全国 30 多个城市</p><p>海外分会场：西班牙、土耳其、新加坡、泰国、沙特、墨西哥、南非、埃及等全球四大洲 10 多个国家</p><p>&nbsp;</p><p>官网链接：<a href=\"https://developer.huaweicloud.com/HDC.Cloud2023.html\">https://developer.huaweicloud.com/HDC.Cloud2023.html</a>\"&nbsp;</p>",
    "publish_time": "2023-05-29 13:17:45",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "神州云科：超高可用架构，应用可持续性的保证",
    "url": "https://www.infoq.cn/article/TVVL1R6W3skfWVPBmK3C",
    "summary": "<p>5 月 25 日，F5 Forum 科技趋势线上峰会成功举行。本次峰会聚焦科技的发展与变革，通过对数以千计的各行各业用户调研的分析，深入剖析数字化时代的机会与挑战，共话技术发展趋势、战略与解决方案。神州云科副总裁、通明湖云和信创研究院副院长吴静涛发表主旨演讲，他表示，“应用可持续性是数字化时代的关键技术，企业业务可持续的发展需要统一的架构、统一的管理和服务。”</p><p></p><h2>应用可持续性保证的关键要素</h2><p></p><p></p><p>应用可持续性是数字化时代的关键技术。在 Gartner 发布的《2023 年十大战略性技术趋势》中指出，可持续技术的投资也有可能创造更大的运营弹性和财务业绩，同时提供新的业务增长途径；同时，IDC 也指出，52% 的企业把实现业务可持续性做为接下来的工作重点。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/6e/0e/6e583e332872468eea825733f548190e.png\" /></p><p></p><p>吴静涛强调，“在数字化转型的过程中，企业从传统IT架构向云原生架构过渡，在企业内部形成了云原生、信创和传统IT架构等多元并举的态势。企业实现应用可持续性发展，需要站在架构的战略高度，通过统一的配置界面、统一的管理平台、统一的大数据采集分析，以及统一的服务平台等关键要素，来保证企业技术迭代创新过程中的应用可持续性和技术选型灵活性，尤其是实现核心信创的可靠过渡。”</p><p></p><p></p><h2>核心信创如何实现可靠、快速、灵活的过渡</h2><p></p><p></p><p>信创已然成为不可逆的趋势，如何可靠、快速、灵活的实现核心业务向信创环境的过渡，并且在兼容新老技术和架构的同时保证应用可持续性，成为了各个行业在数字化转型进程中无法避开的命题。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/c1/3b/c1401cda85bb526899e9f3895b515b3b.png\" /></p><p></p><p>为帮助客户更好地应对数字经济时代对应用可持续性的高要求，实现“信创”与“数字化”齐头并进，神州云科联合 f5 推出了双轨超高可用架构。吴静涛指出，“f5 引领了负载均衡，应用交付市场的发展，特别是双活数据中心更是稳定运行多年的事实标准，神州云科和 f5 希望通过双轨超高可用架构，助力企业平滑过渡核心信创。”</p><p></p><p>双轨超高可用架构在双活数据中心的分区调度基础上，增加信创域和非信创域的分域调度，实行信创域与传统域应用全量部署，使双中心运营变为双中心四区域并行运行，互为多活，将传统架构变为分区分域协同的多活双轨超高可用架构。帮助客户在新架构下，保障“信创”的同时解决性能瓶颈，提升稳定性，保证应用可持续性，最终实现信创区域和非信创区域的平滑过渡，完成国产化替代目标。</p><p></p><p></p><h2>双轨超高可用架构是应用可持续性的保证</h2><p></p><p></p><p>为实现双轨超高可用架构信创区和非信创区的跨域协同，实现信创区域和非信创区域的平滑过渡，神州云科通过五大引擎实现多层次的应用可持续性。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/97/4c/97388d47e08d7ef6cc21775a9f7ca44c.png\" /></p><p></p><p>高可用调度引擎：助力信创业务验证，消除隐患；动态调整信创业务比例，风险可控；助力信创业务应急逃生；助力现代应用敏捷联动。安全服务编排引擎：助力实现信创安全架构创新，提高攻防对抗能力。自主创新高可用引擎：继承业界领导者的应用交付功能，实现无缝配置迁移，联网协同，智能调度。现代应用高可用引擎：确保用户使用纯正可信开源软件，满足现代应用的高可靠、敏捷发布，快速迭代的需求。大数据引擎：提供无探针的采集能力，助力业务可观测性。</p><p>&nbsp;</p><p>同时，为了更好的适配双轨超高可用架构，神州云科推出了容翼系列和云科通明湖信创系列两大应用交付控制器产品。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/0a/cf/0ab8b4cfec4050918f0f7e9716164ccf.png\" /></p><p></p><p>神州云科应用交付控制器云科通明湖信创系列完全自主研发，拥有比肩世界一流产品的水准，凭借全国产、高性能、安全可控、高效能设计、扩展性设计等五大优势，可满足信创需求。</p><p>&nbsp;</p><p>神州云科应用交付控制器容翼系列采用全新设计的API 优先理念和容器底座，硬件架构采用技术先进的 FPGA 芯片和最新英特尔 CPU 处理器融合的全新架构，可以提供 200G 超强性能，满足企业对超高性能和超高安全的应用交付需求。</p><p>&nbsp;</p><p></p><h2>独特能力，引领应用可持续性高质量发展</h2><p></p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/39/92/3961f9698fe21c0a0eb78b82011a6092.png\" /></p><p></p><p>神州云科多年来深耕应用交付领域，致力于成为领先的国产数字化生态厂商。据 IDC《2022 年 Q4 应用交付市场跟踪报告》显示，<a href=\"https://www.infoq.cn/news/iola1LzWGoAzhplBtLx1\">神州云科</a>\"应用交付控制器产品营收增长率 130%，排名第一，成为国内增长最快的应用交付厂商。更是通过独特的技术能力和前瞻性，引领应用可持续性</p><p>云原生、金融信创和应用可持续性人才建设等方面的高质量发展。</p><p>&nbsp;</p><p>在应用可持续性架构方面，神州云科联合艾瑞咨询发布了《数字时代应用可持续性架构和验证白皮书》中，详细对应用可持续性架构的设计思想、特征以及验证指标体系进行了详细说明。通过应用交付领域的方法、工具、平台等体系建设方面的重要实践指引，促进应用交付领域标准持续迭代；在云原生方面，联合中国信通院共同发布《云原生应用引擎技术发展白皮书》，全景描绘了云原生技术图谱。该白皮书从云原生应用引擎的定义、产品形态、行业应用场景及未来趋势等多个维度，深度剖析了我国云原生应用引擎技术发展的现状和未来，以及解读如何通过应用引擎实现云原生“根”技术上的突破，并驱动云原生产业生态的建设。</p><p>&nbsp;</p><p>在金融信创方面，<a href=\"https://www.infoq.cn/article/QIPUJkmYmbLBlfRf9APJ\">神州云科</a>\"自主研发的云科负载均衡管理系统成功通过了人民银行金融信创生态实验室适配验证，成为国内首家在应用交付测试中通过测试的供应商；在应用可持续性人才建设方面，与工信部人才交流中心开展可持续应用-应用交付课程培训项目合作，赋能用户的信息化能力提升。</p><p>&nbsp;</p><p>历经多年的发展与沉淀，<a href=\"https://xie.infoq.cn/article/3994bec023558ae589c5b09cc\">神州云科</a>\"通过丰富的产品矩阵，优质的服务体系，联合上下游合作伙伴构建数字化解决方案新生态。未来，神州云科将继续加大研发投入，持续打磨应用交付技术和产品，为企业数字化的高质量发展保驾护航！</p>",
    "publish_time": "2023-05-29 13:28:50",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]