[
  {
    "title": "Cloudflare的可持续解决方案：降低碳排放，提高网络安全可持续性",
    "url": "https://www.infoq.cn/article/S9udjBPBhgzPfWM01q94",
    "summary": "<p>咨询公司Analysys Mason的一项研究表明，将网络和安全工作负载转移到Cloudflare可以<a href=\"https://blog.cloudflare.com/switching-cloudflare-cut-your-network-carbon-emissions-sbti/\">显著减少网络碳排放</a>\"。报告称，Cloudflare的网络产品可以帮助企业降低碳排放，实现可持续发展的目标。</p><p>&nbsp;</p><p><a href=\"https://downloads.ctfassets.net/slt3lc6tev37/25p5KbWP3RwWan5FdVb5ym/d9b3f9a285fe3e7e4972fee797b22ac2/Analysys-Mason-for-Cloudflare-Carbon-Savings-of-ENF-Report-Sep-2023.pdf\">报告</a>\"比较了Cloudflare和企业自建（on-premise）设备服务的平均功耗，强调了将网络和安全功能转移到云端是如何提高网络和安全运维可持续性的。Cloudflare的总监<a href=\"https://www.linkedin.com/in/patrick-day-77119018/\">Patrick Day</a>\"和Cloudflare的项目经理<a href=\"https://www.linkedin.com/in/annika-garbers/\">Annika Garbers</a>\"这样写到：</p><p>&nbsp;</p><p></p><blockquote>研究指出，专用硬件在执行特定功能时，每瓦特电量的效率更高，换句话说，与设计能够承载多种不同工作负载的通用服务器相比，针对入侵检测进行了优化的设备在执行入侵检测功能时，每次请求所消耗的电力会更少（……）。只有当专用硬件设备的使用率持续接近其容量时，这些收益才是有价值的，而企业环境中的大多数设备并非如此。</blockquote><p></p><p>&nbsp;</p><p>用来进行对比的技术栈包括网络防火墙和WAF、DDoS防御、负载均衡、WAN优化和SD-WAN。根据Cloudflare委托进行的独立研究，向云迁移的主要收益是减少本地设备的闲置容量（只需能够优雅处理峰值流量）。此外，针对云工作负载进行优化的数据中心的电力使用效率（<a href=\"https://en.wikipedia.org/wiki/Power_usage_effectiveness\">power usage effectiveness，PUE</a>\"）和碳密度也得到了改善，从而带来了边际收益。</p><p>&nbsp;</p><p>虽然标题是“切换至Cloudflare可以使网络碳排放最高可减少96%”，但研究表明，总体的碳排放减少在78%至96%，这取决于网络和重要假设：其中包括企业不会在当前内部自建设备的生命周期自然结束之前迁移至云端，以及迁移不会使企业流量传输的距离和连接数发生重大变化。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9f/9f81a90b733189c9cd65f4da3baa12f4.png\" /></p><p></p><p></p><p>&nbsp;Cloudflare最近申请加入了“基于科学的目标倡议”（Science Based Targets initiative，<a href=\"https://sciencebasedtargets.org/\">SBTi</a>\"），这是一个针对私营组织气候行动的项目，使企业能够在设备、运维和供应链中设定基于科学的减排目标。SBTi是CDP、联合国全球契约（United Nations Global Compact）、世界资源研究所 (World Resources Institute，WRI) 和世界自然基金会 (WWF) 的合作项目。Day和Garbers补充到：</p><p>&nbsp;</p><p></p><blockquote>Cloudflare对SBTi减排目标的承诺建立在我们100%使用可再生能源、在2025年前抵消或消除与网络供电相关的历史碳排放以及植树造林努力的持续承诺之上。</blockquote><p></p><p>&nbsp;</p><p>Cloudflare并不是唯一一家提出向云服务迁移可以减少总体碳排放的提供商，<a href=\"https://www.infoq.com/sustainablecomputing/\">可持续发展</a>\"是整个行业的一个重要话题。在QCon伦敦会议上，亚马逊云科技负责可持续发展架构的前副总裁<a href=\"https://www.infoq.com/profile/Adrian-Cockcroft/\">Adrian Cockcroft</a>\"就云提供商的可持续发展承诺和挑战以及制定<a href=\"https://www.infoq.com/news/2023/03/carbon-footprint-standard/\">新的实时碳足迹标准的必要性</a>\"分享了他的观点。他的演讲现已在<a href=\"https://www.infoq.com/presentations/cloud-sustainability-green-energy\">InfoQ上发布</a>\"。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/10/cloudflare-carbon-emissions/\">Cloudflare Claims Migration to Their Services Can Reduce Network Carbon Emissions by 78-96%</a>\"</p>",
    "publish_time": "2023-11-13 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "向量数据库失宠了？OpenAI力捧检索增强生成（RAG）技术，对行业来说意味着什么？",
    "url": "https://www.infoq.cn/article/oyYuL6eNtxwRYxirbQ6o",
    "summary": "<p>在刚刚过去的首届OpenAI开发者大会上，OpenAI 不仅公布了新的 GPT-4 Turbo 模型，还推出了多项对现有功能的升级和融合，一系列新产品和新功能的发布让外界大呼过瘾。虽然其中重要内容很多，但一条具有革命性意义的消息让人很难不注意到：消除在某些用例中对纯向量数据库的需求。换言之，OpenAI将提供一款Retrieval检索工具，用户已无需创建或搜索向量。</p><p>&nbsp;</p><p>那么，到底什么是Retrieval检索工具？它和此前OpenAI使用的向量数据库有什么区别？</p><p></p><h2>检索增强生成（RAG）到底是什么？</h2><p></p><p>&nbsp;</p><p>大语言模型尽管具有所有语言能力，但缺乏掌握“现在”的能力。 在快节奏的世界里，“现在” 就是一切。</p><p>&nbsp;</p><p>基于大语言模型 (LLM) 构建的产品（例如 OpenAI 的 ChatGPT 和 Anthropic 的 Claude）非常出色，但也存在缺陷：</p><p>&nbsp;</p><p>它们的数据集是静态的——大语言模型在静态数据集上进行训练，该数据集仅在某个时间点是最新的。这意味着它们可能无法收集训练数据后发生的事件或发展的信息。缺乏特定领域的知识——大语言模型接受过通用任务的培训，这意味着它们不能访问某一家公司的私有数据或本地数据。它们只能根据接受过训练的知识生成响应，这可能会限制他们提供个性化或针对具体情况的响应的能力。幻觉“黑匣子”——很难理解大语言模型在得出结论时考虑了哪些数据来源。大语言模型有时会产生事实上不准确或毫无根据的信息，这种现象被称为“幻觉”。生产效率低下且成本高昂——很少有组织拥有财力和人力资源来生产和部署基础模型。</p><p></p><p>不幸的是，这些问题影响了基于大语言模型 (LLM) 构建的应用程序的准确性。而好在，这些问题都可以通过检索增强生成（RAG）来解决。</p><p>&nbsp;</p><p>据悉，检索增强生成（RAG）一词来自于Facebook AI部门自然语言处理研究员Lewis等人在2020年发表的<a href=\"https://arxiv.org/abs/2005.11401\">一篇论文中。</a>\"这个想法是使用预先训练的语言模型 (LM) 来生成文本，但使用单独的检索系统来查找相关文档来调节语言模型。</p><p>&nbsp;</p><p>也就是说，RAG提供了一种方法，在不修改底层模型本身的情况下，用目标信息优化大语言模型的输出；有针对性的信息可以比大语言模型更及时也更聚焦某一特定组织和行业。这意味着生成式人工智能系统可以为Prompt提供更适合上下文的答案，也可以根据最新的数据提供这些答案。简而言之，RAG帮助大语言模型（LLM）给出更好的答案。</p><p>&nbsp;</p><p>在此之前，如果想要开发基于大语言模型（LLM）的应用，首先需要保证该应用能够识别相关数据（即存放在防火墙之后、或虚拟私有云之内的数据），这就需要用到LangChain、Llamaindex以及纯向量数据库等一整套工具组合。相关架构如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/44/4412cbddebac90edc745229743bfcd1e.png\" /></p><p></p><p>使用LangChain与Llamaindex实现检索。</p><p>&nbsp;</p><p>这一次，OpenAI引入了名为Assistants的新概念，允许用户以低代码/无代码方式配置出类似的架构。这就消除了对纯向量数据库的需求，并将整个过程简化为两个步骤。此外，在Assistants助手创建完成之后，我们可以通过几行代码轻松加以访问。</p><p>&nbsp;</p><p>再有，用户现在可以通过API向OpenAI发送其他文件，而且所能接收的上下文最多可达128K&nbsp;token，相当于约300页的文本内容。在通过代码访问这些Assistants时，我们还可以向其提供最多128种工具的访问权限，包括调用外部API并接收返回的数据以供Assistants进行处理。</p><p>&nbsp;</p><p>下面来看基于Assistants的新架构：</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/5e/5e5c33b576a46b7ab2e0cf5071b83282.png\" /></p><p></p><p>OpenAI的Assistant助手与Retrieval检索工具。</p><p>&nbsp;</p><p>以下是OpenAI在官方公告中关于Retrieval检索工具的重要说明：“此工具主要是利用我们模型之外的知识以增强助手，例如专有领域数据、产品信息或用户提供的文档。也就是说，您不再需要计算和存储文档嵌入、也无需实现分场和搜索算法。Assistants API将根据我们在ChatGPT中构建知识检索的经验，对所用检索技术进行优化。”</p><p>&nbsp;</p><p>未来几天之内，众多开发人员将着手测试这项新功能，并思考新架构之下Llamindex与纯向量数据库将往何处去。但这里需要强调一点，尽管新架构消除了个人/独立/业余开发者使用/购买纯向量数据库以构建新应用程序的需求，但大规模企业仍然掌握着SQL、NoSQL、二进制、HDFS等各种格式的PB级数据。</p><p>&nbsp;</p><p>如果您是一家需要构建数据感知大模型应用的规模化企业，那么将仍然需要使用上下文数据库——即能够提供混合搜索（词汇与语义搜索）功能以存储和检索多种数据类型的数据库。但无论如何，看到OpenAI保持如此迅猛的发展速度仍然令人欣慰。</p><p>&nbsp;</p><p>下图所示，为OpenAI Retrieval检索工具目前所能支持的文件类型。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/2e/2e2e5a064a27788446ff78b6991c06d8.png\" /></p><p></p><h2>RAG技术的优越性及未来发展方向</h2><p></p><p>&nbsp;</p><p>说了这么多，到底RAG技术有哪些具体的优越性？归根结底，RAG技术可用于提高生成式AI系统对提示的响应质量，而不仅仅是大语言模型所能提供的那些。具体的优势包括：</p><p>&nbsp;</p><p>RAG可以访问可能比用于训练大语言模型的数据更新鲜的信息；RAG知识存储库中的数据可以不断更新，而不会产生重大成本；RAG的知识存储库可以包含比通用大语言模型中的数据更关联上下文的数据；可以确定RAG的向量数据库中的信息来源。由于数据源是已知的，因此可以更正或删除RAG中的错误信息。</p><p>&nbsp;</p><p>可以确定的是，如今，我们正处于RAG的早期阶段，目前该技术还仅被用于为查询提供及时、准确和上下文相关的响应。这些用例适用于聊天机器人、电子邮件、文本消息传递和其他会话应用程序。在未来，RAG技术可能的方向是帮助生成式人工智能根据上下文信息和用户提示采取适当的行动。</p><p>&nbsp;</p><p>RAG也许还能协助处理更复杂的问题。例如，生成式人工智能或许能够告诉员工公司的学费报销政策；RAG可以添加更多的上下文数据来告诉员工附近哪些学校有符合该政策的课程，并可能推荐适合员工工作和以前培训的课程——甚至可能帮助申请这些课程并发起报销请求。</p><p>&nbsp;</p><p></p><h2>纯向量数据库厂商何去何从？</h2><p></p><p>&nbsp;</p><p>尽管RAG技术有着种种优势，但一直以来OpenAI内部一直是向量数据库和RAG技术并行采用的状态。而在OpenAI发布了这份关于RAG技术的最新公告后，各家纯向量数据库厂商“坐不住了”。</p><p>&nbsp;</p><p>有创业者调侃，“OpenAI几乎把上半年的创业项目全都自己做了一遍，也彻底把创业者们打懵了。”</p><p>&nbsp;</p><p>此外，一些唱衰向量数据库的言论也此起彼伏：“去死吧向量数据库”，“还要什么向量数据库缓存呢”，“还要什么 LangChain 中间件呢”？</p><p>&nbsp;</p><p>在业内竞争已经十分激烈的环境下，OpenAI的一纸公告给整个向量数据库行业又增添了一丝焦虑。</p><p>&nbsp;</p><p>近日，Chroma的联合创始人Anton Troynikov在接受外媒采访时讨论了RAG技术以及在传统数据库厂商虎视眈眈下，纯粹的向量数据库初创公司该何去何从的问题。</p><p>&nbsp;</p><p>大模型爆火后，向量数据库成了一块人人都想进来分一杯羹的“香饽饽”。现有的数据库厂商也在竞相在传统数据库上增加向量存储功能，当被问及这是否会让Chroma和其他向量初创公司难以发展业务时，Anton表示，“这样的想法太过局限了”。</p><p>&nbsp;</p><p>Anton观察到，Chroma中存储的大部分数据以前从未存储在数据库中，这表明在一段时间内，至少在基础设施层将会出现大量此类数据，这类数据将为 Chroma 带来越来越多的价值。向量数据库可以让向量检索就变得像将文本转储到文本框中一样简单，这与人们目前使用聊天机器人的方式没有什么不同。这个领域即使有很多传统数据库厂商加入游戏，似乎也不影响Chroma 取得伟大的成果。</p><p>&nbsp;</p><p>而当谈及如今比较火的RAG技术时，Anton表示要保持检索增强生成（RAG）技术在大模型内部循环运行，而不仅仅依赖于外部API。</p><p>&nbsp;</p><p>对于这些唱衰的声音，一位IDswyx的用户为在X上发表言论称：“对于今年向向量数据库投资2.35亿美元的公司来说，他们要的不是基础模型实验室Sherlocking和增加上下文长度这些基础功能，因为现有SQL和NoSQL数据库很容易增加向量支持，从而大幅减少TAM。在90%的重度用例中，数据的基本处理功能是占主导地位的。纯粹的向量数据库厂商必须竭尽全力在功能、DX或性能方面进行创新和领先。”</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/4d/4dda389873e19e95e27d427780f771be.png\" /></p><p></p><p>参考链接：</p><p><a href=\"https://medium.com/madhukarkumar/what-does-openais-announcement-mean-for-retrieval-augmented-generation-rag-and-vector-only-54bfc34cba2c\">https://medium.com/madhukarkumar/what-does-openais-announcement-mean-for-retrieval-augmented-generation-rag-and-vector-only-54bfc34cba2c</a>\"</p><p><a href=\"https://cookbook.openai.com/examples/fine-tuned_qa/ft_retrieval_augmented_generation_qdrant\">https://cookbook.openai.com/examples/fine-tuned_qa/ft_retrieval_augmented_generation_qdrant</a>\"</p><p><a href=\"https://arxiv.org/abs/2005.11401\">https://arxiv.org/abs/2005.11401</a>\"</p><p><a href=\"https://medium.com/madhukarkumar/what-does-openais-announcement-mean-for-retrieval-augmented-generation-rag-and-vector-only-54bfc34cba2c\">trieval-augmented-generation-rag-and-vector-only-54bfc34cba2c</a>\"</p><p><a href=\"https://www.oracle.com/artificial-intelligence/generative-ai/retrieval-augmented-generation-rag/\">https://www.oracle.com/artificial-intelligence/generative-ai/retrieval-augmented-generation-rag/</a>\"</p>",
    "publish_time": "2023-11-13 10:27:46",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "中国工商银行软件开发中心 BizDevOps 平台建设产品负责人梁子能确认出席 FCon，分享中国工商银行 BizDevOps 平台建设实践",
    "url": "https://www.infoq.cn/article/XF30QWcDQqpELkmj5buN",
    "summary": "<p><a href=\"https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle\">FCon 全球金融科技大会</a>\"，将于 11 月在上海召开。中国工商银行软件开发中心 BizDevOps 平台建设产品负责人梁子能将发表题为《中国工商银行 BizDevOps 平台建设实践》主题分享，介绍如何通过建设企业级的端到端价值交付平台和电子看板体系，来解决业务和科技融合过程中的复杂管理场景以及大规模团队协作的问题。</p><p></p><p>梁子能，工银 e 企研的产品经理，负责研发管理领域的数字化转型工作。他在本次会议的演讲内容如下：</p><p></p><p>演讲：中国工商银行 BizDevOps 平台建设实践</p><p></p><p>如何通过建设企业级的端到端价值交付平台和电子看板体系，建立起贯穿研发全生命周期的价值流模型，借助多层次的可视化手段和数字化能力，来解决业务和科技融合过程中的复杂管理场景以及大规模团队协作的问题。</p><p></p><p>演讲提纲：</p><p></p><p>中国工商银行 BizDevOps 的建设思路和方法端到端的价值交付看板体系与可视化管理思想大模型技术与数字员工在研发过程的实践场景</p><p></p><p>你将获得：</p><p></p><p>○ 学习大型银行如何通过创新的管理模式和丰富的技术手段，建立起面向业务价值交付的 BizDevOps 工具链</p><p>○ 面对大型研发团队，如何通过数据驱动的可视化手段，建立起智慧研发管理的自组织模式，来提升研发团队的研发效能</p><p>○ 了解大模型技术与数字员工在工银 e 企研中的运用场景</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle\">DevOps&nbsp;在金融企业落地实践</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle\">金融行业大模型应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle\">创新的金融科技应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle\">金融实时数据平台建设之路</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle\">金融安全风险管控</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle\">数据要素流通与数据合规</a>\"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，享 9 折优惠 ，立省 ￥680！咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png\" /></p><p></p>",
    "publish_time": "2023-11-13 11:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "网易有道上线“易魔声” 开源语音合成引擎，支持中英文双语，包含2000多种不同音色",
    "url": "https://www.infoq.cn/article/dTNqe4wIoZo5m5u8JyTV",
    "summary": "<p>11月10日，网易有道正式上线“易魔声”开源语音合成（TTS）引擎，所有用户可免费在开源社区GitHub进行下载使用，通过其提供的web界面及批量生成结果的脚本接口，轻松实现音色的情感合成与应用。</p><p>&nbsp;</p><p>据悉，“易魔声”是一款有道自研TTS引擎，目前支持中英文双语，包含2000多种不同的音色，更有特色的情感合成功能，支持合成包含快乐、兴奋、悲伤、愤怒等广泛情感的语音。只需简单通过在文本中加入情感的描述提示，就可以自由合成符合自己需求的带有情感的语音，比传统TTS更加自然逼真。</p><p>&nbsp;</p><p>随着基于GAN等现代AI技术的语音能力越来越成熟，实现一个质量较高的TTS系统的门槛越来越低。但即使如此，中英双语的高质量、现代TTS模块还是不易找到，要在自己的应用与内容中加入高逼真度且高度可控的语音，特别是中英双语的语音，也依然比较麻烦。</p><p>&nbsp;</p><p>网易有道CEO周枫表示，“目前该项目还处于初期阶段，现在将这个项目开源，也是希望能帮助到有需求的开发者与内容创作者，并不断扩大高质量TTS的应用范围，让产品及应用更好地落地。也期待大家试用后给我们提供更多反馈与建议。”</p><p>&nbsp;</p><p>公开信息显示，网易有道从2008年开始布局AI，多年来一直致力于基于Transformer模型进行创新和应用，并在神经网络翻译、计算机视觉、高性能计算、智能语音AI技术等方面都具备了核心技术，为应用的实际落地打下了坚实的技术基础。在 TTS 领域，网易有道推出了多款高效便捷的应用和产品。例如，推出教育领域首个明星语音功能，将王源、欧阳娜娜、马伯骞等明星的声音内置在网易有道词典中，陪伴用户共同学习英语；提供声音定制和声音复刻功能，仅需 5 分钟即可完成个性化声音定制；近期推出的 Hi Echo 虚拟人口语私教，借助有道「子曰」教育大模型、语音和虚拟人技术，帮助用户随时随地轻松练习英语口语。</p><p>&nbsp;</p><p>此外，用户还可通过有道智云官网，体验已经对开发者通过API等形式开放的文本和图像翻译、文字和各类图片识别、作文批改等各类AI技术。</p>",
    "publish_time": "2023-11-13 11:33:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]