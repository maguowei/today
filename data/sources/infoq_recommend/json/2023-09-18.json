[
  {
    "title": "谷歌发布了针对MySQL和PostgreSQL的Cloud SQL Enterprise Plus",
    "url": "https://www.infoq.cn/article/dH3URzwYC8hkZhDqsTuS",
    "summary": "<p>谷歌云（Google Cloud）最近发布了<a href=\"https://cloud.google.com/blog/products/databases/announcing-the-cloud-sql-enterprise-plus-edition-for-mysql-and-postgresql\">Cloud SQL企业增强（Cloud SQL Enterprise Plus）版本，用于MySQL和PostgreSQL的托管数据库服务</a>\"。新版本提供了读写操作的性能优化、改进的机器类型和配置，以及一个集成SSD支持的数据缓存选项。</p><p>&nbsp;</p><p>根据云提供商的说法，与现有的<a href=\"https://cloud.google.com/sql/\">Cloud SQL</a>\"相比，针对MySQL的<a href=\"https://cloud.google.com/sql/docs/editions-intro\">Cloud SQL Enterprise Plus</a>\"版本读取吞吐量提高了3倍，写入延迟改进了2倍。此外，新选项减少了运维操作的停机时间，并提供了35天的日志保留以满足合规性要求。谷歌云数据库工程副总裁Andi Gutmas强调了新的可配置数据缓存的优势：</p><p>&nbsp;</p><p></p><blockquote>数据缓存利用闪存透明地扩展了基于DRAM的缓存，降低了读取延迟，提高了吞吐量，并能扩展到更大的数据集。此外，软件优化使事务提交延迟减少了2倍，写入吞吐量提高了2倍，使得Cloud SQL成为了最苛刻的MySQL工作负载的最佳目的地。</blockquote><p></p><p>&nbsp;</p><p>数据缓存仅适用于MySQL引擎。Cloud SQL Enterprise Plus提供了99.99%的可用性SLA（包括维护），将计划停机时间减少到不足10秒。</p><p>&nbsp;</p><p>Cloud SQL企业版最多支持96个CPU和624 GB内存，新的企业增强版最多支持128个CPU和864 GB内存，价格因地区而异。新版本的<a href=\"https://cloud.google.com/sql/pricing#mysql-pg-pricing\">成本平均</a>\"比现有版本高出了30%，但Gutmans<a href=\"https://www.linkedin.com/feed/update/urn:li:activity:7084930212961939456?commentUrn=urn:li:comment:%28activity:7084930212961939456,7084943627386327040%29&amp;replyUrn=urn:li:comment:%28activity:7084930212961939456,7084957322812276736%29\">评论道</a>\"：</p><p>&nbsp;</p><p></p><blockquote>成本的差异取决于你的工作负载，因为你可能不需要使用企业增强版来提供相同大小的实例。因此，建议在具有代表性的工作负载上进行基准测试以了解成本差异。</blockquote><p></p><p>&nbsp;</p><p>作为公告的一部分，云提供商将现有版本的Cloud SQL重新命名为Cloud SQL Enterprise。当用户abhigm在Reddit上强调<a href=\"https://www.reddit.com/r/googlecloud/comments/14xuk67/comment/jrqv88v/?utm_source=share&amp;utm_medium=web2x&amp;context=3\">其缺乏内置代理或连接池</a>\"时，用户OnTheGoTrades<a href=\"https://www.reddit.com/r/googlecloud/comments/14xuk67/comment/jrp7m6t/?utm_source=share&amp;utm_medium=web2x&amp;context=3\">评论道</a>\"：</p><p>&nbsp;</p><p></p><blockquote>太酷了。可惜的是，你不能简单地点击几下就升级到企业增强版。看起来必须要完全从企业版迁移到企业增强版。</blockquote><p></p><p>&nbsp;</p><p>目前，将现有数据库迁移到Cloud SQL Enterprise Plus需要使用<a href=\"https://cloud.google.com/database-migration\">数据库迁移服务（Database Migration Service）</a>\"，而未来预计会提供就地升级的选项。新版本可在部分地区访问，包括爱荷华州、南卡罗来纳州、比利时、台湾和新加坡。</p><p>&nbsp;</p><p>Cloud SQL并不是在谷歌云上运行PostgreSQL数据库的唯一选项，为<a href=\"https://www.infoq.com/news/2022/05/google-cloud-alloydb-postgresql/\">PostgreSQL提供AlloyDB</a>\"则是企业的另一个托管选项。</p><p>&nbsp;</p><p>该云提供商希望在稍后阶段发布针对SQL Server的Cloud SQL Enterprise Plus。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/07/google-cloud-sql-enterprise-plus/\">https://www.infoq.com/news/2023/07/google-cloud-sql-enterprise-plus/</a>\"</p>",
    "publish_time": "2023-09-18 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "华为云携手深圳市气象局将打造高精度区域气象预报大模型，探索降水预报新技术",
    "url": "https://www.infoq.cn/article/btQ8Hp4ASq22ouNIjSyk",
    "summary": "<p>9月18日，华为云宣布将联合深圳市气象局，致力于打造区域气象预报大模型，探索强降水等气象要素预报新技术，提供深圳及周边区域高分辨率中短期气象预报产品。该区域气象大模型将利用人工智能技术提升中短期强降水等气象要素预报精度和模型运算速度，对大城市气象灾害预警和防灾减灾有着积极意义。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/94/94abbcc5c2a75206eef2050ce2e1ff76.png\" /></p><p>深圳9月8日经历极端特大暴雨</p><p></p><p>强降水预测一直是气象领域的世界难题。其影响因子复杂，包含大尺度环流背景、中小尺度天气系统、地形、海陆界面差异等，且多系统多尺度各要素之间互相作用，充满了随机性；与此同时，全球气候变化和深圳的快速城市化所带来的不确定性，让气象灾害防御形势更加复杂。长期以来深圳市气象局在超大城市精细化预报服务、气象防灾减灾和预警信息精准发布等方面持续创新，走在国内前列。未来，还将在短时临近预报及高分辨率区域模式等方面持续研发，为深圳经济社会高质量发展提供高水平气象科技支撑。</p><p></p><p>今年7月，华为云发布的盘古气象大模型在气象学家所关心的一些代表性指标和极端天气预报中展现出独特的优势，具有一定的竞争力和巨大潜力，但预报的空间精细度不足，同时缺乏降水等要素精细化预报能力。接下来，华为云盘古团队和深圳市气象局将基于盘古全球气象大模型，采用更高效的计算方式，打造更精细的深圳区域气象预报大模型，积极探索并提高包括降雨在内的各气象要素精细预报能力和时效。在预训练阶段，区域气象预报大模型能基于深圳市气象局提供的泛华南区域3km分辨率高质量再分析数据集，学习该区域的三维大气运动规律，进而预测包括深圳在内的泛华南区域的气象要素在未来的变化情况。</p><p></p><p>此前，华为云与深圳市气象局已签署深度合作框架协议，共同推动超大城市气象精准预报、智慧城市气象服务的突破性创新。通过本次合作，深圳区域气象预报大模型有望尽快在粤港澳大湾区落地，应用于气象灾害预报预警、防灾减灾决策等场景中。</p>",
    "publish_time": "2023-09-18 09:56:06",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "程序员会使用的十个基础算法",
    "url": "https://www.infoq.cn/article/10c63a8a59322d25e71f9ff4c",
    "summary": "<p>作为一名程序员，掌握各种算法可以帮助我们解决各种复杂的问题，提高代码的效率和性能，同时也是面试中常被考察的重要内容之一。无论是开发新的软件应用、优化现有的算法逻辑还是解决各类计算问题，算法都是不可或缺的工具。因此，程序员掌握一系列常用的算法，以确保能够高效地编写出稳定、功能强大的软件。</p><p>常用的算法类别及其应用如下：</p><p>一.&nbsp;排序算法</p><p>&nbsp;1. 冒泡排序：用于将一组数据按照升序或降序进行排列，它通过比较相邻元素的大小来进行交换，直到整个序列排序完成。</p><p>&nbsp;2. 快速排序：快速排序是一种常用且高效的排序算法，它采用递归的方式将问题划分为更小的子问题，并使用一个基准元素进行排序。</p><p>&nbsp;3. 归并排序：归并排序采用分治策略，将问题逐步细化并通过合并操作得到最终的有序结果。</p><p><img src=\"https://static001.geekbang.org/infoq/e7/e77a3e274ad2b1e87f88f959220e6a23.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ff/ffd5dd9a7cf78c625facf262c2bf608b.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1b/1b5475e651879c9df8e7775b7df71afa.png\" /></p><p>二.&nbsp;搜索算法</p><p>1. 二分查找：二分查找适用于有序数组，它将目标值与数组的中间元素进行比较，从而缩小搜索范围，直到找到目标元素或确定不存在。</p><p>2. 广度优先搜索：广度优先搜索用于遍历或搜索图或树的结构。它按照层次的顺序遍历节点，先访问根节点，然后是所有与根节点相邻的节点，然后是他们的邻节点，依次类推。</p><p>3. 深度优先搜索：深度优先搜索也用于遍历或搜索图或树的结构。它从根节点开始，沿着一条路径搜索到最深的节点，然后再回溯到之前的节点继续搜索。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/d2/d27f5022d1daf6aa67aa0a22172877b2.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/93/9315ecc3dd281abb6a092067fe420789.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b6/b61a6d337760ab8f0e3dd5c933333977.png\" /></p><p>三.&nbsp;图算法</p><p>1. 最短路径算法：最短路径算法用于寻找两个节点之间的最短路径。常用的最短路径算法有Dijkstra算法和Floyd-Warshall算法。</p><p>&nbsp;2. 最小生成树算法：最小生成树算法用于在一个带权重的无向图中找出一棵包含所有节点的子树，并且使得该子树的边权重之和最小。常见的最小生成树算法有Prim算法和Kruskal算法。</p><p><img src=\"https://static001.geekbang.org/infoq/cd/cd8bed30493ef055db8dabfbd5dd612a.png\" /></p><p>四.动态规划</p><p>1.背包问题：背包问题是一类经典的优化问题，其中给定一组物品和一个背包容量，目标是将物品放入背包中，使得物品总价值最大化，同时不超过背包的容量。</p><p>2.最长公共子序列：最长公共子序列问题是一类经典的字符串处理问题，目标是找出两个字符串中最长的共同子序列的长度。</p><p><img src=\"https://static001.geekbang.org/infoq/5d/5d72d72346f0c2da65fe1a8a2c8134a2.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9d/9d7e00a618bfd265e174febd0297e277.png\" /></p><p></p>",
    "publish_time": "2023-09-18 10:08:06",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "富滇银行数字金融中心 / 副总经理李涛确认出席 FCon ，分享金融数字化转型业务价值提升之路",
    "url": "https://www.infoq.cn/article/8OhuOKyViFF7X3vy7Bh7",
    "summary": "<p><a href=\"https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle\">FCon 全球金融科技大会</a>\"，将于 11 月在上海召开。富滇银行数字金融中心 / 副总经理李涛将发表题为《<a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5530?utm_source=infoqweb&amp;utm_medium=article\">金融数字化转型业务价值提升之路</a>\"》主题分享，介绍在 5 年时间，一个银行从信息化到数字化高速脱变的根因、思考和架构演进，以业务价值为驱动的银务全面数字化转型实践，BizDevOps 的实践经验，以及金融业数字化转型未来的思考。</p><p></p><p><a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5530?utm_source=infoqweb&amp;utm_medium=article\">李涛</a>\"，富滇银行数字金融中心副主任，富滇银行“滇峰”计划架构设计负责人。具有 20 年金融 IT 架构和敏捷实践经验，曾任职中国工商银行软件开发中心主要从事对私、对公核心业务架构设计和敏捷实践。2015 年加入富滇银行主要担任新一代核心系统建设架构师、项目经理。富滇银行全面数字化转型“滇峰”计划项目架构和产品团队负责人，并牵头负责“滇峰”计划项目组织敏捷改进相关工作。他在本次会议的演讲内容如下：</p><p></p><p>演讲：金融数字化转型业务价值提升之路</p><p></p><p>银行业数字化转型是这个时代的必选项，富滇银行“滇峰”计划为银行业数字化转型树立了全面转型的标杆案例。本次演讲，主要会分为 3 部分内容，首先是在 5 年时间，一个银行从信息化到数字化高速脱变的根因、思考和架构演进。</p><p></p><p>第二，以业务价值为驱动的银务全面数字化转型实践，其中包括前端、业务中台、数据中台、AI 中台、PaaS、IaaS 业务、产品架构设计如何落地，以及对关键的问题的思考。</p><p></p><p>第三，BizDevOps 基于业务价值的组织效能提升和超大规模项目管理实践经验，以及金融业数字化转型未来的思考。</p><p></p><p>演讲提纲：</p><p></p><p>银行业发展的架构演进“滇峰”计划总体架构设计和业务价值业务中台关键设计和思考数据中台关键设计和思考运营营销关键设计和思考BizDevOps 效能提升实践</p><p></p><p>你将获得：</p><p></p><p>○ 从银行业数字化转型的实践中获得思考</p><p>○ 在业务中台、数据中台、AI 中台、营销、运营获得共鸣</p><p>○ 了解 DevOps 在数字化时代的大规模实践如何完成</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle\">DevOps&nbsp;在金融企业落地实践</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle\">金融行业大模型应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle\">创新的金融科技应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle\">金融实时数据平台建设之路</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle\">金融安全风险管控</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle\">数据要素流通与数据合规</a>\"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，前 100 人可享 5 折特惠购票，咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png\" /></p><p></p>",
    "publish_time": "2023-09-18 10:51:15",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "OGAI详解：AIStation调度平台如何实现大模型高效长时间持续训练",
    "url": "https://www.infoq.cn/article/xekMQIvkR2X3sd09reMs",
    "summary": "<p>大模型是当前通用人工智能产业发展创新的核心技术，目前国内已发布的生成式AI模型超过了100个。面向以大模型为核心的生成式AI开发与应用场景，近日浪潮信息发布了大模型智算软件栈OGAI（Open GenAI Infra）——“元脑生智”，为大模型业务提供了全栈全流程的智算软件栈，包括AI算力系统环境部署、算力调度保障、模型开发管理等。OGAI软件栈由5层架构组成，从L0到L4分别对应于基础设施层的智算中心OS产品、系统环境层的PODsys产品、调度平台层的AIStation产品、模型工具层的YLink产品和多模纳管层的MModel产品。</p><p></p><p>其中L2层AIStation是面向大模型开发的AI算力调度平台，AIStation针对大模型训练中的资源使用与调度、训练流程与保障、算法与应用管理等方面进行了系统性优化，具备大模型断点续训能力，保证长时间持续训练。AIStation支撑浪潮信息“源”大模型的训练算力效率达到44.8%。某大型商业银行基于AIStation打造的大规模并行运算集群，帮助其充分发掘计算潜能进行大模型训练，并荣获2022 IDC“未来数字基础架构领军者”奖项。</p><p></p><p>本文将重点讨论大模型训练面临的挑战、AIStation如何提升大模型训练效率，以及取得的效果。</p><p></p><h2>一、大模型训练面临巨大挑战</h2><p></p><p></p><h4>1.大模型训练巨大算力成本和算力利用难题</h4><p></p><p></p><p>大模型训练要面对的首要挑战就是海量数据和计算量，算力开销巨大，如GPT-3是在10000个GPU上训练得到的，“源1.0”模型是在2128个GPU上通过AIStation平台完成1800亿tokens的训练，训练一个万亿token的700亿参数模型将花费上百万美元。但计算平台的性能通常不能随着算力线性增长，而是会出现耗损，因此大模型训练还需要高效的算力调度来发挥算力平台的效能。而这不仅需要依赖算法、框架的优化，还需要借助高效的算力调度平台，以根据算力集群的硬件特点和计算负载特性实现最优化的算力调度，整体提高算力利用率和训练效率。</p><p></p><h4>2.耗时且维护复杂的多种网络兼容适配</h4><p></p><p></p><p>大模型训练过程中，成千上万颗GPU会在节点内和节点间不断地进行通信。为了获得最优的训练效果，单台GPU服务器会搭载多张InfiniBand、ROCE等高性能网卡，为节点间通信提供高吞吐、低时延的服务。但不同的网络方案各有优劣，InfiniBand因性能优异已被公认为大模型训练的首选，但其成本较高；RoCE虽然成本较低，但在大规模的网络环境下，其性能和稳定性不如InfiniBand方案。因此要想满足大模型训练对通信的要求，就要对集群网络中的通信设备适配使用和网络情况进行探索和设计。</p><p></p><h4>3.不稳定的大模型训练和高门槛的系统级别优化</h4><p></p><p></p><p>大模型训练过程比传统的分布式训练复杂，训练周期长达数月。集群计算效力低、故障频发且处理复杂，会导致训练中断后不能及时恢复，从而会降低大模型训练的成功概率，也会使得大模型训练成本居高不下。因此，大模型对训练的稳定性、故障检测与训练容错提出了更高的要求。同时简化大模型分布式任务提交、实现智能与自动化的任务资源匹配和训练健壮性也是提升训练效率的重要保证。</p><p></p><p>Meta在训练模型体量与GPT3规模相当的Open Pre-trained Transformer (OPT)-175B时，遇到的一大工程问题就是训练不稳定。如下图所示，可以看到有许多训练停止的时间节点，原因有GPU掉卡、GPU性能异常导致训练意外中断等。训练稳定性和有效的断点续训是目前大模型训练中亟待解决的问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c7/c71b3cdc5ef43a7ea390b5804a8ea636.png\" /></p><p></p><p>总之，在超大规模分布式环境下开展大模型训练，如果想要缩短训练周期、降低训练成本，就需要解决算力调度、网络通信、训练稳定性等各种挑战。不仅要灵活、充分地利用集群内的所有资源，通过多种手段优化数据使用、通讯，还要及时处理大规模计算集群的异常。</p><p></p><h2>二、AIStation全流程简化和提速大模型训练</h2><p></p><p></p><p>浪潮信息AIStation提供了系统性软硬一体优化的平台与软件栈能力，来保障大模型的训练需求。AIStation平台从资源使用与调度、训练流程与保障、算法与应用等角度进行了系统性的优化，实现了对大模型训练的端到端优化和加速。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a1/a11a6db3938ab93d2ccfdd7514d3db53.png\" /></p><p></p><h4>1.毫秒级调度，高效使用大规模算力，解决算力利用低难题</h4><p></p><p></p><p>AIStation在大模型训练实践中，针对云原生调度系统性能做了优化，实现了上千POD极速启动和环境就绪。如下表所示，AIStation调度器与原生社区版相比，能大幅提升大规模POD任务的调度性能，尤其能保证大模型训练的计算资源的调度使用。</p><p></p><p>表1 大规模POD调度任务性能对比：</p><p></p><p></p><p>此外，AIStation平台能够支持大模型特有的开发模式，提供多种尺度作业资源使用方式，包括小尺度资源调度，大尺度资源调度、高性能调度等。算力调度器通过动态、智能地管理和调配集群计算资源，制定合理的作业执行计划，以最大限度地利用资源，满足各类训练任务的时延和吞吐需求，保证作业高效稳定运行，实现算力平台高利用率、强扩展性、高容错性。</p><p></p><p>通过多种资源高效管理和调度策略，AIStation能实现毫秒级调度，将整体资源利用率提升到70%以上，帮助客户更好地利用计算集群算力，充分发挥算力价值。</p><p></p><h4>2.高效网络资源管理，多卡加速比达90%，极致加速训练过程</h4><p></p><p></p><p>AIStation定义了互相独立的计算高性能网络、存储高性能网络，并且支持交换机级别的资源调度，减少跨交换机流量，同时具备网络故障自动识别和处理功能。针对大模型训练通信要求高的场景，AIStation提供集群拓扑感知能力，容器网络与集群物理网络一致，保证了容器互联性能，满足训练通信要求。分布式通信优化结合集群的InfiniBand或 RoCE高性能网络和专门优化的通信拓扑，使得AIStation在千卡规模集群测试中，多卡加速比达到了90%。尤其AIStation对大规模RoCE无损网络下的大模型训练也做了相应优化，实测网络性能稳定性达到了业界较高水平。</p><p></p><p>借助AIStation平台，某大型商业银行实现了主流大模型训练框架，如DeepSpeed、Megatron-LM和大语言模型在RoCE网络环境的训练，快速实现大模型的落地实践。</p><p></p><h4>3.大规模训练系统级别优化，故障处理时间缩短90%，最大限度降低实验成本</h4><p></p><p></p><p>大模型任务提交时，经常会伴随着大量的环境配置、依赖库适配和超参数调整。AIStation能够自动化配置计算、存储、网络环境，同时对一些基本的超参数提供自定义修改，方便用户使用，通过几步就能启动大模型分布式训练，目前支持诸多大模型训练框架和开源方案，如Megatron-LM、DeepSpeed等。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b7/b727e01696187e3afbf36396e3f95e5c.png\" /></p><p></p><p>AIStation在大规模训练集群上利用自研数据缓存系统，提高了训练前、训练中的数据读取速率，大大减少对存储系统和网络的依赖。配合优化的调度策略，与直接使用存储系统相比，可让模型训练效率获得200%-300%的提升，硬件性能100%释放。</p><p></p><p>健壮性与稳定性是高效完成大模型训练的必要条件。AIStation针对资源故障等集群突发情况，会自动进行容错处理或者执行弹性扩缩容策略，保证训练任务中断后能以最快速度恢复，为需要长时间训练的大模型提供可靠环境，平均将异常故障处理时间缩短90%以上。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f5/f545238d2060dfaba2bfaf76b642b2c1.png\" /></p><p></p><p>综上，针对大规模分布式计算，AIStation内置分布式训练自适应系统，覆盖训练的全生命周期，满足了大模型训练的诸多诉求，提供资源使用视图、计算与网络调度策略、分布式训练加速、训练监控、训练容错与自愈能力，在加速训练的同时，能够自动定位故障和恢复任务，保证了训练的稳定性和效率。某银行客户在AIStation智能容错的机制保障下，在极其严苛的业务投产测试中能够实现快速故障排查和恢复，大幅降低业务投产上线时间。</p><p></p><h2>三、AIStation助力行业提升大模型开发效率</h2><p></p><p></p><p>AIStation平台在AI开发、应用部署和大模型工程实践上积累了宝贵的经验和技术，帮助诸多行业客户在资源、开发、部署层面实现降本增效。在垂直行业领域，AIStation平台帮助头部金融客户、生物制药服务公司快速利用密集数据训练、验证大模型，大大降低大模型业务成本。某大型商业银行基于AIStation打造的并行运算集群，凭借领先的大规模分布式训练支撑能力，荣获2022 IDC“未来数字基础架构领军者”奖项。</p><p></p><p>浪潮信息AIStation在大模型方面已经取得了诸多业界领先的经验和积累，实现了端到端的优化，是更适合大模型时代的人工智能平台。未来AIStation将与浪潮信息OGAI软件栈一同进化，进一步通过低代码、标准化的大模型开发流程，以及低成本和高效的推理服务部署，帮助客户快速实现大模型开发和落地，抢占先机。</p><p></p><h4>作者介绍</h4><p></p><p></p><p>Leon Wang，浪潮信息高级产品经理，山东大学、法国马赛粒子物理中心理学博士，CERN访问学者，致力于人工智能基础设施与算法的产品设计和生态建设，参与多项相关国家标准制定工作，申请发明专利10余项并授权6项，发表相关国际国内学术论文4篇。</p>",
    "publish_time": "2023-09-18 11:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "内存都去哪了",
    "url": "https://www.infoq.cn/article/92ce399000f46e5d308b3d935",
    "summary": "<p></p><h1>问题背景</h1><p></p><p><img src=\"https://static001.geekbang.org/infoq/d8/d8430a682116f98b363576afe1b93e8a.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/95/953c930624b32947e688669a2d167a0f.png\" /></p><p></p><p>有小伙伴反馈客户生产环境（裸机部署）频繁告警可用内存不足，但是计算出来每个进程的内存使用总和不多，那多出来的内存哪里去了呢？</p><p></p><p>通过 free 命令我们能计算出来系统的使用内存 （used=11G），free 内存 （free=4.8G）当前linux 系统的版本是RHEL 6.8 内核 kernel 版本 2.6.32top 命令里面展示的 top 进程使用的RES 内存总和不到 6G，剩余的 11-6=5G 哪里去了呢？被系统内核占用了？那怎么才能看到系统内存的详细分配情况？</p><p></p><p>带着这些疑问我们来梳理 linux 中常见的查看系统内存资源一些命令和详细的指标解释，包括一些参数配置的最佳实践</p><p></p><h1>命令集</h1><p></p><p></p><h2>free命令</h2><p></p><p></p><h3>命令</h3><p></p><p><code lang=\"java\">free -m\n</code></p><p></p><h3>选项</h3><p></p><p><code lang=\"java\">-b # 以Byte为单位显示内存使用情况；\n-k # 以KB为单位显示内存使用情况；\n-m # 以MB为单位显示内存使用情况；\n-g # 以GB为单位显示内存使用情况。 \n-o # 不显示缓冲区调节列；\n-s&lt;间隔秒数&gt; # 持续观察内存使用状况；\n-t # 显示内存总和列；\n-V # 显示版本信息。\n</code></p><p></p><h3>数据</h3><p></p><p><code lang=\"java\">free -m\n             total       used       free     shared    buffers     cached\nMem:          2016       1973         42          0        163       1497\n-/+ buffers/cache:        312       1703\nSwap:         4094          0       4094\n</code></p><p></p><p>注意：RHEL 6 和 RHEL 7及以上版本可能还不一样，7以上版本会多一项数据指标 avaliable，会帮你把真实可用的内存值算出来。</p><p></p><h3>含义解释</h3><p></p><p></p><h4>Mem 行显示的数值定义</h4><p></p><p>total：系统内存总数</p><p></p><p>used：已经使用的内存数</p><p></p><p>free： 空闲的内存数</p><p></p><p>shared：当前已经废弃不用</p><p></p><p>buffers：缓存内存数</p><p></p><p>cached：缓存内存数</p><p></p><p>Buffers和cached的区别Buffers作为buffer cache的内存，是块设备的读写缓冲区,是即将写入磁盘的，是内存和磁盘之间的缓存buffer是由各种进程分配的，被用在如输入队列等方面。一个简单的例子如某个进程要求有多个字段读入，在所有字段被读入完整之前，进程把先前读入的字段放在buffer中保存cached作为page cache的内存， 文件系统的cache，是cpu到内存之间的缓存，是从磁盘中读出来的数据的缓存cache经常被用在磁盘的I/O请求上，如果有多个进程都要访问某个文件，于是该文件便被做成cache以方便下次被访问，这样可提高系统性能如何释放缓存</p><p></p><p><code lang=\"shell\">#释放page cache\necho 1 &gt; /proc/sys/vm/drop_caches\n----------------------------------------\n#释放 Linux 系统中的 dentries（目录项）和 inodes（索引节点）所占用的资源\necho 2 &gt; /proc/sys/vm/drop_caches\n----------------------------------------\n\n#释放 page cache 及 dentries（目录项）和 inodes（索引节点）所占用的资源\necho 3 &gt; /proc/sys/vm/drop_caches\n\n----------------------------------------\n#释放前最好sync一下，防止丢失数据，但是一般情况下没有必要手动释放内存\n</code></p><p></p><h4>(-/+ buffers/cache)是从用户角度描述内存使用详情</h4><p></p><p>used = Mem行的 used-buffers-cached</p><p>free = Mem行的 free+buffers+cached</p><p></p><h4>SWAP</h4><p></p><p>在 Linux 系统中，Swap 是一种虚拟内存技术，用于扩展系统的可用内存空间。当物理内存（RAM）不足时，Swap 允许将一部分数据从内存交换到硬盘上的 Swap 分区或 Swap 文件中SWAP 的优势扩展内存：Swap 提供了一种方式来增加系统可用的虚拟内存空间，以处理内存需求超过物理内存容量的情况保证系统的稳定：当物理内存不足时，Swap 可以避免系统崩溃或进程被终止，而是将一部分数据交换到磁盘上SWAP 的值设置的最佳实践针对小型的系统物理内存的倍数：一般来说，建议将 Swap 的大小设置为物理内存的 1-2 倍对于大型的系统可以设置为内存的一半：如16G的物理内存，可以把SWAP 设置为 8G考虑应用系统的类型，对于内存密集型的系统，建议把SWAP 值尽量提高保留系统的冗余能力linux 上查看 Swap 设置值大小和修改方法查看</p><p></p><p><code lang=\"shell\">#查看方式1\nswapon --show\n---------------------------------------------\nNAME      TYPE       SIZE USED PRIO\n/dev/dm-1 partition 15.7G  12G   -2\n---------------------------------------------\n#查看方式2\ncat /etc/fstab\n--------------------------------------------\n/dev/mapper/centos-root /                       xfs     defaults        0 0\nUUID=5daa0a7f-cc95-4a7d-9aeb-94816daf4025 /boot                   xfs     defaults        0 0\n/dev/mapper/centos-home /home                   xfs     defaults        0 0\n/dev/mapper/centos-swap swap                    swap    defaults        0 0\n---------------------------------------------\n# swap 和dm-1建立的是软连接\n---------------------------------------------\nlrwxrwxrwx. 1 root root       7 5月  22 20:10 centos-swap -&gt; ../dm-1\n---------------------------------------------\n</code></p><p></p><p>修改</p><p></p><p><code lang=\"shell\">#创建 Swap 分区（可选）\n---------------------------------------------\nsudo mkswap /dev/mapper/test-swap\n---------------------------------------------\n#方法一\n---------------------------------------------\nsudo swapon /dev/mapper/test-swap\n---------------------------------------------\n\n#方法二（永久设置 Swap 分区）\n#编辑上文中的/etc/fstab 文件，并添加以下行到文件末尾\n---------------------------------------------\nvim /etc/fstab\n---------------------------------------------\n#添加代码\n---------------------------------------------\n/dev/mapper/test-swap   none   swap   defaults   0   0\n---------------------------------------------\n</code></p><p></p><p>关闭swap</p><p></p><p><code lang=\"shell\">#关闭swap\nswapoff /dev/mapper/test-swap\n</code></p><p></p><p>修改触发swap的阈值 (定义：内存在使用到100-swappiness 的时候，就开始出现有交换分区的使用)0：在任何情况下都不发生物理内存数据和 swap 文件的交换100：表示积极进行物理内存数据和 swap 数据的交换</p><p></p><p><code lang=\"shell\">#查看阈值\ncat /proc/sys/vm/swappiness\n---------------------------------------------\n30\n---------------------------------------------\n\n#临时修改\nsysctl vm.swappiness=60\n\n#永久修改\nvim  /etc/sysctl.conf\n\n#添加\nvm.swappiness=60\n</code></p><p></p><p>物理内存和 Swap 使用的优先级和策略物理内存优先当物理内存不足时，系统会将一部分不活动的数据（如未使用的进程、未被频繁访问的页面等）交换到 Swap 分区或交换文件中Linux 内核中使用的内存管理算法会根据应用程序的需求和系统的负载情况来决定何时将数据交换到 SwapSwappiness 值Swap 中的数据何时回返还到物理内存中内存需求减少通过一些计算算法，发现部分频繁访问的数据在 swap 区，而物理内存中存在不经常被访问的数据，这个时候系统会做热点数据的交换，以保证获得更高的数据读取性能</p><p></p><h2>Top命令</h2><p></p><p></p><h3>top命令面板</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/ce/ceb15e231493fc6b6eea430fb0a1dc11.png\" /></p><p></p><h3>指标解析</h3><p></p><p>第一行</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cc/cc8b28c6a93218423143c729ee6f3a2f.png\" /></p><p></p><p>load average: 如果这个数除以逻辑CPU的数量，结果高于5的时候就表明系统在超负荷运转了。</p><p></p><p>第二行</p><p><img src=\"https://static001.geekbang.org/infoq/af/af30d30a53c55c0716ae18eb2261666c.png\" /></p><p></p><p>第三行</p><p><img src=\"https://static001.geekbang.org/infoq/94/94c70de0ac0e675af781ccabf6375d75.png\" /></p><p></p><p>|</p><p></p><p>第四行第五行和内存使用相关的数据和 free 命令中的一致</p><p><img src=\"https://static001.geekbang.org/infoq/8a/8ace746586b91db85b471b2179336a3e.png\" /></p><p></p><p>进程相关</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3f/3fb5616ca73a9071ece18da938158b1c.png\" /></p><p></p><p>默认情况下仅显示比较重要的 PID、USER、PR、NI、VIRT、RES、SHR、S、%CPU、%MEM、TIME+、COMMAND 几个列！</p><p></p><p>如果想看上述列表中的其他数据，先按键 f ，再选择你想展示的指标 ，按d选中 回车。q 退出</p><p></p><p><code lang=\"shell\">top\n#按 f\n------------------------------------------------------------------\n* PID     = Process Id             RSfd    = RES File-based (KiB)\n* USER    = Effective User Name    RSlk    = RES Locked (KiB)    \n* PR      = Priority               RSsh    = RES Shared (KiB)    \n* NI      = Nice Value             CGNAME  = Control Group name  \n* VIRT    = Virtual Image (KiB)    NU      = Last Used NUMA node \n* RES     = Resident Size (KiB) \n* SHR     = Shared Memory (KiB) \n* S       = Process Status      \n* %CPU    = CPU Usage           \n* %MEM    = Memory Usage (RES)  \n* TIME+   = CPU Time, hundredths\n* COMMAND = Command Name/Line   \n  PPID    = Parent Process pid  \n  UID     = Effective User Id   \n  RUID    = Real User Id        \n  RUSER   = Real User Name      \n  SUID    = Saved User Id       \n  SUSER   = Saved User Name     \n  GID     = Group Id            \n  GROUP   = Group Name          \n  PGRP    = Process Group Id    \n  TTY     = Controlling Tty     \n  TPGID   = Tty Process Grp Id  \n  SID     = Session Id          \n  nTH     = Number of Threads   \n  P       = Last Used Cpu (SMP) \n  TIME    = CPU Time            \n  SWAP    = Swapped Size (KiB)  \n  CODE    = Code Size (KiB)     \n  DATA    = Data+Stack (KiB)    \n  nMaj    = Major Page Faults   \n  nMin    = Minor Page Faults   \n  nDRT    = Dirty Pages Count   \n  WCHAN   = Sleeping in Function\n  Flags   = Task Flags \n  CGROUPS = Control Groups      \n  SUPGIDS = Supp Groups IDs     \n  SUPGRPS = Supp Groups Names   \n  TGID    = Thread Group Id     \n  OOMa    = OOMEM Adjustment    \n  OOMs    = OOMEM Score current \n  ENVIRON = Environment vars    \n  vMj     = Major Faults delta  \n  vMn     = Minor Faults delta  \n  USED    = Res+Swap Size (KiB) \n  nsIPC   = IPC namespace Inode \n  nsMNT   = MNT namespace Inode \n  nsNET   = NET namespace Inode \n  nsPID   = PID namespace Inode \n  nsUSER  = USER namespace Inode\n  nsUTS   = UTS namespace Inode \n  LXC     = LXC container name  \n  RSan    = RES Anonymous (KiB) \n------------------------------------------------------------------\n# 选中想要展示的指标 按d 选中  按q 退出\n------------------------------------------------------------------\n\n PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND                 PPID TTY        CODE    DATA \n   6218 systemd+  20   0 1740884 404556      0 S   0.3  10.5 420:03.84 mysqld                  6201 ?         55828  806684 \n   6768 root      20   0 2736204 410092   3368 S   0.3  10.6 103:43.46 java                    6750 pts/0         4  615804 \n      1 root      20   0  178784  10308   7468 S   0.0   0.3 172:31.49 systemd                    0 ?          1260   20720 \n      2 root      20   0       0      0      0 S   0.0   0.0   0:03.22 kthreadd                   0 ?             0       0 \n      3 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 rcu_gp                     2 ?             0       0 \n      4 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 rcu_par_gp                 2 ?             0       0 \n      6 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 kworker/0:0H-kblockd       2 ?             0       0 \n      8 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 mm_percpu_wq               2 ?             0       0 \n      9 root      20   0       0      0      0 S   0.0   0.0   2:54.83 ksoftirqd/0                2 ?             0       0 \n     10 root      20   0       0      0      0 I   0.0   0.0  26:28.63 rcu_sched                  2 ?             0       0 \n     11 root      rt   0       0      0      0 S   0.0   0.0   0:05.90 migration/0                2 ?             0       0 \n     12 root      rt   0       0      0      0 S   0.0   0.0   0:00.60 watchdog/0                 2 ?             0       0 \n     13 root      20   0       0      0      0 S   0.0   0.0   0:00.00 cpuhp/0                    2 ?             0       0 \n     14 root      20   0       0      0      0 S   0.0   0.0   0:00.00 cpuhp/1                    2 ?             0       0 \n</code></p><p></p><h3>常用命令</h3><p></p><p>top + c 显示启动命令</p><p></p><p>top + m  按照内存使用从高到低进程排序</p><p></p><p>top + P 按照cpu使用从高到低进程排序</p><p></p><p>top + 1 显示每个cpu的使用情况</p><p></p><h3>重点指标</h3><p></p><p>RES（Resident Set Size）：RES 表示进程当前实际占用的物理内存大小。它包括进程的代码、数据和共享库等在物理内存中的部分。RES 反映了进程实际使用的物理内存量，也可以理解为进程当前使用的实际内存。RES的值通常大于 DATA+CODE的值VIRT（Virtual Memory Size）：VIRT 表示进程所占用的虚拟内存大小。它包括进程可访问的所有虚拟内存空间，包括实际分配的内存、共享库、堆、栈和映射文件等。VIRT 指标可能会大于实际物理内存，因为它包括了未实际分配的虚拟内存空间</p><p></p><p>VIRT 包含 RES的值</p><p></p><p>区别</p><p></p><p>RES 反映了进程实际使用的物理内存量，而 VIRT 则表示进程所占用的虚拟内存大小。RES 是实际分配到物理内存的部分，而 VIRT 包括了所有可访问的虚拟内存空间。</p><p></p><h2>meminfo</h2><p></p><p></p><h4>面板</h4><p></p><p><code lang=\"shell\">cat /proc/meminfo\n----------------------------------------------------------------\nMemTotal:        3868864 kB\nMemFree:          140928 kB\nMemAvailable:    2456296 kB\nBuffers:          210416 kB\nCached:          2238404 kB\nSwapCached:            0 kB\nActive:          2546324 kB\nInactive:         941624 kB\nActive(anon):    1038396 kB\nInactive(anon):     1836 kB\nActive(file):    1507928 kB\nInactive(file):   939788 kB\nUnevictable:           0 kB\nMlocked:               0 kB\nSwapTotal:             0 kB\nSwapFree:              0 kB\nDirty:              1000 kB\nWriteback:             0 kB\nAnonPages:       1017048 kB\nMapped:           188840 kB\nShmem:              2216 kB\nKReclaimable:     144468 kB\nSlab:             195904 kB\nSReclaimable:     144468 kB\nSUnreclaim:        51436 kB\nKernelStack:        4352 kB\nPageTables:        10872 kB\nNFS_Unstable:          0 kB\nBounce:                0 kB\nWritebackTmp:          0 kB\nCommitLimit:     1934432 kB\nCommitted_AS:    2446620 kB\nVmallocTotal:   34359738367 kB\nVmallocUsed:           0 kB\nVmallocChunk:          0 kB\nPercpu:             1328 kB\nHardwareCorrupted:     0 kB\nAnonHugePages:    784384 kB\nShmemHugePages:        0 kB\nShmemPmdMapped:        0 kB\nHugePages_Total:       0\nHugePages_Free:        0\nHugePages_Rsvd:        0\nHugePages_Surp:        0\nHugepagesize:       2048 kB\nHugetlb:               0 kB\nDirectMap4k:      171896 kB\nDirectMap2M:     4022272 kB\nDirectMap1G:     2097152 kB\n</code></p><p></p><p>指标解释</p><p><img src=\"https://static001.geekbang.org/infoq/1c/1cdf38eb12d144f3f1bb9aeb0b8ae1d3.png\" /></p><p></p><p>重要指标</p><p>Committed_AS：目前在系统上分配的内存量。是所有进程申请的内存的总和Slab：内核数据结构缓存的大小，可以减少申请和释放内存带来的消耗SReclaimable：可收回Slab的大小PageTables：管理内存分页页面的索引表的大小</p><p></p><h4>SLAB 是什么</h4><p></p><p>内核为了高性能每个需要重复使用的对象都会有个池，这个slab池会cache大量常用的对象，所以会消耗大量的内存，他所消耗的内存是算在 free 命令中的 used 中还是在cache 中呢？我们通过一组命令来确认</p><p></p><h5>slabtop</h5><p></p><p><code lang=\"shell\">#展示具体内核使用的内存的明细\nslabtop\n--------------------------------------------------------------------------------\n Active / Total Objects (% used)    : 3774607 / 4716484 (80.0%)\n Active / Total Slabs (% used)      : 86026 / 86026 (100.0%)\n Active / Total Caches (% used)     : 92 / 119 (77.3%)\n Active / Total Size (% used)       : 678448.10K / 829043.07K (81.8%)\n Minimum / Average / Maximum Object : 0.01K / 0.17K / 14.09K\n\n  OBJS ACTIVE  USE OBJ SIZE  SLABS OBJ/SLAB CACHE SIZE NAME                   \n2262372 2262372 100%    0.19K  53866       42    430928K dentry\n436224 417418  95%    0.03K   3408      128     13632K kmalloc-32\n401856 144870  36%    0.06K   6279       64     25116K kmalloc-64\n337920 105054  31%    0.02K   1320      256      5280K kmalloc-16\n269688  80643  29%    0.04K   2644      102     10576K selinux_inode_security\n137360 137360 100%    0.02K    808      170      3232K fsnotify_mark_connector\n126350  44070  34%    0.57K   2636       56     84352K radix_tree_node\n115712 110541  95%    0.01K    226      512       904K kmalloc-8\n 59920  55324  92%    0.21K   1621       37     12968K vm_area_struct\n 52952  14489  27%    0.94K   1568       34     50176K xfs_inode\n 52836  52836 100%    0.12K    777       68      6216K kernfs_node_cache\n 47872  39820  83%    0.25K    748       64     11968K kmalloc-256\n\n--------------------------------------------------------------------------------\n#或者使用 \ncat /proc/slabinfo\n\n--------------------------------------------------------------------------------\n# name                 : tunables    : slabdata   \nnf_conntrack_ffff8d47c7815200   2550   2550    320   51    4 : tunables    0    0    0 : slabdata     50     50      0\nnf_conntrack_ffff8d49b5e39480    306    306    320   51    4 : tunables    0    0    0 : slabdata      6      6      0\nnf_conntrack_ffff8d47c7813d80   2424   2652    320   51    4 : tunables    0    0    0 : slabdata     52     52      0\nnf_conntrack_ffff8d486c7f5200   2961   3366    320   51    4 : tunables    0    0    0 : slabdata     66     66      0\nnf_conntrack_ffff8d47c7812900    612    612    320   51    4 : tunables    0    0    0 : slabdata     12     12      0\nnf_conntrack_ffff8d49cbaebd80    306    306    320   51    4 : tunables    0    0    0 : slabdata      6      6      0\nnf_conntrack_ffff8d486a449480    306    306    320   51    4 : tunables    0    0    0 : slabdata      6      6      0\nnf_conntrack_ffff8d486a44bd80   2346   2346    320   51    4 : tunables    0    0    0 : slabdata     46     46      0\nnf_conntrack_ffff8d4877072900   2149   2346    320   51    4 : tunables    0    0    0 : slabdata     46     46      0\nnf_conntrack_ffff8d486a44e680    459    459    320   51    4 : tunables    0    0    0 : slabdata      9      9      0\nnf_conntrack_ffff8d486a44d200   2958   2958    320   51    4 : tunables    0    0    0 : slabdata     58     58      0\nnf_conntrack_ffff8d49cbaee680    306    306    320   51    4 : tunables    0    0    0 : slabdata      6      6      0\nnf_conntrack_ffff8d4877076680    255    255    320   51    4 : tunables    0    0    0 : slabdata      5      5      0\nnf_conntrack_ffff8d486a44a900     51     51    320   51    4 : tunables    0    0    0 : slabdata      1      1      0\nnf_conntrack_ffff8d49cbaed200    357    357    320   51    4 : tunables    0    0    0 : slabdata      7      7      0\nnf_conntrack_ffffffffba912940   2703   2703    320   51    4 : tunables    0    0    0 : slabdata     53     53      0\n--------------------------------------------------------------------------------\n\n</code></p><p></p><h4>PageTables</h4><p></p><p><code lang=\"shell\">echo `grep PageTables /proc/meminfo | awk '{print $2}'`\n</code></p><p></p><p>struct page是系统boot的时候就会根据内存大小算出来分配出去的，18内核是1.56%左右，32内核由于cgroup的原因会在2.3%</p><p></p><h2>单进程内存使用详情</h2><p></p><p><code lang=\"shell\">cat /proc/PID/status\n------------------------------------------------------------------------------\nName:   mysqld\nUmask:  0026\nState:  S (sleeping)\nTgid:   6218\nNgid:   0\nPid:    6218\nPPid:   6201\nTracerPid:     0\nUid:    999    999      999     999\nGid:    999    999      999     999\nFDSize: 256\nGroups:  \nNStgid: 6218   1\nNSpid:  6218   1\nNSpgid: 6218   1\nNSsid:  6218   1\nVmPeak:  1784400 kB\nVmSize:  1740884 kB\nVmLck:         0 kB\nVmPin:         0 kB\nVmHWM:    418632 kB\nVmRSS:    404556 kB\nRssAnon:         404556 kB\nRssFile:              0 kB\nRssShmem:             0 kB\nVmData:   806552 kB\nVmStk:       132 kB\nVmExe:     31092 kB\nVmLib:         0 kB\nVmPTE:      1168 kB\nVmSwap:        0 kB\n------------------------------------------------------------------------------\n</code></p><p></p><h2>进程直接内存的使用</h2><p></p><p><code lang=\"shell\">#pmap命令可以查看进程的内存映射，包括堆外内存的使用量\npmap -x PID\n----------------------------------------------------------------\n00000000f0000000  267776  155072  155072 rw---   [ anon ]\n0000000100580000 1042944       0       0 -----   [ anon ]\n000055c0b1b3b000       4       0       0 r-x-- java\n000055c0b1d3b000       4       4       4 r---- java\n000055c0b1d3c000       4       4       4 rw--- java\n000055c0b3499000    1696    1460    1460 rw---   [ anon ]\n00007f4fdeeb9000      12       0       0 -----   [ anon ]\n00007f4fdeebc000    1016      24      24 rw---   [ anon ]\n----------------------------------------------------------------\ncat /proc/PID/smaps\n----------------------------------------------------------------\nSize:             267776 kB\nKernelPageSize:        4 kB\nMMUPageSize:           4 kB\nRss:              155072 kB\nPss:              155072 kB\nShared_Clean:          0 kB\nShared_Dirty:          0 kB\nPrivate_Clean:         0 kB\nPrivate_Dirty:    155072 kB\nReferenced:       155072 kB\nAnonymous:        155072 kB\nLazyFree:              0 kB\nAnonHugePages:    153600 kB\nShmemPmdMapped:        0 kB\nShared_Hugetlb:        0 kB\nPrivate_Hugetlb:       0 kB\nSwap:                  0 kB\nSwapPss:               0 kB\nLocked:                0 kB\nVmFlags: rd wr mr mw me ac sd \n100580000-140000000 ---p 00000000 00:00 0 \n</code></p><p></p><p></p><blockquote>AnonHugePages、Locked、RssAnon等字段的行，它们提供了关于堆外内存的使用量的信息</blockquote><p></p><p></p><h1>不同维度的内存监控数据之间的关系</h1><p></p><p>Committed_AS 和 used 之间的关系</p><p></p><p>Committed_AS 包含了虚拟内存，所以committed_AS的值可能大于 free 命令中的used的值</p><p></p><p>VmRSS 和 RES的关系VmRSS（Virtual Memory Resident Set Size）是指进程在物理内存中实际驻留的内存大小，即进程当前使用的实际物理内存量。RES（Resident Set Size）是指进程当前使用的物理内存量，包括驻留在物理内存中的代码、数据和共享内存等。</p><p></p><p>VmRSS表示当前实际驻留在物理内存中的内存大小，而RES表示进程当前使用的物理内存总量。两者之间的       关系是，VmRSS是RES中的一个组成部分，两者相差不大，基本相同</p><p></p><h1>free中used的内存都去哪儿</h1><p></p><p>实验版本：Linux version 3.10.0-1062.4.1.el7.x86_64首先我们介绍一个工具 nmon (yum install nmon),是一款比较好用的性能分析工具</p><p><img src=\"https://static001.geekbang.org/infoq/06/06d0645c547a8c2c24c4ee8591c46bef.png\" /></p><p>通过该工具我们能看到内核使用的内存及用户态使用的内存USED = use（用户态内存）+ Slab + PageTables我们来做个实验RSS 基本等于VmRSS ，那我们通过top 命令统计出所有的用户进程占用的物理内存</p><p></p><p><code lang=\"shell\">vi rss.sh\n------------------------------------------------------------\n#/bin/bash                                                                                                              \nfor PROC in `ls  /proc/|grep \"^[0-9]\"`\ndo\n  if [ -f /proc/$PROC/statm ]; then\n      TEP=`cat /proc/$PROC/statm | awk '{print ($2)}'`\n      RSS=`expr $RSS + $TEP`\n  fi\ndone\nRSS=`expr $RSS \\* 4`\necho $RSS\"KB\"\n------------------------------------------------------------\nsh RSS.sh\n</code></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fb/fbee65a0b7c0e498b3881f9a25cbaf24.png\" /></p><p></p><p>free命令</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a5/a5d8f5937499155f0b8eee916cfe5b49.png\" /></p><p></p><p>通过slab的占用</p><p></p><p><code lang=\"shell\">echo `cat /proc/slabinfo |awk 'BEGIN{sum=0;}{sum=sum+$3*$4;}END{print sum/1024/1024}'` MB\n</code></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3f/3f9ea27befb9f06f750916ded7623923.png\" /></p><p></p><p>PageTables</p><p></p><p><code lang=\"shell\">echo `grep PageTables /proc/meminfo | awk '{print $2}'` KB\n</code></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4c/4cbb5b51a6115489dc954c3081ef50df.png\" /></p><p></p><p>通过上面的结论，当然数据上可能稍微有一些出入，特别是不同的kernel 版本计算的方法可能存在一些差异，但是我们基本可以确定的是上述 used的计算公式基本成立</p><p></p><p>回到开头的那个问题，小伙伴又送来一张现场的截图，进一步证明了上述的计算公式是成立的</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2b/2be2e54346eb6640bf898a45de3da261.png\" /></p><p></p><p>那为什么slab 占用这么多，可以考虑下是不是可以做下手动回收，服务器上有频繁的用户态到内核态的内存申请或者网络和文件的读取</p><p></p><h1>解决方案</h1><p></p><p>释放缓存</p><p></p><p><code lang=\"shell\">echo 3 &gt; /proc/sys/vm/drop_caches\n</code></p><p></p><p>重启服务器，或者升级内核版本，2.6 版本上存在slab内存泄露的问题</p><p></p><h1>讨论</h1><p></p><p>JVM内存设置参数中中通常有设置xms 和xmx，如果xms=xmx ，那么如果jvm使用的物理内存没达到xms 设置的值，used 中展示的是真实的内存使用值还是xms的值。如果是显示的是真实使用的物理内存的值，那么 xms 设置还有什么意义。怎么保证jvm在需要申请内存的时候有不少于xms的内存能够被申请到</p><p></p><p>如果大家感兴趣在下期分享</p><p></p>",
    "publish_time": "2023-09-18 07:26:15",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "中秋时节赏明月，五子棋戏月饼趣 — Flutter中秋限定版五子棋",
    "url": "https://www.infoq.cn/article/6c46c37523eac8018a058b8e7",
    "summary": "<p></p><p><img src=\"https://static001.geekbang.org/infoq/c5/c5cd3291f5055a07cd825c78c143caf4.jpeg\" /></p><p></p><p></p><h3>前言</h3><p></p><p>当中秋时节来临，我们都期待着与亲人朋友共度这个美好的节日。这个时候，除了传统的赏月和品尝美味的月饼，我还有一个特别的建议——尝试一款有趣的Flutter五子棋游戏！这款五子棋游戏以中秋为主题，游戏的棋子也可爱地模仿了月饼和玉兔的形状，让我们在这个特别的节日中，一边享受游戏，一边品味团圆的温馨氛围~</p><p>代码地址：<a href=\"https://github.com/taxze6/flutter_game_collection/tree/main/gomoku\">https://github.com/taxze6/flutter_game_collection/tree/main/gomoku</a>\"</p><p></p><h3>游戏实现</h3><p></p><p></p><h4>布局部分</h4><p></p><p>非游戏主体布局部分</p><p></p><p>游戏引导页的布局非常的简单，通过Column作为主要布局即可，月亮的动画使用自定义的显式动画：AnimatedBuilder+Transform.scale实现即可。该部分内容较为简单，就不贴代码了~</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/55/55f3facddb856c5a0f7ce722668e95de.png\" /></p><p></p><p>游戏主体界面布局</p><p></p><p>作为五子棋这样的棋类游戏，棋盘一般都使用GridView.builder来进行构建。我们构建一个15*15的棋盘，格子的总数是225，通过取整和取模来取出每个格子对应的x和y。</p><p></p><p><code lang=\"dart\">GridView.builder(\n  ...\n  itemCount: 225,\n  itemBuilder: (context, index) {\n    int row = index ~/ 15;\n    int col = index % 15;\n    return gameButton(row, col);\n  },\n),\n</code></p><p></p><p>而每个格子（gameButton）则需要加上点击事件用于下棋子：</p><p></p><p><code lang=\"dart\">Widget gameButton(int row, int col) {\n  return GestureDetector(\n    onTap:{\n      ...\n    }\n    child: Container(\n      color: Colors.blue,\n      child: Center(\n        child: gamePiece(row, col),\n      ),\n    ),\n  );\n}\n</code></p><p></p><p>而通过gamePiece的坐标点，我们可以从棋盘的数据中判断当前坐标是什么类型，然后展示对应的图标（月饼和玉兔）。</p><p></p><p><code lang=\"dart\">gamePiece(int row, int col) {\n  if (boardState[row][col] == GameState.Black)\n    return Dot(Colors.black);\n  else if (boardState[row][col] == GameState.White)\n    return Dot(Colors.white);\n  else\n    return null;\n}\n</code></p><p></p><h4>逻辑部分</h4><p></p><p>因篇幅原因，只讲解与游戏核心相关的逻辑，其他可查看源码。</p><p></p><p>第一步 — 定义每个棋子的状态</p><p></p><p><code lang=\"dart\">enum GameState {\n  Blank,\n  Black,\n  White,\n}\n</code></p><p></p><p>第二步 — 定义整个棋盘的数据，通过二维数组</p><p></p><p><code lang=\"dart\">var boardState = List&gt;.generate(\n  15,\n  (i) =&gt; List.generate(\n    15,\n    (j) =&gt; GameState.Blank,\n  ),\n);\n</code></p><p></p><p>第三步 — 检查获胜条件</p><p></p><p>每下一颗子触发一次。</p><p></p><p><code lang=\"dart\">// 检查游戏胜利条件\nvoid checkWinningCondition(int row, int col, GameState gameState) {\n  // 如果移动次数小于5，不可能有获胜者，直接返回\n  if (_moveCount &lt; 5) {\n    return;\n  }\n\n  // 检查当前位置是否包含当前玩家的标记\n  if (boardState[row][col] == gameState) {\n    // 检查从底部左侧到顶部右侧的对角线\n    if (countConsecutiveStones(row, col, 1, -1) +\n        countConsecutiveStones(row, col, -1, 1) &gt;=\n        4) {\n      setWinner(gameState); // 设置获胜者\n      return;\n    }\n    // 检查从顶部左侧到底部右侧的对角线\n    if (countConsecutiveStones(row, col, -1, -1) +\n        countConsecutiveStones(row, col, 1, 1) &gt;=\n        4) {\n      setWinner(gameState); // 设置获胜者\n      return;\n    }\n    // 检查水平方向\n    if (countConsecutiveStones(row, col, 0, 1) +\n        countConsecutiveStones(row, col, 0, -1) &gt;=\n        4) {\n      setWinner(gameState); // 设置获胜者\n      return;\n    }\n    // 检查垂直方向\n    if (countConsecutiveStones(row, col, 1, 0) +\n        countConsecutiveStones(row, col, -1, 0) &gt;=\n        4) {\n      setWinner(gameState); // 设置获胜者\n      return;\n    }\n  }\n// 如果移动次数达到225，表示平局\n    if (_moveCount == 225) {\n      print('平局');\n      setWinner(GameState.Blank); // 设置平局\n      return;\n    }\n  }\n</code></p><p></p><p>最核心的检测部分：</p><p></p><p><code lang=\"dart\">// 计算在给定位置开始，特定方向上连续相同棋子类型的数量\nint countConsecutiveStones(int row, int col, int rowIncrement, int colIncrement) {\n  // 初始化一个计数器\n  int count = 0;\n  // 获取起始位置的棋子类型\n  GameState index = boardState[row][col];\n\n  // 遍历最多四个相邻格子，以查找连续相同的棋子类型\n  for (int i = 1; i &lt;= 4; i++) {\n    // 检查下一个要检查的格子是否在游戏棋盘的有效范围内\n    if (inBounds(row + (rowIncrement * i)) &amp;&amp; inBounds(col + (colIncrement * i))) {\n      // 检查下一个格子上的棋子类型是否与起始位置上的棋子类型相同\n      if (boardState[row + (rowIncrement * i)][col + (colIncrement * i)] == index) {\n        // 如果相同，增加计数\n        count++;\n      } else {\n        // 如果不同，中断循环，因为我们只关心连续相同棋子类型的数量\n        break;\n      }\n    }\n  }\n  // 返回在指定方向上连续相同棋子类型的数量\n  return count;\n}\n\n // 检查索引是否在有效范围内\nbool inBounds(int index) {\n    return index &gt;= 0 &amp;&amp; index &lt; boardState.length;\n}\n</code></p><p></p><p>这样，一个基本的双人对战五子棋就实现啦~</p>",
    "publish_time": "2023-09-18 09:39:03",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "把住金融“命脉”，智能技术如何在证券风控场景实现落地？",
    "url": "https://www.infoq.cn/article/ixcNvwClOzTSal48vR6k",
    "summary": "<p>风控作为金融业务的“命脉”，被视为智能化技术落地的重要落脚点。</p><p></p><p>过去，传统风控模式受限于对人工的依赖，风险识别的响应速度和风险预测的精准度存在一定局限性。而随着人工智能、机器学习、大数据等技术的日益成熟，如今，越来越多的金融机构正在通过智能风控手段，实现自动化和智能化风险识别和风控决策。</p><p></p><p>一方面，它可以实时处理大规模数据并迅速作出决策，从而提高风险识别和应对速度；另一方面，它还能对历史数据和模型预测未来风险，提前采取措施进行预防。</p><p></p><p>在 InfoQ《超级连麦. 数智大脑》直播中，华盛证券技术 VP 黄曙光从华盛证券的经验出发，介绍了券商的智能⻛控实践场景，智能⻛控在不同场景的落地挑战和解法 ，以及真正发挥智能⻛控价值的路径和⽅法。</p><p></p><p>以下是分享全文（经 InfoQ 进行不改变原意的编辑整理）（<a href=\"https://www.infoq.cn/video/k0QUqSaEI4Hxbb4V94hZ\">点击链接</a>\"可查看完整直播回放）</p><p></p><h3>智能⻛控与传统⻛控的本质区别</h3><p></p><p></p><p>智能风控更多地基于人工智能和大数据技术，来实现风险的识别、评估和控制。它的目标是通过自动化手段，识别、评估和应对风险，但实际上其背后的目的是提高效率和准确性，从而降低金融行业交易和业务活动的风险，以确保机构和客户的安全，同时满足合规要求。</p><p></p><p>因此，我认为智能风控与传统风控之间的主要区别在于其目标、采用的技术方案以及技术上的差异，这导致了它在效果和成效方面存在着一定的差异。其中，准确率和效率是两个重要的方面。</p><p></p><p>在传统风控中，我们主要采用人工分析和规则，依赖专业的风险管理团队进行决策，强调人的参与。然而，智能风控则更加依赖机器，运用人工智能和机器学习等技术来自动学习和优化模型，以实现自动化的决策。从这方面来看，智能风控的核心价值在于辅助决策。</p><p></p><p>在响应速度方面，人的反应速度显然较快，但也导致了高成本和较长的响应时间。相比之下，智能风控则以机器为基础。举个例子，在风控的事前预测中，差异明显。如果我们依赖人工方法，券商领域可能会面临挑战，因为在事前风控中，追求速度极快的风险预测在传统风控中较为困难。相反，在智能风控中，我们可以通过技术手段实现适度和精准的风险处理。因此，风控是金融行业最基本的核心事务之一。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/57/572912d4ba312494e0077c0f09a6a257.png\" /></p><p></p><h3>券商的智能⻛控实践分享</h3><p></p><p></p><p>接下来与大家分享我们公司在自动风控方面的实践和经验。</p><p><img src=\"https://static001.geekbang.org/infoq/42/4261cd411d176e4c52f549a235d64aa7.png\" /></p><p>首先，从券商领域的风控出发，在用户的整个交易链条中，涵盖了营销链路风险、交易前风险、交易中风险以及交易后风险等几个层面。这些风险类别包括超额风险、信誉风险以及市场风险等，如何在各个场景中处理风险是关键。</p><p></p><p>先看营销风险控制。这里要特别注意对客户基本注册信息时的风险识别，因为我们在进行营销推广时投入了大量资源，但在转化需要对客户进行 KYC 身份认证，通过大数据技术来识别用户是否符合监管要求，以保障交易过程中不同品种和品类的合规要求。这在金融领域是一个基础要求。</p><p></p><p>此外，交易风险可以分为事前、事中和事后。</p><p></p><p>在事前风险方面，我们分析用户下订单前的规则是否满足交易所和监管的要求，并判断用户是否有足够的购买力完成交易。这涉及信用风险的评估，需要判断用户是否有足够的资本进行交易。尤其对于融资类用户，我们分析其是否存在亏损风险，帮助用户及时控制风险。</p><p></p><p>在交易事中，我们通过自动化手段帮助用户快速做出决策，分析交易风险。</p><p></p><p>交易事后，我们关注保证金设置、股票集中度风险等，以确保交易的合规和稳定。我们致力于开发策略，使持仓保持稳定，避免高股票集中度带来的风险。</p><p></p><p>另一个重要的风险类别是市场风险，其中包括操作风险、信用风险和市场风险。我们需要根据市场行情和数据来评估这些风险。市场风险有时可能并非针对特定用户，而是起到提示作用，向用户发出风险提示，帮助他们了解市场风险，减少资金损失。这有助于增加用户对我们平台的信任度。</p><p></p><p>此外，舆情风险也是一个重要方面。我们通过自然语言处理和情感分析等技术，监控社交媒体和公开信息，以判断股票的热度和市场用户的情绪。这有助于我们了解市场走势，帮助用户避免潜在的风险，同时也提供了更好的市场判断依据。</p><p></p><h3>智能⻛控在券商场景的落地挑战和解决方案</h3><p></p><p></p><p>当然，智能风控的落地过程中存在一系列挑战。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8b/8bce1d55a9e489bde2973823804dac1d.png\" /></p><p></p><p>如前所述，智能风控的核心依赖于大数据和人工智能技术，其中人工智能的核心是确定策略和构建适当的模型。因此，智能风控落地的第一个关键挑战是数据隐私和安全的问题。金融数据涉及用户隐私，因此必须严格控制数据的合法使用和防止泄露和滥用，以满足合规要求。</p><p></p><p>第二，互联网券商的数据来源广泛，这就对数据的准确性和完整性，以及券商对数据的加工整合能力提出了更高的要求。数据的准确性，将直接影响智能风控分析决策的准确性。</p><p></p><p>第三个挑战来自于市场环境，尤其在券商行业，交易的实时性和复杂性都非常高，智能风控需要不断适应市场情况和交易模式，必须具备灵活性以应对各种情况，包括突发事件如黑天鹅和灰犀牛。</p><p></p><p>第四，技术升级带来的挑战。智能风控涉及到大量的数据存储和实时处理，这需要大量的成本和技术投入。这意味着，智能风控的实施会受到企业愿意承担的成本和技术人员素质的限制。成本方面，企业需要考虑投入大量资源来支持数据存储和处理的需求。同时，技术人员需要具备深入理解业务属性、政策要求和交易系统的复杂性的能力，这对人员素质提出了较高的要求。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/49/49686eaa210f63f852fde22ce0ff3de1.png\" /></p><p></p><p>对于这些问题，有哪些解决方案呢。从数据隐私和安全角度来看，特别是对于海外业务，我们不可避免地需要遵循 GDPR 的要求。因此，在数据存储、访问、流转和应用等方面，我们必须严格遵守 GDPR 的安全措施，确立明确的规范制度。在数据访问和应用过程中，必须明确使用范围和目的，以确保数据的安全性和合规性。这一点在智能风控领域以及其他数据应用场景中都具有重要意义。</p><p></p><p>在数据质量方面，我们需要更多地进行数据清洗和二次校验，对数据集进行调校和校准，以确保数据的准确性。通过数据质量的回溯和清洗，可以降低不准确数据带来的影响。</p><p></p><p>针对市场环境的不确定性，我们需要构建多维度的智能风控模型，兼顾历史积累和未来预测，以适应不同的市场情况和风险。</p><p></p><p>此外，针对技术升级，我们需要与公司管理层进行充分沟通。风控作为金融公司的基石，本身具有业务价值。因此，公司在风控方面的投入应该是有倾斜度的。同时，在培养风控团队方面，我们应当从大数据和算法两个角度出发，建立一个专业的智能风控团队。</p><p></p><h3>真正发挥智能⻛控价值的路径和⽅法</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/7a/7a58b93632c22c455800fb99fc23f913.png\" /></p><p></p><p>智能风控价值的发挥，核心在于如何通过智能风控帮助客户降低风险。首先，我们可以在交易之前辅助用户进行合理的资产配置和风险评估，了解用户的风险承受能力，对其当前持仓进行风险评级；同时，可以关注用户的投资偏好和行为，以提供有针对性的投资建议，从而降低投资风险。在这一过程中，用户画像和分析是关键，有助于区分专业投资者、一般投资者，以及偏好波动性或抗风险性的投资者。</p><p></p><p>另外，我们也应该关注市场的变化，进行舆情监控和预警。通过多渠道获取数据，分析股票热度和市场倾向，及早发现可能影响市场情绪和投资的信息，以便做出快速应对。交易事中阶段，我们有一系列手段可以应用。例如，可以防止用户进行自交易，以应对洗钱和欺诈风险。通过智能风控技术，可以判断每笔交易是否涉及到此类风险，并阻止不当交易行为，确保金融系统的合规性。此外，对于量化交易，我们可以为用户提供更多投资方式，不限于简单下单。通过量化策略优化，降低投资组合波动性，提高收益率，进一步拓展我们的业务范围。</p><p></p><p>总的来说，智能风控的路径和方法是多维度的，涵盖了事前、事中和事后的风险管理。通过合理的资产配置、风险评估、舆情监控、反洗钱和反欺诈防范和量化交易优化等方法，我们可以充分发挥智能风控的作用，为客户降低风险，提升投资体验。</p><p></p><p>在这个过程中，技术底层也需要做哪一些升级和优化。比如，在大数据方面，需要升级整个大数据平台，从之前的简单离线数据仓库建设，转向更实时、更复杂的数据平台，例如 Lambda 架构等。</p><p>再比如，在 AI 层面，有几个关键点需要关注。首先是将策略与代码分离，这需要进行一些分层升级。其次是对模型进行微调，尤其是对于风控场景，可能需要进行一系列的模型训练。</p><p></p><h4>互动福利</h4><p></p><p>点击链接便可下载本次演讲的 PPT：<a href=\"https://www.infoq.cn/minibook/hZZVM2NUNYg0Gm96pUzL\">https://www.infoq.cn/minibook/hZZVM2NUNYg0Gm96pUzL</a>\"</p><p></p><h4>嘉宾介绍</h4><p></p><p>黄曙光，华盛证券技术 VP，TGO鲲鹏会深圳学员。负责带领华盛通科技术中心支持业务的快速增长，同时致力金融科技产品的创新。拥有近 20 年软件开发及管理经验，曾就职于阿里、云途时代、工商银行等国内外大型知名互联网和金融公司。</p><p></p><h4>活动推荐</h4><p></p><p>首届<a href=\"https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">FCon全球金融科技大会</a>\"将于 11 月 19-20 日在上海举办。大会将围绕金融领域数字化转型挑战探索、DevOps 在金融企业落地实践、金融行业大模型应用、创新的金融科技应用、金融实时数据平台建设之路、金融安全风险管控、数据要素流通与数据合规等 10+专题进行交流。</p><p></p><p>目前大会邀请了汇丰科技中国区的代理总经理马国栋、度小满金融数据智能部总经理杨青先、蚂蚁集团副总裁 &amp; 首席技术安全官韦韬博士、恒生聚源总经理吴震操担任大会联席主席。更多嘉宾仍在邀请中......</p><p></p><p>我们诚挚地邀请您加入我们，共同探索金融科技的未来，<a href=\"https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">点击链接</a>\"即可查看全部演讲专题。</p><p></p><p>目前 <a href=\"https://fcon.infoq.cn/2023/shanghai/apply?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">5 折 优惠购票</a>\"，仅限前 100 人，咨询购票可联系：17310043226（微信同手机号）。</p>",
    "publish_time": "2023-09-18 13:05:05",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "所有的产品都值得用 AI 重做一遍 | 笔记侠AI峰会精编",
    "url": "https://www.infoq.cn/article/wAqsQACUBHvmv0WO4l46",
    "summary": "<p></p><blockquote>本文经授权转载自公众号：Notesman，原文链接：https://mp.weixin.qq.com/s/nNiWhzBdI0-ikFO1nPhr3w</blockquote><p></p><p></p><p></p><h2>商业思维</h2><p></p><p></p><p>笔记君说：</p><p></p><p>9月16日，笔记侠在杭州举办了第二届“AI新视野，增长新势能”新商业大会。</p><p></p><p>此次大会，我们邀请了出门问问创始人兼CEO李志飞，百姓AI创始人兼CEO 王建硕，小冰解决方案总架构师董志盛，影刀RPA 创始人&amp;CEO十布，笔记侠创始人柯洲，大任智库创始人、江苏省数字经济联合会副会长卜安洵，以及出发吧红人星球创始人彭爽，AI山脉创始人易涛，Collov家居GPT中国区负责人六六叔，面壁科技创始人周子杭等众多一线企业家、创业者共同参与。</p><p></p><p>会议上，各位一线企业家、创业者以“AI产业的应用”为主旨，分享了AI产业端的成熟经验，帮助众多创业者更快在应用层找到匹配的用户真实需求，实现业务增长。</p><p></p><p>下面，笔记侠整理此次会议的精彩内容，以飨读者。</p><p></p><p></p><h2>李志飞：大模型的下半场：Agent、多模态、通用机器人</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1b/1bfa6142e68d97722b6b0e9459f9ba16.png\" /></p><p></p><p>李志飞，出门问问创始人兼CEO</p><p></p><p>不管是 CEO，还是产品经理，都觉得大模型要颠覆自己公司。于是，共识极速达成，全球开卷。</p><p></p><p>我先来分享几个共识：</p><p></p><p>第一，超大模型（万亿）与普通大模型（数百亿）各有使命，超大模型探索天花板，普通大模型承载落地。</p><p></p><p>第二，开源与闭源。有闭源，就必然有开源。性能会竞相追赶，不存在闭源一直碾压开源的可能。</p><p></p><p>第三，没有垂直行业大模型，但可以有垂直工种大模型。要想清楚你的大模型是代替谁？</p><p></p><p>同时，我认为算力是一种消耗品，本身不构成壁垒。不要头脑发热就自建算力中心，长期运营很难超越云巨头。</p><p></p><p>真正的壁垒来自数据。但大家都容易获取的数据不是壁垒，用户在自己产品中交互沉淀的数据才是壁垒。</p><p></p><p>ChatGPT带来了通用人工智能的可能性，但能否革新各行各业，取决于Agent和多模态靠不靠谱。</p><p></p><p>Agent的输入输出都依赖于多模态，没有多模态，就没有Agent。</p><p></p><p>最后，创业公司要问自己一个灵魂的问题，为什么要拥有自己的大模型？如果你找不到理由，你做大模型就是在浪费钱。</p><p></p><p></p><h2>王建硕：大模型浪潮下，必将繁荣的应用层</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/82/825d2aa86ac6ae9e302925b95592bc4a.png\" /></p><p>王建硕，百姓AI创始人兼CEO</p><p></p><p>在 AI 带来巨大的生产力提升的时候，世界上会有两批一样重要的人。</p><p></p><p>一类是热血的创业者，冲向星辰大海，帮我们继续拓展人类能力的边界；另一类，是把我们现在已经拥有的 AI 能力做好普及工作，让大多数人都可以学会使用。两件事情，是同等重要的事情。</p><p></p><p>过去二十几年里，我完整经历了整个互联网的周期。</p><p></p><p>在 1994 年，有一场叫世纪商战——浏览器之争。</p><p></p><p>当时，微软组织了2000 人的团队开发Internet Explorer浏览器，最终取代了网景公司的Netscape Navigator主导地位。这在微软历史上，是非常辉煌的一件事情。</p><p></p><p>但是，我们如果从历史的角度来看，微软虽然赢得了浏览器之争的最终胜利，但却错过了整个互联网，因为以微软当时的资源，它简直可以干任何事情，但是没有选择做。</p><p></p><p>所以说，浏览器开创了商业互联网应用的时代，却不是互联网时代的全部。</p><p></p><p>这一次的AI浪潮下，我认为大语言模型之争也不是战争的全部。基于大模型技术基础的应用，也必将是一个非常重要的战场。</p><p></p><p>也就是说，大语言模型和用户之间的中间层大有可为。</p><p></p><p>我给大家一个提醒，虽然1998年就可以看到互联网的未来，但我们用了20年的时间才实现它。</p><p></p><p>同样，大模型也是如此，大模型的能力边界已经展现，但需要脚踏实地匹配大语言模型的能力和需求。</p><p></p><p>所以，大家也不要太着急，未来20年的路需要20年走，而不是两年走完。</p><p></p><p>最后，跟大家分享一下我们百姓 AI 正在做的产品 - Chato，可以基于企业的私有知识库定制专属机器人，同时，我们为企业提供 AI 训练师服务。</p><p></p><p>即使是不懂AI，没有技术能力的企业，只需要通过Chato 进行简单的数据“喂养”，就能获得一个专属的「数字员工」。</p><p></p><p>Chato 在IP数字分身，私域运营，内部知识库等场景下，助力企业解决行政、会务、客服等重复性高，人力成本支出大等问题。</p><p></p><p></p><h2>董志盛：数字人的价值应用</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/ae/ae52b0998e101af04f398c36b376ab25.png\" /></p><p>董志盛，小冰解决方案总架构师</p><p></p><p>人机交互的新的里程碑，从图形界面到搜索，再到推荐，又到如今的对话。</p><p></p><p>每一次人机交互技术的重大升级，都带来巨大的商业机会。</p><p></p><p>第一阶段：DOS系统：指令交互，文字呈现第二阶段：Window系统：键鼠交互，图文呈现第三阶段：移动互联：触控、语音交互，多样化呈现第四阶段：新一代交互技术：人“人”多模态交互</p><p></p><p>新一代人机交互，对虚拟数字人的核心诉求是，让机器更像人，具体要做到这四点：像人一样真实自然、像人一样富有知识和情感、像人一样参差多态、像人一样富有创造力。</p><p></p><p>虚拟数字员工的定义，有三点：</p><p></p><p>1.虚拟数字人在企业端的应用，承担特定工作岗位的角色和职能；</p><p></p><p>2.是世界未来的劳动力，AI基于人类职业镜像复制，创造超越人类劳动力的供应；</p><p></p><p>3.是人类从对资源的挖掘，到对数据的挖掘再到对知识和能力的挖掘而带来的劳动力升级必然选项。</p><p></p><p>数字员工的应用场景，主要有这5个：企业协同与业务流、AI数字专家、品牌IP专属数字员工、名人IP专属分身、客服/导购/电商直播</p><p></p><p>数字员工的出现，对未来有哪些改变，我认为有三点：</p><p></p><p>1.数字员工的出现不是替代人，是让技术服务于人类，让人类的生活变得更美好。</p><p></p><p>2.不是人类岗位的压缩，而是劳动力的解放，让人类有更多的自由和可能，新的岗位和创新也将应运而生。</p><p>&nbsp;</p><p>3.拥抱变化，人机协同，用技术的力量挖掘出人类更大的可能性。</p><p></p><p></p><h2>AI圆桌论坛：实践，是检验大模型的唯一标准</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fe/fe1d345e60d3479b6c912b2e4688583e.png\" /></p><p></p><p></p><p>出发吧红人星球创始人彭爽：在这次的AI创业热潮当中，会涌现非常多的优秀创业者和企业家们，他们跟以往的创业者和企业家有什么不一样？</p><p></p><p>AI山脉创始人易涛：这一波的 AI 应用浪潮下，和移动互联网时代的创业浪潮可能不一样的地方在于：它第一天就要找到自己的商业模式，找到自己的市场合作伙伴，它可能不高频，但它一定能为用户产生价值。</p><p></p><p>出发吧红人星球创始人彭爽：在 AI 实践当中，对于垂类行业，怎么做好实践应用？</p><p></p><p>Collov家居GPT 中国区负责人六六叔：在应用领域，我们一定要学会聚焦。在家居设计领域，我们通过AI工具，在三个月里产出的设计方案总和，比国内前100家设计公司相加还多。</p><p></p><p>出发吧红人星球创始人彭爽：超级IP怎么结合AI玩转自媒体、短视频和直播行业？</p><p></p><p>面壁科技创始人周子杭：在AI时代，普通创业者如何拿到结果？市面上的AI工具，还是停留在降本增效，你会做，别人也会做，最后又会陷入内卷。所以，我觉得要多用AI的脑，而不是用AI的手。</p><p></p><p>出发吧红人星球创始人彭爽：用好AI，还能帮我们做好组织经营，以我为例，我在公司只抓两个核心：一个是效率，一个是人才密度提升。通过AI的实践，我们有效降低了管理的成本，提升了人才密度。</p><p></p><p>对于AI来说，除了算力和算法，最重要的是数据。那么，AI行业还会有哪些机会？</p><p></p><p>大任智库创始人、江苏省数字经济联合会副会长卜安洵：智能化是数字科技的最新的一次浪潮，科技创新，第一波影响的是生产方式，生产方式领域就会发生新的机会，第二波影响的是组织的运行方式，以及消费方式，这其中也会产生一波新的机会。</p><p></p><p></p><h2>十布：我们创造了工具，工具反过来塑造了我们</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/76/763bfaa2490b11b75156c2aaec1857c0.png\" /></p><p></p><p>十布，影刀RPA 创始人&amp;CEO</p><p></p><p>大量的工作都是有逻辑规则的，非主观决策的工作，但是人是有天性的，人不能像机器一样工作，这就是为什么有了 RPA 可以将这些工作从将这些员工，从枯燥的工作中脱离开来。</p><p></p><p>我对 RPA 的理解，它是在机器人领域的延伸，原来我们对机器人的理解是在工厂里面看到的机械手臂，但机械手臂把一些蓝领的工作给释放掉。</p><p></p><p>那同样，在今天的办公室的很多白领干的也是有逻辑规则的工作。</p><p></p><p>那RPA 可以把白领的工作给释放掉，让人不需要像机器一样工作，所以 RPA 就是一个叫软件的机器人。</p><p></p><p>比如它可以模拟鼠标、键盘，把任何有逻辑规则的工作替代。</p><p></p><p>比如财务做对账，天猫的运营做上下架，财务客服做退款，这些都是有逻辑规则的，RPA 可以把它自动化。</p><p></p><p>除此之外，RPA不仅仅是“工具替人”，更是组织能力的提升。</p><p></p><p>RPA可以把一些极端的岗位释放掉，意味着企业可以有更多的钱去招更好的人，提升企业人才密度。好的人才密度可以提升组织氛围，好的组织氛围可以提升组织效率。</p><p></p><p></p><h2>柯洲：AI，结构化调整的应用红利</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b7/b76e9705aee7921108deba56e7434196.png\" /></p><p></p><p>柯洲，笔记侠创始人</p><p></p><p>当下创业的基本事实是：中国的创业时代正式进入了整合期。</p><p></p><p>在全世界，我们很少有机会看到，从40后到90、00后，几乎横跨时间段的六批人，在同一个战场里打拼。</p><p></p><p>这也导致今天有1.7亿个市场主体，其中个体工商户1.14亿个体工商户，做生意的人太多了。但我国总人数只有14亿，在这样的结构下，生意当然不好做。</p><p></p><p>当以移动互联网为代表的技术红利进入尾声，当经济开始准备切换到到以数字经济为核心特征的新周期，一场痛苦的换轨期，一段痛苦的转型升级期，直接摆在每一个行业、企业和个人面前。</p><p></p><p>所有企业，正在经受市场的残酷洗礼，在充满不确定性的巨变时代，在红利消失的时代，所有人都面临各种考验。</p><p></p><p>2022年底，ChatGPT横空出世。</p><p></p><p>微软 CEO 萨提亚说：“所有的产品都值得用 AI 重做一遍。”</p><p></p><p>但这个“重做一遍”不是说推倒重来，而是AI确实可以给业务的效率和效果带来很大的提升。效率是成本，效果是质量，这二者带来的变化，对企业来说就是降本增效。</p><p></p><p>然而，大模型从诞生起，就属于高端创业者。</p><p></p><p>对于中小企业、初创公司来说，考虑最多的是如何将AI切入应用场景，为用户解决问题。</p><p></p><p>未来，很可能是人负责那1%的创意，AI负责那99%的汗水。</p><p></p><p>所以，未来主要有两个方向的变化：一个是，未来一个非常有想法的人，自己就可以开一家公司，员工大部分都是AI员工；少部分的人员需要学习摸索怎么和AI员工，一起合作产生商业上的价值，社会会越来越扁平。</p><p></p><p>另外一个可能性，是以数据为中心的AI，很容易产生数据飞轮：拥有一个很好的场景，然后积攒足够多的数据，有了足够多的数据后，通过AI让这个企业变得更好，从而有更多的用户进来，产生更多的数据。</p><p></p><p>未来，掌握足够多数据的公司，会掌握足够多的生产资料，能够产生足够强的壁垒。</p><p></p><p>这一波AI会彻底改变每一个行业。所以从这些方面看，第一，未来5到10年，行业会发生巨大变化，这是非常确定性的。</p><p></p><p>对于创业者来说，我认为要把探索AI天花板和AI落地分开。</p><p></p><p>如果是探索天花板，现在最确定的路线是继续暴力大模型；但如果要追求AI落地，目前国内很多企业都推出了基于大模型的文字生成、图片生成类应用。</p><p></p><p>大家可以尽可能去使用这些产品，去体验这些产品擅长什么，不擅长什么，能在工作和生活中给自己带来哪些帮助，从而对它们有更直观的认知。</p><p></p><p>但无论在哪个行业，第一素质就是终身学习。这也是当下每个人安身立命的根本。</p><p></p><p>总体来说，AIGC将会深刻改造每一个行业。只是不同行业，改造速度有早有晚，有快有慢，但在趋势面前，没有人可以掉队。</p><p></p><p>敬畏市场，接受无常。</p><p></p><p>暴风雨酝酿之时，正是海燕飞出的时候，勇敢的人早已按捺不住对暴风雨的渴望与欢乐，他们冲击于阴云和海浪之间，奋力飞翔。</p><p></p><p>我们应该深信：乌云遮不住太阳，只要我们心里充满阳光！</p><p></p><p>让暴风雨来得更猛烈些吧！</p><p></p><p></p><h2>七、有道发布会</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/57/5711f276b4d74f3026b5339b32e713a1.jpeg\" /></p><p></p><p></p><p>笔记侠联合创始人张文龙：从长远来看，我们希望陪伴企业家有道、有法、有术。最终我们有个愿望是什么？是未来世界的500 强里，有笔记侠 AI 增长俱乐部陪伴成长起来的企业，这是我们的梦想。下面有请几位私董会成员，讲一下他们在转型升级私董会有哪些体验和新知？</p><p></p><p>HelloTalk创始人魏立华：笔记侠私董会为创业者提供了有效、互助的社交。真实的有一种朋友之间交流的氛围，大家畅所欲言，没有过分礼貌，有啥说啥。</p><p></p><p>银雁集团COO梁岚：笔记侠私董会是一个非常真实真诚，利他成长的学习的平台。每次参加私董会都让我受益匪浅，促使我对自己企业能够创造什么价值有了更深层次的思考。</p><p></p><p>海创数字科技CEO朱润民：在这个平台上，它不单单只是吃个饭、喝个酒，更好的是平台上的导师，还有我们成员之间能有更多深度的连接。</p><p></p><p>望岳集团董事长刘世军：缔造一个符合今天新商业发展的、更有温度、更有价值的，能实现互生共创的商业组织，是非常有价值和意义的。</p><p></p><p>CEO暨核心团队教练张明晶：笔记侠私董会是我见过特别有潜力的私董会。第一，它迭代速度快；第二，它是一个基于真诚、关怀和挑战的价值观的私董会。</p><p></p><p></p><h2>卜安洵：数字化下半场，透明商业新共识</h2><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/44/445211199b4ceab31e3baddda4b78615.png\" /></p><p></p><p>卜安洵，大任智库创始人、江苏省数字经济联合会副会长</p><p></p><p>今天的来宾都在为：如何正确看待AI,特别是GAI，而如何看，决定了怎样做。</p><p></p><p>首先，我们先对数字化的过程做一个解读：</p><p></p><p>从80年代开始，数字化第一次浪潮，也被称为信息化时代。</p><p></p><p>这个阶段，主要是硬件+软件引发的产业变革：</p><p></p><p>标准化：由文本管理→软件管理流程化：由制度管理→流程管理系统化：由单体最佳→全业一体</p><p></p><p>其中，“软件”发展过程呈现三大趋势：从单一到融合；到闭源到开源；到端化到云化。</p><p></p><p>2000年左右，网络化的开始，当时提出所有事情值得被互联网重做一遍；但今天，互联网的比拼仍在进行时。</p><p></p><p>“网络”发展过程呈现三大趋势：从PC到移动；从人联到物联；从交联到意联；</p><p></p><p>“线上+线下”引发的产业变革：由网络产业化到产业网络化。</p><p></p><p>2017年左右开始，迎来第三次浪潮：智能化。</p><p></p><p>智能化发展过程也呈现三大阶段：专用智能、通用智能、泛在智能。</p><p></p><p>其中，“人类智能+人造智能”引发的产业革命体现在：AI产业化和产业AI化。</p><p></p><p>从2030年左右开始，第四次浪潮将迎来元宇宙化，这将是物理世界和虚拟世界结合，引发的产业革命。</p><p></p><p>目前，人工智能四层应用场景：将会是个体应用、企业应用、行业应用和社会应用。</p><p></p><p>其中，从个体应用来说，会有一个大家都必须掌握的“四新”技能：AI生产文本、AI生成图片、AI生成音乐、AI生成视频。</p><p></p><p>而企业级应用，一般主要考虑四个维度：模型如何选？场景如何定？数据如何采？训练如何做？</p><p></p><p>当企业开始智能化，也意味着“透明商业”从必要，到可能，到可行。</p><p></p><p>而企业透明化的目标包括：向用户透明，向员工透明，向监管透明。当然，透明化企业的核心是透明绩效。</p><p></p><p>我相信：商业，因透明而可信，因可信而美好！</p><p></p><p>*文章为作者独立观点，不代表笔记侠立场。</p>",
    "publish_time": "2023-09-18 13:14:09",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "行知数字中国案例集锦（第二期）",
    "url": "https://www.infoq.cn/article/RMLejt1JJCIhE7GV4s0o",
    "summary": "<p>本手册共包括“数智视野篇”、“数智案例篇”、“数智技术篇”、“数字化人才篇”四个部分，其中，“数智案例篇”又划分为汽车、金融、制造、消费零售四个章节模块，分别从不同行业视角拆解数字化转型的最优路径，希望为企业提供更贴合行业特点的实践与思考。</p><p></p><p>精彩内容抢先预览</p><p></p><p>数智视野篇</p><p></p><p>01｜农牧数字化：IT 要冲到前面去引领，“天花板”才能被打开</p><p></p><p>02｜对话用友王文京，探寻企业数智化的“密钥”</p><p></p><p>03｜中国信通院金融数字化探索 : 用技术搞定中小企业融资、绿色双碳、流量反欺诈等棘手问题</p><p></p><p>数智案例篇</p><p></p><p>第一章：汽车数字化</p><p></p><p>04 | 专访吉利汽车：供应链数字化不能有\"断点\"，业技融合是必经之路</p><p></p><p>05｜新生代车主成消费主力，保时捷如何用数字化保持\"年轻态\"</p><p></p><p>06｜如何造出适用转速超 3 倍的新能源汽车高精度齿轮？双环传动：数字化功不可没</p><p></p><p>07｜一把手挂帅、管理层\"换血\"、警惕大而全汽车零部件企业如何蹬出数字化路径</p><p></p><p>第二章：金融数字化</p><p></p><p>08 ｜平安开放银行模式探索实践：从物联网金融到开放联盟</p><p></p><p>09 ｜银行智能化转型：AI 中台的关键要素与实施策略</p><p></p><p>10 ｜5 年，稳态 + 敏态一气呵成：最早进行前中后台一体化的城商行数字化实践</p><p></p><p>11 ｜一百多应用运维面临挑战，开源“走不通”｜广州银行信用卡中心的自动化运维实践</p><p></p><p>12 ｜探索大模型智能：众安保险基于 AIGC 的应用实践</p><p></p><p>13 ｜从单体架构到微服务化拆分，方正证券如何实现前中后台一体化？</p><p></p><p>第三章：制造数字化</p><p></p><p>14 ｜揭秘“灯塔工厂”的 AI 应用案例和规模化策略</p><p></p><p>15 ｜精益管理做不好？可能是少了数字化这把“尺子”</p><p></p><p>第四章：消费零售数字化</p><p></p><p>16 | IT 贯穿所有业务场景，化解大型快消\"人货场\"的复杂性|宝洁中国数字化实践</p><p></p><p>17 ｜探访海底捞门店数字化：减员不是目的，创造价值才是</p><p></p><p>数智技术篇</p><p></p><p>18 ｜ AIGC 在保险行业有哪些应用落地的可能性？</p><p></p><p>19 ｜“初代”数字孪生巨头，揭示虚拟孪生在产品全生命周期的价值和应用</p><p></p><p>数字化人才篇</p><p></p><p>20 ｜传统管理秩序消失，数字化下的组织和人才如何重塑</p><p></p><p>21 ｜南京钢铁：用精准培养方式“填补”人才缺口</p><p></p><p>22 ｜12 维度能力画像、1+3 认证体系，东亚银行如何搭建数字人才体系</p><p></p><p>23 ｜宁德核电：硬核工业数字化人才培训方法的全面解析</p><p><img src=\"https://static001.geekbang.org/infoq/0e/0ea3ded3764effab1bfcc22633529438.jpeg\" /></p><p>扫/码/下/载</p>",
    "publish_time": "2023-09-18 13:56:50",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "航空产业软件供应链发展大会成功召开",
    "url": "https://www.infoq.cn/article/zCjuXEcBwjEspw2RDEFV",
    "summary": "<p>2023年9月14日，由中国信通院泰尔终端实验室联合中航国际供应链科技有限公司（以下简称“中航供应链”）主办的航空产业软件供应链发展大会在北京成功召开。本次大会深度展示了中国信通院在航空数字化的研究成果，并发布了双方共同打造的“航空工艺设备供应链集成服务平台”。来自中国信通院泰尔终端实验室数字生态发展部、中航供应链设备器材事业部、中国航空制造技术研究院、中国航空综合技术研究所、360、致远互联的各领域专家带来了航空数字化主题分享。本次大会邀请了400余名来自数字化转型、工业制造、民用航空等领域的商界领袖和专家学者，共同聚焦民用航空软件供应链高质量发展。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/24/2438abeff1d3d849534e06d5826d8aea.png\" /></p><p></p><p>中国信通院总工程师魏然出席本次大会并致辞。魏然表示，以大飞机为代表的民用航空产业是具有战略意义的重要产业，对国民经济发展与工业技术创新等方面拉动效应明显。工信部在今年年初的重点工作部署会议上，将“加快大飞机产业化发展”列为了重点工作。今年5月，我国C919客机完成了首次商业飞行，标志着我国民用航空的发展达到了国际先进水平，未来随着C919等项目的生产加速，我国的航空工业发展也将迎来更大的机遇。魏然指出，在软件供应链高质量发展方面，应加强行业经验交流、强化供应链韧性并重视供应链数据安全保护。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d1/d1e89a2ff6c8fc6f0f02694127f1352a.png\" /></p><p></p><p>中国航空工业设备供应商管理委员会副主任陈晨出席本次大会并致辞。陈晨表示，航空制造作为高端复杂装备制造业的代表，是现代工业的典范，是尖端技术发展与集成的引擎，对国民经济发展有巨大的带动作用。数字化转型是航空制造企业转型升级的必经之路。期望实力突出、能力卓越的国内外数字化解决方案的供应商加入中国航空产业链，促进航空产业科技创新发展。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/29/2969134037a5b0aeb9f6f0ccb76a1d61.png\" /></p><p></p><p>中国信通院泰尔终端实验室王景尧博士发表了主题为《民用航空制造数字化建设发展观察》的主题演讲。王景尧表示，数字经济引发了数字浪潮下的产业革命，并推动产业效率跨越式提升。工业数字化在工业领域基于网络信息技术，推动技术进步、组织变革和效率提升。民用航空制造业作为高端工业典型代表也面临着新一代信息技术与传统制造工艺的深度融合所带来的诸多机遇与挑战，中国信通院愿与各方一道深入开展民用航空数字化相关研究，助力民航行业高质量发展。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2c/2ca3ed726e3f49eff87aedbfe9c47f8b.png\" /></p><p></p><p>中航国际供应链科技有限公司设备器材事业部商务总监蔡颖介绍了中国信通院泰尔终端实验室联合中航供应链共同打造的“航空数字化工艺设备供应链集成服务平台”。蔡颖介绍，双方将基于该平台，共同开展航空工艺设备的产品寻源、供应商评价、供需对接、航空制造工艺和技术赋能等相关工作。依托中国信通院在智能制造、工业软件、数字化领域的深入积累为航空工艺设备高质量发展提供有力支撑和坚实保障。中航国际供应链科技有限公司设备器材事业部商务总监蔡颖、中航国际供应链科技有限公司设备器材事业部客户三处处长孙博、中国信通院泰尔终端实验室王景尧博士、吴荻博士在大会现场共同见证了平台发布。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8b/8b6dad272e97047b87c5b5160e90a573.png\" /></p><p></p><p>为深化双方合作，中国信通院泰尔终端实验室副主任巫彤宁、中国航空工业设备供应商管理委员会秘书长，中航供应链设备器材事业部供应商管理处处长葛旭阳在现场签署合作协议。同时，葛旭阳在大会现场宣贯了双方即将在CAEE2023中国航空制造装备博览会上举办的航空数字化建设资源对接会相关事宜。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/20/20a3f6d1dc218620f0059143f653995c.png\" /></p><p></p><p>中国航空制造技术研究院信息中心主任钟佳涛、中国航空综合技术研究所研究员技术总师曹平、360集团数字化协作事业部总经理李方翔、致远互联副总裁李志刚分别从航空数字化转型需求侧及供给侧带来了精彩的主题分享。中国信通院泰尔终端实验室吴荻博士介绍了双方后续工作的下一步计划。吴荻表示，后续中国信通院泰尔终端实验室将联合中航供应链共同开展民用航空制造关键技术和应用场景方面研究，建立民用航空软件服务产品供应链准入的技术要求和评测方法，持续举办航空制造数字化建设资源对接会，共同编制《高质量数字化转型产品及服务全景图》及《航空制造装备产业链图谱 - 工业软件/信息化板块》等工作。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7e/7e5e0089d0ff043cd9772e900ce5c4c2.png\" /></p><p></p><p>大会最后，中航供应链作为航空数字化领域需求侧代表同来自中电信量子,埃瑞泰克斯, 360 ,美的海外工程, 致远互联 ,海克斯康 ,蓝湖MasterGo ,大正工业机器人, ONES等数字化领域优秀供应商代表进行了签约。后续，中国信通院泰尔终端实验室将同中航供应链持续举办航空数字化建设资源对接会，首期对接会将于2023年10月26日在CAEE2023中国航空制造装备博览会上举办，敬请关注。</p>",
    "publish_time": "2023-09-18 14:22:38",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "回归硬件还是坚持上云？硬件厂商和云厂商们在争着帮用户省钱",
    "url": "https://www.infoq.cn/article/UKgsA53rk98FTmZYRHA1",
    "summary": "<p>为了应对收入增长放缓的局面，上市公司 Snap 最近采取措施降低支出，削减了向主要云提供商支付的费用。</p><p>&nbsp;</p><p>Snap 2017年上市时披露了其使用谷歌云和亚马逊网络服务(AWS)运营。公司代表称，Snap已经同意在未来五年向谷歌支付20亿美元购买云服务，每年至少购买4亿美元的服务。该公司还表示，它已承诺在2021年12月之前向AWS支出10亿美元。</p><p>&nbsp;</p><p>但Snap首席财务官Derek Andersen在最近的年度投资者日上表示，该公司一直在努力降低基础设施成本，这是仅次于员工的第二大支出。虽然Andersen没有确切说明Snap现在在其云成本上节省了多少，但他展示的一个关于每日活跃用户基础设施成本的图表显示，成本从两年前的2.78美元下降到现在的2.31美元。</p><p>&nbsp;</p><p></p><h2>“降本增效”，剑指云成本</h2><p></p><p>&nbsp;</p><p><a href=\"https://www.prnewswire.com/news-releases/new-survey-reveals-one-third-of-businesses-are-exceeding-their-cloud-budgets-by-as-much-as-40-percent-301216394.html\">根据可观察性软件供应商 Pepperdata 的调查</a>\"，超过三分之一的企业的云预算超支高达 40%。随着科技行业的公司寻求削减成本，客户已经减少了每年向云提供商支付的巨额费用。</p><p>&nbsp;</p><p>这点也被微软首席执行官Satya Nadella&nbsp;证实。在最近的收益报告电话会议上，Satya表示企业在云上的支出在放缓，在很大程度上是由于企业在优化对云产品的使用以节省成本。</p><p>&nbsp;</p><p>“各种规模的企业都在评估和优化云支出方案，以应对艰难的宏观经济条件。”亚马逊首席财务官 Brian Olsavsky 今年2月在讨论公司最新季度财务数据时表示，这一趋势还将持续。</p><p>&nbsp;</p><p>比如，Twitter是另一家寻求削减云计算支出的公司。知情人士透露，Twitter计划从服务器和云方面着手，每日削减150万-300万美元的相关成本，每年可以省下10亿美元。此前，Twitter内部文件显示，去年每日亏损约达300万美元。</p><p>&nbsp;</p><p>Twitter的云供应商也是谷歌云和亚马逊云服务。在之前的合同中，Twitte每年想谷歌云支付10亿美元，马斯克接手后试图重新谈判<a href=\"https://9to5google.com/2023/03/04/twitter-google-ads-cloud/\">但似乎被谷歌云拒绝了</a>\"。此外，Twitte 还要在未来5.5年内向亚马逊支付 5.1 亿美元，目前 AWS 用于 Twitter Spaces。</p><p>&nbsp;</p><p>除了大型企业，一些中小型企业也在寻求削减云成本的方法。</p><p>&nbsp;</p><p>运营项目管理平台 Basecamp 背后的 37Signals 公司首席技术官、Ruby On Rails 之父 DHH（David Heinemeier Hansson）<a href=\"https://www.infoq.cn/article/0xb7kodt55mk8TB2mcgA\">表示</a>\"，37Signals 在2022 年的云上支出费用超 320 万美元，每月平均 26.67 万美元。为此，该公司的做法更为彻底，其计划把大量服务和依赖项从云端转移到内部硬件上，来大幅削减这笔费用。</p><p>&nbsp;</p><p>“经过深思熟虑、多次基准测试以及对 AMD 新 Zen4 芯片与第 4 代 NVMe 驱动器相结合带来的速度体验，我们几乎准备好向戴尔下达我们的巨额订单。”DHH表示。</p><p>&nbsp;</p><p>这项采购计划大约花费60万美元，并且会均摊在未来5年里，也就是说每年该项成本为12万美元，再加上电源、宽带等其它支出，每年共计84万。 考虑到一些不可预见的费用，<a href=\"https://world.hey.com/dhh/we-stand-to-save-7m-over-five-years-from-our-cloud-exit-53996caa\">DHH估计</a>\"，37Signals 将在五年内节省大约 700 万美元的服务器开支。</p><p>&nbsp;</p><p></p><h2>云厂商：我来帮助你优化</h2><p></p><p>&nbsp;</p><p>需要说明的是，云厂商的增长并非停止，而是增长速度开始放缓：Azure 的同比增长率降至 30% 左右；谷歌云的增长率为32%；亚马逊云科技的同比增长率最低，为 20%，这是它在 2021 年第四季度增长量的一半。&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2a/2af70c06475bf1ab1a529fd6e8db8d4c.jpeg\" /></p><p></p><p>三家云厂商增速，来自：businessinsider.com</p><p>&nbsp;</p><p>在过去几年里，云服务已经成为谷歌、亚马逊和微软等公司的主要收入来源。企业在云厂商的计算、存储、网络和软件上花了太多钱。</p><p>&nbsp;</p><p>举例来看，亚马逊集团醉心于亚马逊云科技带来的利润和提供给公司的免费计算能力，就像IBM曾经醉心于其引以为傲的大型主机平台的高昂价格一样。但如今的亚马逊云科技也陷入了两难：一方面，云厂商间的竞争从未停过；另一方面，为了节省成本，人们渴望回归本地IT运营（通常是在一个托管设施中）。</p><p>&nbsp;</p><p>以前，每当AWS的业务开始放缓时，亚马逊云科技的业务部门就会降价，然后一两个季度后其收入和利润就会恢复增长。但现在，亚马逊云科技不再是唯一的提供商，也不是唯一提供复杂产品的公司，也不是唯一降价的公司。</p><p>&nbsp;</p><p>美国已经使用云计算的大型公司，无论是GCP、Azure还是AWS，还都在从长期和绑定的模式，试图调整为季度、月度更为灵活的付费模式。惠普、戴尔、联想、思科等公司推出的按效用定价的系统，不仅可以取代AWS Outposts，还可以从一开始就阻止其安装。</p><p>&nbsp;</p><p>因此，<a href=\"https://www.nextplatform.com/2021/06/25/the-many-other-high-costs-cloud-users-pay/\">数据中心回流可能是真实存在的</a>\"。大企业很可能获得按效用定价的硬件、软件和服务，并把它们放在地理上分散的多个托管设施中，就像他们曾转向一个或一个以上的主流云提供商（甚至是多个相对较小的云提供商）一样。</p><p>&nbsp;</p><p>但亚马逊云科技等云厂商已经意识到：如果他们不帮助客户控制云计算支出，那客户就会自己来完成这项工作。</p><p>&nbsp;</p><p>像很多公司已经意识到要使用多云技术来避免厂商锁定并提高自己的议价能力。企业可以选择部署在任何主流云上的软件平台，并且可以通过云应用商店快速安装及获取云许可，但只从云上获取尽可能便宜的计算、存储和网络。</p><p>&nbsp;</p><p>这种行为也在影响单个云厂商的收入，而这比仅仅因为担心经济衰退而主动勒紧裤腰带要复杂得多。考虑到像亚马逊云科技等厂商近年享有的高利润率，即使在繁荣时期，企业也会勒紧裤腰带。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/aa/aaff2f896e9b57060a3f3915a378cfff.jpeg\" /></p><p></p><p>2007年亚马逊云科技带来不错的收入以来，营收增长放缓的程度</p><p>&nbsp;</p><p>当然，宏观经济形势也确实带来了影响。企业正在减少分析工作，优先选择运行时间比较短、规模比较小的作业，而不是预先支付时间比较长、金额比较大的合同。</p><p>&nbsp;</p><p>亚马逊首席财务官Brian Olsavsky 在近期表示，“我们看到，从2022年第3季度中期开始，我们的同比增长率放缓，因为为了应对艰难的宏观经济形势，各种规模的企业都在评估优化云支出的方法。和预期的一样，这些优化工作持续到了第4季度。与管理自己的数据中心相比，云计算的主要好处是能够处理较大的需求波动并相对快速地优化成本，特别是在经济存在不确定性的时期。我们的客户正在寻找省钱的方法。为此，我们花了很多时间来帮助他们。”</p><p>&nbsp;</p><p>“我们预计，至少在接下来的几个季度，这些优化工作将继续阻碍AWS的增长。”Olsavsky进一步说道。不过，曾负责亚马逊云科技业务的亚马逊新任首席执行官 Andy Jassy 对云服务业务依然有信心：弹性正是客户喜欢云的原因。“我不认为本地部署会消失，但我真的相信，在未来10到15年里，如果我们能继续提供最好的客户体验，大部分本地部署将会迁到云端。”</p><p>&nbsp;</p><p></p><h2>快速增长的硬件厂商</h2><p></p><p>&nbsp;</p><p>坦率地说，许多工作负载只能在各大厂的云服务之间选择。随着这些工作负载战略重要性和规模的提升，企业就会开始寻找减少账单的方法，回归硬件便是37Signals 等企业选择的方案之一。</p><p>&nbsp;</p><p>另一方面云厂商的产业上游之一也是硬件厂商。当企业绕过云厂商直接找硬件厂商购买资源、云厂商收入下降时，对硬件厂商会产生什么影响呢？我们可以先看一组数据。</p><p>&nbsp;</p><p>根据最新财报，联想的 ISG（基础设施解决方案集团）收入28.6亿美元，同比增长48%；运营利润实现3.1亿人民币，猛增156%。细分业务中，云服务提供商的销售额为17.1亿美元，同比增长2.25倍；面向各种规模企业客户的服务器和存储销售额为11.4亿美元，下降2.3%。</p><p>&nbsp;</p><p>其中，联想服务器成为全球第三大服务器提供商，季度营收同比增长35%，超融合存储、云存储、入门级存储和中端存储也都创造了新的记录，整个存储业务营收实现同比增长345%。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ae/ae3a123104f4da12ede932bfda0415db.jpeg\" /></p><p></p><p>&nbsp;</p><p>同样，戴尔的基础设施解决方案集团(ISG) 也取得了不错的成绩：第四财季营收99亿美元，同比增长7%，实现了连续八个季度的增长。其中，服务器和网络业务营收为49亿美元，同比增长5%；存储业务营收50亿美元，同比增长10%。</p><p>&nbsp;</p><p>国内的浪潮赶上了超大规模企业阿里巴巴、百度和腾讯在云计算领域的这一波扩张，但这些公司也都面临各自的挑战，他们往往都是“先吃饱再消化”。而在被问到有关超大规模企业和云提供商削减资本支出预算的问题时，Skaugen 表示：“广义上讲，总可用支出可能是下降的。不过在很大程度上，联想不会受到这些趋势的影响。”</p><p>&nbsp;</p><p>Skaugen 解释道，“我们刚刚宣布了一项云业务的新纪录。多个季度以来，我一直在谈论我们新提出的 ODM+ 业务模式，我们正在为世界上最大的超大规模企业提供定制设计。这些设计已经发展了几个季度——不仅仅是在服务器领域，我们也在大力扩展到存储领域。因此，尽管市场的总支出可能会下降，但在这些年以及过去的几个季度中，联想完全确定，我们已经赢得了主板、系统和机架的设计工作，因为至少在过去一年多的时间里，我们一直在设计这些产品。”</p><p>&nbsp;</p><p>今年，联想在墨西哥的蒙特雷和匈牙利的布达佩斯开设了工厂，大力推行一个名为NextWave的新型销售团队和营销策略，致力于超大规模企业和云提供商的下一波革新浪潮，并在服务器和存储销售方面获得了巨大的回报。</p><p>&nbsp;</p><p>可以看出，能够利用自己的市场地位在半导体供应链上发挥更大影响力的公司正渐入佳境。Skaugen认为，在接下来的几个季度里，联想的同比增长可能会接近50%。他们会继续推动服务器和存储市场份额的增长，扩大营收。</p><p>&nbsp;</p><p></p><h2>结束语</h2><p></p><p>&nbsp;</p><p>所有关于成本节约和性价比改进的讨论几乎都是在云厂商加速发展与当前经济现实相抵触之际出现的。企业需要降低云成本，云厂商的策略是“打不过就融入”，帮助客户做优化，而这场博弈中，硬件厂商似乎还处于赢家位置。但未来发展如何，我们也拭目以待。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.nextplatform.com/2023/02/21/the-long-patience-of-lenovo-starts-paying-off-in-the-datacenter/\">https://www.nextplatform.com/2023/02/21/the-long-patience-of-lenovo-starts-paying-off-in-the-datacenter/</a>\"</p><p><a href=\"https://www.nextplatform.com/2023/02/06/the-on-premises-empire-strikes-back-at-aws/\">https://www.nextplatform.com/2023/02/06/the-on-premises-empire-strikes-back-at-aws/</a>\"</p><p><a href=\"https://www.businessinsider.com/microsoft-amazon-google-cloud-business-lower-spending-growth-slowed-charts-2023-2\">https://www.businessinsider.com/microsoft-amazon-google-cloud-business-lower-spending-growth-slowed-charts-2023-2</a>\"</p>",
    "publish_time": "2023-09-18 15:11:56",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "耗时一年用户从0增长至1400万，背后仅三名工程师，这家社交巨头背后的技术栈是如何搭建的？",
    "url": "https://www.infoq.cn/article/KhfuGzxqxEBXE2F4jkLU",
    "summary": "<p>Instagram迅猛蹿红无疑是硅谷故事的又一个真实写照，该应用在短短几个月内就获得了惊人的发展势头。这款照片与视频共享社交媒体仅用了软件工程师们八周的时间就开发完成，并于2010年10月正式登陆苹果移动操作系统。在之后的不到两年时间里，Facebook（Meta）以10亿美元现金加股票的形式将Instagram收入囊中。</p><p>&nbsp;</p><p>但跟所有的美好故事一样，Instagram的发展过程也历尽曲折、失败、冲突与逆转，当然也不乏众多偶然因素的意外影响。</p><p>&nbsp;</p><p>值得注意的是，这个曾经估值近千亿美元的Instagram在技术运作上一直遵循着三个指导原则：让事情变得更简单、绝不重新发明轮子、尽可能使用经过验证的可靠技术。</p><p>&nbsp;</p><p>在当今这个各领域巨头们都在过度堆砌豪华技术栈以求建立技术霸权的时代，Instagram的成功也不禁让人思考，是否最终99%的公司都可以使用由三、四个人管理的经典 LAMPish 堆栈？</p><p></p><h2>Instagram发展史</h2><p></p><p>2009年，27岁刚刚从斯坦福大学毕业的Kevin Systrom任职于Nextstop——一家旅行推荐初创公司。Systrom之前曾在谷歌担任过企业开发助理，并在Odeo公司实习（该公司后来发展成了Twitter，也就是如今的X）。</p><p>&nbsp;</p><p>虽然Systrom并没有接受过计算机科学方面的正式训练，但还是凭借着才智和毅力在Nextstop任职时利用业余时间学会了编程。他最终开发出一款名叫Burbn的Web应用原型，其设计灵感来自他个人对威士忌和波本酒的深深喜爱。Burbn应用允许用户签到、发布邀约和分享照片。尽管当时基于位置的签到类应用非常流行，但Burbn的照片共享功能仍在同类市场中显得独树一帜。</p><p>&nbsp;</p><p>2010年3月，关键的转折点不期而至。当时Systrom参加了硅谷初创公司Hunch的一场聚会，并在会上遇见了来自Baseline Ventures 和 Andreessen Horowitz 的两位风险投资家。在向他们展示了Burbn应用的原型之后，大家决定有机会喝杯咖啡再做进一步讨论。首次会面之后，Systrom决定辞掉工作、专心打磨Burbn。短短两周之内，他就从Baseline Ventures 和 Andreessen Horowitz筹集到50万美元的种子资金，用以进一步拓展自己的创业公司。</p><p>&nbsp;</p><p>有了种子资金的加持，Systrom得以组建一支维系业务运转的团队：第一位加入的成员是25岁的Mike Krieger。Krieger同样来自斯坦福大学，此前曾在社交媒体平台Meebo担任工程师兼用户体验设计师，而且两人在校期间就认识对方。</p><p>&nbsp;</p><p>在Krieger加入之后，二人重新评估了Burbn的业务空间，并决定将注意力集中在单一核心之上：分享由移动设备拍摄的照片。他们仔细研究了当时摄影领域的其他领先应用。在他们二人看来，Hipstamatic应用的表现最出色，当时也颇受市场欢迎。其最大亮点就是提供丰富的功能选项，比如照片滤镜。然而，由于该软件缺乏社交媒体分享功能，Systrom和Krieger从Hipstamatic和Facebook等社交平台的夹缝当中看到了巨大潜力。</p><p>&nbsp;</p><p>于是他们退后一步，将Burbn精简成了照片加评论加“点赞”的功能综合体。以此为基础，他们将应用重新命名为Instagram，结合的是Instant（即时）与telegram（电报）两个单词。他们还专注于改善照片共享体验，想要把Instagram打造成一款极简化、尽可能减少用户操作需求的产品。经过八周的应用调整之后，他们带着beta版本给朋友们体验，尝试进行初步性能评估。在解决了软件中的一些错误之后，Instagram首度与全世界用户见面。</p><p>&nbsp;</p><p>2010年10月6日Instagram的iOS版本正式亮相，并在一天之内就吸引到2.5万名用户。在第一周结束时，Instagram的下载量已达10万次。到12月中旬，其用户数量达到100万。必须承认，Instagram的成功有着很强的运气因素，因为就在几个月前（2010年6月）搭载更强摄像头的iPhone 4刚刚惊艳出炉。</p><p>&nbsp;</p><p>随着Instagram用户基础的迅速扩张，更多投资者对这家年轻的公司表现出兴趣。2011年2月，Instagram在A轮融资中筹得700万美元。作为其投资方之一，Benchmark Capital为Instagram开出了2500万美元的市场估值。除了机构投资者之外，Instagram还吸引到社交媒体技术行业众多领先厂商的关注，其中就包括Twitter和Facebook。</p><p>&nbsp;</p><p>尽管新一轮融资让Systrom和Krieger拥有了扩大人员规模的底气，但两位创始人还是决定控制自身体量，将班底继续保持在十几人的水平。</p><p>&nbsp;</p><p>Systrom在Odeo实习时结识了Twitter联合创始人Jack Dorsey。Dorsey也对Instagram表现出深厚的兴趣，并提出出手收购的想法。据报道，Twitter最终提出了价值约5亿平均的股票收购方案，但被Systrom予以回绝。</p><p></p><h2>用户从0增长到1400万，背后仅靠3名工程师支撑</h2><p></p><p>&nbsp;</p><p>从2010年10月到2011年12月，Instagram在短短一年多时间里将用户数量从0扩展至1400万。而这一切的实现，背后仅有3名工程师的参与。</p><p>&nbsp;</p><p>这个惊人目标源自三大基本原则，外加稳定可靠的技术栈，以下是Instagram的指导原则与技术栈构成分析。</p><p>&nbsp;</p><p>一直以来，Instagram的技术运作都遵循着三个指导原则：</p><p>让事情变得更简单。绝不重新发明轮子。尽可能使用经过验证的可靠技术。</p><p></p><h2>简要介绍技术栈</h2><p></p><p>Instagram的早期基础设施运行在AWS之上，使用EC2配合Ubuntu Linux，EC2是亚马逊提供的服务，允许开发人员租用虚拟计算机承载自家工作负载。</p><p>&nbsp;</p><p>为了保证一切尽可能简单，这里用纯粹的工程师思维展开讨论，延着用户会话的生命周期捋顺整个流程：</p><p></p><h3>前端</h3><p></p><p>会话：用户打开Instagram应用。</p><p>&nbsp;</p><p>Instagram最初于2010年发布iOS版应用。由于Swift语言要到2014年才亮相，所以合理的猜测是Instagram是使用Objective-C和UIKit等方案组合编写而成。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fb/fbf8d08d4452f3efcbc896c6cc89eb57.png\" /></p><p></p><h4>负载均衡</h4><p></p><p>会话：在应用开启之后，向后端发送一条获取主提要图像的请求，此请求随后抵达Instagram负载均衡器。</p><p>&nbsp;</p><p>Instagram采用亚马逊的Elastic Load Balancer服务。工程师们租用了3个NGINX实例，并根据其运行情况来决定何时切入和切出。</p><p>&nbsp;</p><p>每条请求会首先抵达负载均衡器，而后再被路由至实际应用服务器。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/30/30f93638c7e87d0b82df8a3b8f6e20cf.png\" /></p><p></p><h3>后端</h3><p></p><p>会话：负载均衡器将请求发送至应用服务器，而应用服务器负责保存正确处理请求所必需的逻辑。</p><p>&nbsp;</p><p>Instagram的应用服务器使用Django、由Python编写，并选择Gunicorn作为其WSGI服务器。</p><p>这里解释一下，WSGI（Web服务器网关接口）负责将请求从Web服务器转发至Web应用程序。</p><p>Instagram使用Fabric同时在多个实例上并行运行命令，从而在几秒钟之内完成代码部署。</p><p>&nbsp;</p><p>这一切共同运行在25台以上的亚马逊High-CPU Extra-Large超大设备之上。由于服务器本身保持无状态，所以在需要处理更多请求时，可以灵活添加更多计算资源。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/9f/9fb62101e884261231c753dc89a49748.png\" /></p><p></p><h4>通用数据存储</h4><p></p><p>会话：应用服务器须识别出请求所需要的主提要数据，这里猜测它需要完成以下流程：</p><p>获取相关图像的最新ID；获取与这些ID相匹配的实际图像；为这些图像获取用户数据。</p><p></p><h4>数据库：Postgres</h4><p></p><p>会话：应用服务器从Postgres处获取相关图像的最新ID。</p><p>&nbsp;</p><p>应用服务器将从PostgreSQL处提取数据，PostgreSQL存储有Instagram的大部分数据，包括用户和照片元数据。</p><p>&nbsp;</p><p>Postgres和Django之间的连接，由Pgbouncer负责汇总成池。</p><p>&nbsp;</p><p>由于收取到的数据量很大（每秒超过25张图像和90个赞），因此Instagram需要对数据进行分片。Instagram依靠代码将数千个“逻辑”分片映射至数个物理分片。</p><p>&nbsp;</p><p>Instagram还面临着另一个有趣挑战，即如何生成可以按时间排序的ID。他们生成的可按时间排序ID如下所示：</p><p>用41位表示时间（以毫秒为单位，可在一条自定义epoch中表达41年间的所有ID）；用13位表示逻辑分片ID；用10位表示自动递增序列，模数为1024。这意味着我们可以每毫秒为每个分片生成1024个ID。</p><p>借助Postgres中的可按时间排序ID，应用服务器能够成功接收到相关图像的最新ID。</p><p></p><h4>图像存储：S3与CloudFront</h4><p></p><p>会话：之后，应用服务器会获取与各图像ID相匹配的实际图像，并通过快速CDN链接为用户提供顺畅的加载体验。</p><p>&nbsp;</p><p>Amazon S3中存储有数以TB的图像。这些图像可通过Amazon CloudFront被快速交付给用户。</p><p></p><h4>缓存：Redis与Memcached</h4><p></p><p>会话：为了从Postgres处获取用户数据，应用服务器（Django）使用Redis将图像ID与用户ID进行匹配。</p><p>&nbsp;</p><p>在Redis的支持下，Instagram能够为约3亿张图像存储建立起指向创建者用户ID的映射，借此引导在获取主提要、活动提要等图像时具体应查询哪个分片。所有Redis都存储在内存内以降低延迟，并将数据分片至多台机器之上。</p><p>&nbsp;</p><p>通过一系列巧妙的哈希处理，Instagram得以在不到5&nbsp;GB空间内存储这3亿个键映射。</p><p>&nbsp;</p><p>由此建立的图像ID与用户ID的键值映射，用于指示具体应查询哪个Postgres分片。</p><p>&nbsp;</p><p>会话：借助Memcached的高效缓存（最近响应均被纳入缓存），从Postgres处获取用户数据的速度很快。</p><p>&nbsp;</p><p>对于常规缓存，Instagram使用Memcached。当时Instagram设置了6个Memcached实例，可以在Django上以相对简单的方式进行分层。</p><p>&nbsp;</p><p>有趣的事实：两年之后的2013年，Facebook发布了一篇具有里程碑意义的<a href=\"https://research.facebook.com/publications/scaling-memcache-at-facebook/\">论文</a>\"，介绍了他们如何扩展Memcached以顺利实现每秒数十亿条请求的处理能力。</p><p>&nbsp;</p><p>会话：用户现在可以看到主页内容，其中展示的就是其所关注用户的最新图像。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/10/1068f4964af13680c99249c6d5157879.png\" /></p><p></p><h4>主副本设置</h4><p></p><p>Postgres和Redis均在主副本设置中运行，并使用Amazon EBS（Elastic Block Store）快照对系统进行频繁备份。</p><p></p><h3>推送通知与异步任务</h3><p></p><p>会话：现在，假设用户关闭了Instagram应用，但随后收到朋友发布新图像的推送通知。</p><p>&nbsp;</p><p>与Instagram的其他推送通知一样，动态推送通知也是由pyapns负责发送。Pyapns是一款开源、通用的苹果推送通知（APNS）提供方案。</p><p>&nbsp;</p><p>会话：用户非常喜欢这张图像，并决定分享到Twitter那边。</p><p>&nbsp;</p><p>在后端，这项任务会被推入任务队列Gearman，它的功能就是把工作移交给更适合的其他设备。Instagram拥有约200个Python工作线程，专供Gearman任务队列使用。</p><p>&nbsp;</p><p>Gearman用于执行多项异步任务，例如向所有用户的关注者推送新动态（例如发布的新图像，这项功能被称为fanout）。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/65/653481115a69a3b14e6ef20878cf159c.png\" /></p><p></p><p>&nbsp;</p><p></p><h3>监控</h3><p></p><p>会话：不好！Instagram应用因为服务器发生故障、发出错误响应而遭遇崩溃。三名Instagram工程师立即收到了警报。</p><p>&nbsp;</p><p>Instagram使用开源Django应用Sentry来实时监控Python错误。</p><p>&nbsp;</p><p>Munin则用于整理系统范围内的指标并发出异常警报。Instagrm设置有一大堆自定义Munin插件，用以跟踪应用层级的运行指标，例如每秒发布的图像数量。</p><p>&nbsp;</p><p>Pingdom负责进行外部服务监控，PagerDuty则用于处理事件和通知。</p><p></p><h3>最终架构一览</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/8a/8a4ac2d5900ede7502da9b7750f32523.png\" /></p><p></p><h2>Facebook买下Instagram</h2><p></p><p>到2012年3月，Instagram应用的用户群体已增长至约2700万。2012年4月，Instagram推出了Android版本，不到一天内下载量即突破100万次。当时，该公司还即将进行估值5亿美元的新一轮融资。顺带一提，Systrom与Facebook创始人扎克伯格之前在斯坦福大学举办的活动上结识，并在Instagram迅速走红后一直保持着联系。</p><p>&nbsp;</p><p>2012年4月，Facebook（现更名为Meta）提出以10亿美元现金加股票的价码收购Instagram，同时承诺让Instagram继续保持独立管理。此后不久，就在Instagram即将进行首轮公开募股（IPO）之前，Facebook成功凭借这一条件将其收入囊中。</p><p>&nbsp;</p><p>Instagram于2012年11月发布功能有所精简的网站版本。2014年6月，面向Amazon Fire设备的版本正式发布。最后在2016年，这款已经在全球掀起热潮的照片分享应用终于出现在微软Windows平板电脑和PC端之上。</p><p></p><h2>Instagram为何能一炮而红？</h2><p></p><p>尽管Instagram现已拥有大量功能，但其仍然牢牢把握着当初的设计原则：通过应用界面可直接创建免费账户，并轻松上传各种媒体素材（包括图像和视频）。之后，用户可以使用过滤器编辑上传的媒体内容，并配合位置信息和主题标签（即以#号开头的单词或短语，可供社交媒体平台识别帖子所属的特定主题）进行组织。用户可以将个人资料设为公开或不可见，二者的区别在于：使用公开个人资料时，其他所有Instagram用户均可查看该用户的照片/视频；而使用不可见设置时，用户需要申请并获得批准后才能看到帖子内容。</p><p>&nbsp;</p><p>Instagram用户还可以搜索主题标签和位置来浏览其他用户的照片和视频。此外，用户可以滑动浏览随机热门内容，并通过为帖子“点赞”或添加评论等方式与其他用户的照片和视频进行交互。当有用户“关注”另一用户时，即可将后者的照片和视频转发到自己的动态当中。</p><p>&nbsp;</p><p>Instagram应用的首个版本仅允许用户以正方形长宽比（即图像宽度与高度间的比例关系）显示媒体，即图像的高度和宽度相同。也就是说，当时Instagram用户只能发布2010年时iPhone 4所支持的640像素宽度相匹配的媒体。这一设计直到2015年才有所变化，用户终于能够上传尺寸更大的媒体素材（最高1080像素）。</p><p>&nbsp;</p><p>自首次推出以来，Instagram又陆续添加了消息收发功能，并允许用户在同一帖子中展示多个图像或视频。</p><p>&nbsp;</p><p></p><blockquote>该应用最受欢迎的功能的之一就是“Instagram Stories”。通过此项功能，用户可以将照片和视频发布到应用内的独立内容源处。这类帖子只在发布后的24小时内向其他用户开放。据Instagram介绍，截至2022年，每天有5亿人使用Instagram Stories功能。</blockquote><p></p><p>&nbsp;</p><p>Instagram提供的照片分享与评论功能营造出强烈的用户参与度和营销口碑，促使用户自发宣传、吸引好友和家人纷纷加入。其简洁的界面和顺手的功能也在市场上备受青睐。它允许用户通过滑动轻松浏览大量帖子，在一定程度上培养了受众的使用、乃至生活习惯。</p><p>&nbsp;</p><p>尽管自Meta（前Facebook）收购以来，Instagram的用户数量仍在持续增长，但这款应用本身的改进也变得乏善可陈。唯一延续下来的，就是简单直观的用户体验和对照片/视频共享功能的核心关注。尽管收购出价不菲，但对Meta来说，这10亿美元无疑是笔非常划算的买卖。</p><p>&nbsp;</p><p>2019年，市场研究公司eMarketer预测，到2021年Instagram用户数量将达到1.172亿。2018年，Instagram成为苹果应用商店中下载量第二大的免费应用（仅次于YouTube的免费移动端应用）。到2020年，Instagram的月活用户规模正式突破10亿大关。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://engineercodex.substack.com/p/how-instagram-scaled-to-14-million\">https://engineercodex.substack.com/p/how-instagram-scaled-to-14-million</a>\"</p><p><a href=\"https://history-computer.com/mike-krieger-complete-biography/\">https://history-computer.com/mike-krieger-complete-biography/</a>\"</p>",
    "publish_time": "2023-09-18 15:21:48",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "JetBrains发布Rust IDE RustRover，不再维护原先的开源插件",
    "url": "https://www.infoq.cn/article/XaiOg4GGC3YCsg18Kuc4",
    "summary": "<p>JetBrains发布新的独立Rust IDE <a href=\"https://blog.jetbrains.com/rust/2023/09/13/introducing-rustrover-a-standalone-rust-ide-by-jetbrains/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjYzODMsImZpbGVHVUlEIjoiZXJBZE0xWkxYakN2ZVczRyIsImlhdCI6MTY5NTAyNjA4MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.TNoJH3T_XdOdsdf9SPJI6-f9Z04Ti_yewXI64rD1nPA\">RustRover</a>\"，现在可以通过<a href=\"https://jb.gg/rust_download?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjYzODMsImZpbGVHVUlEIjoiZXJBZE0xWkxYakN2ZVczRyIsImlhdCI6MTY5NTAyNjA4MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.TNoJH3T_XdOdsdf9SPJI6-f9Z04Ti_yewXI64rD1nPA\">早期访问计划</a>\"进行体验。JetBrains表示，RustRover为Rust提供的支持将与JetBrains为其他编程语言提供的支持一样。</p><p></p><p>JetBrains是<a href=\"https://plugins.jetbrains.com/plugin/8182-rust?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjYzODMsImZpbGVHVUlEIjoiZXJBZE0xWkxYakN2ZVczRyIsImlhdCI6MTY5NTAyNjA4MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.TNoJH3T_XdOdsdf9SPJI6-f9Z04Ti_yewXI64rD1nPA\">IntelliJ IDEA和CLion开源Rust插件</a>\"背后主要的贡献力量，不过它决定停止继续开发这款插件，转而采用一种专门针对Rust的商业、闭源的解决方案，以便为Rust开发者提供更好的开发者体验。</p><p></p><p><a href=\"https://www.jetbrains.com/rust/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjYzODMsImZpbGVHVUlEIjoiZXJBZE0xWkxYakN2ZVczRyIsImlhdCI6MTY5NTAyNjA4MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.TNoJH3T_XdOdsdf9SPJI6-f9Z04Ti_yewXI64rD1nPA\">RustRover</a>\"支持语法高亮显示和代码补全、代码生成、即时快速修复、智能重构和实时模板。它还提供了调试器、测试执行器、运行配置、性能分析功能，以及专门用于Web应用程序开发的特性，例如HTTP客户端、数据库访问和Docker支持。</p><p></p><p>此外，RustRover可以很好地与Rust生态系统中的其他语言和工具（包括Cargo和TOML）配合使用，并与Git、GitHub和其他VCS系统集成。</p><p></p><p>JetBrains表示，基于这些特性，RustRover为Rust提供的支持将与JetBrains为其他编程语言提供的支持一样。</p><p></p><p>JetBrains的发布声明在Hacker News和Reddit上都得到了积极的评价，一些人表示<a href=\"https://news.ycombinator.com/item?id=37496686&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjYzODMsImZpbGVHVUlEIjoiZXJBZE0xWkxYakN2ZVczRyIsImlhdCI6MTY5NTAyNjA4MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.TNoJH3T_XdOdsdf9SPJI6-f9Z04Ti_yewXI64rD1nPA\">拥有官方支持和付费客户支持的Rust专用IDE</a>\"是有价值的。另一些人则更关注<a href=\"https://news.ycombinator.com/item?id=37498987&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjYzODMsImZpbGVHVUlEIjoiZXJBZE0xWkxYakN2ZVczRyIsImlhdCI6MTY5NTAyNjA4MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.TNoJH3T_XdOdsdf9SPJI6-f9Z04Ti_yewXI64rD1nPA\">独立IDE</a>\"相对于支持多种语言的通用IDE（比如使用带有特定语言插件的IntelliJ）的优越性。</p><p></p><p>还有一些人对JetBrains正在<a href=\"https://plugins.jetbrains.com/plugin/8182--deprecated-rust?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjYzODMsImZpbGVHVUlEIjoiZXJBZE0xWkxYakN2ZVczRyIsImlhdCI6MTY5NTAyNjA4MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.TNoJH3T_XdOdsdf9SPJI6-f9Z04Ti_yewXI64rD1nPA\">弃用当前用于IntelliJ和CLion的Rust插件</a>\"的行为做出了<a href=\"https://www.reddit.com/r/rust/comments/16hiw6o/introducing_rustrover_a_standalone_rust_ide_by/k0dupiq/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjYzODMsImZpbGVHVUlEIjoiZXJBZE0xWkxYakN2ZVczRyIsImlhdCI6MTY5NTAyNjA4MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.TNoJH3T_XdOdsdf9SPJI6-f9Z04Ti_yewXI64rD1nPA\">批评</a>\" 。</p><p></p><p></p><blockquote>对于现有的开源插件，我们将尽最大努力保持与新版本IDE兼容，但我们不会进行错误修复或添加新功能。</blockquote><p></p><p></p><p>无论如何，这个插件将继续保持开源，并基于MIT许可，社区有可能继续开发它。</p><p></p><p>JetBrains表示，等到RustRover准备就绪，他们就会正式发布，希望不会迟于2024年9月发布。</p><p></p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/09/rustrover-ide-early-access/\">https://www.infoq.com/news/2023/09/rustrover-ide-early-access/</a>\"</p>",
    "publish_time": "2023-09-18 16:36:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]