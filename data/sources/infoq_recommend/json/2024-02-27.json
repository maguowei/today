[
  {
    "title": "React 19 要来了：你准备好了吗？｜讨论",
    "url": "https://www.infoq.cn/article/R7x8TGNPFrQvBqo151y3",
    "summary": "<p>React，作为前端领域中备受瞩目的技术框架之一，自其诞生以来一直以快速的版本迭代和引入新特性而闻名。然而，最近一年多以来，React 18版本停滞不前，当前的稳定版本是18.2，发布于22年6月，之后便没有新的稳定版本发布。直到今年2月15日，官方博客才透露了下一个稳定版本的计划，即React 19。具体更新新闻大家可以看这篇报道：<a href=\"https://www.infoq.cn/news/2t41mOMj3Hw2fBiTGLJH\">沉寂 600 多天后，React 憋了个大招</a>\"。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/a9/e4/a96be12495e7d0f490e70b37a26202e4.png\" /></p><p></p><p></p><p>尽管停止了稳定版本的发布，但React在过去一年中的活跃度并未降低。从代码提交量来看，React仍然保持着较高的活跃度，主要集中在底层架构的重构，因此一年没发新版并非意味着停滞不前，而是其发展理念转变的必然结果。</p><p></p><p>对于 React 19，普通开发者无需担心学习成本过大。如果你不使用 Next 等框架，那么你大概率不会接触到 RSC 体系下的新特性。React 19 对你的最大影响可能就是新特性对老 API 的影响，例如 useContext 变为 use(promise)等。</p><p></p><p>了解更多</p><p></p><p>React 官方博客： <a href=\"https://react.dev/blog\">https://react.dev/blog</a>\"YouTube 视频: <a href=\"https://www.youtube.com/watch?v=B-tjhF7ojeA\">https://www.youtube.com/watch?v=B-tjhF7ojeA</a>\"</p><p></p><p>关于React 19 的进一步消息，可以关注今年 5 月 15 日至 16 日的 React Conf 。那么你最期待 React 哪些功能更新呢？欢迎留言～</p><p></p><p>InfoQ 为大家在前端学习的道路上准备了一份厚礼！扫码免费领取～</p><p><img src=\"https://static001.infoq.cn/resource/image/b7/fd/b74de49052a627a99c4769d3ec6037fd.png\" /></p><p></p>",
    "publish_time": "2024-02-27 10:30:26",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "aiXcoder 代码大模型在企业的应用实践",
    "url": "https://www.infoq.cn/article/JQsMsolAbd7TQ7kI4cVA",
    "summary": "<p>本次演讲针对代码大模型在企业真实落地中存在数据安全、计算资源有限、企业领域知识融合等挑战，结合实际落地案例，介绍 aiXcoder 代码大模型的构建与应用实践，包括代码大模型的训练、私有化部署、结合企业领域知识的个性化训练等。</p>\n<p>听众收益点：</p>\n<p>了解代码大模型的构建基本流程；<br />\n企业如何应用代码大模型提升研发效能。</p>",
    "publish_time": "2024-02-27 11:24:16",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "借助 LangChain 与 LLM Agent 加速生成式 AI 应用开发",
    "url": "https://www.infoq.cn/article/mSVS28xKaCQMfKR3lZDq",
    "summary": "<p>本次分享将会介绍 LLM-based Agent 特性，业界发展情况以及如何利用 Agent 构建生成式 AI 应用，让你快速借助 LangChain 和 Agents for Amazon Bedrock 构建企业自己的可落地的生成式AI应用。</p>\n<p>听众收益：</p>\n<p>了解 LLM-based Agent 特性与发展<br />\n初步掌握如何利用 LLM-based Agent 构建生成式 AI 应用</p>",
    "publish_time": "2024-02-27 11:24:20",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AI Native 化的大前端开发模式",
    "url": "https://www.infoq.cn/article/CK0PJe62BNc5N15PaUIj",
    "summary": "<p>在本次的分享中，我将向大家展示如何将传统的交互方式与对话流相结合，这包括上下文和状态流转的设计策略。除了交互设计本身，我们还会探讨特定场景下的 PatternPlugin，这将涉及如何将状态机技术应用于肉鸽游戏和活动设计。此外，我还将分享如何利用大型模型来进行业务监控和效果评估。</p>\n<p>听众收益点：</p>\n<p>了解传统交互与 LLM 对话的结合方案<br />\n了解 PatternPlugin 状态机的设计<br />\n基于大模型的 EDD 设计思想</p>",
    "publish_time": "2024-02-27 11:36:10",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Sora 技术报告深度解读",
    "url": "https://www.infoq.cn/article/w72jY5dZOrW1f8ANARpG",
    "summary": "<p></p><h2>你将获得</h2><p></p><p>理解 Sora 令人惊叹的 8 大特性了解 Sora 背后的 6 大技术支撑深入探索 Sora 模拟世界的能力大胆探究 Sora 发展方向与前景</p><p></p><h2>课程介绍</h2><p></p><p>Sora 是啥？到底带来了哪些改变？Sora 背后的技术都有哪些？AGI 时代真的要来了吗？</p><p></p><p>OpenAI 的首个视频生成模式 Sora 发布，效果令人惊叹。作为技术人，除了看热闹，我们还要看门道；咱也不必跟着瞎焦虑，踏实下来研究些干货内容。这个公开课是对 Sora 官方技术报告的深度解读，郑建勋老师带我们从 4 个主题层层深入，看懂 Sora 背后技术，探索更多未来可能。</p><p></p><p>这是最好的时代，这是最坏的时代。而我们，跟上技术发展的脚步，扎扎实实练内功，成为同行者。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/d4/eb/d4ca5c2433cb6802f77e957c919f24eb.png\" /></p><p></p><h2>讲师介绍</h2><p></p><p>郑建勋，Go 语言技术专家，成都慧眸科技创始人。极客时间《Go 进阶 · 分布式爬虫实战》专栏讲师，《Go 语言底层原理剖析》《聚沙成塔：Go 语言构建高性能、分布式爬虫项目》图书作者。Go 语言垃圾回收源码贡献者，Go 语言精度库 shopspring/decimal 核心贡献者。曾就职于人工智能独角兽公司的视觉中台与大型互联网企业的业务中台，拥有丰富的大规模云原生、分布式、微服务集群的实战经验。确保了百万级流量系统的服务稳定性，并经历和主导了复杂业务系统的性能优化与系统重构。</p>",
    "publish_time": "2024-02-27 12:29:31",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "欧洲版OpenAI被微软收编了，但这家号称专注于“开源”的大模型企业转向了”闭源“？",
    "url": "https://www.infoq.cn/article/k166omoFE72Qrt5ZMMKQ",
    "summary": "<p>今天，微软突然宣布与法国开源大模型初创公司Mistral达成深度合作。</p><p>&nbsp;</p><p>Mistral AI正式成立于2023年5月，估值 20 亿欧元（约合 21 亿美元）。双方将共同开展研发合作，并将 Mistral 的 AI 模型部署在微软 Azure 云计算平台上。这将使 Mistral 成为继 OpenAI 之后，第二家在 Azure 上提供商用语言模型的公司。</p><p>&nbsp;</p><p>而且，据媒体透露，作为交易的一部分，微软还将对 Mistral 进行投资。这将使其成为继 OpenAI 之后，微软投资的第二家 AI 大模型公司。具体投资金额尚未披露。此前，微软投资OpenAI为130亿美元，持有OpenAI约49%股份。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/29/2971a7c9a91df639171d96f967d024c6.jpeg\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>AI新贵Mistral发布最新旗舰大模型</h2><p></p><p>&nbsp;</p><p>Mistral AI也于今天宣布正式推出最新旗舰模型Mistral Large。这是一种新的语言模型，旨在与 OpenAI 的 GPT-4 直接竞争。</p><p>&nbsp;</p><p>Mistral AI 声称该模型具有“顶级的推理能力”，能用于处理复杂的多语言推理任务，包括文本理解、转换和代码生成。</p><p>&nbsp;</p><p>在常用基准测试MMLU的对比中，Mistral Large的得分仅次于GPT-4，略好于Anthropic开发的Claude 2。至于谷歌的Gemini Pro以及的LLaMA 2 70B模型，则被甩开了一个身位。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b0/b0bfe59bdfca45f0f259be848f9087b7.png\" /></p><p></p><p>&nbsp;</p><p>在推理能力上，Mistral Large也仅次于GPT-4，优于LLaMA 2 70B模型：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ef/ef1e12eaf943f7b44cc5762591af6ee3.png\" /></p><p></p><p>&nbsp;</p><p>Mistral Large 具有本地多语言能力。它在法语、德语、西班牙语和意大利语的 HellaSwag、Arc Challenge 和 MMLU 基准测试中明显优于 LLaMA 2 70B。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5a/5a7071d664caf8ffcbcab578586cc34a.png\" /></p><p></p><p>&nbsp;</p><p>各路网友纷纷对其进行了测试，表示其能力“仅次于OpenAI”、“中文文本处理能力无限逼近GPT-4”......</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b5/b5e6dece60e76df31f3bcec8070cc368.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4d/4d2322f6d0b6669d3eff938a24083f64.jpeg\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>Mistral AI 在发布大模型的博客中，同时宣布将他们的开放式和商业模型引入到 Azure 中。所以现在访问Mistral AI 的模型方式为：</p><p>&nbsp;</p><p>La Plateforme：该平台托管在 Mistral 位于欧洲的基础设施上，使开发人员能够利用Mistral AI全系列模型构建应用程序和服务。Azure：Mistral Large 已通过 Azure AI Studio 和 Azure Machine Learning 上线，用户体验顺畅，一些测试版客户已经在使用。自部署：对于最敏感的用例，用户可以在自己的环境中部署Mistral AI的模型，并访问其模型权重。</p><p>&nbsp;</p><p>微软表示与 Mistral 的合作将帮助 Mistral 将其 AI 模型推向市场，并用于开发满足欧洲各国政府和公共部门需求的应用程序。</p><p>&nbsp;</p><p>微软总裁 Brad Smith 发言称，微软与 Mistral 的合作，将推动 AI 技术在欧洲乃至全球的应用和发展。他认为，AI 将创造全新的业务和商业模式，并将对各个行业产生深远影响。</p><p>&nbsp;</p><p></p><h2>这次合作，让Mistral成为“闭源”公司？</h2><p></p><p>&nbsp;</p><p>微软首席执行官萨特亚·纳德拉 (Satya Nadella) 近日称赞了法国初创公司 Mistral AI，将其视为在 Azure 云计算平台上构建人工智能的创新者之一。</p><p>&nbsp;</p><p>Mistral 由三位来自 Meta 和谷歌的前研究人员 Mensch、Timothée Lacroix 和 Guillaume Lample 创立，致力于构建大语言模型，这也是生成式 AI 产品的基础技术。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f0/f080d14f628eb22f406f8b82d569bdd4.png\" /></p><p></p><p>&nbsp;</p><p>Mistral 于去年 12 月的融资中获得了 20 亿欧元的估值，融资金额约为 4 亿欧元。</p><p>&nbsp;</p><p>据英国《金融时报》，该公司承诺将模型开源，这意味着技术细节将公开发布，这与竞争对手 (例如 ChatGPT 制造商 OpenAI) 的做法形成鲜明对比。OpenAI 最新的模型 GPT-4 是所谓的 “黑匣子”，用于构建模型的数据和代码不会提供给第三方。</p><p>&nbsp;</p><p>Mistral 此前也一直专注于开源 AI 软件，他们坚信生成式 AI 技术应该是开源的，允许自由复制和修改 LLM 代码，通过这种方式帮助其他用户快速构建自己的聊天机器人。Mixtral 8x7b则被许多人视为目前性能最好的开源 LLM。</p><p>&nbsp;</p><p>但因为Mistral 没有像往常一样提供 GitHub 或是下载链接，不少网友担心这家公司开始转为“闭源”方向。</p><p>&nbsp;</p><p>而且，还有网友发现，Mistral 更改了他们的网站，删除了之前提及的关于他们对开源社区义务的地方，这也让一些人认为Mistral已经失去了初心。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a4/a450279b20b76245b79dfd7d6744412e.jpeg\" /></p><p></p><p>&nbsp;</p><p>独立科技记者Luca Bertuzzi得到的消息跟《金融时报》完全相反，他发推表示，“与之前的模型不同，Mistral Large 不会开源，换句话说，Mistral正在放弃其备受赞誉的开源方法。”</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/56/56a28a1542e157459994195b6ae9252a.jpeg\" /></p><p></p><p>&nbsp;</p><p>“他们提供的最初的信息是‘在 2024 年发布开源 GPT-4 级别模型’，现在他们的立场变了，我们不希望他们成为另一个OpenAI。”</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/31/313d63aacac7fe2dd5c9f65ddc5bed03.jpeg\" /></p><p></p><p>&nbsp;</p><p>模型的定价也引发了一些质疑，比如 Mistral Small 的低延迟相比于 Mixtral 8x7B 的提升微乎其微，但输入贵了 2.8 倍，输出贵了 8.5 倍。</p><p>&nbsp;</p><p>那么为什么微软选择和Mistral合作？</p><p>&nbsp;</p><p>微软在其博客中透露，该公司与Mistral AI合作的一个核心方向就是“扩大市场，微软和 Mistral AI 将通过 Azure AI Studio和Azure 机器学习模型目录中的模型即服务 (MaaS) 、MACC服务向客户提供 Mistral AI 的高级模型，提供可替换OpenAI模型的多种选择，包括开源和商用模型。”</p><p>&nbsp;</p><p>微软表示，其数据中心运行着 1,600 个 AI 模型，其中 1,500 个是开源的。公司希望除了支持 OpenAI 等专有技术之外，继续在这个领域提供支持。</p><p>&nbsp;</p><p>而且，训练和开发新的 AI 模型所需的基础设施的建造成本也极高，只有少数几家公司能够参与竞争。</p><p>&nbsp;</p><p>微软总裁 Brad Smith 在巴塞罗那举行的世界移动通信大会上表示，微软将致力于一系列旨在鼓励 AI 创新和竞争的原则。他认为，监管机构最终将关注的更广泛问题是，训练和开发 AI 模型的基础设施是否可以广泛应用于没有自己的数据中心和云基础设施的公司。</p><p>&nbsp;</p><p>微软与Mistral的合作将进一步加剧 AI 领域的竞争。微软、谷歌、亚马逊等科技巨头都在积极布局 AI 领域，并寻求在各自的平台上构建强大的 AI 生态系统。 未来，AI 技术将如何发展，值得我们拭目以待。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://mistral.ai/news/mistral-large/\">https://mistral.ai/news/mistral-large/</a>\"</p><p><a href=\"https://azure.microsoft.com/en-us/blog/microsoft-and-mistral-ai-announce-new-partnership-to-accelerate-ai-innovation-and-introduce-mistral-large-first-on-azure/\">https://azure.microsoft.com/en-us/blog/microsoft-and-mistral-ai-announce-new-partnership-to-accelerate-ai-innovation-and-introduce-mistral-large-first-on-azure/</a>\"</p><p><a href=\"https://twitter.com/satyanadella/status/1762165185513722057\">https://twitter.com/satyanadella/status/1762165185513722057</a>\"</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2024-02-27 14:12:23",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AI Native 化的大前端开发模式 | QCon",
    "url": "https://www.infoq.cn/article/CK0PJe62BNc5N15PaUIj",
    "summary": "<p>在本次的分享中，我将向大家展示如何将传统的交互方式与对话流相结合，这包括上下文和状态流转的设计策略。除了交互设计本身，我们还会探讨特定场景下的 PatternPlugin，这将涉及如何将状态机技术应用于肉鸽游戏和活动设计。此外，我还将分享如何利用大型模型来进行业务监控和效果评估。最新会议动态：QCon 全球软件开发大会暨智能软件开发生态展将于4月11-13日在北京·国测国际会议会展中心举办，点击<a href=\"https://qcon.infoq.cn/2024/beijing/?utm_source=qconshanghai&amp;utm_medium=playback\">链接</a>了解大模型如何革新软件开发全流程。</p>\n<p>听众收益点：</p>\n<p>了解传统交互与 LLM 对话的结合方案<br />\n了解 PatternPlugin 状态机的设计<br />\n基于大模型的 EDD 设计思想</p>",
    "publish_time": "2024-02-27 11:36:09",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "华为发布通信行业首个大模型，提供基于角色的Copilots和基于场景的Agents应用能力",
    "url": "https://www.infoq.cn/article/0PuOGSrqVePTwmZh5lk3",
    "summary": "<p>当地时间2月26日，在MWC24巴塞罗那展期间，华为发布了通信行业首个大模型。据了解，华为通信大模型是一款基于AI的商用大模型，采用先进的技术和算法，提供关键的智能化技术能力，用于优化通信网络性能、智能调度资源等，实现5G-A（5.5G）时代的智能化目标。</p><p>&nbsp;</p><p>针对行业提出的敏捷业务发放、精准用户体验保障、跨领域高效运维的高阶智能化目标，该大模型提供基于角色和基于场景的智能化应用，助力运营商赋能员工、提升用户满意度，全面使能网络生产力。</p><p>&nbsp;</p><p>华为董事、ICT产品与解决方案总裁杨超斌介绍，华为通信大模型发挥智能化技术优势，提供基于角色的Copilots（AI助手）和基于场景的Agents（智能体）的两类应用能力，帮助运营商赋能员工的同时，提升用户满意度，最终将全面提升网络生产力。</p><p>&nbsp;</p><p>杨超斌还分享了华为通信大模型的典型场景实践。在敏捷业务发放案例中，通过放号助手的多模态精准评估，实现了快速用户放号；在用户体验保障案例中，通过大模型的寻优能力，实现了多目标体验保障；在辅助排障场景下，跨流程的质差分析和对话辅助处理，显著改善了故障处理效率。</p><p>&nbsp;</p><p>在MWC24巴塞罗那大会上，华为公司高级副总裁、ICT销售与服务总裁李鹏表示，2024年是5G-A商用元年，结合云和AI技术的发展，运营商商业增长的潜力巨大。李鹏指出，全球运营商可以抓住四个方面的战略机会：优质网络是实现商业成功的基础；多维体验变现，充分挖掘网络每比特的价值；新业务不断涌现，支撑面向未来的持续增长；生成式AI，驱动移动产业走向全面智能化。</p>",
    "publish_time": "2024-02-27 15:51:27",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "大模型时代：最大化CPU价值的优化策略|Qcon",
    "url": "https://www.infoq.cn/article/RFIYuIN1wdG1lQAjMfaI",
    "summary": "<p>本次演讲将探讨在大语言模型时代充分利用 CPU 资源的关键策略。具体介绍一些结合硬件特性的优化方法，例如利用 CPU 的多核特性、采用并行计算和 AMX 指令集扩展技术来提高处理速度。</p>\n<p>此外还将介绍一种结合 CPU 和 GPU 的投机采样方法，通过在 CPU 上运行部分计算任务，充分利用 CPU 资源并减少对 GPU 的依赖。最后，我将分享一些最新的性能情况，让您了解这些优化策略的实际效果。通过这些方法，您将能够更好地利用 CPU 资源，提高模型推理速度，以更快速高效的实现生成式模型部署落地。</p>\n<p>最新会议动态：QCon 全球软件开发大会暨智能软件开发生态展将于4月11-13日在北京·国测国际会议会展中心举办，点击<a href=\"https://qcon.infoq.cn/2024/beijing/?utm_source=qconshanghai&amp;utm_medium=playback\">链接</a>了解大模型如何革新软件开发全流程。</p>\n<p>听众收益点：</p>\n<p>理解并结合硬件特性进行优化，提高模型推理速度和处理能力<br />\n了解 CPU 上的最新性能情况，为实际业务的大模型线上部署提供更多选择<br />\n掌握结合 CPU 和 GPU 协同工作的优化策略，减少对 GPU 的依赖，提高资源利用率</p>",
    "publish_time": "2024-02-27 16:17:45",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]