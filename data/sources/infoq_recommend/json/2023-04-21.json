[
  {
    "title": "让部署更快更安全，GitHub无密码部署现已上线",
    "url": "https://www.infoq.cn/article/QMgmfb48A8AD1YHBdyPC",
    "summary": "<p>GitHub的CI/CD服务产品GitHub Actions现在支持使用<a href=\"https://github.blog/2023-01-11-passwordless-deployments-to-the-cloud/\">Open Identity Connect凭证</a>\"对Hashicorp Vault、AWS、Azure和GCP等云提供商进行身份验证，而无需使用长期凭证或密码。</p><p>&nbsp;</p><p>云的现代开发通常需要针对云提供商对持续集成和持续部署（CI/CD）服务器进行身份验证，以便对已配置的基础设施进行更改。从历史上看，这是通过在云提供商中创建一个身份来实现的，CI/CD服务器可以通过使用一组长期存在的、手动设置的凭证来假定这个身份。考虑到这些凭证的用途，它们的妥协终究会带来重大的业务风险。</p><p>&nbsp;</p><p><a href=\"https://openid.net/connect/#:~:text=OpenID%20Connect%201.0%20is%20a,interoperable%20and%20REST%2Dlike%20manner.\">OpenID Connect身份验证协议</a>\"是一种可互操作的机制，用于提供有关用户身份的可验证信息。假如用户的身份提供者是验证方能够信任的提供者，则可以在称为<a href=\"https://www.oauth.com/oauth2-servers/openid-connect/id-tokens/\">ID令牌</a>\"的<a href=\"https://jwt.io/introduction\">Json Web令牌（JWT）</a>\"中以声明的形式提供相关用户数据。</p><p>&nbsp;</p><p>使用GitHub Actions，第一步是在云提供商的身份和访问管理配置中将GitHub注册为外部身份源。在执行工作流时，管道可以访问管道唯一运行范围内的ID令牌。令牌包括令牌的期望受众、其持有者的标识符以及其他元数据。</p><p>&nbsp;</p><p>然后，云提供商可以使用该信息来为任何的后续操作颁发短期凭证，例如访问令牌。目前GitHub Actions支持<a href=\"https://docs.github.com/en/actions/deployment/security-hardening-your-deployments/configuring-openid-connect-in-hashicorp-vault\">Hashicorp Vault</a>\"、<a href=\"https://docs.github.com/en/actions/deployment/security-hardening-your-deployments/configuring-openid-connect-in-amazon-web-services\">亚马逊网络服务</a>\"、<a href=\"https://docs.github.com/en/actions/deployment/security-hardening-your-deployments/configuring-openid-connect-in-azure\">Azure</a>\"和<a href=\"https://docs.github.com/en/actions/deployment/security-hardening-your-deployments/configuring-openid-connect-in-google-cloud-platform\">谷歌云平台</a>\"。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/df/df09309a6f99c18adbef79574ecc24c9.png\" /></p><p></p><p>&nbsp;</p><p>自该新特性发布以来，人们对它的反响基本上是积极的，Hashicorp创始人<a href=\"https://twitter.com/mitchellh\">Mitchell Hashimoto</a>\"在推特上写道：</p><p>&nbsp;</p><p></p><blockquote>最近发现GitHub Actions每次运行都会创建一个OIDC标识，因此可以将Vault配置为允许w/Actions身份认证，然后使用它来访问……任何内容。虽然需要进行一些清理，但这是非常有希望的！</blockquote><p></p><p>&nbsp;</p><p>尽管反响热烈，但其采用速度似乎比预期的要慢，WhiteDuck DevOps的咨询与运营主管&nbsp;<a href=\"https://twitter.com/nmeisenzahl\">Nico Meisenzahl</a>\"在推特上写道：</p><p>&nbsp;</p><p></p><blockquote>在#GitHub Actions中使用#OIDC进行云提供商和#Kubernetes身份验证已经是一件大事件了吗？我虽然看到了它的很多优点，但已经采用它的人并不多。</blockquote><p></p><p>&nbsp;</p><p>继GitHub于2021年底发布该特性以来，其他CI/CD提供商也在其产品中添加了类似的集成。2022年底发布的GitLab 15.7版本支持访问<a href=\"https://docs.gitlab.com/ee/ci/cloud_services/\">Hashicorp Vault、AWS、Azure和GCP</a>\"，而Circle CI于2023年2月宣布支持<a href=\"https://circleci.com/blog/openid-connect-identity-tokens/\">GCP和AWS</a>\"集成。</p><p>&nbsp;</p><p>所有计划都可以使用GitHub Actions OIDC登录云提供商，而无需额外的费用。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/03/passwordless-deployments-github/\">https://www.infoq.com/news/2023/03/passwordless-deployments-github/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://xie.infoq.cn/article/3a47c0e86ca4f1780a65cfdf3\">玩转 Github：三分钟教你如何用 Github 快速找到优秀的开源项目</a>\"</p><p><a href=\"https://xie.infoq.cn/article/442ddeac1eaada53fd5770750\">8 个很酷的 GitHub 技巧</a>\"</p>",
    "publish_time": "2023-04-21 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "用友 BIP 助力中国领先企业数智化国产替代",
    "url": "https://www.infoq.cn/article/BScfzwB5pdzkKXMDgYyO",
    "summary": "<p>随着数字经济的快速发展，软件的重要性日益凸显。软件是新一代信息技术的灵魂，已经成为数字中国、制造强国、网络强国建设的关键支撑。面对全球竞争新格局，关键软件自主创新与国产化替代已迫在眉睫。</p><p></p><h1>助力华为成功替换国外ERP系统</h1><p></p><p></p><p>在此背景下，作为领先的企业软件提供商，用友应邀承接了华为替换旧有国外ERP总账项目，通过产品研发和交付团队的努力，项目按质量完成交付，并在试点单位成功上线应用。</p><p></p><p>用友依托深厚的企业软件产品创新能力，包括用友BIP最新基于事项法会计理论的智能会计思想与模型，助力华为成功实现对国外ERP系统的替换。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/72/727e837b4b44cbe9652a82e321eea9c5.png\" /></p><p>华为为MetaERP合作伙伴颁奖</p><p></p><p>4月20日，用友作为华为重要合作伙伴，受邀出席华为“英雄强渡大渡河”MetaERP表彰会。在会上，华为为用友颁发“英雄强渡大渡河”奖牌，以表彰用友在MetaERP研发及替换国外ERP系统上做出的贡献。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e2/e2d38078432281d9a5316b559221619f.png\" /></p><p></p><p>把数智化升级与信创国产化相结合，即“价值化国产替代”是用友多年以前就确立的发展方针，除服务华为的本次系统建设外，用友战略研发的新一代服务企业数智化的主力产品-用友BIP，自发布以来，已应用于33000多家大中型企业的数智化建设，累计签约一级央企27家，充分体现了以用友为代表的中国企业软件厂商，已经具备了承担大型、超大型企业数智化底座平台和关键应用系统国产化替代重任的能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/25/25a3f9a5fd62434e81530d44889eb456.png\" /></p><p>华为董事、CEO任正非（左）与用友网络高级副总裁王勇（右）</p><p></p><h1>用友BIP，企业数智化与国产化替代的首选</h1><p></p><p></p><p>信息技术在企业的应用，经历了电脑化、信息化、数智化三大阶段，用友的发展见证了这一历史进程在中国的演化。如果说在电脑化时代中国企业远远落后于发达国家，信息化时代中国追赶发达国家，今天，我们已经开始看到越来越多的中国企业的数智商业创新开始走到全球同业的前列。有了这样的土壤，一定能够在中国成长出数智化时代全球领先的企业软件厂商。</p><p></p><p>用友创立于1988年，始终专注于企业软件与服务产业，用友1.0时期，通过财务软件服务超过40万家企事业单位的会计电算化，成为中国最大的财务软件公司；用友2.0时期，通过ERP服务超过200万家企业的信息化，成为亚太最大、全球前10的ERP软件提供商。当前，用友发展进入3.0新时期，目标是要用新一代产品服务超过千万家企业的数智化，并成为全球前3的企业云服务与软件提供商。</p><p></p><p>在35年行业Know-how积累与大规模客户合作基础上，基于新一代数字与智能技术，用友战略投入，组织国内同类厂商中规模最大的研发团队，历时七年研发打造的全新一代服务企业数智化的主力产品——用友BIP，在平台技术与应用架构、领域与行业应用、生态体系三个层面，实现全面突破，达到全球领先水平，是目前全球领域覆盖最多的企业应用服务群。同时，作为信息技术应用创新工作委员会WG22 ERP与财务软件组组长单位，用友深度参与了信创生态建设。用友BIP从芯片、服务器、操作系统、数据库、中间件到安全，全栈适配中国电子PKS、中国电科、中科院及华为鲲鹏四大信创技术体系。</p><p></p><p>开放融合、生态共荣，共同为客户创造价值，是用友BIP的发展方针之一。用友BIP的生态正在快速成长，目前已有ISV伙伴近2500家，专业服务伙伴419家，开发者活跃数超过108万，并连接了全球2108家银行。在国产化趋势下，一批原来与国外ERP厂商合作的专业服务伙伴陆续加入用友生态体系。</p><p></p><p>用友BIP坚持云中立原则，可根据客户的需要，运行在阿里云、天翼云、华为云、腾讯云、企业自建IDC等不同云计算平台，并可实现便捷的跨云迁移，支持企业拥有开放、自主的数智化基础设施环境。</p><p></p><p>据Gartner研究数据显示，用友目前是全球应用平台软件aPaaS市场和ERP SaaS市场TOP10中唯一的中国厂商，并在财务（FMS）市场占有率连续多年入选全球10强，客户覆盖30多个行业，以及40多个国家和地区，被重要央媒誉为企业数智化的“大国重器”，成为新时期众多行业领先企业推进企业数智化建设与国产化替代的首选。</p><p></p><h1>普及用友BIP，让数智化在更多的企业成功</h1><p></p><p></p><p>“用创想与技术推动商业和社会进步”是用友的企业使命。新时期，用友将承载起引领中国软件产业蓬勃发展的重任，在企业使命的指引下，通过普及用友BIP，服务中国和全球企业的数智化，把融合众多行业领先企业的成功实践，更具普适性推广价值、更贴合企业数智化建设和运营需求的成果规模复制到千行百业，使能客户的数智商业创新与进步发展，让数智化在更多的企业成功！</p>",
    "publish_time": "2023-04-21 09:37:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "华为宣布成功完成MetaERP自研和替换",
    "url": "https://www.infoq.cn/article/QLX24NmbrpfICxdlLAA0",
    "summary": "<p></p><p>4月20日，华为在东莞举办了<a href=\"https://www.infoq.cn/article/ugoDGtJzX9xdm8d9o5eo\">MetaERP</a>\"表彰大会，正式对外宣布实现自主可控的MetaERP研发，并完成对旧ERP系统的替换。</p><p></p><p>据悉，任正非出席本次表彰会向合作伙伴表示感谢，“要谢谢合作伙伴，我们认为今天的成功跟你们分不开，未来的发展跟你们更相关联”。他还表示，今天在软件上我们还是落后的，但是有一天我们可能会变强大。</p><p></p><p>表彰会上，华为董事、质量与流程IT部总裁陶景文表示：“面对包含ERP在内等企业作业和管理核心系统的断供停服，我们不仅能造得出来，还换得了，用得好，现在终于可以宣布，我们已经突破了封锁，我们活了下来！”</p><p></p><p>截至目前，MetaERP已经覆盖了华为公司100%的业务场景和80%的业务量，经历了月结、季结和年结的考验，实现了零故障、零延时、零调账。</p><p></p><p>附陶景文发言全文：</p><p></p><p>同心协力，突破封锁，成功强渡大渡河</p><p></p><p>尊敬的各位来宾、各位伙伴、各位同事，大家好！</p><p></p><p>随着华为技术、华为云等公司ERP的成功替换，MetaERP已经覆盖了集团、销服类、制造类等几类公司，覆盖了100%的业务场景和80%的业务量，经历了月结、季结和年结的考验，年报及时准确发布的同时，实现了零故障、零延时、零调账。面对包含ERP在内等企业作业和管理核心系统的断供停服，我们不仅能造得出来，还换得了，用得好，现在终于可以宣布，我们已经突破了封锁，我们活了下来！</p><p></p><p>今天我们召开MetaERP胜利表彰大会，就是为过去三年来为突破公司经营连续性封锁做出重要贡献的团队和个人庆功，也要特别感谢我们的合作伙伴和所有做出贡献的英雄们！</p><p></p><p>2019年5月16日，美国把华为放入实体清单，ERP供应商在几天内就通知对华为断供停服，而ERP作为华为企业经营最核心的系统，支撑了华为20多年的快速发展，支撑了每年数千亿产值的业务，支撑了全球170+国家业务高效经营，一旦出问题，相当于自身运行的神经系统出了问题，公司基本业务运转面临瘫痪风险，这道影响企业经营生存的“大渡河”突然横亘在前，我们已经没有退路，“强渡大渡河”成为唯一选择。</p><p></p><p>一、断供停服是一场巨大的危机，也让我们重新系统审视老ERP的问题和发展限制，最终我们决定不仅要全栈自主可控，且要基于云原生、元数据多租、实时智能等新技术，打造面向未来的下一代企业核心商业系统，让企业运营更安全、更高效。</p><p></p><p>1. 华为是ERP深度使用者，深刻理解ERP的需求、问题和价值。过去华为坚持用“欧美砖修长城”，1996年就引入MRP II，ERP支撑了大量多业态全球化业务，且承载了IPD、ISC、CRM、IFS等变革项目经验，是老ERP系统全球使用体量最大企业之一，为了保留固化在ERP的多年管理和运营经验，不让管理退步，同时解决老ERP系统存在灵活性差、对业务需求响应慢、不够智能等问题，我们寻找了很多出路，最后发现能救我们的只有自己。</p><p>2. 实现全栈自主可控，并采用最新技术，支持业务需求快速响应、经营决策科学高效、应用数据安全可信。采用云原生架构用好算力，实现全球快速部署，自动适配业务流量变化，轻松应对千万级流量洪峰；采用元数据多租架构，将业务对象、实体、逻辑等元数据资产标准化，租户可灵活编排，快速响应业务需求；采用实时智能技术用好数据，如通过预置多个AI模型，实现风控、经营决策科学高效；采用完全自主的<a href=\"https://xie.infoq.cn/article/60e91f6434a283d60098899bf\">GaussDB</a>\"，会计分录峰值处理3000万笔/天，从30分钟延时改进到实时处理；落实公司可信变革，让系统更加安全可控，让数据在安全合规的前提下高效使用。</p><p></p><p>二、如何成功替换ERP这个非常复杂且实时运行的系统，又能实现“业务无感、数据不丢、报告准确、业财一致”的极致要求，我们积累了一整套经验，总结了一整套方法，构建了一整套工具，并且实现了这个极高难度的挑战。</p><p></p><p>1. 通过“解耦”重定边界，让ERP回归核心功能。老ERP像年久失修的大厦，内部管道和线路交叉纵横、违建繁多，各类应用与ERP的逻辑集成点3950个、数据集成点高达27000个。通过解耦重新定义了ERP边界和功能，并通过“绿地计划”打扫外围各业务应用系统，减少1000+个逻辑集成点，去除ERP客制化代码320万行，实现业务应用系统的标准、可插拔；识别核心业务流，以“业务流”为基础解耦，保证业务财务一体化设计，从而实现主干贯通、业财一致。</p><p>2. 打造切换工具链，让切换高效可靠。ERP系统每天处理海量业务和数据，如销售订单行76万，应付开票行21万，会计分录行1500万，如此复杂场景下要做到业务无感、数据不乱，相当于飞机在飞行中换“发动机”。为此开发了一整套切换工具，如具备 “自动配线架”功能的ERP伴侣，实现异构ERP灵活切换能力，切换时外围系统用户可正常下单和作业；如数据迁移工具，35小时完成高度关联的3200亿行数据搬迁验证，利用周末时间完成ERP搬迁，不影响企业正常运转。</p><p>3. 系统全面验证，提前识别和解决问题。ERP运行业务场景多达2000个，实时要求高，数据处理量多达160T，如何全面高效验证系统是替换能否成功的关键保障，我们通过并行验证将生产环境业务流量实时导入新系统，用真实场景验证，做到上线后“0”缺陷；通过自动化测试解决海量复杂测试场景，测试周期从最初的3个月缩短到7天。</p><p></p><p>三、“上下同欲者胜，风雨同舟者兴”，ERP的成功替换，离不开一路与我们集众智、聚众力的同路人，这不仅是华为的胜利，也是中国软件产业链的共同胜利！</p><p></p><p>1. 感谢业务与IT共同组建的混编团队，你们是强渡大渡河的“勇士连”。华为云、2012实验室等技术团队在一个个技术山头上一起攻坚克难；财经，供应、采购、交付、销售等业务领域在场景设计和验证上一起共建共验；HR、慧通、行政等部门及时有力地提供服务保障；感谢你们一路同行、始终如一。</p><p>2. 感谢我们的伙伴，你们是强渡大渡河的同路人。感谢在ERP替代和IT BCM过程中帮助我们的金蝶、用友、奇安信、天喻、金山、永洪、元年等战略合作伙伴，一起打造企业核心商业系统的“中国砖”；也感谢在ERP维稳、解耦、换芯过程中把华为三十多年管理实践落地到这套系统中的生态伙伴，一起构建了先进的工程方法和丰富的业务应用，感谢大家与华为携手同行、风雨同舟。希望通过华为打造根技术实现“根深”，战略合作伙伴造好“中国砖”实现“干壮”，生态伙伴打造行业应用实现“枝繁叶茂”。</p><p>3. 最后，我要向今天获奖团队和所有对项目做出贡献的英雄们致以敬意。感谢你们在这场漫长而艰苦的战役中的不懈努力和付出，也要特别感谢那些默默支持我们的家人们，是你们的理解、信任和支持，让我们可以专注工作，坚定不移地走到最后胜利。</p><p></p><p>“为有牺牲多壮志，敢叫日月换新天”，ERP的成功“强渡大渡河”，是华为和中国软件全产业链共同努力的成功，是“没有退路就是胜利之路”精神的践行，我们要继续坚持底线思维，持续艰苦奋斗，围绕“极简架构、极高质量、极低成本、极优体验”的目标，在ERP、PLM等领域，和伙伴一起打造不受制于人、更加高效安全的企业核心商业系统。</p>",
    "publish_time": "2023-04-21 11:47:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "年薪高达7位数，甚至无需任何技术背景就能上手，AIGC让这个岗位一夜爆火",
    "url": "https://www.infoq.cn/article/teJtsgJuh2lou9FAlIt5",
    "summary": "<p></p><p>AI催生的新岗位正在兴起 —— 年薪高达六位数（以美元为单位计算），而且无需计算机工程学位，甚至“精通编程”都不是必要条件。</p><p></p><p>随着生成式AI一路起飞，不少公司开始聘请“提示工程师”。他们的工作就是训练新兴的AI工具，引导它们对实际问题给出更准确、相关性更强的回应。</p><p></p><p>其中部分岗位的年薪甚至高达33.5万美元（约合230万人民币）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4e/4ea52f8dece9f14e0d52f22f54761653.png\" /></p><p></p><p>与传统编码工作不同，只要您具备基础编程技能并熟悉大语言模型（例如ChatGPT或者Bard），就有机会担任提示工程师。</p><p></p><h2>提示工程师是干啥的？</h2><p></p><p>29岁的Anna Bernstein目前在位于纽约的生成式AI公司Copy.ai担任提示工程师，她也是这个新兴领域中为数不多的从业者之一。</p><p></p><p>她的工作内容包括编写文本提示，将提示词输入AI工具后端，借此引导大语言模型生成具有适当证据和准确信息的博文或者营销邮件。整个过程无需编写任何代码，她要做的就仅仅是向AI模型输入指令来不断优化响应。</p><p></p><p>Bernstein于2021年9月加入Copy.ai公司，这时候距离OpenAI推出轰动全球、能够生成优雅文字并回答几乎所有问题的ChatGPT还有一年时间。</p><p></p><p>“我们这样的提示工程师并不多，很长一段时间我感觉好像就只有自己在做这方面工作。当时还不存在「提示工程师」这个概念，大家甚至不确定这个岗位会不会存在。”</p><p></p><p>Bernstein在大学攻读的专业是英语，在担任提示工程师之前曾作过撰稿人和历史研究助理。“我没有任何技术背景，但人文学科的教育背景和积累似乎成了我的优势，毕竟AI开发的一部分目标就是模仿人类思维。”</p><p></p><h2>AI相关岗位激增</h2><p></p><p>提示工程如今成为最热门的技术工作之一，众多企业都在寻求可行的方法来训练和微调AI工具，避免这些新的大语言模型动不动输出一些错误甚至是有毒的结果。</p><p></p><p>对提示工程人才的需求，也反映出市场对AI工具的热烈追捧。</p><p></p><p>根据《时代周刊》分享的LinkedIn数据，2021年至2022年之间，提及“生成式AI”的帖子数量较上一年增长了36倍，包含“GPT”字样的招聘岗位增加了51%。新岗位对求职者的教育背景要求也更为宽松，开始欢迎那些不具备计算机科学或者技术背景的申请者。</p><p></p><p>目前还很难判断提示工程这块业务能发展到怎样的规模，但不少企业和行业确实启动了相关招聘。</p><p></p><p>作为由谷歌支持的AI初创公司，Anthropic开始在旧金山地区招聘“提示工程师与素材管理员”，开出的年薪高达33.5万美元。岗位描述中要求，申请者必须“具备创造性的极客精神、热爱解决难题”。自动文档审阅工具Klarity则为机器学习工程师开出最高23万美元的年薪，要求申请人“提示并了解如何让AI工具生成最佳输出”。</p><p></p><p>在科技行业之外，波士顿儿童医院和咨询公司博思艾伦最近也发布了提示工程职位的招聘信息，后者为拥有三年以上机器学习模型操作经验的申请人开出高达21.2万美元的年薪。演员唐纳德·格洛弗（Donald Glover）甚至打算为自己新开的创意工作室聘请一名提示工程师兼提示动画师。</p><p></p><p>可尽管岗位头衔里有“工程师”字样，Bernstein并不觉得她真有资格自诩是工程技术人员。“刚开始的时候，我们用的名头是提示专家。后来才出现了提示工程师这个专有名词。”</p><p></p><h2>如何成为提示工程师</h2><p></p><p>提示工程专家Rob Lennon从去年12月开始，通过Kajabi开放付费线上课程，希望帮助更多普通人学习提示工程所需要的技能。他的两门课程已经吸引到约2000名学员，其中演示了如何为不同类型的任务和领域设置相应的提示格式和结构。</p><p></p><p>Lennon表示，“人们迫切想要掌握这些知识，都想让自己拥有先发优势。”这些课程起价为150美元，定制培训和课程认证费用最高可达3970美元。</p><p></p><p>但另一方面，不少专家则认为随着AI愈发强大并拥有自主生成提示的能力，提示工程也将很快销声匿迹。 宾夕法尼亚大学沃顿商学院副教授Ethan Mollick警告称，希望担任提示工程师的朋友们最好冷静一点，毕竟生成式AI行业的未来仍有很多变数。</p><p></p><p>在他看来，“目前还不清楚提示工程能否长期存在，毕竟AI程序在预测用户需求和生成提示方面已经做得越来越好。我们也不知道提示工程到底涉及哪些特定技能，或者说只需要花大量时间跟聊天机器人沟通。”</p><p></p><p>Lennon也认为，目前市场提供的高薪可能不会持续太久。“能胜任这些岗位的群体可能只有500个人，所以薪酬才高得离谱。但在半年之内，也许将有5万人有能力做好这份工作，这势必会导致知识价值的快速贬值。”</p><p></p><p>Mollick还指出，有意探索这个领域的人们应该先在GPT+和Bard上做点试验，琢磨出自己的一套提示方法，而不是急于参加线上课程。毕竟如今的AI系统变化极快，现在有效的提示可能会很快过时。“我担心人们过度依赖教学内容，误以为有什么神奇的提示操作技巧。”</p><p></p><p>考虑到人们对AI的浓厚兴趣，LinkedIn公司首席经济学家Karin Kimbrough认为，企业雇主也必须尽快转变关注方向。如果继续像过去那样专注于特定技能方向和具备固定教育背景的求职者，那他们很可能难以为新兴岗位找到合适人选，甚至得跟同行们展开一场激烈的人才争夺。“AI技术的突破其实来得有些晚了，所以企业一定得把握住实际技能才是关键的心态，以技能至上的思路看待这些新近出现的岗位需求。”</p><p></p><p>但也有人对看似火热的市场表示怀疑，毕竟科技企业刚刚才完成几波大规模裁员。**但拥有AI力量的科技企业家们则坚信，提示工程有望全面起飞并重塑自动化的新面貌。**特斯拉前AI主管Andrej Karpathy最近就发推文称，“英语才是目前最热门的编程语言。”</p><p></p><p>即使如此，我们恐怕还是很难相信像提示工程这类对教育背景要求不严的岗位能长期维持六位数的年薪水平。</p><p></p><p>Bernstein也承认目前的趋势也在引发质疑，比如批评人文学科出身的员工居然能跟技术出身的员工拿到同等报酬。她的回答非常简单：“为什么不行？决定这一切的是对产品的贡献度，只要贡献相当就可以薪酬对等。”</p><p></p><p>参考链接：</p><p></p><p><a href=\"https://time.com/6272103/ai-prompt-engineer-job/\">https://time.com/6272103/ai-prompt-engineer-job/</a>\"</p><p></p><p><a href=\"https://thenextweb.com/news/prompt-engineering-hottest-job-in-tech-paycheck\">https://thenextweb.com/news/prompt-engineering-hottest-job-in-tech-paycheck</a>\"</p>",
    "publish_time": "2023-04-21 12:22:59",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "叫板ChatGPT？Stability AI 开源语言大模型 StableLM，参数仅为GPT-3百分之四，却能实现超高性能",
    "url": "https://www.infoq.cn/article/kps1yUUKJU1dSLI68lZz",
    "summary": "<p></p><p>4 月 20 日，AI 作画神器 Stable Diffusion 背后公司 Stability AI 发布了新的开源语言模型 StableLM。</p><p>这套模型的 Alpha 版分 30 亿和 70 亿参数两个版本，后续还有 150 亿到 650 亿参数的更多模型变体。</p><p>开发人员可以出于商用或研究等用途，自由体验、使用和微调 StableLM 基础模型，但须遵守 CC BY-SA-4.0 许可条款。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/68/68ae7f7f76615d8e3cedcedb5c511379.png\" /></p><p></p><p>“一只随意样式的鹦鹉，扁平设计，矢量风格” — Stable Diffusion XL</p><p></p><p>2022 年，Stability AI 公开发布了 Stable Diffusion。这套革命性的图像模型，标志着不同于专有 AI 的透明、开放、可扩展替代方案已经出现。</p><p></p><p>随着 StableLM 模型套件的推出，Stability AI 继续践行着让每个人都能用上基础 AI 技术的基本宗旨。StableLM 模型能够生成文本和代码，并将为一系列下游应用程序提供支持。项目的意义，在于展示小规模高效模型如何通过适当训练提供出色的性能。</p><p></p><p>StableLM 的发布，建立在 Stability AI 与非营利性研究机构 EleutherAI 的早期开源语言模型的经验之上。这里的早期开源模型包括 GPT-J、GPT-NeoX 和 Pythia 套件，并在 The Pile 开源数据集上进行训练。近期众多开源语言模型同样以这些努力成果为基础，例如 Cerebras-GPT 和 Dolly-2 等。</p><p></p><p>StableLM 利用 The Pile 上的新实验数据集进行训练，但模型规模增大了 3 倍，包含 1.5 万亿个内容 token。</p><p></p><p>Stability AI 表示，将在适当的时候发布关于数据集的细节信息。这套数据集的高丰富度，使得 StableLM 在会话和编码任务中表现出惊人的高性能，且继续保持着相对较小的参数量——只有 3 亿至 70 亿之间（与之对应，GPT-3 拥有 1750 亿个参数）。</p><p></p><p>Stability AI 还发布了一系列经过指令微调的研究模型。这 5 套经过开源数据集微调的模型均为对话智能体，分别为 Alpaca、GPT4All、Dolly、ShareGPT 以及 HH。目前这些模型仅供研究用途，基于非商用 CC BY-NC-SA 4.0 发布，且遵循斯坦福大学的 Alpaca 许可。</p><p></p><p>以下各图，为 70 亿参数微调模型生成的对话示例：</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5a/5aa9f9d65eca616ad104d2485e557ed3.jpeg\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2a/2a1c0a06e442421aaa7f6a6061799a5c.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/37/37f5ee00aa8c824ada6b7d0c65ace3ac.jpeg\" /></p><p></p><p>Stability AI 表示，“语言模型将构成我们数字经济的支柱，我们希望每个人都能为模型设计提出意见。以 StableLM 为代表的这批开源模型，也再次践行了我们对于打造透明、可访问、支持性 AI 技术的承诺”：</p><p></p><p>透明。通过模型开源以提高透明度并建立社区信任。研究人员可以“深入了解”模型以验证其性能、研究可解释性技术、识别潜在风险并协助制定保障措施。公共和私营部门能够针对自己的应用场景调整（「微调」）这些开源模型，且无需共享敏感数据或放弃对 AI 功能的控制权。</p><p></p><p>可访问性。在设计中考虑到边缘用例，确保日常用户能够在本地设备上运行的模型。利用这些模型，开发人员可以构建与各类常见硬件相兼容的独立应用程序，而无需依赖于少数一、两家企业的专有服务。通过这种方式，AI 的经济利益将被真正分享给广大用户和开发者社区。相较于神秘的闭源模型，更开放、允许细粒度访问和广泛研究的开源模型将为学术社区提供更好的可解释性和安全技术。</p><p></p><p>支持性。Stability AI 之所以构建模型，是为了向用户提供支持、而非将其取代。Stability AI 专注于打造高效、专业且实用的 AI 性能，而不是追求建立起如神般全知全能的人工智能。Stability AI 开发的工具能够为普通人和普通企业赋能，帮助他们释放创造力、提高生产力并开辟新的经济机会。</p><p></p><p>这些模型目前已经发布了 Stability AI 的 GitHub 代码仓库上（https://github.com/stability-AI/stableLM/）。</p><p></p><p>此外，Stability AI 将启动基于人类反馈的强化学习（RLHF）众包计划，并与 Open Assistant 等社区合作，共同为 AI 助手创建一套开源数据集。</p><p></p><p>参考链接：</p><p>https://stability.ai/blog/stability-ai-launches-the-first-of-its-stablelm-suite-of-language-models</p>",
    "publish_time": "2023-04-21 12:58:31",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何让AI读懂“人话”？中关村科金任务型多轮对话的实践与探索 | 对话式AI系列",
    "url": "https://www.infoq.cn/article/mU2TYb5yvAKqA2yw7Jzq",
    "summary": "<p></p><p></p><blockquote>任务型多轮对话是对话式 AI 的必由之路。</blockquote><p></p><p></p><p>移动互联网带来了大数据的普及，摩尔定律预言了计算机硬件的发展，深度学习则借助这阵东风实现了技术上的突破，人工智能成功进入大众视野，并改变了人们的日常生活。</p><p></p><p>“小 X 同学，请打开电视”、“小 X 小 X，请播放音乐”...... 如今，很多年轻人的生活不再像以前一样，只需要动动嘴，就可以控制家里的各种设备。</p><p></p><p>根据全球著名调研咨询机构 IDC 发布的《中国全屋智能设备和解决方案市场回顾和展望》，2021 年中国智能家居设备出货量超过 2.2 亿台，同比增长 9.2%；2022 年中国全屋智能市场销售额将突破百亿，预计同比大幅增长近 55%；到 2023 年，智能家居将会成为物联网支出最高的领域之一。</p><p></p><p>而想要实现通过语音对话的方式来控制家中智能设备，对话式 AI 技术是必不可少的一环。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b4/b4af045ab5f9be4fc57b5f662e09b91a.png\" /></p><p></p><p></p><p></p><h2>任务型多轮对话是对话式 AI 的必由之路</h2><p></p><p></p><p>目前，对话式 AI 主要应用的场景有三种，分别是闲聊型、问答型和任务型。</p><p></p><p>闲聊型：多用于情感陪伴，但由于整体技术水平还未达到人们的心理预期，现阶段商业化并不太成功；</p><p></p><p>问答型：多见于客服系统，能够解决用户的一些事实性问题，但功能上较为局限；&nbsp;</p><p></p><p>任务型：多用于 B2C 类应用，能够将非结构化数据充分利用起来，沉淀企业知识，是企业数字化转型赛道上的关键技术。</p><p></p><p>由于目前的技术水平还处于弱人工智能阶段，全面实现对话式 AI 比较困难。任务型多轮对话因具有较好的可解释性，且易于把控，是以点及面实现完整的对话式 AI 的理想途径。</p><p></p><p>任务型多轮对话是对话式 AI 的外延之一，专注于封闭域下的问题解决。</p><p></p><p>任务型多轮对话的定义是：根据上下文内容，进行连续的、以达到解决某一类特定任务为目的的对话。需要注意的是，任务型多轮对话有三个关键要素，多轮、连续性、封闭域。</p><p></p><p>多轮：与单轮的问答不同，多轮对话解决复杂条件下的问答，需要结合上下文理解多项约束条件，每一次应答都与上下文有强关联关系。</p><p></p><p>连续性：对话需要具备连贯性，一旦捕获到用户意图，则将以完成此任务为目标，进行持续性的对话。</p><p></p><p>封闭域：某一类特定问题表明了对话是受限的，即这是一个封闭域上的问题。对话系统仅负责某个领域下已知的一系列任务，比如说订机票，订外卖，或者查天气等等。</p><p></p><p></p><h2>任务型多轮对话系统的技术架构设计</h2><p></p><p></p><p>目前主流的任务型多轮对话系统依然沿用了模块化的方法，其技术架构如下所示，包含以下几个模块：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/66/66c2a640ea4a45dc78296c2f8930476a.png\" /></p><p></p><p>图 1 多轮对话系统架构图</p><p></p><p>输入模块：接收用户传达的信息，包括语音、图像、文本等。对于语音类信息，通常使用语音识别（Automatic Speech Recognition, ASR）技术转化为文本。而对于图像类信息，目前研究较少，可行的方案包括通过文字识别（Optical Character Recognitionm, OCR）技术将识别图像中的文字转化为文本，或者使用机器学习训练编码器，将图像转化成视觉语义编码。</p><p></p><p>解析模块：对输入的信息进行解析，转化为机器可理解的语义表示。以文本信息及框架语义表示为例，此模块依赖于自然语言理解（Natural Language Understanding, NLU）技术，需要从文本信息中识别出用户的意图（Intent）以及该意图下的语义槽（Slot）。例如“附近有什么比较火的粤菜馆？”，用户意图是“搜寻餐厅”，语义槽是“地点”为“附近”，“热度”为“高”，“菜系”为“粤菜”。</p><p></p><p>对话管理模块：根据解析模块输出的语义表示，更新对话状态，并根据策略选择应答动作。此模块主要包括对话状态跟踪（Dialogue State Tracker, DST）和对话策略学习（Dialogue Policy Learning, DPL）。对话状态跟踪负责维护多轮对话的状态，根据历史对话状态、解析模块当前的输入以及背景知识库综合得到新的对话状态。此模块的主要功能就是记忆与预测，通过与用户间的不断交流，逐渐完善对用户状态的观察。对话策略学习根据 DST 模块输出的当前对话状态，来决策系统采取的动作。例如解析模块的例子，此模块则会选择“搜索”动作，查询以用户当前定位为中心，一定范围内的高浏览量粤菜餐厅。</p><p></p><p>解码模块：与解析模块相反，此模块的任务是将系统结果以人类可以理解的方式解码，通常就是转化为自然语言。例如系统查询到的餐馆在数据表中 ID 为\"r008\"，转化为自然语言可以是“您好，附近热度最高的粤菜馆是金鼎轩，位于 xxx 路 xxx 号，距您 1.1km。\"</p><p></p><p>输出模块：此模块以输入模块相同的形式将解码模块产生的结果反馈给用户，如聊天框、麦克风等。而自然语言想要转化为语音，则需要使用到语音合成（Text To Speech, TTS) 技术。</p><p></p><p></p><h2>业内主流的任务型多轮对话系统平台</h2><p></p><p></p><p>经过多年的发展，任务型多轮对话领域涌现了众多优秀的公司，尽管基础技术差异不大，但在钻研方向上各家却有着自身的特色，下面介绍几个典型案例。</p><p></p><h4>预训练对话模型 — 谷歌 LaMDA</h4><p></p><p></p><p>谷歌 LaMDA 是工业级端到端的预训练对话模型。众所周知，目标决定方向，如何定义模型的训练任务与损失函数，将决定训练方向与最终效果。谷歌重新定义了三个评价指标，Sensibleness, Specificity, Interestingness（是否合理、符合上下文、有创造力）、Safety（是否有风险、不公正）、Groundedness、Informativeness（在知识型问答中，是否包含真实的信息、并引用相关链接），并借此构建分类任务精调模型，提升了模型的对话能力。</p><p></p><p>相比其他对话系统，LaMDA 具有蕴含知识、回复更加灵活等优势，但其不可控性、逻辑能力差等缺点也是极为明显的。然而就在大众对于此类“人工智障”逐渐失望之际，12 月 openAI 推出的同类型的大模型 chatGPT 着实让人惊艳，或许此类对话系统依然是通往终点的一条途径。</p><p></p><p></p><h4>领域预建模型 — Senseforth.ai</h4><p></p><p></p><p>Senseforth 成立于 2017 年，是一家印度对话式人工智能服务商。根据 Gartner 统计，目前 Senseforth 的企业级对话式人工智能平台每月处理超过 1.9 亿次对话，准确率超过 96%。</p><p></p><p>通过大量行业实践，Senseforth 创建了对话式人工智能机器人商店，该商店拥有行业预建模型和领域知识，适用于一系列垂直行业，包括银行、保险、零售、医疗保健、电信和酒店等。Senseforth 尤其专注于 NLU 模块，将意图与实体分开训练，支持快速新增、修改意图，其解决方案中包含 4 万多意图与大量的预置意图库。</p><p></p><p>除了对话式人工智能机器人外，Senseforth 还涉足对话式分析、对话式营销、代理协助、知识管理和智能搜索等技术服务。</p><p></p><p></p><h4>低代码与自动化— Cognigy</h4><p></p><p></p><p>Cognigy 是一家总部位于德国的对话式 AI 服务提供商，成立于 2016 年，旨在提高企业客户服务团队的工作效率。通过将对话式 AI 技术与商业智能、客户关系管理、企业资源规划工具整合，Cognigy 帮助企业用户通过简单对话形式访问实时数据，实现无缝连接关键操作触点。</p><p></p><p>Cognigy 亦专注于低代码平台搭建，结合流程自动化技术，允许企业使用智能 AI 机器人和聊天机器人自动化客户和员工通信。</p><p></p><p></p><h2>任务型多轮对话在中关村科金的实践</h2><p></p><p></p><h4>企业目前存在的痛点</h4><p></p><p></p><p>目前任务型多轮对话系统的技术框架、各模块的细化技术选型都已经较为成熟，但是在实际实践中，我们发现依然存在着定制化程度高、回答生硬、使用门槛高等诸多问题。</p><p></p><p>定制化程度高：任务型多轮对话依赖专家经验，需要预先梳理出领域本体结构，用户的意图及每个意图对应的槽位，针对每个任务还需要设计其对应的故事线，因此不同行业、甚至不同公司都需要根据具体情况来定制。</p><p></p><p>非生成式应答生硬：任务型多轮对话的应答通常是非生成式的，采用的方法往往是枚举、模板等，因此，回复会显得比较生硬，影响客户体验。</p><p></p><p>难以适应语言环境的变化速度：自然语言的创造力很强，变化也非常快，例如“碳交易”、“元宇宙”、“预制菜”、“政银担”等等，新词的出现对于对话系统是很大的考验，需要考虑如何设计产品以跟上快速变化的语言环境。</p><p></p><p>系统使用门槛高：对于系统使用人员来说，构建一个完整的任务型对话机器人具有一定的专业门槛，其中涉及到大量的机器学习模型，如何训练模型、优化模型等，难度都会比较大。</p><p></p><p></p><h2>中关村科金的解决方案</h2><p></p><p></p><p>针对任务型多轮对话系统中存在的挑战，中关村科金提出了自己的解决方案。</p><p></p><p></p><h3>沉淀行业知识，抽象领域通用能力</h3><p></p><p></p><p>针对定制化程度高、非生成式应答生硬的问题，中关村科技的解决方法是定义完善的标签体系与领域实践模板，将知识进行沉淀。</p><p></p><p>据了解，目前中关村科金基于数亿人机对话语料，构建了 100+ 通用实体与意图，帮助客户快速搭建自身领域的标签体系。另外，在某些特定领域，例如金融行业，中关村科金积累了大量行业标注语料，形成了自有的领域实践模板，同领域的客户可以直接应用“现有模板”，避免从 0 到 1 的冷启动阶段，加速项目落地应用。</p><p></p><p></p><h4>&nbsp;借助流程挖掘，构建领域特定故事</h4><p></p><p></p><p>如果我们把多轮对话看作流程，借助流程挖掘技术，就可以从海量数据中绘制出流程图，辅助专家抽象领域 SOP。而基于已有 SOP 的实践，又可以通过流程挖掘的 Replay 技术，完成对关键话术节点、风险对话节点等的感知与预测，针对性的优化改进，进一步完善领域 SOP，助力客户业务增长。</p><p></p><p>在实际的应用中，流程挖掘已经成为中关村科金帮助客户实现领域标准对话程序的关键技术。</p><p></p><p></p><h4>通过闭环迭代，实现智能化运营</h4><p></p><p></p><p>多轮对话依赖于底层知识库与模型，中关村科金通过人机闭环链路，实现了非专业运营的智能化迭代优化。</p><p></p><p>对于知识库，通过知识发现、知识细化、知识优化、知识淘汰四步，运营人员仅需对部分新知识进行审核，即可实现知识库的快速迭代更新。</p><p></p><p>而在模型方面，中关村科金自研的自训练平台，提供了业务中积累的大量规则、模型算子，通过少量的配置，运营人员即可实现模型的优化，降低了学习成本，解决了对话系统使用门槛高的问题。</p><p></p><p>以营销行业为例，中关村科金基于对话式 AI 技术，通过将 MAP 平台、智能外呼机器人、文本机器人、RPA 结合，构建一体化营销云产品。在为某消金线上业务服务中，将营销的 SOP 流程标准化后沉淀下来，配置在营销自动化模块中，基于用户分层实现自动化群发、自动化回复、自动化标签等，打造全新的私域自动化运营体系，营销转化率提升 30%、人力成本下降 60%，帮助客户实现降本增效。</p><p></p><p></p><h4>任务型多轮对话的未来发展趋势</h4><p></p><p></p><p>因其可控性，在可预见的未来任务型多轮对话依然将是对话系统的主要表现形式之一。随着技术的不断提高，中关村科金认为以下三个方面会是任务型多轮对话的未来发展方向。</p><p></p><p>1）冷启动始终是 AI 所不可避免的问题，如何基于现有的大量未标注数据，快速实现对话系统的搭建值得深入研究；</p><p>2）机器学习模型目前还停留在感知智能的阶段，并没有真正理解对话中的含义，同时欠缺对于领域知识、常识知识的应用。引入领域知识和常识知识，并且能够进行知识的推理，将极大的提高对话系统的实用性与竞争力；</p><p>3）语言不是唯一的交互途径，人类的表达方式是多种多样的，人机对话系统的交互方式必将向多模态的方向发展。</p><p></p><p>未来，中关村科金将不断提升多模态对话式 AI，尤其是任务型对话的技术实力与场景落地能力，抓住这一企业数字化转型赛道上的关键技术，助力企业数字化变革。</p>",
    "publish_time": "2023-04-21 13:09:39",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "毫末智行联手火山引擎打造自动驾驶生成式模型 DriveGPT；滴滴自动驾驶卡车 KargoBot 首次亮相上海车展；马斯克称特斯拉今年推出全自动驾驶技术 | 汽车技术新闻速...",
    "url": "https://www.infoq.cn/article/TcyBBTxQx5GKREO4N7wL",
    "summary": "<p>马斯克称特斯拉今年推出全自动驾驶技术；<a href=\"https://www.infoq.cn/article/KKaEhGYQizY2t1SKJbxi\">滴滴自动驾驶</a>\"卡车 KargoBot 首次亮相上海车展；腾讯构建“车云一体”数据驱动应用框架；<a href=\"https://www.infoq.cn/article/VGUtm2FRjkYtOZzqfehi\">毫末智行</a>\"联手火山引擎打造自动驾驶生成式模型 DriveGPT……一文速览汽车技术领域新动态！</p><p>&nbsp;</p><p></p><h4>马斯克称特斯拉今年推出全自动驾驶技术，汽车价值将大幅提升</h4><p></p><p></p><p>特斯拉 CEO 马斯克近期表示，特斯拉可能会在今年推出完全自动驾驶（FSD）技术，并且这项技术将带来可观的利润，抵消一些由于大幅降价而造成的利润压力。特斯拉目前称其 FSD 软件为测试版，马斯克说，“每次发布之间都会有两步前进，一步后退的情况，但趋势非常明确，就是向着全自动驾驶、向着全自主方向发展。”</p><p>&nbsp;</p><p></p><h4>哪吒汽车：基于地平线征程 5 芯片的合作车型 2024 年量产</h4><p></p><p></p><p>4 月 19 日消息，在 2023 年上海国际汽车展览会上，哪吒汽车与<a href=\"https://www.infoq.cn/article/N4615IQwPjOcsX64Yh0c\">地平线</a>\"签署全面深化战略合作协议。哪吒汽车将基于高等级智能驾驶专用芯片征程 5，围绕BEV等算法技术合作，打造高阶 NOA 智能辅助驾驶系统。该系统将应用于多款车型，首款合作车型将于 2024 年量产落地。与此同时，双方基于芯片征程 3 的合作，从已有的哪吒 U-II 拓展至哪吒全系列更多车型。新车哪吒 GT 搭载了征程 3 芯片，实现 L2 级辅助驾驶功能。据了解，作为地平线第三代车载智能芯片，征程 5 搭载了基于软硬协同设计理念的 BPU 贝叶斯架构，兼具性能和算力，能够支持如 BEV 等智能驾驶算法模型的应用部署。</p><p>&nbsp;</p><p></p><h4>滴滴自动驾驶卡车 KargoBot 首次亮相上海车展</h4><p></p><p></p><p>4 月 19 日，在第二十届上海国际汽车工业展览会上，滴滴自动驾驶货运 KargoBot 首次亮相。据了解，KargoBot 打造了一款最适合大宗货运的混合无人化解决方案，能实现短、中、长途各种复杂场景的端到端物流运输。此外，KargoBot 面对复杂场景的处理能力提升了 50 倍，核心的安全指标提升了 20 倍，同时能有效降低风阻，减少 5-10% 的能源消耗。KargoBo 负责人韦峻青博士还透露，在计算方案上，KargoBot 已与地平线达成战略合作，双方将发挥各自优势，基于征程系列芯片开发具备高性能、高可靠性和高冗余能力的无人驾驶卡车域控制器产品，助力自动驾驶卡车提供更安全平稳的运输服务。</p><p>&nbsp;</p><p></p><h4>腾讯智慧出行技术开放日：构建“车云一体”数据驱动应用框架，让车更智能</h4><p></p><p></p><p>近日，腾讯召开了“2023 TIME DAY·腾讯智慧出行技术开放日”。会上，腾讯全面展示了深耕“车云一体”领域的技术和产品体系。腾讯智能汽车云能力进一步升级，云上云下一体化自动驾驶存储方案，可实现单个集群百万存储节点规模，10EB 容量，每桶 1 万亿个对象，与行业平均水平相比节省 50% 的成本。在 AI 训练环节，IO 性能提升 10 倍。同时，面向城市级智能驾驶场景，腾讯推出了 HD Air 轻量级高精数据产品，预计 2023 年底将覆盖 50 座城市。腾讯集团高级执行副总裁、云与智慧产业事业群 CEO 汤道生在开场致辞中表示：“腾讯将做好汽车产业数字化升级助手，借助‘车云一体’，实现从研发到运营全链条的降本增效，帮助车企造好车、卖好车；也帮助车主用好车。联合产业链合作伙伴，共创产业新生态，助力汽车产业不断迈向新的台阶。</p><p>&nbsp;</p><p></p><h4>毫末智行联手火山引擎，打造自动驾驶生成式模型 DriveGPT</h4><p></p><p></p><p>4 月 18 日，毫末智行 CEO 顾维灏受邀参加火山引擎 Force 原动力大会，并在会上分享了与火山引擎的合作成果。4 月 11 号，毫末智行发布了应用于自动驾驶生成式模型 DriveGPT，目前，DriveGPT 已拥有 4000 万公里量产车驾驶数据，参数规模 1200 亿。毫末智行与火山引擎共同发力，在算力端做了大量优化，高性能计算、高性能存储、高性能网络并举。基于海量真实人驾数据预训练的大模型，在 RLHF加持下，通过不断输入真实人驾接管数据，持续优化自动驾驶决策模型，借鉴海量真实驾驶数据，在不同路况、天气和变量下，做出最优解，将 Hardcase 通过率提升 48%。顾维灏表示，相信这种 GPT 的技术范式，可以广泛应用在城市辅助驾驶、高速辅助驾驶、困难场景脱困、智能推荐，智能陪练等多元化场景。同时，随着用户规模和持续的使用里程不断扩大，在大数据、GPT、用户反馈、强化学习等支持下，DriveGPT 也将重塑汽车智能化技术路线，让自动驾驶更早到来，让消费者能够更安全的体验到专属司机的乐趣。</p><p></p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-04-21 14:08:01",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "微众银行勇担金融科技开源“探路者”；京东供应链金融科技 Lite 版“轻量”发布 | 金融科技新闻速览（4.19-4.21）",
    "url": "https://www.infoq.cn/article/GPXgtxsWXyVLaKwLYJFH",
    "summary": "<p><a href=\"https://www.infoq.cn/video/ClldtSRLIKa9U0mcPY7Q\">微众银行</a>\"勇担金融科技开源“探路者”；京东<a href=\"https://www.infoq.cn/article/LNdtkxHuV3hxITGQxVmJ\">供应链金融</a>\"科技 Lite 版“轻量”发布；农商银行数字金融联盟正式发布“CLUB”……一起看看金融科技领域新动态！</p><p>&nbsp;</p><p></p><h4>主导两个开源顶级项目——微众银行勇担金融科技开源“探路者”</h4><p></p><p></p><p>近日，Apache 软件基金会（下称“ASF”）正式宣布，由微众银行主导的开源项目——Apache EventMesh 毕业成为顶级项目（TLP），这也是微众银行主导并毕业的第二个 Apache 顶级项目。在国家政策的指引下，微众银行更坚定地推动开源技术发展。自 2019 年宣布金融科技全面开源以来，微众银行陆续在“ABCD”（人工智能、区块链、云计算和大数据）等多个开源领域取得优异成果。2019 年，微众银行加入 Linux 基金会成为黄金会员，并捐献全球首个工业级联邦学习框架 FATE；围绕区块链底层平台 FISCO BCOS 为基础构建的开源社区，形成了最大最活跃的国产开源联盟链生态圈之一等。微众银行在践行金融科技全面开源的同时，也为全行业开源创新发展充当了“探路者”的角色。基于自身业务发展需求、对创新技术的高度敏感性，微众银行在合规的范围内勇于尝试新兴技术，先后主导了 Apache EventMesh 和 Apache Linkis 两个顶级项目，不仅为各行业提供有效的解决方案、为金融机构开源提供了有效的开源经验借鉴，还探索出一条可提升创新软件国际影响力的有效路径。</p><p>&nbsp;</p><p></p><h4>京东供应链金融科技 Lite 版“轻量”发布</h4><p></p><p></p><p>近日，供应链金融行业又迎来一大新品——京东供应链金融科技平台 Lite 版。<a href=\"https://www.infoq.cn/article/WIRXxsAV4V6HOhRivtmx\">京东</a>\"供金平台 Lite 版通过为核心企业搭建轻量化的供应链金融服务平台，为产业链上下游中小微企业提供更轻快更简单的融资体验。相比传统纯本地化部署模式，供金平台Lite版接入效率可提升 75%，接入时长降为平均三周左右。京东供应链金融科技作为集供应链科技与金融科技于一体的综合服务商，再次向行业亮剑，展示作为科技服务商，在促进“产业-科技-金融”良性循环方面的模式创新与实践引领。未来，京东供应链金融科技还将围绕更多产业场景，提供“数智供应链+供应链金融”的全链路贯通模、以及供金平台 Lite 版轻量化部署的多样化选择，积极助力核心企业数字化升级，为产业链上下游中小微企业的融资可获得性提升加“数”赋“智”。</p><p>&nbsp;</p><p></p><h4>农商银行数字金融联盟正式发布“CLUB”</h4><p></p><p></p><p>近日，第一届全国农商银行金融科技交流大会在杭州召开。会上，由全国21家省级农信系统共同发起的农商银行数字金融联盟正式发布“CLUB”，即以联盟（Union）为新平台，建设“一云（Cloud）一基地（Base）三实验室（Labs）”的新基建，共建共享数字金融综合服务新生态。其中，农商云将提供基础设施（IaaS）、基础平台工具（Paas）、标准应用服务（SaaS）、定制化应用服务等云服务；浙江大学联合科教基地将提供金融科技创新实践的教育培训体系；人工智能实验室、联合创新实验室、联合安全实验室将加快金融科技的前沿探索和实践。</p>",
    "publish_time": "2023-04-21 14:08:04",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "面对频变的企业需求，云基础设施的性能可以拉升到什么样子？",
    "url": "https://www.infoq.cn/article/TADAWBkkqwuECRWMWWU0",
    "summary": "<p>随着云计算技术的高速发展，如今企业对于上云的态度似乎已经非常明确——必须要上。但当我们放眼全球市场，相关报告称，“云”在企业的渗透率可能只有 10%，而在国内，这个数字或许还到不了 10%。这个数字向我们传达出来的信息是，企业对于上云这个事情，虽认可但执行力不足，而这背后的原因值得我们深入探究。</p><p></p><p>4 月 18 日，2023 春季<a href=\"https://www.infoq.cn/article/cX662RHlbwD7SlE1qdGe\">火山引擎 FORCE 原动力</a>\"大会在上海外滩圆满落地，这是一场云计算和数字化领域的盛会。火山引擎在行业实践基础上再次进化，本次大会围绕“敏捷迭代”、“数据驱动”、“体验创新”三大增长要素，重磅发布了在云计算领域的最新技术和产品。作为每年的行业标志事件，本届大会<a href=\"https://www.infoq.cn/article/WKwdgBY1f4wdpjgoSDPf\">火山引擎</a>\"释放出了许多行业信号——企业在获取数字化转型原动力时，对“云”又提出了哪些新要求？火山引擎的敏捷迭代历程映射出了企业哪些需求变化？</p><p></p><p></p><h2>一、“敏捷”是一种业务诉求</h2><p></p><p></p><p>首先可以肯定的是，多云环境是企业的刚需，只是需求各有不同。在上云后，对于传统企业来说，业务已经普遍趋于成熟，爆发式增长不再是核心目标，稳定是业务侧的第一诉求，可能还会保持单云架构，对于这种情况，云厂商的主要任务就是维持老架构平稳运行，实现降本增效。对于有明确增长需求或者比较新型的业务，企业肯定会布局新的技术领域，这就对云厂商的“弹性”和快速迭代的敏捷性提出了挑战。</p><p></p><p>“敏捷迭代”并不是个新概念，2010 年后，它就成为了技术圈的“热词”——也难怪，企业若想跟得上互联网行业日新月异的变化，就必须在技术、业务层面通盘贯彻“敏捷迭代”的思想。十余年来，随着行业及相关方法论的成熟，“敏捷迭代”也成为了企业最核心的诉求。</p><p></p><p>作为“敏捷迭代”思想的坚定支持者，火山引擎主要围绕两个策略展开——“云”和“增长”，而这也是当前所有云厂商必须要解决的事情。企业上云后不一定所有业务都是持续增长的，这就需要做好“弹性”来应对企业需求，同时“云”代表着资源，如何在已有资源上去做好增长是企业最关心的事情。我们当前能看到的，火山引擎为了应对市场需求，很早就已经开始做一些增长类的产品，而依托字节跳动天然的数据优势，火山引擎数据产品确实做到了将自己的能力转化为赋能企业业务发展的能力。</p><p></p><p>具象一点讲，从云基础方面，火山引擎自 2021 年底正式发布第一代产品起，平均一年就会进行一次迭代升级，这个速度在业内是非常快的。据了解，火山引擎的第一代产品在还没发布前就经历了三次大迭代。最初他们通过开源方案来搭建技术体系并支撑架构的快速迭代，后来随着业务的发展，开源方案已经无法满足字节跳动的需求，团队便基于开源的调度方案，在软件层面做了许多重构，比如将许多底层软件的调度引擎换成自研引擎，在 IaaS 层将整个虚拟网络的引擎换成自研引擎等。</p><p></p><p>至 2021 年正式发布时，火山引擎已经基本完成了对公有云初代软硬结合架构的自研。到今年，该架构已经经历了三次大迭代，第一代主要是基于英特尔的 Cascade Lake 处理器；第二代是基于英特尔的 Ice Lake 处理器；第三代基于英特尔第四代<a href=\"https://www.infoq.cn/article/QhpA7gaWGpo3ZRYseHX3\">英特尔®至强®可扩展处理器</a>\"。其中比较有代表性的就是火山引擎 DPU ，DPU 是其自研的一个硬件，同时火山引擎还开发了与其配套的存储软件、网络软件、调度软件及网元网关，力求做到“自研适配”。而在本届火山引擎 FORCE 原动力大会上，火山引擎又在公有云方面围绕稳定可靠、弹性灵活、性能优越、操作便捷的弹性计算发布了多个实例——基于火山引擎自研 DPU 的弹性计算实例及 SPOT 实例。</p><p></p><p>在整个敏捷迭代的过程中，我们可以清晰地看到火山引擎为了满足企业不断变化地需求而做出的敏捷响应。比如面对企业对云原生能力的需求，火山引擎的 PaaS 层产品结合 ECS，帮助企业将原有的云原生能力实现快速迁移；针对企业对 AIGC、ChatGPT 的应用需求，火山引擎基于“云”快速迭代自己的 AI 能力，快速赋能自动驾驶相关企业发展。</p><p></p><p>新网银行和晶泰科技便是火山引擎的两大典型实践。火山引擎帮新网银行在线下部署了混合云方案，使其在满足安全合规的要求下，体验到公有云弹性的同时还达到了降本增效的目标。而晶泰科技作为算力需求比较多的一家企业，火山引擎作为其多云环境的供给商，从引擎等方面给了多方面支持，晶泰科技得到了高性价比及与传统调度相同的用户体验。</p><p></p><p></p><h2>二、不断的“性能拉升”才能满足业务需求</h2><p></p><p></p><p>火山引擎总裁谭待曾指出，“现在中国处于高速发展中，尤其在移动互联网，我们已经走在了世界前列，现在能做的就是不断快速试错，找到创新的方向，唯快不破。”那企业问谁要这个效率？答案其实很简单——云厂商。</p><p></p><p>企业的需求一直在随着业务的发展不断变化，追求敏捷的主要表现其实就是性能的不断拉升以满足业务需求。在赋能更多企业上云，做数智转型这件事上，我们看到火山引擎下了不少功夫，比如从 2023 火山引擎原动力大会的新实例发布中，我们就能看到很多东西。</p><p></p><p>先说基于火山引擎自研 DPU 的弹性技术实例，其真正做到了软硬结合的同时追求极致性能。在百万服务器的规模下，每1%的性能提升都是巨大的成本优化，火山引擎自研的硬件 DPU 实现计算存储网络的全组件卸载，释放更多资源给业务负载，提升算力基础设施效率，性能拉满——全面加速计算、存储、网络云化，网络性能业界领先，整机包量 5000 万 pps，时延低至 20us 。</p><p></p><p>因为有自研 DPU 的支持，使得存储、网络性能实现上由原先的软转逐步切换至硬转，核心价值是能突破之前软转的性能瓶颈并且节约服务器 Host 上的 CPU 以及内存资源，解决了企业对服务器该方面性能要求越来越高的行业痛点。在实例中，火山引擎使用字节跳动自研的虚拟交换机 BVS 配合自研 DPU，其主要是针对自研 DPU 做了一个适配，使 DPU 做到了更高的转发效率和转发带宽的同时，还有更低的网络时延。</p><p></p><p>其次，火山引擎在本届大会上发布了基于 DPU 的裸金属实例，该实例更加适用于大模型等大规模集群分布式训练场景，其可以提高集群并行效率，相较于上一代实例集群性能最高提升 3 倍以上。事实上，火山引擎在弹性裸金属实例的研发方面早就有一定的经验，此次结合高性能 RDMA 网络的新实例开发，主要是针对业务场景做的“性能”、“可靠性”、“故障处理”等专项优化开发。比如在 RDMA 网络的性能调优、整机的带内外监控、故障&amp;亚健康感知以及冷迁移等能力，以满足大模型训练场景对于性能和稳定性的极致追求。据悉，当前异构计算 GPU 实例已交付多个客户，规模已达到数百台。</p><p></p><p>此外，火山引擎还发布了 DPU+Intel 全新一代 SPR CPU 平台的计算实例，整机性能最高提升 93%，单核性能最高提升 13%，小规格实例性能最高提升 6 倍以上。我们可以从本届火山引擎 FORCE 大会上发布的弹性计算实例中发现，火山引擎软硬结合追求极致性能，英特尔提供了不少支持。</p><p></p><p>通过采用最新第四代英特尔®至强®可扩展处理器，火山引擎弹性计算在整个的单核能力、网络转发能力、加解密、视频和AI推理训练能力上都有了大幅提升。从内外部整体来看，火山引擎与字节跳动也会在新一代产品中采用比较激进的策略，转至到更具性价比的产品上来，这一策略从 4 月 12 日刚刚在官网上线邀请测试的火山引擎 g3i 产品中体现得淋漓尽致。</p><p></p><p>g3i 是火山引擎 ecs 最新一代 Intel 通用计算实例产品，其拥有火山引擎全新自研的智能网卡架构、自研网络/存储虚拟化技术，大幅提升了实例 I/O 吞吐能力。从机房建设、物理网络等基础设施层面，其采用高可用设计，采用丰富的故障规避手段，使该产品表现出了较高的稳定性。该实例产品搭载第四代英特尔®至强®可扩展处理器，整机性能最高提升了 93%，英特尔从四个方面帮助其实现了性能突破：</p><p></p><p>工艺：第四代英特尔®至强®可扩展处理器采用了英特尔最新的 Intel 7 制程技术，从 14 纳米走向了 10 纳米，整个晶体管的密度增加了 2. 7 倍，算力进一步增强的同时，带来了更高的能耗比。系统架构：全面升级为 DDR5 内存的第四代英特尔®至强®可扩展处理器，进一步增加内存带宽，同时通过 PCI-E 5.0 和 Compute Express Link (CXL) 1.1 增加 I/O 接口带宽。智能计算：第四代英特尔®至强®可扩展处理器通过软件定义，硬件加速的方式，将数据加解密，AI推理，内存数据处理等特定的处理流程通过内置相关加速器来实现，将目标工作负载的平均每瓦性能提升了 2.9 倍，为g3i 提供了智能计算支持，追求高效的同时降低功耗，确保将 CPU 资源释放出来给最终用户。软件加持：对基础设施平台进行优化，将底层硬件的加速器以服务/API的方式提供给上层应用，同时对上层应用进行优化，充分利用底层的硬件能力，实现底层平台和上层应用端到端的结合，端到端地优化，底层基础设施赋能上层应用，上层应用感知底层设施能力。</p><p></p><p>而这也验证了火山引擎云基础产品负责人罗浩和英特尔大数据资深首席工程师程从超在接受 InfoQ 采访时说到的——“彼此多年的紧密合作中，英特尔最大的优势就是生态赋能和全栈优化。”有消息称，在当下合作基础上，计算密集型、内存密集型、I/O 密集型以及 HPC 的场景实例，火山引擎未来都会切换到基于第四代英特尔®至强®可扩展处理器的引擎上，用以帮助游戏、汽车、医药、金融等行业，在内外部共同释放算力并提升性价比。</p><p></p><p></p><h2>三、更多的“创新”才能解决“企业新需求”</h2><p></p><p></p><p>目前在国内，云市场是一个非常蓬勃的市场，也是一个充满竞争活力的市场。各家云厂商都有自己的特点，但在这其中，火山引擎这朵新云显得更加与众不同。新云代表着新气象，火山引擎的云没有“历史包袱”，其无论是公有云还是混合云，从最初就是同一个用户体验、同一套架构。无论是从云上资源还是从线下部署方面，用户的使用体验和后面的运维体验几乎都是一模一样的，同时适配了许多新业务场景。</p><p>在本届火山引擎 FORCE 原动力大会上，火山引擎除了“敏捷”，提到最多的就是“场景创新”，从企业业务需求出发，火山引擎的新产品发布、版本升级及布局，还向我们传达出了一个新的信号——企业需要更多的“创新”来解决“新需求”。</p><p></p><p>从网络方面，如果我们想要更好地探讨云的性能，那就一定要谈网络能力。不同业务场景下的网络能力可以分成三类，第一类是普通业务，只要网络能达到通用的水平即可，它的能力主要体现在带宽、时延及并发方面；第二类则涉及到大规模集群类的业务，这类业务对于东西向网络流量和带宽时延都是比较敏感的；第三类便是对南北向网络流量比较敏感的的业务，它会大量消耗带宽。对于云厂商来说，面对以上不同的业务场景，就需要提供不同的解决方案。总结火山引擎在本届火山引擎 FORCE 原动力大会上实例发布中表现出的网络能力势能，主要有以下五点：</p><p></p><p>全栈自研架构，实现技术自主可控，驱动产品快速迭代，满足企业不同组网场景下对于网络高性能、高可用的诉求；自研控制器、自研 vSwitch 与自研 DPU 的软硬一体架构，提供业内一流水平的主机网络转发性能，整机包量高达 5000 万 pps，时延低至 20us；面向大规模云原生场景，单 VPC 可提供 100 万私网IP地址，ENI Trunking 可 7 倍提升单 ECS 实例网卡数最高至 120 个，以应对海量容器弹性扩展；自研通用 NFV 平台，基于快慢速路径分离架构设计，提供具备弹性扩展、故障隔离、极致性能的网元产品，解决了企业网络容量规划痛点；核心产品矩阵对标一线厂商，全新的中转路由器 TR、私网连接 PrivateLink 产品，满足企业级用户高阶组网诉求，同时提供网络管理策略与安全访问通路。</p><p></p><p>从云原生基础设施方面，云原生正在成为企业的数字“新基建”，而要用好云原生，不仅仅是支持容器和微服务器这么简单，需要云厂商提供云原生全套构建方案。在这方面，火山引擎做到了在云上可以秒级启动大规模、高密度的容器实例，并且基于火山引擎的自研 DPU 服务器进一步提升性能和运行效率；通过云原生把业务负载和大数据、AI 计算等融合在一起，并通过大规模池化技术，实现存算分离，混合调度，同时针对不同行业进行个性化需求满足；在安全层面，火山引擎的容器网络微隔离技术性能非常优秀，容器安全能力充分适应 DevSecOps 流程，将安全能力嵌入到业务开发的各个环节中。此外，火山引擎通过镜像预热、镜像缓存、P2P 传输等功能，实现超大镜像秒级加载，达到数百节点分钟级自动扩缩容，可以为企业提供高性价比的算力资源。</p><p></p><p>火山引擎在自研网元、自研 DPU 等技术方面带来的领先性的计算实例性能突破，为企业解决了大规模部署下性能瓶颈。就媒体视角的长期观察来看，火山引擎云基础技术自研到商业化落地成功的关键，主要还是在于客户价值。从大会上火山引擎推出的第三代实例来看，整体的性能拉升其实都是满足客户技术需求的同时还做到了性价比，火山引擎的云基础能力肉眼可见地一代比一代好。从技术自研到产品化，到客户侧的落地实践，整个过程中火山引擎都表现出了坚定的决心，就像罗浩表示的那样，“我们自己吃自己的'狗粮’，我们推出的产品都是在字节内部的业务上做完实践后，再给其他企业去用。”</p>",
    "publish_time": "2023-04-21 14:08:17",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "2023 春季火山引擎 FORCE 原动力大会",
    "url": "https://www.infoq.cn/article/pCWD3DNW6sxOGf3hgY61",
    "summary": "<p>2023 春季火山引擎 FORCE 原动力大会由火山引擎主办，是云计算和数字化领域的盛会。“FORCE ·原动力”作为大会品牌，寓意着“云计算是实现数字化的核心动力”，大会旨在面向产业、行业企业和从业人员、研究分析机构和媒体，全方位地展示火山引擎在云技术、云服务和云场景方面的最新探索、应用与实践，呈现创新发展的战略蓝图。</p>",
    "publish_time": "2023-04-21 15:11:18",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]