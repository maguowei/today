[
  {
    "title": "让部署更快更安全，GitHub无密码部署现已上线",
    "url": "https://www.infoq.cn/article/QMgmfb48A8AD1YHBdyPC",
    "summary": "<p>GitHub的CI/CD服务产品GitHub Actions现在支持使用<a href=\"https://github.blog/2023-01-11-passwordless-deployments-to-the-cloud/\">Open Identity Connect凭证</a>\"对Hashicorp Vault、AWS、Azure和GCP等云提供商进行身份验证，而无需使用长期凭证或密码。</p><p>&nbsp;</p><p>云的现代开发通常需要针对云提供商对持续集成和持续部署（CI/CD）服务器进行身份验证，以便对已配置的基础设施进行更改。从历史上看，这是通过在云提供商中创建一个身份来实现的，CI/CD服务器可以通过使用一组长期存在的、手动设置的凭证来假定这个身份。考虑到这些凭证的用途，它们的妥协终究会带来重大的业务风险。</p><p>&nbsp;</p><p><a href=\"https://openid.net/connect/#:~:text=OpenID%20Connect%201.0%20is%20a,interoperable%20and%20REST%2Dlike%20manner.\">OpenID Connect身份验证协议</a>\"是一种可互操作的机制，用于提供有关用户身份的可验证信息。假如用户的身份提供者是验证方能够信任的提供者，则可以在称为<a href=\"https://www.oauth.com/oauth2-servers/openid-connect/id-tokens/\">ID令牌</a>\"的<a href=\"https://jwt.io/introduction\">Json Web令牌（JWT）</a>\"中以声明的形式提供相关用户数据。</p><p>&nbsp;</p><p>使用GitHub Actions，第一步是在云提供商的身份和访问管理配置中将GitHub注册为外部身份源。在执行工作流时，管道可以访问管道唯一运行范围内的ID令牌。令牌包括令牌的期望受众、其持有者的标识符以及其他元数据。</p><p>&nbsp;</p><p>然后，云提供商可以使用该信息来为任何的后续操作颁发短期凭证，例如访问令牌。目前GitHub Actions支持<a href=\"https://docs.github.com/en/actions/deployment/security-hardening-your-deployments/configuring-openid-connect-in-hashicorp-vault\">Hashicorp Vault</a>\"、<a href=\"https://docs.github.com/en/actions/deployment/security-hardening-your-deployments/configuring-openid-connect-in-amazon-web-services\">亚马逊网络服务</a>\"、<a href=\"https://docs.github.com/en/actions/deployment/security-hardening-your-deployments/configuring-openid-connect-in-azure\">Azure</a>\"和<a href=\"https://docs.github.com/en/actions/deployment/security-hardening-your-deployments/configuring-openid-connect-in-google-cloud-platform\">谷歌云平台</a>\"。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/df/df09309a6f99c18adbef79574ecc24c9.png\" /></p><p></p><p>&nbsp;</p><p>自该新特性发布以来，人们对它的反响基本上是积极的，Hashicorp创始人<a href=\"https://twitter.com/mitchellh\">Mitchell Hashimoto</a>\"在推特上写道：</p><p>&nbsp;</p><p></p><blockquote>最近发现GitHub Actions每次运行都会创建一个OIDC标识，因此可以将Vault配置为允许w/Actions身份认证，然后使用它来访问……任何内容。虽然需要进行一些清理，但这是非常有希望的！</blockquote><p></p><p>&nbsp;</p><p>尽管反响热烈，但其采用速度似乎比预期的要慢，WhiteDuck DevOps的咨询与运营主管&nbsp;<a href=\"https://twitter.com/nmeisenzahl\">Nico Meisenzahl</a>\"在推特上写道：</p><p>&nbsp;</p><p></p><blockquote>在#GitHub Actions中使用#OIDC进行云提供商和#Kubernetes身份验证已经是一件大事件了吗？我虽然看到了它的很多优点，但已经采用它的人并不多。</blockquote><p></p><p>&nbsp;</p><p>继GitHub于2021年底发布该特性以来，其他CI/CD提供商也在其产品中添加了类似的集成。2022年底发布的GitLab 15.7版本支持访问<a href=\"https://docs.gitlab.com/ee/ci/cloud_services/\">Hashicorp Vault、AWS、Azure和GCP</a>\"，而Circle CI于2023年2月宣布支持<a href=\"https://circleci.com/blog/openid-connect-identity-tokens/\">GCP和AWS</a>\"集成。</p><p>&nbsp;</p><p>所有计划都可以使用GitHub Actions OIDC登录云提供商，而无需额外的费用。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/03/passwordless-deployments-github/\">https://www.infoq.com/news/2023/03/passwordless-deployments-github/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://xie.infoq.cn/article/3a47c0e86ca4f1780a65cfdf3\">玩转 Github：三分钟教你如何用 Github 快速找到优秀的开源项目</a>\"</p><p><a href=\"https://xie.infoq.cn/article/442ddeac1eaada53fd5770750\">8 个很酷的 GitHub 技巧</a>\"</p>",
    "publish_time": "2023-04-21 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "用友 BIP 助力中国领先企业数智化国产替代",
    "url": "https://www.infoq.cn/article/BScfzwB5pdzkKXMDgYyO",
    "summary": "<p>随着数字经济的快速发展，软件的重要性日益凸显。软件是新一代信息技术的灵魂，已经成为数字中国、制造强国、网络强国建设的关键支撑。面对全球竞争新格局，关键软件自主创新与国产化替代已迫在眉睫。</p><p></p><h1>助力华为成功替换国外ERP系统</h1><p></p><p></p><p>在此背景下，作为领先的企业软件提供商，用友应邀承接了华为替换旧有国外ERP总账项目，通过产品研发和交付团队的努力，项目按质量完成交付，并在试点单位成功上线应用。</p><p></p><p>用友依托深厚的企业软件产品创新能力，包括用友BIP最新基于事项法会计理论的智能会计思想与模型，助力华为成功实现对国外ERP系统的替换。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/72/727e837b4b44cbe9652a82e321eea9c5.png\" /></p><p>华为为MetaERP合作伙伴颁奖</p><p></p><p>4月20日，用友作为华为重要合作伙伴，受邀出席华为“英雄强渡大渡河”MetaERP表彰会。在会上，华为为用友颁发“英雄强渡大渡河”奖牌，以表彰用友在MetaERP研发及替换国外ERP系统上做出的贡献。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e2/e2d38078432281d9a5316b559221619f.png\" /></p><p></p><p>把数智化升级与信创国产化相结合，即“价值化国产替代”是用友多年以前就确立的发展方针，除服务华为的本次系统建设外，用友战略研发的新一代服务企业数智化的主力产品-用友BIP，自发布以来，已应用于33000多家大中型企业的数智化建设，累计签约一级央企27家，充分体现了以用友为代表的中国企业软件厂商，已经具备了承担大型、超大型企业数智化底座平台和关键应用系统国产化替代重任的能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/25/25a3f9a5fd62434e81530d44889eb456.png\" /></p><p>华为董事、CEO任正非（左）与用友网络高级副总裁王勇（右）</p><p></p><h1>用友BIP，企业数智化与国产化替代的首选</h1><p></p><p></p><p>信息技术在企业的应用，经历了电脑化、信息化、数智化三大阶段，用友的发展见证了这一历史进程在中国的演化。如果说在电脑化时代中国企业远远落后于发达国家，信息化时代中国追赶发达国家，今天，我们已经开始看到越来越多的中国企业的数智商业创新开始走到全球同业的前列。有了这样的土壤，一定能够在中国成长出数智化时代全球领先的企业软件厂商。</p><p></p><p>用友创立于1988年，始终专注于企业软件与服务产业，用友1.0时期，通过财务软件服务超过40万家企事业单位的会计电算化，成为中国最大的财务软件公司；用友2.0时期，通过ERP服务超过200万家企业的信息化，成为亚太最大、全球前10的ERP软件提供商。当前，用友发展进入3.0新时期，目标是要用新一代产品服务超过千万家企业的数智化，并成为全球前3的企业云服务与软件提供商。</p><p></p><p>在35年行业Know-how积累与大规模客户合作基础上，基于新一代数字与智能技术，用友战略投入，组织国内同类厂商中规模最大的研发团队，历时七年研发打造的全新一代服务企业数智化的主力产品——用友BIP，在平台技术与应用架构、领域与行业应用、生态体系三个层面，实现全面突破，达到全球领先水平，是目前全球领域覆盖最多的企业应用服务群。同时，作为信息技术应用创新工作委员会WG22 ERP与财务软件组组长单位，用友深度参与了信创生态建设。用友BIP从芯片、服务器、操作系统、数据库、中间件到安全，全栈适配中国电子PKS、中国电科、中科院及华为鲲鹏四大信创技术体系。</p><p></p><p>开放融合、生态共荣，共同为客户创造价值，是用友BIP的发展方针之一。用友BIP的生态正在快速成长，目前已有ISV伙伴近2500家，专业服务伙伴419家，开发者活跃数超过108万，并连接了全球2108家银行。在国产化趋势下，一批原来与国外ERP厂商合作的专业服务伙伴陆续加入用友生态体系。</p><p></p><p>用友BIP坚持云中立原则，可根据客户的需要，运行在阿里云、天翼云、华为云、腾讯云、企业自建IDC等不同云计算平台，并可实现便捷的跨云迁移，支持企业拥有开放、自主的数智化基础设施环境。</p><p></p><p>据Gartner研究数据显示，用友目前是全球应用平台软件aPaaS市场和ERP SaaS市场TOP10中唯一的中国厂商，并在财务（FMS）市场占有率连续多年入选全球10强，客户覆盖30多个行业，以及40多个国家和地区，被重要央媒誉为企业数智化的“大国重器”，成为新时期众多行业领先企业推进企业数智化建设与国产化替代的首选。</p><p></p><h1>普及用友BIP，让数智化在更多的企业成功</h1><p></p><p></p><p>“用创想与技术推动商业和社会进步”是用友的企业使命。新时期，用友将承载起引领中国软件产业蓬勃发展的重任，在企业使命的指引下，通过普及用友BIP，服务中国和全球企业的数智化，把融合众多行业领先企业的成功实践，更具普适性推广价值、更贴合企业数智化建设和运营需求的成果规模复制到千行百业，使能客户的数智商业创新与进步发展，让数智化在更多的企业成功！</p>",
    "publish_time": "2023-04-21 09:37:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "华为宣布成功完成MetaERP自研和替换",
    "url": "https://www.infoq.cn/article/QLX24NmbrpfICxdlLAA0",
    "summary": "<p></p><p>4月20日，华为在东莞举办了<a href=\"https://www.infoq.cn/article/ugoDGtJzX9xdm8d9o5eo\">MetaERP</a>\"表彰大会，正式对外宣布实现自主可控的MetaERP研发，并完成对旧ERP系统的替换。</p><p></p><p>据悉，任正非出席本次表彰会向合作伙伴表示感谢，“要谢谢合作伙伴，我们认为今天的成功跟你们分不开，未来的发展跟你们更相关联”。他还表示，今天在软件上我们还是落后的，但是有一天我们可能会变强大。</p><p></p><p>表彰会上，华为董事、质量与流程IT部总裁陶景文表示：“面对包含ERP在内等企业作业和管理核心系统的断供停服，我们不仅能造得出来，还换得了，用得好，现在终于可以宣布，我们已经突破了封锁，我们活了下来！”</p><p></p><p>截至目前，MetaERP已经覆盖了华为公司100%的业务场景和80%的业务量，经历了月结、季结和年结的考验，实现了零故障、零延时、零调账。</p><p></p><p>附陶景文发言全文：</p><p></p><p>同心协力，突破封锁，成功强渡大渡河</p><p></p><p>尊敬的各位来宾、各位伙伴、各位同事，大家好！</p><p></p><p>随着华为技术、华为云等公司ERP的成功替换，MetaERP已经覆盖了集团、销服类、制造类等几类公司，覆盖了100%的业务场景和80%的业务量，经历了月结、季结和年结的考验，年报及时准确发布的同时，实现了零故障、零延时、零调账。面对包含ERP在内等企业作业和管理核心系统的断供停服，我们不仅能造得出来，还换得了，用得好，现在终于可以宣布，我们已经突破了封锁，我们活了下来！</p><p></p><p>今天我们召开MetaERP胜利表彰大会，就是为过去三年来为突破公司经营连续性封锁做出重要贡献的团队和个人庆功，也要特别感谢我们的合作伙伴和所有做出贡献的英雄们！</p><p></p><p>2019年5月16日，美国把华为放入实体清单，ERP供应商在几天内就通知对华为断供停服，而ERP作为华为企业经营最核心的系统，支撑了华为20多年的快速发展，支撑了每年数千亿产值的业务，支撑了全球170+国家业务高效经营，一旦出问题，相当于自身运行的神经系统出了问题，公司基本业务运转面临瘫痪风险，这道影响企业经营生存的“大渡河”突然横亘在前，我们已经没有退路，“强渡大渡河”成为唯一选择。</p><p></p><p>一、断供停服是一场巨大的危机，也让我们重新系统审视老ERP的问题和发展限制，最终我们决定不仅要全栈自主可控，且要基于云原生、元数据多租、实时智能等新技术，打造面向未来的下一代企业核心商业系统，让企业运营更安全、更高效。</p><p></p><p>1. 华为是ERP深度使用者，深刻理解ERP的需求、问题和价值。过去华为坚持用“欧美砖修长城”，1996年就引入MRP II，ERP支撑了大量多业态全球化业务，且承载了IPD、ISC、CRM、IFS等变革项目经验，是老ERP系统全球使用体量最大企业之一，为了保留固化在ERP的多年管理和运营经验，不让管理退步，同时解决老ERP系统存在灵活性差、对业务需求响应慢、不够智能等问题，我们寻找了很多出路，最后发现能救我们的只有自己。</p><p>2. 实现全栈自主可控，并采用最新技术，支持业务需求快速响应、经营决策科学高效、应用数据安全可信。采用云原生架构用好算力，实现全球快速部署，自动适配业务流量变化，轻松应对千万级流量洪峰；采用元数据多租架构，将业务对象、实体、逻辑等元数据资产标准化，租户可灵活编排，快速响应业务需求；采用实时智能技术用好数据，如通过预置多个AI模型，实现风控、经营决策科学高效；采用完全自主的<a href=\"https://xie.infoq.cn/article/60e91f6434a283d60098899bf\">GaussDB</a>\"，会计分录峰值处理3000万笔/天，从30分钟延时改进到实时处理；落实公司可信变革，让系统更加安全可控，让数据在安全合规的前提下高效使用。</p><p></p><p>二、如何成功替换ERP这个非常复杂且实时运行的系统，又能实现“业务无感、数据不丢、报告准确、业财一致”的极致要求，我们积累了一整套经验，总结了一整套方法，构建了一整套工具，并且实现了这个极高难度的挑战。</p><p></p><p>1. 通过“解耦”重定边界，让ERP回归核心功能。老ERP像年久失修的大厦，内部管道和线路交叉纵横、违建繁多，各类应用与ERP的逻辑集成点3950个、数据集成点高达27000个。通过解耦重新定义了ERP边界和功能，并通过“绿地计划”打扫外围各业务应用系统，减少1000+个逻辑集成点，去除ERP客制化代码320万行，实现业务应用系统的标准、可插拔；识别核心业务流，以“业务流”为基础解耦，保证业务财务一体化设计，从而实现主干贯通、业财一致。</p><p>2. 打造切换工具链，让切换高效可靠。ERP系统每天处理海量业务和数据，如销售订单行76万，应付开票行21万，会计分录行1500万，如此复杂场景下要做到业务无感、数据不乱，相当于飞机在飞行中换“发动机”。为此开发了一整套切换工具，如具备 “自动配线架”功能的ERP伴侣，实现异构ERP灵活切换能力，切换时外围系统用户可正常下单和作业；如数据迁移工具，35小时完成高度关联的3200亿行数据搬迁验证，利用周末时间完成ERP搬迁，不影响企业正常运转。</p><p>3. 系统全面验证，提前识别和解决问题。ERP运行业务场景多达2000个，实时要求高，数据处理量多达160T，如何全面高效验证系统是替换能否成功的关键保障，我们通过并行验证将生产环境业务流量实时导入新系统，用真实场景验证，做到上线后“0”缺陷；通过自动化测试解决海量复杂测试场景，测试周期从最初的3个月缩短到7天。</p><p></p><p>三、“上下同欲者胜，风雨同舟者兴”，ERP的成功替换，离不开一路与我们集众智、聚众力的同路人，这不仅是华为的胜利，也是中国软件产业链的共同胜利！</p><p></p><p>1. 感谢业务与IT共同组建的混编团队，你们是强渡大渡河的“勇士连”。华为云、2012实验室等技术团队在一个个技术山头上一起攻坚克难；财经，供应、采购、交付、销售等业务领域在场景设计和验证上一起共建共验；HR、慧通、行政等部门及时有力地提供服务保障；感谢你们一路同行、始终如一。</p><p>2. 感谢我们的伙伴，你们是强渡大渡河的同路人。感谢在ERP替代和IT BCM过程中帮助我们的金蝶、用友、奇安信、天喻、金山、永洪、元年等战略合作伙伴，一起打造企业核心商业系统的“中国砖”；也感谢在ERP维稳、解耦、换芯过程中把华为三十多年管理实践落地到这套系统中的生态伙伴，一起构建了先进的工程方法和丰富的业务应用，感谢大家与华为携手同行、风雨同舟。希望通过华为打造根技术实现“根深”，战略合作伙伴造好“中国砖”实现“干壮”，生态伙伴打造行业应用实现“枝繁叶茂”。</p><p>3. 最后，我要向今天获奖团队和所有对项目做出贡献的英雄们致以敬意。感谢你们在这场漫长而艰苦的战役中的不懈努力和付出，也要特别感谢那些默默支持我们的家人们，是你们的理解、信任和支持，让我们可以专注工作，坚定不移地走到最后胜利。</p><p></p><p>“为有牺牲多壮志，敢叫日月换新天”，ERP的成功“强渡大渡河”，是华为和中国软件全产业链共同努力的成功，是“没有退路就是胜利之路”精神的践行，我们要继续坚持底线思维，持续艰苦奋斗，围绕“极简架构、极高质量、极低成本、极优体验”的目标，在ERP、PLM等领域，和伙伴一起打造不受制于人、更加高效安全的企业核心商业系统。</p>",
    "publish_time": "2023-04-21 11:47:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "年薪高达7位数，甚至无需任何技术背景就能上手，AIGC让这个岗位一夜爆火",
    "url": "https://www.infoq.cn/article/teJtsgJuh2lou9FAlIt5",
    "summary": "<p></p><p>AI催生的新岗位正在兴起 —— 年薪高达六位数（以美元为单位计算），而且无需计算机工程学位，甚至“精通编程”都不是必要条件。</p><p></p><p>随着生成式AI一路起飞，不少公司开始聘请“提示工程师”。他们的工作就是训练新兴的AI工具，引导它们对实际问题给出更准确、相关性更强的回应。</p><p></p><p>其中部分岗位的年薪甚至高达33.5万美元（约合230万人民币）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4e/4ea52f8dece9f14e0d52f22f54761653.png\" /></p><p></p><p>与传统编码工作不同，只要您具备基础编程技能并熟悉大语言模型（例如ChatGPT或者Bard），就有机会担任提示工程师。</p><p></p><h2>提示工程师是干啥的？</h2><p></p><p>29岁的Anna Bernstein目前在位于纽约的生成式AI公司Copy.ai担任提示工程师，她也是这个新兴领域中为数不多的从业者之一。</p><p></p><p>她的工作内容包括编写文本提示，将提示词输入AI工具后端，借此引导大语言模型生成具有适当证据和准确信息的博文或者营销邮件。整个过程无需编写任何代码，她要做的就仅仅是向AI模型输入指令来不断优化响应。</p><p></p><p>Bernstein于2021年9月加入Copy.ai公司，这时候距离OpenAI推出轰动全球、能够生成优雅文字并回答几乎所有问题的ChatGPT还有一年时间。</p><p></p><p>“我们这样的提示工程师并不多，很长一段时间我感觉好像就只有自己在做这方面工作。当时还不存在「提示工程师」这个概念，大家甚至不确定这个岗位会不会存在。”</p><p></p><p>Bernstein在大学攻读的专业是英语，在担任提示工程师之前曾作过撰稿人和历史研究助理。“我没有任何技术背景，但人文学科的教育背景和积累似乎成了我的优势，毕竟AI开发的一部分目标就是模仿人类思维。”</p><p></p><h2>AI相关岗位激增</h2><p></p><p>提示工程如今成为最热门的技术工作之一，众多企业都在寻求可行的方法来训练和微调AI工具，避免这些新的大语言模型动不动输出一些错误甚至是有毒的结果。</p><p></p><p>对提示工程人才的需求，也反映出市场对AI工具的热烈追捧。</p><p></p><p>根据《时代周刊》分享的LinkedIn数据，2021年至2022年之间，提及“生成式AI”的帖子数量较上一年增长了36倍，包含“GPT”字样的招聘岗位增加了51%。新岗位对求职者的教育背景要求也更为宽松，开始欢迎那些不具备计算机科学或者技术背景的申请者。</p><p></p><p>目前还很难判断提示工程这块业务能发展到怎样的规模，但不少企业和行业确实启动了相关招聘。</p><p></p><p>作为由谷歌支持的AI初创公司，Anthropic开始在旧金山地区招聘“提示工程师与素材管理员”，开出的年薪高达33.5万美元。岗位描述中要求，申请者必须“具备创造性的极客精神、热爱解决难题”。自动文档审阅工具Klarity则为机器学习工程师开出最高23万美元的年薪，要求申请人“提示并了解如何让AI工具生成最佳输出”。</p><p></p><p>在科技行业之外，波士顿儿童医院和咨询公司博思艾伦最近也发布了提示工程职位的招聘信息，后者为拥有三年以上机器学习模型操作经验的申请人开出高达21.2万美元的年薪。演员唐纳德·格洛弗（Donald Glover）甚至打算为自己新开的创意工作室聘请一名提示工程师兼提示动画师。</p><p></p><p>可尽管岗位头衔里有“工程师”字样，Bernstein并不觉得她真有资格自诩是工程技术人员。“刚开始的时候，我们用的名头是提示专家。后来才出现了提示工程师这个专有名词。”</p><p></p><h2>如何成为提示工程师</h2><p></p><p>提示工程专家Rob Lennon从去年12月开始，通过Kajabi开放付费线上课程，希望帮助更多普通人学习提示工程所需要的技能。他的两门课程已经吸引到约2000名学员，其中演示了如何为不同类型的任务和领域设置相应的提示格式和结构。</p><p></p><p>Lennon表示，“人们迫切想要掌握这些知识，都想让自己拥有先发优势。”这些课程起价为150美元，定制培训和课程认证费用最高可达3970美元。</p><p></p><p>但另一方面，不少专家则认为随着AI愈发强大并拥有自主生成提示的能力，提示工程也将很快销声匿迹。 宾夕法尼亚大学沃顿商学院副教授Ethan Mollick警告称，希望担任提示工程师的朋友们最好冷静一点，毕竟生成式AI行业的未来仍有很多变数。</p><p></p><p>在他看来，“目前还不清楚提示工程能否长期存在，毕竟AI程序在预测用户需求和生成提示方面已经做得越来越好。我们也不知道提示工程到底涉及哪些特定技能，或者说只需要花大量时间跟聊天机器人沟通。”</p><p></p><p>Lennon也认为，目前市场提供的高薪可能不会持续太久。“能胜任这些岗位的群体可能只有500个人，所以薪酬才高得离谱。但在半年之内，也许将有5万人有能力做好这份工作，这势必会导致知识价值的快速贬值。”</p><p></p><p>Mollick还指出，有意探索这个领域的人们应该先在GPT+和Bard上做点试验，琢磨出自己的一套提示方法，而不是急于参加线上课程。毕竟如今的AI系统变化极快，现在有效的提示可能会很快过时。“我担心人们过度依赖教学内容，误以为有什么神奇的提示操作技巧。”</p><p></p><p>考虑到人们对AI的浓厚兴趣，LinkedIn公司首席经济学家Karin Kimbrough认为，企业雇主也必须尽快转变关注方向。如果继续像过去那样专注于特定技能方向和具备固定教育背景的求职者，那他们很可能难以为新兴岗位找到合适人选，甚至得跟同行们展开一场激烈的人才争夺。“AI技术的突破其实来得有些晚了，所以企业一定得把握住实际技能才是关键的心态，以技能至上的思路看待这些新近出现的岗位需求。”</p><p></p><p>但也有人对看似火热的市场表示怀疑，毕竟科技企业刚刚才完成几波大规模裁员。**但拥有AI力量的科技企业家们则坚信，提示工程有望全面起飞并重塑自动化的新面貌。**特斯拉前AI主管Andrej Karpathy最近就发推文称，“英语才是目前最热门的编程语言。”</p><p></p><p>即使如此，我们恐怕还是很难相信像提示工程这类对教育背景要求不严的岗位能长期维持六位数的年薪水平。</p><p></p><p>Bernstein也承认目前的趋势也在引发质疑，比如批评人文学科出身的员工居然能跟技术出身的员工拿到同等报酬。她的回答非常简单：“为什么不行？决定这一切的是对产品的贡献度，只要贡献相当就可以薪酬对等。”</p><p></p><p>参考链接：</p><p></p><p><a href=\"https://time.com/6272103/ai-prompt-engineer-job/\">https://time.com/6272103/ai-prompt-engineer-job/</a>\"</p><p></p><p><a href=\"https://thenextweb.com/news/prompt-engineering-hottest-job-in-tech-paycheck\">https://thenextweb.com/news/prompt-engineering-hottest-job-in-tech-paycheck</a>\"</p>",
    "publish_time": "2023-04-21 12:22:59",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "叫板ChatGPT？Stability AI 开源语言大模型 StableLM，参数仅为GPT-3百分之四，却能实现超高性能",
    "url": "https://www.infoq.cn/article/kps1yUUKJU1dSLI68lZz",
    "summary": "<p></p><p>4 月 20 日，AI 作画神器 Stable Diffusion 背后公司 Stability AI 发布了新的开源语言模型 StableLM。</p><p>这套模型的 Alpha 版分 30 亿和 70 亿参数两个版本，后续还有 150 亿到 650 亿参数的更多模型变体。</p><p>开发人员可以出于商用或研究等用途，自由体验、使用和微调 StableLM 基础模型，但须遵守 CC BY-SA-4.0 许可条款。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/68/68ae7f7f76615d8e3cedcedb5c511379.png\" /></p><p></p><p>“一只随意样式的鹦鹉，扁平设计，矢量风格” — Stable Diffusion XL</p><p></p><p>2022 年，Stability AI 公开发布了 Stable Diffusion。这套革命性的图像模型，标志着不同于专有 AI 的透明、开放、可扩展替代方案已经出现。</p><p></p><p>随着 StableLM 模型套件的推出，Stability AI 继续践行着让每个人都能用上基础 AI 技术的基本宗旨。StableLM 模型能够生成文本和代码，并将为一系列下游应用程序提供支持。项目的意义，在于展示小规模高效模型如何通过适当训练提供出色的性能。</p><p></p><p>StableLM 的发布，建立在 Stability AI 与非营利性研究机构 EleutherAI 的早期开源语言模型的经验之上。这里的早期开源模型包括 GPT-J、GPT-NeoX 和 Pythia 套件，并在 The Pile 开源数据集上进行训练。近期众多开源语言模型同样以这些努力成果为基础，例如 Cerebras-GPT 和 Dolly-2 等。</p><p></p><p>StableLM 利用 The Pile 上的新实验数据集进行训练，但模型规模增大了 3 倍，包含 1.5 万亿个内容 token。</p><p></p><p>Stability AI 表示，将在适当的时候发布关于数据集的细节信息。这套数据集的高丰富度，使得 StableLM 在会话和编码任务中表现出惊人的高性能，且继续保持着相对较小的参数量——只有 3 亿至 70 亿之间（与之对应，GPT-3 拥有 1750 亿个参数）。</p><p></p><p>Stability AI 还发布了一系列经过指令微调的研究模型。这 5 套经过开源数据集微调的模型均为对话智能体，分别为 Alpaca、GPT4All、Dolly、ShareGPT 以及 HH。目前这些模型仅供研究用途，基于非商用 CC BY-NC-SA 4.0 发布，且遵循斯坦福大学的 Alpaca 许可。</p><p></p><p>以下各图，为 70 亿参数微调模型生成的对话示例：</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5a/5aa9f9d65eca616ad104d2485e557ed3.jpeg\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2a/2a1c0a06e442421aaa7f6a6061799a5c.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/37/37f5ee00aa8c824ada6b7d0c65ace3ac.jpeg\" /></p><p></p><p>Stability AI 表示，“语言模型将构成我们数字经济的支柱，我们希望每个人都能为模型设计提出意见。以 StableLM 为代表的这批开源模型，也再次践行了我们对于打造透明、可访问、支持性 AI 技术的承诺”：</p><p></p><p>透明。通过模型开源以提高透明度并建立社区信任。研究人员可以“深入了解”模型以验证其性能、研究可解释性技术、识别潜在风险并协助制定保障措施。公共和私营部门能够针对自己的应用场景调整（「微调」）这些开源模型，且无需共享敏感数据或放弃对 AI 功能的控制权。</p><p></p><p>可访问性。在设计中考虑到边缘用例，确保日常用户能够在本地设备上运行的模型。利用这些模型，开发人员可以构建与各类常见硬件相兼容的独立应用程序，而无需依赖于少数一、两家企业的专有服务。通过这种方式，AI 的经济利益将被真正分享给广大用户和开发者社区。相较于神秘的闭源模型，更开放、允许细粒度访问和广泛研究的开源模型将为学术社区提供更好的可解释性和安全技术。</p><p></p><p>支持性。Stability AI 之所以构建模型，是为了向用户提供支持、而非将其取代。Stability AI 专注于打造高效、专业且实用的 AI 性能，而不是追求建立起如神般全知全能的人工智能。Stability AI 开发的工具能够为普通人和普通企业赋能，帮助他们释放创造力、提高生产力并开辟新的经济机会。</p><p></p><p>这些模型目前已经发布了 Stability AI 的 GitHub 代码仓库上（https://github.com/stability-AI/stableLM/）。</p><p></p><p>此外，Stability AI 将启动基于人类反馈的强化学习（RLHF）众包计划，并与 Open Assistant 等社区合作，共同为 AI 助手创建一套开源数据集。</p><p></p><p>参考链接：</p><p>https://stability.ai/blog/stability-ai-launches-the-first-of-its-stablelm-suite-of-language-models</p>",
    "publish_time": "2023-04-21 12:58:31",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何让AI读懂“人话”？中关村科金任务型多轮对话的实践与探索 | 对话式AI系列",
    "url": "https://www.infoq.cn/article/mU2TYb5yvAKqA2yw7Jzq",
    "summary": "<p></p><p></p><blockquote>任务型多轮对话是对话式 AI 的必由之路。</blockquote><p></p><p></p><p>移动互联网带来了大数据的普及，摩尔定律预言了计算机硬件的发展，深度学习则借助这阵东风实现了技术上的突破，人工智能成功进入大众视野，并改变了人们的日常生活。</p><p></p><p>“小 X 同学，请打开电视”、“小 X 小 X，请播放音乐”...... 如今，很多年轻人的生活不再像以前一样，只需要动动嘴，就可以控制家里的各种设备。</p><p></p><p>根据全球著名调研咨询机构 IDC 发布的《中国全屋智能设备和解决方案市场回顾和展望》，2021 年中国智能家居设备出货量超过 2.2 亿台，同比增长 9.2%；2022 年中国全屋智能市场销售额将突破百亿，预计同比大幅增长近 55%；到 2023 年，智能家居将会成为物联网支出最高的领域之一。</p><p></p><p>而想要实现通过语音对话的方式来控制家中智能设备，对话式 AI 技术是必不可少的一环。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b4/b4af045ab5f9be4fc57b5f662e09b91a.png\" /></p><p></p><p></p><p></p><h2>任务型多轮对话是对话式 AI 的必由之路</h2><p></p><p></p><p>目前，对话式 AI 主要应用的场景有三种，分别是闲聊型、问答型和任务型。</p><p></p><p>闲聊型：多用于情感陪伴，但由于整体技术水平还未达到人们的心理预期，现阶段商业化并不太成功；</p><p></p><p>问答型：多见于客服系统，能够解决用户的一些事实性问题，但功能上较为局限；&nbsp;</p><p></p><p>任务型：多用于 B2C 类应用，能够将非结构化数据充分利用起来，沉淀企业知识，是企业数字化转型赛道上的关键技术。</p><p></p><p>由于目前的技术水平还处于弱人工智能阶段，全面实现对话式 AI 比较困难。任务型多轮对话因具有较好的可解释性，且易于把控，是以点及面实现完整的对话式 AI 的理想途径。</p><p></p><p>任务型多轮对话是对话式 AI 的外延之一，专注于封闭域下的问题解决。</p><p></p><p>任务型多轮对话的定义是：根据上下文内容，进行连续的、以达到解决某一类特定任务为目的的对话。需要注意的是，任务型多轮对话有三个关键要素，多轮、连续性、封闭域。</p><p></p><p>多轮：与单轮的问答不同，多轮对话解决复杂条件下的问答，需要结合上下文理解多项约束条件，每一次应答都与上下文有强关联关系。</p><p></p><p>连续性：对话需要具备连贯性，一旦捕获到用户意图，则将以完成此任务为目标，进行持续性的对话。</p><p></p><p>封闭域：某一类特定问题表明了对话是受限的，即这是一个封闭域上的问题。对话系统仅负责某个领域下已知的一系列任务，比如说订机票，订外卖，或者查天气等等。</p><p></p><p></p><h2>任务型多轮对话系统的技术架构设计</h2><p></p><p></p><p>目前主流的任务型多轮对话系统依然沿用了模块化的方法，其技术架构如下所示，包含以下几个模块：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/66/66c2a640ea4a45dc78296c2f8930476a.png\" /></p><p></p><p>图 1 多轮对话系统架构图</p><p></p><p>输入模块：接收用户传达的信息，包括语音、图像、文本等。对于语音类信息，通常使用语音识别（Automatic Speech Recognition, ASR）技术转化为文本。而对于图像类信息，目前研究较少，可行的方案包括通过文字识别（Optical Character Recognitionm, OCR）技术将识别图像中的文字转化为文本，或者使用机器学习训练编码器，将图像转化成视觉语义编码。</p><p></p><p>解析模块：对输入的信息进行解析，转化为机器可理解的语义表示。以文本信息及框架语义表示为例，此模块依赖于自然语言理解（Natural Language Understanding, NLU）技术，需要从文本信息中识别出用户的意图（Intent）以及该意图下的语义槽（Slot）。例如“附近有什么比较火的粤菜馆？”，用户意图是“搜寻餐厅”，语义槽是“地点”为“附近”，“热度”为“高”，“菜系”为“粤菜”。</p><p></p><p>对话管理模块：根据解析模块输出的语义表示，更新对话状态，并根据策略选择应答动作。此模块主要包括对话状态跟踪（Dialogue State Tracker, DST）和对话策略学习（Dialogue Policy Learning, DPL）。对话状态跟踪负责维护多轮对话的状态，根据历史对话状态、解析模块当前的输入以及背景知识库综合得到新的对话状态。此模块的主要功能就是记忆与预测，通过与用户间的不断交流，逐渐完善对用户状态的观察。对话策略学习根据 DST 模块输出的当前对话状态，来决策系统采取的动作。例如解析模块的例子，此模块则会选择“搜索”动作，查询以用户当前定位为中心，一定范围内的高浏览量粤菜餐厅。</p><p></p><p>解码模块：与解析模块相反，此模块的任务是将系统结果以人类可以理解的方式解码，通常就是转化为自然语言。例如系统查询到的餐馆在数据表中 ID 为\"r008\"，转化为自然语言可以是“您好，附近热度最高的粤菜馆是金鼎轩，位于 xxx 路 xxx 号，距您 1.1km。\"</p><p></p><p>输出模块：此模块以输入模块相同的形式将解码模块产生的结果反馈给用户，如聊天框、麦克风等。而自然语言想要转化为语音，则需要使用到语音合成（Text To Speech, TTS) 技术。</p><p></p><p></p><h2>业内主流的任务型多轮对话系统平台</h2><p></p><p></p><p>经过多年的发展，任务型多轮对话领域涌现了众多优秀的公司，尽管基础技术差异不大，但在钻研方向上各家却有着自身的特色，下面介绍几个典型案例。</p><p></p><h4>预训练对话模型 — 谷歌 LaMDA</h4><p></p><p></p><p>谷歌 LaMDA 是工业级端到端的预训练对话模型。众所周知，目标决定方向，如何定义模型的训练任务与损失函数，将决定训练方向与最终效果。谷歌重新定义了三个评价指标，Sensibleness, Specificity, Interestingness（是否合理、符合上下文、有创造力）、Safety（是否有风险、不公正）、Groundedness、Informativeness（在知识型问答中，是否包含真实的信息、并引用相关链接），并借此构建分类任务精调模型，提升了模型的对话能力。</p><p></p><p>相比其他对话系统，LaMDA 具有蕴含知识、回复更加灵活等优势，但其不可控性、逻辑能力差等缺点也是极为明显的。然而就在大众对于此类“人工智障”逐渐失望之际，12 月 openAI 推出的同类型的大模型 chatGPT 着实让人惊艳，或许此类对话系统依然是通往终点的一条途径。</p><p></p><p></p><h4>领域预建模型 — Senseforth.ai</h4><p></p><p></p><p>Senseforth 成立于 2017 年，是一家印度对话式人工智能服务商。根据 Gartner 统计，目前 Senseforth 的企业级对话式人工智能平台每月处理超过 1.9 亿次对话，准确率超过 96%。</p><p></p><p>通过大量行业实践，Senseforth 创建了对话式人工智能机器人商店，该商店拥有行业预建模型和领域知识，适用于一系列垂直行业，包括银行、保险、零售、医疗保健、电信和酒店等。Senseforth 尤其专注于 NLU 模块，将意图与实体分开训练，支持快速新增、修改意图，其解决方案中包含 4 万多意图与大量的预置意图库。</p><p></p><p>除了对话式人工智能机器人外，Senseforth 还涉足对话式分析、对话式营销、代理协助、知识管理和智能搜索等技术服务。</p><p></p><p></p><h4>低代码与自动化— Cognigy</h4><p></p><p></p><p>Cognigy 是一家总部位于德国的对话式 AI 服务提供商，成立于 2016 年，旨在提高企业客户服务团队的工作效率。通过将对话式 AI 技术与商业智能、客户关系管理、企业资源规划工具整合，Cognigy 帮助企业用户通过简单对话形式访问实时数据，实现无缝连接关键操作触点。</p><p></p><p>Cognigy 亦专注于低代码平台搭建，结合流程自动化技术，允许企业使用智能 AI 机器人和聊天机器人自动化客户和员工通信。</p><p></p><p></p><h2>任务型多轮对话在中关村科金的实践</h2><p></p><p></p><h4>企业目前存在的痛点</h4><p></p><p></p><p>目前任务型多轮对话系统的技术框架、各模块的细化技术选型都已经较为成熟，但是在实际实践中，我们发现依然存在着定制化程度高、回答生硬、使用门槛高等诸多问题。</p><p></p><p>定制化程度高：任务型多轮对话依赖专家经验，需要预先梳理出领域本体结构，用户的意图及每个意图对应的槽位，针对每个任务还需要设计其对应的故事线，因此不同行业、甚至不同公司都需要根据具体情况来定制。</p><p></p><p>非生成式应答生硬：任务型多轮对话的应答通常是非生成式的，采用的方法往往是枚举、模板等，因此，回复会显得比较生硬，影响客户体验。</p><p></p><p>难以适应语言环境的变化速度：自然语言的创造力很强，变化也非常快，例如“碳交易”、“元宇宙”、“预制菜”、“政银担”等等，新词的出现对于对话系统是很大的考验，需要考虑如何设计产品以跟上快速变化的语言环境。</p><p></p><p>系统使用门槛高：对于系统使用人员来说，构建一个完整的任务型对话机器人具有一定的专业门槛，其中涉及到大量的机器学习模型，如何训练模型、优化模型等，难度都会比较大。</p><p></p><p></p><h2>中关村科金的解决方案</h2><p></p><p></p><p>针对任务型多轮对话系统中存在的挑战，中关村科金提出了自己的解决方案。</p><p></p><p></p><h3>沉淀行业知识，抽象领域通用能力</h3><p></p><p></p><p>针对定制化程度高、非生成式应答生硬的问题，中关村科技的解决方法是定义完善的标签体系与领域实践模板，将知识进行沉淀。</p><p></p><p>据了解，目前中关村科金基于数亿人机对话语料，构建了 100+ 通用实体与意图，帮助客户快速搭建自身领域的标签体系。另外，在某些特定领域，例如金融行业，中关村科金积累了大量行业标注语料，形成了自有的领域实践模板，同领域的客户可以直接应用“现有模板”，避免从 0 到 1 的冷启动阶段，加速项目落地应用。</p><p></p><p></p><h4>&nbsp;借助流程挖掘，构建领域特定故事</h4><p></p><p></p><p>如果我们把多轮对话看作流程，借助流程挖掘技术，就可以从海量数据中绘制出流程图，辅助专家抽象领域 SOP。而基于已有 SOP 的实践，又可以通过流程挖掘的 Replay 技术，完成对关键话术节点、风险对话节点等的感知与预测，针对性的优化改进，进一步完善领域 SOP，助力客户业务增长。</p><p></p><p>在实际的应用中，流程挖掘已经成为中关村科金帮助客户实现领域标准对话程序的关键技术。</p><p></p><p></p><h4>通过闭环迭代，实现智能化运营</h4><p></p><p></p><p>多轮对话依赖于底层知识库与模型，中关村科金通过人机闭环链路，实现了非专业运营的智能化迭代优化。</p><p></p><p>对于知识库，通过知识发现、知识细化、知识优化、知识淘汰四步，运营人员仅需对部分新知识进行审核，即可实现知识库的快速迭代更新。</p><p></p><p>而在模型方面，中关村科金自研的自训练平台，提供了业务中积累的大量规则、模型算子，通过少量的配置，运营人员即可实现模型的优化，降低了学习成本，解决了对话系统使用门槛高的问题。</p><p></p><p>以营销行业为例，中关村科金基于对话式 AI 技术，通过将 MAP 平台、智能外呼机器人、文本机器人、RPA 结合，构建一体化营销云产品。在为某消金线上业务服务中，将营销的 SOP 流程标准化后沉淀下来，配置在营销自动化模块中，基于用户分层实现自动化群发、自动化回复、自动化标签等，打造全新的私域自动化运营体系，营销转化率提升 30%、人力成本下降 60%，帮助客户实现降本增效。</p><p></p><p></p><h4>任务型多轮对话的未来发展趋势</h4><p></p><p></p><p>因其可控性，在可预见的未来任务型多轮对话依然将是对话系统的主要表现形式之一。随着技术的不断提高，中关村科金认为以下三个方面会是任务型多轮对话的未来发展方向。</p><p></p><p>1）冷启动始终是 AI 所不可避免的问题，如何基于现有的大量未标注数据，快速实现对话系统的搭建值得深入研究；</p><p>2）机器学习模型目前还停留在感知智能的阶段，并没有真正理解对话中的含义，同时欠缺对于领域知识、常识知识的应用。引入领域知识和常识知识，并且能够进行知识的推理，将极大的提高对话系统的实用性与竞争力；</p><p>3）语言不是唯一的交互途径，人类的表达方式是多种多样的，人机对话系统的交互方式必将向多模态的方向发展。</p><p></p><p>未来，中关村科金将不断提升多模态对话式 AI，尤其是任务型对话的技术实力与场景落地能力，抓住这一企业数字化转型赛道上的关键技术，助力企业数字化变革。</p>",
    "publish_time": "2023-04-21 13:09:39",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]