[
  {
    "title": "Stability AI开源图像生成模型Stable Diffusion",
    "url": "https://www.infoq.cn/article/p1DHKrHQjEsQvDcr9jlM",
    "summary": "<p><a href=\"https://stability.ai/\">Stability AI</a>\"对外发布了<a href=\"https://stability.ai/blog/stable-diffusion-public-release\">Stable Diffusion</a>\"的预训练模型权重，这是一个文本至图像的AI模型。根据文本提示，Stable Diffusion能够生成逼真的512x512像素的图像以描述提示中的场景。</p><p></p><p>在模型权重公开发布之前，它的代码已经<a href=\"https://stability.ai/blog/stable-diffusion-announcement\">发布</a>\"，模型权重也有限发布给了研究社区。在最新的版本中，任何用户都可以在消费者级别的硬件中下载并运行Stable Diffusion。除了文本至图像的生成，该模型还支持图像至图像的风格转换以及图像质量提升。在发布该版本的同时，Stable AI还发布了beta版本的API以及模型的Web UI，名为<a href=\"https://beta.dreamstudio.ai/\">DreamStudio</a>\"。Stable AI这样说到：</p><p></p><p></p><blockquote>Stable Diffusion是一个文本至图像的模型，它能让数十亿人在几秒钟内创建出令人赞叹的艺术品。在速度和质量方面，它都有所突破，这意味着它能在消费者级别的GPU上运行……这能够让研究人员和……公众在各种条件下运行，使图像生成技术走向大众。我们期待围绕该模型和其他模型出现一个开放的生态系统，以探索潜在空间的边界。</blockquote><p></p><p></p><p>Stable Diffusion基于名为<a href=\"https://ommer-lab.com/research/latent-diffusion-models/\">潜在扩散模型（latent diffusion models，LDMs）</a>\"的图像生成技术。与其他的流行的图像合成方法不同，如<a href=\"https://en.wikipedia.org/wiki/Generative_adversarial_network\">生成对抗网络（generative adversarial networks，GANs）</a>\"和<a href=\"https://openai.com/dall-e-2/\">DALL-E</a>\"使用的自动回归技术，LDMs通过在一个潜在表示空间中迭代“去噪”数据来生成图像，然后将表示结果解码为完整的图像。LDM是由<a href=\"https://www.lmu.de/\">Ludwig Maximilian University of Munich</a>\"的<a href=\"https://ommer-lab.com/\">机器视觉与学习（Machine Vision and Learning）</a>\"研究组开发的，并在最近的IEEE / CVF&nbsp;<a href=\"https://arxiv.org/abs/2112.10752\">计算机视觉和模式识别会议（Computer Vision and Pattern Recognition Conference）</a>\"上发表的一篇论文中进行了阐述。在今年早些时候，InfoQ曾经报道过谷歌的<a href=\"https://www.infoq.cn/article/QhKzahCQ9bdTgAUobYUg\">Imagen</a>\"模型，它是另一个基于扩散的图像生成AI。</p><p></p><p>Stable Diffusion模型支持多种操作。与DALL-E类似，它能够根据所需图像的文本描述，生成符合匹配该描述的高质量图像。它还可以根据一个简单的草图再加上所需图像的文本描述，生成一个看起来更逼真的图像。Meta AI最近发布了名为<a href=\"https://ai.facebook.com/blog/greater-creative-control-for-ai-image-generation/\">Make-A-Scene</a>\"的模型，具有类似的图像至图像的功能。</p><p></p><p>Stable Diffusion的很多用户已经公开发布了生成图像的样例，Stability AI的首席开发者Katherine Crowson在推特上分享了<a href=\"https://twitter.com/RiversHaveWings\">许多图像</a>\"。基于AI的图像合成可能会对艺术家和艺术领域带来一定的影响，有些评论者对此感到不安。就在Stable Diffusion发布的同一周，一幅由AI生成的艺术品在科罗拉多州博览会的<a href=\"https://news.artnet.com/art-world/colorado-artists-mad-ai-art-competition-2168495\">艺术比赛中获得了一等奖</a>\"。Django框架的共同创建者Simon Williamson<a href=\"https://twitter.com/simonw/status/1563914121883488258\">认为</a>\"：</p><p></p><p></p><blockquote>我见过一种说法，认为AI艺术没有资格获得版权保护，因为“它必须归功于全人类”——如果基于文本生成的设计尚不足以说服公众的话，那[图像至图像]技术可能会打破这种平衡。</blockquote><p></p><p></p><p>Stable AI的创始人Emad Mostaque在推特上回答了一些关于该模型的问题。在回答一位试图<a href=\"https://twitter.com/EMostaque/status/1563870674111832066\">估算训练模型所需的计算资源和成本的</a>\"用户时，Mostaque说到：</p><p></p><p></p><blockquote>实际上，我们为这个模型使用了256个A100显卡，总共15万小时，所以按市场价格计算为60万美元。</blockquote><p></p><p></p><p>Mostaque给出了Reddit上一篇文章的链接，其中给出了如何最好地使用该模型来生成图像的<a href=\"https://www.reddit.com/r/StableDiffusion/comments/x41n87/how_to_get_images_that_dont_suck_a/\">技巧</a>\"。</p><p>Stable Diffusion的代码可以在<a href=\"https://github.com/CompVis/stable-diffusion\">GitHub上找到</a>\"。<a href=\"https://huggingface.co/CompVis/stable-diffusion\">模型的权重</a>\"以及<a href=\"https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb\">Colab notebook</a>\"和<a href=\"https://huggingface.co/spaces/stabilityai/stable-diffusion\">示例Web UI</a>\"都可以在HuggingFace上找到。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/09/stable-diffusion-image-gen/\">Stability AI Open-Sources Image Generation Model Stable Diffusion</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/QhKzahCQ9bdTgAUobYUg\">谷歌最新 Imagen&nbsp;AI&nbsp;在文本至图像生成方面优于 DALL-E</a>\"</p>",
    "publish_time": "2022-09-19 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "性能透明提升 50%，详解SMC + ERDMA 云上超大规模高性能网络协议栈",
    "url": "https://www.infoq.cn/article/dX0r5aHOOm0FJb3fTuzR",
    "summary": "<p></p><blockquote>当前内核网络协议栈有什么问题？新的协议栈是不是重新发明轮子？一个协议栈能否解决所有问题？适配所有场景？本文整理自 2022 年阿里巴巴开源开放周技术演讲。</blockquote><p></p><p></p><p>本文主要分为三部分：第一部分是我们为什么需要一个新的内核网络协议栈，我们是不是在重复发明轮子？第二部分是 SMC + ERDMA 的原理、优劣等等，快速为大家了解 SMC 技术。第三部分是 SMC-R 在网易 Curve 分布式系统的实践。</p><p></p><h2>一、我们为什么需要一个新的内核网络协议栈？</h2><p></p><p></p><p>当前内核网络协议栈有什么问题？新的协议栈是不是重新发明轮子？一个协议栈能否解决所有问题？适配所有场景？这里我们将自己的思考分享出来，和大家一起交流。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/70/e4/700bd6f73ea1bea6305483bdaedf7ae4.png\" /></p><p></p><p>首先我想要抛出一个观点，没有一个网络栈是万能的，之于此没有银弹。要谈现状，离不开背景：</p><p></p><p>第一是 100G/400G 网络的普及，此时 CPU 是瓶颈。第二是云、规模，当前越来越多的业务迁移到云上，云上支持传统 RDMA 网卡成本很高。第三是 DPU，硬件卸载，承接第一点，CPU 成为瓶颈后，是否可以让网络栈将越来越多的逻辑卸载到网卡和 DPU 上，让 CPU 做更多更重要的事情。</p><p></p><p>我们如何平衡吞吐和时延？或者说如何用最少的 CPU 达到相同的吞吐，如何尽可能地降低时延。</p><p></p><p>首先 <a href=\"https://xie.infoq.cn/article/fdbe4ad63e96753c83d6cb7c7\">Linux 内核</a>\"的网络栈倾向于吞吐，而不是时延。提升吞吐很重的一点是，降低拷贝的开销。在大包吞吐的场景，我们很容易看到拷贝占据了&nbsp;CPU 的绝大部分时间。而且内核网络栈的 context switch 开销，拷贝开销也会增加额外的时延。</p><p></p><p>那么这个问题变成了选择在内核态还是用户态实现一个网络栈？</p><p></p><p>我想很多应用，或者说云上 99% 以上的应用使用的是 socket 接口，如果侵入性改造，对于用户态方案最大的壁垒。比如 DPDK 等，此时不仅仅是改造成本，也包括了运维成本、部署成本等等。当然用户态也可以劫持 socket 实现用户态协议栈，但此时 zero copy 等优势不在。并且同样需要改造，此处的改造是运维改造，调度改造和环境改造，这也是额外的成本。此时用户态的优势也不再显著。</p><p></p><p>软件 vs 硬件卸载？</p><p></p><p>一开始 Linux 网络栈，例如 TCP 协议是从纯软件实现到越来越多的将功能卸载到网卡，甚至 TOE 完全卸载到网卡。如果提到卸载到网卡，是不是可以用一种更加成熟的硬件卸载方案？也就是 RDMA，也就是传统以太网卡 vs RDMA 网卡，部分卸载到成熟的完全卸载。RDMA 网络本身有规模的限制，我们可以在小规模把 RDMA 网络玩得很好。那是否有一种大规模 RDMA 的能力。我们现在看到的是阿里云发布的 ERDMA 网络，一种普惠、高性能、完全兼容 RDMA 的生态。我们借助 SMC + ERDMA 可以实现硬件卸载 RDMA 、大规模部署，二者相辅相成。</p><p></p><p>开箱即用 vs 应用改造？</p><p></p><p>上面已经提到一部分，云上 99% 的应用使用的是 socket 接口编程，TCP 进行通信。绝大部分应用不可能投入大量成本改造适配新的网络栈，其中包括开发成本，测试成本（新的协议栈可能会有各种问题），部署和运维成本（例如 DPDK 环境，额外软件包的维护）等。此时还会让应用牢牢绑定在某个网络栈之上，后续迁移，或者遇到环境不支持的情况下，成本更高。所以我们分析后，得出的结论是，当前需要一个兼容 socket 接口，可以透明替换传统 TCP 应用的，硬件卸载的网络栈。利用云上大规模部署、DPU 硬件卸载、达成 100G/400G 网络的全新网络栈。</p><p></p><h2>二、共享内存通信 SMC</h2><p></p><p></p><p>有一点很重要，前面我们没有讨论，也就是所谓的数据通信模型。IPC 进程间通信，TCP 也是进程间通信的一种。我们按照第一性原理，拆分成不同的不可拆分的数据通信模型。对比这几种模型最佳实践下可能的性能数据。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/17/ba/17d121353cbc63084c8dcc32543ayyba.png\" /></p><p></p><p>常见的是基于包的通信模型，例如最典型的 TCP，TCP loopback 性能不是特别理想，但是易用性毋庸置疑。我们之前有提到，绝大多数应用使用的是 socket 编程，其次是共享内存，这个在本机维度的 IPC 通信中，也是一种非常常见的方式。共享内存实现千差万别，但是总体来看，性能远远超过上面几种方式，但是易用性堪忧，第一是提到的实现方式不同、库不同、接口不同，和语言和运行时绑定，导致大部分共享内存的实现不具备跨越应用的普适性。</p><p></p><p>我们快速回顾一下共享内存通信的模型：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/18/9a/187d841dbfyyea9f84c3c9c4ee67c49a.png\" /></p><p></p><p>左边的图中，下面不同颜色的方块代表不同的内存，分别分成&nbsp;sender 和 reciver 角色。首先发送方写入数据到这一块共享内存，之后通过某种方式，通知接收方数据写到了哪里、偏移量是多少，其次接收方按照游标位置读取或者拷贝走这一块内存上的数据，之后通知发送方，本地已经读取完成，下次写数据可以从某某位置开始。</p><p></p><p>这样一次简单的数据通信就完成，同时是 zero copy，这里是单向，如果是双向，只需要维护两个内存区域即可。那么是否有一种技术可以帮助我们搬运内存，让下面两个方框的内存保持同步，从单机共享内存到远端共享内存？答案也就是之前提到的 RDMA，RDMA 本身就是远端直接内存方案的缩写。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/48/1f/481febe16a1b7a5486b36658601a441f.png\" /></p><p></p><p>前面 4 步我们可以完成本地的共享内存通信，基于 RDMA，我们的数据模型只需要一个比较小的改动，也就是在第二步，通过 RDMA write 实现内存从本地同步到远端。这样本地和远端维护内存上的数据可以保持一致，同时通过 RDMA send 作为消息通知机制、通知游标更新。同时也可以实现 zero copy 硬件卸载。</p><p></p><p>基于上面的分析，我们是不是可以基于共享内存同时兼容 socket，基于RDMA 硬件卸载实现这样一个可能高性能的网络栈呢？答案是肯定的，通过 SMC + ERDMA 构建云上高性能网络栈，为什么说 <a href=\"https://www.infoq.cn/article/3rBcBW7v2z46Wv6LVoX6\">SMC + ERDMA</a>\" 可以满足上面我们的结论呢？首先，我们快速了解一下 SMC。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/7d/1a/7dc7f56153368ffc9b6c938fe2cb881a.png\" /></p><p></p><p>SMC 是 IBM 开源到 Linux 代码中，同时 IBM 也一同提出了 IETF RFC 7609，作为描述 SMC-R 协议是如何实现的。首先在上游社区中，龙蜥社区为上游贡献的补丁数排第二，其次，SMC 本身也是一种协议，Linux 下为 AF_SMC，可以直接在 socket 中制定使用，没有其他特殊的 hack 或者&nbsp;tricky 的实现，和 TCP 等价。</p><p></p><p>模型采用了共享内存技术，结合 RDMA 可以实现一次拷贝，硬件卸载的性能。同时最为重要的是，SMC 本身是一种混合协议，SMC 协议本身，需要借助某种更通用的协议建立 RDMA 链接，同时还需要提供一种 fallback 回退机制，如果没有 RDMA 支持，可以透明回退到 TCP。</p><p></p><p>最后，SMC 兼容 socket，可以透明替换所有的 TCP 应用，应用无需改造，也无需配置，即可享受 SMC 带来的性能加速。通过上述特性，最大化兼顾性能和生态。SMC 可以在云上高性能和大规模部署，也离不开阿里云的 ERDMA。ERDMA 完全兼容 RDMA 生态，兼容 verbs 接口，verbs 应用可以无需改造。同时云上的 ERDMA 具备超大规模部署的能力，解决了传统 RDMA 网络的部署难题。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/b7/f6/b7a4aa80b7f1bb34f82818ff8f7dabf6.png\" /></p><p></p><p>SMC 使用 verbs 接口，可以在云上直接使用 ERDMA，从而实现硬件卸载，高性能的网络栈&nbsp;SMC 是如何使用 RDMA 的？</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/0c/41/0c356324171755c27d9abb44e9721a41.png\" /></p><p></p><p>SMC 首先使用 TCP 带完建连，使整个 RDMA 链路可用，此时 TCP 链接可以用于回退，任何 RDMA 的问题都可以顺利回退到 TCP，确保 SMC 链接的可用。其次 RDMA 负责整个数据的通信，在内核态是 zero copy。SMC 有一次用户态-内核态拷贝。RDMA 技术的另一个问题是链接的规模，特别是 RC 模式下，链接的规模不是很大。</p><p></p><p>SMC 通过 linkgroup，将 N 个链接映射到 1 个或多个 RDMA QP 之上，充分复用 QP 资源，也加快了控制路径创建 QP 慢的问题，最重要也具备了 linkgroup 多 QP 的容灾高可用的能力。最后 SMC 支持 RoCE v1/v2，龙蜥版本还支持 ERDMA，确保 SMC 既可以使用在云上，也可以使用在数据中心内部。我们多次提到了 SMC 基于 TCP 链接建连，那么 SMC 是怎么做的？</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/88/42/883168dc24efc5f467b886f832da2442.png\" /></p><p></p><p>首先 SMC 本身是一种混合协议，协议底层包括 TCP 和 RDMA，充分运用&nbsp;TCP 通用、兼容、可达率高、RDMA 高性能的优势。同时这一条 TCP 链接也可以帮助 RDMA 不可用或者建连错误后，快速回退到 TCP 模式，对于应用完全透明。SMC 通过 TCP SYN 包中的特定的 TCP options 标注是否支持 SMC 能力。如果支持会接下来交换 RDMA 建连所需的信息，SMC 兼容 socket 之后，是如何透明替换 TCP？</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/12/02/12b5ea722b6ecb2570e2a21399761e02.png\" /></p><p></p><p>首先 AF_SMC 和 AF_INET 是在同一层级。对外暴露的接口和性能完全一致，应用可以在创建 socket 的时候直接使用 AF_SMC，与使用 TCP 时完全一致。应用不仅可以显示的制定 AF_SMC，也可以使用 smc_run 命令，快速将 TCP 替换成 SMC，如左图所示，任何应用都可以透明改造，无需任何适配，SMC 模块也会自动载入到内核。</p><p></p><p>其次支持 netns 维度的替换，支持容器场景下的加速。也支持 eBPF 的策略替换，通过 eBPF 编写规则匹配所需的应用特征，选择性的替换成 SMC。对于一些不重要，不想要占用 SMC 资源，或者不适合 SMC 的场景，可以使用这种方式。</p><p></p><p>SMC 回退机制，也是 SMC 为什么能够替换 TCP 重要的一个特性。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/65/4f/65728e56b2a34fa53c4baefa3175f44f.png\" /></p><p></p><p>上图左边可以看到，SMC 首先创建 TCP 链接，经过 TCP 的握手后，才会进行 SMC 握手。如之前所提到的是，SMC 是混合协议，在 RDMA 建连失败后，可以快速透明的切回到 TCP。同时也提供了各种错误码，帮助应用排查问题，例如 RDMA 网卡问题，还是资源问题等。谈了这么多 SMC 自身的特性，那么 SMC 的性能如何？下面的测试是在阿里云上 ERDMA 网卡和 SMC 对比 TCP 的性能。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/88/76/888b8fea1bfb08eb7767aa7288926576.png\" /></p><p></p><p>例如常见的 netperf microbenchmark 有一倍以上的性能提升。Redis 和 Netty 这种常见的基础组件有 30% 到 50% 的 QPS 提升，时延也显著下降。NGINX 也有 40% 左右的性能提升。这些性能提升，都是在应用无需任何改造，透明替换成 SMC 下进行的测试。接下来我们聊一下我们龙蜥社区在 SMC 上所做的工作。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/e2/2f/e26f2a21e813bdbb7bf915db0487a22f.png\" /></p><p></p><p>2021 年 11 月开始在社区密切参与开发和稳定性工作，当前贡献共计 70 多个补丁，排在 IBM 之后为第二。首先我们从头到尾优化了 SMC 的性能，包括短链接性能，包括吞吐和一些 syscall，CQ 中断打散等优化，最终 microbenchmark 综合性能提升了 357%，这里是对比的 SMC 之前的版本，对比 TCP 可以参考刚才的数据。其次是更多的场景支持，包括云原生、ERDMA、容器网络等等，拓宽了上游社区 SMC 的使用场景。</p><p></p><p>最重要的是，极大地提升了稳定性，我们一直在持续看护上有社区，解决了数十个 panic 问题，彻底解决了遗留的 link 和 linkgroup 问题，同时也在持续看护 SMC。龙蜥社区我们有 CI/CD 持续不断的测试，能够成为一个产品级别的协议栈。大家可以访问我们的仓库（地址见文末），使用 HPN 中我们不断优化的 SMC 版本。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/d0/3b/d05717bc007488e896aa96fd35c59c3b.png\" /></p><p></p><p>接下来我们谈一谈 SMC 的未来。</p><p></p><p>回到分享的开始，SMC 同样也不是银弹。SMC 基于 RDMA 技术，本身也有 RDMA 引入的各种各样的问题。第一是内存消耗，SMC 本身需要一致维护一块比较大的连续内存区域，用来实现共享内存通信，内存消耗显著大于 TCP。其次是 SMC 的建连性能，还是会受制于 RDMA RC 模式的建连性能，这一块我们会持续不断的优化，相关优化我们会陆续推送到社区。其次是稳定性，SMC 不同于 TCP 在业界广泛使用多年。有很多问题没有被发现，我们当前也在借助 SMC CI/CD 帮助我们发现问题。</p><p></p><h2>三、SMC-R 在网易 Curve 存储系统的实践</h2><p></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/92/cc/92b337163ef671494eb2a9777b7f47cc.png\" /></p><p></p><p>首先介绍一下 Curve。Curve 是一个开源分布式存储系统，可对接 OpenStack 平台为云主机提供高性能块存储服务，可对接 Kubernetes 为其提供持久化存储卷，可对接 PolarFS 作为云原生数据库的高性能存储底座。Curve 在性能、运维、稳定性、工程实践质量上都优于 Ceph。下面介绍 Curve 的网络通信：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/b3/6c/b3f94a3345882fcb9da83d9a6e18746c.png\" /></p><p></p><p>通信过程为由 leader 向 follower 发起 RPC 进行数据拷贝。特点是：网络通信频繁、网络通道稳定、网络传输时延小、RPC 时延占比不低。因此我们调研了几种网络加速选型：</p><p></p><p>其中 <a href=\"https://www.infoq.cn/article/l2chlCBlSb1kCZu1m9O2\">SMC-R</a>\" 可以实现透明替换，无侵入，并且提供较好的性能。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/7b/7a/7bef6be44e60fefa73fc58c371e3e67a.png\" /></p><p></p><p>我们使用 SMC-R 改造了 Curve 并使能。同时扩展了黑名单、资源监控和读取速度监控等能力。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/3e/16/3edb66f5fbf7aa69dd3dd89792f31516.png\" /></p><p></p><p>我们使用 Curve E2E 测试，在 3 Volume &nbsp;256 depth randwrite case 下，对比 TCP 提升了 18.5% 的性能。</p><p></p><p>最后，以上为大家介绍了我们为什么需要 SMC，SMC 的原理和性能以及 SMC 在网易 Curve 的最佳实践。对于 SMC 而言最重要的是社区和生态，在此欢迎大家使用并参与龙蜥社区和 SMC 社区，一同打造 SMC 高性能网络协议栈。</p><p></p><p>本文作者</p><p></p><p>陆扬，阿里云技术专家、龙蜥高性能网络 SIG 成员</p><p>刘亚灿，网易资深服务端开发工程师</p><p></p><p>相关链接：</p><p></p><p>高性能网络 SIG：</p><p>https://openanolis.cn/sig/high-perf-network</p><p>SMC代码仓库：</p><p>https://gitee.com/anolis/hpn-cloud-kernel</p>",
    "publish_time": "2022-09-19 10:19:18",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "2022 深圳国际金融科技大赛（FinTechathon）正式启航：打造世界级顶尖赛事，全面推动金融科技创新！",
    "url": "https://www.infoq.cn/article/7ejrDIB7r5KRIuLwaRPd",
    "summary": "<p>金融科技（FinTech）是金融与科技的融合产物，目前已成为全球金融行业创新和竞争的制高点与主战场。业界一致认为，金融科技将在未来数年迎来战略发展机遇期，行业可能出现颠覆级的科技创新改变金融生态。为此，深圳市地方金融监督管理局在今年发布的《深圳市扶持金融科技发展若干措施》中明确表示，\"从 2022 年起，深圳市人民政府将每年举办金融科技节，期间将举办金融科技大赛、金融科技论坛和金融科技展。\"</p><p>&nbsp;</p><p>9 月 19 日，作为深圳市首届金融科技节中的重要一环，2022 深圳国际金融科技大赛（ FinTechathon ）—— 西丽湖金融科技大学生挑战赛（下文称“大赛”）将正式开赛。</p><p>&nbsp;</p><p>这是一场面向金融科技前沿领域，专为学生团队打造的世界级竞赛。大赛的战略指导单位为深圳市地方金融监督管理局、深圳市南山区人民政府、深圳市福田区人民政府、主办方为深大微众金融科技学院、微众银行、深圳香蜜湖国际金融科技研究院。其中，微众银行是国内首家践行普惠金融理念、充分运用<a href=\"https://www.infoq.cn/article/jtG2A4Xg123R0iFHHGgA\">金融科技</a>\"建设的互联网银行，为助力金融科技产业发展，在人工智能、<a href=\"https://xie.infoq.cn/article/50a68cd3c8337daa348ccf0c2\">区块链</a>\"、云计算、大数据领域发起 30 多个<a href=\"https://www.infoq.cn/article/S72hXOUgAjtFrADTFIzu\">开源项目</a>\"，目前已成为“业界技术顶流”；深大微众金融科技学院则是深圳大学与微众银行共同创建的国际化、高水平研究型金融科技学院，学院同时规划布局不同的专业方向以满足国家金融科技产业各细分领域的专业技术人才培养需求。两家单位强强联合，充分发挥人才环境与产业环境耦合效应，通过产研融合的方式全力驱动金融科技领域的发展与创新。</p><p>&nbsp;</p><p>大赛旨在充分发挥政、学、企多方优势，共创金融科技领域盛世赛事先锋，合力推动国内外高校学生探索金融科技领域的技术应用创新，全面提高高校学生的创新能力、实践能力和就业竞争力，丰富金融科技人才储备以打造深圳市金融科技发展高地，为深圳市抢抓金融科技发展机遇、加快金融科技产业升级注入一股硬核力量。</p><p>&nbsp;</p><p>基于深圳市当下完整良好的金融科技生态，大赛倾力打造人工智能、区块链、金融产品经理三大赛道，多维挖掘高校学生的优秀金融科技创新成果，启思高校学生输出贴近金融科技企业需求的技术及产品解决方案。大赛主办方设置总额超过 69 万元人民币的赛事奖金，激励高校人才持续积极投入到金融科技创新事业中。</p><p>&nbsp;</p><p>此外，大赛主办方还将协同珠海华润银行、平安银行用卡中心、江南银行、金证股份、安信证券、第一创业证券、德科信息、国家金融科技测评中心、华策数科、微言科技等数十家金融及科技相关企业，为进入决赛的学生提供 100 余张可双向选择的实习面试直通卡，助力高校人才实现更充分、更高质量的就业目标，构建产学研一体化人才培养模式，以构建金融科技人才培育生态圈。同时将积极响应国家号召，持续向社会输送优秀的金融科技创新型人才，真正担负起“为党育才、为国育人”的使命。</p><p>&nbsp;</p><p>大赛组委会特别邀请加拿大皇家科学院院士、加拿大工程院院士杨强；加拿大工程院院士、加拿大工程研究院院士、人工智能与数字经济广东省实验室（深圳）执行主任于非；上海交通大学中银科技金融学院院长刘少轩；香港中文大学（深圳）经管学院校长讲席教授张博辉等人担当学术顾问，为大赛提供智力支持。另有来自中科院、深圳大学、武汉大学、西南财经大学、华南理工大学、微众银行等学企单位的数十位科研专家担任大赛评委，为参赛团队指点迷津。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/6e/a2/6ee8c0bdfef60134f67d810df0fd6ea2.jpeg\" /></p><p></p><p>值得一提的是，为贯彻落实深圳市金融科技节指导方针、营造深圳市良好的金融科技生态环境，在大赛决赛及颁奖环节还将举办“金融科技高校论坛”活动，特邀各位专家将围绕“金融科技”展开深度话题分享、圆桌对话，为金融科技领域的发展提供方法论与新思路，蓄能并引爆深圳市首届金融科技节活动高潮。</p><p>&nbsp;</p><p>据悉，大赛前身是 FinTechathon 微众银行金融科技高校技术大赛，前三届参赛人数逐届递增，共吸引 2100 余名来自海内外知名高校的学生参赛，成功在行业内掀起科技创新浪潮。</p><p>&nbsp;</p><p>9 月 19 日起，本届大赛正式开启报名通道，国内外高校在读生（含本科生、硕士/博士研究生）均可报名参赛。有兴趣的同学可点击阅读原文进入大赛官网 <a href=\"https://www.infoq.cn/zones/fintechathon/campus2022/\">https://www.infoq.cn/zones/fintechathon/campus2022/</a>\" 或识别下方海报中的二维码进行报名。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/27/f0/271ff9ac1b4c21eacdc22fc8bfbf35f0.jpg\" /></p><p></p>",
    "publish_time": "2022-09-19 14:12:39",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "苹果拥抱RISC-V更进一步：消息称苹果嵌入式内核将全面转移到RISC-V架构",
    "url": "https://www.infoq.cn/article/rUNXzRRtL9YGUvCGWiBm",
    "summary": "<p></p><blockquote>新兴的RISC-V作为第三大芯片架构正改变做全球芯片架构竞争格局，</blockquote><p></p><p></p><h2>分析师称苹果或将进一步拥抱RISC-V架构</h2><p></p><p>&nbsp;</p><p>日前，据SemiAnalysis报道，苹果正在将其嵌入式内核将全面转移到<a href=\"https://www.infoq.cn/article/x4JNvgz3R55boVWr3ujy\">RISC-V架构</a>\"。</p><p>&nbsp;</p><p>RISC-V 是一个基于精简指令集（RISC）原则的开源指令集架构（ISA）。2010 年，开源指令集架构 RISC-V 首次出现在美国加州大学伯克利分校，其开源架构的形式很快就吸引了包括 IBM、恩智浦、WeaternDigital、NVIDIA、Qualcomm、三星、Google、华为、Tesla 等各大厂商的加盟。</p><p>&nbsp;</p><p>与大多数指令集相比，RISC-V指令集可以自由地用于任何目的，允许任何人设计、制造和销售RISC-V芯片和软件。虽然这不是第一个开源指令集，但它具有重要意义，因为其设计使其适用于现代计算设备（如仓库规模云计算机、高端移动电话和微小嵌入式系统）。设计者考虑到了这些用途中的性能与功率效率。该指令集还具有众多支持的软件，这解决了新指令集通常的弱点。</p><p>&nbsp;</p><p>Semianalysis分析师Dylan Patel表示，即使许多人认为 RISC-V 缺乏软件生态系统，但他强调，RISC-V 正迅速成为新的处理器标准。“苹果的 A15 芯片分布着十几个基于 Arm 的 CPU 内核，用于各种非面向用户的功能。SemiAnalysis 可以确认这些内核在未来几代硬件中，正在积极地转换为 RISC-V。”</p><p>&nbsp;</p><p>据超能网报道，目前苹果M系列处理器中，除了主内核外，还有大量的嵌入式内核，负责与操作系统无关的各种工作负载，包括Wi-Fi/蓝牙、触摸板控制、雷电接口等。这些嵌入式内核运行着自己的固件，围绕运行操作系统的主核心为周边提供动力。</p><p>&nbsp;</p><p>当前，这些嵌入式内核大都基于Arm的Cortex-M系列或低端的Cortex-A系列内核，苹果需要为此支付一大笔授权费用。随着苹果自研芯片进一步发展，后续使用内核数量也会对应增加，支付的费用也将水涨船高。如果将嵌入式内核将全面转移到RISC-V架构，苹果可以省下一大笔钱。</p><p></p><h2>苹果押注RISC-V，早有苗头</h2><p></p><p>&nbsp;</p><p>早在去年，市场上就已有苹果拥抱RISC-V的消息。</p><p>&nbsp;</p><p>去年9 月，苹果发布<a href=\"https://www.infoq.cn/article/CXTRIj6DCgOQj5yYPNjx\">招聘</a>\"启事称正在为其核心操作系统团队的 Vector and Numerics Group (VaNG) 小组寻找对 RISC-V 指令集架构 (ISA) 和 ARM 的 Neon vector ISA 有详细了解且有丰富经验的开发者。</p><p>&nbsp;</p><p>根据招聘广告，这名工程师将在苹果产品上采用“创新的 RISC-V 解决方案和最先进的程序”。具体地说，苹果希望未来的工程师能够使用 RISC-V 指令集，并了解 ARM。</p><p>&nbsp;</p><p>彼时有分析认为，该招聘仅可表明苹果正在探索 RISC-V 的使用，但最终是否决定采用这项开源技术以及是否会用其替代现有芯片架构都是未知的。而在当前来看，苹果拥抱RISC-V或许已成定局。</p><p>&nbsp;</p><p>事实上，近几年有越来越多的厂商和开发者加入 <a href=\"https://www.infoq.cn/article/ULKfa6cJ1uVzME9JQhJm\">RISC-V 的阵营</a>\"。</p><p>&nbsp;</p><p>日前，提供RISC-V内核的SiFive公司高管Jack Kang表示，“最近几年，中国对RISC-V的兴趣越来越大，这刺激了该架构的普及，到2025年，将有超过600亿个 RISC-V 内核集成到物理IC中。”</p>",
    "publish_time": "2022-09-19 15:08:02",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "淘宝店铺是如何全面拥抱 TypeScript 的",
    "url": "https://www.infoq.cn/article/dEAoEuVSEVKCcIm1WI1t",
    "summary": "<p>作者 ｜贾亚宁</p><p>嘉宾 ｜林伟轩</p><p></p><p>TypeScript 在 2021 年依然保持着持续稳定的增长，甚至逐渐成为很多大厂的首选工具。相信大家这段时间也会在各个大厂的年度技术总结文章中屡屡看到 TypeScript 的身影。</p><p></p><p>TypeScript 诞生之初就是为了解决 JavaScript 由于自身的局限性在大型项目中的挑战，它已经造就了许多我们耳熟能详的项目（如：VS Code）。但是在我们日常的项目开发中，可能对它又爱又恨；爱它带来了类型安全和代码即文档的类型注释，恨它带来了大量额外的类型代码，束缚了 JavaScript 的自由洒脱。</p><p></p><p>我们都知道，对于基于 TypeScript 的中大型项目，建立严谨的研发规约是非常有必要的，那么什么样的规约是兼顾各个角色最高效的解决方案？什么样的规约可以更往前看一步？制定规约的过程中会遇到哪些挑战，又如何解决呢？</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ab/abda11ca57421018b39f44dc7a2ce80e.jpeg\" /></p><p></p><p>出于对以上问题的好奇，我们找到了林伟轩老师。他是阿里巴巴淘系技术部的前端开发工程师，负责淘宝旺铺，制定并推进基于 TypeScript 的研发规约在整个淘宝店铺范围内的落地。他热爱开源社区，社区昵称：林不渡；<a href=\"https://github.com/linbudu599/linbudu599\">GitHub：linbudu599</a>\"。专注于前端工程化、GraphQL 和 NodeJS 等。</p><p></p><p>同时林伟轩老师也是已经上线的 <a href=\"https://time.geekbang.org/qconplus/home\">QCon+ 案例研习社</a>\"<a href=\"https://time.geekbang.org/qconplus/album/72\">「TypeScript 在中大型项目中的落地实践」</a>\"专题的讲师，他分别从研发侧和工程侧的角度分享了<a href=\"https://time.geekbang.org/qconplus/detail/100091375\">淘宝店铺项目是如何制定并落地 TypeScript 研发规约的</a>\"。因此我们针对 TypeScript 相关的疑惑和好奇对林伟轩老师进行了采访，让我们一起来看看老师的思考吧。</p><p></p><p></p><h5>InfoQ：你最近在负责什么样的工作呢？</h5><p></p><p></p><p>林伟轩：最近的话，我的核心工作范畴还是在店铺的旺铺侧，可以理解为是面向商家的 B 端产品，核心重点就是其中的旺铺装修部分，包括了移动端装修和 PC 端装修两个部分。偷偷剧透一下，移动端装修目前已经开发完毕，并开放给少数意愿强烈的商家试用当中，很期待未来它能够带给商家们便捷快速的店铺装修体验。</p><p></p><h5>InfoQ：你们团队在选择 TypeScript 时，是基于什么考虑呢？</h5><p></p><p></p><p>林伟轩：首先，做出迁移到 TypeScript 这个决定的过程中，团队中的意见基本是一致的，我们都认为，对于 B 端产品以及部分稳定性要求高的 C 端产品来说，使用 TypeScript 带来的收益一定会远远超出成本。比如我们收获了维护性、可读性、稳定性的成倍提升，通过 TypeScript 的类型定义作为协议层统一了许多分散的依赖库，提升了大家的代码质量等等。而对于一部分零散的独立模块，它们的变动是非常少的，但又非常重要，比如店铺域内官方提供的装修模块，我们就决定保持现状，因为迁移可能会带来超出预期的成本和不确定因素。</p><p></p><p>其次，我们在迁移上也有着长期的规划，如我在 QCon+ 案例研习社的分享里提到的，旺铺装修只是一个试点项目，在它之前与之后，我们还有数个重点项目也开始陆陆续续地迁移到 TypeScript，并且这些后续的过程也很好地借鉴了旺铺装修迁移过程中的经验与教训。</p><p></p><p>最后一点，基于 TypeScript 我们才能够推广更严格的约束，对人和对代码都是，包括 Code Review 要求、Lint、源码的解析、基于类型声明的统一协议层等等。</p><p></p><h5>InfoQ：从 JavaScript 项目迁移到 TypeScript，你有什么印象深刻的踩坑经历吗？</h5><p></p><p></p><p>林伟轩：我个人对 TypeScript 还算熟练，因此过程中倒是也没有遇到过代码层面的坑。但是我很享受将凌乱的 JavaScript 代码转变成干净整洁的 TypeScript 代码的过程。对比来看，在工程层面我倒是遇到了不少问题，如印象最深刻的一点我在 QCon+ 案例研习社的分享中也提到了，那就是在迁移工作开始的初期，没有明确好当前的工作重点，总是在添加类型时手痒地去改逻辑，并认为只要类型不报错就不会有问题，这导致了在后续出现问题时我需要一点点回滚代码去检查，最后往往发现就是当时以为不会产生问题的小小改动导致的。</p><p></p><p>在这种情况发生几次之后，我开始建立严格的分期规划，让每一期的职责完全独立开来，控制自己的手不去做超出当前规划范围的事情。同时确定了各部分最小修改单元的粒度，在完成一个单元的修改后就进行前后差异的检查，不是每修改一行文件，也不是每修改一天的文件。</p><p></p><p>这个困难看起来很简单，但它涉及到了一个核心问题，引入 TypeScript 是只为了添加类型来让项目更好维护，还是说想把整个项目的逻辑完全重写？这是你需要思考的问题，也需要基于自己更关注的问题做对应的规划和预案，而不是说我全都要，来把这两件事情混为一谈，这往往会导致灾难性的后果。也就是说，先确认你最希望从迁移到 TypeScript 得到哪些收益，然后基于此收益展开做规划，一次一口，勿贪得无厌。</p><p></p><h5>InfoQ：你认为 TypeScript 未来是否能得到浏览器和 Node.js 原生支持呢？</h5><p></p><p></p><p>林伟轩：我认为不太可能，首先说最现实的，TypeScript 的性能难以恭维。它需要类型检查，需要加载所有文件到内存，如果浏览器来做 TypeScript 到 JavaScript 的编译，那网页的性能无疑会受到严重的影响，类似的我们也可以认为 Node 同样不会原生支持，参考 Deno 将许多内部的 TypeScript 代码又重写回了 JavaScript。其次，TypeScript 本身的核心是编译时的检查，浏览器直接将其作为运行时支持基本上是没有意义的，因为类型的错误并不影响实际的代码运行，反而白白浪费了检查的时间。</p><p></p><p>还有很重要的一点，许多 TypeScript 拥簇者其实忽略了一个大家伙——ECMAScript，它才是 JavaScript 的实现提案。TypeScript 比 ECMAScript 提前实现了很多进行到 Stage3 阶段的语法，如可选链、空值合并、装饰器以及一些 Class 语法等。对于一部分在 TypeScript 实现完毕后又发生了变化的提案，比如装饰器，TypeScript 实现基于第一版 TC39 的装饰器提案，而目前装饰器提案已经进行到了第三版，实现已经和之前有了比较大的差异，那这可能就会在未来埋下一个祸根，或者说伏笔了。</p><p></p><p>总的来说，我们仍然会大量的使用 TypeScript，但我个人不认为它会得到浏览器和 Node 的原生支持，我们也不需要关注这一点，就像它自己都只关心编译到 JavaScript 的过程一样。</p><p></p><h5>InfoQ：你在使用 TypeScript 重构的过程中，如何协调各方之间的需求呢？</h5><p></p><p></p><p>林伟轩：实际上我理解对于 B 端性质的产品，负责的 PD 与测试同学对于技术改造往往持积极态度，因为正常来说技术改造能带来更高的开发效率和更好的稳定性，后面做起性能优化来也会简单不少。</p><p></p><p>而在协调资源层面，我觉得最重要的点，还是改造的发起者是否有清晰的规划，让 PD 和测试同学了解改造的节奏，需要的时间，是否存在风险，有没有健全的灰度、监控、回滚机制等等。其次就是需要协调出可投入技术改造的时间段，比如每个月留多少个人日，需求节奏放缓的阶段等等，根据这些情况再进一步完善整体的排期。</p><p></p><p>对于测试同学，一个比较良好的方式是在每一期完成后就进行一次回归测试，而不是在全部完成后再进行，以此避免过重的工作量和难以定位的问题。</p><p></p><p>对于团队层面来说，我暂时没有办法给出有用的经验，因为我自身也是一线开发而不是管理者，我看到的往往只是从自身的各种因素出发看到的结论，比如说在团队成员水平不一致的情况下，是否可以将首期，甚至前几期的要求适当放低，或者将整个迁移过程分更多期来帮助能力暂时不足的成员用较平缓的方式过渡。</p><p></p><h5>InfoQ：最后，有一个关于个人成长的话题，你是如何能在一毕业就加入阿里这种互联网大厂的呢？</h5><p></p><p></p><p>林伟轩：我个人其实不是科班出身，大学学的是管理科学。我在 2021 年校招加入阿里，目前算上实习的时间，工作经验差不多刚满一年。我个人踏上前端的路其实比较奇妙，从误触 F12 打开浏览器控制台知道什么是前端，到在网上看了一些前端的学习资源，再到加入学校工作室在一批 Nice 而有趣的人的帮助下一路成长到今天，这个经历不太具有复制性，这里就不赘述了。</p><p></p><p>我想分享一下我的做事原则和态度，我相信这几点正是推动我走到今天的力量：</p><p></p><p>换位思考、同理心，以及尊重。</p><p></p><p>马伯庸在《显微镜下的大明》一书中说到：“读史有一个很重要的原则，就是不要轻易把古人当白痴。我们今天可以看到的历史，和当时人的视角不同，获得的信息亦不同。如果设身处地去想，就能明白，很多看似愚蠢的举动，自有其逻辑和动机。”说白了就是，当我们在接触人事物，尤其是比较陌生的人事物时，一定不能从旁观者的角度直接给出评价，因为这必然过于主观和局限。我们该做的是将自己代入到对方的情境中，尽可能客观地评估自己相对于对方的意义，绝对不要以自我为中心。</p><p></p><p>保持对技术的热情与创新的初衷。</p><p></p><p>这一点我想不必多说，每个技术人都应该拥有。松本行弘说他最快乐的就是让其他的开发者能使用他的发明创造去做更多富有激情的事情。对于我来说，最快乐的事情就是自己的技术让更多的普通人享受到了互联网的便利。</p><p></p><p>独立自主的成长。</p><p></p><p>在内卷文化盛行的当下，我还是要说，不要焦虑、不要比较、不要急躁。不要因为别人会了自己不会的东西就莫名焦虑，为什么要做别人的影子呢？只学自己感兴趣的，只看自己想看到的；不要下意识地给自己设定竞争对手，否则不就是给自己设限吗？当你超越了这个竞争对手，你是继续确立下一个对手还是站在山巅之上茫然无措呢？不要因为未知的领域茫茫无尽就焦躁不安，没有人能探索完世界的每一个角落，你会因为没去过纽约、巴黎、莫斯科就痛苦吗？不会，因为这不会影响你的生活，同样的，专注 C 端产品的前端工程师也不会因为没用过 Express 就寸步难行。认清楚你最需要的，活在当下就好。</p><p></p><p></p><h4>嘉宾简介</h4><p></p><p></p><p>林伟轩  阿里巴巴 淘宝前端开发工程师</p><p>社区昵称：林不渡，现就职于阿里巴巴淘系技术部，负责淘宝旺铺，制定并推进基于 TypeScript 的研发规约在整个淘宝店铺范围落地。热爱开源社区，GitHub：linbudu599，专注于前端工程化、GraphQL、NodeJS 等。</p><p></p><p></p><h4>相关阅读</h4><p></p><p></p><p>林伟轩实操专题：<a href=\"https://time.geekbang.org/qconplus/album/89\">TypeScript 类型系统实战课：自顶向下学习类型系统</a>\"</p><p>郭翔 GMTC 分享：<a href=\"https://www.infoq.cn/video/gC7dFBN8H9kMYpPUz7HV\">未来可期的 TypeScript</a>\"</p>",
    "publish_time": "2022-09-19 16:40:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]