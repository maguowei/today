[
  {
    "title": "Stability AI开源图像生成模型Stable Diffusion",
    "url": "https://www.infoq.cn/article/p1DHKrHQjEsQvDcr9jlM",
    "summary": "<p><a href=\"https://stability.ai/\">Stability AI</a>\"对外发布了<a href=\"https://stability.ai/blog/stable-diffusion-public-release\">Stable Diffusion</a>\"的预训练模型权重，这是一个文本至图像的AI模型。根据文本提示，Stable Diffusion能够生成逼真的512x512像素的图像以描述提示中的场景。</p><p></p><p>在模型权重公开发布之前，它的代码已经<a href=\"https://stability.ai/blog/stable-diffusion-announcement\">发布</a>\"，模型权重也有限发布给了研究社区。在最新的版本中，任何用户都可以在消费者级别的硬件中下载并运行Stable Diffusion。除了文本至图像的生成，该模型还支持图像至图像的风格转换以及图像质量提升。在发布该版本的同时，Stable AI还发布了beta版本的API以及模型的Web UI，名为<a href=\"https://beta.dreamstudio.ai/\">DreamStudio</a>\"。Stable AI这样说到：</p><p></p><p></p><blockquote>Stable Diffusion是一个文本至图像的模型，它能让数十亿人在几秒钟内创建出令人赞叹的艺术品。在速度和质量方面，它都有所突破，这意味着它能在消费者级别的GPU上运行……这能够让研究人员和……公众在各种条件下运行，使图像生成技术走向大众。我们期待围绕该模型和其他模型出现一个开放的生态系统，以探索潜在空间的边界。</blockquote><p></p><p></p><p>Stable Diffusion基于名为<a href=\"https://ommer-lab.com/research/latent-diffusion-models/\">潜在扩散模型（latent diffusion models，LDMs）</a>\"的图像生成技术。与其他的流行的图像合成方法不同，如<a href=\"https://en.wikipedia.org/wiki/Generative_adversarial_network\">生成对抗网络（generative adversarial networks，GANs）</a>\"和<a href=\"https://openai.com/dall-e-2/\">DALL-E</a>\"使用的自动回归技术，LDMs通过在一个潜在表示空间中迭代“去噪”数据来生成图像，然后将表示结果解码为完整的图像。LDM是由<a href=\"https://www.lmu.de/\">Ludwig Maximilian University of Munich</a>\"的<a href=\"https://ommer-lab.com/\">机器视觉与学习（Machine Vision and Learning）</a>\"研究组开发的，并在最近的IEEE / CVF&nbsp;<a href=\"https://arxiv.org/abs/2112.10752\">计算机视觉和模式识别会议（Computer Vision and Pattern Recognition Conference）</a>\"上发表的一篇论文中进行了阐述。在今年早些时候，InfoQ曾经报道过谷歌的<a href=\"https://www.infoq.cn/article/QhKzahCQ9bdTgAUobYUg\">Imagen</a>\"模型，它是另一个基于扩散的图像生成AI。</p><p></p><p>Stable Diffusion模型支持多种操作。与DALL-E类似，它能够根据所需图像的文本描述，生成符合匹配该描述的高质量图像。它还可以根据一个简单的草图再加上所需图像的文本描述，生成一个看起来更逼真的图像。Meta AI最近发布了名为<a href=\"https://ai.facebook.com/blog/greater-creative-control-for-ai-image-generation/\">Make-A-Scene</a>\"的模型，具有类似的图像至图像的功能。</p><p></p><p>Stable Diffusion的很多用户已经公开发布了生成图像的样例，Stability AI的首席开发者Katherine Crowson在推特上分享了<a href=\"https://twitter.com/RiversHaveWings\">许多图像</a>\"。基于AI的图像合成可能会对艺术家和艺术领域带来一定的影响，有些评论者对此感到不安。就在Stable Diffusion发布的同一周，一幅由AI生成的艺术品在科罗拉多州博览会的<a href=\"https://news.artnet.com/art-world/colorado-artists-mad-ai-art-competition-2168495\">艺术比赛中获得了一等奖</a>\"。Django框架的共同创建者Simon Williamson<a href=\"https://twitter.com/simonw/status/1563914121883488258\">认为</a>\"：</p><p></p><p></p><blockquote>我见过一种说法，认为AI艺术没有资格获得版权保护，因为“它必须归功于全人类”——如果基于文本生成的设计尚不足以说服公众的话，那[图像至图像]技术可能会打破这种平衡。</blockquote><p></p><p></p><p>Stable AI的创始人Emad Mostaque在推特上回答了一些关于该模型的问题。在回答一位试图<a href=\"https://twitter.com/EMostaque/status/1563870674111832066\">估算训练模型所需的计算资源和成本的</a>\"用户时，Mostaque说到：</p><p></p><p></p><blockquote>实际上，我们为这个模型使用了256个A100显卡，总共15万小时，所以按市场价格计算为60万美元。</blockquote><p></p><p></p><p>Mostaque给出了Reddit上一篇文章的链接，其中给出了如何最好地使用该模型来生成图像的<a href=\"https://www.reddit.com/r/StableDiffusion/comments/x41n87/how_to_get_images_that_dont_suck_a/\">技巧</a>\"。</p><p>Stable Diffusion的代码可以在<a href=\"https://github.com/CompVis/stable-diffusion\">GitHub上找到</a>\"。<a href=\"https://huggingface.co/CompVis/stable-diffusion\">模型的权重</a>\"以及<a href=\"https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb\">Colab notebook</a>\"和<a href=\"https://huggingface.co/spaces/stabilityai/stable-diffusion\">示例Web UI</a>\"都可以在HuggingFace上找到。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/09/stable-diffusion-image-gen/\">Stability AI Open-Sources Image Generation Model Stable Diffusion</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/QhKzahCQ9bdTgAUobYUg\">谷歌最新 Imagen&nbsp;AI&nbsp;在文本至图像生成方面优于 DALL-E</a>\"</p>",
    "publish_time": "2022-09-19 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "性能透明提升 50%，详解SMC + ERDMA 云上超大规模高性能网络协议栈",
    "url": "https://www.infoq.cn/article/dX0r5aHOOm0FJb3fTuzR",
    "summary": "<p></p><blockquote>当前内核网络协议栈有什么问题？新的协议栈是不是重新发明轮子？一个协议栈能否解决所有问题？适配所有场景？本文整理自 2022 年阿里巴巴开源开放周技术演讲。</blockquote><p></p><p></p><p>本文主要分为三部分：第一部分是我们为什么需要一个新的内核网络协议栈，我们是不是在重复发明轮子？第二部分是 SMC + ERDMA 的原理、优劣等等，快速为大家了解 SMC 技术。第三部分是 SMC-R 在网易 Curve 分布式系统的实践。</p><p></p><h2>一、我们为什么需要一个新的内核网络协议栈？</h2><p></p><p></p><p>当前内核网络协议栈有什么问题？新的协议栈是不是重新发明轮子？一个协议栈能否解决所有问题？适配所有场景？这里我们将自己的思考分享出来，和大家一起交流。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/70/e4/700bd6f73ea1bea6305483bdaedf7ae4.png\" /></p><p></p><p>首先我想要抛出一个观点，没有一个网络栈是万能的，之于此没有银弹。要谈现状，离不开背景：</p><p></p><p>第一是 100G/400G 网络的普及，此时 CPU 是瓶颈。第二是云、规模，当前越来越多的业务迁移到云上，云上支持传统 RDMA 网卡成本很高。第三是 DPU，硬件卸载，承接第一点，CPU 成为瓶颈后，是否可以让网络栈将越来越多的逻辑卸载到网卡和 DPU 上，让 CPU 做更多更重要的事情。</p><p></p><p>我们如何平衡吞吐和时延？或者说如何用最少的 CPU 达到相同的吞吐，如何尽可能地降低时延。</p><p></p><p>首先 <a href=\"https://xie.infoq.cn/article/fdbe4ad63e96753c83d6cb7c7\">Linux 内核</a>\"的网络栈倾向于吞吐，而不是时延。提升吞吐很重的一点是，降低拷贝的开销。在大包吞吐的场景，我们很容易看到拷贝占据了&nbsp;CPU 的绝大部分时间。而且内核网络栈的 context switch 开销，拷贝开销也会增加额外的时延。</p><p></p><p>那么这个问题变成了选择在内核态还是用户态实现一个网络栈？</p><p></p><p>我想很多应用，或者说云上 99% 以上的应用使用的是 socket 接口，如果侵入性改造，对于用户态方案最大的壁垒。比如 DPDK 等，此时不仅仅是改造成本，也包括了运维成本、部署成本等等。当然用户态也可以劫持 socket 实现用户态协议栈，但此时 zero copy 等优势不在。并且同样需要改造，此处的改造是运维改造，调度改造和环境改造，这也是额外的成本。此时用户态的优势也不再显著。</p><p></p><p>软件 vs 硬件卸载？</p><p></p><p>一开始 Linux 网络栈，例如 TCP 协议是从纯软件实现到越来越多的将功能卸载到网卡，甚至 TOE 完全卸载到网卡。如果提到卸载到网卡，是不是可以用一种更加成熟的硬件卸载方案？也就是 RDMA，也就是传统以太网卡 vs RDMA 网卡，部分卸载到成熟的完全卸载。RDMA 网络本身有规模的限制，我们可以在小规模把 RDMA 网络玩得很好。那是否有一种大规模 RDMA 的能力。我们现在看到的是阿里云发布的 ERDMA 网络，一种普惠、高性能、完全兼容 RDMA 的生态。我们借助 SMC + ERDMA 可以实现硬件卸载 RDMA 、大规模部署，二者相辅相成。</p><p></p><p>开箱即用 vs 应用改造？</p><p></p><p>上面已经提到一部分，云上 99% 的应用使用的是 socket 接口编程，TCP 进行通信。绝大部分应用不可能投入大量成本改造适配新的网络栈，其中包括开发成本，测试成本（新的协议栈可能会有各种问题），部署和运维成本（例如 DPDK 环境，额外软件包的维护）等。此时还会让应用牢牢绑定在某个网络栈之上，后续迁移，或者遇到环境不支持的情况下，成本更高。所以我们分析后，得出的结论是，当前需要一个兼容 socket 接口，可以透明替换传统 TCP 应用的，硬件卸载的网络栈。利用云上大规模部署、DPU 硬件卸载、达成 100G/400G 网络的全新网络栈。</p><p></p><h2>二、共享内存通信 SMC</h2><p></p><p></p><p>有一点很重要，前面我们没有讨论，也就是所谓的数据通信模型。IPC 进程间通信，TCP 也是进程间通信的一种。我们按照第一性原理，拆分成不同的不可拆分的数据通信模型。对比这几种模型最佳实践下可能的性能数据。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/17/ba/17d121353cbc63084c8dcc32543ayyba.png\" /></p><p></p><p>常见的是基于包的通信模型，例如最典型的 TCP，TCP loopback 性能不是特别理想，但是易用性毋庸置疑。我们之前有提到，绝大多数应用使用的是 socket 编程，其次是共享内存，这个在本机维度的 IPC 通信中，也是一种非常常见的方式。共享内存实现千差万别，但是总体来看，性能远远超过上面几种方式，但是易用性堪忧，第一是提到的实现方式不同、库不同、接口不同，和语言和运行时绑定，导致大部分共享内存的实现不具备跨越应用的普适性。</p><p></p><p>我们快速回顾一下共享内存通信的模型：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/18/9a/187d841dbfyyea9f84c3c9c4ee67c49a.png\" /></p><p></p><p>左边的图中，下面不同颜色的方块代表不同的内存，分别分成&nbsp;sender 和 reciver 角色。首先发送方写入数据到这一块共享内存，之后通过某种方式，通知接收方数据写到了哪里、偏移量是多少，其次接收方按照游标位置读取或者拷贝走这一块内存上的数据，之后通知发送方，本地已经读取完成，下次写数据可以从某某位置开始。</p><p></p><p>这样一次简单的数据通信就完成，同时是 zero copy，这里是单向，如果是双向，只需要维护两个内存区域即可。那么是否有一种技术可以帮助我们搬运内存，让下面两个方框的内存保持同步，从单机共享内存到远端共享内存？答案也就是之前提到的 RDMA，RDMA 本身就是远端直接内存方案的缩写。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/48/1f/481febe16a1b7a5486b36658601a441f.png\" /></p><p></p><p>前面 4 步我们可以完成本地的共享内存通信，基于 RDMA，我们的数据模型只需要一个比较小的改动，也就是在第二步，通过 RDMA write 实现内存从本地同步到远端。这样本地和远端维护内存上的数据可以保持一致，同时通过 RDMA send 作为消息通知机制、通知游标更新。同时也可以实现 zero copy 硬件卸载。</p><p></p><p>基于上面的分析，我们是不是可以基于共享内存同时兼容 socket，基于RDMA 硬件卸载实现这样一个可能高性能的网络栈呢？答案是肯定的，通过 SMC + ERDMA 构建云上高性能网络栈，为什么说 <a href=\"https://www.infoq.cn/article/3rBcBW7v2z46Wv6LVoX6\">SMC + ERDMA</a>\" 可以满足上面我们的结论呢？首先，我们快速了解一下 SMC。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/7d/1a/7dc7f56153368ffc9b6c938fe2cb881a.png\" /></p><p></p><p>SMC 是 IBM 开源到 Linux 代码中，同时 IBM 也一同提出了 IETF RFC 7609，作为描述 SMC-R 协议是如何实现的。首先在上游社区中，龙蜥社区为上游贡献的补丁数排第二，其次，SMC 本身也是一种协议，Linux 下为 AF_SMC，可以直接在 socket 中制定使用，没有其他特殊的 hack 或者&nbsp;tricky 的实现，和 TCP 等价。</p><p></p><p>模型采用了共享内存技术，结合 RDMA 可以实现一次拷贝，硬件卸载的性能。同时最为重要的是，SMC 本身是一种混合协议，SMC 协议本身，需要借助某种更通用的协议建立 RDMA 链接，同时还需要提供一种 fallback 回退机制，如果没有 RDMA 支持，可以透明回退到 TCP。</p><p></p><p>最后，SMC 兼容 socket，可以透明替换所有的 TCP 应用，应用无需改造，也无需配置，即可享受 SMC 带来的性能加速。通过上述特性，最大化兼顾性能和生态。SMC 可以在云上高性能和大规模部署，也离不开阿里云的 ERDMA。ERDMA 完全兼容 RDMA 生态，兼容 verbs 接口，verbs 应用可以无需改造。同时云上的 ERDMA 具备超大规模部署的能力，解决了传统 RDMA 网络的部署难题。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/b7/f6/b7a4aa80b7f1bb34f82818ff8f7dabf6.png\" /></p><p></p><p>SMC 使用 verbs 接口，可以在云上直接使用 ERDMA，从而实现硬件卸载，高性能的网络栈&nbsp;SMC 是如何使用 RDMA 的？</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/0c/41/0c356324171755c27d9abb44e9721a41.png\" /></p><p></p><p>SMC 首先使用 TCP 带完建连，使整个 RDMA 链路可用，此时 TCP 链接可以用于回退，任何 RDMA 的问题都可以顺利回退到 TCP，确保 SMC 链接的可用。其次 RDMA 负责整个数据的通信，在内核态是 zero copy。SMC 有一次用户态-内核态拷贝。RDMA 技术的另一个问题是链接的规模，特别是 RC 模式下，链接的规模不是很大。</p><p></p><p>SMC 通过 linkgroup，将 N 个链接映射到 1 个或多个 RDMA QP 之上，充分复用 QP 资源，也加快了控制路径创建 QP 慢的问题，最重要也具备了 linkgroup 多 QP 的容灾高可用的能力。最后 SMC 支持 RoCE v1/v2，龙蜥版本还支持 ERDMA，确保 SMC 既可以使用在云上，也可以使用在数据中心内部。我们多次提到了 SMC 基于 TCP 链接建连，那么 SMC 是怎么做的？</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/88/42/883168dc24efc5f467b886f832da2442.png\" /></p><p></p><p>首先 SMC 本身是一种混合协议，协议底层包括 TCP 和 RDMA，充分运用&nbsp;TCP 通用、兼容、可达率高、RDMA 高性能的优势。同时这一条 TCP 链接也可以帮助 RDMA 不可用或者建连错误后，快速回退到 TCP 模式，对于应用完全透明。SMC 通过 TCP SYN 包中的特定的 TCP options 标注是否支持 SMC 能力。如果支持会接下来交换 RDMA 建连所需的信息，SMC 兼容 socket 之后，是如何透明替换 TCP？</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/12/02/12b5ea722b6ecb2570e2a21399761e02.png\" /></p><p></p><p>首先 AF_SMC 和 AF_INET 是在同一层级。对外暴露的接口和性能完全一致，应用可以在创建 socket 的时候直接使用 AF_SMC，与使用 TCP 时完全一致。应用不仅可以显示的制定 AF_SMC，也可以使用 smc_run 命令，快速将 TCP 替换成 SMC，如左图所示，任何应用都可以透明改造，无需任何适配，SMC 模块也会自动载入到内核。</p><p></p><p>其次支持 netns 维度的替换，支持容器场景下的加速。也支持 eBPF 的策略替换，通过 eBPF 编写规则匹配所需的应用特征，选择性的替换成 SMC。对于一些不重要，不想要占用 SMC 资源，或者不适合 SMC 的场景，可以使用这种方式。</p><p></p><p>SMC 回退机制，也是 SMC 为什么能够替换 TCP 重要的一个特性。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/65/4f/65728e56b2a34fa53c4baefa3175f44f.png\" /></p><p></p><p>上图左边可以看到，SMC 首先创建 TCP 链接，经过 TCP 的握手后，才会进行 SMC 握手。如之前所提到的是，SMC 是混合协议，在 RDMA 建连失败后，可以快速透明的切回到 TCP。同时也提供了各种错误码，帮助应用排查问题，例如 RDMA 网卡问题，还是资源问题等。谈了这么多 SMC 自身的特性，那么 SMC 的性能如何？下面的测试是在阿里云上 ERDMA 网卡和 SMC 对比 TCP 的性能。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/88/76/888b8fea1bfb08eb7767aa7288926576.png\" /></p><p></p><p>例如常见的 netperf microbenchmark 有一倍以上的性能提升。Redis 和 Netty 这种常见的基础组件有 30% 到 50% 的 QPS 提升，时延也显著下降。NGINX 也有 40% 左右的性能提升。这些性能提升，都是在应用无需任何改造，透明替换成 SMC 下进行的测试。接下来我们聊一下我们龙蜥社区在 SMC 上所做的工作。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/e2/2f/e26f2a21e813bdbb7bf915db0487a22f.png\" /></p><p></p><p>2021 年 11 月开始在社区密切参与开发和稳定性工作，当前贡献共计 70 多个补丁，排在 IBM 之后为第二。首先我们从头到尾优化了 SMC 的性能，包括短链接性能，包括吞吐和一些 syscall，CQ 中断打散等优化，最终 microbenchmark 综合性能提升了 357%，这里是对比的 SMC 之前的版本，对比 TCP 可以参考刚才的数据。其次是更多的场景支持，包括云原生、ERDMA、容器网络等等，拓宽了上游社区 SMC 的使用场景。</p><p></p><p>最重要的是，极大地提升了稳定性，我们一直在持续看护上有社区，解决了数十个 panic 问题，彻底解决了遗留的 link 和 linkgroup 问题，同时也在持续看护 SMC。龙蜥社区我们有 CI/CD 持续不断的测试，能够成为一个产品级别的协议栈。大家可以访问我们的仓库（地址见文末），使用 HPN 中我们不断优化的 SMC 版本。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/d0/3b/d05717bc007488e896aa96fd35c59c3b.png\" /></p><p></p><p>接下来我们谈一谈 SMC 的未来。</p><p></p><p>回到分享的开始，SMC 同样也不是银弹。SMC 基于 RDMA 技术，本身也有 RDMA 引入的各种各样的问题。第一是内存消耗，SMC 本身需要一致维护一块比较大的连续内存区域，用来实现共享内存通信，内存消耗显著大于 TCP。其次是 SMC 的建连性能，还是会受制于 RDMA RC 模式的建连性能，这一块我们会持续不断的优化，相关优化我们会陆续推送到社区。其次是稳定性，SMC 不同于 TCP 在业界广泛使用多年。有很多问题没有被发现，我们当前也在借助 SMC CI/CD 帮助我们发现问题。</p><p></p><h2>三、SMC-R 在网易 Curve 存储系统的实践</h2><p></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/92/cc/92b337163ef671494eb2a9777b7f47cc.png\" /></p><p></p><p>首先介绍一下 Curve。Curve 是一个开源分布式存储系统，可对接 OpenStack 平台为云主机提供高性能块存储服务，可对接 Kubernetes 为其提供持久化存储卷，可对接 PolarFS 作为云原生数据库的高性能存储底座。Curve 在性能、运维、稳定性、工程实践质量上都优于 Ceph。下面介绍 Curve 的网络通信：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/b3/6c/b3f94a3345882fcb9da83d9a6e18746c.png\" /></p><p></p><p>通信过程为由 leader 向 follower 发起 RPC 进行数据拷贝。特点是：网络通信频繁、网络通道稳定、网络传输时延小、RPC 时延占比不低。因此我们调研了几种网络加速选型：</p><p></p><p>其中 <a href=\"https://www.infoq.cn/article/l2chlCBlSb1kCZu1m9O2\">SMC-R</a>\" 可以实现透明替换，无侵入，并且提供较好的性能。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/7b/7a/7bef6be44e60fefa73fc58c371e3e67a.png\" /></p><p></p><p>我们使用 SMC-R 改造了 Curve 并使能。同时扩展了黑名单、资源监控和读取速度监控等能力。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/3e/16/3edb66f5fbf7aa69dd3dd89792f31516.png\" /></p><p></p><p>我们使用 Curve E2E 测试，在 3 Volume &nbsp;256 depth randwrite case 下，对比 TCP 提升了 18.5% 的性能。</p><p></p><p>最后，以上为大家介绍了我们为什么需要 SMC，SMC 的原理和性能以及 SMC 在网易 Curve 的最佳实践。对于 SMC 而言最重要的是社区和生态，在此欢迎大家使用并参与龙蜥社区和 SMC 社区，一同打造 SMC 高性能网络协议栈。</p><p></p><p>本文作者</p><p></p><p>陆扬，阿里云技术专家、龙蜥高性能网络 SIG 成员</p><p>刘亚灿，网易资深服务端开发工程师</p><p></p><p>相关链接：</p><p></p><p>高性能网络 SIG：</p><p>https://openanolis.cn/sig/high-perf-network</p><p>SMC代码仓库：</p><p>https://gitee.com/anolis/hpn-cloud-kernel</p>",
    "publish_time": "2022-09-19 10:19:18",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "2022 深圳国际金融科技大赛（FinTechathon）正式启航：打造世界级顶尖赛事，全面推动金融科技创新！",
    "url": "https://www.infoq.cn/article/7ejrDIB7r5KRIuLwaRPd",
    "summary": "<p>金融科技（FinTech）是金融与科技的融合产物，目前已成为全球金融行业创新和竞争的制高点与主战场。业界一致认为，金融科技将在未来数年迎来战略发展机遇期，行业可能出现颠覆级的科技创新改变金融生态。为此，深圳市地方金融监督管理局在今年发布的《深圳市扶持金融科技发展若干措施》中明确表示，\"从 2022 年起，深圳市人民政府将每年举办金融科技节，期间将举办金融科技大赛、金融科技论坛和金融科技展。\"</p><p>&nbsp;</p><p>9 月 19 日，作为深圳市首届金融科技节中的重要一环，2022 深圳国际金融科技大赛（ FinTechathon ）—— 西丽湖金融科技大学生挑战赛（下文称“大赛”）将正式开赛。</p><p>&nbsp;</p><p>这是一场面向金融科技前沿领域，专为学生团队打造的世界级竞赛。大赛的战略指导单位为深圳市地方金融监督管理局、深圳市南山区人民政府、深圳市福田区人民政府、主办方为深大微众金融科技学院、微众银行、深圳香蜜湖国际金融科技研究院。其中，微众银行是国内首家践行普惠金融理念、充分运用<a href=\"https://www.infoq.cn/article/jtG2A4Xg123R0iFHHGgA\">金融科技</a>\"建设的互联网银行，为助力金融科技产业发展，在人工智能、<a href=\"https://xie.infoq.cn/article/50a68cd3c8337daa348ccf0c2\">区块链</a>\"、云计算、大数据领域发起 30 多个<a href=\"https://www.infoq.cn/article/S72hXOUgAjtFrADTFIzu\">开源项目</a>\"，目前已成为“业界技术顶流”；深大微众金融科技学院则是深圳大学与微众银行共同创建的国际化、高水平研究型金融科技学院，学院同时规划布局不同的专业方向以满足国家金融科技产业各细分领域的专业技术人才培养需求。两家单位强强联合，充分发挥人才环境与产业环境耦合效应，通过产研融合的方式全力驱动金融科技领域的发展与创新。</p><p>&nbsp;</p><p>大赛旨在充分发挥政、学、企多方优势，共创金融科技领域盛世赛事先锋，合力推动国内外高校学生探索金融科技领域的技术应用创新，全面提高高校学生的创新能力、实践能力和就业竞争力，丰富金融科技人才储备以打造深圳市金融科技发展高地，为深圳市抢抓金融科技发展机遇、加快金融科技产业升级注入一股硬核力量。</p><p>&nbsp;</p><p>基于深圳市当下完整良好的金融科技生态，大赛倾力打造人工智能、区块链、金融产品经理三大赛道，多维挖掘高校学生的优秀金融科技创新成果，启思高校学生输出贴近金融科技企业需求的技术及产品解决方案。大赛主办方设置总额超过 69 万元人民币的赛事奖金，激励高校人才持续积极投入到金融科技创新事业中。</p><p>&nbsp;</p><p>此外，大赛主办方还将协同珠海华润银行、平安银行用卡中心、江南银行、金证股份、安信证券、第一创业证券、德科信息、国家金融科技测评中心、华策数科、微言科技等数十家金融及科技相关企业，为进入决赛的学生提供 100 余张可双向选择的实习面试直通卡，助力高校人才实现更充分、更高质量的就业目标，构建产学研一体化人才培养模式，以构建金融科技人才培育生态圈。同时将积极响应国家号召，持续向社会输送优秀的金融科技创新型人才，真正担负起“为党育才、为国育人”的使命。</p><p>&nbsp;</p><p>大赛组委会特别邀请加拿大皇家科学院院士、加拿大工程院院士杨强；加拿大工程院院士、加拿大工程研究院院士、人工智能与数字经济广东省实验室（深圳）执行主任于非；上海交通大学中银科技金融学院院长刘少轩；香港中文大学（深圳）经管学院校长讲席教授张博辉等人担当学术顾问，为大赛提供智力支持。另有来自中科院、深圳大学、武汉大学、西南财经大学、华南理工大学、微众银行等学企单位的数十位科研专家担任大赛评委，为参赛团队指点迷津。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/6e/a2/6ee8c0bdfef60134f67d810df0fd6ea2.jpeg\" /></p><p></p><p>值得一提的是，为贯彻落实深圳市金融科技节指导方针、营造深圳市良好的金融科技生态环境，在大赛决赛及颁奖环节还将举办“金融科技高校论坛”活动，特邀各位专家将围绕“金融科技”展开深度话题分享、圆桌对话，为金融科技领域的发展提供方法论与新思路，蓄能并引爆深圳市首届金融科技节活动高潮。</p><p>&nbsp;</p><p>据悉，大赛前身是 FinTechathon 微众银行金融科技高校技术大赛，前三届参赛人数逐届递增，共吸引 2100 余名来自海内外知名高校的学生参赛，成功在行业内掀起科技创新浪潮。</p><p>&nbsp;</p><p>9 月 19 日起，本届大赛正式开启报名通道，国内外高校在读生（含本科生、硕士/博士研究生）均可报名参赛。有兴趣的同学可点击阅读原文进入大赛官网 <a href=\"https://www.infoq.cn/zones/fintechathon/campus2022/\">https://www.infoq.cn/zones/fintechathon/campus2022/</a>\" 或识别下方海报中的二维码进行报名。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/27/f0/271ff9ac1b4c21eacdc22fc8bfbf35f0.jpg\" /></p><p></p>",
    "publish_time": "2022-09-19 14:12:39",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "苹果拥抱RISC-V更进一步：消息称苹果嵌入式内核将全面转移到RISC-V架构",
    "url": "https://www.infoq.cn/article/rUNXzRRtL9YGUvCGWiBm",
    "summary": "<p></p><blockquote>新兴的RISC-V作为第三大芯片架构正改变做全球芯片架构竞争格局，</blockquote><p></p><p></p><h2>分析师称苹果或将进一步拥抱RISC-V架构</h2><p></p><p>&nbsp;</p><p>日前，据SemiAnalysis报道，苹果正在将其嵌入式内核将全面转移到<a href=\"https://www.infoq.cn/article/x4JNvgz3R55boVWr3ujy\">RISC-V架构</a>\"。</p><p>&nbsp;</p><p>RISC-V 是一个基于精简指令集（RISC）原则的开源指令集架构（ISA）。2010 年，开源指令集架构 RISC-V 首次出现在美国加州大学伯克利分校，其开源架构的形式很快就吸引了包括 IBM、恩智浦、WeaternDigital、NVIDIA、Qualcomm、三星、Google、华为、Tesla 等各大厂商的加盟。</p><p>&nbsp;</p><p>与大多数指令集相比，RISC-V指令集可以自由地用于任何目的，允许任何人设计、制造和销售RISC-V芯片和软件。虽然这不是第一个开源指令集，但它具有重要意义，因为其设计使其适用于现代计算设备（如仓库规模云计算机、高端移动电话和微小嵌入式系统）。设计者考虑到了这些用途中的性能与功率效率。该指令集还具有众多支持的软件，这解决了新指令集通常的弱点。</p><p>&nbsp;</p><p>Semianalysis分析师Dylan Patel表示，即使许多人认为 RISC-V 缺乏软件生态系统，但他强调，RISC-V 正迅速成为新的处理器标准。“苹果的 A15 芯片分布着十几个基于 Arm 的 CPU 内核，用于各种非面向用户的功能。SemiAnalysis 可以确认这些内核在未来几代硬件中，正在积极地转换为 RISC-V。”</p><p>&nbsp;</p><p>据超能网报道，目前苹果M系列处理器中，除了主内核外，还有大量的嵌入式内核，负责与操作系统无关的各种工作负载，包括Wi-Fi/蓝牙、触摸板控制、雷电接口等。这些嵌入式内核运行着自己的固件，围绕运行操作系统的主核心为周边提供动力。</p><p>&nbsp;</p><p>当前，这些嵌入式内核大都基于Arm的Cortex-M系列或低端的Cortex-A系列内核，苹果需要为此支付一大笔授权费用。随着苹果自研芯片进一步发展，后续使用内核数量也会对应增加，支付的费用也将水涨船高。如果将嵌入式内核将全面转移到RISC-V架构，苹果可以省下一大笔钱。</p><p></p><h2>苹果押注RISC-V，早有苗头</h2><p></p><p>&nbsp;</p><p>早在去年，市场上就已有苹果拥抱RISC-V的消息。</p><p>&nbsp;</p><p>去年9 月，苹果发布<a href=\"https://www.infoq.cn/article/CXTRIj6DCgOQj5yYPNjx\">招聘</a>\"启事称正在为其核心操作系统团队的 Vector and Numerics Group (VaNG) 小组寻找对 RISC-V 指令集架构 (ISA) 和 ARM 的 Neon vector ISA 有详细了解且有丰富经验的开发者。</p><p>&nbsp;</p><p>根据招聘广告，这名工程师将在苹果产品上采用“创新的 RISC-V 解决方案和最先进的程序”。具体地说，苹果希望未来的工程师能够使用 RISC-V 指令集，并了解 ARM。</p><p>&nbsp;</p><p>彼时有分析认为，该招聘仅可表明苹果正在探索 RISC-V 的使用，但最终是否决定采用这项开源技术以及是否会用其替代现有芯片架构都是未知的。而在当前来看，苹果拥抱RISC-V或许已成定局。</p><p>&nbsp;</p><p>事实上，近几年有越来越多的厂商和开发者加入 <a href=\"https://www.infoq.cn/article/ULKfa6cJ1uVzME9JQhJm\">RISC-V 的阵营</a>\"。</p><p>&nbsp;</p><p>日前，提供RISC-V内核的SiFive公司高管Jack Kang表示，“最近几年，中国对RISC-V的兴趣越来越大，这刺激了该架构的普及，到2025年，将有超过600亿个 RISC-V 内核集成到物理IC中。”</p>",
    "publish_time": "2022-09-19 15:08:02",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "淘宝店铺是如何全面拥抱 TypeScript 的",
    "url": "https://www.infoq.cn/article/dEAoEuVSEVKCcIm1WI1t",
    "summary": "<p>作者 ｜贾亚宁</p><p>嘉宾 ｜林伟轩</p><p></p><p>TypeScript 在 2021 年依然保持着持续稳定的增长，甚至逐渐成为很多大厂的首选工具。相信大家这段时间也会在各个大厂的年度技术总结文章中屡屡看到 TypeScript 的身影。</p><p></p><p>TypeScript 诞生之初就是为了解决 JavaScript 由于自身的局限性在大型项目中的挑战，它已经造就了许多我们耳熟能详的项目（如：VS Code）。但是在我们日常的项目开发中，可能对它又爱又恨；爱它带来了类型安全和代码即文档的类型注释，恨它带来了大量额外的类型代码，束缚了 JavaScript 的自由洒脱。</p><p></p><p>我们都知道，对于基于 TypeScript 的中大型项目，建立严谨的研发规约是非常有必要的，那么什么样的规约是兼顾各个角色最高效的解决方案？什么样的规约可以更往前看一步？制定规约的过程中会遇到哪些挑战，又如何解决呢？</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ab/abda11ca57421018b39f44dc7a2ce80e.jpeg\" /></p><p></p><p>出于对以上问题的好奇，我们找到了林伟轩老师。他是阿里巴巴淘系技术部的前端开发工程师，负责淘宝旺铺，制定并推进基于 TypeScript 的研发规约在整个淘宝店铺范围内的落地。他热爱开源社区，社区昵称：林不渡；<a href=\"https://github.com/linbudu599/linbudu599\">GitHub：linbudu599</a>\"。专注于前端工程化、GraphQL 和 NodeJS 等。</p><p></p><p>同时林伟轩老师也是已经上线的 <a href=\"https://time.geekbang.org/qconplus/home\">QCon+ 案例研习社</a>\"<a href=\"https://time.geekbang.org/qconplus/album/72\">「TypeScript 在中大型项目中的落地实践」</a>\"专题的讲师，他分别从研发侧和工程侧的角度分享了<a href=\"https://time.geekbang.org/qconplus/detail/100091375\">淘宝店铺项目是如何制定并落地 TypeScript 研发规约的</a>\"。因此我们针对 TypeScript 相关的疑惑和好奇对林伟轩老师进行了采访，让我们一起来看看老师的思考吧。</p><p></p><p></p><h5>InfoQ：你最近在负责什么样的工作呢？</h5><p></p><p></p><p>林伟轩：最近的话，我的核心工作范畴还是在店铺的旺铺侧，可以理解为是面向商家的 B 端产品，核心重点就是其中的旺铺装修部分，包括了移动端装修和 PC 端装修两个部分。偷偷剧透一下，移动端装修目前已经开发完毕，并开放给少数意愿强烈的商家试用当中，很期待未来它能够带给商家们便捷快速的店铺装修体验。</p><p></p><h5>InfoQ：你们团队在选择 TypeScript 时，是基于什么考虑呢？</h5><p></p><p></p><p>林伟轩：首先，做出迁移到 TypeScript 这个决定的过程中，团队中的意见基本是一致的，我们都认为，对于 B 端产品以及部分稳定性要求高的 C 端产品来说，使用 TypeScript 带来的收益一定会远远超出成本。比如我们收获了维护性、可读性、稳定性的成倍提升，通过 TypeScript 的类型定义作为协议层统一了许多分散的依赖库，提升了大家的代码质量等等。而对于一部分零散的独立模块，它们的变动是非常少的，但又非常重要，比如店铺域内官方提供的装修模块，我们就决定保持现状，因为迁移可能会带来超出预期的成本和不确定因素。</p><p></p><p>其次，我们在迁移上也有着长期的规划，如我在 QCon+ 案例研习社的分享里提到的，旺铺装修只是一个试点项目，在它之前与之后，我们还有数个重点项目也开始陆陆续续地迁移到 TypeScript，并且这些后续的过程也很好地借鉴了旺铺装修迁移过程中的经验与教训。</p><p></p><p>最后一点，基于 TypeScript 我们才能够推广更严格的约束，对人和对代码都是，包括 Code Review 要求、Lint、源码的解析、基于类型声明的统一协议层等等。</p><p></p><h5>InfoQ：从 JavaScript 项目迁移到 TypeScript，你有什么印象深刻的踩坑经历吗？</h5><p></p><p></p><p>林伟轩：我个人对 TypeScript 还算熟练，因此过程中倒是也没有遇到过代码层面的坑。但是我很享受将凌乱的 JavaScript 代码转变成干净整洁的 TypeScript 代码的过程。对比来看，在工程层面我倒是遇到了不少问题，如印象最深刻的一点我在 QCon+ 案例研习社的分享中也提到了，那就是在迁移工作开始的初期，没有明确好当前的工作重点，总是在添加类型时手痒地去改逻辑，并认为只要类型不报错就不会有问题，这导致了在后续出现问题时我需要一点点回滚代码去检查，最后往往发现就是当时以为不会产生问题的小小改动导致的。</p><p></p><p>在这种情况发生几次之后，我开始建立严格的分期规划，让每一期的职责完全独立开来，控制自己的手不去做超出当前规划范围的事情。同时确定了各部分最小修改单元的粒度，在完成一个单元的修改后就进行前后差异的检查，不是每修改一行文件，也不是每修改一天的文件。</p><p></p><p>这个困难看起来很简单，但它涉及到了一个核心问题，引入 TypeScript 是只为了添加类型来让项目更好维护，还是说想把整个项目的逻辑完全重写？这是你需要思考的问题，也需要基于自己更关注的问题做对应的规划和预案，而不是说我全都要，来把这两件事情混为一谈，这往往会导致灾难性的后果。也就是说，先确认你最希望从迁移到 TypeScript 得到哪些收益，然后基于此收益展开做规划，一次一口，勿贪得无厌。</p><p></p><h5>InfoQ：你认为 TypeScript 未来是否能得到浏览器和 Node.js 原生支持呢？</h5><p></p><p></p><p>林伟轩：我认为不太可能，首先说最现实的，TypeScript 的性能难以恭维。它需要类型检查，需要加载所有文件到内存，如果浏览器来做 TypeScript 到 JavaScript 的编译，那网页的性能无疑会受到严重的影响，类似的我们也可以认为 Node 同样不会原生支持，参考 Deno 将许多内部的 TypeScript 代码又重写回了 JavaScript。其次，TypeScript 本身的核心是编译时的检查，浏览器直接将其作为运行时支持基本上是没有意义的，因为类型的错误并不影响实际的代码运行，反而白白浪费了检查的时间。</p><p></p><p>还有很重要的一点，许多 TypeScript 拥簇者其实忽略了一个大家伙——ECMAScript，它才是 JavaScript 的实现提案。TypeScript 比 ECMAScript 提前实现了很多进行到 Stage3 阶段的语法，如可选链、空值合并、装饰器以及一些 Class 语法等。对于一部分在 TypeScript 实现完毕后又发生了变化的提案，比如装饰器，TypeScript 实现基于第一版 TC39 的装饰器提案，而目前装饰器提案已经进行到了第三版，实现已经和之前有了比较大的差异，那这可能就会在未来埋下一个祸根，或者说伏笔了。</p><p></p><p>总的来说，我们仍然会大量的使用 TypeScript，但我个人不认为它会得到浏览器和 Node 的原生支持，我们也不需要关注这一点，就像它自己都只关心编译到 JavaScript 的过程一样。</p><p></p><h5>InfoQ：你在使用 TypeScript 重构的过程中，如何协调各方之间的需求呢？</h5><p></p><p></p><p>林伟轩：实际上我理解对于 B 端性质的产品，负责的 PD 与测试同学对于技术改造往往持积极态度，因为正常来说技术改造能带来更高的开发效率和更好的稳定性，后面做起性能优化来也会简单不少。</p><p></p><p>而在协调资源层面，我觉得最重要的点，还是改造的发起者是否有清晰的规划，让 PD 和测试同学了解改造的节奏，需要的时间，是否存在风险，有没有健全的灰度、监控、回滚机制等等。其次就是需要协调出可投入技术改造的时间段，比如每个月留多少个人日，需求节奏放缓的阶段等等，根据这些情况再进一步完善整体的排期。</p><p></p><p>对于测试同学，一个比较良好的方式是在每一期完成后就进行一次回归测试，而不是在全部完成后再进行，以此避免过重的工作量和难以定位的问题。</p><p></p><p>对于团队层面来说，我暂时没有办法给出有用的经验，因为我自身也是一线开发而不是管理者，我看到的往往只是从自身的各种因素出发看到的结论，比如说在团队成员水平不一致的情况下，是否可以将首期，甚至前几期的要求适当放低，或者将整个迁移过程分更多期来帮助能力暂时不足的成员用较平缓的方式过渡。</p><p></p><h5>InfoQ：最后，有一个关于个人成长的话题，你是如何能在一毕业就加入阿里这种互联网大厂的呢？</h5><p></p><p></p><p>林伟轩：我个人其实不是科班出身，大学学的是管理科学。我在 2021 年校招加入阿里，目前算上实习的时间，工作经验差不多刚满一年。我个人踏上前端的路其实比较奇妙，从误触 F12 打开浏览器控制台知道什么是前端，到在网上看了一些前端的学习资源，再到加入学校工作室在一批 Nice 而有趣的人的帮助下一路成长到今天，这个经历不太具有复制性，这里就不赘述了。</p><p></p><p>我想分享一下我的做事原则和态度，我相信这几点正是推动我走到今天的力量：</p><p></p><p>换位思考、同理心，以及尊重。</p><p></p><p>马伯庸在《显微镜下的大明》一书中说到：“读史有一个很重要的原则，就是不要轻易把古人当白痴。我们今天可以看到的历史，和当时人的视角不同，获得的信息亦不同。如果设身处地去想，就能明白，很多看似愚蠢的举动，自有其逻辑和动机。”说白了就是，当我们在接触人事物，尤其是比较陌生的人事物时，一定不能从旁观者的角度直接给出评价，因为这必然过于主观和局限。我们该做的是将自己代入到对方的情境中，尽可能客观地评估自己相对于对方的意义，绝对不要以自我为中心。</p><p></p><p>保持对技术的热情与创新的初衷。</p><p></p><p>这一点我想不必多说，每个技术人都应该拥有。松本行弘说他最快乐的就是让其他的开发者能使用他的发明创造去做更多富有激情的事情。对于我来说，最快乐的事情就是自己的技术让更多的普通人享受到了互联网的便利。</p><p></p><p>独立自主的成长。</p><p></p><p>在内卷文化盛行的当下，我还是要说，不要焦虑、不要比较、不要急躁。不要因为别人会了自己不会的东西就莫名焦虑，为什么要做别人的影子呢？只学自己感兴趣的，只看自己想看到的；不要下意识地给自己设定竞争对手，否则不就是给自己设限吗？当你超越了这个竞争对手，你是继续确立下一个对手还是站在山巅之上茫然无措呢？不要因为未知的领域茫茫无尽就焦躁不安，没有人能探索完世界的每一个角落，你会因为没去过纽约、巴黎、莫斯科就痛苦吗？不会，因为这不会影响你的生活，同样的，专注 C 端产品的前端工程师也不会因为没用过 Express 就寸步难行。认清楚你最需要的，活在当下就好。</p><p></p><p></p><h4>嘉宾简介</h4><p></p><p></p><p>林伟轩  阿里巴巴 淘宝前端开发工程师</p><p>社区昵称：林不渡，现就职于阿里巴巴淘系技术部，负责淘宝旺铺，制定并推进基于 TypeScript 的研发规约在整个淘宝店铺范围落地。热爱开源社区，GitHub：linbudu599，专注于前端工程化、GraphQL、NodeJS 等。</p><p></p><p></p><h4>相关阅读</h4><p></p><p></p><p>林伟轩实操专题：<a href=\"https://time.geekbang.org/qconplus/album/89\">TypeScript 类型系统实战课：自顶向下学习类型系统</a>\"</p><p>郭翔 GMTC 分享：<a href=\"https://www.infoq.cn/video/gC7dFBN8H9kMYpPUz7HV\">未来可期的 TypeScript</a>\"</p>",
    "publish_time": "2022-09-19 16:40:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "突围电商大促场景，得物在高可用上的探索与实践｜卓越技术团队访谈录",
    "url": "https://www.infoq.cn/article/bzOUlFoox1hyXKUQbzXT",
    "summary": "<p></p><p>采访嘉宾 |&nbsp;金思宇、陈贞宝、胡强忠</p><p></p><p>大型电商系统并非一开始就具有完整设计的高可用特性，而是随着用户的不断增加与业务的快速增长逐步演进与完善的。当前高可用架构体系是互联网企业系统架构的基础要求，随着公司的业务发展，尤其是对于电商平台，每次发生稳定性故障带来的影响越来越大，提供稳定的服务，保证系统的高可用已经变成了整个技术团队需要面对的挑战。</p><p></p><p>基于此，我们深度采访了得物技术团队核心成员，探索他们在高可用架构上的实践、演进，深入了解大促备战是如何进行的，异地多活体系是如何建设的，全链路压测是怎么实践的等过程。</p><p></p><h3>得物高可用架构演进</h3><p></p><p></p><p>和大多数互联网公司一样，得物目前也是<a href=\"https://www.infoq.cn/article/designing-a-microservices-architecture-for-failure\">采用主流的微服务架构来应对高可用的挑战</a>\"。同样的，得物也是从大单体演进而来，经历了涵盖服务规划、服务拆分与合并、存储拆分等过程的微服务构建，集成并自研了基础开发框架及其脚手架、微服务通讯框架、微服务治理体系、微服务生命周期管理平台、微服务支撑基础设施、微服务安全设施，从大单体架构逐步演化成微服务架构。</p><p></p><p>在这一过程中，得物结合自己的业务背景，自研了符合自己特色的微服务架构支撑平台，比如网关、流量回放平台、预案平台、DAL、全链路压测平台、微服务发布平台等，并在分布式核心场景中沉淀自己的最佳实践设计，如服务的无状态化、服务的幂等、分布式锁、分布式事务、缓存失效的设计等。</p><p></p><p>回顾过去，得物高可用架构的整体演进与中国电商平台的业务架构的演进阶段比较相似，大致可以分为四个阶段。</p><p></p><p>第一阶段，得物早期，业务场景比较简单，功能不复杂，团队的规模也较小，使用的开发语言是 PHP，采用的是单体架构，在高可用的建设上也比较少，当时的主要目标是为了快速满足基础的交易需求。</p><p></p><p>第二阶段，随着业务规模的逐步增大，团队规模也越来越大，单体架构已经不能支撑业务的快速发展。得物开始做架构升级，语言从 PHP 转到了 Java，框架上使用的 SpringCloud 全家桶，业务域也进行了拆分，独立出了订单、出价、优惠、商家、商品几个应用，但这个阶段在服务治理上的建设还比较薄弱。</p><p></p><p>第三阶段，时间来到 2019 年下半年，随着业务发展，得物的交易系统亟待优化。一方面系统架构需要承载高并发的流量；另一方面，前期业务模型的设计对日渐复杂的业务需求支撑也不友好。于是得物启动了“五彩石项目”，按照领域驱动设计的思路，对得物交易体系重新规划和设计。只用了 3 个月的时间，就完成了整个系统的重构。新的架构形成新的 6 个核心域，对大数据量场景也做了分库分表，得物也开始逐步建设自己的监控体系、服务治理体系、预案系统，在基础设施中不断升级，来确保系统的高可用。</p><p></p><p>关联阅读：<a href=\"https://www.infoq.cn/article/lzaf60oyqwlcruirch9n\">《业务百倍增长，得物如何在三个月完成交易平台重构？》</a>\"</p><p></p><p>第四阶段，随着业务的进一步快速发展，业务规模越来越大，对交易系统的高可用、稳定性有了更苛刻的要求，一旦业务出现问题就会被快速放大。得物就在原有架构不断治理、升级的基础上，逐步启动了异地双活、容器化项目，让系统的高可用、可扩展、跨地域的容灾能力得到新的提升。</p><p></p><h3>异地多活混合云架构体系建设</h3><p></p><p></p><p>前文提到，得物为了应对规模更大更复杂的业务情况，在高可用架构上做了异地多活、多机房部署等升级。</p><p></p><h4>灾备架构选择</h4><p></p><p></p><p>目前常见的灾备架构有冷备、热备、双活、多活等几种。</p><p></p><p>冷备：只有主数据中心承担业务请求，备份数据中心定期同步主数据中心的数据或者在停机的情况下才开始对主数据中心的数据进行备份，当主数据中心挂掉，需要停机一段时间，手动拉起。从严格意义上讲，在当前对分布式系统高可用的要求下，冷备技术不能算真正的灾备技术，恢复时间过长，对业务影响较大。热备：只有主数据中心承担业务请求。主数据中心会实时向备份数据中心实时同步数据，当主数据中心挂掉，可以通过控制中心自动切换到备份数据中心，通过这种方式来实现高可用。还有一种概念是暖备，与热备架构类似，只不过不能够自动切换，需要人工介入。双活/多活：分为同城双活/多活，异地双活/多活，跨国多活。多个数据中心都会承担业务流量，不同的架构，在具体的落地细节上的复杂度也是相差较大。而且在不同的业务体系下，也会有不同的流量路由、机房部署方式。得物目前采用的是热备+双活的模式。热备成熟可靠，在存储层采用热备，发生故障情况下，可以快速切换到备份节点进行恢复，备份节点一般不对外提供服务，因此热备的资源利用率相对来讲比较低。</p><p></p><p>得物双活基于双数据中心，两个数据中心同时对外提供服务。主数据中心承担主要的流量（一般为 70%），在发生故障时，将流量切换到另一个数据中心。双活资源利用率高，相对一个数据中心，更加地可靠，但是技术难度高，需要投入比较大的时间和人力成本进行技术建设，针对核心买家链路、微服务框架、微服务治理体系、微服务基础设施等做了相应的技术改造来实现。</p><p></p><h4>按需配置多机房部署方案</h4><p></p><p></p><p>多机房部署模式一般分为同城、异地（跨城）、跨国几种，异地一般又分为远端城市和近端城市两种。一般情况在部署地区上有以下几个方面需要考虑：</p><p></p><p>两个机房部署在同一个城市，如果遇到城市级别的停电或者自然灾害，很容易出现两个机房都不可用的情况，达不到灾备的要求。两个机房部署在异地，那么相对同城来说，同时遇到自然灾害的概率要小一些。但是选择两个较远的城市还是选择两个较近的城市需要根据自己的业务场景、用户属性、数据同步延迟的要求以及实际需要解决的问题来决定的。选择两个比较远的城市，比如北京和深圳，那适合的业务场景是对用户以及中心数据进行分区，北方的用户访问北京的机房，南方的用户访问深圳的机房，比较适合本地生活服务类的业务场景。一个机房能够满足用户的实用需求，能够接受较长时间的数据同步延时。</p><p></p><p>得物虽然是多机房部署，但不是这种模式，得物多机房部署的目的是可以对用户进行调度，当一个机房出现问题的时候，自动调度到另外一个机房，面临大流量或者促销活动的时候，通过流量调度来确保系统稳定。而且对于目前电商的业务模式，商品中心的数据需要确保两个机房的实时性，远端城市的部署方式是不适合的。</p><p></p><p>得物在综合技术、人力、业务复杂度、业务场景、时间成本等情况后 ，决定部署异地双活-近端城市的架构模式，后续会逐步演进发展到两地三中心、异地多活并且结合混合云的部署架构。</p><p></p><p>异地双活要解决的核心问题是“确保在极端情况下买家核心链路依然可用”，聚焦于买家链路的稳定性保障。</p><p></p><p>在故障发生时，能够将买家流量从一个数据中心调拨到另一个数据中心。从技术上，需要解决的一个难题就是如何确保买家跨数据中心调拨后，依然能够保证事务的一致性。这一点非常的困难。</p><p></p><p>举一个例子，比如用户订单数据，该数据写入主数据中心，但是当流量调拨到另一个双活数据中心时，用户依然能够在之前的事务上下文访问到正确的数据。这意味着用户订单相关数据必须保证两个机房都能够正常访问到，即数据是双向实时同步的。这里的数据会涉及到 MySQL、Redis、ES、HBase、MQ 等。同样的，这条链路的服务依赖需要隔离在同一个机房，服务路由需要就近路由避免跨机房路由，具体一点，假设数据都存储在 MySQL 的话，那么 DB 的数据就存在仅中心机房部署、中心写单元读部署、单元化部署（双边写并双边同步）。这就要求从基础设施到业务服务进行技术改造来实现。</p><p></p><p>基础设施的建设与改造</p><p></p><p>为了更好的支持异地多活，需要做一些基础设施，为双活奠定基础。首先需要做一个双活控制台，用于整体控制流量调拨并监控双活的运行状态。之后对基础设施进行技术改造以支持双活，在这里会涉及到网关 DLB 层、RPC 服务路由与注册中心、配置中心、MQ、TOC、Redis、MySQL、ES、HBase 等，还定制了数据复制中心（DRC）、数据巡检中心（DCP、DAL）来实现流量的调度。确保流量调度后，在新的数据中心能访问到正确数据，与之前事务上下文保持一致。</p><p></p><p>业务系统的改造</p><p></p><p>业务系统的改造专注于核心买家链路，并不是对所有的链路进行单元化，有些面向 B 端的应用系统甚至完全不用改造。不同的买家链路架构改造方式不同，比如库存链路的 DB 会完全采用中心化部署的方式；商品详情链路中商品库会采用中心写单元读模式；订单链路则完全采用单元化部署方式。</p><p></p><p>买家链路的改造需要从流量入口开始梳理，先进行单元化链路标记，接着梳理上下游，根据上下游是否需要单元化并进行改造，然后再梳理 MQ、Redis、MySQL、TOC 等中间件，确定相应的单元化方案。</p><p></p><p>双活的业务复杂度很高，对业务系统的影响也比较大，得物目前一共有 几十个业务系统涉及单元化改造。这么大的改造对测试同学的挑战也非常大，除了需要测试正常的业务场景，还需要验证双活场景下的流量调度是否正确。</p><p></p><h3>高可用平台治理方案</h3><p></p><p></p><h4>应对“天灾人祸”</h4><p></p><p></p><p>为了预防突发事件，高可用架构需要在设计时提前考虑很多的异常场景，即所谓的“天灾人祸”，比如机器宕机、集群节点宕机、网络抖动、网络攻击、下游服务异常、服务自身代码 bug、消息堆积等。</p><p></p><p>因此在做技术设计&amp;实现时要做好相应的防灾难设计与措施，比如通过机器冗余、集群故障失效转移、主从复制断点续传、业务隔离、性能压测、限流/降级、流量回放、变更控制等手段来保障系统的高可用。</p><p></p><p>这里，可以把“天灾人祸”的原因归为几类：</p><p></p><p>1）硬件问题，比如机器宕机、集群节点宕机、网络抖动、网络攻击，一般依赖于企业的基础设施和相应的支撑团队，这种情况一般通过灾备来解决和预防，得物通过自建异地双活来实现极端情况下硬件问题的故障防控。</p><p></p><p>2）软件问题，比如服务本身异常、下游服务异常、代码 bug、中间件异常等，这里是故障防控的重点，也是故障频发的部分。</p><p></p><p>软件问题具体可以归因为：（1）变更引起的故障；（2）流量和容量变化引起的故障；（3）依赖故障；（4）机房、网络等环境故障；（5）其它：比如幂等失效、分布式Id溢出导致的故障。得物一般是建立变更故障防控、大促故障防控、日常故障防控，对软件问题进行预防，从微服务本身、微服务上下游依赖、微服务依赖的技术环境三个部分梳理潜在问题，并提前做好相应预案，在问题发生时可以通过执行相应的预案来预防和进行故障的快速恢复。</p><p></p><p>3）人为问题，一般涉及到各种线上误操作，通过软件产品自身的完备性、成熟的技术规范、操作 SOP、管控措施、CheckList 来应对。</p><p></p><p>此外在得物的系统链路中都有自定义的限流、熔断手段，当埋点数据触发阈值时，会执行指定的异常处理方法，进行限流或者对下游进行熔断、甚至是通过业务开关直接对指定的业务进行降级。除了系统链路中自动的熔断、降级措施外，我们还在自研的预案平台中有配置的各种预案，当出现异常情况，会人工或基于埋点的自动执行，来实现优雅降级，确保系统的高可用。</p><p></p><h4>全链路压测平台</h4><p></p><p></p><p>得物<a href=\"https://xie.infoq.cn/article/0d8362de38602eab56d0eded1\">全链路压测平台</a>\"于 2019 年完成，在 2020 年的 618 大促首次使用生产环境进行压测，经历了多次大促实战，目前已经能够非常顺滑的验证核心链路应对大促突增流量的稳定性。去年双十一和今年 618，在限流和预案开启或关闭的情况下，得物采用梯度递增、脉冲、稳定水位进行流量验证，分别经过 3 轮和 2 轮压测后，核心链路达到预期的压测目标，并且在大促当天所有核心链路均符合预期表现。</p><p></p><p>得物整个全链路压测平台建设及实施涵盖了以下内容：</p><p></p><p>1）由 Fusion 封装了压测接入 API，所有中间件必须按照统一规范接入和使用；</p><p></p><p>2）构建流量漏斗模型，即外部流量从网关入口开始，在每个调用链路上的变化比例，流量配比参考历史双十一峰值 QPS；</p><p></p><p>3）通过 Mock 模块处理外部依赖的调用链路；</p><p></p><p>4）流量标透并建立影子中间件，包括 MySQL、Redis、MonogoDB、Kafka、RocketMQ、HBase、ES、分布式锁等；</p><p></p><p>5）流量标透传并进行核心链路改造，基于 Fusion 框架识别测试流量标，进行相应改造；</p><p></p><p>6）建设测试环境和仿真环境；</p><p></p><p>7）构建测试用户和测试数据；</p><p></p><p>8）实施单机接口测试、单机混合链路测试、全链路压测。</p><p></p><p>得物的流量标方案，就是要解决数据隔离问题，压测产生的脏数据不能写入线上环境，通过中间件平台封装的 fusion 脚手架，在 RPC、Redis、DB、MQ、跨线程中透传压测标，如果识别是压测流量，产生的数据会写入到影子库，以此来实现数据的隔离，确保线上稳定，为全链路的压测奠定了基础。</p><p></p><p>在全链路压测平台的建设中，我们也逐步摸索出了得物特色的全链路压测流程。得物的全链路压测流程包括：系统摸高，限流演练，预案演练 。通过全链路压测，帮助发现系统性能瓶颈，限流配置，预案缺失等诸多问题。</p><p></p><h4>大促备战经验分享</h4><p></p><p></p><p>大促是考验电商高可用平台的最好时机，首先作为前提的是，每一次大促都会有一个目标策划，确定本次大促的业务和技术目标，之后进行大促备战。得物大促备战主要涵盖三个部分：1）整体稳定性保障；2）业务需求交付；3）组织保障。大促需要以保障稳定性为前提，做好按时的业务需求交付，同时整个组织需要具备强悍的项目管理能力。</p><p></p><p>到目前为止，得物整个大促备战从整体保障、域内保障、组织保障都有清晰的 SOP 和系统化的沉淀。一般分为启动阶段、规划阶段、各域执行交付阶段、压测&amp;验收阶段、作战阶段、作战复盘阶段实施等等，大促备战是井井有条的。</p><p></p><p>首先，得物有专门的 PMO 组织来整体保障需求的流水线交付，保障大促需求的按质交付，下面介绍得物的稳定性保障，主要分为两大部分：大促整体备战；各业务域备战。</p><p></p><p>大促整体备战，顾名思义从全局视角关注突增流量对全域买家链路的影响，确保在大促当天这些核心买家链路应对突增流量的稳定性。因此，首先会先对业务目标进行拆解，之后确定各个链路的流量，做好链路的容量评估以及各个服务的扩缩容。之后会从链路的稳定性入手，梳理链路的架构风险、链路自身的风险，做好链路的预案和演练。</p><p></p><p>最后，通过几轮的压测，确保各个主要链路满足既定业务目标的流量。整体上会规划好大促推进的节奏，准备当天的大促备战。</p><p></p><p>各业务域备战，则是围绕着业务域的核心链路稳定性展开，这些链路一般是 P0 链路，规划需要做的事情，并在总体节奏上符合整体大促备战的节奏。</p><p></p><p>总的来说，链路稳定性保障一般会从几个部分来展开：1）架构大图、业务链路梳理；2）可见性建设；3）风险识别与架构治理；4）可控性建设。下面做简单描述：</p><p></p><p>架构大图，涵盖业务架构、IT架构，关于架构图，大家都很熟悉了，推荐一个架构模型——C4，可以使用 C4 的 L1、L2 来清晰描述 IT 架构。接着是域用例梳理，通过域用例推导业务链路，业务链路一般是域用例的顶级服务交互。一个业务链路的入口，一般就是一个服务，这个服务由服务自身、服务上下游依赖关系、服务依赖的底层技术环境（如 RPC、DB、缓存、MQ、Job、JVM、容器、物理机等）三个部分构成。通过架构大图、业务链路梳理，就可以把域内系统和链路描述的比较清晰，使我们对构建的系统就有比较全局性的理解。这一步相当于我们稳定性建设的目标判断。可见性建设，得物聚焦在系统监控大盘、业务链路大盘、域业务监控大盘，以及系统和业务链路精准报警几个部分构成。通过可见性建设，我们可以实时观测系统、业务链路的运行状况，及时发现正在发生的风险以及潜在的风险。风险识别和架构治理，聚焦在链路风险识别并制定治理方案。有了可见性建设，我们可以从链路通讯的历史数据，主要围绕 P0 链路进行体系化的链路风险分析，一般涵盖架构变更风险、SLA 风险、超时和重试合理性风险、强弱依赖风险、链路调用风险、链路依赖技术环境风险、集群或拓扑风险等，之后针对识别的风险制定相应的架构治理方案。可控性建设，聚焦于风险识别与预案体系。风险识别，我们会通过精准告警、SLO 巡检来识别，SLO 巡检有相应的 CheckList 判断是否系统有故障发生，并查看风险发生链路对应的预案。在故障发生之后，可以对故障快速定位和止损，理想的目标是每一个故障都有相应的预案应对。实际中，并不是所有的故障都有预案，但可以根据历史故障和一些先验知识将故障进行归类，建立相应的预案。另外，预案要能方便执行和触发。得物在出价库存域大促稳定性保障方案，整体方案主要涵盖以下内容：大促作战手册：梳理大促前、大促进行时、大促结束时需要按照时间节点完成的作战事项；业务链路稳定性保障：容量评估、预案与演练、接口限流、流量治理、压测与复盘；架构治理：架构分析与核心链路梳理、慢链路治理、DB 治理、Redis 治理、JVM 治理、定时任务/数据回流与商家后端管控；资损防控：梳理资损点、应急工具、处理 SOP 等；应急工具：数据核对、出价应急处理等。</p><p></p><h3>经验分享，写在最后</h3><p></p><p></p><p>高可用是互联网企业系统架构的基础要求之一，从架构师所能解决的问题的能力划分，小到解决一个子域或模块，大到一个组织，要求的能力完全不同。</p><p></p><p>架构师需要具备准确的定义问题能力和解决高可用系统面临的技术挑战的能力，这要求架构师具备强的思考力以及解决问题的技术能力。构建高可用的系统一般要求架构师能够：1）具备合理的架构设计推导逻辑；2）理解业务并将业务挑战映射到技术挑战；3）从 0 到 1 构建一个满足业务目标的高可用系统；4）在快速业务迭代演进的过程中保持系统高可用。</p><p></p><p>首先，架构设计推导逻辑，是架构师最基本的要求，要求架构师能够从用户问题洞察出发，理解用户问题的解决路径，定义商业流程及组织角色，构建出系统业务架构；接着，从业务架构推导 IT 架构，即应用架构、技术架构和数据架构。这就要求架构师具备架构分析、设计的相应方法论、工具。比如 TOGAF 企业架构方法论、DDD 方法论、C4 架构模型、UML 建模工具箱、四色模型等等，形成一套自己实战的方法论。</p><p></p><p>第二，理解业务并将业务挑战映射到技术挑战，就要求架构师在业务理解下，能够设计合理的架构方案并引导架构活动实施。架构方案要从明确的业务或技术目标展开并对目标合理性进行一定的干预，基于当前的商业环境、企业技术基础设施、企业技术文化，在有限资源和成本约束下，通过合理的架构活动满足目标用户需求，最终确保技术方案实施能够实现商业价值。架构师不是仅仅解决用什么技术、什么架构去实现的问题，而是要考虑业务的方向，从技术角度如何合理的实现，为企业业务支撑带来更高的 ROI。</p><p></p><p>最后，架构师需要具备较强的微服务架构及其支撑的基础设施相应储备，微服务架构一般包含服务拆分与合并、微服务开发框架、微服务治理体系、微服务生命管理平台、微服务支撑基础设施、微服务安全体系等等能力。整体知识非常的庞大，当架构师对微服务架构有深入理解和支撑基础设施较为广度及深度的知识储备，并且通过实践进行验证积累实践经验，就能够从高可用目标出发，进行合理技术选型，实现服务规划、构建和治理，使得服务构建和之后的演进都能满足高可用目标。</p><p></p><h4>嘉宾介绍</h4><p></p><p>金思宇：得物技术 Leader，毕业于东北大学，先后在中兴通讯、阿里巴巴、唯品会任职，并有 2 次创业经验。对电商及上下游有比较丰富的开发及业务架构经验。19 年加入得物 App，目前主要负责交易平台及中间件平台，带领团队支撑得物 App 交易域的业务需求，完善业务基础能力；同时负责中间件团队的管理及技术演进规划。</p><p></p><p>陈贞宝：得物出价&amp;库存 Leader，曾在 Sybase、厦门锐特、阿里巴巴任职，有 5 年创业经历。曾负责 2 次 S 级大促以及多次的域内稳定性保障，在架构设计与治理、大促稳定性保障有较多实战经验和体系化思路。21 年加入得物 App，目前主要负责得物出价&amp;库存团队，带领团队完成技术规划、业务交付、稳定性保障等工作。</p><p></p><p>胡强忠：得物业务架构师，曾在中国航信的不同分支机构任职，有过一次创业经验。对 OTA、电商行业有较丰富的开发、架构经验。19 年加入得物 APP，目前主要负责交易平台的架构演进规划、业务领域建模、稳定性治理等工作。</p>",
    "publish_time": "2022-09-19 17:44:54",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "NGINX局限太多，Cloudflare最终放弃它并用Rust自研了全新替代品",
    "url": "https://www.infoq.cn/article/s2fa603MsEENsCmibTYI",
    "summary": "<p>长期以来，NGINX 可以说是网站安全和托管服务提供商 Cloudflare 的核心，是其所使用的基础软件的一部分。</p><p></p><p>“Cloudflare 将 NGINX 用于其提供的所有 Web 服务，并在世界各地的数千台机器上使用它作为反向代理服务器。”“我们选择NGINX主要是因为它的性能。”Cloudflare CTO John Graham-Cumming <a href=\"https://www.nginx.com/success-stories/cloudflare-boosts-performance-stability-millions-websites-with-nginx/\">曾如此阐述</a>\" NGINX 对 Cloudflare 的重要性。</p><p></p><p>不过，如今 Cloudflare<a href=\"https://blog.cloudflare.com/how-we-built-pingora-the-proxy-that-connects-cloudflare-to-the-internet/\">决定</a>\"放弃 NGINX ，转而使用内部开发的 Pingora。理由也和性能有关。</p><p></p><p>按照官方的说法，随着Cloudflare的发展壮大，NGINX已经无法满足他们的现实业务需求。“虽然NGINX多年来一直表现良好，但时间推移之下。其局限性也在我们的持续迭代、规模扩张之下暴露无遗。我们既无法获得理想的性能，NGINX也没法为高度复杂的环境提供必要的功能支持。”Cloudflare 于 9 月 14 日发布的博文中写道。</p><p></p><p>Pingora 是 Cloudflare 工程师用 Rust 编写的全新HTTP代理系统，专为Cloudflare用例及业务规模设计。据介绍，它每天处理超过1万亿条请求，提高系统性能之余，也为Cloudflrae客户带来不少新功能。更重要的是，它运行所占用的CPU和内存资源只相当于原有代理基础设施的三分之一。</p><p></p><p>目前Pingora尚未开源，官方称将找个合适的时机再对外分享。</p><p></p><p>以下内容源自 Cloudflare，其详细讲述了换掉旧代理的原因，以及他们是如何开发出 Pingora 的。</p><p></p><h2>为什么要构建新代理</h2><p></p><p></p><p>多年以来，NGINX的种种局限性已经严重影响到我们的业务运营。虽然先后优化或缓解了部分限制，但仍有一部分问题始终得不到完美解决。</p><p></p><h4>架构限制开始拖累性能</h4><p></p><p></p><p>NGINX <a href=\"https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/\">worker（进程）架构</a>\"在我们的用例中存在缺陷，而且已经损害了Cloudflare的性能和效率。</p><p></p><p>首先，在NGINX当中，每条请求只能由单个worker处理。这会导致各CPU核心的负载不均衡，进而拖慢处理速度。</p><p></p><p>由于这种请求进程锁定效应，一旦出现高强度CPU操作或阻塞IO任务的请求，那么其他请求的处理速度也会受到影响。我们已经投入了不少精力尝试解决，但收效不佳。</p><p></p><p>对我们的用例来说，NGINX中最大的麻烦还在于糟糕的连接重用机制。我们的设备与原始服务器间通过TCP连接来代理HTTP请求。连接重用会重复使用连接池中包含的原有连接，由此跳过建立新连接所需要的TCP和TLS握手，从而缩短TTFB（第一字节时间）。</p><p></p><p>然而，NGINX连接池是按worker划分的。当请求到达特定worker时，其只能重用该worker之内的连接。因此当我们添加更多NGINX worker进行扩容时，连接重用率就会变得越来越差，导致大量连接分散在所有进程的多个隔离池内。于是TTFB延长了、需要维护的连接数量增加了，我们自己乃至客户的资源（成本）也被白白浪费掉了。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f8/f875f5a2b31825ded349083cd44b84f7.png\" /></p><p></p><p>可以看到，NGINX中的worker/进程模型才是罪魁祸首，所以开发新代理就成了从根源上解决问题的最佳途径。</p><p></p><h4>难以添加某些功能类型</h4><p></p><p>NGINX其实是款非常出色的Web服务器、负载均衡器和简单网关。问题是Cloudflare的需求远不止于此。以往，我们常常围绕NGINX构建自己需要的各项功能，但同时还要避免同NGINX的上游代码库发生严重分歧，这相当于是戴着脚镣跳舞、非常痛苦。</p><p></p><p>例如，当请求重试/失败时，我们往往希望能将请求发送到具有不同请求标头集的其他服务器处。但NGINX并不允许这样的操作，所以我们就得投入时间和精力想办法突破NGINX的限制。</p><p></p><p>除了设计上的限制之外，NGINX的编程语言要求也让我们颇为头痛。NGINX是纯用C语言编写的，因此在设计上不具备内存安全性。在使用第三方代码库时经常会出错，即使对经验丰富的工程师来说，也很容易闹出内存安全问题。我们当然希望能尽量回避掉这些问题。</p><p></p><p>我们用过的另一种补充性语言是Lua，它的风险更低，但性能也比较差。另外，在处理复杂的Lua代码和业务逻辑时，经常会出现静态类型缺失的问题。</p><p></p><p>最后，NGINX社区不太活跃，开发团队往往像在“闭门造车”。</p><p></p><h2>决定自己开辟一条道路</h2><p></p><p>过去几年以来，随着我们不断扩大客户群体和功能集，Cloudflare也一直在认真评估以下三种选项：</p><p></p><p>继续投资NGINX，并尝试通过fork让它能100%满足我们的需求。我们已经拥有必要的专业知识，但考虑到设计之初的架构限制，恐怕要投入大量资源才能根据自身需求完成全面重建。迁移至其他第三方代理选项。市面上并不缺乏好的项目，比如envoy等。但我们担心再过几年，同样的问题也许会在那些项目身上重演。从零开始构建内部平台与框架。这个选项的效果肯定是最好的，问题就是占用的工程资源和产生的前期投入也最多。过去几年来，我们每个季度都会对这些选项开展评估，但始终没找到最有说服力的答案。于是我们继续走阻力最小的道路，不断增强NGINX。但团队中关于自建代理的呼声开始涌现，大家越来越觉得这种方式虽然投资较大，但最终回报是值得的。于是我们开始从零入手构建代理，希望能设计出完美匹配自身需求的代理方案。</p><p></p><h3>Pingora项目</h3><p></p><p></p><h4>设计决策</h4><p></p><p>为了让代理快速、高效且安全地处理每秒数百万条请求，我们先得做出一系列重要的设计决策。</p><p></p><p>首先，我们选择用Rust编写这个项目。因为它能够在不影响性能的前提下，以内存安全的方式带来可与C语言比肩的极佳性能。</p><p></p><p>虽然市面上已经有不少很棒的第三方HTTP库，例如hyper，但我们还是决定自行构建库。理由很简单，我们想要最大限度提升HTTP流量处理的灵活性，并确保按照自己的节奏推动创新。</p><p></p><p>在Cloudflare，我们需要面对几乎是整个互联网的流量，必须支持种种稀奇古怪、不符合RFC的HTTP流量。这也是HTTP社区和Web领域的常见难题，即如何在严格遵循HTTP规范的同时，适应潜在遗留袖或服务器同广泛生态系统间的细微差别与紧张关系。</p><p></p><p>在RFC 9110中，HTTP状态码被定义成一个三位整数，通常区间在100到599之间。Hyper就是这样一种实现。但也有不少服务器支持使用599到999之间的状态码。这种冲突曾引发过激烈的争论，虽然hyper团队最终接受了这一变更，但如果不接受其实也没有办法——毕竟双方都有自己的道理可讲。而这，还只是我们需要支持的种种不合规行为中的冰山一角。</p><p></p><p>为了满足Cloudflare在HTTP生态系统中主导性地位的要求，我们必须建立起一个健壮、宽松、可定制的HTTP库，适应互联网上的狂野法则、支持种种不合规用例。好在由于是内部原创，所以至少决定权把握在我们自己手中。</p><p></p><p>下一项设计决策则跟工作负载调度系统有关。我们选择了多线程、而非多进程，目的是为了轻松实现资源共享，特别是连接池共享。我们还决定用工作窃取机制来避免前文提到的某些性能问题。事实证明，Tokio异步运行时特别符合我们的需求。</p><p></p><p>最后，我们希望这个项目能直观些、对开发者们友好些。我们要开发的并不是最终产品，而是可以进一步扩展的平台，允许在其上构建更多功能。于是，我们决定提供一个类似于NGINX/OpenResty的基于“请求生命周期”事件的可编程接口。举例来说，可以后续编写“请求过滤器”帮助开发人员在收到请求标头时，运行相应代码来修改或拒绝请求。通过这样的设计，我们就能清晰地把业务逻辑和通用代理逻辑分离开来，同时保证之前接触NGINX的开发人员也能轻松转向Pingora、迅速提高工作效率。</p><p></p><h2>Pingora在生产中速度更快</h2><p></p><p>让我们快进到现在，Pingora已经在处理几乎一切需要与源服务器交互的HTTP请求（例如缓存未命中的情况），我们在此期间也收集到了大量性能数据。</p><p></p><p>首先，我们来看看Pingora如何推动客户流量提速。Pingora上的总体流量显示，TTFB中位数降低了5毫秒，第95百分位TTFB降低了80毫秒。这当然不是因为我们的代码运行更快了，毕竟原封不动的旧服务现在也可以将请求响应控制在亚毫秒范围内。</p><p></p><p>这样的节约源自新架构，特别是它跨所有线程实现连接共享的能力。凭借着更好的连接重用率，我们在TCP和TLS握手上耗费的时间大为缩短。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/51/51611c4d59fbbb7577760f537df32cd2.png\" /></p><p></p><p>与旧服务相比，Pingora将全体客户的每秒新连接使用量降低至三分之一。对其中一家主要客户，其连接征用率从之前的87.1%提升到了99.92%，意味着新连接数量降低至原本的一百六十分之一。为了更直观地感受这种变化，大家不妨看看这个数字：自从使用Pingora以来，我们每天能够为客户和用户节约下长达434年的握手时间。</p><p></p><h4>更多功能</h4><p></p><p>有了工程师们熟悉的开发者友好接口，又消除了以往令人头痛的限制，我们自然可以快速开发出更多新功能。凭借新的协议等核心功能，我们现在能够为客户提供更多产品构建块。</p><p></p><p>例如，我们能够以相对简单的方式为Pingora添加HTTP/2上游支持，由此加快了向客户提供gRPC的速度。很明显，要想将这项功能添加进NGINX，不只是涉及的工程量更大、甚至有可能压根无法实现。</p><p></p><p>最近，我们又公布了Cache Reserve，Pingora在其中使用R2存储作为缓存层。随着我们向Pingora添加更多功能，相信未来将提供更多开创性的新产品。</p><p></p><h4>更高效率</h4><p></p><p>在生产环境中， 面对同等流量负载的情况下，Pingora所消耗的CPU和内存资源量与旧有服务相比，分别降低了约70%和67%。这样可观的资源节约源自以下几大要素。</p><p></p><p>与旧的Lua代码相比，我们的Rust新代码运行效率更高。更重要的是，二者在架构上也存在显著的效率差异。以NGINX/OpenResty为例，当Lua代码想要访问HTTP标头时，必从NGINX C结构中进行读取、分配一个Lua字符串，然后将该标头复制到Lua字符串内。最后，Lua还得对这个新字符串进行垃圾回收。而Pingora不同，它能直接执行字符串访问，就这么简单。</p><p></p><p>多线程模型也让跨请求数据共享变得更加高效。NGINX虽然也提供共享内存，但由于实现限制，每次共享内存访问都需要使用互斥锁，而且只能将字符串和数字放入共享内存。在Pingora中，大多数共享条目都能通过原子引用计数器后的共享引用进行直接访问。</p><p></p><p>至于CPU的节约，主要体现在前文提到的新连接创建量显著降低之上。不同于会造成高昂TLS握手成本的旧方案，Pingora可以更多通过已建立的连接实现数据发送和接收。</p><p></p><h4>更安全</h4><p></p><p>快速安全地发布功能绝非易事，在Cloudflare这样庞大的运营规模下更是困难重重。我们几乎无法预测每秒要处理几百万条请求的分布式环境中可能发生哪些极端状况，毕竟模糊测试和静态分析根本就覆盖不到这样的场景。这时候，Rust的内存安全语义保护挺身而出，在保护我们免受未定义行为困扰的同时，也让我们坚定相信自己的服务能够正确运行。</p><p></p><p>有了这些保障，我们就能更多关注自己的服务变更如何与其他服务或客户源进行交互。我们能以更快的节奏开发出新功能，不再受到内存安全和种种未知崩溃的拖累。</p><p></p><p>而一旦真的发生了崩溃，工程师们当然要花时间来诊断崩溃如何发生、背后又有怎样的原因。自Pingora运行以来，我们已经先后处理过数百万亿条请求，还没遇到过任何一次源自服务代码的崩溃问题。</p><p></p><p>事实上，Pingora的崩溃可以说非常罕见，每次出现的问题都跟Pingora自身没什么关系。最近，我们在一次服务崩溃中发现了一个内核bug，还在某些设备上发现了硬件问题。这种感觉简直神奇，长久以来最不稳定的软件元素现在却成了最可靠的部分，甚至足以支持我们发现硬件层面的内存bug……之前无数次重大调试都找不到这些问题，原因自然是当时不等硬件崩溃，软件早已经坚持不住了。</p><p></p><h2>总结</h2><p></p><p>总而言之，我们建立起一套更快、更高效、更通用的内部代理，并把它当成现有及未来产品的运行平台。</p><p></p><p>借此机会，我们重新将视线集中到Cloudflare面临的问题、值得探索的优化空间，以及Pingora开发过程中积累下的重要经验教训与技术细节身上。我们也将回归开源精神，找个适合的机会与大家分享更多后续成果。</p><p></p><p>Pingora是我们重构系统的一次最新尝试，但绝不会是最后一次。期待Pingora能成为我们全面系统重构的重要基石。</p><p></p><p>原文链接：</p><p><a href=\"https://blog.cloudflare.com/how-we-built-pingora-the-proxy-that-connects-cloudflare-to-the-internet/\">https://blog.cloudflare.com/how-we-built-pingora-the-proxy-that-connects-cloudflare-to-the-internet/</a>\"</p>",
    "publish_time": "2022-09-19 17:52:17",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "华为加深云业务布局，面向全球落地多项重磅创新技术",
    "url": "https://www.infoq.cn/article/CHdvyA8kytP3Wz21es1W",
    "summary": "<p></p><p>9月19日，第七届<a href=\"https://www.huawei.com/cn/events/huaweiconnect/global\">华为全联接大会</a>\"首次出海，并在泰国曼谷开幕。华为在大会上分享了推进行业数字化发展的核心举措，并面向全球市场发布超过十五余项创新云服务。</p><p></p><h2>三大核心举措，推进行业数字化发展</h2><p></p><p></p><p>过去两年，疫情等因素导致全球GDP增长波动，但数字经济始终保持增长，2021年同比增长超15%。当前对大多数企业来说，没有人会去怀疑数字化该不该做，大家更关心的是，数字化怎么做，怎么做得好。</p><p></p><p>“我们也看到，不同的国家、行业和企业，数字化发展成熟度有差异，但仍呈现出共性的挑战和关注点。”华为轮值董事长胡厚崑表示，华为对此总结了四类共性问题：</p><p></p><p>首先，数字基础设施仍需加强。一方面，对数字化转型刚起步的国家/企业来说，联接、计算的基础设施仍然比较薄弱；另一方面，数字化转型比较早、进程比较快的国家/企业，对联接和计算都提出更高的要求。千行百业场景多样，需要千亿级联接、10倍的带宽、低至微秒的时延和工业级的稳定性，同时，数据量的激增也要求算力百倍增长。第二，先进技术（如AI、大数据等）在行业场景落地难。比如“场景很复杂，技术不能匹配”，比如“有想法，找不到合适的方案”，再比如“缺乏数字化经验和人才”。我们看到，有些港口已经开始使用AI来提高码头调度的效率，但要用好AI并不容易。不仅需要自建IT设备和开发环境，还需要多名经验丰富的博士花费3-6个月时间，来开发AI应用。第三，伴随着数字化转型的深入，行业应用需求量急剧提升。IDC预测，到2024年数字经济的发展将孕育出超过5亿个新应用/服务，这与过去40年间出现的应用数量相当。基于传统模式的应用开发、部署和运行效率低，无法满足海量需求。基于华为与客户、伙伴的探索和实践，就如何推进千行百业的数字化这个命题，华为提出三大核心举措：基础设施先行，持续提升联接和计算能力；坚定拥抱云，从“上好云”到“用好云”，助力企业数字化转型实现跨越式发展；积极构建本地数字生态，培育数字人才，并助力中小企业发展。</p><p></p><h2>助力企业最大化云的价值</h2><p></p><p></p><p>伴随华为提出的“坚定拥抱云实现跨越式发展”等核心举措，华为云也面向全球首次发布“Go Cloud，Go Global”生态计划，阐明华为云“一切皆服务”“共建智能世界云底座”等核心主张。</p><p></p><p>据华为云CEO张平安介绍，华为云印尼、爱尔兰节点将于近期开服，到今年年末，华为云将布局全球29个区域、75个可用区，覆盖170多个国家和地区。</p><p></p><p>会上，华为云全球Marketing与销售服务总裁石冀琳发布了华为云在云原生、AI开发、数据治理、数字内容、软件开发、开天aPaaS等领域的超过15项创新服务，这些服务首次面向全球落地。</p><p></p><p>在云原生领域，华为云面向全球落地两款<a href=\"https://www.infoq.cn/article/hEizk8L0hl6TewBZZKRs\">云原生产品</a>\"——容器CCE Turbo和分布式云原生UCS (Ubiquitous Cloud Native Service)：CCE Turbo可通过计算、网络、调度全方位加速，实现极致弹性，如帮助新浪公司以3000pod/min的弹性轻松应对业务流量洪峰；UCS提供跨云、跨地域的云原生应用管理，实现一致体验。</p><p></p><p>在AI开发领域，华为云打造AI开发生产线ModelArts，帮助AI开发者一站式高效完成从数据标注、模型训练、到模型部署。其中，AI+RPA （Robotic Process Automation, 机器人流程自动化）服务可实现企业合同处理、财务报销等业务智能化；时空计算服务，可为城市打造精准的实景3D建模；全域感知服务，可根据园区等场景的业务需求，自动适配100多种AI视频算法。</p><p></p><p>同时，华为云打造的<a href=\"https://www.infoq.cn/article/YMaNcENfqGuNM7hIPQTt\">千亿级参数盘古大模型</a>\"，让AI开发由作坊式转变为工业化开发的新模式，加速AI行业应用。当前已经应用于制药、金融、电力、煤炭等领域。例如，本次全新发布的盘古海浪大模型用于全球海浪实时预测，可以将海浪计算时间从小时级缩短到秒级。</p><p></p><p>在数据治理领域，华为云推出<a href=\"https://www.infoq.cn/article/IclRPsVAppKIgDT7kRa1\">数据治理生产线DataArts</a>\"，帮助企业释放数据价值。其中，DataArts LakeFormation通过元数据统一管理，实现AI、数据仓库、数据湖的数据互访互通，让AI更高效地使用湖仓数据。</p><p></p><p>在数字内容领域，华为云发布数字内容生产线MetaStudio，使能媒体领域内容创建，为数字电影、数字动画、数字收藏、教育课件以及数字人等内容开发提供能力支持。</p><p></p><p>在软件开发领域，应用现代化是企业数字化转型的关键，华为云软件开发生产线DevCloud聚焦应用开发现代化，落地了代码检查和云测试两大新服务：代码检查可智能、及时检测出代码缺陷及安全问题，支持超过1万项安全规则，实现低成本纠错，提升代码质量；云测试面向性能、功能、API等海量测试用例，实现7*24小时的自动化策划，大幅提升系统级测试效率。</p><p></p><p>在行业使能领域，华为云进一步携手全球行业伙伴，持续加快开天aPaaS平台能力升级，落地KooMessage和KooSearch服务。其中，KooMessage可为企业提供全场景消息服务，支持多形式消息、多终端设备的智慧消息触达；KooSearch为企业提供智能搜索引擎服务，支持50多个小语种，可通过AI赋能实现精准分析、智能推荐。</p><p></p><p>胡厚崑表示，在云的助力下，“企业可以更聚焦自身业务创新，实现从传统信息化到数字化、智能化的跨越式发展。”</p>",
    "publish_time": "2022-09-19 17:57:37",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]