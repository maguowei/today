[
  {
    "title": "分布式数据库 TiDB 在携程的实践",
    "url": "https://www.infoq.cn/article/cxrXBkI6Ox48BGdVx23X",
    "summary": "<p>随着新冠病毒疫情的缓解和控制，全球旅游业逐渐开始重新复苏。尤其在一些度假胜地，游客数量已经恢复到疫情前的水平。</p><p>&nbsp;</p><p>携程作为全球领先的一站式旅行平台，旗下拥有携程旅行网、去哪儿网、Skyscanner 等品牌。携程旅行网向超过 9000 万会员提供酒店预订、酒店点评及特价酒店查询、机票预订、飞机票查询、时刻表、票价查询、航班查询等服务。</p><p>&nbsp;</p><p>随着业务量迅速增长，携程需要更敏捷的技术架构来满足不断激增的并发与数据量，一个稳定、可靠，可以随业务增长不断扩展的数据库对于携程来说显得尤其重要。作为海内外在线旅游行业的翘楚，携程也曾面临着数据库带来的技术挑战。</p><p>&nbsp;</p><p>携程创立于 1999 年，最初选择使用 SQL Server 数据库，在整体数据库技术栈中占比达到 99%。 2012 年初，携程开始逐步关注开源技术，尤其是 MySQL，不过该阶段 MySQL 使用占比仍然很低，只有 10% 左右。从 2014 至 2019 年，携程开始加深 MySQL 的应用，并因为业务形态发生了变化，携程开始从 SQL Server 转型到 MySQL，对 MySQL 进行了深入研究，包括内核补丁、全自动故障诊断等。</p><p></p><h2>原 MySQL 架构痛点与挑战</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/62/62697da89d1a409edbcb2b1fa038d660.png\" /></p><p></p><p></p><p>携程的应用部署在两个或多个 IDC 中，数据库也对等部署在每个 IDC 中。MySQL 部署方式采用 HA节点，即主备节点，在同一机房部署，另一节点在不同 IDC 部署，这种方式保证了 HA 切换速度和数据的容灾。比如遇到单机房故障或者整个机房宕机，可以迅速把第二节点启动起来。携程在主备切换和第二切换时做了很多自动化工作，但这种架构也有明显缺点，由于应用的无状态化，数据库的切换会造成业务的短暂中断，因为数据库只有一个主节点。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4d/4d29ac22b355c384779aea1dce475847.png\" /></p><p></p><p>在扩展方式方面，携程没有采用中间件的方式，而是采用客户端实现分片规则。客户端在上线时会确定分片规则，比如 64。再根据 ID 使用取模运算定位到某个分片，这样可以更方便地进行扩展。当业务增加时实例数量从 1 变成 N ，当负载下降时也可以缩回来。</p><p>但是这种扩展方式对 DBA 运维来说还有一些挑战，随着 DBA 越来越多，聚合会比较困难，业务代码也变得复杂。</p><p></p><p></p><h2>分布式数据库选型</h2><p></p><p></p><p>2018 年，随着携程业务的快速发展，底层架构需要支持弹性扩展，特别是在季节性高峰期（例如春运火车票抢票等）。分布式数据库由于具有 DB 级弹性、快速扩展和混合负载（HTAP）等优势，更适合业务的发展，携程开始考虑引入分布式数据库，并进行调研选型。携程主要从以下几个维度考量分布式数据库：</p><p>性能：平衡性能和成本，选择通用机型，不使用高端存储或机器，并要求响应稳定；运维与社区：学习成本适中，运维复杂度低，产品需开源且社区活跃；成本：一方面，业务研发需要学习使用 SQL，特别是 MySQL 协议；另一方面，运维团队希望产品不要过于复杂，易于维护；扩展性：分布式数据库需要具有快速的扩展能力，扩缩容对业务影响小。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f6/f65446f593f105a7380f5d3cd4beb16c.png\" /></p><p></p><p>2018 年，携程开始正式引入 TiDB。考虑到 TiDB 的架构和携程的 IDC 环境，携程将 TiDB 分别部署在三个 IDC 机房（IDC1、IDC2、IDC3）中，遵循同时部署的标准。TiKV、TiDB 和 PD 均匀分布在三个 IDC 机房中，业务流量可以本地感知到每个机房的 TiDB Server ，在单机房故障时可以自动重启到其它机房。因为客户端对 TiDB 进行了探活与感知，单个 TiDB 服务器故障时客户端可以重新定向。</p><p></p><p></p><h2>TiDB 在酒店和度假结算场景的应用</h2><p></p><p>&nbsp;</p><p>在酒店和度假结算场景应用中，携程原 MySQL 架构主要采用分片（sharding）的扩展方式，对于酒店和度假结算这类业务来说，分片会变得非常困难。最初的方案是把 SQL Server 上的数据原封不动导入到 MySQL 中，但测试后发现性能不佳，扩展性也受限。如果采用分片方式部署，不论从酒店的维度、供应商的维度或者是用户维度，都很难选择合适的分片键（ sharding key），这种方式也对业务代码侵入性比较大。因此，携程最终选择了 TiDB，将酒店和度假结算业务从 SQL server 迁移到 TiDB 上，总数据量规模达到 8TB，并受到了开发人员的一致好评，满足了性能和扩展性的诸多要求。</p><p>&nbsp;</p><p></p><h2>TiDB 在海量数据场景中的应用</h2><p></p><p>&nbsp;</p><p>携程的海量数据场景涉及到大量数据存储。原架构中由于单机存储限制，扩展必须通过 sharding 方式实现。但该解决方案对于一些业务而言过于复杂，例如在 IBU 海外业务部数据，单表数据已经超过 300 亿。应用 TiDB 可以大幅提高查询性能，实现大量数据的高效存储。TiDB 的行列混存架构（ TiFlash 和 MPP 技术），使得携程部分查询性能有了20倍提升；在信息安全源数据标记数据时，单表数据也超过了 60 亿行，读写的响应时间都达到毫秒级，单天聚合查询秒级返回。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f5/f57f46dbeed5642619c995a515ccd95e.png\" /></p><p></p><p>除了使用 TiDB ，携程还在使用其存储层 TiKV。引入 TiKV 是因为携程现在的业务有一些简单的 KV 存储需求，携程在使用的产品有 Redis 和 Hbase，但是 Hbase 的性能相比于 Redis 比较差，而 Redis 则存在数据不一致的风险，比如网络抖动、中断等。携程有一些业务有强一致 KV 需求，例如近期引入的酒店取消政策项目，Redis 虽然能满足业务需求，但没有强一致性能。综合考量之后，携程选择了 TiKV 解决上述挑战。TiKV 的部署与 TiDB 类似，也是在三个机房分布部署，应用可以感知到每个机房的 PD，并且 PD 也在三个机房分别部署。该架构可以确保如果出现机房级故障，或是单 PD 故障，运维团队都可以做到平滑切换。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d3/d35147a452aafb239413ad3817e5694a.png\" /></p><p></p><p></p><h2>TiDB 在携程的全球化运用</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4a/4acc4e1dec9a9e3423313c20d640a565.png\" /></p><p></p><p></p><p>随着携程近年来开始走向海外，海外业务呈现迅猛增长趋势。携程也将国内成熟的数据库技术直接用于海外。目前，TiDB 在携程的国内和海外业务是分开部署的，海外应用复用了国内的 schema 和代码，监控告警方式也与国内保持一致，部署方式也是相同的。</p><p>&nbsp;</p><p>携程引入 TiDB 并完成了一系列内部生态整合，包括发布系统（如表结构发布、索引发布）、数据修改和查询等。由于 TiDB 和 MySQL 采用了相同的协议，整合过程相对简单平滑：</p><p>TiDB 原生支持 Prometheus + Grafana，提供了丰富的诊断数据，可以根据 TiDB 故障诊断手册快速定位问题。由于 Grafana 的数据在每个集群上单独分布，携程通过prometheus 源生remote write转发性能数据到携程统一监控平台，以便在监控平台上进行性能告警和大盘监控。</p><p>&nbsp;</p><p>目前，携程已经顺利完成从 SQL server 到 TiDB 的迁移，稳定应用于携程的国内、海外各业务场景中，借助 TiDB HTAP 能力，携程大幅提高了查询性能，实现海量数据的高效存储。</p><p>&nbsp;</p>",
    "publish_time": "2023-04-12 10:10:04",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何解决云服务海量数据挑战？ | 技术出海案例故事之vivo x TiDB",
    "url": "https://www.infoq.cn/article/zy2eQoRFqg01d8seZj48",
    "summary": "<p>vivo 是一家全球性的移动互联网智能终端公司，品牌产品包括智能手机、平板电脑、智能手表等&nbsp; ，截至 2022 年 8 月，已进驻 60 多个国家和地区，全球用户覆盖 4 亿多人。</p><p>&nbsp;</p><p>vivo 为用户提供了在手机上备份联系人、短信、便签、书签等数据的能力，底层存储采用 MySQL 数据库进行数据存储。随着 vivo 业务发展，用户量增长迅速，存储在云端的数据量越来越大，海量数据给后端存储和数据库带来了巨大的挑战。云服务业务最大的痛点，就是如何解决用户海量数据的存储问题。</p><p></p><h2>vivo 数据库与存储体系</h2><p></p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/3f/3fb3cb035893997e4e083f10c6c847c4.png\" /></p><p>vivo 数据库与存储体系产品矩阵</p><p>&nbsp;</p><p>在整个 vivo 云服务体系中，数据库与存储处于核心位置，从体系上可以分为两层，最上面一层是工具产品层，包含数据库存储统一管控平台、数据传输服务（支持数据同步、数据订阅、数据迁移等）、运维白屏化工具等。下面一层是数据库产品层，这一层又分为三个部分：一部分是 MySQL、 TiDB 等关系型数据库；一部分是 Redis、ElasticSearch、MongoDB、磁盘 KV 等非关系型数据库；还有一部分是对象存储、文件存储、块存储等存储服务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dd/dd04ef84d283e9677c3f42450d9715bf.png\" /></p><p>vivo 数据库与存储运营管理</p><p>&nbsp;</p><p>为了管理这些众多的数据库与存储产品，vivo 打造了一个数据库与存储运营管理平台，主要分为三层架构：</p><p>最底层是支撑、管理所有数据库的工具产品，包含数据存储服务、关系型数据库、NoSQL 数据库，以及生态工具； 中间是功能层，包括基础存储服务、数据管理服务，以及存储自治服务；最上面是运营层，包括权限账单、用户管理、工单服务等基础服务。同时还有一些安全相关服务，如数据脱敏、数据加密、权限管控、命令通道、数据审计等一系列功能。</p><p>&nbsp;</p><p></p><h2>TiDB 在 vivo 的落地实践</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f1/f1d7bb44cc112919fb0e445485819fba.png\" /></p><p></p><p>此前，vivo 已经用了很多年关系型数据库 MySQL。基于原生的 MySQL 数据库，vivo 结合集群高可用的管理与数据库代理的一体化架构，通过域名服务、名字服务进行接入，提供通用的关系型数据库服务。它主要具有三大核心能力：</p><p>第一，兼容 MySQL 协议与 SQL 语法；第二， 增强 MySQL 集群管控能力。vivo 引入 MySQL 的时间很早，在 MySQL 的一些集群管控能力上都有自研的能力；第三，安全增强能力，包括密码管理、数据脱敏、数据加密等能力。</p><p>&nbsp;</p><p>本质上 MySQL 架构还是一个主从架构，并没有分布式技术引入。针对数据量较大、流量较大的场景，或者分析场景，给业务带来了巨大挑战。基于以上原因，vivo 在对比了主流分布式数据后后考虑引入分布式关系型数据库TiDB，作为关系型数据库产品矩阵的一环，补充整个关系型数据库的能力。</p><p>&nbsp;</p><p>引入TiDB 帮助 vivo 解决了一些在 MySQL 生态中无法解决的问题：</p><p>TiDB 可以解决数据量过大、流量过大的问题，以及海量数据分析的场景；TiDB 兼容MySQL语法，业务迁移比较平滑；TiDB 支持水平扩展，相比传统的 MySQL 复杂的分库分表方式，TiDB 的扩展能力大大降低了运维压力；TiDB 具备数据强一致性、高可用性，可以提供金融级数据安全性。</p><p>&nbsp;</p><p>vivo 研发团队具有较强的自研能力，他们将内部所有数据库统一实现了平台化管理，这是一种提供高度自助、高度智能化、高可用、低成本的数据存储使用与管理平台，包含从数据库服务的申请、部署、维护、变更、优化，以及数据恢复、服务下线等一系列数据库全生命周期的管理。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/91/91a9bdcb428373c359a6ca166509c7a8.png\" /></p><p></p><p>在应用 TiDB 后，vivo 研发团队同样也将 TiDB 集成到该平台中，实现诸如 TiDB 的自动化部署、服务维护、数据变更、数据恢复，包括一些还在持续建设中的能力，如服务优化、服务变更。这些能力与 vivo 的全球化业务场景息息相关。全球化业务场景要求更好满足于本地客户服务，以及符合本地数据安全相关的一些管理规范。所以 vivo 的服务都是本地化部署，平台化的管理方式可以帮助运维、研发更好地支撑业务研发或者业务变更的效率。</p><p>&nbsp;</p><p>该平台一方面提升了 vivo 整个数据服务的安全性，如账号密码管控、敏感数据加密脱敏、集成的研发效能等。在业务开发团队需要一个 TiDB 服务的时候，几分钟内就能得到一款分布式数据库进行代码开发，降低了运维管理成本；运维（DBA）再也不需要登陆服务器执行各种涉钥命令；最后，平台也大大提升了数据的可用性。vivo 数据库团队将一些 TiDB 的备份恢复工具及数据库的可用性也集成在平台里。</p><p>&nbsp;</p><p></p><h2>应用场景</h2><p></p><p></p><h3>推送业务基于 TiDB 的海量数实时 OLAP 方案</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/09/093e8a21194166cd6d0f845be5d98928.png\" /></p><p></p><p>vivo 的推送业务基于 TiDB 实现了一套实时 OLAP 方案。该场景中具有千亿级别的数据指标，vivo 希望数据在数据指标写入时可以实现秒级入库。同时，该场景还要求以月度为范围秒级出报表。原方案中使用了其他 OLAP 数据库方案或 MySQL 方案，在出报表时总会给数据库集群服务造成很大压力，指标的计算性、时效性也很差。尤其当面临海量数据时，查询与指标变更成本会变得很高。引入 TiDB 后，vivo 可以从实时链路里直接把数据秒级写入，再通过 DM 工具，把关系型数据库里面维度的数据，以及其他相关联的数据都同步过来，最终在 TiDB 中进行多表关联，为最终用户提供数据服务，如 BI 报表等。在该场景中，TiDB 的高性能、低延时等特性解决了 vivo 数据量大、时效性高等难题。</p><p>&nbsp;</p><p></p><h3>云服务业务基于 TiDB 的海量元数据管理方案</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f6/f67c2c083bd798e8d4c362a3166e51d3.png\" /></p><p></p><p>vivo 云服务是 vivo 为用户提供的在手机上进行数据备份、数据恢复同步的一款服务。这款服务用到了对象存储与文件存储，同时有大量的元数据需要存储。原方案使用了 MySQL 分库分表的方式，但 MySQL 实际上还是一个单集群方案，分库分表的业务逻辑需要在业务层实现，这就需要解决复杂的业务逻辑问题。同时，分库分表造成运维十分困难，扩容成本高、扩容耗时间长。基于以上原因，vivo 基于 TiDB 实现了一套海量元数据管理方案，支撑了 vivo 百亿级别的元数据表和日志数据表存储，核心业务时延小于 50ms。</p><p>&nbsp;</p><p></p><h3>基于 TiKV 自研的 NoSQL 数据库实践</h3><p></p><p>&nbsp;</p><p>由于 TiDB 整个产品都采用开源的模式，vivo 并没有满足于只作为 TiDB 的使用者，还基于 TiDB 的底层存储引擎 TiKV 自研了一款 NoSQL 数据库，希望能够实现一个高性能的、高稳定的多数据模型的分布式数据库，用以服务内部大数据量存储场景，降低整体数据库的运营成本，同时还针对一些 AI 特殊业务场景的应用进行定制优化。</p><p>&nbsp;</p><p>在此之前，vivo 的 NoSQL 数据库产品矩阵中 KV 产品实际上只有 Redis，但 Redis 是基于内存的存储，性能虽然很好，但存在数据无法持久化及成本高等问题。基于此，vivo 基于 TiKV 研发了自己的 NoSQL 数据库。它兼容 Redis 协议，能够以很低的成本进行迁移，可以持久化大规模存储 TB 级别，甚至 PB 级别数据，还具备高性能、水平扩展、高效故障切换、数据安全保证一致性等特点。之所以能做到这些，很大程度上是因为 TiKV 原本就具备了很好的能力，如存储引擎水平扩展能力、高效故障切换能力、数据安全保证能力等。目前，这款 NoSQL 数据库已经在 vivo 内部的推荐平台、内部管理平台、应用中心中应用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d2/d2301b30b11438b566592b7421734fcd.png\" /></p><p></p><p>通过引入 TiDB ，vivo 解决了原 MySQL 架构无法应对数据量大、流量大等挑战，优秀的水平扩展能力及高可用特性支撑了 vivo 百亿级别的元数据表和日志数据表存储，核心业务时延不到 50ms 。同时，TiDB 的实时 HTAP 能力还帮助 vivo 解决了报表时效性问题。未来，vivo 还将持续在内部混合云中云化 TiDB 产品，将 TiDB 全生命周期的各个能力，在 vivo 内部云上实现出来，支持更多的业务场景。</p>",
    "publish_time": "2023-04-12 10:10:59",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何降低架构复杂性，保障全球900万用户安全可靠投资？ | 案例故事之老虎国际 x TiDB",
    "url": "https://www.infoq.cn/article/32Tldt5xzGylfBULalaF",
    "summary": "<p>券商是一个古老的行业，发展至今已经历了三个时代：第一代券商为传统券商，在线下交易大厅进行买卖；第二代券商开始了电子化进程，从线下到线上进行了浅层服务的转移，改善了用户体验，提高了金融服务的效率；第三代券商更多强调“科技赋能”，在功能业务上更创新、更多样，且存在完整的互联网基因，业务依靠线上平台，拥有底层自研能力，如交易、风控等系统。</p><p>&nbsp;</p><p>老虎国际作为第三代券商的代表，是一家全球知名的国际化券商，在新加坡、美国、中国香港、澳大利亚等地持有 59 张牌照或资质，在全球多地展业。投资者在老虎国际可通过一个账户交易美股、港股、A 股（沪港通/深港通）、星股（新加坡股）、澳股（澳大利亚股）、期货、基金等全球主要市场的金融产品，享受一流的投资体验。</p><p>&nbsp;</p><p>老虎国际自主研发的交易平台 TigerTrade，累计交易规模在三年内突破 10000 亿人民币，创下互联网券商冲击万亿交易规模最短用时。2019 年 3 月，老虎国际在美国纳斯达克挂牌上市，目前拥有全球近 900 万用户，年交易规模超 2000 亿美元。</p><p></p><h2>业务挑战</h2><p></p><p></p><p>作为一家全球化的券商，每个国家证券行业发展情况不同，数据合规要求也存在差异，比如新加坡有 PDPA，欧盟有 GDPR，美国有 CCPA 等，甚至不同国家业务特点也大为迥异。在每个国家/地区都本地部署业务系统显然并不现实，老虎国际采用跨地区的混合云架构为全球用户提供支撑，解决在数据架构、数据安全、数据合规等方面所面临的的全球挑战。</p><p>&nbsp;</p><p>同时，老虎国际的数据架构复杂度非常高，底层系统包含 Java、Python、Go 等不同的语言，中间件、数据库、大数据等都是异构场景，导致维护成本和研发效能都大打折扣。</p><p>&nbsp;</p><p>此外，在老虎国际证券业务发展过程中，业务波动性是常态，这也使得其核心业务--后台账本系统，经常面临数据库的性能挑战。后台账本是用户在老虎国际参与证券交易时，如产品购买、出入金、IPO 打新、公司行动、被收费等各个业务版块，针对用户行为明细数据记录的系统。账本每天需要记录大量的用户流水，并根据用户行为生成用户每日账单。如果账本出现问题，直接关系到用户体验和投资收入。</p><p>&nbsp;</p><p>2020 年 3 月，美股遭遇了前所未有的震荡，开盘即暴跌，触发一级熔断机制，暂停交易 15 分钟。老虎国际的数据库也经历了前所未有的数据查询量，查询数量曲线呈指数级增长，原有的 MySQL 遇到了极大瓶颈。证券交易还要求数据库具有金融级数据强一致性，并具备灾备能力，一旦某个机房宕机，另一个机房可以立刻启用。</p><p>&nbsp;</p><p>数据安全性、数据可用性和数据架构复杂度成为老虎国际国际化业务的三大挑战。出于对开源技术的信任和认同，老虎国际很早就在数据中台业务中应用了 TiDB 3.0 版本，此后一路升级到 TiDB 5.0，解决了业务挑战与数据安全挑战。</p><p>&nbsp;</p><p></p><h2>后台账本数据库迁移</h2><p></p><p>&nbsp;</p><p>老虎国际的后台账本底层数据架构由多套集群组成，单集群数据量接近 2TB，MySQL 数据库虽然具有较好的稳定性和负载能力，但为了应对不断增长的数据量只能采取分库分表方案，难以保证跨分片的事务一致性，跨库的 Join 关联查询性能较差，数据库多次扩展难度和维护量极大。2021 年，老虎国际的运维与研发团队对主流的冷热数据分离、分库分表、分布式数据库等方案进行选型与性能压测。在压测中，TiDB 在 P95 延迟、TPS 事务指标、QPS 等方面整体性能都强于 MySQL，并且 TiDB 的性能可以随着节点水平扩展线性提升，解决性能和单机资源瓶颈问题。压测增强了老虎国际技术团队的信心，最终决定将后台账本的 MySQL 集群也迁移到分布式数据库 TiDB 上。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/79/79c5b1460297704d6f5c4a4fffa3c210.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/24/24d83157d79fc1497994a85a03b30252.png\" /></p><p></p><p>由于 TiDB 拥有非常丰富的生态组件，整个迁移过程十分顺利。为了保障业务稳定，老虎国际采用了新旧数据库同时写入的方式，通过 DM 将 MySQL 数据同步至 TiDB 集群，逐渐切换一部分读流量到 TiDB，整个迁移历经近 3 个月，最终全部切换到 TiDB。同时，老虎国际也制定了“逃生方案”，通过 TiCDC 将数据同步到下游的一个 MySQL 集群，一旦发现 TiDB 有问题可以随时切换。在经过半年多业务的考验后，最终技术团队将该 MySQL 集群关闭。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a9/a9e97af3efd41aa8a3410cf82e726542.png\" /></p><p></p><p></p><p>由于不同国家对于监管、数据可用性，以及 SLA（服务级别协议）要求非常高。在同城，老虎国际还利用 TiDB 的灾备架构，通过 TiCDC 在灾备机房部署了一个 TiDB 集群作为灾备方案，当主机房发生故障时，服务器负载均衡自动切换到备用机房，保证数据服务高可用，整体延迟达到分钟级甚至更低。</p><p>&nbsp;</p><p></p><h2>为什么选择 TiDB？</h2><p></p><p>&nbsp;</p><p>对于券商而言，数据处理速度与成本是紧密相关的。MySQL 的分库分表维护成本较高，对业务的限制也比较多。而 TiDB 的分布式架构无需分库分表，大大简化技术栈，降低了运维难度，通过在线水平扩展有效解决底层数据存储扩容难题；TiDB 的金融级高可用特性，可靠的灾备、数据恢复方案保障了老虎国际证券业务稳定运行；同时，TiDB 高度兼容 MySQL，有着成熟的 MySQL 迁移方案，研发侧大部分代码无需改动，即可顺利完成整个迁移工作，大大降低迁移成本。</p><p>&nbsp;</p><p></p><h2>业务收益</h2><p></p><p>&nbsp;</p><p>现在，老虎国际的数据架构整体可以分为三部分：第一，将分布在各业务系统甚至 APP 内的数据进行收集；第二，进行数据处理；第三，将数据持久化存储。非敏感数据通过 DM 和 CDC 快速同步到 TiDB，敏感数据通过 Flink 进行脱敏后输入 TiDB，利用 TiDB HTAP 的能力构建数据中台和实时数仓，既保证 OLAP 查询时系统的稳定性，又保证 OLTP 的快速分析，两者同时存在又保证隔离，兼顾安全和稳定。最后，老虎国际还将 TiDB 作为类似数据湖的概念提供数据源给下游的 HDFS 使用，对外提供更多数据服务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/37/37c2651e509529dc6a73eb41bcf5ff52.png\" /></p><p></p><p>从前，老虎国际的数仓只能满足 T+1 的数据分析，通过 TiDB ，老虎国际实现了实时同步、实时分析，将延迟降低到了 5 秒钟；同时，TiDB 的性能实现了比较快的数据接入，之前 Hbase 中只有 4,000+ 表，TiDB 目前已经达到 80,000+ 表；此外，使用 TiDB 后，老虎国际将数据的全量同步变成增量同步，极大减少了网络带宽压力。 TiDB 统一了两个大数据分析场景，提升了易用性，并节省了 40% 的资源，实现了降本增效。</p>",
    "publish_time": "2023-04-12 10:11:53",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "成长、转型与创业，探讨技术人成长的秘诀 | ArchSummit",
    "url": "https://www.infoq.cn/article/xW8ovkePNf9U1uqqUYy2",
    "summary": "<p>好多技术同学都会有同样的困惑，特别是在中国这个环境下，技术人的发展路径有没有统一的模式，在技术上该如何提升，在管理上该如何转变？在<a href=\"https://archsummit.infoq.cn/202304/shanghai/schedule\">ArchSummit全球架构师峰会（上海站）</a>\"上，我们策划了【技术人成长】专题，本专题就围绕个人发展的技能图谱，找到属于自己的路。</p><p>&nbsp;</p><p>为了保证专题的分享质量，我们邀请了携程大住宿研发部研发总监<a href=\"https://archsummit.infoq.cn/202304/shanghai/track/1504\">顾佳璐</a>\"，担任专题出品人。在此专题下，一共有四个分享，具体如下：</p><p>&nbsp;</p><p>邹娟，阿里巴巴资深技术专家，分享主题为“在变化中抽象不变：技术变局下的架构师升级之想”。她将会分享技术变革对架构师工作的影响，抽象思维的重要性，建立思考体系，不断学习和实践等内容。听众将会了解如何建立思考体系，提升工作成绩。顾钧，EMQ开源社区运营总监，分享主题为“开发者社区运营，工程师修炼的另一条路径”。他将会分享软件业务模式变革带来的挑战与机遇，工程师如何适应软件业务模式变革带来的挑战等内容。听众将会了解进一步提升自己的可能路径。郝峻晟，晟云磐盾信息技术（上海）有限公司总裁，分享主题为“技术人如何走上创业之路，实现人生价值”。他将会分享优秀的架构师VS优秀的创业者或管理者、用云原生的架构来设计敏捷的现代组织、架构师如何成为创业者或企业管理者等内容。听众将会了解云原生的架构设计、现代化敏捷的组织。李军，千鸟集团CTO，分享主题为“技术成长的底层逻辑和N个坑”。他将会分享程序员到架构师、再到技术总监和CTO所需要掌握的技能和能力、技术人成长中容易遇到的误区等内容。听众将会了解学些架构师思维和认知方法论、了解如何把握每个阶段的技术成长机遇、思维认知与提升、快速适应晋升后的角色转变等。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c1/c171fbf3d56650bbb88c56388a7631cc.png\" /></p><p></p><p>活动推荐：</p><p>在4月21-22日，InfoQ即将在上海举办一场ArchSummit，内容涵盖人工智能前沿技术、<a href=\"https://archsummit.infoq.cn/202304/shanghai/track/1503\">AIGC应用探索</a>\"、金融业数字化转型探索、架构标准化和质量评估、大数据+架构、DataOps落地实践、ToB软件质量保障、制造业数字化转型架构创新、架构师成长、以及企业架构演进、数字化转型下的应用现代化、架构稳定性保障等专题。可扫码下方海报了解更多...</p><p><img src=\"https://static001.infoq.cn/resource/image/0e/e3/0ec0e6b9480f72d35f1495fe39ed74e3.jpg\" /></p><p></p><p></p>",
    "publish_time": "2023-04-12 12:01:18",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "“心机boy”马斯克：明面上呼吁暂停先进AI研发，背地里悄悄买1万块GPU推进大模型项目",
    "url": "https://www.infoq.cn/article/oajLcUpF45Vk3L68KDTZ",
    "summary": "<p></p><blockquote>现在来看，彼时的集体呼吁更像是一场“暗渡陈仓”的缓兵之计。</blockquote><p></p><p></p><h2>为了研发自家AIGC，马斯克狂买GPU并四处挖人</h2><p></p><p>&nbsp;</p><p>当地时间4月11日，据多家外媒报道，尽管高调建议在整个行业范围内停止AI训练，但伊隆·<a href=\"https://www.infoq.cn/article/Sktl2hsqUBygTlDGRzOI\">马斯克</a>\"本人倒是在Twitter内启动了新的重大AI项目。</p><p>&nbsp;</p><p>据Business Insider报道，Twitter公司已经采购约1万块GPU，并从DeepMind处招募到AI人才，打算开发自己的大语言模型（LLM）项目。</p><p>&nbsp;</p><p>一位知情人士表示，<a href=\"https://www.infoq.cn/article/5LYIHLWuPVU8btDrfBut\">马斯克的AI项目</a>\"仍处于初始阶段。但根据另一位消息人士的说法，采购大量算力表明他正努力推动项目发展。不过目前还不清楚Twitter这个生成式AI模型的确切用途，潜在方向可能包括改进搜索功能，或者生成针对性广告内容。</p><p>&nbsp;</p><p>Twitter具体采购了哪些硬件仍是个谜。但根据报道，尽管最近一段时间财务问题缠身，Twitter还是豪掷数千万美元购买GPU设备。这些GPU预计将被部署在Twitter剩余的两处数据中心之一内，其中亚特兰大数据中心的可能性更高。有趣的是，马斯克于去年12月下旬刚刚关闭了Twitter位于萨克拉门托的主数据中心，这显然压缩了公司掌握的算力资源。</p><p>&nbsp;</p><p>除了为生成式AI项目采购GPU硬件之外，<a href=\"https://www.infoq.cn/article/1vAhujTNDw65Wp6AOtV0\">Twitter</a>\"还在招聘更多工程师。</p><p>&nbsp;</p><p>今年早些时候，Twitter公司从Alphabet的子公司DeepMind处招募了工程师Igor Babuschkin和Manuel Kroiss。至少从2月开始，马斯克一直在积极物色AI领域的人才，希望与OpenAI的ChatGPT展开竞争。</p><p>&nbsp;</p><p>OpenAI使用英伟达的A100 GPU来训练其ChatGPT聊天机器人，并支撑其后续运行和推理。如今，英伟达已经推出了A100的后继产品，其H100 GPU能够在大致相同的功率下将性能提升几倍。Twitter在其AI项目中使用的可能正是英伟达Hopper H100或者类似硬件，但目前还没有明确证据。考虑到该公司尚未确定新AI项目的实际用途，所以也很难估计他们到底需要多少块Hopper GPU。</p><p>&nbsp;</p><p>像<a href=\"https://www.infoq.cn/article/3OOPEivwhT0gLcKP0Nwl\">Twitter</a>\"这样的巨头级企业采购硬件时，由于需求规模庞大，所以单位价格也将比较优惠。另外，如果单独从CDW等零售商处购买，目前英伟达H100的单价很可能超过1万美元。粗略估算，就能看出Twitter确实打算为自家AI项目砸下重金。</p><p></p><h2>带头呼吁暂停先进AI研发，可能只是缓兵之计</h2><p></p><p>&nbsp;</p><p>虽然马斯克购买了大量GPU试图偷偷训练自家先进AI，但在此之前，他却带头公开<a href=\"https://www.infoq.cn/article/sJSY1kx480W0StNrQHDH\">呼吁暂停研发先进AI</a>\"技术长达6个月。他和一众反对继续研发AI的业内大佬们给出的理由是：我们已经有了 GPT-4，现在应该先缓一缓，别急着搞出比它更强大的新型 AI 系统。</p><p>&nbsp;</p><p>当时，马斯克此举备受关注。因为一直以来，无论是钻研自动驾驶还是脑机接口，马斯克留给外界的印象是一位总能走在科技最前沿“钢铁侠”。公然反对更先进的 AI 的研发，不符合他的一贯作风。</p><p>&nbsp;</p><p>有媒体报道，实际上，马斯克反对的不是 AI，而是 OpenAI 和 GPT。</p><p>&nbsp;</p><p>马斯克不仅是生命未来研究所的最初发起人，也是 OpenAI 公司的联合创始人之一。但他在 2018 年离开了 OpenAI 的董事会，并撤销了一大笔赞助款。</p><p>&nbsp;</p><p>美国《财富》杂志当时报道称，离开的原因是因为马斯克虽然支持人工智能，但特斯拉智能驾驶技术与 OpenAI 之间有“潜在利益冲突”。</p><p>&nbsp;</p><p>还有报道称，马斯克在离开前提出过由他本人执掌 <a href=\"https://www.infoq.cn/article/g9tuoTODP20N1lTzjsjw\">OpenAI </a>\"运营的建议，但遭到了拒绝。这就不难理解，为什么离开 OpenAI 后，马斯克就一直将矛头对准 OpenAI 以及和它有关的一切。</p><p>&nbsp;</p><p>除了在公开场合发表言论攻击 OpenAI 外，马斯克还将手深入了 OpenAI 内部挖走他们的员工。2022 年离职的特斯拉自动驾驶主管 Andrej Kapathy 就是 OpenAI 最优秀的人才之一。</p><p>&nbsp;</p><p>有网友认为，上述举动表明，马斯克并不是真的反对更先进的 AI 技术，而是痛恨这项技术先入了别人之手，而自己只能成为旁观者。</p><p>&nbsp;</p><p>对于这次千人署名事件， 金沙江创投管理合伙人朱啸虎在朋友圈发表了自己的看法，“其实是为竞争对手争取时间，OpenAI 的迭代速度太快了。Google 的搜索比对手好 20% 就占据了 90% 的搜索市场份额。OpenAI 的影响会更广泛，所有的上层应用都希望使用优更强大 AI 赋能的云服务。更不用说微软本来就具有强大优势的前端 Office 应用。只能寄希望于 OpenAI 会像自动驾驶那样发展到某个阶段会遇到难以克服的瓶颈”。</p><p>&nbsp;</p><p>现在来看，彼时的集体呼吁更像是一场“暗渡陈仓”的闹剧，也是马斯克以及一众被OpenAI生态伙伴们甩在身后的科技巨头们的缓兵之计，毕竟签名者中就有正亲自参与 AI 模型研究和部署的人士，比如 <a href=\"https://www.infoq.cn/article/V24vD7kvHyuT3byVVObJ\">Stability AI</a>\" 的 CEO Emad Mostaque。该公司去年发布了文本到图像模型 Stable Diffusion。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p>&nbsp;</p><p><a href=\"https://www.tomshardware.com/news/elon-musk-buys-tens-of-thousands-of-gpus-for-twitter-ai-project\">https://www.tomshardware.com/news/elon-musk-buys-tens-of-thousands-of-gpus-for-twitter-ai-project</a>\"</p><p><a href=\"https://futureoflife.org/open-letter/pause-giant-ai-experiments/\">https://futureoflife.org/open-letter/pause-giant-ai-experiments/</a>\"</p><p><a href=\"https://www.reuters.com/technology/musk-experts-urge-pause-training-ai-systems-that-can-outperform-gpt-4-2023-03-29/\">https://www.reuters.com/technology/musk-experts-urge-pause-training-ai-systems-that-can-outperform-gpt-4-2023-03-29/</a>\"</p>",
    "publish_time": "2023-04-12 13:31:10",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "国产替代潮来了，这与京东云已“养成”的混合多云有什么关系？",
    "url": "https://www.infoq.cn/article/WIRXxsAV4V6HOhRivtmx",
    "summary": "<p></p><p>“目前，大众正处于数字化新纪元的开端。”比尔·盖茨曾在采访中说道，“回顾过往时，我们会把 2020 年 3 月作为一个时间拐点，从那时起，数字化发展进程开始加速。”</p><p></p><p>时至今日，<a href=\"https://www.infoq.cn/article/CUzrDiwNemwvhoVNCQ1V\">数字化</a>\"的重要性已经不需要再多做赘述，但究竟如何做、从哪里下手却是企业转型路上需要解决的首要问题。中国电子技术标准化研究院的数据显示，全国企业的数字化转型整体水平还处于初步探索阶段。虽然开始主动求变，但技术、成本等问题仍是悬在企业头上的达摩克利斯之剑，一不小心就可能做成无效转型。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/4f/4f0a07cfbf3d8c50f0fc07e1336b3d3d.png\" /></p><p></p><p>全国数字化转型整体水平，图源：<a href=\"http://www.cesi.cn/images/editor/20220505/20220505170438288.pdf\">中国电子技术标准化研究院</a>\"</p><p></p><p>在数字化转型技术栈中，有着更高效、更便捷、资源配置更弹性优势的云原生是怎么也绕不开的一个领域。云原生化实际上是云和应用在网上数据的结合，帮助企业将更多精力放在业务而非基础设施搭建上。</p><p></p><p>但是在数字化转型过程中，企业需要什么样的基础设施、云原生又需要达到什么样的能力呢？我们有幸采访了<a href=\"https://www.infoq.cn/article/S5qqTZh-u2Jpx5e2D6KB\">京东云团队</a>\"的成员来为我们解答更多关于企业数字化转型中云基础设施的系列问题。</p><p></p><p>在京东云团队看来，云是被类比为“水电煤”提出来的，那意味着企业无论用的单云还是多云、混合云，使用方式都不能复杂。而云原生化作为数字化转型的重要技术领域，必须可以促进企业基于云原生进行创新，这意味着云要没有绑定、随取随用。同时，在数字化转型过程中，IT 组织需要完成从资源消耗型组织到运营组织，甚至是数字化能力管理组织的转变。</p><p></p><h3>数字化转型，云原生需要解决什么问题</h3><p></p><p></p><p>要回答企业数字化过程中对云的需求是什么，就要先明确当前业内对云的应用情况。</p><p></p><p>云计算发展至今已有十几年的时间。最初，企业由于弹性需求而选择使用单一的公有云或私有云，但由于业务扩展、云厂商绑定严重等原因，大都逐渐演进到多云、混合云阶段。</p><p></p><p>如今，公有云、私有云和边缘云等典型云都有了各自比较明确的使用场景，比如公有云的海量弹性资源可以加速获得 AI 能力，私有云对资源控制、数据合规等要求高的金融、政企等用户来说必不可少。企业更多是将不同的云配合使用。报告显示，高达 85% 的企业使用两个或多个云平台，有 25% 的企业至少使用五个云平台。</p><p></p><p>再看云计算依赖的通用服务器市场，有 X86、ARM、RISC-V、MIPS 等多种不同指令集类型的芯片共存的现状。起初云厂商为加强自研芯片的市场化进程提出了“一云多芯”，后来在数字化转型重点国产化领域中，“一云多芯”除了解决利旧问题外，还让不同的国产化产品都能在项目中发挥其特别作用，故而被广泛应用。</p><p></p><p>因此，数字化转型下的云原生建设，更多要面临“多态、多地、多芯、多栈”的情况。</p><p></p><h4>混合多云下的基础设施需求</h4><p></p><p></p><p>但在“多云”时代，企业的数字化首先需要云上操作更丝滑、协同更高效。这就要求数字基础设施要屏蔽底层各类差异，提供多云一致的操控，同时通过数据统一管理和有效共享来解决数据烟囱问题，还要横向打通各业务应用，实现应用跨平台的统一分发和运维管理。</p><p></p><p>其次，基础设施必须是开放兼容的。当前，单一技术已无法有效解决问题，技术与技术的融合创新更能满足产业的真实需求。基础设施要开放兼容，需要向下可兼容各类异构基础设施、屏蔽多云差异、实现应用一致运行；向上可广泛接入各类行业应用，以 PaaS 方式输出各类组件，从而实现对应用资源的便捷调用。</p><p></p><p>再者，根据边际效益递减规律，随着程度加深，数字化带来的效果会日益减退，但数字化建设本身在某种程度上已经成为企业的重大成本开支项。因此，通过技术降本真正带来极致性价比、向数字化要利润，已经成为产业的重要命题。</p><p></p><p>最后，数字化进程要提升安全合规水平，面向多云环境提供整套安全解决方案，需要利用公有云的安全能力，同时配合业务场景定制安全体系，形成一体化的安全能力。其中尤为重要的是保证稳定安全的国产化替代，渐进式完成国产化的真替、真用。</p><p></p><p>针对上述问题，企业如果有自己对应的基础设施团队也可以解决，但多数业务型公司的研发资源有限，需要更多地放在支持复杂业务上，建设基础设施能力对这些企业来说并非优势，反而是附加的成本。因此，很多企业选择使用厂商提供的混合多云方案。</p><p></p><p>理论上看，混合多云可以确保企业不丧失议价权、不绑定资源消耗量，同时避免自身技术栈与云厂商深度绑定，运维上也可以减少单个服务商响应速度慢、受重视程度低等带来的影响。</p><p></p><p>但实践起来还有一些麻烦，比如很多解决方案最大的问题就是只做了多个云之间的单云资源管理，云与云之间在数据层、应用管理、运维管理等方面都缺少联动，并不能满足企业要求。</p><p></p><p>有的企业用了不同的公有云产品，但相互之间没有联系，形成了“数据烟囱”；有的企业使用的多云平台间可能有联系，但也只是做了接口实现数据层面的共享。而理想的多云是可以让企业在多个云平台之间无缝协作的。</p><p></p><p>从以应用为中心的全生命周期管理视角看，要做好混合多云需要包括以下能力：</p><p></p><p>IaaS 层，即统一的 controller，多云的 IaaS 被抽象为统一的 IaaS；云原生的技术栈，包括容器、Kubernetes、基于 Kubernetes 延伸出来的混部、GPU、HPA 等；T-PaaS 层，即所谓的技术中台，包括数据库、消息队列中间件、微服务等；应用层，也被称为 A-PaaS，主要帮助企业基于云基础设施做自己业务的代码。</p><p></p><p>另外，还需要具备其他常见的，如安全、控制台、账号权限、计量计费等功能。可以看出，混合多云是一个复杂、庞大的技术体系，想要实现真正的混合多云并不简单。面对这样的艰巨挑战，该如何解决呢？</p><p></p><h3>混合多云能力的“养成”</h3><p></p><p></p><p>毋庸置疑，混合多云能力需要大量的技术和实践积累。</p><p></p><p>从 2006 年 IBM 和谷歌联合推出云计算概念至今，云技术已经发生了多次重大演进。此前已在内部大规模使用像 Cgroups 这样容器技术的谷歌，在 2008 年将 Cgroups 合并到了 Linux 内核主干。2013 年，Docker 项目正式发布；2014 年，Kubernetes 项目也正式发布，并迅速发展成为业内的事实标准。</p><p></p><p>谷歌提出的“容器设计模式”思想也在影响国内企业在解决业务问题时的技术选型。2014 年前，京东的应用直接部署在物理机上，APP 上线准备时间过长、缺乏隔离机制、资源利用率不足、调度机制也不够灵活，物理机失效后需要花费数小时迁移应用。为解决这些问题，京东在 2013 年正式布局虚拟化技术方向并在 2014 年打造了第一代容器引擎平台 JDOS 1.0。</p><p></p><p>实际上，京东内部每一步的云原生发展，都与其本身的业务发展需求息息相关。2015 年京东 618 时，容器第一次扛大旗，业务与流量 100% 弹性计算，之后京东逐渐开始将所有业务容器化，并启动自研 JDOS 2.0。</p><p></p><p>2016 年，京东所有的核心业务均已迁至弹性云上，内部也对云资源做了统一整合，打造了京东公有云和同源同栈的私有云 JD Stack。</p><p></p><p>在譬如大促时候，京东需要快速将业务从私有云拓展到公有云。但是，私有云和京东公有的底层架构是不一样的：私有云更多地是在裸金属或者物理机裸金属上，而京东公有云大部分是虚机里面，两者在网络、存储，甚至包括某些性能都不一样。为此，京东用了半年的时间来屏蔽私有云和京东公有云间差异，这也成为后来京东混合多云操作系统云舰的雏形。</p><p></p><p>与此同时，京东业务在飞速发展。根据财报，京东 2017 年全年 GMV（网站成交额）突破万亿大关，接近 1.3 万亿元人民币；年度活跃用户数达 2.925 亿，较上年同期增长 29.1%。对应到技术层，底层需要拥有处理更加复杂资源调度的能力。另外，此前大促前各个业务主要靠新增机器来应对高峰瞬时流量，由此造成的大量服务器资源浪费也引发了内部关注。</p><p></p><p>于是，京东在 2017 年引入 Kubernetes 来重构相关技术栈，对技术进行了全面升级，同时用了大半年的时间构建了阿基米德调度系统，来负责整个京东数据中心的资源调度与驱逐。阿基米德用批处理任务进行统一填充式调度，以达到资源碎片的充分利用和资源的时空复用效果。阿基米德调度系统后来也成为云舰的核心调度系统。</p><p></p><p>当时，京东也开始了海外扩张，由于自建 IDC 成本较高，部分业务就要在一些海外云平台如谷歌云和国内友商的云平台如华为云等上面布局。各公有云在大部分情况下计算能力相差无几，但底层资源的调度却不太一样，京东业务从私有云搬到其他公有云上的改造量非常大。</p><p></p><p>京东云认为此刻已经到了适配多云的时候了。为了不被一朵云绑定，京东云便与其他主流云平台做了适配，无论业务扩展到什么地方，都可以在各个云之间迁移。该能力后来也放到了云舰上。</p><p></p><p>事实上，此前京东内部也有“好几朵”公有云、私有云，但底座不统一给业务带来了许多麻烦，于是内部开始逐渐统一云原生底座，这为云舰的诞生打下了基础，后续京东云做了更多标准化工作，并把各种混合多云能力都放到了云舰上。</p><p></p><p>国内外很多混合多云只是做资源的统一，京东云起初也是这样，但发现这没有彻底实现多云的联动性，因此思考应该在架构层面对上层应用做统一。按照这个思路，京东云在 2021 年正式推出了混合多云操作系统云舰。</p><p></p><p>在服务京东内部业务中，借助全面容器化带来的标准化以及阿基米德智能调度，云舰 2.0 能够完成超千万核资源秒级调度，实现超大规模异构基础设施资源的敏捷调度，CPU 平均使用率提升 2 倍，每年节省 IT 成本数亿元。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/fb/fb4702f7bd1ab34ae7b46ffde02e510c.png\" /></p><p></p><p></p><h4>对外开放</h4><p></p><p></p><p>2016 年，京东云正式开始对外开放商用。如前文所述，在内部混合多云已经被广泛应用后，京东云将积累了十多年的云原生技术融合到了云舰上。</p><p></p><p>一定程度上，京东云的混合多云服务集合了全集团的研发能力。京东内部有统一的底层基础设施团队，在抽象出各种标准后再由数据库、中间件等 PaaS 团队改造适配，整个过程大概涉及了两千多研发人员。那么，经过多年积累，京东云的混合多云能力究竟如何呢？</p><p></p><p>在京东云看来，现在需要给混合多云做“减法”，即企业使用混合多云时，不必关心资源到底来自哪里，当成“一朵云”来用。在内部，京东云将这一概念称为“统一云”。要做“统一云”，混合多云的开放性就非常重要，这也是数字化基础设施的要求之一。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/1b/1ba4ee3d6f288f7dc8281349db354b09.png\" /></p><p></p><p>因此，京东云基于各个平台开放出来的 OpenAPI 做了更多的风险管理和调度抽象，在 OpenCloud 层做了各家 IaaS 的统一纳管和兼容。现在，云舰可以兼容亚马逊云科技、谷歌云、腾讯云、华为云等国内外众多云厂商。</p><p></p><p>在多云之间的数据联动方面，业务应用可以在公有云、专有云、边缘云，甚至线下 IDC 的基础设施之间统一流转。虽然各家底层数据库基本是标准格式，但不同厂商的应用平台千差万别。京东云从各应用管理平台统一抽象出了应用标准，最核心的是基于 OAM（Open Application Model）标准封装统一的应用标准，并在各种基础设施场景做了适配，另外加上应用迁移、数据同步等能力，实现了用一套标准进行多云间的数据流转。</p><p></p><p>多活是云舰的重要优势。在京东云的设计里，多活承载了保障业务连续性、负载均衡、优化云成本、弹性扩展等多个功能。</p><p></p><p>多活最核心的应用场景之一就是提供业务连续性保障。京东云以用户应用为中心构建云原生容灾架构，可以帮助用户在同城或异地机房建立一套与本地生产系统相对应的应用多活系统，保障系统的高可用性。当灾难发生时，RPO 基本可以做到数据零丢失、RTO 时间则保证在两分钟以内。</p><p></p><p>云舰可以利用多活能力，将流量按照百分比或来源等分配到不同的云平台。流量入口的负载均衡器可以做基础的流量均分，更加细粒度的配置策略则由多活系统完成。用户还可根据不同云厂商的价格和优惠措施，利用多活系统随时动态调整各机房的业务流量和相应的云资源，来有效控制总体成本。</p><p></p><p>应用多活提供了全生命周期的业务架构管理，支持用户业务的跨云发布，提供了业务容灾架构的上线、演练、发布、切换等流程，并集成了数据同步、流水线编排、监控大盘等管控运维能力。另外，在京东云应用多活系统中，所有机房内的应用可同时对外提供服务。</p><p></p><p>成本是企业在数字化过程中面临的重要问题。在这个方面，京东云主要从以下三个方面进行优化：</p><p></p><p>资源成本，使用云基础设施付出的资源费用。除了用多活方式，京东云还在 IaaS 层进行资源池化、进行资源超卖，做针对离在线不同业务类型的混部等；运营成本，这是一种隐形成本，主要取决于企业是否有高效、统一的运营运维管理平台，如果没有则会增加运营、运维成本。比如没有及时解决故障带来的品牌信誉损失等。京东云为此提供了针对混合多云场景的、标准统一的运维运营平台，支持问题的快速定位、快速修复等；使用成本，即使用设施所耗费的成本，主要是在数据库、中间件这一层提供一致的产品能力及调用接口，减少开发人员适配学习成本。</p><p></p><p>在备受重视的安全方面，京东云有统一数据访问权限管理认证平台，针对不同的租户做细致的、粒度不同的权限管理，同时有全平台的审计功能，可以查找到底整个平台进行了哪些具体操作、谁有对应权限等。数据传输上则是在云舰内部、多云之间进行了全链路加密，数据的每次读写也是基于 TDE 做了加密处理。</p><p></p><p>在对外服务后，京东内部的技术能力仍然在源源不断地输出到混合多云产品上，比如 2018 年便开始做的离在线混部，到现在做 GPU 虚拟化等都会放到云舰上。与此同时，服务外部用户过程中，产品各方面的能力再次得到加强。</p><p></p><h3>如何为业务带来效益</h3><p></p><p></p><p>“用了你的混合多云，除了降本增效，还能在业务上给我带来什么价值？”现在用户越来越多地会提出这样的问题。</p><p></p><p>2020 年时候，企业的数字化更加关注技术转型。然而，如今企业增速放缓，开始更加关注降本增效、精细化管理。有些企业在数字化转型路上走了弯路，长时间的技术投入没有带来直接的产出，逐渐产生消极情绪。另外，鉴于部分企业研发能力有限，对产品不能有很好的理解，他们更加需要厂商的咨询团队、实施团队，与他们一起把路趟出来。</p><p></p><p>因此，技术转型看似性感，但如何支持业务转型变成如今企业更为看重的事情。</p><p></p><p>在京东云混合多云服务里，与业务支持紧密相关的就是 PaaS。京东云做了数据、智能等相关的 D-PaaS，低代码、研发等相关的 A—PaaS，云舰上承载更多的 T-PaaS 等。这为解决原有基础资源以及 PaaS 组件异构多样、管理复杂、无法高效利用异构资源、运维学习成本高等问题，提供了系列工具。</p><p></p><p>这里，更值得一提的是 B-PaaS。B-PaaS 是京东云在业务层面做的能力抽象。</p><p></p><p>比如，京东的业务中台藏经阁就是抽象出的数字化社会供应链体系。供应链首先是京东的优势，其次在大部分行业如农业、工业等有类似的体系，因此京东云从中抽象出共性能力，添加到了 B-PaaS 层，然后针对不同行业的差异再做个性化方案补充。而像应用架构这块需要业务和应用一起做，并长期演进。B-PaaS 的作用就是让企业的 PaaS 能力、IT 管理能力越来越丰富。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/af/af94d35ff9ba1f0ba700b4f27778d9e8.jpeg\" /></p><p></p><p>另一方面，京东云认为，企业不仅可以内部使用混合多云，更重要的是还可以借此完成 IT 能力转型，做对外的能力输出。</p><p></p><p>根据京东云的设想，这套体系未来可以变成企业自己的 PaaS 平台：用户按照需要随意在这个平台上集成各种组件，然后进一步沉淀到自己的平台上，最后自己做 IT 能力输出。</p><p></p><p>这其实也是企业的现实需要。现在已经五百多家国央企成立了自己的科技公司，这是他们技术转型的路径：一方面服务好集团内部，另一方面对外做商业化运营，逐渐变成经营中心甚至利润中心。在逐步演进到多云过程中，IT 组织也从资源消耗型组织转变成了运营组织。</p><p></p><p>目前，云舰已经融合了国内一百多家企业，这些企业可以根据业务需要灵活敏捷调配，一定程度上市场上所有的云厂商都可以是自己的资源，可以随取随用。可以看到，如今京东云的 PaaS 能力可以分为两类：一是京东自己从业务中锤炼出来的，或自研或是基于开源做增强；二是生态里融入的 PaaS，比如流程引擎既有京东云的也有生态里的。</p><p></p><p>此外，京东云也在整理 SaaS 体系的相关能力，通过与用户体系的结合来呈现京东云在服务用户数字化转型的价值。</p><p></p><h4>渐进式的国产化替代</h4><p></p><p></p><p>值得一提的是，在当前的国际背景下，国内企业正在加速从基础设施层、芯片层到软件层，进行全面的国产替代，尤其是国产化企业。</p><p></p><p>在之前国产化替代主要是从 OA 等管理系统入手，但现在的国产替代已经到了新的阶段，即从管理系统深入到了业务系统，开始影响到企业的日常运营。这种情况下，国产替代必须保持企业业务的延续性。所有的企业都是一边换轮子，一边还要保证业务高速运转。因此，渐进式国产化替用是大多数企业的选择。</p><p></p><p>整个混合多云是一个庞杂的体系，企业要允许这种复杂性的存在，允许过渡的存在。京东云看来，渐进式的国产化可以分两步走：第一步先上线混合多云操作系统；第二步是借助操作系统，对接各类国产化替代的解决方案，包括硬件、系统和应用，一旦证明方向可行，再持续增加国产化份额，逐渐完成从小规模试点验证向大规模真替真用的转变。</p><p></p><p>转型期间，企业会经历新老系统共存的阶段。比如国产化企业转型过程中就会有国产化和非国产化设备共存的时候，此时就非常需要应用多活的能力，一部分流量可以保留在原来的基础设施上，另外一部分新增流量则可以逐步切换到国产化基础设施上，以此逐步完成国产化基础设施的替换。</p><p></p><p>一般情况下，国产化企业的研发人员要更多聚焦到自己本身的业务和开发，基础设施方面可以直接迁移到适配改造后的产品上，而这些产品不只是“能用”，更要“好用”。</p><p></p><p>在<a href=\"https://xie.infoq.cn/article/c030ad11726541aeeeebb8020\">京东云看来</a>\"，在国产替换进程中，数字基础设施需要具备多云、多芯、多活的特征，即整个系统可以同时适配传统开发与国产化环境，全面兼容全球化基础设施，使用多朵云就像使用一朵云，应用在多朵云之间灵活调度。</p><p></p><p>为此，京东云从底层 CPU 架构、X86 及 ARM 架构，到国产化操作系统，再到各个云产品都做了适配改造，现在已经基本改造完成。京东还以全栈国产化云的方式，在京东集团零售、物流、金融、健康、工业等业务板块的上百个应用中进行试点，结果高达 80% 的应用在国产化基础设施上稳定运行。</p><p></p><p>目前，京东云已构建起全面适配国产化应用的全栈产品矩阵，包括混合多云操作系统云舰、云原生理念自主研发的新一代分布式存储系统云海、自研软硬一体虚拟化引擎京刚、旗舰级国产芯片双路机架式服务器天枢、国产分布式数据库 Star DB 等，并且已经被外部用户使用，切实解决了他们数字化过程中亟待解决的问题。</p><p></p><p>比如，我国五大国有独资发电集团之一、全球最大的光伏发电企业国家电力投资集团（简称“国电投”），由于规模庞大，存在管理复杂、迁徙困难、上线缓慢、安全薄弱等技术难点。比如随着越来越多的业务上云，汇集大量产业链信息和数据资源，亟需打通资源并进行统一管理，还要解决数据安全问题。</p><p></p><p>为解决上述问题，国电投选择借助云舰的统一底座能力，对当前异构环境和未来电投云的异构迁移做了屏蔽，通过统一 PaaS 组件和应用实现了更广泛兼容及高可用，极大降低后期的管理和运维成本的同时，也为后续迁移到电投云打下了基础。</p><p></p><p>此外，面对像爱回收这样面临微服务规模依赖关系复杂、用户基数大而对业务连续性和容灾要求高、跨云迁移要兼顾交易数据和业务数据一致等需求的客户，京东云可以帮助其完成公共基础服务多活部署、上层应用分批次完成平滑迁移等的实现。</p><p></p><p>需要明确的是，企业现在“用云”阶段还是存在差异的。企业决策部门首先要做好战略选择，明确混合多云是否符合当前的需求。如果战略不清晰，后续落地就会有很多问题。战略明确后，企业才好继续明确落地路径、解决具体问题。</p><p></p><h3>结束语</h3><p></p><p></p><p>现在，数字化已经从单个企业行为转变为成产业性、地域性的发展要求，在这个浪潮里没有人会愿意掉队。但这必定也是一次缓慢、长期的变革。</p><p></p><p>对于企业来说，经历一段时间的阵痛不可避免。比如，前期对混合多云的理解不到位，仅当作基础设施对待，而对此带来的云化理念、IT 转型等影响没有做好准备，后期必定会出现问题，而这种理念的改变需要更多的实践和时间。</p><p></p><p>另一方面，对于云厂商来说，数字化带来的巨量需求既是机遇也是挑战。虽然需求市场很大，但面对各色企业落地中多种多样且无法预设的需求，云厂商需要不断加速自身技术能力的迭代来快速满足企业需要。要知道，这并不容易。用户需要某一个能力的背后，云厂商无法直接做解耦轻量化输，必须考虑到周边几十个能力的联动。</p><p></p><p>但数字化不仅仅是技术变革，背后更是一整套组织文化、流程的大更迭。因此，云厂商还需要将各种服务经验形成系统性的解决方案，来缓解企业在转型中的焦虑，帮助企业用有限的成本获得更多的收益。</p><p></p><p>云厂商要用混合多云做好数字化助力，现在可能只是开始，未来还有很长的路要走。</p><p></p><p>采访嘉宾：</p><p></p><p>贺皓，京东云混合多云产品负责人</p><p>张金柱，京东云混合多云研发负责人</p><p>周光，京东云云原生总架构师</p><p>何小锋，京东云混合多云首席架构师</p><p>张志君，京东云通用解决方案负责人</p><p></p><p></p>",
    "publish_time": "2023-04-12 14:47:38",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "锚定数据处理几大痛点，企业如何利用数据云平台释放数据全部价值？",
    "url": "https://www.infoq.cn/article/CishxTBMTqUf6YIm7Zvd",
    "summary": "<p>2020年4月9日，国务院发布的《关于构建更加完善的要素市场化配置体制机制的意见》将数据定义为继土地、劳动力、资本、技术之后的第五大生产要素。数据对于社会生产的重要性被提到了前所未有的高度。</p><p></p><p>随着社会各行业的<a href=\"https://www.infoq.cn/article/C0P2bZbE1IVrCkTZvGWi\">数智化转型</a>\"步入深水区，更多企业希望利用数据驱动业务增长，他们在管理其数据分析工作负载的膨胀规模和复杂性方面面临重大挑战。在许多大企业中，拥有几十个分析应用程序并不罕见，这些应用每年产生的查询总量超过数几十甚至上百亿个，数据孤岛和传统分析架构的局限性让数据驱动业务增长变得更加困难。更令人痛心的事实是，这些应用产生的<a href=\"https://www.infoq.cn/article/7tUgzVmJedYMB1H15mAe\">海量数据</a>\"大部分都被浪费掉了，并没有真正服务于生产中。</p><p></p><p>所幸，新兴的数据云提供了解决方案。数字化创新者正在构建数据云来消除数据碎片化并充分利用数据的全部潜力。</p><p></p><p>那么，数据云技术到底在数据处理方面有着怎样的优势？为什么数据云的概念在近几年备受关注？这项技术目前的落地情况如何？数据云领域有哪些前沿技术值得我们关注？近期，InfoQ 采访了Kyligence 合伙人兼副总裁李栋，以期进一步了解数据云技术特性以及应⽤实践。</p><p></p><p></p><blockquote>InfoQ：很高兴您能接受我们的采访，能先向读者简单介绍下您自己吗？（包括您目前负责的工作，过往经历等）您最近在关注哪些技术？</blockquote><p></p><p></p><p>李栋：我是Kyligence 合伙人兼副总裁李栋，目前负责全球市场与增长工作，曾负责过 Kyligence Enterprise、Kyligence Zen 产品线规划、设计和管理工作。也是 Apache Kylin PMC Member和Committer。我最近关注的技术有：<a href=\"https://archsummit.infoq.cn/2023/shanghai/track/1506\">数据分析</a>\"应用、数据平台架构等领域技术，以及最近很火的以 <a href=\"https://archsummit.infoq.cn/2023/shanghai/track/1506\">ChatGPT </a>\"为代表的<a href=\"https://archsummit.infoq.cn/2023/shanghai/track/1503\"> AIGC 技术</a>\"。</p><p></p><p></p><h2>处理数据的方式在不断演进</h2><p></p><p></p><p></p><blockquote>InfoQ：伴随着5G、AI等技术的发展，数据呈现海量爆炸式增长。处理数据的方式也和以往大不相同，据您观察，最近几年处理数据的方式都发生了哪些变革？</blockquote><p></p><p></p><p>李栋：首先，随着云计算、移动互联网等技术的成熟应用，数据的存储与管理模式从传统的集中式管理改变为天然的分布存储。例如数据安全法要求数据不能出国界，或者企业<a href=\"https://archsummit.infoq.cn/2023/shanghai/track/1496\"> IT 架构</a>\"本身是多云的，这导致数据难以像以前一样存储到一个单一的数据仓库，也就是说，林立的数据孤岛成为一种常态。</p><p></p><p>其次，数据的消费者从少数决策者和专家，转变为一线业务人员和普通工作者。以前提数据分析往往是做决策支持（DSS），帮助老板做好决策。而现在企业数字化转型提出了数据平民化的要求，需要人人都能基于数据开展日常经营决策，管理者也需要通过 KPI 和 OKR 等对日常工作成果进行量化管理，这都给每个公司员工提出了使用数据的要求。</p><p></p><p>再有，数据的消费方式从“为已知问题找答案”，转变为“通过智能推荐提供对未知问题的预先洞察”。在 ChatGPT 引领的 <a href=\"https://archsummit.infoq.cn/2023/shanghai/track/1503\">AIGC</a>\" 时代，AI 会帮助人产生很多难以预估的新内容。在数据行业也是一样，Gartner 早在数年前就提出了增强分析的概念，利用AI技术，数据分析将帮助人从中发现洞察，并推荐给人。</p><p></p><p></p><blockquote>InfoQ：在这些变革中，您是否认为数据云是众多趋势之一？</blockquote><p></p><p></p><p>李栋：我认为数据云是趋势。Kyligence 在 2021 年就提出了智能数据云的概念，因为我们认为企业未来使用数据，应该像今天使用云计算资源一样简单、方便。数据云正好迎合前面我介绍的三大趋势的技术形态。首先，数据云能够统一管理这些天然分布的数据，并提供统一的管理和治理平台体系；其次，数据云像水电煤一样，把数据这一只有计算机专业人才才能使用的资源，转变为普通业务人员也可以使用的资产，更好地实现数据平民化；再有，<a href=\"https://www.infoq.cn/article/g3b6cP4A5so7c058yJ9b\">数据云</a>\"融合 AI 技术，结合统一管理的数据平台，能够为用户提供更有价值、更准确的洞察推荐和行动决策。</p><p></p><p></p><blockquote>InfoQ：目前业内对于数据云的定义众说纷纭，您对数据云定义是什么？</blockquote><p></p><p></p><p>李栋：谈到云，往往想到水电煤。而数据云，实质就是数据的水电煤。但这是一种比较虚的概念，在 Kyligence 这里，我们经过和众多企业客户的合作探索发现，指标平台是数据云落地的最佳形态。为什么呢？因为数据本身作为一种技术资源，是不能被业务用户直接使用的，往往需要懂 Hadoop、Spark、BI 等专业技术的人才能使用。但是，指标是一种通用的数据语言，既可以体现出数据技术的业务价值，又可以被业务人员理解。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/81/814e0c7ece02ccc753c731f883899eaf.png\" /></p><p></p><p>指标平台提供统一的指标定义、管理、计算和存储，屏蔽底层的数据仓库、数据湖等技术语言，面向业务用户提供统一的业务语义层和指标口径，任何一个一线员工都可以从指标平台中获取自己感兴趣的指标数据，并驱动自己的日常工作。因此我说，指标平台是数据云的最佳落地形态。</p><p></p><p></p><blockquote>InfoQ：它与数据中台有着怎样的区别？</blockquote><p></p><p></p><p>李栋：指标平台和数据平台的区别，从名字上即可看出，数据要加工成指标才能被业务用户广泛使用，因此指标平台更贴近业务，更符合“数据的水电煤”的数据云的概念。</p><p></p><p></p><h2>数据云能解决哪些问题？</h2><p></p><p></p><p></p><blockquote>InfoQ：目前数据孤岛和数据不一致问题是数据处理方面两大棘手的问题，那么，数据云能否解决这两大问题？</blockquote><p></p><p></p><p>李栋：<a href=\"https://archsummit.infoq.cn/2023/shanghai/track/1523\">数据孤岛</a>\"和数据不一致的问题可以被数据云妥善解决。按照我前面介绍，指标平台是数据云的最佳落地形态，我来解释一下如何通过指标平台来解决这两大问题。</p><p></p><p>数据孤岛的问题，我在介绍趋势时提到，数据孤岛是天然存在的，我们不能通过把这些孤岛全部导入到一个统一数据仓库里来解决，因为这只会产生一个新的孤岛。我们认为，数据的管理方式要从 Collect 转换到 Connect，也就是说要通过连接的方式，对分散存储的数据进行统一管理，并对外提供统一服务。通过指标平台，虽然数据存储在不同的引擎，但业务指标是统一定义和管理在一个体系和平台中，业务用户使用数据时，只需要在平台中寻找正确的指标，无需关心底层数据存储在哪个平台或哪朵云上。</p><p></p><p>导致数据不一致的原因有很多，抛开数据本身的质量问题不讲，在业务应用方面最常见的是数据口径不一致，举个例子，企业在统计不同省份销售收入时因为计算逻辑不同，最后极有可能导致所有省份的数值加一起和总部计算的全国销售收入数值不相等，这就是指标管理问题。再或者，业务和财务对订单收入的指标理解经常是不同的，这是口径管理问题。指标平台提供统一的指标目录能力，能够在同一个数据逻辑中管理不同口径的指标，并对衍生指标、复合指标、相关指标等进行体系化管理，避免因为口径管理混乱导致<a href=\"https://www.infoq.cn/article/iMOykLN1KExO6lt2xHs8\">数据</a>\"不一致的问题。</p><p></p><p></p><blockquote>InfoQ：除以上两大问题之外，数据云还能解决数据处理的哪些问题？</blockquote><p></p><p></p><p>李栋：第一，是业务自主用数的问题。以前，业务想要进行数据探索是很难的，因为必需要先提需求给 IT，然后 IT 开发报表，这不仅效率低下、时间冗长，还限制了业务用户自主创新和探索数据的空间。在数据云上，业务用户不仅可以快速寻找所需要的指标，还可以基于平台中现有的原子指标定义符合自己业务的衍生指标，无需依赖 IT，实现业务用数的快速闭环，给业务用户提供更大的创新空间。</p><p></p><p>第二，帮助 IT 团队展现业务价值。以前，IT 团队为了支撑业务，只能不断开发和交付报表，所管理的都是表、ETL 任务、机器资源，是纯粹的成本中心。在数据云上，IT 团队管理的是指标平台中由业务定义的指标，这些指标都是极具业务价值的数据资产，IT 团队不仅可以轻松地从指标热度和用量来判断数据和自己工作的价值，还可以创新地对业务用户进行指标推荐，用平台角度对业务用户进行指导和赋能，这是从成本中心向业务中心的一个转换。下图就是一个比较形象的说明。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cf/cf3be49bc7dd8bee6af465141674b022.png\" /></p><p></p><p></p><h2>数据安全问题怎么解决？</h2><p></p><p></p><p></p><blockquote>InfoQ：如今数据安全问题也被提到了前所未有的高度，那么数据云是如何解决数据安全这一问题的？</blockquote><p></p><p></p><p>李栋：首先，数据云是架构在成熟的 IaaS 层之上的应用技术，无论是<a href=\"https://www.infoq.cn/article/htF4Xkcj3YqTbBqPN2O1\">公有云还是私有云</a>\"，数据云在数据存储、数据传输方面都是直接利用 IaaS 层的数据安全措施。</p><p></p><p>其次，在数据云中进行指标管理时，可以支持对指标的权限管理，以保证不同业务团队只能访问自己有权访问的指标。与此同时，业务用户只能访问指标，不能访问底层的原始数据，这也为数据安全提供了一层坚实的屏障。</p><p></p><p>再次，数据云提供指标 API，供下游用户轻松获取所需数据，而不是像传统方式导出明细数据供下游二次加工，从而避免因为数据导出产生的数据泄露问题。</p><p></p><p></p><h2>数据云的落地场景及技术趋势</h2><p></p><p></p><p></p><blockquote>InfoQ：数据云领域有哪些前沿技术值得我们关注？数据云又会运用到哪些基础设施来为其提供支撑？</blockquote><p></p><p></p><p>李栋：前面我提到的指标平台是值得关注的技术之一。除此之外，我认为还有低代码、增强分析、AIGC 等技术值得关注，因为这些都是在帮助企业使用数据、开发数据应用提高效率的技术。</p><p></p><p>数据云不仅会运用云原生容器化技术、大数据分布式技术，也会运用到我提到的这几项技术。通过低代码，业务用户和数据分析师可以通过更低的学习门槛，来创建和使用指标，以及把自己的洞察信息分享给他人，开展数据协作。通过增强分析和 AIGC，AI 可以为业务用户提供更多推荐，辅助业务用户快速找到最有价值的数据。</p><p></p><p></p><h5>InfoQ：您能介绍下，目前，数据云发展到什么阶段了？它的落地情况如何了？</h5><p></p><p></p><p>李栋：在 <a href=\"https://www.infoq.cn/article/AugPNHNf201DVzLGSXkU\">Kyligence</a>\"，数据云不再是一个概念，而是经过多家大型金融、零售、制造等企业验证和落地的通用架构——指标平台，例如平安银行，通过搭建潘多拉指标平台把数据开发周期平均缩短3到5天，开发人力成本缩减30%。此外，Kyligence 也发布了一站式指标平台 Kyligence Zen（SaaS 版），帮助包含零售、制造、SaaS 等企业快速获取数据云的能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/76/76edbc3ee0c539e415cb049dfcfa3303.png\" /></p><p></p><p>Kyligence Zen 产品架构图</p><p></p><h5>InfoQ：您能聊一聊数据云的部署相关问题吗？数据云的部署成本高不高？运维难易程度如何？</h5><p></p><p></p><p>李栋：根据不同的企业规模和行业属性，通常建议选择不同的部署形式：</p><p>对于金融、能源、电信等企业，以私有化部署或私有云架构为主，可以通过容器化形式部署，因为数据处理需要弹性的资源，通过容器化技术可以提供弹性可扩展的计算资源；对于零售、互联网、制造等行业的头部企业，尤其是跨国企业，通常使用公有云技术，可以在公有云上部署数据云平台，通过存储与计算分离的特性，能够极大提高资源的利用率，从而优化 IT 成本；对于高速增长型的企业，或初创企业，对数据敏捷性要求更高，可以直接使用 SaaS 产品，既能减少运维方面的人力投入，并按实际用量计费，节约 IT 成本，还能够省去 IT 基础建设的过程，加快平台落地的进程；</p><p></p><p></p><h5>InfoQ：您认为什么样的企业更适合部署数据云？在部署数据云时应注意哪些问题？</h5><p></p><p></p><p>李栋：只要是数据驱动型企业，都适合部署数据云平台，也就是指标平台，只是部署形式不同，具体可以参考上述建议。</p><p></p><p></p><h5>InfoQ：企业在面临数据云技术选型时，应该考虑哪些因素，应该选择什么样是数据云服务？</h5><p></p><p></p><p>李栋：企业做数据云技术选型时，应该考虑的维度包括：业务友好、易于治理、开发方便、成本最优。\n\n指标平台是最佳的数据云服务，主要有以下几点原因：</p><p></p><p>业务友好：指标平台以指标为核心概念，指标是业务和技术都能理解的共同语言，对业务用户十分友好，业务用户不仅可以方便的查找指标并进行查看，还可以自助定义衍生指标，实现创新性的数据探索；易于治理：指标平台以指标为治理单元，通过指标名称、标签等对指标进行分级分类，管理数据资产，以及通过指标评估和发布审核，实现对数据的治理以及 ROI 评估。除此之外，IT 可以以指标为抓手，对数据的价值进行评估，展现数据的业务价值，从管理成本转变为管理数据资产；开发方便：指标平台提供低代码的指标开发流程，无论是 IT 团队还是业务用户，都可以像写 Excel 公式一样，自行定义不同层级的业务指标，大幅缩短数据应用开发的时间；成本最优：因为 Kyligence 是由 Apache Kylin 创始团队创建，因在大数据 OLAP 引擎领域的深厚技术积累，能够以更少的 IaaS 资源支撑更高并发访问和更大数据量，从而把成本优化到最低。除此之外，通过指标平台 SaaS 服务的部署形式，也能帮助企业节省运维开销。</p>",
    "publish_time": "2023-04-12 15:09:40",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "自动驾驶生成式大模型DriveGPT来了：基于4000万公里量产车驾驶数据训练，参数规模1200亿",
    "url": "https://www.infoq.cn/article/VGUtm2FRjkYtOZzqfehi",
    "summary": "<p>4月11日，InfoQ获悉，自动驾驶创企毫末智行发布了业内首个自动驾驶生成式大模型DriveGPT，中文名“雪湖·海若”。</p><p></p><p></p><h3>自动驾驶生成式大模型DriveGPT雪湖·海若</h3><p></p><p></p><p>自动驾驶生成式大模型DriveGPT雪湖·海若，有望成为大模型技术落地自动驾驶新范式。</p><p></p><p>毫末智行CEO顾维灏介绍了雪湖·海若名字的来源：“‘海若’出自《庄子·秋水》，里面有两个神话人物河伯和北海若。河伯请教北海若，何谓大小之分，北海若教导，不因天地而觉大，不因毫末而觉小。毫末雪湖·海若，寓意智慧包容、海纳百川，为行业发展贡献力量。”</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0a/0a6406ef1edc468fcd9a22adaef39d7c.png\" /></p><p></p><p>毫末DriveGPT雪湖·海若通过引入驾驶数据建立RLHF（人类反馈强化学习）技术，对自动驾驶认知决策模型进行持续优化。它的最终目标是实现端到端自动驾驶，现阶段主要用于解决自动驾驶的认知决策问题，后续持续会将毫末多个大模型的能力整合到DriveGPT。</p><p></p><p>目前，毫末DriveGPT雪湖·海若实现了模型架构与参数规模的升级，参数规模达到1200亿，预训练阶段引入4000万公里量产车驾驶数据，RLHF阶段引入 5万段人工精选的困难场景接管Clips。</p><p></p><p>DriveGPT雪湖·海若的底层模型采用GPT（Generative Pre-trained Transformer）生成式预训练大模型，与ChatGPT使用自然语言进行输入与输出不同，DriveGPT输入是感知融合后的文本序列，输出是自动驾驶场景文本序列，即将自动驾驶场景Token化，形成“Drive Language”，最终完成自车的决策规控、障碍物预测以及决策逻辑链的输出等任务。（DriveGPT雪湖·海若）DriveGPT雪湖·海若的实现过程是，首先在预训练阶段通过引入量产驾驶数据，训练初始模型，再通过引入驾驶接管Clips数据完成反馈模型（Reward Model）的训练，然后再通过强化学习的方式，使用反馈模型去不断优化迭代初始模型，形成对自动驾驶认知决策模型的持续优化。同时，DriveGPT雪湖·海若还会根据输入端的提示语以及毫末CSS自动驾驶场景库的决策样本去训练模型，让模型学习推理关系，从而将完整驾驶策略拆分为自动驾驶场景的动态识别过程，完成可理解、可解释的推理逻辑链生成。</p><p></p><p>在应用方面，DriveGPT雪湖·海若的首发车型是新摩卡DHT-PHEV，即将量产上市。顾维灏提到，DriveGPT雪湖·海若可以逐步应用到城市NOH、捷径推荐、智能陪练以及脱困场景中。有了DriveGPT雪湖·海若的加持，车辆行驶会更安全；动作更人性、更丝滑，并有合理的逻辑告诉驾驶者，车辆为何选择这样的决策动作。对于普通用户来说，车辆越来越像老司机，用户对智能产品的信任感会更强，理解到车辆的行为都是可预期、可理解的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4a/4a47ae0e05f178cf0b905c65154468eb.png\" /></p><p></p><p></p><p>目前，毫末DriveGPT雪湖·海若已正式对外开放，开启对限量首批客户的合作，北京交通大学计算机与信息技术学院、高通、火山引擎、华为云、京东科技、四维图新、魏牌新能源、英特尔等已经加入。毫末DriveGPT的对外开放及服务，将促进自动驾驶的从业者和研究机构快速构建基础能力。</p><p></p><p>毫末DriveGPT雪湖·海若将率先探索四大应用能力，包括智能驾驶、驾驶场景识别、驾驶行为验证、困难场景脱困。当前，毫末在使用数据过程中，逐步建立起一套基于4D Clips驾驶场景识别方案，具备极高性价比。在行业上，给出正确的标注结果，一张图片需要约5元；如果使用DriveGPT雪湖·海若的场景识别服务，一张图片的价格将下降到0.5元。单帧图片整体标注成本仅相当于行业的1/10。接下来，毫末会将图像帧及4D Clips场景识别服务逐步向行业开放使用，这将大幅降低行业使用数据的成本，提高数据质量，从而加速自动驾驶技术的快速发展。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/60/6043ed4a3ae6b6034e6c36deb10135be.png\" /></p><p></p><p>大模型研发离不开庞大的算力支撑。</p><p></p><p>顾维灏介绍，毫末在2023年1月发布的中国自动驾驶行业最大的智算中心MANA OASIS（雪湖· 绿洲）此次从算力优化等层面升级了三大能力，进一步支持DriveGPT雪湖·海若的算力。首先，毫末与火山引擎全新搭建了“全套大模型训练保障框架”，实现了异常任务分钟级捕获和恢复能力，可以保证千卡任务连续训练数个月没有任何非正常中断,有效保证了大模型训练稳定性；其次，毫末研发出以真实数据回传为核心的增量学习技术，并将其推广到了大模型训练，构建了一个大模型持续学习系统，自主研发任务级弹性伸缩调度器，分钟级调度资源，集群计算资源利用率达到95%；最后，MANA OASIS通过提升数据吞吐量来降本增效，满足Transformer大模型训练效率，通过引入火山引擎提供的Lego算子库实现算子融合，端到端吞吐提升84%。</p><p></p><p>毫末打造的自动驾驶数据智能体系MANA，在经过一年多的应用迭代后，也迎来了全面的升级，正式开放赋能。顾维灏介绍，MANA计算基础服务针对大模型训练在参数规模、稳定性和效率方面做了专项优化，并集成到OASIS中；其次，MANA感知和认知相关大模型能力统一整合到DriveGPT雪湖·海若中；第三，增加了使用NeRF技术的数据合成服务，降低Corner Case数据的获取成本；同时针对多种芯片和多种车型的快速交付难题优化了异构部署工具和车型适配工具。</p>",
    "publish_time": "2023-04-12 15:12:07",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Rust 基金会拟严格限制 Rust 商标使用，数百个项目将受影响，社区抱怨不断",
    "url": "https://www.infoq.cn/article/rJzSoNk3t5aNHccTa9Hh",
    "summary": "<p>拥有 Rust 和 Cargo商标的 Rust 基金会正在制定新的商标政策，这可能会对广泛的Rust社区产生严重影响，因为该基金会限制包括禁止在 Rust 相关工具或用 Rust 编写的软件的名字中使用Rust，甚至在域名或子域名的部分也禁止使用 Rust。</p><p>&nbsp;</p><p>4 月7日，Rust 基金会发布了新政策草案，并通过<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSdaM4pdWFsLJ8GHIUFIhepuq0lfTg_b0mJ-hvwPdHa4UTRaAg/viewform\">谷歌文档</a>\"征求意见，截止日期为 4 月 16日。使用文档方式意味着评论不公开可见，但 Rust 开发人员在 Twitter、Reddit 和 Discord 等平台上表达了他们的担忧。</p><p>&nbsp;</p><p>有开发者认为，这项政策会影响社区将如何推广语言和发展，“这就像添加了不必要的繁文缛节。”</p><p>&nbsp;</p><p>“除了限制正常的社区活动外，我看不出这些规则中的大多数有什么作用，”&nbsp;Reddit 上的一位开发人员说，而在 Twitter 上对基金会的<a href=\"https://twitter.com/themann/status/1645617833622278146\">评论</a>\"是：“真的希望基金会能听取社区的意见并放弃它那令人震惊的政策。这将损害社区的良好意愿和 Rust 语言的发展。”</p><p>&nbsp;</p><p>从 2022 年 8 月的商标政策审查调查开始，该基金会一致致力于修订商标政策。根据今年 <a href=\"https://foundation.rust-lang.org/static/minutes/2023-02-14-minutes.pdf\">2 月份的董事会会议记录</a>\"指出：“董事会审查了商标政策的当前最终草案，并认为它被广泛接受”，尽管其中一条款指出，将商标用于以 Rust 语言编写的软件程序是一种侵权行为，“似乎无意中变得严格”，并向法律顾问寻求澄清。</p><p>&nbsp;</p><p>政策草案和常见问题解答已发布：</p><p><a href=\"https://docs.google.com/document/d/1ErZlwz9bbSI43dNo-rgQdkovm2h5ycuW220mWSOAuok/edit\">https://docs.google.com/document/d/1ErZlwz9bbSI43dNo-rgQdkovm2h5ycuW220mWSOAuok/edit</a>\"</p><p>&nbsp;</p><p>商标被定义为“文字标记”Rust、Cargo 和 Clippy、Rust 徽标以及“我们网站和包装的独特样式”。Clippy 这个词指的是 Rust linting 工具，不要与微软的 Office 助手混淆。草案的第 4.3.1 条规定：在 Rust 工具链中使用的工具名称中使用商标，用 Rust 语言编写的软件程序，或与 Rust 软件兼容的软件程序，很可能需要许可证，但可以改用“RS”缩写。</p><p>&nbsp;</p><p>有网友称，第 4.3.1 条规定“完全不符合现实”，“这将对 intellij-rust、rust-rocksdb、Steven Fackler 的 openssl-rust 和 rust-postgres、rust-libp2p、Stepan Koltsov 的 rust-protobuf 以及可能数十个受人尊敬的项目造成严重的影响，更不用说其他数百个较小的项目了。”</p><p>&nbsp;</p><p>在草案中，未经特别许可被视为侵权的其他商标使用行为包括活动和会议、域名和子域。</p><p>&nbsp;</p><p>关于“Logo使用”的第 7.2.2 条规定“您不得更改任何Logo，除非对其进行缩放。这意味着您不能添加装饰元素、更改颜色、更改比例、扭曲它、添加元素或将其与其他徽标组合，”尽管基金会允许使用黑白或灰度版本。</p><p>&nbsp;</p><p>为了回应对新草案的大量负面消息，基金会<a href=\"https://twitter.com/rust_foundation/status/1645578831653371905\">在 Twitter 上表示</a>\"，“Rust 基金会团队正在查看所有反馈，并将在 4 月 17 日星期一——表格关闭 1 天后提供后续的更新计划。”&nbsp;</p><p>&nbsp;</p><p>现有实行<a href=\"https://foundation.rust-lang.org/policies/logo-policy-and-media-guide/#the-rust-trademarks\">的商标政策</a>\"限制较少，规定“Rust 和 Cargo 文字商标可以在最低限度的情况下用于指代 Rust 编程语言和 Cargo 包管理器和注册表”，前提是它不会引起混淆或看起来表明官方认可，并承认“由于这条规则是关于管理感知的，因此它是主观的，并且有些难以具体确定。”</p><p>&nbsp;</p><p>根据OpenUK 首席执行官 Amanda Brock 透露，“基金会聘请了美国律师Pam Chesteck 来一起制定政策草案，她是我书中开源和商标章节的作者，被公认为是商标方面的领军人物。目前这还是一个咨询阶段的文件，最终共享的文件可能会非常不同。”</p><p>&nbsp;</p><p>根据 Brock 的说法，“这种加强政策的必要性对我们所有开源人员都是一个教训——任何希望建立开源项目或业务的人。商标是有意不被开源许可所涵盖的，在某些情况下，商标是从许可中剥离出来的。商标的目的是保护原来的品牌，并通过使用来创造事实上的“认证”。我们已经看到了许多未能充分保护商标的例子——例如 Open Source Initiative 没有在足够早的时候标记“开源”一词以获得商标。如果他们这么做了，很多争论就可以避免了。”</p><p>&nbsp;</p><p></p><p>参考链接：</p><p>https://devclass.com/2023/04/11/dont-call-it-rust-community-complains-about-draft-trademark-policy-restricting-use-of-word-marks/?td=rt-3a</p>",
    "publish_time": "2023-04-12 16:11:21",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "数据库内核杂谈（三十）- 大数据时代的存储格式-Parquet",
    "url": "https://www.infoq.cn/article/TSp7PGHp8dCbhsDhAxDS",
    "summary": "<p>欢迎阅读新一期的数据库内核杂谈。在内核杂谈的第二期（<a href=\"https://www.infoq.cn/article/1fj6JjM6xBjOqgyGtll5\">存储演化论</a>\"）里，我们介绍过数据库如何存储数据文件。对于OLTP类型的数据库，通常使用row-based storage（行式存储）的格式来存储数据，而在大数据系统里，通常会选用columnar-based storage（列式存储）来存储数据。这一期杂谈，我们介绍为大数据而生的，最广泛被使用的存储格式parquet（<a href=\"https://parquet.apache.org/\">https://parquet.apache.org/</a>\"）。</p><p>&nbsp;</p><p></p><h1>简介</h1><p></p><p></p><p>Parquet 是一种专为大数据处理系统优化的列式存储文件格式。它由 Twitter 和 Cloudera 两个在大数据生态系统中具有影响力的公司（曾经）于 2013 年共同创建。目标是开发一种高效，高性能的列式存储格式，并且能够与各种数据处理系统兼容。Parquet 从一开始就被设计为开源项目，后来被 Apache 软件基金会采纳为顶级项目。它的开发受到 Apache Parquet 社区的积极推动。自推出以来，Parquet 在大数据社区中广受欢迎。如今，Parquet已经被诸如Apache Spark、Apache Hive、Apache Flink和Presto等各种大数据处理框架广泛采用，甚至作为默认的文件格式，并在数据湖架构中被广泛使用。</p><p>&nbsp;</p><p>与传统的基于行存储的格式（如CSV和JSON）相比，Parquet文件格式具有一系列优势：通过以列式格式存储数据，Parquet可以提高查询性能，尤其是对涉及汇总或过滤大量数据的分析工作负载。此外，Parquet的先进压缩和编码技术有助于降低存储成本，同时保持高读写性能。</p><p>与传统的基于行存储的格式（如CSV和JSON）相比，Parquet文件格式具有以下优势：1.可以提高查询性能，尤其是对涉及汇总或过滤大量数据的分析工作负载。2.有助于降低存储成本，由于Parquet具有先进的压缩和编码技术，所以在降低存储成本的同时还能保持高读写的性能。</p><p>&nbsp;</p><p></p><h1>关键特性</h1><p></p><p></p><p>是哪些特性让Parquet成为大数据处理和分析的理想选择呢？</p><p>&nbsp;</p><p>列式存储格式：相比于JSON或者CSV或者其他行存储格式，Parquet最主要的特点是其列式存储设计。这种方法可以实现更高效的压缩和编码，以及提高分析型语句的查询性能。通常，大数据系统中的表都是用宽表的形式存储，即，一个表有很多column（几十，甚至上百）。而通常的查询语句，特别是分析型语句，只涉及少量列查询。这种情况下，Parquet可以仅读取所需的列，从而显著减少I/O并加快查询执行。</p><p>&nbsp;</p><p>高效压缩和编码：Parquet的列式存储格式允许更好的压缩比，因为同一列中的数据往往更加同质化。Parquet支持多种压缩算法，如Snappy、Gzip和LZO，此外，Parquet使用先进的编码技术，如RLE、bitpacking和dictionary-encoding，以进一步减少存储需求并提高查询性能。</p><p>&nbsp;</p><p>Schema演进支持：Parquet旨在能很好地处理数据schema随时间推移的变化，这对于大数据系统至关重要。它通过允许添加、删除或修改列而不影响现有数据来支持schema演进。</p><p>&nbsp;</p><p>支持复杂数据类型：Parquet支持丰富的数据类型集合，包括嵌套和重复结构，以及数组、映射（map）和结构（struct）等数据类型。此特性支持构建复杂的层次结构数据，并将其高效地存储在紧凑的二进制格式中。</p><p>&nbsp;</p><p></p><h1>Parquet存储格式详解</h1><p></p><p></p><p>这一节，我们深入学习Parquet是如何存储数据的。为了方便讲解，我们使用一个简单的示例表 - 学生表 student data（如下）。</p><p></p><p></p><p>&nbsp;</p><p>在讨论Parquet前，先来做个对比，看一下CSV或者JSON这样的基于行的存储格式是如何存储数据的。顾名思义，数据是按行存储在磁盘上的。每一行的数据都存储在一个连续的块中，这使得整体读取和写入比较容易且直观。基于行的存储格式非常适合事务型工作负载，因为记录通常是单条插入、更新或者删除操作。</p><p>&nbsp;</p><p>如果是CSV存储上面的数据，会是如下表示：</p><p></p><p><code lang=\"null\">id,name,age,country,home_address\n1,Alice,20,USA,123 Main St\n2,Bob,22,UK,456 Maple Ave\n3,Carol,19,Canada,789 Oak St</code></p><p>&nbsp;</p><p>虽然称为列式存储，但Parquet其实是将数据组织成多层级的结构，分别为row groups（行组）, columns（列）, 和page（页）。</p><p>&nbsp;</p><p>行组：行组是Parquet文件中最大的数据单位。它们将整个表的数据划分为多个块，每个块包含一定数量的行。一个Parquet文件可以有一个或多个行组。行组中的行数是可配置的，选择合适的大小对性能至关重要。每个行组包含所有列的数据，分别存储。在设计Parquet文件时，需要考虑行组的大小，因为行组大小的选择对查询性能有重大影响。较大的行组可以带来更好的压缩效果，可能带来更好的读性能，因为它允许更高效的I/O操作。然而，较大的行组也可能在查询特定行子集时增加读取的数据量。在大多数Parquet实现中，默认的行组大小为128 MB，但可以根据具体用例和数据特性进行调整。</p><p>&nbsp;</p><p>在选择行组大小时，需要考虑以下因素：</p><p>查询模式：考虑数据集的典型查询模式。如果查询通常涉及基于特定列过滤或聚合数据，那么可能会有较小的行组，因为这将允许查询引擎在处理这些查询时读取更少的数据。压缩比：压缩算法在处理较大行组时可以实现更好的压缩比，因为它们有更多的数据可供处理。然而，请注意，较大的行组也可能在查询数据时增加内存使用。内存使用：在处理查询时，查询引擎需要将相关行组的数据加载到内存中。较大的行组可能需要更多的内存来处理，如果系统没有足够的内存可用，可能会导致性能问题。</p><p>&nbsp;</p><p>列和页：列是Parquet中存储数据的主要结构。在每个行组中，每个列的数据都单独存储。每个列都经过编码、压缩，然后被存储进页里。页是Parquet中最小的数据单位，也是压缩和编码的基本单位。每个列会被划分为一个或多个页。</p><p>&nbsp;</p><p>因为是按列存储，数据的格式都是一个类型。Parquet就可以使用多种优化将一列数据有效地存储为二进制格式。主要的优化方式有两种，编码和压缩。</p><p>&nbsp;</p><p>Parquet常用的编码技术包括：</p><p>字典编码（dictionary encoding）：用来优化具有少量不同值的列。为唯一值创建字典，并用指向字典的索引替换实际数据。这可以显著减少存储数据量。Run-length encoding（RLE）：用来优化具有重复值的列。RLE不是单独存储每个值，而是存储值及其连续重复的次数。对于具有大量连续重复值的列，这种方法特别有效。位打包（bit packing）：用来优化具有小整数值的列。不是使用完整的32位或64位来表示每个值，而是使用表示值范围所需的最小位数，从而减少了所需的存储空间。</p><p>&nbsp;</p><p>在对数据进行编码后，Parquet会应用压缩算法以进一步减小数据的大小。Parquet中常用的压缩算法有Snappy、Gzip和LZO。压缩算法的选择取决于压缩比和解压速度之间的权衡。</p><p>&nbsp;</p><p>需要注意的是，在二进制的数据文件中，Parquet不使用任何分隔符来分隔数据。相反，它依赖于编码和压缩方案来有效地存储和检索数据。文件页脚中存储的元数据提供了关于数据结构的信息，使查询引擎能够正确访问和解释数据。</p><p>&nbsp;</p><p></p><h1>Parquet实操演练</h1><p></p><p></p><p>这一节，我们通过实操来直观地了解一下Parquet的文件存储。虽然Parquet通常被应用在大数据系统里，但pandas的DataFrame也支持直接以parquet形式导出数据。 下面是示例代码：</p><p>&nbsp;</p><p><code lang=\"null\">import pandas as pd\nfrom sklearn.datasets import load_iris, fetch_california_housing\n\n\n# toy dataset iris data: 150 rows x 5 columns\niris_data = load_iris()\niris_df = pd.DataFrame(data=iris_data['data'], columns=iris_data['feature_names'])\niris_df['target'] = iris_data['target']\n\n\niris_df.to_csv('iris_data.csv')\niris_df.to_json('iris_data.json')\niris_df.to_parquet('iris_data.parquet')\n\n\n# example data: student table: 3 rows * 5 columns\ndata = {\n        'Id': [1, 2, 3],\n        'Name': ['Alice', 'Bob', 'Carol'],\n        'Age': [20, 22, 19],\n        'Country': ['USA', 'UK', 'Canada'],\n        'HomeAddress': ['123 Main St', '456 Maple Ave', '789 Oak St']}\ndf = pd.DataFrame(data)\n\n\ndf.to_csv('student_data.csv')\ndf.to_json('student_data.json')\ndf.to_parquet('student_data.parquet')\n\n\n# california housing: 20640 rows x 9 columns\ncal_house = fetch_california_housing()\ncal_house_df = pd.DataFrame(data=cal_house['data'], columns=cal_house['feature_names'])\ncal_house_df['target'] = cal_house['target']\n\n\ncal_house_df.to_csv('cal_house_data.csv')\ncal_house_df.to_json('cal_house_data.json')\ncal_house_df.to_parquet('cal_house_data.parquet')</code></p><p>&nbsp;</p><p>先来解释一下上述的代码示例：分别load三个dataset，iris data（来自sklearn的toy dataset）, student dataset（我们上面使用的示例），以及california housing dataset（sklearn上比较大的dataset）。代码本身非常直观：数据导入后分别以CSV，JSON，和Parquet的形式存储到文件中。（注：运行这段代码还需要安装其他依赖包，可以通过pip install来安装）。</p><p>&nbsp;</p><p>然后通过`ll`来查看数据文件的大小：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/06/06ee809440ed10deddd6470e8227519a.png\" /></p><p></p><p>通过比较可以发现：</p><p>CSV和JSON的存储大小比大致保持在1:2。当数据量小时，Parquet文件远大于CSV和JSON，因为Parquet会存储更多的metadata，比如row group的column的min，max值，版本管理等等当数据量大时，Parquet文件明显小于CSV和JSON。在大数据应用中，压缩比会更明显（考虑到通常，parquet的文件大小在128MB左右）。</p><p>&nbsp;</p><p>CSV和JSON是明文和txt-based存储，可以直接用cat或者vim打开。Parquet是以二进制存储数据，如果想查看数据文件，可以使用`hexdump`工具（`hexdump -C student_data.parquet`）。 下面是运行截图。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/10/1083ef899b402d67fb03d6fcbc8a9655.png\" /></p><p></p><p>虽然有些特殊的bytecode，但大致可以看出数据是按照列来存储的。在数据文件的下半段，可以看到schema的definition。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/43/439187b9f0720c1c1fc551acf361f3b4.png\" /></p><p>&nbsp;</p><p>推荐大家可以动手，尝试运行一下代码。再留一道思考题给大家，可以使用time包对不同格式的读写加上时间消耗，来比较一下速度。另外，因为是列式存储，parquet的另一个优势是可以只读取要用到的column，推荐大家使用相关API只读取一到两个column，再比较一下速度。</p><p>&nbsp;</p><p></p><h1>总结</h1><p></p><p></p><p>本期杂谈介绍了为大数据系统而生的存储格式Parquet。我们通过介绍Parquet的关键特性和其存储格式，讨论了为什么Parquet更适合海量数据的分析型查询。最后，我们也通过代码实操来让大家对parquet有更直观的了解。感谢阅读！</p><p></p><p></p><h5>相关阅读：</h5><p></p><p><a href=\"https://xie.infoq.cn/article/9472adf321bcce7bc4835eee6\">分享：从数据库开发者的视角，预测 5 个开发趋势</a>\"</p><p><a href=\"https://xie.infoq.cn/article/fb83fe3ef4cb38bb15e2b5e3d\">腾讯云数据库性能打破世界纪录 每分钟可处理 8.14 亿笔交易</a>\"</p><p><a href=\"https://xie.infoq.cn/article/6b4823fedfe05fb494a4055a7\">从传统数据库痛点看分布式数据库选型问题</a>\"</p><p><a href=\"https://xie.infoq.cn/article/d22c59d43971c06c71adc6e7c\">开源面对面：浅谈数据库技术与人工智能的结合与实践</a>\"</p>",
    "publish_time": "2023-04-12 16:12:09",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]