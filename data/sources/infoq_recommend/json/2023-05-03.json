[
  {
    "title": "打造高效对话，与商业利益相关者探讨软件架构",
    "url": "https://www.infoq.cn/article/MJZYs27fPjsf8MAD0Y83",
    "summary": "<p></p><blockquote>\"软件开发中几乎所有的问题都能被归咎于是沟通问题。\"—— Thomas Betts</blockquote><p></p><p></p><p>开发团队在为技术决策寻求商业支持时，常需面对的一个问题是：业务人员不怎么在乎技术。如果你能简短快速地把技术决策内容讲清楚，或许他们会考虑下这些能给自己或客户带来什么。随着科技渗透到人们生活中几乎方方面面，也许你能指望他们有基础的用户层面技术认知，但这也会为讨论带来更多挑战：用户往往接触到的都是能正常运作的系统，而不是摇摇欲坠且乱七八糟的底层系统运作。</p><p></p><p>多数时候这并不算是问题，但也有例外情况：如果你的决策需要资金、产品方向、业务政策或流程方面的业务支持，那么随着技术而来、能为产品带来巨大改善的决策，是需要商业利益相关者能够明白并接受其对业务运行或客户交互方式改变的。利益往往会随巨大成本而来，如果你无法用商业利益相关者能够明白的方式解释清楚，那你将无法获得这些变更所需支持。</p><p></p><h2>信任和透明度促进有效沟通</h2><p></p><p></p><p>在“‘业务’是技术的‘客户’”这一观点所带来的众多问题中，最关键的是它让技术忽略了真正的客户；让技术从属于业务，并在二者之间构建了不信任的关系桥。让人有种这业务与技术是被强行分离的错觉，其中双方各有输赢。但实际情况下，如果没有双赢，那就是双输。</p><p></p><p>后者带来的功能性障碍往往来自于对项目成本和耗时的讨论，情况往往如下：业务说他们需要一个能处理他们不太懂的问题的解决方案，并给出了一系列或多或少真正有用的部分功能清单。技术上钩了，并根据自己对问题的假设以及这部分不一定都有关的功能清单，给出了一套对时间和成本的预估，虽然完全不切实际，但出发点是好的。</p><p></p><p>为了防止假设出错，技术会用警告说明层层包裹他们对时间和成本的预估以规避任何责任。但就像是迫不及待拆礼物的小孩一样，业务会扯掉所有的说明，只记得成本和预算的估计，并将其写入项目管理系统。</p><p>这套预算和预估方法或其他类似手段，都给双方搭建了不信任的基础，在技术和业务双方能够就成本问题进行可行的讨论之前，信任和透明化根本不可能实现。而双方最应该首先明说的是，成本和时间的估计都是假的，最初版本的需求缺乏有用信息且无法从中得出可行估计，但如果技术认为自己从属于业务，那么前者通常不认为自己可以挑战需求，而这种回应更是认可并加强了这种方式。</p><p></p><p>问题在于，多数的“需求”都是没有价值的，但你也不知道哪些是有价值的。将所有潜在范围全部纳入考量只会导致对时间和成本的预估过于离谱，并因此引发争端。一个更好的出发点，也是建立信任并鼓励透明度的更好方式，是首先需要明确合作之中没有“站队”，业务和技术需要相协作才能尽自己所能地开发出最好的解决方案。只有双方在商业案例上鼎力合作，才能更好地理解商业机会和潜在利益，从而了解自己想要或需要实现的目标，以及成功后自己所能收获的利益。</p><p></p><p>这么做的好处如下：</p><p>引导了对预期结果和成功效果的健康讨论；通过财务模型，明确了预期盈利目标下最高开销上限；提供了协作实践，从而引导更为良好的信任与透明度。</p><p></p><p>至少对大型工程而言，成本和时间的估算的难点在于，如果不构建并测试部分方案，则无法确定解决方案。但是，这也会带来对问题更好的理解以及更好的解决方案，同时也让随预算和工时的估算更加准确。在<a href=\"https://www.infoq.com/articles/architecture-skeptics-guide/\">先前发布的文章</a>\"中，可找到对”实验在做出好决策中所扮演的角色”这一话题更为全面的讨论。</p><p></p><p>在能够开诚布公地探讨成本之前，信任和透明是不可能实现的。你需要让商业利益相关者参与到对成本的决策中来，并以结果为导向地对利益和成本进行透明化探讨。对多数大型项目而言，组织在尝试新鲜事物时总会避无可避地涉及到关于得失权衡、方案备选这些困难话题，而从立项开始便进行公开对话，从而协助信任度、透明度以及同理心的建立，是这类困难话题中不可或缺的要素。</p><p></p><h2>以商业成果确定讨论范畴</h2><p></p><p></p><p>阻碍技术决策寻求商业投入对话有效性的一大问题在于，开发团队和商业利益相关者的语言不通。准确来说，业务人员会直接忽略技术人谈及的任何科技相关内容。技术需要用技术决策所带来的商业成果来划定讨论的内容，这些才是商业利益相关者关心的部分。</p><p></p><p>在之前一篇关于<a href=\"https://www.infoq.com/articles/technical-debt-tells-you/\">技术债务</a>\"的文章中，为讨论技术债务如何帮助业务人员理解技术决策，我们引用了一个比喻，虽然比喻或多或少有些帮助，但更好的方式是说明技术问题可以协助组织实现其他方式无法达成的商业成果，或者是说明不解决某个技术问题会如何损害组织所能收获的商业成果。</p><p></p><p>这是一种双向对话。当组织决定退出某个特定市场，或是对监管条目做出回应等业务优先级发生重大转变的情况发生时，用商业结果描述这类转变会让所有人更好地理解其所带来的影响。将架构决策和设计的重点放在其所带来的结果为非构成其设计的功能上，也可以让所有人更好地传达沟通架构为满足不断变化的优先级所需要的调整。</p><p></p><p>在<a href=\"https://www.infoq.com/articles/care-about-architecture/\">另一篇文章</a>\"中，我们借助质量属性需求（QAR）捕捉系统必须具备的重要能力。QAR 所表现的是系统必须实现的商业成果，我们更倾向于使用“刺激、响应、测量”的形式，以贸易金融为例，一个绩效相关的 QAR 可被表示为：</p><p></p><p></p><blockquote>当信用专员在接收到出口商文件后处理付款请求信时系统做出响应，将付款发送至出口商的银行，并从进口商的账户中扣除测量以下情况：端到端的付款交易时间不超过5秒</blockquote><p></p><p></p><p>用商业结果构建 QAR 有助于建立开发团队和业务人员在讨论系统所必须能实现的重要能力时的共同语言。</p><p></p><h3>示例：讨论安全问题</h3><p></p><p></p><p>安全问题颇具挑战性。类似准备应对飓风的讨论，安全问题只有在危机发生时才会得到关注，危机过去后安全相关举措便失去了优先级，也更难得到资助。</p><p></p><p>探讨具体漏洞往往需要非常专业的知识储备，这甚至是许多开发者和架构师都不具备的（不然漏洞也不会出现），因此与商业利益相关者讨论这些漏洞时就更具挑战性。不过，大多数商业利益相关者即使无法掌握漏洞中的细微技术差异，但却能理解一个漏洞可能导致的潜在后果。与其说明修复某个开源框架中内存泄漏的必要性，不如讨论防止敏感客户账户信息丢失的必要性更具备说服力，比如后者一旦发生可能会被媒体大量报道，对公司造成巨大损失，等等。</p><p></p><p>在这类对话中，商业利益相关者很可能一开始会说“任何客户信息丢失都是不可接受的”，但接着又会说时间或投资不足以最终支持清除所有潜在漏洞。如果能找到对话构建的方式，他们显然会更愿意承担一定程度的风险。</p><p></p><p>若想进行更有意义的对话，应在对商业结果的讨论中包含概率和影响信息。只有百万分之一的概率发生，一旦发生对财务的影响也是微乎其微的场景或许不需要应对，而另一个有百分之一概率发生且其后果将影响监管文件或年度报告的场景，就不得不尽快解决了。</p><p></p><h3>软件架构是应用冰山隐藏在水下的部分</h3><p></p><p></p><p>与商业利益相关者对话时一个好用的比喻是将应用程序比作是冰山，商业利益相关者只看得到水面之上的部分，大部分应用程序对其而言都是不可见的。要想讨论隐藏在水下的架构就必须把关注点与水面之上可见的部分联系起来。</p><p></p><p>在<a href=\"https://www.infoq.com/articles/continous-architecture-article-series/\">另一系列的文章</a>\"之中，我们引入了最小可行架构（MVA）的概念，是用于支持最小可行产品（MVP）的架构基础。图一借助冰山的比喻形容了这两个概念之间的关系。MVP 对商业利益相关者而言是可见的，而 MVA 则通常是隐藏的。商业利益相关者或许不在乎 MVA，但他们确实关心 MVA 所带来大的 QAR 和商业结果。因此，你可以试着用他们认为系统应当交付的 QAR 和商业成果为导向进行技术对话。</p><p></p><p><img src=\"https://imgopt.infoq.com/articles/effective-architecture-conversations/en/resources/5Picture1-1677232920038.jpg\" /></p><p>图一：MVP 是利益相关者在乎的，但 MVP 是搭建在隐藏的架构基础之上的</p><p></p><h2>做好准备，与商业利益相关者进行的任何对话最后都会回到金钱上</h2><p></p><p></p><p>与商业利益相关者对话会揭露一个令人不快的现实：对金钱的讨论令技术人员感到不适，但商业利益相关者只想谈钱。把项目经理等角色带入对话只会让场面更混乱。以业务成果作为讨论根据的重要性在于，我们能够用商业利益相关者真正关心的话题（金钱）进行对话的同时，仍可以将对话与应用程序的 MVP 和 MVA 相关联。</p><p></p><h3>传统预算都是烟雾弹</h3><p></p><p></p><p>在前文中我们已经探讨过，传统预算方法因为其所创建的预估无法与组织想要或需要实现的业务成果对齐而失败。保持与业务成果之间的联系是所有人能继续针对应用程序应该或不应该做什么而进行有意义对话的重要形式。</p><p></p><p>基于理想功能的 MVP 几乎都是陷阱。这些功能可能并没有什么用，也可能无法带来期望结果。多数功能毫无关联，但你也没办法知道那些是有用的。最好的方法是抛开这些功能，将重点放在结果上，通过小型增量，交付并用其测量成果。</p><p></p><p>传统预算所依仗的功能清单可信度存疑，其中包含的功能或许有用，但大多数都是没什么关联的，还会让所有人的注意力从真正的问题上转移开，即确定能实现预期结果的最低支出金额。通常来说，只有的一定程度的探索性工作后才能确定这些，但通过一些实验，组织能更好地了解某个主意是否在财务上可行或可取。</p><p></p><p>大多商业人士都或多或少地明白预算流程的糟糕，某位财务总监曾对项目效益表达过质疑：“如果把我们今年投资的项目所宣称的效益全部都加起来，这个数字将超过公司的年收入”。这是他用来表示效益估算不可信的方式，类似的说法有很多，这种双方均缺乏可信度的情况创造了一个以不同形式工作的方式。</p><p></p><h3>利益相关者真正关心的是成本效益</h3><p></p><p></p><p>成本效益是个常常被忽略但是能帮助团队做出更好架构决策的重要质量属性。多数公司，尤其是金融公司，对技术功能的成本非常关心，如零售银行、个人保险公司等等恰巧在零售行业的运作的更是如此，但却很少有团队专为成本效益而设计。这就导致他们所创建的应用程序在运行或维护成本上过于昂贵，如果不考虑成本效益，他们在程序生命周期的后段可能会需要改变架构，从而应对糟糕的成本效益。</p><p></p><p>在建筑、桥梁和船舶的物理世界中，建筑师常常会根据 QAR 或可实现成果（也可能二者兼顾）对客户提供成本效益和权衡选择。这点是对飞机乃至微芯片的设计师而言都是如此。任何客户都会对成本敏感，无论其所处的领域。</p><p></p><p>在面对全新的挑战时，组织并不清楚哪些是为达成特定客户成果所必须的，因此详细的成本预估并不现实。为向前推进，技术人员和商业利益相关者需要相互协助，逐步做出决定和权衡，从而带来一个具备成本效益的解决方案。</p><p></p><h3>成本阈值可以更好地帮助团队做出决策</h3><p></p><p></p><p>有一种特别针对早期阶段关于机遇、成果和成本讨论的解决方案。假设公司识别了一个机遇，并认为如果能满足特定客户的需求将带来一亿美元的额外收入。如果公司期望其中能有20%的利润率，那么在成本交付过程中的所有支出总额不能超出8000万美元（演示说明中忽略了资金的时间价值）。再假设，至少在项目初期，公司不知道成果是否能交付或交付需要花费多少钱，只知道客户可能愿意为其支付的金钱以及组织愿意为实现这一目标所支付的最大金额数目。我们将后者这个数额称作是成本阈值。</p><p></p><p>成本总会被纳入考量，尤其是对业务侧来说，但这点在开发解决方案时偶尔会被忽视。在开发者探寻不同的解决方案时，对成本阈值的了解能帮助他们做出更好的权衡决策。如果某个特定的决策会导致超过成本阈值，那么他们会知道自己应该换种方式。假设他们无法在成本阈值之下找到任何可交付的解决方案，那么他们有责任尽早分享这种担忧，让组织得以选择不同的机遇。了解成本阈值也有助于开发者做出决定，从而在不影响解决方案交付的前提下提高利润率。</p><p></p><h3>共同决策有助于改善工作关系</h3><p></p><p></p><p>成本阈值能够让成本效益方面的对话变得更轻松，这是传统预算所不能达到的。就如我们在上文中所讲，预算往往是基于多半不准确的预估，局限在这个预算之中却没有获得预期的结果往往不做好，超出了预算但交付了预期结果或许会更好，但只看预算的话也不好说。</p><p></p><p>从商业角度来说，成本阈值意味着追寻成本超出阈值的商业结果并不可取。这是一种技术侧和业务侧的人都能理解的语言，他们可以进行有意义的对话，探讨是否应当最寻某些特定的商业成果，以及是否能在其他机会中更好地工作。由此能带来以成本和收益为基础，可以对哪些机会下手的健康讨论。</p><p></p><p>就这些问题进行公开的对话可以帮助业务与技术更有效地协同工作，并共同决定一起工作的内容。</p><p></p><p></p><blockquote>在早期针对成本阈值的对话中所培养出的透明度与信任值，对日后团队需要做出影响成本与解决方案满足 QAR 能力的架构权衡中大有好处。一个例子可以说明这一点：某开发团队正在评估一个潜在解决方案的底层基础是应购入还是开发。目前团队已经找到了具有众多诱人功能的软件包，但该软件包至少在没有大幅变更之前，是无法满足商业利益相关者认为对解决方案能否达成期望商业成果而言所有必须的 QAR，而这些变更将导致成本超过阈值。开发团队和商业利益相关者就 QAR 进行了讨论，并共同得出结论：部分 QAR 过于严格，可以进行放宽。他们记录了 QAR 的变更，开发团队也同时在&nbsp;<a href=\"https://docs.aws.amazon.com/prescriptive-guidance/latest/architectural-decision-records/adr-process.html\">ADR</a>\"&nbsp;中记录：一旦 QAR 变更回原始状态，极可能超过成本阈值。随着在系统上的工作继续，商业利益相关者和开发团队需要根据对进展中系统的开发与测试时获得的信息，不断审视对 QAR 的假设。一旦假设发生变化，则需要对当前前进方向的可行性进行重新评估，并在可能的情况下纠正方向。</blockquote><p></p><p></p><p>QAR 和成本阈值可用于多个层面，既可用于上文示例中对解决方案的底层决定进行基本决策时，也能用于日常权衡不同的方案中。在任何决策中，人们都要自问两个问题：第一，这个选择是否会妨碍实现预期商业成果及相关 QAR；第二，这个选择是否会导致超出成本阈值。</p><p></p><p>许多 MVP 乍一看很有前途，但未考虑到的成本将会让项目不堪重负，最终在其生命周期的成本累积下崩溃。对架构的挑战在于，如何构建一个能在全部生命周期中维持在成本阈值之内的解决方案。一旦解决方案露出无法继续维持在其成本阈值之内运行的苗头，就是产品需要退役的标志。</p><p></p><h2>架构在于管理权衡：有意义地探讨权衡可能颇具挑战</h2><p></p><p>组织有时会在未能完全理解权衡背后意义的时候做出决策。示例如下：</p><p>为抢先进入市场，组织所采用构建 MVP 的技术无法满足基本 QAR，如使用无法扩展至目标工作负载级别或无法满足关键安全性 QAR 的低代码开发工具。忽视早期工作设计中的可扩展性隐患，认为应用上云能解决任何未解决的扩展性问题。只关注在线用户体验问题而忽视大规模的运营问题，而后者本质也是用户体验问题。这类情况可能包括：过多地关注产品的订购，而非订单确认到客户收到产品之间的所有事。</p><p></p><p>解决这类生命周期相关的问题意味着人们能就技术性极强的问题，与不具备对应技术深度的人进行高效的讨论。对 QAR 和期望商业与客户成果的关注为技术与业务之间的相互理解打下了基础。上文中的最后一点强调了理解技术和解决方案架构的重要性，不仅在与对许多人的影响上，也在于需要支持涉及业务不同部分的复杂流程上。</p><p></p><p>类似的情况在医患讨论替代疗法时也会发生：患者通常不具备理解手术细节的医疗背景，但如果医师以结果为重点，那么他们将能以不同方案对患者的短期及长期影响的期望结果进行有意义的探讨。</p><p></p><p>在架构类型的决策讨论中，共同语言往往是由技术决策可能如何影响解决方案是否满足重要结果或 QAR（或二者兼顾） 所决定的。因此，任何会影响成本阈值的都应被纳入讨论范畴，其中就包含万一决策反转所导致的可能成本出现。这样才能让所有人都理解决策的潜在影响。</p><p></p><p>解决方案提议的细节并不重要，重要的是它给商业利益相关者所看重的成果和 QAR 所带来的影响。这些讨论的结果以及其中对架构的探讨都应被记录与 ADR 中，后者需要包含对结果或 QAR 讨论的总结，用于留存做出决策的上下文情况。</p><p></p><p>让商业利益相关者参与到关键架构决策（或至少是结果与 QAR 方面）的重要好处在于，所有人都是原始决策的一部分，所有人都对决策“负责”，这让涉及变更或反转决策的讨论更为容易，也大大减少了互相甩锅的决策讨论现场的出现。</p><p></p><p>当然，也会有一些无关紧要的架构决策，无需牵扯商业利益相关者。如果决策不会对成本阈值或解决方案能否时限期望结果或满足 QAR 造成重大影响，那么这些决策就与商业利益相关者没什么关系，开发团队可以自行做出决策。</p><p></p><h3>示例：探讨可扩展性相关决策</h3><p></p><p></p><p>就如在“<a href=\"https://continuousarchitecture.com/\">实践中的连续架构</a>\"”所述，“可扩展性可被定义为，通过增减系统成本来处理变化的工作负载的系统属性。”可扩展性相关的架构决策可能对部署和运营成本带来极大影响，且可能需要在可扩展性和其他属性（如性能）之间进行权衡。</p><p></p><p>图二中展示了可扩展性是如何影响成本及其他 QAR 的：</p><p></p><p><img src=\"https://imgopt.infoq.com/articles/effective-architecture-conversations/en/resources/3Picture2-1677232920038.jpg\" /></p><p>图二：可扩展性-性能-可用性-易用性的成本关系</p><p></p><p>可扩展性在技术上很复杂，但这种复杂性却很难传达给商业利益相关者。商业利益相关者或许会认为扩展性或性能问题是可以通过砸钱解决的，比如购入更多容量，“让系统上云”、“亚马逊化”；可以对扩展性问题高枕无忧，因为有云供应商在兜底。可实际上，无法在专用环境中正常扩展的设计失败的系统，在没有进行大规模设计改造的前提下，很大概率在商用云环境中也没办法正常扩展。</p><p></p><p>如图二所示，满足可扩展性 QAR 意味着一系列的复杂的权衡问题，这些权衡决定会影响系统在成本阈值内满足业务成果和 QAR 的能力。</p><p></p><p>与商业利益相关者对话时的首要挑战是确定他们对可扩展性的要求，这一点他们或许没有考虑太多，也许了解也不够，如果不需要做出任何代价高昂的决策，这在一段时间内是可以忍受的。模拟大型工作负载对 MVA 的影响可以带来对其可扩展性和性能的更多了解，同时也会带来对扩展需求相关的对话更为有用的信息。</p><p></p><h2>结论</h2><p></p><p></p><p>总之，商业利益相关者看似只关心钱，但这种说法并不完全正确。他们关心的是利润，如果开发团队在讨论赚钱时只说成本，则是限制了自己进行健康的权衡对话、从而开发出更好解决方案的能力。</p><p></p><p>开发团队可以改变与商业利益相关者对话方式，从而提升对话的效率和质量。首先要做是，避免因为对解决方案残缺且不正确的假设从而导致的毫无作用的预算相关对话，将对话的重点转移至解决方案需要达成的商业成果和 QAR 上。随后，双方均需要探讨这些达成的结果对自己的价值，以及组织为实现这些结果所能承担的最大花销（即实现结果的成本阈值）。</p><p></p><p>一旦踏上了更为高效的路线，开发团队应继续专注于维持成本阈值，甚至要在可能接近或超过这一阈值时，尽早提出问题并降低阈值。因此所产生的与商业利益相关者关于权衡的对话会帮助所有人做出更好的权衡决策。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/effective-architecture-conversations/\">How to Have More Effective Conversations with Business Stakeholders About Software Architecture</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/XYlKxH5f3GjBflH31z9h\">ThoughtWorks CTO：2025 年之前，我们会看到架构的演进，但不会看到革命</a>\"</p><p><a href=\"https://www.infoq.cn/article/T4PEt15NU2JUk1VWhTMv\">避免成为“象牙塔”架构师：架构师和组织之间的关系</a>\"</p>",
    "publish_time": "2023-05-03 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "JEP 444：JKD 21 中出现虚拟线程，开创并发新纪元",
    "url": "https://www.infoq.cn/article/wxcjbFtvT7Twva0eeXTj",
    "summary": "<p>JEP 444 <a href=\"https://openjdk.org/jeps/444\">虚拟线程</a>\"已从 JDK 21 的候选（Candidate）<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-March/007543.html\">升至</a>\"建议实现状态（Proposed to Target）。该功能提供虚拟线程这一轻量级线程，可大幅削减在 Java 平台上高吞吐量并发应用的编写、维护及观察的工作量。根据在 JDK 20 中交付的 JEP 436 <a href=\"https://openjdk.org/jeps/436\">虚拟线程（第二次预览）</a>\"，在 JDK 19 中交付的 JEP 425 <a href=\"https://openjdk.org/jeps/425\">虚拟线程（预览）</a>\"，这前两轮的反馈，本次 JEP 预计将最终敲定该项功能。</p><p>&nbsp;</p><p>随着这一 JEP 的加入，Java 将有传统线程（又名平台线程）和虚拟线程两种类型的线程存在。平台线程是对操作系统线程的一对一封装，而虚拟线程则是由 JDK 所提供的轻量级实现，可在同一条操作系统线程中运行多条虚拟线程。虚拟线程提供了比平台线程更为有效的替代方案，允许开发者以肉眼可见的低开销处理大量任务，与此同时，这类线程也受益于增强的性能和资源利用率，提供对已有 Java 代码的兼容性和无缝迁移路径。以下面这段代码为例：</p><p>&nbsp;</p><p><code lang=\"java\">try (var executor = Executors.newVirtualThreadPerTaskExecutor()) {\n    IntStream.range(0, 10_000).forEach(i -&gt; {\n        executor.submit(() -&gt; {\n            Thread.sleep(Duration.ofSeconds(1));\n            return i;\n        });\n    });\n}</code></p><p>&nbsp;</p><p>目前，在低至一个的操作系统（OS）线程上，JDK 可运行高达一万个并发虚拟线程，执行这段让程序睡眠一秒钟的简单代码。</p><p>&nbsp;</p><p>虚拟线程的设计让其可与<a href=\"https://download.java.net/java/early_access/jdk21/docs/api/java.base/java/lang/ThreadLocal.html\">线程本地</a>\"的变量、<a href=\"https://download.java.net/java/early_access/jdk21/docs/api/java.base/java/lang/InheritableThreadLocal.html\">可继承线程本地</a>\"的变量共同运作，这点与平台线程相同。但由于虚拟线程的可创建数量上限非常高，开发者在使用线程本地变量时应当多留心。至于虚拟线程的迁移，JDK 所提供的系统属性 jdk.traceVirtualThreadLocals 可在虚拟线程设置任何线程本地变量值时，触发堆栈跟踪。</p><p>&nbsp;</p><p>程序包 java.util.concurrent 现已包含对虚拟线程的支持。LockSupport API 也已更新，可优雅暂停（park）或恢复（unpark）虚拟线程，允许<a href=\"https://download.java.net/java/early_access/jdk21/docs/api/java.base/java/util/concurrent/locks/package-summary.html\">锁（Lock）</a>\"、<a href=\"https://download.java.net/java/early_access/jdk21/docs/api/java.base/java/util/concurrent/Semaphore.html\">Semaphores</a>\"、<a href=\"https://download.java.net/java/early_access/jdk21/docs/api/java.base/java/util/concurrent/BlockingQueue.html\">阻塞队列</a>\"等使用 LockSupport 的 API 与虚拟线程无缝连接。</p><p>&nbsp;</p><p>其中，Executors.newThreadPerTaskExecutor(ThreadFactory)&nbsp;和Executors.newVirtualThreadPerTaskExecutor()&nbsp;方法，可通过 ExecutorService为每个任务创建一个新线程，在利好迁移的同时，也让使用线程池的已有代码具备与 ExecutorService 的互操作性。</p><p>&nbsp;</p><p>在 java.net 和 java.nio.channels 包中的网络 API 现已支持虚拟线程，使并发应用更为高效。虚拟线程中的阻塞操作可释放底层平台线程，而 Socket、ServerSocket&nbsp;及&nbsp;DatagramSocket 类中的 I/O 方法也已改为<a href=\"https://download.java.net/java/early_access/jdk21/docs/api/java.base/java/lang/Thread.html#interrupt()\">可中断</a>\"。本次更新为并发应用的 Java 开发者们提供了更好的一致性行为和性能。</p><p>&nbsp;</p><p>用于字节流和字符 API 的 java.io 包也已更新，避免在使用虚拟线程时被锁定。虚拟线程中的锁定是指轻量级线程“被困”于某个平台线程而导致的阻塞操作，从而限制了线程的并发性和灵活性。此外， BufferedInputStream、BufferedOutputStream、BufferedReader、BufferedWriter、PrintStream及&nbsp;PrintWriter 在直接使用时，已将原先的监视器锁改为显式锁。InputStreamReader&nbsp;与 PrintWriter&nbsp;所使用的流解码器与编码器现也已改为与其对应的流关闭 InputStreamReader&nbsp;或 OutputStreamWriter 使用相同的锁。</p><p>&nbsp;</p><p>Java 本地接口（<a href=\"https://download.java.net/java/early_access/jdk21/docs/specs/jni/index.html\">JNI</a>\"）引入用于检测对象是否为虚拟线程的新函数 IsVirtualThread。除此之外，JNI 规范没有其他变化。</p><p>&nbsp;</p><p>由 JVM 工具接口（<a href=\"https://download.java.net/java/early_access/jdk21/docs/specs/jvmti.html\">JVM TI</a>\"）、Java 调试协议（<a href=\"https://download.java.net/java/early_access/jdk21/docs/specs/jdwp/jdwp-protocol.html\">JDWP</a>\"），及 Java 调试接口所（<a href=\"https://download.java.net/java/early_access/loom/docs/api/jdk.jdi/module-summary.html\">JDI</a>\"）组成的调试架构现已更新，可支持虚拟线程。其中三个接口均已支持虚拟线程，且增加了用于处理线程开始和结束事件、虚拟线程批量暂停恢复的新功能和方法。</p><p>&nbsp;</p><p>JDK 飞行记录器（<a href=\"https://docs.oracle.com/javacomponents/jmc-5-4/jfr-runtime-guide/about.htm#JFRUH174\">JFR</a>\"）现已支持虚拟线程的新事件，诸如&nbsp;jdk.VirtualThreadStart、jdk.VirtualThreadEnd、jdk.VirtualThreadPinned，以及jdk.VirtualThreadSubmitFailed。上述这些事件均提供了对应用程序内虚拟线程行为的洞察力。</p><p>&nbsp;</p><p>Java管理扩展（<a href=\"https://docs.oracle.com/en/java/javase/20/jmx/introduction-jmx-technology.html\">JMX</a>\"）仍旧通过ThreadMXBean&nbsp;接口仅支持平台线程。HotSpotDiagnosticsMXBean&nbsp; 接口中新方法将生成该新增线程类型的转储，从而支持虚拟线程。</p><p>&nbsp;</p><p>虽然虚拟线程为我们带来了显著的性能改善，但开发者仍应注意对已有 API 及其实现的更改可能造成的兼容性问题，如对 java.io 包中内部锁协议的修订，任何扩展 Thread类的代码源码可能存在与二进制不兼容的问题，等等。</p><p>&nbsp;</p><p>虚拟线程的引入标志着 Java 在支持高并发和可扩展应用道路上的里程碑式进展。随着这一更为高效且更为轻量级的线程模型的出现，开发者现已可以轻松处理数以百万级的任务量，对系统资源的利用也更为充分。关于 JEP 425 的更多开发者细节，请参见 InfoQ <a href=\"https://www.infoq.com/news/2022/05/virtual-threads-for-jdk19/\">新闻</a>\"及 Oracle 公司 Java 平台组的 Java 开发者倡导 <a href=\"https://www.linkedin.com/in/jos%C3%A9-paumard-2458ba5/\">José Paumard</a>\" 在 JEP Café&nbsp;的<a href=\"https://inside.java/2022/06/08/jepcafe11/\">演讲截屏</a>\"。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/04/virtual-threads-arrives-jdk21/\">JEP 444: Virtual Threads Arrive in JDK 21, Ushering a New Era of Concurrency</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/gB3ToN16f0iPC3tvdpDZ\">Java 近期新闻：字符串模板、Quarkus、Open Liberty、PrimeFaces、JobRunr、Devnexus 2023</a>\"</p><p><a href=\"https://www.infoq.cn/article/PyfmlboNJMKzlhZTwDL3\">加入有序集合，Java 集合框架变得更加完善</a>\"</p>",
    "publish_time": "2023-05-03 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "百度爱番番 RT-CDP 架构实践",
    "url": "https://www.infoq.cn/article/FcoVTtQdqzAY5P9D8asA",
    "summary": "<p></p><blockquote>本文整理自百度爱番番业务部 团队技术负责人李新建在<a href=\"https://qcon.infoq.cn/2023/beijing\">QCon 2022 北京站</a>\"的演讲分享，主题为“<a href=\"https://qcon.infoq.cn/2023/beijing/presentation/4521\">百度爱番番 RT-CDP 架构实践</a>\"”。</blockquote><p></p><p></p><p>随着公域流量红利褪去，企业更加注重私域精细化运营、营销。越来越多的企业需要基于 CDP 解决数据孤岛问题，帮助其更快的加温线索、促活客户。但对于中小企业来说，在搭建强大平台能力的同时，如何合理化资源，最大程度降低资源成本也是一个重要课题。本次分享既有先进架构的整体介绍，也有在资效方面上的设计考量，来最大化的帮助企业降本增效。</p><p></p><p>以下为演讲实录。</p><p></p><p>我叫李新建，目前在百度工作已有七八年。我此次分享的主题是关于百度爱番番的实时CDP实践。我之前写过一篇关于这个CDP架构的文章，包括一些选型和设计实践。此次分享是为了贴合资效平衡这个主题，因为我们在这个架构的过程中有几个核心指标和主题密切相关，所以我也参加了这次的会议。需要说明的是，这个PPT是半年前制作的，在制作过程中由于多次调整会议时间，PPT没有同步迭代。另外，涉及业务变更的内容也没有更新到最新状态，但我认为其中的很多方法论、思想和目标在当前仍然适用，因此我想分享给大家，让大家了解当时我们是如何做的。</p><p></p><p>我之前写的一篇<a href=\"https://mp.weixin.qq.com/s/VSZFiQCZxXWY5x169iC3qg\">文章</a>\"，已经发布并受到了不少关注。这次的PPT缺少一些前期背景和业务问题的详细说明，因此可能会更难理解。如果有问题，可以在最后一页的“彩蛋”中找我交流。</p><p></p><p>这次分享主要涵盖几个大块，其中最重要的是介绍资效平衡实践在架构中的应用。</p><p></p><p></p><h2>业务背景</h2><p></p><p>&nbsp;</p><p>简单介绍一下我们的业务和整体的价值。我们主要是在营销领域开展业务，主要服务于广告主。随着互联网的发展，公域流量的增长已经趋于饱和，中小企业获取客户的成本越来越高，而且难以制定贴近客户的营销方案，以获取更高的客户转化率。因此，我们开始针对私域进行建设，以满足客户的需求。对于百度来说，公私域的业务都很重要。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9d/9d0d87169bc7c5d0cac2c97635199de2.png\" /></p><p></p><p>&nbsp;</p><p>当时，整个营销环境的主要问题是广告成本和缺乏创新的营销方案，而且客户的需求变化非常迅速。以前，只要提供了一个产品或服务，客户基本上能够很快地接受它，并且他们的需求变化不会太大，门槛要求也不是很高。但是现在，由于信息量越来越大，客户对自己的想法，包括对企业和客户的想法变化得非常快。客户对数据和信息变化的时效要求也越来越高。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f1/f1a3f7e5330e82cf00eb426d0075815b.png\" /></p><p></p><p>基于多方面的需求，爱番番提供了完整的营销解决方案。这包括公共和私人领域的服务，其中包括百度的广告业务，后续的客户转化链路以及维护环节。通过与百度的整体业务对接，形成了一个强大的闭环系统。我现在分享的主要是关于私领域营销的内容。我们的实时CDP是与私域营销紧密合作的。这包括数据分析和整个数据链的串联，确保数据的及时性。</p><p>&nbsp;</p><p>关于CDP，我们需要考虑两个方面。第一个方面是要确定业务的本质，而第二个方面则是需要了解标准CDP所需要满足的要求和特征。在业务层面，我们可以通过一张简图来了解我们在私域场景下为客户和企业提供的标准能力是哪些。因为我们面向多租户，所以需要在数据模型上支持ToB和ToC。比如，如果一个企业是ToB企业，我们需要管理企业和客户数据，它们是多层的关系。然而，在国内大多数CDP场景下，ToB数据模型基本上没有得到很好的建设，而往往是以ToC为方向来打平数据。这也是我们面临的挑战之一。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f5/f53eb39397b9a7ed4a650d92df9010db.png\" /></p><p>另外，我们还需要考虑多渠道营销。如何赢得营销？首先，我们提供了灵活的数据配置化画布能力。比如，一个企业想要如何向客户进行营销，客户通过访问其官网、H5或其他渠道的媒体信息，企业需要了解客户在不同媒体之间的整体访问轨迹，然后提供灵活的触达，包括活动信息和优惠券等。第三个是解决方案的链路需要多样化，因为无论是涨粉、推广还是直播，其业务需求的链路都不一样。具体的业务场景可能需要更加深入地讨论。</p><p></p><p></p><h2>CDP特征</h2><p></p><p>&nbsp;</p><p>下面介绍下CDP，这是我想着重想分享几个关键点之一。首先，CDP的标准定义是什么？CDP在2013年就已经被提出来了，包括其官方定义和分类。但是在国内，很多公司仍然将其称为MA、数据洞察，并推出了很多不同的产品。甚至包括我们自己的团队在做这个东西的时候，对于CDP的理解和标准也存在很大的差异。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/72/72db581b0adf82d1e0e310e23b95d69d.png\" /></p><p></p><p>如果你对CDP感兴趣，那么这一页是必须要了解的。基本上，所有现在提到的营销链路的东西都是CDP的范畴。然而，CDP对应的能力集不同，因此需要考虑业务分析和技术指标，列出我们要做的CDP应该是什么样子的。有两个主要的细节：一是灵活支持ToB和ToC两类模型，即私有部署和适应多种业务场景；二是统一画像的存储；三是实时的多渠道打通，以保证跨渠道数据的实时同步读写。此外，考虑时效性，即跨渠道数据打通的实时性和海量数据下的实时性。为了满足这些要求，我们进行了很多调优，包括整条链的，服务链的，数据层面的和混部等。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/15/158a78eb0a3c8dcd252d4856a8046e0b.png\" /></p><p></p><p></p><h2>整体架构</h2><p></p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d1/d1b1b1b0d5a46db5cfae09edbaddc57b.png\" /></p><p>我们的架构指标归纳为四个：多租户，高性能，低成本和实时。这四个指标之间存在一些相互冲突，需要权衡，我们花了很大的力气去实现。</p><p>&nbsp;</p><p>我们先了解整体的数据流向，从多元数据对接到采集、处理和输出。这个逻辑架构图中最重要的部分是红色的三个块，这些部分需要结合具体的详细设计和资效平衡来了解。关注这三个部分对应的位置、功能和需要解决的问题是很重要的。虽然其他块比如实时数据处理和统一存储也进行了成本优化和控制，但这三个块是更典型的。因此首先讨论这三个块。</p><p></p><p>在下面这个图中重点想介绍下公共组件与云原生的结合。我们部门是百度内部比较早将功能服务、微服务和数据服务全都拉到K8S生态下的部门之一。CDP平台涉及了许多组件选型和与K8S结合的问题。我们在做这个图服务的时候也遇到了很大的问题。从Dgraph迁移到Nebula Graph的过程中也踩了很多的坑。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1a/1adbd26302df52cf0cbfcf50aee8e6c3.png\" /></p><p></p><p></p><h2>架构/资效均衡实践</h2><p></p><p>&nbsp;</p><p></p><h3>Schema自定义模型</h3><p></p><p>&nbsp;</p><p>今天的重点是讨论三个问题：Schema、实时的IDM和实时的规则引擎。这三个对应的问题比较典型，Schema的关键词是降低成本和提高效率，IDM是资源均衡和性能优化，规则引擎是极致性能和弹性伸缩。在Schema中，我们需要将中小企业的数据用很低成本地接进来，这对于不同的企业来说是非常重要的。虽然其他的数据平台都会考虑这个问题，但这个问题的复杂程度并不小。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/73/7342f9281bc5ab626b6f22ebc470af7b.png\" /></p><p>首先，我们面临的是业务问题，即如何更快地将各种企业、各种维度的数据接入我们的CDP 平台。为了解决这个问题，我们先进行了一层抽象，将数据转换为CDP平台中群组的标准数据。我们将这些数据抽象为三类业务实体，其中两大类是身份信息和行为轨迹，包括属性信息、时序信息和数据变化记录。然后，我们在这个业务抽象的基础上又做了一层内置的标准 Schema，这个Schema针对特定行业的结构化数据，内置了标准字段，比如企业信息、企业地址和企业名称等。</p><p></p><p>在营销场景下，比如微信场景和直播场景，我们对各个场景的标准字段进行抽象内置，并进行简化，以提高效率。稍微配置一下就可以在几分钟内完成数据导入，而以前可能需要一两天。</p><p></p><p>在我们做这个抽象之后，将其转换为一个简单的模型，这个模型可以处理多个实体之间的 1 对 n 的关系，以及一个实体本身的 1 对 n 的关系，可以复制继承并在多机上使用，最终将其转换为一个 结构化的 JSON，带有一些业务含义。当企业使用时，我们将其原始数据打入我们的库中。企业在扩展时，主要是通过子Schema进行扩展，最后统一存储。至于其他模块涉及到业务拆分，不再细说。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d2/d205973ce463e219a1208bd890c4f47f.png\" /></p><p></p><p>对于 Schema，我们面临两个问题。首先是多租户的支持，如何统一存储而不会导致建表量特别多？第二个问题是，如果表量不多，如何存储这些字段？对于第一个问题，我们需要保证建表量不会过多，以降低维护成本。对于第二个问题，如果采用大宽表的方式进行存储，虽然在数据分析时可能会有一个聚合的大宽表，但对于多租户的情况，数据会非常离散，这对于查询成本来说是不划算的。因此，在数据处理方面，我们通过对原始数据结构的映射，将无业务概念的数据字段抽象为数值型、字符型等几类，上层通过Schema进行查询和SQL转换。有了这一机制，我们只需在企业的字段数量超过内置字段限制时才需要干预，添加几个内置字段并自动进行映射转换。在我们底层统一存储使用的Apache Kudu，字段数量官方建议有几百个限制。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ec/ec40a36d279e76e9eca408ddc1f229b6.png\" /></p><p>&nbsp;</p><p></p><h3>万级QPS实时IDM</h3><p></p><p>&nbsp;</p><p>我们也在性能和实时QPS调优方面做出了一定的努力。虽然我们在万级QPS的场景下进行了测试，但这需要在3-6个pod的情况下进行，且存储是读写分离的，包含3个存储节点和3个查询节点。考虑到数据处理过程是基于图结构且深度为4，我们能够处理几万QBS的数据量级，这表明它具备了很强的性能。</p><p></p><p>从模型的角度来看，IDM就是ID的关联，在我们的场景中代表着客户从官网访问后，在微信上登录小程序后需要进行关联。当访问官网时，如何营销和触达客户是一个重要的问题。官网的数据通常只有临时数据，如Cookie ID，且它们是设备粒度的。微信授权可能使用的是百度的OpenID，这些数据是片段化的。解决这个问题的关键是如何将客户数据打通，并在多个渠道上进行营销。这通常涉及到在不同媒体上发布的数据，并使用图的方式来处理这些数据。</p><p></p><p>大多数企业通常倾向于使用结构化的数据表进行离线计算，以获得历史关系数据。与这种方法的区别在于，我们的关系是实时打通的，这是因为如果不实时打通客户，即使在同一个媒介下，也可能无法确定应该归属于哪个人，在统一结构之后，他们会有一个CDP唯一标识。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ea/eadd372b904e1bfdc17c3bbc364a7b3a.png\" /></p><p></p><p>在使用图数据库时，需要考虑使用实体属性值还是实体关系和实体结构来存储数据，因为不同的数据库的数据切分方式是不同的。在实现图数据库时，最初采用了点切分的方式，但由于数据模型下的节点类型有限，加上多租户的需求，导致数据倾斜问题严重。为解决这个问题，系统采用了边切分的方式，并使用了国内的Nebula Graph数据库进行存储。Nebula Graph相对于国外的Dgraph更加成熟，且有较好的发展前景。</p><p></p><p>因为天然的图数据库拥有适合的架构，无论是在计算存储还是底层分布式存储方面都有优点，因此它天然具备伸缩能力。在分布式系统中，有一个常见的小点用于控制Redis的伸缩，这是一个参考。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f6/f6937fa9ce3dcd833ff91ebbc64b0a7d.png\" /></p><p></p><p>在逻辑处理方面，我们对锁和连接池进行了优化，并对查询的SQL进行了调优。我们与图数库的人合作做了很多配合，效果明显，无论是在机型稳定性还是性能方面，对于资源消耗都有很大提升。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/60/604576e3a6fd9c2c71b386684174691b.png\" /></p><p></p><p>最后一个部分是IDM部署，提到部署是因为它与水平伸缩和部署方式相关，对成本和资源有天然的优势。我们对存储计算节点的部署，在混部方式、网络和负载方面以及磁盘上做了很多</p><p>优化，才达到了之前提到的效果。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dc/dc963d6345b519a72123747fdf3039a0.png\" /></p><p></p><p></p><h3>实时规则引擎（RTRE）三次演进</h3><p></p><p>&nbsp;</p><p>在实时规则引擎方面，一个问题是数据量很大，存储的原生数据海量。另一个问题是对于多租户，实时流入的数据量也很大，在实时IDM的前提下，每条数据都需要实现实时读写，实时关系打通并进行处理。我们进行了两三次迭代，最终达到了预期，在性能和资源伸缩方面都有所提升。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ea/ea11f97172fae2ea51963177f1c21db8.png\" /></p><p></p><p>我们的实时规则引擎主要应用于营销场景，并且需要配置对话流程。简而言之，当客户触发某些规则时，我们将采取相应的措施。这些规则相对复杂，例如，在企业的7天内，客户未打电话，且之前提供了手机号码但没有提供微信号码；在最近的3分钟内访问过企业的H5页面等。这些条件需要进行组合，包括两组和三组条件，AND OR关系，因此相对复杂。其次，一旦流程配置完成，我们希望能够实时触发，即在一条数据到达后的毫秒级别内进行响应和触达。尽管规则实验是相同的，但在时效性和数据量方面却有所不同。</p><p></p><p>接下来介绍一个关键点，就是数据查询中是主动还是被动的。传统的数据平台会在设计一堆规则之后，通过查询语句来搜索海量数据。而我们的思路是数据主动查询，在数据流的关键阶段进行重要数据的补充，以确保在进行规则判断时有足够的数据，并进行结果处理。此外，目前还有一些流式数据库，也是非常重要的方向和思路。</p><p><img src=\"https://static001.geekbang.org/infoq/81/81ab9469f3b497bc0762d72b23fddd18.png\" /></p><p>&nbsp;</p><p>在实现这个引擎时，我们持续迭代了实现机制。第一版实现比较粗糙，基于Flink进行实现，需要建立许多Flink的job，并使用Flink SQL进行编写。但我们当时遇到的问题是窗口风暴，这意味着处理每分钟数据与近一分钟数据的实验处理方式不同。当滑动窗口很大时，例如几天或几个月，使用Flink消耗资源和实现程度都面临很大挑战和问题。Flink提供了复杂事件组合处理的标准组件，但目前它主要适用于固定窗口和小滑动窗口场景，例如实时监控日志报警。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d1/d1960853dd0e9f0f35476720e955f8c9.png\" /></p><p></p><p>基于这些前提，我们重新自研了一套实时规则引擎，并进行了拆分和定制化策略以更好地与抽样SQL解析和规则引擎对接。我们还优化了片段规则的结果复用和资源控制。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/61/61e10be848676149e7a55c0d639157a7.png\" /></p><p></p><p>在部署资源时，我们面临多租户的情况，每个job都占用很多CPU和内存资源。对于数据高峰，我们对处理节点进行了分类，有些偏管理，有些偏数据计算和存储，还有些是纯计算。这样，当高峰过去时，我们可以快速消除或解除纯计算节点。第二次演进，我们在百度云的基础上升级了计算平台搭建。我们支持的伸缩策略可以分为两类：一类是固定时间段的，缺乏动态性；另一类是基于指标的，这与在云原生场景下的情况非常相似。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c0/c09dc31ef6f61c35a1e338237606a1e9.png\" /></p><p></p><p>第三次演进是迁移到云原生，因为在最初建设计算平台时，云原生链路尚未完全建立，现在有了之后，可以在多租户场景下进一步缩减资源，主要考虑客户成本和运维方面的因素，尤其是在线业务链路方面，长时间的响应时延是不可接受的。在云原生上，我们能够实现的主要是集群力度和服务力度的伸缩，以及通过虚拟化场景下的预 pod 管理来减少 pod 启动时延。如下图，通过 AP、CA、HPA 三个圈来代表这些方面。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/10/10aca09c5756e68a2d0a9127dab7dcc0.png\" /></p><p></p><p>在这三类前提下，我们将所有的 Flink 作业迁移到云上。在云上，我们遵循官方实践，将 Flink作业运行在高可用模式下。现在，我们的几百个作业可以通过几个物理机承载，并且能够很好地进行伸缩。我们可以将这些资源与其他业务的 pod 进行整体的复用和资源均衡，使得计算集群所占用的资源非常少。</p><p>总结与展望</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/79/79ae351fafd57c360ac44b837f69e099.png\" /></p><p>下图整理了平台能够实现的能力和之后想要实现的一些功能。我们的CDP平台是一个数据平台，主要关注流批一体的数据处理。然而，与智能湖仓相比，我们还有很大的差距，这是我们未来想要探索的方向。</p><p>&nbsp;</p><p>以上是我们平台的一些内容，如果您有任何问题，随时可以联系我们进行交流。谢谢！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/62/6202d16f091b57787ebfd6ded8be8cf2.png\" /></p><p></p><p>相关阅读：</p><p><a href=\"https://xie.infoq.cn/article/67b0b7b5263d82de39c40ab2c\">百度爱番番移动端网页秒开实践</a>\"</p><p><a href=\"https://xie.infoq.cn/article/bf97ac8a495f9e8e9f8bb0d77\">领域驱动设计（DDD）在百度爱番番的实践</a>\"</p><p><a href=\"https://xie.infoq.cn/article/185bbe6e7351fa389241cbed9\">爱番番企业查询结果优化实践</a>\"</p>",
    "publish_time": "2023-05-03 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "7天花5万美元，我们成功复制了 Stable Diffusion，成本大降88%！训练代码已开源",
    "url": "https://www.infoq.cn/article/hzqWDTkJbUCLghFPXmel",
    "summary": "<p></p><p><img src=\"https://constatic.geekbang.org/infoq/5dd6484dc8f6f.png\" /></p><p>作者 | Mihir Patel, Cory Stephenson, Landan Seguin</p><p>译者 | 核子可乐</p><p>策划 | 刘燕</p><p></p><p>4 月 26 日，AI 创企 Mosaic ML 表示：</p><p></p><p>我们已经成功用不到 5 万美元复制了 Stable Diffusion，并将训练代码向大家开放！这样的成本水平只相当于我们之前试水项目的三分之一，更是 Stable Diffusion 2 base 本体的八分之一。换言之，每个人都能以前所未有的极低门槛训练出属于自己的 Stable Diffusion。</p><p></p><p>Mosaic ML 在一篇文章中详细讲述了“复制 Stable Diffusion”的方法、过程以及结果。以下是全文，经 InfoQ 翻译。</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/a1/6f/a1d63bdc1c4af66064fc27c91803856f.png\" /></p><p></p><p>“MosaicML 非常适合训练 diffusion 模型，而且相较于以往的工具有了巨大改进。”—— Tony Francis, Dream3D 公司 CEO‘</p><p></p><p>几个月前，我们曾演示过如何以低廉价格在 MosiacML 平台上从零开始训练大规模 difussion 模型。</p><p>今天（4 月 26 日），我们很高兴能为大家带来新的好消息：使用 MosaicML 平台，我们以不到 5 万美元成本花 7.45 天从零开始成功复制了 Stable Diffusion 2。</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/84/69/84e0bb7dc3ea09361a77793c74f22169.png\" /></p><p></p><p>图一：AI 想象出的菌丝体时装。这种将奇异图像引入设计流程的尝试有望突破创意的边界。以上各图均由我们在 MosaicML 平台上从零训练而成的内部 diffusion 模型创作而成。</p><p></p><p>利用自有数据训练属于自己的图像生成模型，这个前不久还属痴人说梦的目标如今已经切实可行。通过训练自有 diffusion 模型，我们可以：</p><p></p><p>使用专有数据；调整某些艺术或摄影风格的表现形式；避免违反知识产权法，确保模型能够用于商业用途。我们已经对训练 diffusion 模型所使用的代码和方法进行开源，可供您随意训练自己的模型（<a href=\"https://github.com/mosaicml/diffusion\">https://github.com/mosaicml/diffusion</a>\"）。</p><p></p><p></p><h2>设置</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/08/3f/080eaabd8d5beaa5bcdbb3d489af203f.png\" /></p><p></p><p>图二：发挥创造力并拥抱意外发现。我们的 diffusion 模型能够生成不同主题、艺术和摄影风格的画面。</p><p></p><p>模型：我们的 diffusion 模型是一个由变分自动编码器（VAE）、CLIP 模型、U-Net 和扩散噪声调度器组成的 Composer Model，所有功能组件均来自 HuggingFace 的 Diffusers 库。全部模型配置均基于 stabilityai/stable-diffusion-2-base。</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/48/f9/486b11681c17yye18fff51fae55ac2f9.png\" /></p><p></p><p>图三：Diffusion 模型的简化图示。</p><p></p><p>数据： 我们使用的训练数据集为 LAION-5B 的一个子集，其中包括带有纯英文标题且审美得分为 4.5+ 的样本。与 Stable Diffusion 2 base 类似，我们根据训练数据的图像分辨率将训练过程划分成两个阶段。在第一阶段，我们使用的是分辨率大于等于 256 x 256 的图像，总计 7.9 亿个图像 - 标题样本。在第二阶段中，我们仅使用分辨率大于等于 512 x 512 的图像，总计 3 亿个图标 - 标题样本。</p><p></p><p>计算： 两个训练阶段均在 128 个英伟达 A100 GPU 上运行。第一个训练阶段耗时 1.6 天，共运行了 55 万次迭代；第二阶段耗时 4.9 天，共运行了 85 万次迭代，总训练时长为 20051 个 A100 小时。除了训练时间之外，我们还预先计算了 VAE 和 CLIP 模型的潜伏空间，希望减少数据集多次传递所带来的训练时间和成本。潜伏空间计算大致需要额外 3784 个 A100 小时，所以模型的总训练时长为 23835 个 A100 小时。假设 A100 的使用成本为每小时 2 美元，则总价格为 4.77 万美元。</p><p></p><p>技术栈： 我们使用 Composer 作为训练框架，使用 StreamingDataset 来加载 100 TB 训练数据，并使用 MosaicML 平台解决 128 个 GPU 作为训练和评估基础设施时的部署和管理挑战。</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/31/4f/31d7a58eed96739c11c06a864a319b4f.png\" /></p><p></p><p>图四：训练过程中的损失曲线。我们的平台发现了两个硬件故障，并在无人干预的情况下自动完成了重启。损失曲线之所以不连续，是因为第二阶段将分辨率从上阶段的 256 x 256 提高到了 512 x 512。</p><p></p><p></p><h2>挑战与解决方案</h2><p></p><p></p><p>无论是 diffusion 扩散模型还是大语言模型，规模化训练都需要经历一系列重大挑战。我们使用 MosaicML 平台进行 diffusion 模型训练，该平台自动解决了大部分问题，确保我们能专注于训练出最佳模型。下面是规模化训练中的三个主要挑战，还有我们的平台如何加以解决。</p><p></p><h2>基础设施</h2><p></p><p>在大规模数据集上训练大模型无疑需要海量算力。MosaicML 平台能够轻松在任意云服务商处编排数百个 GPU。例如，我们的主训练作业运行在一个包含 128 个 A100 GPU 的集群当中。为了确保评估模型不会拖慢训练速度，我们使用不同云服务商在不同集群的各个检查点上自动启用运行评估，并根据可用性将运行规模收缩至 64 乃至最少 8 个 GPU 上。</p><p></p><p>即使是在训练开始之后，软件或硬件故障也有可能导致训练中断，这就要求 24/7 全天候加以监控。好在 MosaicML 平台的 Node Doctor 和 Watchdog 功能会自动检测故障节点，并根据需要执行恢复操作。通过自动恢复，我们得以从故障中顺利恢复，无需任何人为干预即可继续训练，避免了昂贵的停机时间和人工管理。启动之后，一切无忧！</p><p></p><h2>软件效率</h2><p></p><p>软件配置的优化向来是个大麻烦，好在我们基于 PyTorch 的 Composer 库能够最大程度提高训练效率。跟上一轮实验类似，随着 GPU 数量的增加，Composer 继续保持着出色的吞吐量扩展能力。在本次更新中，我们添加了进一步优化（低精度 GroupNorm 和低精度 LayerNorm，全分片化数据并行）以实现近乎完美的强大扩展能力，将作业最多扩展至 128 个 GPU，从而将成本控制在 5 万美元以内。我们还使用 Composer 的原生指数移动平均（EMA）算法，得以在接近训练结束时（第二阶段的 80 万次迭代中）启用 EMA，从而节约下相当一部分内存和训练算力。</p><p></p><h2>管理 100 TB 数据</h2><p></p><p>我们在训练中使用的是包含 7.9 亿个样本的 LAION-5B 子集，总数据量超过 100 TB。庞大的数据集规模导致其难以管理，特别是在需要配合拥有独立本地存储的多集群情况下。</p><p></p><p>MosaicML StreamingDataset 库让海量数据集的处理变得更加简单快速，该库提供的三个核心功能也在本次训练中发挥了关键作用：</p><p></p><p>将存储在不同位置的数据集混合起来。 我们根据图像分辨率将各样本分别存储在不同的数据集内。在训练时，我们使用 MosaicML StreamingDataset 库将来自各数据集的分辨率素材混合起来。</p><p></p><p>2.即时轮中恢复。 我们能够在一个轮次期间即时恢复训练，这相当于实现了整个数据集在训练过程中的“断点续传”，大大节约了总体用时。</p><p></p><p>3.以弹性方式实现确定性。MosaicML StreamingDataset 库能够以确定性方式混洗数据，且不受训练用 GPU 数量变化的影响。这使我们得以准确重现训练效果，极大简化了调试步骤。</p><p></p><p></p><h2>人类评估结果</h2><p></p><p></p><p>图像生成模型的实际性能往往难以评估，除了投入人力别无他法。在盲测评估中，我们衡量了用户对图像质量的偏好，并在 Stable Diffusion 2 和我们自己的 diffusion 模型间进行了提示词对齐。根据用户偏好，我们得出的结论是两套模型质量相当（参见图五）。所有图像均根据 Imagen 论文中提出的 Drawbench 基准测试揭示词生成。</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/65/4a/65306142dc98020ee67d2da07cda804a.png\" /></p><p></p><p>图五：我们对图像质量（左）和揭示词对齐（右）的人工评估结果。误差条显示的置信区间为 95%。在这两次实验中，两套模型之间的用户偏好差异与衡量的不确定性相当，因此我们得出结论认为两套模型的整体质量也基本相当。</p><p></p><p></p><h2>未来展望</h2><p></p><p>本文向大家介绍了我们这套 diffusion 模型的输出性能和损失曲线，描述了高级模型训练中的种种细节，还有 MosaicML 平台帮助我们解决的规模化训练挑战。但很遗憾，由于 LAION-5B 数据集使用要求和相关法律条款较为模糊，我们暂时还无法对外公布由此训练出的图像生成模型的参数权重。我们很清楚参数权重对于图像生成模型性能的重要意义，但这里只能向大家说声抱歉。</p><p></p><h2>写在最后</h2><p></p><p>下面就是我们这套 diffusion 模型生成的图像结果。团队成员们都玩得不亦乐乎，也希望各位能从中找到属于自己的乐趣。</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/9d/7c/9dde6bf3228601bffcfdb45e8718187c.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/07/22/07acfaca8c183e42b9854fbe8af24e22.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/ca/b1/cacb8690645aa3f057585660476099b1.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/a0/32/a06670e3788e3ff96fcd3b041579fe32.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/01/de/01beafe6f92694ceb8696be3e160bede.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/72/ef/729435936593b3134d804dfd94edb8ef.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/50/ea/50b228476ccf27a381073515c713faea.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/1f/57/1f7267c156c5b93c3d38ce0b4yy3ab57.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/36/25/36624a7501f74d77352065a1ebf4bd25.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/01/22/014df1efa456049921f4a957fea7b622.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/cd/2e/cd488bddbe15e6320548abfd7fb2f22e.png\" /></p><p></p><p>原文链接：</p><p></p><p><a href=\"https://www.mosaicml.com/blog/training-stable-diffusion-from-scratch-part-2\">https://www.mosaicml.com/blog/training-stable-diffusion-from-scratch-part-2</a>\"</p><p></p>",
    "publish_time": "2023-05-03 13:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]