[
  {
    "title": "ZK 训练营第三课：ZKP电路应用导论",
    "url": "https://www.infoq.cn/article/9VrhU74b6JYO9Yk6aeXj",
    "summary": "<p>PrivacyIN隐私学院 (Privacy Institution) 是由LatticeX基金会发起，致力于建设开放的密码和隐私技术布道和研究社区，并联合全球顶尖的学者、隐私技术开发者推动ZK(零知识证明)、MPC(安全多方计算)、FHE(全同态密码)的创新和落地。</p>\n<p>为了推动隐私在下一代多方计算场景中的创新和落地，PrivacyIN隐私学院计划围绕现代密码学技术开展技术培训、研究社区和项目创新孵化。以此降低开发者理论协议应用门槛，提高密码研究人员的工程创新能力，共同维护一个开放的密码隐私技术社区。</p>\n<p>自7月9日PrivacyIN隐私学院首期ZK训练营开课伊始，便收到了几百名密码学爱好者报名参与训练营，PrivacyIN最终遴选出全球不同地区20位同学参与这次丰富、实用、干货满满的密码学实践课程。学生中不乏来自Google Tiktok  推特等知名企业的开发者，亦有来自斯坦福、东京大学、清华等高校的学生。</p>\n<p>本节课程由香港科技大学的韩思远博士以实践为导向，介绍了zkEVM的电路设计技巧，包括程序表达，EVM架构以及zkEVM设计中的优化思路</p>",
    "publish_time": "2022-08-01 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "数据库的发展趋势和技术人的路径｜InfoQ大会早班车第15期",
    "url": "https://www.infoq.cn/article/s9FQYQG6hwfBRW5ExJOl",
    "summary": "<p>本期大会早班车我们主要聊云原生数据库话题，上云已经是大势所趋了，关键是什么样的业务该选用什么类型的数据库？如果自研的话，该如何落地？来听听Google和PingCAP的技术专家的意见吧。</p>\n<p>2022年ArchSummit深圳站即将落地，[点击直达官网]<br />\n(<a href=\"https://archsummit.infoq.cn/2022/shenzhen/track?utm_source=infoq&amp;utm_medium=zaobanche\">https://archsummit.infoq.cn/2022/shenzhen/track?utm_source=infoq&amp;utm_medium=zaobanche</a>)。</p>",
    "publish_time": "2022-08-01 09:54:10",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "腾讯云⼤数据 TBDS 在私有化场景万节点集群的实践",
    "url": "https://www.infoq.cn/article/aHgzGtad4M5X8shuhJEL",
    "summary": "<p></p><blockquote>4 月 15 日-16 日，由 InfoQ 主办的 <a href=\"https://dive.infoq.cn/2022/beijing?utm_source=infoq&amp;utm_medium=conference\">DIVE 全球基础软件创新大会</a>\"通过云上展厅的形式成功召开。在<a href=\"https://www.infoq.cn/video/36VEZEezWd4adMNPiHqL\">腾讯云基础软件创新实践专场</a>\"，来自腾讯云的 TBDS 大数据引擎研发负责人杨鹏程带来了主题为《腾讯云⼤数据 TBDS 在私有化场景万节点集群的实践》的演讲，以下为主要内容。</blockquote><p></p><p></p><p>本次分享主要分为三个部分展开：第一部分是 Hadoop 体系下存算⼀体存在的问题；第二部分是 TBDS 存算分离架构和三层优化；第三部分是云原⽣环境下计算引擎优化和最佳实践，最后是对本次分享内容的总结。</p><p></p><h2>前言</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/57/57f5ae7c337b29066569e334251cd64e.png\" /></p><p></p><p>大数据发展多年以来，总体上根据业务特点主要可以分为四个阶段。</p><p></p><p>第一个阶段是以 Hadoop 体系为代表的存算一体阶段，存算一体顾名思义就是存储和计算部署在一起。Hadoop 就是 HDFS 的 DateNode 节点和 Yarn 的 NodeManager 节点部署在一起的形式。这种模式的好处是计算具有一定的数据本地性，减少了一定的网络 IO，有一定的加速作用，在集群规模较小且节点数较少的时候，每个节点存储分配到的文件相对较多，加速效果比较明显。</p><p></p><p>但是随着集群数据规模和节点的增加，本地加速的优势越来越小，由于集群节点对存储和计算的硬件配置要求都比较高，整体扩容的成本也在增加，HDFS 的 NameNode 元数据扩展性也会产生瓶颈，从而导致集群整体的规模上限也会产生瓶颈。</p><p></p><p>为了解决这个问题，进而催生了第二个阶段，即存算分离阶段。</p><p></p><p>存算分离顾名思义就是存储和计算独立分开部署，各自以分片的方式保证其自身的可扩展性。由于存储资源和计算资源对计算机硬件的配置要求不同，所以生产环境中对计算和存储的需求也在不断变化。</p><p></p><p>集群整体的机器成本，尤其是存储节点机器的成本会比存算一体阶段便宜很多，但存算分离最大的问题是计算节点会通过网络 IO 去远端存储拉取数据进行计算，所以计算速度和效率会比存算一体差很多。这个阶段的存算分离主要还只是一个噱头，或者说是一个概念，很少在大规模生产环境中使用。</p><p></p><p>第三个阶段是数据湖。数据湖解决了业务的多样性以及业务之间数据共享难的问题，比如说用户的一部分结构化数据存储在传统的 MySQL、Oracle 这类关系型数据库中，另外一部分统计的数据存储在 Hive 数仓里。</p><p></p><p>当 Hive 数仓想使用关系型数据库的数据进行 JOIN 关联查询就比较困难，这时候就需要通过 CDC 或 OGG 的方式让传统数据库中的数据实时入湖，在数据湖里用统一的表格式，比如说 Iceberg 或 Hudi 来提供数仓及上层来进行共享计算，总体上是为上层制造了一种更为融合的方式。</p><p></p><p>最后一个阶段就是云原生。云原生的目的是运用多个弹性的计算资源。，计算资源可以快速被申请和创建，但不必关心整体的调度细节以及调度过程中的容错、迁移、重建等一系列操作，这就是基于云原生的存算分离模式。像云数仓这种服务越来越火，存算分离也借助与云原生和缓存加速真正实现大规模生产实践的落地。</p><p></p><h2>Hadoop 体系下存算⼀体存在的问题</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d1/d1b838cb57c0f92ab50c3ea74c513460.png\" /></p><p></p><p>先来看一下 HDFS NameNode 的内存结构，其主要分为四个部分，左边是 Namespace 和 BlockManager，右边是网络拓扑和一些其他结构。</p><p></p><p>Namespace 维护了整个文件系统的目录结构。与 Linux 单机的文件系统类似，HDFS 文件系统的目录结构也是按照树状结构维护的，而且是一个非常巨大的树，树的叶子节点是 INodeFile 结构，这个结构里存储了文件所在 Block 块的引用。除了在内存常驻以外，部分数据也会定期 flush 到磁盘里，生成一个叫 FSImage 的文件，方便 NameNode 发生重启时从 FSImage 恢复整个 Namespace，集群中的目录和文件的总量就是整个 Namespace 目录树中包含节点的总数，这块内存也会随着集群内文件和目录个数的增加而成比例增长。</p><p></p><p>BlockManager 维护了整个文件系统中与数据块相关的信息以及数据块状态的变化，核心有两个结构，一个是 BlockInfo 数组，另外一个是 BlockMap 的链表结构。BlockInfo 维护了 Block 块的元数据信息，Block 块数据本身的信息是由 DataNode 管理的，所以 BlockInfo 需要包含实际数据到 DataNode 的管理信息。</p><p></p><p>BlockMap 是一个链式解决冲突的哈希表，可以通过BlockId 的哈希值快速定位到 BlockInfo，这块内存也会随着集群内的文件个数以及大小的增长而成比例增长。</p><p></p><p>然后就是网络拓扑结构，网络拓扑结构维护着整个机架的拓扑以及 DataNode 的基本信息，整个机架的拓扑结构在 NameNode 的生命周期内一般不会发生变化，即使扩容到上千个节点规模的集群，用的内存也是比较小的，也比较固定，不会随着集群文件个数的增长而变化。</p><p></p><p>第四部分就是其它一些小的内存，比如说 LeaseManager 存储了读写互斥锁的同步信息，像 CacheManager 主要是支持集中式的缓存管理，实现 MemoryLocation 的速度性能提升，还有 SnapshotManager 用于管理数据的备份回滚以及防止用户误操作导致集群出现的一些问题。</p><p></p><p>当然还有 DelegationTokenSecretManager，主要管理 HDFS 之中的一些密钥访问，这些结构所使用到的内存都是比较小的，而且不会随着集群和文件个数的增长而变化，总体上来看，左边部分的内存会随着集群规模的增长而不断的增长，而且占用的内存非常大，而右边的部分占用内存比较小，且比较固定。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/93/93f0cb1b5b8b04ae7bc01b9a9ca3098b.png\" /></p><p></p><p>NameNode 文件系统的元数据及块信息的位置基本全部存放在内存中，所以会面临着常驻内存随着数据规模的持续增长，内存逐渐增大的问题，TBDS 在私有化客户项目中获取的经验值是大概一亿个文件 NameNode 占用 100 GB 左右的内存。</p><p></p><p>HDFS 面临三个主要的问题：</p><p></p><p>第一个是 NameNode 元数据的扩展性问题，随着数据规模和内存使用的逐步增大，对 NameNode 内存的要求也越来越高，需要定制大内存的机器，内存的大小也限制了集群的扩展性。</p><p></p><p>对于硬件，京东的 NameNode 采用了 512 GB 内存的机器，字节跳动的 NameNode 采用了 1TB 内存的机器，此外，因为 NameNode 对内存分配巨大，所以对 GC 的要求也比较高，JVM 相关的处理能力已经达到了比较高的水准，大厂可以定制 JDK 的开发，保证大内存场景下 GC 性能良好，但是一般规模的公司不具备 JDK 的维护能力，所以不具备普遍性。</p><p></p><p>像字节跳动把 NameNode 修改成 C++ 的版本，这样分配内存和释放内存都由程序自己控制，而不是用 JVM，也能达到非常不错的性能，但是这种操作也不具备普遍性，因为开发和维护 C++ 版本的 NameNode 也需要不小的投入。</p><p></p><p>第二个就是块汇报的风暴问题，HDFS 的块默认大小是 128 MB，启动几百 PB 数据量的集群时，NameNode 需要接收所有块汇报的信息，之后推出了安全模式，因此启动的时间也会随着块大小和块数量的增加而延长，有时候会达到数个小时。集群的全量块汇报和 Balance 操作也会对性能造成一定影响，根本的原因是 DataNode 需要把所有的块汇报给 NameNode。</p><p></p><p>第三个就是全局锁问题，NameNode 有一把 FILESYSTEM 的全局锁，每个元数据在请求更新时都会加这把锁，虽然是读写分开的，但是这部分流程以及对该锁持有的范围会随着并发量的增长而持续增大。同时 FILESYSTEM 内部的 FSDirectory 的 INode 树也会存在一个单独的锁，用来保护整个树以及 BlockMap 的修改。</p><p></p><p>TBDS 从私有化客户处获取的经验值是 NameNode 一旦超出了 150 G 内存，或者集群整体的文件规模数量达到 5 亿时就开始新建集群，但是新集群和旧集群的数据是不通的，集群之间就会形成数据孤岛。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b8/b80a553005ff2945315e9b80614abbfe.png\" /></p><p></p><p>思考一下访问 HDFS 文件需要什么？需要一个 HDFS&nbsp;client，不管是命令行的 client 还是 FILESYSTEM 这种加 API 的 client，除了 client 还需要知道 HDFS 集群 NameNode 的 RPC 通讯 IP 和端口以及认证信息，这些信息通常会保存在 HDFS 的 core-site 配置文件里。</p><p></p><p>只需要一个 HDFS client 加上不同孤岛集群的 core-site&nbsp;HDFS 配置文件，就可以达到用一个 client 端访问不同的集群数据的目的，只不过访问不同的集群，每一次都要替换对应集群的配置文件，将不同集群的配置文件信息汇总合并成一个配置文件，就可以用同一个 client 和同一个配置文件访问不同的集群了。</p><p></p><p>不过这也引入了新的问题，就是不同集群的 HDFS&nbsp;schema&nbsp;Namespace 的名字不同，文件路径上看到的还是割裂的。为了解决这个问题，HDFS 社区提出了在 client 端用 ViewFs 挂载表统一管理多个 HDFS Namespace 路径的映射关系，让不同集群的文件路径和 schema 都统一成新的 ViewFs，这就是 HDFS&nbsp; Federation 的联邦模式。</p><p></p><p>但是这种方式是 Client Side 的模式，对 client 端的访问方式变化很大，协议由 HDFS 变成了 ViewFs，另外子集群的信息是以挂载表的方式配置在 client 端，一旦集群发生了机器的迁移变更，所有的 client 端配置都要修改。</p><p></p><p>在这种情况下，尤其是在私有化场景中，引导客户去升级和维护的成本都非常大，基于这种考虑，HDFS 社区在后来的 2.9 版本上又提出了基于 Router 的联邦模式，主要的目的是引入一个 Router 服务管理路由的挂载表，对外由 Router 提供 client 端的 HDFS 协议解析和访问，来代替 ViewFs 协议，达到了向前兼容的目的。</p><p></p><p>Router 把路由表的配置信息放在 StateStore 的分布式存储上，比如 ZK，让 Router 可以平行的无状态地扩展，Router 根据 client 请求中文件的路径到路由表中进行匹配，计算出实际要由哪个子集群处理。</p><p></p><p>其中把 client 的路径转化成子集群实际处理的路径，Router 自己会启动一个 HDFS 的 client 把这个请求转发给具体的子集群，同时有一个 ClientManager 的结构保存所有 client&nbsp;的 Router 以及 Router 到具体每个子集群 NameNode 连接池的信息，保证具体子集群处理完请求的 response 之后，能够经过 Router 返回给 client。</p><p></p><p>TBDS 是基于 Router 的联邦方式，解决了 HDFS 的多集群数据孤岛问题，让集群之间的存储能够互通，当然我们也在 Router 上做了很多新的功能以及性能上的优化。</p><p></p><p>一般在 Hadoop 集群上绝大多数业务都是通过 Hive 库表的方式去访问 HDFS 存储，比如最常见的离线数仓，解决了数据存储的孤岛问题还不能让业务进行跨集群的连通访问，还要解决 Hive 库表的跨集群连通。</p><p></p><p>TBDS 是基于 HDFS&nbsp;Router 的思想自研了 HiveMeta 的 Router Federation 联邦，实现了跨集群 Hive 元数据的连通统一，HiveMeta Router Federation 实现了 Hive&nbsp;Metastore、库表大部分常见的 thrift 协议以及 SQL 语法解析，向 HiveServer2、Presto、Spark 等计算引擎提供了 HiveMeta 服务。Router 本身是根据数据库的前缀管理多个子集群 Hive Metastore 实例的路由表，路由表的信息也是配置在 ZK 里的，Router 根据请求中的数据库名查询路由表，根据前缀进行匹配，计算出它实际要路由到哪个子集群的 Hive Metastore 进行处理，同时把库名的前缀去掉并转发到具体子集群的 Hive Metastore 进行处理，这样就实现了 HiveMeta 层库表元数据的联邦统一。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f7/f7ad0d55d89da69e9d73162b9ea62360.png\" /></p><p></p><p>我们通过 Federation 解决了数据和库表元数据的孤岛问题，让上层应用基本可以无感知底层的变化而实现跨集群的数据互通，但 Federation 也有一些问题。</p><p></p><p>第一个是它增加了数据访问的调用链路，所有的 HDFS 和 Hive Metastore 请求都要经过 Router 的代理转发。虽然 Router 本身的逻辑比后端 HDFS 和 Hive Metastore 轻量，它只实现一些 Proxy 转发逻辑，但还是增加了对系统整体稳定性和耗时的影响，尤其是在进行大量 shuffle 作业时。</p><p></p><p>当然我们也对 Router 的 HA 高可用及性能做了一些优化，我们对社区的 Router 进行压测，发现大部分 handler 时间都花在 RPC 的 response 返回阶段，而在这个阶段中，大部分时间又花在了加密操作上。因为 RPC 的 response 返回的处理都是在 handler 的资源里实现的，比较繁重且占据了大量资源，它影响了整体的 RPC 处理。我们将相关处理操作从 handler 中分离出来，放到了另外一个线程中进行异步化处理，从而使得 handler 资源能够尽早释放。</p><p></p><p>第二个是社区采用 Kerberos 认证，在高并发场景下，其加解密的操作会非常耗时，我们把Router 的 HDFS 认证改成了 TBDS 的 SecretId 和 SecretKey 的方式，优化后整体的耗时比直连 NameNode 多了 4%。同时我们把 handler 的并行处理能力也提升了几倍，整体相比没有经过 Router 处理的时候，性能的差距基本可以持平。</p><p></p><p>联邦架构只是多了一层 Router 代理，它没有根本性的改变原来存算一体的架构，本来联邦中每一个集群的规模和节点数已经基本达到了红线，对 JVM 的要求也达到了很高的标准，HDFS 集群和 Yarn 的混布，也加大了计算节点和存储节点相互影响的风险。而且我们在客户的生产环境上也确实遇到了相关问题，如 DataNode 为了提高处理能力，抢占系统线程数过多导致 NodeManager 分配不到线程处理任务，进而出现 NodeManager OOM 的情况，这整体加大了系统的不稳定性，所以说联邦还是在逻辑上实现了扩展，并没有打破物理上独立分片扩展的瓶颈。</p><p></p><p>第三点是资源成本，联邦很容易造成新建集群中存储的都是热数据的情况，导致出现冷热集群两种状态，老集群的计算资源出现大量闲置，需要通过统一进行库的划分或者动态迁移数据来调整所有集群的整体均衡性，这样又增加了系统整体的复杂性，导致运维成本较高。</p><p></p><p>在生产环境中，不同的时间段，存储和计算的需求往往也是不同的，是弹性变化的。联邦后面的每一个物理集群节点的规模都比较大，机器硬件配置也比较高，计算或存储资源任何一个不足都需要整体扩容，导致资源成本的代价非常高。主要基于后面两点的考虑，我们开始向基于云原生存算分离的架构演化。</p><p></p><h2>TBDS 存算分离架构和三层优化</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/00/00ac2c7f4fd2544e741dbbdb401b9c41.png\" /></p><p></p><p>通过前面存算一体提出的问题以及存算分离的简单的介绍，我们从三个核心点设计和考虑我们的存算分离架构，主要是核心扩展性、海量存储计算速度和云原生。</p><p></p><p>核心扩展性主要指存储、元数据和调度计算的独立物理扩展性，扩展性能需要达到上万节点规模的能力；海量存储计算速度主要是为了解决存算分离引起的大量网络 IO 问题，通过缓存加速等手段可以实现数据的本地性能能力；云原生主要是指计算和调度依赖 Kubernetes 提供的云原生能力，实现弹性计算以及自动容错。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/34/34a686d9e14ba246192b24b1d6351757.png\" /></p><p></p><p>上图是 TBDS 存算分离的大致架构图，主要是存算分离底座部分去掉了应用层，像数据管理、一站式数据开发、数据治理、数据报表分析及上层工具等。我们只看核心组成，这个架构图可能和其它类似的大数据架构图不太一样，区别主要在于存储层，在存储层和计算层中间加了一个元数据层，计算层又分成了计算资源层、计算加速层和计算引擎层。</p><p></p><p>这样设计的原因是把可扩展性的核心交给了存储层，因为实现存储层的扩展性难度是最大的，所以只要存储层是可扩展的，其上面所有层理论上都是可扩展的，或者说是比较容易扩展的，其它上层的东西都可以通过分布式方案解决。</p><p></p><p>我们的存储层主推腾讯自研并贡献给 Apache 社区的 Ozone 对象存储，Ozone 在文件的元数据架构上通过拆分以及 Raft 分布式的方案解决了 HDFS&nbsp;NameNode 元数据中央节点无法扩展的问 题。</p><p></p><p>因为 TBDS 用于私有化场景，考虑到客户的实际情况，我们存储层也支持像亚马逊的 S3、阿里的 OSS、华为的 OBS 这种支持标准对象存储协议的存储方式，当然存储层架构治理同时也兼容了老的 HDFS 文件系统存储。在解决了存储层的扩展性问题后，元数据层再将存储层中一个个的文件组织成一个个的数据表，提供给上层的计算引擎。</p><p></p><p>应用的查询需要在不同的计算引擎上做选择，大数据领域里没有一个万能的计算引擎，不同的计算引擎擅长不同的领域，所以元数据层不是一个统一的一种表格就可以满足所有的场景，而是针对不同的场景，不同的情况，选择不同的计算引擎，甚至会使用不同元数据格式的数据。</p><p></p><p>我们的元数据层支持像 Iceberg、Hudi 这种面向数据湖的表格，也支持像 Parquet/Orc 这种传统的 Hive 数仓的表格式，当然还有一些没有列出来的，比如像 Flink 这种实时计算的动态表格式。</p><p></p><p>元数据层最常用的就是 HiveMeta 这种表格式的管理，然而在海量扩展性存储的场景下，由于 HiveMeta 本身没有元数据采集能力，并且 HiveMeta 用于存储数据的 MySQL 是以主备方式部署的，整体的扩展性和性能在高数据量级的情况下会产生瓶颈，基于以上考虑，我们自研了一个叫统一元数据的服务，统一解决元数据层的扩展性问题，它也同样支持了大部分 HiveMeta 的标准协议。</p><p></p><p>计算资源层支持 Kubernetes 的计算调度和 Yarn 的计算调度，由于 Kubernetes 与 Hadoop 生态及其配套工具还有某些计算引擎存在一些不适配的地方，我们根据不同集群的不同物化的计算引擎去 Kubernetes 和 Yarn 上面做选择。我们整体是往云原生方面发展，计算引擎也越来越多的往云原生上开发适配。计算加速层我们采用 Alluxio 作为计算引擎到存储引擎之间大量网络 IO 的缓冲纽带，Alluxio 带来的数据本地性让上层应用可以享受更快的速度。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/48/4814df0d5ac7f2700a63ee44defcd8a1.png\" /></p><p></p><p>接下来逐层看一下我们目前做的设计和优化。首先对于存储层，最核心的点就是可扩展性，尤其是大规模节点环境下的可扩展性，相比较 HDFS，Ozone 把 Namespace 元数据服务和 BlockManager 拆分成了两个服务。</p><p></p><p>Ozone&nbsp; Manager 负责元数据服务，管理 Ozone&nbsp;Namespace，提供所有 Volume、Bucket 以及 Key 的新建、更新和删除操作，存储 Ozone 的元数据信息，这些元数据信息包括 Volumes、Bucket 和 Key，底层通过 Raft 协议扩展元数据的副本，实现了元数据的 HA 和无限的扩展性。</p><p></p><p>Storage&nbsp;Container&nbsp;Manager 主要负责数据块管理、节点管理以及副本的冗余管理，类似于 HDFS 中的 BlockManager 模块，它管理了 Container、Pipeline 还有 DataNode，为Ozone&nbsp;Manager 提供 Block 以及 Container 相关操作的信息。这个模块同时也监听了 DataNode 发送过来的心跳信息，作为 DataNode&nbsp;Manager 的角色，保证和维护集群所需要的数据冗余级别。</p><p></p><p>这两个服务都可以独立部署在多台机器上，各自利用各自的机器资源，Ozone 的元数据不存储到内存中，不管是 Ozone&nbsp;Manager 的元数据，还是 Storage Container Manager 中的Container 信息，都是在 RocksDB 中存储维护的，极大降低了对内存的依赖，理论上元数据都是可以无限扩展的。</p><p></p><p>Storage&nbsp;Container&nbsp;Manager 无须管理默认 128MB 的 Block 信息，它只需要管理默认 5 GB 的 Container 信息，可以极大的减少数据管理的成本，从而提升自身服务性能。</p><p></p><p>因为 Storage&nbsp;Container&nbsp;Manager 是以 Container 的方式作为块的汇报单位，汇报数量比 HDFS 大大减少了，无论是全量汇报还是增量汇报，整体都不会对 Storage&nbsp;Container&nbsp;Manager 的性能造成很大影响。DataNode 是 Ozone 的数据节点模块，它以 Container 为基本存储单元，维护每一个 Container 内部的数据映射关系，它会定时向 Storage Container&nbsp;Manager 发送心跳并汇报节点信息，同时管理着 Container 和 Pipeline 等信息，DataNode 也是以 Raft 协议的方式实现了一致性的扩展。</p><p></p><p>Ozone&nbsp;Manager 内部的锁是 Bucket 级别的，可以达到 Bucket 级别的写并发，因为 Ozone 是对象存储，对象存储的语义不存在目录和树之间的关系，因此也不需要维护全局的文件系统树，并且可以达到很高的性能吞吐。Ozone 的优势是同时支持 HDFS 和对象存储双层语义，它支持 CSI 协议让 Kubernetes 集群去挂载，也支持标准的 S3 协议。通过压测得出其整体性能和 HDFS 差不多，但稳定性要好很多，尤其是在节点数量达到千台以上规模的情况下。当然对象存储也存在天然的劣势，因为没有 HDFS Namespace 这种庞大的目录树，所以在执行 List 这种操作时会特别耗时，代价也非常高。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/74/7482032c1175f3f570e1f4ed30aa6e66.png\" /></p><p></p><p>接下来看计算资源层，由于我们的存算分离主打的是云原生，这里主要说的是基于 Kubernetes 的计算资源层。</p><p></p><p>在扩展上，Kubernetes 可以快速弹性的支持节点的上下线，但官方表示单个 Kubernetes 集群最大节点数为五千个，虽然五千个节点已经非常多了，但对于腾讯内部的大数据集群，单租户就已经达到了数万个节点，而且私有化场景下，一些行业的头部客户未来的数据量也会逐步增大。万节点是一个越来越现实的诉求，所以五千个节点的限制对于 Kubernetes 集群的扩展性也是一个较大的瓶颈，同时 Kubernetes 的调度性能与 Yarn 有数量级的差距。</p><p></p><p>根据压测，Kubernetes 在一千个 Pod 每秒的调度情况下性能有严重下降，难以支持大规模的数据调度场景，除了调度之外，在超大规模集群的高并发场景下，apiserver、etcd、监控、日志等都会存在明显的瓶颈，这些都是需要解决的问题，因为 Kubernetes 的节点和 Pod 的状态信息都存在 etcd 里。Kubernetes 除了通过 ListAndWatch 的事件监听方式感知 Node 变化外，也会定时从所有 Node 节点查询更新事件。五千个节点的限制主要是因为 etcd 的性能限制，尤其是在 etcd 进行大量并发查询的情况下。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e7/e7315b666195f676e43c305cf83c4b8a.png\" /></p><p></p><p>我们针对原生 Kubernetes 的节点扩展限制以及调度能力上的瓶颈自研了统一 Kubernetes 调度引擎来优化解决这个问题。首先我们有一个租户集群 logical cluster，租户集群对外相当于一个 Kubernetes，它是用户提交任务的入口，提供了和 Kubernetes 标准一样的 apiserver、controller、以及 scheduler 调度器，不过这里的调度器是我们自研的 mg-scheduler，引入了批量调度，实测比原生 Kubernetes 的调度能力快了 10 倍以上，租户集群有很多虚拟的逻辑节点，和租户集群底层管理的 Kubernetes 物理集群的节点是一对一的映射关系。</p><p></p><p>也就是说租户集群的虚拟节点总数是其所管理物理 Kubernetes 集群节点数之和，之所以叫虚拟逻辑节点，是因为租户集群的节点只同步物理集群的 Node 配置以及状态信息用来做展示，并没有责任去维护后面物理 Kubernetes 集群的 Node 健康状态等信息，Node 的健康状态等信息还是由物理 Kubernetes 集群负责维护。</p><p></p><p>更新物理 Kubernetes 集群 Node 信息的频率我们控制的很低，一般是 15 分钟一次，后面可以调整的更低。租户集群更新节点的事件会被过滤掉一大部分，只选择小部分重要事件进行变更，所以虽然租户集群管理的存储节点规模很大，但对于租户集群的压力尤其是 etcd 的压力是很小的，这也是它能维护上万节点，高性能的原因。</p><p></p><p>中间是自研调度引擎的 Meta Cluster 层，Meta 层主要对租户集群做了一些管控，比如通过cluster-controller 模块可以创建新的租户集群，通过 syncer 模块进行信息同步，它将租户集群的虚拟 Pod 信息及 Pod 依赖的 ConfigMap、Secret、PV/PVC、Volume 等资源对象同步到物理集群。</p><p></p><p>此外 syncer 还将 Node、Pod 的状态信息从物理集群同步到租户集群，并且通过ListAndWatch 机制把物理集群的 Node/Pod 的创建销毁事件及时上传到租户集群。</p><p></p><p>proxy-apiserver 给调度器提供了统一的 Node 视图，因为租户集群的节点可能来自于多个不同的物理 Kubernetes 集群，通过 proxy-apiserver 提供统一的 API 访问入口去访问物理集群。</p><p></p><p>最下面就是物理 Kubernetes 集群，配合我们的统一 Kubernetes 调度引擎，它具备管理千万核资源的能力，具有较高的扩展性，底层物理集群可以水平扩展，不影响性能。</p><p></p><p>租户集群有强隔离性、高安全性、高定制性的特点，同时支持原生 Kubernetes 接口，资源可以弹性扩展，支持上万节点的集群规模，腾讯内部单个租户集群最大已经有三万个节点，我们的自研调度器可以达到每秒 5500 个 Pod 的调度能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a6/a6776125a3746eb39d7e122d996a4ccb.png\" /></p><p></p><p>上图是经过自研调度器提交任务启动 Pod 的时序图，用户提交 Pod 创建任务到租户集群，租户集群的 controller-manager 开始创建 Pod，mg-scheduler 调度器会调度 Pod 到具体某一个底层物理 Kubernetes 集群的某个节点上，如果这个节点在租户集群上还没有被创建，syncer 模块会将这个节点以虚拟节点的形式创建出来，并且定期同步物理集群的 Node、心跳等信息到租户集群，这个时间周期可以设置的很短。</p><p></p><p>syncer 模块发现如果底层的物理集群还没有创建 Namespace，它会创建一个租户集群 Namespace，但由于可能存在多个租户集群，Namespace 可能会冲突，这里会统一给租户集群的 Namespace 在底层的物理 Kubernetes 集群映射的 Namespace 上加一个前缀，保证全球唯一，避免冲突。</p><p></p><p>接着 syncer 模块会创建 Pod 依赖的 Secret、ConfigMap、Volume 等对象并同步到底层的物理 Kubernetes 集群上，然后就可以创建底层同名的 Pod 并修改 Pod 里面的一些属性，比如说对象属性，加一些前缀保证唯一性等操作。</p><p></p><p>底层物理 Kubernetes 集群的 kubelet 就会运行这个 Pod，最终syncer 感知到物理集群的 Pod 状态发生变化，就会把 Pod 的状态和 Event 事件同步到租户集群上，租户集群上的 client 用户就能收到这个 Pod 的状态，这就是通过自研调度器提交 Pod 运行任务的流程。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/20/20b30ff2d9607684b03e0d17601f0a38.png\" /></p><p></p><p>接下来就是计算加速层的优化，我们引入了 Alluxio 做计算加速。这里主要讲解一些使用场景上的优化，Alluxio 提供主动和被动两种方式获取数据，主动方式即预热的方式，比如在离线数仓场景，用户可能有很多周期性任务，比如金融系统需要每天统计账单数据，电网系统可能每天要统计电量用量的分布，这些任务周而复始，需要按天甚至按小时进行计算，我们可以在跑任务之前，主动把 Hive 表中的数据加载到 Alluxio 的 Cache 里进行计算加速。</p><p></p><p>由于周期性的任务业务逻辑可能很多，而且 Alluxio 的 Cache 空间有限，全量获取 Cache&nbsp;Hive 表可能导致 Alluxio 中的数据频繁进行数据淘汰，这样加速效果难以达到理想状态，而且周期性任务的表往往会按照周期性进行分区的 partition，比如按天或按小时进行分区。</p><p></p><p>我们利用 Alluxio Prefix Level 的预热能力可以提前按照表的分区级别设置前缀，让数据加载到 Alluxio 的 Cache 里，并且将数据和周期的调度时间按比例设置 TTL 过期时间，保证分区内数据可以在计算完成后迅速过期，给 Alluxio 腾出更多空间来缓存最重要的数据。</p><p></p><p>被动方式是当计算引擎需要相关文件的 Block 并且向 Alluxio 申请时，发现本地 Cache 里不存在，Alluxio 会马上从底层的 UFS 同步数据，以访问相应 Block 的内容，并且 Cache 到 Alluxio 的 Worker 节点中，这种被动的方式第一次比较耗时，但对于后续计算要重复使用的热数据，也有明显的加速效果。</p><p></p><p>另外之前提到了对象存储的 List 操作，它需要遍历，是非常耗时且代价较高的 API。List 操作是计算引擎经常用到的命令，Alluxio 也提供了元数据的 Cache 能力，我们可以把元数据 Cache 到 Alluxio 里以减小 List 操作带来的耗时和代价，提升 Metadata 的访问性能。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fb/fbfc4babf01f8fc1615959b06905b18a.png\" /></p><p></p><p>上图是 Alluxio 部署在 Kubernetes 计算层一个典型的存算分离场景。简单说就是 Alluxio&nbsp;Worker 部署在和执行计算的这个 Pod 节点相同的宿主机上，计算引擎如 Spark、Presto 都有 Master 和 Worker 属性的不同的 Pod，Alluxio&nbsp;Worker 部署在 Spark 的 Executor 或者 Presto 的Worker 节点相同宿主机的 Pod上，为了让 Kubernetes 集群所有的 Node 调度资源均衡。我们采用了 DaemonSet 的方式部署 Alluxio&nbsp;Worker 的 Pod，保证每一台宿主机节点都能提供数据的本地加速。</p><p></p><p>Alluxio Master 通过 StatefulSet 模式部署，因为 Alluxio Master 需要稳定且唯一的网络 ID 来应对容灾等复杂场景。并且 Alluxio Master 是以 Raft 的方式支持多副本的高可用 HA。</p><p></p><p>Alluxio Fuse 也可以通过 DaemonSet 方式部署，并且它可以和 Alluxio Worker 通过 PodAffinity 进行绑定，这样可以达到数据的亲和性，Fuse 主要使用在 AI 场景，它可以通过 Mount 文件到业务的方式直接读取文件，业务端就不需要感知和考虑 Alluxio 数据端的部署模式以及 Pod 的位置，当然 Alluxi 也支持 CSI 这种方式的 Mount。</p><p></p><h2>云原⽣环境下计算引擎优化和最佳实践</h2><p></p><p></p><p>下面讲解实践中计算引擎的优化，主要以 Spark 计算引擎为例。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d7/d714566cca372f0c2c085a3cd170a207.png\" /></p><p></p><p>先看一下 Spark 在物理集群中常见的工作流状态。首先通过 Spark submit&nbsp;client 提交运行一个 Spark&nbsp;job 到 Yarn 或者 Mesos，接着 Yarn 或 Mesos 分配一个 Worker 节点作为 Executor 给 Spark&nbsp;client，Spark client&nbsp;会从 Worker 节点起动 Spark&nbsp;Executor 并且在 Executor 里起动一个物理执行计划的Task 任务。Spark&nbsp;Executor 的每一个 Task 都要从远端的 Ozone 或者 S3 这种对象存储访问数据并进行计算，这种模式的计算都是通过网络 IO 从远端访问数据，整体的网络时延和 IO 都会影响整体的计算速度。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c7/c7f40c8b3fd60036d8c0145acee7bd91.png\" /></p><p></p><p>上图是在物理机上 Spark 经过 Alluxio 加速计算的流程，通常会把 Alluxio 的 Worker 节点和 Yarn 的 Worker 节点部署在一起，达到数据本地性的加速效果。相比于未经过 Alluxio 加速计算的流程，这里的 Yarn 在分配 Executor 节点时策略会有所不同。</p><p></p><p>首先 Spark client 里的 Alluxio&nbsp;client 会到 Alluxio 的 Master 节点查找本次计算要访问的文件的 Block 具体在那个Alluxio&nbsp;Worker 节点，拿到 Alluxio Worker 节点主机的 Host 地址之后，Spark&nbsp;client 会带着这个 Host 地址去 Yarn 或 Mesos 上要求在这个 Host 的宿主机节点上分配 Spark Executor 节点，并且启动 Task 任务。</p><p></p><p>Spark&nbsp;Executor 里面的 Alluxio 通过短路读的方式或者 Local&nbsp;Domain&nbsp;Socket 的方式去访问 Worker&nbsp;Cache 里具体文件的 Block。这里的 Local&nbsp;Domain&nbsp;Socket 和 RPC 的 Socket 通信方式不同，RPC 的通信方式是需要对端的 IP 和端口建立 Socket&nbsp;fd，而 Local&nbsp;Domain&nbsp;Socket 是通过本地文件系统的文件路径去创建 Socket fd，不会经过网络协议栈。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4d/4d3454932c550b8dc7ed9b0a708e8a64.png\" /></p><p></p><p>不过在物理机上经过 Alluxio 加速的模式放在 Kubernetes 上部署会有一些问题。首先 Alluxio&nbsp;Worker Pod 的 Host 是在 Kubernetes 集群里分配的，与所在宿主机的 Host 是不同的，这就导致无法通过Pod 的 Host 分配 Spark&nbsp;Executor 到数据就近的 Pod，在实践中可以通过配置 Pod 的 hostNetwork 属性为 true，让这个 Pod 共享宿主机的 Host 来解决这个问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ae/ae6920c83ef515966f3be7236ceb726b.png\" /></p><p></p><p>这样又引入两个新的问题，第一个是 Spark 的 Executor Pod 的 Host 和宿主机的 Host 不一样，这里同样需要让 Spark Executor 的 Pod 开启 hostNetwork 属性为 true，才可以以物理机 Host 的方式分配和 Alluxio&nbsp;Worker 同一物理机的节点来进行本地计算。</p><p></p><p>第二个问题是即使能让 Alluxio&nbsp;Worker 和 Spark&nbsp;Executor 分配到同一个宿主机上，但是因为 Alluxio 的 client 只能通过短路读或者 Local&nbsp;Domain&nbsp;Socket 的方式去访问，而 Pod 之间的文件系统又不互通。虽然可以通过 Volume Mount 的方式共享宿主机文件，但具体要访问的文件的路径和目录也是动态变化的，而且存储的文件相对比较大，所以 Volume Mount 的访问方式是很不稳定的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5a/5a5bc2d111618a68fd58450ecf7b037a.png\" /></p><p></p><p>实践后得出的解决方法是让 Alluxio&nbsp;Worker 通过挂载 hostPath Volume 的方式共享 Domain Socket 到宿主机，比如挂载到 /opt/domain 这个路径，由于每个 Alluxio&nbsp;Worker 在 Kubernetes 里都有唯一的 Pod UUID，我们把 Pod 的 UUID 挂载到 /opt/domain 路径下，具体的文件就变成了 /opt/domain/UUIDA，Alluxio&nbsp;client 会到 Alluxio&nbsp;Master 询问文件的 Block 所在的Alluxio&nbsp;Worker 的 Pod。</p><p></p><p>Alluxio&nbsp;Worker 会把自己的 Local&nbsp;Socket&nbsp;Domain 通过 Master 发 给 client，Alluxio&nbsp;client 就可以在宿主机上通过匹配 UUID 的方式查找到 Worker 的 Domain&nbsp; Socket 文件，也就是 /opt/domain/UUIDA。匹配到具体要查找的宿主机并且在这个宿主机上分配具体的 Spark&nbsp;Executor 并启动任务，Spark&nbsp;Executor 同样挂载到和 Alluxio&nbsp;Worker 一样的 HostPath&nbsp;Volume 路径，Spark&nbsp;Executor 里面的 Alluxio&nbsp;client 就可以通过 Domain&nbsp; Socket 的方式去访问这个路径的文件，进行本地数据计算加速。</p><p></p><h2>总结</h2><p></p><p></p><p>本次分享主要分为三部分，第一部分提到了存算一体的扩展性问题及产生原因，我们可以通过增加集群的方式进行解决，但增加集群同时带来了新的数据孤岛问题，为了解决数据孤岛问题，我们又引入了联邦集群解决方案，但联邦集群存算分离的架构也依然不够完善。</p><p></p><p>所以第二部分中基于云原生的存算分离架构应运而生，这里讲到存算分离的三层架构以及如何解决存储层的扩展性问题、如何解决 Kubernetes 层的扩展性问题以及如何使用 Alluxio 进行加速计算。</p><p></p><p>最后一部分讲解了 Spark on Alluxio Kubernetes 的最佳实践与优化。</p>",
    "publish_time": "2022-08-01 10:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "机器学习工程化，企业AI的下一个起点",
    "url": "https://www.infoq.cn/article/ipYGCdLZ7O1ON8opTH17",
    "summary": "<p>机器学习在行业中的应用变得越来越流行，从而成为了软件开发的常规武器。行业的关注点，也逐渐从机器学习能做什么，过渡到如何有效地管理机器学习项目的交付流程上来。</p><p>&nbsp;</p><p>然而相对于传统软件开发，例如Web服务或者Mobile应用来说，这类程序的开发、部署和持续改进也更加的复杂。但好在经过不断的实践，行业总结出了一套敏捷的工程化流程，供大家在持续交付时遵循和参照。</p><p>&nbsp;</p><p>在Thoughtworks 技术雷达峰会上，徐昊就《机器学习的工程化》发表了主题演讲，InfoQ也借此机会对徐昊进行了采访，进一步探讨了该主题。本文根据演讲和采访内容整理而成，有删节。</p><p>&nbsp;</p><p>采访嘉宾简介：</p><p>徐昊，Thoughtworks中国区CTO。Thoughtworks全球技术策略顾问、中国区首席咨询师，同时也是北京Java用户组（BJUG： Beijing Java User Group）和Agile China创始人。他从2003年起开始实践极限编程等敏捷方法，2005年开始，多次以敏捷教练的角色帮助国内外多个团队实施极限编程。他在Scrum和FDD等敏捷方法、以及敏捷交付和敏捷项目管理等方面的经验极为丰富。目前，他主要致力于大规模团队（300-500人）内的敏捷实践和管理再造，以及对企业级技术应用趋势和技术战略的研究。</p><p>&nbsp;</p><p></p><h2>为什么我们需要“机器学习工程化”？</h2><p></p><p>&nbsp;</p><p>数据都是一个企业的真正资产，未来企业都应该是数据驱动的。数字化转型潮流中，企业因担心跟竞争对手拉开差距，更为普遍地将机器学习应用到了各种业务场景中。在实际生产环境当中让机器学习产生价值还是一件比较复杂的事，虽然目前业界已经能让算法科学家的模型生效了，但也还存在一些挑战。</p><p>&nbsp;</p><p>现在绝大部分企业机器学习后面的系统，都可以当作一个复杂子系统，是一个跟业务系统单独隔离开的系统。之前大家在讲机器学习的时候，很多人畅想业务数据能够自己适应应用的变化，机器学习和企业软件能得到结合，但实际情况跟这种终极理想状态相比，两者之间距离还比较遥远，业界还没有真正能够找到将机器学习和业务系统真正结合在一起的道路。很多时候机器学习仍然是作为一种外在的能力，插入到企业业务的主流程当中。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4c/4c671b2874162605e53b1df5ae4bed5a.png\" /></p><p></p><p>（图片源自网络）</p><p>&nbsp;</p><p>在机器学习的应用场景中，机器学习代码只占一小部分，无论是自动驾驶、信用卡风控还是图像识别，90%以上是来自于工程领域的人。工程师们需要将算法科学家的模型应用到具体的软件环境中，知道如何跟算法科学家做交互。实际上，在现实环境中部署模型时，科学家给出的模型通常会失效，因为无法适应环境的动态变化或描述环境的数据的变化。由于机器学习模型的生产被认为是算法科学家独立的技能，为了取得成功，我们需要一个混合团队。目前的情况是，一个成功的团队可能包括数据科学家或 ML 工程师、 DevOps 工程师和数据工程师。工程师需要不断在生产环境中健康模型的质量，频繁重新训练生产模型，并尝试新的实现以生成模型。</p><p>&nbsp;</p><p>为了战胜此手动过程的挑战，MLOps就起到了作用，通过设置 CI/CD 系统以快速测试、构建和部署机器学习训练流水线。通过机器学习工程化，自动重新训练和部署新模型，从而达到弥合工程师和算法科学家之间的鸿沟的目的。</p><p>&nbsp;</p><p></p><h2>为什么机器学习难以“工程化”？</h2><p></p><p>&nbsp;</p><p>在传统软件开发中，以团队多人合作方式，追求“高效协同”和“质量可控”，让项目的质量、进度、成本都在可控范围内，这就是“工程化”能力。反过来说，当一个项目不够工程化的时候，实际上有两种情况。</p><p>&nbsp;</p><p>第一种是依赖于个体活动，不需要与其他人一起协同合作的时候，那么其实它就是一个弱工程化体现。“其实大家也可以反思一下，哪怕是对于应用开发，团队里有些个人可能他会更强调自己个人贡献和个人活动，而忽略了团队之间交互，其实这也是一种弱工程化的体现。虽然并不是说我们做应用开发，就一定全部是工程化的，但当它是弱协同、强个体的时候，那么就一定是缺乏工程化的体现。”</p><p>&nbsp;</p><p>第二种是启发性的探索活动。工程化的活动是指我们已经知道要去什么地方，这件事情可能之前大家干过，或者是知道行业里面有其他人实施过，我们只要按照步骤和方法把它拆解成小的步骤和方式就一定可以一样完成。而所谓启发式的探索活动是指我们并不知道事情如何实现，不知道事情完成的大概过程和顺序，我们需要不停的试错和探索，甚至还不能确定是否能达成最终目标。我们就认为这种情况不是一个可以完全工程化的过程，是一种弱工程化的体现。</p><p>&nbsp;</p><p>那么机器学习就是一个非常典型的非工程化的场景，因为它极大的依赖于数据科学家的个人能力，过程也充满了探索。机器学习需要在数据上不断地进行实验和探索。就算深度学习已经降低了对特征工程的要求，但是对hyper parameter的调整，到底选择多少层网络，采用一个什么样的网络架构等等，都主要是依赖于科学家的个人经验。</p><p>&nbsp;</p><p></p><h2>为什么机器学习工程化需要新的工具体系？</h2><p></p><p>&nbsp;</p><p>机器学习项目跟一般软件不同，一般软件代码和数据分得非常清楚，项目开发构造的是代码，和生产环境结合之后才能产生一些数据。而机器学习在生产环境中，本身就是一个对数据加工的过程，所以没有办法像传统软件一样将代码和数据分开。看上去机器学习软件是代码组成，但实际上起到更重要的作用的是数据。</p><p>&nbsp;</p><p>加上本身的弱工程化特性，所以机器学习是比较难以工程化的。但过去短短的几年间，我们把已经驯服了一个看上去来完全不能工程化的实验性品类，变成了一种能够和其他开发方法一样可以相互协同的常规化操作，从一种个人活动慢慢变成一种团队的活动，让它的结果越来越可控，然后更多地接入到了企业的生态中，“这个其实是一个非常有意思的过程。”</p><p>&nbsp;</p><p>对比传统软件工程化的流程来看，机器学习工程化的第一步还是构建一个协同性的开发过程。这个起点源自版本控制，保证在构造的过程中，工程师的产物彼此之间是可以共享的，有明确的产物可以让团队有人员流动的情况下进行工作交接。很多的公司和机构的开发工程化实际上都是从有严格可追溯的版本控制开始的。</p><p>&nbsp;</p><p>机器学习工程化的第二步是打通生产环境和开发环境之间的隔离，从开发环境到生产环境之后，工程师知道如何进行数据和模型的更新，在生产环境中进行运营和维护。这些跟传统意义上的开发都是一样的，都要将它变成一个协同性的团队活动，但是这里面的内容和工具呈现的形式会差别比较大。</p><p>&nbsp;</p><p>拿版本控制举例来说，传统软件开发控制的数据量并不大，并且一个代码库几G、几十G的规模就算很大了。数据量很小，代码也都是文本形态的，对于代码的变更是很容易理解的，所以在传统软件版本管理中，以代码行的修改作为变更要素。</p><p>&nbsp;</p><p>但在机器学习中这些就不一样了，机器学习不仅仅包含代码，还包含模型、数据。机器学习首先得关注数据，数据格式和形态不一定是纯文本的，可以有图片、声音等，以图片像素或声音片段来进行修改。机器学习的数据是不会停止变化的，并无法控制它会如何变化。所以我们不需要每一个更改都定义一个版本，可以将整个数据看成一个跟时间相关的流，把很多天的数据变化算成一个时间段，作为一个版本。所以对比起来，数据对于版本的定义和代码对于版本的定义有很大的差异，这也是我们需要新工具的原因。</p><p>&nbsp;</p><p></p><h2>为什么MLOps不能简单类比DevOps</h2><p></p><p>&nbsp;</p><p>2018年开始出现了机器学习版本控制软件DVC，DVC从这时开始又反过来促进我们去思考数据科学工作流程。在开发流程中，开发代码或模型只是第一步。最大的努力在于使每个步骤都可以在生产中奏效，包含版本控制、模型服务和部署、集成测试、实验跟踪等各方面，让他们在最少的干预下能够重复自动运行。</p><p>&nbsp;</p><p>当将以上所有工程化内容梳理清楚之后，我们还需要将这些步骤紧系在一起，这就是持续交付的业务流程设置工具起作用的地方。于是，MLOps 的概念就出现了，它让全流程变得更顺畅、更加持续，让机器学习越来越工程化。</p><p>&nbsp;</p><p>MLOps是一个DevOps、数据科学和软件工程的交叉学科，是在生产中部署和可靠维护机器学习系统的一组实践和工具，“但和DevOps差别挺大，两者不能简单地进行类比”。</p><p>&nbsp;</p><p>在传统软件开发领域，DevOps实践能够在几分钟内将软件交付到生产环境并保持其可靠运行。在DevOps之前，软件开发方法是开发完软件，交给运维团队。运营中心看管着机器以及其它实际的物理执行架构。在云时代以后，机器的启动可以通过软件控制，开发人员就不再需要运维的人去做这件事情了，这就产生了DevOps运动。DevOps主要控制的是机器，对于软件的升级也就仅仅是看作有一个机器要安装一个新的版本。</p><p>&nbsp;</p><p>而机器学习工程化方面，它是代码加数据，利用数据训练神经网络，关注的是神经网络的参数调整，再将其部署到生产环境中进行试验。数据科学家从样本数据开始，在 Jupyter notebooks上工作，或使用 AutoML 工具来识别模式和训练模型，但训练端环境和执行端环境可能没有直接的关联关系。当数据科学团队尝试将模型部署到生产中时，他们发现现实世界的数据是不同的，无法对不断变化的数据使用相同的数据和方法。</p><p>&nbsp;</p><p>所以在实际开发中，开发人员需要不断重新采集数据，或对模型进行训练，或是对参数进行调整，再重新发布，MLOps主要解决的问题是怎么把训练好的结果放到生产环境当中去。负责在生产环境下运行的和设计神经网络可能不是一组人，所以MLOps可能认为是一个这样的自动化过程，是通过一个流程把大家的工作串在一起。</p><p>&nbsp;</p><p>对于MLOps而言，它反而不太关注机器是什么样子，更多的是关注现在的机器学习参数如何划分，神经网络的结构是否要调整，参数是如何调整的，等等。</p><p>&nbsp;</p><p>MLOps对本身执行的硬件环境关注是相对比较少的。他们唯一相近的地方都是在生产环境下对于最终的产物进行运维的过程，只能说在概念上仅此是相似的，而从工程实践来说差别是非常大的。</p><p>&nbsp;</p><p></p><h2>MLOps只是起点</h2><p></p><p>&nbsp;</p><p>“机器学习工程化目前还处于早期阶段。”</p><p>&nbsp;</p><p>现在我们终于不再去谈网络模型、谈特征工程这些跟机器学习本身算法相关的了。企业开始关注的是如何让机器学习算法，从开发环境过渡到生产环境，形成一套有效的流程，让所有人围绕这套流程来工作。MLOps的出现，让人工智能朝着越来越成熟的工程化迈进了重要的一步。</p><p>&nbsp;</p><p>这是一门全新且令人兴奋的学科，其工具和实践可能会快速发展。这还是一个开端，不是终点，徐昊认为，这说明了“我们工程界又驯服了一个新技术，让人工智能够在特定领域里提供一个更好的解决方案。”</p>",
    "publish_time": "2022-08-01 11:20:17",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "揭秘亚马逊内部与众不同的软件开发系统",
    "url": "https://www.infoq.cn/article/rTyFMWQgbZlQIXMomKEq",
    "summary": "<p>本文最初发布于Gergely Orosz的个人博客。</p><p>&nbsp;</p><p>亚马逊有大量的内部系统。作为软件工程师和工程经理，下面这些值得了解一下。</p><p>&nbsp;</p><p>当作为SDE（软件开发工程师）或SDM（软件开发经理）加入时，你必须学会使用亚马逊自定义的技术栈，这和AWS客户所使用的技术栈有着惊人的差异。下面这些是你可能会遇到的系统。</p><p></p><h2>与SDE密切相关的内部系统</h2><p></p><p>Code：代码搜索和VCS（Git）。</p><p>&nbsp;</p><p>Crux：亚马逊的代码评审系统。</p><p>&nbsp;</p><p>Brazil： 亚马逊的构建系统。可以看下这篇<a href=\"https://gist.github.com/terabyte/15a2d3d407285b8b5a0a7964dd6283b0\">详细介绍Brazil</a>\"<a href=\"https://gist.github.com/terabyte/15a2d3d407285b8b5a0a7964dd6283b0\">的文章</a>\"，虽然已经过时，但仍有意义。</p><p>&nbsp;</p><p>Sage：亚马逊内部的“Stack Overflow”。</p><p>&nbsp;</p><p>亚马逊内部维基系统：该系统有一些令人愉快的特性，比如很容易在页面上嵌入来自AWS Cloudwatch或先前系统（PMET&nbsp;—— 性能指标）的图片。</p><p>&nbsp;</p><p>NAWS（Native AWS）：使用现行AWS的“现代”技术栈。</p><p>&nbsp;</p><p>MAWS（Move to AWS）：遗留的旧AWS系统。</p><p>许多系统在从这上面移走，尤其是在零售领域。MAWS要求服务通过一个名为的Apollo系统在EC2实例上启动，这在NAWS中基本已经废弃了（你应该使用Lambda或ECS，或者在绝对必要的情况下使用原始EC2）。</p><p>&nbsp;</p><p>Isengard/Conduit：AWS账号管理，所有系统都是隔离的，这可以保证每个区域、服务、阶段（stage）都有独一无二的AWS账号。</p><p>&nbsp;</p><p><a href=\"https://www.lastweekinaws.com/\">Last Week in AWS</a>\"编辑Corey Quinn将这项服务说成是“<a href=\"https://www.lastweekinaws.com/blog/the-aws-service-i-hate-the-most/\">他最讨厌的AWS服务</a>\"”。他写道：</p><p></p><blockquote>事实上，这是用于配置AWS账号的内部系统，这意味着，构建AWS的AWS工程师管理AWS账号的方式与世界上其他人管理AWS账号的方式绝缘。他们不需要采用和AWS Organizations、Landing Zones、Control Tower或AWS SSO一样的方式。这是我对这项服务不满的根本原因。</blockquote><p></p><p>Pipelines：CI/CD系统，支持多阶段部署（最多4个阶段：beta、gamma、prod、local）。有一位AWS工程师这样描述它：</p><p></p><blockquote>在亚马逊，管道是“把简单的事情变困难，把困难的事情变可能”的最佳例子之一。部署到3-4阶段的服务（跨不同区域的beta、gamma和prod）大概并不关心管道。而像大多数AWS服务那样，在流水线中有数百个部署单元的服务则对它非常满意。</blockquote><p></p><p>&nbsp;</p><p>LPT：动态管道模板。这是一个生成CloudFormation或CodeDeploy模板的Ruby库，它会同时定义管道、Isengard账号及其他脚手架。通常，每个服务都有一个LPT包来创建所需的资源。</p><p>&nbsp;</p><p>AWS CDK：亚马逊在推动使用它代替LPT，但截至2022年初，与LPT相比，它还是一个不怎么成熟的系统。大部分团队都在采取行动，有些团队表示，他们特别喜欢它提供的TypeScript支持。</p><p>&nbsp;</p><p>2PR：针对敏感操作的第二人审批系统，如Isengard和SSH登录系统。如果访问系统时没有按要求审批，就会自动创建一个团队违规通知单，这可以升级到管理层。</p><p></p><h2>组织层面的系统</h2><p></p><p>AWS Chime：以前是亚马逊的聊天和视频通话应用程序。现在，亚马逊使用Slack聊天，但AWS Chime仍用于视频通话，包括电话面试。</p><p>&nbsp;</p><p>Kingpin：团队、组织及亚马逊公司范围的目标跟踪系统。</p><p>&nbsp;</p><p>Accolades：一个通过评价赞美员工的工具，并且提供了方法，可以方便地抄送给经理和其他人。</p><p>&nbsp;</p><p>Connections：在公司笔记本上预装。它会在一天开始的时候提一个简单的问题，像”你觉得你的经理怎么样“，或者”你的团队对卓越运营（OE）的重视程度如何？“，并让你给出满分为5的评级。公司里每个人每天看到的问题都一样。</p><p>&nbsp;</p><p>Forte：亚马逊公司范围的绩效反馈流程，从12月下旬开始一直运行到1月底。员工使用Forte工具请同行及与他们共事的人反馈意见。简短的反馈，只有60个单词或更少。</p><p>&nbsp;</p><p>汇总后的匿名结果会上传给管理层，他们的目标是随着时间的推移提高他们的Connections分数。这些结果会与团队分享，团队会给出反馈，而他们的经理则会据此采取措施。</p><p></p><h2>编程语言</h2><p></p><p>大多数服务都是用Java编写的。不过，团队是自治的，他们可以选择任何自己想用的语言和框架。虽然Java是主要的，但这些服务中也使用了多种其他语言。</p><p>&nbsp;</p><p>查看英文原文：</p><p><a href=\"https://blog.pragmaticengineer.com/amazon-notable-systems/\">https://blog.pragmaticengineer.com/amazon-notable-systems/</a>\"</p>",
    "publish_time": "2022-08-01 11:45:50",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "超大型金融机构国产数据库全面迁移成功实践",
    "url": "https://www.infoq.cn/article/FzTvGmiIb9oFPA9jY36m",
    "summary": "<p></p><blockquote>在国家层面提出加快建设科技强国，实现高水平科技自立自强的大背景之下，数字技术的自主研发与创新应用愈发重要。然而，由于金融机构对业务连续性和数据准确性的严苛要求，传统头部金融机构始终没能有一家完成国产数据库全面迁移。近日，阿里巴巴集团副总裁、阿里云智能新金融&amp;互联网事业部总经理刘伟光与InfoQ分享，他们深度合作的一家某超大型保险（集团）公司，深入推进数字化转型，紧随先锋技术发展趋势，前瞻性布局启动IT架构分布式改造转型，并于21年9月圆满实现了最后一个规模高达20TB+核心数据库的全面迁移改造工作，也为后续向云原生多活架构演进打下了坚实的基础&nbsp;。&nbsp;在刘伟光看来，该数据库国产迁移项目成功上线，树立了金融行业践行科技强国的标杆实践，也是对国家科技自立自强战略以及国产技术的履责担当；更推动了整个国内数据库管理与应用体系科技生态建设和科技产业链的快速成熟。&nbsp;那么，这家超大型保险（集团）公司，究竟是怎样一步步完成国产数据库全面迁移工作的？本篇干货长文整理自刘伟光的分享，以飨读者。</blockquote><p></p><p><img src=\"https://static001.infoq.cn/resource/image/d9/e5/d9c6404d5e634cf9da4075ae4389cae5.png\" /></p><p>刘伟光，阿里巴巴集团副总裁阿里云新金融&amp;互联网行业事业部总经理</p><p>在金融保险行业，短时业务并发压力虽没有互联网企业那么大，但是在业务复杂性和对数据库专有特性的依赖程度上，都要远大于互联网企业。保险业务的处理更为复杂，单一业务要多个系统完成，调用链比银行和互联网业务更长、更复杂，确保复杂集合大交易量的稳定是保险业务数据库国产的挑战。</p><p>&nbsp;</p><p>这家保险公司成功实施国产数据库全面迁移，并取得了五个突破：</p><p>&nbsp;</p><p>突破一：更短的迁移时间。在传统金融机构从未实现过如此大规模的核心系统全量迁移的情况下，该公司从2020年9月到2021年9月，仅用时一年就完成迁移。</p><p>&nbsp;</p><p>突破二：更大的迁移规模。该公司在一年内完成了包括传统核心、互联网核心、个险销售、团险销售、经营管理、客服管理、大数据在内的近百个业务系统在线Oracle数据库的全量搬迁工作，迁移数据规模超400TB、数据量超千亿，单库数据规模超20TB。</p><p>&nbsp;</p><p>突破三：迁移全程同时保障了业务连续性和数据准确性。该公司在整个迁移过程无一例回切，上线至今一年内，系统稳定运行,且历经2021年完整周期的金融保险行业“业务大考”——承受住了开门红高峰TPS 5万+、QPS 21万+，以及包括精算在内的所有业务环节的严苛考验，不仅完全满足公司生产需要，还实现国产数据库从“可用”到“好用”的跨越。</p><p>&nbsp;</p><p>突破四：迁移后实现技术100%自主创新。该公司基于完全自研创新的国产数据库，迁移过程中版本升级持续发版共计50余次，最长需求解决时间2个月（Pro*C+Tuxedo）。并通过系统培训与交流实现累计超过500位员工的数据库专业考试认证，实现了数据库的全面自主掌控能力。</p><p>&nbsp;</p><p>突破五：迁移后新一代技术成为关键生产力。迁移后，该公司的存储成本显著下降，设备节省投入近2亿元；&nbsp;性能也大幅度提升，TPS：5.8万笔/秒，QPS：21万笔/秒，1:3的存储压缩比。数据库由主备模式发展为支持两地三中心&nbsp;多活部署，生产事件处理时长从小时级缩短到分钟级。</p><p>&nbsp;</p><p>当我们回顾这一段历程，过程虽然艰辛，但积累了宝贵的大型金融机构国产数据库迁移实践经验。下文将详细介绍迁移的全过程，希望对“在路上”的企业有所参考。</p><p>&nbsp;</p><p></p><h1>1、&nbsp;国产金融级数据库迁移实践</h1><p></p><p></p><h2>1.1&nbsp;前期准备工作</h2><p></p><p></p><h3>1.1.1&nbsp;数据库选型</h3><p></p><p>数据库是企业IT基础设施中皇冠上的明珠，存储企业运行核心数据资产，向上支撑应用，向下屏蔽底层基础设施，在金融行业“稳定压倒一切”的大前提下，数据库的选型更为慎重，根据信通院《<a href=\"http://www.caict.ac.cn/kxyj/qwfb/ztbg/202106/t20210625_379495.htm\">数据库发展研究报告（2021年）</a>\"》&nbsp;的描述，截至2021年6月底，国产关系型数据库厂商就高达81家。面对如此纷繁复杂的产品，如何选择合适的数据库是摆在该保险公司面前的首要问题。虽然数据库产品众多，经过审慎的评估后，该公司最终选择了OceanBase、PolarDB等三款产品作为先期试点验证，主要选型考量点如下：</p><p></p><p>1.&nbsp;是否能满足业务的平滑迁移和未来架构的演进要求；</p><p>2.&nbsp;是否具备分层解耦能力，重点关注能否解除数据库与底层硬件、操作系统、中间件之间的耦合；</p><p>3.&nbsp;是否有足够的人才储备、资金投入，能否商业兜底产品的长期演进；</p><p>4.&nbsp;是否有广泛的行业实践案例；</p><p>5.&nbsp;是否能做到完全自主研发；</p><p>6.&nbsp;是否能兼容原有开发运维体系，自有技术人员能否快速掌握。</p><p></p><h3>1.1.2&nbsp;基础设施准备</h3><p></p><p>确定数据库选型标准后，前期准备工作的进度表走到了下一环节——基础设施准备。</p><p></p><p>该公司核心业务系统原先共计使用超过60多台IBM和HP高端小型机，超过70多台高端存储，传统集中式架构耦合性强，难以实现规模和性能的线性扩展。本次国产数据库采用机架式服务器和本地存储全面替代进口小型机及传统SAN存储架构，以满足核心系统全量迁移的云原生分布式架构改造。同时，为了避免基础设施变动过大导致业务系统不稳定，采用Intel+海光+鲲鹏服务器混合部署的架构。前期仍以Intel X86为主，逐步过度到海光、鲲鹏芯片国产服务器，实现在线调整不同型号机器，解除了基础设施供应依赖。</p><p></p><p>2020年9月，该公司正式启动<a href=\"https://s.geekbang.org/search/c=0/k=%E5%9B%BD%E4%BA%A7%E6%95%B0%E6%8D%AE%E5%BA%93/t=\">国产数据库</a>\"迁移项目之后，从硬件环境的型号选择，到选出目标系统，进行容量规划。不到两个月的时间内，该公司从0开始完成了国产数据库的硬件和操作系统适配、以及整个服务器集群的搭建工作。</p><p></p><h3>1.1.3&nbsp;迁移策略制定</h3><p></p><p>基础设施准备工作落地后，该公司开始指定迁移策略。</p><p></p><p>从需求出发，基于该保险公司的业务经过多年的发展，业务范围覆盖全国，特色鲜明、种类繁多，业务关联关系错综繁杂，想要进行核心数据库的迁移，首先需要进行广泛的调研和充分的科学论证——既要求数据库产品比照原有生产数据库的高性能和安全可靠，也需要快速实现多套系统的平滑迁移，同时解决资源弹性和数据库横向扩展的能力。</p><p></p><p>面对这样的需求，该公司先后建立了数据库迁移实施的统一规范和标准--总体遵循“评估-实现-控制-分析改进”的科学方法论，开展有序迁移，并定下三大迁移策略：</p><p>&nbsp;</p><p>1.先平迁再做业务和架构改造升级，避免多个变量同时发生，影响业务的连续性。由于原有数据模型不做改造，所以主体改造工作由新数据库来承担。</p><p>2.迁移批次遵循“以业务系统为粒度，从低负载到高负载，从外围到核心”的原则。</p><p>3.所有数据库迁移不影响正常业务开展。用1年时间完成所有业务系统的数据库全量迁移改造，所有系统数据库迁移动作时间窗口只给周六、周日凌晨0点到早上6点，周末小流量验证，周一重点保障，不影响正常业务开展。</p><p></p><h2>1.2&nbsp;互联网核心迁移</h2><p></p><p></p><h3>1.2.1&nbsp;明确业务系统背景</h3><p></p><p>在完成了所有前期准备工作之后，该公司着手选定数据库系统进行迁移工作。</p><p></p><p>该保险公司核心系统涉及众多，大体可以分为：互联网核心业务系统和传统核心业务系统，中间通过类似ESB的总线机制实现异步解耦。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/34/16/348a6ea9f367243b19667641c2934816.png\" /></p><p>核心系统分类</p><p></p><p>早在2016年，这家保险公司的互联网核心和传统新核心应用就开始从传统单体架构向分布式微服务架构改造。至2020年，也就是开始迁移的时间点，互联网核心业务系统已经拆分成了40多个微服务模块并完成Mesh化接入。</p><p></p><p>该公司互联网核心业务系统的特点是：</p><p></p><p>1.数据库系统已实现全国物理集中、逻辑集中，数据库对接的关联系统较多；</p><p>2.虽然做了微服务拆分，但是数据库仍有一定量的存储过程，另外触发器、自定义类型、函数、外键、分区表等高级功能均有使用；</p><p>3.该公司因为业务特点，需要服务好100多万代理人，对数据库资源弹性和性能要求更高。</p><p>&nbsp;</p><p>因此，进行互联网核心业务系统的数据库迁移面临的主要技术挑战是：</p><p></p><p>1.全国集中式部署下单点故障会影响到全国；</p><p>2.主数据系统作为核心业务链路中的整个保险开户入口，内部对接43个关联系统，数据规模超20TB，最大单表超50亿条数据，每天接口调用量超2000万次，是该公司单体数据库日均请求量最大的系统，因为关联系统多，且处在业务链路的核心位置，因此对数据库SQL的效率要求非常高，要求迁移过程不能影响原有生产系统；</p><p>3.迁移到新的数据库平台要具备实时同步到Kafka的能力，并兼容原有格式，供下游大数据系统消费。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/fa/9d/fa2e905ae753352720811cbc1cee079d.png\" /></p><p>原有大数据消费链路</p><p>&nbsp;</p><p></p><h3>1.2.2&nbsp;选定技术方案</h3><p></p><p>整体选型</p><p>针对以上技术挑战，该公司选择了和原有Oracle RAC架构更接近的<a href=\"https://s.geekbang.org/search/c=0/k=PolarDB/t=\">PolarDB</a>\"作为互联网核心数据库的替换。PolarDB作为新一代云原生数据库主要特点如下：</p><p></p><p>1.计算与存储分离，使用共享分布式存储，满足业务弹性扩展的需求。极大降低用户的存储成本；</p><p>2.读写分离，一写多读，PolarDB引擎采用多节点集群的架构，集群中有一个主节点（可读可写）和至少一个只读节点（最大支持15个只读节点）。写操作发送到主节点，读操作均衡地分发到多个只读节点，实现自动的读写分离；</p><p>3.基于K8S形态部署，提供分钟级的配置升降级，秒级的故障恢复，全局数据一致性和完整的数据备份容灾服务；</p><p>4.集中式架构，不需要进行分布式架构相关考虑设计，和原有使用习惯保持一致，性能不低于原有Oracle数据库；</p><p>5.高度兼容Oracle，应用基本上不需要做SQL语法调整。</p><p>&nbsp;</p><p>迁移方法</p><p>为了避免对原有生产业务造成影响且保证迁移数据的严格一致性，该公司采用了DTS全量+增量的方式，对于数据规模超大的Oracle集群，如客户主数据系统，提前2周启动数据迁移链路，在全量数据迁移之前DTS会启动增量数据拉取模块，增量数据拉取模块会拉取源实例的增量更新数据，并解析、封装、存储在本地存储中。</p><p></p><p>当全量数据迁移完成后，DTS会启动增量日志回放模块，增量日志回放模块会从增量日志读取模块中获取增量数据，经过反解析、过滤、封装后迁移到目标实例，通过目标端主键保证数据的唯一性。</p><p></p><p>应用切换成功后，从应用接口的响应速度上看，性能比Oracle提升约30%。到2020年底，该公司和<a href=\"https://www.infoq.cn/profile/C390D13025ED5D/publish\">阿里云数据库</a>\"团队携手完成了互联网核心业务系统所有模块的迁移，包括服务超百万代理人的出单系统APP，和注册用户超1亿的寿险APP、客户主数据等在内的共计40多个业务系统。</p><p><img src=\"https://static001.infoq.cn/resource/image/0c/be/0cfcaa772fdeffd7257b1f38ab9c0bbe.png\" /></p><p>互联网核心整体迁移技术方案</p><p>&nbsp;</p><p>为了减少迁移过程中对下游大数据消费造成影响，该公司到大数据的同步链路改造采用了2步走的策略，</p><p><img src=\"https://static001.infoq.cn/resource/image/c5/ce/c5dfcf97b749d58f2bace20373a026ce.png\" /></p><p>大数据同步链路改造方案</p><p>&nbsp;</p><p>1.增加PolarDB到Oracle的反向实时同步，原有Oracle到Kafka同步链路不变，避免数据库切换带来太大的变动；</p><p>2.参考SharePlex的格式对DTS进行定制化开发改造，待验证充分后，直接替换掉SharePlex原有同步链路。</p><p>&nbsp;</p><p>主要挑战</p><p>迁移完成后，PolarDB作为互联网核心业务系统的数据库，需要稳定支撑起该公司在2021年一季度的业务冲刺。最前端的出单系统，是整个业务冲刺过程中性能压力的集中点。并且，由于做了微服务化改造拆成了30多个模块，分散在了多个数据库中，任何一个数据库都可能存在被打爆的风险。在迁移到PolarDB之前，该公司的做法是拆在多个Oracle RAC集群中，依靠内部开发的数据库监控完成多个Oracle集群的监控，迁到PolarDB之后，预计整体架构将更适应业务弹性的以下挑战：</p><p></p><p>1.统一管控：通过PolarStack将多台机器组成的集群进行统一管控，提供DBaaS服务；</p><p>2.资源弹性：实例由原来的物理机部署，变为K8S&nbsp;Pod部署，更为灵活和弹性；</p><p>3.读写分离：通过智能代理服务实现自动的读写分离，实现分钟级扩容，故障场景下自动切换，应用不需要做任何调整。</p><p><img src=\"https://static001.infoq.cn/resource/image/89/03/89d2c11b82dcaf654e069b4abaa33303.png\" /></p><p>PolarDB技术架构</p><p>&nbsp;</p><p>业务冲刺当天，互联网核心业务系统经过了三个性能压力高高峰时间点：12：00、17：00、21：00。这三个时间点的每小时出单量和全天出单量进入了历史的前三位，高峰期出单笔数达到9000笔/s。</p><p></p><p>迁移历程</p><p>2020年9月，该公司互联网核心业务系统的首批应用模块迁移到PolarDB，整个适配过程不到一个月。此后，互联网核心各个模块就开始了大规模的迁移。</p><p>2020年11月，PolarDB完成了最大的单库客户主数据迁移。</p><p>2021年1月底，PolarDB作为互联网核心出单系统的数据库，稳定支撑起该保险公司2021年一季度业务冲刺。</p><p>&nbsp;</p><p></p><h2>1.3&nbsp;传统核心迁移</h2><p></p><p></p><h3>1.3.1&nbsp;明确业务系统背景</h3><p></p><p>该大型保险公司的传统核心系统历史悠久，既有1998年之前建成的，也有2004到2008年间建成的，时间跨度长，数据量异常庞大，单个数据库的数据规模甚至超过20TB。更具挑战的是，很多老核心按省市做了拆分，要分省市分别进行迁移，单一老核心系统需要迁移的数据库可能就要多达36个。</p><p></p><p>通过详细地梳理，该公司将传统核心业务系统归纳为三类系统：</p><p></p><p>第一类：2016、2017年基于Java技术栈开发的新核心系统，大概有13个。</p><p>第二类：分别在1998年之前，2004到2008年间建成的老核心系统，大概有6个。</p><p>第三类：一些可能要下线的，不在此次数据库迁移范围内的系统。</p><p>&nbsp;</p><p>彼时，这些传统核心业务系统的数据库当时面临的主要技术挑战是：</p><p></p><p>1.系统关联关系庞杂，既有保单平台管理系统也有资金类系统，系统间关系难以梳理；</p><p>2.既有物理和逻辑集中的新核心，也有物理集中，逻辑分离的老核心，其中老核心分省部署，每个省都会有一套数据库，迁移工作量巨大；</p><p>3.对Oracle专有特性依赖较多，大量使用存储过程、触发器、自定义类型、函数、外键等。更为挑战的是，老核心大量使用Pro*C（SQL嵌入式C程序）和Tuxedo（Oracle中间件做分布式事务处理）做保单过程处理，仅该公司某年金系统涉及到的Pro*C程序就有1500多个，约140万行代码，业务短时间难以改造；</p><p>4.单库体量非常大，超过10TB的就有6个，最大单库规模超20TB，停机窗口短暂；</p><p>5.交易量大，每天数据库调用几十亿次，还有大量复杂集合类精算和结算类交易。</p><p></p><h3>1.3.2&nbsp;确定技术方案</h3><p></p><p>选型方案</p><p>针对以上技术挑战，该公司选择了分布式数据库<a href=\"https://s.geekbang.org/search/c=0/k=OceanBase/t=\">OceanBase</a>\"作为传统核心的替换。OceanBase数据库主要特点如下：</p><p></p><p>1.采用基于无共享（Shared-Nothing）的多副本架构，整个系统没有任何单点故障，保证系统的持续可用；</p><p>2.基于LSM存储引擎技术，结合新硬件的能力，采用可扩展的分布式架构，提供高性能和扩展性；</p><p>3.数据库针对Oracle、MySQL 等应用最为广泛的数据库生态都给予了非常高的应用兼容性支持；</p><p>4.虽然为分布式架构，一般也不需要应用层做相应的重新设计如指定分布键等，与原有Oracle使用习惯基本一致；</p><p>5.OceanBase 数据库完全自主研发，不依赖外部开源代码，真正做到自主研发。</p><p>&nbsp;</p><p>迁移方法</p><p>该公司针对传统核心复杂的数据库情况进行全面验证，最终形成了140页的迁移操作手册和详细的割接行事历，为后续系统的迁移和大面积推广积累了宝贵的经验，并形成了标准的迁移割接方案。整体迁移方法过程如下，从“基础环境准备--迁移过程演练--正式割接--监控运维”等四大环节进行逐项拆解，落实到人，精确到分。</p><p><img src=\"https://static001.infoq.cn/resource/image/86/4f/86a9ab7aa9904da0d4e6a60b2b33214f.png\" /></p><p>数据库整体迁移割接流程</p><p>&nbsp;</p><p>对于规模较大Oracle数据库的迁移，我们总结了如下四点帮助提升迁移效率：</p><p></p><p>1.&nbsp;冷热数据分离</p><p>一般的业务库数据中，数据具有自己的生命周期，数据的高频访问具有冷热特点。比如，流水表历史数据，日志表历史数据除了在审计回查场景之外，访问很少甚至不访问，但是通常这部分数据都会比较大，数据迁移的开销会比较高，造成数据迁移时间的延长。针对该部分数据，我们可以预先对这部分数据进行归档备份，然后采用静态迁移或者利用OMS工具全量迁移单独迁移。</p><p></p><p>2.&nbsp;LOB类型数据</p><p>Oracle数据表行LOB类型空间占用较大，每一批次的数据拉取大小会在原始行的基础上有显著增加。相比无LOB数据类型，对OMS端内存需求有数倍的需求，因此，优化的策略是单独对LOB类型的表建立新的链路，采用较小的并发，防范JVM OOM的风险，同时，为了提高整体迁移的速度，进行多链路并行迁移。</p><p></p><p>3.&nbsp; 无LOB类型数据</p><p>相对于LOB类型数据，无LOB数据类型的表的迁移，单位迁移批次的大小较小且稳定，内存需求可控，并发度可适度加大，提高迁移速度。所以，对该部分数据可使用较高的并发度单链路或多链路迁移。</p><p></p><p>4.多个大库迁移链路通过不同OMS并发迁移</p><p>单台OMS可以支持多个迁移任务，但是共享数据网络出口。鉴于大库数据的持续拉取，可以将大库的迁移分散至不同OMS节点，减少大数据网络流量的争用。</p><p>&nbsp;</p><p>主要挑战</p><p>在整个迁移过程面临的挑战中，我们认为最难的是针对Pro*C的适配。Pro*C是Oracle提供的应用程序专用开发工具，应用C语言编写程序，在程序源代码中可以直接嵌入SQL语句，执行数据库操作。</p><p></p><p>Pro*C既兼容了传统C语言的开发模式，又提供了强大的数据库操控能力，所以在保险行业和其他行业也有不小的用户基础。而Tuxedo(Transactions for Unix, Extended for Distributed Operations)作为是最早的分布式事务产品，是AT&amp;T在20世纪80年代推出的。传统老核心业务中，大量使用Tuxedo调用相关的Pro*C程序来做保单业务流程处理来保证跨库事务的一致性。</p><p></p><p>为了根本上解决该问题，实现应用的平滑迁移，阿里成立项目攻坚团队，计划用1个月时间，从头开发Pro*C兼容预编译程序和运行时库。2020年国庆节前，攻坚团队的预编译程序成功编译了某年金业务的全部1000多个Pro*C程序，并正确跑通了两个典型批处理作业，通过了该公司的验收，进展大大超出该公司预期，也因此在“数据库赛马”中成功胜出并赢得了该公司对OceanBase产品研发能力的信心。</p><p></p><p>OceanBase能在短时间内完成对老核心的适配，得益于：</p><p></p><p>1.自主研发让OceanBase团队对每一行代码熟稔于心。OceanBase始终坚持自主研发，让研发人员有优秀的个人能力，清楚产品每一行代码的来龙去脉，能够快速和高质量地新增和修改代码，真正做到了自主研发。</p><p>2.全链路打通的研发模式。Pro*C只是外在交互模式，底层还要依赖数据库的内核能力，从SQL模式、优化器、服务端等做到了全链路打通，比如研发在批处理作业现场联调时发现SQL对to_date函数的'J'参数尚未支持时，快速反映给SQL模块，后端仅用一天完成了开发测试和发布。</p><p>3.敏捷开发模式，攻坚小组的研发和测试大家坐到一起，每日随着项目进展和变化快速确定和调整当日的目标。打破研发和测试边界，研发一边在开发，测试同学已经把单测和集成测试案例写好，开发侧有一点小的进展就立即验证测试，使得开发和测试能接近同步完成。</p><p></p><p>迁移历程</p><p>2020年10月，首个传统新核心理赔系统顺利上线。</p><p>2021年3月，完成传统老核心最小省份的迁移上线。</p><p>2021年4月，完成13个传统新核心的迁移上线。</p><p>2021年8月，完成传统老核心最后一个大省迁移上线。</p><p>2021年9月，完成传统老核心最后一个单体库迁移上线。</p><p></p><h2>1.4&nbsp;全面体系化迁移</h2><p></p><p>该保险公司发现：如何体系化全面迁移是是核心迁移过程中频发引发团队思考的问题，虽然在2021年3月完成最小省份的迁移，但后面还有多个老核心分布在36个按省市独立部署的Oracle数据库中，每个省份又包括了20多个schema，如果按照老的迁移方式，每个省份都需要创建20多条迁移链路，对于资源和人力都是极大的消耗，短时间也难以完成。</p><p></p><p>通过分析，工程化批量迁移最大的问题是没有做到全流程自动化，手工操作的步骤还比较多，为了解决该问题，产研和现场交付同学做了三件事情：</p><p></p><p>1.OMS数据迁移工具在底层链路上从技术层面支持多schema合并操作，从而可以将同一个省份的二十多条链路合并到一条迁移链路中。</p><p>2.在产品层面将数据迁移工具的底层能力进行拆解，将原来无法自动化的步骤做了自动化，并通过API的方式暴露出来，使得前线交付同学可以根据用户的实际情况像搭积木一样进行组装使用。</p><p>3.交付同学基于暴露的API和140多页的迁移操作手册，用一个月时间开发出简化迁移链路配置的快捷迁移工具。</p><p><img src=\"https://static001.infoq.cn/resource/image/ff/8c/ff763df3ab60dd060c37dc977c7fda8c.png\" /></p><p>一键自动迁移过程图</p><p></p><p>在对快捷迁移工具迭代了四个版本后，投入使用。需要人工干预的工作量减少了80%。同时一起建立了数据库迁移实施的统一规范和标准，开展有序迁移。上线实施标准流程包括8大环节，98个步骤，5倍峰值压测，体系化迁移8大环节如下：</p><p></p><p>1.&nbsp;兼容性评估：明确改动范围，进行适配改造工作量评估并合理安排工作任务。</p><p>2.&nbsp;负载评估：从原数据库获取SQL负载信息并在新数据库测试环境回放，验证新数据库应用后的性能。</p><p>3.&nbsp;测试迁移、适配改造：进行适配改造、全量回归测试、性能测试。有条件的系统（微服务化较好、重构等），可以分批改造和实施迁移。其中，性能测试可根据迁移前的关键业务容量基线，确定测试准出标准。</p><p>4.&nbsp;生产库存量、增量式迁移：对于业务连续性要求不高的系统，一般操作一次性存量方式完成数据迁移；对于业务连续性要求高的系统，采取全量+增量迁移方式，待增量数据追平后实施切换，仅需在切换时点暂停业务（分钟级）。</p><p>5.&nbsp;反向回流：对于关键应用，可实施数据同步回原数据库应对未知风险。</p><p>6.&nbsp;数据验证：迁移完成后进行数据准确性验证及应用验证。</p><p>7.&nbsp;持续监控：对可能遇到的问题进行监控、详细评估分析。</p><p>8.&nbsp;在线压测：迁移完成后，定期开展在线压测，基于实际生产场景进行业务全链路压力测试，持续保障应用容量和性能。</p><p></p><p>2021年5月，西部某省的迁移在2小时内顺利完成，验证了Oracle端多schema合并迁移这一重要技术难点，相比之前有数倍的提升，为剩余省份的并行迁移扫清了障碍，经过优化后：</p><p></p><p>1.测试环境：自主进行数据迁移和压测回放，并通过SQL自动优化建议工具，大大提高了迁移验证效率，可以自助解决90%以上的问题。</p><p><img src=\"https://static001.infoq.cn/resource/image/d6/38/d61fd506358a8a42f54e1253f72f5a38.png\" /></p><p>测试环境多次迁移演练步骤</p><p>&nbsp;2.生产环境：将过程中需要人工检查费时、费力的步骤，做到了自动化</p><p><img src=\"https://static001.infoq.cn/resource/image/9d/49/9d51aa830db6d570bc56675368c72349.png\" /></p><p>正式迁移割接步骤</p><p>紧接着完成了东北三省+内蒙古总共四个省份的数据，过程中解决了Oracle源端出现不可见控制字符脏数据的问题，确保了数据准确无误。</p><p></p><p>2021年8月，历经前面11次的迁移后，终于完成了最后一个、最重要省份，也是数据规模最大的的数据库迁移。</p><p>2021年9月，在解决了所有技术难题，完成了所有核心数据库的迁移，经历了开门红大促的考验后，该公司要完成一个保险公司一个完整的业务周期，只剩下最后一关，就是保险精算。</p><p></p><p>保险精算是保险公司业务经营的特色，需要运用数学、统计学、金融学、保险学及人口学等学科的知识与原理，去解决商业保险与各种社会保障业务中需要精确计算的项目。一般会在季度末和年末进行，以衡量企业的经营状况，并制定更有市场竞争力的保险产品，是保险业务开展不可或缺的关键一环。</p><p></p><p>保险精算分析的特点在于数据量大，分析的模型复杂，过程中还有大量的数据写入，往往要持续一周甚至更长时间，并且要确保精算过程中，快照点的数据不能发生变化。</p><p></p><p>基于传统IOE架构往往通过存储层的快照来实现。迁移到分布式数据库后，怎么保证在不停应用的情况下完成保险精算，是整个迁移过程的最后一个障碍。经过反复评估，阿里云为此制定了最佳方案，受益于OceanBase底层数据块的快速物理备份和表级的恢复能力。经过近1个月的压测验证，集群恢复速度达到800MB/S，完全满足精算的备份恢复的时间要求。最终在2021年9月30日在规定的时间窗口完成了数据的备份并导入到了精算库，有效支撑了全面迁移后的保险精算业务，解决掉了最后遗留的小尾巴。</p><p><img src=\"https://static001.infoq.cn/resource/image/14/77/146202b010187e0317b1a1ae777afb77.png\" /></p><p>保险精算数据准备过程</p><p></p><h2>1.5&nbsp;主要问题总结</h2><p></p><p>当然，整个迁移过程并不是一帆风顺，虽然未产生重大生产事故，但过程中也出了几次故障。而这些故障背后既反映了国产数据库在面对复杂场景上能力的提升，也反映了分布式架构带来的根本性变化。以下详细介绍三大故障情况以及解决办法。</p><p></p><h3>1.5.1&nbsp;数据库连接打满多次触发高可用切换</h3><p></p><p>互联网核心迁移到PolarDB过程中遇到的最大一次问题是在2021年1月，当天凌晨面向C端用户的两个重要系统完成数据迁移和应用的割接。伴随着日间业务流量逐渐增加，两系统因为大量的慢查询堆积较多应用连接，将数据库服务堵塞，全天多次触发PolarDB实例自动高可用切换，执行节点重建恢复流程。</p><p></p><p>以云原生容器形式部署的数据库服务节点，除了受本身数据库相关的内存参数限制外，还受cgroup指定的CPU和内存限制。当时连接池打满后，由于内存超出限制，引起实例的多次高可用切换重建。云原生数据库基于容器部署需要在稳定性和自保能力方面做诸多增强，为了解决相关问题，后续的版本中增加了global plan cache、resource manager、并行日志回放、global &nbsp;index等功能，数据库的内核参数也针对金融场景逐一做了定制化优化。</p><p>&nbsp;</p><p>针对金融场景对稳定性要求极高的需求，通过本次互联网核心迁移也增加了诸多管控运维能力：</p><p></p><p>1.&nbsp;增加AWR功能，定期收集AWR报告对性能和可用性进行分析。</p><p>2.&nbsp;增加GAWR功能，对主机、Dockers、RW/RO进行全量数据采集。</p><p>3.&nbsp;新增online promote功能，优化在线切换，进一步缩短切换时间。</p><p>4.&nbsp;增加Idle状态Session超时自动断开连接功能，减少后台进程数，及时释放回收Idle Session的内存资源。</p><p>5.&nbsp;优化元信息缓存功能，Session级别元信息缓存优化为全局元信息缓存，降低后台进程的内存使用。增加内存总量资源管理控制，设置一定的阈值，到达阈值后开始Cancel Query、Kill Idle Session、Kill Active Session、拒绝新用户Session连接，增强数据库的自保能力。</p><p></p><h3>1.5.2&nbsp;SAN交换机故障导致数据库进入无主状态</h3><p></p><p>由于原有Oracle数据库都是基于SAN存储部署，在2020年9月份启动数据库迁移工作之时，针对OceanBase部署建议的本地SSD盘硬件还没有采购到位。为了快速启动相关的迁移工作，最开始OceanBase传统新核心集群还是部署在SAN存储上，这也为第一个生产问题埋下了隐患。</p><p></p><p>第一个传统新核心应用理赔上线后，系统运行比较平稳。意外出现在某天下午14点7分，系统同时收到了应用监和数据库监控的告警。监控显示，应用出现了90秒的阻塞迭停。然而，当双方团队还在排查问题时，数据库已经自动完成了恢复。</p><p><img src=\"https://static001.infoq.cn/resource/image/19/08/19e454f68f6d47b55c799f9dd03d5208.png\" /></p><p>OceanBase QPS监控截图</p><p><img src=\"https://static001.infoq.cn/resource/image/3e/2c/3ea65fbb151ffdcd27b1f4a01a4a692c.png\" /></p><p>问题现象时间轴分析</p><p>经过深入分析，发现是SAN存储交换机到核心交换机连接的一个端口出现了故障。虽然配置了多路径转发，但由于操作系统内核的超时时间与OceanBase切主时间不匹配，触发了OceanBase的自动选主操作。</p><p></p><p>而选主过程中，另外一台物理机也走的同样端口也出现了IO阻塞的问题，最终导致OceanBase进入无主状态，当多路径软件成功切换后，OceanBase未经过任何干预就完成了自动恢复。本质上是因为软件超时参数与硬件超时参数不匹配所导致，也是软硬件系统磨合不够充分的表现，通过相关参数的调整能减少RTO的时间。</p><p></p><p>在此次故障之前，大家对OceanBase的了解都停留在PPT层面：RPO=0、RTO&lt;30秒。直到这次故障才真切的感受到，故障时的快速切换和自动恢复能力是多么的重要。但是故障发生，项目组内部也有质疑声音出来：“OceanBase基于SAN存储的部署本来就是错的，我们就不该使用OceanBase。”</p><p></p><p>但经过深入的分析才发现并不是OceanBase的问题，也不是SAN存储的问题，而是有没有充分的磨合，软硬件相关的参数是不是最合适的。IOE架构之所以成为集中式架构下的最佳组合，正是经过广泛的实践和各种场景的锤炼，让软硬件都能在一个最佳的状态下提供服务。最终经过这次事件之后，大家统一认识，调整参数并不能根本性解决问题。原来部署在SAN存储上的OceanBase迁移到了本地盘硬件设备上，随后也逐渐演进到两地三中心多活架构部署。</p><p></p><p></p><h3>1.5.3&nbsp;执行计划跳变导致业务卡顿</h3><p></p><p>如果一个数据库厂商说100%兼容Oracle，保证迁移过程不出任何问题，那一定是自吹。即便做到了事前压测充分，且尽量覆盖完所有业务场景。但对于割接上线后的系统稳定性、兼容性还是要画问号。保证迁移过程中不出问题的关键在于，是否有及时有效的监控，以及出现问题后的快速应急手段。已经投产的应用，应急应该放在第一优先级。</p><p></p><p>在11月份某个周末，理赔系统出现慢SQL，导致理赔应用系统票据汇总操作卡顿超时。为什么系统已经稳定运行了半个多月，没有任何的业务变更，反而在周末业务低峰期出现问题？现场交付专家经过分析很快定位到原因：OceanBase的执行计划发生了跳变，导致执行计划走错。</p><p>交付专家经过进一步深入分析发现：OceanBase和其他数据库一样，通过使用执行计划缓存(Plan Cache)，对于相同的SQL（参数不同），跳过解析阶段，避免重新生成执行计划，以提升SQL的性能。但是早实际场景中，传入的参数往往是不同的，就像淘宝双11有热点库存，在保险行业也有大小机构号。虽然SQL看起来一样，但因为传入的参数不同，优化的手段和执行的路径也不一样。传统数据库（比如Oracle）为了选择最优的执行计划，会定期进行数据对象统计信息的收集（如每天夜间的维护窗口（maintenance&nbsp;window）），淘汰旧的执行计划，使新的执行计划能够按照实际的数据统计信息生成更准确更优的执行计划。OceanBase采用类似的方法，但由于OceanBase 每天进行数据冻结合并，增量数据落盘，数据库对象的实际数据信息（行，列，平均值等）会发生较大的变化。因此合并以后，计划缓存会进行清理，并根据第一次传入的参数生成执行计划进行缓存，默认情况下，只会保留一个执行计划。由于周末当时第一次传入的参数不具备普遍代表性，导致后续执行计划走错，产生了性能问题。</p><p>执行计划跳变是一个比较常见的数据库性能现象。Oracle先后推出了Cursor&nbsp;Sharing，Outline，Bind&nbsp;peeking，ACS，SPM等手段来优化改进，然而生产上也无法彻底规避执行计划走错的问题，新的数据库产品从Oracle 99%到100%的兼容优化也是最难的，也不是短时间能一蹴而就。对于这种小概率事件，应急就成为了最后的兜底手段，在不动应用的大前提下，通过数据库灵活的绑定执行计划，是出现突发问题时比较有效和容易落地的手段。实际整个迁移过程中，对于偶发的执行计划跳变，项目组也已经驾轻就熟，没有给迁移带来意外影响。</p><p>&nbsp;</p><p></p><h2>1.6&nbsp;整体效果</h2><p></p><p>从2020年9月到2021年9月，一年的时间里，该公司近100个业务系统全面实现国产数据库迁移，成为首家完成100%核心业务系统国产数据库迁移的大型金融企业，采用的数据库中OceanBase和PolarDB用量占比超过97%。</p><p>&nbsp;</p><p>该公司通过数据库的全面替换，实现了对数据资产的的全面安全保障能力，做到了：</p><p>1.100%数据库技术栈的安全可控，摆脱对Oracle数据库的依赖；</p><p>2.摆脱对小型机和高端存储的依赖；</p><p>3.促进云原生和分布式数据库应用成熟，从可用到好用并取得性能提升；</p><p>4.数据库服务集中管控，显著降低硬件及整体运维成本；</p><p>5.真正的实时扩缩容和高可用能力，轻松应对大促活动。</p><p>&nbsp;</p><p>从完全封闭的体系架构到逐步开放再到全面开放，该公司真正实现了对数据库核心技术的自主掌控。得益于云原生架构和分布式架构的弹性和资源池化能力，也自此能实现“一库多芯”，只需一条命令就可以把租户切换到海光服务器节点，实现了国产硬件的平滑替换。</p><p>&nbsp;</p><p>整体来看，该公司迁移后由于分布式数据库提供的高效压缩能力，存储容量的大小只有原来的1/3，加上高端小型机迁移到国产机架式服务器，设备投入节省近2亿元。</p><p>&nbsp;</p><p>硬件方面，该公司的数据库服务器及存储机柜数量利用率提高了300%，设备功率下降至原有1/3。经测算，该公司全年可节约电力约近千万度，为该公司数字化转型提供了源源不断的绿色动能，有力践行了国家双碳战略，部分冲销了公司由于自建数据中心带来的碳排放增量。</p><p></p><h1>2、&nbsp;总结</h1><p></p><p>行业角度看，今天国内大部分金融机构的核心业务仍然运行在国外的数据库上，这是一个我们无法回避的现实。数据库的替换不仅是一个产品的替换，替换的目的不单纯为了“国产”两个字，更重要的是：技术必须进步；替换后的新系统必须具备老系统和国外产品不具备的能力，不仅是性能和稳定，更多是对业务的敏捷支撑能力，和面对海量业务和不确定性的业务高峰时刻的处理能力，以及更上一层楼的金融级高可用能力。</p><p></p><p>这些年我们看过很多内容对于数据库替换进行了分析和畅想，但是在面对实际的大规模复杂的核心应用系统的技术平台替换过程中，尤其对于现有运行的环境的各种适配和兼容，对应用的友好性等需要实践出真知的问题。某超大型保险（集团）公司和阿里巴巴阿里云团队一同坚定实现的国产数据库全面迁移，为行业积累了弥足珍贵的经验，也将为今后的国产数据库迁移进程给出了很好的范例。</p><p>&nbsp;</p><p>作者简介</p><p>刘伟光，阿里巴巴集团副总裁、阿里云新金融&amp;互联网行业事业部总经理，CF40理事，毕业于清华大学电子工程系。加入阿里云之前，在蚂蚁金服负责金融科技的商业推广和生态建设工作以及蚂蚁区块链的商业拓展工作；他在企业软件市场深耕多年，曾经创建Pivotal软件大中华区分公司，开创了企业级大数据以及企业级云计算PaaS平台的市场先河。在创建Pivotal中国软件公司之前，刘伟光曾经担任EMC公司大中国区数据计算事业部总经理，并在Oracle公司工作多年，曾经创建了Exadata大中国区的产品事业部并担任事业部总监。</p>",
    "publish_time": "2022-08-01 13:34:28",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "首个跨平台的 Serverless 基准测评系统：华为云联合上海交大联合发布ServerlessBench 2.0",
    "url": "https://www.infoq.cn/article/Qc73rOL4sC6EAcWgONbW",
    "summary": "<p></p><blockquote>Key Takeaways1. 华为云联合上海交大，首次提出 Open Serverless Benchmark Initiative (OSBI) , 推动 Serverless 基准测评规范化、标准化；2.OSBI 由自定义度量规范 (Metric Specification, MS)，自定义基准规范 (Pillar Specification, PS), 和自定义模型（Model）组成；3.OSBI 发布首个跨平台的 Serverless 基准测评系统 ServerlessBench 2.0, 聚焦 FaaS 关键特性，提供丰富的测评基准和指标，并发布了针对四大开源 Serverless 平台的首批测评报告；4.OSBI ServerlessBench 2.0 是“服务器无感知创新计划”的首个亮相项目, 该创新计划旨在联合产学研用各方，推动通用全场景 Serverless 技术的发展和规范化建设。</blockquote><p></p><p></p><p></p><h2>背景</h2><p></p><p></p><p>受益于其按用付费 (pay-per-use)、自动弹性伸缩 (auto-scaling)、以及屏蔽后端复杂性的特征，Serverless 正成为下一代云计算的新范式[1]。与此同时，能够封装并兼容多平台、支持关键指标度量的基准测试系统，对于 Serverless 计算实现可持续的降本增效而言，至关重要。一方面，Serverless 系统设计者可以利用基准测试平台，刻画系统的关键性能指标，如冷 / 热启动时延、弹性扩容速度、QoS 保证下的最大并发等，为增强系统架构的性能提供 “度量先行”的有效工具；另一方面，Serverless 应用开发者可以借助基准测试对不同的 Serverless 平台进行对比和选择，从而设计并开发出更加高性能、低成本的 Serverless 应用程序。</p><p></p><h2>Open Serverless Benchmark Initiative</h2><p></p><p></p><p>为推动开放、开源、跨平台兼容的 Serverless 基准测评的规范化、标准化建设，华为云与上海交大联合提出业界首个 Open Serverless Benchmark Initiative (OSBI)。OSBI 包含两个规范和一个模型：自定义度量规范 (Metric Specification, MS)，自定义基准规范 (Pillar Specification, PS), 和自定义模型 (Model), 如图 1 所示。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/01/016551bde66be0a224d53fc804d49419.png\" /></p><p></p><p>图 1: OSBI - Open Serverless Benchmark Initiative</p><p></p><p>其中，自定义度量规范为 Serverless 特性指标的设计提供了规范化接口和扩展标准；自定义基准规范为测评场景用例的设计提供了标准化模板；自定义模型旨在提供统一的、跨平台兼容的指标设计和用例部署标准，包括多平台的接入标准和基准用例的生命周期管理标准等。同时，OSBI 支持申明式测评配置，以及一键式跨平台的对比分析。</p><p></p><h2>ServerlessBench 2.0 发布</h2><p></p><p></p><p>聚焦 FaaS 场景，OSBI 发布业界首个多平台兼容的 Serverless 基准测评系统 ServerlessBench 2.0。ServerlessBench 1.0 是针对 Serverless 计算的关键特性和指标而设计的基准测试平台，由上海交通大学研究团队发表于云计算顶级会议 SoCC 2020[2]。此次，华为云联合上海交大，在 ServerlessBench 1.0 的基础上，通过进一步的封装、抽象、扩展和强化，重磅推出 OSBI ServerlessBench 2.0，为社区提供涵盖 12 类基础性度量基准、5 大类跨平台度量基准、4 大类关键特性指标、且多平台兼容的 Serverless 开放测评系统。</p><p></p><p>同时，OSBI ServerlessBench 2.0 是“服务器无感知创新计划”的首个亮相项目成果。服务器无感知创新计划由中国信通院、上海交大、华为云联合推动落地，旨在链接产学研用各方，凝聚社区力量，围绕技术研究和标准制定等，促进通用全场景 Serverless 的蓬勃发展和规范化建设[3]。</p><p></p><h2>ServerlessBench 2.0 介绍</h2><p></p><p></p><p>ServerlessBench 考虑 Serverless 计算中的四大类关键指标：通信性能（communication performance），启动时延（startup latency），无状态开销 (stateless overhead)，和资源使用效率 (resource utilization)。复杂的 Serverless 应用一般由多个函数组合实现，因此，通信性能指标主要度量函数间通信的效率问题，如常见的函数组合模型 sequence chain 和 nested chain 等。Serverless 函数通常运行时间较短，大多集中在百毫秒级至秒级的范围[4]，且函数执行环境按需加载，自动扩容，因此冷启动、热启动等时延开销是 Serverless 系统和应用最为关注的性能指标之一。在无状态开销指标中，通常包括依赖外部存储服务进行传递的显式状态（如函数逻辑本身所涉及的状态），以及可能影响系统性能的隐式状态（如会话缓存等）。资源使用效率指标主要衡量性价比问题，对于平台，如何在函数混合部署且保证业务 QoS 的前提下提升资源利用率，对用户而言，如何配置合理的资源规格来使得应用性能和成本之间取得最佳平衡。</p><p></p><p>围绕四大类关键指标，ServerlessBench 提供包括资源需求（Bench Pillar 1-varied resource needs），数据迁移开销（Bench Pillar 5-Data transfer costs）, 和 CPU 争用（Bench Pillar 12-CPU contention）等在内的 12 类基准，如表 1 所示。</p><p></p><p>表 1：ServerlessBench 1.0 提供的 12 类基准</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e7/e7a63b56bd76c8d9e0b9e96b09c9b03a.png\" /></p><p></p><p>为良好地兼容多平台, 依据 OSBI-Model, ServerlessBench 2.0 提供了统一的测评接口，对不同 Serverless 平台之间的异构性进行封装，包括统一的函数接口、统一的返回格式，统一的资源配置，以及统一的依赖包装等，如图 2 所示。这里以开源 Serverless 系统为例。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/17/172b39d30b775b2569c41a8c52c78915.png\" /></p><p></p><p>图 2：ServerlessBench 2.0 的多平台兼容性（以开源 Serverless 系统为例）</p><p></p><p>具体以函数调用入口为例，如图 3 所示，四大开源 Serverless 平台 OpenWhisk，OpenFaaS, Knative，Fission 的入口函数都不相同。针对该场景，ServerlessBench 2.0 通过接口抽象，封装了统一的入口函数 def handler(event, context)（这里以 Python 为例），从而使得在跨平台的对比中，无须再关心平台之间的接口差异性。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f9/f9c0f11e8c95c7e99cec570a886e6ce6.png\" /></p><p></p><p>图 3：ServerlessBench 2.0 为多平台提供统一的函数调用入口（以 Python 为例）</p><p></p><p>在多平台兼容的基础上，遵循 OSBI-MS 和 OSBI-PS 规范，ServerlessBench 2.0 对表 1 所列的测试基准进行了扩展，新增了冷热启动开销、冷热执行开销、保证 QoS 的最大并发、弹性扩容速度、性价比等 5 大类跨平台基准，如表 2 所示；同时，更多跨平台基准还在持续更新中，如带有函数链的 Serverless 应用等。</p><p></p><p>表 2：ServerlessBench 2.0 新增 5 类跨平台测试基准</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d8/d89fb8de9b531aa6364ab9634161148e.png\" /></p><p></p><h2>首批针对开源 Serverless 平台的测评结果</h2><p></p><p></p><p>作为 ServerlessBench 2.0 的首批测评结果，我们此次选取四大 serverless 开源平台 OpenWhisk，OpenFaaS，Knative，Fission，作为测评对象，部分关键测评结果展示如下。</p><p></p><h3>1．冷、热启动时延</h3><p></p><p></p><p>测试从调用 invoke 指令到函数的第一条指令的时间差。图 4 所展示的结果为 p90 的时延开销。可以看到，OpenFaaS 在冷热启动性能上表现最差；得益于资源池预热技术，Fission 在冷启动性能上表现最佳。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/05/05887745be3c4e76c4bea76e2c0f02f2.png\" /></p><p></p><p>图 4：四大 Serverless 开源平台“冷、热启动时延”测评结果对比</p><p></p><h3>2. 冷、热执行时延</h3><p></p><p></p><p>利用 Float Operation，测量函数本身的运行时延，考察冷、热启动对函数执行时间的影响，结果如图 5 所示。OpenWhisk 和 OpenFaaS 上函数执行时延基本不受冷热启动的影响。但相比于冷启动，Knative 和 Fission 在热启动的情况下，执行时延都有所改善。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5f/5f20ba1e83abf4425b43710201cad148.png\" /></p><p></p><p>图 5：四大 Serverless 开源平台“冷、热执行时延”测评结果对比</p><p></p><h3>3. 请求并发数对 QoS 的影响</h3><p></p><p></p><p>利用 Float Operation，计算不同并发数下函数实例的 p90 时延，该用例度量的是平台的函数密度支持能力。从图 6 可以看到，除 Fission 外，其它三大平台上，随并发请求数的增长，函数实例的 p90 时延基本呈线性增长。同“冷、热启动时延”的结果相似，由于 Fission 预置了一部分通用资源池，在并发请求数增长的初期，函数 p90 时延没有明显增长；但随着并发数的继续增长，资源池被逐步消耗，直至需要进行补充时，时延出现显著增长。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3d/3de37198a8f50869cdd01b2d326b7076.png\" /></p><p></p><p>图 6：四大 Serverless 开源平台“请求并发数对 QoS 的影响”测评结果对比</p><p></p><p>这里需要指出，在各大云服务提供的 Serverless 或函数系统中，请求并发数对函数执行时延或业务 QoS 的影响是一个更加复杂的过程，还包括其它多个影响因素，如单实例并发数，最大并发实例数限制，平台扩容策略，实例调度策略等。</p><p></p><h3>4. 弹性扩容能力</h3><p></p><p></p><p>利用 Float Operation，测试并观察实例数量从 1 伸缩到某个较大值的过程中，多实例启动尾时延的大小。图 7 展示 OpenFaaS 和 Knative 从 1 个实例弹性扩容到 10 个实例的结果。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/6f/6fca03719d25f78ad3f03e25f17a3845.png\" /></p><p></p><p>图 7：OpenFaaS 和 Knative “弹性扩容能力”测评结果对比</p><p></p><h3>5．平台性价比</h3><p></p><p></p><p>利用 Numpy Matmul，逐步调整给函数所分配的资源数量，测量并观察资源数量对函数的执行时延（图 8）与函数实例成本（图 9）的影响。该用例反映的是相同资源开销下，函数在不同 Serverless 平台上的性能表现。图 8 和图 9 展示了在 OpenFaaS 和 Knative 上的部分结果。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/78/78c289cf4b88a589daaff1031bf267c4.png\" /></p><p></p><p>图 8：OpenFaaS 和 Knative“平台性价比：资源与执行时长”测评结果</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/10/109a85bb908d8cd5eaf92a1e1645bc44.png\" /></p><p></p><p>图 9：OpenFaaS 和 Knative“平台性价比：资源与实例成本”测评结果</p><p></p><h2>未来规划</h2><p></p><p></p><p>OSBI 及其 ServerlessBench 2.0 建立在开源开放的理念之上，将由社区共同运营并持续共建。华为云将继续联合上海交大，推出包括华为云 FunctionGraph 在内的各大公有云服务 Serverless 平台的测评报告，并贡献给社区。另外，我们正在为 OSBI 和 ServerlessBench 2.0 建立项目主页，并推动源码开源等工作。关于 ServerlessBench 1.0 的详细信息，可参见项目主页[5]和 github 主页&nbsp;[6]。</p><p></p><p>此次 OSBI 和 ServerlessBench 2.0 的发布，旨在联合社区共建 Serverless 基准测评的规范与标准。华为云结合自身丰厚的技术积累与多年的发展经验，积极参与、主导相关技术及其服务的规范建设和标准制定, 如 FunctionGraph 与 CNCF Serverless Workflow 携手开拓 Serverless 编排新时代[7]。同时，我们期待与更多的 Serverless 爱好者及从业人员共同推动 OSBI 和 ServerlessBench 2.0 的繁荣发展。</p><p></p><p>作者介绍：</p><p></p><p>历川，华为云 Serverless 研发专家</p><p></p><p>平山，华为云中间件 Serverless 负责人</p><p></p><p>冯嘉，华为云中间件首席专家</p><p></p><p>参考链接：</p><p></p><p>[1].Schleier-Smith, et al. (2021). What serverless computing is and should become: The next phase of cloud computing. Communications of the ACM, 64(5), 76-84.</p><p></p><p>[2].Yu, T., et al. (2020). Characterizing serverless platforms with ServerlessBench. In Proceedings of the 11th ACM Symposium on Cloud Computing (pp. 30-44).</p><p></p><p>[3].<a href=\"https://mp.weixin.qq.com/s?__biz=Mzg5MDU0MDQ0MQ==&amp;mid=2247492242&amp;idx=1&amp;sn=a9a8ca899f723155d10d25aef6eb54ad&amp;scene=21#wechat_redirect\">https://mp.weixin.qq.com/s/vuhqCweenT7sozNzInavyQ</a>\"</p><p></p><p>[4].Shahrad, M., et al. (2020). Serverless in the wild: Characterizing and optimizing the serverless workload at a large cloud provider. In 2020 USENIX Annual Technical Conference (USENIX ATC 20) (pp. 205-218).</p><p></p><p>[5].<a href=\"https://serverlessbench.systems/\">https://serverlessbench.systems/</a>\"</p><p></p><p>[6].<a href=\"https://github.com/SJTU-IPADS/ServerlessBench\">https://github.com/SJTU-IPADS/ServerlessBench</a>\"</p><p></p><p>[7].<a href=\"https://bbs.huaweicloud.com/blogs/336135\">https://bbs.huaweicloud.com/blogs/336135</a>\"</p>",
    "publish_time": "2022-08-01 14:33:53",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "拒绝高估值？这家低代码平台火了后：不能让老员工凭股权成百万富翁、新员工失望",
    "url": "https://www.infoq.cn/article/RiXlIZZtpiDszF7SLS7z",
    "summary": "<p>编译｜燕珊、核子可乐</p><p></p><p>低代码开发平台Retool近日<a href=\"https://retool.com/blog/series-c2/\">宣布</a>\"，其在C2轮融资中以32亿美元的估值融到了4500万美元。</p><p></p><p>按照Retool联合创始人兼CEO David Hsu的说法，本轮融资是其“非常规筹资方法的延续”——2021年12月，Retool宣布完成2000万美元C轮融资（估值为18.5亿美元），当时最为人不解的是，在C轮之前的B轮，Retool可是融了5000万美元，这样反其道而行的“压低融资额度”的做法，让外界纷纷热议。而这次的C2轮，实际上也符合David此前透露的融资策略：每6到9个月进行一轮小规模、渐进式融资。</p><p></p><p>“我们不是以最高估值筹集最大数额的资金，而是以较低的估值进行小轮融资，从而最大限度地减少稀释并为员工保留了上升空间。我们的融资策略是为我们的团队而优化、而不是为虚荣的指标。”David Hsu在博客中写道。</p><p></p><h2>瞄准企业内部应用</h2><p></p><p>在了解Retool的融资思路之前，我们不妨先来看看Retool是做什么的，它为什么能有这么高的估值？</p><p></p><p>Retool是面向企业的低代码开发平台，号称提供 “一种构建软件的新方法”，尤其是面向内部的软件。值得一提的是，自2017年成立以来，已经有超过50万个应用程序在其平台上建立，数十亿次的查询也说明了该平台的使用率很高。</p><p></p><p>它的用户涵盖规模不一的团队，从初创公司（Brex、Checkout.com、CRED 等）到大型企业。例如，NBC（美国全国广播公司）通过 Retool 安排奥运会，Snowflake通过 Retool应用程序每月节省了数千小时的手动工作，亚马逊通过Retool处理GDPR（《通用数据保护条例》）出口......“Retool平台的灵活性和便捷性使我们的内部工具路线图的范围从长达几年变为几个月。”Coursera的高级工程经理Shon Saoji说：“Retool改变了我们的运营方式。”</p><p></p><p>“我们很高兴这些公司通过Retool构建的高质量的内部软件为其内部运作提供动力。”David表示，软件正在吞噬世界，但内部软件的世界却常常被忽视。</p><p></p><p>Retool的核心平台是围绕90个“组件”而建，这些组件可以组合在一起——与其说是以“低代码”的方式，不如说是为软件开发者和工程师提供了一些基本的构件，比如表单、图表和表格的方式。在此基础上，它提供验证、可访问性和其他所需工具。开发人员可以连接任何数据库或API——任何与REST或GraphQL相关的，也支持PostgreSQL、MongoDB或其他数据存储。</p><p></p><p>延展阅读：<a href=\"https://mp.weixin.qq.com/s/hET0Zek0LFLYhFsG3W_KPw\">《Retool 如何升级主应用 4TB 的 PostgreSQL 数据库》</a>\"</p><p></p><p>“对内部应用程序的关注很有意思。在某种程度上，这意味着Retool的形象仍然相对较低。”TechCrunch评价道。</p><p></p><p>David表示，这是公司的一个战略选择，因为内部应用占世界上所有应用的50%以上，而且它们正是企业可能需要更多定制化东西的用例，这些东西可能在私有云上运行，或在本地运行，或只是与他们正在使用的任何传统/更现代的系统一起运作。</p><p></p><p>然而，需要注意的是，内部应用也不是Retool的长期发展方向。Retool未来的计划包括构建功能，让开发者也可以在面向客户的应用程序和潜在的面向消费者的产品上进行开发。</p><p></p><p>红杉资本合伙人Bryan Schreier表示：“Retool处于两大趋势的交汇点：一是开发者的崛起，二是数字化转型因为疫情而加速，卓越运营的重要性变得越来越大。Retool使工程师能够以非常快的速度构建内部软件从而加速企业运营。Retool完全有能力定义企业内部工具的未来，更广泛地说，也是定义开发者实际开发的方式。面对宏观经济的不确定性，Retool的价值主张更加鲜明。”</p><p></p><h2>坚持小众融资道路</h2><p></p><p>David 此前在受访时曾提到，Retool于2017年从Y Combinator毕业时只有四名员工，当时营收就已经达到数百万美元。</p><p></p><p>创立一家新公司，然后手握融来的大把资金在阳光海滩上工作可能是绝大多数人的梦想。但David有自己的想法，他带领Retool在2019年春筹集到第一笔资金，随后于2020年初由红杉领投了2500万美元A轮融资，同年10月又由红杉再次领投B轮融资。但David表示，Retool几乎就没用过这笔钱。</p><p></p><p>随后在C轮融资当中，Retool打破了初创企业的典型运营思路（C轮融资总额为2000万美元，估值为18.5亿美元、两倍于上轮融资评估）。在完成由红杉领投的5000万美元B轮融资的一年之后，David 转而求助于最早的一批个人投资者，包括Color Genomics联合创始人Elad Gil、Stripe联合创始人John Collison与Patrick Collison，以及GitHub前CEO Nat Friedman，希望尽量让Retool继续保持住较小的体量。</p><p></p><p>David 承认，其他科技企业大多乐于追求让人目眩神迷的巨额估值和高达数十亿美元的交易价码。Retool却故意反其道而行，在能够控制的范围内尽可能缩减融资数字。他进一步解释道，“大多数人都觉得估值越高越好、融资越多越好，但其实较低的估值和资金引入量，更有利于保障员工股权。”</p><p></p><p>在此之后，David关于精益融资的想法得到了验证和巩固。他发现一个令人费解的问题：一旦企业估值达到50亿或100亿美元，之后加入科技企业的员工所能获得的财务收益将远低于之前的老员工。为了保障员工利益，David决定每6到9个月进行一轮小规模、渐进式融资，这样的话一位典型工程师在行使股票期权时往往能多拿100万美元，而公司高管则有望多拿到上千万美元。</p><p></p><p>David坦言，“在跟求职者交流时，很多人都害怕公司已经估值过高，错过了最佳价值上升期。我们有责任让公司团队用付出换取更好的回报，这也让Retool吸引到了很多优秀人才。”</p><p></p><h2>大部分初创企业没法照搬Retool的融资思路</h2><p></p><p>作为Retool的支持者，投资方们纷纷表示，这种新方法能帮助该公司更审慎地花费资金，并在同等规模的企业之间获得最强的人才争夺优势。前GitHub掌门人、现任Xamarin CEO的Friedman表示，“在热量过剩的世界中，自律的人才能保持健康。我认为通过融资优化吸引顶尖人才、着力保障他们的利益，其实也最符合公司自己的利益诉求。”</p><p></p><p>但市场上也不乏反对的声音。有风险投资家指出，一旦目前充裕的资本周期发生波动，那么Retool强调小额融资、寄希望于高频筹款的思路可能会带来风险。以Slack的Stewart Butterfield为例，不少企业家认为最好能在融资成本低的时候尽可能多吸纳资金。但风险投资公司Renegade Partners联合创始人兼董事总经理Roseanne Wincek认为，很多初创公司的高管其实是透支了业务优势，相当于亲手放弃了成长为独角兽企业的机会。她还指出，在Uber等上市大厂中，早期员工凭借高股权轻松成为百万富翁的现实，往往会令后来的新员工心灰意冷、甚至爆发文化层面的冲突。</p><p></p><p>Wincek认为，“最明智的作法，就是把员工的权益和收获纳入融资规划。没错，核算方面的工作最好别做得太精，否则就会陷入细节无法自拔。但在原则上，在筹集资金的同时考虑到全体股东的权益，确实才是正确的思路。”</p><p></p><p>但必须承认，大部分初创企业其实没法照搬Retool的这条融资道路。毕竟湾区以外的初创公司根本接触不到Y Combinator或者红杉这些强大的支持性力量，也难以吸引像Stripe公司Collison兄弟这样财力雄厚的天使投资人。只有这样的优质资金，才愿意共同参与多轮融资来换取远低于传统风险投资商的股权比例。另外，相当一部分初创企业的烧钱速度确实很快，甚至需要跟其他风投支持下的竞争对手开展军备竞赛，所以钱肯定是越多越好。红杉资本的Bryan Schreier表示，“毫无疑问，Retool赌赢了，但不是每家公司都能采用他们的策略。”</p><p></p><p>在Retool，David倒是希望自己的思路能为更多初创企业所采纳。但他也承认，最适合的应该是那些具备较高资本效率的软件即服务类公司。这位创始人认为，拒绝高估值确实是个“很有风险的提议”，但他乐意亲身探索。“我们要用自己的努力说服大家。这需要一段时间，但我们会尽力而为。”</p><p></p><p>参考链接：</p><p></p><p><a href=\"https://retool.com/blog/series-c2/\">https://retool.com/blog/series-c2/</a>\"</p><p></p><p><a href=\"https://techcrunch.com/2022/07/28/retool-raises-45m-at-a-3-2b-valuation-to-make-building-custom-software-as-easy-as-buying-off-the-shelf/\">https://techcrunch.com/2022/07/28/retool-raises-45m-at-a-3-2b-valuation-to-make-building-custom-software-as-easy-as-buying-off-the-shelf/</a>\"</p><p></p><p><a href=\"https://www.forbes.com/sites/alexkonrad/2021/12/22/retool-unicorn-funding-round-follows-risky-employee-first-approach/?sh=7ebf1d944f49\">https://www.forbes.com/sites/alexkonrad/2021/12/22/retool-unicorn-funding-round-follows-risky-employee-first-approach/?sh=7ebf1d944f49</a>\"</p>",
    "publish_time": "2022-08-01 15:57:12",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]