[
  {
    "title": "Spotify 的平台迁移经验：从小事做起，关注利益相关者，寻求自动化",
    "url": "https://www.infoq.cn/article/wtufrhBsNxaTlJi70DCK",
    "summary": "<p>在管理不断壮大的开发团队与愈发复杂的代码库的同时，还要提供更快也更可靠的交付，这似乎是飞速发展的科技公司都难逃的挑战，对平台团队而言也是一样。在代码库和组织不断增长的现状下，我们要如何快速推陈出新、更安全地引入新技术呢？</p><p></p><h3>问题域</h3><p></p><p>从2019年的29%，2020年的49%，到2021年的23%，Spotify的移动端代码库规模一直在急速扩大。随着我们在业务上的扩展，Spotify Live等新体验的加入，代码库也在不断演化。而于此同时，Spotify也在不断招收新工程师，致使移动端代码库的修改次数逐渐增加。</p><p>&nbsp;</p><p>我们的移动工程策略项目于一年半前发起了一项倡议，通过多次迁移让客户端功能得以在独立环境中进行开发，类似于后端微服务。</p><p>&nbsp;</p><p>自此之后，我们将系统与约2,200个安卓及iOS组件相关联，将大部分安卓与iOS代码库迁移至谷歌的开源构建系统<a href=\"https://bazel.build/\">Bazel</a>\"进行构建。这一大工程影响了公司上下上百的项目组。</p><p></p><h3>主要难点</h3><p></p><p>我们认为，代码库和组织规模的增长与复杂性的加剧将会是迁移的主要难点所在。如果我们期望能在Spotify的移动端高效且规模化交付平台解决方案，就需要常态化迁移所带来的挑战。</p><p>&nbsp;</p><p>以下是我们在迁移路上所遇到的挑战，其中囊括了场景和问题表征，以及面对问题时应当避免或鼓励的行为。</p><p></p><h4>挑战之一：界定范围</h4><p></p><p>如何在创造变化并提出可支持大部分用例的标准化架构解决方案的同时，不影响其他用例？</p><p>&nbsp;</p><p>场景：</p><p>这一范围看似很广，给人一种无数用例亟待处理的感觉。在面对大量的技术债务、需要的改动、需要支持的用例时，往往会让人无从着手。利益相关者们即使是在多次询问后，也还是对迁移时自己要做的事云里雾里。</p><p>&nbsp;</p><p>应避免：</p><p>在还未确定所有可能情况之前便试图推出解决方案。在尚未预估路线图或成功的界定之前便开始大规模迁移。在没有明确定义利益相关者需要做的事之前便接触他们。</p><p>&nbsp;</p><p>应鼓励：</p><p>清楚目标。在产品简介中写明你的原因、方法，以及目的。注重价值。价值的转变是很耗时的，但需要的时候也要对其调整以适应你的目标。应对受众。了解受众的心智模式才能给出相关的回应、对接他们的需求，并寻找到合适的代理以扩大自己的影响。从小事做起。创建一份概念证明，和利益相关者们核对其内容，并让迁移经历alpha、beta，以及GA产品循环。从最常见的用例开始，随进展不断添加新发现的用例。这一步会让你收到足够的反馈，并渐渐能够支撑不同用例情况。合作！在早期阶段，合作是关键。寻找愿意积极试用早期解决方案的人，他们将成为自己群组内的传播者。这点最后也将助力于方案的可扩展性。&nbsp;</p><p></p><h4>挑战之二：扩大规模</h4><p></p><p>在飞速扩张的组织内，我们要如何才能更快地推动大型架构和基础设施的变化？</p><p>&nbsp;</p><p>场景：&nbsp;</p><p>大量项目组将会受变动影响（超过百个项目组）工作量巨大。其中包括迁移中途需要团队手动重构的任务进展缓慢。涉及无数利益相关者与依赖关系利益相关者被进行中的迁移工作重担压垮</p><p>&nbsp;</p><p>应避免：</p><p>认为大型组织中的大型基础设施和架构中的变动是不可能或不需要的在进行架构或基础设施变动时要缓慢前行</p><p>&nbsp;</p><p>应鼓励：</p><p>关注利益相关者的管理。明确不同利益相关者的优先级，通过邮件或Slack等形式保持联络，并将自己工作的重点相告知。沟通。通过邮件及工作区发帖将自己的进度共享，让受众保持参与感。寻求自动化。预先投入的自动化会简化迁移进程。我们是否需要重构代码？是否能通过脚本将重复步骤自动化？为敏捷的spike周腾出时间。团队与贡献者组队，用一周时间协同合作迁移。通过不同资源提升影响力。培训项目可以帮助团队了解迁移和新的概念，从而能够立刻将其投入应用。在公司的入职计划中介绍公司的工程实践，让新员工能从一开始就理解并遵循所推荐的最佳实践。</p><p></p><h4>挑战之三：事件优先级</h4><p></p><p>平台团队是需要努力减少技术债务并引入新技术，还是要让其对自己代码质量负责？这二者之间要如何平衡？</p><p>&nbsp;</p><p>场景：</p><p>利益相关者参与了优先级更高的项目，而无暇采用你的解决方案。利益相关者认为平台迁移拖慢了他们的脚步，缺乏采用新技术的动力。项目被稀释，推动迁移进行的团队没有动力，甚至有成员选择离开团队。必要的代码修改与迁移方向相左。</p><p>&nbsp;</p><p>应避免：</p><p>自信利益相关者明白迁移的重要性和影响程度，并将其优先处理。实际上他们也有很多其他任务要处理。放弃。“我们忙于抢占更高优先级”，这是个平台迁移中很常见的放弃理由。认为指标和目标是固定且很难变动的。</p><p>&nbsp;</p><p>应鼓励：</p><p>应激励，向利益相关者展示迁移的积极影响，鼓励他们完成迁移任务。持续评估。季度内定期的检查点可以评估迁移进行的速度，判断是否能达成季度、半年度或年度的指标。风险管理。如果迁移进展过慢，要如何调整方法以达成目标？是否能精简流程？是否需要更多工程师？能否雇佣承包商？能否影响其他团队，把自己的任务加入他们积压的工作之中？替平台承担。可能的情况下，为组织做出必要变动，以便组织能专注于为用户创造价值。密切关注与迁移KPI相违背的变动，建立与团队之间的渠道以提供支持。</p><p>&nbsp;</p><p></p><h4>挑战之四：承担责任</h4><p></p><p>如何才能在需要大量变动和重构基础设施的新技术采用过程中，让团队承担起责任？</p><p>&nbsp;</p><p>场景：</p><p>在新技术的采用过程中缺乏责任感，导致迁移进展缓慢。</p><p>无法预估迁移何时结束。</p><p>&nbsp;</p><p>应避免：</p><p>在驱动大量改动时指望内外部能保持一致性。认为基础设施上的变动和影响很难衡量。</p><p>&nbsp;</p><p>应鼓励：</p><p>明确“完成”的定义。借助数据和趋势图给出预测。我们需要清楚自己的出发点和进展速度，才能预估未来的趋势，并确定是否需要调整策略以加快迁移进展。进度展示。掌控成功的定义且不断沟通，才能保持受众参与并接受我们所做的变动。使用看板。通过指标和看板沟通进展和影响，并规模化确定一段时间内的工作优先顺序。维护时间线并实时更新路线图。随着时间的推移，团队和利益相关者可能会有变动，他们需要了解我们的迁移进程和时间线。路线图也有助于透明化，让反馈和协作成为可能，也能帮助发现障碍。</p><p></p><h3>结论</h3><p></p><p>这种性质和规模的迁移工作可能会成为未来的常态，若非如此，公司可能将无法执行特定的变动。新科技将会不断出现，迁移也将成为必然，但我们也应减少这些动作对团队的干扰。有的平台产品或许会让迁移无可避免，且可能会规模不小，我们应将其与测试、设计共同视作是开发周期的一部分。</p><p>&nbsp;</p><p>我们从这项工作中学到了很多，希望这些经验能对其他团队的大型迁移有所帮助。如果你想了解更多关于我们所遇到的挑战和相应的解决方法，请随时联系我们。</p><p>&nbsp;</p><p>特别感谢Marvin、Foundation、BoB，以及Rubik，为我们的工作提供助力。</p><p></p><p>原文链接：</p><p><a href=\"https://engineering.atspotify.com/2022/11/strategies-and-tools-for-performing-migrations-on-platform/\">Strategies and Tools for Performing Migrations on Platform</a>\" </p><p></p>",
    "publish_time": "2024-01-30 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "KSP2 致力于改善 Kotlin 元编程，并添加对 K2 Kotlin 编译器的支持",
    "url": "https://www.infoq.cn/article/PPC5WXDEyXlVoS18ZGP9",
    "summary": "<p>KSP 2.0 是 Kotlin 符号处理（Kotlin Symbol Processing）的演进版本，目前处于预览状态，谷歌的软件工程师 Ting-Yuan Huang 和 Jiaxiang Chen 说到，它引入了新的架构，旨在解决 KSP 1.0 中的一些局限性，并增加了对新的 K2 Kotlin 编译器的支持。</p><p></p><p>KSP1 是作为编译器插件的形式实现的，而 KSP2 是一个独立的库，无需设置编译器即可运行，并能完全控制其生命周期。Huang 和 Chen 说，这使得以编程方式调用 KSP 以及在 KSP 处理器中设置断点变得更容易。下面的代码展示了如何配置 KSP2 并执行它来处理符号的列表：</p><p></p><p><code lang=\"kotlin\">val kspConfig = KSPJvmConfig.Builder().apply {\n  // All configurations happen here.\n}.build()\nval exitCode = KotlinSymbolProcessing(kspConfig, listOfProcessors, kspLoggerImpl).execute()\n</code></p><p></p><p>KSP2 中另外一个值得注意的差异是，它使用了仍处于 beta 状态的 Kotlin K2 编译器来处理源码。不过，如果你愿意的话，也可以通过在gradle.properties中设置languageVersion属性，从而以 K1 的方式使用 KSP。</p><p></p><p>除此之外，KSP2 还旨在解决 KSP1 中的一个缺陷，即同一个源文件可能会被编译多次。借助与 K2 的集成，KSP2 尝试调整 K2 编译文件的方式，使其只处理一次，从而能够提升性能。</p><p></p><p>KSP2 还引入了一些行为的变化，以提高开发人员的工作效率，以及可调试性和错误恢复能力。</p><p></p><p>在 KSP 1.0.14 或更新的版本中，可以在gradle.properties中使用一个标记来启用新的 KSP 预览版本：</p><p></p><p></p><blockquote>ksp.useKSP2=true</blockquote><p></p><p></p><p>KSP 是一个支持创建插件来扩展 Kotlin 编译器的 API。它以独立于编译器的方式理解 Kotlin 的语言特性，如扩展函数、声明处型变（declaration-site variance）和局部函数。</p><p></p><p>该 API 根据 Kotlin 语法在符号层对 Kotlin 程序结构进行建模。当基于 KSP 的插件处理源程序时，处理器可以访问类、类成员、函数和相关参数等构造结构，而 if 代码块和 for 循环等则无法访问。</p><p></p><p>这使得基于 KSP 的插件不像建立在kotlinc之上的插件那样脆弱，后者功能更强大，但是严格依赖于编译器的版本。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2024/01/ksp2-kotlin-metaprogramming/\">https://www.infoq.com/news/2024/01/ksp2-kotlin-metaprogramming/</a>\"</p>",
    "publish_time": "2024-01-30 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Neuralink完成全球首例人类脑机芯片植入手术，马斯克：植入者恢复良好",
    "url": "https://www.infoq.cn/article/w7ks2bB2Gc31qgrt3pXB",
    "summary": "<p>1月30日，脑机接口公司Neuralink创始人埃隆·马斯克在X（Twitter）上宣布：在昨天，人类首次接受脑机接口（Neuralink）芯片植入，植入者恢复良好。马斯克在随后的帖子中表示，Neuralink的第一款产品名为“心灵感应”。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3a/3a4d210f40b261d175830b696a7a9c12.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/97/97165c85614dbc3f3355c3a7c5dc1383.png\" /></p><p></p><p>&nbsp;</p><p>资料显示，Neuralink由马斯克和其他一群科学家和工程师于 2016 年创立。它致力于开发脑机接口 (BCI)，将人脑连接到能够破译神经信号的计算机，旨在帮助严重瘫痪的患者仅使用神经信号来控制外部技术。马斯克称，Neuralink 的设备可以实现“超人认知”，使瘫痪的人有一天能够用他们的思想操作智能手机或机器人肢体，并“解决”自闭症和精神分裂症。</p><p>&nbsp;</p><p>如果这项技术功能正常，患有严重退行性疾病(如ALS)的患者有一天可以使用植入物通过移动光标和用大脑打字来交流或访问社交媒体。马斯克写道：“想象一下，如果斯蒂芬·霍金的沟通速度比打字员或拍卖师还快。”“这就是我们的目标。”</p><p>&nbsp;</p><p>2022 年11月30日，马斯克曾在 Neuralink 发布会上展示了一只头骨上装有电脑芯片的猴子“Sake”，在玩心灵感应视频游戏，并要到了葡萄零食的镜头。猴子“Sake”通过屏幕和脑里植入的 Neuralink 的 N1 设备，来追踪屏幕上的移动光标，拼出了“Can I please have snacks”的英文短句，全程和键盘没有物理接触。</p><p>&nbsp;</p><p>马斯克说，猴子其实不会拼写，它们只是将大脑信号转化为光标移动，迭代到下一个版本才能让猴子具备拼写能力。马斯克还在演讲中表示，Neuralink 还将致力于恢复视力。“即使有人从未有过视力，他们先天就失明了，我们相信我们的设备仍然可以帮助其恢复视力”。</p><p>&nbsp;</p><p>当时，Neuralink 还未获得美国食品和药物管理局（FDA）的批准，因此一直在在对动物进行测试。马斯克说：“我们希望非常小心，并确保它在将设备放入人体之前能正常工作。”</p><p>&nbsp;</p><p>马斯克还表示，在人体测试开始后，他将在自己的大脑中植入脑机接口设备。“你可能现在就植入了一个 Neuralink 设备，而你甚至都不知道……在（未来）其中一个演示中，我会的” 他说。活动结束后，他在推特上重申了这一点。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cf/cf414be80d775a1718eb6f6c6fca114b.png\" /></p><p></p><p>2023年5月，Neuralink获得美国食品和药物管理局(FDA)批准。9月19日，Neuralink宣布，该公司已获得了独立机构审查委员会的批准，开始首次人体临床试验招募人员。Neuralink表示，因颈部脊髓损伤或肌萎缩侧索硬化症（ALS）而瘫痪的患者可能符合参加这项试验的条件。</p><p>&nbsp;</p><p>Neuralink没有透露将有多少人类患者参与其最初的人体试验。据悉，人体临床试验只是Neuralink走向商业化道路上的一步。去年的融资情况显示，Neuralink的估值已高达50亿美元（约合人民币359亿元）。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.cnbc.com/2024/01/29/elon-musks-neuralink-implants-brain-tech-in-human-patient-for-the-first-time.html\">https://www.cnbc.com/2024/01/29/elon-musks-neuralink-implants-brain-tech-in-human-patient-for-the-first-time.html</a>\"</p><p><a href=\"https://www.infoq.cn/article/6s4aDChIwYEOjVH62lGa\">https://www.infoq.cn/article/6s4aDChIwYEOjVH62lGa</a>\"</p>",
    "publish_time": "2024-01-30 11:19:06",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "百度大模型驱动下的智能代码助手提效实践",
    "url": "https://www.infoq.cn/article/biw3d0tLbjlQXkyyHwBV",
    "summary": "<p>Qcon上海站百度工程效能部资深研发工程师李杨坐镇，分享介绍百度大模型在智能代码助手领域的实现和落地场景。</p>\n<p>听众收益点：</p>\n<p>1.AIGC大潮下，帮助软件工程师们知道如何利用工具来进化自己<br />\n2.帮助大家了解工程师们如何用代码生成产品来提升自己的开发效率<br />\n3.了解百度代码生成工具Comate是怎么实现的，除了大模型本身，工程化方面的优化措施</p>",
    "publish_time": "2024-01-30 11:50:44",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "文本检索性能提升 40 倍，Apache Doris 倒排索引深度解读",
    "url": "https://www.infoq.cn/article/mow1CJlqo2IH6zkDoZes",
    "summary": "<p>在 OLAP 领域，<a href=\"https://doris.apache.org/\">Apache Doris</a>\" 已成为高性能、高并发以及高时效性的代名词。在面向海量数据的复杂查询需求时，除硬件配置、集群规模、网络带宽等因素外，提升性能的核心在于如何最大程度地降低 SQL 执行时的 CPU、内存和 IO 开销，而这其中数据库索引扮演着至关重要的角色。合理的索引结构设计可以跳过大量不必要的底层数据读取、快速检索定位到所需数据，并进一步提升后续计算的执行效率、降低查询 SQL 的运行时间和资源消耗。</p><p></p><p>Apache Doris 提供了丰富的索引以加速数据的读取和过滤，依据是否需要用户手工创建，索引类型大体可以分为智能内建索引和用户创建索引两类，其中智能内建索引是指在数据写入时自动生成的索引，无需用户干预，包括前缀索引和 ZoneMap 索引。用户创建索引需要用户根据业务特点手动创建，包括 Bloom Filter 索引和 2.0 版本新增的倒排索引与 NGram Bloom Filter 索引。</p><p></p><p>相较于用户比较熟悉的前缀索引、Bloom Filter 索引，2.0 版本所新增的<a href=\"https://mp.weixin.qq.com/s?__biz=Mzg3Njc2NDAwOA==&amp;mid=2247519079&amp;idx=1&amp;sn=a232a72695ff93eea0ffe79635936dcb&amp;chksm=cf2f8560f8580c768bbde99ef8ca97d3a42ecc03b5d8d106b85f5474c90b6068781a79b3611e&amp;scene=21#wechat_redirect\">倒排索引</a>\"和 NGram Bloom Filter 在文本检索、模糊匹配以及非主键列检索等场景有着更为明显的性能提升。本文将以 Amazon customer reviews 数据集为例，介绍 Apache Doris 在查询该数据集以及类似场景中，如何充分利用倒排索引以及 NGram Bloom Filter 索引进行查询加速，并详细解析其工作原理与最佳实践。</p><p></p><h2>数据集样例</h2><p></p><p>在本文中，我们使用的数据集包含约 1.3 亿条亚马逊产品的用户评论信息。该数据集以 Snappy 压缩的 Parquet 文件形式存在，总大小约为 37GB。以下为数据集的样例：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cf/cfa4cb6e2693f8e899bfeb6379554486.png\" /></p><p></p><p>在子集中，每行包含用户 ID（customer_id）、评论 ID（review_id）、已购买产品 ID（product_id）、产品分类（product_category）、评分（star_rating）、评论标题（review_headline）、评论内容（review_body）等 15 列信息。根据上述可知，列中包含了适用于索引加速的各种特征。例如，customer_id 是高基数的数值列，product_id 是低基数的定长短文本列，product_title 是适合文本检索的短文本列，review_body 则是适合文本搜索的长文本列。</p><p></p><p>通过这些列，我们可以模拟两个典型索引查询场景，具体如下：</p><p></p><p>文本搜索查询：搜索 review body 字段中包含特定内容的产品信息。非主键列明细查询：查询特定产品 ID（product_id）或者特定用户 ID（customer_id）的评论信息。</p><p></p><p>接下来，我们将以文本搜索和非主键列明细查询为主要方向，对比在有索引和无索引的情况下查询性能的差异。同时，我们也将详细解析索引减少查询耗时、提高查询效率的原理。</p><p></p><h2>环境搭建</h2><p></p><p>为了快速搭建环境，并进行集群创建和数据导入，我们使用单节点集群（1FE、1BE）并按照以下步骤进行操作：</p><p></p><p>搭建 Apache Doris ：具体操作请参考：<a href=\"https://doris.apache.org/zh-CN/docs/get-starting/quick-start/\">快速开始</a>\"创建数据表：按照下列建表语句进行数据表创建</p><p></p><p><code lang=\"sql\">CREATE TABLE `amazon_reviews` (  \n  `review_date` int(11) NULL,  \n  `marketplace` varchar(20) NULL,  \n  `customer_id` bigint(20) NULL,  \n  `review_id` varchar(40) NULL,\n  `product_id` varchar(10) NULL,\n  `product_parent` bigint(20) NULL,\n  `product_title` varchar(500) NULL,\n  `product_category` varchar(50) NULL,\n  `star_rating` smallint(6) NULL,\n  `helpful_votes` int(11) NULL,\n  `total_votes` int(11) NULL,\n  `vine` boolean NULL,\n  `verified_purchase` boolean NULL,\n  `review_headline` varchar(500) NULL,\n  `review_body` string NULL\n) ENGINE=OLAP\nDUPLICATE KEY(`review_date`)\nCOMMENT 'OLAP'\nDISTRIBUTED BY HASH(`review_date`) BUCKETS 16\nPROPERTIES (\n\"replication_allocation\" = \"tag.location.default: 1\",\n\"compression\" = \"ZSTD\"\n);\n</code></p><p></p><p>3.下载数据集：从下方链接分别下载数据集，数据集为 Parque 格式，并经过 Snappy 压缩，总大小约为 37GB</p><p></p><p><a href=\"https://datasets-documentation.s3.eu-west-3.amazonaws.com/amazon_reviews/amazon_reviews_2010.snappy.parquet\">amazon_reviews_2010</a>\"<a href=\"https://datasets-documentation.s3.eu-west-3.amazonaws.com/amazon_reviews/amazon_reviews_2011.snappy.parquet\">amazon_reviews_2011</a>\"<a href=\"https://datasets-documentation.s3.eu-west-3.amazonaws.com/amazon_reviews/amazon_reviews_2012.snappy.parquet\">amazon_reviews_2012</a>\"<a href=\"https://datasets-documentation.s3.eu-west-3.amazonaws.com/amazon_reviews/amazon_reviews_2013.snappy.parquet\">amazon_reviews_2013</a>\"<a href=\"https://datasets-documentation.s3.eu-west-3.amazonaws.com/amazon_reviews/amazon_reviews_2014.snappy.parquet\">amazon_reviews_2014</a>\"<a href=\"https://datasets-documentation.s3.eu-west-3.amazonaws.com/amazon_reviews/amazon_reviews_2015.snappy.parquet\">amazon_reviews_2015</a>\"</p><p></p><p>4.导入数据集：下载完成后，分别执行以下命令，导入数据集</p><p></p><p><code lang=\"bash\">curl --location-trusted -u root: -T amazon_reviews_2010.snappy.parquet -H \"format:parquet\" http://${BE_IP}:${BE_PORT}/api/${DB}/amazon_reviews/_stream_load\ncurl --location-trusted -u root: -T amazon_reviews_2011.snappy.parquet -H \"format:parquet\" http://${BE_IP}:${BE_PORT}/api/${DB}/amazon_reviews/_stream_load\ncurl --location-trusted -u root: -T amazon_reviews_2012.snappy.parquet -H \"format:parquet\" http://${BE_IP}:${BE_PORT}/api/${DB}/amazon_reviews/_stream_load\ncurl --location-trusted -u root: -T amazon_reviews_2013.snappy.parquet -H \"format:parquet\" http://${BE_IP}:${BE_PORT}/api/${DB}/amazon_reviews/_stream_load\ncurl --location-trusted -u root: -T amazon_reviews_2014.snappy.parquet -H \"format:parquet\" http://${BE_IP}:${BE_PORT}/api/${DB}/amazon_reviews/_stream_load\ncurl --location-trusted -u root: -T amazon_reviews_2015.snappy.parquet -H \"format:parquet\" http://${BE_IP}:${BE_PORT}/api/${DB}/amazon_reviews/_stream_load\n</code></p><p></p><p>5.查看与验证：完成上述步骤后，可以在 MySQL 客户端执行以下语句，来查看导入的数据行数和所占用空间。从下方代码可知：共导入 135589433 行数据，在 Doris 中占用空间 25.873GB，比压缩后的 Parquet 列式存储进一步降低了 30%。</p><p></p><p><code lang=\"sql\">mysql&gt; SELECT COUNT() FROM amazon_reviews;\n+-----------+\n| count(*)  |\n+-----------+\n| 135589433 |\n+-----------+\n1 row in set (0.02 sec)\nmysql&gt; SHOW DATA FROM amazon_reviews;\n+----------------+----------------+-----------+--------------+-----------+------------+\n| TableName      | IndexName      | Size      | ReplicaCount | RowCount  | RemoteSize |\n+----------------+----------------+-----------+--------------+-----------+------------+\n| amazon_reviews | amazon_reviews | 25.873 GB | 16           | 135589433 | 0.000      |\n|                | Total          | 25.873 GB | 16           |           | 0.000      |\n+----------------+----------------+-----------+--------------+-----------+------------+\n2 rows in set (0.00 sec)\n</code></p><p></p><h2>文本搜索查询加速</h2><p></p><p></p><h3>无索引硬匹配</h3><p></p><p>环境及数据准备就绪后，我们尝试对 review_body 列进行文本搜索查询。具体需求是在数据集中查出评论中包含“is super awesome”关键字的前 5 种产品，并按照评论数量降序排列，查询结果需显示每种产品的 ID、随机一个产品标题、平均星级评分以及评论总数。review_body 列的特征是评论内容比较长，因此进行文本搜索会有一定的性能压力。</p><p></p><p>首先我们直接进行查询，以下是查询的示例语句：</p><p></p><p><code lang=\"sql\">SELECT\n    product_id,\n    any(product_title),\n    AVG(star_rating) AS rating,\n    COUNT() AS count\nFROM\n    amazon_reviews\nWHERE\n    review_body LIKE '%is super awesome%'\nGROUP BY\n    product_id\nORDER BY\n    count DESC,\n    rating DESC,\n    product_id\nLIMIT 5;\n</code></p><p></p><p>执行结果如下，查询耗时为 7.6 秒</p><p></p><p><code lang=\"sql\">+------------+------------------------------------------+--------------------+-------+\n| product_id | any_value(product_title)                 | rating             | count |\n+------------+------------------------------------------+--------------------+-------+\n| B00992CF6W | Minecraft                                | 4.8235294117647056 |    17 |\n| B009UX2YAC | Subway Surfers                           | 4.7777777777777777 |     9 |\n| B00DJFIMW6 | Minion Rush: Despicable Me Official Game |              4.875 |     8 |\n| B0086700CM | Temple Run                               |                  5 |     6 |\n| B00KWVZ750 | Angry Birds Epic RPG                     |                  5 |     6 |\n+------------+------------------------------------------+--------------------+-------+\n5 rows in set (7.60 sec)\n</code></p><p></p><h3>利用 Ngram BloomFilter 索引加速查询</h3><p></p><p>接下来，我们尝试使用 Ngram BloomFilter 索引进行查询加速</p><p></p><p><code lang=\"sql\">ALTER TABLE amazon_reviews ADD INDEX review_body_ngram_idx(review_body) USING NGRAM_BF PROPERTIES(\"gram_size\"=\"10\", \"bf_size\"=\"10240\");\n</code></p><p></p><p>添加 Ngram BloomFilter 索引之后，再次执行相同的查询。执行结果如下，查询耗时缩短至 0.93 秒，相较于未开启索引，查询效率提高了 8 倍。</p><p></p><p><code lang=\"sql\">+------------+------------------------------------------+--------------------+-------+\n| product_id | any_value(product_title)                 | rating             | count |\n+------------+------------------------------------------+--------------------+-------+\n| B00992CF6W | Minecraft                                | 4.8235294117647056 |    17 |\n| B009UX2YAC | Subway Surfers                           | 4.7777777777777777 |     9 |\n| B00DJFIMW6 | Minion Rush: Despicable Me Official Game |              4.875 |     8 |\n| B0086700CM | Temple Run                               |                  5 |     6 |\n| B00KWVZ750 | Angry Birds Epic RPG                     |                  5 |     6 |\n+------------+------------------------------------------+--------------------+-------+\n5 rows in set (0.93 sec)\n</code></p><p></p><p>接下来，我们根据代码示例展开说明。使用 ALTER TABLE 语句为表增加 Ngram BloomFilter 索引时，gram_size 和 bf_size 参数具有特定的含义：</p><p></p><p>gram_size：表示 n-gram 中的 n 值，即连续字符的长度。在上述代码示例中，\"gram_size\"=\"10\" 表示每个 n-gram 包含 10 个字符。这意味着文本将被切割成数个字符长度为 10 的字符串，这些字符串将用于构建索引。bf_size：表示 Bloom Filter 的大小，以字节（Byte）为单位。例如，\"bf_size\"=\"10240\" 表示所使用 Bloom Filter 数据大小占用空间为 10240 字节。</p><p></p><p>在了解基本的参数定义后，我们来探索 Ngram BloomFilter 加速查询的原理：</p><p></p><p>Ngram 分词：使用 gram_size 对每行数据进行分词，当 gram_size=5 时，\"hello world\" 被切分为 [\"hello\"， \"ello \"， \"llo w\"， \"lo wo\"， \"o wor\"， \" worl\"， \"world\"]。这些子字符串经过哈希函数计算后，将被添加到相应大小（bf_size）的 Bloom Filter 中。由于 Doris 数据是按页面（page）组织存储，相应的 Bloom Filter 也会按页面（page）生成。查询加速：以“hello”为例，在匹配过程中也将被切分并生成对应的 Bloom Filter，用于与各页面的 Bloom Filter 进行对比。如果 Bloom Filter 判断为包含匹配字符串（可能会出现假阳性），则加载相应的页面以进一步匹配；否则，将跳过该页面。其原理即通过跳过不需要加载的页面（page），减少需要扫描的数据量，从而显著降低了查询延时。</p><p></p><p><img src=\"\" /></p><p></p><p></p><div><img alt=\"Ngram Bloom Filter 示意图\" src=\"https://cdn.selectdb.com/static/Ngram_Bloom_Filter_5263c434b4.png\" /></div><p></p><p></p><p>通过上述原理描述可以看出，针对不同的场景合理的配置 Ngram BloomFilter 的参数会达到更好的效果，gram_size 的大小直接影响匹配时效率，而 bf_size 的大小影响存储容量和误判率。通常情况下，较大的 bf_size 可以降低误判率，但这样也会占用更多的存储空间。因此，我们建议从以下两方面综合考量配置参数：</p><p></p><p>数据特性： 考虑要索引的数据类型。对于文本数据，需要根据文本的平均长度和字符分布来确定。</p><p></p><p>对于较短的文本（如单词或短语）：较小的 gram_size（例如 2-4）和较小的 bf_size 可能更合适。对于较长的文本（如句子或大段描述：较大的 gram_size（例如 5-10）和较大的 bf_size 可能更有效。</p><p></p><p>查询模式： 考虑查询的典型模式。</p><p></p><p>如果查询通常包含短语或接近完整的单词，较大的 gram_size 可能更好。对于模糊匹配或包含多种变化的查询，较小的 gram_size 可以提供更灵活的匹配。</p><p></p><h3>利用倒排索引加速查询</h3><p></p><p>除了采用 Ngram BloomFilter 索引进行查询加速，还可以选择基于 <a href=\"https://mp.weixin.qq.com/s?__biz=Mzg3Njc2NDAwOA==&amp;mid=2247519079&amp;idx=1&amp;sn=a232a72695ff93eea0ffe79635936dcb&amp;chksm=cf2f8560f8580c768bbde99ef8ca97d3a42ecc03b5d8d106b85f5474c90b6068781a79b3611e&amp;token=533653942&amp;lang=zh_CN#rd\">倒排索引</a>\"  进一步加速文本搜索的效率。可以通过以下步骤来构建倒排索引：</p><p></p><p>1.新增倒排索引： 对 amazon_reviews 表的 review_body 列添加倒排索引，该索引采用英文分词，并支持 Phrase 短语查询，短语查询即进行文本搜索时，分词后的词语顺序将会影响搜索结果。2.为历史数据创建索引： 按照新增索引信息对历史数据进行索引构建，使历史数据就也可以使用倒排索引进行查询。</p><p></p><p><code lang=\"sql\">ALTER TABLE amazon_reviews ADD INDEX review_body_inverted_idx(`review_body`) \n    USING INVERTED PROPERTIES(\"parser\" = \"english\",\"support_phrase\" = \"true\"); \nBUILD INDEX review_body_inverted_idx ON amazon_reviews;\n</code></p><p></p><p>3.查看及验证： 构建完索引之后，可以通过以下方式对索引构建情况进行查看：</p><p></p><p><code lang=\"sql\">mysql&gt; show BUILD INDEX WHERE TableName=\"amazon_reviews\";\n+-------+----------------+----------------+-----------------------------------------------------------------------------------------------------------------------------------+-------------------------+-------------------------+---------------+----------+------+----------+\n| JobId | TableName      | PartitionName  | AlterInvertedIndexes                                                                                                              | CreateTime              | FinishTime              | TransactionId | State    | Msg  | Progress |\n+-------+----------------+----------------+-----------------------------------------------------------------------------------------------------------------------------------+-------------------------+-------------------------+---------------+----------+------+----------+\n| 10152 | amazon_reviews | amazon_reviews | [ADD INDEX review_body_inverted_idx (\nreview_body\n) USING INVERTED PROPERTIES(\"parser\" = \"english\", \"support_phrase\" = \"true\")],  | 2024-01-23 15:42:28.658 | 2024-01-23 15:48:42.990 | 11            | FINISHED |      | NULL     |\n+-------+----------------+----------------+-----------------------------------------------------------------------------------------------------------------------------------+-------------------------+-------------------------+---------------+----------+------+----------+\n1 row in set (0.00 sec)\n</code></p><p></p><p>如果对分词效果不确定，可以使用 TOKENIZE 函数进行分词测试。TOKENIZE 函数接收两个输入：一个是需要进行分词的文本，一个是分词的属性字段。</p><p></p><p><code lang=\"sql\">mysql&gt; SELECT TOKENIZE('I can honestly give the shipment and package 100%, it came in time that it was supposed to with no hasels, and the book was in PERFECT condition.\nsuper awesome buy, and excellent for my college classs', '\"parser\" = \"english\",\"support_phrase\" = \"true\"');\n+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| tokenize('I can honestly give the shipment and package 100%, it came in time that it was supposed to with no hasels, and the book was in PERFECT condition. super awesome buy, and excellent for my college classs', '\"parser\" = \"english\",\"support_phrase\" = \"true\"')                                              |\n+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| [\"i\", \"can\", \"honestly\", \"give\", \"the\", \"shipment\", \"and\", \"package\", \"100\", \"it\", \"came\", \"in\", \"time\", \"that\", \"it\", \"was\", \"supposed\", \"to\", \"with\", \"no\", \"hasels\", \"and\", \"the\", \"book\", \"was\", \"in\", \"perfect\", \"condition\", \"super\", \"awesome\", \"buy\", \"and\", \"excellent\", \"for\", \"my\", \"college\", \"classs\"] |\n+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n1 row in set (0.05 sec)\n</code></p><p></p><p>在倒排索引创建完成后，我们使用 MATCH_PHRASE  来查询包含关键词\"is super awesome\"的产品评论信息（具体需求可回顾前文）。</p><p></p><p><code lang=\"sql\">SELECT\n    product_id,\n    any(product_title),\n    AVG(star_rating) AS rating,\n    COUNT() AS count\nFROM\n    amazon_reviews\nWHERE\n    review_body MATCH_PHRASE 'is super awesome'\nGROUP BY\n    product_id\n\nORDER BY\n    count DESC,\n    rating DESC,\n    product_id\nLIMIT 5;\n</code></p><p></p><p>以上述代码示例进行说明，review_body MATCH_PHRASE 'is super awesome'  表示对 review_body  列进行短语匹配查询。具体而言，查询会在 review_body 中按照英文分词后，寻找同时包含 \"is\"、\"super\" 和 \"awesome\" 这三个词语的文本片段，同时要求这三个词语的顺序是 \"is\" 在前，\"super\" 在中间，\"awesome\" 在后，并且词语之间没有间隔（不区分大小写）。</p><p></p><p>这里需要说明的是，MATCH 与 LIKE 查询的差异在于，MATCH 查询时会忽略大小写，把句子切分成一个个词来匹配，能够更快速定位符合条件的结果，特别是在大规模数据集情况下，MATCH 的效率提升更为明显。</p><p></p><p>执行结果如下所示，开启倒排索引后查询耗时仅 0.19 秒，性能较仅开启 Ngram BloomFilter 索引时提升了 4 倍，较未开启索引时提升了近 40 倍，极大幅度提升了文本检索的效率。</p><p></p><p><code lang=\"sql\">+------------+------------------------------------------+-------------------+-------+\n| product_id | any_value(product_title)                 | rating            | count |\n+------------+------------------------------------------+-------------------+-------+\n| B00992CF6W | Minecraft                                | 4.833333333333333 |    18 |\n| B009UX2YAC | Subway Surfers                           |               4.7 |    10 |\n| B00DJFIMW6 | Minion Rush: Despicable Me Official Game |                 5 |     7 |\n| B0086700CM | Temple Run                               |                 5 |     6 |\n| B00KWVZ750 | Angry Birds Epic RPG                     |                 5 |     6 |\n+------------+------------------------------------------+-------------------+-------+\n5 rows in set (0.19 sec)\n</code></p><p></p><p>究其加速原因可知，倒排索引是通过将文本分解为单词，并建立从单词到行号列表的映射。这些映射关系按照单词进行排序，并构建跳表索引。在查询特定单词时，可以通过跳表索引和二分查找等方法，在有序的映射中快速定位到对应的行号列表，进而获取行的内容。这种查询方式避免了逐行匹配，将算法复杂度从 O（n） 降低到 O（logn），在处理大规模数据时能显著提高查询性能。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e4/e465b26d5d7accafbdf958b0cfa746ff.png\" /></p><p></p><p>为深入了解倒排索引的加速原理，需从倒排索引内部引读写逻辑说起。在 Doris 中，从逻辑角度来看，倒排索引应用于表的列级别，而从物理存储和实现角度来看，倒排索引实际是建立在数据文件级别上的。具体如下：</p><p></p><p>写入阶段： 数据在写入数据文件的同时，也将同步写入排索引文件中，对于每个写入数据的行号，均与倒排索引中的行号一一对应的。查询阶段： 如果查询 WHERE 条件中包含已建立倒排索引的列，Doris 会自动查询索引文件，返回满足条件的行号列表，再利用 Doris 通用的行号过滤机制，跳过不必要的行和页面，只读取满足条件的行，以达到查询加速的效果。</p><p></p><p>总的来说，Doris 的倒排索引机制在物理层面是通过数据文件和索引文件配合工作，而在逻辑层面则通过列和行的映射来实现高效的数据检索和查询加速。</p><p></p><h2>非主键列查询加速</h2><p></p><p>为了进一步验证倒排索引对非主键列查询加速的影响，我们选择对产品 ID 和用户 ID 的维度信息进行查询。</p><p></p><h3>未开启倒排索引</h3><p></p><p>当查询用户 13916588 对产品 B002DMK1R0 的评论信息时，执行以下 SQL 语句进行查询时，需要对全表数据进行扫描，查询耗时为 1.81 秒。</p><p></p><p><code lang=\"sql\">mysql&gt; SELECT product_title,review_headline,review_body,star_rating \nFROM amazon_reviews \nWHERE product_id='B002DMK1R0' AND customer_id=13916588;\n+-----------------------------------------------------------------+----------------------+-----------------------------------------------------------------------------------------------------------------------------+-------------+\n| product_title                                                   | review_headline      | review_body                                                                                                                 | star_rating |\n+-----------------------------------------------------------------+----------------------+-----------------------------------------------------------------------------------------------------------------------------+-------------+\n| Magellan Maestro 4700 4.7-Inch Bluetooth Portable GPS Navigator | Nice Features But... | This is a great GPS. Gets you where you are going. Don't forget to buy the seperate (grr!) cord for the traffic kit though! |           4 |\n+-----------------------------------------------------------------+----------------------+-----------------------------------------------------------------------------------------------------------------------------+-------------+\n1 row in set (1.81 sec)\n</code></p><p></p><h3>倒排索引查询加速</h3><p></p><p>接下来，我们为 product_id 和 customer_id 添加倒排索引。在这个场景中，倒排索引的使用与文本搜索时不同，该场景无需对 product_id 和 customer_id 进行分词，只需对这两列的 Value→RowID 的创建倒排映射表。</p><p></p><p>首先，通过执行以下 SQL 语句创建倒排索引：</p><p></p><p><code lang=\"sql\">ALTER TABLE amazon_reviews ADD INDEX product_id_inverted_idx(product_id) USING INVERTED ;\nALTER TABLE amazon_reviews ADD INDEX customer_id_inverted_idx(customer_id) USING INVERTED ;\nBUILD INDEX product_id_inverted_idx ON amazon_reviews;\nBUILD INDEX customer_id_inverted_idx ON amazon_reviews;\n</code></p><p></p><p>其次，当索引构建完成后，执行同样的查询语句，查询耗时从 1.81 秒降到了 0.06 秒，查询耗时显著降低，相比未添加索引的情况，查询效率提升了约 30 倍。</p><p></p><p><code lang=\"sql\">mysql&gt; SELECT product_title,review_headline,review_body,star_rating FROM amazon_reviews WHERE product_id='B002DMK1R0' AND customer_id='13916588';\n+-----------------------------------------------------------------+----------------------+-----------------------------------------------------------------------------------------------------------------------------+-------------+\n| product_title                                                   | review_headline      | review_body                                                                                                                 | star_rating |\n+-----------------------------------------------------------------+----------------------+-----------------------------------------------------------------------------------------------------------------------------+-------------+\n| Magellan Maestro 4700 4.7-Inch Bluetooth Portable GPS Navigator | Nice Features But... | This is a great GPS. Gets you where you are going. Don't forget to buy the seperate (grr!) cord for the traffic kit though! |           4 |\n+-----------------------------------------------------------------+----------------------+-----------------------------------------------------------------------------------------------------------------------------+-------------+\n1 row in set (0.06 sec)\n</code></p><p></p><p>通过观察可发现，倒排索引在于类似非主键列的维度查询中具有非常出色的加速效果。为更深入且直观的查看加速效果，可通过 Doris Profile 信息来进一步探索。</p><p></p><h3>Profile 分析</h3><p></p><p>需要注意的是，在开启查询的 Profile 之前，需先在 MySQL 客户端执行 SET enable_profile=true;  命令。完成后再执行查询语句，并访问 http://FE_IP:FE_HTTP_PORT/QueryProfile， 来查看与本次查询相关的 Profile ID 以及详细的 Profile 信息。</p><p></p><p>本文中仅截取一个特定片段的 SegmentIterator Profile 信息来说明倒排索引查询加速原因。</p><p></p><p><code lang=\"yaml\">SegmentIterator:\n  - FirstReadSeekCount: 0\n  - FirstReadSeekTime: 0ns\n  - FirstReadTime: 13.119ms\n  - IOTimer: 19.537ms\n  - InvertedIndexQueryTime: 11.583ms\n  - RawRowsRead: 1\n  - RowsConditionsFiltered: 0\n  - RowsInvertedIndexFiltered: 16.907403M (16907403)\n  - RowsShortCircuitPredInput: 0\n  - RowsVectorPredFiltered: 0\n  - RowsVectorPredInput: 0\n  - ShortPredEvalTime: 0ns\n  - TotalPagesNum: 27\n  - UncompressedBytesRead: 3.71 MB\n  - VectorPredEvalTime: 0ns\n</code></p><p></p><p>从上述 Profile 中的 RowsInvertedIndexFiltered: 16.907403M (16907403)以及RawRowsRead: 1，我们可以观察到：倒排索引过滤了 16907403 行数据，最终只保留 1 行数据（即命中的那条数据）。根据 FirstReadTime: 13.119ms 可知，在读取这行数据所在的页面（page）耗时 13.119 ms，而根据InvertedIndexQueryTime: 11.583ms 可知，倒排索引执行时间仅耗时 11.58 ms。这意味着倒排索引仅在 11.58 ms 内过滤了 16907403 行数据，执行效率非常高。</p><p></p><p>为更直接对比，接下来展示未增加倒排索引情况下 SegmentIterator 的执行情况：</p><p></p><p><code lang=\"yaml\">SegmentIterator:\n  - FirstReadSeekCount: 9.374K (9374)\n  - FirstReadSeekTime: 400.522ms\n  - FirstReadTime: 3s144ms\n  - IOTimer: 2s564ms\n  - InvertedIndexQueryTime: 0ns\n  - RawRowsRead: 16.680706M (16680706)\n  - RowsConditionsFiltered: 226.698K (226698)\n  - RowsInvertedIndexFiltered: 0\n  - RowsShortCircuitPredInput: 1\n  - RowsVectorPredFiltered: 16.680705M (16680705)\n  - RowsVectorPredInput: 16.680706M (16680706)\n  - RowsZonemapFiltered: 226.698K (226698)\n  - ShortPredEvalTime: 2.723ms\n  - TotalPagesNum: 5.421K (5421)\n  - UncompressedBytesRead: 277.05 MB\n  - VectorPredEvalTime: 8.114ms\n</code></p><p></p><p>根据上述 Profile 观察可知，由于没有索引进行过滤， FirstRead 需要花费 3.14s 的时间来加载 16680706 行数据，然后使用 Predicate Evaluate 进行条件过滤，过滤掉其中 16680705 行，而条件过滤本身只消耗了不到 10ms 的时间，由此可见，大部分时间被消耗在加载原始数据上。</p><p></p><p>通过对比可知，建立倒排索引可以大大减少加载原始数据的时间，提高查询的执行效率。索引能够快速定位满足条件的行，从而减少不必要的数据加载和处理，节省时间和资源。</p><p></p><h2>低基数文本列索引加速</h2><p></p><p>众所周知，倒排索引对于高基数文本列的查询来说，加速效果十分显著。然而，在低基数列的情况下，可能由于需创建过多的索引项而导致更大的开销，从而对查询性能产生负面影响。接下来，我们将以 product_category 作为谓词列进行过滤，来检验 Apache Doris 倒排索引在低基数文本列的加速效果如何。</p><p></p><p><code lang=\"sql\">mysql&gt; SELECT COUNT(DISTINCT product_category) FROM amazon_reviews ;\n+----------------------------------+\n| count(DISTINCT product_category) |\n+----------------------------------+\n|                               43 |\n+----------------------------------+\n1 row in set (0.57 sec)\n</code></p><p></p><p>通过上述操作可知，到 product_category 仅有 43 种分类，是一个典型的低基数文本列。接下来，我们对其增加倒排索引</p><p></p><p><code lang=\"sql\">ALTER TABLE amazon_reviews ADD INDEX product_category_inverted_idx(`product_category`) USING INVERTED;\nBUILD INDEX product_category_inverted_idx ON amazon_reviews;\n</code></p><p></p><p>添加倒排索引之后，运行如下 SQL 查询，指查询产品分类为 Mobile_Electronics 产品中评价数量最多的前三名产品信息</p><p></p><p><code lang=\"sql\">SELECT \n    product_id,\n    product_title,\n    AVG(star_rating) AS rating,\n    any(review_body),\n    any(review_headline),\n    COUNT(*) AS count \nFROM \n    amazon_reviews \nWHERE \n    product_category = 'Mobile_Electronics' \nGROUP BY \n    product_title, product_id \nORDER BY \n    count DESC \nLIMIT 10;\n</code></p><p></p><p>从下方结果可知，增加倒排索引之后，查询耗时为 1.54s。</p><p></p><p><code lang=\"sql\">+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------+-------+\n| product_id | product_title                                                                                                                                                                                          | rating             | any_value(review_body)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | any_value(review_headline)      | count |\n+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------+-------+\n| B00J46XO9U | iXCC Lightning Cable 3ft, iPhone charger, for iPhone X, 8, 8 Plus, 7, 7 Plus, 6s, 6s Plus, 6, 6 Plus, SE 5s 5c 5, iPad Air 2 Pro, iPad mini 2 3 4, iPad 4th Gen [Apple MFi Certified](Black and White) | 4.3766233766233764 | Great cable and works well. Exact fit as Apple cable. I would recommend this to anyone who is looking to save money and for a quality cable.                                                                                                                                                                                                                                                                                                                                                             | Apple certified lightning cable |  1078 |\n| B004911E9M | Wall AC Charger USB Sync Data Cable for iPhone 4, 3GS, and iPod                                                                                                                                        | 2.4281805745554035 | A total waste of money for me because I needed it for a iPhone 4.  The plug will only go in upside down and thus won't work at all.                                                                                                                                                                                                                                                                                                                                                                      | Won't work with a iPhone 4!     |   731 |\n| B002D4IHYM | New Trent Easypak 7000mAh Portable Triple USB Port External Battery Charger/Power Pack for Smartphones, Tablets and more (w/built-in USB cable)                                                        | 4.5216095380029806 | I bought this product based on the reviews that i read and i am very glad that i did. I did have a problem with the product charging my itouch after i received it but i emailed the company and they corrected the problem immediately. VERY GOOD customer service, very prompt. The product itself is very good. It charges my power hungry itouch very quickly and the imax battery power lasts for a long time. All in all a very good purchase that i would recommend to anyone who owns an itouch. | Great product &amp; company         |   671 |\n+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------+-------+\n3 rows in set (1.54 sec)\n</code></p><p></p><p>接下来，我们关闭倒排索引，以观察未加倒排索引时的查询耗时。这里需要说明的是，当需要关闭索引或在增加索引后发现效果不理想，可以在 MySQL 客户端中执行 set enable_inverted_index_query=false;，便捷且快速地临时关闭倒排索引。我们再次运行查询 SQL，如下所示，查询耗时为 1.8s。</p><p></p><p><code lang=\"sql\">+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------+-------+\n| product_id | product_title                                                                                                                                                                                          | rating             | any_value(review_body)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | any_value(review_headline)            | count |\n+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------+-------+\n| B00J46XO9U | iXCC Lightning Cable 3ft, iPhone charger, for iPhone X, 8, 8 Plus, 7, 7 Plus, 6s, 6s Plus, 6, 6 Plus, SE 5s 5c 5, iPad Air 2 Pro, iPad mini 2 3 4, iPad 4th Gen [Apple MFi Certified](Black and White) | 4.3766233766233764 | These cables are great. They feel quality, and best of all, they work as they should. I have no issues with them whatsoever and will be buying more when needed.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | Just like the original from Apple     |  1078 |\n| B004911E9M | Wall AC Charger USB Sync Data Cable for iPhone 4, 3GS, and iPod                                                                                                                                        | 2.4281805745554035 | I ordered two of these chargers for an Iphone 4. Then I started experiencing weird behavior from the touch screen. It would select the wrong area of the screen, or it would refuse to scroll beyond a certain point and jump back up to the top of the page. This behavior occurs whenever either of the two that I bought are attached and charging. When I remove them, it works fine once again. Needless to say, these items are being returned.                                                                                                                                                                                                                                                                                                                                                                              | Beware - these chargers are defective |   731 |\n| B002D4IHYM | New Trent Easypak 7000mAh Portable Triple USB Port External Battery Charger/Power Pack for Smartphones, Tablets and more (w/built-in USB cable)                                                        | 4.5216095380029806 | I received this in the mail 4 days ago, and after charging it for 6 hours, I've been using it as the sole source for recharging my 3Gs to see how long it would work.  I use my Iphone A LOT every day and usually by the time I get home it's down to 50% or less.  After 4 days of using the IMAX to recharge my Iphone, it finally went from 3 bars to 4 this afternoon when I plugged my iphone in.  It charges the iphone very quickly, and I've been topping my phone off (stopping around 95% or so) twice a day.  This is a great product and the size is very similar to a deck of cards (not like an iphone that someone else posted) and is very easy to carry in a jacket pocket or back pack.  I bought this for a 4 day music festival I'm going to, and I have no worries at all of my iphone running out of juice! | FANTASTIC product!                    |   671 |\n+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------+-------+\n3 rows in set (1.80 sec)\n</code></p><p></p><p>综上可知，倒排索引对于低基数列场景也有 15% 的查询性能提升，虽不如高基数列场景的提升效果，但并未产生退化效果或负面影响。此外，Apache Doris 针对低基数列采用了较好的编码（如字典编码）方式和压缩技术，并且可以通过内置索引（如 zonemap）进行有效过滤。因此，即使不添加倒排索引仍能展现较好的查询效果。</p><p></p><h2>总结语</h2><p></p><p>总而言之，Apache Doris 中的倒排索引显著优化了针对谓词列的过滤操作，即 SQL 查询中的 Where 子句。通过精确匹配行号，减少了存储层需要扫描的数据量，从而提高了查询性能。即使在性能提升有限的情况下，倒排索引也不会对查询效率产生负面影响。此外，倒排索引还支持轻量级的索引管理操作，如对增加或删除索引（ADD/DROP INDEX）以及构建索引（BUILD INDEX）操作进行管理。同时，还提供了在 MySQL 客户端便捷地启用或关闭索引（enable_inverted_index_query=true/false）的功能，使用户能够轻松利用倒排索引来检验查询加速效果。</p><p></p><p>倒排索引和 NGram Bloom Filter 索引为不同场景提供了查询加速方案，在选择索引类型时，数据集的特定特征和查询模式是关键考虑因素。以下是一些常见的适配场景：</p><p></p><p>大规模数据非主键列点查场景： 在这种场景下，往往存在大量分散的数值列在值，且查询的值命中量很低。为了加速查询，除了在建表时利用 Doris 内置的智能索引能力之外，还可以通过给对应的列增加倒排索引来加速查询。倒排索引对字符类型、数值类型、日期等标量类型支持比较完整。短文本列的文本检索场景： 如果短文本分布比较离散（即文本之间相似度低），则适合使用 Ngram Bloom Filter 索引，能够有效地处理短文本的模糊匹配查询（LIKE）。同时，在短文本场景下 Apache Doris 的向量化处理能力可以得到更加充分和高效的应用和发挥。如果短文本分布比较集中（如大量文本相似，少量文本不同），则适合使用倒排分词索引，这样可以保证词典比较小，适合快速检索获取行号列表。长文本列的文本搜索场景： 针对长文本列，倒排分词索引是更好的方案。相比于暴力字符串匹配，倒排索引提供了更高效的查询性能，避免了大量的 CPU 资源消耗。</p><p></p><p>自 Apache Doris 最早引入倒排索引至今已有近一年时间，从 早期 2.0 Preview 版本至最近发布的 2.0.4，这一年间经历了大量开源用户在真实业务环境海量数据下的打磨和验证，性能与稳定性已经得到充分验证。而在后续的规划中，我们也将持续在现有基础上进行迭代和优化，包括：</p><p></p><p>自定义倒排索引分词能力， 针对用户在不同场景下分词效果的需求，提供用户对自定义分词器。支持更多类型的倒排索引， 后续会增加对 Array、Map 等复杂数据类型的支持，以更全面地满足各类查询需求。</p>",
    "publish_time": "2024-01-30 14:30:28",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]