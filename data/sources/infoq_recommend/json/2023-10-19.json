[
  {
    "title": "Linkerd 2.14发布：多集群支持和Kubernetes Gateway API功能升级一览",
    "url": "https://www.infoq.cn/article/TeJctvZNkPuToDNxRfdX",
    "summary": "<p><a href=\"https://linkerd.io/\">Linkerd</a>\" 2.14版本（一个<a href=\"https://www.infoq.com/news/2022/06/future-cloud-kubecon22/\">毕业于CNCF</a>\"的服务网格项目）发布，新特性包括改进企业级多集群支持、与Kubernetes Gateway API保持完全一致，等等。</p><p>&nbsp;</p><p>前不久发布的2.13版本带来了熔断机制和动态请求路由功能。在此基础上，2.14带来了许多增强和改进，包括增强在共享平面网络上进行多集群部署的支持以及与Gateway API保持完全一致。</p><p>&nbsp;</p><p>这个新版本改进了<a href=\"https://linkerd.io/2023/07/20/enterprise-multi-cluster-at-scale-supporting-flat-networks-in-linkerd/\">在共享平面网络上进行多集群部署</a>\"的支持。不同集群中的pod彼此之间可以建立TCP连接，而且不需要多集群网关。这样可以提高性能和安全性，并尽可能地减少通过网关路由的流量，从而减少延迟和云支出。这也保持了Linkerd的一项关键设计：出于安全性和故障隔离的考虑，每个集群仍然有自己的Linkerd控制平面，并且独立于其他集群。<a href=\"https://linkerd.io/2023/09/11/linkerd-214/\">Linkerd上有一篇博文</a>\"详细介绍了它的工作机制。</p><p>&nbsp;</p><p>现在，Linkerd与新的<a href=\"https://gateway-api.sigs.k8s.io/\">Kubernetes Gateway API</a>\"完全一致了。它支持对复杂资源（如HTTP请求）进行标准化配置，并跨Ingress和服务网格提供了统一的API。这意味着重试、超时和渐进式交付等功能都可以完全使用Gateway API类型进行配置，不仅简化了配置过程，还增强了与当前Kubernetes服务网格定义的兼容性。</p><p>&nbsp;</p><p>在X（之前的Twitter）上，<a href=\"https://twitter.com/cloudnativeboy/status/1699408983638065507\">Saim Safdar</a>\"（<a href=\"https://twitter.com/cloudnativefm\">云原生播客主持人</a>\"）评论道：</p><p></p><blockquote>Gateway API代表了Kubernetes中负载平衡、路由和服务网格API的未来。</blockquote><p></p><p>&nbsp;</p><p>除新增了这些核心特性之外，Linkerd 2.14还包括许多性能增强、Bug修复和新特性，如领导者选举特性、多集群服务镜像的高可用模式和经过改进的诊断功能。</p><p>&nbsp;</p><p>在过去的18个月里，Linkerd在阿迪达斯、微软、Plaid和DB Schenker等企业组织中的应用激增。这些公司部署Linkerd的目的是增强其关键任务生产基础设施的安全性、遵从性和可靠性。</p><p>&nbsp;</p><p><a href=\"https://www.cncf.io/blog/2023/09/18/announcing-linkerd-2-14-improved-enterprise-multi-cluster-gateway-api-conformance-and-more/\">这篇文章</a>\"主要是说明了Linkerd的成功，如2022年运行该技术的稳定Kubernetes集群数量增加了一倍。它还暗示说，2023年晚些时候会有一些令人兴奋的特性和进展，以2.13和2.14版本的成果为基础进行构建，并保持Linkerd在服务网格中融合企业级功能、实现操作便利性和成本效益的承诺不变。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/09/linkerd-214-released/\">https://www.infoq.com/news/2023/09/linkerd-214-released/</a>\"</p>",
    "publish_time": "2023-10-19 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "上海兆芯集成SOFAStack机密计算解决方案，共铸云原生安全生态",
    "url": "https://www.infoq.cn/article/qcKBAflw7bZFCv900PM3",
    "summary": "<p>记者今日获悉，上海兆芯与蚂蚁数字科技达成战略合作，将集成其云原生PaaS平台SOFA Stack（下简称SOFA）的机密计算产品，并共同推进金融、医疗等行业落地，应用于隐私计算、数据保护等场景，该合作正填补国产化机密计算的空白。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/25/4e/25cf7930aaedccd8ac1ab8906e989e4e.png\" /></p><p></p><p>&nbsp;</p><p>伴随企业业务上云、大模型发展，保护使用中的数据成为一大挑战，机密计算概念应运而生，它通过具备高度安全性的硬件加密体系来对抗数据泄漏风险。自2019年起，Gartner将机密计算列入云安全技术成熟度曲线，几年来它仍是曲线上重要技术之一。机密计算作为前瞻性安全技术，全球科技巨头微软云、谷歌云、英特尔等纷纷布局，投入探索应用。</p><p></p><p>据介绍，SOFA机密计算产品，基于蚂蚁集团自研HyperEnclave和Occlum TEE OS技术底座，已应用于智能合约、分布式大数据分析、密态数据库等20+行业场景，可支持TB级数据规模。同时均已通过北京国家金融科技认证中心认证，具备企业级应用水平。</p><p></p><p>对SOFA而言，被上海兆芯高性能国产处理器集成后，将可以向上云客户提供芯片层安全保障能力。这是其业务团队升级后又一进展，该团队今年以来完成多项云原生安全产品层面的整合，并已有较广泛的应用实践。</p><p></p><p>此前，SOFA还率先完成全栈软件供应链安全产品及解决方案的布局，包括静态代码扫描Pinpoint、软件成分分析SCA、交互式安全测试IAST、运行时防护RASP、安全洞察Appinsight等，帮助客户应用软件实现“发布前检测，运行时免疫”。</p><p></p><p>IDC《中国云原生市场分析》报告显示，蚂蚁集团是国内云原生技术最全面的厂商之一，SOFA广泛应用于银行、证券、保险等行业的数百家金融机构，国内TOP50银行中超60%选择SOFAStack加速迈向云原生。</p>",
    "publish_time": "2023-10-19 11:43:45",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "剑指Kubernetes！微软发布开源平台Radius：高效构建、运行云原生应用程序",
    "url": "https://www.infoq.cn/article/KVwFZbCikXPpDG84fbAk",
    "summary": "<p></p><blockquote>Kubernetes 最大的缺点就在于它预先加载了大量复杂性要素。复杂性本身有其合理性，但也意味着很多东西需要预先学习。</blockquote><p></p><p>&nbsp;</p><p>对于部分开发者和 IT 运维人员而言，在不断发展且日益复杂的云原生环境中部署、管理和理解应用程序，正变得越来越令人头痛。尽管 Kubernetes 等云基础设施和平台技术的发展的确让微服务应用程序的开发灵活性、可扩展性和可移植性有所改善，但同时也给开发者和运维人员带来了更大的挑战。</p><p>&nbsp;</p><p>对开发者而言，基础设施的管理复杂性以及缺乏对构成其应用程序资源的可见性已经成为障碍生产力提升的关键因素；对运维团队而言，部署过程中缺乏标准化/自动化机制，则很可能导致其失去对基础设施的控制能力、降低对所部署应用程序的信心。最终，开发团队交付的成果在平台和云服务商之间出现使用体验脱节。面对现实问题，陈旧的工件列表往往很难帮助开发者和运维者确切了解自己的应用程序在不同工具集中到底是怎么组合起来的。</p><p>&nbsp;</p><p>10 月 18 日，微软 Azure 孵化团队正式发布开源应用平台 Radius，该平台将应用程序置于每个开发阶段的中心，重新定义应用程序的构建、管理与理解方式。目前，Radius 维护团队正在将 Radius 提交至 CNCF，微软、BlackRock、Comcast 和 Millennium BVP 等企业也在共同努力，确保 Radius 能够与更广泛的云原生社区同步发展。</p><p>&nbsp;</p><p>GitHub 地址：</p><p><a href=\"https://github.com/radius-project\">https://github.com/radius-project</a>\"</p><p></p><h2>解决 Kubernetes 复杂性，微软发布 Radius 平台</h2><p></p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/e5/e51b700fb0d2a6dcc0b06a436486d50c.png\" /></p><p></p><p>据悉，Radius 凭借 Recipes 和 Connections 等标准化部署及自动化资源配置功能，为开发人员/运维人员及其团队提供一套统一工具集，用以开发有效协作。由于资源之间的关系，本质上就是在应用程序的创作与部署活动中确定下来的，因此 Radius 可以通过其应用程序图形数据全面了解组织架。此外，Radius 在立项之初就明确了开源加跨多云的思路，保证应用程序在一次编写之后，即可使用相同的工具集加工作流程被部署至任意云/本地基础设施之上。</p><p>&nbsp;</p><p>Radius 专注于解决支持跨本地基础设施和云服务商（包括微软 Azure 及亚马逊云科技）的应用程序，在实际部署中所面对的平台工程挑战。Radius 能够同时满足开发者和运维人员的需求，为 Dapr 等各类流行应用程序开发工具、以及 Terraform 和 Bicep 等基础设施即代码（IaC）语言提供内置支持。</p><p>&nbsp;</p><p>Radius 强调适应、而非破坏现有开发任务和 CI/CD 管线，致力于帮助开发人员更好地理解构成其应用程序的所有组件，并处理权限、连接字符串等平台配置，简化整个任务流程。如此一来，运维团队也能确保所有应用程序部署均符合组织策略，并使用 Radius 管理应用程序及其配套资源。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/24/24007ce46436a14c7171a272a6b360fe.png\" /></p><p>&nbsp;</p><p></p><h2>Radius 初始开源版本提供了哪些功能？</h2><p></p><p>&nbsp;</p><p>在首个版本中，Radius 平台主要强调其核心基础功能以及如何提高应用程序的开发生产力，具体包括：</p><p>&nbsp;</p><p>简化和统一应用程序开发体验：使用相同的应用程序定义在任意云服务商或本地环境中完成部署，且全面提供统一的工具和体验。具体包括资源的自动化访问和配置能力，以及通过配置满足各开发阶段对于环境的需求等。Recipes 与环境：对部署做标准化及扩展，明确区分开发人员与运维人员间的关注点差异。Radius Recipes 属于可预定义的模板，能够自动配置基础设施资源和环境，确保在设计上符合成本、安全性及合规性等标准。应用程序图：用于了解构成应用程序的资源与资源。Radius能够在开发进程当中捕捉应用程序中各资源之间的关系，并进一步查询和理解这些关系。</p><p>&nbsp;</p><p>为了满足多云架构上不断增长的业务和技术需求，使用 Radius 定义和管理的应用程序可以依托同一组工具在任意云上实现部署和运行，意味着其应用程序代码、定义和开发工作流程均保持统一。无论应用程序是被部署至 Azure、亚马逊云科技还是本地，其创作、部署和管理体验都将保持不变。&nbsp;此外，Radius 还能轻松对接并使用多种流行服务，例如 Redis、Mongo、Dapr 以及 SQL。随着社区需求的发展和变化，未来还将有更多服务被纳入支持范围。</p><p>&nbsp;</p><p>此外，开发人员与运维人员在工作中需要具体协调，这必然导致大量不必要的手动流程，进而影响开发速度。为此，大多数组织都采取构建自定义管线或工单系统的方式进行基础设施部署，但这只能缓和一部分问题，而无法解决手动流程这块最致命的短板。Radius Recipes 的价值也正在此：运维人员能够配置 IaC 模板（Terraform 模块及 Bicep 文件），开发人员则利用这些模板自助完成资源配置和部署。Recipes 还允许运维人员定义和执行公司策略，例如可以使用哪些云资源、如何进行配置以及哪些员工有权部署等。如此一来，开发人员在构建应用程序时不必再分神于基础设施部署中的种种细节，能够专心一意编写应用程序代码。</p><p>&nbsp;</p><p>例如，运维人员可以定义一个 Recipe 来部署组织生产所需要的 Redis 缓存：至少两个节点，至少两套副本。运维人员还可以指定 Redis 缓存必须被部署至特定区域，并预先配置正确的连接字符串及必要凭证。在定义了 Recipe 之后，开发人员就能使用它来部署 Redis 缓存，而不必担心具体部署细节或者配置是否正确。这种关注点分离，将使得运维团队得以扩大对开发者部门的支持，同时确保应用程序的部署始终符合组织策略。</p><p>&nbsp;</p><p>云原生应用程序的最大管理挑战之一，就是如何保证应用程序所使用的云基础设施始终满足成本、运营和安全要求。这是因为 IT 运维人员往往对于已部署应用程序究竟用到哪些资源一无所知，这也限制了他们有效管理企业基础设施的能力。Radius 则引入了包含环境、资源组和连接的应用程序结构，由此生成的应用程序图能够准确展示各应用程序及其基础设施的互连方式，帮助运维团队和开发团队通过视图直观了解应用程序的组成方式。此外，Radius 还与 Terraform 等流行基础设施工具及 GitHub Actions 等现有 CI/CD 系统相集成，带来无缝化的运维操作体验。</p><p></p><h2>Kubernetes 太复杂，开发者怎么看？</h2><p></p><p>&nbsp;</p><p>Kubernetes 的复杂性问题一直饱受诟病，也成了很多企业部署路上的“绊脚石”。</p><p>&nbsp;</p><p>2019 年，知名软件开发服务商 Atlassian 在尝试部署 Kubernetes 三年后公开表示：“过去三年，部署 Kubernetes 的过程非常艰难，并且不推荐大家尝试”。Google Kubernetes Engine（GKE）产品负责人 Drew Bradstock 也曾在一次公开声明中承认，“尽管我们过去几年看到越来越多的企业开始拥抱 Kubernetes，但是随后就陷入了困境。”</p><p></p><p>Kubernetes 的创建者之一，Heptio（VMware）的 Joe Beda 曾在 Twitter 上表示：“Kubernetes 是一个复杂的系统，它做并带来了很多新的抽象，但这并不适合所有问题。我确定，很多人通过更简单的工具实现 Kubernetes 的功能。”Beda 强调，相比于学习的复杂性，工程师往往更擅长削减构建复杂性。当工程师决定使用 Jenkins、Bash、Puppet、Terraform 等创建系统时，最终会得到一个独特的复杂系统，工程师本人会感到很舒适，这可能解决了某些问题。但对新人而言，试图了解这些系统太过复杂。但是，这种复杂性与某些特定系统中的复杂性还不同，Kubernetes 是存在行业标准的，基本只要学习一次就可以在各处应用。</p><p>&nbsp;</p><p>在开发者群体中，关于 Kubernetes 是否太过复杂也分成了不同的阵营，有开发者直言自己花了一年的时间才把 Kubernetes 真正搞明白，时间成本非常高；也有开发者认为，Kubernetes 是否复杂取决于你想解决什么任务。开发者 Maruf Hossain 认为，“对于一些简单的任务，Kubernetes 可以说是最简单的解决方案了。当然，对于某些关键任务，Kubernetes 也确实表现得非常复杂繁琐。”</p><p>&nbsp;</p><p>敏捷团队技术主管 Etienne Dilocker 也有相似的观点：“Kubernetes 到底是简单还是复杂，要取决于大家的实际设置流程。Kubernetes 用起来跟注册云服务一样简单，特别是谷歌、亚马逊云科技或者 Azure。三大云巨头都提供一次单击即可创建集群的功能。在拥有了自己的集群之后，大家可以使用简单的 kubectl run mydeployment —image=myimage 命令来部署容器。</p><p>&nbsp;</p><p>真正的复杂性，来自不同的实际业务流程。当然，动态创建集群并以不可重现的方式通过本地计算机进行部署还远远不够。大家可能需要编写集群创建脚本（这属于基础设施即代码的典型应用），这往往要用到 Terraform 之类工具。当然，应用程序的部署过程也应该可重复，这就要求我们创建一条 CI 管线（使用 Jenkins、Travis、Circle CI、Google Cloud Build 之类的都行）。但是，我们并不需要担心更新过程：因为我们选择了 Kubernetes，它能帮我们轻松搞定滚动更新。也就是说，我们现在只需要把显式创建资源（比如部署）中的 kubectl run 用 kubectl apply 替换掉即可。如此一来，大家就能以幂等的方式来部署应用程序。您的应用程序中涉及依赖项吗？不用担心，把它们跟应用程序一起部署即可，Kubernetes 甚至还免费提供服务发现功能。</p><p>&nbsp;</p><p>如果应用程序需要接受外部访问，那可能还得创建 Ingress 资源。需要往管线中添加yaml，而相关资源管理工作交给 Helm（Kubernetes 的包管理器）之类工具就行。当然，所有这一切都要求应用程序能够在云端运行，所以它应当兼容十二大因素。但还是那句话，这些复杂性并不是 Kubernetes 所特有的，在云端运行弹性应用程序就是会带来这样的复杂性成本。</p><p>&nbsp;</p><p>总而言之，复杂性确实存在，但很多时候跟 Kubernetes 本身关系不大。复杂性的真正来源，是在云环境中以可靠、可重复的方式运行应用程序这个基本要求。相信我，在 Kubernetes 诞生之前，这一切还可以更加复杂。”</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://cloudblogs.microsoft.com/opensource/2023/10/18/enabling-developer-collaboration-with-radius/\">https://cloudblogs.microsoft.com/opensource/2023/10/18/enabling-developer-collaboration-with-radius/</a>\"</p><p><a href=\"https://cloudplane.org/blog/why-kubernetes-is-so-complex\">https://cloudplane.org/blog/why-kubernetes-is-so-complex</a>\"</p><p><a href=\"https://home.robusta.dev/blog/kubernetes-is-complex-because-you-want-complex-things\">https://home.robusta.dev/blog/kubernetes-is-complex-because-you-want-complex-things</a>\"</p><p><a href=\"https://www.quora.com/Why-is-Kubernetes-too-complicated\">https://www.quora.com/Why-is-Kubernetes-too-complicated</a>\"</p>",
    "publish_time": "2023-10-19 14:05:08",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "一夜之间，有价无货！英伟达消费级 RTX 4090显卡遭全面下架，最高售价接近4万",
    "url": "https://www.infoq.cn/article/0AbAmTSduzAuVFFu29Nq",
    "summary": "<p>北京时间10月18日下午，英伟达顶级旗舰显卡 RTX4090 开始全面下架。</p><p>&nbsp;</p><p>目前，当前在京东搜索 “RTX 4090 显卡”只有少数第三方售卖，但需要预约等待到货。 同样，在淘宝搜索也是如此，标注价格基本2万起步，最高甚至接近4万元。而在二手平台咸鱼上，RTX4090售价基本1.2万起步。华硕、微星、影驰等英伟达合作商也同样纷纷下架该型号的非公显卡，官方旗舰店均已显示无货状态。</p><p><img src=\"https://static001.geekbang.org/infoq/4c/4c0dc2603d70908566d865fefe26c49e.jpeg\" /></p><p></p><p></p><h2>“新限令”的结果</h2><p></p><p>&nbsp;</p><p>显然，这次消费级显卡 RTX4090 的下架是受当天美国“新限令”的影响。</p><p>&nbsp;</p><p>北京时间10 月 18 日，美国商务部宣布，计划限制向中国出售更先进的 AI 芯片。据悉，新的政策将限制 Nvidia A800 和 H800 芯片的出口，此外，新规将豁免笔记本电脑、智能手机和游戏设备中使用的大多数消费级芯片，但其中部分芯片仍须受到美国官员的批准和专项管控。相关规定将在未来 30 天内生效。</p><p>&nbsp;</p><p>10 月 16 日晚，美国商务部长 Gina Raimondo 表示，新措施弥补了去年 10 月所发布法规中的漏洞，未来可能“至少每年更新一次”。她解释称，此番措施的目标是限制中国获取“先进半导体，这些半导体能够推动 AI 技术发展以及对军事应用具有重大意义的复杂计算机突破”，并强调美国政府无意在经济上打压中方。</p><p>&nbsp;</p><p>有分析指出，去年10月美国实施原有的AI芯片管制规定后，英伟达推出H100和A100阉割版，分别为H800和A800，处理速度约为对应芯片的70%，它们仍可用于人工智能应用上。而本次的新限制则以“性能密度”（以每平方毫米的浮点运算次数来衡量）取代芯片间通信速度，旨在阻止公司寻找“绕过”方法。这意味着不论英伟达还是英特尔、AMD，按照算力性能密度的要求，新产品可能基本没有办法对华供应。</p><p>&nbsp;</p><p>另外，新规还扩大了半导体制造设备的出口管控，包括强化对美国人才的限制，还对中国以外的 21 个国家提出了芯片制造工具出口管控要求，原因是担心这些设备可能被转移给中国或其他国家，进而引发安全问题。</p><p>&nbsp;</p><p>更多详情可查看：</p><p><a href=\"https://mp.weixin.qq.com/s/IFazU7qhHkkmNWKrwFqDhw\">突发！美国限制向中国出口 Nvidia H800 等先进 AI 芯片，壁仞科技、摩尔线程等中国 GPU 芯片企业被列入实体名</a>\"</p><p>&nbsp;</p><p>“今夜对于无数GPU行业、服务器行业、算力行业以及AI行业从业者来说都是不眠之夜，就连消费级的4090显卡都从每张1.5万跳涨到2.5万。在高度全球化的今天，一纸大洋彼岸的禁令就这样荒谬且真实地影响了国产大模型和人工智能发展的进程。”有业内资深人士称。</p><p>&nbsp;</p><p>附：美国对华半导体制裁记录</p><p>&nbsp;</p><p>2018年10月，美国商务部发布公告，将福建晋华集成电路有限公司列入商务部实体名单，禁止美国企业向福建晋华出售技术和产品；2019年5月，美国商务部正式将华为列入“实体清单”，禁止美企向华为出售相关技术和产品2020年5月，美商务部公告将延长华为的供货临时许可证90天至8月14日，但同时升级了对华为的芯片管制，以限制华为使用美国技术软件在国外设计和制造半导体的能力；2020年12月，美国商务部以“违反美国国家安全或外交政策利益”为由，宣布将中芯国际列入“实体清单，这就意味着中芯国际生产10nm以下芯片所需要的原料和设备无法获得美国批准出口；2022年10月，美国BIS公布对中国出口管制新规，主要针对先进芯片和芯片制造设备领域；2022年11月，美国向日本和荷兰施压，要求两国的芯片制造领域相关企业立即禁止向中国出售产品，阻止先进芯片技术流入中国；2022年12月，美国商务部决定将包括长江存储、寒武纪、上海集成电路研发中心、上海微电子、深圳鹏芯微等在内的36家中国实体 (包括一家长江存储日本子公司) 加入实体清单。</p><p></p><h2>英伟达的应对策略？</h2><p></p><p>&nbsp;</p><p>对于“新限令”，英伟达方面回应称：“我们遵守所有适用的法规，同时努力提供支持不同行业的数千种应用产品。鉴于全球对我们产品的需求，我们预计（新规）短期内不会对我们的财务业绩产生实质性的影响。”</p><p>&nbsp;</p><p>不过，英伟达的市场表现并没有英伟达官方说的那么乐观。</p><p>&nbsp;</p><p>美东时间10月17日周二，美股盘中，英伟达（NVDA）一度重挫7.8%，创2022年12月以来最大盘中跌幅。截至收盘，英伟达跌4.68%，报收439.38美元，市值一夜蒸发超535亿美元（≈4000亿元人民币），最新市值1.09万亿美元。英特尔、AMD也分别收跌1.4%、1.2%，美股芯片股合计蒸发730亿美元（约合5343亿元）市值。</p><p>&nbsp;</p><p>在此背景下，人们更加确信之前爆出英伟达将推出RTX 4080 Super&nbsp;的消息。根据 @hongxing2020 爆料消息，英伟达将带来三款 RTX 40 系 SUPER 显卡，分别为 RTX 4080 SUPER、RTX 4070 Ti SUPER、RTX 4070 SUPER。有媒体求证得知，目前 3 款 SKU 基本上已经确认，但并未拿到具体信息，只知道新版 RTX 4080 将会采用 20GB GDDR6X 显存。</p><p></p><h2>大企业“备货充足”</h2><p></p><p>&nbsp;</p><p>与美股芯片股反应相反，10月18日，A股算力芯片概念股普遍上涨，好利科技一字涨停，寒武纪、弘信电子盘中大涨超10%，景嘉微、海光信息等纷纷收涨。</p><p>&nbsp;</p><p>在芯片管制措施升级消息曝出后不久，部分公司对外透露称“影响不大”、“备货充足”等。10月17日晚，恒润股份公告显示，其控股子公司上海润六尺向供应商A采购75台H800及22台A800现货，合计合同金额约2亿元。腾讯、百度等大厂也表示，“囤货充足”。但中小型AI公司的日子可能不太好过。</p><p>&nbsp;</p><p>当前，国内以大模型为代表的AI领域正在迅速发展。根据TortoiseIntelligence发布的AI指数，对世界各国人工智能进行排名，综合来看，我国仅次于美国排名第二，单项指标中，发展指标和政府策略指标更是位居首位。但新规的发布就是国内AI发展的“绊脚石”。</p><p>&nbsp;</p><p>在美对华持续制裁背景下，算力自主可控需求日益增长。IDC最新数据指出，中国本土云端AI加速芯片制造上正在快速增长，2023年上半年，中国AI服务器使用了50万块本地采购/开发的AI加速芯片。其中，华为、寒武纪、海光等国产算力被寄予厚望。</p><p>&nbsp;</p><p>浙商证券指出，国内算力芯片的发展速度取决于上游供应及下游的迭代速度，因而供应及生态体系较为完善的华为鲲鹏升腾芯片有望最先获益，具备较强技术积累和生态兼容性的海光也有望迎来更大的市场空间。</p><p>&nbsp;</p><p>科大讯飞创史人刘庆峰就曾表示，华为的GPU能力现在已经跟英伟达 A100 一样，现在已经做到对标英伟达的 A100。而前不久，华为Mate 60系列引发抢购热潮，主要因为Mate 60系列顺利上市象征着华为突破美国封锁制裁，取得阶段性胜利。全球著名半导体行业观察机构TechInsights 公开发布了对Mate60 Pro 的拆解报告：Mate60 Pro搭载了新型麒麟9000s芯片，并采用了先进的7纳米。</p><p>&nbsp;</p><p>“接下来，我们每个从业者的选择在共同定义未来，囤货赚快钱或者埋头苦干寻找替代。明天太阳照常升起，卡贩子猫博士也会继续战斗下去。”上述提到的资深人士表示。</p>",
    "publish_time": "2023-10-19 14:08:02",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "北京银行高级经理张汝成确认出席 FCon，分享建设“金融操作系统”，探索平台工程实践",
    "url": "https://www.infoq.cn/article/SNqfIDkSU04mbKDpRRv4",
    "summary": "<p><a href=\"https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle\">FCon 全球金融科技大会</a>\"，将于 11 月在上海召开。北京银行高级经理张汝成将发表题为《<a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5584?utm_source=infoqweb&amp;utm_medium=article\">建设“金融操作系统”，探索平台工程实践</a>\"》主题分享，介绍北京银行自主研发的金融操作系统的建设思路、内容、设计要点，以及实践中的经验总结。</p><p></p><p><a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5584?utm_source=infoqweb&amp;utm_medium=article\">张汝成</a>\"，现任平台研发团队负责人。2009 年加入北京银行从事软件开发相关工作，先后负责 ESB、支付系统、核心业务系统等关键银行系统的建设，拥有 15 年架构设计经验。2019 年开始负责全行技术平台建设，全面展开以自研分布式微服务框架、容器云和 DevOps 等基础平台为代表的平台建设，在银行数字化转型过程中发挥了重要作用。高级工程师、高级经济师、CISSP、CCSP、DOP 等。他在本次会议的演讲内容如下：</p><p></p><p>演讲：建设“金融操作系统”，探索平台工程实践</p><p></p><p>银行数字化转型进程已经进入深水区，随着云平台、人工智能等新基础设施的逐步成熟落地，数字化进程对流程优化、组织优化和文化培养提出更多要求。平台工程概念的提出，在内部开发效率提升、业技融合等方面都提供了一套更加系统的战术打法，更加适应数字化战略目标。一方面，平台工程聚焦基于体验的开发流程重塑，让系统建设更有效率；另一方面，平台能力的业务侧延伸也让业绩融合流程更加顺畅，技术赋能更具着力点。北京银行通过自主研发金融操作系统促进全行数字化转型，在大平台工程的事件中进行了有益探索。</p><p></p><p>演讲提纲：</p><p></p><p>北京银行“金融操作系统”建设思路和内容金融操作系统的设计要点平台工程实践中的经验总结</p><p></p><p>你将获得：</p><p></p><p>○ 探讨如何通过平台工程将技术与业务进行深度融合，以提高金融服务的效率和客户体验</p><p>○ 了解北京银行在大平台工程中遇到的挑战和困难</p><p>○ 深入了解如何聚焦基于体验的开发流程，使系统建设更高效，并满足用户的实际需求</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle\">DevOps&nbsp;在金融企业落地实践</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle\">金融行业大模型应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle\">创新的金融科技应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle\">金融实时数据平台建设之路</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle\">金融安全风险管控</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle\">数据要素流通与数据合规</a>\"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，享 7 折优惠 ，立省 ￥2040！咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png\" /></p><p></p>",
    "publish_time": "2023-10-19 14:42:31",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "四维纵横完成上亿元B轮融资，加速打造极简、极速的超融合数据库",
    "url": "https://www.infoq.cn/article/l4xavy6izPahcDBRKJXe",
    "summary": "<p>近日，新一代超融合数据库厂商四维纵横宣布完成了上亿元人民币的 B 轮融资，本轮融资由用友、顺义产业基金领投，广州同创基金跟投。</p><p>&nbsp;</p><p>目前，四维纵横已打造出聚焦于“分析、事务、时序”的 All-in-One 超融合数据库 YMatrix，并以此为核心，自研了全栈向量化执行器、分布式数据库灾备、MARS3 存储引擎、MatrixShift 迁移工具、MatrixGate 高性能写入组件、MatrixUI 图形化界面等一系列商业化套件，实现了多模数据和多模操作的有效融合。</p><p>&nbsp;</p><p>不同的行业环境和业务模式决定了各自不同的关键性问题与挑战，从而塑造了不同的数据需求。然而，在这些变化和差异之中可以捕捉到共性需求的脉络，YMatrix 正是发端于这些脉络，逐渐构建起“超融合”数据库的版图。</p><p><img src=\"https://static001.geekbang.org/infoq/e7/e71fc588878279b3bdd97d0b4fda3f44.png\" /></p><p></p><p>YMatrix 超融合架构</p><p>&nbsp;</p><p>在 YMatrix 4.0 时期，YMatrix 通过信通院评测，成为国内首款超融合数据库；在 YMatrix 5.0 时期，团队致力于打磨数据库性能，重塑集群架构，进一步提升产品在不同场景中的功能和性能表现。</p><p>&nbsp;</p><p>四维纵横表示，随着 YMatrix 5.0 版本的发布，YMatrix 正式迈向了多行业超融合的全新阶段，实现了由过去专注时序单一应用场景，到现今“分析、事务、时序”等数据库能力的融合、打造超融合数据库数据应用标准和生态的转变。</p><p>&nbsp;</p><p>此外，YMatrix 以国产化替代为入口，技术团队自研了全栈向量化执行器、MARS3 存储引擎、MatrixShift 迁移工具、MatrixGate 写入工具、MatrixUI 图形化界面等一系列商业化套件，帮助各行业快速将业务接入到 YMatrix 生态体系当中。</p><p>&nbsp;</p><p>四维纵横表示，YMatrix 自成立之初就十分重视研发团队的建设，为满足不同行业对数据库性能的多元需求，在技术层面进行了一系列深度创新，也正是这些创新最终构成了 YMatrix 超融合数据库的核心竞争力：</p><p>&nbsp;</p><p>MARS3 存储引擎：以同时适应分析、事务、时序场景为目标，MARS3 创新的提供了灵活的行存/行列混存模式，能够在提供高性能写入能力的同时提供良好的分析性能，同时实现了完善的 MVCC 机制，使 YMatrix 在存储引擎层面实现了“超融合”；向量化执行引擎：YMatrix 经过全面向量化改造的执行引擎能够充分利用现代 CPU 的 SIMD 指令集，实现一条指令操作一批数据，与 MARS3 的列式存储相配合，在大数据分析场景下能够将查询执行效率提升至全新水准；ALOHA 高可用架构：ALOHA(Advanced Least Operation High Availability) 是全新设计的集群状态管理服务；作为一款独立运行的可靠分布式服务，其不仅可单独配置磁盘，还能够在严苛环境中依然能够保证低延迟的节点状态探测和控制，保障故障切换时间 &lt; 3s。</p><p>&nbsp;</p><p>据悉，当前 YMatrix 已被广泛应用到银行、保险、证券、通信、车联网、智能制造等行业，服务了理想汽车、宁德时代、浪潮、中兴、三一重工等多个行业的头部企业。生态方面，为加速超融合数据库在各类应用场景中的落地应用，YMatrix 与用友、天翼云、映云科技、麒麟软件等国产化厂商在产业生态层面进行高度绑定。</p><p>&nbsp;</p><p>在本轮融资之后，四维纵横表示，将会以目前 YMatrix 产品技术能力为根基，以超融合理念为发展方向，继续拓展新的应用领域，将 YMatrix 超融合数据库产品应用于更多的场景中。另外，四维纵横将进一步加快并夯实技术团队的人员建设和技术基础，为全球用户提供更加全面的超融合解决方案。</p><p>&nbsp;</p><p>&nbsp;</p><p>更多阅读：</p><p><a href=\"https://www.infoq.cn/article/NpFtpt7gOm4OJNtkUF4v?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">从一线研发到公司创始人，基础软件创业者迷雾中与市场赛跑</a>\"</p>",
    "publish_time": "2023-10-19 17:15:33",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "SplitRec：隐语拆分学习在推荐系统中的实践",
    "url": "https://www.infoq.cn/article/kEWrpXbJiTxKMA0OzTLR",
    "summary": "<p>大家好，我是蚂蚁隐语联邦学习团队的胡东文。今天非常高兴来分享我们的应用实践。其实拆分学习在隐语第一个版本里就已经有一些内容了，为什么在推荐场景要单独再重新提它呢？其实，在实践过程中，我们发现简单的拆分学习架构是没有办法满足很多实际应用的，在实际应用过程中需要非常多的优化，今天就会和大家分享这方面的工作。</p><p></p><p>我将从以下三个方面展开今天的分享：</p><p></p><p>1.&nbsp;在跨域推荐场景中，普通拆分学习为什么没有办法满足需求</p><p>2.&nbsp;从数据接入到模型设计的全链路解决方案中做了哪些东西</p><p>3.&nbsp;有一整套解决方案后，如何在SecretFlow 中使用这些功能</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bb/bb77d9a314109ca9cbcecbd7350ad2d1.png\" /></p><p></p><p></p><h2>跨域推荐场景的挑战</h2><p></p><p></p><h3>跨域推荐场景介绍</h3><p></p><p></p><p>跨域推荐场景是非常多的，例如在一个APP 里搜索了一个东西，到另外一个 APP 中也会推荐相应的广告。或者在一个平台内也会出现跨域推荐的场景，例如在一个类似短视频平台的内容平台中，后面有内嵌的商家，商家需要在这个平台上做相应推荐吸引更多的用户，这个用户到底喜欢哪些东西，除了商家自己有用户信息之外，这个上架所依附的平台有更多信息。例如，我作为这个平台的用户，在上面刷了很多视频，这些视频就会展示我的兴趣点，这些展现出来的兴趣点对推荐是很有帮助的。这种情况下，如果能把这个数据和我的数据联合起来，做一个推荐模型，效果会比仅使用我在商家里的个人数据展现的推荐效果好很多。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/74/74e0ad9c739338c04a5b1ef53b636716.png\" /></p><p></p><p>抽象一下其实就是上图的表格，左边的平台方有用户兴趣特征，右边的商家方同样也有用户特征和商品特征，同时商家方还有转化数据。相当于是在这样的垂直拆分场景下，商家想要做一些预测，这个用户会不会去买这个商品，或者点击这个商品。</p><p></p><p>在这个过程中，刚才提到了用户的感受。但其实对商家平台方来说是不希望数据在不同公司间流通的。但是从平台的维度看，商家的用户数据是他们自己的资产，商家不想把自己的资产交给别人，但是平台又想把自己的数据和平台上其他商家的数据联合起来给他们提供助力。简而言之，平台不想让商家把自己的数据给出去，但想把这些数据隐含的价值给出去，在这种情况下就很适合用联邦学习，特别是拆分学习。</p><p></p><h3>拆分学习基础架构</h3><p></p><p></p><p>先简单介绍一下拆分学习的基础架构。这个基础架构非常简单，就是我们虽然不能把数据给出去，但是在训练过程中可以把中间的数据做交换。这个场景中，Alice 跟 Bob 都会有一个子模型，这两个子模型可以做一些前向的计算，在有转化标签这一方可以进行融合，出现第三个子模型。在训练过程中，根据前向传播的结果和真实标签计算 loss，然后进行反向传播，使整个训练可以 work，这是基本的拆分学习架构。在隐语第一个版本中就提供了这样的架构，这个架构本身可以满足一些简单的推荐场景，有一个典型的例子是银行营销。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1a/1aff2901f5d136f49babbc875788c869.png\" /></p><p></p><h3>跨域推荐场景的挑战</h3><p></p><p></p><p>在实际业务过程中，会发现基本的拆分学习架构存在很多问题：</p><p></p><p>最直接的就是怎么接入数据。在实际过程中，不同机构或不同公司大数据平台都是不一样的，SecretFlow 作为纯粹的计算引擎，不太可能接所有数据。那我们如何做这件事情。在推荐模型上，可以用简单的推荐模型，例如可以用DNN 做推荐模型，这种是非常简单的，但有些比较高级的推荐模型，是不是可以直接放到拆分架构里做，这也是一个问题。因为这种架构下每一个batch 都需要有前向和后向的通信，通信会不会成为瓶颈。当有前向和后向的通信时，通信的中间数据会不会造成安全性的问题，例如隐私泄露和价值泄露。最后完成了模型的训练，可以发现模型分成A 和 B，那需要如何做在线服务，这也是个问题。</p><p><img src=\"https://static001.geekbang.org/infoq/cf/cf3ec720d1f7380689ba9675ea4aa271.png\" /></p><p>今天，我们就围绕这几个方面分享一下隐语是怎么做的。</p><p></p><h2>从数据接入到模型设计的全链路解决方案</h2><p></p><p></p><h3>数据接入</h3><p></p><p></p><p>我们先分享一下数据需要怎么接入。数据接入是比较典型的平台工程工作，这块并不是交给SecretFlow 这一层实现的。在实际使用时，我们会依赖调度框架 Kuscia ，使用 Kusica 框架一方面可以实现屏蔽不同机构的基础设施、网络等，同时也会有一层数据网格 DataMesh，它是用来负责对应用屏蔽所有数据访问的细节。DataMesh 的设计思想是对上提供一套统一的数据接入接口。我们也不想重新造轮子，所以使用了业界比较成熟的是技术 Arrow Flight RPC，Arrow 是 Apache 开源的一个存储格式或者数据传输的格式，可以比较高性能得实现数据传输和进行零拷贝优化。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2a/2a02e20484b8e22a344834c4d5f82e27.png\" /></p><p></p><p>我们会基于这个ArrowFlightRFC 去实现 DataMesh，这样 SecretFlow 就可以使用 ClientSDK 方便得接入各种数据源。关于 DataMesh，我们计划再进行很多功能的实现，且这块对用户来说是透明的。</p><p></p><p>关键的是下面DataSource 这一层，不同的用户如果有不同数据源接入需求，只需要在 DataSource 层实现 connector，例如阿里云的 OSS，AWS 的 S3 等等，这种类似于文件的数据源可以用线性访问接口实现，SQL 数据源可以用 SQL Connector 来实现，达到整个统一接入的模式。这块目前是在α阶段，我们会在尽快开源，届时也欢迎大家一起共建 DataMesh 的体系。</p><p></p><h3>模型设计</h3><p></p><p></p><p>第二部分是模型设计。刚才提到DNN 是很方便拆分的，但其他模型怎么样？</p><p></p><p>这个以DeepFM 模型为例，这个模型其实是 CTR 里经典的模型，可以看到它的结构比 DNN 会复杂一些，拆分的方式也不是非常显而易见的。简单解释一下它的架构：</p><p>左边是和DNN 模型不一样的部分；右边是个普通的DNN，一个全连接网络。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c5/c5a40392ba8604fe0ea32d752886afbc.png\" /></p><p></p><p>这里我们直接看跟DNN 不同的左边。左边的核心是：它有一个一阶的特征和二阶的特征交叉。</p><p>一阶特征：指一个目标用户有ABCD 几个特征，哪个特征重要性比较强，系数就更大。比如说我是一个喜欢看视频的人，那我就会推荐一些视频相关的东西，比如说好的显示器。特征交叉：我们举一个经典的例子：啤酒和纸尿裤。啤酒和纸尿裤是两个特征，单独看不是很重要，但是放到一起就很重要，有时候买了纸尿裤的用户之后就会买啤酒。想要表达的就是在特征交叉后可以挖掘出用户更多的特征，这个特征更强对整个推荐的效果也更好，这就是所谓的二阶交叉。这也就是FM 这一层要做的事情。</p><p></p><p>简单总结一下，FM 部分就是一阶特征和二阶交叉的和。</p><p></p><p>这个东西怎么拆分？因为要交叉，也就是要做个乘法。A 和 B 两方都有特征，A 和 B 之间的乘法就有问题，不可能把 A 的特征直接给到 B，因为不能把原始数据直接发出去。简单的拆分就是 A 这边自行交叉，B 也自行交叉，然后再去做融合。这种情况下，如果啤酒在 A 这边，纸尿裤在 B 这边，那就没办法发现这组有效的交叉特征，也就是没有办法发挥 DeepFM 的完整能力。</p><p></p><p>所以，我们想设计一个拆分方案，使得所有特征都可以做交叉。</p><p><img src=\"https://static001.geekbang.org/infoq/64/64a6f6cc267c93d6a089cfe393acf8e3.png\" /></p><p></p><p>这是一些推倒公式。最上面是FM 的公式。我们主要看一下下面的右边部分，右边就是交叉的部分，简单理解它就是两两特征之积，前面加一个参数，做个简单变换就可以变成最下面的那行：一些特征和的平方减去所有特征平方的和，也就是平方和公式，A+B 的平方，会变成平方和然后再加上一个交叉项。</p><p></p><p>我们观察一下这个公式，可以很简单的把它变成双边的东西，第一部分可以变成一阶项减去1/2 的平方和，第二部分就是直接求和，这两个其实就是统计数据，第一部分是标量值，它不会泄露隐私的信息，第二个值是 K 维的，K 是模型的参数，也是个很小的值，可能就是 4 或者 8 个数字，本身也不会泄露隐私的信息。</p><p><img src=\"https://static001.geekbang.org/infoq/5b/5b28f651cb22415987404c9d5634058c.png\" /></p><p></p><p>这就相当于在隐层那边算出了这两块东西，把这两块发送到B 这一方，B 这一方只需要根据上面的公式重构出 y 就可以。这样的过程相当于整个计算既保持了所有的特征都可以做交叉，同时又使得隐私没有被泄露出来，这是以 DeepFM 为例简单介绍一下模型的设计。</p><p></p><p>DeepFM 模型已经在隐语的仓库中了，后面还会有更多的推荐模型加入，后面如果大家有其他的需求或者其他模型的拆分方案，欢迎大家参与贡献。</p><p></p><h3>性能相关</h3><p></p><p></p><p>第三是关于性能相关的。我们知道每个batch 都需要做通信，做了那么多通信是不是需要确认一下通信是不是会成为瓶颈。原来拆分学习的方案是先做前向的过程，做计算后把隐层 u 传上去，然后在 Server-Side 那边做前向，接下来再做反向的梯度 d ，然后再做更新，整个过程都是串行的，同时中间有两次数据的传递，是会有比较大的性能问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/51/51d4ed8e793b96988ea81ac4f84baa57.png\" /></p><p></p><p>我们拆解来看可以做哪几方面的优化：</p><p></p><p>带宽：因为有通信，首先想到的是带宽问题，因为很多时候两个公司之间带宽并不会特别高，所以有个想法是减少单次的通信量，例如通过压缩的方法，这边我们也已经实现了稀疏化与量化。在代码仓库里实现了五六种稀疏化与量化方法，可以直接使用。延迟：还有一个思路是减少通信次数，能不能使u 和 d 的总次数变小，思路就是能不能让其他的步骤多执行几次，比如说 server-side 的 fs 和 bs 多执行几次，u 和 d 就可以少执行几次。这里面也会设计一些异步拆分的方法，目前也均已实现。</p><p></p><p>这里也稍微详细介绍一下另外一个方法：流水线并行。可以看到刚刚的流程是完全串行的计算流程，整个计算和带宽都是没有办法打满的。使用流水线计算后，计算流程不会等待所有梯度回传之后更新参数，它会直接进行下一个batch 计算，整个流水线可以让计算和通信跑的比较满，可以更合理地使用带宽和计算资源。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/12/126cb2814493bd5d7df8eee90d49f0ce.png\" /></p><p></p><p>它的参数更新的流程是：</p><p>Server 端和以前一样，只需要正常计算前向和后向更新主要的调整集中在Client 端。它的更新模式是：一开始的参数是 W1，实际在更新时可能已经到 W5 了，那在拿到梯度时直接更新其实是有问题的，所以我会把之前 W1 的模型参数拿过来，再根据拿到的回传梯度来计算要更新的参数，再把正确的梯度应用到目前的模型参数上，这样往前更新参数，使保证整个过程的参数梯度都用到，参数更新都能更新一次，整个流程可以串起来。</p><p></p><h3>安全性问题</h3><p></p><p></p><p>安全性问题其实是个比较大的问题。因为拆分问题中间有信息泄露，所以没办法从密码学或者从数学方式上证明其安全性，所以我们的思路是在攻击和防御的角度看它的安全性：找到一些合理有效的攻击，看其是否能防御住这些攻击。</p><p></p><p>举个例子，RIA 就是重构攻击。在 Alice 这一方想要重构 Bob 这一方的 Dataset 也就是原始数据，通过传输到的隐层等；对于 Bob 这一方来说可能想要“偷”Alice 这一方的 Lable 也就是标签，也可以通过拿到的梯度等来实现。</p><p></p><p>这是我们做的攻击框架，希望把所有攻击都集成进去。这块最大的问题是现在攻击和防御，也就是矛和盾都比较弱。我们本身就会在攻击这边做工作，想把真实场景下的攻击变的更有效。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/38/38ccd9af6445b00701ba2a451836bd4b.png\" /></p><p></p><h3>在线服务</h3><p></p><p></p><p>最后是在线服务，是正在进行中的工作，还没有开源出来，大家也可以期待一下，这里简单介绍一下。在线服务实际应用时在两个机构中存在的，所以需要在两个机构这边同时拉起服务，预测时提交一个ID，两边各自去特征服务那查东西。这里会涉及到一些联合调度的问题，包括跨机构的、高可用的问题。我们还是基于 Kuscia 来实现的，KusciaDeployment 解决来类似 K8s Deployment 的高可用问题，Secretflow-Serving 是专门用来做 Serving 的引擎，后面也会计划开源。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/98/981451f5ca6fd55f182618a259d43ce9.png\" /></p><p></p><h3>测试数据</h3><p></p><p></p><p>最后简单看一下测试数据。这里加上了sparse topk 和 pipeline，可以看到pipeline 跟优化前的结果差了3 倍以上，这个效果是比较好的，在 1000万数据下这个时间已经是可以直接使用的状态。也可以看到后面的 CPU 和网络还没有完全打满，还存在优化空间。</p><p><img src=\"https://static001.geekbang.org/infoq/c0/c06a24e33cba305aa1fec53c90dc8a53.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/70/70654fda23aa382ddcacddb4b1b9de1e.png\" /></p><p></p><p></p><h3>小结</h3><p></p><p></p><p>总结一下，今天讲的所有东西都可以在下方对应链接/ 位置中找到：</p><p>数据接入：https://github.com/secretflow/kuscia/tree/main/pkg/datamesh模型：secretflow.ml.nn.applications通信优化：</p><p> secretflow.ml.nn.sl.backend.tensorflow.strategy</p><p> secretflow.utils.compressor</p><p>安全：</p><p>secretflow.ml.nn.sl.attack</p><p>secretflow.security.privacy</p><p></p><h2>如何在SecretFlow 中使用这些功能</h2><p></p><p></p><p>这是拆分学习怎么去训练它的简单事例</p><p></p><p>首先是可以加一些DP模型可以用自定义模型或者内置模型，像刚才分享的DeepFM 模型通信优化可以加一些通信的压缩，例如这里用了Topk 的稀疏化流水线并行，刚才也提到过了</p><p></p><p>这块整个加起来就可以把所有的东西串起来，进行训练。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/015b2b2a70e72134245e172031369b11.png\" /></p><p></p><p>我的分享就到这里，感谢大家。</p>",
    "publish_time": "2023-10-19 18:04:50",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Alluxio AI全新产品发布：无缝对接低成本对象存储AI训练解决方案",
    "url": "https://www.infoq.cn/article/NWvmKhGUYAjYjdIpAedo",
    "summary": "<p>（2023年10月19日，北京）Alluxio作为一家承载各类数据驱动型工作负载的数据平台公司，现推出全新的Alluxio Enterprise AI高性能数据平台, 旨在满足人工智能 (AI) 和机器学习 (ML) 负载对于企业数据基础设施不断增长的需求。 Alluxio Enterprise AI 平台可综合优化企业AI和分析基础设施的性能、数据可访问性、可扩展性和成本效益，助力生成式AI、计算机视觉、自然语言处理、大语言模型和高性能数据分析等下一代数据密集型应用的发展。</p><p>&nbsp;</p><p>为保持竞争力并在竞争中脱颖而出，各家企业都在全力推进数据和AI基础设施的现代化。在此过程中，企业家们也意识到传统的数据基础设施已经无法匹配下一代数据密集型AI负载的需求。在AI项目推进中经常遭遇的各类挑战，诸如性能低下、数据可访问性差、GPU 稀缺、数据工程复杂以及资源未充分利用等，都严重妨碍了企业获取数据价值。 <a href=\"https://emtemp.gcom.cloud/ngw/globalassets/en/publications/documents/2023-gartner-top-strategic-technology-trends-ebook.pdf\">Gartner</a>\"® 研究称，“可操作AI的价值在于能够在企业的各种环境下进行快速开发、部署、调整和维护。考虑到工程复杂性和更快的市场响应需求，开发较为灵活的AI工程数据流，构建能够在生产中进行自适应的AI模型均至关重要” ，“到 2026 年，采用AI工程来构建和管理自适应AI系统的企业，将在AI模型可操作性方面至少超越同行 25%。”</p><p>&nbsp;</p><p>Alluxio 创始人兼CEO李浩源表示：“Alluxio用最先进的大数据和Al平台为全球头部企业客户赋能，今天我们又向前迈出了一大步”， “Alluxio Enterprise AI 为客户提供高效的AI 解决方案，帮助企业加速 AI工作负载并最大限度地获取数据价值。未来的企业领导者将知道如何利用变革性AI来推进数据驱动，通过最新技术来构建和维护AI基础设施，实现超高性能、无缝访问和便捷管理。”</p><p>&nbsp;</p><p>此次新版发布后，Alluxio 即从一种产品扩展到两种产品组合——Alluxio Enterprise AI 和 Alluxio Enterprise Data，全面满足分析和AI的多样化需求。Alluxio Enterprise AI作为一款全新产品，建立在Alluxio企业版多年积累的分布式系统经验上，采用了针对AI/ML负载优化的新架构。 Alluxio Enterprise Data 是 Alluxio 企业版大数据方向的下一代版本（与Alluxio Enterprise AI平行），并将继续成为专注分析负载企业的理想选择。</p><p></p><h1>加速端到端机器学习工作流</h1><p></p><p>&nbsp;</p><p>Alluxio Enterprise AI 使得企业的AI基础设施能够在现有数据湖上实现高性能运行、无缝数据访问、可扩展且经济高效。它能帮助数据和AI领域的领导者和从业者实现AI项目的四个关键目标：1.高性能模型训练和部署，快速产生业务成效；2.跨区域和跨云负载可无缝访问数据；3.可无限扩展，已经互联网巨头内部严格测试；4. 无需使用昂贵的专用存储，在现有技术栈上即可部署，确保投资回报最大化。企业使用 Alluxio Enterprise AI后，预期训练速度可比使用提供商业服务的对象存储快达 20 倍，模型服务速度提升高达10 倍，GPU利用率达90%以上，AI 基础设施成本节约高达 90%。</p><p>&nbsp;</p><p>Alluxio Enterprise AI 拥有包含去中心化元数据的分布式系统架构，可消除访问海量小文件（常见于AI 负载）时的性能瓶颈。无论文件大小或数量如何，都能确保具备超越传统架构的无限扩展性。与传统分析不同，分布式缓存是根据 AI 负载 I/O 模式量身定制的。此外，还支持分析负载以及从数据摄取到 ETL（提取、转换、加载）、预处理、训练和服务的完整机器学习工作流 。</p><p>&nbsp;</p><p>Alluxio Enterprise AI 包含以下重要特性：</p><p>&nbsp;</p><p>性能出色的模型训练和模型服务——Alluxio Enterprise AI 显著提升企业在现有数据湖上的模型训练和服务性能。用于模型训练的强化API 集可实现优于商业化对象存储20 倍的性能。对于模型服务，Alluxio 提供超高并发性，在将离线训练集群中的模型用于在线推理时实现高达10 倍的速度提升。适合AI工作负载I/O模式的智能分布式缓存——Alluxio Enterprise AI的分布式缓存功能使得AI引擎能够通过高性能Alluxio缓存（而非缓慢的数据湖存储）来读写数据。 Alluxio的智能缓存策略专门针对AI引擎的I/O模式量身定制，包括大文件顺序访问、大文件随机访问和海量小文件访问。该优化帮助需要大量数据的GPU实现高吞吐和低延迟。训练集群持续从高性能分布式缓存中获取数据，可实现90%以上的GPU利用率。跨本地和云环境的AI 工作负载实现无缝数据访问 - Alluxio Enterprise AI 为企业提供了统一的管理界面，可以轻松管理跨不同基础设施环境的 AI 工作负载。该产品为机器学习工作流提供了真实的数据源，从根本上消除了大型企业数据湖孤岛的瓶颈。通过 Alluxio Enterprise AI 这一标准数据访问层，企业可以在不同业务部门和地理位置之间实现数据的无缝共享。经过大规模严格测试的全新分布式系统架构- Alluxio Enterprise AI 平台构建在创新的去中心化架构 DORA（去中心化对象存储库架构）之上。该架构为AI工作负载提供了无限扩展的基础，允许 AI 平台通过包括Amazon S3 在内的商业化对象存储处理多达1000 亿个对象。该新架构借助Alluxio在分布式系统方面的成熟专业知识，解决了系统可扩展性、元数据管理、高可用性和性能方面不断增长的挑战。</p><p>&nbsp;</p><p>&nbsp;Enterprise Strategy Group 分析师 Mike Leone 表示：“随着组织在整个业务范围内扩展AI的应用，优化下一代工作负载过程中的性能、成本和 GPU 利用率变得至关重要” ，“Alluxio 拥有极具优势的产品，能真正帮助数据和 AI 团队实现更高的性能、无缝的数据访问，以及模型训练和模型服务的便捷管理。”</p><p>&nbsp;</p><p>“我们与 Alluxio 合作密切，Allxuio平台对我们的数据基础设施至关重要，”Aunalytics 分析云工程总监 Rob Collins表示， “Aunalytics对于Alluxio新推出的针对企业AI的分布式系统十分期待，并看好新产品在AI 行业的巨大潜力。”</p><p>&nbsp;</p><p>“公司内部训练的大语言模型为我们的问答应用和推荐引擎提供支持，极大地增强了用户体验和参与度”，知乎数据平台团队软件工程师胡梦宇表示， “在我们的AI基础设施中，Alluxio 处于核心地位。在使用 Alluxio 作为数据访问层后，我们的模型训练性能提升了3 倍，部署性能提升了10 倍，GPU 利用率翻倍。Alluxio的Enterprise AI平台采用全新的DORA架构，能支持访问海量小文件，对此我们十分期待。在AI浪潮即将到来的时刻，Alluxio新产品让我们在支持AI应用方面更有信心。”</p><p></p><h1>在机器学习工作流中部署Alluxio</h1><p></p><p></p><p><a href=\"https://www.gartner.com/en/webinar/452057/1065295\">Gartner</a>\"&nbsp;研究显示，数据可访问性和数据量/复杂性是组织应用AI技术中遇到的三大难题之一。 Alluxio Enterprise AI可以添加到由AI计算引擎和数据湖存储组成的已有AI基础设施中。 Alluxio 位于计算和存储中间，可以在机器学习工作流中跨模型训练和模型服务工作，从而实现最大速度和最优成本。例如，将 PyTorch 作为训练和服务引擎， Amazon S3为现有数据湖：</p><p>&nbsp;</p><p>模型训练：当用户训练模型时，PyTorch数据加载器从虚拟本地路径/mnt/alluxio_fuse/training_datasets加载数据集。数据加载器不会直接从 S3 加载数据，而是从 Alluxio 缓存加载。在训练过程中，缓存的数据集将在多个epoch中使用，因此整个训练速度不再受制于访问S3而产生的瓶颈。也就是说，Alluxio通过缩短数据加载来加速训练，消除GPU空闲等待时间，提高GPU利用率。模型训练完成后，PyTorch通过Alluxio将模型文件写入S3。模型服务：最新训练的模型需要部署到推理集群。多个TorchServe实例同时从S3并发读取模型文件。Alluxio会缓存这些来自S3的最新模型文件，并以低延迟提供给推理集群。因此，最新模型一旦可用时，下游的AI应用即可将其用于推理。</p><p></p><h1>平台与现有系统集成</h1><p></p><p>&nbsp;</p><p>要将Alluxio与现有平台集成，用户可以在计算引擎和存储系统之间部署Alluxio集群。在计算引擎侧，Alluxio 可与 PyTorch、Apache Spark、TensorFlow 和 Ray 等流行的机器学习框架无缝集成。企业可以通过 REST API、POSIX API 或 S3 API 将 Alluxio 与这些计算框架集成。</p><p>&nbsp;</p><p>在存储侧，Alluxio 可连接位于任何位置（本地、云端或两者兼有）的各类文件系统或对象存储。支持的存储系统包括 OSS、COS、BOS、OBS、Amazon S3、Google GCS、Azure &nbsp;Blob Storage、MinIO、Ceph、HDFS等。</p><p>&nbsp;</p><p>Alluxio 可在本地和云端、物理机或容器化环境中运行。支持的云平台包括阿里云、腾讯云、百度云、华为云、AWS、GCP、Azure Cloud等。</p><p>&nbsp;</p><p>下载资源</p><p></p><p>Alluxio Enterprise AI 下载链接：<a href=\"https://www.alluxio.io/download/\">https://www.alluxio.io/download/</a>\"</p><p>&nbsp;</p><p>AI Infra Day</p><p></p><p>在美西时间10 月 25 日的AI Infra Day 上，Alluxio 将首次公开展示其最新发布的 Alluxio Enterprise AI平台。AI Infra Day是面向开发者的线上活动，主要探讨构建高性能、可扩展且经济高效的 AI 基础设施中的挑战及各种方案。特邀嘉宾包括Wanchao Liang（Meta ）、 Sally (Mihyoung) Lee（Uber） 和范斌（Alluxio）。活动现已开放报名：<a href=\"https://www.alluxio.io/ai-infra-day-2023/%E3%80%82\">https://www.alluxio.io/ai-infra-day-2023/。</a>\"</p><p>&nbsp;</p><p></p><blockquote>关于Alluxio&nbsp;Alluxio 是全球领先的针对分析和AI的高性能数据平台提供商，可加速企业AI产品价值变现，并最大化基础设施的投资回报率。Alluxio数据平台位于计算与存储系统之间，能够在数据工作流的各个阶段为数据平台上的工作负载提供统一视图。无论数据位于何处，该平台均可提供高性能的数据访问，简化数据工程，提高GPU利用率，并降低云计算和存储成本。企业无需使用专用存储，即可大幅加速模型训练和模型服务，并在现有数据湖上构建AI基础设施。Alluxio在头部投资者的支持下， 为全球科技、互联网、金融和电信企业提供服务，目前全球排名前 10 的互联网公司中有 9 家在使用Alluxio。了解更多信息，请访问 www.alluxio.com.cn。&nbsp;</blockquote><p></p>",
    "publish_time": "2023-10-19 18:14:07",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]