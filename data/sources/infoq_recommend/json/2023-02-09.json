[
  {
    "title": "如何评估代码质量：反馈回路、文化、代码质量、技术债务、部署管道",
    "url": "https://www.infoq.cn/article/bhBft2B1a7MyuLYoJPzC",
    "summary": "<p></p>",
    "publish_time": "2023-02-09 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "为什么你的下一个API应该是GraphQL而不是REST",
    "url": "https://www.infoq.cn/article/0fyZC6Yqvj6Ddr4XEHER",
    "summary": "<p></p><p></p><p></p><blockquote>REST在几年前曾经风靡一时，但现在GraphQL拥有更好的工具和开发者体验。</blockquote><p></p><p></p><p>几年前，我所有的API都是<a href=\"https://www.infoq.cn/article/jfkZ7LHF1HbONN2sPOyw\">REST </a>\"API。我知道GraphQL不可小觑，但也并没有花太多时间学习它。早期的探索表明，<a href=\"https://www.infoq.cn/video/YIShfqdvkUw0M8PC9DYu\">GraphQL</a>\"并不是一颗神奇的API银弹。你仍然需要编写所有的逻辑，仍然需要使用奇怪的模式文件。既然如此，我们为什么要选择为额外的复杂性而烦恼呢？REST API很简单，不需要额外的模式。每个资源都有简单的端点，大多数时候，与API端点相关的代码都是简单的CRUD。</p><p></p><p>在过去的一年里，我们从RPC API切换到更好的GraphQL。这对我们的应用程序来说是件好事，因为RPC接口只是GraphQL的一个糟糕实现，而且应用程序中有复杂的关系，因此使用GraphQL更为合适。</p><p></p><p>虽然我对此持怀疑态度，但也很想看看事情将会如何发展。事实证明，现在的工具非常棒，而且这样做的好处是巨大的。</p><p></p><p>一年后，我迷上了它。我的朋友开始了一个业余项目，当我想到需要再次与一堆REST API打交道时，我的心一沉。GraphQL提供了更好的开发者体验。那么，为什么GraphQL如此神奇？</p><p></p><h1>代码基本相同</h1><p></p><p></p><p>在编写处理请求的代码时，处理逻辑的主要代码几乎是相同的。</p><p></p><p>例如，这是一些获取给定ID资源的伪代码。</p><p></p><p><code lang=\"plain\">func resolver(parent, args, context): Resource {\n  const id = args.id\n  const resource = db.Resource.FindOne({id: id})\n  return resource\n}\n</code></p><p></p><p>通过ID获取资源（GraphQL）</p><p></p><p>这是GraphQL还是REST的端点？</p><p></p><p>代码几乎一模一样。主要的区别在于函数签名。获取、更新和删除资源集合也是如此。</p><p></p><p>二者都是将参数传递给函数并处理请求。有一些小的语法变化，但大部分逻辑保持不变。</p><p></p><p>不过GraphQL有一个值得注意的好处，就是可以获取资源间的关系。</p><p></p><p>假设你有一个包含两个资源的模式：一个Author（作者），它有许多Post（帖子）。你只能根据作者获得帖子，所以你的REST API看起来像这样。</p><p></p><p><code lang=\"plain\">/authors/\n/authors/:author_id/\n/authors/:author_id/posts\n/authors/:author_id/posts/:post_id\n</code></p><p></p><p>你实现了四个不同的API来获取每个层级的数据。</p><p></p><p>但你可以使用GraphQL更简单地达到同样的目的。</p><p></p><p><code lang=\"plain\">type Query {\n  authors(id: Int): [Author!]!\n}\n\ntype Author {\n  posts(id: Int): [Post!]!\n}\n</code></p><p></p><p>还有其他方法也可以实现这一点，但这种模式可以让你：</p><p></p><p>不指定ID获取所有作者（这是可选的）；通过特定的ID获取作者；获取所有作者的所有文章；获取单个作者的所有文章；只获取给定作者的给定文章。</p><p></p><p>就我个人而言，我的根查询经常将author和authors分开，避免为单个资源返回一个数组。将Post放在Author下，然后在Author的上下文中编写Post解析器。这个简单的嵌套让用户可以一起查询作者和他们的帖子。</p><p></p><h1>支持工具已经发展得非常好</h1><p></p><p></p><p>GraphQL是一种强类型模式，可以为客户端和服务器库生成代码。</p><p></p><p>因此，客户端可以获取具有完美类型信息的数据。与手动编写的REST API相比，GraphQL的类型安全是一个巨大的优势。有些工具可以为REST API生成类型，例如Swagger/OpenAPI，但这些工具并没有内置到规范中，所以你不会自动获得这些功能。</p><p></p><p>GraphQL在模式中内置了注释，还提供了一个自检API，可以实现自文档化。有了编写良好的注释，就不需要单独维护文档。</p><p></p><p>类似的，因为模式是强类型的，所以实际上你都不需要构建自定义客户端库。服务通常会提供客户端库，这些库提供了易于使用的类型和方法。GraphQL内置了这些，你只需要用它编写一个客户端。</p><p></p><p>你还可以获得为服务器解析器构建的类型。有些语言，比如Go，会生成整个解析器函数。你需要做的是填充内容。其他的，比如TypeScript，会生成所有的类型，你可以在解析器中使用它们来保证类型安全。</p><p></p><h1>类型可以隐藏敏感信息</h1><p></p><p></p><p>你在GraphQL模式中定义数据的类型，这为你提供了一种便利的方式来剔除敏感信息。例如，假设你有一个User类型，它映射到数据库中的一条用户记录，你可能在对象种保存了个人信息，如电子邮件地址或散列过的密码。</p><p></p><p>如果没有合适的工具，你可能会这么操作：</p><p></p><p><code lang=\"plain\">func handler(request, response) {\n  const user = db.User.findCurrent()\n  // 这样会把邮件地址和密码也返回！\n  return user\n}\n</code></p><p></p><p>它会返回用户的所有字段。你需要把敏感信息剔除掉。</p><p></p><p><code lang=\"plain\">func handler(request, response) {\n  const user = db.User.findCurrent()\n  delete user.email\n  delete user.password\n  return user\n}\n</code></p><p></p><p>GraphQL通过特定的类型（在Go或TypeScript中）可以自动完成这个操作，只公开模式中定义的字段。你可以将对象返回给GraphQL解析器，并只公开模式中定义的字段。</p><p></p><h1>用于快速验证查询的工具</h1><p></p><p></p><p>测试GraphQL也变得更容易了，因为一些工具内置了强大的支持。我目前最喜欢的是Insomnia，用于在应用程序之外测试GraphQL查询。Insomnia会获取模式，并提供自动完成查询的功能，支持变量输入。此外，你还可以导出项目并将其包含在源代码中，方便人们进行快速的探索和使用它们。</p><p></p><p>还有其他一些很好的工具，比如Apollo（<a href=\"https://www.apollographql.com/\">https://www.apollographql.com/</a>\"）。</p><p></p><h1>不纯粹的REST API</h1><p></p><p></p><p>随着时间的推移，我注意到REST有一个缺点——并不是每个操作都能很好地映射成CRUD。有一类操作可以被映射成这种格式，但可能没有意义。</p><p></p><p>一次创建多条记录；一次更新多条记录；启动长时间运行的作业；取消作业。虽然我相信你可以写出有意义的REST API（使用POST /job启动作业，它将返回HTTP 202而不是200！），但也存在争议，例如，它究竟是取消作业还是删除作业，还是修改作业？</p><p></p><p>将批量更新作为一个资源，还是操作多个资源？</p><p></p><p>REST没有针对这些操作提供有意义的语义定义，而GraphQL的mutation可以被任意命名，这样你就可以：</p><p></p><p><code lang=\"plain\">mutation cancelJob(id: Int!): Job\n</code></p><p></p><p>不管是PUT还是DELETE操作，都是取消作业——这种灵活性带来了更有表现力的API。</p><p></p><h1>单个请求</h1><p></p><p></p><p>在为页面请求数据时，REST API只返回它们的资源。通常情况下，如果你想获取相关的资源，需要先获取X，然后是X的Y。</p><p></p><p>一些REST API允许你获取相关的资源，这很好。但你不能获取不相关的资源，如X和Z，但GraphQL可以，你可以用多个根查询来获取它们。</p><p></p><p>在使用GraphQL时，你只需要发出一个HTTP请求就可以获取所有数据。</p><p></p><p>现在，如果你获取的数据太多，仍然可能发生灾难性的错误。但在大多数情况下，服务器可以有效地缓存数据并在单个请求中返回大量信息。</p><p></p><h1>GraphQL &gt; REST</h1><p></p><p></p><p>GraphQL是一种强大的查询语言，它在过去几年里不断发展。它提供了令人难以置信的工具，让你可以专注于业务逻辑。此外，你在定义API时具有很大的灵活性，让你拥有了更多的控制权。</p><p></p><p>REST比之前的API要好很多，它提供了一条重新思考数据和以一种朴素的方式创建API的途径。</p><p></p><p>但GraphQL更强大，更容易使用，并且提供了更好的开发者体验。你的下一个API应该是GraphQL，而不是REST。</p><p></p><p>原文链接：</p><p><a href=\"https://ethanmick.com/why-graphql-is-better-than-rest/\">https://ethanmick.com/why-graphql-is-better-than-rest/</a>\"</p>",
    "publish_time": "2023-02-09 10:26:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "谷歌版ChatGPT首秀“翻车”，公司市值蒸发7000多亿元",
    "url": "https://www.infoq.cn/article/PX7hUhtJmshxACEaYYgE",
    "summary": "<p>本周一，谷歌宣布其人工智能聊天机器人 Bard&nbsp;将“在未来几周内更广泛地向公众开放”。作为<a href=\"https://www.infoq.cn/article/ZWixRo76hFsOw38tRHNF\">OpenAI </a>\"ChatGPT的竞争对手，Bard的一举一动都备受关注。</p><p>&nbsp;</p><p>但让谷歌尴尬的是，该机器人的首次出场并不顺利，专家指出 Bard 在其Demo首秀中犯了一个事实错误。</p><p>&nbsp;</p><p>谷歌分享的一张GIF显示，在回答问题“关于詹姆斯韦伯太空望远镜（JWST）有哪些新发现，我可以告诉我 9 岁孩子哪些内容？”时，<a href=\"https://www.infoq.cn/article/z30mE0bxrvItO9Mm52Nw\">Bard </a>\"提供了三个要点，其中一个指出该望远镜“拍摄了我们太阳系外行星的第一张照片。”</p><p>&nbsp;</p><p>然而，许多天文学家在<a href=\"https://www.infoq.cn/article/9jYdCOGBkoioO6zm1fVG\"> Twitter </a>\"上指出这是不正确的，据NASA网站上所述，第一张系外行星图像是在 2004 年拍摄的。</p><p>&nbsp;</p><p>天体物理学家 Grant Tremblay 在 Twitter 上写道：“我相信Bard会令人印象深刻，但郑重声明：JWST 并没有拍下‘我们太阳系外行星的第一张图片’” 。</p><p>&nbsp;</p><p>加州大学圣克鲁兹分校天文台主任 Bruce Macintosh 也指出了这个错误。“作为一个在 JWST 发射前 14 年拍摄系外行星的人，感觉你应该找到一个更好的例子。”</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/a9/a964f4761be7267dcf4beee2fc855d5c.png\" /></p><p></p><p>在后续推文中，Tremblay 补充道：“我非常喜欢并感谢地球上最强大的公司之一正在使用 JWST 搜索来宣传他们的 LLM。这非常好！但是 <a href=\"https://www.infoq.cn/article/FRcz5vjOvl3bM2d57opX\">ChatGPT</a>\"等大模型虽然令人印象深刻，但经常犯错却盲目自信。未来，如果能看到LLM 进行自我错误检查将会很有趣。”</p><p>&nbsp;</p><p>正如 Tremblay 所指出的，ChatGPT 和 Bard 等<a href=\"https://www.infoq.cn/article/3ykO49FEVYiGOTpLq3lC\"> AI 聊天机器人</a>\"的一个主要问题是它们倾向于自信地将不正确的信息陈述为事实。这些系统经常“产生幻觉”——即编造信息——因为它们本质上是自动完成系统。</p><p>&nbsp;</p><p>他们不是查询已证实事实的数据库来回答问题，而是接受大量文本语料库的训练并分析模式以确定任何给定句子中的下一个单词。换句话说，它们是概率性的，而不是确定性的——这一特征导致一位著名的 AI 教授将它们称为“废话生成器”。</p><p>&nbsp;</p><p>当然，互联网上已经充斥着虚假和误导性信息，但微软和谷歌希望将这些工具用作搜索引擎，可能会使问题变得更加复杂。</p><p>&nbsp;</p><p>也正是由于Bard在首秀上的失误表现，导致其母公司Alphabet股价暴跌8%，市值缩水7000多亿元。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.theverge.com/2023/2/8/23590864/google-ai-chatbot-bard-mistake-error-exoplanet-demo\">https://www.theverge.com/2023/2/8/23590864/google-ai-chatbot-bard-mistake-error-exoplanet-demo</a>\"</p>",
    "publish_time": "2023-02-09 10:43:16",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "用户无法正常发推文，马斯克：暂停新功能开发， API 免费访问延长四天",
    "url": "https://www.infoq.cn/article/A1iUa4p4FZgz4giXhiMQ",
    "summary": "<p>近日，推特全球用户再次遇到了一个持续了约 90 分钟的故障，他们无法正常发送推文，而是收到一条自动消息，说他们“超过了每天发送推文的限制”，甚至当天一次还没有发布过用户都收到了该消息。</p><p>&nbsp;</p><p>据悉，Twitter 的帮助中心表示，每天的推文数量上限为 2,400 条。中断不仅影响了新推文发布，还影响了推文的转发和回复。</p><p>&nbsp;</p><p>美国科技出版物 The Information<a href=\"https://twitter.com/erinkwoo/status/1623460140036026369\">报道称</a>\"，马斯克告诉推特员工暂停“新功能开发”，以在中断期间最大限度地提高平台的稳定性。</p><p>&nbsp;</p><p>推特的开发团队在<a href=\"https://twitter.com/TwitterDev\">出现故障后发推文称</a>\"，对其 API 的免费访问将再延长四天。但目前尚不清楚这次故障是否与 API 更改有关。 同时，开发团队还表示，在当地时间 2 月 13 日将弃用 Premium API。如果用户订阅了高级版，则可以申请企业版以继续使用这些端点。</p><p>&nbsp;</p><p>推特此前在2月3日表示，将开始对API访问收费。该公司表示，从2月9日开始，将提供一个付费的基础层面来访问其应用程序编程接口，即API，开发人员可以使用它来分析包括推文在内的一些内部数据，并用它来构建工具。Twitter未透露将收取多少费用，但表示将在下周分享更多细节。Twitter目前提供免费和付费版本的API，对最活跃的用户每月收费高达2,499美元。</p><p>&nbsp;</p><p>有<a href=\"https://www.reddit.com/r/technology/comments/10xgkmo/elon_musk_emails_twitter_staff_to_pause_new/\">网友分享了一组数据</a>\"，推特的订阅制度仅为其带来了 200 万美元的收入（自马斯克接任以来，他们的新订阅者不到 100,000 人），而同比损失的运营广告收入超过 4 亿美元。</p><p>&nbsp;</p>",
    "publish_time": "2023-02-09 11:08:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "聊一聊，我对DDD的关键理解",
    "url": "https://www.infoq.cn/article/664d56bfddaec0858f6c15929",
    "summary": "<p>作者：闵大为  阿里业务平台解决方案团队</p><p></p><p></p><blockquote>当我们在学习DDD的过程中，感觉学而不得的时候，可能会问：我们还要学么？这的确引人深思。本文基于工作经验，尝试谈谈对DDD的一些理解。</blockquote><p></p><p></p><p></p><h1>一、序</h1><p></p><p></p><p>《阿甘正传》中，阿甘开始了不停地跑步，一段时间后，后面就有了很多追随者一起跑，他们为什么跑呢？</p><p></p><p>阿甘：我也不知道，只是想跑而已。</p><p></p><p>追随者：感觉这样做是有意义的，而且阿甘也还在前面领跑。</p><p></p><p>类似地，一开始我也不知道DDD是什么，但当发现大家都在提DDD、都在学DDD的时候，我也像跟跑者一样不由自主地加入了前行：既然有大牛提出了DDD，既然那么多人趋之若鹜，那么肯定有可取的地方。</p><p></p><p>然而，有一天，阿甘停止了跑步，他不想跑了，追随者遇到了一个问题：我们还要跑么？当我们在学习DDD的过程中，感觉学而不得的时候，可能也会问：我们还要学么？这的确引人深思。</p><p></p><p>本文基于工作经验，尝试谈谈对DDD的一些理解，希望能够更好地探寻学习DDD的意义。</p><p></p><p></p><h1>二、关注DDD的价值</h1><p></p><p></p><p>无论做业务，还是做平台、中台，大家常常会被交错复杂的业务逻辑、晦涩耦合的业务代码搞得心力交瘁。我想，大家对DDD的追求，也是对轻松支撑业务发展的诉求，在探寻有没有合适的理论可以改善现状。毕竟，美好生活，共同向往。</p><p></p><p></p><h2>2.1 现状：分层支撑机制</h2><p></p><p></p><p>我们选择各种框架、进行各种组织设计，核心是为了提高生产效率。但如果业务逻辑都是case by case地进行实现、缺少复用，那么研发成本是非常高的、投入周期也会非常长。</p><p></p><p>为了增加复用、缩短业务的落地时间，就需要很多通用的能力、产品。在我们的交付过程中，主要有两个层次：</p><p></p><p>基础能力：相对原子的能力是基础（域）能力，这个可以较好地支持业务定制。由于比较基础，表达的产品能力范围也是很大的。但是，一个完善的产品需要串联的基础能力是非常多的，串联的成本也是非常高的。</p><p></p><p>平台产品：基础能力的通用性，意味着缺少对场景的理解，缺少了进一步提升生产效率的“基因”。所以在交付的时候，会基于一些高频场景进行抽象，形成平台的产品能力，争取做到“拆箱即用”。业务基于“平台产品”这层进行定制的时候，理解成本会大大减少。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ce/ce3a0be6d8e3f8a7431af5a1382a8be1.png\" /></p><p>分层支撑框架</p><p></p><p></p><h2>2.2 腐化：业务逻辑渗透</h2><p></p><p></p><p>这样的层次，看上去很美好：在起步阶段，由于缺少历史包袱，的确可以提升一定的生产效率，这是能力本身的收益。但是，越往后，随着业务接入的增多，业务之间开始互相影响，研发的阻力也越来越大。</p><p></p><p>研发效能降低的重要原因在于：更多的时候，我们还是按照“业务能跑起来，怎么快怎么来“的逻辑去做相关工作，遇水搭桥，遇山开洞，然后直达目的地，进行信息的传达、数据库字段的操作。</p><p></p><p>这样的过程，违背了我们”希望通过业务场景，丰富平台能力，同时保证内核干净“的初衷。能力应该是基于相对多的用例、相对完善的思考进行抽象，是横向统一看，有更深刻的理解，但是垂直的交付，让我们更加纵向地处理问题，往往只是“窥探”了链路，在交付时长和业务节点的限制下，很难想得更加全面、深刻，难以做出更通用的设计。</p><p></p><p></p><h2>2.3 抵御：平台框架守卫</h2><p></p><p></p><p>那么，为什么关注DDD？如果说DDD直击了软件复杂度的核心——“问题域”，那可能还是比较抽象。具体来说，因为这的确符合我们追求的价值观【提升长期的生产效率】：</p><p></p><p>细分领域，培养专业的人、事：因为DDD的核心是要求让各个领域做好理解和封装，把一个业务需求拆解、安放在各自合理的地方，通过这样的分解与沉淀，保证了领域的输入，能够得到长期可持续的发展，形成竞争力。</p><p></p><p>机制保障，不依赖易变的事物：DDD其实在总结很多通用的技巧和经验，能够让这样的实施更具有确定性。无论是聚合根对领域实体的管控能力、限界上下文的交互策略、领域内核的抽象地位...等等，一旦选择尊奉，确定下来，就能够落在代码结构、组织关系、团队文档中，形成共识，不会因为人员等因素的变化而剧烈波动。</p><p></p><p>对DDD的关注，可以类比于我们对“工匠精神”的关注，对DDD的重视，也是我们对业务理解的重视。贴近业务，更要理解业务，不仅要理解业务，更需要理解大多数的业务。这样的追求，让我们往上看了一个层次，回归了最本质的问题：我们要解决什么问题？如何能够解决得更好？</p><p></p><p></p><h1>三、学习DDD的困难</h1><p></p><p></p><p>不知道大家是否有这样困惑：DDD的学习过程好像是”大海捞针“的过程。即使能够捞到点东西，使用起来，还是会有种“东施效颦”的感觉，并不是很自然。为什么学习DDD那么困难呢？</p><p></p><p></p><h2>3.1 感受：不得其门</h2><p></p><p></p><p>论语中的下面这个场景，和我们的困惑是比较相似的：</p><p></p><p></p><blockquote>叔孙武叔语大夫于朝曰：“子贡贤于仲尼。” 子服景伯以告子贡，子贡曰：“譬之宫墙，赐之墙也及肩，窥见室家之好；夫子之墙数仞，不得其门而入，不见宗庙之美、百官之富。得其门者或寡矣，夫子之云不亦宜乎！”</blockquote><p></p><p></p><p>正如要感受到孔子达到的境界，自己的学问也需要有一定的积累。我们要感受到DDD的力量，自己本身就要成长到一定程度（如：经历了一些成功或者失败的设计，有自己的经验或者教训），才能形成共鸣和认同。</p><p></p><p>工作中，的确很少看到DDD的最佳实践。在复杂的业务面前，谁也没有勇气说，哪个软件结构是理想的设计：</p><p></p><p>因为这不是一个确定性的问题分解，你的设计会被放在显微镜下研究，总能找到各种反例。</p><p></p><p>而且，我们深知，最佳的实践，一定是做得足够的“软”，对扩展留有设计，能够随着业务发展而迭代，不是一个静态的结果。</p><p></p><p>因此，打开学习的大门不是几个案例就能一蹴而就的，需要结合我们自己的工作，慢慢累积、体会。</p><p></p><p></p><h2>3.2 困难：模式发散</h2><p></p><p></p><p>我们有一种困惑，到底怎么样算是DDD：</p><p></p><p>实践的个例，难以信服：当我们看到“DDD实践”的时候，可能会发问：这也算DDD？不就是一个正常的服务端框架与方案，也无法涵盖其它的场景或者部门系统。</p><p></p><p>抽象的理论，觉得空洞：当我们看到“抽象的DDD定义与策略”的时候，可能会发问：这也算DDD？不就是一些软件设计的共识，然后强加了一些名词定义，有些策略与我们手上的系统也并不匹配。</p><p></p><p>无论往抽象看，还是往具体实现看，都很难找到令人信服的理论与实践（能够有确定性的落地能力）。因为这不像23个设计模式那样，可以通过N个模版就能涵盖大多数的模式。</p><p></p><p>为什么不能产生特定的模式呢？可以结合下图进一步来看：</p><p></p><p>抽象理论：如同抽象的接口一样，“DDD理解”最上面的学习主要是理论定义，比如：聚合根、值对象、资源库、核心域、支撑域等各种定义，这些是易于理解掌握的。</p><p></p><p>通用实践：如同相对具体的抽象类一样，“DDD理解”中间层次是一些通用原则和技巧，比如：上下文的映射策略、架构的选择等。这些因素是确定的，但需要自主进行取舍与选择，并且需要与时俱进，增量的部分需要自己学习补充。</p><p></p><p>具体实践：如同具体的类实例一样，“DDD理解”中下面层次是一系列的具体实践，结合各自的业务场景，进行了不同因素的设计、取舍与补充。因为涉及的选项较多，造成最终的选择结果往往是发散的，令人感觉“千人千面”。</p><p></p><p>两者不同的地方是：</p><p></p><p>“代码抽象层次”中层次关系是比较明确的，且有约束。</p><p></p><p>“领域驱动理解层次”中无法提供明确的约束，都是多个策略的取舍、一些关键的建议。</p><p></p><p>因此，由于问题的抽象层次较高，各种策略的不确定性较高，很难在DDD中产生像“23个设计模式”那样精炼的模式。一定要有的话，也是一系列的模式，比较发散。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/25/256f5e9492bc367f8d0b93d4de8f60a4.png\" /></p><p>DDD理解层次的类比</p><p></p><p>因此，我们渐渐明白：DDD面向的是软件的“软”，涵盖方方面面。DDD的深入理解，需要“千锤百炼”后，才能明白那些深入简出的建议，才能体会那句“师傅领进门，修行靠个人”的箴言，才能感受到“众里寻他千百度，那人却在灯火阑珊处”的美妙瞬间。</p><p></p><p></p><h1>四、基于设计原则看DDD</h1><p></p><p></p><p>虽然DDD本身的实践可能千人千面，但是一些核心主题的思考应该是聚焦的，这些高频主题的理解，能让我们更好地进行设计，讨论的性价比也是较高的。接下来，会基于“6大设计原则”（solid 原则）为引子，去看看DDD中的一些关键理解。</p><p></p><p></p><h2>4.1 单一职责原则：领域划分</h2><p></p><p></p><p>单一职责是说：一个类应该只有一个发生变化的原因。职责的单一，可以更好地内聚，减少耦合，方便演化。</p><p></p><p>DDD里面的领域划分可以类比思考。对领域的划分，无论是按领域实体，还是按照功能模块，还是按照服务等划分，其实都想尽量保证领域的正交，能够独立演化和发展。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2e/2e76373f0a534cf988264f1c6d655539.png\" /></p><p>Single Responsibility Principle：单一职责原则</p><p></p><p>领域怎么切分比较合适？刚进入业务平台的时候，了解到领域切分是按“一个或多个实体对象”的边界来切分。这的确比较合理，因为领域的核心职责就是对领域实体进行管理。但这是果，还是因？在切分的时候，是因为我们有了对领域的判断，所以某些实体被分在一起比较合适；还是因为某些实体有明显边界，所以可以形成一个领域？就比如下面的图：</p><p></p><p>可以整体作为1个部分。可以按竖着的正、负切分2个部分：上面1个（红），下面2个（黄、绿）。可以按横轴的正、负切分2个部分：左边1个（黄），右边2个（红、绿）。可以切分成3个部分（红、黄、绿）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/22/2252b54afcfad1c1101444253f099cce.png\" /></p><p>聚类的例子</p><p></p><p>这的确引入深思。切分比较容易的时候，往往是因为已经有了行业的标准（如：电商系统有订单、支付、物流、库存等领域是比较合理的）。那行业的标准来自哪里？是来自于演化：</p><p></p><p>开始的时候，可能只是一个大交易，比如：支付开始的时候只是买卖双方自己协议，也不需要建模。</p><p></p><p>后面支付发展了，也就独立出来一个域。原来不需要专人维护，后面会渐渐拉出一个团队来承接相关研发。</p><p></p><p>所以，领域的演化和划分，很类似“启发式算法”（一个基于直观或经验构造的算法，在可接受的花费下给出待解决组合优化问题每一个实例的一个可行解）：</p><p></p><p>初始化：按照的经验初步的划分，也可以是行业标准（没有行业标准的时候，就只能靠经验了）。花费评价：生产、交付过程的人力成本度量，关注理解成本、开发效率、系统稳定性、运维成本等因素。更优解：在业务发展过程中，计算花费评价，分析影响评价的“好因素”、“坏因素”，进行进一步调整。</p><p></p><p>往往到最后，我们会发现：</p><p></p><p>调整的内容：其实是匹配生产关系。调整的原则：追求职责的内聚，精细化分工。不断调整的原因：业务在发展，内聚的标准也需要与时俱进。</p><p></p><p>此外，从关联的角度看，往往我们看组织架构，就能看到领域的边界，核心原因还是组织架构也是要适应生产关系，follow更优解的结构，是相辅相成的，也就能互相窥探。</p><p></p><p></p><h2>4.2 开闭原则：实体行为</h2><p></p><p></p><p>开闭原则是说：软件中的对象（类、模块、函数等）应该对于扩展是开放的，但是对于修改是封闭的。也就是说，对扩展区块是要有设计的，扩展的部分不应该影响稳定逻辑。</p><p></p><p>在DDD中，实体的行为，在保证对外封闭的情况下，也是需要考虑扩展能力的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/05/05c0f30f84120c0a80fef91c4241e3c6.png\" /></p><p>Open Closed Principle：开闭原则</p><p></p><p>在刚开始学习DDD的时候，我们可能会强行把一些逻辑放到实体中，进行控制和收敛。但后面随着业务的变化，会发现在实体中承担行为逻辑很难受：</p><p></p><p>影响较大：很难有勇气去频繁地修改一个核心类。过于集中：随着方法和逻辑的增多，实体越来越臃肿。场景较多：很多逻辑并不是正交的，不是if这样else那样的，充满着交集与叠加。</p><p></p><p>抛弃POJO的get、set，走向实体的丰富行为，让我们编写代码更加困难了么？其实，我们的烦恼来自于，太关注实体行为的收口，忽略了扩展的设计：</p><p></p><p>原来get set写法很舒服的本质在于，很多的扩展被放在了业务脚本中，业务脚本虽然千疮百孔，但是是在应用层，远离核心逻辑。底层模型、通用组件等基础逻辑还是比较干净的。</p><p></p><p>应用DDD的时候，把一些行为下沉到领域层之后，也是要考虑扩展的。如果只关注收口，不关注扩展，那的确是“画地为牢”、“捡了籽麻，丢了西瓜”。</p><p></p><p>但是，要突破这一个困境，能够在实体行为中设计扩展，其实要有这样的认同：要往上看一个层次，就是实体行为的表达，不一定只有一个类完成，可以通过策略模式等方式的路由，由一个模块中的一些类进行完成，只要对外有封装和管控就可以。</p><p></p><p>突破一个类的限制，走向更多的类的协作设计，也是我们进阶的方向。</p><p></p><p></p><h2>4.3 里氏替换原则：资源库</h2><p></p><p></p><p>里氏代换原则是说：任何基类可以出现的地方，子类一定可以出现。讲究的是合理的抽象和复用。引人深思的一个例子是：正方形是特殊的长方形，正方形如果作为长方形的子类，那么当设置长度的时候就会出现冲突，长方形的长和宽可以独立设置，正方形的长和宽是有约束的，使用继承的关系就比较别扭。</p><p></p><p>在DDD中，关于可替代性，想聊一聊资源库。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4d/4d899e2f482f892711da2b25ff371721.png\" /></p><p>Liskov Substitution Principle：里氏替换原则</p><p></p><p>资源库的替代性需求</p><p></p><p>在原来的分层的架构中，数据库等存储能力作为一种底层基础设施，是被视为稳定的下层服务的。但在实际的交付过程中，往往要遇到不同场景：</p><p></p><p>本地部署：线下零售交易为了服务稳定性，期望可以具备本地保存数据的能力。</p><p></p><p>云上产品：售卖给外部企业的交易产品，成本的要求也不尽相同，期望在云上采购不同的存储服务。</p><p></p><p>这些场景，让大家逐渐深信：当面向更广阔的市场，基础设施也是充满着不确定性，需要具备可替换的能力。</p><p></p><p>存储实现间的复用策略</p><p></p><p>在具体实现的过程中，并不是每个领域都会独立部署，有些领域因为组织、性能的因素会一起部署。往往这些领域的代码也是在一个项目模块中的。出于横向效率的考虑，会设计统一的存储框架。</p><p></p><p>不同设施的存储能力不同，但整个存储流程又是类似的（协议转换，存储语句生成、执行与事务，返回结果），这样在不同存储能力的过程复用方式上需要进行取舍（数据库、Tair等是分开抽象还是统一抽象）：</p><p></p><p>如果“大一统”为主，那么针对关系型存储、KV存储等不同存储进行抽象的时候，就会和“长方形与正方形的问题”一样犹豫：</p><p></p><p>收益：如果你长期维护，了解里面的特殊性，的确是可以省略一些主体代码，提高开发效率。</p><p></p><p>代价：但大多数人要做扩展的时候，会感到很多不解，有很多本不需要的适配，充满迷惑。</p><p></p><p>如果以组合为主，那么可以通过多套模版，更好地进行自主选择。这样分而治之，减少了大家的理解成本，也能独立演化，更能适合存储的能力特性。但是需要沉淀多套理解，往往也缺少人力支持。</p><p></p><p>我想，“基于不同的存储能力，设计不同的模版框架” 应该是首选。大一统的抽象，开始时，人力成本可能低一点，但因为抽象层次较高，在理解与维护上将是一个“人力成本黑洞”，随着时间的推移，会降低整体收益，长期看是得不偿失的。反之，不同的模版复用，最终可以获得更好的整体收益。</p><p></p><p></p><h2>4.4 迪米特法则：领域协作</h2><p></p><p></p><p>迪米特法则，又称最小知识原则，是说：一个软件实体应当尽可能少的与其他实体发生相互作用。应该和一些“关键类”进行沟通。</p><p></p><p>DDD里面，领域间的协作，也需要相关的规划和设计。如果对领域之间的相互调用不做管理，那么链路关系会膨胀到难以理解的地步。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d2/d2c732bbede4e553a5ba5520d2bacb64.png\" /></p><p>Law of Demeter：迪米特法则</p><p></p><p>设计模式中，无论是中介者模式，还是外观模式，都希望通过集中管理，让多对多的复杂关系，简化为多对一、一对多这样易于理解的结构。类似的，在领域协作与对外交付的过程中，往往可以增加一个协调层，去串联各个域的交互。这样即可以降低各域的协作成本，也可以降低外部的理解成本，有更好的研发体验。</p><p></p><p>协调层该如何产生？好比上课：虽然老师可以教，但是老师不在时，可以指定学生代理上课。学生虽然可以干，但教学技巧并不熟练，自己本身还有学习的职责，角色也很尴尬。下面将讨论一下协调层和域的角色关系。</p><p></p><p>域能否成为协调层</p><p></p><p>比较值得讨论的是交易里面“交易域”、“订单域”这样的概念：</p><p></p><p>“交易域”看上去是负责整个交易过程，可以协调各个域，逻辑上比较合适成为协调者，但是主要还是在管理订单，其它赋予的协调能力，这部分并没有领域实体。</p><p></p><p>“订单域”看上去只是负责订单本身的服务，不太关心其他域，但是因为订单合约上有着所有合约信息（无论是直接还是间接持有），这意味着，“订单域”本身就有协调的潜力，只是职责看上去不够单一而已。</p><p></p><p>没有实体，为什么会有“交易域”一说，本人是这么理解的：在交易流程等可以强管控的情况下，把交易的API服务当做域服务（如：下单），“交易域”在逻辑上是有边界、可以成立的。但本质还是在管理订单，靠订单域成为了域，同时想沉淀协调能力。</p><p></p><p>协调层能否成为域</p><p></p><p>那么，如果订单的模型的管理不给交易管理呢，就是本人一直想的问题：如果没有自己的数据库实体，只有内存模型，纯粹靠对下游业务活动理解、数据流转的理解，能否成为一个域？</p><p></p><p>答案大概率可能是不行的：</p><p></p><p>逻辑上个人是认可纯靠理解作为一个域，毕竟知识本身也是一种资产。</p><p></p><p>但实际上，没有载体，就做不了特别多事情，包括状态记录，数据服务等，只能辅助，没有核心竞争力，难以生存下来。</p><p></p><p>协调者的角色，想要成为一个比较公认的“域”，必定要自己持有数据模型，或者借助基础域的一些数据模型，并享有管理的权限。</p><p></p><p>协调层的名称</p><p></p><p>无论是域想承担协调者的角色，还是协调者想发展成一个域，其实都不太符合职责单一的逻辑，但是这样“兼职”的现象却时常发生，核心还是开发人员角色的重叠。</p><p></p><p>既然协调层不太适合从域中选出，也不太适合成为一个域，那么介于业务活动、各个域能力之间的协调部分，应该称之为什么？目前看“商业能力”、“解决方案”这样的词汇都是比较合适的。</p><p></p><p></p><h2>4.5 接口隔离原则：业务活动</h2><p></p><p></p><p>接口隔离原则是说：客户端不应该依赖它不需要的接口。一个类对另一个类的依赖应该建立在最小的接口上。</p><p></p><p>DDD里面除了领域建设的学习，也需要关注应用层如何更好地承接业务请求，并研究业务逻辑分割的依据。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/99/9902f5d2f604377e5a62d8770c441712.png\" /></p><p>Interface Segregation Principle：接口隔离原则</p><p></p><p>没有规矩，难成方圆</p><p></p><p>之前在业务部门做业务的时候，并没有业务活动、流程等相关概念，往往是基于业务需求写业务脚本，经验的多少会影响代码的优雅。但除了经验，大家并没有比较好的结构框架、原则，去承接应用层的各种业务逻辑，因此也充满疑惑：</p><p></p><p>对外服务接口应该如何切分？类似服务之间是否可以共用流程？业务执行过程如何进一步结构化切分？......</p><p></p><p>没有规范的结果是，往往各有各的看法，谁都想立一套结构，谁也不服谁起的一套，各有各的代码区域。</p><p></p><p>平台的稳定框架</p><p></p><p>现在工作中，因为在平台，平台思考和治理的时间也比较久了，也有比较稳定的共识。整体的设计，在业务入口和业务入口之间、业务入口和稳定逻辑之间，预留了空间和扩展能力去承接场景化的逻辑，结构也比较确定：</p><p></p><p>入口按业务活动切分：服务入口按照业务活动扩展，核心理解并关注用例，什么角色要干什么事情。</p><p></p><p>流程独立承接与编排：业务活动在到达复用层（如：领域服务、外部服务、业务扩展）前保持独立，各自编排。</p><p></p><p>借助流程文件编排执行过程：将执行过程切分为执行节点，节点的切分可以以“功能点”、”涉及的域“、“涉及的实体“等为依据。节点间的共同能力下沉到基础能力中。</p><p></p><p>......</p><p></p><p>反复review形成共识</p><p></p><p>分而治之，缩小大家的关注点，更好地切分协作，这样的确很容易理解并接受。但是要保证合理的切分，还是要有统一的共识和原则。</p><p></p><p>往往一致的形成，不是先一致共识，再切分，而是初步沟通后就尝试切分，再review达成一致，在曲折中前进。如果大家的看法、冲突较大，那么这个共识达成的过程就相对较慢。好在，这种切分也不是时常发生，也就大需求、大重构的时候。此时，预留的研讨时间、开发资源也是充足的。</p><p></p><p></p><h2>4.6 依赖倒置原则：六边形架构</h2><p></p><p></p><p>依赖倒置原则是说：程序要依赖于抽象接口，不要依赖于具体实现。</p><p></p><p>DDD里面提到的六边形架构，也是进一步提升了抽象内核的地位，把领域建设作为架构的核心目标。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cd/cd3353a8dd214539c08d7213bb45fa85.png\" /></p><p>Dependence Inversion Principle：依赖倒置原则</p><p></p><p>以领域为中心，其实是一个比较重要的转变：</p><p></p><p>原来以分层架构为主：讲究按层次去看，尽量将能力下沉，进行更多工具复用，积累的是通用组件。</p><p></p><p>现在以领域为中心：讲究按抽象层次去看，尽量将理解融入到领域核心，进行更多“理解”复用，积累的是业务知识。</p><p></p><p>这样的转变，让我们有意识地将“领域理解”作为核心，形成行业竞争力，把“知识”作为资产进行售卖。</p><p></p><p>为了保证领域内核的抽象，需要定义好领域内核的边界，有两类接口：</p><p></p><p>对上游提供的能力：通过接口声明，说明能承担的职责，在领域内部进行实现支撑。</p><p></p><p>对下游的能力依赖：外部服务、业务扩展定制、存储服务都可以作为下游服务看待，通过接口声明服务依赖。</p><p></p><p>可以看到，领域内核与外部之间通过接口进行解耦。对于更基础的服务，会被视为和业务入口一样的外部端口，属于应用层。比如，存储服务：</p><p></p><p>原来更多的是基础能力：数据框架 + DO，不需要理解转换，转换在上游完成，DO也会作为核心模型被上游使用，在采用遵循模型策略的时候，上游完全使用DO作为核心对象进行流转。</p><p></p><p>现在可以理解为“业务组件“：需要实现领域的存储接口，承担协议转换，将领域对象转换为数据存储对象DO，DO也不会被领域直接理解，需要转换为领域对象再往外透，被领域内核定义了表现。</p><p></p><p>这样的架构，奠定了领域理解的抽象核心地位，让研发同学更加注重对业务问题的思考，建设更多“有血有肉”、“贴近业务核心问题”的软件，不仅仅是“基础骨架”，让我们更加走近客户的价值，是应对软件复杂性过程中，大家比较认可的方向。</p><p></p><p></p><h1>五、总结</h1><p></p><p></p><p>对DDD的追求，来自我们渴望优雅地解决各种业务问题，希望有一套框架可以引导我们去分解问题，得到稳定、高效的生产效率。</p><p></p><p>但是这好比对“永动机”的追求，是一个难以有肯定答案的过程。能够解决软件复杂性的方案，必定是结合相关场景并且不断演化的，单纯追求DDD是得不到“银弹”的。</p><p></p><p>不过正如对“永动机”的研究，能让我们关注能量的转换过程，可以引导我们制造出更加高效的能源机器。对DDD的研究与追捧，能够让我们更加关注对业务的深刻理解，可以引领我们写出更加易于扩展的代码实现。</p><p></p><p>我想，正是“业务的不断发展”、“软件的复杂性”的存在，才让编程充满了挑战，才让大家对框架的研究充满热情，这何尝不是一个美妙的事情。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/86/86ce96091c9071cd6ce9b0750517777a.png\" /></p><p></p>",
    "publish_time": "2023-02-09 11:25:18",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "2023，音视频技术将如何发展？",
    "url": "https://www.infoq.cn/article/b2Mf1ZM84Y27xsU2AOJu",
    "summary": "<p>过去三年， 人们的日常生活、工作方式发生了巨大改变，短视频、互动直播、在线教育、云上会议等音视频使用场景深入到各行各业。井喷的需求使音视频的传输方式也发生了许多改变。</p><p></p><p>回顾音视频技术的整体发展，我们将其总共分为三个阶段。第一阶段，音视频的传输方式粗暴简单，通过非模拟信号进行传输；第二阶段，音视频信号纯数字化，诞生了如 DVD、DVB 等一系列的存储传输方式，同时音视频技术延展出了编解码器 codec、存储冗余、流媒体传输等更多细分技术；第三阶段，随着硬件能力的提升和互联网的发展，音视频技术的发展更细分，如编解码器的技术演进、流媒体传输协议的技术演进等，播放方式也变得更加丰富，如点播、直播、超低延时直播、互动直播等。</p><p></p><p>整个音视频领域正朝着超高清、低延时、强互动等方向演进，处于为全真互联时代的到来做技术储备、更多场景覆盖的关键阶段。基于此，InfoQ 与腾讯云音视频高级工程师孙祥学进行了对话，一起讨论音视频技术在 2023 年的具体发展方向。</p><p></p><h2>一、追求极致的“低时延、强互动、超高清”</h2><p></p><p></p><p>5G 的快速落地，4K/8K 视频快速普及，元宇宙、AR、VR 等技术兴起，全真互联时代来临，\"低时延、强互动、超高清\"的音视频能力越来越受到行业内的关注，这对原有的媒体处理系统发起了新挑战。</p><p></p><p>4K/8K 超高清通常需要几十兆，甚至上百兆的码率，带来了高昂的存储和带宽成本。同时，超高分辨率对媒体处理系统也提出了新的要求，尤其是对于直播系统，相比 1080P，8K 视频的分辨率实时转码对算力的要求提高了十几倍。此外，虽然超高清播放设备得到了广泛的普及，但是目前超高清的片源并不多，如何生成超高清的片源视频也是行业的绝对痛点。</p><p></p><p>想要解决这些技术挑战，这就意味着媒体处理产品需要提供性能领先的编码内核，在压缩率上帮助产品降低成本，从而提升终端用户的观看体验。通过分布式来解决单机难以完成的实时 8K 高算力视频处理，所以媒体处理产品对系统的处理能力要做到能够池化。除此之外，媒体处理产品还需要有全面的画质提升工具，包括但不限于去噪、去伪影、HDR、超分、插帧等画质修复能力，来满足用户对超高清画质的诉求。</p><p></p><p>为此，腾讯云媒体处理 MPS 在全球化 region 部署，自动扩缩容，可以灵活应对高并发转码需求。长视频支持最高 30 倍速分布式转码加速，满足极速转码发布需求。腾讯云媒体处理 MPS 的云端画质增强技术在云端进行视频超分来实现超高清的画质体验，解决了“移动端设备难以支持实时 4K/8K 采集”的问题。</p><p></p><p>值得一提的是，在低延时方面，腾讯云媒体处理 MPS 与腾讯云音视频快直播（超低延时直播）结合，通过监测用户的并发情况，为用户实时自动拉起腾讯云媒体处理 MPS 极速高清智能转码相关服务，在降低延时的同时为用户减少带宽成本。腾讯云音视频的快直播是典型的媒体传输技术的升级与融合，其在延迟、秒开、抗性等指标上的大幅优化，极大提高了用户体验。这个技术的背后其实是深刻理解媒体传输特性前提下的融合优化，在信令、数据通道上，采用云端结合的优化方式，并充分理解传输的媒体内容，最终实现“低时延”的目标。</p><p></p><p>另外行内人都知道，超高清的观看体验必然伴随着高码率，尤其当下终端用户对极致视听体验的追求，视频清晰度从高清到超高清，再到 4K/8K，<a href=\"https://www.infoq.cn/article/tPPZS0Ep8eltjvTdEG8N\">视频</a>\"存储越来越大，对带宽的要求也越来越高，用户的成本也越来越大，用户日益增长的观看体验追求和传输、存储成本之间的矛盾成为了音视频处理领域首先要解决的问题。</p><p></p><p>所以，腾讯内部优化了 O264/V265/TXAV1/O266 等编解码内核，在保持画质的前提下，极大地降低视频码率，减少超高清体验的带宽、存储等压力，而这些技术也都在腾讯云媒体处理 MPS 产品中有体现。腾讯云媒体处理 MPS 极速高清技术能够在保持视频画质质量不变的情况下，降 50%+ 的码率，减少视频传输存储成本。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dd/dd026cf3122644bbd2a125da7388384d.png\" /></p><p></p><p>腾讯云媒体处理 MPS 超高性能的编码算法，支持 8K 的 120FPS、144FPS 视频实时编码，融合超分辨率、HDR、拓宽色域等技术，为用户提供了极致清晰的观感。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1e/1e1f7a350f3c15c5da3f6e54921b301f.png\" /></p><p></p><p></p><h2>二、“AI 智能分析”缓解爆炸式增长的短视频管理需求</h2><p></p><p></p><p>最近几年，媒体传播热潮从图文向短视频进行跃迁，在短视频爆发和全民直播的风口下，视频量爆炸式增长，当越来越多人开始玩起短视频，短视频平台之间的博弈从单纯的视频发布逐渐转变为视频处理功能是否足够丰富、好玩且智能，与此同时，每日百万级短视频审核处理，也对传统媒资编目的视频管理工作带来了极大挑战。</p><p></p><p>为此，腾讯云媒体处理 MPS 支持自定义服务流程、音视频转码、音视频增强、视频截图、内容理解、审核、智能编辑等能力，开放丰富的模板配置能力，支持用户根据自身需求自定义配置。传统媒资编目通过该产品可以对海量媒体文件流程化处理，一站式完成转码、截图、水印等基本操作，集成事件回调机制，及时掌握任务进度。</p><p></p><p>其中，<a href=\"https://xie.infoq.cn/article/7384b640363c2699930866954\">腾讯云</a>\"媒体处理 MPS 提供的智能识别、智能分析等相关处理能力，能够通过 AI 对视频内容进行分析，自动提取出视频标签、分类、语音、文字等信息，相较于传统媒资编目效率更高且提取内容更丰富，极大地方便了视频的管理，用户能够基于标签快速检索关联视频，继而进行二次处理和推荐分发。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/39/397ce97ae5766fca33fa2b1a63f12355.png\" /></p><p></p><p>AI 在腾讯云媒体处理 MPS 中应用其实非常广泛，腾讯云媒体处理 MPS 的 AI 能力主要体现在三个方面：</p><p></p><p>第一，转码。在转码方面来看，腾讯云音视频团队应该是最早一批尝试 AI 智能编码的团队。比如腾讯云媒体处理 MPS 极速高清编码，他们根据视频场景识别出不同的视频分类，针对不同场景采用不同的编码参数，在不影响画质的情况下达到最优的压缩效果。同时，团队在前处理、后处理的优化方面也做了许多努力，这帮助腾讯云媒体处理 MPS 转码在 2020/2021 MSU 云端编码大赛获得 2020 全项最佳，2021 年的 15 项考量项中有 12 项为最佳，O264/V265 综合最佳，V265 MSU 连续 4 年行业领先。TXAV1 MSU2021 视频编码评测中取得综合指标第一，O266 4K@1FPS 赛道取得综合指标第一。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bd/bdb6a0ffec76603e446c0dd839f8b181.png\" /></p><p></p><p>MPS 媒体处理在 SLC 2022 内容自适应转码服务评测中取得综合评测方面全部最佳 (Excellent) ：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ed/edd65476fb3b7a3c0015fd661953d264.png\" /></p><p></p><p>据孙祥学介绍，腾讯云媒体处理 MPS 转码在落地一些 AI 增强效果（超分、画质增强、插帧、抠图、色彩增强等）的场景过程中曾经遇到过引擎算力消耗大、语言框架不统一、转码集成困难、上线周期长等问题，在腾讯云音视频的强力探索下，<a href=\"https://xie.infoq.cn/article/7384b640363c2699930866954\">腾讯云</a>\"媒体处理 MPS 通过 AI 算力池调度的通用解决方案很好的解决了这些问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/56/56c73f4756056b76c28ff42b59d75947.png\" /></p><p>&nbsp;MPS AI 算力池调度</p><p></p><p>腾讯云媒体处理 MPS AI 算力池调度通过统一的转码实例同机代理，很好地解耦了引擎和转码实例，既统一了直播转码、点播转码的集成方式，又做到了 CPU/GPU 资源隔离，使转码和引擎资源利用率相互不制约。同时，引擎的迭代更新也完全不依赖转码实例，能够高度解耦独立升级。横向扩充算法种类对转码实例透明，只需配置对应转码模版下发引擎类型即可。</p><p></p><p>第二，内容理解。腾讯云音视频团队集成了腾讯内部多维度的引擎算法，全方位挖掘视频内容，支持对视频进行视频分类、视频标签、视频封面提取、视频拆条、视频集锦、片头片尾识别、语音识别、文字识别、物体识别、帧标签识别等，充分理解视频内容。</p><p></p><p>第三，审核。腾讯云媒体处理 MPS 除了支持“黄暴”视频内容审核以外，腾讯云音视频团队还提出了视频质量审核的解决方案，可以智能检测视频画面中存在的抖动重影、模糊、低光照、过曝光、黑边、白边、黑屏、白屏、花屏、噪点、马赛克、二维码等多个异常场景，还可以自动检测视频无音频异常、无声音片段。</p><p></p><p>此外，腾讯云媒体处理 MPS 拥有业界领先的视频 AI 技术，支持老片修复 / 标准转高清 / 高清转 4K 的能力，能够大幅祛除视频噪声、毛刺、划痕，能够大幅提升视频清晰度和色彩丰富度。这对于有视频处理需求的终端用户来说，是一个实用价值很高的功能。</p><p></p><h2>三、大幅降低“音视频媒体处理”门槛</h2><p></p><p></p><p>行业里对媒体处理 MPS 的标准定义是一种多媒体音视频数据处理服务，致力于通过经济、弹性和高可扩展的转换方法，将存储于 OBS 上的音视频转码为适应各种终端播放的格式，提供极致编码能力的同时，大幅节约存储及带宽成本，并实现音视频增强、内容理解、内容审核等功能，满足多样化的业务场景下的视频处理需求。换言之，媒体处理 MPS 的终极目标是“满足业务的视频处理需求”。</p><p></p><p>于是，当音视频技术的发展走到追求极致的“低时延、强互动、超高清”的这种程度，几乎所有云厂商当前都不再只关注转码速率、高清等技术的实现，在媒体处理系统的接入、易用性方面也投入了更多精力。</p><p>事实上，随着音视频技术的发展，媒体处理门槛高一直是用户对云厂商的“不满之处”。业内对于媒体处理产品的槽点很多，比如功能繁多，却无法快速验证；接入门槛高，对非技术背景用户不友好...云厂商们为了解决这些问题，想出了不少办法。比如腾讯云媒体处理 MPS 为提高产品的易用性，进行了 2.0 版本的升级，通过模版、任务编排的方式，可视化任务处理逻辑，使得用户零代码开发即可完成腾讯云媒体处理 MPS 的接入。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/42/420606389a9b80aefd719232f1be58de.png\" /></p><p></p><p>又比如，针对不同的行业，腾讯云媒体处理 MPS 提出了不同的解决方案。针对在线教育行业，腾讯云媒体处理 MPS 提供具有针对性的、强悍的视频转码功能，可以针对不同的终端生成对应规格的视频，满足在线教育行业多端播放的要求；针对广电行业，腾讯云媒体处理 MPS 具备高速稳定的分片转码系统，支持多任务并发进行和动态扩容，满足广电行业对转码效率的需求；针对 OTT 智能电视领域，媒体处理支持 4K 和 8K 转码，满足智能电视的超清需求等等。</p><p></p><p>另外，腾讯云媒体处理 MPS 在产品层面，除了在不断优化迭代公有云的用户体验外，目前也陆续上线了专有云版本（包括转码 SDK 和 PaaS 平台），其可以私有化部署到用户机房或者第三方云上，全方位满足用户使用场景。在公有云方面，腾讯云音视频团队也正在尝试打通第三方云，支持通过 MPS 控制台配置走内网处理媒体文件存储在第三方云上的用户资源。多云灵活部署，最大程度地降低了用户接入门槛。3 月初即将上线的腾讯云媒体处理 MPS v3.0 版本中会有相关技术优化的体现，大家可以关注一下。</p><p></p><h2>四、写在最后</h2><p></p><p></p><p>总体来说，我们站在宏观视角去看整个音视频领域的发展，其实主要就分为两个部分。</p><p></p><p>从互联网行业的流量来看，将近 84% 的内容都是音视频，面对流量的增长，进一步优化 codec 能力来降低存储和带宽成本、优化产品运营，同时减少编码算力的消耗，是所有提供媒体处理 MPS 服务的云厂商都需要关注且持续探索的问题。</p><p></p><p>从全真互联这个层面看，音视频未来在各行各业的应用占比一定会进一步提升，随之而来是各种终端设备的接入，优化音视频标准和传输协议来适配海量的终端设备，也是未来的关注重点。随着元宇宙、VR 等技术的不断演进和兴起，音视频对实时互动、低延时有了更高的要求，低延时的标准协议，尤其是 WebRTC 将会有更快的发展。</p><p></p><p>但无论怎么看，未来几年，音视频技术的发展都是互联网技术发展的重头戏，云厂商是否能够抢占未来的音视频市场，就看是否能够精准抓住用户需求，是否能够在细分技术上做出新突破，就让我们一起持续关注腾讯云音视频等厂商的技术探索和优化动作。</p>",
    "publish_time": "2023-02-09 13:45:37",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Zoom全球裁员，中国区赔偿N+4，网友：领导层的愚蠢让员工买单",
    "url": "https://www.infoq.cn/article/6gqyyO1jGOhCKsWEiKBS",
    "summary": "<p></p><blockquote>裁员潮一轮又一轮，领导层犯错，买单的只有基层员工？</blockquote><p></p><p></p><h2>Zoom宣布裁员1300人，占全球员工的15%</h2><p></p><p></p><p>2月7日，视频会议应用公司<a href=\"https://www.infoq.cn/article/lRRMRzou5ShfEiYpSNKp\">Zoom</a>\"创始人兼CEO袁征在Zoom博客上发表了一篇致员工的公开信，宣布公司计划裁员1300人，占到全球员工的15%。</p><p></p><p>袁征在公开信中表示，建立 Zoom 是为了消除企业在合作时感受到的摩擦，疫情改变了 Zoom 的发展轨迹，为了实现目标，公司需要迅速配备人员，以支持Zoom平台上用户的快速增长以及他们不断变化的需求。在 24 个月内，Zoom 的规模扩大了 3 倍。</p><p></p><p>但在这个过程中，Zoom 也犯下了错误：公司没有花足够的时间来全面分析团队，或评估是否在朝着最高优先级可持续发展。袁征认为，虽然用户和企业在后疫情时代的生活中仍在依赖Zoom，但“全球经济的不确定性”已经成为现实问题。Zoom 需要认真地重新审视自己，以便公司能够度过经济环境，为客户提供服务并实现 Zoom 的长期愿景。</p><p></p><p>作为 Zoom 的首席执行官和创始人，袁征表示自己对这些错误和当前采取的裁员行动负责——将下一个财政年度的薪水减少 98%，并放弃 23 财年公司奖金。此外， Zoom 的执行领导团队的成员将在下一个财政年度将他们的基本工资降低 20%，同时也将没收他们的 23 财年公司奖金。</p><p></p><p>与Salesforce、微软和Workday等企业软件厂商公布的裁员计划相比，Zoom的裁员举措占比更大，也可以说是下手更狠。消息一出，公司股票旋即上涨9.9%，收于84.66美元，创最近三个月来最大单日涨幅。但目前的价格仍较2020年10月的历史最高位暴跌达85%，与新冠疫情爆发之前基本持平。</p><p></p><p>Zoom财务报告显示，过去两个季度公司的收入仍保持着个位数增长。但分析师预计，Zoom本季度销售额将继续放缓，而本次裁员可能就是要在增长无力的情况下保持或提高利润率。</p><p></p><h2>中国区赔偿N+4</h2><p></p><p></p><p>本次Zoom大裁员，中国区亦受到波及。</p><p></p><p>Zoom 由中国移民袁征创办，总部位于美国加州，是一家美国本土公司。2013年，Zoom进入中国。2020年8 月，Zoom 在<a href=\"https://www.infoq.cn/article/zTyeHcfM*6jMjBCYNK4J\">中国市场</a>\"“大撤退”——Zoom 在中国大陆将只保留一种销售模式：通过合作伙伴销售，即会畅 Bizconf、随锐瞩目以及尚阳 Umeet 三家公司，此前的直接销售、在线订阅等方式将全部取消。</p><p></p><p>据悉，目前Zoom在中国共有四家子公司，分别位于杭州、苏州、合肥和上海。据界面新闻报道，当前Zoom中国区的岗位以技术、产品开发人员为主，此次在全球裁员中大部分受到波及。多名在职、离职的员工表示，杭州、苏州、合肥子公司都已启动裁员，上海暂时未知。</p><p></p><p>据界面新闻报道，关于Zoom中国区的裁员政策，经不同城市子公司的多名员工确认，赔偿方案为“N+4”（N为工作年数兑换成月，再加四个月的工资），员工持有的限制性股票期权到今年8月9日解禁。该套方案在办理离职时已经与人事部门确认。</p><p></p><p>据悉，2020年1月下旬，Zoom的员工总数约为2500人。之后几年间，Zoom又招纳了约6000人。经历本次洗牌，Zoom的员工数量将恢复到2022年初时的水平。</p><p></p><p>Zoom公司在一份监管文件中表示，截至今年4月的本季度运营成本预计在5000万至6800万美元之间，其中大部分是裁员带来的遣散费用。</p><p></p><h2>CEO犯错，员工首当其冲？</h2><p></p><p></p><p>去年以来，包括谷歌、Meta、亚马逊等多家科技公司“大裁员”。在裁员公告中，几乎每家科技公司都将裁员归咎于经济原因。有网友认为，在许多情况下，这些公司走向裁员的真正原因是公司领导层做出的愚蠢决定。</p><p></p><p>比如扎克伯格曾在疫情期间授权疯狂招聘狂潮，并向他的元宇宙投资数十亿美元，之后又不得不裁员 11000；Shopify 的创始人 Tobi Lütke 裁员 1000 人，是因为他对电子商务未来的赌注“没有回报”。</p><p></p><p>而这些公司裁撤的大部分岗位是基础技术岗位，鲜少有高管出面为公司裁员负责。这也引发了普通员工的不满：普通技术人员首当其冲地承受着公司错误决定带来的冲击，而对这些混乱负有最大责任的高管几乎或完全没有承担任何有意义的责任。</p><p></p><p>本次 Zoom 裁员，CEO袁征承认自己对公司发展判断失误，自愿降薪98%。这或许为其他裁员的科技公司树起了新的标杆。</p><p></p><p>无独有偶，稍早前，英特尔高管也开启了大规模<a href=\"https://www.infoq.cn/article/vsoNmp3DK0zVwtpGiBe9\">降薪潮</a>\"。</p><p></p><p>2 月 1 日，据《华尔街日报》报道，在几天前公布的季度财报中，英特尔的收益增长不及分析师们的预期，英特尔表示将全面削减管理层薪酬，以节约资金用于扭亏计划。</p><p></p><p>其中，英特尔公司 CEO Pat Gelsinger 的基本薪资将下调 25%，最高行政领导团队的薪资将下调 15%，高层管理人员减薪 10%，中层管理人员减薪 5%，小时工和公司体系中 7 级以下的员工不会受到影响。</p><p></p><p>据悉，英特尔力争今年削减 30 亿美元成本，并且到 2025 年底，通过成本节约和效率提高举措使年度节支规模增至 100 亿美元，这些措施中包括裁员。英特尔稍早前表示，仍在朝着这个目标前进。</p><p></p><p>随着越来越多的公司意识到裁员问题的根源，“CEO犯错，员工买单”的现象或将得到缓解。</p>",
    "publish_time": "2023-02-09 14:27:04",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]