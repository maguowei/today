[
  {
    "title": "开放式湖仓是湖仓一体架构的最终归宿",
    "url": "https://www.infoq.cn/article/N8D436ZU9qV1UySeIqCw",
    "summary": "<p>随着 Data+AI 技术的快速演进迭代，湖仓一体架构（Lakehouse）已经成为当前数据平台的事实标准。本文将简要概述数据平台的发展史，阐述湖仓架构产生的必然性。再从开放性的角度出发，探讨 Lakehouse 架构的选型，以及为什么开放式湖仓设计（Open Lakehouse）会是湖仓一体架构的最终归宿。</p><p></p><p></p><h2>湖仓一体的诞生</h2><p></p><p></p><p>我们先来看下湖仓一体架构出现之前，数据平台经过了怎样的发展。根据 CCSA TC601 大数据技术标准推进委员会发布的《湖仓一体技术与产业研究报告（2023 年）》显示，数据平台架构持续演进主要经历了数据库、数据仓库、数据湖三个阶段，它们各自都有明显的优缺点：</p><p></p><p>数据库（Database）：数据库诞生于 20 世纪 60 年代，它能够对结构化数据进行集中式的存储和计算，主要作为数据存储和计算的基础设施。数据库支持事务处理，可以确保数据的一致性和完整性。例如，企业可能使用 MySQL 或 Oracle 等关系型数据库管理系统来存储和查询结构化数据，如客户信息、订单记录等。传统数据库主要适用于结构化数据，对于半结构化和非结构化数据的存储和处理能力有限。另外，数据库在处理大规模数据时可能面临性能瓶颈和扩展困难，无法满足快速增长的数据需求。数据仓库（Data Warehouse）：随着数据量的增长和多样化数据类型的出现，在上世纪 90 年代数据仓库成为数据平台的主流架构。数据仓库具备规范性，能够集中存储和计算结构化数据。数据仓库通常采用星型或雪花型模型来组织数据，以支持复杂的分析查询。数据仓库可以帮助企业实现数据整合，进行在线分析处理（OLAP）和数据挖掘（Data Mining），从而辅助决策。例如，企业可能使用 Teradata、Amazon Redshift 和 Google BigQuery 等数据仓库解决方案来集中存储和分析销售数据、市场趋势等。然而，随着大数据技术的发展，数据仓库在处理非结构化数据、半结构化数据以及具有高多样性、高速度和高容量的数据方面表现出局限性。在数据仓库中，数据的加载和转换过程可能较为复杂，导致数据加载速度较慢。由于数据仓库的数据模型和索引设计，某些查询可能需要较长的时间才能返回结果。此外，数据仓库在处理来自不同数据源的数据时，需要进行数据集成和转换，这可能涉及到复杂的 ETL（抽取、转换和加载）过程。数据湖（Data Lake）：为了满足多种数据类型存储和多场景分析的需求，数据湖成为数据平台的另一种主流架构。它采用分布式存储来存储各种类型的数据，包括结构化、半结构化和非结构化数据，例如，企业可以 Amazon S3 等存储系统来存储各种数据源的原始数据，如日志文件、传感器数据、社交媒体数据等。数据湖提供了更大的灵活性和扩展性，使企业能够在需要时进行数据探索和分析。数据湖具有更好的扩展能力，能够灵活支持多种类型数据的高效取用，但不支持事务处理，数据质量难以保障。数据湖通常以原始数据的形式存储，缺乏严格的数据模式和约束，可能导致数据一致性和隔离性的问题。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e7/e7289dbf6e285bb298a6b41b3cb771fe\" /></p><p></p><p>既然数据仓库和数据湖有着非常明显的优缺点（见上表），就短暂地诞生过一种“湖仓混合”架构（见下图），企业将数据湖和数据仓库结合起来，以充分发挥它们各自的优势。例如，企业可以使用数据湖作为数据的原始存储和数据探索的平台，而将数据仓库用于数据集成、数据清洗和高性能的分析查询。但是，\"数据湖 + 数据仓库\"混合架构也有着明显的缺点：</p><p></p><p>架构复杂：混合架构需要同时管理数据湖和数据仓库，涉及到不同的数据存储和计算引擎，增加了架构的复杂性。开发运维难度大：混合架构需要维护和管理多个组件和系统，对开发人员和运维团队提出了更高的要求。成本高：混合架构的建设和维护成本较高，包括硬件设备、软件许可和人力资源等方面的投入。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/98/981a008e330f7d63fb38c9e2a8795aaf\" /></p><p></p><p>由于现有架构中的数据仓库和数据湖有着各种各样的问题，湖仓一体架构就应运而生了，接下来我们来看看什么是湖仓一体。</p><p></p><p></p><h2>湖仓一体是什么</h2><p></p><p></p><p>Databricks 公司在 CIDR 2021 发表论文首次正式提出了 Lakehouse 的概念 ，但实际上湖仓一体的概念并非由单一个体提出，而是随着技术的发展和需求的变化逐渐形成的，下图分别列举了国外主流厂商对 Lakehouse 的理解。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/97/9769899ad51027eb1e9d5f4a4e902c04\" /></p><p></p><p>与\"湖 + 仓\"混合架构简单地把数据湖和数据仓库进行简单的堆积不同，湖仓一体架构（Lakehouse）是一种新兴的数据架构，将数据湖和数据仓库的特点融合在一起。它旨在解决传统数据湖和数据仓库各自的局限性，并提供更强大的数据管理和分析能力。湖仓一体架构的特点如下：</p><p></p><p>统一数据存储：湖仓一体架构将结构化、半结构化和非结构化数据以原生格式存储在数据湖中。这种统一的数据存储方式消除了数据复制和转换的需求，简化了数据管理过程。事务支持：与传统的数据湖相比，湖仓一体架构提供了事务支持。它允许在数据湖中执行事务操作，如插入、更新和删除，确保数据的一致性和可靠性。数据质量和治理：湖仓一体架构注重数据质量和治理。它提供了数据血缘追踪、数据质量监控和数据访问控制等功能，确保数据的准确性、完整性和安全性。实时和批处理：湖仓一体架构支持实时和批处理数据处理。它可以处理实时数据流和大规模批量数据，并提供实时分析和即席查询的能力。弹性和可扩展性：湖仓一体架构具有弹性和可扩展性。它可以根据需求自动扩展计算和存储资源，以适应不断增长的数据量和变化的工作负载。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/4e/4ea605d39947cb762aca7c4e13d44207\" /></p><p></p><p>湖仓一体架构通过将数据湖和数据仓库的优势结合起来，提供了更灵活、可扩展和强大的数据管理和分析能力。它适用于各种数据场景，包括实时分析、机器学习、数据探索和报表等。</p><p></p><p>传统数据仓库和数据湖的老玩家，演进到湖仓一体架构有两个主要方向：一是“湖上建仓”，即在数据湖的基础上构建数据仓库，保留数据湖的灵活性和可扩展性，同时引入数据仓库的治理和分析能力，典型的例子是 Databricks 和开源 Hadoop 体系；二是“仓外挂湖”，即在数据仓库外部挂载数据湖，让数据湖成为数据仓库的一个数据源，以便企业更好地利用数据湖中的数据，典型的例子是 Amazon Redshift、Google BigQuery、阿里云 MaxCompute。由此可见，湖仓一体技术的发展，旨在融合数据湖和数据仓库的优势，形成一种更强大、灵活且易于管理的数据管理架构。通过湖仓一体，企业可以更好地处理和分析各种数据类型，实现数据价值的释放，因此湖仓一体架构已经成为当代大数据平台的事实标准。</p><p></p><p></p><h2>湖仓一体发展趋势</h2><p></p><p></p><p>随着用户场景和业务需求的不断变化，湖仓一体架构在发展过程中也出现了新的趋势。Dremio 在 2023 年发表的论文《The Data Lakehouse: Data Warehousing and More》中，提出 Lakehouse 是一个与具体实现无关的模块化湖仓一体架构：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f3/f3688029c8b0d6a85237ca33262d6bd2\" /></p><p></p><p>模块化的湖仓一体架构，核心模块包括以下几个方面：</p><p></p><p>数据存储（Data Storage）：使用云对象存储来保存原始数据文件，需要能够高效地存储大量来自不同来源的数据。存储引擎（Storage Engine）：负责处理数据管理任务，如数据压缩、重分区和索引等。存储引擎通过优化数据的组织方式，提高查询性能，并确保数据在云对象存储中的高效存储。文件格式（File Format）：它将原始数据以特定的格式存储在对象存储中。数据湖仓使用开放的文件格式（如 Apache Parquet、ORC 等），这些格式具有高效的压缩和查询性能，并且可以被不同的分析引擎使用。表格格式（Table Format）：表格格式是数据湖仓的一个重要组件，它在数据湖上添加了逻辑模型和可靠的数据治理。表格格式简化了数据文件的组织和管理，并提供了元数据管理和数据版本控制的功能。常见的表格格式包括 Apache Iceberg、Apache Hudi 和 Delta Lake 等。计算引擎（Compute Engine）：计算引擎负责处理数据操作和计算任务，它与表格格式进行交互，实现数据的查询、转换和分析等功能。Lakehouse 可以支持多种计算引擎，如 Apache Spark、Presto 等。元数据服务（Catalog）：用于管理数据湖中的表格信息和元数据，它跟踪每个表格的名称、模式和其他相关信息，提供了数据发现和搜索的功能。</p><p></p><p>模块化的设计让湖仓一体架构更加清晰和可解释，这个观点与 Voltron Data（开源项目 Apache Arrow 背后的商业公司）提出的 Composable Codex 不谋而合。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b9/b909eaee1d07473ff12c7cd18c10ee66\" /></p><p></p><p>Voltron Data 联合 Meta 和 Databricks 发表在 VLDB 23 上的论文《The Composable Data Management System Manifesto》指出，不仅模块化是数据系统的正确发展方向，基于开放标准和开源模块构建的数据系统才是未来，可以带来很多好处：</p><p></p><p>提高灵活性和可扩展性：模块化的设计可以将数据计算引擎拆分为多个组件，使得每个组件可以独立开发、维护和优化。这样可以提高系统的灵活性和可扩展性，使得引擎可以适应不同的工作负载和需求。促进互操作性：开放标准可以使不同的数据计算引擎之间实现互操作性，使得它们可以无缝地集成和协同工作。这样可以避免数据孤岛的问题，提高数据生态系统的整体效率和一致性。降低开发和维护成本：模块化的设计和开放标准可以促进组件的重用和共享，减少重复开发的工作量。同时，开放标准可以吸引更多的开发者和厂商参与，形成一个庞大的社区，共同推动引擎的发展和优化，从而降低开发和维护的成本。促进创新和进步：模块化的设计和开放标准可以为不同的开发者和厂商提供一个共同的平台，使他们可以自由地创新和实验新的功能和技术。这样可以推动数据计算引擎的不断进步，满足不断变化的需求和挑战。</p><p></p><p></p><h2>开放式湖仓才是未来</h2><p></p><p></p><p>传统数据仓库对用户最大的困扰是很容易被运营商锁定（Vendor Lock-in），通常有以下几个原因：</p><p></p><p>专有技术和格式：传统数据仓库通常使用特定厂商的专有技术和格式。这些技术和格式是特定厂商的商业机密，不公开或不兼容其他厂商的系统。因此，一旦选择了特定厂商的数据仓库解决方案，就会受到其技术和格式的限制，难以无缝地迁移到其他厂商的解决方案。另外，有一些开源项目使用了自有文件格式来存储数据，虽然源代码开源的，但其文件格式没办法被其他主流计算引擎理解，仍然不属于开放式的架构设计。闭源软件：传统数据仓库通常使用闭源的商业软件，用户无法查看或修改其内部实现细节。这意味着用户对软件的定制和扩展能力受到限制，只能依赖于特定厂商提供的功能和更新。依赖特定硬件和操作系统：传统数据仓库可能依赖于特定的硬件和操作系统。这意味着用户需要购买和维护特定的硬件设备，并且只能在特定的操作系统上运行数据仓库。这增加了用户的成本和依赖性，限制了他们在硬件和操作系统选择上的灵活性。高度集成的架构：传统数据仓库通常采用高度集成的架构，将数据存储、计算和查询等功能紧密耦合在一起。这使得用户难以将数据仓库的不同组件替换为其他厂商的解决方案，因为这些组件之间存在复杂的依赖关系。供应商锁定策略：一些数据仓库供应商可能采用锁定策略，通过限制用户的选择和迁移选项来维持其市场份额。这可能包括限制数据迁移工具、封闭的 API 接口、高昂的许可费用等。这使得用户难以切换到其他供应商的解决方案，从而导致供应商锁定。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/61/61b9318633cd7958d13a446452b8a880\" /></p><p></p><p>湖仓一体架构发展到今天，其最吸引人的一个特点就是就是数据开放性，这是因为其独特的模块化设计带来的：</p><p></p><p>数据格式的灵活性：Lakehouse 架构使用开放的数据格式，例如 Parquet、Avro 或 ORC，这些格式是通用的、开放的标准。这意味着数据可以以一种独立于特定供应商的方式存储和处理，而不会受到特定供应商的限制。这样，即使更换或切换供应商，数据仍然可以保持可访问和可用。开放的数据处理工具和技术：Lakehouse 架构支持使用各种开放的数据处理工具和技术，例如 Apache Spark、Apache Hive、Presto 等。这些工具和技术是开源的，可以在不同的供应商之间进行迁移和切换。这样，即使更换供应商，组织可以继续使用相同的数据处理工具和技术，而不需要重新学习或更换整个技术栈。数据所有权和控制：在 Lakehouse 架构中，数据湖是组织自己拥有和控制的。这意味着组织可以自由地管理和操作数据，而不受运营商的限制。即使切换供应商，组织仍然可以保持对数据的完全控制，并且可以根据需要进行数据迁移或复制。多云和混合云支持：Lakehouse 架构可以在多个云提供商之间进行部署，或者与本地数据中心进行混合部署。这种灵活性使得组织可以根据需求选择最适合的云提供商，而不会受到单一供应商的限制。这样，即使更换或切换云提供商，数据仍然可以保持可访问和可用。</p><p></p><p>值得一提的是，有些厂商声称自己是“开放式”湖仓一体架构，但所谓的“开放”实际是存算分离架构的“开放”，其实是与开放式湖仓一体混为一谈。存算分离是一种大数据处理架构，它将存储和计算节点分开，数据节点负责数据的存储和管理，而计算任务则由单独的计算节点来负责执行。相对于传统的存算一体架构，存算分离架构设计使得系统能够扩展到更大规模的并发能力和数据容量。相较于湖仓一体架构的开放数据设计，存算一体架构只是把数据放在了存储节点上，并没有保证数据的开放性（如使用开源表格式 Apache Iceberg，或者开源文件格式 Apache Parquet 等），因此并不能认为存算分离架构也是开放的。</p><p></p><p>随着人工智能（AI）和大语言模型（LLM）的热潮，AI 给数据平台带来新的挑战：AI 需要更丰富的数据，数据需要更多样的 BI+AI 应用。Data 与 AI 的关系不再是 Data+AI，而是 Data*AI ——数据平台不再是一对一的计算和存储架构，而是 m 对 n 关系的架构。这样的架构改变变化下，数据平台的架构更应有兼具一体化与开放性的设计。开放式湖仓一体架构，是面向 Data+AI 融合场景的新趋势。</p><p></p><p></p><h2>云器开放式湖仓的设计理念</h2><p></p><p></p><p>我们（云器科技）是一家新兴的数据平台服务提供商，主打多云及一体化的数据平台服务。我们依照 Open Lakehouse 的设计理念，实现了一套完整的系统，并服务多家头部客户。存储层设计兼容各种主流的开放存储格式，确保与广泛的数据环境的无缝集成：</p><p></p><p>开放元数据服务：采用 Catalog 形式开放，增强数据管理的灵活性和可访问性。安全的数据访问：保障数据安全的同时，通过身份认证和鉴权机制，允许外部引擎访问云器 Lakehouse 中的数据文件。统一安全策略与开放性结合：结合统一的安全策略与开放性，借助丰富的开源生态系统，最大化地释放企业数据的潜在价值。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a1/a18d792fe769d2c3f528992de96659a8\" /></p><p></p><p>文章前半部分讲述了 Open Lakehouse 的架构优势、设计目标和原则。文章后半部分，重点介绍我们在实现过程中的设计、取舍和经验总结。</p><p></p><p></p><h2>云器开放式湖仓的设计实践</h2><p></p><p></p><p></p><h4>拥抱 Apache Iceberg 打造开放生态</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/00/00b3424bf9adef82ed45ba2c91e87ba9\" /></p><p></p><p>Apache Iceberg、Apache Hudi 和 Delta Lake 是当前数据湖领域中的三种主要表格式，它们都在努力成为数据湖的标准表格式，这种竞争有时被形象地称为\"Table Format War\"。这三种表格式都是开源的，拥有非常好的生态，背后都有一个商业公司在支持。云器认为重复再造一个新的表格式的轮子并不能让 Lakehouse 更加地开放，因此选择一个最合适的表格式，围绕它构建 Lakehouse 的内置表格式，打造一个开放的生态是对用户最负责任的方案。</p><p></p><p></p><h5>为什么是 Apache Iceberg</h5><p></p><p></p><p>来自 Tabular（Apache Iceberg 背后的商业公司）的 Brian Olsen 在 2023 年 7 月发表了一篇文章 Iceberg won the table format war，他认为 Apache Iceberg 已经在这场表格式的竞争中取得了胜利。其观点基本符合我们的看法，也是云器科技选择使用 Apache Iceberg 作为开放存储底座的原因：</p><p></p><p>从技术角度来说，Apache Iceberg 是第一个跳出了 Hive 标准（比如 Hive 分区）限制的表格式，相对于 Apache Hudi 来说没有主键约束，通过 Hidden Partition 的设计支持 Partition Evolution 这种高级功能。这种设计使得使用方有更大的定制空间，支持更丰富的场景。从标准角度来说，Apache Iceberg 首先就制定了一套简单、清晰的标准，然后才提供各种引擎下的实现。Apache Hudi 实现太过复杂，并且非常依赖 JVM 生态。Delta Lake 开源版本相比 Databricks 内部版本有很多滞后性，与 Apache Spark 框架绑定也比较深。有了一个简洁的标准，用户和厂商既可以选择使用官方开源实现，也可以根据自己的需求开发一套完全兼容的实现，这正是一个开放的标准所带来的好处。从生态角度来说，Dremio 很早就选择了 Apache Iceberg 作为其完全开源的 Open Lakehouse 底座。像 Snowflake 这种起初期望用其私有格式抢占市场的大玩家，也支持了 Apache Iceberg 作为可选的内置存储格式，并且性能与内置格式相差无几。甚至像 Databricks 和 Onehouse（Apache Hudi 背后的商业公司）这样的直接竞争对手，也分别通过 Delta Uniserval Format 和 Hudi OneTable 的机制，输出 Apache Iceberg 兼容格式。选择 Apache Iceberg 能更好地避免被运营商绑定的风险，保护用户的数据。</p><p></p><p></p><h5>如何基于 Apache Iceberg 构建通用的增量存储</h5><p></p><p></p><p>云器 Lakehouse 使用 Apache Iceberg 表格式，以及 Apache Parquet 文件格式，打造了一个能够实时兼容 Apache Iceberg 标准的存储文件布局，其元数据通过完全兼容 Iceberg 的 catalog 进行输出，天然兼容所有支持消费 Apache Iceberg 的开源框架，如 Apache Spark 和 Trino 等。由于所有云器 Lakehouse 内表输出的数据文件都是以 Apache Parquet 格式存放在云对象存储上，元数据完全兼容 Apache Iceberg，用户真正拥有自己的数据资产，无需担心 Lock-in 的风险。</p><p></p><p>前面提到过增量计算模式依赖增量存储，这也是通过 Apache Iceberg 实现的。具体来说，基于 Snapshot Isolation 使用 Apache Iceberg V2 标准引入的 Position Delete File 来表示增量数据。由于 Position Delete File 只能表示数据的删除，我们需要把 Update 拆分成经典的 Delete+Insert 模式，这样的设计对数据有三个挑战：</p><p></p><p>Freshness：代表数据进入 Lakehouse 的新鲜度，即数据写入湖仓之后多久可见。为了让数据尽快可见，我们设计了单独的 Ingestion Service 服务，根据不同的表类型，兼顾性能和成本使用最优的方式把数据灌入湖仓。Latency：代表数据的查询性能，也就是查询湖仓中的数据要多久才能出结果。由于数据文件都保存在云对象存储上，我们设计了 Shared-Everything 的分层 Cache 服务，根据数据的冷热以及访问模式，自动将文件中的数据放到最合适的 Cache 中，加快查询速度。Performance：增量计算的间隔越短，就会以增量存储的方式引入越多的小文件，这对后续查询的性能会带来影响。同时，用户的数据和访问模式后续都可能会动态变化，我们需要能够识别并给出存储文件排布的最佳方案。因此，写入增量存储的时候，我们可以根据需要，自动选择以 Copy-on-Write 或者 Merge-on-Read 的方式产生数据文件。同时，在后台使用单独的 Compaction 服务，根据 Lakehouse 搜集到的信息进行文件的重排布，以节省成本，优化查询性能。</p><p></p><p></p><h4>围绕 Apache Parquet 锤炼极致性能</h4><p></p><p></p><p>对于 Lakehouse 的引擎来说，一个 SQL 查询始于读（TableScan）终于写（TableSink）。如果说开放的表格式决定了 Lakehouse 的能力下限，那合适的文件格式则可以决定 Lakehouse 的性能上限。在大数据领域，Apache Parquet 和 Apache Orc 基本就是列存格式的实施标准。两者曾一度各占半壁江山，但现在就像 DuckDB 作者 Hannes 回答社区问题时说的，似乎 Apache Orc 已经被用得越来越少了。那在 Apache Parquet 越来越独领风骚的今天，是不是无脑选择它就能高枕无忧了？</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e0/e0f25a97a12b1a7344fe6008ba6d3752\" /></p><p></p><p>事实并非如此，Parquet 标准其实是一个基于 Thrift 协议定义的文件格式，其中包含很多可选的字段，这为后面的问题埋下了伏笔：</p><p></p><p>由于早期 Parquet 开源代码的糟糕实现，各个引擎和框架都开始从头写自己的 Parquet Reader/Writer，它们都根据自己的需要，只使用了 Parquet 标准中一部分字段，这对不同引擎之间 Parquet 文件的互操作性带来了问题，系统 A 因为用了某个更高级的字段，系统 B 没有实现它，导致 B 无法直接消费 A 产生的文件。不同的 Parquet 实现有不同的 bug，而用户持久化的文件无法重写，这进一步导致不同引擎需要打上各种补丁，从有问题的历史 Parquet 文件中读出正确的数据。再就是臭名昭著的 Parquet V2 争论。Apache Parquet 社区先是引入了一个 Data Page V2 的概念，用来支持对某一列的某个 Page 进行更细粒度的压缩和编码控制，这没有问题。但后续又引入了一个 Feature V2 的概念，把所有新加入的功能如 Page Index、Bloom Filter、Delta Encoding、Byte Stream Split Encoding 等，都称做 V2 功能。这样一来，有的实现认为 Data Page V2 才是 V2，其他则认为只要用了某个 V2 功能也叫 V2，导致对如何判断一个 Parquet 文件是不是 V2 版本没有一个共识。所以很多企业为了规避这个问题，直接禁用 V2 的任何功能。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/89/892fe7ed76ca117dbe125b03f5a5ffeb\" /></p><p></p><p>尽管 Parquet 有各种各样的问题，它仍然是当前大数据文件格式的事实标准，在开放存储这个大前提下，也没有什么好纠结的。既然 Parquet 是开源的，是不是挑一个开源实现拿来用就好了？很多引擎和框架都实现了自己的 Parquet 读写模块，但由于前面提到的问题，要么功能不全，要么性能不佳，基本没有能直接拿来用。早在云器 Lakehouse 选型文件格式的时候（2022 年初），C++ 的开源 Parquet 实现只有 Apache Arrow、Apache Impala 和 DuckDB 三家，其中后两者都只实现了 V1 的功能；而 Apache Arrow 中的 Parquet C++ 代码是 Parquet 社区捐赠的，V2 的功能也实现了一部分，但仍然缺少 Predicate Pushdown、Page Index 和 Bloom Filter 等重要功能，并且内部测评的性能也不及预期，无法直接使用。</p><p></p><p></p><h4>Community Over Code</h4><p></p><p></p><p>纵观国外的一些友商，Velox 和 Databricks 开发了自己的 Native C++ Parquet 实现，而 Snowflake、BigQuery 和 ClickHouse 则都是基于 Apache Arrow 中的 Parquet C++ 实现来完成 Parquet 的拼图。虽然从头开发一套 Parquet 实现的确能够获得最佳的定制和性能，但也需要付出大量重复劳动，也可能会掉进一些前人踩过的坑。既然 Apache Parquet 是一个开源的标准，没有任何秘密，而 Apache Arrow 已经被友商广泛使用，那直接基于 Apache Arrow 中的 Parquet 代码来实现云器 Lakehouse 的文件格式，也符合云器 Lakehouse 追求最佳开放性的设计理念。与此同时，云器科技也决定投入到社区当中，补全 Parquet 缺失的功能，并且深度优化性能，从而真正成为社区的一部分。</p><p></p><p></p><h5>主要贡献</h5><p></p><p></p><p>云器科技对 Parquet 社区的贡献，主要涉及了 Apache 软件基金会旗下两个顶级项目 Apache Parquet 和 Apache Arrow 的三个 GitHub 仓库：</p><p></p><p>apache/parquet-format：Parquet 格式规范，所有的实现必须遵循此规范。参与该项目可以影响格式标准的后续发展，把对云器有益的格式演进推回社区，从而让更多用户受益。apache/parquet-mr：Parquet 的 Java 语言实现，是以 Java 生态为主的大数据开源生态圈依赖最广泛的 Parquet 实现。它也被认为是 Parquet 最权威的实现，其他语言的实现在拿不准的时候，都会参照它来统一行为。参与该社区，可以让云器 Lakehouse 写出的 Parquet 文件，能被所有 Java 生态的开源框架（如 Apache Spark、Apache Hive、Trino）直接消费，达到最大的开放性。apache/arrow：Apache Arrow 项目的核心是一种基于内存的列式数据结构，这是一种与语言无关的标准化规范，使得数据可以在不同的编程语言和计算引擎之间以零复制（zero-copy）的方式进行共享和交换，同时提供了一套比较干净和功能最多的 Parquet C++ 实现。云器 Lakehouse 的 Parquet 正是基于这套代码进行功能开发和性能优化，使其达到一个比较理想的状态。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/0d/0da15416f2a2dde355a52fa9d15e7c46\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/74/74427a8621b51d82d7c36e3b5db17388\" /></p><p></p><p>上面两张图基本涵盖了云器科技在 Parquet 社区中最主要的贡献，团队两名成员也因此被 Apache Parquet 和 Apache Arrow 社区提名为 Committer。云器科技对开源社区的投入不会停止，团队成员在 2023 年 8 月北京举行的「Apache Software Foundation 旗下大会 - Community Over Code Asia 2023」上分享了参与开源项目的心得，后续仍会深耕社区，把我们认为有价值的功能贡献回社区，让更多的用户受益。</p><p></p><p></p><h2>总&nbsp; &nbsp; 结</h2><p></p><p></p><p>本文回顾和分析了数据湖仓的历史和大数据平台的演进趋势，提出了基于增量计算的一体化趋势，以及该架构必然需要一个开放式的增量存储支撑。基于 Single Engine · All Data 理念云器发布了一体化数据平台——云器 Lakehouse，并分享了如何围绕 Apache Iceberg 和 Apache Parquet，来构建开放湖仓之上的增量存储，获得最佳开放性和极致性能。同时云器科技也大力投入开源社区，以合作共赢的姿态践行构建 Open Lakehouse 的设计理念。</p><p></p><p></p><h5>作者简介：</h5><p></p><p></p><p>吴刚，云器科技，Lakehouse 技术专家。目前是 Apache ORC 的 PMC，也是 Apache Arrow 和 Apache Parquet 的 committer。在此之前，曾是阿里巴巴的高级技术专家，负责 MaxCompute 的存储系统，也曾在 Uber 负责 Apache Spark 平台。</p>",
    "publish_time": "2024-01-25 00:09:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AutoML时代：领英工程师如何缩短模型训练时间",
    "url": "https://www.infoq.cn/article/t6emhCPvboDkkt6pIxbh",
    "summary": "<p>领英工程师 Shubham Agarwal 及 Rishi Gupta 解释道，为协助发现并移除违反其标准政策的内容，领英一直在使用自研的 AutoML 框架，该框架可以并行地训练分类器且试验多个模型架构。</p><p></p><p></p><blockquote>我们使用 AutoML 不断重新训练已有模型，将训练所需时间从数月缩短到数天，并减少开发新基线模型所需时间。这也让我们能积极主动地应对新出现的对抗性威胁。</blockquote><p></p><p></p><p>内容审核的关键之一在于持续的执行和调整，以应对规避审核的新手段，除此之外还必须要能适应环境的变化。这些变化包括：数据漂移，即平台上发布的内容会随着对话的进行发生固有变化；全球事件，这类事件往往会在讨论中出现并产生不同观点，其中常充斥着错误信息；对抗性威胁，其中包括欺诈和欺瞒行为，如伪造档案、实施诈骗等。</p><p></p><p>为应对上述挑战，领英采用的方法目标为“主动检测”，该方法需要一个不断调整和发展其 ML 模型和系统的过程。AutoML 是领英内部研发的工具，全称为自动化机器学习（Automated Machine Learning），用于，通过不断在新数据上重新训练模型、使用假负和假正等数据修正模型、微调参数方式提升机器学习性能。</p><p></p><p></p><blockquote>通过 AutoML，我们得以将过去冗长且复杂的流程转变为精简又高效的流程……在实现 AutoML 后，我们开发新基线模型和持续性重新训练已有模型的平均所需时间从两个月缩短直不到一周。</blockquote><p></p><p></p><p>通过 AutoML，领英工程师实现了数据准备和特征转换过程的自动化，其中包括降噪、降维和特征工程，意在创建用于分类器训练的高质量训练数据集。</p><p></p><p>在第二阶段，AutoML 通过搜索一系列超参数和优化方式，对比不同分类器架构在一组已定的评估指标下生成的模型性能。</p><p></p><p>最后，AutoML 将新完成训练的模型供给生产服务器，实现部署过程的自动化。</p><p></p><p>Agarwal 和 Gupta 认为这套工具仍有一些方面不太成熟，具体来说是需要提高速度和效率，使其能够在更大范围内应用，最终提高对计算能力的要求。他们称，另一个颇具前景的领域是使用生成式 AI，减少标签噪声并生成用于模型训练的合成数据，从而提高数据集质量，</p><p></p><p>虽然并不是所有的组织都有领英的运营规模，或者能拥有自研 ML 自动化工具的资源，但 Agarwal 和 Gupta 所描述的方式仍可在小规模范围内进行复制，从而减轻机器学习工程师与重新训练已有模型相关的重复性工作量。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2024/01/linkedin-automl-content-filter/\">https://www.infoq.com/news/2024/01/linkedin-automl-content-filter/</a>\"</p><p></p><p></p><p></p><p></p>",
    "publish_time": "2024-01-25 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Java近期新闻：JEP最终草案、Payara 2024年路线图、TornadoVM IDEA插件",
    "url": "https://www.infoq.cn/article/B28HwykMMrV0LBUE47J3",
    "summary": "<p></p><h4>OpenJDK</h4><p></p><p></p><p>Oracle 的 Loom 项目架构师和技术负责人<a href=\"https://inside.java/u/RonPressler/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">Ron Pressler</a>\"和 Oracle 软件开发总监<a href=\"https://www.linkedin.com/in/jlaskey/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">Jim Laskey</a>\"提交了 JEP 草案 8323335（<a href=\"https://openjdk.org/jeps/8323335?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">隐式声明类和实例主方法（最终）</a>\"） 。之前被称为 未命名类和实例主方法（预览）、灵活主方法和匿名主类（预览） 和 隐式类和增强的主方法（预览），这个 JEP 包含了对之前两轮 <a href=\"https://openjdk.java.net/jeps/12?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">预览</a>\" 反馈的增强，即在JDK 22中交付的 JEP 463（<a href=\"https://openjdk.org/jeps/463?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">隐式类和实例主方法（第二次预览）</a>\"和在JDK 21中交付的 JEP 445（<a href=\"https://openjdk.org/jeps/445?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">未命名类和实例主方法（预览）</a>\"）。该JEP提议“让学生可以在不需要理解太多语言特性的前提下编写他们的第一个程序。”2022年9月，Oracle的Java语言架构师<a href=\"https://www.linkedin.com/in/briangoetz/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">Brian Goetz</a>\"为此撰写了<a href=\"https://openjdk.org/projects/amber/design-notes/on-ramp?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">“Paving the on-ramp”</a>\"一文。Oracle技术委员会成员<a href=\"https://www.linkedin.com/in/gavin-bierman-a0173075/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">Gavin Bierman</a>\"已<a href=\"https://mail.openjdk.org/pipermail/amber-dev/2023-May/008065.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">发布</a>\"<a href=\"https://cr.openjdk.org/~gbierman/jep445/jep445-20230502/specs/unnamed-classes-instance-main-methods-jls.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">规范文档</a>\"初稿，供Java社区评审。关于JEP 445的更多细节可以在InfoQ的其他<a href=\"https://www.infoq.com/news/2023/05/beginner-friendly-java/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">报道</a>\"中找到。</p><p></p><p>在经过了两轮预览之后，Laskey 还提交了 JEP 草案 8323333（<a href=\"https://openjdk.org/jeps/8323333?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">字符串模板（最终）</a>\"。前面的两轮预览即在JDK 22中交付的 JEP 459（<a href=\"https://openjdk.org/jeps/459?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">字符串模板（第二次预览）</a>\"）和在JDK 21交付的 JEP 430（<a href=\"https://openjdk.org/jeps/430?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">字符串模板（预览）</a>\"）。该 JEP 提议使用 字符串模板 来增强 Java 编程语言，这些字符串字面量包含嵌入表达式，将在运行时被解释，其中嵌入的表达式将在运行时进行计算和验证。关于 JEP 430 的更多详细信息可以在 InfoQ 的 <a href=\"https://www.infoq.com/news/2023/04/java-gets-a-boost-with-string/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">新闻报道</a>\" 中找到。</p><p></p><h4>JDK 23</h4><p></p><p></p><p>JDK 23 <a href=\"https://jdk.java.net/23/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">早期访问构建</a>\" 版本的<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-23%2B5?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">Build 5</a>\" 已发布，包含了针对 Build 4 的 <a href=\"https://github.com/openjdk/jdk/compare/jdk-23%2B4...jdk-23%2B5?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">更新</a>\"，其中包括对各种 <a href=\"https://bugs.openjdk.org/issues/?jql=project%20%3D%20JDK%20AND%20fixversion%20%3D%2023%20and%20%22resolved%20in%20build%22%20%3D%20b05%20order%20by%20component%2C%20subcomponent&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">问题</a>\" 的修复。关于此版本的更多详细信息可以在 <a href=\"https://jdk.java.net/23/release-notes?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">发布说明</a>\" 中找到。</p><p></p><h4>JDK 22</h4><p></p><p></p><p>JDK 22 <a href=\"https://jdk.java.net/22/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">早期访问构建</a>\"版本的<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-22%2B31?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">Build 31</a>\" 也已发布，包含了针对 Build 30 的 <a href=\"https://github.com/openjdk/jdk/compare/jdk-22%2B30...jdk-22%2B31?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">更新</a>\"，包括对各种 <a href=\"https://bugs.openjdk.org/issues/?jql=project%20%3D%20JDK%20AND%20fixversion%20%3D%2022%20and%20%22resolved%20in%20build%22%20%3D%20b31%20order%20by%20component%2C%20subcomponent&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">问题</a>\" 的修复。关于此版本的更多详细信息可以在 <a href=\"https://jdk.java.net/22/release-notes?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">发布说明</a>\" 中找到。</p><p></p><p>对于 <a href=\"https://openjdk.org/projects/jdk/23/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">JDK 23</a>\" 和 <a href=\"https://openjdk.org/projects/jdk/22/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">JDK 22</a>\"，开发者可以通过 <a href=\"https://bugreport.java.com/bugreport/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">Java Bug Database</a>\" 报告错误。</p><p></p><h4>Spring Framework</h4><p></p><p></p><p><a href=\"https://spring.io/projects/spring-framework?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">Spring Framework</a>\" 6.1.3 和 6.0.16 已 <a href=\"https://spring.io/blog/2024/01/11/spring-framework-6-1-3-and-6-0-16-available-now/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">发布</a>\"，包含了错误修复、文档改进、依赖项升级和新特性，例如：在使用 <a href=\"https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/web/reactive/function/client/WebClient.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">WebClient</a>\" 接口时，从剩余的单检查点排除包含敏感查询参数的完整请求 URI；如果在预检请求中发送了 Access-Control-Request-Private-Network 标头（Private Network Access），则允许 <a href=\"https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/web/bind/annotation/CrossOrigin.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">@CrossOrigin</a>\" 注解在应用程序中向 Google Chrome 提供 Access-Control-Allow-Private-Network 标头；避免在 <a href=\"https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/context/annotation/CommonAnnotationBeanPostProcessor.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">CommonAnnotationBeanPostProcessor</a>\" 类中由于在找到注解之前在外层级别调用而提前解析 ClassUtils 类中定义的 getMostSpecificMethod() 方法。这些版本将与即将发布的 Spring Boot 3.2.2 和 3.1.8 一起提供。关于这些版本的更多详细信息可以在 <a href=\"https://github.com/spring-projects/spring-framework/releases/tag/v6.1.3?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">6.1.3</a>\" 和 <a href=\"https://github.com/spring-projects/spring-framework/releases/tag/v6.0.16?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">6.0.16</a>\" 的发布说明中找到。</p><p></p><p><a href=\"https://spring.io/projects/spring-data?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">Spring Data</a>\" 的 2023.1.2 和 2023.0.8 已 <a href=\"https://spring.io/blog/2024/01/12/spring-data-2023-1-2-and-2023-0-8-available/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">发布</a>\"，包含了错误修复和相应的子项目依赖项升级，例如：Spring Data Commons 3.2.2 和 3.1.8；Spring Data MongoDB 4.2.2 和 4.1.8；Spring Data Elasticsearch 5.2.2 和 5.1.8；以及 Spring Data Neo4j 7.2.2 和 7.1.8。这些版本也可以在即将发布的 Spring Boot 3.2.2 和 3.1.8 中使用。</p><p></p><p><a href=\"https://spring.io/projects/spring-ws/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">Spring Web Services</a>\" 4.0.10 已 <a href=\"https://spring.io/blog/2024/01/12/spring-web-services-4-0-10-is-released/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">发布</a>\" ，带来了一些显著变化，例如：支持 jar:nested，这是 uber JAR 资源的 URI Schema，作为 Spring Boot 3.2 新加载器实现的一部分，位于 <a href=\"https://docs.spring.io/spring-ws/docs/current/api/org/springframework/xml/validation/SchemaFactoryUtils.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">SchemaFactoryUtils</a>\" 类中；删除了 Apache HttpComponents <a href=\"https://hc.apache.org/httpcomponents-client-5.4.x/current/httpclient5/apidocs/org/apache/hc/client5/http/classic/HttpClient.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">HttpClient</a>\" 接口的重复依赖声明；将 Spring Framework 依赖项升级到 6.0.16。关于这个版本的更多详细信息可以在 <a href=\"https://github.com/spring-projects/spring-ws/releases/tag/v4.0.10?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">发布说明</a>\" 中找到。</p><p></p><p><a href=\"https://spring.io/projects/spring-cloud-dataflow/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">Spring Cloud Dataflow</a>\" 2.11.2 已<a href=\"https://spring.io/blog/2024/01/11/spring-cloud-dataflow-2-11-2-released/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">发布</a>\"，带来了一些重要的变化，例如：将 <a href=\"https://logback.qos.ch/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">Logback</a>\" 升级到 1.2.13 ，解决了 <a href=\"https://github.com/advisories/GHSA-vmq6-5m68-f53m?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">CVE-2023-6378</a>\"问题（这是 Logback 接收器组件中的一种序列化漏洞，允许攻击者通过发送有毒数据来发动拒绝服务攻击）；更新 <a href=\"https://docs.spring.io/spring-cloud-dataflow/docs/2.11.2/api/org/springframework/cloud/dataflow/server/batch/BatchVersion.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">BatchVersion</a>\" 枚举和 <a href=\"https://docs.spring.io/spring-cloud-dataflow/docs/2.11.2/api/org/springframework/cloud/dataflow/server/batch/JdbcSearchableJobExecutionDao.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">JdbcSearchableJobExecutionDao</a>\" 类，支持在基于 Batch5 的模式被删除的 JOB_CONFIGURATION_LOCATION 字段；解决了 JdbcSearchableJobExecutionDao 类中的 getJobExecutionsWithStepCountFilteredByTaskExecutionId() 方法不支持 BATCH_ 任务前缀的问题。关于这个版本的更多详细信息可以在 <a href=\"https://github.com/spring-cloud/spring-cloud-dataflow/releases/tag/v2.11.2?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">发布说明</a>\" 中找到。</p><p></p><h4>Payara</h4><p></p><p></p><p>Payara团队对2023年进行了<a href=\"https://blog.payara.fish/payara-platform-roadmap-2024?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">回顾</a>\"，并提供了Payara平台2024年及以后的路线图。2023年的亮点包括：发布Payara Platform 6；支持JDK 21和MicroProfile 6.1；推出<a href=\"https://start.payara.fish/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">Payara Starter</a>\"。2024年的路线图包括：对所有Payara产品的愿景（直至2026年）；详细的Payara Server、Payara Micro、Payara Cloud和Payara Developer Tools路线图；对Jakarta EE 11的支持，计划于2024年6月/7月发布正式版。更多详细信息可以在Payara高级产品经理<a href=\"https://blog.payara.fish/author/louise-castens?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">Louise Castens</a>\"和Payara合同技术作家<a href=\"https://www.linkedin.com/in/ghgeek/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">Luqman Saeed</a>\"在2023年12月Payara虚拟大会上的演讲<a href=\"https://www.crowdcast.io/c/virtualpayaraconference/xstAZ?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">“用Jakarta EE赋能企业创新”</a>\"中找到。</p><p></p><h4>TornadoVM</h4><p></p><p></p><p><a href=\"https://www.tornadovm.org/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">TornadoVM团队</a>\"推出了<a href=\"https://github.com/beehive-lab/tornado-insight/blob/main/README.md?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">TornadoInsight</a>\"，一个“开源的用于增强开发者使用TornadoVM体验的IntelliJ IDEA插件”。关键功能包括：即时静态检查器，实时扫描TornadoVM代码并报告TornadoVM不支持的Java特性；一个动态测试框架，简化了单个TornadoVM任务的测试过程。InfoQ将进一步跟进并发布更详细的新闻报道。</p><p></p><h4>Micrometer</h4><p></p><p></p><p><a href=\"https://github.com/micrometer-metrics/micrometer/blob/main/README.md?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">Micrometer Metrics</a>\" 1.12.2和1.11.8版本均包含了依赖项升级和错误修复，如：POM文件中<a href=\"https://central.sonatype.com/artifact/io.netty/netty-transport-native-epoll?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">io.netty:netty-transport-native-epoll</a>\" 缺失version声明时报告编译错误；重命名在<a href=\"https://github.com/micrometer-metrics/micrometer/blob/main/micrometer-core/src/main/java/io/micrometer/core/instrument/step/StepMeterRegistry.java?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">StepMeterRegistry</a>\"类中轮询指标的线程；修复在<a href=\"https://github.com/micrometer-metrics/micrometer/blob/main/micrometer-core/src/test/java/io/micrometer/core/instrument/binder/grpc/GrpcObservationTest.java?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">GrpcObservationTest</a>\"类中定义的unaryRpcAsync()方法，提高并发性。有关这些版本的更多详细信息，请参阅<a href=\"https://github.com/micrometer-metrics/micrometer/releases/tag/v1.12.2?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">1.12.2</a>\"和<a href=\"https://github.com/micrometer-metrics/micrometer/releases/tag/v1.11.8?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">1.11.8</a>\"的发布说明。</p><p></p><p>同样，<a href=\"https://github.com/micrometer-metrics/tracing/blob/main/README.md?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">Micrometer Tracing</a>\"的1.2.2和1.1.9版本也都包含了依赖项升级和错误修复，如：<a href=\"https://github.com/micrometer-metrics/tracing/blob/main/micrometer-tracing-tests/micrometer-tracing-test/src/main/java/io/micrometer/tracing/test/simple/SimpleTraceContextBuilder.java?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">SimpleTraceContextBuilder</a>\"类不会覆盖<a href=\"https://github.com/micrometer-metrics/tracing/blob/main/micrometer-tracing/src/main/java/io/micrometer/tracing/TraceContext.java?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">TraceContext</a>\"接口的值；手动创建的传递字段不通过<a href=\"https://github.com/micrometer-metrics/tracing/blob/main/micrometer-tracing/src/main/java/io/micrometer/tracing/contextpropagation/ObservationAwareSpanThreadLocalAccessor.java?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">ObservationAwareSpanThreadLocalAccessor</a>\"类进行跨线程传播。有关这些版本的更多详细信息，请参阅<a href=\"https://github.com/micrometer-metrics/tracing/releases/tag/v1.2.2?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">1.2.2</a>\"和<a href=\"https://github.com/micrometer-metrics/tracing/releases/tag/v1.1.9?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">1.1.9</a>\"的发布说明。</p><p></p><h4>Project Reactor</h4><p></p><p></p><p><a href=\"https://github.com/reactor/reactor/blob/main/README.md?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">Project Reactor</a>\" <a href=\"https://github.com/reactor/reactor/releases/tag/2023.0.2?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">第二个维护版本</a>\"2023.0.2进行了依赖项升级：reactor-core 3.6.2、reactor-netty 1.1.15和reactor-pool 1.0.5。reactor-kafka 1.3.22、reactor-addons 3.5.1和reactor-kotlin-extensions 1.2.2保持不变。有关此版本的更多详细信息，请参阅<a href=\"https://github.com/reactor/reactor/compare/2023.0.1...2023.0.2?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">变更日志</a>\"。</p><p></p><p>Project Reactor <a href=\"https://github.com/reactor/reactor/releases/tag/2022.0.15?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">第十五个维护版本</a>\"2022.0.15的依赖项升级包括：reactor-core 3.5.14、reactor-netty 1.1.15和reactor-pool 1.0.5。reactor-kafka 1.3.22、reactor-addons 3.5.1和reactor-kotlin-extensions 1.2.2保持不变。有关此版本的更多详细信息，请参阅<a href=\"https://github.com/reactor/reactor/compare/2022.0.14...2022.0.15?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">变更日志</a>\"。</p><p></p><p>Project Reactor 2020.0.40，代号Europium-SR40，<a href=\"https://github.com/reactor/reactor/releases/tag/2020.0.40?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">发布</a>\"，包含了依赖项升级：reactor-core 3.4.35和reactor-netty 1.0.41。reactor-pool 0.2.12、reactor-kafka 1.3.22、reactor-addons 3.4.10、reactor-kotlin-extensions 1.1.10和reactor-rabbitmq 1.5.6保持不变。有关此版本的更多详细信息，请参阅<a href=\"https://github.com/reactor/reactor/compare/2020.0.39...2020.0.40?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">变更日志</a>\"。</p><p></p><h4>Apache软件基金会</h4><p></p><p></p><p><a href=\"https://tomcat.apache.org/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">Apache Tomcat</a>\" <a href=\"https://www.mail-archive.com/announce@apache.org/msg08838.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">11.0.0-M16</a>\"、<a href=\"https://www.mail-archive.com/announce@apache.org/msg08836.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">10.1.18</a>\"、<a href=\"https://www.mail-archive.com/announce@apache.org/msg08839.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">9.0.85</a>\"和<a href=\"https://www.mail-archive.com/announce@apache.org/msg08837.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">8.5.98</a>\"均包含了错误修复和显著的变更，例如：重构<a href=\"https://tomcat.apache.org/tomcat-11.0-doc/api/org/apache/tomcat/util/threads/VirtualThreadExecutor.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">VirtualThreadExecutor</a>\"类，使其可以被NIO2连接器使用；纠正了<a href=\"https://bz.apache.org/bugzilla/show_bug.cgi?id=67675&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">问题67675</a>\"修复中的一个回归，该回归破坏了通常由OpenSSL 1.0.2生成的TLS密钥文件的解析，这些格式的密钥没有指定显式的伪随机函数，只依赖默认值;；允许在内省的<a href=\"https://tomcat.apache.org/tomcat-11.0-doc/mbeans-descriptors-howto.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">MBeans</a>\"上进行具有相同名称的多个操作，修复了由于引入第二个addSslHostConfig()方法引起的回归。有关这些版本的更多详细信息，请参阅<a href=\"https://tomcat.apache.org/tomcat-11.0-doc/changelog.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">11.0.0-M16</a>\"，<a href=\"https://tomcat.apache.org/tomcat-10.1-doc/changelog.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">10.1.18</a>\"，<a href=\"https://tomcat.apache.org/tomcat-9.0-doc/changelog.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">9.0.85</a>\"和<a href=\"https://tomcat.apache.org/tomcat-8.5-doc/changelog.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">8.5.98</a>\"的发布说明。</p><p></p><p>在<a href=\"https://cocoon.apache.org/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">Apache Cocoon</a>\" 2.3.0发布之后，开发团队最近决定<a href=\"https://www.mail-archive.com/announce@apache.org/msg08844.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">报废</a>\"Cocoon的2.1和3.0分支。最初发布于20多年前的2.1分支现在被认为已经过时了。3.0分支试图从头开始重写Cocoon，但从未最终完成。Apache Cocoon是一个基于Spring的框架（自版本2.2起），建立在关注点分离和基于组件开发概念的基础上。</p><p></p><h4>Grails</h4><p></p><p></p><p>Grails基金会发布Grails Framework 5.3.6和3.3.18，其中一些显著变化包括：回滚了最近对SnakeYAML、Micronaut、Spring和Spring Boot的升级，因为它们不向后兼容；添加手动触发SDKMan<a href=\"https://sdkman.io/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">发布</a>\"的工作流；更新<a href=\"https://grails-plugins.github.io/grails-release/docs/manual/guide/plugins.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">NexusPublishing</a>\"扩展，将重试延迟从2000毫秒增加到3000毫秒。有关这些版本的更多详细信息，请参阅<a href=\"https://github.com/grails/grails-core/releases/tag/v5.3.6?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">5.3.6</a>\"和<a href=\"https://github.com/grails/grails-core/releases/tag/v3.3.18?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">3.3.18</a>\"的发布说明。</p><p></p><h4>Piranha Cloud</h4><p></p><p></p><p><a href=\"https://piranha.cloud/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">Piranha</a>\" 23.12.0已<a href=\"https://github.com/piranhacloud/piranha/releases/tag/v24.1.0?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">发布</a>\"，带来了一些显著变化，例如：通过将<a href=\"https://projects.eclipse.org/projects/ee4j.wasp?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">Eclipse WaSP</a>\"从3.2.1降级到3.2.0来解决Windows构建失败问题（Eclipse WaSP是<a href=\"https://jakarta.ee/specifications/pages/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">Jakarta Pages</a>\"和<a href=\"https://jakarta.ee/specifications/tags/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">Jakarta Standard Tag Library</a>\"的兼容实现）；一个新的<a href=\"https://github.com/piranhacloud/piranha/blob/current/uber/src/main/java/cloud/piranha/uber/UberPiranha.java?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">UberPiranha</a>\"类和相应的uber模块，用于在命令行初始化Piranha；为Piranha Uber设置临时目录的能力。有关此版本的更多详细信息，请参阅<a href=\"https://javadoc.io/doc/cloud.piranha/project/latest/index.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">文档</a>\"和<a href=\"https://github.com/piranhacloud/piranha/issues?q=is%3Aissue+-label%3Awontfix+milestone%3A24.1.0+is%3Aclosed&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">问题跟踪</a>\"。</p><p></p><h4>OpenXava</h4><p></p><p></p><p><a href=\"https://openxava.org/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">OpenXava</a>\" 7.2.2<a href=\"https://openxava.org/blog/openxava-7.2.2-released?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">发布</a>\"，包含了依赖项升级和错误修复，例如：在同一行应用多个<a href=\"https://openxava.org/OpenXavaDoc/apidocs/org/openxava/annotations/ListProperties.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">@RowStyle注解时只考虑其中的一个；[@ListProperties</a>\"注解在与<a href=\"https://openxava.org/OpenXavaDoc/apidocs/org/openxava/annotations/Tree.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">@Tree</a>\"或<a href=\"https://openxava.org/OpenXavaDoc/apidocs/org/openxava/annotations/Editor.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">@Editor(\"TreeView\")</a>\"注解结合使用时不支持多属性；在使用日历列表格式时数据库连接泄漏。有关此版本的更多详细信息，请参阅<a href=\"https://github.com/openxava/openxava/releases/tag/7.2.2?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">发布说明</a>\"。</p><p></p><h4>Gradle</h4><p></p><p></p><p>Gradle 8.6的<a href=\"https://github.com/gradle/gradle/releases/tag/v8.6.0-RC2?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">第二个候选版本</a>\"带来以下这些改进：通过GRADLE_ENCRYPTION_KEY环境变量支持配置缓存中的自定义加密密钥；改进错误和警告报告；改进<a href=\"https://docs.gradle.org/8.6-rc-1/userguide/build_init_plugin.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">Build Init Plugin</a>\"，支持各种类型的项目；增强了插件作者和构建工程师为插件开发自定义构建逻辑的构建编写过程。有关此版本的更多详细信息，请参阅<a href=\"https://docs.gradle.org/8.6-rc-2/release-notes.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDYxNDg5MDUsImZpbGVHVUlEIjoiV3IzRHA4MnJvMkZZbE8zSiIsImlhdCI6MTcwNjE0ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.9x4scHATH8vmXrS8s5aB0-6AW1MGat_Vbk6Ku9cW3rA\">发布说明</a>\"。</p><p></p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2024/01/java-news-roundup-jan08-2024/\">https://www.infoq.com/news/2024/01/java-news-roundup-jan08-2024/</a>\"</p>",
    "publish_time": "2024-01-25 10:13:44",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "曙光全栈托管云，助力“东数西算”发展持续提速",
    "url": "https://www.infoq.cn/article/6mwRolf1N411h7ZFYAF1",
    "summary": "<p>1月22日，信通院发布《面向东数西算的全栈托管云服务发展报告》，曙光全栈托管云作为经典案例被广泛提及。随着“东数西算”工程的持续推进，云计算作为算力的载体，为产业数字化转型注入强劲动能。然而，传统云服务难以满足全栈、安全、开放、绿色等方面的需求。曙光“一云俱全”全栈托管云，成为当下云服务市场的一剂“良方”。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/33/33d6ec26a2af0cc54e075d0de19532f3.jpeg\" /></p><p>中国信通院云计算与大数据研究所所长何宝宏（右）、</p><p>中科曙光总裁助理兼重庆计算公司副总裁兼重庆计算公司技术部经理何牧君共同发布</p><p></p><p>基于自研的云计算操作系统，曙光从处理器到应用，打造出集全栈服务、安全可信、开放兼容、绿色节能、算力强劲等核心优势于一体的全栈托管云平台。</p><p></p><p>全栈服务：涵盖云、数、智全栈服务，包含虚拟化、大数据组件、AI等多种能力，具备集IaaS、PaaS和SaaS为一体的产品能力，满足用户多样化需求。</p><p></p><p>安全可信：以国产硬件为底座，构建安全可信的基础环境，支持多重安全加密功能，针对业务的全生命周期，有效保障数据、网络、应用等各层次的安全。</p><p></p><p>开放兼容：与底层硬件、中间件、数据库、操作系统、第三方应用广泛适配，满足快速部署、迁移和扩展需求。</p><p></p><p>绿色节能：采用全浸式相变液冷技术，保持电子元器件恒温，整体提升系统性能，通过部署液冷服务器使算力系统PUE突破性降至1.04，节能效果显著。</p><p></p><p>算力强劲：接入全国一体化大数据中心算力调度平台，进行统一调度，承接成渝、京津冀、长三角、粤港澳等国家节点的各类实时或非实时算力需求服务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d1/d1a403e69961667f16b311eb4947c00c.png\" /></p><p>                                                   《面向东数西算的全栈托管云服务发展报告》扫码下载</p>",
    "publish_time": "2024-01-25 10:14:03",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "被严重宕机坑惨了！多家公司向这个已经存在10年却“鲜为人知”的架构迁移",
    "url": "https://www.infoq.cn/article/FezObW1xRCZavVgEkMsF",
    "summary": "<p></p><blockquote>一次持续了近 6 小时的网络中断故障让 Slack 团队意识到，是时候从单体架构迁移到基于单元的架构上了。对比发现，新的架构可以在 5 分钟内逐步排出受影响的可用区的所有流量。</blockquote><p></p><p>&nbsp;</p><p>单元化架构作为一种增加冗余和有效限制站点故障影响范围的方式，在大型在线服务中越来越流行。在过去一年半时间里，Slack 将大多数面向用户的关键服务从单体架构迁移到基于单元的架构上。此前，Slack 团队在一篇文章中解释了大规模迁移原因，以及团队在此过程中所做出的工程技术权衡。</p><p></p><h2>为减少灰色故障，Slack 迁移到 AWS 中基于单元的架构上</h2><p></p><p>&nbsp;</p><p>Slack团队会在每次发生明显的服务中断后进行一次事故评审。以下是Slack团队内部事故评审报告的一部分摘录，该摘录总结了其中的一起事故以及Slack团队的发现：</p><p>&nbsp;</p><p></p><blockquote>2021 年 6 月 30 日上午 11 点 45 分，我们的云供应商在美国东海岸的一个可用区域发生网络中断，Slack 的大部分服务都托管在那里。连接一个可用区域和其他几个包含 Slack 服务器的可用区域的网络链路发生了间歇性故障，导致 Slack 服务器之间的连接变慢，进而出现服务降级。&nbsp;当日下午 12 点 33 分，我们的云供应商自动从服务中删除了网络链接，恢复了对 Slack 客户的全部服务。经过他们的一系列自动检查之后，网络链接再次进入服务状态。&nbsp;当日下午 5 点 22 分，网络链路又发生了同样的间歇性故障。下午 5 点 31 分，云供应商永久地从服务中删除了网络链接，恢复了对我们全部的服务。</blockquote><p></p><p>&nbsp;</p><p>乍一看，Slack的服务遭遇了物理硬件故障，导致了一些错误。直到故障硬件被移除，问题才得到解决。然而，在事故评审过程中，不禁要问：让用户经历这样的服务中断是合理的吗？</p><p>&nbsp;</p><p>Slack 的基础设施覆盖全球，但其核心平台托管在美国东海岸地区 (us-east-1)，该公司使用可用区（AZ）进行故障隔离。在云端托管服务的构建者可以通过这种方式提高服务的可用性：即使某个AZ发生故障，整个服务的运行也不会受到影响。这就引出了一个问题：为什么6月30日的策略没有奏效？为什么一个AZ的故障会导致用户体验中断？</p><p>&nbsp;</p><p>Slack 的高级工程师 Cooper Bethea 解释了为什么分布式系统中的故障检测可能会出现问题：</p><p>&nbsp;</p><p></p><blockquote>事实证明，检测分布式系统中的故障是一个难题。来自用户的单个 Slack API 请求（比如说加载一个频道中的消息）可能会分散成数百个服务后端的 RPC，所有 RPC 都必须全部完成才能向用户返回正确的响应。我们的服务前端不断尝试检测和排除出现故障的后端，但在排除出现故障的服务器之前，我们必须先记录下来一些故障！</blockquote><p></p><p>&nbsp;</p><p>Slack 将这种类型的故障可以归类为灰色故障。在发生灰色故障时，系统可用性对于不同的组件来说是不一样的。例如，在上述案例中，受影响AZ内的系统看到其AZ内的后端完全可用，但AZ外的后端不可用。反过来，未受影响AZ内的系统看到受影响的AZ是不可用的。即使是同一个受影响的AZ内的客户端能够看到的后端可用性也是不一样的，这取决于它们的网络流量是否碰巧流经发生故障的设备。这就需要分布式系统在处理消息和提供小动物动图的同时处理好一切故障，这是一个相当复杂的任务。</p><p>&nbsp;</p><p>为了解决这个难题，Slack 团队决定改用一种基于单元（cell）的方法，其中每个可用区包含完全独立的后端部署，且后端组件仅限于单个可用区使用。这种方法使用一个基于 Envoy/xDS 的层将流量路由到 AZ 层面的单元。这种独立部署的方法在某种程度上是 Slack 平台异构属性的自然延伸，该平台使用了许多语言栈和服务发现接口，因此在后端服务之间引入复杂的路由逻辑会是非常麻烦的事情。</p><p><img src=\"https://static001.geekbang.org/infoq/44/449d4052128225b403378dddf13fb759.webp\" /></p><p></p><p>有了这个新架构后，Slack就可以快速将流量从出现问题的单元转移出去，因为配置更改只需几秒钟就能传播出去。流量可以渐次（以 1% 的粒度）且优雅地转移（所有正在进行的请求都在正在排出流量的单元中完成）。</p><p>&nbsp;</p><p>Slack 的设计路径遵循了 AWS 制定的指南，该指南在 AWS 的云原生架构系列中得到了深入探讨，其中作者提供了多种工具和技术，用来利用基于容器的计算服务提高云负载的可扩展性和弹性。AWS 架构师主张在云架构中建立强大的故障隔离边界，以应对黑天鹅事件并最大限度地减少意外故障的影响。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/31/319247571f01b71b978febe1b522d0e2.webp\" /></p><p></p><h2>从 73 小时故障中吸取教训，Roblox通过单元化架构改进用户体验</h2><p></p><p>&nbsp;</p><p>最近，在线游戏平台和创作系统Roblox也分享了其基于单元的架构走过的历程，以及进一步提高其平台弹性的未来计划。和Slack 一样，Roblox也是从一次故障中意识到，是时候采用单元化架构了。</p><p>&nbsp;</p><p>2021年10月，Roblox遭遇了一次长达73小时的系统范围故障，该故障最初源于一个数据中心的小问题，但迅速演变为大规模故障。事故后分析表明，团队需要加强其基础设施的稳固性，以应对流量峰值、天气条件、硬件故障、软件错误和人为失误等各种故障因素。重点在于防止单个组件问题扩散至整个系统，并确保网络或用户持续重试操作不会引发与负载相关的级联故障。</p><p>&nbsp;</p><p>为了应对类似2021年10月的故障，Roblox最初在多个区域的数据中心设置了基础设施的副本，采用主备方式。这意味着当主数据中心发生重大故障时，整个系统可以切换到备份基础设施上。这种方式提供了一种应急弹性，但Roblox的长期目标是实现从主备数据中心到双活数据中心的转型，使两个数据中心同时处理工作负载，提高可靠性和近乎即时的故障切换能力。</p><p>&nbsp;</p><p>Roblox还实现了单元化架构，在数据中心内建立坚固的“防爆墙”，以防止发生整个数据中心范围的故障。Roblox的目标是将所有服务迁移至单元中，以增强弹性和高效的工作负载管理。整个单元（每个单元可能包含1400台服务器）可在必要时进行修复或完全重新配置。这一过程需要确保一致性，要求服务进行容器化，并实现基础设施即代码的理念。Roblox新的部署工具会自动确保服务跨单元分布，从而使服务所有者无需考虑复制问题。</p><p>&nbsp;</p><p>Roblox 将单元作为一种防火门，可以将故障限制在一个单元内。目标是使单元变得可互换，以便在出现问题时更快地恢复。然而，管理单元之间的通信存在一些挑战，因为需要防止“死亡查询”，即重试查询会导致级联故障。他们正在部署短期解决方案，例如将计算服务的副本部署到每个计算单元中，并在单元间平衡流量，以此来缓解这种情况。他们的长期计划包括实现用于服务发现的下一代服务网格以及将依赖请求定向到与原始调用方相同单元的方法。这将降低故障从一个单元传播到另一个单元的风险。70% 的后端流量现在由单元提供，他们的最终目标是达到 100%。近 3 万台服务器正在运行单元，但这还不到总服务器数量的 10%。</p><p>&nbsp;</p><p>在不中断用户的情况下迁移一个非常繁忙的在线平台的复杂性是巨大的。由于没有大量的资金购买全新的服务器来运行单元化架构基础设施，Roblox 创造性地利用了一小部分备用机器，并策略性地建立了新的、单元，逐步迁移工作负载，然后重新使用已释放的机器来进行下一次迁移。这在不同的数据中心之间造成了一些理想的单元碎片，增加了单元内的弹性。Roblox 预计将于 2025 年完成迁移，他们需要强大的工具来部署均衡的服务，并且不会干扰到用户，他们还需要进行详尽的测试，确保在单元化架构中运行的新服务的兼容性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e6/e6eba328605b95ac54f42dc5d6a9a3d0.png\" /></p><p></p><p>Roblox的努力取得了显著成果，但针对单元化架构的工作仍在进行中。他们致力于在不断扩展规模的过程中提高效率和弹性，主要成就包括建立第二个数据中心，在主备数据中心创建单元，将超过70％的后端服务流量迁移到单元中，以及建立实现一致性的要求。</p><p>&nbsp;</p><p>2023年9月，Roblox在数据中心启动了双活实验，增强了可靠性并最大限度地缩短了故障转移时间。这些成果让他们获得了一个实现全面双活基础设施的计划，确定了改进系统设计的模式。</p><p>&nbsp;</p><p>Roblox一直致力于提升效率和弹性，设想让平台成为数百万用户可靠、高性能的实用工具，并实现实时连接十亿人。他们的基础设施目前运行在近14万5千台服务器上（大部分在本地私有混合云中心）——两年内增长了三倍。目前，Roblox正在努力改造基础设施，使平台更具弹性、更加高效，为数百万用户提供服务，为持续的增长和创新奠定基础。</p><p></p><h2>单元化架构已存在至少十年</h2><p></p><p>&nbsp;</p><p>Slack 采用单元化架构的举措在社区中引发了广泛的讨论。用户esprehn认为，单元并不是要防止可用区故障，而是要对生产基础设施进行分区，以防止出现错误的部署和配置更改。每个 AZ 被分为许多不同的单元。另一位名为 ignoramous 的用户（自称前 AWS 员工）强调，对基于单元的架构的指南是来源于 Amazon 和 AWS 在云中为提供弹性所做的努力。</p><p>&nbsp;</p><p>用户 tedd4u 指出基于单元的架构已经存在至少 10 年了，并附上了一篇发表于 2012 年的文章链接。文中提到，面向服务的架构（SOA）带来了对大规模提供服务的迫切需求。为了满足这些需求，一种鲜为人知的架构技术应运而生——单元化架构。</p><p>&nbsp;</p><p>在传统的服务化架构下（如下图），服务是分层的，每一层使用不同的分区算法，每一层都有不同数量的节点，上层节点随机选择下层节点。当然这个随机是比较而言的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bb/bb149a6e83a4c81d5621db8bdf411eff.png\" /></p><p></p><p>而在单元化架构下，服务虽然分层划分，但每个单元自成一体。按照层次来讲的话，所有层使用相同的分区算法，每一层都有相同数量的节点，上层节点也会访问指定的下层节点。因为他们已经在一起。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c7/c7346d3beb7619f85ad2838bdf311f76.png\" /></p><p></p><p>具体来说，单元化架构具有以下优点：</p><p></p><p>单元提供了一个可并行处理的单元，能够随着用户群的增长而按需调整大小。当需要更多容量时，可以增量式地添加单元。单元之间相互隔离，一个单元的故障不会影响到其他单元。单元内的存储和应用能力独立于其他单元，提供了很好的隔离性。单元提供了多种功能，如测试升级、滚动升级以及在不同版本软件间进行测试的能力。单元可以发生故障、进行升级，并且可以独立于其他单元分布在数据中心内。</p><p>&nbsp;</p><p>在2012年，就已经有包括Facebook在内的多家公司采用单元化结构：</p><p></p><p>Tumblr：用户被映射到单元中，每个数据中心内存在多个单元。每个单元都有一个HBase集群、服务集群和Redis缓存集群。用户被限定在一个单元内，所有单元通过Firehose更新来获取所有帖子。后台任务使用Firehose来填充表和处理请求。每个单元存储所有帖子的单个副本。Flickr：使用联合方法，其中所有用户数据都存储在一个分片上，该分片由不同服务的集群组成。Facebook：消息服务将称为单元的机器和服务集群作为其系统的基本构建块。每个单元由ZooKeeper控制器、应用程序服务器集群和元数据存储组成。Salesforce：Salesforce是根据Pod构建的。Pod是独立的功能集，由50个节点、Oracle RAC服务器和Java应用程序服务器组成。每个Pod支持数千名客户。如果Pod发生故障，只有该Pod上的用户会受到影响。</p><p>&nbsp;</p><p>采用单元化架构的关键在于创建可扩展且强大的服务，以提高系统的平均故障间隔时间（MTBF）。这种服务可以用作由可编程编排层协调的其他服务系统的基础组件，无论是在数据中心还是云环境中都同样有效。如果团队正在寻找更高级的组织模式，那么单元化架构是一个很好的选择。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.infoq.com/news/2024/01/slack-cell-based-architecture/\">https://www.infoq.com/news/2024/01/slack-cell-based-architecture/</a>\"</p><p><a href=\"https://news.ycombinator.com/item?id=37274871\">https://news.ycombinator.com/item?id=37274871</a>\"</p><p><a href=\"https://www.infoq.cn/article/rBofrx6EO9VkId1mmmO3?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">https://www.infoq.cn/article/rBofrx6EO9VkId1mmmO3</a>\"</p><p><a href=\"http://highscalability.com/blog/2012/5/9/cell-architectures.html\">http://highscalability.com/blog/2012/5/9/cell-architectures.html</a>\"</p>",
    "publish_time": "2024-01-25 14:09:42",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "OpenAI演讲：如何通过API将大模型集成到自己的应用程序中",
    "url": "https://www.infoq.cn/article/Okfe2ExwdDtD2tZZmw6d",
    "summary": "<p></p><p>OpenAI的员工Sherwin Wu和Atty Eleti在QCon上讨论了如何使用OpenAI API将这些大语言模型集成到应用程序中，并通过使用API和工具将GPT连接到外部世界以扩展GPT的功能。</p><p></p><p>Atty Eleti：我想带大家回到1973年，也就是50年前。1973年，《科学美国人》（Scientific American）发表了一篇非常有趣的文章，他们在文章中比较了各种动物的运动。他们着手比较运动的效率。换句话说，一只动物从A点到B点燃烧了多少卡路里，与它们的体重等是否有关？他们比较了各种动物，鸟类、昆虫，当然还有我们人类，并将它们根据效率从高到低进行了排名。他们发现，就运动的效率而言，秃鹫的最高。</p><p>&nbsp;</p><p>秃鹫是一种美丽的鸟类，原产于加利福尼亚州和南美洲的一些地区，有时它可以飞数百英里而无需扇动翅膀。它具有非常好的滑翔能力。另一方面，人类行走，在榜单中的排名相当平庸，大约排在榜单三分之一的位置。《科学美国人》这篇文章的精妙之处在于，除了所有物种之外，他们还增加了一个项目，那就是骑自行车的人。骑自行车的人在竞争中大获全胜，击败了所有竞争对手，其运动效率几乎是秃鹫的两倍。</p><p>&nbsp;</p><p>我很喜欢这个故事，因为它有一个很简单的认识，只要用一点工具，有一点机械帮助，我们就能极大地增强我们的能力。你们中的一些人可能以前听过这个故事。你可能会想，我是在哪里看到的？这个故事是苹果公司创立之初史蒂夫·乔布斯（Steve Jobs）经常讲的。他和苹果团队利用这个故事作为早期Macintosh的灵感来源。史蒂夫比较了这个故事，并说到：“人类是工具的制造者。”</p><p>&nbsp;</p><p>我们制造了像自行车这样的工具来增强我们完成任务的能力。就像自行车是运动的工具一样，计算机也是我们思维的工具。它增强了我们的能力、创造力、想象力和生产力。事实上，史蒂夫曾经用这个神奇的短语来形容个人计算机。他说：“计算机是思维的自行车”。这篇文章发表十年后的1983年，苹果公司发布了Macintosh，并掀起了个人计算的革命。当然，多年后的今天，我们仍然每天都在使用mac电脑。</p><p>&nbsp;</p><p></p><h1>2023——人工智能和语言模型</h1><p></p><p>那是1973年。现在是2023年，50年后，计算已经发生了很大的变化。如果《科学美国人》的工作人员再次进行这项研究，我敢打赌他们会在名单上再增加一个“物种”。对我们大多数人来说，这个“物种”在公众的想象中只存在了大约六个月的时间。我谈论当然是人工智能，或者具体来说是语言模型。</p><p>&nbsp;</p><p>自去年11月ChatGPT推出以来，人工智能和语言模型已经在全球范围内引起了公众的广泛关注。更令人兴奋的是，它们吸引了世界各地开发者的想象力。我们已经看到很多人将人工智能集成到他们的应用程序中，使用语言模型来构建全新的产品，并提出与计算机交互的全新方式。自然语言交互终于成为了可能，并且质量很高。但这存在局限性，也存在问题。对于任何使用过ChatGPT的人来说，我们都知道它的训练数据是2021年9月之前的，所以它不知道当前的事件。</p><p>&nbsp;</p><p>在大多数情况下，像ChatGPT这样的语言模型是根据训练中的记忆进行操作的，因此它们与当前事件或所有API、我们每天使用的自己的应用程序和网站无关。或者，如果你在一家公司工作，它不会连接到你公司的数据库和你公司的内部知识库等等。这使得语言模型的使用受到了限制。你可以写一首诗，可以写一篇文章，可以从中得到一个很棒的笑话，可以搜索一些东西。但如何将语言模型与外部世界联系起来呢？如何增强人工智能的能力，让它来代表你执行行动，让它做比它固有能力更多的事情呢？</p><p>&nbsp;</p><p></p><h2>概述</h2><p></p><p>如果计算机是思维的自行车，那么人工智能思维的自行车是什么？这就是我们要探讨的问题：一辆人工智能思维的自行车。我们将讨论GPT，这是OpenAI开发的一组旗舰语言模型，以及如何将它们与工具或外部API和函数集成，以支持全新的应用程序。我叫Atty。是OpenAI的一名工程师。Sherwin是我的搭档，我们是OpenAI的API团队的成员，共同构建了OpenAI API和其他各种开发者产品。</p><p>&nbsp;</p><p>我们将讨论三件事。首先，我们将讨论语言模型及其局限性。我们将快速介绍它们是什么以及它们是如何工作的。先培养下对它们的直观认识。然后还要了解它们的不足之处。其次，我们将讨论我们发布的一个全新特性，即使用GPT进行函数调用。函数调用是将OpenAI的GPT模型插入外部世界并让它执行操作的方式。最后，我们将通过三个快速演示样例来演示如何使用OpenAI模型和GPT函数调用功能，并将其集成到公司产品和辅助项目中。</p><p>&nbsp;</p><p></p><h2>大语言模型（LLMs）及其局限性</h2><p></p><p>Sherwin Wu：首先，我想对LLM做一个非常高层级的概述：它们做什么，它们是什么，它们如何工作。然后再谈谈它们开箱即用的一些限制。对于那些已经关注这个领域一段时间的人来说，这可能是你们都知道的信息，但我只是想在深入讨论细节之前确保我们都能达成共识。</p><p>&nbsp;</p><p>非常高层级的GPT模型，包括ChatGPT、GPT-4、GPT-3.5-turbo，它们都是我们所说的自回归语言模型。这意味着它们是巨大的人工智能模型，它们接受过庞大的数据集的训练，包括互联网、维基百科、公共GitHub代码和其他授权材料。它们被称为自回归，因为它们所做的只是综合所有这些信息。它们接受一个prompt，或者我们可以称之为上下文。它们查看prompt。然后它们基本上只是决定，给定这个prompt，给定这个输入，下一个单词应该是什么？它实际上只是在预测下一个单词。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6a/6a281b92260f77472c4dace8f5218988.png\" /></p><p></p><p>&nbsp;</p><p>例如，如果给定GPT的输入是，“the largest city in the United States is“（美国最大的城市是），那么答案就是New York City（纽约市）。它会一个字一个字地思考，它会说“New”、“York”，然后是“City”。同样，在更具对话性的环境中，如果你问它地球和太阳之间的距离是多少。GPT 已经从互联网上学过这个，它将输出9400万英里。它是根据输入逐个单词逐个单词思考的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1a/1a708f4455415a53608f886bd7cbdc35.png\" /></p><p></p><p>&nbsp;</p><p>在底层，它真正做的是每次输出单词时，都会查看一堆候选单词并为它们分配概率。例如，在最初的例子中，“美国最大的城市是”，它可能有很多候选城市，New代表“纽约”（New York），或者“新泽西”（New Jersey），或者其他什么，Los代表“洛杉矶”（Los Angeles），然后还有其他一些可能的例子。你可以看到，它确实认为“New York City”（纽约市）可能是正确的答案，因为New的概率为95%。在这种情况下，它通常会选择最有可能的结果，所以它会选择New，然后继续前进。这个单词出现后，我们现在就知道New是第一个单词，所以它对下一个单词是什么就有了更多的限制。</p><p>&nbsp;</p><p>我们可以看到，现在它认为New York（纽约）的可能性要高得多，但它也在考虑New Brunswick（新不伦瑞克）、New Mexico（新墨西哥）和New Delhi（新德里）等。直到完成第二个单词，这基本上是模型的叠加。它基本上知道答案是New York City，概率几乎是100%。但它仍在考虑其他一些剩余概率很低的选项，比如County（县）、New York Metro（纽约地铁）、New York Times（纽约时报），但最终它选择了City并给出答案。</p><p>&nbsp;</p><p>对于更机敏的LLM人士来说，这在技术上过于简单化了。我们并不是真正在预测单词，而是在预测token，比如单词片段，这实际上是一种更有效的表达英语的方式，主要是因为单词片段会在一堆不同的单词中重复，而不是单词本身会重复。但概念仍然是一样的。LLM在这种上下文中，很可能会连续输出一堆不同的token。就是这样，这就是这些语言模型的真正含义。了解了这一点，我认为让我们很多人感到惊讶的疯狂之处在于，我们只需预测下一个单词就可以走得很远。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/56/5673c0fe7089d2faab377baf358f7d0d.png\" /></p><p></p><p>&nbsp;</p><p>这张图表来自我们今年3月发布的GPT-4博客文章，它显示了我们最有能力的模型GPT-4在各种专业考试中的表现。这实际上只是GPT-4根据问题预测下一个单词。你可以看到，在很多不同的考试中，它的表现实际上和人类一样，甚至超过了人类的表现。y轴是考生的百分位数。在AP考试、GRE考试、LSAT考试、美国生物奥林匹克竞赛等一系列不同的考试中，它基本上处于第80个百分位，有时甚至是第90个百分位，甚至是第100个百分位。</p><p>&nbsp;</p><p>在这一点上，很多这样的测试我甚至都做不到，所以GPT-4远远超出了我自己的能力，而这只是来自对下一个单词的预测。这真的太酷了。你可以用它构建很多很酷的东西。任何一个已经学习了LLM一段时间的人都会意识到，我们很快就会遇到一些限制。当然，最大的一个是开箱即用的LLM或GPT实际上是一个装在盒子里的人工智能。它无法进入外部世界。它不知道任何其他信息。它就在那里，有它自己的记忆。感觉就像你在学校里参加考试时，只有你和考试，你只能根据记忆来回忆一些东西。</p><p>&nbsp;</p><p>想象一下，如果考试是开放的，你可以使用手机或类似的东西，你会做得更好。GPT今天真的只是在它自己的盒子里。正因为如此，作为工程师，我们希望使用GPT并将其集成到我们的系统中。限制GPT，不允许它与我们的内部系统对话，这对于你可能想做的事情来说是非常有限的。此外，即使它确实可以访问某些工具，因为语言模型是概率性的，有时也很难保证模型与外部工具交互的方式。如果你有一个API或其他你想要使用的东西，当前模型不能保证总是能与你API可能想要的输入相匹配时，这最终也会成为一个问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/25/2580bcf915d852712ba15dc55c330e14.png\" /></p><p></p><p>例如，如果我正在构建一个应用程序，并将此输入提供给GPT，基本上就是说，下面是一个剧本的文本，从中提取一些信息，并以这种JSON格式对其进行结构化。我真的只是给它一个剧本，让它推断出一种类型和一个子类型，以及其中的一些角色和年龄范围。我真正想要的是，我希望它能输出像这样的东西。就像JSON输出一样。</p><p>&nbsp;</p><p>也许这是一个关于哈利波特的浪漫故事之类的剧本。它知道这是浪漫的，青少年的浪漫，它看到罗恩（Ron）和赫敏（Hermione），并以这种JSON格式准确输出。这太棒了，因为我可以获取这个输出，现在我可以使用它并将其放入API中。然后我就像在我的代码中一样，一切都正常。问题是，它大概只有80%、70%的概率是这样的。</p><p>&nbsp;</p><p>在剩下的时间里，它会尝试并提供额外的帮助，做一些像这样的事情，它会说：“当然，我可以为你做。下面是你要求的JSON格式的信息。”这是非常有用的，但如果你试图将其插入到API中，它实际上室不起作用的，因为前面所有这些随机文本，你的API并不知道如何解析它。这显然是非常令人失望的。这不是你真正想要的。我们真正想做的是，帮助GPT打破常规，或者给GPT一辆自行车或另一套工具来真正增强它的能力，并让它无缝地工作。</p><p>&nbsp;</p><p></p><h2>使用GPT进行调用函数</h2><p></p><p>这就把我们带到了下一部分，那就是我们所说的GPT函数调用，这是我们发布的API的一个新变化，它使函数调用能够以一种非常一流的方式更好地使用我们的GPT模型。举个例子，如果你问GPT这样的问题，what's the weather like in Brooklyn today? （今天布鲁克林的天气怎么样？）如果你问一个普通的GPT这个问题，它基本上会说，“作为一个由OpenAI训练的人工智能模型，我无法提供实时信息。”这是真的，因为它实际上无法访问任何东西。它在一个盒子里。它怎么会知道今天天气怎么样呢？</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/76/76c19cc7f6ed1d6b67c222e0be0fc12f.png\" /></p><p></p><p>&nbsp;</p><p>这显然确实限制了它的能力，这是不可取的。我们所做的是更新了GPT-4和gpt-3.5-turbo模型或旗舰模型。我们收集了大量的工具使用和函数调用数据，根据这些数据对我们的模型进行了微调，使其真正擅长选择是否使用工具。最终的结果是我们发布了一组新的模型，这些模型现在可以为你智能地使用工具和调用函数。在这个特殊的例子中，当我们询问模型“今天布鲁克林的天气怎么样？”时，我现在能做的就是解析这个输入，同时告诉它一组函数，或者在本例中，告诉它它可以访问的一个函数，如果需要帮助，它应该尝试并调用这个函数。在本例中，我们将为它提供一个名为get_current_filther的函数。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/43/43e2a8a9cd6b458f9047cdbaa76a12a1.png\" /></p><p></p><p>它接收一个带有location（位置）的字符串，然后它就知道它可以使用这个。在本例中，在这个新的世界里，当你解析此输入时，GPT将表达它打算调用get_current_filther函数的意图。然后，你可以根据需要在自己的系统中自行调用该函数。假设你得到的输出是 “22 Celsius and Sunny”（22摄氏度和阳光明媚）。你可以将其解析回GPT，它会综合这些信息，并返回给用户说：the weather in Brooklyn is currently sunny, with a temperature of 22 degrees Celsius（目前布鲁克林天气晴朗，温度为22摄氏度。）</p><p>&nbsp;</p><p>稍微解释一下，真正发生的事情是GPT知道一组函数，并且它会智能地自行表达调用其中某个函数的意图。然后执行调用，并将其解析回GPT。这就是我们最终将它与外界联系起来的方式。为了进一步了解它在高层级上到底发生了什么，其实它仍然就像是一个来回，你的用户问了一个问题，发生了很多事情后，你对你的用户做出了回应。你的应用程序在底层实际做的事情将经历一个三步的过程，首先调用 OpenAI，然后使用你自己的函数，最后再次调用OpenAI或GPT。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/de/de2e19a01388973a0dc7a6ca59fe9d6a.png\" /></p><p></p><p>&nbsp;</p><p>第一步，显然是用户问了一个问题，在本例中，问题是what's the weather like in Brooklyn today?（“今天布鲁克林的天气怎么样？”）然后下一步是，在应用程序中，调用模型，调用OpenAPI，并非常具体地告诉它它可以访问的函数集以及用户输入。这是一个API请求的例子，目前它实际有效且可正常工作，任何具有API访问权限的人都可以尝试该操作。这是一个使用函数调用能力的curl示例。我们可以看到，这只是我们聊天完成端点的正常curl，这是我们发布的一个新的API端点，为我们的GPT-4和GPT-3.5模型提供支持。你curl该API。它会在模型中进行解析。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a0/a02129b0f8e597f1fc1f439cca209731.png\" /></p><p></p><p>在本例中，我们将在gpt-3.5-turbo-0613中进行解析，它代表6月13日，一个我们发布的模型。这是一个能够进行函数调用的模型。我们还在解析一组消息。对于那些可能不熟悉我们聊天完成格式的人，你可以将其解析到我们的模型中，基本上是一个消息列表，也就是对话记录。</p><p>在本例中，实际上只有一条消息，没有历史记录。它只是用户询问“今天布鲁克林的天气怎么样”。你可以想象，随着对话的变长，它可能是一个包含5到10条消息的列表。我们正在解析消息，模型将能够看到历史记录并对此做出回应。那么，这里的新事物就是函数。</p><p>&nbsp;</p><p>这是一个我们现在可以解析的新参数，我们在这里解析的是，我们列出了这个模型应该知道的一组函数，它应该可以访问的函数集。在本例中，我们只有一个函数，它就是get_current_tweather函数。我们在这里还放了一个自然语言描述。我们说这个函数可以获取特定位置的当前天气。我们还需要输入函数签名。并且我们告诉它有两个参数。一个参数是location（位置），这是一个字符串，包含城市和州，格式是这样的：旧金山，加州（San Francisco, California.）。另一个参数时unit（单位），即摄氏度（Celsius）或华氏度（Fahrenheit）。</p><p>&nbsp;</p><p>在这里首屏的下面，还有另一个参数，该参数表示唯一必须的属性是位置。从技术上讲，你只需要解析位置，这里不需要单位。我们将该请求解析到GPT，然后GPT将作出响应。在过去中，GPT可能只会以文本形式进行响应。它会说：“我不能这样做，因为我没有访问权限。”在本例中，我们的API响应的是调用天气函数的意图。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/23/2339e79558c3eda24de50f9a9e11bcd4.png\" /></p><p></p><p>&nbsp;</p><p>这里真正发生的事情是GPT凭自己的直觉，为了弄清楚今天的天气，我自己做不到，但我可以访问get_current_weither这个函数，所以我会选择调用它，所以我要表达要调用它的意图。此外，如果你还没有真正注意到的话，GPT在这里所做的是，它在这里构造参数。我们可以看到它在告诉我们，它想调用get_current_tweather，它想用参数位置（Brooklyn, New York；纽约布鲁克林）来调用该函数。</p><p>&nbsp;</p><p>它所做的就是看到函数签名，并为其创建请求。然后还算出布鲁克林在纽约，然后用这种方式构造字符串。它把这一切都弄清楚了。至此，GPT就表达了现在要调用函数的意图。下一步是，我们要弄清楚我们到底想要如何调用这个函数。我们可以根据特定参数从get_current_tweather的函数调用中获取相应的返回值。然后我们可以自己执行。它可以是本地的，在我们自己的Web服务器上运行。它也可以是系统中的另一个API，还可能是一个外部API，我们可以调用weather.com API。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/57/57bc52645179b986fb8dc2fe597ac591.png\" /></p><p></p><p>那么在这个例子中，我们调用了一些东西，可能是一个内部API，它返回的输出是我们看到的是22 degrees Celsius and Sunny（22摄氏度和晴天）。给定了模型的输出，就可以开始这个过程中的第三步，即调用模型，用函数的输出调用GPT，然后查看GPT想要做什么。在本例中，我谈论的是消息。这次，我们在向OpenAI API发送的第二个请求中添加了几条消息。最初，只有一条信息，那就是“今天布鲁克林的天气怎么样？”，现在再添加两条新消息来表示函数调用时所发生的情况。</p><p>&nbsp;</p><p>第一个基本上是对意图的重申，所以基本上是说助理或GPT想要用纽约布鲁克林的这个参数来调用get_current_tweather函数。然后，我们还添加了第三条消息，它基本上说明了我们所进行的函数调用的结果，因此这是get_current_filther的结果。然后，内联这里输出的数据，即温度“22”、单位“摄氏度”和描述“晴天”，然后将所有数据解析给GPT。在此时，GPT接收了它，并决定它想要做什么。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/52/52c47226a60424b8e67d5dfe8869db8e.png\" /></p><p></p><p>此时，模型已经足够智能了，它能够意识到“我将调用这个函数。这是输出。我实际上已经掌握了实际完成请求所需的所有信息。”它现在最终会通过文本方式来做出回应，并显示“今天布鲁克林天气晴朗，温度为22摄氏度”。这时，我们终于得到了GPT的最终输出。然后我们就可以回应我们的用户了。</p><p>&nbsp;</p><p>将所有这些放在一起，我们最终会得到我们理想中的体验，即用户询问“今天布鲁克林的天气怎么样？”我们的服务器会思考一下，GPT表达意图，我们完成完整的三步过程，调用了我们的函数。最终，用户看到的是“今天布鲁克林天气晴朗，气温为22摄氏度。成功”</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>演示1——将自然语言转换为查询</h2><p></p><p>Eleti：我们刚刚介绍了几个入门性的主题。首先，我们了解了语言模型是如何工作的，以及它们的一些局限性，因为它们没有所有的训练数据，它们没有连接到外部世界，它们的结构化输出并不总是可解析的。Sherwin还向我们介绍了新特性、函数调用和API的工作原理，以及如何将函数解析为API并获取输出，以及如何让GPT以面向用户的方式来总结响应。让我们通过几个演示来了解如何将所有这些组合起来，并将其应用到我们的产品和应用程序中。</p><p>&nbsp;</p><p>让我们从小事做起。我们将介绍的第一个示例是将自然语言转换为查询的内容。我们的示例是，假设你正在构建一个数据分析应用程序或商业智能工具，比如Tableau或Looker。你们中的一些人可能很擅长SQL，但我肯定不擅长了。大多数情况下，我只想问数据库，谁是顶级用户，然后得到响应。今天终于有可能了。我们将使用GPT，将给它一个称为SQL查询的函数，它只需要一个参数，即一个字符串“query”。</p><p>&nbsp;</p><p>它应该是针对我们数据库的一个有效SQL字符串。让我们看看它是如何工作的。首先，我们将为模型提供一条系统消息，描述它应该做什么。我们称之为SQL GPT，可以将自然语言查询转换为SQL。当然，模型需要访问数据库模式。在本例中，我们有两个表，用户表（users）和订单表（orders）。用户表有姓名、电子邮件和生日。订单表有用户ID、购买金额和购买日期。现在我们可以开始使用一些自然语言来查询数据库了。</p><p>&nbsp;</p><p>我们来问这样一个问题“根据上周的消费金额，找出排名前10的用户姓名”（get me the names of the top 10 users by amount spent over the last week.）。这是一个相当正常的业务问题，当然不是我可以立即编写SQL就能解决的问题，但GPT可以。让我们运行一下。我们可以看到它正在调用SQL查询函数。它有一个参数“query”，它创建了一个漂亮的SQL查询。它是选择了名称和金额的总和；它连接到订单表；并获取最后一周的订单，按总花费进行排序，并将其限制为10个。这看起来是正确且恰当的。让我们在数据库中运行一下它。我们得到了一些结果。</p><p>&nbsp;</p><p>当然，这是JSON格式的，因此用户无法渲染它。让我们把它发送回GPT看看它说了什么。GPT总结了这些信息，并表示“这些是按消费金额排名前十的用户。这是他们上周的花费，包括Global Enterprises, Vantage Partners。”这是一个了不起的用户可读的答案。</p><p>&nbsp;</p><p>我们要对GPT给予的帮助表示感谢。我们说“谢谢”，GPT说“不客气”。这是一种快速的方法，它可以了解完全的自然语言、完全的自然语言查询是如何将结构化输出转换为有效的SQL语句的，我们在数据库中运行该语句，获取数据，并将其汇总回自然语言。我们当然可以在此基础上构建数据分析应用程序。</p><p>&nbsp;</p><p>你还可以构建其他的内部工具。Honeycomb最近为Honeycomb查询语言构建了一个非常相似的工具。这是使用GPT和函数将自然语言转换为查询的一个示例。</p><p>&nbsp;</p><p></p><h2>演示2——调用外部API和多个函数</h2><p></p><p>让我们来做第二个演示。这是关于将外部API和多个函数一起调用的。我们提高了复杂度。假设我们正在纽约参加一个会议，我们想预订今晚的晚餐。我们将使用两个函数来调用GPT。第一个是get_current_location。它在设备上本地运行，比如在你的手机或浏览器上，并获取你所在位置的纬度（Lat）和经度（Long）。第二个函数是Yelp搜索，它使用Yelp的API，也就是流行餐厅评价应用程序，我们可以对纬度、经度和查询进行解析。</p><p>&nbsp;</p><p>我们来运行一下这个演示。本例中的系统消息相当简单。它所说的就是我们的私人助理，来帮助用户完成任务，把GPT变成了一个有用的助手。我说“我正在参加一个会议，想在附近吃晚饭，有什么选择吗？我的公司会支付这笔费用，这样我们就可以尽情享受了”。让我们用GPT来运行一下它，看看它是如何做的。</p><p>&nbsp;</p><p>当然，GPT不知道我们在哪里，所以它说get_current_location，我们将调用本地API来获取我们的纬度和经度。我们已经获取到了。是纽约的布鲁克林（Brooklyn, New York）的某个地方。我们会将其返回给GPT，看它怎么说。它已经有了所需的信息，现在它想调用Yelp，它说“纬度、经度和查询”，并且会说“美食”。这很好。这就是我想要的。让我们调用Yelp并获取一些数据。</p><p>&nbsp;</p><p>我们从Yelp API中获取了一堆餐馆。当然，我希望它能给出一个漂亮的总结，所以让我们再次运行它。它回复说“你附近有一些高档餐饮可选择，La Vara、Henry's End、Colonie、Estuary”。上面还写着“请检查营业时间，尽情用餐。”这听起来很美味。再次感谢GPT帮助我们组织今晚的晚宴。</p><p>&nbsp;</p><p>这是一个使用GPT和函数调用外部API（在本例中为Yelp API）以及协调多个函数的示例。它能够凭借推理能力解析用户意图，并依次执行多个步骤的操作，以实现最终目标。</p><p>&nbsp;</p><p></p><h2>演示3——将高级推理与日常任务相结合</h2><p></p><p>第三个演示，让我们来进一步加强。我们讨论了GPT-4是如何通过SAT和GRE的。如果可以的话，它一定比仅仅调用Yelp API或编写一些SQL更聪明。让我们来测试一下。我们都是工程师，我们每天都有很多事情要做。我们必须要做的任务之一是拉取请求审查。我们必须审查同事的代码。如果GPT能帮助我，减轻我的工作量，那就太棒了。我们将做一个GPT的演示，它可以进行拉取请求审查，有点像构建自己的工程师。</p><p>&nbsp;</p><p>我们只需要一个函数submit_comments。它接受一些代码并返回一个要审查的评论列表，包括行、数字和评论。你可以想象，我们可以将其发送到GitHub API或GitLab API，并发布一堆评论。当然，你还可以添加更多的功能以使其更强大。让我们看看它是如何做的。</p><p>&nbsp;</p><p>在本例中，prompt有点长。我们向上滚动着看下。我们说：“GPT，你记录、审查rot，查看其差异并生成有关更改代码的审查评论，保留所有代码审查评论和相应的行号。”我们在这里也卖弄下个性。我们说toxicity为10分之0，其实我们不希望这样。</p><p>&nbsp;</p><p>为了好玩，让我们在snark上尝试10分之8。我们都认识一些表现出这些个性的工程师。然后尝试10分之2。让我们从这里开始吧。下面是一些我们要审查的代码。它是SaaS应用程序中的一个API方法，用于更改用户的权限。让我们运行一下它。我们看看GPT对这些代码有何看法。它给出了三条审查意见。我们可以看到它调用了submit_comments函数，并且它输出了完全有效的JSON。让我们看看上面写着什么。它说，“我们现在是在捉迷藏吗？”，“当角色不在身体里时会发生什么？”，“你在那里添加一个了小转折，你就直接访问了第一项。”</p><p>&nbsp;</p><p>我们只是随意地加入了数据库会话，是吗？这有点粗鲁。我们也不想那样。让我们来解决一下这个问题。我现在要退出并稍微修改一下prompt。要执行该操作，请退出。在幕后，我所做的就是返回prompt并更改这些的数字：toxicity，然后下一个，snark，我们将其恢复到0。我们并不希望这样。让我们礼貌一点。</p><p>&nbsp;</p><p>我们要把礼貌做到十分之十。好吧，再给我三条审查意见。它再次使用完全有效的JSON调用该函数。它说，“很高兴看到你检索角色值。”；“你的错误信息简洁明了。”；“我很感激你对数据库的更改，做得很好。”。我希望有人能这样审查我的代码。感谢GPT，我将退出了。这是第三个快速演示。</p><p>&nbsp;</p><p>从本质上讲，它仍然在做同样的事情。它调用一个函数，给出一些prompt，并对其做出响应。我们看到的是GPT的推理能力。GPT认识代码。它已经看到了成千上万行代码，可以给出很好的评价。如果你抛开一些个性的东西，它会指出错别字，指出潜在的错误案例和边缘案例。我们在这里将高级推理与日常任务相结合。它确实非常擅长编码。它在考试方面也确实非常出色，它的智力应用范围也很广。这实际上取决于开发人员的创造力，将其应用于尽可能困难的任务，并在此基础上循环运行。</p><p>&nbsp;</p><p></p><h2>总结</h2><p></p><p>这是本次内容的快速总结。我们讨论了三件事。首先，我们讨论了LLM及其局限性。我们了解了LLM是如何工作的，它是token预测机。我们了解了它的局限性。它被时间限制住了。它并不总是输出结构化的输出等等。其次，我们了解了这个新特性，即使用GPT进行函数调用，这是对我们API和模型的更新。它允许模型表达何时调用函数的意图，并为我们构建有效的参数，然后在我们的终端上调用该函数。最后，我们浏览了一些演示。在某个时候，我会把公关的东西产品化。</p><p>&nbsp;</p><p>让我们回到开始的地方。我们谈到了史蒂夫·乔布斯的名言，他说“计算机是思维的自行车”。这对我来说确实如此，对你们所有人来说也都是如此。我们身处计算机行业，计算机改变了我们的生活。计算机增强了我们与生俱来的能力，给了我们更多的生产力、想象力和创造力。ChatGPT中的人工智能和语言模型还是个婴儿。它才出生几个月。我们有责任增强人工智能的思维，赋予它超越其内在推理能力的新能力，将其与工具连接，与API连接，并利用这一特性开发出真正令人兴奋的应用程序。</p><p>&nbsp;</p><p>原话对我来说非常有启发。我们永远无法公正地对待史蒂夫·乔布斯的名言。“我记得在我大约12岁的时候读过一篇文章，我想可能是在《科学美国人》上，他们在文章中测量了地球上所有这些物种的运动效率，它们从A点到B点需要消耗多少千卡热量。秃鹫赢了，位居榜首，超过了其他所有物种。人类排在榜单大约三分之一的位置，这对创造之冠来说并不是一个很好的表现。在那里有人有足够的想象力来测试人类骑自行车的效率。一个骑自行车的人把秃鹫吹走了，一直高居榜首。这给我留下了非常深刻的印象，我们人类是工具的制造者，我们可以制造出将这些固有能力放大到惊人程度的工具。对我来说，计算机一直是思维的自行车，它让我们远远超越了固有的能力。我认为我们只是处于这个工具的早期阶段，非常早期的阶段。我们只走了很短的一段距离，它仍处于形成阶段，但我们已经看到了巨大的变化。我认为，与未来100年发生的事情相比，这算不了什么。”</p><p>&nbsp;</p><p>就像50年前的计算机一样，我认为今天的人工智能也是如此。技术还处于起步阶段，所以我们很高兴看到它的发展。</p><p>&nbsp;</p><p></p><h1>问答</h1><p></p><p></p><h2>应对错误和失败的策略</h2><p></p><p>参会者1：我们应该如何应对错误和失败，你有什么建议的策略？以你的演示为例，在你构建SQL查询时，如果我提出的问题导致ChatGPT给出了一个在语法上完成正确，但在语义上完全不正确的SQL查询时，该怎么办？然后我向我的用户报告一些不正确的内容。很难告诉用户，这是错误的，但你有什么建议的策略来应对这个问题吗？</p><p></p><h1>&nbsp;</h1><p></p><p>Eleti：我认为首先，作为一个社会和这些语言模型的用户，我们必须了解它的局限性，几乎要围绕它的局限性来建立抗体。要知道输出可能是不准确的。我认为第二部分就像打开了盒子。我们已经将生产中的函数调用与ChatGPT集成在了一起。我们推出了一款名为插件的产品，它基本上可以做到这一点，它允许ChatGPT与互联网对话。我们要做的一件事是，如果最终用户愿意的话，那么所有的请求和响应都是可见的。这有助于信息部分。我个人认为SQL也是一个非常广阔的开放领域。我认为将其限制在仅在后端执行安全操作的知名API是一个好方法。你总是可以得到好的错误信息之类的。这些就是我即兴的建议。</p><p>&nbsp;</p><p></p><h2>LLM和langChain</h2><p></p><p>参会者2：有人尝试过做一些LangChain吗，它可以与LangChain一起使用吗？</p><p>Eleti：是的，事实上，LangChain、Harrison团队在我们推出一个小时后就发布了一个集成，所以它是有效的。</p><p>&nbsp;</p><p></p><h2>数据泄漏</h2><p></p><p>参会者2：这还暴露了一个泄漏问题。SQL示例就是一个很好的例子。如果有人读到这篇文章，他们对金融数据库进行SQL查询，并将其输入到gpt-3.5-turbo，我们基本上就泄露了数据。</p><p>如果你使用的是text-davinci-003或不同的模型，就会出现这样的问题，一些来自查询的数据会变成模型本身。在我看来，这个例子是极其危险的。</p><p>&nbsp;</p><p>Wu：实际上这存在一个误解，我认为我们最近没有作出很好地澄清，直到今年3月或2月，在我们为API提供的服务条款中，我们就说过“我们保留自己对API输入数据进行培训的权利”。我想这可能就是你所说的，就像你对一些SQL查询进行解析一样，它会在返回时以某种方式回到模型中。事实上，到目前为止，我们已经不再这样做了。根据我们的服务条款，我们实际上不会在API中对你的数据进行训练。我认为我们还没有把这一点说得非常清楚，所以人们对此非常偏执。到目前为止，还没有。你应该查阅我们的服务条款。我们不训练它。也就是说，解析的东西并不像企业级的那样。我们不会针对你的用户进行隔离。我们只是没有在自己的数据上训练它。这种围绕企业级数据隔离的特性显然很快就会出现。这一特定的安全层还没有出现。</p><p>&nbsp;</p><p>Eleti：我们不使用API数据进行训练。</p><p>&nbsp;</p><p></p><h2>函数调用的并行化</h2><p></p><p>参会者3：你展示的演示运行有点慢。我想知道，你们支持函数调用的并行化吗？就像现在你是串行的吗，你得到了这个函数签名，然后调用它，但假设ChatGPT说，三个函数应该同时被调用，这可行吗？</p><p>&nbsp;</p><p>Eleti：API实际上不支持多个函数调用。没有输出显示“调用这三个函数”。但你可以破解它。你只需要定义一个函数，让它调用多个函数，然后你提供一个签名，让模型调用它，即可实现调用多个函数，这完全是可行的。归根结底，我们仍然是使用模型的推理能力来输出一些文本。</p><p>&nbsp;</p><p></p><h2>模型上下文的预加载</h2><p></p><p>参会者4：在你给出的SQL示例中，你为其提供了一些可以访问的表。我们有没有办法可以让任何人的后续调用预加载所有上下文呢？</p><p>&nbsp;</p><p>Wu：有几个潜在的解决方案。我们有一个称为系统消息的功能，你可以在那里进行解析，它基本上设置了模型的整体对话上下文。但在当时的语境中它是完全颠倒的。目前，我们已经将上下文窗口增加到大约16000个token。你可以逐渐将更多内容压缩到系统消息中。该模型经过训练，会格外关注系统消息，以指导其做出回应。在本例中，Atty在系统消息中有两个表的模式。可以预见的是，你可以添加更多的内容来填充整个上下文。</p><p>&nbsp;</p><p>参会者4：这就是我们的预加载方式吗？</p><p>&nbsp;</p><p>Wu：是的，这是最简单的。还有一些其他的方法。你可以将它连接到外部数据源、数据库之类的。微调也是另一种选择。还有其他一些。</p><p>&nbsp;</p><p></p><h2>使用GPT进行可靠的函数调用</h2><p></p><p>参会者5：关于将GPT集成到不同的软件中。我在使用枚举时遇到了一些问题，当我要求它用英语、法语或德语做一些工作时，我使用的枚举有时会出现德语或法语。API函数也会发生这种情况吗？</p><p>&nbsp;</p><p>Eleti：是的，很不幸。模型在正常情况下以及在这种情况下都很容易产生幻觉。我们所做的基本上是对模型进行了微调，因此我们可以看到大约100000个关于如何可靠地调用函数的示例。它比你自己做的任何其他提示都要好得多。它仍然会生成参数，可能会输出无效的JSON，也可能会输出其他语言。为了防止这种情况，我们将进行更多的微调。我们也在探索一些低级推理技术来改进这一点。然后在你这边，你可以做prompt工程，只要提醒模型，不要输出德语，它会尽力的。</p><p>&nbsp;</p><p>Wu：看看它在这方面是否能做得更好，这会很有趣，尤其是如果你有一个函数签名，并且你明确列出了5个不同的英文枚举。较新的模型可能会更好，但也不完美。我不能百分百确定，不幸的是，我们没有跨英语、法语枚举那样的评估。这可能是一个值得思考的好问题，但我们很好奇，想看看它是否会变得更好。</p><p>&nbsp;</p><p></p><h2>GPT识别意图的能力</h2><p></p><p>参会者6：我有一个关于API理解意图能力的问题。函数调用是否有相似的温度（temperature）参数；如果我解析两个具有相似意图的函数，那么GPT对每个要调用的函数是否具有确定性；或者如果我多次询问，选择要调用哪个函数是否具有随机性？</p><p>&nbsp;</p><p>Eleti：随机性依然是存在的。归根结底，在底层，它仍然是一个token一个token地输出，选择要调用的函数。降低温度增加了确定性，但这并不能保证确定性。也就是说，API中有一个名为函数调用的参数，如果你知道你想让它调用哪个函数，实际上可以直接指定它，它肯定会调用该函数的。</p><p>&nbsp;</p><p></p><h2>函数调用权限</h2><p></p><p>参会者7：如果我们想限制某些用户进行某些函数调用，或者像你这样在这些SQL查询中访问某些表，你们有函数调用的权限吗，人们还需要实现他们自己的吗？</p><p>&nbsp;</p><p>Eleti：所有这些都会发生在你的服务器上，因为你拥有谁可以访问什么内容的完整上下文。这个API提供的只是GPT选择要调用哪个函数以及要使用哪些参数的能力。然后，我们希望你像对待任何其他客户端一样对待GPT的输出，因此对于不受信任的客户端输出，你可以在你的终端上验证其权限和内容。</p><p>&nbsp;</p><p></p><h2>思维链提示和约束采样</h2><p></p><p>参会者8：我只是想知道你是否可以详细说明一下这在底层发生了什么。这是底层的思维链吗？这是这些技术之上的一个有效的API层吗？</p><p>&nbsp;</p><p>Eleti：思维链提示是一种在给模型任务时的询问方式，首先，告诉我你要做什么，然后去做。如果你问“布鲁克林的天气怎么样？”它可能会说“我收到了一个天气请求，我将调用天气API”。然后它就这样做了。这是一种快速的工程技术。这是一个微调。随着插件的推出，我们收集了大约100000个用户问题和函数调用示例的内部和外部数据。这一切都在模型中进行了微调。这就是它的来源。</p><p>&nbsp;</p><p>我们还可以使用第三种技术，叫做约束采样，其中在token采样层，你可以确保预测的下一个token是值集中的一个。在JSON示例中，逗号之后必须是新行或类似的内容。我们可能会弄错，但是我们明白了，我们有语法要分配。这是我们正在探索的领域。这是从提示到微调再到更低层的东西的漫长旅程。这是让GPT输出可靠结构化数据的过程。</p><p>&nbsp;</p><p></p><h2>矢量数据库的兼容性</h2><p></p><p>参会者9：这可以与矢量数据库一起使用吗？我的想法是，我想根据我输入到向量数据库中的信息来约束信息，但它仍然能适用于函数逻辑？</p><p>&nbsp;</p><p>Eleti：是的，和以前一样好用。</p><p>&nbsp;</p><p></p><h2>函数调用是否公开可用？</h2><p></p><p>参会者10：我们今天就能使用它了吗？它现在对公众开放了吗？</p><p>&nbsp;</p><p>Wu：它是今天公开的，但有一个警告。它在gpt-3.5-turbo模型上可用。这里的任何人实际上都可以使用gpt-3.5-turbo访问函数调用，因为这是普遍可用的。它也可以在GPT-4 API上使用，但不幸的是，它仍然处于等待名单中。如果你不在该等待名单中，并且你可以访问GPT-4 API，那么你实际上可以使用GPT-4进行此操作。它在这方面做得更好。进度有点慢。如果你仍在等待名单上，或者你无法访问GPT-4 API，你今天可以在GPT-3.5-turbo上试用。</p><p>&nbsp;</p><p>查看更多<a href=\"https://www.infoq.com/transcripts/presentations/\">演示文稿字幕</a>\"</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/presentations/bicycle-ai-gpt-4-tools/\">https://www.infoq.com/presentations/bicycle-ai-gpt-4-tools/</a>\"</p>",
    "publish_time": "2024-01-25 14:38:25",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "代码屎山噩梦加速来袭，都是AI生成代码的锅？",
    "url": "https://www.infoq.cn/article/H3NJGImSe4aZA5i76HTL",
    "summary": "<p>“周边很多程度员一直在使用，都是用上就离不开了！”知乎上，在“大家现在使用哪些AI辅助编程工具？节省了多少工作量？”话题下，答主“以默”说道。</p><p>&nbsp;</p><p>按照“以默”了解的情况，AI辅助编程工具估计至少能帮程序员减少30%的工作量。对于工具，他表示“当然首选GPT，也可能是唯一答案！国产在这方面差距很大。”“综合能力水平: 4.0&gt;3.5&gt;国产大模型。模型能力越强，越好用！”</p><p>&nbsp;</p><p>现在用AI辅助编程已经是很多程序员的选择，但随着AI软件开发迅速普及，代码质量又会随之受到怎样的影响？⻓期代码研究员 Adam Tornhill 就曾表示担忧，AI辅助编程的主要挑战在于，它非常容易生成大量本来就不应该编写的代码。</p><p>&nbsp;</p><p>根据最新研究，结果确实令人忧心。除了代码返工（即代码在添加后不久即遭删除）以外，重复代码比例升高等问题愈发严重。</p><p></p><h2>主要让“添加代码”</h2><p></p><p>&nbsp;</p><p>自2021年6月推出beta版以来，GitHub Copilot已经掀起AI编码的一波流域。据公司CEO Thomas Dohmke介绍，该软件目前拥有超100万付费订阅开发者，已经让开发任务的速度提高了55%。而且在启用Copilot的文件中，有46%的代码量是由AI生成。</p><p>&nbsp;</p><p>根据来自开发者分析公司GitClear的研究，基于从1.5亿行已更改代码中收集到的数据，调查发现其中三分之二来自以匿名方式共享数据的私营企业，三分之一则来自谷歌、Facebook及微软等技术大厂的开源项目。</p><p>&nbsp;</p><p>这项研究着眼于经过添加、更新、删除、复制及移动的代码，并排除掉GitClear预先定义的“噪音”，例如被提交至多个分支的相同代码、空行及其他无意义的代码行。</p><p>&nbsp;</p><p>但GitClear的研究将关注重点放在代码质量、而非数量上，并观察到AI助手主要是在提供“代码添加建议，但很少涉及代码的更新、移动或删除建议”。</p><p>&nbsp;</p><p>研究人员还指出，“根据奖励设计，代码建议算法更倾向于提供最可能被采纳的建议”。尽管看似有理，但这明显忽略了代码简洁、易读等特性的重要意义。</p><p><img src=\"https://static001.geekbang.org/infoq/d6/d67e4520e1e054e976fbe8d8bf32b403.png\" /></p><p>GitClear分析得出的代码更改趋势</p><p>&nbsp;</p><p>对代码质量做精准衡量并不容易。研究人员也的确发现了一些变化趋势，表明代码的添加、删除、更新和复制/粘贴量大大提高，但代码移动比例却有所下降。他们还发现代码返工率大幅增加，从2020年的3.3%提升到目前的7.1%。</p><p>&nbsp;</p><p>一般来讲，代码移动是开发者进行代码重构的关键指标。具体来讲，就是在改进代码设计和结构的同时，确保不改变行为。</p><p>&nbsp;</p><p>研究人员初步猜测这种趋势可能与AI编码技术的日益普及相关，但真实原因仍有待验证。他们还严厉批评了大量复制/粘贴代码的负面影响，称“这种对AI生成代码的无脑使用，将对代码的长期可维护性产生灾难性的影响”。</p><p>&nbsp;</p><p>但过度使用复制/粘贴并不算是新问题。开发人员之所以这样做，很可能是因为无脑照搬比调整和重用现有代码更快、更省事，或者同一项目下多位开发者之间沟通不畅，抑或是从开发示例/编码问答网站上“抄袭”了太多内容。</p><p>&nbsp;</p><p>GitClear研究人员并没有具体讨论应如何解决调查中发现的这些问题，而是转向了“后续研究问题”。但他们也建议工程部门领导者应当“监督提交数据，并考虑其对未来产品维护造成的影响”。</p><p>&nbsp;</p><p>这次研究可能在一定程度上让那些担心被AI工具取代的开发者们感到放心。代码分析公司CodeScene最近开展的一项AI代码重构研究也得出结论，“在编码环境中，AI还远无法取代人类；当前的AI太容易出错，且完全不具备安全修改现有代码的水平。”</p><p></p><h2>代码质量，谁更应该关注</h2><p></p><p>&nbsp;</p><p>可以肯定的是，AI编码助手绝不会就此消失，反而是像一切新工具那样不断改进，并由开发者学习优化思路、改善使用效果。</p><p>&nbsp;</p><p>其实，现在开发者们也已经意识到了代码质量的问题。在GitHub 与 Wakefield Research 的调查报告中，当被调查的程序员被问到，“在积极使⽤⼈⼯智能时，应该根据哪些指标进⾏评估？”“代码质量”成为最关⼼的问题，</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/18/18784e8d5e1a34cd6205d5b389bb4bd3.png\" /></p><p></p><p>但另一方面，更应该关注代码质量问题的其实是公司领导层。</p><p>&nbsp;</p><p>“我公司的领导曾经就动过用代码行数衡量每个人的工作量这种想法。 研发人员每周代码量至少在500行以上，一个月必须在2000行以上。 甚至他还搞来了第三方的测算软件，输入git账号来计算你的代码量。然后在一次技术会议上，全体组员忍无可忍的怼了技术总监。“知乎上有网友分享到。</p><p>&nbsp;</p><p>一般公司考核代码量相对简单直观，但是代码质量考核就不那么容易了：满足用户需求，</p><p>合理的进度、成本、功能关系，具备扩展性和灵活性等都不是那么可量化的指标。</p><p>&nbsp;</p><p>但<a href=\"https://dl.acm.org/doi/abs/10.1145/3524843.3528091\">关于代码质量对业务影响的研究</a>\"表明，一般来说，由于技术债务和糟糕的代码，公司平均浪费了开发人员 23%～ 42%的时间。但似乎这还不够令人感到担忧，关于<a href=\"https://research.chalmers.se/publication/511450/file/511450_Fulltext.pdf\">软件开发人员由于技术债务而导致的生产力损失</a>\"的研究还发现，开发人员经常“被迫”引入新的技术债务，因为公司一直在用代码质量换取新功能等短期收益。</p><p>&nbsp;</p><p>现在企业为“降本增效”引入AI辅助工具是可以理解的，但需要注意扬长避短、合理使用。根据Alphacodium的说法，大模型生成单个冗长函数的结果很差，代码通常包含错误或逻辑错误，大模型也往往在需要思考、推理并做出严格、重要决策的代码任务中遇到困难。</p><p>&nbsp;</p><p>代码生成与其他对话不同，它需要匹配目标语言的精确语法、识别最佳路径和边缘情况、关注问题规范中的众多小细节，并解决其他特定于代码的问题和要求。因此，在自然语言生成中许多优化和技巧可能对代码任务无效。</p><p>&nbsp;</p><p>如何让AI辅助编程更好地帮助开发者，也需要各方努力。</p><p>&nbsp;</p><p>参考链接：</p><p>&nbsp;</p><p><a href=\"https://devclass.com/2024/01/24/ai-assistance-is-leading-to-lower-code-quality-claim-researchers/\">https://devclass.com/2024/01/24/ai-assistance-is-leading-to-lower-code-quality-claim-researchers/</a>\"</p><p><a href=\"https://www.zhihu.com/question/640036429\">https://www.zhihu.com/question/640036429</a>\"</p><p><a href=\"https://zhuanlan.zhihu.com/p/626643788\">https://zhuanlan.zhihu.com/p/626643788</a>\"</p><p><a href=\"https://github.blog/2023-06-13-survey-reveals-ais-impact-on-the-developer-experience/\">https://github.blog/2023-06-13-survey-reveals-ais-impact-on-the-developer-experience/</a>\"</p>",
    "publish_time": "2024-01-25 15:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "蚂蚁集团去中心化的高性能存储服务 LiteIO 正式开源",
    "url": "https://www.infoq.cn/article/1LMBLffVZJMetQkAXDMd",
    "summary": "<p></p><p>在传统分布式存储盛行的时代，LiteIO 作为点对点块设备服务的代表作，在蚂蚁集团内部实践中，带来了极大的业务与技术收益。并在近期由阿里云软硬件结合研发团队与蚂蚁集团数据库技术团队联合撰写的论文《LightPool: A NVMe-oF-based High-performance and Lightweight Storage Pool Architecture for Cloud-Native Distributed Database 》，被 HPCA‘24 论文评审结果收录，CCF-A 类论文也肯定了 LiteIO 的技术先进性。</p><p></p><p>趁着这个机会，我们非常荣幸的宣布蚂蚁集团去中心化的高性能存储服务 LiteIO 正式开源。将我们的技术与全世界的开发者共享，激发更多的创意和想法，我们相信，对于数据库、存储产品类有状态的、有产品层多副本能力的产品，需要 LiteIO 这样的点对点技术来适配当下的 FinOps。</p><p></p><p>我们希望吸引更多社区的想法，只有通过开放和协作，LiteIO 才能够迎接更多的挑战，解决更多的问题，并为用户带来更多的价值，让 LiteIO 项目走得更远，成为云原生时代，存储使用的一种标准范式。</p><p></p><p>开源项目仓库：<a href=\"https://github.com/eosphoros-ai/liteio\">https://github.com/eosphoros-ai/liteio</a>\"</p><p></p><p></p><h2>“什么是 LiteIO ？”</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/57/575e0c24568f7dd06438726db99a6fdf.jpeg\" /></p><p></p><p>LiteIO 是一款高性能、易扩展的云原生块设备服务，专为超融合架构下的 Kubernetes 设计。在蚂蚁集团内部孵化 3 年并大规模应用在生产环境，为蚂蚁集团全数据型、存储型产品提供稳定、高效、易扩展的磁盘服务。</p><p></p><p>LiteIO 是将本地磁盘 / 逻辑卷，通过网络的方式共享给远程其他服务器使用，结合云原生 Kubernetes 的调度，将一系列磁盘统一管理、池化的通用技术。点对点的技术设计，相较传统分布式存储，有效地控制住硬件故障所带来的爆炸半径，同时去除存储冗余，有更多使用空间。</p><p></p><p></p><h4>01 设计背景</h4><p></p><p></p><p>在降本增效的时代，FinOps 显得格外重要，尤其像蚂蚁集团这种存储服务器规模庞大的体系，全局 1% 的存储利用率提升都会带来巨大的成本经济收益。因此需要再成本优化、保证通用性的同时稳定性不降。</p><p></p><p>数据库是一种重 IO 的软件系统，对于 IO 的稳定性和性能要求极高，一般生产系统都将数据库部署在本地磁盘的服务器上，这将带来两个问题：</p><p></p><p>利用率不均：IO 密集型和计算密集型的 workload 不同，这就会出现一台机器计算用完而存储富裕，亦或者存储用完计算还富裕，且通过调度也很难做到全局最优解。扩展性差：当出现存储不足，需要 scale up 存储，不得不通过迁移的手段换一台更大存储的服务器，拷贝数据的过程长。</p><p></p><p>传统分布式存储也是一种不错的解决方案，但在数据库领域，它将带来几个方面的问题：</p><p></p><p>副本数上升（成本）：分布式存储的优势在于通过 EC、多副本技术将存储池化，对于单硬件故障有很好的保护，但通过 EC、多副本技术造成单份数据副本在此架构下副本数将大于 1，往往副本数在 1.375~2 之间。数据库作为业务服务重要的组成，往往在上层有异 AZ、异地容灾的要求，在另一个 AZ 已经有数据库层面的备副本。总数据副本数会增加。爆炸半径大（稳定性）：分布式存储一般有一层中心式的 Meta 层，故障将带来全局性异常。</p><p></p><p></p><h4>02 设计思路</h4><p></p><p></p><p>LiteIO 采用去中心化的设计思路，基于 SPDK 数据引擎以及高性能 NVMe-over-Fabric 协议，将计算节点直接连到远程存储节点，通过高效的协议和后端 I/O 轮询，提供接近本地磁盘的高性能。点对点的设计配合 K8S 的调度控制，有效的控制单硬件故障所影响的服务。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/12/12e052c0c11da2ad1f8e0646742d47e0.png\" /></p><p></p><p></p><h4>03 FinOps</h4><p></p><p></p><p>基于 LiteIO，可以将服务器中无法分配的存储，按需分给远程计算节点使用，同时全局配合调度，将全局存储池化，从而提升全局的存储利用率。</p><p></p><p>例如有两种型号的服务器，计算密集型 96C 4T，存储密集型 64C 20T，假设存储机型的 CPU 已经分配完还剩 5T 磁盘，计算机型还有 CPU 但无磁盘可分，使用 LiteIO 可以将计算机型的 CPU + 存储机型的剩余磁盘组合成新的容器提供服务，同时提升了计算、存储利用率。</p><p></p><p></p><h4>04 通用存储计算分离</h4><p></p><p></p><p>LiteIO 是一个通用的存储服务技术，作用于存储逻辑卷，配合 K8S 上层容器或应用看到的和本地磁盘无差别，不论是直接读写块设备 bdev 还是将块设备做成任何文件系统均可以，不需要上层服务做任何修改，不论是 OceanBase、MySQL、PostgreSQL 这样的数据库，或者 Java、Python、Go 写的应用服务均可以将它用作一块普通磁盘使用。</p><p></p><p></p><h4>05 Serverless</h4><p></p><p></p><p>LiteIO 的通用的存储计算分离能力，使得 Scale 变得无比简单。配合感知与调度系统，部署一个 MySQL 实例就天然具备了 Serveless 能力。当 MySQL 的算力不够时，通过 LiteIO 将 MySQL 存储挂到一台更大算力的容器即可快速完成 scale up。当 MySQL 存储空间不足时，从其他存储节点挂一块磁盘即可完成无损扩容。</p><p></p><p></p><h2>\"技术特性 \"</h2><p></p><p></p><p></p><h4>01 高性能协议</h4><p></p><p></p><p>LitelO 使用 NVMe-oF 协议来提升性能，NVME-oF 协议可以充分利用新兴 NVMe 设备的固有并行性和多队列功能。而 iSCSI 在访问 NVMe SSD 时，性能损失高达 40％，并在协议转换等其他操作时也会消耗多于 30％的 CPU 资源。NVMe-oF 在性能方面优于 iSCSI，可以提供接近本地连接的 NVMe SSD 的性能。因此，在 LiteIO 中采用 NVMe-oF 可以最大程度地减少访问存储池中的存储资源时的开销，以提供接近原生磁盘的高性能。LiteIO 采用了 NVMe over Fabric（TCP）作为远程存储协议，以便集群中的其他节点访问存储资源。</p><p></p><p></p><h4>02 简化的 IO 链路</h4><p></p><p></p><p>传统分布式存储架构下，一个 Write IO 需要经过查询元数据、写元数据、写多副本数据三个过程，整个过程需要多次网络交互；而在 LitelO 架构下，由于单副本机制，点对点访问，前端 bdev 和后端 vol 一一映射，不需要额外的 rootserver 或者 metaserver 来管理全局元数据，IO 链路中只有一次跨网络访问，同时也不需要考虑多副本写带来的数据传输延迟，数据放大的问题，使得 LitelO 有更高的 IO 吞吐和更低的 IO 延迟</p><p></p><p></p><h4>03 零拷贝</h4><p></p><p></p><p>在访问本地磁盘时，I/O 请求和数据在 NoF-Initiator 和 NoF-Engine 之间通过 tcp-loopback 传输，但是这个过程涉及许多冗余的数据拷贝。为了消除这些拷贝并减少 CPU 开销，我们提出了一种新颖的零拷贝传输方式，用于 LiteIO 的本地访问。对于 I/O 请求，零拷贝传输采用 NoF-Initiator 和 NoF-Engine 之间的共享内存。对于数据，我们提出了一种 DMA 重映射机制，使本地存储设备可以直接访问应用程序缓冲区。零拷贝传输抛弃了 TCP 堆栈，并消除了用户缓冲区和内核之间的冗余数据拷贝，实现了访问本地存储资源时接近本地性能的效果。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b3/b390a1e035ee22d4b101c08fcd356f3c.png\" /></p><p></p><p></p><h4>04 热升级</h4><p></p><p></p><p>充分考虑到作为数据链路上的关键一环的 LiteIO 也会面临功能升级，我们实现了在升级 LiteIO 的过程中，让前端业务无感，IO 短时间抖动（&lt;100ms），同时机头挂载的 nvme 盘符不会发生改变。</p><p></p><p>Target 整体框架如下图所示，在热升级期间必须保持 nvmf 的网络连接不可中断，否则 host 侧会感知并去重连或者删除盘符，热升级采用旧的 target 程序 fork 新的 target 程序并加载新的二进制文件来实现，整个热升级过程中 IO 不可丢失，新旧进程的切换速度要快。基于热升级框架的简单性设计原则，热升期间下图中绿色的 TCP 或 RDMA 连接为必须保持的上下文，其他模块均无需保存上下文状态，网络连接的保持通过父子进程继承文件描述符的方式实现。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7f/7f13f8d5651f349f6c8c07790735730c.png\" /></p><p></p><p></p><h4>05 热迁移</h4><p></p><p></p><p>卷热迁移特性是为了在不影响业务的情况下，将卷的数据从原 Target 迁移到新的 Target，当迁移完成时由 Host 端完成链路的切换，从而实现业务无感切换到新的 Target。</p><p></p><p>热迁移过程中，将原 Target 的数据发送到新 Target 采用的方法是多轮循环迭代。每一轮开始前都会从卷获取一份 data map，然后根据这个 map 进行数据的拷贝。初始轮可能需要拷贝较多的数据，后续每一轮只需要拷贝上一轮迁移过程中新修改（write, discard）的数据。在保证迁移带宽大于新写入数据带宽的前提下，经过多轮拷贝后原 Target 和新 Target 之间的数据差异会逐渐缩小，从而可以停 IO 进行最后一轮的拷贝。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/4e/4e4df0d93dd0b227d39e1787fb710be5.png\" /></p><p></p><p></p><h4>06 快照</h4><p></p><p></p><p>LiteIO 对接了 CSI 的 Snapshot 相关的接口，允许用户使用 K8S 社区的 Snapshot 资源对 LiteIO 卷创建快照。快照能力与底层数据引擎有关，LiteIO 支持两种引擎：LVM 和 SPDK。LVM 的快照能力是 VG/LV 提供的， NoF-Engine 的快照能力是 SPDK LVS 提供的。LVM 和 SDPK 都是单机引擎，要求 Snapshot 和 原始 LV 必须在同一台机器，这就意味着，在创建原始 LV 时，就需要预留一定空间给快照，如果没有预留空间，则无法保证创建 Snapshot 一定成功。</p><p></p><p>LiteIO 对接了 CSI 的 ExpandVolume 相关接口，用户可以通过修改 PVC 磁盘空间，实现磁盘在线扩容。对于 LVM 引擎，LV 扩容无需修改，NoF-Engine 暴露远程盘的流程中新增了 bdev_aio_resize RPC 调用，实现了远程盘的在线扩容。扩容同样有一些限制，原因也和快照一样，由于 LVM, SPDK 都是单机引擎，无法保证单机上有足够空间扩容。</p><p></p><p></p><h4>07 多盘</h4><p></p><p></p><p>点对点的数据链路模式，不可避免还是会产生一些存储资源碎片。LiteIO 支持将这些碎片组合起来，变为一个卷供业务使用。这也带来一个故障率提升问题，假设提供碎片的任意一个节点故障，则这个卷不可用。内部恰好有这样一个业务 LDG 可以容忍这样的故障率，物尽其用。LDG(logic data guard) 设计旨在构建常态化逻辑主备数据库，提供一站式的主备库生命周期管理和应用使用管控平台，为提升稳定性，减小运维过程中由于升级，维护，意外等产生的数据风险进行规避, 同时提升数据操控的能力。</p><p></p><p></p><h4>08 Thin provisioning</h4><p></p><p></p><p>LitelO 还提供 Thin provisioning 能力，在单机维度实现存储的超卖，适合于像 Mysql 等存储非预填充空间的存储产品使用，Thin provisioning 结合热迁移能力，可以在单机存储空间不足时，快速无缝迁移数据到空间空闲的节点；由于 LitelO 不是分布式存储架构，对 Thin provisioning 功能的使用需要精确控制超卖比例和和超卖资源总量，保障空间不足时能快速迁移，避免业务受损</p><p></p><p></p><h2>\"实践落地 \"</h2><p></p><p></p><p>LiteIO 广泛地应用在蚂蚁集团数万台生产服务器，整体提升了 25% 的存储利用率，极大地优化了资源服务成本。与本地存储相比，LiteIO 带来的额外 IO Latency 仅约为 2.1 us。其通用的存储计算分离架构，不仅服务于数据库产品，同时也为蚂蚁其他计算产品、应用服务提供了存储计算分离以及 Serverless 的能力。配合热升级、热迁移、Kubernetes 生态，使其在日常运维中不增加额外的运维负担。快照、多盘聚合等能力让其有更多灵活的使用与玩法。针对 LiteIO 在蚂蚁集团的最佳实践，后续有系列文章分享，敬请期待。</p><p></p><p>今日好文推荐</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651194503&amp;idx=1&amp;sn=50355b06c918ff3a05a59349519a6f3a&amp;chksm=bdbbfcd48acc75c24b77b624b23779e46a342a1624eb0d2123ebe7e2dc8b79e51bc9bd143617&amp;scene=21#wechat_redirect\">Apache 顶级项目 MXNet 退役！大神李沐创办、亚马逊首选深度学习框架如何从大厂“宠儿”到落入“冷宫”？</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651194286&amp;idx=1&amp;sn=f013aa5e430eefdb4ae0d3aa20d1ff24&amp;chksm=bdbbfbfd8acc72ebbcf727db172add001c4142323e93a15149d9cd63f2a2f46ac7f218c60421&amp;scene=21#wechat_redirect\">“印度 CEO 毁了谷歌！”大裁员引发谷歌元老集体怀旧：20 年前为梦想而战，20 年后混口饭吃</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651194221&amp;idx=1&amp;sn=a3c659847ce4bdb38cda2128822319ce&amp;chksm=bdbbfb3e8acc722822b79a5040bcb29e317df0c37afe56bcc339cca06ed9ad56640993d9d10f&amp;scene=21#wechat_redirect\">中国开源，又一次让人失望了</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651194220&amp;idx=1&amp;sn=ea3097e47d0cf652f6e70f8c68d9dde1&amp;chksm=bdbbfb3f8acc722913b73454d48eea22bf8c6bf0e48698879fb906d01bf0b1d68e790507eead&amp;scene=21#wechat_redirect\">TikTok 员工加速“出海”，薪资翻倍；老外控诉中国科技巨头抄袭：反正官司打不赢，不费那个劲了；快手上市后首次整体盈利｜Q资讯</a>\"</p><p></p><p></p><p></p>",
    "publish_time": "2024-01-25 15:05:11",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Bonree ONE技术实践：如何用5台机器资源支撑起2000探针同时起跑？",
    "url": "https://www.infoq.cn/article/R9fJP6k6OMMomRuHbzmI",
    "summary": "<p></p><h2>背景</h2><p></p><p></p><p>日志、指标和调用链是可观测性取得成功的三要素，而这些的实现离不开数据采集，探针采集并上报数据，后端服务接收后对数据进行处理分析，从而达到可观测的目的。通常，服务器性能数据、服务相关数据、服务之间的调用等数据经由探针采集上报，经过ETL处理后，成为可观测性分析中的重要依据。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/53/53faac546c822ea88af9c75b9e52b432.png\" /></p><p></p><p>探针采集的数据量大小依赖两个要素：</p><p></p><p>采样率：采样率越高，数据量越大，对应可观测性分析会更加全面。业务调用量：当业务服务调用频率越高， 相应的数据量越大，对应可观测性分析会更加复杂。</p><p></p><h2>2000探针难在哪儿？</h2><p></p><p></p><p>由于私有化部署资源有限，需要尽可能多的满足企业监控需求，因此博睿数据的内部测试会以5台机器的集群作为部署标准，在资源固定的前提条件下，随着探针量的增多，主要难点如下：</p><p></p><p>业务场景存在峰值波动，高峰期的服务调用是低峰期的2倍+业务数据是多种业务场景同时存储，常见的涉及调用链数据、指标数据、服务快照数据等5台机器是混合部署多种服务，比如数据接入的controller服务、报警服务、业务查询服务、数据调用链存储、数据快照存储、数据指标存储、消息中间件等，在更大数据量写入的情况下，针对CPU、内存、磁盘IO的消耗都是抢占式的，影响服务的稳定性。</p><p></p><h2>如何优化瘦身？</h2><p></p><p></p><p>针对以上难点，首先想到的就是瘦身，即降低服务组件的数量，减少服务资源抢占的情况。其次是业务存储迁移，弃用高消耗组件，使用低消耗组件满足业务需求。最后在合理的数据存储方案的前提下，优化存储服务本身的性能，满足业务查询稳定性。</p><p></p><h3>降低组件数量</h3><p></p><p></p><p>hadoop存储套装节点数据量比较多，而且是java服务，资源消耗较大，内存需求较大。hadoop的主要业务方是AI服务，AI团队基于自研的数据处理框架，打造了全新一代的swiftAI服务，组件种类只有1个，部署服务最少只需要2个。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7b/7bc02b0db2a5a36f000b2b95ef572220.png\" /></p><p></p><h3>业务存储优化</h3><p></p><p></p><p>当前APM业务的存储分为三大块：指标数据、调用链和快照。目前主要使用三种不同的存储系统分别来支撑，指标数据存储在clickhouse、调用链使用ES，快照数据存储在自研的对象存储系统中。在实际的业务场景中，会交叉访问多种存储引擎，在资源估算时，没有一个合理的尺度来衡量资源的上下界。在单台机器上，如果部署多种存储引擎，势必会对服务稳定性产生影响，所以，减少APM业务的存储组件，成为一个可行性较高的方案。</p><p></p><p>探针调用链数据基于ES来存储，有以下痛点：</p><p></p><p>调用链数据与关联的快照数据写入时机存在不一致，基于ES的数据写入存在延迟。ES消耗资源较大，在CPU 和 IO上消耗较多，影响其他服务稳定性。ES的查询效率不稳定，随着数据量越来越大，甚至出现无法查询出数据的问题。</p><p></p><p>探针调用链快照数据基于对象存储系统来存储，有以下痛点：</p><p></p><p>写入不稳定，存在毛刺。对cpu 和 IO消耗较大，容易触达瓶颈。</p><p></p><p>针对以上两个组件的明显痛点，迁移数据到clickhouse进行存储，获益如下：</p><p></p><p>调用链数据和关联的快照数据同时写入clickhouse，保证关联数据的一致性。clickhouse写入稳定，即使是针对挽回数据，资源消耗较小。clickhouse读取稳定，clickhouse支持查询熔断、资源限制等手段，提高clickhouse查询稳定性。基于合理的攒批策略，clickhouse整体资源消耗平稳，毛刺点波动很小。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c5/c57f44453d67c976229d73dd57fd0068.png\" /></p><p></p><h3>存储服务优化</h3><p></p><p></p><p>相关的业务存储进行了聚焦，那么势必会对clickhouse服务产生影响， clickhouse服务的优化以及运维监控就显得更加重要。</p><p></p><p>在优化方面，我们从以下三个方向着手：</p><p></p><p>服务参数调优</p><p></p><p>max_bytes_before_external_group_by：通过维度聚合查询时，当 RAM 消耗超过这个阈值， GROUP BY 会把多余的临时数据输出到文件系统并在磁盘进行处理计算，通常会建议配置成当前服务内存的80%。max_bytes_before_external_sort：涉及数据排序时，当 RAM 消耗超过这个阈值，ORDER BY 会把多余的临时数据输出到文件系统并在磁盘进行排序计算，通常会建议配置成当前服务内存的80%。max_memory_usage：用户单条查询可以使用的最大内存，通常会建议配置成当前服务内存的80%。max_execution_time：单条查询可以执行的最长时间，这个根据业务响应时间的上限来定。</p><p></p><p>物化视图、索引、projection的合理使用</p><p></p><p>针对不同的场景，使用不同的加速手段，解决查询效率的问题。</p><p></p><p>高频查询要充分利用主键索引。主键索引满足不了的高频查询，借助索引来加速。涉及排序操作，利用projection和物化视图来加速，优先使用projection。无法使用projection的场景，使用物化视图。</p><p></p><p>监控、容错的支持</p><p></p><p>为了解决多业务接入带来的复杂影响，需要对集群有充分的监控，且在容错性上需要考虑更多因素。</p><p></p><p>监控首要跟踪的监控是写入和读取两个方向，比如每分钟写入量，写入耗时、查询QPS等，针对特定敏感业务可以个性化跟踪。针对节点本身的状态信息进行监控，比如服务负载、merge任务数、parts数量等，这些指标可以及时发现服务的稳定性风险。针对集群的均衡性进行监控，比如parts数据同步的延迟时间、各个节点的查询均衡性、各个节点的写入均衡性等，避免集群倾斜。容错性写入节点单节点异常，不影响整体服务写入。clickhouse单节点异常，不影响整体集群的写入也不影响读取。</p><p></p><p></p><h3>效果</h3><p></p><p></p><p>AI组件瘦身</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/97/97b98196e76a1bb486581489aa5c6d9a.png\" /></p><p></p><p>调用链等相关数据迁移到CK</p><p></p><p></p><p></p><p></p><h2>总结</h2><p></p><p></p><p>为了实现5台集群可以支持到2000探针，我们首先要做的就是减法，减少组件之间的影响，让单个组件可以发挥更大的效能。再围绕这个组件，构建更全面的生态，包括监控、运维和操作等入口。最后在围绕业务使用场景进行深入优化，保证整体服务稳定性。</p><p></p><p>后续我们会在clickhouse内核上深入发力，不断拓展clickhouse的使用场景，与开发者一起分享博睿数据在clickhouse方向的探索和实践，助力Bonree ONE在更快、更准、更稳定的方向上走得更远。</p>",
    "publish_time": "2024-01-25 15:08:44",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]