[
  {
    "title": "从 Logstash 到 Vector：升级应用日志处理实践",
    "url": "https://www.infoq.cn/article/0Sd6oOmvKKMGYw7EGO1L",
    "summary": "<p></p><h2>背景</h2><p></p><p></p><p>我们当前的应用每天生产近 30 亿条日志，这些日志被 fluent-bit 从 K8S 中收集并保存到 Kafka 中，再使用 Logstash 从 Kafka 中消费日志，并对日志进行格式化等操作，最终写入到 Elasticsearch 中供查询。</p><p>&nbsp;</p><p>为了满足上述体量的日志处理，我们运行了 20 台 2 核 8 G 的 Logstash 服务器，但是在业务高峰期，日志消费性能依然捉襟见肘，导致 Kafka 相关的 Topic 出现积压的情况。</p><p>&nbsp;</p><p>由于业务快速发展，日志量还在不断增加，单纯增加服务器的缺点也很明显，管理成本和实际花销都在增加，这时寻找性能更高的替代品势在必行。</p><p></p><h2>终于找到你：Vector</h2><p></p><p></p><p>如果直接在搜索引擎中查找 \"vector\"，结果可能会让人大失所望，搜索结果基本和日志收集处理毫无关系，这与 Logstash 铺天盖地的文档形成了鲜明对比，这说明 Vector 相对于 Logstash 还很年轻，很多公司的大多数场景下仍在使用 Logstash 等老牌工具收集、处理日志，但是随着 FinOps 等概念的兴起，真正义意上的降本增效是企业发展的重点，其功在点滴，成本优化工作积少成多，本文讲解如何使用 Vector 处理日志以降低成本，旨在抛砖引玉，希望有更多人测试使用、并探索推动 Vector 的更佳实践，来切实为企业降本增效出一份力。</p><p></p><h2>Vector 简介</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/76/768eaa3a25763258c9df0f64ccd00415.png\" /></p><p></p><p>&nbsp;</p><p>引用官网的内容：“A lightweight, ultra-fast tool for building observability pipelines”，即一个轻量级的、快速的可视化管道构建工具，通俗来讲，它能作为一个管道，连接不同上下游组件，比如从 Kafka 消费数据并写入到 AWS S3。</p><p>&nbsp;</p><p>其由 Datadog 公司开源并主导维护，力求做到不同厂商间的中立，目前被 Atlassian、T-Mobile、Comcast、 Zendesk、Discord 和国内的豆瓣等公司使用，其中最大的用户每天使用 Vector 处理超过 30 TB 的日志。</p><p></p><h2>Vector 性能如何</h2><p></p><p></p><p>现代管理学之父彼得·德鲁克说：如果你不能衡量它，你就不能改进它。 IT 领域技术选型也是如此，如果我们决定使用 Vector，首要先确定它是适合我们的，是优于其它方案的。</p><p>&nbsp;</p><p>常见的老牌日志收集/处理软件如 Logstash、Fluentd 采用 Ruby 语言开发，其 CPU 和 内存占用较高，性能一般。而 Vector 采用 Rust 语言开发，单从语言性能来讲可比肩 C 语言，从部署使用的角度来看，Vector 仅占用极少的内存就能高效的工作，而且能充分利用 CPU 的多个核心。</p><p>&nbsp;</p><p>下图是 Vector 与其它日志收集器的性能测试结果对比，可以看到，Vector 的各项性能指标都优于 Logstash，综合性能也不错，加上其丰富的功能，完全可以满足我们的日志处理需求。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/24/24b98322c617de2b70e0b153937ffab8.png\" /></p><p></p><h2>生产环境下的安装和监控</h2><p></p><p>&nbsp;</p><p>很多教程注重软件的理论讲解，安装使用一带而过，仿佛这是最不重要的环节，但服务器软件和个人电脑上的软件有很大差别，如何管理进程的运行、如何合理规划配置文件等都是服务稳定性中重要的一环，所以值得花些时间来讲解 Vector 的安装实践。</p><p></p><h3>使用 yum 安装</h3><p></p><p>&nbsp;</p><p>大多数情况下，使用社区编译好的版本即可，怎么简单怎么安装，不必吹毛求疵自已编译，这里介绍在 CentOS 7 操作系统上使用 yum 进行安装的流程，其它系统和安装方式<a href=\"https://vector.dev/docs/setup/installation/\">官方文档</a>\"中有详细介绍。</p><p>&nbsp;</p><p>添加 yum 源：</p><p><code lang=\"shell\">curl -1sLf 'https://repositories.timber.io/public/vector/cfg/setup/bash.rpm.sh' \\\n  | sudo -E bash</code></p><p>&nbsp;</p><p>执行安装命令：</p><p><code lang=\"shell\">sudo yum install vector</code></p><p>&nbsp;</p><p>启动 Vector 并设置开机自启动：</p><p><code lang=\"shell\">systemctl start vector\nsystemctl enable vector</code></p><p></p><h3>配置文件管理实践</h3><p></p><p>&nbsp;</p><p>软件安装完成后，在 /etc/vector/ 目录下有默认的 vector.toml 配置文件，这也是 Vector 启动时默认会读取的配置文件，但是思考一个问题，当项目、环境、规则等十分庞杂时，将所有配置写到一个配置文件里合理吗？答案是否定的，好的方法是把配置文件根据需要进行拆分，比如按项目拆分成 project_xxx.toml 等多个配置文件，按环境拆分成 prod_xxx.toml、test_xxx.toml 等多个配置文件，而默认的 vector.toml 文件中可以写入一些全局配置。注意 Vector 除 .toml 格式外，还支持其它配置文件格式，如 Yaml，大家可根据习惯自行选择。</p><p></p><h3>配置 Vector 读取指定目录下所有配置文件</h3><p></p><p></p><p>上面提到要把复杂的配置文件拆分为多个，使用 yum 安装的 Vector 由 systemctl 命令管理，下面修改相关配置，让 Vector 读取指定目录下所有配置文件，而非默认的 vector.toml 文件。</p><p>&nbsp;</p><p>将 Vector systemd 配置文件第 12 行由 ExecStart=/usr/bin/vector 修改为：ExecStart=/usr/bin/vector \"--config-dir\" \"/etc/vector\"：</p><p>&nbsp;</p><p><code lang=\"shell\"># /usr/lib/systemd/system/vector.service\n[Unit]\nDescription=Vector\nDocumentation=https://vector.dev\nAfter=network-online.target\nRequires=network-online.target\n\n\n[Service]\nUser=vector\nGroup=vector\nExecStartPre=/usr/bin/vector validate\nExecStart=/usr/bin/vector \"--config-dir\" \"/etc/vector\"\nExecReload=/usr/bin/vector validate\nExecReload=/bin/kill -HUP $MAINPID\nRestart=always\nAmbientCapabilities=CAP_NET_BIND_SERVICE\nEnvironmentFile=-/etc/default/vector\n# Since systemd 229, should be in [Unit] but in order to support systemd &lt;229,\n# it is also supported to have it here.\nStartLimitInterval=10\nStartLimitBurst=5\n[Install]\nWantedBy=multi-user.target</code></p><p>&nbsp;</p><p>修改 vector 配置目录环境变量，将 VECTOR_CONFIG_DIR=\"/etc/vector/\"追加到 /etc/default/vector 文件最后：</p><p>&nbsp;</p><p><code lang=\"shell\"># /etc/default/vector\n# This file can theoretically contain a bunch of environment variables\n# for Vector.  See https://vector.dev/docs/setup/configuration/#environment-variables\n# for details.\nVECTOR_CONFIG_DIR=\"/etc/vector/\"</code></p><p>&nbsp;</p><p>重新加载 systemd 配置并重启 Vector：</p><p>&nbsp;</p><p><code lang=\"shell\">systemctl daemon-reload\nsystemctl restart vector</code></p><p>&nbsp;</p><p>至此 Vector 的安装就完成了，当服务器因某些原因宕机再重启后，Vector 会自启动并开始工作，后续有需要对配置文件进行修改时，由于前期已经做了基本的拆分，所以看起来也不至于是庞杂的一坨。</p><p></p><h3>Vector 的监控</h3><p></p><p>在运维领域，运行服务不加监控，就等于闭着眼晴开车。对 Vector 的监控可以从两个方面进行。</p><p>&nbsp;</p><p>周期性访问 Vector 的健康检查端口，检查状态是否正常。</p><p>&nbsp;</p><p>首先打开 Vector 的 api 功能，在 vector.toml 配置文件中加入以下内容即可：</p><p><code lang=\"shell\">[api]\n  enabled = true\n  address = \"0.0.0.0:8686\"</code></p><p>&nbsp;</p><p>重启 Vector，获取 Vector 的健康状态：</p><p><code lang=\"null\">$ curl localhost:8686/health\n{\"ok\":true}</code></p><p>&nbsp;</p><p>将 Vector 内部指标 Sink 到 Prometheus，据此建立更为详细的 Dashboard 和告警。</p><p>&nbsp;</p><p>在 vector.toml 配置文件中加入以下内容即可，vector 内置的指标将打入指定的 Prometheus。</p><p><code lang=\"shell\">[sources.vector_metrics]\ntype = \"internal_metrics\"\n\n\n[sinks.prometheus]\ntype = [\"prometheus_remote_write\"]\nendpoint = [\"https://:8087/\"]\ninputs = [\"vector_metrics\"]</code></p><p></p><h2>Vector 基本原理</h2><p></p><p></p><p>使用一项新的技术前，了解其工作原理和设计理念，在此大的框架上再进行细节的补充配置，就能快速将其应用，下面是 Vector 官网提供的 Vector 架构图。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9f/9f3cfbd57c3f4a06485d095945bc47f1.png\" /></p><p></p><p>&nbsp;</p><p>下面对照架构图对 Vector 组成进行讲解，可以看到 Vector 由 Sources、Transforms 和 Sinks 三个组件构成，对应的中文可以翻译为：源、转换、以及下沉。用最通俗的理解方式来讲，我们把 Vector 想象成一条管道，日志可以从多个源头（source）流入管道，比如 HTTP、Syslog、File、Kafka 等等，当日志数据流入管道后，就可以被进行一系列处理，处理的过程就是转换（Transform），比如增减日志中的一些字段，对日志进行重新格式化等操作，日志被处理成想要的样子后，就可以进行下沉（Sink）处理，也就是日志最终流向何处，可以是 Elasticsearch、ClickHouse、AWS S3 等等，下面对这三个部分进行逐一讲解。</p><p></p><h3>Sources</h3><p></p><p></p><p>Vector 提供了丰富的 Sources 供使用，常用的有 File、Elasticsearch、Kafka 等，并且支持的种类还在不断增加，详情可查看 Vector 的 Sources <a href=\"https://vector.dev/docs/reference/configuration/sources/\">参考</a>\"。</p><p>&nbsp;</p><p>如下是 Kafka 的 Source 配置实例：</p><p><code lang=\"shell\">[sources.kafka-log-topics]\ntype = \"kafka\"\nbootstrap_servers = \"kafka.address1.com:9092,kafka.address2.com:9092\"\ngroup_id = \"logstash\"\nauto_offset_reset = \"latest\"\ntopics = [\n            \"app-log1\",\n            \"app-log2\",\n            \"app-log3\",\n         ]</code></p><p></p><h3>Transforms</h3><p></p><p></p><p>Vector 提供了诸多 Transforms 类型来对日志进行处理，比如可以使用 Vector 专有的 VRL 语言对日志进行处理，它提供了非常丰富的<a href=\"https://vector.dev/docs/reference/vrl/functions/\">函数</a>\"，可以拿来即用。</p><p>&nbsp;</p><p>如果 VRL 不能满足用户对日志的处理需求，Vector 也支持嵌入 Lua 语言对日志进行处理，但是这种方式要比 VRL 慢将近 60 %，所以如果不是针对十分复杂的日志处理需求，可以向 Vector 社区提出自己的需求，社区则会考虑将用户需要的功能完善到 VRL 中。</p><p>&nbsp;</p><p>如下是使用 VRL 将日志解析成 json 格式的配置实例：</p><p><code lang=\"shell\">[transforms.journal-shaping-app-log]\ninputs = [\"kafka-log-topics\"]\ntype = \"remap\"\nsource = '''\n  if .topic == \"app-log1\" {\n    ., err = parse_json(.message)\n  } else {\n    abort\n  }</code></p><p></p><h3>Sinks</h3><p></p><p></p><p>Vector 同样提供了很多 Sinks 类型，其中有些和 Sources 是重合的，比如 Kafka、AWS S3 等，如果当前还没有你需要的 Sink 类型，同样可以向 Vector 社区进行反馈，让其考虑添加该功能。</p><p></p><h2>VRL 实例</h2><p></p><p>&nbsp;</p><p>假设我们线上环境的日志架构如下，Vector 的任务是从 Kafka 中消费日志，把日志处理成特定格式，最终打入到 Elasticsearch 中：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/32/32d520eb6c9ea94250fcbde3f5574a54.png\" /></p><p></p><p>&nbsp;</p><p>处理需求 1：json 扁平化，很多时候日志是多层嵌套的 json，可以使用 VRL 将嵌套 json 中的字段平铺到最外层后再打入 Elasticsearch 中。下面实例使用 VRL 将 message 字段包含的 Country 及 Language 字段解析到最外层的 json 中，如果内层字段与外层字段重合，内层字段会覆盖外层字段。</p><p>&nbsp;</p><p><code lang=\"shell\"># 源日志\n{\n\"name\": \"alex\",\n\"age\": 18,\n\"message\": {\n\"Country\": \"CN\",\n\"Language\": \"Chinese\"\n}\n}\n\n\n# 目标日志\n{\n\"Country\": \"CN\",\n\"Language\": \"Chinese\",\n\"age\": 18,\n\"message\": {\n\"Country\": \"CN\",\n\"Language\": \"Chinese\"\n},\n\"name\": \"alex\"\n}\n\n\n# VRL\n., err = merge(., .message)</code></p><p>&nbsp;</p><p>处理需求 2：删除无用的字段，还是上面的例子，message 里的字段被解析到最外层后，如果不再需要 message 字段，则可将其删除。</p><p>&nbsp;</p><p><code lang=\"shell\"># 源日志\n{\n\"Country\": \"CN\",\n\"Language\": \"Chinese\",\n\"age\": 18,\n\"message\": {\n\"Country\": \"CN\",\n\"Language\": \"Chinese\"\n},\n\"name\": \"alex\"\n}\n\n\n# 目标日志\n{\n\"Country\": \"CN\",\n\"Language\": \"Chinese\",\n\"age\": 18,\n\"name\": \"alex\"\n}\n\n\n# VRL\ndel(.message)</code></p><p>&nbsp;</p><p>处理需求 3： 字段重命名，VRL 支持将日志字段重命名，比如下面将 name 字段重命名为 my_name：</p><p>&nbsp;</p><p><code lang=\"shell\"># 源日志\n{\n\"Country\": \"CN\",\n\"Language\": \"Chinese\",\n\"age\": 18,\n\"name\": \"alex\"\n}\n\n\n# 目标日志\n{\n\"Country\": \"CN\",\n\"Language\": \"Chinese\",\n\"age\": 18,\n\"my_name\": \"alex\"\n}\n\n\n# VRL\n.my_name = del(.name)</code></p><p>&nbsp;</p><p>在编写复杂的 VRL 时，可以使用 VRL <a href=\"https://playground.vrl.dev/\">playground</a>\" 来帮助我们进行即时的编写测试来大大提高效率。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0e/0e615066cad9b8d959b8c748e76b3b8b.png\" /></p><p></p><p></p><h2>结论</h2><p></p><p>&nbsp;</p><p>使用 Vector 替换 Logstash 后，我们线上的日志收集服务从 20 台 2 核 8 G 的机器减少为 5 台 4 核 8 G 的机器，整体服务器费用减少了 50 % 左右，虽然不同公司的使用场景不同，但 Vector 依然值得测试并使用。</p>",
    "publish_time": "2023-04-23 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "华为投入数千人实现自主可控ERP；SpaceX星舰爆炸了，马斯克：祝贺！谷歌合并旗下两大人工智能部门，加速力战ChatGPT｜ Q资讯",
    "url": "https://www.infoq.cn/article/pfvptdM187FttPtq54mC",
    "summary": "<p></p><blockquote>华为实现自主可控 MetaERP，任正非：今天软件落后但终会强大；SpaceX星舰爆炸了，马斯克：祝贺！宣布裁员2.1万人之后，扎克伯格：未来不排除继续裁员；最新论文显示，ChatGPT 生成的代码安全性远低于最低标准；谷歌合并旗下两大人工智能部门Brain和DeepMind，加速研究力战ChatGPT；三家AI公司要求美国法院驳回版权诉讼：AI生成图像与艺术家作品不相似；杭州一家公司开出320万年薪抢AIGC人才；亚马逊编程助手 CodeWhisperer 正式可用，面向个人开发者免费开放；Stable Diffusion背后团队发布开源大语言模型，可用于本地部署；微软副总裁参与起草，业内最新报告称ChatGPT或会暴露企业机密信息；iOS 17 将支持应用侧载以遵守欧盟监管规定......</blockquote><p></p><p>&nbsp;</p><p></p><h2>科技公司</h2><p></p><p>&nbsp;</p><p></p><h4>华为实现自主可控 MetaERP，任正非：今天软件落后但终会强大</h4><p></p><p>&nbsp;</p><p>4 月 20 日电，<a href=\"https://www.infoq.cn/news/QLX24NmbrpfICxdlLAA0\">华为宣布已实现</a>\"自主可控的 MetaERP 研发，基于华为欧拉操作系统、GaussDB 等根技术，并已完成对旧 ERP 系统的替换。ERP 是最关键、最重要的企业级 IT 应用，2019 年受美国制裁后，华为决定启动对旧有 ERP 系统替换，并开启研发自主可控的 MetaERP 系统。</p><p>&nbsp;</p><p>三年来，华为投入数千人，联合产业伙伴和生态伙伴攻坚克难，研发出面向未来的超大规模云原生的 MetaERP。目前，MetaERP 已经覆盖华为 100% 的业务场景和 80% 的业务量，经历了月结、季结和年结的考验，实现了零故障、零延时、零调账。</p><p>&nbsp;</p><p>在华为 MetaERP 表彰会上，华为董事、质量与流程IT部总裁陶景文表示：“面对包含ERP在内的企业作业和管理核心系统的断供停服，我们不仅能造得出来，还换得了，用得好，现在终于可以宣布，我们已经突破了封锁，我们活了下来！”华为创始人任正非则表示，今天在软件上我们还是落后的，但是有一天我们可能会变强大。我们跟合作伙伴在一起共同奋斗，加强合作，为这个国家的安全共同奋斗。</p><p>&nbsp;</p><p></p><h4>SpaceX星舰爆炸了，马斯克：祝贺！</h4><p></p><p>&nbsp;</p><p>4月20日，马斯克旗下SpaceX（太空探索技术公司）星舰发射升空，星舰在发射之初姿态正常并成功升空，直至约1分钟时发射现场还响彻观众掌声。但在持续上升的过程中，星舰姿态发生变化，其中3分钟左右时已经能够看到星舰姿态出现明显异常。在飞行不到四分钟后，上级火箭未能按照设计与下级超重型助推器分离，星舰在飞行到接近20英里的高度时剧烈解体。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f2/f2eef42560a32d52a582f4907f9e5073.png\" /></p><p></p><p>&nbsp;</p><p>马斯克此前估计，开发“星舰”耗资约50亿美元，并且这些资金大部分都是来自公司内部。在飞船遭遇“猛烈的计划外解体”后，马斯克在Twitter上说：“祝贺SpaceX团队进行了一次激动人心的测试发射。他们从中学到了许多，有助于几个月后的下一次发射。”同时，NASA局长比尔·纳尔逊（Bill Nelson）在发射后也表示：“祝贺SpaceX的‘星舰’进行了首次综合飞行测试。”</p><p>&nbsp;</p><p>对此，有很多人不理解为什么发射失败还会欢呼庆祝，而SpaceX则表示测试即使失败，那也是成功之母。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d9/d99257c8d9bfd839dee5d7a21aa0f3c9.png\" /></p><p></p><p>&nbsp;</p><p></p><h4>宣布裁员2.1万人之后，扎克伯格：未来不排除继续裁员</h4><p></p><p>&nbsp;</p><p>4月20日，Facebook母公司Meta，进行了最新一轮的4000人裁员，并准备在5月份进行又一轮裁员。今年3月，<a href=\"https://www.infoq.cn/article/DISIpqNzOaslaKw0RooO\">扎克伯格已表示，该公司将在未来几个月内再裁员1万人</a>\"。此前，该公司已在去年11月裁员1.1万人。扎克伯格表示，4月份的裁员将影响技术部门，而5月份的裁员将影响公司的业务部门。</p><p>&nbsp;</p><p>扎克伯格告诉员工，公司还可能大幅放缓招聘速度，并表示Meta在未来几年面临着不确定性，不能保证裁员已经结束。他说：“总的来说，我对目前的形势感觉良好，但考虑到市场的波动性，我不想承诺未来不会出现任何问题。我能说的是，我们现在没有什么计划，如果我们做些什么，也会在那个时间框架内。”</p><p>&nbsp;</p><p>扎克伯格在一个问答环节中说道：“从新技术中获得的效率而言，这可能是我们期待的正确模式，这将是一种不同的运营模式，我认为我们可以做得很好。”他还表示，本周对技术人员的裁员“永远是最困难、最具争议的一次”。</p><p>&nbsp;</p><p></p><h4>&nbsp;</h4><p></p><p></p><h4>谷歌合并旗下两大人工智能部门Brain和DeepMind，加速研究力战ChatGPT</h4><p></p><p>&nbsp;</p><p>4月21日消息，据报道，谷歌母公司Alphabet将合并旗下的DeepMind和谷歌大脑两个人工智能研究部门，从而结束伦敦和硅谷这两大人工智能研究基地之间的内部竞争，在生成式人工智能领域夺回被微软和<a href=\"https://www.infoq.cn/article/70RoOfPyX22GyJlNg9OH\">OpenAI抢走的失地</a>\"。</p><p>&nbsp;</p><p>DeepMind成立于2010年，是谷歌在2014年收购的英国公司。此次调整后，DeepMind英国主管蒂米斯·哈撒比斯（Demis Hassabis）将负责合并后的部门。现在的前谷歌人工智能部门负责人杰夫·迪安（Jeff Dean）现在将成为谷歌的首席科学家，并向皮查伊报告。DeepMind和谷歌大脑之前都曾取得过重大研究突破，从而将人工智能变成自互联网诞生以来整个科技行业最重要的新技术。DeepMind最大的突破包括AlphaGo系统，它曾在2016年击败围棋世界冠军李世石。该公司开发的AlphaFold系统则能预测蛋白结构，有可能对医学行业产生深远影响。</p><p>&nbsp;</p><p>此番合并是让Alphabet最先进的研究资源更集中于人工智能建模领域，并直接应用于谷歌的互联网业务。这主要是受到OpenAI旗下的ChatGPT聊天机器人大获成功的刺激。微软多年来一直试图挑战谷歌在互联网搜索行业的地位，但却未能成功，而OpenAI的出现却对谷歌构成了巨大挑战。</p><p>&nbsp;</p><p></p><h4>三家AI公司要求美国法院驳回版权诉讼：AI生成图像与艺术家作品不相似</h4><p></p><p>&nbsp;</p><p>此前，一群艺术家指责人工智能企业Stability AI、商业人工智能图像生成服务Midjourney公司和展示用户制作各种艺术品的大型国际社群网站DeviantArt在生成式人工智能系统中使用他们的作品，侵犯了他们的版权。本周二，三家企业对此进行了回击。这些企业认为，人工智能生成的图像与艺术家的作品不相似，而且该诉讼没有指出涉嫌侵犯版权的具体图像。艺术家回称，这些公司未经授权就复制他们的作品来训练系统，并以他们的风格创建人工智能生成的图像，这些行为侵犯了他们的权利。</p><p>&nbsp;</p><p></p><h4>杭州一家公司开出320万年薪抢AIGC人才</h4><p></p><p>&nbsp;</p><p>4月15日，据杭州网消息，位于杭州未来科技城一家公司，开出了最高320万年薪，招聘AIGC方向算法工程师一名。ChatGPT在全球掀起了AI热潮，国内互联网大厂纷纷加入战局打造国内版ChatGPT。很多人在担心失业的同时，AI人才则站上了“风口”，遭到爆抢。</p><p>&nbsp;</p><p>最高开出高薪招人的公司，位于杭州未来科技城欧美中心。月薪在10万至20万之间，16薪，相当于一年最高可以拿到320万。根据招聘的岗位要求，计算机、数学相关专业博士，具有扎实的计算机或机器学习算法基础，在相关方向知名国际会议发表过论文；熟悉VAE、GAN、Stable Diffusion等基础生成模型，及相关跨模态模型，熟练使用主流LLM并了解其原理等。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8e/8e2cc33cec3afa64a72876b18afe824b.png\" /></p><p></p><p>&nbsp;</p><p>在猎聘上，AIGC方向热招的职位除了图像算法工程师、产品经理，还包括应用研究员、海外运营主管等。月薪普遍在20k-200k之间。另外，AI测试也是急需人才，最近达摩院招聘对话机器人测试开发专家，开出的月薪是50-80k。主要为阿里巴巴人工智能应用平台阿里小蜜提供各种软件测试、白盒测试和性能测试。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/49/4923860d216a2f968404e9b9e6b46003.png\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>IT业界</h2><p></p><p>&nbsp;</p><p></p><h4>亚马逊编程助手 CodeWhisperer 正式可用，面向个人开发者免费开放</h4><p></p><p>&nbsp;</p><p>4月17日，亚马逊云科技宣布，正式推出实时 AI 编程助手 Amazon CodeWhisperer，包括 CodeWhisperer 个人套餐，所有开发人员均可免费使用。开发人员可以通过在他们最喜欢的 IDE（包括 Visual Studio Code、IntelliJ IDEA 等）中使用 CodeWhisperer 来提高工作效率并简化工作。在为常规任务或耗时、无差异的任务创建代码、使用不熟悉的 API 或 SDK、正确有效地使用 AWS API 以及其他常见的编码场景（例如读写文件、图像处理、编写单元测试等），CodeWhisperer 都可以提供帮助。</p><p>&nbsp;</p><p>目前，免费版本可以编写多种语言的代码，包括 Python、Java、JavaScript、TypeScript、C#、Go、Rust、PHP、Ruby、Kotlin、C、C++、Shell 脚本、SQL 和 Scala 。而且，亚马逊云科技特地指出，CodeWhisperer 提供的代码建议并不专门针对使用 AWS的情况。另外，CodeWhisperer 也具有安全扫描功能，可以发现难以检测的漏洞并提出修复建议，扫描生成的代码和开发人员编写的代码，寻找漏洞，例如开放式 Web 应用程序安全项目（OWASP）中列出的前十大漏洞。如果发现漏洞，CodeWhisperer 会提供建议，帮助修复问题。</p><p>&nbsp;</p><p></p><h4>Stable Diffusion背后团队发布开源大语言模型，可用于本地部署</h4><p></p><p>&nbsp;</p><p>4月19日，开发AI图像生成工具Stable Diffusion的创业公司Stability AI宣布，发布并开源该团队训练的大语言模型StableLM。根据该团队的公告，目前StableLM的“阿尔法版本”中拥有30亿和70亿参数的模型已经可以从GitHub等开源平台上下载，后续还将推出150亿至650亿参数的版本。</p><p>&nbsp;</p><p>与Stable Diffusion类似，StableLM同样支持知识共享4.0协议，开发者可以在遵守协议的情况下，将这个模型用于商业或研究活动。Stability AI介绍称，StableLM可以生成文本和代码，并将助力一系列下游应用。并且与GPT-4等超级大模型不同，Stability AI的产品可供每一个人下载并部署在本地。这家公司在去年发布的Stable Diffusion，使得AI“文生图”赛道成为AIGC领域商业化前景最为明朗的行业。</p><p>&nbsp;</p><p></p><h4>微软副总裁参与起草，业内最新报告称ChatGPT或会暴露企业机密信息</h4><p></p><p>&nbsp;</p><p>本周，以色列网络安全公司Team8在一份最新报告中表示，使用ChatGPT等生成式人工智能工具的公司，可能会将客户信息和商业机密置于危险之中。</p><p>&nbsp;</p><p>该报告指出，新型人工智能聊天机器人和协作工具的广泛推广普及，可能会令一些公司面临数据泄露和法律风险。许多人眼下已担心，黑客可能会利用人工智能聊天工具，来获取敏感的企业信息或对企业发动攻击。此外，目前投喂给聊天机器人的机密信息，未来也有可能会被AI公司所利用。</p><p>&nbsp;</p><p>这份报告的发布方——Team8在全球网络安全领域享有盛名，这家以色列公司成立于2014年，由前以色列国防军精英部队“8200部队”的成员创立，专注于网络安全、数据分析和人工智能等领域。巴克莱、微软、沃尔玛和思科等多家全球巨头企业都与Team8有着合作和投资关系。</p><p>&nbsp;</p><p>根据媒体看到的信息，微软公司副总裁Ann Johnson参与起草了这份报告。微软已经向ChatGPT的开发者Open AI投资了数十亿美元。微软发言人表示，“微软鼓励就安全和人工智能领域不断发展的网络风险进行透明讨论。”</p><p>&nbsp;</p><p></p><h4>iOS 17 将支持应用侧载以遵守欧盟监管规定</h4><p></p><p>&nbsp;</p><p>苹果将在 iOS 17 中首次加入对应用侧载（sideloading）的支持，允许 iOS 用户安装从官方商店 App Store 之外下载的应用，比如应用的官网，这意味着应用开发商不需要向苹果支付 15% 到 30% 的分成。</p><p>&nbsp;</p><p>欧盟的数字市场法 Digital Markets Act (DMA)于 2022 年 11 月 1 日生效，要求苹果等担负起守门人角色的巨头向其他公司和开发商开放其服务和平台。为了遵守欧盟的监管规定，苹果计划在明年前支持侧载。首先，侧载变化将仅限于欧盟的客户，但随着其他国家通过类似于欧洲数字市场法案的立法，苹果可能会扩展该功能。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>最新论文显示，ChatGPT 生成的代码安全性远低于最低标准</h4><p></p><p>&nbsp;</p><p>4月21日消息，在对大型语言模型的狂热兴趣中，加拿大魁北克大学的四名研究人员深入研究了 ChatGPT 生成代码的安全性。</p><p>&nbsp;</p><p>在题为“ChatGPT 生成代码的安全性如何？”的论文中，计算机科学家 Raphaël Khoury、Anderson Avila、Jacob Brunelle 和 Baba Mamadou Camara 的研究基本等于是说“ChatGPT的安全性不是很好”。四位作者在使用C 、C++ 、python、html和 Java 五种编程语言，生成 21 个程序后得出了该结论。</p><p>&nbsp;</p><p>“结果是很令人担忧的，”作者们在他们的论文中说。“我们发现，在某些情况下，ChatGPT 生成的代码远低于适用于大多数情况的最低安全标准。”事实上，“ChatGPT 能够识别到，而且确实很乐意承认，它的代码中存在严重漏洞”， 但除非被要求评估其代码安全性，否则它自己不会指出。</p><p>&nbsp;</p><p>他们还引用了一个 Java 反序列化漏洞示例，其中“聊天机器人生成了易受攻击的代码，并提供了如何使其更安全的建议，但表示无法创建更安全的代码版本。”</p>",
    "publish_time": "2023-04-23 10:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "开放原子全球开源峰会，全面升级再出发！",
    "url": "https://www.infoq.cn/article/6c524762219f64349ca446567",
    "summary": "<p>当前，开源已经成为全球信息技术产业发展的一种重要协作方式和生态构建形式。开源能够集众智、采众长，加速软件迭代升级，促进产用协同创新，推动产业生态完善，已成为全球软件技术和产业创新的主导模式。开放原子开源基金会以繁荣开源事业，共享开源价值为愿景，秉持国际视野，突出科技特色，促进业态繁荣，成功召开全球数字经济大会——2022开放原子全球开源峰会。今年6月，盛会将全面升级再出发！</p><p>立足中国，面向世界，基金会将呈现我国及全球开源生态发展成果，以及对数字经济发展所起到的长远助力价值和社会效益，推动开源软件与软件产业深度融合。</p><p></p><p>今年，盛会全面升级，内容更加丰富。一是更广泛地汇聚顶尖开源力量，将邀请政府领导、院士学者、国际开源领袖、开源领军企业、创新创业园代表、主流媒体、开源创新人才、优秀开发者等莅临参会，探索开源赋能数字经济与推动社会发展的有效路径。二是更全面地展示开源技术应用，聚焦全球开源生态最新发展与前沿技术动态，覆盖开源治理、开源项目、开源前沿技术、开源行业实践等多个话题方向。三是更深入地履行国家级基金会社会责任，秉持基金会科技公益性服务机构的定位，打造科技创新共同体，助力推动全球新一代技术和产业发展，重磅发布Atomgit代码托管平台，展示开放原子开源大赛和开放原子校源行公益项目成果等。基金会将秉持开放共享，共建共治的宗旨，以开源的方式打造盛会，加大国际合作力度，覆盖更多参与主体和项目，服务全球开发者。</p><p></p><p>让我们共同回顾2022开放原子全球开源峰会的精彩瞬间！</p><p>感谢所有关心与支持开放原子开源基金会的社会各界人士！</p><p></p><p>参会人员广：企业CXO占比超过10%、行业专家占比超过12%、开发者占比超过51%。覆盖软件行业、计算机硬件及电子消费行业、互联网及Web服务、汽车交通行业、咨询类行业、媒体及政府非营利机构等领域；</p><p>组织方式新：峰会秉持开放共享，共建共治的宗旨，50+共建单位及开源社区共同承办分论坛，63家企业和开源社区共同参与开源长廊建设；</p><p>峰会传播广：峰会全网曝光量4亿+，直播观看量578万+，社交媒体相关话题曝光量1亿+，新华网头条报道，中国中央电视台中文国际频道、中央广播电视总台经济之声深度报道，多家中央媒体、行业媒体和网络媒体输出多角度、多类型、有深度的报道，媒体报道总量5000+篇次；</p><p>转化落地快：会中，基金会联合全国十余所高校，启动开放原子校源行公益项目；会后，基金会联合国内知名企业和国际知名软件厂商，加速成果转化落地；</p><p>国际交流广：峰会宣传了基金会开源服务模式和治理体系，邀请国际主流基金会Linux、Eclipse、OpenSSF等相关负责人作主题演讲，中外共话开源，展示我国基金会融入全球开源生态的开放姿态和合作诚意；</p><p>参与主体多：20余个行业组织、12个国内外重点平台、20余家头部企业积极参与；</p><p>辐射范围广：全国22个省市、741家企业，30多个科研教育机构持续关注。</p><p></p><p>让我们共同回顾2022开放原子全球开源峰会精彩瞬间</p><p>开幕式及高峰论坛</p><p><img src=\"https://static001.geekbang.org/infoq/73/73b08db560b488dcea710a4104c041c9.jpeg\" /></p><p>工业和信息化部党组成员、副部长王江平</p><p><img src=\"https://static001.geekbang.org/infoq/bc/bcd6b7571d54b6f0b69ca0485a6aece5.jpeg\" /></p><p>北京市委常委，市政府党组成员、副市长靳伟</p><p><img src=\"https://static001.geekbang.org/infoq/66/66e989292d75d9a32ed90a40612c965d.jpeg\" /></p><p>工业和信息化部信息技术发展司副司长王威伟</p><p><img src=\"https://static001.geekbang.org/infoq/02/02702ee948ad69b2c3cdc2368609454c.jpeg\" /></p><p>开放原子开源基金会理事长孙文龙</p><p><img src=\"https://static001.geekbang.org/infoq/2e/2e10695454c4cd9eeb41ebf933c1255e.jpeg\" /></p><p>中国科学院院士梅宏</p><p><img src=\"https://static001.geekbang.org/infoq/45/4582331f0d45640a32f555b2f7382dff.jpeg\" /></p><p>中国科学院院士王怀民</p><p><img src=\"https://static001.geekbang.org/infoq/36/36f977c3a7130740538e8c9e2226fa3f.jpeg\" /></p><p>中国开源软件推进联盟名誉主席陆首群</p><p><img src=\"https://static001.geekbang.org/infoq/3d/3da8b4d58b17395ea83a3a72d6043c2d.jpeg\" /></p><p>北京市经济和信息化局信息化与软件服务业处副处长赵祥伟</p><p><img src=\"https://static001.geekbang.org/infoq/9b/9bdbc48d7ac5cda300e20dbac13bdde5.jpeg\" /></p><p>阿里巴巴集团CTO程立</p><p><img src=\"https://static001.geekbang.org/infoq/66/66f22975f4bc1941fc8af6251425217f.jpeg\" /></p><p>Linux基金会执行董事Jim Zemlin</p><p><img src=\"https://static001.geekbang.org/infoq/52/5200eeb36b0ca3020969f0efcd4cfca2.jpeg\" /></p><p>中软国际有限公司董事局主席兼CEO陈宇红</p><p><img src=\"https://static001.geekbang.org/infoq/26/2678451184d5cf600e14eaca85a30f3d.jpeg\" /></p><p>腾讯高级执行副总裁汤道生</p><p><img src=\"https://static001.geekbang.org/infoq/75/758b617ebe55b2a5f2da132ae2a399d4.jpeg\" /></p><p>蚂蚁集团副总裁何征宇</p><p><img src=\"https://static001.geekbang.org/infoq/47/47687cdeebc51802b4dc3409e0cf7f6c.jpeg\" /></p><p>Eclipse基金会执行董事Mike Milinkovich</p><p><img src=\"https://static001.geekbang.org/infoq/9f/9fadca31da4735d89d850af4c995da24.jpeg\" /></p><p>华为战略与产业发展副总裁肖然</p><p><img src=\"https://static001.geekbang.org/infoq/60/606fc304d7d7e58d93f15623c1b6c641.jpeg\" /></p><p>开源安全基金会（OpenSSF）总经理Brian Behlendorf</p><p><img src=\"https://static001.geekbang.org/infoq/a2/a27d2a6e611794b8eef4d40f258c0455.jpeg\" /></p><p>软通动力集团董事黄颖</p><p><img src=\"https://static001.geekbang.org/infoq/6d/6d3c05904466e6b899661781cf3c704c.jpeg\" /></p><p>深圳开鸿数字产业发展有限公司CEO王成录</p><p><img src=\"https://static001.geekbang.org/infoq/62/622bb206b4172dd76bf2da361488cccb.jpeg\" /></p><p>英特尔软件与先进技术事业部研发总监杨继国</p><p><img src=\"https://static001.geekbang.org/infoq/26/26fe01f296c50196d89f98e4dd21401d.jpeg\" /></p><p>LF AI &amp; Data基金会执行董事Ibrahim Haddad</p><p><img src=\"https://static001.geekbang.org/infoq/4c/4c52efab8a431d8f8b16505e6b8ad44a.jpeg\" /></p><p>白金捐赠人授牌仪式</p><p><img src=\"https://static001.geekbang.org/infoq/ed/edfe61228366116119a3114d279e3e6b.jpeg\" /></p><p>黄金捐赠人授牌仪式</p><p><img src=\"https://static001.geekbang.org/infoq/e8/e87aaefe4f461969526b39625370d077.jpeg\" /></p><p>白银捐赠人授牌仪式</p><p><img src=\"https://static001.geekbang.org/infoq/c2/c202110e9e1097ebc53118f3f34ffb5f.jpeg\" /></p><p>开放原子开源大赛启动仪式</p><p><img src=\"https://static001.geekbang.org/infoq/a0/a0a28f827f20f4c4c07dcbc22db100ea.jpeg\" /></p><p>开放原子校源行启动仪式</p><p></p><p></p><p></p><p>分论坛</p><p><img src=\"https://static001.geekbang.org/infoq/cf/cf0e0525402b93bf2b3c960840ad9927.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5d/5df0e534868b97828af2a61de9b8bb91.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fa/fad7764027fba6fa916325d0e8505c7d.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7d/7d1ff74ed008c240b6dbb9de06f33c00.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a824712ed8397da5eefd019ea452034a.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/64/64faca554884d7ae61a29d24e57a855c.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7d/7dd2503c0005468dc12e2c3ca8fdb086.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0b/0bcc0fdd0f3bca5be000aef6ae0f689f.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/15/156056a65d3287415d9979489d370684.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0d/0d6dd723d19e766d3ed99fe54ed62531.jpeg\" /></p><p></p><p></p><p>展区</p><p><img src=\"https://static001.geekbang.org/infoq/65/650865a8daceab44382d46818edb6634.jpeg\" /></p><p></p>",
    "publish_time": "2023-04-23 10:32:49",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "腾讯游戏打通 Apache Pulsar 与 Envoy，构建高效 OTO 营销平台",
    "url": "https://www.infoq.cn/article/x8vFUTThrIo5qEoYNK8K",
    "summary": "<p></p><p>本文整理自 Pulsar Summit Asia 2022 上腾讯互娱 GDP 微服务开发平台网关技术负责人江烁的演讲《打通 Apache Pulsar 与 Envoy，构建高效游戏 OTO 营销平台实践》。本文将介绍介绍腾讯互娱利用 Apache Pulsar 和 Envoy 运营游戏 OTO 营销平台的经验。</p><p>&nbsp;</p><p>腾讯互动娱乐旗下涵盖腾讯游戏、腾讯文学、腾讯动漫等多个互动娱乐业务平台。其中，腾讯游戏注册用户超过 8 亿。2022 年 6 月，腾讯游戏旗下王者荣耀日活跃用户数量超过 1 亿 6 千万，和平精英日活跃用户数量超过 8 千万。</p><p>&nbsp;</p><p>OTO 是 One-Time Offer 的缩写，是从商品购物中衍生出来的术语。它指的是顾客下单过程中出现一次性销售机会的产品。比如消费者付款时销售人员会提醒顾客，只要加一点费用就可以换购很划算的商品，错过就没有机会。OTO 在游戏场景中的应用是在一定场景下为玩家提供限时优惠礼包，或推荐比较适合用户的任务。这就需要系统能够及时为用户产生个性化的内容，有效触达用户，造成紧迫感，使更多用户能够参与活动。</p><p></p><h1>传统架构及其问题</h1><p></p><p>为实现上述目标，腾讯互娱早期基于传统上实时数据处理的系统经验搭建了基于 Kafka + Flink 的 OTO 干预系统：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/45/45abb2a19328350b88743f05a6c9f037.png\" /></p><p></p><p>活动中的用户游戏日志接入到 Kafka，Flink 实时消费 Kafka 中的消息，分发到状态服务和 OTO 服务。状态服务记录用户的累积状态，如是否参与过活动、累积输了多少次等数据，供 OTO 服务查询。OTO 服务包含推荐模块和任务系统模块，根据用户日志和状态判断用户是否触发活动，再通过推荐模块生成个性化任务，以红点/弹窗方式通过游戏运营后台推送到终端用户 App 的运营活动模块，为用户展示相应的活动参与界面。</p><p>&nbsp;</p><p>上述架构分为两大部分，分别为 Kafka + Flink 的大数据处理套件，和以微服务方式部署在 K8s 上的微服务开发平台。后者是以云原生理念搭建的开发平台，方便开发和运维。</p><p>&nbsp;</p><p>系统运营上线一段时间后团队发现了 OTO 营销活动具有以下特点：</p><p>&nbsp;</p><p>活动多，效果好的活动经常被复制到其他业务中；活动具有周期性，如双周、一个月、几个月和长线活动，还有很多活动会复开，活动上下线频繁；活动期间流量不稳定，每日各时段流量差距较大，高峰时段流量是低谷段的十几倍；不同业务和活动的量级不一样，差距较大。</p><p>&nbsp;</p><p>OTO 服务通过基于 Kubernetes 的 GDP（游戏微服务开发平台），可以快速部署、自动扩缩容和资源回收复用。但这里 Kafka + Flink 的架构存在一些问题：</p><p>&nbsp;</p><p>Kafka 的消费并行度基于 Partition，如果应用直接消费 Kafka Topic，并行度就会受此限制。例如 Kafka 只有三个分区，那么只有三个 Pod 在消费数据，其他 Pod 都在空转。因此团队加入了 Flink 来分发，解决了并行度问题。但如果消息量变大，要调整 Kafka 的分区数是一件复杂的事情，会造成集群重平衡。而且引入 Flink 还带来了一些问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9e/9e499cdd333a913555ee3d9591d9f984.png\" /></p><p></p><p>引入 Flink 带来的问题主要是 Flink 的作业资源调整需要重启作业，对实时在线业务有着较大影响。在 OTO 场景中 Flink 只用来消费事件、调用下游微服务，为此专设集群比较浪费。出海时还需要考虑兼容不同云端 Flink 的接口，作业调度比较复杂，需要专设运维人员协助开发，增加额外成本。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d0/d0389d79d1716e11d2c999e34f3744f4.png\" /></p><p></p><p>触达失败率较高。原因有多个：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/19/19c9f16af65819397522d5291f1ba8eb.png\" /></p><p></p><p>调用推送接口时可能会失败，例如用户对局结束马上推送。很多在对局期间为了保障用户体验，会停止其他模块，在对局完成后重新拉起。但我们经常处理完对局相关事宜后就会推送，此时推送链接还未建立。终端网络不稳定会造成推送消息丢失。即时推送消息到达客户端，也存在游戏不在安全区（如尚在对决结算中）而无法弹窗，导致推送失败。总体来看触达率只有 60%。</p><p>业务与活动的资源需要隔离。一方面需要通过隔离防止不同业务和活动互相影响，另一方面需要对业务进行独立成本核算。采用共享集群会导致费用结算复杂，集群太多又导致运维管理成本过高，活动上下线资源管理困难。</p><p></p><h1>云原生架构与网关扩展</h1><p></p><p>为解决上述问题，腾讯互娱团队做了诸多优化。</p><p></p><h2>优化一：用 Pulsar 代替 Kafka</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/07/071d6c9327a45036d340b5d1902f4283.png\" /></p><p>在此不赘述 Pulsar 和 Kafka 对比，只针对我们的场景介绍一些用 Pulsar 代替 Kafka 的好处。Pulsar 提供了 Shared 消费模式，并发量不受 Partition 限制。这样消费服务完全不需要关心分区数，后端服务需要时即可调整副本数，直接提高了并发度，增强了处理能力。再配合 K8s 的 HPA 即可自动根据后端性能指标扩缩容，极大提升资源利用率。</p><p>&nbsp;</p><p>Pulsar 还支持对单个消息独立 Ack，可以很好地防止重复消费。Pulsar 还提供 Key_Shared 消费模式，在某些并发控制场景非常方便。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cb/cbf511016307a787d566ca3d8064330d.png\" /></p><p></p><p>Pulsar 还提供了延迟处理能力，包括延迟投递和延迟重试。使用这两个能力可以轻松解决触达率较低的问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9c/9c2a98c0a24bc27ceea9de57e9e19f34.png\" /></p><p></p><p>Pulsar 还提供了多租户能力，一个集群就可以解决多业务/活动资源隔离和 SLA 的需求，大大降低了运营压力，方便业务成本核算。</p><p></p><h2>优化二：采用云原生方案代替 Flink</h2><p></p><p>使用 Pulsar 代替 Kafka 后无需再用 Flink 做并发分发，可以去掉 Flink。为兼容之前的服务，又考虑到后续的微服务平台灵活性，简化其他微服务的开发工作，团队在平台的 Envoy 网关上扩展了几个特性，使 Envoy 可以处理 Pulsar 协议。结合 Envoy 已有的灵活规则配置和大量功能插件，可以配置出很多便利功能。</p><p></p><h2>云原生架构</h2><p></p><p>经过上述优化，新的系统云原生架构如下：</p><p><img src=\"https://static001.geekbang.org/infoq/22/22847cac58525bf25d535146838dde95.png\" /></p><p></p><p>上述架构分为事件总线和微服务两大块。前者负责日志到 Pulsar 消息的生产，增加了事件元数据管理模块，统一管理业务事件到 Pulsar Topic 的映射。这里为了兼容性，还会有部分数据流向老的 Kafka 流程。</p><p>&nbsp;</p><p>微服务层加入了 Envoy 网关，通过配置管理获取元数据信息，监听相应的 Topic 路由到微服务进行处理；增加推送服务，利用 Pulsar 的延迟投递与延迟重试能力进行重推和回执处理，提高触达率。这样所有服务都在云端通过 K8s 调度，有高可用保障，只需调整副本数即可轻松扩缩容。</p><p></p><h2>基于事件总线的事件分发</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9b/9bbb4cd3c893a04d302f89bbdd6c756f.png\" /></p><p></p><p>事件总线用于规范事件管理，事件按业务和类型维度管理。事件元数据管理登记各业务的各种类型事件应存放在 Pulsar 的哪个租户的哪个 Topic 下，由事件网关负责路由。微服务侧由配置中心将微服务需要处理的指定业务事件类型在事件元数据管理处查询到具体的 Topic 后下发给 Envoy 网关，再通过 Pulsar Consumer Filter 消费 Message 后路由给微服务进行处理。这样事件的生产和处理两方都无需知晓具体的事件存放类型和位置，只需关心业务和事件类型，简化了业务复杂度。</p><p></p><h2>通用延迟重试</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fa/fa596dda7310da8bee27ab46a9e56ba9.png\" /></p><p></p><p>Envoy 网关有失败后立即重试的能力，在很多场景下没有意义，例如在推送服务连接还没有建好的情况下，立即重试毫无意义。有了 Pulsar 后，就可以在 Envoy 上部署通用的延迟重试。当服务 A 通过网关来调用服务 B，网关插件可以提供限速，服务 B 也可以有限速。超过限速的请求会返回 429 状态码。如无限速，可能返回 503 码。如果网关针对特定状态码配置了延迟重试，Pulsar Filter 就会将请求做 Deliver After 处理，或者 Reconsume Later 按配置的时间间隔写入指定 Topic，并返回 202 Accepted 给服务 A。Pulsar Consumer Filter 会监听该 Topic，在指定时间间隔后收到该 Message，还原成 HTTP 请求，并加上带有重试信息的请求头重新路由，发送到服务 B。如果这段时间内，服务 B 或者其以来的资源恢复就会重试成功，最大程度保障服务成功率。这样，初始推送成功率不到 10% 的对局结算比较慢的业务在重试后成功率也能提升到 80% 以上，其他业务也有很大提升。</p><p></p><h2>通过回执确认与补推提高触达率</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d0/d0c207a69be106d3837de0596b382f05.png\" /></p><p></p><p>推送成功并不意味着成功触达用户，因为游戏 OTO 服务发起推送给游戏运营后台，后台通过客户端连接发送推送包，就会直接返回成功消息，但客户端不一定能收到推送包，因为可能终端网络不稳定或者网络断开，游戏运营后台无法感知，也存在即使感知到也无法弹窗的情况。为此团队和客户端协商了一套回执协议，在推送成功后利用 Pulsar 的延迟投递能力写入延迟检查消息。如果运营前端收到推送并成功触达，就会向后台发送回执。后台经过事件总线写入 Pulsar，回执处理模块消费该消息，并记录回执。设置回执检查的时间（延迟消息）Timeout 后，回执检查模块会消费延迟检查消息，并查询回执记录。如果记录存在则流程结束，说明用户已被触达，不存在则进入补推流程。</p><p>&nbsp;</p><p>上述机制可将整体触达率提升到 90% 左右。</p><p></p><h2>Pulsar 延迟消息的其他应用</h2><p></p><p>定时任务：可以实现在某个时间给特定用户发送通知；定时活动上下线和物品上架等。礼包未领取提醒：给用户推送礼包或任务后，用户一段时间未领取，可以通过延迟消息来触发一些动作。</p><p></p><h2>优化效果</h2><p></p><p>改用 Pulsar 并发量不受 Partition 的限制；去掉 Flink 分发请求，降低成本；微服务方式部署扩缩容方便；基于 Pulsar 的延迟重试和回执确认与补推提升了触达率；通过单集群、多租户隔离各个业务或活动，简化运维工作。</p><p></p><h3>通过网关来集成 Pulsar 的好处</h3><p></p><p>兼容原有服务，状态服务和 OTO 服务无需改造；减轻微服务开发者的工作量，开发者只需开发 HTTP 接口即可；结合网关能力实现可灵活的配制化功能：通用触发、削峰填谷、延迟重试和计划任务等。</p><p></p><h1>后续规划</h1><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/df/df113f56f3c9ff29dab0fd8edee21814.png\" /></p><p>腾讯互娱团队未来计划进一步集成 K8s 和 Pulsar。K8s 支持 HPA，通过监控容器 CPU 和其他内存指标，当达到一定阈值时，触发服务扩缩容。这对一些队列消费服务不适用。有时依赖的第三方服务延迟较大会导致消息堆积，此时消息处理服务内存和 CPU 指标可能不高，但是需要增加并发度来提高处理能力。我们计划扩展 K8s 的 HPA，在监控 CPU 和内存等指标基础上再监控 msgBacklog，增强扩缩容灵活性，防止消息堆积。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/48/48ac4278b2302d1c2c3ffc48791a60ff.png\" /></p><p></p><p>Pulsar 官方提供了非常方便的无服务器计算框架 Pulsar Functions，可以方便地开发 Serverless 消息处理服务。Pulsar Functions 还提供了方便的 K8s 部署方式。未来团队会探索这一方面的应用。</p><p>&nbsp;</p><p>作者简介：</p><p>江烁，腾讯互娱 GDP 微服务开发平台网关技术负责人。</p>",
    "publish_time": "2023-04-23 11:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]