[
  {
    "title": "开源如何助力软件开发团队",
    "url": "https://www.infoq.cn/article/UhDl1z5zO5qhiYkD4KES",
    "summary": "<p>近年来，开源软件的使用和开源贡献程度在显著增加，并继续成为开发者个人和专业项目的来源。对许多新进入软件开发领域的人来说，为开源项目做出贡献已经成为一种仪式。开源社区在帮助初级开发者解决技术问题的同时，也为他们提供了很好的学习和交流机会。</p><p>&nbsp;</p><p>在许多方面，为开源项目做贡献也变得比以往任何时候都容易。软件协作和开发平台（如GitHub）的发展使得参与开源贡献的机会变得更加大众化，而行业活动（如<a href=\"https://streaklinks.com/BGxxDTHsrEWPcWPbCwfIf65-/https%3A%2F%2Fhacktoberfest.digitalocean.com%2F\">Hacktoberfest</a>\"）或社区论坛也成为开发者寻找他们第一个贡献项目的地方。</p><p>&nbsp;</p><p>开源软件对科技行业和开发者来说至关重要，这一点毋庸置疑。然而，开源社区仍然面临着各种各样的挑战。围绕开源建立的社区和开源所提供的好处是非常有影响力的——技术领导者会鼓励更多的人参与其中，包括他们的团队和整个行业。</p><p></p><h2>开源参与度</h2><p></p><p>&nbsp;</p><p>DigitalOcean最近发布的一项关于开源社区状态的<a href=\"https://streaklinks.com/BGxxDTHPDxe898I6zQoB2vS6/https%3A%2F%2Fwww.digitalocean.com%2Fcurrents%2Fjune-2022\">报告</a>\"表明，大约50%的被调查开发者表示他们在过去的一年中参与了开源。在参与的开发者当中，几乎所有人（93%）表示，自疫情开始以来，他们的参与程度要么提高了，要么保持不变。这表明，尽管过去几年疫情对开发者的工作与生活带来了影响，但致力于开源的开发者已经找到了将这种实践融入日常和“新常态”的方法。</p><p></p><h2>参与开源贡献所面临的挑战</h2><p></p><p>&nbsp;</p><p>然而，即使是最坚定的开发者也承认，时间约束是参与开源项目的最大障碍之一。DigitalOcean的研究发现，大多数参与开源项目的开发者每周会花1到5个小时在开源项目上，并将“缺乏资源/时间”和“技术债务”列为他们目前面临的两大挑战。</p><p>&nbsp;</p><p>除了时间约束之外，开源世界有时可能不欢迎那些努力参与的人。Carnegie Mellon对开源动态的一项研究表明，开源项目贡献者之间的交流可能会演变为“上下文相关的、微妙的和消极的”评论，或者贡献者可能会发现他们面对的是僵化而死板的贡献策略。当项目面临严重的文档负债时，开源项目贡献者之间的交流也会迅速中断。当（大多数）开源项目受到时间和资源的约束时，首先受影响的是文档化程度。如果没有完整的文档，新人将面临非常陡峭的学习曲线，这导致他们很难参与贡献，除非他们已经非常熟悉项目。</p><p>&nbsp;</p><p>与技术行业的其他领域一样，软件项目也缺乏多样性和包容性。DigitalOcean的研究发现，虽然大多数开发者认为开源的包容性在过去几年中有所提升，但少数群体的成员对这种看法存在异议——有26%的少数群体成员不认同开源的包容性，而非少数群体的这一比例只有12%。管理开源项目的贡献者已经在寻找各种各样的解决方案，试图减轻有害行为，例如通过禁令和积极的审核来强制执行行为准则，但即使是这些解决方案也严重依赖于审核人员在这些项目上的时间投入。</p><p>&nbsp;</p><p>在目前的状态下，开源贡献似乎介于“爱好”和“志愿者工作”之间。为开源项目腾出时间的开发者正在做着重要和创新的工作，但这些工作往往没有得到各方的承认，尤其是那些从这些工作成果中受益的公司。开源软件的诞生方式（即软件是如何由大多数没有或缺乏资源的人在网上构建、开发和更新的）与开源技术在当今公司发展中所扮演的角色相去甚远。</p><p></p><h2>开源为我们带来了什么</h2><p></p><p>&nbsp;</p><p>技术领导者和开发者一直承认开源软件对他们的公司产出了巨大影响。64%的开发者表示，他们公司50%或更多的项目使用了开源软件，这一比例在初创公司和小型企业中甚至更高。35%的初创公司和中小企业在其50%或更多的项目中使用了开源代码，而大型企业的这一比例为28%。</p><p>&nbsp;</p><p>当大公司公开谈论开源时，通常会从安全性的角度出发。亚马逊、谷歌和微软等公司已经加入了各种基金会和组织，如开源安全基金会（Open Source Security Foundation，OpenSSF），这个基金会专注于改善开源开发和实现中的网络安全实践，并确保开源的“供应链”安全。这些团体和组织对于开源软件的长期成功和可持续发展来说非常重要，但并没有太多地关注如何解决开发者在维护开源项目中所面临的困难。当开发者被问及安全方面的考虑时，大多数人（43%）相信雇佣专门的安全专家来监督项目或者增加对贡献者本身的报酬和培训有助于提高安全性。</p><p>&nbsp;</p><p>在较小的范围内，各种水平的开发者借助开源代码库来解决问题、扩展他们的技能或处理新的场景——这些带来了个人和专业方面的好处。35%的开源开发者表示，他们通过开源贡献提升了自己的技能，19%的人表示他们与更多人建立了联系，还有11%的人甚至因此找到了工作机会。强大的开源社区也是让开发者继续做出贡献的关键——32%的开发者表示，开源贡献让他们感觉到“意义或作为社区一份子的归属感”，20%的人甚至扮演了导师的角色，帮助其他社区成员发展他们的技能。</p><p>&nbsp;</p><p>尽管大部分都是无偿的，但这些志愿者工作、指导和社区在保持开源活跃度和参与度方面发挥了关键作用，即使开源开发者面临时间和技术债务方面的挑战。<a href=\"https://streaklinks.com/BGxxDTHenro2sEVPdAuTU0HU/https%3A%2F%2Foctoverse.github.com%2Fsustainable-communities%2F\">GitHub 2021年度Octoverse状态报告</a>\"显示，开源社区的指导承诺使开源项目的生产力提高了46%。这种效应在工作场合中也能看到，“指导几乎让形成强大的文化具有成倍的可能性”。在合适的环境下，强大的开发者社区会让开源变得更好，强大的开源社区也会让开发者变得更好。</p><p></p><h2>开源的未来</h2><p></p><p>&nbsp;</p><p>当关于公司和组织如何回馈开源社区的问题出现时，支付报酬成了一个首当其冲的话题。开源贡献的报酬是一个备受争议的话题。一方面，大多数开发者（在DigitalOcean的报告中有53%的开发者）似乎都同意或非常同意个人应该为从他们的开源贡献中获得报酬，而另一方面，也有开发者担心开源盈利或融资模型可能会导致开发生态系统变得更加封闭，而不是更加开放。</p><p>&nbsp;</p><p>企业可能不愿意为开源软件付费，或者为开源贡献付费，但一些行业领袖已经在探索其他替代方案，作为一种与社区更深入合作并“回馈”社区的方式。例如，去年思科聘请了一个开源主管，作为开源计划、思科客户和不同商业团体之间的“结缔组织”，希望为那些“隐形工作”的开发者和维护者提供支持。然而，这些角色或计划在很大程度上依赖于内部有人倡导开源，并说明构建开源社区的ROI。最近，这些工作落在了开发者关系（DevRel）和开发者倡导团队（这些团队开始在一些大型科技公司中不断发展壮大）的肩上。</p><p>&nbsp;</p><p>开发者认为，公司可能可以将工作时间的一部分分配给开源，这是解决时间和优先级问题的一个潜在的解决方案。79%的被调查开发者同意或强烈同意公司应该将部分工作时间分配给开源。在未来，开源贡献可以包含在开发者的工作描述中，或者公司可以将开源时间纳入到员工志愿者工作和大型企业常见的社会公益项目中。特别是在后疫情工作场所当中，员工现在比以往任何时候都更有可能希望将自己的时间和技能贡献给他们认为有价值的工作或回馈给社会。如果不鼓励将工作时间分配给开源项目或进行志愿者项目，公司可能会错过一个可以解决开源信任问题和员工参与度问题的解决方案。</p><p>&nbsp;</p><p>激励参与开源的问题也可能是一个代际问题——经验较少的开发者（不足一年）比经验丰富的开发者更有可能在过去的一年中参与过开源项目。我们可以推测，也许更有经验的开发者在成长为更高级的角色时，会遇到更大的时间限制和带宽问题，这将取决于公司如何提供公平的竞争环境让所有类型的开发者都有机会参与到在公司级别的开源计划中。这看起来就像是在生产进度中为开源贡献和评审分配时间，或者让开源责任成为某些角色或头衔的关键组成部分。</p><p>&nbsp;</p><p>最终，技术领导者、公司和个人开发者将不得不协同工作，有效地最大化开源为行业带来的创新和好处，同时又不失去社区和协作的整体价值（这是开源项目的关键）。就目前的情况而言，开源项目代表我们正在通过最好的、最具合作性质和最富激情的方式使用技术。开发者可以获得指导和新的机会，以最符合他们兴趣的方式发展他们的技能。正如大多数工程专业人士和团队领导者已经认识到的那样，工作场所可以多一点这种精神。</p><p>&nbsp;</p><p>作者简介：</p><p>&nbsp;</p><p>Al Sene是DigitalOcean的工程副总裁兼架构总经理。Al负责推动DigitalOcean关键服务和产品的创新和速度，以满足客户不断变化的需求。在加入DigitalOcean之前，Al曾担任DDN和NexGen Storage的工程副总裁，后者被Fusion-io和SanDisk收购。他还在惠普担任过几个技术和管理职位，并持有存储专利。他在St. Cloud State University学习计算机科学，并在Colorado State University获得工商管理硕士学位。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/open-source-contributing-development/\">How Open Source is Contributing to Your Team’s Development: What Leaders Should Know</a>\"</p><p></p><p>InfoQ 发布<a href=\"https://www.infoq.cn/minibook/DTAg4l8piWHrBGfU3der\">《中国开源发展研究分析 2022 》研究报告</a>\"，为开发者，技术管理者，开源社区运营、市场，开源办公室工作人员以及其他对开源有一定基础认知，但期待进一步了解开源、理解开源的朋友，带来信息上的增量以及对开源趋势、开源人画像方面的关键洞察。</p>",
    "publish_time": "2022-08-17 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "龙蜥社区正式发布virtio 1.2，打造新版虚拟化 IO 标准",
    "url": "https://www.infoq.cn/article/QF4BocH6R58D2fHVka0r",
    "summary": "<p></p><h2>一、virtio spec 是什么?</h2><p></p><p></p><p>在云计算如火如荼的今天，我们应该经常可以在云计算平台上看 \"virtio\" 这个词，它出现在云计算机的各种设备上：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e0/e06b1529263c3fe2b554db66176c942a.png\" /></p><p></p><p>它是怎样的一种存在，在虚拟化的技术领域扮演着一种怎样的角色呢?</p><p></p><p>virtio 是一种 I/O 半虚拟化解决方案，是一套通用 I/O 设备虚拟化的程序，是对半虚拟化 Hypervisor 中的一组通用 I/O 设备的抽象。</p><p></p><p>一般来说，我们所说的 virtio 包含三个部分：</p><p></p><p>虚拟机中的 virtio 网卡驱动宿主机或者 CIPU 上面的 virtio 设备的实现virtio spec (规范)前面两个是 virtio 在不同的操作系统及计算机模拟器中具体实现的 driver 和 device，driver 和 device 如何实现并没有严格的规定，基于其所处的环境不同而有所区别，但是 driver 与 device 之间的交互必须严格遵守 virtio spec 的定义。这样才能保证所有的 OS 在不同的 host 上的模拟器里面都可以正常运行。</p><p></p><p>所以 virtio spec 是 virtio 的灵魂。</p><p></p><p>virto spec 通过定义一套 virtqueue 机制，实现 guest 和 host 的通信。这套机制可以应用于多种设备(网络设备、块设备等)。所以 virtio spec 发展出了多种设备，基本完成了对于虚拟化场景下各种设备的覆盖。</p><p></p><h4>1.1 我们为什么选择它呢?</h4><p></p><p></p><p>virtio 是一种半虚拟化的技术，如果对于设备进行全虚拟化，hypervisor 就要对于所有的硬件请求指令进行截获，这对于性能的影响是巨大的。</p><p></p><p>但是实际上 guest 本质上是一个 host 上的进程，它与 hypervisor 进行交互并不用这么麻烦，完全可以基于进程之间的通信方式进行交互。只是这种方式要 guest 进行配合。所以基于此实现的 virtio 可以获得更高的性能。这也就是 virtio 获得广泛支持的原因。</p><p></p><h4>1.2 virtio spec 的历史</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/75/75fb596fc4d782026ab2ab6c98dffffc.png\" /></p><p></p><p>2012 最早由 Rusty Russell 起草的并不是一个正式的规范。后续 virtio spec 由 virtio 技术委员会负责，并发布了多个版本。在委员会的主持下，社区的广泛参与下，不断地为 virtio spec 增加新的特性与能力，目前 virtio spec 已经推进到 v1.2 版本。</p><p></p><h4>1.3 virtio spec 1.2 关键时间点</h4><p></p><p></p><p>25 Jan 2022 virtio spec 冻结10 May 2022 &nbsp;- 08 June 2022 Public Review01 July 2022&nbsp;virtio v1.2 正式版本完成 &nbsp;html15 July 2022 virtio v1.2 正式对外宣布发布 announcement经过半年多的努力，vrtio 1.2 终于正式发布了。</p><p></p><h4>1.4 virtio spec 1.2 新特性</h4><p></p><p></p><p>首先 virtio spec &nbsp;1.2 对更早的版本是完全兼容的，virtio spec 定义的所有特性都是通过 features 进行协商的，所以在实现上可以平滑地进行过渡。并不存在升级之后不同版本之间的不兼容问题。</p><p></p><p>在设备方面 virtio spec 1.2 新支持了一些设备: virtio-pmem，virtio-fs， virtio-rpmb......</p><p></p><p>一些主流的设备也支持了一些新的特性，比如 virtio-net 增加了这些新的特性：</p><p></p><p>UDP segmentation offloadReceive Side ScalingPer-packet hash reportingGuest hdrlen optimizationLink speed and duplex reporting此外， virtio core 还增加了一些新的基础特性：Per-virtqueue resetShared memory resourcesObject resources for inter-device sharingVirtio-pci vendor-specific capabilitiesVirtio-pci queue_notify_data optimization总体而言，这次 virtio spec 1.2 的发布带来了很多让人激动的新特性。相信等这些功能正式实现之后，我们会感受到更加现代化的 virtio。同时也是一个驱动各个厂家完善自家 virtio 实现的机会。</p><p></p><h2>二、Per-virtqueue reset</h2><p></p><p></p><p>virtio spec 1.2 中的 Per-virtqueue reset 是由阿里云的 Xuan Zhuo <a href=\"mailto:xuanzhuo@linux.alibaba.com\">xuanzhuo@linux.alibaba.com</a>\"起草的，引入这个特性的目的是解决 virtio-net 不支持队列级别的 reset 操作的问题。这在很多现代化的网卡中是一个比较常见的功能, 是实现很多功能的基础能力, 为了让 virtio-net 支持更多能力, 这个特性的引入是必须的。但是 Per-virtqueue reset 并不只限于 virtio-net 这一种设备，它是一个 virtio 的基础能力，相信其它的 virtio 设备也会慢慢支持这个 feature。</p><p></p><h4>2.1 Per-virtqueue reset 的实现过程</h4><p></p><p></p><p>Per-virtqueue reset 由 driver 针对某一个队列发起，基于某一种 transport(比如 PCIe) 通知 device。device 停止使用队列，driver 在 reset 之后可以重新 re-enable 队列。virtio spec 定义了这个过程中详细的交互流程和信息。</p><p></p><p>以下是 virtio spec 中定义的详细流程：</p><p></p><p>driver 基于 transport 通知 device 某个指定的队列要 reset。device 收到请求之后设置 reset 状态为 1，停止此队列的所有操作，包括中断等，并设置队列的所有的状态到初始值。在 device 完成 reset 操作之前，返回给 driver 的 reset 状态都是 1，直到 reset 操作完成。reset 完成之后 reset 及 enable 的值都要设置成 0。driver 在检查到队列的 reset 状态变成 0 之后，就表示device reset 操作已经完成了。这个时候开始，driver 就可以安全地回收队列占用的相关资源了。到此 driver 对于队列的 reset 操作就已经完成了。之后 virtio driver 可选地进行 re-enable 操作，在操作的过程中，driver 可以给 device 新的参数来 re-enable 这个队列。比如新的队列大小。以上是一个完整的 reset &amp; re-enable 的过程，理论上 re-enable 是可选的。</p><p></p><h4>2.2 Per-virtqueue reset 的意义</h4><p></p><p></p><p>对于现代的很多硬件设备来讲，对于队列进行 reset 是一个比较常见的功能，所以这个功能的引入让 virtio 设备更加现代化。早期 virtio 的出现是伴随着高性能的需求而来的，我们原来更加关注它在性能上的基本功能，一些高级功能并不重视。per-virtqueue reset&nbsp;让 virtio 对于队列的使用更加灵活，譬如我们可以基于 per-vertqueue reset 实现下面两个功能：</p><p></p><p>1.调整virtio-net 网卡队列的ring size。在 virtio-net 的场景下，基于&nbsp;per-virtqueue reset&nbsp;我们可以实现网卡队列 ring size 的调整。目前一般的网卡都支持使用&nbsp;&nbsp;ethtool -G eth0 rx  tx 来调整队列的大小，但是原来的 virtio-net 一直是不支持这样一个简单的功能的，现在基于 per-virtqueue reset，我们很快就可以在 Linux 下使用这个命令来调整队列的大小。</p><p></p><p>2.支持AF_XDP，扩展云上应用的边界。除了应用于上述简单的场景之外，我们还可以在更高级的场景应用到这个功能。per-virtqueue reset 也可以视作一种资源的快速回收机制。比如在 virtio-net 的情况下，我们必须要等待收到新的数据包或者硬件完成数据包的发送才能完成对于 buffer 资源的回收。而现在基于&nbsp;per-virtqueue reset，driver 可以不用被动地等待而是可以主动调用 reset 快速地让 device 释放对于某个队列上的 buffer 资源的占用，实现资源的快速回收。这可以让 virtio-net 支持 AF_XDP 这样的高级功能，实现在 linux 内核框架下的高性能收发包。</p><p></p><p>更多的应用场景还等待大家的探索。</p><p></p><h4>2.3 实现及进展</h4><p></p><p></p><p>以上都是 virtio spec 的定义，Xuan Zhuo作为这个 feature 的起草人，在这个 feature 正式进入 virtio spec 之后，就开始向 Linux kernel 社区开源相关的实现，其它 device 后端实现也都在推进中:</p><p></p><p>virtio core 支持 per-virtqueue reset 功能的 patch set 近期应该可以进入 linux 内核主线，这个 patch set 里面包含 virtio-net 支持 ring size 的实现。virtio-net 支持 AF_XDP 的实现也会近期开源到社区。qemu/vhost-user(DPDK)/vhost-kernel 的后端实现也在推进中&nbsp;@Kangjie Xu <a href=\"mailto:kangjie.xu@linux.alibaba.com\">kangjie.xu@linux.alibaba.com</a>\"。相信大家不久之后就可以在新版本的 Qemu 及 linux kernel 上体验到这个功能了。</p><p></p><h2>三、高性能网络&nbsp;Virtio SIG</h2><p></p><p></p><p>virtio 作为一个云计算大范围使用的技术，国内的各大云厂家基本都是基于它实现的，但是这么些年我们对它的反馈与参与是非常少的，基本都是拿来主义的状态。最近，我们开始注意到，阿里等国内的云厂家开始积极地参与其中，修复 bug，参与标准制定，推进实现等， 一起推广及做强云基础技术。这对于国内云技术的长远发展是非常好的一件事。希望这样的深度的参与越来越多，共同推进 virtio 的发展。</p><p></p><p>为了更好地支持更多的特性和优化在龙蜥操作系统的落地，我们在龙蜥社区高性能网络SIG下组建了 virtio 兴趣小组，通过加强社区内各个 virtio 相关的团队及公司之间的合作，增强彼此在这一块的沟通和了解，从而推动 virtio 本身以及其在龙蜥更好的发展。希望后续有更多的社区伙伴来共同参与进来，也欢迎大家积极参与讨论，提问题或需求，大家以一种平等的关系共构建龙蜥社区的&nbsp;virtio SIG。我们认为这是一个共赢的过程。</p><p></p><p>原则：共赢、平等、开源。</p><p></p><p>愿景：</p><p>探索 virtio 标准的更多可能性，推进 virtio 标准实现与落地促进技术交流提供技术帮助为各个伙伴提供需求输入同步各个伙伴的开发进展促进各个伙伴之间的合作</p><p></p><p>SIG 成员：丁雪峰(阿里)、衡琪(阿里)、许康捷(阿里)、马江英(Intel&nbsp;&nbsp;CNDP)、 顾正国(云豹智能)、 张明礼(云豹智能)、 杨涛(云豹智能)、孙传明(云豹智能)、龚有华(云脉芯联)、孟祥宏(云脉芯联)、陈杨(云脉芯联)、钱荣(云脉芯联)。</p><p></p><p>欢迎大家加入高性能网络 Virtio SIG。</p><p></p><p></p><blockquote>SIG 地址链接：<a href=\"https://openanolis.cn/sig/high-perf-network\">https://openanolis.cn/sig/high-perf-network</a>\"</blockquote><p></p>",
    "publish_time": "2022-08-17 10:02:30",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "企业级证券业务中台探索与实践",
    "url": "https://www.infoq.cn/article/PQJM9YHHafAD9c7BNUsu",
    "summary": "<p></p><h2>一、背景</h2><p></p><p></p><p>近年来，随着移动互联网、大数据和人工智能等新技术的全面深入应用，以及新商业模式的涌现和财富管理转型，对证券公司的 IT 能力提出了新的挑战。如何快速响应业务的需求、提供差异化的服务、满足投资者个性化的需求，成为摆在证券公司 IT 建设面前的巨大挑战。总体来说，券商在系统建设过程中仍存在不少的痛点，主要如下：</p><p></p><p>“烟囱式”建设，与大多数公司一样，东方证券系统以往多采用“烟囱式”发展方式，系统各自为政，功能大量重复，例如证券公司面向零售客户的网上交易系统，一般都有通达信 / 同花顺等，面向机构客户的 PB 产品端往往有恒生 / 迅投 / 根网等系统，架构层面也缺乏统一规划和管控，技术成果更加无法共享；单体架构，牵一发而动全身，且系统相互之间耦合度高，相互影响，无法保证 7*24 小时业务开展；技术架构异构化，各个系统的功能调用方式、支持的开发语言、调用入口等等也不尽相同，形成了系统间的技术壁垒。在此基础上再进行系统开发以及进一步的迭代，其技术难度和风险也非常大；交付速度慢，核心系统建设多以购买为主，需求响应缓慢，受制于人；</p><p></p><h2>二、中台定义</h2><p></p><p></p><p>从 2015 年开始，以阿里巴巴为代表的各互联网巨头，陆续开启中台化进程，随后，“中台化”的理念与相关实践开始快速向各行业渗透和发展；对于金融行业，打造中台能力，无论是银行、证券或是保险等细分行业，均已是高度共识的战略举措之一。与此同时，证券行业财富管理转型、客户需求日新月异、IT 改造难度加大等现实状况也日益严峻。为了促进公司数字化转型，基于企业现状及未来展望，东方证券也提出了“薄应用 厚中台 稳后台”的企业中台战略规划。</p><p></p><p>中台的定义各有不同，如阿里[1]官方定义“业务中台就是将企业的核心能力随着业务不断发展以数字化形式沉淀到平台，形成以服务为中心，由业务中台和数据中台构建起数据闭环运转的运营体系，供企业更高效的进行业务探索和创新，实现以数字化资产的形态构建企业核心差异化竞争力。”Gartner [2]将中台定义为企业应用系统的 SOD 层，是灵活响应的前台与稳定可靠的后台之间的“变速齿轮”，ThoughtWorks[3] 定义为企业级能力复用平台，是面向用户与创新的新兴平台型企业组织。</p><p></p><p>东方证券企业级业务中台的核心建设目标是基于 API 化的开放式模块化架构核心思想，将核心业务知识进行沉淀，以模块化、服务化、共享化的形式建设企业级业务能力，从而快速响应市场变化和客户需求，提升业务交付效率，破除证券前台业务快（敏捷响应）和后台稳（坚实支撑）之间的“发展速率脱节和失配”的突出矛盾。</p><p></p><h2>三、企业业务中台建设原则</h2><p></p><p></p><p>企业业务中台建设对于证券行业来说也是一个新生事物，为此在实际建设过程中，我们遵循如下建设原则：</p><p></p><p>业务引领</p><p></p><p>中台的建设是以提高业务响应为目标，所以需从自身商业模式和市场需要出发，围绕业务目标，按照中台的理念推进业务 / 技术架构变革，而不是简单跟风和模仿，为中台而中台；</p><p></p><p>领域划分</p><p></p><p>按照领域驱动的原则，在战略阶段划分问题域，确定核心领域，将系统划分为多个业务能力中心，当系统划分为多个业务能力中心后，中台建设就进入战术阶段。在战术阶段，针对已确定的各业务能力中心，结合业务需求进行具体的领域设计。</p><p></p><p>统一视角</p><p></p><p>企业业务中台面对众多业务线，需要站在业务整体视角，如 PC 网上交易、APP、临柜等，梳理业务流程，统筹考虑建设，要将后台资源抽象、沉淀和整合，包装成便于前台使用的可复用、可共享的核心能力，实现后台资源到前台易用能力的简化。</p><p></p><p>能力复用</p><p></p><p>中台是针对“商业模式”和“业务模式”的抽象与复用，沉淀共享能力，以可重用和可复制方式输出给各渠道产品线，以组件和能力编排实现业务场景化应用，并以服务化的形式输出能力。</p><p></p><h2>四、用户业务旅程</h2><p></p><p></p><p>区别于互联网行业及其他传统行业，证券行业也有其自身行业特点，我们站在用户的视角，具体来分析下券商用户的核心业务旅程，以券商用户目前应用最为广泛的 APP 应用为例，其典型具体业务旅程如下：</p><p></p><p>打开 APP，进入首页，查看各类资讯；进行手机号注册，注册后点击登录进行认证登录，进行积分等权益登记；提示开立资金账号，点击开立后，上传各类资料，进行风险评测及双向视频验证；资金账户开立，适当性管理，可进行各类业务办理；点击银证转账，设置银行账号，转入 / 转出资金；点击理财页面，查看各类理财产品信息；点击产品购买，进行适当性判断，进入理财产品购买流程；点击基金投顾页面，配置基金投顾服务；点击行情页面，查看市场行情；点击交易页面，点击买入 / 买出，进行场内交易；点击资产页面，查看资产详情；点击商城页面，查看 LEVEL2 等非金融产品，可使用积分 / 第三方 / 保证金等方式购买非金融产品；</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/55/5548ffdf610cdb977fffad046975586f.png\" /></p><p></p><p>图 1 &nbsp;用户业务旅程图</p><p></p><h2>五、业务中台整体架构</h2><p></p><p></p><p>通过对用户旅程进行分析，可以得知，券商客户的核心业务领域主要涉及行情、资讯、账户、资金、认证、产品、基金销售 / 投顾、场内交易、资产及商城等核心场景。因此，根据业务单一原则，如图 1 所示，东方证券将企业业务中台主要划分为账户、产品、财富、资产、行情、资讯、交易、认证、支付、会员、权益、投研等能力中心，形成“薄应用 厚中台 稳后台”的企业架构全景。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/6e/6ed7f5c10664fbbd69401c54bf45c02c.png\" /></p><p></p><p>图 2 &nbsp;东方证券企业架构全景图</p><p></p><p>部分能力中心定位分别如下：</p><p></p><p>账户中心，建设权威、完整、标准的账户主数据中心，进行账户类业务受理及办理，提供各类账户全生命周期及适当性管理，并为各业务渠道提供数据服务；</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/12/12628d5332d2628d52c05be35bf99e10.png\" /></p><p></p><p>图 3 &nbsp;账户中心架构图</p><p></p><p>财富中心，对接场外交易系统原子能力，进行金融产品销售业务流程封装，提供场外交易统一接入服务能力；</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/82/822762b9f7b6a88c070d7784882f7f9c.png\" /></p><p></p><p>图 4 &nbsp;财富中心整体架构图</p><p></p><p>产品中心，建设公司级金融产品仓库，覆盖公司全业务全类型的金融产品及产品化业务，从产品引入、产品上架、产品库管理、销售支持、营运管理到售后的分析报表与绩效考核，实现金融产品全生命周期管理，成为公司金融产品标准和权威的来源；</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/60/6098f720d8f7d9fd07eb2afca88f4629.png\" /></p><p></p><p>图 5 产品中心架构图</p><p></p><p>交易中心，统一制定场内交易协议，一方面屏蔽各柜台接口差异性（各交易中心须按交易接入中心协议进行对接），进行交易系统路由，对交易业务进行管控，另一方面对接场内竞价原子能力，对竞价业务流程进行组合包装，统一提供场内竞价业务能力；</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e4/e49b7d4e0753190e42641876deaa4c64.png\" /></p><p></p><p>图 6 &nbsp;交易中心架构图</p><p></p><p>资产中心，整合各个相关业务系统的底层数据，汇总交易和回报的实时数据，承接交易清算数据，进行交易明细数据、资产查询及各类衍生指标的计算和服务，为客户提供更加深度的资产交易查询分析服务等功能（7*24 小时服务)，统一提供用户整体资产解决方案；</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/0c/0c49bcabac5e34cd99e68e0134c223b9.png\" /></p><p></p><p>图 7 &nbsp;资产中心整体架构图</p><p></p><p>资讯中心，统筹管理公司内外各类资讯数据源，对资讯数据进行提取、清洗、加工、存储等操作，形成资讯数据标准，对资讯数据进行全生命周期数据管理，并对外整体提供资讯类服务；</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b3/b38bfd2578c58c8b3739b28d4a2d6eb4.png\" /></p><p></p><p>图 8 资讯中心架构图</p><p></p><p>行情中心，整合接入了国内外主要金融市场的交易行情，提供了行情接入与推送、存储、回放、计算及分析等领域的一体化解决方案；</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/25/253f7e28ca5b017be2c7f8c4ad316bcd.png\" /></p><p></p><p>图 9 行情中心架构图</p><p></p><p>权益中心，旨在为公司客户的数字化商品权益和卡劵类等虚拟资产提供管理功能，为相关的运营体系提供基础服务，系统提供的主要服务包括权益管理、卡劵管理和内控管理。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/69/69cfe2ae33010b4cf9a173837e96519c.png\" /></p><p></p><p>图 10 &nbsp;权益中心架构图</p><p></p><p>投研中心，贯穿投前、投中、投后整个投资研究过程，进行分析、决策、投资的整体投研流程生命周期管理，提供资产配置，数据服务，算法服务，因子计算、策略回测与分析等投研相关服务；</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3b/3b06bb9822818996aca9aef90d4ab2ae.png\" /></p><p></p><p>图 11 投研中心架构图</p><p></p><p>认证中心，以用户身份管理为核心，加强管理 B/S、C/S、移动 APP 等结构的多应用的安全访问机制，集身份管理、身份认证、授权管理、应用资源访问控制及其安全审计于一体，构建多信息资源的应用整合、集约管理和安全防护的安全基础服务平台；</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/90/90d945f2688cd221f0db78961ee65536.png\" /></p><p></p><p>图 12 &nbsp;认证中心整体架构图</p><p></p><h2>六、DDD 领域驱动建模</h2><p></p><p></p><p>领域拆分各能力中心内部先进行模块化的拆分，可以先按照业务类型进行拆分，如场内交易可拆分为股票、信用、期权等模块。模块内部要进行更为细致的服务拆分，运用领域驱动建模的方法论，实现“高内聚低耦合”的业务模型。根据模型的关系进行划分限界上下文，限界上下文往微服务转化，并得到系统架构、API 列表、集成方式等产出，形成良好的微服务架构设计，避免形成大单体或混沌的微服务架构，核心原则是单个服务可独立开发、独立部署及运行，如财富中心 / 交易中心服务可拆分为下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b0/b093120047e9cf72edc75ac73f056444.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d4/d430dd10207158089e49c3ad2af44757.png\" /></p><p></p><p>图 13 领域模型示意图</p><p></p><p>分层代码架构如图 14 所示，在具体代码模块内部，基于 DDD 模式，建立清晰的应用层、接口层、领域层和基础设施层代码结构，易于后续的代码变更、升级及维护；</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e7/e791f2ac0d6882445d6fa3ae789d14c9.png\" /></p><p></p><p>图 14 分层代码架构</p><p></p><h2>七、技术架构</h2><p></p><p></p><p>技术框架是业务中台成功的基石，为此，东方证券进行了体系化的技术架构建设，为企业业务中台提供了全方位的技术支撑。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a6/a667ce9b5de3a6f578da1f4680ef2a04.png\" /></p><p></p><p>图 15 &nbsp;东方证券企业中台技术架构图</p><p></p><p></p><h3>7.1 服务治理框架</h3><p></p><p></p><p>券商传统信息系统多采用单体架构模式开发，把所有的功能都打包在一个独立单元中，并当作一个整体来开发、测试和部署。然而，随着业务的爆炸性增长，应用系统规模不断增大，单体架构将给业务系统的开发、维护、部署带来巨大的问题。为此，东方证券也制定了企业技术架构向以微服务为核心的现代化架构转型。通过对比 gRPC[6]、Dubbo[7] 及 SpringCloud[8] 等业界主流框架，基于证券行业的特点，我们选择了具有跨语言特性的 gRPC 为核心框架，并在其基础之上新增服务治理特性，建设了 gRPC-Nebula 服务治理框架和星辰服务治理平台，从而实现企业内部及外部服务的统一化管理，构建服务调用关系及拓扑结构，优化改进服务质量。图 16 展示了东方证券服务治理平台的总体架构。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c7/c7c284da3606737b90a0f4e415381a26.png\" /></p><p></p><p>图 16 &nbsp;东方证券服务治理总体架构</p><p></p><p>东方证券服务治理框架主要包括如下跨语言微服务通讯框架、注册中心、服务消费者（客户端）、服务提供者（服务端）、信息收集器、数据处理引擎、服务治理门户等模块。相对于原生 gRPC 框架，gRPC-Nebula 服务治理框架引入了 ZooKeeper 作为注册中心，融合了服务注册发现、负载均衡、黑白名单、动态分组、集群容错、流量控制等服务治理机制。服务治理框架详细介绍参见东方证券企业架构之技术架构转型实践[15]。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/9d/9de31cfd5cfc7f0464996d2e4b3eb241.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/61/61499a31c7e595cec36b4f7629ef3e29.png\" /></p><p></p><p>图 17 &nbsp;服务治理应用图</p><p></p><h3>7.2 PaaS 平台</h3><p></p><p></p><p>随着互联网场景的不断延伸，业务系统对高吞吐低时延的要求越来越高，而开源中间件作为其中的佼佼者很好地承接了互联网业务的发展，同时也支撑了其它各类业务场景的探索，为此我们在 PaaS 平台上做了如下工作：</p><p></p><p>建设了标准化的 PaaS 平台，对市场上主流的开源中间件进行了筛选，包括 Kafka、Redis、Zookeeper、Nginx、elasticsearch 等各类中间件，并设置相应版本基线；发布了 PaaS 管理规范的架构决策，从架构治理上了规范了 PaaS 中间件的使用；对各类中间件进行全生命周期的纳管，供各应用方申请使用；对于业务应用最为常用的三个核心中间件 Kafka/Redis/Zookeeper，实现了同城三机房高可用部署，支撑各类应用由目前的单活向多活的高可用架构演进，如图 18，19，20 所示；</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/30/309783701a93a0011cc8830d03c0f4c9.png\" /></p><p></p><p>图 18 &nbsp;ZooKeeper 三机房高可用架构</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/53/53e2d1f86705f8a9f9af5d70df5fcad7.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/8b/8b18fdaf9d0d2d57294cc55b87121580.png\" /></p><p></p><p>Redis Sentinel &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Redis Cluster</p><p></p><p>图 19 &nbsp;Redis 三机房高可用架构</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b9/b977631e2b9425140f99ea2fe28b196e.png\" /></p><p></p><p>图 20 &nbsp;Kafka 三机房高可用架构</p><p></p><h3>7.3 应用多活</h3><p></p><p></p><p>“应用多活”是“应用容灾”技术的一种高级形态，指在同城或异地机房建立一套与本地生产系统部分或全部对应的生产系统，所有机房内的应用同时对外提供服务。当灾难发生时，多活系统可以极短时间内实现业务流量切换，用户甚至感受不到故障发生。常见的应用多活架构分为同城多活、异地多活、混合云多活，和传统容灾相比，应用多活具备 RTO 低、资源充分利用、切换成功率高、流量精准控制等优势。如图 21 所示，我们主要在同城多活做了以下工作：</p><p></p><p>首先，将各业务应用中经常使用的 PaaS 中间件 (Zookeeper/Kafka/Redis) 进行多活机房部署；其次，由于 gRPC-Nebula 框架所依赖的 PaaS 中间件 Zookeeper 已实现多机房部署，并配合框架本身的多机房分组功能，实现 gRPC-Nebula 的多活架构；最终，依赖 gRPC-Nebula 开发框架与 PaaS 中间件的结合，从而实现各应用的多活架构，最终实现企业架构整体应用多活；</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5e/5e46783811fd20fabd036d608be50dc3.png\" /></p><p></p><p>图 21 &nbsp;gRPC-Nebula 应用多活架构</p><p></p><h2>八、研发管理</h2><p></p><p></p><p>整个企业业务中台为巨型系统，且从业务需求视角出发，关联系统众多，所以需要有规范的研发管理制度和工具链来保障整体的交付效率及交付质量。</p><p></p><p>代码分支管理，采用 Bitbucket 进行代码管理，并以经典的 Git Flow 模型为代码分支管理工作流程，以 master 版本生产发布，dev 分支为主开发，feature 分支为特性开发，release 分支构建，生产合并主干，hotfix 分支紧急修复 bug 的原则；</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/03/03d7b663e4987497d1439b9e9f4059e0.png\" /></p><p></p><p>图 22 &nbsp;Git Flow 分支模型</p><p></p><p>版本火车发布，如图 23 所示，建立版本火车的研发管理模式，每个模块或服务建立清晰的版本发布计划，同时整体研发活动有明确的需求评审 --&gt;架构设计评审 --&gt;代码 review–&gt;接口评审 --&gt;测试案例评审 --&gt;验收评审 --&gt;各类变更评审 ;</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d3/d37a3690a940a9293c1502f46aa2b11d.png\" /></p><p></p><p>图 23 &nbsp;研发版本火车发布模式</p><p></p><p>研发流水线，如图 24 所示，建设研发运行一体化平台，集成各类工具，紧紧围绕制品版本，建立严格的质量门禁和自动化测试体系，实现整个代码编译 - 打包 - 测试 - 发布自动化流水线作业，大幅提升交付质量及交付效率；</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/0a/0a4d5f398516f46691155915e78f0b8f.png\" /></p><p></p><p>图 24 &nbsp;研发运行一体化平台架构图</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/07/07f6bd100f517e491c67572e599aebd9.png\" /></p><p></p><p>图 25 &nbsp;研发运行一体化流程图</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/64/642b11f43850b2f870301222e85f1a1a.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7b/7b97d6ac7cf7beedb083c4c4faf332dd.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/17/17d56c94c521d40446f89ba62a48a2d0.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/93/934e8559bc5af77ee37815356c9a160d.png\" /></p><p></p><p>图 26 研发运行一体化应用图</p><p></p><p>数据治理，以业务中台为基准形成主数据中心，确定整体各业务的词根、数据字典、公共代码等数据规范，形成公司级业务术语、标准词根及公共代码，并将数据治理流程嵌入整体研发流程，在接口评审中对数据字段及人工代码进行审核；</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/26/2616ff0c45b102ef2d4a0c2af231968e.png\" /></p><p></p><p>图 27 业务术语标准示意图</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ba/ba2f1a34136d431c6e6fb6254e4c079a.png\" /></p><p></p><p>图 28 &nbsp;数据治理接口评审示意图</p><p></p><h2>九、实践成果</h2><p></p><p></p><p>从 2019 年初开始，东方证券确定了企业大中台战略，围绕业务价值与 IT 用户体验，大力推进“薄应用，厚中台，稳后台”的架构转型，并通过制定架构标准推动相应领域建设，经过三年多的建设，截止到 2022 年 8 月底，形成了体系化的技术架构和数字化管理能力，各业务中台上线对外服务数 195 个，对外接口总数达 1822 个，日峰值请求量 4600 万 + 次，对接各类业务需求 450+（不完全统计），形成数据治理词根 2436 个，字段 1554 个，公共代码 13 个，已深入经纪、财富管理、期货、资管、PB、自营等业务领域，初步形成了集团协同能力，为东方赢家 APP、网上交易 PC 端、机构交易客户端、机构理财客户端、CRM 等业务线提供共享能力服务，并成功实现了财富管理业务领域需求全覆盖，助力东方证券以客户数排名 38 名，经纪业务排名 20 名，取得了公募基金保有量在行业排名第 7 位 [16]的成绩，整体上线业务需求达 90%，通过技术共享、服务共享、数据共享、研发规范，有力的提升了开发效率，降低了对开发商的依赖和系统研发成本，避免了系统的重复建设和异构化，提升了业务需求的交付速度，沉淀了证券核心领域业务知识库和领域，对于增强公司科技创新应用能力，激发行业技术创新动力，发挥了重要作用。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/9e/9e08b6ba14f00557eb64f87975d4f04c.png\" /></p><p></p><p>图 29 东方证券企业中台对外接口数</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/86/86617c60166798bd79a66ac3f326e2ee.png\" /></p><p></p><p>图 30 东方证券企业中台接口峰值访问量</p><p></p><p>账户中心，使原有账户系统的功能外延大范围扩展，支持 7*24 小时不间断接口能力服务，不受后端处理系统影响；具备健全、细化的投资者适当性管理，灵活满足监管要求；并为各个业务系统提供统一、权威、标准的客户账户数据服务。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/2e/2e7adb614fdc4c7abe327b76a6f8e238.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ff/ffb39073da56850521c2f0c51352b231.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f4/f473c31d8adda0cc8c7148a2bdb95fdb.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/99/99fb8a08ffb5e6083e7ab85c98ba3235.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5d/5daad53ae19a5034a55d75b8ceeaa967.png\" /></p><p></p><p>图 31 &nbsp;账户中心应用效果图</p><p></p><p>财富中心，建成了基于金融产品全生命周期交易的业务组装平台，打破账户、产品以及各单一业务后台系统的局限性，促使业务融合并优化产品销售能力，面向 APP、PC 等终端，为客户提供产品适当性匹配、认购、申购、赎回、持仓等的交易前、中、后的业务逻辑编排能力，实现金融产品的 7*24 小时交易能力。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/26/26b83a8293984d2ed23d1df6f9887e81.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b8/b8d6f3b4274d9e26a10b75157ce06a5d.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/8f/8f4a0c355ef5a5d126a3f9c248a2f626.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/11/11d213e8f7724d585eddb8128931c126.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7c/7ccff760bc7c87b18bbdb0ef6ddb9cc5.png\" /></p><p></p><p>图 32 财富中心应用效果图</p><p></p><p>产品中心，实现了金融产品管理和服务从离散化向集中化、服务化、中台化的转化。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3c/3c18e2075f9dc070760b7604bc58df95.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c7/c78c7665a95d9e5a508b49ed7c8ebdd2.png\" /></p><p></p><p>图 33 产品中心应用效果图</p><p></p><p>资产中心，其应用场景适用于除了核心交易链路之外的大部分资产交易数据服务场景，面向 PC/ 移动 APP/CRM 等业务系统，提供准确的实时资产查询 / 个性化资产分析，实时推送服务 / 推荐，其他衍生场景，能灵活适应业务的资产呈现方式，并将部分查询和统计分析类增值服务从交易系统解耦，降低交易系统查询压力。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/cb/cb94f2f938b3b70e9ce0d0952ff7857f.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/6f/6f33fa1d363988ff50a4f91cc69f9737.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/91/9187ef4187b0e955bbdfee968cedf8a3.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a0/a096693d4b8b3c891ec3c78df82b63a8.png\" /></p><p></p><p>图 34 资产中心应用效果图</p><p></p><p>交易中心，在机构交易方向，兼容 OST、集中交易柜台、新一代交易系统及其他第三方交易系统接口协议，为机构终端提供统一的场内交易接口协议及接入能力，大幅降低机构客户交易柜台切换成本。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/17/1790d539473f56bfbef3eecb15c1a3b2.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e0/e0fa5ef452f5ac244ef0f39f70d8f0be.png\" /></p><p></p><p>图 35 交易中心应用效果图</p><p></p><p>资讯中心，统筹管理公司内外各类资讯数据源，对资讯数据进行提取、清洗、加工、存储等操作，形成资讯数据标准，对资讯数据进行全生命周期数据管理，并对外整体提供资讯类服务；</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/38/38c7154ee13d16353038d6fa94eb2011.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d6/d6b555b454be4cc7d771cc5f14f03f1c.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/46/460c1dd4a7bc13c13e6095aa3f998ffa.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/85/85222cfd010114303604ff98ad1632cb.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/bb/bb41367a06e9859ad680f45dbe4e0730.png\" /></p><p></p><p>图 36 资讯中心应用效果图</p><p></p><p>行情中心，为公司内各业务部门及子公司、机构及零售财富客户提供实时行情及历史行情服务，接入、整合和管理从全球交易所及其他三方行情源发送的各类市场行情，提供统一的数据接口标准、超低延时以及高质量的市场行情数据推送、查询服务，并提供多种衍生行情服务如全息处理、指标计算、智能盯盘等，以支持各类用户的量化投资研究、算法交易、高频交易、程序化交易、统计套利、组合管理、风险控制等各种业务应用。21 年实时行情 40 个有效用户共登录 4.1 万次，累计使用时长 32 万小时，历史行情查询服务全年共 35 个用户接入，服务请求量峰值为 128 万 / 天</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/06/068eef254335598779dad9f7d26a38fd.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d1/d12da0cccf4f170b748effeb730b241d.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/4e/4e29284345277ab2df4f835ae4e651fd.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/2a/2abb40bccba6d6e8431c477d3ac3b4c1.png\" /></p><p></p><p>图 37 行情中心应用效果图</p><p></p><p>权益中心，形成了东方证券虚拟资产管理能力，并对 APP 端提供了相应服务。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/9f/9fce2510155371591d1e3ecb57870ee1.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/36/364df76a53a524a5595bcd3a481d8fab.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/44/446cffa95135863d82e436775c057f76.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7f/7f0a246135ecc86bf3c0020425dde298.png\" /></p><p></p><p>图 38 权益中心应用效果图</p><p></p><p>投研中心，初步形成了东方证券投资研究的服务体系，并在基金投顾等业务中取得了良好的应用效果。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/65/65d4c7c33584d6d1cdca7737c114f836.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/08/085009f06568e4e5f85b071160fdd4ee.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ca/ca05cb52c7aef0421a022ed87f059f78.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/6e/6e225c172e8a3635eb6a0d2696a2cf74.png\" /></p><p></p><p>图 39 投研中心应用效果图</p><p></p><p>认证中心，将公司内部各个组织、子公司等人员结构集中整合至认证中心统一管理，并将各类安全规则统一配置，实现了公司内部账户和应用的集中管控，使安全性得到提升，并大幅减少新建系统适配认证源的成本。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/70/70204a70427cb86bf64a595791f4cb41.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/83/83a9789401fe1d85a9b79d7460fa109b.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/10/10911078f640abf85fd04fdb10b3f836.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/01/01d1927fd77b576e9b6f509b556df995.png\" /></p><p></p><p>图 40 认证中心应用效果图</p><p></p><h2>十、总结与展望</h2><p></p><p></p><p>东方证券经过三年多的建设，并基于 API 化的开放式模块化架构核心思想，形成了“薄应用 厚中台 稳后台”的企业架构全景，并将核心业务知识进行沉淀，以模块化、服务化、共享化的形式建设企业级业务能力，从而快速响应市场变化和客户需求，大幅提升业务交付效率，金融科技核心竞争力取得重要突破。</p><p></p><p>未来，东方证券将继续以开放共享、合作共赢为原则，以金融科技规划为牵引，持续推进中台战略转型，并以新一代交易核心平台建设为契机，与交易系统配合形成更为全面的领域服务划分，合理清晰的原子及业务流程服务，精细化各系统内部及之间细粒度的服务、接口及数据库设计，持续推动金融科技研究应用，以金融科技赋能业务，引领创新，不断助力公司数字化转型与行业创新发展。</p><p></p><p>【参考文献】</p><p></p><p>[1] 钟华. 企业 IT 架构转型之道 阿里巴巴中台战略思想与架构实战. 机械工业出版社，2017.5.</p><p></p><p>[2] Mary Mesaglio , Matthew Hotle. Pace-Layered Application Strategy and IT Organizational Design: How to Structure the Application Team for Success.Garnter，2016.4. <a href=\"https://www.gartner.com/en/documents/3297020\">https://www.gartner.com/en/documents/3297020</a>\"</p><p></p><p>[3] 王健. 白话中台战略 3：中台的定义. Thoughtworks，2019.4. <a href=\"https://insights.thoughtworks.cn/what-is-zhongtai-definition/\">https://insights.thoughtworks.cn/what-is-zhongtai-definition/</a>\"</p><p></p><p>[4]Fowler M, Lewis J. Microservices. Viittattu, 2014, 28: 2015. <a href=\"https://martinfowler.com/articles/microservices.html\">https://martinfowler.com/articles/microservices.html</a>\"</p><p></p><p>[5] Scott Millett , Nick Tune. 领域驱动设计模式、原理与实践. 清华大学出版社，2016.2.</p><p></p><p>[6]<a href=\"https://grpc.io/\">https://grpc.io/</a>\"</p><p></p><p>[7]<a href=\"https://dubbo.io/\">https://dubbo.io/</a>\"</p><p></p><p>[8]<a href=\"https://spring.io/projects/spring-cloud/\">https://spring.io/projects/spring-cloud/</a>\"</p><p></p><p>[9]<a href=\"https://github.com/grpc-nebula\">https://github.com/grpc-nebula</a>\"</p><p></p><p>[10] 胡长春, 杨子江, 樊建. 微服务框架 gRPC 交易接入网关实践. 交易技术前沿,Vol.47,2021.10.</p><p></p><p>[11] 杨子江, 胡长春, 章儒楠. 基于 NodeJS 的动态 gRPC 业务网关服务设计与实现. 交易技术前沿,Vol.47,2021.10.</p><p></p><p>[12] 樊建, 杨子江, 胡长春, 舒逸. 东方证券服务治理建设实践. 交易技术前沿,29-37,Vol.39,2020.8.</p><p></p><p>[13] 樊建. 东方证券企业架构建设实践. 金融电子化，2020.11. <a href=\"https://mp.weixin.qq.com/s/37eXHR6bgNkxFWnwrvH9tA\">https://mp.weixin.qq.com/s/37eXHR6bgNkxFWnwrvH9tA</a>\"</p><p></p><p>[14] 樊建, 舒逸. 东方证券企业架构之技术架构转型实践. InfoQ,2020.9. <a href=\"https://mp.weixin.qq.com/s/ObAniOFLtSP4UMkxh5oFvQ\">https://mp.weixin.qq.com/s/ObAniOFLtSP4UMkxh5oFvQ</a>\"</p><p></p><p>[15] 樊建, 舒逸, 胡长春. 跨语言服务治理框架在证券行业的探索与实践. 证券市场导报, 60-73, 深圳证券交易所金融科技中心 2020 年度课题专刊, 2021.12.</p><p></p><p>[16] 基金代销机构公募基金保有规模前 100 家 (2021 年四季度). 中国基金业协会,2022.1.</p>",
    "publish_time": "2022-08-17 14:18:16",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Node之父着急宣布：Deno将迎来重大变革，更好地兼容Node和npm包",
    "url": "https://www.infoq.cn/article/juXB8EaoJrlLx4vB7ttD",
    "summary": "<p>或许是因为受到来自近日<a href=\"https://www.infoq.cn/article/m48tvaz8w2BbblIQKZZF\">大火的「Bun」</a>\"的压力，Deno 官方在8月15日发布了一篇名为《Deno 即将发生重大变化》的<a href=\"https://deno.com/blog/changes\">博文</a>\"。</p><p></p><h2>Deno的焦虑</h2><p></p><p></p><p>2018 年，Node.js 的创始人 Ryan Dahl 在 JSConf EU 上做了主题为 “10 Things I Regret About Node.js” 的分享，Ryan 回顾了在他看来当初开发 Node.js 时留下的<a href=\"https://www.infoq.cn/article/SiVQVIwANd_1SXkBwlFL\">十大遗憾</a>\"。由于 Node.js 现在已经广泛应用于各个领域，为了保证兼容性，对 Node.js 底层进行大规模改造已经不现实。于是 Ryan 宣布他决定开发一个全新的 JavaScript运行时以解决当初的种种缺陷，<a href=\"https://mp.weixin.qq.com/s?__biz=MzUxMzcxMzE5Ng==&amp;mid=2247488986&amp;idx=1&amp;sn=7f03d4a056096fffa826e2b619e39836&amp;chksm=f951a099ce26298f8372277785c472cd25558e516cc38175f0c141e70c6604a29ec9b33fef96#rd\">这便是 Deno 的由来。</a>\"</p><p></p><p>Deno 由以下技术构建：</p><p></p><p>Rust（Deno 的核心是用 Rust 编写的，Node 用 C ++编写）Tokio（用 Rust 编写的事件循环）TypeScript（Deno 支持 JavaScript 和开箱即用的 TypeScript）V8（google 在 Chrome 和 Node 等中使用的 JavaScript 运行时）</p><p></p><p>不过，尽管Deno宣称解决了一些长期困扰开发者的老大难问题（把 es-modules 设定成默认值，引入了第一方 TypeScript 支持（无需在发布前转译npm模块等等），但在一些用户看来，Deno 在解决老问题的同时，也引入了不少新问题。</p><p></p><p>其中，生态是Deno主要被诟病的问题。首先，Deno 对包解析和语法做的变更过于大刀阔斧，导致没法跟原有npm生态系统兼容。换言之，Deno 需要培养起自己的全新库生态。虽然 Deno 慢慢开始支持一些早期库，但一个项目的影响力会直接决定它的发展上限。当然也有一些变通方法，比如把npm包转换成Deno包的 CDN，但也有人觉得这不是什么好招。</p><p></p><p>此外，Deno还有着不少暴露其半成品身份的问题，比如缺少 package.json。无论是从模块解析的角度来看，还是从缺少 manifest 文件出发，Deno 都不允许开发者为自己的包编写可扩展元数据。GoLang 甚至专门为此引入了 go.mod。</p><p></p><h2>即将有重大变革</h2><p></p><p></p><p>8月15日，Deno官方发布了一篇名为《Deno 即将发生重大变化》的博文。这个时机点难免让人将其与前阵子大火的「Bun」联想起来。</p><p></p><p>Bun是今年才发布的前端工具链项目，作者是前 Stripe 开发人员 Jared Sumner 。不同于 Node.js 和 Deno 使用的 V8 引擎，Bun 使用 JavaScriptCore 引擎，并用 Zig 编程语言编写。</p><p></p><p>据悉，Bun 最初只是一种 JavaScript webserver，但在后续发展中逐渐酝酿出了<a href=\"https://www.infoq.cn/article/Tqy53cjOVUY8GAk4V9We\">全面颠覆 JS 生态系统的野心</a>\"，它的性能表现优异，其 React 的服务器端渲染速度据称是 Node 或 Deno 的三倍以上。</p><p></p><p>面对这样的强劲新对手，Deno也迫不及待要预告自己的新动态和进展。</p><p></p><p>根据官方博文，Deno这次想要对外强调的进展包括：</p><p></p><p>团队一直在通过更新降低Deno对npm包的导入门槛，预计未来三个月内，绝大多数npm包都能在Deno中顺畅运行。Deno目标是成为最快的JavaScript运行时。这里向新用户稍做解释，Deno的下个版本将包含新的HTTP服务器，这也是有史以来速度最快的JavaScript Web服务器。考虑到不少大型企业和公司初创团队都在使用Deno，其将面向这些商业用户提供办公时段专用套餐。</p><p></p><p>下面我们一同看看Deno具体的变化是什么样的：</p><p></p><h4>Node与npm兼容性</h4><p></p><p></p><p>在未来三个月内，有80%到90%的npm包都能够顺畅运行在Deno当中。具体实现方式是使用特殊的npm URL，具体示例：</p><p></p><p><code lang=\"typescript\">import express from \"npm:express@5\";</code></p><p></p><p>未来三个月内，大多数npm模块都能通过上述方式作为依赖项引入。用户将告别node_modules文件夹、告别npm install；这些包将被自动下载至Deno缓存内。从类型检查到LSP、再到deno vendor，所有Deno工具都可以使用这些npm包。</p><p></p><h4>最快的JavaScript运行时</h4><p></p><p></p><p>官方称Deno将成为速度最快的JavaScript运行时，没有之一。他们100%相信，Deno自身的技术堆栈、V8再加上Rust完全可以把这个目标变成现实。</p><p></p><p>Deno的HTTP服务器也在经历大改，“现在我们向大家正式宣布，它就是有史以来速度最快的JavaScript Web服务器。我们整个运营系统的优化度越来越高，能够直连V8 Fast API以通过JS快速调用本机代码。同样地，我们的外部函数接口（FFI）也迎来了振奋人心的更新。请注意，我们可不是在针对少数极端情况进行优化，而是真正实现了整体实践层面的性能提升。”</p><p></p><p>Deno表示，预计在今年夏天结束之前，相关成果就将正式发布、供大家上手体验。</p><p></p><h4>支持企业用户</h4><p></p><p></p><p>Deno指出，在最近进行的调查中，发现近半数Deno活跃用户会在工作当中使用Deno，其中包括不少大企业的开发者和初创公司创始人。未来，团队希望将为在商业环境中使用Deno的朋友们提供免费办公时段套餐。</p><p></p><p>因为Deno团队的规模还相当有限，所以呼吁相关用户先填写表单，需求将根据大家的项目规模和紧迫性进行优先级排序。表格填写地址：<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSewMCz1wB8SMZI8n7xUVeH00tBo5xLBGmj26-QVjjhQ4FfZlQ/viewform\">https://docs.google.com/forms/d/e/1FAIpQLSewMCz1wB8SMZI8n7xUVeH00tBo5xLBGmj26-QVjjhQ4FfZlQ/viewform</a>\"</p><p></p><h4>流畅的开发者体验</h4><p></p><p></p><p>在接下来几个月中，Deno将陆续发布后续更新，包括全部第三方Deno代码实现全文符号搜索，以及自动为JavaScript和TypeScript项目生成文档等。下图为功能预览界面：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0f/0f36117021aa7c7f10d0dc72f672f771.png\" /></p><p></p><p>最后，Ryan Dahl表示对Deno过去几年中建立的庞大生态系统和良好的支持成效感到自豪。目前，Deno在GitHub上的下载量已突破410万次，月活跃用户高达25万，项目采用率还在持续提升。</p><p></p><p></p><blockquote>“哇，对兼容 npm 的 Deno 非常感兴趣！我认为这将消除进入 Deno 的巨大障碍。”</blockquote><p></p><p></p><p></p><blockquote>“一旦 Deno 发布了这些功能，我将再次尝试 Deno。”</blockquote><p></p><p></p><p>从<a href=\"https://news.ycombinator.com/item?id=32468613\">网友的反应</a>\"来看，Deno的这番“紧急预告”已经开始产生效果。不过，用户也许还得等两三个月才能用上改进后的新版Deno。</p><p></p><p>参考链接：</p><p><a href=\"https://deno.com/blog/changes\">https://deno.com/blog/changes</a>\"</p><p><a href=\"https://www.infoq.cn/article/3ZyWlLFvesQtS8acV7UU\">https://www.infoq.cn/article/3ZyWlLFvesQtS8acV7UU</a>\"</p>",
    "publish_time": "2022-08-17 14:44:24",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "转转 K8s 实践：如何解决容器化带来的四大问题",
    "url": "https://www.infoq.cn/article/Goqb1iutA3RMMY9PxAi4",
    "summary": "<p></p><blockquote>为进一步加强技术交流，推进云原生生态共建，6月28日下午，首届云原生实践者大会在线上线下同步举办。来自<a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651116086&amp;idx=4&amp;sn=b3d27e3302e8c7a0ecafa73bbafbafa1&amp;chksm=bdb92a658acea37365a1511c67cfda9132e03586f5fa549f23992a05a217a5ac73f1362c18a2&amp;scene=27#wechat_redirect\">作业帮</a>\"、<a href=\"https://www.infoq.cn/article/SslDEik5WJa6U5GweKfp\">知乎</a>\"、转转、58、同程等多家科技企业的数十名研发人员，以及中国信通院云大所的专家共同参与了此次技术研讨沙龙。&nbsp;研讨会上，转转基础服务负责人梁会彬分享了转转在k8s方面的实践。梁会彬表示，相较于传统物理机，容器化带来了资源隔离、轻量快捷、隆本提质增效、高可用等诸多优点，从而被各大互联网公司采用。但同时，这也引入了新的问题，如IP动态、日志收集、服务治理融合、监控等。面对这些问题，各大公司根据业务场景采用了不同的解决方案。梁会彬同与会者分享了转转的解决方案，包括镜像管理、发布升级、容器监控、日志收集等方面。&nbsp;以下，是梁会彬的分享。</blockquote><p></p><p>&nbsp;</p><p></p><p>我主要从实现层面来介绍K8s在转转的实践。本着让rd无感容器相关概念的原则，转转云平台主要包括镜像管理、发布升级、容器监控、日志收集四个部分。</p><p></p><h2>总体架构</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a0/a072551a90c9a7a3bfbd0d6b7247a8e6.png\" /></p><p>&nbsp;</p><p>这是转转云平台架构图，其中包括组件镜像存储、日志收集、K8s、服务治理、NG治理、监控等，云平台统一管控这些组件。如图所示，云平台屏蔽以上组件，让rd无感，减少复杂性，学习曲线平缓。</p><p></p><h2>功能流转</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5d/5d808f1061cf8cfc6b486df7c128888c.png\" /></p><p>&nbsp;</p><p>这幅图是云平台的结构关系，该图包含了用户行为和数据流转关系，属于系统的反馈回路图。</p><p>&nbsp;</p><p>从左边来看，rd通过CI/CD平台编译部署，通过日志平台查询日志，通过大数据收集平台配置日志收集信息，最后这些平台统一和云平台交互，由云平台统一管理和K8s的交互，而其他系统与K8s无耦合。如图所示，云平台负责镜像编译、发布升级、日志收集等功能。</p><p>&nbsp;</p><p></p><h2>镜像管理</h2><p></p><p>&nbsp;</p><p>镜像管理的目标是让rd对Dockerfile无感，减少学习成本。由于容器之前，编译系统有现成的编译产物，我们选择直接复用，来减少CI/CD开发成本，同时也能提高编译性能。</p><p>&nbsp;</p><p>对应实现方案为应用分类（ZZJAVA、ZZWEB、WF），这样每种技术栈类型对应一种基础镜像，也就是各自对应相应的启动脚本，做到用户无需感知Dockerfile。物理机编译产物+CMD（启动命令）就和物理机应用无异，做到物理机编译产物直接复用到容器中。</p><p>&nbsp;</p><p>对于容器编译的执行过程，我们把编译镜像的程序以pod的形式部署到K8s集群运行，天然继承K8s的优势，做到分布式编译，以此打破性能瓶颈。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/07/0704d6e914d7f82a8ed25de378cccb96.png\" /></p><p>&nbsp;</p><p>下面看一下镜像管理的流程交互图。如上图，rd通过CI/CD编译工程，按原有编译流程执行编译，产物推送到FTP服务，然后利用云平台能力产生编译pod，最终编译镜像程序在编译pod中编译镜像并推送到镜像仓库（Harbor）。下面是云平台的Dockerfile，业务镜像输入参数是编译产物url和服务名称，而编译镜像的Dockerfile的本质就是用Docker client在pod中进行docker build，这样编译镜像程序本身也能享受到隔离且编译后自我清理中间产物的优势。</p><p>&nbsp;</p><p></p><h2>发布升级</h2><p></p><p></p><p>对于发布升级，我主要讲两个点：</p><p>转转发布技术的演进，包括Deployment控制器和转转自定义控制器&nbsp;不同应用类型服务的实现细节，包括rpc服务和Web服务</p><p></p><h4>通用问题</h4><p></p><p></p><p>Deployment控制器使用过程中重点考虑的通用问题包括：cpu如何超分、超分会出现什么问；ready检查如何做；亲和策略怎么选择；以及针对不同服务类型的具体实现是什么等。</p><p></p><h4>CPU 超分</h4><p></p><p></p><p>CPU 超分的目标是让重点集群控制CPU超分比例，以此保证重点集群机器性能。</p><p>&nbsp;</p><p>实现方案：保证重点集群性能就要控制其他非重点集群不调度到对应机器，所以本质来说是对宿主机集群进行分类。具体来说，就是为宿主机打不同的label，部署的时候使用NodeSelector去匹配相应的宿主机，同时控制CPU request=limit*设置比例，做到宿主机超分比率控制。</p><p></p><h4>ready检查</h4><p></p><p></p><p>ready检查的目标是，在pod在滚动升级时保证新启动容器进程可以提供服务，避免新容器出现问题时全部替换老容器，导致服务不可用。</p><p>&nbsp;</p><p>实现方案：对于Web服务来说，访问 health 接口返回200认为ready；rpc服务判断端口启动成功即可，我们的rpc服务保证端口暴露时注册到服务治理服务。</p><p></p><h4>亲和策略</h4><p></p><p></p><p>亲和策略的目标是将同一个集群pod调度到不同宿主机，防止宿主机crash导致整个集群不可用。</p><p></p><p>实现方案：podAntiAffinity技术。</p><p></p><h4>rpc服务</h4><p></p><p></p><p>rpc服务遇到的挑战：</p><p></p><p>转转rpc支持节点分组；服务治理联动。</p><p>&nbsp;</p><p>实现方案：针对分组配置节点数，rpc框架改造支持分组发现，云平台支持针对分组部署，具体分组发现依靠env中的分组id。</p><p></p><h4>Web服务</h4><p></p><p></p><p>Web服务遇到的挑战：</p><p>Web服务没有注册中心&nbsp;；Nginx如何自动上下线。</p><p>&nbsp;</p><p>实现方案：利用容器的生命周期控制Nginx上下线，实现Nginx服务化，即在Nginx上提供服务上下线接口。这样在容器 prestop 时下线Nginx，readyness时上线Nginx，做到容器自我管理上下线Nginx功能。</p><p></p><h4>自定义控制器</h4><p></p><p></p><p>使用Deployment控制器会遇到 IP 漂移、日志丢失、kubelet不支持subPath等问题。我们自定义控制器是为了方便开发，直接重写RC控制器，复用pod，解决ip漂移和日志丢失问题。我们还重写了emptyDir实现subPath，解决相同集群调度到同一机器日志冲突问题。</p><p></p><h4>自定义控制器的实现</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fd/fd2542cd6ca7129d3c336007fdf737dc.png\" /></p><p>&nbsp;</p><p>这幅图是K8s控制器流程图，经典的list/watch模型。</p><p>&nbsp;</p><p>我们重写RC的逻辑也比较简单：监听Replication、发现image版本变化，直接替换pod的镜像版本，做到本地升级。但也有例外情况，如果cpu、内存、env等发生变化，我们就更换pod。</p><p></p><h2>容器监控</h2><p></p><p></p><p>关于云平台的监控，我们也经历了几个版本：从Heapster到Metrics-server，最后直接使用Prometheus抓取cAdvisor数据。这里有个小细节，Prometheus抓取cAdvisor数据没有IP和pod关联关系的数据，是需要处理的。</p><p></p><h4>容器监控示例</h4><p></p><p><img src=\"https://static001.geekbang.org/infoq/14/1404c48bed12b6e7c839e08de92d82b4.png\" /></p><p></p><p>这幅图是转转的容器监控，可以看到相应pod的宿主机以及自身性能数据。</p><p></p><h2>日志收集</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/99/99ceb12a782b506ed02327129a175536.png\" /></p><p>&nbsp;</p><p>&nbsp;</p><p>日志收集遇到的问题：</p><p></p><p>Java技术栈日志一般不往stdout打印，有自己的日志框架，而且是多文件的，比如info、warn、error，这点和Docker设计有些出入&nbsp;；日志量很大&nbsp;；日志丢失&nbsp;。</p><p>&nbsp;</p><p>我们的应对方案：日志使用hostpath直接打到宿主机，解决丢失问题，然后使用异步收集解决量大问题。所谓异步收集是指宿主机上有专门的agent读取Docker启动/销毁事件，进而生成flume配置文件，做到收集日志和云平台解耦。</p><p>&nbsp;</p>",
    "publish_time": "2022-08-17 16:41:47",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "谷歌云又一个服务被扼杀，这次是IoT Core",
    "url": "https://www.infoq.cn/article/1UwW0fMPkfIeGmvGv59s",
    "summary": "<p>目前，谷歌云的 IoT Core 英文<a href=\"https://cloud.google.com/iot-core\">网页</a>\"上挂着一则明显的公告：谷歌 Cloud IoT Core将于2023年8月16日退役。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/28/289bd1c2f5693125d3ec8a1f12a401f3.png\" /></p><p></p><p>消息一出，引起不少争议。谷歌发言人对此回应道：“自从推出 IoT Core 以来，我们的客户需求显然通过我们专门从事物联网应用和服务的合作伙伴网络中得到更好的服务。我们已经开展了广泛的工作，为客户提供迁移选项和替代解决方案，并在 IoT Core 停止服务之前提供长达一年的缓冲时间。”</p><p></p><p>谷歌云在2017年以<a href=\"https://www.infoq.cn/article/2017/10/google-cloud-iot\">公开测试版</a>\"的形式推出了 IoT Core 服务，并在<a href=\"https://www.infoq.cn/article/2018/03/google-cloud-iot-core-ga\">2018年</a>\"将其商业化，在此期间，谷歌也一度兜售其之前的物联网产品<a href=\"https://www.infoq.cn/article/lvhk7ovjznnwn1vgalo5\">Android Things</a>\"（2021 年 1 月 5 日停止支持），Android Things是一个基于Android的嵌入式操作系统（最初名为Brillo），前后有6年多历史。</p><p></p><p>回到IoT Core，根据官方介绍，这是一项全代管式服务，可帮助用户安全地连接和管理分布在全球各地的数百万台设备，并从中提取数据。IoT Core 与 Google Cloud 上的其他服务搭配在一起，便可构成一套完整的解决方案，可以实时地收集、处理、分析和直观展示IoT数据，从而帮助提高运营效率。</p><p></p><p>谷歌云 IoT Core 支持两种设备连接和通信协议：MQTT 和 HTTP。设备通过“网桥”（MQTT 网桥或 HTTP 网桥）与 Cloud IoT Core 通信。</p><p></p><p>有网友公开了谷歌云发给 IoT Core 用户的电子邮件内容，里面提到，IoT Core 服务将在2023 年 8 月 16 日停用，到时用户将无法再访问 IoT Core 设备管理器 API，设备也将无法连接到 IoT Core 的MQTT和HTTP“网桥”，现有连接将被关闭。谷歌建议用户尽早采取行动，从 IoT Core迁移到“替代服务”。该网友还提到，AWS已经伸出援手。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c6/c613ce1722227f3c9438f80b469da0f1.png\" /></p><p></p><p>目前暂不清楚谷歌云此举将带来多大的影响，2018年ZDNet的一篇报道将 IoT Core <a href=\"https://www.zdnet.com/article/google-cloud-iot-core-generally-available/\">描述</a>\"为“已经在运输、石油和天然气、公用事业和医疗保健等行业中使用”。</p><p></p><p>今年第二季度，谷歌云的营业收入同比增长至63亿美元，但该板块的营业亏损也从5.91亿美元增至8.58亿美元，谷歌称主要是因为增加了在数据中心的支出。</p>",
    "publish_time": "2022-08-17 17:10:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "过去的十五年，我们怎样做 IM？",
    "url": "https://www.infoq.cn/article/7UN5uPMYQWOxws5BRIKd",
    "summary": "<p></p><blockquote>世界变了，即使同样的场景和需求，在每个时代使用的技术做的事情都可能完全不一样。虽然用户需求越来越高，人力成本越来越高，研发一个行业水准的系统也越来越难。但要不要从头自建，依然受到很多因素的影响。阅读本文，了解过去十五年里，IM软件研发走过的三个阶段，了解系统选型背后的思考，了解新一代云原生IM。</blockquote><p></p><p></p><p>就在前几天，飞信要关停了，消息传出，很多人感慨说「又一滴时代的眼泪」，言语唏嘘。</p><p></p><p>飞信诞生于2007年，迄今已经运营了15年。由于出现时恰逢国内互联网建设初期，网络速率较低且资费昂贵，大部分即时通讯软件事实上还只能作为半留言式工具，这让与短信结合的飞信在消息投递方面的即时性无人能及，顺理成章地迎来了爆发式的增长。</p><p></p><p>只不过这种优势并没有保持多久，随着网络建设和资费下调，红利很快就开始消退，并最终在移动互联网崛起后彻底失去了机会。</p><p></p><p>巧的是，笔者也是从 2007 年开始做IM，算来也有十五年。因此除了跟其他用户一样感慨外，也会有行业从业者的不同角度和观点。特别是最近几年一直做 <a href=\"https://mp.weixin.qq.com/s?__biz=MzA4NTU2MTg3MQ==&amp;mid=2655213246&amp;idx=3&amp;sn=b3ae1199230ccbb308ab2c8a8f885463&amp;chksm=8461f1deb31678c82136f493fcbbacf150063a8302de4e387cc93d624876bc6535aee2e2e5f5&amp;scene=27#wechat_redirect\">IM 云服务</a>\"，看过数以万计的 APP，这种情况也是见怪不怪。</p><p></p><p>除此之外，其实我还会经常遇到的一个问题是：</p><p></p><p>IM不就是聊天吗，技术发展这么多年应该成熟了吧，还有什么可做的呢？</p><p></p><p>所以今天我们不谈产品，来谈一个技术问题，我们怎样实现一个即时通讯系统（IM）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/33/338dae3e732a6a2092775c87fb4ae919.jpeg\" /></p><p></p><p>过去的十五年里，即时通讯（IM）技术大致经历了三个阶段。</p><p></p><h2>第一阶段：软件和高并发服务</h2><p></p><p></p><p>网络刚刚兴起的时代，开发一个软件系统要从买电脑租服务器机架开始。由于没有云服务和现成的 <a href=\"https://xie.infoq.cn/article/99f415a36760ae350ccdb16a8\">SDK 技术</a>\"，工作会往往从开源的协议和软件开始。</p><p></p><p>这也是属于 PC 互联网的时代，网络虽然不快但相对稳定，扩展性和互操作性相对重要，也因此发布于 2000 年的 XMPP 协议逐渐成为标准。</p><p></p><p>在这个以研发软件为主的时期，互联网用户开始增长，越来越多的服务开始遇到大量用户带来的并发挑战。后端技术也随之不断发展，从解决 C10K 问题（承载一万并发）到 C100K、C1000K，与之相关的线程池、IO模型优化等技术成为重点。</p><p></p><p>为了解决并发连接，大多数服务器都要确保切换 epoll，因为在 IO 多路复用的问题上，epoll 要比 select 要高效。而当用户数超过了单机容量，就要进行会话的分片管理，你要用一致性哈希这样的技术，确保在部分节点宕机情况下整体服务的可用性。</p><p></p><p>显而易见，这个阶段软件复用率很低，每一个需要 IM 的业务基本都要从头构建自己的系统，都要自行解决这些技术难题，导致开发周期漫长且低效。现在看来简直如刀耕火种般原始，但当时确实是常态，能够从开源软件开始构建已经是高阶开发做的事情了。</p><p></p><p>这种情况一直持续到后来的移动互联网时期，直到云的出现。</p><p></p><h2>第二阶段：移动互联网和云</h2><p></p><p></p><p>2009 年中国正式发布 3G 牌照，标志着中国进入 3G 时代，而同年苹果发布了 iPhone 3GS 手机，开发生态也逐步完善，为随后到来的移动移动互联网爆发做好了铺垫。</p><p></p><p>3G 网络的成熟，为手机上网提供了便利，也为业务带来了新的挑战。因为手机终端的移动特性，导致用户在网络切换过程中会频繁断网重登录，以 XMPP 协议为代表的 IM 系统会因此耗费相当大的网络流量以及电量，而且还会丢失消息。</p><p></p><p>这个时期的 IM 系统，重点开始解决在移动网络下消息可靠投递的问题，以及省电省流量设计，很多公司开始使用二进制数据结构来实现自己的协议。</p><p></p><p>这个问题首先被微信解决了，这就是后来大家经常提的增量同步 XSync 协议。这种设计思想一般说是从邮箱协议启发而来，比如微软的 ActiveSYNC，但用在 IM 场景算是一个创新。</p><p></p><p>除了二进制包更小有效负荷更高外，比起传统的 XMPP 协议，开发者还会重点解决两个问题。</p><p></p><p>一个是消息投递确认机制改为显式 ACK。即把原来 XMPP 以消息离开服务端为投递成功，改为客户端收到消息后回复 ACK，服务端收到 ACK 才认为投递成功，失败的投递会触发重试，这样保证了消息投递的可靠性。</p><p></p><p>另一个是离线消息的存储与获取。原来 XMPP 协议有单独的离线存储设计，用户登录后会自动下发，而在线消息则是直接投递。前面提到，这两种情况下都会遇到的是，消息投递后如果网络切换或者不稳定，消息就会丢失。在新的显式 ACK 设计下，在线投递和离线投递合二为一，统一简化了处理。</p><p></p><p>也是部分因为这样的设计，部分因为用户体验，移动互联网后，大家不再强调在线和离线的状态，而是宣称永远在线。毕竟一个进了电梯断网的用户，下一秒就会上线，而手机一直带在身边，只要联网消息就会被取走。在线状态这个原来 IM 系统里最大的负担特性被舍弃了。</p><p></p><p>说到这里，你可能会觉得，移动互联网就是技术栈变了，好像要做的事情比之前还要多，因为协议甚至都没有现成的开源的方案可以用了。</p><p></p><p>事实并非如此，因为云的时代也到了。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a8cb7502aa84e35455f23e646987ecaf.jpeg\" /></p><p></p><p>大量移动 App 的爆发，带来了标准化模块化 SDK 的需求，因此为开发者服务的云服务应运而生。2014 年开始，市场上开始出现即时通讯云服务，为企业和开发者提供 IM SDK 和 <a href=\"https://xie.infoq.cn/article/6fb7d7e5606ec5b05634f4492\">API 服务</a>\"，我们是其中之一。</p><p></p><p>由于存在大量的机会和竞争，对于每一个移动互联网企业来讲，时间和人才变得更加宝贵。机会稍纵即逝，你要在最短的时间里跑通业务，便不可能在每个系统中都投入人力，集成 SDK 是最经济也是最明智的决策。</p><p></p><p>研发的专业化比如带来分工分化。因此，也就是从这个时期开始，研发 IM 功能的开发人员产生了分化。</p><p>一个群体是普通 App 开发者。他们的工作不再是解决 IM 系统的实现问题，而是开始集成现成的服务，使用标准的 API，将重心放在自己的业务上。</p><p></p><p>另一个群体是云服务提供方。他们开始研究客户端跨平台（iOS、安卓、Web等）技术，解决更大规模的分布式系统问题，提供更高可用性的服务。当然在这之前，他们也要首先解决多租户问题，即大量应用使用同一个云服务，又有足够的隔离保证数据不会通不会乱。</p><p></p><p>随后对 IM 系统的更大挑战到来。2015 年，互联网直播开始流行，万人群甚至无上限聊天室等极端场景被提了出来，要知道在此之前，一般的群都是千人规模，微信群规模限制更是长期在 500 人左右。</p><p></p><p>如果要做万人群，甚至是无上限聊天室，消息的分发模型必须进行改造。因为每个用户发送消息默认都会被扩散到所有人，因此即使是万人群，每人发一条消息，系统就要承载一亿条的峰值压力，更别提百万人聊天室了。之前有个知乎提问说「把 14 亿中国人都拉到一个群里，技术上能实现吗」，算是一个很有意思的例子。</p><p></p><p>因此，服务实现时首先要将分发分批打散，分散到多台队列以及处理机上。这其中的每一步，都涉及一个更为基本的操作，即获取群成员列表，这样的压力下使得存储必须进入内存而且要分片才能解决。</p><p></p><p>客户端自然也存在群成员展示问题，毫无疑问这个列表也需要分片获取。然后你会发现，即使服务器能够下发成功，一个手机也无法同时处理一万条消息。因此，在无上限聊天室场景下，服务端在消息分发开始就需要区分消息优先级并实现消息丢弃策略。</p><p></p><p>这个阶段是云服务逐渐渗透的过程，因此我们还是会看到一些企业没有上云，这便是第三类开发者。</p><p></p><p>他们思考了自己的业务，发现业务有相对稳定的用户数，不会有用户突然爆发的情况，也没有极端的群聊需求，但同时，他们出于政策要求或者安全考虑，不放心聊天数据上云，因此他们还是会从头构建自己的 IM 系统。如前面所提，这种情况下，一般他们的 TCO 成本会远高于公有云，因为需要投入额外人力和独立的服务器，同时，他们在 IM 系统研发上投入以及服务质量也会跟专业的 IM 云服务有不少差距。</p><p></p><h2>第三阶段：云原生</h2><p></p><p></p><p>在云服务阶段，我们提到了三类开发者。其实在很长时间内，我们作为第二类云服务开发者，是相信未来大部分服务都是要上云的，即使不是全部的话。</p><p></p><p>然而随着越来越多场景的出现，这个观点也在逐渐改变。前面说的数据安全要求是一个原因，跟它类似的是网络安全要求。在某些业务里，IM 聊天要求内网通讯，或在特定专网内，这就使得租用一个公共的云服务变得不可行。</p><p></p><p>同时从云服务的角度看，云服务模式成立的基础在于规模效应，即通过统一服务提高资源使用效率，以低于客户自建服务成本的价格收取租用费，然后通过大量客户来获得利润。也就是说，每一个公有云服务的运行，需要有足够量的客户支撑。反之则不然。</p><p></p><p>也因此我们发现，在某些发展中国家或地区，当移动开发者和企业数量不足的时候，公有云服务实际上无法做到有效覆盖，使得在这些地区的开发者只能选择非云的当地 IDC 和技术服务。</p><p></p><p>在无法使用公有云服务的场景下，某些有足够预算的企业可以通过购买云厂商的私有部署来继续将自己的开发人员锁定在一类开发者中。这便是 IM 私有云的场景。</p><p></p><p>在过去，私有云的交付一直处在两个极端。系统集成商一般有自己的过时的相对陈旧的 IM 软件（由于客户群相同，我们暂且也称其为私有云）。它们分层抽象不足，性能差，业务灵活性不足，然而他们设计简单，交付工作量反而可控；与此同时，云厂商虽然有设计优秀的 SDK 和 API 服务，然而服务却也因承载大规模高并发而进行了各种拆分，导致私有部署复杂，交付困难，也因此定价昂贵。</p><p></p><p>这种情况一直持续到云原生技术的成熟。2015年，随着 Kubernetes v1.0 发布，<a href=\"https://www.cncf.io/\">Cloud Native Computing Foundation（CNCF）</a>\"成立，并在随后几年逐渐成为容器编排的主流工具。各大云服务厂商也逐渐开始使用云原生技术来重构自己的服务，IM 服务也不例外。</p><p></p><p>借助于云原生技术，云服务厂商可以统一私有云和公有云的技术栈，在私有云或者自建服务器上进行服务部署不再是一件复杂的事情，交付实施成本得以大幅降低。</p><p></p><p>当然，要实现云原生，要解决两个重要的技术问题，也是技术难题。</p><p></p><p>首先是多云架构，也是前面提到的，必须统一公有云私有云接口、技术栈和管理控制台。做到这一点，不仅需要统一每一层的接口定义，更难的是，IM 系统多集群技术。在过去的互联网后端技术里，多集群技术，有时候会在异地多活或者单元化设计提到，是多数业务都不会涉及的工程难题。雪上加霜的是，多云架构下，多集群进一步被放大成了大量集群，且集群之间的网络环境是不稳定的公网链路。</p><p></p><p>但我们也都知道，最优的设计必然来源于对业务的深层理解。我们要实现的是 IM 系统的多集群，而不是某个通用服务的多集群。因此这里首先可以利用的业务特点是消息投递的一致性要求。并不是一般互联网服务的的最终一致性，而是消息发送的因果一致性。也就是说，IM 消息的有序，可以主要限定在某一对通话的人，发送者的消息要保证在回复者的消息前面显示即可。</p><p></p><p>因此要实现作为多集群数据核心服务的 ID 生成器，我们可以通过预先划分而不是中心服务的方式进行设计，典型的设计可参照 Snowflake 或 Ticktock，核心思想是将八个字节的 Long 型整数看成 64 位比特，约定特定位数的意义。这样就可以保证全系统跨地域生成的时候，ID 唯一且在时间上粗略有序。</p><p></p><p>第二个问题是自动化安装部署与 License 控制，在这个基础上如果有定制需求，再进一步完善版本管理和制品管理，这里也是用到云原生技术的地方。</p><p></p><p>通过容器技术，实现内置服务的持续集成和交付 CI/CD，实际上是制品的版本管理。其次借助 K8S 等编排工具，将所有服务以及模板整合成一个整体，进而将部署实施的过程变为在目标主机上安装 K8S 并拉取镜像启动服务。这样，就可以做到私有云的部署安装以及配置在极短的时间内完成。</p><p></p><p>顺便提一句，这个时间在我们实际业务中的基准是十分钟。超过了这个数量级的时间一般还是通过挤压运维操作时间来实现的，但要达到这个时间，有人参与的方式是不太可行的。</p><p></p><p>需要注意的是，这里面还有个前置条件是配置的服务化，这是很多系统实现时会忽略的地方。只有将配置服务化，所有的配置项可以从一个服务获取，而不是配置文件里读取，才能更好地支持动态更改与配置，也才能方便的通过编排工具来管理。</p><p></p><p>所以在这个阶段，云服务厂商将可以同时提供专业设计的 SDK 和低成本的私有云，根据现有的市场定价来看，云原生 IM 私有云的价格可以将成本降低两个数量级，即之前价格的百分之一，这样的价格下，客户使用 IM 的成本也会极大降低。</p><p></p><p>也因此根据我们的预测，这个阶段将会是第三类开发者，即不上云而坚持自建 IM 的开发者大量减少的阶段。</p><p></p><h2>后记</h2><p></p><p></p><p>在本质上，我是相信大多数软件技术都经历了类似的发展。只不过由于我个人经验所限，就以即时通讯（IM）技术为例。如果可以抛砖引玉，对各位所从事业务的软件开发或服务能有个启发，也算是一件开心的事。</p><p></p><p>2011年，Marc Andreessen 在华尔街日报上发表文章说，软件正在吞噬世界。过去几年，云服务厂商一直想让客户在云和软件中选择，传统软件厂商则绞尽脑汁劝说客户不要上云，两者你来我往，势均力敌。</p><p></p><p>现在到了云原生时代，云服务终于又变回软件，客户也不再需要在「不上云」和「好产品」之间犹豫徘徊了，系统集成商和云服务厂商之间新的竞争和合作模式也开始逐渐形成。</p><p></p><p>因此，这必将也是一场软件交付的变革，让我们拭目以待吧。</p><p></p><h2>关于「蓝莺IM」</h2><p></p><p></p><p><a href=\"https://www.lanyingim.com/\">蓝莺IM</a>\"是由美信拓扑团队发布的新一代云原生IM，专业 IM SDK，私有云也可按月付费。未来还会逐步开放这套云原生框架，成为所有 IM 相关应用的云原生通讯底座，让应用直接一步变成云原生服务，也可以重新变成快速分发和交付软件。</p><p></p><p>想了解更多关于蓝莺IM或者云原生服务设计的内容，可以继续阅读关于蓝莺IM的那些儿事：《<a href=\"https://github.com/maxim-top/im.gitbook/blob/master/zh-hans/articles/product-and-technologies/one-out-of-two-smartphones-sold-in-africa-has-lanying-im-in-it.md\">未来在非洲，每两台智能手机就有一台使用蓝莺IM技术</a>\"》。</p><p></p><h2>蓝朋友计划的最新情报</h2><p></p><p></p><p>我们正在以蓝莺IM开源项目为基础，打造一个专业的即时通讯技术社区，这便是我们的「蓝朋友计划」。此计划将会邀请社区技术专家一起，共同分享关于即时通讯（IM）技术相关内容，欢迎持续关注，也欢迎自荐或推荐。</p><p></p><p>另外，微博关注 @蓝莺IM，参与文章转发，有机会获得「蓝莺IM礼盒」哦~</p><p></p><h2>作者介绍</h2><p></p><p></p><p><a href=\"https://www.infoq.cn/profile/E67EE14DEE3438/publish\">一乐</a>\"，本名梁宇鹏，蓝莺IM创始人，<a href=\"https://tgo.infoq.cn/\">TGO 鲲鹏会</a>\"（北京）成员。原环信首席架构师、云通讯事业部总经理，也曾任新浪微博通讯技术专家，负责过微博聊天系统设计与研发，也负责当时微博平台研发的架构委员会。从开始使用XMPP协议，在工作中进行相关开源软件的研发，包括C语言的Jabberd2、Erlang的EJabberd、Java的Openfire，到移动互联网后自己设计通讯协议并实现，已经做了10余年IM，其中两款产品服务达到千万级同时在线。</p><p></p><p>原文链接：https://docs.lanyingim.com/articles/Industry-development/how-we-build-an-instant-messging-system-in-the-past-fifteen-years.html</p>",
    "publish_time": "2022-08-17 18:00:50",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "“打脸”谷歌云，说好的超低延迟和可靠性呢？",
    "url": "https://www.infoq.cn/article/b28wu3QTJO57BhSIS9WX",
    "summary": "<p>在国内，很多朋友习惯用Discord收发消息。每一天，都有成百上千万用户通过Discord平台传递多达40亿条消息，而文本聊天其实只占其中一部分。服务器角色、自定义表情符号、视频通话等也都在一刻不停地往来流转，共同构成了全球用户高达数百TB的交互数据总量。</p><p></p><p>为了支持如此庞大的数据规模，我们运行有一组NoSQL数据库集群（采用ScyllaDB），其中每个集群都作为相应数据集的真实来源。作为实时聊天平台，我们希望Discord的数据库能够尽快响应来自用户的高频率查询。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/9a/5d/9ab87bcc5ea0761c39e68be6f820a75d.png\" /></p><p></p><p>从截屏中可见，我们的数据库每秒处理约200万条请求</p><p></p><h2>超越硬件极限</h2><p></p><p></p><p>我们这套数据库面临的最大性能挑战，就是单一磁盘操作带来的延迟——也就是面向物理硬件执行数据读取/写入所耗费的时间。在数据库查询率低于一定水平时，磁盘延迟其实并不明显，毕竟我们的数据库在并行处理请求方面颇有心得（不会阻塞单个磁盘操作）。</p><p></p><p>但这种并行能力是有极限的，所以一旦查询率达到某个阈值，数据库就需要先等待上一条磁盘操作完成，之后才会发出下一条。再加上本身就需要一、两毫秒才能完成的磁盘操作，就导致数据库无法立即向传入的查询提供数据结果。于是乎，磁盘操作和查询就得排队等待，拖慢对查询客户端的响应速度，进而导致应用程序性能不佳。</p><p></p><p>在最极端的情况下，整个事态可能会级联出一个不断扩大的磁盘操作队列，最终使得磁盘查询超时。我们在自己的服务器上就曾经见到过这样的状况，数据库中的磁盘读取队列越来越长，查询操作也开始发生超时。</p><p></p><p>看到这里，细心的朋友可能发现了：磁盘操作要一、两毫秒才能完成？磁盘延迟不是应该以微秒为单位吗，这怎么直接提升了一个数量级？</p><p></p><p>Discord的大部分硬件运行在谷歌云中，所以能够获得对“本地SSD”的直接访问。所谓本地SSD，就是基于NVMe的实例存储，确实可以提供令人印象深刻的超低延迟性能指标。</p><p></p><p>但遗憾的是，我们在测试中发现了一大堆可靠性问题，所以没法安心将关键数据存储在这套解决方案当中。于是我们重新开始思考，既然无法依赖超高速存储设备，那要怎么获得极低的延迟水平？</p><p></p><p>谷歌云还提供另外一种实例存储选项，也就是持久磁盘。这些磁盘可以一边运行，一边从服务器上附加/拆解，可以无需停机就调整容量大小，可以随时生成当前时间点快照，也可以按设计进行复制（防止单块磁盘故障导致数据丢失）。优点确实很多，但持久磁盘的短板就是并非直接接入服务器，而是通过网络就近（可能与服务器处于同一处数据中心内）连接。</p><p></p><p>虽然本地网络连接的延迟并不算高，但还是没法跟跨度在一米以内的PCI或SATA连接相比肩。所以，磁盘操作的平均延迟（从操作系统的角度来看）一般在几毫秒左右，而直连磁盘则可以控制在约0.5毫秒。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/78/4f/7820a67508d1dc0bd903400yyf1f204f.png\" /></p><p></p><p></p><p>本地SSD还有其他问题。跟传统磁盘驱动器一样，一旦某款硬件（可能是SSD本身，也可能是SSD控制器）发生故障，则盘上的所有数据都会立即丢失。而且比传统磁盘更糟的是，如果本地SSD所接入的主机发生严重故障，那么盘上的数据将永久消失。因为无法为全盘创建时间点快照，所以Discord的某些工作流程（例如数据备份）在SSD上根本就不可行。正是由于这些功能缺失，所以Discord的几乎所有服务器配备的都是持久磁盘，而非本地SSD。</p><p></p><h2>问题评估</h2><p></p><p></p><p>在理想状态下，我们当然应该用持久磁盘搭配本地SSD，让它们各自发挥最佳属性，共同为数据库提供完美支持。但这样的完美搭配根本不存在，至少在常规云服务商的生态系统中完全找不到。选择延迟更低的直连SSD，就意味着必须放弃持久磁盘的灵活性优势。</p><p></p><p>但如果我们愿意放弃其中一部分灵活性呢？比方说，写入延迟对我们的工作负载并不重要，因为读取延迟才是对应用程序性能影响最大的部分（消息发布平台上的大部分工作负载都属于读取密集型）。另外，在不停机的前提下，调整磁盘大小也没那么重要，我们完全可以认真预估容量需求，并提前配置更大的存储空间。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/f1/e5/f11890a9ff0c91c22c5b85420fb9fde5.png\" /></p><p></p><p></p><p>所以在考量了数据库运营中最关键的几项指标之后，我们缩小了对数据库解决方案的要求：</p><p></p><p>继续使用谷歌云（继续使用Google Cloud Platform的存储产品）继续使用时间点快照进行数据备份将低延迟SSD读取，设为高于其他一切指标的首要原则不影响现有数据库的正常运行时间谷歌云提供多种存储选项，能够以各自不同的方式满足上述要求。所以如果能把两种存储方案组合成超级选项，那可就太方便了。因为我们对存储性能的核心诉求是低延迟读取，所以最好是能把读取操作交给谷歌云的本地SSD（保证低延迟），而写入则继续指向持久磁盘（发挥快照、复制冗余等优势）。那么，有没有办法能在纯软件层面创建起这样的超级存储方案呢？</p><p></p><h2>创建“超级盘”</h2><p></p><p></p><p>我们前文描述的这套存储方案在本质上其实是个直写缓存，其中以本地SSD作为缓存、持久磁盘则作为存储层。我们的数据库服务器运行的是Ubuntu，所以我们发现Linux内核提供dm-cache、lvm-cache和bcache等模块，能够以多种方式在盘这个层次上实现数据缓存。</p><p></p><p>但很遗憾，我们在缓存实验中发现了几个问题。首先就是如何处理缓存盘中的故障：一旦缓存中出现坏扇区，就会直接导致整个读取操作失败。本地SSD是NVMe SSD硬件之上的一个“薄”层，所以跟常规物理盘一样会受到坏扇区的影响。</p><p></p><p>我们当然可以用来自存储层的数据覆盖掉缓存上的扇区，借此实现坏扇区修复，但目前可选的缓存选项要么不提供这种功能、要么就是复杂度超出了当前阶段的承受范围。</p><p></p><p>总之，如果无法修复缓存中的坏扇区，这些扇区将直接暴露在执行调用的应用程序面前，我们的数据库则会出于安全原因而关闭：</p><p></p><p>storage_service - 由于I/O错误导致通信关闭，需要操作员干预</p><p></p><p>storage_service - 盘错误：std::system_error (error system:61, 无可用数据)</p><p></p><p>到这里，我们的需求被更新为：能够容忍本地SSD上存在坏扇区。为此，我们尝试了另外一种不同类型的Linux内核系统：md。</p><p></p><p>其实md的作用很简单，就是允许Linux创建软件RAID阵列，将多个盘转化成单一“阵列”（虚拟盘）。但我们无法简单将本地SSD和持久磁盘构建成简单的镜像（RAID1）阵列，因为这样会导致约一半的读取操作错误命中持久磁盘。这时候md的优势就来了，它提供一项传统RAID控制器所不具备的附加功能，即“write-mostly”。内核手册对这项功能做出了准确描述：</p><p></p><p>RAID1中的单个设备可被标记为“write-mostly”。这些驱动器将被排除在正常的读取均衡之外，仅在没有其他选项时才会被读取。这项功能适用于通过慢速链路接入的设备。</p><p></p><p>就是它了，“通过慢速链路接入的设备”，这说的不就是持久磁盘吗？看起来md应该能帮我们完成打造“超级盘”的计划。只要构建一个包含本地SSD和&nbsp;“write-mostly”持久磁盘的RAID1阵列，我们的所有要求就都能得到满足。</p><p></p><p>但现在还有最后一个问题：谷歌云中的本地SSD大小正好是375 GB。对于某些应用程序，Discord需要让单一数据库实例具备1&nbsp;TB甚至更大的存储空间，所以375 GB明显有点不够看。我们当然可以把多个本地SSD接入服务器，但还需要找到办法把这堆小盘整合成统一的大盘。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/1f/9f/1f601f02f2ed7d02e065dc97aaffcc9f.png\" /></p><p></p><p>好在md提供多种RAID配置，可以跨多个盘实现数据条带化。最简单的方式就是用RAID0将原始数据拆分到所有盘上，但这样如果某个盘损坏，整个阵列都会出现故障、导致全部数据丢失。更复杂的方法是用RAID5、RAID6保持奇偶校验，这样至少在单盘损坏时仍能保持数据完好，但代价就是性能下降。这是一种常见的正常运行时间保障方法，把损坏盘拆下、换块新盘即可。</p><p></p><p>但在谷歌云中，压根不存在替换本地SSD这个概念——毕竟这些设备都隐藏在谷歌数据中心的未知角落。另外，谷歌云还为本地SSD提供了一项神奇的“保障”服务：一旦有本地SSD发生故障，整个服务器将被迁移至另外一套数据集上，就相当于擦除了该服务器之前的所有本地SSD数据。因为没办法更换本地SSD，也不想承担RAID条带造成的性能影响，所以我们最终选择用RAID0把多个本地SSD转化为单一低延迟虚拟磁盘。</p><p></p><p>我们用本地SSD建立RAID0阵列，再把持久磁盘跟RAID0阵列共同构建成RAID1阵列，这样就可以为数据库提供低延迟读取盘，同时仍然享受持久磁盘提供的种种灵活性优势。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/61/12/610cbf7986b848f9ceb4c933792b2c12.png\" /></p><p></p><p></p><h2>数据库性能</h2><p></p><p></p><p>从测试来看，这套新方案确实表现不错。那在实际生产中，它又能不能满足我们的需求呢？</p><p></p><p>结果没有令我们失望 — 在峰值负载时，我们的数据库再未出现过磁盘操作队列，而且查询延迟也不会波动。再结合实践指标，可以看到绝大部分数据库读取都发生在这套“超级盘”上，极少会跑去读持久磁盘，所以I/O操作的整体耗时得到显著降低。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/c9/e6/c9ff7e0c5yy05bd62a7cf5d020bec1e6.png\" /></p><p></p><p>凭借出色的性能提升，我们能够在同一批服务器上处理更多查询。这对我们这些数据库服务器维护人员和公司财务部门来说，都是个好消息。</p><p></p><h2>总结</h2><p></p><p>回想起来，我们真该在数据库部署之初就认真处理磁盘延迟问题。云计算世界中包含太多系统，所以同样的硬件在其中的运行方式往往跟我们熟悉的本地数据中心截然不同。</p><p></p><p>通过这次“超级盘”解决方案的研发和测试经历，我们总结出一系列实用的性能监控指标，让团队理解了存储设备的内部工作原理（包括在Linux和谷歌云环境下），同时也改善了我们的测试与验证架构变更文化。随着“超级盘”的生产实践，我们的数据库终于能随Discord用户规模的扩大而稳定拓展了。</p><p></p><p>但拥有RAID集群维护经验的朋友可能还抱有疑问：这样一套配置能稳定运行吗？毕竟云环境下充斥着无数系统，往往会以难以理解的方式引发故障。所以单靠md配置，恐怕不足以支撑起一套稳定的存储组合方案。说得没错，所以请大家期待本系列博文的第二部分，届时我们将具体介绍“超级盘”在云端遇到的极端案例，并分享我们的解决思路。</p><p></p><p>原文链接：</p><p></p><p><a href=\"https://discord.com/blog/how-discord-supercharges-network-disks-for-extreme-low-latency\">https://discord.com/blog/how-discord-supercharges-network-disks-for-extreme-low-latency</a>\"</p><p></p>",
    "publish_time": "2022-08-17 18:04:06",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "为什么人工智能的未来是混合智能？",
    "url": "https://www.infoq.cn/article/GqhluvskSPQQwQNT9aEt",
    "summary": "<p>本文最初发布于T.Ferguson的个人博客。</p><p></p><p>混合智能是一种让人工智能和人类一起工作以实现预期结果并相互学习的方法。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/a4/58/a45d1a0bc697708f8a0b181a8f213358.png\" /></p><p></p><p>图片来源：<a href=\"https://www.piqsels.com/en/public-domain-photo-zwfob/download\">https://www.piqsels.com/en/public-domain-photo-zwfob/download</a>\"</p><p></p><p><a href=\"https://www.oracle.com/artificial-intelligence/what-is-ai?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjA3MzE1MTcsImZpbGVHVUlEIjoiemRreUI1MmFlNEh5bGJBNiIsImlhdCI6MTY2MDczMTIxNywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyMDQxOTA5MH0.SF3jokywvRtkKezN5-B9IcL_DI3urlPw2mOuSMasYvY\">人工智能（AI）</a>\"正迅速成为全球数据生态系统的主导趋势。而且，在经过十年的发展后，它预计还会继续增长。</p><p></p><p>数据社区对人工智能及其所能完成的任务了解得越多，IT系统和结构就能获得越多的赋能。</p><p></p><p>这就是为什么IDC预计到2024年市场规模将达到<a href=\"https://www.idc.com/getdoc.jsp?containerId=prUS48127321&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjA3MzE1MTcsImZpbGVHVUlEIjoiemRreUI1MmFlNEh5bGJBNiIsImlhdCI6MTY2MDczMTIxNywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyMDQxOTA5MH0.SF3jokywvRtkKezN5-B9IcL_DI3urlPw2mOuSMasYvY\">5000亿美元</a>\"，它会渗透到几乎所有行业和数量庞大的应用程序和服务中，目的是提高工作效率。事实上，根据CB Insights Research的数据，在2021年第三季度末，人工智能公司的融资已经<a href=\"https://www.cbinsights.com/research/report/ai-trends-q3-2021?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjA3MzE1MTcsImZpbGVHVUlEIjoiemRreUI1MmFlNEh5bGJBNiIsImlhdCI6MTY2MDczMTIxNywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyMDQxOTA5MH0.SF3jokywvRtkKezN5-B9IcL_DI3urlPw2mOuSMasYvY\">超过了2020年</a>\"约55%，连续四个季度创造了全球纪录。</p><p></p><p>根据人工智能在复杂认知任务（如自然语言解释）方面的进展，我们预计，2022年，它在解决妨碍非结构化语言数据驱动的操作（<a href=\"https://www.techtarget.com/searchenterpriseai/definition/natural-language-understanding-NLU?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjA3MzE1MTcsImZpbGVHVUlEIjoiemRreUI1MmFlNEh5bGJBNiIsImlhdCI6MTY2MDczMTIxNywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyMDQxOTA5MH0.SF3jokywvRtkKezN5-B9IcL_DI3urlPw2mOuSMasYvY\">NLU</a>\"）方面将变得更加强大。同时，对人工智能的如何和为何的审查将越来越多。例如，<a href=\"https://www.nist.gov/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjA3MzE1MTcsImZpbGVHVUlEIjoiemRreUI1MmFlNEh5bGJBNiIsImlhdCI6MTY2MDczMTIxNywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyMDQxOTA5MH0.SF3jokywvRtkKezN5-B9IcL_DI3urlPw2mOuSMasYvY\">美国国家标准与技术研究院（NIST）</a>\"将继续采取措施，使人工智能更容易理解。这需要在不降低性能或增加成本的情况下，让人工智能的计算功能更加开放。</p><p></p><h1>语言理解的挑战</h1><p></p><p></p><p>理解语言是人工智能必须面对的最困难的问题之一。</p><p></p><p>虽然大多数人工智能系统可以在眨眼间处理大量的原始数值或结构化数据，但语言中有大量含义和细微差别，上下文不同，描述的故事可能就不同。</p><p></p><p>对人类思维来说简单而自然的事情，对软件来说却不那么简单。这就是为什么<a href=\"https://www.scnsoft.com/software-development/ai?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjA3MzE1MTcsImZpbGVHVUlEIjoiemRreUI1MmFlNEh5bGJBNiIsImlhdCI6MTY2MDczMTIxNywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyMDQxOTA5MH0.SF3jokywvRtkKezN5-B9IcL_DI3urlPw2mOuSMasYvY\">创建能够持续正确地理解语言的软件</a>\"已经成为人工智能全面发展的一个重要方面。让人工智能可以获取和吸收几乎任何类型的知识，实现这种水平的计算能力将真正打开人工智能发展的闸门。</p><p></p><p>受限于挖掘大量语言数据的能力，NLU是这个难题的一个关键部分。由于语言遍及商业活动的各个方面，如果不能从这类数据中收集尽可能多的有价值的信息，人工智能战略就不完整。</p><p></p><p>基于知识或符号的人工智能方法利用了一个开放式的知识图谱。它的结构是人类设计用来模仿现实世界的，其中定义了概念，而概念之间通过语义关系相互关联。借助于知识图谱和NLU<a href=\"https://rockcontent.com/blog/artificial-intelligence-algorithm?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjA3MzE1MTcsImZpbGVHVUlEIjoiemRreUI1MmFlNEh5bGJBNiIsImlhdCI6MTY2MDczMTIxNywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyMDQxOTA5MH0.SF3jokywvRtkKezN5-B9IcL_DI3urlPw2mOuSMasYvY\">算法</a>\"，你可以阅读和学习任何现成的资料，真正理解数据分析过程以及从那个解释形成的推论。这可以与我们人类获得特定领域知识的方式相媲美，让人工智能项目将算法输出与明确的知识表示联系起来。</p><p></p><p>我们应该看到，这种结合两种方法的人工智能战略是一种明显的趋势。<a href=\"https://www.techtarget.com/searchenterpriseai/feature/Enterprise-hybrid-AI-use-is-poised-to-grow?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjA3MzE1MTcsImZpbGVHVUlEIjoiemRreUI1MmFlNEh5bGJBNiIsImlhdCI6MTY2MDczMTIxNywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyMDQxOTA5MH0.SF3jokywvRtkKezN5-B9IcL_DI3urlPw2mOuSMasYvY\">混合人工智能</a>\"采用了各种策略来提高整体性能，更好地解决高难度的认知问题。对于NLU和自然语言处理，混合人工智能正变得越来越流行（NLP）。针对如今企业提出的准确、快速、大规模解锁非结构化语言数据价值的需求，最有效的方法是将基于人工智能的知识或符号人工智能与学习模型（机器学习，ML）相结合。</p><p></p><p>知识、符号推理和语义理解不仅会产生更准确的结果和更高效、更有效的人工智能环境，而且还会减少在昂贵的高速数据基础设施上进行耗时的资源密集型训练所产生的浪费。主题专家和/或机器学习算法可以通过分析微小的定题训练数据集来增加特定领域的知识，从而快速有效地提供准确、可行的答案。</p><p></p><h1>混合人工智能的世界</h1><p></p><p>为什么现在会发生这种变化？为什么人工智能以前没有能够利用基于语言的知识？学习方法让我们相信，它们可以解决我们的任何困难。但也只是在某些情况下可以，因为ML在某些情况和上下文中表现良好，并不意味着它总是最佳选择。当涉及掌握和吸收语言的能力时，我们经常看到这种情况。只是在过去几年里，我们看到了基于混合（或复合）人工智能的NLU取得了重大进展。</p><p></p><p>我们现在不是使用单一类型的人工智能和一套有限的工具来解决一个问题，而是可以使用许多方式。每一种都可以从不同的角度来处理问题，在多上下文中，采用多个模型来评估和解决一个问题。而且，由于这些策略中的每一个都可以独立于其他策略进行检查，所以很容易弄清楚哪些策略生成的结果最好。</p><p></p><p>2022年，这种<a href=\"https://www.cmswire.com/information-management/why-ibms-ai-hybrid-cloud-strategy-is-more-than-good-its-imperative?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjA3MzE1MTcsImZpbGVHVUlEIjoiemRreUI1MmFlNEh5bGJBNiIsImlhdCI6MTY2MDczMTIxNywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyMDQxOTA5MH0.SF3jokywvRtkKezN5-B9IcL_DI3urlPw2mOuSMasYvY\">混合战略</a>\"有望成为一项战略性努力，企业已经尝到了人工智能所带来的好处。它节省了时间和金钱，同时加快了分析和操作程序的速度，提高了准确性和效率。举例来说，考虑到训练的复杂性和成本，现在的标注过程是由少数专业人员进行的。通过整合适当的信息库和图，训练过程可能被大大简化，使其在整个知识工作队伍中实现民主化。</p><p></p><h1>未来展望</h1><p></p><p>当然，各种人工智能的发展是一个持续的过程。然而，由于企业一直面临着快速、低成本地使用大量数据的压力，我们将看到人们会对构建知识图谱和自动化ML和其他技术特别关注。</p><p></p><p>随着时间的推移，我们将看到企业利用这些混合模式在一些最关键的活动方面逐渐取得进展。电子邮件管理和搜索已经成为业务自动化的案例。例如，目前基于关键词的搜索方法本质上还无法吸收和理解整个文档，这就是为什么它只能检索到基本的、本质上没有语境的数据。同样地，自动化电子邮件管理系统也很少能够解释产品名称等数据点之外的意义。最终，用户不得不对大量的结果进行筛选，才能获得最重要的信息。流程被拖慢，决策被推迟，生产力和收入因此而受到影响。</p><p></p><p>所有以知识为基础的公司都将能够通过在混合架构中结合NLU工具和符号理解，在其智能、自动化流程中模仿人类理解整个文档的能力。</p><p></p><p>查看英文原文：</p><p></p><p><a href=\"https://medium.com/@fergie19702004_40140/why-is-hybrid-intelligence-the-artificial-intelligence-of-the-future-7adb73fad130?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjA3MzE1MTcsImZpbGVHVUlEIjoiemRreUI1MmFlNEh5bGJBNiIsImlhdCI6MTY2MDczMTIxNywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyMDQxOTA5MH0.SF3jokywvRtkKezN5-B9IcL_DI3urlPw2mOuSMasYvY\">https://medium.com/@fergie19702004_40140/why-is-hybrid-intelligence-the-artificial-intelligence-of-the-future-7adb73fad130?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjA3MzE1MTcsImZpbGVHVUlEIjoiemRreUI1MmFlNEh5bGJBNiIsImlhdCI6MTY2MDczMTIxNywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyMDQxOTA5MH0.SF3jokywvRtkKezN5-B9IcL_DI3urlPw2mOuSMasYvY</a>\"</p><p></p>",
    "publish_time": "2022-08-17 18:32:26",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]