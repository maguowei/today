[
  {
    "title": "谷歌推出Bigtable联邦查询，实现零ETL数据分析",
    "url": "https://www.infoq.cn/article/cfBjW6rIGjIfU4LhjezU",
    "summary": "<p>最近，<a href=\"https://www.infoq.cn/topic/google\">谷歌</a>\"宣布Bigtable联邦查询普遍可用，用户通过BigQuery可以更快地查询Bigtable中的数据。此外，查询无需移动或复制所有谷歌云区域中的数据，增加了联邦查询并发性限制，从而缩小了运营数据和分析数据之间长期存在的差距。</p><p>&nbsp;</p><p>BigQuery是谷歌云的无服务器、多云数据仓库，通过将不同来源的数据汇集在一起来简化数据分析。Cloud Bigtable是谷歌云的全托管NoSQL数据库，主要用于对时间比较敏感的事务和分析工作负载。后者适用于多种场景，如实时欺诈检测、推荐、个性化和时间序列。</p><p>&nbsp;</p><p>在以前，用户需要使用ETL工具（如Dataflow或者自己开发的Python工具）将数据从Bigtable复制到BigQuery。现在，他们可以直接使用BigQuery SQL查询数据。联邦查询BigQuery可以访问存储在Bigtable中的数据。</p><p>&nbsp;</p><p>要查询Bigtable中的数据，用户可以通过指定Cloud Bigtable URI（可以通过Cloud Bigtable控制台获得）为Cloud Bigtable数据源创建一个外部表。URI包含以下这些内容：</p><p>&nbsp;</p><p>包含Cloud Bigtable实例的项目ID——project_id；Cloud Bigtable实例ID——instance_id；要使用的应用程序配置文件ID——app_profile（可选）；要查询的表名——table_name。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0d/0dcf4d50fbb381f0343adde4dd85fcc5.png\" /></p><p></p><p>来源：<a href=\"https://cloud.google.com/blog/products/data-analytics/bigtable-bigquery-federation-brings-hot--cold-data-closer\">https://cloud.google.com/blog/products/data-analytics/bigtable-bigquery-federation-brings-hot--cold-data-closer</a>\"</p><p>&nbsp;</p><p>在创建了外部表之后，用户就可以像查询BigQuery中的表一样查询Bigtable。此外，用户还可以利用BigQuery的特性，比如JDBC/ODBC驱动程序、用于商业智能的连接器、数据可视化工具（Data Studio、Looker和Tableau等），以及用于训练机器学习模型的AutoML表和将数据加载到模型开发环境中的Spark连接器。</p><p>&nbsp;</p><p>大数据爱好者Christian Laurer在一篇文章中解释了Bigtable联邦查询的好处。</p><p>&nbsp;</p><p></p><blockquote>你可以使用这种新的方法克服传统ETL的一些缺点，如：&nbsp;1. 更多的数据更新（为你的业务提供最新的见解，没有小时级别甚至天级别的旧数据）；2. 不需要为相同的数据存储支付两次费用（用户通常会在Bigtable中存储TB级甚至更多的数据）；3. 减少ETL管道的监控和维护。</blockquote><p></p><p>&nbsp;</p><p>最后，关于Bigtable联邦查询的更多详细信息，请参阅官方的<a href=\"https://cloud.google.com/bigquery/docs/external-data-bigtable\">文档页</a>\"。此外，所有受支持的Cloud Bigtable区域都可以使用新的联邦查询。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/08/bigtable-bigquery-zero-etl/\">Google Introduces Zero-ETL Approach to Analytics on Bigtable Data Using BigQuery</a>\"</p>",
    "publish_time": "2022-08-25 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Kafka Streams与Quarkus：实时处理事件",
    "url": "https://www.infoq.cn/article/WfA0p1XoZCJ6INdyJLyv",
    "summary": "<p>在本系列的<a href=\"https://www.infoq.cn/article/cFpvXRLmZzJBGbzAeFu5\">第一部分</a>\"中，我们学习了<a href=\"https://kafka.apache.org/\">Apache Kafka</a>\"和<a href=\"https://quarkus.io/\">Quarkus</a>\"的集成，并开发了一个简单的应用，从两个Kafka主题生产和消费事件。</p><p></p><p>在那个样例中，我们模拟了一个影视流公司，在一个Kafka主题中存储电影信息，在另外一个主题中存储了用户停止观看电影时所发生的每个事件，并捕获了电影已播放的时间。</p><p></p><p>下图展示了该应用的架构：</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/quarkus-with-kafka-streams/en/resources/1Untitled-10-1656674518432.jpeg\" /></p><p></p><p>我们可以看到，消费消息很简单，只要有消息生成，我们就可以得到它们，但是除此之外，我们也做不了其他的事情了。如果我们需要实时处理数据（比如过滤或操作事件）或者我们需要在事件之间做一些关联，单纯使用Kafka的消费API可能就不是最佳的方式了，因为这会导致代码非常复杂。</p><p></p><h2>Kafka Streams</h2><p></p><p><a href=\"https://kafka.apache.org/documentation/streams/\">Kafka Streams</a>\"项目能够帮助我们在事件产生时实时消费它们，应用各种转换，执行流连接等，并且可以选择性地将新的数据表述写回主题中。</p><p></p><p>对于有状态和无状态的流应用来说，Kafka Streams都是理想方案，它能够实现基于时间的操作（例如，围绕给定的时间段对事件进行分组），并且考虑到了Kafka生态系统中普遍存在的可扩展性、可靠性和可维护性。</p><p></p><p>Kafka Stream由三个元素组成，即输入（源处理器）、输出（sink处理器）和处理器（流处理器）。</p><p></p><p>源处理器（Source processor）：源处理器代表一个Kafka主题。源处理器会发送事件到一个或多个流处理器中。</p><p></p><p>流处理器（Stream processor）：流处理器会将转换/逻辑应用于输入流中，比如连接、分组、计数、映射等。流处理器可以连接至另一个流处理器和/或sink处理器。</p><p></p><p>Sink处理器（Sink processor）：Sink处理器代表了输出的数据，它会连接至一个Kafka主题。</p><p></p><p>**拓扑结构（topology）**是由源、处理器和sink组成的无循环图，事件会传入到一个Kafka Streams中，该实例将开始拓扑结构的执行。</p><p></p><h2>Kafka Streams和Quarkus</h2><p></p><p>Quarkus使用Quarkus KStreams扩展实现与<a href=\"https://kafka.apache.org/documentation/streams/\">Kafka Streams</a>\"集成。</p><p></p><h3>Quarkus起步</h3><p></p><p>使用Quarkus最快捷的方式是通过<a href=\"https://code.quarkus.io/\">初始化页面</a>\"添加所需的依赖。每个服务可能需要不同的依赖，你可以选择Java 11或Java 17。为了实现Quarkus与Kafka Streams的集成，我们至少需要添加Kafka Streams扩展。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/quarkus-with-kafka-streams/en/resources/1Captura%20de%20Pantalla%202022-04-10%20a%20las%2022.34.28-1656674518432.jpeg\" /></p><p></p><h2>要开发的应用</h2><p></p><p>正如在本文开始时所提到的，在本系列的<a href=\"https://www.infoq.cn/article/cFpvXRLmZzJBGbzAeFu5\">第一部分</a>\"中，我们开发了一个影视流公司，它有两个Kafka主题，其中一个用来存储电影的列表，另外一个主题会在用户停止播放电影时存储用户所在的区域（事件的键），并且会以电影id和播放时间作为事件的值。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/quarkus-with-kafka-streams/en/resources/1topic-1656674518432.jpeg\" /></p><p></p><p>所有的这些逻辑都是在名为<a href=\"https://github.com/lordofthejars/movie-plays-kafka/tree/main/movie-plays-producer\">Movie Plays Producer</a>\"的生成者服务中创建的，该服务是使用Quarkus开发的。</p><p></p><p>除此之外，我还使用Quakus开发了一个<a href=\"https://github.com/lordofthejars/movie-plays-kafka/tree/main/movie-plays-consumer\">Movie Plays Consumer</a>\"服务，它会消费这两个主题的事件并且会在控制台上展示它们（并实现了HTTP服务器端事件）。</p><p></p><p>但是，这里没有对数据进行任何处理，它只是按照原样进行了接收。如果我们想要在movies和playtimemovies主题之间进行一下连接，在获取电影播放时长的时候得到电影的详细信息而不是id的话，那又该怎么办呢？</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/quarkus-with-kafka-streams/en/resources/1join-1656674518432.jpeg\" /></p><p></p><p>如果仅仅使用Kafka消息来实现这样的逻辑会变成一项很复杂的任务，因为我们需要在一个Map中存储Movie信息，并且在每个playedmovie事件发生时，进行匹配处理。</p><p></p><h3>Movie Plays KStream</h3><p></p><p>与其为每个用例手工编写代码，不如看一下如何使用Kafka Streams，以及它是如何与Quarkus集成来解决这个问题的。</p><p></p><h4>创建项目</h4><p></p><p>导航至Quarkus的<a href=\"https://code.quarkus.io/\">初始化页面</a>\"，并选择Apache Kafka Streams扩展来实现与Kafka Streams的集成。然后，选择RestEasy和RestEasy Jackson扩展实现事件从Java对象和JSON之间的编排/解排。同时，取消选中Started Code生成选项。</p><p></p><p>请参照下面的截图：</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/quarkus-with-kafka-streams/en/resources/1Captura%20de%20Pantalla%202022-04-10%20a%20las%2017.25.38-1656674518432.jpeg\" /></p><p></p><p>你也可以跳过这个手动的步骤并导航至<a href=\"https://code.quarkus.io/?a=movie-plays-kstreams&amp;nc=true&amp;e=kafka-streams&amp;e=resteasy-jackson&amp;e=resteasy\">Kafka Stream Quarkus Generator链接</a>\"，在这里，所有的依赖都已经选择好了。然后，点击Generate your application按钮，以下载应用骨架的压缩文件。</p><p></p><p>解压文件，并在你最喜欢的IDE中打开项目。</p><p></p><h4>开发</h4><p></p><p>当开发Kafka Stream应用时，我们需要做的第一件事就是创建<a href=\"https://kafka.apache.org/28/javadoc/org/apache/kafka/streams/Topology.html\">Topology</a>\"实例，并定义源、处理器和sink。</p><p></p><p>在Quarkus中，我们只需要创建一个_CDI_类，这个类需要包含一个返回Topology实例的方法。</p><p></p><p>创建名为TopologyProducer的类，它将会实现从这两个主题消费事件并连接它们的逻辑。最后，生成的结果将会发送至一个sink处理器，该处理器以控制台输出的形式展示结果。</p><p></p><p>还有一个元素我们没有提到，在这些场景中它非常有用，那就是Kafka Tables。</p><p></p><p>一个主题可以包含具有相同键的多个事件。例如，我们可以使用某个键插入一个电影，然后我们可以使用相同的键创建一个新的事件来对电影进行更新：</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/quarkus-with-kafka-streams/en/resources/1topic-1656674518432.jpg\" /></p><p></p><p>但是，如果我们想要让movies主题与_playtimemovies_主题进行连接的话，那我们该选择使用哪个值为1的事件呢？第一个还是第二个？在这个具体的情况中，应该选择最新的那一个，因为它包含了电影的最新版本。为了获取每个事件的最新版本，Kafka Streams有一个_表_的概念（<a href=\"https://kafka.apache.org/28/javadoc/org/apache/kafka/streams/kstream/GlobalKTable.html\">KTable/GlobalKTable</a>\"）。</p><p></p><p>Kafka Streams会浏览指定的主题，获取每个事件的最新版本，并将其放到一个表实例中。</p><p></p><p>KafkaStream扩展并不会像Kafka Messaging集成那样自动注册<a href=\"https://kafka.apache.org/23/javadoc/org/apache/kafka/common/serialization/Serdes.html\">SerDes</a>\"，所以我们需要在拓扑中手动注册它们。</p><p></p><p><code lang=\"java\">package org.acme;\n\nimport javax.enterprise.context.ApplicationScoped;\nimport javax.enterprise.inject.Produces;\n\nimport org.apache.kafka.common.serialization.Serdes;\nimport org.apache.kafka.streams.KeyValue;\nimport org.apache.kafka.streams.StreamsBuilder;\nimport org.apache.kafka.streams.Topology;\nimport org.apache.kafka.streams.kstream.Consumed;\nimport org.apache.kafka.streams.kstream.GlobalKTable;\nimport org.apache.kafka.streams.kstream.KStream;\nimport org.apache.kafka.streams.kstream.Printed;\n\nimport io.quarkus.kafka.client.serialization.ObjectMapperSerde;\n\n@ApplicationScoped\npublic class TopologyProducer {\n\n   private static final String MOVIES_TOPIC = \"movies\";\n   private static final String PLAY_MOVIES_TOPIC = \"playtimemovies\";\n\n   @Produces\n   public Topology getTopCharts() {\n\n       final StreamsBuilder builder = new StreamsBuilder();\n\n// 用于Movie和PlayedMovie的SerDes\n\n       final ObjectMapperSerde movieSerder = new ObjectMapperSerde&lt;&gt;(Movie.class);\n       final ObjectMapperSerde moviePlayedSerder = new ObjectMapperSerde&lt;&gt;(MoviePlayed.class);\n\n    // 为Movies主题创建一个Global Kafka Table\n\n       final GlobalKTable moviesTable = builder.globalTable(\n               MOVIES_TOPIC,\n               Consumed.with(Serdes.Integer(), movieSerder));\n\n    // 连接至playtimemovies主题的流，每当该主题有事件生成都会被该流所消费\n\n       final KStream playEvents = builder.stream(\n               PLAY_MOVIES_TOPIC, Consumed.with(Serdes.String(), moviePlayedSerder));\n\n// PlayedMovies使用区域作为键，对象作为值。我们对内容进行map操作，让电影的id作为key（以便于进行连接）并让对象继续作为值\n// 另外，我们使用movies表的键（movieId）以及流的键（在前面的map方法中，我们也将其变成了movieId）进行连接\n\n// 最后，结果会流向控制台\n\n    playEvents\n           .map((key, value) -&gt; KeyValue.pair(value.id, value)) // Now key is the id field\n           .join(moviesTable, (movieId, moviePlayedId) -&gt; movieId, (moviePlayed, movie) -&gt; movie)\n           .print(Printed.toSysOut());\n       return builder.build();\n\n   }\n}\n</code></p><p></p><p>Movie和MoviePlayed POJO包含了实现逻辑所需的属性：</p><p></p><p>Movie对象如下所示：</p><p><code lang=\"java\">package org.acme;\n\npublic class Movie {\n\n   public int id;\n   public String name;\n   public String director;\n   public String genre;\n\n   public Movie(int id, String name, String director, String genre) {\n       this.id = id;\n       this.name = name;\n       this.director = director;\n       this.genre = genre;\n   }\n}\n</code></p><p></p><p>MoviePlayed对象如下所示：</p><p><code lang=\"java\">package org.acme;\n\npublic class MoviePlayed {\n\n   public int id;\n   public long duration;\n\n   public MoviePlayed(int id, long duration) {\n       this.id = id;\n       this.duration = duration;\n   }\n\n}\n</code></p><p></p><p>运行Kafka Stream应用之前的最后一步是配置参数，其中最重要的是quarkus.kafka-streams.topics。它是一个主题列表，在拓扑结构开始处理数据之前，它们就要存在于Kafka集群中，这是一个前提条件。</p><p></p><p>打开src/main/resources/application.properties文件并添加如下的代码行：</p><p><code lang=\"java\">kafka-streams.cache.max.bytes.buffering=10240\nkafka-streams.commit.interval.ms=1000\nkafka-streams.metadata.max.age.ms=500\nkafka-streams.auto.offset.reset=earliest\nkafka-streams.metrics.recording.level=DEBUG\n\nquarkus.kafka-streams.topics=playtimemovies,movies\n</code></p><p></p><p>现在，我们可以测试一下流了。我们启动在<a href=\"https://www.infoq.cn/article/cFpvXRLmZzJBGbzAeFu5\">上一篇文章</a>\"中开发的生产者。生产者的源码可以在<a href=\"https://github.com/lordofthejars/movie-plays-kafka/tree/main/movie-plays-producer\">这里</a>\"找到。</p><p></p><p>Quarkus KStreams集成了Quarkus DevServices。所以，我们不需要启动Kafka集群，也不需要配置它的位置，因为Quarkus Dev模式会处理好所有的事情。我们只需要记住在自己的计算机上要有一个运行中的容器环境即可，比如Podman或其他兼容OCI的工具。</p><p></p><p>在终端窗口中启动生产者服务：</p><p><code lang=\"java\">cd movie-plays-producer\n./mvnw compile quarkus:dev\n\n2022-04-11 07:49:31,900 INFO  [org.acm.mov.MovieKafkaGenerator] (executor-thread-0) movie Cruella played for 287 minutes\n2022-04-11 07:49:31,941 INFO  [io.quarkus] (Quarkus Main Thread) movie-plays-producer 1.0.0-SNAPSHOT on JVM (powered by Quarkus 2.7.3.Final) started in 4.256s.\n2022-04-11 07:49:31,942 INFO  [io.quarkus] (Quarkus Main Thread) Profile dev activated. Live Coding activated.\n2022-04-11 07:49:31,943 INFO  [io.quarkus] (Quarkus Main Thread) Installed features: [cdi, kafka-client, smallrye-context-propagation, smallrye-reactive-messaging, smallrye-reactive-messaging-kafka, vertx]\n2022-04-11 07:49:32,399 INFO  [org.acm.mov.MovieKafkaGenerator] (executor-thread-0) movie Encanto played for 162 minutes\n2022-04-11 07:49:32,899 INFO  [org.acm.mov.MovieKafkaGenerator] (executor-thread-0) movie The Hobbit played for 255 minutes\n2022-04-11 07:49:33,404 INFO  [org.acm.mov.MovieKafkaGenerator] (executor-thread-0) movie Sing 2 played for 264 minutes\n2022-04-11 07:49:33,902 INFO  [org.acm.mov.MovieKafkaGenerator] (executor-thread-0) movie Encanto played for 28 minutes\n2022-04-11 07:49:34,402 INFO  [org.acm.mov.MovieKafkaGenerator] (executor-thread-0) movie Star Trek: First Contact played for 137 minutes\n2022-04-11 07:49:34,903 INFO  [org.acm.mov.MovieKafkaGenerator] (executor-thread-0) movie Star Trek: First Contact played for 277 minutes\n2022-04-11 07:49:35,402 INFO  [org.acm.mov.MovieKafkaGenerator] (executor-thread-0) movie The Hobbit played for 141 minutes\n</code></p><p></p><p>在另一个终端窗口中，启动我们刚刚开发的Kafka Stream代码：</p><p><code lang=\"java\">./mvnw compile quarkus:dev\n\n2022-04-11 07:54:59,321 INFO  [org.apa.kaf.str.pro.int.StreamTask] (movie-plays-kstreams-22c86daa-cd28-4956-9d0d-57b6b282a2ea-StreamThread-1) stream-thread [movie-plays-kstreams-22c86daa-cd28-4956-9d0d-57b6b282a2ea-StreamThread-1] task [1_0] Restored and ready to run\n2022-04-11 07:54:59,322 INFO  [org.apa.kaf.str.pro.int.StreamThread] (movie-plays-kstreams-22c86daa-cd28-4956-9d0d-57b6b282a2ea-StreamThread-1) stream-thread [movie-plays-kstreams-22c86daa-cd28-4956-9d0d-57b6b282a2ea-StreamThread-1] Restoration took 74 ms for all tasks [1_0]\n2022-04-11 07:54:59,322 INFO  [org.apa.kaf.str.pro.int.StreamThread] (movie-plays-kstreams-22c86daa-cd28-4956-9d0d-57b6b282a2ea-StreamThread-1) stream-thread [movie-plays-kstreams-22c86daa-cd28-4956-9d0d-57b6b282a2ea-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING\n2022-04-11 07:54:59,324 INFO  [org.apa.kaf.str.KafkaStreams] (movie-plays-kstreams-22c86daa-cd28-4956-9d0d-57b6b282a2ea-StreamThread-1) stream-client [movie-plays-kstreams-22c86daa-cd28-4956-9d0d-57b6b282a2ea] State transition from REBALANCING to RUNNING\n[KSTREAM-LEFTJOIN-0000000005]: 4, Movie [director=Craig Gillespie, genre=Crime Comedy, id=4, name=Cruella]\n[KSTREAM-LEFTJOIN-0000000005]: 2, Movie [director=Jonathan Frakes, genre=Space, id=2, name=Star Trek: First Contact]\n[KSTREAM-LEFTJOIN-0000000005]: 4, Movie [director=Craig Gillespie, genre=Crime Comedy, id=4, name=Cruella]\n[KSTREAM-LEFTJOIN-0000000005]: 1, Movie [director=Peter Jackson, genre=Fantasy, id=1, name=The Hobbit]\n[KSTREAM-LEFTJOIN-0000000005]: 4, Movie [director=Craig Gillespie, genre=Crime Comedy, id=4, name=Cruella]\n[KSTREAM-LEFTJOIN-0000000005]: 4, Movie [director=Craig Gillespie, genre=Crime Comedy, id=4, name=Cruella]\n[KSTREAM-LEFTJOIN-0000000005]: 3, Movie [director=Jared Bush, genre=Animation, id=3, name=Encanto]\n[KSTREAM-LEFTJOIN-0000000005]: 5, Movie [director=Garth Jennings, genre=Jukebox Musical Comedy, id=5, name=Sing 2]\n</code></p><p></p><p>在输出中打印的是事件（连接所生成的结果），其中键是movieId，值是movie本身。我们现在所具有的功能是，每当一个电影停止播放时，Kafka Stream会对其进行处理并以Movie全量信息的形式对其进行展现。</p><p></p><p>到目前为止，还不算复杂，对于这样的场景，你可能会想我们根本没有必要使用Kafka Streams。但是，我们再加一些需求，这样你就能看到它的强大之处了。</p><p></p><p>现在，我们不是在用户每次停掉电影的时候都生成事件，而是只对用户观看时间超过10分钟的电影发送事件。</p><p></p><p>我们可以使用filter方法按照持续时长进行过滤。</p><p><code lang=\"java\">playEvents\n       .filter((region, event) -&gt; event.duration &gt;= 10) // filters by duration\n       .map((key, value) -&gt; KeyValue.pair(value.id, value))\n       .join(moviesTable, (movieId, moviePlayedId) -&gt; movieId, (moviePlayed, movie) -&gt; movie)\n        .print(Printed.toSysOut());\n</code></p><p></p><p>重启应用，我们可以发现观看时长小于10分钟的电影将不会被处理。</p><p></p><p>我们发现，Kafka Streams有助于代码的整洁性，接下来，我们添加最后的需求。现在，我们对每部电影的播放时长并不感兴趣，而是对每部电影有多少次超过10分钟的播放感兴趣。</p><p></p><p>到目前为止，对事件的处理都是无状态的，因为事件都是遵循这样的步骤，即接收、处理并发送至sink处理器（也就是发送至一个主题或控制台输出），但是，为了统计某部电影播放的次数，我们需要在内存记住电影被播放了多少次，并且当任意用户再次观看超过10分钟的时候，要对这个统计数字递增一次。此时，事件的处理就要以有状态的方式进行了。</p><p></p><p>我们需要做的第一件事就是创建一个Java类，以存储电影的名称及其播放的次数。</p><p><code lang=\"java\">public class MoviePlayCount {\n   public String name;\n   public int count;\n\n   public MoviePlayCount aggregate(String name) {\n       this.name = name;\n       this.count++;\n\n       return this;\n   }\n\n   @Override\n   public String toString() {\n       return \"MoviePlayCount [count=\" + count + \", name=\" + name + \"]\";\n   }\n\n}\n</code></p><p></p><p>这是一个计数器类，它依然需要两样东西：</p><p></p><p>我们需要有一个地方存储这个类的实例，确保每次触发事件的时候，它不会被重置。每当_playtimemovies_主题中有事件触发时，调用aggregate方法的逻辑。</p><p></p><p>关于第一个问题，我们需要使用<a href=\"https://kafka.apache.org/28/javadoc/org/apache/kafka/streams/state/KeyValueBytesStoreSupplier.html\">KeyValueBytesStoreSupplier</a>\"接口。</p><p></p><p><code lang=\"java\">public static final String COUNT_MOVIE_STORE = \"countMovieStore\";\n\nKeyValueBytesStoreSupplier storeSupplier = Stores.persistentKeyValueStore(COUNT_MOVIE_STORE);\n</code></p><p></p><p>对于第二个问题，Kafka Streams有一个用来聚合结果的aggregate方法。</p><p></p><p>在我们的用例中，也就是每部电影播放时长超过10分钟的次数。</p><p></p><p><code lang=\"java\">// MoviePlayCount可以被序列化和反序列化\nObjectMapperSerde moviePlayCountSerder = new ObjectMapperSerde&lt;&gt;(MoviePlayCount.class);\n\n// 这是之前的连接操作，其中键是电影id，值是电影\n.join(moviesTable, (movieId, moviePlayedId) -&gt; movieId, (moviePlayed, movie) -&gt; movie)\n// 根据键对事件进行分组，在本例中，也就是电影的id\n.groupByKey(Grouped.with(Serdes.Integer(), movieSerder))\n // 聚合方法，如果MoviePlayCount已经创建的话，获取该对象（如果尚未创建的话，会创建该实例）并调用其aggregate方法，以对观看次数进行递增\n .aggregate(MoviePlayCount::new,\n             (movieId, movie, moviePlayCounter) -&gt; moviePlayCounter.aggregate(movie.name),\n              Materialized. as(storeSupplier)\n                  .withKeySerde(Serdes.Integer())\n                  .withValueSerde(moviePlayCountSerder)\n             )\n</code></p><p></p><p>重启应用，在控制台上将会展示电影播放的次数。</p><p></p><p>提示：要重启应用，只需在终端输入“s”，应用将会自动重启。</p><p></p><p>应用重启之后，控制台将会展示每部电影的状态。</p><p></p><p><code lang=\"java\">[KTABLE-TOSTREAM-0000000011]: 4, MoviePlayCount [count=13, name=Cruella]\n[KTABLE-TOSTREAM-0000000011]: 3, MoviePlayCount [count=11, name=Encanto]\n[KTABLE-TOSTREAM-0000000011]: 5, MoviePlayCount [count=14, name=Sing 2]\n[KTABLE-TOSTREAM-0000000011]: 2, MoviePlayCount [count=15, name=Star Trek: First Contact]\n[KTABLE-TOSTREAM-0000000011]: 1, MoviePlayCount [count=16, name=The Hobbit]\n[KTABLE-TOSTREAM-0000000011]: 2, MoviePlayCount [count=16, name=Star Trek: First Contact]\n[KTABLE-TOSTREAM-0000000011]: 3, MoviePlayCount [count=12, name=Encanto]\n[KTABLE-TOSTREAM-0000000011]: 2, MoviePlayCount [count=17, name=Star Trek: First Contact]\n[KTABLE-TOSTREAM-0000000011]: 5, MoviePlayCount [count=15, name=Sing 2]\n[KTABLE-TOSTREAM-0000000011]: 4, MoviePlayCount [count=14, name=Cruella]\n[KTABLE-TOSTREAM-0000000011]: 1, MoviePlayCount [count=17, name=The Hobbit]\n[KTABLE-TOSTREAM-0000000011]: 4, MoviePlayCount [count=15, name=Cruella]\n[KTABLE-TOSTREAM-0000000011]: 4, MoviePlayCount [count=16, name=Cruella]\n</code></p><p></p><p>交互式查询</p><p></p><p>因为我们将_sink_处理器设置成了System.out 流，所以聚合结果会流向控制台。</p><p></p><p><code lang=\"text\">.toStream()\n.print(Printed.toSysOut());\n</code></p><p></p><p>但是，我们也可以将结果流发往一个Kafka主题：</p><p></p><p><code lang=\"text\">.to(\"counter_movies\",                      Produced.with(Serdes.Integer(), moviePlayCountSerder)\n);\n</code></p><p></p><p>但是，如果我们感兴趣的不是每次对新事件的反应，而只是想查询特定的电影此时播放的次数，那又该怎么办呢？</p><p></p><p>Kafka Streams的交互式查询(interactive query)允许我们直接查询底层存储，以获取给定键相关的值。</p><p></p><p>首先，我们创建一个名为MoviePlayCountData的类来存储查询结果。按照这种方式，我们可以解耦Kafka Streams使用的类与应用中其他部分所使用的类。</p><p></p><p><code lang=\"java\">public class MoviePlayCountData {\n\n   private String name;\n   private int count;\n\n   public MoviePlayCountData(String name, int count) {\n       this.name = name;\n       this.count = count;\n   }\n\n   public int getCount() {\n       return count;\n   }\n\n   public String getName() {\n       return name;\n   }\n\n}\n</code></p><p></p><p>现在，创建名为InteractiveQueries的类来实现对状态存储（KeyValueBytesStoreSupplier）的访问并根据电影的id查询它被播放的次数。</p><p></p><p><code lang=\"java\">import javax.enterprise.context.ApplicationScoped;\nimport javax.inject.Inject;\n\nimport org.apache.kafka.streams.KafkaStreams;\nimport org.apache.kafka.streams.errors.InvalidStateStoreException;\nimport org.apache.kafka.streams.state.QueryableStoreTypes;\nimport org.apache.kafka.streams.state.ReadOnlyKeyValueStore;\n\nimport static org.apache.kafka.streams.StoreQueryParameters.fromNameAndType;\n\nimport java.util.Optional;\n\n@ApplicationScoped\npublic class InteractiveQueries {\n\n   @Inject\n   KafkaStreams streams;\n\n   public  getMoviePlayCountData(int id) {\n       // 获取状态存储并根据电影id获取播放次数\n       MoviePlayCount moviePlayCount = getMoviesPlayCount().get(id);\n       // 如果有结果的话\n       if (moviePlayCount != null) {\n           // 将结果包装到MoviePlayCountData中\n           return Optional.of(new MoviePlayCountData(moviePlayCount.name, moviePlayCount.count));\n       } else {\n           return Optional.empty();\n       }\n   }\n\n   // 获取状态存储\n   private ReadOnlyKeyValueStore getMoviesPlayCount() {\n       while (true) {\n           try {\n               return streams.store(fromNameAndType(TopologyProducer.COUNT_MOVIE_STORE, QueryableStoreTypes.keyValueStore()));\n           } catch (InvalidStateStoreException e) {\n               // 忽略之，此时存储尚未就绪\n           }\n       }\n   }\n\n}\n</code></p><p></p><p>现在，我们可以添加一个简单的REST端点来运行该查询。</p><p><code lang=\"java\">import java.util.Optional;\n\nimport javax.inject.Inject;\nimport javax.ws.rs.GET;\nimport javax.ws.rs.Path;\nimport javax.ws.rs.PathParam;\nimport javax.ws.rs.core.Response;\nimport javax.ws.rs.core.Response.Status;\n\n@Path(\"/movie\")\npublic class MovieCountResource {\n\n   // 注入前文的类进行查询\n   @Inject\n   InteractiveQueries interactiveQueries;\n\n   @GET\n   @Path(\"/data/{id}\")\n   public Response movieCountData(@PathParam(\"id\") int id) {\n       Optional moviePlayCountData = interactiveQueries.getMoviePlayCountData(id);\n\n       // 根据结果判定返回值还是404\n       if (moviePlayCountData.isPresent()) {\n           return Response.ok(moviePlayCountData.get()).build();\n       } else {\n           return Response.status(Status.NOT_FOUND.getStatusCode(),\n                   \"No data found for movie \" + id).build();\n       }\n\n   }\n}\n</code></p><p></p><p>Kafka Stream实现的模式如下图所示：</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/quarkus-with-kafka-streams/en/resources/1topology-1656674518432.jpeg\" /></p><p></p><h3>扩展</h3><p></p><p>Kafka Streams应用可以进行扩展，所以流会分布到多个实例中。在这种情况下，每个实例都包含聚合结果的一个子集，所以要想获得总的聚合结果，我们需要通过将REST API重定向到另外的实例来获取其他实例的数据。</p><p></p><p>Kafka Streams提供了一个<a href=\"https://kafka.apache.org/28/javadoc/org/apache/kafka/streams/KafkaStreams.html#allMetadataForStore(java.lang.String)\">API</a>\"，可以知道要请求的数据是在本地Kafka Streams存储中还是在其他的主机中。</p><p></p><p>虽然这个过程并不复杂，但已经超出了本文的讨论范围。</p><p></p><h2>结论</h2><p></p><p>到目前为止，我们已经看到，将Quarkus应用连接到Apache Kafka并生产和消费主题中的消息/事件是很容易的。此外，还看到Kafka Streams让我们不仅可以消费Kafka中消息，还能够实时处理它们，进行转换、过滤等操作，例如以同步的方式消费结果数据。 这是一项强大的技术，当需要处理的数据不断变化时，它可以轻松扩展，提供实时的体验。</p><p></p><p>但是，我们还没有解决该架构的最后一个问题。通常情况下，数据并不是存储在一个地方。电影信息可能存储在关系型数据库中，而电影的播放信息则存储在一个Kafka主题中。那么，该如何保持这两个地方的信息更新，以便Kafka Streams能正确地连接数据呢？</p><p></p><p>这里有一个缺失的部分，名为Debezium的项目可以帮助我们解决这个问题。我们将用一整篇文章来介绍Debezium和Quarkus，敬请持续关注。</p><p></p><p>作者简介：</p><p>Alex Soto是红帽公司的开发者体验总监。他对Java领域、软件自动化充满热情，他相信开源软件模式。Soto是Manning的《Testing Java Microservices》和O’Reilly的《Quarkus Cookbook》两本书的共同作者，他还是多个开源项目的贡献者。自 2017 年以来，他一直是Java Champion，是国际演讲者和Salle URL 大学的教师。你可以在 Twitter 上关注他（<a href=\"https://twitter.com/alexsotob\">Alex Soto </a>\"），随时了解 Kubernetes 和 Java 领域的动态。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/quarkus-with-kafka-streams/\">Kafka Streams and Quarkus: Real-Time Processing Events</a>\"</p><p></p><p>相关阅读：</p><p>本系列第一部分：<a href=\"https://www.infoq.cn/article/cFpvXRLmZzJBGbzAeFu5\">使用 Apache Kafka 实现 Quarkus 的反应式消息</a>\"</p>",
    "publish_time": "2022-08-25 11:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "4年后，苹果汽车前工程师张小浪认罪，小鹏汽车回应：与案件无任何关联",
    "url": "https://www.infoq.cn/article/Tka0o4X29AGFhPX6F2eg",
    "summary": "<p>在跳槽小鹏前窃取苹果汽车商业机密的张小浪正式认罪，小鹏汽车回应：与案件无任何关联。</p><p></p><h2>前苹果员工张小浪正式认罪</h2><p></p><p></p><p>8月22日，美国联邦法院提交的一份刑事起诉书显示，美国有关部门指控一名苹果前雇员窃取商业机密，称此人将一份与自动驾驶汽车有关的商业机密文件下载到了个人笔记本电脑，随后试图逃离美国。</p><p></p><p>起诉书称，这名苹果前员工张小浪(Xiaolang Zhang)透露了其为一家中国自动驾驶汽车初创公司工作的意图，其在下载了苹果自动驾驶汽车电路板的计划后，在最后一刻预订了飞往中国的航班。2018年7月，该员工在圣何塞机场通过安检后被警方逮捕。</p><p></p><p>当时，苹果在一份声明中表示:“苹果非常重视保密和保护我们的知识产权。”“我们正在与有关部门就此事进行合作，并将尽一切可能确保此人和任何其他涉案人员为自己的行为负责。”</p><p></p><p>张最初对这些指控不认罪。如今，在持续了4年后，该案迎来最新进展，这名苹果前雇员于8月22日在圣何塞的联邦法院认罪。他已与检察官达成认罪协议，并将认罪改为有罪。</p><p></p><p><a href=\"https://storage.courtlistener.com/recap/gov.uscourts.cand.329276/gov.uscourts.cand.329276.72.0.pdf\">根据本周一提交的法庭文件，</a>\"张小浪与美国政府的认罪协议已经盖章并密封。在承认犯有盗窃商业机密的重罪后，张将面临长达 10 年的监禁和 25 万美元的罚款。据悉，张的律师证实了认罪协议，但拒绝进一步置评。该案件定于今年 11 月宣判。</p><p></p><p>张小浪被指控下载了有关苹果公司汽车项目的内部文件。具体来说，这是一份 25 页的文件，其中包括自动驾驶汽车电路板的工程原理图。张小浪还被指控使用描述苹果原型和原型要求的参考手册和 PDF。</p><p></p><p>根据联邦调查局和美国检察官办公室的收费文件，张小浪自 2015 年以来一直在苹果公司工作，其最后一份职务是担任苹果自动驾驶汽车团队的硬件工程师。</p><p></p><p>这些指控让人们窥见了苹果公司甚至多年后仍然不经常承认的秘密的一面：其部门正在开发自动驾驶电动汽车。</p><p></p><p>在 2018 年的指控文件中，一名 FBI 特工表示，该公司有大约 5,000 名“被披露”的员工，这意味着他们了解该项目，还有 2,700 名“核心员工”可以访问项目材料和数据库。</p><p></p><p>一份投诉称，苹果使用内部软件来跟踪哪些员工在哪些项目上被披露，并被要求参加面对面的保密培训。张小浪在苹果公司自动驾驶汽车项目的计算团队工作，该团队为传感器设计和测试电路板。电路设计的原理图被认为是电子行业最有价值的商业机密之一。</p><p></p><p>苹果首先怀疑张小浪在休陪产假并前往中国后窃取了商业机密。根据 2018 年的投诉，当他回到公司时，他递交了辞呈，说他想回到中国。苹果的一项调查发现，张小浪从公司数据库中下载了文件和信息。苹果闭路摄像头甚至拍到张小浪进实验室并拆除硬件 —— 后来被确定为电路板和 Linux 服务器。</p><p></p><p>当时张告诉苹果，他计划为中国的电动汽车公司 Xmotors（小鹏） 工作。</p><p></p><p>8月23日，张小浪在2018年离开苹果后加入的小鹏汽车在其新浪微博上发布了一则声明回应此事。小鹏汽车表示：</p><p></p><p></p><blockquote>我们今日从媒体上获悉前苹果员工张小浪涉嫌窃取苹果商业秘密案件的最新进展。案件至今已经四年多，小鹏汽车并不了解案件的具体情况，也未介入美国司法机关对案件的后续调查，我们与苹果公司之间也没有相关的争议，与该案件也无任何关联。小鹏汽车严格遵守相关法律，高度重视知识产权保护。小鹏汽车是中国自动辅助驾驶的领军企业，会继续坚持全栈自研的路线。感谢各位对事实的理解和支持。</blockquote><p></p><p></p><p>据凤凰科技报道，美国格知律师事务所合伙人、知名律师叶俊，知名 IT 与知识产权律师赵占领律师均认为，没有任何证据能证明，张小浪的窃密行为受小鹏汽车指示，或相关机密、技术被小鹏汽车使用。赵占领认为，从目前的信息来看，此案的审理过程中，苹果与检方均未对小鹏提起诉讼或进行调查，也表明此案件实际是苹果和离职华裔员工个人的之间的纠纷，和小鹏公司无关。苹果保护自己知识产权，张小浪只要有被苹果认定的不良行为，就会被调查，与他去哪工作无关。</p><p></p><h2>事件回溯</h2><p></p><p></p><p>我们再来回顾下整个事件的来龙去脉。</p><p></p><p>已经公开的资料显示，涉案人员张某，本科毕业于东南大学，后在英属哥伦比亚大学获得电子与电脑工程学的硕士学位。</p><p></p><p>张某 2015 年 12 月进入苹果公司工作，参与苹果无人驾驶汽车 Project Titan 的项目研发，主要负责设计和测试用来分析传感器数据的线路板。</p><p></p><p>因为工作性质的原因，张某获得了苹果公司“加密安全数据库”的广泛使用权，拥有许多苹果公司无人驾驶技术相关加密信息及专利的访问权。据了解，张某在被苹果聘用时，签署了一份知识产权协议，并参加了苹果组织的强制性保密培训。</p><p></p><p>2018年 4 月，在以休产假为由回到中国之后，张某告知苹果，自己准备离职，并加入位于广州的专注于国产无人车的研究的初创公司 XMotors（小鹏汽车）。</p><p></p><p>据外媒报导，法院的相关文件显示了一些细节：提出离职后，张某的上级对他在公司例会上所表现出的刻意回避产生了怀疑，在管理层的要求下，苹果新成立的产品安全团队（Product Security Team）对张某展开了调查，翻看了他离职时还给公司的 2 部工作用 iPhone 和 1 台笔记本电脑。</p><p></p><p>苹果公司发现，就在张某离职之前，他在公司内部网上的活动，与他前两年工作时相比“呈指数增长”。</p><p></p><p>法院文件显示，那段时间张某在网上做的最多的两件事，就是批量搜索，以及从加密数据库中下载大量信息。</p><p></p><p>苹果产品安全团队找张某进行了面谈，面对铁证，他最终承认自己在休产假时从苹果实验室里带走了一些网上的数据资料，以及包括一个 Linux 服务器和几个线路板在内的硬件设备。他还承认使用 AirDrop 把下载下来的资料数据，传到了妻子的笔记本电脑里。</p><p></p><p>FBI 通过调查发现，张某传到妻子电脑里的资料，60% 为高级别的加密信息，涉及到了人工智能技术的研发、测试和调试等各个阶段。</p><p></p><p>当时案发后，小鹏汽车2018年发布的声明显示，张某在 5 月初入职当天签署了知识产权合规文件，没有记录显示他向小鹏汽车上报任何敏感和违规的情况。当公司在 6 月 27 日获悉美国当地相关部门对张某的调查时，已按照规定封存了张某的电脑和办公用品，并将继续积极配合关于此事的相关调查。</p><p></p><h2>自动驾驶车企频发员工盗窃商业机密案</h2><p></p><p></p><p>近几年，自动驾驶车企频频发生内部员工盗窃公司商业机密案件。</p><p></p><p>值得注意的是，小鹏汽车已卷入多起华人工程师窃密案。在该案之外，2019 年 1 月，苹果前美籍华裔硬件工程师陈继忠 (Jizhong Chen) 因涉嫌窃取苹果电动汽车部门商业机密被起诉。苹果发现陈继忠已向一家与苹果在无人自动驾驶车项目开发具有竞争关系的中国公司投了简历，疑似是小鹏汽车，被小鹏汽车否认。目前，陈没有认罪，其案件由与张相同的律师代理。他的法庭听证会定于今年 8 月 29 日举行。</p><p></p><p>特斯拉也曾起诉过小鹏汽车工程师窃取商业机密。2019 年 7月11日，据外媒<a href=\"https://www.theverge.com/2019/7/10/20689468/tesla-autopilot-trade-secret-theft-guangzhi-cao-xpeng-xiaopeng-motors-lawsuit-filing\">The  Verge</a>\"报道，前特斯拉员工曹光植在本周新提交的法庭文件中承认，他曾在2018年底将包含Autopilot源代码的zip文件上传到他个人的iCloud账户。但同时，曹光植否认窃取了特斯拉的敏感信息，他的律师称，在从特斯拉离职之前，曹光植已经认真的删除了与特斯拉相关的资料。</p><p></p><p>据悉，曹光植此前是特斯拉负责高级驾驶辅助系统的40名雇员之一，他有权直接访问AUTOPILOT源代码。2019年3月，特斯拉向已经加入小鹏汽车担任“感知负责人”的曹光植发起了诉讼，特斯拉指控曹光植自2018年年底开始陆续向他的个人iCloud账户上传“特斯拉自动驾驶仪相关源代码的完整副本”，他压缩并移动了超过30万个与Autopilot相关的文件和目录。</p><p></p><p>特斯拉这几年不是在打官司就是在打官司的路上，公司内部员工泄密案高发。</p><p></p><p>2020年12月，特斯拉与其前工艺技术人员Martin Tripp达成了和解，后者承认泄露了机密信息。双方的官司打了2年多时间，起因是Martin Tripp指责特斯拉在生产Model 3时浪费了大量原材料。诉讼中，特斯拉认为，Tripp入侵了电动汽车公司的系统并将“千兆字节”的数据传输给了第三方。</p><p></p><p>2020年7月，特斯拉对四名前员工发起了诉讼，特斯拉发现，这四名前员工涉嫌将特斯拉的机密信息携带到了电动汽车初创公司Rivian。而且，Rivian其实在“故意鼓励”这种行为，特斯拉将对其恶意行为寻求惩罚性赔偿。诉讼中，特斯拉表示已有两名被告承认接受机密信息，其中一位曾担任特斯拉的人事高级经理，在她接受Rivian的offer的第二天，她就从特斯拉的网络中至少获取了十份机密和专有文件”，包括候选人名单及详细的内部书面记录等。</p><p></p><p>2019年初，特斯拉还对无人驾驶初创公司Zoox 提起了诉讼，指控4名曾在特斯拉工作过的Zoox员工将有关特斯拉制造业的专有信息和商业机密带给了Zoox，并帮助这家公司跳过了过去几年开发和运行自己的仓储、物流和库存控制业务所需的工作。在经过了一年多的诉讼后，该案件于2020年4月迎来关键进展，双方达成和解。Zoox承认其四名员工从其前任雇主特斯拉那里获取了有关运输、接收和仓库程序的机密文件。Zoox承诺将向特斯拉支付一笔未公开的款项赔偿。</p><p></p><p><=\"\" p=\"\"></p><p></p><p>title=\"微软认为AutoML不够用，智能系统才是未来！\"</p><p></p><p>link=\"\"&gt;</p><p></p><p></p><p></p><p><img src=\"https://static.geekbang.org/infoq/5c6947ecc1649.png\" /></p><p></p>",
    "publish_time": "2022-08-25 14:11:39",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "SaaS 创业者的世界里没有风口，只有客户需求",
    "url": "https://www.infoq.cn/article/mGWsrgj8sWVCHQjqe62W",
    "summary": "<p></p><blockquote>编者按：在企业数字化转型升级的浪潮下，近几年，国内 SaaS 赛道显得格外火热。对 SaaS 创业者而言，风口真的来了吗？极客邦科技创始人兼 CEO 霍太稳认为，SaaS 创业者的世界里没有风口，只有用户和客户需求。一个创业者、企业家最重要的就是要敏锐地去发现问题，然后去执着地解决问题。&nbsp;对于那些新入局的 SaaS 创业者，微梦传媒/爱设计 CEO 赵充认为必须要关注四件事：找钱、找人、找方向、修炼心性。SaaS 创业前期需要非常多的粮草，先投入产品研究，再做市场营销，之后才能逐步产生收入；早期要考虑的竞争维度比较多，不仅要找内部团队的人，也要找外部的人；to B 和 to C 的业务模型不同，需要的人也不太一样，创业者需要提前考虑好方向；SaaS 业务从产品调研、上线再到商业化整个周期较长，创业者需要有内心，磨炼心性。</blockquote><p></p><p>&nbsp;</p><p>本期《超级连麦》，我们邀请到了微梦传媒/爱设计 CEO 赵充，和极客邦科技创始人兼 CEO 霍太稳（Kevin），InfoQ 极客传媒生态总监张昂，共话内容 SaaS 赛道的实践与认知。内容有删减，感兴趣的同学可进入“霍太稳视频号”观看直播回放。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/e2/10/e283cba6d9aefde07bbe2206b12ed410.jpg\" /></p><p></p><h4>为什么投身内容创业？当前这条赛道还是风口吗？</h4><p></p><p>&nbsp;</p><p>赵充：Kevin 算是标准的内容创业，我们还不算标准的内容创业，我们属于内容科技。我是从 2011 年开始创业的，之前在新浪负责自媒体商业化，也正是因为这段经历的影响，所以我的第一个创业项目“<a href=\"http://www.microdreams.com/\">微梦传媒</a>\"”主营业务就是新媒体营销。微梦的商业模式说起来也比较简单，底层就是新媒体数据能力，基于新媒体的数据去做双边市场。一侧是微博、微信、抖音、小红书、B 站等社交媒体的内容创作者，另一侧就是服务于大型的广告主如阿里、腾讯。主要做的事情集中在新媒体营销/传播层面，主要包含数据、内容、媒介三个版块。</p><p>&nbsp;</p><p>后来，我们做到一定规模，就开始思考内容传播的上游，内容生产侧还有什么事情可以做。我们服务的了几百个大型企业，他们提出了对内容生产的需求，包括新媒体侧内容高效生产的需求。于是我们从 2017 年开始立项，并孵化了第一个产品——<a href=\"https://www.365editor.com/\">365 编辑器</a>\"。很快就做到了几百万用户，以新媒体小编的用户人群为主，当然这是个比较细分的赛道。不过就是从这开始，我们接触到了一些在线设计的工具公司有流量合作的需求，因为用户画像是高度匹配的，于是我们就自己孵化了<a href=\"https://www.isheji.com/\">爱设计</a>\"isheji.com，开始去做在线设计工具。一开始，爱设计是 to C 的，跟 365 编辑器的商业模式一样，后来开始往 B 端走。视觉中国战投了我们，帮我们补齐上游版权侧的资源，同时我们也开始服务 B 端，后来又增加了内容中台和创意众包的业务，帮企业提供创意的 SaaS，并做内容生产。</p><p>&nbsp;</p><p>霍太稳：赵充把他的整个业务介绍了一下。赵充是一个典型的年轻创业者，也是一个典型的连续创业者。他的公司很早就已经在新三板上市了，在上市的过程中又去持续开拓一些新的业务，而且业务与业务之间有非常强烈的关联。原来可能是做像广告类的一些业务，现在又去做内容科技，赶上 SaaS 这样一个浪潮。我最近正好在清华经管 EMBA 上课，老师说了一个理念，他说对一个创业者、企业家来讲，最重要的就是要敏锐地去发现问题，然后去执着地解决问题，赵充就是这样一个非常典型的创业者和企业家。</p><p>&nbsp;</p><p>我简单说一下极客邦科技，我是认为“风口”固然重要，但最主要的还是来自用户和客户的需求。极客邦科技存在了 15 年，在 15 年前，我们做 InfoQ 的时候，就认为中国的程序员这类数字人才需要去看一些来自国外最新的技术资讯，很多内容在国内是没有的，我就组织很多志愿者去把 InfoQ 英文站的内容翻译成中文，再把其他国际上非常优秀的技术社区里的内容翻译过来。我们在 2007 年开始做 InfoQ，当时整个 InfoQ 中国团队没有研发的力量，我们是和国际团队一起用罗马尼亚的研发团队。</p><p>&nbsp;</p><p>2017 年，我们开始做极客时间，开始正式组建研发团队，做了极客时间 APP，并邀请一些专家到我们 APP 平台上去创作内容。极客时间算是一个内容科技方向的创业，相当于把内容和科技正式连在一起了。一开始，极客时间 APP 是一个面向个人的知识服务平台，2019 年，我们开始做极客时间企业版。因为我认为，做培训，尤其是做数字人才的培训，刚需还是在企业里，企业希望他的员工能够去更好地掌握一些技能，在企业的发展过程中发挥作用。</p><p></p><h4>创业过程中，踩过哪些坑？</h4><p></p><p>&nbsp;</p><p>赵充：爱设计早期踩了不少坑，也花了不少钱。前期我们做 365 编辑器，它的盈利模型很简单，就是在搜索市场上去买量，买量之后就看用户充值的收入和ROI。我们当时认为如果上线爱设计，它的受众面比 365 编辑器的受众面要大很多。因为像 365 编辑器潜在的用户可能就一两千万，主要是公众号企业或者自媒体在用。但在国内，设计的受众可能得大几千万，甚至是一个亿的市场规模，如果我们再上线一个同样的产品，用同样的模型去跑就是轻而易举，但是事实上却踩了坑。</p><p>&nbsp;</p><p>因为爱设计的变现模型的ROI没有 365 编辑器那么高，365 编辑器有搜微信公众号编辑器或者搜微信编辑器进来的用户，有很高的匹配率。但是像在线设计、设计这些关键词比较泛，它的匹配率要低很多。盈利模型大概是一个月投放一百万，可能回来很少的比例；下个月再投放一百万，当月回收一部分收入，同时上个月再滚下来一部分收入。但是整个回收周期拉得很长，可能要八到十个月，甚至更长的时间才能收回来钱。如果完全按照 to C 的作战方式去打，可能几千万资金要打出去才能看看有没有可能回来钱。这是我们当时踩过的一个坑。</p><p>&nbsp;</p><p>但是后来我们也在从坑里面往外爬，我们果断地把业务模型调整成了 to B 这样的方式，先重点去做 to B。我们毕竟做了十几年的 to B，还是有些资源的积累，包括也拉了视觉中国这样的战投方进来一起去做 to B 的市场。</p><p>&nbsp;</p><p>霍太稳：我们也踩过一些坑，比如，在微信公众号刚出来的时候，在 2013 年，我就马上注册了 InfoQ 的公众号，但是迟迟没有动，为什么？因为我当时的思维就是我们的客户、用户是在 InfoQ 网站上，我如果去做 InfoQ 的公众号，会不会让 InfoQ 网站的资源受限？直到两年之后，公众号已经风生水起了，我们才开始去做。但是在这两年的时间里，微信公众号的红利基本上消耗得差不多了，在这种情况下，相当于别人已经跑得比较靠前了，你再去追，难度就会非常大。当然，现在 InfoQ 的微信公众号已经拥有超过百万的粉丝，我们花了很大的代价最终才赶上来。</p><p>&nbsp;</p><p>这个坑给我的启示就是：对于一些新生的事物，你要保持非常敏锐的观察，而且要实时和它保持同步，也看一下周围的同学是怎么去做的，这时候千万不要静止不动，你可以做一些小范围的尝试，就像 MVP 一样，如果说一旦有效果，马上进行大规模跟进。这样，就可以让你在红利期做很多事半功倍的事情。</p><p></p><h4>SaaS 内容平台在 to B、to C 两个方向分别要有哪些运营策略？</h4><p></p><p>&nbsp;</p><p>赵充：我做这些决策主要还是基于一些市场分析。从市场上来讲，短期来看，如果只做国内的 C 端市场，获客成本不低，留存也不高，比较难变现。但如果做 B 端市场就会好很多，客单价很高，续费的稳定性也比较高。从我们自身来讲，我们毕竟做了十几年的 B 端，也积累了很多方法。</p><p>&nbsp;</p><p>具体来说，C 端用户主要在意两件事，一是产品体验够不够好，二是内容版权的丰富度跟品质是不是足够高，当你把这两个做好之后，就可以开始通过流量助推了。未来我们会选择在海外主打 C 端市场，一次性把产品的内容做好了之后，去打全球市场，这样就摊薄了成本。</p><p>&nbsp;</p><p>B 端用户就是企业，它的需求层次会更多，要看的层面也会更多。比如，你的版权是不是有保证，工具是不是好用，协作管理是不是足够好，有没有分发能力，有没有内容生产能力，等等。在 B 端打市场，我们基本上是 SLG（Sales-led Growth，销售驱动增长）为主，MLG（Marketing-led Growth，营销驱动增长）为辅，带一点点 PLG（Product-led Growth，产品驱动增长）。</p><p>&nbsp;</p><p>霍太稳：C 端和 B 端还是有非常大的区别。比如，C 端对价格非常敏感，我们极客时间 APP 上的很多专栏，有的定价 129 元，有的定价 99 元，有的定价 69 元。如果某天 129 元的专栏降价至 99 元，就会新增很多销量。但是对于 B 端用户来说，价格不是他们首要考虑的因素，他们最关注的是你的平台、内容和服务，比如极客时间企业版能不能帮助员工有效地提升数字化能力。他们使用你的平台，是为员工节省了时间，提升了能力，还是说浪费了时间，并且没有提升能力。这是非常大的区别。</p><p>&nbsp;</p><p>我们在设计产品的过程中，对于 C 端来讲，需要考虑到这部分人对价格是相对比较敏感的；对于 B 端来讲，需要考虑你能不能对企业有价值，让企业觉得用你的产品，员工的收获和体验都是非常好的。</p><p>&nbsp;</p><p>另外，C 端和 B 端还有一个区别在于，C 端对产品体验的要求非常高，每个 C 端用户的手机上装了好多个 APP，他们已经养成各种各样的习惯。如果你的产品体验不好，或者性能不好，他可能马上就卸载掉，甚至看都不看，这是 C 端的特点。但是对于 B 端，做产品设计时主要考虑的是实用性和专业性，只要产品功能是符合企业需求的，员工都是愿意去用的。</p><p></p><h4>如何看待“内容为王”与“技术为王”？如何更好地以技术赋能内容，以及如何赋能客户和用户？</h4><p></p><p>&nbsp;</p><p>赵充：我们给用户/客户交付的是结果，对于我们的用户/客户来说，无论他们是做 H5、PPT，还是做平面设计，希望通过我们的工具解决内容的问题，而技术是一个比较好的完成结果的路径。所以内容是结果，我们只是希望用效率更高的方式，也就是技术，来去解决内容的问题，这是我们对这个问题的思考。我们的六七成业务是解决内容的问题，三四成是解决技术的问题。爱设计是一个内容中台，它上面是各种形态的内容，无论是做众包、版权，还是做编辑器。</p><p>&nbsp;</p><p>我们有三种不同的解题思路，满足不同用户的需求。</p><p>&nbsp;</p><p>第一个解决思路是针对 C 端，我们提供一个底层的编辑器，包括平面、视频、H5、PPT等等这样的全家桶编辑器；同时我们还有各种各样的模板，我们在济南有一个内容中心，专门帮我们的用户做模板；我们也有创作者平台，希望调动更多的内容创作者生态来给爱设计提供资源，帮我们的用户高效地生产内容。无论是市场部的负责人、新媒体小编还是销售，能直接在我们这里找到素材物料并发出去。</p><p>&nbsp;</p><p>第二个解决思路是采用 AI 技术来做内容，主要服务于广告跟电商场景。比如一个比较大的电商平台每个季度要生产几万张、几十万张素材物料，尺寸有几百种，人工的效率比较低，我们平台能实现一个尺寸的素材物料，自动生成一百个不同尺寸的素材物料。</p><p>&nbsp;</p><p>第三个解决思路是用众包的方式帮企业解决内容生产的需求。一些大型企业，比如百度、腾讯等有很多营销的节点，需要做很多素材物料满足各个场景。我们做了一个内容创意的双边市场，汇聚了各种各样的内容供应商，给所有的供应商打上标签，我们知道它的价格、服务水准，然后去给客户做匹配。</p><p>&nbsp;</p><p>总结来说就是，我们有三个路径通过技术来解决内容生产：第一，我们提供模板跟编辑器，赋能他们自己来做内容生产；第二，满足广告跟电商场景的需求，用 AI 来帮他们做内容；第三，针对一些非标的需求，采用内容众包或者创意供给平台的方式来帮企业去解决内容的生产。</p><p></p><h4>Kevin&nbsp;在&nbsp;2020&nbsp;年的时候专门在极客时间上写过一门专栏<a href=\"https://time.geekbang.org/opencourse/intro/100060101\">《一个草根创业者的&nbsp;40&nbsp;岁人生复盘》</a>\"，2&nbsp;年后再来回看这些思考，是否有了新的变化？</h4><p></p><p>&nbsp;</p><p>霍太稳：这个专栏原来的名字叫《一个草根创业者的 40 岁人生复盘》，现在我给它改成《知行合一 职场成长手册》，我希望每年能够迭代一下手册，这样做最主要的原因就是那句话：一个人的成长就是，你看昨天的自己觉得够不够傻，是不是很多事情都做得不够好。我在 2 年前写下这个专栏，里面的很多概念和实践是需要去更新的。举个例子，我之前在专栏里提到一个 CEO 主要做的事情就是找人找钱找方向，谈梦谈情谈共赢。现在回过头来看，我对这几件事情的理解已经完全不一样。</p><p>&nbsp;</p><p>先来看找人。过去我觉得找人就是把人招过来，只要有钱，就可以找到你想找的人。但现在我发现，你得找到对你公司非常合适的人，而且这个人空降到你的公司里，能非常好地去落地，融入进来，这才算是真正地找到了一个合适的人。而且找人是需要创始人、CEO 花很多时间去做的事情，如果找错了一个人，很有可能耽误了你岗位角色差不多一年的时间，一年的时间对一个创业公司来说是非常宝贵的。总的来说，找人永远是第一位的，这里的找人是指找到非常合适的人。</p><p>&nbsp;</p><p>再来看找钱。过去我对找钱的理解就是找到合适的投资人，请他过来投资我们就可以了，但是现在我对找钱有了更深刻的理解。找钱不仅仅包括和投资人沟通，还包括设计你的商业模式，盘一盘手里面有一些什么样的资源，哪些资源是可以通过交易去做增值。这也是一个 CEO、一个创始人应该花很多的时间去做的事情，设计你的商业模式，做底层的设计。</p><p>&nbsp;</p><p>最后看找方向。过去我觉得做视频号、公众号、知识付费就是找到一个合适的方向，现在我对这个事情也有了更多的理解，找方向不仅仅包括你的产品方向、业务的方向，还包括你对整个大趋势的理解，对整个行业的理解，还要花很多时间去看一看世界发生了什么样的变化。</p><p></p><h4>作为已经站在数字化浪潮中的创业者，对于那些新的入局者，有什么忠告或建议吗？</h4><p></p><p>&nbsp;</p><p>赵充：现在各行各业都在谈数字化，企业需要更加精细化、科学化地去做运营管理，这是个大的背景，也推动了整个 SaaS 行业的发展。SaaS 商业模式比较厉害的点在于，它能够有年度的、持续性的收入，如果产品跟服务足够好，用户就会持续订阅跟续费。产品跟客户之间的关系比较持续，对于企业自身来讲，经营结果可以预测，今年有一个亿收入，明年不会掉太多，不会像依赖几个大型客户的公司，业绩波动会比较大。这是 SaaS 行业比较吸引人的地方。</p><p>&nbsp;</p><p>说到需要注意的一些点就是，我们需要考虑的还是找钱、找人、找方向，再加一个修炼心性，这四点是比较重要的。</p><p>&nbsp;</p><p>第一，找钱。SaaS 创业前期还是需要非常多的粮草的，先投入产品研究，再做市场营销，之后才能逐步产生收入。而且第一年的收入也不一定能打得回来，它主要靠持续性的续费来实现盈利。这就要求大家一开始一定要把预算表做准，把控好现金流，很多 SaaS 企业失败的原因都是现金的问题。这个是大家需要考虑的第一个问题，备足粮草，要准备足够多的钱。</p><p>&nbsp;</p><p>第二，找人。除了内部团队找人之外，外部找人也比较重要，我们在早期的时候就拉了战略伙伴进来，一起“打群架”。早期要考虑的竞争维度是比较多的，比如你要做产品，要做内容，还要做市场等等，所以最开始我们就拉了 A 股最大的版权素材公司视觉中国做我们的战略合作伙伴，同时它还能拉既有的一两千客户，也能变成我们潜在的客户去做交叉销售。比较重要的就是早期的时候，拉一些人一起来做事情，在某些维度上让自己处于行业领先，这样我们就可以专注解决自己擅长的问题。</p><p>&nbsp;</p><p>第三，找方向。此前提到我们在 to B 还是 to C 方向上花了很多时间，整个的反馈速度还是比较慢的。to B 和 to C 背后的组织能力模型不太一样，需要的人基本上也是不太一样的，这个也是需要大家去考虑的。</p><p>&nbsp;</p><p>第四，修炼心性。做 SaaS 业务是比较需要有耐心的，需要磨炼心性。SaaS 业务从产品的调研，到产品上线，再到真正开始商业化，整个周期非常长，着急一点用都没有，需要耐心，比较适合长跑型的创业者。</p><p>&nbsp;</p><p>霍太稳：我认为需要想清楚自己做的这件事情到底能帮客户解决什么样的问题，然后围绕这一点去做。不一定要做非常宏大的产品，非常宏大的服务，然后通过非常宏大的志向去找到投资人，然后开始怎么样。我认为还是先从最具体的场景去做，到底我带着几个人做产品、做服务，我能够帮客户去解决一个什么样的问题，一旦我帮他解决了问题，我就让他的生产效率有了非常大的提升，也能够让老板满意，这是第一点。</p><p>&nbsp;</p><p>第二点也是在当前阶段需要特别注意的，因为现在整个经济环境并不是非常的理想，新入局的创业者手上的资源并不多，包括人的资源、钱的资源，在这种情况之下就要特别小心，你所花出去的每一笔钱，你所做的每一个投资，你所招的每一个人，你都要算清楚他能够给你带来什么样的价值。管理要精细再精细，在这上面把所有的帐都给计算清楚。如果你的投资在短期不能收回来，我觉得在经济环境并不是很好的情况下就不要去做了，还是务实一点比较好，先让你的整个业务以一个正循环的方式转起来，我认为是非常必要的。</p><p>&nbsp;</p><p>简单总结来讲，第一，不要想太多，先去帮助你的客户去解决他的痛点，哪怕是很小的一个点都可以，他一定会愿意付你钱。第二，你现在手里面的资源并不是非常多，一定要非常精细化地去使用，保证自己活得长久一点，等经济复苏的时候，你还在车上，还在牌桌上。</p><p></p><h4>嘉宾介绍</h4><p></p><p>&nbsp;</p><p>赵充，微梦传媒/爱设计 CEO。曾经就职于新浪，有多年互联网产品开发和运营的相关经验。2011 年创立微梦传媒并成功挂牌新三板。2018 年创立爱设计，2022 年 6 月，爱设计完成策源创投和亚杰基金领投的数千万元 A2 轮融资，致力于打造中国企业内容数字化转型的新基建。</p><p>&nbsp;</p><p>霍太稳，极客邦科技创始人兼 CEO，InfoQ 中国创始人，极客时间创始人，TGO 鲲鹏会发起人。2007 年创立 InfoQ 中国，2014 年创立极客邦科技，2015 年发起 TGO 鲲鹏会，2017 年创立在线职业教育学习品牌极客时间，2019 年开创极客时间企业版，拓展企业服务市场。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/6c/40/6c915f3910a1332179815d3a866c2240.png\" /></p><p></p>",
    "publish_time": "2022-08-25 14:14:21",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "图数据库赛道兴起，看NebulaGraph如何打造差异化！",
    "url": "https://www.infoq.cn/article/uEJiV4YRfHIPAZ9uF40t",
    "summary": "<p>5G、物联网、AI 等新兴技术的不断发展，不仅让数据量急剧攀升，同时也使得数据的关联变得复杂化，而传统的关系型数据库往往无法承接这些变化。相比之下，图数据库在处理关联关系上的性能则更具有优势，也能够深挖数据之间的关联性，释放数据的潜在价值。</p><p>&nbsp;</p><p>为了深入了解图数据库的发展趋势与落地情况，InfoQ 记者有幸在 <a href=\"https://archsummit.infoq.cn/2022/beijing/presentation/4310\">2022 ArchSummit全球架构师峰会北京站</a>\" 上，采访了 NebulaGraph CTO&nbsp;于新林老师。</p><p>&nbsp;</p><p>以下是视频采访的全部内容，为方便读者查看，视频下方也附上了文字内容。</p><p>&nbsp;</p><p></p><p></p><p>InfoQ：近年来，我们看到越来越多的公司开始进军图数据库领域，对于厂商自身而言，如何才能打出差异化？</p><p>&nbsp;</p><p>于新林：在考虑差异化之前，我们首先要考虑客户需要什么，我们解决了客户哪方面的问题，然后再考虑如何做好，给客户提供更大的价值。当我们在服务好客户的时候，差异化如何体现呢？</p><p>&nbsp;</p><p>目前来看，我们的图数据库产品 NebulaGraph 的几个关键词是：开源、分布式、OLTP+OLAP、计算存储分离、处理超大规模数据、高性能。对于杭州悦数科技有限公司来说，做好产品，服务好客户就是我们打出的差异化：NebulaGraph 稳定性好，原生分布式，并且可以支持大规模海量数据。</p><p>&nbsp;</p><p>另外，作为一家坚持开源的图数据库厂商，我们一直保持服务好用户的初心，给客户提供更优质的服务。在前期的 POC 阶段，我们可以跟客户一起理清他们的数据模型，帮助客户写一些数据上的语句，让他们更好地使用图数据库。上线以后，我们会快速地响应客户的问题以及持续地给客户提供升级、运维的一整套服务。</p><p>&nbsp;</p><p>InfoQ：对于企业而言，又该如何结合自身业务选择最适合自己的图数据库产品？或者说，选择一款图数据库需要从哪几个维度去考虑？</p><p>&nbsp;</p><p>于新林：我感觉企业要想选图数据库主要从以下几个方面出发：</p><p>&nbsp;</p><p>首先，要看业务的场景，如果你的业务是偏线上实时交易的，那就需要选择 OLTP 能力比较强的图数据库，如果你的场景是偏图计算和分析的，可能要选一款偏 OLAP 的，亦或者两种场景都需要，那就选择混合的；</p><p>&nbsp;</p><p>其次，要考虑图数据库的稳定性，如果不稳，其实业务都无法开展。另外就是性能因素，这款图数据库产品的并发情况、响应时间等等；此外，由于图数据库中有大量数据是从外部导入的，因此，也需要考虑海量数据的导入性能和时间是否满足业务需求。最后，当我们选择图数据库厂商时，也需要考虑服务持久化的问题。</p><p>&nbsp;</p><p>InfoQ：据 Gartner 预言，图数据库很快约占到数据库领域 10％市场。从您的观察来看，图技术的落地情况达到了怎样的阶段？</p><p>&nbsp;</p><p>于新林：图技术是一个快速发展的方向，是否占 10%我没法准确感受。我能感受到的是：起风了。从目前市场来看，客户对图相关接受度越来越高，购买、使用图数据库的客户越来越多，这基于两个方面：一方面得益于技术的成熟，另一方面是客户的认知和对图的需求逐渐攀升。图技术相关领域其实蛮广泛的，图计算、分析、存储、渲染、展示、图+AI 以及各种各样基于图的业务应用，如社交、防疫、供应链、知识图谱等。我们最近也发布了几个联合方案：金融反欺诈、智能投研平台、智能运维，通过这些方案，让我们能更好地配合合作伙伴的业务，推动生态的健康发展。</p><p>&nbsp;</p><p>InfoQ：与传统关系型数据库相比，图数据库虽然可以从海量数据中挖掘数据的关联，但据了解，目前市面上的图数据库产品还很难满足快速实时导入数据。能否请您介绍下，目前图数据还存在哪些局限性？</p><p>&nbsp;</p><p>于新林：从我们目前接触客户来看，客户对快速实时导入确实是刚需，我们这方面能力相对还好，目前感觉不是瓶颈。我现在一个基本的感受是：图技术，相对于关系型数据库来说属于新兴技术，可能对于很多国内用户来说对还比较陌生，但其实这项技术在海外已经盛行了几十年，包括NASA、ebay、airbnb在内的大小企业都在使用图数据库来解决通信、 互联网、电子商务、社交网络和物联网等场景下的数据问题。近几年，图数据技术在国内也逐渐开始火热，NebulaGraph 也逐渐被腾讯、美团、京东、360数科、微众银行、小红书、知乎、快手、BOSS直聘等许多知名企业采用。</p><p>&nbsp;</p><p>虽然现在国内图数据库行业还不够成熟，标准也不完全统一，但同时我们也欣喜地看到国内互联网大厂、以及像NebulaGraph 这样的专业厂商，正在努力构建一个成熟完善、用户友好的生态。相信假以时日，我们能够让更多用户低门槛地使用各种图探索工具，感受图算法的快捷高效、更生动地感受到“图”数据的直观性和处理关联数据的强大能力。</p><p>&nbsp;</p><p>InfoQ：面对行业的痛点问题，NebulaGraph 做了哪些迭代和优化？</p><p>&nbsp;</p><p>于新林：客户目前的一些痛点问题主要还是在稳定性、性能、大数据、高可用、实效性以及数据导入性能等。针对这些痛点，我们通过产品的一个个迭代和版本逐步解决。</p><p>&nbsp;</p><p>举例来讲，为了解决稳定性问题，我们加大了测试的投入，包括功能测试、长期稳定测试、极限压力测试、混沌测试等等；为了解决高可用问题，我们做了很多功能，包括快速扩缩容、数据 balance、备份恢复、集群间复制等等。通过一次次迭代和优化，能在最短时间内解决客户的痛点问题，也尽快建立起和客户之间的信任关系，客户会更放心的使用我们的产品。</p><p>&nbsp;</p><p>InfoQ：在 NebulaGraph 数据库支持下，已经解决了哪些企业的问题，能否分享几个成功的案例？</p><p>&nbsp;</p><p>于新林：在<a href=\"https://www.nebula-graph.com.cn/\">官网</a>\"上有很多这样的案例，这些都是客户贡献的案例说明，比较客观一些。我分享两个：我们有家客户是偏政府的，他们最大的特点就是数据量特别大，而且数据量在持续地增长，点在千亿级别、边在万亿级别，他们的数据需要定期导入。最大的诉求是分布式、支持海量数据、快速响应时间以及很高的导入速度。刚好我们的产品能比较好地满足他们的需求，所以两边能很快地配合进行 POC、验证、上线，现在已经持续稳定跑了很久。</p><p>&nbsp;</p><p>另一个是微众银行在数据血缘方案中，引入了 NebulaGraph 作为大数据平台的图数据基础。主要看中了快速导入大规模数据、低时延的实时计算，可以很好地帮助微众银行生成一份数据地图，以快速发现数据问题、定位和分析以及解决问题，帮助业务开展。</p><p>&nbsp;</p><p>InfoQ：在 2021 年 AS 的专访中，您提到了 NebulaGraph 接下来的三个计划，分别是 NebulaGraph 上云，加大对 AP 领域的投入，以及把图的计算和图的分析以 SaaS 化的服务形式搬上云。想了解下，目前的进展如何，是否有达到团队的预期？</p><p>&nbsp;</p><p>于新林：目前相关工作在持续开展，NebulaGraph 上云这部分是开展比较快的一部分。目前我们已经和多家云厂商在紧密的合作，包括 Azure、阿里云、AWS、Gcp、华为云等等。目前产品已经在部分云厂商上线了，国内在阿里云已经上线，大家可以免费试用。</p><p>&nbsp;</p><p>AP 领域也在有序推进，相对进展没有这么快，当前主要把 AP 和 TP 产品做了整合，主要解决了客户易用性问题，让客户更加方便地使用图数据库和图计算的能力。SaaS是我们未来要做的事，但目前还不是重点，现阶段我们还是会更关注底层数据库的性能和最佳用户体验。还是要集中优势兵力把当前这个产品打磨好，本身这些产品也是为将来 SaaS 服务的一个根基，可能会到明年左右开始发力 SaaS 服务。当然了，考虑到终端用户的实际使用需求，NebulaGraph 也正在与一些 ISV 和 SI 企业积极合作，这些生态伙伴中不乏有多年垂直领域行业经验的解决方案提供商，通过提供图数据库底座能力给到他们来实现面向用户的方案，便于终端用户部署落地。</p><p>&nbsp;</p><p>InfoQ：谢谢于老师接受采访，也期待 NebulaGraph 在接下来有更大的突破。</p>",
    "publish_time": "2022-08-25 14:42:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "“要什么DevOps，我们开发者根本不想做运维！”",
    "url": "https://www.infoq.cn/article/FfBlx8SYkV9hDBsgolqu",
    "summary": "<p>&nbsp;</p><p></p><blockquote>“谁构建、谁运行”的口号让开发者们倍感压力，但另一方面，运维团队的日子也不好过。那么，这场席卷全球的开发与运维融合浪潮会不会黯然退场？&nbsp;根据外媒记者Scott Carey的观察，众多开发者纷纷表示“苦<a href=\"https://www.infoq.cn/article/hyw1a1g3w9quyvds22ed\">DevOps</a>\"久矣”。我们将Carey记录的文章在不改变愿意的基础上进行了编译，以飨读者。本文谨代表作者个人观点，不代表InfoQ立场。面对争议问题，希望大家理智讨论。</blockquote><p></p><p>&nbsp;</p><p>&nbsp;</p><p>“在大多数情况下，开发人员并不想处理运维问题。”亚马逊云科技社区参与负责人、《DevOps for Dummies》作者<a href=\"https://twitter.com/editingemily/status/1509197581301080067\">Emily Freeman</a>\"在推特上坦言。</p><p>&nbsp;</p><p>一石激起千层浪。Freeman的观点引起了广泛共鸣，几百条抱有同样观点的开发人员纷纷留言回应。</p><p>&nbsp;</p><p>“我就是个开发者，我不想处理运维问题。”快餐公司 Chipotle 软件工程师 Scott Pantall直接表示。</p><p>&nbsp;</p><p>“我确实更喜欢回到只需要掌握特定编程技巧的时候，而不是现在这样成为一个万事通，因为多个责任分散了我太多精力。这两者都是全职工作，而我只能各自投入一半的精力。”开发者Mitchell Abbott&nbsp;说道。</p><p>&nbsp;</p><p>SUSE 开发人员布道师 Andrew Gracey 认为，开发人员和运维人员应该密切合作，同时各自扮演不同的角色，能够让团队成员相互理解的同理心才是DevOps的真正核心。</p><p>&nbsp;</p><p>“强迫开发者身兼太多任务，最终只会搬起石头砸自己的脚。不同场景对应着不同的技能组合。”Kubernetes存储技术提供商 Ondat 的产品负责人James Brown表示。</p><p>&nbsp;</p><p>“人们慢慢意识到，电工和水管工确实不是同一个职位。”Harness公司专项CTO Nick Durkin说道。</p><p>&nbsp;</p><p>当然，也有开发者人认为，当自己全面负责代码、基础设施和监控时，通常会感到自己很有能力。“这就是全才和专家的区别吧。”</p><p>&nbsp;</p><p></p><h2>职责“大量”增加</h2><p></p><p>&nbsp;</p><p>2000年代后期，DevOps与敏捷方法随着云计算的兴起而大行其道。作为将开发与运维合并起来的新理念，DevOps希望打通这两支以往长期孤立的软件构建与部署力量，实现“1+1&gt;2”的积极效应。与此同时，当时的软件工程师也恰好需要缩短用户反馈循环、提升生产环境下的更新推送频率，这也在无形中推进了开发与运维间的融合。</p><p>&nbsp;</p><p>不少组织敏锐把握住了这个机会，将两方面的专家汇聚起来，试图以前所未有的速度解决种种常见问题。但也有一些组织把DevOps解读成了“让开发人员负责运维工作”，并据此描绘出一个白日梦般的超级概念——全栈开发人员。</p><p>&nbsp;</p><p>但开发运维受到很多限制。网友“beall49”表示，“我厌倦了一切东西像是从钥匙孔里获取，它令人筋疲力尽。”</p><p>&nbsp;</p><p></p><blockquote>领导：我们希望你做开发运维，但我们不会将所有内容直接给你，您必须绕过防火墙才能获得。哦，是的，我们也不会提供一种标准化的方式来访问某些东西。领导：为什么要花这么长时间？我：这不是真正的开发操作。领导：别那么消极。</blockquote><p></p><p>&nbsp;</p><p>“有时，你会得到一台被公司严格锁定的开发机器（硬件加速设置已关闭并且没有密码无法使用，严格的操作系统安全策略禁止你从公司存储库以外的任何地方安装软件等），你不能甚至使用虚拟化，使用这台机器就是你进入公司网络的方式。”开发者“FloRup”补充道。</p><p>&nbsp;</p><p>同时，随着企业软件开发者的总体规模达到历史新高，大家对运维侧的关注度却始终不高。更可怕的是，随着软件开发的增长，运维工作量实际上也始终在同步攀升。</p><p>&nbsp;</p><p>正如DevOps工程师、前系统管理员<a href=\"https://matduggan.com/operations-is-not-developer-it/\">Mathew Duggan</a>\"去年的观点，虽然运维人员继续承担着之前的所有职责，确保应用程序可用、受控、安全和合规，但现在他们还得负责构建和维护软件交付管道，确保开发人员在无需运维介入的情况下，快速安全地发布代码。</p><p>&nbsp;</p><p>要干的活越来越重、要上的再培训课程越来越多，特别是云工程和基础设施即代码技能，几乎成为当前运维从业者们的必修课。</p><p>&nbsp;</p><p>“在我看来，情况已经恶化到了历史极点。运维团队的职责范围大幅增加，但管理层还是对速度提出不切实际的要求，整个体系已然不堪重负。”Duggan写道。</p><p>&nbsp;</p><p>事实上，压力带来的恶果正开始显现。</p><p>&nbsp;</p><p>戴尔技术资本董事总经理Tyler Jewell在一份<a href=\"https://tylerjewell.substack.com/p/complexity-automation-autonomous-development?utm_source=%2Fprofile%2F15568990-tyler-jewell&amp;utm_medium=reader2\">研究报告</a>\"中提到，“要想建立一支能够长期、和谐保持这种稳定迭代水平的团队，其实是个巨大的挑战。随着系统复杂度的提升和最终用户反馈的增加，人们已经很难准确预测某项变更可能给系统造成的影响。”</p><p>&nbsp;</p><p></p><h2>“人人都能成为专家”谬论</h2><p></p><p>&nbsp;</p><p>当然，情况可能并没Duggan等人描绘的那么糟糕，但对工程团队及其职责做出重大调整确实非常必要。</p><p>&nbsp;</p><p>“转型的目的不是要给开发人员增加负担，而是在正确的时间为开发者提供正确的信息。”Harness公司的Durkin 表示，“开发者最需要的不是额外的配置任务，而是在正确的时间能从系统中快速获取必要信息，这样就能支持运维、安全和基础设施团队的正常工作。除非出现问题，否则运维元素就不应该出现在开发者的视野当中。”</p><p>&nbsp;</p><p>迪士尼公司前企业技术战略总监Nigel Simpson也希望公司能认识到这个问题，并努力让开发人员摆脱对底层基础设施的担忧，重新回到自己最擅长的软件构建上来。</p><p>&nbsp;</p><p>更重要的是，DevOps代表一个连续的统一体，其具体实施会因组织而异。现在的开发者能做一点运维，并不代表他们就该每天都承担运维压力。</p><p>&nbsp;</p><p>Gartner 公司分析师<a href=\"https://cloudpundit.com/2022/03/28/cloud-self-service-doesnt-need-to-invite-the-orc-apocalypse/\">Lydia Leong</a>\"认为，开发人员对基础设施的控制，并不是“要么全做、要么彻底不做”的命题。企业可以把这部分职责划分到整个应用程序生命周期当中，只有这样“谁构建、谁运行”才能发挥积极作用，而不是把开发者空降到一个他们既不熟悉、也难以驾驭的陌生环境。</p><p>&nbsp;</p><p>粗暴把基础设施和运维团队的问题抛给开发者，不会带来任何好处。&nbsp;Leong表示，更好的办法应该是放手让开发人员自行访问开发和测试环境，并为他们赋予将基础设施构建为生产代码模板的能力。这才是重点，而不是让他们全面负责生产。</p><p>&nbsp;</p><p>在云计算领域，Kubernetes 容器编排正在成为开发与运维之间的边界。关注这条边界，就能让开发者集中于自己的代码，并让运维人员确保底层基础设施和管理的运行与优化。“但这种独立是以沟通和理解作为基础的，并不是以往那种孤岛式的各自为战。”Ondat公司 Brown 说道。</p><p>&nbsp;</p><p>事实上，根据VMware公司发布的《2022年Kubernetes现状》报告，776名受访者中，54%的人采用Kubertnetes的关键原因就是要提高开发者效率，另有超过三分之一（37%）的受访者称是为了提高运维人员的效率。</p><p>&nbsp;</p><p>“千万别相信那种‘人人都能成为专家’的谬论。在高效团队中，其实很少会有所谓专门的Kubernetes专家。这些团队只是通过极高的抽象度着力缓和了每位成员的认知负担。”Humanitec公司创始人<a href=\"https://humanitec.com/blog/cloud-native-five-principles\">Kaspar von Grunberg</a>\"表示。</p><p>&nbsp;</p><p></p><h2>DevOps已死</h2><p></p><p>&nbsp;</p><p>如果 DevOps 的时代真的走到了尽头，或者至少走过了辉煌时期、来到新的转折点，那接下来事情将如何发展呢？</p><p>&nbsp;</p><p>站点可靠性工程（SRE）诞生自谷歌内部，当时搜索巨头遭遇到了DevOps希望解决的成长阵痛。现在来看，这个职位确实能有效平衡开发与运维间的矛盾。谷歌工程副总裁、SRE之父Ben Treynor曾经坦言，“从本质上讲，如果要求软件工程师设计一项运维功能，那结果就是SRE。”</p><p>&nbsp;</p><p>以 Vanguard 和摩根士丹利两家大型金融机构为例，他们在向着云原生实践过渡时，就发现越来越难以平衡开发和运维两端的职责。而 SRE 就像是缓冲层，把它铺在集中运维团队和各开发者团队之间，就能帮助各方建立信心，感受到既保持良好开发速度、又获得稳定运营状态的可能性。</p><p>&nbsp;</p><p>有开发者现身说法道，“我们有 SRE，他们为我们构建了很好的工具并维护应用程序的基础设施。我们仍然自己做几乎所有的日常部署和运维工作，但是 SRE / 基础设施团队已经做得很好了，我们只需要担心会发生什么而不必担心要如何做。”</p><p>&nbsp;</p><p>然而，SRE也受到过不少批评。摩根士丹利的DevOps和企业技术架构负责人Trevor Brosnan就提到，建立SRE原则“有时会被误读为要对运维团队进行大洗牌。”</p><p>&nbsp;</p><p>“这是个需要解决的微妙问题。引入SRE确实会让人有种正在再次剥离运维团队的感觉。”但事实并非如此，Vanguard 站点可靠性工程师 Christina Yakomin 就一直在鼓励公司的开发者和运维人员分担安全责任，并把运营需求整体交由共享平台团队承担。</p><p>&nbsp;</p><p></p><h2>平台工程才是未来？</h2><p></p><p>&nbsp;</p><p>如今，不少企业开始尝试建立内部开发者平台或者平台工程部门，这样既能给开发人员提供必要工具，也能通过适当的组织护栏隔开其他事务对开发和运维造成的影响。</p><p>&nbsp;</p><p>内部开发者平台往往由大量API、工具、服务、知识和支持所构成，目的是为开发人员提供代码生产部署所必需的一切助力。至于平台本身，则由公司专门的专家团队或所有者负责维护。</p><p>&nbsp;</p><p>软件工程师兼 DevOps 评论员 <a href=\"https://twitter.com/sidpalas/status/1551936840453820417?s=21&amp;t=82OedrWfFO-EDsfNVYpDfA\">Sid Palas</a>\" 在推特上写道，“DevOps已死，平台工程才是未来。开发者不想跟基础设施打交道，企业在发展过程中又需要控制自己的基础设施。只有平台工程，能将这两个相互矛盾的命题统一起来。”</p><p>&nbsp;</p><p>“平台工程部门的实际表现确实不错，能够在消除开发流程摩擦的同时，赋予开发者充分的灵活性。”软件咨询公司Thoughtworks的技术主管Brandon Byars表示，“一旦把这些工作硬塞给缺乏专业知识和工具支持的开发者，情况就会迅速恶化。”</p><p>&nbsp;</p><p>因此面对新的历史阶段，要想在工程团队中贯彻DevOps原则，组织首先需要了解怎样在软件开发与运维团队间寻求平衡。正是因为这一微妙平衡点的存在，才让云原生时代的系统复杂性越来越高。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p>&nbsp;</p><p><a href=\"https://www.infoworld.com/article/3669477/devs-don-t-want-to-do-ops.html\">https://www.infoworld.com/article/3669477/devs-don-t-want-to-do-ops.html</a>\"</p>",
    "publish_time": "2022-08-25 14:54:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "字节跳动正式开源自研 Shuffle 框架 Cloud Shuffle Service",
    "url": "https://www.infoq.cn/article/mar2OIsciJeE2czyQoGN",
    "summary": "<p></p><blockquote>大数据计算引擎常用的 Pull-Based Sort Shuffle 方案实现机制存在缺陷，在大规模生产环境下经常因为 Shuffle 问题影响作业稳定性。在此背景下，字节跳动自研了 Cloud Shuffle Service，提供比原生方案稳定性更好、性能更高、更弹性的数据 Shuffle 能力，同时也为存算分离/在离线混部等场景提供了 Remote Shuffle 解决方案。</blockquote><p></p><p></p><p>8 月 25 日，字节跳动宣布正式开源 Cloud Shuffle Service。</p><p></p><p><a href=\"https://github.com/bytedance/CloudShuffleService\">Cloud Shuffle Service</a>\"（以下简称CSS） 是字节自研的通用 Remote Shuffle Service 框架，支持 Spark/FlinkBatch/MapReduce 等计算引擎，提供了相比原生方案稳定性更好、性能更高、更弹性的数据 Shuffle 能力，同时也为存算分离/在离线混部等场景提供了 Remote Shuffle 解决方案。</p><p>目前，CSS 已在 GitHub 上开源，欢迎感兴趣的同学一起参与共建。</p><p></p><p>项目地址：</p><p>https://github.com/bytedance/CloudShuffleService</p><p></p><h2>开源背景</h2><p></p><p></p><p>在大数据计算引擎中，Pull-Based Sort Shuffle 是一种常见的 Shuffle 方案，比如 Spark/MapReduce/FlinkBatch (高于1.15版本)等都将 Sort Shuffle 作为引擎默认方案，但是 Sort Shuffle 实现机制有一定的缺陷，在大规模生产环境下经常因为 <a href=\"https://xie.infoq.cn/article/a5ce4525d848d96d9d96950df\">Shuffle 问题</a>\"影响作业稳定性。</p><p></p><p>以 Spark 的 Sort Shuffle 为例：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/c9/36/c984e2b31426ca54e53e097216155036.jpeg\" /></p><p></p><p>如上图所示链路，Sort Shuffle 会存在以下一些问题：</p><p></p><p>将多个 Spill 文件合并成一个文件，会额外消耗读写 IO；假设有 m 个 MapTask &amp; n 个 ReduceTask，会产生 m*n 个网络链接，当数量特别多时：大量的网络请求会导致 Shuffle Service 容易形成积压；Shuffle Service 会产生大量的随机读取，容易导致 IO 瓶颈，特别是 HDD 集群；Shuffle Service 无法做到 Application 的资源隔离，当有一个异常作业时，可能会影响同一个 Shuffle Service 节点上其它所有作业，问题容易放大；MapTask 生成的 Shuffle Data File 只存储一份到本地，当磁盘坏了也会导致数据丢失，同样引起 FetchFailed 问题；Shuffle Data File 写到本地磁盘的方式，依赖计算节点上的磁盘，无法做到存算分离。</p><p></p><p>这些都很容易导致 ShuffleRead 慢或者超时，引起 FetchFailed 相关错误，严重影响线上作业的稳定性，ShuffleRead 慢也会大大降低资源利用率(CPU&amp;Memory)，同时 FetchFailed 也会导致 Stage 中相关 Task 重算，浪费大量资源，拖慢整个集群作业运行；无法存算分离的架构，在在离线混部(在线资源磁盘不足)/Serverless 云原生等场景下，也很难满足要求。</p><p></p><p>字节跳动使用 Spark 作为主要的离线大数据处理引擎，每天线上运行作业数过百万，日均 Shuffle 量 300+PB。在 HDFS 混部&amp;在离线混部等场景，Spark 作业的稳定性经常无法得到保障，影响业务 SLA：</p><p></p><p>受限 HDD 磁盘 IO 能力/磁盘坏等情况，导致大量的 Shuffle FetchFailed 引起的作业慢/失败/Stage 重算等问题，影响稳定性&amp;资源利用率。External Shuffle Service (以下简称ESS) &nbsp;存算无法分离，遇到磁盘容量低的机器经常出现磁盘打满影响作业运行。</p><p></p><p>在此背景下，字节跳动自研了 CSS，用来解决 Spark 原生 ESS 方案的痛点问题。自 CSS 在内部上线一年半以来，当前线上节点数&nbsp;1500+，日均 Shuffle 量&nbsp;20+PB，大大提高了 Spark 作业的 Shuffle 稳定性，保障了业务的 SLA。</p><p></p><h2>Cloud&nbsp;Shuffle&nbsp;Service 介绍</h2><p></p><p></p><p>CSS 是字节自研的 Push-Based Shuffle Service，所有 MapTask 通过 Push 的方式将同一个 Partition 的 Shuffle 数据发送给同一个 CSS Worker 节点进行存储，ReduceTask 直接从该节点通过 CSS Worker 顺序读取该 Partition 的数据，相对于 ESS 的随机读取，顺序读的 IO 效率大大提升。</p><p></p><h4>CSS 架构</h4><p></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/36/82/36d6063d08dee10a51cb2f59eec2c382.jpeg\" /></p><p></p><p>CSS Cluster 是独立部署的 Shuffle Service 服务，主要涉及的组件为：</p><p></p><p>CSS Worker</p><p></p><p>CSS Worker 启动后会向 ZooKeeper 节点注册节点信息，它提供 Push/Fetch 两种服务请求，Push 服务接受来自 MapTask 的 Push 数据请求，并将同一个 Partition 的数据写到同一个文件；Fetch 服务接受来自 ReduceTask 的 Fetch 数据请求，读取对应 Partition 数据文件返回；CSS Worker还负责 Shuffle 数据清理的工作，当 Driver 进行 UnregisterShuffle 请求删除 ZooKeeper 对应 ShuffleId 的 Znode 时，或者 Application 结束删除 ZooKeeper 中 ApplicationId 的 Znode 时，CSS Workers 会 Watch 相关事件对 Shuffle 数据进行清理。</p><p></p><p>CSS Master</p><p></p><p>作业启动后会在 Spark Driver 中启动 CSS Master，CSS Master 会从 ZooKeeper 中获取到 CSS Worker 的节点列表，然后为后续 MapTask 产生的各个 Partition 分配 n 个副本(默认为2)的 CSS Worker 节点，并对这些 Meta 信息进行管理，供 ReduceTask 获取 PartitionId 所在的 CSS Worker 节点进行拉取，同时在 RegisterShuffle/UnregisterShuffle 过程中会在 ZooKeeper 中创建对应的 ApplicationId/ShuffleId 的 Znode，CSS Worker 会 Watch Delete 事件对 Shuffle 数据进行清理。</p><p></p><p>ZooKeeper</p><p></p><p>如前描述，用来存储 CSS Worker 节点信息以及 ShuffleId 等信息。</p><p></p><h4>CSS 特性</h4><p></p><p></p><p>多引擎支持</p><p></p><p>CSS除了支持 Spark(2.x&amp;3.x) 之外，也可以接入其他引擎，目前在字节跳动内部，CSS 还接入了 MapReduce/FlinkBatch 引擎。</p><p></p><p>PartitionGroup 支持</p><p></p><p>为了解决单个 Partition 太小，Push 效率比较低的问题，实际会将多个连续的 Partition 组合成更大的 PartitionGroup进行 Push。</p><p></p><p>高效统一的内存管理</p><p></p><p>跟 ESS 类似，MapTask 中的 CSS Buffer 将所有 Partition 的数据都存储在一起，在 Spill 之前会对数据按照 PartitionId 进行排序，然后按照 PartitionGroup 维度进行数据推送；同时 CSS Buffer 完全纳入 Spark 的 UnifiedMemoryManager 内存管理体系，内存相关参数由 Spark 统一管理。</p><p></p><p>容错处理</p><p></p><p>Push 失败：当触发 Spill 进行 Push PartitionGroup 数据时，每次 Push 的数据大小为 4MB（一个Batch），当某次 Push batch 失败时，并不影响之前已经 Push 成功的数据，只需要重新分配节点（Reallocate）继续 Push 当前失败的数据以及后续还未 Push 的数据，后续 ReduceTask 会从新老节点读取完整的 Partition 数据；</p><p></p><p>多副本存储：ReduceTask 从 CSS Worker 读取某个 Partition 数据是按照 Batch 粒度进行拉取的，当 CSS Worker 异常（如网络问题/磁盘坏等）导致无法获取该 Batch 数据，可以继续选择另外一个副本节点继续读取该 Batch 以及后续 Batch 的数据；</p><p></p><p>数据去重：当作业开启 Speculative 推测执行会有多个 AttempTask 并发跑，需要在读取的时候进行去重。在 Push Batch 的时候，会给 Batch 数据加上 Header 信息，Header 信息中包含 &nbsp;MapId + AttempId + BatchId 等信息，ReduceTask 读取时可以根据这些 ID 信息进行去重。</p><p></p><p>Adaptive Query Execution(AQE) 适配</p><p></p><p>CSS 完整支持 AQE 相关的功能，包括动态调整 Reduce 个数/ SkewJoin 优化/Join 策略优化。对于SkewJoin，CSS做了更多的适配优化工作，解决了 Skew Partition 数据被多个 ReduceTask 重复读取问题，大大提高了性能。</p><p></p><h4>CSS 性能测试</h4><p></p><p></p><p>我们将 CSS 与开源的 ESS 使用独占 Label 计算资源进行 1TB 的 TPC-DS Benchmark 测试对比，整体端到端的性能提升15%左右，部分 Query 有30%以上的性能提升。</p><p></p><p>同时我们也使用线上混部资源队列(ESS 稳定较差)进行 1TB 的 TPC-DS Benchmark 测试对比，整体端到端性能提升4倍左右。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/8e/8a/8ee5a1244af4014168aa2c48e6c2808a.png\" /></p><p></p><h2>未来规划</h2><p></p><p></p><p>CSS 目前开源了部分 Feature，还有一些 Feature &amp; 优化后续会陆续开放：</p><p></p><p>支持 MapReduce/FlinkBatch 引擎；CSS 集群增加 ClusterManager 服务角色，管理 CSS Worker 的状态&amp;负载信息，同时将当前 CSS Master 分配 CSS Worker 的功能提到 ClusterManager；基于异构机器(如磁盘能力不同)/负载 等维度的 CSS Worker 分配策略。</p>",
    "publish_time": "2022-08-25 15:04:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "施耐德电气：AI工业应用的规模化，从视觉检测做起",
    "url": "https://www.infoq.cn/article/MDuweEQy7Qr1FNHFXzfN",
    "summary": "<p>在<a href=\"https://www.infoq.cn/article/Aub92hlkdiu7sBaYryEt\">施耐德电气</a>\"武汉工厂的生产车间，每一个微型断路器、接触器和各类工业控制小元器件在从产线下线之前，都要经过一位“特殊质检员”的检测。一旦发现表面有任何污渍、划痕、破损或者印刷字体模糊、不清，产品就会被退回返工处理。</p><p></p><p>这位“质检员”并不是人类，也不是传统的CV机器<a href=\"https://xie.infoq.cn/article/1cfe035a968f9100c72761a31\">视觉检测</a>\"系统，而是一个AI工业视觉检测平台。</p><p></p><p>通常来说，企业使用系统替代人工进行检测，目的都是为了提高产品品质、减少人工、提升效率。但是，质量检测又是一个非常难拿捏的工作——要么漏检率偏高，影响产品品质；要么过检率偏高，浪费人力物力——所以很多情况下，即便使用了CV机器视觉检测，产线上也不得不安排人工进行二次检测，这种方式既不够经济，也不够效率。</p><p></p><p>而借助AI工业视觉检测平台，据说施耐德电气武汉工厂已经把产品的漏检率降到了0，过检率则稳定控制到0.5%以内。</p><p></p><p>“传统的CV机器视觉检测系统只能根据既定的规则判断产品的缺陷，但是产品出现瑕疵的情况非常多，很多时候我们很难用一套规则覆盖所有检验类别。而AI技术不一样，它可以通过机器学习举一反三，不断优化算法模型，随着它越来越见多识广，还会越来越聪明。”施耐德电气全球供应链中国区数字化解决方案负责人冒飞飞在日前接受InfoQ采访时解释道。</p><p></p><p>据他介绍，AI工业视觉检测是施耐德电气落地<a href=\"https://www.infoq.cn/article/7vTfCLYoKzuIZTjdLGk0\">AIoT应用</a>\"一个关键的切入点，也是当下很多制造企业落地工业AI的主要应用场景。</p><p></p><h1>为什么是AI工业视觉检测</h1><p></p><p></p><p>从技术角度而言，AIoT可以视为是AI能力和IoT能力的融合——前者是技术升维，负责智能化；后者是技术底座，负责互联互通。</p><p></p><p>其中，AI技术虽然过去几年在消费级市场激起了不少浪花，但是由于前期投入高、短期回报难以评估，加上工业流程的复杂性，对精准度的要求非常高，AI在工业场景的规模化一直还未能实现，企业实践大多还是单点局部试水为主。而值得关注的是，哪怕对于试点的场景，企业也不能盲目选择，找到合适的场景才能确保应用的成功落地。</p><p></p><p>那么，何为“合适”？施耐德电气的判断依据是——业务有需要。以施耐德电气武汉工厂为例，据冒飞飞介绍，之所以上线AI工业视觉检测平台，背后主要有三方面的原因：</p><p></p><p>第一，客户（尤其是C端消费者）近年来对产品质量的要求越来越高，除了确保功能完善，任何外观上的瑕疵都可能影响他们的消费选择和体验；</p><p></p><p>第二，全球制造行业普遍面临招工难的问题，在人员不足的情况下，急需自动化、智能化技术赋能员工、弥补用工缺口；</p><p></p><p>第三，从以人为本的角度出发，施耐德电气武汉工厂希望利用技术把员工从疲劳繁琐的工作中释放出来，去做更具有创造力的工作，改善工作环境和体验。</p><p></p><p>“过去人工去做检测，工人需要长时间用眼，不仅身心疲劳，而且效率低，失误率反而更高。哪怕是使用CV机器视觉检测，背后仍然有很多工作需要人工二次检测。而基于AI机器视觉，可以通过图像检测算法辅助工人对缺陷定位和分类，减少繁琐操作的能耗、人力成本，降低劳动强度的同时有效控制质量异常。”冒飞飞表示。</p><p></p><p>当然，任何算法模型的准确性、有效性都会受到样本数据的影响。冒飞飞告诉InfoQ，施耐德电气使用AI工业视觉检测平台过程中遇到的挑战之一，就是样本的问题。</p><p></p><p>传统的AI检测模型通常都是使用“负样本数据”进行训练——也就是说，会先告诉计算机什么是不好的质量表现，然后再对应地去找质量残次品。但是，由于施耐德电气在过往的生产经营过程中积累的“负样本数据”量不足以支撑模型训练，所以，只能“反其道而行”。</p><p></p><p>“我们的算法逻辑是，先基于‘正样本数据’进行训练，然后再用少部分的‘负样本’做验证。”冒飞飞解释道，“比如说，我们针对产品质量好的状态会设定一个大概的阈值，如果超过这个阈值就可以初步判断质量异常，然后把这个异常框出来，由人工再做一次二次检测。”</p><p></p><p>虽然同样需要人工的二次干预，但是和传统CV视觉检测模式下的人机关系不同，人在其中的角色和作用不再是候补，而是主力。“除了对AI检测出来的不合格产品做二次确认之外，人还需要定期对AI判断的结果进行抽检，而这些人工的检测结果反过来还会输入到模型中，对<a href=\"https://www.infoq.cn/article/dbLYT47GWIIccobhQap5\">AI算法</a>\"的准确性再次进行验证和迭代，实现精度爬坡的过程。随着精度越来越高，人的干预还会越来越少。”冒飞飞表示。</p><p></p><h1>如何实现AI工业应用的推广和复制</h1><p></p><p></p><p>据了解，在施耐德电气武汉工厂先行投入使用的这一AI工业视觉检测平台，目前已经在北京、上海、天津等地的10个工厂、20条生产线部署使用，这些工厂分布于不同生产基地、覆盖各种类型的电气产品。</p><p></p><p>“当一个产品或者解决方案的价值能够被大家都认可的时候，它的规模化推广就会特别顺利。”冒飞飞强调，“但是，我们在推行和复制这一应用的时候也是有标准的。首先，部署的工厂要真的对质量提升有强烈需求；其次，产线的可复制性也要比较强，举例来说，通常是优先在同类型的生产线横向推广，这样试错的成本更低；除此之外，我们还会看AI视觉对于<a href=\"https://www.infoq.cn/article/UlxmUYElHHjTsU55rFUP\">自动化改造</a>\"的难度，如果原来的工厂和产线已经有机器视觉设备，可能只需要优化一下算法而不是投入大量新的设备就能实现，这种我们也会优先考虑。”</p><p></p><p>然而，这种平台的复用和推广并不是技术的简单“复制粘贴”。冒飞飞表示，如果把AI视觉在工业场景完成度比较高的任务划分为几个类别——第一种是做尺寸测量，第二种是做位置定位，第三种是做二维码/条码识别，第四种是做外观质量检测。其中，前三类的参数标准、识别标准相对简单，即便是不同的产品类型，差异也不会太大，反而质量检测的模型复用是最难啃的“骨头”，一旦产品发生变化，模型几乎很难复用。</p><p></p><p>“这就是为什么我们谈AI工业应用的时候经常会提到‘一机一模型’，不只是一个产品要对应一个模型，甚至很多情况下，一个设备就要对应一个模型。因为AI是经过不断训练才能提升智能化能力的，一旦设备不一样，就要进行新的模型训练。”冒飞飞解释道。</p><p></p><p>对此，施耐德电气的“折中”做法是先做到“一个基地一模型”，针对相同产品、相似产线直接快速复用，对于不同产品和产线，则通过中央化的平台实现数据标准化和模型能力沉淀。也就是说，不同基地和产线可以对相对标准化和通用的数据和模型进行调用，然后在这基础上根据特定产品需求做定制化配置——这能在一定程度上解决“重复造轮子”的问题，在减少技术重复投入的同时加速技术的创新应用。</p><p></p><p>当然，视觉识别检测只是施耐德电气切入AIoT的其中一个点，<a href=\"https://www.infoq.cn/article/r53clOWzVRBg61pjSLJZ\">工业AI</a>\"落地的核心应用场景还有很多。</p><p></p><p>“比如设备的预测性维护，对于我们的工厂来说，真空炉、激光机、空压机等这些关键资产设备的投入往往就要几千万，为了延长它们的使用寿命，保养维护维修就很重要；比如质量的自适应控制，在产品的生产制造过程中，结合AI技术，产线机床可以根据实时回传的质量数据自适应调整相关参数，不断优化和改善生产过程；再比如能源管理，通过把AI、工业和能源结合起来，加上增强现实的呈现方法、IPC的过程控制，可以实现对能效、供应链等整体的优化。”冒飞飞表示。</p><p></p><p>换句话说，凡是在工业场景的算法和数据密集区，AI就会有比较大的用武之地。而究其目的，一方面是在设备全面互联基础上，实现降本增效；与此同时，弱化甚至提出生产过程中等不确定因素，实现生产的可靠和可控。 </p><p></p><h1>怎么做好IoT能力“打底”</h1><p></p><p></p><p>当然，这一切的前提离不开AIoT的另一个技术能力——<a href=\"https://xie.infoq.cn/article/1c77ccf6da77b17423bcbc660\">IoT</a>\"做“打底”。</p><p></p><p>具体而言，IoT的作用之一是采集并回传制造生产中各个环节的数据，并汇集、存储到中控室；在此基础上，通过<a href=\"https://www.infoq.cn/article/VrV6xCMbxxm5EOCRTCGD\">大数据分析</a>\"等技术，对数据进行可视化呈现，为一线人员生产以及进行设备控制、维护改造提供依据。</p><p></p><p>据冒飞飞介绍，施耐德电气所有工厂的基础架构设计都会遵循从底层数据采集、到中间层<a href=\"https://www.infoq.cn/video/xS3fjSEvE3Zu7L9d3itm\">边缘计算</a>\"、再到顶层分析应用与服务的三层结构。其中，数据采集层会连接各种互联互通的硬件设备，对所有结构化、非结构化的工业现场数据进行统一的汇总；边缘计算层主要是对各环节的数据进行统一管理、存储和计算；应用分析层即是对数据做进一步的分析，并赋能给业务。</p><p></p><p>而在具体的部署过程中，不同工厂之间既有共性的问题，也有个性化的场景。举例来说，仅仅是在中国市场，施耐德电气就有近30家工厂和物流中心，如何做到统一部署，又能满足不同的业务和产品生产需求？这是绕不开的一个问题。</p><p></p><p>“通常来说，我们会按照一个中央平台加多个分布式架构的方式来做部署。在中央平台，会配置多个集中化训练迭代的管理模型，这些模型可以通过云的形式下发到边缘，进行分布式部署；在每个工厂的边缘，又会有他们自己独立运算的数据中心，配置GPU等<a href=\"https://xie.infoq.cn/article/c99c7895ba0e0a976350c0f2d\">高性能计算</a>\"能力，可以实现边缘的实时计算——最终做到云边端的融合”</p><p></p><p>然而，并不是所有企业都能天生具有这种互联互通的技术能力，更确切来说，具有这种数字化原生能力的企业是极少数。冒飞飞坦言，尤其是在国内，很多传统工厂还有大量“聋哑设备”在运行。“对于这些存量的老旧设备，如果不能接入到数据通讯的主干道上来，它就没法发挥价值。所以，必须想办法解决这些设备的联网问题，把它们变成感知设备。”</p><p></p><p>其中，一种直接的办法，是对设备加设传感器、PLC、通讯接口，把没有数据采集和传输能力对设备，变成互联互通的设备；而对于连接口都没有的设备，另一种间接的办法是通过摄像头+OCR的方式，采集仪表盘的数据。“比如真空炉，我们要对它的温度进行监控，就可以在仪表盘前面加一个摄像头，让它读取上面的数据，然后通过光学自动识别技术把图片的数值转化成数据。”冒飞飞举例。</p><p></p><p>而除了对存量设备进行改造，新进增量设备的数据标准、接口标准也要纳入到统一规划中来。也就是说，所有新设备的入场，都必须符合统一的数据标准和通讯协议。但是，在这个过程中可能还会遇到另一个问题——设备有感知能力，数据也可以获取，但是设备商不允许使用者获取或者获取的费用特别大。</p><p></p><p>“这时候，需要制造企业联合更多的生态合作伙伴，用规模和体量去打动设备原厂，包括从采购的初期，就把设备数据提取和接口的问题放在谈判过程中着重讨论。尤其是对于一些关键设备，一般资产价格特别昂贵，不会轻易替换，在采购时更要把这些问题纳入进来考虑清楚。”冒飞飞强调，“但总的来说，传统制造企业的设备改造和升级，主要还是要看投资回报，也就是看这个改造值不值当，投入产出比合不合适。”</p><p></p><h1>AIoT落地不仅仅是技术问题</h1><p></p><p></p><p>不过，话说回来，一切能用钱和技术解决的问题都不叫问题。</p><p></p><p>在冒飞飞看来，AIoT的理念已经超越了技术与技术的融合，最终事实上是技术和场景的融合。“无论是工业自动化、AIoT还是<a href=\"https://www.infoq.cn/theme/144\">制造业数字化</a>\"，其实归根结底，我们讲的是一种面向未来的思维方式。在这个过程中，我们遇到最大的挑战并不来自于技术，而是来自企业文化、组织架构以及人才培养方面的挑战。”</p><p></p><p>举例来说，一个工厂即便配备了最先进的智能化设备，数据从采集到分析的生命周期链路也非常完整，但是，缺少了关键决策者在最后一步做出及时的反馈动作，那AIoT的闭环也无法形成。比如，数据分析结果显示某个设备需要在某个时间段内进行保养维修，但是维修人员却对此熟视无睹，管理者也没有下达对应指令，那么这个数据分析动作就是无效动作。最终，所有的设备和软硬件技术都会束之高阁、成为摆设。</p><p></p><p>要解决这个问题有两个关键点——一是提高员工意识，二是提升员工数字化能力。而冒飞飞认为，对于企业来说，可以从三个方面着手：</p><p></p><p>第一，管理层对于变革本身要有足够的决心，并且要对应地制定自上而下的战略方针；</p><p></p><p>第二，应该由业务部门主导推动数字化转型，他们来自工厂一线，能够更快抓住技术与场景结合的机会点；</p><p></p><p>第三，需要与人力资源部门协同起来，对外招聘更合适的<a href=\"https://www.infoq.cn/article/h8I3yhi8JkLffu25C2Cd\">人才</a>\"，同时，在内部通过培训、考核等方式提升全员的数字化能力。</p><p></p><p>据冒飞飞介绍，在施耐德电气，每一次变革背后都对员工对能力提升有具体并且硬性的要求。比如，对于智能化设备，会制定面向蓝领工人的AI技术能力发展计划，鼓励员工学会与AI算法模型“共生”，更好地与智能机器进行协作，起码要做到会操作、会读、会修；而针对白领员工，就会对AI模型算法的训练能力，能不能识别更多AI应用场景有要求。</p><p></p><p>除此之外，施耐德电气还会通过举办一年一度的数字化竞赛、筹办数字化相关的俱乐部（比如AI俱乐部、IoT俱乐部、BI俱乐部），通过持续影响每一个员工，最终实现文化改造和人才培养的目的。</p><p></p><p>“总之，数字化这件事不是靠一两个人就能完成的，我们现在要做的是让每位员工都成为数字化公民，从数字化意识到数字化能力全面提升，然后逐渐建立从数字化公民到数字化专家，甚至是Top级别的数字化科学家的人才梯队。”冒飞飞表示。</p><p></p><p>可见，这是支持施耐德电气百年来持续创新，以及未来实现AI工业应用规模化的原动力，同时，也是支持未来每一个企业加速变革和发展的驱动力。</p>",
    "publish_time": "2022-08-25 15:46:43",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "金融数据能力建设，少不了数据安全这块“拼图”",
    "url": "https://www.infoq.cn/article/bJN929Myd2VdLepSOgD2",
    "summary": "<p>想象一下，当你打开手机软件时，第一反应是什么？对于大多数人来说，应该是同意软件开发商的一切要求，尽可能快速地直接操作，而不是考虑自己究竟怎么做才能不泄露自己的隐私。因为，很多人并没有耐心去查阅一条条《用户协议》和《隐私政策》，于是就把个人隐私数据让位给了便捷的服务体验，被动接受服务商的“霸王条款”。</p><p></p><p>好在，这样的情况正在发生转变。随着技术与人们的生活和工作交织越来越紧密，从个人、企业到国家层面，数据隐私和<a href=\"https://xie.infoq.cn/article/3729bc8f6a38322ee9950e1d0\">数据安全</a>\"的重要性不仅得到越来越广泛的认同，在相关法律和监管中也有所体现。比如，我国从2021年9月份开始实施的《数据安全法》，2021年11月1号开始实施的《个人信息保护法》，以及今年宣布即将实施的《数据跨境处理办法细则》。这些法律法规以及具体实施细则的密集出台，无疑都在传递这一信号。</p><p></p><p>而对于<a href=\"https://www.infoq.cn/article/1zd5MLr5iQOBzgAaGpOm\">金融</a>\"行业而言，数据安全的重要性更不必说。金融数据往往涉及了大量的个人敏感信息、企业经营资金信息、社会经济活动等重要内容，一旦受到安全攻击，往小了说将影响人们的正常生活，往大了说将关乎企业运营、社会稳定。</p><p></p><p>因此，在金融数据生命周期建设过程中，数据安全必然是其中的一块重要拼图。脱离了数据安全，只谈数据能力建设，就好像在寻找如何用充满裂纹的瓶子去装更多水的方法，稍有不慎，满盘皆输。</p><p></p><h2>为什么企业的数据泄露成本日益攀升？</h2><p></p><p></p><p>那么，<a href=\"https://xie.infoq.cn/article/0de8e82fc8ddfd1305c6c4da2\">数据泄漏</a>\"的影响究竟有多大呢？根据IBM最近发布的《2022年数据泄露的成本报告》，在全球范围内，数据泄露事件给企业和组织造成的经济损失和影响力度达到了前所未有的水平，单个数据泄露事件给来自全球的受访组织造成平均高达435万美元的损失，较去年增加2.6%，较前年增加12.7%。研究还发现，金融是仅次于医疗受到攻击第二大的行业。</p><p></p><p>“但是这并不意味着金融行业的数据不比医疗行业值钱，金融行业数据一旦泄露，成本非常高。所谓魔高一尺、道高一丈，金融行业其实是众多行业中最重视数据安全的行业，保护措施也是最到位的。”IBM中国科技事业部网络安全业务总经理冯靓在日前接受InfoQ等媒体采访时表示。</p><p></p><p>那么，具体来说，究竟有什么因素会导致企业数据容易泄露呢？冯靓总结了三点：安全系统的复杂性、云迁徙、合规的失败。</p><p></p><p>“安全系统的复杂性使得整个数据泄漏成本比较高，安全系统很多时候是孤立的，当威胁绕过了防火墙，与其他系统的信息就不再连贯了。比如说，当你出了某个地区以后，可能就是一个全新的人了，其他地方并不知道你这个人到底安不安全。其实我们的内部系统也是如此，<a href=\"https://www.infoq.cn/article/HFv7gDOPLt4E5uZdKYV9\">孤岛</a>\"效应比较明显，这时候就需要有一个开放和集成的平台，把这些复杂性全部管理起来。”冯靓在谈到第一个因素时说道。</p><p></p><p>换句话说，当威胁出现时，即使安全系统可以立即识别出来，但是由于系统的孤立性，不能够及时与其他系统传递消息，也无法形成联动，反而会让威胁大张旗鼓地进入到不同的系统中，蔓延开来。因此，拥有一个开放和集成的安全系统管理平台是非常必要的，这样一个平台可以帮助企业做到从系统到数据，及时、全面地把控威胁。</p><p></p><p>“第二个因素是云迁徙。云环境的复杂性，以及大家对于云环境默认它是安全的心态，现在也导致了数据泄漏成本开始变高。IBM《2022年数据泄露的成本报告》显示，现在有45%的数据泄漏是发生在云环境里面的，这说明云环境的安全性还没有做到像传统封闭式IT系统那样可靠。”冯靓表示。</p><p></p><p>进一步来看，在<a href=\"https://www.infoq.cn/article/2fHFRAFOYTE5QZaXbU43\">云原生</a>\"时代，API成为服务交付的必然手段，很多云服务提供商只是强调企业迁徙到云上有多么必要，上云可以为企业带来多少的好处，然而他们对API和接口或许会存在的潜在风险只字不提。</p><p></p><p>API之所以具有很大的风险，是因为一方面它是云上内部数据与外界的唯一关联；另一方面它所承载的数据量以及数据的敏感性，随着数据总量的增加而与日俱增。因此，无论是从攻击未知上还是从价值量级上考虑，API理所当然地成为了攻击者爬取企业数据的头号目标。</p><p></p><p>因此，云环境的复杂性加上API接口的风险性，让云迁徙的数据泄露成本增加。</p><p></p><p>冯靓介绍到，“第三个因素是合规的失败，这也会导致数据泄漏成本居高不下。合规有两方面，第一方面是符合国家的规范，第二方面是要完全遵守企业的安全流程。”</p><p></p><p>为什么会没有满足国家的规范？典型情况是发生在外部数据的引用时。如果外部数据没有按监管规则进行合法引用，而是在未确认数据来源的情况下，就通过第三方机构获取数据，这样极易将第三方合作机构的数据风险转接至金融机构内部，从而带来巨大的数据安全隐患。</p><p></p><p>另一方面，如果企业没有完全遵守金融机构的安全流程，比如在数据处理过程中，没有按照脱敏规则对个人信息、商业机密等进行加密、变形，那么，很大程度上就无法实现对隐私数据的保护，用户在使用数据的过程中不经意便会泄露重要的信息。</p><p></p><p>对于这些问题，究竟怎样才能缓解和降低这些数据泄露的成本呢？</p><p></p><p>冯靓引用报告中的数据与发现，提出第一点是使用<a href=\"https://www.infoq.cn/article/Tbp8up9FRue9yJQUmwTC\">人工智能</a>\"的安全平台，这是对降低整个数据泄漏成本最有效的手段。第二点是采用DevSecOps，也可以大大降低数据泄漏成本。第三点是一定要建立一个Incident Response（事件响应）团队，也就是说一定要有事后响应与防范的系统，并且不断地去演练。这样能够大大降低出事之后修补的成本。</p><p></p><p>报告数据显示，部署了专注于安全的AI和自动化的组织，其数据泄露平均成本要低305万美元。也就是说，科技的力量加上事前的准备，能够有效降低数据泄露的成本。</p><p></p><h2>如何从“被动防御”转向“主动防御”？</h2><p></p><p></p><p>所谓“事前的准备”，意味着企业必须从过去的“被动防御”转变为“主动防御”。而“<a href=\"https://www.infoq.cn/article/cyp8cGxllDNxd6Zl3jbr\">零信任</a>\"策略”是目前比较流行的一种“主动防御”策略，相比防火墙等传统的被动防御办法，“零信任”的核心理念在于默认任何用户和进程都不应该被信任，并据此验证每一位用户、设备、应用程序。</p><p></p><p>但是，《2022年数据泄露的成本报告》显示，45%的数据泄漏发生于云环境，并且来自于<a href=\"https://xie.infoq.cn/article/f7b55f95e1d1895200b4446bb\">关键性基础设施</a>\"组织。其中，将近 80% 的基础设施组织的受访者表示，他们并没有采用零信任策略。“这些关键性基础设施‘过度信任’网络环境，往往会造成非常大的安全风险面，因为威胁者可以通过攻击这些关键性基础设施组织，来破坏与之相依存的全球供应链，而这些关键性基础设组织施涉及金融服务、工业、运输和医疗卫生等领域。”</p><p></p><p>为什么没有采取零信任策略，会带来如此大的风险？</p><p></p><p>冯靓举了个例子：“打个比方，三年前去机场的时候，无需验证乘客体温、疫苗接种情况和核酸72&nbsp;小时的有效期，假定进来的这个人是没有威胁的，这是基于信任的准入机制。但是今天外部的环境改变了，有了传染性极强的新冠病毒，那么现在要进入一个密集的公共区域，我们采取的安全策略就是每个人都必须证明自己是没有威胁的、没有被传染的。零信任安全策略就是类似的逻辑，因为如今的网络安全环境已经改变，威胁无处不在、无孔不入、如影随形，所以在整个IT环境里面，我们必须采取零信任的策略。”</p><p></p><p>简言之，企业应该时刻保持警惕，不要怀着侥幸的心态认为，系统之前没有遭受到攻击，便意味着以后也不会。因为，黑客的攻击行为是以商业价值为导向，只要企业的数据存在商业价值，就可能成为他们的攻击对象。</p><p></p><p>对此，冯靓提出了企业应该采取正确的策略加以应对，并且总结了零信任策略的四大原则：严控<a href=\"https://xie.infoq.cn/article/c75e47cd3d94eceea61ae8630\">特权访问</a>\"、从不信任、永远验证、假设有漏洞。</p><p></p><p>“我们一直和客户讲特权访问应该放在最小的范围里，只有在非常有必要的情况下，才会下放这样的查阅权限。”在她看来，在非必要的情况下，应该尽可能的减少使用数据的权限。这样可以从源头上降低数据泄露的可能性。</p><p></p><p>现实中，无论是最近频发的安全事件也好，还是各种各样的合规要求也罢，其实很多企业的安全团队是从原来信任自己的系统，到现在慢慢变成不那么信任，但是，这距离零信任还是有一些差距需要去弥补的。</p><p></p><p>对此，冯靓建议要想实现零信任策略，这四点是必须要做的：</p><p></p><p>第一，要专注于检测。一定要假设攻击已经发生了，然后不断地去修补系统里面的漏洞；</p><p></p><p>第二，要去做主动的威胁狩猎。威胁狩猎和威胁检测是有区别的，狩猎是要主动出击，不是说等到攻击打到村口了，再去反击。而是要作为一个猎手，主动出击，把攻击消灭在防线之外；</p><p></p><p>第三，要注意<a href=\"https://xie.infoq.cn/article/0c188078cfc469a3fb0111722\">MFA多因子认证技术</a>\"。最简单的就是通过多种手段来确认，比如说在用户输入密码以后可能还要再加一个指纹识别，或者在电脑端输入密码之后，要加一个手机APP端的确认、或者是短信的验证；</p><p></p><p>第四，要采用人工智能以及自动化技术，当企业的安全人员不足时，尤其是安全服务人员，他们很难做到24小时不间断地、保持同样的服务质量去检测安全事件的情况，这时候一定要利用人工智能与自动化的工具去完善安全系统。</p><p></p><p>除了零信任策略以外，她还强调，想要确保数据安全，整个过程并不是一蹴而就的。</p><p></p><p>她举了一个关于农牧型企业的例子：“这家农牧型企业的现代化程度其实已经非常高了，大型农场的很多工作是基于物联网的技术进行控制，几乎见不到工作人员了。然而此时需要采用数据业务中台、智慧农场等新的技术去高效规划企业，其中就会存在非常多的安全威胁。当时，从这家企业的领导人到整个业务团队、IT团队都达成了共识，确定了他们企业安全战略的核心就是不断地去增强主动安全防御的能力。在这个过程中，技术支撑也要跟上，我们具体帮他们搭建了把IT域和OT域集成起来的QRadar智能分析平台，从而落实谋定而后动、规划先行的安全策略。”</p><p></p><p>冯靓认为，从企业安全管理流程考虑，需要进行事件模拟、对手模拟和事件响应系统演练，这些都是应对攻击的前提策略；从技术架构方式考虑，需要采取开放集成式的架构来降低系统复杂度。</p><p></p><p>“其实我们很多安全措施都是比较零散的，或者烟囱式的系统，中间只要有一点没有被顾及到就可能会出现很大的纰漏。因此，开放集成式的架构方法，一方面，可以打破系统孤岛，有助于企业云上所有零散的安全信息；另一方面，集成平台也可以更好地同步管理安全策略。”冯靓说道。</p><p></p><p>所以，企业想要确保数据安全、要实现零信任策略，不仅仅是一句口号，而是应该在策略上，流程上、技术上全面规划并且践行。</p><p></p><h2>如何从制度文化到技术流程贯彻数据安全思想？</h2><p></p><p></p><p>事实上，数据安全不仅仅是一个技术问题，“零信任策略”实际上是对意识和流程的改变。虽然不同行业有着它们特定的思维方式，但是毫无疑问，数据必然是所有网络攻击最终的目标。那么金融机构如何不断提升自己的数据安全能力呢？</p><p></p><p>以银行为例，数据已经被视为一种资产，在业务运营过程中发挥着越来越重要的作用。而冯靓认为，如果企业把数据当作资产，就一定要搞清楚资产的状况。“但是在现实中，即便是银行这样的头部金融机构，对于数据资产的安全防护仍然是有待改善的。我们曾经和银行交流，询问他们最重要的数据资产在哪里、有几个备份、此时此刻有多少个用户可以接触到这些资产？我们发现，很多人都回答不了这些问题。”</p><p></p><p>冯靓强调，确保数据安全不仅仅是IT人员的工作，而是需要从企业领导人到一线员工的通力协作。把零信任策略严格从意识到制度与文化，再到技术与流程规范上切实落实。</p><p></p><p>这一理念在建设银行的数据治理方面得到了充分的验证。和大多数金融机构类似，银行几乎所有的员工都会接触到数据，无论是通过系统查询数据，还是处理数据。因此，建设银行主要通过数据安全文化、<a href=\"https://www.infoq.cn/article/vowCat1mQwWzyuYu2PcU\">数据合规</a>\"文化、数据风险的奖惩机制这三种体系，将数据安全融入到组织保障中。</p><p></p><p>具体来看，每当员工遇到了数据安全问题，确切的说是处于数据风险的关键时刻时，究竟他们是及时规避掉了数据风险？还是事不关己的任由数据风险持续扩大？这些都是可以通过激励与惩罚机制进行调控。做得好的有奖励，做得差的有惩戒，由此便可以激发员工的主观能动性与自律责任心。对于建设银行来说，这三套体系也可以看做是数据安全的三道基础防线，是必须要在银行组织文化层面落实践行的。</p><p></p><p>通常而言，所有的银行员工，无论是数据的生产者、使用者还是管理者都会接触到数据。而数据安全问题，尤其是数据泄露，可能出现在数据流通中的任意一个环节。比如内部工作人员利用便捷的数据访问权限偷取数据、买卖数据，这些现象在过去时有发生。</p><p></p><p>针对这个情况，冯靓认为：“我们做数据安全的第一步，就是要对银行的数据资产做一个摸排梳理，也就是经常说的数据分级分类。就好比，想要给家里上个保险，首先要盘点清楚家里有多少资产，有多少值钱的东西，值钱的东西放在哪里。”此外，她认为银行每一位员工都要以正确的身份、用正确的方式、正确地访问数据并且正确地使用数据，这四个正确也是数据安全流程必不可少的要素。</p><p></p><p>而建设银行在实际的数据管理流程里面，就梳理了银行的资产，确定好了数据安全的分级、分类。除此之外，建设银行还很清晰的定义出谁能看到什么数据，以及他们应该承担的责任和义务，这也就是冯靓说的严控特权访问。换句话说，当一个人想要使用数据时，他的权利和责任一定是并存的。</p>",
    "publish_time": "2022-08-25 15:54:22",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何在规模化微服务项目中应用服务虚拟化测试技术",
    "url": "https://www.infoq.cn/article/6srQ8RfV7cRzRs8PTIYc",
    "summary": "<p>作者 | 刘冉</p><p>编辑 | 贾亚宁</p><p></p><p></p><blockquote>本文由极客时间整理自 Thoughtworks 资深测试与质量专家刘冉在<a href=\"https://time.geekbang.org/qconplus/home\"> QCon+ 案例研习社</a>\"的演讲<a href=\"https://time.geekbang.org/qconplus/detail/100110474\">《服务虚拟化在规模化微服务项目中的实践》</a>\"。</blockquote><p></p><p></p><p>大家好，我是刘冉，我现在在 Thoughtworks 主要从事测试和质量相关的工作，其中以培训、咨询、带领团队完成敏捷测试和管理团队的质量相关的一些工作。我们主要交付企业级软件，最近主要是以交付基于规模化微服务的软件系统为主。我现在正在一个几百人的团队中实施敏捷测试，管控项目上质量的工作。</p><p></p><p>大家都知道基于微服务，特别是规模化微服务的系统，它存在着各种困难。其中有一个困难就是我们需要一套稳定的测试环境，但是在面对如此多的服务，而且还有很多第三方服务的情况下，我们如何才能得到一套稳定的环境，这是我们在测试和开发工作中面临的一个非常棘手的问题。其中有一个方案和技术就是服务虚拟化的技术，它可以很好地解决我们在规模化微服务项目中的测试环境的稳定性问题。今天我们就以这个话题来进行探讨。</p><p></p><p>我们今天的目录包括三部分：</p><p>第一部分就是规模化微服务测试的现状和问题；第二部分是服务虚拟化架构创新和技术重点；第三部分是我在自己曾经完整交付的一个在线支付项目中如何去落地服务虚拟化的技术实践及总结；最后我们会把这些内容简单地总结一下，方便大家学习相应的知识。</p><p></p><h3>一、规模化微服务测试的现状和问题</h3><p></p><p></p><p>首先我们来看一下规模化微服务测试的现状与问题。现状大家都知道，问题其实是非常多的。我基本上在每一个刚刚启动的新项目上都会遇到各种测试环境不稳定的问题，其中很多就包括测试数据很难构造、Dependencies 经常不稳定、不管是它的版本在不断更新，或者因为它的网络环境、还是说它自身由于各种不确定性，造成的一会儿可以使用，一会儿不能使用等各种问题。</p><p></p><h4>1. 测试环境被多个团队共同使用</h4><p></p><p></p><p>这些问题我们归结成四类：第一类就是测试环境会被多个团队同时使用，当一个测试环境被多个团队同时使用的时候，他们关于测试环境、测试版本的需求都可能是不一样的，所以这个时候你如何让不同的人能拿到不同的测试数据以及相应的测试 API 的表现行为，这是一个很大的问题。</p><p></p><h4>2. 测试数据的准备需要花费大量时间</h4><p></p><p></p><p>第二个是测试数据的准备需要花费大量时间，很多特别是我们做银行系统的，它的很多子系统的交易数据是很难构造的。我去过不少银行，他们最大的一个痛点之一就是他们底层的交易数据以及底层的各种类交易数据，就是和交易数据相关的其他数据准备是非常困难的，这个时候就肯定是需要一套 Mock 系统，而这套 Mock 系统，如果你要人工去构造的话，它成本也是非常高的，因为它们有各种关联性也非常难以构造。</p><p></p><h4>3. 某些服务的部署或网络等问题导致测试环境不稳定</h4><p></p><p></p><p>第三个就是某些服务的部署和网络问题导致的测试环境不稳定，这可能是由于现在很多服务是构建在虚拟化网络上面的，比如说 Amazon 的这种网关、网络等各种搭建都是基于代码去配置的。所以这种时候不管是因为基础设施 Infrastructure 的代码出了问题，还是在升级，还是说有些时候就是网络的不稳定造成的，都可能导致你的某些服务不可用。那这时整个测试环境就崩掉了，就不能用了。</p><p></p><h4>4. 依赖服务的版本更新影响了当前版本的测试</h4><p></p><p></p><p>第四个就是依赖服务的版本更新影响了当前版本的测试。那就是说由于你的第三方版本，或者是你的内部开发的微服务的某个版本不小心升级了，或者是说它需要升级，这个时候你本身这个版本还是基于老版本的测试，你就很难解决你的问题，就很容易出现老版本和新兴版本不兼容的问题，导致你的测试环境不可用了。</p><p></p><p>所以主要是这四类问题。第一个问题就是测试环境被多个团队使用，同一个数据有可能被不同的团队修改，这个时候我们就需要数据的多样性以及数据的数量的多样，这样的话每个团队可以分。在很多时候一个环境是很难构造足够多的数据的，像我现在做的一个银行系统也是，数据的构造是非常复杂的，所以说构造数据量是有限的。很多时候是多个团队在用同一个数据，也就是同一个数据可能被其他团队占用，这个时候就很麻烦了。因为一旦占用了之后，理论上说我就不应该使用到，如果你去使用的话，会影响到别人，别人的测试也就会被影响到。</p><p></p><p>那测试数据的准备不要花大量时间，因为数据的关联很多，数据一旦使用就无法还原，特别是像比如最近我们使用的一个系统，它的 Source Token 一旦被注册了，它就不能再被注册了，这种就是非常痛苦的。</p><p></p><p>测试数据可能被刷新或者销毁，有人刷新、销毁你是无可预知的，某些服务的网络导致测试不稳定可能是有些情况比如依赖服务正在部署、依赖服务正在调试、依赖服务存在某个 bug 导致某个功能失效。这个时候你要么就等着它们部署好、等待它们调试、等待它们把 bug 修好，其实你的时间也浪费了，可能你的测试工作或者你自己的测试工作就会被 block 了。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7f/7fbd05e20ae030e6a2408486f32798d9.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7a/7aeeaec96b36c2ec19bfd5fc94385abb.png\" /></p><p></p><p>还有一种情况，最后一种问题就是依赖服务的版本更新。就是说我有两个服务，比如说现在一个依赖服务它是 1.0 版本，突然它版本升级到 1.1 了，这个时候你的服务 A 和服务 B 是没有办法依赖于这个版本 1.1 的，只能在 1.0 的版本上面工作。此时你肯定要进行更改、修复，这个时候如果你还没有来得及去兼容 1.1 的代码修改，服务 A 服务 B 的测试工作全部都得停止，银行就不能工作了，你必须等到你的开发人员把服务 A 和服务 B 的兼容 1.1 版本的工作给完成了才行。这个时间段内的测试工作，基本上就被停止了。</p><p></p><h3>二、服务虚拟化的架构、创新和技术重点</h3><p></p><p></p><p>这种情况下，我们如何能很好地在这段时间依然让服务 A 和服务 B 的测试工作正常进行，就需要有相应的解决方案了。这个解决方案其实就是服务虚拟化，在传统的服务虚拟化的解决方案里面，他们不叫服务虚拟化，叫 Stub 或者叫 Mock。</p><p></p><h4>1. 传统 Stub 服务的架构</h4><p></p><p></p><p>我一般叫 Stub，所谓的 Stub 服务，就是我有一个虚拟服务、有一个真实服务，其实被测系统要么全部用我的虚拟服务，要么就全部用我的真实服务，这就是最经典的 WireMock 最开始用的方案。</p><p><img src=\"https://static001.geekbang.org/wechat/images/29/293d3753abba32559ec6b8a73395a600.png\" /></p><p>这种方案最大的问题就是它非常死板，传统的意义上来说，它要么就是全部使用依赖服务，要么全部使用真实服务，所以说它能解决一部分问题，但是它很难解决测试环境的多样性的问题。所以说在这种传统的 Stub 服务的架构上面，它其实可以解决上面我们提到的 4 种问题中的某些问题，但是它没办法很好地解决 4 种问题中的所有问题。</p><p></p><h4>2. 服务虚拟化的架构和创新</h4><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/9c/9cae6a24d87c1c44813f2ae19a260073.png\" /></p><p>服务虚拟化对它进行了一个架构的创新，架构的创新是什么意思呢？其中最主要的理念就是我们要设立一套所谓的透明代理，这透明代理的核心是说，当我去给我的被测服务提供所谓的 Stub 或者是 Mock，就是传统意义上的这种虚拟数据的时候，我并不是简单地只是提供虚拟数据，我还能提供各种自定义的虚拟数据，甚至是修改或是穿透。什么叫穿透呢？就是说我的数据可以是一部分真的、一部分假的，这个就是它最核心的创新的意义。</p><p></p><p>并且它还提供各种更新的理念，比如说它提供 RESTful API、提供 Docker 化，后面会慢慢地跟大家解答这些核心的技术细节点。提供这个之后我们可以更好地去适应基于云，比如说基于 Amazon、基于阿里云的这种云化的环境下面去部署所谓的虚拟数据和虚拟服务，这样的话更有利于现在这种大规模微服务的实施。不像以前的 WireMock，我可能就是单独起一个服务，可能还要起另外一种服务，这种方式非常传统，虽然可以解决问题，但是它解决问题的种类是有限的。</p><p></p><h5>2.1 服务虚拟化的技术重点一 —— 录制</h5><p></p><p></p><p>其中虚拟服务化的技术重点之一就是录制，录制是传统技术基本上最理想的功能。不管是以前的 Stub、Mock，还是虚拟服务化都需要支持。所以说这是一个基础功能，因为有了录制，你才能节约很多人工去写数据的时间。</p><p><img src=\"https://static001.geekbang.org/wechat/images/ec/ec3a439fbe3b625df4d0119bfc970671.png\" /></p><p>一旦你录制完了之后，你就可以把这个数据进行定制化，很容易地用起来，所以说它的理念就是它需要有一个代理服务器，当你的数据和你的真实的依赖服务进行通信的时候，它会在中间把你的数据录制下来。这个是很多的传统服务比如 Stub、Mock 或者是虚拟化服务的技术都需要有的基础功能。</p><p></p><h5>2.2 服务虚拟化的技术重点二 —— 修改</h5><p></p><p></p><p>第二个功能也是一个比较基础的功能 —— 修改。就是说我不是简单地把录制下的数据或者手写的数据放置在那儿，你去访问它，它就能返回一个你希望要的数据，并不是这么简单。而是说我可以提供第三方脚本来动态地根据不同的参数获取不同的数据。比如我要获取当前的时间，如果你写死的一个 Stub 数据，你获取的永远都是固定时间；这个时候我其实有一个数据可以去获取当前系统的时间，然后返回时间。</p><p><img src=\"https://static001.geekbang.org/wechat/images/28/282939359caead4eb93a0a2ed2ff606d.png\" /></p><p>你可以把相应的修改脚本放在你的虚拟化服务器代理里面，当你获取 API 的时候，它就会自动地去调用系统时间。当然我还可以做各种其他的自定义，这个也是服务虚拟化的最重要的一个功能，很基础的功能。</p><p></p><h5>2.3 服务虚拟化的技术重点三 —— 模拟穿透</h5><p></p><p></p><p>其中它最有创新意义的一个功能 —— 模拟穿透。模拟穿透是什么意思？其实它最核心解决的问题就是到底应该用模拟号的假数据还是应该用真数据，这个不应该是以请求的 URL，或者是不应该与我的服务配置有关，它应该是和我的数据有关。假设三个用户登录：第一个用户登录，他应该拿到的所有的数据都是假数据；第二个用户登录，他可能拿到的全部都是真数据；或者说第三个用户，他登录的时候用的是真数据，但是里面某个功能用的是假数据，这些都是可以的。</p><p><img src=\"https://static001.geekbang.org/wechat/images/91/9167ee209f3c8febc7291d6495f10a7f.png\" /></p><p>对于很多特定的微服务的功能测试，因为微服务是把很多服务分成各个小的这种领域服务，所以说某些服务不可用，可能导致某个功能就直接崩掉了，但是其他功能可能还可以用，这种时候我只需要虚拟化某一个服务的 Dependencies 就可以了。所以这种时候我可以根据我的定制化需求，只虚拟某一部分，或者只虚拟某一些特定的账号，这种时候就需要模拟穿透。</p><p></p><p>大家可以很明显地看出来，其实就是在虚拟代理服务器里面有一个所谓的 Matcher（匹配器），当我的匹配器规则满足某一个请求的时候，比如我的 HTTP 的 Header、HTTP 的 Body、HTTP 的 Parameter 都可以，Get Parameter 或者是 Post Body 中某一个 ID，它只要匹配到这个值时就用假的数据，如果没匹配到就直接去访问外部真实的依赖，返回真实的数据。这个是我在很多项目中用的最多的一种模型，非常实用。</p><p></p><h5>2.4 服务虚拟化的技术重点四 —— 穿透修改</h5><p></p><p></p><p>第四个重点就是穿透并修改，它其实就是在上一个穿透的功能上做了另外一种扩展，扩展什么意思呢？就是说我可以让你穿透，穿透之后我可以把这些穿透的数据根据我的一些规则进行修改，这个使用的场景不多。</p><p><img src=\"https://static001.geekbang.org/wechat/images/a0/a075670eca4806121297e98e89a93874.png\" /></p><p>但是也有很特殊的一些场景，比如说我在做安全测试的时候，或者安全测试模拟的时候，大家可能听过 Man-in-the-middle attack，所谓的中间人攻击，这种时候它是可以很好地产生或者模拟一个中间人攻击的场景，所以说它也是非常有意义的，能解决我们很多很特殊的场景。</p><p></p><h5>2.5 服务虚拟化的技术重点五 —— 差异化（Snapshot）</h5><p></p><p></p><p>第五个是一个非常特殊的场景，这个也是很多服务虚拟化技术里面所使用到的，它其实就是用了一个所谓的 Snapshot Test 的概念，就是差异化，或者是叫对比测试。它的核心点就是我可以录制我上一个版本的微服务，比如说刚才我们遇到的第四个问题，就是微服务版本 1.0，这个时候当我的外部服务升级到 1.1 版本的时候，我去跑一下测试。跑测试的过程中，如果我的代理服务器里面存的是 1.0 的版本，但是访问的外部服务升级到了 1.1 版本。1.1 返回的版本和 1.0 版本如果有区别，代理服务器就会报警、报错，就会告诉你，其实现在你拿到的 Response 外部服务已经变成了新的版本，而不是老的。</p><p><img src=\"https://static001.geekbang.org/wechat/images/c1/c1340d8c16bfa06ab4a1ba1a3eb63af5.png\" /></p><p>这个时候你就可以用它完成类似于像 Schema Test，我们所谓的外部依赖的 Schema 的结构测试，或者 Snapshot，就是差异化测试。这样的话可以省去你很多工作量，它可以很好地侦测到你的服务有没有变化，当服务有变化的时候，其实可以自动化启动你的版本功能，就是我们之前说的让它维持在 1.0 版本，这样的话 1.0 所有的服务就可以动态地去启动起来，而不是去使用 1.1 版本的。所以差异化服务给了我们更多的想象空间和操作空间。</p><p></p><h4>3. 服务虚拟化的技术重点总结</h4><p></p><p></p><p>服务虚拟化技术的重点我们总结一下。服务虚拟化是可扩展的，不管是刚才我们看到的穿透还是定制化，它其实都是修改模型，都是可以定制、可以扩展的。我们把传统的基于这种 Stub、Mock 的服务，可以随便地去扩展新的功能，而不是简单地返回一个固定的数据，然后我们还可以提供 RESTful API，很容易地去控制它，这样的话我们就可以通过编程的方式来控制我的虚拟化服务器的代理了。</p><p></p><p>第二个是虚拟服务可以定制化，什么叫定制化呢？就是我可以根据我的需求来定制化我的功能，它和可扩展性的意义类似，只不过可扩展性体现的是我可以扩展，而定制化是我扩展的过程中还可以通过代码，比如说 Modify 模型，其实是嵌入了一段基于 Python 或者 Java 的代码，这样的话我可以在我的修改里面自己写代码去实现我的功能，这是可定制化。</p><p></p><p>可配置化也是一个非常重要的功能，它的配置我们是可以通过 RESTful API 去远程配置的，而不是简单的，一旦我运行起来所有的配置是不可变的、所有的功能都是定好了，只能通过命令行去操作，或者通过本地的方式操作，而不通过语言的方式去操作，为什么要这样呢？因为现在很多时候虚拟服务器是部署在云端的，云端的时候，其实我需要通过 Jenkins 去控制它，而不是人工地去调试它。很多时候我通过 Jenkins 触发一个功能，就能在特定的情况下配置虚拟化服务器，达到一个特定状态，比如说 1.0 还是 1.1。或者是说当我 Snapshot 测试挂的时候，或者什么测试挂的时候，我能把服务切到某个特定版本，所以说需要远程可配置化。</p><p></p><p>还有可容器化，可容器化也是一个非常重要的功能，因为现在很多服务都是基于云的，它都是容器化的解决方案。所以如果容器化了之后，就很容易地可以在云端进行部署了。</p><p></p><p>另外就是支持双向证书。支持双向证书的话，如果懂 HTTPS 和 SSL 的人就知道，因为有些服务和服务之间的通信用 HTTPS，它可以要求客户端支持 Pinning，所谓的 Pinning 就是客户端的证书，如果不是和服务器端证书是匹配的，其实客户端发的请求，服务端是可以抛弃的、不认的。服务器端证书就是服务端需要有个证书，客户端必须要去认可这个证书，不认可的话，那客户端也是可以把它扔掉的，大家可以想象这个代理服务器在中间，如果我的证书不是双向的，就是不支持双向的，这样的话有可能只是在某一端我支持了。</p><p></p><p>比如说现在 WireMock 就不支持客户端证书，什么意思呢？假设你用 WireMock 架在服务 A 和服务 B 中间，并且服务 A 和服务 B 都是 HTTPS 通信，支持 SSL Pinning 的，这个时候如果你的 WireMock 没有办法把 B 服务的 Client 证书集成进来，所有的通过 A 服务发的 WireMock 再转发到 B 服务的请求，都会被 B 服务禁止掉，因为 WireMock 没有办法支持 Client 证书。其实服务虚拟化就需要支持这个，因为现在很多微服务，特别是规模化微服务里面都需要支持这个功能。</p><p></p><h3>三、一个在线支付项目的落地实践</h3><p></p><p></p><p>这是我的一个真实的在线项目的落地实践。这个实践里面其实是一个抽象出来的项目，现实其实远比这个复杂，比如说它的领域服务有银行服务、存储服务、第三方的认证服务等等很多服务，我只是把它抽象成了领域服务 1、2、3、4、5、6。因为我们落地实践的时候，用的中间代理是 Hoverfly（我在文章里和演讲中都讲过很多），那么我就详细讲讲 Hoverfly 的本质，也就是它本身的特点。</p><p></p><h4>1. 架构</h4><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c4/c4c1615eefde13efec7fa5435d620583.png\" /></p><p>我们是基于 Hoverfly Proxy Server 来搭的一个所谓的虚拟化服务 Server。大家可以看到这里面画了 1 个我们的被测服务，但其实被测服务是很多的，至少是 10 个以上，这 10 个以上的被测服务都会同时连到 1 个 Hoverfly Server。1 个 Hoverfly Server 也可以同时连到十几二十个不同的领域 Server，其实这些领域 Server 和被测服务之间本质上来讲可以是我们开发的服务，也可以是云服务，也可以是第三方的 Dependencies 服务，这个不是重点。</p><p></p><p>重点是 Hoverfly 可以架在我们自己开发的领域服务和领域服务之间，也可以架在领域服务和被测依赖服务之间。所以说大家看到我用了不同的颜色，其中最下面 5 和 6 就是两个所谓的 Dependencies 服务。前面两个和我们是相同的颜色，就是我们自己开发的领域服务。因为我测试的时候肯定是基于某个特定的功能来测某个特定的 API，所以这个示意图只是示意这个被测服务我可以通过手动 API 去测试，也可以通过 CI 上的自动化测试来进行测试。</p><p></p><h4>2. 实践重点</h4><p></p><p></p><p>基于这种架构来看一下我们是如何去做实践的，这个实践的重点是什么。我把实践重点列成了很多小条，因为大家可以很容易进行总结。首先我们选择了虚拟服务化工具 Hoverfly，选择 Hoverfly 最主要是因为它的性能很好，后面我们会说还要来做性能测试挡板，这是其中一个特点。第二个特点是它支持双向证书，也是后面会详细解释的。还有最主要的是它能几乎全部支持刚才我上面提到的那些模型，不管是穿透模型、录制、修改模型，还是 Snapshot 模型都有，所以说我能很好地进行一个扩展和定制化的工作。</p><p></p><p>第二我们要选择真实的服务来录制生成虚拟数据，一般来讲我的数据全部是录制之后，再经过第二次加工修改来生成的，所以我们的录制工作也是非常重要的。</p><p></p><p>第三我主要的测试工作全部是基于模拟穿透模型来的，就是说只要把需要的虚拟数据导入到 Hoverfly 里面，这些数据匹配上后，它就会返回这些虚拟数据；但是一旦没有匹配上这些虚拟数据，它就会访问真实数据。这是一个我用的最多的功能，在这个项目上 90% 以上的虚拟数据都是通过这种方式来提供的，还有其他一些别的方式来提供的。</p><p></p><p>因为大家知道 Hoverfly 是可以通过 RESTful API 来远程配置的，所以说我会随时切换不同的模型，选用容器化的方式，在 AWS 上部署 Hoverfly。因为我们整个系统是架在 Cloud 上的，所以说我们利用了 AWS 的 Docker 的方式来部署 Hoverfly。Hoverfly 在 Docker Hub 上有自己的标准，官方提供的 Docker 的镜像。我们也可以自己去做，还是非常容易的，因为它就是一个基于 Linux 的二进制包，很容易搭建起来。下面我们选用了 Hoverfly 自己提供的 RESTful API，来控制和配置虚拟服务。就像我刚才说的，我可以通过 API 来导入虚拟数据，我可以拿来切换模型、切换功能，什么时候我应该切换到什么模型，什么时候进行什么都会完全根据我要跑什么测试来手动切换的。下面我们还使用到 CI 流水线来发布和启动虚拟服务，也就是说这一切我都不应该手动去做，包括发布虚拟服务、导入数据、启动服务都是通过 Jenkins，用 CI 的流水线来做的。</p><p></p><p>接下来我们还使用到真实的测试数据，这是我的一个测试策略。使用真实的测试数据来对 API 进行小规模的集成测试，因为我们不可能把所有的 API 测试都用模拟数据来进行返回，我们其实也是构建了一部分的真实数据。因为在我们可行的范围之内构建了足够多的真实数据，这部分真实数据对应的 API 测试，全部是跑真实数据的，所以说我们的自动化测试里面会有一部分测试跑的账号是真实账号。真实账号里面就会扩真实的 Dependencies，但是因为我们的测试场景是非常多的，大规模的回归测试是会基于伪造的虚拟数据进行，所以说我们会在测试数据的分类里面有两部分数据，一部分是真实数据，一部分就是我的虚拟的伪造数据。这些不同的账号、不同的数据就会存成不同的文件，跑测试的时候就对应着不同的测试场景。</p><p></p><p>我们还使用到了伪造数据来模拟错误注入，什么意思呢？大家可以想象一下，就是说我们假设想模拟领域服务、领域 API，服务 API 1 在失败的情况下，被测服务应该是什么样的状况呢？这个时候如果有了 Hoverfly，你就可以很容易地把领域 API 1 的某几个账号对应的数据返回特定的 504、500 或是 400，也可以是超时 timeout。你都可以去模拟这些特定的失败，模拟特定失败之后，再看一下被测服务 A 的 API 的自动化测试或手动测试有什么样的表现。</p><p></p><p>这样的话就是完成了一个基础的错误注入测试，其实错误注入测试大家都知道，这是混沌工程的一个最核心的能力。混沌工程里面最核心的能力就是我能进行错误注入，并且根据错误注入之后可以动态收集整个系统的情况，然后去调试、分析、优化。混沌工程其实是一个很复杂的工程，但是它核心中的核心就是，我们怎么实施动态的错误注入。错误注入通过 Hoverfly 其实可以很容易地手动实施，此时你可以实施一个比较简易版的手动混沌工程，这是我个人总结的。</p><p></p><p>在银行项目里面大家可以知道，假设我的银行 API 交易超时了，我去调真正的银行的 API，但是银行的 API 是银行提供给我们的一个测试服务，它不会返回一些特定的 error，不可能给我们提供 error，所以这个时候像 timeout、500 的报错，我怎么让我们的服务去获得银行服务的 500、timeout 或者 400 情况呢？只能是通过 Hoverfly 来模拟了。</p><p></p><p>当我们做性能测试的时候，因为银行服务中就算是测试环境，也是有限制的，就是固定时间内只能调用多少次，所以说基本上不可能用它来连接真实的银行服务做性能测试。这个时候我就选用了 Hoverfly 来做性能测试挡板，大家知道 Hoverfly 是用 Golang 写的，所以它相对于 WireMock 来讲，性能非常高。当我的性能测试不断提升的时候，其实我能保证我的性能测试挡板的性能一定要比我被测系统好；如果反之，我的性能测试挡板的性能比我的被测系统要差，这样的话我测的不是被测系统的性能，而且性能挡板的性能，所以说用 Golang 可以很好地解决性能测试挡板的性能问题。</p><p></p><p>这样的话，其实我测出来的性能基本上可以认为是我被测系统的性能，而被测系统我们是用 Java 写的，也分析过它的性能，一般来讲都是比 Golang 要差很多的， 可能很多人会诟病 Java 写的这一点，从我现在测出来的结果看它确实要差一点。最后我们是使用了支持服务端和客户端的双证书，因为银行那边使用 HTTPS，也是开启了 SSL Pinning 的这种功能，所以说最后我们使用了这个东西才能完整地模拟整个银行服务，包括需要的稳定性。</p><p></p><h4>3. CI 流水线中的虚拟服务</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7e/7eb24b66773ab565cb62c5367f54ccde.png\" /></p><p>我们再看看 CI 流水线中的虚拟化服务是怎么进行同步的？大家可以看到首先录制并编辑 Simulation，就是我的虚拟服务的数据，这个时候我把它提到代码库里面，通过 code commit 提供到 Git Repo 里面，而 Git Repo 里面 Jenkins 流水线，你可以人工触发也可以定时触发，也可以在代码提交之后，通过一个 Hook 去触发 Jenkins API 调它的 RESTful API，Jenkins 自己也有一套 API 去触发流水线，流水线一旦触发，它就会把 Simulation 从代码库里面下载下来，通过 RESTful API 上传到 Hoverfly 并且导入到 Hoverfly 上面去，这是一个标准的服务。</p><p></p><h3>四、总结</h3><p></p><p></p><p>最后我们再总结一下今天我们讲的这个课程，我们讲到了一些服务虚拟化的基本功能、核心功能以及创新的点，包括它相对于 WireMock、相对于传统的 Stub 服务，它提供了一些新的东西，其中它主要是为了解决我们微服务测试中的几个最大的问题，包括测试数据和测试服务稳定性，它都能很好地通过不管是录制、修改还是穿透等各种方式来完成测试数据的多样性，包括稳定性也都能解决到。通过虚拟化服务可以极大地改善测试数据和稳定性，这个也是我们可以去解决的，通过 Hoverfly 的虚拟化服务，我们基本上解决了遇到的各种问题。</p><p></p><p>第三点，服务虚拟化的特点是功能强大，包括可定制化、可扩展化、远程配置化和 Docker 化。所以说我们需要有一套功能足够强大的虚拟化服务解决方案来实施以满足这些功能，实施我们的虚拟服务化，包括满足包括我们所说的所有功能。</p><p></p><p>最后，我的真实项目里面使用了一款 Hoverfly 的免费的，功能强大的虚拟化服务解决方案来解决，这个大家可以从我总结的几点里面知道我到底做了些什么，包括我们通过 Docker 化部署，通过 Jenkins 触发、上传、变更，Hoverfly 的这种模型，数据的管理，包括我们通过什么样的数据测试什么样的功能，还有通过证书来解决 SSL Pinning 的问题。</p><p></p><p>这就是我今天的一个简单分享，希望当你遇到测试环境不稳定、测试数据相关的一些问题，特别是在大规模微服务项目里面，能尝试一下服务虚拟化的解决方案。</p><p></p><p></p><h3>作者介绍</h3><p></p><p></p><p>刘冉 &nbsp;Thoughtworks 资深测试与质量专家</p><p></p><p>对 Web 应用测试、Web 服务测试、服务器性能测试、移动测试、安全测试、敏捷测试、测试驱动开发（TDD）、CI/CD 和测试分层一体化解决方案等有深入理解。现在关注全程软件自动测试，测试服务平台以及质量内建。书籍<a href=\"https://book.douban.com/subject/35879790/\">《软件研发效能提升实践》</a>\"、<a href=\"https://book.douban.com/subject/27611269/\">《代码管理核心技术及实践》</a>\"和<a href=\"https://book.douban.com/subject/33443351/\">《软件测试实验教程》</a>\"的作者之一。</p>",
    "publish_time": "2022-08-25 15:58:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]