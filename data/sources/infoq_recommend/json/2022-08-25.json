[
  {
    "title": "谷歌推出Bigtable联邦查询，实现零ETL数据分析",
    "url": "https://www.infoq.cn/article/cfBjW6rIGjIfU4LhjezU",
    "summary": "<p>最近，<a href=\"https://www.infoq.cn/topic/google\">谷歌</a>\"宣布Bigtable联邦查询普遍可用，用户通过BigQuery可以更快地查询Bigtable中的数据。此外，查询无需移动或复制所有谷歌云区域中的数据，增加了联邦查询并发性限制，从而缩小了运营数据和分析数据之间长期存在的差距。</p><p>&nbsp;</p><p>BigQuery是谷歌云的无服务器、多云数据仓库，通过将不同来源的数据汇集在一起来简化数据分析。Cloud Bigtable是谷歌云的全托管NoSQL数据库，主要用于对时间比较敏感的事务和分析工作负载。后者适用于多种场景，如实时欺诈检测、推荐、个性化和时间序列。</p><p>&nbsp;</p><p>在以前，用户需要使用ETL工具（如Dataflow或者自己开发的Python工具）将数据从Bigtable复制到BigQuery。现在，他们可以直接使用BigQuery SQL查询数据。联邦查询BigQuery可以访问存储在Bigtable中的数据。</p><p>&nbsp;</p><p>要查询Bigtable中的数据，用户可以通过指定Cloud Bigtable URI（可以通过Cloud Bigtable控制台获得）为Cloud Bigtable数据源创建一个外部表。URI包含以下这些内容：</p><p>&nbsp;</p><p>包含Cloud Bigtable实例的项目ID——project_id；Cloud Bigtable实例ID——instance_id；要使用的应用程序配置文件ID——app_profile（可选）；要查询的表名——table_name。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0d/0dcf4d50fbb381f0343adde4dd85fcc5.png\" /></p><p></p><p>来源：<a href=\"https://cloud.google.com/blog/products/data-analytics/bigtable-bigquery-federation-brings-hot--cold-data-closer\">https://cloud.google.com/blog/products/data-analytics/bigtable-bigquery-federation-brings-hot--cold-data-closer</a>\"</p><p>&nbsp;</p><p>在创建了外部表之后，用户就可以像查询BigQuery中的表一样查询Bigtable。此外，用户还可以利用BigQuery的特性，比如JDBC/ODBC驱动程序、用于商业智能的连接器、数据可视化工具（Data Studio、Looker和Tableau等），以及用于训练机器学习模型的AutoML表和将数据加载到模型开发环境中的Spark连接器。</p><p>&nbsp;</p><p>大数据爱好者Christian Laurer在一篇文章中解释了Bigtable联邦查询的好处。</p><p>&nbsp;</p><p></p><blockquote>你可以使用这种新的方法克服传统ETL的一些缺点，如：&nbsp;1. 更多的数据更新（为你的业务提供最新的见解，没有小时级别甚至天级别的旧数据）；2. 不需要为相同的数据存储支付两次费用（用户通常会在Bigtable中存储TB级甚至更多的数据）；3. 减少ETL管道的监控和维护。</blockquote><p></p><p>&nbsp;</p><p>最后，关于Bigtable联邦查询的更多详细信息，请参阅官方的<a href=\"https://cloud.google.com/bigquery/docs/external-data-bigtable\">文档页</a>\"。此外，所有受支持的Cloud Bigtable区域都可以使用新的联邦查询。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/08/bigtable-bigquery-zero-etl/\">Google Introduces Zero-ETL Approach to Analytics on Bigtable Data Using BigQuery</a>\"</p>",
    "publish_time": "2022-08-25 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Kafka Streams与Quarkus：实时处理事件",
    "url": "https://www.infoq.cn/article/WfA0p1XoZCJ6INdyJLyv",
    "summary": "<p>在本系列的<a href=\"https://www.infoq.cn/article/cFpvXRLmZzJBGbzAeFu5\">第一部分</a>\"中，我们学习了<a href=\"https://kafka.apache.org/\">Apache Kafka</a>\"和<a href=\"https://quarkus.io/\">Quarkus</a>\"的集成，并开发了一个简单的应用，从两个Kafka主题生产和消费事件。</p><p></p><p>在那个样例中，我们模拟了一个影视流公司，在一个Kafka主题中存储电影信息，在另外一个主题中存储了用户停止观看电影时所发生的每个事件，并捕获了电影已播放的时间。</p><p></p><p>下图展示了该应用的架构：</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/quarkus-with-kafka-streams/en/resources/1Untitled-10-1656674518432.jpeg\" /></p><p></p><p>我们可以看到，消费消息很简单，只要有消息生成，我们就可以得到它们，但是除此之外，我们也做不了其他的事情了。如果我们需要实时处理数据（比如过滤或操作事件）或者我们需要在事件之间做一些关联，单纯使用Kafka的消费API可能就不是最佳的方式了，因为这会导致代码非常复杂。</p><p></p><h2>Kafka Streams</h2><p></p><p><a href=\"https://kafka.apache.org/documentation/streams/\">Kafka Streams</a>\"项目能够帮助我们在事件产生时实时消费它们，应用各种转换，执行流连接等，并且可以选择性地将新的数据表述写回主题中。</p><p></p><p>对于有状态和无状态的流应用来说，Kafka Streams都是理想方案，它能够实现基于时间的操作（例如，围绕给定的时间段对事件进行分组），并且考虑到了Kafka生态系统中普遍存在的可扩展性、可靠性和可维护性。</p><p></p><p>Kafka Stream由三个元素组成，即输入（源处理器）、输出（sink处理器）和处理器（流处理器）。</p><p></p><p>源处理器（Source processor）：源处理器代表一个Kafka主题。源处理器会发送事件到一个或多个流处理器中。</p><p></p><p>流处理器（Stream processor）：流处理器会将转换/逻辑应用于输入流中，比如连接、分组、计数、映射等。流处理器可以连接至另一个流处理器和/或sink处理器。</p><p></p><p>Sink处理器（Sink processor）：Sink处理器代表了输出的数据，它会连接至一个Kafka主题。</p><p></p><p>**拓扑结构（topology）**是由源、处理器和sink组成的无循环图，事件会传入到一个Kafka Streams中，该实例将开始拓扑结构的执行。</p><p></p><h2>Kafka Streams和Quarkus</h2><p></p><p>Quarkus使用Quarkus KStreams扩展实现与<a href=\"https://kafka.apache.org/documentation/streams/\">Kafka Streams</a>\"集成。</p><p></p><h3>Quarkus起步</h3><p></p><p>使用Quarkus最快捷的方式是通过<a href=\"https://code.quarkus.io/\">初始化页面</a>\"添加所需的依赖。每个服务可能需要不同的依赖，你可以选择Java 11或Java 17。为了实现Quarkus与Kafka Streams的集成，我们至少需要添加Kafka Streams扩展。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/quarkus-with-kafka-streams/en/resources/1Captura%20de%20Pantalla%202022-04-10%20a%20las%2022.34.28-1656674518432.jpeg\" /></p><p></p><h2>要开发的应用</h2><p></p><p>正如在本文开始时所提到的，在本系列的<a href=\"https://www.infoq.cn/article/cFpvXRLmZzJBGbzAeFu5\">第一部分</a>\"中，我们开发了一个影视流公司，它有两个Kafka主题，其中一个用来存储电影的列表，另外一个主题会在用户停止播放电影时存储用户所在的区域（事件的键），并且会以电影id和播放时间作为事件的值。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/quarkus-with-kafka-streams/en/resources/1topic-1656674518432.jpeg\" /></p><p></p><p>所有的这些逻辑都是在名为<a href=\"https://github.com/lordofthejars/movie-plays-kafka/tree/main/movie-plays-producer\">Movie Plays Producer</a>\"的生成者服务中创建的，该服务是使用Quarkus开发的。</p><p></p><p>除此之外，我还使用Quakus开发了一个<a href=\"https://github.com/lordofthejars/movie-plays-kafka/tree/main/movie-plays-consumer\">Movie Plays Consumer</a>\"服务，它会消费这两个主题的事件并且会在控制台上展示它们（并实现了HTTP服务器端事件）。</p><p></p><p>但是，这里没有对数据进行任何处理，它只是按照原样进行了接收。如果我们想要在movies和playtimemovies主题之间进行一下连接，在获取电影播放时长的时候得到电影的详细信息而不是id的话，那又该怎么办呢？</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/quarkus-with-kafka-streams/en/resources/1join-1656674518432.jpeg\" /></p><p></p><p>如果仅仅使用Kafka消息来实现这样的逻辑会变成一项很复杂的任务，因为我们需要在一个Map中存储Movie信息，并且在每个playedmovie事件发生时，进行匹配处理。</p><p></p><h3>Movie Plays KStream</h3><p></p><p>与其为每个用例手工编写代码，不如看一下如何使用Kafka Streams，以及它是如何与Quarkus集成来解决这个问题的。</p><p></p><h4>创建项目</h4><p></p><p>导航至Quarkus的<a href=\"https://code.quarkus.io/\">初始化页面</a>\"，并选择Apache Kafka Streams扩展来实现与Kafka Streams的集成。然后，选择RestEasy和RestEasy Jackson扩展实现事件从Java对象和JSON之间的编排/解排。同时，取消选中Started Code生成选项。</p><p></p><p>请参照下面的截图：</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/quarkus-with-kafka-streams/en/resources/1Captura%20de%20Pantalla%202022-04-10%20a%20las%2017.25.38-1656674518432.jpeg\" /></p><p></p><p>你也可以跳过这个手动的步骤并导航至<a href=\"https://code.quarkus.io/?a=movie-plays-kstreams&amp;nc=true&amp;e=kafka-streams&amp;e=resteasy-jackson&amp;e=resteasy\">Kafka Stream Quarkus Generator链接</a>\"，在这里，所有的依赖都已经选择好了。然后，点击Generate your application按钮，以下载应用骨架的压缩文件。</p><p></p><p>解压文件，并在你最喜欢的IDE中打开项目。</p><p></p><h4>开发</h4><p></p><p>当开发Kafka Stream应用时，我们需要做的第一件事就是创建<a href=\"https://kafka.apache.org/28/javadoc/org/apache/kafka/streams/Topology.html\">Topology</a>\"实例，并定义源、处理器和sink。</p><p></p><p>在Quarkus中，我们只需要创建一个_CDI_类，这个类需要包含一个返回Topology实例的方法。</p><p></p><p>创建名为TopologyProducer的类，它将会实现从这两个主题消费事件并连接它们的逻辑。最后，生成的结果将会发送至一个sink处理器，该处理器以控制台输出的形式展示结果。</p><p></p><p>还有一个元素我们没有提到，在这些场景中它非常有用，那就是Kafka Tables。</p><p></p><p>一个主题可以包含具有相同键的多个事件。例如，我们可以使用某个键插入一个电影，然后我们可以使用相同的键创建一个新的事件来对电影进行更新：</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/quarkus-with-kafka-streams/en/resources/1topic-1656674518432.jpg\" /></p><p></p><p>但是，如果我们想要让movies主题与_playtimemovies_主题进行连接的话，那我们该选择使用哪个值为1的事件呢？第一个还是第二个？在这个具体的情况中，应该选择最新的那一个，因为它包含了电影的最新版本。为了获取每个事件的最新版本，Kafka Streams有一个_表_的概念（<a href=\"https://kafka.apache.org/28/javadoc/org/apache/kafka/streams/kstream/GlobalKTable.html\">KTable/GlobalKTable</a>\"）。</p><p></p><p>Kafka Streams会浏览指定的主题，获取每个事件的最新版本，并将其放到一个表实例中。</p><p></p><p>KafkaStream扩展并不会像Kafka Messaging集成那样自动注册<a href=\"https://kafka.apache.org/23/javadoc/org/apache/kafka/common/serialization/Serdes.html\">SerDes</a>\"，所以我们需要在拓扑中手动注册它们。</p><p></p><p><code lang=\"java\">package org.acme;\n\nimport javax.enterprise.context.ApplicationScoped;\nimport javax.enterprise.inject.Produces;\n\nimport org.apache.kafka.common.serialization.Serdes;\nimport org.apache.kafka.streams.KeyValue;\nimport org.apache.kafka.streams.StreamsBuilder;\nimport org.apache.kafka.streams.Topology;\nimport org.apache.kafka.streams.kstream.Consumed;\nimport org.apache.kafka.streams.kstream.GlobalKTable;\nimport org.apache.kafka.streams.kstream.KStream;\nimport org.apache.kafka.streams.kstream.Printed;\n\nimport io.quarkus.kafka.client.serialization.ObjectMapperSerde;\n\n@ApplicationScoped\npublic class TopologyProducer {\n\n   private static final String MOVIES_TOPIC = \"movies\";\n   private static final String PLAY_MOVIES_TOPIC = \"playtimemovies\";\n\n   @Produces\n   public Topology getTopCharts() {\n\n       final StreamsBuilder builder = new StreamsBuilder();\n\n// 用于Movie和PlayedMovie的SerDes\n\n       final ObjectMapperSerde movieSerder = new ObjectMapperSerde&lt;&gt;(Movie.class);\n       final ObjectMapperSerde moviePlayedSerder = new ObjectMapperSerde&lt;&gt;(MoviePlayed.class);\n\n    // 为Movies主题创建一个Global Kafka Table\n\n       final GlobalKTable moviesTable = builder.globalTable(\n               MOVIES_TOPIC,\n               Consumed.with(Serdes.Integer(), movieSerder));\n\n    // 连接至playtimemovies主题的流，每当该主题有事件生成都会被该流所消费\n\n       final KStream playEvents = builder.stream(\n               PLAY_MOVIES_TOPIC, Consumed.with(Serdes.String(), moviePlayedSerder));\n\n// PlayedMovies使用区域作为键，对象作为值。我们对内容进行map操作，让电影的id作为key（以便于进行连接）并让对象继续作为值\n// 另外，我们使用movies表的键（movieId）以及流的键（在前面的map方法中，我们也将其变成了movieId）进行连接\n\n// 最后，结果会流向控制台\n\n    playEvents\n           .map((key, value) -&gt; KeyValue.pair(value.id, value)) // Now key is the id field\n           .join(moviesTable, (movieId, moviePlayedId) -&gt; movieId, (moviePlayed, movie) -&gt; movie)\n           .print(Printed.toSysOut());\n       return builder.build();\n\n   }\n}\n</code></p><p></p><p>Movie和MoviePlayed POJO包含了实现逻辑所需的属性：</p><p></p><p>Movie对象如下所示：</p><p><code lang=\"java\">package org.acme;\n\npublic class Movie {\n\n   public int id;\n   public String name;\n   public String director;\n   public String genre;\n\n   public Movie(int id, String name, String director, String genre) {\n       this.id = id;\n       this.name = name;\n       this.director = director;\n       this.genre = genre;\n   }\n}\n</code></p><p></p><p>MoviePlayed对象如下所示：</p><p><code lang=\"java\">package org.acme;\n\npublic class MoviePlayed {\n\n   public int id;\n   public long duration;\n\n   public MoviePlayed(int id, long duration) {\n       this.id = id;\n       this.duration = duration;\n   }\n\n}\n</code></p><p></p><p>运行Kafka Stream应用之前的最后一步是配置参数，其中最重要的是quarkus.kafka-streams.topics。它是一个主题列表，在拓扑结构开始处理数据之前，它们就要存在于Kafka集群中，这是一个前提条件。</p><p></p><p>打开src/main/resources/application.properties文件并添加如下的代码行：</p><p><code lang=\"java\">kafka-streams.cache.max.bytes.buffering=10240\nkafka-streams.commit.interval.ms=1000\nkafka-streams.metadata.max.age.ms=500\nkafka-streams.auto.offset.reset=earliest\nkafka-streams.metrics.recording.level=DEBUG\n\nquarkus.kafka-streams.topics=playtimemovies,movies\n</code></p><p></p><p>现在，我们可以测试一下流了。我们启动在<a href=\"https://www.infoq.cn/article/cFpvXRLmZzJBGbzAeFu5\">上一篇文章</a>\"中开发的生产者。生产者的源码可以在<a href=\"https://github.com/lordofthejars/movie-plays-kafka/tree/main/movie-plays-producer\">这里</a>\"找到。</p><p></p><p>Quarkus KStreams集成了Quarkus DevServices。所以，我们不需要启动Kafka集群，也不需要配置它的位置，因为Quarkus Dev模式会处理好所有的事情。我们只需要记住在自己的计算机上要有一个运行中的容器环境即可，比如Podman或其他兼容OCI的工具。</p><p></p><p>在终端窗口中启动生产者服务：</p><p><code lang=\"java\">cd movie-plays-producer\n./mvnw compile quarkus:dev\n\n2022-04-11 07:49:31,900 INFO  [org.acm.mov.MovieKafkaGenerator] (executor-thread-0) movie Cruella played for 287 minutes\n2022-04-11 07:49:31,941 INFO  [io.quarkus] (Quarkus Main Thread) movie-plays-producer 1.0.0-SNAPSHOT on JVM (powered by Quarkus 2.7.3.Final) started in 4.256s.\n2022-04-11 07:49:31,942 INFO  [io.quarkus] (Quarkus Main Thread) Profile dev activated. Live Coding activated.\n2022-04-11 07:49:31,943 INFO  [io.quarkus] (Quarkus Main Thread) Installed features: [cdi, kafka-client, smallrye-context-propagation, smallrye-reactive-messaging, smallrye-reactive-messaging-kafka, vertx]\n2022-04-11 07:49:32,399 INFO  [org.acm.mov.MovieKafkaGenerator] (executor-thread-0) movie Encanto played for 162 minutes\n2022-04-11 07:49:32,899 INFO  [org.acm.mov.MovieKafkaGenerator] (executor-thread-0) movie The Hobbit played for 255 minutes\n2022-04-11 07:49:33,404 INFO  [org.acm.mov.MovieKafkaGenerator] (executor-thread-0) movie Sing 2 played for 264 minutes\n2022-04-11 07:49:33,902 INFO  [org.acm.mov.MovieKafkaGenerator] (executor-thread-0) movie Encanto played for 28 minutes\n2022-04-11 07:49:34,402 INFO  [org.acm.mov.MovieKafkaGenerator] (executor-thread-0) movie Star Trek: First Contact played for 137 minutes\n2022-04-11 07:49:34,903 INFO  [org.acm.mov.MovieKafkaGenerator] (executor-thread-0) movie Star Trek: First Contact played for 277 minutes\n2022-04-11 07:49:35,402 INFO  [org.acm.mov.MovieKafkaGenerator] (executor-thread-0) movie The Hobbit played for 141 minutes\n</code></p><p></p><p>在另一个终端窗口中，启动我们刚刚开发的Kafka Stream代码：</p><p><code lang=\"java\">./mvnw compile quarkus:dev\n\n2022-04-11 07:54:59,321 INFO  [org.apa.kaf.str.pro.int.StreamTask] (movie-plays-kstreams-22c86daa-cd28-4956-9d0d-57b6b282a2ea-StreamThread-1) stream-thread [movie-plays-kstreams-22c86daa-cd28-4956-9d0d-57b6b282a2ea-StreamThread-1] task [1_0] Restored and ready to run\n2022-04-11 07:54:59,322 INFO  [org.apa.kaf.str.pro.int.StreamThread] (movie-plays-kstreams-22c86daa-cd28-4956-9d0d-57b6b282a2ea-StreamThread-1) stream-thread [movie-plays-kstreams-22c86daa-cd28-4956-9d0d-57b6b282a2ea-StreamThread-1] Restoration took 74 ms for all tasks [1_0]\n2022-04-11 07:54:59,322 INFO  [org.apa.kaf.str.pro.int.StreamThread] (movie-plays-kstreams-22c86daa-cd28-4956-9d0d-57b6b282a2ea-StreamThread-1) stream-thread [movie-plays-kstreams-22c86daa-cd28-4956-9d0d-57b6b282a2ea-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING\n2022-04-11 07:54:59,324 INFO  [org.apa.kaf.str.KafkaStreams] (movie-plays-kstreams-22c86daa-cd28-4956-9d0d-57b6b282a2ea-StreamThread-1) stream-client [movie-plays-kstreams-22c86daa-cd28-4956-9d0d-57b6b282a2ea] State transition from REBALANCING to RUNNING\n[KSTREAM-LEFTJOIN-0000000005]: 4, Movie [director=Craig Gillespie, genre=Crime Comedy, id=4, name=Cruella]\n[KSTREAM-LEFTJOIN-0000000005]: 2, Movie [director=Jonathan Frakes, genre=Space, id=2, name=Star Trek: First Contact]\n[KSTREAM-LEFTJOIN-0000000005]: 4, Movie [director=Craig Gillespie, genre=Crime Comedy, id=4, name=Cruella]\n[KSTREAM-LEFTJOIN-0000000005]: 1, Movie [director=Peter Jackson, genre=Fantasy, id=1, name=The Hobbit]\n[KSTREAM-LEFTJOIN-0000000005]: 4, Movie [director=Craig Gillespie, genre=Crime Comedy, id=4, name=Cruella]\n[KSTREAM-LEFTJOIN-0000000005]: 4, Movie [director=Craig Gillespie, genre=Crime Comedy, id=4, name=Cruella]\n[KSTREAM-LEFTJOIN-0000000005]: 3, Movie [director=Jared Bush, genre=Animation, id=3, name=Encanto]\n[KSTREAM-LEFTJOIN-0000000005]: 5, Movie [director=Garth Jennings, genre=Jukebox Musical Comedy, id=5, name=Sing 2]\n</code></p><p></p><p>在输出中打印的是事件（连接所生成的结果），其中键是movieId，值是movie本身。我们现在所具有的功能是，每当一个电影停止播放时，Kafka Stream会对其进行处理并以Movie全量信息的形式对其进行展现。</p><p></p><p>到目前为止，还不算复杂，对于这样的场景，你可能会想我们根本没有必要使用Kafka Streams。但是，我们再加一些需求，这样你就能看到它的强大之处了。</p><p></p><p>现在，我们不是在用户每次停掉电影的时候都生成事件，而是只对用户观看时间超过10分钟的电影发送事件。</p><p></p><p>我们可以使用filter方法按照持续时长进行过滤。</p><p><code lang=\"java\">playEvents\n       .filter((region, event) -&gt; event.duration &gt;= 10) // filters by duration\n       .map((key, value) -&gt; KeyValue.pair(value.id, value))\n       .join(moviesTable, (movieId, moviePlayedId) -&gt; movieId, (moviePlayed, movie) -&gt; movie)\n        .print(Printed.toSysOut());\n</code></p><p></p><p>重启应用，我们可以发现观看时长小于10分钟的电影将不会被处理。</p><p></p><p>我们发现，Kafka Streams有助于代码的整洁性，接下来，我们添加最后的需求。现在，我们对每部电影的播放时长并不感兴趣，而是对每部电影有多少次超过10分钟的播放感兴趣。</p><p></p><p>到目前为止，对事件的处理都是无状态的，因为事件都是遵循这样的步骤，即接收、处理并发送至sink处理器（也就是发送至一个主题或控制台输出），但是，为了统计某部电影播放的次数，我们需要在内存记住电影被播放了多少次，并且当任意用户再次观看超过10分钟的时候，要对这个统计数字递增一次。此时，事件的处理就要以有状态的方式进行了。</p><p></p><p>我们需要做的第一件事就是创建一个Java类，以存储电影的名称及其播放的次数。</p><p><code lang=\"java\">public class MoviePlayCount {\n   public String name;\n   public int count;\n\n   public MoviePlayCount aggregate(String name) {\n       this.name = name;\n       this.count++;\n\n       return this;\n   }\n\n   @Override\n   public String toString() {\n       return \"MoviePlayCount [count=\" + count + \", name=\" + name + \"]\";\n   }\n\n}\n</code></p><p></p><p>这是一个计数器类，它依然需要两样东西：</p><p></p><p>我们需要有一个地方存储这个类的实例，确保每次触发事件的时候，它不会被重置。每当_playtimemovies_主题中有事件触发时，调用aggregate方法的逻辑。</p><p></p><p>关于第一个问题，我们需要使用<a href=\"https://kafka.apache.org/28/javadoc/org/apache/kafka/streams/state/KeyValueBytesStoreSupplier.html\">KeyValueBytesStoreSupplier</a>\"接口。</p><p></p><p><code lang=\"java\">public static final String COUNT_MOVIE_STORE = \"countMovieStore\";\n\nKeyValueBytesStoreSupplier storeSupplier = Stores.persistentKeyValueStore(COUNT_MOVIE_STORE);\n</code></p><p></p><p>对于第二个问题，Kafka Streams有一个用来聚合结果的aggregate方法。</p><p></p><p>在我们的用例中，也就是每部电影播放时长超过10分钟的次数。</p><p></p><p><code lang=\"java\">// MoviePlayCount可以被序列化和反序列化\nObjectMapperSerde moviePlayCountSerder = new ObjectMapperSerde&lt;&gt;(MoviePlayCount.class);\n\n// 这是之前的连接操作，其中键是电影id，值是电影\n.join(moviesTable, (movieId, moviePlayedId) -&gt; movieId, (moviePlayed, movie) -&gt; movie)\n// 根据键对事件进行分组，在本例中，也就是电影的id\n.groupByKey(Grouped.with(Serdes.Integer(), movieSerder))\n // 聚合方法，如果MoviePlayCount已经创建的话，获取该对象（如果尚未创建的话，会创建该实例）并调用其aggregate方法，以对观看次数进行递增\n .aggregate(MoviePlayCount::new,\n             (movieId, movie, moviePlayCounter) -&gt; moviePlayCounter.aggregate(movie.name),\n              Materialized. as(storeSupplier)\n                  .withKeySerde(Serdes.Integer())\n                  .withValueSerde(moviePlayCountSerder)\n             )\n</code></p><p></p><p>重启应用，在控制台上将会展示电影播放的次数。</p><p></p><p>提示：要重启应用，只需在终端输入“s”，应用将会自动重启。</p><p></p><p>应用重启之后，控制台将会展示每部电影的状态。</p><p></p><p><code lang=\"java\">[KTABLE-TOSTREAM-0000000011]: 4, MoviePlayCount [count=13, name=Cruella]\n[KTABLE-TOSTREAM-0000000011]: 3, MoviePlayCount [count=11, name=Encanto]\n[KTABLE-TOSTREAM-0000000011]: 5, MoviePlayCount [count=14, name=Sing 2]\n[KTABLE-TOSTREAM-0000000011]: 2, MoviePlayCount [count=15, name=Star Trek: First Contact]\n[KTABLE-TOSTREAM-0000000011]: 1, MoviePlayCount [count=16, name=The Hobbit]\n[KTABLE-TOSTREAM-0000000011]: 2, MoviePlayCount [count=16, name=Star Trek: First Contact]\n[KTABLE-TOSTREAM-0000000011]: 3, MoviePlayCount [count=12, name=Encanto]\n[KTABLE-TOSTREAM-0000000011]: 2, MoviePlayCount [count=17, name=Star Trek: First Contact]\n[KTABLE-TOSTREAM-0000000011]: 5, MoviePlayCount [count=15, name=Sing 2]\n[KTABLE-TOSTREAM-0000000011]: 4, MoviePlayCount [count=14, name=Cruella]\n[KTABLE-TOSTREAM-0000000011]: 1, MoviePlayCount [count=17, name=The Hobbit]\n[KTABLE-TOSTREAM-0000000011]: 4, MoviePlayCount [count=15, name=Cruella]\n[KTABLE-TOSTREAM-0000000011]: 4, MoviePlayCount [count=16, name=Cruella]\n</code></p><p></p><p>交互式查询</p><p></p><p>因为我们将_sink_处理器设置成了System.out 流，所以聚合结果会流向控制台。</p><p></p><p><code lang=\"text\">.toStream()\n.print(Printed.toSysOut());\n</code></p><p></p><p>但是，我们也可以将结果流发往一个Kafka主题：</p><p></p><p><code lang=\"text\">.to(\"counter_movies\",                      Produced.with(Serdes.Integer(), moviePlayCountSerder)\n);\n</code></p><p></p><p>但是，如果我们感兴趣的不是每次对新事件的反应，而只是想查询特定的电影此时播放的次数，那又该怎么办呢？</p><p></p><p>Kafka Streams的交互式查询(interactive query)允许我们直接查询底层存储，以获取给定键相关的值。</p><p></p><p>首先，我们创建一个名为MoviePlayCountData的类来存储查询结果。按照这种方式，我们可以解耦Kafka Streams使用的类与应用中其他部分所使用的类。</p><p></p><p><code lang=\"java\">public class MoviePlayCountData {\n\n   private String name;\n   private int count;\n\n   public MoviePlayCountData(String name, int count) {\n       this.name = name;\n       this.count = count;\n   }\n\n   public int getCount() {\n       return count;\n   }\n\n   public String getName() {\n       return name;\n   }\n\n}\n</code></p><p></p><p>现在，创建名为InteractiveQueries的类来实现对状态存储（KeyValueBytesStoreSupplier）的访问并根据电影的id查询它被播放的次数。</p><p></p><p><code lang=\"java\">import javax.enterprise.context.ApplicationScoped;\nimport javax.inject.Inject;\n\nimport org.apache.kafka.streams.KafkaStreams;\nimport org.apache.kafka.streams.errors.InvalidStateStoreException;\nimport org.apache.kafka.streams.state.QueryableStoreTypes;\nimport org.apache.kafka.streams.state.ReadOnlyKeyValueStore;\n\nimport static org.apache.kafka.streams.StoreQueryParameters.fromNameAndType;\n\nimport java.util.Optional;\n\n@ApplicationScoped\npublic class InteractiveQueries {\n\n   @Inject\n   KafkaStreams streams;\n\n   public  getMoviePlayCountData(int id) {\n       // 获取状态存储并根据电影id获取播放次数\n       MoviePlayCount moviePlayCount = getMoviesPlayCount().get(id);\n       // 如果有结果的话\n       if (moviePlayCount != null) {\n           // 将结果包装到MoviePlayCountData中\n           return Optional.of(new MoviePlayCountData(moviePlayCount.name, moviePlayCount.count));\n       } else {\n           return Optional.empty();\n       }\n   }\n\n   // 获取状态存储\n   private ReadOnlyKeyValueStore getMoviesPlayCount() {\n       while (true) {\n           try {\n               return streams.store(fromNameAndType(TopologyProducer.COUNT_MOVIE_STORE, QueryableStoreTypes.keyValueStore()));\n           } catch (InvalidStateStoreException e) {\n               // 忽略之，此时存储尚未就绪\n           }\n       }\n   }\n\n}\n</code></p><p></p><p>现在，我们可以添加一个简单的REST端点来运行该查询。</p><p><code lang=\"java\">import java.util.Optional;\n\nimport javax.inject.Inject;\nimport javax.ws.rs.GET;\nimport javax.ws.rs.Path;\nimport javax.ws.rs.PathParam;\nimport javax.ws.rs.core.Response;\nimport javax.ws.rs.core.Response.Status;\n\n@Path(\"/movie\")\npublic class MovieCountResource {\n\n   // 注入前文的类进行查询\n   @Inject\n   InteractiveQueries interactiveQueries;\n\n   @GET\n   @Path(\"/data/{id}\")\n   public Response movieCountData(@PathParam(\"id\") int id) {\n       Optional moviePlayCountData = interactiveQueries.getMoviePlayCountData(id);\n\n       // 根据结果判定返回值还是404\n       if (moviePlayCountData.isPresent()) {\n           return Response.ok(moviePlayCountData.get()).build();\n       } else {\n           return Response.status(Status.NOT_FOUND.getStatusCode(),\n                   \"No data found for movie \" + id).build();\n       }\n\n   }\n}\n</code></p><p></p><p>Kafka Stream实现的模式如下图所示：</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/quarkus-with-kafka-streams/en/resources/1topology-1656674518432.jpeg\" /></p><p></p><h3>扩展</h3><p></p><p>Kafka Streams应用可以进行扩展，所以流会分布到多个实例中。在这种情况下，每个实例都包含聚合结果的一个子集，所以要想获得总的聚合结果，我们需要通过将REST API重定向到另外的实例来获取其他实例的数据。</p><p></p><p>Kafka Streams提供了一个<a href=\"https://kafka.apache.org/28/javadoc/org/apache/kafka/streams/KafkaStreams.html#allMetadataForStore(java.lang.String)\">API</a>\"，可以知道要请求的数据是在本地Kafka Streams存储中还是在其他的主机中。</p><p></p><p>虽然这个过程并不复杂，但已经超出了本文的讨论范围。</p><p></p><h2>结论</h2><p></p><p>到目前为止，我们已经看到，将Quarkus应用连接到Apache Kafka并生产和消费主题中的消息/事件是很容易的。此外，还看到Kafka Streams让我们不仅可以消费Kafka中消息，还能够实时处理它们，进行转换、过滤等操作，例如以同步的方式消费结果数据。 这是一项强大的技术，当需要处理的数据不断变化时，它可以轻松扩展，提供实时的体验。</p><p></p><p>但是，我们还没有解决该架构的最后一个问题。通常情况下，数据并不是存储在一个地方。电影信息可能存储在关系型数据库中，而电影的播放信息则存储在一个Kafka主题中。那么，该如何保持这两个地方的信息更新，以便Kafka Streams能正确地连接数据呢？</p><p></p><p>这里有一个缺失的部分，名为Debezium的项目可以帮助我们解决这个问题。我们将用一整篇文章来介绍Debezium和Quarkus，敬请持续关注。</p><p></p><p>作者简介：</p><p>Alex Soto是红帽公司的开发者体验总监。他对Java领域、软件自动化充满热情，他相信开源软件模式。Soto是Manning的《Testing Java Microservices》和O’Reilly的《Quarkus Cookbook》两本书的共同作者，他还是多个开源项目的贡献者。自 2017 年以来，他一直是Java Champion，是国际演讲者和Salle URL 大学的教师。你可以在 Twitter 上关注他（<a href=\"https://twitter.com/alexsotob\">Alex Soto </a>\"），随时了解 Kubernetes 和 Java 领域的动态。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/quarkus-with-kafka-streams/\">Kafka Streams and Quarkus: Real-Time Processing Events</a>\"</p><p></p><p>相关阅读：</p><p>本系列第一部分：<a href=\"https://www.infoq.cn/article/cFpvXRLmZzJBGbzAeFu5\">使用 Apache Kafka 实现 Quarkus 的反应式消息</a>\"</p>",
    "publish_time": "2022-08-25 11:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "4年后，苹果汽车前工程师张小浪认罪，小鹏汽车回应：与案件无任何关联",
    "url": "https://www.infoq.cn/article/Tka0o4X29AGFhPX6F2eg",
    "summary": "<p>在跳槽小鹏前窃取苹果汽车商业机密的张小浪正式认罪，小鹏汽车回应：与案件无任何关联。</p><p></p><h2>前苹果员工张小浪正式认罪</h2><p></p><p></p><p>8月22日，美国联邦法院提交的一份刑事起诉书显示，美国有关部门指控一名苹果前雇员窃取商业机密，称此人将一份与自动驾驶汽车有关的商业机密文件下载到了个人笔记本电脑，随后试图逃离美国。</p><p></p><p>起诉书称，这名苹果前员工张小浪(Xiaolang Zhang)透露了其为一家中国自动驾驶汽车初创公司工作的意图，其在下载了苹果自动驾驶汽车电路板的计划后，在最后一刻预订了飞往中国的航班。2018年7月，该员工在圣何塞机场通过安检后被警方逮捕。</p><p></p><p>当时，苹果在一份声明中表示:“苹果非常重视保密和保护我们的知识产权。”“我们正在与有关部门就此事进行合作，并将尽一切可能确保此人和任何其他涉案人员为自己的行为负责。”</p><p></p><p>张最初对这些指控不认罪。如今，在持续了4年后，该案迎来最新进展，这名苹果前雇员于8月22日在圣何塞的联邦法院认罪。他已与检察官达成认罪协议，并将认罪改为有罪。</p><p></p><p><a href=\"https://storage.courtlistener.com/recap/gov.uscourts.cand.329276/gov.uscourts.cand.329276.72.0.pdf\">根据本周一提交的法庭文件，</a>\"张小浪与美国政府的认罪协议已经盖章并密封。在承认犯有盗窃商业机密的重罪后，张将面临长达 10 年的监禁和 25 万美元的罚款。据悉，张的律师证实了认罪协议，但拒绝进一步置评。该案件定于今年 11 月宣判。</p><p></p><p>张小浪被指控下载了有关苹果公司汽车项目的内部文件。具体来说，这是一份 25 页的文件，其中包括自动驾驶汽车电路板的工程原理图。张小浪还被指控使用描述苹果原型和原型要求的参考手册和 PDF。</p><p></p><p>根据联邦调查局和美国检察官办公室的收费文件，张小浪自 2015 年以来一直在苹果公司工作，其最后一份职务是担任苹果自动驾驶汽车团队的硬件工程师。</p><p></p><p>这些指控让人们窥见了苹果公司甚至多年后仍然不经常承认的秘密的一面：其部门正在开发自动驾驶电动汽车。</p><p></p><p>在 2018 年的指控文件中，一名 FBI 特工表示，该公司有大约 5,000 名“被披露”的员工，这意味着他们了解该项目，还有 2,700 名“核心员工”可以访问项目材料和数据库。</p><p></p><p>一份投诉称，苹果使用内部软件来跟踪哪些员工在哪些项目上被披露，并被要求参加面对面的保密培训。张小浪在苹果公司自动驾驶汽车项目的计算团队工作，该团队为传感器设计和测试电路板。电路设计的原理图被认为是电子行业最有价值的商业机密之一。</p><p></p><p>苹果首先怀疑张小浪在休陪产假并前往中国后窃取了商业机密。根据 2018 年的投诉，当他回到公司时，他递交了辞呈，说他想回到中国。苹果的一项调查发现，张小浪从公司数据库中下载了文件和信息。苹果闭路摄像头甚至拍到张小浪进实验室并拆除硬件 —— 后来被确定为电路板和 Linux 服务器。</p><p></p><p>当时张告诉苹果，他计划为中国的电动汽车公司 Xmotors（小鹏） 工作。</p><p></p><p>8月23日，张小浪在2018年离开苹果后加入的小鹏汽车在其新浪微博上发布了一则声明回应此事。小鹏汽车表示：</p><p></p><p></p><blockquote>我们今日从媒体上获悉前苹果员工张小浪涉嫌窃取苹果商业秘密案件的最新进展。案件至今已经四年多，小鹏汽车并不了解案件的具体情况，也未介入美国司法机关对案件的后续调查，我们与苹果公司之间也没有相关的争议，与该案件也无任何关联。小鹏汽车严格遵守相关法律，高度重视知识产权保护。小鹏汽车是中国自动辅助驾驶的领军企业，会继续坚持全栈自研的路线。感谢各位对事实的理解和支持。</blockquote><p></p><p></p><p>据凤凰科技报道，美国格知律师事务所合伙人、知名律师叶俊，知名 IT 与知识产权律师赵占领律师均认为，没有任何证据能证明，张小浪的窃密行为受小鹏汽车指示，或相关机密、技术被小鹏汽车使用。赵占领认为，从目前的信息来看，此案的审理过程中，苹果与检方均未对小鹏提起诉讼或进行调查，也表明此案件实际是苹果和离职华裔员工个人的之间的纠纷，和小鹏公司无关。苹果保护自己知识产权，张小浪只要有被苹果认定的不良行为，就会被调查，与他去哪工作无关。</p><p></p><h2>事件回溯</h2><p></p><p></p><p>我们再来回顾下整个事件的来龙去脉。</p><p></p><p>已经公开的资料显示，涉案人员张某，本科毕业于东南大学，后在英属哥伦比亚大学获得电子与电脑工程学的硕士学位。</p><p></p><p>张某 2015 年 12 月进入苹果公司工作，参与苹果无人驾驶汽车 Project Titan 的项目研发，主要负责设计和测试用来分析传感器数据的线路板。</p><p></p><p>因为工作性质的原因，张某获得了苹果公司“加密安全数据库”的广泛使用权，拥有许多苹果公司无人驾驶技术相关加密信息及专利的访问权。据了解，张某在被苹果聘用时，签署了一份知识产权协议，并参加了苹果组织的强制性保密培训。</p><p></p><p>2018年 4 月，在以休产假为由回到中国之后，张某告知苹果，自己准备离职，并加入位于广州的专注于国产无人车的研究的初创公司 XMotors（小鹏汽车）。</p><p></p><p>据外媒报导，法院的相关文件显示了一些细节：提出离职后，张某的上级对他在公司例会上所表现出的刻意回避产生了怀疑，在管理层的要求下，苹果新成立的产品安全团队（Product Security Team）对张某展开了调查，翻看了他离职时还给公司的 2 部工作用 iPhone 和 1 台笔记本电脑。</p><p></p><p>苹果公司发现，就在张某离职之前，他在公司内部网上的活动，与他前两年工作时相比“呈指数增长”。</p><p></p><p>法院文件显示，那段时间张某在网上做的最多的两件事，就是批量搜索，以及从加密数据库中下载大量信息。</p><p></p><p>苹果产品安全团队找张某进行了面谈，面对铁证，他最终承认自己在休产假时从苹果实验室里带走了一些网上的数据资料，以及包括一个 Linux 服务器和几个线路板在内的硬件设备。他还承认使用 AirDrop 把下载下来的资料数据，传到了妻子的笔记本电脑里。</p><p></p><p>FBI 通过调查发现，张某传到妻子电脑里的资料，60% 为高级别的加密信息，涉及到了人工智能技术的研发、测试和调试等各个阶段。</p><p></p><p>当时案发后，小鹏汽车2018年发布的声明显示，张某在 5 月初入职当天签署了知识产权合规文件，没有记录显示他向小鹏汽车上报任何敏感和违规的情况。当公司在 6 月 27 日获悉美国当地相关部门对张某的调查时，已按照规定封存了张某的电脑和办公用品，并将继续积极配合关于此事的相关调查。</p><p></p><h2>自动驾驶车企频发员工盗窃商业机密案</h2><p></p><p></p><p>近几年，自动驾驶车企频频发生内部员工盗窃公司商业机密案件。</p><p></p><p>值得注意的是，小鹏汽车已卷入多起华人工程师窃密案。在该案之外，2019 年 1 月，苹果前美籍华裔硬件工程师陈继忠 (Jizhong Chen) 因涉嫌窃取苹果电动汽车部门商业机密被起诉。苹果发现陈继忠已向一家与苹果在无人自动驾驶车项目开发具有竞争关系的中国公司投了简历，疑似是小鹏汽车，被小鹏汽车否认。目前，陈没有认罪，其案件由与张相同的律师代理。他的法庭听证会定于今年 8 月 29 日举行。</p><p></p><p>特斯拉也曾起诉过小鹏汽车工程师窃取商业机密。2019 年 7月11日，据外媒<a href=\"https://www.theverge.com/2019/7/10/20689468/tesla-autopilot-trade-secret-theft-guangzhi-cao-xpeng-xiaopeng-motors-lawsuit-filing\">The  Verge</a>\"报道，前特斯拉员工曹光植在本周新提交的法庭文件中承认，他曾在2018年底将包含Autopilot源代码的zip文件上传到他个人的iCloud账户。但同时，曹光植否认窃取了特斯拉的敏感信息，他的律师称，在从特斯拉离职之前，曹光植已经认真的删除了与特斯拉相关的资料。</p><p></p><p>据悉，曹光植此前是特斯拉负责高级驾驶辅助系统的40名雇员之一，他有权直接访问AUTOPILOT源代码。2019年3月，特斯拉向已经加入小鹏汽车担任“感知负责人”的曹光植发起了诉讼，特斯拉指控曹光植自2018年年底开始陆续向他的个人iCloud账户上传“特斯拉自动驾驶仪相关源代码的完整副本”，他压缩并移动了超过30万个与Autopilot相关的文件和目录。</p><p></p><p>特斯拉这几年不是在打官司就是在打官司的路上，公司内部员工泄密案高发。</p><p></p><p>2020年12月，特斯拉与其前工艺技术人员Martin Tripp达成了和解，后者承认泄露了机密信息。双方的官司打了2年多时间，起因是Martin Tripp指责特斯拉在生产Model 3时浪费了大量原材料。诉讼中，特斯拉认为，Tripp入侵了电动汽车公司的系统并将“千兆字节”的数据传输给了第三方。</p><p></p><p>2020年7月，特斯拉对四名前员工发起了诉讼，特斯拉发现，这四名前员工涉嫌将特斯拉的机密信息携带到了电动汽车初创公司Rivian。而且，Rivian其实在“故意鼓励”这种行为，特斯拉将对其恶意行为寻求惩罚性赔偿。诉讼中，特斯拉表示已有两名被告承认接受机密信息，其中一位曾担任特斯拉的人事高级经理，在她接受Rivian的offer的第二天，她就从特斯拉的网络中至少获取了十份机密和专有文件”，包括候选人名单及详细的内部书面记录等。</p><p></p><p>2019年初，特斯拉还对无人驾驶初创公司Zoox 提起了诉讼，指控4名曾在特斯拉工作过的Zoox员工将有关特斯拉制造业的专有信息和商业机密带给了Zoox，并帮助这家公司跳过了过去几年开发和运行自己的仓储、物流和库存控制业务所需的工作。在经过了一年多的诉讼后，该案件于2020年4月迎来关键进展，双方达成和解。Zoox承认其四名员工从其前任雇主特斯拉那里获取了有关运输、接收和仓库程序的机密文件。Zoox承诺将向特斯拉支付一笔未公开的款项赔偿。</p><p></p><p><=\"\" p=\"\"></p><p></p><p>title=\"微软认为AutoML不够用，智能系统才是未来！\"</p><p></p><p>link=\"\"&gt;</p><p></p><p></p><p></p><p><img src=\"https://static.geekbang.org/infoq/5c6947ecc1649.png\" /></p><p></p>",
    "publish_time": "2022-08-25 14:11:39",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "SaaS 创业者的世界里没有风口，只有客户需求",
    "url": "https://www.infoq.cn/article/mGWsrgj8sWVCHQjqe62W",
    "summary": "<p></p><blockquote>编者按：在企业数字化转型升级的浪潮下，近几年，国内 SaaS 赛道显得格外火热。对 SaaS 创业者而言，风口真的来了吗？极客邦科技创始人兼 CEO 霍太稳认为，SaaS 创业者的世界里没有风口，只有用户和客户需求。一个创业者、企业家最重要的就是要敏锐地去发现问题，然后去执着地解决问题。&nbsp;对于那些新入局的 SaaS 创业者，微梦传媒/爱设计 CEO 赵充认为必须要关注四件事：找钱、找人、找方向、修炼心性。SaaS 创业前期需要非常多的粮草，先投入产品研究，再做市场营销，之后才能逐步产生收入；早期要考虑的竞争维度比较多，不仅要找内部团队的人，也要找外部的人；to B 和 to C 的业务模型不同，需要的人也不太一样，创业者需要提前考虑好方向；SaaS 业务从产品调研、上线再到商业化整个周期较长，创业者需要有内心，磨炼心性。</blockquote><p></p><p>&nbsp;</p><p>本期《超级连麦》，我们邀请到了微梦传媒/爱设计 CEO 赵充，和极客邦科技创始人兼 CEO 霍太稳（Kevin），InfoQ 极客传媒生态总监张昂，共话内容 SaaS 赛道的实践与认知。内容有删减，感兴趣的同学可进入“霍太稳视频号”观看直播回放。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/e2/10/e283cba6d9aefde07bbe2206b12ed410.jpg\" /></p><p></p><h4>为什么投身内容创业？当前这条赛道还是风口吗？</h4><p></p><p>&nbsp;</p><p>赵充：Kevin 算是标准的内容创业，我们还不算标准的内容创业，我们属于内容科技。我是从 2011 年开始创业的，之前在新浪负责自媒体商业化，也正是因为这段经历的影响，所以我的第一个创业项目“<a href=\"http://www.microdreams.com/\">微梦传媒</a>\"”主营业务就是新媒体营销。微梦的商业模式说起来也比较简单，底层就是新媒体数据能力，基于新媒体的数据去做双边市场。一侧是微博、微信、抖音、小红书、B 站等社交媒体的内容创作者，另一侧就是服务于大型的广告主如阿里、腾讯。主要做的事情集中在新媒体营销/传播层面，主要包含数据、内容、媒介三个版块。</p><p>&nbsp;</p><p>后来，我们做到一定规模，就开始思考内容传播的上游，内容生产侧还有什么事情可以做。我们服务的了几百个大型企业，他们提出了对内容生产的需求，包括新媒体侧内容高效生产的需求。于是我们从 2017 年开始立项，并孵化了第一个产品——<a href=\"https://www.365editor.com/\">365 编辑器</a>\"。很快就做到了几百万用户，以新媒体小编的用户人群为主，当然这是个比较细分的赛道。不过就是从这开始，我们接触到了一些在线设计的工具公司有流量合作的需求，因为用户画像是高度匹配的，于是我们就自己孵化了<a href=\"https://www.isheji.com/\">爱设计</a>\"isheji.com，开始去做在线设计工具。一开始，爱设计是 to C 的，跟 365 编辑器的商业模式一样，后来开始往 B 端走。视觉中国战投了我们，帮我们补齐上游版权侧的资源，同时我们也开始服务 B 端，后来又增加了内容中台和创意众包的业务，帮企业提供创意的 SaaS，并做内容生产。</p><p>&nbsp;</p><p>霍太稳：赵充把他的整个业务介绍了一下。赵充是一个典型的年轻创业者，也是一个典型的连续创业者。他的公司很早就已经在新三板上市了，在上市的过程中又去持续开拓一些新的业务，而且业务与业务之间有非常强烈的关联。原来可能是做像广告类的一些业务，现在又去做内容科技，赶上 SaaS 这样一个浪潮。我最近正好在清华经管 EMBA 上课，老师说了一个理念，他说对一个创业者、企业家来讲，最重要的就是要敏锐地去发现问题，然后去执着地解决问题，赵充就是这样一个非常典型的创业者和企业家。</p><p>&nbsp;</p><p>我简单说一下极客邦科技，我是认为“风口”固然重要，但最主要的还是来自用户和客户的需求。极客邦科技存在了 15 年，在 15 年前，我们做 InfoQ 的时候，就认为中国的程序员这类数字人才需要去看一些来自国外最新的技术资讯，很多内容在国内是没有的，我就组织很多志愿者去把 InfoQ 英文站的内容翻译成中文，再把其他国际上非常优秀的技术社区里的内容翻译过来。我们在 2007 年开始做 InfoQ，当时整个 InfoQ 中国团队没有研发的力量，我们是和国际团队一起用罗马尼亚的研发团队。</p><p>&nbsp;</p><p>2017 年，我们开始做极客时间，开始正式组建研发团队，做了极客时间 APP，并邀请一些专家到我们 APP 平台上去创作内容。极客时间算是一个内容科技方向的创业，相当于把内容和科技正式连在一起了。一开始，极客时间 APP 是一个面向个人的知识服务平台，2019 年，我们开始做极客时间企业版。因为我认为，做培训，尤其是做数字人才的培训，刚需还是在企业里，企业希望他的员工能够去更好地掌握一些技能，在企业的发展过程中发挥作用。</p><p></p><h4>创业过程中，踩过哪些坑？</h4><p></p><p>&nbsp;</p><p>赵充：爱设计早期踩了不少坑，也花了不少钱。前期我们做 365 编辑器，它的盈利模型很简单，就是在搜索市场上去买量，买量之后就看用户充值的收入和ROI。我们当时认为如果上线爱设计，它的受众面比 365 编辑器的受众面要大很多。因为像 365 编辑器潜在的用户可能就一两千万，主要是公众号企业或者自媒体在用。但在国内，设计的受众可能得大几千万，甚至是一个亿的市场规模，如果我们再上线一个同样的产品，用同样的模型去跑就是轻而易举，但是事实上却踩了坑。</p><p>&nbsp;</p><p>因为爱设计的变现模型的ROI没有 365 编辑器那么高，365 编辑器有搜微信公众号编辑器或者搜微信编辑器进来的用户，有很高的匹配率。但是像在线设计、设计这些关键词比较泛，它的匹配率要低很多。盈利模型大概是一个月投放一百万，可能回来很少的比例；下个月再投放一百万，当月回收一部分收入，同时上个月再滚下来一部分收入。但是整个回收周期拉得很长，可能要八到十个月，甚至更长的时间才能收回来钱。如果完全按照 to C 的作战方式去打，可能几千万资金要打出去才能看看有没有可能回来钱。这是我们当时踩过的一个坑。</p><p>&nbsp;</p><p>但是后来我们也在从坑里面往外爬，我们果断地把业务模型调整成了 to B 这样的方式，先重点去做 to B。我们毕竟做了十几年的 to B，还是有些资源的积累，包括也拉了视觉中国这样的战投方进来一起去做 to B 的市场。</p><p>&nbsp;</p><p>霍太稳：我们也踩过一些坑，比如，在微信公众号刚出来的时候，在 2013 年，我就马上注册了 InfoQ 的公众号，但是迟迟没有动，为什么？因为我当时的思维就是我们的客户、用户是在 InfoQ 网站上，我如果去做 InfoQ 的公众号，会不会让 InfoQ 网站的资源受限？直到两年之后，公众号已经风生水起了，我们才开始去做。但是在这两年的时间里，微信公众号的红利基本上消耗得差不多了，在这种情况下，相当于别人已经跑得比较靠前了，你再去追，难度就会非常大。当然，现在 InfoQ 的微信公众号已经拥有超过百万的粉丝，我们花了很大的代价最终才赶上来。</p><p>&nbsp;</p><p>这个坑给我的启示就是：对于一些新生的事物，你要保持非常敏锐的观察，而且要实时和它保持同步，也看一下周围的同学是怎么去做的，这时候千万不要静止不动，你可以做一些小范围的尝试，就像 MVP 一样，如果说一旦有效果，马上进行大规模跟进。这样，就可以让你在红利期做很多事半功倍的事情。</p><p></p><h4>SaaS 内容平台在 to B、to C 两个方向分别要有哪些运营策略？</h4><p></p><p>&nbsp;</p><p>赵充：我做这些决策主要还是基于一些市场分析。从市场上来讲，短期来看，如果只做国内的 C 端市场，获客成本不低，留存也不高，比较难变现。但如果做 B 端市场就会好很多，客单价很高，续费的稳定性也比较高。从我们自身来讲，我们毕竟做了十几年的 B 端，也积累了很多方法。</p><p>&nbsp;</p><p>具体来说，C 端用户主要在意两件事，一是产品体验够不够好，二是内容版权的丰富度跟品质是不是足够高，当你把这两个做好之后，就可以开始通过流量助推了。未来我们会选择在海外主打 C 端市场，一次性把产品的内容做好了之后，去打全球市场，这样就摊薄了成本。</p><p>&nbsp;</p><p>B 端用户就是企业，它的需求层次会更多，要看的层面也会更多。比如，你的版权是不是有保证，工具是不是好用，协作管理是不是足够好，有没有分发能力，有没有内容生产能力，等等。在 B 端打市场，我们基本上是 SLG（Sales-led Growth，销售驱动增长）为主，MLG（Marketing-led Growth，营销驱动增长）为辅，带一点点 PLG（Product-led Growth，产品驱动增长）。</p><p>&nbsp;</p><p>霍太稳：C 端和 B 端还是有非常大的区别。比如，C 端对价格非常敏感，我们极客时间 APP 上的很多专栏，有的定价 129 元，有的定价 99 元，有的定价 69 元。如果某天 129 元的专栏降价至 99 元，就会新增很多销量。但是对于 B 端用户来说，价格不是他们首要考虑的因素，他们最关注的是你的平台、内容和服务，比如极客时间企业版能不能帮助员工有效地提升数字化能力。他们使用你的平台，是为员工节省了时间，提升了能力，还是说浪费了时间，并且没有提升能力。这是非常大的区别。</p><p>&nbsp;</p><p>我们在设计产品的过程中，对于 C 端来讲，需要考虑到这部分人对价格是相对比较敏感的；对于 B 端来讲，需要考虑你能不能对企业有价值，让企业觉得用你的产品，员工的收获和体验都是非常好的。</p><p>&nbsp;</p><p>另外，C 端和 B 端还有一个区别在于，C 端对产品体验的要求非常高，每个 C 端用户的手机上装了好多个 APP，他们已经养成各种各样的习惯。如果你的产品体验不好，或者性能不好，他可能马上就卸载掉，甚至看都不看，这是 C 端的特点。但是对于 B 端，做产品设计时主要考虑的是实用性和专业性，只要产品功能是符合企业需求的，员工都是愿意去用的。</p><p></p><h4>如何看待“内容为王”与“技术为王”？如何更好地以技术赋能内容，以及如何赋能客户和用户？</h4><p></p><p>&nbsp;</p><p>赵充：我们给用户/客户交付的是结果，对于我们的用户/客户来说，无论他们是做 H5、PPT，还是做平面设计，希望通过我们的工具解决内容的问题，而技术是一个比较好的完成结果的路径。所以内容是结果，我们只是希望用效率更高的方式，也就是技术，来去解决内容的问题，这是我们对这个问题的思考。我们的六七成业务是解决内容的问题，三四成是解决技术的问题。爱设计是一个内容中台，它上面是各种形态的内容，无论是做众包、版权，还是做编辑器。</p><p>&nbsp;</p><p>我们有三种不同的解题思路，满足不同用户的需求。</p><p>&nbsp;</p><p>第一个解决思路是针对 C 端，我们提供一个底层的编辑器，包括平面、视频、H5、PPT等等这样的全家桶编辑器；同时我们还有各种各样的模板，我们在济南有一个内容中心，专门帮我们的用户做模板；我们也有创作者平台，希望调动更多的内容创作者生态来给爱设计提供资源，帮我们的用户高效地生产内容。无论是市场部的负责人、新媒体小编还是销售，能直接在我们这里找到素材物料并发出去。</p><p>&nbsp;</p><p>第二个解决思路是采用 AI 技术来做内容，主要服务于广告跟电商场景。比如一个比较大的电商平台每个季度要生产几万张、几十万张素材物料，尺寸有几百种，人工的效率比较低，我们平台能实现一个尺寸的素材物料，自动生成一百个不同尺寸的素材物料。</p><p>&nbsp;</p><p>第三个解决思路是用众包的方式帮企业解决内容生产的需求。一些大型企业，比如百度、腾讯等有很多营销的节点，需要做很多素材物料满足各个场景。我们做了一个内容创意的双边市场，汇聚了各种各样的内容供应商，给所有的供应商打上标签，我们知道它的价格、服务水准，然后去给客户做匹配。</p><p>&nbsp;</p><p>总结来说就是，我们有三个路径通过技术来解决内容生产：第一，我们提供模板跟编辑器，赋能他们自己来做内容生产；第二，满足广告跟电商场景的需求，用 AI 来帮他们做内容；第三，针对一些非标的需求，采用内容众包或者创意供给平台的方式来帮企业去解决内容的生产。</p><p></p><h4>Kevin&nbsp;在&nbsp;2020&nbsp;年的时候专门在极客时间上写过一门专栏<a href=\"https://time.geekbang.org/opencourse/intro/100060101\">《一个草根创业者的&nbsp;40&nbsp;岁人生复盘》</a>\"，2&nbsp;年后再来回看这些思考，是否有了新的变化？</h4><p></p><p>&nbsp;</p><p>霍太稳：这个专栏原来的名字叫《一个草根创业者的 40 岁人生复盘》，现在我给它改成《知行合一 职场成长手册》，我希望每年能够迭代一下手册，这样做最主要的原因就是那句话：一个人的成长就是，你看昨天的自己觉得够不够傻，是不是很多事情都做得不够好。我在 2 年前写下这个专栏，里面的很多概念和实践是需要去更新的。举个例子，我之前在专栏里提到一个 CEO 主要做的事情就是找人找钱找方向，谈梦谈情谈共赢。现在回过头来看，我对这几件事情的理解已经完全不一样。</p><p>&nbsp;</p><p>先来看找人。过去我觉得找人就是把人招过来，只要有钱，就可以找到你想找的人。但现在我发现，你得找到对你公司非常合适的人，而且这个人空降到你的公司里，能非常好地去落地，融入进来，这才算是真正地找到了一个合适的人。而且找人是需要创始人、CEO 花很多时间去做的事情，如果找错了一个人，很有可能耽误了你岗位角色差不多一年的时间，一年的时间对一个创业公司来说是非常宝贵的。总的来说，找人永远是第一位的，这里的找人是指找到非常合适的人。</p><p>&nbsp;</p><p>再来看找钱。过去我对找钱的理解就是找到合适的投资人，请他过来投资我们就可以了，但是现在我对找钱有了更深刻的理解。找钱不仅仅包括和投资人沟通，还包括设计你的商业模式，盘一盘手里面有一些什么样的资源，哪些资源是可以通过交易去做增值。这也是一个 CEO、一个创始人应该花很多的时间去做的事情，设计你的商业模式，做底层的设计。</p><p>&nbsp;</p><p>最后看找方向。过去我觉得做视频号、公众号、知识付费就是找到一个合适的方向，现在我对这个事情也有了更多的理解，找方向不仅仅包括你的产品方向、业务的方向，还包括你对整个大趋势的理解，对整个行业的理解，还要花很多时间去看一看世界发生了什么样的变化。</p><p></p><h4>作为已经站在数字化浪潮中的创业者，对于那些新的入局者，有什么忠告或建议吗？</h4><p></p><p>&nbsp;</p><p>赵充：现在各行各业都在谈数字化，企业需要更加精细化、科学化地去做运营管理，这是个大的背景，也推动了整个 SaaS 行业的发展。SaaS 商业模式比较厉害的点在于，它能够有年度的、持续性的收入，如果产品跟服务足够好，用户就会持续订阅跟续费。产品跟客户之间的关系比较持续，对于企业自身来讲，经营结果可以预测，今年有一个亿收入，明年不会掉太多，不会像依赖几个大型客户的公司，业绩波动会比较大。这是 SaaS 行业比较吸引人的地方。</p><p>&nbsp;</p><p>说到需要注意的一些点就是，我们需要考虑的还是找钱、找人、找方向，再加一个修炼心性，这四点是比较重要的。</p><p>&nbsp;</p><p>第一，找钱。SaaS 创业前期还是需要非常多的粮草的，先投入产品研究，再做市场营销，之后才能逐步产生收入。而且第一年的收入也不一定能打得回来，它主要靠持续性的续费来实现盈利。这就要求大家一开始一定要把预算表做准，把控好现金流，很多 SaaS 企业失败的原因都是现金的问题。这个是大家需要考虑的第一个问题，备足粮草，要准备足够多的钱。</p><p>&nbsp;</p><p>第二，找人。除了内部团队找人之外，外部找人也比较重要，我们在早期的时候就拉了战略伙伴进来，一起“打群架”。早期要考虑的竞争维度是比较多的，比如你要做产品，要做内容，还要做市场等等，所以最开始我们就拉了 A 股最大的版权素材公司视觉中国做我们的战略合作伙伴，同时它还能拉既有的一两千客户，也能变成我们潜在的客户去做交叉销售。比较重要的就是早期的时候，拉一些人一起来做事情，在某些维度上让自己处于行业领先，这样我们就可以专注解决自己擅长的问题。</p><p>&nbsp;</p><p>第三，找方向。此前提到我们在 to B 还是 to C 方向上花了很多时间，整个的反馈速度还是比较慢的。to B 和 to C 背后的组织能力模型不太一样，需要的人基本上也是不太一样的，这个也是需要大家去考虑的。</p><p>&nbsp;</p><p>第四，修炼心性。做 SaaS 业务是比较需要有耐心的，需要磨炼心性。SaaS 业务从产品的调研，到产品上线，再到真正开始商业化，整个周期非常长，着急一点用都没有，需要耐心，比较适合长跑型的创业者。</p><p>&nbsp;</p><p>霍太稳：我认为需要想清楚自己做的这件事情到底能帮客户解决什么样的问题，然后围绕这一点去做。不一定要做非常宏大的产品，非常宏大的服务，然后通过非常宏大的志向去找到投资人，然后开始怎么样。我认为还是先从最具体的场景去做，到底我带着几个人做产品、做服务，我能够帮客户去解决一个什么样的问题，一旦我帮他解决了问题，我就让他的生产效率有了非常大的提升，也能够让老板满意，这是第一点。</p><p>&nbsp;</p><p>第二点也是在当前阶段需要特别注意的，因为现在整个经济环境并不是非常的理想，新入局的创业者手上的资源并不多，包括人的资源、钱的资源，在这种情况之下就要特别小心，你所花出去的每一笔钱，你所做的每一个投资，你所招的每一个人，你都要算清楚他能够给你带来什么样的价值。管理要精细再精细，在这上面把所有的帐都给计算清楚。如果你的投资在短期不能收回来，我觉得在经济环境并不是很好的情况下就不要去做了，还是务实一点比较好，先让你的整个业务以一个正循环的方式转起来，我认为是非常必要的。</p><p>&nbsp;</p><p>简单总结来讲，第一，不要想太多，先去帮助你的客户去解决他的痛点，哪怕是很小的一个点都可以，他一定会愿意付你钱。第二，你现在手里面的资源并不是非常多，一定要非常精细化地去使用，保证自己活得长久一点，等经济复苏的时候，你还在车上，还在牌桌上。</p><p></p><h4>嘉宾介绍</h4><p></p><p>&nbsp;</p><p>赵充，微梦传媒/爱设计 CEO。曾经就职于新浪，有多年互联网产品开发和运营的相关经验。2011 年创立微梦传媒并成功挂牌新三板。2018 年创立爱设计，2022 年 6 月，爱设计完成策源创投和亚杰基金领投的数千万元 A2 轮融资，致力于打造中国企业内容数字化转型的新基建。</p><p>&nbsp;</p><p>霍太稳，极客邦科技创始人兼 CEO，InfoQ 中国创始人，极客时间创始人，TGO 鲲鹏会发起人。2007 年创立 InfoQ 中国，2014 年创立极客邦科技，2015 年发起 TGO 鲲鹏会，2017 年创立在线职业教育学习品牌极客时间，2019 年开创极客时间企业版，拓展企业服务市场。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/6c/40/6c915f3910a1332179815d3a866c2240.png\" /></p><p></p>",
    "publish_time": "2022-08-25 14:14:21",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]