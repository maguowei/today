[
  {
    "title": "使用Strimzi将Kafka和Debezium迁移到Kubernetes",
    "url": "https://www.infoq.cn/article/ElNtSM5ISobpMB8fMC0j",
    "summary": "<p>在本系列文章的<a href=\"https://www.infoq.cn/article/cFpvXRLmZzJBGbzAeFu5\">第1部分</a>\"和<a href=\"https://www.infoq.cn/article/WfA0p1XoZCJ6INdyJLyv\">第2部分</a>\"中，我们学习了<a href=\"https://kafka.apache.org/\">Apache Kafka</a>\"、Apache Kafka Streams和<a href=\"https://quarkus.io/\">Quarkus</a>\"之间的集成。我们开发了一个简单的应用程序，向Kafka主题生成事件，并使用<a href=\"https://kafka.apache.org/documentation/streams/\">Kafka Streams</a>\"实时消费和处理它们。</p><p></p><p>在那个例子中，我们模拟了一家电影流媒体公司。我们将电影信息保存在一个Kafka主题中，并在另一个Kafka主题中保存用户停止观看电影时的事件，并捕获影片播放的时间。我们实时对这些事件进行后期处理，计算电影播放超过10分钟的次数。</p><p></p><p>下图是这个应用程序的架构。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/strimzi-the-gitops-way/en/resources/11-1664224713829.jpeg\" /></p><p>然后，在<a href=\"https://www.infoq.cn/article/V4kqPgrQlqqPgWQuMmDP\">第3部分</a>\"中，我们介绍了发件箱模式和Debezium，用于避免在不同系统需要同步相同数据时发生的双写问题。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/strimzi-the-gitops-way/en/resources/12-1664224713829.jpeg\" /></p><p>在前面的三篇文章中，我们已经从开发人员的角度学习了所有这些技术，并最终在开发人员的本地机器上（以开发模式）部署应用程序。</p><p></p><p>在本文中，我们将探讨如何将所有东西部署到生产环境，更具体地说，部署到Kubernetes中。我们将学习：</p><p></p><p>在Kubernetes中安装和管理Apache Kafka集群。容器化Quarkus应用程序。配置一个带有生产参数的Quarkus应用程序。将Debezium Embedded迁移成Debezium Server。</p><p></p><h2>Kubernetes</h2><p></p><p></p><p>Kubernetes是一个开源的容器编配器，是部署微服务的事实上的平台。这些服务既可以在裸金属环境中运行，也可以在云环境中运行。</p><p></p><p>本文使用<a href=\"https://minikube.sigs.k8s.io/docs/\">minikube</a>\"作为Kubernetes集群，但同样的步骤应该适用于任何其他实现。</p><p></p><h4>启动集群</h4><p></p><p>在终端窗口中执行以下命令，在配备了8GB内存和2个vCPU的VirtualBox机器上启动集群。</p><p></p><p><code lang=\"plain\">minikube start -p strimzi --kubernetes-version='v1.22.12' --vm-driver='virtualbox' --memory=8096\n\n  [strimzi] minikube v1.24.0 on Darwin 12.5\n  minikube 1.26.1 is available! Download it: https://github.com/kubernetes/minikube/releases/tag/v1.26.1\n  To disable this notice, run: 'minikube config set WantUpdateNotification false'\n\n✨  Using the virtualbox driver based on user configuration\n  Starting control plane node strimzi in cluster strimzi\n  Creating virtualbox VM (CPUs=2, Memory=8096MB, Disk=20000MB) ...\n    &gt; kubelet.sha256: 64 B / 64 B [--------------------------] 100.00% ? p/s 0s\n    &gt; kubeadm.sha256: 64 B / 64 B [--------------------------] 100.00% ? p/s 0s\n    &gt; kubectl.sha256: 64 B / 64 B [--------------------------] 100.00% ? p/s 0s\n    &gt; kubeadm: 43.74 MiB / 43.74 MiB [-------------] 100.00% 13.98 MiB p/s 3.3s\n    &gt; kubectl: 44.77 MiB / 44.77 MiB [-------------] 100.00% 11.11 MiB p/s 4.2s\n    &gt; kubelet: 115.30 MiB / 115.30 MiB [-----------] 100.00% 20.16 MiB p/s 5.9s\n\n    ▪ Generating certificates and keys ...\n    ▪ Booting up control plane ...\n    ▪ Configuring RBAC rules ...\n    ▪ Using image gcr.io/k8s-minikube/storage-provisioner:v5\n  Verifying Kubernetes components...\n  Enabled addons: storage-provisioner, default-storageclass\n\n❗  /usr/local/bin/kubectl is version 1.24.0, which may have incompatibilites with Kubernetes 1.22.12.\n    ▪ Want kubectl v1.22.12? Try 'minikube kubectl -- get pods -A'\n  Done! kubectl is now configured to use \"strimzi\" cluster and \"default\" namespace by default\n</code></p><p></p><p>在终端窗口执行下面的命令检查Kubernetes集群是否正常运行。</p><p></p><p><code lang=\"plain\">kubectl get nodes\n\nNAME      STATUS   ROLES                  AGE    VERSION\nstrimzi   Ready    control-plane,master   3m4s   v1.22.12\n\nkubectl get pods\nNo resources found in default namespace.\n</code></p><p></p><h2>Apache Kafka</h2><p></p><p></p><p>在之前的文章中，我们通过Quarkus的开发模式来启动运行应用程序所需的外部依赖项（Kafka集群和MySQL数据库）。从开发的角度来看，开发模式非常棒，但在部署到生产环境时，你会发现这些东西管理起来更加复杂。第一个障碍可能是在Kubernetes中安装和配置Kafka集群。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/strimzi-the-gitops-way/en/resources/13-1664224713829.jpeg\" /></p><p>你可能想知道以下这些问题的答案：</p><p></p><p>Kafka组件（Kafka、Zookeeper等）需要使用哪个容器镜像?如何在Kubernetes中轻松部署所有这些组件？如何在Kubernetes中创建用户、主题或HA？安全性如何？你可以尝试手动完成所有这些事情，例如编写很长的YAML文件和使用Kafka CI工具配置Kafka组件。然而，还有另一种Kubernetes原生的、完全自动化和可复制的（非常适合CI/CD）方法，就是使用Strimzi。</p><p></p><h4>Strimzi</h4><p></p><p><a href=\"https://strimzi.io/\">Strimzi</a>\"是一个<a href=\"https://www.redhat.com/en/topics/containers/what-is-a-kubernetes-operator\">Kubernetes Operator</a>\"，通过控制器来创建、配置和保护Kafka集群，就像其他Kubernetes资源（如Pod、Deployment、ConfigMap等）一样。</p><p></p><p>Strimzi项目包含三个Operator——一个用于管理Kafka集群，一个用于管理主题，一个用于用户管理。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/strimzi-the-gitops-way/en/resources/14-1664224713829.jpeg\" /></p><p>在Kubernetes集群中安装了Strimzi Operator之后，你只需要使用下面的YAML文件就可以启动并运行一个Kafka集群，其中包含了一个Kafka副本和三个使用临时存储（没有挂载持久卷）的ZooKeeper副本。</p><p></p><p><code lang=\"plain\">apiVersion: kafka.strimzi.io/v1beta2\nkind: Kafka\nmetadata:\n name: my-cluster\nspec:\n kafka:\n   version: 3.2.0\n   replicas: 1\n   listeners:\n     - name: plain\n       port: 9092\n       type: internal\n       tls: false\n     - name: tls\n       port: 9093\n       type: internal\n       tls: true\n   config:\n     offsets.topic.replication.factor: 1\n     transaction.state.log.replication.factor: 1\n     transaction.state.log.min.isr: 1\n     default.replication.factor: 1\n     min.insync.replicas: 1\n     inter.broker.protocol.version: \"3.2\"\n   storage:\n     type: ephemeral\n zookeeper:\n   replicas: 3\n   storage:\n     type: ephemeral\n entityOperator:\n   topicOperator: {}\n   userOperator: {}\n</code></p><p></p><p>接下来，我们将在已经启动的集群中安装Strimzi。</p><p></p><h4>安装Strimzi</h4><p></p><p>首先是创建一个命名空间来安装Strimzi Operator。在本例中，我们使用了命名空间kafka。在终端窗口中执行如下命令：</p><p></p><p><code lang=\"plain\">kubectl create namespace kafka\nnamespace/kafka created\n</code></p><p></p><p>接下来，我们应用Strimzi安装文件，其中包括用于声明式管理Kafka集群、Kafka主题和用户的CRD（CustomerResourceDefinition）。</p><p></p><p><code lang=\"plain\">kubectl create -f 'https://strimzi.io/install/latest?namespace=kafka' -n kafka\n</code></p><p></p><p>运行下面的命令验证Operator是否安装正确。</p><p></p><p><code lang=\"plain\">kubectl get pods -n kafka\n\nNAME                                        READY   STATUS    RESTARTS   AGE\nstrimzi-cluster-operator-597d67c7d6-ms987   1/1     Running   0          4m27s\n</code></p><p></p><p>现在，我们开始创建带有movies主题的Kafka集群。我们将在这个主题中保存所有电影的信息，稍后Kafka Streams将消费这个主题，正如我们在本系列文章的<a href=\"https://www.infoq.cn/article/WfA0p1XoZCJ6INdyJLyv\">第2部分</a>\"中所看到的那样。</p><p></p><h4>创建Kafka集群</h4><p></p><p>创建一个新的文件（即kafka.yaml）来安装一个带有一个副本的<a href=\"https://strimzi.io/docs/operators/latest/configuring.html#assembly-config-kafka-str\">Kafka集群</a>\"，不启用TLS，作为内部<a href=\"https://kubernetes.io/docs/concepts/services-networking/service/\">Kubernetes服务</a>\"。</p><p></p><p><code lang=\"plain\">apiVersion: kafka.strimzi.io/v1beta2\nkind: Kafka\nmetadata:\n name: my-cluster\nspec:\n kafka:\n   version: 3.2.0\n   replicas: 1\n   listeners:\n     - name: plain\n       port: 9092\n       type: internal\n       tls: false\n   config:\n     offsets.topic.replication.factor: 1\n     transaction.state.log.replication.factor: 1\n     transaction.state.log.min.isr: 1\n     default.replication.factor: 1\n     min.insync.replicas: 1\n     inter.broker.protocol.version: \"3.2\"\n   storage:\n     type: ephemeral\n zookeeper:\n   replicas: 1\n   storage:\n     type: ephemeral\n entityOperator:\n   topicOperator: {}\n   userOperator: {}\n</code></p><p></p><p>然后在终端窗口中使用kubectl命令创建这个资源：</p><p></p><p><code lang=\"plain\">kubectl create -f kafka.yaml -n kafka\nkafka.kafka.strimzi.io/my-cluster created\n</code></p><p></p><p>此时，Strimzi开始在默认命名空间中安装Kafka集群。</p><p></p><p>现在，我们通过获取默认的名称空间Pod来检查集群的创建情况。</p><p></p><p><code lang=\"plain\">kubectl get pods -n kafka\n\nNAME                                          READY   STATUS    \nmy-cluster-entity-operator-755596449b-cw82g   3/3     Running   \nmy-cluster-kafka-0                            1/1     Running \nmy-cluster-zookeeper-0                        1/1     Running\n</code></p><p></p><p>Kafka集群已启动并运行。我们除了可以将Kafka作为Kubernetes资源安装之外，还可以查询和描述它。例如，在终端窗口中执行如下命令：</p><p></p><p><code lang=\"plain\">kubectl get kafka -n kafka\n\nNAME         DESIRED KAFKA REPLICAS   DESIRED ZK REPLICAS   READY   WARNINGS\nmy-cluster   1                        1                     True    True\n\n\n\nkubectl describe kafka my-cluster -n kafka\n\nName:         my-cluster\nNamespace:    default\nLabels:       \nAnnotations:  \nAPI Version:  kafka.strimzi.io/v1beta2\nKind:         Kafka\nMetadata:\n  Creation Timestamp:  2022-08-09T10:57:39Z\n…\n</code></p><p></p><p>当然，你也可以像删除其他Kubernetes资源一样删除它。此外，系统还创建了4个Kubernetes服务来访问Kafka集群：</p><p></p><p><code lang=\"plain\">kubectl get services -n kafka\n\nNAME                          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE\n               143m\nmy-cluster-kafka-bootstrap    ClusterIP   172.30.77.150           9091/TCP,9092/TCP            21m\nmy-cluster-kafka-brokers      ClusterIP   None                    9090/TCP,9091/TCP,9092/TCP   21m\nmy-cluster-zookeeper-client   ClusterIP   172.30.5.186            2181/TCP                     21m\nmy-cluster-zookeeper-nodes    ClusterIP   None                    2181/TCP,2888/TCP,3888/TCP   21m\n</code></p><p></p><p>应用程序用于访问集群的服务是my-cluster-kafka-bootstrap，它公开了Kafka的9092端口。</p><p></p><p>在进入到应用程序部分之前，我们需要使用另一个YAML文件来创建和配置movies主题。</p><p></p><h4>创建movies主题</h4><p></p><p>Strimzi有一个用于创建和管理主题的Operator。要创建一个新主题，我们需要创建一个<a href=\"https://strimzi.io/docs/operators/latest/configuring.html#using-the-topic-operator-str\">KafkaTopic</a>\"类型的Kubernetes资源文件，在strimzi.io/cluster中指定主题的名称和集群的名称（在我们的例子中是my-cluster）。我们使用下面的内容创建一个名为movies-topic.yaml的新文件。</p><p></p><p><code lang=\"plain\">apiVersion: kafka.strimzi.io/v1beta2\nkind: KafkaTopic\nmetadata:\n name: movies\n labels:\n   strimzi.io/cluster: my-cluster\nspec:\n partitions: 1\n replicas: 1\n config:\n   retention.ms: 7200000\n   segment.bytes: 1073741824\n</code></p><p></p><p>并应用这个文件：</p><p></p><p><code lang=\"plain\">kubectl apply -f movies-topic.yaml -n kafka\nkafkatopic.kafka.strimzi.io/movies create\n</code></p><p></p><p>和其他Kubernetes资源一样，我们也可以查询和描述它。</p><p></p><p><code lang=\"plain\">kubectl get kafkatopic -n kafka\n\nNAME                                                                                               CLUSTER      PARTITIONS   REPLICATION FACTOR   READY\nconsumer-offsets---84e7a678d08f4bd226872e5cdd4eb527fadc1c6a                                        my-cluster   50           1                    True\nmovies                                                                                             my-cluster   1            1                    True\nstrimzi-store-topic---effb8e3e057afce1ecf67c3f5d8e4e3ff177fc55                                     my-cluster   1            1                    True\nstrimzi-topic-operator-kstreams-topic-store-changelog---b75e702040b99be8a9263134de3507fc0cc4017b   my-cluster   1            1                    True\n</code></p><p></p><p>描述已创建的主题：</p><p></p><p><code lang=\"plain\">kubectl port-forward -n kafka service/my-cluster-kafka-bootstrap 9092:9092\n\nForwarding from 127.0.0.1:9092 -&gt; 9092\nForwarding from [::1]:9092 -&gt; 9092\n</code></p><p></p><p>我们来检查一下创建的主题是否有<a href=\"https://kubernetes.io/docs/tasks/access-application-cluster/port-forward-access-application-cluster/\">端口转发</a>\"。</p><p></p><p>在终端窗口执行如下命令：</p><p></p><p><code lang=\"plain\">kubectl port-forward -n kafka service/my-cluster-kafka-bootstrap 9092:9092\n\nForwarding from 127.0.0.1:9092 -&gt; 9092\nForwarding from [::1]:9092 -&gt; 9092\n</code></p><p></p><p>打开一个新的终端窗口，使用<a href=\"https://github.com/edenhill/kcat\">kcat</a>\"工具列出Kafka集群的元素。我们可以使用localhost作为主机名，就像在上一步中使用端口转发技巧一样。</p><p></p><p><code lang=\"plain\">kcat -b localhost:9092 -L\n\nMetadata for all topics (from broker -1: localhost:9092/bootstrap):\n 1 brokers:\n  broker 0 at my-cluster-kafka-0.my-cluster-kafka-brokers.default.svc:9092 (controller)\n 4 topics:\n  topic \"movies\" with 1 partitions:\n    partition 0, leader 0, replicas: 0, isrs: 0\n</code></p><p></p><p>最后，我们停止端口转发进程，对项目进行容器化，就像我们在本系列文章的<a href=\"https://www.infoq.cn/article/V4kqPgrQlqqPgWQuMmDP\">第3部分</a>\"中所做的那样，并进行一些相应的配置，以便连接到Kafka集群。</p><p></p><h2>生产者Debezium</h2><p></p><p></p><p>我们在系列文章的<a href=\"https://www.infoq.cn/article/V4kqPgrQlqqPgWQuMmDP\">第3部分</a>\"解决了双写问题，使用Debezium（具体来说是<a href=\"https://github.com/lordofthejars/movie-plays-kafka/blob/main/movie-plays-producer-debezium/src/main/java/org/acme/DebeziumListener.java\">Debezium Embedded</a>\"）修复了这个问题，具体方法是监听来自MySQL服务器的事务日志，并在每次插入新的电影播放信息时生成带有数据的Kafka事件。你可以在本地机器上运行这个示例，使用开发服务启动所需的服务（MySQL和Kafka），并自动配置应用程序来连接它们。</p><p></p><p>现在有点不一样了——服务必须运行在Kubernetes集群中，包括在前面步骤中创建的Kafka集群和MySQL数据库。要让它在Kubernetes中运行，需要做出三个改变。</p><p></p><p>使用新的Kafka和MySQL参数（主机名、端口、用户名和密码）来配置服务。将应用程序装入容器，并推送到容器注册表。创建Kubernetes资源文件，用于部署服务。</p><p></p><h2>配置服务</h2><p></p><p></p><p>首先要配置的是Kafka的主机名和端口，它们指向Strimzi创建的Kubernetes服务。打开src/main/resources/application.properties文件并添加下面的内容：</p><p></p><p><code lang=\"plain\">%prod.kafka.bootstrap.servers=my-cluster-kafka-bootstrap:9092\n</code></p><p></p><p>%prod前缀表示这个属性仅在应用程序以prod模式下运行时使用（而不是在dev或test模式下)。</p><p></p><p>其次时配置插入影片信息的数据库连接。在application.properties文件中添加下面的内容。</p><p></p><p><code lang=\"plain\">quarkus.hibernate-orm.database.generation=drop-and-create\n%prod.quarkus.datasource.username=alex\n%prod.quarkus.datasource.password=alex\n%prod.quarkus.datasource.jdbc.url=jdbc:mysql://mysql:3306/moviesdb\n</code></p><p></p><p>稍后，我们将使用这些参数部署一个MySQL实例。现在，我们假设配置参数是正确的。</p><p></p><h4>容器化</h4><p></p><p>Quarkus为创建容器提供了与<a href=\"https://github.com/GoogleContainerTools/jib\">Jib</a>\"项目的集成，让容器镜像的构建和推送简单得只需要执行一个Maven/Gradle任务。</p><p></p><p>打开pom.xml文件，在dependencies部分添加以下依赖项：</p><p></p><p><code lang=\"plain\">\n     io.quarkus\n     quarkus-container-image-jib\n\n</code></p><p></p><p>添加了<a href=\"https://quarkus.io/guides/container-image\">Jib依赖项</a>\"后，它将在打包时自动将应用程序装入容器。因为<a href=\"https://github.com/GoogleContainerTools/jib\">Jib</a>\"的一些默认配置选项可能不适用于所有情况，所以你可以在src/main/resources/application.properties中覆盖它们。对于本例，我们将覆盖生成的容器镜像的group和容器注册中心的主机。</p><p></p><p>打开application.properties文件，并添加下面的内容：</p><p></p><p><code lang=\"plain\"># Substitue the value with your account name\nquarkus.container-image.group=lordofthejars\n \n# Defaults to Docker.io, overriden to Quay.\nquarkus.container-image.registry=quay.io\n</code></p><p></p><p>你需要设置容器注册表的凭据，以便向注册表推送容器。你可以在执行构建之前运行docker的login命令。Maven将从那里读取凭据，或者你可以使用quarkus.container-image.username和quarkus.container-image.password属性。</p><p></p><p>在项目的根目录下运行下面的命令来构建应用程序，它将构建出一个容器并将其推到指定的容器注册表中。</p><p></p><p><code lang=\"plain\">./mvnw clean package -DskipTests -Dquarkus.container-image.push=true\n\n[INFO] Scanning for projects...\n[INFO]\n[INFO] ---------------&lt; org.acme:movie-plays-producer-debezium &gt;---------------\n[INFO] Building movie-plays-producer-debezium 1.0.0-SNAPSHOT\n[INFO] --------------------------------[ jar ]---------------------------------\n[INFO]\n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ movie-plays-producer-debezium ---\n[INFO] Deleting /Users/asotobu/git/quarkus-integrating-kafka/strimzi/movie-plays-producer-debezium/target\n…\n[INFO] [io.quarkus.container.image.jib.deployment.JibProcessor] Using base image with digest: sha256:1a2fddacdcda67494168749c7ab49243d06d8fbed34abab90566d81b94f5e1a5\n[INFO] [io.quarkus.container.image.jib.deployment.JibProcessor] Container entrypoint set to [java, -Djava.util.logging.manager=org.jboss.logmanager.LogManager, -jar, quarkus-run.jar]\n[INFO] [io.quarkus.container.image.jib.deployment.JibProcessor] Pushed container image quay.io/lordofthejars/movie-plays-producer-debezium:1.0.0-SNAPSHOT (sha256:73dfe42d53f8d7e3c268dbebc2e5f866596de33b8fcaf82c27bdd414d28bdb8a)\n</code></p><p></p><p>从最后一行日志可以看到，容器被创建，并使用application.properties中指定的账号推送到注册中心。</p><p></p><h4>Kubernetes</h4><p></p><p>在将容器推送到注册表之后，我们准备将服务部署到Kubernetes中。我们可以手动创建Kubernetes资源文件，但没有必要这么做，因为Quarkus为我们提供了一个<a href=\"https://quarkus.io/guides/deploying-to-kubernetes\">Kubernetes扩展</a>\"。</p><p></p><p>打开pom.xml文件，并在dependencies部分添加下面的依赖项。</p><p></p><p><code lang=\"plain\">\n     io.quarkus\n     quarkus-kubernetes\n\n</code></p><p></p><p>每次Maven打包应用程序时都会注册Kubernetes扩展，并生成将应用程序部署到Kubernetes集群的kubernetes.yml文件。你可以通过application.properties来修改生成文件的内容。例如，我们将Kubernetes Service设置为LoadBalancer而不是ClusterIP，并将命名空间设置为kafka。</p><p></p><p>打开application.properties文件并添加下面的内容。</p><p></p><p><code lang=\"plain\">quarkus.kubernetes.service-type=load-balancer\nquarkus.kubernetes.namespace=kafka\n</code></p><p></p><p>修改好以后运行Maven package生成部署文件。</p><p></p><p><code lang=\"plain\">./mvnw clean package -DskipTests\n\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n</code></p><p></p><p>检查生成的文件target/kubernetes/kubernetes.yml：</p><p></p><p><code lang=\"plain\">cat target/kubernetes/kubernetes.yml\n</code></p><p></p><p>输出的内容应该类似于下面这样：</p><p></p><p><code lang=\"plain\">---\napiVersion: v1\nkind: Service\nmetadata:\n …\n name: movie-plays-producer-debezium\nspec:\n ports:\n   - name: http\n     port: 80\n     targetPort: 8080\n selector:\n   app.kubernetes.io/name: movie-plays-producer-debezium\n   app.kubernetes.io/version: 1.0.0-SNAPSHOT\n # Type is LoadBalancer as set in the application.properties file \n type: LoadBalancer\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n …\n name: movie-plays-producer-debezium\nspec:\n replicas: 1\n selector:\n   matchLabels:\n     app.kubernetes.io/name: movie-plays-producer-debezium\n     app.kubernetes.io/version: 1.0.0-SNAPSHOT\n template:\n   metadata:\n     …\n   spec:\n     containers:\n       - env:\n           - name: KUBERNETES_NAMESPACE\n             valueFrom:\n               fieldRef:\n                 fieldPath: metadata.namespace\n         # The image is correctly set automatically\n         image: quay.io/lordofthejars/movie-plays-producer-debezium:1.0.0-SNAPSHOT\n         imagePullPolicy: Always\n         name: movie-plays-producer-debezium\n         ports:\n           - containerPort: 8080\n             name: http\n             protocol: TCP\n</code></p><p></p><p>在本例中，配置参数是硬编码在application.properties中的，但你可以将它们作为环境变量传递进去。要在Kubernetes Deployment对象中设置环境变量，比如覆盖Kafka的配置，可以添加下面的行：</p><p></p><p><code lang=\"plain\">quarkus.kubernetes.env.vars.kafka-bootstrap-servers=my-new-cluster:9092 \n</code></p><p></p><p>生成文件的env部分将包含这个新的环境变量：</p><p></p><p><code lang=\"plain\">containers:\n       - env:\n           - name: KAFKA_BOOTSTRAP_SERVERS\n             value: my-new-cluster:9092\n         image: quay.io/lordofthejars/movie-plays-producer-debezium:1.0.0-SNAPSHOT\n</code></p><p></p><h4>全部放到一起</h4><p></p><p>我们已经使用Strimzi在Kubernetes集群中部署了一个Kafka集群。我们将应用下面的文件（mysql-deployment.yaml）和application.properties中配置的参数部署MySQL实例。</p><p></p><p><code lang=\"plain\">apiVersion: v1\nkind: Service\nmetadata:\n name: mysql\n labels:\n   app: mysql\nspec:\n ports:\n   - port: 3306\n selector:\n   app: mysql\n clusterIP: None\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n name: mysql\n labels:\n   app: mysql\nspec:\n selector:\n   matchLabels:\n     app: mysql\n strategy:\n   type: Recreate\n template:\n   metadata:\n     labels:\n       app: mysql\n   spec:\n     containers:\n     - image: mysql:8.0.30\n       name: mysql\n       env:\n       - name: MYSQL_ROOT_PASSWORD\n         value: alex\n       - name: MYSQL_DATABASE\n         value: moviesdb\n       - name: MYSQL_USER\n         value: alex\n       - name: MYSQL_PASSWORD\n         value: alex\n       ports:\n       - containerPort: 3306\n         name: mysql\n</code></p><p></p><p>将MySQL实例部署到Kubernetes集群：</p><p></p><p><code lang=\"plain\">kubectl apply -f mysql-deployment.yaml -n kafka\n</code></p><p></p><p>最后要部署的是应用程序本身。我们有两个选择，第一个是直接应用资源：</p><p></p><p><code lang=\"plain\">kubectl apply -f target/kubernetes/kubernetes.yml -n kafka\n</code></p><p></p><p>第二个是将quarkus.kubernetes.deploy标志设置为true来打包应用程序。当这个标志设置为true时，Maven将：</p><p></p><p>创建应用程序JAR文件。构建容器镜像。将容器镜像推送到注册表中。自动应用kubernetes.yml资源文件到已连接的Kubernetes集群。为了验证所有的东西都能正确地运行，我们将发送一个插入新电影信息的请求，并验证在Kafka主题中插入的新事件。</p><p></p><p>在终端窗口中执行以下命令获取访问服务的IP和端口。</p><p></p><p>获取访问服务的IP：</p><p></p><p><code lang=\"plain\">minikube ip -p strimzi\n\n192.168.59.104\n</code></p><p></p><p>获取movie-plays-producer-debezium的公开端口，也就是第二个端口。</p><p></p><p><code lang=\"plain\">kubectl get services -n kafka\n\nmovie-plays-producer-debezium   LoadBalancer   10.100.117.203        80:30306/TCP                 67m\n</code></p><p></p><p>运行curl命令，插入一条新的电影信息记录。</p><p></p><p><code lang=\"plain\">curl -X 'POST' \\\n  'http://192.168.59.104:30306/movie' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"name\": \"Minions: The Rise of Gru\",\n  \"director\": \"Kyle Balda\",\n  \"genre\": \"Animation\"\n}'\n</code></p><p></p><p>检查Quarkus日志，查看数据库运行的SQL语句：</p><p></p><p><code lang=\"java\">kubectl get pods -n kafka\n\nNAME                                             READY   STATUS      RESTARTS   AGE\nmovie-plays-producer-debezium-56f644cb87-5cchk   1/1     Running     0          6m5s\nmy-cluster-entity-operator-755596449b-cw82g      3/3     Running     0          35h\nmy-cluster-kafka-0                               1/1     Running     0          35h\nmy-cluster-zookeeper-0                           1/1     Running     0          35h\n</code></p><p></p><p>打印movie-plays-producer-debezium的日志：</p><p></p><p><code lang=\"java\">kubectl logs movie-plays-producer-debezium-6b9b65bf4-9z524 -n kafka\n\n2022-08-11 07:44:25,658 INFO  [org.acm.MovieResource] (executor-thread-1) New Movie inserted Minions: The Rise of Gru\n:)\nHibernate:\n    select\n        next_val as id_val\n    from\n        hibernate_sequence for update\n\nHibernate:\n    update\n        hibernate_sequence\n    set\n        next_val= ?\n    where\n        next_val=?\nHibernate:\n    insert\n    into\n        Movie\n        (director, genre, name, id)\n    values\n        (?, ?, ?, ?)\nHibernate:\n    insert\n    into\n        OutboxEvent\n        (aggregatetype, aggregateid, type, timestamp, payload, tracingspancontext, id)\n    values\n        (?, ?, ?, ?, ?, ?, ?)\n\n# Debezium reacts to the change\n2022-08-11 07:44:25,867 INFO  [io.deb.con.com.BaseSourceTask] (executor-thread-0) 1 records sent during previous 00:20:44.297, last recorded offset: {transaction_id=null, ts_sec=1660203865, file=binlog.000002, pos=14795, row=1, server_id=1, event=4}\nMovie Created and Reacting\n</code></p><p></p><p>你还可以使用Kafka容器里的Kafka-console-consumer.sh脚本来检查Kafka中的内容。进入容器并运行下面的命令：</p><p></p><p><code lang=\"java\">kubectl exec -ti my-cluster-kafka-0 -n kafka /bin/bash\n\n./bin/kafka-console-consumer.sh --topic movies --from-beginning --bootstrap-server localhost:9092\n{\"id\":1,\"name\":\"Minions: The Rise of Gru\",\"director\":\"Kyle Balda\",\"genre\":\"Animation\"}\n</code></p><p></p><p>要返回本地终端窗口，请按Ctrl+C停止kafka-console-consumer进程，然后执行exit命令。</p><p></p><p>到目前为止，一切都很顺利。我们已经得到了与本系列文章第3部分中相同的应用程序，只是现在它运行在Kubernetes集群中。</p><p></p><p>到目前为止，我们使用的是Debezium Embedded，但其实我们可以使用Debezium Server。</p><p></p><h2>Debezium Server</h2><p></p><p></p><p><a href=\"https://debezium.io/documentation/reference/stable/operations/debezium-server.html\">Debezium Server</a>\"是一个可配置的、使用就绪的应用程序，它将事件从源数据库流到消息传递系统中，如Kafka。它可以被注册成一个<a href=\"https://kafka.apache.org/documentation/#connect\">Kafka Connect组件</a>\"，作为源连接器。</p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/strimzi-the-gitops-way/en/resources/15-1664224713829.jpeg\" /></p><p>虽然我们不能在所有的场景中都使用Debezium Server，但在我看来，使用这种方法有两个大的优点：</p><p></p><p>你可以获得Kafka连接器的所有好处（容错、可扩展、可重用等）。因为它是一个外部组件，所以不需要更改应用程序代码，也不需要Debezium Embedded相关的代码或依赖项。因此，任何应用程序都可以在不做出修改或重新部署的情况下开始使用Debezium。接下来，我们来看看如何从Debezium Embedded迁移到Debezium Server。</p><p></p><h4>移除Debezium Embedded</h4><p></p><p>首先要做的是删除Debezium Embedded相关的依赖项。</p><p></p><p>打开pom.xml文件，删除以下依赖项：</p><p></p><p><code lang=\"java\">\n     io.debezium\n     debezium-ddl-parser\n\n\n     io.debezium\n     debezium-embedded\n\n\n     io.debezium\n     debezium-connector-mysql\n\n</code></p><p></p><p>下一步是删除所有与Debezium Embedded配置和监听器相关的代码。删除这些类文件——DebeziumConfiguration.java、DebeziumListener.java和MySqlJdbcParser.java。</p><p></p><p>因为所有与Kafka的交互都是通过Kafka Connect组件进行的，不需要Kafka代码，所以最后一步是从pom.xml中移除以下依赖项：</p><p></p><p><code lang=\"go\">\n     io.quarkus\n     quarkus-smallrye-reactive-messaging-kafka\n\n</code></p><p></p><p>application.properties文件中的这一行不再需要：</p><p></p><p><code lang=\"java\">%prod.kafka.bootstrap.servers=my-cluster-kafka-bootstrap:9092\n</code></p><p></p><p>项目中已经没有了Kafka或Debezium Embedded依赖项。创建一个包含这些最新变更的容器镜像。</p><p></p><p>在终端窗口执行以下命令，删除之前的部署：</p><p></p><p><code lang=\"go\">kubectl delete deployment movie-plays-producer-debezium\nkubectl delete service movie-plays-producer-debezium\n</code></p><p></p><p>要保留带有Debezium Debezium的容器镜像，请将artifactId更改为movie-plays-producer-debezium-server。</p><p></p><p>然后将不带Debezium代码的新版本部署到Kubernetes集群中，如下所示：</p><p></p><p><code lang=\"plain\">./mvnw clean package -DskipTests -Dquarkus.kubernetes.deploy=true\n</code></p><p></p><p>运行以下命令验证新部署的服务：</p><p></p><p><code lang=\"java\">kubectl get pods -n kafkaa\n\nNAME                                                    READY   STATUS    RESTARTS   AGE\nmovie-plays-producer-debezium-server-59db564b74-vhdmf   1/1     Running   0          73m\n</code></p><p></p><h4>部署Debezium Kafka Connect</h4><p></p><p>首先，部署一个Kafka Connect组件与所需的MySQL连接器插件。你可以认为它跟我们在<a href=\"https://github.com/lordofthejars/movie-plays-kafka/blob/main/strimzi/movie-plays-producer-debezium/src/main/java/org/acme/DebeziumListener.java\">DebeziumListener</a>\"类中实现的逻辑差不多，只是被作为一个Kafka Connect元素，可以在项目中重用。我们必须为Kafka Connect和连接器插件创建一个容器镜像，因为Debezium没有为各种可能的Kafka与数据的组合提供“官方”镜像。对于本例，我们使用Kafka 3.2.0的MySQL连接器创建一个容器镜像。</p><p></p><p>本文中MySQL连接器的容器镜像可以在<a href=\"http://quay.io/lordofthejars/debezium-connector-mysql:1.9.4\">quay.io/lordofthejars/debezium-connector-mysql:1.9.4</a>\"找到，如果你对它的构建过程感到好奇，可以查看位于这个<a href=\"https://github.com/lordofthejars/movie-plays-kafka/blob/main/strimzi/Dockerfile\">GitHub</a>\"存储库中的Dockerfile文件。</p><p></p><p>为了部署Debezium Kafka Connect，我们将使用Strimzi提供的<a href=\"https://strimzi.io/docs/operators/latest/deploying.html#deploying-kafka-connect-str\">KafkaConnect</a>\"，因为它简化了整个过程。在这个Kubernetes资源文件中，我们指定了Kafka版本、Kafka集群的位置（my-cluster-kafka-bootstrap:9092）、容器镜像（quay.io/lordofthejars/debezin-connector-mysql:1.9.4），以及一些特定的配置参数。</p><p></p><p>创建一个名为debezium-kafka-connect.yaml的文件，内容如下：</p><p></p><p><code lang=\"java\">apiVersion: kafka.strimzi.io/v1beta2\nkind: KafkaConnect\nmetadata:\n name: debezium-connect-cluster\n annotations:\n   strimzi.io/use-connector-resources: \"true\"\nspec:\n version: 3.2.0\n image: quay.io/lordofthejars/debezium-connector-mysql:1.9.4\n replicas: 1\n bootstrapServers: my-cluster-kafka-bootstrap:9092\n config:\n   group.id: connect-cluster\n   key.converter: org.apache.kafka.connect.json.JsonConverter\n   value.converter: org.apache.kafka.connect.json.JsonConverter\n   key.converter.schemas.enable: false\n   value.converter.schemas.enable: false\n   offset.storage.topic: connect-offsets\n   offset.storage.replication.factor: 1\n   config.storage.topic: connect-configs\n   config.storage.replication.factor: 1\n   status.storage.topic: connect-status\n   status.storage.replication.factor: 1\n</code></p><p></p><p>然后在终端窗口中应用这个资源：</p><p></p><p><code lang=\"java\">kubectl apply -f debezium-kafka-connect.yaml -n kafka\n</code></p><p></p><p>并通过运行以下命令验证它是否被正确部署：</p><p></p><p><code lang=\"java\">kubectl get pods -n kafka\n\ndebezium-connect-cluster-connect-546c8695c-lszn7        1/1     Running   0          91m\n</code></p><p></p><p>请记住，这个过程可能需要几分钟的准备时间。</p><p></p><p>Kafka Connect组件现在连接到了Kafka集群，最后一步是通过配置让它监听MySQL实例的数据变更。</p><p></p><p>为此，我们将使用Strimzi提供的KafkaConnector。这有点类似于我们在DebeziumConfiguration类中所做的那样，提供database.hostname或table.include.list之类的参数。此外，我们还要将strimzi.io/cluster的值设置为上一个YAML文件中指定的KafkaConnect名称（debezum-connect-cluster）。</p><p></p><p>创建一个名为debezium-kafka-connector.yaml的文件，内容如下：</p><p></p><p><code lang=\"java\">apiVersion: kafka.strimzi.io/v1beta2\nkind: KafkaConnector\nmetadata:\n name: debezium-connector-mysql\n labels:\n   strimzi.io/cluster: debezium-connect-cluster\nspec:\n class: io.debezium.connector.mysql.MySqlConnector\n tasksMax: 1\n config:\n   tasks.max: 1\n   database.hostname: mysql\n   database.port: 3306\n   database.user: root\n   database.password: alex\n   database.server.id: 184054\n   database.server.name: mysql\n   database.include.list: moviesdb\n   database.allowPublicKeyRetrieval: true\n   table.include.list: moviesdb.OutboxEvent\n   database.history.kafka.bootstrap.servers: my-cluster-kafka-bootstrap:9092\n   database.history.kafka.topic: schema-changes.movies\n</code></p><p></p><p>通过应用资源来配置Debezium Connector：</p><p></p><p><code lang=\"plain\">kubectl apply -f debezium-kafka-connector.yaml -n kafka\n</code></p><p></p><p>为了验证一切工作正常，我们添加一条新的电影数据记录，并验证将新记录插入数据库时Kafka主题中会产生一个新事件。</p><p></p><p>获取新服务的端口，IP仍然是相同的：</p><p></p><p><code lang=\"java\">kubectl get services -n kafka\n\nmovie-plays-producer-debezium-server   LoadBalancer   10.100.117.203        80:30307/TCP                 67m\n\ncurl -X 'POST' \\\n  'http://192.168.59.104:30307/movie' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"name\": \"Minions: The Rise of Gru\",\n  \"director\": \"Kyle Balda\",\n  \"genre\": \"Animation\"\n}'\n</code></p><p></p><p>使用kafka-console-consumer.sh脚本验证插入的数据：</p><p></p><p><code lang=\"java\">kubectl exec -ti my-cluster-kafka-0 -n kafka /bin/bash\n</code></p><p></p><p>然后在容器中运行脚本。注意，Debezium连接器将事件发送到一个Kafka主题，名称是这样的..，在这个示例中是mysql.moviesdb.OutboxEvent。<p></p><p></p><p><code lang=\"java\">./bin/kafka-console-consumer.sh --topic mysql.moviesdb.OutboxEvent --from-beginning --bootstrap-server localhost:9092\n\n{\"before\":null,\"after\":{\"id\":\"Yxk0o5WwTvi0+nwBr2Y36wAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\",\"aggregatetype\":\"Movie\",\"aggregateid\":\"5\",\"type\":\"MovieCreated\",\"timestamp\":1660253420864918,\"payload\":\"{\\\"id\\\":5,\\\"name\\\":\\\"Minions: The Rise of Gru\\\",\\\"director\\\":\\\"Kyle Balda\\\",\\\"genre\\\":\\\"Animation\\\"}\",\"tracingspancontext\":null},\"source\":{\"version\":\"1.9.4.Final\",\"connector\":\"mysql\",\"name\":\"mysql\",\"ts_ms\":1660253420000,\"snapshot\":\"false\",\"db\":\"moviesdb\",\"sequence\":null,\"table\":\"OutboxEvent\",\"server_id\":1,\"gtid\":null,\"file\":\"binlog.000002\",\"pos\":8788,\"row\":0,\"thread\":41,\"query\":null},\"op\":\"c\",\"ts_ms\":1660253420878,\"transaction\":null}\n</code></p><p></p><p>before字段是空的，因为是插入操作，所以没有前值，但是在after字段中有电影信息数据。</p><p></p><h2>结论</h2><p></p><p></p><p>我们已经将应用程序从本地迁移到了Kubernetes集群中。</p><p></p><p>Strimzi为我们提供了在Kubernetes中部署和管理Apache Kafka集群的一个关键元素。我们可以使用Kubernetes资源文件安装和管理集群，采用GitOps的方式来管理Kafka。</p><p></p><p>Debezium Embedded适用于一些场景，比如在检测数据变更时使用的临时逻辑。不过，在其他项目中（特别是在遗留项目或需要高可伸缩性和容错性的项目），Debezium Server可能更合适。</p><p></p><p>有了Strimzi、Jib和Kubernetes Quarkus扩展，从本地转移到Kubernetes集群应该并不难。</p><p></p><p>本文的源代码可以在<a href=\"https://github.com/lordofthejars/movie-plays-kafka/tree/main/strimzi\">GitHub</a>\"上找到。</p><p></p><h2>作者简介</h2><p></p><p></p><p>Alex Soto是Red Hat的开发者体验总监。他对Java和软件自动化领域充满热情，并相信开源软件模型。Soto是《Testing Java Microservices》（Manning出版）和《Quarkus Cookbook》（O'Reilly出版）的合著者，也是多个开源项目的贡献者。自2017年以来，他获得Java Champion的称号，也是Salle URL大学的国际演讲师和教师。你可以在Twitter上关注他（Alex Soto），继续关注Kubernetes和Java世界的动态。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/strimzi-the-gitops-way/\">https://www.infoq.com/articles/strimzi-the-gitops-way/</a>\"</p><p></p><p>相关阅读：</p><p>本系列第一部分：<a href=\"https://www.infoq.cn/article/cFpvXRLmZzJBGbzAeFu5\">使用 Apache Kafka 实现 Quarkus 的反应式消息</a>\"</p><p>本系列第二部分：<a href=\"https://www.infoq.cn/article/WfA0p1XoZCJ6INdyJLyv\">Kafka Streams 与 Quarkus：实时处理事件</a>\"</p><p>本系列第三部分：<a href=\"https://www.infoq.cn/article/V4kqPgrQlqqPgWQuMmDP\">Debezium 和 Quarkus：通过 CDC 模式来避免双重写入</a>\"</p><table></table></p>",
    "publish_time": "2022-10-12 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "现代化工具链在大规模 C++ 项目中的技术实践",
    "url": "https://www.infoq.cn/article/KsctTt5cIpCCl5T2SmtJ",
    "summary": "<p></p><blockquote><a href=\"https://www.infoq.cn/article/Y9KJX5zaEXov90wK68JP\">C++ 语言</a>\"与<a href=\"https://xie.infoq.cn/article/f5c1ccfd528e8a169edbc3711\">编译器</a>\"一直都在持续演进，出现了许多令人振奋的新特性，同时还有许多新特性在孵化阶。除此之外，还有许多小更改以提高运行效率与编程效率。本文整理自全球 C++ 及系统软件技术大会上的精彩分享，作者将带我们了解&nbsp;C++ 项目的实践工作等具体内容。</blockquote><p></p><p></p><h2>介绍</h2><p></p><p></p><p>C++ 是一门有着长久历史并依然持续活跃的语言。C++ 最新标准已经到了 <a href=\"https://xie.infoq.cn/article/bb41da0e3eed0c7f42571c3d8\">C++23</a>\"。Clang/LLVM、GCC 与 MSVC 等三大编译器都保持着非常频繁的更新。除此之外的各个相关生态也都保持着持续更新与跟进。但遗憾的是，目前看到积极更近 C++新标准与 C++新工具链的都主要以国外项目为主。国内虽然对 C++ 新标准也非常关注，但大多以爱好者个人为主，缺乏真实项目的跟进与实践。</p><p></p><p>本文以现代化工具链作为线索，介绍我们实际工作中的大型 C++ 项目中现代化工具链的实践以及结果。</p><p>对于 C++ 项目，特别是大型的 C++项目而言，常常会有以下几个特点（或痛点）：</p><p></p><p>项目高度自治 – 自主决定编译器版本、语言标准高度业务导向 – 少关注、不关注编译器和语言标准先发劣势 – 丧失应用新技术、新特性的能力沉疴难起 – 编译器版本、语言标准、库依赖被锁死</p><p></p><p>许多 C++ 项目都是高度自治且业务导向的，这导致一个公司内部的 C++ 项目的编译器版本和语言标准五花八门，想统一非常困难。同时由于日常开发主要更关心业务，时间一长背上了技术债，再想用新标准与新工具链的成本就更高了。一来二去，编译器、语言标准与库依赖就被锁死了。</p><p></p><p>同时对于业务来说，切换编译器也会有很多问题与挑战：</p><p></p><p>修复更严格编译器检查的问题修复不同编译器行为差异的问题修复语言标准、编译器行为改变的问题 – 完善测试二进制依赖、ABI兼容问题 – 全源码编译/服务化性能压测、调优</p><p></p><p>这里的许多问题哪怕对于有许多年经验的 C++工程师而言可能都算是难题，因为这些问题其实本质上是比语言层更低一层的问题，属于工具链级别的问题。所以大家觉得棘手是很正常的，这个时候就需要专业的编译器团队了。</p><p></p><p>在我们的工作中，少数编译器造成的程序行为变化问题需要完善的测试集，极少数编译器切换造成的问题在产线上暴露出来 – 本质是业务/库代码的 bug，绝大多数问题在构建、运行、压测阶段暴露并得到修复。</p><p></p><p>这里我们简单介绍下我们在实际工作中遇到的案例：</p><p></p><p>业务1（规模5M）</p><p>业务本身10+仓库；三方依赖50+，其中大部分源代码依赖，部分二进制依赖。二进制依赖、ABI兼容问题 – 0.5人月；编译器切换、CI、CD – 1.5人月；性能分析调优 – 1人月。</p><p></p><p>业务2（规模7M）</p><p>二方/三方依赖 30+，二进制依赖。编译器切换改造 – 2 人月；性能压测调优 – 1 人月。</p><p></p><p>业务3（规模3M）</p><p>二方/三方依赖 100+，多为二进制依赖。二进制依赖、ABI 兼容问题 – 预估 2 人年。</p><p></p><p>在切换工具链之后，用户们能得到什么呢？</p><p>更短的编译时间更好的运行时性能更好的编译、静态、运行时检查更多优化技术 – ThinLTO、AutoFDO、Bolt 等更新的语言特性支持 – C++20 协程、C++20 Module 等持续性更新升级 – 良性循环</p><p></p><p>其中更短的编译时间本身就是 clang 的一个特性，从 gcc 切换到 clang 就会得到很不错的编译加速。同时运行时性能也一直是编译器的目标。而各种各样的静态与运行时检查也是编译器/工具链开发的一个长期主线。另外更新的工具链也会带来更多的优化技术与语言特性支持，这里我们后面会重点介绍。最后是我们可以得到一个长期持续性更新升级的良性循环，这一点也是非常重要和有价值的。</p><p></p><h2>优化技术简介</h2><p></p><p></p><h3>ThinLTO</h3><p></p><p></p><p>传统的编译流程如下图所示</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/49/49a0a0844ea30120bc669b0d58eb8ab2.png\" /></p><p></p><p>编译器在编译&nbsp;*.c&nbsp;文件时，只能通过&nbsp;*.c&nbsp;及其包含的文件中的信息做优化。</p><p></p><p>LTO （Linking Time Optimization）技术是在链接时使用程序中所有信息进行优化的技术。但 LTO 会将所有&nbsp;*.o&nbsp;文件加载到内存中，消耗非常多的资源。同时 LTO 串行化部分比较多。编译时间很长。落地对环境、技术要求比较高，目前只在 suse 等传统 Linux 厂商中得到应用。</p><p></p><p>为了解决这个问题，LLVM 实现了 ThinLTO 以降低 LTO 的开销。</p><p></p><p>GCC WHOPR 的整体架构如图所示。思路是在编译阶段为每个编译单元生成 Summary 信息，之后再根据 Summary 信息对每个编译单元进行优化。</p><p><img src=\"https://static001.geekbang.org/infoq/47/472f5387eac79dab985b7d1c891a3586.png\" /></p><p></p><p>ThinLTO 技术的整体架构如上图所示。都是在编译阶段为每个&nbsp;*.o&nbsp;文件生成 Summary 信息，之后在 thin link 阶段根据 Summary 信息对每个&nbsp;*.o&nbsp;文件进行优化。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6d/6dcf4ec3f426527b9f01d7a15bc768a7.png\" /></p><p></p><p>使用 GCC LTO 的原因是 GCC 的 LTO 实现相对比较成熟。</p><p></p><p>从图上可以看出，在性能收益上 ThinLTO 与 &nbsp;LTO 的差距并不大。而 ThinLTO 与 LTO 相比最大的优势是占用的资源极小：</p><p><img src=\"https://static001.geekbang.org/infoq/84/8434fb161d7b6a7820dcb6f9026092ec.png\" /></p><p></p><p>如图为使用 LLVM ThinLTO、LLVM LTO 以及 GCC LTO 链接 Chromium 时的内存消耗走势图。</p><p><img src=\"https://static001.geekbang.org/infoq/ff/ff6e9f042e2524c435e24b14807bb301.png\" /></p><p></p><p>所以使用 ThinLTO 可以使我们的业务在日常开发中以很小的代价拿到很大的提升。同时开启 ThinLTO 的难度很低，基本只要可以启用 clang 就可以使能 ThinLTO。在我们的实践中，一般开启 ThinLTO 可以拿到 10% 的性能提升。</p><p></p><h3>AutoFDO</h3><p></p><p></p><p>AutoFDO 是一个简化 FDO 的使用过程的系统。AutoFDO 会从生产环境收集反馈信息（perf 数据），然后将其应用在编译时。反馈信息是在生产环境的机器上使用 perf 工具对相应硬件事件进行采样得到的。总体来说，一次完整的 AutoFDO 过程如下图可分为 4 步：</p><p><img src=\"https://static001.geekbang.org/infoq/b7/b759f72f9bbfca37e9cd37dba7cb2c07.png\" /></p><p></p><p>1. 将编译好的 binary 部署到生产环境或者测试环境， 在正常工作的情况下使用 perf 对当前进程做周期性的采集。</p><p>2. 将 perf 数据转化成 llvm 可以识别的格式，并将其保存到数据库中。</p><p>3. 当用户再次编译的时候，数据库会将亲近性最强的profile文件返回给编译器并参与到当前构建中。</p><p>4. 将编译好的二进制进行归档和发布。</p><p></p><p>对于业务而言，AutoFDO 的接入有同步和异步两种接入方式：</p><p></p><p>同步接入：首先编译一个 AutoFDO 不参与的二进制版本。在 benchmark 环境下运行当前二进制并使用perf采集数据。使用 AutoFDO 再次构建一个二进制版本，此二进制为最终发布版本。异步接入：在客户线上机器进行周期性采集，将采集数据进行合并和保存。构建新版本的时候将对应的数据文件下载， 并参与当前版本的编译。</p><p>在实际中开启 AutoFDO 可以拿到 2%～5% 的性能提升。</p><p></p><h3>Bolt</h3><p></p><p></p><p>Bolt 基于 LLVM 框架的二进制 POST-LINK 优化技术，可以在 PGO/基础进一步优化。</p><p></p><p>Bolt 应用于其数据中心负载处理，即使数据中心已进行了 PGO(AutoFDO)和 LTO 优化后，BOLT 仍然能够提升其性能。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/28/28b91f2f276b42ba9a56a043d3f148eb.png\" /></p><p></p><p>1. Function Discovery：通过 ELF 符号表查找所有函数名字与地址。</p><p>2. Read debug info：如果二进制编译时带有 Debug 信息，读取 Debug 信息。</p><p>3. Read Profile data：读取 Profile 数据，用于驱动 CFG 上优化。</p><p>4. Disassembly：基于LLVM将机器码翻译成保存在内存里的汇编指令。</p><p>5. CFG Construction：依据汇编指令构建控制流图（Control-Flow graph）。</p><p>6. Optimization pipeline：经过上述操作，汇编指令内部表示形式均含有Profile信息，就可以进行一系列的操作优化:</p><p>BasicBlock ReorderingFunction Reordering...</p><p>7. Emit and Link Functions：发射优化后代码，重定向函数地址；</p><p>8. Rewrite binary file：重写二进制文件。</p><p></p><p>Bolt 的接入类似 AutoFDO，也需要先收集到 Perf 数据同时使用该数据重新编译。在我们的实践中性能可以提升 8%。</p><p></p><h2>语言特性</h2><p></p><p></p><p>这里我们简单介绍下两个 C++ 语言的新特性 Coroutines &nbsp;与 Modules 来展示更新到现代化工具链后可以使用的 C++ 新特性。</p><p></p><h3>Coroutines</h3><p></p><p></p><p>首先可以先简单介绍一下&nbsp;Coroutines：</p><p>协程是一个可挂起的函数。支持以同步方式写异步代码。C++20 协程是无栈协程。在语义层面不保存调用上下文信息。对比有栈协程两个数量级的切换效率提升。更好的执行 &amp; 切换效率。对比 Callback更简洁的编程模式，避免 Callback hell。</p><p>接下来我们以一个简单的例子为例，介绍协程是如何支持以同步方式写异步代码。首先我们先看看同步代码的案例：</p><p></p><p><code lang=\"text\">uint64_t ReadSync(std::vector Inputs) {\n    uint64_t read_size = 0;\n    for (auto &amp;&amp;Input : Inputs)\n      read_size += ReadImplSync(Input);\n    return read_size;\n}</code></p><p>这是一个统计多个文件体积的同步代码，应该是非常简单。</p><p></p><p>接下来我们再看下对应的异步写法：</p><p><code lang=\"text\">template \nfuture do_for_each(Range, Lambda);                    // We need introduce another API.\nfuture ReadAsync(vector Inputs) {\n    auto read_size = std::make_shared(0);        // We need introduce shared_ptr.\n    return do_for_each(Inputs,                                           // Otherwise read_size would be\n                 [read_size] (auto &amp;&amp;Input){            // released after ReadAsync ends.\n                                    return ReadImplAsync(Input).then([read_size](auto &amp;&amp;size){\n                                             *read_size += size;\n                                             return make_ready_future();\n                                       });\n                                })\n      .then([read_size] { return make_ready_future(*read_size); });\n}</code></p><p></p><p>肉眼可见地，异步写法麻烦了非常多。同时这里还使用到了&nbsp;std::shared_ptr。但&nbsp;std::shared_ptr&nbsp;会有额外的开销。如果用户不想要这个开销的话需要自己实现一个非线程安全的&nbsp;shared_ptr，还是比较麻烦的。</p><p></p><p>最后再让我们来看下协程版的代码：</p><p></p><p><code lang=\"text\">Lazy ReadCoro(std::vector Inputs) {\n    uint64_t read_size = 0;\n    for (auto &amp;&amp;Input : Inputs)\n        read_size += co_await ReadImplCoro(Input);\n    co_return read_size;\n}</code></p><p></p><p>可以看到这个版本的代码与同步代码是非常像的，但这份代码本质上其实是异步代码的。所以我们说：</p><p>协程可以让我们用同步方式写异步代码；兼具开发效率和运行效率。</p><p></p><p>接下来来简单介绍下 C++20 协程的实现：</p><p></p><p>C++20 协程是无栈协程，需要编译器介入才能实现。判定协程并搜索相关组件。（Frontend Semantic Analysis）生成代码。（Frontend Code Generation）生成、优化、维护协程桢。（Middle-end）C++20 协程只设计了基本语法，并没有加入协程库。C++20 协程的目标用户是协程库作者。其他用户应通过协程库使用协程。</p><p></p><p>同时我们在 GCC 和 Clang 中做了以下工作：</p><p></p><p>GCC与社区合作进行协程的支持。GCC-10 是第一个支持 C++ 协程特性的 GCC 编译器。仅支持，无优化。Clang/LLVM与 Clang/LLVM 社区合作完善 C++ 协程。改善&amp;优化：对称变换、协程逃逸分析和CoroElide优化，协程帧优化（Frame reduction），完善协程调试能力、尾调用优化、Coro Return Value Optimization等。在 Clang/LLVM14 中，coroutine 移出了 experimental namespace。Maintaining</p><p></p><p>最后我们还实现并开源了一个经过双 11 验证的协程库 async_simple：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/20/2097c206f96f6fab1d6971ba1b795f6d.png\" /></p><p>async_simple设计借鉴了 folly 库协程模块。轻量级。包含有栈协程、无栈协程以及 Future/Promise 等异步组件。从真实需求出发。与调度器解藕，用户可以选择合适自己的调度器。经受了工业级 Workload 的考验。开源于：https://github.com/alibaba/async_simple</p><p></p><p>最后我们来看下我们应用协程后的效果：</p><p>业务1（1M Loc、35w core）原先为同步逻辑协程化后 Latency 下降 30%超时查询数量大幅下降甚至清零业务2（7M Loc）原先为异步逻辑协程化后 Latency 下降 8%业务3（100K Loc、2.7w core）原先为同步逻辑协程化后 qps 提升 10 倍以上性能</p><p></p><h3>Modules</h3><p></p><p></p><p>Modules 是 C++20 的四大重要特性（Coroutines、Ranges、Concepts 以及 Modules）之一。Modules 也是这四大特性中对现在 C++ 生态影响最大的特性。Modules 是 C++20 为复杂、难用、易错、缓慢以及古老的 C++ 项目组织形式提供的现代化解决方案。Modules 可以提供：</p><p></p><p>降低复杂度与出错的机会更好的封装性更快的编译速度</p><p></p><p>对于降低复杂度而言，我们来看下面这个例子：</p><p></p><p><code lang=\"text\">#include \"a.h\"\n#include \"b.h\"\n// another file\n#include \"b.h\n#include \"a.h\"</code></p><p></p><p>在传统的头文件结构中 a.h与 b.h 的 include 顺序可能会导致不同的行为，这一点是非常烦人且易错的。而这个问题在 Modules 中就自然得到解决了。例如下面两段代码是完全等价的：</p><p></p><p><code lang=\"text\">import a;\nimport b;</code></p><p></p><p>与</p><p></p><p><code lang=\"text\">import b;\nimport a;</code></p><p></p><p>对于封装性，我们以 asio 库中的&nbsp;asio::string_view&nbsp;为例进行说明。以下是&nbsp;asio::string_view&nbsp;的实现：</p><p></p><p><code lang=\"text\">namespace asio {\n\n#if defined(ASIO_HAS_STD_STRING_VIEW)\nusing std::basic_string_view;\nusing std::string_view;\n#elif defined(ASIO_HAS_STD_EXPERIMENTAL_STRING_VIEW)\nusing std::experimental::basic_string_view;\nusing std::experimental::string_view;\n#endif // defined(ASIO_HAS_STD_EXPERIMENTAL_STRING_VIEW)\n\n} // namespace asio\n\n# define ASIO_STRING_VIEW_PARAM asio::string_view\n#else // defined(ASIO_HAS_STRING_VIEW)\n# define ASIO_STRING_VIEW_PARAM const std::string&amp;\n#endif // defined(ASIO_HAS_STRING_VIEW)</code></p><p></p><p>该文件的位置是&nbsp;/asio/detail/string_view.hpp，位于 detail 目录下。同时我们从 asio 的官方文档（链接地址见文末）中也找不到 string_view 的痕迹。所以我们基本可以判断 asio::string_view这个组件在 asio 中是不对外提供的，只在库内部使用，作为在 C++ 标准不够高时的备选。然而使用者们确可能将&nbsp;asio::string_view作为一个组件单独使用（Examples），这违背了库作者的设计意图。从长远来看，类似的问题可能会导致库用户代码不稳定。因为库作者很可能不会对没有暴露的功能做兼容性保证。</p><p>这个问题的本质是头文件的机制根本无法保证封装。用户想拿什么就拿什么。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/3f/c3/3fd7d88f9d647365bcb8794a7134c5c3.png\" /></p><p></p><p>而 Modules 的机制可以保障用户无法使用我们不让他们使用的东西，极强地增强了封装性：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/67/e9/670994c8b42864f25cff5858bde4bce9.png\" /></p><p></p><p>最后是编译速度的提升，头文件导致编译速度慢的根本原因是每个头文件在每个包含该头文件的源文件中都会被编译一遍，会导致非常多冗余的编译。如果项目中有&nbsp;n&nbsp;个头文件和&nbsp;m&nbsp;个源文件，且每个头文件都会被每个源文件包含，那么这个项目的编译时间复杂度为&nbsp;&nbsp;O(n*m)。如果同样的项目由&nbsp;n&nbsp;个 Modules 和&nbsp;m&nbsp;个源文件，那么这个项目的编译时间复杂度将为&nbsp;O(n+m)。这会是一个复杂度级别的提升。</p><p></p><p>我们在&nbsp;https://github.com/alibaba/async_simple/tree/CXX20Modules&nbsp;中将 async_simple 库进行了完全 Modules 化，同时测了编译速度的提升：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8b/8bf8381ba2633d29051bdbb9f913a5cf.png\" /></p><p></p><p>可以看到编译时间最多可以下降 74%，这意味着 4 倍的编译速度提升。需要主要 async_simple 是一个以模版为主的 header only 库，对于其他库而言编译加速应该更大才对。关于 Modules 对编译加速的分析我们在今年的 CppCon22 中也有介绍（链接地址见文末）。</p><p></p><p>最后关于 Modules 的进展为：</p><p></p><p>编译器初步开发完成支持 std modules优先内部应用已在 Clang15 中发布探索编译器与构建系统交互 (ing)</p><p></p><h2>总结</h2><p></p><p></p><p>最后我们再总结一下，使用现代化工具链带来的好处：</p><p></p><p>更短的编译时间更好的运行时性能更好的编译、静态、运行时检查更多优化技术 – ThinLTO、AutoFDO、Bolt 等更新的语言特性支持 – C++20 协程、C++20 Module 等持续性更新升级 – 良性循环</p><p></p><p>希望更多的项目可以使用更现代化的工具链。</p><p></p><p>相关链接：</p><p>asio官方文档链接地址：</p><p>https://think-async.com/Asio/asio-1.22.1/doc/asio/index.html</p><p>CppCon22 链接地址：</p><p>https://cppcon.digital-medium.co.uk/session/2022/how-much-compilation-speedup-we-will-get-from-c-modules/。</p>",
    "publish_time": "2022-10-12 10:47:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "达摩院损失AI“大将”，预训练大模型M6技术负责人杨红霞离职",
    "url": "https://www.infoq.cn/article/DXPyv0mf6q09hmWtNxEV",
    "summary": "<p>阿里达摩院损失AI“大将”。</p><p></p><p>日前，据 Tech 星球报道，阿里达摩院大模型带头人杨红霞已于9月初离职。InfoQ发现，杨红霞于不久前注销了钉钉账号。</p><p></p><h3>全球最大AI 预训练模型 M6 背后的技术负责人</h3><p></p><p></p><p><a href=\"https://www.infoq.cn/article/IhiliY5-iSW4H60ushSl\">杨红霞</a>\"博士是超大规模多模态预训练模型M6的技术负责人。</p><p></p><p>M6，英文全称是 MultiModality-to-MultiModality Multitask Mega-transformer，6 个 M，简称 M6。</p><p></p><p>顾名思义，M6 大模型主打多模态、多任务能力，其目标是打造全球领先的具有通用性的人工智能大模型。</p><p></p><p>2021年 3 月，达摩院发布了国内首个千亿参数多模态大模型 M6，引发海外关注。OpenAI 前政策主管 Jack Clark 公开点评道：“这个模型的规模和设计都非常惊人。这看起来像是众多中国的 AI 研究组织逐渐发展壮大的一种表现。”</p><p></p><p>2021年11月，阿里 M6 宣布<a href=\"https://www.infoq.cn/article/z40A8r0QeP32g0Jo4TK1\">升级</a>\"至万亿参数，并在全球范围内首次大幅降低了万亿参数超大模型训练能耗，更加符合业界对低碳、高效训练 AI 大模型的需求。</p><p></p><p>据悉，通过一系列突破性的技术创新，达摩院团队仅使用 480 卡 V100 32G GPU，即训练出了规模达人类神经元 10 倍的万亿参数多模态大模型 M6，与英伟达、谷歌等海外公司实现万亿参数规模相比，能耗降低超八成、效率提升约 11 倍。</p><p></p><p>这一技术突破将极大降低万亿模型训练门槛，让大模型研究和工业化落地进入更加普惠的时代。</p><p></p><p>针对此次升级，达摩院资深算法专家杨红霞曾表示，“接下来，M6 团队将继续把低碳 AI 做到极致，推进应用进一步落地，并探索对通用大模型的理论研究。”</p><p></p><p>以下为 M6 发展历程：</p><p></p><p>2021 年 1 月&nbsp;——&nbsp;M6 百亿参数模型达成，国内首个百亿规模多模态大模型2021 年 2 月&nbsp;——&nbsp;M6 千亿参数模型达成，国内首个千亿规模多模态大模型2021 年 5 月&nbsp;——&nbsp;M6 万亿参数模型达成，全球范围内首次大幅降低了万亿参数超大模型训练能耗，且成为国内首个实现商业化落地的多模态大模型</p><p></p><h2>AI项目落地难？</h2><p></p><p></p><p>据报道，杨红霞此次离职是因为个人家庭原因。</p><p></p><p>Tech 星球的报道中称，此番杨红霞离职，被认为是达摩院对一些难以落地的商业化项目进行调整。一位阿里云内部人士透露，“达摩院很多项目都是远看很牛，近看难以落地”，虽然二者都在云与科技，但是达摩院的项目与业务产研隔的较远，也很少和云服务一起对外售卖。所以达摩院每个项目的落地应用和商业化程度，很多是个谜。</p><p></p><p>去年5月，阿里宣布AI 大模型首次商用，M6 成为国内首个实现商业化落地的多模态大模型。经过一段时间的试用，M6 作为 AI 助理设计师正式上岗阿里新制造平台犀牛智造，通过结合潮流趋势进行快速设计、试穿效果模拟，有望大幅缩短快时尚新款服饰设计周期。M6 还已应用于支付宝、淘宝等平台，参与跨模态搜索、文案撰写、图片设计等工作。</p><p></p><p>此前，阿里一直强调，达摩院不用有盈利压力。但2022年，互联网企业普遍降本增效，达摩院也进行了诸多调整。在杨红霞之前，阿里集团副总裁、阿里云研究院副院长肖利华，达摩院副院长<a href=\"https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247544724&amp;idx=2&amp;sn=e89dbb5a3823608d0ae1ab7cebbd1ce7&amp;chksm=fbea965bcc9d1f4da26769446553fc0cb96fa8fadde2462163ca238320e6b4bd8b10b3c43a23&amp;scene=27#wechat_redirect\">金榕</a>\"等都已相继离开阿里。</p><p></p><p>杨红霞是AI领域杰出的人工智能科学家。资料显示，杨红霞&nbsp;2007 年本科毕业于南开大学，获统计学学士学位。其后她去往美国杜克大学统计科学系攻读博士学位，师从 David Dunson 教授。杨红霞拥有顶级论文 40 余篇。曾任 IBM Watson 研究员、Yahoo！主任数据科学家等职。她曾带领团队获2019世界人工智能大会最高奖卓越人工智能引领者（Super AI Leader，简称SAIL奖），曾获2022年福布斯中国科技女性50强的荣誉，获得2020年国家科学技术进步奖二等奖。</p>",
    "publish_time": "2022-10-12 12:07:01",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "十问“海外名声大噪”的现代数据堆栈：定义、架构特点及发展趋势",
    "url": "https://www.infoq.cn/article/ZX7RP0GEQOMrRaFtvMuO",
    "summary": "<p>嘉宾 ｜吴英骏、李栋、王宇飞</p><p>采访 ｜赵钰莹</p><p></p><p>数据堆栈是近几年在海外方兴未艾的概念，其中，最知名的当属&nbsp;dbt 的 CEO Tristan Handy 在 2020 年下半年发表的“The Modern Data Stack: Past, Present, and Future”(The Modern Data Stack: Past, Present, and Future)，在文章中，他将现代数据堆栈分成了寒武纪大爆发一期（2012-2016），部署（2016-2020），与寒武纪大爆发二期（2020-2025）三个时代。</p><p>&nbsp;</p><p>在国内，红点中国的合伙人刘岚也在今年初发表的一篇文章中提到，国内也出现了一些在现代数据栈方面布局的企业。那么，到底什么是现代数据堆栈？它是哪些问题的解决之道？如何区分现代数据堆栈和企业内部构建的数据平台、中台、湖仓一体等架构？</p><p>&nbsp;</p><p>本期<a href=\"https://www.infoq.cn/video/IQdSQUTqbmgjV5cel8DC\">《极客有约》</a>\"，我们邀请到了 RisingWave Labs 创始人 &amp;CEO 吴英骏、Kyligence 合伙人兼副总裁李栋、字节跳动数据平台-开发套件方向的负责人王宇飞共同探讨这一新晋技术概念，希望帮助国内开发者和感兴趣的朋友更好地了解<a href=\"https://archsummit.infoq.cn/2022/hangzhou/presentation/4901\">现代数据堆栈</a>\"。</p><p></p><p></p><p>本文将直播精华内容整理后予以刊布，以飨同好。</p><p>&nbsp;</p><p>InfoQ 第一问：“现代数据堆栈”（Modern Data Stack）这个概念具体指的是什么？</p><p>&nbsp;</p><p>吴英骏：我理解现代数据堆栈解决了从数据中提取“信息”的问题。以往主要采用结合&nbsp;Oracle、DB2、SQL Server 等数据库软件搭建一套平台的方式，现在随着云的兴起和各种商业化创业公司的兴起，主要通过“现代”的方式从原始数据中提取信息。</p><p>&nbsp;</p><p>王宇飞：现代数据堆栈的核心是企业数据上云，在此基础上，大数据从采集到应用的全链路被不同细分领域的 SaaS 服务支撑，并且这些服务是可选择和拼装的，这是堆栈的一个意义。我个人感觉，云数仓的演进进一步催化了各个细分数据领域里 SaaS 场景的发展，围绕云上数据全链路的建设过程，可以选择多个 SaaS 服务来解决。比如：第一，数据上云需要先选择一个云数仓；第二，数据落仓，需要对数据进行建设和加工；第三，需要具备元数据管理能力和数据治理能力来保证数据质量和成本；最后，需要反向 ETL 领域的公司推数据到营销系统或 CRM 系统之中。“现代数据堆栈”概念本身不重要，关键是要关注背后要解决的问题。但不得不说的是，国外能发展数据堆栈的核心是企业数据上云和 SaaS 发展比较成熟，国内的情况与国外相比还是差距比较大的。</p><p>&nbsp;</p><p>李栋：技术的出现往往是要解决特定的问题，想要了解 Modern Data Stack 需要先了解 Modern Data Challenge。首先，从用户的角度来讲，数据安全合规的要求、不同企业技术架构的选型和限制导致数据难以集中储存在一个平台或数据库中，最终形成数据孤岛；第二，从需求方面，整个市场趋势变化很快，需要对新信息有特别快的反应速度；第三，在人力成本方面，企业面临如何用更低的 IT 成本来满足更多业务需求的问题。我认为现代数据堆栈就是充分利用云、AI、大数据等技术简化 data pipeline 来帮助用户提升数据使用效率和数据治理效率。</p><p>&nbsp;</p><p>InfoQ 第二问：与现代数据堆栈相对应的还有传统数据堆栈，这二者之间有何区别？企业在从传统数据堆栈向现代数据堆栈转换的过程中，会不会存在一些中间地带？</p><p>&nbsp;</p><p>吴英骏：与 20 年前相比，当今时代数据变得越来越复杂，但数据栈越来越简化，处理的问题也越来越复杂。传统数据库时代，往往需要招不同的工程师去解决数据库管理、导入数据、提取数据、运维等问题。之后，随着云的出现，将管理、运维等事情“外包”出去，企业不再需要招各种工程师，唯一需要做的就是点几下鼠标，拖拽几下或者写几个 SQL 就能全部搞定，帮助企业降低了成本。</p><p>&nbsp;</p><p>王宇飞：现代数据堆栈，核心是基于云实现模块化，倾向于使用专精的组件构成。刚刚英骏老师也提到，传统数据堆栈，需要自己进行部署运维，维护成本较大，云帮助我们降低了成本。另外，随着云的发展和硬件存储成本的降低，数据处理模型也出现了从传统的 ETL 到 EL（T） 模式的转变，ELT 解耦了 EL 和 T，让数据集成系统专注于解决数据抽取问题，简化数据抽取链路的复杂度，使数据开发同学更专注于业务相关的数据转化部分。从字节的角度来看，数据中台的设计一开始就采用了 EL（T）的模式，近期数据集成组件也会开源出来，希望能帮助解决企业数字化转型过程中的数据集成问题。</p><p>&nbsp;</p><p>李栋：云的引入在成本方面实现了很大的优化和突破，除了资源和 IT 基础设施本身的成本优化外，还带来了企业内部数据使用过程中协作流程的转变和优化。传统的数据使用方式大多以 IT 为中心，相反 Modern&nbsp;Data&nbsp;Stack 简化了流程，并以业务为核心。举一个我们服务的国内头部股份制银行的例子，在过去，传统的 BI 使用方式是堆砌报表，业务运营人员需要依赖数据开发团队来分析客户画像，业务人员什么时候想看什么数据完全取决于数据开发团队的资源排期。后来他们搭建了统一指标中台（指标中台是 Modern Data Stack 的一部分），业务人员可以在平台上自助地创建、使用和管理指标，消除对开发团队的依赖，整体效率大幅提高，完成了从以 IT 为中心向以业务为中心的转变。</p><p>&nbsp;</p><p>InfoQ 第三问：刚刚聊到的云成本控制，不少公司过去一段时间都在抱怨收到的云账单费用太贵，这有解决方案吗？</p><p>&nbsp;</p><p>李栋：在我们公司早期做云产品和业务的性能测试时，也经常会遇到一些血泪教训。后来我们总结了一下，这块也是需要从管理上入手的，我们会用指标中台的实践来管理我们的云成本：定义一个指标体系，除了管理所有的账单数据之外，更多的是去管理云资源的用量数据，除了一些结果指标外还要寻找 CPU 资源利用率、资源闲置率、超期使用率等过程指标。从过程上抓管理，通过这种方式，云研发的 Leader 只需要每周或者每天去跟下属们抓这些云的过程指标，确保没有资源的浪费，或者是在资源到期之后及时停掉，通过这些过程日积月累节省云资源。</p><p>&nbsp;</p><p>王宇飞：我自己的理解是，成本可以从两方面来看，一方面是我们真正使用资源的成本，比如如果数据上云要用哪些 SaaS 服务以及一些实际使用云的资源，如果不上云，需要自己去私有化、部署、运维和开发，这个过程还是有开发成本的。最终要考虑这两部分哪个更划算；另一方面，其实海外也存在成本控制方面的痛点，比如有专门的公司提供云上成本控制相关的服务，把数据治理做得更好，在这个过程中帮助企业降本增效。</p><p>&nbsp;</p><p>吴英骏：尽管大家都觉得Redshift或者Snowflake卖的很贵，但从厂商角度一直觉得自己卖东西不贵。要理解这件事，实际上要从另外一个角度看问题，卖东西的时候不是只卖机器，也不是只卖数据库，它其实还“卖人”；假设我们去看 Snowflake 这家公司，我们在云上面购买了一台机器，或者说订阅了一个服务，我们不仅仅是订阅了这个服务，我们还订阅了这个服务背后的一些工程师，这个成本就高了，哪怕电费都是非常高的。假设我们不去买这些服务，只是在 AWS 上开一台 EC2 的机器，大家看账单的时候，可能会觉得开一年这个机器的钱似乎可以直接买一台机器了，如果这样想问题，考虑的可能还不够完善，因为要买一台机器，还要考虑找谁去搬这台机器，我还要付房租，而且机器可能过几年又要淘汰掉了等等，如果把这些成本都算上，我觉得云成本没有那么恐怖。</p><p>&nbsp;</p><p>当然了，我们作为用户来讲，肯定还是觉得云是非常贵的，因为最早的时候数据仓库如Redshift 还是按照机器的数量来付费的，机器开着哪怕不用，还是照样需要为这台机器付费的。所以现在出现了所谓的 Serverless 这种 pay as you go 的方式，使用了多少资源就付多少钱。但是如果使用次数较少，你会看到账单还是比较低的，如果长期用，你会发现还不如去订阅一台机器，这个时候也会更加高效得使用资源。</p><p></p><p>InfoQ 第四问：如果在企业中推进现代数据堆栈，可能谁会最先推进，最先解决的是谁的生产力？解决的是什么样的问题？</p><p>&nbsp;</p><p>吴英骏：推进现代数据堆栈，首先需要换掉数据仓库，再上其他的服务。因为数据仓库是现代数据堆栈的核心。而针对一些没有数仓需求的小公司，在 AWS 上开一个数据库也是可行的，只要服务在云上，就是整个生态中的一环，就可以连接生态里的其他组件，未来如果想换更加高端的数仓，迁移过程也非常简便。</p><p>&nbsp;</p><p>王宇飞：不管是之前的技术栈还是现在的技术栈，本质上解决的都是让数据高效发挥自身价值的问题。在我的理解中，现代数据堆栈强调的更多是以云上数据为中心的平台技术和产品能力，但让数据发挥价值，还需要符合自身行业模式的一些方法论和沉淀。</p><p>&nbsp;</p><p>推进现代数据堆栈，靠数据驱动、自身有较强研发能力的企业，一般通过自研搭建平台产品的方式解决问题；具有一定研发能力的企业，通常采用拼凑组合一些开源产品或者部分采用商业化产品的模式；一些传统或者初创企业可能会采用完全商业化产品。</p><p>&nbsp;</p><p>现代数据堆栈可以解决企业内使用数据同学的生产力，使得他们可以更专注于解决自身业务问题，而不是数据质量问题或数据研发效率问题等。</p><p>&nbsp;</p><p>李栋：在企业里推进现代数据堆栈，除了可以解决降本增效等问题外，还可以提升数据以及数据团队的价值。举一个电商平台的例子：在传统模式中，通过 ETL 开发各种宽表，每个宽表又支撑一些报表，久而久之就会出现宽表爆炸的情况，即便是存储在云上也会产生很大的成本。在数据湖上搭建指标中台，把数据以指标的方式进行统一管理，所以平台中维护的每个指标都是有业务意义的数据资产而不再是成本，一方面可以从业务价值角度更好地管理数据、提升数据管理 ROI，另外一方面还可以帮助数据/IT团队从管理成本变为管理资产，不断提升团队价值和影响力。</p><p>&nbsp;</p><p>InfoQ 第五问：这两年，国内的很多企业在解决数据问题上做了不少事情，比如中台、平台、湖仓一体等，这些事情和现代数据堆栈有什么区别和联系？</p><p>&nbsp;</p><p>李栋：不论是国内的湖仓一体、数据中台还是海外的<a href=\"https://mp.weixin.qq.com/s?__biz=MzI4MTY5NTk4Ng==&amp;mid=2247502757&amp;idx=3&amp;sn=24627a171ef8402303d0b7f42050fbe9&amp;chksm=eba7c838dcd0412e38fefb681b8ea8c4bda482d8480c893da2eb77d0af44f8acb341c21563a8&amp;scene=27#wechat_redirect\"> Data Mesh、Data Fabric&nbsp;</a>\"等理念，核心都是解决数据使用和数据管理中遇到的各类问题。Modern Data Stack 的优势在于丰富的技术生态，企业可以根据自身实际情况在生态中选型，比如想帮助企业建立一个指标体系的时候可以考虑指标中台的方式。</p><p>&nbsp;</p><p>王宇飞：数据中台、湖仓一体和现代数据堆栈应该不是一个维度和层面的概念。企业内部，数据中台应当具备平台能力、方法论和组织模式这三个比较核心的要素，三者结合在一起解决了企业内数据体系建设问题；湖仓一体本质上是从数据处理和存储的场景出发，降低不同场景需求下数据的移动和存储成本，在解决非结构化、半结构化和结构化的数据处理和管理的同时兼顾性能和成本；现代数据堆栈可以解决数据中台的平台产品能力方面的问题，现代数据堆栈中的中心存储和云数仓解决方案可以采用湖仓一体的技术方案。</p><p>&nbsp;</p><p>吴英骏：在小公司中，各个团队之间彼此知道对方在做什么，可以使用&nbsp;USB、Excel 等一些简单的方法传输数据，当发展成比较大的公司后，不同组之间传递数据变得复杂，需要中台这种统一的方式传输数据。在中台中使用的技术栈也可以是现代技术栈，这只是中台的一种实现方式。湖仓一体本质上说的是数据存放到哪里的问题，不管是数据湖还是数据仓库，它都是存储。而现代数据栈的核心是存储，只要存了数据之后，才有管理、分析和可视化数据的需求。现代数据栈的核心是“数据湖”，“湖”的周围是一些生态。</p><p>&nbsp;</p><p>InfoQ 第六问：国内外目前对这件事情的热度差别很大，具体是什么原因？</p><p>&nbsp;</p><p>王宇飞：本质上还是发展阶段不太一样。数据堆栈的核心是基于云，目前国内云的发展和普及度与海外相比还存在一定差距；从客户偏好上来说，国内的客户更喜欢用 All In One 的解决方案。这背后主要有几点原因，一是国内平均 IT 基础能力更差一些，让客户在一个场景的不同细分领域选择不同的产品和解决方案，对客户自身的 IT 要求是比较高的，另外一个原因是国内云 SaaS 产品之间的标准化程度没有海外那么成熟，这也导致目前不同 SaaS 组件之间的成本比较大。</p><p>&nbsp;</p><p>目前来看，整体 All IN ONE 的解决方案对国内企业数据上云和数据化转型过程来说，成本更低。除此之外，ALL IN ONE 还有组件内部联动性和组件之间数据共享方面的优势。举个例子，比如在使用&nbsp; DataLeap 开发平台的过程中，除了写 SQL、配置任务依赖、部署发布耦合运维管理之外还需要拿到元数据平台的信息去提效整个开发过程，在上线前加上治理平台提供的数据质量检测能力，整个操作链路对用户来说是更闭环而不是跨多个产品的方式，这是核心的操作链路体验一致性方面的优势。</p><p>&nbsp;</p><p>但这并不是说现代数据堆栈的这种多细分领域的 SaaS 模式做不到 ALL IN ONE 产品解决方案的优势，只是如果它做到相同程度，成本会高一些。</p><p>&nbsp;</p><p>现代数据堆栈的兴起一定程度上也验证了我们当初的一些判断：随着 SaaS 细分领域的成熟也会出现灵活的对接需求。比如，虽然目前DataLeap开发套件是以 ALL IN ONE 的形式对外，但从比较早期的设计来看，也考虑了各个场景的产品能力，具备一定的独立性，尽量做到了开放兼容的能力，也可以去对接一些其他产品。从最后的发展来说，两种形态可能会是一个长期共存的状态。</p><p>&nbsp;</p><p>最后想说的是，对于企业客户来说，不用过多关注现代数据堆栈、湖仓一体、流批一体等炒热的概念，我们需要看清它背后解决的问题以及给我们带来的价值，依据自身的发展阶段做合理的选择。</p><p>&nbsp;</p><p>吴英骏：我说一下我为什么要做现代数据堆栈，我一开始是不知道这个概念的，等到我创业的时候发现，不管是什么公司都要提这个概念，而这个现象的本质就是，在国外大家非常注重生态，而生态在于打通，我把负责的部分做到最好，其他的部分放心交给其他厂商去做。在所谓的生态里，我可以只做我自己的事情，但同时也希望给用户一个选择的权利，我跟其他厂商的关系不仅仅是单纯的竞争关系，我们两者之间承担一种共建生态的职责而不是内卷。现代数据堆栈就很好地体现了生态这个概念，在现代数据堆栈中，每个平台都会去做集成。而在国内，这相对来说是一件难以接受的事情，大家更习惯一种大一统的解决方案。</p><p>&nbsp;</p><p>李栋：英骏老师针对海外的一些观念和思路介绍的很详细，我多讲一下国内。举一个我们自己的例子，在过去的两年，我们帮国内的很多客户实践了指标中台。去年下半年的时候，我们观察到&nbsp;Metrics&nbsp;Store 在海外也在兴起并出现了一系列的创业公司。当时，虽然 Modern Data Stack 这样的概念在国内还没有兴起，但是 Modern Data Stack 当中的一些细分领域已在国内有很多沉淀，就像我们的客户在指标中台这个方面已经有了实践。</p><p>&nbsp;</p><p>但是，为什么国内就没有形成 Modern Data Stack 这样的生态或者说还正在起步过程当中？云是一方面，另一方面，国内基于细分领域的生态建设的成熟度还不够。但在过去的一两年，越来越多的云原生技术组件和公司都已发展起来，一些开源技术也都开始向云原生方面切入，开始形成这个生态，这些都是很好的现象。我对国内想形成自己的 Modern Data Stack 还是很有信心的，甚至因为不同国家地区的情况不一样，我们也许会形成一个叫“China Data Stack”的概念，更适合于中国本土的一些企业。</p><p>&nbsp;</p><p>InfoQ 第七问：李栋老师刚才提到很多客户开始部署指标中台，这里面是什么在驱动？</p><p>&nbsp;</p><p>李栋：在指标中台部分，核心要看解决的问题是什么。如前面谈到的，企业都需要把使用效率提升起来以及把数据管理做起来，最简单的一个问题在于数据口径的管理，可能大家都有数据仓库或者数据湖，也有客户在做湖仓一体的建设，也许不是云上，但是久而久之，大家都会遇到，也许就是两个部门的人在做数据分析时发现计算指标的口径是不一样的，比如一个零售的企业开会，可能华南区和华北区销售额的计算口径、计算逻辑各有不同，这样会带来背后的无论是数据开发还是业务决策的整个流程上的很多问题，所以就有了统一管理这些指标的需求，就产生了对指标中台的诉求。</p><p>&nbsp;</p><p>InfoQ 第八问：传统BI，自助BI，还有指标中台之间的联系？</p><p>&nbsp;</p><p>李栋：有两点最大的区别。一是一般企业想把BI用好，还是有一定的门槛的，比如各大BI厂商都有一些认证，想成为BI专家一般是需要专业认证的，这就带来了使用门槛上的区别，任何一个业务人员都有自己的KPI或OKR，也就是自己工作中最关心的指标，指标中台是以指标为核心，在指标中台中可以定义、管理、查看、分析这些指标，并开展业务决策，这里的门槛很低，更不需要考认证等；二是数据治理方面，在多数BI系统中，核心管理的都是可视化报表，但是不同报表中很容易存在指标重复或口径不一的问题。通过指标中台可以统一管理所有指标的定义，无论是原子指标还是衍生指标，所有的业务用户或者所有下游的应用都可以在这个平台中获取到最可靠的数据指标，确保所有口径的一致性。</p><p>&nbsp;</p><p>InfoQ第九问：字节跳动在数据治理上面的一些关键动作？</p><p>&nbsp;</p><p>王宇飞：数据治理对我们来说是一个比较看重的问题，这两年我们也在这方面投入了很大的精力，字节的数据治理还是有一些自身的挑战：字节的业务线比较多，组织比较扁平灵活，从上到下发布治理运动的模式在字节不见得行得通；另外由于业务发展快和复杂度高，我们的治理域问题涉及广，不只是成本治理。</p><p>&nbsp;</p><p>基于这些挑战，我们也沉淀了一个全域的数据治理平台，它把像SLA 治理、成本治理、报警治理等治理域全部都串联在一起，可以通过规划式路径一站式的解决多领域问题，提升治理效率。同时我们提倡“集中决策和分布自治”的理念，让不同的业务根据自身发展阶段，制定自己的治理目标。另外，平台也可以监控整个治理过程与最终效果，治理平台能力我们近期也会对外输出。</p><p>&nbsp;</p><p>InfoQ 第十问：未来三到五年，在数据架构的发展方向上，国内和国外的发展状态和方向大概是什么样子的？</p><p>&nbsp;</p><p>王宇飞：我个人理解，国内的数据架构随着云的发展会越来越加强整个生态的建设。现在看到，很多云厂商其实都是以All In One的形式去提供服务，本身也会有局部组件的能力变得越来越开放或局部组件也都在走向开源，像刚刚提到的字节跳动的数据集成工具即将开源，可能也会有一些其他组件开源出来，或者提供第三方对接能力，帮助完善国内整个数据生态的建设和发展。</p><p>&nbsp;</p><p>我个人觉得，如果走到国外这么成熟的SaaS服务生态体系，还需要一定时间。</p><p>&nbsp;</p><p>李栋：我觉得接下来技术的发展，云肯定是一个方面，另一方面是自动化或者智能化。因为无论是AIOps还是数据分析领域增强分析的概念，这些技术的背后都是更多地把AI的自动化技术应用到整个数据平台中。在这样的理念下，Modern Data Stack中的很多场景都可以通过自动化来简化人工的工作。过去很多需要人力的工作被软件和工具所替代，在替代过程中，就需要有更多的AI方面的技术集成进来去实现一些自动化。</p><p>&nbsp;</p><p>吴英骏：针对国外的情况，接下来可能会朝着几个方向发展。第一个方面，接下来会从Subscription Base全面转向Consumption Base；第二个方面 ，所谓天下大事合久必分，分久必合，从SaaS角度来讲，我相信还是会有小的领域互相吃掉，这种也是比较良性的；哪怕是在云这个方面，现在有三朵云AWS、GCP和Microsoft Azure，尽管这三朵云之间不会“互吃”，但我们也发现其实已经有一些工具统一了，比如伯克利大学最近搞的sky computing，把比较割裂的体验做中和；第三个方面，就是我们在做的realtime这个方向。现在的公司数据量特别大，大家会更希望看到实时的结果，所以大家会看到现在很多软件都在做实时推送，同步的频率会越来越高，而我们做的就是对实时流进来的数据做实时处理，同时我们也发现哪怕是可视化的部分也已经有实时的倾向了，就比如之前可能是一张静态报表，现在大家会希望看到一张动态的报表，以上这几方面我相信是比较大的趋势</p>",
    "publish_time": "2022-10-12 13:58:11",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "龙芯中科官宣：龙架构平台已初步支持OpenHarmony操作系统",
    "url": "https://www.infoq.cn/article/gJ8ClaBdEOqcy89jG2qT",
    "summary": "<p>近日，<a href=\"https://www.infoq.cn/article/6uhRvm2HsDxUwic8Xsa3\">龙芯中科</a>\"宣布，在龙芯中科与润和软件共同努力下，OpenHarmony操作系统与龙芯2K0500开发板完成适配验证，龙架构（LoongArch）平台对于<a href=\"https://www.infoq.cn/article/NE86B4oiDempVd5RV06g\">OpenHarmony</a>\"已形成初步支持，万物互联的生态体系与龙芯平台即将全面连接。</p><p></p><p>龙芯中科表示，当前基于龙芯2K0500平台，多个龙芯生态伙伴已形成面向工业物联网关、国产化BMC、教育开发板、IDE编程工具、自主打印机等一系列解决方案。在OpenHarmony的支持下，龙芯中科与更多合作伙伴将进一步扩大国产自主生态丛林，形成信息产业命运共同体，推动万物智联领域创新发展。</p><p></p><p>据了解，龙芯2K0500是一款基于64位LA264处理器核设计的高集成度处理器芯片，主要面向工控互联网应用、打印终端、BMC等应用场景，可实现ACPI、DVFS/DPM动态电源功耗管理等低功耗技术，支持多种电源级别和唤醒方式，并可根据具体应用场景对芯片部分功能和高速接口进行裁剪。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/44/44d159310c3b0a607f7d7deed01f2b0d.png\" /></p><p></p><p>OpenHarmony是全球开发者共建的开源分布式操作系统，2020 年 12 月，博泰、华为、京东、润和、亿咖通、中科院软件所、中软国际等七家单位在开放原子开源基金会的组织下成立了 <a href=\"https://xie.infoq.cn/article/22108203d79c3809d4720bac8\">OpenHarmony 项目群工作委员会</a>\"，开始对 OpenHarmony 项目进行开源社区治理。当前，国内众多厂商已基于其形成多个跨终端全领域的发行版操作系统。</p><p></p><p>为推动龙架构芯片适配OpenHarmony系统，2022年4月，龙芯中科与润和软件、慧睿思通、龙芯俱乐部等发起成立OpenHarmony LoongArch SIG。</p><p></p><p>龙芯中科表示，下一步将与润和软件携手继续完成更多龙架构芯片与OpenHarmony的适配，共建基于龙架构平台的OpenHarmony国产自主生态及全栈式解决方案，推进产品化工作以及相关方案落地。同时，双方将就OpenHarmony产业人才教培展开深入合作，并会逐步将代码开源到OpenHarmony社区，为开源生态持续贡献力量。</p>",
    "publish_time": "2022-10-12 14:23:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "搭上绿色金融科技“快船”的最佳方式",
    "url": "https://www.infoq.cn/article/xlshY7xzPkVyq5rK4BtT",
    "summary": "<p>国家“十四五”规划中明确指出，我国要稳妥发展金融科技，加快金融机构数字化转型。2022 年，主管部门制定《金融科技发展规划（2022-2025年）》，重在推动金融科技健全治理体系，完善数字基础设施，促进金融与科技更深度融合、更持续发展。为把握金融科技战略发展机遇期，深圳市地方金融监督管理局发布了《扶持金融科技发展若干措施》。</p><p>&nbsp;</p><p>于是，由深圳市地方金融监督管理局、深圳市南山区人民政府、深圳市福田区人民政府作为战略指导单位，深大微众金融科技学院、微众银行、深圳香蜜湖国际金融科技研究院作为主办方联袂打造的“ <a href=\"https://www.infoq.cn/article/7ejrDIB7r5KRIuLwaRPd\">2022 深圳国际金融科技大赛（FinTechathon）——西丽湖金融科技大学生挑战赛</a>\"”于 2022 年 9 月 19 日正式开赛。大赛为同学们准备了超过 69 万元的奖金池、联合深圳金融及科技类 10 余家企业提供 100 多张名企面试直通卡等重磅好礼。</p><p>&nbsp;</p><p><a href=\"https://www.infoq.cn/article/zoACG6LNerBfgzPhGQWD\">大赛前身</a>\"是 FinTechathon 微众银行金融科技高校技术大赛，本届大赛全面升级，设立了“金融产品经理”全新赛道，为帮助参赛选手尽快熟悉和理解赛题赛制，9 月 29 日特别安排了针对本赛道赛题解析的线上技术公开课。深大微众金融科技学院院长助理祁涵、微众银行揽月平台负责人殷磊与微众银行创新孵化项目组高级产品经理赵锦哲带来了精彩分享。点击链接（<a href=\"https://www.infoq.cn/video/zoWTxiawoZwaHoSscI3Y\">https://www.infoq.cn/video/zoWTxiawoZwaHoSscI3Y</a>\"）可观看直播回放。</p><p>&nbsp;</p><p>以下为本期公开课直播精华内容整理：</p><p>&nbsp;</p><p></p><h2>深大微众金融科技学院院长助理祁涵：“金融科技产品校园实践”</h2><p></p><p>&nbsp;</p><p>金融科技是公认的现代金融转型新引擎之一。深圳大学金融科技学院作为大湾区第一家金融科技学院，近年来同微众银行银行合作取得了丰硕的产学研共建成果。在本期公开课的第一部分，深大金融科技学院院长助理祁涵就从金融科技的产业概况入手，介绍了学院在实践中培养金融科技人才的细节和心得。</p><p>&nbsp;</p><p>所谓金融科技，就是技术驱动的金融创新。金融科技不仅是推动传统金融业数字化转型的引擎，还可以促进普惠金融发展，防范金融风险。当前金融科技涉及的几大核心技术包括人工智能、区块链、云计算、大数据、数据可视化等，这些技术在实践中都有着广泛应用，例如人工智能分析遥感数据监测碳排放、区块链加强金融透明化、分布式云存储系统支持金融电子化服务、大数据分析经济不确定性、数据可视化助力金融知识普及等等。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/02/8a/0249db18e16a0b442d6e090e6ee5438a.png\" /></p><p></p><p>如今，多国政府都将金融科技作为重点产业来培育。但金融科技的发展离不开人才培养，以意图打造全球金融科技中心的深圳市为例，据测算金融科技人才缺口多达 150 万。深圳大学金融科技学院是粤港澳第一家金融科技学院，有着大湾区与深圳先行示范区的政策支持。学院同微众银行与法国兰特高登商学院开展了校企深度合作与国际化办学，争取打造世界顶级的金融科技学院，为全国金融科技产业持续输送后备人才。</p><p>&nbsp;</p><p>微众银行与深大金融科技学院取得了大量产学研共建成果。微众银行专家为学院课程编写教材、授课并带领学生进行项目落地实践。学院首届毕业生在实践课程中完成了 10 个项目，全部得到了业界专家高度评价。其中，“轻流RPA金融监测平台”已在中国银行深圳分行落地使用。“基于财业数据的可视化展示”则被认为具有市场化应用潜力，该项目将银行后端数据库中日常操作的所有数据与前端数据可视化进行有机结合，监控银行主要业务指标、财务状况的同时，也为未来业务发展做预测分析。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/2c/0a/2c29d39c42423d23e9886971ee57ce0a.png\" /></p><p></p><p>祁涵认为，本届大赛的参赛选手凭借过硬的技术背景和知识储备，有望做出比上述作品更理想、落地可行性更高的产品。希望选手对自己的作品充满信心，以积极的心态参加大赛并取得优异成绩。</p><p>&nbsp;</p><p></p><h2>微众银行揽月平台负责人殷磊：“绿色金融科技的技术探索与应用实践”</h2><p></p><p>&nbsp;</p><p>环境保护、可持续发展是每一个行业必须关注的重大议题。随着金融行业全面转型数字化，IT基础设施的能源消耗等问题也成为了行业面对的一大挑战。微众银行在全力发展金融科技的同时，也对可持续发展、绿色金融主题投入了大量资源。微众银行揽月平台负责人殷磊就为大家解读了绿色金融理念与相关的技术探索与应用实践。</p><p>&nbsp;</p><p>科学研究表明，温室气体（以二氧化碳为主）排放是全球变暖现象的主要成因。70%的温室气体来自于能源领域，其中又有 30% 来自发电厂排放。为保护地球环境，实现可持续发展目标，中国将碳达峰、碳中和列为国家主要战略方向。基于这一战略，国家大力推进新能源产业，限制煤炭、石油等传统工业发展，希望在 2030 年实现碳达峰，2060 年实现碳中和目标。</p><p>&nbsp;</p><p>目前，中国年碳排放量达 130 亿吨，要在未来 40 年中将这一数字降至零需要全社会的共同努力。在这样的背景下，微众银行响应国家战略号召，投入一流人才队伍和资源建设了“揽月平台”。揽月平台的宗旨是通过人工智能、大数据等技术，对国内传统能源与新能源行业进行全方位客观分析，为监管部门与企业提供直观易懂的量化报告，为新能源国家战略提供助力。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/99/68/9939957706cd110ac41dd2aac00bcc68.png\" /></p><p></p><p>在实践中，揽月平台在诸多领域取得了颇具价值的成果。例如，揽月平台通过AI手段监测和预估大型钢厂与电厂的碳排放浓度；通过卫星遥感数据测算全国范围内部署的光伏面板总量，从而制定光伏方向的新能源发展指数；通过卫星雷达监测各大新能源汽车厂商的产量，结合停车场数据制定新能源汽车发展指数；结合遥感图像与大数据，分析企业建厂的环境影响，等等。针对近年来监管部门、投资者对企业 ESG 指数的测算需求，揽月平台还可以结合多种传感器获得的企业数据，与企业涉及的环保处罚数据、互联网新闻评论等多渠道信息综合给出 ESG 评分，填补了这一领域的空白。</p><p>&nbsp;</p><p>总体而言，微众揽月平台利用 AI 分析多渠道数据，可以在宏观经济分析、企业经营活动监测、绿色金融等领域做出可观贡献。殷磊也希望参赛选手能够从中获得启发，设计出富有创意的优秀作品。</p><p>&nbsp;</p><p></p><h2>微众银行创新孵化项目组高级产品经理赵锦哲：“金融产品经理赛道赛题、赛制解读”</h2><p></p><p>&nbsp;</p><p>近年来，国家金融监管机构对双碳战略、绿色金融非常关注。去年以来，《绿色债券支持项目目录》、《绿色金融评价方案》、《银行业保险业绿色金融指引》等政策指引相继出台，显示绿色金融产业已获得国家高度重视。与此同时，刚刚起步的绿色金融也存在很大探索空间，行业希望利用区块链、人工智能、大数据等先进技术帮助绿色金融业务实现精细化、多元化发展。这也是本次产品经理赛道的赛题背景。</p><p>&nbsp;</p><p>在本期公开课的最后，微众银行创新孵化项目组高级产品经理赵锦哲结合自身的专业经验对本届大赛产品经理赛道的赛题、赛制进行了深度解读。产品经理赛道为开放式命题，参赛选手需要围绕“数字化转型时代，金融科技应该如何赋能绿色金融业务？”这个话题完成产品设计方案，包括但不限于从碳账户、绿色投资、绿色信贷等方面进行探讨。</p><p>&nbsp;</p><p>选手在设计作品时，可以参考微众银行现有的两个案例。其一，为微众银行面向年轻用户群体推出的 We2000 数字账户设计产品方案。该产品具有消费、闲钱管理、攒钱花等功能，选手可以设法将日常生活中的减碳行为与这一账户结合，如设计碳积分变现体系为用户的减碳行为带来收益等。其二，选手可以结合微众银行揽月平台（<a href=\"https://ms.webank.com/\">https://ms.webank.com/</a>\"）实现的 ESG 评分能力，设计创新产品方案来支持金融机构绿色投资、绿色信贷、企业碳账户等场景。</p><p>&nbsp;</p><p>产品经理赛道的评委将主要根据四大维度对作品打分，参赛选手们可以着重关注一下：</p><p>&nbsp;</p><p>创新性。作品需要有效的竞品和市场分析，并且总结出产品的优劣势、创新点；作品要有清晰的产品设计思路，产品流程设计、功能模块设计、业务模式设计有亮点可循。完整性。作品需同时提供 PPT 和 Word 文档。PPT 给出完整的产品介绍，Word 文件包含完整的产品设计文档，包括设计背景、流程、功能模块、商业模式的说明。产品流程应形成闭环，各环节参与角色均要有自己的作用。技术先进性。产品经理赛道不要求作品提供详细代码，但选手要对产品所用技术有清晰认识，清楚说明所使用的技术、对应场景和痛点。社会效益和经济效益。希望作品对于双碳战略和绿色金融起到助力作用，且产品模式链条上参与的角色能够获得激励，进而保持长期参与，从而使产品方案能够良性运转下去。</p><p>&nbsp;</p><p>想要报名<a href=\"https://www.infoq.cn/article/amRrNh9XruvaPjY90RWO\"> 2022 深圳国际金融科技大赛（FinTechathon）</a>\"——西丽湖金融科技大学生挑战赛产品经理赛道的同学可以到大赛官网（<a href=\"https://www.infoq.cn/zones/fintechathon/campus2022\">https://www.infoq.cn/zones/fintechathon/campus2022</a>\"）进行报名，1-5个人都可组队参赛，如果没找到小伙伴，也可以先报名，我们大赛组委会可以帮助同学们组队！</p><p>&nbsp;</p><p></p><h2>大家关注的其他问题</h2><p></p><p>&nbsp;</p><p>Q：金融行业优秀的产品经理需要哪些能力和特质？</p><p>A：相比传统的互联网行业产品经理，金融产品经理的入门门槛相对更高。金融产品经理对金融业务要有深刻理解，同时要保证产品的合规性与用户的流畅体验。金融产品经理要做到胆大心细，既有扎实的业务领域知识，还要对产品有独到的见解，敢于尝试创新。从实践来看，金融产品经理还要对金融产品背后运用的技术有深度了解，能够与技术部门同事及时沟通、反馈。这也是深大金融科技学院对学生的培养方向。</p><p>&nbsp;</p><p>Q：金融产品经理一定要学金融或计算机专业吗？</p><p>A：没有这方面的限制和要求。因为金融科技在持续高速更新换代，产品经理最需要的是持续学习能力。很多产品经理并非这两个专业出身，但会利用业余时间不断学习相关知识，也取得了非常优秀的成绩。</p><p>&nbsp;</p><p>Q：金融科技领域有哪些产品较受欢迎？</p><p>A：日常生活场景有支付宝、微信支付；理财投资领域有富途、东方财富；贷款信用卡领域有微众微粒贷、招行信用卡等，用户体验都很不错。此外，银行常见的自助柜员机，以及数字人民币、网络支付都是金融科技的落地应用成果，给我们的生活带来了更多便利。</p><p>&nbsp;</p><p>Q：碳中和背景下的绿色金融需要怎样的产品属性？</p><p>A：碳中和领域里的一大挑战是量化困难、数据不足、数据时效性不够。如果能够解决这一挑战，会对碳中和目标有很大促进。此外，提供量化能力的产品如果能融入标准体系，也更容易取得成功。</p><p>&nbsp;</p><p>Q：产品经理会做表格、图像分析工作吗？</p><p>A：产品经理是一个综合性岗位，更多要在业务场景和技术中间起到桥梁作用，而不是只做数据分析。</p><p>&nbsp;</p><p>Q：产品经理赛道是否希望选手利用现成技术提出新的构思？</p><p>A：是的。产品经理赛道与互联网+、大创等比赛近似。选手要用产品尝试解决日常生活中面临的问题，同时在产品设计中加入金融科技元素，利用人工智能、区块链、云计算、大数据等工具实现创意。此外，产品经理赛道更注重的是用产品解决现实问题，而不用太多技术层面的创新。</p>",
    "publish_time": "2022-10-12 14:45:40",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AI 遇上金融科技，将擦出怎样的火花？",
    "url": "https://www.infoq.cn/article/ApBkYFrwyto8N6OZAOMT",
    "summary": "<p>人类正在步入一个以核心算法为重要生产要素的智能时代，人工智能技术的进步和创新已经成为社会经济发展的核心。作为新一轮产业变革的核心驱动力，人工智能将进一步释放历次科技革命和产业变革积蓄的巨大能量，创造新的强大引擎。</p><p>&nbsp;</p><p>在人工智能赋能金融的浪潮中乘风破浪，当代青年争做领域“弄潮儿”。为此，“<a href=\"https://www.infoq.cn/article/7ejrDIB7r5KRIuLwaRPd\">2022 深圳国际金融科技大赛（ FinTechathon ）—— 西丽湖金融科技大学生挑战赛</a>\"”这场面向金融科技前沿领域、专为学生团队打造的世界级竞赛，便设置了人工智能赛道。</p><p>&nbsp;</p><p>作为深圳市首届金融科技节中的重要一环，本届大赛由深圳市地方金融监督管理局、深圳市福田区人民政府、深圳市南山区人民政府担任战略指导单位，由深大微众金融科技学院、微众银行、深圳香蜜湖国际金融科技研究院主办。大赛为同学们准备了超过 69 万元的奖金池、联合深圳金融及科技类 10 余家企业提供 100 多张名企面试直通卡等重磅好礼。</p><p>&nbsp;</p><p>为帮助同学们深入了解金融科技前沿成果，尽快熟悉和理解赛题赛制，9 月 28 日，本届大赛人工智能赛道的线上技术公开课上线。来自中国科学院计算技术研究所的陈益强老师、<a href=\"https://www.infoq.cn/article/zoACG6LNerBfgzPhGQWD\">微众银行</a>\"人工智能部服务智能室经理杨海军老师、微众银行人工智能部的高级算法工程师马国强老师围绕“人工智能”相关话题和赛题展开了主题分享。点击链接（<a href=\"https://www.infoq.cn/video/RrCRTejeMWrOBkGv75G8\">https://www.infoq.cn/video/RrCRTejeMWrOBkGv75G8</a>\"）可观看直播回放。</p><p>&nbsp;</p><p>以下为本期公开课直播精华内容整理：</p><p>&nbsp;</p><p></p><h2>中国科学院计算技术研究所陈益强：“人工智能的前沿技术及应用分享”</h2><p></p><p>&nbsp;</p><p>人工智能竞赛推动着人工智能技术的发展。在图像领域，2010 年到 2017 年间每年举办一次的 Image Net 挑战赛完成了使用人工提取特征+机器学习到大规模应用深度神经网络再到广泛使用 ViT 进行图片分类的转变，分类准确率已提升到 90% 以上；在 NLP 领域，从使用词袋技术创建特征输入到机器学习分类器后使用 TF-IDF 微调，到词嵌入+神经网络的广泛使用，再到预训练模型和 TransFromer 架构的大量使用，NLP 系列挑战赛见证了 NLP 发展的历史进程，除此之外的其他大赛，例如 ACM MM Challenge 2022 中更是把视频和自然语言多模态结合在一起做研究，提供了美妆视频时域定位、美妆视频密集描述生成等赛题。</p><p>&nbsp;</p><p>数字经济领域是未来中美竞争和国际竞争之间竞争的主战场，实现数字经济，就是把人工智能赋能到各个传统场景中，把人工智能中的一些在图像、语言、文本、视频中的方法和场景做结合，在结合过程中要考虑以下三个主流问题：</p><p>&nbsp;</p><p>如何按照国务院定义的“原始数据不出域，数据可用不可见”的交易范式来推动AI的研究。这是一个具有挑战性的问题，也是现在的研究热点。由于AI正越来越多地被用于直接影响到人类的福祉、生命或自由的“关键系统”，需要一种在满足监管标准或政策需求的情况下，既能帮助增强用户对 AI 系统的信心与信任，又能防止偏见促进算法公平的可解释的AI。发展囊括了可解释性、安全、隐私、计算等多个方面的可信 AI 已成为全球共识，是未来人工智能健康发展的必由之路。</p><p>&nbsp;</p><p>挑战与机遇叠加，变局与新局并存，陈益强也带来了人工智能发展过程中的挑战和应对策略的分享：</p><p>&nbsp;</p><p>第一，质量低的数据会影响联邦性能，针对数据质量统计问题，可以采用基于联邦共识的数据标签修正方案：利用共识机制，共享参与方置信度，从而计算联邦置信度，利用联邦置信度来实现标签噪声修正。</p><p>&nbsp;</p><p>第二，常规的联邦学习方法会过度拟合本地数据，导致难以快速收敛；通用模型难以自适应个性化的本地数据分布，性能提升有限。针对模型个性化问题，可以采用类别自适应蒸馏的异构联邦学习方法，在分类损失和蒸馏损失之间做平衡。</p><p>&nbsp;</p><p>第三，针对每个中心都建了一个联邦，但多联邦构建主体不一的情况，公共知识积累阶段+个性化阶段的多联邦协同方式较简单地加权平均在效果上提升显著。</p><p>&nbsp;</p><p>第四，做到AI的可解释性，可以采用图神经网络。图网络关系对齐算法就能够把不同图的网络知识图谱在语意关系上进行对齐并表征，使用图神经网络可以更好地表达拓扑关联结构的数据。</p><p>&nbsp;</p><p>最后，做到可信 AI ，可以从以模型为中心和以数据为中心两个方面考虑。以模型为中心时，在给定数据的基础上调整模型达到最优，例如使用决策树解释从根节点到叶节点产生标签的过程，使用类似 Garad-CAM 模型这种基于梯度的解释；以数据为中心时，主要考虑如何完善数据，例如在一站式的模型开发平台通过数据清洗、筛选、标注、增强等过程系统地改进数据。</p><p>&nbsp;</p><p></p><h2>微众银行人工智能部服务智能室经理杨海军：“微众银行场景下的 AI 解决方案”</h2><p></p><p>&nbsp;</p><p>需求引领技术，在AI技术的浪潮下，微众银行面向丰富的业务场景，提供了多种AI解决方案，实现了AI创新成果的快速落地。本次直播分享中，来自微众银行人工智能部的服务智能室经理杨海军老师带来了微众银行的场景化产品矩阵，在解决企业实际问题的同时，也为同学们带来了许多启迪。</p><p>&nbsp;</p><p>首先，杨海军分享了在线智能文本客服、智能语音机器人等面向客户的智能产品，不论是在使用效率、使用成本、还是用户满意度上，它们都交出了一份满意的答卷。值得一提的是，由于NLU应用效果与具体业务场景非常相关，业界厂商提供的通用AI服务在大多实际业务开展中并没有很好的表现。比如业界通用语音识别引擎在微众银行业务中语音识别字准率在70%左右，微众银行则通过自研语音识别引擎并在实际业务应用中进行优化，将语音识别字准率提升到了96%。另外自研的语音合成引擎，针对业务场景进行了深度定制，支持音色、语调、音量等多种场景化设置，达到了不错的应用效果。</p><p>&nbsp;</p><p>然后，杨海军又针对智能坐席助手、智能培训、智能质检等面向银行内部的智能产品做了分享。在智能坐席助手中，通过对坐席与用户的通话录音进行实时质检来规范坐席行为，系统中除了会实时显示用户画像信息外，还会通过根据标准流程对客服进行话术推荐来增加促成效率。而智能培训则可让管理员灵活安排培训任务，让坐席灵活安排时间进行在线培训，可实现智能化交互式培训流程，该系统降低了由于坐席频繁流动带来的培训成本，提高坐席培训的效率。</p><p>&nbsp;</p><p>此外，杨海军还针对智能内容分析、智能营销、智能核身、智能双录、声纹识别、人脸识别、活体检测、多种OCR 应用等进行了逐一介绍分享，这些技术已在微众实际业务中得到了大量应用，并在技术指标上普遍优于业界优秀厂商。</p><p>&nbsp;</p><p>在最后，杨海军分享了将多个独立的产品联合应用在客服、营销、催收、运营等场景中的AI场景化解决方案。比如在客服场景中，用户通过智能文本客服或智能语音客服进行用户咨询或投诉，机器人对用户提问分析后进行回复，同时机器人可自行学习完善知识库；对于机器人无法解决的问题可转接到人工坐席，智能坐席助手对通话内容进行实时智能质检并提供优秀话术引导、流程提示等；此外对于流动性较大的坐席团队还可使用智能培训工具进行坐席培训。</p><p>&nbsp;</p><p></p><h2>微众银行人工智能部高级算法工程师马国强：“人工智能赛道参赛指南和联邦学习 FATE 的应用”</h2><p></p><p>&nbsp;</p><p>抓住了问题的关键，其他一切则会迎刃而解。为此，在 9 月 28 日直播的“<a href=\"https://www.infoq.cn/article/amRrNh9XruvaPjY90RWO\">2022 深圳国际金融科技大赛（ FinTechathon ）—— 西丽湖金融科技大学生挑战赛</a>\"”人工智能赛道公开课中，微众银行人工智能部高级算法工程师马国强为同学们详细解读了“人工智能赛道参赛指南”和“FATE联邦学习”。</p><p>&nbsp;</p><p>本届大赛已于 9 月 19 日启动报名（报名官网：<a href=\"https://www.infoq.cn/zones/fintechathon/campus2022\">https://www.infoq.cn/zones/fintechathon/campus2022</a>\"），以组队赛形式参赛，每个队伍2-5人，报名后由平台协助组队。人工智能赛道的赛题主要是基于FATE联邦学习平台，利用纵向和横向联邦学习去设计一些创新性的产品。初赛阶段主要关注 Demo 的可行性、完备性以及最终实现的可能性，12月初的线下决赛评委会从产品最终完成度，产品完备性、创新度、商业化价值、路演情况这些方面对产品进行评判。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/ea/42/ea86464278869cf81af63a788e4ff942.png\" /></p><p></p><p>马国强对纵向联邦学习和横向联邦学习进行了详细介绍。关于纵向联邦学习的建模，其中各个参与者拥有的数据ID相同，数据特征不同（有的参与者可能没有标签）：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/b2/4a/b24fae8c503595e4bba47ebcec35e44a.png\" /></p><p></p><p>纵向联邦学习中的一些经典协议：</p><p>同态加密：数据在密文状态下运算的结果解密后等价于明文运算下的结果；MPC-SecretSharing：各数据持有方将数据随机拆分成N份后分发给各方，各方只有该数据的一个随机切分部分，最终通过协议可以重构还原计算结果；不经意传输：A持有多条消息m1,m2…mn，B希望获取其中的一条mk，但B不希望A知道获取了mk，A不希望B 获取除了mk之外的其他消息。</p><p>&nbsp;</p><p>下面介绍几种纵向联邦中的常用算法：</p><p>基于隐私保护的样本 ID 匹配。FATE 中提供了 RSA+ 哈希机制的安全求交和基于椭圆曲线的 DH 安全求交两种解决方案；逻辑回归。FATE 提供基于同态加密和 Secret-Sharing 混合协议的纵向联邦逻辑回归；SecureBoost 算法。结合 XGBoost 算法原理及同态加密的协议，在多方数据不出域的情况下去完成梯度直方图的计算，从而构建梯度提升树模型，效果安全无损。</p><p>&nbsp;</p><p>与纵向联邦学习不同的是，横向联邦学习的建模，其中各个参与者拥有的数据特征相同（包括数据标签），数据 indices/ID 不同：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/c5/27/c5a0ab23a958cdacd5cb4ac2cea7e627.png\" /></p><p></p><p>企业将联邦学习在实际业务应用中取得了傲人的成绩。比如，某新闻平台联合多方数据建立联邦推荐模型，在PV、停留时长、CTR方面都有显著提升。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/d7/d2/d797e915c2fc0058b8ba2447cd8e05d2.png\" /></p><p></p><p>又如，某企业通过联邦智能数据合作协同中台，服务某集团内客户资源管理与协同共享。集团内不同业务子公司之间进行大数据合作，准确地分析集团现有客户，更有效地利用集团内部客户资源发挥不同业务板块的数据价值，通过联邦建模建设更有力的推荐服务，从而实现精准的交叉营销。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/05/ef/05871ce06530862e66164dca51dyy2ef.png\" /></p><p></p><p>再如，某通信企业异构平台互联互通。采用轻量化中间件模式，分别基于数据、状态、结果的消息队列技术进行了组件化改造，以最小改动来满足“低耦合、可复制、易扩展”的异构互通需求，利用中间件实现的任务事件转发，贯穿隐私计算任务的各个交互阶段。基于中间件的互通方式，可将对各平台原生框架的改动量降到最小，便于对不同隐私计算平台的扩展对接，具备较好的通用性与灵活性。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/00/ac/003505c3d7928e75b63e6be4f1be1aac.png\" /></p><p></p><p>工欲善其事，必先利其器，一件称心顺手的工具往往能带来意想不到的效果。 作为本届大赛人工智能赛道的指定开发平台，FATE 是全球首个工业级联邦学习开源框架，FATE 也是国内最大的联邦学习开源社区。FATE是目前最具权威和价值的联邦学习开源技术框架，成为很多公司的联邦学习产品技术框架，中国信通院调研统计显示，55% 的国内隐私计算产品是基于或者参考开源框架，其中以FATE开源项目为主。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/63/af/637c0297aa5bfd2f0c061e9ab4d840af.png\" /></p><p></p><p>本届大赛官网中的人工智能学习园区（<a href=\"https://www.infoq.cn/zones/fintechathon/campus2022/support/ai\">https://www.infoq.cn/zones/fintechathon/campus2022/support/ai</a>\"）也提供了很多 FATE 教学视频供同学们参考。FATE 支持 AlllnOne集群版部署、单机版部署，以及 K8s 部署等多种方式，本次比赛不对使用的 FATE 版本做任何限制，同学们可按需使用。</p><p>&nbsp;</p><p>同时同学们在开发上层系统的时候可能会用到 FATE 提供的 RestAPI 或 python SDK 去进行系统对接。此外，马国强还向同学们推荐了一个比较好用的工具—— FATE-Pipeline 客户端，它是和Keras类似的用户建模编程界面，接口比较简单，写一个“联邦建模流程”和“神经网络联邦模型”是很简单的，它可以无缝对接 Keras与 pytorch， 风格保持一致，欢迎大家去使用。</p><p>&nbsp;</p><p></p><h2>同学们关心的其他问题</h2><p></p><p>&nbsp;</p><p>Q：智能语音机器人在研发过程中有什么难点？</p><p>A：智能语音机器人是人工智能技术很多技术模块的集成，包括 ASR、TTS 以及语义理解。在 ASR 部分，我们一开始使用友商后来自研。自研 ASR 的过程中，数据采买和数据标注部分对数据的要求非常高。在 NLU 部分，实现一个比较容易配置的多轮对话的对话树，需要对对话树的每一个节点做语义意图的理解，标注很多数据和一个非常庞大的数据池。此外，在与数据中心、呼叫中心互联的部分，不同的通讯协议会影响交互延时，需要不断进行调优。难度还是比较高的。</p><p>&nbsp;</p><p>Q：有没有学习方面的书籍推荐？</p><p>A：针对初学者，推荐购买一些偏向实践类的书，先去做一些真正的题或者下载一些开源的题去实际运行，针对运行过程中的疑惑，去阅读一些当前技术点相关的理论知识，这样一来，接触的会更快些。可以去网上购买一些人工智能、深度学习相关的手把手或者实践类的书籍；针对有更深需求的人，可以下载一些论文，了解一些比较好比较新的技术后再去尝试。</p><p>&nbsp;</p><p>Q：人工智能赛道提供相关数据吗？纵向联邦的数据集去哪里找？</p><p>A：本届人工智能赛道不提供数据，需要大家自行寻找机器学习的数据并做切分，也可以去找一些业界标准的数据集来使用。本次大赛不提供数据集，也不限制大家的场景，需要靠大家自己去发挥创造力。</p><p>&nbsp;</p><p>Q：比赛过程中面临的一些个性化解决问题时如何使用联邦数据？</p><p>A：数据集的切分和实际使用息息相关，每个人面临的场景不同，需要更加熟悉现实中的场景，只有真正了解该场景，创造的数据才有一些现实意义。同时要注意问题解决思路的可持续性和延展性，让它在后续可以进行一些持续开发、完善和推广。</p>",
    "publish_time": "2022-10-12 14:45:44",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "区块链创新如何助力金融科技发展？",
    "url": "https://www.infoq.cn/article/alkGhdXM8CAawLLAxIjy",
    "summary": "<p>2022 年，国家金融管理部门发布《金融科技发展规划（2022-2025年）》，明确指出我国要注重金融创新的科技驱动和数据赋能，推动我国金融科技从“立柱架梁”全面迈入“积厚成势”新阶段，力争到 2025 年实现整体水平与核心竞争力跨越式提升。为响应国家政策，把握金融科技战略发展机遇期，深圳市地方金融监督管理局发布了《扶持金融科技发展若干措施》。作为深圳市首届金融科技节中的重要一环，<a href=\"https://www.infoq.cn/article/7ejrDIB7r5KRIuLwaRPd\">2022 深圳国际金融科技大赛（FinTechathon）——西丽湖金融科技大学生挑战赛</a>\"（以下称“大赛”）于 2022年 9 月 19 日正式开赛。</p><p>&nbsp;</p><p>大赛面向金融科技前沿领域，由深圳市地方金融监督管理局、深圳市南山区人民政府、深圳市福田区人民政府作为战略指导单位，深大微众金融科技学院、微众银行、深圳香蜜湖国际金融科技研究院作为主办方联袂打造。本届大赛充分利用微众银行与深大微众金融科技学院在金融科技产业与学术研究领域的优势，在深圳市政府相关部门的正确指导下，希望有效激励高校学子探索金融科技应用实践、增强学术和就业竞争力，积极投入金融科技创新事业。</p><p>&nbsp;</p><p><a href=\"https://www.infoq.cn/article/amRrNh9XruvaPjY90RWO\">大赛</a>\"为同学们准备了超过69 万元的奖金池、联合深圳金融及科技类数十家企业提供上百张名企面试直通卡等重磅好礼。为帮助参赛选手深入了解金融科技前沿成果，尽快熟悉和理解赛题赛制，9 月 27 日，区块链赛道公开课直播上线，商道纵横合伙人张智、微众银行区块链首席架构师张开翔与微众银行区块链高级架构师周禄带来了精彩分享。点击<a href=\"https://www.infoq.cn/video/p9BoDdRq3qs4cgSD90z7\">此处链接</a>\"可观看直播回放。</p><p>&nbsp;</p><p>以下为本期公开课直播精华内容整理：</p><p>&nbsp;</p><p></p><h2>商道纵横合伙人张智：“拥抱 ESG，实现企业、价值和环境的共赢”</h2><p></p><p></p><p>ESG，即环境、社会与治理，是当下社会的热点议题之一。ESG 也是本届大赛重点关注的话题。在本期公开课的第一部分，商道纵横合伙人张智就为我们讲解了ESG的基本理念，及ESG与区块链的互动关系。</p><p>&nbsp;</p><p>ESG 的核心理念是企业基于良好的公司治理规范，在环境与社会层面识别潜在风险、实施有效管控，从而给投资人带来长期的财务投资回报。它与常见的企业社会责任概念有着本质差异，与企业捐赠、社会公益没有必然联系。ESG 对于不同行业会有不同的重点。对于金融行业，ESG 的主要议题有绿色金融和普惠金融等。</p><p>&nbsp;</p><p>ESG 本质上是风险管理策略，主要针对企业在社会层面需要面对的非财务风险。近年来，非财务风险对企业运营的影响日益增长，因此企业需要用 ESG 的理念与框架对其进行全生命周期的识别和管控。对于金融行业而言，ESG 相关能力主要体现几个方面的价值：</p><p>&nbsp;</p><p>中国人民银行、银保监会、交易所都对企业的ESG 管理工作与相关信息披露有了明确规定，企业在 IPO 阶段就要满足 ESG 相关诉求；企业面临的环境风险日益增多，需要通过环境风险管理确保资产安全；健全商业道德机制，在监管盲区保障企业稳健运营。这一点对于新兴行业尤为重要；帮助公司治理更加规范成熟，为金融机构提供业务新机遇。例如金融机构可以通过ESG 在绿色金融领域把握市场机遇，并在宏观环境变化背景下进行服务创新，满足客户更多需求等。</p><p>&nbsp;</p><p>当ESG 与区块链技术发生交集时，产生的化学反应有两个方面值得关注：</p><p>&nbsp;</p><p>首先，ESG 会对区块链技术带来正面作用。区块链产业基于 ESG 理念，可以更加关注技术存在的负面影响。在研发产品、推进业务时，区块链企业应做好 ESG 管理工作，积极扩大正面效应，守住科技伦理防线，把控负面影响。</p><p>&nbsp;</p><p>其次，区块链技术能够帮助企业更好地推进ESG 管理。例如，企业可以应用区块链技术管理敏感信息，并上传到公共平台交由社会监管，从而保证信息链条的完整性，避免信息被恶意篡改。由此以来，企业开展业务时就能更好地控制交易风险，更容易赢得客户信任。</p><p>&nbsp;</p><p>总结来看，ESG 的核心逻辑就是通过对企业环境与社会风险的管理，为投资人带来长期回报，ESG 与区块链技术可以相辅相成，形成良性互动。</p><p>&nbsp;</p><p></p><h2>微众银行区块链首席架构师张开翔：“构筑ESG可信基础设施”</h2><p></p><p></p><p>今年4月，微众银行正式宣布推出“微众区块链”全新品牌，并提出了“构筑ESG可信基础设施，促进公平与可持续”的全新使命，致力于为ESG战略中的政府、公众、企业等多方参与构筑信任底座。作为大赛区块链赛道的出题人和评委成员，微众银行区块链首席架构师张开翔在公开课上分享了区块链作为ESG可信基础设施的基本原理和应用。</p><p>&nbsp;</p><p>金融行业的发展是与科技发展高度相关的。例如，过去的银行只有人工服务，今天的银行已经部署了很多无人机器，而未来的银行可能会迈向虚拟化、元宇宙化，客户在任何时间、地点都可以获得金融服务。在这一过程中需要大量科技元素介入，由此催生了金融科技这一行业类型。</p><p>&nbsp;</p><p>在金融科技领域，环境、风险、金融和科技是紧密联系、息息相关的。例如，当养殖场要向金融机构申请贷款时，后者需要充分掌握养殖牲畜的健康状况、了解养殖场的经营现状，综合采集多方数据形成可信、可衡量、可追溯的风险模型。基于这样的模型，保险公司就可以计算保险费率，银行可以确定贷款利率，从而为养殖场提供金融服务。</p><p>&nbsp;</p><p>而区块链技术扮演的角色相当于数据的链条，承载金融服务全过程中的相关数据并提供可信基础。基于这样的锚点，企业可以改善经营状况、降低金融风险，更好地执行ESG 管理工作。由此可见，研究区块链技术的目的不应该是单纯谋利，而是要通过区块链技术帮助建设更好的社会环境，帮助企业实现 ESG 目标，这也是本届大赛区块链赛道的一个核心主题。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/3f/58/3f7b3a56289f9fbcaed207f5ca438458.png\" /></p><p></p><p>具体而言，区块链在ESG 基础设施中主要起到治理、保护、计量和协同四个层面的作用。区块链可以搭建起一套公开透明、全局一致、难以篡改、防止挪用的资产管理体系，也可以有效地保护各个参与方的数据安全与隐私权利。</p><p>&nbsp;</p><p>虽然区块链属于新兴技术门类，但这并不意味着开发者需要面对很高的入门门槛。大赛官方就提供了快速上手路径、开源代码、文档和图形化界面，选手可以在几分钟内就搭建起一个区块链项目原型。选手还可以通过视频课程与教材学习深度内容，尽可能抚平学习曲线。</p><p>&nbsp;</p><p>最后，张开翔老师希望参赛选手能够充分发挥想象力，在充分调研社会实际问题的基础上开发创新的区块链作品，解决现实金融生活领域存在的痛点、难点。张开翔老师也预祝选手取得好成绩，非常期待决赛时与各位优秀选手会面。</p><p>&nbsp;</p><p></p><h2>微众银行区块链高级架构师周禄：“全方位解锁区块链赛道高分秘籍”</h2><p></p><p></p><p>2022 深圳国际金融科技大赛（FinTechathon）——西丽湖金融科技大学生挑战赛以极高的规格和专业水平吸引了国内外大批优秀学子参赛，但很多参赛选手对赛题、赛制了解不足，担心自己因此无法取得更好成绩。于是，本次公开课的最后，微众银行区块链高级架构师周禄为选手们带来了干货满满的“制胜锦囊”。</p><p></p><h4>赛题赛制解析</h4><p></p><p></p><p>本届大赛已于9 月 19 日启动报名，9 月 27-29 日发布线上技术公开课，初赛作品提交截止时间为 11 月 11 日。11 月 23 日公布决赛入围名单，12 月 1日-3 日将举办线下决赛及金融科技高校论坛。</p><p>&nbsp;</p><p>区块链赛道的赛题为开放式命题，选手基于FISCO BCOS区块链底层开源平台、微众区块链系列开源技术设计并开发一个区块链系统，为ESG相关场景提供数字化解决方案，如大湾区一体化、双碳、乡村振兴、公共服务等。</p><p>&nbsp;</p><p>周禄还给出了<a href=\"https://www.infoq.cn/article/zoACG6LNerBfgzPhGQWD\">往届大赛</a>\"作品给参赛选手们做参考，2019 年竞赛获得第一名的项目是排污权许可区块链交易平台，是一个践行ESG场景的典型应用。2020 年大赛的一个获奖项目利用了微众银行的“善度”框架来量化善行。2021 年大赛的季军项目则利用了微众银行的 WeDPR 技术解决慈善募捐信息不对称问题。这些作品的产品方案和代码目前都已经放到了大赛官方开源项目中（<a href=\"https://www.infoq.cn/zones/fintechathon/campus2022/support/blockchain\">https://www.infoq.cn/zones/fintechathon/campus2022/support/blockchain</a>\"），选手可以自行获取。</p><p></p><h4>高分秘籍</h4><p></p><p></p><p>参赛选手需要注意的是，区块链是传递信任的工具，应用场景需要涉及多方共识，因此，作品还要兼顾透明性与隐私保护。选手选择的应用方向需要在链上实现资产化，能够流转、量化、激励，且全过程的每一笔数据流动均可追溯，保障可信验证，这样的场景才是与区块链紧密结合的。本次大赛选择的主题是ESG 方向，选手不能偏题。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/6b/4a/6b895dc08a91bbb6857d496231d4a14a.png\" /></p><p></p><p>开发区块链项目时，首先使用FISCO BCOS 搭建好区块链环境，之后根据题目使用solidity编写智能合约，并部署到链上。选手还要提供相应的合约交互 API，供DAPP调用。以下分层结构仅供参考：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/f1/bb/f17d62002d04b397b0574070ed8373bb.png\" /></p><p></p><p>大赛日程紧凑，选手需要善用官方和业内提供的各种工具、开源项目、智能合约库来加快进度，节约大量时间。官方GitHub 提供了 160 多个代码仓库，包括往届参赛作品；官方黑客松路径提供了历届参赛项目代码和文档。选手如果需要更多资料可以关注微众区块链公众号，后台回复“资料包”即可获取。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/77/de/77aacec862274f21d888a9d7ab8460de.png\" /></p><p></p><p>目前还没有报名的小伙伴，可以到“2022 深圳国际金融科技大赛（FinTechathon）——西丽湖金融科技大学生挑战赛”官网（<a href=\"https://www.infoq.cn/zones/fintechathon/campus2022\">https://www.infoq.cn/zones/fintechathon/campus2022</a>\"）进行报名。</p><p>&nbsp;</p><p></p><h2>大家关注的其他问题</h2><p></p><p></p><p>Q：如何在 ESG 领域选择匹配区块链技术的议题？</p><p>A：选手可以尝试了解中国环境领域近年的重大社会问题，例如环境信息造假、碳市场交易等。选手可以关注热门 ESG 网站或公众号，从过往大事件中挑选与区块链技术匹配的议题。</p><p>&nbsp;</p><p>Q：区块链上记录的隐私数据会被破解和泄露吗？一旦泄露是否会有重大影响？</p><p>A：区块链应用不会将隐私数据本身上链，数据都是加密存储在链下的，区块链主要起到对比验证数据真实性的作用，因此无需担心数据被破解和泄露。</p><p>&nbsp;</p><p>Q：智能合约在现实生活中有哪些应用场景？</p><p>A：智能合约是区块链上共同认可的链上规则，可以实现的内容包罗万象。生活中有很多需要大家共同见证、背书的场景，可以用智能合约的形式来解决共识问题。</p><p>&nbsp;</p><p>Q：参加赛事是否需要掌握特定编程语言？</p><p>A：大赛没有规定具体的应用编程语言，但选手必须掌握 Solidity 这种脚本语言才能开发自己的智能合约。应用层面可以使用多种语言编写，官方提供的 SDK 和中间件也支持多种语言。</p><p>&nbsp;</p><p>Q：参赛项目初赛阶段需要提交哪些材料？</p><p>A：需要提交作品介绍（ppt）、作品技术文档（doc）、作品展示材料（如代码、demo、演示视频）等。</p><p>&nbsp;</p><p>Q：参赛项目主题有哪些限制？</p><p>A：ESG相关产业选题皆可。选手需要深刻理解 ESG 理念，选择具体的场景来解决痛点问题。</p><p>&nbsp;</p><p>Q：过往竞赛有哪些团队经验可供分享？</p><p>A：首先，历届比赛来看女性选手比例逐渐增多；其次，团队中可以安排问题研究和框架设计、代码编写、PPT 准备与宣讲几种角色。组队时最好多元化搭配，体现综合能力。</p>",
    "publish_time": "2022-10-12 14:45:50",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Meta最新款VR头显体验者亲述：Quest Pro更漂亮、更有趣，但佩戴久了，脑袋疼！",
    "url": "https://www.infoq.cn/article/KOcaWVjk3jdAmOFUYEpU",
    "summary": "<p></p><p>声明：本文为InfoQ翻译，未经许可禁止转载。</p><p>&nbsp;</p><p>当地时间10月11日，元宇宙公司<a href=\"https://www.infoq.cn/article/iLFhrxI8yG2Y2P7MiqfL\">Meta</a>\"召开了一年一度的Meta Connect大会，在此次大会上，Meta发布了最新款VR头显Meta Quest Pro。</p><p>&nbsp;</p><p>据报道称，<a href=\"https://www.meta.com/quest/quest-pro/\">Meta Quest Pro</a>\"的功能非常强大，它不仅能以VR形式显示文字和画面，就连细小字体也能得到清晰锐利的呈现。它能跟踪用户的眼球和面部特征，供大家在虚拟空间里与其他人建立完成生动的交流。</p><p>&nbsp;</p><p>简单来说，我们自己皱起眉头或者鼓起脸颊，其中的VR化身也能做出同样的表情。它还支持混合现实功能，把可交互的数字对象叠加在彩显真实背景之下。于是乎，用户可以在虚拟画架上作画，也能在迷你高尔夫球场上挥杆。</p><p></p><h2>新款VR头显价格过万，主要面向商业用户</h2><p></p><p>&nbsp;</p><p>虽然优势多多，但Meta周二发布的这款黑色头显远远超出了大多数受众的预算极限。其售价为1500美元（1499.99美元），几乎相当于同品牌入门Quest 2头显的四倍。从价位、功能和潜在应用场景就能看到，Quest Pro主要面向的是建筑师、设计师、创意用户和VR铁粉，也就是那些对价格不太敏感的消费者。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c9/c95822a3a4e2901b0a2ce59bdc5b62db.png\" /></p><p></p><p>Meta发布的最新VR头显Quest Pro主要面向商业用户，售价为1500美元（折合人民币约10700元）。</p><p>&nbsp;</p><p>Quest Pro的亮相标志着Meta（及公司CEO扎克伯格）已经迎来一大重要里程碑，代表其真的在耗费几年时间加数十亿美元，只为把数字元素与现实世界融合起来、创造出一个人们愿意长期驻留的虚拟空间。</p><p>&nbsp;</p><p>但必须承认，<a href=\"https://www.infoq.cn/article/4iDmM3PgXmvELorwQ8M3\">Meta公司</a>\"的VR部门Reality Labs在商业体量上，还远远无法跟Facebook和Instagram等主干业务相提并论。Meta表示，Reality Labs单在今年第二季度就亏损达28亿美元。</p><p>&nbsp;</p><p>这同时也是一次重大的战略转变，表明Meta公司决定将最前沿的<a href=\"https://qcon.infoq.cn/2022/beijing/track/1308\">VR技术</a>\"先交付给商业客户，培养他们在工作中使用VR与混合现实应用的习惯。虽然这可能会暂时分散消费级VR业务方面的资源，但从长期来看却有望成为扭亏为盈的关键（Meta公司计划设置两条Quest产品线，并借助高端产品线的试水作用探索应将哪些功能下放到消费级层面）。</p><p>&nbsp;</p><p>这样的转变无疑给了<a href=\"https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247575824&amp;idx=2&amp;sn=45d9643ca7d11ca0b93624ae86ef5e64&amp;chksm=fbeb10dfcc9c99c9575e7f4b21f32cbea4fb0135eea60454869ff32ef2f70592751967b71455&amp;scene=27#wechat_redirect\">微软</a>\"和Magic Leap等厂商当头一棒。</p><p>&nbsp;</p><p>多年以来，这些公司也一直在努力说服企业用户，想要证明昂贵的混合现实头显将代表未来的工作常态。</p><p>&nbsp;</p><p>不过“老奸巨猾”的微软还有后手，就是将自家软件引入Quest Pro和Quest 2以摊薄风险，避免大量软件开发投入因自家混合现实HoloLens头显失败而颗粒无收。</p><p>&nbsp;</p><p>目前还不清楚这款强大的设备能否，或者说如何帮助Meta普及所谓<a href=\"https://www.infoq.cn/article/j4AToos49jT09GQ5TCkr\">元宇宙</a>\"。扎克伯格本人对于元宇宙的落地深信不疑，甚至在去年直接把Facebook更名为Meta。</p><p>&nbsp;</p><p>作为新兴VR头显市场的领导者，其消费级Quest 2产品确实受到了广泛欢迎。但与游戏主机相比，目前这部分业务仍然体量有限。</p><p>&nbsp;</p><p>上周，我（本文作者）有幸在Meta总部花了几小时体验这款最新的Quest Pro。结果嘛，既令人印象深刻，又有不少困扰和谜团。</p><p>&nbsp;</p><p>我很快意识到，Quest Pro压根就不打算面向大众用户，这个消息肯定会让两年来苦等Quest 2升级的用户感到沮丧。</p><p>&nbsp;</p><p>但Pro的优点就在于，它确实揭示出未来几年VR与混合现实体验的潜在样貌：更漂亮、更有趣、也更直观。</p><p></p><h2>眼球与面部追踪</h2><p></p><p></p><p>Quest Pro在外观上就明显跟Quest 2拉开了差距。Meta决定在新产品上将电池取向，做成弯曲的形状并单独放置在用户脑后。这样的设计，再加上头带背面的表盘，让用户能够精确调整头显位置，整个佩戴感受越来越趋近于常规眼镜。</p><p>&nbsp;</p><p>这样的布局不禁让人想起了HoloLens 2。表盘设计也降低了头显开关机的难度，对于长发用户可说是相当友好。</p><p>&nbsp;</p><p>但很遗憾，新的布局对部分用户而言可能反而不太舒服，特别是佩戴久了之后。因为脑后的配重增加，加上只能通过一个旋钮来调整单根头带，我时不时就得紧上一下。而且在约两个小时的体验过程中，我用多台头显感受了从虚拟绘画到DJ的六段不同演示，最后脑袋生疼。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e4/e469736ae4fe632f1d28bb8da5b555b7.png\" /></p><p>Quest Pro带有充电座，可以为耳机和控制器供电。</p><p></p><p>Quest Pro上最值得注意的一大新功能，就是它跟追踪佩戴者的眼球和面部，借此提升人们在虚拟空间中与其他化身互动时的真实感。</p><p>&nbsp;</p><p>为此，头显会使用五个红外传感器来捕捉细节，例如用户在看哪里，是在冷笑、微笑、皱眉还是扬眉。此追踪功能默认关闭，Meta还表示系统会在眼球和面部图像处理完成后将数据删除，后续其他应用程序在使用此功能时也必须照此办理。</p><p>&nbsp;</p><p>我在体验Aura外星人演示时尝试了这项追踪功能，Meta希望借此帮助开发者们了解Quest Pro的功能原理。只要将Quest Pro戴在头上，我就可以随意微笑、冷笑、眨眼、眯眼、抽动鼻子等，而Aura外星人会同步做出一样的表情（很遗憾，尚不支持舌头追踪）。即使尚处于开发早期，Aura精准的面部模仿能力和明确的表情区分度还是令人印象深刻。</p><p>&nbsp;</p><p>这种强大的追踪能力，似乎确实朝着扎克伯格承诺的未来迈进了一步。他曾在Facebook上发布过一张自己在Meta旗舰社交应用Horizon Worlds中的方块卡通头像。Meta方面也表示，在Quest Pro发布之后，用户可以在包括Horizon Workrooms、绘画应用Painting VR以及DJ应用Tribe XR在内的各类应用中使用这项功能。</p><p></p><h2>更新的手持控制器</h2><p></p><p></p><p>与传统VR头显相比，Quest Pro其实更像是一款混合现实设备，因为它并不会持续遮挡住外界环境光。Meta在以往的沉浸式VR中专注塑造纯虚拟空间，其中的物理环境并非资产、而单纯成为用户的行动障碍。Meta还专门为此推出过磁性遮光板，用来遮蔽侧面射入的外界光线。今年11月起还将上市另一款售价50美元的配件，据称能够完全阻挡一切环境光。</p><p>&nbsp;</p><p>但可以想见，只有让部分外界光线射入，头显用户才能跟物理环境始终保持联系。以此为基础，Quest Pro头显配备一颗外向摄像头，能够以彩色画面（而非Quest 2上的黑白画面）呈现周边环境。Meta明显想用这种方式把虚拟应用跟真实世界融合起来。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/90/9055f4e9ab3be3f939de8090de061bbc.png\" /></p><p></p><p>Quest Pro头显配有传感器，能够追踪用户的眼球和面部表情。</p><p></p><p>在演示当中，我使用Painting VR在虚拟画布上作画。其中画布一侧的画笔、工具架和油彩罐都是虚拟的，但所处空间却是真实的。我可以在其中混合颜料、拿起画笔、完成创作，再把虚拟画作贴在身后的真实墙体上。整个过程我都能看到身边的物理环境，随时从站在身边的应用开发者那寻求帮助。</p><p>&nbsp;</p><p>Quest Pro随附的手持控制器也在VR和混合现实应用中发挥着重要作用。与Quest 2的手持控制器相比，Quest Pro版得到了极大改进。现在，控制器的空间位置不再由头显本体来确定，而是由控制器内的三个传感器负责实现。如此一来，它们就能跟踪360度运动，在各类应用中带来更好的手部与手臂动作还原效果。（但很遗憾，现在的VR还无法追踪腿部动作。但扎克伯格周二宣布，Meta将在未来向Horizon Worlds引入全身化身。）</p><p>&nbsp;</p><p>与Quest 2控制器相比，Pro版控制器的压力传感器也让运动精度上了一个台阶。我在演示当中拾取并抛掷各种小物件，例如茶杯、积木和花园小矮人。如果是轻轻拿起茶杯、特别是把手部分，那就没有问题；但如果用力握紧杯体，它就会被捏碎。</p><p>&nbsp;</p><p>Facebook在2014年收购VR头显厂商Oculus时，人们根本无法想象像Quest Pro和手持控制器这样的设备能在无需接入中央计算机、或安装大量外部传感器的情况下实现这么丰富的功能。当时，大多数人甚至根本不相信VR能够成为大众技术。但经过了八年锤炼与数十亿美元的投入，我们见证了VR的最新发展，而且对未来有了更大的期待。总而言之，Quest Pro已经在技术上证明了自己，接下来就看用户们买不买账了。</p><p>&nbsp;</p><p>感兴趣的朋友从昨天开始已经可以预订Quest Pro，实际出货时间是10月25日。目前Meta的线上商店已开放购买，美国市场的Best Buy商店/网站和Amazon也都上架了这款产品，那么，价值一万多块的VR头显设备，你会买吗？</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://edition.cnn.com/2022/10/11/tech/meta-quest-pro-vr-headset/index.html\">https://edition.cnn.com/2022/10/11/tech/meta-quest-pro-vr-headset/index.html</a>\"</p><p>&nbsp;</p>",
    "publish_time": "2022-10-12 15:02:34",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "日本63岁退休工程师自学编程，写出二合一计算器程序，上线21天下载量56800次",
    "url": "https://www.infoq.cn/article/WVz57aX3696hAxBKf1OO",
    "summary": "<p>本文最初发布于 Mainichi Japan 博客。</p><p></p><p>日本一名 63 岁的男子是 iPhone 的忠实用户。在退休后的几年时间里，他把一部分时间用来开发一款独特而受欢迎的 App。该 App 可以在一个屏幕上显示两个计算器。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/84/84921d4c818595dbbb678857fe25e77e.png\" /></p><p></p><p>在上图所示的 App 中，一个屏幕里显示了两个计算器。点击箭头，左边计算器的计算结果就可以移动到右边的计算器中，让用户可以继续计算。（Mainichi）</p><p></p><p>这款二合一计算器 App 的 iPhone 和 iPad 版本已经发布，名称为“Twin-Calc”。住在兵库县西宫市的 Hiroyuki Ueda 设计了这款 App。虽然发布初期下载量不高，但经过他一番调整后，下载量出现了猛增。</p><p>在这款双计算器 App 中，用户可以使用屏幕中间的箭头将一个计算器的计算结果移到另一个计算器中。例如，如果一个用户在一个计算器计算“89 x 15 = 1335”，那么点击箭头后，结果“1335”将显示在另一个计算器中，用户可以以此为基础继续计算，而之前的等式仍然显示在屏幕上。这样更便于发现错误。</p><p>也可以在每个计算器上执行不同的计算。例如，当用户想要比较两个商店中同一产品每克的价格时，这个功能就很方便。&nbsp;</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/51/25/514d2eb364cced54d34e011a24165025.png\" /></p><p>如上图所示，该 App 将两个计算器组合到了一个屏幕中。用户可以在每个计算器中执行单独的计算。（Mainichi）</p><p></p><p>Ueda 在大学里学的是机械设计，在 60 岁退休之前，他在一家汽车公司工作了多年，主要从事工程工作，包括传动部件的设计。</p><p></p><p>他原本就是一名忠实的 iPhone 粉丝，退休后因为有时间，就开始学习 Swift 编程。终于，他实现了梦想，开发出了这款他认为可以为人们带来便利的 App。</p><p></p><p>Ueda 将注意力放在了计算器上，这是因为计算器与人们的日常生活息息相关，而且是一种没有语言障碍的通用工具。三、四年前，他开始制定这款应用的愿景，并于 2021 年 8 月开始了实际的开发工作。按照 Ueda 的说法，当时还没有在一个屏幕上把两个计算器结合在一起的 App，他抓住这个机会，开发了一款独一无二的软件，他的目标是开发在 iPhone 和 iPad 上可以运行的 App。</p><p></p><p>不过，Ueda 回忆说，“我原以为那很简单，但却出乎意料地困难。”他在处理带有小数点的数字输入时遇到了麻烦。例如，有些用户在输入 0.5 时会依次点击“0”、小数点、“5”，但也有些用户只输入小数点和“5”，而不输入“0”。他说：“类似这样的情况大约有 100 种，要解决它们需要做大量的工作。”&nbsp;</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/d4/56/d42020a000e0e6f16b3406ff19ed8556.png\" /></p><p></p><p>上图即 Twin-Calc 开发者 Hiroyuki Ueda，照片由他本人提供。</p><p></p><p>经过反复试错，他在 9 个月后的 2022 年 5 月发布了这款应用。最开始，下载量增长缓慢，因为按照设计，它在智能手机竖屏时只显示一个计算器，而只有在横屏时才显示两个计算器。所以，许多用户误以为它只是一个普通的计算器。</p><p></p><p>随后，Ueda 做了一些改动，使应用固定为横屏显示，即应用打开后总是同时显示两个计算器。更新版于 8 月 18 日发布。据 Ueda 说，截至 9 月 8 日，售价为 490 日元（约 3 美元，含税）的版本下载量大约为 56800 次，而免费版本的下载量约为 5000 次。在更新前，付费版本的下载量约为 1.8 万次，所以更新后的下载量增加了三倍多。</p><p></p><p>他评论道：“下载这款应用的人多得令人惊讶。我认为这说明有需求。”他的最新任务是响应在竖屏时显示两个计算器的请求。</p><p></p><p>Ueda 说，他这一代很少有人精通技术，“我希望自己能成为可以激励他人的人。”</p><p></p><p>原文链接：</p><p></p><p>https://mainichi.jp/english/articles/20220916/p2a/00m/0sc/017000c</p>",
    "publish_time": "2022-10-12 15:13:12",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "社区分裂、应用争议，5年都没火起来的WebAssembly “炒错”方向了？",
    "url": "https://www.infoq.cn/article/JgjqtYjuef2VNApb2zok",
    "summary": "<p>WebAssembly（Wasm）已经诞生了五年。在云原生领域，这段时间并不算短，毕竟堪称业界标准的Kubernetes也才出现八年。作为一种供基于堆栈的虚拟机使用的二进制指令格式，Wasm想让开发者实现“一次构建、随处运行”，因此被广泛认为具有改变游戏规则的潜力。</p><p>&nbsp;</p><p>但 HTTP Archive 发布的 2022 年 Web 技术报告显示：“WebAssembly 的应用还不够广泛，我们并没有发现使用量的增加，反而看到了小幅收缩。”</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/09/0937421e8550f986191acf4244049a4e.png\" /></p><p></p><p>WebAssembly 语言使用情况，图源：<a href=\"https://almanac.httparchive.org/en/2022/webassembly#fig-5\">https://almanac.httparchive.org/en/2022/webassembly#fig-5</a>\"</p><p>&nbsp;</p><p>这份报告基于对 800 多万个网站的调查，这些网站是谷歌 <a href=\"https://developer.chrome.com/docs/crux/methodology/\">Chrome Chrome UX Report</a>\"（用户体验报告）所分析的网站。据 Netcraft 的<a href=\"https://news.netcraft.com/archives/category/web-server-survey/\">月度调查</a>\"显示，有超过 11 亿个网站，但其中许多网站并不活跃，因此这份报告仅针对那些最活跃的网站。</p><p>&nbsp;</p><p>需要注意的是，通常情况下，网络爬虫并不会登录 Web 应用，它们只能浏览网站上的公开内容，因此这项调查并不包括那些使用中的 Web 技术应用。当涉及更加以应用为核心的技术时，则可能会导致结果失真，包括 WebAssembly。</p><p>&nbsp;</p><p>尽管如此，在报告中撰写 WebAssembly 分析的技术博主 Colin Eberhardt 并没有放弃，<a href=\"https://almanac.httparchive.org/en/2022/webassembly\">他指出</a>\"，网页中的 Wasm（编译的 WebAssembly 代码）数量很少：</p><p>&nbsp;</p><p></p><blockquote>“我们发现，在桌面上有 3204 个确认的 WebAssembly 请求，移动端有 2777 个。这些模块被用于桌面上的 2524 个域名和移动上的 2216 个域名，分别占桌面和移动上所有域名的 0.06%和 0.04%。”</blockquote><p></p><p>&nbsp;</p><p>对该 Wasm 的分析表明，到目前为止，最大的份额是亚马逊 IVS（互动视频服务），这是 AWS Chime 服务用于优化视频通信的库模块。这并不代表开发者有意为之，仅仅是使用这种特定的AWS 服务的结果。也许更重要的是，微软的 Blazor 框架出现在最普遍 Wasm 使用的第三位，因为这将是开发者为特定网站而编写的代码。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/4a/4a9dcb0468414d41ba0c0b83da7b6c77.png\" /></p><p></p><p>流行的 WebAssembly 库，图源：<a href=\"https://almanac.httparchive.org/en/2022/webassembly#fig-4\">https://almanac.httparchive.org/en/2022/webassembly#fig-4</a>\"</p><p>&nbsp;</p><p>Eberhardt 认为，目现在还没有充分的理由去使用 WebAssembly，原因是 Wasm 代码不能替代 JavaScript，它只能作为 JavaScript 的补充。他认为，WebAssembly 的未来可能不是“作为一个小众的 Web 技术，而是作为一种在其他平台上完全主流的运行时”。</p><p>&nbsp;</p><p>为什么Wasm就一直火不起来？虽然有各种各样的原因，但Wasm自身生态系统的震荡不定却是难辞其咎。</p><p></p><h2>AssemblyScript的分裂</h2><p></p><p></p><p>最近几周，Wasm 生态的问题再度暴露无遗。</p><p>&nbsp;</p><p>AssemblyScript 是一种专为 Wasm 在浏览器中使用所设计的语言。最近，其宣布不再支持WASI——一种易于在浏览器之外使用的Wasm系统接口。目前还不清楚 AssemblyScript 到底为什么要放弃 WASI，但理由大概率还是在技术和观点层面有分歧。</p><p>&nbsp;</p><p>WASI 项目提案侧重于Wasm与Rust、C++等语言的互操作性，相对牺牲了JavaScript，而这最终会损害AssemblyScript（具有TypeScript特性）的利益，并迫使其在项目层面做出重大更改。</p><p>&nbsp;</p><p>AssemblyScript 的作者们通过线上文档<a href=\"https://www.assemblyscript.org/standards-objections.html?utm_source=thenewstack&amp;utm_medium=website&amp;utm_content=inline-mention&amp;utm_campaign=platform\">《对标准的反对意见》</a>\"提出，W3C 的 WASI 子团队“扩大了职能范围”，其“设计的自有提案……会与既定或当前设计的Web标准相竞争。”</p><p>&nbsp;</p><p>除此之外，作者们还表示，“我们的代表受到了系统性歧视，没人在乎他们表达的担忧和反对。”</p><p>&nbsp;</p><p>再者，AssemblyScript 还将矛头指向 Bytecode 联盟。该联盟拥有多家重量级技术成员，包括亚马逊、谷歌和微软三大云服务巨头，专司为Wasm和WASI提供支持。</p><p>&nbsp;</p><p>AssemblyScript的作者们警告称，“我们想提醒公众，应密切关注潜在的反竞争行为。有必要的时候，甚至应该要求反垄断立法的介入。”</p><p>&nbsp;</p><p>这里再介绍一点相关背景：有数据表明，人们对于AssemblyScript的关注正在下降。在Scott Logic今年6月发布的《2022年WebAssembly现状调查》中，只有17%的受访者表示有意在未来大量使用AssemblyScript，比例远低于2021年调查时的26%。</p><p>&nbsp;</p><p>虽然这一结果可能跟Wasm项目范围扩大而导致AssemblyScript用量稀释有关，但必须承认，当前对开发者吸引力最大的仍然是 Go 和 JavaScript 那几种热门语言。AssemblyScript在其中的确缺乏竞争力。</p><p>&nbsp;</p><p>至于反竞争指控，虽然 Bytecode 联盟的成员名单确实有利益集团绑定的嫌疑，但这更多是种对强势技术趋势的主动参与，未必代表各方打算强行通过有利于自己的议程。</p><p>&nbsp;</p><p>Bytecode 联盟成员、边缘云平台厂商 Fastly公司首席技术官Tyler McMullen表达了他对这波冲突的失望之情。</p><p>&nbsp;</p><p>McMullen强调，症结其实就是“一个非常细微的技术细节——是否允许在客串中包含某些无效代码点。” 他指出，这个“技术细节”的决定并不是某个人或一家公司说了算，“提案经过了整个行业中很多专家的审查和投票，包括各家主要浏览器开发商。”</p><p>&nbsp;</p><p>开源平台工具厂商Suborbital工程总监、Grain编程语言联合缔造者Oscar Spencer也有类似判断：</p><p>&nbsp;</p><p></p><blockquote>“这可能引发碎片化趋势，阻碍标准的发展和进步，肯定不利于建立起有凝聚力的生态系统。”</blockquote><p></p><p>&nbsp;</p><p></p><h2>推广Wasm的力量来源并非用户</h2><p></p><p>鉴于这样的冲突和分歧，整体软件社区找不到使用Wasm的理由和必要性。</p><p>&nbsp;</p><p>尽管Wasm最初专门为浏览器所设计，但现在这类用例似乎不是特别重要。大家更多的关注和兴趣主要集中到 Wasm在浏览器之外的潜力，例如在服务器上使用（有望与Docker结合使用，甚至直接替代Docker），或者通过代码捆绑实现跨多应用程序运行。</p><p>&nbsp;</p><p>Spencer对于Wasm的发展历程也有自己的看法：</p><p>&nbsp;</p><p></p><blockquote>“我们最终看到……JavaScript引擎其实已经很快了。单纯用Wasm重写现有应用程序，其实并不一定能让它变得更快，毕竟 JavaScript 引擎已经有了几十年的积累，目前非常成熟且完善。”&nbsp;“正因为如此，在浏览器上用Wasm编写完整应用程序的需求越来越少。现在的开发者更多在用Wasm编写那些对速度比较敏感的后台任务。”</blockquote><p></p><p>&nbsp;</p><p>但这并不是说Wasm在Web世界失去了生命力。相反，它找到了最适合自己的利基市场：强调速度和性能的场景。</p><p>&nbsp;</p><p>全球开源咨询公司 Igalia 软件工程师Andy Wingo提到，他最近刚刚为某受众庞大、基于浏览器的电子表格做了一个项目。在此项目中，他希望“提高JavaScript与Wasm之间的字符串转换效率。”在他看来，这类项目属于“大型利益相关方与浏览器开发商间的一对一合作”，也是Wasm最常见的应用环境之一。</p><p>&nbsp;</p><p>这也再一次提醒我们，虽然新兴技术总能引发炒作热情与激烈讨论，但其最终命运仍然要由非常具体的用例来决定。</p><p>&nbsp;</p><p>Wingo还提到，Fastly和电子商务平台Shopify等企业也在使用Wasm，而这两家公司之所以选择Wasm，是因为供应商们喜欢用。“所以，推广Wasm的力量之源并不是用户，而是先由平台所有者的意愿决定，再一步步传导至用户群体当中。”</p><p>&nbsp;</p><p>Wingo的观点跟McMullen可谓不谋而合，即：并不是所有平台都支持Wasm，“之所以无法广泛支持，是因为Wasm难以嵌入。而导致难以嵌入的原因之一，就是Wasm缺乏标准的交互模型。”</p><p>&nbsp;</p><p>因此，尽管大家普遍对Wasm的速度和性能优势赞不绝口、给予关注，但在实际应用方面仍存在很大的争议甚至是分歧。</p><p>&nbsp;</p><p></p><h2>局外人眼中的Wasm</h2><p></p><p>&nbsp;</p><p>对局外人来说，Wasm是种相当奇怪的语言。</p><p>&nbsp;</p><p>首先，这种语言最初的用途定位跟后来真正让它声名鹊起的用例几乎没有关系，但在脱离浏览器的过程中，Wasm也确实变得更加流畅灵活。于是问题来了：现在的Wasm，还是当初设想的那个Wasm吗？</p><p>&nbsp;</p><p>也许正是存在这个问题，才导致Wasm在标准制定方面遭遇困境——由于缺乏明确的共识，不同群体都在朝着自己心中正确的方向发力。</p><p>&nbsp;</p><p>这对用户和潜在的Wasm开发者来说当然不是好消息。Wingo表示，“人们其实都或多或少知道Wasm的一些特性，只是不清楚为什么会这样。”</p><p>&nbsp;</p><p>但这也未必是坏事，反而凸显出Wasm面临的最大挑战，即如何将其在浏览器中安全高效运行任意代码的能力在制定项目中成功应用。只要解决这点，Wasm必然能够一飞冲天。</p><p>&nbsp;</p><p>Spencer对此表示赞同，并在采访中坦言大多数尝试Grain的用户其实是想借此探索Wasm。其实很多用户都“愿意在Wasm当中做一些尝试”，只是发现跟Rust或C++等其他语言相比，Wasm真的让人望而生畏。</p><p>&nbsp;</p><p>虽然编程语言的实质就是帮助人们触及那些无比复杂的逻辑和事物。但有趣的是，Scott Logic调查给出的数据，其实跟Spencer的观点相互矛盾：</p><p>&nbsp;</p><p></p><blockquote>在将Rust与Wasm结合使用的开发者当中，有24%的受访者表示未来想要试试Grain。而在其余的调查参与者当中，只有7%的受访者表示有意尝试Grain。</blockquote><p></p><p>&nbsp;</p><p>看起来，虽然Grain是专门为了降低Wasm门槛而生，但有能力解决复杂工程问题的人们也完全不抗拒这种更简单的方法工具。</p><p>&nbsp;</p><p>Grain项目的主页上写道：很多语言都有着绝佳的设计思路，但最终却因为过于深奥难学而致人放弃，无法建立起庞大的技术社区。Grain希望为这些思路带来新的活力，通过易于使用、理解的方式加以呈现。</p><p>&nbsp;</p><p>这么看来，Grain 存在本身也许正是Wasm生态系统的最大短板——这证明Wasm没能用简单易行的方法，帮助开发者们了解如何用它解决问题。</p><p>&nbsp;</p><p>互联网上关于这个问题的讨论很多。</p><p>&nbsp;</p><p>在Quora上，IT支持软件厂商Licorice的CTO Julian Jensen就回答了Wasm是否难以上手的问题。</p><p></p><blockquote>“这个主题下的几乎每篇文章，都涉及如何在浏览器中加载和执行某些非常简单的功能。”“这类回答着实没有营养。它们无法反映大家在现实开发中遇到的问题，也没能触及严肃项目中可能遇到的任何痛点。”</blockquote><p></p><p>&nbsp;</p><p>Jensen的看法可能有些偏激，但他的基本判断是对的：虽然很多人都对Wasm抱有兴趣，但Wasm的生态系统始终没能提供一种简便易行的学习方式。</p><p>&nbsp;</p><p>更重要的是，这也凸显出Wasm面临的一大核心挑战：如何在帮助广大开发者降低理解门槛的同时，确保Wasm自身的很多特性不致因过度简化而失去意义？</p><p>&nbsp;</p><p></p><h2>WebAssembly组件模型</h2><p></p><p>&nbsp;</p><p>于是问题又回到了标准化上。没有标准化，我们就永远无法把大肆宣扬的各种技术期望变成现实。目前，最有前途的方案就是WebAssembly组件模型。</p><p>&nbsp;</p><p>根据Spencer的说法，就是因为负责这项工作的小组始终达不成共识，才“真正阻止了……Wasm的全面崛起。”McMullen也回应了这种说法，表示组件模型对于保障“标准交互模型”至关重要，甚至直接决定着Wasm能得到多少支持。</p><p>&nbsp;</p><p>组件模型的意义在于简化Wasm在浏览器以外的使用方式。通过为不同事物间的协同运行编写出规则和规范，组件模型应该能够消除Wasm实际应用中的不少认知负担（和额外代码）。</p><p>&nbsp;</p><p>“组件模型的关键，是让代码得以跨语言和生态系统实现安全高效共享与连接。除此之外，组件模型还有望帮助Wasm建立起睽违已久的代码公开接口。只有通过更高级的方式定义这些接口，我们才能就跨语言和平台的工作模式和标准达成一致。”McMullen表示。</p><p>&nbsp;</p><p>尽管组件模型对整个Wasm项目都具有重要意义，但W3C WebAssembly社区小组仍在讨论其中的具体细节，而且整个过程可能还需要一些时间。</p><p>&nbsp;</p><p>Spencer注意到，尽管大家的出发点都是好的，但由于民主化程度过高，人们其实是在相互内耗、把大量时间浪费在了对于小细节的争论上。</p><p>&nbsp;</p><p>那么，距离最终定稿还有多久？Spencer表示，他觉得具体实施可能要等到2023年春季去了。McMullen则强调，目前的延误其实有其道理：</p><p>&nbsp;</p><p></p><blockquote>“大多数工业标准都不及Wasm及其配套标准那么严格。这里需要极其精确的措辞，并最终以数学形式编写，这样才能对其正确性做出强有力的证明。”&nbsp;“特别是组件模型，它要做的是定义一项标准，借此跨越多种语言、异步模型、线程模型和行业，同时保持极高的运行效率和安全水平。”</blockquote><p></p><p>&nbsp;</p><p>尽管进展缓慢，但Spencer和McMullen对这项工作的重要意义都给予了充分肯定。Spencer坦言，Wasm的命运由工具链决定，毕竟开发者最关心的就是一种语言有没有完备的工具链。</p><p>&nbsp;</p><p></p><h2>Wasm会落入专有陷阱吗？</h2><p></p><p>脱离浏览器之后的Wasm，其未来命运似乎就取决于组件模型能否一战成功。但在此之后，Wasm还须着眼于更广泛的软件市场。</p><p>&nbsp;</p><p>Wingo预计，届时会有风险投资入驻这个领域，其中一些可能愿意遵循标准，但也有一些可能想让Wasm走向专有锁定。</p><p>&nbsp;</p><p>也许Shopify和Fastly等公司的当前贡献，就是在为后续的专有演变做铺垫。唯一的问题就是，供应商们能不能把Wasm轻松打包成边缘计算解决方案。只要Wasm项目的开发门槛不高，就会有更多工程师熟悉这项技术，最终影响供应商对于Wasm类方案的设计思路。</p><p>&nbsp;</p><p>而且Bytecode联盟也未必就有垄断Wasm的想法。McMullen更愿意将联盟视为Wasm的“元生态系统”。“我们绝不会在Wasm之内搞一言堂。我们所需要的不只是一种语言，更是多样性的平台和行业。”</p><p>&nbsp;</p><p></p><h2>结束语</h2><p></p><p>&nbsp;</p><p>无论风险投资方们怎么谋划、无论项目各种fork背后的核心开发团队选择哪条路线，Wasm本身永远是一项重要且极具价值的技术，完全有能力在正确的场景下改变游戏规则。</p><p>&nbsp;</p><p>所以，最大的难题其实就是，怎么按捺住激动的心、颤抖的手，忍着别把Wasm的影响力和价值抽象化成特定某一种软件工程工具。</p><p>&nbsp;</p><p>Spencer强调，归根结底，Wasm只是一种编译器目标、一种实现细节。如果Wasm能在未来几年内把自己的问题解决好，那它就会从流行词转化为润物细无声的开发方式。</p><p>&nbsp;</p><p>这样的未来看似简单，也是Wasm最合理的发展目标。但纵观整个发展历程，要让这个目标真正落地，还需要解决大量争论、探索、实验和共识。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p>&nbsp;</p><p><a href=\"https://thenewstack.io/whats-stopping-webassembly-from-widespread-adoption/\">https://thenewstack.io/whats-stopping-webassembly-from-widespread-adoption/</a>\"</p><p>&nbsp;</p><p>https://devclass.com/2022/09/29/massive-web-tech-survey-shows-how-bad-habits-continue-and-webassembly-may-be-over-hyped/?td=rt-3a</p><p>&nbsp;</p>",
    "publish_time": "2022-10-12 17:48:12",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Rust 编码风格团队宣布完成重组",
    "url": "https://www.infoq.cn/article/1g3Yeu0kX7UXhV3R9E0P",
    "summary": "<p></p><blockquote><a href=\"https://www.infoq.cn/article/ejcr2ef2iP7O4PqwgmNH\">Rust</a>\" 编程语言变得如此流行，以至于其背后的人正在创建一个致力于定义默认 Rust 编码风格的团队。&nbsp;</blockquote><p></p><p>&nbsp;</p><p>当编程语言足够流行之后，就逐渐会有一些编码风格指南发布出来，比如<a href=\"https://google.github.io/styleguide/cppguide.html\">谷歌曾发布 C++ 指南</a>\"&nbsp;，Python 之父 Guido van Rossum 也发布过Python代码风格指南。&nbsp;</p><p>&nbsp;</p><p>2015年，<a href=\"https://www.infoq.cn/article/o2QRFPElEpOgvLPe5qzI\">Rust </a>\"发布1.0版本的时候，在GitHub上发布过一个带有风格指南的rustfmt 工具。该工具会自动格式化 Rust 代码，旨在减少新 Rust 开发者面临的陡峭的学习曲线。该指南指示了开发人员 \"使用 spaces，而不是 tabs\"，并表明 \"每个缩进必须是 4 个 spaces\" 等。</p><p>&nbsp;</p><p>正如<a href=\"https://blog.rust-lang.org/inside-rust/2022/09/29/announcing-the-rust-style-team.html\">Josh Triplett 在最近的 Rust 博客文章中解释的那样</a>\"：“标准化的风格指南能帮助 Rust 开发者在许多不同的项目中感到舒适和自在，而来自 rustfmt 的工具支持使其易于维护和融入持续集成”。</p><p>&nbsp;</p><p>不过，负责在2016 年至 2018 年间编写风格指南的团队已经“按计划”解散了。但随着 Rust 语言的发展，需要经常对风格指南进行改进，例如支持新的语言结构，包括较小的语言更改，以及备受期待的新功能，例如 let-chaining（RFC 2497）和 let-else（RFC 3137）。近年来，相关的一些工作逐渐落到了 rustfmt 团队肩上，但该团队似乎更愿意执行由另一个团队做出的 style 决定，而不是自己做出的。</p><p>&nbsp;</p><p>因此， <a href=\"https://rust-lang.github.io/rfcs/3309-style-team.html\">RFC 3309</a>\"提出了重新组建Rust style 团队，新团队的目标是：</p><p>确定新 Rust 结构的样式；发展现有的 Rust 风格；定义机制以发展 Rust 风格指南，同时考虑向后兼容性。</p><p>&nbsp;</p><p>该团队由 Triplett、Caleb Cartwright、Michal Goulet 和 Jane Lusby 作为初始成员，他们将继续定义和实施机制以发展默认的 Rust 风格，平稳引入风格改进，“我们不打算做出任何惊天动地的风格改变”，那么Rust 的外观和感觉将基本保持不变。</p><p>&nbsp;</p><p>更多阅读：</p><p><a href=\"https://blog.rust-lang.org/inside-rust/2022/09/29/announcing-the-rust-style-team.html\">https://blog.rust-lang.org/inside-rust/2022/09/29/announcing-the-rust-style-team.html</a>\"</p>",
    "publish_time": "2022-10-12 18:09:43",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]