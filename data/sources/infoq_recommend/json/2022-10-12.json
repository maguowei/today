[
  {
    "title": "使用Strimzi将Kafka和Debezium迁移到Kubernetes",
    "url": "https://www.infoq.cn/article/ElNtSM5ISobpMB8fMC0j",
    "summary": "<p>在本系列文章的<a href=\"https://www.infoq.cn/article/cFpvXRLmZzJBGbzAeFu5\">第1部分</a>\"和<a href=\"https://www.infoq.cn/article/WfA0p1XoZCJ6INdyJLyv\">第2部分</a>\"中，我们学习了<a href=\"https://kafka.apache.org/\">Apache Kafka</a>\"、Apache Kafka Streams和<a href=\"https://quarkus.io/\">Quarkus</a>\"之间的集成。我们开发了一个简单的应用程序，向Kafka主题生成事件，并使用<a href=\"https://kafka.apache.org/documentation/streams/\">Kafka Streams</a>\"实时消费和处理它们。</p><p></p><p>在那个例子中，我们模拟了一家电影流媒体公司。我们将电影信息保存在一个Kafka主题中，并在另一个Kafka主题中保存用户停止观看电影时的事件，并捕获影片播放的时间。我们实时对这些事件进行后期处理，计算电影播放超过10分钟的次数。</p><p></p><p>下图是这个应用程序的架构。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/strimzi-the-gitops-way/en/resources/11-1664224713829.jpeg\" /></p><p>然后，在<a href=\"https://www.infoq.cn/article/V4kqPgrQlqqPgWQuMmDP\">第3部分</a>\"中，我们介绍了发件箱模式和Debezium，用于避免在不同系统需要同步相同数据时发生的双写问题。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/strimzi-the-gitops-way/en/resources/12-1664224713829.jpeg\" /></p><p>在前面的三篇文章中，我们已经从开发人员的角度学习了所有这些技术，并最终在开发人员的本地机器上（以开发模式）部署应用程序。</p><p></p><p>在本文中，我们将探讨如何将所有东西部署到生产环境，更具体地说，部署到Kubernetes中。我们将学习：</p><p></p><p>在Kubernetes中安装和管理Apache Kafka集群。容器化Quarkus应用程序。配置一个带有生产参数的Quarkus应用程序。将Debezium Embedded迁移成Debezium Server。</p><p></p><h2>Kubernetes</h2><p></p><p></p><p>Kubernetes是一个开源的容器编配器，是部署微服务的事实上的平台。这些服务既可以在裸金属环境中运行，也可以在云环境中运行。</p><p></p><p>本文使用<a href=\"https://minikube.sigs.k8s.io/docs/\">minikube</a>\"作为Kubernetes集群，但同样的步骤应该适用于任何其他实现。</p><p></p><h4>启动集群</h4><p></p><p>在终端窗口中执行以下命令，在配备了8GB内存和2个vCPU的VirtualBox机器上启动集群。</p><p></p><p><code lang=\"plain\">minikube start -p strimzi --kubernetes-version='v1.22.12' --vm-driver='virtualbox' --memory=8096\n\n  [strimzi] minikube v1.24.0 on Darwin 12.5\n  minikube 1.26.1 is available! Download it: https://github.com/kubernetes/minikube/releases/tag/v1.26.1\n  To disable this notice, run: 'minikube config set WantUpdateNotification false'\n\n✨  Using the virtualbox driver based on user configuration\n  Starting control plane node strimzi in cluster strimzi\n  Creating virtualbox VM (CPUs=2, Memory=8096MB, Disk=20000MB) ...\n    &gt; kubelet.sha256: 64 B / 64 B [--------------------------] 100.00% ? p/s 0s\n    &gt; kubeadm.sha256: 64 B / 64 B [--------------------------] 100.00% ? p/s 0s\n    &gt; kubectl.sha256: 64 B / 64 B [--------------------------] 100.00% ? p/s 0s\n    &gt; kubeadm: 43.74 MiB / 43.74 MiB [-------------] 100.00% 13.98 MiB p/s 3.3s\n    &gt; kubectl: 44.77 MiB / 44.77 MiB [-------------] 100.00% 11.11 MiB p/s 4.2s\n    &gt; kubelet: 115.30 MiB / 115.30 MiB [-----------] 100.00% 20.16 MiB p/s 5.9s\n\n    ▪ Generating certificates and keys ...\n    ▪ Booting up control plane ...\n    ▪ Configuring RBAC rules ...\n    ▪ Using image gcr.io/k8s-minikube/storage-provisioner:v5\n  Verifying Kubernetes components...\n  Enabled addons: storage-provisioner, default-storageclass\n\n❗  /usr/local/bin/kubectl is version 1.24.0, which may have incompatibilites with Kubernetes 1.22.12.\n    ▪ Want kubectl v1.22.12? Try 'minikube kubectl -- get pods -A'\n  Done! kubectl is now configured to use \"strimzi\" cluster and \"default\" namespace by default\n</code></p><p></p><p>在终端窗口执行下面的命令检查Kubernetes集群是否正常运行。</p><p></p><p><code lang=\"plain\">kubectl get nodes\n\nNAME      STATUS   ROLES                  AGE    VERSION\nstrimzi   Ready    control-plane,master   3m4s   v1.22.12\n\nkubectl get pods\nNo resources found in default namespace.\n</code></p><p></p><h2>Apache Kafka</h2><p></p><p></p><p>在之前的文章中，我们通过Quarkus的开发模式来启动运行应用程序所需的外部依赖项（Kafka集群和MySQL数据库）。从开发的角度来看，开发模式非常棒，但在部署到生产环境时，你会发现这些东西管理起来更加复杂。第一个障碍可能是在Kubernetes中安装和配置Kafka集群。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/strimzi-the-gitops-way/en/resources/13-1664224713829.jpeg\" /></p><p>你可能想知道以下这些问题的答案：</p><p></p><p>Kafka组件（Kafka、Zookeeper等）需要使用哪个容器镜像?如何在Kubernetes中轻松部署所有这些组件？如何在Kubernetes中创建用户、主题或HA？安全性如何？你可以尝试手动完成所有这些事情，例如编写很长的YAML文件和使用Kafka CI工具配置Kafka组件。然而，还有另一种Kubernetes原生的、完全自动化和可复制的（非常适合CI/CD）方法，就是使用Strimzi。</p><p></p><h4>Strimzi</h4><p></p><p><a href=\"https://strimzi.io/\">Strimzi</a>\"是一个<a href=\"https://www.redhat.com/en/topics/containers/what-is-a-kubernetes-operator\">Kubernetes Operator</a>\"，通过控制器来创建、配置和保护Kafka集群，就像其他Kubernetes资源（如Pod、Deployment、ConfigMap等）一样。</p><p></p><p>Strimzi项目包含三个Operator——一个用于管理Kafka集群，一个用于管理主题，一个用于用户管理。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/strimzi-the-gitops-way/en/resources/14-1664224713829.jpeg\" /></p><p>在Kubernetes集群中安装了Strimzi Operator之后，你只需要使用下面的YAML文件就可以启动并运行一个Kafka集群，其中包含了一个Kafka副本和三个使用临时存储（没有挂载持久卷）的ZooKeeper副本。</p><p></p><p><code lang=\"plain\">apiVersion: kafka.strimzi.io/v1beta2\nkind: Kafka\nmetadata:\n name: my-cluster\nspec:\n kafka:\n   version: 3.2.0\n   replicas: 1\n   listeners:\n     - name: plain\n       port: 9092\n       type: internal\n       tls: false\n     - name: tls\n       port: 9093\n       type: internal\n       tls: true\n   config:\n     offsets.topic.replication.factor: 1\n     transaction.state.log.replication.factor: 1\n     transaction.state.log.min.isr: 1\n     default.replication.factor: 1\n     min.insync.replicas: 1\n     inter.broker.protocol.version: \"3.2\"\n   storage:\n     type: ephemeral\n zookeeper:\n   replicas: 3\n   storage:\n     type: ephemeral\n entityOperator:\n   topicOperator: {}\n   userOperator: {}\n</code></p><p></p><p>接下来，我们将在已经启动的集群中安装Strimzi。</p><p></p><h4>安装Strimzi</h4><p></p><p>首先是创建一个命名空间来安装Strimzi Operator。在本例中，我们使用了命名空间kafka。在终端窗口中执行如下命令：</p><p></p><p><code lang=\"plain\">kubectl create namespace kafka\nnamespace/kafka created\n</code></p><p></p><p>接下来，我们应用Strimzi安装文件，其中包括用于声明式管理Kafka集群、Kafka主题和用户的CRD（CustomerResourceDefinition）。</p><p></p><p><code lang=\"plain\">kubectl create -f 'https://strimzi.io/install/latest?namespace=kafka' -n kafka\n</code></p><p></p><p>运行下面的命令验证Operator是否安装正确。</p><p></p><p><code lang=\"plain\">kubectl get pods -n kafka\n\nNAME                                        READY   STATUS    RESTARTS   AGE\nstrimzi-cluster-operator-597d67c7d6-ms987   1/1     Running   0          4m27s\n</code></p><p></p><p>现在，我们开始创建带有movies主题的Kafka集群。我们将在这个主题中保存所有电影的信息，稍后Kafka Streams将消费这个主题，正如我们在本系列文章的<a href=\"https://www.infoq.cn/article/WfA0p1XoZCJ6INdyJLyv\">第2部分</a>\"中所看到的那样。</p><p></p><h4>创建Kafka集群</h4><p></p><p>创建一个新的文件（即kafka.yaml）来安装一个带有一个副本的<a href=\"https://strimzi.io/docs/operators/latest/configuring.html#assembly-config-kafka-str\">Kafka集群</a>\"，不启用TLS，作为内部<a href=\"https://kubernetes.io/docs/concepts/services-networking/service/\">Kubernetes服务</a>\"。</p><p></p><p><code lang=\"plain\">apiVersion: kafka.strimzi.io/v1beta2\nkind: Kafka\nmetadata:\n name: my-cluster\nspec:\n kafka:\n   version: 3.2.0\n   replicas: 1\n   listeners:\n     - name: plain\n       port: 9092\n       type: internal\n       tls: false\n   config:\n     offsets.topic.replication.factor: 1\n     transaction.state.log.replication.factor: 1\n     transaction.state.log.min.isr: 1\n     default.replication.factor: 1\n     min.insync.replicas: 1\n     inter.broker.protocol.version: \"3.2\"\n   storage:\n     type: ephemeral\n zookeeper:\n   replicas: 1\n   storage:\n     type: ephemeral\n entityOperator:\n   topicOperator: {}\n   userOperator: {}\n</code></p><p></p><p>然后在终端窗口中使用kubectl命令创建这个资源：</p><p></p><p><code lang=\"plain\">kubectl create -f kafka.yaml -n kafka\nkafka.kafka.strimzi.io/my-cluster created\n</code></p><p></p><p>此时，Strimzi开始在默认命名空间中安装Kafka集群。</p><p></p><p>现在，我们通过获取默认的名称空间Pod来检查集群的创建情况。</p><p></p><p><code lang=\"plain\">kubectl get pods -n kafka\n\nNAME                                          READY   STATUS    \nmy-cluster-entity-operator-755596449b-cw82g   3/3     Running   \nmy-cluster-kafka-0                            1/1     Running \nmy-cluster-zookeeper-0                        1/1     Running\n</code></p><p></p><p>Kafka集群已启动并运行。我们除了可以将Kafka作为Kubernetes资源安装之外，还可以查询和描述它。例如，在终端窗口中执行如下命令：</p><p></p><p><code lang=\"plain\">kubectl get kafka -n kafka\n\nNAME         DESIRED KAFKA REPLICAS   DESIRED ZK REPLICAS   READY   WARNINGS\nmy-cluster   1                        1                     True    True\n\n\n\nkubectl describe kafka my-cluster -n kafka\n\nName:         my-cluster\nNamespace:    default\nLabels:       \nAnnotations:  \nAPI Version:  kafka.strimzi.io/v1beta2\nKind:         Kafka\nMetadata:\n  Creation Timestamp:  2022-08-09T10:57:39Z\n…\n</code></p><p></p><p>当然，你也可以像删除其他Kubernetes资源一样删除它。此外，系统还创建了4个Kubernetes服务来访问Kafka集群：</p><p></p><p><code lang=\"plain\">kubectl get services -n kafka\n\nNAME                          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE\n               143m\nmy-cluster-kafka-bootstrap    ClusterIP   172.30.77.150           9091/TCP,9092/TCP            21m\nmy-cluster-kafka-brokers      ClusterIP   None                    9090/TCP,9091/TCP,9092/TCP   21m\nmy-cluster-zookeeper-client   ClusterIP   172.30.5.186            2181/TCP                     21m\nmy-cluster-zookeeper-nodes    ClusterIP   None                    2181/TCP,2888/TCP,3888/TCP   21m\n</code></p><p></p><p>应用程序用于访问集群的服务是my-cluster-kafka-bootstrap，它公开了Kafka的9092端口。</p><p></p><p>在进入到应用程序部分之前，我们需要使用另一个YAML文件来创建和配置movies主题。</p><p></p><h4>创建movies主题</h4><p></p><p>Strimzi有一个用于创建和管理主题的Operator。要创建一个新主题，我们需要创建一个<a href=\"https://strimzi.io/docs/operators/latest/configuring.html#using-the-topic-operator-str\">KafkaTopic</a>\"类型的Kubernetes资源文件，在strimzi.io/cluster中指定主题的名称和集群的名称（在我们的例子中是my-cluster）。我们使用下面的内容创建一个名为movies-topic.yaml的新文件。</p><p></p><p><code lang=\"plain\">apiVersion: kafka.strimzi.io/v1beta2\nkind: KafkaTopic\nmetadata:\n name: movies\n labels:\n   strimzi.io/cluster: my-cluster\nspec:\n partitions: 1\n replicas: 1\n config:\n   retention.ms: 7200000\n   segment.bytes: 1073741824\n</code></p><p></p><p>并应用这个文件：</p><p></p><p><code lang=\"plain\">kubectl apply -f movies-topic.yaml -n kafka\nkafkatopic.kafka.strimzi.io/movies create\n</code></p><p></p><p>和其他Kubernetes资源一样，我们也可以查询和描述它。</p><p></p><p><code lang=\"plain\">kubectl get kafkatopic -n kafka\n\nNAME                                                                                               CLUSTER      PARTITIONS   REPLICATION FACTOR   READY\nconsumer-offsets---84e7a678d08f4bd226872e5cdd4eb527fadc1c6a                                        my-cluster   50           1                    True\nmovies                                                                                             my-cluster   1            1                    True\nstrimzi-store-topic---effb8e3e057afce1ecf67c3f5d8e4e3ff177fc55                                     my-cluster   1            1                    True\nstrimzi-topic-operator-kstreams-topic-store-changelog---b75e702040b99be8a9263134de3507fc0cc4017b   my-cluster   1            1                    True\n</code></p><p></p><p>描述已创建的主题：</p><p></p><p><code lang=\"plain\">kubectl port-forward -n kafka service/my-cluster-kafka-bootstrap 9092:9092\n\nForwarding from 127.0.0.1:9092 -&gt; 9092\nForwarding from [::1]:9092 -&gt; 9092\n</code></p><p></p><p>我们来检查一下创建的主题是否有<a href=\"https://kubernetes.io/docs/tasks/access-application-cluster/port-forward-access-application-cluster/\">端口转发</a>\"。</p><p></p><p>在终端窗口执行如下命令：</p><p></p><p><code lang=\"plain\">kubectl port-forward -n kafka service/my-cluster-kafka-bootstrap 9092:9092\n\nForwarding from 127.0.0.1:9092 -&gt; 9092\nForwarding from [::1]:9092 -&gt; 9092\n</code></p><p></p><p>打开一个新的终端窗口，使用<a href=\"https://github.com/edenhill/kcat\">kcat</a>\"工具列出Kafka集群的元素。我们可以使用localhost作为主机名，就像在上一步中使用端口转发技巧一样。</p><p></p><p><code lang=\"plain\">kcat -b localhost:9092 -L\n\nMetadata for all topics (from broker -1: localhost:9092/bootstrap):\n 1 brokers:\n  broker 0 at my-cluster-kafka-0.my-cluster-kafka-brokers.default.svc:9092 (controller)\n 4 topics:\n  topic \"movies\" with 1 partitions:\n    partition 0, leader 0, replicas: 0, isrs: 0\n</code></p><p></p><p>最后，我们停止端口转发进程，对项目进行容器化，就像我们在本系列文章的<a href=\"https://www.infoq.cn/article/V4kqPgrQlqqPgWQuMmDP\">第3部分</a>\"中所做的那样，并进行一些相应的配置，以便连接到Kafka集群。</p><p></p><h2>生产者Debezium</h2><p></p><p></p><p>我们在系列文章的<a href=\"https://www.infoq.cn/article/V4kqPgrQlqqPgWQuMmDP\">第3部分</a>\"解决了双写问题，使用Debezium（具体来说是<a href=\"https://github.com/lordofthejars/movie-plays-kafka/blob/main/movie-plays-producer-debezium/src/main/java/org/acme/DebeziumListener.java\">Debezium Embedded</a>\"）修复了这个问题，具体方法是监听来自MySQL服务器的事务日志，并在每次插入新的电影播放信息时生成带有数据的Kafka事件。你可以在本地机器上运行这个示例，使用开发服务启动所需的服务（MySQL和Kafka），并自动配置应用程序来连接它们。</p><p></p><p>现在有点不一样了——服务必须运行在Kubernetes集群中，包括在前面步骤中创建的Kafka集群和MySQL数据库。要让它在Kubernetes中运行，需要做出三个改变。</p><p></p><p>使用新的Kafka和MySQL参数（主机名、端口、用户名和密码）来配置服务。将应用程序装入容器，并推送到容器注册表。创建Kubernetes资源文件，用于部署服务。</p><p></p><h2>配置服务</h2><p></p><p></p><p>首先要配置的是Kafka的主机名和端口，它们指向Strimzi创建的Kubernetes服务。打开src/main/resources/application.properties文件并添加下面的内容：</p><p></p><p><code lang=\"plain\">%prod.kafka.bootstrap.servers=my-cluster-kafka-bootstrap:9092\n</code></p><p></p><p>%prod前缀表示这个属性仅在应用程序以prod模式下运行时使用（而不是在dev或test模式下)。</p><p></p><p>其次时配置插入影片信息的数据库连接。在application.properties文件中添加下面的内容。</p><p></p><p><code lang=\"plain\">quarkus.hibernate-orm.database.generation=drop-and-create\n%prod.quarkus.datasource.username=alex\n%prod.quarkus.datasource.password=alex\n%prod.quarkus.datasource.jdbc.url=jdbc:mysql://mysql:3306/moviesdb\n</code></p><p></p><p>稍后，我们将使用这些参数部署一个MySQL实例。现在，我们假设配置参数是正确的。</p><p></p><h4>容器化</h4><p></p><p>Quarkus为创建容器提供了与<a href=\"https://github.com/GoogleContainerTools/jib\">Jib</a>\"项目的集成，让容器镜像的构建和推送简单得只需要执行一个Maven/Gradle任务。</p><p></p><p>打开pom.xml文件，在dependencies部分添加以下依赖项：</p><p></p><p><code lang=\"plain\">\n     io.quarkus\n     quarkus-container-image-jib\n\n</code></p><p></p><p>添加了<a href=\"https://quarkus.io/guides/container-image\">Jib依赖项</a>\"后，它将在打包时自动将应用程序装入容器。因为<a href=\"https://github.com/GoogleContainerTools/jib\">Jib</a>\"的一些默认配置选项可能不适用于所有情况，所以你可以在src/main/resources/application.properties中覆盖它们。对于本例，我们将覆盖生成的容器镜像的group和容器注册中心的主机。</p><p></p><p>打开application.properties文件，并添加下面的内容：</p><p></p><p><code lang=\"plain\"># Substitue the value with your account name\nquarkus.container-image.group=lordofthejars\n \n# Defaults to Docker.io, overriden to Quay.\nquarkus.container-image.registry=quay.io\n</code></p><p></p><p>你需要设置容器注册表的凭据，以便向注册表推送容器。你可以在执行构建之前运行docker的login命令。Maven将从那里读取凭据，或者你可以使用quarkus.container-image.username和quarkus.container-image.password属性。</p><p></p><p>在项目的根目录下运行下面的命令来构建应用程序，它将构建出一个容器并将其推到指定的容器注册表中。</p><p></p><p><code lang=\"plain\">./mvnw clean package -DskipTests -Dquarkus.container-image.push=true\n\n[INFO] Scanning for projects...\n[INFO]\n[INFO] ---------------&lt; org.acme:movie-plays-producer-debezium &gt;---------------\n[INFO] Building movie-plays-producer-debezium 1.0.0-SNAPSHOT\n[INFO] --------------------------------[ jar ]---------------------------------\n[INFO]\n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ movie-plays-producer-debezium ---\n[INFO] Deleting /Users/asotobu/git/quarkus-integrating-kafka/strimzi/movie-plays-producer-debezium/target\n…\n[INFO] [io.quarkus.container.image.jib.deployment.JibProcessor] Using base image with digest: sha256:1a2fddacdcda67494168749c7ab49243d06d8fbed34abab90566d81b94f5e1a5\n[INFO] [io.quarkus.container.image.jib.deployment.JibProcessor] Container entrypoint set to [java, -Djava.util.logging.manager=org.jboss.logmanager.LogManager, -jar, quarkus-run.jar]\n[INFO] [io.quarkus.container.image.jib.deployment.JibProcessor] Pushed container image quay.io/lordofthejars/movie-plays-producer-debezium:1.0.0-SNAPSHOT (sha256:73dfe42d53f8d7e3c268dbebc2e5f866596de33b8fcaf82c27bdd414d28bdb8a)\n</code></p><p></p><p>从最后一行日志可以看到，容器被创建，并使用application.properties中指定的账号推送到注册中心。</p><p></p><h4>Kubernetes</h4><p></p><p>在将容器推送到注册表之后，我们准备将服务部署到Kubernetes中。我们可以手动创建Kubernetes资源文件，但没有必要这么做，因为Quarkus为我们提供了一个<a href=\"https://quarkus.io/guides/deploying-to-kubernetes\">Kubernetes扩展</a>\"。</p><p></p><p>打开pom.xml文件，并在dependencies部分添加下面的依赖项。</p><p></p><p><code lang=\"plain\">\n     io.quarkus\n     quarkus-kubernetes\n\n</code></p><p></p><p>每次Maven打包应用程序时都会注册Kubernetes扩展，并生成将应用程序部署到Kubernetes集群的kubernetes.yml文件。你可以通过application.properties来修改生成文件的内容。例如，我们将Kubernetes Service设置为LoadBalancer而不是ClusterIP，并将命名空间设置为kafka。</p><p></p><p>打开application.properties文件并添加下面的内容。</p><p></p><p><code lang=\"plain\">quarkus.kubernetes.service-type=load-balancer\nquarkus.kubernetes.namespace=kafka\n</code></p><p></p><p>修改好以后运行Maven package生成部署文件。</p><p></p><p><code lang=\"plain\">./mvnw clean package -DskipTests\n\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n</code></p><p></p><p>检查生成的文件target/kubernetes/kubernetes.yml：</p><p></p><p><code lang=\"plain\">cat target/kubernetes/kubernetes.yml\n</code></p><p></p><p>输出的内容应该类似于下面这样：</p><p></p><p><code lang=\"plain\">---\napiVersion: v1\nkind: Service\nmetadata:\n …\n name: movie-plays-producer-debezium\nspec:\n ports:\n   - name: http\n     port: 80\n     targetPort: 8080\n selector:\n   app.kubernetes.io/name: movie-plays-producer-debezium\n   app.kubernetes.io/version: 1.0.0-SNAPSHOT\n # Type is LoadBalancer as set in the application.properties file \n type: LoadBalancer\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n …\n name: movie-plays-producer-debezium\nspec:\n replicas: 1\n selector:\n   matchLabels:\n     app.kubernetes.io/name: movie-plays-producer-debezium\n     app.kubernetes.io/version: 1.0.0-SNAPSHOT\n template:\n   metadata:\n     …\n   spec:\n     containers:\n       - env:\n           - name: KUBERNETES_NAMESPACE\n             valueFrom:\n               fieldRef:\n                 fieldPath: metadata.namespace\n         # The image is correctly set automatically\n         image: quay.io/lordofthejars/movie-plays-producer-debezium:1.0.0-SNAPSHOT\n         imagePullPolicy: Always\n         name: movie-plays-producer-debezium\n         ports:\n           - containerPort: 8080\n             name: http\n             protocol: TCP\n</code></p><p></p><p>在本例中，配置参数是硬编码在application.properties中的，但你可以将它们作为环境变量传递进去。要在Kubernetes Deployment对象中设置环境变量，比如覆盖Kafka的配置，可以添加下面的行：</p><p></p><p><code lang=\"plain\">quarkus.kubernetes.env.vars.kafka-bootstrap-servers=my-new-cluster:9092 \n</code></p><p></p><p>生成文件的env部分将包含这个新的环境变量：</p><p></p><p><code lang=\"plain\">containers:\n       - env:\n           - name: KAFKA_BOOTSTRAP_SERVERS\n             value: my-new-cluster:9092\n         image: quay.io/lordofthejars/movie-plays-producer-debezium:1.0.0-SNAPSHOT\n</code></p><p></p><h4>全部放到一起</h4><p></p><p>我们已经使用Strimzi在Kubernetes集群中部署了一个Kafka集群。我们将应用下面的文件（mysql-deployment.yaml）和application.properties中配置的参数部署MySQL实例。</p><p></p><p><code lang=\"plain\">apiVersion: v1\nkind: Service\nmetadata:\n name: mysql\n labels:\n   app: mysql\nspec:\n ports:\n   - port: 3306\n selector:\n   app: mysql\n clusterIP: None\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n name: mysql\n labels:\n   app: mysql\nspec:\n selector:\n   matchLabels:\n     app: mysql\n strategy:\n   type: Recreate\n template:\n   metadata:\n     labels:\n       app: mysql\n   spec:\n     containers:\n     - image: mysql:8.0.30\n       name: mysql\n       env:\n       - name: MYSQL_ROOT_PASSWORD\n         value: alex\n       - name: MYSQL_DATABASE\n         value: moviesdb\n       - name: MYSQL_USER\n         value: alex\n       - name: MYSQL_PASSWORD\n         value: alex\n       ports:\n       - containerPort: 3306\n         name: mysql\n</code></p><p></p><p>将MySQL实例部署到Kubernetes集群：</p><p></p><p><code lang=\"plain\">kubectl apply -f mysql-deployment.yaml -n kafka\n</code></p><p></p><p>最后要部署的是应用程序本身。我们有两个选择，第一个是直接应用资源：</p><p></p><p><code lang=\"plain\">kubectl apply -f target/kubernetes/kubernetes.yml -n kafka\n</code></p><p></p><p>第二个是将quarkus.kubernetes.deploy标志设置为true来打包应用程序。当这个标志设置为true时，Maven将：</p><p></p><p>创建应用程序JAR文件。构建容器镜像。将容器镜像推送到注册表中。自动应用kubernetes.yml资源文件到已连接的Kubernetes集群。为了验证所有的东西都能正确地运行，我们将发送一个插入新电影信息的请求，并验证在Kafka主题中插入的新事件。</p><p></p><p>在终端窗口中执行以下命令获取访问服务的IP和端口。</p><p></p><p>获取访问服务的IP：</p><p></p><p><code lang=\"plain\">minikube ip -p strimzi\n\n192.168.59.104\n</code></p><p></p><p>获取movie-plays-producer-debezium的公开端口，也就是第二个端口。</p><p></p><p><code lang=\"plain\">kubectl get services -n kafka\n\nmovie-plays-producer-debezium   LoadBalancer   10.100.117.203        80:30306/TCP                 67m\n</code></p><p></p><p>运行curl命令，插入一条新的电影信息记录。</p><p></p><p><code lang=\"plain\">curl -X 'POST' \\\n  'http://192.168.59.104:30306/movie' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"name\": \"Minions: The Rise of Gru\",\n  \"director\": \"Kyle Balda\",\n  \"genre\": \"Animation\"\n}'\n</code></p><p></p><p>检查Quarkus日志，查看数据库运行的SQL语句：</p><p></p><p><code lang=\"java\">kubectl get pods -n kafka\n\nNAME                                             READY   STATUS      RESTARTS   AGE\nmovie-plays-producer-debezium-56f644cb87-5cchk   1/1     Running     0          6m5s\nmy-cluster-entity-operator-755596449b-cw82g      3/3     Running     0          35h\nmy-cluster-kafka-0                               1/1     Running     0          35h\nmy-cluster-zookeeper-0                           1/1     Running     0          35h\n</code></p><p></p><p>打印movie-plays-producer-debezium的日志：</p><p></p><p><code lang=\"java\">kubectl logs movie-plays-producer-debezium-6b9b65bf4-9z524 -n kafka\n\n2022-08-11 07:44:25,658 INFO  [org.acm.MovieResource] (executor-thread-1) New Movie inserted Minions: The Rise of Gru\n:)\nHibernate:\n    select\n        next_val as id_val\n    from\n        hibernate_sequence for update\n\nHibernate:\n    update\n        hibernate_sequence\n    set\n        next_val= ?\n    where\n        next_val=?\nHibernate:\n    insert\n    into\n        Movie\n        (director, genre, name, id)\n    values\n        (?, ?, ?, ?)\nHibernate:\n    insert\n    into\n        OutboxEvent\n        (aggregatetype, aggregateid, type, timestamp, payload, tracingspancontext, id)\n    values\n        (?, ?, ?, ?, ?, ?, ?)\n\n# Debezium reacts to the change\n2022-08-11 07:44:25,867 INFO  [io.deb.con.com.BaseSourceTask] (executor-thread-0) 1 records sent during previous 00:20:44.297, last recorded offset: {transaction_id=null, ts_sec=1660203865, file=binlog.000002, pos=14795, row=1, server_id=1, event=4}\nMovie Created and Reacting\n</code></p><p></p><p>你还可以使用Kafka容器里的Kafka-console-consumer.sh脚本来检查Kafka中的内容。进入容器并运行下面的命令：</p><p></p><p><code lang=\"java\">kubectl exec -ti my-cluster-kafka-0 -n kafka /bin/bash\n\n./bin/kafka-console-consumer.sh --topic movies --from-beginning --bootstrap-server localhost:9092\n{\"id\":1,\"name\":\"Minions: The Rise of Gru\",\"director\":\"Kyle Balda\",\"genre\":\"Animation\"}\n</code></p><p></p><p>要返回本地终端窗口，请按Ctrl+C停止kafka-console-consumer进程，然后执行exit命令。</p><p></p><p>到目前为止，一切都很顺利。我们已经得到了与本系列文章第3部分中相同的应用程序，只是现在它运行在Kubernetes集群中。</p><p></p><p>到目前为止，我们使用的是Debezium Embedded，但其实我们可以使用Debezium Server。</p><p></p><h2>Debezium Server</h2><p></p><p></p><p><a href=\"https://debezium.io/documentation/reference/stable/operations/debezium-server.html\">Debezium Server</a>\"是一个可配置的、使用就绪的应用程序，它将事件从源数据库流到消息传递系统中，如Kafka。它可以被注册成一个<a href=\"https://kafka.apache.org/documentation/#connect\">Kafka Connect组件</a>\"，作为源连接器。</p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/strimzi-the-gitops-way/en/resources/15-1664224713829.jpeg\" /></p><p>虽然我们不能在所有的场景中都使用Debezium Server，但在我看来，使用这种方法有两个大的优点：</p><p></p><p>你可以获得Kafka连接器的所有好处（容错、可扩展、可重用等）。因为它是一个外部组件，所以不需要更改应用程序代码，也不需要Debezium Embedded相关的代码或依赖项。因此，任何应用程序都可以在不做出修改或重新部署的情况下开始使用Debezium。接下来，我们来看看如何从Debezium Embedded迁移到Debezium Server。</p><p></p><h4>移除Debezium Embedded</h4><p></p><p>首先要做的是删除Debezium Embedded相关的依赖项。</p><p></p><p>打开pom.xml文件，删除以下依赖项：</p><p></p><p><code lang=\"java\">\n     io.debezium\n     debezium-ddl-parser\n\n\n     io.debezium\n     debezium-embedded\n\n\n     io.debezium\n     debezium-connector-mysql\n\n</code></p><p></p><p>下一步是删除所有与Debezium Embedded配置和监听器相关的代码。删除这些类文件——DebeziumConfiguration.java、DebeziumListener.java和MySqlJdbcParser.java。</p><p></p><p>因为所有与Kafka的交互都是通过Kafka Connect组件进行的，不需要Kafka代码，所以最后一步是从pom.xml中移除以下依赖项：</p><p></p><p><code lang=\"go\">\n     io.quarkus\n     quarkus-smallrye-reactive-messaging-kafka\n\n</code></p><p></p><p>application.properties文件中的这一行不再需要：</p><p></p><p><code lang=\"java\">%prod.kafka.bootstrap.servers=my-cluster-kafka-bootstrap:9092\n</code></p><p></p><p>项目中已经没有了Kafka或Debezium Embedded依赖项。创建一个包含这些最新变更的容器镜像。</p><p></p><p>在终端窗口执行以下命令，删除之前的部署：</p><p></p><p><code lang=\"go\">kubectl delete deployment movie-plays-producer-debezium\nkubectl delete service movie-plays-producer-debezium\n</code></p><p></p><p>要保留带有Debezium Debezium的容器镜像，请将artifactId更改为movie-plays-producer-debezium-server。</p><p></p><p>然后将不带Debezium代码的新版本部署到Kubernetes集群中，如下所示：</p><p></p><p><code lang=\"plain\">./mvnw clean package -DskipTests -Dquarkus.kubernetes.deploy=true\n</code></p><p></p><p>运行以下命令验证新部署的服务：</p><p></p><p><code lang=\"java\">kubectl get pods -n kafkaa\n\nNAME                                                    READY   STATUS    RESTARTS   AGE\nmovie-plays-producer-debezium-server-59db564b74-vhdmf   1/1     Running   0          73m\n</code></p><p></p><h4>部署Debezium Kafka Connect</h4><p></p><p>首先，部署一个Kafka Connect组件与所需的MySQL连接器插件。你可以认为它跟我们在<a href=\"https://github.com/lordofthejars/movie-plays-kafka/blob/main/strimzi/movie-plays-producer-debezium/src/main/java/org/acme/DebeziumListener.java\">DebeziumListener</a>\"类中实现的逻辑差不多，只是被作为一个Kafka Connect元素，可以在项目中重用。我们必须为Kafka Connect和连接器插件创建一个容器镜像，因为Debezium没有为各种可能的Kafka与数据的组合提供“官方”镜像。对于本例，我们使用Kafka 3.2.0的MySQL连接器创建一个容器镜像。</p><p></p><p>本文中MySQL连接器的容器镜像可以在<a href=\"http://quay.io/lordofthejars/debezium-connector-mysql:1.9.4\">quay.io/lordofthejars/debezium-connector-mysql:1.9.4</a>\"找到，如果你对它的构建过程感到好奇，可以查看位于这个<a href=\"https://github.com/lordofthejars/movie-plays-kafka/blob/main/strimzi/Dockerfile\">GitHub</a>\"存储库中的Dockerfile文件。</p><p></p><p>为了部署Debezium Kafka Connect，我们将使用Strimzi提供的<a href=\"https://strimzi.io/docs/operators/latest/deploying.html#deploying-kafka-connect-str\">KafkaConnect</a>\"，因为它简化了整个过程。在这个Kubernetes资源文件中，我们指定了Kafka版本、Kafka集群的位置（my-cluster-kafka-bootstrap:9092）、容器镜像（quay.io/lordofthejars/debezin-connector-mysql:1.9.4），以及一些特定的配置参数。</p><p></p><p>创建一个名为debezium-kafka-connect.yaml的文件，内容如下：</p><p></p><p><code lang=\"java\">apiVersion: kafka.strimzi.io/v1beta2\nkind: KafkaConnect\nmetadata:\n name: debezium-connect-cluster\n annotations:\n   strimzi.io/use-connector-resources: \"true\"\nspec:\n version: 3.2.0\n image: quay.io/lordofthejars/debezium-connector-mysql:1.9.4\n replicas: 1\n bootstrapServers: my-cluster-kafka-bootstrap:9092\n config:\n   group.id: connect-cluster\n   key.converter: org.apache.kafka.connect.json.JsonConverter\n   value.converter: org.apache.kafka.connect.json.JsonConverter\n   key.converter.schemas.enable: false\n   value.converter.schemas.enable: false\n   offset.storage.topic: connect-offsets\n   offset.storage.replication.factor: 1\n   config.storage.topic: connect-configs\n   config.storage.replication.factor: 1\n   status.storage.topic: connect-status\n   status.storage.replication.factor: 1\n</code></p><p></p><p>然后在终端窗口中应用这个资源：</p><p></p><p><code lang=\"java\">kubectl apply -f debezium-kafka-connect.yaml -n kafka\n</code></p><p></p><p>并通过运行以下命令验证它是否被正确部署：</p><p></p><p><code lang=\"java\">kubectl get pods -n kafka\n\ndebezium-connect-cluster-connect-546c8695c-lszn7        1/1     Running   0          91m\n</code></p><p></p><p>请记住，这个过程可能需要几分钟的准备时间。</p><p></p><p>Kafka Connect组件现在连接到了Kafka集群，最后一步是通过配置让它监听MySQL实例的数据变更。</p><p></p><p>为此，我们将使用Strimzi提供的KafkaConnector。这有点类似于我们在DebeziumConfiguration类中所做的那样，提供database.hostname或table.include.list之类的参数。此外，我们还要将strimzi.io/cluster的值设置为上一个YAML文件中指定的KafkaConnect名称（debezum-connect-cluster）。</p><p></p><p>创建一个名为debezium-kafka-connector.yaml的文件，内容如下：</p><p></p><p><code lang=\"java\">apiVersion: kafka.strimzi.io/v1beta2\nkind: KafkaConnector\nmetadata:\n name: debezium-connector-mysql\n labels:\n   strimzi.io/cluster: debezium-connect-cluster\nspec:\n class: io.debezium.connector.mysql.MySqlConnector\n tasksMax: 1\n config:\n   tasks.max: 1\n   database.hostname: mysql\n   database.port: 3306\n   database.user: root\n   database.password: alex\n   database.server.id: 184054\n   database.server.name: mysql\n   database.include.list: moviesdb\n   database.allowPublicKeyRetrieval: true\n   table.include.list: moviesdb.OutboxEvent\n   database.history.kafka.bootstrap.servers: my-cluster-kafka-bootstrap:9092\n   database.history.kafka.topic: schema-changes.movies\n</code></p><p></p><p>通过应用资源来配置Debezium Connector：</p><p></p><p><code lang=\"plain\">kubectl apply -f debezium-kafka-connector.yaml -n kafka\n</code></p><p></p><p>为了验证一切工作正常，我们添加一条新的电影数据记录，并验证将新记录插入数据库时Kafka主题中会产生一个新事件。</p><p></p><p>获取新服务的端口，IP仍然是相同的：</p><p></p><p><code lang=\"java\">kubectl get services -n kafka\n\nmovie-plays-producer-debezium-server   LoadBalancer   10.100.117.203        80:30307/TCP                 67m\n\ncurl -X 'POST' \\\n  'http://192.168.59.104:30307/movie' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"name\": \"Minions: The Rise of Gru\",\n  \"director\": \"Kyle Balda\",\n  \"genre\": \"Animation\"\n}'\n</code></p><p></p><p>使用kafka-console-consumer.sh脚本验证插入的数据：</p><p></p><p><code lang=\"java\">kubectl exec -ti my-cluster-kafka-0 -n kafka /bin/bash\n</code></p><p></p><p>然后在容器中运行脚本。注意，Debezium连接器将事件发送到一个Kafka主题，名称是这样的..，在这个示例中是mysql.moviesdb.OutboxEvent。<p></p><p></p><p><code lang=\"java\">./bin/kafka-console-consumer.sh --topic mysql.moviesdb.OutboxEvent --from-beginning --bootstrap-server localhost:9092\n\n{\"before\":null,\"after\":{\"id\":\"Yxk0o5WwTvi0+nwBr2Y36wAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\",\"aggregatetype\":\"Movie\",\"aggregateid\":\"5\",\"type\":\"MovieCreated\",\"timestamp\":1660253420864918,\"payload\":\"{\\\"id\\\":5,\\\"name\\\":\\\"Minions: The Rise of Gru\\\",\\\"director\\\":\\\"Kyle Balda\\\",\\\"genre\\\":\\\"Animation\\\"}\",\"tracingspancontext\":null},\"source\":{\"version\":\"1.9.4.Final\",\"connector\":\"mysql\",\"name\":\"mysql\",\"ts_ms\":1660253420000,\"snapshot\":\"false\",\"db\":\"moviesdb\",\"sequence\":null,\"table\":\"OutboxEvent\",\"server_id\":1,\"gtid\":null,\"file\":\"binlog.000002\",\"pos\":8788,\"row\":0,\"thread\":41,\"query\":null},\"op\":\"c\",\"ts_ms\":1660253420878,\"transaction\":null}\n</code></p><p></p><p>before字段是空的，因为是插入操作，所以没有前值，但是在after字段中有电影信息数据。</p><p></p><h2>结论</h2><p></p><p></p><p>我们已经将应用程序从本地迁移到了Kubernetes集群中。</p><p></p><p>Strimzi为我们提供了在Kubernetes中部署和管理Apache Kafka集群的一个关键元素。我们可以使用Kubernetes资源文件安装和管理集群，采用GitOps的方式来管理Kafka。</p><p></p><p>Debezium Embedded适用于一些场景，比如在检测数据变更时使用的临时逻辑。不过，在其他项目中（特别是在遗留项目或需要高可伸缩性和容错性的项目），Debezium Server可能更合适。</p><p></p><p>有了Strimzi、Jib和Kubernetes Quarkus扩展，从本地转移到Kubernetes集群应该并不难。</p><p></p><p>本文的源代码可以在<a href=\"https://github.com/lordofthejars/movie-plays-kafka/tree/main/strimzi\">GitHub</a>\"上找到。</p><p></p><h2>作者简介</h2><p></p><p></p><p>Alex Soto是Red Hat的开发者体验总监。他对Java和软件自动化领域充满热情，并相信开源软件模型。Soto是《Testing Java Microservices》（Manning出版）和《Quarkus Cookbook》（O'Reilly出版）的合著者，也是多个开源项目的贡献者。自2017年以来，他获得Java Champion的称号，也是Salle URL大学的国际演讲师和教师。你可以在Twitter上关注他（Alex Soto），继续关注Kubernetes和Java世界的动态。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/strimzi-the-gitops-way/\">https://www.infoq.com/articles/strimzi-the-gitops-way/</a>\"</p><p></p><p>相关阅读：</p><p>本系列第一部分：<a href=\"https://www.infoq.cn/article/cFpvXRLmZzJBGbzAeFu5\">使用 Apache Kafka 实现 Quarkus 的反应式消息</a>\"</p><p>本系列第二部分：<a href=\"https://www.infoq.cn/article/WfA0p1XoZCJ6INdyJLyv\">Kafka Streams 与 Quarkus：实时处理事件</a>\"</p><p>本系列第三部分：<a href=\"https://www.infoq.cn/article/V4kqPgrQlqqPgWQuMmDP\">Debezium 和 Quarkus：通过 CDC 模式来避免双重写入</a>\"</p><table></table></p>",
    "publish_time": "2022-10-12 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "现代化工具链在大规模 C++ 项目中的技术实践",
    "url": "https://www.infoq.cn/article/KsctTt5cIpCCl5T2SmtJ",
    "summary": "<p></p><blockquote><a href=\"https://www.infoq.cn/article/Y9KJX5zaEXov90wK68JP\">C++ 语言</a>\"与<a href=\"https://xie.infoq.cn/article/f5c1ccfd528e8a169edbc3711\">编译器</a>\"一直都在持续演进，出现了许多令人振奋的新特性，同时还有许多新特性在孵化阶。除此之外，还有许多小更改以提高运行效率与编程效率。本文整理自全球 C++ 及系统软件技术大会上的精彩分享，作者将带我们了解&nbsp;C++ 项目的实践工作等具体内容。</blockquote><p></p><p></p><h2>介绍</h2><p></p><p></p><p>C++ 是一门有着长久历史并依然持续活跃的语言。C++ 最新标准已经到了 <a href=\"https://xie.infoq.cn/article/bb41da0e3eed0c7f42571c3d8\">C++23</a>\"。Clang/LLVM、GCC 与 MSVC 等三大编译器都保持着非常频繁的更新。除此之外的各个相关生态也都保持着持续更新与跟进。但遗憾的是，目前看到积极更近 C++新标准与 C++新工具链的都主要以国外项目为主。国内虽然对 C++ 新标准也非常关注，但大多以爱好者个人为主，缺乏真实项目的跟进与实践。</p><p></p><p>本文以现代化工具链作为线索，介绍我们实际工作中的大型 C++ 项目中现代化工具链的实践以及结果。</p><p>对于 C++ 项目，特别是大型的 C++项目而言，常常会有以下几个特点（或痛点）：</p><p></p><p>项目高度自治 – 自主决定编译器版本、语言标准高度业务导向 – 少关注、不关注编译器和语言标准先发劣势 – 丧失应用新技术、新特性的能力沉疴难起 – 编译器版本、语言标准、库依赖被锁死</p><p></p><p>许多 C++ 项目都是高度自治且业务导向的，这导致一个公司内部的 C++ 项目的编译器版本和语言标准五花八门，想统一非常困难。同时由于日常开发主要更关心业务，时间一长背上了技术债，再想用新标准与新工具链的成本就更高了。一来二去，编译器、语言标准与库依赖就被锁死了。</p><p></p><p>同时对于业务来说，切换编译器也会有很多问题与挑战：</p><p></p><p>修复更严格编译器检查的问题修复不同编译器行为差异的问题修复语言标准、编译器行为改变的问题 – 完善测试二进制依赖、ABI兼容问题 – 全源码编译/服务化性能压测、调优</p><p></p><p>这里的许多问题哪怕对于有许多年经验的 C++工程师而言可能都算是难题，因为这些问题其实本质上是比语言层更低一层的问题，属于工具链级别的问题。所以大家觉得棘手是很正常的，这个时候就需要专业的编译器团队了。</p><p></p><p>在我们的工作中，少数编译器造成的程序行为变化问题需要完善的测试集，极少数编译器切换造成的问题在产线上暴露出来 – 本质是业务/库代码的 bug，绝大多数问题在构建、运行、压测阶段暴露并得到修复。</p><p></p><p>这里我们简单介绍下我们在实际工作中遇到的案例：</p><p></p><p>业务1（规模5M）</p><p>业务本身10+仓库；三方依赖50+，其中大部分源代码依赖，部分二进制依赖。二进制依赖、ABI兼容问题 – 0.5人月；编译器切换、CI、CD – 1.5人月；性能分析调优 – 1人月。</p><p></p><p>业务2（规模7M）</p><p>二方/三方依赖 30+，二进制依赖。编译器切换改造 – 2 人月；性能压测调优 – 1 人月。</p><p></p><p>业务3（规模3M）</p><p>二方/三方依赖 100+，多为二进制依赖。二进制依赖、ABI 兼容问题 – 预估 2 人年。</p><p></p><p>在切换工具链之后，用户们能得到什么呢？</p><p>更短的编译时间更好的运行时性能更好的编译、静态、运行时检查更多优化技术 – ThinLTO、AutoFDO、Bolt 等更新的语言特性支持 – C++20 协程、C++20 Module 等持续性更新升级 – 良性循环</p><p></p><p>其中更短的编译时间本身就是 clang 的一个特性，从 gcc 切换到 clang 就会得到很不错的编译加速。同时运行时性能也一直是编译器的目标。而各种各样的静态与运行时检查也是编译器/工具链开发的一个长期主线。另外更新的工具链也会带来更多的优化技术与语言特性支持，这里我们后面会重点介绍。最后是我们可以得到一个长期持续性更新升级的良性循环，这一点也是非常重要和有价值的。</p><p></p><h2>优化技术简介</h2><p></p><p></p><h3>ThinLTO</h3><p></p><p></p><p>传统的编译流程如下图所示</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/49/49a0a0844ea30120bc669b0d58eb8ab2.png\" /></p><p></p><p>编译器在编译&nbsp;*.c&nbsp;文件时，只能通过&nbsp;*.c&nbsp;及其包含的文件中的信息做优化。</p><p></p><p>LTO （Linking Time Optimization）技术是在链接时使用程序中所有信息进行优化的技术。但 LTO 会将所有&nbsp;*.o&nbsp;文件加载到内存中，消耗非常多的资源。同时 LTO 串行化部分比较多。编译时间很长。落地对环境、技术要求比较高，目前只在 suse 等传统 Linux 厂商中得到应用。</p><p></p><p>为了解决这个问题，LLVM 实现了 ThinLTO 以降低 LTO 的开销。</p><p></p><p>GCC WHOPR 的整体架构如图所示。思路是在编译阶段为每个编译单元生成 Summary 信息，之后再根据 Summary 信息对每个编译单元进行优化。</p><p><img src=\"https://static001.geekbang.org/infoq/47/472f5387eac79dab985b7d1c891a3586.png\" /></p><p></p><p>ThinLTO 技术的整体架构如上图所示。都是在编译阶段为每个&nbsp;*.o&nbsp;文件生成 Summary 信息，之后在 thin link 阶段根据 Summary 信息对每个&nbsp;*.o&nbsp;文件进行优化。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6d/6dcf4ec3f426527b9f01d7a15bc768a7.png\" /></p><p></p><p>使用 GCC LTO 的原因是 GCC 的 LTO 实现相对比较成熟。</p><p></p><p>从图上可以看出，在性能收益上 ThinLTO 与 &nbsp;LTO 的差距并不大。而 ThinLTO 与 LTO 相比最大的优势是占用的资源极小：</p><p><img src=\"https://static001.geekbang.org/infoq/84/8434fb161d7b6a7820dcb6f9026092ec.png\" /></p><p></p><p>如图为使用 LLVM ThinLTO、LLVM LTO 以及 GCC LTO 链接 Chromium 时的内存消耗走势图。</p><p><img src=\"https://static001.geekbang.org/infoq/ff/ff6e9f042e2524c435e24b14807bb301.png\" /></p><p></p><p>所以使用 ThinLTO 可以使我们的业务在日常开发中以很小的代价拿到很大的提升。同时开启 ThinLTO 的难度很低，基本只要可以启用 clang 就可以使能 ThinLTO。在我们的实践中，一般开启 ThinLTO 可以拿到 10% 的性能提升。</p><p></p><h3>AutoFDO</h3><p></p><p></p><p>AutoFDO 是一个简化 FDO 的使用过程的系统。AutoFDO 会从生产环境收集反馈信息（perf 数据），然后将其应用在编译时。反馈信息是在生产环境的机器上使用 perf 工具对相应硬件事件进行采样得到的。总体来说，一次完整的 AutoFDO 过程如下图可分为 4 步：</p><p><img src=\"https://static001.geekbang.org/infoq/b7/b759f72f9bbfca37e9cd37dba7cb2c07.png\" /></p><p></p><p>1. 将编译好的 binary 部署到生产环境或者测试环境， 在正常工作的情况下使用 perf 对当前进程做周期性的采集。</p><p>2. 将 perf 数据转化成 llvm 可以识别的格式，并将其保存到数据库中。</p><p>3. 当用户再次编译的时候，数据库会将亲近性最强的profile文件返回给编译器并参与到当前构建中。</p><p>4. 将编译好的二进制进行归档和发布。</p><p></p><p>对于业务而言，AutoFDO 的接入有同步和异步两种接入方式：</p><p></p><p>同步接入：首先编译一个 AutoFDO 不参与的二进制版本。在 benchmark 环境下运行当前二进制并使用perf采集数据。使用 AutoFDO 再次构建一个二进制版本，此二进制为最终发布版本。异步接入：在客户线上机器进行周期性采集，将采集数据进行合并和保存。构建新版本的时候将对应的数据文件下载， 并参与当前版本的编译。</p><p>在实际中开启 AutoFDO 可以拿到 2%～5% 的性能提升。</p><p></p><h3>Bolt</h3><p></p><p></p><p>Bolt 基于 LLVM 框架的二进制 POST-LINK 优化技术，可以在 PGO/基础进一步优化。</p><p></p><p>Bolt 应用于其数据中心负载处理，即使数据中心已进行了 PGO(AutoFDO)和 LTO 优化后，BOLT 仍然能够提升其性能。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/28/28b91f2f276b42ba9a56a043d3f148eb.png\" /></p><p></p><p>1. Function Discovery：通过 ELF 符号表查找所有函数名字与地址。</p><p>2. Read debug info：如果二进制编译时带有 Debug 信息，读取 Debug 信息。</p><p>3. Read Profile data：读取 Profile 数据，用于驱动 CFG 上优化。</p><p>4. Disassembly：基于LLVM将机器码翻译成保存在内存里的汇编指令。</p><p>5. CFG Construction：依据汇编指令构建控制流图（Control-Flow graph）。</p><p>6. Optimization pipeline：经过上述操作，汇编指令内部表示形式均含有Profile信息，就可以进行一系列的操作优化:</p><p>BasicBlock ReorderingFunction Reordering...</p><p>7. Emit and Link Functions：发射优化后代码，重定向函数地址；</p><p>8. Rewrite binary file：重写二进制文件。</p><p></p><p>Bolt 的接入类似 AutoFDO，也需要先收集到 Perf 数据同时使用该数据重新编译。在我们的实践中性能可以提升 8%。</p><p></p><h2>语言特性</h2><p></p><p></p><p>这里我们简单介绍下两个 C++ 语言的新特性 Coroutines &nbsp;与 Modules 来展示更新到现代化工具链后可以使用的 C++ 新特性。</p><p></p><h3>Coroutines</h3><p></p><p></p><p>首先可以先简单介绍一下&nbsp;Coroutines：</p><p>协程是一个可挂起的函数。支持以同步方式写异步代码。C++20 协程是无栈协程。在语义层面不保存调用上下文信息。对比有栈协程两个数量级的切换效率提升。更好的执行 &amp; 切换效率。对比 Callback更简洁的编程模式，避免 Callback hell。</p><p>接下来我们以一个简单的例子为例，介绍协程是如何支持以同步方式写异步代码。首先我们先看看同步代码的案例：</p><p></p><p><code lang=\"text\">uint64_t ReadSync(std::vector Inputs) {\n    uint64_t read_size = 0;\n    for (auto &amp;&amp;Input : Inputs)\n      read_size += ReadImplSync(Input);\n    return read_size;\n}</code></p><p>这是一个统计多个文件体积的同步代码，应该是非常简单。</p><p></p><p>接下来我们再看下对应的异步写法：</p><p><code lang=\"text\">template \nfuture do_for_each(Range, Lambda);                    // We need introduce another API.\nfuture ReadAsync(vector Inputs) {\n    auto read_size = std::make_shared(0);        // We need introduce shared_ptr.\n    return do_for_each(Inputs,                                           // Otherwise read_size would be\n                 [read_size] (auto &amp;&amp;Input){            // released after ReadAsync ends.\n                                    return ReadImplAsync(Input).then([read_size](auto &amp;&amp;size){\n                                             *read_size += size;\n                                             return make_ready_future();\n                                       });\n                                })\n      .then([read_size] { return make_ready_future(*read_size); });\n}</code></p><p></p><p>肉眼可见地，异步写法麻烦了非常多。同时这里还使用到了&nbsp;std::shared_ptr。但&nbsp;std::shared_ptr&nbsp;会有额外的开销。如果用户不想要这个开销的话需要自己实现一个非线程安全的&nbsp;shared_ptr，还是比较麻烦的。</p><p></p><p>最后再让我们来看下协程版的代码：</p><p></p><p><code lang=\"text\">Lazy ReadCoro(std::vector Inputs) {\n    uint64_t read_size = 0;\n    for (auto &amp;&amp;Input : Inputs)\n        read_size += co_await ReadImplCoro(Input);\n    co_return read_size;\n}</code></p><p></p><p>可以看到这个版本的代码与同步代码是非常像的，但这份代码本质上其实是异步代码的。所以我们说：</p><p>协程可以让我们用同步方式写异步代码；兼具开发效率和运行效率。</p><p></p><p>接下来来简单介绍下 C++20 协程的实现：</p><p></p><p>C++20 协程是无栈协程，需要编译器介入才能实现。判定协程并搜索相关组件。（Frontend Semantic Analysis）生成代码。（Frontend Code Generation）生成、优化、维护协程桢。（Middle-end）C++20 协程只设计了基本语法，并没有加入协程库。C++20 协程的目标用户是协程库作者。其他用户应通过协程库使用协程。</p><p></p><p>同时我们在 GCC 和 Clang 中做了以下工作：</p><p></p><p>GCC与社区合作进行协程的支持。GCC-10 是第一个支持 C++ 协程特性的 GCC 编译器。仅支持，无优化。Clang/LLVM与 Clang/LLVM 社区合作完善 C++ 协程。改善&amp;优化：对称变换、协程逃逸分析和CoroElide优化，协程帧优化（Frame reduction），完善协程调试能力、尾调用优化、Coro Return Value Optimization等。在 Clang/LLVM14 中，coroutine 移出了 experimental namespace。Maintaining</p><p></p><p>最后我们还实现并开源了一个经过双 11 验证的协程库 async_simple：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/20/2097c206f96f6fab1d6971ba1b795f6d.png\" /></p><p>async_simple设计借鉴了 folly 库协程模块。轻量级。包含有栈协程、无栈协程以及 Future/Promise 等异步组件。从真实需求出发。与调度器解藕，用户可以选择合适自己的调度器。经受了工业级 Workload 的考验。开源于：https://github.com/alibaba/async_simple</p><p></p><p>最后我们来看下我们应用协程后的效果：</p><p>业务1（1M Loc、35w core）原先为同步逻辑协程化后 Latency 下降 30%超时查询数量大幅下降甚至清零业务2（7M Loc）原先为异步逻辑协程化后 Latency 下降 8%业务3（100K Loc、2.7w core）原先为同步逻辑协程化后 qps 提升 10 倍以上性能</p><p></p><h3>Modules</h3><p></p><p></p><p>Modules 是 C++20 的四大重要特性（Coroutines、Ranges、Concepts 以及 Modules）之一。Modules 也是这四大特性中对现在 C++ 生态影响最大的特性。Modules 是 C++20 为复杂、难用、易错、缓慢以及古老的 C++ 项目组织形式提供的现代化解决方案。Modules 可以提供：</p><p></p><p>降低复杂度与出错的机会更好的封装性更快的编译速度</p><p></p><p>对于降低复杂度而言，我们来看下面这个例子：</p><p></p><p><code lang=\"text\">#include \"a.h\"\n#include \"b.h\"\n// another file\n#include \"b.h\n#include \"a.h\"</code></p><p></p><p>在传统的头文件结构中 a.h与 b.h 的 include 顺序可能会导致不同的行为，这一点是非常烦人且易错的。而这个问题在 Modules 中就自然得到解决了。例如下面两段代码是完全等价的：</p><p></p><p><code lang=\"text\">import a;\nimport b;</code></p><p></p><p>与</p><p></p><p><code lang=\"text\">import b;\nimport a;</code></p><p></p><p>对于封装性，我们以 asio 库中的&nbsp;asio::string_view&nbsp;为例进行说明。以下是&nbsp;asio::string_view&nbsp;的实现：</p><p></p><p><code lang=\"text\">namespace asio {\n\n#if defined(ASIO_HAS_STD_STRING_VIEW)\nusing std::basic_string_view;\nusing std::string_view;\n#elif defined(ASIO_HAS_STD_EXPERIMENTAL_STRING_VIEW)\nusing std::experimental::basic_string_view;\nusing std::experimental::string_view;\n#endif // defined(ASIO_HAS_STD_EXPERIMENTAL_STRING_VIEW)\n\n} // namespace asio\n\n# define ASIO_STRING_VIEW_PARAM asio::string_view\n#else // defined(ASIO_HAS_STRING_VIEW)\n# define ASIO_STRING_VIEW_PARAM const std::string&amp;\n#endif // defined(ASIO_HAS_STRING_VIEW)</code></p><p></p><p>该文件的位置是&nbsp;/asio/detail/string_view.hpp，位于 detail 目录下。同时我们从 asio 的官方文档（链接地址见文末）中也找不到 string_view 的痕迹。所以我们基本可以判断 asio::string_view这个组件在 asio 中是不对外提供的，只在库内部使用，作为在 C++ 标准不够高时的备选。然而使用者们确可能将&nbsp;asio::string_view作为一个组件单独使用（Examples），这违背了库作者的设计意图。从长远来看，类似的问题可能会导致库用户代码不稳定。因为库作者很可能不会对没有暴露的功能做兼容性保证。</p><p>这个问题的本质是头文件的机制根本无法保证封装。用户想拿什么就拿什么。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/3f/c3/3fd7d88f9d647365bcb8794a7134c5c3.png\" /></p><p></p><p>而 Modules 的机制可以保障用户无法使用我们不让他们使用的东西，极强地增强了封装性：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/67/e9/670994c8b42864f25cff5858bde4bce9.png\" /></p><p></p><p>最后是编译速度的提升，头文件导致编译速度慢的根本原因是每个头文件在每个包含该头文件的源文件中都会被编译一遍，会导致非常多冗余的编译。如果项目中有&nbsp;n&nbsp;个头文件和&nbsp;m&nbsp;个源文件，且每个头文件都会被每个源文件包含，那么这个项目的编译时间复杂度为&nbsp;&nbsp;O(n*m)。如果同样的项目由&nbsp;n&nbsp;个 Modules 和&nbsp;m&nbsp;个源文件，那么这个项目的编译时间复杂度将为&nbsp;O(n+m)。这会是一个复杂度级别的提升。</p><p></p><p>我们在&nbsp;https://github.com/alibaba/async_simple/tree/CXX20Modules&nbsp;中将 async_simple 库进行了完全 Modules 化，同时测了编译速度的提升：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8b/8bf8381ba2633d29051bdbb9f913a5cf.png\" /></p><p></p><p>可以看到编译时间最多可以下降 74%，这意味着 4 倍的编译速度提升。需要主要 async_simple 是一个以模版为主的 header only 库，对于其他库而言编译加速应该更大才对。关于 Modules 对编译加速的分析我们在今年的 CppCon22 中也有介绍（链接地址见文末）。</p><p></p><p>最后关于 Modules 的进展为：</p><p></p><p>编译器初步开发完成支持 std modules优先内部应用已在 Clang15 中发布探索编译器与构建系统交互 (ing)</p><p></p><h2>总结</h2><p></p><p></p><p>最后我们再总结一下，使用现代化工具链带来的好处：</p><p></p><p>更短的编译时间更好的运行时性能更好的编译、静态、运行时检查更多优化技术 – ThinLTO、AutoFDO、Bolt 等更新的语言特性支持 – C++20 协程、C++20 Module 等持续性更新升级 – 良性循环</p><p></p><p>希望更多的项目可以使用更现代化的工具链。</p><p></p><p>相关链接：</p><p>asio官方文档链接地址：</p><p>https://think-async.com/Asio/asio-1.22.1/doc/asio/index.html</p><p>CppCon22 链接地址：</p><p>https://cppcon.digital-medium.co.uk/session/2022/how-much-compilation-speedup-we-will-get-from-c-modules/。</p>",
    "publish_time": "2022-10-12 10:47:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "达摩院损失AI“大将”，预训练大模型M6技术负责人杨红霞离职",
    "url": "https://www.infoq.cn/article/DXPyv0mf6q09hmWtNxEV",
    "summary": "<p>阿里达摩院损失AI“大将”。</p><p></p><p>日前，据 Tech 星球报道，阿里达摩院大模型带头人杨红霞已于9月初离职。InfoQ发现，杨红霞于不久前注销了钉钉账号。</p><p></p><h3>全球最大AI 预训练模型 M6 背后的技术负责人</h3><p></p><p></p><p><a href=\"https://www.infoq.cn/article/IhiliY5-iSW4H60ushSl\">杨红霞</a>\"博士是超大规模多模态预训练模型M6的技术负责人。</p><p></p><p>M6，英文全称是 MultiModality-to-MultiModality Multitask Mega-transformer，6 个 M，简称 M6。</p><p></p><p>顾名思义，M6 大模型主打多模态、多任务能力，其目标是打造全球领先的具有通用性的人工智能大模型。</p><p></p><p>2021年 3 月，达摩院发布了国内首个千亿参数多模态大模型 M6，引发海外关注。OpenAI 前政策主管 Jack Clark 公开点评道：“这个模型的规模和设计都非常惊人。这看起来像是众多中国的 AI 研究组织逐渐发展壮大的一种表现。”</p><p></p><p>2021年11月，阿里 M6 宣布<a href=\"https://www.infoq.cn/article/z40A8r0QeP32g0Jo4TK1\">升级</a>\"至万亿参数，并在全球范围内首次大幅降低了万亿参数超大模型训练能耗，更加符合业界对低碳、高效训练 AI 大模型的需求。</p><p></p><p>据悉，通过一系列突破性的技术创新，达摩院团队仅使用 480 卡 V100 32G GPU，即训练出了规模达人类神经元 10 倍的万亿参数多模态大模型 M6，与英伟达、谷歌等海外公司实现万亿参数规模相比，能耗降低超八成、效率提升约 11 倍。</p><p></p><p>这一技术突破将极大降低万亿模型训练门槛，让大模型研究和工业化落地进入更加普惠的时代。</p><p></p><p>针对此次升级，达摩院资深算法专家杨红霞曾表示，“接下来，M6 团队将继续把低碳 AI 做到极致，推进应用进一步落地，并探索对通用大模型的理论研究。”</p><p></p><p>以下为 M6 发展历程：</p><p></p><p>2021 年 1 月&nbsp;——&nbsp;M6 百亿参数模型达成，国内首个百亿规模多模态大模型2021 年 2 月&nbsp;——&nbsp;M6 千亿参数模型达成，国内首个千亿规模多模态大模型2021 年 5 月&nbsp;——&nbsp;M6 万亿参数模型达成，全球范围内首次大幅降低了万亿参数超大模型训练能耗，且成为国内首个实现商业化落地的多模态大模型</p><p></p><h2>AI项目落地难？</h2><p></p><p></p><p>据报道，杨红霞此次离职是因为个人家庭原因。</p><p></p><p>Tech 星球的报道中称，此番杨红霞离职，被认为是达摩院对一些难以落地的商业化项目进行调整。一位阿里云内部人士透露，“达摩院很多项目都是远看很牛，近看难以落地”，虽然二者都在云与科技，但是达摩院的项目与业务产研隔的较远，也很少和云服务一起对外售卖。所以达摩院每个项目的落地应用和商业化程度，很多是个谜。</p><p></p><p>去年5月，阿里宣布AI 大模型首次商用，M6 成为国内首个实现商业化落地的多模态大模型。经过一段时间的试用，M6 作为 AI 助理设计师正式上岗阿里新制造平台犀牛智造，通过结合潮流趋势进行快速设计、试穿效果模拟，有望大幅缩短快时尚新款服饰设计周期。M6 还已应用于支付宝、淘宝等平台，参与跨模态搜索、文案撰写、图片设计等工作。</p><p></p><p>此前，阿里一直强调，达摩院不用有盈利压力。但2022年，互联网企业普遍降本增效，达摩院也进行了诸多调整。在杨红霞之前，阿里集团副总裁、阿里云研究院副院长肖利华，达摩院副院长<a href=\"https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247544724&amp;idx=2&amp;sn=e89dbb5a3823608d0ae1ab7cebbd1ce7&amp;chksm=fbea965bcc9d1f4da26769446553fc0cb96fa8fadde2462163ca238320e6b4bd8b10b3c43a23&amp;scene=27#wechat_redirect\">金榕</a>\"等都已相继离开阿里。</p><p></p><p>杨红霞是AI领域杰出的人工智能科学家。资料显示，杨红霞&nbsp;2007 年本科毕业于南开大学，获统计学学士学位。其后她去往美国杜克大学统计科学系攻读博士学位，师从 David Dunson 教授。杨红霞拥有顶级论文 40 余篇。曾任 IBM Watson 研究员、Yahoo！主任数据科学家等职。她曾带领团队获2019世界人工智能大会最高奖卓越人工智能引领者（Super AI Leader，简称SAIL奖），曾获2022年福布斯中国科技女性50强的荣誉，获得2020年国家科学技术进步奖二等奖。</p>",
    "publish_time": "2022-10-12 12:07:01",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]