[
  {
    "title": "使用Strimzi将Kafka和Debezium迁移到Kubernetes",
    "url": "https://www.infoq.cn/article/ElNtSM5ISobpMB8fMC0j",
    "summary": "<p>在本系列文章的<a href=\"https://www.infoq.cn/article/cFpvXRLmZzJBGbzAeFu5\">第1部分</a>\"和<a href=\"https://www.infoq.cn/article/WfA0p1XoZCJ6INdyJLyv\">第2部分</a>\"中，我们学习了<a href=\"https://kafka.apache.org/\">Apache Kafka</a>\"、Apache Kafka Streams和<a href=\"https://quarkus.io/\">Quarkus</a>\"之间的集成。我们开发了一个简单的应用程序，向Kafka主题生成事件，并使用<a href=\"https://kafka.apache.org/documentation/streams/\">Kafka Streams</a>\"实时消费和处理它们。</p><p></p><p>在那个例子中，我们模拟了一家电影流媒体公司。我们将电影信息保存在一个Kafka主题中，并在另一个Kafka主题中保存用户停止观看电影时的事件，并捕获影片播放的时间。我们实时对这些事件进行后期处理，计算电影播放超过10分钟的次数。</p><p></p><p>下图是这个应用程序的架构。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/strimzi-the-gitops-way/en/resources/11-1664224713829.jpeg\" /></p><p>然后，在<a href=\"https://www.infoq.cn/article/V4kqPgrQlqqPgWQuMmDP\">第3部分</a>\"中，我们介绍了发件箱模式和Debezium，用于避免在不同系统需要同步相同数据时发生的双写问题。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/strimzi-the-gitops-way/en/resources/12-1664224713829.jpeg\" /></p><p>在前面的三篇文章中，我们已经从开发人员的角度学习了所有这些技术，并最终在开发人员的本地机器上（以开发模式）部署应用程序。</p><p></p><p>在本文中，我们将探讨如何将所有东西部署到生产环境，更具体地说，部署到Kubernetes中。我们将学习：</p><p></p><p>在Kubernetes中安装和管理Apache Kafka集群。容器化Quarkus应用程序。配置一个带有生产参数的Quarkus应用程序。将Debezium Embedded迁移成Debezium Server。</p><p></p><h2>Kubernetes</h2><p></p><p></p><p>Kubernetes是一个开源的容器编配器，是部署微服务的事实上的平台。这些服务既可以在裸金属环境中运行，也可以在云环境中运行。</p><p></p><p>本文使用<a href=\"https://minikube.sigs.k8s.io/docs/\">minikube</a>\"作为Kubernetes集群，但同样的步骤应该适用于任何其他实现。</p><p></p><h4>启动集群</h4><p></p><p>在终端窗口中执行以下命令，在配备了8GB内存和2个vCPU的VirtualBox机器上启动集群。</p><p></p><p><code lang=\"plain\">minikube start -p strimzi --kubernetes-version='v1.22.12' --vm-driver='virtualbox' --memory=8096\n\n  [strimzi] minikube v1.24.0 on Darwin 12.5\n  minikube 1.26.1 is available! Download it: https://github.com/kubernetes/minikube/releases/tag/v1.26.1\n  To disable this notice, run: 'minikube config set WantUpdateNotification false'\n\n✨  Using the virtualbox driver based on user configuration\n  Starting control plane node strimzi in cluster strimzi\n  Creating virtualbox VM (CPUs=2, Memory=8096MB, Disk=20000MB) ...\n    &gt; kubelet.sha256: 64 B / 64 B [--------------------------] 100.00% ? p/s 0s\n    &gt; kubeadm.sha256: 64 B / 64 B [--------------------------] 100.00% ? p/s 0s\n    &gt; kubectl.sha256: 64 B / 64 B [--------------------------] 100.00% ? p/s 0s\n    &gt; kubeadm: 43.74 MiB / 43.74 MiB [-------------] 100.00% 13.98 MiB p/s 3.3s\n    &gt; kubectl: 44.77 MiB / 44.77 MiB [-------------] 100.00% 11.11 MiB p/s 4.2s\n    &gt; kubelet: 115.30 MiB / 115.30 MiB [-----------] 100.00% 20.16 MiB p/s 5.9s\n\n    ▪ Generating certificates and keys ...\n    ▪ Booting up control plane ...\n    ▪ Configuring RBAC rules ...\n    ▪ Using image gcr.io/k8s-minikube/storage-provisioner:v5\n  Verifying Kubernetes components...\n  Enabled addons: storage-provisioner, default-storageclass\n\n❗  /usr/local/bin/kubectl is version 1.24.0, which may have incompatibilites with Kubernetes 1.22.12.\n    ▪ Want kubectl v1.22.12? Try 'minikube kubectl -- get pods -A'\n  Done! kubectl is now configured to use \"strimzi\" cluster and \"default\" namespace by default\n</code></p><p></p><p>在终端窗口执行下面的命令检查Kubernetes集群是否正常运行。</p><p></p><p><code lang=\"plain\">kubectl get nodes\n\nNAME      STATUS   ROLES                  AGE    VERSION\nstrimzi   Ready    control-plane,master   3m4s   v1.22.12\n\nkubectl get pods\nNo resources found in default namespace.\n</code></p><p></p><h2>Apache Kafka</h2><p></p><p></p><p>在之前的文章中，我们通过Quarkus的开发模式来启动运行应用程序所需的外部依赖项（Kafka集群和MySQL数据库）。从开发的角度来看，开发模式非常棒，但在部署到生产环境时，你会发现这些东西管理起来更加复杂。第一个障碍可能是在Kubernetes中安装和配置Kafka集群。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/strimzi-the-gitops-way/en/resources/13-1664224713829.jpeg\" /></p><p>你可能想知道以下这些问题的答案：</p><p></p><p>Kafka组件（Kafka、Zookeeper等）需要使用哪个容器镜像?如何在Kubernetes中轻松部署所有这些组件？如何在Kubernetes中创建用户、主题或HA？安全性如何？你可以尝试手动完成所有这些事情，例如编写很长的YAML文件和使用Kafka CI工具配置Kafka组件。然而，还有另一种Kubernetes原生的、完全自动化和可复制的（非常适合CI/CD）方法，就是使用Strimzi。</p><p></p><h4>Strimzi</h4><p></p><p><a href=\"https://strimzi.io/\">Strimzi</a>\"是一个<a href=\"https://www.redhat.com/en/topics/containers/what-is-a-kubernetes-operator\">Kubernetes Operator</a>\"，通过控制器来创建、配置和保护Kafka集群，就像其他Kubernetes资源（如Pod、Deployment、ConfigMap等）一样。</p><p></p><p>Strimzi项目包含三个Operator——一个用于管理Kafka集群，一个用于管理主题，一个用于用户管理。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/strimzi-the-gitops-way/en/resources/14-1664224713829.jpeg\" /></p><p>在Kubernetes集群中安装了Strimzi Operator之后，你只需要使用下面的YAML文件就可以启动并运行一个Kafka集群，其中包含了一个Kafka副本和三个使用临时存储（没有挂载持久卷）的ZooKeeper副本。</p><p></p><p><code lang=\"plain\">apiVersion: kafka.strimzi.io/v1beta2\nkind: Kafka\nmetadata:\n name: my-cluster\nspec:\n kafka:\n   version: 3.2.0\n   replicas: 1\n   listeners:\n     - name: plain\n       port: 9092\n       type: internal\n       tls: false\n     - name: tls\n       port: 9093\n       type: internal\n       tls: true\n   config:\n     offsets.topic.replication.factor: 1\n     transaction.state.log.replication.factor: 1\n     transaction.state.log.min.isr: 1\n     default.replication.factor: 1\n     min.insync.replicas: 1\n     inter.broker.protocol.version: \"3.2\"\n   storage:\n     type: ephemeral\n zookeeper:\n   replicas: 3\n   storage:\n     type: ephemeral\n entityOperator:\n   topicOperator: {}\n   userOperator: {}\n</code></p><p></p><p>接下来，我们将在已经启动的集群中安装Strimzi。</p><p></p><h4>安装Strimzi</h4><p></p><p>首先是创建一个命名空间来安装Strimzi Operator。在本例中，我们使用了命名空间kafka。在终端窗口中执行如下命令：</p><p></p><p><code lang=\"plain\">kubectl create namespace kafka\nnamespace/kafka created\n</code></p><p></p><p>接下来，我们应用Strimzi安装文件，其中包括用于声明式管理Kafka集群、Kafka主题和用户的CRD（CustomerResourceDefinition）。</p><p></p><p><code lang=\"plain\">kubectl create -f 'https://strimzi.io/install/latest?namespace=kafka' -n kafka\n</code></p><p></p><p>运行下面的命令验证Operator是否安装正确。</p><p></p><p><code lang=\"plain\">kubectl get pods -n kafka\n\nNAME                                        READY   STATUS    RESTARTS   AGE\nstrimzi-cluster-operator-597d67c7d6-ms987   1/1     Running   0          4m27s\n</code></p><p></p><p>现在，我们开始创建带有movies主题的Kafka集群。我们将在这个主题中保存所有电影的信息，稍后Kafka Streams将消费这个主题，正如我们在本系列文章的<a href=\"https://www.infoq.cn/article/WfA0p1XoZCJ6INdyJLyv\">第2部分</a>\"中所看到的那样。</p><p></p><h4>创建Kafka集群</h4><p></p><p>创建一个新的文件（即kafka.yaml）来安装一个带有一个副本的<a href=\"https://strimzi.io/docs/operators/latest/configuring.html#assembly-config-kafka-str\">Kafka集群</a>\"，不启用TLS，作为内部<a href=\"https://kubernetes.io/docs/concepts/services-networking/service/\">Kubernetes服务</a>\"。</p><p></p><p><code lang=\"plain\">apiVersion: kafka.strimzi.io/v1beta2\nkind: Kafka\nmetadata:\n name: my-cluster\nspec:\n kafka:\n   version: 3.2.0\n   replicas: 1\n   listeners:\n     - name: plain\n       port: 9092\n       type: internal\n       tls: false\n   config:\n     offsets.topic.replication.factor: 1\n     transaction.state.log.replication.factor: 1\n     transaction.state.log.min.isr: 1\n     default.replication.factor: 1\n     min.insync.replicas: 1\n     inter.broker.protocol.version: \"3.2\"\n   storage:\n     type: ephemeral\n zookeeper:\n   replicas: 1\n   storage:\n     type: ephemeral\n entityOperator:\n   topicOperator: {}\n   userOperator: {}\n</code></p><p></p><p>然后在终端窗口中使用kubectl命令创建这个资源：</p><p></p><p><code lang=\"plain\">kubectl create -f kafka.yaml -n kafka\nkafka.kafka.strimzi.io/my-cluster created\n</code></p><p></p><p>此时，Strimzi开始在默认命名空间中安装Kafka集群。</p><p></p><p>现在，我们通过获取默认的名称空间Pod来检查集群的创建情况。</p><p></p><p><code lang=\"plain\">kubectl get pods -n kafka\n\nNAME                                          READY   STATUS    \nmy-cluster-entity-operator-755596449b-cw82g   3/3     Running   \nmy-cluster-kafka-0                            1/1     Running \nmy-cluster-zookeeper-0                        1/1     Running\n</code></p><p></p><p>Kafka集群已启动并运行。我们除了可以将Kafka作为Kubernetes资源安装之外，还可以查询和描述它。例如，在终端窗口中执行如下命令：</p><p></p><p><code lang=\"plain\">kubectl get kafka -n kafka\n\nNAME         DESIRED KAFKA REPLICAS   DESIRED ZK REPLICAS   READY   WARNINGS\nmy-cluster   1                        1                     True    True\n\n\n\nkubectl describe kafka my-cluster -n kafka\n\nName:         my-cluster\nNamespace:    default\nLabels:       \nAnnotations:  \nAPI Version:  kafka.strimzi.io/v1beta2\nKind:         Kafka\nMetadata:\n  Creation Timestamp:  2022-08-09T10:57:39Z\n…\n</code></p><p></p><p>当然，你也可以像删除其他Kubernetes资源一样删除它。此外，系统还创建了4个Kubernetes服务来访问Kafka集群：</p><p></p><p><code lang=\"plain\">kubectl get services -n kafka\n\nNAME                          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE\n               143m\nmy-cluster-kafka-bootstrap    ClusterIP   172.30.77.150           9091/TCP,9092/TCP            21m\nmy-cluster-kafka-brokers      ClusterIP   None                    9090/TCP,9091/TCP,9092/TCP   21m\nmy-cluster-zookeeper-client   ClusterIP   172.30.5.186            2181/TCP                     21m\nmy-cluster-zookeeper-nodes    ClusterIP   None                    2181/TCP,2888/TCP,3888/TCP   21m\n</code></p><p></p><p>应用程序用于访问集群的服务是my-cluster-kafka-bootstrap，它公开了Kafka的9092端口。</p><p></p><p>在进入到应用程序部分之前，我们需要使用另一个YAML文件来创建和配置movies主题。</p><p></p><h4>创建movies主题</h4><p></p><p>Strimzi有一个用于创建和管理主题的Operator。要创建一个新主题，我们需要创建一个<a href=\"https://strimzi.io/docs/operators/latest/configuring.html#using-the-topic-operator-str\">KafkaTopic</a>\"类型的Kubernetes资源文件，在strimzi.io/cluster中指定主题的名称和集群的名称（在我们的例子中是my-cluster）。我们使用下面的内容创建一个名为movies-topic.yaml的新文件。</p><p></p><p><code lang=\"plain\">apiVersion: kafka.strimzi.io/v1beta2\nkind: KafkaTopic\nmetadata:\n name: movies\n labels:\n   strimzi.io/cluster: my-cluster\nspec:\n partitions: 1\n replicas: 1\n config:\n   retention.ms: 7200000\n   segment.bytes: 1073741824\n</code></p><p></p><p>并应用这个文件：</p><p></p><p><code lang=\"plain\">kubectl apply -f movies-topic.yaml -n kafka\nkafkatopic.kafka.strimzi.io/movies create\n</code></p><p></p><p>和其他Kubernetes资源一样，我们也可以查询和描述它。</p><p></p><p><code lang=\"plain\">kubectl get kafkatopic -n kafka\n\nNAME                                                                                               CLUSTER      PARTITIONS   REPLICATION FACTOR   READY\nconsumer-offsets---84e7a678d08f4bd226872e5cdd4eb527fadc1c6a                                        my-cluster   50           1                    True\nmovies                                                                                             my-cluster   1            1                    True\nstrimzi-store-topic---effb8e3e057afce1ecf67c3f5d8e4e3ff177fc55                                     my-cluster   1            1                    True\nstrimzi-topic-operator-kstreams-topic-store-changelog---b75e702040b99be8a9263134de3507fc0cc4017b   my-cluster   1            1                    True\n</code></p><p></p><p>描述已创建的主题：</p><p></p><p><code lang=\"plain\">kubectl port-forward -n kafka service/my-cluster-kafka-bootstrap 9092:9092\n\nForwarding from 127.0.0.1:9092 -&gt; 9092\nForwarding from [::1]:9092 -&gt; 9092\n</code></p><p></p><p>我们来检查一下创建的主题是否有<a href=\"https://kubernetes.io/docs/tasks/access-application-cluster/port-forward-access-application-cluster/\">端口转发</a>\"。</p><p></p><p>在终端窗口执行如下命令：</p><p></p><p><code lang=\"plain\">kubectl port-forward -n kafka service/my-cluster-kafka-bootstrap 9092:9092\n\nForwarding from 127.0.0.1:9092 -&gt; 9092\nForwarding from [::1]:9092 -&gt; 9092\n</code></p><p></p><p>打开一个新的终端窗口，使用<a href=\"https://github.com/edenhill/kcat\">kcat</a>\"工具列出Kafka集群的元素。我们可以使用localhost作为主机名，就像在上一步中使用端口转发技巧一样。</p><p></p><p><code lang=\"plain\">kcat -b localhost:9092 -L\n\nMetadata for all topics (from broker -1: localhost:9092/bootstrap):\n 1 brokers:\n  broker 0 at my-cluster-kafka-0.my-cluster-kafka-brokers.default.svc:9092 (controller)\n 4 topics:\n  topic \"movies\" with 1 partitions:\n    partition 0, leader 0, replicas: 0, isrs: 0\n</code></p><p></p><p>最后，我们停止端口转发进程，对项目进行容器化，就像我们在本系列文章的<a href=\"https://www.infoq.cn/article/V4kqPgrQlqqPgWQuMmDP\">第3部分</a>\"中所做的那样，并进行一些相应的配置，以便连接到Kafka集群。</p><p></p><h2>生产者Debezium</h2><p></p><p></p><p>我们在系列文章的<a href=\"https://www.infoq.cn/article/V4kqPgrQlqqPgWQuMmDP\">第3部分</a>\"解决了双写问题，使用Debezium（具体来说是<a href=\"https://github.com/lordofthejars/movie-plays-kafka/blob/main/movie-plays-producer-debezium/src/main/java/org/acme/DebeziumListener.java\">Debezium Embedded</a>\"）修复了这个问题，具体方法是监听来自MySQL服务器的事务日志，并在每次插入新的电影播放信息时生成带有数据的Kafka事件。你可以在本地机器上运行这个示例，使用开发服务启动所需的服务（MySQL和Kafka），并自动配置应用程序来连接它们。</p><p></p><p>现在有点不一样了——服务必须运行在Kubernetes集群中，包括在前面步骤中创建的Kafka集群和MySQL数据库。要让它在Kubernetes中运行，需要做出三个改变。</p><p></p><p>使用新的Kafka和MySQL参数（主机名、端口、用户名和密码）来配置服务。将应用程序装入容器，并推送到容器注册表。创建Kubernetes资源文件，用于部署服务。</p><p></p><h2>配置服务</h2><p></p><p></p><p>首先要配置的是Kafka的主机名和端口，它们指向Strimzi创建的Kubernetes服务。打开src/main/resources/application.properties文件并添加下面的内容：</p><p></p><p><code lang=\"plain\">%prod.kafka.bootstrap.servers=my-cluster-kafka-bootstrap:9092\n</code></p><p></p><p>%prod前缀表示这个属性仅在应用程序以prod模式下运行时使用（而不是在dev或test模式下)。</p><p></p><p>其次时配置插入影片信息的数据库连接。在application.properties文件中添加下面的内容。</p><p></p><p><code lang=\"plain\">quarkus.hibernate-orm.database.generation=drop-and-create\n%prod.quarkus.datasource.username=alex\n%prod.quarkus.datasource.password=alex\n%prod.quarkus.datasource.jdbc.url=jdbc:mysql://mysql:3306/moviesdb\n</code></p><p></p><p>稍后，我们将使用这些参数部署一个MySQL实例。现在，我们假设配置参数是正确的。</p><p></p><h4>容器化</h4><p></p><p>Quarkus为创建容器提供了与<a href=\"https://github.com/GoogleContainerTools/jib\">Jib</a>\"项目的集成，让容器镜像的构建和推送简单得只需要执行一个Maven/Gradle任务。</p><p></p><p>打开pom.xml文件，在dependencies部分添加以下依赖项：</p><p></p><p><code lang=\"plain\">\n     io.quarkus\n     quarkus-container-image-jib\n\n</code></p><p></p><p>添加了<a href=\"https://quarkus.io/guides/container-image\">Jib依赖项</a>\"后，它将在打包时自动将应用程序装入容器。因为<a href=\"https://github.com/GoogleContainerTools/jib\">Jib</a>\"的一些默认配置选项可能不适用于所有情况，所以你可以在src/main/resources/application.properties中覆盖它们。对于本例，我们将覆盖生成的容器镜像的group和容器注册中心的主机。</p><p></p><p>打开application.properties文件，并添加下面的内容：</p><p></p><p><code lang=\"plain\"># Substitue the value with your account name\nquarkus.container-image.group=lordofthejars\n \n# Defaults to Docker.io, overriden to Quay.\nquarkus.container-image.registry=quay.io\n</code></p><p></p><p>你需要设置容器注册表的凭据，以便向注册表推送容器。你可以在执行构建之前运行docker的login命令。Maven将从那里读取凭据，或者你可以使用quarkus.container-image.username和quarkus.container-image.password属性。</p><p></p><p>在项目的根目录下运行下面的命令来构建应用程序，它将构建出一个容器并将其推到指定的容器注册表中。</p><p></p><p><code lang=\"plain\">./mvnw clean package -DskipTests -Dquarkus.container-image.push=true\n\n[INFO] Scanning for projects...\n[INFO]\n[INFO] ---------------&lt; org.acme:movie-plays-producer-debezium &gt;---------------\n[INFO] Building movie-plays-producer-debezium 1.0.0-SNAPSHOT\n[INFO] --------------------------------[ jar ]---------------------------------\n[INFO]\n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ movie-plays-producer-debezium ---\n[INFO] Deleting /Users/asotobu/git/quarkus-integrating-kafka/strimzi/movie-plays-producer-debezium/target\n…\n[INFO] [io.quarkus.container.image.jib.deployment.JibProcessor] Using base image with digest: sha256:1a2fddacdcda67494168749c7ab49243d06d8fbed34abab90566d81b94f5e1a5\n[INFO] [io.quarkus.container.image.jib.deployment.JibProcessor] Container entrypoint set to [java, -Djava.util.logging.manager=org.jboss.logmanager.LogManager, -jar, quarkus-run.jar]\n[INFO] [io.quarkus.container.image.jib.deployment.JibProcessor] Pushed container image quay.io/lordofthejars/movie-plays-producer-debezium:1.0.0-SNAPSHOT (sha256:73dfe42d53f8d7e3c268dbebc2e5f866596de33b8fcaf82c27bdd414d28bdb8a)\n</code></p><p></p><p>从最后一行日志可以看到，容器被创建，并使用application.properties中指定的账号推送到注册中心。</p><p></p><h4>Kubernetes</h4><p></p><p>在将容器推送到注册表之后，我们准备将服务部署到Kubernetes中。我们可以手动创建Kubernetes资源文件，但没有必要这么做，因为Quarkus为我们提供了一个<a href=\"https://quarkus.io/guides/deploying-to-kubernetes\">Kubernetes扩展</a>\"。</p><p></p><p>打开pom.xml文件，并在dependencies部分添加下面的依赖项。</p><p></p><p><code lang=\"plain\">\n     io.quarkus\n     quarkus-kubernetes\n\n</code></p><p></p><p>每次Maven打包应用程序时都会注册Kubernetes扩展，并生成将应用程序部署到Kubernetes集群的kubernetes.yml文件。你可以通过application.properties来修改生成文件的内容。例如，我们将Kubernetes Service设置为LoadBalancer而不是ClusterIP，并将命名空间设置为kafka。</p><p></p><p>打开application.properties文件并添加下面的内容。</p><p></p><p><code lang=\"plain\">quarkus.kubernetes.service-type=load-balancer\nquarkus.kubernetes.namespace=kafka\n</code></p><p></p><p>修改好以后运行Maven package生成部署文件。</p><p></p><p><code lang=\"plain\">./mvnw clean package -DskipTests\n\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n</code></p><p></p><p>检查生成的文件target/kubernetes/kubernetes.yml：</p><p></p><p><code lang=\"plain\">cat target/kubernetes/kubernetes.yml\n</code></p><p></p><p>输出的内容应该类似于下面这样：</p><p></p><p><code lang=\"plain\">---\napiVersion: v1\nkind: Service\nmetadata:\n …\n name: movie-plays-producer-debezium\nspec:\n ports:\n   - name: http\n     port: 80\n     targetPort: 8080\n selector:\n   app.kubernetes.io/name: movie-plays-producer-debezium\n   app.kubernetes.io/version: 1.0.0-SNAPSHOT\n # Type is LoadBalancer as set in the application.properties file \n type: LoadBalancer\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n …\n name: movie-plays-producer-debezium\nspec:\n replicas: 1\n selector:\n   matchLabels:\n     app.kubernetes.io/name: movie-plays-producer-debezium\n     app.kubernetes.io/version: 1.0.0-SNAPSHOT\n template:\n   metadata:\n     …\n   spec:\n     containers:\n       - env:\n           - name: KUBERNETES_NAMESPACE\n             valueFrom:\n               fieldRef:\n                 fieldPath: metadata.namespace\n         # The image is correctly set automatically\n         image: quay.io/lordofthejars/movie-plays-producer-debezium:1.0.0-SNAPSHOT\n         imagePullPolicy: Always\n         name: movie-plays-producer-debezium\n         ports:\n           - containerPort: 8080\n             name: http\n             protocol: TCP\n</code></p><p></p><p>在本例中，配置参数是硬编码在application.properties中的，但你可以将它们作为环境变量传递进去。要在Kubernetes Deployment对象中设置环境变量，比如覆盖Kafka的配置，可以添加下面的行：</p><p></p><p><code lang=\"plain\">quarkus.kubernetes.env.vars.kafka-bootstrap-servers=my-new-cluster:9092 \n</code></p><p></p><p>生成文件的env部分将包含这个新的环境变量：</p><p></p><p><code lang=\"plain\">containers:\n       - env:\n           - name: KAFKA_BOOTSTRAP_SERVERS\n             value: my-new-cluster:9092\n         image: quay.io/lordofthejars/movie-plays-producer-debezium:1.0.0-SNAPSHOT\n</code></p><p></p><h4>全部放到一起</h4><p></p><p>我们已经使用Strimzi在Kubernetes集群中部署了一个Kafka集群。我们将应用下面的文件（mysql-deployment.yaml）和application.properties中配置的参数部署MySQL实例。</p><p></p><p><code lang=\"plain\">apiVersion: v1\nkind: Service\nmetadata:\n name: mysql\n labels:\n   app: mysql\nspec:\n ports:\n   - port: 3306\n selector:\n   app: mysql\n clusterIP: None\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n name: mysql\n labels:\n   app: mysql\nspec:\n selector:\n   matchLabels:\n     app: mysql\n strategy:\n   type: Recreate\n template:\n   metadata:\n     labels:\n       app: mysql\n   spec:\n     containers:\n     - image: mysql:8.0.30\n       name: mysql\n       env:\n       - name: MYSQL_ROOT_PASSWORD\n         value: alex\n       - name: MYSQL_DATABASE\n         value: moviesdb\n       - name: MYSQL_USER\n         value: alex\n       - name: MYSQL_PASSWORD\n         value: alex\n       ports:\n       - containerPort: 3306\n         name: mysql\n</code></p><p></p><p>将MySQL实例部署到Kubernetes集群：</p><p></p><p><code lang=\"plain\">kubectl apply -f mysql-deployment.yaml -n kafka\n</code></p><p></p><p>最后要部署的是应用程序本身。我们有两个选择，第一个是直接应用资源：</p><p></p><p><code lang=\"plain\">kubectl apply -f target/kubernetes/kubernetes.yml -n kafka\n</code></p><p></p><p>第二个是将quarkus.kubernetes.deploy标志设置为true来打包应用程序。当这个标志设置为true时，Maven将：</p><p></p><p>创建应用程序JAR文件。构建容器镜像。将容器镜像推送到注册表中。自动应用kubernetes.yml资源文件到已连接的Kubernetes集群。为了验证所有的东西都能正确地运行，我们将发送一个插入新电影信息的请求，并验证在Kafka主题中插入的新事件。</p><p></p><p>在终端窗口中执行以下命令获取访问服务的IP和端口。</p><p></p><p>获取访问服务的IP：</p><p></p><p><code lang=\"plain\">minikube ip -p strimzi\n\n192.168.59.104\n</code></p><p></p><p>获取movie-plays-producer-debezium的公开端口，也就是第二个端口。</p><p></p><p><code lang=\"plain\">kubectl get services -n kafka\n\nmovie-plays-producer-debezium   LoadBalancer   10.100.117.203        80:30306/TCP                 67m\n</code></p><p></p><p>运行curl命令，插入一条新的电影信息记录。</p><p></p><p><code lang=\"plain\">curl -X 'POST' \\\n  'http://192.168.59.104:30306/movie' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"name\": \"Minions: The Rise of Gru\",\n  \"director\": \"Kyle Balda\",\n  \"genre\": \"Animation\"\n}'\n</code></p><p></p><p>检查Quarkus日志，查看数据库运行的SQL语句：</p><p></p><p><code lang=\"java\">kubectl get pods -n kafka\n\nNAME                                             READY   STATUS      RESTARTS   AGE\nmovie-plays-producer-debezium-56f644cb87-5cchk   1/1     Running     0          6m5s\nmy-cluster-entity-operator-755596449b-cw82g      3/3     Running     0          35h\nmy-cluster-kafka-0                               1/1     Running     0          35h\nmy-cluster-zookeeper-0                           1/1     Running     0          35h\n</code></p><p></p><p>打印movie-plays-producer-debezium的日志：</p><p></p><p><code lang=\"java\">kubectl logs movie-plays-producer-debezium-6b9b65bf4-9z524 -n kafka\n\n2022-08-11 07:44:25,658 INFO  [org.acm.MovieResource] (executor-thread-1) New Movie inserted Minions: The Rise of Gru\n:)\nHibernate:\n    select\n        next_val as id_val\n    from\n        hibernate_sequence for update\n\nHibernate:\n    update\n        hibernate_sequence\n    set\n        next_val= ?\n    where\n        next_val=?\nHibernate:\n    insert\n    into\n        Movie\n        (director, genre, name, id)\n    values\n        (?, ?, ?, ?)\nHibernate:\n    insert\n    into\n        OutboxEvent\n        (aggregatetype, aggregateid, type, timestamp, payload, tracingspancontext, id)\n    values\n        (?, ?, ?, ?, ?, ?, ?)\n\n# Debezium reacts to the change\n2022-08-11 07:44:25,867 INFO  [io.deb.con.com.BaseSourceTask] (executor-thread-0) 1 records sent during previous 00:20:44.297, last recorded offset: {transaction_id=null, ts_sec=1660203865, file=binlog.000002, pos=14795, row=1, server_id=1, event=4}\nMovie Created and Reacting\n</code></p><p></p><p>你还可以使用Kafka容器里的Kafka-console-consumer.sh脚本来检查Kafka中的内容。进入容器并运行下面的命令：</p><p></p><p><code lang=\"java\">kubectl exec -ti my-cluster-kafka-0 -n kafka /bin/bash\n\n./bin/kafka-console-consumer.sh --topic movies --from-beginning --bootstrap-server localhost:9092\n{\"id\":1,\"name\":\"Minions: The Rise of Gru\",\"director\":\"Kyle Balda\",\"genre\":\"Animation\"}\n</code></p><p></p><p>要返回本地终端窗口，请按Ctrl+C停止kafka-console-consumer进程，然后执行exit命令。</p><p></p><p>到目前为止，一切都很顺利。我们已经得到了与本系列文章第3部分中相同的应用程序，只是现在它运行在Kubernetes集群中。</p><p></p><p>到目前为止，我们使用的是Debezium Embedded，但其实我们可以使用Debezium Server。</p><p></p><h2>Debezium Server</h2><p></p><p></p><p><a href=\"https://debezium.io/documentation/reference/stable/operations/debezium-server.html\">Debezium Server</a>\"是一个可配置的、使用就绪的应用程序，它将事件从源数据库流到消息传递系统中，如Kafka。它可以被注册成一个<a href=\"https://kafka.apache.org/documentation/#connect\">Kafka Connect组件</a>\"，作为源连接器。</p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/strimzi-the-gitops-way/en/resources/15-1664224713829.jpeg\" /></p><p>虽然我们不能在所有的场景中都使用Debezium Server，但在我看来，使用这种方法有两个大的优点：</p><p></p><p>你可以获得Kafka连接器的所有好处（容错、可扩展、可重用等）。因为它是一个外部组件，所以不需要更改应用程序代码，也不需要Debezium Embedded相关的代码或依赖项。因此，任何应用程序都可以在不做出修改或重新部署的情况下开始使用Debezium。接下来，我们来看看如何从Debezium Embedded迁移到Debezium Server。</p><p></p><h4>移除Debezium Embedded</h4><p></p><p>首先要做的是删除Debezium Embedded相关的依赖项。</p><p></p><p>打开pom.xml文件，删除以下依赖项：</p><p></p><p><code lang=\"java\">\n     io.debezium\n     debezium-ddl-parser\n\n\n     io.debezium\n     debezium-embedded\n\n\n     io.debezium\n     debezium-connector-mysql\n\n</code></p><p></p><p>下一步是删除所有与Debezium Embedded配置和监听器相关的代码。删除这些类文件——DebeziumConfiguration.java、DebeziumListener.java和MySqlJdbcParser.java。</p><p></p><p>因为所有与Kafka的交互都是通过Kafka Connect组件进行的，不需要Kafka代码，所以最后一步是从pom.xml中移除以下依赖项：</p><p></p><p><code lang=\"go\">\n     io.quarkus\n     quarkus-smallrye-reactive-messaging-kafka\n\n</code></p><p></p><p>application.properties文件中的这一行不再需要：</p><p></p><p><code lang=\"java\">%prod.kafka.bootstrap.servers=my-cluster-kafka-bootstrap:9092\n</code></p><p></p><p>项目中已经没有了Kafka或Debezium Embedded依赖项。创建一个包含这些最新变更的容器镜像。</p><p></p><p>在终端窗口执行以下命令，删除之前的部署：</p><p></p><p><code lang=\"go\">kubectl delete deployment movie-plays-producer-debezium\nkubectl delete service movie-plays-producer-debezium\n</code></p><p></p><p>要保留带有Debezium Debezium的容器镜像，请将artifactId更改为movie-plays-producer-debezium-server。</p><p></p><p>然后将不带Debezium代码的新版本部署到Kubernetes集群中，如下所示：</p><p></p><p><code lang=\"plain\">./mvnw clean package -DskipTests -Dquarkus.kubernetes.deploy=true\n</code></p><p></p><p>运行以下命令验证新部署的服务：</p><p></p><p><code lang=\"java\">kubectl get pods -n kafkaa\n\nNAME                                                    READY   STATUS    RESTARTS   AGE\nmovie-plays-producer-debezium-server-59db564b74-vhdmf   1/1     Running   0          73m\n</code></p><p></p><h4>部署Debezium Kafka Connect</h4><p></p><p>首先，部署一个Kafka Connect组件与所需的MySQL连接器插件。你可以认为它跟我们在<a href=\"https://github.com/lordofthejars/movie-plays-kafka/blob/main/strimzi/movie-plays-producer-debezium/src/main/java/org/acme/DebeziumListener.java\">DebeziumListener</a>\"类中实现的逻辑差不多，只是被作为一个Kafka Connect元素，可以在项目中重用。我们必须为Kafka Connect和连接器插件创建一个容器镜像，因为Debezium没有为各种可能的Kafka与数据的组合提供“官方”镜像。对于本例，我们使用Kafka 3.2.0的MySQL连接器创建一个容器镜像。</p><p></p><p>本文中MySQL连接器的容器镜像可以在<a href=\"http://quay.io/lordofthejars/debezium-connector-mysql:1.9.4\">quay.io/lordofthejars/debezium-connector-mysql:1.9.4</a>\"找到，如果你对它的构建过程感到好奇，可以查看位于这个<a href=\"https://github.com/lordofthejars/movie-plays-kafka/blob/main/strimzi/Dockerfile\">GitHub</a>\"存储库中的Dockerfile文件。</p><p></p><p>为了部署Debezium Kafka Connect，我们将使用Strimzi提供的<a href=\"https://strimzi.io/docs/operators/latest/deploying.html#deploying-kafka-connect-str\">KafkaConnect</a>\"，因为它简化了整个过程。在这个Kubernetes资源文件中，我们指定了Kafka版本、Kafka集群的位置（my-cluster-kafka-bootstrap:9092）、容器镜像（quay.io/lordofthejars/debezin-connector-mysql:1.9.4），以及一些特定的配置参数。</p><p></p><p>创建一个名为debezium-kafka-connect.yaml的文件，内容如下：</p><p></p><p><code lang=\"java\">apiVersion: kafka.strimzi.io/v1beta2\nkind: KafkaConnect\nmetadata:\n name: debezium-connect-cluster\n annotations:\n   strimzi.io/use-connector-resources: \"true\"\nspec:\n version: 3.2.0\n image: quay.io/lordofthejars/debezium-connector-mysql:1.9.4\n replicas: 1\n bootstrapServers: my-cluster-kafka-bootstrap:9092\n config:\n   group.id: connect-cluster\n   key.converter: org.apache.kafka.connect.json.JsonConverter\n   value.converter: org.apache.kafka.connect.json.JsonConverter\n   key.converter.schemas.enable: false\n   value.converter.schemas.enable: false\n   offset.storage.topic: connect-offsets\n   offset.storage.replication.factor: 1\n   config.storage.topic: connect-configs\n   config.storage.replication.factor: 1\n   status.storage.topic: connect-status\n   status.storage.replication.factor: 1\n</code></p><p></p><p>然后在终端窗口中应用这个资源：</p><p></p><p><code lang=\"java\">kubectl apply -f debezium-kafka-connect.yaml -n kafka\n</code></p><p></p><p>并通过运行以下命令验证它是否被正确部署：</p><p></p><p><code lang=\"java\">kubectl get pods -n kafka\n\ndebezium-connect-cluster-connect-546c8695c-lszn7        1/1     Running   0          91m\n</code></p><p></p><p>请记住，这个过程可能需要几分钟的准备时间。</p><p></p><p>Kafka Connect组件现在连接到了Kafka集群，最后一步是通过配置让它监听MySQL实例的数据变更。</p><p></p><p>为此，我们将使用Strimzi提供的KafkaConnector。这有点类似于我们在DebeziumConfiguration类中所做的那样，提供database.hostname或table.include.list之类的参数。此外，我们还要将strimzi.io/cluster的值设置为上一个YAML文件中指定的KafkaConnect名称（debezum-connect-cluster）。</p><p></p><p>创建一个名为debezium-kafka-connector.yaml的文件，内容如下：</p><p></p><p><code lang=\"java\">apiVersion: kafka.strimzi.io/v1beta2\nkind: KafkaConnector\nmetadata:\n name: debezium-connector-mysql\n labels:\n   strimzi.io/cluster: debezium-connect-cluster\nspec:\n class: io.debezium.connector.mysql.MySqlConnector\n tasksMax: 1\n config:\n   tasks.max: 1\n   database.hostname: mysql\n   database.port: 3306\n   database.user: root\n   database.password: alex\n   database.server.id: 184054\n   database.server.name: mysql\n   database.include.list: moviesdb\n   database.allowPublicKeyRetrieval: true\n   table.include.list: moviesdb.OutboxEvent\n   database.history.kafka.bootstrap.servers: my-cluster-kafka-bootstrap:9092\n   database.history.kafka.topic: schema-changes.movies\n</code></p><p></p><p>通过应用资源来配置Debezium Connector：</p><p></p><p><code lang=\"plain\">kubectl apply -f debezium-kafka-connector.yaml -n kafka\n</code></p><p></p><p>为了验证一切工作正常，我们添加一条新的电影数据记录，并验证将新记录插入数据库时Kafka主题中会产生一个新事件。</p><p></p><p>获取新服务的端口，IP仍然是相同的：</p><p></p><p><code lang=\"java\">kubectl get services -n kafka\n\nmovie-plays-producer-debezium-server   LoadBalancer   10.100.117.203        80:30307/TCP                 67m\n\ncurl -X 'POST' \\\n  'http://192.168.59.104:30307/movie' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"name\": \"Minions: The Rise of Gru\",\n  \"director\": \"Kyle Balda\",\n  \"genre\": \"Animation\"\n}'\n</code></p><p></p><p>使用kafka-console-consumer.sh脚本验证插入的数据：</p><p></p><p><code lang=\"java\">kubectl exec -ti my-cluster-kafka-0 -n kafka /bin/bash\n</code></p><p></p><p>然后在容器中运行脚本。注意，Debezium连接器将事件发送到一个Kafka主题，名称是这样的..，在这个示例中是mysql.moviesdb.OutboxEvent。<p></p><p></p><p><code lang=\"java\">./bin/kafka-console-consumer.sh --topic mysql.moviesdb.OutboxEvent --from-beginning --bootstrap-server localhost:9092\n\n{\"before\":null,\"after\":{\"id\":\"Yxk0o5WwTvi0+nwBr2Y36wAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\",\"aggregatetype\":\"Movie\",\"aggregateid\":\"5\",\"type\":\"MovieCreated\",\"timestamp\":1660253420864918,\"payload\":\"{\\\"id\\\":5,\\\"name\\\":\\\"Minions: The Rise of Gru\\\",\\\"director\\\":\\\"Kyle Balda\\\",\\\"genre\\\":\\\"Animation\\\"}\",\"tracingspancontext\":null},\"source\":{\"version\":\"1.9.4.Final\",\"connector\":\"mysql\",\"name\":\"mysql\",\"ts_ms\":1660253420000,\"snapshot\":\"false\",\"db\":\"moviesdb\",\"sequence\":null,\"table\":\"OutboxEvent\",\"server_id\":1,\"gtid\":null,\"file\":\"binlog.000002\",\"pos\":8788,\"row\":0,\"thread\":41,\"query\":null},\"op\":\"c\",\"ts_ms\":1660253420878,\"transaction\":null}\n</code></p><p></p><p>before字段是空的，因为是插入操作，所以没有前值，但是在after字段中有电影信息数据。</p><p></p><h2>结论</h2><p></p><p></p><p>我们已经将应用程序从本地迁移到了Kubernetes集群中。</p><p></p><p>Strimzi为我们提供了在Kubernetes中部署和管理Apache Kafka集群的一个关键元素。我们可以使用Kubernetes资源文件安装和管理集群，采用GitOps的方式来管理Kafka。</p><p></p><p>Debezium Embedded适用于一些场景，比如在检测数据变更时使用的临时逻辑。不过，在其他项目中（特别是在遗留项目或需要高可伸缩性和容错性的项目），Debezium Server可能更合适。</p><p></p><p>有了Strimzi、Jib和Kubernetes Quarkus扩展，从本地转移到Kubernetes集群应该并不难。</p><p></p><p>本文的源代码可以在<a href=\"https://github.com/lordofthejars/movie-plays-kafka/tree/main/strimzi\">GitHub</a>\"上找到。</p><p></p><h2>作者简介</h2><p></p><p></p><p>Alex Soto是Red Hat的开发者体验总监。他对Java和软件自动化领域充满热情，并相信开源软件模型。Soto是《Testing Java Microservices》（Manning出版）和《Quarkus Cookbook》（O'Reilly出版）的合著者，也是多个开源项目的贡献者。自2017年以来，他获得Java Champion的称号，也是Salle URL大学的国际演讲师和教师。你可以在Twitter上关注他（Alex Soto），继续关注Kubernetes和Java世界的动态。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/strimzi-the-gitops-way/\">https://www.infoq.com/articles/strimzi-the-gitops-way/</a>\"</p><p></p><p>相关阅读：</p><p>本系列第一部分：<a href=\"https://www.infoq.cn/article/cFpvXRLmZzJBGbzAeFu5\">使用 Apache Kafka 实现 Quarkus 的反应式消息</a>\"</p><p>本系列第二部分：<a href=\"https://www.infoq.cn/article/WfA0p1XoZCJ6INdyJLyv\">Kafka Streams 与 Quarkus：实时处理事件</a>\"</p><p>本系列第三部分：<a href=\"https://www.infoq.cn/article/V4kqPgrQlqqPgWQuMmDP\">Debezium 和 Quarkus：通过 CDC 模式来避免双重写入</a>\"</p><table></table></p>",
    "publish_time": "2022-10-12 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]