[
  {
    "title": "架构师（2023 年 12 月）",
    "url": "https://www.infoq.cn/article/Pu0szgrG5sJuOl8AV2tr",
    "summary": "<h2>卷首语：俭约架构师的七大黄金法则</h2>\n<p>亚马逊 CTO Werner Vogels 向企业传达了一条信息：在管理云成本方面，是时候成为节俭的架构师了。</p>\n<p>他拥有近 20 年的平台构建经验，在今天的 re:Invent 2023 大会主题演讲中，给大家上了一节关于成本优化的课：“作为技术专家，我们生活在一个瞬息万变的世界，我们需要保持学习，坐下来，拿出你的记事本，现在开始做笔记。”</p>\n<p><strong>法则一：将成本视为一种非功能性需求。</strong><br />\n架构师需要尽可能早的、以更加可持续的方式考虑成本影响，才能在系统设计过程中在功能、上市时间和效率之间寻求平衡。</p>\n<p><strong>法则二：确保系统的最终成本与业务保持一致。</strong><br />\n系统能否长治久安，取决于其成本是否与业务模式高度匹配。在设计和构建系统时，架构师必须考虑收入来源和利润杠杆。更重要的是，必须找到能够产生利润的维度，确保架构规划始终围绕收益展开。</p>\n<p><strong>法则三：架构设计是一系列权衡的集合。</strong><br />\n在架构当中，每项决定都涉及相应的权衡。在技术与业务需求间找到适当的平衡将至关重要。请记住，节俭是为了最大限度提升价值，而不只是尽可能控制支出。因此，在必须得花的钱上别吝啬。</p>\n<p><strong>法则四：无法观察的系统将带来无法估量的成本。</strong><br />\n尽管实现可观察性需要投入，但这笔钱绝对会物有所值。有句格言说“如果无法量化，也就无法管理。持续检查能帮我们发现非必要支出，并调整运营以减少浪费。总之，可观察性带来的回报往往远超过前期投入。</p>\n<p><strong>法则五：依托成本感知架构实现成本控制。</strong><br />\n节俭架构的本质，在于强大监控与成本优化能力的结合。明确定义各层，即可在成本及其他要求之间求得平衡。对组件的精细控制则能优化成本和体验。</p>\n<p><strong>法则六：成本优化是个渐进的过程。</strong><br />\n追求成本效率是个持续的过程。即使在部署之后，我们也必须随时审视系统以逐步寻求优化。看似微小的优化，累积起来足以产生超出想象的成本优势。</p>\n<p><strong>法则七：顺风局打多了会让人盲目自信。</strong><br />\n软件团队经常陷入这样的陷阱：仅凭以往的工作经验，他们就认为当前的技术、架构或语言永远是最佳选择。这可能会产生一种错误的安全感，阻碍对现状的质疑，更会打击对可能更加高效、更具成本效益或可扩展性更强的新选项的探索。</p>\n<h2>目录</h2>\n<p><strong>热点 | Hot</strong></p>\n<p>全球首款经安全认证的开源实时操作系统！开发了 20 多年、部署在超 120 亿台设备上的 ThreadX 正式开源</p>\n<p>省钱在于“架构师”！亚马逊 CTO 20 年架构经验之道：俭约架构师的七大黄金法则</p>\n<p>联手 OpenAI 最强竞对展开生成式 AI 反击战：亚马逊云科技将 S3 写入速度提升 10 倍、推出全新三层技术栈</p>\n<p>疯狂马斯克的“极限”计划居然成功了？！“下云”后成本降低 60%，部分功能代码精简 90%，30 天急速迁移服务器</p>\n<p>微软发布开源平台 Radius：高效构建、运行云原生应用程序</p>\n<p><strong>访谈文章 | Interview</strong></p>\n<p>主力开发已经 68 岁了！“老龄化”严重的 Postgres 开源社区呼唤“年轻一代”</p>\n<p>美图的这 100 天：三月三版本，大模型博弈中谁能笑到最后？</p>\n<p>是时候基于云重新设计 Kafka 了！AutoMQ 如何实现 Kafka 十倍的降本增效</p>\n<p><strong>案例研究 | Case Study</strong></p>\n<p>一个失败的 AI 女友产品，以及我的教训：来自一位中国开发者的总结</p>\n<p>从 ES 到 Clickhouse：信息技术发展的新浪潮</p>\n<p>GitHub 基于大语言模型构建 Copilot 的经验和教训</p>\n<p><strong>推荐文章 | Article</strong></p>\n<p>从谷歌 20 年站点可靠性工程（SRE）中学到的 11 个经验教训</p>\n<p>无服务计算，厂商究竟在打什么算盘</p>\n<p>我，技术不过硬，但是团队里的重要“胶水”</p>\n<p>是时候彻底放弃“高分低能”的 Leetcode 了：AI 时代的面试需要大变革！</p>\n<p>Docker 的诅咒：曾以为它是终极解法，最后却是“罪大恶极”？</p>\n<p><strong>特别专题｜我们需要纯向量数据库吗</strong></p>\n<p>数据库内核杂谈：向量数据库（一）</p>\n<p>数据库内核杂谈： 向量数据库（二）</p>\n<p>数据库内核杂谈：向量数据库（三）</p>\n<p>数据库内核杂谈： 向量数据库（四）</p>\n<p>向量数据库？不要投资！不要投资！不要投资！</p>\n<p>AutoGPT 放弃向量数据库！向量数据库是小题大作的方案？</p>\n<p>向量数据库失宠了？OpenAI 力捧检索增强生成（RAG）技术，对行业来说意味着什么？</p>\n<p><strong>特别专栏 | 视频推荐</strong></p>\n<p>欢迎阅读 InfoQ 架构师电子刊！每个月，我们都会为你带来行业同行关于新兴技术和模式的重要新闻及经验。</p>\n<p>本月，我们聚焦“AI Agent”这一话题。</p>",
    "publish_time": "2023-12-08 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Web ML 库 Transformers.js 提供文本转语音功能",
    "url": "https://www.infoq.cn/article/N1vpady26bKq23GOZNqQ",
    "summary": "<p>JavaScript 库 Transformers.js 提供了类似 Python Transformers 库的功能，设计用于在 Web 浏览器中直接运行 Transformer 模型，而不再需要外部服务器参与处理。在最新的 2.7 版本中，Transformers.js 引入了增强功能，其中包括文本转语音（TTS）支持。这次升级响应了用户的诸多需求，扩展了库的应用场景。</p><p></p><p>文本转语音（TTS）包括从文本创建听起来比较自然的语音，并提供了多种口语语言和 speaker。目前，Transformers.js 只通过 Xenova/speecht5_tts 提供 TTS 支持，而 Xenova/speecht5_tts 基于微软提供的带有 ONNX 权重的 SpeechT5。未来更新计划中包括增加对 bark 和 MMS 的支持。</p><p></p><p>开发人员可以通过 @xenova/transformers 中的管道函数来使用文本转语音功能，包括指定“文本转语音”任务和要使用的模型（'Xenova/ speecht5_ts '），并使用选项{quantized: false}。此外，其中还包含提供 speaker embeddings 的文件链接。</p><p></p><p>将 TTS 模型应用于给定的文本后，它就会输出音频数组和采样率。该数组表示合成语音，可以进一步处理或直接在浏览器中播放。</p><p></p><p>Transformers.js 适用于各种用例，包括风格转换、图像绘制、图像着色和超分辨率。它的多功能性和定期更新使其成为开发人员探索机器学习和 Web 开发结合点的宝贵资产，并使其成为 Web 机器学习领域的可靠工具。</p><p></p><p>按照设计，Transformers.js 在功能上等同于 Hugging Face 的 Python 库 transformers，也就是说，你可以使用非常近似的 API 运行相同的预训练模型。</p><p></p><p>Transformers.js 支持许多任务和模型，涉及自然语言处理、视觉、音频、表格数据、多模态应用和强化学习。该库涵盖了从文本分类和摘要到图像分割和对象检测的各种任务，这使其成为各种机器学习应用程序的通用工具。</p><p></p><p>Transformers.js 提供了广泛的模型支持，包括 BERT、GPT-2、T5 和 Vision Transformer（ViT）等架构，确保用户可以针对特定的任务选择正确的模型。</p><p></p><p>对于 Transformers.js 的发布，社区持积极态度。在今年早些时候发起的 <a href=\"https://www.reddit.com/r/LocalLLaMA/comments/14w0p1p/transformersjs_thoughts/\">Reddit 帖子</a>\"中，用户 Intrepid-Air6525 表示：我决定用它来代替 openai 的嵌入模型。速度非常快。我实际使用的 LLM 是 webLLM ，因为我不想消耗太多的 CPU 处理。</p><p></p><p>用户 1EvilSexyGenius 对 Hugging Face 的市场定位以及关于实际应用的讨论发表了看法：</p><p></p><p></p><blockquote>[…] 借助 Transformers.js 及他们提供的其他优秀的库，很显然， [Hugging Face] 正在努力实现语言模型的民主化，并将它们带给大众。与每天发布的所有模型相比，这样的帖子会让这个社区受益匪浅。</blockquote><p></p><p></p><p>感兴趣的读者可以从 <a href=\"https://huggingface.co/docs/transformers.js/index\">Hugging Face Transformers.js</a>\" 官方网站及其 GitHub 库中获得更多信息。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/11/transformersjs-ml-for-web/\">https://www.infoq.com/news/2023/11/transformersjs-ml-for-web/</a>\"</p><p></p><p></p><p></p><p></p><p></p><p></p>",
    "publish_time": "2023-12-08 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Timescale 推出无服务器数据库的替代方案Dynamic PostgreSQL",
    "url": "https://www.infoq.cn/article/BX5Ee69dLu5UpMBfAPzx",
    "summary": "<p>Timescale 最近推出了 <a href=\"https://www.timescale.com/blog/introducing-dynamic-postgresql/\">Dynamic PostgreSQL</a>\"，这是一种新的云托管选项，可在预定义的 vCPU 范围内扩展数据库容量。这个新选项的宣传亮点是“购买基础容量，峰值需求靠租用解决”，它可以根据负载变化来扩展容量，试图以这种方式解决无服务器产品的不可预测性和可变性问题。</p><p>&nbsp;</p><p>Dynamic PostgreSQL 基于 <a href=\"https://github.com/timescale/timescaledb\">TimescaleDB</a>\"（扩展 PostgreSQL 的一款开源时间序列数据库），希望在预置数据库和无服务器数据库之外提供第三种方案。Timescale 首席技术官兼联合创始人 Mike Freedman 和 Timescale 高级产品经理 Grant Godeke 解释道：</p><p>&nbsp;</p><p></p><blockquote>它基于动态计算技术，这是一项 Timescale 开发的创新，可根据你的负载情况在预定义的最小/最大范围内实时扩展你的可用计算资源。你现在可以选择一个计算范围，不用再针对峰值需求配置资源（并一直为这些资源付费）：你的数据库启动时会使用基础的容量，并且仅在需求上涨时实时扩展到峰值容量。买基础，租峰值。</blockquote><p></p><p>&nbsp;</p><p>当客户选择一个范围时，动态最大值的上限为基本容量的两倍。 Timescale 认为，数据库与 Lambda 函数有很大不同，如今的无服务器数据库对于大多数生产负载来说效率是很差的，因为它们只盯着缩放的极端情况，并且为了服务不断变化的需求而保留的那些资源还使用了费用高昂且难以理解的定价机制。 Ampt 首席执行官兼创始人 Jeremy Daly 写道：</p><p>&nbsp;</p><p></p><blockquote>这里的区别（我认为）是他们将其定位为“买基础，租峰值”。我很久以前就开始这么呼吁了，云服务商的无服务器服务定价机制一直缺这么一块，他们应该跟上脚步。</blockquote><p></p><p>&nbsp;</p><p>数据库顾问 Tobias Petry 评论说：</p><p>&nbsp;</p><p></p><blockquote>它就像是支持突发机制的 EC2 机器一样，这是一个完美的解决方案：基础定价的成本低廉，你只需在极少数情况下为临时增加的需求支付更多费用。有了它，团队就用不着像往常那样买过大的实例了。</blockquote><p></p><p>&nbsp;</p><p>无服务器数据库的好处之一是能够将容量缩到零，只需为所使用的计算时间付费。Freedman 和 Godeke 认为：</p><p>&nbsp;</p><p></p><blockquote>在某些用例中，“缩放到零”是有意义的，比如说概念验证演示或更偏业余爱好者的应用程序（……）但如果跑的是你的生产数据库和更接近运营层面的东西？你肯定不想要缩到零。缩放到零意味着重新启动时要“冷启动”：数据库共享缓冲区清空了、操作系统缓存清空了、目录缓存也清空了。</blockquote><p></p><p>&nbsp;</p><p>Dynamic PostgreSQL 主要针对在 AWS 上运行的部署，声称客户从 RDS for PostgreSQL 迁移过来时会节省 10-20% 的成本，从 Aurora Serverless 迁移过来时可节省 50-70%，但他们尚未发布基准测试。</p><p>&nbsp;</p><p>Dynamic PostgreSQL 并不是 Dynamic Infra 发布周期间的唯一亮点：<a href=\"https://www.timescale.com/blog/create-timescale-services-with-terraform-provider/\">Terraform provider</a>\" 已全面可用，<a href=\"https://www.timescale.com/blog/timescale-x-cloudflare-time-series-from-the-edge/\">Cloudflare Hyperdrive</a>\" 增加了超级表支持，Timescale 云现已在澳大利亚、欧洲、美国和亚洲的 7 个 AWS 区域推出。</p><p>&nbsp;</p><p>1-2 个 CPU 范围的每月定价为 87.60 美元起，如果使用量高于承诺的基础容量，则每个 CPU 每小时额外收取 0.12 美元。 Timescale 为新帐户提供 30 天免费试用。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/11/timescale-dynamic-postgresql/\">https://www.infoq.com/news/2023/11/timescale-dynamic-postgresql/</a>\"</p>",
    "publish_time": "2023-12-08 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "刚发布就被质疑？超过GPT-4的“最强”大模型Gemini、“最高效”训练加速器，谷歌到底行不行",
    "url": "https://www.infoq.cn/article/Xcu7VoHdktaHGrbvbEcu",
    "summary": "<p>当地时间12 月 6 日，谷歌发布了自己“迄今为止功能最强、通用性最高”的AI模型Gemini。</p><p></p><p>谷歌及Alphabet&nbsp;CEO桑达尔·皮查伊 (Sundar&nbsp;Pichai)表示，首个Gemini 1.0针对不同规模进行优化，具体分为Ultra、Pro和Nano三个版本。“这是Gemini时代的首批模型，也是我们今年早些时候重组Google DeepMind时所表达愿景的首个实现。此模型代表着谷歌作为一家企业，在AI新时代下所做出的最重要的科学与工程努力之一。”</p><p></p><p>但刚发布不久，科技专栏作家Parmy Olson 指出，其中一个AI实时对人类的涂鸦和手势动作给出评论和吐槽的视频被曝出“不是实时或以语音方式进行的”。还有<a href=\"https://twitter.com/noguestein/status/1732927393466040617\">网友吐槽</a>\"整个互动过程“特别慢，跟演示视频完全不同。”</p><p></p><p>这个视频主要是演示“多模态提示”（multimodal prompting），即为大模型提供不同模式的组合（在本例中为图像和文本），并让其通过预测接下来会发生什么来做出反应。</p><p></p><p></p><p>对此，Google DeepMind 研究与深度学习主管副总裁 <a href=\"https://twitter.com/OriolVinyalsML/status/1732885990291775553\">Oriol Vinyals</a>\"表示，“视频中的所有用户提示和输出都是真实的，只是为简洁起见进行了缩短剪辑。”但网友对此并不买账，认为谷歌在玩营销手段，误导大家。</p><p></p><p>在谷歌发布的<a href=\"https://developers.googleblog.com/2023/12/how-its-made-gemini-multimodal-prompting.html?m=1\">一篇文章</a>\"里，详细介绍了效果实现经过，可以看出是使用静态图片和多段提示词拼凑训练。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/87/879c43b3919928ef014c63fd299e9cbb.png\" /></p><p></p><p></p><h2>看看谷歌的测试</h2><p></p><p></p><p>Gemini 被称为谷歌迄今为止最灵活的模型，能够从数据中心到移动设备实现高效运行，帮助开发人员与企业客户显著增强在利用AI进行构建和扩展时的操作方式。谷歌针对三种不同体量优化了Gemini 1.0（首个正式模型版本），分别为：</p><p></p><p>Gemini Ultra&nbsp;— 最大、功能最强的模型，适用于高度复杂的任务。Gemini Pro&nbsp;— 可处理各种任务类型的最佳模型。Gemini Nano&nbsp;— 能够在多种设备上高效运行的任务处理模型。</p><p></p><p>值得注意是，本次尚未发布最强大的Gemini Ultra，距离正式发布还需要几个月的时间。目前Gemini Ultra正在进行全面的信任与安全检查，包括由受信的外部合作方进行红队审查，并在广泛应用前通过微调和基于人类反馈的强化学习（RLHF）对其做进一步完善。</p><p></p><p>Gemini Pro和Gemini Nano已分别集成到了聊天机器人Bard和智能手机Pixel 8 Pro上。此外，自12月13日开始，开发者和企业客户都可通过Google AI Studio或者Google Cloud Vertex AI中的Gemini API访问Gemini Pro模型。在未来几个月间，Gemini将逐步登陆谷歌更多产品及服务，包括搜索、广告、Chrome浏览器以及Duet AI等。</p><p></p><p>谷歌说得很厉害，那Gemini 1.0 的实力到底如何？</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/9677686c03434f3f8237cd371682bc06.png\" /></p><p>﻿</p><p>根据谷歌测试结果，从自然图像、音频和视频理解再到数学推理，在大语言模型（LLM）研发领域的32种常见学术基准测试中，Gemini Ultra的性能一举创下30项最佳新纪录。</p><p></p><p>在MMLU（大规模多任务语言理解）中Gemini Ultar的得分高达90.0%，成为首个超越人类专家的模型。这项测试结合了数学、物理、历史、法律、医学和伦理学等57个科目，旨在测试AI模型掌握知识和解决问题的能力。</p><p></p><p>Gemini在文本和编码等一系列基准测试中表现超过GPT-4：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/69/691456eef49288cbb54143ec862c3dc2.png\" /></p><p></p><p>Gemini Ultra还在新的MMMU基准测试中取得了59.4%的最高得分。这项基准测试涵盖跨越不同领域、需要深思熟虑的一系列多模态推理任务。</p><p></p><p>根据谷歌测得的图像基准，Gemini Ultra的性能优于以往最先进的模型，且无需借助从图像中提取文本以供进一步处理的对象字符识别（OCR）系统的辅助。谷歌表示，这些测试结果凸显出Gemini的天然多模态优势，也证明Gemini已经表现出具备复杂推理能力的早期特征。</p><p></p><p>Gemini在一系列多模态基准测试中均创下性能新纪录，全面超越GPT-4V：</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ea/eabc1941f73a277dcac4574c7de7d681.png\" /></p><p></p><h2>多模态推理能力</h2><p></p><p></p><p>到目前为止，创建多模态模型的标准方法主要是针对不同模态训练单独的组件，再将其组合起来以粗略模仿相应能力。由此实现的模型虽然比较擅长执行某些特定任务，例如描述图像内容，但却难以处理概念性更强、复杂度更高的推理任务。</p><p></p><p>在Gemini的起始阶段就将其定位为原生多模态形式，针对不同模态开展预训练。之后，谷歌又使用额外的多模态数据对其进行微调，希望进一步完善其有效性。现在，Gemini可以同时识别和理解文本、图像、音频、视频和代码五种信息。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ab/abb5095053fbb457004d5057561f4555.png\" /></p><p></p><h4>理解文本、图像、音频等各种素材</h4><p></p><p></p><p>Gemini 1.0拥有精妙的多模态推理能力，可以帮助理解复杂的书面与视觉信息，展现出了在大量数据中提取重要知识的独特能力。比如，Gemini 在阅读、过滤和理解信息的过程中，可以从数十万份文档中提取见解并进行分析。</p><p></p><p>Gemini 1.0在训练之后，能够同时识别并理解文本、图像、音频等各种素材，因此可以把握住更加微妙的信息，并回答与复杂主题相关的更多问题。这使得它特别擅长解释数学、物理等复杂学科的推理过程。</p><p></p><p>比如，Gemini 可以识别学生的手写物理题答案，并验证正确性：</p><p>﻿</p><p><img src=\"https://static001.geekbang.org/infoq/09/0993347ceccee6452d2a0f3248905fd5.png\" /></p><p></p><p>基于视觉线索进行推理：</p><p>﻿</p><p><img src=\"https://static001.geekbang.org/infoq/91/9122b89b1f3140bc6e1a323e529acd5a.png\" /></p><p></p><p>音频方面，可以看下Google DeepMind 研究科学家 Adrià Recasens Continente 演示 Gemini 能够理解来自多个扬声器的不同语言的音频，并结合视觉、音频和文本，在厨房做饭时提供帮助的场景：</p><p></p><p></p><p></p><h4>高级编码能力</h4><p></p><p></p><p>谷歌介绍，首个Gemini正式版能够理解、解释并生成基于目前各种流行编程语言（例如Python、Java、C++和GO）的高质量代码。其表现出的跨语言工作和复杂信息推理能力，也使得Gemini成为世界领先的编码基础模型之一。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/62/62fd21473ee722a5f3eb12414a0ad27d.png\" /></p><p></p><p>Gemini&nbsp;&nbsp;的多模式推理功能生成用于重新排列子图的matplotlib代码</p><p></p><p></p><p>Gemini Ultra在多项编码基准测试中表现出色，包括HumanEval（用于评估编码任务性能的重要行业标准）和 Natural2Code（谷歌内部保留的数据集），此数据集使用作者专门创作的源素材、而非来自网络的信息。</p><p></p><p>Gemini还能作为更高级编码系统的引擎。谷歌两年之前发布了ALphaCode，这也是首个在编程竞赛中表现出一定竞争力的AI代码生态系统。使用Gemini的专用版本，谷歌推出更加先进的代码生成系统AlphaCode 2。除了编码场景之外，它还擅长解决涉及复杂数学和理论计算科学的更多编程难题。</p><p><img src=\"https://static001.geekbang.org/infoq/10/108a0fe125a7ab615f9e83a23e82c6e7.png\" /></p><p></p><p>面对与初代AlphaCode相同的评估场景，AlphaCode 2表现出巨大的性能改进，其解决的问题数量几乎达到初版的两倍，谷歌估计其成绩优于85%的竞赛参与者，而AlphaCode成功解决问题的比例只接近50%。因此当程序员通过代码示例来定义某些属性，并借此向AlphaCode 2寻求帮助时，其表现会更好。</p><p></p><p></p><h2>“专为训练顶尖AI模型而生”的TPU系统</h2><p></p><p></p><p>在介绍自家大模型的同时，谷歌顺势推出了了自己的AI训练基础设施。</p><p></p><p>谷歌使用内部设计的张量处理单元（TPU）v4和v5e在AI优化的基础设施之上，完成了Gemini 1.0的大规模训练任务。</p><p></p><p>在TPU上，Gemini的运行速度明显快于其他更早、更小且功能较差的模型。这些定制设计的AI加速器一直是谷歌AI产品的核心，负责为搜索、YouTube、Gmail、谷歌地图、Google Play和Android等服务的数十亿用户提供支持。它们也使得世界各地的其他企业也能经济高效地训练出自己的大规模AI模型。</p><p></p><p>如今，谷歌宣布推出迄今为止“最强大、最高效且可扩展”的TPU系统Cloud TPU v5p，专为训练顶尖AI模型而生。谷歌表示，作为下一代TPU，它将加速Gemini开发，帮助开发者和企业客户快速训练大规模生成式AI模型，将新产品和新功能更快交付至客户手中。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ee/ee5fb38056fa5ac7026cfc835d0eb72a.png\" /></p><p></p><p>谷歌数据中心内的Cloud TPU v5p AI加速器超级计算机</p><p></p><p>此外，在安全问题上，谷歌表示，Gemini拥有迄今为止所有谷歌AI模型当中最全面的安全评估机制，包括偏见与有毒内容检测。谷歌还对网络攻击、说服与自主判断等潜在风险领域开展了新颖研究，并应用谷歌研究院领先的对抗性测试技术抢在部署之前帮助发现Gemini中的重大安全隐患。</p><p></p><p>为了诊断Gemini训练阶段的内容安全问题，并确保其输出结果符合政策，谷歌使用诸如真实毒性提示词Real Toxicity Prompts在内的多种基准。这是一组从网络提取的、包含不同程度毒性内容的10万条提示词，由艾伦AI研究所的专家们提供。为了限制伤害，谷歌还构建了专门的安全分类器，用以识别、标记并整理涉及暴力或负面刻板印象的内容。</p><p></p><p>附 Sundar&nbsp;Pichai 公开信内容：</p><p>&nbsp;</p><p></p><blockquote>每一次技术变革都代表着推动科学发现、加速人类进步和改善生活品质的机遇。我相信我们现在所见证的AI转变，将成为我们一生当中最具深远意义的事件，甚至远远超越之前的移动或者Web革命。AI有望为全球各地的人们创造前所未有的日常生活体验和非凡的职业发展空间，将掀起新一波的创新与经济进步，并以前所未见的规模提升知识、学习、创造力与生产力。&nbsp;这也让我感到兴奋，期待通过AI技术为各国各地的每一个人提供帮助。&nbsp;作为一家AI优先的厂商，我们已经走过近八年历程，而前进的步伐只会不断加快：数百万用户正在我们的产品中运用生成式AI完成一年之前还难以想象的工作，包括为更加复杂的问题寻求答案、使用新工具协作与创新等等。与此同时，开发人员也在使用我们的模型与基础设施构建出新的生成式AI应用程序，世界各地的初创企业和组织正利用我们的AI工具不断拓展业务。&nbsp;这是一股令人难以置信的发展态势，而且我们才刚刚开始触及这无限可能性的最表层。我们正以大胆且负责任的态度开展这项工作。这意味着我们既需要追求雄心勃勃、能够为人类和全社会带来巨大收益的技术成果，同时也要建立保障措施并与政府和专家合作，应对AI发展过程中带来的种种风险。我们将继续投资打造更好的工具、基础模型和底层设施，并在我们AI原则的指导下将其引入自己的产品及其他方案当中。</blockquote><p></p><p></p><p></p><p>相关链接：</p><p><a href=\"https://blog.google/technology/ai/google-gemini-ai/#availability\">https://blog.google/technology/ai/google-gemini-ai/#availability</a>\"</p><p><a href=\"https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf\">https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf</a>\"</p>",
    "publish_time": "2023-12-08 10:04:59",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "稳定性出了大问题，是降本增效的锅？",
    "url": "https://www.infoq.cn/article/kOUdqdgpOBo3NPu2gQOE",
    "summary": "<p>稳定性出了大问题，是降本增效的锅？恰逢 QCon 中国 15 周年之际，InfoQ 技术大会早班车栏目邀请到 3 位 QCon 往届嘉宾，云器科技 CTO 关涛、趣丸科技技术保障部负责⼈刘亚丹 、贝联珠贯合伙人王元良，于 12 月 5 日 20:00-21:30 直播剖析灵魂三问：</p>\n<ol>\n<li>怎么算清成本账？</li>\n<li>IT 部门是成本中心还是价值中心？</li>\n<li>稳定性问题，谁是第一责任人？</li>\n</ol>",
    "publish_time": "2023-12-08 10:10:45",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "实现“数据资产当日达”，国泰君安证券做数据平台的逻辑与实践",
    "url": "https://www.infoq.cn/article/FK7BvgSk0p340NFjN6rZ",
    "summary": "<p>金融业务和数据的深度融合，不仅仅是数字化转型的一次技术升级，更是为了更好地响应用户需求，实现用户服务体验的全面提升。在国泰君安，数据治理不再是一个抽象的名词，而是通过切实行动融入到业务价值链的各个环节。</p><p></p><p>在日前举办的<a href=\"https://www.infoq.cn/article/BNiefsWtdjeQmreGkaUI?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">FCon 大会</a>\"期间，国泰君安证券数据平台运营部副总经理<a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5624?utm_source=infoqweb&amp;utm_medium=article\">苑博</a>\"接受 InfoQ 采访，分享了国泰君安证券数字化转型和数据平台运营方面的实践经验。</p><p></p><p>在苑博看来，数据团队的使命是“让公司没有难用的数据”。如果业务部门的人在使用数据时遇到困难，拿不到需要的数据，甚至对数据的应用一头雾水，那么企业整体数字化转型的效果将大打折扣。其次，要让业务部门内的数据使用者感到有成就感，这不仅仅是技术层面的问题，更涉及到整个数据服务链的打通。</p><p></p><p>从“数据资产当日达”到“数据空间”，苑博所在的团队一直在推行内部实现“全民用数”，并采取了“1+N+X”数据人才能力提升的创新模式，以打造“有数、用数、治数”的良性循环。</p><p></p><p>以下是对话全文（经 InfoQ 进行不改变原意的编辑整理）：</p><p></p><p></p><h2>证券行业数字化转型的背景和挑战</h2><p></p><p></p><p>InfoQ：结合整个<a href=\"https://www.infoq.cn/article/TkHfwhl8xwNjmzmPbFqu?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">证券行业</a>\"现状来看，现在推动数字化转型的背景和最大的挑战在哪里？</p><p></p><p>苑博：我认为主要存在两个方面的挑战。首先，在组织意识方面面临比较大的挑战，数字化转型的最大特点是科技与业务的深度融合，转型首先要转意识，业务负责人需认识到数字化转型的意义，并主动参与到数字化转型的全过程中。</p><p></p><p>这与过去建设系统的方式有很大不同，以前业务领导不必过多操心系统建设，但在数字化转型的进程下，业务领导需要更多地参与牵头协调，包括流程设置、权责划分，平台愿景和使命的制定，这要求业务领导更深度地参与。因此，数字化转型特别需要关注组织意识和领导能力的提升，这也是数字化转型与以往的数字化和信息化工作有所不同的地方。</p><p></p><p>其次，行业整体的趋势也构成了数字化转型的挑战。近年来，整个证券行业头部化的趋势日益明显，同时监管力度逐渐增加。在受到强监管和降费的双重压力下，数字化转型的挑战在于如何提升公司的整体运营效率。</p><p></p><p>因此，我认为数字化转型当前所面临的挑战之一是在不同业务模式中找到提升效率、提升用户体验和确保安全的通用路径。这一路径并非特定于某一业务模式，而更注重公司整体的运营能力。目前，行业里比较热的话题是机构客户服务，那么面向 B 端市场时，必须应对处理周期长、见效慢、个性化要求高等多重挑战。</p><p></p><p>InfoQ：该怎么去应对这些挑战？有哪些策略？</p><p></p><p>苑博：我觉得可以从几个方面看。首先，从意识层面来看，数字化转型是“科业融合”的事情，需要着重解决科技和业务融合的问题。其关键点和落脚点可能还是在于组织能力、流程、以及效率的提升。这是一项需要“练内功”的工作。</p><p></p><p>其次，虽然公司已经认同数字化转型的重要性，并愿意为此投入资金和资源，但科技部门可能还需要更主动地走多一步，积极推动这项工作。</p><p></p><p>总的来说，数字化转型要求业务领导需要思考战略布局，而科技部门则需要更主动地投入并推动这一进程，要有换位思考、全局意识和服务意识。在这一层面上，需要双方共同努力。</p><p></p><p>InfoQ：在数字化的投入产出比这方面，目前会有哪些明确的要求吗？</p><p></p><p>苑博：在评估投入产出比时，业务和科技视角可能涉及不同的考量。从科技角度来看，我们关注一些关键指标，比如创新业务的首批上线率。举例来说，在新业务推出时，我们关注的是能否迅速上线，抢占市场先机，这反映了我们的自主研发能力。特别是在应对监管政策调整时，我们需要进行业务、流程和系统的改造等等。这时候，能否在行业首批上线新业务就展现了我们的自主研发水平。</p><p></p><p>科技方面还有其他维度，如技术领先性，包括交易速度、系统吞吐量等关键指标。此外，我们还关注是否参与行业标准的建设，以及获得行业奖项和评级等方面的成就。</p><p></p><p>从业务视角来看，关键在于效率。当我们所谓的能力达到市场领先地位时，整体运营效率、开发和交付效率，以及数据获取的效率等指标是否达到预期，都是值得密切关注的要素。</p><p></p><p></p><h2>数据平台建设和价值</h2><p></p><p></p><p>InfoQ：数据是驱动企业数字化转型核心要素，国泰君安在强化数据能力方面有哪些部署和创新？</p><p></p><p>苑博：我们在强化数据能力方面，主要着眼于有数、用数和治数三个方面，通过平台化能力的提升，将更好地支持数据的应用和整体逻辑的实现。</p><p></p><p>在“用数”方面，我们目前是希望平台的用户越来越多、平台服务效率越来越高，并得到用户好评。</p><p></p><p>所以这里的“用”有两个要点，第一点是数据平台在集团内部的用户渗透率，在过去三年里，这一比例呈现稳定的增长趋势，每年平均增长率约为 10%。我们预计今年可以实现 70% 左右的使用率。第二点，数据平台的服务目标是让所有员工都能够充分利用数据平台所提供的服务。为此，我们需要积极开展运营工作，因此打造了能够为数据人才提供全面培训和发展的“1+N+X”的运营体系：</p><p></p><p></p><blockquote>1：一个统一的智慧化数据中台N：培养 N 个集团数据分析核心用户，通过线上 + 线下的方式，培养数据人才X：吸引 X 个数据产品用户，通过经营管理驾驶舱、智能报表、经营指标卡、企业画像、数据学堂等产品打造全方位数据产品矩阵，吸引更多集团用户参与到数据价值的挖掘中来</blockquote><p></p><p></p><p>“1+N+X ”相当于我们强化数据能力的抓手和触手，一方面，它能够收集问题；另一方面，它能够将数据服务普及开来。因此，我们的平台是开放的，平台并非为用户直接呈现最终结果，而是让用户能够在这之上自主开发报表、进行数据分析，找到问题的解决方案。</p><p></p><p>“治数”方面，数据治理是一项高度专业且体系化的任务，同时也是非常务实的工作。其主要目标是解决问题并确保数据质量。以“1+N+X”为触点，将从一线收集到的问题整理成数据治理的问题列表，并通过组织机制和流程有针对性地解决。</p><p></p><p>在解决问题的过程中，我们通过平台和端到端的流程来保障工作效率。数据平台的建设服务于“用数”、“治数”和“有数”，遵循“四全四可”的理念，即“全员工可用、全数据可通、全流程可见、全领域可管”。我们希望，数据平台可以像京东一样提供服务，无论用户走到哪里都能轻松查阅。此外，数据平台不仅解决数据团队服务的问题，也帮助各个部门单位的数据治理专员、甚至科技团队解决问题。</p><p></p><p>简而言之，国泰君安做数据平台的目标是将复杂性留给平台，将简单性留给用户。不仅仅关注技术视角，还着眼于全领域的可管理性，包括安全资产和权限。通过以数据为引导，通过治理解决问题，通过数据工作提升效率。效率本身就是标准化、SOP 和端到端。在不同阶段，我们会侧重这三点中的的不同方面来应对。</p><p></p><p>InfoQ：在国泰君安构建和运营数据平台的过程中，有什么让您和团队特别影响深刻的故事（问题、经验、成就等）可以分享？</p><p></p><p>苑博：近两年我们在推行“数据资产当日达”计划。尽管这个愿景可能有些理想化，但数据平台是为全员提供服务的，我追求的目标是在用户提出数据请求的同一天内予以响应。</p><p></p><p>我认为做数据平台，就要致力于为用户提供可靠的服务承诺。比如用户在上午提出了数据需求，我们在当天下午能够满足他们的需求，并在整个流程中保持透明，确保用户能够清晰地了解申请进度，随时查看流程的每一个步骤。</p><p></p><p>这看似简单的目标实际上涉及到许多挑战。首先，需要“打破部门墙”，实现科技与业务的紧密融合。其次，必须提高数据交付的效率，确保用户能够在需要时迅速获得所需的数据。</p><p></p><p>科技和业务的融合还涉及到权限的管理，需要判断用户是否具备获取所需数据的权限。进一步地，如果用户有权限，科技端是否能够高效地交付数据也是一个关键问题，因此，需要建立完善的端到端流程。</p><p></p><p>为了确定用户是否有权限获取数据，还需要建立一套公司级机制。同时我们又希望最大程度地减少审批流程，因此也需要对公司的数据资产进行盘点、分级分类，然后根据分级设定共享审批机制。</p><p></p><p>InfoQ：截至目前，这个项目的实施成果如何？</p><p></p><p>苑博：目前，在非受控类数据资产方面，我们已经基本实现 90% 以上申请的当日达效果。从今年年中开始试行以来，我们进行了流程优化、运营推广和宣传等工作。</p><p></p><p>当前，大家普遍认为数据是数字化转型的基础，但要实现这一目标，有几个前提条件。首先，你必须能获得想要的、所需的数据。第二点，获取数据的效率应尽可能高，第三，获得的数据必须是可用且可分析的。</p><p>我认为这就是数字化转型的核心。我们在建设系统的过程中，流程往往会出现割裂和断裂的情况，因为每个部门都希望建立自己的流程。但从用户的角度来看，我们的目标是将这些流程串联起来，从需求提出开始，一直到通知用户任务已完成，确保每一个步骤都在用户的视野范围内，这实际上也是一项基本的要求。</p><p></p><p>InfoQ：数据从沉淀到价值挖掘，期间还有很多工作要做，您认为影响数据赋能业务的主要因素有哪些？在处理大数据时，团队是如何进行数据治理和确保数据质量的？</p><p></p><p>苑博：首先，关于数据发挥价值的问题，我理解是要让“做数据的人都很爽”。如果业务部门的人在使用数据时感到困扰，无法顺利获取数据或提出的问题得不到解决，这显然是不可接受的。</p><p></p><p>第二，我们要让业务部门里使用数据的人感到有成就感，并且他们的价值在组织中得到认可。</p><p></p><p>第三，为了发挥数据的乘数效应，我们需要增加数据的维度。这意味着在数据分析中要考虑更多维度的指标和要素，让分析结果更为全面和准确。</p><p></p><p>至于数据质量的问题，我认为关键在于标准的制定和源头管理。一方面要确保数据的标准化，使口径统一。其次，从源头开始管理数据质量，从录入数据的环节就着手管理。</p><p></p><p>InfoQ：在您看来国泰君安在数据治理方面，在行业内是处于一个什么样的水平？</p><p></p><p>苑博：我们最近获评 DCMM4 级（量化管理级），是国内证券行业首家获评 DCMM4 级的证券公司，也是国内证券公司目前在该领域获评的最高等级，它标志着国泰君安在数据管理和应用方面是处于行业领先水平的。</p><p></p><p>当然，我们也应意识到，数据治理工作是一项长期、系统性工程，是一个随着市场、公司发展以及组织能力提升而不断深化的过程。我们需要保持清醒的头脑打好攻坚战和持久战，持续提升数据作为重要生产要素的支撑作用。</p><p></p><p></p><h2>未来发展与规划</h2><p></p><p></p><p>InfoQ：在国泰君安的数据平台上，融合了哪些前沿技术（如人工智能等）？接下来会有哪些新的动态吗？</p><p></p><p>苑博：我们也关注一些前沿技术，比如 ChatGPT，还有存算分离和湖仓一体化。</p><p></p><p>我们的目标是为全员提供数据服务，现阶段希望为每个人创建一个数据空间，使其能够有效地管理和充分利用自己的数据，实现数据的增值。</p><p></p><p>这个数据空间并非虚拟概念，对于国泰君安的人来说，它是一个实际的功能。员工在公司参与了多个业务，留下了许多业务足迹，他们应该拥有自己的数据。我们希望能提供这样的一个平台，让员工能够轻松查看和管理他们所涉及的数据，而不必到处寻找数据。</p><p></p><p>尽管这个想法很简单且实用，但涉及到复杂的管理问题和技术挑战。这与存储、管理、机制和工具等多个方面都有关联。我们希望员工可以在平台上查看和加工数据，同时确保数据不会被随意传播。</p><p></p><p>InfoQ：随着 GPT 浪潮的到来，您认为大模型的流行会给证券行业数字化带来哪些影响？国泰君安在这方面有哪些布局和规划？</p><p></p><p>苑博：首先，对于证券行业而言，可能采用行业大模型与小模型相结合的方式来解决这个问题会更实在。</p><p>其次，从长期来看，大模型可能会带来颠覆性的变革。然而，短期内它仍受到很多限制，例如数据治理、数据标准化流程以及 SOP 建设等工作，这些都需要得到有效实施才能更好地发挥大模型的价值。</p><p></p><p>目前来看最有潜力的应用场景可能在客户服务方面，特别是对于互联网用户。我们可以通过协助他们进行投资研究，提供建议。鉴于证券公司的数据基础相对较好，这是一个优势，可以辅助用户进行投资。在短期内，这可能是比较有价值的方向。</p><p></p><p>当然，对于内部的经营分析、报告撰写等工作也会有应用场景，但这些工作仍然需要回归到我们组织能力的提升和业务执行效率的提升上，这也是全面数字化转型的应有之义。</p><p></p><p>内容推荐</p><p>11 月 19 日-20 日在上海成功举办的首届 FCon 全球金融科技大会，以「科技 + 金融，激发创新力量」为主题，汇聚了来自金融龙头企业的数百名技术高管，掀起一场探讨新时代金融科技未来的高潮。经征得大会分享嘉宾同意，InfoQ 数字化经纬为您奉上精彩演讲 PPT！关注「InfoQ 数字化经纬」，回复「金融创新」即可获取 PPT，深度洞悉科技趋势，助您引领金融创新未来！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0e/0e09b84945701548f14ab91a2c49ef51.png\" /></p><p></p>",
    "publish_time": "2023-12-08 11:14:11",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "英特尔软件与先进技术事业部 / 首席工程师胡宁馨确认出席 QCon 上海，分享 WebNN，Web 端侧推理的未来",
    "url": "https://www.infoq.cn/article/TqNGiNCf3yfomTXbrwm9",
    "summary": "<p><a href=\"https://qcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=1208&amp;utm_content=huningxin\">QCon 全球软件开发大会</a>\"，将于 12 月在上海召开。英特尔软件与先进技术事业部 / 首席工程师胡宁馨将发表题为《<a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5646?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=1208&amp;utm_content=huningxin\">WebNN，Web 端侧推理的未来</a>\"》主题分享，探讨 WebNN API 的 W3C 标准进度，对 CNN，Transformer 以及更广泛的生成式 AI (Generative AI) 模型的支持情况和计划，以及在 Chrome，Edge 等浏览器的实现进展。</p><p></p><p><a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5646?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=1208&amp;utm_content=huningxin\">胡宁馨</a>\"，就职于 Intel 软件与先进技术事业部，专注于 Web 技术，W3C 机器学习工作组 Web Neural Network API (WebNN) 规范的发起者和联合编辑，Chromium 项目 Code Committer，WebNN 模块负责人。他在本次会议的演讲内容如下：</p><p></p><p>演讲：WebNN，Web 端侧推理的未来</p><p></p><p>AI PC 以及 AI Mobile 的新兴时代已经到来，越来越多的设备集成了强大的神经处理单元 NPU，以实现高效的人工智能加速，这对需要端侧推理的应用至关重要。除了通过 CPU 和 GPU 进行推理之外，Web Neural Network API (WebNN) 提供了 Web 应用访问此类专有 AI 加速器 NPU 的途径，以获得卓越性能及更低功耗。</p><p></p><p>本次演讲将会给大家分享 WebNN API 的 W3C 标准进度，对 CNN，Transformer 以及更广泛的生成式 AI (Generative AI) 模型的支持情况和计划，以及在 Chrome，Edge 等浏览器的实现进展。作为 JavaScript ML 框架的后端，WebNN 将会在几乎不更改前端代码的前提下，为 Web 开发者及他们的产品带来相较于 Wasm，WebGL 更为优异的性能体验。</p><p></p><p>演讲提纲：</p><p></p><p>当前 Web AI 发展概况主流硬件加速器的发展（CPU，GPU，NPU)WebNN 设计与架构WebNN 代码演示WebNN 浏览器（Chromium）实现WebNN 机器学习框架集成（ONNXRuntime 和 TensorFlowLite)WebNN Transformers 支持WebNN 性能</p><p></p><p>听众收益点：</p><p></p><p>○ 了解 Web 平台对异构处理器的支持</p><p>○ 了解基于 Web 的机器学习模型硬件加速</p><p>○ 了解 Chromium 实现内部细节</p><p></p><p>除上述演讲外，QCon 上海还将围绕&nbsp;<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart\">GenAI和通用大模型应用探索</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1596?utm_source=infoqweb&amp;utm_medium=teacherart\">AI&nbsp;Agent&nbsp;与行业融合应用的前景</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart\">LLM&nbsp;时代的性能优化</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart\">智能化信创软件&nbsp;IDE</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart\">面向人工智能时代的架构</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart\">性能工程：提升效率和创新的新方法</a>\"等专题进行交流。</p><p></p><p>QCon 上海 2023，相约 12 月！ 现在购票，享 9 折优惠，立减￥680！咨询购票请联系：18514549229（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/0113b3dfb187d5f9988b7eb16d2e0594.png\" /></p><p></p>",
    "publish_time": "2023-12-08 11:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从业务应用挑战出发，火山引擎专家深度拆解“弹幕互动方案”的全新实践",
    "url": "https://www.infoq.cn/article/SKtUWjqpsK9DV0gFaR5W",
    "summary": "<p>从互联网到全行业视频化时代，营销、商品、知识与空间的体验正在被重塑和创新，<a href=\"https://www.infoq.cn/article/z1CW0cFhLxLi2KYk258t?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">火山引擎</a>\"视频云以“面向体验，驱动创新”为核心，特别与 NVIDIA 团队合作推出《<a href=\"https://www.infoq.cn/article/OHhA89XUrsQtm7T5Ts43?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">云上新视界</a>\"》线上课程。第五期课程中，火山引擎 RTC 商业化解决方案团队负责人郭健为大家分享了当前热门玩法“弹幕互动”的解决方案与应用实践。</p><p></p><h2>一、什么是“弹幕互动玩法”?</h2><p></p><p></p><p>弹幕互动玩法是依托直播间（直播连麦、语聊房等互娱核心场景），观众可以通过弹幕、送礼物等互动操作，控制直播画面中的互动内容的一种直播方式，具备即开即玩、多人互动等特性，兼具观众互动性强、直播内容游戏化趣味化等特点。</p><p></p><p>从 2014 年的《Plays Pokémon》到 2021 年尾《修勾夜店》爆火，弹幕互动几经翻红。今年开始，弹幕互动受到各大平台的广泛关注，从玩法上线后效果看弹幕互动玩法的户观看人数 / 时长、营收等核心指标都有很好的收益。</p><p></p><h2>二、弹幕互动方案的 3 个核心演进阶段</h2><p></p><p></p><p>弹幕互动经历了 PC 端开播、云游戏方案、云游戏 + <a href=\"https://www.infoq.cn/article/Ue0E2ZXpr2BwaYxlQ0fL?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">RTC </a>\"方案三个阶段。</p><p></p><p>第一个阶段，PC 端开播。传统开播流程需要主播先在 PC 端安装程序和开播工具，互动玩法在主播 PC 上运行和渲染。同时，主播使用 PC 端直播工具（比如 OBS）对本地画面和主播直播画面混流，再推送到直播间。观众进入直播间发送弹幕或者发送礼物参与互动。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f6/f65bdaf68b7489076c5d4af003097847.png\" /></p><p></p><p>这种方式存在一定局限性，比如：</p><p></p><p>弹幕互动内容本身需要实时计算渲染，对设备硬件配置如显卡计算能力有较高要求，甚至堪比 3A 大作性能要求，开播设备性能不足，就会导致弹幕无效甚至内容本身卡死，影响直播间用户体验；越来越多的主播更习惯在移动端随时开播，而只能运行在 PC 端的弹幕互动程序，会大大增加开播门槛，也降低平台玩法覆盖度；移动端开播还可以与平台其他玩法相结合，但如果单独为弹幕玩法准备 PC 端 OBS 开播，既增加了维护成本，也难以进行推广。</p><p></p><p>第二阶段，在直播 / 语聊的基础上引入云游戏。主播进入连麦房间推拉 RTC 流的同时，也需要进入云游戏的房间拉取互动玩法音视频。然后业务层把 H5 引擎拉取到的视频流和业务层采集到的摄像头流在端上合流后，推入直播房间。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/07/07a7368a086b934ca4812074f93dbffb.png\" /></p><p></p><p>这个方案解决了开播平台限制和开播设备的限制，但是有一些方案接入和体验问题。从方案层面看，业务逻辑复杂接入相对麻烦。从体验看，存在嘉宾 / 观众侧主播解说和互动画面会有轻微的不同步、画面延时大、有回声等问题。其中，RTC 引擎订阅云游戏音频观众侧有回声主要是因为游戏流的声音或者麦克风会采集到本地播放的游戏声音。</p><p></p><p>为了解决上个方案的几个问题，火山引擎视频云首推“云游戏 +RTC 方案”方案，而弹幕互动方案也正式进入了第三阶段——火山引擎 RTC 与云游戏产品在服务侧和引擎侧做了深度协同优化。在服务侧，优化了调度方案，保证用户连接的云游戏 pod+RTC 媒体服务器在同一个机房、云游戏音视频流可直接送入 RTC 房间。在引擎侧，云游戏引擎直接依赖宿主侧的火山 RTC 引擎、云游戏引擎裁剪场景无关功能。</p><p></p><p>在具体操作中，首先主播通过云游戏引擎开启互动完成程序，云游戏启动 pod 并创建火山 RTC 房间。完成后，Pod 集成云游戏引擎和 RTC 引擎向火山云游戏房间推音视频流，火山云游戏房间跨房转推音视频流到两个直播 / 语聊房间，嘉宾和观众通过 RTC 直接拉取直播流和云游戏流即可。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/91/918deed71d6b8a03257846fafd65c7d3.png\" /></p><p></p><p>云游戏和 RTC 内部深度协作，缩短数据流转链路在接入直播 / 语聊的基础上，仅需接入 veGameSDK 启动游戏、业务端通过 OpenAPI 同步弹幕 / 礼物数据到云游戏服务器两步即可完成场景“升级”，大大简化业务逻辑，缩短接入周期减少工作量。</p><p></p><h2>三、火山引擎是怎么解决历史方案问题的？</h2><p></p><p></p><p>此前弹幕互动方案所存在的观众弹幕互动延时、主播外放有回声等体验问题，火山引擎方案是如何解决的？</p><p></p><h4>&nbsp;1. 弹幕互动延时问题</h4><p></p><p></p><p>未优化的云游戏方案观众端发送弹幕后，由于传统 RTMP 直播流延迟较大，观看云游戏观众侧会有 3~5 秒延时，并且都会有轻微的互动画面与解说的不同步，体验较差。这些在普通常见的场景可能影响不大，但是在对战场景，战场形势瞬息万变，可能最后一秒的延时失去被“偷家”导致战斗失败。</p><p></p><p>优化后，使用全 RTC 方案，可以让用户参与玩法整体延时&lt;400ms 。</p><p></p><h4>&nbsp;2. 外放回声消除</h4><p></p><p></p><p>在未优化方案中，云游戏的声音在经过扬声器播放后，会被近端用户的麦克风采集到并产生回声问题，需要参考扬声器播放的声音进行回声消除技术处理，云游戏和 RTC 独立运行，云游戏音频无法给到 RTC 引擎，所以容易产生回声。</p><p></p><p>在优化方案中，云游戏音频可以直接跨房转推到 RTC 房间，场景内音频播放通过音频托管的方式统一由 RTC 进行音频播放，有参考信号，可以彻底消除回声，以确保对端收到清晰的声音。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b7/b7615c34243048d5d4edabe66d99ef81.png\" /></p><p></p><p></p><h2>四、弹幕互动方案在业务应用中的挑战与实践</h2><p></p><p></p><h4>&nbsp;1. 卡顿优化</h4><p></p><p></p><p>弹幕互动场景有一个特点就是画面极致高清，一般是高清 1080P、 帧率 30fps、高码率 8Mbps。同时，主播、观众均为移动端设备，随时开播与参与，用户网络环境复杂且不稳定。在这种高分辨率高码率、且网络不稳定情况下极其容易造成卡顿劣化。</p><p></p><p>要优化这种情况，首先把线上 H264 升级为自研 ByteVC1 编解码，在 PSNR（视频质量客户评价）画质质量优于原方案 2dB 时，还能节约 10% 码率。此时对于线上情况码率可能仍较大，火山引擎 RTC 采用智能流控协议 (VISC)，它基于 Simulcast 和 SVC 策略优化而来、更加智能的一种传输协议，它可以综合考虑音视频通话中每个订阅者的个性化需求，在网络情况、终端性能发生变化的时候，自动调整音视频流的配置，最大限度地让每个参与者的个性化需求得到满足，为用户提供更流畅的互动体验。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5a/5a57bdf9d82120b552297cf2fbbe2456.png\" /></p><p></p><h4>&nbsp;2. 操作延时优化</h4><p></p><p></p><p>云游戏在所有的云计算相关应用中，对延时要求最为苛刻，火山引擎 RTC 针对云游戏与 RTC 场景相结合的应用场景，进行全链路延时优化。</p><p></p><p>阶段一，边缘机房阶段。保证用户连接的云游戏 Pod 和 RTC 服务器调度到同一个机房，使用更高效传输方式优化，首帧时长减少约 30ms；降低延时 50ms；编码前优化采集和格式转换，使用 OpenGL 转换替换 libyuv 转换，优化延迟 15ms;阶段二，级联服务优化。减少级联服务器和优化信令传输，优化 20ms;阶段三，订阅端。针对云游戏下行音视频调整 jitterbuffer 大小，降低延时 60~260ms，有优化的处理，可以不影响直播 / 语聊体验；针对不同的硬件解码器做优化，最多优化延迟 90ms；内部渲染替代外部渲染降低延迟 5ms，整体云游戏到端延时可以达到小于 75ms。</p><p></p><h4>&nbsp;3. 性能优化</h4><p></p><p></p><p>弹幕互动玩法可以在个人直播、直播连麦或者跨房 PK 中等场景中加入。在语聊房跨房 PK+ 弹幕互动玩法场景中，假设每个语聊房会有 9 人，两个房间 PK 时，单个用户最多需要拉 18 路音频流和云游戏音视频流，性能压力大，玩法准入机型门槛高，设备发热严重。</p><p></p><p>因此，为减少对手机性能消耗，火山引擎 RTC 使用 RTC 公共流不进房拉流方案。这个方案中，本房间内拉流方式不变，PK 房间的音频流合流后推一路公共流，对比普通语聊模式单个用户只多拉一路音频流和一路云游戏流。两个房间 PK，每个房间 1 位主播、8 位嘉宾、100 位观众流数评估，单房间减少（1+8+100）*8 约 872 路、单用户减少 8 路流，有效优化用户拉流性能，减少 50% 流数量。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3c/3c3b679655ff084ab5807c48eece0a0f.png\" /></p><p></p><p>独立集成云游戏 SDK 包体增量一般 9M 左右，9M 的包增量对客户来说是不可接受的。弹幕互动方案中云游戏直接复用火山引擎 RTCSDK 传输能力，云游戏 SDK 精简包只需操控信令和选路部分，精简包给整体带来增量仅 610KB。</p><p></p><h2>五、写在最后</h2><p></p><p></p><p>总体来说，火山引擎弹幕互动方案有五大优势：</p><p></p><p>不限设备、不限场景，零门槛开播：无论是个播还是多人互动，移动端即可随时随地“云开启”弹幕互动玩法，无需高性能 PC，消除互动内容本身对用户终端算力的限制；热门弹幕互动内容全适配：云游戏支持直接部署基于 UE/Unity 框架的互动内容，底层多种类型 IaaS 和对应 GPU 配置，满足不同等级算力要求的弹幕互动玩法；无惧弹幕高并发，渲染画面高清流畅：云游戏支持 ARM、x86 以及定制化 GPU 等多样化计算资源，并采用自研 ByteVC1 编解码结合动态码率技术，保证互动画面流畅体验同时节约带宽消耗，互动画面 100ms 卡顿率低于 2%；主播解说与玩法进程实时同步：通过火山引擎 RTC 媒体节点和 云游戏 Pod 端同机房调度，超低延时体验，操作延时小于 90ms，主播讲解和内容画面实时同步，保障观众沉浸互动体验；应用最小包增量引入：弹幕互动方案中云游戏可直接复用火山引擎 RTC SDK 传输能力，云游戏 SDK 精简包只需操控信令和选路部分，精简包增量仅 KB 级。</p><p></p><p>而本期课程中介绍的弹幕互动玩法的解决方案技术实践只是“小试牛刀”，如果想要了解更多，可以扫描下方二维码，有更加详细的弹幕互动解决方案和获取弹幕互动 Demo！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/eb/ebba54e6aafb6fea8351787b6285c768.png\" /></p><p></p>",
    "publish_time": "2023-12-08 12:15:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "互联网大厂“组团”宕机，都怪降本增“笑”？",
    "url": "https://www.infoq.cn/article/F5V2uRJcxZVUWOR6bQpC",
    "summary": "<p></p><blockquote>当服务器宕机的那一刻，时间仿佛也停滞了。</blockquote><p></p><p></p><p>&nbsp;</p><p>前不久，国际数据公司IDC发布了《中国公有云服务市场（2023上半年）跟踪》报告。该报告显示，2023年上半年中国公有云服务整体市场规模（IaaS/PaaS/SaaS）为190.1亿美元。其中，IaaS（基础设施即服务）市场规模为112.9亿美元，同比增速13.2%；PaaS（平台即服务）市场规模为32.9亿美元，同比增速为26.3%。</p><p>&nbsp;</p><p>伴随着AIGC技术的崛起，云计算市场增长迅速。但另一方面我们也不得不注意到，最近半年来互联网基础设施宕机事件频发，服务器这个曾经被我们视为坚不可摧的巨人，如今却倒在了自己的重量之下。它的宕机，像一座大山瞬间崩塌，带来的震动与影响远远超出了人们的想象。</p><p>&nbsp;</p><p>当宕机事件发生，我们就犹如被困在了一座孤岛上，只能眼睁睁地看着外面的世界在不断运转，这些曾经熟悉的工具都变得遥不可及，也给客户带来了无尽的失望和不满。</p><p>&nbsp;</p><p>最后，我们开始反思这一切的根源。是什么导致了这场技术灾难？是技术不够先进，还是管理存在问题？是对风险的评估有误，还是对备份方案的准备不足？</p><p>&nbsp;</p><p>本文总结了近半年来的云宕机事故，以期能沉淀出更加清醒的认知，降低类似事件发生的频率。</p><p>&nbsp;</p><p></p><h2>宕机事件频发，云基础设施靠不住了？</h2><p></p><p>&nbsp;</p><p></p><h3>腾讯视频App“崩了”，回应称出现短暂技术问题</h3><p></p><p></p><p>12 月 3 日晚，腾讯视频出现网络故障，有网友反馈出现首页无法加载内容、VIP 用户看不了会员视频等情况。稍晚些时候，@腾讯视频就“App崩了”发布致歉声明：</p><p>&nbsp;</p><p>尊敬的用户：目前腾讯视频出现了短暂技术问题，我们正在加紧修复，各项功能在逐步恢复中。感谢您的耐心等待，由此给您带来的不便我们深感歉意。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a9/a98eb811f03ae651d48e9e97fc75ca25.png\" /></p><p></p><p>&nbsp;</p><p>除了腾讯视频，近期遭遇宕机事件的还有滴滴、语雀、Boss、钉钉、淘宝、闲鱼盘等多个App。</p><p>&nbsp;</p><p></p><h3>阿里云一个月内崩完了再崩</h3><p></p><p></p><p>11月27日，阿里云服务器遭遇了近两小时的中断，影响到中国和美国的客户，这是该业务一个月内第二次宕机。</p><p>&nbsp;</p><p>随后，11月28日，阿里云在网站上发布的声明中表示，北京时间2023年11月27日09时16分起，阿里云监控检测到资料库产品的控制台和OpenAPI访问异常，称问题已于当天10点58分解决。</p><p>&nbsp;</p><p>受到此次事件影响的主要是北京、上海、杭州、深圳、青岛、香港以及美东、美西等多个地区的数据库产品，包括PostgreSQL、Redis和MySQL等。</p><p>&nbsp;</p><p>而类似的事故，在双十一刚过的第二天，也就是11月12日刚刚发生过。</p><p>&nbsp;</p><p>11月12日，阿里云发生了宕机，旗下的钉钉、淘宝、闲鱼等产品皆受到了不同程度的影响，此次事故还影响到了使用阿里云的一些企业级客户，受影响地区从东亚和东南亚，覆盖到了中东和北美。经过数小时的修复后，服务恢复正常。&nbsp;</p><p>&nbsp;</p><p>有人猜测，阿里云11月27日的宕机甚至可能造成了滴滴出行App崩了一夜，但业内人士认为这种情况概率比较低。</p><p>&nbsp;</p><p></p><h3>滴滴崩了一夜</h3><p></p><p></p><p>11 月27日深夜，上海、北京、广州等多地滴滴用户反馈，滴滴出行 App 无法使用，显示网络异常，地图无法加载，用户无法使用定位功能且无法打车。</p><p>&nbsp;</p><p>“滴滴崩了”的话题也登上微博热搜。热搜话题下不少用户发帖表达自己在使用滴滴 App 过程中遇到的“离谱”问题。</p><p>&nbsp;</p><p>有用户反馈虽然打到了车，但同时来了好几辆车，有的用户遇到来了三辆、有用户遇到来了四辆车，无法取消，无法联系客服。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/fc/fce212da55fe65e28b44e5aa561999e8.png\" /></p><p></p><p>&nbsp;从各平台上的反馈来看，此次滴滴平台在接单、定位、计费等环节上都出现了问题。</p><p>&nbsp;</p><p>有网约车司机表示，昨晚 App 崩溃时刚好在接单，“从晚上 10 点 20 分开始什么都做不了，客服电话也进不了线。目前恢复了少部分功能，但不能正常使用，很多错单乱单，还出现了多位司机接同一单的现象。”</p><p>&nbsp;</p><p>27 日深夜，滴滴出行对滴滴 App 服务出现异常进行了回复，滴滴出行称：非常抱歉，由于系统故障，今天晚间滴滴 App 服务出现异常，技术目前正陆续恢复中。由此给广大用户和司机师傅们造成不便，再次向大家致歉。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8e/8e1cf938800786964f0990d674453623.jpeg\" /></p><p></p><p>&nbsp;经过一夜维修，滴滴在 28 日早上 7:31 分做出回应称“滴滴网约车等服务已恢复”。</p><p>&nbsp;</p><p></p><h3>语雀突发 P0 级事故，宕机 8 小时&nbsp;</h3><p></p><p></p><p>10 月 23 日 14&nbsp;时左右，在程序员节的前一天，蚂蚁集团旗下的在线文档编辑与协同工具语雀发生服务器故障，在线文档和官网目前均无法打开。当日 15 时，语雀发布官方声明称，“目前因网络故障，出现无法访问的情况。此故障不会影响用户在语雀存储的数据，不会引起数据丢失，我们正在紧急恢复中，再次抱歉给你带来的损失。”</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b9/b9bb61408aa6d8755a279293f1a4c09c.png\" /></p><p></p><p>&nbsp;随后，“语雀崩了”登上话题热搜，有网友表示自己的公司项目文档都在语雀上，文档打不开严重影响工作进度；有网友将自己整理的面试题放在了语雀上，宕机时正好赶上电话面试，想查答案都无从下手；也有网友对语雀的运维提出质疑，认为“长时间的故障明显是存储出现了问题，用户数据可能丢失了，在紧急恢复”。</p><p>&nbsp;</p><p>从故障发生到完全恢复正常，语雀整个宕机时间将近 8 小时，如此长时间的宕机已经达到了&nbsp;P0 级事故，并在网络上引发巨大讨论。</p><p>&nbsp;</p><p></p><h3>肯德基App崩了，13元买五人餐</h3><p></p><p></p><p>11月14日，“肯德基App崩了”冲上微博热搜第一。有网友爆料称，肯德基App崩溃期间，还出现了大Bug，14.9元+139元的套餐同时加入购物车，领取“-10的优惠券”，再把那个双人餐退掉，就可以13元买五人餐。</p><p>&nbsp;</p><p>当日晚些时候，肯德基官方客服表示，刚才系统确实崩溃了，但目前已经修复完成，用户可以重新登录使用。</p><p>&nbsp;</p><p></p><h3>月活用户超4000万，BOSS崩了</h3><p></p><p></p><p>9月15日，据媒体报道，在线招聘App BOSS直聘崩了。当天11时前后，许多用户涌入“BOSS直聘”官微的最新博文中留言，抱怨无法刷新页面，发信息也发不出去，给客服反馈也没有任何回应。</p><p>&nbsp;</p><p>有网友透露，这已经是BOSS直聘今年第三次出现网络崩溃。随后网络上流传一张截图显示：9月15日10点15分26秒，在线统计超过4700万人在刷BOSS直聘，导致服务器超荷载，正努力维护中。随后BOSS直聘官博辟谣，称服务器崩了是真的，网传数据是假的，BOSS直聘月活为4360万人。</p><p></p><h2>探究大厂App排队宕机背后的真相</h2><p></p><p></p><p>在互联网大厂的App频繁出现宕机后，一众网友将宕机背后的原因归结为裁员、降本增效等行为，以此来讽刺互联网大厂缺乏稳定性的系统服务，但这真的是事件背后的真相吗？</p><p>&nbsp;</p><p>在<a href=\"https://qcon.infoq.cn/2023/shanghai?utm_source=infoq&amp;utm_medium=conference\">QCon</a>\"中国15周年之际，InfoQ特别邀请了云器科技联合创始人兼 CTO&nbsp;关涛、贝联珠贯合伙人王元良、趣丸科技技术保障部负责人刘亚丹，参与「大会早班车·QCon15 周年特别策划」直播栏目，围绕“稳定性出了大问题，是降本增效的锅？”相关话题展开讨论。</p><p>&nbsp;</p><p></p><p></p><p>&nbsp;</p><p></p><h3>降本会带来哪些问题？</h3><p></p><p>&nbsp;</p><p>在全球降本增效的大环境下，在一定程度上降低成本成为了所有公司的普遍共识，也是一种显而易见的大趋势，那么降本会带来哪些问题呢？</p><p>&nbsp;</p><p>趣丸科技技术保障部负责人刘亚丹认为：降本主要涉及两个维度——砍人和砍资源，而不同纬度则会带来不同的问题。</p><p>&nbsp;</p><p>在砍人的维度上，可能会出现以下问题：</p><p>测试不充分： 由于人员减少，测试可能无法覆盖到所有的情况，导致上线出现问题；开发人员不足： 开发人员减少可能导致项目延迟，影响整体进度；上线验收不完整： 由于人手不足，上线后的验收可能不够严格，存在潜在问题；</p><p>&nbsp;</p><p>如果资源被砍，则可能会出现以下问题：</p><p>容量不足： 预估的用户量超过实际承载能力，导致系统崩溃或性能下降；配置问题： 上线后需要配置验收，但由于资源减少，可能存在配置不当的情况。</p><p>&nbsp;</p><p></p><h3>稳定性问题到底是不是降本造成的？</h3><p></p><p>&nbsp;</p><p>那么，是不是不降本，就能保证稳定性了？云器科技联合创始人兼CTO&nbsp;关涛认为，稳定性的危机一直存在，虽然我们能够察觉到一些故障，但未显露的潜在问题更为庞大，显露出的问题只是冰山一角。即便选择不走“降本”的路径，稳定性问题仍然存在。</p><p>&nbsp;</p><p>只是，如果选择了降低成本，那么就要在保证稳定性的前提下进行成本优化，这就需要在事前进行详细评估，事中制定相应的预案并进行演练，然后在确保这些工作完成后，再考虑进行降本操作。比如在进行降本操作前，需要对目标进行详细的评估，思考能否成功节省80%的成本，或者是否可以先推高5%的Cluster。还需要假设系统的任何一个部分都可能发生故障，并制定相应的预案。例如，如果资源调度模块出现故障，应如何恢复等，这些都需要提前考虑清楚。</p><p>&nbsp;</p><p></p><h3>谁是稳定性第一责任人？宕机了谁该背锅？</h3><p></p><p>&nbsp;</p><p>尽管考虑到了种种可能出现的问题，但系统在运行时到底会发生什么突发意外却是未知的，一旦出现了问题，该有谁来负责？</p><p>&nbsp;</p><p>就此问题，王元良表示，从首席执行官（CEO）的角度来说，稳定性是CTO的责任。</p><p>&nbsp;</p><p>如果CTO重视稳定性的问题，这将会对整个企业产生影响，包括内部的各个层面。管理者可以将自己的理念、血液或者说灵魂注入整个组织，并且大多数公司面对故障时都应该去思考如何改进，而不是追责。</p><p>&nbsp;</p><p>关涛则称，“的确应该由公司一号位来负责，但比起对事故负责，对发生的故障进行复盘更为重要。”</p><p>&nbsp;</p><p></p><blockquote>“第一责任人应该位于公司的首位，这并非是要完全推卸责任，而是在一般情况下确实存在资源投入比例的问题。也就是说，公司需要在稳定性、业务开发以及技术底座沉淀上进行资源投入，而这个投入的比例不同确实会影响整个公司的发展方向。因此，从这个角度来看，如果一定要明确个第一责任人，那一定是公司的一号位。”</blockquote><p></p><p>&nbsp;</p><p>此外，就如何拆分稳定性的问题关涛也给出了他的方法论。他表示，首先，要区分研发和运维的责任。明确这个故障究竟是研发的问题还是运维的问题。其次，要明确到底是谁负责解决问题。</p><p>&nbsp;</p><p>在云器科技，如果将故障分成P1、P2、P3、P4，最底层P4是最不严重的故障，最不严重的故障会交给一线的研发同学来解决。也就是说，如果故障真的是研发的Bug或者SRE操作失误，那么这个责任就在最底层。P3层交给一线的Leader，到了三级可能就不再是某一个程序人员的责任，而是一线Leader的责任。</p><p>&nbsp;</p><p>之所以造成此类故障，可能是故障发生之前没有做好事前预判，故障中也没有抓住稳定性问题，事后缺乏兜底措施，演练不够，爆炸半径控制不够等一系列问题。P1、P2的故障就需要TO（Technical Owner）来负责，也就是当更大的故障发生时，说明在机制、防范措施以及整个公司资源调配方面没有做好，包括SRE和研发的协同层面。因此，在云器科技内部，采用的是这种模式来看待故障。关涛表示，目前来看，这种模式运行状况还不错，也没有出现特别大的问题，可以为行业提供一些参考。</p><p>&nbsp;</p><p>同时，关涛也表示，这种波动性在公司的运营中是很常见的。有时候，公司可能会因为对系统稳定性的过度自信或者资源限制等原因，而没有对系统进行适当的扩展或者备份。然而，当系统遇到超出预期的流量或者负载时，就可能出现故障。</p><p>&nbsp;</p><p>这种经验通常是非常宝贵的。在事后分析中，公司可以更深入地了解故障的原因，包括系统瓶颈、潜在的容量不足以及其他可能的问题。这些信息可以用来改进系统的设计和运营策略，以增强系统的稳定性和性能。</p><p>&nbsp;</p><p></p><h3>小结：降本势在必行，但我们要“健康”降本</h3><p></p><p>&nbsp;</p><p>以目前企业总体经营状况来看，降本在一段时间内仍是一个势在必行的方向，但更重要的是要实现“健康”降本。这里的“健康”降本是指在企业进行降本的过程中，不能以牺牲系统的稳定性和性能为代价。</p><p>&nbsp;</p><p>在实现“健康”降本时，一些关键的考虑因素必须要提前考虑清楚：</p><p>&nbsp;</p><p>首先，是合理规划。在降本之前，需要进行全面的规划和评估。这包括对当前系统的稳定性、性能和容量进行深入的分析，以及评估所需的资源和预算。</p><p>&nbsp;</p><p>王元良认为，在数字化领域，能力、成本、人力和硬件等因素都至关重要。然而，对于许多企业来说，尤其是那些大型传统企业，他们往往无法清晰地呈现成本。尽管这些企业拥有强大的流程功能，但他们无法明确说明每个部门使用了哪些成本以及云服务的具体部分，这使得他们难以做出明智的决策。</p><p>&nbsp;</p><p>为了解决这个问题，最首要做的就是清晰地了解账单。然而，目前看来，从首席执行官到单个使用节点的整个评估过程尚未完全打通。这不仅影响了企业的决策过程，也阻碍了他们优化运营成本的能力。因此，建立一个完善的评估体系，使得从首席执行官到单个使用节点的所有层面都能明确自己的成本和责任，是非常必要的。</p><p>&nbsp;</p><p>随着数字化和信息化程度的提高，IT成本、硬件人力成本以及一些运维手段成本逐年增加。特别是随着大语言模型的推出，这种趋势对企业的运营产生了深远的影响。因此，将成本可视化并建立完善的评估体系可能是未来企业的必然选择。</p><p>&nbsp;</p><p>其次，是充分了解风险。我们需要有一个成本决策中心，将财务、研发、运维和产品的资源管理方案整合在一起，然后设立一个机制，在这个机制中对过去发生的花费以及未来可能采取的技术手段、优化等方面达成共识。</p><p>&nbsp;</p><p>刘亚丹强调说，共识不仅仅是关于省下多少钱，其背后省下的钱所带来的风险也是大家需要了解的。</p><p>&nbsp;</p><p>再次，以创新技术代替粗暴地乱砍项目。关涛认为：稳定性是健康的FinOps（降本增效）的前提，不稳定的FinOps是危险的，甚至可能是致命的。FinOps不仅仅是砍成本，很多FinOps是靠技术手段去解决。就比如说调度系统的混部技术，是用技术手段高效率地实现在线和离线的混合使用，同时做到成本最低。它更多的是一个技术问题，而不是砍人或者砍项目的问题。</p><p>&nbsp;</p><p>12 月 28-29 日，QCon全球软件开发大会即将落地上海，中国科学院外籍院士、国际数据库专家樊文飞院士，英特尔大数据技术全球 CTO 戴金权等大咖会亲临现场分享大数据、芯片、架构等方向的前沿洞见。这次会议主要探讨大模型的全面技术架构的进化，不仅有跟大模型本身相关的推理加速、AI Agent、GenAI，还有架构的演进思路、性能优化，以及以智能代码助手为代表的研发效能提升等方向，会议目前 9 折优惠中，感兴趣的朋友可以扫码屏幕下方的二维码添加小助手，了解参会详情。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e9/e969a06bdedf2e18c8f8cd29ca5a4c17.png\" /></p><p></p>",
    "publish_time": "2023-12-08 12:21:39",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "大语言模型加速信创软件 IDE 技术革新",
    "url": "https://www.infoq.cn/article/VG9Loxtgp3eHdPdDec49",
    "summary": "<p>什么是智能化信创软件 IDE？为什么它很重要？</p><p>&nbsp;</p><p><a href=\"https://qcon.infoq.cn/2023/shanghai/schedule\">QCon 全球软件开发大会（上海站）</a>\"将于 12 月 28-29 日举办，会议特别策划「智能化信创软件 IDE」专题，邀请到华为云开发工具和效率领域首席专家、华为软件开发生产线 CodeArts 首席技术总监<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1598\">王亚伟</a>\"担任专题出品人，为专题质量深度把关。作为拥有云和开发工具领域近 20 年经验的老兵，华为公司软件开发工具领域的领军人物，20 多项软件开发技术发明专利的拥有者，王亚伟对于「智能化新创软件 IDE」这个专题有着怎样的理解？在会议即将开幕之际，王亚伟与 InfoQ 分享了他的核心观点。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/29/29e75f26136948c06ee3f9bfd82139f8.jpeg\" /></p><p></p><p>&nbsp;</p><p>“信创”是信息技术应用创新的简称，其本质是发展国产替代技术，实现核心技术的可掌控、可研究、可发展等。</p><p>&nbsp;</p><p>相比“信创”，“智能化”在过去 5 年中被业界反复提起，智能化技术的发展必然会使诸如 IDE 这样的软件开发工具更加强大。随着大语言模型的诞生，IDE 除了可以自动地完成一些重复性工作之外，还可以协助开发人员在软件的设计和开发过程中完成更多创新性的工作，比如：</p><p>自动化重构：将一段复杂的代码分解为更小、更易于管理的函数或类。开发者可以描述他想要实现的重构目标，然后让模型生成相应的代码代码翻译：大语言模型可以将一种编程语言的代码翻译成另一种编程语言，再配合 IDE 的语法高亮和错误检查功能，可以帮助开发者使用不熟悉的编程语言编写代码自动化文档生成和更新：大语言模型可以根据代码和注释生成相应的文档，或者在修改代码时自动更新文档。大语言模型是 IDE 的智能化加速度</p><p>&nbsp;</p><p>IDE 的”信创“化旨在将基础软件开发的核心技术实现自主可控，在拥抱开源的同时逐步建立基于自有技术内核的架构和标准，形成自有开放生态。信创化的目的是为了规避可能或已经发生的风险：</p><p>信息安全和供应链安全风险：在关键时刻，国外的产品和技术可能会面临供应链中断的风险。此外，国外产品或开源技术可能会存在安全漏洞或后门，基于这些技术打造的商业解决方案会威胁用户的信息安全 - 2020 年 3 月发生的 SolarWinds 攻击事件导致业界领先的开发工具公司 JetBrains 遭受牵连技术依赖风险：如果完全依赖于外国的技术，那么我们在软件开发核心技术领域的研究、发展和创新能力就会受制于人，最终导致落后经济风险：技术上依赖意味着我们需要持续支付大量的许可费用</p><p>&nbsp;</p><p><a href=\"https://www.infoq.cn/article/d4613NRodWJEAXqRblEu\">延伸阅读：被逼出来的自主可控，从华为自研看国产 IDE 的未来和商业模式</a>\"</p><p>&nbsp;</p><p>“信创”化不意味着重复造轮子或为了与现有技术不同而进行盲目创新，而是目标实现核心技术可控的前提下，解决现有技术的问题，从而对现有技术实现某些方面的超越。举个例子，代码索引是 IDE 的文件查找、代码提示等功能的基础数据源，现有商业 IDE 代码索引的创建、存储和访问效率并不高，索引数据基于对象存储访问时，一个只有 8 字节（2 个 int）内容的数据封装成对象后要占据至少 24 个字节的存储空间。同时，由于内存读写速率要远低于缓存，如果在存储和访问索引时没有以一种缓存友好的方式进行，读写效率甚至 100 倍下降。我们团队在代码索引存储和访问领域提出了一种基于内存压缩的索引自动化存储和访问技术，可以做到 50 倍以上的综合效率提升，该技术已经被评选为华为云高价值专利，并应用到 IDE 内核、运行时优化、云编译等多个领域。” <a href=\"https://www.infoq.cn/article/ubciEs8NPH06CwlpEvtf\">延伸阅读：生成的代码会出错、质量差？面对 AI 编程工具的老大难问题，华为这群人打算这样做</a>\"</p><p>&nbsp;</p><p>技术的积累需要时间，产品研发更需要打磨。王亚伟介绍道：“从 2019 年初开始，我们逐步组建了一支数百人的软件研发专家队伍，分布在中国、俄罗斯、欧洲等国家地区，其中一半成员来自于业界顶尖的软件和工具公司，超过 40% 的成员是开源社区的 Committer 和 Contributor，整个团队都围绕着‘做最好的产品’展开工作，我们建立了从产品、运营、UX 到开发、测试的完整专业的产品研发流程，每月一个小版本、三个月一个大版本，基于内外部用户的反馈快速迭代。过去五年我们真正做到了深耕软件开发工具这个专业领域。”</p><p>&nbsp;</p><p>同时，王亚伟也坦言：“虽然从产品成熟度上看我们的信创化工具跟业界成熟的商用工具相比还有差距，但‘信创’本身绝不意味着竞争力弱，体验打折。我们会继续秉持着‘做最好的产品’的信念，不断前进。”</p><p>&nbsp;</p><p>在今年的「智能化信创软件 IDE」专题上，王亚伟带领他的专家团队将围绕大语言模型、AI 编码辅助、下一代 IDE 平台架构、动态语言类型推理等技术，给大家带来一场技术盛宴。</p><p>&nbsp;</p><p>议题<a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5567\">《AI 开道，让编程体验“一路狂飙》</a>\"，详细介绍华为云 <a href=\"https://www.huaweicloud.com/devcloud/\">CodeArts</a>\" 团队应用大模型开发的 AI 辅助编程的技术 - CodeArts Snap，讲师程啸从博士阶段开始就对代码生成、RAG、代码克隆检测等领域有较深入的研究，他这次也是代表 Snap 团队进行分享。</p><p>&nbsp;</p><p>另外三个英文议题是来自于 CodeArts 俄罗斯的专家团队。</p><p>&nbsp;</p><p><a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5568\">Applying Machine Learning in IDE Challenges and Insights</a>\"将会系统讨论 AI 技术在 IDE 中的应用研究以及如何深远改变我们的开发，测试和调试代码的方式。讲师 Pavel 是俄研院新西伯利亚实验室主任，20 年开发者工具构建经验，机器学习专家、Eclipse IDE 的专家和 Committer。</p><p>&nbsp;</p><p>议题 <a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5575\">Evolution of IDE Platforms</a>\" 会紧密围绕其在构建 IDE 平台时面临的问题和挑战比如分布式代码模型架构下如何确保前后端组件可以高效交互、如何直接从后端内核画出前端复杂 UI，以及我们如何做出艰难的架构和设计决策，同时分享对下一代 IDE 平台的架构和设计展望。Denis 是俄罗斯新西伯利亚实验室的首席架构师，20 多年的工具研发经验，精通编译器、DSL、编程框架，Eclipse 社区 Committer。</p><p>&nbsp;</p><p>静态语言如 Java，C# 等，它的类型推理主要通过编译器完成，代码模型可以通过类型绑定（通常存在于程序的元数据 metadata 中）获得所需要的类型信息。而动态语言的类型推理主要由 IDE 完成，由于缺少编译元数据的支持，动态语言的类型推理是一个业界难题。以 Python 为例，其有一个完全动态严格的类型系统，类型（type）在运行时动态绑定到变量（variable），变量和类型都可以在运行时动态被改变 – 这增加 Python IDE 进行可靠类型推理的难度。议题 <a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5576\">Type inference engine</a>\" 会介绍该团队在做动态语言类型推理时设计和实现的技术细节，并讨论未来该领域的发展方向。Nikolai 是俄罗斯圣彼得堡实验室的首席软件工程师，拥有 15 年 IDE 研发经验，是前 JetBrains Intellij IDEA 和 Scala 项目负责人，精通 Compiler、Program Language Design、Code Analysis 等技术。</p><p>&nbsp;</p><p>据了解，QCon 上海还邀请到了<a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5623\">中国科学院外籍院士、国际数据库专家樊文飞院士</a>\"，<a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5586\">英特尔大数据技术全球 CTO 戴金权</a>\"等大咖会亲临现场分享大数据、芯片、架构等方向的前沿洞见。这次会议主要探讨大模型的全面技术架构的进化，不仅有跟大模型本身相关的推理加速、AI Agent、GenAI，还有架构的演进思路、性能优化，以及以智能代码助手为代表的研发效能提升等方向，邀请<a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5599\">阿里巴巴的通义星尘</a>\"、魔搭社区开源 <a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5673\">ModelScope-Agent</a>\" 框架、百度文心大模型驱动下的智能代码助手等团队核心技术骨干前来分享，目前大会日程已上线，<a href=\"https://qcon.infoq.cn/2023/shanghai/schedule\">可点击下方图片查看详情。</a>\"</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/66/66a620fc97b46ea55958f9b172195701.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0a/0a6b81251700257adb01b1334e7d49f9.png\" /></p><p></p>",
    "publish_time": "2023-12-08 15:38:33",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "多场开发实战课，百度智能云技术大咖现场教学！",
    "url": "https://www.infoq.cn/article/I7oTGIxwXsUk2SGfQAyf",
    "summary": "<p>大模型技术正在以前所未有的速度推动各行业的智能化跨越。对于身处这个时代的开发者来说，他们不仅需要不断学习新知识，还要探索如何将 AI 更好地融入实际应用场景。</p><p></p><p>面对崭新的时代，开发者若想找到一条提升思维认知和开发效率的最短路径，百度智能云每年举办的百度云智大会·智算大会是不容错过的：</p><p></p><p>智能计算大会是百度智能云面向“云计算产品与技术”的重磅活动之一，以引领智能计算技术创新为目标，传递百度智能云产品与技术的最新实践与突破。历经 3 载，从 AI 原生云到深入产业，百度智能云传递着创新的火种，描绘着智能计算的未来。2023 年，智能计算大会全新起航，将以“重构云计算·Cloud for AI”为主题，结合大模型技术以及 MaaS 服务，碰撞最前沿的技术与产品，开启全新的智能计算时代。</p><p></p><p>“工欲善其事，必先利其器”。对于开发者来说，百度云智大会·智算大会是你不可或缺的技术盛宴，它不仅是探索前沿科技的窗口，更是开发实战的“课堂”。</p><p></p><p>2023 百度云智大会·智算大会将于 12 月 20 日在北京落地，本次大会以“重构云计算·Cloud For AI”为主题，汇集了百度集团副总裁侯震宇、IDC 中国区副总裁兼首席分析师武连峰、百度副总裁谢广军等多位行业大咖，聚焦 AI 和云，解读智能计算带来的万千可能和全新图景，带开发者窥见 AI 原生时代的技术创新重构。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a9/a9f9eea7c6ff5cd2c5ecdb72404cb32b.png\" /></p><p></p><p>仅是让大家了解 AI 原生时代的趋势还不够！为了让你获得知行合一的参会感受，下午特别开设了「2023 百度云智大会·智算大会 开发者沙龙」，旨在为开发者提供切实有效的开发技能。 今年 9 月，李彦宏曾在 2023 百度云智大会上强调 AI 原生应用的重要性，他表示，AI 原生应用要能解决过去解决不了、解决不好的问题，应用才是大模型存在的意义。这意味着在 AI 大模型时代，AI 原生应用的构建和实际落地是关键。对于所有开发者而言，则需要能在先进技术和模型的基础上，将 AI 技术与实际应用场景相结合，开发出有用、有价值的产品和服务。</p><p></p><p>为了让开发者能够实操跟练，下午场的「2023 百度云智大会·智算大会 开发者沙龙」活动，由百度智能云主任架构师吴多益、百度资深工程师 &amp; 百度 Comate 产品架构师徐晓强等技术大咖担任分享讲师。</p><p></p><p>实践课程设置方面，由浅入深地涵盖了从编码到应用开发的内容，帮助开发者通过现场实战，学习热门产品及技术、提升软件开发效率，打破在技术与实际应用场景结合方面的障碍。期待参与其中的你，不仅能够掌握提升开发效率的方法，还能建立起构建 AI 原生应用的思维方式。</p><p></p><p>本次沙龙，还为开发者准备了丰富的互动礼品，完成任意一场课程及实验，即可获得精美礼品！线下席位有限，抓紧扫码占位！12 月 20 日 13:00，我们在「2023 百度云智大会&nbsp;· 智算大会 开发者沙龙」不见不散！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e8/e8203ab57b2d095c1230776b92aabdf3.jpeg\" /></p><p></p><p>                                                           一起掌握开发“金手指”</p><p></p><p>                                                        提升开发效率，准时下班吧！</p>",
    "publish_time": "2023-12-08 15:42:04",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何看待 OpenAI Q* 谣言",
    "url": "https://www.infoq.cn/article/N6cVIbuu90KyyRVP2Q7G",
    "summary": "<p>作者 ｜ Timothy B Lee</p><p>译者 ｜ 核子可乐</p><p>策划 ｜ Tina</p><p>&nbsp;</p><p></p><blockquote>OpenAI仍未明确解释Q*究竟是什么，但透露的线索倒是相当不少。</blockquote><p></p><p>&nbsp;</p><p>11月22日，就在OpenAI决定解雇（后又重新聘用）CEO Sam Altman的几天之后，技术媒体The Information报道称OpenAI取得了一项重大技术突破，使其能够“开发出更强大的AI模型”。新模型被命名为Q*（音为「Q star」），“具备解决全新数学问题的能力。”</p><p>&nbsp;</p><p>路透社也发表了类似的报道，但细节同样含糊不清。</p><p>&nbsp;</p><p>两篇报道都将这项突破与董事会解雇Altman的决策联系起来。路透社在报道中指出，几名OpenAI员工向董事会发函，“警告称这项强大的AI发现可能对人类构成威胁。”然而，“路透社未能拿到这封信的副本”，随后的报道也没有继续将Altman下台与Q*一事联系起来。</p><p>&nbsp;</p><p>The Information指出，今年早些时候，OpenAI开发出“能够解决基本数学问题的系统，攻克了这一对现有AI模型来说颇为艰巨的任务。”路透社则表示Q*“具备小学生水平的数学计算能力。”</p><p>&nbsp;</p><p>为了避免妄下结论，我们又花了几天时间搜集相关内容。OpenAI确实没有公布Q*项目的详细信息，但发表了两篇关于其解决小学数学问题的论文。在OpenAI之外，不少研究人员（包括Google DeepMind的研究人员）也一直在这方面开展探索。</p><p>&nbsp;</p><p>我个人怀疑Q*正是指向通用人工智能（AGI）的关键技术突破。虽然不一定会对人类构成威胁，但这可能标志着迈向具有一般推理能力的AI的重要一步。</p><p>&nbsp;</p><p>在本文中，我们将一同了解AI研究领域的这一重大事件，并解释专为数学问题设计的分步推理技术如何发挥关键作用。</p><p>&nbsp;</p><p></p><h1>分步推理的力量</h1><p></p><p>我们首先考虑以下数学问题：</p><p></p><blockquote>John给了Susan五个苹果，之后又给了她六个。之后Susan吃掉其中三个，又给了Charlie三个苹果。她把剩下的苹果给了Bob，Bob吃掉一个。接下来，Bob把手中半数苹果给了Charlie。John给了Charlie七个苹果，Charlie将手中三分之二的苹果给了Susan，最后Susan又把其中四个还给了Charlie。问，现在Charlie还剩几个苹果？</blockquote><p></p><p>&nbsp;</p><p>大家可以先试着自己算算。</p><p>&nbsp;</p><p>其实我们都在小学阶段学过简单的加减乘除，所以看到问题里说“John给了Susan五个苹果，之后又给了她六个”，就知道这时候Susan有11个苹果。</p><p>&nbsp;</p><p>但对于更复杂的问题，那人类在尝试解决时就需要借助笔算或者心算了。比如在此问题中，先有5+6=11，之后是11-3=8，接着8-3=5，以此类推。通过一步步思考，我们最终会得到正确答案：8。</p><p>&nbsp;</p><p>同样的技巧也适用于大语言模型。在2022年1月发表的著名论文中，谷歌研究人员指出，如果大语言模型能按照提示词分步进行推理，就会产生更好的结果。以下是论文中的一份关键图表：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e8/e8aa3c3a12e1e619a196d0456cebedb1.png\" /></p><p></p><p>&nbsp;</p><p>这篇论文的发表时间还早于“零样本”提示技术，因此研究人员通过给出示例答案的方式来提示模型。在左图中，系统会提示模型直接给出最终答案，但结果是划的。而在右侧，系统会一步步提示模型并最终推理出正确答案。谷歌研究人员将这项技术称为“思维链提示法”，且至今仍被广泛应用。</p><p>&nbsp;</p><p>对于大语言模型来说，“五”和“六”这样的数字只是token，跟“这”、“那”或者“猫”没什么区别。这些模型之所以能把大写数字转换成5+6=11，是因为这个token序列曾经在训练数据中出现过。但大模型的训练数据中可能并不包含长计算示例，比如((5+6-3-3-1)/2+3+7)/3+4=8，所以如果要求模型直接给出计算结果，那它就很可能搞不清状况并生成错误答案。</p><p>&nbsp;</p><p>或者用另一种思路来解释，大语言模型没有可用于记忆中间结果（例如5+6=11）的外部“临时空间”。而思维链推理使得大模型能够有效使用自己的输出作为暂时记忆空间，从而将复杂问题拆分成更多步骤——每个步骤都可能与模型训练数据中的示例相匹配。</p><p>&nbsp;</p><p></p><h1>解决更复杂的数学难题</h1><p></p><p>&nbsp;</p><p>在谷歌发表关于思维链提示法论文的几个月前，OpenAI曾经推出一套包含8500道小学数学应用题的GSM8K数据集，以及一篇描述问题解法新技术的论文。OpenAI没有让模型逐一给出答案，而是要求其一次性给出100个思路答案，再通过名为验证器的另一套模型对各个答案进行评分。在这100条回复中，系统将只返回评分最高的答案。</p><p>&nbsp;</p><p>乍看起来，训练验证器模型也需要大费周章，难度不啻于训练大语言模型来生成正确答案。但从OpenAI的测试结果来看，情况并非如此。OpenAI发现只需小型生成器与小型验证器的组合，就能提供与单独使用超大生成器模型（参数是前者的30倍）相当的结果。</p><p>&nbsp;</p><p>2023年5月的一篇论文介绍了OpenAI在该领域的最新研究情况。OpenAI已经跨越小学数学，开始研究更具挑战性的MATH数据集。OpenAI现在不再让验证器对完整答案打分，而是训练验证器具体评估各个步骤，具体参见论文给出的下图：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/30/308ab3a9a944e10fa406a17b643ca6ed.png\" /></p><p></p><p>&nbsp;</p><p>每一步都有一个绿色笑脸符号，代表该步骤处于正确的思路之上，直到最后一步模型得出“x=7”，这时打出的是红色的皱眉符号。</p><p>&nbsp;</p><p>文章得出的结论是，在推理过程中的各个步骤上都使用验证器，其结果比直接验证最终答案更好。</p><p>&nbsp;</p><p>这种逐步验证方法的最大缺点，就是更难实现自动化。MATH训练数据集中包含每个问题的正确答案，因此很容易自动检查模型是否得出了正确的结论。但OpenAI未能找到更好的方法来自动验证中间步骤。于是，该公司只能聘请了一些审查员，为7.5万个解题思路的共80万个计算步骤提供反馈。</p><p>&nbsp;</p><p></p><h1>求解路漫漫</h1><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0b/0be88a7f03a5274850c9978a79424c1e.png\" /></p><p></p><p>&nbsp;</p><p>需要注意的是，GSMK8K和MATH数据集中的问题至少还可以通过分步方式简单解决。但在实际应用中，相当一部分数学问题根本无法拆解，例如：</p><p>&nbsp;</p><p>你正在筹划一场分五张餐桌、每桌三位客人的婚宴。</p><p></p><blockquote>Alice不想跟Bethany、Ellen或者Kimmie一起坐。Bethany不想跟Margaret一起坐。Chuck不想跟Nancy一起坐。Fiona不想跟Henry或者Chuck一起坐。Jason不想跟Bethany或Donald一起坐。Grant不想跟Ingrid、Nancy或Olivia一起坐。Henry不想跟Olivia、Louise或Margaret一起坐。Louise不想跟Margaret或Olivia一起坐。要如何安排客人座位，才能充分满足他们的要求？</blockquote><p></p><p>&nbsp;</p><p>在把这样的提示词输入GPT_4时，它开始分步进行问题推理：</p><p>餐桌1：Alice、Chcuk和Donald。餐桌2：Bethany、Fiona和Ellen。餐桌3：Jason、Grant和Ingrid。</p><p>&nbsp;</p><p>但到第四张餐桌时，它就卡住了。这时候Henry、Margaret和Louise还没有入座，他们彼此都不想坐在一起，但接下来只剩两张桌子可以安排。</p><p>&nbsp;</p><p>在这个问题中，我们不知道GPT-4具体错在哪个具体步骤上。它在前三张桌子的安排上完全满足规则，但这些前期选择也导致余下的客人没办法正确入座。</p><p>&nbsp;</p><p>这就是计算机科学家们所说的NP难题，即不存在通用算法以线性方式加以解决。唯一的办法就是尝试一种可能的安排，看看是否符合要求，如果不行则推倒重来。</p><p>&nbsp;</p><p>GPT-4可以通过在上下文窗口中添加更多文本来完成回溯，但其扩展能力仍然有限。更好的方法是为GPT-4提供一个“退格键”，这样它就能删除最后一个或几个推理步骤，然后重试。为此，系统还需要一种方法来跟踪它已经尝试过的组合，避免重复尝试。如此一来，大语言模型就能探索下图所示的可能性树：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9e/9ed8f78ee2b5f43a4ff715f21bb0f4e1.png\" /></p><p></p><p>&nbsp;</p><p>今年5月，普林斯顿大学和Google DeepMind的研究人员共同发表论文，提出一种名为“思路树”的方法。思路树不再用单一推理链来解决问题，而是允许大模型系统探索一系列指向不同方向的推理链“分支”。</p><p>&nbsp;</p><p>研究人员发现，该算法在解决某些传统大语言模型难以解决的问题上表现良好。其中不仅包括所谓“24点游戏”（即通过添加运算符号将随机给出的几个数字计算为24），还实现了创意写作能力。</p><p>&nbsp;</p><p></p><h1>AlphaGo模型</h1><p></p><p>以上，就是OpenAI和DeepMind迄今为止发表过的所有研究成果，可以看到他们都在让大语言模型更好地解决数学问题方面付出了不懈努力。现在，我们一起来推测这项研究最终可能会走向何方。当然，这些猜测没有任何依据，大家也可以根据自己掌握的情况做出展望。</p><p>&nbsp;</p><p>今年10月，播客Dwarkesh Patel曾就通用人工智能开发计划采访过DeepMind联合创始人兼首席科学家Shane Legg。Legg认为，迈向AGI的关键一步就是把大语言模型跟搜索可能响应的树结构结合起来：</p><p></p><blockquote>这些基础模型属于某种世界模型，通过搜索方式实现问题的创造性解决能力。以AlphaGo为例，它那惊人的棋路到底是从何而来？是学习了人类棋手的经验，还是参考了原有数据？不，根本没有。它其实是选择了一个非常罕见、但也极为合理的棋步，再通过搜索过程思考这步棋会造成怎样的后续影响。也就是说，要想获得真正的创造力，必须探索可能性空间并找出隐藏其中的最佳答案。</blockquote><p></p><p>&nbsp;</p><p>Legg在这里提到了著名的“第37手”，即2016年DeepMind AlphaGo软件与顶尖棋手李世石第二场比赛中的一步。大多数人类选手最初都觉得AlphaGo在这步棋上出现了失误，但其最终刻了比赛，且复盘分析发现这是一手强棋。换言之，AlphaGo表现出了超越人类棋手的布局洞察力。</p><p>&nbsp;</p><p>AlphaGo能够根据当前棋盘状态模拟出数千种可能的后续发展，从而获取类似的见解。对于计算机来说，潜在棋序实在太多，根本不可能一一检查，所以AlphaGO使用神经网络来简化整个过程。</p><p>&nbsp;</p><p>其中的策略网络能够预测出哪些棋路最有希望，值得进一步做模拟分析。而价值网络则负责估算棋盘的当前状态是对白方有利、还是对黑方有利。根据这些估算，AlphaGo再逆向计算下面一步该怎么走。</p><p>&nbsp;</p><p>Legg的观点是，这类树搜索方法有望提高大语言模型的推理能力。大语言模型要预测的不只是单个最可能出现的token，而应在给出回答之前探索数千种不同的响应。事实上，DeepMind的思维树论文似乎就是朝这个方向迈出的第一步。</p><p>&nbsp;</p><p>前文提到，OpenAI曾经尝试使用生成器（生成潜在答案）与验证器（估算这些答案是否正确）组合来解决数学问题。这与AlphaGo明显有几分相似，同样可以理解成策略网络（生成潜在棋步）与价值网络（估算这些棋步能否导向更有利的盘面状态）。</p><p>&nbsp;</p><p>如果将OpenAI的生成器/验证器网络与DeepMind的思维树概念相结合，就能得到一套与AlphaGo非常相似的语言模型，同时保留AlphaGo的强大推理能力。</p><p>&nbsp;</p><p></p><h1>为何命名为Q*</h1><p></p><p>在AlphaGO之前，DeepMind曾在2013年发表过一篇关于训练神经网络以打通雅达利电子游戏的论文。DeepMind并没有手动录入每款游戏的规则，而是让网络不断游玩这些游戏，通过反复试验自行理解玩法。</p><p>&nbsp;</p><p>参考早期强化学习技术Q-learning，DeepMind将这套雅达利解决方案命名为Deep Q-learning。DeepMind的雅达利AI中包含一个Q函数，用于估算任意特定操作（例如向左或向右推操纵杆）可能获得的奖励（比如更高的得分）。当系统游玩雅达利游戏时，它会不断优化Q函数，提升获取更佳得分的估算能力。</p><p>&nbsp;</p><p>DeepMind 2016年在AlphaGo论文同样使用字母Q来表示AlphaGo中的棋步价值函数——该函数用于估算任意给定棋步有多大可能通往对局胜利。</p><p>&nbsp;</p><p>AlphaGo和DeepMind的雅达利AI都属于强化学习的范畴，这是一种从经验中学习知识的机器学习技术。在大语言模型兴起之前，OpenA也I一直将强化学习作为关注重点。例如，OpenAI曾在2019年使用强化学习让机械臂在自行探索中学会解开魔方。</p><p>&nbsp;</p><p>参考这些背景，我们似乎可以对Q*做出有理有据的解读：它是将大语言模型同AlphaGo式搜索能力相结合的产物，而且应该是在以强化学习的方式进行混合模型训练。其重点就是找到一种在困难的推理任务中“自我较量”的方式，借此改进语言模型的实际能力。</p><p>&nbsp;</p><p>其中一条重要线索，就是OpenAI今年早些时候决定聘请计算机科学家Noam Brown。Brown在卡耐基梅隆大学获得博士学位，并在那里开发出首个能够超越人类水平的扑克AI。之后Brown加入Meta，并开发出玩《强权外交》桌游的AI。这款游戏的成功秘诀在于同其他玩家结成联盟，因此AI必须把战略思维与自然语言能力结合起来。</p><p>&nbsp;</p><p>由此看来，这似乎就是帮助大语言模型提高推理能力的绝佳案例。</p><p>&nbsp;</p><p>Brown今年6月在推文中表示，“多年以来，我一直在研究扑克和〈强权外交〉桌游中的AI自我对弈和推理课题。现在，我想探索如何将成果转化为普适性能力。”</p><p>&nbsp;</p><p>AlphaGo和Brown扑克AI中使用的搜索方法，明显只适用于这些特定游戏。但Brown预测称，“如果我们能发现一个通用版本，则必然带来巨大的收益。没错，推理速度可能会降低至千分之一且成本迅速膨胀，但如果能够发现新的抗癌药物、或者证明黎曼猜想，这一切难道不值得吗？”</p><p>&nbsp;</p><p>而在Brown于今年早些时候离职之后，Meta公司首席AI科学家Yann LeCun表示，他认为Brown研究的就是Q*。</p><p>&nbsp;</p><p>LeCun在11月的推文中指出，“看起来OpenAI更进一步的探索就是Q*，他们还聘请了Noam Brown来协助解决这个问题。”</p><p>&nbsp;</p><p></p><h1>两大挑战</h1><p></p><p>&nbsp;</p><p>如果大家跟科学家或者工程师共事时，就会注意到他们特别喜欢用白板。当我自己在研究生院学习计算机科学时，我们就经常站在白板前面绘制图表或者议程。随后在谷歌的实习经历，也让我意识到技术大厂里同样到处都是白板。</p><p>&nbsp;</p><p>白板确实很有启发意义，因为面对极为困难的技术问题，人们刚开始根本不知道该如何下手。他们可能会花几小时勾勒出了种潜在的解决思路，却发现根本就不适用。之后他们就擦掉一切，从零开始找个不同的切入角度。或者，他们也可能觉得方案的前半部分还行，于是擦掉后半部分再换条新的探索路线。</p><p>&nbsp;</p><p>这本质上就是一种智能树搜索：对多种可能的解决方案进行迭代，直到找出一个似乎可以实际解决问题的路线。</p><p>&nbsp;</p><p>OpenAI和DeepMind之所以对大语言模型加AlphaGo搜索树感到如此兴奋，就是因为他们希望计算机也能执行同样的开放式智能探索。到那个时候，我们只需要把充满挑战的数学问题输入给大语言模型，然后安心上床睡觉。第二天早上醒来，它已经考虑了几千种可能的解决方案，并最终给出一些可能有希望的探索方向。</p><p>&nbsp;</p><p>这当然是个鼓舞人心的愿景，但OpenAI至少还要克服两大挑战才能将其转化为现实。</p><p>&nbsp;</p><p>首先，就是找到一种让大语言模型进行“自我对弈”的方法。AlphaGo就是通过自我对弈完成了对顶尖人类棋手的碾压。OpenAI也在模拟物理环境中进行魔方实验，通过判断魔方是否处于“解开”状态来判断哪些操作有正向作用。</p><p>&nbsp;</p><p>而他们的梦想就是建立起一套大语言模型，通过类似的自动化“自我对弈”方式提高推理能力。但这就需要一种能够自动检查特定解决方案是否正确的办法。如果系统还需要人类来检查每条答案正确与否，那么训练规模将非常有限、难以带来可与人类匹敌的推理水平。</p><p>&nbsp;</p><p>就在2023年5月发表的论文中，OpenAI还在聘用审查员来核对数学答案的正确性。所以如果真的出现了突破，那肯定是发生在过去这几个月间。</p><p>&nbsp;</p><p></p><h1>学习是个动态的过程</h1><p></p><p>&nbsp;</p><p>我认为第二个挑战才是根本：通用推理算法，必须在探索各种可能性时表现出动态学习能力。</p><p>&nbsp;</p><p>当人们尝试在白板上推衍解题思路时，他们并不是在机械地迭代各种可能路线。相反，每试过一个失误的路线，人们对问题的理解也就又加深了一步。在推理过程中，他们的心理模型也在不断演进，逐渐生出能快速判断哪种方法更好的强大直觉。</p><p>&nbsp;</p><p>换句话说，人类内心的“策略网络”和“价值网络”并非一成不变。我们在同一个问题上花费的时间越多，在思考潜在答案时的判断能力也就增强，自然更善于预测当前思路是否有效。如果没有这种实时学习能力，我们一定会迷失在无穷无尽的潜在推理步骤当中。</p><p>&nbsp;</p><p>相比之下，目前大多数神经网络在训练和推理之间保持着严格的边界。一旦训练完成，AlphaGo的策略和价值网络就被固定下来了——后续任何比赛过程都不会产生改变。这对围棋来说没有问题，因为这项游戏的规则足够简单，可以在自我对弈的过程中体验各种可能的情况。</p><p>&nbsp;</p><p>但现实世界要比方寸棋枰复杂得多。从定义上讲，研究者想要解决的是以往未能解决过的问题，所以实际情况很可能与训练期间遇到的任何问题都存在巨大差异。</p><p>&nbsp;</p><p>因此，通用推理算法的实现必须在推理过程中持续获取见解，以便在模型解决问题的同时不断增强后续决策质量。然而，目前的大语言模型完全通过上下文窗口来维持状态，而思维树方法在现有模型的一个分支跳往另一分支时，之前的记忆信息会被新的上下文窗口直接删除。</p><p>&nbsp;</p><p>一种可能的解决方案，就是使用图搜索来取代树搜索。今年8月的一篇论文就提到这种方法，尝试让大语言模型将来自多个“分支”的见解结合起来。</p><p>&nbsp;</p><p>但我高度怀疑，真正的通用推理引擎恐怕需要在底层架构上做根本性创新。语言模型必须借助新的方法来学习超越训练数据的抽象概念，并利用这些不断发展的抽象概念强化探索潜在解决方案空间时的具体选择。</p><p>&nbsp;</p><p>我们都知道这绝非妄言，毕竟人类的大脑就能做到这一点。而OpenAI、DeepMind乃至其他厂商可能还需要一段时间，才能搞清楚如何把这种方法照搬到硅芯片之上。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.understandingai.org/p/how-to-think-about-the-openai-q-rumors\">https://www.understandingai.org/p/how-to-think-about-the-openai-q-rumors</a>\"</p><p>&nbsp;</p>",
    "publish_time": "2023-12-08 15:55:09",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "直播预告 | 12月13日用友BIP数据资产入表解决方案即将发布",
    "url": "https://www.infoq.cn/article/DfUTbLBdVYa7cwgWvO6S",
    "summary": "<p></p><p>2024年1月1日，财政部今年8月发布的《企业数据资源相关会计处理暂行规定》将开始施行，这项规定为企业数据资产“入表”提供操作指引，数据资产“入表”势在必行。</p><p></p><p>数据资产“入表”有利提升企业的资产规模，加强企业核心竞争力，同时凸显数据价值，不少上市公司正积极探索数据要素变现。有分析机构指出，入表意味着数据完成了从自然资源到经济资产的跨越，作为数字经济时代的第一生产要素，数据有望成为政企报表及财政等收入的重要支撑。后续数据要素确权、定价、交易流通、收益分配、试点等进展有望陆续推出。</p><p></p><p>不过，当前企业数据资产“入表”和估值仍存在不少难点，比如数据的确权与合规、数据资产的财务判断、数据资源的估值与披露等。</p><p></p><p>12月13日14:00-15:30，用友将围绕企业“入表”难点，直播发布“用友BIP数据资产入表解决方案”，攻克企业“入表”难题，方案将分享用友如何助力企业“完成基础入表工作”，以及如何“激发企业内数据价值”、实现“数据要素的社会级流转”。</p><p></p><p>届时，用友还将携手国际数据管理协会-中国分会(DAMA China)、国际数据管理高级研究院揭牌《全球数据要素企业应用研究中心》，促进数据资产“入表”在企业落地，推动数据资产生态的产业繁荣。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/63/63c4793d4be919dd991651d088477f87.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/08/081c8c84cf68e9257b1956c4141dec50.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c6/c67fee770a1ab4041e855877682ec7e4.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6d/6d91d6e076fd06538891f0ad8f5c77ae.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/21/2166d85e33895fef6010e12c8400c4ac.jpeg\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/13/13ab9e82ce212adc5e4ada713f6ccd83.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/73/7317cb0af63f3dcc209f02e2de73e7db.jpeg\" /></p><p></p>",
    "publish_time": "2023-12-08 16:18:01",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "FCon 最新演讲视频：大模型在金融领域的落地探索",
    "url": "https://www.infoq.cn/article/OkAUyMNBwo5FHSVxsMST",
    "summary": "<p>在金融行业，随着技术的快速发展，大数据和大模型正在逐渐成为推动行业创新的重要力量。这种变革不仅在风险管理和预测方面展现出巨大潜力，而且在促进金融机构与科技公司之间的合作、推动数字化转型，以及优化数据管理和治理方面也显示出其独特价值。然而，在这一进程中，行业也面临着如可解释性、社会智能等一系列挑战。在<a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5517\">FCon全球金融科技大会</a>\"上，我们邀请了光大信托信息技术部副总经理、数据中心总经理祝世虎 博士，为你分享了大模型在金融领域的应用及其带来的机遇与挑战。以下为分享的重要内容：</p><p></p><p>大数据、大模型与风控的关系：探讨了大数据和大模型如何影响金融领域的风险控制，特别是如何通过数据分析和模型预测来管理和减少风险。大合作与创新：讨论了金融机构与科技公司之间的合作以及这种合作如何促进创新，特别是在开发和应用大型模型方面。关注的问题：提出了金融行业在采用大型模型时面临的一些挑战和问题，例如可解释性、社会智能等。数字化转型对大模型的助力：分析了数字化转型如何助力大模型在金融行业的发展和应用。数据信托与大模型：讨论了数据信托如何帮助管理和优化大模型，特别是在处理和保护数据方面。大模型的治理：探索了在金融行业中应用大模型时需要考虑的治理问题，包括伦理和法律方面的考量。</p><p></p><p>详细内容，请观看完整视频：</p><p></p><p></p><p>活动推荐：</p><p>QCon 全球软件开发大会（上海站）即将在 12 月 28-29 日开始，届时将围绕&nbsp;<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart\">GenAI和通用大模型应用探索</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1596?utm_source=infoqweb&amp;utm_medium=teacherart\">AI&nbsp;Agent&nbsp;与行业融合应用的前景</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart\">LLM&nbsp;时代的性能优化</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart\">智能化信创软件&nbsp;IDE</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart\">面向人工智能时代的架构</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart\">性能工程：提升效率和创新的新方法</a>\"等专题进行交流。现在购票，享 9 折优惠，立减￥680！咨询购票请联系：18514549229（微信同手机号）。</p>",
    "publish_time": "2023-12-08 16:42:48",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "银行如何理解中央金融工作会议「五篇文章」？企业战略须重新审视",
    "url": "https://www.infoq.cn/article/BpAYeYkzIHtJaPlHC5TR",
    "summary": "<p>10 月底召开的中央金融工作会议对中国金融行业的成绩和不足、机会与挑战进行了深层次的论断，提出了新时代的中国特色金融新理论、新道路，对今后的金融工作是一次深刻的调整。会议精神博大精深，笔者仅基于自身多年的银行从业经验，从银行视角对会议精神进行学习、领会，所思所想，供从业者参考，不当之处，请多指正。</p><p></p><p>会议精神从理论到实践，包含历史逻辑、理论逻辑、现实逻辑，覆盖宽广，本文仅总结几个有助于学习会议精神的要点。</p><p></p><h3>一、保持头脑清醒：一种理论、八个坚持</h3><p></p><p></p><p>会议精神的核心是“中国特色金融发展之路”，这是融合了马克思主义政治经济学理论和中华优秀传统文化的中国金融理论，是对全球金融发展经验的借鉴和超越。无论是在金融行业还是在其他行业，都必须有“道路自信”、“理论自信”，东西文化发展路径有差异，西方文化有“多中心、断代式”的演进特点，但我国自身历史发展有“单中心、连续式”的演进特点，对历史的继承和扬弃本就是民族发展的必然模式，所以，中国的金融也必有自己的道路。</p><p></p><p>此外，无论投入了多少精力进行研究，经济危机、金融危机依然是西方经济理论、金融理论无法摆脱的问题，这一点也必然需要从我国国情出发加以研究和解决。每家银行都要基于“中国特色金融发展之路”这个核心理论重新思考银行的经营准则，思考新时代的金融理论，思考如何基于“政治性、人民性”吸收并超越商业银行传统经营理念中的“流动性、安全性、盈利性”原则。</p><p></p><p>全面理解“中国特色金融发展之路”，还需要做到“八个坚持”，“必须坚持党中央对金融工作的集中统一领导，坚持以人民为中心的价值取向，坚持把金融服务实体经济作为根本宗旨，坚持把防控风险作为金融工作的永恒主题，坚持在市场化法治化轨道上推进金融创新发展，坚持深化金融供给侧结构性改革，坚持统筹金融开放和安全，坚持稳中求进工作总基调”。</p><p></p><p>“八个坚持”涵盖了领导方式、价值取向、服务目标、工作底线、创新原则、改革重点、外部连接、工作基调，是一个整体，也是八个制定金融机构战略的检验维度，银行的战略是否得当，要先从“八个坚持”的角度自省自问，是否真的走在“中国特色金融发展之路”上。既有战略应当重新修订了，总体战略、条线战略、技术战略都需要重新审视。</p><p></p><h3>二、坚持身体力行：一套体制、五篇文章</h3><p></p><p></p><p>今年中央成立了中央金融委员会、中央金融工作委员会，组建了金融监督管理局，人民银行也有组织机构调整，新的金融体系正在调整之中，从会议精神上理解，从监管主体和客体的角度，可以将走“中国特色金融发展之路”的关键实施主体分为两大部分，也即监管机构和商业银行。</p><p></p><h4>（一）监管侧</h4><p></p><p></p><p>监管机构除了中央层面设立中央金融委员会、中央金融工作委员会外，各地方党委也要设立金融委员会、金融工作委员会，将党管金融的要求进一步落实到地方党委，金融是一个复杂体，牵涉社会的方方面面，政府、企业、个人均有参与其中，有些金融难题的攻克无法只在金融内部做；金融的价值也主要体现在金融领域之外，而非银行的经营利润上，所以，党管金融需要落实到地方党委，而不仅是传统的专业监管机构，需要更为广泛的地方力量支持金融改革，尤其是在地方债务等问题方面。</p><p></p><p>原有监管机构方面，人民银行取消了县级机构，职能上也更加集中于货币政策和宏观审慎政策双支柱调控框架，“管好货币总闸门”，做好支付体系、信用体系建设。近日，中国人民银行党委书记、行长潘功胜在接受采访时，就“中国人民银行将如何有力有效支持高质量发展和实体经济稳定增长”的问题，总结了四方面的回答，包括“更加注重跨周期和逆周期调节，保持货币信贷总量和社会融资规模合理增长”、“加强与财政、监管等政策的协调配合，持续加大对重大战略、重点领域和薄弱环节的支持力度”、“合理把握利率水平，推动实体经济融资成本稳中有降”、“统筹内外均衡，保持人民币汇率在合理均衡水平上的基本稳定”，充分体现了央行的工作重点。</p><p></p><p>今年新组建的国家金融监督管理总局，已明确监管除证券行业外的所有金融机构，总局的成立加强了对各类金融机构的统一监管，“长牙带刺”是本次会议的明确要求，监管力度将进一步加强，防止各种“伪创新”的出现，“消除监管空白和盲区”，坚持“同一业务、同一标准”。近日，国家金融监督管理总局党委书记、局长李云泽在接受采访时，就“金融监管总局如何进一步提升监管质效？”回答了三方面内容，包括“全面强化“五大监管””、“严格执法敢于亮剑”、“着力加强监管保障”，体现了总局的工作方向。</p><p></p><p>对各监管机构而言，引导金融机构服务实体经济、防范金融风险是共同的使命。</p><p></p><h4>（二）银行侧</h4><p></p><p></p><p>在商业银行方面，“身体力行”的重点是努力做好“五篇大文章”，会议提出的“科技金融、绿色金融、普惠金融、养老金融、数字金融”就是银行今后业务的延展方向，也是本文前述所言，银行既有战略必须调整的原因。</p><p></p><p>“科技金融”立足于对科技企业、科技攻关、科技创新等领域的支持，是为支持科技自主发展所做的战略性业务，将“科技金融”放在五大文章之首，是值得认真思考其深意的，它是未来国际竞争的核心，决定了国家的真实领先水平。</p><p></p><p>但是“科技金融”对银行而言并不轻松，比如笔者为银行讲授数字化转型课程时曾引用的生产汽车“滑板底盘”的企业案例，如何评估这样的企业？“科技金融”中涉及太多、太深的专业知识，而科创企业又无法仅从财务视角衡量企业潜力，知识壁垒是现实存在的，科技信息、科技企业信息的流通如何更有利于银行介入，是一个实实在在的话题。所幸银行的数字化转型开展也比较深入，对数字技术有一定的理解，基于多年的“摸爬滚打”，逐渐通过各种研究学习建立起了初步的科技企业评价框架，一些大型银行在地方分支机构层面还有比较擅长“科技金融”的“科技支行”，但是距离将“科技金融”置于五大文章之首的要求，仍有一定差距，“科技金融”这篇文章银行必须做好，但确实不好做。</p><p></p><p>“绿色金融”面向的不仅是现在，更是未来，如果说“科技金融”关注先进性，那么“绿色金融”关注的自然是可持续性，我国是负责任的环境保护大国，不少企业在“绿色工厂”等方向上有大量投入和创新，节能技术、排放交易都有长足发展，银行自身也在数字化过程中不断提升数据中心的“绿色”程度。但是，“绿色金融”的快速发展仍然需要来自顶层设计的支持，如何将企业的环保行为、环保评价更有激励性的转化为信用评价，如何为绿色信贷、绿色债券增加更好的外部信用支持，需要整个体系的努力。“绿色金融”是银行一定要去做、要长期做，更要少计得失地去做的文章。</p><p></p><p>“<a href=\"https://www.infoq.cn/article/HzpHzgZF7ZhGZiYGvtl0\">普惠金融</a>\"”不仅是我国金融要面对的问题，也是世界级难题。“普惠金融”总体而言属于典型的“长尾业务”，也即利润薄、风险高，需要高度经营技巧的业务，主要面向的群体是中小微企业，以及净资产不高的个人客户，难题主要在信贷类业务上。</p><p></p><p>“普惠金融”就业务对象而言，在信贷类业务上要把握的核心原则可能是适度，准入规则适度、利率价格适度、放款规模适度、信贷周期适度，过严、过高、过大、过短，虽然有利于银行业务管理，但于客户而言，于“普惠金融”的本意而言则是不合适的，当然，也不能过松、过低、过小、过长，所以，把握度，“一户一策”是最难的，就行业早年引进的一些国外经验看，面向中小微企业的“普惠金融”业务需要投入大量人力来做信息核实、现场核实，还需要持续跟踪，所以客户经理的服务半径始终有限，近年来随着数字化水平的提升，单个客户经理可以真实有效维护的客户数量已经突破了 200 以上，当然，数字化对效率的提升仍需长期观察其实效，不能单纯看眼前数量的提升。不过，数字化水平不高的银行，暂时还达不到这种维护能力。</p><p></p><p>“普惠金融”要解决的问题对经济而言非常重要，毕竟就业的核心是中小微企业，而就业是经济发展的重要目标，也是社会稳定的基础。“普惠金融”这篇大文章的核心就是责任，它解决的是稳定性问题，但“普惠金融”就其业务范围和模式而言，对信息是高度依赖的。</p><p></p><p>“养老金融”是伴随人口老龄化的现实发展起来的新机遇，“养老金融”涉及的不只是老人，也包括年轻人对养老的规划，所以，是个“老中青”三结合的领域，涉及适老性服务、资产理财、财务规划等，可以贯穿个人客户的全生命周期。除了本次会议将其作为“大文章”提出外，国务院日前印发的《关于推进普惠金融高质量发展的实施意见》中也有“完善适老、友好的金融产品和服务，加强对养老服务、医疗卫生服务产业和项目的金融支持”的要求，养老金融的发展是需要跨行业信息互联互通的。“养老”是社会文明的体现，出自《礼记》的“老有所终”正是前人对“大同”社会的追求。所以，“养老金融”这篇大文章即要充分体现人民性，更要体现文明性。</p><p></p><p>“数字金融”是银行业做了近四十年的文章，但是对这篇文章的描述方式一直有变化，从电算化、信息化、网络化、金融科技到现在的数字金融，走到数字金融真的是在中国式现代化的大背景下找到了定义的归宿，从数字中国到数字经济，之下必然是数字金融，这样的定义方式才是符合“2522”整体规划的。</p><p></p><p><a href=\"https://www.infoq.cn/article/ROrh4hSJPu1UkXzx5Uhc\">如同笔者之前文章阐述</a>\"的，“数字金融”的理解可以有两层含义，一是对银行自身，只有数字化的银行，才能充分做好科技金融、绿色金融、普惠金融、养老金融这四篇大文章，因为这四篇大文章都离不开信息，也就是数据要素的互联互通，离不开基于数字技术分析和处理数据要素，离不开通过数字技术实现更好的金融服务嵌入，也就是基于数据、工具、网络这三大抓手实现深度的业技融合的数字化转型，可以说，数字金融就是充分利用数据要素、运用数字化手段服务好实体经济、防范好金融风险的金融形态，是与数字经济大背景融合的金融。这四篇大文章落实起来都需要结合场景做具体的业务实现，但是场景多数在客户侧、在上游，也不需要金融机构非要去自建，做好场景的融入即可，上游开放场景，下游自由接入场景，让客户在场景中选择，而不是银行试图去控制场景。</p><p></p><p>另一层含义则是对其他行业数字化的支持，既包括资金支持（此处不同于科技金融，是面向企业一般性业务转型而言的资金支持）也包括技术信息、技术能力支持，毕竟银行有丰富的数字化经验，本就该创造数字化转型理论、输出转型能力，不少银行也成立了数字科技公司，这些数字科技公司在这五篇大文章背景下的定位是该深入思考的。“数字金融”本就是银行在持续做的文章，这篇文章对银行而言，没必要再总去纠结其价值性了，作为前四篇文章的重要支持，作为数字时代银行的基本特征，银行需要问的不是“数字金融”的价值，而是另外四篇文章需要的“数字金融”是什么，这个社会需要的“数字金融”是什么，所以，“数字金融”这篇文章要体现的是时代性，是一个如何能用<a href=\"https://www.infoq.cn/article/FK7BvgSk0p340NFjN6rZ\">数据要素</a>\"、数字化手段高效做好另外四篇文章的基本功问题，也是银行对数字化的理解是否符合国家政策导向、是否可以与其他行业共融的问题，不是银行问数字化的价值，而是要问自己为数字中国贡献的价值，带着反思，面向经济、客户去做数字化。</p><p></p><p>先进性、可持续性、稳定性、文明性、时代性，可能是做好这五篇大文章时需要思考的问题，这些问题综合起来可以体现政治性、人民性，同时，贯穿这五篇大文章的共性命题就是“服务实体经济，防范金融风险”。</p><p></p><p>要做好这五篇大文章还有一点值得注意，那就是这五篇文章中，除了“数字金融”外，其他文章之前在银行总体战略中的站位、总体业务中的占比都不算太高，而且不能与较强的盈利性直接挂钩，至于这一点，即便是“数字金融”也一样，那么，这就意味着银行的价值取向、总体战略、业务评价方式应该改变了。在五篇大文章方面，银行应多“秀”服务，少“秀”业绩。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0f/0fc84c87bd9f7e83794ab547a4807b94.jpeg\" /></p><p></p><h3>三、秉持大道为公：政通人和、脉畅体健</h3><p></p><p></p><p>“大道之行也，天下为公”。金融“必须坚持党中央对金融工作的集中统一领导，坚持以人民为中心的价值取向，坚持把金融服务实体经济作为根本宗旨”，这是金融安身立命之道，通过银行的金融业务、经营行为，将国家政策落实到实体经济，落实到微末毫厘，才能使自身真正成为经济的血脉，才能通过血液的流动，助力实现政令通达、人民安居、经济健康，这是金融的使命，是金融理论创新、金融实践革新的目标，也是只有走“中国特色金融发展之路”才能实现的目标。</p><p></p><h4>作者介绍</h4><p></p><p>付晓岩，《企业级业务架构设计：方法论与实践》、《银行数字化转型》和《聚合架构：面向数字生态的构件化企业架构》三书作者。北京天润聚粮咨询服务有限公司执行董事总经理，数孪模型科技公司高级副总裁；工业和信息化重点领域数字化转型与人工智能产业人才基地专家委员会副主任；中国计算机学会软件工程专委会委员；信通院企业架构推进中心、组装式推进中心技术专家；中华全国数字化人才培育联盟专家委员会特聘专家；工信部中小企业发展促进中心产教融合产业实践教授；国家工程实验室金融大数据应用与安全研究中心研究员；CIC 金融科技与数字经济发展专家委员会成员；国家互联网数据中心产业技术创新战略联盟专家委员会副主任专家委员。</p><p></p><h4>内容推荐</h4><p></p><p>11 月 19 日 -20 日在上海成功举办的首届 FCon 全球金融科技大会，以「科技 + 金融，激发创新力量」为主题，汇聚了来自金融龙头企业的数百名技术高管，掀起一场探讨新时代金融科技未来的高潮。经征得大会分享嘉宾同意，InfoQ 数字化经纬为您奉上精彩演讲 PPT！关注「InfoQ 数字化经纬」，回复「金融创新」即可获取 PPT，深度洞悉科技趋势，助您引领金融创新未来！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/af/afc55058ba66a0cd61acf97f02db59a1.png\" /></p><p></p>",
    "publish_time": "2023-12-08 17:33:21",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "国内首份“图风控”报告发布：图风控成应对新型网络安全风险的关键性技术",
    "url": "https://www.infoq.cn/article/qcE019AscmDYTUJUfIHX",
    "summary": "<p>12 月 8 日，国内首份《图风控行业技术报告》（以下简称“报告”）在北京发布，指出智能风控迈入“全图时代”，图智能应用于<a href=\"https://www.infoq.cn/article/TDdJaEAY6dBu474REtL0?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">风控</a>\"领域形成的“图风控技术”成为应对 AI 时代复杂风险形势的下一代风控基础设施和关键性技术。报告认为，图风控充分利用了海量数据时代的数据关联性特征，实现了大规模时序关系图的高效构建及全周期实时风险识别，在解决黑产复杂隐蔽、信息孤岛等挑战，挖掘更多隐藏风险等方面提供了强大的技术功能和应用价值。</p><p>&nbsp;</p><p>据了解，该报告由<a href=\"https://www.infoq.cn/article/bjCH8kMloxFUfp00WQIX?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">蚂蚁集团</a>\"、清华大学、北京邮电大学、中山大学、上海交通大学、复旦大学、之江实验室和<a href=\"https://www.infoq.cn/article/EE2bAVOOWa0K_g5lLh7j?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">阿里巴巴</a>\"淘天集团联合编写，中国人民大学国际货币研究所（IMI）、金融科技50人论坛（CFT50）提供学术支持，详细呈现了新型数字风险态势、图风控算法技术、图数据库等底层基础设施，并提供了丰富的行业应用案例。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/ed/ed12501a3e99fa960e9b079af7002bb6.png\" /></p><p>图：《图风控行业技术报告》发布现场</p><p>&nbsp;</p><p>数字化智能化的颠覆性变革正在带来全新的安全挑战。尤其是 AI 大规模渗透应用引发新一轮智能化浪潮，带来新型数字经济网络中数据复杂度和关联性呈几何倍增，也带来了更加复杂、隐蔽、强对抗和更具破坏力的安全威胁。传统的风控方式已难以抵御多样化的风险形势，越来越多的场景需要更智能化的技术利器。图风控技术的出现，提供了一种解决问题的利器。</p><p>&nbsp;</p><p>课题组专家、北京邮电大学教授、博士研究生导师石川在报告中指出，智能风控技术历经专家策略、机器学习和深度学习的演进，如今图智能技术正逐渐成熟。在金融、电商、安全、社交等领域，风险涉及多个实体之间的复杂交互关系。图智能技术以更直观、高效、智能的方式表达和分析这些交互关系，助力系统发现潜在风险中的隐藏模式和异常，进而提升对潜在风险的准确性和及时性识别。</p><p>&nbsp;</p><p>具体来说，“图”是一种以点和边来表示实体和关系的数据结构；“图智能技术”指包括图数据库、图计算引擎、图神经网络、图可解释等一系列和图有关的人工智能技术通称，是最适应大数据海量、动态等特征的技术之一；应用于风险控制领域而形成的“图风控技术”，可以聚合风险事件、交易属性、关系图谱、专家特征等各类动态变化的风险数据，结合图结构数据的可解释性，实现对风险全链路、基于关系视角的刻画，为风控从业者提供更加全面、可见、实时的风险监测并及时决策。因此，运用图技术提升风控系统能力，正成为行业的新发展趋势。</p><p>&nbsp;</p><p>图风控技术目前在业界已有成熟应用，涵盖支付风控、信贷风控、电商风控，以及供应链、网络安全和基础设施安全等多个领域，是金融机构、安全服务商、新兴初创企业，以及大型科技公司逐浪的“风控风口”。</p><p>&nbsp;</p><p>蚂蚁集团副总裁、大安全事业群总裁赵闻飙在报告中表示，数字经济时代，安全的重要性日益凸显。图风控技术作为蚂蚁集团重点研发投入的创新技术之一，现已成为强化风险管理的利器，对构筑坚固的安全防线作出了重要贡献。</p><p>&nbsp;</p><p>报告显示，蚂蚁集团从 2015 年开始探索图技术，推出了底层自研的大规模图风控基础设施 TuGraph。基于 TuGraph 布局的全图风控体系，打造了万亿级点边规模的全域风险大图，目前已全面应用在业务场景中，不仅实现了支付过程的毫秒级极速风控，支撑了高频交易的高精准度识别，还显著降低了资损率，提高了反欺诈和反洗钱等安全业务的效率。</p><p>&nbsp;</p><p>据了解，全图风控是蚂蚁集团智能风控体系“IMAGE”的重要组成部分。该体系还包括交互式主动风控、端边云协同风控、多方安全风控、智能对抗，支撑了支付宝资损率连续三年低于亿分之一，为解决风控的智能化、主动性、可预测性、隐私保护等世界级难题提供了新突破，获得 CCF 科学技术奖、吴文俊人工智能科学技术奖、浙江省科学技术奖等多个权威奖项。</p>",
    "publish_time": "2023-12-08 17:51:28",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "数据库产品层出不穷，金融行业应该怎么选？｜飞轮科技联合创始人连林江",
    "url": "https://www.infoq.cn/article/vhjghWP18LoJUmfXiuhE",
    "summary": "<p>众所周知，金融行业对于数据有着极为严苛的标准和要求，尤其当在线化、实时化业务场景增多以后，金融行业也面临着多重的挑战：既要满足实时数据分析的高性能、高效率需求，又要确保数据的安全性和完整性。基于此，金融行业对数据服务的选型也会格外谨慎与困难。尤其是在各类数据库产品层出不穷的当下，金融行业到底应该如何选型？怎样的产品才更加符合金融行业的未来发展？</p><p></p><p>在 FCon 全球金融大会的大会现场，InfoQ 也采访到了飞轮科技联合创始人连林江，他本人长期投身在大数据、基础架构和云计算领域，过去 12 年一直在百度工作，曾担任百度智能云副总裁、大数据与云存储等部门总经理，从零到一开拓出数十款云产品及数十亿营收。目前致力于推广开源 Apache Doris，并基于 Apache Doris 内核打造了实时数仓产品 SelectDB ，助力中国邮政储蓄银行、银联商务、平安人寿等多家头部金融企业升级了实时数据仓库平台。关于金融领域客户对实时分析场景的痛点与解决方案，他在采访过程中分享了自己的观点。以下是视频采访的全部内容，为方便读者查看，视频下方也附上了文字内容。</p><p></p><p> InfoQ：金融行业对数据服务的需求主要集中在哪些方面？包括对实时数据仓库的需求点主要是在哪些方面？</p><p></p><p>连林江：金融行业在数字化转型上走得相对靠前，无论是技术力量的投入，还是对新技术的使用都非常深入，但聚焦于数字化转型，依然面临着很多诉求和挑战。</p><p></p><p>从业务需求看，可以看到金融行业的业务更多地开始走向在线化，消费者金融业务、企业金融业务等都大量 APP 化，这些在线化的变化都带来业务感知、风控、客户洞察和决策等业务路径的实时化要求，所以就需要做更实时的消费信贷、欺诈交易识别、客户行为洞察等等动作。可以看到，金融行业服务客户的时间、路径都比以前更短了，也就需要更快的数据分析和响应速度。</p><p></p><p>从技术角度看，新技术给金融业务带来了更多业务变革的可能性，对技术的超前建设、对前沿技术趋势的预判也尤其重要，所以我们看到很多行业客户都开始设立金融科技部、信息科技部这样的战略组织，来全盘推进金融科技的战略。</p><p></p><p>但很多金融行业在大数据建设上，普遍还存在滞后性、复杂性。举例来说，很多的金融企业在一定程度上复刻了原来互联网公司走过的大数据建设路径，基于 Hadoop 构建了大数据平台，并在此之上建设了大量的系统以应对不同业务的挑战，比如有批量处理分析系统、实时处理分析系统等等，少则十来个，多则可能几十个。所以从技术规划和发展趋势的角度来说，金融行业的大数据系统需要化繁为简，架构需要更简单、更高效。</p><p></p><p>此外，大数据的技术发展是日新月异的，如何能够紧跟时代变化也是金融行业面临的另一挑战。</p><p></p><p>&nbsp;InfoQ：那么，金融领域的企业如何找到一款适合自身业务的数据库产品？您能否从实时数据仓库选型的角度给一些建议？</p><p></p><p>连林江：第一，从需求出发。刚刚也提到了金融行业的业务开始走向在线化，更需要一个实时的数据库应对业务挑战，同时还需要解决一系列随之而来的如何用好的问题，比如数据如何集成、如何治理、如何面向业务进一步调优等；第二，看清楚未来的技术趋势。技术的日新月异往往带来不断的更新换代，这其实是一个不断迭代的过程，因为系统的建设是滞后于技术发展的，可能造成的局面是今天投入力量进行系统升级了，过一两年又在新技术的冲击下需要迭代。而我们对大数据未来趋势的判断是朝三个方向发展：实时化、统一化以及云原生化，所以也建议金融领域的企业用户能够选择面向未来、符合技术趋势的产品；第三，关注产品的开放性。所谓开放性指的是尽量选择能够代表行业标准的产品，类似像数据库领域的 SQL 这种标准接口语言，这类标准性带来的是更开放的选择，以及未来历史资产的继承性。纵观大数据技术，开源其实一直在引领大数据产业发展，开源能够非常好地促进标准，也能够带来开放性。</p><p></p><p>&nbsp;InfoQ：刚好连总也讲到了开源这个因素，我们知道 SelectDB 是基于开源的 Apache Doris 来开发的，对于金融行业而言，开源是否是企业选型的重要考虑点之一？</p><p></p><p>连林江：我今天看到很多金融领域的企业，他们普遍对前沿技术有非常强的敏感性和开放性。从实际的交流观点来看，大家对于开源技术的认可和采用也是普遍趋同的。为什么呢？</p><p></p><p>第一，如刚刚提到的，开源本身能够很好地带来标准性，因为开源在开发者群体里是一种市场经济化的行为。一个好的开源产品如果被大家认可了，便能够引发更大范围、更广泛的使用，这个过程天然具有很大的可信度和标准性，所以优秀的开源产品一定有它的独特优势和普遍适应性；第二，一个开源项目要想发展好，它一定要有持续的先进性，这也会给产品带来持续的、蓬勃的生机；第三，金融对自主可控的要求比较高，而由于开源的代码可以共享，使其具备了自主可控的特性，如果企业有能力就可以很好地掌控、投入建设，便能在这个社区里得到一加一大于二的效益。</p><p></p><p>我认为开源是对金融企业来说是一个非常有前景的平台建设路径，它能提供更强的生命力和正向循环。通过开源也可以让我们的产品得到锤炼，对我们自身而言也是一个机会。就像 Apache Doris 是从百度的海量数据场景里锤炼出来的，通过开源又广泛地吸收了多行业、多场景的需求，让其能够更快地蓬勃发展。所以我们可以看到，金融领域的企业以及开发者对开源是非常认可的，也是很愿意投入，并且是在持续做建设的过程。</p><p></p><p>&nbsp;InfoQ：众所周知，金融是对数据要求极高的行业，因此也是不少数据库厂商的竞争高地，相比于其他金融级数据库，SelectDB 的核心优势是什么？</p><p></p><p>连林江：从公司设立的第一天起，我们就非常清楚自己的定位——实时数仓，实时性是产品的第一要求。</p><p></p><p>要对数据做到实时分析，最重要的是解决好两个延迟问题，数据集成的低延迟和数据查询的低延迟。换而言之，数仓必须能满足数据进得足够快、同时能够实时可见支持秒级的查询。</p><p></p><p>因此我们在实时性上进行了大量的技术创新，包括支持毫秒级的实时数据写入、实时增删改的主键存储模型、实时追加的明细和聚合存储模型以及毫秒级轻量化表结构更新等，可以实现数据的实时导入与实时可见。而在实时查询方面，SelectDB 在高并发点查询、大宽表查询、复杂多表关联等多种查询负载上都拥有极速性能。在全球分析型数据库测评榜单 ClickBench 中，SelectDB 更是凭借在多种场景下的卓越性能表现，占据性能全球排名第一的位置。</p><p></p><p>在定位之外，还要进一步看清大数据的发展形势，当前企业普遍使用典型的湖仓并行架构方案，既有面向批量的多个组件、也有面向交互分析的多个组件，甚至不止一个湖一个仓。基于此，我们提出了统一化的理念，简化当前复杂的架构，尽可能减少数据组件；特别值得一提的是，我们也在不断地完善湖仓一体方案，采用了 SelectDB 的现代化数据平台方案将数据仓库和数据湖进行融合统一，在一套架构中为 BI 报表、Adhoc 分析，以及批量和增量 ETL 等多种业务负载提供统一的数据处理和分析能力。</p><p></p><p>此外，针对有上云需求的客户，会更加在意云服务的性价比和资源弹性。SelectDB 也是从开始就把云产品当成核心来做，在去年 10 月份我们就推出了第一款云原生产品，也是国内第一款立足于多云之上、完全 SaaS 化的云原生数据仓库 SelectDB Cloud，目前已经支持阿里云、华为云、腾讯云和亚马逊云科技等国内外主要云厂商。</p><p></p><p>除了上述提到的优势以外，SelectDB 还有架构简单和生态丰富的特点。当金融客户要将历史资产迁移到 SelectDB 上时，能够很好地保障企业用户数据的迁移以及集成。考虑到很多金融客户的大数据系统上、下层都有联动，所以 SelectDB 也与数十家合作伙伴做了产品互兼容、互认证以及方案打通。</p><p></p><p>最后一点，由于金融客户的特殊性，持续的陪伴和服务能力也是更为重要的。在这一点上，我们其实也做了很多的建设和投入，目前在国内有 7 个分支机构，会安排售前、售后等支持人员，为他们提供可靠的服务保障。</p><p></p><p>&nbsp;InfoQ：相比于其他实时分析的需求场景，金融行业的应用软件是否有哪些额外的关注点？SelectDB 会采用哪些方案进行保障？</p><p></p><p>连林江：对于互联网行业而言，他们更喜欢在云上一站式地选购 SaaS 化的产品，既能做到开箱即用，产品之间也有很好的联动性。但对于金融企业而言，出于对可靠性或监管的要求，大量系统建设都是私有化独立部署的。对此，我们做了大量金融企业级产品的工作：</p><p></p><p>首先，我们为金融行业打造了企业版，可以私有化部署在各种环境下，比如虚拟机、物理机、云原生基础设施或者私有云，我们都能为其提供非常高效的部署，以及简单、易用、易运维的能力。其次，金融客户对数据以及整个 IT 基础设施的安全性要求是非常高的，我们除了保证单一软件系统的高可靠性、高可用性以及完整的权限系统外，我们尤其加强了容灾备份的能力，提供了本地双集群和多地多中心集群之间 CCR 的能力，一旦有服务断掉了，马上能够秒级分钟级的启动。</p><p></p><p>&nbsp;InfoQ：是否方便分享一个 SelectDB 在金融场景的落地案例？</p><p></p><p>连林江：SelectDB 在整个金融行业服务的客户非常多，包括银行、证券、基金等等。这里我可以分享一个国有大行在金融反欺诈上的实践案例。</p><p></p><p>因为国有大行本身有非常多的网点和客户，在这基础上做业务的在线化，就需要在事前、事中、事后做很多的风控判断和处理。尤其对于反欺诈行为来说，过了一天可能损失是追不回来的，所以基本上要达到秒级，最差分钟级的反馈闭环。此外，由于反欺诈行为更多发生在终端，国有大行有数万个网点、亿级的用户，需要有几万甚至几十万的并发来支撑，这对于技术有非常强的要求。另外，作为一个建设的平台方，它还需要管理起来更简单、数据高可靠，而且每次数据统计都是精确无误的。这些特性决定了它的选型非常苛刻，所以他们也做了非常多的评测，最后整体认为 SelectDB 的技术是最符合要求的，比业内同款产品的性能要高出几倍、几十倍。</p><p></p><p>现在客户实际落地用下来效果非常好，如果用以前的老架构去实施，效果可能是小时级甚至是 T+1，现在做到了秒级的实时性，所以也在大力推广更大规模使用。他们也在规划更多的落地场景，也想让日志分析用到我们的技术，把原来做指标观测、订单分析查询的系统都替换掉，而且整体的成本投入只需要以前方案的三分之一到五分之一。这个客户整体上讲，SelectDB 不仅很好地满足了业务方需求，也更好地满足了建设方需求。</p><p></p><p>&nbsp;InfoQ：后续，SelectDB 将如何服务好更多金融领域的客户，基于此，我们是否有相应的规划？</p><p></p><p>连林江：从技术角度，我们会在实时化、统一化、云原生化三个方向上持续投入和迈进，这很好地满足广大企业客户的需求；今天，大量的金融客户也已经从中获得了收益，我们也会齐头并进继续做深技术创新。</p><p></p><p>从业务场景，我们会沿着用户的业务场景做深入的优化。比如针对画像行为分析，我们进行函数的设计、业务流程优化；针对数据分析，做实时报表、辅助决策、日志分析，甚至 AI 的数据分析，这些都是更加深入的场景化思考和落地实践。这就意味着我们的技术和业务是双向迭代的过程。</p><p></p><p>在金融领域，当前数据分析的技术和业务场景是非常多的，这其中对于数据的存储和数据的处理其实是一个非常基础性的要求，在这之上应用场景的需求满足更需要端到端的解决方案能力落地，这就需要和领域内的广大生态厂商一起努力。比如，我们跟一些 BI 厂商联合做指标分析，效果就比以前提升了好多倍，这些场景方案能力最后都会在广大的金融客户场景中释放出效益。后续，我们也希望和更多的合作伙伴一起提供更多端到端的场景化方案</p><p></p><p>&nbsp;写在最后</p><p></p><p>作为全球数据库和大数据领域最活跃的开源社区之一 Apache Doris 的商业化公司，我们看到了 SelectDB 在实时化、统一化、云原生化方向上的坚定投入。我们也期待随着 SelectDB 在金融领域商用化程度的不断加深，以及端到端金融联合解决方案的持续补充，未来将帮助更多金融领域的企业释放数据价值。</p>",
    "publish_time": "2023-12-08 17:58:31",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "夸克大模型通过备案 将升级通识、健康、创作等搜索产品与智能工具",
    "url": "https://www.infoq.cn/article/d4rIQ0vpsW9b06qToiji",
    "summary": "<p>日前，记者获悉阿里智能信息事业群自研的夸克大模型已通过备案，将陆续在通识、健康、创作等领域升级内容产品与智能工具，并落地一系列 AIGC 创新应用，借助大模型能力全面升级夸克，提升用户在学习、工作、生活上的效率。</p><p></p><p>今年下半年，国内多款大模型已经完成备案且能力水平部分超过 GPT-3.5，广大用户也都期待爆款产品的出现以更好地解决方方面面的实际问题。作为深受年轻人喜欢的信息服务产品，夸克App将在自研大模型的助力下，加速迈向年轻人的AI助手。</p><p></p><p>今年11月中旬，阿里巴巴智能信息事业群发布全栈自研、千亿级参数的夸克大模型，将应用于通用搜索、医疗健康、教育学习、职场办公等众多场景。夸克大模型也凭借四大优势，接连登顶 C-Eval 和 CMMLU 两大权威榜单。同时在法律、医疗、问答等领域的性能评测中夺冠，成为了名副其实的“学霸”。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a2/a2026ddaf74dacff9fec92c89fb31921.png\" /></p><p></p><p>清华大学新闻学院教授、博士生导师沈阳认为，依托搜索平台，夸克大模型拥有高质量的各类数据，在中文语境下，模型能力处在行业领先水平。在教育、医疗等垂直领域中，夸克在对话、解题上的能力取得了新的突破，是国产自研大模型的优秀代表之一。</p><p></p><p>夸克相关负责人表示，夸克大模型是面向搜索、生产力工具和资产管理助手的应用型大模型。在搜索应用中，将通过图文多模理解、专业知识生成、交互方式创新进一步拓宽应用场景，提升用户体验。同时，在健康等垂直领域中，夸克将依托大模型能力，提供更加实用的信息服务。</p><p></p><p>目前，夸克 App 已经为数千万 95 后职场人和大学生提供了跨场景的智能效率工具。根据 QuestMobile发布的《2023年轻人群智能效率应用研究》报告显示，夸克 App 在泛学生人群和新生代职场人群的用户占比最高，年轻用户使用时长位列行业第一。</p>",
    "publish_time": "2023-12-08 18:16:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]