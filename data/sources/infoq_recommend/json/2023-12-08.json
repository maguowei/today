[
  {
    "title": "架构师（2023 年 12 月）",
    "url": "https://www.infoq.cn/article/Pu0szgrG5sJuOl8AV2tr",
    "summary": "<h2>卷首语：俭约架构师的七大黄金法则</h2>\n<p>亚马逊 CTO Werner Vogels 向企业传达了一条信息：在管理云成本方面，是时候成为节俭的架构师了。</p>\n<p>他拥有近 20 年的平台构建经验，在今天的 re:Invent 2023 大会主题演讲中，给大家上了一节关于成本优化的课：“作为技术专家，我们生活在一个瞬息万变的世界，我们需要保持学习，坐下来，拿出你的记事本，现在开始做笔记。”</p>\n<p><strong>法则一：将成本视为一种非功能性需求。</strong><br />\n架构师需要尽可能早的、以更加可持续的方式考虑成本影响，才能在系统设计过程中在功能、上市时间和效率之间寻求平衡。</p>\n<p><strong>法则二：确保系统的最终成本与业务保持一致。</strong><br />\n系统能否长治久安，取决于其成本是否与业务模式高度匹配。在设计和构建系统时，架构师必须考虑收入来源和利润杠杆。更重要的是，必须找到能够产生利润的维度，确保架构规划始终围绕收益展开。</p>\n<p><strong>法则三：架构设计是一系列权衡的集合。</strong><br />\n在架构当中，每项决定都涉及相应的权衡。在技术与业务需求间找到适当的平衡将至关重要。请记住，节俭是为了最大限度提升价值，而不只是尽可能控制支出。因此，在必须得花的钱上别吝啬。</p>\n<p><strong>法则四：无法观察的系统将带来无法估量的成本。</strong><br />\n尽管实现可观察性需要投入，但这笔钱绝对会物有所值。有句格言说“如果无法量化，也就无法管理。持续检查能帮我们发现非必要支出，并调整运营以减少浪费。总之，可观察性带来的回报往往远超过前期投入。</p>\n<p><strong>法则五：依托成本感知架构实现成本控制。</strong><br />\n节俭架构的本质，在于强大监控与成本优化能力的结合。明确定义各层，即可在成本及其他要求之间求得平衡。对组件的精细控制则能优化成本和体验。</p>\n<p><strong>法则六：成本优化是个渐进的过程。</strong><br />\n追求成本效率是个持续的过程。即使在部署之后，我们也必须随时审视系统以逐步寻求优化。看似微小的优化，累积起来足以产生超出想象的成本优势。</p>\n<p><strong>法则七：顺风局打多了会让人盲目自信。</strong><br />\n软件团队经常陷入这样的陷阱：仅凭以往的工作经验，他们就认为当前的技术、架构或语言永远是最佳选择。这可能会产生一种错误的安全感，阻碍对现状的质疑，更会打击对可能更加高效、更具成本效益或可扩展性更强的新选项的探索。</p>\n<h2>目录</h2>\n<p><strong>热点 | Hot</strong></p>\n<p>全球首款经安全认证的开源实时操作系统！开发了 20 多年、部署在超 120 亿台设备上的 ThreadX 正式开源</p>\n<p>省钱在于“架构师”！亚马逊 CTO 20 年架构经验之道：俭约架构师的七大黄金法则</p>\n<p>联手 OpenAI 最强竞对展开生成式 AI 反击战：亚马逊云科技将 S3 写入速度提升 10 倍、推出全新三层技术栈</p>\n<p>疯狂马斯克的“极限”计划居然成功了？！“下云”后成本降低 60%，部分功能代码精简 90%，30 天急速迁移服务器</p>\n<p>微软发布开源平台 Radius：高效构建、运行云原生应用程序</p>\n<p><strong>访谈文章 | Interview</strong></p>\n<p>主力开发已经 68 岁了！“老龄化”严重的 Postgres 开源社区呼唤“年轻一代”</p>\n<p>美图的这 100 天：三月三版本，大模型博弈中谁能笑到最后？</p>\n<p>是时候基于云重新设计 Kafka 了！AutoMQ 如何实现 Kafka 十倍的降本增效</p>\n<p><strong>案例研究 | Case Study</strong></p>\n<p>一个失败的 AI 女友产品，以及我的教训：来自一位中国开发者的总结</p>\n<p>从 ES 到 Clickhouse：信息技术发展的新浪潮</p>\n<p>GitHub 基于大语言模型构建 Copilot 的经验和教训</p>\n<p><strong>推荐文章 | Article</strong></p>\n<p>从谷歌 20 年站点可靠性工程（SRE）中学到的 11 个经验教训</p>\n<p>无服务计算，厂商究竟在打什么算盘</p>\n<p>我，技术不过硬，但是团队里的重要“胶水”</p>\n<p>是时候彻底放弃“高分低能”的 Leetcode 了：AI 时代的面试需要大变革！</p>\n<p>Docker 的诅咒：曾以为它是终极解法，最后却是“罪大恶极”？</p>\n<p><strong>特别专题｜我们需要纯向量数据库吗</strong></p>\n<p>数据库内核杂谈：向量数据库（一）</p>\n<p>数据库内核杂谈： 向量数据库（二）</p>\n<p>数据库内核杂谈：向量数据库（三）</p>\n<p>数据库内核杂谈： 向量数据库（四）</p>\n<p>向量数据库？不要投资！不要投资！不要投资！</p>\n<p>AutoGPT 放弃向量数据库！向量数据库是小题大作的方案？</p>\n<p>向量数据库失宠了？OpenAI 力捧检索增强生成（RAG）技术，对行业来说意味着什么？</p>\n<p><strong>特别专栏 | 视频推荐</strong></p>\n<p>欢迎阅读 InfoQ 架构师电子刊！每个月，我们都会为你带来行业同行关于新兴技术和模式的重要新闻及经验。</p>\n<p>本月，我们聚焦“AI Agent”这一话题。</p>",
    "publish_time": "2023-12-08 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Web ML 库 Transformers.js 提供文本转语音功能",
    "url": "https://www.infoq.cn/article/N1vpady26bKq23GOZNqQ",
    "summary": "<p>JavaScript 库 Transformers.js 提供了类似 Python Transformers 库的功能，设计用于在 Web 浏览器中直接运行 Transformer 模型，而不再需要外部服务器参与处理。在最新的 2.7 版本中，Transformers.js 引入了增强功能，其中包括文本转语音（TTS）支持。这次升级响应了用户的诸多需求，扩展了库的应用场景。</p><p></p><p>文本转语音（TTS）包括从文本创建听起来比较自然的语音，并提供了多种口语语言和 speaker。目前，Transformers.js 只通过 Xenova/speecht5_tts 提供 TTS 支持，而 Xenova/speecht5_tts 基于微软提供的带有 ONNX 权重的 SpeechT5。未来更新计划中包括增加对 bark 和 MMS 的支持。</p><p></p><p>开发人员可以通过 @xenova/transformers 中的管道函数来使用文本转语音功能，包括指定“文本转语音”任务和要使用的模型（'Xenova/ speecht5_ts '），并使用选项{quantized: false}。此外，其中还包含提供 speaker embeddings 的文件链接。</p><p></p><p>将 TTS 模型应用于给定的文本后，它就会输出音频数组和采样率。该数组表示合成语音，可以进一步处理或直接在浏览器中播放。</p><p></p><p>Transformers.js 适用于各种用例，包括风格转换、图像绘制、图像着色和超分辨率。它的多功能性和定期更新使其成为开发人员探索机器学习和 Web 开发结合点的宝贵资产，并使其成为 Web 机器学习领域的可靠工具。</p><p></p><p>按照设计，Transformers.js 在功能上等同于 Hugging Face 的 Python 库 transformers，也就是说，你可以使用非常近似的 API 运行相同的预训练模型。</p><p></p><p>Transformers.js 支持许多任务和模型，涉及自然语言处理、视觉、音频、表格数据、多模态应用和强化学习。该库涵盖了从文本分类和摘要到图像分割和对象检测的各种任务，这使其成为各种机器学习应用程序的通用工具。</p><p></p><p>Transformers.js 提供了广泛的模型支持，包括 BERT、GPT-2、T5 和 Vision Transformer（ViT）等架构，确保用户可以针对特定的任务选择正确的模型。</p><p></p><p>对于 Transformers.js 的发布，社区持积极态度。在今年早些时候发起的 <a href=\"https://www.reddit.com/r/LocalLLaMA/comments/14w0p1p/transformersjs_thoughts/\">Reddit 帖子</a>\"中，用户 Intrepid-Air6525 表示：我决定用它来代替 openai 的嵌入模型。速度非常快。我实际使用的 LLM 是 webLLM ，因为我不想消耗太多的 CPU 处理。</p><p></p><p>用户 1EvilSexyGenius 对 Hugging Face 的市场定位以及关于实际应用的讨论发表了看法：</p><p></p><p></p><blockquote>[…] 借助 Transformers.js 及他们提供的其他优秀的库，很显然， [Hugging Face] 正在努力实现语言模型的民主化，并将它们带给大众。与每天发布的所有模型相比，这样的帖子会让这个社区受益匪浅。</blockquote><p></p><p></p><p>感兴趣的读者可以从 <a href=\"https://huggingface.co/docs/transformers.js/index\">Hugging Face Transformers.js</a>\" 官方网站及其 GitHub 库中获得更多信息。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/11/transformersjs-ml-for-web/\">https://www.infoq.com/news/2023/11/transformersjs-ml-for-web/</a>\"</p><p></p><p></p><p></p><p></p><p></p><p></p>",
    "publish_time": "2023-12-08 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Timescale 推出无服务器数据库的替代方案Dynamic PostgreSQL",
    "url": "https://www.infoq.cn/article/BX5Ee69dLu5UpMBfAPzx",
    "summary": "<p>Timescale 最近推出了 <a href=\"https://www.timescale.com/blog/introducing-dynamic-postgresql/\">Dynamic PostgreSQL</a>\"，这是一种新的云托管选项，可在预定义的 vCPU 范围内扩展数据库容量。这个新选项的宣传亮点是“购买基础容量，峰值需求靠租用解决”，它可以根据负载变化来扩展容量，试图以这种方式解决无服务器产品的不可预测性和可变性问题。</p><p>&nbsp;</p><p>Dynamic PostgreSQL 基于 <a href=\"https://github.com/timescale/timescaledb\">TimescaleDB</a>\"（扩展 PostgreSQL 的一款开源时间序列数据库），希望在预置数据库和无服务器数据库之外提供第三种方案。Timescale 首席技术官兼联合创始人 Mike Freedman 和 Timescale 高级产品经理 Grant Godeke 解释道：</p><p>&nbsp;</p><p></p><blockquote>它基于动态计算技术，这是一项 Timescale 开发的创新，可根据你的负载情况在预定义的最小/最大范围内实时扩展你的可用计算资源。你现在可以选择一个计算范围，不用再针对峰值需求配置资源（并一直为这些资源付费）：你的数据库启动时会使用基础的容量，并且仅在需求上涨时实时扩展到峰值容量。买基础，租峰值。</blockquote><p></p><p>&nbsp;</p><p>当客户选择一个范围时，动态最大值的上限为基本容量的两倍。 Timescale 认为，数据库与 Lambda 函数有很大不同，如今的无服务器数据库对于大多数生产负载来说效率是很差的，因为它们只盯着缩放的极端情况，并且为了服务不断变化的需求而保留的那些资源还使用了费用高昂且难以理解的定价机制。 Ampt 首席执行官兼创始人 Jeremy Daly 写道：</p><p>&nbsp;</p><p></p><blockquote>这里的区别（我认为）是他们将其定位为“买基础，租峰值”。我很久以前就开始这么呼吁了，云服务商的无服务器服务定价机制一直缺这么一块，他们应该跟上脚步。</blockquote><p></p><p>&nbsp;</p><p>数据库顾问 Tobias Petry 评论说：</p><p>&nbsp;</p><p></p><blockquote>它就像是支持突发机制的 EC2 机器一样，这是一个完美的解决方案：基础定价的成本低廉，你只需在极少数情况下为临时增加的需求支付更多费用。有了它，团队就用不着像往常那样买过大的实例了。</blockquote><p></p><p>&nbsp;</p><p>无服务器数据库的好处之一是能够将容量缩到零，只需为所使用的计算时间付费。Freedman 和 Godeke 认为：</p><p>&nbsp;</p><p></p><blockquote>在某些用例中，“缩放到零”是有意义的，比如说概念验证演示或更偏业余爱好者的应用程序（……）但如果跑的是你的生产数据库和更接近运营层面的东西？你肯定不想要缩到零。缩放到零意味着重新启动时要“冷启动”：数据库共享缓冲区清空了、操作系统缓存清空了、目录缓存也清空了。</blockquote><p></p><p>&nbsp;</p><p>Dynamic PostgreSQL 主要针对在 AWS 上运行的部署，声称客户从 RDS for PostgreSQL 迁移过来时会节省 10-20% 的成本，从 Aurora Serverless 迁移过来时可节省 50-70%，但他们尚未发布基准测试。</p><p>&nbsp;</p><p>Dynamic PostgreSQL 并不是 Dynamic Infra 发布周期间的唯一亮点：<a href=\"https://www.timescale.com/blog/create-timescale-services-with-terraform-provider/\">Terraform provider</a>\" 已全面可用，<a href=\"https://www.timescale.com/blog/timescale-x-cloudflare-time-series-from-the-edge/\">Cloudflare Hyperdrive</a>\" 增加了超级表支持，Timescale 云现已在澳大利亚、欧洲、美国和亚洲的 7 个 AWS 区域推出。</p><p>&nbsp;</p><p>1-2 个 CPU 范围的每月定价为 87.60 美元起，如果使用量高于承诺的基础容量，则每个 CPU 每小时额外收取 0.12 美元。 Timescale 为新帐户提供 30 天免费试用。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/11/timescale-dynamic-postgresql/\">https://www.infoq.com/news/2023/11/timescale-dynamic-postgresql/</a>\"</p>",
    "publish_time": "2023-12-08 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "刚发布就被质疑？超过GPT-4的“最强”大模型Gemini、“最高效”训练加速器，谷歌到底行不行",
    "url": "https://www.infoq.cn/article/Xcu7VoHdktaHGrbvbEcu",
    "summary": "<p>当地时间12 月 6 日，谷歌发布了自己“迄今为止功能最强、通用性最高”的AI模型Gemini。</p><p></p><p>谷歌及Alphabet&nbsp;CEO桑达尔·皮查伊 (Sundar&nbsp;Pichai)表示，首个Gemini 1.0针对不同规模进行优化，具体分为Ultra、Pro和Nano三个版本。“这是Gemini时代的首批模型，也是我们今年早些时候重组Google DeepMind时所表达愿景的首个实现。此模型代表着谷歌作为一家企业，在AI新时代下所做出的最重要的科学与工程努力之一。”</p><p></p><p>但刚发布不久，科技专栏作家Parmy Olson 指出，其中一个AI实时对人类的涂鸦和手势动作给出评论和吐槽的视频被曝出“不是实时或以语音方式进行的”。还有<a href=\"https://twitter.com/noguestein/status/1732927393466040617\">网友吐槽</a>\"整个互动过程“特别慢，跟演示视频完全不同。”</p><p></p><p>这个视频主要是演示“多模态提示”（multimodal prompting），即为大模型提供不同模式的组合（在本例中为图像和文本），并让其通过预测接下来会发生什么来做出反应。</p><p></p><p></p><p>对此，Google DeepMind 研究与深度学习主管副总裁 <a href=\"https://twitter.com/OriolVinyalsML/status/1732885990291775553\">Oriol Vinyals</a>\"表示，“视频中的所有用户提示和输出都是真实的，只是为简洁起见进行了缩短剪辑。”但网友对此并不买账，认为谷歌在玩营销手段，误导大家。</p><p></p><p>在谷歌发布的<a href=\"https://developers.googleblog.com/2023/12/how-its-made-gemini-multimodal-prompting.html?m=1\">一篇文章</a>\"里，详细介绍了效果实现经过，可以看出是使用静态图片和多段提示词拼凑训练。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/87/879c43b3919928ef014c63fd299e9cbb.png\" /></p><p></p><p></p><h2>看看谷歌的测试</h2><p></p><p></p><p>Gemini 被称为谷歌迄今为止最灵活的模型，能够从数据中心到移动设备实现高效运行，帮助开发人员与企业客户显著增强在利用AI进行构建和扩展时的操作方式。谷歌针对三种不同体量优化了Gemini 1.0（首个正式模型版本），分别为：</p><p></p><p>Gemini Ultra&nbsp;— 最大、功能最强的模型，适用于高度复杂的任务。Gemini Pro&nbsp;— 可处理各种任务类型的最佳模型。Gemini Nano&nbsp;— 能够在多种设备上高效运行的任务处理模型。</p><p></p><p>值得注意是，本次尚未发布最强大的Gemini Ultra，距离正式发布还需要几个月的时间。目前Gemini Ultra正在进行全面的信任与安全检查，包括由受信的外部合作方进行红队审查，并在广泛应用前通过微调和基于人类反馈的强化学习（RLHF）对其做进一步完善。</p><p></p><p>Gemini Pro和Gemini Nano已分别集成到了聊天机器人Bard和智能手机Pixel 8 Pro上。此外，自12月13日开始，开发者和企业客户都可通过Google AI Studio或者Google Cloud Vertex AI中的Gemini API访问Gemini Pro模型。在未来几个月间，Gemini将逐步登陆谷歌更多产品及服务，包括搜索、广告、Chrome浏览器以及Duet AI等。</p><p></p><p>谷歌说得很厉害，那Gemini 1.0 的实力到底如何？</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/9677686c03434f3f8237cd371682bc06.png\" /></p><p>﻿</p><p>根据谷歌测试结果，从自然图像、音频和视频理解再到数学推理，在大语言模型（LLM）研发领域的32种常见学术基准测试中，Gemini Ultra的性能一举创下30项最佳新纪录。</p><p></p><p>在MMLU（大规模多任务语言理解）中Gemini Ultar的得分高达90.0%，成为首个超越人类专家的模型。这项测试结合了数学、物理、历史、法律、医学和伦理学等57个科目，旨在测试AI模型掌握知识和解决问题的能力。</p><p></p><p>Gemini在文本和编码等一系列基准测试中表现超过GPT-4：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/69/691456eef49288cbb54143ec862c3dc2.png\" /></p><p></p><p>Gemini Ultra还在新的MMMU基准测试中取得了59.4%的最高得分。这项基准测试涵盖跨越不同领域、需要深思熟虑的一系列多模态推理任务。</p><p></p><p>根据谷歌测得的图像基准，Gemini Ultra的性能优于以往最先进的模型，且无需借助从图像中提取文本以供进一步处理的对象字符识别（OCR）系统的辅助。谷歌表示，这些测试结果凸显出Gemini的天然多模态优势，也证明Gemini已经表现出具备复杂推理能力的早期特征。</p><p></p><p>Gemini在一系列多模态基准测试中均创下性能新纪录，全面超越GPT-4V：</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ea/eabc1941f73a277dcac4574c7de7d681.png\" /></p><p></p><h2>多模态推理能力</h2><p></p><p></p><p>到目前为止，创建多模态模型的标准方法主要是针对不同模态训练单独的组件，再将其组合起来以粗略模仿相应能力。由此实现的模型虽然比较擅长执行某些特定任务，例如描述图像内容，但却难以处理概念性更强、复杂度更高的推理任务。</p><p></p><p>在Gemini的起始阶段就将其定位为原生多模态形式，针对不同模态开展预训练。之后，谷歌又使用额外的多模态数据对其进行微调，希望进一步完善其有效性。现在，Gemini可以同时识别和理解文本、图像、音频、视频和代码五种信息。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ab/abb5095053fbb457004d5057561f4555.png\" /></p><p></p><h4>理解文本、图像、音频等各种素材</h4><p></p><p></p><p>Gemini 1.0拥有精妙的多模态推理能力，可以帮助理解复杂的书面与视觉信息，展现出了在大量数据中提取重要知识的独特能力。比如，Gemini 在阅读、过滤和理解信息的过程中，可以从数十万份文档中提取见解并进行分析。</p><p></p><p>Gemini 1.0在训练之后，能够同时识别并理解文本、图像、音频等各种素材，因此可以把握住更加微妙的信息，并回答与复杂主题相关的更多问题。这使得它特别擅长解释数学、物理等复杂学科的推理过程。</p><p></p><p>比如，Gemini 可以识别学生的手写物理题答案，并验证正确性：</p><p>﻿</p><p><img src=\"https://static001.geekbang.org/infoq/09/0993347ceccee6452d2a0f3248905fd5.png\" /></p><p></p><p>基于视觉线索进行推理：</p><p>﻿</p><p><img src=\"https://static001.geekbang.org/infoq/91/9122b89b1f3140bc6e1a323e529acd5a.png\" /></p><p></p><p>音频方面，可以看下Google DeepMind 研究科学家 Adrià Recasens Continente 演示 Gemini 能够理解来自多个扬声器的不同语言的音频，并结合视觉、音频和文本，在厨房做饭时提供帮助的场景：</p><p></p><p></p><p></p><h4>高级编码能力</h4><p></p><p></p><p>谷歌介绍，首个Gemini正式版能够理解、解释并生成基于目前各种流行编程语言（例如Python、Java、C++和GO）的高质量代码。其表现出的跨语言工作和复杂信息推理能力，也使得Gemini成为世界领先的编码基础模型之一。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/62/62fd21473ee722a5f3eb12414a0ad27d.png\" /></p><p></p><p>Gemini&nbsp;&nbsp;的多模式推理功能生成用于重新排列子图的matplotlib代码</p><p></p><p></p><p>Gemini Ultra在多项编码基准测试中表现出色，包括HumanEval（用于评估编码任务性能的重要行业标准）和 Natural2Code（谷歌内部保留的数据集），此数据集使用作者专门创作的源素材、而非来自网络的信息。</p><p></p><p>Gemini还能作为更高级编码系统的引擎。谷歌两年之前发布了ALphaCode，这也是首个在编程竞赛中表现出一定竞争力的AI代码生态系统。使用Gemini的专用版本，谷歌推出更加先进的代码生成系统AlphaCode 2。除了编码场景之外，它还擅长解决涉及复杂数学和理论计算科学的更多编程难题。</p><p><img src=\"https://static001.geekbang.org/infoq/10/108a0fe125a7ab615f9e83a23e82c6e7.png\" /></p><p></p><p>面对与初代AlphaCode相同的评估场景，AlphaCode 2表现出巨大的性能改进，其解决的问题数量几乎达到初版的两倍，谷歌估计其成绩优于85%的竞赛参与者，而AlphaCode成功解决问题的比例只接近50%。因此当程序员通过代码示例来定义某些属性，并借此向AlphaCode 2寻求帮助时，其表现会更好。</p><p></p><p></p><h2>“专为训练顶尖AI模型而生”的TPU系统</h2><p></p><p></p><p>在介绍自家大模型的同时，谷歌顺势推出了了自己的AI训练基础设施。</p><p></p><p>谷歌使用内部设计的张量处理单元（TPU）v4和v5e在AI优化的基础设施之上，完成了Gemini 1.0的大规模训练任务。</p><p></p><p>在TPU上，Gemini的运行速度明显快于其他更早、更小且功能较差的模型。这些定制设计的AI加速器一直是谷歌AI产品的核心，负责为搜索、YouTube、Gmail、谷歌地图、Google Play和Android等服务的数十亿用户提供支持。它们也使得世界各地的其他企业也能经济高效地训练出自己的大规模AI模型。</p><p></p><p>如今，谷歌宣布推出迄今为止“最强大、最高效且可扩展”的TPU系统Cloud TPU v5p，专为训练顶尖AI模型而生。谷歌表示，作为下一代TPU，它将加速Gemini开发，帮助开发者和企业客户快速训练大规模生成式AI模型，将新产品和新功能更快交付至客户手中。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ee/ee5fb38056fa5ac7026cfc835d0eb72a.png\" /></p><p></p><p>谷歌数据中心内的Cloud TPU v5p AI加速器超级计算机</p><p></p><p>此外，在安全问题上，谷歌表示，Gemini拥有迄今为止所有谷歌AI模型当中最全面的安全评估机制，包括偏见与有毒内容检测。谷歌还对网络攻击、说服与自主判断等潜在风险领域开展了新颖研究，并应用谷歌研究院领先的对抗性测试技术抢在部署之前帮助发现Gemini中的重大安全隐患。</p><p></p><p>为了诊断Gemini训练阶段的内容安全问题，并确保其输出结果符合政策，谷歌使用诸如真实毒性提示词Real Toxicity Prompts在内的多种基准。这是一组从网络提取的、包含不同程度毒性内容的10万条提示词，由艾伦AI研究所的专家们提供。为了限制伤害，谷歌还构建了专门的安全分类器，用以识别、标记并整理涉及暴力或负面刻板印象的内容。</p><p></p><p>附 Sundar&nbsp;Pichai 公开信内容：</p><p>&nbsp;</p><p></p><blockquote>每一次技术变革都代表着推动科学发现、加速人类进步和改善生活品质的机遇。我相信我们现在所见证的AI转变，将成为我们一生当中最具深远意义的事件，甚至远远超越之前的移动或者Web革命。AI有望为全球各地的人们创造前所未有的日常生活体验和非凡的职业发展空间，将掀起新一波的创新与经济进步，并以前所未见的规模提升知识、学习、创造力与生产力。&nbsp;这也让我感到兴奋，期待通过AI技术为各国各地的每一个人提供帮助。&nbsp;作为一家AI优先的厂商，我们已经走过近八年历程，而前进的步伐只会不断加快：数百万用户正在我们的产品中运用生成式AI完成一年之前还难以想象的工作，包括为更加复杂的问题寻求答案、使用新工具协作与创新等等。与此同时，开发人员也在使用我们的模型与基础设施构建出新的生成式AI应用程序，世界各地的初创企业和组织正利用我们的AI工具不断拓展业务。&nbsp;这是一股令人难以置信的发展态势，而且我们才刚刚开始触及这无限可能性的最表层。我们正以大胆且负责任的态度开展这项工作。这意味着我们既需要追求雄心勃勃、能够为人类和全社会带来巨大收益的技术成果，同时也要建立保障措施并与政府和专家合作，应对AI发展过程中带来的种种风险。我们将继续投资打造更好的工具、基础模型和底层设施，并在我们AI原则的指导下将其引入自己的产品及其他方案当中。</blockquote><p></p><p></p><p></p><p>相关链接：</p><p><a href=\"https://blog.google/technology/ai/google-gemini-ai/#availability\">https://blog.google/technology/ai/google-gemini-ai/#availability</a>\"</p><p><a href=\"https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf\">https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf</a>\"</p>",
    "publish_time": "2023-12-08 10:04:59",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "稳定性出了大问题，是降本增效的锅？",
    "url": "https://www.infoq.cn/article/kOUdqdgpOBo3NPu2gQOE",
    "summary": "<p>稳定性出了大问题，是降本增效的锅？恰逢 QCon 中国 15 周年之际，InfoQ 技术大会早班车栏目邀请到 3 位 QCon 往届嘉宾，云器科技 CTO 关涛、趣丸科技技术保障部负责⼈刘亚丹 、贝联珠贯合伙人王元良，于 12 月 5 日 20:00-21:30 直播剖析灵魂三问：</p>\n<ol>\n<li>怎么算清成本账？</li>\n<li>IT 部门是成本中心还是价值中心？</li>\n<li>稳定性问题，谁是第一责任人？</li>\n</ol>",
    "publish_time": "2023-12-08 10:10:45",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]