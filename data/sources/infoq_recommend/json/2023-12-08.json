[
  {
    "title": "架构师（2023 年 12 月）",
    "url": "https://www.infoq.cn/article/Pu0szgrG5sJuOl8AV2tr",
    "summary": "<h2>卷首语：俭约架构师的七大黄金法则</h2>\n<p>亚马逊 CTO Werner Vogels 向企业传达了一条信息：在管理云成本方面，是时候成为节俭的架构师了。</p>\n<p>他拥有近 20 年的平台构建经验，在今天的 re:Invent 2023 大会主题演讲中，给大家上了一节关于成本优化的课：“作为技术专家，我们生活在一个瞬息万变的世界，我们需要保持学习，坐下来，拿出你的记事本，现在开始做笔记。”</p>\n<p><strong>法则一：将成本视为一种非功能性需求。</strong><br />\n架构师需要尽可能早的、以更加可持续的方式考虑成本影响，才能在系统设计过程中在功能、上市时间和效率之间寻求平衡。</p>\n<p><strong>法则二：确保系统的最终成本与业务保持一致。</strong><br />\n系统能否长治久安，取决于其成本是否与业务模式高度匹配。在设计和构建系统时，架构师必须考虑收入来源和利润杠杆。更重要的是，必须找到能够产生利润的维度，确保架构规划始终围绕收益展开。</p>\n<p><strong>法则三：架构设计是一系列权衡的集合。</strong><br />\n在架构当中，每项决定都涉及相应的权衡。在技术与业务需求间找到适当的平衡将至关重要。请记住，节俭是为了最大限度提升价值，而不只是尽可能控制支出。因此，在必须得花的钱上别吝啬。</p>\n<p><strong>法则四：无法观察的系统将带来无法估量的成本。</strong><br />\n尽管实现可观察性需要投入，但这笔钱绝对会物有所值。有句格言说“如果无法量化，也就无法管理。持续检查能帮我们发现非必要支出，并调整运营以减少浪费。总之，可观察性带来的回报往往远超过前期投入。</p>\n<p><strong>法则五：依托成本感知架构实现成本控制。</strong><br />\n节俭架构的本质，在于强大监控与成本优化能力的结合。明确定义各层，即可在成本及其他要求之间求得平衡。对组件的精细控制则能优化成本和体验。</p>\n<p><strong>法则六：成本优化是个渐进的过程。</strong><br />\n追求成本效率是个持续的过程。即使在部署之后，我们也必须随时审视系统以逐步寻求优化。看似微小的优化，累积起来足以产生超出想象的成本优势。</p>\n<p><strong>法则七：顺风局打多了会让人盲目自信。</strong><br />\n软件团队经常陷入这样的陷阱：仅凭以往的工作经验，他们就认为当前的技术、架构或语言永远是最佳选择。这可能会产生一种错误的安全感，阻碍对现状的质疑，更会打击对可能更加高效、更具成本效益或可扩展性更强的新选项的探索。</p>\n<h2>目录</h2>\n<p><strong>热点 | Hot</strong></p>\n<p>全球首款经安全认证的开源实时操作系统！开发了 20 多年、部署在超 120 亿台设备上的 ThreadX 正式开源</p>\n<p>省钱在于“架构师”！亚马逊 CTO 20 年架构经验之道：俭约架构师的七大黄金法则</p>\n<p>联手 OpenAI 最强竞对展开生成式 AI 反击战：亚马逊云科技将 S3 写入速度提升 10 倍、推出全新三层技术栈</p>\n<p>疯狂马斯克的“极限”计划居然成功了？！“下云”后成本降低 60%，部分功能代码精简 90%，30 天急速迁移服务器</p>\n<p>微软发布开源平台 Radius：高效构建、运行云原生应用程序</p>\n<p><strong>访谈文章 | Interview</strong></p>\n<p>主力开发已经 68 岁了！“老龄化”严重的 Postgres 开源社区呼唤“年轻一代”</p>\n<p>美图的这 100 天：三月三版本，大模型博弈中谁能笑到最后？</p>\n<p>是时候基于云重新设计 Kafka 了！AutoMQ 如何实现 Kafka 十倍的降本增效</p>\n<p><strong>案例研究 | Case Study</strong></p>\n<p>一个失败的 AI 女友产品，以及我的教训：来自一位中国开发者的总结</p>\n<p>从 ES 到 Clickhouse：信息技术发展的新浪潮</p>\n<p>GitHub 基于大语言模型构建 Copilot 的经验和教训</p>\n<p><strong>推荐文章 | Article</strong></p>\n<p>从谷歌 20 年站点可靠性工程（SRE）中学到的 11 个经验教训</p>\n<p>无服务计算，厂商究竟在打什么算盘</p>\n<p>我，技术不过硬，但是团队里的重要“胶水”</p>\n<p>是时候彻底放弃“高分低能”的 Leetcode 了：AI 时代的面试需要大变革！</p>\n<p>Docker 的诅咒：曾以为它是终极解法，最后却是“罪大恶极”？</p>\n<p><strong>特别专题｜我们需要纯向量数据库吗</strong></p>\n<p>数据库内核杂谈：向量数据库（一）</p>\n<p>数据库内核杂谈： 向量数据库（二）</p>\n<p>数据库内核杂谈：向量数据库（三）</p>\n<p>数据库内核杂谈： 向量数据库（四）</p>\n<p>向量数据库？不要投资！不要投资！不要投资！</p>\n<p>AutoGPT 放弃向量数据库！向量数据库是小题大作的方案？</p>\n<p>向量数据库失宠了？OpenAI 力捧检索增强生成（RAG）技术，对行业来说意味着什么？</p>\n<p><strong>特别专栏 | 视频推荐</strong></p>\n<p>欢迎阅读 InfoQ 架构师电子刊！每个月，我们都会为你带来行业同行关于新兴技术和模式的重要新闻及经验。</p>\n<p>本月，我们聚焦“AI Agent”这一话题。</p>",
    "publish_time": "2023-12-08 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Web ML 库 Transformers.js 提供文本转语音功能",
    "url": "https://www.infoq.cn/article/N1vpady26bKq23GOZNqQ",
    "summary": "<p>JavaScript 库 Transformers.js 提供了类似 Python Transformers 库的功能，设计用于在 Web 浏览器中直接运行 Transformer 模型，而不再需要外部服务器参与处理。在最新的 2.7 版本中，Transformers.js 引入了增强功能，其中包括文本转语音（TTS）支持。这次升级响应了用户的诸多需求，扩展了库的应用场景。</p><p></p><p>文本转语音（TTS）包括从文本创建听起来比较自然的语音，并提供了多种口语语言和 speaker。目前，Transformers.js 只通过 Xenova/speecht5_tts 提供 TTS 支持，而 Xenova/speecht5_tts 基于微软提供的带有 ONNX 权重的 SpeechT5。未来更新计划中包括增加对 bark 和 MMS 的支持。</p><p></p><p>开发人员可以通过 @xenova/transformers 中的管道函数来使用文本转语音功能，包括指定“文本转语音”任务和要使用的模型（'Xenova/ speecht5_ts '），并使用选项{quantized: false}。此外，其中还包含提供 speaker embeddings 的文件链接。</p><p></p><p>将 TTS 模型应用于给定的文本后，它就会输出音频数组和采样率。该数组表示合成语音，可以进一步处理或直接在浏览器中播放。</p><p></p><p>Transformers.js 适用于各种用例，包括风格转换、图像绘制、图像着色和超分辨率。它的多功能性和定期更新使其成为开发人员探索机器学习和 Web 开发结合点的宝贵资产，并使其成为 Web 机器学习领域的可靠工具。</p><p></p><p>按照设计，Transformers.js 在功能上等同于 Hugging Face 的 Python 库 transformers，也就是说，你可以使用非常近似的 API 运行相同的预训练模型。</p><p></p><p>Transformers.js 支持许多任务和模型，涉及自然语言处理、视觉、音频、表格数据、多模态应用和强化学习。该库涵盖了从文本分类和摘要到图像分割和对象检测的各种任务，这使其成为各种机器学习应用程序的通用工具。</p><p></p><p>Transformers.js 提供了广泛的模型支持，包括 BERT、GPT-2、T5 和 Vision Transformer（ViT）等架构，确保用户可以针对特定的任务选择正确的模型。</p><p></p><p>对于 Transformers.js 的发布，社区持积极态度。在今年早些时候发起的 <a href=\"https://www.reddit.com/r/LocalLLaMA/comments/14w0p1p/transformersjs_thoughts/\">Reddit 帖子</a>\"中，用户 Intrepid-Air6525 表示：我决定用它来代替 openai 的嵌入模型。速度非常快。我实际使用的 LLM 是 webLLM ，因为我不想消耗太多的 CPU 处理。</p><p></p><p>用户 1EvilSexyGenius 对 Hugging Face 的市场定位以及关于实际应用的讨论发表了看法：</p><p></p><p></p><blockquote>[…] 借助 Transformers.js 及他们提供的其他优秀的库，很显然， [Hugging Face] 正在努力实现语言模型的民主化，并将它们带给大众。与每天发布的所有模型相比，这样的帖子会让这个社区受益匪浅。</blockquote><p></p><p></p><p>感兴趣的读者可以从 <a href=\"https://huggingface.co/docs/transformers.js/index\">Hugging Face Transformers.js</a>\" 官方网站及其 GitHub 库中获得更多信息。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/11/transformersjs-ml-for-web/\">https://www.infoq.com/news/2023/11/transformersjs-ml-for-web/</a>\"</p><p></p><p></p><p></p><p></p><p></p><p></p>",
    "publish_time": "2023-12-08 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Timescale 推出无服务器数据库的替代方案Dynamic PostgreSQL",
    "url": "https://www.infoq.cn/article/BX5Ee69dLu5UpMBfAPzx",
    "summary": "<p>Timescale 最近推出了 <a href=\"https://www.timescale.com/blog/introducing-dynamic-postgresql/\">Dynamic PostgreSQL</a>\"，这是一种新的云托管选项，可在预定义的 vCPU 范围内扩展数据库容量。这个新选项的宣传亮点是“购买基础容量，峰值需求靠租用解决”，它可以根据负载变化来扩展容量，试图以这种方式解决无服务器产品的不可预测性和可变性问题。</p><p>&nbsp;</p><p>Dynamic PostgreSQL 基于 <a href=\"https://github.com/timescale/timescaledb\">TimescaleDB</a>\"（扩展 PostgreSQL 的一款开源时间序列数据库），希望在预置数据库和无服务器数据库之外提供第三种方案。Timescale 首席技术官兼联合创始人 Mike Freedman 和 Timescale 高级产品经理 Grant Godeke 解释道：</p><p>&nbsp;</p><p></p><blockquote>它基于动态计算技术，这是一项 Timescale 开发的创新，可根据你的负载情况在预定义的最小/最大范围内实时扩展你的可用计算资源。你现在可以选择一个计算范围，不用再针对峰值需求配置资源（并一直为这些资源付费）：你的数据库启动时会使用基础的容量，并且仅在需求上涨时实时扩展到峰值容量。买基础，租峰值。</blockquote><p></p><p>&nbsp;</p><p>当客户选择一个范围时，动态最大值的上限为基本容量的两倍。 Timescale 认为，数据库与 Lambda 函数有很大不同，如今的无服务器数据库对于大多数生产负载来说效率是很差的，因为它们只盯着缩放的极端情况，并且为了服务不断变化的需求而保留的那些资源还使用了费用高昂且难以理解的定价机制。 Ampt 首席执行官兼创始人 Jeremy Daly 写道：</p><p>&nbsp;</p><p></p><blockquote>这里的区别（我认为）是他们将其定位为“买基础，租峰值”。我很久以前就开始这么呼吁了，云服务商的无服务器服务定价机制一直缺这么一块，他们应该跟上脚步。</blockquote><p></p><p>&nbsp;</p><p>数据库顾问 Tobias Petry 评论说：</p><p>&nbsp;</p><p></p><blockquote>它就像是支持突发机制的 EC2 机器一样，这是一个完美的解决方案：基础定价的成本低廉，你只需在极少数情况下为临时增加的需求支付更多费用。有了它，团队就用不着像往常那样买过大的实例了。</blockquote><p></p><p>&nbsp;</p><p>无服务器数据库的好处之一是能够将容量缩到零，只需为所使用的计算时间付费。Freedman 和 Godeke 认为：</p><p>&nbsp;</p><p></p><blockquote>在某些用例中，“缩放到零”是有意义的，比如说概念验证演示或更偏业余爱好者的应用程序（……）但如果跑的是你的生产数据库和更接近运营层面的东西？你肯定不想要缩到零。缩放到零意味着重新启动时要“冷启动”：数据库共享缓冲区清空了、操作系统缓存清空了、目录缓存也清空了。</blockquote><p></p><p>&nbsp;</p><p>Dynamic PostgreSQL 主要针对在 AWS 上运行的部署，声称客户从 RDS for PostgreSQL 迁移过来时会节省 10-20% 的成本，从 Aurora Serverless 迁移过来时可节省 50-70%，但他们尚未发布基准测试。</p><p>&nbsp;</p><p>Dynamic PostgreSQL 并不是 Dynamic Infra 发布周期间的唯一亮点：<a href=\"https://www.timescale.com/blog/create-timescale-services-with-terraform-provider/\">Terraform provider</a>\" 已全面可用，<a href=\"https://www.timescale.com/blog/timescale-x-cloudflare-time-series-from-the-edge/\">Cloudflare Hyperdrive</a>\" 增加了超级表支持，Timescale 云现已在澳大利亚、欧洲、美国和亚洲的 7 个 AWS 区域推出。</p><p>&nbsp;</p><p>1-2 个 CPU 范围的每月定价为 87.60 美元起，如果使用量高于承诺的基础容量，则每个 CPU 每小时额外收取 0.12 美元。 Timescale 为新帐户提供 30 天免费试用。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/11/timescale-dynamic-postgresql/\">https://www.infoq.com/news/2023/11/timescale-dynamic-postgresql/</a>\"</p>",
    "publish_time": "2023-12-08 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "刚发布就被质疑？超过GPT-4的“最强”大模型Gemini、“最高效”训练加速器，谷歌到底行不行",
    "url": "https://www.infoq.cn/article/Xcu7VoHdktaHGrbvbEcu",
    "summary": "<p>当地时间12 月 6 日，谷歌发布了自己“迄今为止功能最强、通用性最高”的AI模型Gemini。</p><p></p><p>谷歌及Alphabet&nbsp;CEO桑达尔·皮查伊 (Sundar&nbsp;Pichai)表示，首个Gemini 1.0针对不同规模进行优化，具体分为Ultra、Pro和Nano三个版本。“这是Gemini时代的首批模型，也是我们今年早些时候重组Google DeepMind时所表达愿景的首个实现。此模型代表着谷歌作为一家企业，在AI新时代下所做出的最重要的科学与工程努力之一。”</p><p></p><p>但刚发布不久，科技专栏作家Parmy Olson 指出，其中一个AI实时对人类的涂鸦和手势动作给出评论和吐槽的视频被曝出“不是实时或以语音方式进行的”。还有<a href=\"https://twitter.com/noguestein/status/1732927393466040617\">网友吐槽</a>\"整个互动过程“特别慢，跟演示视频完全不同。”</p><p></p><p>这个视频主要是演示“多模态提示”（multimodal prompting），即为大模型提供不同模式的组合（在本例中为图像和文本），并让其通过预测接下来会发生什么来做出反应。</p><p></p><p></p><p>对此，Google DeepMind 研究与深度学习主管副总裁 <a href=\"https://twitter.com/OriolVinyalsML/status/1732885990291775553\">Oriol Vinyals</a>\"表示，“视频中的所有用户提示和输出都是真实的，只是为简洁起见进行了缩短剪辑。”但网友对此并不买账，认为谷歌在玩营销手段，误导大家。</p><p></p><p>在谷歌发布的<a href=\"https://developers.googleblog.com/2023/12/how-its-made-gemini-multimodal-prompting.html?m=1\">一篇文章</a>\"里，详细介绍了效果实现经过，可以看出是使用静态图片和多段提示词拼凑训练。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/87/879c43b3919928ef014c63fd299e9cbb.png\" /></p><p></p><p></p><h2>看看谷歌的测试</h2><p></p><p></p><p>Gemini 被称为谷歌迄今为止最灵活的模型，能够从数据中心到移动设备实现高效运行，帮助开发人员与企业客户显著增强在利用AI进行构建和扩展时的操作方式。谷歌针对三种不同体量优化了Gemini 1.0（首个正式模型版本），分别为：</p><p></p><p>Gemini Ultra&nbsp;— 最大、功能最强的模型，适用于高度复杂的任务。Gemini Pro&nbsp;— 可处理各种任务类型的最佳模型。Gemini Nano&nbsp;— 能够在多种设备上高效运行的任务处理模型。</p><p></p><p>值得注意是，本次尚未发布最强大的Gemini Ultra，距离正式发布还需要几个月的时间。目前Gemini Ultra正在进行全面的信任与安全检查，包括由受信的外部合作方进行红队审查，并在广泛应用前通过微调和基于人类反馈的强化学习（RLHF）对其做进一步完善。</p><p></p><p>Gemini Pro和Gemini Nano已分别集成到了聊天机器人Bard和智能手机Pixel 8 Pro上。此外，自12月13日开始，开发者和企业客户都可通过Google AI Studio或者Google Cloud Vertex AI中的Gemini API访问Gemini Pro模型。在未来几个月间，Gemini将逐步登陆谷歌更多产品及服务，包括搜索、广告、Chrome浏览器以及Duet AI等。</p><p></p><p>谷歌说得很厉害，那Gemini 1.0 的实力到底如何？</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/9677686c03434f3f8237cd371682bc06.png\" /></p><p>﻿</p><p>根据谷歌测试结果，从自然图像、音频和视频理解再到数学推理，在大语言模型（LLM）研发领域的32种常见学术基准测试中，Gemini Ultra的性能一举创下30项最佳新纪录。</p><p></p><p>在MMLU（大规模多任务语言理解）中Gemini Ultar的得分高达90.0%，成为首个超越人类专家的模型。这项测试结合了数学、物理、历史、法律、医学和伦理学等57个科目，旨在测试AI模型掌握知识和解决问题的能力。</p><p></p><p>Gemini在文本和编码等一系列基准测试中表现超过GPT-4：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/69/691456eef49288cbb54143ec862c3dc2.png\" /></p><p></p><p>Gemini Ultra还在新的MMMU基准测试中取得了59.4%的最高得分。这项基准测试涵盖跨越不同领域、需要深思熟虑的一系列多模态推理任务。</p><p></p><p>根据谷歌测得的图像基准，Gemini Ultra的性能优于以往最先进的模型，且无需借助从图像中提取文本以供进一步处理的对象字符识别（OCR）系统的辅助。谷歌表示，这些测试结果凸显出Gemini的天然多模态优势，也证明Gemini已经表现出具备复杂推理能力的早期特征。</p><p></p><p>Gemini在一系列多模态基准测试中均创下性能新纪录，全面超越GPT-4V：</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ea/eabc1941f73a277dcac4574c7de7d681.png\" /></p><p></p><h2>多模态推理能力</h2><p></p><p></p><p>到目前为止，创建多模态模型的标准方法主要是针对不同模态训练单独的组件，再将其组合起来以粗略模仿相应能力。由此实现的模型虽然比较擅长执行某些特定任务，例如描述图像内容，但却难以处理概念性更强、复杂度更高的推理任务。</p><p></p><p>在Gemini的起始阶段就将其定位为原生多模态形式，针对不同模态开展预训练。之后，谷歌又使用额外的多模态数据对其进行微调，希望进一步完善其有效性。现在，Gemini可以同时识别和理解文本、图像、音频、视频和代码五种信息。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ab/abb5095053fbb457004d5057561f4555.png\" /></p><p></p><h4>理解文本、图像、音频等各种素材</h4><p></p><p></p><p>Gemini 1.0拥有精妙的多模态推理能力，可以帮助理解复杂的书面与视觉信息，展现出了在大量数据中提取重要知识的独特能力。比如，Gemini 在阅读、过滤和理解信息的过程中，可以从数十万份文档中提取见解并进行分析。</p><p></p><p>Gemini 1.0在训练之后，能够同时识别并理解文本、图像、音频等各种素材，因此可以把握住更加微妙的信息，并回答与复杂主题相关的更多问题。这使得它特别擅长解释数学、物理等复杂学科的推理过程。</p><p></p><p>比如，Gemini 可以识别学生的手写物理题答案，并验证正确性：</p><p>﻿</p><p><img src=\"https://static001.geekbang.org/infoq/09/0993347ceccee6452d2a0f3248905fd5.png\" /></p><p></p><p>基于视觉线索进行推理：</p><p>﻿</p><p><img src=\"https://static001.geekbang.org/infoq/91/9122b89b1f3140bc6e1a323e529acd5a.png\" /></p><p></p><p>音频方面，可以看下Google DeepMind 研究科学家 Adrià Recasens Continente 演示 Gemini 能够理解来自多个扬声器的不同语言的音频，并结合视觉、音频和文本，在厨房做饭时提供帮助的场景：</p><p></p><p></p><p></p><h4>高级编码能力</h4><p></p><p></p><p>谷歌介绍，首个Gemini正式版能够理解、解释并生成基于目前各种流行编程语言（例如Python、Java、C++和GO）的高质量代码。其表现出的跨语言工作和复杂信息推理能力，也使得Gemini成为世界领先的编码基础模型之一。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/62/62fd21473ee722a5f3eb12414a0ad27d.png\" /></p><p></p><p>Gemini&nbsp;&nbsp;的多模式推理功能生成用于重新排列子图的matplotlib代码</p><p></p><p></p><p>Gemini Ultra在多项编码基准测试中表现出色，包括HumanEval（用于评估编码任务性能的重要行业标准）和 Natural2Code（谷歌内部保留的数据集），此数据集使用作者专门创作的源素材、而非来自网络的信息。</p><p></p><p>Gemini还能作为更高级编码系统的引擎。谷歌两年之前发布了ALphaCode，这也是首个在编程竞赛中表现出一定竞争力的AI代码生态系统。使用Gemini的专用版本，谷歌推出更加先进的代码生成系统AlphaCode 2。除了编码场景之外，它还擅长解决涉及复杂数学和理论计算科学的更多编程难题。</p><p><img src=\"https://static001.geekbang.org/infoq/10/108a0fe125a7ab615f9e83a23e82c6e7.png\" /></p><p></p><p>面对与初代AlphaCode相同的评估场景，AlphaCode 2表现出巨大的性能改进，其解决的问题数量几乎达到初版的两倍，谷歌估计其成绩优于85%的竞赛参与者，而AlphaCode成功解决问题的比例只接近50%。因此当程序员通过代码示例来定义某些属性，并借此向AlphaCode 2寻求帮助时，其表现会更好。</p><p></p><p></p><h2>“专为训练顶尖AI模型而生”的TPU系统</h2><p></p><p></p><p>在介绍自家大模型的同时，谷歌顺势推出了了自己的AI训练基础设施。</p><p></p><p>谷歌使用内部设计的张量处理单元（TPU）v4和v5e在AI优化的基础设施之上，完成了Gemini 1.0的大规模训练任务。</p><p></p><p>在TPU上，Gemini的运行速度明显快于其他更早、更小且功能较差的模型。这些定制设计的AI加速器一直是谷歌AI产品的核心，负责为搜索、YouTube、Gmail、谷歌地图、Google Play和Android等服务的数十亿用户提供支持。它们也使得世界各地的其他企业也能经济高效地训练出自己的大规模AI模型。</p><p></p><p>如今，谷歌宣布推出迄今为止“最强大、最高效且可扩展”的TPU系统Cloud TPU v5p，专为训练顶尖AI模型而生。谷歌表示，作为下一代TPU，它将加速Gemini开发，帮助开发者和企业客户快速训练大规模生成式AI模型，将新产品和新功能更快交付至客户手中。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ee/ee5fb38056fa5ac7026cfc835d0eb72a.png\" /></p><p></p><p>谷歌数据中心内的Cloud TPU v5p AI加速器超级计算机</p><p></p><p>此外，在安全问题上，谷歌表示，Gemini拥有迄今为止所有谷歌AI模型当中最全面的安全评估机制，包括偏见与有毒内容检测。谷歌还对网络攻击、说服与自主判断等潜在风险领域开展了新颖研究，并应用谷歌研究院领先的对抗性测试技术抢在部署之前帮助发现Gemini中的重大安全隐患。</p><p></p><p>为了诊断Gemini训练阶段的内容安全问题，并确保其输出结果符合政策，谷歌使用诸如真实毒性提示词Real Toxicity Prompts在内的多种基准。这是一组从网络提取的、包含不同程度毒性内容的10万条提示词，由艾伦AI研究所的专家们提供。为了限制伤害，谷歌还构建了专门的安全分类器，用以识别、标记并整理涉及暴力或负面刻板印象的内容。</p><p></p><p>附 Sundar&nbsp;Pichai 公开信内容：</p><p>&nbsp;</p><p></p><blockquote>每一次技术变革都代表着推动科学发现、加速人类进步和改善生活品质的机遇。我相信我们现在所见证的AI转变，将成为我们一生当中最具深远意义的事件，甚至远远超越之前的移动或者Web革命。AI有望为全球各地的人们创造前所未有的日常生活体验和非凡的职业发展空间，将掀起新一波的创新与经济进步，并以前所未见的规模提升知识、学习、创造力与生产力。&nbsp;这也让我感到兴奋，期待通过AI技术为各国各地的每一个人提供帮助。&nbsp;作为一家AI优先的厂商，我们已经走过近八年历程，而前进的步伐只会不断加快：数百万用户正在我们的产品中运用生成式AI完成一年之前还难以想象的工作，包括为更加复杂的问题寻求答案、使用新工具协作与创新等等。与此同时，开发人员也在使用我们的模型与基础设施构建出新的生成式AI应用程序，世界各地的初创企业和组织正利用我们的AI工具不断拓展业务。&nbsp;这是一股令人难以置信的发展态势，而且我们才刚刚开始触及这无限可能性的最表层。我们正以大胆且负责任的态度开展这项工作。这意味着我们既需要追求雄心勃勃、能够为人类和全社会带来巨大收益的技术成果，同时也要建立保障措施并与政府和专家合作，应对AI发展过程中带来的种种风险。我们将继续投资打造更好的工具、基础模型和底层设施，并在我们AI原则的指导下将其引入自己的产品及其他方案当中。</blockquote><p></p><p></p><p></p><p>相关链接：</p><p><a href=\"https://blog.google/technology/ai/google-gemini-ai/#availability\">https://blog.google/technology/ai/google-gemini-ai/#availability</a>\"</p><p><a href=\"https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf\">https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf</a>\"</p>",
    "publish_time": "2023-12-08 10:04:59",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "稳定性出了大问题，是降本增效的锅？",
    "url": "https://www.infoq.cn/article/kOUdqdgpOBo3NPu2gQOE",
    "summary": "<p>稳定性出了大问题，是降本增效的锅？恰逢 QCon 中国 15 周年之际，InfoQ 技术大会早班车栏目邀请到 3 位 QCon 往届嘉宾，云器科技 CTO 关涛、趣丸科技技术保障部负责⼈刘亚丹 、贝联珠贯合伙人王元良，于 12 月 5 日 20:00-21:30 直播剖析灵魂三问：</p>\n<ol>\n<li>怎么算清成本账？</li>\n<li>IT 部门是成本中心还是价值中心？</li>\n<li>稳定性问题，谁是第一责任人？</li>\n</ol>",
    "publish_time": "2023-12-08 10:10:45",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "实现“数据资产当日达”，国泰君安证券做数据平台的逻辑与实践",
    "url": "https://www.infoq.cn/article/FK7BvgSk0p340NFjN6rZ",
    "summary": "<p>金融业务和数据的深度融合，不仅仅是数字化转型的一次技术升级，更是为了更好地响应用户需求，实现用户服务体验的全面提升。在国泰君安，数据治理不再是一个抽象的名词，而是通过切实行动融入到业务价值链的各个环节。</p><p></p><p>在日前举办的<a href=\"https://www.infoq.cn/article/BNiefsWtdjeQmreGkaUI?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">FCon 大会</a>\"期间，国泰君安证券数据平台运营部副总经理<a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5624?utm_source=infoqweb&amp;utm_medium=article\">苑博</a>\"接受 InfoQ 采访，分享了国泰君安证券数字化转型和数据平台运营方面的实践经验。</p><p></p><p>在苑博看来，数据团队的使命是“让公司没有难用的数据”。如果业务部门的人在使用数据时遇到困难，拿不到需要的数据，甚至对数据的应用一头雾水，那么企业整体数字化转型的效果将大打折扣。其次，要让业务部门内的数据使用者感到有成就感，这不仅仅是技术层面的问题，更涉及到整个数据服务链的打通。</p><p></p><p>从“数据资产当日达”到“数据空间”，苑博所在的团队一直在推行内部实现“全民用数”，并采取了“1+N+X”数据人才能力提升的创新模式，以打造“有数、用数、治数”的良性循环。</p><p></p><p>以下是对话全文（经 InfoQ 进行不改变原意的编辑整理）：</p><p></p><p></p><h2>证券行业数字化转型的背景和挑战</h2><p></p><p></p><p>InfoQ：结合整个<a href=\"https://www.infoq.cn/article/TkHfwhl8xwNjmzmPbFqu?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">证券行业</a>\"现状来看，现在推动数字化转型的背景和最大的挑战在哪里？</p><p></p><p>苑博：我认为主要存在两个方面的挑战。首先，在组织意识方面面临比较大的挑战，数字化转型的最大特点是科技与业务的深度融合，转型首先要转意识，业务负责人需认识到数字化转型的意义，并主动参与到数字化转型的全过程中。</p><p></p><p>这与过去建设系统的方式有很大不同，以前业务领导不必过多操心系统建设，但在数字化转型的进程下，业务领导需要更多地参与牵头协调，包括流程设置、权责划分，平台愿景和使命的制定，这要求业务领导更深度地参与。因此，数字化转型特别需要关注组织意识和领导能力的提升，这也是数字化转型与以往的数字化和信息化工作有所不同的地方。</p><p></p><p>其次，行业整体的趋势也构成了数字化转型的挑战。近年来，整个证券行业头部化的趋势日益明显，同时监管力度逐渐增加。在受到强监管和降费的双重压力下，数字化转型的挑战在于如何提升公司的整体运营效率。</p><p></p><p>因此，我认为数字化转型当前所面临的挑战之一是在不同业务模式中找到提升效率、提升用户体验和确保安全的通用路径。这一路径并非特定于某一业务模式，而更注重公司整体的运营能力。目前，行业里比较热的话题是机构客户服务，那么面向 B 端市场时，必须应对处理周期长、见效慢、个性化要求高等多重挑战。</p><p></p><p>InfoQ：该怎么去应对这些挑战？有哪些策略？</p><p></p><p>苑博：我觉得可以从几个方面看。首先，从意识层面来看，数字化转型是“科业融合”的事情，需要着重解决科技和业务融合的问题。其关键点和落脚点可能还是在于组织能力、流程、以及效率的提升。这是一项需要“练内功”的工作。</p><p></p><p>其次，虽然公司已经认同数字化转型的重要性，并愿意为此投入资金和资源，但科技部门可能还需要更主动地走多一步，积极推动这项工作。</p><p></p><p>总的来说，数字化转型要求业务领导需要思考战略布局，而科技部门则需要更主动地投入并推动这一进程，要有换位思考、全局意识和服务意识。在这一层面上，需要双方共同努力。</p><p></p><p>InfoQ：在数字化的投入产出比这方面，目前会有哪些明确的要求吗？</p><p></p><p>苑博：在评估投入产出比时，业务和科技视角可能涉及不同的考量。从科技角度来看，我们关注一些关键指标，比如创新业务的首批上线率。举例来说，在新业务推出时，我们关注的是能否迅速上线，抢占市场先机，这反映了我们的自主研发能力。特别是在应对监管政策调整时，我们需要进行业务、流程和系统的改造等等。这时候，能否在行业首批上线新业务就展现了我们的自主研发水平。</p><p></p><p>科技方面还有其他维度，如技术领先性，包括交易速度、系统吞吐量等关键指标。此外，我们还关注是否参与行业标准的建设，以及获得行业奖项和评级等方面的成就。</p><p></p><p>从业务视角来看，关键在于效率。当我们所谓的能力达到市场领先地位时，整体运营效率、开发和交付效率，以及数据获取的效率等指标是否达到预期，都是值得密切关注的要素。</p><p></p><p></p><h2>数据平台建设和价值</h2><p></p><p></p><p>InfoQ：数据是驱动企业数字化转型核心要素，国泰君安在强化数据能力方面有哪些部署和创新？</p><p></p><p>苑博：我们在强化数据能力方面，主要着眼于有数、用数和治数三个方面，通过平台化能力的提升，将更好地支持数据的应用和整体逻辑的实现。</p><p></p><p>在“用数”方面，我们目前是希望平台的用户越来越多、平台服务效率越来越高，并得到用户好评。</p><p></p><p>所以这里的“用”有两个要点，第一点是数据平台在集团内部的用户渗透率，在过去三年里，这一比例呈现稳定的增长趋势，每年平均增长率约为 10%。我们预计今年可以实现 70% 左右的使用率。第二点，数据平台的服务目标是让所有员工都能够充分利用数据平台所提供的服务。为此，我们需要积极开展运营工作，因此打造了能够为数据人才提供全面培训和发展的“1+N+X”的运营体系：</p><p></p><p></p><blockquote>1：一个统一的智慧化数据中台N：培养 N 个集团数据分析核心用户，通过线上 + 线下的方式，培养数据人才X：吸引 X 个数据产品用户，通过经营管理驾驶舱、智能报表、经营指标卡、企业画像、数据学堂等产品打造全方位数据产品矩阵，吸引更多集团用户参与到数据价值的挖掘中来</blockquote><p></p><p></p><p>“1+N+X ”相当于我们强化数据能力的抓手和触手，一方面，它能够收集问题；另一方面，它能够将数据服务普及开来。因此，我们的平台是开放的，平台并非为用户直接呈现最终结果，而是让用户能够在这之上自主开发报表、进行数据分析，找到问题的解决方案。</p><p></p><p>“治数”方面，数据治理是一项高度专业且体系化的任务，同时也是非常务实的工作。其主要目标是解决问题并确保数据质量。以“1+N+X”为触点，将从一线收集到的问题整理成数据治理的问题列表，并通过组织机制和流程有针对性地解决。</p><p></p><p>在解决问题的过程中，我们通过平台和端到端的流程来保障工作效率。数据平台的建设服务于“用数”、“治数”和“有数”，遵循“四全四可”的理念，即“全员工可用、全数据可通、全流程可见、全领域可管”。我们希望，数据平台可以像京东一样提供服务，无论用户走到哪里都能轻松查阅。此外，数据平台不仅解决数据团队服务的问题，也帮助各个部门单位的数据治理专员、甚至科技团队解决问题。</p><p></p><p>简而言之，国泰君安做数据平台的目标是将复杂性留给平台，将简单性留给用户。不仅仅关注技术视角，还着眼于全领域的可管理性，包括安全资产和权限。通过以数据为引导，通过治理解决问题，通过数据工作提升效率。效率本身就是标准化、SOP 和端到端。在不同阶段，我们会侧重这三点中的的不同方面来应对。</p><p></p><p>InfoQ：在国泰君安构建和运营数据平台的过程中，有什么让您和团队特别影响深刻的故事（问题、经验、成就等）可以分享？</p><p></p><p>苑博：近两年我们在推行“数据资产当日达”计划。尽管这个愿景可能有些理想化，但数据平台是为全员提供服务的，我追求的目标是在用户提出数据请求的同一天内予以响应。</p><p></p><p>我认为做数据平台，就要致力于为用户提供可靠的服务承诺。比如用户在上午提出了数据需求，我们在当天下午能够满足他们的需求，并在整个流程中保持透明，确保用户能够清晰地了解申请进度，随时查看流程的每一个步骤。</p><p></p><p>这看似简单的目标实际上涉及到许多挑战。首先，需要“打破部门墙”，实现科技与业务的紧密融合。其次，必须提高数据交付的效率，确保用户能够在需要时迅速获得所需的数据。</p><p></p><p>科技和业务的融合还涉及到权限的管理，需要判断用户是否具备获取所需数据的权限。进一步地，如果用户有权限，科技端是否能够高效地交付数据也是一个关键问题，因此，需要建立完善的端到端流程。</p><p></p><p>为了确定用户是否有权限获取数据，还需要建立一套公司级机制。同时我们又希望最大程度地减少审批流程，因此也需要对公司的数据资产进行盘点、分级分类，然后根据分级设定共享审批机制。</p><p></p><p>InfoQ：截至目前，这个项目的实施成果如何？</p><p></p><p>苑博：目前，在非受控类数据资产方面，我们已经基本实现 90% 以上申请的当日达效果。从今年年中开始试行以来，我们进行了流程优化、运营推广和宣传等工作。</p><p></p><p>当前，大家普遍认为数据是数字化转型的基础，但要实现这一目标，有几个前提条件。首先，你必须能获得想要的、所需的数据。第二点，获取数据的效率应尽可能高，第三，获得的数据必须是可用且可分析的。</p><p>我认为这就是数字化转型的核心。我们在建设系统的过程中，流程往往会出现割裂和断裂的情况，因为每个部门都希望建立自己的流程。但从用户的角度来看，我们的目标是将这些流程串联起来，从需求提出开始，一直到通知用户任务已完成，确保每一个步骤都在用户的视野范围内，这实际上也是一项基本的要求。</p><p></p><p>InfoQ：数据从沉淀到价值挖掘，期间还有很多工作要做，您认为影响数据赋能业务的主要因素有哪些？在处理大数据时，团队是如何进行数据治理和确保数据质量的？</p><p></p><p>苑博：首先，关于数据发挥价值的问题，我理解是要让“做数据的人都很爽”。如果业务部门的人在使用数据时感到困扰，无法顺利获取数据或提出的问题得不到解决，这显然是不可接受的。</p><p></p><p>第二，我们要让业务部门里使用数据的人感到有成就感，并且他们的价值在组织中得到认可。</p><p></p><p>第三，为了发挥数据的乘数效应，我们需要增加数据的维度。这意味着在数据分析中要考虑更多维度的指标和要素，让分析结果更为全面和准确。</p><p></p><p>至于数据质量的问题，我认为关键在于标准的制定和源头管理。一方面要确保数据的标准化，使口径统一。其次，从源头开始管理数据质量，从录入数据的环节就着手管理。</p><p></p><p>InfoQ：在您看来国泰君安在数据治理方面，在行业内是处于一个什么样的水平？</p><p></p><p>苑博：我们最近获评 DCMM4 级（量化管理级），是国内证券行业首家获评 DCMM4 级的证券公司，也是国内证券公司目前在该领域获评的最高等级，它标志着国泰君安在数据管理和应用方面是处于行业领先水平的。</p><p></p><p>当然，我们也应意识到，数据治理工作是一项长期、系统性工程，是一个随着市场、公司发展以及组织能力提升而不断深化的过程。我们需要保持清醒的头脑打好攻坚战和持久战，持续提升数据作为重要生产要素的支撑作用。</p><p></p><p></p><h2>未来发展与规划</h2><p></p><p></p><p>InfoQ：在国泰君安的数据平台上，融合了哪些前沿技术（如人工智能等）？接下来会有哪些新的动态吗？</p><p></p><p>苑博：我们也关注一些前沿技术，比如 ChatGPT，还有存算分离和湖仓一体化。</p><p></p><p>我们的目标是为全员提供数据服务，现阶段希望为每个人创建一个数据空间，使其能够有效地管理和充分利用自己的数据，实现数据的增值。</p><p></p><p>这个数据空间并非虚拟概念，对于国泰君安的人来说，它是一个实际的功能。员工在公司参与了多个业务，留下了许多业务足迹，他们应该拥有自己的数据。我们希望能提供这样的一个平台，让员工能够轻松查看和管理他们所涉及的数据，而不必到处寻找数据。</p><p></p><p>尽管这个想法很简单且实用，但涉及到复杂的管理问题和技术挑战。这与存储、管理、机制和工具等多个方面都有关联。我们希望员工可以在平台上查看和加工数据，同时确保数据不会被随意传播。</p><p></p><p>InfoQ：随着 GPT 浪潮的到来，您认为大模型的流行会给证券行业数字化带来哪些影响？国泰君安在这方面有哪些布局和规划？</p><p></p><p>苑博：首先，对于证券行业而言，可能采用行业大模型与小模型相结合的方式来解决这个问题会更实在。</p><p>其次，从长期来看，大模型可能会带来颠覆性的变革。然而，短期内它仍受到很多限制，例如数据治理、数据标准化流程以及 SOP 建设等工作，这些都需要得到有效实施才能更好地发挥大模型的价值。</p><p></p><p>目前来看最有潜力的应用场景可能在客户服务方面，特别是对于互联网用户。我们可以通过协助他们进行投资研究，提供建议。鉴于证券公司的数据基础相对较好，这是一个优势，可以辅助用户进行投资。在短期内，这可能是比较有价值的方向。</p><p></p><p>当然，对于内部的经营分析、报告撰写等工作也会有应用场景，但这些工作仍然需要回归到我们组织能力的提升和业务执行效率的提升上，这也是全面数字化转型的应有之义。</p><p></p><p>内容推荐</p><p>11 月 19 日-20 日在上海成功举办的首届 FCon 全球金融科技大会，以「科技 + 金融，激发创新力量」为主题，汇聚了来自金融龙头企业的数百名技术高管，掀起一场探讨新时代金融科技未来的高潮。经征得大会分享嘉宾同意，InfoQ 数字化经纬为您奉上精彩演讲 PPT！关注「InfoQ 数字化经纬」，回复「金融创新」即可获取 PPT，深度洞悉科技趋势，助您引领金融创新未来！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0e/0e09b84945701548f14ab91a2c49ef51.png\" /></p><p></p>",
    "publish_time": "2023-12-08 11:14:11",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "英特尔软件与先进技术事业部 / 首席工程师胡宁馨确认出席 QCon 上海，分享 WebNN，Web 端侧推理的未来",
    "url": "https://www.infoq.cn/article/TqNGiNCf3yfomTXbrwm9",
    "summary": "<p><a href=\"https://qcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=1208&amp;utm_content=huningxin\">QCon 全球软件开发大会</a>\"，将于 12 月在上海召开。英特尔软件与先进技术事业部 / 首席工程师胡宁馨将发表题为《<a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5646?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=1208&amp;utm_content=huningxin\">WebNN，Web 端侧推理的未来</a>\"》主题分享，探讨 WebNN API 的 W3C 标准进度，对 CNN，Transformer 以及更广泛的生成式 AI (Generative AI) 模型的支持情况和计划，以及在 Chrome，Edge 等浏览器的实现进展。</p><p></p><p><a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5646?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=1208&amp;utm_content=huningxin\">胡宁馨</a>\"，就职于 Intel 软件与先进技术事业部，专注于 Web 技术，W3C 机器学习工作组 Web Neural Network API (WebNN) 规范的发起者和联合编辑，Chromium 项目 Code Committer，WebNN 模块负责人。他在本次会议的演讲内容如下：</p><p></p><p>演讲：WebNN，Web 端侧推理的未来</p><p></p><p>AI PC 以及 AI Mobile 的新兴时代已经到来，越来越多的设备集成了强大的神经处理单元 NPU，以实现高效的人工智能加速，这对需要端侧推理的应用至关重要。除了通过 CPU 和 GPU 进行推理之外，Web Neural Network API (WebNN) 提供了 Web 应用访问此类专有 AI 加速器 NPU 的途径，以获得卓越性能及更低功耗。</p><p></p><p>本次演讲将会给大家分享 WebNN API 的 W3C 标准进度，对 CNN，Transformer 以及更广泛的生成式 AI (Generative AI) 模型的支持情况和计划，以及在 Chrome，Edge 等浏览器的实现进展。作为 JavaScript ML 框架的后端，WebNN 将会在几乎不更改前端代码的前提下，为 Web 开发者及他们的产品带来相较于 Wasm，WebGL 更为优异的性能体验。</p><p></p><p>演讲提纲：</p><p></p><p>当前 Web AI 发展概况主流硬件加速器的发展（CPU，GPU，NPU)WebNN 设计与架构WebNN 代码演示WebNN 浏览器（Chromium）实现WebNN 机器学习框架集成（ONNXRuntime 和 TensorFlowLite)WebNN Transformers 支持WebNN 性能</p><p></p><p>听众收益点：</p><p></p><p>○ 了解 Web 平台对异构处理器的支持</p><p>○ 了解基于 Web 的机器学习模型硬件加速</p><p>○ 了解 Chromium 实现内部细节</p><p></p><p>除上述演讲外，QCon 上海还将围绕&nbsp;<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart\">GenAI和通用大模型应用探索</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1596?utm_source=infoqweb&amp;utm_medium=teacherart\">AI&nbsp;Agent&nbsp;与行业融合应用的前景</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart\">LLM&nbsp;时代的性能优化</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart\">智能化信创软件&nbsp;IDE</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart\">面向人工智能时代的架构</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart\">性能工程：提升效率和创新的新方法</a>\"等专题进行交流。</p><p></p><p>QCon 上海 2023，相约 12 月！ 现在购票，享 9 折优惠，立减￥680！咨询购票请联系：18514549229（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/0113b3dfb187d5f9988b7eb16d2e0594.png\" /></p><p></p>",
    "publish_time": "2023-12-08 11:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从业务应用挑战出发，火山引擎专家深度拆解“弹幕互动方案”的全新实践",
    "url": "https://www.infoq.cn/article/SKtUWjqpsK9DV0gFaR5W",
    "summary": "<p>从互联网到全行业视频化时代，营销、商品、知识与空间的体验正在被重塑和创新，<a href=\"https://www.infoq.cn/article/z1CW0cFhLxLi2KYk258t?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">火山引擎</a>\"视频云以“面向体验，驱动创新”为核心，特别与 NVIDIA 团队合作推出《<a href=\"https://www.infoq.cn/article/OHhA89XUrsQtm7T5Ts43?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">云上新视界</a>\"》线上课程。第五期课程中，火山引擎 RTC 商业化解决方案团队负责人郭健为大家分享了当前热门玩法“弹幕互动”的解决方案与应用实践。</p><p></p><h2>一、什么是“弹幕互动玩法”?</h2><p></p><p></p><p>弹幕互动玩法是依托直播间（直播连麦、语聊房等互娱核心场景），观众可以通过弹幕、送礼物等互动操作，控制直播画面中的互动内容的一种直播方式，具备即开即玩、多人互动等特性，兼具观众互动性强、直播内容游戏化趣味化等特点。</p><p></p><p>从 2014 年的《Plays Pokémon》到 2021 年尾《修勾夜店》爆火，弹幕互动几经翻红。今年开始，弹幕互动受到各大平台的广泛关注，从玩法上线后效果看弹幕互动玩法的户观看人数 / 时长、营收等核心指标都有很好的收益。</p><p></p><h2>二、弹幕互动方案的 3 个核心演进阶段</h2><p></p><p></p><p>弹幕互动经历了 PC 端开播、云游戏方案、云游戏 + <a href=\"https://www.infoq.cn/article/Ue0E2ZXpr2BwaYxlQ0fL?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">RTC </a>\"方案三个阶段。</p><p></p><p>第一个阶段，PC 端开播。传统开播流程需要主播先在 PC 端安装程序和开播工具，互动玩法在主播 PC 上运行和渲染。同时，主播使用 PC 端直播工具（比如 OBS）对本地画面和主播直播画面混流，再推送到直播间。观众进入直播间发送弹幕或者发送礼物参与互动。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f6/f65bdaf68b7489076c5d4af003097847.png\" /></p><p></p><p>这种方式存在一定局限性，比如：</p><p></p><p>弹幕互动内容本身需要实时计算渲染，对设备硬件配置如显卡计算能力有较高要求，甚至堪比 3A 大作性能要求，开播设备性能不足，就会导致弹幕无效甚至内容本身卡死，影响直播间用户体验；越来越多的主播更习惯在移动端随时开播，而只能运行在 PC 端的弹幕互动程序，会大大增加开播门槛，也降低平台玩法覆盖度；移动端开播还可以与平台其他玩法相结合，但如果单独为弹幕玩法准备 PC 端 OBS 开播，既增加了维护成本，也难以进行推广。</p><p></p><p>第二阶段，在直播 / 语聊的基础上引入云游戏。主播进入连麦房间推拉 RTC 流的同时，也需要进入云游戏的房间拉取互动玩法音视频。然后业务层把 H5 引擎拉取到的视频流和业务层采集到的摄像头流在端上合流后，推入直播房间。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/07/07a7368a086b934ca4812074f93dbffb.png\" /></p><p></p><p>这个方案解决了开播平台限制和开播设备的限制，但是有一些方案接入和体验问题。从方案层面看，业务逻辑复杂接入相对麻烦。从体验看，存在嘉宾 / 观众侧主播解说和互动画面会有轻微的不同步、画面延时大、有回声等问题。其中，RTC 引擎订阅云游戏音频观众侧有回声主要是因为游戏流的声音或者麦克风会采集到本地播放的游戏声音。</p><p></p><p>为了解决上个方案的几个问题，火山引擎视频云首推“云游戏 +RTC 方案”方案，而弹幕互动方案也正式进入了第三阶段——火山引擎 RTC 与云游戏产品在服务侧和引擎侧做了深度协同优化。在服务侧，优化了调度方案，保证用户连接的云游戏 pod+RTC 媒体服务器在同一个机房、云游戏音视频流可直接送入 RTC 房间。在引擎侧，云游戏引擎直接依赖宿主侧的火山 RTC 引擎、云游戏引擎裁剪场景无关功能。</p><p></p><p>在具体操作中，首先主播通过云游戏引擎开启互动完成程序，云游戏启动 pod 并创建火山 RTC 房间。完成后，Pod 集成云游戏引擎和 RTC 引擎向火山云游戏房间推音视频流，火山云游戏房间跨房转推音视频流到两个直播 / 语聊房间，嘉宾和观众通过 RTC 直接拉取直播流和云游戏流即可。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/91/918deed71d6b8a03257846fafd65c7d3.png\" /></p><p></p><p>云游戏和 RTC 内部深度协作，缩短数据流转链路在接入直播 / 语聊的基础上，仅需接入 veGameSDK 启动游戏、业务端通过 OpenAPI 同步弹幕 / 礼物数据到云游戏服务器两步即可完成场景“升级”，大大简化业务逻辑，缩短接入周期减少工作量。</p><p></p><h2>三、火山引擎是怎么解决历史方案问题的？</h2><p></p><p></p><p>此前弹幕互动方案所存在的观众弹幕互动延时、主播外放有回声等体验问题，火山引擎方案是如何解决的？</p><p></p><h4>&nbsp;1. 弹幕互动延时问题</h4><p></p><p></p><p>未优化的云游戏方案观众端发送弹幕后，由于传统 RTMP 直播流延迟较大，观看云游戏观众侧会有 3~5 秒延时，并且都会有轻微的互动画面与解说的不同步，体验较差。这些在普通常见的场景可能影响不大，但是在对战场景，战场形势瞬息万变，可能最后一秒的延时失去被“偷家”导致战斗失败。</p><p></p><p>优化后，使用全 RTC 方案，可以让用户参与玩法整体延时&lt;400ms 。</p><p></p><h4>&nbsp;2. 外放回声消除</h4><p></p><p></p><p>在未优化方案中，云游戏的声音在经过扬声器播放后，会被近端用户的麦克风采集到并产生回声问题，需要参考扬声器播放的声音进行回声消除技术处理，云游戏和 RTC 独立运行，云游戏音频无法给到 RTC 引擎，所以容易产生回声。</p><p></p><p>在优化方案中，云游戏音频可以直接跨房转推到 RTC 房间，场景内音频播放通过音频托管的方式统一由 RTC 进行音频播放，有参考信号，可以彻底消除回声，以确保对端收到清晰的声音。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b7/b7615c34243048d5d4edabe66d99ef81.png\" /></p><p></p><p></p><h2>四、弹幕互动方案在业务应用中的挑战与实践</h2><p></p><p></p><h4>&nbsp;1. 卡顿优化</h4><p></p><p></p><p>弹幕互动场景有一个特点就是画面极致高清，一般是高清 1080P、 帧率 30fps、高码率 8Mbps。同时，主播、观众均为移动端设备，随时开播与参与，用户网络环境复杂且不稳定。在这种高分辨率高码率、且网络不稳定情况下极其容易造成卡顿劣化。</p><p></p><p>要优化这种情况，首先把线上 H264 升级为自研 ByteVC1 编解码，在 PSNR（视频质量客户评价）画质质量优于原方案 2dB 时，还能节约 10% 码率。此时对于线上情况码率可能仍较大，火山引擎 RTC 采用智能流控协议 (VISC)，它基于 Simulcast 和 SVC 策略优化而来、更加智能的一种传输协议，它可以综合考虑音视频通话中每个订阅者的个性化需求，在网络情况、终端性能发生变化的时候，自动调整音视频流的配置，最大限度地让每个参与者的个性化需求得到满足，为用户提供更流畅的互动体验。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5a/5a57bdf9d82120b552297cf2fbbe2456.png\" /></p><p></p><h4>&nbsp;2. 操作延时优化</h4><p></p><p></p><p>云游戏在所有的云计算相关应用中，对延时要求最为苛刻，火山引擎 RTC 针对云游戏与 RTC 场景相结合的应用场景，进行全链路延时优化。</p><p></p><p>阶段一，边缘机房阶段。保证用户连接的云游戏 Pod 和 RTC 服务器调度到同一个机房，使用更高效传输方式优化，首帧时长减少约 30ms；降低延时 50ms；编码前优化采集和格式转换，使用 OpenGL 转换替换 libyuv 转换，优化延迟 15ms;阶段二，级联服务优化。减少级联服务器和优化信令传输，优化 20ms;阶段三，订阅端。针对云游戏下行音视频调整 jitterbuffer 大小，降低延时 60~260ms，有优化的处理，可以不影响直播 / 语聊体验；针对不同的硬件解码器做优化，最多优化延迟 90ms；内部渲染替代外部渲染降低延迟 5ms，整体云游戏到端延时可以达到小于 75ms。</p><p></p><h4>&nbsp;3. 性能优化</h4><p></p><p></p><p>弹幕互动玩法可以在个人直播、直播连麦或者跨房 PK 中等场景中加入。在语聊房跨房 PK+ 弹幕互动玩法场景中，假设每个语聊房会有 9 人，两个房间 PK 时，单个用户最多需要拉 18 路音频流和云游戏音视频流，性能压力大，玩法准入机型门槛高，设备发热严重。</p><p></p><p>因此，为减少对手机性能消耗，火山引擎 RTC 使用 RTC 公共流不进房拉流方案。这个方案中，本房间内拉流方式不变，PK 房间的音频流合流后推一路公共流，对比普通语聊模式单个用户只多拉一路音频流和一路云游戏流。两个房间 PK，每个房间 1 位主播、8 位嘉宾、100 位观众流数评估，单房间减少（1+8+100）*8 约 872 路、单用户减少 8 路流，有效优化用户拉流性能，减少 50% 流数量。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3c/3c3b679655ff084ab5807c48eece0a0f.png\" /></p><p></p><p>独立集成云游戏 SDK 包体增量一般 9M 左右，9M 的包增量对客户来说是不可接受的。弹幕互动方案中云游戏直接复用火山引擎 RTCSDK 传输能力，云游戏 SDK 精简包只需操控信令和选路部分，精简包给整体带来增量仅 610KB。</p><p></p><h2>五、写在最后</h2><p></p><p></p><p>总体来说，火山引擎弹幕互动方案有五大优势：</p><p></p><p>不限设备、不限场景，零门槛开播：无论是个播还是多人互动，移动端即可随时随地“云开启”弹幕互动玩法，无需高性能 PC，消除互动内容本身对用户终端算力的限制；热门弹幕互动内容全适配：云游戏支持直接部署基于 UE/Unity 框架的互动内容，底层多种类型 IaaS 和对应 GPU 配置，满足不同等级算力要求的弹幕互动玩法；无惧弹幕高并发，渲染画面高清流畅：云游戏支持 ARM、x86 以及定制化 GPU 等多样化计算资源，并采用自研 ByteVC1 编解码结合动态码率技术，保证互动画面流畅体验同时节约带宽消耗，互动画面 100ms 卡顿率低于 2%；主播解说与玩法进程实时同步：通过火山引擎 RTC 媒体节点和 云游戏 Pod 端同机房调度，超低延时体验，操作延时小于 90ms，主播讲解和内容画面实时同步，保障观众沉浸互动体验；应用最小包增量引入：弹幕互动方案中云游戏可直接复用火山引擎 RTC SDK 传输能力，云游戏 SDK 精简包只需操控信令和选路部分，精简包增量仅 KB 级。</p><p></p><p>而本期课程中介绍的弹幕互动玩法的解决方案技术实践只是“小试牛刀”，如果想要了解更多，可以扫描下方二维码，有更加详细的弹幕互动解决方案和获取弹幕互动 Demo！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/eb/ebba54e6aafb6fea8351787b6285c768.png\" /></p><p></p>",
    "publish_time": "2023-12-08 12:15:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]