[
  {
    "title": "NVIDIA发布新的C++数值计算库：支持GPU加速",
    "url": "https://www.infoq.cn/article/6P17qXTgH2XI6oYKmgvh",
    "summary": "<p>&nbsp;<a href=\"https://developer.nvidia.com/blog/speeding-up-numerical-computing-in-c-with-a-python-like-syntax-in-nvidia-matx/\">MatX 是一个 C++ 库</a>\"，由 Nvidia 为其自有的 GPU 开发，，旨在使用高级语法在数值计算中实现接近本地性能，不遑多让于 Python 的 scipy 或 MATLAB。<a href=\"https://github.com/NVIDIA/MatX/releases\">它的最新版本引入了</a>\"许多新功能，包括可以将变换作为运算符，以及新的运算符，如上采样、下采样、pwelch 等等。</p><p>&nbsp;</p><p>现在，可以在任何运算符表达式中使用变换，以使用运算符融合来进行延迟评估。运算符融合是 MatX 中的一个特殊功能，旨在提高性能，通过减少内存访问，从而避免内存访问成本相对寄存器访问昂贵数个数量级的问题。</p><p>&nbsp;</p><p>旨在通过减少内存访问来提高性能，内存访问的成本可能比寄存器访问高出几个数量级。使用运算符融合，一个表达式不会立即计算，而是转换为表示该表达式的 C++ 类型，该类型将在需要其值时进行评估。换句话说，不是立即计算表达式的结果，比如：</p><p>&nbsp;</p><p><code lang=\"null\">(A = B * (cos(C) / D)).run();</code></p><p>&nbsp;</p><p>你可以将其值存储在一个中间表达式中：</p><p>&nbsp;</p><p><code lang=\"null\">auto op = (B * (cos(C) / D));</code></p><p>&nbsp;</p><p>将其与其他表达式组合，并在需要时进行延迟评估。这一特性是通过重载 C++ 运算符实现的。MatX 的最新版本将这一功能扩展到了变换中，例如在以下表达式中：</p><p>&nbsp;</p><p><code lang=\"null\">(A = B * fft(C)).run();</code></p><p>&nbsp;</p><p>编译器能够理解乘法运算符的右侧是 FFT 变换，而左侧是另一个表达式，可以在编译时与前者的结果进行融合。</p><p>&nbsp;</p><p>值得注意的是，将变换用作运算符的这种新语法与以前的变换使用方式存在一些不兼容。具体而言，以前你可能会写成matmul(C, A, B, stream)，而现在应该使用(C = matmul(A,B)).run(stream)。</p><p>&nbsp;</p><p>MatX 0.6.0 引入的另一个新功能是新的<a href=\"https://github.com/NVIDIA/MatX/pull/459#issuecomment-1658987574\">多相通道化运算符</a>\"，它可以将输入信号分成一组通道。例如，它可用于将高采样率的宽带信号转换为多个低采样率的窄带信号。</p><p>&nbsp;</p><p>新的运算符包括 <a href=\"https://nvidia.github.io/MatX/api/signalimage/general/upsample.html\">`upsample`</a>\"，用于通过插入零来上采样信号；<a href=\"https://nvidia.github.io/MatX/api/signalimage/general/downsample.html\">downsample</a>\"，用于通过丢弃样本来下采样信号；<a href=\"https://github.com/NVIDIA/MatX/pull/479\">pwelch</a>\"，用于可视化信号的频谱，而无需进行预处理。</p><p>&nbsp;</p><p>MatX 的最新版本拥有更多功能，此处无法详尽列出。如果你对完整细节感兴趣，不要错过官方发布说明。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/10/Nvidia-matx-cpp-numerical-lib/\">https://www.infoq.com/news/2023/10/Nvidia-matx-cpp-numerical-lib/</a>\"</p>",
    "publish_time": "2023-11-15 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "阿里巴巴总监郭瑞杰（国泊），确认担任 QCon Serverless 化云产品架构设计与实践专题出品人",
    "url": "https://www.infoq.cn/article/RvMo6z9bAo5SXr69VMk8",
    "summary": "<p><a href=\"https://qcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=7&amp;utm_term=1115&amp;utm_content=guoruijie\">QCon 全球软件开发大会</a>\"，将于 12 月在上海召开。阿里巴巴总监郭瑞杰（国泊）将担任「 <a href=\"https://qcon.infoq.cn/2023/shanghai/track/1608?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=7&amp;utm_term=1115&amp;utm_content=guoruijie\">Serverless 化云产品架构设计与实践</a>\"」的专题出品人。在此次专题中，你将了解到 Serverless 化云产品的快速弹性、存算分离、租户隔离等技术架构设计，以及应用实践等。</p><p></p><p><a href=\"https://qcon.infoq.cn/2023/shanghai/track/1608?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=7&amp;utm_term=1115&amp;utm_content=guoruijie\">郭瑞杰（国泊）</a>\"，2009 年毕业于毕业于中国科学院计算技术研究所，毕业后加入阿里巴巴，先后负责阿里巴巴搜索平台 iSearch4.5、问天 2、问天 3 等架构设计和开发工作，现任阿里巴巴控股集团智能引擎事业部云服务负责人，阿里云智能集团计算平台事业部搜索推荐云服务负责人，Havenask 开源项目负责人。负责构建了阿里云 Elasticsearch、开放搜索 OpenSearch、智能推荐 AIRec、图计算 GraphCompute 等云产品。</p><p></p><p>相信郭瑞杰（国泊）的到来，可以帮助提升此专题的质量，让你学习到 Serverless 化云产品按量付费、快速弹性伸缩、无需感知底层物理资源，更为经济的运维成本等优势。目前，赢得了业界的广泛认可和积极响应。</p><p></p><p>除上述专题外，QCon 上海还将围绕&nbsp;<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart\">智能化信创软件&nbsp;IDE</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart\">GenAI和通用大模型应用探索</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart\">LLM&nbsp;时代的性能优化</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1599?utm_source=infoqweb&amp;utm_medium=teacherart\">LLM&nbsp;时代的大前端技术</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart\">面向人工智能时代的架构</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart\">性能工程：提升效率和创新的新方法</a>\"等专题进行交流。</p><p></p><p>QCon 上海 2023，相约 12 月！ 7 折优惠仅剩最后 3 天，现在购票立减￥2040！咨询购票请联系：18514549229（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/0113b3dfb187d5f9988b7eb16d2e0594.png\" /></p><p></p>",
    "publish_time": "2023-11-15 11:32:16",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "首周聚焦百度智能云千帆大模型平台使用，《大模型应用实践》实训营 11 月 16 日开讲！",
    "url": "https://www.infoq.cn/article/bEPZxpLYrCAUYm1RLTQM",
    "summary": "<p><a href=\"https://www.infoq.cn/article/JAE4rgf6s1cHNQoYZ93I?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">百度智能云千帆大模型</a>\"平台官方出品的《大模型应用实践》实训营本周正式上线！这是百度智能云推出的首个系列课程，课程内容满满干货！</p><p></p><p>11 月 16 日本周四即将开课，首周由<a href=\"https://www.infoq.cn/article/WrlUWpf2OkgQsSAD6NJ1?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">百度智能云</a>\"千帆大模型平台产品经理以及百度智能云千帆资深用户知名技术 UP 主同济子豪兄来进行平台使用攻略及使用经验分享！欢迎个人及企业开发者与百度智能云千帆<a href=\"https://www.infoq.cn/article/o8abj2wff5yLfGWuB0E1?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">大模型平台</a>\"共同学习进步！</p><p></p><p>&gt;&gt;&gt;立即扫描下方二维码进行报名&lt;&lt;&lt;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ce/ce25c89ce7eafdfeec62f524decdf39a.jpeg\" /></p><p></p><p></p><h2>首周课程具体内容</h2><p></p><p>&nbsp;</p><p>课程一：11 月 16 日 19:00-20:00 直播</p><p></p><p>课程名称：百度智能云千帆平台明星大模型与工具链概览课程讲师：Ziqi 百度智能云千帆大模型平台产品经理课程亮点内容：</p><p>     百度智能云千帆大模型平台全能力概览</p><p>     精选「明星大模型」使用攻略（在应用场景下该如何选择适用大模型）</p><p>&nbsp;</p><p>课程二：11 月 17 日 19:00-20:00 直播</p><p></p><p>课程名称：平台应用分享：基于文心大模型 4.0 打造大模型时代游戏 NPC课程讲师：同济子豪兄 知名技术 UP 主课程亮点内容：</p><p>     文心大模型 4.0 能力展示</p><p>     游戏行业实战：如何基于大模型创建游戏 NPC</p><p>     基于应用场景，百度智能云千帆大模型平台整体使用指南</p><p></p><p></p><h2>实训营课程福利</h2><p></p><p></p><p>实训营优质用户将有机会获得百度智能云千帆社区周边产品以及百度智能云千帆产品体验代金券（适用于百度智能云千帆全产品），除此之外参与实训营的优质企业认证的开发者还将有机会获得 200 元百度智能云千帆平台代金券！</p><p></p><p>更多实训营福利等待大家，快来点击【<a href=\"https://cloud.baidu.com/survey/qianfantraining.html?track=infoq\">此处链接</a>\"】报名加入我们吧！！</p>",
    "publish_time": "2023-11-15 13:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "李开复旗下340亿参数开源大模型被指“套壳LLaMA”，最新回应来了！",
    "url": "https://www.infoq.cn/article/YCV0E9FALCpIUftbJiBv",
    "summary": "<p></p><blockquote>有网友在 Twitter 上评价道：“这就是中国大模型研发现状？”</blockquote><p></p><p></p><h2>李开复的 Yi-34B 被指是对 LLaMA 的重构</h2><p></p><p>&nbsp;</p><p>近日，国外开发者&nbsp;ehartford&nbsp;在开源大模型 Yi-34B 的 Hugging Face 主页上评论称，除了对两个张量做重命名之外，Yi 团队完全使用了&nbsp;LLaMA&nbsp;架构（input_layernorm,&nbsp;post_attention_layernorm）&nbsp;<a href=\"https://github.com/turboderp/exllamav2/commit/6d24e1ad40d89f64b1bd3ae36e639c74c9f730b2\">https://github.com/turboderp/exllamav2/commit/6d24e1ad40d89f64b1bd3ae36e639c74c9f730b2</a>\"&nbsp;由于 LLaMA 架构涉及大量投资和工具，因此保留全部张量的原名称显然更好。开源社区肯定会重新发布 Yi 模型并调整张量名称，制作出符合 LLaMA 架构的新版本。我们希望贵团队能在模型被广泛部署之前也能官方采取这项调整，确保成果最终得到妥善使用。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/52/523d2c1589682c4fb0d376465b8a9b5c.png\" /></p><p></p><p>ehartford 补充道，他只是提醒 Yi 团队调整张量名称来匹配相关资源，直接套用 LLaMA 架构没有任何问题，训练才是重点。</p><p>&nbsp;</p><p>网友 brucethemoose 认为，不仅如此，Yi-34B 还是对 LLaMA 代码的重构，而且似乎没有做任何改动。这显然就是在原始 Apache 2.0 llama 文件的基础上稍做调整，却没有提及LLaMA：<a href=\"https://www.diffchecker.com/bJTqkvmQ/\">https://www.diffchecker.com/bJTqkvmQ/</a>\"</p><p>&nbsp;</p><p>brucethemoose 提到：</p><p>&nbsp;</p><p></p><blockquote>这些调整并没有 PR 到 Transformer 当中，只是作为外部代码被添加了进来，这样可能引发安全风险、或者与框架发生冲突。HuggingFace 排行榜甚至不打算对其 200K 版本做基准测试，因为该模型根本没有自定义代码政策。他们宣称这是套 32K 模型，但实际配置为 4K 模型，没有 RoPE 拉伸配置，也没有解释应该如何拉伸。目前，关于其如何调校数据的信息完全为零。他们并未提供重现基准测试结果的说明，包括高到可疑的 MMLU 得分。&nbsp;任何对 AI 稍有了解的朋友都会意识到其中的问题。这是纯粹在吹牛？吹完了就跑？违反许可证要求？在基准测试里作弊？都有可能，但却没人在乎。反正他们可以继续发论文，或者是骗走死而一大笔风险投资。至少在这个圈子里，Yi 还算是高于平均水平，毕竟它总归是套基础模型、而且性能似乎的确不错。</blockquote><p></p><p>&nbsp;</p><p>有不少网友与 brucethemoose 观点相同，认为 Yi-34B 纯粹就是 LLaMA 的复制粘贴，再对部分张量重新命名，“太丢人了”。网友&nbsp;JosephusCheung&nbsp;表示，如果 Yi 团队用的就是 Meta LLaMA 原架构、代码库还有相关资源，那就必须得遵守 LLaMA 所规定的许可协议。换句话说，如果直接按照 LLaMA 的形式发布 Yi 模型，那么 Yi 许可中的很多条款也就无法成立。我认为这种行为非常粗鲁，Yi 团队明显对许可证制度缺乏应有的尊重。有些事情开源社区可以做，但商业实体绝对不行。</p><p>&nbsp;</p><p>网友&nbsp;turboderp&nbsp;认为，提交当中涉及一些重构，但也有一项用来对 RMSNorm 模块的键进行重命名的变更：如果模型的 config 文件识别到模型为“YiForCausalLM”，则“input_layernorm”为“In1”且“post_attention_layernorm”为“In2”。“据我所知，除此之外 Yi-34B 的架构与 LLaMA 没有任何区别。其实 OpenLLaMA 也是类似的情况。虽然 Yi-34B 的词库有两倍大，但它仍然是个 SentencePiece 模型而且能够正常运行。所以我们很难说 Yi-34B 算不算新成果。其架构在 modeling_yi.py 中布局，而且除了张量名称的调整之外，看起来跟 LLaMA 一模一样。当然，可能还有其他被我忽略掉的差异。”</p><p>&nbsp;</p><p>值得一提的是，前几日，阿里前技术副总裁、大模型行业创业者贾扬清曾在朋友圈中提到，有个“大厂新模型 exactly 就是 LLaMA 的架构，但是为了表示不一样，把代码里面的名字从 LLaMA 改成了他们的名字，然后换了几个变量名。然后，海外有工程师直接指了这一点出来... 还有人在 HF 上面放了个把名字改回去的 checkpoint，说好了，现在你们可以直接用 LLaMA 的代码来 load 这个 checkpoint 了”。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1a/1a36acb8fd82a4d313bbfb564db7c208.png\" /></p><p></p><p>&nbsp;贾扬清虽然没有指明具体的大模型名字，但有观点怀疑其指的很可能就是零一万物旗下的&nbsp;Yi-34B。</p><p></p><h2>零一万物回应争议：基于 GPT 研发，将进行代码更新</h2><p></p><p>&nbsp;</p><p>对于本次争议，零一万物回应称：GPT 是一个业内公认的成熟架构，LLaMA 在 GPT 上做了总结。零一万物研发大模型的结构设计基于 GPT 成熟结构，借鉴了行业顶尖水平的公开成果，由于大模型技术发展还在非常初期，与行业主流保持一致的结构，更有利于整体的适配与未来的迭代。同时零一万物团队对模型和训练的理解做了大量工作，也在持续探索模型结构层面本质上的突破。</p><p>&nbsp;</p><p>零一万物团队开源总监&nbsp;richardllin 回应 ehartford 称：</p><p>&nbsp;</p><p></p><blockquote>非常感谢您在讨论中指出了这一点，也感谢您以良好的耐心等待我们做出回复。您对张量名称的看法是正确的，我们会按照您的建议将其从 Yi 重命名为 LLaMA。我们也一直强调以准确、透明的方式完成工作。您在前面的帖子中提到，“开源社区肯定会重新发布 Yi 模型并调整张量名称，制作出符合 LLaMA 架构的新版本。”这让我们不禁好奇：您是希望提交一条包含这些变更的 PR 吗？或者说，如果您希望由我们处理更新，我们也可以按要求操作并在本 repo 中发布新版本——这样可能更省时间。这个命名问题是我们的疏忽。在大量训练实验中，我们对代码进行了多次重命名以满足实验要求。但在发布正式版本之前，我们显然没能将它们全部正确调整回来。我们对此深感抱歉，对于由此造成的混乱也感到遗憾。我们正在努力加强工作流程，力争未来不出现类似的失误。您的反馈给了我们很大帮助，接下来我们将再次核查所有代码，确保其余部分准确无误。也希望您还有整个社区持续关注我们的工作进展。再次感谢您的提醒，期待您的更多支持和宝贵建议。</blockquote><p></p><p></p><h2>340亿参数开源大模型 Yi-34B&nbsp;</h2><p></p><p>&nbsp;</p><p>据悉，开源大模型&nbsp;Yi-34B 来自李开复旗下 AI 大模型创业公司“零一万物”，该模型发布于 2023 年 11 月 6 日。今年 7 月，李开复博士正式官宣并上线了其筹组的“AI 2.0”新公司：零一万物。此前李开复曾表示，AI 大语言模型是中国不能错过的历史机遇，零一万物就是在今年 3 月下旬，由他亲自带队孵化的新品牌。</p><p>&nbsp;</p><p>Yi-34B 是一个双语（英语和中文）基础模型，经过 340 亿个参数训练，明显小于 Falcon-180B 和 Meta LlaMa2-70B 等其他开放模型。零一万物团队对其进行了一系列打榜测试，具体成绩包括：</p><p>&nbsp;</p><p>Hugging Face 英文测试榜单，以 70.72 分数位列全球第一；以小博大，作为国产大模型碾压 Llama-2 70B 和 Falcon-180B 等一众大模型（参数量仅为后两者的 1/2、1/5）；C-Eval 中文能力排行榜位居第一，超越了全球所有开源模型；MMLU、BBH 等八大综合能力表现全部胜出，Yi-34B 在通用能力、知识推理、阅读理解等多项指标评比中“击败全球玩家”；......</p><p>&nbsp;</p><p>对于模型尺寸的选择，零一万物团队认为，34B 是一个黄金尺寸。虽然 6B 也能在某些领域，比如客服上可用，但模型毕竟越大越好，但随之而来的就是推理成本和后续训练的系列资源问题。</p><p>&nbsp;</p><p>“34B 不会小到没有涌现或者涌现不够，完全达到了涌现的门槛。同时它又没有太大，还是允许高效率地单卡推理，而且不一定需要 H 和 A 级别的卡，只要内存足够，4090 或 3090 都是可以使用的。”李开复解释道，“既满足了精度的要求，训练推理成本友好，达到涌现的门槛，是属于非常多的商业应用都可以做的。”</p><p>&nbsp;</p><p>另外，李开复提到，通用模型决定了行业模型的天花板。虽然行业大模型有相当大的价值，但是底座如果不好，也无法完成超过底座的事情，所以选底座就要选表现最好的底座。李开复自信地表示，“今天我们在中英文上就是最好的底座，没有之一，也希望更多人选择 Yi-34B。”</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://huggingface.co/01-ai/Yi-34B/discussions/11\">https://huggingface.co/01-ai/Yi-34B/discussions/11</a>\"</p><p><a href=\"https://news.ycombinator.com/item?id=38258015\">https://news.ycombinator.com/item?id=38258015</a>\"</p><p><a href=\"https://www.infoq.cn/news/cVfuQaHVJ0SDPtP2jb7m\">https://www.infoq.cn/news/cVfuQaHVJ0SDPtP2jb7m</a>\"</p>",
    "publish_time": "2023-11-15 14:14:16",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "“谷歌有谷歌的规矩”",
    "url": "https://www.infoq.cn/article/91ScH6rzjCfPqcodde2a",
    "summary": "<p></p><p></p><blockquote>这可能只是众多被谷歌收购的公司中，不被众人注意的其中一个。&nbsp;2013年，Shreyans Bhansali 和Chris Pedregal 做了一个互联网学习平台，之后发展成了类似Quora的系统，也有点像国内的“作业帮”。Socratic在App Store上拥有超50万次评价，综合4.9星。2016年，Socratic从 Shasta Ventures、Spark Capital 和 Omidyar Network 筹集了 600 万美元的 A 轮融资。&nbsp;后来，这家10人初创公司被谷歌收购，创始团队加入谷歌，也开始以谷歌的方式重塑自家产品。下面是Bhansali 的分享，他讲述了公司被收购的过程以及并入谷歌工作后发现的谷歌工程文化。Bhansali 意识到要想在谷歌实现理想，就得按谷歌的规矩来。</blockquote><p></p><p>&nbsp;</p><p>在2017年着手为Socratic筹划B轮融资时，我们很快意识到过去以牺牲收入为代价换取客群的方式必然会使公司陷入困境。之前的快速增长让我们出现在投资人的视野当中，但每家风险投资机构都要求我们制定详尽的货币化计划。于是我们慢慢学到了精髓：Socratic为那帮连信用卡都没有的高中生们开发的教育类应用，不可能发展成什么惊人的业务。</p><p>&nbsp;</p><p>大约在同一时间，我们被引荐给了SnapChat公司CEO Evan Spiegel。Evan建议我们建立合作伙伴关系，将我们基于摄像头的作业助手软件添加到他们的应用当中。但我方一位顾问认为，既然我们已经见到了该公司的业务发展主管，那就意味着对方可能有收购的意向。这时候最好立刻启动竞争流程，于是我们开始主动联系微软、Chegg、Gyju’s还有谷歌。</p><p>&nbsp;</p><p>另一位联合创始人Chris之前在谷歌工作过，于是跟之前的经理重新取得了联系。对方介绍了谷歌自己围绕手机摄像头打造的应用Lens。而我们不知道的是，她本人最近还跟教育机构Khan Academy以及Android的联合创始人一起搞了自己的教育创业。在当面对话之后，我们发现自己的业务跟这位导师的AI教育发展愿景高度重合。也可能是我们之前刚刚拿下Google 2017最佳应用的桂冠，所以在会面后不久，双方就启动了收购流利，最终Socratic于2018年3月正式并入谷歌麾下。</p><p>&nbsp;</p><p>我们加入了一支规模相仿的谷歌团队，团队成员都是长年任职的老员工。Chris和我成为产品与工程主管，负责开发AI教师并将功能纳入谷歌的其他核心产品。</p><p>&nbsp;</p><p>在接下来的三年中，我们重塑了Socratic并以“Socratic by Google”的名义发布，相关功能也被引入谷歌搜索和Lens应用当中。此外，我们还推出了数学解题工具和分步数学教学原型，服务开始延伸至整个谷歌生态。</p><p>&nbsp;</p><p>以下是我在其间学到的一点经验心得。</p><p>&nbsp;</p><p></p><h2>“谷歌有谷歌的规矩”</h2><p></p><p>&nbsp;</p><p>在谷歌工作，就像是拥有第二本护照。前往世界上的任何一座主要城市，我都会骄傲地展示自己的谷歌徽章。那里有漂亮的办公室、美味的食物、宽大的办公桌，以及能与谷歌20万员工随时沟通的顺畅渠道。这是一种奇妙的感觉，谷歌的全球影响力第一次以如此具象的方式呈现在我面前。</p><p>&nbsp;</p><p>注：谷歌徽章就是公司里等级制度的鲜明体现。白色徽章代表新入职的正式员工，绿色徽章代表实习生。红色徽章代表临时工、供应商和外包商（TVC），这部分员工总数超过10万，也肩负着从平凡到关键的各类任务，但福利和访问权限远低于正式员工（这也在谷歌内部造成了许多问题），甚至无权声称自己是谷歌的一员。</p><p>&nbsp;</p><p>更令人震惊的&nbsp;，我可以立即访问谷歌的所有资产。访问他们巨大的monorepo，其中包含数十亿行代码，涵盖谷歌旗下的所有产品。还有覆盖全球各地的数据中心实时状态，跨越二十年历史的战略文件，甚至是那些以往我只能仰望的传奇项目。</p><p>&nbsp;</p><p>谷歌有谷歌的规矩。谷歌使用的几乎每款软件、每处基础设施都来自内部构建，这是因为谷歌一路大踏步发展，所以早早就遇到了大多数其他公司后来才意识到的工程难题。站在谷歌这等体量之上，外部世界已经可以忽略不计，围墙内部就足以形成浩瀚无边的技术宇宙。</p><p>&nbsp;</p><p>也就是说，我们不可能保留原本的Socratic代码库。来了谷歌，我们需要从头开始，与新团队一同重塑产品形态和底层设计，之后在谷歌技术栈这上重构应用本体。具体来讲，我们之前已经解决掉的问题（比如如何使用机器学习系统对作业内容进行分类）现在需要用谷歌的技术和标准来重新解决。不用说，谷歌的标准当然比我们高得多。</p><p>&nbsp;</p><p>我们唯一能够自主决定的，就是继续沿用之前的应用吉祥物“Ceebo”。看看谷歌的应用图标集，就会发现它们形状简单而且只用四种颜色。</p><p>&nbsp;</p><p>大厂有大厂的坚持，但在我们看来这也太无聊了。他们强调“去拟人化”，但我们觉得这套框框拿去管理Android就好了，手别伸到应用这边来。最终我们赢了，原因是这边体量太小，不会造成什么大影响。软件图标继续沿用Ceebo，还在谷歌内部得到蓬勃发展，获得了几十种变体。如今，Ceebo终于出现在谷歌官方的文档和网站当中。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/eb/eb51ea74792383f67cd57b61fb5b1788.png\" /></p><p></p><p>各种常见谷歌应用图标，还有我们的Ceebo</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0f/0f17526a0edb8b28ae2041503b435ea3.png\" /></p><p></p><p>&nbsp;</p><p>重复完成简单工作，会带来神奇的启发。通过与资深搜索人士重构我们的查询分类系统，让我们对于搜索功能本身有了更深刻、更富启发的理解。一方面，信息检索工具有着令人难以置信的深度，而计算新信号并将其添加到互联网的每个页面上则塑造出了我们之前无法想象的新功能（比如，现在搜索contains_math或者学科：化学都会显示我们的应用）。</p><p>&nbsp;</p><p></p><h2>用户不到5000万，“不值得浪费时间”</h2><p></p><p>&nbsp;</p><p>另一方面，我们发现大多数搜索改进，都是由工程师们在电子表格上“并排”比较新旧结果来手动审核来完成的。</p><p>&nbsp;</p><p>很多人都觉得谷歌工程主要是靠各种高深莫测的算法来实现的。虽然有时确实如此，但搜索或者AI工程师的主要工作其实就是观察示例、提取模式、手动标注数据，还有处理大量不可扩展的杂乱分析。这种情况似乎也是<a href=\"https://twitter.com/_jasonwei/status/1708921475829481683\">顶尖AI团队中的常态</a>\"：</p><p>&nbsp;</p><p>“我注意的一大规律，就是优秀的AI研究人员更愿意手动检查大量数据。更重要的是，他们建立起基础设施，因此能够快速完成手动数据检查。虽然过程比较枯燥乏味，但手动检查数据确实能帮助他们建立起关于问题的宝贵直觉。”</p><p>&nbsp;</p><p>大多数问题在谷歌这边都不值得浪费时间，只有关键议题才有资格拿出来讨论。大多数涉及10到5000万用户的问题都不值得谷歌浪费时间，也不符合他们的运营策略。只有对那些涉及业务定位、发展策略和关乎个人职位晋升的事情上，他们才愿意投入巨大的热情。</p><p>&nbsp;</p><p>举例来说，计算机视觉是Socratic界面中的重要组成部分，负责读取图像中的文本和数学内容。作为一家初创公司，我们选择使用第三方工具。但考虑到敏感数据暴露、业务规模预期还有复杂的供应商审查流程之后，谷歌认为这种依赖外部的作法没有必要。有时候，直接把对方买下来，将外部技术转为内部方案还更容易一些。同样的，在发现我们的应用功能值得挖掘之后，AI研究团队会聘请顶尖人才参与探索，并在短短6个月内就开发出了世界一流的数学识别API。</p><p>&nbsp;</p><p>而且参考<a href=\"https://gist.github.com/chitchcock/1281611\">Steve Yegge</a>\"比较谷歌和亚马逊平台的经典博文，大家就会知道这项遥遥领先的功能至今仍无敌手。</p><p>&nbsp;</p><p></p><h2>打败谷歌员工的是频繁的重组</h2><p></p><p>&nbsp;</p><p>谷歌是一整套向着不断变化的目标而努力的网络。只要被合适的人关注到，那谷歌之内就会孕育出新的奇迹。</p><p>&nbsp;</p><p>具体来讲，就是一位了解细节的副总裁、一支遵循相关章程的研究团队，或者再加上与公司发展目标的一致性。产品经理的主要工作就是驾驭住这种混乱与利益冲突。之后，项目还需要得到隐私、信任、安全以及基础设施等部门的批准。往往需要进行几十次对话才能确定一个想法是否可行，再通过几百次对话让灵感转化为可以落地的成果。</p><p>&nbsp;</p><p>但前面说的只是最乐观的情况。奇迹之所以被称为奇迹，就是因为它极为罕见。更普遍的情况是，每过一个季度，团队的目标都有可能发生变化，甚至整个队伍在“重组”之后彻底消失。这种现象非常普遍，所以谷歌员工们早已习惯了别离，只能把重组视为新的开始。</p><p>&nbsp;</p><p>假设以上一系列大刀阔斧的操作都没伤到你，也还有最后一道考验要通过：大家可能突然发现，公司里还有另一个之前从没听说过的团队也在做类似的尝试。于是是时候一决胜负了，因为只有一支团队能够胜出并赢得项目所有权。而如果失败，不好意思，你的API会被快速“弃用”，哪怕替代方案还远没有准备就绪。</p><p>&nbsp;</p><p>谷歌员工希望打造出色的成果，但往往有心无力。毫无疑问，总有些人单纯是为了混口饭吃，比如每天上班摸鱼、一有机会就想提前退休。但在谷歌，我遇到的每个人都认真、勤奋，想要成就伟大的事业。</p><p>&nbsp;</p><p>而真正击败他们的，是繁琐的挑战、频繁的重组、过往失败在他们身上烙下的耻辱印记，被迫在全球顶尖的舞台上重复最简单的工作。初创公司空间更大、每位员工都能随意施为，但谷歌这边就极度缺乏这种自由度。</p><p>&nbsp;</p><p>阻碍发展的还有人们自身——最睿智的头脑们在这里被迫谨言慎行，就连领导者自己也不敢直接说出那些令人不安的事实。我还发现不少缺乏明确定位的员工，但他们仍然长年留在谷歌，甚至通过一个个根本没有意义的岗位保持着晋升。</p><p>&nbsp;</p><p></p><p><img src=\"https://uploader.shimo.im/f/CUYLWqUB9AQulqi6.png!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDAwMjkxMTIsImZpbGVHVUlEIjoicnAzT01hV0o4ZFVkVjhrbSIsImlhdCI6MTcwMDAyODgxMiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyNDM2MDc5MH0.CPSNGEc4HRF_cfyo_XfM1X87u-auUgSHbRMGSdMZY_c\" /></p><p></p><p>&nbsp;</p><p>头重脚轻的组织最难驾驭。结合自己的切身感受，我发现谷歌这种头重脚轻的组织结构已经严重制约了其顺利发展。一支汇聚了多位成功联合创始人、外加十几位谷歌资深工程师的团队听起来似乎战斗力极强，但却往往是什么都做不了、什么都通不过。</p><p>&nbsp;</p><p>如果真有多个领域需要探索、目标已经明确设定而且拥有很强的自主权，那这样的结构应该能够发挥优势。但大多数情况下我们只是在开发一款统一的产品，这时候就需要一位明确的领导者、一个明确的方向，再加上众多实干家、而非空想家。另外跟直觉相反，在早期项目中添加人手并不能加快速度，反而可能导致工作陷入停滞。</p><p>&nbsp;</p><p></p><h2>被威胁到了才改变</h2><p></p><p>&nbsp;</p><p>技术债真实存在，流程债也一样。工程师们对于技术债应该不会陌生：当下为了节约时间、快速发布功能所抄的近道，未来都会成为制约项目进一步发展的阻力。要么早点偿还，要么就是成为项目身上流血不止的伤口。优秀的团队总会定期找段不忙的时间，有条不紊地偿还掉一部分“债务”。</p><p>&nbsp;</p><p>流程债的情况跟技术债类似，可能是因为之前产品出错而添加了新的审核，有可能是引入法务检查以防止潜在诉讼，包括在文档模板中增设新的部分。多年以来，层层积累下的流程已经极度繁复，导致开发完成数月有余的新功能陷入审查而迟迟无法发布，而且没人说得清该怎么提速。</p><p>&nbsp;</p><p>在某些极端情况下，流程甚至需要回滚：谷歌最近调整了繁琐的绩效评估流程，从每年两次改为一年一次、从长问卷改为短问卷，希望把评估工作占用经理们的时间从每年30%压缩到10%以下。</p><p>&nbsp;</p><p>但这往往是因为受到了外部威胁的冲击，因为如果不这么做，公司就会加速衰落、直到失去一切。谷歌才是ChatGPT底层技术的真正发明者，但胜利的果实却别人摘下。如今，他们希望夺回自己在AI领域的领先地位，可同时又得跟时刻提防出岔子的审核人员之间斗智斗勇。</p><p>&nbsp;</p><p>但只要处理得当，谷歌仍有创造奇迹的能力。谷歌曾经提出过“三个尊重”的价值理念：尊重用户、尊重彼此、尊重机遇。前两条比较容易理解，但第三条该怎么解读就各有各的说法了。</p><p>&nbsp;</p><p>我自己是这样认识的：我们在谷歌工作，这是一家利润丰厚、天才云集的企业。我们薪水丰厚、赚得盆满钵满，生活在位于生态链顶端的硅谷世界里。作为幸运之神的宠儿，这样的我们能做的最好的事情是什么？</p><p>&nbsp;</p><p>我个人的答案很简单：找到所在领域中最重要的问题，并拼尽一切将其解决。</p><p>&nbsp;</p><p>实际上，践行理念的第一步就是先做好分配给自己的工作。而只要日常工作处理得当，我们就有机会深入到庞大的谷歌网络，接触正在筹划的创新内容，凝聚出清晰的未来愿景，通过文档和演示让它引发共鸣，找到同样关注这个问题的高层领导者，同时坚持不懈地宣传自己的目标。</p><p>&nbsp;</p><p>从某种意义上讲，我自己也算是做到了这些。最典型的例子就是开发分步数学教学演示，这项功能是以之前的数学解答工具为基础，由三个人花几个月时间制作完成。该演示将我们的智能辅导愿景转化成了可以体验的直观形式——有链接，可以直接使用，也可以转发给他人。有了这样的成果，后续的对话才有可能性，体验者能够做出相应反馈，功能的影响力逐渐扩散到团队之外，再带着更多观点和建议回到我们手中。</p><p>&nbsp;</p><p>当然，我也有做错的时候。有位领导就觉得我们的想法不错，安排设计师制作了出色的演示，而且不管走到哪都向其他人推荐。但他当时身处的部门跟项目理念不合，他的上司根本就不关注这个方向。最终他转到了另一个团队，在那里终于有机会把梦想变成现实。</p><p>&nbsp;</p><p>大多数收购其实都失败了，就连Socratic也不能算完全成功。一方面，我们成功将两种截然不同的文化融合到了一起，我们的产品也继续存在并不断发展，每年支持约50亿次查询。更重要的是，Socratic的初创班底也都获得了广阔的职业发展空间。</p><p>&nbsp;</p><p>但另一方面，Chris和我还是离开了谷歌去建立了新的初创公司，而且直到现在，Socratic团队或者谷歌也仍未推出一款现象级的AI教育产品。不过我有信心，只要别被暴力重组，Socratic项目组早晚可以实现这个目标。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://shreyans.org/google\">https://shreyans.org/google</a>\"</p><p>&nbsp;</p><p>相关链接：</p><p><a href=\"https://gist.github.com/chitchcock/1281611\">https://gist.github.com/chitchcock/1281611</a>\"</p><p><a href=\"https://twitter.com/_jasonwei/status/1708921475829481683\">https://twitter.com/_jasonwei/status/1708921475829481683</a>\"</p><p><a href=\"https://techcrunch.com/2015/03/25/did-socratic-org-raise-6-million/\">https://techcrunch.com/2015/03/25/did-socratic-org-raise-6-million/</a>\"</p>",
    "publish_time": "2023-11-15 14:42:59",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AI Agent在全球化背景下的机遇和挑战 ｜InfoQ《极客有约》",
    "url": "https://www.infoq.cn/article/UiQS2L3Axj7kBIlsSVyO",
    "summary": "<p>随着科技的飞速发展，人工智能（AI）已经渗透到我们生活的方方面面。在这个全球化的时代，AI Agent更是成为了科技领域的热门话题。那么，在全球化背景下，AI Agent将面临怎样的机遇和挑战？有哪些落地场景？未来AI Agent产业格局将是什么样子？</p>\n<p>本期《极客有约》栏目，我们邀请了AI领域的知名专家，为您深入剖析AI Agent的发展趋势和应用前景。我们将分享一些成功的AI Agent应用案例，让您了解全球化背景下各行业的发展现状和未来趋势。让我们一起走进这场直播，共同探讨这个话题。</p>",
    "publish_time": "2023-11-15 15:29:47",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "抓住最后机会！产品经理赛道报名即将截止！",
    "url": "https://www.infoq.cn/article/yyJNGrS7UivgiVdbXUDl",
    "summary": "<p>你是否对<a href=\"https://www.infoq.cn/article/2K0clWV5ZGjlPumJhf9G?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">金融科技</a>\"充满热情，希望在这个领域里大展拳脚，发挥你的创新思维和专业技能？是否愿意深入探索产品经理的角色，并希望在这个角色中展现你的才华与智慧？现在，一个绝佳的机会来啦！\"<a href=\"https://www.infoq.cn/article/NjkLsroBG4rfmaAYdu13?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">2023深圳国际金融科技大赛</a>\"——西丽湖金融科技大学生挑战赛\"正在火热报名中！</p><p>&nbsp;</p><p>在金融科技领域，<a href=\"https://mp.weixin.qq.com/s?__biz=MzA4ODgwNjk1MQ%3D%3D&amp;chksm=8bfdbb0bbc8a321d78008d9ef8eff28f661d9fdf8910c72a53a0a333ebe582e43a95e399c2b4&amp;idx=1&amp;mid=2653788227&amp;scene=27&amp;sn=303d841024f3e50c32f6d4fcfd846fac&amp;utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search#wechat_redirect\">产品经理</a>\"的角色非常重要，决定着企业业务、产品服务的方向和质量，因此大赛自上一届起，专门设立了产品经理赛道。通过本届大赛，你将有机会：</p><p></p><p>与来自全球的顶尖金融科技高手同台竞技，切磋技艺；获得金融科技领域专家、企业及其众多从业者的指导和关注；赢取丰厚的奖金和诱人的职业发展机会。</p><p>&nbsp;</p><p>所以，无论你是金融、计算机科学、数据科学、产品设计等相关专业的学生，还是对金融科技充满热情的跨专业人才，我们都热切期待你的参与！截至当下，报名已进入倒计时阶段！抓紧行动，立即报名，和你的队友一起踏上金融科技之路！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f8/f809f94fd6516dca87d4ec45060698c3.jpeg\" /></p><p></p>",
    "publish_time": "2023-11-15 16:02:48",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "文生图大型实践：揭秘百度搜索AIGC绘画工具的背后故事",
    "url": "https://www.infoq.cn/article/AKtrgk3oT7K8AhNq5W8z",
    "summary": "<p>嘉宾 | 鱼哲、TianBao</p><p>编辑 | Tina</p><p>&nbsp;</p><p>自从进入2023年以来，AIGC技术已催生了新一轮人工智能浪潮。AI绘画作为大模型最引人瞩目的应用领域之一，近年来也取得了重大突破。AI绘画系统可以根据用户的输入或提示生成各种风格的图像，这为艺术家、设计师和创作者提供了强大的工具，也为数字创意领域带来了新的可能性。在本期“极客有约”对话节目中，鱼哲和百度搜索主任架构师TianBao就图像生成技术进行了深入探讨，包括百度搜索的应用场景、相关技术的思考，以及在搜索业务场景的应用落地经验。</p><p>&nbsp;</p><p>原视频链接：<a href=\"https://www.infoq.cn/video/8N0S0NOekxOEGSJ5X92G\">https://www.infoq.cn/video/8N0S0NOekxOEGSJ5X92G</a>\"</p><p>&nbsp;</p><p>亮点：</p><p>这是一个巨大的变革，从过去用户在全网寻找图像，转变为结合了查找图像和生成图像两种方式，以满足用户更具体的需求，这也在一定程度上鼓励用户更主动地表达他们真正的需求。要使一个模型更好地理解中文，准备和清理与中文语义相关的语料非常重要。对于去除低质量样本和构建高价值样本，这些都是图文对齐所必需的能力。百度搜索需要满足用户在内容和风格方面多样化的需求，因此在百度搜索目前支持上千种不同的画面风格定义。遵循美学标准，构建自己的美学认知，无论是在整体模型构建方面还是在算法优化方面，都需要按照这些先进标准来进行相关的指导和评估。</p><p>&nbsp;</p><p></p><h4>嘉宾简介：</h4><p></p><p>鱼哲，Lepton AI 创始团队成员，产品负责人。</p><p>TianBao，百度搜索内容技术部主任架构师，搜索内容策略负责人。负责百度千亿级内容获取策略、多模态内容理解技术、AIGC内容生成技术。</p><p>&nbsp;</p><p></p><h4>文生图的技术发展过程</h4><p></p><p>鱼哲：AIGC从去年9月到现在，我们能看到各种各样的模型和公司不断涌现。从最初大家使用Stable Diffusion来生成简单的图像，到后来用一些其它方法进行生成式图像编辑，后来甚至Adobe Photoshop 支持使用自然语言方式修改图片。我觉得从之前看到的AIGC在生成文本方面取得的成就之外，还有更多有趣的应用领域。除了生成图片，还能够生成视频和音频。最近，我也看到了一些令人惊艳的生成视频产品。今天想请TianBao老师跟大家展开介绍一下文生图技术目前的整体发展趋势是什么样的。</p><p>&nbsp;</p><p>TianBao：2022年可以算是文生图的元年，整体上分为以Stable Diffusion为代表的开源的流派，以及Midjourney 、Adobe的Firefly、Dall-E 3 为代表的闭源模型。而之所以说这一年是元年，是源于 Disco Diffusion。Disco Diffusion的目标主要是 landscape 等风景类创作，风景类场景是一个容错率比较高的场景，并结合了富有视觉冲击的色彩，极具艺术质感，这在2021年底至2022年初，是一个很大胆、很惊艳的一个尝试。</p><p>&nbsp;</p><p>直到2022年2月，Midjourney发布了v1版本。v1的整体效果相当令人吃惊，但在生成人像方面还差强人意。直到同年7月中旬，Midjourney v3才能正常地生成一些常规人像。在8月份时，作品《太空歌剧院》就通过Midjourney v3进行生成，加上 Photoshop的后期处理，这使得Midjourney成功引起了轰动。</p><p>&nbsp;</p><p>stable-diffusion 1.5版本也在同一时期开源，这个开源事件具有里程碑的意义，因为从那时起，像C站这样的更多用户开始涌向去中心化的模型和优化领域。随着开源技术的发展，整个生态系统，包括下游应用，都经历了爆发式增长和涌现。之后，技术的进步以及下游应用的发展持续在相互促进。</p><p>&nbsp;</p><p></p><h4>百度文生图的探索和成果</h4><p></p><p>&nbsp;</p><p>鱼哲：我大致还记得Stable Diffusion刚开始的效果并不太好，例如在尝试生成人像时，出现了很多扭曲的结果，如一个人有三条腿或多个眼睛。随着时间推移，这一技术逐渐变得更加逼真。同时，类似Civitai的AI技术也兴起，允许人们根据他们的图像进行各种场景的创作，比如受欢迎的原神系列。这种生成图像技术的发展催生了多种应用。比如，在抽卡类游戏中，原画师可以利用这一技术来创建游戏组件。在百度搜索等国民级应用中，文生图又如何与场景相结合的？刚开始，我理解它可能是在搜索框中，用户输入关键词后能够找到相关的图像，但我相信你们会有更多不同的创新。</p><p>&nbsp;</p><p>TianBao：早期，百度也进行了一些AIGC图像生成的尝试。正如刚才和大家讨论的，文生图技术从最初的结果不够可用，逐渐变得可用，并能够释放想象力，带来了引人注目的视觉冲击。</p><p>对于搜索，用户以前要找一张图片，通常会进行文本搜索。例如，一个戴着太阳镜和帽子的猫，做着愤怒的手势，用户在脑海中构想的画面，他们通常只能在全网中搜索到已经被创作好的、可感知的内容。但对于一些更具体的场景，比如猫要做着愤怒的手势，穿着特殊服饰，如果全网没有人创作这种图片，用户需求的满足就会受到限制，导致需求退化成寻找一个愤怒的猫，之后，他们将变成浏览型需求，查看全网上是否有类似的愤怒的猫来满足他们的需求。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/71/710e9a9dda01d7dd886e893bd5910a1b.jpeg\" /></p><p></p><p>&nbsp;</p><p>然而，随着生成式技术的迅速发展，我们现在有能力将用户脑海中的图像具体呈现出来，以满足他们的需求。我们将用户的查找需求，转变为结合了查找图像和生成图像两种方式，以满足用户更具体的需求，这也在一定程度上鼓励用户更主动地表达他们真正的需求。在产品方面，用户可以通过百度的App，搜索\"画一个愤怒的猫\"或者\"画一画\"，然后进入文生图的相关功能页面，大家可以亲自体验一下。</p><p>&nbsp;</p><p>寻找一张图片是搜索的第一步。在图像领域，许多创作者首先需要找到适合他们需求的图像，然后他们可能需要用这张图像作为头像，或者用它作为创作素材，或者在工作中使用它。因此，在生成的过程中，我们正在加入编辑工作，例如修复（inpainting）、扩展（outpainting）。举个例子，如果画面中有一只戴着帽子的猫，通过自然语言交互，我们可以将猫替换为一只狗，从而增加了图像的再利用能力。这背后通常会涉及一个基于文生图的预训练大模型，用于图像编辑。</p><p>整体而言，从最初的寻找图像，变成了“找图”加“生图”的过程，然后进入到第二个阶段，即图像的用途，以满足用户在图像领域的需求。</p><p>&nbsp;</p><p></p><h4>文生图的实践及挑战</h4><p></p><p>&nbsp;</p><p>鱼哲：听起来这是一个非常有趣的应用场景，因为很多时候，比如我以前制作PPT时，需要找到能满足我的想象场景的图像，例如客户使用产品的场景或某个行业的照片。然而，我又不希望侵犯版权，或者避免涉及各种图像来源的纠纷。在这种情况下，能够找到图像，并在此基础上进行inpainting修改、边框补全，甚至进行图像超分辨率处理，这实际上是一个非常实用的应用场景。</p><p>&nbsp;</p><p>外界可能认为我们只支持一些基本的图像生成和编辑功能，如生成、简单编辑、边框展开以及高分辨率图像的补全。但实际上，根据我的了解，这项技术在中文语境下是相当具有挑战性的。特别是针对中文文化和语义场景，大部分模型通常是在以英语为基础的语境下进行训练的，其原始语料库也是英语为主。然而，百度作为中文搜索引擎领域的巨头，需要处理中文和英文，甚至一些方言的情况，面对这种挑战是如何应对的？</p><p>&nbsp;</p><p>TianBao：作为最大的中文搜索引擎，百度在理解中文方面具有更强的优势，包括对中文特有元素、中文习惯表达以及方言的理解。要使一个模型更好地理解中文，准备和清理与中文语义相关的语料显然是不可或缺的步骤。</p><p>&nbsp;</p><p>我们在搜索领域拥有感知全网最全的中文语料的能力，这是天然优势。但除此之外，还需要进行样本的清理、更全面的知识覆盖、获取更多多样性的高质量样本等，以更好地理解整体模型的语义。同时，如果我们希望模型生成的图像质量更高，就需要考虑图像质量、美学因素，例如图像中物体的明显特征和美学风格的准确呈现。此外，还需要进行去重处理，这些都需要有基础的算子能力支持。</p><p>&nbsp;</p><p>所以对于清洗来说，底层基础算子的基建也是一个非常重要的工作。百度在图片基础层面的刻画体系上有多年的积累，所以我们在收录的数据优势之上，可以快速根据模型的不同目标，进行样本的组织和筛选。例如，我们想要更好的语义样本，要做到样本的均衡，要积累不同等级质量和美观度的样本，包括一些人像或者是特殊的 IP 概念等。 我们对这些样本进行快速学习，而后应用在模型里。</p><p>&nbsp;</p><p>鱼哲：对于生成图像大模型，一方面，在训练过程中，我们需要准备高质量的数据集，建立一个良好的基础。另一方面，用户在使用时可能会提供各种各样的复杂描述，例如描述一个杯子，用户可能会加入很多形容词，比如高的、透明的、蓝色的，里面装了一只蟋蟀等，这些描述词可能超出了标准模型支持的Token长度。特别是在中文语境中，用户的描述可能更长，就像您刚才提到的，一只戴着帽子、站在山峰顶、吹着西北风、雪花在背后飘落的猫。在这种情况下，如何处理具有大量描述词和形容词的图像是一个挑战吗？</p><p>&nbsp;</p><p>TianBao：这是一个非常好的问题。图文配对的质量非常重要。目前，大家主要关注的是开源的Laion-5b，一个包含50亿样本的英文模型，主要基于英文数据集，中文数据相对较少。同时，从这个数据集中，我们也观察到许多不相关的图文对的问题，这些问题可能是由一些杂质引起的。因此，我们需要使用相关性建模算法来过滤掉这些不相关的图文对。</p><p>&nbsp;</p><p>对于使用中文数据集，例如Laion-5b，有一种较快速的方法，即通过英文翻译成中文。然而，这种方法可能会引入很多语言上的歧义，特别是中英文之间表达上的歧义，以及中文所特有的一些语义。例如，如果我们将\"transformer\"翻译成中文，它可能会变成\"变压器\"，而如果是指一个头像，对应的英文可能会是\"阿凡达\"。这些情况都是由于中文语料建设不足导致的中文理解能力上的不足。关于刚才提到的图文对的相关性质量问题，过滤低质量的图文对，需要使用类似于常规的CLIPScore等方式来度量图文的相关性。</p><p>&nbsp;</p><p>另一个方向是在优质数据集的构建上。毕竟，一张图片可以被非常详细地描述成上百个字，而当前互联网上这种详细描述的数据还相对较少。当前互联网上的描述通常较为简短，可能只包含几十个标记，甚至更短。因此，在构建优质数据集方面，需要将一些高质量的图像与文本描述的力度和视角相结合，以进行文本描述的补充。通常，人们描述的可能是图像的主体和意境，但他们可能会忽略掉图像中的背景、物体的数量以及基本实体的描述。因此，如何实现图像和文本的对齐理解对于文生图的构建非常重要。</p><p>&nbsp;</p><p>因此，对于提供高质量样本的问题，可能需要更适合于图像生成任务的模型，例如caption生成模型。百度在这方面积累了一些经验，所以对于去除低质量样本和构建高价值样本，这些都是图文对齐所必需的能力。</p><p>&nbsp;</p><p></p><h4>图片美感的评估</h4><p></p><p>&nbsp;</p><p>鱼哲：确实，与我想象的相比，这个处理的复杂度要高得多。您刚才提到的去除低质量、保留高质量的很重要。您所说的低值和高值是指图像质量对吗？在生成图像时，如果要生成一只猫，首先它必须是一只猫，其次重要的是它必须符合美感。它必须符合一只猫的形状，或者说它必须符合一只狗的形状，而美感是一个非常主观的事情。例如，即使是一只猫，有些人喜欢圆圆的、胖胖的、毛发丰富的猫，他们认为最好是长得像个球一样，但有些人认为猫应该像猫一样，应该有猫的特征，头是头，腿是腿，脖子是脖子。在这种情况下，百度如何处理关于猫应该长成什么样子的问题呢？</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1e/1e8afe5c413c72c4e9a73d1fd914f846.jpeg\" /></p><p></p><p>&nbsp;</p><p>TianBao：对于美学，确实像刚才提到的，它是一个偏主观的一个感知，其实是千人千面的，大家可能对美的认知是不太一样的，但是这里面我们其实是期望通过大部分人的美学认知，提出一些美学的定义。</p><p>&nbsp;</p><p>例如，美学的定义通常包括图像的构图，整个画面的结构是什么样的，还包括色彩的应用，如饱和度、对比度、整体的配色，以及光感，例如在摄影棚中的光线设置，如何为不同场景创造更好和更合适的光感。除了视觉色彩方面的定义，画面的内容也可以体现美学，例如画面内容的丰富度或画面的叙事性，这些都是由画面内的内容构成的。因此，这些维度形成了更具普世性的美学标准。</p><p>&nbsp;</p><p>我们遵循这些美学标准，然后构建自己的美学认知，无论是在整体模型构建方面还是在算法优化方面，都按照这些先进标准来进行相关的指导和评估。除了美学之外，图像的清晰度也会影响整体的质感。同时，内容的一致性也很重要，如果看到一只猫有三只腿，内容实体的不一致性将会导致缺陷，从而间接影响图像的可用性和美感。</p><p>&nbsp;</p><p>鱼哲：您刚刚提到内容的一致性，可以展开这个解释一下这个概念吗？</p><p>&nbsp;</p><p>TianBao：内容一致性可以大概理解为内容的质量或可用性。比如，如果画一只手，出现了手部的畸形或畸变，这实际上与我们通常对手的概念不符。这会导致手的实体不一致，因此可以认为它存在质量问题。</p><p>&nbsp;</p><p></p><h4>文生图提示工程</h4><p></p><p>鱼哲：不同场景和用途对美学要求不同，以戴帽子和太阳镜的猫为例，用户可能希望生成不同风格的漫画，如日漫和美漫，它们在视觉体验上有显著差异。美漫通常色彩丰富、轮廓鲜明，而日漫则以黑白为主，视觉冲击力较强。在保障在内容一致性的要求下，百度是如何在不同风格的情况下，从用户的 prompt 中获取相关信息，以支持不同画风的生成？</p><p>&nbsp;</p><p>TianBao：我们来看一下当前文生成图的应用场景。目前，在主流的交互中，通常提供了一些明确定义的特定风格选项，如漫画风格或水彩画风格。但对于用户而言，不应该受到过多的限制，例如，如果用户需要生成一个赛博朋克风格的猫，将其绘制成卡通风格就无法满足用户需求。也就是说，用户不仅可以描述生成画面中出现的内容，如猫，还可以描述他们期望的画面风格。因此，百度搜索需要满足用户在内容和风格方面多样化的需求。</p><p>&nbsp;</p><p>在百度搜索中，我们目前支持上千种不同的画面风格定义。举例来说，用户可以将一只猫呈现为水墨画或卡通画，也可以将它呈现为铝制品或雕刻品，甚至以不同的材质。此外，用户还可以选择不同的视角，如带有运动模糊效果、延时摄影效果，或者鱼眼和广角视角等。我们覆盖了多种不同的风格和分类，因此用户如果有更具体的风格要求，只需在他们的prompt中包含相关风格，即可获得符合他们期望的画面并具备相应风格。</p><p>&nbsp;</p><p>鱼哲：我还有一个问题，就是关于风格的叠加，是否支持这种操作？例如，能否将鱼眼广角和水墨画的风格同时应用在图像上？因为一个是关于画风，另一个是视角，那如果我们想要将水墨画与卡通风格结合，这是否也是支持的呢？</p><p>&nbsp;</p><p>TianBao：在模型方面，支持多风格是可行的，这样可以激发新的风格创意。然而，我们面临的另一个问题是如何在保持内容一致性的前提下，有效地融合和协调多种风格。因为不同风格之间的差异可能很大，可能会发生一些相互制约的情况，但这确实为用户提供了更多的实验和探索机会，可以通过尝试不同风格的组合，实现更广泛的创意空间。</p><p>&nbsp;</p><p>鱼哲：如果我有多个风格的关键词去描述最后的主体，最后整张图出来的效果和关键词所在的位置的关联度大吗？比如说水墨、卡通风格的猫和卡通、水墨风格的猫，这两个出来的效果会是一样的吗？</p><p>&nbsp;</p><p>TianBao：这个其实就会涉及到刚才说的一个可控性。最基本的，就像刚才提到的猫一样。它关系到我们如何控制生成的内容，尤其是在涉及到风格方面。实际上，可控性与我们整体的prompt方式相关，因为不同的prompt方式可以导致不同的结果。有些人可能会提供简短的提示，可能前后并列会输入两个不同的风格，而其他人可能更喜欢更详细的prompt表达方式，比如他们可能希望描述一个场景的画面，指定特定的风格，或者强调某种风格在生成中的比重。这些都是不同的prompt方式，可以影响生成内容的方式。</p><p>&nbsp;</p><p>然后对于这种可控来说，其实现在这种顺序上会有一些 Bias。比如Stable Diffusion 的prompt炼丹，也会提及一些，比如怎么写prompt，是放到前面好还是后面好，其实本质上是一种控制的能力，理想的话应该不会存在这样的一些偏差。当然最理想的还是我们可以引导用户能够去更精准的去表达自己脑海中的画面。</p><p>&nbsp;</p><p>鱼哲：刚才提到百度支持上千种风格，我想问，这上千种风格是人工梳理的，还是通过模型聚类后自动生成的？对于用户来说，知道有这么多风格可选可能一开始会觉得有点过多，有点难以选择。</p><p>&nbsp;</p><p>TianBao：关于风格，基于我们之前提到的，我们对全网内容的感知非常广泛，因此我们有能力感知到全网存在的各种风格数据。第二点是，我们也依赖于对图像相关的理解，无论是聚合算法还是风格美观度的描述，都需要首先有数据，然后通过数据的筛选和识别能力，对这些风格进行自然而然的呈现。这是对风格定义的方式。</p><p>&nbsp;</p><p>另外刚才提到的，比如说我们当前支持上千种风格，对于用户来说，其实大家可能还是得有一个认知的过程，因为每一种风格可能对于艺术向的用户来说还是会有比较大的一些惊喜的。比如我们看到某种风格和我们常规看到的画面有很大的这种区别，也具备很强的视觉冲击感。所以这里面怎么样能够把我们已有的这些风格能够更好的传递给用户，让用户理解这种风格，并且在后续的这些需求满足创作中能够应用上这些风格，这其实是需要整体的产品和技术来引导的一个工作。</p><p>&nbsp;</p><p>鱼哲：正如你刚提到的，有上千种不同的艺术风格。即使对于非专业和一些专业的美术生来说，通常只了解一两种风格，比如素描或水墨画。实际上，很少有人能深入了解这么多不同风格并写出好的提示词。那么，当用户不太了解如何编写prompt提示词时，我们该怎么处理呢？比如，用户第一次使用百度，除非有人告诉他们，他们可能不知道支持上千种风格。在这种情况下，我们应该如何处理，并引导他们了解更多有关百度的各种风格以及可以编写的其他提示词呢？</p><p>&nbsp;</p><p>TianBao：对于艺术风格和创造性而言，大家更常接触到关键词\"Midjourney\"，可以将其作为一个例子，来讲述一个从零开始激发想象力的过程。在早期的运营推广中，有些资源并未过多优化提示词。通常，它们提供了一些相对简单的提示词，比如\"dog\"（狗）。然而，这是建立在disco社区基础之上的，允许所有用户参与。一些用户尝试将他们的提示词更改为描述一只毛茸茸的狗，而其他用户可能更喜欢科幻题材，例如一只拥有镭射眼睛的狗是什么样子。通过不断的尝试，他们会发现在不同的提示词下可以获得更引人入胜或有趣的效果。这导致了彼此学习，观察其他人如何生成内容，如何设置提示词，以及这会产生什么样的效果。因此，提示词的优化逐渐变得流行起来。这个问题对于整个业界，包括百度搜索和文生图，也是类似的。</p><p>&nbsp;</p><p>对于一般用户而言，他们可能较少接触文生图这个场景。对于初次使用的用户，通常只是尝试绘制一只猫或一只小狗，这引出了一个问题，即如何在用户使用环境相对简单的情况下，为他们生成更好的效果。</p><p>&nbsp;</p><p>这里就会涉及到 prompt的扩充或者是改写。这里有两种思路，一种是去扩充画面的内容，类似于内容的一个丰富性或者是故事感。比如刚才说的戴着帽子，然后做着愤怒的手势的狗，把画面更具象，其实这是prompt的优化所做的一个工作。同样也可以对风格进行一些扩展，我们可以感知到大部分人对于这个内容之下更喜欢哪些风格，我们就可以通过这种prompt来做更多风格的一些扩写。像刚才说的内容以及在风格上的一些扩写多样性之后，就可以极大的去优化画面的内容丰富度、故事性，以及风格和美观的程度。所以这里面会涉及到怎么样把一个简单的表达的 prompt的输入，通过优化的方式变成一个对模型来说效果更好的一组prompt。</p><p>&nbsp;</p><p>鱼哲：有一个更具体的问题需要讨论，涉及到prompt的改写。例如，当我们将一个提示从描述一只狗转变为一只带帽子的生气的手势狗时，用户实际上无法看到被改写的部分。我们是否能够确保每次改写都是一样的，或者每次改写的内容可能略有不同？举例来说，第一次可能是一只戴帽子的狗，而第二次可能是一只戴眼镜躺在沙滩上的狗。这个过程是否具有随机性，或者每次都是固定的？</p><p>&nbsp;</p><p>TianBao：对于 prompt的改写来说，其实我们更期望给到用户更多多样性、更多丰富的结果。因为如果是一条狗的话，我们可以想象到的是一个主体是一条狗，可能会有不同的一些犬类的品种，但是狗可能穿着不同服饰出现在不同场景之下，这个对更多人来说会有更多样的一些结果，大家会有更多的预期。所以在模型层面，我们期望通过prompt这种改写和优化，有更多的多样性的备选，然后基于用户实际的反馈，去来感知用户对哪些风格，对什么类型的内容场景的一个画面结果会感兴趣，后验反馈会比较高，这对于整体的prompt的改写模型也会有数据促进的作用。</p><p>&nbsp;</p><p></p><h4>反馈和评估</h4><p></p><p>&nbsp;</p><p>鱼哲：刚刚提到了改写，从用户侧收集反馈来迭代模型，有一个词叫做 RLHF（Reinforcement Learning from Human Feedback）。这里我觉得最难的点是human feedback是不稳定的，因为人与人之间的主观观点会差很多。如果我们需要依赖人的反馈来去迭代模型，其实是比较困难的。如果再落实到说模型的evaluation上来说，在这种情况下，百度是如何去manage balance，在图像生成的方向上去做评估。</p><p>&nbsp;</p><p>TianBao：关于后验反馈，首先需要考虑反馈数据是否确实能够代表人类的后验反馈，这对于反馈质量有更高的要求。因此，可以将这一方面与产品的整体设计和用户交互相结合，以收集更多积极的用户行为反馈。例如，当用户对某个结果感兴趣时，他们可能会点击图片以进行放大查看，然后进行下载等后续行为，这些都是积极的反馈。如果用户对某张图片点赞或进行评论，也提供了直接的反馈。我们希望在整个反馈系统中更有效地收集这些反馈，因为它们实际上反映了用户的偏好。至于模棱两可的反馈，只能通过更大的样本量来收集更具代表性的数据。</p><p>&nbsp;</p><p>鱼哲：过去，无论是传统的统计机器学习还是标准的深度学习模型，基本上都是监督学习，需要样本或监督来计算F1分数、IQZ和VCR等指标。然而，对于生成式模型，如GPT系列模型或DALL-E这样的生成式模型，技术上并没有像以前那样的标准基准数据集，大家可以根据这些基准数据集来生成和评估。相比之下，生成式模型需要一种更高效的评价方法，而不是依赖人工逐个观察。在这个领域，与其让人们用肉眼逐个观察，是否有方法可以更高效地进行评估呢？</p><p>&nbsp;</p><p>TianBao：更高效的方法实际上更多地涉及到人机结合的手段。就像之前提到的图像评价，我们可以通过一些初步的机器指标来进行观察。</p><p>如果我们关注整体的相关性或质量美观度，那么在某些机器指标上可以进行一些刻画。但如果需要精确评估两张图片之间的差异，这些机器指标可能并不具备太大的意义，更需要人工进行判断。前面提到的机器初步评估可以帮助人们进行初步的筛选，从而在人工评价方面节省一些劳动力。</p><p>&nbsp;</p><p></p><h4>未来展望</h4><p></p><p>鱼哲：好的，接下来的问题稍微展望未来，尽管并不是非常遥远，因为最近我看到许多初创团队和相关公司正在尝试这个领域。以动画为例，动画实际上是将多幅图像的帧叠加在一起呈现的。通常，动画电影以每秒24帧或16帧的速度播放。除了静态单幅图像的编辑，我们可以看到在AIGC领域，对于视频生成或短视频生成，无论是三秒还是七八秒的视频，都在不断发展。之前Runway团队曾举办了一个使用文生图进行视频生成的比赛。您认为在未来多久内，我们会看到第一部完全由AI生成的电影或电影状态？</p><p>&nbsp;</p><p>TianBao：简要回顾一下图像生成，在2022年初，图像生成效果并不是特别理想，但到了2022年的七八月份，整体变得更加可行。根据技术发展趋势，对于动态图或视频的生成，预计不会太久就会迎来技术的飞速发展。因为最近在视频生成领域还有很多探索，无论是基于可控生成的方法还是像Runway这样生成几秒小短片的方法。对于几秒小短片，大家通常会将生成的最后一帧作为下一段的第一帧，以实现更连贯的长视频。然而，对于视频生成来说，面临更大的挑战，因为它不仅要保证空间效果，还需要确保时间上的一致性，这引入了一个额外的维度，对技术要求更高。随着最近对视频生成的不断探索，我们可以预计未来一到两年内可能会出现类似于Stable Diffusion这样革命性的时刻。</p><p></p><p>延伸阅读：</p><p><a href=\"https://www.infoq.cn/article/WL2yVwKEqIutiwppz0wK\">AIGC 编程：代码编程模型的应用与挑战</a>\"</p><p><a href=\"https://www.infoq.cn/article/8wWUiBa8eBWVLRMrxJaT\">我，一个 95 后，从阿里辞职与贾扬清去硅谷创业</a>\"</p><p></p><h4>&nbsp;</h4><p></p>",
    "publish_time": "2023-11-15 20:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]