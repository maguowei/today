[
  {
    "title": "NVIDIA发布新的C++数值计算库：支持GPU加速",
    "url": "https://www.infoq.cn/article/6P17qXTgH2XI6oYKmgvh",
    "summary": "<p>&nbsp;<a href=\"https://developer.nvidia.com/blog/speeding-up-numerical-computing-in-c-with-a-python-like-syntax-in-nvidia-matx/\">MatX 是一个 C++ 库</a>\"，由 Nvidia 为其自有的 GPU 开发，，旨在使用高级语法在数值计算中实现接近本地性能，不遑多让于 Python 的 scipy 或 MATLAB。<a href=\"https://github.com/NVIDIA/MatX/releases\">它的最新版本引入了</a>\"许多新功能，包括可以将变换作为运算符，以及新的运算符，如上采样、下采样、pwelch 等等。</p><p>&nbsp;</p><p>现在，可以在任何运算符表达式中使用变换，以使用运算符融合来进行延迟评估。运算符融合是 MatX 中的一个特殊功能，旨在提高性能，通过减少内存访问，从而避免内存访问成本相对寄存器访问昂贵数个数量级的问题。</p><p>&nbsp;</p><p>旨在通过减少内存访问来提高性能，内存访问的成本可能比寄存器访问高出几个数量级。使用运算符融合，一个表达式不会立即计算，而是转换为表示该表达式的 C++ 类型，该类型将在需要其值时进行评估。换句话说，不是立即计算表达式的结果，比如：</p><p>&nbsp;</p><p><code lang=\"null\">(A = B * (cos(C) / D)).run();</code></p><p>&nbsp;</p><p>你可以将其值存储在一个中间表达式中：</p><p>&nbsp;</p><p><code lang=\"null\">auto op = (B * (cos(C) / D));</code></p><p>&nbsp;</p><p>将其与其他表达式组合，并在需要时进行延迟评估。这一特性是通过重载 C++ 运算符实现的。MatX 的最新版本将这一功能扩展到了变换中，例如在以下表达式中：</p><p>&nbsp;</p><p><code lang=\"null\">(A = B * fft(C)).run();</code></p><p>&nbsp;</p><p>编译器能够理解乘法运算符的右侧是 FFT 变换，而左侧是另一个表达式，可以在编译时与前者的结果进行融合。</p><p>&nbsp;</p><p>值得注意的是，将变换用作运算符的这种新语法与以前的变换使用方式存在一些不兼容。具体而言，以前你可能会写成matmul(C, A, B, stream)，而现在应该使用(C = matmul(A,B)).run(stream)。</p><p>&nbsp;</p><p>MatX 0.6.0 引入的另一个新功能是新的<a href=\"https://github.com/NVIDIA/MatX/pull/459#issuecomment-1658987574\">多相通道化运算符</a>\"，它可以将输入信号分成一组通道。例如，它可用于将高采样率的宽带信号转换为多个低采样率的窄带信号。</p><p>&nbsp;</p><p>新的运算符包括 <a href=\"https://nvidia.github.io/MatX/api/signalimage/general/upsample.html\">`upsample`</a>\"，用于通过插入零来上采样信号；<a href=\"https://nvidia.github.io/MatX/api/signalimage/general/downsample.html\">downsample</a>\"，用于通过丢弃样本来下采样信号；<a href=\"https://github.com/NVIDIA/MatX/pull/479\">pwelch</a>\"，用于可视化信号的频谱，而无需进行预处理。</p><p>&nbsp;</p><p>MatX 的最新版本拥有更多功能，此处无法详尽列出。如果你对完整细节感兴趣，不要错过官方发布说明。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/10/Nvidia-matx-cpp-numerical-lib/\">https://www.infoq.com/news/2023/10/Nvidia-matx-cpp-numerical-lib/</a>\"</p>",
    "publish_time": "2023-11-15 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "阿里巴巴总监郭瑞杰（国泊），确认担任 QCon Serverless 化云产品架构设计与实践专题出品人",
    "url": "https://www.infoq.cn/article/RvMo6z9bAo5SXr69VMk8",
    "summary": "<p><a href=\"https://qcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=7&amp;utm_term=1115&amp;utm_content=guoruijie\">QCon 全球软件开发大会</a>\"，将于 12 月在上海召开。阿里巴巴总监郭瑞杰（国泊）将担任「 <a href=\"https://qcon.infoq.cn/2023/shanghai/track/1608?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=7&amp;utm_term=1115&amp;utm_content=guoruijie\">Serverless 化云产品架构设计与实践</a>\"」的专题出品人。在此次专题中，你将了解到 Serverless 化云产品的快速弹性、存算分离、租户隔离等技术架构设计，以及应用实践等。</p><p></p><p><a href=\"https://qcon.infoq.cn/2023/shanghai/track/1608?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=7&amp;utm_term=1115&amp;utm_content=guoruijie\">郭瑞杰（国泊）</a>\"，2009 年毕业于毕业于中国科学院计算技术研究所，毕业后加入阿里巴巴，先后负责阿里巴巴搜索平台 iSearch4.5、问天 2、问天 3 等架构设计和开发工作，现任阿里巴巴控股集团智能引擎事业部云服务负责人，阿里云智能集团计算平台事业部搜索推荐云服务负责人，Havenask 开源项目负责人。负责构建了阿里云 Elasticsearch、开放搜索 OpenSearch、智能推荐 AIRec、图计算 GraphCompute 等云产品。</p><p></p><p>相信郭瑞杰（国泊）的到来，可以帮助提升此专题的质量，让你学习到 Serverless 化云产品按量付费、快速弹性伸缩、无需感知底层物理资源，更为经济的运维成本等优势。目前，赢得了业界的广泛认可和积极响应。</p><p></p><p>除上述专题外，QCon 上海还将围绕&nbsp;<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart\">智能化信创软件&nbsp;IDE</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart\">GenAI和通用大模型应用探索</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart\">LLM&nbsp;时代的性能优化</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1599?utm_source=infoqweb&amp;utm_medium=teacherart\">LLM&nbsp;时代的大前端技术</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart\">面向人工智能时代的架构</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart\">性能工程：提升效率和创新的新方法</a>\"等专题进行交流。</p><p></p><p>QCon 上海 2023，相约 12 月！ 7 折优惠仅剩最后 3 天，现在购票立减￥2040！咨询购票请联系：18514549229（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/0113b3dfb187d5f9988b7eb16d2e0594.png\" /></p><p></p>",
    "publish_time": "2023-11-15 11:32:16",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "首周聚焦百度智能云千帆大模型平台使用，《大模型应用实践》实训营 11 月 16 日开讲！",
    "url": "https://www.infoq.cn/article/bEPZxpLYrCAUYm1RLTQM",
    "summary": "<p><a href=\"https://www.infoq.cn/article/JAE4rgf6s1cHNQoYZ93I?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">百度智能云千帆大模型</a>\"平台官方出品的《大模型应用实践》实训营本周正式上线！这是百度智能云推出的首个系列课程，课程内容满满干货！</p><p></p><p>11 月 16 日本周四即将开课，首周由<a href=\"https://www.infoq.cn/article/WrlUWpf2OkgQsSAD6NJ1?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">百度智能云</a>\"千帆大模型平台产品经理以及百度智能云千帆资深用户知名技术 UP 主同济子豪兄来进行平台使用攻略及使用经验分享！欢迎个人及企业开发者与百度智能云千帆<a href=\"https://www.infoq.cn/article/o8abj2wff5yLfGWuB0E1?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">大模型平台</a>\"共同学习进步！</p><p></p><p>&gt;&gt;&gt;立即扫描下方二维码进行报名&lt;&lt;&lt;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ce/ce25c89ce7eafdfeec62f524decdf39a.jpeg\" /></p><p></p><p></p><h2>首周课程具体内容</h2><p></p><p>&nbsp;</p><p>课程一：11 月 16 日 19:00-20:00 直播</p><p></p><p>课程名称：百度智能云千帆平台明星大模型与工具链概览课程讲师：Ziqi 百度智能云千帆大模型平台产品经理课程亮点内容：</p><p>     百度智能云千帆大模型平台全能力概览</p><p>     精选「明星大模型」使用攻略（在应用场景下该如何选择适用大模型）</p><p>&nbsp;</p><p>课程二：11 月 17 日 19:00-20:00 直播</p><p></p><p>课程名称：平台应用分享：基于文心大模型 4.0 打造大模型时代游戏 NPC课程讲师：同济子豪兄 知名技术 UP 主课程亮点内容：</p><p>     文心大模型 4.0 能力展示</p><p>     游戏行业实战：如何基于大模型创建游戏 NPC</p><p>     基于应用场景，百度智能云千帆大模型平台整体使用指南</p><p></p><p></p><h2>实训营课程福利</h2><p></p><p></p><p>实训营优质用户将有机会获得百度智能云千帆社区周边产品以及百度智能云千帆产品体验代金券（适用于百度智能云千帆全产品），除此之外参与实训营的优质企业认证的开发者还将有机会获得 200 元百度智能云千帆平台代金券！</p><p></p><p>更多实训营福利等待大家，快来点击【<a href=\"https://cloud.baidu.com/survey/qianfantraining.html?track=infoq\">此处链接</a>\"】报名加入我们吧！！</p>",
    "publish_time": "2023-11-15 13:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "李开复旗下340亿参数开源大模型被指“套壳LLaMA”，最新回应来了！",
    "url": "https://www.infoq.cn/article/YCV0E9FALCpIUftbJiBv",
    "summary": "<p></p><blockquote>有网友在 Twitter 上评价道：“这就是中国大模型研发现状？”</blockquote><p></p><p></p><h2>李开复的 Yi-34B 被指是对 LLaMA 的重构</h2><p></p><p>&nbsp;</p><p>近日，国外开发者&nbsp;ehartford&nbsp;在开源大模型 Yi-34B 的 Hugging Face 主页上评论称，除了对两个张量做重命名之外，Yi 团队完全使用了&nbsp;LLaMA&nbsp;架构（input_layernorm,&nbsp;post_attention_layernorm）&nbsp;<a href=\"https://github.com/turboderp/exllamav2/commit/6d24e1ad40d89f64b1bd3ae36e639c74c9f730b2\">https://github.com/turboderp/exllamav2/commit/6d24e1ad40d89f64b1bd3ae36e639c74c9f730b2</a>\"&nbsp;由于 LLaMA 架构涉及大量投资和工具，因此保留全部张量的原名称显然更好。开源社区肯定会重新发布 Yi 模型并调整张量名称，制作出符合 LLaMA 架构的新版本。我们希望贵团队能在模型被广泛部署之前也能官方采取这项调整，确保成果最终得到妥善使用。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/52/523d2c1589682c4fb0d376465b8a9b5c.png\" /></p><p></p><p>ehartford 补充道，他只是提醒 Yi 团队调整张量名称来匹配相关资源，直接套用 LLaMA 架构没有任何问题，训练才是重点。</p><p>&nbsp;</p><p>网友 brucethemoose 认为，不仅如此，Yi-34B 还是对 LLaMA 代码的重构，而且似乎没有做任何改动。这显然就是在原始 Apache 2.0 llama 文件的基础上稍做调整，却没有提及LLaMA：<a href=\"https://www.diffchecker.com/bJTqkvmQ/\">https://www.diffchecker.com/bJTqkvmQ/</a>\"</p><p>&nbsp;</p><p>brucethemoose 提到：</p><p>&nbsp;</p><p></p><blockquote>这些调整并没有 PR 到 Transformer 当中，只是作为外部代码被添加了进来，这样可能引发安全风险、或者与框架发生冲突。HuggingFace 排行榜甚至不打算对其 200K 版本做基准测试，因为该模型根本没有自定义代码政策。他们宣称这是套 32K 模型，但实际配置为 4K 模型，没有 RoPE 拉伸配置，也没有解释应该如何拉伸。目前，关于其如何调校数据的信息完全为零。他们并未提供重现基准测试结果的说明，包括高到可疑的 MMLU 得分。&nbsp;任何对 AI 稍有了解的朋友都会意识到其中的问题。这是纯粹在吹牛？吹完了就跑？违反许可证要求？在基准测试里作弊？都有可能，但却没人在乎。反正他们可以继续发论文，或者是骗走死而一大笔风险投资。至少在这个圈子里，Yi 还算是高于平均水平，毕竟它总归是套基础模型、而且性能似乎的确不错。</blockquote><p></p><p>&nbsp;</p><p>有不少网友与 brucethemoose 观点相同，认为 Yi-34B 纯粹就是 LLaMA 的复制粘贴，再对部分张量重新命名，“太丢人了”。网友&nbsp;JosephusCheung&nbsp;表示，如果 Yi 团队用的就是 Meta LLaMA 原架构、代码库还有相关资源，那就必须得遵守 LLaMA 所规定的许可协议。换句话说，如果直接按照 LLaMA 的形式发布 Yi 模型，那么 Yi 许可中的很多条款也就无法成立。我认为这种行为非常粗鲁，Yi 团队明显对许可证制度缺乏应有的尊重。有些事情开源社区可以做，但商业实体绝对不行。</p><p>&nbsp;</p><p>网友&nbsp;turboderp&nbsp;认为，提交当中涉及一些重构，但也有一项用来对 RMSNorm 模块的键进行重命名的变更：如果模型的 config 文件识别到模型为“YiForCausalLM”，则“input_layernorm”为“In1”且“post_attention_layernorm”为“In2”。“据我所知，除此之外 Yi-34B 的架构与 LLaMA 没有任何区别。其实 OpenLLaMA 也是类似的情况。虽然 Yi-34B 的词库有两倍大，但它仍然是个 SentencePiece 模型而且能够正常运行。所以我们很难说 Yi-34B 算不算新成果。其架构在 modeling_yi.py 中布局，而且除了张量名称的调整之外，看起来跟 LLaMA 一模一样。当然，可能还有其他被我忽略掉的差异。”</p><p>&nbsp;</p><p>值得一提的是，前几日，阿里前技术副总裁、大模型行业创业者贾扬清曾在朋友圈中提到，有个“大厂新模型 exactly 就是 LLaMA 的架构，但是为了表示不一样，把代码里面的名字从 LLaMA 改成了他们的名字，然后换了几个变量名。然后，海外有工程师直接指了这一点出来... 还有人在 HF 上面放了个把名字改回去的 checkpoint，说好了，现在你们可以直接用 LLaMA 的代码来 load 这个 checkpoint 了”。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1a/1a36acb8fd82a4d313bbfb564db7c208.png\" /></p><p></p><p>&nbsp;贾扬清虽然没有指明具体的大模型名字，但有观点怀疑其指的很可能就是零一万物旗下的&nbsp;Yi-34B。</p><p></p><h2>零一万物回应争议：基于 GPT 研发，将进行代码更新</h2><p></p><p>&nbsp;</p><p>对于本次争议，零一万物回应称：GPT 是一个业内公认的成熟架构，LLaMA 在 GPT 上做了总结。零一万物研发大模型的结构设计基于 GPT 成熟结构，借鉴了行业顶尖水平的公开成果，由于大模型技术发展还在非常初期，与行业主流保持一致的结构，更有利于整体的适配与未来的迭代。同时零一万物团队对模型和训练的理解做了大量工作，也在持续探索模型结构层面本质上的突破。</p><p>&nbsp;</p><p>零一万物团队开源总监&nbsp;richardllin 回应 ehartford 称：</p><p>&nbsp;</p><p></p><blockquote>非常感谢您在讨论中指出了这一点，也感谢您以良好的耐心等待我们做出回复。您对张量名称的看法是正确的，我们会按照您的建议将其从 Yi 重命名为 LLaMA。我们也一直强调以准确、透明的方式完成工作。您在前面的帖子中提到，“开源社区肯定会重新发布 Yi 模型并调整张量名称，制作出符合 LLaMA 架构的新版本。”这让我们不禁好奇：您是希望提交一条包含这些变更的 PR 吗？或者说，如果您希望由我们处理更新，我们也可以按要求操作并在本 repo 中发布新版本——这样可能更省时间。这个命名问题是我们的疏忽。在大量训练实验中，我们对代码进行了多次重命名以满足实验要求。但在发布正式版本之前，我们显然没能将它们全部正确调整回来。我们对此深感抱歉，对于由此造成的混乱也感到遗憾。我们正在努力加强工作流程，力争未来不出现类似的失误。您的反馈给了我们很大帮助，接下来我们将再次核查所有代码，确保其余部分准确无误。也希望您还有整个社区持续关注我们的工作进展。再次感谢您的提醒，期待您的更多支持和宝贵建议。</blockquote><p></p><p></p><h2>340亿参数开源大模型 Yi-34B&nbsp;</h2><p></p><p>&nbsp;</p><p>据悉，开源大模型&nbsp;Yi-34B 来自李开复旗下 AI 大模型创业公司“零一万物”，该模型发布于 2023 年 11 月 6 日。今年 7 月，李开复博士正式官宣并上线了其筹组的“AI 2.0”新公司：零一万物。此前李开复曾表示，AI 大语言模型是中国不能错过的历史机遇，零一万物就是在今年 3 月下旬，由他亲自带队孵化的新品牌。</p><p>&nbsp;</p><p>Yi-34B 是一个双语（英语和中文）基础模型，经过 340 亿个参数训练，明显小于 Falcon-180B 和 Meta LlaMa2-70B 等其他开放模型。零一万物团队对其进行了一系列打榜测试，具体成绩包括：</p><p>&nbsp;</p><p>Hugging Face 英文测试榜单，以 70.72 分数位列全球第一；以小博大，作为国产大模型碾压 Llama-2 70B 和 Falcon-180B 等一众大模型（参数量仅为后两者的 1/2、1/5）；C-Eval 中文能力排行榜位居第一，超越了全球所有开源模型；MMLU、BBH 等八大综合能力表现全部胜出，Yi-34B 在通用能力、知识推理、阅读理解等多项指标评比中“击败全球玩家”；......</p><p>&nbsp;</p><p>对于模型尺寸的选择，零一万物团队认为，34B 是一个黄金尺寸。虽然 6B 也能在某些领域，比如客服上可用，但模型毕竟越大越好，但随之而来的就是推理成本和后续训练的系列资源问题。</p><p>&nbsp;</p><p>“34B 不会小到没有涌现或者涌现不够，完全达到了涌现的门槛。同时它又没有太大，还是允许高效率地单卡推理，而且不一定需要 H 和 A 级别的卡，只要内存足够，4090 或 3090 都是可以使用的。”李开复解释道，“既满足了精度的要求，训练推理成本友好，达到涌现的门槛，是属于非常多的商业应用都可以做的。”</p><p>&nbsp;</p><p>另外，李开复提到，通用模型决定了行业模型的天花板。虽然行业大模型有相当大的价值，但是底座如果不好，也无法完成超过底座的事情，所以选底座就要选表现最好的底座。李开复自信地表示，“今天我们在中英文上就是最好的底座，没有之一，也希望更多人选择 Yi-34B。”</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://huggingface.co/01-ai/Yi-34B/discussions/11\">https://huggingface.co/01-ai/Yi-34B/discussions/11</a>\"</p><p><a href=\"https://news.ycombinator.com/item?id=38258015\">https://news.ycombinator.com/item?id=38258015</a>\"</p><p><a href=\"https://www.infoq.cn/news/cVfuQaHVJ0SDPtP2jb7m\">https://www.infoq.cn/news/cVfuQaHVJ0SDPtP2jb7m</a>\"</p>",
    "publish_time": "2023-11-15 14:14:16",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "“谷歌有谷歌的规矩”",
    "url": "https://www.infoq.cn/article/91ScH6rzjCfPqcodde2a",
    "summary": "<p></p><p></p><blockquote>这可能只是众多被谷歌收购的公司中，不被众人注意的其中一个。&nbsp;2013年，Shreyans Bhansali 和Chris Pedregal 做了一个互联网学习平台，之后发展成了类似Quora的系统，也有点像国内的“作业帮”。Socratic在App Store上拥有超50万次评价，综合4.9星。2016年，Socratic从 Shasta Ventures、Spark Capital 和 Omidyar Network 筹集了 600 万美元的 A 轮融资。&nbsp;后来，这家10人初创公司被谷歌收购，创始团队加入谷歌，也开始以谷歌的方式重塑自家产品。下面是Bhansali 的分享，他讲述了公司被收购的过程以及并入谷歌工作后发现的谷歌工程文化。Bhansali 意识到要想在谷歌实现理想，就得按谷歌的规矩来。</blockquote><p></p><p>&nbsp;</p><p>在2017年着手为Socratic筹划B轮融资时，我们很快意识到过去以牺牲收入为代价换取客群的方式必然会使公司陷入困境。之前的快速增长让我们出现在投资人的视野当中，但每家风险投资机构都要求我们制定详尽的货币化计划。于是我们慢慢学到了精髓：Socratic为那帮连信用卡都没有的高中生们开发的教育类应用，不可能发展成什么惊人的业务。</p><p>&nbsp;</p><p>大约在同一时间，我们被引荐给了SnapChat公司CEO Evan Spiegel。Evan建议我们建立合作伙伴关系，将我们基于摄像头的作业助手软件添加到他们的应用当中。但我方一位顾问认为，既然我们已经见到了该公司的业务发展主管，那就意味着对方可能有收购的意向。这时候最好立刻启动竞争流程，于是我们开始主动联系微软、Chegg、Gyju’s还有谷歌。</p><p>&nbsp;</p><p>另一位联合创始人Chris之前在谷歌工作过，于是跟之前的经理重新取得了联系。对方介绍了谷歌自己围绕手机摄像头打造的应用Lens。而我们不知道的是，她本人最近还跟教育机构Khan Academy以及Android的联合创始人一起搞了自己的教育创业。在当面对话之后，我们发现自己的业务跟这位导师的AI教育发展愿景高度重合。也可能是我们之前刚刚拿下Google 2017最佳应用的桂冠，所以在会面后不久，双方就启动了收购流利，最终Socratic于2018年3月正式并入谷歌麾下。</p><p>&nbsp;</p><p>我们加入了一支规模相仿的谷歌团队，团队成员都是长年任职的老员工。Chris和我成为产品与工程主管，负责开发AI教师并将功能纳入谷歌的其他核心产品。</p><p>&nbsp;</p><p>在接下来的三年中，我们重塑了Socratic并以“Socratic by Google”的名义发布，相关功能也被引入谷歌搜索和Lens应用当中。此外，我们还推出了数学解题工具和分步数学教学原型，服务开始延伸至整个谷歌生态。</p><p>&nbsp;</p><p>以下是我在其间学到的一点经验心得。</p><p>&nbsp;</p><p></p><h2>“谷歌有谷歌的规矩”</h2><p></p><p>&nbsp;</p><p>在谷歌工作，就像是拥有第二本护照。前往世界上的任何一座主要城市，我都会骄傲地展示自己的谷歌徽章。那里有漂亮的办公室、美味的食物、宽大的办公桌，以及能与谷歌20万员工随时沟通的顺畅渠道。这是一种奇妙的感觉，谷歌的全球影响力第一次以如此具象的方式呈现在我面前。</p><p>&nbsp;</p><p>注：谷歌徽章就是公司里等级制度的鲜明体现。白色徽章代表新入职的正式员工，绿色徽章代表实习生。红色徽章代表临时工、供应商和外包商（TVC），这部分员工总数超过10万，也肩负着从平凡到关键的各类任务，但福利和访问权限远低于正式员工（这也在谷歌内部造成了许多问题），甚至无权声称自己是谷歌的一员。</p><p>&nbsp;</p><p>更令人震惊的&nbsp;，我可以立即访问谷歌的所有资产。访问他们巨大的monorepo，其中包含数十亿行代码，涵盖谷歌旗下的所有产品。还有覆盖全球各地的数据中心实时状态，跨越二十年历史的战略文件，甚至是那些以往我只能仰望的传奇项目。</p><p>&nbsp;</p><p>谷歌有谷歌的规矩。谷歌使用的几乎每款软件、每处基础设施都来自内部构建，这是因为谷歌一路大踏步发展，所以早早就遇到了大多数其他公司后来才意识到的工程难题。站在谷歌这等体量之上，外部世界已经可以忽略不计，围墙内部就足以形成浩瀚无边的技术宇宙。</p><p>&nbsp;</p><p>也就是说，我们不可能保留原本的Socratic代码库。来了谷歌，我们需要从头开始，与新团队一同重塑产品形态和底层设计，之后在谷歌技术栈这上重构应用本体。具体来讲，我们之前已经解决掉的问题（比如如何使用机器学习系统对作业内容进行分类）现在需要用谷歌的技术和标准来重新解决。不用说，谷歌的标准当然比我们高得多。</p><p>&nbsp;</p><p>我们唯一能够自主决定的，就是继续沿用之前的应用吉祥物“Ceebo”。看看谷歌的应用图标集，就会发现它们形状简单而且只用四种颜色。</p><p>&nbsp;</p><p>大厂有大厂的坚持，但在我们看来这也太无聊了。他们强调“去拟人化”，但我们觉得这套框框拿去管理Android就好了，手别伸到应用这边来。最终我们赢了，原因是这边体量太小，不会造成什么大影响。软件图标继续沿用Ceebo，还在谷歌内部得到蓬勃发展，获得了几十种变体。如今，Ceebo终于出现在谷歌官方的文档和网站当中。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/eb/eb51ea74792383f67cd57b61fb5b1788.png\" /></p><p></p><p>各种常见谷歌应用图标，还有我们的Ceebo</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0f/0f17526a0edb8b28ae2041503b435ea3.png\" /></p><p></p><p>&nbsp;</p><p>重复完成简单工作，会带来神奇的启发。通过与资深搜索人士重构我们的查询分类系统，让我们对于搜索功能本身有了更深刻、更富启发的理解。一方面，信息检索工具有着令人难以置信的深度，而计算新信号并将其添加到互联网的每个页面上则塑造出了我们之前无法想象的新功能（比如，现在搜索contains_math或者学科：化学都会显示我们的应用）。</p><p>&nbsp;</p><p></p><h2>用户不到5000万，“不值得浪费时间”</h2><p></p><p>&nbsp;</p><p>另一方面，我们发现大多数搜索改进，都是由工程师们在电子表格上“并排”比较新旧结果来手动审核来完成的。</p><p>&nbsp;</p><p>很多人都觉得谷歌工程主要是靠各种高深莫测的算法来实现的。虽然有时确实如此，但搜索或者AI工程师的主要工作其实就是观察示例、提取模式、手动标注数据，还有处理大量不可扩展的杂乱分析。这种情况似乎也是<a href=\"https://twitter.com/_jasonwei/status/1708921475829481683\">顶尖AI团队中的常态</a>\"：</p><p>&nbsp;</p><p>“我注意的一大规律，就是优秀的AI研究人员更愿意手动检查大量数据。更重要的是，他们建立起基础设施，因此能够快速完成手动数据检查。虽然过程比较枯燥乏味，但手动检查数据确实能帮助他们建立起关于问题的宝贵直觉。”</p><p>&nbsp;</p><p>大多数问题在谷歌这边都不值得浪费时间，只有关键议题才有资格拿出来讨论。大多数涉及10到5000万用户的问题都不值得谷歌浪费时间，也不符合他们的运营策略。只有对那些涉及业务定位、发展策略和关乎个人职位晋升的事情上，他们才愿意投入巨大的热情。</p><p>&nbsp;</p><p>举例来说，计算机视觉是Socratic界面中的重要组成部分，负责读取图像中的文本和数学内容。作为一家初创公司，我们选择使用第三方工具。但考虑到敏感数据暴露、业务规模预期还有复杂的供应商审查流程之后，谷歌认为这种依赖外部的作法没有必要。有时候，直接把对方买下来，将外部技术转为内部方案还更容易一些。同样的，在发现我们的应用功能值得挖掘之后，AI研究团队会聘请顶尖人才参与探索，并在短短6个月内就开发出了世界一流的数学识别API。</p><p>&nbsp;</p><p>而且参考<a href=\"https://gist.github.com/chitchcock/1281611\">Steve Yegge</a>\"比较谷歌和亚马逊平台的经典博文，大家就会知道这项遥遥领先的功能至今仍无敌手。</p><p>&nbsp;</p><p></p><h2>打败谷歌员工的是频繁的重组</h2><p></p><p>&nbsp;</p><p>谷歌是一整套向着不断变化的目标而努力的网络。只要被合适的人关注到，那谷歌之内就会孕育出新的奇迹。</p><p>&nbsp;</p><p>具体来讲，就是一位了解细节的副总裁、一支遵循相关章程的研究团队，或者再加上与公司发展目标的一致性。产品经理的主要工作就是驾驭住这种混乱与利益冲突。之后，项目还需要得到隐私、信任、安全以及基础设施等部门的批准。往往需要进行几十次对话才能确定一个想法是否可行，再通过几百次对话让灵感转化为可以落地的成果。</p><p>&nbsp;</p><p>但前面说的只是最乐观的情况。奇迹之所以被称为奇迹，就是因为它极为罕见。更普遍的情况是，每过一个季度，团队的目标都有可能发生变化，甚至整个队伍在“重组”之后彻底消失。这种现象非常普遍，所以谷歌员工们早已习惯了别离，只能把重组视为新的开始。</p><p>&nbsp;</p><p>假设以上一系列大刀阔斧的操作都没伤到你，也还有最后一道考验要通过：大家可能突然发现，公司里还有另一个之前从没听说过的团队也在做类似的尝试。于是是时候一决胜负了，因为只有一支团队能够胜出并赢得项目所有权。而如果失败，不好意思，你的API会被快速“弃用”，哪怕替代方案还远没有准备就绪。</p><p>&nbsp;</p><p>谷歌员工希望打造出色的成果，但往往有心无力。毫无疑问，总有些人单纯是为了混口饭吃，比如每天上班摸鱼、一有机会就想提前退休。但在谷歌，我遇到的每个人都认真、勤奋，想要成就伟大的事业。</p><p>&nbsp;</p><p>而真正击败他们的，是繁琐的挑战、频繁的重组、过往失败在他们身上烙下的耻辱印记，被迫在全球顶尖的舞台上重复最简单的工作。初创公司空间更大、每位员工都能随意施为，但谷歌这边就极度缺乏这种自由度。</p><p>&nbsp;</p><p>阻碍发展的还有人们自身——最睿智的头脑们在这里被迫谨言慎行，就连领导者自己也不敢直接说出那些令人不安的事实。我还发现不少缺乏明确定位的员工，但他们仍然长年留在谷歌，甚至通过一个个根本没有意义的岗位保持着晋升。</p><p>&nbsp;</p><p></p><p><img src=\"https://uploader.shimo.im/f/CUYLWqUB9AQulqi6.png!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDAwMjkxMTIsImZpbGVHVUlEIjoicnAzT01hV0o4ZFVkVjhrbSIsImlhdCI6MTcwMDAyODgxMiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyNDM2MDc5MH0.CPSNGEc4HRF_cfyo_XfM1X87u-auUgSHbRMGSdMZY_c\" /></p><p></p><p>&nbsp;</p><p>头重脚轻的组织最难驾驭。结合自己的切身感受，我发现谷歌这种头重脚轻的组织结构已经严重制约了其顺利发展。一支汇聚了多位成功联合创始人、外加十几位谷歌资深工程师的团队听起来似乎战斗力极强，但却往往是什么都做不了、什么都通不过。</p><p>&nbsp;</p><p>如果真有多个领域需要探索、目标已经明确设定而且拥有很强的自主权，那这样的结构应该能够发挥优势。但大多数情况下我们只是在开发一款统一的产品，这时候就需要一位明确的领导者、一个明确的方向，再加上众多实干家、而非空想家。另外跟直觉相反，在早期项目中添加人手并不能加快速度，反而可能导致工作陷入停滞。</p><p>&nbsp;</p><p></p><h2>被威胁到了才改变</h2><p></p><p>&nbsp;</p><p>技术债真实存在，流程债也一样。工程师们对于技术债应该不会陌生：当下为了节约时间、快速发布功能所抄的近道，未来都会成为制约项目进一步发展的阻力。要么早点偿还，要么就是成为项目身上流血不止的伤口。优秀的团队总会定期找段不忙的时间，有条不紊地偿还掉一部分“债务”。</p><p>&nbsp;</p><p>流程债的情况跟技术债类似，可能是因为之前产品出错而添加了新的审核，有可能是引入法务检查以防止潜在诉讼，包括在文档模板中增设新的部分。多年以来，层层积累下的流程已经极度繁复，导致开发完成数月有余的新功能陷入审查而迟迟无法发布，而且没人说得清该怎么提速。</p><p>&nbsp;</p><p>在某些极端情况下，流程甚至需要回滚：谷歌最近调整了繁琐的绩效评估流程，从每年两次改为一年一次、从长问卷改为短问卷，希望把评估工作占用经理们的时间从每年30%压缩到10%以下。</p><p>&nbsp;</p><p>但这往往是因为受到了外部威胁的冲击，因为如果不这么做，公司就会加速衰落、直到失去一切。谷歌才是ChatGPT底层技术的真正发明者，但胜利的果实却别人摘下。如今，他们希望夺回自己在AI领域的领先地位，可同时又得跟时刻提防出岔子的审核人员之间斗智斗勇。</p><p>&nbsp;</p><p>但只要处理得当，谷歌仍有创造奇迹的能力。谷歌曾经提出过“三个尊重”的价值理念：尊重用户、尊重彼此、尊重机遇。前两条比较容易理解，但第三条该怎么解读就各有各的说法了。</p><p>&nbsp;</p><p>我自己是这样认识的：我们在谷歌工作，这是一家利润丰厚、天才云集的企业。我们薪水丰厚、赚得盆满钵满，生活在位于生态链顶端的硅谷世界里。作为幸运之神的宠儿，这样的我们能做的最好的事情是什么？</p><p>&nbsp;</p><p>我个人的答案很简单：找到所在领域中最重要的问题，并拼尽一切将其解决。</p><p>&nbsp;</p><p>实际上，践行理念的第一步就是先做好分配给自己的工作。而只要日常工作处理得当，我们就有机会深入到庞大的谷歌网络，接触正在筹划的创新内容，凝聚出清晰的未来愿景，通过文档和演示让它引发共鸣，找到同样关注这个问题的高层领导者，同时坚持不懈地宣传自己的目标。</p><p>&nbsp;</p><p>从某种意义上讲，我自己也算是做到了这些。最典型的例子就是开发分步数学教学演示，这项功能是以之前的数学解答工具为基础，由三个人花几个月时间制作完成。该演示将我们的智能辅导愿景转化成了可以体验的直观形式——有链接，可以直接使用，也可以转发给他人。有了这样的成果，后续的对话才有可能性，体验者能够做出相应反馈，功能的影响力逐渐扩散到团队之外，再带着更多观点和建议回到我们手中。</p><p>&nbsp;</p><p>当然，我也有做错的时候。有位领导就觉得我们的想法不错，安排设计师制作了出色的演示，而且不管走到哪都向其他人推荐。但他当时身处的部门跟项目理念不合，他的上司根本就不关注这个方向。最终他转到了另一个团队，在那里终于有机会把梦想变成现实。</p><p>&nbsp;</p><p>大多数收购其实都失败了，就连Socratic也不能算完全成功。一方面，我们成功将两种截然不同的文化融合到了一起，我们的产品也继续存在并不断发展，每年支持约50亿次查询。更重要的是，Socratic的初创班底也都获得了广阔的职业发展空间。</p><p>&nbsp;</p><p>但另一方面，Chris和我还是离开了谷歌去建立了新的初创公司，而且直到现在，Socratic团队或者谷歌也仍未推出一款现象级的AI教育产品。不过我有信心，只要别被暴力重组，Socratic项目组早晚可以实现这个目标。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://shreyans.org/google\">https://shreyans.org/google</a>\"</p><p>&nbsp;</p><p>相关链接：</p><p><a href=\"https://gist.github.com/chitchcock/1281611\">https://gist.github.com/chitchcock/1281611</a>\"</p><p><a href=\"https://twitter.com/_jasonwei/status/1708921475829481683\">https://twitter.com/_jasonwei/status/1708921475829481683</a>\"</p><p><a href=\"https://techcrunch.com/2015/03/25/did-socratic-org-raise-6-million/\">https://techcrunch.com/2015/03/25/did-socratic-org-raise-6-million/</a>\"</p>",
    "publish_time": "2023-11-15 14:42:59",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]