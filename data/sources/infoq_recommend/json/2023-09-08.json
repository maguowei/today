[
  {
    "title": "架构师（2023 年 9 月）",
    "url": "https://www.infoq.cn/article/ZQq8d6dXd8TcKqHo4M9Y",
    "summary": "<h2>卷首语：向量数据库会是 AI 的“iPhone 时刻”吗？</h2>\n<p>作者：冬梅</p>\n<p>最近一年，以 ChatGPT、LLaMA 为代表的大语言模型的兴起，将向量数据库的发展推向了新的高度。</p>\n<p>向量数据库是一种在机器学习和人工智能领域日益流行的新型数据库，它能够帮助支持基于神经网络而不是关键字的新型搜索引擎。向量数据库不同于传统的关系型数据库，例如 PostgreSQL，其最初设计用于以行和列的形式存储表格数据。它也明显不同于较新的 NoSQL 数据库，例如 MongoDB，其主要是将数据存储在 JSON 文档中。</p>\n<p>向量数据库是为存储和检索一种特定类型的数据而设计的：向量嵌入。它们本质上是机器学习过程的推理部分中运行新数据的过滤器。</p>\n<p>在大模型部署中，向量数据库可用于存储大模型训练产生的向量嵌入。通过存储代表大模型广泛训练的潜在数十亿个向量嵌入，向量数据库执行最重要的相似性搜索，找到用户提示（他或她提出的问题）和特定向量嵌入之间的最佳匹配。</p>\n<p>大模型爆火后，更多企业开始大力投资向量数据库以提升算法准确性和效率。据相关统计，2023 年 4 月的 AI 投资领域呈增长趋势，尤其是向量数据库领域的投资活动颇为活跃，Pinecone、Chroma 和 Weviate 等向量数据库初创公司都在这个月获得了融资。</p>\n<p>当前的向量数据库在大模型淘金时代扮演着重要角色，它就像一把好的铲子一样，有助于挖掘出更多更宝贵的资源。</p>\n<p>但不能忽视的是，大模型在一定时段内可能无法解决所有问题。虽然有些大模型的创建者相信通用人工智能（AGI）会到来，但不少业内专家认为所谓的AI的“iphone”时刻不会这么快到来。在这个阶段，我们需要着手将大模型应用到实际中，让其具备非常智能的能力，可以进行对话，解决问题等。</p>\n<p>然而，要做好这件事并不容易，因为首先你需要了解如何挖掘金矿，即了解整个流程。就像采金矿一样，需要一套标准的流程，不能只是做好一把铲子，还需要考虑如何做筛子，如何对资源进行更深入的处理。这是一个复杂的过程，需要对向量数据库和大模型进行更深入的了解和探索。</p>\n<h2>目录</h2>\n<p><strong>热点 | Hot</strong><br />\nOpenAI 或于 2024 年底破产？大模型太烧钱了，快把 OpenAI 烧没了！</p>\n<p>吵翻了！到底该选 Rust 还是 Go，成 2023 年最大技术分歧</p>\n<p>IPv4 开始收费！新的 IT 灾难？<br />\n用 Rust 编写，已有 10 万行代码：顶级黑客组织出手，将推出新的反数据收集开源框架 Veilid</p>\n<p>平头哥推出首个 RISC-V AI 平台：软硬件深度协同，支持运行 170 余个主流 AI 模型</p>\n<p><strong>访谈文章 | Interview</strong><br />\n独家对话 AGI 模型“之父” Marcus Hutter：AI 能完成人类半数的工作，但让人类失业是一件美好的事情</p>\n<p>两个多月完成全自研：大模型之争，从 GPU 卷到了向量数据库</p>\n<p>QQ NT 全新重构，探寻 24 岁 QQ 大重构背后的思考</p>\n<p><strong>案例研究 | Case Study</strong><br />\nApache Doris 助力中国联通万亿日志数据分析提速 10 倍</p>\n<p>处理时延降低 24 倍，联通云粒数据引擎优化实践</p>\n<p>解读 Linux 内存管理新特性 Memory folios</p>\n<p>大模型颠覆研发模式：字节跳动是如何在单元测试中落地大模型的?</p>\n<p><strong>推荐文章 | Article</strong><br />\n谷歌的反“背锅”文化</p>\n<p>生成的代码会出错、质量差？面对 AI 编程工具的老大难问题，华为这群人打算这样做</p>\n<p>将 60 多年的 COBOL 语言重构为 Java，IBM 用 AI 工具解决大型机维护难</p>\n<p>七年没能将 Python 集成到 Excel，Python 之父加入微软三年后成了！</p>\n<p><strong>特别专题｜AIGC时代，我们需要什么样的向量数据库？</strong></p>\n<p>百亿级向量检索的向量数据库是如何构建的？</p>\n<p>解决成本、易用性和扩展性三大挑战，星环科技向量数据库从 0 到 1 技术实践</p>\n<p>DingoDB 多模向量数据库正式发布，支持多模态数据统一存储和联合分析</p>\n<p>向量数据库内核面临的技术挑战及应对措施</p>\n<p><strong>特别专栏 | 视频推荐</strong><br />\n本月，这些视频值得一看！</p>",
    "publish_time": "2023-09-08 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "OpenTelemetry Protocol（OTLP）1.0.0版本正式发布：开源可观察性框架迈出关键一步",
    "url": "https://www.infoq.cn/article/qkkLpwRHSargeKqGU68J",
    "summary": "<p>最近，OpenTelemetry Protocol（OTLP）1.0.0版本发布了。<a href=\"https://github.com/open-telemetry/opentelemetry-specification/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTM5MDE3MjksImZpbGVHVUlEIjoiNk16N0FmV05zajQxcXBMaiIsImlhdCI6MTY5MzkwMTQyOSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.Kt1bLpVB_57v_KxssMEDXo1DDjMHq-sx-fPkkwBVuX4\">OTLP规范</a>\"描述了遥测数据在遥测源、中间节点（如收集器）和遥测后端之间的编码、传输和传递机制。OTLP是一个通用的遥测数据传递协议，隶属于OpenTelemetry项目。</p><p></p><p><a href=\"https://opentelemetry.io/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTM5MDE3MjksImZpbGVHVUlEIjoiNk16N0FmV05zajQxcXBMaiIsImlhdCI6MTY5MzkwMTQyOSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.Kt1bLpVB_57v_KxssMEDXo1DDjMHq-sx-fPkkwBVuX4\">OpenTelemetry</a>\"（OTEL）是一个开源的<a href=\"https://www.cncf.io/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTM5MDE3MjksImZpbGVHVUlEIjoiNk16N0FmV05zajQxcXBMaiIsImlhdCI6MTY5MzkwMTQyOSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.Kt1bLpVB_57v_KxssMEDXo1DDjMHq-sx-fPkkwBVuX4\">云原生计算基金会</a>\"（CNCF）项目，由<a href=\"https://opencensus.io/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTM5MDE3MjksImZpbGVHVUlEIjoiNk16N0FmV05zajQxcXBMaiIsImlhdCI6MTY5MzkwMTQyOSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.Kt1bLpVB_57v_KxssMEDXo1DDjMHq-sx-fPkkwBVuX4\">OpenCensus</a>\"和<a href=\"https://opentracing.io/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTM5MDE3MjksImZpbGVHVUlEIjoiNk16N0FmV05zajQxcXBMaiIsImlhdCI6MTY5MzkwMTQyOSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.Kt1bLpVB_57v_KxssMEDXo1DDjMHq-sx-fPkkwBVuX4\">OpenTracing</a>\"项目合并而成。它是一个与供应商无关的开源<a href=\"https://opentelemetry.io/docs/concepts/observability-primer/#what-is-observability?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTM5MDE3MjksImZpbGVHVUlEIjoiNk16N0FmV05zajQxcXBMaiIsImlhdCI6MTY5MzkwMTQyOSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.Kt1bLpVB_57v_KxssMEDXo1DDjMHq-sx-fPkkwBVuX4\">可观察性</a>\"框架，用于增强、生成、收集和导出遥测数据（如<a href=\"https://opentelemetry.io/docs/concepts/signals/traces/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTM5MDE3MjksImZpbGVHVUlEIjoiNk16N0FmV05zajQxcXBMaiIsImlhdCI6MTY5MzkwMTQyOSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.Kt1bLpVB_57v_KxssMEDXo1DDjMHq-sx-fPkkwBVuX4\">跟踪</a>\"信息、<a href=\"https://opentelemetry.io/docs/concepts/signals/metrics/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTM5MDE3MjksImZpbGVHVUlEIjoiNk16N0FmV05zajQxcXBMaiIsImlhdCI6MTY5MzkwMTQyOSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.Kt1bLpVB_57v_KxssMEDXo1DDjMHq-sx-fPkkwBVuX4\">指标</a>\"和<a href=\"https://opentelemetry.io/docs/concepts/signals/logs/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTM5MDE3MjksImZpbGVHVUlEIjoiNk16N0FmV05zajQxcXBMaiIsImlhdCI6MTY5MzkwMTQyOSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.Kt1bLpVB_57v_KxssMEDXo1DDjMHq-sx-fPkkwBVuX4\">日志</a>\"）。该框架提供了一组API、库、代理和收集器服务，用于捕获分布式跟踪和指标信息。此外，它在2021年早些时候发布了1.0.0版规范，InfoQ对此进行过<a href=\"https://www.infoq.com/news/2021/03/opentelemetry-spec-1-0/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTM5MDE3MjksImZpbGVHVUlEIjoiNk16N0FmV05zajQxcXBMaiIsImlhdCI6MTY5MzkwMTQyOSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.Kt1bLpVB_57v_KxssMEDXo1DDjMHq-sx-fPkkwBVuX4\">报道</a>\"。</p><p></p><p>OpenTelemetry通过使用<a href=\"https://opentelemetry.io/docs/concepts/instrumentation/libraries/#opentelemetry-api?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTM5MDE3MjksImZpbGVHVUlEIjoiNk16N0FmV05zajQxcXBMaiIsImlhdCI6MTY5MzkwMTQyOSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.Kt1bLpVB_57v_KxssMEDXo1DDjMHq-sx-fPkkwBVuX4\">API</a>\"生成遥测数据、在不同SDK之间实现无缝的指标收集来增强应用程序代码。它提供了<a href=\"https://opentelemetry.io/docs/instrumentation/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTM5MDE3MjksImZpbGVHVUlEIjoiNk16N0FmV05zajQxcXBMaiIsImlhdCI6MTY5MzkwMTQyOSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.Kt1bLpVB_57v_KxssMEDXo1DDjMHq-sx-fPkkwBVuX4\">特定于语言的集成</a>\"方式和库，如用于Java、Golang、.NET和Python的OTel SDK，让开发人员能够增强他们的代码并捕获遥测数据。通过这些库收集的遥测数据被集中传输给<a href=\"https://opentelemetry.io/docs/collector/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTM5MDE3MjksImZpbGVHVUlEIjoiNk16N0FmV05zajQxcXBMaiIsImlhdCI6MTY5MzkwMTQyOSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.Kt1bLpVB_57v_KxssMEDXo1DDjMHq-sx-fPkkwBVuX4\">OpenTelemetry Collector</a>\"，利用OTLP在客户端和服务器之间进行数据交换。OTLP定义了一种序列化模式，与跟踪信息、指标和日志的数据模型紧密相关。</p><p></p><p>作为一个中央仓库，OpenTelemetry Collector负责接收、处理并导出从各种来源收集到的遥测数据，既作为应用程序的本地代理，也作为多个应用程序的网关。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3a/3aadb8046bd283512c13bb5d7d1929fc.webp\" /></p><p></p><p></p><p>Open Telemetry架构图（来源：<a href=\"https://opentelemetry.io/docs/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTM5MDE3MjksImZpbGVHVUlEIjoiNk16N0FmV05zajQxcXBMaiIsImlhdCI6MTY5MzkwMTQyOSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.Kt1bLpVB_57v_KxssMEDXo1DDjMHq-sx-fPkkwBVuX4\">https://opentelemetry.io/docs/</a>\"）</p><p></p><p>OTLP在数据序列化、反序列化和网络传输方面发挥着重要作用。它致力于根据数据模型指定一种与之紧密相关的序列化模式，并解决与<a href=\"https://github.com/open-telemetry/opentelemetry-proto/blob/main/docs/requirements.md?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTM5MDE3MjksImZpbGVHVUlEIjoiNk16N0FmV05zajQxcXBMaiIsImlhdCI6MTY5MzkwMTQyOSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.Kt1bLpVB_57v_KxssMEDXo1DDjMHq-sx-fPkkwBVuX4\">其他遥测协议</a>\"相关的问题。</p><p></p><p>Honeycomb开发者布道师<a href=\"https://twitter.com/MartinDotNet?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTM5MDE3MjksImZpbGVHVUlEIjoiNk16N0FmV05zajQxcXBMaiIsImlhdCI6MTY5MzkwMTQyOSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.Kt1bLpVB_57v_KxssMEDXo1DDjMHq-sx-fPkkwBVuX4\">Martin Thwaites</a>\"告诉InfoQ：</p><p></p><p></p><blockquote>OTLP是OpenTelemetry的核心，它让OpenTelemetry变得比之前已有的东西都更强大，1.0.0版本则更上一层楼。目前，大多数供应商已经在使用OTLP协议接收数据，1.0.0版本的发布给人们带来了更强的信心，并有望让最后的一些观望者也加入使用OTLP的行列。</blockquote><p></p><p></p><p>此外，他还表示：</p><p></p><p></p><blockquote>这很重要，因为它带来了更多的互操作性，减少了在技术栈中加入专有协议库的需求，这对于希望更多地了解应用程序发生了什么的人来说是一个好消息。</blockquote><p></p><p></p><p>OpenTelemetry目前是一个CNCF<a href=\"https://www.cncf.io/projects/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTM5MDE3MjksImZpbGVHVUlEIjoiNk16N0FmV05zajQxcXBMaiIsImlhdCI6MTY5MzkwMTQyOSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.Kt1bLpVB_57v_KxssMEDXo1DDjMHq-sx-fPkkwBVuX4\">孵化器项目</a>\"。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/08/otlp-version-one-released/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTM5MDE3MjksImZpbGVHVUlEIjoiNk16N0FmV05zajQxcXBMaiIsImlhdCI6MTY5MzkwMTQyOSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.Kt1bLpVB_57v_KxssMEDXo1DDjMHq-sx-fPkkwBVuX4\">https://www.infoq.com/news/2023/08/otlp-version-one-released/</a>\"</p>",
    "publish_time": "2023-09-08 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "关于征集中国人工智能产业联盟数据委员会首批成员的通知",
    "url": "https://www.infoq.cn/article/6lqRZZbyximTXzP7okTI",
    "summary": "<p>随着大模型技术的突破，新一轮人工智能浪潮正在引领各行各业快速发展。数据作为此轮变革的主要驱动力，已成为人工智能发展的关键战略要素。但国内人工智能行业正在面临高质量训练数据供给不足、训练数据治理水平不高、数据供需流通机制不畅等挑战，制约了我国生成式人工智能创新发展。</p><p></p><p>为破解AI数据短缺难题，中国人工智能产业发展联盟（AIIA）成立“数据委员会”。AIIA数据委员会拟定10月中旬正式举办成立仪式，成立后将与人工智能关键技术和应用评测工信部重点实验室、中国通信标准化协会大数据技术标准推进委员会（CCSA TC601）等组织加强协同，共同推动产业研究、标准研制、技术应用等相关工作。主要工作方向包括但不限于以下几个方面：</p><p></p><p>（一）AI数据资源供需对接</p><p>汇聚数据资源持有方、数据标注加工方、数据需求方等主体，聚焦AI数据资源汇聚、需求反馈、数据加工、供需对接等方面，提供AI数据集产业公共服务能力。</p><p></p><p>（二）AI数据技术应用研究推广</p><p>针对数据构建、增强、清洗、标注、治理和合成等共性关键技术和工具平台建设，推动数据合成等新兴技术应用，开展联合攻关和应用推广。</p><p></p><p>（三）AI数据治理体系建设</p><p>面向AI训练的数据全生命周期，围绕数据采集标注、质量管理、开放共享等方面需求，建设AI数据治理标准体系，提升训练数据质量，保证数据真实性、准确性、多样性和可追溯性。</p><p></p><p>（四）AI数据应用创新</p><p>围绕金融、零售、制造、教育等数据密集型行业，探索人工智能数据应用场景示范，推广典型人工智能数据应用方式。</p><p></p><p>（五）AI数据商业模式与政策研究</p><p>对接数据拥有方、数据训练方和数据加工方等主体，探索合作共赢的商业模式，总结业界最佳实践，形成可推广的商业模式；结合国家数据基础制度建设进展，提出适应AI训练场景的数据政策建议。</p><p></p><p>现公开征集组长单位、副组长单位和成员单位，作为首批发起单位，首批报名截至时间为2023年9月30日。</p><p></p><p>请有意向加入AIIA数据委员会的企业，填写报名表（点击“阅读原文”获取）并反馈至wanghongjing@aiiaorg.cn。</p><p></p><p>联系人：</p><p>李老师 18611353631&nbsp; &nbsp;</p><p>樊老师 18612301312</p>",
    "publish_time": "2023-09-08 08:54:45",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "面对复杂技术栈，中泰证券如何做云原生转型？",
    "url": "https://www.infoq.cn/article/3f7M1Fiv0t9AB1F2xpxs",
    "summary": "<p>近年来，云原生转型已成为众多企业关注的焦点，中泰证券也不例外。但中泰证券的云原生转型面临着很大挑战。</p><p>&nbsp;</p><p><a href=\"https://xie.infoq.cn/article/799714640c0e5863f76910022\">中泰证券</a>\"的软件架构非常复杂。除了传统架构，还有一些自行研发的<a href=\"https://www.infoq.cn/topic/cloud-computing\">云原生</a>\"架构、独立框架以及独立的C++框架等，云原生架构的比例较低。数据库方面同样如此，内部数据库类型繁多，Oracle 占了30%，此外还有MySQL、SQL Server等等。过多的技术栈，各种架构交织在一起增加了转型难度。</p><p>&nbsp;</p><p>中泰证券金融科技委员会主任兼科技研发部总经理何波在“2023网易数帆城市行”大会上，分享了自己做云原生转型的过程。面对复杂的技术栈，中泰证券的技术团队的策略是将技术的复杂性与业务研究的复杂性分离。“通过标准化技术，我们可以将技术复杂性下沉，从而更多地关注业务复杂性，减少处理技术细节的时间和精力。”何波表示。</p><p></p><h4>转型过程</h4><p></p><p>&nbsp;</p><p>从软件工程的演进来看，架构逐渐复杂，但基本原则一直清晰：低耦合、高内聚。通过不断将复杂性标准化下沉至基础框架，可以更好地实现从作坊式向工业化的转变，从而应对更加复杂的体系。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/db/dbe35271fa382f48c73e7224d588efd0.png\" /></p><p></p><p>中泰证券在构建微服务体系的过程中，经历了技术选型、技术验证、引入开源实现及完全自研等一系列的过程。对于技术选型，中泰证券不希望重复发明轮子，也不希望完全受制于开源的实现，所以在技术选型时遵循如下原则：</p><p><img src=\"https://static001.geekbang.org/infoq/55/55f8c88b2038941bcea95b47c61f2af8.png\" /></p><p></p><p>在云原生转型过程中，中泰证券按照一系列明确的步骤进行了架构的迁移，其中一个关键举措是将应用与环境进行解耦。中泰证券需要逐步将原有的粗放式架构层层拆分，将其中台化。新自研项目除少数性能敏感的系统外，全部采用微服务架构；传统架构根据业务分类分组按需进行服务拆分改造；异构系统按需做服务适配，以API形式提供服务，保护投资，复用能力。</p><p>&nbsp;</p><p>通过微服务的转型，技术团队成功将研发工作从上层抽离出应用和环境，也解决了过去部署过程中常见的配置文件和环境问题。借助Kubernetes（K8s），团队成功实现了配置与环境的解耦。目前，中泰证券已经成功在11个K8s集群上运行了2000多个业务。</p><p>&nbsp;</p><p>应用和环境解耦后，接下来就是应用和配置的解耦。在传统的开发模式中，许多应用都含有大量的配置文件，有时甚至会将配置存储在数据库中。然而，这种做法在软件的配置、交付和上线过程中经常导致问题，因为不同环境中的配置可能不同。但实际上，应用本身与配置是没有直接关联的。按照云原生原则，中泰证券将配置转移到环境变量中，并通过配置中心进行管理，成功将应用与配置解耦，使得测试环境和生产环境中的应用完全一致，避免了配置文件引起的问题。目前，其已经建立了4个配置中心，涵盖了80%的自研项目。</p><p>&nbsp;</p><p>中泰证券的另一个重要改进是将中间件进行PaaS化。团队采用了网易数帆轻舟云原生平台作为中间件的资源池，将资源的管理从单个应用下沉到资源池中，避免了每个应用独立构建这些中间件。无论是Redis、Kafka还是多达40种不同版本的MySQL数据库，都被纳入了这一PaaS化的管理中。</p><p>&nbsp;</p><p>金融机构的数据库存储量是很大的。为了提高维护性和升级的便捷性，中泰证券对数据库进行轻量化处理，摒弃存储过程，回归到分布式数据库存储。这样，架构不仅保障了数据的完整性，还将大部分业务逻辑下沉到应用层，资源层的PaaS化也为外部提供了便利。此外，中泰证券对制品库进行了全面的管理，实现了统一的交付渠道。</p><p></p><h4>安全建设</h4><p></p><p>&nbsp;</p><p>技术发展过程中，建立一个更加安全和高效的治理体系至关重要。而中泰证券主要面临着技术栈多样性的挑战，涵盖了注册发现、配置中心、底层数据库、PaaS等。</p><p>&nbsp;</p><p>对于安全问题，中泰证券的技术团队认为，最关键的是要能够及早暴露出故障率。除了前述的技术栈，确保良好的监控和可观测性显得尤为重要。在实际操作中，技术团队需要明确监控的程度，确定哪些指标有意义、哪些无意义，并对衡量标准作出充分考虑，避免系统出现问题时仓促采取行动。</p><p>&nbsp;</p><p>因此，中泰证券非常重视混沌工程的实践，通过模拟红蓝军演练，在系统中引入破坏并尝试恢复，从而更快地发现潜在故障。在这个过程中，技术团队进行了攻防演练，涵盖了大量故障处理，包括基础故障、CPU、内存使用率、磁盘使用率、中间件问题、MySQL异常等。这一实践在某二级部门中得以应用，涉及到20多个业务场景、100多个混沌场景以及300次的演练，有力保障了业务的运行。</p><p>&nbsp;</p><p>接下来，中泰证券进入安全工具的应用阶段，通过代码扫描等安全工具，在CICD安全环节中加入了更多的监测。此外，无论是常规发布还是紧急发布，安全门禁都被置于产品的每个关键点，以确保发布和审核的安全性。</p><p></p><h4>结束语</h4><p></p><p>&nbsp;</p><p>为了评估转型效果，中泰证券对资产进行了分类：实用资产和战略资产，实用资产包括服务器、网络、财务系统等，战略资产包括企业用来向客户提供产品或服务的工具，可以形成差异化竞争优势。去年，中泰证券的战略资产占比为20%，如今已提升至28%左右。</p><p>&nbsp;</p><p>总体而言，云原生转型带来了研发质量和效率的提升。通过减少重复劳动和不必要的开发，中泰证券实现了研发效率的增加。测试能力的提升以及自动化测试平台的使用，也节省了大量的测试时间，大幅度降低了测试成本。</p><p>&nbsp;</p><p>何波还表示，中泰证券最近也在尝试用大模型自动生成代码、自动化测试等，希望开发人员可以聚焦在写业务代码上，并且通过云原生改造真正把技术沉淀下来，变成一些标准化的东西使用。</p><p>&nbsp;</p><p>目前，中泰证券自研项目的研发部分完成了约70%。“我们的目标是进行全面的云原生转型。”何波表示，云原生带来了研发质量和效率的提升，通过敏捷IT能力的构建，为证券业务数字化转型加速，更好地支撑业务创新与客户体验提升。</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-09-08 09:56:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "当 Apache Doris 遇上大模型：探秘腾讯音乐如何基于大模型 + OLAP 构建智能数据服务平台",
    "url": "https://www.infoq.cn/article/uIbplGaLM0pJTTWcLsgT",
    "summary": "<p></p><blockquote>当前，大语言模型的应用正在全球范围内引发新一轮的技术革命与商业浪潮。腾讯音乐作为中国头部在线音乐娱乐平台，利用庞大用户群与多元场景的优势，持续探索大模型赛道的多元应用。本文将详细介绍腾讯音乐如何基于 <a href=\"http://doris.apache.org/\">Apache Doris</a>\" 构建查询高效、实时统一分析的 OLAP 引擎，使 OLAP 作为底层基建加强模型连接转化效率、结果输出准确率，最终将大模型 + OLAP 引擎结合为用户提供个性化、实时化、灵活化的智能数据服务平台。</blockquote><p></p><p></p><p>作者｜腾讯音乐大数据架构张俊、罗雷</p><p></p><p>腾讯音乐娱乐集团（以下简称“腾讯音乐”）是中国在线音乐娱乐服务开拓者，有着广泛的用户基础，总月活用户数超过 8 亿，通过“一站式”的音乐娱乐平台，用户可以在多场景间无缝切换并享受多元的音乐服务。我们希望通过技术和数据赋能，为用户带来更好的体验，为音乐人和合作伙伴在音乐制作、发行、销售等方面提供支持。</p><p></p><p>基于公司丰富的音乐内容资产，需要将歌曲库、艺人资讯、专辑信息、厂牌信息等大量数据进行统一存储形成音乐内容数据仓库，并通过产品工具为业务人员提供数据分析服务。在内容数仓搭建的过程中，我们的工作始终围绕降本增效为主要目的进行优化与迭代，希望在数据服务方面不断提升产品工具的开发与分析效率，同时在数仓架构方面能够有效减少架构成本与资源开销。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/be/be6d51243889d07c791efa856d5693f4.jpeg\" /></p><p></p><p>在传统数据服务中，我们为业务分析师提供了多种数据服务，包括 SQL 查询、固定看板、定制化的分析工具以及人工跑数。然而，在实际应用过程中仍然存在一定痛点：</p><p></p><p>SQL 查询平台 ： 业务分析师根据需求进行 SQL 语句编写，对平台数据进行查询分析，每位业务人员都需要掌握 SQL，导致学习成本高、上手难度大。固定看板（Dashboard） ： 技术人员基于常规业务开发制作数据看板，虽然能够简化业务分析师查询的过程，但是看板制作成本高且灵活度低，当面对复杂的用户问题时，看板无法及时调整以满足需求变更。定制分析工具： 基于特定的业务需求，技术人员需要定制化开发产品分析工具，整体开发成本过高，且单一的开发工具不具备通用性，随着工具数量增加，操作介面变得散乱，从而降低业务效率。人工跑数： 当以上三个场景都无法满足业务需求时，业务分析师需要向技术人员提需求进行人工跑数，沟通成本过高、整体解决效率低下。</p><p></p><p>随着行业发展趋势，LLMs 大语言模型（LLMs - Large Language Models，以下统一简称为大模型）出现有效地解决了这些问题。当平台融入大模型后，平台用户输入的问题会进入大模型进行语义解析，自动转化为 SQL 语句触发 OLAP 引擎开启数据分析与查询。通过平台智能问答交互的方式，业务分析师不再需要依靠人工编写 SQL 提供查询分析结果，技术人员也不需要再制作过于固定或者过于定制化的产品工具。大模型 + OLAP 引擎结合的全新数据服务模式，不仅为平台用户提供了个性化、灵活表达、秒级回复的服务体验，还大幅降低了企业内部技术与业务学习成本，加速数据分析效率，实现多端入口统一、界面统一的平台构建。</p><p></p><p>本文将详细介绍腾讯音乐如何基于 Apache Doris 构建查询高效、实时写入且统一的 OLAP 分析引擎，使 OLAP 作为底层基建加强大模型与之连接转化的效率、结果输出的准确率，最终提供更智能化的问答交互服务，也希望通过这篇文章为有相关业务需求的公司提供不同视角和思路。</p><p></p><h2>大模型 + OLAP ：开启数据服务平台新模式</h2><p></p><p></p><p>在大模型 + OLAP 架构方案中，目前经典方案如下图所示，大模型充当中间层将用户输入的自然语言转化为 SQL 执行语句，OLAP 作为底层存储和数据处理的引擎，负责接受和执行从大模型发送过来的 SQL 语句，对数据进行预聚合、多维分析等操作，满足大规模数据集的查询分析需求。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/05/058c7be9d4bf67b4ee4af097566b4b16.png\" /></p><p></p><p>然而，这种架构在实际落地过程中也面临一定挑战，例如语义理解的准确性、查询效率的优化、私域知识的理解等方面，具体如下：</p><p></p><p>复杂数据口径不统一： 大模型对于技术方面的词汇，如字段、行列、表等无法理解，相反对于业务方面的词汇，如公司收入情况、日活跃用户数量等能够提供有效翻译与转换。因此挑战之一是需要思考如何引导用户进入指标范围内提问，挑战之二是当用户存在对多种指标、多类指标查询时，需要考虑如何保持指标维度口径的统一、如何有效生成对应的指标计算公式。模型处理效率较低： 现阶段大模型虽然支持交互能力，但推理速度较慢，需要花费十秒级以上响应，用户每增加一个问题输入，就需要花费更多等待时间，使服务质量降低。同时大模型整体按照 Token 收费，使用量增加时也会导致平台成本升高。私域知识无法识别： 虽然大模型已经开展许多公开数据集的语言转换训练，但面对企业内部的大量专业术语仍无法很好地理解转化。以音乐内容数据库为例，大模型时常缺少对于某些冷门歌曲的认知，在问答过程中无法正确给出交互反馈，因此我们需要增强大模型对于私域知识的理解。定制场景无法满足： 大模型主要依据自身数据集进行回答，会出现“知识幻觉”（输出缺乏依据的内容）问题，我们需要允许第三方插件的接入使大模型得以联网，让用户借助内部插件完成更定制化、更多样的任务。因此如何接入、匹配并触发组件功能是我们的重点优化目标。</p><p></p><p>面对经典方案中的落地难点，我们的总体解决思路是将以上四大挑战逐一拆解，通过组件叠加分阶段完善大模型 + OLAP 架构构建，最终实现全新的交互问答服务模式，接下来我们将介绍各阶段挑战对应的解决方案。</p><p></p><h3>增加语义层：处理复杂数据问题</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/bc/bc1cc7076ec03de757325be3df7d235e.png\" /></p><p></p><p>为了解决复杂数据处理问题，我们在大模型与 OLAP 中间增加 Semantic Layer（以下简称语义层）。</p><p></p><p>一方面语义层作为连接技术与业务之间的转换桥梁，能够将数据字段翻译为业务用户的术语，使业务知识作为额外的抽象层。通过语义层，业务分析师不需要在定义指标后存储于 OLAP 数仓中，能够直接在语义层中指定过滤条件，将所需指标筛选后生成 SQL 语句并在 OLAP 中进行字段查询。这意味着，业务分析师能够把多源数据按照需求定义成语义信息并形成语义标准，有效解决了多种指标、多类维度计算口径不统一的挑战。</p><p></p><p>另一方面语义层能够针对业务计算逻辑，进行语义加工、描述、关联和运算。语义层在过滤数据后，能够屏蔽由表关联所产生的复杂指标计算公式，将多表 Join 场景进行拆解、转化，形成较为简单的单表查询，以提升语义转化的准确性。</p><p></p><h3>设定人工经验：处理模型效率问题</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/bc/bc685dbf1f204f0a4cbb196ef7c9b01a.png\" /></p><p></p><p>针对模型效率问题，我们的解决思路是对指标计算、明细查询、人群圈选等查询场景进行复杂度判定，将简单查询场景直接跳过大模型解析的步骤，进入底层 OLAP 进行处理分析，使大模型更加专注处理复杂查询场景。</p><p></p><p>为此，如上图所示我们在模型中添加人工经验判断。当业务分析师输入 “查询各大音乐平台收入”问题时，模型依据判定规则发现该场景只需要提供某个指标或几个维度即可完成，这时不需要将问题进入大模型解析，直接使用 OLAP 进行查询分析，能够有效缩短响应时间，提升结果反馈效率。此外，跳过大模型解析的步骤也能够节省 API 调用经费，解决平台使用成本升高的问题。</p><p></p><h3>增加内容映射：处理私域知识问题</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/4f/4f6148b63a2e12a5d4ba82951251f012.png\" /></p><p></p><p>针对私域知识的问题，我们在大模型上游增加 Schema Mapper 、在外部建立业务知识库，将平台用户的问题与知识库进行连接，通过 Schema Mapper 判定是否存在部份文字能够与知识库内容匹配。如果匹配成功，大模型将进一步解析转化、OLAP 分析处理。Schema Mapper 与业务知识库的引入，有效解决了大模型对私域知识理解不足的问题，提升语言处理的效果。</p><p></p><p>目前，我们正在不断对 Schema Mapper 匹配准确性进行测试与优化，将知识库中的内容进行分类处理、字段评级等操作，同时将输入文本进行不同范围的内容映射（如全文本映射与模糊映射），通过映射结果来加强模型语义解析的能力。</p><p></p><h3>插件接入：处理定制场景问题</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/db/db37efda5c82f1f802c1ec1afeef655a.png\" /></p><p></p><p>定制化场景主要指代业务范围之外的查询需求，需要将音乐内容数据与法律、政治、金融、监管等方面信息结合提供问答服务。通过增加插件，使平台用户能够访问实时更新且无法包含在训练数据或业务知识库中的信息，以实现定制化交互。</p><p></p><p>由于插件类型不同，模型接入方式也会有所不同，常见的接入方式主要分为两种：</p><p></p><p>Embedding 本地文本接入： 该方式首先对本地文档进行向量化处理，通过语义向量搜索，找到本地文档中相关或者相似的词语进行匹配，之后将文档内容注入大模型解析窗口中生成答案。这种方式非常适合业务分析师希望将音乐内容数据库与最新政策等一类较为私有的文件结合完成查询需求。ChatGPT 第三方插件接入： 每款插件具备对应的 Prompt 与调用函数。业务人员在安装某款插件之后，在与模型对话中可以通过 Prompt 词触发函数开启调用。目前第三方插件类型丰富，涉及行业广泛，能够有效增加多元场景的处理与响应能力。</p><p></p><h2>超音数平台框架构思</h2><p></p><p></p><p>根据上述大模型 + OLAP 的四大解决方案进行了方案整合，以此进行框架设计并将其命名为超音数平台。大模型主要作用于自然语言与 SQL 分析语句的连接与转化，OLAP 引擎则作为数据存储与查询分析的核心基建。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/97/97aefdf681aef73a34cb28e0b1f3002b.png\" /></p><p></p><p>超音数平台对于业务流程如图所示，模型运转具体过程如下：</p><p></p><p>用户输入问题通过 Schema Mapper 检索，判定字段是否匹配与业务知识库。如若匹配则跳过大模型解析步骤，直接利用知识库中的指标计算公式触发 OLAP 进行查询分析；如若不匹配则进入大模型，开启下一步判定。大模型首先通过人工经验判定问题复杂度，简单查询将指定 OLAP 引擎直接分析，复杂查询则开启语义解析形成 DSL 语句。DSL 语句通过语义层进一步过滤、拆解关联查询场景，生成简易单表 SQL 语句以触发 OLAP 数据处理与查询加速。针对需要与外部信息结合的查询场景，大模型会判断是否调用第三方插件来辅助完成查询。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/21/211c2536582f1990432fc3c0252448eb.png\" /></p><p></p><p>以“某首歌曲能否在综艺节目播出”为例，在经过检索匹配、语义解析后，大模型选择利用 OLAP 数据查询与第三方版权行业插件结合的方式进行回答，最终呈现结果由数仓中的歌曲信息与插件判定结果构成。</p><p></p><p>如今，业务分析师只需要在超音数平台中定义指标含义、维度类型即可直接开展自然语言的问答交互服务。同时还可以在平台中内置插件、丰富指标市场来拓展语义解析能力，完全覆盖了业务在常规与定制化场景下的查询需求。平台基于大模型 + OLAP 的模式加速业务分析效率，减少技术开发成本，向智能化、个性化、实时化的全新业务服务模式更近一步。</p><p></p><p>在这里希望可以与大家分享该开源项目，让更多人体验和学习大模型构建，也欢迎感兴趣的读者们共同参与大模型开发与建设。</p><p></p><p></p><blockquote>超音数开源框架：https://github.com/tencentmusic/supersonic</blockquote><p></p><p></p><h2>超音数平台框架演进</h2><p></p><p></p><p>在平台构建的过程中，OLAP 引擎作为整体架构的基建对 SQL 语句处理、数据存储分析、上游应用层的查询响应等有着至关重要的作用，我们希望通过架构升级以加强大模型到 OLAP 引擎的转化效率与结果输出准确性。</p><p></p><p>接下来我们将对比介绍 OLAP 早期架构与新一代架构在数据写入与查询两方面的差异，分享在架构演进过程中大模型 + OLAP 模型优化历程，最终助力超音数平台的构建，开启新一代的数据服务模式。</p><p></p><h3>数据架构 1.0</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/07/079ab31e38fea758f9f92fe2a4d23f89.jpeg\" /></p><p></p><p>我们初期的业务架构如上图所示，分为处理层、分析层、应用层三部份，用户文本在进入大模型之后解析为 SQL 语句使 OLAP 开始执行任务，具体的工作原理如下：</p><p></p><p>处理层：在 ODS- DWD- DWS 三层中将数据整合为不同主题的标签和指标体系之后，通过对 DWS 调度与采集所需字段，在 DWM 层将维度与指标数据加工成大宽表。分析层：通过大宽表进入分析层，将数据导入 Clickhouse 与 Elasticsearch，其中 Clickhosue 主要负责维度与指标两类数据的查询加速，作为分析引擎为后续提供报表开发服务；Elasticsearch 主要负责维度数据处理，作为搜索/圈选引擎。应用层：业务人员基于场景选取所需要的标签与指标，在应用层中创建数据集作为逻辑视图，同时可以二次定义衍生的标签与指标。</p><p></p><p>在实际业务使用中，早期架构的数据处理方式存在大宽表带来的数据延迟与存储浪费、多套组件导致架构冗余带来指标维度重复定义、学习与运维成本高等问题，具体如下：</p><p></p><p>数据延迟： 处理层不支持部分列表更新，DWS 层数据写入产生延迟后会造成大宽表的延迟，进而导致数据时效性下降。运维成本高： 在处理层大宽表中维度数据量平均占一张大宽表的 50%，且在大部份情况下变化缓慢，这意味着每一张宽表的开发会将维度数据叠加，造成存储资源的浪费、维护成本增加；在分析层中存在多引擎使用的问题，查询 SQL 语句需要同时适配 Clickhouse 与 Elasticsearch 两个组件，增加人力成本，且两套组件也会加大运维难度，运维成本进一步升高。架构冗余： 在应用层进行指标与维度定义时，导致相同数据会进行多次定义使各种指标、维度定义口径不一致，造成权限不可控，例如上图所示的 T1 （标签）与 M1 （维度）在应用层中，被不同数据集多次定义。</p><p></p><h3>数据架构 2.0</h3><p></p><p>基于以上问题，我们开始对架构进行改造升级，并在众多 OLAP 引擎中选择了 Apache Doris 来替换原有组件，主要因为 Apache Doris 具备以下核心优势：</p><p></p><p>实时导入：  Apache Doris 能够支持海量业务数据的高吞吐实时写入，时效性可以做到秒级完成导入。引擎统一： 支持 Multi-Catalog 功能，能够通过 Elasticsearch Catalog 外表查询，实现查询出口统一，查询层架构实现链路极简，维护成本也大幅降低。查询分析性能： Apache Doris 是 MPP 架构，支持大表分布式 Join，其倒排索引、物化视图、行列混存等功能使查询分析性能更加高效极速。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7b/7b9e4ec29a21c25ffe2161d0e3a616fb.jpeg\" /></p><p></p><p>在数据架构 2.0 版本中，数据架构保留处理层部份，主要升级分析层架构，并进行了语义层叠加：</p><p></p><p>分析层：引入 Apache Doris 替换 Clickhouse 组件，利用 Doris 的 Elasticsearch Catalog 功能对 Elasticsearch 外表进行查询，实现查询出口统一；语义层：应用层不再需要创建数据集视图，直接通过语义层获取指标与标签内容执行查询任务，有效解决标签与指标口径问题。</p><p></p><h3>数据架构 3.0</h3><p></p><p>由于宽表开发过程中，维度数据一般变化较小、字符存储空间较大，且分析查询一般只需要查询最新的维度数据。在这种情况下，如果不断叠加维度数据制作宽表，会造成存储空间浪费的问题，同时查询响应速度也受到影响。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c2/c2cebe08abe150c665cc8e67dddf552c.jpeg\" /></p><p></p><p>为了进一步提升架构性能，数据架构 3.0 主要将处理层中大宽表进行拆分，同时将分析层统一使用 Apache Doris 作为查询分析引擎：</p><p></p><p>处理层：按照业务分类在 DWM 中将大宽表拆分成缓慢维度表与指标表，使两类表在本地 Hive 中进行关联，通过 Hive 导入 Apache Doris 分析层中加速任务；分析层：将关联数据表直接导入 Apache Doris 中，结合语义层暴露指标与维度以实现语义统一，用户只需要通过过滤条件就能够直接查询数据，得到所需要的结果。</p><p></p><h3>数据架构 4.0</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/7b/7b1c7017f2b38d5e33b15b4dab8b0740.jpeg\" /></p><p></p><p>我们延续了 3.0 架构中分析层统一的优势，对处理层、分析层、语义层架构进一步优化，使查询性能显著提升：</p><p></p><p>分析层 + 处理层：数仓 DWD 层数据采用  Rollup 功能使事实表与维度表实时关联并创建多个视图进入 DWS 中。通过这种方式，分析层与处理层中的各类指标数据无需再重复定义，能够基于 Apache Doris 全部写入新建的 Rollup 视图中并利用GROUP BY将维度传入视图进行查询加速，直接对外暴露所需数据。语义层：利用 Apache Doris 物化视图对指标与维度自定义口径，通过语义物化层进行查询加速，并将指标与维度通过 SUM 加工开发衍生标签与维度数据。应用层：利用 Apache Doris 2.0 版本的倒排索引功能，对现有的索引结构进行丰富，满足了对知识库进行模糊查询、等值查询和范围查询等场景中的能力，进一步加速指标、维度查询响应速度。</p><p></p><p>数仓架构基于 Apache Doris 迭代升级，最终实现导入实时、引擎统一、查询高效的现代化湖仓 OLAP 引擎，简化架构链路的同时，有效解决大宽表中指标重复定义所带来的问题。在架构演进的过程，我们也积累许多关于 Apache Doris 性能优化经验，希望通过分享给读者们带来一些参考。</p><p></p><h2>Apach Doris 性能优化实践</h2><p></p><p></p><h3>Colocate Join 宽表优化</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/bd/bd3fab4281d7addc8c0d9e52a3e80f39.jpeg\" /></p><p></p><p>在上文架构改造中我们提及，由于宽表开发会不断叠加字符数据，消耗存储空间，降低查询性能，因此我们充分利用了 Colocate Join 功能对宽表拆分、本地关联查询加速进行优化，具体过程如下：</p><p></p><p>指标大宽表：采用 Apache Doris 的 Aggregate Key 模型，使用增量的方式将数据覆盖写入；缓慢维度表：主要通过 start_date 和end_date的设置进行表建设，同时利用 end_date 进行分区，当我们需要查询最新的维度数据时只需要将 end_date 设置为 ‘9999-12-31’ 即可。此外我们引用 Doris 2.0 版本中的写时合并，利用 Unique Key 模型进行维度数据聚合，使查询性能在该场景中得到很大的提升。对外访问视图：在指标与维度表建设完成之后，利用 CREAT VIEW 提供统一对外访问视图，同时添加 end_date 条件，使视图保持最新数据的展示。通过这样的方式不仅能够大幅度降低查询的复杂性，还能够充分利用 Doris 特性实现查询加速。</p><p></p><h3>Rollup 解决指标膨胀问题</h3><p></p><p>宽表拆分为指标表与维度表后，我们发现每一次视图产生都需要定义多个指标，出现指标膨胀的情况。以“歌曲播放量结算”为例，当仅定义单一指标时，我们需要将各个平台 + 各类内容进行排列组合，使语义层定义很多指标数据，造成指标数量过多。此外这些指标都需要通过离线生产任务进行加工，并通过 Hive 导入至 Apache Doris 中，造成链路较长、加工维护比较困难。</p><p></p><p></p><blockquote>平台指标：覆盖四大音乐平台，包括酷我、QQ 音乐、酷狗、K 歌内容指标：包含歌曲、歌手、专辑以及厂牌等数据</blockquote><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ea/eac947d54b0095df842f936a67792d32.jpeg\" /></p><p></p><p>为了有效解决指标膨胀问题，我们引入了 Doris Rollup 功能。如图所示，在 Doris Base 表数据基础之上，可以根据指定维度来创建任意多个 Rollup 视图并自动进行GROUP BY，实现各个平台与各类内容指标定义不重复、查询性能提升的目标。</p><p></p><h3>物化视图实现查询加速</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/06/06728fde804a3b45f38ec42c4894a4af.jpeg\" /></p><p></p><p>除了减少指标数量外，我们还希望能够衍生指标并且做到查询加速。在 Apache Doris 2.0 版本中我们采用了物化视图功能进行衍生指标的开发。目前，我们主要在单一维度表中单独地去查询自定义标签与维度，在定义复杂口径后自动的通过语义层物化任务。</p><p></p><p>如上图所示我们将指标 M1 、M2、M3 与维度 T1、T2、T3 分别进行定义，并通过  SUM  加工衍生标签，在加工完成之后创建物化视图加速查询。此外，在 Doris 后续 2.1 版本中还会支持多表创建物化视图，我们也非常期待使用该功能。</p><p></p><h2>Apach Doris 导入性能调优实践</h2><p></p><p></p><p>目前，腾讯音乐具有 90+ 数据来源表、 3000 + 维度和指标、导入数据量达到千亿级别，我们希望数仓能够支持大规模数据快速导入，且导入过程中保证数据写入的准确性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/12/12bfd92cd2a10f60da70dce25cd7ea63.jpeg\" /></p><p></p><p>导入链路如图所示，主要分为离线与实时两个部分，离线链路中指标表与变更维度表通过 Spark 进行批量导入，两类表利用 Flink 聚合形成宽表后写入；实时链路主要利用 Kafak 消息队列进行流式写入。最终，离线与实时两条链路利用 Flink  实时写入 Apache Doris 数仓中。</p><p></p><p>由于 Flink 聚合为攒批写入，如果出现写入任务失败，会导致数据丢失；同时，在聚合任务过多、字段过多的情况下存在 Compaction 不及时的情况，导致实时能力不可控；此外在加工宽表的过程中，也会造成重复写入的问题，无法保证数据写入准确性。</p><p></p><p>在 Apache Doris 2.0 版本发布后，我们引入了其全新功能 Flink Doris Connector 与 Doris Compaction，有效解决了 Flink 聚合引起的问题。</p><p></p><h3>Flink Doris Connector 实现快写入</h3><p></p><p>Flink Doris Connector 主要是依赖 Checkpoint 机制进行流式写入，同时该功能默认开启两阶段提交，保证写入过程中 Exactly Once 语义。值得注意的是，我们在引入最新版的 Flink Doris Connector 功能后，实现了从关系型数据库到 Apache Doris 的一键整库同步，承载了我们实际业务中千亿级别的实时并行写入，满足数据快写入与不丢不重的需求。</p><p></p><h3>Doris Compaction 保证写入稳定性</h3><p></p><p>为了解决 Flink 聚合引起的偶发性 Compaction 不及时问题，我们引入最新版的 Vertical Compaction 与 Segment Compaction 功能。</p><p></p><p>Vertical Compaction 功能优势： 在单次合并过程中，我们不需要再将所有的列读出，只需要加载部份列数据即可，这能极大减少合并过程中的内存占用问题，提高压缩的执行速度，实现在大宽表场景下的部份数据合并。Segment Compaction 功能优势： 在单批次大数据量的导入场景下可以有效减少 Flink 写入过程中产生的 Segment 数量，且能够使合并和导入两个过程并行，避免增加导入时间。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/46/466cfe3127b16b3f2fb54a3cba5d46b7.jpeg\" /></p><p></p><p>如上图所示在引入 Doris Compation 功能后，在写入量增加 50 % 的情况下，Compaction Score 从平均 650 分降低至 80 分，技术人员不再需要担心夜间出现告警的情况，保证了整体链路的稳定性。</p><p></p><h2>总结收益与展望</h2><p></p><p></p><p>在引入 Apache Doris 后，数据架构围绕降本增效的目标，不仅在写查方面的性能得到大幅度提升，并且有效减少架构成本与资源开销，具体的收益如下：</p><p></p><p>极速查询分析： 通过 Apache Doris 的 Rollup、物化视图、倒排索引功能，由原来的分钟级查询时间达到现如今秒级毫秒级；导入性能提升： 导入优化完成后，原本 3000+ 维度、指标数据的导入时间需要超过一天，现如今能够在 8 小时内完成导入，导入时间缩短至原来的 1/3，实现快速导入需求；更重要的是，Apache Doris 在保证数据快写入的同时，使数据能够不丢不重、准确写入；链路极简与统一： Apache Doris 将查询与分析出口引擎统一，去除 Elasticsearch 集群使架构链路极简；存储成本降低： 通过大宽表拆分的方式，使存储成本降低 30%，开发成本降低 40% 。</p><p></p><p>在未来，我们将进一步拓展使用 Apache Doris 湖仓一体功能，对 Hive、MySQL、数据湖等多源异构数据库进行网关统一，实现真正意义上的实时统一分析引擎。同时，尝试 CCR 跨集群数据同步功能，通过用户多集群的数据库表自动同步以提升在线服务数据的可用性。未来，我们也将在测试环节中验证读写负载分离以及多机房备份的性能效果。</p><p></p><p>目前，Apache Doris 社区已经公布了后续版本中将推出的存算分离全新架构，能够利用低成本的共享存储系统简化上层计算节点的复杂度，使架构带来巨大的成本经济优势。我们也希望能够进一步探索，基于 Apache Doris 本地高速缓存 + 共享存储系统的混合模式，在保障性能的同时降低系统存储开销。</p>",
    "publish_time": "2023-09-08 11:10:31",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "HBlock实战 深挖独创存储技术亮点",
    "url": "https://www.infoq.cn/article/491wZbTFvRAuoxvo4N0q",
    "summary": "<p>企业对于“数据驱动”这个词都不陌生，也都深知数据对于业务发展的重要影响。然而，如何保障传输数据的安全? 如何避免意外场景下的数据丢失? 如何合理利用老旧服务器? 如何实现高效运维，有效节约人力和时间成本…</p>\n<p>是否存在一款存储产品能同时满足，使用者对成本、性能和安全的考量呢？天翼云重磅推出的存储资源盘活系统 HBlock，或许可以满足你的所有期待！</p>\n<p>InfoQ 联合天翼云策划了主题为《存储难题新解法，揭秘极致易用的 HBlock》的线上技术分享会，本期为第二期直播回放——《 HBlock实战，深挖独创存储技术亮点》。</p>",
    "publish_time": "2023-09-08 11:19:44",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AuxBridge CEO Michael Girel 确认出席 FCon ，分享新时代下以色列在金融转型创新上的探索",
    "url": "https://www.infoq.cn/article/bLwTqslvCuRdUirst9rK",
    "summary": "<p><a href=\"https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle\">FCon 全球金融科技大会</a>\"，将于 11 月在上海召开。AuxBridge&nbsp;CEO&nbsp;Michael&nbsp;Girel&nbsp;将发表题为《&nbsp;<a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5496?utm_source=infoqweb&amp;utm_medium=article\">Israeli&nbsp;Innovation:&nbsp;Transforming&nbsp;Financial&nbsp;Society&nbsp;in&nbsp;the&nbsp;Modern&nbsp;Age</a>\"》主题分享，介绍以色列现在的真实经验以及过去 5 年在数字金融领域所做的改变，以及当今以色列金融现实的各个方面，例如数字银行、金融数据安全和数字投资（风险基金）。</p><p></p><p><a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5496?utm_source=infoqweb&amp;utm_medium=article\">Michael Girel（迈克尔·吉雷尔）</a>\"是以色列的主要企业家，AuxBridge 的创始人兼首席执行官。 Michael 在美国、以色列和欧洲高科技管理和多项目方面拥有 20 多年的成功经验，并在世界各地实施复杂项目，其主要合作伙伴是美国国务院，以色列商业发展部，世界货币基金组织，世界发展银行和等等。他是以色列商业发展部的顾问，以色列企业家协会的成员。他在本次会议的演讲内容如下：</p><p></p><p>演讲：Israeli Innovation: Transforming Financial Society in the Modern Age</p><p></p><p>呈现以色列现在的真实经验以及过去 5 年在数字金融领域所做的改变。作为一个在包括金融领域在内的所有生活领域创新成分排名最高的国家，以色列凭借在技术和组织领域的一系列创新，使其金融领域变得安全、可靠和高度技术化。</p><p></p><p>还将介绍当今以色列金融现实的各个方面，例如数字银行、金融数据安全和数字投资（风险基金）。会从金融部门竞争的角度介绍现代以色列金融部门与初创企业之间通过风险投资基金的合作模式，以及投资者在这种情况下可以获得什么好处。</p><p></p><p>由于初创企业是以色列最受欢迎的技术创新工作形式，因此初创企业投资和融资也是人们感兴趣的领域。</p><p></p><p>演讲提纲：</p><p></p><p>以色列是一个具有创业思维的国家金融初创企业及其在以色列金融领域的作用是什么让以色列数字金融领域既独特且安全数字金融与现实世界合作的形式和模式数字金融在以色列是如何运作的中以创业金融及数字金融合作趋势与展望</p><p></p><p>你将获得：</p><p></p><p>○ 听众将获得有关以色列金融和数字金融行业现实的最新集中信息</p><p>○ 中国和以色列是地方和州层面许多项目的合作伙伴，帮助大家了解合作的真实信息</p><p>○ 许多以色列金融初创企业已经走向全世界，有助于建立本地企业与国外企业间的合作</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle\">DevOps&nbsp;在金融企业落地实践</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle\">金融行业大模型应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle\">创新的金融科技应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle\">金融实时数据平台建设之路</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle\">金融安全风险管控</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle\">数据要素流通与数据合规</a>\"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，前 100 人可享 5 折特惠购票，咨询购票请联系：13269078023（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png\" /></p><p></p>",
    "publish_time": "2023-09-08 12:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]