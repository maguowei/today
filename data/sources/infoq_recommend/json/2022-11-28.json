[
  {
    "title": "Rust 1.65引入泛型关联类型，向高级类类型迈进了一步",
    "url": "https://www.infoq.cn/article/ULQrMu8BgYDmTCEFpHOZ",
    "summary": "<p>最新版本的Rust引入了一个功能强大的新语言特性，叫作泛型关联类型，允许开发人员为trait中的关联类型指定泛型。其他值得注意的新特性还包括let-else语句，以及对跳出标记块的支持。</p><p></p><p>经过6年的开发，泛型关联类型（GAT）可以被认为是trait类型构造函数的一种形式，可以用来定义关联类型的泛型、寿命或常量泛型。</p><p></p><p>这个特性（关联类型构造函数）解决了高级类类型最常见的用例之一，与其他形式的高级类类型多态相比，它是对类型系统的一个相对简单的扩展，并向前兼容将来可能引入的更复杂的高级类类型多态。</p><p></p><p><a href=\"https://www.infoq.cn/article/j7oW4G2WULtf8SbhGag9\">Rust</a>\"中的关联类型是定义通用trait的一种机制。例如，在下面的例子中有一个叫作Graph的trait，它的节点和边使用了两个关联类型。</p><p></p><p><code lang=\"cpp\">trait Graph {\n    type N;\n    type E;\n\n    fn has_edge(&amp;self, _: &amp;Self::N, _: &amp;Self::N) -&gt; bool;\n    fn edges(&amp;self, _: &amp;Self::N) -&gt; Vec\n}\n</code></p><p></p><p>使用关联类型提高了代码的可读性。Graph的客户端确实可以使用它，而不需要每次都指定其关联的类型是什么，这对于泛型类型来说是必需的。例如：</p><p><code lang=\"cpp\">fn distance(graph: &amp;G, start: &amp;G::N, end: &amp;G::N) -&gt; i32 { ... }</code></p><p></p><p>现在，GTA引入了一种方法来指定本身就是泛型的关联类型。例如：</p><p></p><p><code lang=\"cpp\">trait LendingIterator {\n    type Item&lt;'a&gt; where Self: 'a;\n\n    fn next&lt;'a&gt;(&amp;'a mut self) -&gt; Option<'a>&gt;;\n}<'a></code></p><p></p><p>将其与标准Iterator的定义进行比较：</p><p><code lang=\"cpp\">pub trait Iterator {\n    type Item;\n    ...\n    fn next(&amp;mut self) -&gt; Option\n    ...\n}</code></p><p></p><p>如你所见，LendingIterator使用Item&lt;'a&gt;而不是非泛型的Item相关类型，并将Self约束为类型'a。这意味着next函数将返回一个从self借用的项。</p><p></p><p>虽然乍一看有些神秘，但GAT是一个非常强大的抽象概念，许多crate已经在不稳定版本中使用了它。此外，由于GAT还不稳定，许多crate的进一步开发被阻塞。可以使用GAT构建的一些特性包括：用于从DB加载数据的零拷贝接口、通用构建模式、表示非拥有值等等。值得注意的是，在某些情况下，GAT被不安全的代码替代，并且GAT可以减少对不安全代码的使用，对于这些情况，Rust不再提供任何安全性保证。</p><p></p><p>如前所述，GAT并不是Rust 1.65唯一值得注意的新特性。特别值得一提的还有新的let-else语句和使用break跳出代码块。</p><p></p><p>let-else语句是let的扩展，它试图匹配模式，并在找不到匹配时提供要执行的else块，例如从函数中提前返回或panic。</p><p></p><p>由于循环块支持任意时候跳出循环，标记的break让已经使用只执行一次的loop块来实现的行为变得更完整了。现在，你还可以标记一个块，然后使用break &lt;块标记&gt;语句跳转到这个标记块的末尾。</p><p></p><p>如果你对Rust 1.65的详细变更感兴趣，请查看官方发布说明。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/11/rust-generic-associated-types/\">https://www.infoq.com/news/2022/11/rust-generic-associated-types/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/wdRX0deAbrI0yl8R4OsC\">前端又开撕了：用Rust写的Turbopack，比Vite快10倍？</a>\"</p><p><a href=\"https://www.infoq.cn/article/RgA0yves4Q1FHI9dJlry\">微软首席工程师Nick Cameron：Rust要想取得更大的成功，需要解决这十大挑战</a>\"</p>",
    "publish_time": "2022-11-28 09:29:09",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从博士论文到被各大厂应用，Alluxio 如何走过7年创业路",
    "url": "https://www.infoq.cn/article/RW9VBsZDdBNtIAKPrGzf",
    "summary": "<p>今年2月，<a href=\"https://www.infoq.cn/article/zCdZAZp3xcFPtP2T4Md0\">Alluxio </a>\"宣布以实现收入同比增长 3 倍的成绩结束了2022财年。“这个财年的业绩进一步表明了市场需要更好的方法来访问大规模分析和 AI/ML 应用程序中的数据，尤其是在分布式混合云和多云环境中。”Alluxio 创始人兼CEO 李浩源表示。</p><p>&nbsp;</p><p>事实上，从当初一个论文项目到如今被市值最大的十家公司中的七家使用，李浩源用了九年的时间。那么，Alluxio 这样一个基础软件领域的创企，是如何从零成长至取得如今成绩？Alluxio 又会如何应对当前动荡的市场呢？</p><p>&nbsp;</p><p></p><h2>起步：另辟蹊径的数据架构</h2><p></p><p>&nbsp;</p><p>2000年初期，大数据伴随着互联网的蓬勃发展应运而生，从而衍生出整个数据科技的发展。从宏观角度看，数据科技可以分成两层：上层的计算和下层的存储。一直以来，存储占据了整个数据生命周期的绝大部分。</p><p>&nbsp;</p><p>2013年，北大毕业后来到伯克利攻读博士学位的李浩源在准备毕业论文时，自然而然地想要做存储相关的选题。但在调研了存储行业的发展历程后，李浩源发现，这个行业每5～10年就会发生一次革新，新产品取代上一代产品。同时，存储市场极其分散，没有一家企业的市场份额能占到25%以上，也没有一款产品的数据存储量能占整个全球数据量的5%以上。</p><p>&nbsp;</p><p>有鉴于此，在存储领域做到改变行业的颠覆性创新，在可预见的未来几乎是不可能的。”李浩源说道，“但是，我们可以把存储里面的数据管理好，让这些数据更好地来服务上层数据应用，从而提高整个社会效率。”</p><p>&nbsp;</p><p>带着这个想法，李浩源提出了一种新的架构，即将虚拟分布式文件系统（Virtual Distibuted File Syestem）作为计算层和存储层之间的新层，为上层 Spark、Presto、Tensorflow、Pytorch 等计算框架提供服务。</p><p>&nbsp;</p><p>这就是李浩源的博士论文《虚拟分布式文件系统》研究的主题。这个项目在当时被称为 Tachyon，也是如今 Alluxio 的前身。</p><p>&nbsp;</p><p>伯克利大学一直有<a href=\"https://www.infoq.cn/topic/opensource\">开源</a>\"的传统，李浩源顺应了这一传统，在第一时间将这个项目开源。开源后，李浩源发现整个技术演进路线的确在往其预想的方向发展，项目也有了越来越多的用户，收到了越来越多业界的正向反馈。</p><p>&nbsp;</p><p>不过，要想实现更宏大的愿景就需要更加体系化的公司化运营，因此，2015年，李浩源选择了创业。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;</p><p>创业初期，很多事情都要李浩源亲力亲为，但最重要的还是按照规划把产品打磨到1.0版本。“我们要把代码写好，大家对代码有了反馈后去进行支持或回应，把产品打磨的越来越好。”李浩源说道。</p><p>&nbsp;</p><p>2016年，Alluxio 1.0 版本正式发布，这是首个以内存为中心的虚拟分布式存储系统，统一了数据访问的方式，在上层计算框架和底层存储系统之间搭建了桥梁。</p><p>&nbsp;</p><p>与此同时，Alluxio 开源社区也在不断发展。社区日常管理由PMC（项目管理委员会）负责。而在有了更多用户后，李浩源开始把更多时间用在与用户和开发者交流上，希望参与进来的人可以为社区做出贡献。据悉，Alluxio 目前在 GitHub 上的贡献者已超过 1,200 人，社区 Slack 频道成员接近 10,000 人。</p><p>&nbsp;</p><p></p><h2>开源助力商业化</h2><p></p><p>&nbsp;</p><p>产品逐渐成熟后，Alluxio 开始进入商业化阶段。早期没有客户时候的商业化很难，但好在Alluxio 的开源社区获得了一些行业和社区的认可，因此当这些开发者有需求的时候便会主动找到Alluxio。李浩源也很重视与潜在用户的交流，帮助解决用户具体痛点，建立信任后再进行更大的合作。这样的方式，帮助 Alluxio 完成了早期用户积累。</p><p>&nbsp;</p><p>Alluxio的商业化模型与其他开源产品差不多，都是在开源版本基础上添加商业化功能，并以付费的企业版输出，企业版根据客户使用的节点情况收取费用。</p><p>&nbsp;</p><p>据悉，&nbsp;Alluxio企业版在全球市场客单价从几十万美元到数百万美元规模不等，客户多集中在科技、金融、电信等行业。李浩源此前表示，Alluxio 90%的客户都是全球五百强，产品已经得到很好的市场验证。</p><p>&nbsp;</p><p>随着企业的发展，李浩源开始将精力放在为公司的整体发展和方向做出决策，以确保制定最为有效的战略，让公司成长为一家全球领先的企业。</p><p>&nbsp;</p><p>实际上，自 Alluxio 创立以来，数据生态系统发生了巨大的变化，越来越多的企业开始上云。与在传统数据仓库中提供托管分析工作不同，云中的数据服务变得更加遥远（如从 S3 传输）、孤立（如分布在多个不同的区域或存储服务中），并且通常在性能上存在很大差异。</p><p>&nbsp;</p><p>为此，在2019年的纽约AWS 峰会上，Alluxio 发布了大版本2.0，针对多云增加了多项功能，包括支持跨本地和任意数量云进行自动数据分层等，还为云计算优化数据访问、与 AWS Elastic Map Reduce (EMR) 服务集成等。</p><p>&nbsp;</p><p>而最近发布的<a href=\"https://xie.infoq.cn/article/1add84ca9a4750f34e2e60fbc\">2.9版本</a>\"增加了跨环境集群同步功能，支持横向扩展的多租户架构，显著改进在Kubernetes上部署的工具集和指南，增强Alluxio的易管理性，并通过优化S3 API 和 POSIX API 实现安全性和性能提升。</p><p>&nbsp;</p><p>如今，全球头部互联网企业Facebook、Airbnb、Uber、阿里巴巴、腾讯和字节跳动等已经在生产环境里部署了 Alluxio 的软件系统；全球前六名的云厂商中有五家云厂商已经嵌入了 Alluxio 的技术；全球前两名的芯片厂商英特尔、英伟达也在使用&nbsp;Alluxio。</p><p>&nbsp;</p><p>同时，Alluxio 也正在全球扩大目标市场规模和研发运营覆盖范围，其中包括大力拓展国内市场业务，将北京设立为中国区总部，并成立本地化的研发团队。今年9月，Alluxio 还与北京大学计算机学院签署产学研合作框架协议。</p><p>&nbsp;</p><p></p><h2>如何“过冬”</h2><p></p><p>&nbsp;</p><p>作为创业公司，Alluxio 在科研方面一直在进行大量投入，员工人数相比之前也实现了三倍增长，并且还在进一步扩大公司执行管理团队等。这些投入的背后主要来自Alluxio自身快速增长的营收和投资人的支持。</p><p>&nbsp;</p><p>一方面，Alluxio在前年营收实现了同比3.5倍的增长，去年实现3倍增长。另一方面，Alluxio一步步兑现甚至超额完成预期也得到了投资人坚定支持，比如 a16z 一直在加磅 Alluxio。</p><p>&nbsp;</p><p>不过当前受疫情影响，资本进入“寒冬”，全球企业都在面临着一场生死“大考”，Alluxio 也不例外。对此，李浩源的应对之道就是“练内功”。</p><p>&nbsp;</p><p>“在市场动荡的情况下，企业更多还是要做好核心根基。正所谓‘集中力量练内功’，本质上就是把核心产品做得更好，为你的核心客户带来更多的价值，让已有客户更满意，在此基础之上再扩张。”李浩源补充道，“这也是Alluxio 一直以来的发展策略。”</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>结束语</h2><p></p><p>&nbsp;</p><p>未来，Alluxio 将继续加强对大规模数据分析、人工智能技术的支持，通过加强与 Kubernetes&nbsp; 的整合等方式，优化用户使用体验。而对于其进一步深入扩展全球市场能做出什么样的成绩，李浩源很有信心。</p><p>&nbsp;</p><p>“兵来将挡，水来土掩，面对未来的种种困难，只要一一处理就好了。”李浩源说道。</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2022-11-28 11:48:20",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "奈雪的茶：一杯奶茶中的数字化“秘密”",
    "url": "https://www.infoq.cn/article/VNTgMY30plY1K5o7jAcN",
    "summary": "<p>奶茶圈究竟有多“卷”？有数据统计，截止 2021 年，全国的奶茶店数量已经超过 40 万家。消费者的选择越来越多，行业的竞争压力越来越大，比起以价格取胜，稳定的口感、服务和供应链变成茶饮品牌间竞争更重要的砝码。</p><p></p><p>拿一杯奶茶来说，里面有水果、茶叶、鲜奶、配料等各种不同的食材，消费者在购买时，对甜度、温度、配料比等又有完全不同的需求。如果全靠店员手工制作，即便是出自同一家店，口感也很难保持稳定，更别提做到全国统一。</p><p></p><p>在这背后，<a href=\"https://www.infoq.cn/theme/161\">供应链</a>\"的稳定性同样重要。试想这样一个场景，奶茶店力推新品，却因为备料不足很快售罄——对门店来说，这会使得新品的推广效果难以评估；对消费者来说，满心期待却悻悻而归，消费体验就会大打折扣。</p><p></p><p>在最新一期的 InfoQ《超级连麦. 数智大脑》中，<a href=\"https://www.naixue.com/\">奈雪的茶</a>\"技术中心高级总监李道兵表示，过去，门店配货主要都是由门店自己订货，其中的问题在于，店长的主观判断很容易出错，乐观的店长会囤积太多的原料，导致其他门店无货可售，马虎的店长会对同一商品的不同原料配比错误，导致原料在门店呆滞报废。整体来看，都浪费了大量的销售机会。</p><p></p><p>数字化解决的问题，不仅仅在于能比中位值的员工提供更好的决策。数字化更大的用处，是扫除连锁扩张的一个大障碍，就是<a href=\"https://time.geekbang.org/\">人才</a>\"匮乏。连锁品牌每扩张一家门店，就需要寻找同时有排班、订货、生产计划技能，以及有服务意识的管理组，而且还必须在当地，这个难度很大。而奈雪的茶的数字化目标，就是解决掉排班、订货和生产计划的问题，在连锁扩张中只需要找到有服务意识的人，这就大幅度降低了难度。</p><p></p><p>除此之外，门店店员的培训成本，也是连锁餐饮经营面临的核心挑战。通常来说，把一个新员工培养成熟练工，至少需要 1-2 个月时间，其中不少时间还是脱产培训。但是，数据统计，餐饮门店员工在职平均时长只有 1 年左右，脱产培训成本不低，而且新员工的出品品质还不稳定。</p><p></p><p>因此，奈雪的茶自 2018 年开始布局<a href=\"https://xie.infoq.cn/article/b05f695fc335f6498582ed0f5\">数字化转型</a>\"。一方面，是为了剔除人为的不稳定因素，保持商品品质、服务和供应链的稳定性、可靠性；另一方面，也是为了降低对人的强依赖，降低门店运营成本，同时把人力解放出来，为消费者提供更优质的服务。</p><p></p><p>具体来说，奈雪的茶在前端门店配置了自主研发的自动和半自动化制茶设备，从煮茶到加料，人与机器协作一气呵成，实现了流程的标准化、自动化；在后端，通过自研的数字运营系统，可以做到自动订货，从公司全局视角进行统一调配，实现物料供应的精准化，降低销售机会损失，以及库存资金占用。</p><p></p><p></p><blockquote>本期 InfoQ《超级连麦. 数智大脑》，由奈雪的茶技术中心高级总监李道兵，对话极客邦科技创始人兼 CEO 霍太稳（Kevin），和 InfoQ 极客传媒数字化主编高玉娴，一起探讨奈雪的茶一杯奶茶中的数字化“秘密”。内容有删减，感兴趣的同学可进入“霍太稳视频号”或“InfoQ 视频号”观看直播回放。  </blockquote><p></p><p></p><h2>用 AI 在门店管理中减少人为失误，提升人效</h2><p></p><p></p><h4>问：2018 年奈雪开始布局数字化转型战略，促使我们去做数字化的动因是什么？</h4><p></p><p></p><p>李道兵：归根结底，是餐饮连锁业为什么需要数字化？过去大家并不太关注这件事，直到用户运营变得越来越重要，餐饮门店的营业额开始大幅受到用户复购的影响。比如一个门店，品牌有了，所在地区的用户群也有了，能否触发用户的购买欲，让他想起来去买一杯奶茶，就成为了提升营业额的关键。</p><p></p><p>商品品质的提升、价格的设定都是过去商家本身比较擅长的。但是，就触发购买欲这一点，没有用户运营、用户体系，几乎做不到。这就是促使越来越多的连锁品牌进行数字化转型的重要原因。</p><p></p><p>当然，除了用户运营之外，餐饮连锁的日常运营还有很多地方需要数字化手段去做支持。比如，门店如何去扩张？如果只有 5 家、10 家门店，老板自己盯着就可以了；如果有 20-30 家门店，找几个得力店长可能也够了；但是，当门店达到数百家，就需要利用数字化的手段解决管理的问题。</p><p></p><h4>问：今年奈雪的门店总数已经超过 900 家，我们在门店经营管理过程中，遇到的核心痛点有哪些？</h4><p></p><p></p><p>李道兵：首先，还是门店扩张的问题。和自动贩卖机这种轻量级的运营模式不同，门店的迁移、扩张是非常重成本的。比如，好的店铺位置往往非常稀缺，很多时候可能要等半年到一年才有空缺，这是时间成本。而等到店铺位置之后，还要装修、配置设备、招聘员工、进行员工培训等等，其中的前期投入成本非常高。</p><p></p><p>其次，是门店管理的问题。门店管理组的能力，往往决定了一个门店运营的好坏。而随着门店扩张，比如当一个企业开了 300 家店，其实很难找到 300 个合适的店长，并且这些店长还必须跟城市、区域去匹配。我们不可能在三线城市开一家店，还要从一线城市调一个店长过去，店长的薪资水平还没有达到能让一个店长举家搬迁的吸引力。</p><p></p><p>第三，是门店店员培训成本的问题。对于很多餐饮企业来说，每个店员的平均在职时间并不长，差不多一年就要轮换一次，甚至更多，假设一个店员在店里只工作了 12 个月，培训就要用 1-2 个月的时间，其中的培训成本就是非常高的。</p><p></p><h4>问：这些问题怎么用数字化的办法解决？</h4><p></p><p></p><p>李道兵：对于奈雪的茶来说，数字化要解决的第一个问题就是怎么降低门店对店长个人能力的要求，第二个问题是降低店员培训的成本。</p><p></p><p>尤其是对店长来说，理想的状态是，假如他没有那么高的技术水平、管理水平，也能当好店长。举个例子，店长的一个重要职责就是排班，通过评估一段时间内的营业额，匹配对应的人手规模，以及这些人手分别需要在什么时间段上下班。一方面是确保效率，另一方面还要避免工时浪费。</p><p></p><p>除此之外，店长另一个重要工作就是订货。如果货定少了很快就会售罄，消费体验不好；如果货定多了，仓库肯定放不下，会造成非必要的库存。拿奈雪的茶来说，我们不但卖茶饮，还卖面包，面包几乎每天只出炉一次，售卖的数量是有限的。所以，每种面包每天应该做几个，店长心里要有数，不能等到发现当天卖得好再想着要货。这就是我们在门店经营中遇到的实实在在的挑战。</p><p></p><p>现在，对我们来说，最重要的技术手段就是 <a href=\"https://www.infoq.cn/news/VitTKb0zLljDj4QTPMpw\">AI</a>\"。最近几年，AI 就像是一个“榔头”，它能够把我们所找到的所有“钉子”都试着敲一遍。尽管不是在每个领域都能起到作用，但在能起到作用的领域效果还是很明显的。</p><p></p><p>比如，虽然 AI 现在还很难预测某款产品会卖得好。但是，至少我们能做的就是在公司决定推某个新产品的时候，帮助门店实现物料和效率的最大化。</p><p></p><p>同样是推一个新品，不同区域的销量表现不一样，即便是同一区域的不同门店，效果可能也不完全一致。这就意味着，我们在针对新品物料做门店配送的时候，需要根据销量预测，进行相应的匹配，而不是进行均匀分布。当然，也不是直接按历史销售额做匹配，还可以做得更精细化，通过对销量本身的预测，比如，某个店周围的人群特征可能直接影响新品销量，这个门店就可以多追新，多配新品物料。</p><p></p><p>在这个过程中，所有的物料分配标准、货品的配置，都是由系统自动算出来的，而不需要店长拍脑袋决策。</p><p></p><p>霍太稳：也就是说，当餐饮连锁扩张到几百家门店之后，就面临一个问题——如何为店长赋能，通过数字化的手段，包括前后端的协同，让管理组的能力实现复制，让门店的管理经验变成“可插拔”的事情。</p><p></p><p>比如，现在很多连锁门店在做<a href=\"https://xie.infoq.cn/article/1b45e5aa434202b7817ca1aa4\">智能排班</a>\"，其实就是通过数字化计算门店店员的合理调配，包括在哪个时间段需要店员更多一些，哪个时间段需要的店员更少一些，这是技术更擅长的事情，可以节省很多的人力成本。对于备料也一样，每天预估备多少的面粉、茶叶、水果等等，如果都能够用算法相对比较精准地计算出来，那门店就能做到更精细化的管理，而且能大大减少对店长能力的依赖。</p><p></p><h4>问：在这个过程中，人机协同的效果怎么最大化？</h4><p></p><p></p><p>李道兵：AI对人的价值主要体现在错误操作预警、行为修正，帮助员工提升工作效率和能动性。</p><p></p><p>首先，AI 可以及时发现员工犯错，或者可能犯错的情况。如果机器判断一个员工肯定犯错，就可以直接阻止他的相关行为；如果判断员工可能犯错，就可以进行预先提醒，给出再次确认的指令，或者增加审批流程，从而防止出错概率。</p><p></p><p>其次，AI 还可以帮助提升员工效率。其中的关键就在于，找到低效的环节。盘点、收货、生产各种场景下都需要人来产生数据，而人产生数据的环节就是一个错误产生点，就需要做管控。而要提升门店的人效管理，一般就可以靠智能排班系统来解决。</p><p></p><h2>避免供应浪费，降低物料损耗率</h2><p></p><p></p><h4>问：除了门店管理的精细化，奈雪的后端供应链又是如何通过数字化支持门店更准确地制定生产和销售计划的？</h4><p></p><p></p><p>李道兵：对于连锁餐饮来说，供应链端如果出现问题，主要表现是配货不均衡。过去，门店配货的做法是由门店自己订货，这里面的问题是，店长的主观判断可能出错。比如，他们觉得接下来某个产品会卖得很好，订货数量就会增加，囤了一堆货品之后，最后却卖不出去；还有另一个问题，有的店长比较马虎，某个产品的两种原料的配比是 1:5，最后他按 1:10 配货，造成大量的浪费。</p><p></p><p>所以，我们通过供应链的数字化，主要目的是做物料端的主动配货。由于公司层面拥有全局视角，就可以从全局去做评估，经过系统去计算，给出决策建议，好处就是确保我们给某个门店定的货，恰好是他们需要的，避免不必要的浪费。</p><p></p><h4>问：除此之外，成品、半成品等物料本身的损耗率如何通过技术手段降低？</h4><p></p><p></p><p>李道兵：首先，一定要找出造成损耗的原因，针对性地解决。当然，这里面有一个前提，就是<a href=\"https://xie.infoq.cn/article/fea9b5681189605423bad1f08\">数据</a>\"一定要准确，如果数据不准或者有误差，损耗率达总指标是无法分解下去的。只有数据准了，才能找到具体在哪个环节造成了损耗，才能去改流程。</p><p></p><p>举例来说，分析后发现，是因为预测不精准，导致半成本生产多了，最后用不掉，又不能过夜，只能报损。那么，需要优化的就是预测流程。对于门店来说，数据需要精确到各个细节，比如，究竟是在下班前半小时还是一小时不煮最后一缸茶了，这些细节都要规范下来。并且，对于不同物料，规范是不一样的，没有很通用的标准。这就要求我们在数字化流程上把数据做扎实，才能去很好的去洞见问题。</p><p></p><h4>问：如何判断哪些数据是否有用？</h4><p></p><p></p><p>李道兵：判断数据是否有用，最简单方法就是回测。举个例子，某个产品在门店的售卖，一般第一天的物料供应都是充足的，所以第一天的数据是比较完整、真实的。第一步我们可以对比某个产品推出后，在不同门店第一天的销量差异，并且从中找到规律，把后续的数据放到算法模型中，持续验证。</p><p></p><p>当然，即便是因为物料不足，产品在第一天售罄了，也是有数据可用的。因为系统可以掌握某个产品在某个时间段的销售趋势，并且把它还原出来——用来测算当物料供应充足的情况下，究竟能卖多少。在这基础上，还可以分析当天供给不足的原因，用于后续的防范。</p><p></p><p>也就是说，当所有流程都实现了数字化，那么，数据就是现成的，只不过需要我们一次次去回测，找到可用的数据，同时持续优化相关的<a href=\"https://xie.infoq.cn/article/7572e279a6358b587cafbcfda\">算法</a>\"。我们不能要求所有预测都会百分百准确，最开始的算法可以做得很简单，只要它的得分是正分，比常规表现下的 80% 做得更好，那就值得推广。接下来，主要工作就是去做优化，让它比 95%、99% 的情况做得更好。这样门店的运营能力就会不断提升。</p><p></p><h2>技术不是万能的，数据准确性很重要</h2><p></p><p></p><h4>问：从前端运营到后端管理，数字化的落地，给奈雪的业务带来了哪些具体的优化和改善？</h4><p></p><p></p><p>李道兵：第一，是在做业务优化和改进的时候，可以快速去落地和试错。在没有数字化的时候，很多问题没有办法清晰呈现，因为缺少数据去做支撑。而有了数字化手段，就可以清晰定位问题，并且校验解决办法的可执行性，加快产品、流程的迭代速度。</p><p></p><p>第二，是提高门店的运营效率。拿自动制茶机为例，它非常依赖于后面一整套数字化体系的运作，具体来说可以解决我们说的门店管理组的培训问题，降低培训成本，减少店员出错的概率。过去很多人要熬夜背配方，现在不需要了，只要点一个按钮，一杯茶就做好了。</p><p></p><p>第三，是运营成本的降低。最直观的表现，就是今年奈雪的茶的产品，从以前平均 25-28 的价格，降到了 20 元以下。这背后就是因为我们通过数字化不断地优化成本，为降价留出了足够的空间。</p><p></p><p>其中，对我个人来说，感受最大的是 PDCA 循环的优化（Plan（计划）、Do（执行）、Check（检查）、Act（处理））。你要怎么发现问题？怎么才能决策？怎么让决策落地？没有数字化，很多事情是走不动的。特别是在疫情这样的大背景下，如何让企业的营运模式有<a href=\"https://www.infoq.cn/article/z9DfpZCh0femWpQ6awVp\">韧性</a>\"，当冲击来临的时候，成本能够快速降下来，这很关键。</p><p></p><h4>问：在奈雪推进数字化的过程中，遇到了什么让您印象深刻的挑战？我们又是如何克服的？</h4><p></p><p></p><p>李道兵：最大的挑战是数据准确性的问题。餐饮行业和互联网行业不一样，互联网行业的数据都是按照比较严格的流程产生的，所以数据质量比较高。但餐饮行业不同，其中有很多不可控因素。最开始我们还是过于理想化，没有意识到“凡是有人参与的地方，就会有错误”，最后导致了一些<a href=\"https://xie.infoq.cn/article/6cadb8669646d839423aa1f32\">数据质量</a>\"的问题。</p><p></p><p>在发现这个问题之后，我们开始用比较系统的方法规范员工的操作，用体系化的方法贯彻下去，在任何与人打交道，需要人去输入数据的节点，尽量实现流程标准化，操作自动化，降低对人本身的依赖。</p><p></p><p>有一点特别重要，就是关键流程都要在线上，并且一定要有一个数据池，能够把所有数据都汇集在一起。在这基础上，要有 BI 分析平台，平台还要持续监测对业务有较大影响的关键数据，持续不断地去改去优化，打磨质量管理的 PDCA 循环。</p><p></p><p>在具体的落地过程中，要擅用头脑风暴发现业务运营中的问题，定义好这些问题，并且提出改进项。换句话说，所有的架构都要围绕业务展开，形成一个持续向上优化的闭环。</p><p></p><h4>问：所以技术不是万能的，数字化的顺利推进，还需要配套的组织流程的保障？</h4><p></p><p></p><p>李道兵：是的，比如前面说的，对店长来说，可以根据 AI 给出的信息去做决策。但这个决策究竟好不好，后面我们还有一些相关的手段去追踪和闭环。我们会先拿一定数量的对照组出来做比较，比如，其中十家使用新决策新办法进行运营，其中十家保留原来的运营办法，通过比较这些门店平均数据表现，如果前者表现更好，那就继续扩大试行门店数量，通过一轮一轮的比较优化把事情做好。</p><p></p><p>在这个过程中，系统最大的好处就是提供一个闭环持续提升的方法，我们只要持续比较，就会发现 AI 在哪些地方做好了，哪些地方做砸了，做砸了的原因是什么？是少考虑了什么因素？下次能不能补齐？比如，不同区域的消费者对天气这个因素的敏感度是不一样的，同样是下雨天，不同城市的人的选择行为其实是不一样的。所以，不能用同一套逻辑套用，一定要知道里面的差别，知道 AI 出差错的地方在哪，然后才能不断迭代，系统得分才能越来越高，算法模型才能越来越精准。直到所有门店的经营状况都被优化，那这个系统和模型就自然而然被推行下去了。</p><p></p><h2>技术人也要下一线，要持续学习</h2><p></p><p></p><h4>问：奈雪的茶很早就非常重视技术研发，在我们培养数字化人才的过程中，有什么成功的经验？</h4><p></p><p></p><p>李道兵：我认为最重要的还是下一线，要能够跟业务摸爬滚打在一起，持续去调研，切实体会他们遇到的问题，真正体验他们的工作流程，这样才能清楚把握改进的点在哪。数字化转型的规划只是一个主导的方向，具体在执行中该往哪边走，很多落地的细节还是需要一点点跟一线需求结合起来，才能打磨得更好。</p><p></p><p>对于奈雪的茶来说，产品部门在其中会发挥比较重要的作用，他们类似于业务和技术之间的桥梁。甚至从某种角度上来讲，他要比业务更懂业务。当然也有一些企业会从业务线去提拔产品负责人，我觉得这也是个好主意。</p><p></p><p>除此之外，对于<a href=\"https://www.infoq.cn/article/wliPhHXvgVJrKIs52RYk\">人才培养</a>\"，我的另一个心得是，永远要“奖励优秀”。要让优秀的人有荣誉感，他们是团队里的一颗星，要让他们的工作方法被推广下去。</p><p></p><p>霍太稳：对于数字化人才，极客邦科技双数研究院“<a href=\"https://www.infoq.cn/minibook/WvG2KwN4tFfpjtTaxNve\">数字人才粮仓模型</a>\"”把他们分成了五层：</p><p><img src=\"https://static001.infoq.cn/resource/image/4f/c6/4fab60a222ayy7yy5716ab718084e9c6.jpg\" /></p><p>从上往下，最上面那层是数字思维管理者，一般是公司的一把手，CXO 这一人群，他们往往决定了公司到底要不要做数字化，能不能成功实现数字化；第二层是数字思维业务人才，包括销售、运营、营销、财务、市场、品牌、产品设计等等；第三层是业务架构人才，他们是业务的架构师，扮演的是业务和技术连接者的角色；第四层是技术架构人才，通常横跨多个技术领域，具有技术侧的全局思维；最下面一层是专项技术人才，这部分人才需要具备两类能力，一类是软件工程能力，知道开发体系怎么运转，另一类是专项技术能力，包括人工智能、区块链、大数据等。</p><p></p><p>而我们在去给这些不同类型的人才进行培训的时候，就要给他们提供不同的技能补齐。比如，对于专项技术人才，可能要提供一些 Java、Python 之类的课程；对于业务架构人才，可能要教授他一些业务的方法论等等。所以，“数字人才粮仓模型”发布以来受到了很多关注，它分享了在数字经济方面的观察以及在数字人才发展与培养方面的研究和发现，现在很多的企业都把它作为内部人才培养的一个参考指南。</p><p></p><h4>问：您对于技术领域的人才发展有什么好的建议吗？</h4><p></p><p></p><p>李道兵：第一是长见识，首先一定要去找一些比自己阅历更高的专家进行对标，通过会议、课程等方式，让自己的见识不断提升。要知道业界都在聊什么，行业需要解决的问题是什么，有了这些方向之后，你才知道自己该去学什么。</p><p></p><p>第二是持续学习。一方面，要追求一定的知识广度，另一方面，要追求一定的知识深度。在这个过程中，很重要的一点是一定是要在产业中去学习 Know-How，只有这样，你才能透过现象，深入问题的本质，并且让自己的能力和经验变得可复制。</p><p></p><p>霍太稳：如今，我们正在从消费互联网时代迈向产业互联网时代。过去，很多 2C 企业是靠“烧钱”获得用户，获得营业增长，获得竞争力的。但是，到了产业互联网时代，你会发现这样的做法已经不适用了，背后的原因就在于，2B 领域更看重 Know-How，它需要你通过更长的时间，形成更扎实的积累，要求你必须沉浸其中，反复打磨。</p><p></p><p>如果你没有这一基础认知，还拿着消费互联网时代的“锤子”去砸产业互联网市场的“钉子”，实际上很难获得什么价值。就像抓沙子一样，越努力沙子漏的越快。</p><p></p><p>所以，目前对于很多的技术人，非常重要的就是去提升自己的认知，去改变自己固有的思维，用发展的眼光去看一看产业互联网，多去关注实体经济，看看哪些技术可以在其中发挥价值，去帮实体企业提升效率，降低成本。</p><p></p><h3>嘉宾介绍</h3><p></p><p></p><p>李道兵，奈雪的茶技术中心高级总监。先后在金山、盛大云、七牛云、京东云等公司工作。曾任盛大云资深研究员，七牛云 SVP 兼首席架构师、京东云高级总监。现主要关注连锁经营和供应链的产业互联网领域。</p><p></p><p>霍太稳，极客邦科技创始人兼 CEO，InfoQ 中国创始人，极客时间创始人，TGO 鲲鹏会发起人。2007 年创立 InfoQ 中国，2014 年创立极客邦科技，2015 年发起 TGO 鲲鹏会，2017 年创立在线职业教育学习品牌极客时间，2019 年开创极客时间企业版，拓展企业服务市场。</p>",
    "publish_time": "2022-11-28 11:49:22",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "移植到Rust，你考虑过语言的复杂性吗？",
    "url": "https://www.infoq.cn/article/zcNkbgkE7KiRtfG7fKo0",
    "summary": "<p>四年前，我曾经写过一篇题为“<a href=\"https://pointersgonewild.com/2018/02/18/minimalism-in-programming/\">编程中的极简主义</a>\"”的博客文章，文中我试图提出一个观点，说明为什么在编程项目中应该尽量减少复杂性。现在，我想写一些已经思考了很久的东西，那就是在设计编程语言的时候，我们也应该更有意识地遵循极简主义（minimalistic）哲学。</p><p></p><p>在我看来，在设计编程语言的时候，有意识地遵循极简主义是一个被严重低估的想法。大多数的现代编程语言都更多地采用了极繁主义（maximalism）的设计方式。快速增加新的特性被视为相对于其他编程语言的竞争优势。一般的想法似乎是，如果你的语言缺少某个特性，那么人们就会选择使用另外一门语言，或者说，增加更多的特性是一种展示进步的简单方式。这种想法是非常肤浅的，而且忽略了许多其他关键因素，它们是一门编程语言成功和繁荣的必要条件，如易学性（learnability）、稳定性、工具支持和性能。</p><p></p><h2>变化与流式</h2><p></p><p></p><p>我想说的是，有意将编程语言设计为具有较少的特性，并且随着时间的推移，较少发生变更，这本身就是一个强大的特性。当一门编程语言经常变化时，它必然会导致破坏和流式。工具会过时，代码库需要更新，库会损坏，而且它也会导致人员方面的流式。</p><p></p><p>我第一次开始使用C++编程是在1998年左右。我已经有几年的时间没有真正接触这种语言了，不得不说，我感到有点迷茫。现在增加了这么多的特性，它已经是一门完全不同的语言了。去年，我想在一个新项目中使用C++20，但是发现对G++和Clang的支持是如此不完整，以至于模块根本就是一个不可用的特性。我当时的总体印象是，没有足够的人从事C++编译器的工作，以保持这些编译器处于最新状态。这门语言已经变得如此复杂，而且增加了如此多的新特性，以至于编译器开发人员都已经精疲力尽了。在我看来，C++会慢慢崩溃于自己的重点，我对这一点非常肯定。</p><p></p><p>许多人忘记了，一门语言要想成功，必须要有良好工具的支持。如果语言和它的特性集不断变化，那么工具就需要不断地更新。C++的众多问题之一就是它的语法难以解析。在1998年就已经是这样了。如果在这个问题之上，每隔一两年就加入新的语法变化，使其更加复杂，那么会带来什么样的影响呢？维护C++工具的人们就会想着去做其他的事情了，使用这些工具的人同样如此。</p><p></p><h2>易学性和人的因素</h2><p></p><p></p><p>最近，我和同事们决定将一个<a href=\"https://shopify.engineering/porting-yjit-ruby-compiler-to-rust\">C语言代码库移植到Rust</a>\"。总的来说，我对Rust的核心特性集很满意，我觉得在很多方面，它都比C和C++有很大的进步。然而，在我看来，Rust的主要问题在于它的复杂性。无论是在语法还是语义方面，Rust都是很复杂的语言。语法可以变得非常冗长，有很多的东西需要了解，有很多规则和不直观的细节，比如在什么地方可以做什么，不可以做什么。它的学习曲线很陡峭，认知负荷很高。</p><p></p><p>上周，我和同事在进行结对编程的时候，他说“我觉得Rust编译器总是在告诉我，我太笨了。”这句话让我很吃惊，因为我也有相同的想法。不知为何，Rust给人的感觉是不符合人类工程学的，而该语言高度的复杂性肯定会加剧这种感觉，即该语言对用户不太友好。它打破了我们的直觉，而且感觉编译器在不断告诉你，你写的代码是错误的。在我和同事说这番话的两天后，我看到了Hacker News上一篇名为“<a href=\"https://www.bunniestudios.com/blog/?p=6375\">Rust: A Critical Retrospective</a>\"”的文章，其中对Rust的复杂性也有类似的感受。</p><p></p><p>在很多方面，我觉得如果能够将语言设计成简约的、有较少的概念并且能够选择基元（primitive）进行组合，那么这是让语言更易于学习的好办法。如果编程语言有更少的概念，那么需要学习的东西会更少，你的熟练程度也会快速提升。用更简约语言编写的代码也更易于阅读。如果思考一下C++语言的代码，我们都会有这样的场景，该语言有许多多余的特性，以至于在典型的工作场所中仅允许使用C++的子集来编写代码，有些语言特性被明令禁止。这意味着在不同场所编写C++代码的人将很难读懂对方的代码，因为别人的C++代码会使用不同的方言来编写。</p><p></p><p>在某些方面，我觉得有意将复杂性降到最低，并保持较小的特性集是尊重程序员的更好方式。这意味着我们尊重程序员，他们的生活可能会很忙，有很多事情要做，而且他们可能没有足够的时间去阅读数百页的文档来学习我们的语言。编程语言是用户接口，因此，它们应该遵守<a href=\"https://en.wikipedia.org/wiki/Principle_of_least_astonishment\">最小惊喜的原则</a>\"。尽量减少复杂性也是减少认知负荷和尊重人类局限性的一种方式。人类是能力惊人的生物，但我们基本上也只是会说话的聪明猴子而已。我们只能在工作记忆中保留有限的内容，我们只能考虑到有限的设计限制，我们只能在有限的时间内保持专注。尽管我们有人类的局限性，但一个设计良好的编程语言应该能帮助我们取得成功。</p><p></p><p>最后，我认为一门语言的复杂性和它给人的直觉会影响其吸引和保留新用户的能力。在我看来，对减少冲突的关注在很大程度上促成了Python的最初成功和快速普及。我觉得也可以这样说，当Python生态系统的复杂性增加时，许多人会感到很沮丧，例如，在从Python 2到3的转换过程中，或者当多余的<a href=\"https://pythonsimplified.com/the-most-controversial-python-walrus-operator/\">walrus操作符</a>\"被引入时。</p><p></p><h2>极简主义</h2><p></p><p></p><p>到目前为止，我已经多次提到了极简主义，也简单提到了最小惊喜原则。我已经暗示过，极简主义意味着要学习一个较小的特性集和较少的概念。不过，极简主义并不仅仅意味着较小的特性集。它还意味着仔细选择那些能无缝结合在一起的特性。如果我们设计的语言有一个很大的特性集，那么这些不同的特性就会出现组合爆炸，这意味着可能遇到一些语言特性在一起互动不良的情况。</p><p></p><p>命令式编程语言通常对语句（statement）和表达式（expression）进行语法上的区分。函数式语言则倾向于以一种结构化的方式，将函数体中的所有内容都作为一种表达式。后者更加简约，而且对程序员的约束也更少。有些语言将编译时运行的代码与程序执行时运行的代码区分开来。这种区分往往会增加语言的复杂性，因为往往会出现语言特征的重复，以及对编译器在编译时能够运行哪些代码的随意限制。</p><p>在尽量减少惊喜方面，我们要避免引入只在某些情况下出现的奇怪边缘场景。另一个需要避免的重要陷阱是引入程序员可能没有意识到的隐藏行为。这方面的一个例子是JavaScript中的相等（==）运算符，它实际上包括对字符串类型的隐性转换，这意味着1==\"1\"会被认为是true。由于这种不理想的隐藏行为，JS实际上有一个单独的严格相等运算符（===），它不执行隐藏的字符串转换。在我看来，JS只应该有一个严格的相等运算符，如果你想在执行相等比较之前将要比较的值转换为字符串，那只需要明确地写出来即可。</p><p></p><h2>实现的复杂性</h2><p></p><p></p><p>语言设计是很困难的，因为编程语言可能的空间是无限的，所以必须要做出妥协。很难提供硬性的数字来量化如何让某种设计比其他设计更好。在某种程度上可以量化的一些东西是语言的实现复杂性，以及特定语言的实现方式。</p><p></p><p>我的<a href=\"https://pointersgonewild.files.wordpress.com/2011/08/phdthesis.pdf\">博士论文</a>\"中涉及到了JavaScript ES5的JIT编译器实现。因此，我对该语言的语义以及为使JavaScript代码快速运行而必须在幕后进行的所有工作都非常熟悉。在某种程度上来说，这是一个令人沮丧的经历。我确信，JS和许多其他语言中的许多复杂性以及隐藏行为在本质上对每个人都是不利的。</p><p>一门语言中不必要的复杂性对学习这门语言的人是不利的，因为它使这门语言不直观，难以学习。这对每天与语言打交道的程序员来说是不好的，因为这增加了他们的认知负担，使他们更难沟通代码。这对语言实现者和工具维护者来说是不好的，因为这使得他们的工作更加困难，但归根到底，这对最终用户来说也是不好的，因为它导致软件会有更多的缺陷和更差的性能。</p><p></p><p>举一个不必要的实现复杂性的样例，许多面向对象的语言有这样的想法，这是从Smalltalk借鉴来的，“一切都应该是对象”，包括布尔和整数值。同时，这些语言的实现必须在幕后做大量的工作，试图有效地表示整数（作为机器整数），同时向用户展示一个类似于对象的接口。然而，呈现给用户的整数对象的抽象通常与普通的OOP对象的抽象并不一样，它是一个漏洞百出的抽象，因为从逻辑上能够重新定义整数值完全没有意义，整数值必须是单例的，能够在整数上存储属性是既愚蠢又损害性能的，所以通常不被允许。</p><p></p><p>归根结底，整数不是面向对象意义上的对象。它们是一种具有特殊含义的原子值类型。认为“一切都应该是对象”的错误想法实际上并没有在实践中简化什么。我们在欺骗自己，这实际上使语言实现者和程序员的生活都变得更加复杂。</p><p></p><h2>可行的建议</h2><p></p><p></p><p>这篇文章更多已经变成了抱怨，这超出了我的预期。批评现状是很容易的，但最终我也会尝试给出一些可操作的建议。我对有志于成为语言设计师的第一个建议是，你应该从小处着手。你的语言是一个用户接口，是一个人们用来与机器交互的API。API的面越小，引入意外复杂性和不经意设计错误的风险就越低。</p><p></p><p>我的第二个建议是，如果可以的话，应该尽量控制语言的规模。将自己限制在一个较小的特性集上，这可能意味着你要选择那些没有重叠的特性，它们能够给程序员带来最大的表现力和最大的价值。如果确实想发展你的语言，那就慢慢来吧。花一些时间在你的语言中编写代码，并研究你所做的设计改变会带来的潜在影响。</p><p></p><p>增加新的特性是很容易的，但是如果你增加了新的特性，人们开始使用它们，就很难甚至不可能收回这些特性了，所以要明智地选择。记住，你不需要取悦所有人，也不需要对每个特性请求都说“好”。没有任何一种语言或工具可以满足所有的使用场景，而且在我看来，试图这样做就是一个错误。</p><p></p><p>最后，请记住，语言设计是一门艺术。它是众多不同约束条件的微妙平衡，就像用户界面设计一样。Brainfuck是一种非常小的语言，只有很少的概念，但没有人会说它具有表现力或优雅。Lisp被许多人认为是现存的最漂亮、最优雅的语言之一，但我的博士生导师是一位Scheme（Lisp编程语言的方言之一——译者注）的狂热爱好者，他有写代码时使用单字母变量名和很少添加注释的习惯。优雅的语言不会自动产生优雅的代码，但如果你以身作则，可以鼓励实现良好的编码实践。</p>",
    "publish_time": "2022-11-28 14:18:03",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "大数据技术演进实录：云原生大数据、湖仓一体、AI for Data，未来“谁主沉浮”？",
    "url": "https://www.infoq.cn/article/p8OyeDyoRs5jZSD2lvcN",
    "summary": "<p>从大数据发展的历史长河来看，谷歌的“三驾马车”—— 《GFS》、《MapReduce》和《BigTable》，加上亚马逊的一篇关于 Dynamo 系统的论文奠定了大数据时代发展的基础。从“大数据之父”道格·卡丁创造了 Hadoop 到现在许多厂商开始单独造轮子、做开源，大数据的发展首先是获得了大规模数据的处理能力，然后再解决了数据的分析与挖掘问题，到如今又开始解决“如何实时查询数据”的问题，从近 20 年的发展中基本可以看出，这些演进的背后都是由企业需求和业务发展驱动的。</p><p></p><p>英特尔院士、大数据技术全球 CTO 戴金权曾提出，未来大数据的发展主要有三大方向：大数据平台云原生化；湖仓一体；大数据与人工智能重塑数据价值，本文将对三大方向逐一展开解读。</p><p></p><p></p><h2>一、大数据平台云原生化是必然趋势</h2><p></p><p></p><p>众所周知，大数据系统是一个复杂性很高的系统，传统的大数据系统运维成本很高，比如处理资源分配、进行容错等这些工作其实并不能对终端业务产生直接价值。然而，如今的大多企业都面临着日益增长的数据量、各种类型数据的实时化和智能化处理的需求，企业亟需降低运维成本，并希望能够通过对数据的挖掘产生支撑业务侧的洞见与预测！</p><p></p><p>于是，云原生大数据平台因为其高弹性扩展、多租户资源管理、海量存储、异构数据类型处理及低成本计算分析的特点，受到了企业的欢迎，这也是大数据系统的必然发展趋势，将大数据运行在云上，以云服务的形式提供给用户，能大大提高企业服务化能力，用户可以直接在云上进行价值挖掘。而且，当厂商通过云服务提供大数据技术后，很多新能力也变得很透明，企业无需经过摸索和集成，就可以将自己的服务无缝提供给用户。</p><p></p><p>但另外一方面，云原生大数据也有非常多的技术挑战。许多大数据系统最初并不是为云原生架构而设计的，比如开发者在做数据的 Shuffle 时，思考的是如何利用本地 IO 能力来提高效率。</p><p></p><p>企业为了能够让业务更好地运行在云的体系架构之上，当前一般采用的都是架构层的解决方案，融合了高性能计算（HPC）强大算力和云服务安全性、易用性的云原生超级计算似乎是当前最佳的有效方案。但事实上，软件层的升级多少还是会受硬件层的影响。所以，不如换个方向，思考一下如何利用硬件能力来提高数据处理效率。</p><p></p><p>厂商在硬件层提升性能的方式往往是，通过使用服务器来响应对高性能计算 (HPC) 集群的需求，通过对 CPU 升级来处理更大规模的高性能计算 (HPC) 应用。像英特尔® 至强® 可扩展处理器提供业界领先、经工作负载优化的性能，具有内置人工智能加速功能，可提供无缝性能基础，就是许多企业的选择。</p><p></p><p>应对业务侧日益增长的需求和不断演变的数据服务模式，企业可利用<a href=\"https://www.infoq.cn/article/a1rIzRu3CAsC5LXKwJ3f\">英特尔® 至强® 可扩展处理器</a>\"上集成的英特尔® 高级矢量扩展 512（英特尔® AVX-512）来继续进行工作负载优化创新。英特尔® 高级矢量扩展 512（英特尔® AVX-512）是一组指令集，可以加速工作负载和用例的性能，如科学模拟、金融分析、人工智能 (AI) / 深度学习、3D 建模和分析、图像和音频 / 视频处理、密码学和数据压缩等。英特尔® AVX-512 可以处理苛刻的计算任务，借助两个 512 位融合乘加 (FMA) 单元，应用程序在 512 位矢量内的每个时钟周期每秒可打包 32 次双精度和 64 次单精度浮点运算，以及八个 64 位和十六个 32 位整数，大大地提高了数据处理效率。</p><p></p><p></p><h2>二、“湖仓一体”是解决实时性数据问题的新兴架构</h2><p></p><p></p><p>随着人工智能等技术的兴起，数据规模越来越大，存储的数据类型也越来越丰富，与文字相比，体积更大空间的图片、声音和视频存储需求爆发。面对这些海量数据治理需求，数据仓库、数据湖架构被企业广泛应用。</p><p></p><p>当前许多人认为，面向领域主题的、集成的、稳定的、能够反映历史数据变化的数据仓库，已经满足不了 人工智能、机器学习技术的数据需求，开始逐渐走下坡路，数据治理架构正在逐渐从数据仓库跨越到数据湖。他们认为，数据湖是多结构数据的系统或存储库，以原始格式和模式存储，通常作为对象“blob”或文件存储，可以更好地解决企业数据需求，甚至有人认为数据湖就是下一代数据仓库。</p><p></p><p>事实上，大多数企业目前至少有一个或者多个数据仓库服务于各种下游应用程序，而且把所有的原始数据都放到数据湖，可能会提升数据的使用难度，对于企业数据治理来说也不是一个小的挑战；此外，从实时性方面，数据湖也做不到真正的实时。</p><p></p><p>然而，企业数据的使用场景如今已然发生巨大变化，需求从离线场景转变到实时数据分析场景。数据规模发展到一定程度后，离线数据的缺点就会愈发凸显，企业对于实时数据治理有了更高的要求，希望从业务端获取到数据后，能够立即被清洗处理，从而满足基于数据的挖掘、预测和分析。</p><p></p><p>所以“湖仓一体”作为一种新兴架构，结合了数据仓库与数据湖的优点，在类似数据湖的低成本存储上，实现了与数据仓库中类似的数据结构和数据管理功能，在扩展性、事务性以及灵活度上都体现出了独有的优势，是解决目前企业数据治理需求的更优解。</p><p></p><p>火山引擎与英特尔在云原生大数据领域深入合作，从用户云业务需求出发提升数据价值。从湖仓一体方面，<a href=\"https://www.infoq.cn/article/eB2MHKxSCVPXR7TQ9jrm\">英特尔</a>\"技术团队和火山引擎技术团队联合对 ClickHouse 软件进行优化，通过对硬件指令等其他的优化，使 ClickHouse 核心代码的性能有了 1.5 倍以上的提升，ClickHouse（Repartition-Block shuffle）性能加速 4.2 倍。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/45/45ee1a3830a696f8e42b8ae04c35289f.png\" /></p><p>图：英特尔和火山引擎 ByteHouse 的合作优化</p><p></p><p>总体而言，湖仓一体是一种更开放的新型架构，有人做了一个比喻，“这种操作方式类似于在湖边搭建了很多小房子，有的负责数据分析，有的运转机器学习，有的来检索音视频等，至于那些数据源流，都可以从数据湖里轻松获取。”</p><p></p><p>Gartner 也发布了湖仓一体的未来应用场景预测，“湖仓一体架构需要支持三类实时场景，第一类是实时持续智能；第二类是实时按需智能；第三类是离线按需智能。这三类场景将可以通过快照视图、实时视图以及实时批视图提供给数据消费者，这同样是未来湖仓一体架构需要持续演进的方向。”</p><p></p><p></p><h2>三、“AI 与大数据一体化”重塑数据价值</h2><p></p><p></p><p>如今各行各业都在探索怎样让 AI 在实际应用中提高工作效率或者体验，但有数据表明，85% 以上的人工智能项目都是以失败而告终的，并没有真正地得到交付。归其原因是，实验室中正在跑的人工智能模型、算法和真正落地到生产环境或业务场景中的东西要求是不一样的。这意味着，企业想真正地将算法、AI 模型运用到生产系统中，需要经过非常复杂的 AB 测试，但将 AI 模型算法和真实的业务数据流水线相结合是一个非常大的挑战。</p><p></p><p>回想一下，在构建一些 AI 架构时，大家通常的做法是利用一个大数据处理平台，然后对数据进行处理，处理完后再将数据拷贝到另外一个 AI 集群或是深度学习的集群中进行训练。显而易见，数据拷贝的过程会产生一定的时间成本和移植成本，解决了这个问题，可以大大提高企业研发效率，快速实现降本增效。</p><p></p><p>将大数据分析与 AI 平台融为一体的模式成为了企业解决以上问题的方案，其也正在成为一种行业的新趋势。构建一个端到端的大数据 AI 的流水线，将大数据 +AI 的流程从数据的获得、读取、数据的处理到特征的处理、建模、训练、部署、推理等流水线都统一起来，是实现 AI 真正落地的关键点。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dc/dcc8ec3ba3377df9b44466fb37807d7f.png\" /></p><p></p><p>为了支撑大数据的处理，<a href=\"https://www.infoq.cn/article/JQCakovYENiLlGOAj1QX\">英特尔</a>\"在“AI+ 大数据”方面做的第一件事情就是构建统一的大数据 AI 平台、集群——英特尔 BigDL ，其是用于 Spark 的分布式深度学习库，可以直接在现有 Spark 或 Apache Hadoop 集群之上运行，并可以将深度学习应用程序编写为 Scala 或 Python 程序。</p><p></p><p>作为底层计算平台，英特尔 BigDL 针对分布式的英特尔® 至强® 处理器 CPU 集群进行了大数据 AI 平台的构建，包括在硬件上的众多优化，包括 CPU 本身对 AI 的支持。虽然英特尔® 至强® 处理器是一个通用处理器，但它提供了非常多的硬件指令及针对 AI 优化和加速的硬件支持，包括在低精度 INT8 上的 AVX512_VNNI , 以提升 DL 性能。其主要具有以下特点：</p><p>丰富的深度学习支持：基于 Torch &nbsp;BigDL 为深度学习提供全面支持，包括数值计算（通过 Tensor 和高级神经网络）；此外，可以将预训练的 Caffe * 或 Torch 模型加载到 Spark 框架中，然后使用 BigDL 库运行推理应用他们的数据。高效的横向扩展：BigDL 可以通过使用 Spark 以及同步随机梯度下降 (SGD) 和 Spark 中的 all-reduce 通信的有效实现，有效地向外扩展以执行“大数据规模”的数据分析。极高的性能：BigDL 在每个 Spark 任务中使用英特尔® 数学核心函数库（英特尔® MKL）和多线程编程，BigDL 和英特尔® MKL 专为英特尔® 至强® 处理器设计和优化，可提供极高的性能。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/43/43870ec25822beae1fbaeb0807e402a4.png\" /></p><p></p><p>万事达卡在企业的数据仓库建构在分布式大数据平台之上，便是直接用英特尔 BigDL 来构建 AI 应用，将大数据的数据处理与人工智能的处理直接统一起来，帮助平台支撑超过 20 亿的用户。平台上的几千亿的交易数据训练了非常多的 AI 模型，其中最大的模型在一个任务运行在 500 台以上的英特尔服务器上进行大规模分布式训练，差不多在 5 小时之内训练出一个大规模的 AI 模型，提高各种 AI 能力，实现了超大规模用户量的支撑。</p><p></p><p></p><h2>四、写在最后</h2><p></p><p></p><p>经过近 20 年的发展，大数据的技术栈逐渐成熟，“大数据”如今几乎已经是程序员技术栈的标配，基本上大多数应用环境都会牵扯到数据治理、数据处理。</p><p></p><p>近年来，云计算、人工智能等技术的发展，还有底层芯片和内存端的变化以及视频等应用的普及，都给大数据技术带来了新的要求。不管是应用基于数据还是要用数据改善应用，怎样能够把整个技术平台和软件平台做得更加易用，这对于厂商来说是亟待解决的难题。此外，人工智能、大数据技术的应用场景都非常广泛，但在具体应用开发的技术实现上还有很多缺陷，如何实现技术突破和技术创新，这是所有人都面临的难点。</p><p></p><p>我们可以预测到的是，未来的大数据技术会沿着异构计算、云化，AI 融合、内存计算等方向持续更迭，目前我们看到的这些难点应该都会被逐一解决，但当我们在进行算法、架构优化时，也要记得硬件是实现所有技术演进升级的基本盘。当在软件层找不到解决方案的时候，也可以尝试把目光放到硬件层。</p>",
    "publish_time": "2022-11-28 14:36:20",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "智能化与低码化在兴盛优选的应用与实践",
    "url": "https://www.infoq.cn/article/bFSNMOKkXsgROVUl7cLm",
    "summary": "<p></p><h2>前言</h2><p></p><p></p><p>Hello，大家好，我是文子穰，来自兴盛优选体验技术部，本文主要话题是围绕低码化&amp;智能化两个方向的实践与总结。</p><p></p><p>在进入正文之前，我想我们应该回溯下历史也了解下背景，任何新技术方案和平台兴起的背后都是由于某一些问题的产生从而推进得来的。前端技术发展至今，前辈们通过不断的探索，挖掘出了多种技术方向，涌现出不同的技术方案，我们作为后辈作为受益者，在平日的工作中会通过工程化，视觉化，区块化，微应用化等方案，去赋能于企业，赋能于产线。而面对日益复杂的业务场景，日益剧增的业务迭代以及频繁的重复性结果交付，这造成了团队的人力需求剧增，投入成本巨大等问题，我想这都是大家在现实工作中所面临的共同问题。因此”低代码“这一话题，就从历史的轮子当中再次被提取了出来。当前低代码的表现形式大家对其都褒贬不一，部分人认为它没有实际用处，没法给研发人员通用化提效，反而增加了大量的定制化工作，给其定性为“毒瘤”。而部分人认为它解决了业务线具体的生产需求，是一个有效的生产力工具。无论大家对其如何的评价都不可否定低代码是一个较好的解决方案，每一个人每一件事站在的角度不一样得出的结论也大不相同。在接下来的文章中我会具体的讲解，针对低代码这一话题我不同的看法及其整体布局。</p><p></p><h2>低码化的方案制定</h2><p></p><p></p><p>关于低码化方案制定我们从两个部分展开分别是《展现形式》《方案抉择》，通过这两部分我们能够比较清晰的看待低代码以及在日常工作中如何决策平台建设工作。</p><p></p><h3>展现形式</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/69/694909e4bc9870844f6f31c6dbfbbb0e.png\" /></p><p></p><p>如上图所示<a href=\"https://xie.infoq.cn/article/9bd5f87e954120755cbb987e5\">低代码的特征</a>\"是极具特色和明显的，我们可以用三个维度看出与其他方案不同之处。第一部分为交互模式的改变。第二部分为组件模式的不同，<a href=\"https://xie.infoq.cn/article/5ca9d7c0c8ab979478211b138\">低代码平台</a>\"中会预先制作好常用组件，预先存留好常规场景，从而来缩短输出工期。这一部分是低代码平台的特色也是其最受争议的模块。在以往的模式内我们有视觉化所提供出来的通用组件库，有区块化提供出来的业务组件和模版物料，常规模式里组件库与区块是高度灵活和抽象的。而低代码平台组件和物料部分被固化，形成先天性的劣势，从而造成灵活性不高拓展性不强等问题，因此它最适合运用在”通用性““重复性”较高的场景。第三部分是数据模式的不同，在低代码中数据是被抽象成配置的，无论是组件的属性还是组件的事件流转，都是通过数据配置化结合配置可视化来进行处理。结合上述三个不同维度的分解，我们不难看出其在某一些方向的优势和劣势，低代码它不可被万能化它不是一个可被业务运用在任何场景之下的通用技术方案，我们应该合理把控合理规划的去建设其核心能力以及平台。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2a/2a732dc21e47a8d00220d1f25594ab66.png\" /></p><p></p><p>了解完低代码的核心特征后我想多数人对此都会有了一定的客观印象，接下来我们从模式和角色上进行分析。如上图所示，<a href=\"https://xie.infoq.cn/article/2a62aae24861c8edfde006709\">低码模式</a>\"主要分为四种，“ProCode”“LowCode”“NoCode”“AutoCode”，每一种模式在使用方式上都有所不同，研发难易程度也是从低到高呈现，它们都被应用在不同的场景之下。第二部分我们从使用角色上进行拆解，面对平台不同的使用角色决定了我们对于平台建设上不同的技术架构，在图中我粗略的以三种角色进行概括，其分为“开发人员使用”“无编码能力人员使用”“基于环节式驱动”每一种方式我们所提供的功能及低码模式都不一样。其中开发人员更适合Pro-Code|Low-Code的方式，平台需要具备更高的灵活性和组件的插拔式面对多样的业务场景都有很好的承接性。运营人员、产品经理、设计师等角色他们不具备编码能力，对于页面的生产过程不具备一定的了解。所以更适合No-Code|Auto-Code的方式,平台内需要内置大量的场景模块，组件和事件流转方案，在使用的过程中能够被用户更好地理解以及快速的输出产物，不必纠结于细节，能够模版配置化最好。而最难的莫过于环节驱动下的需求，每一个环节使用角色不一样，其呈现出一连一的特征，这时我们就要考虑混合的建设方式，用不同的模式来解决每一个环节的痛点，最终打通整体流程。</p><p></p><h3>方案决策</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c6/c698ac39c7e54f2baa07e4a6cd68f17e.png\" /></p><p></p><p>对于我们在业务产线中，想要基于低代码方案来布局平台解决问题时，我们最重要的不是关注平台功能本身而是需要决策平台的落地方式。前文中我有分析过目前低代码的整体情况及其展现形式，跟大家说这些也并不是我写这篇文章的初心，而是想通过一步一步的演进从而推导出决策的方法。如上图所陈列的一样“应对不同的场景与角色，使用不同的方案以及方案的下沉深度”。确定使用人群，聚焦业务形态，寻找平台闭环。当我们确立了平台准确目标后，平台建设基本上就有了初步的形态，反之低代码的展现形式及相关布局方式不符合当前业务场景使用时，请勿生搬硬套，反而容易吃力不讨好。有了基本的形态那么接下来我们才需要考虑具体的技术方案，目前市面上有较多的方案可供选择。例如：阿里系的<a href=\"https://xie.infoq.cn/article/899013deb6513cddda327c89b\">LowCodeEngine</a>\"，腾讯系的<a href=\"https://mp.weixin.qq.com/s?__biz=MzAxODcyNjEzNQ==&amp;mid=2247561666&amp;idx=3&amp;sn=87267db2878d508e984306d9ba15840e&amp;chksm=9bd25c5aaca5d54c0471a46c03fc4d09a8ba1e52ff96b8d8e96fcda72394c2120c9c26c13769&amp;scene=27#wechat_redirect\"> TmagicEditor</a>\"，百度系<a href=\"https://mp.weixin.qq.com/s?__biz=MzUxMzcxMzE5Ng==&amp;mid=2247514984&amp;idx=1&amp;sn=c258ad1d9b7253f4905ada0608b49c81&amp;chksm=f9520e2bce25873d090c56b11d8fbe64e9b5623bc9e933afc7ec1911756f6078a96b49611ea3&amp;scene=27#wechat_redirect\">Amis</a>\"等。这些不乏都是行业里比较成熟的案例，它们经过了企业内部的推敲验证，我们可大胆尝试使用。而面对一些中大型厂商，会有一些独特的场景需求及定制化工作，在拥有合适技术人选以及人力资源投入时，我们可以不使用开源方案，自己制定出符合企业内部特色的低代码技术解决方案。</p><p></p><h3>惊奇引擎</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2d/2d9f6fadbb39db346fc91252dccdccc9.png\" /></p><p></p><p>在我加入兴盛优选体验技术部前，我们团队内已经存在一部分低代码的产品，他们都被运用在不同的业务领域，有大屏可视化的，有中后台搭建的，有营销侧的，有表单类的。无一例外它们都具备一定的业务价值，解决着一定的业务问题。但是每一个平台都有各自的方法论和实现原理。每一个平台有各自不同的视觉呈现以及其不同的交互方式。它们都划分在不同的团队中由不同的人员维护管理。不可否认这确实挺锻炼人的，毕竟会输送出一批了解低代码平台建设的人才。但在同一个企业之中各平台所面对的大多数使用者或许是同一批人，这极大的增加了用户使用的成本以及用户切换平台的连贯性。其次多个平台的底层实现原理都由不同的人维护，每一个平台的底层迭代更新在功能层面也没法更好的进行共享。新来一个搭建需求又是另起炉灶，重复迭代。说白了”轮子不怕多，越多越好“的事实在大多数企业内部也同样存在，甚至整个圈子里也在不断重复建设。</p><p></p><p>结合上面所阐述的问题以及对整个团队低码产品有了充分了解后，我们开始了相关能力的研发工作，最终形成了一套可多端（移动端+中后台+大屏）支撑通用性强的低代码引擎，它由四个模块组合而成分别是 《低代码视觉体系的建设》《低代码底层原理库的建设》《通用化低代码开箱即用的建设》《低代码物料协议与物料模版的建设》我为其取名《惊奇引擎-Marvel》，上图为惊奇引擎整体的架构图，接下来我会依次介绍每一个组成部分。</p><p></p><h3>Dlib的组成部分</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f4/f4352eb81aba696c720da31f49557038.png\" /></p><p></p><p>Dlibrary为惊奇引擎提供底层能力支撑，它包含八个高度解耦的服务模块，我们将常规低代码平台中需被通用化的功能在此统一封装且每一个模块都具备独立插拔的能力，具体模块如下：</p><p></p><p>●component-loader： 物料加载器，提供物料的接入识别以及转换能力，为低码平台提供源源不断的资产支撑。</p><p></p><p>●canvas-loader ： 画布加载器，其中包含多画布，卡尺，容器自适应，沙箱隔离等功能，为低代码平台提供作业区域的的核心能力支撑。</p><p></p><p>●draggable-lib： 拖拽库，拖拽库中包含了拖拽容器及拖拽元素的组件级封装，并提供自由拖拽模式，排序拖拽模式供不同交互形态使用，还包含元素距离检测，覆盖检测，边界检测，合并成组等常见功能。</p><p></p><p>●render：渲染器，渲染器是组件&amp;自定义设置器&amp;页面的核心渲染能力的包装。</p><p></p><p>●animation-timeline：动画设置器，其基于时间轴的方式配置的动画细节，内置了整个动画编排规则及常规动画库。</p><p></p><p>●factorys： 数据工厂，其内部包含数据源，接口，变量等不同模块的工厂服务，提供各模块的数据创建，存储，提取，更新，监听等操作。</p><p></p><p>●hotkeys：热键库，我们针对键盘操作提供了一套高度封装的方法，通过简单的参数配置即可对接到低码平台，使其快速拥有快捷操作等功能。</p><p></p><p>●tools： 工具库，其内部封装了在低代码平台建设中常见的工具函数</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bc/bcb2353cf0d2efa2450ce6a1dafb43ac.png\" /></p><p>区域展示-01</p><p></p><h4>画布核心</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0e/0ee12b1e33723fb6404a62e54c414ffe.png\" /></p><p></p><p>画布是低代码平台重交互区域，其作用就不言而喻了，很多人对画布的概念不清晰，甚至很多平台没有画布的概念，从“区域展示-01”图中可见画布为低代码平台中呈现在那一部分。我们将卡尺、参考线、沙箱隔离等功能融合在了画布组件之中，通过属性进行功能的控制。而整个画布的核心实现原理主要通过控制画布容器的TransformMatrix数值从而控制整个区域的移动、缩放、旋转、倾斜。具体如上图所示</p><p></p><h4>拖拽核心</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f9/f95364353489ae4e4f65794f5c2d135d.png\" /></p><p></p><p>拖拽是低代码平台最常见的交互形态，而常见平台内多为单一模式，也就是非自由模式及排序模式。从“区域展示-01”图中可见拖拽为低代码平台中呈现在那一部分。作为底层引擎我们当然需要符合不同场景的需求，例如大屏可视化搭建、海报搭建依赖于自由拖拽模式，营销活动h5搭建、中后台搭建依赖于排序拖拽模式。拖拽核心也主要划分为两个部分拖拽元素主体，拖拽容器主体。具体实现原理如上图所示。</p><p></p><h4>渲染核心</h4><p></p><p><img src=\"https://static001.geekbang.org/infoq/45/45e0ed4808e2331b1b37ddcd04c09132.png\" /></p><p></p><p>渲染这一话题在低代码平台内分为两种分别是组件的渲染、页面的渲染。上图有分离拆解图供大家可视理解。而惊奇的核心渲染逻辑分为四个步骤</p><p></p><p>《整合数据》我们基于页面Schema来进行组件渲染映射表的生成，形成组件与远程渲染地址的一一映射的数据源，接着在进行数据的清洗，页面中可能会存在重复组件的现象而面对这种情况我们采取由高为先的模式进行存留，避免组件渲染时组件脚本未被按照顺序加载。</p><p></p><p>《创建渲染层级顺序》首先我们会获取当前承接渲染页面的设备视宽视高，在根据组件的渲染顺序获取组件真实渲染的宽高值，在按照设备视高进行计算按照一个可视版面进行分组，分组数据会默认往后多增加一位。在通过分组数据进行脚本地址字符混合为后期CDNCombo方案做准备。</p><p></p><p>《预加载脚本》从前两个步骤获取到的最终映射表数据我们将会进行脚本的加载和组件实例追加的操作，一个可视版面进行两次操作预先loader下一个可视版面资源。</p><p></p><p>《渲染核心》基于高阶组件的方式通过schema中对于组件属性配置的数据进行props的获取与绑定，事件的获取与绑定。从而完成整体页面以及组件的渲染。整个过程可能无法通过几段话来概括，但流程和原理大致如此。</p><p></p><p></p><h4>物料接入的建设</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d1/d17e6c0d27dd71ffcca6162cd77d1259.png\" /></p><p></p><p>关于物料这一层级是很多低代码平台乃至低代码引擎都为之头疼的部分，因为物料资产不够或物料的研发流程复杂而限制低码平台的拓展面的情况数不胜数。为解决这一问题目前市面上最为常见的做法是根据平台性质而内置化丰富的组件物料。好一点的平台或引擎会提供一些物料接入的规则，按照规定的模式进行研发，平台侧提供物料注册函数。而惊奇的做法相对于这些方式而言会更为轻便，接下来我简单阐述下惊奇的原理和过程。如上图所示，惊奇提供了物料接入的可视化操作，使得惊奇引擎搭建出来的低代码平台可以在不变更平台代码的基础上无需平台发版的基础上，即可快速接入单一物料或物料组。</p><p></p><p>我们可以通过两种方式进行物料输入，第一种是npm的对接，你只需提供包名包版本，component-loader的node服务会自动解析这一个npm包并分析出此包为单或多的形态从而进行单组件接入流程或组件集接入流程，在服务中我们会创建一个类似真实渲染的环境沙箱从而来获取组件的相关信息例如组件的名称、属性、事件等信息，最终自动生成一份符合惊奇可被接受的物料描述数据集，第二种是cnd资源的对接，核心逻辑与npm类似。具体每一个核心流程在上图有详细的诺列。除此之外针对物料的生产我们也提供了一套物料脚手架，脚手架中提供了项目的创建打包部署等功能。除此之外惊奇为每一个物料都提供可视化的管理版本能力，每一个组件的渲染都与物料版本，物料配置版本强关联从而避免造成组件更新影响老项目使用等核心问题。</p><p></p><h3>DPro的组成部分</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/bf/bf04cfd1adf15bdd56601235c0d7638e.png\" /></p><p></p><p>DPro为惊奇引擎提供上层的能力支撑，目前DPro主要分为两个主要部分，分别是一整套低代码的视觉体系规范其中包含低代码平台的视觉规范以及视觉组件。除此之外还提供通过视觉规范所衍生出来的低码细粒度模块化组件，具体情况下面如下。</p><p></p><p></p><h4>低代码视觉体系的建设</h4><p></p><p><img src=\"https://static001.geekbang.org/infoq/a0/a06b24991071628b615511e574714a63.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f9/f9a4f8f6c373ed976b0cacbc1ea864da.png\" /></p><p></p><p>如上图所示，目前视觉规范中包含了1000+的低码平台常规图标资源、40多个缺省图、八大模块（接口管理、数据源管理、变量管理、代码编辑器、事件流管理、动作管理、组件物料管理、模版管理）30+的常规模块（通用属性设置器，样式设置器，菜单组件等）</p><p></p><h4>低代码开箱即用的建设</h4><p></p><p></p><p>我们在脚手架中也提供了初始化低码平台的功能，而marvel-pro的包提供了如下图所诺列的相关组件。开发者无需考虑Dlibrary的核心实现只需要通过DPro提供的模块化组件，像搭积木一样搭建出你所需要的低代码平台，目前惊奇引擎在兴盛内部支撑着会场搭建、中台搭建等场景，我们也在着手基于惊奇引擎提供服务一体化平台，为企业提供更强有力的支撑。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/98/98f0617a74127cb28d7187f65774de50.png\" /></p><p></p><p></p><h2>智能化方向的探索</h2><p></p><p></p><p>近两年前端智能化方向非常火热各大厂都纷纷投入其中，在接触这一方向之前我们其实也思考过智能化相关落地的场景，它所能带来的实际价值，研究过目前市面上相关的产品其中就有《imgcook》《codefun》《deco》这些平台。现阶段市面上智能化相关的产品大多数都是基于D2C这一个场景下衍生出来的。而对于我们团队内部而言D2C并不是我们第一层级所需要的能力，如何找到一个恰到合适的落地点，如何用智能化方案赋能前端领域，增强前端建设的多样性，也成了我们探究很久的话题。通过不懈的努力我们最终在团队内部孵化出了第一款相关平台MarvelDesign。</p><p></p><p></p><h3>MarvelDesign的诞生</h3><p></p><p></p><p>MarvelDesign是一款打通设计稿交付，页面自动走查的集成平台，我们通过智能化的手段，帮助前端开发工程师，视觉设计师在工作中简化协作步骤，简化思考，提高输出质量，在前端页面还原阶段，设计验收阶段提供不同的智能辅助能力从而起到降本增效的目的。整个平台由figma端的数据接收服务，设计稿解析服务，标注生成服务，自动走查服务组合而成。在整个平台中除了通用的画板标注能力，智能走查能力之外，我们还基于深度学习的方式研发了组件识别模型，图标识别模型等，我们会将这些模型运用在设计稿标注生成阶段，将设计稿中的图层进行识别，来反馈出这一图层的类别，在与常规资产进行一一匹配。下面都是平台的相关截图。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5f/5f46f1977653d0e03d2676d90cae3a3f.png\" /></p><p>figma端插件</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c7/c75871af19a3f042b8b445a3735cae84.png\" /></p><p>平台侧相关模块</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/07/072ad3163bd80f8403f3e2f8aa084bc0.png\" /></p><p>设计稿标注模块图标图像管理模块及项目生成模块</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/66/660d8d45bf9061e9f7a1c714b606863f.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0e/0ed1e62fe2c931fc16db024d122c3d17.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f0/f002fcfe764441da2a3949f8ab70957d.png\" /></p><p>智能走查模块</p><p></p><h4>核心能力的剖析</h4><p></p><p><img src=\"https://static001.geekbang.org/infoq/03/03d46dd6aa6adc47514fac6fcf1dfedb.png\" /></p><p>MD-01</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a3/a387cde2d7f4e288f3f5b24951064c3d.png\" /></p><p>MD-02</p><p></p><p>如何解析设计稿并生成我们想要的产物呢 ？我们拿figma举例，<a href=\"https://xie.infoq.cn/article/f1d34ac4ea7e5be4a351b9de5\">figma平台</a>\"本身有第三方插件研发生态提供了丰富的openapi供开发者使用。如上图-MD-01所示，调用OpenApi我们能够获取到整个设计稿画板的原始数据结构其中包含了画板中每一个元素的细节数据。拿到数据就可以进行一些骚操作了，比如说你想基于这些数据的关联关系生成代码或者基于这些数据做标注生成等功能，这就看每一个团队的核心需求了。那么MD是如何基于这份数据来进行标注生成的呢？如上图-MD-02所示其基本步骤有五个《数据的清洗》《图层的处理》《新结构的生成》《样式的转换》《数据的混淆》我们将figma拿到的数据进行一次清洗后得到一个更清晰的结构其中就包含了画板的基础信息，图层的基本信息与图层的属性信息等，接下来进行图层的处理，我们将不可见图层无含义图层数据进行删除（隐藏的图层或没有任何展示效果的图层）在进行叠加图层的处理为叠加图层增加一个父容器图层。处理好数据与关系后，我们就会针对每一个图层进行分析，分析过程大致会经过三个步骤“图标识别”“组件识别”“循环节点识别”，处理好每一个图层的的信息后得到一份MD的新数据结构。最后我们可以根据这份新的数据来进行下一阶段的处理如样式转换，代码生成等。</p><p></p><p>在上部分有讲到关于组件与图标的识别，那么我们是如何处理这块的呢？我们基于深度学习的方式进行组件识别模型与图标识别模型的训练最终得到相对应的权重文件，将其部署到云服务器后在通过接口服务提供相关识别能力支撑。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/14/14ce6417baaee60311208f669e4446ce.png\" /></p><p>SD-01</p><p><img src=\"https://static001.geekbang.org/infoq/6b/6bf76deb04680cb527a0e586f27978cd.png\" /></p><p>SD-02</p><p></p><p>关于AI-人工智能大家可能都有耳闻，AI其实包含的东西有很多例如机器学习，深度学习等，它们之间有什么区别呢？如上图-SD-02所示它们之间是一种包裹关系 AI &gt; 机器学习 &gt; 深度学习。用通俗易懂一点的方式来介绍一下，机器学习是人提前设定好标签和特征，然后由计算机按照设定好的标签特征去工作。 深度学习无需人工设定特征。基于提供的样本数据集自动训练模型计算权重偏量，找到各种数据的特征然后进行工作。那么如果我们想基于深度学习来训练一个自己的组件识别模型那么需要怎么做呢？如上图SD-01所示，其整个过程分为8个步骤，我们挑一些重要的步骤讲解一下。首先第一步是样本的准备，样本就是我们要提供给算法的训练数据，我们可以通无头浏览器去跑一些站点收集一些组件不同形态的图像，例如文本框的展现形式按钮的展现形式，有了样本后我们就会进行样本打标操作，最后我们要按照比例整理好结构其中包含训练数据集、验证数据集、测试数据集。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/db/dbc0260438c2d8aa575d5586c671c6f3.png\" /></p><p></p><p>有了样本数据我们就需要进入到算法决策以及模型训练等环节，想要完成组件识别这一功能，有两种方式可供选择分别是图像分类，目标检测。如上图所示图像分类又分为强监督细粒度图像分类和弱监督细粒度图像分类。目标检测也分为One Stage检测算法和Two stage检测算法。MD采取的是图像分类算法，我们不需要在一张图中检测出该图有哪一些命中目标，只需要一对一的图像识别即可。那么如果你是直接进行设计稿图像的识别那么就需要使用目标检测的方式来进行组件识别，这样可以在设计稿图像中识别出多个命中目标。目前市面上有两个主流框架来进行深度学习和机器学习的研发分别是TesorFlow&amp;Pytorch，使用这些框架多多少少需要具备一定python的研发能力，作为前端来说这会有一定的学习成本，在这里我推荐大家可以了解下阿里开源的《Pipcook》它是一款能让前端工程师更容易上手的框架，处理一些组件识别图标识别等功能还是绰绰有余。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8e/8ed0ba3d46c7535ae51b8ad4fe278f52.png\" /></p><p></p><h4>智能UI走查的实现原理</h4><p></p><p></p><p>智能走查的应用场景在那里？我想大多数设计师朋友都能体会到，由于每一个前端工程师的能力都有区别那么基于设计稿还原出来的页面质量都有所不同，每一次项目上线之前设计师都会进行页面的设计还原度测试，检测页面还原是否有问题比如说颜色的检查，字体大小字重的检查，间距的检查，宽高的检查等。这是一个没有什么技术含量却非常花费时间精力的一项工作。那么我们基于智能走查的方案能够在页面还原度验收环节降低非常多的人力成本。那么具体实现原理如下图所示，整个自动走查的原理是基于图像对比进行元素匹配，在基于真实dom元素样式表和与之匹配的设计稿元素标注样式表进行数据层面上的对比最终形成一份差异映射表。其中分为五个步骤《获取页面可视节点》《生成节点快照》《节点与图层匹配》《计算匹配数据的样式表差异》这一整个步骤中最为重要和有难度的的就是“节点匹配”这一个环节。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/67/674b2bad2b8d1f9e09523e0105bf3e8c.png\" /></p><p></p><p>针对”节点匹配“我们可以通过图像相似度对比的方式来进行处理其分为两个步骤《图像的指纹提取》《图像指纹的比对》如上图所示方案有很多不做一一讲解，以均值哈希算法作为例子。一张图片就是一个二维信息，它包含了不同频率的成分亮度小的为低频它描述大范围信息，亮度变化大的就是高频区域他描述具体细节。高频可以提供图像的详细信息，低频提供整体图像框架，均值哈希算法就是利用图像的低频信息进行处理。我们基于下图ZC-0的步骤可以获取到两张图像的指纹，在基于下图ZC-1中的方式的得到两个指纹的相似度值，最终可以得出可视节点与设计稿节点的匹配度。在MD中我们采取的是混合提取与混合比对的模式来提高比对的准确度。整个过程包含了初筛，排序，复筛这三个过程具体如下图ZC-2，最终我们可以通过上述手段输出设计稿自动走查的完成能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/67/67d85d2e0cf91254e6a4f71dca78e1fd.png\" /></p><p>ZC-0</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/36/36e37d7792af8aadc970acf866d49232.png\" /></p><p>ZC-1</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0f/0fb5ef8ae6fd1b183b3e7165c0c10d98.png\" /></p><p>ZC-2</p><p></p><h2>总结</h2><p></p><p></p><p>目前智能化与低码化在我们团队内部都有很好的落地场景以及产品输出，虽然每一个产品都会存在相关问题，但产品的完善是一步一步来的。未来我们也会在这两个方向不断输出更多有价值的功能赋能于企业。如果你也面临着一些相同问题或正在这两个方向做相关产品布局，希望这一篇文章讲述的过程和思路能给你带来一些启发。</p><p></p><p>若有收获，就点个赞吧</p>",
    "publish_time": "2022-11-28 14:39:58",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "34年换5个技术方向, WPS不想停止“折腾” | 卓越技术访谈录",
    "url": "https://www.infoq.cn/article/M72DshiUqZkM8SIuCbgy",
    "summary": "<p></p><p></p><blockquote>有着超30年历史的国产老牌办公软件，如何在云与AI时代焕发新春？</blockquote><p></p><p></p><h2>34年，跨越5个时代</h2><p></p><p></p><p>在国产办公软件发展史上，WPS 是公认的“鼻祖”。诞生于 1989年的WPS，如今已经走过了30多个年头。放眼现在，也是为数不多的生命力如此持久的IT软件。</p><p></p><p>1988年5月，后来被盛赞为“中国第一程序员”的求伯君把自己关在深圳蔡屋围酒店的501房间，用一台386电脑天天敲代码，饿了就吃方便面，困了倒头就睡。“闭关”一年零四个月，他用汇编语言写下了12万2千行代码，WPS 1.0 版本从此诞生。</p><p></p><p>当时，电脑刚进入中国，中文办公软件奇缺，这也正是WPS瞄准的机会。WPS 1.0 推出后便很快占领了中文文字处理软件领域90%以上的市场份额，销售额达到了6600万元。曾经一度，WPS几乎成了电脑的代名词，成为PC时代的闪耀新星。</p><p></p><p>1992年，雷军受求伯君之邀加入金山，两个意气风发的年轻人立志让中国人都用上金山的办公软件。</p><p></p><p>然而，WPS很快迎来了一个强大的对手。1995年，微软进入中国市场，微软Office来势凶猛，在WPS的地盘攻城略地。为了迎战，在WPS的基础上，金山花3年时间研发出了「盘古组件」，不料这款承载着求伯君和雷军“开天辟地”梦想的产品却遭遇滞销。</p><p></p><p>在不速之客微软与横行的国内盗版软件双重夹击之下， 那几年，金山进入了低谷期。200多人的公司，只剩下20多人。为维持公司运转，求伯君卖掉了此前投资人奖给他的别墅，筹得了200万。</p><p></p><p>为扭转局面，金山决定从头再来。2002年8月，雷军提议花3年时间和金山账上仅有的3500万人民币重写WPS。这显然不是一个简单的决定，此前14年的技术积累从此将放弃，无异于“自废武功”，而且前途未卜。</p><p></p><p>但也必须绝地求生。100多位工程师将以往运行了14年的架构全部推翻，在重写了500多万行代码，重建了100多个版本后，金山2005年推出的 WPS 2005&nbsp;实现了与Office深度兼容。而且，这次特别将 WPS 2005 压缩到了不足20兆的超小体积，还将个人版免费开放给个人用户，这些主动拥抱互联网时代的特性让 WPS 2005 改变了Office的市场格局。</p><p></p><p>2010年，移动互联网的大幕徐徐拉开。金山觉得，弯道超车的机会要来了，便几乎投入了所有资源将重心转向移动端业务。2011年，金山办公正式推出了移动端的WPS。前金山办公董事长葛珂曾表示，拥抱变化，而非躺在过去的功劳簿上等待被淘汰，希望WPS能在移动时代实现“为移动而生”。根据金山办公2012年12月发布的数据，移动版WPS累积用户数已达3000万，到2012年第三季度末，WPS 移动版连续4个季度的复合增长率超过了176%，日新增用户达19.5万，约占全球安卓系统每日新增设备的14.8%。</p><p></p><p>移动互联网浪潮之下，衍生出了大量新的需求，例如多屏、多设备。传统的人坐在电脑前操作办公文档的形式将不再单一。用户希望文档能在多设备间流转，多屏和多设备间的文件存储需求也不断增加。这样一来，云的诉求越来越强烈，通过云文档的方式完成设备间的流转将是新的解决方案。</p><p></p><p>于是，2018年，金山办公提出了“多屏、内容、云、AI”推动业务转型。“多屏”是指不局限于PC设备，同时覆盖移动端，如Pad、移动手机、Web等；“内容”指将WPS传统的工具属性变成服务属性，提供内容服务。“云”指利用云存储技术，将原来office传统的单机离线应用变成在线应用，基于云存储。“AI”是指通过AI能力开发创新性功能，AI辅助办公以提高办公效率。</p><p></p><p>2020年，金山办公加注“协作”，计划从用户需求出发，从提升用户办公效率出发，为用户提供更多协作产品。金山办公CEO章庆元认为，2020年是协作办公的元年。在线办公正在迈入协作办公时代。</p><p></p><p>回顾过去这34年来，金山办公经历了PC时代，互联网时代，移动互联网时代，云与AI时代，协作时代，几经沉浮，历经各时代变迁。结合时代以及客观环境的发展变化顺势而为，且坚持技术立业，已然是刻在金山骨子里的基因，这也正是WPS 30多年来穿越5个时代仍然是办公软件常青树的秘诀。</p><p></p><h2>AI如何颠覆办公？</h2><p></p><p>金山办公的进化之路，同样也是办公软件跟随时代的技术变化之路。</p><p></p><p>近日，金山办公高级副总裁庄湧在接受InfoQ采访时表示，办公软件正在往移动化、云化和智能化的方向发展。再加上这几年疫情所带来的远程办公的趋势，进一步坚定了云服务、云文档、智能文档的诉求和实际应用场景。</p><p></p><p>本部分着重以AI技术在金山办公的技术创新与应用实践为例，展现这家老牌办公软件在智能化时代的蝶变。</p><p></p><h3>AI上升为内部战略，老将重回金山办公组建AI团队</h3><p></p><p>2017年，AI在金山办公内部被首次上升到战略地位，这一决策也顺应了当时AI的发展趋势。</p><p></p><p>2016年，AlphaGo大战李世石，掀起了AI领域的又一轮热潮，与3年前深度神经网络所引领的学术界热潮相比，这一次热潮令工业界开始重新重视起AI。一些应用工程的大型开源项目开始出现，工业界的开源框架陆续开源，英伟达的GPU算力支持在17年左右慢慢成熟，这让AI在实际应用上变得更加可行。</p><p></p><p>全球范围内做应用开发的企业开始逐步投入AI领域的算法工程研发。在感受到上述形势的变化后，作为一家以应用开发为主的企业，金山办公也开始有了一些新的动作。</p><p></p><p>2017年5月，告别金山十余年的老将姚冬重回老东家，担任金山办公副总裁。姚冬自1998年加入金山，此前曾负责过金山词霸、金山游侠等产品。此番重回金山，姚冬转型做 AI 方向的算法和工程产品，负责算法改进、推动工程落地、人才梯队建设工作。</p><p></p><p>姚冬牵头组建了金山办公的AI算法、工程和产品团队。目前，金山办公的AI团队约有百人规模，划分为基础设施、平台、产品和应用、基础算法等小组。</p><p></p><p>当时站在风口浪尖的AI创业团队多数是学术背景出身，姚冬则决定从工程思维出发组班子。“我在起步阶段的想法是，如何将工程研发体系建立起来，怎么做出一些产品和功能，让AI能在工程上落地”。一直到现在，在AI团队内部，算法和工程并不泾渭分明，姚冬更加注重培养工程师的全栈能力。</p><p></p><p>成立5年来，AI团队在每一阶段侧重不同的目标，分“三步走”战略。前两年，团队更强调积累AI研发能力，包括算法能力，工程能力，数据采集，数据分析能力等。后两年更注重将技术产品化，关注AI产品能力。</p><p></p><p>姚冬表示，现阶段以及未来几年，AI团队将把重心放到第三步——产品业务化上，只有将产品变成业务，对用户及公司产生价值，创造营收和利润，才能实现长期可持续发展。</p><p></p><h3>AI辅助提高办公效率</h3><p></p><p>人类在办公领域所进行的智力活动分为两部分，一是创造力的部分，比如写文章、编故事、构建文档、表格。非创造力的部分不需要创意，但也需要进行一些智力操作，如文章排版、文字转图片、多语言互译等。</p><p></p><p>创造性活动是人类特有的，今天的AI还无法完全替代那些创造力的部分。而在非创造力的部分，尤其是一些需要重复性工作的部分，如机器翻译、自动会议纪要、自动排版等，AI可以帮助人们大幅提高办公效率。</p><p></p><p>庄湧介绍，AI在办公领域的应用主要体现在三项技术上，CV（计算机视觉）领域的图像识别，自然语言处理（NLP）、语音处理。</p><p></p><p>具体而言，在CV领域，金山办公结合办公场景做了很多智能化的应用，最有代表性的是在版式转流式的应用场景上，以前在PC时代，拍照扫描功能算不上office领域的功能，但在移动时代，已变成了常用功能，金山办公已在这方面做得比较成熟，且优势突出，例如在识别后的格式复原就是一项已在业内做到领先功能。</p><p></p><p>与单纯的功能开发不同，NLP技术需要结合办公及文档的场景深入使用，引导用户来帮助提升算法，以提升AI的准确度。庄湧表示，在NLP方面，金山办公自身积累了很多对办公用户有用的数据，这是其他厂商所不可比拟的。</p><p></p><p>现在，WPS还衍生出了智能辅助写作功能，只要根据提纲就能自动生成文字段落，帮用户打底稿。</p><p></p><p>这些技术能力都由一个统一的AI中台对外输出。目前，金山办公AI中台面向计算机视觉、自然语言处理、语音处理等算法研究方向，围绕办公领域，开发出了近100项AI能力。</p><p></p><p>作为AI中台的负责人，姚冬在采访时表示，最近几年，中台十分火热，但它并不是适合所有公司的灵丹妙药。他认为，像办公软件这样生命较长且规模较大的软件项目，非常适合构建一个中台部门进行长期持续的技术投入。</p><p></p><p>金山办公AI中台的构建过程是一个自我迭代的过程。2017年，在起步阶段，AI中台仅有几个算法工程师负责搭建，随后几年间，随着新场景、新需求、业界新技术的探索，一点点自我成长。待自有算法平台成熟后，再向业务部门以及对外做输出和推广。</p><p></p><p>现在，WPS的AI中台能力已逐步对外开放。去年7月，金山办公宣布开源业界首个面向办公领域的深度学习框架KSAI-lite。这套框架具有免费、开源、跨端的特性，自适应国内外主流软硬件平台，包括国产信创环境，在OCR（光学字符识别）、机器翻译、智能校对等场景具有显著优势。</p><p></p><p>这套框架的一个特色功能在于能够离线做AI计算。姚冬介绍，面向办公领域的框架与其他通用的框架不同，并非所有的AI计算都在服务端进行，有些计算一定要在客户端完成。这主要出于几个原因，一是用户数据需要保密，不能上传，必须在用户的电脑上处理，甚至有的客户不联网或在内网，必须在客户端完成计算。还有的计算要求算法执行快且实时，如果上传到服务器再返回，时间就过长了。因此，可以离线做AI计算的框架就格外重要，无需依赖服务器，在断网的情况下，单机、手机或PC上都能使用。而且，这段框架一定要跨平台，跨多个设备，不必为每一个移动设备或PC设备单独开发一套。</p><p></p><p>去年在开放框架的同时，金山办公AI团队还开放出了一些内部模型，如KSAI OCR开源模型。姚冬表示，团队后续还有计划开放更多模型，如校对、翻译模型，先在内部落地，在应用迭代成熟后再对外开放。</p><p></p><h3>计算机视觉技术在WPS的技术创新</h3><p></p><p>金山办公技术副总监、CV团队负责人熊龙飞自2018年加入金山办公，他向InfoQ介绍，CV部门专注于WPS内的CV相关的需求，聚焦于CV算法和技术，从模型的研究到算法落地均有涉及，注重服务和功能的落地。目前已陆续落地了大大小小二十来个项目，其中包含OCR文字识别、文档矫正、字体识别、智能抠图、图像质量提升等已经在WPS上线了两三年的功能。</p><p></p><p>版式还原系统是CV团队最近两年最聚焦的项目。这套系统可以将复杂的图片型文档重新解析成可编辑的文档，例如将扫描件PDF转化成docx，将截图或拍摄的表格图片转化成xlsx或HTML。其中表格还原除了可还原常规表格，还可以处理变形、污染、光线干扰的复杂场景，解决了用户在很多场景下对不可编辑文档进行再编辑的痛点。</p><p></p><p>这套技术之所以被称为系统，是因为它不仅可以用于上述的文档转化，也可以用于扫描件PDF编辑和扫描件PDF及图片内文字的提取、复制和检索，可以大大提高技术能力在各类需求下的复用性。</p><p></p><p>版式还原是姚冬坚持拍板要做的一个功能。已有的PDF转化业务用户满意度不高，姚冬认为，这个问题长久来看，必须解决。而且，这项技术自研可以产生巨大价值，值得投入。综合来看，基于金山办公的庞大用户基础和数据积累以及在文档处理领域30多年的技术积累，WPS是国内最适合做这个项目的公司。目前，测试和线上灰度数据显示，这项已经开发2年多的系统在行业内已处于领先位置。</p><p></p><p>近年来，CV团队取得的其他创新成果还有：2019年，金山办公将OCR模型在移动端本地实现推理，且模型体积不足10M，准确度仅比服务端下落2个百分点。当时，行业里做这个功能的还是</p><p></p><p>凤毛麟角。同年，WPS上线了移动端拍摄对书本进行弯曲矫正的能力，到目前为止还未能有超越者。</p><p></p><p>据熊龙飞透露，自去年以来，CV团队正在推进多个项目，希望进一步解决用户在文档处理领域遇到的其他痛点。例如，以往，扫描件PDF编辑是一个老大难的问题，尽管行业翘楚Adobe Acrobat等公司已经推出了扫描件编辑，但是效果和体验一直无法达到用户预期。金山办公CV团队正在研发的扫描件PDF编辑v2版抛弃了行业内通用的成熟方案，将通过团队自己构建的方案进行可编辑处理，预计这项功能会给用户带来明显的体验提升。</p><p></p><p>视觉信息抽取（VIE）是最近一年来业内的一项热门新技术。它可以将CV和NLP两种模态结合起来对文档进行识别和解析，可以获得更高层次的信息抽取。</p><p></p><p>“常规的OCR和版式还原有些类似人类阅读那样去识别介质上的文字和排版，这类能力被称为感知智能，而如果想像人那样在阅读时能联想信息的关系和信息的扩展，则需要加入理解能力，可以获得文字之外的更高维度的信息，这个过程被称为认知智能。从感知智能到认知智能将会是一个大跨步，将会带来更高维度的文档内容理解的收益，这些收益将会给用户带来更多智能化的体验”，熊龙飞表示，目前金山的AI能力正在这一领域进行技术研究和产品化落地。“在未来，大家会发现WPS里的AI功能会越来越像一个人性化的助手，它帮助用户利用文档里的信息提高办公效率。</p><p></p><h3>未来，办公AI化的壁垒不在于算法</h3><p></p><p>谈到AI在办公领域的应用趋势以及核心竞争力，姚冬认为，随着业界和学界不断地研发出一些新的算法，以及开源盛行，算力的提升和普及，未来AI技术的门槛将会降低。这也就意味着，各家在算法能力上的差别将不会很大。</p><p></p><p>那么，未来的差别来自哪里？姚冬认为，主要来自于对用户场景的挖掘。未来，谁有更多的用户场景，谁就拥有了“护城河”。</p><p></p><p>凭借过去30多年的技术积累，WPS在上述方面已逐渐形成了核心优势。WPS的用户量级非常之大，且用户场景具备多样性，复杂度也高。即便是一个小众场景，也有几百万用户，这将构筑起WPS在办公领域的壁垒。</p><p></p><h2>老牌办公软件的华丽转身</h2><p></p><p></p><h3>技术团队如何拥抱时代变化</h3><p></p><p>从PC时代到云与AI时代，跨越如此长的时间维度，每一次大的转型对于技术团队来说，都是不小的考验。</p><p></p><p>“有时候，当时代的发展趋势以及场景的变化来临时，产研需要敏锐地把握住。但有时候跟进得太早，也会出现一些超前带来的问题。反而，如果一直都挺努力，即便表现平平，也会产生事半功倍的效果”，庄湧表示，如何把握这种应变之道并不容易。</p><p></p><p>金山办公也走过一些弯路。比如，金山办公很早就抓住了从工具到服务转变的契机，开始做云文档。但因为做得太早，当时网络条件还不算成熟，加上账号便利性不够，移动端还没起来时多设备的诉求还不高，技术转型面临较多外部掣肘因素。</p><p></p><p>随着云转型后，WPS的登录用户越来越多，云文档的稳定性和安全性也经受了挑战。一方面，需要为用户提供7×24小时无间断地服务。但真正做得不出任何问题，是不可能的。这时候的应对思路就是，一旦出现问题，应最大程度上降低受影响的用户比例以及影响深度。为此，金山办公团队花了很长的时间来建设云文档的稳定性和安全性，在团队组织架构上也发生了很大的转变。</p><p></p><p>无论是windows还是移动时代，程序员的比例和研发经验都以客户端为主，客户端研发更多是从崩溃的角度看稳定性，而服务端角度要确保7×24小时无间断地不能有服务异常。在开始往云与AI转型后，研发人员尤其是服务端研发人员的比例和经验远远不够，需要不断成长不断积累，在这期间，也会短暂地出现因经验不足造成的一些问题。</p><p></p><p>如今公司的研发力量一半来自于云，服务端的研发力量比例显著提升，在C++之外，Java、Go等研发人员增加，数据库、缓存、容器、存储等都有了专门的工程师，复合型人才增加，技术栈变得更加多样，服务端经验也在不断迭代和摸爬滚打中积累下来。</p><p></p><p>得失并存，更多的是在变化中成长。“在探路过程中，我们学会了耐心。团队也越来越认同各个方向的转向，未来，对云、AI等技术，我们会继续持之以恒地投入”。庄湧说道。</p><p></p><p>然而不变的是，金山办公一直以来，崇尚技术的文化氛围。“我们内部的研发模式一直在随着业界的趋势走，但整个文化氛围上还是很务实的风格，贴近产品和业务，最近一两年包括未来几年，我们都倾向于业务落地”。姚冬说。</p><p></p><h3>转型已经渐显成效</h3><p></p><p>转型以来，金山办公已经走到了一个新的节点。</p><p></p><p>谈到转型成果，庄湧表示，“ 自云与AI战略实施以来，一直到去年，我们在自己心目中才觉得WPS 真正意义上达到了云文档的稳定性以及安全性的基本成果”。</p><p></p><p>从PC时代到云与AI时代，基于云已经做到了成型的水平，原来从传统的工具软件往云服务化转型，已经迈过了初步阶段，到了渐成规模的阶段，但还没到实现完整性的程度，准确地说，到了半云化的阶段。</p><p></p><p>从0到1的阶段已经迈过了，客户端版本的使用，工具的使用，已经跨越到了用户主动接受、愿意登录使用办公软件，并且享受上云后的便利服务。与此同时，AI技术能力的加入，为用户提供了整个云文档从创作到编辑再到发布、分享、协作、归档、搜索等，贯穿整个生命周期的智能化体验。</p><p></p><p>“我之所以说，是一个半云化的阶段，还没达到心中满意的程度，是因为在目前的阶段中，虽然用户接受，但不是全部的用户接受。有一些用户还没有意识到上云的好处，仍继续把WPS当作一个传统的办公工具在使用。此外，上云后，更多的用户还是在被动体验云后的服务，比如，很多用户使用金山文档的微信小程序查看和编辑文档，但很多时候，他们并没有意识到或者说根本不知道他们正在使用的这款产品是金山文档”。</p><p></p><p>“因此，这对我们来说，至少是万里长征的一小步，还需更多的、真正意义上的云化的或端云一体化的、云化的办公产品和服务，我们还需要再投入更多的时间以及更多的资源去完善”。庄湧表示。</p><p></p><h3>采访嘉宾介绍：</h3><p></p><p>庄湧：金山办公高级副总裁</p><p></p><p>毕业于浙江大学计算机科学与技术专业。现任金山办公高级副总裁、研发中台事业部总经理。2003年至2011年，先后担任金山办公项目经理、技术总监，负责WPS演示项目开发、毒霸单机版研发等工作，成功组建并管理日本金山研发团队，同时协助参与WPS从工具软件向服务转型；2012年至2014年，担任金山办公WPS iOS产品研发总监，成功带领团队研发iPhone和iPad设备端的办公软件产品；2015年至2018年，担任金山办公副总裁，全面负责包括WPS桌面版、Linux版和移动版的研发管理工作，带领WPS桌面版月度活跃用户数突破1亿大关。</p><p></p><p>姚冬：金山办公副总裁</p><p></p><p>毕业于南开大学，金山办公副总裁、武汉研发中心总经理。1998 年加入金山办公，从事软件开发将近二十年，先后主持多个平台客户端相关技术开发，擅长 GUI 框架，大型客户端软件架构，音视频处理等技术领域。1998年至 2004 年，负责金山词霸、金山快译、金山游侠等工具软件开发；2017 年至今，担任金山办公副总裁，并负责 AI 中台，负责公司AI方向的研发（包括AI算法研究、AI技术实施和相关产品服务开发）以及研发管理、基础技术架构演进等。</p><p></p><p>熊龙飞：金山办公技术副总监</p><p></p><p>硕士毕业于德国基尔大学，电子信息科学与技术专业，主要研究领域为：BCI（脑机接口）和图像处理，参与发表两篇IEEE EMBC文章。有过三次创业经历，现为珠海金山办公软件有限公司技术副总监，组建了金山办公CV团队，负责OCR、版式还原、PDF编辑等多个重点项目的研发管理工作，申请专利十余篇。2021年起任中国图象图形学学会《文档图像分析与识别专委会》专业委员。2021年带领团队获得金山办公技术大奖一等奖，2021年荣获金山办公和金山集团双料十佳员工。2022年获得“珠海创新创业好青年”称号。</p>",
    "publish_time": "2022-11-28 14:50:46",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "虚拟角色赛道的新“闯入者”：3D引擎Cocos和它的新故事",
    "url": "https://www.infoq.cn/article/jEs0tEhfmkjbQ1LGPkbI",
    "summary": "<p>在元宇宙风潮之下，数字人先火了。近两年，国内数字人项目呈现井喷态势。IDC预计，到2026年中国AI数字人市场规模将达到102.4亿元。作为时下最热的技术话题，我们判断，开发者有必要对数字人技术有完整的认知和理解。</p><p></p><p>在此背景下，InfoQ 特别策划了《数字人基础技术解析》专题。本专题将首先对数字人做概要介绍，紧接着围绕数字人的技术、应用落地等维度分别做解读。我们将收集来自国内业界一流团队的最佳实践，供读者参考。本文是本专题的行业落地篇。</p><p></p><p>在数字人生产全产业链中，以Cocos为代表的3D引擎厂商，处在产业链中偏工具和服务的环节。近日，Cocos 虚拟角色项目团队负责人倪飞接受了InfoQ专访，详细介绍了这家老牌3D引擎在虚拟角色构建上的技术创新以及应用落地实践。</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/9a/fc/9ab06de4643eb576fe824eff8a536dfc.png\" /></p><p></p><h2>老牌3D引擎入局虚拟数字人</h2><p></p><p>当前，元宇宙的话题度无疑空前高涨，正迅速攀升为顶流概念。</p><p></p><p>在不久前Gartner发布的2023年十大战略技术趋势中，元宇宙技术上榜。Gartner 将元宇宙定义为：由虚拟技术增强的物理和数字现实融合而成的集体虚拟共享空间。</p><p></p><p>元宇宙火爆之下，虚拟人作为元宇宙的场景入口与连接纽带也备受瞩关注。艾媒咨询发布的《2022-2023年中国虚拟人行业深度研究及投资价值分析报告》中提到，2020-2021年，虚拟人相关企业数量逐渐呈现快速增长趋势。</p><p></p><p>目前，海内外的厂商正在加快布局虚拟人赛道，尤其是巨头厂商正在占得先机。</p><p></p><p>近两年，知名3D引擎Cocos将“触角”延伸到了虚拟角色领域。Cocos CEO 林顺十分看好元宇宙的发展，他认为元宇宙技术带来的颠覆性改革，或许可以媲美上一个软硬结合的划时代发明 — 互联网。林顺认为，元宇宙有三种呈现形态：虚拟空间、增强现实、平行世界。而不论是哪一种呈现形态，不管是哪一种虚拟世界，都需要一个强大的3D技术作支撑。</p><p></p><p>3D技术正是Cocos的擅长领域，Cocos在该领域已有数年技术积累，凭此入局元宇宙已是水到渠成，Cocos更是直接成立了虚拟角色项目团队。</p><p></p><p>近日，Cocos 虚拟角色项目团队负责人倪飞接受了InfoQ专访，详细介绍了这家老牌3D引擎在虚拟角色构建上的技术创新和应用落地实践。</p><p></p><p>在虚拟数字人产业链中，基础层为其提供必要的软件和硬件支撑；平台层为其制作及开发提供技术，连接技术和服务使之呈现出不同的虚拟人样态；应用层令虚拟数字人在各领域应用实践。</p><p></p><p>倪飞认为，无论虚拟角色未来会发展成什么样的应用形态，其底层是通用的工具化的能力。像Cocos 这样长期致力于工具开发和技术能力赋能的厂商，处在虚拟数字人全产业链中偏工具和服务的环节。Cocos 更擅长做工具赋能，将工具做好赋能给第三方厂商使用。</p><p></p><p>如何在低算力终端中运行虚拟角色，是一个十分复杂的难题，需要专业积淀和积累。凭借过往在渲染层、移动端适配、工具化等方面沉淀多年的丰富技术经验，Cocos 试图让这一问题简单化。而这些经验也成为Cocos进入虚拟角色领域的底气和优势。</p><p></p><p>“面向未来的3D化交互，大致分为人、事物、组织在3D空间里的活动。Cocos 从发散的数字孪生的逻辑，收敛到数字孪生中的“人”的部分，我们团队专注于通过虚拟角色构建来推动数字孪生，以及未来面向未来的3D交互”。</p><p></p><h2>如何创建一个全周期的虚拟角色？</h2><p></p><p>基于沉淀多年的引擎底层技术能力和与开发实践经验，Cocos为开发者提供了多个低门槛、高效率、跨平台的虚拟内容生产工具，降低整个生产链路和实际发布链路的成本和门槛，为行业提供覆盖虚拟角色创作、使用全生命周期的虚拟角色产品线。</p><p></p><h3>自研多项虚拟角色编辑工具</h3><p></p><p>如何既能让虚拟角色动起来，又具有性格，且能够跨平台进行交互，具有相当高的技术门槛，Cocos 希望用自身擅长的工具化能力将技术门槛降下来。</p><p></p><p>针对虚拟角色制作，目前Cocos 已自研了Cocos Creator、Cocos&nbsp;Persona&nbsp;Editor&nbsp;编辑器、Cocos&nbsp;Avatar&nbsp;SDK等多款虚拟角色编辑工具。</p><p></p><p>Cocos 认为，虚拟角色涵盖的范畴大于数字人。目前，整个虚拟角色行业分布的大类是写实、卡通和二次元，其中，写实虚拟数字人是当下的主流方向。倪飞介绍，写实数字人、卡通数字人、二次元数字人等人形的角色都是Cocos 的工具支持的方向，希望这些工具能够支持美术创作者自定义生产写实类或卡通类、二次元类的虚拟角色。</p><p></p><p>今年8月，Cocos 发布了Creator 3.6版本，这一版本被官方称为是 Cocos 近两年来最重要的版本，在画面渲染、性能、原生化、编辑器优化等方面都做了大幅进化。在3.6 版本中，引擎在 3D &amp; 2D 开发上体验更好、性能更高、效果更出众。</p><p></p><p>倪飞介绍，Creator 3.6版本做了更易用的封装和升级，引入了动画系统，增加了对材质和光照模型进行优化等新功能，这一新版本引擎的发布能够提高虚拟角色的表现效果，让虚拟角色呈现出的光影更加真实。</p><p></p><p>目前，Cocos&nbsp;Persona&nbsp;Editor&nbsp;编辑器，Cocos Avatar SDK正在紧锣密鼓地开发中，预计不久后将正式推出。</p><p></p><p>采访中，倪飞向InfoQ透露了上述工具的一些核心功能。Cocos&nbsp;Avatar&nbsp;SDK的核心逻辑是快速让B端用户拥有创建、操作虚拟角色的能力，SDK已经适配了安卓、iOS 、H5、微信小程序/小游戏端，可以直接嵌入到APP内，实现流量的闭环，为用户提供更好的体验，据悉目前市场上已经有知名APP采用了Cocos的这套SDK逻辑。</p><p></p><p>Cocos&nbsp;Avatar&nbsp;SDK最核心的三个特点是高性能、可热更、易使用。它提供了SaaS化美术素材托管与热更服，通过对“指定素材的分发、热更+SDK展现+编辑器快速编辑”的逻辑，Cocos形成了一个开箱即用的虚拟角色创建、展示能力工具集。不仅能够让传统的软件开发商无需追加3D开发人员即可立即拥有虚拟角色的加载、替换、捏脸、换装、插入视频播放、替换2/3D背景&amp;场景、3D空间音频等能力，而且内置动捕、面捕、WAV口型播报等AI能力，能够接收本地/远程的结构化数据，驱动虚拟人进行表情、动作、口型、特效等表演。</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/c6/62/c624e9eb4301e6f947d28c91ca33ae62.png\" /></p><p></p><p>Cocos 虚拟角色编辑器预览</p><p></p><p>Cocos&nbsp;Persona&nbsp;Editor&nbsp;编辑器的逻辑是，从预制模型到直接输出，内部已预制了多种不同风格的虚拟角色的基础模型，提供了200多个参数，包括脸型、服装、道具、妆容、鞋子、配饰等，用户可以通过预设的参数创建虚拟角色。与创建游戏角色的逻辑类似，通过Cocos&nbsp;Persona&nbsp;Editor&nbsp;编辑器，用户选择想要的美术风格，选择想要的虚拟角色的类型，再进行捏脸，选择动作、表情等，就可以输出一个虚拟角色。</p><p></p><h3>渲染、AI 接入五大关键技术</h3><p></p><p>据悉，目前 Cocos 基于虚拟人已实现了建模、口型、动捕、渲染、AI 接入五大关键技术。</p><p></p><h4>高度自定义角色编辑&amp;AI建模</h4><p></p><p>预置角色模型拥有多达263个脸部、身体调节系数，支持用户自主开发独一无二的虚拟形象。同时 AI 建模技术能让用户利用照片快捷生成真人数字化身。</p><p></p><h4>实时渲染</h4><p></p><p>渲染能力对虚拟角色来说非常重要，这也是Cocos引擎所提供的一项基础能力。</p><p></p><p>渲染分非实时渲染和实时渲染两种逻辑。以前影视剧、动画中逼真、漂亮的虚拟角色，大多是离线，非实时渲染出来的，先给虚拟角色做好3D模型，再在离线渲染器中渲染出来。这类虚拟角色的存储格式是视频，交互较困难，无法做到和人进行交互。</p><p></p><p>如果希望虚拟角色能够像真人一样说话，并展现相应的表情和体态动作，让人觉得是舒服、有温度的交流，这就需要有实时渲染的能力。现在大量数字人应用场景里的虚拟助手、身份IP、偶像IP等，都要求虚拟角色被实时渲染出来，且能够被驱动起来，包括脸部驱动、身体、动作、手势驱动等。让虚拟角色在移动端能够跑起来且能够跟人做实时交互，这也需要用较小的算力把虚拟角色渲染出来。此外，在虚拟角色应用的场景里，如在虚拟角色在元宇宙里开会、办公、展览等，这些场景实现都依赖实时渲染能力。</p><p></p><p>与卡通、二次元类的虚拟角色相比，写实的虚拟角色对渲染管线的要求更高，且需要采用不同的渲染技术，如次表面反射、双向反射分布函数等。Creator 3.6版本在3D画面渲染能力上，重点优化了对3D内容非常重要的材质导入功能与渲染算法，包括了Surface Shader 自定义材质、CSM级联阴影、各向异性光照模型、GGX环境反射卷积图等重点功能。</p><p></p><h4>人物动态捕捉及采集技术</h4><p></p><p>骨骼动画重定向后能让虚拟人拥有无限的动作表现潜能。一张照片、一段视频，无需专业动捕演员，你的虚拟形象便能拥有精彩的动作表现。</p><p></p><p>Cocos 已经实现了用通用摄像头进行中低精度动作捕捉。基于视觉的动作捕捉分为TOF、激光、基于RGB-D摄像头和直接基于普通的RGB的摄像头做形象、图像等信息采集。</p><p></p><p>目前Cocos 正在尝试通过 RGB-D 的摄像头采集数据进行AI训练解决动作捕捉遮挡定位与 3D 空间关系问题。基于 AI 训练能够自动补全视觉当中图像未可见部分的手部、脚部等 3D 空间位置，自动预判躯干前后遮挡关系。</p><p></p><h4>面部系统捕捉技</h4><p></p><p>Cocos 实现了高精度实时表情捕捉技术，利用大量视频数据来训练模型，最终产生高质量的连续变形体（Blendshape）权值输出，用于驱动完整的虚拟角色，实时表情捕捉效果与离线效果相近，可实现高精度捕捉。</p><p></p><p>基于人工标注的脸部数据、拟真的渲染数据进行机器学习训练，将采集到的语音播报和人脸数据进行学习后，输出学习模型，实现面部捕捉。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/0d/36/0de69e06e9e6a5f03ab8e23e934ac736.gif\" /></p><p></p><p>Cocos 虚拟角色面部捕捉技术演示</p><p></p><h4>口型驱动技术</h4><p></p><p>语音口型驱动是通过对音频中的音素进行识别，通过大量的数据 AI 训练模型，以 mesh 变换的形式驱动 3D 人物口型，从而达到高拟真语音播报。</p><p></p><h4>AI 骨骼绑定技术</h4><p></p><p>完善的骨骼标准及骨骼重定向是驱动人物的关键，丰富的动作库能够快速提升制作效率。</p><p></p><p>当前 Cocos 正在内部测试可视化的人体骨骼快速绑定功能，实现导入模型与标准骨骼的快速绑定，从而快速适配 Cocos 动作库中的动作，驱动人物在相关场景中使用。</p><p></p><h3>针对解决虚拟角色构建难点，面向移动端发力</h3><p></p><p>超写实虚拟人的一大特点就具有类人的外观，业内很多虚拟人产品尤其是虚拟偶像都被赋予了超高的颜值，而且在五官、皮肤等方面十分逼真，例如发丝都清晰可见。但类人程度越高，算力就是一大难点。</p><p></p><p>在传统的虚拟角色生产逻辑中，一个虚拟角色模型四面导出后，可能光头发就几千万面。在手机端，很难有如此庞大的算力可以带动几千万面的头发实现“丝毫毕现”的飘动效果。</p><p></p><p>倪飞表示，针对这一难题，Cocos现在集中在移动端发力，在移动端做了大量的技术优化，采用“面片”的逻辑将虚拟角色的头发输出，从而实现了飘动、毫发毕现等头发细节的生动展现，支持按照不同性能机型，选择虚拟角色渲染策略。当前虚拟角色已经能够在手机端进行下图级别卡通写实人物的实时渲染，在骁龙865机型上保持30万面左右 60FPS 的同时，进行面捕捕捉和捏脸换装。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/ea/04/ea23d20232f8821bb5688caee4f92b04.gif\" /></p><p></p><p></p><p>倪飞提到，除了头发，服装的飘动、仿真也是业界的一大痛点。如何让服装动起来，例如在虚拟角色跳舞时实现裙子飘动，这类基础问题在业内已有各种实现方案。但让虚拟角色的服装呈现出纯物理世界的形态，逼真地将真实世界中衣服的动态还原出来，当下还是一个很难实现的问题，尤其在移动端的实现格外困难。</p><p></p><p>接下来，Cocos还将在移动端上持续发力，让开发者不仅可以创造足够逼真的 3D 形象，而且能在最小的算力范围内，达到最优的虚拟人效果，实现覆盖大多数低算力设备及操作系统。</p><p></p><h2>虚拟人应用和规模化落地</h2><p></p><p></p><h3>支持企业按需定制虚拟人</h3><p></p><p>针对不同行业对虚拟人的差异化需求，Cocos推出了可快速接入的Cocos&nbsp;Avatar&nbsp;SDK，以及虚拟角色编辑器Cocos&nbsp;Persona&nbsp;Editor，支持企业“按需定制”虚拟人，并为企业提供标准化的服务，帮助其降低时间成本和制作成本。企业可以标准化地生产自己需要的虚拟角色，并将其应用到相应的场景中去。</p><p></p><p>在实际的落地项目中，Cocos多样化的功能支持能帮助虚拟人拓宽更多使用场景，比如Cocos支持灵活加载视频，搭配虚拟角色，能很好满足线上会议、文旅游览等场景需求。又比如，Cocos还支持对本地渲染结果反向进行纹理输出，能够实现一次输出视频、满足多端使用，大大提升了效率。同时，Cocos 支持热更新及按需分包远程加载，保证 SDK首包足够小，有效提升了各个场景中用户的浏览体验与留存率，这样可以让虚拟人更好地跑在各种终端上。</p><p></p><p>据了解，Cocos正在与一些厂商合作，助其实现虚拟数字人应用落地。例如，Cocos与声网就虚拟人项目达成合作，共同搭建SDK，推出了功能丰富的元娱乐解决方案，帮助开发者集成后完成自己的内容创作。而在百度元宇宙解决方案“希壤Lite\"里面，则整套技术都是采用Cocos的方案。</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/ef/4b/ef135d4e36143fc087447ce4d2yy294b.png\" /></p><p></p><p>希壤Lite</p><p></p><p>值得注意的是，当下，应用场景受限是当前虚拟数字人在应用过程中存在较为普遍的一个问题。</p><p></p><p>“我们目前看到的客户两三年以前就有做虚拟角色的了，但做完虚拟角色之后他们也在发愁—— 做了一个超写实的虚拟角色，买了七八万的设备，就只是在发布会上用一下，其他地方用不了。这个虚拟角色到底能干嘛？他们也挺愁的”。</p><p></p><p>倪飞表示，对于这些用户的痛点，Cocos给出的解法是，让这些虚拟角色在Cocos的引擎里做二次加工，让它的效果在基本保持一致的情况下，能在移动端、计算类端、小程序端，小游戏端跑起来。再往后可以架设自己的角色服务能力。例如，可以让虚拟角色具备对话能力，成为虚拟客服。或者，让虚拟角色后面接中之人，让它具备直播的能力。或者，让虚拟人直接运行在电视大屏幕、投影屏幕等，让虚拟角色在应用场景中与人类用户沟通交流；或者应用在车机场景，将虚拟角色与车机内的系统深度绑定，让它担任车内的智能助手等。</p><p></p><p>“这都是现在行业里已经存在的逻辑，只是看厂商有多大的投入决心，愿意投入多少技术去解决这类问题”，倪飞说，“现在已经看到一些服装厂商对虚拟角色表现出了较大的兴趣和偏好”。</p><p></p><h3>批量化生产未来会成为普遍现实</h3><p></p><p>倪飞认为，尽管每家厂商在虚拟人制作上的逻辑不完全一致，但未来，虚拟角色的生产将成为非常普遍的现象，无论批量生产是基于现有素材的重组，还是基于AI生成，还是基于条件的，抑或是基于其他的逻辑。</p><p></p><p>“批量生产，本质上是未来的一个通用的需求。之所以是一个通用的需求,是因为我们需要在各种场景里去丰富“路人甲乙丙丁”，以让整个虚拟世界里，看起来是更拟真的”。</p><p></p><h3>虚拟角色的商业化已在进行中</h3><p></p><p>可以看到，虚拟数字人已经被应用在各种应用场景中。</p><p></p><p>现阶段，虚拟数字人还在发展的早期，谈商业化还为时尚早。但根据倪飞的观察，业内已有一些提供数字人服务的团队，实现了小规模盈利。此外，在数字人的制作环节，原先做2D动画的厂商在转向做3D动画后，生产流程发生了很大改变，生产效率也大幅提升。</p><p></p><p>有人认为，虚拟数字人将是元宇宙率先实现盈利的领域。倪飞认为，虚拟角色将会是未来元宇宙里基数最大的，也是最通用的一个领域。因为，未来，每个人都会有自己的虚拟化身，如果未来信息交互的入口发生了改变，由原来的文字变成形象、语音、图片、视频推送的交互的流，虚拟数字人在所有的应用领域都会存在，到时候它将变成一个非常基础的应用。</p><p></p><p>倪飞认为，当虚拟人成为所有应用领域的基础形象后，在虚拟人之上，一定会产生新的与之强相关的业务，例如，在各个应用间的虚拟角色可能会产生联通互动的社交需求等。这些都蕴含着潜在的机会和商业价值。</p><p></p><p>采访嘉宾介绍：</p><p></p><p>倪飞，Cocos 虚拟角色项目总监。2020年加入Cocos团队。擅长数字孪生及大系统构建，致力于工具赋能创作者，实现”有趣地做人，做有趣的人“的产品理念。目前正在带领团队构建Cocos Avatar SDK、Cocos Persona Editor 编辑器、虚拟角色创作社区，为行业提供覆盖虚拟角色创作&amp;使用全生命周期的虚拟角色产品线。</p>",
    "publish_time": "2022-11-28 14:57:56",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "后Kubernetes时代的未来？Wasmer 3.0 发布，可在浏览器外运行 WebAssembly",
    "url": "https://www.infoq.cn/article/xYczhQN4hYdBE0Z7d2wC",
    "summary": "<p>11月23日，Wasmer 3.0 正式发布。作为开源<a href=\"https://www.infoq.cn/article/JgjqtYjuef2VNApb2zok\">WebAssembly (Wasm) </a>\"开源运行时的最新版本，Wasmer 3.0可以将 Wasm 编译为适用于 Windows、Linux 或 Mac 的本机可执行文件，而无需任何运行时依赖。</p><p>&nbsp;</p><p>创始人 Syrus Akbary表示，新版本还能够直接使用“wasmer run”运行 WAPM包，这是一个新重建的 Rust API，并改进了对 WASI的支持，它添加了文件 I/ O 和 WebAssembly 的其他功能，用于在浏览器外运行。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ee/ee5885bb0829b495282f6a7ca8878a5a.png\" /></p><p></p><p>&nbsp;</p><p>Wasmer：从任何语言到任何操作系统</p><p>&nbsp;</p><p>WebAssembly 最初被设计为在 Web 浏览器中，以接近本机的性能，安全地运行以其他语言（例如 C/C++）编写的代码。2015年，Luke Wagner在自己的Mozilla博客上发布了一条公告：“我很高兴向大家报告，我们在Mozilla开始跟Chromium、Edge和WebKit的工程师们合作创建新的标准——WebAssembly。它定义了一种可移植，而且尺寸和加载效率更高的格式与执行模型，专供Web编译场景使用。”</p><p>&nbsp;</p><p>随后，在W3的协助下，核心Wasm规范已经被列为“推荐”项目，且各大主流浏览器也都为其提供支持。并且多数语言都已经能够支持Wasm。Wasm在浏览器领域取得了成功，也拥有了Adobe和Figma等体量可观的采用者。但在此期间，Wasm在浏览器之外的优势也被越来越多的人所注意。对于Wasmtime、Wamr、Wasm3、WasmEdge和Wasmer等采用Wasm格式的非浏览器运行时，其一方面展示了Wasm规范的灵活性，比如把Wasm3当成解释器来执行；另一方面则能支持JIT和AOT编译，外加各种缓存及优化功能。</p><p>&nbsp;</p><p>虽然Wasm在浏览器中高度依赖于JavaScript和Wasm运行时之间的桥梁，但非营利性组织字节码联盟（Cosmonic、Fermyon和Suborbital等都是其成员）一起参与研发，希望为Wasm引入系统绑定。Wasm系统接口（WASI）就是典型案例，其添加了能够与文件系统、环境变量、时钟和随机数生成器等系统资源进行交互的标准化支持。</p><p>&nbsp;</p><p>在这过程中，已经有很多人认为Wasm 的未来就在于能在浏览器之外运行它。Fermyon的CEO <a href=\"https://www.linkedin.com/in/mattbutcher/\">Matt Butcher</a>\"（软件工程师、前教授，以及包含Helm在内的数十个开源项目的创始成员） 认为，Wasm像虚拟机和容器一样，能够在云中运行，这才是真正令人兴奋的地方。Wasm代表了云原生技术的新时代，“我们喜欢容器。我们中的许多人多年来一直参与Kubernetes生态系统。但我们也很兴奋，因为在容器生态系统中有些没有解决的问题，现在我们正在找到解决方案。这就是为什么我们将其视为下一波浪潮。”</p><p>&nbsp;</p><p>如今的新生标准已经让Wasm能够在浏览器之外发挥作用。很多Wasm项目的创建者/维护者对此感受非常积极：凭借着与浏览器高度匹配的各种特性，Wasm在浏览器之外更有种“广阔天地、大有作为”的意味。作为多个最大开源Wasm项目的创建者/维护者，Matt Butcher等人发表了一篇<a href=\"https://www.wasm.builders/thomastaylor312/why-webassembly-belongs-outside-the-browser-331a\">技术博客</a>\"，从多个积极的角度讲解了为什么他们认为“Wasm适用于浏览器，更适用于云”。</p><p>&nbsp;</p><p></p><h2>适用于浏览器，更适用于云</h2><p></p><p>&nbsp;</p><p>网络浏览器中的语言运行时必须满足几大特征，而这些特征在云端也同样非常重要。</p><p>&nbsp;</p><p>安全性：如果要在浏览器中运行不受信代码，则需要确保它是独立运行的。这一点在云端也同样适用。跨平台/跨架构：当我们为浏览器构建代码时，当然希望能一次编写、随处运行。这一点在云端也同样适用。多语言：Wasm项目的一大目标，就是将浏览器扩展到多种语言。云开发还不像浏览器开发那样以JS为中心，所以多语言支持可以说是个必要前提。速度：没人愿意坐等网页加载，云端同样如此。只有实现了即时加载，才能进行快速扩展。效率：浏览器在功耗方面需要控制好自己的“胃口”，云基础设施也是一样。运行时效率越高，运营成本也就越低。代码大小：下载快慢，很大程度上取决于我们要下载怎样的对象。较小的二进制文件下载得快，这类对象在云端也能够更快移动。</p><p>&nbsp;</p><p></p><h3>安全性</h3><p></p><p>云软件运行中的一大难题，就是了解其安全属性、攻击面和如何保障组织安全。当前供应链暴露出的安全漏洞以及未打补丁的遗留操作系统，已经给企业造成数十亿美元损失和无法估量的业务时间拖延。</p><p>&nbsp;</p><p>而Wasm的一大重要目标就是提供一个简单、易于理解的表面区，确保代码能够在沙箱内执行，充分考虑到攻击者从外而内或由内而外可能采取的一切基础设施危害方法。Wasm这种强制在沙箱内运行代码、再与沙箱外操作系统交互的办法，被具体拆分成了一个个精细的启用选项。宏观来看，我们可以在启动时，将Wasm字节码中所执行的每个“系统调用”都提供给运行时的一组函数处理。</p><p>&nbsp;</p><p>如此一来，如果大家希望禁用文件系统访问、网络访问、甚至是系统时钟访问，都可以随时变更主机函数集来实现。再与具备边界检查的线性程序内存相结合，我们就得到了一个能够执行任意不受信代码的容器，其简单性与攻击面受控性都远远优于传统的虚拟机和容器安全模型。</p><p>&nbsp;</p><p>在现实世界中，这相当于是给操作人员提供一个能够安定运行不受信代码的执行环境。我们可以在这里测试未经审核的第三方依赖项，或者用户提交的代码（例如插件和用户定义函数，简称UDF）。对于用户可以上传软件扩展代码的情况，大家肯定不敢贸然把这些提交内容直接运行在基于容器的平台上，毕竟其中还是有很大的内部基础设施接触和损害空间。</p><p>&nbsp;</p><p>另外，我们还要考虑到用于执行用户代码的基础容器镜像可能包含漏洞，因此当需要对数百、数千甚至更多用户提交的容器打补丁并进行操作系统重构时，这必然会造成巨大麻烦。通过从运行程序中删除大部分“类操作系统”元素，Wasm提供了一个更可控、更易于理解的底层基础，帮助用户在此之上构建起安全的代码运行环境。</p><p>&nbsp;</p><p></p><h3>跨平台/跨架构</h3><p></p><p>Wasm最受欢迎的特性，应该就是突出的平台与架构中立性了。更重要的是，Wasm的强大已经远远超出了JVM之类“一次编译、随处运行”的想象。这里我们以组件模型为例，其允许开发人员编写代码并将其API导出为接口。假设我们打算使用密钥库，而密钥存储的接口可能如下所示：</p><p>set: func(key: string, value: payload, ttl: option) -&gt; expected</p><p>get: func(key: string) -&gt; expected</p><p>delete: func(key: string) -&gt; expected</p><p>&nbsp;</p><p>如果我们想要实现一个密钥库，当然可以用任何语言来编写（示例中使用的就是Go），而且只要导出到这个接口，就能将其编译成Wasm模块。之后，另一位想要使用这个实现的开发者可以用另一种不同的语言编写代码，并继续使用我们用Go编写的键值实现。从本质上讲，这就相当于提供了一个通用库或依赖项注册表，能够根据各个具体用例的需要组合起来。因此，大家不必为每种语言建立单独的客户端库，而是实现一次编写、随意“组合”。无论大家使用哪种语言、平台或者架构，共享和协作都将变得轻松而顺畅。</p><p>&nbsp;</p><p>Matt Butcher等人认为，除了Wasm的跨平台/架构可组合性之外，它还特别适合在后Kubernetes时代下作为运行时方案。“我们知道这个观点可能有点激进，但人们会很快意识到，Kubernetes和容器技术的拓展边界已经快到头了。没错，我们总会说容器可以‘随处运行’，但扪心自问，大家都知道这个结论有待商榷。为了支持不同的平台，我们需要为每个平台+架构组合构建不同的镜像。此外，容器其实是一种Linux技术。没错，也有一些特别聪明的贡献者让Windows也获得了容器，但这已经是套完全不同的技术方案了（无法直接运行Linux容器，常规容器平台也没法直接运行Windows容器）。”</p><p>&nbsp;</p><p>另外，容器运行时的开销并不小（特别是在Kubernetes的时候），所以很难在边缘位置广泛应用。最重要的一点，容器还需要不断支持越来越多的定制化处理器。可以看到，Wasm简直堪称完美的解决方案——它具备明显的平台和架构中立性，代码体积小，代码既可以直接运行在大型云服务器上、也能在边缘位置的微型设备中起效，而且无需任何重新编译。</p><p>&nbsp;</p><p>Matt Butcher等人承认容器在云过渡时期带来的种种便利，但也坚持Wasm才代表着后Kubernetes时代的未来形态。</p><p>&nbsp;</p><p></p><h3>多语言支持</h3><p></p><p>我们知道，Wasm的另一大关键特性就是支持多种语言。由于Wasm代表一个编译目标，所以只要你使用的语言支持Wasm就可以了。有些语言的Wasm支持来得较早，有些稍微晚些，但目前大部分语言都已经开始甚至完成了这项工作。总之，开发者可以用不同的语言编写同一应用程序内的各个服务、甚至是各个部分。这就是组件模型的威力所在！</p><p>&nbsp;</p><p>对此，Matt Butcher等人再放豪言：“我们认为，Wasm有可能会成为最后一种插件模型”。截至目前，为任何工具编写插件都是种痛苦的体验。大家要么必须使用相同的语言编写，要么得设置某种通信协议（例如gRPC），要么使用某种商定的stdin/stdout合约输出二进制文件。这些选项局限性强、效率也不高。而使用Wasm，插件可以用任意语言编写、再编译成Wasm。之后，该Wasm模块就能作为插件模型的一部分由任何其他语言执行——无需劳烦shell、也不必跨进程通信。最重要的是，Wasm还有速度和大小优势。</p><p>&nbsp;</p><p></p><h3>速度</h3><p></p><p>让公有云成为可能的关键支持技术，其一是虚拟机，其二是容器。二者都是在计算世界中占有一席之地的伟大技术，但却不可能是满足一切云需求的至高“银弹”。当在资源受限或者使用率极高（例如边缘计算、物联网或规模巨大的数据处理集群等场景）的条件下运行代码时，虚拟机和容器其实会阻碍我们充分发掘硬件性能的能力。</p><p>&nbsp;</p><p>而Wasm在多数情况下都能提供相同或更高的隔离保障，让我们能够安心剔除虚拟机和容器的底层“公有云安全网”，更好地使用运行代码的服务器和设备。由于Wasm是一种低级字节码，所以可以编译并支持任何硬件架构、任何操作系统，因此我们完全能够，也应该直接在裸机上运行Wasm。这样就能把工作负载更紧密地打包至可用硬件，并在性能、能源效率、环境影响等方面迎来新的飞跃。</p><p>&nbsp;</p><p>这些性能优势在云功能等临时性工作负载中体现得尤其明显。由于Wasm运行时及其加载的代码，通常要比等效的容器镜像或虚拟机小一个数量级（甚至更多），所以可以通过更高的复制量快速实现启动和终止。在大部分云部署场景下，这些都是很重要的特性，能够更灵活地部署软件以应用流量高峰，进一步扩展来消化总流量波动。而且Wasm模块实际上只是个程序，绝非操作系统中的容器或虚拟机，因此主机操作系统的控制和硬件优化机制也能高效利用多核心架构，同时继续保持工作负载间的强隔离。</p><p>&nbsp;</p><p></p><h3>大小和效率</h3><p></p><p>在目前的大部分用例中，我们其实都在过度消耗云资源。我们得准备充足的副本来满足峰值负载要求，而这些副本在大多数时间里都处于闲置状态，平白浪费资源。同样的，由于我们需要针对超高需求进行优化，所以也得分配比必要水平更多的CPU、内存和存储空间，以便随时应对流量高峰。承担这么多浪费的理由只有一个：目前的解决方案无法实现快速扩展。</p><p>&nbsp;</p><p>Wasm的大小和效率优势，让快速扩展成为了可能。我们几乎可以立即扩大规模，再轻松缩减回正常水平。我们可以在整个数据中心或集群内安装同样的小规模Wasm模块，并在需求出现之前不实际执行。这样，我们就能省下副本资源，保证只在必要时才把宝贵的资源拿出来。</p><p>&nbsp;</p><p>而有了JIT/AOT运行时，我们还能对Wasm二进制文件进行执行预优化，进一步减少电力和资源消耗。</p><p>&nbsp;</p><p>在多数场景下，需要处理的系统库和文件工件数量也显著减少，因此我们实际处理的对象大小要比容器时代小得多。</p><p>&nbsp;</p><p>总而言之，所有这一切都指向了Wasm在云端的核心优势：比其他云服务更低的运行成本。虽然Wasm还很年轻、还需要完善，但它提供的种种可能性已经非常有吸引力，如果社区发展更为壮大，Wasm最终会发展出更美好的未来图景。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://wasmer.io/posts/announcing-wasmer-3.0\">https://wasmer.io/posts/announcing-wasmer-3.0</a>\"</p><p><a href=\"https://devclass.com/2022/11/25/wasmer-3-0-released/\">https://devclass.com/2022/11/25/wasmer-3-0-released/</a>\"</p><p><a href=\"https://wasmer.io/posts/wasm-as-universal-binary-format-part-1-native-executables\">https://wasmer.io/posts/wasm-as-universal-binary-format-part-1-native-executables</a>\"</p><p><a href=\"https://thenewstack.io/whats-next-in-webassembly/\">https://thenewstack.io/whats-next-in-webassembly/</a>\"</p><p><a href=\"https://www.wasm.builders/thomastaylor312/why-webassembly-belongs-outside-the-browser-331a\">https://www.wasm.builders/thomastaylor312/why-webassembly-belongs-outside-the-browser-331a</a>\"</p>",
    "publish_time": "2022-11-28 20:12:23",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]