[
  {
    "title": "Visual Studio 17.7预览版：插件管理器和HTTP编辑器改进，与VSCode功能相比仍有差距",
    "url": "https://www.infoq.cn/article/I7ThoMmKYVF1wiZFWEXj",
    "summary": "<p>微软发布了<a href=\"https://learn.microsoft.com/en-us/visualstudio/releases/2022/release-notes-preview#17.7.0-pre.3.0\">Visual Studio 2022 17.7的第三个预览版本</a>\"。预览版本 3带来了一系列的改进和新特性，旨在提高开发人员的生产力，并帮助维护简洁的代码。预览版本3重点是为C++开发人员提供了一个名为#includes cleanup的新工具。<a href=\"https://visualstudio.microsoft.com/vs/preview/\">最新版本已经可以下载</a>\"，开发人员可以在预览版本中探索并利用它的最新进展。</p><p></p><p>预览版本3为C++、生产力、.NET和云开发、Microsoft 365开发和Teams工具包以及SQL Server Data Tools等多个领域带来了更改和改进。</p><p></p><p>作为最大的新闻，最新的更新引入了一个令人兴奋的新特性，称为“包含清理”（Include Cleanup）功能。这个有价值的工具为开发人员提供了在检测到间接包含时添加直接包含的建议，以及识别可以安全删除的任何冗余包含。值得注意的是，该功能在默认情况下处于禁用状态，以确保开发人员可以控制它的使用。为了利用它的优势，用户可以通过导航“工具”&gt;“选项”&gt;“文本编辑器”&gt;“C/C++”&gt;“IntelliSense”并选择“启用#include cleanup”选项来轻松地启用它。</p><p></p><p>在有关#include工具的<a href=\"https://devblogs.microsoft.com/cppblog/include-cleanup-in-visual-studio/\">原始博客文章</a>\"中，C++项目经理Mryam Girmay指出：</p><p></p><p></p><blockquote>……该功能通过生成删除未使用的头文件和添加直接头文件的建议来提高代码的质量。我们建议的工作流程是首先执行直接包含建议，在使用间接头文件的地方添加直接头文件，然后删除未使用的包含。</blockquote><p></p><p></p><p>对于C++和预览版本3，最新的更新还引入了对<a href=\"https://learn.microsoft.com/en-us/cpp/sanitizers/asan?view=msvc-170\">Address Sanitizer</a>\"支持的扩展，现在提供了continue_on_error模式。该运行时功能实现了对隐藏内存安全错误的实时检测和报告，并且零误报。开发人员可以通过为stdout设置ASAN_OPTIONS=continue_on_error=1或为stderr设置ASAN-OPTIONS=continue_on_eerror=2来将其集成到工作流中。该更新增强了应用程序的可靠性，并提供了更安全的代码库。</p><p></p><p>对于开发人员的<a href=\"https://learn.microsoft.com/en-us/visualstudio/releases/2022/release-notes-preview#productivity\">生产力</a>\"，体现在解决方案资源管理器中，在上下文菜单中添加了一个新的“折叠所有子节点”命令，使用户可以折叠选定的节点及其子节点。这也可以通过Ctrl+Left快捷键来实现。</p><p></p><p>此外，<a href=\"https://learn.microsoft.com/en-us/visualstudio/ide/finding-and-using-visual-studio-extensions?view=vs-2022\">扩展管理器</a>\"也进行了更新，以简化从Visual Studio Marketplace中发现和管理扩展的过程，从而更容易地更新现有的扩展。开发人员可以通过启用“工具”&gt;“选项”&gt;“环境”&gt;“预览功能”下的“扩展管理器UI刷新”预览功能来访问现代扩展管理器。</p><p></p><p>此外，最新版本还对<a href=\"https://learn.microsoft.com/en-us/visualstudio/releases/2022/release-notes-preview#net-and-cloud-development\">HTTP编辑器</a>\"进行了显著的改进。其中包括添加了一个新的响应视图，该视图支持JSON高亮显示。现在，开发人员可以很容易地检查原始响应、请求标头以及发送到Web服务器的请求。此外，用于发送请求的绿色播放按钮已被代码镜头操作所取代，从而简化了开发过程。</p><p></p><p>同样，开发人员现在可以利用Microsoft Power Platform的连接服务支持。正如发布文章中所报道的：你可以创建一个到Power Platform环境的自定义连接器，并创建一个开发隧道来本地测试和调试Web API项目。</p><p></p><p>其他更改则与Microsoft 365开发有关：Teams Toolkit现在提供了简化的Teams Tab应用程序模板。这个版本还包括缺陷修复和UI改进，增强了用户体验。此外，在<a href=\"https://learn.microsoft.com/en-us/visualstudio/releases/2022/release-notes-preview#ssdt-sql\">SQL Server Data Tools</a>\"中，最新的更新解决了将Azure Interactive Dir用于<a href=\"https://visualstudio.microsoft.com/vs/debug-in-azure/\">Azure Debugger</a>\"时的发布问题。此外，Target平台对SQL Serverless的命名已更改为<a href=\"https://learn.microsoft.com/en-us/azure/synapse-analytics/sql/on-demand-workspace-overview\">Azure Synapse Analytics Serverless SQL Pool</a>\"。</p><p></p><p>微软和开发团队<a href=\"https://developercommunity.visualstudio.com/VisualStudio/suggest\">鼓励用户提供反馈意见，并分享了他们对新功能和改进的建议</a>\"，强调了他们将致力于不断增强Visual Studio的体验。最后，有兴趣了解更多关于该版本和其他Visual Studio版本信息的开发人员可以访问有关Visual Studio 2022 IDE的其他更新，这些更改和新功能有<a href=\"https://learn.microsoft.com/en-us/visualstudio/releases/2022/release-notes-preview#1770-pre30--visual-studio-2022-version-177-preview-3\">非常详细的发布说明</a>\"。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/07/vs2022-v17-7-preview-3/\">https://www.infoq.com/news/2023/07/vs2022-v17-7-preview-3/</a>\"</p>",
    "publish_time": "2023-08-23 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "我们如何训练和应用大模型 | InfoQ《极客有约》",
    "url": "https://www.infoq.cn/article/5ZglMYd9IuxRQSXpAw2O",
    "summary": "<p>本期《极客有约》我们和数禾科技AI技术总监杨春勇聊聊如何解决模型计算底层应用的资源处理问题。</p>",
    "publish_time": "2023-08-23 09:10:18",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "混合精度下位置编码竟有大坑，llama 等主流开源模型纷纷中招！百川智能给出修复方案",
    "url": "https://www.infoq.cn/article/OcjyhximVsWg4o5rboDB",
    "summary": "<p>位置编码技术是一种能够让神经网络建模句子中Token位置信息的技术。在Transformer大行其道的时代，由于Attention结构无法建模每个token的位置信息，位置编码（Position Embedding)成为Transformer非常重要的一个组件。研究人员也提出了各种各样的位置编码方案来让网络建模位置信息，RoPE和 Alibi 是目前最被广泛采纳的两种位置编码方案。</p><p></p><p>然而最近来自百川智能的研究发现，RoPE和Alibi位置编码的主流实现在低精度（尤其是bfloat16)下存在位置编码碰撞的bug, 这可能会影响模型的训练和推理。而且目前大部分主流开源模型的实现都存在该问题，连llama官方代码也中招了。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/01eb204f519f1a3bbba3a2baf9da6393.png\" /></p><p></p><p></p><h2>还得从位置编码算法说起</h2><p></p><p></p><p>为了弄清楚这个问题，得先从位置编码的算法原理说起，在Transformer结构中，所有Attention&nbsp;Block的输入都会先经过位置编码,&nbsp;再输入网络进行后续处理。纯粹的Attention结构是无法精确感知到每个token的位置信息的，而对于语言的很多任务来说，语句的顺序对语义信息的影响是非常大的，为了建模token之间的位置关系，Transfomer原始论文中引入位置编码来建模位置信息。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/32/32967120b3070d35d0830e26c0a53dda.png\" /></p><p></p><p>图1-施加&nbsp;Positon&nbsp;Embedding&nbsp;示意图&nbsp;</p><p></p><p>为了让模型更好地建模句子的位置信息，研究人员提出了多种位置编码方案，Meta开源的llama模型采用了RoPE方案，使得RoPE成为在开源社区被广泛采纳的一种位置编码方案。Alibi编码也因为其良好的外推性也被广泛应用。</p><p></p><p>了解低精度下的位置编码碰撞之前，先来回顾一下相关算法原理</p><p></p><p>Sinusoidal位置编码</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e6/e61da7251a4b186b24da63f661606860.png\" /></p><p></p><p>这是Transformer原始论文中提出的位置编码方法。它通过使用不同频率的正弦和余弦函数来为每个位置产生一个独特的编码。选择三角函数来生成位置编码有两个良好的性质：</p><p></p><p>1）编码相对位置信息，数学上可以证明&nbsp;PE(pos+k)&nbsp;可以被&nbsp;PE(pos)&nbsp;线性表示，&nbsp;这意味着位置编码中蕴含了相对位置信息。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8e/8ee749ad80cc5f5e3c30415e3844fa23.png\" /></p><p></p><p>图2-句子长度为50的位置编码，编码维度128，每行代表一个Position&nbsp;Embedding</p><p></p><p>2）远程衰减：不同位置的position&nbsp;embedding点乘结果会随着相对位置的增加而递减。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/79/79dc2b1e8b3fe6bb3407c0de70363015.png\" /></p><p></p><p>图3-不同位置的位置编码点积可视化</p><p></p><p></p><h3>RoPE</h3><p></p><p></p><p>RoPE是目前开源社区应用最广泛的一种位置编码方案，&nbsp;通过绝对位置编码的方式实现相对位置编码，在引入相对位置信息的同时保持了绝对位置编码的优势（不需要像相对位置编码一样去操作Attention&nbsp;matrix)。令f_q,&nbsp;f_k&nbsp;为&nbsp;位置编码的函数，m表示位置,&nbsp;x_m&nbsp;表示该位置token对应的Embedding，希望经过位置编码后的Embedding&nbsp;点积仅和相对位置有关，则可以有公式</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f5/f559cabec80db456783b14b9f0fa03a9.png\" /></p><p></p><p>上面公式中g是某个函数，表示内积的结果只和x_m&nbsp;和&nbsp;x_n的值，以及二者位置的相对关系(m-n)有关在2维的情况下可以推导出（详细推导过程可参考原论文）：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9b/9bc0d18dbe8c0b452d5ac76a68a7435c.png\" /></p><p></p><p>因为矩阵乘法线性累加的性质，可以拓展到多维的情况可得：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f9/f938a63197c2e3d5ff64bc304631904c.png\" /></p><p></p><p>为了引入远程衰减的特性，Rope中\\theta的选取选择了Transformer&nbsp;原始论文中&nbsp;sinusoidal&nbsp;公式。</p><p></p><p></p><h3>Alibi</h3><p></p><p></p><p>Alibi是谷歌发表在ICLR2022的一篇工作，Alibi主要解决了位置编码外推效果差的痛点，算法思想非常的简单，而且非常直观。与直接加在Embedding&nbsp;上的绝对位置编码不同，Alibi的思想是在&nbsp;Attention&nbsp;matrix上施加一个与距离成正比的惩罚偏置，惩罚偏置随着相对距离的增加而增加。在具体实现时，对于每个head会有一个超参m&nbsp;来控制惩罚偏置随着相对距离增加的幅度（斜率）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b9/b9cce5a91e59e333c7848d019d4a9952.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/68/68a563c092f6706d27f8a3716055f91b.png\" /></p><p></p><p>图4-Alibi&nbsp;attention&nbsp;bias示意图</p><p></p><p>论文结果显示Alibi&nbsp;极大的提升了模型的外推性能，16k&nbsp;token&nbsp;的输入依然可以很好的支持</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e9/e9a2eac6f89e8a81b85c0d148ca0fa48.png\" /></p><p></p><p>图5-Alibi&nbsp;外推效果对比</p><p></p><p></p><h2>混合精度下位置编码的bug</h2><p></p><p></p><p>从上面的算法原理中，不管是RoPE&nbsp;的&nbsp;cos(m&nbsp;\\theta)&nbsp;还是alibi&nbsp;的&nbsp;i-1（m,&nbsp;i&nbsp;代表postion&nbsp;id),&nbsp;都需要为每个位置生成一个整型的position_id,&nbsp;在上下文窗口比较大的时候，百川智能发现目前主流的位置编码实现在混合精度下都存在因为低精度（float16/bfloat16)浮点数表示精度不足导致位置编码碰撞的问题。尤其当模型训练（推理）时上下文长度越来越长，低精度表示带来的位置编码碰撞问题越来越严重，进而影响模型的效果，下面以bfloat16为例来说明这个&nbsp;bug</p><p></p><p></p><h3>浮点数表示精度</h3><p></p><p></p><p>浮点数在计算机中表示由符号位（sign)，指数位(exponent)，尾数位(fraction)&nbsp;三部分组成,&nbsp;对于一个常规的数值表示，可以由如下公式来计算其代表的数值（其中offset是指数位的偏置）：(−1)sign∗2exponent−offset∗&nbsp;1.fraction由公式可知，尾数位的长度决定了浮点数的表示精度。深度学习中常用的&nbsp;float32/float16/bfloat16&nbsp;内存中的表示分别如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/99/99761418655f97e1ce8dd09e74febf3f.png\" /></p><p></p><p>图6-bfloat16&nbsp;的表示格式</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4b/4b96eb4bcf849b0ec99b48d53e951c86.png\" /></p><p></p><p>图7-float16&nbsp;的表示格式</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b5/b564ac3629f0eaf1478457c3b55558ec.png\" /></p><p>图8-float32&nbsp;的表示格式</p><p></p><p>可以看到可以看到float16和bfloat16相比于float32都牺牲了表示的精度，后续以bfloat16为例说明位置编码中存在的问题（float16同理）。&nbsp;下表展示了bfloat16在不同数值范围（只截取整数部分）内的表示精度。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e1/e15867272be48a2f7257420e26b32177.png\" /></p><p>可以看到当整数范围超过256，bfloat16就无法精确表示每一个整数，我们可以用代码验证一下表示精度带来的问题</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d9/d99a9388367466b2bb2117612c06ec05.png\" /></p><p></p><p></p><h3>RoPE&amp;&nbsp;Alibi&nbsp;编码的问题</h3><p></p><p></p><p>Meta开源的llama模型采用了RoPE的位置编码方式，官方的实现（以及大部分的第三方llama系列模型）在bfloat16下存在精度问题带来的位置编码碰撞（不同位置的token在bfloat16下变成同一个数）。llama官方代码如下：</p><p><img src=\"https://static001.geekbang.org/infoq/16/167c35f417e14c767e5bdbc58b6a72e9.png\" /></p><p></p><p>上面第18行核心一句根据输入序列长度生成每个位置的positonidx在bfloat16下产生位置碰撞</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0e/0ea73b01c1f0491280be73cf8940310c.png\" /></p><p></p><p>在实际训练时如果开了bfloat16,self.inv_freq的dtype会被转为bfloat16,我们可以通过简单的代码来看一下位置碰撞的问题</p><p><img src=\"https://static001.geekbang.org/infoq/a1/a15ac096412771b3c4fb02d3d1350e8b.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/58/586c77d014373d36bda4fdf37c9a31ad.png\" /></p><p>图9-bfloat16位置碰撞示意图</p><p></p><p>• 根据bfloat16的表示精度可知，训练（推理）时上下文长度越长，位置编码碰撞的情况越严重，长度为8192的上下文推理中，仅有大约10%的token位置编码是精确的，好在位置编码碰撞有局域性的特质，只有若干个相邻的token才会共享同一个positionEmbedding,在更大的尺度上，不同位置的token还是有一定的区分性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ef/efb63ef90d156427e1741dfd08ae1a04.png\" /></p><p>图10-不同上下文窗口下位置编码精确token所占比例</p><p>&nbsp;</p><p>除了RoPE位置编码方案，百川智能发现Alibi位置编码也存在上述问题，原因依然在于生成整数的位置索引时会在低精度下产生碰撞问题。</p><p>&nbsp;</p><p></p><h2>修复方案</h2><p></p><p></p><p></p><h3>RoPE修复</h3><p></p><p></p><p>￮&nbsp;RoPE的修复相对简单，只需要保证在生成position_id的时候一定在float32的精度上即可。注意：</p><p>▪&nbsp;float32的tensor register_buffer后在训练时如果开启了bfloat16,也会被转为bfloat16</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7f/7fd56c5f08e1acc71d53d345e94385f5.png\" /></p><p></p><p></p><h3>Alibi修复</h3><p></p><p></p><p>￮&nbsp;&nbsp;Alibi位置编码修复思路和RoPE的修复思路一致，但因为Alibi的attention bias直接加在attention matrix上面，如果按照上面的修复思路，attention matrix的类型必须和attention bias一致，导致整个attention的计算都在float32类型上计算，这会极大的拖慢训练速度</p><p></p><p>￮&nbsp;目前主流的attention加速方法flashattention不支持attention bias参数， 而xformers要求attention bias类型必须与query.dtype相同，因此像RoPE那样简单的将attention bias类型提升到float32将会极大的拖慢训练速度</p><p></p><p>￮&nbsp;针对该问题百川智能提出了一种新的Alibi attention方案， 整个attention bias依然在bfloat16类型上，类似于sinusoidal的远程衰减特质，我们尽量保证临近token位置编码的精确性，对于相对距离过远的的token我们则可以容忍其产生一定的位置碰撞。原本的Alibi实现则相反，相对距离越远的token表示越精确，相对距离越近的token则会碰撞</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c3/c3ad25c9614c0ef0c2f996ecd68d3c11.png\" /></p><p></p><p>图11-修复前后alibi attention_bias对照</p><p></p><p></p><h2>修复效果</h2><p></p><p></p><p>•&nbsp;此处仅在推理阶段对位置编码的精度问题进行修复【注：训练阶段可能也存在问题，取决于训练的具体配置和方法】，可以看到：</p><p>a.&nbsp;在长上下文的推理中，模型的ppl要显著优于修复前的ppl</p><p>b.&nbsp;Benchmark上测试结果显示修复前后区别不大，可能是因为benchmark上测试文本长度有限，很少触发Position embedding的碰撞</p><p></p><p></p><h3>Benchmark对比</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/af/af2b0985292e6fbf6546dd096b6e8970.png\" /></p><p></p><p></p><h3>Perplexity对比</h3><p></p><p></p><p>在通用的文本数据上对修改前后模型在中英文文本上的困惑度进行测试，效果如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d7/d7373342af4f4040a601084d01a14626.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/91/917042b5f8ccf7468a7d1699c1b87f96.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/64/6407bfa62d853922a8ad74a2bc40f24a.png\" /></p><p></p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/ff/ff2b53fd120bd9516766844551a24c6e.png\" /></p><p></p><p>&nbsp;</p><p>参考资料：</p><p></p><p>Dongxu Zhang, &amp; Dong Wang. (2015). Relation Classification via Recurrent Neural Network.</p><p>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, &amp; Illia Polosukhin. (2023). Attention Is All You Need.</p><p>Zihang Dai, Zhilin Yang, Yiming Yang, Jaime Carbonell, Quoc V. Le, &amp; Ruslan Salakhutdinov. (2019). Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context.</p><p>Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, &amp; Peter J. Liu. (2020). Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer.</p><p>Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, &amp; Guillaume Lample. (2023). LLaMA: Open and Efficient Foundation Language Models.</p><p>Jianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, &amp; Yunfeng Liu. (2022). RoFormer: Enhanced Transformer with Rotary Position Embedding.</p><p>Ofir Press, Noah A. Smith, &amp; Mike Lewis. (2022). Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation.</p><p>Yutao Sun, Li Dong, Barun Patra, Shuming Ma, Shaohan Huang, Alon Benhaim, Vishrav Chaudhary, Xia Song, &amp; Furu Wei. (2022). A Length-Extrapolatable Transformer.</p><p>https://kazemnejad.com/blog/transformer_architecture_positional_encoding/</p><p>Shouyuan Chen, Sherman Wong, Liangjian Chen, &amp; Yuandong Tian. (2023). Extending Context Window of Large Language Models via Positional Interpolation.</p><p>https://www.reddit.com/r/LocalLLaMA/comments/14lz7j5/ntkaware_scaled_rope_allows_llama_models_to_have/</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-08-23 10:50:59",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "谁说 AI 编程工具缺乏记忆和联想能力，简单琐碎的需求完全可以交给它",
    "url": "https://www.infoq.cn/article/yiLUmJIFFwVKkBmguIpu",
    "summary": "<p>今年算是 AI 正式破圈的一年，无数的工具，产品横空出世。无论在面向企业的大语言模型，还是帮助个人的 AI 工具，数不胜数。其中关于 AI 编程助手领域，近年来也涌现了很多不错的产品，例如 Copilot, Cursor, 还是我们今天要体验的 CodeWhisperer。已经在潜移默化中改变了程序员们的生产和解决问题的方式，传统解决问题往往依靠的是谷歌等搜索引擎，找到对应的官网和知名的论坛查找问题。而如今，我们仅仅依靠 AI 编程助手就能解决很多问题。</p><p></p><p>回到 CodeWhisperer 上来，它的出生还是带着许多光环的。首先来自著名的大厂 Amazon, 他们在 AI 领域有足够多的积累，在面向开发者方面有足够多的经验和产品用户体验来反馈用户感受，不断迭代相关产品，而且还有一个相当强大的优势，借助亚马逊云的力量，能够将 AI 和云打通，这在当前云原生时代是必不可少的能力。</p><p></p><p></p><h2>目标及前期准备</h2><p></p><p></p><p>先给大家讲讲今天我们希望实现的目标，基于 Spring Boot 框架，简单实现用户登陆，。我们使用的是 IntelliJ 开发工具，选用 Maven 进行管理依赖管理，用到的依赖如下。</p><p></p><p>WebJPAH2</p><p></p><p>我们首先尝试安装 CodeWhisperer 插件，在 Plugins 中搜索 AWS Toolkit 下载即可。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c9/c9cb132ddd4b715d77597ad7909fd2ca.png\" /></p><p></p><p>下载完成后绑定自己的亚马逊账号即可开始使用，默认开启自动建议。</p><p></p><p>项目结构如图所示</p><p><img src=\"https://static001.geekbang.org/infoq/b4/b4e1550475358d429df0c06fd5d673d9.png\" /></p><p></p><p>pom.xml 文件如下</p><p><code lang=\"text\"><!--?xml version=\"1.0\" encoding=\"UTF-8\"?-->\n\n4.0.0\n\norg.springframework.boot\nspring-boot-starter-parent\n3.1.0\n <!-- lookup parent from repository -->\n\ncom.example\ndemo\n0.0.1-SNAPSHOT\ndemo\ndemo\n\n17\n\n\n\norg.springframework.boot\nspring-boot-starter-data-jpa\n\n\n\norg.projectlombok\nlombok\ntrue\n\n\norg.springframework.boot\nspring-boot-starter-web\n\n\n\ncom.h2database\nh2\nruntime\n\n\norg.springframework.boot\nspring-boot-starter-test\ntest\n\n\n\n\n\n\norg.springframework.boot\nspring-boot-maven-plugin\n\n\n\n\n\n</code></p><p></p><p></p><h2>开始</h2><p></p><p></p><p>健康检查</p><p>我们先实现一个最简单的 Controller，请求 /ping 返回 pong 即可。</p><p></p><p><code lang=\"text\">package com.example.demo.controller;\n\nimport org.springframework.stereotype.Controller;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.ResponseBody;\n\n@Controller\npublic class PingController {\n\n    @RequestMapping(\"/ping\")\n    public @ResponseBody String greeting() {\n        return \"pong\";\n    }\n\n}</code></p><p></p><p>测试用例是检验代码正确性必不可少的一环，我们来写个简单的测试用例。这时 CodeWhisperer 已经开始展示它的实力了，只是写了一行 @Test 注解，它将我们想要做的测试代码完整提示出来。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1f/1f15552b186f211ebbafb25651b68503.png\" /></p><p></p><p>下面是完整的测试代码。</p><p><code lang=\"text\">package com.example.demo;\n\nimport com.example.demo.controller.PingController;\nimport org.junit.jupiter.api.Test;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.boot.test.autoconfigure.web.servlet.AutoConfigureMockMvc;\nimport org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTest;\nimport org.springframework.test.web.servlet.MockMvc;\n\nimport static org.springframework.test.web.servlet.result.MockMvcResultHandlers.print;\nimport static org.springframework.test.web.servlet.result.MockMvcResultMatchers.content;\nimport static org.springframework.test.web.servlet.result.MockMvcResultMatchers.status;\nimport static org.springframework.test.web.servlet.request.MockMvcRequestBuilders.get;\n\n@AutoConfigureMockMvc\n@WebMvcTest(PingController.class)\npublic class TestWebApplication {\n    @Autowired\n    private MockMvc mockMvc;\n\n    @Test\n    public void shouldReturnDefaultMessage() throws Exception {\n        this.mockMvc.perform(get(\"/ping\")).andDo(print()).andExpect(status().isOk())\n                .andExpect(content().string(\"pong\"));\n    }\n}\n</code></p><p></p><p>运行一下测试用例，很顺利的通过🎉。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/12/129e75101051dd8b06d68bd62e267618.png\" /></p><p></p><p>用户类设计</p><p></p><p>我们来定一个 User 模型，发现它在 Table To Class 的实现中具备一定的表设计能力，以及字段关联联想，约束设计能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ff/ff1736b30f934fc4bfd593e8acebb76d.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d9/d95f1d75c172c72fb86feddfbccc6d28.png\" /></p><p></p><p>能推测我想要的表字段，索引约束建议。这对于新手来说是莫大的帮助，想象有一位功力深厚的同伴在旁指点你设计表结构，那么表结构的设计就能相对合理一些。</p><p><code lang=\"text\">package com.example.demo.model;\n\n\nimport jakarta.persistence.*;\nimport lombok.AllArgsConstructor;\nimport lombok.Getter;\nimport lombok.NoArgsConstructor;\nimport lombok.Setter;\nimport org.springframework.stereotype.Indexed;\n\n@Entity\n@Getter\n@Setter\n@AllArgsConstructor\n@NoArgsConstructor\n@Table(name = \"game_users\")\npublic class User {\n    @Id\n    private Long id;\n    @Column(unique = true, nullable = false)\n    private String username;\n    @Column(nullable = false, length = 64)\n    private String password;\n    @Column(unique = true, nullable = false)\n    private String email;\n}\n</code></p><p></p><p>DAO 层实现</p><p></p><p>这时我灵光一现，根据官网的 GIF 图展示，可以通过注释进行代码推断，那好，DAO 层的实现就交给它啦。</p><p><img src=\"https://static001.geekbang.org/infoq/9a/9a7477a0ba9ed9586699dd91fbd14b93.png\" /></p><p></p><p>哎哟，不错哦，根据我上面想要根据邮箱查询用户的注视，它已经给出了相应的提示，让我们再考考它，注释中进行多个方法的描述。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/22/223464519261a7e4dce1e87a41d8ea99.png\" /></p><p></p><p>挺聪明呀，也很顺利的实现了。</p><p></p><p><code lang=\"text\">package com.example.demo.dao;\n\nimport com.example.demo.model.User;\nimport org.springframework.data.jpa.repository.JpaRepository;\nimport org.springframework.stereotype.Repository;\n\nimport java.util.Optional;\n\n@Repository\npublic interface UserDao extends JpaRepository {\n    // function to implement find user by email\n    Optional findByEmail(String email);\n\n    Optional findByUsername(String username);\n\n    // two function to implement find user by id or email\n    Optional findById(Long id);\n    Optional findByEmailIgnoreCase(String email);\n\n    // function to implement check user is existed\n    Boolean existsByEmail(String email);\n\n}\n</code></p><p></p><p>看来以后 CRUD 的 DAO 层实现可以交给它来完成啦。我们希望能够预先插入一些数据便于测试，琐碎的日志测试对它来说轻轻松松。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f7/f7b8df0190574ddee4053206908f964d.png\" /></p><p></p><p><code lang=\"text\">package com.example.demo;\n\nimport com.example.demo.dao.UserDao;\nimport com.example.demo.model.User;\nimport org.slf4j.Logger;\nimport org.springframework.boot.CommandLineRunner;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\n\n@Configuration\nclass LoadDatabase {\n    public static final Logger log = org.slf4j.LoggerFactory.getLogger(LoadDatabase.class);\n\n    // this is Bean is loaded once in the application context\n    // it is used to load the data into the database\n    @Bean\n    public CommandLineRunner initDatabase(UserDao dao) {\n        return args -&gt; {\n            log.info(\"Preloading \" + dao.save(new User(1L, \"test1\", \"111111\", \"abc@gmail.com\")));\n            log.info(\"Preloading \" + dao.save(new User(2L, \"test2\", \"222222\", \"123@gmail.com\")));\n        };\n    }\n}\n</code></p><p></p><p>Service 层实现</p><p></p><p>轮到 Service 层了，让我们看看它的表现，在这里我们简单的根据用户名查询用户，返回对应的数据即可。当我方法签名写一半时，它给我的建议让我停下继续敲击的手指，因为基本符合我的预期，而且具备一定的记忆联想能力，在 DAO 层定义的 Optional，这里也能找到对应的方法进行处理。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d7/d7c42ac068b25d92ef1c6f74789e7d6f.png\" /></p><p></p><p><code lang=\"text\">package com.example.demo.service;\n\nimport com.example.demo.dao.UserDao;\nimport com.example.demo.model.User;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.stereotype.Service;\n\nimport java.util.Optional;\n\n@Service\npublic class UserDetailServiceImpl {\n    private final UserDao userdao;\n\n    @Autowired\n    public UserDetailServiceImpl(UserDao userdao) {\n        this.userdao = userdao;\n    }\n\n    public User getUserByUsername(String username) throws Exception {\n        Optional user = userdao.findByUsername(username);\n        if (user.isPresent()) {\n            return user.get();\n        } else {\n            throw new Exception(\"User not found\");\n        }\n    }\n}\n</code></p><p></p><p>Controller 层实现</p><p></p><p>最后我们来实现最外层入口，简单的进行相关业务校验，用户名是否为空，密码是否正确，在这里用于演示。</p><p><img src=\"https://static001.geekbang.org/infoq/63/630f79d9119c36fcbcc756a2b379e8d9.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9d/9d2c2e078f6cc74eda6368403486281b.png\" /></p><p></p><p>用户不存在相关处理，密码正确性验证，基本符合我们的要求。</p><p></p><p><code lang=\"text\">package com.example.demo.controller;\n\nimport com.example.demo.model.User;\nimport com.example.demo.service.UserDetailServiceImpl;\nimport org.apache.coyote.Response;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.http.HttpStatus;\nimport org.springframework.http.ResponseEntity;\nimport org.springframework.web.bind.annotation.*;\n\n@RestController\n@RequestMapping(\"/api/auth\")\npublic class UserController {\n    private final UserDetailServiceImpl userDetailService;\n\n    @Autowired\n    public UserController(UserDetailServiceImpl userDetailService) {\n        this.userDetailService = userDetailService;\n    }\n\n    @PostMapping(\"/login\")\n    public ResponseEntity<!--?--> login(@RequestBody User user) {\n        try {\n            if (user.getUsername().isEmpty()) {\n                return ResponseEntity.badRequest().body(\"user name is empty\");\n            }\n\n            User res;\n            res = userDetailService.getUserByUsername(user.getUsername());\n            if (res == null) {\n                return ResponseEntity.badRequest().body(\"user not  found\");\n            }\n\n            if (res.getPassword().equals(user.getPassword())) {\n                return ResponseEntity.ok(res);\n            }\n            return new ResponseEntity&lt;&gt;(\"user password invalid\", HttpStatus.BAD_REQUEST);\n        } catch (Exception e) {\n            return ResponseEntity.notFound().build();\n        }\n    }\n}\n</code></p><p></p><p>最后我们来测试一下，格式错误和用户密码错误的情况。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/42/42c109e87539d87d7961febae59764d4.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/23/230784c0e5596c4ee345b861a11099a9.png\" /></p><p>与预期一致，撒花。</p><p></p><h2>总结</h2><p></p><p></p><p>CodeWhisperer 就我今天的使用而言，还是有些出乎我的意料，之前的一些 AI 编程工具并不具备记忆和联想能力，今天 CodeWhisperer 展示的记忆联想效果不错，并且具备一定的表结构设计能力，一些简单的测试用例完成度也不错，我想未来一些简单琐碎的需求，测试用例也可以交给它了。但是今天在体验的过程中还是发现了一些不足，插件 UI 会出现挡住建议的情况，这样我需要再次触发建议才行，目前阶段可以使用它来投入生产，在一些复杂的场景还是需要谨慎，会出现胡言乱语的情况，跟上下文关联性不强的建议。</p><p></p><p>当然，这些问题相信随着模型的数据量级和质量不断优化能够慢慢解决🎉。</p><p></p><p>版权声明: 本文为 InfoQ 作者【天黑黑】的原创文章。</p><p>原文链接:【<a href=\"https://xie.infoq.cn/article/179127e04fff483aac667444d\">https://xie.infoq.cn/article/179127e04fff483aac667444d</a>\"】。文章转载请联系作者。</p>",
    "publish_time": "2023-08-23 10:56:28",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "时间敲定！企业数据将作为资产被纳入会计报表",
    "url": "https://www.infoq.cn/article/4rsaCarUujfmVyxW8wWl",
    "summary": "<p></p><p>据<a href=\"http://kjs.mof.gov.cn/zhengcefabu/202308/t20230821_3903354.htm\">财政部网站</a>\"8月21日消息，为规范企业数据资源相关会计处理，强化相关会计信息披露，财政部发布了《企业数据资源相关会计处理暂行规定》（下称《暂行规定》），该规定自2024年1月1日起施行。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/a2/6d/a2c75e230a53877137a0246ddbba246d.jpg\" /></p><p></p><p>数据，是数字经济时代的生产要素。《暂行规定》的发布意味着数据将作为资产被纳入会计报表，从而有助于推动数据要素资产化，这反映了数据资源在生产要素中的地位，也体现了我国在制度层面进行的创新。</p><p></p><p>2022年12月19日，《中共中央国务院关于构建数据基础制度更好发挥数据要素作用的意见》（以下简称“数据二十条”）对外发布，从数据产权、流通交易、收益分配、安全治理等方面构建数据基础制度，提出20条政策举措。</p><p></p><p>当时“数据二十条”的出台为数据要素市场建设提供了顶层制度设计。其后，在此背景下，各地相继制定了多项地方或行业促进方案，旨在鼓励和推动数字经济的发展，以及促进数据要素的流通，地方上数据交易市场也在不断建立和完善。</p><p></p><p>根据《暂行规定》对适用范围的定义，数据资源是指企业按照企业会计准则相关规定确认为无形资产或存货等资产类别的数据资源，以及企业合法拥有或控制的、预期会给企业带来经济利益的、但由于不满足企业会计准则相关资产确认条件而未确认为资产的数据资源。</p><p></p><p>据财政部会计司有关负责人介绍，《暂行规定》包括以下四部分内容：</p><p></p><p>一是适用范围。明确《暂行规定》适用于符合企业会计准则规定、可确认为相关资产的数据资源，以及不满足资产确认条件而未予确认的数据资源的相关会计处理。后续随着未来数据资源相关理论和实务的发展，可及时跟进调整。</p><p></p><p>二是数据资源会计处理适用的准则。按照会计上的经济利益实现方式，根据企业使用、对外提供服务、日常持有以备出售等不同业务模式，明确相关会计处理适用的具体准则，同时，对实务反映的一些重点问题，结合数据资源业务等实际情况予以细化。</p><p></p><p>三是列示和披露要求。要求企业应当根据重要性原则并结合实际情况增设报表子项目，通过表格方式细化披露，并规定企业可根据实际情况自愿披露数据资源（含未作为无形资产或存货确认的数据资源）的应用场景或业务模式、原始数据类型来源、加工维护和安全保护情况、涉及的重大交易事项、相关权利失效和受限等相关信息，引导企业主动加强数据资源相关信息披露。</p><p></p><p>四是附则。《暂行规定》将自2024年1月1日起施行，企业应当采用未来适用法应用本规定。</p><p></p><p>财政部会计部相关负责人亦明确表示，企业在贯彻实施《暂行规定》时需要注意以下三个事项：一是正确做好前后衔接；二是严格执行企业会计准则；三是是积极加强信息披露。</p><p></p><p>德勤中国风险咨询合伙人何铮认为，《暂行规定》的发布会给企业正在进行的数字化转型带来实质性的推动作用，促进数据资产价值的可量化，值得企业各利益相关方的重视。具体而言，其对企业带来的多方面改变包括：</p><p>企业数据资源采购数据资源开发与应用数据治理数据资源相关科目设定与会计处理数据资源相关税务处理数据资源相关信息披露数据资源及企业估值……</p><p></p><p>“企业数据资产化与数字化转型关联紧密、相辅相成，数据资产化既可以成为数字化转型的成效之一，也是实现数字化转型重要举措。”何铮表示，着眼于数据资源入表，企业可以从数据资产化战略、数据驱动业务经营与决策、数据资产管理与运营、数据资产价值评估、数据资源会计处理与信息披露等方面入手，多层次、端到端、跨条线着手准备并开展试点实践。</p><p></p><p>参考链接：</p><p><a href=\"https://mp.weixin.qq.com/s/o65I8ZIQ7b_j2FyE_hkRug\">https://mp.weixin.qq.com/s/o65I8ZIQ7b_j2FyE_hkRug</a>\"</p><p><a href=\"http://kjs.mof.gov.cn/zhengcejiedu/202308/t20230821_3903359.htm\">http://kjs.mof.gov.cn/zhengcejiedu/202308/t20230821_3903359.htm</a>\"</p><p></p><p>附下载：</p><p><a href=\"http://kjs.mof.gov.cn/zhengcefabu/202308/P020230821585628790308.pdf\">企业数据资源相关会计处理暂行规定.pdf</a>\"</p>",
    "publish_time": "2023-08-23 11:17:08",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "重磅！OpenAI 开放 GPT-3.5 Turbo 微调，网友：将prompt减少90%才实惠",
    "url": "https://www.infoq.cn/article/3le2VX8uRPBOllXeoTKz",
    "summary": "<p>当地时间8月22日，<a href=\"https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates\">OpenAI 宣布</a>\"企业现在可以使用自己的数据对 GPT-3.5 Turbo&nbsp;进行微调，OpenAI 声称最终的定制模型可以赶上甚至超过 GPT-4 执行某些任务的能力。今年秋天OpenAI 将开放更先进的GPT-4。</p><p>&nbsp;</p><p>该公司表示，此次更新将使开发人员能够自定义更适合实际用例的模型，并大规模运行这些自定义模型。OpenAI 强调，传入和传出微调 API 的数据归客户所有， OpenAI或任何其他组织不会使用这些数据来训练其他模型。</p><p>&nbsp;</p><p>OpenAI 此举似乎挽回了一些针对其开源的质疑，有网友评价称，“许多人支持开源人工智能，并批评 OpenAI 不够开放。但最重要的是，OpenAI 在不断创新。”</p><p>&nbsp;</p><p></p><h2>微调用例</h2><p></p><p>&nbsp;</p><p>GPT-3.5 Turbo是OpenAI推出的一种先进的语言模型，它能够准确理解并生成自然语言的文本。相比于之前的版本，GPT-3.5 Turbo在多个方面有了极大的改进。比如，它具备更加出色的上下文理解能力，能够更好地理解用户的问题或指令，从而提供更准确的回答。它还能够产生更流畅、连贯的文本，仿佛是由人类写就的一样。最重要的是，GPT-3.5 Turbo具备更快的响应速度，使得用户可以即时得到答案或帮助。</p><p>&nbsp;</p><p>自GPT-3.5 Turbo发布以来，开发人员和企业纷纷要求开放模型自定义功能，以便为用户创造独特且差异化的体验。通过此次发布，开发人员现可运行监督微调，使得该模型在不同用例中表现更好。</p><p>&nbsp;</p><p>微调的基本思想是，先在大规模文本数据上预训练一个大型的语言模型，例如GPT-3.5，然后使用特定任务的数据集（如法律、医疗），进一步对模型进行训练，以适应特定的任务。在这个过程中，模型的参数会进行微小的调整，使其在特定业务场景上的性能更好。</p><p>&nbsp;</p><p>在OpenAI 的内部beta测试中，微调客户已经能够在各类常见用例中显著提高模型性能，例如：</p><p>&nbsp;</p><p>改善可操纵性：微调允许企业引导模型更好地遵循指令，例如输出更简洁的答案，或者始终以给定语言做出响应。开发人员可以通过微调保证模型在收到德语提示词后，始终以德语给出回应。更可靠的输出格式：微调使模型所输出响应结果的格式更加统一。对于需要特定响应格式的应用场景（例如代码补全或编写API调用），这种格式可靠性至关重要。例如，开发人员可以用微调将用户提示词转换为可在系统中使用的高质量JSON片段。自定义调节：微调是提升模型输出质量的好办法（包括改善语气、风格），更好地适应企业品牌的固有定位。拥有知名品牌调性的企业可以对模型做出微调，使其与自身市场形象更趋一致。</p><p>&nbsp;</p><p>除了提高性能之外，微调还能帮助企业缩短提示词长度，并保证性能基本不变。OpenAI表示，GPT-3.5 Turbo的微调可处理4k个tokens——可达之前微调模型的2倍。早期测试人员还对模型本身的指令进行了微调，从而将提示词长度缩短达90%，成功加快每次API调用的速度并降低了执行成本。</p><p>&nbsp;</p><p></p><h2>成本是更高了吗？</h2><p></p><p>&nbsp;</p><p>价格问题是开发者们普遍关注的问题之一。根据OpenAI说法，微调成本分为两个部分：初始训练成本与使用成本：</p><p>&nbsp;</p><p>训练：0.008美元/1K&nbsp;tokens使用输入：0.012美元/1K tokens使用输出：0.016美元/1K tokens</p><p>&nbsp;</p><p>例如，一个gpt-3.5-turbo微调作业中包含10万个token的训练文件。经过3个epoch训练轮次，预计成本为2.40美元。</p><p>&nbsp;</p><p>此前，OpenAI宣布各初版GPT-3基础模型（ada、babbage、curie和davinci）将于2024年1月4日正式关闭。OpenAI 如今发布了babbage-002和davinci-002作为这些模型的替代方案，用户可将其用作基础模型或微调模型。这些模型可以使用新API端点/v1/fine_tuning/jobs进行微调。下面是各基础/微调GPT-3模型的定价：</p><p><img src=\"https://static001.geekbang.org/infoq/20/20389e571631b6416a97c327d1e29ebd.png\" /></p><p>&nbsp;</p><p>对此，有网友算了一笔账：微调的 GPT 3.5 Turbo 生成成本是基本模型生成成本的 8 倍，因此用户确实必须处于OpenAI提到的“将提示大小减少 90%”的范围内，才能从中获得成本效益。</p><p>&nbsp;</p><p></p><blockquote>微调定价，每 16 次用户交互的成本将超过 1 美元：16 次交互 *（0.012 美元*4 输入 + 0.016 美元输出）= 1.02 美元。</blockquote><p></p><p>&nbsp;</p><p>本质上，一个简短的提示，如“打个招呼”，比一个长提示“给黄鼠狼宠物起五个可爱的名字”要花费更少的钱。“要想对一个花费 8 倍以上的微调模型来获得纯粹的财务胜利，需要您将输入和输出提示的大小减少 8 倍或更多。”开发者simonw表示。有开发者猜测，这是由于OpenAI需要存储和加载模型，即使他们或许也在使用类似 LoRA 的方式来微调模型。</p><p>&nbsp;</p><p>对此，也有网友表示，如果进行大量检索增强，那么 8 倍的成本可能仍然比在注入的上下文上消耗大量令牌便宜。</p><p></p><p>曾基于OpenAI API做过 GPT-3开发的drcode分享称，GPT 的“微调”与 Llama2 之类的微调不同，因为它可能不会调整网络的所有权重，只是会调整网络的一小部分。代价是 OpenAI 微调的成本较低，但它的功能也没有“真正的”微调强大。</p><p>&nbsp;</p><p></p><h2>附：微调步骤</h2><p></p><p>&nbsp;</p><p>目前微调需要准备数据、上传必要的文件并通过 OpenAI 的 API 创建微调作业，步骤如下：</p><p>&nbsp;</p><p>准备数据</p><p>&nbsp;</p><p><code lang=\"null\">{\n  \"messages\": [\n    { \"role\": \"system\", \"content\": \"You are an assistant that occasionally misspells words\" },\n    { \"role\": \"user\", \"content\": \"Tell me a story.\" },\n    { \"role\": \"assistant\", \"content\": \"One day a student went to schoool.\" }\n  ]\n}</code></p><p>&nbsp;</p><p>上传文件</p><p>&nbsp;</p><p><code lang=\"null\">curl -https://api.openai.com/v1/files \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -F \"purpose=fine-tune\" \\\n  -F \"file=@path_to_your_file\" </code></p><p>&nbsp;</p><p>创建微调作业</p><p>&nbsp;</p><p><code lang=\"null\">curl https://api.openai.com/v1/fine_tuning/jobs \\\n-H \"Content-Type: application/json\" \\\n-H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n-d '{\n  \"training_file\": \"TRAINING_FILE_ID\",\n  \"model\": \"gpt-3.5-turbo-0613\",\n}'</code></p><p>&nbsp;</p><p>在模型完成微调过程之后，可以立即在生产环境下使用，且具有与基础模型相同的共享速率限制。</p><p>&nbsp;</p><p>使用微调后的模型</p><p>&nbsp;</p><p><code lang=\"null\">curl https://api.openai.com/v1/chat/completions \\\n-H \"Content-Type: application/json\" \\\n-H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n-d '{\n  \"model\": \"ft:gpt-3.5-turbo:org_id\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"You are an assistant that occasionally misspells words\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Hello! What is fine-tuning?\"\n    }\n  ]\n}'</code></p><p>&nbsp;</p><p>该公司表示，所有微调数据都必须通过“审核”API 和 GPT-4 支持的审核系统，以查看是否与 OpenAI 的安全标准相冲突。OpenAI 还计划在未来推出一个微调 UI，其中包含一个仪表板，用于检查正在进行的微调工作负载的状态。</p><p>&nbsp;</p><p>OpenAI表示，在与其他技术（例如提示词工程、信息检索和函数调用）结合使用后，微调的潜力才能得到充分发挥。对函数调用和gpt-3.5-turbo-16k微调的支持也计划于今年秋季推出。</p><p>&nbsp;</p><p>对于OpenAI 开放 GPT-3.5 Turbo 微调，您有什么想法？欢迎在评论区发表您的观点！</p><p>&nbsp;</p><p>参考链接：</p><p>&nbsp;</p><p><a href=\"https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates\">https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates</a>\"</p><p><a href=\"https://news.ycombinator.com/item?id=37227139\">https://news.ycombinator.com/item?id=37227139</a>\"</p>",
    "publish_time": "2023-08-23 13:58:09",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "玉山银行数字化（上）：构建台湾第一个银行自建的“微服务架构”核心系统",
    "url": "https://www.infoq.cn/article/4IHu4Qv0hiJJgTwzo1W8",
    "summary": "<p></p><h3>引言</h3><p></p><p>玉山，海拔超过 3900 米，是台湾的第一高山；<a href=\"https://www.esun-bank.com.cn/\">玉山银行</a>\"名取自玉山，成立于 1992 年，是台湾最大的银行之一。</p><p></p><p>据 InfoQ 了解，台湾地区的银行分布密度极高，但利息差又极低。总面积 3.6 万平方公里，却聚集着近 70 家银行；而相较于大陆近几年平均 2.1% 的利息差，台湾地区银行的利息差只有 1.4% 左右。当地银行间的竞争之激烈可想而知。</p><p></p><p>面对市场的激烈竞争，风险管理能力成为决胜的关键点。为此，玉山银行早在 2006 年成立了大数据分析团队 CRV（Customer Risk &amp; Value），开始利用数据分析帮助银行实现更精准的风险管控。时机恰逢 Bank 3.0 时代伊始，银行服务无处不在，同样，风险也变得无处不在。</p><p></p><p>“但过去，一般面向客户 KYC（Know Your Customer），我们只会收集最基本的顾客资料，例如性别、教育程度、收入等等，这样的资料是静态的。”玉山银行数位长唐枬在接受 InfoQ 专访时表示，而实际上，用户的经济状况会随着时间不停改变，“为此，玉山银行意识到必须要更动态、适时地理解顾客的状况及需求”。</p><p></p><p>大数据分析团队 CRV 的成立，目的就是解决这个问题，通过瞄准客户风险价值，探勘既有的顾客 KYC 资料，更精细化地对客户进行分类。</p><p></p><p>此外，在玉山银行看来，数据的收集也与营销应用息息相关，这是持续提升客户体验的基础。玉山银行希望以内部的客户 KYC 资料作为基础，渐渐累积商业智能以外的数据处理经验，再辅以深度学习、语音识别、语音合成与影像识别等技术，将数据分析成果应用于数字业务及经营客群，向内外部客户提供更多具有创新、效率且有品质的服务。</p><p></p><p>自那之后，玉山银行的数字化转型，又分别经历了数字化、数字优化、数字转型三个阶段。并且，在这期间，构建了全台第一个银行自建的“微服务架构”核心系统，以该核心系统为“心脏”，人工智能为“大脑”，借由二者的相互搭配，实现银行服务体验优化、营运效率提升、成本降低及商品 / 服务模式创新等目标。相信其数字化实践路径和方法，将为业界提供具有价值的参考。</p><p></p><p></p><blockquote>本文是「玉山银行数字化实践」的上篇，主要分享玉山银行数字化转型的阶段性目标和问题拆解，以及背后从文化组织、业务流程到技术架构升级各方面的挑战和解法，包括玉山银行在其中的成功经验。在文章下篇我们将深度解读玉山银行的 3 大 FinTech 策略——普惠金融、智慧金融、场景金融。</blockquote><p></p><p></p><p>以下为采访实录（经 InfoQ 编辑整理）：</p><p></p><h2>以核心系统为“心脏”，人工智能为“大脑”</h2><p></p><p></p><h5>InfoQ：在玉山银行数字化转型的三个阶段，我们的目标以及需要解决的问题有何不同？</h5><p></p><p></p><p>唐枬：在“数字化”阶段，玉山银行主要是帮助顾客可以通过非实体（在线）的方式取得产品与服务。然而，我们发现，在前端数字化的背后，后端仍然是人工操作的作业流程，这样的数字化并没有达到提升内部效率的目的。</p><p></p><p>因此，进入“数字优化”阶段，我们开始通过<a href=\"https://live.infoq.cn/room/1848\"> AI 技术</a>\"等应用，发展真正端到端、由内部作业开始构建全数字化的产品，从而使得面向外部客户的数字化服务的使用率也大幅提升。</p><p></p><p>但是，随着越来越多数字产品的推出，我们发现，顾客对实体分行的需求仍没有减少，于是又进一步开始思考如何可以透过虚实整合，让数字能够成为分行发展的助力，以全渠道的方式提供顾客服务，并积极开展分行端的创新。为了支撑成倍增长的数字化交易，以及这样的数字优化，玉山银行从系统面着手，投入了 4 年多的时间，用最新的技术自建了新一代核心系统。</p><p></p><p>对玉山银行而言，数字化转型不仅仅是应用数字科技，最主要的目的是要创造顾客喜欢且满意的体验。为了迎接数字时代的到来，员工的能力、组织的样貌，甚至商业模式，都应该有所转变。</p><p></p><p>因此，在“数字转型”阶段，玉山进行了 29 年来最大规模的组织转型，分别成立个人及法人金融事业总处 。同时，整合产品资源、推出全新数字品牌 e. Fingo，并且发展场景生态圈，改变过往的获客方式，致力于无断点地串联产品，让金融服务真正像水电一般走入顾客的日常生活，创造更大顾客体验，也对银行带来更高的价值。</p><p></p><h5>InfoQ：传统金融机构普遍具有比较重的技术包袱，对玉山银行来说，在这个过程中是如何进行内部系统和技术架构的重新整合和升级的？</h5><p></p><p></p><p>唐枬：一方面，玉山银行构建了全台第一个银行自建的“<a href=\"https://www.infoq.cn/video/3UaAmw4dFVESmYhOZaZ2\">微服务</a>\"架构”核心系统，支持数字业务的快速发展。</p><p></p><p>金融业传统架构在大型主机上的封闭式核心系统，虽然稳定却缺乏灵活度，较难满足数字金融时代的步调。为此，玉山银行于 2016 年推动核心系统建置工程，从封闭式走向开放式架构，打造弹性且灵活的 IT 架构，作为数字金融时代的竞争基石。</p><p></p><p>玉山银行是台湾金融业首家自行开发设计银行核心系统的金融机构，要重新打造一颗银行全新的心脏，玉山银行最在乎的是核心系统的稳定性，以及面对数位时代瞬间大量的交易，能快速完成交易与弹性扩充。因此，玉山银行以开放的云原生（Cloud Native）技术、微服务（Microservices）架构来打造新核心系统。</p><p></p><p>此外，玉山银行也导入开发维运一体化（DevOps）机制，使用 CI/CD 将程序开发、测试与上线，通过自动化方式快速部署，并在开发上线时，使用自动化测试进行信息安全检核、系统回归测试、上版自动化等，降低因人为疏失，造成服务的中断。同时，玉山银行在设计新核心系统时，也纳入了未来业务发展的弹性，通过各项参数化、模块化设计，加速金融商品推出效率，提供顾客创新金融服务。</p><p></p><p>另一方面，在发展新一代核心系统的同时，玉山银行也同步建构 AI 应用，希望以核心系统为“心脏”，人工智能为“大脑”，借由“心脏与大脑”的相互搭配，实现优化服务体验、提高营运效率、降低成本及创新商品 / 服务模式等目标。</p><p></p><p>而开源软件则是玉山银行建构<a href=\"https://www.infoq.cn/article/UAupCc1Z0NppCUHEqoRE\">人工智能</a>\"大脑的关键，凭借已经成熟发展且很多人使用的开源软体，让玉山银行可以在短时间内快速发展出 AI 落地服务，打造一个涵盖系统底层到 AI 服务输出的机器学习即服务（Machine Learning as a Service， MLaaS）平台。</p><p></p><h5>InfoQ：在技术重构的过程中，我们遇到过什么印象深刻的挑战？又是如何化解的？</h5><p></p><p></p><p>唐枬：新核心计划是玉山银行科技发展与数字转型的关键基础工程。</p><p></p><p>1992 年玉山银行成立时，在 IBM 大型系统上开发的第一套核心系统，经过近 30 年，虽然仍稳定运作，却可能难以支持未来数字业务成长。然而，核心系统的重新建置，不仅将耗费极大的成本、人力与时间，转换失败的机率与风险亦甚高。对此，在玉山银行经营团队高度支持下，信息团队与业务团队携手，无后顾之忧地展开了这一浩大工程。</p><p></p><p>核心系统是银行业务运作的心脏，对于全行近百套业务系统，如何梳理系统间的串接，是第一大挑战。为此，玉山银行重新整编了架构师团队，让架构师的职责更为清楚，来思考相关解决方案，经过论辩、论证后，才找出真正能满足未来核心系统的架构。在完成了架构师团队整编，也制定出相关原则与准则之后，玉山银行开始发展新一版的信息蓝图，以顾客为中心的思考模式，制订出了从通路、顾客管理、产品管理、财务会计、风险管理到管理信息的业务发展模型。</p><p></p><p>完成了完整信息蓝图的构建，下一个挑战是如何落地。玉山银行的微服务是基于业务导向进行拆分的，在这个过程中，虽然玉山银行拥有许多具有丰富经验的信息人员，相当了解既有核心系统，因此，拆分微服务并未遭遇太大困难；然而，因为多数成员并没有微服务架构开发系统经验，导致初期出现较大挑战。为改善这一现象，玉山银行制订了一套微服务设计训练准则，引导团队遵循，透过确立工作方法、落实训练与实作，后续即顺利获得改善。</p><p></p><p>新兴科技确实驱动许多变革，但每隔一段时间就会有新技术被提出，信息部门需负责 IT 基础架构的规划，判断何为关键趋势，确保财务与人力资源投入的有效。在数字浪潮下，信息人员只专注技术已然不足，招募或培育具有信息技术能力与数字发展领域的人才，将是决定未来银行数字发展成效的关键。</p><p></p><h3>每年平均投入新台币 3.8 亿创新研发资金</h3><p></p><p></p><h5>InfoQ：其实转型涉及方方面面，除了技术之外，玉山银行又是如何构建更适应数字化发展的文化、组织和流程的？</h5><p></p><p></p><p>唐枬：玉山银行认为，数字化转型并不仅仅是将实体服务或产品转化为数字方式储存提供服务，而是要改变整体金融服务的流程、产品内容或商业模式。因此，主要挑战确实不仅在于导入新技术，更在于企业内部的组织、文化、策略的调整适应，资源及人力的投入，以及如何更好地做到虚实整合，以顾客导向思维提供有温度的金融服务。</p><p></p><p>从策略及文化面来看，玉山银行以信息为核心、科技为加速器，规划数字化发展蓝图，逐步建立了“导客 - 获客 - 活客 - 留客 - 悦客”五大引擎所需之数字能力，打造完整的信息与科技发展基础。同时，推动数据驱动决策之文化，掌握各单位关键绩效指标，提供经营团队即时资讯以掌握市场脉动，且透过 PDCA（Plan- 计划、Do- 执行、Check- 检查和 Action- 处理）+Benchmark 的检视流程，让绩效管理和策略目标紧密结合，并参考市场变化调整 OKR 及行动方案。</p><p></p><p>从组织架构和流程层面来看，以新核心系统的构建过程为例，期间不只是涉及核心系统的转换，我们更是通过此次的移转，将顾客信息的整合、人才的能力与专业技术，还有团队合作的机制与流程，都进行了重新打造。为此，玉山银行特别成立了一个专门的团队，负责新核心计划的发展、风险管理、人才培育等方式。</p><p></p><p>在新核心系统 2020/8 顺利上线后，2021 年（也就是在“数字转型”阶段）玉山银行启动了成立以来最大幅度的组织改造。以往，玉山银行的科技联队与业务联队是“互相整合”的关系，但这次组织改造更进一步做到“融合”，以“你中有我，我中有你”的概念，建立个人金融事业总处，将整个数字化客群与平台经营融入到个金融业务发展中。</p><p></p><p>此外，为了打造更具有敏捷精神的 IT 组织，玉山银行信息处也在 2021 年进行了组织改造，从“部 / 科”组织，调整为依业务领域设立信息发展中心，并于中心辖下设立小组，由兼顾技术、专业与管理能力的 Team Leader（TL）带领约 5-7 人具有高度弹性的小团队，从而适应数字时代的快速业务变化。</p><p></p><p>从资源及人力投入面来说，玉山银行近 5 年创新与研发资金每年平均为 3.8 亿，通过不断整合创新的服务，以及成立跨功能团队（Cross Functional Team），运用<a href=\"https://www.infoq.cn/article/9FRdGfIdRe3OIoygTBrt\">敏捷</a>\"开发 Scrum 架构，在团队高度自主管理与赋权下，快速从经验中学习、修正商品规划，实时响应市场、提供符合顾客需求的数字金融服务，来提高数字金融科技的效能。</p><p></p><h5>InfoQ：回顾玉山银行数字化转型的整个历程，您认为最值得分享的成功经验是什么？</h5><p></p><p></p><p>唐枬：数字化转型是企业提升竞争力的关键因素，有些企业挑选一个小部门做<a href=\"https://www.infoq.cn/theme/200\">数字化</a>\"，但是一艘小船难以拖动航空母舰 ; 有些企业选择许多部门做数字实验，但 100 支烟火亦难成为熊熊烈火 ; 有些企业将数字化用以节省成本，但企业本质没有改变。</p><p></p><p>玉山银行认为数字转型需要软硬兼备，因此采用 CSOP 创新与研发策略架构，以明确的战略布局、组织架构、人才发展，启动全面数字转型：</p><p></p><p>Culture 创新文化：建立信任容错的文化，鼓励多元尝试，并推广以数据导向（A/B Testing）的实验精神；</p><p></p><p>Strategy 策略连结：聚焦数字转型、海外布局、风险管理与 ESG 等策略面向投入创新与研发资源，目标是成为亚洲最具特色的标竿银行；</p><p></p><p>Organization 组织设计：建立科技储备干部（Technology Management Associate， TMA）制度、设置科技长并发展逾千人科技联队，以组织设计打造创新环境；</p><p></p><p>People 人才培育：以完整的训练模块培育创新人才，对外则透过产学合作、举办人工智能公开挑战赛及孵化新创企业，培育社会人才。</p><p></p><p>值得一提的是，玉山银行在发展数字战略时，不是用数字取代实体，而是注重两者互补关系，我们认为，实体通路不会消失。其次，数字策略中最重要的不是科技，而是顾客，要用科技让顾客更满意和更好体验。第三则是采取渐进改善的作法，靠不断改进来达到更好的服务，而非破坏式创新。</p><p></p><h5>InfoQ：最后总结分享一下玉山银行数字化转型下一步的工作重点，计划如何布局和实施？</h5><p></p><p></p><p>唐枬：玉山银行将持续以“建立制度、培育人才、发展信息”为永续发展的三大支柱，以 PDCA 循环进行创新与研发——通过 Plan 拟定创新策略、Do 高效执行、Check 檢查、Action 修正与行动，以成为金融创新的领航者为目标，积极推动数字转型，藉此创造玉山银行的成长动能。</p><p></p><p>Plan：以 CSOP–Culture、Strategy、Organization、People 作为创新与研发的策略架构，全面推动数字转型。</p><p></p><p>Do：投入逾千人「科技联队」分进合击，自行打造云原生的银行核心系统、并重点投入 AI 人工智能，同时建立项目流程控管制度、知识管理、专利管理制度，有纪律管理创新。</p><p></p><p>Check：以量化指标 - 数字顾客、数字互动、数字销售、数字营收占比，辅以质化获奖指标检视创新成效，确保创新投入符合目的。</p><p></p><p>Action：持续以顾客需求为核心，运用数据与 AI、整合虚实通路优化顾客体验，与业务共同精进优化，期透过科技成为亚洲最具特色标竿银行。</p><p></p><p>同时玉山银行也将秉持 5A 顾客经营策略，透过导客（Access）、获客（Acquire）、活客（Activate）、留客（Adhere）、悦客（Advocate）五个阶段，并结合数据导向、AI 赋能与稳固的信息建设，持续优化产品和服务，建立顾客黏着度和忠诚度，长期期望能提供顾客 Simple（简易）、Smooth（流畅）、Sweet（贴心） 的数字服务，攻占顾客的心占率，发展以人为本的数字金融领导品牌，成为亚洲最具特色的标竿银行。</p><p></p><h4>互动福利</h4><p></p><p>AIGC 热度一路狂飙，金融行业作为前沿技术应用的引领者，将迎来哪些新的机会？又如何冲破阻力借势而上？在「InfoQ数字化经纬」公众号文章评论区留言发表自己的观点和见解，将有机会获得精美礼品👇</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/12/6e/12cdc6ee765c5353e41da3555045e46e.png\" /></p><p></p><p></p><h4>嘉宾介绍</h4><p></p><p><img src=\"https://static001.infoq.cn/resource/image/e8/11/e8416d53cdc65260802a53588a26cf11.jpg\" /></p><p></p><p>唐枬（Danny Tang），玉山银行数位长，毕业于台湾大学工商管理系，并拥有加州大学洛杉矶分校的 MBA 学位。在加入玉山之前，任职美国 IBM 公司近 20 年，担任全球银行业的解决方案总监，拥有丰富的国际金融创新经验，提供逾 50 国银行顾问服务。Danny 在国际的金融相关期刊发表过许多文章，也曾获选为全球银行业最值得追踪的意见领袖之一。2021 年加入玉山后即针对玉山数字金融发展，提出以顾客为核心，聚焦在 5 个 A，包含 Access 导客、Acquire 获客、Activate 活客、Adhere 留客、Advocate 悦客，以达成 Simple、Smooth、Sweet 的 3S 顾客服务体验为目标的顾客经营策略。</p>",
    "publish_time": "2023-08-23 14:39:41",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "羿娲科技联合创始人 COO 贾梓筠博士确认出席 QCon 北京，分享 AIoT 创业项目从 0 到 1 的挑战与对策",
    "url": "https://www.infoq.cn/article/it4mDa29E5oCVqKR4DG9",
    "summary": "<p>9 月 3 日 - 5 日，在<a href=\"https://qcon.infoq.cn/202309/beijing/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=0823&amp;utm_content=jiaziyun\"> QCon 全球软件开发大会（北京站）</a>\"上，羿娲科技联合创始人 COO 贾梓筠博士将发表题为《AIoT 创业项目从 0 到 1 的挑战与对策》主题分享，解析一个 AIoT 创业项目的实战案例，并介绍后 ChatGPT 时代会对 AIoT 创业产生哪些影响。</p><p></p><p><a href=\"https://qcon.infoq.cn/202309/beijing/presentation/5402?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=0823&amp;utm_content=jiaziyun\">贾梓筠博士</a>\"，MIT&amp; 北交大联合培养博士，羿娲科技联合创始人 COO；前阿里巴巴 AI 产品专家、图灵机器人首席科学家；10 年 + 智能硬件产品化与商业化落地经验；国际论文 10+，国际专利 4+、中国专利 30+，机器人著作 2 部；中关村 U30 百强榜青年创业人才。她在本次会议的演讲内容如下：</p><p></p><p>演讲：AIoT 创业项目从 0 到 1 的挑战与对策</p><p></p><p>如果将 0 视为创业初期的 Idea，1 是 PMF，即产品匹配市场需求，那么一个项目从 0 到 1 的过程可分为想清楚、做出来、推出去三个阶段。对 AIoT 项目而言，每个阶段有不同挑战，例如想清楚阶段的商业模式和目标客户画像不清晰，做出来阶段会存在资源不足、技术链条协同困难、进度 Delay、返工等挑战。而 AIoT 项目又涉及软件和硬件链条算法链条，与软件项目管理相比，成本管理更为复杂，综合型人才稀缺，往往需要公司高管甚至一把手直接驱动。在此情况下，无法复用敏捷项目管理的思路，甚至某些环节要求一次性作对决策，对年轻 AIoT 创业者来说是巨大挑战。本次分享将解析一个 AIoT 创业项目的实战案例，并介绍后 ChatGPT 时代会对 AIoT 创业产生哪些影响。</p><p></p><p>演讲提纲：</p><p></p><p>AIoT 的前世今生创业项目从 0 到 1 的挑战 如何应对？AIoT 项目的北极星指标 后 ChatGPT 时代对 AIoT 创业的影响</p><p></p><p>你将获得：</p><p></p><p>○ 了解一个 AIoT 创业项目的实战案例</p><p>○ 了解用人、方向、数据指标、流程设计、组织架构设计和信息化的方法论与策略</p><p>○ 思考 AI 大模型技术 在企业项目管理中的应用机会</p><p></p><p>除上述演讲外，QCon 北京还将围绕 <a href=\"https://qcon.infoq.cn/202309/beijing/track/1556?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">FinOps&nbsp;落地</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1570?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">云原生</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1567?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">AIGC&nbsp;浪潮下的研发效能提升</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1558?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">业务安全技术</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1552?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">面向&nbsp;AI&nbsp;的存储</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1557?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">从&nbsp;BI&nbsp;到&nbsp;BI+AI，新计算范式下的大数据平台</a>\"等进行分享。</p><p></p><p>110+ 名嘉宾、近 30 个精彩专题、8 种交流活动，QCon 北京 2023，相约 9 月！咨询购票请联系 18514549229（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/33/33cbbbf20baa8b2a18db4f0681f159aa.jpeg\" /></p><p></p>",
    "publish_time": "2023-08-23 15:14:14",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "不止于 IT 运维，赋能行业的数科公司如何精准踩点？",
    "url": "https://www.infoq.cn/article/8yKQHyTP1cx05M6rM24m",
    "summary": "<p>在内外部环境影响下，数科公司的运营模式正在悄然发生转变，即从以往只服务集团内部，转变成为行业赋能。在这样的背景之下，数科公司不仅需要面临从产品到运营的挑战，还需要在服务好集团企业的同时，找寻商业闭环，为市场提供有价值的服务。那么在这个转变过程中，数科公司该如何更好发挥自己的优势，并且如何借助外力来赋能企业提升IT运营能力？</p><p></p><h1>数科公司向价值运营转型&nbsp;挑战重重</h1><p></p><p></p><p>就用友观察发现，数科公司的转型驱动因素来源于两方面：</p><p></p><p>从外部政策来看，国务院国资委围绕对标世界一流的财务管理体系建设、司库体系建设、国产化替代等发布的一系列文件，奠定央企数字化转型政策基础，政府政策加持下央企数智化、国产化进程进一步加速；</p><p></p><p>从内部来看，随着数智化转型在各个领域的广泛深入，传统企业的封闭式创新模式逐渐被突破，基于互联网的开放式创新模式不断涌现并迅猛发展，其中企业IT组织的服务对象也从“服务内部用户”逐渐向“服务外部用户”转型。这使得企业在数据利用、应用系统、系统架构、基础架构、组织治理、资金支持、市场推广等层面都发生了转变。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5e/5ea169ed9379828789ba60558991759b.png\" /></p><p></p><p>举例来说，“数据利用”需要从数据归纳、制作报告，转变为支撑深度分析和业务洞察；“系统架构”需要从过去的垂直孤岛系统，转为更为开放、易于扩展、互联互通的架构；组织治理，需要从围绕项目管理的职能分配，转变为围绕产品持续交付及运营；资金支持也由原来的自有资金，转变为市场化资本介入运作等等。</p><p>&nbsp;</p><p>然而，由于数科公司在产品成熟度、技术、市场覆盖度、资本合作、持续运营等方面能力不足，因此数科公司的转型过程仍面临一些挑战。具体挑战如下：</p><p></p><p>产品成熟度：如果数科公司选择自己从0开始研发数字化产品，需要经历不断的迭代和试错，成本较高。此外，还需要经历市场调查、需求调研、开发测试、产品推广等诸多阶段，周期较长，试错成本高；技术能力：通过大数据、AI、物联网等新技术，提升产品的先进性和竞争力已是当下的共识，但对于大部分数科公司而言，其职能更多聚焦在业务侧，会面临数据智能技术运用不足、数据整合能力亟待加强、架构灵活性较低、数据孤岛待打通等问题；营销、市场：数科公司缺少营销团队和伙伴渠道对行业和产业链客户进行触达，导致产品市场覆盖度较低，无法快速占领市场。此外，产品缺少专业的市场拓展，无法在行业内进行宣传推广；资本合作：资本是全面合作的催化剂，数科公司需要一支资源整合能力强、产业协同能力强、创新孵化能力强的专业产业投资公司进行资本合作和孵化，全面深化各领域合作，加快业务全面发展；运营能力：企业建立可持续的工程化能力及运营体系，需要专业的企业数字化公司提供全方位的持续运营赋能，包括顶层设计、团队建设、技术支持、市场推广等等。</p><p></p><h1>四种模式，用友与数科公司打造合作共赢的数字生态&nbsp;</h1><p></p><p></p><p>面对诸多挑战，数科公司如何才能迎刃而解？用友网络副总裁罗小江介绍，用友深耕企业服务三十余年，计划将用友积累的产品和运营优势赋能数科公司，并和数科公司携手合作，充分发挥各自优势，共同建立面向行业客户和产业链客户的全面服务能力。</p><p></p><p>针对数科公司自身需求及特点，用友为其量身打造了四种业务模式：</p><p></p><p>1.&nbsp;应用开发：基于用友iuap 和标准产品联合研发集团内应用软件及行业级应用软件；</p><p>2.&nbsp;专业服务：以行业级专业服务生态伙伴身份加入用友生态，为本行业客户提供项目实施交付服务；</p><p>3.&nbsp;销售合作：基于联合研发产品，针对行业客户，双向引流，联合营销；</p><p>4.&nbsp;联合运营：用友输出成熟的产品研发、IT 运维方法论，帮助企业建立可持续的运营能力体系。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f5/f501fa6a66ec6329aa76bf5a72e55639.png\" /></p><p></p><p>总结来说，第一，用友可以为数科公司提供完整的开发云，帮助数科公司将能力开放、集成；第二，双方可一同打造创新中心，IVE、领域专家、架构师等专业人才将与数科公司联合共创模型能力；第三，进行联合创新以后，知识产权将归属于数科公司；第四，助力数科公司建立市场渠道，让其能够快速触达到客户；第四，开放生态 API 能力、生态服务能力，从而加速数科公司的应用开发。</p><p>&nbsp;</p><p>目前，已经旭阳数科、双良混沌、中船信息、广药信息、中国振华、微乘科技等众多数科公司与用友展开了合作，旭阳数科便是标杆案例之一。据了解，旭阳数科以用友iuap 平台为原型构建了企业整体的数智化底座，并与业务深度融合，将原有100多个系统逐步迁移上来，包括 ERP、HRM、MES 等核心系统。同时，为了提升“双效”、提高工厂的管控能力和安全性，他们大力推进智能工厂建设，同样以iuap平台为基础，打造了焦化行业的第一个智能工厂，覆盖企业从原料煤运输、备煤、炼焦等五大环节的22个应用场景，创造了“互联网+协同制造”的数字化、智能化制造体系。</p><p></p><p>基于用友iuap平台强大的底座能力，旭阳云通过打造以垂直行业工业互联网平台为核心的产品体系，提供从规划咨询到软件产品和硬件支撑，从特种机器人到运维服务场景的整体解决方案，帮助企业提高资源配置效率，引领转型升级。</p><p></p><p>除此之外，在生态方面，旭阳数科不仅与用友共建了行业数智化联合创新中心，而且积极与产品ISV、专业服务伙伴和分销商打造各类型生态合作。</p><p></p><h1>全面的赋能体系，助力数科公司走向价值运营</h1><p></p><p></p><p>为加速数科公司构建数字生态及数字赋能增值体系，用友为数智公司提供了领先的产品与技术、强大的市场营销能力、大规模生态体系、完善的工程化能力、专业的投资与孵化平台等完善的能力、平台与资源，赋能数科公司实现长期可持续的价值运营。</p><p></p><p>首先，企业实现产品市场化，需要有一个经历过千锤百炼的成熟的底座进行支撑。用友提供了全球领先的数智商业创新平台——用友BIP。用友BIP PaaS平台iuap平台是更懂业务、技术领先、体系完整的企业数智化底座。它累积了用友35年服务数百万企业客户的人财物项、产供销研等10大领域和众多行业的应用实践，以企业业务为导向，实现了多项应用架构的领先创新和技术突破。基于三大中台和三大平台，形成了完整的企业数智化底座平台体系，并提供数智化工程、可持续运营两大体系，助力企业全面升级数智化底座。</p><p></p><p>其次，用友iuap具备领先的技术，通过敏捷、可靠、多云适配的技术平台，为数科公司商业创新提供了坚如磐石的技术保障，自研多维数据库实现了企业报表快速合并，全栈的信创适配能力和领先的信创实践为数科公司提供了完整的信创开发环境。</p><p>&nbsp;</p><p>首创企业服务大模型：发布首个多领域融合化、多形态综合型的企业服务大模型YonGPT，重新定义企业服务的新形态；首创YMS云中间件技术：实现跨云技术突破和多云适配能力。YMS Cloud(Yon Middleware Service)云中间件提供了统一的技术栈、统一的基础技术组件、统一配置管理、统一中间件适配能力，实现统一运营环境下的资源共享、降低微服务的服务器资源。首创云上云下一体的持续交付体系：用友BIP构建了完整的从公有云到私有云的敏捷工程化体系，实现了云上云下一体化一套代码的敏捷交付，让企业私有云平台体验到公有云的更新效率，让云下应用升级像 AppStore 一样简单，加速了企业的商业创新。领先的云监控大盘：为用友BIP稳定、高性能、持续安全运行保驾护航，承担健康管理专家角色；领先的多租户、多数据中心技术：多租户部署在多云异构的多数据中心，云上管理，云下运行，多数据中心技术提高了大规模公有云的性能稳定性，实现真正的专属云模式。领先的迁移家族：在不同环境中共享成果，便捷的开发迁移、环境迁移、配置迁移、档案迁移；自研多维数据引擎（存算一体）：实现100%自主安全可控，支持千亿级数据规模下的“多准则、多币种、主附表”快速合并，一键出表。这一技术已经在大型央企中进行了验证，实现了 1500 家分子公司规模的超大型企业报表的快速合并、一键出表。安全可信的国产化信创适配，为企业客户提供稳固可信、自主可控的数智化平台服务。比如多维引擎，与国内的信创服务商中国曙光进行了性能测试报告，并申请了相关专利。</p><p></p><p>第三，用友具备强大的市场营销能力。数科公司基于行业积累及业务洞察，与用友打造联合产品或解决方案，同时可以借助用友强大的市场营销能力和精准触达能力，通过丰富的市场活动形式进行宣传推广，扩大产品和解决方案在行业的影响力，在行业市场进行发声。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b3/b30f5ea952ea3af977ef6f53ab503494.png\" /></p><p></p><p>第四，不同的数科公司在业务发展中形成了具有鲜明特色的能力优势，用友丰富的合作伙伴合作模式为数科公司提供迈向市场的最优定位，用友大规模生态聚合优势可以助力合作产品精准大规模推广。</p><p></p><p>第五，通过敏捷工程化体系，可以实现敏捷化交付，快速响应客户需求。通过用友iuap技术平台的工程化能力，可以方便灵活地将企业自有的工程化的模块进行嵌入，实现灵活配置和优势互补。用友可以与众多领先数科公司合作运用平台工程，不断积累经验构建一套企业级产品运营体系，为产品全生命周期管理提供领先实践。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/92/9234b69375b1c49b361e195a2a676a14.png\" /></p><p></p><p>第六，提供专业投资与孵化平台。与互联网公司的投资不同，用友产投的目标不是通过投资来颠覆某个行业，而是赋能行业数科公司，和数科公司一起成长。用友产业投资秉承深耕数字科技产业、助力实体经济的发展理念，以“产业投资+产业孵化”为发展方向，不断增强在 投资、咨询、管理、分销、交付、并购等方面的综合能力，着力打造具有国际影响力的专业化产业投资与产业孵化平台。</p><p>&nbsp;</p><p>&nbsp;“产业数字化”和“数字产业化”的时代号角已经吹响，从IT运维转向价值运营，数科公司无疑需要承担更多的责任与挑战。展望未来，用友将与更多大型企业的数科公司、行业及领域ISV、专业服务商并肩，一同来打造共生共赢的合作生态，服务更多大型企业升级数智底座，加速数智化进程，实现商业创新。</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-08-23 16:04:11",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "一文读懂QUIC协议：更快、更稳、更高效的网络通信",
    "url": "https://www.infoq.cn/article/Lddlsa5f21StY04LI3hP",
    "summary": "<p>你是否也有这样的困扰：打开APP巨耗时、刷剧一直在缓冲、追热搜打不开页面、信号稍微差点就直接加载失败……</p><p></p><p>如果有一个协议能让你的上网速度，在不需要任何修改的情况下就能提升20%，特别是网络差的环境下能够提升30%以上；如果有一个协议可以让你在WiFi和蜂窝数据切换时，网络完全不断开、直播不卡顿、视频不缓冲；你愿意去了解一下它吗？它就是QUIC协议。本文将从QUIC的背景、原理、实践部署等方面来详细介绍。</p><p></p><p>作者：李龙彦</p><p>编辑：李忠良</p><p></p><h1>一：网络协议栈</h1><p></p><p></p><h2>1.1什么叫网络协议？</h2><p></p><p></p><p>类似于我们生活中签署的合同一样，比如买卖合同是为了约束买卖双方的行为按照合同的要求履行，网络协议是为了约束网络通信过程中各方（客户端、服务端及中间设备）必须按照协议的规定进行通信，它制定了数据包的格式、数据交互的过程等等，网络中的所有设备都必须严格遵守才可以全网互联。</p><p></p><p>在网络协议栈中，是有分层的，每一层负责不同的事务。我们讨论最多的有三个：应用层、传输层、网络层。应用层主要是针对应用软件进行约束，比如你访问网站需要按照HTTP协议格式和要求进行，你发送电子邮件需要遵守SMTP等邮件协议的格式和要求；传输层主要负责数据包在网络中的传输问题，比如如何保证数据传输的时候的安全性和可靠性、数据包丢了怎么处理；网络层，也叫路由转发层，主要负责数据包从出发地到目的地，应该怎样选择路径才能更快的到达。合理的网络协议能够让用户上网更快！</p><p></p><h2>1.2 HTTP/3协议</h2><p></p><p></p><p>HTTP/3是第三个主要版本的HTTP协议。与其前任HTTP/1.1和HTTP/2不同，在HTTP/3中，弃用TCP协议，改为使用基于UDP协议的QUIC协议实现。所以，HTTP/3的核心在于QUIC协议。显然，HTTP/3属于应用层协议，而它使用的QUIC协议属于传输层协议。</p><p></p><h2>1.3我们需要HTTP/3协议吗</h2><p></p><p></p><p>很多人可能都会有这样一个疑问，为什么在2015 年才标准化了 HTTP/2 ，这么快就需要 HTTP/3？</p><p>我们知道，HTTP/2通过引入“流”的概念，实现了多路复用。简单来说，假设你访问某个网站需要请求10个资源，你使用HTTP1.1协议只能串行地发请求，资源1请求成功之后才能发送资源2的请求，以此类推，这个过程是非常耗时的。如果想10个请求并发，不需要串行等待的话，在HTTP1.1中，应用就需要为一个域名同时建立10个TCP连接才行（一般浏览器不允许建立这么多），这无疑是对资源的极大的浪费。HTTP/2的多路复用解决了这一问题，能使多条请求并发。</p><p></p><p>但现实很残酷，为什么很多业务用了HTTP/2，反倒不如HTTP1.1呢？</p><p></p><p>第一：多流并发带来了请求优先级的问题，因为有的请求客户端（比如浏览器）希望它能尽快返回，有的请求可以晚点返回；又或者有的请求需要依赖别的请求的资源来展示。流的优先级表示了这个请求被处理的优先级，比如客户端请求的关键的CSS和JS资源是必须高优先级返回的，图片视频等资源可以晚一点响应。流的优先级的设置是一个难以平衡或者难以做到公平合理的事情，如果设置稍微不恰当，就会导致有些请求很慢，这在用户看来，就是用了HTTP/2之后，怎么有的请求变慢了。</p><p></p><p>第二：HTTP/2解决了HTTP协议层面的队头阻塞，但是TCP的队头阻塞仍然没有解决，所有的流都在一条TCP连接上，如果万一序号小的某个包丢了，那么TCP为了保证到达的有序性，必须等这个包到达后才能滑动窗口，即使后面的序号大的包已经到达了也不能被应用程序读取。这就导致了在多条流并发的时候，某条流的某个包丢了，序号在该包后面的其他流的数据都不能被应用程序读取。这种情况下如果换做HTTP1.1，由于HTTP1.1是多条连接，某个连接上的请求丢包了，并不影响其他连接。所以在丢包比较严重的情况下，HTTP/2整体效果大概率不如HTTP1.1</p><p></p><p>事实上，我们并不是真的需要新的HTTP 版本，而是需要对底层传输控制协议(TCP) 进行升级。</p><p></p><h2>1.4 QUIC协议栈</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ec/ec0ce46b387488c26d88ab39f7b869ce.png\" /></p><p>图0-QUIC协议栈</p><p></p><p>QUIC协议实现在用户态，建立在内核态的UDP的基础之上，集成了TCP的可靠传输特性，集成了TLS1.3协议，保证了用户数据传输的安全。</p><p></p><h1>二：QUIC协议的优秀特性</h1><p></p><p></p><h2>2.1建连快</h2><p></p><p></p><p>数据的发送和接收，要想保证安全和可靠，一定是需要连接的。TCP需要，QUIC也同样需要。连接到底是什么？连接是一个通道，是在一个客户端和一个服务端之间的唯一一条可信的通道，主要是为了安全考虑，建立了连接，也就是建立了可信通道，服务器对这个客户端“很放心”，对于服务器来说：你想跟我进行通信，得先让我认识一下你，我得先确认一下你是好人，是有资格跟我通信的。那么这个确认对方身份的过程，就是建立连接的过程。</p><p></p><p>传统基于TCP的HTTPS的建连过程为什么如此慢？它需要TCP和TLS两个建连过程。如图1所示（传统HTTPS请求流程图）：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/18/183a4b3746b8019930a5c787a8026590.png\" /></p><p>图1-传统HTTPS请求流程图</p><p>对于一个小请求（用户数据量较小）而言，传输数据只需要1个RTT，但是光建连就花掉了3个RTT，这是非常不划算的，这里建连包括两个过程：TCP建连需要1个RTT，TLS建连需要2个RTT。RTT：Round Trip Time，数据包在网络上一个来回的时间。</p><p></p><p>为什么需要两个过程？可恶就可恶在这个地方，TCP和TLS没办法合并，因为TCP是在内核里完成的，TLS是在用户态。也许有人会说把干掉内核里的TCP，把TCP挪出来放到用户态，然后就可以和TLS一起处理了。首先，你干不掉内核里的TCP，TCP太古老了，全世界的服务器的TCP都固化在内核里了。所以，既然干不掉TCP，那我不用它了，我再自创一个传输层协议，放到用户态，然后再结合TLS，这样不就可以把两个建连过程合二为一了吗？是的，这就是QUIC。</p><p></p><h3>2.1.1 QUIC的1-RTT建连</h3><p></p><p></p><p>如图2所示，是QUIC的连接建立过程：初次建连只需要1个RTT即可完成建连。后续再次建连就可以使用0-RTT特性</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/04/0409c295ff59bc81ca81744f9d197a9a.png\" /></p><p>图2-QUIC建连过程图</p><p>QUIC的1-RTT建连：客户端与服务端初次建连（之前从未进行通信过），或者长时间没有通信过（0-RTT过期了），只能进行1-RTT建连。只有先进行一次完整的1-RTT建连，后续一段时间内的通信才可以进行0-RTT建连。</p><p></p><p>如图3所示：QUIC的1-RTT建连可以分成两个部分。QUIC连接信息部分和TLS1.3握手部分。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fb/fbae68fbcee3089e8db5d9233a0b0565.png\" /></p><p>图3-QUIC建连抓包</p><p></p><p>QUIC连接：协商QUIC版本号、协商quic传输参数、生成连接ID、确定Packet Number等信息，类似于TCP的SYN报文；保证通信的两端确认过彼此，是对的人。</p><p></p><p>TLS1.3握手：标准协议，非对称加密，目的是为了协商出对称密钥，然后后续传输的数据使用这个对称密钥进行加密和解密，保护数据不被窃取。</p><p></p><p>我们重点看QUIC的TLS1.3握手过程。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cc/cc5fc448a61d6ab1e6772e65ab244ce3.png\" /></p><p>图4-QUIC的1-RTT握手流程</p><p></p><p>我们通过图4可以看到，整个握手过程需要 2次握手（第三次握手是带了数据的），所以整个握手过程只需要1-RTT（RTT是指数据包在网络上的一个来回）的时间。</p><p></p><p>1-RTT的握手主要包含两个过程：</p><p>1.&nbsp;客户端发送Client Hello给服务端；</p><p>2.&nbsp;服务端回复Server Hello给客户端；</p><p></p><p>我们通过下图中图5和图6来看Client Hello和Server Hello具体都做了啥：</p><p>第一次握手（Client Hello报文）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1d/1d14a69acef9ac341b92644d97e4bbe8.png\" /></p><p>图5-Client Hello报文</p><p></p><p>首先，Client Hello在扩展字段里标明了支持的TLS版本（Supported Version：TLS1.3）。值得注意的是Version字段必须要是TLS1.2，这是因为TLS1.2已经在互联网上存在了10年。网络中大量的网络中间设备都十分老旧，这些网络设备会识别中间的TLS握手头部，所以TLS1.3的出现如果引入了未知的TLS Version 必然会存在大量的握手失败。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/80/80a39283eb0ec8bbde0fbae0566de863.png\" /></p><p>图6-Client Hello报文</p><p></p><p>其次，ClientHello中包含了非常重要的key_share扩展：客户端在发送之前，会自己根据DHE算法生成一个公私钥对。发送Client Hello报文的时候会把这个公钥发过去，那么这个公钥就存在于key_share中，key_share还包含了客户端所选择的曲线X25519。总之，key_share是客户端提前生成好的公钥信息。</p><p>最后，Client Hello里还包括了：客户端支持的算法套、客户端所支持的椭圆曲线以及签名算法、psk的模式等等，一起发给服务端。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/98/98d5944335d392278db5344238308f55.png\" /></p><p>图7-Client Hello报文</p><p>第二次握手：（Server Hello报文）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4b/4b38d033ad5b60ecb4c757bd405b4cc4.png\" /></p><p>图8-Server Hello报文</p><p></p><p>服务端自己根据DHE算法也生成了一个公私钥对，同样的，Key_share扩展信息中也包含了 服务端的公钥信息。服务端通过ServerHello报文将这些信息发送给客户端。</p><p></p><p>至此为止，双方（客户端服务端）都拿到了对方的公钥信息，然后结合自己的私钥信息，生成pre-master key，在这里官方的叫法是（client_handshake_traffic_secret和server_handshake_traffic_secret），然后根据以下算法进行算出key和iv，使用key和iv对Server Hello之后所有的握手消息进行加密。</p><p></p><p>注意：在握手完成之后，服务端会发送一个New Session Ticket报文给客户端，这个包非常重要，这是0-RTT实现的基础。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/38/3801589c0bb6cd88b982137d9cd44710.png\" /></p><p>图9-New Session Ticket报文</p><p></p><h3>2.1.2 QUIC的0-RTT握手</h3><p></p><p></p><p>这个功能类似于TLS1.2的会话复用，或者说0-RTT是基于会话复用功能的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/55/55ea86d24200791391ceea5334f5f3ac.png\" /></p><p>图10- QUIC的0-RTT流程图</p><p>&nbsp;</p><p>&nbsp;通过上面图10我们可以看到，client和server在建连时，仍然需要两次握手，仍然需要1个rtt，但是为什么我们说这是0-rtt呢，是因为client在发送第一个包client hello时，就带上了数据（HTTP 请求），从什么时候开始发送数据这个角度上来看，的确是0-RTT。</p><p></p><p>我们通过抓包来看0-RTT的过程：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cc/cc8ef6844b753b2d767732e496b39066.png\" /></p><p>图11- QUIC的0-RTT抓包</p><p></p><p>所以真正在实现0-RTT的时候，请求的数据并不会跟Initial报文（内含Client Hello）一起发送，而是单独一个数据包（0-RTT包）进行发送，只不过是跟Initial包同时进行发送而已。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/11/11eadbd1376faafc046642d69810279e.png\" /></p><p>图12- QUIC的0-RTT包</p><p></p><p>我们单独看Initial报文发现，除了pre_share_key、early-data标识等信息与1-RTT时不同，其他并无区别。</p><p></p><h3>2.1.3 QUIC建连需要注意的问题</h3><p></p><p></p><p>第一，QUIC实现的时候，必须缓存收到的乱序加密帧，这个缓存至少要大于4096字节。当然可以选择缓存更多的数据，更大的缓存上限意味着可以交换更大的密钥或证书。终端的缓存区大小不必在整个连接生命周期内保持不变。这里记住：乱序帧一定要缓存下来。如果不缓存，会导致连接失败。如果终端的缓存区不够用了，则其可以通过暂时扩大缓存空间确保握手完成。如果终端不扩大其缓存，则其必须以错误码CRYPTO_BUFFER_EXCEEDED关闭连接。</p><p></p><p>第二，0-RTT存在前向安全问题，请慎用！</p><p></p><h2>2.2连接迁移</h2><p></p><p></p><p>QUIC通过连接ID实现了连接迁移。</p><p></p><p>我们经常需要在WiFi和4G之间进行切换，比如我们在家里时使用WiFi，出门在路上，切换到4G或5G，到了商场，又连上了商场的WiFi，到了餐厅，又切换到了餐厅的WiFi，所以我们的日常生活中需要经常性的切换网络，那每一次的切换网络，都将导致我们的IP地址发生变化。</p><p></p><p></p><p>传统的TCP协议是以四元组（源IP地址、源端口号、目的ID地址、目的端口号）来标识一条连接，那么一旦四元组的任何一个元素发生了改变，这条连接就会断掉，那么这条连接中正在传输的数据就会断掉，切换到新的网络后可能需要重新去建立连接，然后重新发送数据。这将会导致用户的网络会“卡”一下。</p><p></p><p>但是，QUIC不再以四元组作为唯一标识，QUIC使用连接ID来标识一条连接，无论你的网络如何切换，只要连接ID不变，那么这条连接就不会断，这就叫连接迁移！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/88/888bcbda55730fbf2c0e5826fec88a7a.png\" /></p><p>图13-QUIC连接迁移介绍</p><p></p><h3>2.2.1连接ID</h3><p></p><p></p><p>每条连接拥有一组连接标识符，也就是连接ID，每个连接ID都能标识这条连接。连接ID是由一端独立选择的，每个端（客户端和服务端统称为端）选择连接ID供对端使用。也就是说，客户端生成的连接ID供服务端使用（服务端发送数据时使用客户端生成的连接ID作为目的连接ID），反过来一样的。</p><p></p><p>连接ID的主要功能是确保底层协议（UDP、IP及更底层的协议栈）发生地址变更（比如IP地址变了，或者端口号变了）时不会导致一个QUIC连接的数据包被传输到错误的QUIC终端（客户端和服务端统称为终端）上。</p><p></p><h3>2.2.2 QUIC的连接迁移过程</h3><p></p><p></p><p>QUIC限制连接迁移为仅客户端可以发起，客户端负责发起所有迁移。如果客户端接收到了一个未知的服务器发来的数据包，那么客户端必须丢弃这些数据包。</p><p></p><p>如图14所示，连接迁移过程总共需要四个步骤。</p><p>1.&nbsp;连接迁移之前，客户端使用IP1和服务端进行通信；</p><p>2.&nbsp;客户端IP变成IP2，并且使用IP2发送非探测帧给服务端；</p><p>3.&nbsp;启动路径验证（双方都需要互相验证），通过PATH_CHANLLENGE帧和PATH_RESPONSE帧进行验证。</p><p>4.&nbsp;验证通过后，使用IP2进行通信。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/81/81afe7f207ec98e4d079492ad2ef09a7.png\" /></p><p>图14- 连接迁移流程图</p><p></p><h2>2.3解决TCP队头阻塞问题</h2><p></p><p></p><p>在HTTP/2中引入了流的概念。目的是实现多个请求在同一个连接上并发，从而提升网页加载的效率。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/d9/d986e473889bbb94aefe4229b3e58e1a.png\" /></p><p>图15-QUIC解决TCP队头阻塞问题</p><p></p><p>由图15来看，假设有两个请求同时发送，红色的是请求1，蓝色的是请求2，这两个请求在两条不同的流中进行传输。假设在传输过程中，请求1的某个数据包丢了，如果是TCP，即使请求2的所有数据包都收到了，但是也只能阻塞在内核缓冲区中，无法交给应用层。但是QUIC就不一样了，请求1的数据包丢了只会阻塞请求1，请求2不会受到阻塞。</p><p></p><p>有些人不禁发问，不是说HTTP2也有流的概念吗，为什么只有QUIC才能解决呢，这个根本原因就在于，HTTP2的传输层用的TCP，TCP的实现是在内核态的，而流是实现在用户态度，TCP是看不到“流”的，所以在TCP中，它不知道这个数据包是请求1还是请求2的，只会根据seq number来判断包的先后顺序。</p><p></p><h3>2.4更优的拥塞控制算法</h3><p></p><p></p><p>拥塞控制算法中最重要的一个参数是RTT，RTT的准确性决定了拥塞控制算法的准确性；然而，TCP的RTT测量往往不准确，QUIC的RTT测量是准确的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/30/30083a245d35bf3e1ac3abe760ff0737.png\" /></p><p>图16-TCP计算RTT</p><p></p><p>如图16所示：由于网络中经常出现丢包，需要重传，在TCP协议中，初始包和重传包的序号是一样的，拥塞控制算法进行计算RTT的时候，无法区别是初始包还是重传包，这将导致RTT的计算值要么偏大，要么偏小。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c3/c3483df10c03671e2ed709cf53719b50.png\" /></p><p>图17-QUIC计算RTT</p><p></p><p>如图17所示：QUIC通过Packet Number来标识包的序号，而且规定Packet Number只能单调递增，这也就解决了初始包和重传包的二义性。从而保证RTT的值是准确的。</p><p></p><p>另外，不同于TCP，QUIC的拥塞控制算法是可插拔的，由于其实现在用户态，服务可以根据不同的业务，甚至不同的连接灵活选择使用不同的拥塞控制算法。（Reno、New Reno、Cubic、BBR等算法都有自己适合的场景）</p><p></p><h2>2.5 QUIC的两级流量控制</h2><p></p><p></p><p>很多人搞不清楚流量控制与拥塞控制的区别。二者有本质上的区别。</p><p></p><p>流量控制要解决的问题是：接收方控制发送方的数据发送的速度，就是我的接收能力就那么大点，你别发太快了，你发太快了我承受不住，会给你丢掉你还得重新发。拥塞控制要解决的问题是：数据在网络的传输过程中，是否网络有拥塞，是否有丢包，是否有乱序等问题。如果中间传输的时候网络特别卡，数据包丢在中间了，发送方就需要重传，那么怎么判断是否拥塞了，重传要怎么重传法，按照什么算法进行发送数据才能尽可能避免数据包在中间路径丢掉，这是拥塞控制的核心。</p><p></p><p>所以，流量控制解决的是接收方的接收能力问题，一般采用滑动窗口算法；拥塞控制要解决的是中间传输的时候网络是否拥堵的问题，一般采用慢启动、拥塞避免、拥塞恢复、快速重传等算法。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/d8/d89905a3dab658be40fd85906f51d500.png\" /></p><p>图18-QUIC流量控制</p><p></p><p>QUIC是双级流控，不仅有连接这一个级别的流控，还有流这个级别的流控。如下图所示，每个流都有自己的可用窗口，可用窗口的大小取决于最大窗口数减去发送出去的最大偏移数，跟中间已经发送出去的数据包，是否按顺序收到了对端的ACK 无关。</p><p></p><h1>3.&nbsp;QUIC协议如何优化</h1><p></p><p></p><p>QUIC协议定义了很多优秀的功能，但是在实现的过程中，我们会遇到很多问题导致无法达到预期的性能，比如0-RTT率很低，连接迁移失败率很高等等。</p><p></p><h2>3.1 QUIC的0-RTT成功率不高</h2><p></p><p></p><p>导致0-RTT成功率不高的原因一般有如下几个：</p><p></p><p>1.&nbsp;服务端一般都是集群，对于客户端来说，处理请求的服务端是不固定的，新的请求到来时，如果当前client没有请求过该服务器，则服务器上没有相关会话信息，会把该请求当做一个新的连接来处理，重新走1-RTT。</p><p></p><p>针对此种情况，我们可以考虑集群中所有的服务器使用相同的ticket文件。</p><p></p><p>2.&nbsp;客户端IP不是固定的，在发生连接迁移时，服务端下发的token融合了客户端的IP，这个IP变化了的话，携带token服务端校验不过，0-RTT会失败。</p><p></p><p>针对这个问题，我们可以考虑采用如图19所示的方法，使用设备信息或者APP信息来生成token，唯一标识一个客户端。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3c/3cbfa0d4c385445ae98cae8b77d2470d.png\" /></p><p>图19- 使用设备信息提高0-RTT的成功率</p><p></p><p>3.&nbsp;Session Ticket过期时间默认是2天，超过2天后就会导致0-RTT失败，然后降级走1-RTT。可以考虑增长过期时间。</p><p></p><h2>3.2实现连接迁移并不容易</h2><p></p><p></p><p>连接迁移的实现，不可避开的两个问题：一个是四层负载均衡器对连接迁移的影响，一个是七层负载均衡器对连接迁移的影响。</p><p></p><p>四层负载均衡器的影响：LVS、DPVS等四层负载均衡工具基于四元组进行转发，当连接迁移发生时，四元组会发生变化，该组件就会把同一个请求的数据包发送到不同的后端服务器上，导致连接迁移失败；</p><p></p><p>七层负载均衡器的影响（QUIC服务器多核的影响）：由于多核的影响，一般服务器会有多个QUIC服务端进程，每个进程负载处理不同的连接。内核收到数据包后，会根据二元组（源IP、源port）选择已经存在的连接，并把数据包交给对应的socket。在连接迁移发生时，源地址发生改变，可能会让接下来的数据包去到不同的进程，影响socket数据的接收。</p><p></p><p>如何解决以上两个问题？DPVS要想支持QUIC的连接迁移，就不能再以四元组进行转发，需要以连接ID进行转发，需要建立 连接ID与对应的后端服务器的对应关系；</p><p></p><p>QUIC服务器也是一样的，内核就不能用四元组来进行查找socket，四元组查找不到时，就必须使用连接ID进行查找socket。但是内核代码又不能去修改（不可能去更新所有服务器的内核版本），那么我们可以使用eBPF的方法进行解决。如下图20所示：</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/1f/1f97158b2c3649a67ebc8ac693f34fd6.png\" /></p><p>图20-多核QUIC服务器解决连接迁移问题</p><p></p><h2>3.3 UDP被限速或禁闭</h2><p></p><p></p><p>业内统计数据全球有7%地区的运营商对UDP有限速或者禁闭，除了运营商还有很多企业、公共场合也会限制UDP流量甚至禁用UDP。这对使用UDP来承载QUIC协议的场景会带来致命的伤害。对此，我们可以采用多路竞速的方式使用TCP和QUIC同时建连。除了在建连进行竞速以外，还可以对网络QUIC和TCP的传输延时进行实时监控和对比，如果有链路对UDP进行了限速，可以动态从QUIC切换到TCP。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/80/80d4ef6541decbd615977e13d85bd4e7.png\" /></p><p>图21-QUIC和TCP协议竞速</p><p></p><h2>3.4 QUIC对CPU消耗大</h2><p></p><p></p><p>相对于TCP，为什么QUIC更消耗资源？</p><p></p><p>1.&nbsp;QUIC在用户态实现，需要更多的内核空间与用户空间的数据拷贝和上下文切换；</p><p>2.&nbsp;QUIC的ACK报文也是加密的，TCP是明文的。</p><p>3.&nbsp;内核知道TCP连接的状态，不用为每一个数据包去做诸如查找目的路由、防火墙规则等操作，只需要在tcp连接建立的时候做一次即可，然而QUIC不行；</p><p></p><p>总的来说，QUIC服务端消耗CPU的地方主要有三个：密码算法的开销；udp收发包的开销；协议栈的开销；</p><p></p><p>针对这些，我们可以适当采取优化措施来：</p><p>1.&nbsp;使用Intel硬件加速卡卸载TLS握手</p><p>2.&nbsp;开启GSO功能。</p><p>3.&nbsp;数据在传输过程中，可以将一轮中所有的ACK解析后再同时进行处理，避免处理大量的ACK。</p><p>4.&nbsp;适当将QUIC的包长限制调高（比如从默认的1200调到1400个字节）</p><p>5.&nbsp;减少协议栈的内存拷贝</p><p></p><h1>4.&nbsp;QUIC的性能</h1><p></p><p></p><p>从公开的数据来看，国内各个厂（腾讯、阿里、字节、华为、OPPO、网易等等）使用了QUIC协议后，都有很大的提升，比如网易上了QUIC后，响应速度提升45%，请求错误率降低50%；比如字节火山引擎使用QUIC后，建连耗时降低20%~30%；比如腾讯使用QUIC后，在腾讯会议、直播、游戏等场景耗时也降低30%；</p><p><img src=\"https://static001.geekbang.org/infoq/e6/e63c7be789e0fd00b620c456446eb19d.png\" /></p><p>图22-字节火山引擎QUIC业务收益</p><p></p><h1>总结</h1><p></p><p></p><p>QUIC协议的出现，为HTTP/3奠定了基础。这是近些年在web协议上最大的变革，也是最优秀的一次实践。面对新的协议，我们总是有着各种各样的担忧，诚然，QUIC协议在稳定性上在成熟度上，的确还不如TCP协议，但是经过近几年的发展，成熟度已经相当不错了，Nginx近期也发布了1.25.0版本，支持了QUIC协议。所以面对这样优秀的协议，我们希望更多的公司，更多的业务参与进来使用QUIC，推动QUIC更好的发展，推动用户上网速度更快！</p><p></p><p>下面是我本人的微信公众号，经常在公众号中分享网络相关知识，敬请大家关注，谢谢！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4e/4e8f7f239827dff8a968eef80f517217.png\" /></p><p></p>",
    "publish_time": "2023-08-23 16:33:34",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "信也科技副总裁陈磊，确认担任 FCon 金融实时数据平台建设之路",
    "url": "https://www.infoq.cn/article/L1BZYTucBJsBw1VdORud",
    "summary": "<p><a href=\"https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle\">FCon 全球金融科技大会</a>\"，将于 11 月在上海召开。信也科技副总裁陈磊将担任「<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=article\">金融实时数据平台建设之路</a>\"」的专题出品人。在此次专题中，你将了解到金融业务发展需要满足时效性要求，平台化建设优化将影响数据开发及应用效率，以及实时数据平台的相关议题、未来走向和演变。</p><p></p><p><a href=\"https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=article\">陈磊</a>\"，本硕毕业于上海交通大学电子工程系，上海市首批人工智能高级职称专家，曾就职于中国移动、eBay、Opera Solutions，长期从事数据挖掘、数据工程、数据产品等相关方向的研发和管理工作。致力于打通数据科技、AI 技术在金融场景的价值通路，形成数据、算法、工程的相互促进，最终实现在安全可信前提下的开发和服务的效率和效果的提升。</p><p></p><p>2017 年加入信也科技，负责金融科技智能产品的行业赋能，自 2019 年开始负责大数据及 AI 中心，推动数据科技和 AI 的业务落地和前沿研究，形成了消费金融领域覆盖获客、风控、运营全流程的解决方案，支撑国内和国际多个国家的业务发展。建立了从风控特征到模型服务的高效链路，打造了全渠道智能获客系统，实现了风控在获客阶段的前置，达成了风险指标的持续优化。带领团队深耕机器学习、图计算、自然语言处理、智能语音等算法和工程能力，多篇文章被 KDD、IJCAI、NeurIPS、TKDE 等国际会议期刊收录。多项产品荣获各级奖项，“G-ASR：支持多语种的高性能离线流式一体语音识别系统”获世界人工智能大会算法金奖。</p><p></p><p>相信陈磊的到来，可以帮助提升此专题的质量，让你学习到，在充分考虑数据全生命周期和金融业务独特属性的基础上，实时数据平台的设计理念、技术难题、组件选择以及场景应用等诸多议题。同时，结合 Cloud-Native 和 AI-Native 的最新发展，对实时数据平台的未来走向和演变进行展望。</p><p></p><p>除上述专题外，FCon 上海还将围绕&nbsp;<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle\">DevOps&nbsp;在金融企业落地实践</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle\">金融行业大模型应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle\">创新的金融科技应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle\">金融实时数据平台建设之路</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle\">金融安全风险管控</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle\">数据要素流通与数据合规</a>\"等专题进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，前 100 人可享 5 折特惠购票，咨询购票请联系：13269078023（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png\" /></p><p></p>",
    "publish_time": "2023-08-23 16:48:13",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "EMQX Enterprise 5.1 产品发布会：开启下一代物联网标准协议",
    "url": "https://www.infoq.cn/article/Zmp21J30GcRVpN94FmPv",
    "summary": "<p>在数字化的世界中，数据是新的石油。随着 5G 和物联网技术的推广，物联网设备数量也呈现爆发式增长。这些设备带来了更加海量的数据，需要更高效的方式来管理，从而获得更有价值的洞察。作为企业级 MQTT 物联网接入平台，EMQX Enterprise 为企业提供高可靠、高性能的物联网实时数据连接、移动、处理和集成能力，助力企业快速构建物联网时代的关键应用。</p><p></p><p>历经多年迭代，EMQX Enterprise 来到了 5.1 版本。此次版本创新性地引入了 MQTT over QUIC，让数据传输在不稳定的网络环境中更稳定高效。作为 MQTT 生态领导者，EMQ 也正在将 MQTT over QUIC 构建成下一代物联网标准协议。同时，新版本还提升了 Dashboard 的操作体验，在集群架构上将设备接入能力提升 10 倍，并通过基于 MQTT 协议的文件传输功能帮助用户简化物联网系统架构。</p><p></p><p>了解版本详情：<a href=\"http://mp.weixin.qq.com/s?__biz=Mzg3NjAyMjM0NQ==&amp;mid=2247491518&amp;idx=1&amp;sn=ed650ceb1f9c877afc7d7718e043e3ef&amp;chksm=cf39c098f84e498e58eb620d6d0adca3492d7549ea85df4be805d88b8fa8f56a2fc7aec753a7&amp;scene=21#wechat_redirect\">EMQX Enterprise 5.1 发布：生产环境就绪的 MQTT over QUIC、基于 MQTT 的文件传输支持</a>\"</p><p></p><p>8 月 31 日，EMQ 将举行线上特别发布活动，来自 EMQ 中国及海外研发中心的工程师们将向大家分享 5.1 版本的亮点功能及其背后的设计细节。此外，发布会还特邀华北油田的软件专家以及零束科技的研发负责人，他们将与 EMQ 一起，基于多年深耕石油石化、车联网、能源电力、工业互联网等各行业的经验，分享如何有效管理企业中产出的海量数据，并利用这些数据驱动企业的决策和分析。</p><p></p><p>发布会亮点抢先看</p><p>重磅发布：多项突破性功能，引领企业级 MQTT 消息平台发展的里程碑版本。行业案例：来自石油、车联网行业标杆客户的真实声音，分享行业数字化实际项目中的先进经验。前瞻议题：探讨物联网领域未来发展趋势，探索 EMQ 产品与方案如何为行业注入创新活力。合作创新：EMQ 国内与海外研发中心工程师共同参与，讨论技术创新如何助力企业把握机遇、赢得竞争。</p><p></p><p>活动详情</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/77/77d7b05374862e61ed1128e8c4f9716a.jpeg\" /></p><p></p>",
    "publish_time": "2023-08-23 17:01:14",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "开源免费用｜Apache Doris 2.0 推出跨集群数据复制功能",
    "url": "https://www.infoq.cn/article/Tl0a1q7iIu4p4F44SU7S",
    "summary": "<p>随着企业业务的发展，系统架构趋于复杂、数据规模不断增大，数据分布存储在不同的地域、数据中心或云平台上的现象越发普遍，如何保证数据的可靠性和在线服务的连续性成为人们关注的重点。在此基础上，跨集群复制（Cross-Cluster Replication，CCR）应运而生，并逐渐成为数据和服务高可用性的重要保障。</p><p></p><p>CCR 通常被用于容灾备份、读写分离、集团与公司间数据传输和隔离升级等场景。</p><p></p><p>容灾备份：通常是将企业的数据备份到另一个集群与机房中，当突发事件导致业务中断或丢失时，可以从备份中恢复数据或快速进行主备切换。一般在对 SLA 要求比较高的场景中，都需要进行容灾备份，比如在金融、医疗、电子商务等领域中比较常见。读写分离：读写分离是将数据的查询操作和写入操作进行分离，目的是降低读写操作的相互影响并提升资源的利用率。比如在数据库写入压力过大或在高并发场景中，采用读写分离可以将读/写操作分散到多个地域的只读/只写的数据库案例上，减少读写间的互相影响，有效保证数据库的性能及稳定性。集团与分公司间数据传输：集团总部为了对集团内数据进行统一管控和分析，通常需要分布在各地域的分公司及时将数据传输同步到集团总部，避免因为数据不一致而引起的管理混乱和决策错误，有利于提高集团的管理效率和决策质量。隔离升级：当在对系统集群升级时，有可能因为某些原因需要进行版本回滚，传统的升级模式往往会因为元数据不兼容的原因无法回滚。而使用 CCR 可以解决该问题，先构建一个备用的集群进行升级并双跑验证，用户可以依次升级各个集群，同时 CCR 也不依赖特定版本，使版本的回滚变得可行。</p><p></p><p>为满足上述各场景的需求，市面上也有不少数据产品推出 CCR 功能，其中比较有代表性的是 Elasticsearch 和 ClickHouse。</p><p></p><p>CCR 是 Elasticsearch 推出的一项付费功能，其本质上是 Leader/Follower 的同步，它在数据导入时是按照分区进行数据同步，而不是按照写入的数据同步，这就会导致数据不一致的问题出现。ClickHouse 一般通过 Remote Function 或者 ClickHouse-Copier 来实现 CCR。Remote Function 仅适合全量同步，同步时需要遍历表、分区进行同步。ClickHouse-Copie 也不支持增量迁移，由于 ClickHouse 本身没有事务的设计，在使用 Copier 同步数据相当于跨级群之间的副本同步，无法保证同步的一致性，也无法配置关于 DB 级别的同步，需要按照表逐个进行配置，使用流程比较复杂，易用性一般。</p><p></p><p>由于 CCR 是企业在系统服务可用性方面的强需求，因此许多厂商将其纳入产品的付费增值功能中，需要购买企业版才能使用。 秉持开源开放的原则，在 <a href=\"http://doris.apache.org/\">Apache Doris</a>\" 2.0 版本中我们正式推出 CCR 来服务广大开源用户。</p><p></p><p>相较于 Elasticsearch 和 Clickhouse，Apache Doris CCR 可以在库/表级别将源集群的数据变更同步到目标集群，可根据场景精细控制同步范围；用户也可以根据需求灵活选择全量或者增量同步，有效提升了数据同步的灵活性和效率；此外 Doris CCR 还支持 DDL 同步，源集群执行的 DDL 语句可以自动同步到目标集群，从而保证了数据的一致性。Doris CCR 配置和使用也非常简单，简单操作即可快速完成跨集群数据复制。基于 Doris CCR 优异的能力，可以更好实现读写负载分离以及多机房备份，并可以更好支持不同场景的跨集群复制需求。</p><p></p><h1>Doris CCR 的设计</h1><p></p><p>在 Apache Doris 2.0 版本中，我们引入了 Binlog 机制来追踪数据的修改记录，包括 Meta Binlog 和 Data Binlog。为了实现集群间的数据同步，我们引入了外部组件 Syncer ，通过 Syncer 获取到最新的 Binlog 并回放到下游集群来实现数据的同步，同时增加了一系列机制来清理多余 Binlog。具体实现包括：</p><p></p><h2>新增Binlog</h2><p></p><p>在 Apache Doris 2.0 之前的版本中，我们无法追踪到 Apache Doris 数据修改记录，而数据变更记录正是实现 CCR 的前置依赖。为解决该问题，在 Apache Doris 2.0 版本中，我们引入了 Binlog 机制，通过 Binlog 机制自动记录数据修改记录和操作，以实现数据的可追溯性，同时我们还可以基于 Binlog 回放机制来实现数据的重放和恢复。由于我们支持库表级别同步，因此在使用时需要为 DB/Table 添加 Binlog 相关的属性，目前 Binlog 支持enable和ttl_seconds这两种属性。</p><p></p><p>注意：如果想要使用 CCR 功能，开启 Binlog 是的必要前提条件。</p><p></p><p><code lang=\"text\">-- Table\nalter table binlog set (\"binlog.enable\" = \"true\"); //开启 binlog\nalter table binlog set (\"binlog.ttl_seconds\" = \"864000\"); // 配置 binlog 过期时间\n\n-- DB\nalter database ccr set properties (\"binlog.enable\" = \"true\");\nalter database ccr set properties (\"binlog.ttls\" = \"864000\");\n</code></p><p></p><h2>持久化机制</h2><p></p><p>为了确保在系统崩溃或者各种突发事件后可以得到及时恢复，我们引入了持久化机制，将数据持久化至磁盘来确保数据的可靠性和一致性。数据的持久化主要涉及 FE 所存储的元数据信息以及 BE 所存储的实际数据本身，在开启 Binlog 属性后，FE 和 BE 会将 DDL/DML 操作的修改记录持久化成 Meta Binlog 和 Data Binlog。在进行数据操作时，FE 会触发相应的日志记录。我们对 EditLog 的实现进行了增强，以确保日志的有序性。我们通过构建一个递增序列的 LogID，对每个操作进行准确记录，并按顺序持久化。这种有序的持久化机制有助于保证数据的一致性。</p><p></p><p>在 FE 发起 Publish Transaction 的时候，BE 会执行对应的 Publish 操作，BE 会将这次 Transaction 涉及 Rowset 的元数据信息写入以 rowet_meta 为前缀的 KV 中，并持久化到 Meta 存储中，提交后会把导入的 Segment Files 链接到 Binlog 文件夹下。通过该方式，FE 的元数据和 BE 的数据可以构建一个逻辑上的 Binlog 系列。而该机制可以通过物理文件回放或逻辑回放来实现数据的恢复，在性能和可靠性方面均能提供有效的解决方案。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ed/ed8a945d59334f31eb14b11f055d911b.png\" /></p><p></p><h2>数据回放</h2><p></p><p>为了更好的连接源集群及目标集群，我们引入了中间同步与控制组件——Syncer。通过 Syncer 可以将源集群的数据抽取到目标集群上，并且可以将 Binlog 系列抽取到另一个集群上进行数据回放。</p><p></p><p>具体实现：</p><p></p><p>支持了物理文件回放，使用物理文件回放方式，可以有效地重现数据操作流程。Syncer 以 FE CommitSeq 作为游标，可以获取到下一条提交 Commit 的 Meta Binlog。Syncer 会根据 Meta Binlog的信息协调下游的 BE 去上游 BE 抽取真实的 Binlog 文件。该机制不仅保证了回放数据的一致性，还保证了高效的数据同步性能。在处理同步时，Syncer 在创建任务时优先使用 Snapshot 级别的 Backup/Restore 对 Doris 进行全量的数据恢复，接下来根据恢复的 Snapshot 的 CommitSeq 进行增量数据恢复。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fb/fb65972d58b2499515e0838e80cbb8ec.png\" /></p><p></p><h2>Binlog 数据清理</h2><p></p><p>随着数据导入越来越多，Binlog 记录的数据操作也会越来越多，占用的存储资源也会逐步增大。因此，我们需要一种数据回收机制来清理多余的 Binlog。</p><p></p><p>当我们进行 Binlog 数据清理时，在配置 Binlog GC 时我们需要注意 DB 和 Table  Binlog GC 的同步状态。比如当用户在 Enable DB Binlog 之前 Enable Table Binlog，之后又需要 Disable DB  Binlog 时，我们需要保持之前的 Table Binlog Enable 状态的相关配置，原因是 DB 的清理条件优先于 Table 的清理条件，如果 DB Binlog 是 Enable 状态，那么就需要按照 DB 的 GC 时间进行 Binlog 清理，否则就会出现 DB 和 Table 的清理状况是不一致，进而导致 Binlog 不一致的情况。</p><p></p><p>面对这种情况，FE 端会根据 Binlog 的过期时间定期扫描已经过期的 Binlog，将对应的清理过期请求下发给 BE，而 BE 会根据最后一条的 Commit Seq 对对应的 Tablet 进行元数据和 Rowset Binlog 的清理。在这个过程之中需要关注 DB 和 Table Binlog 的重叠情况。</p><p></p><h1>如何使用 CCR</h1><p></p><p></p><h2>使用须知</h2><p></p><p>目前在使用 CCR 时暂时需要开启 Doris 的 Root 权限，其他须知如下：</p><p></p><p>对于源集群的 Binlog 流程需要 Master Token，Master Token 在 FE 上获取需要 Root 权限对于其他对元集群的 Binlog 获取只需要 Show 权限Binlog 本身的同步只需要对表或者 DB 的目标集群开启 Load 权限</p><p></p><h2>安装部署</h2><p></p><p>部署源集群和目标 Doris 集群部署数据同步组件 Syncer</p><p></p><p>下载和编译源码</p><p></p><p><code lang=\"text\">git clone https://github.com/selectdb/ccr-syncer\ncd ccr-syncer\n\n# -j 开启多线程编译\n# --output指定输出的路径名称，默认名称为output\nbash build.sh &lt;-j NUM_OF_THREAD&gt; &lt;--output SYNCER_OUTPUT_DIR&gt;\n</code></p><p></p><p>编译完成的源码在 Output 文件夹中，与 Doris 类似启停脚本在 Bin 中，可执行文件在 Lib 中</p><p></p><p><code lang=\"text\"># SYNCER_OUTPUT_DIR是编译的输出路径\n# SYNCER_DEPLOY_DIR是实际部署的路径\ncp -r SYNCER_OUTPUT_DIR SYNCER_DEPLOY_DIR\ncd SYNCER_DEPLOY_DIR\n\n# 启动syncer，加上--daemon使syncer在后台运行\nbash bin/start_syncer.sh --daemon\n\n# 停止syncer\nbash bin/stop_syncer.sh\n</code></p><p></p><h2>配置任务</h2><p></p><p>在 FE/BE 的 conf 文件中添加如下配置以开启 Binlog</p><p></p><p><code lang=\"text\">enable_feature_binlog=true\n</code></p><p></p><p>打开目标集群中同步库/表的 Binlog</p><p></p><p><code lang=\"text\">-- enable database binlog\nALTER DATABASE ccr SET properties (\"binlog.enable\" = \"true\");\n\n-- enable table binlog\nALTER TABLE enable_binlog SET (\"binlog.enable\" = \"true\");\n</code></p><p></p><p>向 Syncer 发起同步任务</p><p></p><p><code lang=\"text\">curl -X POST -H \"Content-Type: application/json\" -d '{\n    \"name\": \"ccr_test\",\n    \"src\": {\n      \"host\": \"localhost\",\n      \"port\": \"9030\",\n      \"thrift_port\": \"9020\",\n      \"user\": \"root\",\n      \"password\": \"\",\n      \"database\": \"demo\",\n      \"table\": \"example_tbl\"\n    },\n    \"dest\": {\n      \"host\": \"localhost\",\n      \"port\": \"9030\",\n      \"thrift_port\": \"9020\",\n      \"user\": \"root\",\n      \"password\": \"\",\n      \"database\": \"ccrt\",\n      \"table\": \"copy\"\n    }\n}' http://127.0.0.1:9190/create_ccr\n</code></p><p></p><p>补充参数说明：</p><p></p><p>name：CCR 同步任务的名称，唯一即可host、port：对应集群 Master 的 Host、MySQL（JDBC）  的端口thrift_port：对应 FE 的 rpc_portuser、password：说明 Syncer 以何种身份去开启事务、拉取数据等database、table：如果是库级别的同步，dbName、tableName 为空如果是表级别同步，则需要填入 dbName、tableName，不为空</p><p></p><h2>查看和取消状态</h2><p></p><p>查看同步进度</p><p></p><p><code lang=\"text\">curl -X POST -H \"Content-Type: application/json\" -d '{\n    \"name\": \"ccr_test\"\n}' http://127.0.0.1:9190/get_lag\n</code></p><p></p><p>停止任务</p><p></p><p><code lang=\"text\">curl -X POST -H \"Content-Type: application/json\" -d '{\n    \"name\": \"ccr_test\"\n}' http://127.0.0.1:9190/stop_ccr\n</code></p><p></p><h1>数据同步性能实测</h1><p></p><p>为了测试 CCR 的数据同步效率，我们也进行了基于全量数据的导入测试。在全量数据的导入过程中，2TB 数据仅需不到 4 小时即可同步完成，单节点写入速度超过 170MB 每秒，具体结果见下方表格。随着集群规模的扩展，数据写入的效率呈线性提升的趋势。</p><p></p><p>需要说明的是，性能测试在特定的环境和配置上进行测试，结果与不同的环境、版本及配置有关，在此仅作为参考。</p><p></p><h2>全量同步</h2><p></p><p>源集群和目标集群均为 1FE 1BE 的集群，系统信息与硬件信息如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/04/04dfe9e4cab722b9a3cee44e2c77a3c8.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/60/608297bc1474cdeed9bff60f591c86cb.png\" /></p><p></p><p>源集群数据量：2097152MB</p><p></p><p>目标集群数据量：0</p><p></p><p>全量同步性能测试结果</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ba/ba86461d13a999c04f9ea41cdd4fffbc.png\" /></p><p></p><h1>后续规划</h1><p></p><p>目前 Doris CCR 已支持表和库级别的数据同步。具体来说，在表级别支持各种数据导入方式，支持轻量级和重量级 Schema Change，包括增加单表物化视图等，以支持更灵活的数据同步需求；同时 CCR 还支持动态分区，手动分区等。在库级别支持整库同步，可以将源集群中的所有表数据同步到目标集群中。此外，CCR 还支持创建和删除表的同步操作，可以在源集群中创建或删除表时，自动同步到目标集群中，以实现数据的同步和一致性。</p><p></p><p>未来我们还将在持续发力，不断提升 Doris CCR 的同步能力与性能，主要包括：</p><p></p><p>进一步增强表库级别的 DDL 操作，提供更灵活、更可靠的数据同步和管理功能；支持用户自定义 Binlog 消费，直接使用 Select 语句消费 Binlog，按照对应的 Driver 返回数据，比如 MySQL 协议的 Rowset；支持逻辑数据格式同步，允许用户让目标集群 BE 去源集群 BE 获取 CSV 或者 Parquet 等标准格式的增量数据（Binlog），方便用户在多个底层 BE 数据格式（Rowset）不兼容版本之间进行同步；支持冷热分离，完善对 Doris 本身分层存储的支持；库级别同步支持黑名单，目的是过滤掉某些表 ，用户可以方便在使用CCR的时候不需要因为库内有些表无需同步而为每张表都设置单独的同步任务(方便保证在几张表之上的事务)目标集群支持主备切换，开启 Binlog 可以将增量数据同步给源集群；增强 Syncer 的运维与可观测性相关的功能，提升 Syncer 的运维部署能力，监控 Syncer 的开销和同步任务的进度。使得 Syncer 支持更多相关的运维操作，支持分布式部署和同步进度多种 DB 的支持。</p><p></p><p>在此也欢迎有相关需求的同学积极在评论区反馈需求或问题。</p><p></p><p>作者介绍：</p><p></p><p>许瑞亮，<a href=\"https://selectdb.com/\">SelectDB</a>\" 资深研发工程师</p><p></p><p>李仕杨，SelectDB 生态研发工程师</p>",
    "publish_time": "2023-08-23 18:00:42",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]