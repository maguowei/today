[
  {
    "title": "Visual Studio 17.7预览版：插件管理器和HTTP编辑器改进，与VSCode功能相比仍有差距",
    "url": "https://www.infoq.cn/article/I7ThoMmKYVF1wiZFWEXj",
    "summary": "<p>微软发布了<a href=\"https://learn.microsoft.com/en-us/visualstudio/releases/2022/release-notes-preview#17.7.0-pre.3.0\">Visual Studio 2022 17.7的第三个预览版本</a>\"。预览版本 3带来了一系列的改进和新特性，旨在提高开发人员的生产力，并帮助维护简洁的代码。预览版本3重点是为C++开发人员提供了一个名为#includes cleanup的新工具。<a href=\"https://visualstudio.microsoft.com/vs/preview/\">最新版本已经可以下载</a>\"，开发人员可以在预览版本中探索并利用它的最新进展。</p><p></p><p>预览版本3为C++、生产力、.NET和云开发、Microsoft 365开发和Teams工具包以及SQL Server Data Tools等多个领域带来了更改和改进。</p><p></p><p>作为最大的新闻，最新的更新引入了一个令人兴奋的新特性，称为“包含清理”（Include Cleanup）功能。这个有价值的工具为开发人员提供了在检测到间接包含时添加直接包含的建议，以及识别可以安全删除的任何冗余包含。值得注意的是，该功能在默认情况下处于禁用状态，以确保开发人员可以控制它的使用。为了利用它的优势，用户可以通过导航“工具”&gt;“选项”&gt;“文本编辑器”&gt;“C/C++”&gt;“IntelliSense”并选择“启用#include cleanup”选项来轻松地启用它。</p><p></p><p>在有关#include工具的<a href=\"https://devblogs.microsoft.com/cppblog/include-cleanup-in-visual-studio/\">原始博客文章</a>\"中，C++项目经理Mryam Girmay指出：</p><p></p><p></p><blockquote>……该功能通过生成删除未使用的头文件和添加直接头文件的建议来提高代码的质量。我们建议的工作流程是首先执行直接包含建议，在使用间接头文件的地方添加直接头文件，然后删除未使用的包含。</blockquote><p></p><p></p><p>对于C++和预览版本3，最新的更新还引入了对<a href=\"https://learn.microsoft.com/en-us/cpp/sanitizers/asan?view=msvc-170\">Address Sanitizer</a>\"支持的扩展，现在提供了continue_on_error模式。该运行时功能实现了对隐藏内存安全错误的实时检测和报告，并且零误报。开发人员可以通过为stdout设置ASAN_OPTIONS=continue_on_error=1或为stderr设置ASAN-OPTIONS=continue_on_eerror=2来将其集成到工作流中。该更新增强了应用程序的可靠性，并提供了更安全的代码库。</p><p></p><p>对于开发人员的<a href=\"https://learn.microsoft.com/en-us/visualstudio/releases/2022/release-notes-preview#productivity\">生产力</a>\"，体现在解决方案资源管理器中，在上下文菜单中添加了一个新的“折叠所有子节点”命令，使用户可以折叠选定的节点及其子节点。这也可以通过Ctrl+Left快捷键来实现。</p><p></p><p>此外，<a href=\"https://learn.microsoft.com/en-us/visualstudio/ide/finding-and-using-visual-studio-extensions?view=vs-2022\">扩展管理器</a>\"也进行了更新，以简化从Visual Studio Marketplace中发现和管理扩展的过程，从而更容易地更新现有的扩展。开发人员可以通过启用“工具”&gt;“选项”&gt;“环境”&gt;“预览功能”下的“扩展管理器UI刷新”预览功能来访问现代扩展管理器。</p><p></p><p>此外，最新版本还对<a href=\"https://learn.microsoft.com/en-us/visualstudio/releases/2022/release-notes-preview#net-and-cloud-development\">HTTP编辑器</a>\"进行了显著的改进。其中包括添加了一个新的响应视图，该视图支持JSON高亮显示。现在，开发人员可以很容易地检查原始响应、请求标头以及发送到Web服务器的请求。此外，用于发送请求的绿色播放按钮已被代码镜头操作所取代，从而简化了开发过程。</p><p></p><p>同样，开发人员现在可以利用Microsoft Power Platform的连接服务支持。正如发布文章中所报道的：你可以创建一个到Power Platform环境的自定义连接器，并创建一个开发隧道来本地测试和调试Web API项目。</p><p></p><p>其他更改则与Microsoft 365开发有关：Teams Toolkit现在提供了简化的Teams Tab应用程序模板。这个版本还包括缺陷修复和UI改进，增强了用户体验。此外，在<a href=\"https://learn.microsoft.com/en-us/visualstudio/releases/2022/release-notes-preview#ssdt-sql\">SQL Server Data Tools</a>\"中，最新的更新解决了将Azure Interactive Dir用于<a href=\"https://visualstudio.microsoft.com/vs/debug-in-azure/\">Azure Debugger</a>\"时的发布问题。此外，Target平台对SQL Serverless的命名已更改为<a href=\"https://learn.microsoft.com/en-us/azure/synapse-analytics/sql/on-demand-workspace-overview\">Azure Synapse Analytics Serverless SQL Pool</a>\"。</p><p></p><p>微软和开发团队<a href=\"https://developercommunity.visualstudio.com/VisualStudio/suggest\">鼓励用户提供反馈意见，并分享了他们对新功能和改进的建议</a>\"，强调了他们将致力于不断增强Visual Studio的体验。最后，有兴趣了解更多关于该版本和其他Visual Studio版本信息的开发人员可以访问有关Visual Studio 2022 IDE的其他更新，这些更改和新功能有<a href=\"https://learn.microsoft.com/en-us/visualstudio/releases/2022/release-notes-preview#1770-pre30--visual-studio-2022-version-177-preview-3\">非常详细的发布说明</a>\"。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/07/vs2022-v17-7-preview-3/\">https://www.infoq.com/news/2023/07/vs2022-v17-7-preview-3/</a>\"</p>",
    "publish_time": "2023-08-23 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "我们如何训练和应用大模型 | InfoQ《极客有约》",
    "url": "https://www.infoq.cn/article/5ZglMYd9IuxRQSXpAw2O",
    "summary": "<p>本期《极客有约》我们和数禾科技AI技术总监杨春勇聊聊如何解决模型计算底层应用的资源处理问题。</p>",
    "publish_time": "2023-08-23 09:10:18",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "混合精度下位置编码竟有大坑，llama 等主流开源模型纷纷中招！百川智能给出修复方案",
    "url": "https://www.infoq.cn/article/OcjyhximVsWg4o5rboDB",
    "summary": "<p>位置编码技术是一种能够让神经网络建模句子中Token位置信息的技术。在Transformer大行其道的时代，由于Attention结构无法建模每个token的位置信息，位置编码（Position Embedding)成为Transformer非常重要的一个组件。研究人员也提出了各种各样的位置编码方案来让网络建模位置信息，RoPE和 Alibi 是目前最被广泛采纳的两种位置编码方案。</p><p></p><p>然而最近来自百川智能的研究发现，RoPE和Alibi位置编码的主流实现在低精度（尤其是bfloat16)下存在位置编码碰撞的bug, 这可能会影响模型的训练和推理。而且目前大部分主流开源模型的实现都存在该问题，连llama官方代码也中招了。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/01eb204f519f1a3bbba3a2baf9da6393.png\" /></p><p></p><p></p><h2>还得从位置编码算法说起</h2><p></p><p></p><p>为了弄清楚这个问题，得先从位置编码的算法原理说起，在Transformer结构中，所有Attention&nbsp;Block的输入都会先经过位置编码,&nbsp;再输入网络进行后续处理。纯粹的Attention结构是无法精确感知到每个token的位置信息的，而对于语言的很多任务来说，语句的顺序对语义信息的影响是非常大的，为了建模token之间的位置关系，Transfomer原始论文中引入位置编码来建模位置信息。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/32/32967120b3070d35d0830e26c0a53dda.png\" /></p><p></p><p>图1-施加&nbsp;Positon&nbsp;Embedding&nbsp;示意图&nbsp;</p><p></p><p>为了让模型更好地建模句子的位置信息，研究人员提出了多种位置编码方案，Meta开源的llama模型采用了RoPE方案，使得RoPE成为在开源社区被广泛采纳的一种位置编码方案。Alibi编码也因为其良好的外推性也被广泛应用。</p><p></p><p>了解低精度下的位置编码碰撞之前，先来回顾一下相关算法原理</p><p></p><p>Sinusoidal位置编码</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e6/e61da7251a4b186b24da63f661606860.png\" /></p><p></p><p>这是Transformer原始论文中提出的位置编码方法。它通过使用不同频率的正弦和余弦函数来为每个位置产生一个独特的编码。选择三角函数来生成位置编码有两个良好的性质：</p><p></p><p>1）编码相对位置信息，数学上可以证明&nbsp;PE(pos+k)&nbsp;可以被&nbsp;PE(pos)&nbsp;线性表示，&nbsp;这意味着位置编码中蕴含了相对位置信息。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8e/8ee749ad80cc5f5e3c30415e3844fa23.png\" /></p><p></p><p>图2-句子长度为50的位置编码，编码维度128，每行代表一个Position&nbsp;Embedding</p><p></p><p>2）远程衰减：不同位置的position&nbsp;embedding点乘结果会随着相对位置的增加而递减。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/79/79dc2b1e8b3fe6bb3407c0de70363015.png\" /></p><p></p><p>图3-不同位置的位置编码点积可视化</p><p></p><p></p><h3>RoPE</h3><p></p><p></p><p>RoPE是目前开源社区应用最广泛的一种位置编码方案，&nbsp;通过绝对位置编码的方式实现相对位置编码，在引入相对位置信息的同时保持了绝对位置编码的优势（不需要像相对位置编码一样去操作Attention&nbsp;matrix)。令f_q,&nbsp;f_k&nbsp;为&nbsp;位置编码的函数，m表示位置,&nbsp;x_m&nbsp;表示该位置token对应的Embedding，希望经过位置编码后的Embedding&nbsp;点积仅和相对位置有关，则可以有公式</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f5/f559cabec80db456783b14b9f0fa03a9.png\" /></p><p></p><p>上面公式中g是某个函数，表示内积的结果只和x_m&nbsp;和&nbsp;x_n的值，以及二者位置的相对关系(m-n)有关在2维的情况下可以推导出（详细推导过程可参考原论文）：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9b/9bc0d18dbe8c0b452d5ac76a68a7435c.png\" /></p><p></p><p>因为矩阵乘法线性累加的性质，可以拓展到多维的情况可得：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f9/f938a63197c2e3d5ff64bc304631904c.png\" /></p><p></p><p>为了引入远程衰减的特性，Rope中\\theta的选取选择了Transformer&nbsp;原始论文中&nbsp;sinusoidal&nbsp;公式。</p><p></p><p></p><h3>Alibi</h3><p></p><p></p><p>Alibi是谷歌发表在ICLR2022的一篇工作，Alibi主要解决了位置编码外推效果差的痛点，算法思想非常的简单，而且非常直观。与直接加在Embedding&nbsp;上的绝对位置编码不同，Alibi的思想是在&nbsp;Attention&nbsp;matrix上施加一个与距离成正比的惩罚偏置，惩罚偏置随着相对距离的增加而增加。在具体实现时，对于每个head会有一个超参m&nbsp;来控制惩罚偏置随着相对距离增加的幅度（斜率）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b9/b9cce5a91e59e333c7848d019d4a9952.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/68/68a563c092f6706d27f8a3716055f91b.png\" /></p><p></p><p>图4-Alibi&nbsp;attention&nbsp;bias示意图</p><p></p><p>论文结果显示Alibi&nbsp;极大的提升了模型的外推性能，16k&nbsp;token&nbsp;的输入依然可以很好的支持</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e9/e9a2eac6f89e8a81b85c0d148ca0fa48.png\" /></p><p></p><p>图5-Alibi&nbsp;外推效果对比</p><p></p><p></p><h2>混合精度下位置编码的bug</h2><p></p><p></p><p>从上面的算法原理中，不管是RoPE&nbsp;的&nbsp;cos(m&nbsp;\\theta)&nbsp;还是alibi&nbsp;的&nbsp;i-1（m,&nbsp;i&nbsp;代表postion&nbsp;id),&nbsp;都需要为每个位置生成一个整型的position_id,&nbsp;在上下文窗口比较大的时候，百川智能发现目前主流的位置编码实现在混合精度下都存在因为低精度（float16/bfloat16)浮点数表示精度不足导致位置编码碰撞的问题。尤其当模型训练（推理）时上下文长度越来越长，低精度表示带来的位置编码碰撞问题越来越严重，进而影响模型的效果，下面以bfloat16为例来说明这个&nbsp;bug</p><p></p><p></p><h3>浮点数表示精度</h3><p></p><p></p><p>浮点数在计算机中表示由符号位（sign)，指数位(exponent)，尾数位(fraction)&nbsp;三部分组成,&nbsp;对于一个常规的数值表示，可以由如下公式来计算其代表的数值（其中offset是指数位的偏置）：(−1)sign∗2exponent−offset∗&nbsp;1.fraction由公式可知，尾数位的长度决定了浮点数的表示精度。深度学习中常用的&nbsp;float32/float16/bfloat16&nbsp;内存中的表示分别如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/99/99761418655f97e1ce8dd09e74febf3f.png\" /></p><p></p><p>图6-bfloat16&nbsp;的表示格式</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4b/4b96eb4bcf849b0ec99b48d53e951c86.png\" /></p><p></p><p>图7-float16&nbsp;的表示格式</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b5/b564ac3629f0eaf1478457c3b55558ec.png\" /></p><p>图8-float32&nbsp;的表示格式</p><p></p><p>可以看到可以看到float16和bfloat16相比于float32都牺牲了表示的精度，后续以bfloat16为例说明位置编码中存在的问题（float16同理）。&nbsp;下表展示了bfloat16在不同数值范围（只截取整数部分）内的表示精度。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e1/e15867272be48a2f7257420e26b32177.png\" /></p><p>可以看到当整数范围超过256，bfloat16就无法精确表示每一个整数，我们可以用代码验证一下表示精度带来的问题</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d9/d99a9388367466b2bb2117612c06ec05.png\" /></p><p></p><p></p><h3>RoPE&amp;&nbsp;Alibi&nbsp;编码的问题</h3><p></p><p></p><p>Meta开源的llama模型采用了RoPE的位置编码方式，官方的实现（以及大部分的第三方llama系列模型）在bfloat16下存在精度问题带来的位置编码碰撞（不同位置的token在bfloat16下变成同一个数）。llama官方代码如下：</p><p><img src=\"https://static001.geekbang.org/infoq/16/167c35f417e14c767e5bdbc58b6a72e9.png\" /></p><p></p><p>上面第18行核心一句根据输入序列长度生成每个位置的positonidx在bfloat16下产生位置碰撞</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0e/0ea73b01c1f0491280be73cf8940310c.png\" /></p><p></p><p>在实际训练时如果开了bfloat16,self.inv_freq的dtype会被转为bfloat16,我们可以通过简单的代码来看一下位置碰撞的问题</p><p><img src=\"https://static001.geekbang.org/infoq/a1/a15ac096412771b3c4fb02d3d1350e8b.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/58/586c77d014373d36bda4fdf37c9a31ad.png\" /></p><p>图9-bfloat16位置碰撞示意图</p><p></p><p>• 根据bfloat16的表示精度可知，训练（推理）时上下文长度越长，位置编码碰撞的情况越严重，长度为8192的上下文推理中，仅有大约10%的token位置编码是精确的，好在位置编码碰撞有局域性的特质，只有若干个相邻的token才会共享同一个positionEmbedding,在更大的尺度上，不同位置的token还是有一定的区分性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ef/efb63ef90d156427e1741dfd08ae1a04.png\" /></p><p>图10-不同上下文窗口下位置编码精确token所占比例</p><p>&nbsp;</p><p>除了RoPE位置编码方案，百川智能发现Alibi位置编码也存在上述问题，原因依然在于生成整数的位置索引时会在低精度下产生碰撞问题。</p><p>&nbsp;</p><p></p><h2>修复方案</h2><p></p><p></p><p></p><h3>RoPE修复</h3><p></p><p></p><p>￮&nbsp;RoPE的修复相对简单，只需要保证在生成position_id的时候一定在float32的精度上即可。注意：</p><p>▪&nbsp;float32的tensor register_buffer后在训练时如果开启了bfloat16,也会被转为bfloat16</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7f/7fd56c5f08e1acc71d53d345e94385f5.png\" /></p><p></p><p></p><h3>Alibi修复</h3><p></p><p></p><p>￮&nbsp;&nbsp;Alibi位置编码修复思路和RoPE的修复思路一致，但因为Alibi的attention bias直接加在attention matrix上面，如果按照上面的修复思路，attention matrix的类型必须和attention bias一致，导致整个attention的计算都在float32类型上计算，这会极大的拖慢训练速度</p><p></p><p>￮&nbsp;目前主流的attention加速方法flashattention不支持attention bias参数， 而xformers要求attention bias类型必须与query.dtype相同，因此像RoPE那样简单的将attention bias类型提升到float32将会极大的拖慢训练速度</p><p></p><p>￮&nbsp;针对该问题百川智能提出了一种新的Alibi attention方案， 整个attention bias依然在bfloat16类型上，类似于sinusoidal的远程衰减特质，我们尽量保证临近token位置编码的精确性，对于相对距离过远的的token我们则可以容忍其产生一定的位置碰撞。原本的Alibi实现则相反，相对距离越远的token表示越精确，相对距离越近的token则会碰撞</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c3/c3ad25c9614c0ef0c2f996ecd68d3c11.png\" /></p><p></p><p>图11-修复前后alibi attention_bias对照</p><p></p><p></p><h2>修复效果</h2><p></p><p></p><p>•&nbsp;此处仅在推理阶段对位置编码的精度问题进行修复【注：训练阶段可能也存在问题，取决于训练的具体配置和方法】，可以看到：</p><p>a.&nbsp;在长上下文的推理中，模型的ppl要显著优于修复前的ppl</p><p>b.&nbsp;Benchmark上测试结果显示修复前后区别不大，可能是因为benchmark上测试文本长度有限，很少触发Position embedding的碰撞</p><p></p><p></p><h3>Benchmark对比</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/af/af2b0985292e6fbf6546dd096b6e8970.png\" /></p><p></p><p></p><h3>Perplexity对比</h3><p></p><p></p><p>在通用的文本数据上对修改前后模型在中英文文本上的困惑度进行测试，效果如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d7/d7373342af4f4040a601084d01a14626.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/91/917042b5f8ccf7468a7d1699c1b87f96.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/64/6407bfa62d853922a8ad74a2bc40f24a.png\" /></p><p></p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/ff/ff2b53fd120bd9516766844551a24c6e.png\" /></p><p></p><p>&nbsp;</p><p>参考资料：</p><p></p><p>Dongxu Zhang, &amp; Dong Wang. (2015). Relation Classification via Recurrent Neural Network.</p><p>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, &amp; Illia Polosukhin. (2023). Attention Is All You Need.</p><p>Zihang Dai, Zhilin Yang, Yiming Yang, Jaime Carbonell, Quoc V. Le, &amp; Ruslan Salakhutdinov. (2019). Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context.</p><p>Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, &amp; Peter J. Liu. (2020). Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer.</p><p>Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, &amp; Guillaume Lample. (2023). LLaMA: Open and Efficient Foundation Language Models.</p><p>Jianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, &amp; Yunfeng Liu. (2022). RoFormer: Enhanced Transformer with Rotary Position Embedding.</p><p>Ofir Press, Noah A. Smith, &amp; Mike Lewis. (2022). Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation.</p><p>Yutao Sun, Li Dong, Barun Patra, Shuming Ma, Shaohan Huang, Alon Benhaim, Vishrav Chaudhary, Xia Song, &amp; Furu Wei. (2022). A Length-Extrapolatable Transformer.</p><p>https://kazemnejad.com/blog/transformer_architecture_positional_encoding/</p><p>Shouyuan Chen, Sherman Wong, Liangjian Chen, &amp; Yuandong Tian. (2023). Extending Context Window of Large Language Models via Positional Interpolation.</p><p>https://www.reddit.com/r/LocalLLaMA/comments/14lz7j5/ntkaware_scaled_rope_allows_llama_models_to_have/</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-08-23 10:50:59",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "谁说 AI 编程工具缺乏记忆和联想能力，简单琐碎的需求完全可以交给它",
    "url": "https://www.infoq.cn/article/yiLUmJIFFwVKkBmguIpu",
    "summary": "<p>今年算是 AI 正式破圈的一年，无数的工具，产品横空出世。无论在面向企业的大语言模型，还是帮助个人的 AI 工具，数不胜数。其中关于 AI 编程助手领域，近年来也涌现了很多不错的产品，例如 Copilot, Cursor, 还是我们今天要体验的 CodeWhisperer。已经在潜移默化中改变了程序员们的生产和解决问题的方式，传统解决问题往往依靠的是谷歌等搜索引擎，找到对应的官网和知名的论坛查找问题。而如今，我们仅仅依靠 AI 编程助手就能解决很多问题。</p><p></p><p>回到 CodeWhisperer 上来，它的出生还是带着许多光环的。首先来自著名的大厂 Amazon, 他们在 AI 领域有足够多的积累，在面向开发者方面有足够多的经验和产品用户体验来反馈用户感受，不断迭代相关产品，而且还有一个相当强大的优势，借助亚马逊云的力量，能够将 AI 和云打通，这在当前云原生时代是必不可少的能力。</p><p></p><p></p><h2>目标及前期准备</h2><p></p><p></p><p>先给大家讲讲今天我们希望实现的目标，基于 Spring Boot 框架，简单实现用户登陆，。我们使用的是 IntelliJ 开发工具，选用 Maven 进行管理依赖管理，用到的依赖如下。</p><p></p><p>WebJPAH2</p><p></p><p>我们首先尝试安装 CodeWhisperer 插件，在 Plugins 中搜索 AWS Toolkit 下载即可。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c9/c9cb132ddd4b715d77597ad7909fd2ca.png\" /></p><p></p><p>下载完成后绑定自己的亚马逊账号即可开始使用，默认开启自动建议。</p><p></p><p>项目结构如图所示</p><p><img src=\"https://static001.geekbang.org/infoq/b4/b4e1550475358d429df0c06fd5d673d9.png\" /></p><p></p><p>pom.xml 文件如下</p><p><code lang=\"text\"><!--?xml version=\"1.0\" encoding=\"UTF-8\"?-->\n\n4.0.0\n\norg.springframework.boot\nspring-boot-starter-parent\n3.1.0\n <!-- lookup parent from repository -->\n\ncom.example\ndemo\n0.0.1-SNAPSHOT\ndemo\ndemo\n\n17\n\n\n\norg.springframework.boot\nspring-boot-starter-data-jpa\n\n\n\norg.projectlombok\nlombok\ntrue\n\n\norg.springframework.boot\nspring-boot-starter-web\n\n\n\ncom.h2database\nh2\nruntime\n\n\norg.springframework.boot\nspring-boot-starter-test\ntest\n\n\n\n\n\n\norg.springframework.boot\nspring-boot-maven-plugin\n\n\n\n\n\n</code></p><p></p><p></p><h2>开始</h2><p></p><p></p><p>健康检查</p><p>我们先实现一个最简单的 Controller，请求 /ping 返回 pong 即可。</p><p></p><p><code lang=\"text\">package com.example.demo.controller;\n\nimport org.springframework.stereotype.Controller;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.ResponseBody;\n\n@Controller\npublic class PingController {\n\n    @RequestMapping(\"/ping\")\n    public @ResponseBody String greeting() {\n        return \"pong\";\n    }\n\n}</code></p><p></p><p>测试用例是检验代码正确性必不可少的一环，我们来写个简单的测试用例。这时 CodeWhisperer 已经开始展示它的实力了，只是写了一行 @Test 注解，它将我们想要做的测试代码完整提示出来。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1f/1f15552b186f211ebbafb25651b68503.png\" /></p><p></p><p>下面是完整的测试代码。</p><p><code lang=\"text\">package com.example.demo;\n\nimport com.example.demo.controller.PingController;\nimport org.junit.jupiter.api.Test;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.boot.test.autoconfigure.web.servlet.AutoConfigureMockMvc;\nimport org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTest;\nimport org.springframework.test.web.servlet.MockMvc;\n\nimport static org.springframework.test.web.servlet.result.MockMvcResultHandlers.print;\nimport static org.springframework.test.web.servlet.result.MockMvcResultMatchers.content;\nimport static org.springframework.test.web.servlet.result.MockMvcResultMatchers.status;\nimport static org.springframework.test.web.servlet.request.MockMvcRequestBuilders.get;\n\n@AutoConfigureMockMvc\n@WebMvcTest(PingController.class)\npublic class TestWebApplication {\n    @Autowired\n    private MockMvc mockMvc;\n\n    @Test\n    public void shouldReturnDefaultMessage() throws Exception {\n        this.mockMvc.perform(get(\"/ping\")).andDo(print()).andExpect(status().isOk())\n                .andExpect(content().string(\"pong\"));\n    }\n}\n</code></p><p></p><p>运行一下测试用例，很顺利的通过🎉。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/12/129e75101051dd8b06d68bd62e267618.png\" /></p><p></p><p>用户类设计</p><p></p><p>我们来定一个 User 模型，发现它在 Table To Class 的实现中具备一定的表设计能力，以及字段关联联想，约束设计能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ff/ff1736b30f934fc4bfd593e8acebb76d.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d9/d95f1d75c172c72fb86feddfbccc6d28.png\" /></p><p></p><p>能推测我想要的表字段，索引约束建议。这对于新手来说是莫大的帮助，想象有一位功力深厚的同伴在旁指点你设计表结构，那么表结构的设计就能相对合理一些。</p><p><code lang=\"text\">package com.example.demo.model;\n\n\nimport jakarta.persistence.*;\nimport lombok.AllArgsConstructor;\nimport lombok.Getter;\nimport lombok.NoArgsConstructor;\nimport lombok.Setter;\nimport org.springframework.stereotype.Indexed;\n\n@Entity\n@Getter\n@Setter\n@AllArgsConstructor\n@NoArgsConstructor\n@Table(name = \"game_users\")\npublic class User {\n    @Id\n    private Long id;\n    @Column(unique = true, nullable = false)\n    private String username;\n    @Column(nullable = false, length = 64)\n    private String password;\n    @Column(unique = true, nullable = false)\n    private String email;\n}\n</code></p><p></p><p>DAO 层实现</p><p></p><p>这时我灵光一现，根据官网的 GIF 图展示，可以通过注释进行代码推断，那好，DAO 层的实现就交给它啦。</p><p><img src=\"https://static001.geekbang.org/infoq/9a/9a7477a0ba9ed9586699dd91fbd14b93.png\" /></p><p></p><p>哎哟，不错哦，根据我上面想要根据邮箱查询用户的注视，它已经给出了相应的提示，让我们再考考它，注释中进行多个方法的描述。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/22/223464519261a7e4dce1e87a41d8ea99.png\" /></p><p></p><p>挺聪明呀，也很顺利的实现了。</p><p></p><p><code lang=\"text\">package com.example.demo.dao;\n\nimport com.example.demo.model.User;\nimport org.springframework.data.jpa.repository.JpaRepository;\nimport org.springframework.stereotype.Repository;\n\nimport java.util.Optional;\n\n@Repository\npublic interface UserDao extends JpaRepository {\n    // function to implement find user by email\n    Optional findByEmail(String email);\n\n    Optional findByUsername(String username);\n\n    // two function to implement find user by id or email\n    Optional findById(Long id);\n    Optional findByEmailIgnoreCase(String email);\n\n    // function to implement check user is existed\n    Boolean existsByEmail(String email);\n\n}\n</code></p><p></p><p>看来以后 CRUD 的 DAO 层实现可以交给它来完成啦。我们希望能够预先插入一些数据便于测试，琐碎的日志测试对它来说轻轻松松。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f7/f7b8df0190574ddee4053206908f964d.png\" /></p><p></p><p><code lang=\"text\">package com.example.demo;\n\nimport com.example.demo.dao.UserDao;\nimport com.example.demo.model.User;\nimport org.slf4j.Logger;\nimport org.springframework.boot.CommandLineRunner;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\n\n@Configuration\nclass LoadDatabase {\n    public static final Logger log = org.slf4j.LoggerFactory.getLogger(LoadDatabase.class);\n\n    // this is Bean is loaded once in the application context\n    // it is used to load the data into the database\n    @Bean\n    public CommandLineRunner initDatabase(UserDao dao) {\n        return args -&gt; {\n            log.info(\"Preloading \" + dao.save(new User(1L, \"test1\", \"111111\", \"abc@gmail.com\")));\n            log.info(\"Preloading \" + dao.save(new User(2L, \"test2\", \"222222\", \"123@gmail.com\")));\n        };\n    }\n}\n</code></p><p></p><p>Service 层实现</p><p></p><p>轮到 Service 层了，让我们看看它的表现，在这里我们简单的根据用户名查询用户，返回对应的数据即可。当我方法签名写一半时，它给我的建议让我停下继续敲击的手指，因为基本符合我的预期，而且具备一定的记忆联想能力，在 DAO 层定义的 Optional，这里也能找到对应的方法进行处理。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d7/d7c42ac068b25d92ef1c6f74789e7d6f.png\" /></p><p></p><p><code lang=\"text\">package com.example.demo.service;\n\nimport com.example.demo.dao.UserDao;\nimport com.example.demo.model.User;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.stereotype.Service;\n\nimport java.util.Optional;\n\n@Service\npublic class UserDetailServiceImpl {\n    private final UserDao userdao;\n\n    @Autowired\n    public UserDetailServiceImpl(UserDao userdao) {\n        this.userdao = userdao;\n    }\n\n    public User getUserByUsername(String username) throws Exception {\n        Optional user = userdao.findByUsername(username);\n        if (user.isPresent()) {\n            return user.get();\n        } else {\n            throw new Exception(\"User not found\");\n        }\n    }\n}\n</code></p><p></p><p>Controller 层实现</p><p></p><p>最后我们来实现最外层入口，简单的进行相关业务校验，用户名是否为空，密码是否正确，在这里用于演示。</p><p><img src=\"https://static001.geekbang.org/infoq/63/630f79d9119c36fcbcc756a2b379e8d9.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9d/9d2c2e078f6cc74eda6368403486281b.png\" /></p><p></p><p>用户不存在相关处理，密码正确性验证，基本符合我们的要求。</p><p></p><p><code lang=\"text\">package com.example.demo.controller;\n\nimport com.example.demo.model.User;\nimport com.example.demo.service.UserDetailServiceImpl;\nimport org.apache.coyote.Response;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.http.HttpStatus;\nimport org.springframework.http.ResponseEntity;\nimport org.springframework.web.bind.annotation.*;\n\n@RestController\n@RequestMapping(\"/api/auth\")\npublic class UserController {\n    private final UserDetailServiceImpl userDetailService;\n\n    @Autowired\n    public UserController(UserDetailServiceImpl userDetailService) {\n        this.userDetailService = userDetailService;\n    }\n\n    @PostMapping(\"/login\")\n    public ResponseEntity<!--?--> login(@RequestBody User user) {\n        try {\n            if (user.getUsername().isEmpty()) {\n                return ResponseEntity.badRequest().body(\"user name is empty\");\n            }\n\n            User res;\n            res = userDetailService.getUserByUsername(user.getUsername());\n            if (res == null) {\n                return ResponseEntity.badRequest().body(\"user not  found\");\n            }\n\n            if (res.getPassword().equals(user.getPassword())) {\n                return ResponseEntity.ok(res);\n            }\n            return new ResponseEntity&lt;&gt;(\"user password invalid\", HttpStatus.BAD_REQUEST);\n        } catch (Exception e) {\n            return ResponseEntity.notFound().build();\n        }\n    }\n}\n</code></p><p></p><p>最后我们来测试一下，格式错误和用户密码错误的情况。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/42/42c109e87539d87d7961febae59764d4.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/23/230784c0e5596c4ee345b861a11099a9.png\" /></p><p>与预期一致，撒花。</p><p></p><h2>总结</h2><p></p><p></p><p>CodeWhisperer 就我今天的使用而言，还是有些出乎我的意料，之前的一些 AI 编程工具并不具备记忆和联想能力，今天 CodeWhisperer 展示的记忆联想效果不错，并且具备一定的表结构设计能力，一些简单的测试用例完成度也不错，我想未来一些简单琐碎的需求，测试用例也可以交给它了。但是今天在体验的过程中还是发现了一些不足，插件 UI 会出现挡住建议的情况，这样我需要再次触发建议才行，目前阶段可以使用它来投入生产，在一些复杂的场景还是需要谨慎，会出现胡言乱语的情况，跟上下文关联性不强的建议。</p><p></p><p>当然，这些问题相信随着模型的数据量级和质量不断优化能够慢慢解决🎉。</p><p></p><p>版权声明: 本文为 InfoQ 作者【天黑黑】的原创文章。</p><p>原文链接:【<a href=\"https://xie.infoq.cn/article/179127e04fff483aac667444d\">https://xie.infoq.cn/article/179127e04fff483aac667444d</a>\"】。文章转载请联系作者。</p>",
    "publish_time": "2023-08-23 10:56:28",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "时间敲定！企业数据将作为资产被纳入会计报表",
    "url": "https://www.infoq.cn/article/4rsaCarUujfmVyxW8wWl",
    "summary": "<p></p><p>据<a href=\"http://kjs.mof.gov.cn/zhengcefabu/202308/t20230821_3903354.htm\">财政部网站</a>\"8月21日消息，为规范企业数据资源相关会计处理，强化相关会计信息披露，财政部发布了《企业数据资源相关会计处理暂行规定》（下称《暂行规定》），该规定自2024年1月1日起施行。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/a2/6d/a2c75e230a53877137a0246ddbba246d.jpg\" /></p><p></p><p>数据，是数字经济时代的生产要素。《暂行规定》的发布意味着数据将作为资产被纳入会计报表，从而有助于推动数据要素资产化，这反映了数据资源在生产要素中的地位，也体现了我国在制度层面进行的创新。</p><p></p><p>2022年12月19日，《中共中央国务院关于构建数据基础制度更好发挥数据要素作用的意见》（以下简称“数据二十条”）对外发布，从数据产权、流通交易、收益分配、安全治理等方面构建数据基础制度，提出20条政策举措。</p><p></p><p>当时“数据二十条”的出台为数据要素市场建设提供了顶层制度设计。其后，在此背景下，各地相继制定了多项地方或行业促进方案，旨在鼓励和推动数字经济的发展，以及促进数据要素的流通，地方上数据交易市场也在不断建立和完善。</p><p></p><p>根据《暂行规定》对适用范围的定义，数据资源是指企业按照企业会计准则相关规定确认为无形资产或存货等资产类别的数据资源，以及企业合法拥有或控制的、预期会给企业带来经济利益的、但由于不满足企业会计准则相关资产确认条件而未确认为资产的数据资源。</p><p></p><p>据财政部会计司有关负责人介绍，《暂行规定》包括以下四部分内容：</p><p></p><p>一是适用范围。明确《暂行规定》适用于符合企业会计准则规定、可确认为相关资产的数据资源，以及不满足资产确认条件而未予确认的数据资源的相关会计处理。后续随着未来数据资源相关理论和实务的发展，可及时跟进调整。</p><p></p><p>二是数据资源会计处理适用的准则。按照会计上的经济利益实现方式，根据企业使用、对外提供服务、日常持有以备出售等不同业务模式，明确相关会计处理适用的具体准则，同时，对实务反映的一些重点问题，结合数据资源业务等实际情况予以细化。</p><p></p><p>三是列示和披露要求。要求企业应当根据重要性原则并结合实际情况增设报表子项目，通过表格方式细化披露，并规定企业可根据实际情况自愿披露数据资源（含未作为无形资产或存货确认的数据资源）的应用场景或业务模式、原始数据类型来源、加工维护和安全保护情况、涉及的重大交易事项、相关权利失效和受限等相关信息，引导企业主动加强数据资源相关信息披露。</p><p></p><p>四是附则。《暂行规定》将自2024年1月1日起施行，企业应当采用未来适用法应用本规定。</p><p></p><p>财政部会计部相关负责人亦明确表示，企业在贯彻实施《暂行规定》时需要注意以下三个事项：一是正确做好前后衔接；二是严格执行企业会计准则；三是是积极加强信息披露。</p><p></p><p>德勤中国风险咨询合伙人何铮认为，《暂行规定》的发布会给企业正在进行的数字化转型带来实质性的推动作用，促进数据资产价值的可量化，值得企业各利益相关方的重视。具体而言，其对企业带来的多方面改变包括：</p><p>企业数据资源采购数据资源开发与应用数据治理数据资源相关科目设定与会计处理数据资源相关税务处理数据资源相关信息披露数据资源及企业估值……</p><p></p><p>“企业数据资产化与数字化转型关联紧密、相辅相成，数据资产化既可以成为数字化转型的成效之一，也是实现数字化转型重要举措。”何铮表示，着眼于数据资源入表，企业可以从数据资产化战略、数据驱动业务经营与决策、数据资产管理与运营、数据资产价值评估、数据资源会计处理与信息披露等方面入手，多层次、端到端、跨条线着手准备并开展试点实践。</p><p></p><p>参考链接：</p><p><a href=\"https://mp.weixin.qq.com/s/o65I8ZIQ7b_j2FyE_hkRug\">https://mp.weixin.qq.com/s/o65I8ZIQ7b_j2FyE_hkRug</a>\"</p><p><a href=\"http://kjs.mof.gov.cn/zhengcejiedu/202308/t20230821_3903359.htm\">http://kjs.mof.gov.cn/zhengcejiedu/202308/t20230821_3903359.htm</a>\"</p><p></p><p>附下载：</p><p><a href=\"http://kjs.mof.gov.cn/zhengcefabu/202308/P020230821585628790308.pdf\">企业数据资源相关会计处理暂行规定.pdf</a>\"</p>",
    "publish_time": "2023-08-23 11:17:08",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "重磅！OpenAI 开放 GPT-3.5 Turbo 微调，网友：将prompt减少90%才实惠",
    "url": "https://www.infoq.cn/article/3le2VX8uRPBOllXeoTKz",
    "summary": "<p>当地时间8月22日，<a href=\"https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates\">OpenAI 宣布</a>\"企业现在可以使用自己的数据对 GPT-3.5 Turbo&nbsp;进行微调，OpenAI 声称最终的定制模型可以赶上甚至超过 GPT-4 执行某些任务的能力。今年秋天OpenAI 将开放更先进的GPT-4。</p><p>&nbsp;</p><p>该公司表示，此次更新将使开发人员能够自定义更适合实际用例的模型，并大规模运行这些自定义模型。OpenAI 强调，传入和传出微调 API 的数据归客户所有， OpenAI或任何其他组织不会使用这些数据来训练其他模型。</p><p>&nbsp;</p><p>OpenAI 此举似乎挽回了一些针对其开源的质疑，有网友评价称，“许多人支持开源人工智能，并批评 OpenAI 不够开放。但最重要的是，OpenAI 在不断创新。”</p><p>&nbsp;</p><p></p><h2>微调用例</h2><p></p><p>&nbsp;</p><p>GPT-3.5 Turbo是OpenAI推出的一种先进的语言模型，它能够准确理解并生成自然语言的文本。相比于之前的版本，GPT-3.5 Turbo在多个方面有了极大的改进。比如，它具备更加出色的上下文理解能力，能够更好地理解用户的问题或指令，从而提供更准确的回答。它还能够产生更流畅、连贯的文本，仿佛是由人类写就的一样。最重要的是，GPT-3.5 Turbo具备更快的响应速度，使得用户可以即时得到答案或帮助。</p><p>&nbsp;</p><p>自GPT-3.5 Turbo发布以来，开发人员和企业纷纷要求开放模型自定义功能，以便为用户创造独特且差异化的体验。通过此次发布，开发人员现可运行监督微调，使得该模型在不同用例中表现更好。</p><p>&nbsp;</p><p>微调的基本思想是，先在大规模文本数据上预训练一个大型的语言模型，例如GPT-3.5，然后使用特定任务的数据集（如法律、医疗），进一步对模型进行训练，以适应特定的任务。在这个过程中，模型的参数会进行微小的调整，使其在特定业务场景上的性能更好。</p><p>&nbsp;</p><p>在OpenAI 的内部beta测试中，微调客户已经能够在各类常见用例中显著提高模型性能，例如：</p><p>&nbsp;</p><p>改善可操纵性：微调允许企业引导模型更好地遵循指令，例如输出更简洁的答案，或者始终以给定语言做出响应。开发人员可以通过微调保证模型在收到德语提示词后，始终以德语给出回应。更可靠的输出格式：微调使模型所输出响应结果的格式更加统一。对于需要特定响应格式的应用场景（例如代码补全或编写API调用），这种格式可靠性至关重要。例如，开发人员可以用微调将用户提示词转换为可在系统中使用的高质量JSON片段。自定义调节：微调是提升模型输出质量的好办法（包括改善语气、风格），更好地适应企业品牌的固有定位。拥有知名品牌调性的企业可以对模型做出微调，使其与自身市场形象更趋一致。</p><p>&nbsp;</p><p>除了提高性能之外，微调还能帮助企业缩短提示词长度，并保证性能基本不变。OpenAI表示，GPT-3.5 Turbo的微调可处理4k个tokens——可达之前微调模型的2倍。早期测试人员还对模型本身的指令进行了微调，从而将提示词长度缩短达90%，成功加快每次API调用的速度并降低了执行成本。</p><p>&nbsp;</p><p></p><h2>成本是更高了吗？</h2><p></p><p>&nbsp;</p><p>价格问题是开发者们普遍关注的问题之一。根据OpenAI说法，微调成本分为两个部分：初始训练成本与使用成本：</p><p>&nbsp;</p><p>训练：0.008美元/1K&nbsp;tokens使用输入：0.012美元/1K tokens使用输出：0.016美元/1K tokens</p><p>&nbsp;</p><p>例如，一个gpt-3.5-turbo微调作业中包含10万个token的训练文件。经过3个epoch训练轮次，预计成本为2.40美元。</p><p>&nbsp;</p><p>此前，OpenAI宣布各初版GPT-3基础模型（ada、babbage、curie和davinci）将于2024年1月4日正式关闭。OpenAI 如今发布了babbage-002和davinci-002作为这些模型的替代方案，用户可将其用作基础模型或微调模型。这些模型可以使用新API端点/v1/fine_tuning/jobs进行微调。下面是各基础/微调GPT-3模型的定价：</p><p><img src=\"https://static001.geekbang.org/infoq/20/20389e571631b6416a97c327d1e29ebd.png\" /></p><p>&nbsp;</p><p>对此，有网友算了一笔账：微调的 GPT 3.5 Turbo 生成成本是基本模型生成成本的 8 倍，因此用户确实必须处于OpenAI提到的“将提示大小减少 90%”的范围内，才能从中获得成本效益。</p><p>&nbsp;</p><p></p><blockquote>微调定价，每 16 次用户交互的成本将超过 1 美元：16 次交互 *（0.012 美元*4 输入 + 0.016 美元输出）= 1.02 美元。</blockquote><p></p><p>&nbsp;</p><p>本质上，一个简短的提示，如“打个招呼”，比一个长提示“给黄鼠狼宠物起五个可爱的名字”要花费更少的钱。“要想对一个花费 8 倍以上的微调模型来获得纯粹的财务胜利，需要您将输入和输出提示的大小减少 8 倍或更多。”开发者simonw表示。有开发者猜测，这是由于OpenAI需要存储和加载模型，即使他们或许也在使用类似 LoRA 的方式来微调模型。</p><p>&nbsp;</p><p>对此，也有网友表示，如果进行大量检索增强，那么 8 倍的成本可能仍然比在注入的上下文上消耗大量令牌便宜。</p><p></p><p>曾基于OpenAI API做过 GPT-3开发的drcode分享称，GPT 的“微调”与 Llama2 之类的微调不同，因为它可能不会调整网络的所有权重，只是会调整网络的一小部分。代价是 OpenAI 微调的成本较低，但它的功能也没有“真正的”微调强大。</p><p>&nbsp;</p><p></p><h2>附：微调步骤</h2><p></p><p>&nbsp;</p><p>目前微调需要准备数据、上传必要的文件并通过 OpenAI 的 API 创建微调作业，步骤如下：</p><p>&nbsp;</p><p>准备数据</p><p>&nbsp;</p><p><code lang=\"null\">{\n  \"messages\": [\n    { \"role\": \"system\", \"content\": \"You are an assistant that occasionally misspells words\" },\n    { \"role\": \"user\", \"content\": \"Tell me a story.\" },\n    { \"role\": \"assistant\", \"content\": \"One day a student went to schoool.\" }\n  ]\n}</code></p><p>&nbsp;</p><p>上传文件</p><p>&nbsp;</p><p><code lang=\"null\">curl -https://api.openai.com/v1/files \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -F \"purpose=fine-tune\" \\\n  -F \"file=@path_to_your_file\" </code></p><p>&nbsp;</p><p>创建微调作业</p><p>&nbsp;</p><p><code lang=\"null\">curl https://api.openai.com/v1/fine_tuning/jobs \\\n-H \"Content-Type: application/json\" \\\n-H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n-d '{\n  \"training_file\": \"TRAINING_FILE_ID\",\n  \"model\": \"gpt-3.5-turbo-0613\",\n}'</code></p><p>&nbsp;</p><p>在模型完成微调过程之后，可以立即在生产环境下使用，且具有与基础模型相同的共享速率限制。</p><p>&nbsp;</p><p>使用微调后的模型</p><p>&nbsp;</p><p><code lang=\"null\">curl https://api.openai.com/v1/chat/completions \\\n-H \"Content-Type: application/json\" \\\n-H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n-d '{\n  \"model\": \"ft:gpt-3.5-turbo:org_id\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"You are an assistant that occasionally misspells words\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Hello! What is fine-tuning?\"\n    }\n  ]\n}'</code></p><p>&nbsp;</p><p>该公司表示，所有微调数据都必须通过“审核”API 和 GPT-4 支持的审核系统，以查看是否与 OpenAI 的安全标准相冲突。OpenAI 还计划在未来推出一个微调 UI，其中包含一个仪表板，用于检查正在进行的微调工作负载的状态。</p><p>&nbsp;</p><p>OpenAI表示，在与其他技术（例如提示词工程、信息检索和函数调用）结合使用后，微调的潜力才能得到充分发挥。对函数调用和gpt-3.5-turbo-16k微调的支持也计划于今年秋季推出。</p><p>&nbsp;</p><p>对于OpenAI 开放 GPT-3.5 Turbo 微调，您有什么想法？欢迎在评论区发表您的观点！</p><p>&nbsp;</p><p>参考链接：</p><p>&nbsp;</p><p><a href=\"https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates\">https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates</a>\"</p><p><a href=\"https://news.ycombinator.com/item?id=37227139\">https://news.ycombinator.com/item?id=37227139</a>\"</p>",
    "publish_time": "2023-08-23 13:58:09",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "玉山银行数字化（上）：构建台湾第一个银行自建的“微服务架构”核心系统",
    "url": "https://www.infoq.cn/article/4IHu4Qv0hiJJgTwzo1W8",
    "summary": "<p></p><h3>引言</h3><p></p><p>玉山，海拔超过 3900 米，是台湾的第一高山；<a href=\"https://www.esun-bank.com.cn/\">玉山银行</a>\"名取自玉山，成立于 1992 年，是台湾最大的银行之一。</p><p></p><p>据 InfoQ 了解，台湾地区的银行分布密度极高，但利息差又极低。总面积 3.6 万平方公里，却聚集着近 70 家银行；而相较于大陆近几年平均 2.1% 的利息差，台湾地区银行的利息差只有 1.4% 左右。当地银行间的竞争之激烈可想而知。</p><p></p><p>面对市场的激烈竞争，风险管理能力成为决胜的关键点。为此，玉山银行早在 2006 年成立了大数据分析团队 CRV（Customer Risk &amp; Value），开始利用数据分析帮助银行实现更精准的风险管控。时机恰逢 Bank 3.0 时代伊始，银行服务无处不在，同样，风险也变得无处不在。</p><p></p><p>“但过去，一般面向客户 KYC（Know Your Customer），我们只会收集最基本的顾客资料，例如性别、教育程度、收入等等，这样的资料是静态的。”玉山银行数位长唐枬在接受 InfoQ 专访时表示，而实际上，用户的经济状况会随着时间不停改变，“为此，玉山银行意识到必须要更动态、适时地理解顾客的状况及需求”。</p><p></p><p>大数据分析团队 CRV 的成立，目的就是解决这个问题，通过瞄准客户风险价值，探勘既有的顾客 KYC 资料，更精细化地对客户进行分类。</p><p></p><p>此外，在玉山银行看来，数据的收集也与营销应用息息相关，这是持续提升客户体验的基础。玉山银行希望以内部的客户 KYC 资料作为基础，渐渐累积商业智能以外的数据处理经验，再辅以深度学习、语音识别、语音合成与影像识别等技术，将数据分析成果应用于数字业务及经营客群，向内外部客户提供更多具有创新、效率且有品质的服务。</p><p></p><p>自那之后，玉山银行的数字化转型，又分别经历了数字化、数字优化、数字转型三个阶段。并且，在这期间，构建了全台第一个银行自建的“微服务架构”核心系统，以该核心系统为“心脏”，人工智能为“大脑”，借由二者的相互搭配，实现银行服务体验优化、营运效率提升、成本降低及商品 / 服务模式创新等目标。相信其数字化实践路径和方法，将为业界提供具有价值的参考。</p><p></p><p></p><blockquote>本文是「玉山银行数字化实践」的上篇，主要分享玉山银行数字化转型的阶段性目标和问题拆解，以及背后从文化组织、业务流程到技术架构升级各方面的挑战和解法，包括玉山银行在其中的成功经验。在文章下篇我们将深度解读玉山银行的 3 大 FinTech 策略——普惠金融、智慧金融、场景金融。</blockquote><p></p><p></p><p>以下为采访实录（经 InfoQ 编辑整理）：</p><p></p><h2>以核心系统为“心脏”，人工智能为“大脑”</h2><p></p><p></p><h5>InfoQ：在玉山银行数字化转型的三个阶段，我们的目标以及需要解决的问题有何不同？</h5><p></p><p></p><p>唐枬：在“数字化”阶段，玉山银行主要是帮助顾客可以通过非实体（在线）的方式取得产品与服务。然而，我们发现，在前端数字化的背后，后端仍然是人工操作的作业流程，这样的数字化并没有达到提升内部效率的目的。</p><p></p><p>因此，进入“数字优化”阶段，我们开始通过<a href=\"https://live.infoq.cn/room/1848\"> AI 技术</a>\"等应用，发展真正端到端、由内部作业开始构建全数字化的产品，从而使得面向外部客户的数字化服务的使用率也大幅提升。</p><p></p><p>但是，随着越来越多数字产品的推出，我们发现，顾客对实体分行的需求仍没有减少，于是又进一步开始思考如何可以透过虚实整合，让数字能够成为分行发展的助力，以全渠道的方式提供顾客服务，并积极开展分行端的创新。为了支撑成倍增长的数字化交易，以及这样的数字优化，玉山银行从系统面着手，投入了 4 年多的时间，用最新的技术自建了新一代核心系统。</p><p></p><p>对玉山银行而言，数字化转型不仅仅是应用数字科技，最主要的目的是要创造顾客喜欢且满意的体验。为了迎接数字时代的到来，员工的能力、组织的样貌，甚至商业模式，都应该有所转变。</p><p></p><p>因此，在“数字转型”阶段，玉山进行了 29 年来最大规模的组织转型，分别成立个人及法人金融事业总处 。同时，整合产品资源、推出全新数字品牌 e. Fingo，并且发展场景生态圈，改变过往的获客方式，致力于无断点地串联产品，让金融服务真正像水电一般走入顾客的日常生活，创造更大顾客体验，也对银行带来更高的价值。</p><p></p><h5>InfoQ：传统金融机构普遍具有比较重的技术包袱，对玉山银行来说，在这个过程中是如何进行内部系统和技术架构的重新整合和升级的？</h5><p></p><p></p><p>唐枬：一方面，玉山银行构建了全台第一个银行自建的“<a href=\"https://www.infoq.cn/video/3UaAmw4dFVESmYhOZaZ2\">微服务</a>\"架构”核心系统，支持数字业务的快速发展。</p><p></p><p>金融业传统架构在大型主机上的封闭式核心系统，虽然稳定却缺乏灵活度，较难满足数字金融时代的步调。为此，玉山银行于 2016 年推动核心系统建置工程，从封闭式走向开放式架构，打造弹性且灵活的 IT 架构，作为数字金融时代的竞争基石。</p><p></p><p>玉山银行是台湾金融业首家自行开发设计银行核心系统的金融机构，要重新打造一颗银行全新的心脏，玉山银行最在乎的是核心系统的稳定性，以及面对数位时代瞬间大量的交易，能快速完成交易与弹性扩充。因此，玉山银行以开放的云原生（Cloud Native）技术、微服务（Microservices）架构来打造新核心系统。</p><p></p><p>此外，玉山银行也导入开发维运一体化（DevOps）机制，使用 CI/CD 将程序开发、测试与上线，通过自动化方式快速部署，并在开发上线时，使用自动化测试进行信息安全检核、系统回归测试、上版自动化等，降低因人为疏失，造成服务的中断。同时，玉山银行在设计新核心系统时，也纳入了未来业务发展的弹性，通过各项参数化、模块化设计，加速金融商品推出效率，提供顾客创新金融服务。</p><p></p><p>另一方面，在发展新一代核心系统的同时，玉山银行也同步建构 AI 应用，希望以核心系统为“心脏”，人工智能为“大脑”，借由“心脏与大脑”的相互搭配，实现优化服务体验、提高营运效率、降低成本及创新商品 / 服务模式等目标。</p><p></p><p>而开源软件则是玉山银行建构<a href=\"https://www.infoq.cn/article/UAupCc1Z0NppCUHEqoRE\">人工智能</a>\"大脑的关键，凭借已经成熟发展且很多人使用的开源软体，让玉山银行可以在短时间内快速发展出 AI 落地服务，打造一个涵盖系统底层到 AI 服务输出的机器学习即服务（Machine Learning as a Service， MLaaS）平台。</p><p></p><h5>InfoQ：在技术重构的过程中，我们遇到过什么印象深刻的挑战？又是如何化解的？</h5><p></p><p></p><p>唐枬：新核心计划是玉山银行科技发展与数字转型的关键基础工程。</p><p></p><p>1992 年玉山银行成立时，在 IBM 大型系统上开发的第一套核心系统，经过近 30 年，虽然仍稳定运作，却可能难以支持未来数字业务成长。然而，核心系统的重新建置，不仅将耗费极大的成本、人力与时间，转换失败的机率与风险亦甚高。对此，在玉山银行经营团队高度支持下，信息团队与业务团队携手，无后顾之忧地展开了这一浩大工程。</p><p></p><p>核心系统是银行业务运作的心脏，对于全行近百套业务系统，如何梳理系统间的串接，是第一大挑战。为此，玉山银行重新整编了架构师团队，让架构师的职责更为清楚，来思考相关解决方案，经过论辩、论证后，才找出真正能满足未来核心系统的架构。在完成了架构师团队整编，也制定出相关原则与准则之后，玉山银行开始发展新一版的信息蓝图，以顾客为中心的思考模式，制订出了从通路、顾客管理、产品管理、财务会计、风险管理到管理信息的业务发展模型。</p><p></p><p>完成了完整信息蓝图的构建，下一个挑战是如何落地。玉山银行的微服务是基于业务导向进行拆分的，在这个过程中，虽然玉山银行拥有许多具有丰富经验的信息人员，相当了解既有核心系统，因此，拆分微服务并未遭遇太大困难；然而，因为多数成员并没有微服务架构开发系统经验，导致初期出现较大挑战。为改善这一现象，玉山银行制订了一套微服务设计训练准则，引导团队遵循，透过确立工作方法、落实训练与实作，后续即顺利获得改善。</p><p></p><p>新兴科技确实驱动许多变革，但每隔一段时间就会有新技术被提出，信息部门需负责 IT 基础架构的规划，判断何为关键趋势，确保财务与人力资源投入的有效。在数字浪潮下，信息人员只专注技术已然不足，招募或培育具有信息技术能力与数字发展领域的人才，将是决定未来银行数字发展成效的关键。</p><p></p><h3>每年平均投入新台币 3.8 亿创新研发资金</h3><p></p><p></p><h5>InfoQ：其实转型涉及方方面面，除了技术之外，玉山银行又是如何构建更适应数字化发展的文化、组织和流程的？</h5><p></p><p></p><p>唐枬：玉山银行认为，数字化转型并不仅仅是将实体服务或产品转化为数字方式储存提供服务，而是要改变整体金融服务的流程、产品内容或商业模式。因此，主要挑战确实不仅在于导入新技术，更在于企业内部的组织、文化、策略的调整适应，资源及人力的投入，以及如何更好地做到虚实整合，以顾客导向思维提供有温度的金融服务。</p><p></p><p>从策略及文化面来看，玉山银行以信息为核心、科技为加速器，规划数字化发展蓝图，逐步建立了“导客 - 获客 - 活客 - 留客 - 悦客”五大引擎所需之数字能力，打造完整的信息与科技发展基础。同时，推动数据驱动决策之文化，掌握各单位关键绩效指标，提供经营团队即时资讯以掌握市场脉动，且透过 PDCA（Plan- 计划、Do- 执行、Check- 检查和 Action- 处理）+Benchmark 的检视流程，让绩效管理和策略目标紧密结合，并参考市场变化调整 OKR 及行动方案。</p><p></p><p>从组织架构和流程层面来看，以新核心系统的构建过程为例，期间不只是涉及核心系统的转换，我们更是通过此次的移转，将顾客信息的整合、人才的能力与专业技术，还有团队合作的机制与流程，都进行了重新打造。为此，玉山银行特别成立了一个专门的团队，负责新核心计划的发展、风险管理、人才培育等方式。</p><p></p><p>在新核心系统 2020/8 顺利上线后，2021 年（也就是在“数字转型”阶段）玉山银行启动了成立以来最大幅度的组织改造。以往，玉山银行的科技联队与业务联队是“互相整合”的关系，但这次组织改造更进一步做到“融合”，以“你中有我，我中有你”的概念，建立个人金融事业总处，将整个数字化客群与平台经营融入到个金融业务发展中。</p><p></p><p>此外，为了打造更具有敏捷精神的 IT 组织，玉山银行信息处也在 2021 年进行了组织改造，从“部 / 科”组织，调整为依业务领域设立信息发展中心，并于中心辖下设立小组，由兼顾技术、专业与管理能力的 Team Leader（TL）带领约 5-7 人具有高度弹性的小团队，从而适应数字时代的快速业务变化。</p><p></p><p>从资源及人力投入面来说，玉山银行近 5 年创新与研发资金每年平均为 3.8 亿，通过不断整合创新的服务，以及成立跨功能团队（Cross Functional Team），运用<a href=\"https://www.infoq.cn/article/9FRdGfIdRe3OIoygTBrt\">敏捷</a>\"开发 Scrum 架构，在团队高度自主管理与赋权下，快速从经验中学习、修正商品规划，实时响应市场、提供符合顾客需求的数字金融服务，来提高数字金融科技的效能。</p><p></p><h5>InfoQ：回顾玉山银行数字化转型的整个历程，您认为最值得分享的成功经验是什么？</h5><p></p><p></p><p>唐枬：数字化转型是企业提升竞争力的关键因素，有些企业挑选一个小部门做<a href=\"https://www.infoq.cn/theme/200\">数字化</a>\"，但是一艘小船难以拖动航空母舰 ; 有些企业选择许多部门做数字实验，但 100 支烟火亦难成为熊熊烈火 ; 有些企业将数字化用以节省成本，但企业本质没有改变。</p><p></p><p>玉山银行认为数字转型需要软硬兼备，因此采用 CSOP 创新与研发策略架构，以明确的战略布局、组织架构、人才发展，启动全面数字转型：</p><p></p><p>Culture 创新文化：建立信任容错的文化，鼓励多元尝试，并推广以数据导向（A/B Testing）的实验精神；</p><p></p><p>Strategy 策略连结：聚焦数字转型、海外布局、风险管理与 ESG 等策略面向投入创新与研发资源，目标是成为亚洲最具特色的标竿银行；</p><p></p><p>Organization 组织设计：建立科技储备干部（Technology Management Associate， TMA）制度、设置科技长并发展逾千人科技联队，以组织设计打造创新环境；</p><p></p><p>People 人才培育：以完整的训练模块培育创新人才，对外则透过产学合作、举办人工智能公开挑战赛及孵化新创企业，培育社会人才。</p><p></p><p>值得一提的是，玉山银行在发展数字战略时，不是用数字取代实体，而是注重两者互补关系，我们认为，实体通路不会消失。其次，数字策略中最重要的不是科技，而是顾客，要用科技让顾客更满意和更好体验。第三则是采取渐进改善的作法，靠不断改进来达到更好的服务，而非破坏式创新。</p><p></p><h5>InfoQ：最后总结分享一下玉山银行数字化转型下一步的工作重点，计划如何布局和实施？</h5><p></p><p></p><p>唐枬：玉山银行将持续以“建立制度、培育人才、发展信息”为永续发展的三大支柱，以 PDCA 循环进行创新与研发——通过 Plan 拟定创新策略、Do 高效执行、Check 檢查、Action 修正与行动，以成为金融创新的领航者为目标，积极推动数字转型，藉此创造玉山银行的成长动能。</p><p></p><p>Plan：以 CSOP–Culture、Strategy、Organization、People 作为创新与研发的策略架构，全面推动数字转型。</p><p></p><p>Do：投入逾千人「科技联队」分进合击，自行打造云原生的银行核心系统、并重点投入 AI 人工智能，同时建立项目流程控管制度、知识管理、专利管理制度，有纪律管理创新。</p><p></p><p>Check：以量化指标 - 数字顾客、数字互动、数字销售、数字营收占比，辅以质化获奖指标检视创新成效，确保创新投入符合目的。</p><p></p><p>Action：持续以顾客需求为核心，运用数据与 AI、整合虚实通路优化顾客体验，与业务共同精进优化，期透过科技成为亚洲最具特色标竿银行。</p><p></p><p>同时玉山银行也将秉持 5A 顾客经营策略，透过导客（Access）、获客（Acquire）、活客（Activate）、留客（Adhere）、悦客（Advocate）五个阶段，并结合数据导向、AI 赋能与稳固的信息建设，持续优化产品和服务，建立顾客黏着度和忠诚度，长期期望能提供顾客 Simple（简易）、Smooth（流畅）、Sweet（贴心） 的数字服务，攻占顾客的心占率，发展以人为本的数字金融领导品牌，成为亚洲最具特色的标竿银行。</p><p></p><h4>互动福利</h4><p></p><p>AIGC 热度一路狂飙，金融行业作为前沿技术应用的引领者，将迎来哪些新的机会？又如何冲破阻力借势而上？在「InfoQ数字化经纬」公众号文章评论区留言发表自己的观点和见解，将有机会获得精美礼品👇</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/12/6e/12cdc6ee765c5353e41da3555045e46e.png\" /></p><p></p><p></p><h4>嘉宾介绍</h4><p></p><p><img src=\"https://static001.infoq.cn/resource/image/e8/11/e8416d53cdc65260802a53588a26cf11.jpg\" /></p><p></p><p>唐枬（Danny Tang），玉山银行数位长，毕业于台湾大学工商管理系，并拥有加州大学洛杉矶分校的 MBA 学位。在加入玉山之前，任职美国 IBM 公司近 20 年，担任全球银行业的解决方案总监，拥有丰富的国际金融创新经验，提供逾 50 国银行顾问服务。Danny 在国际的金融相关期刊发表过许多文章，也曾获选为全球银行业最值得追踪的意见领袖之一。2021 年加入玉山后即针对玉山数字金融发展，提出以顾客为核心，聚焦在 5 个 A，包含 Access 导客、Acquire 获客、Activate 活客、Adhere 留客、Advocate 悦客，以达成 Simple、Smooth、Sweet 的 3S 顾客服务体验为目标的顾客经营策略。</p>",
    "publish_time": "2023-08-23 14:39:41",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "羿娲科技联合创始人 COO 贾梓筠博士确认出席 QCon 北京，分享 AIoT 创业项目从 0 到 1 的挑战与对策",
    "url": "https://www.infoq.cn/article/it4mDa29E5oCVqKR4DG9",
    "summary": "<p>9 月 3 日 - 5 日，在<a href=\"https://qcon.infoq.cn/202309/beijing/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=0823&amp;utm_content=jiaziyun\"> QCon 全球软件开发大会（北京站）</a>\"上，羿娲科技联合创始人 COO 贾梓筠博士将发表题为《AIoT 创业项目从 0 到 1 的挑战与对策》主题分享，解析一个 AIoT 创业项目的实战案例，并介绍后 ChatGPT 时代会对 AIoT 创业产生哪些影响。</p><p></p><p><a href=\"https://qcon.infoq.cn/202309/beijing/presentation/5402?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=0823&amp;utm_content=jiaziyun\">贾梓筠博士</a>\"，MIT&amp; 北交大联合培养博士，羿娲科技联合创始人 COO；前阿里巴巴 AI 产品专家、图灵机器人首席科学家；10 年 + 智能硬件产品化与商业化落地经验；国际论文 10+，国际专利 4+、中国专利 30+，机器人著作 2 部；中关村 U30 百强榜青年创业人才。她在本次会议的演讲内容如下：</p><p></p><p>演讲：AIoT 创业项目从 0 到 1 的挑战与对策</p><p></p><p>如果将 0 视为创业初期的 Idea，1 是 PMF，即产品匹配市场需求，那么一个项目从 0 到 1 的过程可分为想清楚、做出来、推出去三个阶段。对 AIoT 项目而言，每个阶段有不同挑战，例如想清楚阶段的商业模式和目标客户画像不清晰，做出来阶段会存在资源不足、技术链条协同困难、进度 Delay、返工等挑战。而 AIoT 项目又涉及软件和硬件链条算法链条，与软件项目管理相比，成本管理更为复杂，综合型人才稀缺，往往需要公司高管甚至一把手直接驱动。在此情况下，无法复用敏捷项目管理的思路，甚至某些环节要求一次性作对决策，对年轻 AIoT 创业者来说是巨大挑战。本次分享将解析一个 AIoT 创业项目的实战案例，并介绍后 ChatGPT 时代会对 AIoT 创业产生哪些影响。</p><p></p><p>演讲提纲：</p><p></p><p>AIoT 的前世今生创业项目从 0 到 1 的挑战 如何应对？AIoT 项目的北极星指标 后 ChatGPT 时代对 AIoT 创业的影响</p><p></p><p>你将获得：</p><p></p><p>○ 了解一个 AIoT 创业项目的实战案例</p><p>○ 了解用人、方向、数据指标、流程设计、组织架构设计和信息化的方法论与策略</p><p>○ 思考 AI 大模型技术 在企业项目管理中的应用机会</p><p></p><p>除上述演讲外，QCon 北京还将围绕 <a href=\"https://qcon.infoq.cn/202309/beijing/track/1556?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">FinOps&nbsp;落地</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1570?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">云原生</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1567?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">AIGC&nbsp;浪潮下的研发效能提升</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1558?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">业务安全技术</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1552?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">面向&nbsp;AI&nbsp;的存储</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1557?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">从&nbsp;BI&nbsp;到&nbsp;BI+AI，新计算范式下的大数据平台</a>\"等进行分享。</p><p></p><p>110+ 名嘉宾、近 30 个精彩专题、8 种交流活动，QCon 北京 2023，相约 9 月！咨询购票请联系 18514549229（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/33/33cbbbf20baa8b2a18db4f0681f159aa.jpeg\" /></p><p></p>",
    "publish_time": "2023-08-23 15:14:14",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "不止于 IT 运维，赋能行业的数科公司如何精准踩点？",
    "url": "https://www.infoq.cn/article/8yKQHyTP1cx05M6rM24m",
    "summary": "<p>在内外部环境影响下，数科公司的运营模式正在悄然发生转变，即从以往只服务集团内部，转变成为行业赋能。在这样的背景之下，数科公司不仅需要面临从产品到运营的挑战，还需要在服务好集团企业的同时，找寻商业闭环，为市场提供有价值的服务。那么在这个转变过程中，数科公司该如何更好发挥自己的优势，并且如何借助外力来赋能企业提升IT运营能力？</p><p></p><h1>数科公司向价值运营转型&nbsp;挑战重重</h1><p></p><p></p><p>就用友观察发现，数科公司的转型驱动因素来源于两方面：</p><p></p><p>从外部政策来看，国务院国资委围绕对标世界一流的财务管理体系建设、司库体系建设、国产化替代等发布的一系列文件，奠定央企数字化转型政策基础，政府政策加持下央企数智化、国产化进程进一步加速；</p><p></p><p>从内部来看，随着数智化转型在各个领域的广泛深入，传统企业的封闭式创新模式逐渐被突破，基于互联网的开放式创新模式不断涌现并迅猛发展，其中企业IT组织的服务对象也从“服务内部用户”逐渐向“服务外部用户”转型。这使得企业在数据利用、应用系统、系统架构、基础架构、组织治理、资金支持、市场推广等层面都发生了转变。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5e/5ea169ed9379828789ba60558991759b.png\" /></p><p></p><p>举例来说，“数据利用”需要从数据归纳、制作报告，转变为支撑深度分析和业务洞察；“系统架构”需要从过去的垂直孤岛系统，转为更为开放、易于扩展、互联互通的架构；组织治理，需要从围绕项目管理的职能分配，转变为围绕产品持续交付及运营；资金支持也由原来的自有资金，转变为市场化资本介入运作等等。</p><p>&nbsp;</p><p>然而，由于数科公司在产品成熟度、技术、市场覆盖度、资本合作、持续运营等方面能力不足，因此数科公司的转型过程仍面临一些挑战。具体挑战如下：</p><p></p><p>产品成熟度：如果数科公司选择自己从0开始研发数字化产品，需要经历不断的迭代和试错，成本较高。此外，还需要经历市场调查、需求调研、开发测试、产品推广等诸多阶段，周期较长，试错成本高；技术能力：通过大数据、AI、物联网等新技术，提升产品的先进性和竞争力已是当下的共识，但对于大部分数科公司而言，其职能更多聚焦在业务侧，会面临数据智能技术运用不足、数据整合能力亟待加强、架构灵活性较低、数据孤岛待打通等问题；营销、市场：数科公司缺少营销团队和伙伴渠道对行业和产业链客户进行触达，导致产品市场覆盖度较低，无法快速占领市场。此外，产品缺少专业的市场拓展，无法在行业内进行宣传推广；资本合作：资本是全面合作的催化剂，数科公司需要一支资源整合能力强、产业协同能力强、创新孵化能力强的专业产业投资公司进行资本合作和孵化，全面深化各领域合作，加快业务全面发展；运营能力：企业建立可持续的工程化能力及运营体系，需要专业的企业数字化公司提供全方位的持续运营赋能，包括顶层设计、团队建设、技术支持、市场推广等等。</p><p></p><h1>四种模式，用友与数科公司打造合作共赢的数字生态&nbsp;</h1><p></p><p></p><p>面对诸多挑战，数科公司如何才能迎刃而解？用友网络副总裁罗小江介绍，用友深耕企业服务三十余年，计划将用友积累的产品和运营优势赋能数科公司，并和数科公司携手合作，充分发挥各自优势，共同建立面向行业客户和产业链客户的全面服务能力。</p><p></p><p>针对数科公司自身需求及特点，用友为其量身打造了四种业务模式：</p><p></p><p>1.&nbsp;应用开发：基于用友iuap 和标准产品联合研发集团内应用软件及行业级应用软件；</p><p>2.&nbsp;专业服务：以行业级专业服务生态伙伴身份加入用友生态，为本行业客户提供项目实施交付服务；</p><p>3.&nbsp;销售合作：基于联合研发产品，针对行业客户，双向引流，联合营销；</p><p>4.&nbsp;联合运营：用友输出成熟的产品研发、IT 运维方法论，帮助企业建立可持续的运营能力体系。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f5/f501fa6a66ec6329aa76bf5a72e55639.png\" /></p><p></p><p>总结来说，第一，用友可以为数科公司提供完整的开发云，帮助数科公司将能力开放、集成；第二，双方可一同打造创新中心，IVE、领域专家、架构师等专业人才将与数科公司联合共创模型能力；第三，进行联合创新以后，知识产权将归属于数科公司；第四，助力数科公司建立市场渠道，让其能够快速触达到客户；第四，开放生态 API 能力、生态服务能力，从而加速数科公司的应用开发。</p><p>&nbsp;</p><p>目前，已经旭阳数科、双良混沌、中船信息、广药信息、中国振华、微乘科技等众多数科公司与用友展开了合作，旭阳数科便是标杆案例之一。据了解，旭阳数科以用友iuap 平台为原型构建了企业整体的数智化底座，并与业务深度融合，将原有100多个系统逐步迁移上来，包括 ERP、HRM、MES 等核心系统。同时，为了提升“双效”、提高工厂的管控能力和安全性，他们大力推进智能工厂建设，同样以iuap平台为基础，打造了焦化行业的第一个智能工厂，覆盖企业从原料煤运输、备煤、炼焦等五大环节的22个应用场景，创造了“互联网+协同制造”的数字化、智能化制造体系。</p><p></p><p>基于用友iuap平台强大的底座能力，旭阳云通过打造以垂直行业工业互联网平台为核心的产品体系，提供从规划咨询到软件产品和硬件支撑，从特种机器人到运维服务场景的整体解决方案，帮助企业提高资源配置效率，引领转型升级。</p><p></p><p>除此之外，在生态方面，旭阳数科不仅与用友共建了行业数智化联合创新中心，而且积极与产品ISV、专业服务伙伴和分销商打造各类型生态合作。</p><p></p><h1>全面的赋能体系，助力数科公司走向价值运营</h1><p></p><p></p><p>为加速数科公司构建数字生态及数字赋能增值体系，用友为数智公司提供了领先的产品与技术、强大的市场营销能力、大规模生态体系、完善的工程化能力、专业的投资与孵化平台等完善的能力、平台与资源，赋能数科公司实现长期可持续的价值运营。</p><p></p><p>首先，企业实现产品市场化，需要有一个经历过千锤百炼的成熟的底座进行支撑。用友提供了全球领先的数智商业创新平台——用友BIP。用友BIP PaaS平台iuap平台是更懂业务、技术领先、体系完整的企业数智化底座。它累积了用友35年服务数百万企业客户的人财物项、产供销研等10大领域和众多行业的应用实践，以企业业务为导向，实现了多项应用架构的领先创新和技术突破。基于三大中台和三大平台，形成了完整的企业数智化底座平台体系，并提供数智化工程、可持续运营两大体系，助力企业全面升级数智化底座。</p><p></p><p>其次，用友iuap具备领先的技术，通过敏捷、可靠、多云适配的技术平台，为数科公司商业创新提供了坚如磐石的技术保障，自研多维数据库实现了企业报表快速合并，全栈的信创适配能力和领先的信创实践为数科公司提供了完整的信创开发环境。</p><p>&nbsp;</p><p>首创企业服务大模型：发布首个多领域融合化、多形态综合型的企业服务大模型YonGPT，重新定义企业服务的新形态；首创YMS云中间件技术：实现跨云技术突破和多云适配能力。YMS Cloud(Yon Middleware Service)云中间件提供了统一的技术栈、统一的基础技术组件、统一配置管理、统一中间件适配能力，实现统一运营环境下的资源共享、降低微服务的服务器资源。首创云上云下一体的持续交付体系：用友BIP构建了完整的从公有云到私有云的敏捷工程化体系，实现了云上云下一体化一套代码的敏捷交付，让企业私有云平台体验到公有云的更新效率，让云下应用升级像 AppStore 一样简单，加速了企业的商业创新。领先的云监控大盘：为用友BIP稳定、高性能、持续安全运行保驾护航，承担健康管理专家角色；领先的多租户、多数据中心技术：多租户部署在多云异构的多数据中心，云上管理，云下运行，多数据中心技术提高了大规模公有云的性能稳定性，实现真正的专属云模式。领先的迁移家族：在不同环境中共享成果，便捷的开发迁移、环境迁移、配置迁移、档案迁移；自研多维数据引擎（存算一体）：实现100%自主安全可控，支持千亿级数据规模下的“多准则、多币种、主附表”快速合并，一键出表。这一技术已经在大型央企中进行了验证，实现了 1500 家分子公司规模的超大型企业报表的快速合并、一键出表。安全可信的国产化信创适配，为企业客户提供稳固可信、自主可控的数智化平台服务。比如多维引擎，与国内的信创服务商中国曙光进行了性能测试报告，并申请了相关专利。</p><p></p><p>第三，用友具备强大的市场营销能力。数科公司基于行业积累及业务洞察，与用友打造联合产品或解决方案，同时可以借助用友强大的市场营销能力和精准触达能力，通过丰富的市场活动形式进行宣传推广，扩大产品和解决方案在行业的影响力，在行业市场进行发声。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b3/b30f5ea952ea3af977ef6f53ab503494.png\" /></p><p></p><p>第四，不同的数科公司在业务发展中形成了具有鲜明特色的能力优势，用友丰富的合作伙伴合作模式为数科公司提供迈向市场的最优定位，用友大规模生态聚合优势可以助力合作产品精准大规模推广。</p><p></p><p>第五，通过敏捷工程化体系，可以实现敏捷化交付，快速响应客户需求。通过用友iuap技术平台的工程化能力，可以方便灵活地将企业自有的工程化的模块进行嵌入，实现灵活配置和优势互补。用友可以与众多领先数科公司合作运用平台工程，不断积累经验构建一套企业级产品运营体系，为产品全生命周期管理提供领先实践。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/92/9234b69375b1c49b361e195a2a676a14.png\" /></p><p></p><p>第六，提供专业投资与孵化平台。与互联网公司的投资不同，用友产投的目标不是通过投资来颠覆某个行业，而是赋能行业数科公司，和数科公司一起成长。用友产业投资秉承深耕数字科技产业、助力实体经济的发展理念，以“产业投资+产业孵化”为发展方向，不断增强在 投资、咨询、管理、分销、交付、并购等方面的综合能力，着力打造具有国际影响力的专业化产业投资与产业孵化平台。</p><p>&nbsp;</p><p>&nbsp;“产业数字化”和“数字产业化”的时代号角已经吹响，从IT运维转向价值运营，数科公司无疑需要承担更多的责任与挑战。展望未来，用友将与更多大型企业的数科公司、行业及领域ISV、专业服务商并肩，一同来打造共生共赢的合作生态，服务更多大型企业升级数智底座，加速数智化进程，实现商业创新。</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-08-23 16:04:11",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]