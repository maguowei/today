[
  {
    "title": "Visual Studio 17.7预览版：插件管理器和HTTP编辑器改进，与VSCode功能相比仍有差距",
    "url": "https://www.infoq.cn/article/I7ThoMmKYVF1wiZFWEXj",
    "summary": "<p>微软发布了<a href=\"https://learn.microsoft.com/en-us/visualstudio/releases/2022/release-notes-preview#17.7.0-pre.3.0\">Visual Studio 2022 17.7的第三个预览版本</a>\"。预览版本 3带来了一系列的改进和新特性，旨在提高开发人员的生产力，并帮助维护简洁的代码。预览版本3重点是为C++开发人员提供了一个名为#includes cleanup的新工具。<a href=\"https://visualstudio.microsoft.com/vs/preview/\">最新版本已经可以下载</a>\"，开发人员可以在预览版本中探索并利用它的最新进展。</p><p></p><p>预览版本3为C++、生产力、.NET和云开发、Microsoft 365开发和Teams工具包以及SQL Server Data Tools等多个领域带来了更改和改进。</p><p></p><p>作为最大的新闻，最新的更新引入了一个令人兴奋的新特性，称为“包含清理”（Include Cleanup）功能。这个有价值的工具为开发人员提供了在检测到间接包含时添加直接包含的建议，以及识别可以安全删除的任何冗余包含。值得注意的是，该功能在默认情况下处于禁用状态，以确保开发人员可以控制它的使用。为了利用它的优势，用户可以通过导航“工具”&gt;“选项”&gt;“文本编辑器”&gt;“C/C++”&gt;“IntelliSense”并选择“启用#include cleanup”选项来轻松地启用它。</p><p></p><p>在有关#include工具的<a href=\"https://devblogs.microsoft.com/cppblog/include-cleanup-in-visual-studio/\">原始博客文章</a>\"中，C++项目经理Mryam Girmay指出：</p><p></p><p></p><blockquote>……该功能通过生成删除未使用的头文件和添加直接头文件的建议来提高代码的质量。我们建议的工作流程是首先执行直接包含建议，在使用间接头文件的地方添加直接头文件，然后删除未使用的包含。</blockquote><p></p><p></p><p>对于C++和预览版本3，最新的更新还引入了对<a href=\"https://learn.microsoft.com/en-us/cpp/sanitizers/asan?view=msvc-170\">Address Sanitizer</a>\"支持的扩展，现在提供了continue_on_error模式。该运行时功能实现了对隐藏内存安全错误的实时检测和报告，并且零误报。开发人员可以通过为stdout设置ASAN_OPTIONS=continue_on_error=1或为stderr设置ASAN-OPTIONS=continue_on_eerror=2来将其集成到工作流中。该更新增强了应用程序的可靠性，并提供了更安全的代码库。</p><p></p><p>对于开发人员的<a href=\"https://learn.microsoft.com/en-us/visualstudio/releases/2022/release-notes-preview#productivity\">生产力</a>\"，体现在解决方案资源管理器中，在上下文菜单中添加了一个新的“折叠所有子节点”命令，使用户可以折叠选定的节点及其子节点。这也可以通过Ctrl+Left快捷键来实现。</p><p></p><p>此外，<a href=\"https://learn.microsoft.com/en-us/visualstudio/ide/finding-and-using-visual-studio-extensions?view=vs-2022\">扩展管理器</a>\"也进行了更新，以简化从Visual Studio Marketplace中发现和管理扩展的过程，从而更容易地更新现有的扩展。开发人员可以通过启用“工具”&gt;“选项”&gt;“环境”&gt;“预览功能”下的“扩展管理器UI刷新”预览功能来访问现代扩展管理器。</p><p></p><p>此外，最新版本还对<a href=\"https://learn.microsoft.com/en-us/visualstudio/releases/2022/release-notes-preview#net-and-cloud-development\">HTTP编辑器</a>\"进行了显著的改进。其中包括添加了一个新的响应视图，该视图支持JSON高亮显示。现在，开发人员可以很容易地检查原始响应、请求标头以及发送到Web服务器的请求。此外，用于发送请求的绿色播放按钮已被代码镜头操作所取代，从而简化了开发过程。</p><p></p><p>同样，开发人员现在可以利用Microsoft Power Platform的连接服务支持。正如发布文章中所报道的：你可以创建一个到Power Platform环境的自定义连接器，并创建一个开发隧道来本地测试和调试Web API项目。</p><p></p><p>其他更改则与Microsoft 365开发有关：Teams Toolkit现在提供了简化的Teams Tab应用程序模板。这个版本还包括缺陷修复和UI改进，增强了用户体验。此外，在<a href=\"https://learn.microsoft.com/en-us/visualstudio/releases/2022/release-notes-preview#ssdt-sql\">SQL Server Data Tools</a>\"中，最新的更新解决了将Azure Interactive Dir用于<a href=\"https://visualstudio.microsoft.com/vs/debug-in-azure/\">Azure Debugger</a>\"时的发布问题。此外，Target平台对SQL Serverless的命名已更改为<a href=\"https://learn.microsoft.com/en-us/azure/synapse-analytics/sql/on-demand-workspace-overview\">Azure Synapse Analytics Serverless SQL Pool</a>\"。</p><p></p><p>微软和开发团队<a href=\"https://developercommunity.visualstudio.com/VisualStudio/suggest\">鼓励用户提供反馈意见，并分享了他们对新功能和改进的建议</a>\"，强调了他们将致力于不断增强Visual Studio的体验。最后，有兴趣了解更多关于该版本和其他Visual Studio版本信息的开发人员可以访问有关Visual Studio 2022 IDE的其他更新，这些更改和新功能有<a href=\"https://learn.microsoft.com/en-us/visualstudio/releases/2022/release-notes-preview#1770-pre30--visual-studio-2022-version-177-preview-3\">非常详细的发布说明</a>\"。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/07/vs2022-v17-7-preview-3/\">https://www.infoq.com/news/2023/07/vs2022-v17-7-preview-3/</a>\"</p>",
    "publish_time": "2023-08-23 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "我们如何训练和应用大模型 | InfoQ《极客有约》",
    "url": "https://www.infoq.cn/article/5ZglMYd9IuxRQSXpAw2O",
    "summary": "<p>本期《极客有约》我们和数禾科技AI技术总监杨春勇聊聊如何解决模型计算底层应用的资源处理问题。</p>",
    "publish_time": "2023-08-23 09:10:18",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "混合精度下位置编码竟有大坑，llama 等主流开源模型纷纷中招！百川智能给出修复方案",
    "url": "https://www.infoq.cn/article/OcjyhximVsWg4o5rboDB",
    "summary": "<p>位置编码技术是一种能够让神经网络建模句子中Token位置信息的技术。在Transformer大行其道的时代，由于Attention结构无法建模每个token的位置信息，位置编码（Position Embedding)成为Transformer非常重要的一个组件。研究人员也提出了各种各样的位置编码方案来让网络建模位置信息，RoPE和 Alibi 是目前最被广泛采纳的两种位置编码方案。</p><p></p><p>然而最近来自百川智能的研究发现，RoPE和Alibi位置编码的主流实现在低精度（尤其是bfloat16)下存在位置编码碰撞的bug, 这可能会影响模型的训练和推理。而且目前大部分主流开源模型的实现都存在该问题，连llama官方代码也中招了。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/01eb204f519f1a3bbba3a2baf9da6393.png\" /></p><p></p><p></p><h2>还得从位置编码算法说起</h2><p></p><p></p><p>为了弄清楚这个问题，得先从位置编码的算法原理说起，在Transformer结构中，所有Attention&nbsp;Block的输入都会先经过位置编码,&nbsp;再输入网络进行后续处理。纯粹的Attention结构是无法精确感知到每个token的位置信息的，而对于语言的很多任务来说，语句的顺序对语义信息的影响是非常大的，为了建模token之间的位置关系，Transfomer原始论文中引入位置编码来建模位置信息。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/32/32967120b3070d35d0830e26c0a53dda.png\" /></p><p></p><p>图1-施加&nbsp;Positon&nbsp;Embedding&nbsp;示意图&nbsp;</p><p></p><p>为了让模型更好地建模句子的位置信息，研究人员提出了多种位置编码方案，Meta开源的llama模型采用了RoPE方案，使得RoPE成为在开源社区被广泛采纳的一种位置编码方案。Alibi编码也因为其良好的外推性也被广泛应用。</p><p></p><p>了解低精度下的位置编码碰撞之前，先来回顾一下相关算法原理</p><p></p><p>Sinusoidal位置编码</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e6/e61da7251a4b186b24da63f661606860.png\" /></p><p></p><p>这是Transformer原始论文中提出的位置编码方法。它通过使用不同频率的正弦和余弦函数来为每个位置产生一个独特的编码。选择三角函数来生成位置编码有两个良好的性质：</p><p></p><p>1）编码相对位置信息，数学上可以证明&nbsp;PE(pos+k)&nbsp;可以被&nbsp;PE(pos)&nbsp;线性表示，&nbsp;这意味着位置编码中蕴含了相对位置信息。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8e/8ee749ad80cc5f5e3c30415e3844fa23.png\" /></p><p></p><p>图2-句子长度为50的位置编码，编码维度128，每行代表一个Position&nbsp;Embedding</p><p></p><p>2）远程衰减：不同位置的position&nbsp;embedding点乘结果会随着相对位置的增加而递减。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/79/79dc2b1e8b3fe6bb3407c0de70363015.png\" /></p><p></p><p>图3-不同位置的位置编码点积可视化</p><p></p><p></p><h3>RoPE</h3><p></p><p></p><p>RoPE是目前开源社区应用最广泛的一种位置编码方案，&nbsp;通过绝对位置编码的方式实现相对位置编码，在引入相对位置信息的同时保持了绝对位置编码的优势（不需要像相对位置编码一样去操作Attention&nbsp;matrix)。令f_q,&nbsp;f_k&nbsp;为&nbsp;位置编码的函数，m表示位置,&nbsp;x_m&nbsp;表示该位置token对应的Embedding，希望经过位置编码后的Embedding&nbsp;点积仅和相对位置有关，则可以有公式</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f5/f559cabec80db456783b14b9f0fa03a9.png\" /></p><p></p><p>上面公式中g是某个函数，表示内积的结果只和x_m&nbsp;和&nbsp;x_n的值，以及二者位置的相对关系(m-n)有关在2维的情况下可以推导出（详细推导过程可参考原论文）：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9b/9bc0d18dbe8c0b452d5ac76a68a7435c.png\" /></p><p></p><p>因为矩阵乘法线性累加的性质，可以拓展到多维的情况可得：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f9/f938a63197c2e3d5ff64bc304631904c.png\" /></p><p></p><p>为了引入远程衰减的特性，Rope中\\theta的选取选择了Transformer&nbsp;原始论文中&nbsp;sinusoidal&nbsp;公式。</p><p></p><p></p><h3>Alibi</h3><p></p><p></p><p>Alibi是谷歌发表在ICLR2022的一篇工作，Alibi主要解决了位置编码外推效果差的痛点，算法思想非常的简单，而且非常直观。与直接加在Embedding&nbsp;上的绝对位置编码不同，Alibi的思想是在&nbsp;Attention&nbsp;matrix上施加一个与距离成正比的惩罚偏置，惩罚偏置随着相对距离的增加而增加。在具体实现时，对于每个head会有一个超参m&nbsp;来控制惩罚偏置随着相对距离增加的幅度（斜率）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b9/b9cce5a91e59e333c7848d019d4a9952.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/68/68a563c092f6706d27f8a3716055f91b.png\" /></p><p></p><p>图4-Alibi&nbsp;attention&nbsp;bias示意图</p><p></p><p>论文结果显示Alibi&nbsp;极大的提升了模型的外推性能，16k&nbsp;token&nbsp;的输入依然可以很好的支持</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e9/e9a2eac6f89e8a81b85c0d148ca0fa48.png\" /></p><p></p><p>图5-Alibi&nbsp;外推效果对比</p><p></p><p></p><h2>混合精度下位置编码的bug</h2><p></p><p></p><p>从上面的算法原理中，不管是RoPE&nbsp;的&nbsp;cos(m&nbsp;\\theta)&nbsp;还是alibi&nbsp;的&nbsp;i-1（m,&nbsp;i&nbsp;代表postion&nbsp;id),&nbsp;都需要为每个位置生成一个整型的position_id,&nbsp;在上下文窗口比较大的时候，百川智能发现目前主流的位置编码实现在混合精度下都存在因为低精度（float16/bfloat16)浮点数表示精度不足导致位置编码碰撞的问题。尤其当模型训练（推理）时上下文长度越来越长，低精度表示带来的位置编码碰撞问题越来越严重，进而影响模型的效果，下面以bfloat16为例来说明这个&nbsp;bug</p><p></p><p></p><h3>浮点数表示精度</h3><p></p><p></p><p>浮点数在计算机中表示由符号位（sign)，指数位(exponent)，尾数位(fraction)&nbsp;三部分组成,&nbsp;对于一个常规的数值表示，可以由如下公式来计算其代表的数值（其中offset是指数位的偏置）：(−1)sign∗2exponent−offset∗&nbsp;1.fraction由公式可知，尾数位的长度决定了浮点数的表示精度。深度学习中常用的&nbsp;float32/float16/bfloat16&nbsp;内存中的表示分别如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/99/99761418655f97e1ce8dd09e74febf3f.png\" /></p><p></p><p>图6-bfloat16&nbsp;的表示格式</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4b/4b96eb4bcf849b0ec99b48d53e951c86.png\" /></p><p></p><p>图7-float16&nbsp;的表示格式</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b5/b564ac3629f0eaf1478457c3b55558ec.png\" /></p><p>图8-float32&nbsp;的表示格式</p><p></p><p>可以看到可以看到float16和bfloat16相比于float32都牺牲了表示的精度，后续以bfloat16为例说明位置编码中存在的问题（float16同理）。&nbsp;下表展示了bfloat16在不同数值范围（只截取整数部分）内的表示精度。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e1/e15867272be48a2f7257420e26b32177.png\" /></p><p>可以看到当整数范围超过256，bfloat16就无法精确表示每一个整数，我们可以用代码验证一下表示精度带来的问题</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d9/d99a9388367466b2bb2117612c06ec05.png\" /></p><p></p><p></p><h3>RoPE&amp;&nbsp;Alibi&nbsp;编码的问题</h3><p></p><p></p><p>Meta开源的llama模型采用了RoPE的位置编码方式，官方的实现（以及大部分的第三方llama系列模型）在bfloat16下存在精度问题带来的位置编码碰撞（不同位置的token在bfloat16下变成同一个数）。llama官方代码如下：</p><p><img src=\"https://static001.geekbang.org/infoq/16/167c35f417e14c767e5bdbc58b6a72e9.png\" /></p><p></p><p>上面第18行核心一句根据输入序列长度生成每个位置的positonidx在bfloat16下产生位置碰撞</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0e/0ea73b01c1f0491280be73cf8940310c.png\" /></p><p></p><p>在实际训练时如果开了bfloat16,self.inv_freq的dtype会被转为bfloat16,我们可以通过简单的代码来看一下位置碰撞的问题</p><p><img src=\"https://static001.geekbang.org/infoq/a1/a15ac096412771b3c4fb02d3d1350e8b.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/58/586c77d014373d36bda4fdf37c9a31ad.png\" /></p><p>图9-bfloat16位置碰撞示意图</p><p></p><p>• 根据bfloat16的表示精度可知，训练（推理）时上下文长度越长，位置编码碰撞的情况越严重，长度为8192的上下文推理中，仅有大约10%的token位置编码是精确的，好在位置编码碰撞有局域性的特质，只有若干个相邻的token才会共享同一个positionEmbedding,在更大的尺度上，不同位置的token还是有一定的区分性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ef/efb63ef90d156427e1741dfd08ae1a04.png\" /></p><p>图10-不同上下文窗口下位置编码精确token所占比例</p><p>&nbsp;</p><p>除了RoPE位置编码方案，百川智能发现Alibi位置编码也存在上述问题，原因依然在于生成整数的位置索引时会在低精度下产生碰撞问题。</p><p>&nbsp;</p><p></p><h2>修复方案</h2><p></p><p></p><p></p><h3>RoPE修复</h3><p></p><p></p><p>￮&nbsp;RoPE的修复相对简单，只需要保证在生成position_id的时候一定在float32的精度上即可。注意：</p><p>▪&nbsp;float32的tensor register_buffer后在训练时如果开启了bfloat16,也会被转为bfloat16</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7f/7fd56c5f08e1acc71d53d345e94385f5.png\" /></p><p></p><p></p><h3>Alibi修复</h3><p></p><p></p><p>￮&nbsp;&nbsp;Alibi位置编码修复思路和RoPE的修复思路一致，但因为Alibi的attention bias直接加在attention matrix上面，如果按照上面的修复思路，attention matrix的类型必须和attention bias一致，导致整个attention的计算都在float32类型上计算，这会极大的拖慢训练速度</p><p></p><p>￮&nbsp;目前主流的attention加速方法flashattention不支持attention bias参数， 而xformers要求attention bias类型必须与query.dtype相同，因此像RoPE那样简单的将attention bias类型提升到float32将会极大的拖慢训练速度</p><p></p><p>￮&nbsp;针对该问题百川智能提出了一种新的Alibi attention方案， 整个attention bias依然在bfloat16类型上，类似于sinusoidal的远程衰减特质，我们尽量保证临近token位置编码的精确性，对于相对距离过远的的token我们则可以容忍其产生一定的位置碰撞。原本的Alibi实现则相反，相对距离越远的token表示越精确，相对距离越近的token则会碰撞</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c3/c3ad25c9614c0ef0c2f996ecd68d3c11.png\" /></p><p></p><p>图11-修复前后alibi attention_bias对照</p><p></p><p></p><h2>修复效果</h2><p></p><p></p><p>•&nbsp;此处仅在推理阶段对位置编码的精度问题进行修复【注：训练阶段可能也存在问题，取决于训练的具体配置和方法】，可以看到：</p><p>a.&nbsp;在长上下文的推理中，模型的ppl要显著优于修复前的ppl</p><p>b.&nbsp;Benchmark上测试结果显示修复前后区别不大，可能是因为benchmark上测试文本长度有限，很少触发Position embedding的碰撞</p><p></p><p></p><h3>Benchmark对比</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/af/af2b0985292e6fbf6546dd096b6e8970.png\" /></p><p></p><p></p><h3>Perplexity对比</h3><p></p><p></p><p>在通用的文本数据上对修改前后模型在中英文文本上的困惑度进行测试，效果如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d7/d7373342af4f4040a601084d01a14626.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/91/917042b5f8ccf7468a7d1699c1b87f96.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/64/6407bfa62d853922a8ad74a2bc40f24a.png\" /></p><p></p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/ff/ff2b53fd120bd9516766844551a24c6e.png\" /></p><p></p><p>&nbsp;</p><p>参考资料：</p><p></p><p>Dongxu Zhang, &amp; Dong Wang. (2015). Relation Classification via Recurrent Neural Network.</p><p>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, &amp; Illia Polosukhin. (2023). Attention Is All You Need.</p><p>Zihang Dai, Zhilin Yang, Yiming Yang, Jaime Carbonell, Quoc V. Le, &amp; Ruslan Salakhutdinov. (2019). Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context.</p><p>Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, &amp; Peter J. Liu. (2020). Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer.</p><p>Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, &amp; Guillaume Lample. (2023). LLaMA: Open and Efficient Foundation Language Models.</p><p>Jianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, &amp; Yunfeng Liu. (2022). RoFormer: Enhanced Transformer with Rotary Position Embedding.</p><p>Ofir Press, Noah A. Smith, &amp; Mike Lewis. (2022). Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation.</p><p>Yutao Sun, Li Dong, Barun Patra, Shuming Ma, Shaohan Huang, Alon Benhaim, Vishrav Chaudhary, Xia Song, &amp; Furu Wei. (2022). A Length-Extrapolatable Transformer.</p><p>https://kazemnejad.com/blog/transformer_architecture_positional_encoding/</p><p>Shouyuan Chen, Sherman Wong, Liangjian Chen, &amp; Yuandong Tian. (2023). Extending Context Window of Large Language Models via Positional Interpolation.</p><p>https://www.reddit.com/r/LocalLLaMA/comments/14lz7j5/ntkaware_scaled_rope_allows_llama_models_to_have/</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-08-23 10:50:59",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "谁说 AI 编程工具缺乏记忆和联想能力，简单琐碎的需求完全可以交给它",
    "url": "https://www.infoq.cn/article/yiLUmJIFFwVKkBmguIpu",
    "summary": "<p>今年算是 AI 正式破圈的一年，无数的工具，产品横空出世。无论在面向企业的大语言模型，还是帮助个人的 AI 工具，数不胜数。其中关于 AI 编程助手领域，近年来也涌现了很多不错的产品，例如 Copilot, Cursor, 还是我们今天要体验的 CodeWhisperer。已经在潜移默化中改变了程序员们的生产和解决问题的方式，传统解决问题往往依靠的是谷歌等搜索引擎，找到对应的官网和知名的论坛查找问题。而如今，我们仅仅依靠 AI 编程助手就能解决很多问题。</p><p></p><p>回到 CodeWhisperer 上来，它的出生还是带着许多光环的。首先来自著名的大厂 Amazon, 他们在 AI 领域有足够多的积累，在面向开发者方面有足够多的经验和产品用户体验来反馈用户感受，不断迭代相关产品，而且还有一个相当强大的优势，借助亚马逊云的力量，能够将 AI 和云打通，这在当前云原生时代是必不可少的能力。</p><p></p><p></p><h2>目标及前期准备</h2><p></p><p></p><p>先给大家讲讲今天我们希望实现的目标，基于 Spring Boot 框架，简单实现用户登陆，。我们使用的是 IntelliJ 开发工具，选用 Maven 进行管理依赖管理，用到的依赖如下。</p><p></p><p>WebJPAH2</p><p></p><p>我们首先尝试安装 CodeWhisperer 插件，在 Plugins 中搜索 AWS Toolkit 下载即可。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c9/c9cb132ddd4b715d77597ad7909fd2ca.png\" /></p><p></p><p>下载完成后绑定自己的亚马逊账号即可开始使用，默认开启自动建议。</p><p></p><p>项目结构如图所示</p><p><img src=\"https://static001.geekbang.org/infoq/b4/b4e1550475358d429df0c06fd5d673d9.png\" /></p><p></p><p>pom.xml 文件如下</p><p><code lang=\"text\"><!--?xml version=\"1.0\" encoding=\"UTF-8\"?-->\n\n4.0.0\n\norg.springframework.boot\nspring-boot-starter-parent\n3.1.0\n <!-- lookup parent from repository -->\n\ncom.example\ndemo\n0.0.1-SNAPSHOT\ndemo\ndemo\n\n17\n\n\n\norg.springframework.boot\nspring-boot-starter-data-jpa\n\n\n\norg.projectlombok\nlombok\ntrue\n\n\norg.springframework.boot\nspring-boot-starter-web\n\n\n\ncom.h2database\nh2\nruntime\n\n\norg.springframework.boot\nspring-boot-starter-test\ntest\n\n\n\n\n\n\norg.springframework.boot\nspring-boot-maven-plugin\n\n\n\n\n\n</code></p><p></p><p></p><h2>开始</h2><p></p><p></p><p>健康检查</p><p>我们先实现一个最简单的 Controller，请求 /ping 返回 pong 即可。</p><p></p><p><code lang=\"text\">package com.example.demo.controller;\n\nimport org.springframework.stereotype.Controller;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.ResponseBody;\n\n@Controller\npublic class PingController {\n\n    @RequestMapping(\"/ping\")\n    public @ResponseBody String greeting() {\n        return \"pong\";\n    }\n\n}</code></p><p></p><p>测试用例是检验代码正确性必不可少的一环，我们来写个简单的测试用例。这时 CodeWhisperer 已经开始展示它的实力了，只是写了一行 @Test 注解，它将我们想要做的测试代码完整提示出来。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1f/1f15552b186f211ebbafb25651b68503.png\" /></p><p></p><p>下面是完整的测试代码。</p><p><code lang=\"text\">package com.example.demo;\n\nimport com.example.demo.controller.PingController;\nimport org.junit.jupiter.api.Test;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.boot.test.autoconfigure.web.servlet.AutoConfigureMockMvc;\nimport org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTest;\nimport org.springframework.test.web.servlet.MockMvc;\n\nimport static org.springframework.test.web.servlet.result.MockMvcResultHandlers.print;\nimport static org.springframework.test.web.servlet.result.MockMvcResultMatchers.content;\nimport static org.springframework.test.web.servlet.result.MockMvcResultMatchers.status;\nimport static org.springframework.test.web.servlet.request.MockMvcRequestBuilders.get;\n\n@AutoConfigureMockMvc\n@WebMvcTest(PingController.class)\npublic class TestWebApplication {\n    @Autowired\n    private MockMvc mockMvc;\n\n    @Test\n    public void shouldReturnDefaultMessage() throws Exception {\n        this.mockMvc.perform(get(\"/ping\")).andDo(print()).andExpect(status().isOk())\n                .andExpect(content().string(\"pong\"));\n    }\n}\n</code></p><p></p><p>运行一下测试用例，很顺利的通过🎉。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/12/129e75101051dd8b06d68bd62e267618.png\" /></p><p></p><p>用户类设计</p><p></p><p>我们来定一个 User 模型，发现它在 Table To Class 的实现中具备一定的表设计能力，以及字段关联联想，约束设计能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ff/ff1736b30f934fc4bfd593e8acebb76d.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d9/d95f1d75c172c72fb86feddfbccc6d28.png\" /></p><p></p><p>能推测我想要的表字段，索引约束建议。这对于新手来说是莫大的帮助，想象有一位功力深厚的同伴在旁指点你设计表结构，那么表结构的设计就能相对合理一些。</p><p><code lang=\"text\">package com.example.demo.model;\n\n\nimport jakarta.persistence.*;\nimport lombok.AllArgsConstructor;\nimport lombok.Getter;\nimport lombok.NoArgsConstructor;\nimport lombok.Setter;\nimport org.springframework.stereotype.Indexed;\n\n@Entity\n@Getter\n@Setter\n@AllArgsConstructor\n@NoArgsConstructor\n@Table(name = \"game_users\")\npublic class User {\n    @Id\n    private Long id;\n    @Column(unique = true, nullable = false)\n    private String username;\n    @Column(nullable = false, length = 64)\n    private String password;\n    @Column(unique = true, nullable = false)\n    private String email;\n}\n</code></p><p></p><p>DAO 层实现</p><p></p><p>这时我灵光一现，根据官网的 GIF 图展示，可以通过注释进行代码推断，那好，DAO 层的实现就交给它啦。</p><p><img src=\"https://static001.geekbang.org/infoq/9a/9a7477a0ba9ed9586699dd91fbd14b93.png\" /></p><p></p><p>哎哟，不错哦，根据我上面想要根据邮箱查询用户的注视，它已经给出了相应的提示，让我们再考考它，注释中进行多个方法的描述。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/22/223464519261a7e4dce1e87a41d8ea99.png\" /></p><p></p><p>挺聪明呀，也很顺利的实现了。</p><p></p><p><code lang=\"text\">package com.example.demo.dao;\n\nimport com.example.demo.model.User;\nimport org.springframework.data.jpa.repository.JpaRepository;\nimport org.springframework.stereotype.Repository;\n\nimport java.util.Optional;\n\n@Repository\npublic interface UserDao extends JpaRepository {\n    // function to implement find user by email\n    Optional findByEmail(String email);\n\n    Optional findByUsername(String username);\n\n    // two function to implement find user by id or email\n    Optional findById(Long id);\n    Optional findByEmailIgnoreCase(String email);\n\n    // function to implement check user is existed\n    Boolean existsByEmail(String email);\n\n}\n</code></p><p></p><p>看来以后 CRUD 的 DAO 层实现可以交给它来完成啦。我们希望能够预先插入一些数据便于测试，琐碎的日志测试对它来说轻轻松松。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f7/f7b8df0190574ddee4053206908f964d.png\" /></p><p></p><p><code lang=\"text\">package com.example.demo;\n\nimport com.example.demo.dao.UserDao;\nimport com.example.demo.model.User;\nimport org.slf4j.Logger;\nimport org.springframework.boot.CommandLineRunner;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\n\n@Configuration\nclass LoadDatabase {\n    public static final Logger log = org.slf4j.LoggerFactory.getLogger(LoadDatabase.class);\n\n    // this is Bean is loaded once in the application context\n    // it is used to load the data into the database\n    @Bean\n    public CommandLineRunner initDatabase(UserDao dao) {\n        return args -&gt; {\n            log.info(\"Preloading \" + dao.save(new User(1L, \"test1\", \"111111\", \"abc@gmail.com\")));\n            log.info(\"Preloading \" + dao.save(new User(2L, \"test2\", \"222222\", \"123@gmail.com\")));\n        };\n    }\n}\n</code></p><p></p><p>Service 层实现</p><p></p><p>轮到 Service 层了，让我们看看它的表现，在这里我们简单的根据用户名查询用户，返回对应的数据即可。当我方法签名写一半时，它给我的建议让我停下继续敲击的手指，因为基本符合我的预期，而且具备一定的记忆联想能力，在 DAO 层定义的 Optional，这里也能找到对应的方法进行处理。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d7/d7c42ac068b25d92ef1c6f74789e7d6f.png\" /></p><p></p><p><code lang=\"text\">package com.example.demo.service;\n\nimport com.example.demo.dao.UserDao;\nimport com.example.demo.model.User;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.stereotype.Service;\n\nimport java.util.Optional;\n\n@Service\npublic class UserDetailServiceImpl {\n    private final UserDao userdao;\n\n    @Autowired\n    public UserDetailServiceImpl(UserDao userdao) {\n        this.userdao = userdao;\n    }\n\n    public User getUserByUsername(String username) throws Exception {\n        Optional user = userdao.findByUsername(username);\n        if (user.isPresent()) {\n            return user.get();\n        } else {\n            throw new Exception(\"User not found\");\n        }\n    }\n}\n</code></p><p></p><p>Controller 层实现</p><p></p><p>最后我们来实现最外层入口，简单的进行相关业务校验，用户名是否为空，密码是否正确，在这里用于演示。</p><p><img src=\"https://static001.geekbang.org/infoq/63/630f79d9119c36fcbcc756a2b379e8d9.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9d/9d2c2e078f6cc74eda6368403486281b.png\" /></p><p></p><p>用户不存在相关处理，密码正确性验证，基本符合我们的要求。</p><p></p><p><code lang=\"text\">package com.example.demo.controller;\n\nimport com.example.demo.model.User;\nimport com.example.demo.service.UserDetailServiceImpl;\nimport org.apache.coyote.Response;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.http.HttpStatus;\nimport org.springframework.http.ResponseEntity;\nimport org.springframework.web.bind.annotation.*;\n\n@RestController\n@RequestMapping(\"/api/auth\")\npublic class UserController {\n    private final UserDetailServiceImpl userDetailService;\n\n    @Autowired\n    public UserController(UserDetailServiceImpl userDetailService) {\n        this.userDetailService = userDetailService;\n    }\n\n    @PostMapping(\"/login\")\n    public ResponseEntity<!--?--> login(@RequestBody User user) {\n        try {\n            if (user.getUsername().isEmpty()) {\n                return ResponseEntity.badRequest().body(\"user name is empty\");\n            }\n\n            User res;\n            res = userDetailService.getUserByUsername(user.getUsername());\n            if (res == null) {\n                return ResponseEntity.badRequest().body(\"user not  found\");\n            }\n\n            if (res.getPassword().equals(user.getPassword())) {\n                return ResponseEntity.ok(res);\n            }\n            return new ResponseEntity&lt;&gt;(\"user password invalid\", HttpStatus.BAD_REQUEST);\n        } catch (Exception e) {\n            return ResponseEntity.notFound().build();\n        }\n    }\n}\n</code></p><p></p><p>最后我们来测试一下，格式错误和用户密码错误的情况。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/42/42c109e87539d87d7961febae59764d4.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/23/230784c0e5596c4ee345b861a11099a9.png\" /></p><p>与预期一致，撒花。</p><p></p><h2>总结</h2><p></p><p></p><p>CodeWhisperer 就我今天的使用而言，还是有些出乎我的意料，之前的一些 AI 编程工具并不具备记忆和联想能力，今天 CodeWhisperer 展示的记忆联想效果不错，并且具备一定的表结构设计能力，一些简单的测试用例完成度也不错，我想未来一些简单琐碎的需求，测试用例也可以交给它了。但是今天在体验的过程中还是发现了一些不足，插件 UI 会出现挡住建议的情况，这样我需要再次触发建议才行，目前阶段可以使用它来投入生产，在一些复杂的场景还是需要谨慎，会出现胡言乱语的情况，跟上下文关联性不强的建议。</p><p></p><p>当然，这些问题相信随着模型的数据量级和质量不断优化能够慢慢解决🎉。</p><p></p><p>版权声明: 本文为 InfoQ 作者【天黑黑】的原创文章。</p><p>原文链接:【<a href=\"https://xie.infoq.cn/article/179127e04fff483aac667444d\">https://xie.infoq.cn/article/179127e04fff483aac667444d</a>\"】。文章转载请联系作者。</p>",
    "publish_time": "2023-08-23 10:56:28",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "时间敲定！企业数据将作为资产被纳入会计报表",
    "url": "https://www.infoq.cn/article/4rsaCarUujfmVyxW8wWl",
    "summary": "<p></p><p>据<a href=\"http://kjs.mof.gov.cn/zhengcefabu/202308/t20230821_3903354.htm\">财政部网站</a>\"8月21日消息，为规范企业数据资源相关会计处理，强化相关会计信息披露，财政部发布了《企业数据资源相关会计处理暂行规定》（下称《暂行规定》），该规定自2024年1月1日起施行。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/a2/6d/a2c75e230a53877137a0246ddbba246d.jpg\" /></p><p></p><p>数据，是数字经济时代的生产要素。《暂行规定》的发布意味着数据将作为资产被纳入会计报表，从而有助于推动数据要素资产化，这反映了数据资源在生产要素中的地位，也体现了我国在制度层面进行的创新。</p><p></p><p>2022年12月19日，《中共中央国务院关于构建数据基础制度更好发挥数据要素作用的意见》（以下简称“数据二十条”）对外发布，从数据产权、流通交易、收益分配、安全治理等方面构建数据基础制度，提出20条政策举措。</p><p></p><p>当时“数据二十条”的出台为数据要素市场建设提供了顶层制度设计。其后，在此背景下，各地相继制定了多项地方或行业促进方案，旨在鼓励和推动数字经济的发展，以及促进数据要素的流通，地方上数据交易市场也在不断建立和完善。</p><p></p><p>根据《暂行规定》对适用范围的定义，数据资源是指企业按照企业会计准则相关规定确认为无形资产或存货等资产类别的数据资源，以及企业合法拥有或控制的、预期会给企业带来经济利益的、但由于不满足企业会计准则相关资产确认条件而未确认为资产的数据资源。</p><p></p><p>据财政部会计司有关负责人介绍，《暂行规定》包括以下四部分内容：</p><p></p><p>一是适用范围。明确《暂行规定》适用于符合企业会计准则规定、可确认为相关资产的数据资源，以及不满足资产确认条件而未予确认的数据资源的相关会计处理。后续随着未来数据资源相关理论和实务的发展，可及时跟进调整。</p><p></p><p>二是数据资源会计处理适用的准则。按照会计上的经济利益实现方式，根据企业使用、对外提供服务、日常持有以备出售等不同业务模式，明确相关会计处理适用的具体准则，同时，对实务反映的一些重点问题，结合数据资源业务等实际情况予以细化。</p><p></p><p>三是列示和披露要求。要求企业应当根据重要性原则并结合实际情况增设报表子项目，通过表格方式细化披露，并规定企业可根据实际情况自愿披露数据资源（含未作为无形资产或存货确认的数据资源）的应用场景或业务模式、原始数据类型来源、加工维护和安全保护情况、涉及的重大交易事项、相关权利失效和受限等相关信息，引导企业主动加强数据资源相关信息披露。</p><p></p><p>四是附则。《暂行规定》将自2024年1月1日起施行，企业应当采用未来适用法应用本规定。</p><p></p><p>财政部会计部相关负责人亦明确表示，企业在贯彻实施《暂行规定》时需要注意以下三个事项：一是正确做好前后衔接；二是严格执行企业会计准则；三是是积极加强信息披露。</p><p></p><p>德勤中国风险咨询合伙人何铮认为，《暂行规定》的发布会给企业正在进行的数字化转型带来实质性的推动作用，促进数据资产价值的可量化，值得企业各利益相关方的重视。具体而言，其对企业带来的多方面改变包括：</p><p>企业数据资源采购数据资源开发与应用数据治理数据资源相关科目设定与会计处理数据资源相关税务处理数据资源相关信息披露数据资源及企业估值……</p><p></p><p>“企业数据资产化与数字化转型关联紧密、相辅相成，数据资产化既可以成为数字化转型的成效之一，也是实现数字化转型重要举措。”何铮表示，着眼于数据资源入表，企业可以从数据资产化战略、数据驱动业务经营与决策、数据资产管理与运营、数据资产价值评估、数据资源会计处理与信息披露等方面入手，多层次、端到端、跨条线着手准备并开展试点实践。</p><p></p><p>参考链接：</p><p><a href=\"https://mp.weixin.qq.com/s/o65I8ZIQ7b_j2FyE_hkRug\">https://mp.weixin.qq.com/s/o65I8ZIQ7b_j2FyE_hkRug</a>\"</p><p><a href=\"http://kjs.mof.gov.cn/zhengcejiedu/202308/t20230821_3903359.htm\">http://kjs.mof.gov.cn/zhengcejiedu/202308/t20230821_3903359.htm</a>\"</p><p></p><p>附下载：</p><p><a href=\"http://kjs.mof.gov.cn/zhengcefabu/202308/P020230821585628790308.pdf\">企业数据资源相关会计处理暂行规定.pdf</a>\"</p>",
    "publish_time": "2023-08-23 11:17:08",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "重磅！OpenAI 开放 GPT-3.5 Turbo 微调，网友：将prompt减少90%才实惠",
    "url": "https://www.infoq.cn/article/3le2VX8uRPBOllXeoTKz",
    "summary": "<p>当地时间8月22日，<a href=\"https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates\">OpenAI 宣布</a>\"企业现在可以使用自己的数据对 GPT-3.5 Turbo&nbsp;进行微调，OpenAI 声称最终的定制模型可以赶上甚至超过 GPT-4 执行某些任务的能力。今年秋天OpenAI 将开放更先进的GPT-4。</p><p>&nbsp;</p><p>该公司表示，此次更新将使开发人员能够自定义更适合实际用例的模型，并大规模运行这些自定义模型。OpenAI 强调，传入和传出微调 API 的数据归客户所有， OpenAI或任何其他组织不会使用这些数据来训练其他模型。</p><p>&nbsp;</p><p>OpenAI 此举似乎挽回了一些针对其开源的质疑，有网友评价称，“许多人支持开源人工智能，并批评 OpenAI 不够开放。但最重要的是，OpenAI 在不断创新。”</p><p>&nbsp;</p><p></p><h2>微调用例</h2><p></p><p>&nbsp;</p><p>GPT-3.5 Turbo是OpenAI推出的一种先进的语言模型，它能够准确理解并生成自然语言的文本。相比于之前的版本，GPT-3.5 Turbo在多个方面有了极大的改进。比如，它具备更加出色的上下文理解能力，能够更好地理解用户的问题或指令，从而提供更准确的回答。它还能够产生更流畅、连贯的文本，仿佛是由人类写就的一样。最重要的是，GPT-3.5 Turbo具备更快的响应速度，使得用户可以即时得到答案或帮助。</p><p>&nbsp;</p><p>自GPT-3.5 Turbo发布以来，开发人员和企业纷纷要求开放模型自定义功能，以便为用户创造独特且差异化的体验。通过此次发布，开发人员现可运行监督微调，使得该模型在不同用例中表现更好。</p><p>&nbsp;</p><p>微调的基本思想是，先在大规模文本数据上预训练一个大型的语言模型，例如GPT-3.5，然后使用特定任务的数据集（如法律、医疗），进一步对模型进行训练，以适应特定的任务。在这个过程中，模型的参数会进行微小的调整，使其在特定业务场景上的性能更好。</p><p>&nbsp;</p><p>在OpenAI 的内部beta测试中，微调客户已经能够在各类常见用例中显著提高模型性能，例如：</p><p>&nbsp;</p><p>改善可操纵性：微调允许企业引导模型更好地遵循指令，例如输出更简洁的答案，或者始终以给定语言做出响应。开发人员可以通过微调保证模型在收到德语提示词后，始终以德语给出回应。更可靠的输出格式：微调使模型所输出响应结果的格式更加统一。对于需要特定响应格式的应用场景（例如代码补全或编写API调用），这种格式可靠性至关重要。例如，开发人员可以用微调将用户提示词转换为可在系统中使用的高质量JSON片段。自定义调节：微调是提升模型输出质量的好办法（包括改善语气、风格），更好地适应企业品牌的固有定位。拥有知名品牌调性的企业可以对模型做出微调，使其与自身市场形象更趋一致。</p><p>&nbsp;</p><p>除了提高性能之外，微调还能帮助企业缩短提示词长度，并保证性能基本不变。OpenAI表示，GPT-3.5 Turbo的微调可处理4k个tokens——可达之前微调模型的2倍。早期测试人员还对模型本身的指令进行了微调，从而将提示词长度缩短达90%，成功加快每次API调用的速度并降低了执行成本。</p><p>&nbsp;</p><p></p><h2>成本是更高了吗？</h2><p></p><p>&nbsp;</p><p>价格问题是开发者们普遍关注的问题之一。根据OpenAI说法，微调成本分为两个部分：初始训练成本与使用成本：</p><p>&nbsp;</p><p>训练：0.008美元/1K&nbsp;tokens使用输入：0.012美元/1K tokens使用输出：0.016美元/1K tokens</p><p>&nbsp;</p><p>例如，一个gpt-3.5-turbo微调作业中包含10万个token的训练文件。经过3个epoch训练轮次，预计成本为2.40美元。</p><p>&nbsp;</p><p>此前，OpenAI宣布各初版GPT-3基础模型（ada、babbage、curie和davinci）将于2024年1月4日正式关闭。OpenAI 如今发布了babbage-002和davinci-002作为这些模型的替代方案，用户可将其用作基础模型或微调模型。这些模型可以使用新API端点/v1/fine_tuning/jobs进行微调。下面是各基础/微调GPT-3模型的定价：</p><p><img src=\"https://static001.geekbang.org/infoq/20/20389e571631b6416a97c327d1e29ebd.png\" /></p><p>&nbsp;</p><p>对此，有网友算了一笔账：微调的 GPT 3.5 Turbo 生成成本是基本模型生成成本的 8 倍，因此用户确实必须处于OpenAI提到的“将提示大小减少 90%”的范围内，才能从中获得成本效益。</p><p>&nbsp;</p><p></p><blockquote>微调定价，每 16 次用户交互的成本将超过 1 美元：16 次交互 *（0.012 美元*4 输入 + 0.016 美元输出）= 1.02 美元。</blockquote><p></p><p>&nbsp;</p><p>本质上，一个简短的提示，如“打个招呼”，比一个长提示“给黄鼠狼宠物起五个可爱的名字”要花费更少的钱。“要想对一个花费 8 倍以上的微调模型来获得纯粹的财务胜利，需要您将输入和输出提示的大小减少 8 倍或更多。”开发者simonw表示。有开发者猜测，这是由于OpenAI需要存储和加载模型，即使他们或许也在使用类似 LoRA 的方式来微调模型。</p><p>&nbsp;</p><p>对此，也有网友表示，如果进行大量检索增强，那么 8 倍的成本可能仍然比在注入的上下文上消耗大量令牌便宜。</p><p></p><p>曾基于OpenAI API做过 GPT-3开发的drcode分享称，GPT 的“微调”与 Llama2 之类的微调不同，因为它可能不会调整网络的所有权重，只是会调整网络的一小部分。代价是 OpenAI 微调的成本较低，但它的功能也没有“真正的”微调强大。</p><p>&nbsp;</p><p></p><h2>附：微调步骤</h2><p></p><p>&nbsp;</p><p>目前微调需要准备数据、上传必要的文件并通过 OpenAI 的 API 创建微调作业，步骤如下：</p><p>&nbsp;</p><p>准备数据</p><p>&nbsp;</p><p><code lang=\"null\">{\n  \"messages\": [\n    { \"role\": \"system\", \"content\": \"You are an assistant that occasionally misspells words\" },\n    { \"role\": \"user\", \"content\": \"Tell me a story.\" },\n    { \"role\": \"assistant\", \"content\": \"One day a student went to schoool.\" }\n  ]\n}</code></p><p>&nbsp;</p><p>上传文件</p><p>&nbsp;</p><p><code lang=\"null\">curl -https://api.openai.com/v1/files \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -F \"purpose=fine-tune\" \\\n  -F \"file=@path_to_your_file\" </code></p><p>&nbsp;</p><p>创建微调作业</p><p>&nbsp;</p><p><code lang=\"null\">curl https://api.openai.com/v1/fine_tuning/jobs \\\n-H \"Content-Type: application/json\" \\\n-H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n-d '{\n  \"training_file\": \"TRAINING_FILE_ID\",\n  \"model\": \"gpt-3.5-turbo-0613\",\n}'</code></p><p>&nbsp;</p><p>在模型完成微调过程之后，可以立即在生产环境下使用，且具有与基础模型相同的共享速率限制。</p><p>&nbsp;</p><p>使用微调后的模型</p><p>&nbsp;</p><p><code lang=\"null\">curl https://api.openai.com/v1/chat/completions \\\n-H \"Content-Type: application/json\" \\\n-H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n-d '{\n  \"model\": \"ft:gpt-3.5-turbo:org_id\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"You are an assistant that occasionally misspells words\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Hello! What is fine-tuning?\"\n    }\n  ]\n}'</code></p><p>&nbsp;</p><p>该公司表示，所有微调数据都必须通过“审核”API 和 GPT-4 支持的审核系统，以查看是否与 OpenAI 的安全标准相冲突。OpenAI 还计划在未来推出一个微调 UI，其中包含一个仪表板，用于检查正在进行的微调工作负载的状态。</p><p>&nbsp;</p><p>OpenAI表示，在与其他技术（例如提示词工程、信息检索和函数调用）结合使用后，微调的潜力才能得到充分发挥。对函数调用和gpt-3.5-turbo-16k微调的支持也计划于今年秋季推出。</p><p>&nbsp;</p><p>对于OpenAI 开放 GPT-3.5 Turbo 微调，您有什么想法？欢迎在评论区发表您的观点！</p><p>&nbsp;</p><p>参考链接：</p><p>&nbsp;</p><p><a href=\"https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates\">https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates</a>\"</p><p><a href=\"https://news.ycombinator.com/item?id=37227139\">https://news.ycombinator.com/item?id=37227139</a>\"</p>",
    "publish_time": "2023-08-23 13:58:09",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]