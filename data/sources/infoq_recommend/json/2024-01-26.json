[
  {
    "title": "SBOMit发布：简单实用，改善软件物料清单完整性",
    "url": "https://www.infoq.cn/article/s5IxT6tkp0dZ81uJFLu4",
    "summary": "<p><a href=\"https://openssf.org/\">开源安全基金会（OpenSSF）</a>\"最近发布了<a href=\"https://openssf.org/blog/2023/12/13/introducing-sbomit-adding-verification-to-sboms/\">SBOMit</a>\"，这是一个设计用来通过<a href=\"https://in-toto.io/\">in-toto证明</a>\"增强<a href=\"https://www.infoq.com/podcasts/secure-supply-chains/\">软件物料清单（SBOM）</a>\"的工具。这一个成果来自OpenSSF安全工具工作组，它可以提升软件开发过程的透明度和安全性。</p><p>&nbsp;</p><p>软件物料清单（SBOM）是软件包组件的清单。SBOM有多种存储方法，还可以选择通过签名做额外的验证，但是确保整个软件开发过程的完整性仍然是一个挑战，因为无法能保证创建软件的所有过程都被恰当地执行。SBOMit旨在提供一种标准化的、SBOM格式无关的方法，通过附加验证信息来证明组件的有效性。</p><p>&nbsp;</p><p>In-toto是“完整性和透明度”的缩写。它是一个框架，旨在为确定软件供应链的完整性提供可验证和可复制的机制。In-toto证明是该框架的关键组成部分。本质上，In-toto证明是一种记录或陈述，为所采取的步骤提供证据，确保软件供应链的完整性。这些证明可以作为一种方法来验证软件开发和部署过程中的每个步骤是否已被安全执行且未被篡改。</p><p>&nbsp;</p><p>SBOMit会在软件构建中加入in-toto证明。生成的SBOMit文档会引用原始的SBOM文档，并包含关于软件开发中每个步骤的加密签名元数据，以及一个概述必要过程的策略。</p><p>&nbsp;</p><p>包含in-toto证明有助于降低产生意外错误的风险，并解决诸如人在开发过程中忽略关键步骤之类的问题。此外，它使得恶意活动更难隐蔽，从而增强了安全性。SBOMit不仅有助于提供更安全的环境，而且还使组织能够从入侵中安全地恢复，并及时识别和防止恶意活动。</p><p>&nbsp;</p><p>SBOMit项目由OpenSSF安全工具工作组托管，是行业协作的成果，旨在推进开源安全工具和最佳实践。将in-toto证明集成到SBOM中可以在软件组件的完整性和真实性方面为开发人员提供更多的保证。<a href=\"https://github.com/SBOMit/specification\">SBOMit规范</a>\"可从GitHub上获得，欢迎贡献。</p><p>&nbsp;</p><p>SBOMit的<a href=\"https://github.com/SBOMit/specification/wiki/SBOMit-Roadmap\">路线图</a>\"概述了其开发过程中的三个要点。</p><p>&nbsp;</p><p>强化工具和社区：</p><p>强调中立、支持和包容性。里程碑包括建立多元化社区、吸引利益相关者、推进下一阶段工作和实现可持续性。评估侧重于多样化领导力和重要工具提供商的参与。</p><p>&nbsp;</p><p>扩大终端用户采用：</p><p>旨在与监管机构合作，在各个部门广泛采用。里程碑包括合作伙伴关系、早期采用者协作、融合推广以及通过社区主导的增强实现可持续性。评估侧重于是通过跨部门的采用深度来衡量是否成功以及确保领先采用者的稳定。</p><p>&nbsp;</p><p>使利益相关者保持一致：</p><p>旨在通过明确的规范解决SBOMit不一致的问题。里程碑包括起草规范、通过协作进行细化、实现国际化标准以及过渡到一个自我延续模型。评估侧重于监控规范更新、提案流程的效率以及维护低一致性问题。</p><p>&nbsp;</p><p>开源安全基金会的首要目标是将SBOMit构建成为一个广泛采用的、定义明确的标准，并拥有一个能够自我延续的社区，确保软件供应链的兼容性和安全性。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2024/01/sbomit-attestations/\">https://www.infoq.com/news/2024/01/sbomit-attestations/</a>\"</p>",
    "publish_time": "2024-01-26 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "民生银行云原生业务的 eBPF 可观测性建设实践",
    "url": "https://www.infoq.cn/article/rdykA7AtBFKHoz4EHEsp",
    "summary": "<p></p><blockquote>本文整理自民生银行总行科技部网络管理中心高级工程师冯晶晶在「清华大学&amp;云杉网络·可观测性技术论坛」的演讲实录。</blockquote><p></p><p></p><p>民生银行通过 DeepFlow 构建了容器/云全路径网络观测能力、eBPF 零侵扰应用观测能力、应用函数监控能力、容器系统指标观测能力，并借助 WebAssembly 技术探索业务观测能力的建设。通过应用、系统、网络的全栈统一观测，民生银行的网络运维团队从网络监控时代迈向全栈主动观测时代，有效提升运维监控能力，提供更加全面、精准、有效、安全的监控服务能力，整体提升了故障定位和根因分析水平。本文讲述了民生银行的网络运维团队的工程师们在企业全面拥抱云原生的过程中，如何与云杉 DeepFlow 团队携手以 vTap 流量分发为起点，逐步改变传统网络运维思路，拥抱分布式流量采集方案，引入 eBPF 零侵扰应用追踪技术，并积极探索更多观测能力的发展历程。</p><p></p><h2>1、前序</h2><p></p><p></p><p>今天我们的主题是“以网络为中心的可观测性”，听到这个主题之后我特别激动和感慨，作为一名资深的网络运维工程师，多年来积累了大量网络相关的技术经验和心得体会，所以我现在站在台上，是以一种非常激动的心情向大家分享民生银行多年来从网络出发在云原生可观测性领域的建设实践。</p><p></p><p>在开始之前，我想对个人工作经历向大家做一个分享，刚才多次提到我是一名网络运维工程师，2006 年大学毕业以后就一直在银行做网络运维工作，在银行做网络运维其实是一个很艰难、压力很大的工作，为什么呢？因为银行对业务的连续性和稳定性要求极高，任何一次故障或业务中断就可能会直接带来用户的资金损失，无论是监管机构考核，还是部门内部要求，均是以安全生产为第一要务，在第一时间恢复安全生产是对我们运维工作的基本要求、底线要求，所以每一次故障处理的时候，运维人员都是背负极大的心理压力。</p><p></p><p>网络本质上就是用来为业务搭桥，当业务发生问题的时候，大家首先会怀疑网络有问题。当有业务中断时，大家的第一反应总是“网络哪里出问题了”、“现在业务中断了，抓紧查一下网络”、“是不是网络断了导致业务中断”；当有业务慢了的时候，大家总是说“查一下网络，是不是网络哪块抖动了，导致我们业务慢了”；当业务有异常的时候，大家总会说“我们这笔查询失败了，看看是不是网络哪块有问题”……所有的问题首先想到的都是网络问题，所以网络工程师总是背锅侠，不是在背锅中，就是在背锅的路上。</p><p></p><h2>2、民生银行可观测平台概况</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3a/3a2583f9a937e00da67177682bd62fd0.png\" /></p><p></p><p>我们怎么去解决故障边界不清晰这样的问题呢，流量分析观测平台给我们提供了一个很好的方案，民生银行在 7、8 年前开始建设流量分析观测平台，在传统环境中，通过交换机旁路镜像采集网络流量的方式，将流量输送到流量汇聚平台，过滤、标记后输出到流量分析观测平台，实现全网络的流量视图监控。</p><p>通过流量分析观测平台，极大的缩短了故障定位的时间，同时我们把网络流量数据通过数据服务的方式输出给各运维平台，比如交易监控平台、安全运维平台、态势感知平台、大数据平台，提供网络流量数据服务。</p><p></p><p>在传统网络环境下我们很好的解决了这些问题，但随着云原生时代的到来，新的问题产生了。所有人都在讲，我们的业务要敏态交付，所有的应用向微服务化转变，云原生时代来了以后，对流量分析工作造成了什么困扰呢？大量的业务流量都在计算节点内部直接交换，不会进入到物理交换机，那我们怎么去分析容器内部、虚机内部的业务交互情况呢，那么当然感谢我们的 DeepFlow 产品，通过我们与云杉的深度合作，利用第一代的 vTap 技术，在每一个计算节点内分布式的采集容器内部、虚机内部的东西向流量，从而弥补虚拟网络监控的观测盲区，同时通过 eBPF 的零侵扰采集能力，把应用数据采集并输出来，实现了我们真正的从设备级运维，转变到基于用户、基于业务交互、基于用户体验、基于安全合规的场景化运维服务及数据服务能力。</p><p></p><h2>3、建设历程</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1d/1d50ed1bcab8e9ad3af787971e7ba3b3.png\" /></p><p></p><p>民生银行的可观测性平台是通过我们的逐步摸索，分为四个阶段一点一点丰富能力而稳步建设起来。</p><p>在第一阶段，我们基本沿着传统的流量采集、流量分发的技术思路，采用 vTap 流量分发方案，通过部署采集器在计算节点上把容器内部、虚拟机内部的流量采集并分发出来，解决容器网络东西向流量的监控需求，这就是这个平台建设初期的目标。</p><p></p><p>在第一阶段建设完成后，我们发现通过采集器采集出来的容器内部东西向流量特别大，在流量突发的情况下，对流量汇聚平台产生很大的压力，于是我们进入了发展的第二个阶段，采用分布式采集的理念，在采集器中直接进行分布式的数据采集计算，再把采集计算后的结构化数据上送到数据分析节点，解决了整个流量分析系统分发带宽瓶颈的问题，同时也实现了整个云原生容器网络的全路径的流量追踪能力。</p><p></p><p>到了第三个阶段，我们积极采用 eBPF 技术，通过底层 Linux 内核提供的 eBPF 编程能力捕获应用进程调用相关的数据，实现应用调用链的零侵扰追踪，将我们从网络观测能力提升到了应用的观测能力。</p><p>现在我们进入新的探索期，在这个时期我们将大力拓展 eBPF 的潜力，并积极引入 Prometheus、Skywalking、听云等数据，构建包含应用、网络、系统的统一观测平台数据底座，并延伸到业务观测。</p><p></p><h3>初期——延续传统思路，vTap 打开云网黑盒</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3a/3a2583f9a937e00da67177682bd62fd0.png\" /></p><p></p><p>在传统的物理网络运维中，我们通过对交换机镜像操作以获取负载均衡、防火墙、核心/边界、接入/汇聚的南北向流量，并输送到统一流量汇聚平台，通过统一流量汇聚平台按需输出到网络监控，安全监控，交易监控，以及场景化数据服务。</p><p></p><p>到了云原生时代，我们在计算节点上部署 DeepFlow 采集器（实现 vTap 的能力），利用 Linux 的 cBPF 能力把容器内部，以及虚拟机内部的流量采集，通过 VxLAN 隧道把虚拟网络流量分发到统一流量汇聚平台，弥补虚拟化环境的流量监控空白。现在虚拟网络流量的分发能力已经完整覆盖了总行和分行的全部测试集群、生产集群。</p><p></p><h3>发展——拥抱新理念，分布式采集增强网络观测</h3><p></p><p></p><p>在传统物理网络环境中，交换机等位置的南北向流量其实并不是很大，相比较来说容器化以后所有计算节点内部的东西向流量规模则非常巨大，如果全部输送出来会对中间流量汇聚平台造成很大的压力，尤其是在流量突发时，会导致中间的流量采集层产生丢包，影响监控服务质量。</p><p><img src=\"https://static001.geekbang.org/infoq/4c/4cd5cf02aadceeea62d11aa5fe99accf.png\" /></p><p></p><p>因此我们通过分布式采集的方式增强整体的网络观测能力，也就是在已部署采集器的流量分发能力基础上，在采集器内部采集到所有 Pod 或虚拟机的流量后直接分布式计算生成流量的指标、流量的日志、流量的追踪信息，然后把这些数据上送到云原生流量分析节点，通过分析节点统一分析、展示，可以提供的运维能力包括整个云原生网络的流量全景分析、流量监控、云网络故障诊断分析，同时在这个基础之上，还可以识别容器、虚拟机的扩缩容、资源迁移等变更事件。</p><p></p><p>在这个阶段我们落地的技术关键点包括：</p><p></p><p>分布式采集：在采集端分布式采集流量性能指标、流量日志，从而解决流量分发方案 CPU 需求瓶颈、物理网络带宽瓶颈；全路径采集：在容器网络全路径实现数据采集，获取同一条 TCP 流从客户端 Pod 网卡到服务端网卡 4 个关键位置的性能数据；全路径关联：对流量数据标记位置信息，对任意 TCP 流端到端路径实现全路径关联分析。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c1/c1de0f9325f6a799a8592086cade5ed1.png\" /></p><p></p><p>分布式采集给我们带来了什么收益呢？首先让我们从无到有的打开了容器和云的虚拟化网络的全路径，其次将容器内部的交互情况进行可视化分析、展示，然后把容器网络的流量性能数据通过自服务的方式提供给其他部门。</p><p></p><h3>创新——落地新技术，eBPF 实现应用观测</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e4/e439efc8a199d69b1f213e5e4a170eb0.png\" /></p><p></p><p>实现了容器网络观测能力之后，我们又进入到了一个新的建设阶段，即创新阶段，在这个阶段我们的技术实现了从 cBPF 到 eBPF 的跳跃，我们的观测能力实现了从网络观测、系统观测向应用观测的跳跃。</p><p></p><p>我们通过 eBPF 技术，对应用程序零侵扰的方式从 Linux 内核捕获应用进程的函数调用，采集到应用进程的调用指标、调用日志、调用追踪数据，并上送到云原生可观测性分析节点，从而在原有的网络观测能力基础上，实现了包括应用全景分析、调用链追踪、调用回溯、进程 CPU 剖析等应用观测能力。</p><p>在这个阶段我们具体实现的能力包括：</p><p></p><p>eBPF 应用数据采集：通过 eBPF 技术，实现了对 Nginx、DNS、Redis 等无法插码位置的数据获取能力和观测能力；观测延伸至进程：对应用调用（HTTP、DNS、MySQL…）的观测能力从虚拟网卡延伸到客户端、服务端进程；零侵扰调用链追踪：无干扰、对入侵，对任意一次应用调用的全链路进行追踪。</p><p><img src=\"https://static001.geekbang.org/infoq/7b/7b401a99eb51ac908c88c27d2e99018c.png\" /></p><p></p><p>通过这一阶段的能力建设，我们的数据不仅可以满足网络监控的需求，还能够输出到应用运维部门，应用运维人员可以通过链路追踪、指标数据第一时间观测到整个应用程序的运行情况。通过 eBPF 的能力消除了 Nginx、DNS、MySQL、Redis 等应用服务的监控盲区，并且将追踪能力由网络扩展到应用进程，实现应用、网络的统一追踪、统一观测，大幅度提高了问题定位和处置效率。</p><p></p><p>下面做个简单的过程对比，直观感受通过 eBPF 实现的应用观测能力如何提升运维的效率。大家可能都会在运维过程中遇到这样的问题，比如某个系统报障说某个服务突然响应慢了，在传统物理网络环境中，网络运维会通过流量分析平台人工分析应用的响应时延指标，定位到问题以后通过人工下载 Pcap 并读包的方式，追溯整个业务的交互情况，确定慢在哪一个环节。有了 eBPF 技术实现的调用链追踪以后，我们可以通过火焰图形式的调用链追踪，第一步输入服务名称，第二步找到慢响应，第三步点击调用链追踪，就自动把慢响应的整个调用链过程包括网卡、进程在视图上展示，并清晰的看出到底是哪个位置、哪个服务占用的时间比较长。</p><p></p><p>以下是 4 个通过 eBPF 实现的应用调用链追踪处理的经典案例供参考。</p><p></p><p>案例 1：业务运营系统 Web 服务慢响应根因锁定</p><p><img src=\"https://static001.geekbang.org/infoq/c6/c650d5a4dd92051fbd1cfb7355d34dd3.png\" /></p><p></p><p>在某一个业务排障中我们发现 Web 服务的某次服务响应时延长达 3.04 秒，使用基于 eBPF 的零侵扰应用调用链追踪能力，可以一键调阅这次 3.04 秒的应用调用的完整链条，并快速、直观的在火焰图中通过不同 span 的长度确定慢响应的根因 span 是后端的 oms-app Pod。</p><p></p><p>案例 2：零售综合服务系统慢响应根因锁定</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e3/e3610ad811768f3eee1f012a60d1ff50.png\" /></p><p></p><p>在另外一个服务系统的排障中，我们发现部分响应时延接近 500ms，使用基于 eBPF 的零侵扰应用调用链追踪能力，一键调阅慢响应的完整调用链，从火焰图中可以快速发现，是由于后端的 acuiagwapp 服务响应慢导致。</p><p></p><p>相比较，使用传统的物理网络的定位模式，类似的问题需要多次抓包，然后逐跳分析，逐跳定位，逐个 IP 跟踪，才能定位到具体哪一个服务出现了问题，但是通过我们实现的调用链追踪能力，它可以直接可视化展示到具体的是哪一个服务、哪一个位置慢了。</p><p></p><p>案例 3：零售综合服务系统慢响应根因锁定</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e3/e34f809c72e12dcdcc9d25595c7774b9.png\" /></p><p></p><p>在案例 3 中是我们的决策分析平台客户端反馈出现了 HTTP 502 报错，但是客户端不知道到底是哪一个服务导致的一个 502 报错，通过我们的调用链追踪可以直接发现在服务端向 DNS Server 请求域名解析的时候，发生了 DNS 请求失败的异常，从而确定 DNS 服务的失败导致了此次 HTTP 服务的失败。</p><p></p><p>案例 4：支付通道整合系统容器 DNS 潜在隐患发现</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c7/c733f7c47fa7c00d7c47d85bdbfe23d8.png\" /></p><p></p><p>在我们对支付通道整合系统进行运维观测时，发现大量 DNS 异常，对异常 DNS 调用一键点开调用链追踪，发现 tpp-pay-* 的 Pod 高频查询外部域名，并且由于 kube-dns 的 DNS 查询机制导致需要多次遍历解析内部域名，潜在影响交易性能，从而发现了容器集群中 DNS 配置一些可以优化提升的技术点，指导系统运维对容器 DNS 配置进行优化。</p><p></p><p>通过这些案例会发现，借助于 eBPF 实现的应用观测能力，我们的网络运维不仅具备了对网络问题的分析诊断能力，还具备了对应用的追踪诊断能力，具备了对 DNS、Nginx、Redis 等公共服务的追踪诊断能力。</p><p></p><h3>探索——拓展新功能，构建数据底座</h3><p></p><p></p><p>现在，我们进入到了可观测性系统建设的第四个阶段，即探索阶段。在这个阶段我们要做一个整体的观测数据底座，把尽可能多的数据（比如系统的 Prometheus 数据、应用的数据）融入到数据底座中，实现一个覆盖网络、应用、系统的统一观测平台，消除整个数据鸿沟，然后提高整体运维的效率。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7d/7d70eb90133fdd54274db45126ccd6c3.png\" /></p><p></p><p>同时我们计划对 eBPF 能力进行增强，实现应用进程的 CPU Perf 数据采集能力，深入剖析包括应用进程内部的内核函数、库函数、业务函数在内的 CPU 消耗分布。通过这个能力，我们的开发人员可以快速定位到有哪些函数执行效率比较低，并针对性提升或者优化程序代码。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/82/82067efabefe7dcdcb210cf27f34b9db.png\" /></p><p></p><h2>4、总结</h2><p></p><p></p><h3>可观测性为我们带来了什么</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/e7/e749b51ec94e53baeaa40208ad0324d1.png\" /></p><p></p><p>可观测性到底给我们带来了什么收益呢？</p><p></p><p>在传统物理网络时代，我们通过网络流量分析平台，首先实现了全流量网络监控能力，其次实现了网络问题排障能力，最后为其他部门提供了交易流量数据服务、网络性能数据服务。到了云原生时代，我们通过 eBPF 的零侵扰可观测性，实现了主动的、全栈的观测能力。监控能力从网络的监控延伸到了系统监控、应用监控。数据服务能力除了面向网络人员的数据服务，增加了面向系统运维、应用运维，以及交易数据的输出。</p><p></p><p>我们从网络监控迈向了全栈、主动观测！</p><p></p><h3>未来展望</h3><p></p><p></p><p>下一步除了网络监控、系统监控、应用监控之外，我们还需要对业务进行监控，包括基于某笔交易流水号、某一类业务返回码、或者某个交易类型进行观测分析，所以我们计划通过 Wasm 技术对数据包和系统调用进行深度的解码分析，识别交易流水的情况，从而实现面向业务交易的全景监控和可观测性分析能力输出。</p><p></p><p>其次 eBPF 的强大能力为我们提供了很多新的运维观测能力，但它需要操作系统内核达到一定的版本，目前我们并不是所有的操作系统内核版本都支持 eBPF，由于 eBPF 给我们运维能力带来的巨大提升，在 2024 年我们会把所有的系统升级到新的内核版本，实现 eBPF 能力 100% 全覆盖。</p><p></p><p>另外在 2024 年的一个重要工作就是逐渐的融入 skywalking、听云的 APM 数据，然后做一个数据整合，在此基础上向开发部门提供更多的性能监控数据服务、业务监控数据服务的能力输出。</p>",
    "publish_time": "2024-01-26 09:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "机器人行业数据闭环实践：从对象存储到 JuiceFS",
    "url": "https://www.infoq.cn/article/VkhZyk80eoxyYmfOiawE",
    "summary": "<p>JuiceFS 社区聚集了来自各行各业的前沿科技用户。本次分享的案例来源于刻行，一家商用服务机器人领域科技企业。商用服务机器人指的是我们日常生活中常见的清洁机器人、送餐机器人、仓库机器人等。</p><p></p><p>刻行采用 JuiceFS 来弥补对象存储性能不足等问题。值得一提的是，前不久社区版 v1.1 中发布的“克隆”功能，已经成功被应用于刻行数据版本管理之中，有效提升仿真训练的效率。</p><p></p><p>在商用服务机器人领域，后期运维和开发工作至关重要。这包括监控机器人性能、执行定期维护、处理故障、进行软件更新及数据管理等。这些环节产生将产生大量数据，数据处理效率对于降低企业成本和提高工作效率起着决定性作用。刻行专注于后期的运维环节，为机器人企业提供全方位的闭环数据服务，涵盖从数据采集、存储到数据的可视化和仿真训练等多个功能。</p><p></p><p></p><h2>什么是机器人的数据闭环</h2><p></p><p></p><p>数据闭环是指收集终端用户的软件系统运行数据，以此来优化产品的功能和用户体验。</p><p></p><p>数据闭环如下图所示，首先，机器人系统会捕捉并上传现场问题相关的数据。这些数据，包括传感器数据以及感知、规划和控制方面的信息，都将被直接采集并用于后续处理。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/de/de64890f3f6bd44e445dbcb36bcd70e2\" /></p><p></p><p>服务机器人数据闭环</p><p></p><p>接下来，工程师将着手解决现场问题，首要任务是将前一步骤中采集的数据进行可视化处理。这需要直接访问存储在 JuiceFS 的数据。</p><p></p><p>解决问题的开发迭代阶段可能涉及机器人系统代码的逻辑优化，或者是算法模型的调整，此时需利用传感器数据进行标注和训练。无论解决方案的类型如何，最终都必须通过仿真测试进行验证，这就要求实现数据的版本化管理。</p><p></p><p></p><h2>JuiceFS 在不同场景中的实践</h2><p></p><p></p><p></p><h4>数据采集</h4><p></p><p></p><p>机器人采集的数据量极大，例如我们服务的一位客户，每日活跃设备数量达到数百台，每次数据采集的持续时间为一分钟，每分钟产生的数据量可达数百兆。因此，每天的数据增量大约是几百 GB。这些数据通常是非结构化的，因此将原始数据直接存储在对象存储中是极为合适的。</p><p></p><p>然而，对象存储也有局限性。首先，从设计上讲，它会根据键（key）自动进行分区。如果采用连续的前缀，很容易触及其限制的查询次数（QPS）。这一点在众所周知的 OSS 和 S3 等服务中也有所体现，具体限制可以参照它们的官方文档 [1]。</p><p></p><p>此外，若用户希望通过 FUSE 将对象存储用作文件系统，需要注意的是，类似 s3fs 这样的开源工具在性能和兼容性方面表现一般。具体的特性对比可参考 JuiceFS 的文档 [2]。</p><p></p><p>因此，我们正在寻找更优的存储方案，期望它既能提供对象存储的便利性，又能拥有更出色的性能表现。</p><p></p><p>我们最初接触的工具是开源版的 Alluxio。然而，我们最终没有选择它，主要原因是其对 S3 和 FUSE 协议的兼容性不足。以 S3 协议为例，它支持在读取数据时进行范围访问，类似于文件系统的高效操作。最初，Alluxio 并不支持此功能，我本人在 2020 年接触 Alluxio 时，曾提交过一个 PR 来解决这个问题，社区直到 2021 年才将其合并，我们最终决定放弃使用 Alluxio。此外，我们也尝试过自主研发类似的系统。</p><p></p><p>后来，我们选择使用 JuiceFS。JuiceFS 在设计上有效地规避了对象存储的一些限制。例如，原始数据的查询不依赖于对象存储提供的 API，而是通过自动分散文件到对象存储中来实现。此外，JuiceFS 的社区也非常活跃，开发者们对于问题的响应非常积极，这进一步促使我们采用了这个工具。</p><p></p><p>值得强调的是数据合规性问题，许多国内的机器人公司和制造业企业在出海时都会面临数据合规性挑战。由于国外的法律和法规通常要求数据必须在本地存储，因此多云架构的使用变得不可避免。JuiceFS 在这方面表现出色，因为它不仅兼容多种对象存储产品，而且非常适合在多云环境中作为存储层使用。因此，对于那些在开发业务时面临类似问题，需要采用多元化架构的企业来说，选择 JuiceFS 可以有效减少由不同存储产品带来的复杂度和挑战。</p><p></p><p></p><h4>数据可视化</h4><p></p><p></p><p>为了让大家理解 JuiceFS 在数据可视化中的重要性，先简单介绍一下机器人行业常见的原始数据存储格式。大多数系统会采用类似于 ROS 或 MCAP 这样的文件格式，这是在机器人系统实际运行过程中记录并存储数据的结构。</p><p></p><p>下图展示了这一存储结构。首先，会存储一些文件的元数据。接下来是不同类型传感器的 TOPIC，例如激光雷达和摄像头各自对应一个 TOPIC。TYPE 会定义每个 TOPIC 的数据结构，例如激光雷达数据结构通常被称为点云。TIME STAMP 记录了传感器采集数据的时间点。最后，存储的是真实采集到的数据。因此，我们的设备采集的数据实际上按时间顺序保存在系统中。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/1d/1d51a92f0d4198ba360ba98d92648e7b\" /></p><p></p><p>服务机器人数据格式</p><p></p><p>具体到数据可视化的实际应用场景，运维人员需要响应用户提出的工单。在获得用户授权后，他们会主动向设备发送数据采集请求。随后，所采集的数据需要被迅速访问并可视化处理。在此过程中，JuiceFS 提供的缓存特性起到了关键作用，数据在写入时同时建立缓存，方便在接下来的访问中直接命中缓存，这个设计极大地提高了数据使用的效率。这种高效率的数据处理对于快速解决工单、提升用户体验至关重要。</p><p></p><p>此外，JuiceFS 在处理数据方面也展现出显著优势。由于原始数据的时序特征，在数据可视化过程中，大量的时序连续数据需要被顺序读取。JuiceFS 提供了预读和预取功能（详见 JuiceFS 缓存文档 [3]），这使得计算资源得到了更有效的利用。具体来说，处理当前帧数据时，JuiceFS 会自动预读后续帧的数据。这样的机制不仅提高了数据处理的效率，还节省了计算资源，从而使整个数据处理流程更为高效和流畅。</p><p></p><p></p><h4>数据流水线</h4><p></p><p></p><p>如下图所示，我们首先通过 S3 网关将原始数据和待测试的软件上传至 JuiceFS 。随后，通过设定的统一事件和规则，这些过程可自动或手动触发。在我们的系统中，除了 S3 网关产生的事件外，还整合了内部系统的其他事件。所有的流水线（pipeline）操作均在我们的 Kubernetes 集群中执行。对于有兴趣深入了解如何在 Kubernets 集群中使用 JuiceFS 的用户，建议参考 JuiceFS 文档 [4]。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/0c/0c541852d2a960c54fdbb2d11e29e5ec\" /></p><p></p><p>服务机器人数据流水线</p><p></p><p></p><h4>数据版本</h4><p></p><p></p><p>如图所示，每当我们进行软件或模型的迭代仿真测试时，均需借助之前收集的传感器数据。这些数据用于对比规划和感知的结果，并通过特定指标进行评估。此过程的目的是判断哪个结果更为优秀，进而生成新的数据集。这一过程体现了业务层面的数据处理和分析。通过这种方式，我们能够精确地评估各个迭代步骤的效果，确保最终结果的优化和提升。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a5/a5707aa7f1e3e44d7e6b6eed3137e543\" /></p><p></p><p>刻行数据版本流程</p><p></p><p>在具体的执行层面，当我们运行 Python 时，系统首先会指定挂载特定版本的数据。例如，在图示中，系统挂载了最新的 HEAD 数据版本。接着，我们从执行的结果中筛选出更优的数据，以此形成一个新版本。在这个过程中，历史版本的管理依赖于 JuiceFS 提供的克隆功能 [5] 来实现。如果未来工程师需要对比或回退到某个历史版本，他们可以直接挂载相应的文件版本。</p><p></p><p>JuiceFS 克隆功能，它只会创建新的元数据而不复制实际的存储数据，这使得整个过程非常高效。这种方式不仅确保了数据版本的灵活管理，还大大减少了存储空间的需求，提高了操作效率。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/51/51972334e5221279d743c7b87d3d6e78\" /></p><p></p><p>刻行数据版本流程</p><p></p><p>一般，一个包含上百个文件、总大小为 10 GB 的数据集的克隆操作可以在一秒钟内完成。鉴于版本创建并非频繁进行的操作，这样的性能是完全可以接受的。</p><p></p><p>此外，JuiceFS 克隆功能在移动或复制数据集时也表现出极高的效率，其使用场景和数据版本管理类似。然而，需要注意的是，克隆功能也有一定的限制，正如文档中所介绍的，它不太适用于包含大量小文件、操作频繁的数据集。</p><p></p><p>最后，我要特别感谢 JuiceFS 团队为我们带来了这样一款卓越的产品，极大地促进了我们数据平台的发展和业务的成功。</p><p></p><p>引用链接</p><p></p><p>[1] 官方文档: <a href=\"https://help.aliyun.com/zh/oss/product-overview/limits\">https://help.aliyun.com/zh/oss/product-overview/limits</a>\"</p><p>[2] JuiceFS 的文档：</p><p><a href=\"https://juicefs.com/docs/zh/community/comparison/juicefs_vs_s3fs#%E5%8A%9F%E8%83%BD%E7%89%B9%E6%80%A7\">https://juicefs.com/docs/zh/community/comparison/juicefs_vs_s3fs#%E5%8A%9F%E8%83%BD%E7%89%B9%E6%80%A7</a>\"</p><p>[3]JuiceFS 缓存文档: <a href=\"https://juicefs.com/docs/zh/community/guide/cache%5B4%5D\">https://juicefs.com/docs/zh/community/guide/cache</a>\"</p><p>[4]JuiceFS 文档: <a href=\"https://juicefs.com/docs/zh/csi/introduction%5B5%5D\">https://juicefs.com/docs/zh/csi/introduction</a>\"</p><p>[5]克隆功能: <a href=\"https://juicefs.com/docs/zh/community/guide/clone\">https://juicefs.com/docs/zh/community/guide/clone</a>\"</p>",
    "publish_time": "2024-01-26 10:16:19",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "2024 InfoQ 极客传媒合作伙伴年会即将开幕：“Q”到你了！请回答：AIGC IN ALL！",
    "url": "https://www.infoq.cn/article/hVx7bmqULUUH1M46z8li",
    "summary": "<p>2023 年，令人瞩目且充满变革的年份。这一年，AI 爆火之下，世界正在经历着前所未有的改变。AI 技术的广泛应用，不仅带来了产业升级和经济增长，还为各行各业带来了更多的创新机会。与此同时，InfoQ 的许多合作伙伴都敏锐地捕捉到了这一机遇，将 AI 技术融入各自的业务领域，并不断探索与实践，积极寻求新的机遇。</p><p>&nbsp;</p><p>当然，“云计算”、“音视频”、“数据库”等其他技术领域也在 2023 年有了一个蓬勃的发展，在这些领域的许多 InfoQ 合作伙伴，都在市场逆流之下完成了全新的产业创新和商业创新。</p><p>&nbsp;</p><p>在这个过程中，InfoQ极客传媒作为极客邦科技旗下的全球性科技媒体品牌，始终聚焦于前沿技术产品，致力于为合作伙伴传递最新、最具价值的技术资讯与深度洞察。提供中立、由技术实践主导的技术资讯及技术会议，搭建连接中国技术高端社区与国际主流技术社区的桥梁。2023 年，我们也深感荣幸能得到许多合作伙伴的大力支持与帮助。</p><p>&nbsp;</p><p>感恩各位合作伙伴的一路同行，在 2024 新春佳节即将到来之际，InfoQ 极客传媒合作伙伴年会时隔三年，再次回归线下，于 1 月 31 日在前门 · blue note 举办。</p><p>&nbsp;</p><p>本次活动内容将围绕“有被 Q 到”这个主题精彩展开，Q 代表着 Quality（坚守品质）、Quick（敏锐、速度和专业能力）、Question（不断求知、探索、创新），InfoQ 全体同学“Cue ”各位合作伙伴相聚一堂，共同分享这一年的感悟与收获。</p><p>&nbsp;</p><p>Quality/坚守品质：机会总是留给有准备的人</p><p>&nbsp;</p><p>2023，大模型“神仙打架”。OpenAI 大模型 GPT-4 的性能在上半年遥遥领先，年末为吃瓜群众献上“宫斗大戏”；下半年，号称“史上最强”的谷歌 Gemini 模型登场，在部分基准测试中击败 GPT-4。与此同时，国内“百模大战”拉开序幕——从百度、阿里巴巴、华为、科大讯飞、腾讯、昆仑万维等国内多家企业，到清华、复旦等高校实验室，都陆续发布大模型产品。</p><p>&nbsp;</p><p>“大模型”激战正酣，“小模型”也在开辟新战场。法国初创公司 MistralAI 的模型 Mixtral 8x7B 性能比肩 GPT-3.5，且小到足以在一台电脑上运行；微软亮出小模型大招，发布 27 亿参数规模的小语言模型 Phi-2 在部分基准测试中超过谷歌的 Gemini Nano 2。此外，开源和闭源路线也在博弈，Meta 发布免费商业应用的开源 AI 模型 Llama 2，开源社区平台 Hugging Face 则提供大量高质量的开源模型与工具，将研发成果最大程度地惠及开源社区。</p><p>&nbsp;</p><p>但无论如何，大模型技术带动了国内人工智能产业链上下游企业的增长，生成式 AI 正在加速渗透各行各业。那，在这股浪潮之下，企业还能做些什么？我们应该做好哪些准备才能迎接 2024 年？InfoQ 极客传媒总经理汪丹将在年会现场进行 2024 年 InfoQ 极客传媒战略发布——InfoQ将在2024年发生的十大变化，邀请各位共同开启商业新篇章。</p><p>&nbsp;</p><p>Quick/敏锐、速度和专业能力：升级，并不断超越</p><p>&nbsp;</p><p>2023 年的热闹从 ChatGPT 炸场开始，AI 技术的突破直接拉动了自动驾驶、机器人和生成式 AI 的融资增长。在这个由 AI 撕开的新风口中，扶摇而上的大有人在。数据和算力作为训练大模型的底座也受到了越来越多的关注和讨论，升级是必然，如何更好地适配 AI 能力是目前行业需要探索的重要课题。与此同时，数字化转型依旧是企业的老课题，目前已经成为企业发展的重要驱动力，它逐渐改变了企业的运营模式，重塑了整个商业生态。</p><p>&nbsp;</p><p>总而言之，随着技术的不断进步，企业需要紧跟时代步伐，积极拥抱 AI 与数字化，以实现更高效、更智能的业务运营。在这个充满变革的时代，我们需要保持敏锐的洞察力。为此，InfoQ 双数研究院将在合作伙伴年会现场将为大家详细解读 2023 年中国软件技术洞察及 2024 年趋势预测，希望有助于各位更清晰地把握市场动态，发现新的商业机会。</p><p>&nbsp;</p><p>Question/不断求知、探索、创新：开启新变革</p><p>&nbsp;</p><p>AIGC 时代的到来，对技术品牌营销与市场运营提出了更高的要求。品牌需要不断刷新自身的认知边界，深入挖掘用户需求，并紧跟技术革新的步伐，将前沿科技融入产品和服务中。只有这样，才能构建出具有差异化和引领性的技术品牌形象。</p><p>&nbsp;</p><p>同时，市场运营在 AIGC 时代应更加注重数据驱动的决策。通过精准的数据分析，企业才能够洞察市场动态、用户偏好及竞争态势，从而制定更为有效的市场策略。这种以数据为核心的运营模式，不仅提升了决策的准确性和效率，还为企业带来了更大的竞争优势。</p><p>&nbsp;</p><p>InfoQ 极客传媒始终保持着敏锐的洞察力和创新精神，为合作伙伴提供更具前瞻性和实战性的思路与经验。在年会活动的开放麦环节中，我们邀请了三位行业内的重磅大咖进行闪电分享，在他们丰富的品牌与管理实战经验之上，讲述他们在各自领域探索创新的故事，为大家深入剖析如何在 AIGC 浪潮下面对激烈的市场竞争。</p><p>&nbsp;</p><p>为了感谢合作伙伴们的长期支持与贡献，年会现场我们还特别设立了奖项表彰环节，为杰出的合作伙伴颁发荣誉奖项，敬请期待这场盛大典礼，共同见证荣耀时刻！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/77/77e0b561847c37bce54cada362b05044.png\" /></p><p></p><p>AI 打破了 2023 年的平静，科技领域的进步如一轮即将跃出地平线的太阳，我们能感受到徐徐升起的光亮和温暖。</p><p>&nbsp;</p><p>这场活动不仅是对一直以来支持我们的合作伙伴的真诚回馈，更希望各位能够通过这场活动结交更多志同道合的朋友，获取更多有价值的商业信息。1 月 31 日，就让我们共同探讨行业发展趋势，分享彼此的经验与见解，寻找未来机遇。大家现场见！</p>",
    "publish_time": "2024-01-26 10:17:41",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "大模型落地金融行业，如何闯关最后一公里？",
    "url": "https://www.infoq.cn/article/kQOjfc1iCvObWXEleaGP",
    "summary": "<p>AI 大模型引领千行百业加速升级。在金融行业，大模型正以其出色的数据处理和分析能力引领着一场技术变革。那么，目前大模型在金融行业的应用现状如何？大模型在金融行业的落地应用面临哪些问题和挑战？如何打通大模型在金融业落地的最后一公里？近日，InfoQ《极客有约》邀请到了腾讯金融云技术总监全成，InfoQ 社区编辑，美国 Cognizant 公司架构师（solution architect）马可薇，共话《大模型落地金融行业，如何闯关最后一公里？》。</p><p>&nbsp;</p><p>以下为访谈实录，完整视频参看：<a href=\"https://www.infoq.cn/video/wV7sNBNqeO27V3p5E2Gu\">https://www.infoq.cn/video/wV7sNBNqeO27V3p5E2Gu</a>\"</p><p>&nbsp;</p><p>马可薇：欢迎大家来到 InfoQ 极客有约，我是今天的特邀主持人 InfoQ 社区编辑、美国 Cognizant 公司架构师马可薇。本期直播，我们邀请到了腾讯金融云技术总监全成来给我们做分享。我们今天直播的主题是《大模型落地金融行业，如何闯关最后一公里？》。首先请全成与网友们打个招呼。</p><p>&nbsp;</p><p>全成：我一直在金融行业工作，负责过金融大数据、数据挖掘、机器学习、深度学习等方面工作，在算法、研发方面也有一些经验，为了探知市场的信息和动向也做过一段时间的产品和售前架构师相关的工作。目前，我在腾讯金融云项目中负责远程音视频应用，以及大模型在金融行业应用的研发工作。</p><p></p><h2>大模型如何赋能金融行业？</h2><p></p><p>&nbsp;</p><p>马可薇：去年年底 ChatGPT 的爆火成功掀起了大模型热潮，对于这波浪潮，您观察到哪些有趣的趋势？</p><p>&nbsp;</p><p>全成：从大模型至今的发展来看，我从体感上来说没有发现很多有趣的趋势，更多的是一些担忧。大模型本身具有一定的技术门槛，其本身的计算和逻辑推理过程又是黑盒，目前的大模型应用过程发展趋势更是在逐渐走向闭塞。Transformer、Hugging Face 库中的开源模型数量多、版本迭代速度快，但超大型模型却更多地走向闭源。这类黑科技一旦极端地走向闭塞、黑盒的方向，将会给大模型带来泡沫，也给了许多意见领袖左右舆论的可能性。我还是更多地希望开源和闭源的体系能同时存在，这样也更加地合理。</p><p>&nbsp;</p><p>同时我们也能看到，目前除了大模型的训练和研发平台外，许多创业公司也在进行一些基于大模型的智能应用，比如辅助办公或 PDF 和论文类的解读等等。</p><p>&nbsp;</p><p>此外，基于大模型的智能应用研发也会需要研发的平台，类似移动 APP 研发平台的中间 PaaS 层组件，这类平台的研发和开源数量也在增长，像是 LangChain 这类在早期较为典型的平台也会逐渐出现。在这一点上，科技公司或是金融公司这类对信息化同步需求较高的行业，也可以关注一下这类基于大模型的研发平台在未来的发展趋势。</p><p>&nbsp;</p><p>马可薇：在金融行业，大模型的价值主要体现在哪些层面？</p><p>&nbsp;</p><p>全成：说起价值点，如果一个技术能够解决行业中存在的一个问题，那么其价值自然能体现出来。在金融行业里，我们不提金融服务的个性化推荐、风控量化水平精准度的提高、客户体验的提高等等这些较为空泛的话题，举一个最简单的例子，智能客服。大家在日常给金融机构或客服打电话时往往能感觉到客服机器人的难以沟通。这个问题在各种领域中其实都存在，可以说金融机构并没有通过智能化的技术将客户和咨询的诉求解决掉，而是恰恰相反，通过这些技术将客户的咨询和诉求全部挡在了门外。</p><p>&nbsp;</p><p>从这方面来说，客户的咨询和互动方面肯定会有很大的提升，这也是我们能切身感受到的。此外，大家常常在很多金融 APP 上发现光是产品的购买，其中的图片和文档都会让人眼花缭乱，客户最为关注的核心信息往往很难获取到，人们与金融服务的互动或信息获取效率是过于底下的。</p><p>&nbsp;</p><p>在这些问题上，大模型对金融行业还是会有很大帮助的。金融行业中的各大渠道，包括手机银行、网银、ATM、线下网点，乃至微信的小程序中，我们与客户能产生的互动只有点击和浏览。在 ChatGPT 这些大模型出现后，我们可以看到它们在语言生成和组织回答的能力上是非常强大的，可以让金融行业中最为直观的价值点，也就是与客户的互动率会有大幅的提升。</p><p>&nbsp;</p><p>大模型在金融行业内部的工作效率提升方面，也有很大的助力。我个人在工作中也会坚持写代码，常常会用到 GitHub Copilot 或腾讯的 AI 代码助手之类，我感觉它们可以明显地为我带来代码编写的效率提升。此外，我在之前做架构师相关工作时也会遇到一类问题。金融机构中对于一些数据的统计，比如风险参股在 20%-30% 的客户情况，这些数据通常是无法在 BI 平台上获取到的。数据分析或运维人员必须要找到科技公司提交数据需求说明书，科技部还要经过排期，最终要到两个星期后才能拿到数据结果。大模型出现后，在 AI 数据和数据查询等方面也会有大幅度的提升。</p><p>&nbsp;</p><p>马可薇：当前金融机构对于大模型的态度是怎样的？</p><p>&nbsp;</p><p>全成：目前金融机构对大模型的态度普遍来说还是持有期待的。金融和电信可以说是数字化和信息化程度最高的两大行业了，他们对创新性的新科技接受程度都很高，也很愿意尝试。但大语言模型的训练和推理投入都很大，金融行业更多是期待科技公司能开发出一些可以带来更多业务价值提升，同时也能解决客观问题的应用。大型银行则更有技术实力和资本实力进行更多创新性的先行探索，我们也已经在一家大型银行的积极配合下，双方联合完成代码助手的落地等任务。</p><p>&nbsp;</p><p>马可薇：根据您的观察，目前行业对大模型的认知是否存在一些误区？</p><p>&nbsp;</p><p>全成：误区说不上，不过我个人比较喜欢 Geoffrey Moore 在《跨越鸿沟》中提到的营销模型：任何一个新技术都会有早期的受众，以及中期的保守主义和实用主义人群。我们更多是希望能和金融机构一同成为具备创新性和探索性的早期使用者，以此为后来的实用主义者给出更多的证明。当然，有些保守主义的同行会提出一些较为极端的案例，比如说互联网出现后会有手机银行这类能够直接接触核心交易方面的应用出现，那么大模型出现之后是否也能带来变革型的应用？对此我觉得要实现这些还是需要一段时间的，互联网刚出现时也是经历了网页、网站、网上银行、手机银行及线上支付的发展。总体来说，目前行业在误区层面倒没有很多，但我还是更希望金融和电信作为数字化领先的行业，能够在大模型的应用和创新的探索上有更多的积极合作趋势。</p><p></p><h2>大模型在金融行业的落地规则及部署方式</h2><p></p><p>&nbsp;</p><p>马可薇：大模型在金融行业的产业落地需要遵循哪些规则？这和其他行业有哪些异同？</p><p>&nbsp;</p><p>全成：规则的制订是为了防止打破规则后带来的损失，或者是对部分人群带来的风险。大模型作为一项新技术，就目前可见一些舆论报道等信息渠道来看，都在谈论数据隐私安全、伦理、歧视偏见，但对于金融这项非常审慎的服务来说，可解释性和可追溯性是金融机构一定要关注的规则，当然，模型输出一定要符合法律法规这项最基本的要求更不用说了。金融机构要想应用大模型，就会对科技公司或产品研发公司提出更多的要求，大模型的推理过程以及推理后的每个环节都要有相应的日志。虽然说大模型的很多输出都没有缘由，但模型运算过程中还是会有一些能够佐证的信息和日志。</p><p>&nbsp;</p><p>大模型毕竟是新技术，必然会存在很多不可预料性。但我们也不能光是嘴上说说，还是要将产品先做出来，然后在使用的过程中沉淀一些具备可操作性的规则。举例来说，腾讯安全在某个仅利用视觉进行智能驾驶的品牌中，通过安全团队的实验，发现地面上存在的某些特殊图片会导致汽车进行一些预料外的行为。这种情况如果发生在实际的高速公路上将会十分危险。因此，我们应该是进行更多的实验和探索，并在探索过程中将各种规则沉淀下来，为行业做出更多的贡献。但目前为止还没有说有人尝试过利用个人隐私数据进行指令学习的大模型 fine tune 之后，模型会输出怎样的结论并影响到客户这类的实验。</p><p>&nbsp;</p><p>马可薇：先前 ChatGPT 出现过 prompt 泄露模型训练数据的事故，那么腾讯云有针对这类风险做过什么防范措施吗？</p><p>&nbsp;</p><p>全成：这是肯定的，我们甚至还有一个专门的团队研究如何拦截大模型中高风险的输出。腾讯的混元大模型在训练的时候也会充分考虑到这一点，在训练的数据集中把法律合规、可解释性、隐私安全都考虑到。同时，因为大模型本身的计算过程非常复杂，其输出肯定会存在意外性，目前英伟达也有一些开源组件可以对模型的最终输出进行拦截。腾讯的安全实验室也在进行这方面的安全探索和研发。</p><p>&nbsp;</p><p>马可薇：要如何确保大语言模型的应用是符合法规要求的呢？</p><p>&nbsp;</p><p>全成：首先是训练数据集，我们要杜绝违法的训练数据集，因为如果存在违法的训练数据，模型必然会学习到。目前的大语言模型的训练数据通常是互联网上通用的文章、书籍、新闻报道之类信息，但金融行业还有行业内的政策文档文案以及一些领域知识，这些都需要添加到大语言模型的训练之中。这样才能更多地让模型学习到金融行业的规则和法规。</p><p>&nbsp;</p><p>其次是针对输出的拦截，在这一过程中我们可以对参数进行一些调整，实现对敏感词汇进行过滤，减少其被选取的概率，并尽可能避免人名的出现（除了百科类型中的名人）。</p><p>&nbsp;</p><p>最后一道防线则是安全机制，通过一套筛选过滤的机制从而保障大模型的输出尽可能地安全合规。虽然这样下来还是会存在漏网之鱼，但目前还没有全面观测到这种情况的出现，这方面我们还是有很长的一段路要走。</p><p>&nbsp;</p><p>马可薇：目前大模型在金融行业的应用现状如何？主要有哪些应用场景？存在哪些挑战？</p><p>&nbsp;</p><p>全成：虽然大模型面世仅仅只有一年的时间，但它的 Transformer 技术架构是从2017年底逐渐发展到现在的，真正惊艳众人的还是一千五百多亿参数的超大级别模型 ChatGPT。目前大模型虽然还没有得到大规模的应用落地，但在探索和创新性上的尝试还是有很多的。金融机构目前还是希望能和更多的科技公司合作实现大模型的应用落地。今年四五月份我们就已经能看到 ChatGPT 与 GPO 进行金融投研的 fine tune 及相应的合作，在券商或投资银行的层面上，我们能看到很多投研和投顾（投资顾问）相关的探索性合作；商业银行希望能提高与客户的互动性，智能客服和线上营销方面合作较多。至于商业银行在个人信用和企业内部评级，因为信用风控领域需要模型具备极强的可解释性，风控和风险量化方面，比如违约概率、违约损失率或风险计量等方面的应用目前还没有非常直观的应用场景。目前来说，大模型基于互联网行为数据获取到的信用评分或是代码助手之类的应用相对而言还是比较多的，但大模型目前还没有直接进入交易或模型直接决策的层面。</p><p>&nbsp;</p><p>至于挑战，大模型技术门槛不低，因此在技术上的挑战肯定存在，但更多的挑战还是在于投入产出的平衡方面。以 16B（160亿参数）的小型大语言模型来说，光是推理部分就需要一个 32G 显卡的服务器，英伟达 V100 的 GPU 一个月是四千块钱，三节点的负载均衡一个月下来就是一万二。两千亿参数的超大型模型一年在 GPU 上投入就是 144 万，在算上应用中的数据库和其他的基础设施，一年中光是推理的投入就要有三百万，因此我们还是要提高业务价值，做好投入产出的平衡。</p><p>&nbsp;</p><p>马可薇：当前金融机构部署大模型主要有哪些方式？不同方式的关键点是什么？</p><p>&nbsp;</p><p>全成：大模型的部署方式有很多，基础的云平台、本地，以及混合型部署，谷歌前阵子推出的 Gemini 甚至有可以在边缘计算部署的超小型模型，其他还有 OpenAI 通过 API 提供的模型即服务类型。</p><p>&nbsp;</p><p>具体的部署方式选择还是和大模型的应用架构息息相关。假如说是对语言能力和语言组织能力要求极高的需求场景，需要一千五百亿甚至是两千亿级别以上的模型，那么专为这种应用或云环境搭建机房的成本还是很高的。这种场景下，可以在尽可能保障安全的情况下与科技公司合作，通过 API 调用模型即服务（MaaS）共创一个安全的云环境。目前没有任何一个模型能针对任何细分场景下的任何任务都有百分百的解决率，金融机构如果希望构建大模型的应用，则必然要针对不同的细分场景，由推理和训练微调成本较低的小型模型解决细分场景，中间层 Agent 代理判断意图（究竟是调用大模型、专业模型还是搜索工具），并利用大模型的语言和推理能力将结果整理，从而交给用户一个满意的答复。</p><p>&nbsp;</p><p>马可薇：金融行业最关注的还是大模型带来的风险，具体来说，可能会存在哪些风险？如何规避这些风险？</p><p>&nbsp;</p><p>全成：这个问题拿去问 ChatGPT 能得到十几条的回答，非常全面且完善。金融行业在这十几项的风险中会更多地关注信息数据安全，隐私数据被滥用这方面。在信息安全方面，除了传统的信息加密、访问控制和脱敏等手段，我们还要有研究团队，利用个人隐私数据或行为数据做模型的微调和训练，通过模型输出反馈结果的实验证明，发现具体的潜在风险，才能提出更多的反制措施。</p><p>&nbsp;</p><p>其次，金融机构也会非常关注对客的公众性。既要确保个性化的利率定价和产品推荐，同时也要保障在某些领域中的对客公正性。在训练数据集中，即使是要用隐私或金融数据，我们也不能过度依赖银行或个人券商的内部数据，而是要考虑到公共的、更为全面的数据。内部的数据必然不是正态分布的，而有些地域或地方性金融机构的客户可能都是局限在某一区域的。</p><p>&nbsp;</p><p>第三，是模型输出的可解释性和可追溯性。在应用大模型时，金融机构要尽可能避免通过大模型直接从端到端解决非常复杂的任务。大模型在解决复杂的逻辑推理任务时还存在能力上的短板，在解决这类问题时大模型的推理过程也是完全的黑盒。因此，我们要尽可能地将复杂任务拆分，并通过这一过程中对模型的拆解，提高模型结果的可追溯性和可解释性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f5/f5f30a5d7a4d51b69dec2fac68c0f8ed.png\" /></p><p></p><p>马可薇：科技公司要如何为金融机构提供定制化、差异化的大语言模型服务？</p><p>&nbsp;</p><p>全成：首先要看用户提出的需求，其次是大模型的训练，我们目前也在用很多开源的模型进行微调，这些开源模型有很多，Chinese-Llama2、千问，以及腾讯内部通过中文语料训练出的模型等等。开源模型肯定要用中文语料训练，我们会在 Hugging Face 上看有哪些评测较好的模型，再用业内比较认可的 LoRA 技术做模型的训练和微调。在金融机构内部训练数据不足的情况下，就得用更大型的生成式模型生成训练用数据构成指令数据集，再通过 LoRA 进行微调。因为可训练的参数基本可以控制在 1% 以内，所占用的显存不会很高。</p><p></p><h2>打通大模型在金融业落地的最后一公里</h2><p></p><p>&nbsp;</p><p>马可薇：大模型目前的应用和边界在哪里？</p><p>&nbsp;</p><p>全成：将一个不稳定的新技术直接应用到核心业务上会带来较大的风险，目前大模型的应用边界还是更多地在外围一些客服咨询、内部工作效率提升、文档解读等相关的应用，而不是直接应用到精确的风险量化值计算之类。</p><p>&nbsp;</p><p>马可薇：打通大模型在金融业落地的最后一公里并非易事，有哪些可行性路径？金融机构如何才能充分发挥大模型的潜力？</p><p>&nbsp;</p><p>全成：可行性路径很多，官方一些的回答是“合作通赢”；和科技公司一同合作，找到一些较为边缘性、与核心交易不算较为相关，且能相对地带来更多的工作效率的高业务价值场景，小步快跑地进行尝试，当然也还要构建一个专业的团队。</p><p>&nbsp;</p><p>不同的技术路线也有不同的落地方式。一种路径是利用金融领域数据，点对点微调大模型，这种方式成本较高，很多科技部的领导很难有魄力投入如此大的资源。另一种路线是通过 prompt 提示工程将许多大模型一同利用起来，很多具体场景中的 prompt 设计有很巧妙的设计，好的提示工程会让模型回复的精准度和准确度有大幅度的提升。</p><p>&nbsp;</p><p>这样通过知识库和大模型中 prompt 能力相结合的搭建形式，是金融机构目前来看可行性较高的路线。前面提到的复杂任务拆分，对数据外泄零容忍的细分任务用小型模型完成，利用金融机构内部的数据进行微调，再挂载到大模型的应用内，从而实现更高的落地安全性和保障性，可行性也较高，成本也更好把控。</p><p>&nbsp;</p><p>马可薇：在人才储备方面，金融机构需要哪些技能和经验来支持金融大模型的落地？</p><p>&nbsp;</p><p>全成：大模型虽然也有技术门槛，但远没有传闻中的神乎其神，实际的微调和训练工作都会需要两方面的人才。一是数据工程类人才，基于业务需求对数据集进行设计、清洗、验证，大规模地构建数据集。这一过程不仅需要具备业务知识，还需要耗费极大的人力精力。我们都知道 OpenAI 或者是谷歌等公司的架构永远是 Transformer、训练代码在 GitHub 上也有很多（并行训练、流水线训练、数据定性等等），唯独没有数据集中各种数据来源的占比，或者训练结束后指令学习中具体的任务构建。</p><p>&nbsp;</p><p>在模型训练方面，除非需要从预训练开始，将 Transformer 的架构模型重新设计或修修改改，否则只做微调的话，用 RoLA 微调开源模型就可以了。国内也有 LLaMA-Factory 的 H5 工具，很简单就能进行训练了。模型训练方面的人才首先要理解 Transformer 或图像生成方面 Diffusion 的理论基础和架构原理，会写 Python 并能利用 Hugging Face 微调应该就是足够了。</p><p>&nbsp;</p><p>马可薇：金融领域大模型的技术路线和其他垂直领域的大模型有什么不同？</p><p>&nbsp;</p><p>全成：在我看来其实差不太多，金融机构在技术路线的落地方面会更加关注私有化、本地化的部署，对产品研发和创业公司来说要更多地考虑到这一点。模型不是越大越好，越大的模型对 B 端客户的成本也就越大，模型的设计和微调以及更多的研发工作时都要考虑到这点。</p><p>&nbsp;</p><p>马可薇：对于那些还未或正在落地大模型的金融机构，您会给他们提供哪些建议？企业具体需要做好哪些准备？</p><p>&nbsp;</p><p>全成：建议谈不上，但还是希望更多的金融机构能够让员工先用起来大模型。以代码助手为例，任何技术人员肯定都觉得自己的代码水平很高，何必让 AI 给自己搞乱，但只有真正地拥抱新技术，才会在使用的时候发现它真的能带来很多便捷和效率上的提升。看似大模型没有解决什么问题，但对员工整体对大模型技术上的理解是有很大帮助的。此外，无论是技术人员还是业务人员，在应用了大模型的技术后能够天马行空地提需求才是好的循环，而不是直接否认大模型。金融机构的中高层也需要对大模型的应用有一些一两年内的规划和整体目标，这样才会更还是一些，五年计划倒是指不上，毕竟技术发展太快了。</p><p>&nbsp;</p><p>马可薇：展望未来，大模型落地金融行业还会带来哪些产业价值？未来可能会发生哪些变革？</p><p>&nbsp;</p><p>全成：金融领域在未来会积极地拥抱新技术，在可见的未来也必然会有更多创新性的应用出现，大模型会帮助金融行业实现客户和金融服务之间的互动和交付，而未来金融行业的应用也可能会出现更多的对话式、交互式应用。从变革的层面来讲，未来也必然会带来更多变革型、创新性的应用。</p><p></p><h3>嘉宾介绍</h3><p></p><p>&nbsp;</p><p>特邀主持：</p><p>&nbsp;</p><p>马可薇，InfoQ社区编辑，美国Cognizant公司架构师（solution architect），主要负责保险领域的业务。</p><p>&nbsp;</p><p>嘉宾：</p><p>&nbsp;</p><p>全成，腾讯金融云技术总监。之前曾在某金融集团公司参与关系网络风控识别项目，和说话人声纹识别比对项目；在券商互联网企业参与过大数据量化投资项目。目前在腾讯主要参与TX2SQL大模型智能应用项目，负责专业知识及推理大模型微调，构建端到端TX2SQL问答系统。</p>",
    "publish_time": "2024-01-26 10:42:37",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]