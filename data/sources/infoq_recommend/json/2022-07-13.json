[
  {
    "title": "规避代码被“投毒”，开源软件供应链安全面面观",
    "url": "https://www.infoq.cn/article/6jm3rPVwybGMbJl358Fx",
    "summary": "<p>开源软件供应链当前面临的主要是两大风险：一是安全风险，一是许可证、版权、专利和出口管制等方面的法律合规风险。当然针对使用开源软件的企业来说，还有供应链风险及运维风险。这些风险如何更好地规避？开源协议、开源组织都做了哪些事情？企业如何自查内部开源项目的安全性？本期<a href=\"https://www.infoq.cn/video/EgmPvTu4Ik9xeFJ8qToL\">《极客有约》</a>\"，我们邀请到了 Zilliz 合伙人，首席布道师顾钧，上海安势信息技术有限公司资深解决方案架构师朱贤曼共同解答上述问题。</p><p></p><p></p><p></p><p>&nbsp;</p><p>InfoQ：开源软件供应链到底应该如何理解？</p><p>&nbsp;</p><p>顾钧：我觉得开源软件供应链和传统制造业类似，只是开源软件供应链会有很多新的挑战。传统制造业供应链的供应商承担的责任相对清晰，因为合作方之间会在成熟的法律条框下签订商业合同。但是，用户在使用开源软件时可能没有特别意识到已经对其形成依赖，该项目已经成为上游。传统意义上，可以将该开源项目理解为是供应商，但其又不承担供应商的职责。这个新的挑战就是，上下游之间没有强制的商务合作，没有法律条框可以限制使用过程，想要确保安全会有很多不确定的地方。</p><p>&nbsp;</p><p>朱贤曼：开源软件供应链面临的最大挑战就是企业自己都不知道用了哪些开源软件，大一点的公司可能开始关注到开源合规治理的内容，但是很多小公司可能还没有这个意识。</p><p>&nbsp;</p><p>InfoQ：国内当前在软件供应链安全方面的意识形态大概是什么样的？</p><p>&nbsp;</p><p>顾钧：站在使用者的角度，Zilliz开发服务的新一代向量数据库Milvus ，希望提供给最终用户云服务，所以我们既是一个开源软件的供应商，但同时我们Milvus也引用了大量第三方开源组件，是供应链上的消费者。项目初期引用上游其他开源组件的时候，我们会有一些比较简单的规则，比如说考虑许可证的兼容性问题，加入到Linux基金会时也会有一些开源项目合规性检查，回溯其中引入的开源项目许可证的合规性。</p><p>&nbsp;</p><p>站在用户的角度，明显分为两类：一类是动手能力较强的互联网类型的技术公司或者创业公司，可能没有那么严格的要求，不强制开源项目的开发团队提供一个质量保证的书面化内容，也不会尝试商务合同；另一类社区当中的用户，比如金融机构等，非常关心这个问题，尤其是想要投入到生产上的时候。我觉得国内目前有严格内部规范的企业，对开源软件供应链还是比较在意的，希望引入的开源软件有服务商提供质量保证。</p><p>&nbsp;</p><p>朱贤曼：国内企业做这件事的动力来源大部分都是外部压力，比如欧盟的运营商会在合同里面要求提供开源软件清单，写清楚项目中使用了哪些开源软件，且保证后续不会造成法律风险。国内的部分厂商是因为下游客户的要求，在合同里面签订相关条款，保证代码合规性，整个供应链环环相扣，这些是外部的压力。</p><p>&nbsp;</p><p>此外，国家层面也在慢慢重视开源合规，国内有很多安全相关的法律法规，尤其是金融行业。</p><p>&nbsp;</p><p>InfoQ：如果企业的业务在规划或正在做出海，会着重考虑这一块吗？</p><p>&nbsp;</p><p>顾钧：现在的厂商一般偏向于提供SaaS型云服务，像我们这样的创业团队是从基础软件开始做云服务，早期是在做基础软件，后来慢慢做云服务，再去做合规。海外则有很多上来就做SaaS相关云服务的公司，最重要的事情就是先把合规全部完成，这是很不一样的地方。</p><p>&nbsp;</p><p>朱贤曼：开源软件在出口管制层面的合规性要求，在美国是有法条规定的，如果不特别注意，可能会无意识当中触犯美国的出口管制条款。在中美贸易合规大背景下，企业可能就得额外关注这种合规性。所以，开源软件治理的驱动力是合规和安全，以及环境影响，比如国内之前发生的GPL诉讼，这会让很多公司逐渐关注开源合规并识别风险。</p><p>&nbsp;</p><p>顾钧：GPL开源协议和法律条款容易引人误会的地方是传统上，大家觉得要白纸黑字签署过才有法律约束，但开源协议是使用时默认代表接受整个协议，如果不接受就不能使用。</p><p>&nbsp;</p><p>InfoQ：随着国内使用开源的人越来越多，大家对开源协议的理解程度大概是什么样子的？</p><p>&nbsp;</p><p>顾钧：开源协议的数量还是挺多的，GitHub上也有一些专门的许可证选择器，帮助用户选择适合自己的许可证，基本上大家都会集中选择几大主流协议。</p><p>&nbsp;</p><p>首先是Apache 2.0，因为国内很多项目都加入了Apache软件基金会，很多新项目也是希望遵循这种方式进行治理，很多都默认选择了Apache 2.0许可证，所以对该许可证的解读会比较充分。</p><p>&nbsp;</p><p>其次是MIT许可，因为MIT许可相对宽松，所以很多个人项目或者程序库型的项目，直接就选择了该许可。因为大家都比较容易理解。当然这之中可能会潜藏一些专利问题。整体上MIT因为最简单，大家都能理解，用的人也比较多。</p><p>&nbsp;</p><p>最后是GPL，名声大，受到的攻击就比较多，很多人的错误解读，造成了GPL的评价特别两极分化。GPL协议的开源项目近期国内不是特别多，大家一般不会选择GPL，但是会有一些项目选择AGPL。</p><p>&nbsp;</p><p>朱贤曼：近几年，国内对许可证的理解程度要好很多，中大型企业都会关注，很多公司已经成立了专门的开源治理办公室，但实际业务当中会发现仍有很多问题需要解决。根据我目前的了解，国内对GPL还是能不用尽量不用，毕竟需要承担更多的合规业务。对商业应用比较友好的是Apache，宽松、不需要开放源代码、条款也相对严谨，如果商业公司使用，法务风险相对较低。AGPL、SSPL这种一般很多公司直接禁用。一般的分发概念，需要实际发布代码，以前的分发是寄光盘，现在可能是把源代码包上传到应用商店，但AGPL的分发可能通过远程访问云服务就算，这个范围就大了，所以很多公司不会选择这两种协议。如果公司内部有类似开源办公室这种角色，制订规则的时候一般会将这两者禁用。企业在对外发布开源项目时，如果希望商业化之后保留一个商业版本、一个社区版本，可能会选择类似GPL的许可，一方面可以收集到用户意见，也就是开源的反馈意见，用于改进商业版，同时也不希望被直接白嫖。</p><p>&nbsp;</p><p>InfoQ：国内在供应链管理方面有没有比较好的软件工具可以推荐的？</p><p>&nbsp;</p><p>朱贤曼：供应链是一个系统工程，肯定不是单一工具可以解决的，需要一整套的工具。因为这个链条很长，很多都需要DevOps这一套工具链。但如果想知道开源治理部分的潜在风险，最基本的是要知道到底使用了哪些开源软件，由于现在软件使用的开源软件数量众多，调用关系错综复杂，且层层依赖，靠人工去梳理基本不太现实，所以一般稍大点的公司都会引入专业的SCA工具，用于梳理企业的产品中使用了哪些开源软件，这些开源软件存在怎样的安全风险和许可证风险。</p><p>&nbsp;</p><p>InfoQ：发生漏洞事件之后，可以做哪些事情尽量降低不好的影响？</p><p>&nbsp;</p><p>顾钧：从开发人员的角度讲，如果发现了一个漏洞，首先要找到可行的绕过方法，在用户不需要进行系统更新、不需要改动任何代码的情况下将问题危害降到最低，找到方法后尽快公布，通知用户漏洞详情，如果没有也需要告知用户漏洞信息，毕竟对用户来讲是非常危险的，哪怕连夜完成修复，比较严谨的大型公司也很难将新的修复版本上线生产环境。因为这类公司有自己的流程且不易打破，连夜赶出来的修复版本也没有经过完善的测试，对企业来讲是不可取的。</p><p>&nbsp;</p><p>朱贤曼：如果是开源软件出现漏洞，我们一般建议升级版本，成本相对来说偏低，当然企业内部一般会有完备的应急预案，肯定不是随便发版升级的。</p><p>&nbsp;</p><p>InfoQ：如果一个开源项目总是频繁发布漏洞修复信息，是应该使用还是尽量少用？</p><p>&nbsp;</p><p>顾钧：我觉得这个问题挺有趣的。首先肯定要看开源软件本身的代码质量以及Issue里的反馈，对开源项目本身有一个整体评判。如果觉得软件不行就不要使用，如果用户反馈比较积极，经常更新漏洞信息说明真的有很多人在用，经常有用户给出反馈，说明项目质量在稳步提高。此外，也要注意频繁升级带来的成本。</p><p>&nbsp;</p><p>朱贤曼：我在做行管时，如果软件频繁出现安全漏洞升级信息，不建议使用。当然也分情况，开源软件同类型的项目很多，要多方面综合考虑，但是一般不建议选择频繁出现漏洞，或者漏洞版本很多的开源软件，建议选择基金会支持或者商业公司主导的项目，当然这种项目也曾出现过较大漏洞，但相对来说可能会有保障一些。</p><p>&nbsp;</p><p>InfoQ：开源项目有什么样的措施保证安全性？</p><p>&nbsp;</p><p>顾钧：代码托管在GitHub上，平台就有专门的工具扫描依赖，如果有比较严重的安全性问题会提示是否升级到新的版本。软件升级本身是一个复杂的过程，有时升级太快会引入一些新的问题，如果只是一些简单修复，对其他的影响不大，我觉得是需要积极升级的。当然有时候，这种修复也可能会引入新的问题。企业在生产当中要具体问题具体分析。</p><p>&nbsp;</p><p>InfoQ：开源项目背后的商业公司在整个过程中起到什么样的作用，或者说会引入一些什么样的风险吗？</p><p>&nbsp;</p><p>顾钧：早期来看，很多开源软件都是社区驱动的，要保证项目长期发展，光靠社区志愿是很难的，没办法要求太高。只有商务合同或者有现实利益分配时，才能确保需要的项目按时交付，个人业余时间做的项目出现在依赖上，无法提出太多要求。如果开源项目成立自己的商业公司，用户可以与其签订法律合同，提出SLA或问题修复时效相关的承诺，这些开源软件背后的公司扮演了一个让供应链更牢固的角色。</p><p>&nbsp;</p><p>朱贤曼：我非常认可顾老师的观点，站在企业的角度，选择开源软件，我会建议考量这些因素。如果自己没有支持能力，建议选择有商业背景的公司，可以购买公司提供的服务。有时免费的才是最贵的，有人帮助对整个项目兜底，至少能够解决很多问题，这是值得做的方式。</p><p>&nbsp;</p><p>InfoQ：请两位分享开源软件供应链可能面临的风险或者问题？</p><p>&nbsp;</p><p>顾钧：我觉得从早期许可证的角度来讲，很容易出现类似MIT、BSD这种过于宽松的协议，因为其不带专利所有权。代码虽然是开源的，但不代表不能就这些代码申请专利。开发者可以在代码开源之前，先递交专利申请。如果开源项目的协议是Apache 2.0，提交代码时已经默认授权用户在项目范围内使用专利，这也是相对安全的。类似MIT或者BSD这些可能就没有这个显式过程，会有另外的方式去弥补，比如通过CLA的方式将专利授权给项目用户使用，这是从许可证兼容性和专利层面的考量。</p><p>&nbsp;</p><p>另一个显著问题是需要将企业内部流程或者习惯做法更加规范化。因为之前开源的JavaScript生态当中的一些开源项目，作者直接往npm站点上传所谓的“有毒”代码，正常情况不应该在生产环境中直接下载mpn包做升级，肯定有测试环境，验证升级没问题再搬到生产环境，用户需要有这样的流程。</p><p>&nbsp;</p><p>朱贤曼：一般来说，开源软件的风险可能来自四个方面：一是安全风险，其中又分为开源软件本身的安全漏洞导致的风险和目前关注度很高的软件供应链攻击的风险，个人建议不信任所有从外面下载的组件；二是法律风险，其中又分为许可证本身的协议，如果未履行开源合规义务，可能会造成侵权而遭到索赔、诉讼、产品下架、商誉受损等风险。另外一个是专利方面的风险，一种是本身的创建者/贡献者实现的专利，有可能预埋专利陷阱，另一种是第三方专利维权风险。此外，还有商标侵权及出口管制方面的风险；三是供应链断供风险，比如俄乌事件后，可能GitHub直接就不允许俄罗斯开发人员下载代码了，甚至把俄罗斯账号的代码提交删掉了。还有上次faker.js删库事件，导致后续版本和代码更新都没有了；四是运维风险，如果企业自己没有能力支撑，没有商业公司帮忙的话，维护成本很大。</p><p>&nbsp;</p><p>InfoQ：请两位老师简单分享开源软件供应链常见的攻击类型。</p><p>&nbsp;</p><p>顾钧：首先是专利，比如潜水艇专利，预留专利埋坑，这类是很不容易防范的，因为专利审核对一般公司来讲需要一些代价。其次是恶意代码，现在主流的开源软件分发方式就是npm、GitHub，从公开站点获得开源软件后一定要做验证，这能够帮助大家减少很多麻烦。</p><p>&nbsp;</p><p>朱贤曼：一种是恶意代码，前段时间也有新闻提到可以在GitHub上把恶意代码装上去且不留下任何记录，这是很恐怖的，我们还是比较信任GitHub上面下载下来的内容，因为我们认为这是官方网站。另外一种最近提的比较多依赖混淆攻击，npm包管理器的设计存在一些问题，比如用户创建了一个私人组件，其版本是一个范围，如果同名组件更新源码，但其中存放了恶意代码，也会自动拉取过来，同名组件的代码就跑到用户环境中了，企业内部在引入组件时则需要做更多校验，我们建议企业建立自己的开源软件库，在组件进来之前有个准入机制，做测试验证，保证所使用的组件都是受信任的。当然这个成本是相对较高的，但确实很有必要。</p><p>&nbsp;</p><p>InfoQ：关于断供问题怎么解决？</p><p>&nbsp;</p><p>顾钧：开源本身不限制地域，但是承载开源这件事情的通常是一个商业实体，商业实体会受到所在地区的出口管制法，或者其他制裁条例的限制。很多时候，我们现在用到的开源软件，包括自己的开源软件都托管在GitHub上，GitHub是美国的公司，必然会受到美国的出口管制法的限制。从这个角度来讲，企业内部可以建内部代码库，所依赖的东西可以将其放在内部代码库上，万一有一天访问不了GitHub，总有个备份的源码池可以获得这些代码。从国家角度来讲，对此一直在做准备。目前来讲，我觉得大家都有各自的解决方法，似乎影响没有那么大。</p><p>&nbsp;</p><p>朱贤曼：我个人觉得，相比许可证合规和安全风险来说，断供风险只是开源众多风险之一，相对来说还是影响比较小的，开源治理更多的是许可证的法律法务的合规和安全性。</p><p>&nbsp;</p><p>讲师介绍：</p><p>&nbsp;</p><p>顾钧，Zilliz 合伙人、首席布道师，LF AI&amp;Data 基金会 TAC 成员，开放原子基金会开源导师。北大毕业 16 年以来专注于数据库、大数据技术，尤其对 OLTP 平台与场景有着丰富的经验，先后任职于工商银行、IBM、摩根士丹利、华为等企业。运营的视频号ID为「JUN不断向前」，不定期更新开源领域的热门趋势及重要内容解析。</p><p>&nbsp;</p><p>朱贤曼，上海安势信息技术有限公司资深解决方案架构师，十余年软件开发经验，先后从事出口管制合规、合规相关系统设计和实施、开源软件合规等工作。</p>",
    "publish_time": "2022-07-13 07:56:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从10万npm用户信息被窃看开源软件供应链安全",
    "url": "https://www.infoq.cn/article/l63udT3Mj3m2xf3xpkmW",
    "summary": "<p>如今，所有热爱开源的开发者可能都心怀担忧：开源软件的供应链安全问题如何解决？关于开源代码维护者因反俄给node-ipc库添加恶意代码、GitHub封停部分俄罗斯开发者账号的讨论还未结束，10万npm用户账号信息被窃再登HN热搜，开源软件供应链的安全性成为业界关注的焦点话题。</p><p>&nbsp;</p><p>前段时间，ARM 开源项目宣布从 GitHub 迁移至 GitLab。当时，Arm 杰出工程师兼软件社区高级总监 Andrew Wafaa 解释道：“GitHub 其实是个黑箱，我们必须与之合作、或者把一部分工作交给对方来完成，而最终结果并不一定准确可靠，使得我们不得不规划更多审查。”本期<a href=\"https://www.infoq.cn/video/CFdQJA4Nir6k6aCruMY7\">《极客有约》</a>\"，我们邀请到了极狐（GitLab）的解决方案架构部负责人Gavin和我们一起交流如何提高开源软件供应链安全性以及极狐(GitLab)的一些想法。</p><p></p><p></p><p></p><p></p><h2>热点问题及概念探讨</h2><p></p><p>&nbsp;</p><p>InfoQ：请解读一下10万npm被泄露的事件？</p><p>&nbsp;</p><p>Gavin：该事件的引爆一方面源于GitHub的热度，由于GitHub是全球最大的开源软件协作平台，而且其本身的架构是闭源的，没有任何人知道其底层逻辑。此前，GitHub已经有很多安全相关的事件被爆出，故而GitHub一直不遗余力在做快速应对，GitHub也是在第一时间发布了问题的前因后果，证明不是自己的过错。</p><p>&nbsp;</p><p>回到问题本身，这是一个典型的软件供应链安全问题，本身与GitHub的架构没有关系，问题原因是有攻击者偷窃了GitHub的某个高级用户账号的OAuth令牌，从私有仓库下载数据，其中影响最大的是窃取了10万的npm用户数据。</p><p>&nbsp;</p><p>为什么说该事件与开源软件供应链安全相关，从整个问题逻辑上来讲，与GitHub并没有直接关系，是其合作伙伴非常重要的账号被盗导致的用户数据泄漏，但实际上已经对GitHub的品牌有一定影响，因为最终向用户呈现的是GitHub。GitHub的快速应对做得还是不错的，立刻让该令牌失效，又重置了所有受影响的用户。之后通过自查发现，由于npm与GitHub是完全独立的架构，所以本次泄漏不是由于GitHub技术原因导致的。此外，GitHub的SRE团队又进一步的分析，因为两个服务之间做了整合，故在GitHub日志系统里可以查到npm的日志信息，通过分析发现，npm日志中存在很多带有明文存放的用户密钥信息，这实际上非常危险，说明npm架构在数据库日志里没有对用户信息做加密。</p><p>&nbsp;</p><p>InfoQ：能否解释一下软件供应链安全、DevSecOps、安全左移分别是什么？以及它们之间的联系？</p><p>&nbsp;</p><p>Gavin：按时间来讲，“DevSecOps“这个概念出现的时间要比“软件供应链安全”要早一点。</p><p>&nbsp;</p><p>DevSecOps在DevOps中间加Security，即安全，这也说明其是DevOps在安全方面的延伸。我们知道DevOps是一种文化，从实践角度来讲，其解决的是软件研发生产的全生命周期管理，包括需求设计、研发测试、发布到生产运营等阶段，所以DevSecOps就是在软件全生命周期流程中加入安全，进而保护整个全流程安全的实践过程。</p><p>&nbsp;</p><p>软件供应链安全是DevSecOps的延伸，这个延伸点在哪里？实际上，软件供应链安全是一个更大的生命周期，在DevSecOps周期基础上，从软件供应链安全的角度，又有上游跟下游两个阶段，上游就是对入口的安全管控，比如依赖的开源软件、采购的商业组件，下游就是出口的安全管控，即该软件的安全分发，商用交付，包括可能做为另外一个更大软件的一部分的管理。</p><p>&nbsp;</p><p>安全左移的概念稍微小一点，对照DevSecOps软件生命周期，传统的安全方式不叫左移，是右置，企业软件开发完成，在上线之前请专门的安全厂商做一次针对运行环境的全方位扫描。这意味着出现任何问题都要返工，在国内软件研发，基本上工期都是非常紧凑的，能按时上线已经不不易，上线之后发现安全问题导致返工，研发人员的幸福感基本就葬送在这里了。安全左移指的是将安全前置，从需求设计到开发、测试、编译到部署上线的每一个阶段，都要进行安全管理，包括安全扫描引擎、管理措施、管理规范。而且要通过自动化工具实现，最终是在保障安全的前提下让应用上线变得高效。</p><p>&nbsp;</p><p>InfoQ：我们需要先把DevOps部署完全之后再做DevSecOps，还是直接做DevSecOps？</p><p>&nbsp;</p><p>Gavin：DevSecOps从定义上来讲是指软件全生命周期每个阶段都要注入安全，如果将DevOps的工程实践跟安全联系起来且能保证速率，才是真正的DevSecOps。如果没有通过DevOps的流水线集成全部的安全工具，即研发、测试、运维各阶段再安全方面都是各自为战，这就会造成运转缓慢，虽然每个阶段都在做安全，但实际上整个流程周期会特别长，作为开发、测试、运维人员，没有享受到工具带来的便利，只有管理带来的复杂，导致最终结果比较差。故最平滑的做法就是，先有DevOps的最佳实践，然后再在此经验基础上把安全工具嵌套进去，从而真正实现DevSecOps的价值。</p><p>&nbsp;</p><p>InfoQ：国内外软件供应链安全目前发展历程大概是什么样的？</p><p>&nbsp;</p><p>Gavin：根据我的观察，欧美尤其是美国在整个安全领域，包括软件供应链的细分角度，领先国内至少四年。很多细分的安全工具，头部企业基本清一色都是欧美企业，国内很多企业在一些关键场景上也是采购国外的工具。</p><p></p><p>政策分析：</p><p></p><p>一、美国方面：</p><p></p><p>1、美国政府对安全领域大力支持，2021年4月，美国正式制定软件供应链标准，由国家保护与计划局（CISA）和国家研究所标准与技术委员会（NIST）发布了论文“Defending Against Software Supply Chain Attacks”。</p><p></p><p>2、2021年5月12日，美国总统拜登签署名为“加强国家网络安全的行政命令”（Executive Order on Improving the Nation’s Cybersecurity）以加强网络网络安全和保护联邦政府网络。</p><p>&nbsp;</p><p>3、在2022年2月份，NIST发布《软件供应链安全指南》，其中核心要求：</p><p>&nbsp;</p><p>软件开发者应实施并证明采用了安全软件开发实践；安全开发环境；自动化工具确保代码完整性；自动化工具检查漏洞；</p><p>&nbsp;</p><p>4、2022年5月中旬，由Linux基金会与开源安全基金会举办了开源软件安全峰会，集结多家科技巨头的高层主管，以及美国白宫等多个联邦机关官员参会，这次会议具体指出将解决开源软件的十大挑战，同时这些科技巨头也承诺，在未来两年内，将投入1.5亿元经费解决相关问题。本次峰会进一步指出开源软件十大问题：</p><p>&nbsp;</p><p>安全教育风险评估数字签名内存安全安全应变强化扫描能力程序代码审核数据分享软件物料清单SBOM供应链改善</p><p>&nbsp;</p><p>二、欧洲方面：</p><p></p><p>2021年5月，英国政府宣布，正从治理IT供应链的组织及相关MSP，寻求防御数字供应链攻击的建议和服务。</p><p>&nbsp;</p><p>2021年5月，德国通过了《信息技术安全法案2.0》，作为对第一部法案的更新，该法案旨在“在日益频繁和复杂的网络攻击以及日常生活持续数字化的背景下提高网络和信息安全。”该法案影响到德国IT行业的许多领域，特别强调一点，针对供应商，即关键部件的制造商，也将承担一定的义务，以保护整个供应链。</p><p>&nbsp;</p><p>2021年7月，欧盟网络安全机构（ENISA）发布了一份题为《Understanding the increase in Supply Chain Security Attacks》的报告，分析了最近一年的软件供应链安全的信息。</p><p>&nbsp;</p><p>三、国内：</p><p></p><p>国内软件供应链安全整体相对比较滞后，从国家标准角度来讲，我们在供应链方面有一些偏硬件的标准，软件供应链安全标准正在制定中，具体为：</p><p></p><p>2022年4月《信息安全技术软件供应链安全要求》由&nbsp;<a href=\"http://std.samr.gov.cn/gb/search/gbDetailed?id=DDAD3E83D90FB52EE05397BE0A0A2737\">TC260</a>\"（全国信息安全标准化技术委员会）制定</p><p></p><p>在行业标准方面，中国信通标准化由中国信通院牵头，也在做软件供应链产品方面的标准。具体为：</p><p>《软件供应链安全保障基本要求》 中国通信标准化协会标准</p><p>&nbsp;</p><p></p><h2>开源软件合规性问题解答</h2><p></p><p>&nbsp;</p><p>InfoQ：开源协议及其基金会在整个开源软件供应链中扮演着一个什么样的角色，他们具体能解决哪些问题？</p><p>&nbsp;</p><p>Gavin：站在软件供应链安全的角度，开源只是其中一部分，但目前绝大多数安全事件都是因为开源软件导致的，所以大家潜移默化会把软件供应链安全与开源软件漏洞紧密结合起来。</p><p>&nbsp;</p><p>从开源软件管理角度，通常会有有三个主体：个人，企业，基金会，不同的开源项目会选择包含其中的一个或者三个主体，并不是每一个项目都要加入基金会才能运作的。而基金会的价值之一就如何保证用户的利益以及如何保证项目贡献者的利益，开源协议在这两个点发挥着重要作用，既能够保护使用者的利益，同时也能够保护生产者的利益。</p><p>&nbsp;</p><p>InfoQ：目前在整个开源软件供应链里面最常见的法律合规性的问题是什么？企业应该怎么应对这些问题？</p><p>&nbsp;</p><p>Gavin：回归到法律相关，开源软件供应链相关主要有两大问题：</p><p>&nbsp;</p><p>第一类是License违规使用，一些License会对使用者带来一些约束。比如之前很多云厂商通过售卖MongoDB云服务盈利，一定程度了影响了MongoDB的业务发展，所以MongoDB再2018年修改了License协议，改成了更加严格的SSPL，根据协议，云计算厂商在MongoDB的基础上共享，要么从MongoDB获取商业许可证，要么面向社区开源相关源代码。</p><p>&nbsp;</p><p>第二类，如果企业将产品出海到欧美市场，尤其是一些软硬结合的高科技产品，根据美国或者欧盟的法律要求，需要提供对应的供应链清单，比如产品中采用了哪些开源软件，包含了哪些商业软件，采购的商业软件的构成是什么样子？采用了哪些开源软件？版本是什么？这些版本存在哪些漏洞。如果提供不出来，可能在招投标层面会受到很多限制。如果发现违规使用License协议，甚至会被诉讼。</p><p>&nbsp;</p><p>针对第一类问题，企业需要对自身开源软件的使用进行合规管控，由法务部门制定相关开源软件引入的规范，然后由信息化部门落实在软件生产的日常管理中。</p><p>针对第二类问题，企业需要建立相应的软件供应链安全管理机制，同时引入软件成分分析工具，甚至构建软件供应链安全的平台，提前对自身软件进行分析。</p><p>&nbsp;</p><p>InfoQ：大家是否已经形成安全左移的意识形态？</p><p>&nbsp;</p><p>Gavin：第一类行业的头部企业，主要从品牌保护的角度出发，会实时关注安全技术的发展动向，即使引入最先进的安全管理技术，第二类，涉及到强监管的行业，如金融行业；第三类是出海企业，不做这件事情，产品就卖不出去，或者在竞标环节处于下风；第四类是医药领域，对用户信息数据安全非常严格，但是医药信息化相对来讲没有那么快，DevOps做得还一般，实现DevSecOps自动化工具可能还有一段路要走，但是目前是一个不错的切入点。</p><p>&nbsp;</p><p>InfoQ：从极狐(GitLab)视角去看，开源项目包括社区背后的公司在这块主要起到了哪些比较关键的作用？</p><p>&nbsp;</p><p>Gavin：首先，国内目前开源环境下，大家贡献相对较少，专门做开源软件的公司也很少，需要激励大家增加开源贡献，把国内的社区、开源软件项目做大做强。从社区角度来讲，我们需要建立相对公平的态势，不断提高开源项目的价值、热度与采纳度；其次，站在平台社区的角度，社区平台需要做一些事情，让大家了解如何合理合规使用开源项目，需要告诉大家满足合规安全的开发规范是什么，只有让广大开发者真正去使用起来，才能体会到软件供应链安全和相关服务带来的价值。比如极狐(GitLab)&nbsp;SaaS版本，会给用户一到两个月的旗舰版试用期，在试用期里可以体会如何通过一体化的DevSecOps解决方案实现端到端的安全，开箱即用，非常方便。如果让用户体会到产品的价值，在一定程度上也会帮助整个软件供应链安全的推广。</p><p>&nbsp;</p><p></p><h2>常见安全问题及阻止办法</h2><p></p><p>&nbsp;</p><p>InfoQ：从开发、交付和使用三个层面分别来看，常见的软件供应链安全问题有哪些？</p><p>&nbsp;</p><p>Gavin：开发层面主要有引入License不合规的软件、开源软件的漏洞、测试不充分（缓存溢出、SQL注入、跨站脚本）、密钥硬编码； 交付层面是制品库被篡改；运维层面是针对服务器、网络方面的攻击， DDOS等。</p><p>&nbsp;</p><p>InfoQ：从我们常见的一些安全问题的角度出发，从去年开始，只要提到开源软件工具，肯定要依赖项目工具，您是怎么看待的？</p><p>&nbsp;</p><p>Gavin：这是一个非常有意思的问题，依赖混淆攻击的攻击方法特别简单，主要针对JavaScript、Node.js包等，攻击者盲猜npm库的命名规则，上传一个带有漏洞的版本到外网的官方npm库中，版本号用最新的，这样企业在自动构建的时候，会从外网下载这些带有漏洞的版本号最新的最新依赖库，从而导致被攻击。其整个攻击原理非常简单，解决途径也非常简单，最直接的就是管理好用户，不要连外网，只从自己的内部工具下载，这样肯定就没有问题了。其次，如果有外网，就需要对制品过程做一些配置，不允许制品下载的过程去访问外网，避免到外网下载恶意版本。另外，从管理角度来讲，需要加强对包命名的规范，不要轻易被攻击者猜到。</p><p>&nbsp;</p><p>InfoQ：现在有哪些比较好的手段可以自查项目的安全性？</p><p>&nbsp;</p><p>Gavin：这里讲一些低成本，简单好用的方法给到大家。首先，引入开源软件扫描引擎工具，利用这些工具对现有的第三方开源软件进行License扫描、漏洞扫描，有专业的商业软件，也有一些入门级的开源软件；其次，对于一些关键开源软件，如MySQL，Redis，尽量关注其版本发布说明，软件升级除了增加功能之外，最重要的就是为了解决安全漏洞；第三，代码里面不要硬编码任何用户信息、密钥、Token，可以通过写一些脚本实现；最后，如果采用容器技术的话，我们可以引入一些容器镜像扫描工具保证镜像的安全。</p><p>&nbsp;</p><p>InfoQ：引入开源软件或者对外输出软件或者服务的时候，应该具体注意什么？</p><p>&nbsp;</p><p>Gavin：这涉及到选型过程。首先，企业需要建立真正适合自己的管理体系标准，管理好入口，满足一定要求才能引入该软件；其次，软件工具的采买要把涉及到赔偿的法规作为引入层采购的条款，这是非常重要的；第三，需要拿到采购的软件自身以及上游的软件引用清单，一定要清楚具体引入了什么软件以及对应的版本信息；最后，做整体审查，包括自己的代码和上游代码，实时关注漏洞信息，尤其是关键组件出现问题一定要第一时间解决。</p><p></p><h2>未来规划</h2><p></p><p>&nbsp;</p><p>InfoQ：关于软件供应链安全，国内有没有一些比较好的软件工具？</p><p>&nbsp;</p><p>Gavin：这个问题从乙方提供平台工具的角度来讲，大概分为两个流派，第一类是做安全工具厂商起家的，先有安全工具，然后再集成到DevOps体系中，安全工具厂商通常由多种工具解决软件供应链安全中的局部安全问题，随着DevSecOps兴起，安全工具厂商需要与客户的DevOps解决方案体系融合，慢慢形成DevSecOps平台类型的解决方案及产品；第二类是做DevOps起家的厂商，先有DevOps，然后再整合各类安全的工具，比如极狐(GitLab)，我们有DevOps端到端工具，支持云原生的Kubernetes和CI/CD，在这个基础上又收购了专业解决安全的软件厂商，包括一些测试工具，同时我们又集成了其他商业工具，先有DevOps再有Sec工具。从软件供应链平台角度来讲，类似极狐(GitLab)这样的DevSecOps厂商很少。</p><p>&nbsp;</p><p>InfoQ：现在很多企业在用云，选择某一家云平台之后，厂商本身是不是也会提供云安全的能力？这种安全能力足够保证软件在上面的安全性吗？</p><p>&nbsp;</p><p>Gavin：最近一两年，企业在引入与扩大使用云原生技术的时候，关注点已经向安全方面考虑。对于安全话题，我们要始终保持敬畏的，因为这是有一定的行业壁垒，需要专业的人经过时间的积累，才能形成不错的解决方案和比较优秀的产品。云原生厂商或者云原生延伸的安全更多在于云原生技术本身的安全，比如，如何保证网络安全？如何保障Kubernetes集群的安全？对于在云平台上面部署的应用的安全防护，从软件供应链的角度，开发阶段可以引入SCA、SAST、License检测等检测工具，发布阶段需要确保制品的安全性，在运行态，可以引入如IAST、DAST的检测技术，这背后是一整套安全体系，对应需要一系列的安全工具集。</p><p>&nbsp;</p><p>InfoQ：开源软件供应链安全未来三到五年要把一些事情大概做到什么样子？</p><p>&nbsp;</p><p>Gavin：这个问题很大，我结合个人看法提几点粗浅的看法。第一点是尽快出台国家标准，包括行业标准的建立，由政府机构牵头，要集合行业专家的智慧；第二点是需要出台行业评测体系化的指导意见；第三点是打磨更多产品出来，并且在更多的行业推广起来，尤其是头部客户，需要将最佳实践分享出来引领其行业在安全方面不断向前发展。</p><p>&nbsp;</p><p>嘉宾介绍：</p><p>&nbsp;</p><p>Gavin WANG（王斌峰） &nbsp; 极狐(GitLab)公司 解决方案架构部负责人</p><p>&nbsp;</p><p>Gavin致力于帮助企业开展DevOps实践、云原生转型、远程办公、软件供应链安全的技术咨询工作，参与过DevOps一体化平台、混合云管理平台、人工智能平台、微服务运维平台、数据技术中台、架构设计项目，曾拜访逾100家终端用户，熟悉多个行业的转型痛点及业务诉求。</p>",
    "publish_time": "2022-07-13 08:30:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Leyden延迟了OpenJDK AOT编译器，转而优化JIT编译器",
    "url": "https://www.infoq.cn/article/xH5DI20VgkxdVEgjogVM",
    "summary": "<p><a href=\"https://www.google.com/url?q=https://openjdk.java.net/projects/leyden/&amp;sa=D&amp;source=docs&amp;ust=1654694658621055&amp;usg=AOvVaw3rBIGTg6iHNtdqk4H53pBg\">Leyden项目</a>\"的目标是“解决Java启动时间慢、达到性能峰值慢和占用空间大等长期痛点问题”。它想通过在OpenJDK中“引入静态镜像的概念”来实现这一目标。静态镜像来自于对<a href=\"https://www.infoq.com/articles/native-compilations-boosts-java/\">原生可执行文件的提前（Ahead-of-Time，AOT）编译</a>\"。在两年没有公开的活动之后，Leyden项目在2022年5月改变了方向，首先优化即时（Just-in-Time,JIT）编译。由此产生的<a href=\"https://mail.openjdk.java.net/pipermail/leyden-dev/2022-May/000001.html\">优化几乎肯定要比最初计划的要弱</a>\"，它最早会在2025年底交付给主流Java开发者。Oracle的Graal项目已经实现了Leyden项目的目标，但其代价是该项目目前竭力想避免的。</p><p></p><p>Graal项目起源于Oracle Labs，并不是OpenJDK的一部分。它的<a href=\"https://www.infoq.com/articles/native-java-graalvm\">GraalVM Native Image</a>\"是一个Java AOT编译器，如今能够生成原生可执行文件。与Java的JIT编译器相比，它们有<a href=\"https://www.youtube.com/watch?v=EpcovUvQ-XA&amp;t=179s\">四个优势</a>\"，即启动更快、内存和CPU占用更低、安全漏洞更少以及文件更小。</p><p></p><p>但是，这些成就是有代价的，那就是GraalVM Native Image对Java应用有一个所谓的封闭性假设（closed-world assumption）的要求，这对所有的Java的应用来说都是很难接受的。为什么呢？因为Java是一个动态语言，它在运行时赋予了应用很多的权力，比如反射、类加载，甚至构建类。有些特性在GraalVM Native Image的<a href=\"https://www.infoq.com/articles/native-java-aligning/\">封闭世界里是无法正常运行的</a>\"。这也就是Leyden项目现在想要“探索比封闭性假设更弱的约束，并发现它们能够实现哪些优化”的原因。尽管如此，Leyden项目“依然有希望[...]生成完全静态的镜像”，只不过“这是长期来看”的目标了。</p><p></p><h3>OpenJDK以前曾经尝试过AOT编译</h3><p></p><p>Leyden项目是OpenJDK对AOT编译的第二次尝试。第一次尝试是JEP 295 Ahead-of-Time Compilation的jaotc，并于2017年9月在JDK 9中交付。与GraalVM Native Image类似，它使用了Graal项目。但是，与GraalVM Native Image不同的是，它非常不受欢迎：当Oracle在Java 16构建版中<a href=\"https://bugs.openjdk.java.net/browse/JDK-8255616\">移除</a>\"jaotc时，“没有受到任何人的抱怨”。于是，Oracle在JDK 17中，基于JEP 410 Remove the Experimental AOT and JIT Compiler，干脆利落地移除了它。</p><p></p><p>对于OpenJDK项目来说，Leyden有着不同寻常的历史。Java语言的架构师Mark Reinhold在2020年4月<a href=\"https://www.infoq.com/news/2020/05/java-leyden/\">提出了它</a>\"，随后，OpenJDK在2020年6月将其<a href=\"https://mail.openjdk.java.net/pipermail/announce/2020-June/000290.html\">批准</a>\"为一个项目。但是，从批准到2022年5月<a href=\"https://mail.openjdk.java.net/pipermail/leyden-dev/2022-May/000000.html\">创建邮件列表</a>\"的两年时间里，没有看到该项目任何明显的进展。这也就是该项目为何刚刚起步，现在主要关注的是“<a href=\"https://mail.openjdk.org/pipermail/leyden-dev/2022-May/000000.html\">概念，而不是代码</a>\"”的原因。Reinhold指出，像“HotSpot JVM、C2编译器、应用类数据共享（application class-data sharing，CDS）以及jlink链接工具”都是优化的目标。值得注意的是，列表里缺失的一个组件是<a href=\"https://youtu.be/0evEs_3yaEI\">CRaC</a>\"，它是一个OpenJDK项目，能够通过在磁盘中加载Java应用来减少启动时间。</p><p></p><p>通过反推可以得出可能的交付日期。现在，LTS版本的重要性已经超出了预期。Ben Evans，之前就职于性能监控公司New Relic，在Devoxx UK 2022上宣布“<a href=\"https://youtu.be/SYO-LmA647E?t=186\">没有任何一个非LTS版本的市场份额超过了1%</a>\"”。这表明，主流的Java开发人员只会从一个Java LTS版本迁移至另一个LTS版本。</p><p></p><p>因为Leyden项目现在刚刚开始，估计很少有成果能够以生产可用的状态进入2023年9月份发布的JDK 21（也就是下一个<a href=\"https://www.infoq.com/news/2021/10/oracle-java-two-year-lts\">LTS版本</a>\"）。所以，主流Java开发人员可能只有在2025年9月的LTS版本（JDK 25）中才能看到Leyden项目的第一批成果。基于这样的假设，Leyden项目最早会在2027年9月通过JDK 29向原生可执行文件提供AOT编译功能。InfoQ将继续关注Leyden项目的进展。</p><p></p><h3>Spring Boot对Leyden项目的反应</h3><p></p><p>在Leyden考虑的特性中，至少有一些需要应用框架的支持才能发挥最佳效果，比如jlink或CRaC。所以，InfoQ联系了Spring Boot、Quarkus和Micronaut的开发者，了解他们对Leyden公告的初步反应。</p><p>Spring Framework的项目负责人Juergen Hoeller对Leyden项目表示了认可：</p><p></p><p></p><blockquote>Leyden项目是一个很有前途的倡议，与我们在Spring Framework 6和Spring Boot 3的大方向上是一致的。</blockquote><p></p><p></p><p>Hoeller还欣然接受在Spring中支持CRaC：</p><p></p><p></p><blockquote>CRaC堆快照可以作为改善Spring应用的启动时间的通用方案。在应用启动的最后阶段生成快照，此时几乎没有任何处于打开状态的文件或网络资源，这符合CRaC的预期。Spring甚至已经在应用上下文刷新结束时重置了它的通用缓存，在用请求相关的元数据动态地重新填充缓存之前清除了启动相关的元数据。在 [......] 应用上下文对快照事件的具体反应，以及改进通用组件的“快照安全”方面，我们肯定会在技术上可行的情况下，在Spring Framework 6.x产品线中努力为早期采用者赋予更多的能力。</blockquote><p></p><p></p><p>Hoeller认为Spring将会很快支持jlink和Java平台模块系统（Java Platform Module System ，JPMS）：</p><p></p><p></p><blockquote>目前的Spring Framework 6.0的里程碑版本还不包括module-info描述符。但这在9月份M6里程碑版本的路线图上，在我们进入6.0的发布候选阶段时，会重新评估第三方生态系统的模块系统就绪情况。由于Leyden项目有可能将jlink变成一个更强大、更通用的工具，所以我们计划不仅为jlink目前的能力做好准备，也会考虑它进一步的演进。</blockquote><p></p><p></p><h3>Quarkus对Leyden项目的反应</h3><p></p><p>Quarkus的联合创始人和共同负责人Jason Greene对Leyden项目发表了评论：</p><p></p><p></p><blockquote>我们对Leyden项目修改Java语言规范以更好地支持静态镜像、原生编译和其他技术（如JVM检查点）的目标感到最为兴奋。此外，我们很高兴看到封闭性假设仍然可能是该项目的长期目标。</blockquote><p></p><p></p><p>Greene也欣然接受在Quarkus中支持CRaC：</p><p></p><p></p><blockquote>最近，对CRaC研究项目的初步支持已经由CRaC的负责人贡献给了Quarkus项目。不管运行时的目标类型是什么，Quarkus都会进行构建时的优化，所以在OpenJDK上运行时，我们依然能够看到相当可观的成本节省，而不仅限于GraalVM。在OpenJDK之上添加检查点的方式，比如CRaC，能够进一步优化启动时间。它无法带来类似于原生镜像那样的成本节省，但是对倾向于或必须采用JVM执行的应用来讲，未来这都是一个很有意思的可选方案。</blockquote><p></p><p></p><p>但是，Greene对于在Quarkus中使用jlink和JPMS并没有表现出太高的热情：</p><p></p><p></p><blockquote>截止到目前为止，jlink只是为基于JVM的应用的存储开销带来了好处（不管有没有它，内存开销和启动时间基本上都是一样的）。但是，在容器和Kubernetes应用中，常见的实践是在标准JVM基础镜像上建立新的层，这已经比将所有的应用切换到jlink上带来了更多的成本节省（因为每个人都会打包自己裁剪过的JVM）。在原生镜像的场景中，JVM的细粒度元素编译到了镜像中，所以在这种情况下，jlink也提供不了什么帮助。同样，对于JPMS，Quarkus已经通过Quarkus扩展实现了自己的模块化理念，允许我们将依赖集修剪到只包含所需的内容。Quarkus所采取的方式与简单扁平化classpath是兼容的，这也是大多数Java生态系统和构建工具如今所偏爱的方式。在成本方面，如果按照jlink的要求转向纯JPMS模块（没有自动模块），那么将意味着不仅对Quarkus，还对Quarkus构建所需的大量的库都会产生破坏性的变更。在考虑进行转换之前，我们希望看到这些因素能够更好地平衡。</blockquote><p></p><p></p><h3>Micronaut对Leyden项目的反应</h3><p></p><p>Object Computing, Inc.（OCI）的首席软件工程师Sergio del Amo Caballero对Leyden项目没有发表Micronaut框架的官方声明。但他在最近一个关于在Micronaut上添加对CRaC支持的<a href=\"https://github.com/micronaut-projects/micronaut-core/issues/7601\">GitHub issue</a>\"上对此进行了阐述。</p><p></p><p>Caballero还分享了2020年7月的一段<a href=\"https://youtube.com/clip/UgkxyPlY-jWrPCWnBdf-EeKd6iMklqp8a7df\">YouTube视频</a>\"，视频中Micronaut的创始人Graeme Rocher对JPMS进行了评论：Micronaut支持JPMS并发布了module-info文件，但必须要“在支持Java 8之间取得平衡”。JPMS是在Java 9中加入的，但Micronaut 3.5，即当前版本，仍然运行在Java 8上。</p><p></p><h3>结论</h3><p></p><p>到目前为止，OpenJDK还没有解决“Java启动时间慢、达到性能峰值慢以及占用空间大的问题”。首先，它的jaotc&nbsp;AOT编译器并没有得到足够的动力，并且已经废弃了。随后，Leyden项目开始对Java的原生编译进行标准化，但停滞了两年之久。</p><p></p><p>现在，Leyen项目已经转向首先优化JIT编译，情况正在好转：Spring和Quarkus都拥抱CRaC以减少启动时间。但是当涉及到实现较小的Java应用时，只有Micronaut坚持Leyden项目的建议，即使用JPMS。Spring计划在2022年底的6.0版本中支持JPMS，不过Spring生态系统可能还不会这样做。而Quarkus目前没有计划加入JPMS。</p><p></p><p>Leyden项目的成果，最早可以在2025年底以JEP的形式到达主流Java开发者手中。因此，至少在那之前，将GraalVM Native Image AOT编译器与Quarkus、Micronaut或即将推出的Spring Boot 3等框架结合起来，仍然是避免“Java启动时间慢、达到性能峰值慢以及占用空间大的问题”的最佳选择。</p><p></p><p>作者简介：</p><p>Karsten Silz全栈 Java 开发人员，Karsten Silz 在欧洲和美国工作了23年。2004年，他在美国合伙创立了一家提供软件产品的初创公司。Karsten领导了13年的产品开发，并在公司成功出售后离开。自2017年以来，他一直在德国和英国做承包商（Spring Boot、Angular、Flutter）。2020年，他作为CTO共同创立了SaaS初创公司“Your Home in Good Hands”。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/06/project-leyden-delays-aot/\">Project Leyden Delays OpenJDK AOT Compiler, Optimizes JIT Compiler Instead</a>\"</p>",
    "publish_time": "2022-07-13 09:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "对话金融科技“老兵”：数字化转型越急，失败概率越大",
    "url": "https://www.infoq.cn/article/zz3JtiokOUIrJXHl4wLE",
    "summary": "<p></p><blockquote>嘉宾介绍区海鹰，美国运通中国合资公司中国区总经理及首席增长官。此前曾先后担任平安科技首席产品官、平安云事业部总经理，是平安集团数字化转型的领军人物，其领导的ＡI团队曾经达到当时全球人脸识别最高准确度。在加入平安之前，区海鹰曾在麦肯锡任职4年，为微软、联想、华为、中移动等头部企业提供战略咨询服务，之后加入微软工作9年，是微软云Azure在中国的创始人之一，帮助诸多企业成功上云。</blockquote><p></p><p></p><p>在风云变幻的技术潮中，总有人能有精准地踏浪前行。</p><p></p><p>2007年，区海鹰离开任职了4年的麦肯锡，进入微软工作了9年——那段时间，恰逢<a href=\"https://www.infoq.cn/article/PFNc5TVyFlLR5Fr8NsBo\">云计算</a>\"从无到有，海内外云市场格局初步形成，而他则成了微软云Azure最初进入中国的关键参与者；2016年，区海鹰加入平安科技——彼时，国内的云计算已经进入应用期，企业上云进程加快，行业云初见苗头，他主导推动了平安科技产品从对内赋能转向对外输出；2020年，区海鹰进入平安集团联营公司金融壹账通——那一年，我国<a href=\"https://xie.infoq.cn/article/effe0c4991d7a4d7bf5f9018e\">金融科技</a>\"开始从战略部署走向广泛落地，中台也从概念普及阶段进入实际应用阶段，而他负责的Gamma平台基于的正是中台理念，面向的是金融行业的数字化改造。</p><p></p><p>十数年来，区海鹰个人从业经历的几次转折都与技术发展的关键节拍重合，这些重合让他借浪起、见水阔，成为了云计算、金融科技、<a href=\"https://xie.infoq.cn/article/ee7e78b48228fa627ada8762e\">中台</a>\"等各类技术从萌芽到发展，再到落地应用的亲历者。他既参与了平安从传统金融机构到金融科技公司的“蜕变史”，同样，也见证了许多银行、保险、证券等金融企业在数字化转型中的成与败。</p><p></p><p>以下内容根据InfoQ与区海鹰的对话编辑整理：</p><p></p><h1>金融行业变革“变在哪”？</h1><p></p><p></p><p>InfoQ：从微软云到平安云、金融壹账通再到美国运通，您接触和服务了大量的金融机构。以您的视角来看，近些年来金融行业经历了哪些变革？</p><p></p><p>区海鹰：最直观的是大量金融业务从线下转到了线上，而要在线处理大量业务就需要借助技术。所以，科技在金融机构的定位就发生了改变。以前在金融公司，IT是一个大后台，现在金融科技已经从后台迈向中台再延续到前台，成为业务增长的引擎之一。</p><p></p><p>InfoQ：很多企业在这个过程中会没有方向，金融机构该怎么判断自己要不要变，以及要变什么？</p><p></p><p>区海鹰：任何转型核心驱动还是业务。金融业务的转型主要在于两个维度：一个是产品跟服务的定义，另一个是获客及服务客户的生态和渠道建设。</p><p></p><p>举例来说，以前客户到线下网点，柜台服务人员就可以顺带推荐一些其它产品，但现在大部分人都不去网点了，金融的获客及销售体系就要和生态合作伙伴去对接——比如腾讯、阿里、抖音、美团等等这些大流量平台——你要能从他们的海量的用户流量中精准找到自己的客户群体，然后再匹配他们的需求提供金融服务产品。</p><p></p><p>InfoQ：所以，是业务对技术提出了新的需求。</p><p></p><p>区海鹰：没错，这也是当年平安科技这家公司诞生的原因。大概在2005年到2010年，平安集团做了一个后援集中共享服务*注【1】的项目，把整个集团下的三十几家子公司，全都整合到平台上实现了大集中，而这个项目后来就演变出了平安科技。</p><p></p><p>在这之前，平安集团旗下每个子公司都有自己的科技板块，每个板块又都有不同的IT架构和IT系统，这些系统都基于强组合性去做设计，所以只能支持几个最基本的流程，如果想要做一些调整需要花很长的时间和精力做改动。</p><p></p><p>平安整合这些科技板块的核心思路，是把整个IT架构从过去非常垂直的设计，调整为扁平化、平台化的架构。以前的IT架构的都是基于ERP、CRM这些大系统，以及数据库这样很大的功能板块去做定义的，但现在不一样了，会按照大数据平台、开发应用平台、云基础平台的维度来划分。</p><p></p><p>InfoQ：这种平台式的架构设计有什么好处？</p><p></p><p>区海鹰：首先，可以省去在数据处理中的很多麻烦。平台化之后，从数据的录入、检测到最后的存储各个方面都形成了一个统一标准，这会简化数据清洗、数据对接等等过去非常繁琐的工作；</p><p></p><p>其次，可以提高开发的速度和灵活性。以前企业开发的都是非常大的系统，一个系统支持很多业务，不仅开发周期长，而且灵活性也比较差，如果基于平台，不同系统应用的技术开发标准就是统一的，开发人员可以在上面进行模块化开发，灵活度更好，周期也更短。</p><p></p><p>这也是为什么当年平安集团在做了后援集中共享服务项目之后，市场竞争力和市场占有率会明显提升的原因。</p><p></p><h1>金融行业转型“怎么转”？</h1><p></p><p></p><p>InfoQ：大家面对的外部变化可能类似，但每个企业的具体情况又都是不一样的，金融企业如何去考虑转型这件事？有没有通用的方法论？</p><p></p><p>区海鹰：一个关键的问题是，企业到底有没有搞清楚自己转型的目的是什么。比如十几年前很多企业做的互联网项目都失败了，原因就是他们并没有搞清楚自己为什么要做互联网。他们不是因为业务的发展需要通过互联网来改变获客方式，只是因为别人都在做自己就去做。所以，他们砸了很多钱，可能就做一个网站，做完之后又没有对价值链和供应链做对应的调整。</p><p></p><p>对应到<a href=\"https://www.infoq.cn/article/liUFUdOgUE24jOKOllBZ\">数字化转型</a>\"这件事，它带来的转变甚至要比当年的互联网更加深入，它基于的是用户的使用习惯、体验，需要企业从客户角度出发，重新梳理自己的产品设计、服务设计等等。</p><p></p><p>战略制定</p><p></p><p>InfoQ：这背后其实需要一套战略作为指导，那企业如何才能制定符合自己情况的战略？</p><p></p><p>区海鹰：首先，跟上技术的更新趋势这是非常重要的一个考虑因素。现在技术发展非常快，差不多每十年就会有一个大的技术升级，企业需要每隔一段时间结合技术趋势对战略进行动态迭代，比如回顾一下过去做得好和不好的地方，再看看下一阶段如何通过技术创造新的机会点。当然，战略的更新也不能特别频繁，通常每5年去做一次就足够了。</p><p></p><p>其次，不要只依赖于战略部门，要让各种不同角色都参与其中。包括技术、业务等部门的核心管理人员，甚至有时候还需要引入外脑，他们看待行业的角度往往会更加全面和客观。在这个过程中，有一点比较重要，就是企业要去建立一个组织架构来支持数字化转型，这个组织架构主要就是包括业务、创新技术跟传统IT这三部分人员。就像前面说的，<a href=\"https://www.infoq.cn/article/dXiIvgGYTxBreaMAHtBV\">数字化</a>\"转型是业务驱动的转型，然后才是创新，去寻找新的机遇和技术创新。</p><p></p><p>另外，制定战略之前一定要先做业务诊断。虽然一般来说顶级咨询公司的方法论可以满足企业70%左右的通用需求，但是另外30%就需要企业根据自己的现状去做调整，一定要找到问题的关键点在哪，才能有针对性地去解决。</p><p></p><p>平台整合</p><p></p><p>InfoQ：那么基于全新的战略和平台化的思路，怎么把新的架构搭起来？它有哪些关键的部分？</p><p></p><p>区海鹰：首先，是硬件的基础架构，也就是IaaS层，包括机房、网络、存储、服务器、终端设备等等，这些资源都可以云化；第二层是PaaS，包括数据、区块链、应用开发、AI等平台式服务；第三层是SaaS，包括从研发管理、质量管理到产品认证等终端的应用。另外，在这三层基础上还需要一个独立运营、贯穿期间的安全模块和系统运营平台，主要是监控所有系统的安全性和稳定性。</p><p></p><p>InfoQ：但是，要把原来烟囱式的系统整合到统一平台上并不容易，企业具体要怎么做呢？</p><p></p><p>区海鹰：这件事情没有捷径，需要企业投入大量资源。但是它的方法论是有的，借鉴平安集团科技大转型的方法：</p><p></p><p>第一步，先定义一个云架构，包括对底层的数据库、网络、存储等等，用云的方式重新组建，就像建一个摩天大厦，这部分就是地基。这个过程同样要遵循以业务为导向，如果业务对旧系统没有强需求的改变，就可以先把这部分保留在原有架构上，建一个“围墙”把它们独立围起来作为一个“黑盒子”去处理，然后数据可以导入到统一的<a href=\"https://www.infoq.cn/article/Jx18F2HPWBlh4XBtMp1F\">大数据平台</a>\"；反之，如果业务急需新的系统做支持，涉及比较大的调整，就可以选择用云的方式部署新的能力。</p><p></p><p>InfoQ：需求的紧迫性判断标准是什么？</p><p></p><p>区海鹰：对于金融机构来说，一般和客户通过互联网、移动互联网直接连接的新业务，使用频率高、响应速度要求快，就会需要上云；如果是面向监管或者内部员工管理的系统，可能上云的迫切性就没有那么大。所以，如果现有架构已经满足需求的，就没有必要为改而改。</p><p></p><p>InfoQ：这个“地基”搭好后做什么？</p><p></p><p>区海鹰：第二步，重新定义企业科技标准，包括数据、研发管理、IT安全等等，都要基于新的架构、按照新的需求重新定义。其实现在很多第三方的大数据平台和开发平台都已经自带非常成熟的标准体系，它们大概可以满足企业70-80%的需求，剩下的需要企业结合行业特性再做定义。举例来说，用户的个人标签，其中性别、年龄这些基础数据都是有一套非常体系化的标准的，其它的例如在金融行业，用户的交易数据等等，就要结合具体业务，匹配行业标准来制定。</p><p></p><p>第三步，根据最新的标准，对已有的数据进行清洗、梳理、迁移和整合，构建大数据仓库及平台框架。这里面，最重要的一个工作就是<a href=\"https://www.infoq.cn/article/more-time-of-big-data-mining-is-used-to-clean-the-data\">数据清洗</a>\"，因为很多时候企业在不同系统做了数据抽取后，会发现很多冲突的地方，这时候就要判断哪个源头的数据更准确，怎么互补。如果数据不准确，那不如没有。另外，这也是挖掘数据价值的一个过程，很多企业拥有大量数据，但里面没有什么特别的价值，而怎么去衡量，首先就要先把质量高的数据找出来。所以，企业一定要真的花时间、花精力去做这件事，这应该是数据治理中人力成本投入最大的一部分。</p><p></p><p>InfoQ：平安当年是怎么做数据清洗的？</p><p></p><p>区海鹰：当年他们专门成立了一个大数据团队，大概有200-300人，其中，除了数据平台的搭建，数据清洗就是他们最重要的工作。当然，也有一些体量特别大的企业，会把这部分工作交给第三方的数据治理公司，用他们的方法论和技术工具做数据清洗，但实际上，仅仅靠工具是很难做好这件事的，因为他还必须具备一定行业经验，才能判断数据的质量和价值。</p><p></p><p>InfoQ：顶层的应用怎么办？需不需要都上云？</p><p></p><p>区海鹰：应用迁移是一个长期的过程，一家金融机构可能拥有成百上千个不同的应用，如果一下子都做转移可能会影响业务稳定，所以，最开始企业可能还要设计一些通路去继续支持原有的应用系统，有些应用其实还可以用，可能只是功能不足，所以就按照它的生命周期，等它到了一个生命周期的结束时再把它剔除出去，而新的应用就可以完全基于新的架构去做开发。</p><p></p><p>技术落地</p><p></p><p>InfoQ：在这个过程中，虽然很多技术都比较成熟了，但是很多企业表示在具体落地过程中还有很多“坑”，您怎么看？怎么避免或者克服？</p><p></p><p>区海鹰：这是普遍存在的问题，企业可以从几个维度入手：一方面是要按部就班，不要想着把饭一口气吃完，因为数字化转型应该分阶段进行，它是一个长跑，企业应该把这当做马拉松，首先把规划做起来，然后基于规划，按照业务的优先级，再一步一步地把方案落实下去；第二方面是去学习别人的经历跟经验，比如平安的数字化转型，很多人会把它当作案例参考；第三方面其实还是像前面所说的，要有专门的组织架构去做支撑，要有业务、技术、传统IT的不同人员参与进来。</p><p></p><p>有些时候，企业越着急越想快，反而失败的几率反而可能更大。所以，企业必须制定一个长期战略，而不是一个短期的目标，当然这个过程中如果有成功的行业经验借鉴最好，如果没有的话，就要自己摸着石头过河，慢慢把自己的路给蹚出来。</p><p></p><p>InfoQ：那企业做技术选型的时候要考虑什么因素？比如，公有云和私有云怎么选？</p><p></p><p>区海鹰：如果从成本的角度来考虑，肯定是选便宜的，比如公有云肯定比私有云便宜。但是，尤其是对金融机构来说，监管是不允许把数据放在企业外部的，这就意味着也要搭建自己的私有云。这就是为什么现在大家都倾向于去使用<a href=\"https://mp.weixin.qq.com/s?__biz=MzIzNjUxMzk2NQ==&amp;mid=2247510178&amp;idx=2&amp;sn=affba849acc16d361aaa613097ec14b2&amp;chksm=e8d45760dfa3de76c987708ee911cd40382ad4e1b113551eda0443e0fbaa32162afe5bc6dc92&amp;scene=27#wechat_redirect\">混合云</a>\"的架构。</p><p></p><p>那么，二者怎么结合呢。主要是从企业的业务整体以及监管的要求出发，一般来说，不涉及很多私人信息的数据就可以放在公有云上，而如果是一些敏感的业务数据、客户数据，就要放到私有云环境。</p><p></p><p>InfoQ：技术提供商又怎么选？</p><p></p><p>区海鹰：我认为最重要的是看他的行业经验，因为不同厂商在不同行业的积累是不同的，而行业经验很多时候甚至比技术本身更为重要。如果单从技术出发来做选型，你就会发现很多时候技术很难落地，无法解决真正的业务困扰，这不是纯粹技术提供方可以搞定的；</p><p></p><p>第二点，可能还要考虑监管的要求，也就是技术产品本身能不能帮助企业满足监管需要；</p><p></p><p>第三点，还要看行业大的发展方向和趋势，也就是技术产品能不能覆盖到这些行业标准。</p><p></p><p>只有基于这些不同的考量，多维度地去做比较和选型，才能找到比较合适的产品。</p><p></p><p>InfoQ：要把技术价值转变为业务价值，还会存在哪些阻力？怎么解决这些问题？</p><p></p><p>区海鹰：其实对于金融机构来说，钱可能不是最主要的问题，更重要的是时间的投入，金融机构往往希望对市场做出更快的响应。所以，除了通过在技术架构层面实现平台化，缩短应用开发的时间之外，还可以把业务单位引入进来一起做决策，这样就可以缩短决策的周期。</p><p></p><p>拿平安集团来说，它的业务跟科技其实是一个联合团队，这个联合团队会一起协作制定具体的业务指标，相当于把双方的利益连接在一起，让技术也能更了解业务真正需要的是什么，并且能更快地去实现。</p><p></p><p>以前技术部门部署了一个大型系统，对业务到底有什么帮助，大家都很难说得清楚。但现在通过双方的交互，这个问题就简单化了。比如，业务部门说自己要加强跟短视频平台的合作，那么只要在内部把需求和目标结果定义好，双方达成指标的共识，就可以很快梳理出来技术部门到底要做一些什么投入、要在什么时间完成功能的迭代。业务部门参与其中，也可以很快感受到新应用、新功能的投入产出是不是符合需求，更快进行应用的迭代更新。</p><p></p><h1>强监管时代下“怎么办”？</h1><p></p><p></p><p>InfoQ：对于整个金融行业来说，强监管是近几年面对的一个比较大的变化和挑战。在这个背景下，金融机构怎么去平衡业务创新和监管之间关系？</p><p></p><p>区海鹰：不仅是政府层面的强监管，另一个维度是用户对信息保护的意识也在增强。</p><p></p><p>首先，监管机构希望所有金融交易都能更加透明，以确保整个金融体系的稳定，这里面会涉及大量的数据，对于金融机构来说，要考虑提供什么数据给到监管机构，对于监管机构来说也是个挑战，因为他们要判别应该管什么、不应该管什么，管太松怕数据滥用，管太紧又会限制创新；</p><p></p><p>其次，虽然用户数据可以帮助金融机构给到客户比较贴心的服务，但从另外一个维度来说，如果金融机构过度使用甚至泄露用户数据，不仅不符合监管要求，带来的体验也很不好。</p><p></p><p>其实这对平安来说，曾经是个很大的挑战。因为以前平安做得最好的一点就是交叉销售，比如银行的客服，可以根据相关的数据，精准地向客户销售其它的保险、理财产品。但在新的监管规定下，这件事情的难度就增加了，比如，在把保险产品推给银行客户的时候，必须要向客户征求书面同意等等，背后也会给对应的业务系统带来很大变化。对此，平安投入了大量的资源重整了大数据平台，对集团几十家子公司不同的数据的交互使用，做了全新的界定和划分。</p><p></p><p>InfoQ：取舍的点在哪里？具体怎么把握？</p><p></p><p>区海鹰：要提供更好的服务，但是又不能把数据隐私泄露出来，这条线其实是很难定义的。一方面，需要行业一起去校验，磨合出一个新的标准出来；另一方面，也需要政策提供更多的支持。</p><p></p><p>当然，技术在其中肯定是一个非常重要的一个手段，我估计如果没有针对性的技术，很多事情是无法实现的。比如监管科技*注【2】，就是专门围绕监管要求而提出的一种技术；再比如隐私计算*注【3】，它的作用就是在保护<a href=\"https://xie.infoq.cn/article/6649e4b95b15354ac1e49d5c2\">数据隐私</a>\"的前提下，解决数据流通、数据应用等数据服务问题。</p><p></p><p>除此之外，在金融机构的内部，也可以根据不同的业务需求和合规标准，给每个数据使用者设定不同的权限，同时，引入联邦学习、<a href=\"https://xie.infoq.cn/article/1b50b54088d3e15af549156e9\">加密算法</a>\"等技术，确保数据使用的合规性，更好地保护用户隐私，确保交易是合法合规的。举一个例子，金融机构在对企业做交易认证的时候，并不一定要完全掌握实际的交易细节，只需要通过区块链技术，基于加密计算和加密认证，就能判断交易的真实性，从而评估是否提供相关的交易贷款。</p><p></p><p>而对于数据的处理，我们还可以通过对数据做标签化来规避隐私风险。拿征信场景来举例，其中涉及了大量的个人隐私数据，在打标签的过程中，其实并不需要精确地知道某一个人的年龄、工作、收入等等，只要知道年龄范围、工作类型、收入区间就可以做基础分析，拿到这个人的信用积分。</p><p></p><h1>“金融+科技的杠杆作用会持续加大”</h1><p></p><p></p><p>InfoQ：从事金融科技的这些年，您最大的感触是什么？</p><p></p><p>区海鹰：这几十年科技的变化是很大的，从早期服务器和终端这样的两层架构，到现在基于云的多层架构，短短四十来年，就发生了跨代的变更。也就是说，科技在快速创新和发展，所以，不论你是什么角色，必须要不停地学习，不停地进步，不停地更新对新事物的理解，否则很快就会被时代淘汰、跟时代脱节。</p><p></p><p>其次，行业经验也是很宝贵的。就像刚才举的例子，特别是在企业数字化转型过程中，它不是纯靠技术就能够完成的，需要结合业务需求。这时候，只有足够的行业经验积累，才能更好地判断用什么技术方式、按照什么样的节奏去做转型，一定不能贪快，要按照企业可行的节奏往前走。</p><p></p><p>InfoQ：那么，在未来数字经济背景下，您认为金融科技如何更好地服务于客户？</p><p></p><p>区海鹰：在数字经济背景下，科技扮演的是一个持续帮助企业实现降本增效和业务场景创新的角色。比如说数字资产交易，其中会涉及到一个非常重要的问题——就是确权。怎么确定数字资产的归属、怎么通过交易平台确定它的价值、怎么衡量它的定价等等，其中需要很多新的科技去做支撑。</p><p></p><p>对于金融行业来说也是如此，它也需要通过新的服务模式，迎合新的时代需求、场景需求。比如，未来线上线下的体验一定是相结合的，两个渠道如何打通，我觉得关键的一点是以客户为中心去做设计，比如，有什么服务是必须用线下模式去做的，有哪些可以通过线上满足他的需求，这需要根据不同场景去做设计，没有固定模版。我相信只要把客户放在第一位，相应设计出来的服务方式和方法，客户最终都会接受。</p><p></p><p>我们如果回看整个人类社会的发展，就会发现金融业有很强的杠杆效应，而科技也是这样，一个突破性的科技创新，最终可以撬动很大的业务提升，甚至撬动一个新的市场发展机会。我认为在未来的数字经济时代，金融加科技这两个领域的杠杆作用还会更大。从企业的角度来说，必须去接纳数字化的发展维度，更好地结合科技加金融，从而驱动业务创新。</p><p></p><p></p><blockquote>注：【1】平安集团后援集中共享服务：二十一世纪初，平安集团确定了实施后援集中的战略目标，引入了共享服务理念，其主要是对企业内部各独立公司的后台服务职能进行集中整合，建立统一的后台服务共享中心，以实现组织、人员、信息和系统等方面的集中运营管理，从而达到标准统一、成本节约、效率提升、风险可控的目的。【2】监管科技：英国金融市场行为监管局最早使用监管科技（RegTech）一词并将其定义为——解决监管面临的困难，推动各类机构满足合规要求的新兴技术。它具有四个关键特征，即组织数据集的敏捷性、配置和生成报告的速度、为缩短解决方案的启动和运行时限的集成能力、大数据分析。我国在2014年首次提出了监管科技相关的工作，并且在2017年，中国人民银行特别成立了金融科技委员会，旨在加强金融科技工作的研究规划和统筹协调，首次明确要强化监管科技应用实践。【3】隐私计算：2016 年发布的《隐私计算研究范畴及发展趋势》正式提出“隐私计算”一词，并将隐私计算定义为：“面向隐私信息全生命周期保护的计算理论和方法，是隐私信息的所有权、管理权和使用权分离时隐私度量、隐私泄漏代价、隐私保护与隐私分析复杂性的可计算模型与公理化系统。</blockquote><p></p>",
    "publish_time": "2022-07-13 12:03:54",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Observability 之深度讲解采样 Sampling 场景和落地案例（上）",
    "url": "https://www.infoq.cn/article/doKB90ttLE0kRDljFeVJ",
    "summary": "<p></p><h1>采样的知识背景</h1><p></p><p></p><h2>回顾可观测系统解决的主要问题</h2><p></p><p></p><p>系统的调用链信息Traces、Metrics、Logs 串联后，开发者基于调用链进行系统行为分析。</p><p>常见的使用场景可以分为以下几类：</p><p></p><h3>异常检测</h3><p></p><p></p><p>异常检测指的是定位和排查一些引发系统异常行为的请求，通常这些请求的出现频率很低。尽管异常事件被采样的概率很低，但它的信息熵大，能给到开发者更多细节信息。这些细节可能体现在：慢请求、慢查询、循环调用未设上限、存在错误级别日志、未覆盖测试的问题逻辑分支等等。如果调用链追踪系统能主动为开发者发现异常问题，将使得风险隐患提前暴露，并被扼杀在摇篮中。</p><p></p><h3>健康度分析</h3><p></p><p></p><p>健康度分析指的是分析业务系统健康度，分析粒度可能包括单个接口、单个服务、多个服务等等；分析范围可能是单个请求或多个请求；分析角度可能包括埋点指标、依赖关系、流量大小等等。分析反映系统主要流程的健康状态，一些配置的改动，如存储节点修改、客户端日志上报频率，都可能反馈到系统稳态。健康度关键点：</p><p></p><h5>1. 可用性</h5><p></p><p></p><p>首先，将业务系统的运行状态分为“可用”和“不可用”两个状态。若业务系统或其支撑服务不可用，则健康度直接 0 分甚至负分。</p><p></p><p>其次，业务系统关联的网络、中间件、数据库的运维状态分为“可用”和“不可用”两个状态。如存在“不可用”状态，则根据关键点重要等级权重计算业务系统健康度。</p><p></p><p>再次，业务系统底层的硬件设备，也存在“可用”和“不可用”两个状态，考虑到当前服务均使用高可用模式，所以会存在服务“可用”但支持的硬件出现“不可用”情况。</p><p></p><h5>2. 性能</h5><p></p><p></p><p>性能指标更关注于业务系统，包含：响应时间（可以再细分到：响应时间（宏观）；加载速度（微观，各个服务）），可以通过控制性能健康度权重值调节业务系统健康度。</p><p></p><p>稳态性能分析：定位和排查系统稳态中的性能问题，这些问题的起因通常与异常检测类似，只是其影响尚不足以触发报警。</p><p></p><p>服务依赖分析：构建接口级别的依赖关系图，节点通常为接口或服务，边通常为接口或服务的调用关系，边的权重则为流量。构建方式可以分为离线构建和在线构建，对应的就是静态关系图和动态关系图。这些信息可以以基础 API 的方式提供给上游应用使用，如 APM。</p><p></p><h3>资源归因</h3><p></p><p></p><p>资源归因解答的主要问题是：“谁该为我的服务成本买单？” 它需要将资源消耗或占用与请求方关联，资源归因也是成本分析的基础。</p><p></p><h3>负载建模</h3><p></p><p></p><p>负载建模主要指分析和推测系统的行为表现，该场景解答的问题通常可以表述为 “如果出现 XX 变化，系统整体或关键链路状态会发生什么改变” 。</p><p></p><p>常见应用如容量预估、全链路压测、混沌测试等等。</p><p></p><h2>采样角色在调用链系统架构的位置</h2><p></p><p></p><p>从调用链系统架构设计看，采样处理几乎每个阶段都在。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/10/1015f1db22b7bc6bebdaeb1b551ac1d8.png\" /></p><p></p><h3>采样</h3><p></p><p></p><p>采样分成两种部署模式：客户端采样、服务端采样，有的系统客户端、服务器同时采样。</p><p></p><p>实践中无论从计算和存储资源成本消耗上分析，还是从具体使用场景出发，都不一定需要收集所有埋点数据。因此许多调用链追踪系统会要求按照一定的策略上报数据，目的是取得成本与收益之间的平衡，提高投入产出比。</p><p></p><h3>上报</h3><p></p><p></p><p>数据可以从服务实例中直接发送到处理中心，或经由同一宿主机上的 agent 代理上报。使用 agent 上报的好处之一在于一些计算操作可以在 agent 中统一处理，一些逻辑如压缩、过滤、配置变更等可以集中到 agent 中实现，服务只需要实现很薄的一层埋点、采样逻辑即可，这也能使得调用链追踪方案对业务服务本身的影响降到最低；使用 agent 上报的另一好处是数据处理服务的发现机制对服务本身透明。因此在每台宿主机上部署 agent 是许多调用链追踪系统的推荐部署方案。</p><p></p><p>Kubernetes，Istio 上报也是类似 Agent 原理：SideCar、DaemonSet的模式，思路类似。</p><p></p><h3>收集中心</h3><p></p><p></p><p>调用链数据上报到中心节点，通常称后者为收集器 (Collector)，由收集器完成必要的后处理，如数据过滤、数据标记、尾部采样、数据建模等等，最后批量写到不同的存储服务中，并建立必要的索引。</p><p></p><h3>存储/索引、可扩展性</h3><p></p><p></p><p>调用链追踪系统需要处理的数据与全站的请求总量正相关。假如全站所有请求平均要经过 10 个服务处理，那么调用链追踪系统将需要承担全站请求总量 10 倍压力，如果不做任何采样，一方面系统存储压力成指数增长，服务器成本非常高。另一方面链路系统其架构设计上要求具备可扩展性。</p><p></p><h2>采样的常见场景</h2><p></p><p></p><p>分布式系统，微服务系统存在调用链比较深情况，让一个Trace产生指数的比例Span，链路数据量巨大。</p><p></p><p>服务TPS很高，高并发的情况，全量采集给公司系统整体带来两方面压力：</p><p></p><p>因数据上报造成的每个业务服务的网络 I/O 压力因数据采集、分析造成的调用链追踪服务的计算和存储压力。</p><p></p><p>采样主要为了干三件事：</p><p></p><p>节约服务器资源，数据存储成本；高并发带来链路采集的性能瓶颈，讲请求量指数级降低可以指数级减少性能问题困难度；异常检测、链路故障排查更聚焦，采样不只是减小传送，有可能甚至增加采样样本；</p><p></p><h3>采样的好处</h3><p></p><p></p><p>这里，我举两个案例给大家一个参考，说实在，这也只是我平时随便留意的一小部分。</p><p></p><h4>伴鱼案例</h4><p></p><p></p><blockquote>2020 年，我们不断收到业务研发的反馈：能不能全量采集 trace？这促使我们开始重新思考如何改进调用链追踪系统。我们做了一个简单的容量预估：目前 Jaeger 每天写入 ES 的数据量接近 100GB/天，如果要全量采集 trace 数据，保守假设平均每个 HTTP API 服务的总 QPS 为 100，那么完整存下全量数据需要 10TB/天；乐观假设 100 名服务器研发每人每天查看 1 条 trace，每条 trace 的平均大小为 1KB，则整体信噪比千万分之一。可以看出，这件事情本身的 ROI 很低，考虑到未来业务会持续增长，存储这些数据的价值也会继续降低，因此全量采集的方案被放弃。退一步想：全量采集真的是本质需求吗？实际上并非如此，我们想要的其实是「有意思」的 trace 全采，「没意思」的 trace 不采。</blockquote><p></p><p></p><h4>货拉拉</h4><p></p><p></p><blockquote>2.0架构虽然能满足高吞吐量，但是也存在存储成本浪费的问题。其实从实践经验看，我们会发现80~90%的Trace数据都是无价值的、无意义的数据，或者说是用户不关心的。那么用户关心哪些数据呢？关心链路中错、慢的请求以及部分核心服务的请求。那么我们是不是可以通过某些方式，把这些有价值的数据给过滤采样出来从而降低整体存储成本？在这个背景下，我们进行3.0的改造，实现了差异化的完成链路采样，保证1H以内的数据全量保存，我定义它为热数据，而一小时以外的数据，只保留错、慢、核心服务请求Trace，定义为冷数据，这样就将整体的存储成本降低了60%。原文链接： <a href=\"https://www.sohu.com/a/531709613_411876\">https://www.sohu.com/a/531709613_411876</a>\"</blockquote><p></p><p></p><h4>字节跳动</h4><p></p><p></p><blockquote>由于字节整体线上流量非常大，微服务数目众多，不同微服务的性能敏感度、成本敏感度和数据需求各有不同，例如有些服务涉及敏感数据，必须有非常完整的追踪数据；有些服务性能高度敏感，需要优先控制采样数最小化 Overhead；测试泳道、小流量灰度或者线上问题追查等场景会需要不同的采样策略；常规流量和发生异常的流量也需要不同的采样策略。原文链接：<a href=\"https://blog.csdn.net/ByteDanceTech/article/details/122076591\">https://blog.csdn.net/ByteDanceTech/article/details/122076591</a>\"</blockquote><p></p><p></p><h2>采样的主要方案</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/97/97cffbc53b88e8b0b7c1c874cd249077.png\" /></p><p></p><p>&nbsp;主要分三类：</p><p></p><p>头部连贯采样：Head-based coherent sampling，从图中，采样决策 Sampling decision 从请求一开始做出了哪些初始节点需要采样的决定。头部采样是没有做预判的逻辑，从一开始选择性采集少量数据。但是，如果错误发生在没采集的节点，它无法采集到异常链路；单元采样：Unitary sampling；尾部连贯采样：Tail-based coherent sampling，尾部采样，是Agent 在采集完整个服务链路，准备将采集数据上报时，根据一定的策略做选择性上报。比如下面的过程。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5a/5a24779c0bb3bc6738bbbac346ed5fd1.png\" /></p><p></p><p>某个请求出问题开发者需要查看完整调用链信息，因此需要连贯采样。又由于问题请求的发生是小概率事件，只能通过尾部连贯采样来保证数据都能被捕获。</p><p></p><p>所以，业界普遍都选择尾部采样的方式。</p><p></p><h2>主流开源和商业系统的采样实现</h2><p></p><p></p><h3>SkyWalking</h3><p></p><p></p><p>它采样机制主要在 Agent 端支持 Head-based Sampling：能够支持简单的采样百分比 Sampling Rate，允许 forceSampleErrorSegment：错误链路强制采样。</p><p></p><p>Skywalking 做了Slow SQL Sampling：分布式系统中，数据库非常常用，往往也是性能问题常出的中间件。</p><p></p><p>对SQL 慢查询的采样在链路调用中一个重要的点，Skywalking 也做了支持。</p><p></p><blockquote><a href=\"https://skywalking.apache.org/docs/main/v8.5.0/en/setup/backend/slow-db-statement/\">https://skywalking.apache.org/docs/main/v8.5.0/en/setup/backend/slow-db-statement/</a>\"</blockquote><p></p><p></p><h3>Jaeger</h3><p></p><p>采样策略: 头部连贯采样，目前 Jaeger 支持三种采样方式：</p><p></p><p>Const：要么全采样，要么不采样；Probabilistic：按固定概率采样；Rate Limiting：限流采样，即保证每个进程每隔一段时间最多采 k 个；</p><p></p><p>除了Agent 配置外，Jaeger 还支持远程动态调整采样方式，但调整的选择范围仍然必须为上面三种之一。为了防止一些调用量小的请求因为出现概率低而无法获得调用链信息，Jaeger 团队也提出了适应性采样 (Adaptive Sampling) ，但这个提议从 2017 年至今仍然未有推进。</p><p></p><p>限流采样适用范围有限，比如伴鱼案例：伴鱼的生产环境中使用的是限流采样策略：每个进程每秒最多采 1 条 trace。这种策略虽然很节省资源，但其缺点在一次次线上问题排查中逐渐暴露：一个进程中包含多个接口：不论按固定概率采样还是限流采样，都会导致小流量接口一直采集不到调用链数据而饿死 (starving)线上服务出错是小概率事件，导致出错的请求被采中的概率更小，就导致采到的调用链信息量不大，引发问题的调用链却丢失的问题，可以参考<a href=\"https://www.infoq.cn/article/2GAo0XPw37ArecbYcPXl\">这篇内容</a>\"。</p><p></p><h3>OpenTelemetry</h3><p></p><p></p><h5>支持尾部连贯采样</h5><p></p><p></p><p>OpenTelemetry 收集器引入尾部连贯采样的支持。</p><p></p><blockquote><a href=\"https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/tailsamplingprocessor\">https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/tailsamplingprocessor</a>\"</blockquote><p></p><p></p><p>OpenTelemetry 尾部连贯采样提供的策略也是非常丰富，下面常用一些策略：</p><p>常见的百分比采样 Latency: Sample based on the duration of the trace.基于Metric指标范围的采样过滤：在你只想采集一些超过监控阈值的异常链路时候很有用</p><p>numeric_attribute: Sample based on number attributesprobabilistic: Sample a percentage of traces. Read a comparison with the Probabilistic Sampling Processor.</p><p>专门提供给API状态码定义采样，这个场景：异常特殊采样</p><p>status_code: Sample based upon the status code (OK, ERROR or UNSET)</p><p>基于标签匹配的采样过滤，这个场景：URL 采样过滤，某些特定自定义监控采样过滤，非常灵活，给专门的应用服务和节点打标签的采样：很多业务监控会用上</p><p>string_attribute: Sample based on string attributes value matches, both exact and regex value matches are supportedrate_limiting: Sample based on rate</p><p>限流采样: 不详细说了</p><p></p><p>OpenTelemetry 还支持多种采样规则混合搭配方式：它把一种策略叫做 Policy。你可以根据自身系统，定制化一套完整的采样方案。比如下面，是Collector 收集中心定义的一套完整的采集方案：</p><p></p><p><code lang=\"null\">processors:\n  tail_sampling:\n    decision_wait: 10s\n    num_traces: 100\n    expected_new_traces_per_sec: 10\n    policies:\n      [\n          {\n            name: test-policy-2,\n            type: latency,\n            latency: {threshold_ms: 5000}\n          },\n          {\n            name: test-policy-3,\n            type: numeric_attribute,\n            numeric_attribute: {key: key1, min_value: 50, max_value: 100}\n          },\n          {\n            name: test-policy-4,\n            type: probabilistic,\n            probabilistic: {sampling_percentage: 10}\n          },\n          {\n            name: test-policy-5,\n            type: status_code,\n            status_code: {status_codes: [ERROR, UNSET]}\n          },\n          {\n            name: test-policy-6,\n            type: string_attribute,\n            string_attribute: {key: key2, values: [value1, value2]}\n          },\n          {\n            name: test-policy-7,\n            type: string_attribute,\n            string_attribute: {key: key2, values: [value1, val*], enabled_regex_matching: true, cache_max_size: 10}\n          }\n        ]</code></p><p></p><h4>OpenTelemetry 尾部采样实例</h4><p></p><p></p><p>我们做一个简单异常链路采集的例子：Github 我放上了案例，大家可以自行下载体验</p><p></p><blockquote><a href=\"https://github.com/laziobird/otel-collector-java/\">https://github.com/laziobird/otel-collector-java/</a>\"</blockquote><p></p><p>我们看看对于的效果，在没有开启异常采样前：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0e/0e541fd6acc98a1f896ae8c3fe6f7554.png\" /></p><p></p><p>&nbsp;所有链路都采集上报到Jaeger 做链路数据分析，当我们开启了一个采集策略配置，对应 otel-collector-config.yaml 简单配置一个Policy：</p><p></p><p><code lang=\"null\">processors:\nbatch:\ntail_sampling:\npolicies:\n[\n  {\n    name: test-policy-5,\n    type: status_code,\n    status_code: {status_codes: [ERROR]}\n  }\n]\nservice:\nextensions: [pprof,health_check]\npipelines:\ntraces:\nreceivers: [otlp]\nprocessors: [tail_sampling]\nexporters: [jaeger]</code></p><p></p><p>看看加了异常 Sampling结果：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/36/3665cea6d28263ed8f6463ee948d682c.png\" /></p><p></p><p>看到了吧，只有异常链路被上报了！</p><p></p><h3>Datadog</h3><p></p><p></p><p>默认Agent 也有头部采样，同时支持尾部采样。</p><p></p><p>Datadog 做全链路追踪的可观测，同时支持了RUM、APM 前后端的采样。</p><p></p><blockquote><a href=\"https://docs.datadoghq.com/tracing/trace_ingestion/mechanisms/?tab=environmentvariables#head-based-sampling\">https://docs.datadoghq.com/tracing/trace_ingestion/mechanisms/?tab=environmentvariables#head-based-sampling</a>\"</blockquote><p></p><p></p><p>在 APM 侧，做了基于Tag尾部采样</p><p><a href=\"https://docs.datadoghq.com/serverless/distributed_tracing/\">https://docs.datadoghq.com/serverless/distributed_tracing/</a>\"</p><p>Tail-based sampling and fully customizable tag-based retention filters.</p><p></p><p>它做了一个采样 Trace 的权重等级，通过权重区分采样还是不采样。</p><p><code lang=\"null\">PRIORITY SAMPLING\nThe sampler can set the priority to the following values:\nDatadog::Tracing::Sampling::Ext::Priority::AUTO_REJECT: the sampler automatically decided to reject the trace.\nDatadog::Tracing::Sampling::Ext::Priority::AUTO_KEEP: the sampler automatically decided to keep the trace.</code></p><p></p><h4>染色采样</h4><p></p><p></p><p>刚才根据权重采样，是采样一种常见模式，我们可以归类染色采样的范畴：当我们针对特殊场景、服务进行针对性分析时，可以给他们打上特殊标签Tag 进行全量采集。</p><p></p><p>我们简单看看染色采样的案例：</p><p></p><p>腾讯云的自定义采样：</p><p></p><blockquote>介绍出处: <a href=\"https://cloud.tencent.com/document/product/1463/66104\">https://cloud.tencent.com/document/product/1463/66104</a>\"</blockquote><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d9/d988e503f0c5b5db50e7752eff539e79.png\" /></p><p></p><h2>采样模式的案例分享和简单讲解</h2><p></p><p></p><h3>尾部连贯采样VS头部连贯采样</h3><p></p><p></p><p>收钱吧一开始头部连贯采样，后面也是考虑尾部采样：</p><p></p><blockquote>由于我们目前采样的是头采样（Head-Based Sampling）方案，一旦在链路中间的服务发生抛出异常且这条链路没有被采样，那么就会出现有错误日志和报警，但链路追踪系统无法查询到这条链路的情况，这给开发排查问题带来很大的阻碍。</blockquote><p></p><p></p><p>伴鱼最早采用Jaeger，默认头部连贯采样的限流采样，后面开始使用OpenTelemetry一个原因，也是采样支持尾部采样：</p><p></p><blockquote>伴鱼的生产环境中使用的是限流采样策略：每个进程每秒最多采 1 条 trace。这种策略虽然很节省资源，但其缺点在一次次线上问题排查中逐渐暴露：一个进程中包含多个接口：不论按固定概率采样还是限流采样，都会导致小流量接口一直采集不到调用链数据而饿死 (starving)线上服务出错是小概率事件，导致出错的请求被采中的概率更小，就导致采到的调用链信息量不大，引发问题的调用链却丢失的问题</blockquote><p></p><p></p><p>字节跳动、货拉拉，OpenTelemetry 都有分享尾部采样案例，这里我不一一列举了。最后，还推荐 Oy LM Ericsson Ab 芬兰公司 (母公司爱立信）的核心开发 G KIBRIA SHUVO 分享尾部连贯采样的完整一本书介绍，里面也有OpenTelemetry 在尾部采样的应用实现。</p><p></p><blockquote>Tail Based Sampling Framework for Distributed Tracing Using Stream Processing</blockquote><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/99/99d27bdfd37ce18a8d561c19ef50f105.png\" /></p><p></p><p>英文原版下载链接</p><p></p><blockquote><a href=\"https://kth.diva-portal.org/smash/get/diva2:1621787/FULLTEXT01.pdf\">https://kth.diva-portal.org/smash/get/diva2:1621787/FULLTEXT01.pdf</a>\"</blockquote><p></p><p>&nbsp;</p>",
    "publish_time": "2022-07-13 14:23:42",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "比 Node.js 快三倍，新 JavaScript 运行时 Bun 火了",
    "url": "https://www.infoq.cn/article/m48tvaz8w2BbblIQKZZF",
    "summary": "<p>近日，前端工具链 Bun 项目的关注度颇高。<a href=\"https://bun.sh/\">Bun</a>\" 是像 Node 或 Deno 一样的现代 JavaScript 运行时，作者是&nbsp;Jarred Sumner &nbsp;，曾在 Stripe 和 Thiel Fellowship 工作。</p><p>&nbsp;</p><p>Bun 原生实现了数百个 Node.js 和 Web API，包括约 90% 的 Node-API 函数（本机模块）、fs、path、Buffer 等。而据其新推出的网站称，“从头开始构建，专注于三个方面”：</p><p>&nbsp;</p><p>快速开始（考虑到优势）。新的性能水平（扩展 JavaScriptCore，引擎）。作为一个伟大而完整的工具（捆绑器、转译器、包管理器）。</p><p>&nbsp;</p><p></p><blockquote>Bun 的目标是在浏览器之外运行世界上大多数 JavaScript，为您的未来基础架构带来性能和复杂性的增强，并通过更好、更简单的工具提高开发人员的生产力。</blockquote><p></p><p></p><h4>更好的性能表现</h4><p></p><p></p><p>它在 serve、sqlite、ffi 三个方面与 <a href=\"https://nodejs.org/zh-cn/\">Node.js</a>\" 和 <a href=\"https://deno.land/\">Deno</a>\" 的性能对比如下：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/87/6d/87c5f6c3a1f85ff5a85121e7ef73e66d.png\" /></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/18/1e/18880cdfc307bd35cc35dddb74f3aa1e.png\" /></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/7a/f7/7a0b768e5c9d0351be11c07c9c75ddf7.png\" /></p><p></p><p>根据官网测试截图，其 React 的服务器端渲染速度是 Node 或 Deno 的三倍以上，同时，官网也给出了 Bun 性能表现如此好的原因：</p><p>&nbsp;</p><p>不同于 Node.js 和 Deno 使用的是 V8 引擎，Bun 使用了 <a href=\"https://github.com/WebKit/WebKit/tree/main/Source/JavaScriptCore\">JavaScriptCore 引擎</a>\"，不同的引擎会产生不同性能；使用了新兴的系统编程语言 Zig，Bun 的创建者说 Zig 缺少隐藏的控制流使得编写快速软件变得更加简单。</p><p>&nbsp;</p><p>到目前为止，大多数观察者都认为 Bun 在性能方面值得关注，并且 npm 模块兼容性是一个巨大的优势。但值得注意的是，Bun 仍处于早期阶段，近日才发布 Beta 测试版。</p><p>&nbsp;</p><p>参考链接：</p><p>&nbsp;</p><p><a href=\"https://developers.slashdot.org/story/22/07/10/000246/meet-bun-a-speedy-new-javascript-runtime\">https://developers.slashdot.org/story/22/07/10/000246/meet-bun-a-speedy-new-javascript-runtime</a>\"</p><p>&nbsp;</p><p><a href=\"https://devclass.com/2022/07/06/zig-based-bun-appears-in-beta-an-incredibly-fast-all-in-one-javascript-runtime/\">https://devclass.com/2022/07/06/zig-based-bun-appears-in-beta-an-incredibly-fast-all-in-one-javascript-runtime/</a>\"</p><p></p><p>项目地址：</p><p>&nbsp;</p><p><a href=\"https://github.com/oven-sh/bun\">https://github.com/oven-sh/bun</a>\"</p>",
    "publish_time": "2022-07-13 14:30:44",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "程序员如何转行做产品｜InfoQ大会早班车第11期",
    "url": "https://www.infoq.cn/article/fKlA0lJOZHCU6MLOhBfS",
    "summary": "<p>InfoQ大会早班车连线 CodeFun 创始人杨帆，快手企业信息化、协同办公负责人罗杰，聊聊他们从写代码到做产品的转型经历，一起探讨从程序员转行产品的契机、优势和劣势，以及短期内如何快速入门产品经理。</p>\n<p>2022年GMTC北京站即将落地，<a href=\"http://gmtc.infoq.cn/2022/beijing/schedule?utm_source=infoq&amp;utm_medium=zaobanche\">点击查看最新日程</a>。</p>",
    "publish_time": "2022-07-13 14:33:30",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "韦伯望远镜344个单点故障，最多存储68GB数据，工程师：百亿美元可能眨眼就没了",
    "url": "https://www.infoq.cn/article/Czgb3NcFAta4rzx35RBI",
    "summary": "<p></p><blockquote>这两天持续刷屏的韦伯太空望远镜靠什么存储数据和通讯？</blockquote><p></p><p></p><p>当地时间 7 月 12 日，<a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651115001&amp;idx=4&amp;sn=537b265c982e855e7de4df1620963011&amp;chksm=bdb935aa8acebcbc7c730cef0c87d1692e16b55456f2478b1ef424c85e5f50f51e1f13322cb1&amp;scene=27#wechat_redirect\">美国国家航空航天局（NASA）</a>\"在官网上公布了一张由詹姆斯·韦伯太空望远镜从距离地球 100 万英里处拍摄的全彩照片。这是人类史上首次捕捉到深空宇宙画面的高解析度图像，照片中显示了最早期的恒星和星系。</p><p></p><p>2021 年 12 月 25 日，韦伯太空望远镜从法属圭亚那的欧洲空间局库鲁基地升空，起飞 7 天后，在该望远镜距离地球约 80.86 万公里时，按照计划完成了遮光罩的展开动作。一个月后飞至离地球约 150 万公里 远的拉格朗日 L2 点工作区域，对遮阳板和镜片完全展开并且调试，随后便开始了探索宇宙起源的征程。</p><p></p><p>詹姆斯·韦伯太空望远镜项目启动于 1996 年，由美国宇航局、欧洲航天局（ESA）和加拿大航天局（CSA）合作开发，是来自美国 29 个州和全球 14 个国家的数千名<a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651125963&amp;idx=5&amp;sn=a3b3938d92f59505dde6b64c823831b4&amp;chksm=bdb900988ace898e6cdc365006e4c79f0bc9f3b24e09c8a4c2d3c17d5d8ba4391e6bcd46678d&amp;scene=27#wechat_redirect\">工程师</a>\"、数百名科学家、300 所大学、机构和公司共同努力的结晶。</p><p></p><p>此项目最初被称为“新一代太空望远镜”（Next Generation Space Telescope），2002 年，为了纪念在阿波罗登月计划中做出突出贡献的 NASA 第二任局长詹姆斯·韦伯，改以其名字命名。</p><p></p><p>26 年研发期间，韦伯太空望远镜“烧掉”了百亿美元，是迄今为止美国航天局建造的最大、功能最强的空间望远镜。</p><p></p><h2>距离地球约150 万公里的韦伯靠什么通讯？</h2><p></p><p></p><p>那么，这个有望引领世界进入太空探索新时代的韦伯望远镜，究竟靠什么将拍摄到的图片传输到地球上？</p><p>据 NASA 称，韦伯的通信系统并不华丽。相反，<a href=\"https://qcon.infoq.cn/2022/guangzhou/track/1379\">数据</a>\"和通信系统的设计除了可靠，还是可靠。</p><p></p><p>韦伯望远镜停在拉格朗日点 L2。这是一个引力平衡点，位于地球外约 150 万公里处，位于行星和太阳之间的直线上。对于韦伯望远镜来说，这是一个理想的位置，可以无障碍地观察宇宙，并且轨道调整最少。</p><p></p><p>然而，距离地球如此之远，意味着<a href=\"https://qcon.infoq.cn/2022/guangzhou/track/1383\">数据</a>\"要走得更远才能将其整合为一体。这也意味着通信子系统需要可靠，因为至少在短期内，派遣维修任务来解决问题的可能性极小。韦伯望远镜的任务系统工程师 Michael Menzel 称，考虑到所涉及的成本和时间，“除非出现严重错误，否则我不赞同让韦伯望远镜执行会合和维修任务。”</p><p></p><p>参与韦伯望远镜项目 20 多年的工程师 Michael Menzel 表示，该计划一直是使用广为人知的 Ka 波段频率来传输大量科学数据。具体来说，韦伯望远镜正在以高达 28 兆比特 / 秒的速度在 25.9 GHz 信道上将数据传输回地球。Ka 波段是更宽的 K 波段的一部分（另一部分 Ku 波段，也被考虑在内）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6d/6d2e175a30424c58ec20a13c2ee348f0.png\" /></p><p></p><p>拉格朗日点是平衡位置，在该位置上，物体上的竞争引力牵引力为零。韦伯望远镜是目前占据 L2 的另外两艘飞船之一。图片来源：IEEE</p><p></p><p>韦伯望远镜的<a href=\"https://archsummit.infoq.cn/2022/shenzhen/track/1339\">数据收集和传输</a>\"速率与旧的哈勃太空望远镜有着是天壤之别。与仍然处于活动状态并每天生成 1 到 2 GB 数据的哈勃相比，韦伯望远镜 每天可以产生高达 57 GB 的数据（尽管该数量取决于计划的观测内容）。</p><p></p><h3>稳定的数据传输能力至关重要</h3><p></p><p></p><p>Menzel 强调，他第一次看到韦伯望远镜的频率选择建议是在 2000 年左右，当时他还在 Northrop Grumman 工作。他于 2004 年成为韦伯望远镜任务系统工程师。“我知道这次任务的风险在哪里。我想确保我们没有遇到任何新的风险，”他说。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/af/af70c9aad38a721132b98f89f36f3420.png\" /></p><p>图片来源：IEEE</p><p>此外，Ka 波段频率可以传输比 X 波段（7 至 11.2 GHz）或 S 波段（2 至 4 GHz）更多的数据，这是深空飞行器的常见选择。</p><p></p><p>高速数据是韦伯望远镜将要进行的科学工作的必要条件。此外，根据太空望远镜科学研究所（韦伯望远镜科学运营中心）的飞行系统工程师 Carl Hansen 的说法，类似的 X 波段天线太大了，无法保证航天器稳定成像。</p><p></p><p>虽然 25.9 GHz Ka 波段频率是望远镜的主要通信频道，但它也在 S 波段中使用了两个频道。一种是 2.09 GHz 上行链路，它将未来的传输和科学观测计划以每秒 16 千比特的速度传送到望远镜。另一个是 2.27 GHz、40 kb/s 的下行链路，望远镜通过该下行链路传输工程数据，这些工程数据包括其运行状态、系统健康状况以及有关望远镜日常活动的其他信息。</p><p></p><p>韦伯望远镜在其生命周期内收集的所有科学数据都需要存储在飞船上，因为航天器不会与地球保持全天候的联系。从其科学仪器上收集到的数据，也都会存储在航天器的 68 GB 固态驱动器中（3% 用于工程和遥测数据）。</p><p></p><h3>最多能存储 68GB 数据</h3><p></p><p></p><p>太空望远镜科学研究所的飞行系统工程师 Alex Hunter 表示，由于深空辐射和磨损，到韦伯望远镜 10 年任务寿命结束时，他们预计，固态驱动器的数据存储能力将从 68GB 降至 60GB 左右。</p><p></p><p>板载存储足以在空间用完之前收集大约 24 小时的数据。在出现这种问题之前，韦伯望远镜将找机会将这些宝贵的数据发送到地球。</p><p></p><p><a href=\"https://www.infoq.cn/video/YSwwhPsAR1bdXHLvEtXZ\">韦伯望远镜</a>\"将通过深空网络（DSN）与地球保持联系——这是它与 Parker 太阳探测器、凌日系外行星测量卫星、航海者探测器以及整个火星探测器和轨道飞行器共享的资源。</p><p></p><p>DSN 由三个天线复合体组成：澳大利亚堪培拉、西班牙马德里、加利福尼亚州巴斯托。韦伯望远镜需要与许多其他深空任务共享有限的天线时间，每个任务都有独特的通信需求和时间表。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2b/2ba40fc7ab9b0bbe2111161a58577b5c.png\" /></p><p></p><p>图片来源：IEEE</p><p></p><p>DSN 系统工程师 Sandy Kwan 称，与航天器的接触窗口需要提前 12 到 20 周进行规划。这样韦伯望远镜才能在其仪器上线、检查和校准等调试阶段有更多的预定联系窗口。该过程的大部分需要与地球进行实时通信。</p><p></p><p>所有通信通道都使用 Reed-Solomon 纠错协议——与 DVD 和蓝光光盘以及 QR 码中使用的纠错标准相同。较低数据速率的 S 波段信道使用二进制相移键控调制——涉及信号载波的相移。然而，K 波段信道使用正交相移键控调制。正交相移键控可以使通道的数据速率加倍，但代价是更复杂的发射器和接收器。</p><p>韦伯望远镜与地球的通信包含一个应答协议——只有在韦伯望远镜确认文件已成功接收后，它才会继续删除其数据副本以清理空间。</p><p></p><p>通信子系统由诺斯罗普·格鲁曼公司与航天器总线的其余部分一起组装，使用来自多家制造商的现成组件。</p><p></p><p>韦伯望远镜的开发时间长且经常延迟，但其通信系统一直是项目其余部分的基石。保持至少一个系统的可靠性意味着少了一件需要担心的事情。</p><p></p><h2>344 个“坑”，“坑坑”毁所有</h2><p></p><p></p><p>据透露，工程师在建造像韦布望远镜这样的空间仪器时，会保留一份事项清单，其中任何一项出现问题，带来的后果可能是灾难性的，这就是所谓的“单点故障”清单。换句话说，任何一处<a href=\"https://qcon.infoq.cn/2022/guangzhou/track/1389\">单点故障</a>\"都可能会造成整体故障。</p><p></p><p>之所以会有“单点故障”清单，是想通过开发备份系统和冗余来使“单点故障”列表尽可能短，但由于设计、技术、预算、人员等限制因素，通常意味着某些“单点故障”必须保留在这份清单当中。</p><p></p><p>例如，1980 年代美国宇航局（NASA）发送到木星的伽利略探测器有大约 30 个单点故障，一次火星登陆的单点故障有 100 多个。Menzel 在谈到韦伯任务时表示：“韦伯有 344 个单点故障，其中 80% 可以通过准备工作避免，但依旧难以完全避开。”</p><p></p><p>詹姆斯韦伯太空望远镜属于折叠的太空望远镜，在发射进入太空后，需要自行伸展，到达目标形状。</p><p>韦伯飞船系统工程师 Krystal Puga 在发布会上说，韦伯飞船有 144 个释放装置（折叠单位），“所有装置都必须完美工作”。</p><p></p><p>NASA 戈达德韦伯部署系统负责人 Alphonso Steward 在简报中也表示：“就像折纸一样，为了实现特定的形状，正确的折叠和展开是必要的。”</p><p></p><p>Menzel 解释说，团队已经在尽可能地减少了折叠数量。他说：“我们使用了大型柔性膜来达到最佳平衡点，而不会增加太多的单点故障。”</p><p></p><p>尽管任务，尤其是部署阶段存在大量单点故障，但 Menzel 强调了任务团队为确保成功所做的大量工作。“当我们发现单点故障时，我们会给予非常特殊的处理。我们有所谓的关键项目控制计划，并且我们总是会设置额外的检查点。我们已经对这些设备进行了额外的离线测试，”Menzel 说。</p><p></p><p>他补充说，NASA 和诺斯罗普·格鲁曼（Northrop Grumman）对每一个发现单点故障都进行了额外的检查和测试，以了解它可能失败的不同方式，并尽可能做好准备。“我们对单点故障项目给予了很多关注，”他说。</p><p></p><h2>随时准备上场的 Plan B</h2><p></p><p></p><p>尽管任务艰难而又复杂，但任务团队仍然需要迎难而上。Menzel 解释道：“团队不能建立冗余，但任务总体上也有很多应急计划或者备选方案。</p><p></p><p>“我们确实有多个应急计划，”Menzel 说道。他补充说，应急计划有的非常简单，也有的非常复杂，有些计划就像重新发送没有发送成功的命令一样简单，他说，”在韦伯望远镜大部分任务中有‘相当多的冗余’”。</p><p></p><p>韦伯团队一直在确保他们的备份计划和内置冗余功能按预期工作，以防万一。</p><p></p><p>此外，研究团队还需要确保太空望远镜的太阳能电池板可以正常展开，因为电力是詹姆斯韦伯太空望远镜最为核心的能量源，拥有电力，詹姆斯韦伯太空望远镜才能和地球沟通。</p><p></p><h2>韦伯的任务何时结束？</h2><p></p><p></p><p>科学家通常希望在望远镜的使用寿命期间能够尽可能多地获取有用信息。据 NASA 表示，从发射之日起，望远镜的寿命不会少于 5.5 年，韦伯团队希望将其寿命延长至 10 年以上，而望远镜的寿命取决于它在轨道上使用的燃料量，以及航天器上设备和仪器的效率。</p><p></p><p>目前，NASA 已经为韦伯空间天文台提供了足够 10 年的燃料，之后——如果一切按计划进行——望远镜将耗尽燃料，然后逐渐偏离它的路径，成为漂浮在太空中的垃圾之一。</p><p></p><p>参考链接：</p><p></p><p>https://spectrum.ieee.org/james-webb-telescope-communications</p><p>https://www.space.com/james-webb-space-telescope-deployment-points-of-failure</p>",
    "publish_time": "2022-07-13 14:45:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]