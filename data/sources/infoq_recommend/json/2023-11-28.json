[
  {
    "title": "MySQL 8.2正式可用，支持读写分离",
    "url": "https://www.infoq.cn/article/bEeAdpiaS1dpfTOquuEL",
    "summary": "<p>最近，Oracle宣布<a href=\"https://blogs.oracle.com/mysql/post/mysql-82-transparent-readwrite-splitting?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDEwNjQzMDksImZpbGVHVUlEIjoiS3JrRWxZRXIweEZtTlpxSiIsImlhdCI6MTcwMTA2NDAwOSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjotODQyMjQ1MTkwNH0.ExrsOHuTzXDW9RnNyUktPP60034QZmyIlhJy9O2oToE\">MySQL 8.2正式可用</a>\"，包括对读写分离的支持。这一备受期待的特性已经在最新的创新版本中引入，有助于优化数据库性能和提升可扩展性。</p><p></p><p><a href=\"https://dev.mysql.com/doc/mysql-router/8.2/en/router-read-write-splitting.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDEwNjQzMDksImZpbGVHVUlEIjoiS3JrRWxZRXIweEZtTlpxSiIsImlhdCI6MTcwMTA2NDAwOSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjotODQyMjQ1MTkwNH0.ExrsOHuTzXDW9RnNyUktPP60034QZmyIlhJy9O2oToE\">读写分离</a>\"使应用程序能够将所有写入流量定向到读写（主要或源）实例，将所有读取流量定向到只读实例，这些实例是InnoDB Cluster的附属实例，或者是Replica Cluster的主实例或附属实例。MySQL社区经理<a href=\"https://www.linkedin.com/in/freddescamps/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDEwNjQzMDksImZpbGVHVUlEIjoiS3JrRWxZRXIweEZtTlpxSiIsImlhdCI6MTcwMTA2NDAwOSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjotODQyMjQ1MTkwNH0.ExrsOHuTzXDW9RnNyUktPP60034QZmyIlhJy9O2oToE\">Frederic Descamps</a>\"解释说：</p><p></p><p></p><blockquote>我们在副本之间分配读取流量，但这需要在应用程序中通过某种方式来管理：将写入流量指向某个地方，将读取流量指向其他地方。MySQL 8.2的MySQL Router现在能够识别读取和写入流量，并将它们路由到InnoDB Cluster的主实例，或者将写入流量路由到异步复制源，将读取流量路由到附属实例或副本。</blockquote><p></p><p></p><p>使用读写分离，每个客户端会话可以与一个read_write和一个read_only目标通信，路由器会将每个查询分类为读取或写入，并将其定向到适当的后端。Percona创始人兼开源布道师Peter Zaitsev<a href=\"https://www.linkedin.com/posts/peterzaitsev_mysql-82-transparent-readwrite-splitting-activity-7123290675688714240-S7B9?utm_source=share&amp;utm_medium=member_desktop&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDEwNjQzMDksImZpbGVHVUlEIjoiS3JrRWxZRXIweEZtTlpxSiIsImlhdCI6MTcwMTA2NDAwOSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjotODQyMjQ1MTkwNH0.ExrsOHuTzXDW9RnNyUktPP60034QZmyIlhJy9O2oToE\">表示</a>\"：</p><p></p><p></p><blockquote>这是MySQL 8.2的一项重大特性！不过尚不清楚在这种情况下对读取是否有一致性级别的保证。是否可以读取过时的数据？如果可以，过时多久？</blockquote><p></p><p></p><p>客户端使用读写端口（默认为6450）连接到MySQL，如果进行读取，连接将到达副本（附属），如果启动了事务，它们将到达复制源（主实例）。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d6/d6152026b6d2cea28d902e04cc7558d7.webp\" /></p><p></p><p>社区普遍对这一新特性<a href=\"https://twitter.com/boyzoid/status/1717858999763173819?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDEwNjQzMDksImZpbGVHVUlEIjoiS3JrRWxZRXIweEZtTlpxSiIsImlhdCI6MTcwMTA2NDAwOSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjotODQyMjQ1MTkwNH0.ExrsOHuTzXDW9RnNyUktPP60034QZmyIlhJy9O2oToE\">表示赞赏</a>\"，但PingCAP软件架构师<a href=\"https://www.linkedin.com/in/bainssunny/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDEwNjQzMDksImZpbGVHVUlEIjoiS3JrRWxZRXIweEZtTlpxSiIsImlhdCI6MTcwMTA2NDAwOSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjotODQyMjQ1MTkwNH0.ExrsOHuTzXDW9RnNyUktPP60034QZmyIlhJy9O2oToE\">Sunny Bains</a>\"<a href=\"https://www.linkedin.com/feed/update/urn:li:activity:7123290675688714240?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7123290675688714240%2C7123331787145039872%29&amp;dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287123331787145039872%2Curn%3Ali%3Aactivity%3A7123290675688714240%29&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDEwNjQzMDksImZpbGVHVUlEIjoiS3JrRWxZRXIweEZtTlpxSiIsImlhdCI6MTcwMTA2NDAwOSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjotODQyMjQ1MTkwNH0.ExrsOHuTzXDW9RnNyUktPP60034QZmyIlhJy9O2oToE\">表示</a>\"：</p><p></p><p></p><blockquote>MySQL Group Replication提供了时间线一致性，路由器无法做得更好，除非路由器能够跟踪副本间的一致性，这似乎是可行的，但需要通过轮询或群集向路由器发送某种事件通知来实现。</blockquote><p></p><p></p><p>Descamps总结道：</p><p></p><p></p><blockquote>这是一项有价值的特性，可以优化数据库性能和提升可扩展性，且无需对应用程序做任何更改……这个特性不仅增强了整体用户体验，还简化了数据库的管理和部署。</blockquote><p></p><p></p><p>在今年早些时候，Oracle更改了MySQL的版本模型，引入了创新和LTS版本。<a href=\"https://blogs.oracle.com/mysql/post/mysql-820-is-out-thank-you-for-the-contributions?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDEwNjQzMDksImZpbGVHVUlEIjoiS3JrRWxZRXIweEZtTlpxSiIsImlhdCI6MTcwMTA2NDAwOSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjotODQyMjQ1MTkwNH0.ExrsOHuTzXDW9RnNyUktPP60034QZmyIlhJy9O2oToE\">MySQL 8.2.0</a>\"是最新的季度创新版本，包含了错误修复、安全补丁和新特性，<a href=\"https://dev.mysql.com/doc/refman/8.2/en/mysql-nutshell.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDEwNjQzMDksImZpbGVHVUlEIjoiS3JrRWxZRXIweEZtTlpxSiIsImlhdCI6MTcwMTA2NDAwOSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjotODQyMjQ1MTkwNH0.ExrsOHuTzXDW9RnNyUktPP60034QZmyIlhJy9O2oToE\">改进</a>\"包括：用于集合操作的哈希表优化、MySQL Enterprise Firewall的增强以及支持智能卡、安全密钥和生物识别读卡器等设备的新的WebAuthn身份验证方法。</p><p></p><p>MySQL 8.2.0 <a href=\"https://dev.mysql.com/downloads/mysql/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDEwNjQzMDksImZpbGVHVUlEIjoiS3JrRWxZRXIweEZtTlpxSiIsImlhdCI6MTcwMTA2NDAwOSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjotODQyMjQ1MTkwNH0.ExrsOHuTzXDW9RnNyUktPP60034QZmyIlhJy9O2oToE\">已正式可用</a>\"，可以从Oracle网站下载。</p><p></p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/11/mysql-read-write-splitting/\">https://www.infoq.com/news/2023/11/mysql-read-write-splitting/</a>\"</p>",
    "publish_time": "2023-11-28 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "美图的这100天：三月三版本，大模型博弈中谁能笑到最后？",
    "url": "https://www.infoq.cn/article/AF5E7b2wNVwK3oNZvyZo",
    "summary": "<p>“大家没日没夜地在视觉大模型上投入，我们也真金白银花了很多钱。”美图公司创始人、董事长兼首席执行官吴欣鸿在提到新发布的视觉大模型时说道。</p><p>&nbsp;</p><p>10月9日，美图发布了自研AI视觉大模型MiracleVision 3.0版本。实际上，在引入大型模型之前，美图已经将很多AI技术应用到美图秀秀、美颜相机等产品中，比如图像识别、图像处理和图像生成等等。</p><p>&nbsp;</p><p>至今已有十多年历史的美图影像研究院（MT&nbsp;Lab）深耕深度学习，如今也开始将重点转向大模型研究。在美图公司技术副总裁兼美图影像研究院负责人刘洛麒看来，团队在技术方向上的升级是自然而然的事情。</p><p>&nbsp;</p><p>“大模型的数据量级和模型规模相比之前确实要更大些，需要进行大量的开发和对比实验，这是必然的。但在多年的AI算法研发中，我们已经积累了深厚的底层技术积累，这为大模型的研发提供了坚实的技术基础。”刘洛麒说道，“我们在北京、深圳和厦门都设有研发中心，吸引了国内外众多高校和研究机构的顶尖人才。我们还持续跟踪AI行业的前沿发展和学术研究工作，保证自身的视野始终位于行业的最前端，。”</p><p>&nbsp;</p><p>那么，美图的视觉大模型具体经历了哪些开发和打磨？未来又将如何利用大模型实现商业变现？</p><p></p><h3>“量变引发质变”的大模型</h3><p></p><p>&nbsp;</p><p>MiracleVision是基于扩散模型理论的文生图模型，目前是数十亿的参数规模。核心部分有两个：一是将文本转化为潜在编码，以控制扩散模型生成过程的文本编码模块。二是采用扩散模型的生成模块，还有一些附加模块，例如超分辨率模块，用于在生成后对图像进行放大并增强细节。</p><p>&nbsp;</p><p>美图的技术团队要先收集高质量的数据并进行筛选。通常，团队会用自动化算法对训练数据进行预处理，包括增强图像的清晰度和画质、调整色调、裁剪等，然后使用自研的模型架构进行训练，最后进行效果调整。</p><p>&nbsp;</p><p>MiracleVision演进经历了三个关键阶段。</p><p>&nbsp;</p><p>在1.0版本期间，美图着重构建了基础架构和模型美学体系，为后续效果的引入奠定了基础。</p><p>&nbsp;</p><p>对美图的技术团队来说，一开始技术体系的搭建显然是个很大的挑战，特别是在处理大规模数据方面。团队提出了很多标准和设想，并进行了大量实验。</p><p>&nbsp;</p><p>“因为之前缺乏这方面的经验，我们需要思考如何扩展数据规模来支持上亿级别的训练，同时保持高效的GPU利用率，确保效果可控。我们进行了一系列实验和探索，最终确定了整个流程。”刘洛麒说道。</p><p>&nbsp;</p><p>在2.0版本中，更注重引入高质量数据进行模型训练，主要目标是提高美观度、细节多元化，并增强文生图的准确性，以此适应更多场景。</p><p>&nbsp;</p><p>技术发展更像是量变引发质变，而不是在一个特定的节点突然改变一切。经过大量的数据积累，团队在内测2.0版本时，大模型生成的图像开始展现出创造力，展现出整体效果。</p><p>&nbsp;</p><p>“这让我们非常振奋，因为它超出了我们的预期。”美图公司副总裁、设计中心总经理许俊说道，“当时，我们都沉浸到了这个大模型的效果中，感觉不再是工作，而更像是在创作自己的东西。这种体验非常独特。”</p><p>&nbsp;</p><p>如今，MiracleVision已经进入3.0版本，团队集中精力来提升模型的可控性，以便用户能够更精确地进行细节控制和局部编辑，同时引入更多与工作流结合的数据增强，特别是在垂直领域方面。</p><p>&nbsp;</p><p>这里的可控性包括三个方面，一是通过中文语义描述的精准理解来达到想要的效果，二是可以对生成图像进行局部修改以及在修改的区域生成新的图像内容；三是提高分辨率，可以清晰呈现微小的细节，例如发丝细节。这种可控性的提升需要的是综合技术能力，既有算法优化，也需要设计师的经验和审美来帮助微调。</p><p>&nbsp;</p><p>除了通用领域的可控性，如何做好垂直领域的效果精致度也是一个难点。美图内部花了很多精力在不同垂直领域效果上进行各种调试，针对每个领域制定不同的训练、生成和调试方式。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/81/81c616dd5d871c360030964ec8a85f78.png\" /></p><p>&nbsp;</p><p>从1.0到3.0的效果对比</p><p>&nbsp;</p><p>算力方面，美图提供基础算力支持，包括华为云等公有云以及自建的私有云部署，使得美图能够使用高性能的GPU卡进行不同规模的深度学习训练。</p><p>&nbsp;</p><p>在此基础上，美图设立了专门的团队，采取了一系列措施来提高大模型训练效率和资源的利用率，包括持续优化分布式训练框架，构建大规模AI高性能网络通信；建立健全的数据监控系统，用于监测每个GPU的使用率、功率消耗以及数据传输速度等，以此确保GPU的整体利用率保持高效。</p><p>&nbsp;</p><p>目前发布的MiracleVision主要是做图片生成，后续团队还将其扩展到视频生成领域。视频生成对连续性的要求更高，即生成的画面帧需要保持连贯，并且清晰度和质量要更高。</p><p>&nbsp;</p><p></p><h3>“设计师+研发”的化学反应</h3><p></p><p>&nbsp;</p><p>美图技术生态系统都与大模型相关，相关工程师有数百人，包括参与核心大模型训练和部署的研发，和基于大型模型构建具体应用场景的研发，如AI模特和AI动漫等方向的工程师。</p><p>&nbsp;</p><p>“美图的技术团队相当庞大，其独特之处在于，我们深刻理解业务和用户产品，而不仅仅专注于研究技术本身。”刘洛麒说道，团队将用户产品、设计师效果与技术有机结合，从用户用户反馈中反推技术的演进和提升。</p><p>&nbsp;</p><p>刘洛麒提到的“设计师效果”，就是为美图为解决视觉大模型研发的另一个挑战：对美学的理解，而设计的一个重要环节。</p><p>&nbsp;</p><p>“之前国内的一些图像大模型开发可能比我们开始得更早，但为什么他们的结果不太理想呢？我们将大模型训练比喻成一个小孩学习绘画，如果小孩开始学画画时看到的都是美好的事物，那就避免了想象出不美好的东西。”许俊表示。</p><p>&nbsp;</p><p>美，不像数学是一件有标准答案的事情，但生成图像需要标准。</p><p>&nbsp;</p><p>因此，美图设计师和外部艺术家早期花了很长的时间共同建立了一套美学评估体系。这套美学评估体系涵盖了数十个维度，每个维度设置了相应的得分，这些得分综合起来形成最终的美学分数。团队以每个维度的得分作为模型训练标准。</p><p>&nbsp;</p><p>这套评估体系贯穿了美图的整个大模型生命周期，包括前期数据筛选标准和模型效果调整标准等。</p><p>&nbsp;</p><p>实际上，这种设计师深入参与研发的方式，是美图一直采取的研发方法，不只是大模型领域。</p><p>&nbsp;</p><p></p><h3>大模型给谁用？</h3><p></p><p>&nbsp;</p><p>做出大模型只是开始，怎么让大模型产生收益是每个公司都要考虑的问题。</p><p>&nbsp;</p><p>经过调研，美图公司集团高级副总裁、影像与设计产品事业群总裁陈剑毅发现，大模型赛道对于创业公司来说很不友好，最后可能只会剩下比较成熟或者中大型公司。这其中的一个关键点就是要回答“模型给谁用”的问题。</p><p>&nbsp;</p><p>陈剑毅表示，给别人用的前提是要有一个应用层作为辅助和支撑。创业公司做出一个大模型，如果没有应用层，就得自己做然后花钱推广，结果也不一定理想。</p><p>&nbsp;</p><p>那么，美图的视觉大模型要给谁用？</p><p>&nbsp;</p><p>首先是要给自己用，现在基本上美图的大部分产品都逐渐融入了MiracleVision。其次，通过美图产品，个人用户也间接用上了MiracleVision。而通过用户的反馈，美图团队会进行针对性训练，以最快的速度调整效果，与用户应用场景结合。这种直接to C带来的闭环也是美图优势所在。</p><p>&nbsp;</p><p>但这只是大模型在现有产品体系的应用，还不够。如何让大模型产生降本增效的能力是美图关注的重点，美图的目标是做AI原生工作流。</p><p>&nbsp;</p><p>所谓原生工作流就是跳出传统工作流，利用AI能力更高效、高质量地完成创作。美图首先瞄向了电商、广告、游戏、动漫、影视这五大互联网性较强、长尾效应也高的行业。比如电商诞生于互联网，其中的一些小商家对效果的要求相对容易满足，美图可以为这类用户提供服务。美图希望可以在上述五大行业中实现落地，并获得一些重要的客户和行业订单。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/38/38ea43f555b5a517ef6143401f40d935.png\" /></p><p>&nbsp;</p><p>实际上，这种思路意味着美图需要分别去了解不同行业的需求，背后的工作量是不小的。为此，美图针对不同行业设置了不同的团队，负责了解具体行业的需求，并构建对应的产品。在产品落地的过程中，需求也会给到研发团队，业务团队与研发团队共同研发。美图影像研究院的研发也是业务驱动的，会优先考虑业务需求，然后利用最新的技术来解决用户的问题。</p><p>&nbsp;</p><p>不过，在与不同行业合作时，美图也会面临一些问题。</p><p>&nbsp;</p><p>比如，最初提供的一些概念性想法和图像设计，虽然效果可能很酷炫，但由于涉及到一些特殊的材料或技术，在实际生产中却难以应用。为此，团队需要更深入了解行业的切实需求和解决方案的可行性，以脱离提供抽象概念的误区。</p><p>&nbsp;</p><p>“与行业专业人士的合作非常重要，因为他们可以提供反馈，告诉我们真正的痛点是什么。通过交流，我们可以更好地调整产品和大模型，以满足他们的需求，解决他们的问题。这种合作是实现大模型在行业落地的关键。”许俊说道。</p><p>&nbsp;</p><p>产品设计过程中，美图团队的重点在于确保用户不需要经历冗长的学习曲线，无需过多的介绍和解释就可以使用。用户只需将创意以提示词的方式表达，然后交给大模型来实现想要的效果。如果有需要，用户还可以通过一些高级选项来微调或控制大模型的输出。</p><p>&nbsp;</p><p>目前，不同行业的用户对这种变化的接受速度不同。电商和游戏行业是两个转型较快的行业。在电商行业，很多时候需要与摄影师安排时间线下拍摄模特照片或商品图像，流程效率低下且成本较高。因此，电商用户更容易接受AI工作流程，因为电商本身是在线平台，具有更快的操作速度，可以显著降低成本。</p><p>&nbsp;</p><p>游戏行业类似。以前游戏制作通常需要从零开始绘制粗糙的原始图像，与最终效果相差甚远。现在，一些游戏制作公司使用AIGC工具来绘制更精致的效果图，甚至在最终产品的渲染过程中应用，这样绘图成本可以大大降低。</p><p>&nbsp;</p><p>不过，让行业里的所有人都丢掉之前工作方式、全面拥抱大模型还有些挑战。根据美图团队经验，现在离大模型最近的是一群“传播者”，即新媒体运营、电商运营和网红，他们没有太多之前的经验包袱，能够很快适应新的、更简单的工作流程。</p><p>&nbsp;</p><p>“AI原生工作流并不代表AI工具会取代他们的地位，因为他们仍然需要提供大量的创意和想法。AI工具只是能更快地实现他们的构想。”许俊强调。</p><p>&nbsp;</p><p>目前，美图团队正在视觉大模型基础上，围绕特定垂直领域对大模型进行针对性训练，让垂直领域性能达到极致。</p><p>&nbsp;</p><p>在变现方面，美图的用户付费模式具有多种变体。用户可以选择按月订阅，也可以选择单独购买特定功能。此外，广告等各种方式也可以用来产生收入，以弥补大模型的成本。&nbsp;</p><p></p><h3>结束语</h3><p></p><p>&nbsp;</p><p>就像普通用户会用美图秀秀做短视频封面或者简单的带货图片，大模型的使用并不需要专业技能加持，更低的门槛意味着更多的用户参与。</p><p>&nbsp;</p><p>对于美图来说，大模型已然是其必争之地。就像吴欣鸿曾说的，随着视觉大模型和生产端的磨合，垂直领域的极致效果、工作流整合和变现能力，这三个问题会被逐步解决。美图能否趟平这条道路，我们拭目以待。</p><p></p>",
    "publish_time": "2023-11-28 09:35:11",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Docker 的诅咒：曾以为它是终极解法，最后却是“罪大恶极”？",
    "url": "https://www.infoq.cn/article/8hmeeHoDOA0Sv4q2xTMY",
    "summary": "<p></p><blockquote>GitLab 高级专业服务工程师、DevOps 顾问 J. B. Crawford 最近写了一篇关于抱怨 Docker 的文章，在网上引发了开发者们的讨论。有人力挺，也有人反对：“我不明白没有 Docker 的堆栈管理怎么会更好。”J. B. Crawford 在文章中表示：“我不太确定 Docker 帮助节约的时间有没有超过对它的管理成本。”下面让我们具体看看他为什么对 Docker 感到不满。</blockquote><p></p><p></p><h2>系统管理中的基础问题</h2><p></p><p>&nbsp;</p><p>打包软件一直是系统管理中的一大基础问题。它非常重要，对系统的使用方式有着巨大影响，甚至让包管理器成为区分操作系统的一项重要指标。</p><p>&nbsp;</p><p>以Windows为例：在很多“Linux派”眼中，这款操作系统最不讨喜的就是缺乏包管理机制，微软先后多次尝试引入这个概念也都没能得到广泛认可。相比之下，Linux世界中各发行版间的主要区别，就集中在其管理软件repo的方式上。我所指的不只是dpkb和rpm之间的差异，而是在强调更底层的设计，例如硬性指定还是上游配置、稳定repo还是滚动发布。拿RHEL和Arch来说，二者虽然共享绝大多数实现，但管理风格却截然不同。</p><p>&nbsp;</p><p>大多数Linux发行版都会明确强调某种软件应该如何打包（甚至规定了多久打包一次），而且这些系统也都有着一项共通理念：将依赖项集中起来。应该把库声明为依赖项，并把所依赖的包安装在公共位置以供链接器使用。但这也可能带来挑战，因为不同的软件往往依赖于不同的库版本，而各版本之间可能并不兼容。这也是在维护Linux发行版时最典型的老大难问题：如何提供能够良好协作的软件repo版本。像RHEL这类稳定发行版的一大优势，就是它们在这方面表现得相当可靠；至于缺点，就是这种可靠性其实是通过拒绝大部分新版本软件来实现的。</p><p>&nbsp;</p><p>由于需要提供大量可以相互兼容的软件版本，并确保发行版遵守各种构建规范（例如支持自由软件等开发理念、以及配置文件布局等具体规则），所以向Linux发行版引入新软件时往往极度麻烦且繁琐。对于软件维护人员来说，他们需要面对一大堆有着特定构建和配置差异的旧版本，并想办法把它们塞进发行版中去。而在发行版和软件包维护者这边，则需要全盘考虑各种上游软件是否符合发行版策略，并解决版本和依赖项问题。虽然行业中已经出台了一系列相关规范，但具体操作仍然令人头痛，庞大的工作量也几近疯狂。</p><p>&nbsp;</p><p>这就形成了一种双输的诡异局面：希望自己的软件能够广泛传播的开发者必须忍受发行版的怪癖，而想要壮大自身软件生态的发行版也得顺应开发者。每个人都不开心，每个人都很疲惫。</p><p>&nbsp;</p><p>有问题，自然有人尝试解决。业界已经在这方面做出了各种探索，但也正是因为方法多种多样，所以至今没有真正出现一种能够统领全局的解决方案。在桌面环境中，常见的软件分发选项有Flatpak、Snap和AppImage等。这些系统的镜像或应用程序能够将软件及其依赖项共同打包，提供一套完整的独立环境，从而保证在任何发行版上都能正常工作。</p><p>&nbsp;</p><p>但在实际使用时，我自己曾不止一次对flatpak文件进行逆向工程以修改其中的依赖项，所以说上述工具的宣传效果在日常应用时并不一定能发挥作用。但公平地讲，软件在与各种要素的交互过程中，难免会出现意料之外的状况——比如运行时无法正确将各种要素彼此隔离开来。视频技术栈就是个典型，我们往往需要删除或替换掉包中错误的OpenGL库，才能使其跟特定图形驱动程序共同运行。</p><p>&nbsp;</p><p>尽管如此，我还是承认上述工具的运行效果不错，甚至值得进一步扩展并普遍使用。它们所依托的桌面应用形式主要强调与用户交互，并通过自身界面接收用户发来的配置选项。尽管在与文件系统交互时仍然不够顺畅丝滑，但这种将交互界面限制在GUI形式内的作法确实让沙箱变得既可行、又极具现实意义。</p><p>&nbsp;</p><p>需要强调的是，本文不会对沙箱问题做过多延伸。沙箱是一项重要的安全和稳定性保障技术，但这里讨论的主要是软件打包和分发问题。毕竟沙箱软件也可以通过更传统的方式进行分发，在其现代外壳之下的打包机制其实远没有人们想象的那么先进。</p><p>&nbsp;</p><p></p><h2>让我无法忍受的是什么？</h2><p></p><p>&nbsp;</p><p>总而言之，我想抱怨的其实是服务器端的软件运行体系。这里的软件打包方案基本只有一个：Docker。当然，人们偶尔也会使用Podman等兼容性的工具选项。</p><p>&nbsp;</p><p>Docker的出现被广泛视为服务器运营最佳实践的里程碑事件。尽管Docker是一种软件分发方式，但其最初似乎主要是为了将容器编排引入大规模可扩展环境。但最终随着不断发展和思想融合，Docker成为一种面向开发者和单节点用例的常见软件分发方式。</p><p>&nbsp;</p><p>现如今，Docker也成为Linux上最常见的服务器端软件分发选项。而我，对它恨之入骨。</p><p>千万别误会，我在这里要批评的并不是容器技术本身。容器化非常精妙、有着诸多优点，虽然未必像炒作中说的那样全面碾压轻量化虚拟机，但它的亮点还是非常突出。我不太确定Docker帮助节约的时间有没有超过对它的管理成本，但公平地讲，身为一名DevOps顾问，实践经验告诉我正确运行Docker镜像并不算特别麻烦。</p><p>&nbsp;</p><p>真正让我无法忍受的，就是在非DevOps环境中盲目使用Docker镜像。镜像需要集中规划和管理，也就是说Docker应该是向用户分发软件时的最小公共集，应该是种最低的保障性选项。而每当看到开源服务器端软件以Docker镜像的形式提交过来，甚至是更糟糕的Docker Compose栈时，我的第一反应就是愤怒。跟传统Linux软件包分发、或者使用源代码直接构建的软件相比，Docker镜像总是需要耗费更多时间才能正常起效。</p><p>&nbsp;</p><p>很多朋友可能不太理解，Docker不是把所有元素都独立隔离开来，降低了部署难度吗？确实，但接下来我打算聊几个常见问题，也就是“Docker不适用的情况”。</p><p>&nbsp;</p><p></p><h4>配置</h4><p></p><p>&nbsp;</p><p>Docker在分发中最大的问题之一，就是缺少统一的配置约定。</p><p>&nbsp;</p><p>绝大多数服务器端Linux软件需要读取文本文件来获取配置，这种古老的方式当然有自己的问题……但至少它有着统一的框架和准则。</p><p>&nbsp;</p><p>可Docker镜像就不同了。</p><p>&nbsp;</p><p>如果大家听说过12因素应用原则，就会意识到Docker镜像的最佳配置方式应该是通过环境变量。这样做的好处在于，启动容器时可以在命令行上轻松实现；至于缺点，就是环境变量不太适合传递结构化数据，而且由于大多需要通过shell脚本进行交互，这些脚本在处理长值或复杂值也显得比较笨拙。</p><p>&nbsp;</p><p>DevOps环境中使用的许多Docker镜像确实会从环境变量中获取配置，但出于前面这些现实问题，它们往往要通过避免复杂配置（例如假设TLS将被「他方」终止）或者控制信息获取量来实现。而配置内容，则来自网络上的数据库或服务。</p><p>&nbsp;</p><p>不过对于大多数最终用户软件来说，其配置过于复杂或冗长，单靠环境变量根本无法容纳。这时他们就只能求助于配置文件，即以某种方式将配置文件纳入容器的文件系统当中。Docker倒是提供了多种操作执行方式，于是不同软件包的文档会根据相关推荐而有所区别，甚至经常触发关于所有权和权限的警告。</p><p>&nbsp;</p><p>更糟糕的是，很多Docker镜像还试图通过提供某种入口点shell脚本来降低配置难度，这些脚本负责向容器提供更简单的文档以生成完整配置。这种抽象级别在实践中往往缺少相应的记录痕迹，这就让故障排查变得更加困难。</p><p>&nbsp;</p><p>我自己就无数次经历过软件无法正常启动的“惊喜”，原因就是脚本引用了一些配置中未提供的键，导致我们必须查阅Docker镜像构建说明和入口点脚本来反推它的启动过程。这好吗？这一点也不好。</p><p>&nbsp;</p><p>最要命的是，很多配置入口点脚本还有自己的设计倾向性。别看“设计倾向性”这词好像比较中性，但它的真实含义就是“除了开发者自己，别人都弄不明白”。我至少有十几次都被迫自己构建Docker镜像版本，来替换掉那些没有公开底层软件参数的入口点脚本。</p><p>&nbsp;</p><p>更夸张的是，某些Docker镜像甚至根本不提供任何说明文档。用户必须深入研究、四下探寻，才能找出当前软件所使用的配置文件的具体位置。我认为Docker镜像至少也得给出最基本的README信息，帮助我们了解打包的软件到底应该如何配置。</p><p>&nbsp;</p><p></p><h4>文件系统</h4><p></p><p>&nbsp;</p><p>Docker提供的沙箱或者说隔离机制肯定是个优点，但这也代表着它必然有着一切沙箱所面临的共同问题。</p><p>&nbsp;</p><p>沙箱隔离机制跟Linux的文件系统兼容性很差，哪怕不涉及UID行为、单纯在Docker Compose栈中使用命名分卷就足以引发意外。在需要使用虚拟容器跟命名分卷中的文件进行交互时，比如执行备份之类的日常操作（都不说故障排查这类更复杂的需求），结果都很可能让人头痛欲裂。随着时间推移，命名分卷得到了大幅改进，但看似简单的操作在不同Docker版本之间仍经常出现奇怪的冲突，更不用说还得考虑如何兼容Podman等其他工具了。</p><p>&nbsp;</p><p>当然，UID也有自己的问题。Docker的一大原罪，就是要求以root身份运行软件。</p><p>&nbsp;</p><p>没错，Docker确实提供一定程度的隔离，但从纵深防御的角度来看，以root身份公开运行用户操作仍然不是明智之举。为此，我需要频繁重构软件来适应Docker的这种怪癖，而且整个过程相当复杂。而且在稍微繁琐的环境中使用Docker，都有很大概率引发涉及UID分配的NFS难题。使用命名分卷当然能缓解这些问题，但分卷本身又有自己的痛点，简直是要人老命。</p><p></p><h4>容器可移植性很差</h4><p></p><p>&nbsp;</p><p>对于强调分布式特性的Docker（特别是Docker Compose）来说，最讽刺的还在于很多常规实践会大大影响其可移植性。</p><p>&nbsp;</p><p>在Docker Compose中对网络执行的任何非默认操作，都有可能导致其在网络设置比较复杂的计算机上无法正常工作。很多Docker Compose栈都会将那些众所周知的端口默认为可供侦听器使用。它们还会启用各种底层软件功能，又不提供禁用的方法，甚至用到很多在具体环境中并不可用的通用值。</p><p>&nbsp;</p><p>就个人而言，最让我恼火的就是TLS。前文已经提到，我认为Docker容器不应该终止掉TLS。只有接受TLS连接，才允许访问私钥信息。尽管长达90天的临时TLS证书和普遍懈怠的安全意识已经破坏了保障能力，但我仍然认为私钥信息应该受到严密保护。这部分信息只应存储在一个位置，且只能由一名主体进行访问。当然，能不能实现这种安全破坏还在其次，很多用户可能根本就搞不定TLS配置。</p><p>&nbsp;</p><p>不少自行托管软件的朋友都会选择SNI或者虚拟托管的方式，其中往往存在涉及多个子域的通用证书。这一切最好都能在少量、甚至是单一专用点上处理。而一旦遇到在构建中假设在各个点上单独处理TLS的Docker镜像，可就倒了大霉了。即使完全不考虑TLS，我个人也永远不想把Docker应用容器直接暴露在互联网上，在前面部署反向代理才是正确的选择。</p><p>&nbsp;</p><p>此外，Docker Compose栈还总想要使用ACME为最终用户软件颁发自有证书，我们得深入研究说明文档才能搞清如何禁用这一行为。</p><p>&nbsp;</p><p></p><h4>单一用途计算设备</h4><p></p><p>&nbsp;</p><p>我前面说的这些问题在业余人士开发的软件中最为常见，我现在脑海中就浮现了HomeAssistant和Nextcloud这两个例子。请别误会，我所说的“业余”并不质疑软件本身，而是在强调普通用户的使用习惯。</p><p>&nbsp;</p><p>遗憾的是，由于Raspberry Pi设备的价格越来越低廉，很多业余爱好者失去了那份严谨态度。可能我说的有点夸张，但他们在专用硬件上运行的“自托管”软件包已经多到了荒谬的程度。在我看来，软件名称中带有“pi”基本就是个危险信号，代表着开发者“没考虑过在共享设备上运行需要做哪些改动”。大家可以说是我太守旧，但我认为计算设备就不该只能执行一项任务，特别是那些需要24/7全天候开机的设备。</p><p>&nbsp;</p><p>HomeAsistant可能就是其中最大的罪魁祸首，我自己就在一台设备上通过Docker运行它，还有其他几款应用程序。但HomeAsistantr明显不想跟其他软件共存，每次更新后都会弹出“检测到不支持软件”的提醒。这也太过分了，有必要管得这么宽吗？</p><p>&nbsp;</p><p>后来我决定尝试一下Nextcloud，大概花了两个小时想让打包的Docker镜像在自己的环境上正常运行。最终，我决定放弃并转为手动安装，结果发现它就是一款平平无奇的PHP应用，跟十几年前的程序没有任何区别。这么简单的东西，你把它打包成Docker镜像干什么嘛？直接用config.php不好吗？</p><p></p><h2>“罪大恶极，罄竹难书”</h2><p></p><p>&nbsp;</p><p>当然，大家可能觉得前面的问题都是操作细节，只要认真制作Docker镜像就能避免。没错，确实可以！也许Docker最大的问题就是它门槛太低了。创建RPM或者Debian软件包就有一定的技术难度，即使是经验丰富的开发者需要多次尝试才能让rpmbuild顺利运行起来（这里建议只用copr和rpkg）。</p><p>&nbsp;</p><p>我的抱怨在于，纯以Docker镜像的形式做分发，往往代表着开发者并没有对自己的项目投入足够的心力、或者至少没有专门做过项目分发设计。要想让自己的成果在各种非标环境中运行起来，就一定得预先考虑到可能出现的意外。</p><p>&nbsp;</p><p>当然，大家应该能明白，我的用词只是种夸张和讽刺。我曾经把Docker誉为稳定可靠的终极解决方案，只是后来发现必须得有一定的配置经验和管理水平才能实现。</p><p>&nbsp;</p><p></p><h2>写在最后</h2><p></p><p>&nbsp;</p><p>当然，以上只是我的一点个人观点，相信很多朋友会抱有完全不同的意见——比如我坚信Docker Compose是容器时代最大的错误之一。</p><p>&nbsp;</p><p>15年前我曾写过一篇类似的文章，讲述自己在开发小型项目时在RPM中遇到的各种问题。Docker最让我惊讶的一点，就是它能让项目发展到很大的规划、获得企业的广泛支持，同时还通过Docker Compose栈大大降低了分发的技术门槛。</p><p>&nbsp;</p><p>我在前面提到的很多问题也确实源自这种“简单性”，因为很多项目根本就没有固定的分布式工程人员。面对不断变化的软件发展格局，他们只是想用廉价的单片机搭配上Docker容器技术，回避掉相对更麻烦的虚拟机镜像。当然，我也承认随着年纪愈长，我这人说话也越来越不中听了。</p><p></p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://computer.rip/2023-11-25-the-curse-of-docker.html\">https://computer.rip/2023-11-25-the-curse-of-docker.html</a>\"</p><p>&nbsp;</p>",
    "publish_time": "2023-11-28 09:54:43",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "快手基础平台部系统软件中心 / 系统软件负责人熊刚确认出席 QCon 上海，分享快手的系统软件资源效率优化实践",
    "url": "https://www.infoq.cn/article/bb2xZYR7MY56rLQSwcPf",
    "summary": "<p><a href=\"https://qcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=8&amp;utm_term=1128&amp;utm_content=xionggang\">QCon 全球软件开发大会</a>\"，将于 12 月在上海召开。快手基础平台部系统软件中心 / 系统软件负责人熊刚将发表题为《<a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5591?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=8&amp;utm_term=1128&amp;utm_content=xionggang\">快手的系统软件资源效率优化实践</a>\"》主题分享，探讨性能优化方法论，如何通过提升资源利用率和性能优化来降低服务器用量，如何通过微架构优化、内核优化、编译优化、基础库 / 框架优化、JVM 优化技术提升性能，以及如何通过引入新性价比更高的硬件来降低单价。</p><p></p><p><a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5591?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=8&amp;utm_term=1128&amp;utm_content=xionggang\">熊刚</a>\"，擅长海量服务、高稳定高性能服务架构、系统软件技术。2010 年硕士毕业就职腾讯：先后深度参与或主导 QQ 后台几次架构升级（包括参与通信系统重构、主导接入鉴权系统重构、主导调度系统重构），主导腾讯视频云质量优化，以及 CV 技术研发落地。2019 年加入快手，参与央视春晚项目 (A1)，负责应用启动、过载保护、核心配置系统设计和落地，死保中的死保，0 事故。2021～2023 年之间，从 0 到 1 建立系统软件领域，包括操作系统、JVM、编译构建、系统诊断、系统观测、性能优化等子领域。他在本次会议的演讲内容如下：</p><p></p><p>演讲：快手的系统软件资源效率优化实践</p><p></p><p>案例分享概述：介绍利用系统软件技术来全面提升服务器资源效率。服务器总成本是服务器总量和单价相乘，分两部分，一部分是通过提升资源利用率和性能优化来降低服务器用量，比如内核隔离与控干扰技术，GPU 虚拟化与混部技术来提升 CPU 与 GPU 利用率，通过微架构优化、内核优化、编译优化、基础库 / 框架优化、JVM 优化技术提升性能。另外一部分是通过引入新性价比更高的硬件来降低单价。总计为公司带来 10 亿级别的成本优化价值，ROI 在 10 以上。</p><p></p><p>整个项目成功的要点在于，形成快手独特成本优化方法论，抓住关键技术，借助公司关键战役进行创新突破，最大化系统软件价值。</p><p></p><p>演讲提纲：</p><p></p><p>性能优化方法论通过提升资源利用率和性能优化来降低服务器用量</p><p>○ 比如内核隔离与控干扰技术</p><p>○ GPU 虚拟化与混部技术来提升 CPU 与 GPU 利用率</p><p>通过微架构优化、内核优化、编译优化、基础库 / 框架优化、JVM 优化技术提升性能通过引入新性价比更高的硬件来降低单价</p><p></p><p>你将获得：</p><p></p><p>○ 获得性能优化的方法论；</p><p>○ 性能优化常见的武器有哪些；</p><p>○ 如何深入系统做性能优化。</p><p></p><p>除上述演讲外，QCon 上海还将围绕&nbsp;<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart\">GenAI和通用大模型应用探索</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1596?utm_source=infoqweb&amp;utm_medium=teacherart\">AI&nbsp;Agent&nbsp;与行业融合应用的前景</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart\">LLM&nbsp;时代的性能优化</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart\">智能化信创软件&nbsp;IDE</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart\">面向人工智能时代的架构</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart\">性能工程：提升效率和创新的新方法</a>\"等专题进行交流。</p><p></p><p>QCon 上海 2023，相约 12 月！ 8 折优惠还剩最后 4 天，现在购票立减￥1360！咨询购票请联系：18514549229（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/0113b3dfb187d5f9988b7eb16d2e0594.png\" /></p><p></p>",
    "publish_time": "2023-11-28 11:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]