[
  {
    "title": "Grafana Labs发布跟踪查询语言TraceQL",
    "url": "https://www.infoq.cn/article/4rQRdft9ps5mfbXu2gRs",
    "summary": "<p>作为即将发布的<a href=\"https://www.infoq.com/news/2022/10/grafana-92-metrics-tracing/\">Grafana Tempo 2.0</a>\"的一部分，<a href=\"https://grafana.com/blog/2022/11/30/traceql-a-first-of-its-kind-query-language-to-accelerate-trace-analysis-in-tempo-2.0/\">TraceQL</a>\"是一种旨在简化交互式搜索和提取跟踪信息的查询语言。根据Grafana官方的说法，这将有助于加快诊断故障根源的过程。</p><p>&nbsp;</p><p></p><blockquote>分布式跟踪包含了丰富的信息，可以帮助开发者跟踪错误、确定故障根源、分析性能，等等。虽然一些自动增强检测工具也可以用于捕获这些数据，但从这些数据中提取有价值的信息却要困难得多。</blockquote><p></p><p>&nbsp;</p><p>根据Grafana官方的说法，如果你不知道你需要哪些跟踪信息，或者如果你想重建事件链的上下文，那么现有的跟踪解决方案在搜索跟踪信息时就没有那么灵活。这也就是为什么要从头设计TraceQL来处理跟踪信息。下面的示例展示了如何查找与耗时超过一秒的数据库插入操作相对应的跟踪信息：</p><p><code lang=\"null\">{ .db.statement =~ \"INSERT.*\"} | avg(duration) &gt; 1s</code></p><p>&nbsp;</p><p>TraceQL支持<a href=\"https://github.com/grafana/tempo/blob/main/docs/design-proposals/2022-04%20TraceQL%20Concepts.md\">使用span</a>\"、时间点和时间段来选择跟踪信息，它可以聚合同一个跟踪信息中的多个span的数据，并利用span之间的结构关系。查询由一组被选中或被丢弃的span集合的链式表达式组成，例如：</p><p><code lang=\"null\">{ .http.status = 200 } | by(.namespace) | count() &gt; 3</code></p><p>&nbsp;</p><p>它支持属性字段、包含字段的表达式、组合并聚合span集合、分组、管道，等等。下面的示例展示了如何过滤所有按照特定的顺序经过两个区域的跟踪信息：</p><p><code lang=\"null\">{ .region = \"eu-west-0\" } &gt;&gt; { .region = \"eu-west-1\" }</code></p><p>&nbsp;</p><p>TraceQL可感知数据类型，这意味着你可以使用文本、整数和其他数据类型来表示查询。此外，TraceQL兼容Tempo 2.0中的<a href=\"https://parquet.apache.org/\">Apache Parquet</a>\"存储格式。Parquet是一种列式数据文件格式，许多数据库和分析工具都支持这种格式。</p><p>&nbsp;</p><p>如上所述，TraceQL将成为Tempo 2.0的一部分，后者将在未来几周内发布，<a href=\"https://grafana.com/grafana/download/9.3.1?edition=oss&amp;mdm=rss&amp;platform=docker&amp;src=grafana\">Grafana 9.3.1</a>\"中已经内置了其预览版本。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/12/grafana-traceql/\">https://www.infoq.com/news/2022/12/grafana-traceql/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://xie.infoq.cn/article/2723176da5693f6085c6b1e78\">一文带你了解&nbsp;Grafana&nbsp;最新开源项目 Mimir 的前世今生</a>\"</p><p><a href=\"https://www.infoq.cn/article/e2B77jUHkWSRmgN9G7uV\">Grafana、Loki 和 Tempo 更改开源协议，由 Apache License 2.0 转为 AGPL v3</a>\"</p><p><a href=\"https://www.infoq.cn/article/k2tWvtKrSIpKIxloqfdN\">Grafana&nbsp;9 在警报和用户体验方面带来巨大改进</a>\"</p>",
    "publish_time": "2023-01-05 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "消息称微软将投资自动驾驶初创公司Gatik，后者估值超7亿美元",
    "url": "https://www.infoq.cn/article/yQW1dCHFQemYLSuHx0Tf",
    "summary": "<p>当地时间1月4日，据路透社报道，据两名知情人士透露，微软公司正在就投资<a href=\"https://gatik.ai/\">自动驾驶初创公司 Gatik </a>\"进行高级谈判，这也是双方进行云计算合作的一部分。</p><p>&nbsp;</p><p>据悉，Gatik公司总部位于加州，由行业资深人士 Gautam Narang 和 Arjun Narang 于 2017 年创立，专注于零售业的中等距离B2B物流。</p><p>&nbsp;</p><p>自从 2021 年以来，该公司已经与沃尔玛和 Loblaw Companies 合作推出了全无人驾驶商业配送服务，Gatik 负责在美国阿肯色州和加拿大安大略省提供厢式货车的短途配送服务。</p><p>&nbsp;</p><p>迄今为止，Gatik公司已经融资超过 1.2 亿美元，投资者包括 Koch Disruptive Technologies、Innovation Endeavors、Goodyear Ventures 和 RyderVentures。</p><p>&nbsp;</p><p>今年第一季度，Gatik 计划将该公司的自动驾驶箱式货车整合到 Pitney Bowes 位于美国得州达拉斯市的电子商务物流网络中，以期改善配送效率和降低物流成本。</p><p>&nbsp;</p><p>消息人士补充说，此次<a href=\"https://www.infoq.cn/article/kAa4265g8zfsKVXm1MG3\">微软</a>\"计划为Gatik投资超过1000万美元，对 Gatik的估值也超过7亿美元。作为该交易的一部分，Gatik 将使用微软的云和边缘计算平台 Azure 来开发卡车无人驾驶交付技术。</p><p>&nbsp;</p><p>知情人士称，该交易的具体条款仍有可能发生变化。</p><p>&nbsp;</p><p>截至发稿前，<a href=\"https://www.infoq.cn/article/FJhulyO6mpox7bqqZIg4\">微软</a>\"和Gatik均拒绝对此置评。</p><p>&nbsp;</p><p>与其他大型科技公司一样，微软最近一直在向<a href=\"https://www.infoq.cn/article/JElWUoZJokAshqchaiBw\">自动驾驶</a>\"技术投入资金。2021年1月，微软投资了通用汽车旗下的机器人出租车公司 Gruise，这笔交易对该公司的估值为300亿美元。Cruise 计划使用微软 Azure 来加快无人驾驶汽车解决方案的商用步伐，并与 Alphabet 旗下的 Waymo 和亚马逊旗下的 Zoox 展开竞争。</p><p>&nbsp;</p><p>自动驾驶技术被视为运输和物流行业的革命性技术，但由于监管机构担心安全问题，加之市场增长放缓导致资金匮乏，使得整个行业面临挫折。</p><p>&nbsp;</p><p>2022年11月，福特和大众关闭了他们的自动驾驶技术部门 <a href=\"https://www.infoq.cn/article/bucqgwcQO7KSPctEc3oV\">Argo AI</a>\"，称开发无人驾驶机器人出租车“比把人类送上月球还难”。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.reuters.com/business/autos-transportation/microsoft-invest-autonomous-trucking-startup-gatik-sources-2023-01-04/\">https://www.reuters.com/business/autos-transportation/microsoft-invest-autonomous-trucking-startup-gatik-sources-2023-01-04/</a>\"</p>",
    "publish_time": "2023-01-05 10:08:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Apache Doris 在小米亿级用户行为分析平台的实践",
    "url": "https://www.infoq.cn/article/iT7purpsKqaPwr8Touco",
    "summary": "<p></p><blockquote>作者｜小米数据智能部开发工程师 汤佳树编辑｜SelectDB</blockquote><p></p><p></p><p>小米用户行为分析统一平台是基于海量数据的一站式、全场景、多模型、多维度、自助式大数据智能洞察分析服务平台，对接各类数据源，进行加工处理、分析挖掘和可视化展现，满足各类用户在用户洞察场景下的数据分析应用需求，提供高效极致的分析体验。</p><p></p><h1>业务需求</h1><p></p><p></p><p>平台可以基于数据进行时间分析，留存分析，分布分析，漏斗分析等，业务方主要基于事件进行分析，事件是追踪或记录的用户行为或业务过程，可以是单个事件也可以是多个事件组合的虚拟事件。</p><p></p><p>数据来源于各业务的打点数据，且基于事件模型进行建模，用户在产品中的各种操作都可以抽象成 Event 实体，并且里面都会包含五要素：</p><p></p><p>Who：即参与这个事件的用户是谁，例如用户的唯一 IDWhen：即这个事件发生的实际时间，例如time字段，记录精确到毫秒的事件发生时间Where：即事件发生的地点，例如根据 IP 解析出的省份和城市How：即用户从事这个事件的方式，例如用户的设备，使用的浏览器，使用的 App 版本等等What：描述用户所做的这件事件的具体内容，例如点击类型的事件，需要记录的字段有点击 URL，点击 Title，点击位置等</p><p></p><p>数据基于 OLAP 引擎 Doris 进行存储，随着接入业务不断增多，且接入的业务量不断膨胀，Top 级应用可以达到 100 亿条/天，查询压力和时间相继增大，用户对查询时延的吐槽愈来愈多，我们急切的需要提升查询性能来提升用户的体验。</p><p></p><h1>痛点问题</h1><p></p><p></p><p>针对于业务需求，我们总结了以下痛点问题：</p><p></p><p>为了实现复杂的业务需求，OLAP 分析引擎需要留存、漏斗等分析函数支撑。增量数据 100亿/天，导入压力大，部分业务要求数据导入不丢不重。业务接入不断增多，数据量膨胀，需要 PB 级的数据下的交互式分析查询达到秒级响应。</p><p></p><p>为了解决以上的痛点问题，我们对比了多款 OLAP 分析引擎，最终选择了 Apache Doris。Doris 提供了留存、漏斗分析等函数，极大程度的简化了开发的成本。在数据导入的过程中，我们尝试 Doris 刚推出的 <a href=\"http://mp.weixin.qq.com/s?__biz=Mzg3Njc2NDAwOA==&amp;mid=2247512201&amp;idx=1&amp;sn=13e743781165eb3b28cef0a98aa09902&amp;chksm=cf2fbe8ef858379879dcb3769285759c74515b6a7d069cea8e445c5200e053e4da44e8ff4b17&amp;scene=21#wechat_redirect\">Merge On Write Unique Key</a>\" 导入模型，可以抗住 100 亿/天的增量数据压力。针对于向量化查询引擎的改造也是的性能较之前的版本有 3-5 倍的提升。</p><p></p><h1>架构演进</h1><p></p><p></p><p>一个优秀的系统离不开持续迭代与演进。为了更好的满足业务需求，我们在存储架构与查询引擎两个层面上不断进行尝试，小米用户行为分析系统在上线后，目前已完成 3 次改造，以下将为大家介绍改造历程。</p><p></p><h2>数据存储结构：数据架构的演进</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/79/79026c1e0c92aab3c4444ef499032e00.png\" /></p><p></p><p>在小米的用户行为分析平台中，原始数据通过小米自研的消息队列 Talos，在 Flink 中清洗与建模后，被下游的 Doris 与 Hive 消费。全量的数据会存储在 Hive 中，进行批量 ETL 或历史数据召回的查询。实时增量数据被存储在 Doris 中，用来做热数据的查询操作。基于冷热数据分离的架构，我们进行了 3 次架构的演进。</p><p></p><h3>第一阶段：基于明细宽表的查询</h3><p></p><p></p><p>在最初的阶段我们使用了基于明细的宽表查询模式。为了处理灵活多样的分析请求，在系统中，我们配合统一埋点平台处理数据，接入的 OLAP 的数据是直接埋点的全字段展平。在入库之前，我们在 Flink 中将数据打平，以宽表的模式存储在 Doris 明细表中。根据查询的需求，我们将经常使用的列作为建表的维度列，利用前缀索引的特性进行查询加速。但某些头部大数据量业务容易查询多天数据，一个大查询可能就会将集群资源占满甚至导致集群不可用，且查询耗时相当之久。</p><p></p><h3>第二阶段：基于聚合模型的查询加速</h3><p></p><p></p><p>在改造的第二阶段，我们使用了聚合模型对业务查询进行加速。 我们对接入行为分析的应用进行统计分析，绝大多数接入行为分析的应用数据量在 1 亿/天数据量以内。对于部分使用频率较高的表，我们采用聚合表完成查询加速，对单天数据量超 10 亿且高频的头部应用做聚合表加速。具体流程为根据数据量挑选出头部应用，对其进行字段解析，并挑选出常用指标及维度，由 Hive 表数据进行聚合 T-1 产出数据，最后写入到 Doris 中，进行查询加速。该阶段的改造解决了集群头部业务大查询的问题，此时虽然独立集群存储没问题，但由于其他业务接入后还会持续增加数据量和埋点字段 ，这样会导致元数据最先进入瓶颈。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/99/994259848095bea0234db963d87decc6.png\" /></p><p></p><h3>第三阶段（当前阶段）：业务适配的建表改造</h3><p></p><p></p><p>当前阶段，我们对业务需求进行深度解析后重新规划了建表结构。我们对某些应用的埋点字段进行分析，发现有些用户埋点字段多达 500+，但在行为分析里实际用到的可能只有 100+，这显然有所浪费。所以我们与用户沟通调研需求，配合行为分析平台侧的能力，用户可在平台对有用事件和属性进行筛选，同时设置字段映射和过滤逻辑，然后再进行建表。</p><p></p><h2>查询服务架构：查询引擎的改造与演进</h2><p></p><p></p><p>我们基于业务深度改造了查询的服务架构，构建了新的查询引擎架构，实现 SQL 的权重、路由、缓存和资源调度操作。根据查询条件，路由引擎会将 SQL 拆分成多条子查询，在 Doris 或 Hive 中执行后，将子查询的结果汇总，得到最终的结果。针对查询引擎，我们也进行了 3 次技术架构的改造。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/42/42d78a8d362bf4feb222dcd707f1d40a.png\" /></p><p></p><h3>第一阶段：基于集群粒度的查询资源管理</h3><p></p><p></p><p>我们对集群粒度进行查询资源管理，在资源调度中，我们会给每一个 Doris 集群设置一个总的资源池大小（根据集群能力和测试进行量化），根据数据量大小和查询天数对每个 SQL 进行加权，并对资源池的最大最小并行 SQL 数进行限制，如果计算的 SQL 超过限制则进行排队。其次，还会利用 Redis 对数据进行 SQL 级别缓存。</p><p></p><h3>第二阶段：基于 SQL 路由的改造</h3><p></p><p></p><p>为适配聚合表加速做了路由层，提升缓存命中率和利用率，此阶段拆分原始提交 SQL，基于指标进行缓存，粒度更细，服务端可根据指标进行适当计算更易于缓存命中。值得一提的是排队时间往往会比较长，有些场景下可能会进行重复提交或拆分成同样的 SQL，为了提高效率会在 SQL 排队前和排队后各进行一次缓存校验。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ac/acbc39babd523f934b0f89f265ebe54a.png\" /></p><p></p><h3>第三阶段（当前阶段）：基于 SQL 权重的改造</h3><p></p><p></p><p>整体架构方面，由于采取了筛选埋点字段而非全量字段导入 Doris，针对头部问题用户，我们会基于查询历史统计指标及维度，根据指定的某些规则进行默认初始化操作，并以此沟通用户并进行引导升级。此外为了更精细的控制资源调度，本阶段对对 SQL 内容进行加权，如含有DISTINCT，LIKE，VARIANCE_SAMP等字样再加权。对于资源消耗较大的操作，如 DISTINCT，会给予更高的权重，调度引擎在执行时会分配更多的资源。</p><p></p><h1>实践应用</h1><p></p><p></p><p>数据建模</p><p></p><p>对业务来讲，分析查询需要较高的灵活度，且是对用户粒度进行分析，所以需要保留较多的维度和指标，我们选用 Doris 作为存储查询引擎，且采用明细表建模，这样可以保证用户能够根据分析需求查出数据。另一方面，由于查询分析是一个延时要求较高的产品，对于数据量大、查询天数多、语句复杂的情况，查询延时会很高，所以对于头部应用，我们根据高频指标维度进行了聚合表模型建模。</p><p></p><p><code lang=\"sql\"> CREATE TABLE `doris_XXX_event` (\n  `olap_date` bigint(20) NOT NULL COMMENT \"\",\n  `event_name` varchar(256) NOT NULL COMMENT \"\",\n  `uniq_id` varchar(256) NOT NULL COMMENT \"\",\n  `dim1` varchar(256) REPLACE NULL COMMENT \"\",\n  `dim2` varchar(256) REPLACE NULL COMMENT \"\",\n  ...\n  `cnt` bigint(20) REPLACE NULL COMMENT \"\",\n  `index1` double REPLACE NULL COMMENT \"\",\n  `index2` double REPLACE NULL COMMENT \"\",\n  ...\n) ENGINE=OLAP\nAGGREGATE KEY(`olap_date`, `event_name`, `uniq_id`)\nCOMMENT \"OLAP\"\nPARTITION BY RANGE(`olap_date`)</code></p><p></p><p>数据导入</p><p></p><p>明细表部分，我们接入 Json 格式 TalosTopic，动态获取 Doris 表的 Schema 信息，通过双缓冲区循环攒批的方式，利用 StreamLoad 向 Doris 中写数据，如果在导入 Doris 时有出现失败的批次，重试 10 次仍然失败，会将数据按照应用粒度存入 HDFS，并在凌晨定时调度任务重新写入 T-1 未写入的数据。聚合表部分，我们由 Talos 落盘的 Iceberg 表，每日进行 T-1 数据的聚合，根据服务端选取的维度和指标，以及聚合类型（count ,count distinct , sum ,max ,min ），进行聚合存入中间 Hive 表，再由统一导入 Doris 程序进行导入。</p><p></p><p>数据管理</p><p></p><p>明细数据和应用聚合表分库存储，TTL 均为 33 天。数据表会有数据质量监控，如果总行数或者设置指标环比波动太大，会进行告警人工介入确认数据是否有误，视紧急程度进行回补处理。</p><p></p><p>数据查询及应用</p><p></p><p>绝大多数用户会锚定事件，进行含指标聚合，去重用户数（几乎占总查询的 50%）的事件行为分析，同时还会有留存分析，漏斗分析，分布分析等分析类型。</p><p></p><p>建表模型的维护</p><p></p><p>为了适配业务的变更，上游的埋点信息会周期性的更新。原有的表结构需要进行变更以适配埋点的增加。在过去的 Doris 版本中，Schema Change 是一项相对消耗较大的工作，需要对文件进行修改。在<a href=\"http://mp.weixin.qq.com/s?__biz=Mzg3Njc2NDAwOA==&amp;mid=2247509133&amp;idx=1&amp;sn=a1c5a66404c0ceb0cd3015a4f2e13b9a&amp;chksm=cf2faa8af858239c761a46e4f729191cce45cd8cd0e5e1dfd78e8a7263f32661814c590306af&amp;scene=21#wechat_redirect\">新版本中开启 Light Schema Change 功能后</a>\" ， 对于增减列的操作不需要修改文件，只需要修改 FE 中的元数据，从而实现毫秒级的 Schame Change 操作。</p><p></p><h1>应用现状</h1><p></p><p></p><p>小米目前在 300 多个业务线上线了 Doris 集群，超过 1.5PB 的业务数据。在初期我们选择了两个使用较为频繁的集群进行向量化升级。</p><p></p><p>现迁移 Doris 向量化集群的行为分析业务有 2 个，7 天增量数据的平均值在百亿左右，存储空间占用 7T/天左右。在升级到向量化的版本后，存储资源有较大的节省，只需要原有集群约 2/3 的存储空间。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/21/2113287a96fb92fae409ad675e128a50.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1b/1b3827026c93b1cd0a6286f569f723ff.png\" /></p><p></p><h1>性能提升</h1><p></p><p></p><h2>请求粒度</h2><p></p><p></p><p>升级 Doris 向量化版本后，行为分析平台以请求粒度统计查询耗时 P80 和均值，P80 耗时下降 43% ，平均耗时下降 27% ；统计口径：汇总 12.07-12.11 期间，行为分析请求粒度查询执行时间。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/31/3162d30d6d313bfa349b3cf3f2b1a24e.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/60/6013a31e2d7e4ff187dbbd15d7e2410e.png\" /></p><p></p><h2>SQL 粒度</h2><p></p><p></p><p>升级 Doris 向量化版本后，行为分析平台以 SQL 粒度来统计查询耗时 P80 和均值，耗时 P80 下降 70% ，平均耗时下降 54% 。统计口径：汇总 12.04-12.11 期间，行为分析 SQL 粒度查询执行时间（未含排队）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c1/c1dcb20e203d5576f90fac0224ccf60b.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/9636245b7d709c8324a7369d23651c7d.png\" /></p><p></p><p>升级 Doris 向量化版本后，行为分析平台以 SQL 粒度统计查询耗时 P80 和均值，耗时 P80 下降 56% ，平均耗时下降 44% ；</p><p></p><p>统计口径：汇总 12.02-12.11，行为分析 SQL 粒度查询总时间 （含排队）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/40/405af931262151e61f28b8108dda4351.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/79/79aa7f0734f5982ed85dc1f85978cfb4.png\" /></p><p></p><h2>去重优化</h2><p></p><p></p><p>在 ID-Mapping 的时候，通常需要针对 ID 进行去重操作。在最初我们使用了COUNT DISTINCT来完成去重。</p><p></p><p><code lang=\"sql\">SELECT      a.`olap_date` AS `time`, \n            count(distinct a.`distinct_id`) AS distinct_id \nFROM        analysis.doris_XXX_event a \nWHERE       `a`.`olap_date` BETWEEN 20221218 AND 20221220 AND \n            a.`event_name` IN(XXXX, XXX, XXX, XXX) AND \n            ... ... \nGROUP BY    1 \nORDER BY    2 DESC \nLIMIT       10000</code></p><p></p><p>在经过优化后，我们使用子查询+ GROUP BY来替代COUNT DISTINCT的功能</p><p></p><p><code lang=\"sql\">SELECT      z.`time`, \n            count(distinct_id) var1 \nFROM        (SELECT     a.`olap_date` AS `time`, \n                        a.`distinct_id` AS distinct_id \n            FROM        analysis.doris_XXX_event a \n            WHERE       `a`.`olap_date` BETWEEN 20221218 AND 20221220 AND \n                        a.`event_name` (XXXX, XXX, XXX, XXX) AND \n                        ... ...\n            GROUP BY 1, 2) z \nGROUP BY    1 \nORDER BY    2 DESC \nLIMIT       10000</code></p><p></p><p>相较于原有的COUNT DISTINCT，使用子查询+ GROUP BY 的模式性能有 1/3 的提升。</p><p></p><h1>未来规划</h1><p></p><p></p><p>在过去的三年时间里，Apache Doris 已经在小米内部得到了广泛的应用，支持了集团数据看板、广告投放/广告 BI、新零售、用户行为分析、A/B 实验平台、天星数科、小米有品、用户画像、小米造车等小米内部数十个业务，并且在小米内部形成了一套以 Apache Doris 为核心的数据生态 。随着业务的持续增长，未来我们会进一步推动小米的其他业务上线向量化版本。</p><p></p><p>非常感谢 Apache Doris 社区与 SelectDB 公司的鼎力支持，小米集团作为 Apache Doris 最早期的用户之一，一直深度参与社区建设，参与 Apache Doris 的稳定性打磨，未来我们也会密切联系社区，为社区贡献更多的力量。</p>",
    "publish_time": "2023-01-05 10:27:51",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从编译到可执行，eBPF 加速容器网络原理分析",
    "url": "https://www.infoq.cn/article/xpBcjM5O7PeRlteVXWQE",
    "summary": "<p></p><blockquote><a href=\"https://xie.infoq.cn/article/4740fad28050c331ea9d329df\">eBPF</a>\"(extended Berkeley Packet Filter) 是一种可以在 Linux 内核中运行用户编写的程序，而不需要修改内核代码或加载内核模块的技术。简单说，eBPF 让 <a href=\"https://www.infoq.cn/article/4lDxHRoqXbSw6zl29AEo\">Linux</a>\" 内核变得可编程化了。本文整理自龙蜥大讲堂第 57 期，浪潮信息 SE 王传国从原理上分析了 eBPF 的加载工作过程，解释了它如何保证系统运行稳定以及它能加速网络的原因。</blockquote><p></p><p></p><h2>1. eBPF 加载过程</h2><p></p><p></p><p>我们知道，一般 eBPF 的加载过程，首先是写&nbsp;C 代码，然后用 llvm lang 编译成&nbsp; ELF 文件，接着用 libelf 对&nbsp;ELF&nbsp;文件进行解析，解析之后按照 libbpf 所需要的格式进行数据的整理、组织，再通过 BPF 的系统调用，可以将这些数据都加载到内核里面，包括程序翻译出来的 eBPF 指令集。</p><p></p><p>在内核里面有校验器负责对程序进行校验，有 JIT 对程序进行翻译解析。</p><p></p><h4>1.1 重定位</h4><p></p><p></p><p>BPF 基础设施提供了一组有限的“稳定接口”， 使用 convert_ctx_access 对各种 CTX 进行转换，在内核版本升级时保证稳定。</p><p></p><p>CO-RE 核心思想就是采用(BTF)非硬编码的形式对成员在结构中的偏移位置进行描述，解决不同版本之间的差异。</p><p></p><p>需要重定位的元素：Map、函数调用、Helper函数调用、字段、Extern 内核符号和kconfig。</p><p></p><h4>1.2 安全性检查：数据、指令、循环</h4><p></p><p></p><p>数学计算除数不能为 0，指令调用范围[0, prog-&gt;len)深度优先遍历排除环。</p><p></p><h4>1.3 eBPF 指令集</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/69/69d44b84bf70de0cf3650c18c2aef55d.png\" /></p><p></p><h4>1.4 指针安全性检查</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dd/ddd2c0f2de215b96b804e3cda0f3a23a.png\" /></p><p></p><p>确定指针类型、范围纠正，识别不了的指针类型不允许引用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/14/14bc918c8f8cbe676585133fcb738e36.png\" /></p><p></p><p>范围检查，不同的指针类型有不同的检查方法和范围。</p><p></p><h2>2. eBPF&nbsp;加速容器网络</h2><p></p><p></p><p>主要涉及的 eBPF 程序类型：XDP、tc、sock_ops。</p><p></p><p>它们加速网络性能的基本原理都是把数据直接从一端（网口/socket）的发送队列传递到另一端的接收或发送队列，绕过不需要的网络协议栈。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ce/ce278ff54bbe200e08db28af012d010b.png\" /></p><p></p><p>XDP 位于整个 Linux 内核网络软件栈的底部，还未生成 skb，能够非常早地识别并丢弃攻击报文，具有很高的性能；但是在虚拟机中有时候可能无法支持 XDP 程序的加载，例如虚拟机网卡的接收队列太少。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/55/55016b4f999908d23edf234cc9414ddd.png\" /></p><p></p><p>在 tc 功能的 sch_handle_ingress、sch_handle_egress 添加 hook 点，分别是 tc ingress 和 tc egress，没有 XDP 那么多要求，基本上所有的 OS 中都能使用，绕过 netfilter 等非必要的内核网络协议栈路径，能极大地提升网络性能，降低延迟。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/15/15084f0089e2b8b54ea77c4b0561f2e6.png\" /></p><p></p><p>技术概述：把数据从一端 socket 发送队列直接发送到对端 socket 的接收队列或发送队列。</p><p>sockops：挂载到cgroup，监控整个 cgroup 中所有 socket 的握手和挥手（主动|被动），记录 tcp 连接。</p><p>sockmap：存储数据特征与 socket 句柄的关系。写数据时执行 bpf_map_update，修改对应 socket 的 sendmsg 函数指针。</p><p>sk_msg：使用 sockmap 对数据进行 redirect 判定。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1b/1bfbf86749340e9360ae5a58bdab060d.png\" /></p><p></p><p>经过我们的测试，如果用 <a href=\"https://xie.infoq.cn/article/69592432882ccce6cc3fbd177\">Cilium</a>\" 替换 calico，用 TCP Throughput 模式测，那么&nbsp;pod 间的通讯性能&nbsp;tcp 吞吐量提升 58%、sockops 提升 153%、跨节点也能提升 24%。</p><p></p><p>如果用 TCP-RR 模式来测，那么相比 calico 同节点能提升 28%、sockops 提升200.82%、跨节点提升 43%。</p><p></p><p>如果用&nbsp;TCP_CRR&nbsp;模式去测的话，&nbsp;calico&nbsp;同节点能提升40%、sockops 提升 35% 、跨节点提升 55%。&nbsp;</p><p></p><p>Cilium&nbsp;在提升性能的时候，它对于 CPU 的占用降低了&nbsp;10% 以上，因此我们测试的结果是&nbsp;Cilium&nbsp;的性能要明显优于使用 iptables 的&nbsp;calico。所以说目前我们打算使用&nbsp;Cilium&nbsp;优化我们的容器网络。</p>",
    "publish_time": "2023-01-05 10:58:18",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "谷歌推出文本到图像模型Muse：生成图片质量更高、推理时间更短",
    "url": "https://www.infoq.cn/article/zIcEM3fpYm9zfvvcYUSu",
    "summary": "<p>自 2021 年初以来，随着大量深度学习支持的文本到图像模型（例如<a href=\"https://analyticsindiamag.com/choose-your-player-dall-e-2-or-midjourney/\">DALL-E-2</a>\"、<a href=\"https://analyticsindiamag.com/stability-ai-releases-stable-diffusion-2-0/\">Stable Diffusion</a>\"和<a href=\"https://analyticsindiamag.com/this-scariest-horror-movie-was-made-using-midjourney/\">Midjourney</a>\"等）的诞生，人工智能研究的进展发生了革命性的变化。</p><p>&nbsp;</p><p>近日，<a href=\"https://www.infoq.cn/article/76gYqPA2YU0YXCDHFvIE\">谷歌</a>\"Muse AI系统正式亮相。据谷歌Muse AI团队称，Muse是一种文本到图像的 Transformer 模型，该模型可以实现先进的图像生成性能。&nbsp;</p><p>&nbsp;</p><p></p><blockquote>我们提出Muse，一种文本到图像的 Transformer 模型，可实现先进的图像生成性能，同时比扩散或自回归模型更有效。——谷歌Muse AI团队</blockquote><p></p><p>&nbsp;</p><p>据开发团队介绍，与<a href=\"https://www.infoq.cn/article/BKPTWSyeidEDNaoBvEKv\"> Imagen </a>\"和 <a href=\"https://www.infoq.cn/article/SwDArsl8afPV6baZRyE0\">DALL-E 2</a>\" 等像素空间扩散模型相比，Muse 由于使用离散标记并且需要更少的采样迭代，因此效率显着提高；与 <a href=\"https://github.com/google-research/parti\">Parti </a>\"和其他自回归模型不同，<a href=\"https://muse-model.github.io/\">Muse </a>\"利用了并行解码。 为了生成高质量的图像并识别物体、它们的空间关系、姿态、基数等视觉概念，使用预训练的 LLM 可以实现细粒度的语言理解。Muse 还可以直接启用许多图像编辑应用程序，而无需微调或反转模型：修复、修复和无蒙版编辑。</p><p>&nbsp;</p><p>Muse的900M 参数模型在 CC3M 上实现了新的 SOTA，FID 得分为 6.06。Muse 3B 参数模型在零样本 COCO 评估中实现了 7.88 的 FID，以及 0.32 的 CLIP 分数。Muse 还可以直接启用许多图像编辑应用程序，而无需微调或反转模型：修复、修复和无蒙版编辑。</p><p>&nbsp;</p><p>Muse模型能够根据文本提示快速生成高质量图像：在 TPUv4 上，512x512 分辨率为 1.3 秒，256x256 分辨率为 0.5 秒。</p><p>&nbsp;</p><p>根据 MUSE 的基准测试可以看出，Muse 的推理时间明显低于竞争模型。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/f5/f58f561c185e85afe800916a2b119952.png\" /></p><p></p><p>参考链接：</p><p>&nbsp;</p><p><a href=\"https://muse-model.github.io/\">https://muse-model.github.io/</a>\"</p><p><a href=\"https://dataconomy.com/2023/01/google-muse-ai-explained-how-does-it-work/\">https://dataconomy.com/2023/01/google-muse-ai-explained-how-does-it-work/</a>\"</p>",
    "publish_time": "2023-01-05 11:43:08",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]