[
  {
    "title": "LinkedIn 将 Espresso 从 HTTP1.1 迁移到 HTTP2，连接数减少 88%，延迟降低 75%",
    "url": "https://www.infoq.cn/article/GMWGJZzawHaXiklM7eBA",
    "summary": "<p>LinkedIn 将其 Espresso 数据库从 HTTP/1.1 迁移到 HTTP/2，极大 提升 了可伸缩性和性能，减少了连接数量、降低了延迟并缩短了垃圾回收时间。为了获得这些好处，团队不得不优化 Netty 默认的 HTTP/2 栈来满足需求。</p><p></p><p>LinkedIn 使用 Espresso（构建在 MySQL 之上的文档平台）来存储和提供大部分数据。随着 LinkedIn 平台的有机增长，数据量不断增加，迫使公司不断扩展 Espresso 集群的规模，并进行优化工作，例如为 Espresso 引入 集中式缓存层 或者 采用 Protocol Buffers 进行服务间通信。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/91/916c9aa7e511e0aafce5cdbeb793dc14.png\" /></p><p></p><p>Espresso 高层架构（来源：LinkedIn Engineering Blog）</p><p></p><p>Espresso 的事务栈包括两个主要组件：路由器和存储节点。路由器负责将请求发送到正确的存储节点上，存储节点负责与 MySQL 集群进行交互，并相应地调整数据格式。这些组件之间的通信使用 HTTP 协议，更具体地说是使用了 Netty 框架。随着时间推移，团队发现到 Espresso 集群的规模增长导致可伸缩性下降。</p><p></p><p>最近增加的 100 个路由器节点导致存储节点内存使用量增加，额外的垃圾回收导致延迟增加了 15%。此外，由于增加了大量的 HTTP/1.1 连接，从连接池中获取连接所需的时间达到了几毫秒。最后，在发生网络事件（如交换机升级）期间，由于达到存储节点的连接限制，重新建立数千个连接可能会导致错误。</p><p></p><p>LinkedIn 的软件工程师 &nbsp;Abhishek Andhavarapu 解释了 HTTP/1.1 和 HTTP/2 之间的差异，以及这些差异如何影响 Espresso 平台的可伸缩性和性能：</p><p></p><p></p><blockquote>对于路由器与存储层之间的通信，我们早期的方法是使用了 HTTP/1.1，这是一种广泛用于 Web 服务器和客户端之间交互的协议。然而，HTTP/1.1 是基于每个请求连接的，在大规模集群中，这种方法会导致路由器和存储节点之间产生数百万个并发连接。这导致了可伸缩性、弹性和众多与性能相关的障碍。团队决定在进行 HTTP/2 迁移时继续使用 Netty 框架，但很快发现其性能并不理想（比 HTTP/1.1 实现的吞吐量低 45%，延迟高 60% 左右），因此工程师们不得不去解决 HTTP/2 栈的性能瓶颈。在经过一番诊断后，他们确定了两个改进方向：获取连接和处理请求，以及请求的编码 / 解码。</blockquote><p></p><p></p><p>开发人员通过修改几个内部的 Netty 实现细节来增强功能。他们创建了一个可以重复使用已有通道的处理程序，避免为每个请求创建新的处理通道。他们还引入了一个自定义的 EventLoopGroup 实现，可以更均匀地在工作线程之间平衡连接。为了减少获取连接时的上下文切换，团队重新设计了连接池实现，使用了高性能、线程安全的队列。</p><p></p><p>此外，SSL 处理使用原生的、基于 JNI 的 SSL 引擎进行了优化，并使用自定义的 SSL 初始化逻辑避免了冗长的 DNS 查找延迟。最后，团队通过创建自定义编解码器来优化编码 / 解码性能，编解码器将 HTTP/2 请求封装为 HTTP/1.1 请求，帮助处理 Espresso 使用的许多自定义 HTTP 标头，并禁用了 HPACK 标头压缩。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a1/a105f8a2d023cd058e5de92a376064bb.png\" /></p><p></p><p>迁移到 HTTP/2 后延迟减少（来源：LinkedIn Engineering Blog）</p><p></p><p>团队报告称，在所有这些定制化改进之后，迁移到 HTTP/2 带来了明显的性能改进，相较于 HTTP/1.1，TCP 连接数量减少了 88%，延迟降低了 65% 至 75%，垃圾回收时间减少了 75% 至 81%，获取连接的等待时间从 11 毫秒 降至 0.02 毫秒（改进了 99%）。</p><p></p><p>英文原文：</p><p><a href=\"https://www.infoq.com/news/2023/12/linkedin-espresso-http2/\">https://www.infoq.com/news/2023/12/linkedin-espresso-http2/</a>\"</p>",
    "publish_time": "2023-12-20 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "基于共享存储的 leader 选举：在存算分离架构云数仓 ByConity 中的实践",
    "url": "https://www.infoq.cn/article/NmUUxzcCmmF2CG4Ltygp",
    "summary": "<p>本文作者｜Yuan Zhu</p><p></p><p></p><blockquote>ByConity 0.3.0 版本本周发布，其中「基于共享存储的选主方式」作为 0.3.0 版本的主要功能将在此次更新中实现。本文将介绍其在 ByConity 中的设计思考与实践。项目地址｜<a href=\"https://github.com/ByConity/ByConity\">https://github.com/ByConity/ByConity</a>\"</blockquote><p></p><p></p><p></p><h2>背景</h2><p></p><p></p><p>在传统常见的分布式 share-nothing 微服务架构中，我们通常使用 DNS 这类成熟方案来进行节点之间的服务发现，使用 Zookeeper、Etcd、Consul 这类成熟组件在副本节点之间进行 leader-follower 选举以实现集群的高可用，在配置、使用、运维管理都有一定的复杂度。</p><p></p><p>在越来越多的分布式系统中使用一份高可用存储来实现 share-everything 存算分离架构的今天，我们可以利用这块高可用存储来模拟单机系统里的共享内存，将不同的计算节点看成是单机系统里的进（线）程，模仿单机系统的方案来实现他们之间的发现、同步。</p><p></p><p>本文即介绍以上思想是如何在开源云原生数仓 ByConity 中设计和实践的。</p><p></p><p></p><h2>ByConity 的基本架构</h2><p></p><p></p><p>《<a href=\"http://mp.weixin.qq.com/s?__biz=MzkwMTQzMjc2OQ==&amp;mid=2247483778&amp;idx=1&amp;sn=06e9a9fe4180fa8c78079b45686a4bbe&amp;chksm=c0b5952cf7c21c3ac32f39c1008a7c0535af6b2cb7210ae2031953db91fd0b737b268310a66f&amp;scene=21#wechat_redirect\">谈谈 ByConity 存储计算分离架构和优势</a>\"》介绍了基于 ClickHouse 的开源云原生数仓 ByConity 的存算分离架构。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2e/2edbef28e971d3eed68614183d0ba54e.png\" /></p><p></p><p></p><p>可以看到，在计算一侧，存在多种控制节点，它们需要各自通过多副本 + 选主来提供高可用的服务能力，例如上图中的 Resource manager/Timestamp oracle 等。实际中的多个计算 server，也需要在选出一个单节点来执行特定的读写任务。</p><p></p><p>最早 ByConity 使用了 ClickHouse-keeper（以下简称\"keeper\"）组件来进行选主，该组件基于 Raft 实现，提供兼容 zookeeper 的选主接口，在实际使用中遇到了以下运维问题：</p><p>至少需要部署 3 个 keeper 节点，才能提供单个节点故障的容灾。这是因为 Raft 协议需要过半节点正常运行，才能维护主节点的正常工作和选举。节点增删和服务发现流程复杂。需要修改所有 keeper 节点的配置文件才能生效，且所有的调用者也需要修改配置才能发现这个结果。ByConity 实现过一个使用固定的共享域名来代替给每个 keeper 节点配置地址的方案，但又进一步带来了处理 域名解析的可访问节点数量和 keeper 中配置数量不一致时的复杂性。容器重启后如果服务变换 ip 和服务端口，ClickHouse-keeper 难以快速恢复。这不仅是因为 2，也是因为 keeper 实现中 raft 的 server_id 和监听地址进行了强绑定。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/42/42c5ee69f1baed46c43fb666c677f3f1.png\" /></p><p></p><p></p><p>我们可以把以上问题分类为：</p><p>故障时的容灾性能。高可用的运维、部署成本。</p><p></p><p>考虑到 ByConity 作为一个新的云原生服务，并不需要兼容 ClickHouse 对 zookeeper 的访问，我们选择了基于存算分离的云原生架构实现一种新的选主方式来优化以上问题。</p><p></p><p></p><h2>基于共享存储的 leader 选举</h2><p></p><p></p><h3>术语定义</h3><p></p><p></p><p>副本：地位相互平等的某个服务多个部署实例进程。业务：除了选举之外的服务逻辑。Follower：副本中不可提供业务服务的节点。Leader：副本中可提供业务服务的节点，本文也常把 leader 选举简称为“选主”。客户端：需要访问 leader 提供业务服务的节点。</p><p></p><h3>设计思想</h3><p></p><p></p><p>我们注意到如果一台计算机在试图同步多个线程对一个临界资源的访问竞争时，常见的 pthread_mutex 内存锁实现方案是非常简单的，依赖了以下基础：</p><p>锁被分配在一份所有线程可见的内存中；内存支持通过 CAS（Compare&nbsp;And&nbsp;Swap）指令实现小对象的原子写入；内存支持确保原子写入的结果，读者看到的写入顺序和写者的写入顺序一样；操作系统内核通过 futex 等系统调用指令，支持原子的等待 / 通知线程某个值的变化，使得线程知道某个资源又可以被竞争了。&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/d0/d07e62d508b75ff0638dbd3d0f3c1ac4.png\" /></p><p></p><p>如果我们把 ByConity 多个试图选主的节点看成不同的线程，把支持事务提交、可见性顺序等于事务提交顺序的 Foudation DB（用于存储 ByConity 元数据的高可用 KV 存储，以下简称为“FDB”）看成支持 CAS 写入、保证可见性顺序的本地内存，用节点的定期 Get 轮询去模拟 Linux 内核的线程唤醒通知机制，我们就可以用 ByConity 所使用的高可用 Foudation DB KV 存储，通过模拟 CAS 操作去同步多个节点之间对“谁是 leader”这个问题答案的竞争：谁 CAS 成功谁就是 leader。</p><p></p><p>解决了相互竞争的写者之间的同步，我们还需要把写者竞争的结果发布给读者。Linux 的锁的数据结构会记录谁是 mutex owner，这里也可以把 leader 的监听地址写入竞争的结果：CAS 的 key 写入内容 value 需要包括自己的监听地址。所以读者访问这个 key 就可以完成服务发现（读者不需要知道非 leader 的地址）。</p><p></p><p></p><h3>设计目标</h3><p></p><p></p><p>我们预期实现以下目标：</p><p>选举组件以一个库的形式嵌入业务服务进行使用。类似 linux mutex 使用的 pthread 库。支持任意多副本节点。增删节点无需额外操作。节点变更监听地址无需额外操作。只要有一个副本节点可用，即可选主成功。这是因为存算分离场景，节点本地无状态，任何一个节点都可以成为主节点，无需从其他副本同步状态到本地。副本节点之间无需相互通信和服务发现，包括无需进行物理时钟同步。</p><p></p><p>接下来，我们使用若干个分布式共识的达成来介绍如何具体去实现这些目标：</p><p>follower 之间对“谁是新 leader”达成共识。新旧 2 任 leader 对“如何让卸任和上任的时间不重叠”达成共识。服务端节点在配置变更时，对“选举的时间参数”在每一轮选举中达成共识。客户端如何感知“谁是新 leader”这个服务端产生的共识。</p><p></p><h3>follower 节点的角色共识：leader 选举的实现</h3><p></p><p></p><p>数据结构</p><p></p><p>分布式系统具有许多单机系统所不涉及的复杂性，其中最主要的一个复杂性来源就是有限操作时间限制和非全连通拓扑带来的不可访问：单机系统的任何读写内存操作都没有“超时”或者失败的概念，而分布式系统必须考虑这个点才能保证可用性。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e7/e79b6c515ead54d2b3b7888c13994d14.png\" /></p><p></p><p></p><p>所以如上图，对于 leader CAS 写入的数据结构 LeaderInfo，除了包括自己的监听地址 address，也需要包括关于绑定了时间相关的状态信息 lease：例如 leader 上任时间点 elected_time，最近一次刷新时间 last_refresh_time（有变化就证明自己还活着），刷新的时间间隔要求 refresh_interval_ms，多长时间不刷新就认为 leader 已经任期结束（其它节点可以开始重新竞争 leader 了）expired_interval_ms，以及 leader 的状态 status。</p><p></p><p>选举基本规则</p><p></p><p>每个节点要么是 follower，要么是 leader。预期系统内任何一个时间点，只有一个节点认为自己是 leader。任何节点都可以读 KV 存储中的一个 key （以下皆简称 “key”），从中得知 “谁是 leader”这个结果。如果这个 key 不存在，说明 leader 从未被成功选举。leader 定期 CAS 更新 key 中存储&nbsp;value（以下皆简称 “value”）的 lease.last_refresh_time 字段，延长自己的任期到 lease.last_refresh_time + lease.refresh_interval_ms。leader 遇到进程结束等服务可控停止时，可以 CAS 更新 value 的 lease.status 字段为 Yield，主动让出 leader 身份。每个 follower 定期 GET 读取 value，确认 leader 是否被成功选举、是否已经任期过期、是否已经让出 leader。如果是，那么 follower CAS 尝试更新 key 的 value 来竞选 leader，修改 address 为自己的地址。</p><p></p><p>接下来我们展开这个规则，介绍如何实际完成全流程的选举。</p><p></p><p>备选</p><p></p><p>前置条件</p><p>当前节点是 follower。</p><p></p><p>前置条件说明</p><p>每个节点启动后，都认为自己是 follower。每个 leader 在 lease 任期结束之前没有成功更新 lease，被认为任期过期（即 now()<=\"\" p=\"\"></p><p></p><p>动作</p><p>follower 每隔 lease.refresh_interval_ms 就去轮询读取 key 的结果，检测key 是否存在，或者 value 中的任期是否已经过期。</p><p></p><p>竞选</p><p></p><p>前置条件</p><p>当前节点是 follower。对于存算分离服务，我们认为每一个无状态副本都可以参与竞选，不存在状态机同步进度差异。key 不存在，或者 value 中的任期已经过期，或者 value 中的&nbsp;lease.status 是 Yield，或者&nbsp;value&nbsp;中的 address 是自己的监听地址。</p><p></p><p>动作</p><p>如果 key 不存在， 那么 Put if not exist 写入自己的地址信息。如果 value 中的任期已经过期或者 value 中的 address 是自己的监听地址，那么 Put CAS 写入自己的地址信息。写入的 lease 信息为：lease.status=Ready, lease.last_refresh_time=lease.elected_time=now(), lease.refresh_interval_ms 和 lease.expired_interval_ms 为配置文件中的信息。</p><p></p><p>胜选</p><p></p><p>前置条件</p><p>当前节点是 follower。当前节点写入 value 成功；或者虽然 CAS 失败，但是发现 value 的 address 是自己的监听地址。</p><p></p><p>动作</p><p>检查是否任期已过期，即当前时间 now() 是否满足 now()<=\"\" p=\"\"></p><p></p><p>就职</p><p></p><p>前置条件</p><p>当前节点胜选，且任期没有过期。</p><p></p><p>动作</p><p>调用业务侧注册的 onLeader() 回调，提醒业务可以以 leader 方式提供服务了。对于有状态的服务，可能在这个过程需要同步一些状态才能以 leader 方式提供服务；对于无状态服务（例如 ByConity 的存算分离计算节点），胜选即可立即就职服务。提供 isLeader() 接口供业务调用检查，仅在 now()<=\"\" p=\"\"></p><p></p><p>续任</p><p></p><p>前置条件</p><p>当前节点是 leader，且任期没有过期。可无限期连任。距离竞选或最近一次续任时间已经超过或等于 lease.refresh_interval_ms，即 now()&gt;=lease.last_refresh_time + lease.refresh_interval_ms 。</p><p></p><p>动作</p><p>CAS 设置&nbsp;value&nbsp;的&nbsp;lease.last_refresh_time = now()。</p><p></p><p>主动离职</p><p></p><p>前置条件</p><p>当前节点是 leader。被业务侧调用 yield() 接口。常见于服务退出等场景。</p><p></p><p>动作</p><p>调用业务侧注册的 onFollower() 回调，提醒业务不可以以 leader 方式提供服务了。CAS 更新&nbsp;value&nbsp;的 lease.status=Yield，lease.last_refresh_time=now()。当前节点变为 follower，即使 CAS 失败。</p><p></p><p>被动离职</p><p></p><p>前置条件</p><p>当前节点是 leader。now()&gt;=lease.last_refresh_time + lease.expired_interval_ms 或者在 CAS 更新 lease 发现被别的节点提前更新了。</p><p></p><p>动作</p><p>调用业务侧注册的 onFollower() 回调，提醒业务不可以以 leader 方式提供服务了。当前节点变为 follower。</p><p></p><p>总结</p><p></p><p>我们回顾一下预期的目标，可以看到都实现了。</p><p>支持任意多副本节点。它们只需要和共享存储 FDB 进行通信。增删节点无需额外操作。这是因为节点之间彼此都不互相服务发现和通信。节点变更监听地址无需额外操作。这是因为节点主动通过 CAS 写入自己的监听地址，无需类似 Raft 需要显式的节点减少再增加动作。只要有一个副本节点可用，即可选主成功。这是因为对于存算分离的无状态节点，任何副本都可以成为 leader。副本节点之间无需相互通信同步和服务发现，包括物理时钟同步。</p><p></p><p>但是不进行物理时钟同步，会不会产生 2 个 leader 的任期相互交叠，而给集群服务带来风险？我们在下一节分析这个问题。</p><p></p><h3>新旧 2 任 leader 的时间共识：对任期过期的判断</h3><p></p><p></p><p>问题描述</p><p></p><p>我们可以看到一个旧的 follower 节点胜选之后，可以立即就职提供 leader 服务。此时有没可能整个集群中有 2 个 leader，都在提供 leader 服务呢？</p><p></p><p>先定义需求：</p><p>新 leader 上任开始 leader 服务后，旧 leader 不再以 leader 身份响应新的请求。新 leader 上任开始 leader 服务后，旧 leader 在之前已经开始以 leader 身份处理的请求可以继续处理。</p><p></p><p>满足上面的需求需要以下保证：</p><p>任何 2 个节点的 leader 任期没有交叠。即不会发生节点 a 的 leader 任期还未结束，节点 b 的 leader 任期就已经开始。业务服务在响应请求时，总是先调用选主组件提供的 isLeader() 接口检查任期是否过期。</p><p></p><p>第二个点我们需要业务服务进行改造即可满足。第一个点我们需要基于对任期的设计和实现说明安全性。</p><p></p><p>问题分析</p><p></p><p>如果要让 2 个 leader 之间任期在全局时钟下没有交叠，我们只需要保证：</p><p></p><p>假设 1：任何 follower 认为某 leader 的任期结束时间点 A 大于 leader 认为的自己的任期结束时间点 B。</p><p></p><p>因为 A 一定小于该 follower 竞选 leader 成功后的任期开始时间点。这样任何 2 个 leader 的任期就不会</p><p>有交叠了。而任期的结束时间点通常是由任期开始时间点来确定，为了方便工程实践，我们可以把假设 1 进行一个转换：</p><p></p><p>假设 1a: follower 认为的 leader 的任期开始时间点 大于 leader 认为的自己的任期开始时间点。</p><p>如果我们认为 leader 和 follower 的时钟，在任期内的计时误差，小于 2 者认为的任期开始时间点的差，那么显然假设 1a 成立时假设 1 也成立。我们接下来尝试找出能够实现假设 1a 的实际方案。</p><p></p><p>问题方案：任期区间的定义</p><p></p><p>如果我们怀疑 2 任 leader 的任期有交叠，那旧 leader 一定有一次对自己任期的续期成功 CAS 写入，第一个和他任期有交叠的新 leader 的成功上任时一定有对这个旧 leader 这个续期租约的成功读取，和对这个任期过期的判断，以及自己竞选时任期的成功 CAS 写入。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8e/8e816c4df85c596eb2a493081128070b.png\" /></p><p></p><p></p><p>如上图：上一任旧 leader 最后一次对自己任期的续期写入的开始时间是 T_w0， 收到回包的是 T_w1；下一任新 leader 对旧 leader 最后一个任期 lease 的第一次读取的开始时间是 T_r0， 收到回包的是 T_r1， 竞选写入的开始时间是 T_w2， 收到回包的是 T_w3。假设这些数值是由一个虚拟但精确的全局时钟给出的时间戳。</p><p></p><p>从单机的视角来看，必然有大小关系顺序：</p><p><code lang=\"null\">T_w0 &lt; T_w1\nT_r0 &lt; T_r1 &lt; T_w2 &lt; T_w3</code></p><p>由于下一任新 leader 对旧 leader 写入最后一个任期的租约成功读取，这说明一定写、读之间有\"happened-before\"的关系，所以也有多机视角下的大小关系顺序：</p><p></p><p><code lang=\"text\">T_w0 &lt; T_r1</code></p><p></p><p>我们将使用这个关系来给出符合假设 1a 的任期区间定义。设任期时间固定为 expired_interval_ms：</p><p>旧 leader 认为自己的任期是 [T_w0, T_w0+expired_interval_ms)follower（未来的新 leader）认为旧 leader 的任期是 [T_r1, T_r1+expired_interval_ms)新 leader 认为自己的任期是 [T_w2, T_w2+expired_interval_ms)</p><p></p><p>即 leader 总是认为自己的任期开始时间是从自己最近一次写入 FDB 成功的写入开始时间（竞选或续任发起开始时间），而其他 follower 认为这个 leader 的这一任任期开始时间是自己第一次读到这个任期 lease 的读取结束时间（得知 leader 胜选或续任成功时间）。</p><p></p><p>由于 T_w0 &lt; T_r1，所以T_w0+expired_interval_ms<=\"T_w2（一定会等到上一任任期结束才开始竞选）。故有结论</p><p></p><p><code lang=\"null\">T_w0+expired_interval_ms< code=\"\"></code></p><p></p><p><code lang=\"null\">即：两任 leader 的任期在 2 个 leader 的视角下都没有交叠。</code></p><p></p><p><code lang=\"null\">方案安全性分析</code></p><p></p><p><code lang=\"null\">现在我们考虑在包含时钟走时误差（不是时刻误差）情况下，在最极端的场景下上述方案的安全性。</code></p><p></p><p></p><p><code lang=\"null\"><img src=\"https://static001.geekbang.org/infoq/87/87a36d6ad9bec0eb9d852c121e9850ee.png\" /></code></p><p></p><p></p><p><code lang=\"null\">我们假设 follower 在认为上一任 leader 任期结束之后立即开始竞选，则有 T_r1+expired_interval_ms==T_w2，此时新的任期开始时间为 T_w2，旧的任期结束时间为 T_w0+expired_interval_ms。在没有时钟误差的情况下</code></p><p><code lang=\"null\"><code lang=\"null\">T_w2-(T_w0+expired_interval_ms)==T_r1-T_w0&gt;0</code></code></p><p></p><p><code lang=\"null\">现在分析时钟误差是否会超过这个差值，以及安全门限：</code></p><p><code lang=\"null\">即如果 follower 和 leader 的时钟在 expired_interval_ms 时间内的走时差异小于 T_r1-T_w0，那么不会发生上一任 leader 认为自己还在任的时候，follower 就已经开始尝试竞选的问题；如果 follower 和 leader 的时钟在 expired_interval_ms 时间内的走时差异小于 (T_r1-T_w0)+(T_w3-T_w2），那么不会发生 2 任 leader 所在的业务各自认定自己的服务任期 实际有相互交叠的问题：这是因为业务感知到的任期开始需要等待 FDB 写入完成，新 leader 的实际上任时间需要从 T_w3 而不是 T_w2 开始计算（T_w2 仅用于计算超时时刻）。</code></p><p></p><p><code lang=\"null\">通常我们配置的任期&lt;10s，而 2 次读和 CAS 写 fdb 带来的读写保守估计耗时&gt;1ms。而按极端场景的估计，现代电子计算机晶振在高温情况下工作 1s 内时钟漂变&lt;50us，预期 10s 内连续偏差&lt;500us。考虑到写入就差不多同时发生了读取也是很罕见的情况，我们的参数配置属于比较安全的范畴，但不建议设置大于 10s 的任期。</code></p><p></p><p><code lang=\"null\">实际实现</code></p><p></p><p><code lang=\"null\">在上面的流程中，可以看到是不需要在节点之间同步实际的绝对物理时刻的，那为什么选择在数据结构中存储 lease.last_refresh_time 这个任期开始的本地物理时刻，而不是如同 Raft 那样只需写入一个自增的逻辑时间戳？</code></p><p></p><p><code lang=\"null\">这是因为</code></p><p><code lang=\"null\">leader 有可能发生重启，我们希望它重启之后，能够基于这个物理时间判定自己还在 leader 任期之内，快速恢复工作。follower 竞选时写入的内容可能返回超时，但实际最终写入成功了。如果该 follower 在定期查看 key 的备选过程中能够看到自己已经竞选成功了，并且这个物理时间判定自己还在 leader 任期之内，那也能快速切换为 leader 工作。</code></p><p></p><p><code lang=\"null\">所以写入的这个物理时间不是为了分布式同步，而是 leader 自己为了提升 recovery 速度，而持久化自己的状态。</code></p><p></p><h3><code lang=\"null\">服务端节点的选举参数共识：发布选举参数改变</code></h3><p></p><p></p><p><code lang=\"null\">和 Raft 等分布式同步方案相比，本文介绍的方案有一个细微但重要的区别：不仅可以随意的增删节点，而且还可以随意的修改和配置任期！换而言之，集群的配置、管理类的元信息可以安全和简易的变更。</code></p><p><code lang=\"null\">传统的 Raft 之所以不能随意的直接修改心跳周期、leader 任期等时间参数，是因为升级修改这些参数的时候，集群内不同节点会持有不一致的参数值，而 leader 选举等共识构建流程的安全性是和这些参数的一致性有关系的（考虑到一些工程实现的取舍，那更是如此）。所以安全的工程实践往往不支持热升级修改这些参数，而需要停止所有节点来更新这些参数。</code></p><p></p><p><code lang=\"null\">而在本文的方案中，当 leader 把心跳周期 lease.refresh_interval_ms，任期 lease.expired_interval_ms 写入共享存储 key 之后，下一任 leader 尝试竞选时必须按照这个参数来进行竞选，即使它本地的配置参数和共享存储不一样；下一任 leader 胜选之后，它自然也就把自己的配置参数覆盖写入共享存储，它自己和其他 follower 都按照新发布的配置参数来决定自己的任期和未来的重新选主时间点。</code></p><p></p><p><code lang=\"null\">简而言之：每一任 leader 胜选后都自动发布自己配置中的新选举参数到共享存储中，下一任 leader 的选举一定所有节点都能看见并遵守（否则 CAS 会失败）。所以滚动升级过程中，即使不同节点的有不同的本地配置并参与竞选，也不会带来不一致问题。</code></p><p></p><p></p><h3><code lang=\"null\">客户端和服务端的共识：“谁是 leader”的服务发现</code></h3><p></p><p></p><p><code lang=\"null\">上面我们已经介绍完了服务副本之间的分布式共识建立，涵盖 follower 之间竞选的冲突、新任和上任 leader 交接的冲突、选举参数变更等共识问题的解决。我们最后介绍客户端如何感知服务端的 leader 选举结果变更。</code></p><p></p><p><code lang=\"null\">客户端访问 leader 的逻辑很简单：</code></p><p><code lang=\"null\">读取 K 中 address 的结果，如果 key 存在且 address.status==Ready， 无限期缓存并访问其中的地址。如果 leader 的响应返回自己不是 leader，那么删除缓存后重试 1。</code></p><p></p><p><code lang=\"null\">我们可以看到客户端无需访问 lease 中的时间信息，从而无需感知副本之间的时间共识，也不需要本地时钟和服务端进行任何同步。</code></p><p></p><p></p><h3><code lang=\"null\">总结</code></h3><p></p><p></p><p><code lang=\"null\">介绍到这里，我们可以看到一个新 leader 的产生，是如何是如何在 follower 之间竞争产生分布式共识，并和旧任 leader 以及未来可能出现的新 leader 对这个共识的有效期的安全性产生共识，再让客户端感知到这个共识的全过程。</code></p><p></p><p></p><p><code lang=\"null\"><img src=\"https://static001.geekbang.org/infoq/da/dae7df478a84a03e009da79f8ebdfd0c.png\" /></code></p><p></p><p></p><p></p><h2><code lang=\"null\">ByConity 的使用</code></h2><p></p><p></p><p><code lang=\"null\">ByConity 可以把上面的选主方案使用在使用 leader 节点工作的服务，例如 Resource manager/Timestamp oracle 等。这套方案允许启动后的节点副本无需配置客户端对服务端的服务发现地址，也无需配置 ClickHouse-keeper 中副本之间的相互服务发现以及设置静态的副本数量：增加的副本只要能启动即能被客户端发现，并自动参与选主竞争。</code></p><p></p><p><code lang=\"null\">如果使用 K8s 部署 ByConity 集群，只需要调整 replicas 属性就能简单的增减服务 Pod 副本。</code></p><p></p><h2><code lang=\"null\">总结</code></h2><p></p><p></p><p><code lang=\"null\">本文介绍了一套基于共享存储和 CAS 操作进行 leader 选举的通用方案，充分利用了高可用共享存储的能力，使得 leader 选举运维和配置简单，让 ByConity 开源用户能更轻松的用上高可用服务能力。该方案可以简单的推广到任意的无状态服务的选主场景。</code></p><p></p><p><code lang=\"null\">ByConity 也借此去除了对 ClickHouse-keeper 的依赖，在支持多副本高可用的同时大大简化了配置，也提升了在 2 节点等低成本场景的容灾能力，并且使得服务无论单节点和多节点副本部署 在运行逻辑上进行了统一，降低代码复杂度。</code></p><p></p><p><code lang=\"null\">项目地址：<a href=\"https://github.com/ByConity/ByConity\">https://github.com/ByConity/ByConity</a>\"</code></p><p></p><p></p><p></p>",
    "publish_time": "2023-12-20 09:08:14",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "CodeWhisperer：亚马逊的 AI 编码助手彻底改变了软件开发",
    "url": "https://www.infoq.cn/article/iCUjvWTzGm68ui4WbqFX",
    "summary": "<p></p><h2>CodeWhisper 的出现</h2><p></p><p></p><p>根据 Insider 最近的一份报告，本月早些时候，<a href=\"https://www.yundongfang.com/Yuntag/%e4%ba%9a%e9%a9%ac%e9%80%8a?trk=cndc-detail\">亚马逊</a>\"的<a href=\"https://www.yundongfang.com/Yuntag/%e8%bd%af%e4%bb%b6?trk=cndc-detail\">软件</a>\"工程师收到了一封内部电子邮件，敦促他们采用 CodeWhisperer，这是一种<a href=\"https://www.yundongfang.com/Yuntag/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd?trk=cndc-detail\">人工智能</a>\"编码助手，旨在优化和简化软件开发。这种先进的工具，与 ChatGPT 非常相似，能够理解和响应自然语言查询，使其非常人性化并可供所有人使用。</p><p></p><p>在获得内部使用批准后，CodeWhisperer 现在可供亚马逊的所有软件开发团队使用。这意味着整个组织的工程师可以利用 AI 的力量编写更好的代码，比以往任何时候都更快、更准确。CodeWhisperer 理解自然语言查询的能力是一个显着优势，因为它允许开发人员以一种感觉直观和熟悉的方式与该工具进行交互。通过消除对复杂编程命令和语言的需求，CodeWhisperer 使工程师可以轻松地专注于手头的任务——编写满足亚马逊客户需求的高质量代码。</p><p></p><p>通过采用 CodeWhisperer，亚马逊的软件工程师有望实现更高水平的生产力和效率，这最终将使公司及其客户受益。随着人工智能的不断发展和改进，我们很可能会看到更复杂、更先进的工具，如 CodeWhisperer 正在被各行各业的公司开发和采用。</p><p></p><h2>CodeWhisper 的工作原理</h2><p></p><p></p><p>CodeWhisperer 的核心旨在简化编码过程并减少工程师花在日常任务上的时间。这款由 AI 驱动的编码助手的主要功能之一是它能够理解自然语言查询，这使得它非常易于使用。</p><p></p><p>当开发人员向 CodeWhisperer 输入查询时，该工具会使用高级语言模型和算法来分析查询、提取关键信息，并随后生成相关代码片段。这个过程非常复杂，并考虑了广泛的因素，包括正在使用的编程语言、查询的上下文以及开发人员的编码风格和偏好。</p><p></p><p>通过自动化这些过程，CodeWhisperer 能够显着减少编写高质量代码所需的时间和精力。这使开发人员可以专注于更具创造性和更高层次的任务，例如设计新功能和优化现有代码，而不是陷入繁琐且耗时的编码任务中。</p><p></p><p>除了其自然语言处理能力外，CodeWhisperer 还采用一系列其他高级功能和技术来改进编码过程。例如，该工具能够从过去的查询和交互中学习，从而随着时间的推移提供越来越准确和有用的建议。它还考虑了广泛的因素，例如代码复杂性、最佳实践和潜在错误或错误，以确保它生成的代码具有尽可能高的质量。</p><p></p><h2>对软件开发的潜在影响</h2><p></p><p></p><p>在亚马逊的软件开发生态系统中实施 CodeWhisperer 有望带来多项好处，包括：</p><p></p><h4>提高效率</h4><p></p><p></p><p>CodeWhisperer 旨在自动执行各种编码任务，使软件工程师能够专注于开发过程中更复杂和关键的方面。通过减少日常编码任务所需的时间和精力，人工智能编码助手可以显着提高整体效率和生产力。</p><p></p><h4>改善协作</h4><p></p><p></p><p>凭借其理解和响应自然语言查询的能力，CodeWhisperer 可以促进团队成员之间更好的沟通。这使得协作讨论和解决问题变得更加容易，从而导致更有效的团队合作和更快的进步。</p><p></p><h4>减少错误</h4><p></p><p></p><p>CodeWhisperer 可以通过向开发人员提供建议和指导来帮助最大限度地减少代码生成中的人为错误。这可确保最终产品更加健壮和可靠，减少可能影响用户体验的错误和缺陷。</p><p></p><h4>加速学习</h4><p></p><p></p><p>CodeWhisperer 可以作为初级开发人员的宝贵资源，提供即时指导和代码建议以增强他们的学习体验。通过提供对最佳实践和编码标准的实时反馈和洞察，该工具可以帮助加快学习曲线并提高经验不足的开发人员编写的代码质量。</p><p></p><h3>挑战与未来展望</h3><p></p><p></p><p>尽管 CodeWhisperer 的推出代表了 AI 辅助软件开发的一个重要里程碑，但必须解决潜在的挑战以确保其成功。以下是一些最重要的：</p><p></p><p></p><h4>准确性和安全性</h4><p></p><p></p><p>CodeWhisperer 生成的代码必须准确、可靠且安全。这意味着 AI 编码助手必须经过严格测试，以确保其生成的代码符合行业标准，并且没有漏洞和安全漏洞。</p><p></p><h4>遵守</h4><p></p><p></p><p>遵守行业标准对于软件开发至关重要，CodeWhisperer 的设计必须符合相关法规和标准。这包括遵守与软件开发相关的最佳实践和指南，以及遵守数据隐私和安全法规。</p><p></p><h4>适应性</h4><p></p><p></p><p>编程语言和开发框架不断发展的本质意味着 CodeWhisperer 必须具有适应性和灵活性，以跟上该领域的变化。这需要持续开发和更新，以确保 AI 编码助手在面对新技术和新兴技术时保持相关性和有效性。</p><p></p><h4>可用性</h4><p></p><p></p><p>虽然 CodeWhisperer 旨在简化编码过程并提高效率，但它还必须易于使用并可供软件开发团队的所有成员访问。这需要用户友好的界面和清晰的文档，以确保开发人员可以充分利用其功能。</p><p></p><h2>未来由人工智能驱动，但以人为主导</h2><p></p><p></p><p>亚马逊的 CodeWhisperer 等人工智能工具的采用预示着软件开发的新时代，在这个时代，人类和机器智能共同推动创新、效率和质量。随着 AI 的不断发展，我们可以期待看到更先进、更复杂的工具出现，从而改变软件的开发、部署和维护方式。</p><p></p><p>经亚马逊云科技授权转载，文章出处：<a href=\"https://www.yundongfang.com/Yun220423.html?trk=cndc-detail\">https://www.yundongfang.com/Yun220423.html?trk=cndc-detail</a>\"</p>",
    "publish_time": "2023-12-20 10:09:13",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "百度侯震宇：大模型将彻底改变AI原生应用研发范式",
    "url": "https://www.infoq.cn/article/BJB2FqRVpNNLIG10XBXA",
    "summary": "<p>12月20日，在2023百度云智大会·智算大会上，百度集团副总裁侯震宇以“大模型重构云计算”为主题发表演讲。他强调，AI原生时代，面向大模型的基础设施体系需要全面重构，为构建繁荣的AI原生生态筑牢底座。</p><p></p><p>侯震宇表示：“大模型重构云计算主要体现在三个层面：AI原生云将改变云计算的格局，MaaS ( Model as a Service ，模型即服务）会成为新的基础服务，AI原生应用催生新的研发范式。”</p><p></p><h3>1、在算力层，计算更智能</h3><p></p><p></p><p>在底层的云基础设施层，以往从互联网应用到移动互联网应用，底层都基于CPU计算芯片，而AI应用对GPU或异构计算的需求大幅增加，云市场的底层算力开始迁移到以GPU为主。</p><p></p><p>2023年第三季度，英伟达的营收已经超过英特尔，英伟达最新市值也超过英特尔1万亿美元，未来GPU的增长将远大于CPU。在这一趋势下，我们需要对面向大模型的云计算基础设施体系进行全面重构，以支撑AI原生应用系统落地。</p><p></p><p>具体来说，云计算的全面重构会表现在三大领域，即：面向模型的智算基础设施、面向数据的数据基础设施、面向应用的云基础设施全面升级，让计算更智能。</p><p></p><h3>2、在模型层，大模型正在成为通用的服务能力，即MaaS</h3><p></p><p></p><p>MaaS将大幅降低Al落地的门槛、实现真正的Al普惠，其依赖的新型IT基础设施也将进一步在底层颠覆现有的云计算市场格局。</p><p></p><p>从百度智能云的实践来看，自8月31日文心一言全面开放后至今的4个月，百度智能云千帆大模型平台（百度智能云推出的MaaS平台）上，API日调用量增长10倍，客户主要来自互联网、教育、电商、营销、手机、汽车等各行业。可以明显看到，最近半年，已经有很多企业真正把大模型用起来了。</p><p></p><h3>3、在应用层，应用开发的范式已经被彻底颠覆</h3><p></p><p></p><p>大模型理解、生成、逻辑、记忆的独特能力会催生A原生应用研发新范式，整个应用技术栈、数据流和业务流都将被改变。</p><p></p><p>原先基于CPU的应用开发主要是业务逻辑驱动，传统的AI研发需要针对每一个独立场景获取数据，再分别从头训练模型。而现在AI原生应用主要基于大模型能力，以数据驱动开发。企业可直接在基础大模型之上，利用场景数据微调出专属大模型，再用模型能力设计AI原生应用，无需从头训练大模型。随着企业业务扩大，逐渐积累出更多有竞争力的场景数据，进而反哺模型和应用效果提升，从而形成数据飞轮。</p><p></p><p>具体来说，大模型驱动的AI原生应用研发新范式展现出几个新变化：</p><p></p><p>首先是“新场景”。生成式大语言模型，在理解、生成、推理、记忆等多维度展现出超预期的能力，带来了智能涌现，由此催生了很多新的可落地的业务场景应用，如个人助理、智能文案创作、GBI（智能商业分析）、编码助手等。</p><p></p><p>第二是“新架构”。大模型具体在这些新场景落地的过程中，也产生了很多新的系统架构，如检索增强生成RAG，智能体Agent 等。</p><p></p><p>第三是“新开发生态”。以大模型为核心，开发者工具层也出现了一些新工具，包括编排工具LangChain、AI应用开发工具PromptFlow、数据框架Llamalndex等。</p><p></p><p>侯震宇表示，总体来说，构建繁荣的A原生应用生态，需要大模型、智能算力、AI原生应用研发新范式三要素相辅相成。大模型是AI原生应用的“大脑”，智能计算则为AI原生应用运行提供坚实支撑，新研发范式助力开发者高效基于大模型能力开发应用。数据飞轮是成功的AI原生应用的充分必要条件，让大模型能力高速迭代，产品体验持续进步。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/d4/d4a20542591a70a414fe957dd6549bd6.png\" /></p><p></p><p>“我相信，真正非常闪耀的AI原生应用会在2024年诞生。”侯震宇说。</p><p>&nbsp;</p>",
    "publish_time": "2023-12-20 10:14:12",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "React 单元测试实例：快速上手指南",
    "url": "https://www.infoq.cn/article/1ypo54cMidb7PzRpxowD",
    "summary": "<p>你是否正计划为你的React代码编写测试？是否因找不到好的入门教程而感到苦恼？那么，这篇文章正是你所需要的。在本文中，我们将涵盖编写单元测试的所有步骤以及这个过程中可能遇到的错误和问题。</p><p>&nbsp;</p><p>本文使用了<a href=\"https://jestjs.io/\">Jest</a>\"和<a href=\"https://testing-library.com/\">React Testing Library</a>\"库。如果你想使用其他库也没关系，文中的一些基础知识也会对你有所帮助。</p><p>&nbsp;</p><p>本文涉及的全部代码都托管在GitHub上，文末提供了链接地址。</p><p>&nbsp;</p><p></p><h1>为什么要编写测试</h1><p></p><p>当然，不写测试代码也可以完成产品开发。用户、产品经理，甚至测试人员或QA都不在乎该产品是否有测试代码。但是你，作为一名开发人员，应该在乎！</p><p>&nbsp;</p><p>假设你有一个拥有数万用户的网站，当你对一个公共的工具函数做了一些重构（或添加了一个功能修复），并在应用中某个调用它的地方进行了测试，表明该函数可以正常运行。于是你选择在周五上线（这是个低级错误）。然后，该函数在应用中的其他地方无法运行，导致网站在周末期间出现线上故障。 此时，你多么希望这些地方能有测试代码，可以在发布生产之前自动运行，从而避免此次故障。</p><p>&nbsp;</p><p>上述场景比你想象的还要普遍。你可能还没遇到过（不过，这是迟早的事情），但是包括我在内的很多工程师都已经遇到过了。</p><p>&nbsp;</p><p>因此，测试代码之所以很重要，主要有以下几个原因：</p><p>&nbsp;</p><p>🚀 增强你对代码发布上线的信心。</p><p>📜 测试代码本身也是一种文档。</p><p>🛠️ 有助于调试和重构。</p><p>⌛️ 从长远来看，有助于减少开发时间。</p><p>&nbsp;</p><p>对于所有希望晋升的初级开发人员来说，务必要具备编写测试代码的能力。</p><p>&nbsp;</p><p></p><h1>测试教程</h1><p></p><p></p><p>我们将从零开始教你编写测试代码，所以请准备好终端。首先，我们使用vite创建一个示例项目。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/23/23d333bb0c9cf450b18148db95163a48.png\" /></p><p></p><p>&nbsp;</p><p>在创建项目后，使用以下命令运行它。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7c/7ce59376e4453453392ad383b68f45e1.png\" /></p><p></p><p>&nbsp;</p><p>程序运行之后，你会在页面上看到一个demo应用。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bf/bf68ee643b5bc3745b3e62bc2ce94fcf.png\" /></p><p></p><p>&nbsp;</p><p>我们不会给该应用添加新功能，但为了给按钮编写测试代码，我们需要将按钮重构为一个单独的组件。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b4/b4ea3dc23d1e7136c0b95352829016ee.png\" /></p><p></p><p>&nbsp;</p><p>接下来，我们在页面上添加两个按钮：</p><p>&nbsp;</p><p>一个按钮的功能是点击时将count的值乘以2。另外一个按钮的功能是点击时按以下顺序执行操作：如果count的值以0结尾，那么就将它的值除以2。如果count的值是斐波那契数，那么就将它的值加1。否则，将count的值进行平方操作。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/75/755fe81d7644d23570e3fc730f88486f.png\" /></p><p></p><p>&nbsp;</p><p>我们需要在utils模块中声明上面代码中用到的两个函数。同时，我们也声明了一些辅助函数，但由于其他地方并不会用到这些辅助函数，因此这里不需要做导出。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e8/e81e4956bbc7bd0598f76ff4273c5e35.png\" /></p><p></p><p>&nbsp;</p><p>代码已经准备好，现在可以开始编写测试代码了。这里我们跳过React代码，直接先给工具函数编写测试。这有助于我们了解Jest框架的大致用法。</p><p>&nbsp;</p><p>下面，让我们为doubleTheNum函数编写测试。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d4/d4ec3629fcbdb09db9b1d87c19026826.png\" /></p><p></p><p>&nbsp;</p><p>上面的代码用于测试我们的函数是否可以按预期执行。任何测试代码都会包含以下这些关键组件：</p><p>&nbsp;</p><p>describe函数：第一个参数是字符串，它会在测试运行的时候显示。第二个参数则是测试实际执行的函数。describe函数的主要作用是对同类型的测试进行分组。这里只有一个测试，在另外一个示例中，你会看到其中有多个测试。it函数：其参数结构和describe函数类似。但这里的字符串参数应该尽可能详细地描述测试函数的具体内容。当然，你也可以使用test函数替代it。expect语句块：此函数中的前三行很简单。其最后一行是通过断言来判断doubleTheNum函数能否正确运行。此外，这里我们还用到了toEqual匹配器函数。</p><p>&nbsp;</p><p>Jest提供了很多匹配器，例如：</p><p>&nbsp;</p><p>toBeNull用于匹配null。toBeTruthy用于匹配判定结果为true的语句。</p><p>&nbsp;</p><p>想了解关于匹配器的更多信息，参考如下链接：</p><p><a href=\"https://jestjs.io/docs/using-matchers\">https://jestjs.io/docs/using-matchers</a>\"</p><p>&nbsp;</p><p>为了运行测试，我们需要先安装Jest：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2e/2e1a80a0229feaa5402672d0e4e76f21.png\" /></p><p></p><p>&nbsp;</p><p>然后在package.json中添加测试脚本：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/02/021ddf8b4f904b18db3395ffd7ac9d28.png\" /></p><p></p><p>&nbsp;</p><p>最后，通过执行yarn test命令来运行测试。</p><p>&nbsp;</p><p>对于大多数人来说，上面的步骤已经足够了。但如果你遇到了与模块导入或TypeScript相关的任何问题，请按以下步骤进行操作：</p><p>&nbsp;</p><p>安装并设置@babel/preset-env：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b7/b779fbb03349520acbc69d2cd7972b13.png\" /></p><p></p><p>&nbsp;</p><p>然后，将它配置到package.josn中：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ca/ca49063018bcd3c622bfe22f8ce966da.png\" /></p><p></p><p>&nbsp;</p><p>安装TypeScript依赖库：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/10/1082431bb2f809f966c12f5f00b29e9e.png\" /></p><p></p><p>&nbsp;</p><p>然后，在jest.config.ts中添加Jest配置：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/90/907d52e74d61ad00e70a9c018c902832.png\" /></p><p></p><p>&nbsp;</p><p>然后执行测试，结果如下：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f3/f32c6afc2bb452c03a2cf9a1bd5df6ae.png\" /></p><p></p><p>&nbsp;</p><p>从输出中可以看到我们在describe和it函数中声明的字符串信息。</p><p>&nbsp;</p><p>🎉 恭喜，你完成了第一个测试！</p><p>&nbsp;</p><p></p><blockquote>喜欢这篇文章吗？如果觉得还不错，我推荐你看看我的另一篇最受欢迎的文章<a href=\"https://dev.to/thesanjeevsharma/just-redux-the-complete-guide-44d5\">《Redux完整指南》</a>\"，阅读量高达2.5万：<a href=\"https://dev.to/thesanjeevsharma/just-redux-the-complete-guide-44d5\">https://dev.to/thesanjeevsharma/just-redux-the-complete-guide-44d5</a>\"</blockquote><p></p><p>&nbsp;</p><p>接下来，我们给funkyNum函数编写测试。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d1/d18abb3c06d906e76689816f454d061c.png\" /></p><p></p><p>&nbsp;</p><p>编写测试时，应该尽量多地覆盖函数的分支和语句。测试覆盖率越高会让人越有信心。</p><p>&nbsp;</p><p>如果你再次运行测试，应该会看到以下输出。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/43/43f3b575208fcdb4a77806b26cabf23a.png\" /></p><p></p><p>&nbsp;</p><p>理想情况下，我们也应该为isFibonacci和isPerfectSquare函数编写单独的describe语句块。在单元测试中，测试代码应该是互相独立的。简洁起见，这里我们没有这样做。</p><p>&nbsp;</p><p>💡小提示</p><p>&nbsp;</p><p>通过调用.skip或test.skip来跳过任何测试，或调用describe.skip来跳过整个测试块。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9a/9ac7ed914c3e510737c5bb5e2706294a.png\" /></p><p></p><p>&nbsp;</p><p>通过调用it.only或test.only执行单个测试。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/67/67cce5813b3c3ec30991ffc61a525454.png\" /></p><p></p><p>&nbsp;</p><p>上面我们已经介绍了如何使用Jest进行JS代码的测试。现在，让我们深入探讨下关于React的测试。</p><p>&nbsp;</p><p>在开始之前，我们还需要安装一些依赖库：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/99/99ad433321fbe10be116b12b30228cb7.png\" /></p><p></p><p>&nbsp;</p><p>同时，还需要在jest.config.ts中添加环境：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/03/031c37fff58a94db093a06a92423066d.png\" /></p><p></p><p>&nbsp;</p><p>下面我们给CounterButton组件编写一个最基础的测试：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/09/098c25daedd09aac49b8149bae9557a0.png\" /></p><p></p><p>&nbsp;</p><p>在上面的代码中，我们提供了所需的props&nbsp;，并尝试渲染组件。对于任何组件，这都应该是你为它编写的第一个测试。因为如果该测试无法通过，那么其他测试就毫无用处。</p><p>&nbsp;</p><p>RTL（React Testing Library）的render函数将在document.body中渲染传入的组件。</p><p>&nbsp;</p><p>它还返回了一些诸如getByText这样的查询方法，可用于在DOM中查找元素。</p><p>&nbsp;</p><p>点击<a href=\"https://testing-library.com/docs/queries/about/\">这里</a>\"查阅所有的查询方法。</p><p>&nbsp;</p><p>如果你再次运行测试，应该可以看到2组测试——全部为绿色且通过。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3f/3f374aa9f5d2bb6cdbcf8bf9dcac64ec.png\" /></p><p></p><p>&nbsp;</p><p>我们编写的第二个测试是测试组件对于props的反应。如果各个prop之间没有互相依赖，那么应该为每个prop参数都编写单独的测试。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6d/6d1e8835c40ee84e948a848c21dd3de2.png\" /></p><p></p><p>&nbsp;</p><p>getByText函数是一种查询方法，可以让我们通过字符串来获取元素。</p><p>&nbsp;</p><p>toBeInTheDocument函数是一个和toEqual类似的匹配器。Jest默认不提供该函数，需要在安装@testing-library/jest-dom库之后才能使用。</p><p>&nbsp;</p><p>不同的环境有不同的包，例如在React Native环境中，需要使用@testing-library/jest-native。</p><p>&nbsp;</p><p>如果你再次运行测试，测试应该也会通过。</p><p>&nbsp;</p><p>最后，我们来编写本文的最后一个测试，同时也是最重要的一个。我们将编写一个测试来检查点击事件处理程序是否按预期工作。</p><p>&nbsp;</p><p>为了生成用户事件（例如点击和按键），我们需要安装另外一个包。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/99/99125f68bb66364842dcb5c51c444cec.png\" /></p><p></p><p>&nbsp;</p><p>与之前的测试代码相比，这次的测试代码几乎一样，只有一些微小的差异。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/65/65da5af9c546d4190121fb400413acb0.png\" /></p><p></p><p>&nbsp;</p><p>注意：由于是模拟用户事件，所以该函数异步执行。</p><p>&nbsp;</p><p>第一行的jest.fn()是一个模拟函数。在测试运行时，可以通过它跟踪诸如调用参数、调用次数等很多非常有用的信息。类似这样的函数，以后你会看到很多。</p><p>&nbsp;</p><p>我们还使用了一种新的查询方法getByRole来查找按钮元素。</p><p>&nbsp;</p><p>在检查模拟函数是否被调用之前，我们需要先等待点击事件完成。</p><p>&nbsp;</p><p>就是这样！如果你运行测试，它们应该也会通过。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d6/d6e6932126142a25934103e271c12018.png\" /></p><p></p><p>&nbsp;</p><p>🔗&nbsp;<a href=\"https://github.com/thesanjeevsharma/devto-unit-testing\">这里</a>\"获取所有代码：</p><p><a href=\"https://github.com/thesanjeevsharma/devto-unit-testing\">https://github.com/thesanjeevsharma/devto-unit-testing</a>\"</p><p>&nbsp;</p><p></p><h1>下一步</h1><p></p><p></p><p>如果你遵循本文成功地完成了测试代码的编写，那么你可以开始在自己的代码库中添加测试代码并且进一步探索各种测试功能了。</p><p>&nbsp;</p><p>另外，我建议你进一步了解以下几个方面的内容：</p><p>getByTestId——这是一个使用很普遍的查询方法。当其他方法都不好使的时候，可以用它。了解<a href=\"https://jestjs.io/docs/setup-teardown\">Setup和Teardown</a>\"方法。它将提升你的测试水平。学习如何模拟npm模块、API 调用、全局状态和上下文等。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://dev.to/thesanjeevsharma/writing-your-first-unit-test-in-react-150h\">https://dev.to/thesanjeevsharma/writing-your-first-unit-test-in-react-150h</a>\"</p><p>&nbsp;</p><p></p><h5>相关阅读：</h5><p></p><p></p><p><a href=\"https://www.infoq.cn/article/4ydKY3wbZDp7Eei0JJm1\">React&nbsp;JS 广受业界认可，高级开发者年薪百万</a>\"</p><p><a href=\"https://www.infoq.cn/article/Tv3SyqoivXMWUoj8qSMT\">从新&nbsp;React&nbsp;文档看未来 Web 的开发趋势</a>\"</p><p><a href=\"https://www.infoq.cn/article/CZKMjHaxbf1Z7xcSzisX\">我被&nbsp;React&nbsp;劫持了，很痛苦又离不开</a>\"</p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MzUxMzcxMzE5Ng==&amp;mid=2247516803&amp;idx=1&amp;sn=f584917f8afe2f7bb10f8686acb040cf&amp;chksm=f95237c0ce25bed6980bdc34c630cbda97d0325a489663440b4c904499ca81da31729d476476&amp;scene=27#wechat_redirect\">React&nbsp;开发者们的 Solid.js&nbsp;快速入门教程</a>\"</p>",
    "publish_time": "2023-12-20 10:33:04",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "容联云大模型应用升级，发布容犀智能与容犀Copilot",
    "url": "https://www.infoq.cn/article/ryKfCI9KaLJVhHbDGUsL",
    "summary": "<p>12月19日，容联云“未来生成式——大模型应用升级新品发布会”在北京举办。发布会上，容联云正式发布基于自研赤兔大模型的全新产品品牌【容犀智能】及生成式应用【容犀Copilot】。</p><p></p><p>容犀智能从业务场景出发，结合全流程链路的数据能力、大小模型应用、端到端解决方案落地能力，弥合企业在数智化转型时技术与业务应用的差距，寻求投入与效益的最佳平衡，帮助企业实现营销服数智化升级。全新的容犀智能品牌将包含容犀AICC、容犀Desk、诸葛IO/CDP/CEP、容犀Copilot四大模块。</p><p><img src=\"https://static001.geekbang.org/infoq/63/637bb164d35cf34c46551051870fa3b5.png\" /></p><p></p><h2>容犀Copilot：大模型时代的实时AI领航员</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/d3/d34121133ce3f4939a47c2d9f3469e61.png\" /></p><p>容联云产业数字云事业群副总经理孔淼</p><p></p><p>在发布会现场，容联云产业数字云事业群副总经理孔淼宣布了容犀智能品牌的诞生，同时正式发布全新生成式应用容犀Copilot。</p><p><img src=\"https://static001.geekbang.org/infoq/9a/9aa329f7576f9e9f385afbf680816b5b.png\" /></p><p></p><p>容犀Copilot集“全链路数据+大小模型+分析洞察”于一体，在每一次的服务与营销场景中，实时根据企业与客户产生的会话数据与业务数据，结合“聚焦客户联络全场景的大小模型”与“会话洞察”能力，产出最佳沟通策略，打造销售和客服的实时AI领航员。</p><p><img src=\"https://static001.geekbang.org/infoq/86/86e8a3ae45918f593f6d7f5991a4669b.png\" /></p><p></p><p>首先是大模型话术挖掘，容犀Copilot后台一键快速对海量历史会话数据进行核对筛选，挑选出最佳话术并生成金牌话术，兼顾质与量的同时，挖掘出客户高频关注的问题，从问题中洞悉业务痛点。其次，大模型智能知识库可以帮助企业从零开始、低成本地快速构建话术库，包括理解文档知识、知识快搜、智能问答等，大幅提升构建效率。最后，通过大模型会话洞察，高效便捷洞察每一通会话沟通情况，分析客户诉求，精准诊断问题并优化。回归实际业务本身，容犀Copilot深入金融行业细分场景，打造场景化客服助手，譬如分期挽留助手、荐卡挽留助手、投诉安抚助手等，实时辅助快速洞察客户需求，推荐最佳应答话术，诊断客户情绪变化，提醒措辞及注意事项。</p><p><img src=\"https://static001.geekbang.org/infoq/04/0499aa61c33c701f4945ac2f5cfc1096.png\" /></p><p>容联云AI研究院院长 刘杰</p><p></p><p>容犀智能与容犀Copilot的落地意味着容联云赤兔大模型在智能性、可控性、投产比上都有了新的跃升，容联云AI研究院院长刘杰详解了赤兔大模型的落地路径。在智能性上，通过检索增强，会话分析，逻辑推理，数据分析等多维度深度理解分析，实现全面的沟通会话智能。在可控性上，快速对业务上的各种规定要求进行对齐，明确各个知识模块的范围界定，只处理业务角色相关问题，保证安全可控。在投产比上，通过大小模型配合构建最适合业务规模的AI底座。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4c/4c8ade842be0e93fc5adcde49097e115.png\" /></p><p>北京华为云CTO&nbsp;丁晨</p><p></p><p>现场，北京华为云CTO丁晨也带来了与容联云合作的现状与展望，在基于9月份双方签订的战略合作协议之上达成深度合作共识，结合华为5G、大数据、鲲鹏、昇腾、大模型等前沿技术，持续创新行业大模型和场景化应用，打造云上客服联合解决方案。</p><p></p><h2>拓展海外市场，容联云业务持续升级与落地</h2><p></p><p>&nbsp;</p><p>容联云在发布会上还宣布了其业务的升级与落地计划。</p><p><img src=\"https://static001.geekbang.org/infoq/74/744c65b34f5062057a7a5504886d34bd.png\" /></p><p>容联云数字智能云AI产品专家 刘倩</p><p></p><p>持续深耕海外市场，容联七陌在日本和东南亚已累计服务上百家客户，并计划在未来推出更多AIGC的智能交互应用。在日本市场，容联七陌在2023年3月即推出了AIGC的智能交互应用，实现了诸如智能文档问答、AIGC电话交互等能力，是最早一批拥有AIGC落地应用的企业之一。容联七陌助力全日本最大的外国人求职服务会社Y社，应用语音机器人进行会员邀约注册、求职意向采集等服务。客户S社为印刷、活动推广、媒体业务服务商，在容联七陌文本机器人助力下，实现了自助答疑，节省人力成本60%以上，大量进订单咨询均由机器人独立接待回复。容联云数字智能云AI产品专家刘倩表示，未来，容联七陌将持续自研智能客服技术核心，在全球化规模营收支撑下，探索AIGC时代的新服务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/23/2394097275a24b3714fd7a7dadd8b51f.png\" /></p><p>容联云CV产品解决方案总监李杰</p><p>&nbsp;</p><p>同时，容联云还将推出基于AIOT平台的金融银行场景解决方案，涵盖安防风控、合规运营、重资管理等多个方面。容联云CV产品解决方案总监李杰表示，该方案将利用多模态大模型和AIOT平台的技术优势，为金融银行业提供更加智能化、高效化的智慧营业厅。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e6/e60501b7df596018f0d2f02d4c179f81.png\" /></p><p>阳光出行智能服务部负责人王妙心</p><p>&nbsp;</p><p>在发布会现场，阳光出行作为标杆客户代表，分享了其使用大模型等AI技术的经验。阳光出行通过使用大模型等AI技术优化了其服务流程和用户体验，实现了商业价值的提升。</p><p>&nbsp;</p><p>大模型时代，容联云将通过沟通智能、数据智能、链路智能等重构企业面向内部和面向外部的多元化应用，帮助企业打造全生命周期的智慧经营闭环，从而更好地感知客户需求，驱动数据的精细运营，创造个性化体验，让数智化真正可用、有用，从而带动整体业务增长。</p><p>&nbsp;</p>",
    "publish_time": "2023-12-20 10:39:47",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "阿里巴巴通义实验室 NLP 资深算法专家张佶确认出席 QCon 上海，分享通义星尘——个性化大模型驱动的 AI 对话新范式",
    "url": "https://www.infoq.cn/article/Df1NwOv9o5k95deVBjpS",
    "summary": "<p><a href=\"https://qcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=1220&amp;utm_content=zhangji\">QCon 全球软件开发大会</a>\"，将于 12 月在上海召开。阿里巴巴通义实验室 NLP 资深算法专家张佶将发表题为《<a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5599?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=1220&amp;utm_content=zhangji\">通义星尘——个性化大模型驱动的 AI 对话新范式</a>\"》主题分享，探讨 AI 对话领域的最新发展趋势以及相关大模型关键技术和场景。</p><p></p><p><a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5599?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=1220&amp;utm_content=zhangji\">张佶</a>\"，负责通义大模型的应用研究和落地，带领的研究团队发表国际顶级会议论文 40 余篇，曾在机器阅读理解（MRC）、视觉问答（VQA）等国际权威榜单中实现首次超越人类基准的成绩。曾领导开发的阿里小蜜算法平台服务于阿里全球 23 个语言、130 多个国家的电商用户。他在本次会议的演讲内容如下：</p><p></p><p>演讲：通义星尘——个性化大模型驱动的 AI 对话新范式</p><p></p><p>随着近年来大模型技术的快速演进，AI 对话领域迸发出全新的发展可能和想象空间，阿里巴巴通义大模型近期发布了个性化 AI 角色创作和对话平台——通义星尘，在保持通用大模型基础能力的情况下，延伸出个性化大模型，提供拟人化、场景化、多模态和共情的对话能力以及复杂任务执行能力。本次分享将介绍 AI 对话领域的最新发展趋势以及相关大模型关键技术。</p><p></p><p>演讲提纲：</p><p></p><p>AI 对话系统的进展和趋势通用大模型和个性化大模型个性化大模型的 4 个关键技术</p><p>○ 个性化、大小模型协同的 AI 智能体、多模态、安全负责的 AI</p><p>个性化大模型的场景未来展望</p><p></p><p>听众收益点：</p><p></p><p>○ 了解大模型对 AI 对话领域带来的新趋势</p><p>○ 个性化大模型的关键技术</p><p>○ 落地场景和挑战</p><p></p><p>除上述演讲外，QCon 上海还将围绕&nbsp;<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart\">GenAI和通用大模型应用探索</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1596?utm_source=infoqweb&amp;utm_medium=teacherart\">AI&nbsp;Agent&nbsp;与行业融合应用的前景</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart\">LLM&nbsp;时代的性能优化</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart\">智能化信创软件&nbsp;IDE</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart\">面向人工智能时代的架构</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart\">性能工程：提升效率和创新的新方法</a>\"等专题进行交流。</p><p></p><p>12 月 28-29 日，QCon 全球软件开发大会即将落地上海，中国科学院外籍院士、国际数据库专家樊文飞院士，英特尔大数据技术全球 CTO 戴金权等大咖会亲临现场分享大数据、芯片、架构等方向的前沿洞见。</p><p>这次会议主要探讨大模型的全面技术架构的进化，不仅有跟大模型本身相关的推理加速、AI Agent、GenAI，还有架构的演进思路、性能优化，以及以智能代码助手为代表的研发效能提升等方向，感兴趣的朋友可以扫描下方二维码，查看大会详细日程。咨询购票可联系票务经理 18514549229。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/0113b3dfb187d5f9988b7eb16d2e0594.png\" /></p><p></p>",
    "publish_time": "2023-12-20 11:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]