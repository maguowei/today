[
  {
    "title": "极客时间重磅推出认证业务，引领IT人才职业技能培训",
    "url": "https://www.infoq.cn/article/AGrPyqat9ouzmZwZMVs9",
    "summary": "<p>极客时间是数字人才的移动知识库，是专注于为开发者提供高质量技术教育的专业平台。为了进一步满足职场需求，极客时间于&nbsp;2023&nbsp;年&nbsp;12&nbsp;月&nbsp;15&nbsp;日重磅推出认证业务，包含计算机软件资格考试认证和阿里云职业认证，以帮助学习者提升职业技能，实现职业生涯新突破。</p><p></p><p></p><h2>认证有什么作用</h2><p></p><p></p><p>行业认可</p><p></p><p>计算机软件资格考试（下称软考）是由国家人力资源和社会保障部、工业和信息化部领导下的国家级考试，主要目的是科学、公正地对全国计算机与软件专业技术人员进行职业资格、专业技术资格认定和专业技术水平测试。而阿里云认证体系则是结合阿里云丰富的行业实践和生态企业人才需求，输出针对泛云生态人才标准的专业认证体系。软考和阿里云认证均在&nbsp;IT&nbsp;行业备受认可。</p><p></p><p>全方位的技能提升</p><p></p><p>软考认证不仅考察理论知识，更强调实际应用和项目经验，阿里云认证的特点是场景化课程和实验型考核，学员将在学习过程中积累更多的实际工作能力，全面提升技术素养。</p><p></p><p>职业竞争力提升</p><p></p><p>获得软考证书和阿里云认证的人员，表明其已具备从事相应专业岗位工作的水平和能力，更有机会成为团队中的关键人才，拥有更广阔的职业发展空间。</p><p></p><p></p><h2>极客时间认证课程有什么优势</h2><p></p><p></p><p>选择极客时间认证课程，学员将享受到以下诸多优势。</p><p></p><p>全面的课程设置</p><p></p><p>极客时间提供全方位的软考认证课程，深入解析每个学科的重点知识和实践技能。</p><p></p><p>极客时间软考认证涵盖中级-系统集成项目管理工程师、高级-系统设计师、高级-系统架构设计师、高级-信息系统项目管理工程师，阿里云认证涵盖云计算&nbsp;ACP、容器&nbsp;ACP&nbsp;多类目，满足全方位的考证需求。</p><p></p><p>专业的导师团队</p><p></p><p>软考认证课讲师均是软考辅导书编委会成员，熟悉考点和命题套路，教学经验丰富；阿里云认证课程邀请资深从业者担任导师，分享丰富实践经验，为学员提供专业指导。</p><p></p><p>灵活的学习方式</p><p></p><p>知识点精讲和直播冲刺相结合，学员可根据个人时间和进度自主学习，无论是视频课程、实战项目还是交互性学习，均能满足个性化学习需求。</p><p></p><p>实时测评和反馈</p><p></p><p>通过刷题测评和模拟考试，学员可以了解自身学习成果，及时调整学习策略。</p><p></p><p>学习辅导服务</p><p></p><p>为了克服惰性，班主任会全程关注和提醒学习，助教会及时解答课程疑问。软考考试未通过，学员可免费再进入下一班期，阿里云认证考试通过后，极客时间将提供就业内推服务，帮助学员更好地面对职场挑战。</p><p></p><p>极客时间认证的推出标志着我们在职业教育领域的不断创新和发展。认证形式简便高效，适合快节奏的职场人士，我们期望通过这一业务，帮助广大&nbsp;IT&nbsp;从业者更好地适应行业发展变化，更快速、更高效地实现职业目标。点击「阅读原文」访问极客时间认证官网</p><p></p><p>极客时间认证将覆盖多项国际通用认证、国家认证、专业认证产品，我们会一如既往地致力于为学员提供优质的学习体验，共同见证他们在职场上的辉煌成就。欢迎你积极参与认证课程，与极客时间一同开启职业新征程！</p><p></p><p>详情请访问：</p><p><a href=\"https://u.geekbang.org/certificate\">https://u.geekbang.org/certificate</a>\"</p>",
    "publish_time": "2023-12-18 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "微软为Logic Apps（标准版）引入基于AI的工作流助手",
    "url": "https://www.infoq.cn/article/pDT4qwL7sI7sSfxhvBu2",
    "summary": "<p>微软最近发布了一款适用于 Logic Apps（标准版）的工作流助手，Logic Apps 是该公司的集成平台即服务（integration Platform as a Service，iPaaS）产品的公开预览版。借助该助手，开发人员会有一个聊天界面，可以访问 Azure Logic Apps 文档和最佳实践，而无需浏览文档或搜索在线论坛。</p><p></p><p>工作流助手是 Logic App 产品团队为 Logic Apps 提供的又一项功能增强，除此之外，还有 .NET 自定义代码的正式支持、应用程序洞察支持以及数据映射器（data mapper）。这些增强均适用于 Logic Apps 的标准版本，该层级允许开发人员在任何地方运行工作流。</p><p></p><p>工作流助手使用 Azure Open AI 和 ChatGPT 来查询与 Azure Logic Apps 相关的各种知识源，为开发人员构建的工作流提供经过整理的信息。查询结果会被处理成向量化格式，然后通过构建在 Azure App Service 之上的后台系统进行访问。</p><p></p><p>微软 Logic Apps 团队的项目经理 Divya Swarnkar 这样写到：</p><p></p><p></p><blockquote>当你提供输入提示（prompt）时，Azure Logic Apps 后端将执行预处理，并将提示转发给 Azure Open AI 大语言模型。该模型会根据给定的上下文（以工作流 JSON 的形式）和你的提示生成响应。鉴于目前有 1000 多个可用的连接器（connector），该公司建议在选择连接器或行为时使用工作流助手，另外建议在与其他开发人员协作描述工作流时或查找最佳方式构建工作流时使用工作流助手。</blockquote><p></p><p></p><p>Swarnkar 告诉 InfoQ：</p><p></p><p></p><blockquote>我们的核心任务是提高开发人员的工作效率，而 AI 是我们实现这一目标的关键盟友。我们最新发布的工作流助手旨在帮助用户将 AI 无缝集成到工作流中。它提供了革新，并且搭建了发现产品帮助文档、最佳实践、标准模式和创建最佳应用程序的桥梁。</blockquote><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/9d/9d426176848d007fcdf42ea9191929c8.png\" /></p><p></p><p>工作流助手（来源：Microsoft Learn）</p><p></p><p>微软在 iPaaS 领域的竞争对手之一是谷歌，它最近推出了应用集成服务（Application Integration Service），后来又与 Duet AI 进行了集成。应用集成中的 Duet AI 可以根据服务中通过用户界面提供的自然语言描述的需求创建集成流。此外，Duet AI 还能在集成流中创建默认的数据映射，该数据映射能够根据在集成流和集成应用中创建的变量连接两个应用。</p><p></p><p>当 InfoQ 问及微软如何看待工作流助手未来的发展时，Swarnkar 说：</p><p></p><p></p><blockquote>客户反馈和实际问题的解决为 AI 带来了巨大的可能性。我们正在通过工作流助手引入工作流的文档。AI 在应用程序开发的各个阶段，从创建、部署到测试和监控，都具有巨大的增值潜力，客户的反馈将指导我们的投资方向。</blockquote><p></p><p></p><p>最后，有关 Logic Apps（标准版）中工作流助手的更多详情，请参阅文档页面。</p><p></p><p>英文原文：</p><p><a href=\"https://www.infoq.com/news/2023/11/logic-app-workflow-assistant/\">https://www.infoq.com/news/2023/11/logic-app-workflow-assistant/</a>\")</p><p></p><p></p><p></p><p>​​​</p><p></p>",
    "publish_time": "2023-12-18 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "不止 LLM、鸿蒙，与头部大厂交流 2024 年的技术规划｜QCon 上海日程确",
    "url": "https://www.infoq.cn/article/fpevIyjLZm1sElt6um25",
    "summary": "<p>当前，AI Agent 已是公认大语言模型落地的有效方式之一，它让更多人看清了大语言模型创业的方向，以及 LLM、Agent 与已有的行业技术融合应用的前景。</p><p></p><p>智能化信创软件 IDE 旨在将基础软件开发工具的核心技术实现自主可控，在拥抱开源的同时逐步建立基于自有技术内核的架构和标准，形成自有开放生态。其另一大特征是 AI 原生，内核架构从最初的设计开始就思考如何无缝融入人工智能。</p><p></p><p>在前段时间举办的亚马逊云科技 re:Invent 大会和阿里云举办的云栖大会上，都提到了 Serverless 化云产品趋势，Serverless 化云产品具有按量付费、快速弹性伸缩、无需感知底层物理资源，更为经济的运维成本等优势，赢得了业界的广泛认可和积极响应。</p><p></p><p>这些当前最新的技术趋势话题，将在 12 月 28-29 日的 <a href=\"https://qcon.infoq.cn/2023/shanghai/schedule\">QCon 上海</a>\"会议上全部呈现给大家。将围绕这些技术趋势和技术特征展开讨论。</p><p></p><p>此外，会议上还设置了 LLM 时代的性能优化、智能化信创软件 IDE、业技融合驱动金融创新、LLM 推理加速和大规模服务、面向人工智能时代的架构、性能工程：提升效率和创新的新方法、GenAI 和通用大模型应用探索、现代数据架构演进、建设具备战略思维和弹性文化的组织、高性能网关设计、构建本土编程语言生态的实践专题。</p><p></p><h2>大咖齐聚</h2><p></p><p></p><p>会议邀请到顺丰集团 CTO 耿艳坤、美的集团首席信息安全官兼软件工程院院长，欧洲科学院院士，IEEE Fellow 刘向阳、京东集团副总裁、京东零售技术委员会主席尚鑫担任联席主席。</p><p></p><p>中国科学院外籍院士，国际数据库专家樊文飞、亚马逊云科技大中华区解决方案架构部总经理代闻、英特尔大数据技术全球 CTO 戴金权等大咖，将在主会场环节分享他们对新时期的软件开发的洞见，刘向阳老师也会分享 AI 技术和架构结合的话题。</p><p></p><p>来自中国工银科技、火山引擎、腾讯云、PayPal、华为、爱奇艺、Intel、网易、小红书、好未来等公司与单位的近百位大咖，以及数百位来自国内大企业的技术高管，将莅临现场参与本次盛会。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/81/816ce139ef7b8d59a7b21d89c595a614.png\" /></p><p></p><p>&nbsp;不止精彩演讲，还有七大亮点活动，助力 QCon15 周年庆典。</p><p></p><h2>亮点一：「下一站 GenAI」x &nbsp;QCon 上海站</h2><p></p><p></p><p>全国巡回的不一定是演唱会，还可以是生成式 AI。12 月 28 日，承载着最前沿生成式 AI 技术之旅「 下一站 GenAI 」即将抵达 QCon 上海站。作为【下一站 GenAI 】站点之一，你可以在上海站现场探索亚马逊云科技生成式 AI 的过去、现在和未来；体验 re:Invent 全新发布的生成式 AI  Demo ；在构建者游乐场脑洞大开，操纵 PartyRock 生成应用程序 ；边学边玩，最新生成式 AI Jam 挑战；更有“AI 就绪”计划免费全新生成式 AI 课程和专属亚马逊云科技认证折扣等你来拿 ……</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6f/6f5d61c05f1db4fd48e196b0f7e27bf9.png\" /></p><p></p><p>在本次 QCon 上海站，你还能听到最新技术分享，欢迎扫描下方二维码报名亚马逊云科技专场学习 「全球视野：赋能生成式 AI 应用构建与技术出海」。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/78/78cc9d18aa3702c1996d1490241d20a3.png\" /></p><p></p><h2>亮点二：精彩专场，开放交流</h2><p></p><p></p><p>本次会议特别策划<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1615\">「云原生时代的数据架构与性能提升」</a>\"专场，通过扫描下方二维码，可免费报名参加此次专场交流，一同亲身领略最新的数据架构理念，掌握提升数据性能的绝佳方法，更深入地了解云原生时代的技术趋势。</p><p>《云原生环境下的新型超融合数据架构》 by 邓楠 矩阵起源产品总监《解锁 SQL 查询性能：深入理解关系数据库的内部机制与优化策略》by 李小燕 The Trade Desk 首席软件工程师《企业发现云成本优化的新秘密武器》by 于功波 Azul 大中华区技术总监</p><p><img src=\"https://static001.geekbang.org/infoq/d0/d09bc481c99b817fae595aa4c05ac2f0.png\" /></p><p></p><p></p><h2>亮点三：深度共创，闭门研讨</h2><p></p><p></p><p>值此 QCon 中国 15 周年之际，上海站现场还将举办五场高端闭门交流会议，旨在回顾过去 15 年来的技术变革历程，探索技术发展的内在逻辑和规律。同时，立足当下，面向未来，关注未来架构、大前端、数据开发、人工智能以及研发效能等热点话题，帮助参与者深入了解技术领域的最新趋势和发展动态，以及探索行业内部的关键问题和挑战，为参与者提供关于 2024 年技术规划的可拓展的、可持续的、可落地的建议与见解。详细主题及报名方式见下方海报，也可以<a href=\"https://jinshuju.net/f/dA1QbD\">点击此处</a>\"直接报名。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/37/377c5eeb5bcc8121dc98845523d32e94.png\" /></p><p></p><p></p><h2>亮点四：精彩路演，晚场交流</h2><p></p><p></p><p>随着人工智能技术的不断发展，大模型作为其中的重要组成部分，正在逐渐改变我们的生活和工作方式。为了帮助更多人了解大模型的发展趋势和应用现状，我们将特别邀请至少 6 个典型的客户或企业代表分享他们在大模型技术应用方面的经验和成果，免费对外开放，我们期待您的参与！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/09/09ac31a3262751796ddf8776dd91f2b7.png\" /></p><p></p><p></p><h2>亮点五：展区升级，体验升级</h2><p></p><p></p><p>自五月份广州站开始，QCon 每一次现场都设置了大模型体验区，给参会者亲自实操体验大模型，与相关开发者面对面交流的机会。本次 QCon15 周年庆典将对大模型展区大幅度升级，目前已有 10 多家大模型相关企业确认出席，你熟悉的、你想体验的国内最强大模型力量都将来到现场，阵容空前强大，具体名单会前公布。</p><p></p><p>同时，亚马逊云科技、矩阵起源、The Trade Desk、Azul、IPIP、PingCode、Coupang 等合作伙伴也将来到现场，欢迎来展位打卡最新技术产品，参与活动。</p><p></p><p>与国内最强大模型力量零距离接触，亲身体会最前沿的技术和思想，敬请期待！</p><p></p><h2>亮点六：致敬实践，榜单发布</h2><p></p><p></p><p>日前，极客邦科技双数研究院、长城战略咨询、《培训》杂志等多家单位联合发起了「2023 数字化践行者年度力量榜」，中国信通院“铸基计划”作为特约评审单位，面向企业、团队、个人 3 大维度，发掘以数字化变革助力业务发展的实践成果和经验，以期为数字化道路上的同行者带来启发和参考。目前已有涵盖银行、保险、证券、制造、人工智能等行业在内的 50+ 数字化先锋企业筹备参选。</p><p></p><p>榜单的评选结果将在 QCon 上海站现场正式公布，获奖单位 / 个人将受邀参加颁奖活动。同时，入选案例将收录《行知数字中国案例集》，通过 InfoQ 极客传媒与榜单合作伙伴的全媒体渠道，为入选企业提供持续性宣传与品牌曝光。</p><p></p><p>申报截至 2023 年 12 月 17 日，扫描下方二维码获取申报表 ↓↓↓</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/06/063619828b00a889c11a0463bf590aae.png\" /></p><p></p><p></p><h2>亮点七：感恩同路，现场抽奖</h2><p></p><p></p><p>QCon 15 周年生日 Party，没你怎么行？为感谢各位一路同行，上海站现场特地设置两大抽奖活动，分别是 ChatGPT 抽奖和幸运大转盘。</p><p></p><p>目前奖池不断加码，不仅有丰厚的实物奖品，还有实用的学习资料和其他高价值的福利，比如明年大会门票、极客时间会员卡、极客时间课程包、畅销书籍、定制马克杯、文化衫、玩具、帆布袋等等。</p><p></p><p>中奖概率 100%，我们不来虚的！</p><p></p><p>更多大会相关资讯可扫描下方二维码了解。今天是<a href=\"https://qcon.infoq.cn/2023/shanghai/schedule\"> QCon·上海站</a>\" 9 折特惠售票最后 2 天，极客时间企业版新增客户、TGO 鲲鹏会新增会员企业享有折上再减 2 折（最低 5 折）购票优惠，极客时间 VIP 会员享有免费半天体验权益，详情咨询票务经理 18514549229。12 月 28-29 日，我们上海见！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/61/617db6e80380a7105fd78e5c204678bc.jpeg\" /></p><p></p>",
    "publish_time": "2023-12-18 09:49:18",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "银行工程师离职删库，被判两年监禁；华为做得好被指因为“财散人聚”机制；GPT-4.5被疑定价是GPT-4的6倍｜AI一周资讯",
    "url": "https://www.infoq.cn/article/yr9cz9Dzoy16UBxW8ZVF",
    "summary": "<p></p><h2>资讯</h2><p></p><p></p><h4>某银行工程师离职删库并嘲讽同事，被判两年监禁</h4><p></p><p>近日，美国司法部（DoJ）发布了一则判决公告，一名云工程师&nbsp;Miklos Daniel Brody 因被公司解雇后展开蓄意报复，故删除这家公司的代码存储库，最终被判两年监禁并赔偿 529,000 美元。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bc/bc3102158d4bc796d01dbdd80699b1e6.png\" /></p><p></p><p>现年38岁的&nbsp;Miklos Daniel Brody，来自旧金山，此前入职美国的一家商业银行——第一共和银行（FRB），担任云工程师一职。</p><p>&nbsp;</p><p>Miklos Daniel Brody 在&nbsp;2020 年 3 月 11 日便遭到了 FRB 的解雇。至于其中的原因，根据一份法庭文件显示，Brody 违反公司政策，将包含色情等内容的 USB 驱动器连接到公司的计算机，在被发现之后的第二天，公司终止了与 Brody 的雇佣关系，让其在下午四点半左右离开了办公室。</p><p>&nbsp;</p><p>Brody 被解雇之后拒绝归还他工作的笔记本电脑，并在被解雇的当晚使用他仍然有效的账户访问银行的计算机网络，开始了他一系列的报复行为。</p><p>&nbsp;</p><p>Brody不但删除了银行的代码存储库，还运行恶意脚本删除日志，并在银行代码中讥讽同事，Brody还假冒其他银行员工加入会话。</p><p>&nbsp;</p><p>根据公告，Brody还通过电子邮件给自己发送了自己作为员工时使用的专有银行代码，该代码的价值超过5000美元。</p><p>&nbsp;</p><p>在2020年3月12日结束对第一共和银行网络的非法访问之前，Brody先后执行了以下操作：</p><p>&nbsp;</p><p>运行名为“dar.sh”的恶意脚本来擦除第一共和银行的服务器删除了特定脚本的git日志和git提交历史记录访问第一共和银行的GitHub存储库并删除托管代码在代码中插入“嘲讽”内容，包括对“grok”的引用冒充第一共和银行的另一位云工程师访问该公司的网络并进行配置更改</p><p>&nbsp;</p><p>事件发生后，Brody向旧金山警察局谎报称公司发放的笔记本电脑从他的车里被盗。</p><p>最终，Brody于2023年4月承认在笔记本电脑问题上撒谎，并承认两项违反《计算机欺诈和滥用法》的指控。</p><p>&nbsp;</p><p>除了两年监禁和支付赔偿金外，Brody还将被监视居住三年。</p><p></p><h4>GPT-4.5疑定价遭泄漏：价格是 GPT-4 的6倍</h4><p></p><p>外媒有消息称，GPT-4.5 信息疑似泄露。据泄露信息，这款OpenAI 最先进的 GPT 4.5 模型定价被曝光，多模态功能大升级——支持跨语言、音频、视觉、视频和3D的多模态功能，以及复杂的推理和跨模态理解能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bd/bd5bd535fdf254aa80b24443f8a0c153.png\" /></p><p></p><p>目前最早泄漏该信息截图的reddit帖子已经被删除。</p><p>&nbsp;</p><p>从泄漏的截图可以看出，OpenAI这次推出了三种型号：</p><p>&nbsp;</p><p>• GPT-4.5，每1千输入token 0.06美元，每1千输出token 0.18美元；</p><p>• GPT-4.5-64k，每1千输入token 0.12美元，每1千输出token 0.36美元；</p><p>• GPT-4.5-音频&amp;语音，每分钟输入0.012美元，每分钟输出0.024美元；</p><p>&nbsp;</p><p>可以看出，相比之前的 GPT-4 Turbo模型，GPT-4.5 的价格提高了整整6倍，GPT-4.5-64k的价格提高了12倍。</p><p></p><h4>AI代写年终报告标价不足30元，2小时卖出上百份</h4><p></p><p>临到年末，又到了一年一度做年终总结的时候。今年，AI（人工智能）代写火了。相比千字60元-80元的人工写作价格，AI代写只要不到30元的价格，就能得到一个“永久免费使用”的AI写作软件。</p><p>&nbsp;</p><p>据悉，只要输入关键词，立马“一键生成”年终总结报告。打开某购物App，记录显示，有的店铺2小时就卖出了上百份产品。但业内人士提醒，AI代写虽然提高了工作效率，但不可过度依赖，有必要在特定领域对AI功能进行限制。</p><p></p><h4>京东否认裁员传闻：没有任何类似计划，依然在招聘员工</h4><p></p><p>12月13日消息，针对市场传言京东正在裁员的传闻，京东内部人士予以否认，并表示没有任何类似计划。目前京东依然在招聘员工，公司总人数已经达到59万人。</p><p>&nbsp;</p><p>据此前报道，京东正在进行人员调整，涉及科技、物流、零售、工业等多个业务线，赔偿金为N+1，没有年终奖。有员工透露，不同部门的比例有所不同，其所在的部门比例较大，年后或将继续调整。</p><p></p><h4>微软推出27亿参数Phi-2模型</h4><p></p><p>近日，微软发布了一款名为Phi-2的人工智能模型，该模型表现出了不凡的能力，其性能可媲美甚至超越规模是其25倍的、更大、更成熟的模型。</p><p>&nbsp;</p><p>微软在近日的一篇博文中宣布，Phi-2是一个拥有27亿参数的语言模型，与其他基础模型相比，它在复杂的基准测试中表现出了 \"先进的性能\"，这些测试评估了推理、语言理解、数学、编码和常识能力。Phi-2现在通过微软Azure人工智能工作室的模型目录发布，这意味着研究人员和开发人员现在就可以将其集成到第三方应用程序中。</p><p>&nbsp;</p><p>Phi-2由微软首席执行官Satya Nadella（如图）于11月在Ignite大会上首次发布，其强大的功能得益于该公司所称的“教科书质量”数据（专门针对知识），以及学习其他模型传递的洞见的技术。</p><p>&nbsp;</p><p>Phi-2 的有趣之处在于，传统上，大型语言模型的能力总是与其总体规模密切相关，而总体规模是以参数来衡量的。参数越大的模型通常能力越强，但 Phi-2 的出现改变了这种状况。</p><p>&nbsp;</p><p>微软表示，Phi-2在某些基准测试中显示出与更大型的基础模型相匹敌甚至超越它们的能力，包括Mistral AI 70亿参数的Mistral、Meta Platforms公司130亿参数的Llama 2，甚至在某些基准测试中超过了700亿参数的Llama-2。</p><p></p><h4>网传B站游戏研发业务将全部裁员，官方:仅部分项目调整</h4><p></p><p>12月14日，网络流传“B站将向字节看齐，游戏研发全裁”的消息。对此，B站回应表示，相关信息不实，仅部分项目有调整。据财报显示，B站第三季度游戏业务营收9.918亿元，减少33%。今年一二季度，B站游戏业务营收分别为11.3亿元和8.9亿元。而2022年1-4季度，这一数字分别为13.58亿元、10.5亿元、14.7亿元和11亿元。今年前三季度，游戏业务的营收只有2021年全年的58%。</p><p></p><h4>谷歌宣布向云计算客户开放 Gemini Pro</h4><p></p><p>美国时间周三，谷歌发布了面向企业的Gemini Pro，允许开发者利用谷歌最新的人工智能模型构建应用程序。谷歌云客户可以使用 Gemini Pro 创建人工智能聊天机器人、易于查询的库存数据库以及营销演示等应用程序。</p><p><img src=\"https://static001.geekbang.org/infoq/52/52118cda1e5c5573918c56a56ccdc41b.jpeg\" /></p><p></p><p>&nbsp;</p><p>该公司还强调，Gemini Pro最初将免费提供给云客户，但有一些限制。不过，谷歌表示，最终计划确保其云人工智能产品的“价格具有竞争力”。</p><p></p><h2>IT业界热评新闻&nbsp;</h2><p></p><p></p><h4>美商务部长就英伟达对华出售AI芯片表态</h4><p></p><p>美国商务部部长吉娜·雷蒙多表示，英伟达公司有能力、也愿意且应该向中国出售人工智能芯片，这也是符合商业逻辑的。目前，美国商务部正在与英伟达就相关事宜进行讨论。然而，当前监管规定限制了可向中国出售的产品种类。</p><p>&nbsp;</p><p>雷蒙多指出，英伟达希望能在向中国销售人工智能芯片方面“做出正确的选择”。据早些时候的报道，英伟达在中国用于处理大数据和开发人工智能软件的芯片市场上占据了高达90亿美元的份额。</p><p></p><h4>宋志平：任正非不是神仙，华为做得好是因为财散人聚的机制</h4><p></p><p>近日，中国上市公司协会会长，中国企业改革与发展研究会会长宋志平在演讲中提到自己做企业是一个机制主义者。谈及华为时，他表示：“任正非是神仙吗？不是。华为做好是因为它有财散人聚的机制。但是如果没有机制，神仙也做不好。这是最最核心的。所以，做企业应该有机制。”</p><p>&nbsp;</p><p>“这个机制也在随着我们的认识在变化，最早的时候讲的比较多的叫激励机制，但是现在讲共同富裕，应该改成共享机制。所谓“共享”就是把人，把管理层、技术骨干、员工，把他们的人力资本当成资本，让人力资本和财务资本共享企业的财富。因为这不光能够调动大家的积极性，也体现了公平。”他说。</p>",
    "publish_time": "2023-12-18 10:10:01",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "洞见 re:Invent：生成式 AI 与云共舞，成为构建者最好的时代来临！",
    "url": "https://www.infoq.cn/article/131zKtx58AANp4CF9bd9",
    "summary": "<p>不久前，亚马逊云科技 re:Invent 2023 在拉斯维加斯圆满落幕，会上发布了一系列对行业带来深远影响的产品及服务，并由此引发了圈内的广泛探讨。为了能够更加清晰地理解这家全球云计算巨头的战略意图，以及这次大会对开发者带来的深刻影响，InfoQ 中国创始人霍太稳在 re:Invent 2023 现场采访了亚马逊云科技大中华区解决方案架构部总经理代闻，以下为经编辑整理后的访谈实录。</p><p></p><p></p><h2>完整的端到端能力：亚马逊云科技的生成式 AI 全景图</h2><p></p><p></p><p>本次 re:Invent 大会，最引人瞩目的无疑是“生成式 AI”，亚马逊云科技首席执行官 Adam Selipsky 表示：围绕生成式 AI 模型的创新具有爆炸性，它将重塑我们在工作和家庭中交互的每一个应用程序，我们正在以一种跟以往完全不同的方式来探讨生成式 AI 的概念。</p><p></p><p>由此，亚马逊云科技围绕生成式 AI 的全新技术堆栈诞生，这也是目前业内最早围绕开发者和用户公布完整的生成式 AI 应用开发端到端能力的厂商之一。</p><p></p><p>亚马逊云科技大中华区解决方案架构部总经理代闻表示，亚马逊云科技的生成式 AI 技术堆栈共由三层技术栈组成，自底向上分别是基础设施层、基础模型服务层和 AI 应用层。在该架构之下，一方面亚马逊云科技会利用自研的芯片、模型、数据、服务等综合能力，确保在计算能力与成本之间取得平衡；另一方面，为了给到开发者和客户更多样化的选择，亚马逊云科技也将持续与英伟达、Anthropic 等软硬件厂商保持紧密合作。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/44/44a8135984980fd94af8d29ad7ff5d72.png\" /></p><p></p><p>他进一步解释道：“在基础设施层，主要包括用于训练和推理的基础设施和 MLOps 平台，共同为生成式 AI 提供稳定可靠的计算和存储等能力的支持。”</p><p></p><p>事实上，凭借着 Nitro 虚拟机管理程序以及 Graviton、Trainium 和 Inferentia 等芯片家族，亚马逊云科技已经积累起丰富的芯片开发技术经验。在今年的 re:Invent 大会上，亚马逊云科技更进一步，推出了为生成式 AI 和机器学习训练而生的云端 AI 芯片 Amazon Trainium2 和 Inferentia2，以及自研服务器 CPU 芯片 Amazon Graviton4。</p><p></p><p>“模型层主要负责模型的调用、微调、优化等，帮助用户更加灵活和高效地使用生成式 AI 技术，提高模型的性能和效率。这次发布会，我们也重磅升级了 Amazon Bedrock。它是一个可对托管基础模型进行访问的平台，其中既包括亚马逊云科技自身的 Amazon Titan 系列大语言模型，也提供来自其他厂商及开源生态系统的神经网络选项。”代闻介绍道。</p><p></p><p>值得一提的是，针对 Amazon Bedrock，亚马逊云科技此次还公布三项新功能：模型微调、检索增强生成（RAG) 与大模型预训练，允许客户针对特定任务对 Bedrock 中的大模型进行定制。</p><p></p><p>应用层主要包括各种生成式 AI 应用，如自然语言处理、图像识别、语音识别等。亚马逊云科技新推出的生成式 AI 助理 Amazon Q 也包含在这一层中。这些应用可以帮助企业快速构建和部署 AI 应用，提高业务效率和创新能力。</p><p></p><p>代闻表示：“总的来说，这三层 AI 堆栈里面，底层面向的是大模型的构建者，中间层面向大模型的使用者，最上层面向生成式 AI 应用的开发者。”</p><p></p><p>谈及这些发布对开发者究竟有何影响，代闻表示，对于国内大模型开发者而言，如何以更低的成本训练出高质量的模型才是重中之重。这涉及到两大核心问题：一是有没有强大的芯片支持，二是有没有便捷的框架来调度这些计算资源。恰好亚马逊云科技平台为用户提供了丰富的选择，包括高效的 GPU、机器学习和推理芯片，以及用户友好的 Amazon SageMaker 机器学习框架等等。</p><p></p><p>“对于希望在企业内部实际应用大模型的用户来说，亚马逊云科技的 Amazon Bedrock 则是个不可或缺的工具。如果没有它，开发者可能需要投入大量精力进行毒性过滤和鲁棒性评估等工作。但现在，有了这个标准化平台，开发者可以直接使用它的 Guardrails 等功能来解决上述问题，大大简化了工作流程。”代闻补充介绍道。</p><p></p><p>此外，对于纯应用开发者，比如移动 APP 开发者。代闻表示，即使没有大语言模型的知识，开发者们也可以利用亚马逊云科技的应用层服务，比如 Amazon Q 来轻松整合后台的各种数据源，来为 APP 增添新功能等。</p><p></p><p>综合来看，从底层基础设施到中间的基础模型，再到顶层 AI 应用，透过这张 AI 全景图，显而易见的是亚马逊云科技多年来在前沿技术领域的持续深耕，由此沉淀下来的端到端的综合实力。生成式 AI 浪潮的出现，正在全面影响技术行业，而亚马逊云科技希望以“全家桶”式的产品服务，帮助企业与开发者掌握先机。</p><p></p><p></p><h2>生成式 AI 正在全面影响技术行业</h2><p></p><p></p><h3>重构开发规则与业务流程</h3><p></p><p></p><p>毋庸置疑，生成式 AI 正在全面、广泛且深刻地影响着技术行业，但是对于企业和开发者而言，盲目地使用生成式 AI 产品很可能会对业务增长带来适得其反的效果，先进的技术与工具是否能够跟现有的业务流无缝链接、深度融合才是关键。而这一次的 re:Invent 大会上的一系列生成式 AI 产品的发布，则是在向全行业宣告 “企业级生成式 AI 工具” 正式到来了。</p><p></p><p>回顾 re:Invent 2023 生成式 AI 方面的重要发布，最令开发者兴奋的可能就是 Amazon Q 了。Amazon Q 是一项新型生成式 AI 辅助服务，官方定义其为——为业务量身定制的生成式 AI 助手，可以帮助员工快速利用公司的数据和专业知识获得问题答案、解决问题、生成内容等，同时还能根据企业客户的业务进行个性化定制。</p><p></p><p>据介绍，Amazon Q 主要面向生成式 AI 应用的开发，目前已经具备四个方面的能力：</p><p>亚马逊云科技专家：对亚马逊云科技的每一个功能、模块都有充分的了解。业务专家：能够自动分析行业状况及下游客户的需求。商业智能专家：能够对大量商业数据进行分析，从而辅助决策。客服专家：对用户企业情况充分了解，可以充当智能客服工作。</p><p></p><p>代闻补充介绍道，首先是关于亚马逊云科技平台本身的开发，Amazon Q 能够显著提高开发者的效率。比如，如果你想知道如何在亚马逊云科技上构建一个网站，你可以直接咨 Amazon Q，它会在控制台内为你提供答案。如果你不清楚如何使用亚马逊云科技的某项服务，在过去你可能需要花费数小时搜索文档，但现在只需提问，Amazon Q 就能立即为你提供操作步骤，甚至生成所需的代码片段。</p><p></p><p>其次，在业务层面，Amazon Q 可以收集并连接多个数据接口，提取数据，并根据 Insights 进行综合分析，从而直接支持业务需求。</p><p></p><p>在 BI（商业智能）方面，Amazon Q 可以直接让用户在 QuickSight 等 BI 工具中提问，并进行 BI 级别的分析。</p><p></p><p>在呼叫中心方面，Amazon Q 能够直接被集成到亚马逊云科技平台上，从而帮助企业提升呼叫中心的运营效率。一方面，通过云计算的弹性和可扩展性，Amazon Q 能够根据实际需求自动调整资源投入，确保在高峰期提供稳定的服务；另一方面，通过亚马逊云科技平台，企业可以方便地获取并分析客服数据，了解客户需求和行为模式，为产品优化和市场策略制定提供支持。</p><p></p><p>另外，Amazon Q 还已经扩展到了 ETL 工具 Glue 中，你可以使用自然语言的方式来生成 ETL 代码。甚至在 RedShift 数据仓库中，你也可以利用 Amazon Q 的功能来助力查询等。</p><p></p><p>从某种意义上说，Amazon Q 的出现，就是为了帮助企业在做工程化的过程中能够获得更多标准化能力的支持，从而减少大量的重复性劳动。</p><p></p><p>“只要是通过亚马逊云科技的产品或服务写的代码，都可以使用 Amazon Q 来进行查询、分析、纠错等等；对于 BI（商业智能） 也一样，Amazon Q 能够直接把大模型的能力给到你，无论是数据的提取、异跳、查询以及 BI 展现，都能一站式解决。这些背后都源于我们给 Amazon Q 做了非常多标准化接口，并且能与业务流做整合。”代闻解释道。</p><p></p><p>除了面向生成式 AI 应用开发者的 Amazon Q 外，面向大模型使用者的 Amazon Bedrock 同样引发了广泛的关注。此次发布会上，Amazon Bedrock 迎来重磅升级，增加了 Fine-tuning、Agents、Knowledge Bases、Guardrails 等全新功能，旨在帮助客户更高效、智能、安全地构建应用。</p><p></p><p>发布会上，Adam 表示：“不会有一种模式能够统治一切，你需要尝试不同的模型，你需要选择合适的模型提供商。”据悉，Amazon Bedrock 支持 Stability AI、AI21 labs、Anthropic、Cohere、Meta，以及 Amazon Titan 等各类大语言模型或基础模型，为客户带来了更多的开放选择，目前已经吸引了超过 1 万名客户使用。</p><p></p><p>对于 Amazon Bedrock 开放兼容，代闻表示：“我认为对于客户来说，这不只是一个模型选择的问题，还有选择模型以后，怎样在自己的环境里面落地的问题。”</p><p></p><p>在大模型百花齐放的今天，究竟怎样的大模型才是最适合自身企业的大模型？这是很多企业想要得到的答案。Swami 在演讲里提到了一个金融科技公司 INTUIT 的案例，该客户表示虽然有非常多的大模型可供选择，但是就算选择了一个非常适合的大模型，也还是需要做一定的定制化，包括 Fine-tuning 能够使用自有语料，让它变成能够在自身企业上下文里理解问题、产生内容的大模型。</p><p></p><p>“其实我觉得这一点在 ToB 领域会更加明显，因为在 ToB 领域，各种行业的知识和交互都有特定的上下文，比方说在医疗行业里或在制造行业里，它们的上下文都是不一样，甚至一样的话可能有不一样的意思。在国内叫定制化，也刚好是这次 Amazon Bedrock 它进一步增强的能力。”代闻表示。</p><p></p><p>对于 Amazon Bedrock 的最新进展，代闻进一步补充道：“第一是 Amazon Bedrock 它已经严选了一批模型，覆盖了多种自然语言的交互，甚至包括一些小语种；第二，在网络安全层面，Amazon Bedrock 采用了单独的 VPC 做隔离，能保障模型的安全性和数据的隐私性；第三是 Amazon Bedrock 目前已经宣布对所有的库内模型提供 Fine-tuning 支持，能够帮助企业开发者更好地定制大模型。”</p><p></p><p>此外代闻还提到，虽然 Amazon Bedrock 才推出不到半年，但是已经有很多国内厂商在积极加入。比如，金山办公在 WPS 出海业务里已经使用了 Amazon Bedrock，之后亚马逊云科技也将会与金山办公的客户一起将 Amazon Bedrock 的一些新功能融入到业务场景中去。</p><p></p><p>总的来说，Amazon Bedrock 的这些更新不仅只是效率、灵活性、拓展性等方面的提升，更重要的是明确地传达了一个信息：在 AI 的开发和应用中，技术和道德、功能和责任是并行不悖的，也即是发布会上，亚马逊云科技反复提及的 “Responsible AI” 的理念，而这无疑是对整个行业的一个重要提醒和指引。</p><p></p><p></p><h3>新的范式下，云计算与生成式 AI 如何相辅相成？</h3><p></p><p>作为云计算行业的年度盛会，在与生成式 AI 碰撞之后，又会产生哪些新的火花与思考？</p><p></p><p>“用一个比较通俗的形容来说，云计算与生成式 AI 是相辅相成的关系。假设回到十年前，云计算还没诞生，我想生成式 AI 也很难实现，因为它背后需要大量的数据、大量的算力支撑等等，没有云计算和高性能的芯片支撑，是很难实现的。所以云计算本身的意义就在于计算的普惠，而生成式 AI 又大大地促进了技术对人类生产生活方式的改造。而且现在大家逐渐有了一个共识——只有在云上来做生成式 AI，才能够更进一步地普及生成式 AI。”代闻如是地答道。</p><p></p><p>“再反过来，生成式 AI 其实对云计算也会带来革命性的改变。比方说之前云计算本身很大一个方面是自动化。自动化以后我们就有 API，那现在有生成式 AI 以后，代码都可以自动生成了，再与 Serverless 结合之后，如果我们想生成一个网站，使用自然语言完全就可以实现。”代闻补充道。</p><p></p><p>事实上，现在亚马逊云科技社区里，已经推出了一项生成式 AI 试玩工具——Amazon PartyRock，开发者可以用自然语言的方式去实现基于云的生成式 AI 应用开发。关于 Amazon PartyRock 的更多玩法，我们同样有在 re:Invent 现场采访亚马逊云科技副总裁、首席布道师 Jeff Barr，听他谈谈 《生成式 AI 时代，开发者们如何玩转 PartyRock？》。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c4/c42138b7011e7fd5b5403965f88cecfb.png\" /></p><p>👆 扫码围观&nbsp;👆</p><p></p><p>对于“云 + 生成式 AI”如何更好地赋能开发者，代闻表示，云其实是一个抽象工具，它首先抽象了所有的基础设施，然后再抽象了很多的平台软件，包括各种应用类、数据类的，进而我们又有了 Serverless 的编程方式。一方面，生成式 AI 的出现可能会进一步加速 Serverless 的普及，因为当一个组织里的技术人员，都开始思考怎样更好地应用生成式 AI、怎样提出更好的问题时，一些无差别的运维工作或者基础开发工作，通过生成式 AI + Serverless 的方式，很快能够做出来；另一方面，生成式 AI 的落地也需要结合 Serverless 的一些服务，去促进它的平台建设，当然这也是一个持续抽象的过程，比如基础设施抽象成基础设施即服务的接口，数据服务又抽象出数据服务的接口，应用服务抽象出应用服务的接口等。</p><p></p><p>对于 Serverless 的优势，他进一步举例道，亚马逊云科技新发布的 Amazon ElastiCache &nbsp;Serverless 缓存服务，能够把整个集群的内存容量扩到 5 个 TB。如果企业自己运营一个 5TB 的集群，运维工作量非常大。但是在云上其实只要使用 Amazon ElastiCache Serverless，就可以轻松地获得这个能力。包括这次发布 Amazon Aurora Limitless Database，也是一个 Serverless 的体现，它可以支持 PB 级的容量、百万级的写并访问，传统做法肯定是得用多个 Aurora 的 Instance 做分库分表，并且需要自己持续维护，但现在通过云上原生的一些能力就能实现，就像你写在一张表或者一个 Database 里面的效果，大大简化了运维，同时拥有更好的性能。恰好，Serverless 的这些能力也同样适用于生成式 AI 应用的构建。</p><p></p><p>从某种意义上来说，“云＋生成式 AI”的核心优势就在于——开发者们通过云原生的环境去构建生成式 AI 应用，随时随地、且无限制地使用云上最新的资源、工具与服务，只需要专注于开发本身即可。而这也即是亚马逊云科技所倡导的“成为生成式 AI 原生开发者”。</p><p></p><p></p><h3>Let's 构！“现在是成为构建者最好的时代！”</h3><p></p><p>事实上，无论是面向企业开发者的 Amazon Q 还是面向大模型使用者的 Amazon Bedrock，亦或是更早发布的面向个人开发者的 AI 编程工具 Amazon CodeWhisperer，随着生成式 AI 能力的增强与场景实践日益丰富，开发的门槛被大大降低，用自然语言进行编程正在逐渐成为现实。</p><p></p><p>“以前如果一个企业有数据中心，那就需要风火水电以及相应的运维工程师，但是现在有了云计算，大家可以省去这些基础运维了，基础性物理硬件维护都变少了。工程师们更多思考的是怎么样升级技能，把时间精力放在离业务价值更近的地方去。生成式 AI 也一样会带来类似的变化，这其实都是技术更迭带来的结果。”代闻表示。</p><p></p><p>面向未来，通过使用生成式 AI 工具，人人都可能成为开发者或者更准确的说是构建者，人们可以节省大量的重复劳动的时间，将精力集中在实现业务目标上，低代码和零代码平台同样也是这一趋势下的产物。</p><p>“但是虽然生成式 AI 工具能够帮你解决很多基础性问题，但这并不意味着你不需要学习，因为生成式 AI 之下，你得提出好问题，这样才能依托工具得出理想的结果，如果你不学习，缺乏系统性认知，其实是没有办法来提出有效的问题的。”代闻补充道。</p><p></p><p>对于传统的开发者而言，如何面对生成式 AI 的浪潮，需要做出怎样的改变，是亟需思考的一个话题。事实上，随着生成式 AI 的广泛应用，无论是开发者的技术路径还是职业发展路径，都可能会受到影响。</p><p></p><p>“我觉得对于开发者而言，首先是要拥抱技术趋势，不断学习。在亚马逊云科技的公司文化里，有一条叫‘learn and be curious’，即好奇求知。对于技术人员或者每一个人来说，好奇求知是应对技术更新和环境变革的最好方式；其次是要保持冷静，从自己的真实工作环境出发，去思考生成式 AI 能够给自己带来怎样的价值。很多网文贩卖焦虑，但在实际落地时，更应该与自己的实际需求形成闭环，比如短期内通过生成式 AI 的帮助能带来一个立竿见影的结果。只有这样才能大大推动生成式 AI 在组织中的利用，也为开发人员提供了一个正向的反馈。”代闻解释道。</p><p></p><p>针对不同背景的开发人员，如数据开发人员和传统的 Java 前端开发人员，他表示可以根据自身技能和背景直接使用已经开箱即用的生成式 AI 服务，比如通过亚马逊云科技提供的各种服务快速构建生成式 AI 应用，找到最小成本的体验路径和最快的正向反馈。</p><p></p><p>事实上，一项新的技术的提出并广泛推广，往往需要更多来自组织层面的力量。代闻强调在实际项目中，生成式 AI 的成功落地与业务部门的支持息息相关。生成式 AI 的浪潮与之前的 AI 项目有所不同，现在企业的业务部门甚至一把手都意识到了生成式 AI 对于降本增效的重要性，因此他们会支持这样的项目。这种支持也会让技术人员有更多的机会去了解和应用生成式 AI，促使技术人员成为“业技复合型”人才。同样也会对生成式 AI 的技术普惠和个人的职业生涯发展带来积极的影响。</p><p></p><p></p><h2>技术前轮，市场后轮，生成式 AI 普惠已来</h2><p></p><p>当然，除了生成式 AI 方面的一系列重磅发布，本届 re:Invent 同样也带来了一系列云计算领域的新突破：比如亚马逊云科技全面升级 S3 对象存储服务 Amazon S3 Express One Zone，能够提供个位数、毫秒级的每秒数十万次数据访问，并且请求成本降低 50%，计算成本降低 60%；还比如宣布了 4 项新的 Zero-ETL 集成功能，使客户能够快速、轻松地连接和分析数据，而无需构建和管理复杂的提取、转换和加载（ETL）数据管道等等。</p><p></p><p>技术的车轮滚滚向前，对于企业而言，只有不断拥抱变化，持续创新，才有可能基业长青，从亚马逊云科技今年在生成式 AI 领域的大放异彩中，可见一斑。“总的来说，对于开发者而言，我认为理性看待生成式 AI 的浪潮，保持学习，并且积极利用先进的生成式 AI 工具解放双手，提高生产力、激发创造力，才是关键。”代闻总结道。</p><p></p><p>re:Invent 2023 带给行业最大的惊喜在于：伴随着亚马逊云科技一系列的生成式 AI 产品和云服务的发布，AI 普惠的力量开始从产业端、企业端，更进一步落位到个体端的构建者身上。构建者们可以利用这套全新的、融入业务流的生成式 AI 工具去重构业务，并且能够以更强的主观能动性去创造更大的社会价值。</p><p></p><p>期待更多的企业和开发者能够通过各种生成式 AI 产品或服务去重构未来竞争力，助力业务创新，进而推动生成式 AI 技术的普惠。而在这个过程中，亚马逊云科技或许会持续带给行业更多惊喜。</p>",
    "publish_time": "2023-12-18 10:18:31",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "作业帮大数据平台架构负责人孙建业确认出席 QCon 上海，分享作业帮大数据湖仓架构和实践",
    "url": "https://www.infoq.cn/article/wqQSCIih229MRTwr7Ieu",
    "summary": "<p><a href=\"https://qcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=1218&amp;utm_content=sunjianye\">QCon 全球软件开发大会</a>\"，将于 12 月在上海召开。作业帮大数据平台架构负责人孙建业将发表题为《<a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5636?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=1218&amp;utm_content=sunjianye\">作业帮大数据湖仓架构和实践</a>\"》主题分享，从作业帮现有架构面对的挑战出发，结合真实的业务场景，探讨相关数据湖仓技术方案和实践经验。</p><p></p><p><a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5636?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=1218&amp;utm_content=sunjianye\">孙建业</a>\"，曾就职于 Talkingdata、摩拜、美团，多年大数据研发经验。目前就职于作业帮平台架构部，主要负责组件维护、平台架构和成本管控。他在本次会议的演讲内容如下：</p><p></p><p>演讲：作业帮大数据湖仓架构和实践</p><p></p><p>随着数据湖相关技术的逐渐成熟、湖仓理论的发展，生产环境落地已经非常广泛。相比较传统数仓在数据更新时效性、查询索引增强等方面有明显优势，在基于云对象存储的存算分离架构下表现更为突出。本次演讲将从作业帮现有架构面对的挑战出发，结合真实的业务场景，阐述相关数据湖仓技术方案和实践经验。</p><p></p><p>演讲提纲：</p><p></p><p>现有架构的挑战</p><p>○ 作业帮现有数据架构</p><p>○ 架构缺陷及历史问题</p><p>Iceberg 介绍</p><p>○ 元数据结构 &amp; 特性</p><p>湖仓整体架构</p><p>○ 典型场景 </p><p>○ 架构方案</p><p>湖仓实践</p><p>○ 采集入湖实践 </p><p>○ 离线计算实践</p><p>展望和不足</p><p></p><p>听众收益点：</p><p></p><p>○ 作业帮的业务场景及可复制的湖仓架构设计</p><p>○ HIVE 到 Iceberg 迁移及 Iceberg 应用实践</p><p></p><p>除上述演讲外，QCon 上海还将围绕&nbsp;<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart\">GenAI和通用大模型应用探索</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1596?utm_source=infoqweb&amp;utm_medium=teacherart\">AI&nbsp;Agent&nbsp;与行业融合应用的前景</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart\">LLM&nbsp;时代的性能优化</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart\">智能化信创软件&nbsp;IDE</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart\">面向人工智能时代的架构</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart\">性能工程：提升效率和创新的新方法</a>\"等专题进行交流。</p><p></p><p>12 月 28-29 日，QCon 全球软件开发大会即将落地上海，中国科学院外籍院士、国际数据库专家樊文飞院士，英特尔大数据技术全球 CTO 戴金权等大咖会亲临现场分享大数据、芯片、架构等方向的前沿洞见。</p><p></p><p>这次会议主要探讨大模型的全面技术架构的进化，不仅有跟大模型本身相关的推理加速、AI Agent、GenAI，还有架构的演进思路、性能优化，以及以智能代码助手为代表的研发效能提升等方向，感兴趣的朋友可以扫描下方二维码，查看大会详细日程。咨询购票可联系票务经理 18514549229。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/0113b3dfb187d5f9988b7eb16d2e0594.png\" /></p><p></p>",
    "publish_time": "2023-12-18 11:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Tech Talk丨生成式 AI 重构开发者未来竞争力",
    "url": "https://www.infoq.cn/article/SXwiL4YY9WdLVupuW82V",
    "summary": "<p>re:Invent 2023 圆满结束，在会上亚马逊云科技发布了一系列新产品、新服务、新工具等，其中最令开发者们兴奋的便是生成式 AI 方面的产品服务，包括面向生成式 AI 的 Graviton4 和 Trainium2 芯片、Amazon Q、Bedrock、PartyRock等等开发平台或工具；除此之外，会上还公布了亚马逊云科技在 Serverless 等方面的最新进展。</p>\n<p>透过 re:Invent 2023，我们能看到哪些技术趋势？有哪些值得开发者关注的重点？又该如何去体验相关的产品或者服务？</p>\n<p>12 月 13 号 19:00，极客邦科技创始人兼 CEO &amp; InfoQ 中国创始人 霍太稳对话亚马逊云科技大中华区解决方案架构部总经理 代闻，围绕 re:Invent 2023 上的最新发布展开探讨。</p>\n<p>探讨内容如下：<br />\n生成式 AI 正在重塑开发工具与开发规则<br />\n深度解析亚马逊云科技推出的全栈生成式 AI 服务<br />\n生成式 AI 时代，开发者们如何构建未来竞争力？</p>",
    "publish_time": "2023-12-18 12:05:39",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "围绕“五篇文章”调整价值导向，银行2024年“开门红”可否带头退“卷”",
    "url": "https://www.infoq.cn/article/43yPLOMShGFKTbu0z77V",
    "summary": "<p>近期，中央金融工作会议、中共中央政治局会议、中央经济工作会议先后召开，为明年的经济工作、金融工作指明了重要方向，综合学习三次会议的公告精神，调整银行经营方向，加强与宏观政策取向一致性是2024年银行工作的重中之重。</p><p></p><h2>一、2024年宏观政策综合学习</h2><p></p><p>&nbsp;</p><p>三次会议均包括对明年经济形势的重要研判和方向指导，总基调上，稳中求进，稳字当头；目标上，做好三个“统筹”（统筹扩大内需和深化供给侧结构性改革，统筹新型城镇化和乡村全面振兴，统筹高质量发展和高水平安全），把握三个关注点（切实增强经济活力、防范化解风险、改善社会预期），巩固和增强经济回升向好态势，实现新格局下的高质量增长。</p><p>&nbsp;</p><p>落实措施上，坚持稳中求进、以进促稳、先立后破，稳预期、稳增长、稳就业；财政政策重点是适度加力、提质增效，货币政策重点灵活适度、精准有效，二者都体现了时度效的要求；要以科技创新引领现代化产业体系建设；要着力扩大国内需求；要深化重点领域改革；要扩大高水平对外开放；要持续有效防范化解重点领域风险；要坚持不懈抓好“三农”工作；要坚持尽力而为、量力而行，切实保障和改善民生。</p><p>&nbsp;</p><p>更细节的工作要求上，货币政策强调了总量和结构双重功能，引导金融机构加大对科技创新、绿色转型、普惠小微、数字经济等方面的支持力度；</p><p></p><p>科技创新是方向之首，强调对“以颠覆性技术和前沿技术催生新产业、新模式、新动能”的关注，“发展新质生产力”，这是“先立后破”的一个重要举措，“要大力推进新型工业化，发展数字经济，加快推动人工智能发展”，“打造生物制造、商业航天、低空经济等若干战略性新兴产业，开辟量子、生命科学等未来产业新赛道，广泛应用数智技术、绿色技术，加快传统产业转型升级”，寻找新的、引领产业升级的增长点，这是实现增长动能转化的基础；</p><p></p><p>扩大内需方面，“数字消费、绿色消费、健康消费”，“智能家居、文娱旅游、体育赛事、国货“潮品””，“新能源汽车、电子产品”等都是榜上有名的消费促进方向，会议公告也提到供给、消费两侧的调整，产业升级生产出来的东西必须要有人消费掉，所以，产业升级也意味着消费升级，有了消费升级才有更好的产业升级，“推动大规模设备更新和消费品以旧换新”，当然，消费升级关键的还是离不开“增加城乡居民收入”；</p><p></p><p>在改革方面，对国企的要求是增强核心功能，民企则在市场准入、要素获取、公平执法、权益保护等方面迎来新机遇，还要有效降低全社会物流成本，物流产业的发展也是会重点支持的；</p><p></p><p>在开放方面，由于既要降低社会融资成本，又要保持汇率稳定，那么从汇率形成的角度看，增加投资吸引力是必然要采取的措施之一；</p><p></p><p>在风险防范方面，重点是房地产、地方债、中小金融机构三个领域，“先立后破”对地产领域的反思应该不仅限于最近几年地产业出现的状况，而有可能是回顾整个地产行业的发展历程；</p><p></p><p>在“三农”方面，提到了“强化科技和改革双轮驱动”以及“建设宜居宜业和美乡村”，这对引导人员合理流动而言是非常必要的，“三农”也是数字时代的“三农”了，这与 “城乡融合、区域协调发展”的部署是相呼应的，“推动以县城为重要载体的新型城镇化建设”，城市规模过大会造成的问题也是显而易见的；</p><p></p><p>在“低碳发展”方面，“完善生态产品价值实现机制”仍是需要多动脑筋的点，“落实集体林权制度改革”则已经是非常现实的需要了；在民生方面，“更加突出就业优先导向”、“发展银发经济”可以说是政策重点导向，少有所为，老有所养。</p><p>&nbsp;</p><p>笔者一直认为银行各级人员都需要认真研究、深刻领会国家政策方向，因为国家政策要求的内容不是银行要做的，就是银行服务的客户要做的，最终都会跟金融发生千丝万缕的联系，笔者上述对会议通告的介绍，都属于银行该关注的业务方向。国家层面已经开始重点要求宏观政策取向的一致性了，那么，银行自己的“一盘棋”又如何、该如何呢？</p><p></p><h2>二、如何做好银行的“五篇大文章”</h2><p></p><p></p><h4>（一）统筹学习，认真领会</h4><p></p><p>&nbsp;</p><p>既是“五篇文章”也是“一篇文章”，一个银行，一套答卷，不是五个科目分别交卷，不同银行规模、禀赋不同，不是每家银行都能完美交上五张答卷，何况有的银行要先交的还是风控的卷子，一地一策、一行一策，货币政策要“灵活适度、精准有效”，银行经营也一样。</p><p></p><p>“五篇文章”也有分工，比如“<a href=\"https://www.infoq.cn/article/ROrh4hSJPu1UkXzx5Uhc\">数字金融</a>\"”，既是所有文章的基础，也是自成一体的文章，中小金融机构风险化解这个课题中，对实力不足、风险较大的金融机构进行地区性整合可能是必由之路，但是整合不能只是资产、负债，更要整合的是数字化能力，将小机构负担不起、执行不来的数字化工作落实到位，自身数字化不到位，如何理解客户的数字化？如何支持数字经济建设？大型金融机构的数字化工作资源充足，进展显著，正是将数字化能力和经验用于支持客户数字化的好时机，支持客户数字化就是在实体层面支持数字经济建设，这正是体现“业技融合”能力的地方。</p><p></p><p>不要把“五篇文章”简单转化成任务指标，这其中蕴含着执行货币政策“存量和结构双重功能”的要求，如何在存量适度增长的情况下，完成230多万亿金融资产结构的转换，这是从2024年“开门红”起就应体现的工作方向。</p><p></p><h4>（二）加强“科技金融”、“普惠金融”，推动结构转换</h4><p></p><p>&nbsp;</p><p>就结构调整而言，“科技金融”、“普惠金融”是有“扳道岔”能力的，毕竟这两项业务可以做成“体量”，有足够的“体量”才能转换结构。从会议精神看，“科技金融”命题范围很大，颠覆性技术、前沿技术、新质生产力、产业链高质量发展、人工智能发展、生物制造、商业航天、低空经济、量子、生命科学、数智技术、绿色技术、应用基础研究等等，都属于该命题，它是科技突破，也是产业升级，既有风险投资，也有传统的技改贷款，银行需要在贷款类别上进行重新规划，精确统计资金流向，笔者之前会议精神解读文章提到的可灵活调整的“客群规划”能力也很重要，没有这些调整能力，很难做到在业务方向上随时跟进政策导向。</p><p></p><p>“普惠金融”的范围更大，从落实中央经济工作会议精神的角度看，扩大国内需求、深化重点领域改革、化解重点领域风险、抓好“三农”工作、城乡融合、区域协调发展、切实保障和改善民生这些方面都与“普惠金融”有着密切联系，即便在“扩大高水平对外开放”中也提到关注“小而美”的民生项目，所以，“普惠金融”真的该认真关注。</p><p>&nbsp;</p><p>对于“稳预期、稳增长、稳就业”这三个“稳”字当头的政策目标而言，如果说“科技金融”侧重的是从前瞻性的视角实现“稳”，“普惠金融”则是实打实的从基本盘上实现“稳”，对银行来讲，这不仅是业务，更是责任。这两篇文章是银行需要特别关注的，而且，在本次中央金融工作会议精神指引下，银行的市场竞争应当适度，“科技金融”、“普惠金融”需要的可能是整体信息体系、信用体系、联合风险分担机制的完善，需要更多的分工合作而非简单竞争，尤其是在业务结构转换过程中，银行体系里还有中小金融机构风险化解这个命题。关于“普惠金融”的一些开展建议可以<a href=\"https://www.infoq.cn/article/T7cUzo9pjuiXXVsdSRjc\">参考笔者上一篇文章的介绍</a>\"。</p><p></p><h4>（三）做好“绿色金融”、“养老金融”，助力持续发展</h4><p></p><p>&nbsp;</p><p>就总量而言，“绿色金融”、“养老金融”确实未必能在整个银行资产体系中占比很高，但仍需要银行将其作为业务调整方向进行重点关注，就业务而言，“绿色金融”具有地区性特征，“养老金融”更具普遍性，但是二者都涉及金融产品的持续演进和创新能力，可以在全盘业务的关联性上进行考虑，不应苛求一点，而是纵观全局，这一点对大型金融机构而言尤其如此。</p><p>&nbsp;</p><p>“绿色金融”对绿色低碳供应链的研究、对生态产品价值实现机制的研究和集体林权制度改革的落地应用是需要关注的；“养老金融”中提出的“兜住、兜准、兜牢民生底线”、“发展银发经济”都需要金融产品的创新发展。如笔者之前解读文章提到的，这两篇文章代表的可持续性、文明性也是银行需要考虑的问题。</p><p></p><h4>（四）立足“数字金融”，转换、提供金融动能</h4><p></p><p>&nbsp;</p><p>本部分一开始就提到，“五篇大文章”各有分工，在之前的解读也中提到过，“科技金融”可以关注先进性，“绿色金融”可以关注可持续性，“普惠金融”可以关注稳定性，“养老金融”可以关注文明性， “数字金融”可以关注时代性，本文中则提到，“科技金融”、“普惠金融”可以支持对银行资产结构的大幅度转化，“绿色金融”、“养老金融”则助力长期的持续发展，但是这四篇文章想做好，都离不开“数字金融”这个基础，因为它是属于这个时代的银行的基本特质。</p><p>&nbsp;</p><p>“数字金融”方面首先需要做好的依然是人员数字素养的提升，这包括专业开发人才梯队建设、充当融合桥梁的业务架构人才队伍建设、业务侧人员结构化思维和数据资产基础能力提升以及对技术趋势发展的了解、中高管理层架构思维能力提升，通过合理设计、定制具有本行特征、结合本行战略、融入本行实践（不是总盯着别人）的数字化能力训战融合体系，完成对数字素养的基础性提升；</p><p></p><p>加强对人才结构的调整，持续引进技术人员，既包括IT人员，也包括具有目标行业（比如科技金融中的细分赛道）学习背景或工作背景的业务侧人员；</p><p></p><p>加强对业务侧可深度利用的低零代码等低强度开发工具的引入和使用，让业务人员有机会亲身体验数字化能力，据笔者观察，低零代码应当成为银行开发体系的有益组成部分，以提供对具有结构化思维的人才、对值得投入开发的应用设想的筛选能力；</p><p></p><p>积极研究业务知识转化成系统知识、系统能力的工作，提升系统对业务效能而不只是办理过程的支持；积极研究中小金融机构联合共享数字化能力的方式；</p><p></p><p>积极研究整体转型、布局设计能力，这是数字时代银行不可或缺的业务发展能力，是实现以“自身工作的确定性应对形势变化的不确定性”的基础。</p><p></p><p>通过自身的数字化建设，逐步实现银行自身增长动能从经验、关系、规模向数据要素、数字生态、金融效能的转换，先完成自身增长动能的转换。</p><p>&nbsp;</p><p>在自身数字化的基础上，做好对数字经济的支持，实现更大范围定义的“数字金融”。须牢记，能做好自己的数字化，才能更好地支持别人的数字化，这也是需要业务侧更多参与数字化的原因，只有在自己身上理解了数字化的价值，知道业技融合创新的逻辑，才能更好地发现、评价别人的数字化价值，如果自己业务中的痛点都不知道、不鼓励、不坚持用数字化方式方法去解决，总是试图以各种理由绕开该深化的数字改革，只能说明自身对时代的理解尚有待加强。</p><p></p><p>这是一个快速变化的时代，对于银行而言，需要的不是别人告诉自己什么有价值，而是自己能培养起什么样的框架去观察、发现价值，如果在自身的转型实践中，都没能培养起合理的数字化价值观、没有长期理性思维指导的业技融合观念，那也很难认识到整个社会的数字化价值，难以树立正确的数字中国、数字经济、数字金融理念，更难谈及从先进性、可持续性、稳定性、文明性、时代性的角度去做好“五篇大文章”。银行对“数字金融”的理解和定位反映的是银行自省、演进的能力，“数字金融”的定位也很容易与其他四篇文章出现交叉，这也是对银行布局能力的考验。</p><p>&nbsp;</p><p>面对“数字金融”，银行系的科技公司该如何定位也需要借机思考一下了，银行系金融科技公司已经成立了一批，该如何定位自身的发展，面向内部、面向同业还是面向客户，需要结合本行的“数字金融”这篇文章要怎么做去定位一下。</p><p></p><h4>（五）调整价值导向，带头退“卷”</h4><p></p><p>&nbsp;</p><p>“五篇大文章”将体现银行价值创造能力的调整，笔者在之前<a href=\"https://www.infoq.cn/article/BpAYeYkzIHtJaPlHC5TR\">利用价值链视角分析中央金融工作会议落实策略</a>\"时，曾提到，导向的改变离不开考核方式的调整，考核是有效的指挥棒，如果考核依然是盯着旧指标、旧方向，那手段当然也只能是旧手段，换汤不换药，就像对规模的非理性追求始终未曾真正停止一样，每年的“开门红”依旧“动力十足”，当然，“开门红”的存在有其合理因素，尤其是信贷类资产，年初放款一年的收益能够最大化，放款越晚，当年收益越少，额度还有可能被调剂。</p><p></p><p>但从新的发展要求来看，考核是要建立长期考核意识的，2024年货币增量是要适度的，但精准投放要求提高了，所以，2024年是结构转换年，结构转换在存量调整方面的工作要求更高而不是新市场份额的扩展上，但这个行为变化需要考核指挥，因此，在KPI下达上，要深入研究，想好新的KPI体系调整前，建议暂停原有的“开门红”经营方式，省一省营销费用，先过个不那么“卷”的新年，将时间、精力先花到思考上。如果依然有开展的，也可以先不将其结果纳入年度考核。</p><p>&nbsp;</p><p>2024年的新“开门红”可以用如下方式开展：</p><p>&nbsp;</p><p>1、学习的“开门红”。认真组织对三次会议文件精神的深入解读、落实建议征集，为经营模式调整做好思想动员。</p><p>&nbsp;</p><p>2、研究的“开门红”。针对“五篇大文章”，总分支行开展对自己现状的认真梳理，整理自己的当前业务特征，注意，这个整理不是要求每个分支机构都完全转变成可以做“五篇大文章”的分支机构，而是确认好当前的业务模式，当前所在区域的环境，以便于从总体上确定棋盘的“布局”，有些分支机构仍然是基本盘，有些则要加速向“五篇大文章”的方向尤其是其中的某个细分方向转型，从而在全行层面构成合理布局，不是简单将“五篇大文章”作为指标任务下达，而是有针对性地调整，并且坚持长期动态调整。</p><p>&nbsp;</p><p>3、推演的“开门红”。基于对业务特征的研究，科学计算结构转换的成本，稳妥制定调整方案，将“五篇大文章”的蓝图一步步实现，而不是一次性实现，“先立后破”的原则要求同样适用于银行经营模式的转换。“抓住一切有利时机，利用一切有利条件，看准了就抓紧干，能多干就多干一些”，这是对中央经济工作会议精神落实的要求，银行的“开门红”也可以把握在这个原则在资产结构转换方面进行一些尝试，以利于对更大范围的调整进行测算。</p><p>&nbsp;</p><p>4、创新的“开门红”。这个创新的核心指的是考核激励体系，这一点也需要监管层面与银行经营管理层面同步开展，对银行管理层的考核和银行内部考核体系在导向上结合，保持政策取向一致性。这将是一次很有挑战性的调整，要体现地区的差异性、进度的差异性、反馈时效的差异性，是一盘高难度的“统筹棋”。</p><p>&nbsp;</p><p>2024年是银行调整的一年，需要思考如何在数字中国、数字经济中走出“中国特色金融发展之路”，把对规模和增速的关注真正转向高质量发展，银行的经营思路确实要改变了，因为银行眼中的不应只是行业，更是国家，不应只是客户，更是人民，要关注政治性、人民性。</p><p></p><h4>作者介绍</h4><p></p><p>付晓岩，《企业级业务架构设计：方法论与实践》、《银行数字化转型》和《聚合架构：面向数字生态的构件化企业架构》三书作者。北京天润聚粮咨询服务有限公司执行董事总经理，数孪模型科技公司高级副总裁；工业和信息化重点领域数字化转型与人工智能产业人才基地专家委员会副主任；中国计算机学会软件工程专委会委员；信通院企业架构推进中心、组装式推进中心技术专家；中华全国数字化人才培育联盟专家委员会特聘专家；工信部中小企业发展促进中心产教融合产业实践教授；国家工程实验室金融大数据应用与安全研究中心研究员；CIC 金融科技与数字经济发展专家委员会成员；国家互联网数据中心产业技术创新战略联盟专家委员会副主任专家委员；CCF数字金融峰会首批执行委员。</p><p></p><h4>内容推荐</h4><p></p><p>11 月 19 日-20 日在上海成功举办的首届 FCon 全球金融科技大会，以「科技 + 金融，激发创新力量」为主题，汇聚了来自金融龙头企业的数百名技术高管，掀起一场探讨新时代金融科技未来的高潮。经征得大会分享嘉宾同意，InfoQ 数字化经纬为您奉上精彩演讲 PPT！关注「InfoQ 数字化经纬」，回复「金融创新」即可获取 PPT，深度洞悉科技趋势，助您引领金融创新未来！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0e/0e09b84945701548f14ab91a2c49ef51.png\" /></p><p></p>",
    "publish_time": "2023-12-18 13:02:54",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "发没发布吵了一周，你在对GPT-4.5期待些什么？",
    "url": "https://www.infoq.cn/article/JMtV9BGq3zeJ8F9IiDJZ",
    "summary": "<p>“我上周一直都在告诉你们 GPT-4.5Turbo 即将发布，有人说我说瞎话，有人说我疯了。他们说是假新闻，但它就在这里，GPT-4.5 Turbo 不仅上线了，而且还处于保密状态。”网友Wes Roth 在自己的视频里说道。Wes Roth 透露，OpenAI的 GPT-4.5 Turbo 已经开始灰度测试，并展示了测试结果：</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/ea/ea4db705e8cc15070543f0c936453747.png\" /></p><p></p><p>&nbsp;其他网友测试后也给出了相同的结果：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b4/b45a5624d9a8d3be74422ac4fd5c2b2a.png\" /></p><p></p><p>还有网友称，自己在 iPad 版本上测试成功，但在桌面版本上不行。“不过，当要求详细信息时，它就会变得非常通用。”还有网友在移动端测试也成功了。</p><p>&nbsp;</p><p>推特著名爆料博主Jimmy Apples也表示，当反复询问其版本时，他注意到模型的不同反应。“令我印象深刻的是该模型在移动设备上承认是GPT-4.5 Turbo，而桌面查询却产生了不同的结果。”</p><p>&nbsp;</p><p>目前，很多都是对于GPT-4 Turbo灰测的结果大多来源于用户对ChatGPT 提问后得到的回答。网友“Bahou”对此表示，“我相信这是一种幻觉。”Bahou给出的具体理由如下：</p><p>&nbsp;</p><p>我们无法证明GPT-4总是正确或错误地回答这个问题。如果你不断地重试这个问题，你会得到不同的结果，其中之一可能是正确的。</p><p>2. 系统提示仍然显示GPT-4。</p><p>3. GPT 向人学习，在过去的几天里，可能有很多问题使模型倾向于谈论 GPT-4.5。</p><p>&nbsp;</p><p>还有网友猜测，“这似乎来自它的训练数据。也有可能他们已经开始训练 GPT-4.5，但尚未完成，因此并未公布。”</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/99/9912794910d93ff2dbb323fcfb1afcee.png\" /></p><p></p><p>值得注意的是，Reddit上一篇发布不久的“<a href=\"https://www.reddit.com/r/OpenAI/comments/18kcmi3/gpt45turbo_is_live_here_is_how_it_performs/\">GPT-4.5 Turbo已经正式发布</a>\"”的帖子被删掉。其中就有用户表示，自己并没有看到这个版本：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d2/d240e65777191aa52bbed87f7d0e5f38.png\" /></p><p></p><p>根据一些说法，GPT-4.5 Turbo 将在推理和“不那么懒惰”方面取得一些进步。但有网友表示，如果当前所谓灰度测试的就是GPT-4.5 Turbo，“那么改进似乎并不太显著，否则我们会看到一些巨大的飞跃。”</p><p>&nbsp;</p><p>“太棒了，你应该让Altman知道这件事！”有网友调侃道。实际上，在12月14日时候就有用户问道关于GPT-4.5 是否泄漏的问题，但Altman给出了模棱两可的回答。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f4/f49871efecdcee6d07006086a0c6ac95.png\" /></p><p></p><p>&nbsp;</p><p>一名疑似OpenAI员工的网友否认这个消息：“兄弟们，你们需要对疯狂的人工智能炒作有更多的抵抗力。没有 4.5，如果有，也不会静默发布。 ”</p><p><img src=\"https://static001.geekbang.org/infoq/5e/5e2d4b28051057f04b3770ed5c4dce55.png\" /></p><p></p><h2>GPT-4.5到底啥样？</h2><p></p><p>&nbsp;</p><p>最早表示GPT 4.5泄露的是reddit上的一个帖子（现已经被删除）：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9e/9e773d7665814b984f4842cd5ff348df.png\" /></p><p></p><p>GPT 4.5将被描述为OpenAI最先进的“一款”模型，具备全新多模态能力，文本语音图片以及视频和3D信息全都能一并处理，并且还可以跨模态理解。从泄漏的截图可以看出，OpenAI可能推出三种型号：</p><p>&nbsp;</p><p>• GPT-4.5，每1千输入token 0.06美元，每1千输出token 0.18美元；</p><p>• GPT-4.5-64k，每1千输入token 0.12美元，每1千输出token 0.36美元；</p><p>• GPT-4.5-音频&amp;语音，每分钟输入0.012美元，每分钟输出0.024美元；</p><p>&nbsp;</p><p>如果泄露的信息为真，那么相比之前的 GPT-4 Turbo模型，GPT-4.5 的价格提高了整整6倍，GPT-4.5-64k的价格提高了12倍。</p><p>&nbsp;</p><p>该消息爆出时，Jimmy Apples表示：“OpenAI 或将在 12 月底前发布 GPT-4.5。”科技圈知名爆料人futuristflower也认为屏幕截图泄露的信息基本正确，只是无法验证截图是否是官方的。这两位的说法让大家普遍认为GPT-4.5就会在这个月发布。</p><p>&nbsp;</p><p>也不怪大家这么期待 GPT-4.5，一方面，OpenAI 的发布会总会给人“惊喜”，另一方面，人们发现最近的GPT-4 变得有些“懒惰”，老是拒绝执行某些任务或直接返回简化的结果。</p><p>&nbsp;</p><p>目前，OpenAl还没有公开详细介绍 GPT-4.5 的技术细节和改进，但ChatGPT有回答“它的设计目的是在会话式AI应用程序中提供高效和有效的响应。”</p><p>&nbsp;</p><p>根据外媒的预测，GPT-4.5 可能基于令人难以置信的 1.8 万亿个参数，而 GPT 3.5 仅有 1750 亿个参数。GPT-4.5 几乎肯定会考虑更多参数，并接受更多最新数据的训练。</p><p>&nbsp;</p><p>GPT-4 仅限于 2021 年秋季之前的数据，未来GPT-4.5 模型可能至少会基于 2022 年的信息，也可能会持续到 2023 年。它还可能可以立即访问网络搜索和插件，GPT-4已引入该功能几个月了。</p><p>&nbsp;</p><p>GPT-4 的推出还增加了 ChatGPT 识别图像的能力，并对提示做出更自然、更细微的响应。GPT-4.5 可以再添加新功能，也许能够分析视频，或本地执行一些插件功能，例如阅读 PDF 文档，或者甚至帮助教学。</p><p>&nbsp;</p><p>GPT-4.5 也有可能能够记住更多信息，利用过去的对话来构建对未来的响应。GPT-4.5 也可能比GPT-4更加高效，运行资源需求更少，这有可能使其能够在更小的设备上运行并更快地响应。</p><p></p><h2>GPT-5 都在路上了</h2><p></p><p>&nbsp;</p><p>在大家纷纷期待GPT-4.5 时，OpenAI已经开始了GPT-5的研发。</p><p>&nbsp;</p><p>Sam Altman 在一次最新的采访中对外透露出，下一代人工智能模型 GPT-5 正在开发中。Altman还表示，计划从微软获得更多资金支持，用以创造相当于人脑的超级AI——通用人工智能（AGI）。</p><p>&nbsp;</p><p>不过， Altman 并没有透露具体的时间和进度，只是说GPT-5会比GPT-4更加复杂，连他也无法准确预测GPT-5会具有哪些新功能和新技能。</p><p>&nbsp;</p><p>Altman表示，GPT-5的终极目标就是是相当于人脑的超级AI，目前OpenAI在构建AGI方面还是取得了一定进展，而大语言模型（LLM）是构建AGI的核心部分：“语言是压缩信息很好的一个方法，我们已经用GPT-3证明了这一点，而谷歌DeepMind却错失了这一机会，虽然这些公司也有很多聪明人，但他们并没有这么做。”</p><p>&nbsp;</p><p>但要做好GPT-5并不容易。Altman在公开场合表示需要更多的数据。除了来自公共在线的数据资源，OpenAI 还寻求利用未公开提供的、更高质量的数据资源。</p><p>&nbsp;</p><p>OpenAI 还需要大量的GPU。据报道，GPT-5的训练需要5万张英伟达H100的加持。Altaman此前也表示OpenAI 很缺GPU，以至于并不希望太多人用ChatGPT。此前，OpenAI就受到GPU的限制，推迟了微调、专用容量、32k上下文窗口、多模态等短期计划。Altman 表示，最近收到了一批英伟达最新的 H100 芯片，他预计 2024 年供应将进一步放松。</p><p>&nbsp;</p><p>Altman 没有承诺 GPT-5 的发布时间，但即使很快开始训练，该模型也不会在短期内面世。根据其大小和设计，训练可能需要数周或数月的时间。然后原始算法必须经过很多人的压力测试和微调以确保其安全。该公司花了八个月的时间打磨并在测试后发布了 GPT-4。尽管现在竞争格局更加激烈，但GPT-4 的到来比 GPT-3 晚了近三年。</p><p>&nbsp;</p><p>不过值得注意的是，比尔·盖茨评论称，“GPT-5不会比GPT-4好多少。”他认为，当前生成式人工智能已经达到极限。</p><p>&nbsp;</p><p>&nbsp;</p><p>相关链接：</p><p><a href=\"https://twitter.com/BahouPrompts\">https://twitter.com/BahouPrompts</a>\"</p><p><a href=\"https://www.digitaltrends.com/computing/gpt-45-language-model/\">https://www.digitaltrends.com/computing/gpt-45-language-model/</a>\"</p><p><a href=\"https://singularityhub.com/2023/11/15/openai-ceo-sam-altman-says-his-company-is-now-building-gpt-5/\">https://singularityhub.com/2023/11/15/openai-ceo-sam-altman-says-his-company-is-now-building-gpt-5/</a>\"</p>",
    "publish_time": "2023-12-18 14:47:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "智能进阶：机器学习颠覆广告创意新思路",
    "url": "https://www.infoq.cn/article/NNSKhRR03fGTWBbNw7wo",
    "summary": "<p>在当今信息过载的时代，广告主面临着双重挑战：一方面，广告需要成为品牌和消费者之间建立联系的媒介；另一方面，碎片化信息使得受众的注意力变得愈发短暂。毫无疑问，优秀的广告创意是能在竞争激烈的市场中脱颖而出的制胜法宝，拥有独具创意的广告不仅是品牌产品或服务的展示，更是捕捉目标受众的心灵，激发他们采取行动，并最终实现转化的工具。</p><p></p><p>而作为广告投放商，重点关注的指标之一就是点击率（CTR），即用户在看到广告后点击的百分比。高点击率不仅代表着网站流量的增加，更意味着广告成功引起了受众的共鸣。然而，实现高点击率需要对受众行为深入剖析，对广告创意的每个细节保持敏感洞察，并具备在市场迅速变化时快速调整和迭代的能力。</p><p></p><h2>机器学习驱动下，广告创意之演变</h2><p></p><p></p><p>在过去，广告创意往往依赖于创作者的经验和直觉，这种创作方式在传统广告领域中确实发挥了重要作用，带来了一些令人难忘的经典广告作品。然而，随着科技的不断进步，这种依赖于个体感知的创意方式也面临着一系列挑战。</p><p></p><h3>01、传统广告创意面临的挑战</h3><p></p><p></p><p>传统手动广告创意过程通常受限于创作者的主观决策，使得广告往往只反映了个体的经验和喜好，难以全面迎合广大受众。此外，手动创意设计需要耗费大量时间进行市场研究和判断，导致反应速度相对较慢，效率不高。处理大规模、高维度的数据超出了人的认知能力范围，容易忽略一些潜在的优化机会。在快节奏的广告市场中，手动优化可能无法实时响应变化，从而导致错失市场机会。</p><p></p><p>更进一步，缺乏系统化和一致性的方法使得每次优化决策都受到不同因素的影响，难以建立起持续、可复制的优化流程。这使得广告创意的改进过程变得零散而不可控。同时，固定的创意模式使得创新变得困难，广告内容缺乏新意，无法跟上市场和受众的变化，进一步限制了广告的影响力和吸引力。</p><p></p><p>正因如此，在科技高速发展的时代，广告行业也急需技术助力，而机器学习则是这一领域的焦点。作为人工智能的子集，机器学习通过提供基于数据的深刻洞察，优化广告创意以更好地满足观众的期望和需求，在广告技术领域迅速获得认可和应用，为广告行业带来了深远的变革。</p><p></p><h3>02、机器学习助力广告创新</h3><p></p><p></p><p>机器学习能够以数据驱动的方式进行广告创意。在新时代的广告创意过程中，不再仅仅依赖主观判断，而是通过分析海量用户数据，精准地定位目标受众的兴趣和偏好。个性化定制的广告不仅为消费者带来千人千面的体验，而且对受众产生更为深远的影响力。</p><p></p><p>在创意生成方面，机器学习通过自然语言处理、机器视觉等技术，能够从多个维度提取关键特征，实现创意的多样性和创新性。不再受固定的创意模式的约束，机器学习使得广告创意变得更加灵活和富有创意。</p><p></p><p>而实时优化是机器学习在广告创意中的又一利器。通过不断地分析实时数据，能够迅速调整广告内容和形式，以保持与市场变化的同步。这种动态优化不仅提高了广告效果，还大大提升了广告投放的效率。</p><p></p><h2>广告投放新范式，机器学习引领创意生成优化</h2><p></p><p></p><p>作为开发者全球增长平台，汇量科技深度整合机器学习技术，将其贯穿广告投放的各个关键阶段。通过持续的技术升级和算法能力的优化，推出了以机器学习为技术基础的一站式增长解决方案。这不仅实现了精准广告投放，同时关注投放效果、变现收益及应用体验。针对性帮助广告主更好的实现广告投放目标的 ROI 最大化，完成更智能、高效、精确的广告投放策略，以突破增长平台期。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ef/efbf38f6a9b6bbe4873f8280693ebd3a.jpeg\" /></p><p></p><p>汇量科技机器学习系列内容将深入介绍汇量科技的机器学习技术如何在广告投放的每个关键阶段提供支持及赋能。作为系列内容的开篇，本文将聚焦广告投放第一步——【创意生成优化】环节，深入探索机器学习机器学习在此环节的应用，以及它如何通过高效的数据处理和预测算法，彻底改变了营销人员对创意优化的传统方式。</p><p></p><p>机器学习在广告创意优化方面也发挥关键作用，通过海量创意分析、自动创意生成和动态创意优化，不仅在提高广告效果方面取得显著成果，同时为受众创造了更富趣味和价值的广告体验。</p><p></p><p>海量创意分析：</p><p></p><p>借助自然语言处理（NLP）、机器视觉（CV）等数据挖掘技术，从市场中汲取灵感，为广告创意提供方向。这项技术的应用也帮助广告主不断创新，吸引用户注意力。</p><p></p><p>语义图像识别：&nbsp;</p><p>通过NLP分析文本描述，结合CV识别图像元素，广告创作者可以更精准地理解图像中的物体、场景，以及与广告相关的元素。这有助于生成更富有创意和与广告目标相关的图像内容。</p><p></p><p>基于情感分析的创意生成：</p><p>NLP可以对自然语言进行文本&amp;情感分析，CV也可以通过数据挖掘进行情感识别，广告创作者可以更好地理解用户在文字和图像中表达的情感。通过了解用户的情感状态，广告内容可以调整以更好地契合用户的情感体验，提高广告的情感共鸣力。</p><p></p><p>视觉元素个性化推荐：</p><p>利用NLP对用户文本数据的分析，结合CV对图像元素的识别，广告系统可以个性化推荐与用户兴趣相关的视觉元素。这使得广告创意可以更好地迎合用户的口味，提高广告内容的吸引力。</p><p></p><p>品牌一致性管理：</p><p>结合CV技术识别品牌标识和NLP技术理解品牌声音，广告系统可以确保广告中的文本和图像与品牌形象一致。这有助于构建和维护品牌形象的一致性，提高品牌在用户心中的认知度和信任感。</p><p></p><p>自动创意生成&amp;动态创意优化：</p><p></p><p>利用大语言模型（LLM）、机器视觉（CV）、生成式AI（AIGC）等技术，从现有创意素材中提取关键特征，并生成创新性的广告图像、文案和视频；通过动态调整创意风格，实现千人千面的创意投放，提高广告的针对性和吸引力。这意味着广告主可以更高效地创建吸引人的广告内容，提高创意生成的效率和质量的同时提高用户互动率。</p><p></p><p>广告文案生成：</p><p>如GPT-3，可以通过学习大量文本数据，生成更自然、有趣、并富有创意的广告文案。广告创作者可以利用LLM生成的文案作为创意的起点，从而更快速地产生大量个性化、引人入胜的广告语言。</p><p></p><p>个性化推荐：&nbsp;</p><p>LLM可以通过分析用户行为和历史数据，生成个性化的广告推荐文案。这种个性化的推荐能够更好地满足用户的兴趣和需求，提高广告的点击率和转化率。</p><p></p><p>情感分析：</p><p>CV还可以用于分析图像中的情感元素，例如人脸表情。通过了解广告中传达的情感，广告创作者可以调整内容以更好地引起目标受众的共鸣，提高广告的情感互动性。</p><p></p><p>例如不久前可口可乐进军生成式人工智能所推出的广告《Masterpiece》， 该广告与 OpenAI 合作，采用 AI（Stable Diffusion + 3D 建模 + 实拍）设计。通过将人工智能增强动画与真人表演巧妙结合，成功地“复活”了多件世界名画作品。这不仅在视觉上深刻传达了品牌形象，更宣告了生成式人工智能已深入广告行业，为广告领域带来了重大变革，而这一创新案例也生动地印证了机器学习与广告创意相辅相成，为行业拓展了更多可能性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fb/fb907dadfec4eb03906d4ad4502cb57a.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/93/937e14ee8a91c73eac94d7c7763940b3.png\" /></p><p></p><h2>技术驱动创意，广告投放效率质量双提升</h2><p></p><p></p><p>在持续的研发投入下，汇量的机器学习平台体系逐渐完善、日益强大。这一技术实力在旗下程序化广告平台 Mintegral 上得以充分体验，让广告在正确的时间、合适的场景下能够实现精准触达目标用户，同时兼顾了投放效果、变现收益以及应用体验。作为全球领先的程序化移动广告平台，Mintegral 也是首批将 DCO 动态创意优化技术与互动创意相结合的广告平台之一。</p><p></p><p>动态创意优化技术通过智能组合与动态优选广告素材，实时将广告呈现成用户喜欢的模样。我们的算法在广告请求筛选中增加创意组合的维度，提高广告投放效率，实时优化投放策略，帮助广告主更迅速、更有效地提升获客效益与质量。</p><p></p><p>以汇量科技旗下一站式创意制作平台举例，该平台集素材编辑器、录屏、创意模板等功能于一体，无须任何代码基础，即可「从 0 到 N」实现流畅、简单、自动化的素材制作与优化：</p><p></p><p>200+ 在线可玩素材模板，可通过 PPT 式的「拖拉拽」，快速组建个性化试玩素材，并一键适配各大投放渠道，轻松实现降本增效，高效输出优质试玩素材。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/04/04ce6f2c915e034e7128e72cf9c085d1.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d5/d560e22654a3553ca1ac05a9c62a89dd.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bd/bd7eef8e46f2d2ddbaaee6ff517fd8b0.png\" /></p><p></p><p>通过学习大量文本数据，根据不同的游戏素材，智能生成更为自然、富有趣味和创意的视频（口播）文案。从而快速生成大量个性化广告语言，实现高效而富有创造力的应用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/46/46ee4a3f1036c80329dfaa8050aedc8f.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/35/357f1937c97ca7390366871e8a3b914e.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9b/9b3f637b30e7420f8f9d028608ef038e.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3c/3ceffbea603c06362b602b1db7a113a0.png\" /></p><p></p><p>集成多种便捷AI组件，包括视频分镜智能切割、语音转文字、元素消除/替换、AI配音 、智能翻译等，开发者可以在同一平台中就能完成所有操作，批量输出多条视频创意，进而快速投入A/B 测试，适配多样化投放渠道，高效定位爆款素材、优化投放效果。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/49/497a2cb36d5e21f939e89948a5234b43.png\" /></p><p></p><p>通过机器学习技术的助力，广告创意素材的制作开发有了显著提速，原本需要多方协同耗时1~2周才能完成的广告素材组合，现在仅需1~2天即可实现。技术和创意的融合，也使得汇量科技可以为广告主提供更全面、高效的解决方案。</p><p></p><p>面对未来经济发展的不确定性，广告主将更加注重效果营销，以实现最佳的投入产出比。在这个过程中，机器学习的运用变得尤为关键。通过精确的数据分析和预测算法，广告主可以更智能地选择广告创意素材，提升广告活动的表现效果，进而增加用户粘性。对于移动游戏营销业者而言，他们所面临的挑战在于找到适合目标受众的平衡点。在这一挑战中，正确选择适合的机器学习驱动的广告创意合作伙伴，将事半功倍，为广告活动的成功投放注入更多智能化策略。</p><p></p><p>从大语言模型到实现千人千面，机器学习为广告领域带来了前所未有的创新。随着技术的不断演进，我们能够期待看到更多广告创意领域的应用，为品牌传播开辟更广阔的可能性，助力广告主在不确定的环境中取得更为显著的市场竞争优势。</p>",
    "publish_time": "2023-12-18 15:01:05",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "用ChatGPT自研大模型被封号，字节最新回应：最初有用GPT API，但没发布、已停止",
    "url": "https://www.infoq.cn/article/kHeRZ5t2x5mX0XWiAz1P",
    "summary": "<p>根据 <a href=\"https://www.theverge.com/2023/12/15/24003151/bytedance-china-openai-microsoft-competitor-llm\">The Verge</a>\" 报道，字节跳动内部文件证实“其基础 LLM的开发依赖OpenAI API 进行”。名为为“Project Seed”的项目报告称，几乎涵盖了模型训练、评估等开发的每个阶段。为此，OpenAI 暂停了字节跳动的帐户。</p><p>&nbsp;</p><p>OpenAI 发言人表示，所有 API 客户都必须遵守“我们的使用政策，以确保我们的技术是用来做好事的。”</p><p>&nbsp;</p><p>“虽然字节跳动对我们 API的使用很少，但我们在进一步调查期间已暂停了他们的帐户。如果我们发现他们的使用不遵守这些政策，我们将要求他们进行必要的更改或终止他们的帐户。”据称，字节跳动使用 GPT 违反了微软和 OpenAI 的开发者许可。</p><p>&nbsp;</p><p>根据OpenAI <a href=\"https://openai.com/policies/business-terms\">条款</a>\"，客户不得“开发任何与我们的产品和服务竞争的人工智能模型”。用户也不能“使用 API 允许之外的任何方法从服务中提取数据”或应用程序编程接口，允许开发者使用 GPT 创建自己的应用程序。</p><p>&nbsp;</p><p>The Verge 报道称，字节跳动意识到了这一点，但仍继续使用 API 来训练和比较其模型。 The Verge 还表示，它看到了该公司指示员工使用“数据脱敏”来掩盖证据的内部通讯内容。</p><p>&nbsp;</p><p>大约在字节跳动的聊天机器人豆包（Doubao）被国内监管机构批准使用时，公司指示员工停止使用该API来开发Project Seed项目。但Verge杂志报道称，该API仍被用于评估他们自己的聊天机器人的表现。据悉，豆包是字节在8 月发布的首款 AI 对话产品，多家媒体评测结果显示，豆包的智能化水平在大模型 C 端助理类产品中不算突出。</p><p>&nbsp;</p><p>对此，字节跳动相关负责人回应称，公司在使用OpenAI相关服务时，强调要遵守其使用条款。公司也正与OpenAI联系沟通，以澄清外部报道可能引发的误解。以下是字节跳动使用OpenAI服务相关情况的介绍：</p><p>&nbsp;</p><p>今年年初，当技术团队刚开始进行大模型的初期探索时，有部分工程师将GPT的API服务应用于较小模型的实验性项目研究中。该模型仅为测试，没有计划上线，也从未对外使用。在4月公司引入GPT API 调用规范检查后，这种做法已经停止。早在今年4月，字节大模型团队已经提出了明确的内部要求，不得将GPT模型生成的数据添加到字节大模型的训练数据集，并培训工程师团队在使用GPT时遵守服务条款。9月，公司内部又进行了一轮检查，采取措施进一步保证对GPT的API 调用符合规范要求。例如分批次抽样检测模型训练数据与GPT的相似度，避免数据标注人员私自使用GPT。未来几天里，字节会再次全面检查，以确保严格遵守相关服务的使用条款。</p><p>&nbsp;</p><p>&nbsp;参考链接：</p><p><a href=\"https://www.theverge.com/2023/12/15/24003151/bytedance-china-openai-microsoft-competitor-llm\">https://www.theverge.com/2023/12/15/24003151/bytedance-china-openai-microsoft-competitor-llm</a>\"</p><p>https://www.businessinsider.com/bytedance-openai-tech-artificial-intelligence-tiktok-sam-altman-2023-12</p>",
    "publish_time": "2023-12-18 15:18:56",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "吉利将汽车驾驶信息图像投影至用户眼睛；比亚迪公布新专利；​智己汽车将于2025年实现绝大多数场景自动驾驶 | 汽车技术资讯",
    "url": "https://www.infoq.cn/article/erWBO9JwXKZoe6CHlGYW",
    "summary": "<p></p><h3>吉利新专利可将汽车驾驶信息图像投影至用户眼睛</h3><p></p><p></p><p>近日，浙江极氪智能科技有限公司、浙江<a href=\"https://www.infoq.cn/article/dXYjsLxYiFhOzSyfNwxu?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">吉利</a>\"控股集团有限公司申请的“车辆图像显示控制方法、存储介质、控制系统和车辆”专利公布。该专利可以将图像直接投影到用户眼睛，能使用户在保持驾驶视野的情况下看见驾驶信息图像，提高驾驶安全性和用户体验感。据悉，控制方法包括：响应于操作部件被用户操作而产生的显示请求指令，向光线发射机发送相应的图像信息；获取用户的眼睛位置信息；控制光线发射机向用户的眼睛位置投影图像信息。</p><p></p><h3>比亚迪公布“一种电芯管理芯片、电池系统、车辆”专利</h3><p></p><p></p><p>据国家知识产权局公告，比亚迪半导体股份有限公司申请一项名为“一种电芯管理芯片、电池系统、车辆“，公开号 CN117183818A，申请日期为 2022 年 5 月，预计适合延长电池使用寿命的有效保护措施。</p><p>专利摘要显示，本发明实施例提供了一种电芯管理芯片、电池系统、车辆，该芯片包括：采集电路用于采集单体电芯的工作参数的参数值并传输至处理电路；电源为处理电路供电，存储电路用于存储针对工作参数的动态保护阈值，处理电路用于在异常情况下调整单体电芯的工作状态，动态保护电路用于按照动态保护阈值调整单体电芯的工作状态。</p><p></p><h3>智己汽车宣布高速高架 NOA 中国大陆全部贯通，2025 年实现绝大多数场景自动驾驶</h3><p></p><p></p><p><a href=\"https://www.infoq.cn/article/KKaEhGYQizY2t1SKJbxi?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">智己汽车</a>\"近日宣布，IM AD 高速 NOA （自动辅助导航驾驶）正式贯通中国大陆，2025 年迈入 Door to Door（全场景通勤）时代，实现绝大多数场景下的自动驾驶。据介绍，IM AD 高速高架 NOA 现已全新登陆 9 省 28 市，包括西藏、新疆、内蒙古、青海、广西、山西、辽宁、吉林、黑龙江等省域高速及 28 个城市的高速高架路段。IM AD 高速 NOA 实现辐射全国 333 城的高速路段（除港澳台地区外），并覆盖 59 城高架路段；高速高架 NOA 适用道路总计 38.9 万公里。</p><p></p><h3>大疆车载“成行平台”升级，全面提升智能驾驶功能</h3><p></p><p></p><p>12 月 15 日，大疆车载“成行平台”通过深度优化算法、软件、模型及进一步累积数据，全面提升了各项智能驾驶功能的能力上限，将应用在所有搭载成行平台的量产车型上。本次升级将于 2023 年 12 月到 2024 年 3 月之间陆续推送。在已量产车型上将通过大版本 OTA 的方式推送，在即将量产的车型上将直接应用“成行平台”最新的技术和能力。</p><p></p><h3>蔚来汽车领航路线验证预计年底前遍布 200 城市</h3><p></p><p></p><p>近日，<a href=\"https://www.infoq.cn/video/Im8lhBm1NlZWOHAwOxGI?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">蔚来</a>\"智能驾驶研发副总裁任少卿今日公布了蔚来智能驾驶的最新进展。在即将全量推送的 Banyan 2.3.0 版本中，蔚来增强领航辅助 NOP + 正式更名为“全域领航辅助 NOP+”（以下简称 NOP+），并为用户提供覆盖高速、城区和换电场景的全域领航体验。</p><p></p><p>据介绍，NOP + 支持车辆在城区道路上依据设定的导航路线，自主完成如路口通行、导航变道、超车变道、绕行车辆等驾驶任务，并具备面对施工区域、异形障碍物等场景的安全避让能力，提供连通地面道路与城市快速路、高速公路的点到点辅助驾驶体验。</p>",
    "publish_time": "2023-12-18 15:33:11",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "百度 Comate 技术公开课来了！百度工程师直播分享高效编程实用技巧",
    "url": "https://www.infoq.cn/article/yE7hIpBqkt1p39ppziZX",
    "summary": "<p>复盘传统的编码流程，从编写代码、搜索代码、查阅文档，到代码调优、单元测试，开发环节流程多、任务繁重，工作逐渐成了“体力活”。如果这个过程中，开发者能够拥有一个代码助手，覆盖开发者编程工作的全场景和全周期，协助完成一些复杂、琐碎的工作，工作效率将大大提高。</p><p></p><p>“大模型”盛行的当下，很多厂商推出了 AI 代码助手，这些“助手”主要是帮助开发者缩短开发周期，避免重复造轮子，让开发者在编码时只需思考代码结构而减少费时费力的代码校对工作。比如像百度在今年 6 月推出的智能代码助手<a href=\"https://xie.infoq.cn/article/14a675fa0f233aa192e141e7b?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">百度 Comate</a>\"，就是一个典型代表，其基于<a href=\"https://www.infoq.cn/article/rMaACTsMeatV9vgt9CdU?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">文心大模型</a>\"打造的新一代智能编程工具。借助文心大模型的理解、推理能力，百度 Comate 可支持代码解释、技术问答、实时续写、生成单元测试、代码优化与修复、智能 CLI 等 10 余项编码功能，助力企业研发全流程降本增效。</p><p></p><p>在应用实效上，基于模型层多种能力，百度 Comate 具有优秀的代码推荐、单测生成、自然语言代码生成和代码修复等能力，并通过开放 SaaS 版和私有化部署能力，满足个人用户、中小企业和大型企业的不同需求。在百度内部，通过 Comate 生成代码占比 20%，整体采纳率达 40%。</p><p></p><p>12 月 21 日，<a href=\"https://www.infoq.cn/video/eCB7TDEfVlQYAXYPDqVa?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">百度智能云</a>\"将带来技术公开课《百度 Comate：提升编码效率，释放“十倍”软件生产力》，由百度资深工程师、百度 Comate 架构师徐晓强深度解读智能代码助手“百度 Comate”全流程提效方法、效果及其典型使用场景，并通过现场实操，帮助大家快速上手 Comate，切实助力研发效率提升。</p><p>通过此次课程，你将：</p><p></p><p>了解大模型产品在代码生成领域的基本原理和前景，以及百度 Comate 在百度内部的落地实践；结合具体 demo，体验百度 Comate 在实际开发中的使用方法和效果；AI 时代，作为开发者，先人一步利用 AI 工具提升开发效率。</p><p></p><p>立即识别下方海报中的二维码预约课程，12 月 21 日（周四）18:00-19:00，不见不散！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7e/7e3788d38a5ca8b9c75a980f871e51d6.png\" /></p><p></p>",
    "publish_time": "2023-12-18 15:38:12",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "腾讯云向开放原子开源基金会捐赠OpenTenBase：已打磨超十年，助力企业实现数字化转型",
    "url": "https://www.infoq.cn/article/fh3bPhV6beTJsLeXFHYE",
    "summary": "<p>12月16日，在2023开放原子开发者大会上，腾讯云宣布将企业级分布式数据库TDSQL的社区发行版OpenTenBase 捐赠给开放原子基金会，通过开源共创的方式，与上下游产业链以及开发者共同打造繁荣数据库技术生态。据了解，这是继编译器软件OpenKona JDK，以及全链路自主演进的操作系统OpenCloudOS之后，腾讯捐赠的又一重磅基础软件项目。</p><p>&nbsp;</p><p>数据库作为计算机三大基础软件之一，向下可充分发挥硬件算力，向上支撑上层的应用需求,是信息系统高效运行的关键基础。目前，OpenTenBase 已在腾讯社交、游戏、广告、金融等内部业务及外部商用场景下打磨10年以上，可完美适用于拥有海量数据、高并发、高HTAP，以及分布式事务能力的应用场景。</p><p>&nbsp;</p><p>腾讯云数据库研发总经理潘安群表示，OpenTenBase数据库在技术上填补了业内基于 PostgreSQL的开源分布式OLTP系统空白，并且集HTAP双引擎、分布式事务一致性、高 SQL 兼容度、复杂查询等技术能力于一身，能够为企业数字化转型提供强有力支撑。</p><p>&nbsp;</p><p>比如，在引擎方面，OpenTenBase同时支持OLTP（在线交易处理）和OLAP（在线分析处理）能力，能够有效降低业务架构复杂度和成本；在事务一致性方面，引入全局事务管理节点来管理分布式事务，通过分布式事务一致性技术来保证在全分布式环境下的事务一致性；在兼容性方面，高度兼容PostgreSQL版本和Oracle版本；在查询方面则全新开发分布式查询优化器，可将复杂查询的性能提升十倍以上。</p><p>&nbsp;</p><p>开放原子开源基金会秘书长冯冠霖表示：“很高兴看到腾讯能够把多年研发打磨、通过海量业务场景考验的基础软件数据库项目OpenTenBase开源并捐赠到基金会，未来，基金会将秉持中立开放的态度，与业界一起将OpenTenBase打造成为具有全球影响力的优秀开源项目。”</p><p>&nbsp;</p><p>近年来，腾讯云数据库TDSQL在多个领域取得重要突破，在性能上，今年3月刷新TPC-C世界记录，每分钟事务处理数达到8.14亿；在最新的IDC报告中，位居中国分布式关系型数据库“领导者”类别，并在市场份额上取得国内第一的成绩。</p><p>&nbsp;</p><p>腾讯云数据库总经理王义成介绍，TDSQL已涵盖金融级分布式、云原生、分析型等多引擎融合的完整数据库产品体系，提供业界领先的金融级高可用、存算分离、数据仓库、企业级安全等能力。未来会持续投入和突破数据库核心技术，打造更加健康可持续发展的数据库生态和开源社区，为企业数字化转型提供长久动力。</p>",
    "publish_time": "2023-12-18 16:42:41",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "提高视频编辑一致性，美图、国科大联合提出基于文生图模型的新方法",
    "url": "https://www.infoq.cn/article/M0MkRgrZwdL7Uxi6t7Ad",
    "summary": "<p>美图影像研究院（MT Lab）与中国科学院大学提出了基于文生图模型的视频生成新方法EI²，用于提高视频编辑过程中的语义和内容两方面的一致性，并发布了相关论文。该论文从理论角度分析和论证视频编辑过中出现的不一致的问题，主要由引入的时序信息学习模块使特征空间出现协变量偏移造成，并针对性地设计了新的网络模块进行解决以生成高质量的编辑结果。目前，该论文已被机器学习顶会之一NeurIPS 2023接收。</p><p>&nbsp;</p><p>论文链接：<a href=\"https://arxiv.org/abs/2208.02646\">https://arxiv.org/abs/2208.02646</a>\"&nbsp;</p><p></p><h2>基于文生图模型的视频生成方案有哪些问题</h2><p></p><p>&nbsp;</p><p>作为当前炙手可热的前沿技术之一，生成式AI被广泛应用于各类视觉合成任务，尤其是在图像生成和编辑领域获得了令人赞叹的生成效果。对比静态图像，视频拥有更丰富的动态变化和语义信息，而现有的视觉生成任务主要基于变分自编码器（VAE）和生成对抗网络（GAN），但通常会受限于特定场景和数据，很难提供普适的解决方案。</p><p>&nbsp;</p><p>因此，近年来基于扩散模型（Diffusion Models）在分布式学习上表现出的卓越能力，扩散模型也开始被拓展到视频领域，并在视频生成与编辑领域展现出了巨大的潜力。</p><p>&nbsp;</p><p>在研究初期，基于扩散模型的视频生成和编辑任务利用文本-视频数据集直接训练文生视频模型以达到目标。然而，由于缺少高质量的视频数据，这类工作泛化能力通常较差。此外，它们也需要耗费大量的计算资源。</p><p>&nbsp;</p><p>为避免上述问题，近期业内更倾向于将基于大规模数据集上预训练的文生图模型拓展到视频领域。此类任务通过引入可学习的时序模块使文生图模型具备视频生成和编辑能力，从而减少了对视频数据的需求以及计算量，并提供了简单易用的方案。因此，这类任务在近期引起了广泛的关注。</p><p>&nbsp;</p><p>然而，以上基于文生图模型的视频生成方案也面临着两个关键问题：一是时序不一致问题，即生成视频帧间内容的不一致，例如闪烁和主体变化等；二是语义不一致问题，即生成视频未能按照给定文本进行修改。解决上述两个核心问题将极大地推动基于文本的视频编辑与生成技术在实际场景中的应用和落地。</p><p>&nbsp;</p><p>美图影像研究院（MT&nbsp;Lab）与中国科学院大学在NeurIPS 2023上共同提出一种基于文生图模型的视频编辑方法EI²,从理论上分析和论证了现有方案出现不一致的原因，并提出了有效的解决方案。</p><p>&nbsp;</p><p></p><h2>基于文生图模型的视频一致性编辑解决方案</h2><p></p><p>&nbsp;</p><p>EI²首先对语义不一致问题进行了分析，发现该问题不是由微调策略或过拟合现象出现所导致的，而是由新引入的时序模块造成的。这些模块虽然能提升文生图模型的时序连续性，但会减弱甚至消除其原有的生成和编辑能力。</p><p>&nbsp;</p><p>EI²方案将这一现象的出现归因于生成特征空间出现协变量偏移：由于时序模块只在目标视频上进行训练，其输出特征的分布与源模型的分布存在差异。此外，现有空间注意力机制为减小计算量，通常会忽略特定元素进行局部计算，从而导致次优解的出现。因此，高效地融合全局上的空间和时序注意力信息也是取得时序一致性编辑的关键。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c5/c5127fd470f5076fb457f775ce0e96fd.png\" /></p><p>&nbsp;</p><p>图1&nbsp;本文提出的EI²方案与已有方案在视频编辑任务上的结果对比</p><p>&nbsp;</p><p>基于上述分析，EI²设计了更为合理的时序模块并将其与文生图模型相结合，用于增强生成能力，以更好地解决视频编辑任务。</p><p>&nbsp;</p><p>具体而言，EI²采用一次微调框架（One-shot&nbsp;Tuning），从理论和实践两方面对现有方法进行了改进。</p><p>&nbsp;</p><p>首先，EI²设计了偏移控制时序注意力模块，用于解决视频编辑过程中出现的语义不一致问题。EI²从理论上证明了在特定假设下，协变量偏移与微调无关，是由时序注意力机制新引入的参数造成，这为解决语义不一致问题提供了有价值的指导。</p><p>&nbsp;</p><p>通过上述论证，EI²定位层归一化（Layer&nbsp;Norm）模块是协变量偏移出现的重要原因。为了解决这一问题，EI²提出了简单有效的实例中心化模块以控制分布偏移。此外，EI²也对原时序注意力模块中的权值进行归一化，从而限制方差的偏移。</p><p>&nbsp;</p><p>其次，EI²设计了粗细力度帧间注意力模块来缓解视频编辑过程中出现的时序不一致问题。EI²提出了一种粗细力度交互机制，用于更为有效地建立时空注意力机制，从而使得低成本的视频全局信息交互成为可能。</p><p>&nbsp;</p><p>与现有丢弃空间信息的方案相比，EI²在空间维度上进行采样，这不仅保持了时空数据的整体结构，也减少了需要考虑的数据规模。</p><p>&nbsp;</p><p>具体而言，粗细力度帧间注意力模块对于当前帧保留细粒度信息，而对于其他帧则进行下采样以获得粗粒度信息来做交互。这种方式使得EI²在有效学习时序信息的同时，保证了与现有时空交互方案接近的计算量。</p><p>&nbsp;</p><p>基于以上设计，实验结果表明EI²可以有效地解决视频编辑过程中出现的语义不一致问题并保证时序上的一致性，取得了超越现有方案的视频编辑效果。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/76/766deba2af121534d6599476b0466f71.png\" /></p><p>&nbsp;图2 EI²的训练和推理流程</p><p></p><h2>实验结果</h2><p></p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/d9/d9563b1b72cbd5650d9e14b76b91c4c1.png\" /></p><p>&nbsp;表1 与基线方法的量化对比</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ac/acf52f1eae3a1ca7a01063111c5a0799.png\" /></p><p>&nbsp;图3 与基线方法的可视化对比</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/02/02f9d4c13f793f4a05da9728242253ff.png\" /></p><p>&nbsp;图4 协变量偏移控制的消融实验</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0a/0aff35d4015b6ce36a022ef130c20abb.png\" /></p><p>&nbsp;图5 时空注意力机制的消融实验</p><p>&nbsp;</p><p></p><h2>总结</h2><p></p><p>&nbsp;</p><p>该论文创新性地提出了基于文生图模型的视频编辑新方案EI²，解决了现有方案遇到的语义和时序不一致问题。其中，EI²从理论上证明了语义不一致问题由引入的时序模块产生的协变量偏移造成，并设计了偏移控制时序注意力进行改进。</p><p>&nbsp;</p><p>另外，EI²提出了粗细力度帧间注意力模块，在提升视频编辑效果的同时也保证了较低的计算复杂度。与现有方案相比，EI²在量化和可视化的分析中都表现出了明显的优势。</p><p>&nbsp;</p><p>研究团队介绍</p><p>&nbsp;</p><p>本论文由美图影像研究院（MT Lab）和中国科学院大学的研究者们共同提出。美图影像研究院成立于2010年，致力于计算机视觉、深度学习、计算机图形学等人工智能（AI）相关领域的研发。曾先后参与CVPR、ICCV、ECCV等计算机视觉国际顶级会议，并斩获ISIC Challenge 2018皮肤癌病灶分割赛道冠军，ECCV 2018图像增强技术比赛冠军，CVPR-NTIRE2019图像增强比赛冠军，ICCV2019服饰关键点估计比赛冠军等十余项冠亚军，在AAAI、CVPR、ICCV、ECCV、NIPS等国际顶级会议及期刊上累计发表48篇学术论文。</p><p>&nbsp;</p><p>在美图影像研究院（MT Lab）的支持下，美图公司拥有丰富的AIGC场景落地经验。2010年开始人工智能领域的相关探索，2013年开始布局深度学习，2016年推出AIGC雏形产品“手绘自拍”，2022年AIGC产品全面进入爆发期，2023年6月发布自研AI视觉大模型MiracleVision(奇想智能)，2023年12月MiracleVision迭代至4.0 版本，主打AI设计与AI视频。</p>",
    "publish_time": "2023-12-18 17:08:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "寻找增长，SaaS 企业选择上飞书",
    "url": "https://www.infoq.cn/article/dgHcorv9G9E1I3j1Qurg",
    "summary": "<p>作者 | 付秋伟</p><p></p><p>编者按：</p><p>前期看市场，中期看效益，后期看理念。这是我在与飞书团队访谈后最大的感受，这句话不仅仅适用于 SaaS 类企业，更适用于人口红利见顶的大时代下所有的创业者。</p><p></p><p>SaaS 行业的下一个春天在哪里？在呐喊与彷徨中前行的从业者们突然发现：越来越多的头部 SaaS 企业开始向飞书靠拢，目的很简单：上飞书找业务新增长、用飞书做降本增效。</p><p></p><p></p><h3>春天冬天，不如明天</h3><p></p><p></p><p>冬去春来冬又至，潮起潮落潮水平，中国的 SaaS 行业走过了波澜壮阔的十年。回归价值、回归产品、回归服务是当下 SaaS 行业的真实写照，玩家们正在等待春天的到来。但“春天”什么时候会来？That is a question!</p><p></p><p>事实上，最近几年在数字化浪潮的推动下，中国 SaaS 行业也确实迎来了一轮新的机遇，但也加剧了细分赛道的产品竞争。如何获取更多的企业用户、如何从粗放式增长走向精益化管理，成为了 SaaS 企业共同面临的挑战。</p><p></p><p>“如今人口红利进入瓶颈期后，下一步增长来源无非两个方面：一个是向外等待科技革命，另一个向内要效益，也就是所谓的降本增效。虽然 AI 让人们看到了苗头，但距离真正的产业革命，仍有距离。”飞书企业服务行业解决方案总监程浩表示。</p><p></p><p></p><h3>上飞书，找增量</h3><p></p><p></p><p>飞书最初是以“协同”著名。</p><p></p><p>“其实一开始，字节并没有考虑自己做工具，当时我们几乎把全世界的协同工具都用了个遍，能打通的 API 也都打通了，但是发现还是无法满足需求。”程浩表示。</p><p></p><p>今年上半年，外界发现，飞书将产品定位从协同办公工具升级成了业务管理工具。他们发布了业务三件套——多维表格、应用引擎、集成平台。</p><p></p><p>飞书多维表格，是一款以无代码形式搭建的表格型数据库，用以和办公场景进行更好的连接；飞书应用引擎，针对客户的 20% 核心业务而设计，为开发者提供了广泛的通用模块以及可视化编辑模块，帮助研发提效；飞书集成平台则是一个主要为企业解决内部“数据孤岛”问题而生的集成工具，目前已有 100 多个系统连接器。</p><p></p><p>随着这一套 ToB 组合拳的发布，飞书找到了一条新路子：飞书开始拥抱 ToB 市场，从极致的用户体验走向体验 + 业务融合的道路。</p><p></p><p>近几年，越来越多的企业开始拥抱飞书，尤其是在 SaaS 赛道，不少细分领域几乎实现了“全垒打”。例如，费控赛道：汇联易、分贝通、合思这三家头部费控都在用飞书。</p><p></p><p>为什么 SaaS 企业要拥抱飞书？程浩反复提到一个词——“有未来”。“我认为现在的飞书就像一个蓄势待发的火箭，马上要发射了，‘你’要不要跳上去？”</p><p></p><p>他表示，一方面，随着飞书的产品越来越成熟，就会吸引越来越多的企业用户用飞书，飞书在目标用户中的口碑效应“变现”。相比于其他友商，对于 SaaS 企业而言，飞书是一个更有增长潜力、更有诱惑的平台。</p><p></p><p>在“有增量 + 可商业闭环”这两个因素的影响之下，大量 SaaS 企业主动拥抱飞书，将产品和服务集成到飞书生态中去，似乎也就成了趋之若鹜的选择。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7f/7f1d6c0d7320f5df21fc0b9848acd4c1.png\" /></p><p></p><p>事实上，对于国内 SaaS 行业而言，大厂搭建生态，小厂精耕细作。“搭建生态，是需要大量的人力物力投入进去的，其实很难让一家创业公司去做这件事，但是大的平台搭建起来之后，大家可以一起进来共建，发挥各自的长板，去为用户提供更好的服务。”程浩表示。</p><p></p><p>此外，对于用户端的企业而言，随着数字化进程加深，必然会导致越来越多的 SaaS 产品接入业务，不同的系统、不同的账号，如何管理、如何拉通又会是一个不小的挑战。这样的背景之下，类似飞书这样的“协同办公集成平台”+“三方 SaaS”的组合模式似乎成为帮助企业以最低的门槛、最快的速度打通内部数据链条，释放数据价值的最优解。</p><p></p><p>当然，“被集成”同样会有隐忧，即集成方的产品边界问题。互联网行业大鱼吃小鱼的故事每天都在上演，如何放心加入生态，也是每一个 SaaS 企业所关注的问题。</p><p></p><p>“第一，对于大厂而言，要做好一个产品首先得看看它有没有这个基因；第二，就是决心有多大，因为对于大厂而言这个项目可能只是枝繁叶茂中的一片叶子，但是对于小厂而言，则是性命攸关的大事，所以论战斗力和产品力，孰强孰弱还真不一定。”程浩说道。</p><p></p><p>“另外，现在已经过了互联网高速发展、赢家通吃的阶段了，社会化分工是必然趋势。而且对于大厂而言，做不做这件事，说到底还是个 ROI 问题：第一是如果你做了有损合作伙伴的事，那么你前期所有的生态构建就会瞬间崩塌，想要再做大生态几乎不可能了；第二是从营收的角度，如果把生态做大了，大盘里每增长 1% 可能都比你在垂直赛道做到 100% 都大得多。”程浩补充道。</p><p></p><p>事实上，飞书在生态方面的开放超乎大家的想象。“我们做生态并不是说要划山头，很多竞品企业的好产品也都在我们的生态内。”程浩说。据悉，目前飞书开放平台已经接入了 1000+ API ，飞书希望通过丰富灵活的开放能力、流畅便捷的开发体验，帮助企业系统与飞书深度融合。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e5/e55e73c7d9c070247bbdd58223d64259.png\" /></p><p></p><p></p><h3>用飞书，找效益</h3><p></p><p></p><p>“先进团队，先用飞书”，不只是一句口号。</p><p></p><p>访谈过程中，给到 InfoQ 最大的认知重构在于：“先进”并非一句贴金的形容词，而是一种企业经营理念，一种集体趋向的状态，飞书这个产品更像是字节文化的外显，效率、协同、数据、理性……不一而足，这些特质实际上是当下整个商业社会所稀缺且亟待弥补的。而这个感受，则需要从飞书的协同能力谈起。</p><p>程浩表示：“其实整个飞书的协同能力我认为应该分三个阶段，1.0 阶段就是最被大家熟知的飞书，包括各种知识的沉淀、业务流的审批以及一些机器人待办提醒等等；2.0 阶段则开始帮助更多的企业将业务接入到飞书上去，比如销售流程管理、产品研发管理等等，这个阶段的飞书能够直接帮助企业降本增效；3.0 则是 AI 共创阶段，比如今年我们推出了飞书智能伙伴这一开箱即用的功能，将大模型的能力接入进来。</p><p></p><p>如果把飞书 1.0 阶段的协同能力比作点式协同，那么 2.0 阶段则更像是能够实现跨组织、跨部门、跨业务协作的线和网。</p><p></p><p>以合思为例，在没有使用飞书之前，合思公司使用第三方的 CRM 系统和项目管理系统来解决外部工单场景问题。使用流程是：客户成功团队从 CRM 系统内提单 → 分诊台接单并对工单进行分析，确认是 bug 的工单会手动转发给研发人员 → 研发人员在项目管理系统中，针对工单内容确认修复或给出解决方案 → 分诊台手动在 CRM 系统内操作完成并备注。</p><p></p><p>在使用飞书后，合思公司实现了外部工单场景 SOP 的自动化，依托飞书的协同能力打通系统数据，从人找数据变成了数据找人，大大提高了工单实施效率。当外部工单进入后，飞书会自动进行分类并转发至相应角色，其中确认是 bug 的工单，会通过 IM 发送至指定研发人员进行确认，并且还能自动生成开发任务，任务状态也会自动流转至工单系统，并完结工单状态。</p><p></p><p>项目管理同样也是企业内部高需求场景之一。引入飞书，汇联易的项目管理效率有了显著提升。以前，项目负责人和节点负责人需要频繁沟通以同步项目信息。现在，借助飞书的多维表格功能，无论是研发还是交付，所有项目可以在一个统一界面中管理，极大地增强了协作效率。例如，在研发项目中不同团队负责不同模块，通过飞书的可视化报表，每位项目成员都能一目了然地掌握整个项目的进度和状态。这不仅有助于合理规划时间，保证按期完成，还能确保跨部门的顺畅协同作业。一旦任务完成，下一个环节的责任人也会自动收到提醒，确保流程的高效推进和人效的有效提升。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/77/77dd0071450969d43d701716874093a5.png\" /></p><p></p><p>对于多维表格，程浩补充表示，多维表格的一大价值是帮助企业做数据整合与分析。以成本核算为例，以前大家都是不同的服务商、不同的费用清单，最终汇总起来，决策者能看到的只是一个结果性的数字，没法往下深挖，或者说需要花很多时间去“刨根问底”，有了多维表格，大家可以把各种数据表单都“灌进去”，然后通过多维表格去做数据透视、可视化分析等等，所有花销的投入产出比一目了然。</p><p></p><p>此外，在企业最关注的销售管理场景，飞书同样与合作伙伴探索出了很多最佳实践。以分贝通为例，通过使用飞书，分贝通建立了一客一群、一客一档等机制，所有客户数据和沟通分析过程都会自动同步客户群并汇总到客户档案，大大规避了人工记录汇总的各种不规范、不及时等问题；同时分贝通使用飞书项目功能，对客户全生命周期数据的填写制定了规范的表格，并严格结合客户旅程按照“项目”管理方式管理数据填写。同时在填写完数据后实时同步客户群，并及时通知群成员审核。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e7/e785b654f78f9c677953b634506343a9.png\" /></p><p></p><p>根据介绍，使用飞书后，分贝通的开发工作量降低了 60%、客户管理效率提升 1 倍、客户转化周期提升了 40%。</p><p></p><p>事实上，从 1.0 到 2.0，飞书已经实现了从协同办公工具向业务管理工具的进化，3.0 阶段更多的是面向客户场景去深挖、去抽象出更多的最佳实践，同时引入 AI 的能力去赋能。“其实飞书一直以来卖的都不是一个产品或者一种工具，而是行业最佳实践。与我们一起合作、共创的一些企业，他们也希望自己的最佳实践能够被传播，被更多人看到，因为这也是实力的一种体现。”程浩补充道。</p><p></p><p>对于 3.0 阶段的最新进展，程浩表示：“目前我们已经提供了很多即插即用的场景，大家可以去官网上看，另外一些与客户行业、业务结合比较紧密的场景，也在与客户持续共创中。”</p><p></p><p></p><h3>成为“先进企业”</h3><p></p><p></p><p>事实上，在与客户的共创过程中，一些“触及灵魂”的事情发生了。</p><p></p><p>“有很多客户在跟我们进行共创的过程中，通过使用飞书的一些功能和服务之后，开始思考自己之前的工作流是否合理、是否高效，进而开始主动优化。”程浩表示。</p><p></p><p>而这就比较有趣了。事实上，相比于国外企业选择的长期顾问咨询的模式，中国的企业更倾向于出现问题见招拆招的打法，好处是短期成本更低，但是从长远来看，容易带来大量的历史遗漏问题。而这也就是为什么中大型企业需要花费大量的时间、金钱去请顾问专家做战略梳理、业务梳理的根因。</p><p></p><p>但是，如果企业一开始就使用类似飞书这样的工具，去管理业务、数据、人力等，那企业发展中后期的定时炸弹是否还会存在？如果一些传统企业通过使用飞书，利用工具的力量去倒逼、优化组织流程，是否也能最大程度规避未来的麻烦呢？更重要的是，它可以先从高频痛点的场景先出发，对于既有业务运转的影响也会降到最低。</p><p></p><p>前期看市场，中期看效益，后期看理念。文首的这句话，一方面指的是对于 SaaS 企业上飞书、用飞书而言，首先是从飞书能够给它带来多少的市场价值出发，而后则是飞书能够给组织的降本增效带来哪些帮助，最后则是通过飞书，对企业的组织运转的理念和认知能带来怎样的改变，也就是利用先进工具，成为先进企业。前两者，能够帮助企业增强前中期的战斗力，而最后一层，则关乎企业未来的基业长青。就像人年轻的时候，大都会为了拼搏事业而牺牲一定程度的健康，但是当鱼与熊掌可兼得之时，相信没有人会拒绝。</p><p></p><p>另一方面，这句话同样也适用于我们如何理解飞书。企业竞争，理念致胜，更先进的理念可能开花结果更晚，但却更有机会赢得未来。</p>",
    "publish_time": "2023-12-18 17:18:24",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "API 网关 APISIX 在 DataVisor 的应用与实践",
    "url": "https://www.infoq.cn/article/jZsSWfaqmKiCdPKMNsFL",
    "summary": "<p>DataVisor 是一家专注于风控领域的公司，致力于防范反击战、反作弊等方面的工作。在 DataVisor 的产品开发中，我们不仅在生产环境中应用了 APISIX，还对 APISIX 进行了多个维度的二次开发，如插件方面的二次开发，并最终获得了良好的生产效果。下面将为大家简单分享 DataVisor 应用 APISIX 的经验。</p><p></p><h1>业务痛点</h1><p></p><p></p><p>性能压力大： DataVisor 所在的风控行业对性能指标极为敏感，要求风控计算时间在极短的时间内完成。未能在规定时间内完成风控计算可能导致丧失风险控制结果。在这个高度竞争和风险敏感的环境中，确保风控计算的及时性和有效性成为行业内的首要任务。难以平衡安全与用户体验： 风控任务旨在拦截用户的危险操作，但又要确保不影响用户的正常操作。这要求 DataVisor 的系统能在保障用户使用安全的同时，能够降低对用户体验的不利影响。网关工具难以满足要求：大部分市面上的 API 网关工具容易出现延迟高或毛刺问题，这种低性能可能对 DataVisor 整个系统的稳定性和可用性产生负面影响，特别是在需要高效处理业务流量的情况下。因此，选择一个性能稳定、延迟低的 API 网关工具对于确保系统的顺畅运行至关重要。</p><p></p><h1>在生产环境中应用 APISIX</h1><p></p><p></p><p>DataVisor 在产品领域中采用了一种综合的网关和认证解决方案。在我们的产品体系中，不仅仅使用了 APISIX，同时还整合了 AWS API Gateway、ALB 和 Imperva 等其他产品，以及 Application Load Balancer (ALB)，并在加入了一个 OAuth 认证机制。这些组件都有一些网关功能，它们共同协作，实现了我们系统中的流量接入功能。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4b/4b924e7b804ea08fb1e9998f198b7c6a.png\" /></p><p></p><h2>为何选择 APISIX</h2><p></p><p></p><p>在选择适用于我们生产环境的解决方案时，我们进行了多方面的比较，最终决定采用 APISIX。</p><p></p><p>低成本：相较于由云厂商提供的简单应用网关（例如 ALB），APISIX 为我们节省了大量成本。高性能、低延迟：APISIX 突显出的卓越性能是其一大亮点。与其他 API Gateway 工具相比，APISIX 不仅不会出现较高的延迟，而且不容易产生 P99 或 P9999 毛刺。并且 APISIX 能够有效应对并刷新这些性能上的问题。关注行业特性：在风控领域，业务系统规定风控计算时间仅为 50 毫秒。在这短暂的时间内，如果无法完成风控计算，将直接放弃风控结果。风控的任务是拦截用户的危险操作，但不能影响用户的正常操作。</p><p>&nbsp;</p><p></p><h2>如何使用 APISIX</h2><p></p><p></p><p>目前，APISIX 在我们的生产环境中的应用越来越广泛。</p><p></p><p>由于 DataVisor 本身没有直接的业务，其产品主要销售给各种各样的厂家，由厂家调用我们的服务；因此，APISIX 实际上是我们部署在公网的流量入口，这在实际应用中可能相对较为少见。通常情况下，APISIX 可能会被部署在内网或公网再下一层的网络上，而我们选择将其直接部署在公网，由 APISIX 帮助我们承接来自不同业务上的流量。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/21/212eb3760acefecef6ae09779c60b2fe.png\" /></p><p></p><p>为了更具体地说明我们在生产环境中对 APISIX 的应用，以下是一个典型的应用场景示例：</p><p></p><p></p><blockquote>客户 A 首先通过红色线路访问我们的系统，以获取授权访问的 token，然后访问我们内部的授权服务器；或通过 APISIX 接入其他的授权服务器，例如海外常用的 Okta。我们主要使用Okta对流量进行鉴权，首先将所有流量转发到 Okta，再由 Okta 进行第一步鉴权。接下来，客户获取到不同的 token 后，我们通过 APISIX 的路由选择，将这些经过授权服务器鉴权的流量录入到不同的 Kubernetes 集群中。</blockquote><p></p><p>&nbsp;</p><p>目前，我们已经部署了一个双活 Kubernetes 集群，其中流量被路由到 A 集群或者 B 集群。通常情况下，我们会将流量录入到一个 Kubernetes 集群，另一个集群用于储备，只有在进行大范围升级或者集群升级时才会进行分流。</p><p><img src=\"https://static001.geekbang.org/infoq/df/dfbb466421cc533acca6bed55f7ab1e4.png\" /></p><p></p><p>在网关的使用方面，我们采用了相对简单和常规的部署模式。有一个有趣的观察是，我们可以将 APISIX 部署在我们的 Kubernetes 集群之外。这是因为 APISIX 具有非常高的性能，基本上不会消耗太多 CPU。通过在集群外使用小型机型来部署 APISIX，我们能轻松处理大量的网络流量。</p><p></p><p>在生产环境中，我们部署了三个 APISIX 节点，每个节点可能只配置了两核，并使用 2G 或 4G 的小型机器来承接流量。APISIX 的性能足够媲美 NGINX 与 OpenResty，甚至超出了我们的预期。</p><p></p><h1>对 APISIX 的二次开发</h1><p></p><p></p><h2>扩展特权进程</h2><p></p><p></p><p>在 NGINX 中并不存在特权进程这个概念，但在 OpenResty 中有所体现，它与 worker 进程处于同一级别。这个进程相对来说较为特殊，因为它并不具备接入网络流量的能力，即不监听任何端口，但却可以执行一系列的计算和采集任务。因此，我们对这个特权进程进行了一定的扩展。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/24/24ef0473c19f1496e439fb6e2193dc28.png\" /></p><p></p><p>上面的示意图简明地呈现了 APISIX 与我们后端服务之间的关系。我们主要用 APISIX 来接收和分发流量。</p><p>在网关层，APISIX 在流量进入之前进行预处理，而我们独特的地方在于在 APISIX 这一层引入了一个小进程。这个进程类似于 Sidecar，它在与 APISIX 进程同时运行的同时，负责执行自身的任务。随后，它将采集到的数据发送给 APISIX，再由 APISIX 传递回到自身的上层，去做一些业务逻辑。这种用法相对较为罕见，通常业务场景较少涉及，但在风控领域可能会遇到这种情况。</p><p><img src=\"https://static001.geekbang.org/infoq/15/15f72ffb36c6d5038620f66ae17afcf2.png\" /></p><p></p><p>而特权进程又该如何实现呢？我们的模型通常采用 master-worker 结构，其中 worker 进程负责处理业务流量，而 master 进程则会 fork 出一个特殊的特权进程。在我们的开发中，特权进程只能有一个。因此，我们采取了一种特殊的策略，即在特权进程中 fork 了另一个进程，由这个进程执行其他任务，以避免干扰特权进程繁忙的工作。</p><p></p><p>在数据采集方面，特权进程和 worker 进程通过 shared-dict 进行通信。shared-dict 的性能是非常高的，对于大多数场景都能够满足需求。</p><p></p><h2>扩展 ssl-certificate-phase</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/1a/1a906c0c2cc5063ce76eb5a74f1cb253.png\" /></p><p></p><p>扩展 ssl-certificate-phase 涉及 APISIX 基于 NGINX + Lua 框架的引入。起初，APISIX 并不支持在 TLS 中的握手阶段进行大量的脚本注入。随后，当 OpenResty 社区支持了在 ssl-client-hello 阶段注入代码的功能时，我们注意到 APISIX 社区尚未跟进。因此，我们只能采取手动修改 APISIX 的方式。</p><p></p><p>我们参考了之前的代码结构，在 APISIX 的流程中插入了我们自己的代码，使其在 client-hello 阶段运行我们的一些代码。在 client-hello 阶段，可以实现的功能很多，但在 Lua 层面相对较为有限。在许多情况下，我们需要借助 NGINX 进行 module 开发，或者为 NGINX 创建一个小的动态库来完成这些任务。</p><p></p><p>目前，OpenResty 和 Lua 在加载动态库这方面表现得非常出色。有一个名为 ffi 的功能，可以轻松加载动态库。这只需在动态库中编辑好所需的外部接口，然后通过几个简单的 ffi 命令即可将动态库中的函数导出到 Lua 来使用，它将提供出乎意料的性能提升。使用 ffi + Lua 这种模式编写出来的代码性能大致相当于纯 C 语言编写的 70%。换句话说，假如纯 C 语言一秒可以执行 100 次，它每秒就能执行 70 次，基本可以认为是性能第一。而且，随着运行时间的增加，呈现出来的效果会越来越好。</p><p></p><h2>插件开发</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/e5/e5c8467cd21ee0a04bc3f6472c6cbcb4.png\" /></p><p>由于我们对 APISIX 进行了二次开发，打包出来的产品中，许多功能仍然硬编码在整个项目中，难以进行动态调整。因此，我们决定打包一些插件，将它们整合到 APISIX 项目中，然后用 Dashboard 再进行修改。</p><p>使用 APISIX 进行插件开发非常便利，可以轻松地开发高性能插件。目前，APISIX 不仅支持 Lua 插件开发，还支持多种编程语言，包括 Java、Go，还有 Python，帮助用户实现各种各样的功能。</p><p></p><h1>APISIX 带来的生产效果</h1><p></p><p></p><p>我们在生产环境中使用 APISIX 已经超过一年时间，对其稳定性和性能的表现深感满意，使得我们对其应用的信心倍增。部署 APISIX 后，我们整体提升了系统性能，取得了优异的生产效果。</p><p></p><p>延迟最小化：APISIX 的优异表现体现在显著降低的延迟水平。与其他解决方案相比，我们注意到用户请求的处理时间更短，这对于提供更为流畅的用户体验至关重要。吞吐量提升：APISIX 的部署带来了显著的吞吐量提升，使得系统能够更高效地处理并发请求。相较于其他 API 网关产品，我们成功实现了更大规模的请求处理，确保了系统在高负载下的稳定性和可靠性。这为应对激增的用户流量提供了可靠的基础。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ee/ee43c5abb065e7a0df02ac94e4d17e31.png\" /></p><p>&nbsp;</p><p></p><h1>对 APISIX 的展望</h1><p></p><p></p><p>APISIX 是一个极富活力的社区，会持续进行每月的版本迭代。在这一领域，我对 APISIX 的未来发展有两点功能改进的展望。</p><p></p><h2>通过 Dashboard 实现动态新增或更新</h2><p></p><p></p><p>当前情况下，一旦插件开发完成，我们就无法实现热更新。插件无法直接通过 post 方式传递到 APISIX server，依然需要重新打包 APISIX server 并重新启动，尤其在 Dashboard 方面。因此，我们期望 APISIX 能够实现热更新的功能，使得插件的动态新增与更新能够更为便捷地通过 Dashboard 实现。</p><p></p><h2>支持使用 run_worker_thread 计算&nbsp;CPU 敏感型</h2><p></p><p></p><p>NGINX 中引入了一项名为线程的特殊机制。这些线程的主要任务是处理一些与网络无关的任务，例如高 CPU 利用率的活动（数据的加解密和压缩）。虽然它与网络 I/O 无关，但高 CPU 使用率可能导致该进程中其他网络请求受到一定的阻塞。</p><p></p><p>因此，我希望 APISIX 能引入类似的功能。如果能使用 APISIX 处理一些复杂功能计算，比如数据的加解密和转存等，将是一项有益的改进。&nbsp;</p><p></p><h1>总结</h1><p></p><p></p><p>DataVisor 特别注重了风控领域的性能需求，并通过采用二次开发的独特策略来解决实际问题。APISIX 在&nbsp;DataVisor&nbsp;的应用经验不仅在技术实践中取得了成功，而且为我们公司在风控行业中的稳健运作提供了坚实的基础。通过这些经验的分享，我们希望能够为行业内其他相关企业提供有益的参考，共同推动风控技术的不断创新与进步。</p><p>&nbsp;</p><p>作者介绍：</p><p>&nbsp;</p><p>赵晓彪，DataVisor 高级架构师，Apache Kvrocks Committer，OpenResty 及 Apache APISIX Contributor。</p><p>&nbsp;</p>",
    "publish_time": "2023-12-18 17:21:51",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]