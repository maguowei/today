[
  {
    "title": "代码生成：基于AI大模型的挑战与前景",
    "url": "https://www.infoq.cn/article/5LWEiT9DNPzCWsoqtdQE",
    "summary": "<p>使用 AI 通用模型来完成代码生成这类非常具体的任务可能会带来问题。人工智能生成的代码就像是陌生人的代码，它们可能并不符合你的代码质量标准。这种情况下，创建专业或专用的模型不失为一条出路。</p><p>&nbsp;</p><p>Luise Freese 和 Iona Varga 在<a href=\"https://ndcoslo.com/\">2023</a>\" 年的&nbsp;<a href=\"https://ndcoslo.com/\">NDC Oslo</a>\" 大会上探讨了 AI 模型的实践困境和伦理相关问题。</p><p>&nbsp;</p><p>Varga 提到，“人工智能”这个词给人一种智慧的感觉，虽然这个名字实际只是代表了这些模型的构建方式。以节点相连的形式模仿人脑中神经元与突触连接而成的网络，这类模型因此而得名“人工网络”或“人工智能”。</p><p>&nbsp;</p><p>Freese 补充道，抽象来说，计算机是完全依赖于或开或关的晶体管，通过这些开关的组合，我们得以操纵比特。由于晶体管之间没有相互的纠缠，这些开关最终会带来这样的结果：</p><p></p><p></p><blockquote>因此，计算机并不会思考，不过是我们的人工智能算法赋予了它们个性和特征，比如“让我考虑一下”这类礼貌说辞。AI 仅仅是利用统计数据对事物进行预测、分类或组合。</blockquote><p></p><p>&nbsp;</p><p>Varga 提到，AI 的问题在与使用极其通用的模型或是基础模型完成非常具体的任务。大语言模型（LLM）的工作原理是先分析问题、创建一两个词语，再根据统计数据预测下一个标记的最佳匹配。此外，LLM 本身是无法对事实进行核查的，因为这类模型的设计目的是生成而非验证。</p><p>&nbsp;</p><p>如果我们试图建立一个能解决所有 AI 问题的 AI 模型，那么我们将会创造出一种自我放大的螺旋式下降，Freese 补充道。若想实现螺旋式上升，那就应该少用基础模型，多用更为具体的模型，后者中有一部分实际就是搭建在基础模型之上的。</p><p>&nbsp;</p><p>AI 或许能生成代码，但这些代码是否能安全地使用，是否能满足我们对质量的标准要求？Varga 认为这些问题只能由真正的人类来回答，这一过程并不容小觑。归根结底，就像是代码的编写一样，调试陌生人的代码远比自己从头到尾参与其中的代码更为困难。</p><p>&nbsp;</p><p>一般模型的理解能力也更为通用，这在代码生成问题上可能会带来问题，正如 Varga 所解释的：</p><p></p><blockquote>举例来说，React v17 或 v16 这些可能没有直接反应在模型的上下文中，但模型也能了解这些代码库。或许你会发现自己生成的一个函数中会混杂有两个版本的代码。</blockquote><p></p><p>Varga 认为，多数情况下 AI 都是解决问题的好帮手。但使用 AI 就意味着你要去检查、验证、修改、编辑或重写部分内容，而这一部分可能才是我们低估 AI 工具带来工作量的地方。</p><p>&nbsp;</p><p>InfoQ 针对人工智能所带来的挑战问题采访了 <a href=\"https://www.linkedin.com/in/luisefreese/\">Luise Freese</a>\"&nbsp;和 <a href=\"https://www.linkedin.com/in/iona-dahlia/\">Iona Varga</a>\"。</p><p>&nbsp;</p><p>InfoQ：什么因素会造成 AI 的失败？</p><p></p><p></p><blockquote>Iona Varga：一般来说，AI 并不是命中注定要失败的。我是医学物理出身的，我也见过很多优秀的 AI 工具，它们能出色地完成波弹性成像的实时剪切，早期阶段的婴儿检测，甚至能检测出肿瘤专家都无法发现的肺癌细小结节。&nbsp;但由于虚假数据和扭曲事实问题的存在，这些结果并不完全可信。举例来说，川普就职典礼上，实际的到场人数是要少于最初公布的数据。试着问模型就职典礼的公园有多热闹，你大概会得到一个出乎意料的答案。但同样，数据的来源时至今日也有颇具争议的历史背景，它们可能会出于政治剧本或标准等原因而被修改。</blockquote><p></p><p></p><p>InfoQ：伦理道德如何才能帮助我们解决 AI 所带来的问题？</p><p></p><p></p><blockquote>Luise Freese：伦理道德作为工具本身是帮不上太多忙的。伦理只是一种工作的方式，就像是 DevOps 一样。一旦你有了规划，知道该做什么了，“伦理道德”就是你对“完成”的定义。我所用的数据是否覆盖了所有产品使用相关的人或事？通过这些道德的检测，我们的工作方式将会在可访问性、包容性和避免偏见方面得到改善。</blockquote><p></p><p>&nbsp;</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/10/producing-quality-code-AI/\">The Challenges of Producing Quality Code When Using AI-Based Generalistic Models</a>\"</p>",
    "publish_time": "2023-10-16 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "京东辟谣“刘姓商人涉嫌违法被抓”；比特大陆全员工资暂停发放；一周可居家办公3 天，去哪儿灵活办公制度出炉｜Q资讯",
    "url": "https://www.infoq.cn/article/FjKxBRyykMgAsNHSHJe6",
    "summary": "<p></p><p></p><blockquote>去哪儿回应实行灵活办公制度：和员工一起探索更酷的工作方式；比特大陆部矿进度严重不达标，全部员工工资被暂停发放；Unity首席执行官卸任，曾受死亡威胁；印度逮捕vivo中国员工？vivo回应；威马车主反映车机、手机 App 已停服，客服电话无人接听；传百度文心4.0推理成本翻10倍；微软GitHub Copilot 亏损严重，每个用户每月亏损超 20 美元；OpenAI 的年化营收超过 13 亿美元；图灵奖得主、深度学习之父Hinton入局机器人创业；强化学习之父萨顿联手传奇程序员卡马克入局 AGI 创业，放话不依赖大模型；为成为 iOS 默认搜索引擎，Google 每年向苹果支付 180 亿-200 亿美元；美国欲打算管制开源的RISC-V，担心中国借此发展自己的半导体产业；北京应届毕业生招聘月薪超1.3万元居全国首位，人工智能领跑行业……</blockquote><p></p><p>&nbsp;</p><p></p><h2>科技公司</h2><p></p><p></p><h4>京东：关注到有谣言称“刘姓商人涉嫌违法被抓”已报案</h4><p></p><p>&nbsp;</p><p>10月13日，京东发言人发文称，我们关注到有谣言称“刘姓商人涉嫌违法被抓”，该谣言被别有用心的人刻意发布在京东相关新闻动态下，以混淆视听、操纵舆论。我们对此恶劣行径表示强烈愤慨，并已向公安机关报案。</p><p>&nbsp;</p><p>当天上午，京东集团港股股价大跌，一度跌超12%，报每股103.5港元，创上市以来新低。目前，京东集团港股最新总市值约为3291亿港元。此外，隔夜美股京东收跌8.27%，报27.83美元。</p><p>&nbsp;</p><p></p><h4>去哪儿回应实行灵活办公制度：和员工一起探索更酷的工作方式</h4><p></p><p>&nbsp;</p><p>此前，有去哪儿员工爆料称，继携程之后去哪儿网也开始实行居家办公制度。10月10日，去哪儿COO（首席运营官）刘连春发全员信称：让员工可以自己选择办公地点是去哪儿此次的尝试，分组进行是希望 “探索更酷的工作方式，在不同模式下，找到工作效率与生活幸福指数间最大的平衡。混合办公就是为了鼓励大家多走出去看看这个世界。”</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/13/134353b4ef915034cc42a0a00adbffea.png\" /></p><p></p><p>&nbsp;</p><p>据了解，去哪儿灵活办公目前只有一部分员工参与实验，分ABCD四组，分别是每周灵活0、1、2、3天，该分组会持续到明年六月。有网友调侃道：只要不在去哪儿呆着，想去哪儿去哪儿。</p><p>&nbsp;</p><p></p><h4>比特大陆部矿进度严重不达标，全部员工工资被暂停发放</h4><p></p><p>&nbsp;</p><p>据多名比特大陆内部员工确认，比特大陆发布通知：9月公司经营现金流仍未转正，尤其是部矿（指矿机进驻矿场）进度严重不达标，EMT决定暂缓发放9月份全体员工部分工资，10月7日假期之后视情况发放。多名员工透露，所有员工9月份的绩效工资被全部扣掉，基本工资也被扣了一半，被扣掉的工资不知道啥时候才能发。截至10月8日，员工们都还没收到未发的工资，2022年的年终奖至今都没有发。</p><p>&nbsp;</p><p>比特大陆曾垄断全球超七成的比特币矿机市场份额，后因两大创始人吴忌寒、詹克团争夺控制权的“内斗”事件元气大伤。今年一季度，比特大陆执行员工结构薪酬改革，在绩效考核时加入“年龄分”，基准年龄之上，年纪越大扣分越多。比特大陆员工称，在最新的薪酬调整方案中，原本的固定工资调整为基础工资+绩效工资两部分，而绩效工资与职级挂钩，T3x、T4x、T5x三档职级绩效工资比例分别为30%、50%、70%。</p><p>&nbsp;</p><p></p><h4>Unity首席执行官卸任，曾受死亡威胁</h4><p></p><p>&nbsp;</p><p>10月9日，游戏引擎开发商Unity发布一则关于《Unity宣布领导层交接》的公告，称公司CEO John Riccitiello将卸任，即日起生效。而这距9月12日那项引爆整个游戏圈的“按安装量收费”新模式推出以来，还不足一个月，Riccitiello 甚至在9月15日被曝受到了死亡威胁。</p><p>&nbsp;</p><p>9月12日，Unity在官网公告称，将从2024年1月1日开始向符合条件的游戏产品征收运行时费用“Unity Runtime Fee”，按安装量单次收费，价格区间为0.01-0.2美元。Unity这一公告在游戏圈内引发震动，多家开发商集体表达了不满和抗议。当前，外界对这新一轮的人事变动的普遍看法是，这应该是为此前“灾难性的”新收费模式所引发的巨大争议进行收场。</p><p>&nbsp;</p><p>更多详情阅读：</p><p><a href=\"https://mp.weixin.qq.com/s/tv4Yb5uftj2WyVPG3WtUuA\">小型开发者的生存之战：Unity 想要我们的全部收入！我们要破产了</a>\"</p><p>&nbsp;</p><p></p><h4>印度逮捕vivo中国员工？vivo回应</h4><p></p><p>&nbsp;</p><p>10月11日，据外媒报道，印度金融执法机构已经逮捕了中国手机公司vivo的一名中国籍员工。一名印度政府官员证实，印度执法局已经逮捕了四名与vivo有关的人，其中包括一名中国公民。截至目前，印度执法局尚未就此公开发表评论。</p><p>&nbsp;</p><p>对此，vivo 回应称，一名员工被捕，但没有详细说明被捕者的国籍。该公司在一份声明中表示：“印度执法局最近的逮捕行动令我们深感担忧。我们将动用一切可用的法律手段。”vivo还补充说，公司会“坚定地遵守其道德原则，并致力于合法合规”。</p><p>&nbsp;</p><p></p><h4>威马车主反映车机、手机 App 已停服，客服电话无人接听</h4><p></p><p>&nbsp;</p><p>近日，威马汽车配套软件无法使用的消息引发热议，而威马车友圈中有网友表示，最早从今年 8 月开始，威马的 App 就出现异常。有网友反映，手机端只能接收数据，不能控制车辆。也有网友称，威马车机系统登入二维码都已经无法显示。</p><p>&nbsp;</p><p>此外，还有众多车主反映，威马汽车目前经营异常，门店关停、无法提供汽车配件、售后服务停滞、人工客服缺位等。导致他们在购买威马汽车后无法正常进行保养、汽车出现故障后不能及时维修、签订的电池更换协议无法履行、客服热线一直处于忙线状态无法打通等，消费者权益因此受损。另据报道，尝试拨打威马汽车 400 客服电话，但处于无人接听的状态，而威马汽车社交平台的官方号也未对此做出回应。</p><p>&nbsp;</p><p></p><h4>传百度文心4.0推理成本翻10倍</h4><p></p><p>&nbsp;</p><p>近日，有媒体报道称，百度正加紧训练文心大模型4.0，这将是文心大模型3.5版本后又一个重磅版本，或将在 10 月 17 日举行的百度世界大会上发布。</p><p>&nbsp;</p><p>据报道，文心大模型4.0进展比预期快很多，将是基础模型的大升级，理解、生成、逻辑、记忆核心能力都将提升，特别是在逻辑推理、代码和数学等方面提升最明显。据悉，文心大模型4.0的推理成本相比文心大模型3.5增加10倍。此外，文心大模型4.0的参数规模也将更大，预计突破万亿级别。</p><p>&nbsp;</p><p></p><h4>微软GitHub Copilot 亏损严重，每个用户每月亏损超 20 美元</h4><p></p><p>&nbsp;</p><p>10月10日消息，过去一年，生成式 AI 的热潮为许多公司带来了巨大的利润。其中最大的受益者之一就是英伟达，其 GPU 在 2023 年被大量用于微软等公司的数据中心，使得该公司的利润和股价大幅上涨。然而，微软在其 AI 服务方面却一直难以盈利。据外媒报道，微软在其首个生成式 AI 服务 GitHub Copilot 上损失了大量资金。</p><p>&nbsp;</p><p>报道称，自推出以来，微软在 GitHub Copilot 上一直亏损惨重：“据一位知情人士透露，今年前几个月，平均每个用户让微软每月亏损超过 20 美元，有些用户每月给公司造成的损失高达 80 美元。”报道还称，微软一直在寻找更便宜的运行其 AI 服务的方式。其中一种可能是自制 AI GPU，而不是从英伟达购买。最近有消息称，微软将于 11 月 14 日在 Ignite 大会上正式公布这种 AI 芯片。</p><p>&nbsp;</p><p></p><h4>OpenAI 的年化营收超过 13 亿美元</h4><p></p><p>&nbsp;</p><p>据多位知情人士透露，OpenAI CEO Sam Altman本周告知员工，公司的收入达到年化 13 亿美元。这意味着，当前 OpenAI 的月收入超过 1 亿美元。13 亿美元的年化收入较夏季时年化 10 亿美元的收入还要高出 30%。而去年一整年，OpenAI 的收入仅为 2800 万美元。自今年 2 月推出付费版 ChatGPT 以来，该公司的收入增长速度相当可观，主要来自其“会话聊天机器人”的订阅。</p><p>&nbsp;</p><p>不过，与此同时，布朗大学的计算机科学研究人员发现了 OpenAI 的 GPT-4 安全设置中的新漏洞。他们利用一些不太常见的语言，如祖鲁语和盖尔语，即可以绕过 GPT-4 的各种限制。研究人员使用这些语言来写通常受限的提示词（prompt），发现得到回答的成功率为 79%，而仅使用英语的成功率不到 1%。研究人员承认发布这项研究可能会造成危害，并给网络犯罪分子提供灵感。值得一提的是，在向公众发布之前，该研究团队已经与 OpenAI 分享了他们的发现，以减轻这些风险。</p><p>&nbsp;</p><p></p><h4>图灵奖得主、深度学习之父Hinton入局机器人创业</h4><p></p><p>&nbsp;</p><p>10月12日消息，图灵奖得主、深度学习之父Geoffrey Hinton宣布，将加入机器人初创公司Vayu Robotics，担任顾问一职。今年5月，Hinton突然从任职十载的谷歌离职，轰动整个科技圈。他本人当时表示，这么做是为了可以自由地讨论人工智能风险。</p><p>&nbsp;</p><p>自从离职后，这位AI教父收到邀约不断，但都没能吸引到他——直到Vayu Robotics出现。Hinton给出的加入理由是，它们的技术路线和其他很多AI应用相比，AI道德风险更低。当然Vayu Robotics自身实力也很强，被英伟达AI科学家Jim Fan称为业内的“big names”。不过还有一点非常关键：Vayu Robotics的CTO尼蒂什·斯里瓦斯塔瓦（Nitish Srivastava）为Hinton门下弟子。</p><p>&nbsp;</p><p></p><h4>强化学习之父萨顿联手传奇程序员卡马克入局 AGI 创业，放话不依赖大模型</h4><p></p><p>&nbsp;</p><p>据报道，传奇程序员卡马克和强化学习之父萨顿联手创办了 AI 创业公司 Keen Technologies，他们的目标是在 2030 年向公众展示通用人工智能的可行性。</p><p>&nbsp;</p><p>与主流方法不同，他们不依赖大模型，而是追求实时的在线学习。他们相信，最终的 AGI 源代码可以由一个人编写，只需几万行。两人在萨顿任教的阿尔伯塔大学机器智能研究所（Amii）特别活动上宣布了这一消息。萨顿同时还会保持在阿尔伯塔的教职。</p><p>&nbsp;</p><p>两人在活动中都承认，与拥有成百上千员工的大公司相比，Keen Technologies 的团队规模很小。目前还在刚起步阶段，“公司整个技术团队都到了现场——只有站着的这 4 个人。”</p><p>&nbsp;</p><p></p><h4>为成为 iOS 默认搜索引擎，Google 每年向苹果支付 180 亿-200 亿美元</h4><p></p><p>&nbsp;</p><p>据外媒报道，投资管理公司联博（Bernstein）报告估算，Google 每年向苹果支付 180 亿至 200 亿美元，以保持其是 iPhone 等产品的默认搜索引擎，占苹果年度营业利润的 14-16%。</p><p>&nbsp;</p><p>Bernstein 在报告中表示，“联邦法院有可能做出对 Google 不利的裁决，并迫使其终止与苹果的搜索协议。”Bernstein 称 Google 将 22% 的广告营收投入流量获取成本（TAC，Traffic Acquisition Costs），而苹果公司在其中的占比达到 40% 左右。据此前报道，Google 每年向苹果支付数十亿美元，以便于在苹果设备上，将其设置为默认搜索引擎。本次审理大部分都是闭门进行的，官方并未披露 Google 向苹果支付了多少金额。</p><p>&nbsp;</p><p></p><h4>华为5.5G手机或明年上半年商用</h4><p></p><p>10月11日，据媒体报道，华为相关人士透露，最早今年底，各大手机厂商旗舰手机将达到5.5G的网速标准，下行速率将达5Gbps，上行速率将达500Mbps，真正的5.5G手机可能要到2024上半年到来。此外，从产业链相关人士处获悉，目前手机大厂已对5G-A（5G-Advanced / 5.5G）芯片在能力验证中，有望在2024年上半年商用。</p><p>&nbsp;</p><p>10日在全球移动宽带论坛（MBBF2023）上，华为宣布将在2024年推出面向商用的端到端5.5G全套网络设备。同时，华为轮值董事长胡厚崑表示，正努力将5G-A带进现实。大模型、ChatGPT、自动驾驶需求持续增长，对网络持续演进提出要求，而5.5G便是为未来所做的准备。</p><p>&nbsp;</p><p></p><h2>IT 业界</h2><p></p><p>&nbsp;</p><p></p><h4>美国欲打算管制开源的RISC-V，担心中国借此发展自己的半导体产业</h4><p></p><p>&nbsp;</p><p>近日，美国正试图开辟“科技战”的“新战线”，包括两名共和党众议院委员会主席、共和党参议员Marco Rubio和民主党参议员Mark Warner在内的一些美国议员，正要求美国政府限制美国企业参与合作研发在中国广泛使用的RISC-V开源技术。此举可能会颠覆全球科技行业的跨境合作方式。</p><p>&nbsp;</p><p>上述美国政客表示，他们担心中国正在利用美国企业之间开放合作的文化来发展自己的半导体产业，这可能会削弱美国目前在芯片领域的领先地位。这些意见是对美国公司在RISC-V方面工作施加限制的首次重大举动。</p><p>&nbsp;</p><p>美国众议院中国问题特别委员会主席Mike Gallagher在给路透社的一份声明中表示，美国商务部需要“要求任何美国个人或企业在与中国实体就RISC-V技术进行合作之前获得出口许可证”。</p><p>&nbsp;</p><p></p><h4>北京应届毕业生招聘月薪超1.3万元居全国首位，人工智能领跑行业</h4><p></p><p>10月11日，猎聘大数据研究院发布《全国高校毕业生就业趋势与展望2023》显示，北京应届生招聘月薪全国居首。从城市对应的2023届应届生平均招聘月薪看，北京以13283元位居第一；深圳、上海分别以12783元、12317元位居第二、第三。</p><p>&nbsp;</p><p>从各细分行业2023届应届生新发职位平均招聘月薪看，人工智能以18592元位居第一；区块链、养老服务、航空/航天设备分别以17467元、16992元、16042元位居第二至第四。</p><p>&nbsp;</p><p></p><h4>curl 项目披露高危漏洞</h4><p></p><p>&nbsp;</p><p>curl 项目发布了 curl 8.4.0，其中修复了一个高危漏洞 CVE-2023-38545，该漏洞被认为是至今 curl 项目发现的最严重漏洞之一。curl 作者 Daniel Stenberg 在个人博客上详细解释了这一漏洞。攻击者可通过发送长度超过 16kB 的主机名触发该漏洞，导致堆缓冲区溢出。Stenberg 表示，如果 curl 是用内存安全语言 aka Rust 开发的话那么该问题不会发生，但重写 curl 不在他的议程中。他说可能会支持用 Rust 写一些依赖项目，逐步取代部分功能，但在可预见的未来，curl 仍然是用 C 编写的。</p><p>&nbsp;</p>",
    "publish_time": "2023-10-16 09:10:31",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "同盾科技软件产品及方案部 / 总经理董纪伟确认出席 FCon，分享黑灰产欺诈攻防体系的研究与实践",
    "url": "https://www.infoq.cn/article/hI5XGjZzTsLxDS2Q9zSL",
    "summary": "<p><a href=\"https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle\">FCon 全球金融科技大会</a>\"，将于 11 月在上海召开。同盾科技软件产品及方案部 / 总经理董纪伟将发表题为《<a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5573?utm_source=infoqweb&amp;utm_medium=article\">黑灰产欺诈攻防体系的研究与实践</a>\"》主题分享，解析欺诈攻防的底层逻辑，通过对攻防内容设计，综合评判欺诈概率，解决信息差的欺诈本质问题，并基于行业的领先实践，给出新一代的欺诈攻防体系的建设路径和实现建议。</p><p></p><p><a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5573?utm_source=infoqweb&amp;utm_medium=article\">董纪伟</a>\"，花名“阅微”，行业资深安全专家，硕士毕业于中国科学院大学计算机技术专业，曾任国密局密码算法课题组成员 ，人民银行支付清算协会反诈培训讲师，北京金融科技产业联盟金融科技领域高级技术专家。</p><p></p><p>目前担任同盾科技软件产品及方案部总经理兼策略模型总监，负责软件产品线相关解决方案、技术及架构，以及安全策略咨询及模型咨询，负责过工行、建行、邮储、广发、中信、银联等金融行业多家机构风控应用及策略模型的设计与研发，主力研发的交易监控反欺诈软件荣获 2015 年人民银行科技发展二等奖。</p><p></p><p>10 余年金融行业工作经验，FRM 金融风险管理师认证。熟悉金融领域风控与反欺诈相关产品、技术、业务及场景解决方案，擅长反欺诈规则、策略设计及特征建模；曾任人民银行下属机构研发部开发经理、项目经理、高级安全咨询顾问、反欺诈团队负责人、反欺诈项目总监等。他在本次会议的演讲内容如下：</p><p></p><p>演讲：黑灰产欺诈攻防体系的研究与实践</p><p></p><p>随着 ChatGPT 的横空出世，人工智能技术发展迅猛。但与此同时，AI 技术被黑灰产滥用的负面作用也逐步显现，移动互联网的发展也促使场景复杂化，黑灰产欺诈的攻击面、攻击点呈现爆发式增长，呈现隐匿化、团伙化、速度化的态势。此次分享的解决方案将通过黑灰产的最新趋势分析，解析欺诈攻防的底层逻辑。通过对不同主体、在不同环节的攻防内容设计，综合评判欺诈概率，解决信息差的欺诈本质问题，并基于行业的领先实践，给出新一代的欺诈攻防体系的建设路径和实现建议。</p><p></p><p>演讲提纲：</p><p></p><p>黑灰产的最新态势分析不知攻焉知防——黑灰产实施攻击的主要手法、攻击链路如何一环扣一环对于欺诈攻防的思考他山之石——如何有效构建欺诈防御体系</p><p></p><p>你将获得：</p><p></p><p>○ 了解最新的黑灰产欺诈形势</p><p>○ 知晓典型的欺诈场景，如 ChatGPT、AI 换脸、屏幕共享如何被黑产利用</p><p>○ 了解反诈的最新技术应用</p><p>○ 了解业内先进的攻防实践</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle\">DevOps&nbsp;在金融企业落地实践</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle\">金融行业大模型应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle\">创新的金融科技应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle\">金融实时数据平台建设之路</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle\">金融安全风险管控</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle\">数据要素流通与数据合规</a>\"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，享 7 折优惠 ，立省 ￥2040！咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png\" /></p><p></p>",
    "publish_time": "2023-10-16 11:59:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "创新风潮迭起，2023深圳国际金融科技大赛——西丽湖金融科技大学生挑战赛正式启动",
    "url": "https://www.infoq.cn/article/9AYU96ZSPoCZ6kyClK94",
    "summary": "<p>近年来，我国在金融科技领域取得显著发展。根据赛迪顾问《金融科技发展白皮书》数据显示，自 2016 年起相关市场规模一直保持着 10% 左右的稳定增速，2022 年的市场规模同比增长 18.3%。10 月 8 日，《深圳市关于金融支持科技创新的实施意见》正式印发实施，明确将进一步完善金融支持科技创新体系，加大对科技型企业融资的支持力度，建立健全“基础研究 + 技术攻关 + 成果产业化 + 科技金融 + 人才支撑”的全过程创新生态链。</p><p></p><p>为了满足金融科技产业技术创新及人才需求，更好地推动金融科技产业发展，目前政府、学术界和企业界形成了良好的产学研合作机制。作为 2023 年<a href=\"https://www.infoq.cn/article/7ejrDIB7r5KRIuLwaRPd\">深圳市金融科技节</a>\"的重要一环，在深圳市地方金融监督管理局、深圳市福田区人民政府、深圳市南山区人民政府战略指导下，由深圳大学、微众银行、深圳香蜜湖国际金融科技研究院等多方联合举办的“2023 深圳国际金融科技大赛（FinTechathon）——西丽湖金融科技大学生挑战赛”（下文称“大赛”）于 10 月 16 日正式开赛。</p><p></p><p>据悉，该赛事自 2019 年落地至今，已成功举办四届并完成了<a href=\"https://www.infoq.cn/article/5DkdKQyjRuC9YNTgbhm6\">赛事品牌升级</a>\"。大赛汇聚了全球前沿的金融科技人才，其高水平的参赛者、极具挑战性的赛题内容和评委的卓越见解，在过往四届吸引了 3500 余名来自海内外知名高校的学生参赛，备受金融科技领域从业者的关注和认可。本届大赛组委会将基于往届办赛经验，继续进一步提升赛事体验和评选质量。大赛全程聚焦金融科技的前沿理论，分设人工智能、区块链、产品经理三个赛道，将通过初赛、复赛在各赛道分别遴选出 10 支队伍进入决赛角逐，并设置总额超过 69 万人民币的赛事奖金及参赛专属电子区块链证书，以奖励各赛道获得一等奖、二等奖、三等奖的队伍及成员。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/7b/e1/7b9055577073aea33b430e1f0ea373e1.jpg\" /></p><p></p><p>本次大赛致力于鼓励国内外高校学生积极探索金融科技领域的技术应用创新，将创新成果转化为实际应用，为金融科技行业提供更多有价值的技术解决方案。为此，大赛组委会特别邀请了国家统计局原副局长许宪春；加拿大皇家科学院院士、加拿大工程院院士、微众银行首席人工智能官杨强；清华大学五道口金融学院教授、华夏银行原行长、中国人民银行研究局原局长张健华；中国工商银行首席技术官吕仲涛；上海新金融研究院副院长、浙商银行原行长刘晓春；全国政协委员、南方科技大学副校长金李；中国银行业协会首席信息官高峰等人担当学术顾问，为大赛提供智力支持，帮助参赛团队更好地理解和应用金融科技知识。</p><p></p><p>此外，大赛组委会还邀请了来自中科院、清华大学、中山大学、西安电子科技大学、深圳大学、武汉大学、中央财经大学、广东财经大学、浙江财经大学、哈尔滨工业大学、微众银行等学企单位的数十位科研专家担任大赛评委，为参赛团队提供专业的指导建议，挖掘优秀的参赛项目和人才，以加快深圳市金融科技产业升级，抢抓金融科技发展机遇。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/db/dba9c5b835fb450d6ad26674e2cc743b.jpeg\" /></p><p></p><p>10 月 16 日起，本届大赛正式开启报名通道，国内外高校在读生（含本科生、硕士 / 博士研究生）均可报名参赛。有兴趣的同学可点击<a href=\"https://www.infoq.cn/zones/fintechathon/campus2023\">链接</a>\"进入大赛官网 ，或识别下方海报中的二维码进行报名。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/04/04fc67e1a319867248a9cde86965a33e.png\" /></p><p></p>",
    "publish_time": "2023-10-16 13:40:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "OpenAI悄悄改变核心价值观惹争议：埋头搞AGI，其他的都是浮云！",
    "url": "https://www.infoq.cn/article/QFytIPELB8ZxSrmDpLXj",
    "summary": "<p></p><blockquote>最近几周，OpenAI悄然修改了其网站上列出的所有“核心价值观”，更加强调 AGI（通用人工智能）的发展。</blockquote><p></p><p></p><h2>OpenAI悄悄改变核心价值观，重点聚焦AGI</h2><p></p><p>&nbsp;</p><p>据外媒报道，最近几周，作为全球领先的AI研究机构，OpenAI正悄悄对其核心价值观做出重大调整，将之前未明确列出的通用人工智能 (AGI) 纳入其中。</p><p>&nbsp;</p><p>据&nbsp;Semafor报道，该公司此前的价值观为“大胆”、“深思熟虑”、“朴实无华”、“影响力驱动”、“协作”和“以增长为导向”。这些旧点价值观将被一系列新的价值观所取代、明确将AGI列为后续工作的重中之重。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/0b/0b153e221b9044420859bf71377018d2.png\" /></p><p></p><p>&nbsp;截图来源：OpenAI官网首页</p><p>&nbsp;</p><p>新变更的价值观主要包括五点：</p><p>&nbsp;</p><p>聚焦通用人工智能</p><p>OpenAI致力于构建安全、对社会有所助益的人工智能，它将对人类未来产生巨大的积极影响。</p><p>与此无关的任何事情都不在考虑范围之内。</p><p>&nbsp;</p><p>坚韧不拔、勇往直前</p><p>创造非凡的事物需要努力工作（通常是不那么吸引人的任务）和紧迫感；我们所做的每一件事都很重要。要谦逊务实，想尽一切办法做切实可行的事。</p><p>&nbsp;</p><p>坚守规模化效应</p><p>当在我们的模型、系统、自身、流程以及理想抱负达到一定规模时，就会创造奇迹。当受到质疑时，扩大规模是一种十分奏效的方式。</p><p>&nbsp;</p><p>制造出让人喜爱的东西</p><p>OpenAI的技术和产品应当对人们的生活带来革命性的积极影响。</p><p>&nbsp;</p><p>团队精神</p><p>OpenAI最大的进步和差异化来自于团队内部和之间的有效协作。虽然OpenAI的团队有着越来越多的不同身份和优先事项，但整体目标和宗旨必须保持完全一致。凡是归因自身，没有什么问题是别人的问题。</p><p>&nbsp;</p><p>OpenAI 多年来一直表示希望开发 AGI，尽管这种技术的具体细节尚不清楚。在 2018 年发布的一份使命声明中，OpenAI 将 AGI 描述为“在最具经济价值的工作中超越人类的高度自治系统”。</p><p></p><h2>价值观变更惹争议，说变就变也太随意了</h2><p></p><p>&nbsp;</p><p>这一变化引发了人们对这些核心价值观真实性和可靠性的质疑。如果一家企业能够轻松更改其核心价值观，那么这些价值观还能否称得上“核心”？这无疑会激起外界对于该公司在既定目标一致性和承诺方面的担忧。</p><p>&nbsp;</p><p>将“聚焦AGI”作为公司核心价值之举尤其值得注意。而且，OpenAI对于AGI的解释似乎也仍有含糊不清之处。今年 2 月，OpenAI 的首席执行官山姆·奥尔特曼（Sam Altman）在公司博客文章中写道，AGI 可以广义地定义为“通常比人类更聪明的系统”，但在最近一次采访中，奥特曼似乎重新将AGI定义为与普通人类等同的人工智能。</p><p>&nbsp;</p><p>这种AGI定义层面的差异，也进一步引发了关于OpenAI发展目标的讨论。作为一家随时间推移而不断调整方向的公司，OpenAI已经从一家专注于打造良好AI的非营利组织，转变成一家营利性实体。这种目标转变似乎又反过来影响了其技术定义与核心价值观。</p><p>&nbsp;</p><p>尽管人们对于核心价值观的转变持怀疑态度，但OpenAI的未来方向的确已经在就此做出调整。该公司强调将致力于开发安全、有益的AGI技术，借此对人类产生积极影响。也就是说，OpenAI在接下来的经营活动当中将优先考虑与该目标相适应的项目和举措。</p><p>&nbsp;</p><p>在新核心价值观的加持下，OpenAI明显将投入更多资源推动AGI议题。然而，他们将采取怎样的AGI定义方式和实现思路仍然有待观察。</p><p></p><h2>网友怎么看？</h2><p></p><p>&nbsp;</p><p>OpenAI价值观变更一事在Reddit上引发了积极讨论，有网友猜测，“AGI已在OpenAI内部实现了”。一些用户认为这种变更很有意思，“看起来OpenAI似乎已经弄清楚了如何让自己更加强大，现在只是在寻找人来实际建造它（AGI），新的核心价值观读起来更聚焦。”</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/47/475f52621980c42d460ef9dddf47c0b3.png\" /></p><p></p><p>&nbsp;截图来源：Reddit</p><p>&nbsp;</p><p>但也有一些用户对于价值观的改变表现出了担忧，一名ID为Freedom_Alive的用户称：</p><p>&nbsp;</p><p></p><blockquote>“这让我想起了谷歌从其核心价值页面中删除“不作恶”的时候。”</blockquote><p></p><p>&nbsp;</p><p>言外之意，OpenAI价值观的改变也说明了公司行事风格将会与以前不同了。</p><p>&nbsp;</p><p>ID名为Accurate-Ease1675的用户则表示，“让我有点担心的是，像 OpenAI 这样的公司似乎并不理解价值观、使命、目标和愿景之间的区别。以前的价值观没问题，但修改后的价值观不是真正的价值观。它们是一些雄心勃勃的陈述的大杂烩，如果需要做一些额外的工作来解释这些所谓的价值观。 OpenAI之前的价值观中有一条是深思熟虑，现在看来，他们压根也没实现这一价值观。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://ts2.space/en/openai-updates-core-values-to-include-artificial-general-intelligence-agi/\">https://ts2.space/en/openai-updates-core-values-to-include-artificial-general-intelligence-agi/</a>\"</p><p><a href=\"https://futurism.com/the-byte/openai-core-values-agi\">https://futurism.com/the-byte/openai-core-values-agi</a>\"</p><p><a href=\"https://nymag.com/intelligencer/article/sam-altman-artificial-intelligence-openai-profile.html\">https://nymag.com/intelligencer/article/sam-altman-artificial-intelligence-openai-profile.html</a>\"</p>",
    "publish_time": "2023-10-16 13:41:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "大模型时代下的技术变革：训练、负载、部署、效率、安全……都遇到了新挑战？",
    "url": "https://www.infoq.cn/article/u3LfJYWerRKM6u2l4Ek2",
    "summary": "<p>随着互联网的快速发展，AI 大模型算的上是当前行业里最“炽手可热”的技术，大模型是 AI 领域的重要发展趋势。大模型需要大量的数据和计算资源，同时也需要强大的应用场景支持，对各行各业都有深远的影响，各厂商开始了“千模大战”。</p><p></p><p>当前，在 AI 大模型的研发和应用方面，产业界和学术界在很多方面都有深入的合作和探索。产业界和学术界都有各自的优势——产业界在数据采集、计算资源、应用需求理解等方面有独特的优势，学术界则在理论创新、方法研究、前沿技术探索等方面有显著的优势。</p><p></p><p>然而，在这个大模型时代，算力资源、数据质量和规模都对模型的性能有着至关重要的影响，包括数据安全也是当前亟需解决的问题。所以，在产业界和学术届深度融合探索下的 AI 大模型技术都有了哪些进展和变化？在这个过程中，是否释放出了新机遇？这两个问题的答案似乎在英特尔及其伙伴的实践中找到了。</p><p></p><p></p><h2>一、大模型的训练与负载：算力与成本之间需要寻找一个平衡</h2><p></p><p></p><p>随着人工智能和深度学习的发展，模型训练所需的数据量和处理能力在不断增加。多家研究报告显示，当前大型模型的训练数据量通常都达到了数百万甚至数千万级别。这些大型模型在进行训练时，需要处理的参数量相当庞大，例如 GPT-3 在训练时使用了 28.5 万 CPU 核心，总算力为 17.5 亿亿次，消耗了大约 250 万美元的 GPU 算力。大模型对大规模数据和计算资源的需求，对算力相关的硬件和软件都提出了更高要求。</p><p></p><p>为了提高模型的效果，往往需要采用更复杂的模型结构和训练策略，这也进一步增加了算力需求。同时，由于模型训练需要大量的时间和资源，训练时间也成了制约大模型发展的一个重要因素。对于一般企业而言，拥有如此强大的计算资源并不现实，因此企业都在积极寻找可以迭代优化模型训练和推理的基础设施。</p><p></p><p>然而算力与成本之间存在着明显的矛盾。首先，大模型训练需要大量的算力资源，而这些资源通常需要花费高昂的成本来获取。其次，数据传输和处理也会产生大量的成本，因为需要将大量数据从存储设备传输到计算设备进行处理。此外，硬件维护和软件开发也需要投入大量的人力物力。因此，在提高大模型训练效果的同时，厂商需要考虑如何平衡算力与成本之间的关系。</p><p></p><p>从整个模型的生态来看，其对于整个生态的部署要求肯定是“效率越来越高、成本越来越低”越好。英特尔院士、大数据技术全球 CTO 戴金权对此也表示：“从计算的角度来看，大模型需要很多的预训练，把模型预训练出一些比较好的基数。训练之后如何去用它、部署它，包括推理效率、微调效率，包括大模型其实是嵌入在一个端到端的一个工作流里面去后还能保持工作负载平衡。从这种计算角度来说，除预训练外，还需要做更多计算场景的策略和优化。”</p><p></p><p>戴金权的观点也显示出了英特尔的技术探索路径。为了保证负载平衡，英特尔提出了 Habana®Gaudi®2 的解决方案，其专注于深度学习的高性能解决方案，可满足大规模、高复杂性生成式 AI 和大型语言模型 (LLM) 训练工作负载的需求。</p><p></p><p>Gaudi2 采用经过验证的高性能深度学习 AI 训练处理器架构，利用 Habana 完全可编程的 TPC 和 GEMM 引擎，支持面向 AI 的高级数据类型，如 FP8、BF16、FP16、TF32 和 FP32 等，是一款性能更高的计算架构。值得一提的是，TPC 是一款 VLIW SIMD 矢量处理器，其指令集和邮件经过定制，不仅支持深度学习训练和推理工作负载，还可高效处理工作负载。</p><p></p><p>除了计算能力突出，Gaudi2 的内存带宽和容量也十分突出，其采用先进的 HBM 内存技术，内存容量高达 96GB，内存带宽高达 2.4TB/s。Gaudi 先进的 HBM 控制器已针对随机访问和线性访问进行了优化，在各种访问模式下均可提供高内存带宽。</p><p></p><p>Gaudi2 的能力其实就是帮助企业通过优化训练流程来降低成本——通过提高训练效率来减少训练时间，同时优化模型结构，减少参数量，从而降低算力和成本。除了这两种方式，企业其实还可以采用更加经济的算法和硬件资源来实现“算力与成本之间的平衡”，例如使用 GPU 代替 CPU 进行计算，目前很多硬件厂商也都在此方向上进行发力。</p><p></p><p>比如英特尔®Data Center GPU Max 系列则是专为应对最严苛的高性能计算 (HPC) 和 AI 工作负载而设计。英特尔&nbsp;®Xe Link 高速、一致的统一架构可灵活运行任何外形规格，实现纵向扩展和横向扩展。其利用“基于独立 SRAM 技术”的高达 408 MB 的 L2 高速缓存 (Rambo)、64 MB 的 L1 高速缓存，以及高达 128 GB 的高带宽内存，确保高容量和高带宽。同时还利用每个英特尔®&nbsp;Max 系列 GPU 上高达 128 个光线追踪单元，加速了科学可视化和动画过程；利用搭载深度脉动阵列的英特尔®&nbsp;Xe Matrix Extensions (XMX)，在单个设备上加速了 AI 工作负载，并启用矢量和矩阵功能，极好地帮助企业找到了算力与成本之间的平衡。</p><p></p><p></p><h2>二、大模型的部署：除了解决多场景，更重要的是提高效率</h2><p></p><p></p><p>戴金权对于“未来 AI 大模型技术创新及发展潜力”有许多值得行业从业者咂摸的观点：“大模型给了我们一个启示，大模型技术的前提不只是计算，而是训练本身，比如三阶段的训练，举个例子——很多大模型“诗写的好”，但是“写代码”不行，然后你就会发现它一般都会再发一个相应的“code 大模型”；而“什么都行”的大模型可能写代码就没有“code 大模型”写的好。其实本质上它是一个多任务或多目标的学习，所以是不是有办法来提升通用大模型的单项能力，这是一个很有意思的探索方向。但不管算力也好、成本也好、效率也好，怎么样利用是需要大家共同去探索的问题。比如大模型有很多不同的部署的场景，预训练、微调、推理、嵌入到工作流里去等等。如何通过硬件的 XPU 不同计算平台、软件上的各种技术能力来提高它的部署效率，这是另一个需要各厂商要去探索的问题。”</p><p></p><p>从戴金权的观点出发，并基于笔者对于行业的观察，我们基本上是可以总结出大模型当前的部署现状的：</p><p>模型部署难度较高：随着模型规模的不断扩大，需要消耗的计算资源、存储资源、网络资源等也越来越多，部署难度逐渐增大。对硬件资源需求大：大模型需要大量的 GPU 内存来进行计算，需要高性能的服务器来存储和传输数据，对硬件资源的需求非常大。需要支持并发处理：为了提高模型推理速度和效率，需要支持并发处理，这对服务器的并发处理能力提出了更高的要求。</p><p></p><p>从部署问题上，英特尔的合作伙伴腾讯云的解决方案就非常值得借鉴，在易用性方面，腾讯云训练集群的开启涉及复杂的系统设计，如 HCC 集群和分布式计算网络互通，并在实例设计时呈现给 AI 开发者一键部署功能，实现工程化效率提升；此外在供训练过程中，HCC 还具有高稳性能和故障自愈能力。从成本方面，腾讯云通过资源调度（如潮汐算力）实现集群效率最高。例如，在训练过程中，可能不会对加速芯片本身进行调度，而是将数据预处理或 DLC 业务与逻辑计算单元混部，以提高算力集群利用率。在部署效率方面，AI 开发者常遇到驱动版本不一致、兼容性等问题。腾讯云致力于在云原生环境中为大家提供更多一键部署和开发工具链，以缩短开发时间并提高效率。”</p><p></p><p>当然了，为了解决大模型的部署问题，<a href=\"https://www.infoq.cn/minibook/8XJWG3OkRtc7pBBTY172\">英特尔</a>\"确实没有少做努力。比如专为大模型时代发展而生的 Gaudi®&nbsp;2 在第一代基础上做了许多升级，第二代 Gaudi AI 深度学习夹层卡 HL-225B 专为数据中心实现大规模横向扩展而设计。其 AI 处理器基于第一代 Gaudi 的高效架构打造而成，目前采用 7 纳米制程工艺，在性能、可扩展性和能效方面均实现了飞跃，是一个“名副其实”的用于生成式 AI 和 LLM 训练的功能强大且经济高效的深度学习解决方案。</p><p></p><p>尤其值得说的是，在扩展性方面，Gaudi2 处理器具备出色的 2.1 Tbps 网络容量可扩展性，原生集成 21 个 100 Gbps RoCE v2 RDMA 端口，可通过直接路由实现 Guadi 处理器间通信。Gaudi2 处理器集成了专用媒体处理器，用于图像和视频解码及预处理。此外，Gaudi2 深度学习夹层卡还符合 OCP OAM 1.1（开放计算平台之开放加速器模块）等多种规范，可以为企业业务带来系统设计的灵活性。</p><p>在 2023 英特尔 On 技术创新峰会上，英特尔介绍的一台大型 AI 超级计算机，便是完全采用了英特尔至强处理器和 4000 个英特尔 Gaudi2 加速器打造的，据说它将跻身全球 TOP15 超算，目前热门 AIGC 应用 Stable Diffusion 的开发商 Stability AI 已经在全面使用它。同时英特尔首席执行官帕特·基辛格在本次峰会上还向大家透露了 Gaudi 3 的推出进程，“采用 5nm 制程的 Gaudi 3 将于明年推出，其算力是 Gaudi 2 的两倍，网络带宽、HBM 容量是 Gaudi 2 的 1.5 倍。”这意味着，大模型的部署效率问题可能在明年将实现一个飞跃式发展。</p><p></p><p>事实上，除了 Gaudi 2，为了更好地完成大模型的部署，英特尔®&nbsp;至强®&nbsp;可扩展处理器也一直在升级迭代，其无处不在的计算解决方案，配备英特尔®&nbsp;AMX 和其他集成式 AI 加速器，可在数据中心或边缘应用运行实时、中等吞吐量、低延迟的模型及应用。像阿里云通义千问大模型便是内置 AI 加速器的第四代英特尔至强可扩展处理器用于其生成式 AI 和大语言模型，英特尔技术大幅缩短了该模型的响应时间，平均加速可达 3 倍。</p><p></p><p>基辛格表示，第五代英特尔®&nbsp;至强®&nbsp;可扩展处理器未来将在同样功耗下，将有效提升数据中心的性能和存储速度，相比于第四代，该处理器在 AI 方面的性能将提升 2-3 倍。据悉，该处理器将于 12 月 14 日发布，非常值得大家密切关注。</p><p></p><p></p><h2>三、大模型的安全：将成为未来需要重点关注的问题</h2><p></p><p></p><p>今年 8 月底，首批通过备案的人工智能大模型名单出炉，这意味着这些生成式 AI 产品可以正式面向公众开放注册、提供服务。那在发布前后，大模型应用技术的开发速度或者供应商方面的技术演进上有何变化？对于该问题，戴金权表示——“如何更好地保护模型、保护数据、保护业务问题等安全问题变得越来越重要。”</p><p></p><p>所有技术在经历了爆火和高速发展的过程后，最终都会落到“安全”问题上，所以大模型也不例外。伴随着 AI 大模型的复杂性和应用范围将进一步扩大，其安全隐患将越来越多。例如，随着量子计算等新技术的出现，AI 大模型将面临更高级别的安全威胁。同时，随着数据隐私保护等法律法规的出台，企业当前越来越重视 AI 大模型的数据隐私保护工作。因此，未来需要加强技术研发，完善 AI 大模型的安全保障机制。</p><p></p><p>当前 AI 大模型安全现状并不乐观，技术漏洞是当前 AI 大模型面临的主要安全问题之一。例如，模型被黑客攻击、恶意注入病毒等问题时有发生。代码实现不当也可能导致 AI 大模型出现安全问题，比如有些模型在实现过程中可能存在未经验证的功能或逻辑漏洞，给恶意攻击者留下可乘之机。</p><p></p><p>我们溯源一下问题根本，数据质量差是影响 AI 大模型安全的重要因素之一。例如，如果数据本身存在大量噪声或缺失，将直接影响模型的训练效果和安全性。为了保护、清洗这些数据，<a href=\"https://www.infoq.cn/article/X50dOoVNWEIlhSvvCpiE\">英特尔</a>\"在机密计算领域投入大量研发资源，在 2015 年推出了英特尔®&nbsp;SGX，其是一种安全相关的指令，被内置于一些现代 Intel 中央处理器（CPU）中，它可以在基于硬件的可信执行环境中执行计算，确保任务和数据的安全性，防止被恶意程序窃取。在管理敏感数据和受监管数据方面，机密计算技术可以提高相关组织的安全级别。</p><p></p><p>此外，英特尔®&nbsp;TDX 是另一项前沿安全技术，其在虚拟机层面支持机密计算，满足虚拟机安全需求。所以英特尔的“机密计算”也被戴金权称为是一个“端到端”的能力，“大模型安全并不是只需要在一个环节安全，整个流程都需要安全，而英特尔的机密计算从数据存储、加密、整个分布式计算、网络通讯，包括远程验证等都完成了实现了安全保护。”目前英特尔作为“机密计算联盟（Confidential Computing Consortium）”成员之一，正在持续积极推动机密计算技术的标准化和普及。</p><p></p><p></p><h2>四、写在最后：AI 大模型对基础设施、硬件提出了更高要求</h2><p></p><p></p><p>随着大模型技术逐渐进入深水期，各企业在相关技术方面的验证逐渐全面，大家都已经非常明确，如果想要充分释放 AI 大模型的潜力，仅依靠软件层面的优化是不够的，基础设施硬件设备的性能和稳定性也在 AI 大模型的高效运行中扮演着至关重要的角色。</p><p></p><p>当前大模型对基础设施的要求非常高。就单从硬件方面来看，大模型需要大量的高性能计算资源，包括 CPU、GPU 和 TPU 等。这些计算资源需要具备高并发、低延迟的特点，以满足 AI 大模型的计算需求。同时，为了提高计算效率，需要采用先进的芯片设计和制造技术，加强芯片间的通信和协作。</p><p></p><p>为了满足大模型对硬件性能的高要求，硬件厂商需要不断提升自身的研发实力和技术积累。这包括对先进制程技术的掌握，以及对各种处理器架构的深入理解。此外，硬件厂商还需要与软件厂商紧密合作，共同优化大模型的性能。通过软硬件的协同创新，可以充分发挥硬件设备的性能潜力，为大模型的发展提供强大的支持，无论是从算力、效率、成本还是安全等各个方面。</p><p></p><p>于此，大模型对硬件厂商的技术能力也提出了更高的要求。这意味着硬件厂商需要具备跨学科的能力，以整合不同领域的技术资源，为企业提供更加完善的解决方案，以满足不同行业和应用场景的需求。</p><p></p><p>不仅是硬件厂商，大模型技术的发展离不开产业链上的每一个角色，众人拾柴才能火焰高，大模型时代需要学术界和产业界进行深入地合作和联动。通过联动，学术界的研究成果可以更快地应用于产业界，推动技术的发展和进步，同时产业界的需求和反馈也可以引导学术界的研究方向，使其更加贴近实际应用场景。在当前这个大模型时代的背景下，合作和联动可以促进不同组织之间的协作，实现资源的共享和整合，提高研究的效率和成果的质量。</p><p></p><p>正如戴金权所说的那样，“<a href=\"https://www.infoq.cn/article/cff5Oa9fYLNtU46us0ez\">英特尔</a>\"一直坚持开源开放，无论是从客户侧的产业界合作，还是从学术界的高校合作，英特尔都在持续推动，相信在多方的努力下，大模型技术的发展将会越来越好。”</p>",
    "publish_time": "2023-10-16 14:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "主力开发已经68岁了！“老龄化”严重的Postgres开源社区呼唤“年轻一代”",
    "url": "https://www.infoq.cn/article/mlKaRhlz0jVCJMyCKRZP",
    "summary": "<p>开源已成为这个社会的根基。从上世纪80 年代Richard Stallman 发起的自由软件运动，到Linux、GitHub以及互联网的崛起，开源的发展也已经经历了不止一代人。</p><p>&nbsp;</p><p>近日，分析机构RedMonk发表了一篇文章，指出Postgre核心开发社区正在逐渐老龄化，其平均年龄可能在 50 岁左右，主力开发已经68岁。这些老牌开源社区，希望唤起年轻人对开源的重视。InfoQ也就“项目维护者老化与项目可持续性之间的关系”、“开源项目如何招募更多年轻开源爱好者”等问题采访了开源社区的资深专家，希望给大家带来启示。</p><p>&nbsp;</p><p></p><h2>Postgres开源社区的“老龄化”问题</h2><p></p><p>&nbsp;</p><p>PostgreSQL 是一个功能强大的开源关系型数据库系统，其起源可以追溯到1986 年，作为加州大学伯克利分校Postgres项目的一部分，经过几十年的发展，在当前数据库领域发挥着举足轻重的作用。</p><p>&nbsp;</p><p>最近，Postgres 提交者兼 EnterpriseDB 首席数据库科学家 Robert Haas 统计了该项目的贡献者情况，发现了该社区面临的一个比较严重的问题，即核心开发社区正在逐渐老龄化，其平均年龄可能在 50 岁左右。比如现年 68 岁Tom Lane 仍然是 Postgres 项目的支柱。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/06/060652f09725de337322d7715021754f.jpeg\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>Hacker News上<a href=\"https://news.ycombinator.com/item?id=37832319\">也有网友指出</a>\"，Postgres已经好几年没有新的committer了。因此，Postgres开源项目的可持续性的确令人担忧：“我们假设 Postgres 在 20 年内仍然强劲，那么20年后谁会从事这项工作？”</p><p>&nbsp;</p><p>“Postgres 引擎的不断发展非常重要。”致力于Serverless Postgres的Neon公司首席执行官 Nikita Shamgunov指出，“Postgres committer人群年龄都在 50、60 岁左右，也许还有一些 30 多岁的。我们希望能够雇用更多初级人员，培训他们成为committer并希望最终成为维护者。成为committer需要付出很大的努力，但成为contributor则没那么难——你只需要编写好的代码即可。”但作为一家商业公司，他又对花钱雇佣初级人员这事儿有点犹豫，“目前尚不清楚这种花钱的方式是不是最好的。”</p><p>&nbsp;</p><p>分析机构RedMonk认为，队列老化不是 Postgres 独有的问题，但Postgres “在任何意义上”都没有做到努力去吸引新用户。“让年轻开发人员进入大型机领域 IBM 在这方面就做得非常出色，例如他们发起的大学职业教育项目。”</p><p>&nbsp;</p><p>无独有偶，Linux 缔造者 Linus Torvalds 也曾在几年前表述过类似的问题。</p><p>&nbsp;</p><p>2020年，Linus 在一次会议连线中谈到了为开源操作系统寻找未来维护者时的问题：Linux社区项目管理者是 Torvalds 这批五零后、六零后，但社区终归要考虑代际变更的问题，在目前这一代维护者逐渐老去之后，Linux 项目该怎么发展？</p><p>&nbsp;</p><p>Linus Torvalds 当时表示，跟那些 30 岁上下的年轻人相比，他们确实是越来越老了。而且“事实证明，维护者真的不好找。我们的维护者确实不够。”而Linux社区的其他核心贡献者也非常担心自己变老精力变差，但年轻一代没有像当初贡献者们那样充满热情，导致“人才匮乏已经成为 Linux 实现进一步增长的最大障碍。”</p><p>&nbsp;</p><p></p><h2>如何改变“老龄化”现状？</h2><p></p><p>&nbsp;</p><p>从某种程度上来说， Postgres 和 Linux 都希望新生代程序员能够加入到项目维护中，来改变社区“老龄化”问题。</p><p>&nbsp;</p><p>那么项目维护者老化会影响项目可持续性吗？如果年轻人较少会有什么影响？开源项目如何招募更多年轻开源爱好者？我们采访了开源社区的一些资深专家。</p><p>&nbsp;</p><p>只要项目维护者精力还足够，年龄变大其实也不是很大的问题。国外有不少50、60岁还活跃在一起的程序员，战斗力其实也不差。如果确实已经年龄很大了，对项目的长期发展肯定还是有影响的，“需要尽早做打算”，Apache 软件基金会 Member、Apache HBase PMC 主席张铎指出。</p><p>&nbsp;</p><p>但 Postgres 和 Linux 可能还不同于全部开源社区的整体情况，这两个社区属于“老牌”开源社区。</p><p>&nbsp;</p><p>天工开物开源基金会、执行副秘书长庄表伟认为“整个开源社区在经过早期的飞速发展期之后，应该进入稳定期，年龄分布应该趋近于整个社会的工作人群的正常年龄分布（甚至还应该再年轻一些）。而老牌的开源项目，除非能够经过高妙的运营手段，焕发新的生机，再加上老项目的技术能够保持先进性，否则对于年轻人的吸引力，就是会出现‘自然下降’的现象。”</p><p>&nbsp;</p><p>因此，庄表伟认为开源社区的老龄化，可能是一个伪命题：“老牌开源项目的老龄化，虽然的确是一个现实问题，但是真正应该关注的是：老牌开源项目（技术），在日新月异的开源技术发展浪潮中，如何保持先进性的问题。”</p><p>&nbsp;</p><p>项目维护者退休的确会影响项目的可持续发展，但很多开源项目背后也有多个商业公司开发新分支。对于如何吸引年轻人，并要保持项目的持续健康发展，Apache RocketMQ 作者王小瑞认为，商业公司的支持也能发挥重要作用，“只有在开源项目上投入的资源足够多，产生的商业价值足够大，自然就会有更多的年轻人参与。因为不但会为年轻人带来荣誉，甚至会成为年轻人一生的事业，让他们将贡献开源作为业余爱好变为主要职业。（这样原创社区作为最大投入方，吸引了最多的爱好者，创造了最大的商业价值，就能避免商业公司开发新分支，导致生态分裂等问题，也能在项目维护者退休后有更多年轻人接棒，形成正循环。）”</p><p>&nbsp;</p><p>Apache软件基金会董事姜宁，以及张铎两位老师则提出了一个有实施前例的方案：“需要项目创始人适当的退出一下，围绕着项目构建起健康的社区，这样能保证项目的可持续发展。”</p><p>&nbsp;</p><p>通常来说，只要项目还有足够的使用场景，总是会有新开发者进入的。这中间的关键点就在于原来的核心维护者需要花心思培育一个活跃的社区，并且逐步后退，把更多的责任交给社区里的其他人。这样后续项目发展的问题就变成了一个社区维护的问题，只要社区能一直维护好，原核心开发者是否退出影响就没有那么大了。</p><p>&nbsp;</p><p>这个典型的例子就是 Apache NuttX 项目。</p><p>&nbsp;</p><p>Nuttx是一个基于实时操作系统 (RTOS) 的开源项目，旨在提供一个可嵌入、可移植、可扩展和可靠的操作系统解决方案。其创始人 Gregory Nutt （<a href=\"http://www.scguild.com/Resume/7465R.html\">http://www.scguild.com/Resume/7465R.html</a>\"&nbsp; ）在2007年正式对外开源了Nuttx项目。在这之后的很长时间里，基本都是由Gregory Nutt 一个人在维护。</p><p>&nbsp;</p><p>到了2019年左右，Gregory Nutt 已经 69 岁了，也到了“该考虑未来的时候了”。因为项目本身的特色，小米选择了这个项目作为 IoT 操作系统的基座。所以这一年，Gregory Nutt和小米就项目的未来进行了讨论，在成立新的基金会挂靠，以及选择加入现有的几个基金会（Apache，SPI）之间进行比较之后，最终选择加入 Apache 进行孵化。该项目于2023年毕业，成为了顶级项目。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/84/84bb248f36a833414fa63698fa960aaa.jpeg\" /></p><p></p><p>&nbsp;</p><p>现在，Gregory Nutt 已经不是项目里最活跃的贡献者了，甚至代码写的也不多了。但当前项目依然非常活跃，贡献者高达400多人，每个月都有近百个开发者贡献代码。目前基本可以确定，NuttX 项目可以在脱离 Greg 完全控制之后也能发展的很好。</p><p>&nbsp;</p><p>吸引年轻人，项目本身也可以做出一些改变，张铎提到了一些其他办法：例如发掘一些新的技术方向，引入一些新的技术，比如 Linux 的 eBPF 现在就非常火，和云原生结合，就可以吸引到大量新的开发者，以及在 linux kernel 中引入 Rust，也是一个吸引更年轻开发者的办法。</p><p>&nbsp;</p><p>他同时认为开源项目其实也不必拘泥于一定要年轻人，只要不停的有新鲜血液进来就可以。年轻人总是会追热点的，并且老的技术方向，市场容量本身也有限。一个操作系统项目，在对年轻人吸引力显然无法和一个 AI 项目相提并论。“所以还是要放下执念，不同生命周期的项目维护者的年龄分布肯定是不一样的，不要强求。”</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://redmonk.com/jgovernor/2023/10/10/postgres-the-next-generation-investing-in-the-next-generation-of-committers/\">https://redmonk.com/jgovernor/2023/10/10/postgres-the-next-generation-investing-in-the-next-generation-of-committers/</a>\"</p><p><a href=\"https://www.infoq.cn/article/NfU1d3oCcfpgXc06NXlg\">https://www.infoq.cn/article/NfU1d3oCcfpgXc06NXlg</a>\"</p><p><a href=\"https://en.wikipedia.org/wiki/NuttX\">https://en.wikipedia.org/wiki/NuttX</a>\"</p><p><a href=\"https://github.com/apache/nuttx/graphs/contributorshttps://incubator.apache.org/projects/nuttx.html\">https://github.com/apache/nuttx/graphs/contributors</a>\"</p><p><a href=\"https://github.com/apache/nuttx/graphs/contributorshttps://incubator.apache.org/projects/nuttx.html\">https://incubator.apache.org/projects/nuttx.html</a>\"</p><p><a href=\"https://news.apache.org/foundation/entry/the-apache-software-foundation-announces-apache-nuttx-as-a-top-level-project\">https://news.apache.org/foundation/entry/the-apache-software-foundation-announces-apache-nuttx-as-a-top-level-project</a>\"</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-10-16 14:12:04",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "无服务计算，厂商究竟在打什么算盘",
    "url": "https://www.infoq.cn/article/rx9fs5NxvNq1ixeMssbP",
    "summary": "<p></p><p></p><p>一说到无服务计算（Serverless computing），很多人脑海中马上浮现出几个熟悉且令人兴奋的词汇：“瞬间启动”、“弹性扩缩容”和“按量计费”等等。如今，随着公有云的普及，几乎每过一段时间我们都会听到有新的无服务计算产品问世。同时，许多知名的云服务产品，如 AWS Aurora、AWS Redshift、Databricks 等，都陆续推出了它们的无服务版本。一时间，无服务计算迅速成为了行业内的焦点，无论是创业公司还是大型厂商，都在探索推出无服务产品的可能性，甚至在近期备受瞩目的大模型领域，也涌现出了许多关于无服务机器学习平台的讨论。</p><p></p><p>无疑，无服务计算的理念极具魅力。它所推崇的特性精准的抓住了用户的痛点。毕竟，几乎没有哪家公司愿意花费过多精力来管理运维，也没有哪家公司希望为基础服务支付过高的费用。当然，仅仅有个好的理念还不够。对于任何一个产品来说，是否能真正得到广泛的采纳和实施，最终还是取决于它是否能满足买家与卖家双方的利益需求。</p><p></p><p>在本文，我将从商业和技术的角度来深入探讨无服务技术，希望给大家带来更全面的认识。</p><p></p><p></p><h2>市面上的软件服务</h2><p></p><p></p><p>尽管云计算这一概念已经深入人心，但并不是所有公司都愿意拥抱云服务。由于各种各样的原因，不同公司对使用云服务都有自己的看法，并且有不少公司因为监管、风控等要求，根本就无法接入云平台，更不用说使用云服务。在具体谈论无服务计算之前，我们先聊聊市面上的软件服务种类。</p><p></p><p>我们先从私有化部署模式开始讲起。私有化部署即指客户将软件服务直接部署在自己的服务器或数据中心上。在这种部署方式中，企业对自己的数据以及软件服务拥有 100% 的完全控制权。这为企业提供了高度的数据安全性保证。当然，自己可以掌控数据安全，也就意味着自己同样也需要对自己的安全负责。私有化部署模式的缺陷也很明显，即部署与运维成本相当高。企业不但需要购买大量的服务器，而且还要琢磨如何在自己的服务器上安装想要的软件。一旦出现故障或需要升级，企业可能需要与供应商进行频繁的沟通，甚至可能需要供应商的现场支持。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5e/5e763d74c7eebf44918ac33638904a5f.png\" /></p><p></p><p>在全托管模式中，数据面板与控制面板均在公网中；在 BYOC 模式中，数据面板在用户的云网络环境下，而控制面板在公网中。</p><p></p><p>云的出现便是为了解决私有化部署的痛点。在云上，大家默认使用的模式便是云上全托管模式，或者被称为公有 SaaS。云上全托管意味着客户使用供应商在公有云上提供的软件服务。在这种情况中，企业所使用的软件以及自己的数据都会被放在云端。这种模式将企业对软件运维的压力几乎降为 0，但这也意味着企业可能面临一系列安全和隐私问题。毕竟，由于软件厂商对软件具有管理的权利，从理论来说（尽管实际上几乎不可能发生）厂商可以访问到用户的数据，万一出现数据泄漏等情况，后果不堪设想。</p><p></p><p>为了解决企业对全托管模式在安全方面的顾虑，不少厂商开始推出私有 SaaS，也就是 BYOC，即 Bring Your Own Cloud 模式。从字面意思来看，可能有些难以理解。但简单来说，大家可以将其想像成让企业在云时代实现私有部署的方式。BYOC 模式要求客户企业已经拥有某个云服务提供商（比如 AWS、GCP 等）的账户，而软件系统厂商会将软件部署在客户企业的云账户下。这样一来， 数据的所有权完全由企业所掌握，而厂商仅拥有客户系统的管控平台的访问。这样一来，厂商访问数据的权限被限制到最小，从而大幅降低了数据泄漏的风险。当然，BYOC 模式对于厂商来说在运维方面提出了不少要求。在这里我们就不展开讨论。</p><p></p><p>最后一种模式便是我们今天要着重讨论的话题，即 Se****rverless，或称无服务。无服务可以被认为是全托管模式的进一步延伸。在这种模式下，所有的服务都由供应商在云上部署，而客户仅仅是使用这些服务，无需关心后台的运维工作。也就是说，用户不再需要考虑自己使用了多少计算资源与存储资源，只需要为自己所使用的服务付费。</p><p></p><p>使用数据库系统打个比方。对于全托管模式下的云数据库服务来说，用户需要知道自己的云数据库实际占用了几台机器、有多少个 CPU、使用了多少 memory。而对于 Serverless 的云数据库来说，用户不再需要知道这些资源，只需要直接使用即可，在使用之后，云数据库厂商会按照所消耗掉的资源量来收费。</p><p></p><p>Serverless 模式最大的好处就是带来极大的便利性，同时可能可以为用户节省大量成本。与此同时，Serverless 让用户更少的关心底层细节，理论上可以做到自动根据负载量进行弹性扩缩容。然而，Serverless 根据实现方式不同，可能会带来潜在性能与安全性的风险，而这需要用户在使用前进行更加谨慎的评估。我们在下一段详细阐述。</p><p></p><p>有一些厂商尽管核心服务并不卖 Serverless，但是允许用户的部分负载 Serverless 化。有两个比较经典的例子。数据库厂商 Databricks 只出售 BYOC 模式的服务，但是其仍然允许用户使用 Serverless 服务来对部分查询进行加速。这一模式在 AWS Redshift 中也被使用。Redshift 尽管是全托管模式，但是用户如果希望针对某条查询进行加速，那么便可以使用 concurrency scaling 方式，从共享资源池中获取资源，瞬时对复杂查询进行弹性计算。</p><p></p><p></p><h2>Serverless 实现思路</h2><p></p><p></p><p>对于用户来说，Serverless 是一层非常高层的抽象：只要让用户不感知到底层部署模式与运行方式，从用户角度看，那就是 Serverless。Serverless 有各种实现思路，而各种思路会影响性能、安全性、成本等多个方面。最主流的实现方式有两种：容器模式与多租户模式。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b3/b328f0f19ae24758d225ffb48cb8bc4e.png\" /></p><p></p><p>在基于容器模式的 Serverless 实现中，每个用户实际获得独立的由容器隔离的集群，而用户并不需要知道集群配置细节；在基于多租户模式的 Serverless 实现中，多个用户共享一个超大集群，而资源隔离由系统来执行。</p><p></p><p>Serverless 最简单的实现思路是直接利用云上的 Kubernetes 对容器进行编排，并在容器层来进行资源隔离处理。这种实现方式实际上与传统的全托管方式无异，只不过是从用户角度来讲，用户不再需要知道底层细节。这种 Serverless 实现方式尽管不需要考虑如何进行底层资源隔离，但对产品的封装与自动运维提出了非常高的要求。由于用户不再需要对资源进行管控，Serverless 服务提供商需要根据用户的负载来动态进行资源分配。如果能够真正做到按需分配资源，则可以为用户节省大量成本。然而，系统动态扩缩容本身在实现上就有不少挑战，而按照运行时情况进行资源调度更是难上加难。如果实现不够理想，那么不仅会造成资源浪费，甚至有可能由于资源匮乏而造成服务宕机。</p><p></p><p>多租户模式是另一种实现 Serverless 的经典思路。我们所熟知的一些 OLTP 数据库厂商所提供的 Serverless 服务都是选择了这种架构。这样的架构要求数据库本身来做资源隔离，也就是直接在数据库系统层面来做多租户之间的资源隔离。在提供服务时，可以认为厂商直接开了一个巨大的实例，不同用户都在同一实例中分享资源。这种实现方式对系统内核的资源管控与隔离提出了极高的要求，但其可以做到资源的高效利用。毕竟，相比于基于容器的实现来说，多租户模式让不同用户共享同一份资源，而不是为每个用户分别管控资源。理论来说，多租户模式是资源利用率最高的实现方式。</p><p></p><p></p><h2>客户的诉求</h2><p></p><p></p><p>当考虑到用户在选购软件系统时的逻辑，一切从他们的需求和预期出发。</p><p></p><p>对于只能接受私有化部署的用户来说，当与软件厂商签署合同之后，真正的工作才刚刚开始。客户可能需要组建专门的技术团队来部署和管理这个系统，确保它能够在自己的内部网络中顺利运行。如果你对早期 IBM 与 Oracle 的服务有所了解，应该会知道客户需要为软件配置专业人员。而对于软件厂商，每个客户的环境都是独特的，因此需要提供高度的定制化服务。这无疑增加了双方的工作量和成本。</p><p></p><p>而转向云服务后，整个过程变得更加简洁。云提供了无以伦比的便利性与弹性，消除了客户对自己购买硬件与维护硬件的烦恼，允许他们根据实际需求灵活地调整服务规模。而为了能够取得如此的便利性弹性，云服务厂商所做出的最大突破便是将一切服务标准化，并让用户建立信任并接受标准化。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/18/18564ceef8b0997782c97a6e3f812495.png\" /></p><p></p><p>如果我们把私有化部署、BYOC 模式、全托管模式、Serverless 模式这四种模式全部罗列出来，就会发现用户在做选择时，实际上是在便利性、弹性、性能、安全性与价格这五个方面在做权衡。</p><p></p><p>从便利性角度来讲，私有化部署极其不方便，用户需要在购买并配置硬件的基础上再购买与配置软件；BYOC 模式便利性中等，因为用户需要维护自己的云账户，做一些轻量级运维；全托管模式便利性高，用户只需选择购买服务的规格即可；Serverless 模式便利性极高，因为用户甚至无需选择规格，做到完全按量付费。从弹性来讲，私有化部署几乎不具备弹性，用户一般需要购买特定的机器来安装相应软件；BYOC 与全托管模式都可以在云上做到弹性，但在 BYOC 中，由于数据面板在用户侧，在做弹性扩缩容时会需要在用户账号中动态申请或释放资源，从技术与政策角度可能会有一定限制；而全托管模式与 Serverless 模式在弹性这一块几乎没有任何限制，可以做到极高弹性。从性能角度来讲，基于多租户的 Serverless 模式要求不同用户同时分享存储与计算资源。共享资源可能造成性能互相影响，因此性能相比于独占模式来说可能处于劣势。而在其他实现方式中，每个用户都拥有自己独立的计算存储资源，能够得到高性能保障。从安全性来讲，私有化部署模式没有太多安全风险；BYOC 模式由于数据存放在用户侧，因此安全性也相当高；全托管模式与基于容器的 Serverless 模式很显然存在一定的安全性风险；而基于多租户的 Serverless 则具有相对更高的安全性风险，这是因为其数据访问并非在物理上进行隔离。从价格来讲，私有化部署成本相当之高，因为用户不仅需要投入资金购买硬件与软件，同时需要配备相应的运维团队；BYOC 与全托管模式从厂商角度来讲，定价模式一般保持一致，因此价格也相差无几；Serverless 模式由于可以根据用户负载自动调节资源使用，并且可以共享资源，因此做到了价格的大幅降低。</p><p></p><p>从这五个方面考虑，我们应该不难得出一个推断：小型公司可能更倾向于牺牲某些性能和安全性来降低成本并获得便利性与弹性，而大型企业，考虑到它们庞大的用户基础和数据资产，会优先保障性能和安全性。</p><p></p><p></p><h2>厂商的算盘</h2><p></p><p></p><p>对于软件服务提供商，核心目标始终是盈利。从商业角度看，无论提供哪种服务，厂商最终的目的都是希望将利润最大化。当我们审视上面一章节的表单时，我们应该不难发现，如果希望从 Serverless 服务中赚到钱，那么所提供的服务必须具有广泛的吸引力和市场需求。当然，这不仅仅是因为 Serverless 服务的客单价可能低于（或者远低于）其他种类的服务，也是因为从厂商角度来说，提供 Serverless 服务要比传统的全托管或 BYOC 模式所支付的基础成本更高。</p><p></p><p>我们可以想象一下，Serverless 的核心卖点之一便是弹性。为了确保用户可以随时获得所需的资源，并享受到瞬时启动的体验，厂商一般都需要维护一定数量的预备资源，这通常称为\"热池\"或\"warm pool\"。维护预备资源的成本得有厂商自己买单。相比之下，如果只是售卖全托管服务或者使用 BYOC 模式，那么基础资源的费用都是由用户承担的，厂商所赚到的钱即为基础费用之上的软件服务费用。</p><p></p><p>当然，如果 Serverless 服务拥有大量用户，那么相比于传统云服务来说，软件厂商会发现有更多的盈利机会。他们可以通过各种方式提高收益，例如资源共享、元数据节点共享或超售策略。超售策略基于的是一个简单的事实，即尽管用户可能预留了大量资源，但在实际使用中，总有一部分用户不会充分利用他们的配额。这为软件厂商提供了一个卖出更多资源的机会。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a8/a87658565eb0fba8ba3ded52c8a2caf6.png\" /></p><p></p><p>Serverless 与传统托管模式在商业模式方面的不同。</p><p></p><p>上图表述了 Serverless 与传统托管服务在商业模式方面的不同。在传统托管模式下，厂商的成本与营收比例相对比较固定，且随着客户数的增长而线性增长。而对于 Serverless 来说，当在客户数不多的情况下，厂商基本都是在做着亏本的生意，只有在客户数达到一定规模之后，营收才可能高于成本。但与传统托管服务很不一样的点是，当厂商的利润率可能会随着客户数的提升而显著提升，出现超线性增长。这也许就是为什么 Serverless 的故事在创投圈里非常吃香的原因。</p><p></p><p>但我们应该可以很容易想象到，并非所有软件都适合做成 Serverless 服务。从市场接受角度来说，只有那些已经被广泛接受的技术才有可能从 Serverless 中真正获得利润。同时，由于 Serverless 用户量大，出线上故障的几率一定也是更大。因此，一般来说 Serverless 服务适合商业化那些历史悠久且更加成熟的系统，如 MySQL、PostgreSQL 等，从而大大降低系统的故障率。</p><p></p><p></p><h2>案例分析：如何将流处理系统Serverless 化</h2><p></p><p></p><p>由于本人一直在从事流处理方面的开发与商业化工作，因此时常会考虑如何将如 RisingWave 这样的流处理数据库做成云服务提供给用户。而由于流处理数据库相对于传统数据库来说较为独特，很适合作为案例来讨论如何进行 Serverless 化。</p><p></p><p>我们先从用户角度考虑。上文提到，用户经常会从便利性、弹性、性能、安全性、和价格这五个方面考虑所需要的服务模式。从便利性、安全性与价格这三个角度来看，流数据库并没有什么过多特别之处。而从弹性与性能这两个角度来看，流数据库的差异化便体现出来。流数据库的核心概念是物化视图，而其表示的是对数据流进行的连续不断的增量计算。而数据流可能会随时间而有较大幅度的变化，因此弹性至关重要。而由于其进行的是连续不断的计算，且用户可能对计算结果的新鲜度非常敏感，因此需要系统持续保持高性能。从本文前面的表格中我们可以看到，基于多租户的 Serverless 模式由于会共享资源，导致性能干扰，因此可能并不适合流处理。因此，想要将流处理系统进行 Serverless 化，更可靠的方式应该是采用容器进行实现。而也如上文提到的，基于容器的 Serverless 实现方式需要通过用户负载来进行动态资源调度，要高效利用资源并不容易。从用户基数来讲，不得不说流处理技术还远没有到达像 PostgreSQL 与 MySQL 这样的普及程度，因此想要获得超线性增长并不容易。</p><p></p><p>总的来说，从用户与厂商双方面的诉求来分析，我们不难得出一个结论：流处理系统厂商暂时比较难通过 Serverless 来获得最大收益。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/18/18c4a7b24a12dc48e28d7ead8a3c8336.png\" /></p><p></p><p>当然，这种局面可能会随着时间的改变而改变。在流处理领域，基于 Apache Flink 的商业化公司 Decodable 便提供了基于容器的 Serverless 服务。与流处理系统紧密相关的消息流队列系统背后的商业化公司，如 Redpanda、StreamNative (Apache Pulsar) 等，都在考量提供 Serverless 服务的可能性。其中，Redpanda 的 Serverless 服务即将上线，而 StreamNative 所商业化的 Apache Pulsar 从内核上便支持多租户能力，想必提供 Serverless 模式只是时间问题。</p><p></p><p></p><h2>总&nbsp; &nbsp; 结</h2><p></p><p></p><p>近几年，云上 Serverless 服务这一理念逐渐崭露头角，吸引了大量开发者和企业的目光。它所带来的众多优点，如弹性伸缩、成本效益和运维简化，使得越来越多的项目考虑采纳这一模式。然而，每一种技术都有其适用的场景，Serverless 并非例外。它不一定适合所有的软件系统和业务需求。在决策过程中，企业和开发者需要明确其局限性。总体来说，厂商是否应该开发 Serverless 产品，以及用户是否应该购买 Serverless 产品，都应该经过对自身情况与市场的整体分析之后再做出决定。</p><p></p><p>作者简介：</p><p>&nbsp;</p><p>吴英骏，流数据库公司 RisingWave（risingwave.dev） 创始人 &amp;CEO。博士毕业于新加坡国立大学计算机系，为前 Amazon Redshift 工程师和前 IBM Research Almaden 研究员。常年担任数据库三大顶会 SIGMOD/VLDB/ICDE 的评审委员会成员。技术交流可以扫码关注如下公众号“RisingWave 中文开源社区”或者添加微信“risingwave_assistant”。</p><p><img src=\"https://static001.infoq.cn/resource/image/9y/ee/9yyb88913b9a7e95d8e892ca358e14ee.jpg\" /></p><p>RisingWave 中文开源社区公众号</p><p><img src=\"https://static001.infoq.cn/resource/image/d7/ed/d7277de614e35b50537bfaef3317a8ed.jpeg\" /></p><p>RisingWave 中文开源社区技术交流群</p><p></p><p>今日好文推荐</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651183474&amp;idx=1&amp;sn=bf1ac9f9a237e0e286b3a38d42a696e1&amp;chksm=bdb821218acfa837bac8a8e10ee8ad12a7ae66f5c1e68ede96d3b28b16cca08931ee2b676892&amp;scene=21#wechat_redirect\"></a>\"<a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651183581&amp;idx=1&amp;sn=bd6e465b6f44f9b0d075da6ec77c8e08&amp;chksm=bdb8218e8acfa898f3c16510fa57af2c6c15752f92e30be1c43c2b115ccd01c8263b64f4dc09&amp;scene=21#wechat_redirect\">放弃 React 改用 Web 组件，微软这次重构让开发者不解：没有任何意义</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651183474&amp;idx=1&amp;sn=bf1ac9f9a237e0e286b3a38d42a696e1&amp;chksm=bdb821218acfa837bac8a8e10ee8ad12a7ae66f5c1e68ede96d3b28b16cca08931ee2b676892&amp;scene=21#wechat_redirect\">AutoGPT 宣布不再使用向量数据库！向量数据库是小题大作的方案？</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651183187&amp;idx=1&amp;sn=d0233c44a7caf29be43f88f74889e01d&amp;chksm=bdb820008acfa91607880cf8e9284ff32a1863b3a6405ea60699e820f356baffb9e130711797&amp;scene=21#wechat_redirect\">下一代 Docker 来了！1小时构建缩至1.5分钟，还能结合 LangChain、Ollama 等做 AI 应用开发</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651183105&amp;idx=1&amp;sn=5cab30f7529ef0d4a6fd9f76cf23533d&amp;chksm=bdb820528acfa944ebcc10ac2de14112c4d2f6510f4b837f8b1f42f7786b5d1a305f7828cdbd&amp;scene=21#wechat_redirect\">苹果中国App Store将不允许未备案应用上架；iPhone 15发热严重，问题源于第三方软件？Meta又要裁员了 | Q资讯</a>\"</p><p></p><p></p>",
    "publish_time": "2023-10-16 14:24:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "人瑞人才数字化实践：年均投入近2000万，拒绝业务当甩手掌柜",
    "url": "https://www.infoq.cn/article/u7lLw2rLqF6tLIiYZXcL",
    "summary": "<p>企业的人力资源管理需求正在发生变化。</p><p></p><p>首先，大环境背景下企业普遍面临着降本增效需求，其中人工是企业成本重心，仅靠减员这种简单粗暴的方式并不能解决根本问题；其次，外部市场快速变化要求企业业务快速响应，从管理层面来看，企业需要针对人员采取动态管理机制；其三，如今企业用工模式愈加灵活多样，根据项目配置相关人员的模式越来越普遍。</p><p></p><p>“对于<a href=\"https://www.infoq.cn/article/34WS9TXHFTKLjO0Vr5qk\">人瑞人才</a>\"这样的人力资源公司来说，如何快速地把合适的人才转化到企业项目中，实现人才动态管理，帮助企业适应业务快速变化，同时降低用工成本，这是巨大的挑战。”人瑞人才执行董事、主席兼行政总裁张建国在日前接受 InfoQ 等媒体采访时表示。</p><p></p><p>同时他也自信地表示，“人瑞人才在满足企业客户以上需求方面做得还不错”。基于多年的人力资源管理服务经验，加上近年来在数字化技术方面的投入，人瑞人才的人效和服务能力提升，以及成本降低等方面均取得了可见的成果。</p><p></p><p>“比如，在人均产能方面，行业平均每月招聘 3 人左右，但我们能达到 5-6 人；再比如，在成本方面，基于线上化的人员管理，人瑞人才的人员外包服务价格相比其它公司降低了 30% 左右。”换言之，人瑞人才在帮助企业实现降本增效的同时，自己也在完成转型。</p><p></p><h2>数字化给人力资源行业带来 4 个转变</h2><p></p><p></p><p>数字化转型“转什么”？在人瑞人才副总裁（技术开发）伏学发看来，企业数字化主要涉及三方面的转型，即产品和服务转型、运营和管理转型，以及商业模式转型。而对于人力资源行业而言，数字化技术将从员工招聘、员工服务、客户用工、客户服务等多个维度带来改变——对内，提升协同管理效应、提高人均产能；对外，提升客户满意度的同时扩大市场份额，提高行业竞争力。</p><p></p><p>员工招聘方面，从过去的线下简历投递、线下面试、员工信息登记等颇为繁琐的方式，转变为简历资源自动入库、简历资源标签化、客户需求动态跟踪、招聘目标在线分配、招聘过程全流程跟踪、岗位利润实时测算等更高效的方式。</p><p></p><p>员工服务方面，所有的入职资料收集、入职办理、合同签署、员工考勤请休假、证明开具、薪资查询等流程和琐碎的工作，都可以通过微信小程序或者 APP，由员工自主完成，而人事专员就可以从中解放出来，提高人事服务效率。</p><p></p><p>伏学发举例，在上线数字化系统之前，人瑞人才曾面临一个巨大难题——外包员工的劳动合同丢失率超过 60%。“当时人瑞人才外包员工超过 3000 人，全部通过人工、纸质形式管理，信息的存储、查阅、调取基本都靠手工。不仅管理效率低、工作量大，而且出错率也比较高。根据人瑞人才最新财报，截至 2023 年 6 月 30 日其在岗的综合灵活用工人数达到 33864 人，而历年来管理过的员工数量更达几十万人，如果还用这种传统的管理模式，仅仅是员工的入职资料、档案，整个楼层都可能放不下，查阅起来更是一个‘灾难’。”伏学发表示，“而数字化技术的引入，在很大程度上解决了这一问题。”</p><p></p><p>客户用工方面，如前所述，灵活用工成为“潮流”，企业对人才的需求，正在从“为我所有”，转变为“为我所用”。<a href=\"https://www.infoq.cn/theme/144\">数字化</a>\"系统帮助人瑞人才更好满足了企业客户的这一需求。</p><p></p><p>人瑞人才 ITO 事业部商务总监何静以<a href=\"https://www.infoq.cn/theme/180\">汽车</a>\"行业为例介绍了这一变化：汽车产品更新迭代速度加快，软硬件结合趋势日益凸显，任何一个研发环节的变化都会对其它链条环节带来影响，因此，车企很难再把软硬件设计外包给外部公司完成，必须自建团队。</p><p></p><p>“但是，这部分岗位并不是长期需求，而且人才稀缺，薪资比较高，所以，很多车企会通过外包团队解决这一问题。在业务需要时快速组建、响应，项目周期完成后再释放到市场。”何静解释道。而对于人瑞人才而言，利用数字化系统，可以更快、更精准地帮助企业匹配到相应的人才，同时提高人才的复用率和复推率。</p><p></p><p>进一步来说，这也将在客户服务方面带来改变，借此，可以帮助客户用更低的成本，享受更高效、优质的服务。</p><p></p><h2>数字化系统建设遵循“四维一体”原则</h2><p></p><p></p><p>以上提及的人瑞人才“数字化系统”指的是其经过 10 年的持续研发投入，建立的自主知识产权一体化人力资源服务技术平台，其中包括了客户合同管理系统、招聘业务管理系统、外包业务管理系统等在内的数十个业务系统。</p><p></p><p>其中，客户合同管理系统是人瑞人才所有管理的“源头”，集客户商机、客户方案、招投标立项、合同管理、交付结算、开票回款管理于一体；招聘和外包是两大核心业务，覆盖数万员工的管理，以及面向客户的服务、交付、结算等流程全都在这两个系统上完成。</p><p></p><p>“基于业务管理系统，我们内部的业务管理从客户经营、业务经营两个维度实现了真正的闭环。从客户经营维度，自商机的落单合作、需求厘清，到需求派发、交付、结果呈现，形成了客户的经营的闭环。”人瑞人才高级副总裁兼第二事业群总裁李伯楠分享道：“从内部业务经营维度，基于商务、招聘、交付、服务，构建了内部业务体系的闭环管理。所有业务环节提炼出来的数据，均以客户的需求为基础，目标为导向，进而为目标管理提供关键的参考，同时，可以实时发现问题、解决问题，让团队能力不断得到提升。”</p><p></p><p>李伯楠对业务管理系统进行了演示，只要点击某个客户，就可以进入对应的管理界面，其中会对客户的经营状态、给人瑞带来的营收、回款情况，它所需的岗位信息、外包员工的在岗情况等等进行清晰的呈现。对应地，外包人员的所有基础信息、薪资标准、项目经验、社保管理等数据，也可以在系统中随时动态查询、提取。</p><p></p><p>除此之外，针对客户服务，外包员工从入职到离职整个全流程最关键的管理指标是流失率，每个月的流失率水平、主动流失 / 被动流失的原因等等信息，也可以通过系统进行自动分类分析，从而采取对应的管理手段。</p><p></p><p>“总结而言，人瑞人才数字化转型系统建设的核心定位，遵循‘四维一体’的基本原则。”</p><p></p><p>伏学发介绍：首先，它是一个工作平台，包括商务、招聘、服务、经营等在内的各个角色都可以在上面处理日常事务，进行协同工作，同时还可以实现自下而上的业务基础数据的收集；</p><p></p><p>其次，它是一个效率平台，可以满足多角色线上线下的高效协同，实现数据实时共享流转；</p><p></p><p>此外，它还是一个管理平台，是管理层自上而下的管理抓手，帮助技术与业务实现融合，达到管理升级转型的目标；</p><p></p><p>最后，它还是一个价值平台，可以实现应收、回款、垫付 &amp; 资金实时预测，实时监控和分析客户经营价值，实现一人一岗、一薪酬、一价值的动态管理。”</p><p></p><h2>拒绝业务当甩手掌柜</h2><p></p><p></p><p>李伯楠及其业务团队被伏学发所在的技术部门称为“合格的用户”，“在很多企业，业务用户提需求非常积极，但到了系统上线之后从来不去验证流程节点和需求设置是否合理，导致很多项目做完之后不能匹配业务需要，没有人用。而在人瑞人才的数字化建设中，我们拒绝业务当甩手掌柜，在业务端的关键用户要能够实实在在参与进来，切身体验系统功能。”伏学发强调。</p><p></p><p>当然，在给业务部门提要求的同时，伏学发对技术人员的要求也并不低。“所有技术开发人员在做内部系统时一定要有业务代入感，在响应任何需求时，首先要站在业务场景，不能像盲人摸象，业务说什么就做什么，最后的结果可能做了个‘四不像’。”根据这一标准，伏学发在招聘技术人员时除了会对其工作年限、经验做评估之外，还会询问其所开发系统背后的使用用户量、支撑的业务体量。“通过这一一个简单的问题，我们大概就可以看出来他对业务是否有自己的理解，这是基本的要求。”</p><p></p><p>根据麦肯锡此前的一份报告指出：企业数字化转型成功率仅为 20％。换言之，80% 的企业数字化转型都失败了。</p><p></p><p>究其背后的原因，伏学发首当其冲的一个痛点就是需求难以管理，而业务与技术的“双向奔赴”，彼此之间的磨合与沟通，是捋清需求的重要前提。“需求清，则建设准；需求乱，则建设难。只有合理管控需求，分步推进，才能标准化、制度化、流程化整个数字化转型过程。”伏学发表示。</p><p></p><p>但即便如此，伏学发和李伯楠也坦言，<a href=\"https://www.infoq.cn/article/YcvRvZaOoez9sKJ92jHR\">业务与技术</a>\"人员在话语体系上有天然的差异，双方也并不是在协作最初就能行云流水般达成一致默契。“因此，我们在沟通需求时，会先推出系统原型，用实实在在的界面来直观呈现技术对业务需求的理解。如果是匹配的，那就往下推进开发，如果不是，就提出调整建议或者及时止损。”伏学发告诉 InfoQ 记者。</p><p></p><p>除此之外，数字化转型的痛点之二是系统难于实现。企业上系统普遍追求大而全，追求规模和数量，但最后却有始无终。在人瑞人才看来，企业数字化转型，聚焦比规模重要，要以有限的资源快速落地项目，然后快速验证、持续迭代。</p><p></p><p>自 2016 年到 2022 年的 7 年时间里，人瑞人才的研发支出持续提升，年均大约 1736 万，占营收的 1.3%。虽然这并不是一笔小数目，但是伏学发表示，作为技术负责人必须为这些投入负责，尽量用更小的成本验证数字化转型过程中需求的合理性，把投入控制在适度、可控、有预期的范围内。</p><p></p><p>痛点之三，发生在系统上线之后的推行过程中。新工具、新系统的上线势必带来工作模式、工作习惯的改变，对于“接受变化”这件事，并非一朝一夕，需要时间慢慢完成。与此同时，还需要管理手段层面的约束。</p><p></p><p>痛点之四，是经过系统积累沉淀的数据如何更好地治理。“如果数据质量不能保证，系统就犹如僵尸，无法产生生产力，那么所有努力和投入都可能付之东流。”伏学发说道。</p><p></p><p>与此同时，在他看来，数字化转型的痛与苦还来自两“怕”——怕外行、怕新官。一方面，很多企业内部缺少数字化和数据认知，对于项目投入没有清晰的评估，导致需求及流程调整随心所欲，系统建设没有连贯性；另一方面，管理层的频繁变动，也可能会导致企业制度、流程、标准“朝令夕改”，使得既有系统崩溃或被边缘化。</p><p></p><h2>成功的企业数字化转型，至少需要 6 大保障</h2><p></p><p></p><p>但话说回来，判断数字化转型成功与否的标准是什么？</p><p></p><p>伏学发强调了三点：首先，有没有人用，一个数字化系统上线，如果没有人愿意使用，毋庸置疑就是失败的；其次，有人用也不等于成功，还要在用户使用过程中产生有价值的业务数据，并在系统中流转；此外，企业内部能够通过系统实现全流程业务闭环管理。</p><p></p><p>而为了实现这些成功目标，伏学发认为，企业需要做足至少六个层面的措施保障：</p><p></p><p>第一，共识保障。即在企业层面达成数字化转型的全面共识，达成一致目标，才能统一思想、一致行动，克服转型中的各种困难，比如业务与技术的鸿沟、需求和系统的对齐等等；</p><p></p><p>第二，组织保障。在人瑞人才，由一把手、分管领导、研发组成了数字化战略、运营、技术“铁三角”，所有人对于数字化系统都要“亲自上、亲自学、亲自用”；</p><p></p><p>第三，制度保障。没有规矩不成方圆，数字化转型的推进，需要配备相关的制度管理，以数据治理为例，如果用户不能根据相关标准和流程及时录入数据，并保证数据的准确性，就会导致数据质量问题，给业务带来不可预估的风险；</p><p></p><p>第四，技术保障。“硬件”方面，需要有满足转型的各种技术，“软件”方面，需要有各类业务和技术人才团队；</p><p></p><p>第五，文化保障。需要全新的数字化文化贯穿企业经营、转型全过程，这也是形成数字化共识的重要前提；</p><p></p><p>第六，资金保障，伴随整个数字化转型全过程，需要持续不断的资金投入。</p><p></p><p>“正是基于这些保障，在人瑞人才，失败的数字化项目相对是比较少的。每一个项目的开始都会经过严格的内部评估，并且通过系统原型快速验证这件事的可行性，如果可行就持续投入，不可行就见好就收。这是一个全公司内部多方探讨、博弈的过程，需要参与其中的每个人大胆提出想法，然后实事求是。”伏学发总结道。</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/34WS9TXHFTKLjO0Vr5qk\">《认清时代、掌握先机：数字企业 &amp; 数字人才的成长之路与管理之道》</a>\"</p><p><a href=\"https://www.infoq.cn/article/A7VCO3RePjBOPTLKS79B\">《极客邦科技与人瑞人才达成战略合作，共建数字化人才生态链》</a>\"</p><p><a href=\"https://www.infoq.cn/article/h8I3yhi8JkLffu25C2Cd\">《优秀的数字化人才，都具备这 3 个特征》</a>\"</p>",
    "publish_time": "2023-10-16 15:24:37",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "千刀万剐的微服务，我们到底应该如何应对分布式系统的挑战和风险",
    "url": "https://www.infoq.cn/article/zFRQN45YMZJJxuN5rpPy",
    "summary": "<p></p><blockquote>本文探讨了软件开发领域中追求复杂分布式系统的趋势，以及可能引发的问题。作者提到了一些常见的挑战和解决方案，强调了在不必要的复杂性前要保持清晰思考，而不是盲目追求分布式架构。文章最后指出，当前行业趋势正在回归理性，企业开始认识到简单而实用的解决方案可能更为可行。</blockquote><p></p><p></p><p></p><h2>复杂性教义</h2><p></p><p></p><p>有一个颇具知名度的短视频，展现了一位工程师向项目经理解释一个过于复杂的微服务“迷宫”是如何工作的，意在获取用户的生日，然而最终却以失败告终。这个场景生动地揭示了当前科技文化中的荒谬之处。我们或许为之发笑，但在正式场合讨论这个问题却是自寻烦恼，甚至可能因此失去工作。</p><p></p><p>怎么就搞成这样了？我们是如何从解决手头任务转变为把大量资源花费在解决根本不存在的问题上的？</p><p></p><p></p><h2>完美风暴</h2><p></p><p></p><p>近年来，一系列因素可能对当前状况产生了影响。首先，大批编写浏览器 JavaScript 的开发人员开始自认为是 “全栈”，涉足服务器开发和异步编程。毕竟，JavaScript 就是 JavaScript，对吧？无论是用它创建用户界面、服务器、游戏还是嵌入式系统，似乎都没有太大区别。而当时的 Node.js 仍然只是一个人的学习项目，早期的 JavaScript 在服务器开发领域存在诸多问题。试图向那些刚刚踏入服务器端开发领域的人指出这些问题通常会引发许多抱怨和反驳。毕竟，对他们来说，这是唯一熟悉的东西。在他们看来，Node.js 之外的世界似乎几乎不存在，而采用 Node.js 的方式是唯一的选择。因此，这是今天我们仍然面临的顽固、教条式思维的根源。</p><p></p><p>接着，大批来自 FAANG（译注：指 Facebook、亚马逊、苹果、Netflix 和谷歌，类似国内的 BAT）的资深人员纷纷加入初创公司，指导那些刚刚进入行业、易受影响的年轻 JavaScript 服务器端工程师。他们坚信 “他们在谷歌那边是怎么做事” 的方式是毫无疑问和正确的，即使在某些情况下没有道理。他们认为，没有一个单独的用户首选项服务简直就是缺乏可扩展性的表现！</p><p></p><p>然而，将所有责任都推给资深人员和新手是过于简单化了问题。除了资深人员的指导外，还有一个因素在起作用——资金的易得性。</p><p></p><p>一旦获得风险投资，你是否对盈利就漠不关心了呢？我不止一次地收到管理层的电子邮件，要求大家到办公室去整理自己的桌子，看上去非常忙碌，因为一群投资者即将在办公室游览。投资者渴望看到爆炸性增长，但并不在意盈利能力。他们只关心公司能够多快地雇佣昂贵的软件工程师来做某事。</p><p></p><p>既然你已经拥有这些开发人员，你会如何利用他们呢？是让他们构建一个更简单、更容易扩展和维护的系统，还是让他们创造一个庞大而神秘的 “微服务” 星座呢？微服务 —— 这是编写可扩展软件的新方式！我们是否应该假装 “分布式系统” 的概念从未存在过？（我们可以忽略有关微服务不是真正的分布式系统的微妙差异的解释吗？）</p><p></p><p>回到科技行业还没有变得如此庞大荒谬的时代，分布式系统备受尊敬，通常被视为最后的手段，仅用于解决非常棘手的问题。拥有分布式系统的一切都变得更具挑战性和耗时 —— 开发、调试、部署、测试、弹性等等。但我不知道 —— 也许现在一切都变得超级容易，因为有了太多的工具。</p><p></p><p>微服务开发没有标准工具，没有通用的框架。到了 2020 年代，处理分布式系统的难度只是略有改善。即使有了 Docker 和 Kubernetes 这样的工具，分布式设置的固有复杂性也没有神奇地消失。</p><p></p><p>我喜欢引用这份 5 年初创公司审计总结，因为它充满了基于确凿证据（和付费见解）得出的常识性结论：</p><p></p><p></p><blockquote>“…… 我们审计的那些现在表现最出色的初创公司通常采用了一种几乎是毫不掩饰的‘保持简单’的工程方法。纯粹为了聪明而聪明往往遭受鄙视。相反，那些让我们感到‘哇，这些人聪明得不得了’的公司，大多数已经衰落了。”一般来说，许多公司陷入困境的主要问题是过早采用了微服务、依赖分布式计算和消息传递密集型设计的架构。</blockquote><p></p><p></p><p>简而言之：“复杂性会毁掉一切”。</p><p></p><p>审计揭示出一个有趣的趋势：许多初创公司在构建直观、简单、高性能的系统时，都陷入了一种群体冒充综合症。有一种教条观念认为，无论问题是什么，都不应该从第一天开始使用微服务。“每个人都在使用微服务，但我们只有一个由少数工程师维护的 Django 单体应用和一个 MySQL 实例 —— 我们做错了什么？” 答案几乎总是 “没有做错什么”。</p><p></p><p>同样，经验丰富的工程师在当今的技术世界中经常感到犹豫和不足。好消息是，这可能并不是他们的问题。团队通常会假装他们正在处理 “网站规模” 的工作，藏在库、ORM 和缓存背后 —— 对自己的专业知识充满信心（他们在 Leetcode 上表现非常出色！），然而，他们甚至可能不了解数据库索引的基本概念。你正在处于一个没有根据的过度自信、浪费和邓宁 - 克鲁格效应（译注：也称为邓克效应或达克效应，是一种认知偏差，能力不足的人错误地认为自己比实际情况更优越）的海洋中，那么真正的冒名顶替者是谁呢？</p><p></p><p></p><h2>单体架构没有问题</h2><p></p><p></p><p>认为只有那种看起来像阿富汗战争战略图一样复杂的系统才能够发展壮大，这种观念在很大程度上是一个误解。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ca/ca4ebede7c628afbc59bcfd7edefca11.jpeg\" /></p><p></p><p>Dropbox、Twitter、Facebook、Instagram、Shopify、Stack Overflow 等公司最初都是从单体代码库起步的，当中许多公司至今仍以单体架构为核心。举例来说，Stack Overflow 以其极少的硬件资源运行着庞大的网站，以此为豪；而 Shopify 仍是一个 基于 Rails 的单体应用，依赖经过验证的 Resque 处理数十亿个任务。</p><p></p><p>WhatsApp 凭借其 Erlang 单体应用和仅有 50 名工程师的团队取得了巨大的成功。背后的原因是什么呢？</p><p></p><p></p><blockquote>WhatsApp 刻意保持其工程团队规模小巧，仅有约五十名工程师。每个工程团队人数也不多，通常由一到三名工程师组成，但各团队都拥有极大的自主权。在服务器方面，WhatsApp 更偏爱使用较少数量的服务器，并竭尽所能地使每台服务器发挥最大功效。</blockquote><p></p><p></p><p>你是否曾以为 Threads 是一项涉及整个 Meta 园区的大型工程？其实不是的。他们采用了 Instagram 的模式，这就是整个 Threads 团队：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/84/84d0294ffd681230b9bd15ced5b8a044.jpeg\" /></p><p></p><p>或许，宣称你的特定问题领域需要一个极度复杂的分布式系统和充满超级天才的开放办公室，只是一种妄自尊大的表现，而非明智之举？</p><p></p><p></p><h2>不要解决你没有的问题</h2><p></p><p></p><p>这是一个简单的问题 —— 你正在解决什么问题？是规模吗？你能否将问题分解，以实现规模和性能的双赢？你是否有足够的数据，来甄别什么需要成为一个独立的服务，以及背后的原因？分布式系统正是为应对规模与弹性而生。你的系统能否兼顾规模和弹性？如果其中一个服务宕机或变得缓慢，又当如何应对？仅凭扩展吗？那其他的服务又如何承受流量的冲击？你是否已经对各种可能的错误情况进行了周密的排列组合测试？是否考虑了反馈压力、断路器、队列、抖动等方面的影响？每个端点是否都有合理的超时时间？是否实施了防止简单改动导致系统崩溃的严密保护措施？你需要了解和调整的参数繁多且各异，皆因你的系统使用与负载特征而异。</p><p></p><p>实际上，大多数公司永远无法达到构建真正分布式系统所需的庞大规模。在缺乏相应规模、专业知识和无限资源的情况下，盲目模仿亚马逊和谷歌可能只会浪费大量资金和时间。遵循一篇名为《成功人士的十种早晨习惯》的文章，并不能确保你成为亿万富翁。</p><p></p><p>唯一比分布式系统更糟糕的，是一个糟糕的分布式系统。</p><p></p><p>Jason Warner：</p><p></p><p>全球百分之九十的公司或许只需依靠一个单体架构，运行于主数据库集群上，配备数据库备份、缓存和代理，即可满足需求。然而，那百分之十的公司却达到了全球规模（绝无戏言，Sam），解决此问题犹如一门艺术。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c1/c1faa4b8e0a347226adc99cd3856a4f6.jpeg\" /></p><p></p><p></p><h2>“但是每个团队……但是分开……但是 API”</h2><p></p><p></p><p>将分布式拓扑结构强行嵌入公司组织结构，虽理想却往往适得其反。常见的解决之道是将问题分解成小块，逐一攻破。因此，若将一项服务拆分为多个微服务，一切似乎变得轻而易举。</p><p></p><p>这个理论看似美好而优雅 —— 每个微服务都有专门的团队精心维护，通过美丽、兼容、有版本的 API 进行隔离。实际上，这种可靠性之高，以至于你几乎无需与该团队沟通 —— 仿佛微服务是由第三方供应商维护一般。多么简单！</p><p></p><p>或许这听起来陌生，因为这种情况实属罕见。事实上，我们的 Slack 频道充斥着关于发布、错误、配置更新、重大变更和公告的消息，团队成员需时刻掌握一切。更常见的情况是，一个本就繁忙的团队分散精力于多个微服务，而非在单个微服务上取得卓越成绩，通常随着人员变动不断更换所有权。</p><p></p><p>为了赢得比赛，我们不是建造一辆出色的赛车，而是组建了一支糟糕的高尔夫球车队。</p><p></p><p>Kelsey Hightower：</p><p></p><p>这是一个很好的问题。这是我的回答：我敢断言，一个庞大的单体应用在性能上必将胜过每一个微服务架构。只需简单计算一下每个服务间的网络延迟以及每个请求的序列化和反序列化量，即可明显得出结论，毫无争议。</p><p></p><p></p><blockquote>Eugene Atsu：一个庞大的单体应用，通过自动扩展模型进行打包和部署，是否能在性能上与微服务架构相媲美？</blockquote><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/45/453656735882c221b76ca0b6695e412a.jpeg\" /></p><p></p><p></p><h2>你会失去什么</h2><p></p><p></p><p>构建系统时，微服务固然诱人，却暗藏陷阱。这些问题或被轻视，或被忽略，导致团队耗费数月编写定制工具，学习与核心产品无关的教训。以下仅是常被忽视的几个方面。</p><p></p><h3>告别 DRY 原则</h3><p></p><p></p><p>多年以来，我们不断教导开发人员遵循 “不要重复自己”（Don't Repeat Yourself，DRY）的原则编写代码，然而如今，我们似乎已经彻底忽视了这个问题。微服务架构下，默认情况下并不符合 DRY 原则，每个服务都充斥着冗余的样板代码。这种 “管道” 的负担如此沉重，而微服务的规模如此之小，以至于服务的平均实例比 “产品” 更多。那么，我们能否将公共代码提取出来呢？</p><p></p><p>是否存在一个公共库？公共库如何更新？在各处保留不同的版本？强制定期更新，在所有仓库中创建数十个拉取请求？把它们都放在一个单体代码库（monorepo）中？这也伴随着一系列问题。是否允许一些代码的重复？毕竟每家公司都有权在每次重复发明轮子。</p><p></p><p>每家公司都必须面对这些选择，而且没有一个 “人机工程学” 方案是完美的 —— 你必须选择你愿意承受的痛苦。</p><p></p><p></p><h3>开发人员人机工程学将大幅下降</h3><p></p><p></p><p>“开发人员人机工程学”指的是完成新功能或解决错误时所付出的努力和摩擦。</p><p></p><p>在使用微服务时，工程师需要构建整个系统的思维导图，了解执行特定任务所需的服务、团队合作、联系对象以及关注事项。这是 “在做任何事情之前，你必须了解一切” 的原则。Spotify 这样的市值数十亿美元的公司，投入了大量资源来构建 Backstage，用于编目其无尽系统和服务的软件。</p><p></p><p>这至少应让你明白这个游戏并不适合每个人，代价也相当高。对于工具方面，Spotify 之外的公司不得不自行解决问题，解决方案的稳定性和可移植性可想而知。</p><p></p><p>有多少团队实际上简化了启动“又一个愚蠢服务”的流程？这包括：</p><p></p><p>GitHub/GitLab 中的开发者权限默认环境变量和配置CI/CD代码质量检查代码审查设置分支规则和保护监控和可观测性测试工具基础设施即代码</p><p></p><p>当然，要将这种列表乘以公司内部使用的编程语言数量。也许你有一个可用的模板或操作手册？也许有一个无摩擦、一键启动新服务的系统？要消除这些自动化问题需要数月的时间。因此，你可以将重心放在产品上，或者致力于工具开发。</p><p></p><p></p><h3>集成测试</h3><p></p><p></p><p>仿佛日常微服务的磨难还不够，你竟然舍弃了稳定的集成测试带来的安心感。尽管你的单一服务和单元测试都通过了，但每次提交后，你是否仍能确保关键路径完整无缺？谁负责整个 Postman 或其他地方的集成测试套件呢？有答案吗？</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/72/72fa47ffdc8c8e8f1938fa5f14b7a75e.gif\" /></p><p></p><p>在分布式系统中进行集成测试几乎成为无解的难题，因此我们不得不放弃，转而追求 “可观测性”。就像 “微服务” 是新的 “分布式系统”，而 “可观测性” 则是新的 “生产中调试”。若忽视可观测性，那写出的软件定然不够完美！</p><p></p><p>如今，可观测性已成为独立领域，你不仅需付出昂贵代价，还需消耗开发人员的时间。它无法即插即用 —— 你需要了解并应用金丝雀发布、功能标志等。谁来担当这个责任？难道要由一个已经忙碌不堪的工程师承担吗？</p><p></p><p>如你所见，将问题拆解并不意味着问题会变得更容易，相反，只会让你面临更加复杂的困境。</p><p></p><p></p><h2>那么仅仅使用“服务”呢？</h2><p></p><p></p><p>为什么非得将你的服务划分为“微服务”？仅使用“服务”有什么问题吗？有些初创公司甚至已经走到了为每个功能创建一个服务的地步，是的，这不就像使用 Lambda 吗？这是一个非常有见地的问题，让我们对这种无法控制的崇拜有了更深入的认识。</p><p></p><p>那么我们应该采取什么策略呢？从单体架构开始显然是一个明智的选择。在许多情况下，一种有效的模式是 “主干和分支”，其中主要的 “主干” 单体架构得到了 “分支” 服务的支持。这些 “分支” 服务可以处理明确定义、可独立扩展负载的任务。例如，一个需要大量 CPU 资源的图像调整服务可能比一个用户注册服务更有实际意义。或者说，你是否每秒都在进行大量用户注册，以至于需要进行独立的横向扩展呢？</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/43/4375d3b382447cb14903e25f06f46fb0.gif\" /></p><p></p><p></p><blockquote>副注：在版本控制的时代，我们很少使用 “master” 分支这个术语。相反，我们通常采用 “主干和分支” 的表达方式，因为它更易于理解 —— 犹如树形结构一般。然而，随着 GitHub 决定摆脱令人遗憾的命名约定，年轻的工程师们早已忘却了 “主干” 的概念，因此 “main” 便成为了默认的名称。</blockquote><p></p><p></p><p>DHH：</p><p></p><p>除了壮观的单体之外，还应该编写成“城堡”的模式：一个单一的、壮观的单体，承载了应用程序的大部分主体，同时为高度专业化和不同需求的情况提供了一些辅助外围应用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/61/61c1167465c03d01b6c53b6e9757d553.jpeg\" /></p><p></p><p></p><h2>钟摆回荡，炒作渐息</h2><p></p><p></p><p>风险投资的洪流退去，企业明智地回归市场，认清了过度投入 Web 规模架构可能带来的风险。或许，在网络问题不再成为困扰的情况下，理性决策才是可持续发展的关键。</p><p></p><p>Arjun Narayan：</p><p></p><p>然而，这并非为 Web 规模量身打造。当 Rails 单体应用达到极限容量，无法继续扩展公司规模……</p><p>除了坐拥 940 亿美元市值，你又将如何应对？</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2f/2fa3b819d4ecc849e58a4a7236235a76.jpeg\" /></p><p></p><p>Milan Jovanović：</p><p></p><p>亚马逊 Prime Video 团队将一个系统从微服务迁移到了单体架构，并且成功将云成本降低了 90%。</p><p></p><p>以下是最重要的收获：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/47/47bbf4f739de11043585ec1f18e8e2e5.jpeg\" /></p><p></p><p>Gergel Orosz：</p><p></p><p>记录一下，在 Uber，我们正在将许多微服务迁移到所谓的 \"宏服务\"，正如 @copyconstruct 所称的 \"宏服务\"（适度规模的服务）。这样做的原因是，测试和维护数以千计的微服务不仅费力，而且从长远来看，解决短期问题可能更加麻烦。</p><p></p><p></p><blockquote>Cindy Sridharan：· 微服务很难。· 构建可靠且可测试的微服务远非易事。· 高效地 \"测试\" 微服务需要大量的工具和远见。· 许多（甚至大多数？）组织无需采用 Netflix/Uber 风格的微服务。· 宏服务</blockquote><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/81/81c9c725a94320f0a3b9d04e33f9bb67.jpeg\" /></p><p></p><p>最终，当从纽约前往费城时，你面临两个选择。你可以构建一艘高度复杂的太空飞船，进行轨道下降抵达目的地，或者选择购买一张美国国家铁路运营商 Amtrak 的火车票，乘坐 90 分钟的列车。这就是抉择的难题。</p><p></p><p></p><h5>原文链接：</h5><p></p><p>https://renegadeotter.com/2023/09/10/death-by-a-thousand-microservices.html</p><p></p><p></p><h5>相关阅读：</h5><p></p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MzUzMTA2NTU2Ng==&amp;mid=2247522713&amp;idx=3&amp;sn=ed22bce0368a683ed721b2553428ebad&amp;chksm=fa4ae628cd3d6f3ec59f8389632834f01057c97df42fac18ccba2cf1715669c64e65c4ffd739&amp;scene=27#wechat_redirect\">微服务等于&nbsp;Spring&nbsp;Cloud？了解微服务架构和框架</a>\"</p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MzIxMzEzMjM5NQ==&amp;mid=2651054765&amp;idx=1&amp;sn=3297015bfece7433f222d95e2f930c1e&amp;chksm=8c4c37a9bb3bbebf1604d994dd87355419f9a7bd2dc8383ca82affb34ed2528f25b98023e472&amp;scene=27#wechat_redirect\">微服务的几个陷阱</a>\"</p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MzIxMzEzMjM5NQ==&amp;mid=2651032682&amp;idx=1&amp;sn=6fa8158e697246e7fb2afbf0be3597ac&amp;chksm=8c4c596ebb3bd0785e9bc6b6bd515b325651b8fe06dbdb162bdc19a0e5cfb54464df63e5546d&amp;scene=27#wechat_redirect\">百亿流量微服务网关的设计与实现</a>\"</p><p><a href=\"https://www.infoq.cn/video/3UaAmw4dFVESmYhOZaZ2\">聊聊微服务架构的稳定性保障</a>\"</p>",
    "publish_time": "2023-10-16 15:53:01",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]