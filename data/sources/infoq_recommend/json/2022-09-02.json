[
  {
    "title": "谷歌云IoT Core服务停止公告震惊社区和客户",
    "url": "https://www.infoq.cn/article/U9lVZay87HMlTwLifw6c",
    "summary": "<p><a href=\"https://cloud.google.com/iot-core?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjIwMzQ3NzIsImZpbGVHVUlEIjoiMk16THNRempHYThnQkdlWCIsImlhdCI6MTY2MjAzNDQ3MiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.JadP58otP7MdCr0-ruByu-M5WeMUNoBr-rHzNKimKvo\">谷歌云IoT Core</a>\"是一项全托管的服务，可以帮助客户快速、安全地连接、管理和摄取来自全球数百万个设备的数据。最近，谷歌宣布停止这项服务——<a href=\"https://cloud.google.com/iot/docs/resources?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjIwMzQ3NzIsImZpbGVHVUlEIjoiMk16THNRempHYThnQkdlWCIsImlhdCI6MTY2MjAzNDQ3MiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.JadP58otP7MdCr0-ruByu-M5WeMUNoBr-rHzNKimKvo\">文档</a>\"显示，谷歌将于2023年8月16日停止这项服务。</p><p></p><p>谷歌于2017年发布了IoT Core的第一个公开测试版，作为其他云供应商IoT产品的竞争解决方案——<a href=\"https://www.infoq.cn/topic/Microsoft\">微软</a>\"的<a href=\"https://www.infoq.cn/topic/Azure\">Azure</a>\" IoT Hub和<a href=\"https://www.infoq.cn/profile/16442875E6261F\">亚马逊云科技</a>\"的AWS IoT Core。2018年初，这项服务开始普及。现在，谷歌通过电子邮件通知客户——“您将无法访问IoT Core设备管理器API。届时，设备将无法连接到谷歌云IoT Core MQTT和HTTP桥，现有连接将被关闭。”因此，这项服务的寿命只有5年。</p><p></p><p>考虑到物联网目前的发展状态，停止这项服务的决定非常值得我们注意。</p><p></p><p></p><blockquote>联网设备数量的增长速度在2021年放缓，但预计在2022年及以后将重新加速。尽管物联网市场出现了通货膨胀和长期供应中断等新的不利因素，但整体人气仍相对乐观。预计到2022年底，联网物联网设备数量将达到144亿件。</blockquote><p></p><p></p><p>此外，多年来，许多公司甚至为那些希望围绕托管服务构建物联网产品的人提供了专门的硬件套件。The Duckbill Group云经济学家Cory Quinn在推特上写道：</p><p></p><p></p><blockquote>我敢打赌@augurysys对他们发布的谷歌云IoT Core研究案例感到非常震惊。没有什么比公开推荐更能说明你押错了赌注。</blockquote><p></p><p></p><p>去年，InfoQ<a href=\"https://www.infoq.com/news/2021/08/google-enterprise-apis-label/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjIwMzQ3NzIsImZpbGVHVUlEIjoiMk16THNRempHYThnQkdlWCIsImlhdCI6MTY2MjAzNDQ3MiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.JadP58otP7MdCr0-ruByu-M5WeMUNoBr-rHzNKimKvo\">报道</a>\"了谷歌在企业API和“杀死产品”方面的名声——社区也表达了他们的担忧和看法。一年后，LookDeep Health联合创始人兼首席执行官Narinder Singh在一条推特上再次表达了类似的观点：</p><p></p><p></p><blockquote>真不敢相信@Google @googlcloud对企业的支持每况愈下。是的，他们现在更擅长销售，但是他们通过他们的行动反复劝说你应该只使用GCP的核心部分。</blockquote><p></p><p></p><p>此外，一位用户在Reddit的一个<a href=\"https://www.reddit.com/r/googlecloud/comments/wp93ss/legal_notice_iot_core_will_be_discontinued_on_aug/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjIwMzQ3NzIsImZpbGVHVUlEIjoiMk16THNRempHYThnQkdlWCIsImlhdCI6MTY2MjAzNDQ3MiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.JadP58otP7MdCr0-ruByu-M5WeMUNoBr-rHzNKimKvo\">帖子</a>\"中写道：</p><p></p><p></p><blockquote>有时候我真的不懂谷歌云。Azure和亚马逊云科技的支持者们之所以反对谷歌云，主要原因是他们关闭了一些东西。他们所要做的应该是不要再做这样的事情来留住他们的一些信誉。</blockquote><p></p><p></p><p>Hacker News关于谷歌云IoT Core停止服务的<a href=\"https://news.ycombinator.com/item?id=32475298&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjIwMzQ3NzIsImZpbGVHVUlEIjoiMk16THNRempHYThnQkdlWCIsImlhdCI6MTY2MjAzNDQ3MiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.JadP58otP7MdCr0-ruByu-M5WeMUNoBr-rHzNKimKvo\">帖子</a>\"中也带了很多评论，有的表示对谷歌的不信任，有的表示多多少少理解谷歌的立场。</p><p></p><p>最后，谷歌合作伙伴ClearBlade宣布了对IoT Core的全面替代服务，包括从谷歌IoT Core到ClearBlade的<a href=\"https://www.clearblade.com/wp-content/uploads/2022/08/ClearBlade-Google-IoT-Core-Migration_Website.pdf?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjIwMzQ3NzIsImZpbGVHVUlEIjoiMk16THNRempHYThnQkdlWCIsImlhdCI6MTY2MjAzNDQ3MiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.JadP58otP7MdCr0-ruByu-M5WeMUNoBr-rHzNKimKvo\">迁移路径</a>\"。然而，在Hacker News的<a href=\"https://news.ycombinator.com/item?id=32475298&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjIwMzQ3NzIsImZpbGVHVUlEIjoiMk16THNRempHYThnQkdlWCIsImlhdCI6MTY2MjAzNDQ3MiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.JadP58otP7MdCr0-ruByu-M5WeMUNoBr-rHzNKimKvo\">帖子</a>\"中，一位名叫patwolf的用户表示：</p><p></p><p></p><blockquote>我已经使用谷歌云IoT Core好几年了。现在我得找个替代方案。有一个叫作ClearBlade的供应商今天宣布了一个直接的迁移路径，不过目前我考虑自己进行迁移。</blockquote><p></p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/08/google-iot-core-discontinued/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjIwMzQ3NzIsImZpbGVHVUlEIjoiMk16THNRempHYThnQkdlWCIsImlhdCI6MTY2MjAzNDQ3MiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.JadP58otP7MdCr0-ruByu-M5WeMUNoBr-rHzNKimKvo\">The Announcement of Discontinuing Google Cloud IoT Core Service Stirs the Community and Customers</a>\"</p><p></p>",
    "publish_time": "2022-09-02 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "微软向 Windows Server 添加虚拟核心许可，引来亚马逊、谷歌等不满",
    "url": "https://www.infoq.cn/article/3m3wuY1m98jPrbOzzavJ",
    "summary": "<p>&nbsp;</p><p>8 月 29 日，<a href=\"https://blogs.partner.microsoft.com/mpn/new-licensing-benefits-make-bringing-workloads-and-licenses-to-partners-clouds-easier/\">微软</a>\"宣布将于 2022 年 10 月 1 日对其外包和托管条款进行重大修订和升级，最核心的变化是将引入新的 <a href=\"https://mp.weixin.qq.com/s?__biz=MzIzNjUxMzk2NQ==&amp;mid=2247488892&amp;idx=1&amp;sn=0cefa94664126c62388be432b5aaab5b&amp;chksm=e8d7eabedfa063a867fd842740a3c67acab91c71e374e76cf83ffe64f51371a9f52c17b8ec6e&amp;scene=27#wechat_redirect\">Windows Server</a>\" 虚拟核心许可。微软称通过简化在云中使用微软软件的许可条款，全球合作伙伴和客户将从中受益。</p><p>&nbsp;</p><p>“现在，Windows Server 是通过物理内核授权的，这意味着客户必须访问物理服务器硬件，来确保他们有足够的 Windows Server 许可证来覆盖机器中的所有物理内核，”微软首席合作伙伴官 Nicole Dezen 解释道。</p><p>&nbsp;</p><p>Dezen表示，“有了虚拟内核许可选项，客户可以根据他们在虚拟机中使用的虚拟内核数量选择 Windows Server 授权，从而使 Windows Server 在虚拟化或外包时更容易获得授权。”</p><p>&nbsp;</p><p>微软想让用户将 Windows Server 迁移到云中，但不是任何云——新许可证不适用于阿里巴巴、亚马逊、谷歌和微软，其目标是由微软合作伙伴社区运行的云。据悉，新规则在全球范围内适用。</p><p>&nbsp;</p><p>此外微软还表示，任何拥有 Microsoft 365 F3、Microsoft 365 E3 或 Microsoft 365 E5 许可证的用户都可以在自己的服务器或外包商的服务器（列出的提供商除外）上虚拟化 Windows 10 或 Windows 11，无论用户的主要设备是否具有合格的操作系统 (QOS)。没有QOS的主设备的Microsoft 365用户还必须获得VDA附加许可证来虚拟化Windows 10或Windows 11。</p><p>&nbsp;</p><p>尽管微软表示这些改变是为了让客户受益并响应合作伙伴的反馈，但外媒表示，这实际上是在对 OVHcloud 等欧洲云运营商的法律诉讼做出反应。</p><p>&nbsp;</p><p>此前，OVHcloud 在对微软的控诉中称，微软授权其办公软件和其他产品的方式可能会使企业使用Microsoft Azure以外的云服务的成本更高。然而其他云服务更难与微软竞争，因为其软件在其平台上使用时效果不佳。“微软通过滥用其主导地位破坏了公平竞争并限制了消费者在云计算服务市场上的选择。”OVHcloud 发言人曾表示。</p><p>&nbsp;</p><p>这次修改后，云领域的一些人对微软的大修并不满意，普遍认为微软没有解决问题的关键。</p><p>&nbsp;</p><p>“云计算行业对客户的承诺是提供灵活、弹性的计算服务，客户无需担心传统的合约锁定，云计算的客户应该能够在不同的平台自由迁移，选择最合适他们的技术和平台，而不是被迫选择最符合微软利益的平台。”谷歌负责政府和政策事务的副总裁 Marcus Jadotte在 <a href=\"https://twitter.com/MarcusJadotte/status/1564725111965601792\">Twitter</a>\"上表示。</p><p>&nbsp;</p><p>与此同时，AWS 母公司<a href=\"https://www.reuters.com/article/eu-microsoft-alphabet-amazon-com-idCAKBN2Q023Y\">亚马逊对此的批评</a>\"更为严厉，该公司的一名发言人报道称，“微软现在正在通过实施更多限制来加倍打击同样的有害行为，以不公平的方式试图限制其面临的竞争，而不是倾听客户的意见，为每个人恢复公平的软件许可。”</p><p>&nbsp;</p><p>微软目前正在接受欧盟委员会的调查，欧洲云厂商指控涉其在云中的授权方面存在反竞争行为。尽管许可变更可能会安抚一些欧洲云厂商，但该公司似乎仍可能因故意将其最大竞争对手排除在新条款之外的政策而面临麻烦。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.theregister.com/2022/08/31/cloud_rivals_hit_back_at/\">https://www.theregister.com/2022/08/31/cloud_rivals_hit_back_at/</a>\"</p>",
    "publish_time": "2022-09-02 09:35:43",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "在阿里达摩院搞了四年数据库，我来聊聊实际情况 | 卓越技术团队访谈录",
    "url": "https://www.infoq.cn/article/CdcXAeoEzdVsDaI0LD1Q",
    "summary": "<p>2017 年的云栖大会，阿里巴巴达摩院宣布成立。</p><p></p><p>5 大研究方向，16 个实验室，数据库与存储实验室便是<a href=\"https://s.geekbang.org/search/c=0/k=%E8%BE%BE%E6%91%A9%E9%99%A2/t=\">达摩院</a>\"下设实验室之一。</p><p></p><p>成立伊始，达摩院定位发力硬核基础科技。</p><p></p><p>前沿<a href=\"https://qcon.infoq.cn/2022/beijing/track/1306\">数据库技术</a>\"，就是发力方向之一。</p><p></p><p>五年时间，社交媒体上每隔一段时间就有人出来问“阿里达摩院搞出来什么成果了？”，“阿里达摩院的技术水平是什么样的？”，“达摩院里面的人平常的 KPI 是什么？”，“什么样的人可以进阿里达摩院？”......</p><p>InfoQ 日前对达摩院数据库与存储实验室的三个核心团队的负责人汪晟、谭剑和谢炯进行了集中采访，了解他们在数据库前沿研究的具体工作，以及这些工作对阿里云数据库实力的加持，同时也一窥达摩院的人是如何开展研究工作的。</p><p></p><h2>密态数据管理，重新定义数据要素时代的安全边界</h2><p></p><p></p><p>数据有望成为新型生产要素推动社会变革，然而现阶段却面临着巨大挑战。人类社会的演进离不开生产要素的升级：从农业经济时代的土地、劳动力，到工业信息时代的资本、技术。在如今的数字经济时代，全球数据爆炸式增长，大数据、人工智能等技术不断涌现，数据正俨然成为这个时代最核心的生产要素。然而，为使数据真正成为生产要素，我们仍然面临着巨大的挑战：不同于其他生产要素，数据的易复制性、非排他性等特征导致其极易被泄露、难以被限制用途用量，如何在保障数据机密性、隐私性的前提下进行数据的大规模集中管理和跨组织有序流通是数据走向资产化的一大挑战。</p><p></p><p>“博士期间，我的研究方向是传统的数据库系统内核，与数据安全并没有太多关联。加入达摩院后，我逐渐意识到在云计算、数据互联迅速普及的当下，数据管理与流通中的隐私安全是非常严峻的挑战，会成为数据库系统突破其能力边界的一个重要方向。但具体可以做成什么样子，我脑子里起初也很模糊，只是不停地朝着这个方向探索。”</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/62/623c3b67131e74f40c39b64b24a1d893.jpeg\" /></p><p></p><p>汪晟于 2018 年加入达摩院，是数据库与存储实验室的第一位专注基础研究的科学家（Research Scientist）。自加入之后，他就开始探索数据库安全可信方向的研究，并带领团队从 0 到 1 完成了全密态数据库技术的研究突破与产品落地，使阿里云成为了全球少数具备全密态数据库管理能力的云厂商。</p><p>传统数据库系统的安全体系中已经有很多经典的技术，比如存储落盘加密、访问控制、网络传输加密等。但所有这些技术考虑的情境是：数据库管理着企业内部的数据，数据库服务所在的服务器被放置在企业专属的、物理安全的机房中，数据库与服务器的管理人员是完全被信任的企业内部员工，安全防护措施只需要保证没有权限的外部人员无法访问数据库即可。</p><p></p><p>但是，数据应用和云计算的出现改变了数据的使用和管理方式，从而颠覆了上述情境。</p><p></p><p>例如，数据应用业务链路越来越复杂，经常涉及企业自己数据在其他企业的系统中流动（比如电商场景的平台、商家、物流等），不同企业间是不完全信任的；在企业内部，业务团队的数据是由 IT 基础设施团队统一管理的，不同团队间也可能是不完全信任的。也就是说，数据的机密性、完整性、隐私性等问题，这是传统数据库系统在设计时从未考虑过的。</p><p></p><p>因此，业内也开始将研究重点聚焦在全密态数据库上。</p><p></p><p>全密态数据库旨在解决数据全生命周期的隐私保护问题，使得系统无论在何种业务场景和环境下，数据在传输、运算以及存储的各个环节始终都处于密文状态。当数据拥有者在客户端完成数据加密并发送给服务端后，在攻击者（包括黑客、超级用户等任何角色）借助系统脆弱点窃取用户数据的状态下仍然无法获得有效的价值信息，从而起到保护数据隐私的作用。</p><p></p><p>全密态数据库这个概念可追溯至 2011 年 MIT 提出的 CryptDB，该项目不是指某种特定的数据库，而是一种针对加密数据的查询技术，允许用户查询加密后的 SQL 数据库，在不解密数据的情况下返回结果。</p><p>CryptDB 使用的是特殊的加密算法，包括保序加密、可检索加密、半同态加密等，但各算法支持的计算操作极为有限，安全强度也各异，难以在复杂的业务场景中使用。此外，全同态加密被誉为密码学领域的圣杯，一旦实现就代表着所有计算都可以在密文上执行，且其安全性也能得到保障，因此受到了学术界的追捧。但其性能非常低，虽然过去几年业内有很多研究机构推出了各种各样的加速方案，但实际效果还是会与其他方案存在数量级上的差距。那么，其他方案具体是指什么呢？</p><p></p><p>第二种方案是多方安全计算。将数据存放在多个互补共谋的云平台之上，单一云平台上的数据显示为毫无意义的字节串，多个云平台的数据组合在一起才可以计算出想要的结果。其缺点是受到多云架构的制约，与集中化、单一的云平台设计初衷相违背，数据计算过程严重依赖跨云或者跨数据中心的网络交互，信息传输成本极高，难以处理大规模数据。</p><p></p><p>第三种方案是基于可信硬件（TEE）的方式实现。相较于普通服务器只需要有根用户或超级用户权限就可以访问任何进程中的任何数据内容，可信硬件内部的资源是由硬件机制保证隔离的，即便拥有上述权限也无法访问由可信硬件保护的区域内部。即便攻击者控制了整个服务器也无法窃取其中的数据。这种模式的缺点是十分依赖硬件的能力，且存在侧信道攻击隐患等。目前国际上比较成熟的是英特尔的 SGX 技术，达摩院内部也已经具备自研的 TEE 技术。</p><p></p><p>汪晟团队对上述三种技术方案均有研究布局，但技术研究和产品落地是两回事，经过多方权衡，团队当前选择了第三种方案进行商业化落地。</p><p></p><p>“阿里云是全球第三的云计算提供商，支撑着无数企业用户。我们希望研究出来的密态数据管理技术可以适用于任何场景下的任何数据库系统，且在硬件加持下，最终的性能损耗是可以无限趋近于零的。如果针对特别敏感的数据子集，不希望依赖硬件安全，我们可以对这部分数据使用同态加密算法做进一步加固，这自然是建立在牺牲性能的基础上实现的，需要企业自行抉择。”</p><p></p><p>在 2020 年初，汪晟团队的研究成果已经开始在阿里集团内部业务试运行，2021 年 9 月份，全密态数据库系列产品正式在阿里云对外发布，成为全球第二个全密态数据库云服务。阿里云的几大数据库产品，比如 PolarDB、RDS 均已接入该能力。</p><p></p><p>从性能指标来看，在事务型（OLTP）场景下，性能可以达到明文数据库的 50% 到 90%，具体性能损耗与实际运行的工作负载有关，这个损耗与业内其他方案相比已经把控得相当优秀了。当然，用户可以在安全与性能之间自行选择向哪一侧倾斜。</p><p></p><p>从改造视角来看，团队发现实际落地需要考虑的问题不单单是产品技术能力本身，更需要考虑与原有数据库的兼容性、降低迁移成本和提供回迁备案等。基于这些诉求，团队又研发了定制的数据库连接驱动，在业务无感的情况下自动完成数据加解密，无需修改应用侧代码。</p><p></p><p>“提供数据库内的密态数据管理能力只是个开始，最终企业客户希望得到的一定是覆盖整个数据生命周期全链路的密态数据管理能力。只有做到了这一点，才能真正实现数据要素的资产化和市场化，这是个更具挑战但也更有价值的研究问题。”</p><p></p><p>汪晟团队的研究不仅停留在数据库系统层面，面向上述数据全生命周期密态管理的问题，他们最新的研究成果已经转化为学术论文发表在了数据库领域顶会 VLDB’2022 上，得到了业界同行的认可。除此之外，他们在防篡改数据存储、隐私增强计算引擎等全方位数据安全技术的研究和产品化上也在进行着持续的探索突破。</p><p></p><p>在汪晟闷头研究数据库安全可信技术的时候，同处一个实验室的谭剑正在思考数据库到底能不能“自动驾驶”。</p><p></p><h2>AI FOR DB：让数据库实现“自动驾驶”</h2><p></p><p></p><p>1970 年代，DBMS 的出现简化了应用开发人员对数据进行统一管理的棘手问题。数据库通过关系型模型和 SQL 声明式语法，为事务、存储、查询、性能等一系列问题提供了一个高效的， 自动的解决方案。这个阶段数据库的优化工作聚焦在数据库内核的若干基础原子能力，例如针对索引， 或分区分表等“点”上的自动优化。</p><p></p><p>1990 年代，主流的 DB2，Oracle 等数据库推出更加全面的专家自动优化系统，可以在一个更大的决策空间中对不同配置下的系统性能进行估计，用来指导系统的自动优化。虽然在之前“点”上的优化进一步扩大到了“面”，但大多时候仍然高度依赖 DBA 的经验和人的手工操作。</p><p></p><p>2010 年代，云计算的兴起对数据库自动驾驶的能力提出了更高的， 更直接的要求。在云原生数据库的弹性平台之上，单纯依靠人力已经不可行， 迫切要在更丰富的“体”上， 对多样的数据库形态实现要求更高的“自动驾驶”。其实关于数据库自治的研究早在十几年前就已经在学术界提出，但真正的大规模商用落地则是在云计算成熟之后的近几年。谭剑团队推出的数据库自治产品 DAS， 自成为阿里云产品以来用户数和营收近两年一直保持在 70% 到 80% 以上的快速增长，就是一个直接的证明。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/57/57e06e8007271aa119c50bcbb25ce89b.jpeg\" /></p><p></p><p>Gartner 报告指出，预计到 2023 年全球 75% 的数据库都会跑在云上， 这与传统数据库的天下发生了本质变化。在这么一个复杂的系统环境中，数据库运行的过程中会出现各种性能问题，概括起来主要分为三类：</p><p></p><p>一是从可观测的角度，数据库性能指标多，难快速形成对故障的可解释性诊断；从可控制的角度， 难做到对实例的个性化运维。比如，DAS 支持的一个典型头部客户，一个 DBA 管理了数百个数据库实例，性能问题和故障告警很容易淹没在海量的观测数据之中，故障现场也很难捕捉，要做到故障定位和快速精准恢复就更难了。</p><p></p><p>二是数据库要做到 24 小时永不停歇，持续调优，保持稳定，传统上需要专业的 DBA 来负责，需要丰富的运维经验。但是，对于云上的大规模数据库，由于人力不足或者经验存在差异，并不总能保质保量的解决问题，而这种不确定性在要求很高的商用生产环境中是要尽力避免的， 因为“线上问题无小事”。</p><p>三是面对发展的业务对资源需求的动态变化，如何做好容量规划和资源优化， 避免人工频繁干预，降低运维成本，这些都是在云时代的背景下，企业和开发者对自治数据库的实质需求。</p><p></p><p>从技术层面来看，数据库自治是一系列原子技术的组合，广义上包含两大类：数据库外部运维和内核技术的智能化。外部运维就是最近流行的 AIOps，内核技术则是用 AI 技术提升数据库内核的某些性能。目前学术上对后者有很多前沿研究，比如 MIT 提出过使用深度学习网络代替 B-Tree 做索引， 在一些实例上取得了不错的效果；IBM 使用深度模型做 SQL 执行计划优化等。但是，目前离成熟的、大规模产品落地还有一段距离。</p><p></p><p>“当前，业界的实现路径呈现‘百家争鸣，百花齐放’的状态。我们采取的策略是‘外围包围内核’， 先从 AIOps 做起，逐步进入内核智能化的领域。不过有时候这两者界限并非那么明显，我们有的产品能力本身属于内核能力的一种外置。例如我们研发的外置 SQL 优化，对 MySQL 等开源数据库特别适用。商用数据库往往都有很成熟的执行器优化，可惜是几个传统头部数据库公司的商业机密。对开源托管类的数据库，往往是欠缺的状态，而我们提供的外置优化可以直接解决客户很多问题。”</p><p></p><p>数据库自治 DAS 基于全量 SQL 和性能指标的大数据能力，深度融合人工智能和专家经验，可以分成上游的可观测技术，和下游的可控制技术两个系统。上游包括例如异常 SQL 定位，信号异常检测，针对稀疏数据或倾斜分布的高效统计采样， 还有把观测技术的结果按场景进行归类，用来驱动下游的控制。下游技术包括例如 SQL 外置优化，限流，压测，调参，弹性扩缩容，资源调度，SQL 审计等。这是一个复杂的，包含众多原子技术的体系。通过单点技术的原子能力，加上体系上的构建的丰富的产品功能，和阿里云上独有的规模化的服务，三者的结合构成飞轮效应，呈现给用户智能化的数据库自治能力，让用户聚焦在自己的业务创新和发展上。</p><p></p><p>对自治中可控制技术的部分，数据库可能会通过改变物理设计 / 参数配置 / 物理资源等方式进行自动优化，可能会包含多种不同的优化方式。从这个角度来看， 阿里达摩院研发的数据库自治产品架构，采用了让多种优化服务通过解耦的方式协同满足客户的需求，在具体业务场景中各种服务会呈现不同的自治形态。</p><p></p><p>一是改变物理设计。例如改变表结构。可能开始 OLTP 表的设计不是特别合理， 如一些需要频繁更新的数据和以读为主基本不变的数据大量放在了一起。这从优化的角度会更多以推荐的形式推送给客户， 因为除非引擎产品直接支持混合事务分析 HTAP，那么改变表结构需要由客户来评估线上的影响， 再决定是否采纳。</p><p></p><p>二是优化参数配置。这是当前比较热门的研究方向， 数据库有数以百计的性能参数，通过专家经验可以总结出来一些核心的参数。这些可以与智能压测相结合，对参数进行优化。这里往往也涉及到在线变更的操作， 所以需要和数据库领域知识以及业务场景的分析结合起来。</p><p></p><p>三是对资源的优化。例如自动扩缩容， 一定程度上已经比较成熟， 阿里云数据库多个产品都推出了自动扩缩容的功能。另外一个例子是自动限流，当数据库突然出现 CPU 负载高， 造成响应异常等问题，我们会自动定位到造成问题的 SQL 语句， 对其进行限流， 甚至 kill 等操作， 通过止血来避免对其他任务造成影响。当然了， 这些主动运维的操作都需要客户的事先授权。</p><p></p><p>基于对不同路径的研究及可落地性的考量，阿里云数据库于 2020 年推出数据库自治产品 DAS，以期实现<a href=\"https://qcon.infoq.cn/2022/beijing/track/1308\">数据库的“自动驾驶”</a>\"。采访中，谭剑提到，数据库自治关注的是让数据库不但“可用”， 还要“好用”。终极的目标就是让数据库运维做到无人自动驾驶。提到自动驾驶， 大家就会想到 AI 技术，这在数据库自治上同样适用， 只不过这里的 AI 是更广义的角度，不局限于现在大家比较熟悉的深度学习技术， 还包括传统的控制， 统计， 优化等方法。更重要的是， 这些 AI 技术需要和数据库的领域知识结合起来。</p><p>从产品角度，数据库自治提供了自感知、自决策、自恢复、自优化、自安全的能力，保障服务稳定、安全和高效。</p><p></p><p>从技术角度， 谭剑提到“可以形式化借用编程 class 的语言来描述：DAS 是一个继承了多种数据库引擎内核能力， 实现了 AI 和大数据两个接口的一个子类”。DAS 支持的引擎包括 Redis、PolarDB、MySQL、PostgreSQL、Mongo、SQL Server 等多种内核，在原引擎基础上提供的一种增值能力。这对自建数据库也是一个很好的场景。在此基础之上，DAS 实现了两个接口 ：一是 AI 算法，提供智能化决策能力；二是大数据技术，基于用户全量 SQL 的日志数据和性能指标数据，实现感知和审计能力。上述两者之所为称为接口，是因为对不同的数据库引擎有具体的实现差异，不同的业务场景也有不同的产品需求。</p><p></p><p>“今年以来，系统的可观测性概念火了， 其实从数据库自治的角度， 还有一个对偶的概念叫做可控制性。事实上，二者在控制理论中存在严格的对偶关系。可观测性和可控制性两者的有机结合， 才构成了数据库自治的完整链路。”</p><p></p><p>这种能力具体到阿里云自研的 PolarDB 数据库上是如何体现的呢？PolarDB 是一个分布式数据库，支持水平和垂直扩缩容。从自动扩缩容 Auto Scaling 的角度，需要考虑是优化只读节点还是写入节点以及两者的关系；从负载的角度，需要进行针对性的优化；从迁移角度，当客户从其他数据库迁库转到 PolarDB 时，为了不影响在线业务和评估容量，可以使用 DAS 提供的智能压测能力，将原有数据库与目标数据库（PolarDB）做一次性能评测和容量评估。DAS 支持不同速度的回放，保障多次回放过程的数据库运行时状态一致，便于客户进行评测，这些都可以对 PolarDB 进行特色支持。</p><p></p><p>自治能带来一些什么具体的业务价值呢？流利说的基础架构负责人表示：“阿里云数据库的自治使得运维人效大幅提升， 实现团队转型升级”。捷顺的运维总监则表示：“自治大幅降低了数据库故障时间， 提高了系统的可用性。”可见，自治数据库已经在企业中落地并获得了实际的业务价值。</p><p></p><p>在谭剑团队忙着“落地”数据库自治技术的时候， 谢炯团队正被“空天数据”问题深深吸引。</p><p></p><h2>空天数据库引擎：天地乾坤，万象合一</h2><p></p><p></p><p>随着对地观测技术、物联网和数字孪生技术的快速发展，车联网 / 自动驾驶、视觉定位、物流配送等位置服务将随时在、随地在、随身在。与之而来，多维空天数据呈现爆发式增长，给数据存储、处理与分析计算带来极大挑战。在谢炯看来，空天数据有狭义和广义之分。狭义上，空天数据（aerospace data）主要来自天基和空基，例如，基于天基平台的 GNSS（全球导航卫星系统）数据和各类卫星遥感数据等，基于空基平台的倾斜摄影、航拍影像、视频数据等。广义上，则可以将空天数据定义为涵盖 Spatial（空，即地理空间）和 Space（天，即宇宙空间）的地、海、空、天各类与位置相关数据。天问一号携祝融号在火星的登陆为我们传来大量火星遥感影像和空间信息，使大家最直观地感受到来自地球之外的空天大数据。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/27/276afa10ac4b7bba7f0006fcda2df18d.jpeg\" /></p><p></p><p>谢炯在浙大教过本科，在中科院做过研究，也曾经和一群伙伴创过业，一直热衷于数据库技术。2018 年，他选择加入阿里云，这被他认为是人生中很重要的一个选择。</p><p></p><p>“当时，云计算发展迅速，我认为这代表着未来的演进方向，阿里云在国内做得最早，影响力最大，当时脑海里奔出四个字，“顺势而为”。此外，阿里很擅长将技术转化为产品，不仅内部有高德、菜鸟、本地服务等大量位置服务场景，通过阿里云这个平台能辐射更广阔的行业和客户，这和我做研究是不一样的。”</p><p></p><p>在他看来，传统的空间数据库（spatial database）主要处理点、线、面等空间几何对象，这类数据体量和结构复杂性相对可控。但现今遥感影像、时空轨迹、倾斜 3D 等大量位置传感型数据面临着数据结构复杂多样难以管理，数据动态变化要求更高维度计算，大数据和大计算场景性能不佳以及智能化需要多模态数据融合管理等一些列难题。这类新型多模态数据无论在存储上，还是计算上，都需要基于云的池化能力和弹性能力，才能在性能、成本、规模化上达到有效平衡。谢炯认为，将空天信息处理融入 PaaS 服务（Platform as Services），以云数据库与存储平台为核心解决空天数据的实时接入、高效存储和弹性计算，是支撑传统时空信息云化架构向纵深发展的必走之路。</p><p></p><p>在谢炯看来，这种架构演进具体可分解为平台即服务、多模融合、计算下推和云原生四个方向。</p><p></p><p>1 、平台即服务</p><p></p><p>是将空天数据处理内置于云上 OLTP 数据库、OLAP 数据仓库、NoSQL 多模数据库等不同系统，相比传统中间件方案在易用性、计算效率和事务一致性处理上存在先天优势。难点在于技术融合之后涉及数据库内核技术、图形图像技术和空天数据专业处理技术的跨学科交叉，这三个方向各自的技术门槛都不低，同时熟悉这三个方向的技术人才则是少之又少。</p><p></p><p>2、多模融合</p><p></p><p>是跨结构的多模态数据融合和一体化处理。有两个层次，首先在空天数据层次，不同空天多模态数据有非常大的结构差异和计算方式，只有模型打通，数据结构打通，算法才能真正打通（高效率）；其次是泛空天求解，把独立的空天数据处理能力嵌入到时序、图、文本等更多通用模型中，实现时序时空、空间 / 时空图、空间文本等跨界融合，这些不同模型之间数据结构和计算方式差异巨大，融合的挑战自然更大。</p><p></p><p>3、计算下推</p><p></p><p>是将空间信息系统业务关键计算下推数据库系统，让计算离数据更近。难点在于生态共建，已有上层的 CIM/BIM/GIS/RS 等涉空间系统都需要升级换代。谢炯谈到，差不多十年之前我就在推动这一架构转型，但面临很多挑战。直到最近几年，大家看到了这一技术架构带来的利好，不少行业厂商和数据库厂商才主动加入这一方向阵营。</p><p></p><p>4、云原生</p><p></p><p>新一代空天数据库一定要与云原生能力紧密结合，与公有云结合，并由公有云走向混合云。谢炯团队认为，云服务的本质是算力经济，数据要灵活，算法去补；而算法要灵活，算力去补，即借助足够弹性的算力来保障算法的纯粹性和普适性。公共云厂商在这方面具有独特优势，因为可以把空天计算能力下沉到存储、硬件等更底层次做垂向优化。</p><p></p><p>Ganos 是在综合以上四个方面基础上，实验室研制推出的首个云原生、跨数据库平台的空天数据库引擎。该引擎已内置于了云关系型数据库 RDS PG、云原生关系型数据库 PolarDB PostgreSQL、云原生数据仓库 AnalyticDB PostgreSQL 和多模数据库 Lindorm 中，将传统空间数据、新型空天数据和其他类型数据实现了多模一体化处理。用户可以按不同数据库产品独立使用，也可以基于产品组合构建空天数据库大数据一体化底座。</p><p></p><p>谈到 Ganos 与传统空间数据库的区别，谢炯认为主要有三点：</p><p></p><p>一是云原生，Ganos 从诞生就在云上，充分利用了云原生能力进行设计。</p><p></p><p>二是专业特性上突出了多维、动态、场景化。多维是既兼容传统 2D，也支持 3D；动态是指时空变化的表达能力，比如移动对象数据库；场景化是指视觉和行为信息处理，比如原生支持各类 3D 建筑的视觉信息处理，共享单车（移动对象）的开锁、闭锁事件描述等。Ganos 分别在 2018 年和 2021 年在业界首个推出了基于云的移动对象数据库和 3D 场景数据库，并在今年的 VLDB 2022 数据库顶会上作了整体介绍，获得了业界同行的认可。而传统空间数据库对多维、动态、场景化仅提供非常有限的支持。</p><p></p><p>三是跨数据库平台，Ganos 未来的目标是一站式空天 / 时空数据处理平台。</p><p></p><p>业界对于多模态数据的处理和支持大多处于早期落地阶段，虽然学术届开展了长期、广泛的学术探讨，但真正商品化提供服务的一直未见有成熟系统。空天数据是一类最典型，且应用广泛的多模态数据。早在 2018 年，Ganos 就结合 PolarDB 推出了完全自研的移动对象数据库，并在这几年快速迭代发展。这背后得益于与阿里内部场景的广泛结合，所谓的“母体带动”。&nbsp;在达摩院，Ganos 在支持包括自动驾驶实验室的小蛮驴，机器智能实验室的 AI Earth，XR 实验室的 3D 空间计算等各类创新场景；同时，Ganos 也在支持包括高德、网商银行大山雀、本地生活等各类位置相关业务场景。据不完全统计，云上 Ganos 引擎被创建次数达到 3 万 6 千多次，目前已广泛应用到航空航天、自然资源、共享出行、灾害应急、交通物流、远程银行、农业 / 海洋 / 水利以及社交 / 健身 /O2O 等总计 45 个不同行业 / 应用方向。天地乾坤，万象合一，这个“一”就是万物在时空中的位置，也正因此，空间计算业已成为数字化浪潮中的关键基础设施。</p><p></p><h2>达摩院眼中云原生数据库的未来</h2><p></p><p></p><p>过去几年，达摩院的前沿技术研究与阿里云数据库的产品商业化服务形成相互促进的“飞轮”，前沿技术研究保证了数据库产品技术及时更新换代，带给客户更多价值，同时大规模服务客户遇到的丰富场景推动达摩院不断在前沿技术研究领域获得突破。</p><p></p><p>这种良性互动的“飞轮效应”体现在阿里云数据库自研产品 PolarDB 等云原生数据库技术创新中：PolarDB 在业内率先实现了一种全新的架构——计算、内存和存储的三层解耦，首次实现内存池化。这种架构创新能够帮助下一代云原生数据库显著提升性能和弹性，大幅降低成本。</p><p></p><p>在汪晟团队的努力下，阿里云成为全球仅有的两家实现了全加密数据库云服务商业化输出的云厂商之一（另外一家是微软）；在谭剑团队的努力下，达摩院丰富的智能算法在数据库领域的深度应用，让 PolarDB 等数据库产品拥有了“自动驾驶”能力，方便客户简便、智能、高效地使用；在谢炯团队的努力下，PolarDB 可以高效管理多维、动态、场景化的空间 / 时空 / 网格数据，更好地支持数字孪生城市等复杂 3D 多模态数据管理场景。</p><p></p><p>接下来，汪晟、谭剑和谢炯所在的数据库与存储实验室将继续为云原生数据库的未来努力着。</p><p></p><p>今年初，中国信通院对数据库领域关于智能化数据库、关系型数据库的安全能力，自动运维能力，全密态、防篡改等标准均在起草中，达摩院数据库与存储实验室深入参与了每一个标准的制定。</p><p></p><p>在全密态数据库的技术层面，汪晟团队接下来将会思考如何做出一个可信密态的数据管理体系，涵盖数据全生命周期的安全性，这是从技术视角要解决的一个问题；在业务价值的层面，团队希望能够将当前的能力进一步标准化，让不同的数据库均可无缝接入到该体系；在生态建设层面，将密态数据推广到数据管理的各个层面，从数据收集到数据处理，再到数据共享等环节都能通过生态化共建的方式进一步完善现有能力。</p><p></p><p>DAS 目前已经是首批通过信通院数据库管理系统智能化标准的两大厂商之一。而且，该标准和 DAS 目前的产品能力高度一致。未来一年，谭剑所在团队会主要解决如何更好地将自治技术与数据库领域知识结合，用来解决复杂的根因诊断问题，将数据库领域的知识和经验沉淀下来，和 AI 结合让客户真正能够从可解释性的角度更好地运维和优化数据库，并理解其运行状态。除了 AI for DB 的数据库自治，谭剑团队最近也推出了 DB for AI 产品，将 AI 的能力直接构建在 DB 的内核之上，让客户通过数据库直接获得原生的 AI 能力，为其提供价值挖掘能力和解决方案。例如今年 7 月，通过 PolarDB 推出的 Polar for AI 产品，可以对数据库典型场景和客户提供各种 AI 解决方案。</p><p></p><p>在 Ganos 的未来发展上，谢炯团队会面向云原生和云孪生结合，朝向大规模空天数据一站式管理方向演进。系统层面，向下会从多模态并行查询、扩展存储引擎等方向发力，向上会从算法层面针对轨迹、影像、3D 等新型空天数据实现高性能分析计算，把整体能力做深做精；我们会重点把云和 LBS、数字孪生 / 元宇宙等业务结合，借助数据库产品与行业 ISV 开展更广泛的生态合作，把解决方案做好，实现从技术到产品到产业化应用的快速迭代。</p><p></p><h2>在达摩院做科研是种什么体验</h2><p></p><p></p><p>（因本文三位嘉宾均来自数据库与存储实验室，故此处只从他们的视角谈科研体验。）</p><p></p><h3>做研究，拥有自由探索的空间</h3><p></p><p></p><p>从数据来看，阿里云数据库团队过去几年在国际顶级会议上发布的论文数量不断创下新高，从 2018 年的 2 篇增长到 2022 年的 15 篇。在刚刚结束的数据库顶会 VLDB2022 上，数据库与存储实验室向 Industrial Track 投稿的五篇论文被全部接收（该 Track 全球共接收 22 篇），这也意味着实验室的相关探索得到了业内的广泛认可。实验室内部对论文的质量审核极其严格，这也是一投即中的重要原因。</p><p>从实际感受来看，三位嘉宾认为实验室的整体氛围还是不错的，实验室总负责人李飞飞在对技术方向的把控上十分到位，并会给予大家自由的探索空间，达摩院的品牌效应及阿里内部广泛的落地场景给研究带来了极大优势。</p><p></p><p>“做研究和做产品不同，团队氛围非常重要，产品商业化之后可以立刻收到市场反馈，但研究有时候没那么快与商业产品相结合，实验室中的资深专家们会及时对大家的工作成果给出评价反馈，让大家更容易认可和强化手头工作的研究价值。”汪晟在采访中表示。</p><p></p><h3>实验室 70% 成员是博士，欢迎交叉学科人才加入</h3><p></p><p></p><p>数据库与存储实验室内部有很多相对年轻的成员。“技术的未来需要更多颠覆性创新，因此我们非常欢迎年轻的同学加入进来”。</p><p></p><p>目前，该实验室 70% 左右的同学都是博士，来自海内外各大名校，研究方向也非常多样化。此外，虽然实验室的定位是数据库，但并不是只接收数据库背景的人才，也欢迎交叉学科的同学加入。</p><p></p><p>嘉宾介绍：</p><p></p><p>汪晟，计算机博士，毕业于新加坡国立大学，达摩院数据库与存储实验室系统与安全方向负责人，全面负责下一代云数据库安全可信与隐私计算体系的科学研究和产品落地。研究领域为大规模实用数据管理系统，主要研究兴趣包括云原生数据库系统、隐私与机密计算、云数据库安全、数据分析系统、区块链等，在 SIGMOD/VLDB/ICDE 等数据库与存储领域顶级会议上发表学术论文近 40 篇，获得 IEEE ICDCS 2020 最佳论文奖、ACM MM 2015 最佳论文奖提名。</p><p></p><p>谭剑，电子与计算机系博士，毕业于美国哥伦比亚大学，阿里云数据库自治服务和达摩院智能数据库方向负责人。曾先后任职 IBM 沃森实验室研究员和俄亥俄州立大学电子工程与计算机系终身制教职。研究兴趣包括分布式计算系统的资源与性能优化，AIOps 系统设计与实现，随机系统的数学建模与算法分析，优化算法的理论与应用。五次获得最佳论文奖，在俄亥俄州立大学曾获美国自然科学基金支持，并在多个著名学术会议中任执行委员会成员。</p><p></p><p>谢炯，GIS 系统博士，毕业于浙江大学，达摩院数据库与存储实验室空天数据库方向技术研发负责人，CCF 计算机协会数据库专委会委员，中国测绘学会智慧城市专委会委员。近十五年来聚焦多模态数据处理和空间数据库系统研究，感兴趣于三维对象数据库、遥感图像数据库、轨迹大数据处理和 NoSQL 时空分布式系统等领域，研发成果曾获得了科技部国产优秀软件奖、国家科技进步二等奖、中国电子学会科技进步一等奖等奖项。</p><p></p><h4>内容推荐</h4><p></p><p></p><p>本文选自<a href=\"https://www.infoq.cn/minibook/EQzDrPI1dT9G8V6alV1I\">《中国卓越技术团队访谈录》（2022 年第三季）</a>\"，本期精选了阿里达摩院数据库、得物、华润云、民生保险、众安 DevOps、字节跳动 App Infra 等技术团队在技术落地、团队建设方面的实践经验及心得体会。</p><p></p><p>《中国卓越技术团队访谈录》是 InfoQ 打造的重磅内容产品，以各个国内优秀企业的 IT 技术团队为线索策划系列采访，希望向外界传递杰出技术团队的做事方法 / 技术实践，让开发者了解他们的知识积累、技术演进、产品锤炼与团队文化等，并从中获得有价值的见解。</p><p></p><p>访谈录现开放长期报名通道，如果你身处传统企业经历了数字化转型变革，或者正在互联网公司进行创新技术的研发，并希望 InfoQ 可以关注和采访你所在的技术团队，可以添加微信：caifangfang842852，请注明来意及公司名称。</p>",
    "publish_time": "2022-09-02 10:19:04",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "拒绝“悬浮”，区块链如何变得更加“务实”？| InfoQ《极客有约》",
    "url": "https://www.infoq.cn/article/1H4sBEj6P8IqZyjrk9Ql",
    "summary": "<p>2019年10月，中共中央总书记习近平在主持第十八次集体学习时强调，要把区块链作为核心技术自主创新的重要突破口。自此，区块链上升为国家战略。</p>\n<p>从全民热议至今过去两年多的时间，区块链行业发生了巨大变化。根据赛迪区块链研究院数据，区块链全年产业规模由2016年的一亿元增加至2021年的65亿元。目前，我国区块链相关机构大多以提供软件开发及信息技术服务为主，其中金融行业是区块链应用场景最为丰富的领域。</p>\n<p>因此本期《极客有约》，InfoQ邀请到了微众银行分布式商业科技发展部副总经理、区块链负责人范瑞彬，一起聊一聊如今的区块链如何更加“务实”地发挥自己的作用。</p>\n<p><strong>直播大纲：</strong></p>\n<p>区块链行业发生了哪些变化？<br />\n有哪些离日常生活很近的区块链应用？<br />\n区块链的商业价值是什么？<br />\n如何入门区块链</p>\n<p><strong>主持人：</strong><br />\n褚杏娟  InfoQ编辑</p>\n<p><strong>对话嘉宾：</strong><br />\n范瑞彬，现任微众银行分布式商业科技发展部副总经理，微众银行区块链负责人。</p>\n<p>加入微众之前在腾讯任职十余年，腾讯T4级专家，在海量分布式后台架构设计以及移动互联网业务架构设计方面有丰富经验，曾任手机QQ技术总监，长期负责手机QQ后台整体建设，完整地经历了手机QQ从萌芽到亿级在线的整个发展过程，见证了十多年来移动互联网的高速发展。</p>\n<p>从2015年开始带领微众银行区块链团队进行联盟链的技术攻坚，打造了业界领先、全面开源的联盟链核心技术体系，并实现了完整的国产化支持，助力国家推进关键技术安全可控战略的落地。联合众多合作伙伴共建开源生态圈，目前开源生态已经汇聚了3000+ 企业/机构 、70000+ 个人成员，构建了完整的区块链人才培育体系，支持了金融、医疗、司法、农业、制造业等多个行业的数百个区块链应用落地，推动最大最活跃国产联盟链开源生态圈的形成。</p>",
    "publish_time": "2022-09-02 14:17:12",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "RTC 技术的试金石：火山引擎视频会议场景技术实践",
    "url": "https://www.infoq.cn/article/KQF6vrZSIuMOZ5VWtpLH",
    "summary": "<p></p><p>视频会议场景一直被认为是<a href=\"https://www.infoq.cn/article/gRZzIZw7qv6LlHY1UoRi\">RTC</a>\"最具挑战性的场景，一方面，它对抗弱网、低端机适配、降噪、多人上麦等都有极高的要求，对 Web 端的要求也远高于其他场景；另一方面，有很多孵化自会议场景的技术能力最终都被复制到了其他场景。</p><p></p><h2>RTC 在会议场景的独特挑战</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/69/69072591ae7558fbd28d48902d43ddbb.png\" /></p><p></p><p>为什么说“视频会议”场景对于 RTC 的技术挑战最大？相比于<a href=\"https://www.infoq.cn/article/LsSe5oPGClMmImeAsXol\">其他行业和场景</a>\"，“视频会议”中的 RTC 到底独特在哪？</p><p></p><p>首先，会议场景的需求是更为复杂的，这里举 4 个例子。</p><p></p><p>第一个是「自由开麦」。在视频会议中，每一个参会方都可以自由选择是否打开自己的麦克风和摄像头，这是视频会议非常基础的功能，但随着参会人数的增加，技术实现会越发复杂。行业内 RTC 一般可以实现五十到上百人的自由开麦，超过了这个人数之后就需要主持人来控制麦位。飞书会议要求我们支持 1000 个参会方，如果 RTC 支持自由上麦的人数低于 1000，飞书会议的用户使用起来就会非常不方便（虽然所有参会人同时开麦的极端情况比较少见，但是业务的需求是希望主持人不要过多“干预”会议——不断地控制参会人上麦、下麦，把发言能力分配给想发言的人）。假设一场会议里有 1000 个参会方，但只有 50 个麦位可以发言，主持人就要把想说话的参会人不停地“挪”到这 50 个麦位之中。为了让主持人知道谁想发言，还需要引入一些沟通机制，整体操作成本非常高。RTC 为什么会限制拥有上麦能力的用户数量？如果不限制可以上麦用户的数量，发布/订阅流模型的算法复杂度就是O（n^2），即，如果有 1000 人参会，就会产生 100 万 音视频流发布/订阅关系。短时间高频的上下麦操作会造成服务端信令风暴，所以上麦人数才需要加以限制。可是现实中，一些大型会议的规模往往会超过 1000 人，甚至达到几千、上万，我们不该因为技术的限制而牺牲用户的体验。</p><p></p><p>第二个是「自由布局」。视频会议一般会提供多种视图布局类型供参会方选择，从 1*1 全屏，到 2*2 四宫格，3*3 九宫格，到 7*7 四十九宫格……这还只是普通的宫格，还会有一些其他布局，比如演讲者模式、侧边栏模式等。画面布局类型的丰富让每个参会者都可以自己选择自己喜欢的布局，但这样一来，同一个会上，有开四宫格的，有开九宫格的，有开演讲者模式的，视频发布者就需要决策到底发布什么样的分辨率。如果发布的分辨率过大，对于选择多宫格的订阅方来说，分辨率就过剩了，同时还造成了极大的下行带宽和设备性能压力——试想一下，一个订阅方同时拉了 49 路 1080P 的视频，什么样的神仙设备和带宽都扛不住；如果发布的分辨率过小，对于全屏或者演讲者模式这样的大窗口来说，清晰度就会不足，用户体验会受到影响。严格来说，每一种布局都应该有一个最合适的分辨率。在多人会议中，如何在有限的带宽与设备性能下，尽量提供灵活多样的画面布局，是一个很大的挑战。</p><p></p><p>第三个是「屏幕共享」。这个功能大家比较容易理解，它的挑战在于，屏幕共享虽然也是视频流，但是它的视频画面特点和我们摄像头拍摄的视频画面特点是不一样的。简单来说，屏幕共享对画面的要求更清晰，要能看清楚很小的文字，但是对于帧率的要求并不高。对于编码器来说，需要决策什么时候编高帧率的视频，什么时候编低帧率的视频，这是关键。</p><p></p><p>最后是「Web 入会」。很多时候，视频会议软件的用户是“临时用户”，比如用视频会议去参加一场面试，或者是合作伙伴用你们公司的会议软件来参加一场会议…这些“临时用户”可能并不希望去安装一个会议 App，用 Web 入会就是一个非常好的选择。但是 Web 对音视频有很多限制，而对视频会议的需求和体验的要求一点都没少，怎么才能把 Web 入会的体验尽量追上 Native 的体验？</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/30/307f64768600d17c0e65ba6d0d441485.png\" /></p><p></p><p>除了业务需求更加复杂以外，视频会议场景所<a href=\"https://xie.infoq.cn/article/370e5545b3ff62aae40aa3394\">面临的环境</a>\"也更为极端。</p><p></p><p>过去，开视频会议都是在专业的会议室里开，有很多专业的会议硬件设备来支撑会议体验，环境是相对比较好的。但现在，开会环境早已不限于会议室了，会议环境的多样性让 RTC 面临了很多新的挑战。这几年，疫情让我们居家办公的时间更多了，在家里开视频会议成为了很普遍的场景；一些经常出差的人——他们往往也是会比较多的人——在路上、车上、高铁上甚至飞机上通过手机参加视频会议也非常普遍。</p><p></p><p>会议环境多样性为 RTC 带来的挑战主要可以分为以下四大类：首先是极端弱网，俗称“用户网络差”。这种情况非常常见，尤其是不在公司会议室里开会，弱网情况更常见；其次是弱设备，也就是“设备性能不足”。如果参会设备不是专业视频会议硬件，就会承担更多的性能压力，尤其当参会人开启美颜或者虚拟背景这样高消耗的功能之后，原本可以开会的设备也会出现性能不足。现在在视频会议中使用虚拟背景是一个非常高频的功能，大家看我现在视频的背景就是一个虚拟背景。再者就是会议场景的噪声类型会更多，除了会议场景常见的键盘声之外，如果你不是在会议室开会，就会伴随各种各样的噪声：空调的声音、开关门的声音、隔壁装修的声音、附近人说话的声音、小孩的哭闹声，室外的喧嚣声……最后一个挑战是光线差。离开专业会议室的环境之后，可能会面临严重的光线不足、背光等问题——本来家里的光线布局就不是为了居家开会所设计的，更不要说在户外或者交通工具上开会了。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b7/b7bca41d4eb9ac483195dcdaba54ca07.png\" /></p><p></p><p>从技术角度看，RTC 技术最初就是从视频会议中抽象剥离出来的，后来逐渐应用到会议以外的领域，所以很多 RTC 的新场景其实就是从视频会议中迁移出来的。换句话说，RTC 在视频会议场景的「独特性」，其实也可以认为是一种「领先性」。</p><p></p><p>从最近几年的行业发展来看，不断有从会议场景技术溢出到其他行业的案例。之前特别热门的「大班小组课」，其实就是会议中的「分组会议 Breakout Room」。再比如现在很火的 「3D 空间音效」，其实最初的应用是高级视频会议产品中的「听声辨位」，HP 2005 年发布的 Halo 就支持这个功能。最后说说「千方会议」。我们在去年 6 月已经对外介绍了我们做的“千人上麦”能力，在今年 2 月份正式对外发布了这个功能。当时很多朋友不理解我们为什么要做那么大的上麦并发，实际上是因为，我们看到不仅视频会议有这个需求，其他场景也陆续出现了这个需求，像在线教育大班课中的齐声朗读或者抢答，大型吃鸡游戏中的世界语音，还有现在正在发生的大型 VR 社交，这些场景需要自由上麦的人数很容易突破几百甚至上千。既然「千方会议」可以支持大型视频会议，何不做成 RTC 的标准能力，来解锁各行各业中“自由上麦”人数的瓶颈，发挥更大的价值呢？顺便提一句，目前我们还在进一步突破上麦人数上限，实现「万方会议」甚至更多。</p><p></p><p>「千方会议」过去已经和大家介绍过了，今天不再重点展开。接下来和大家分享视频会议对 RTC 的几个新的挑战和我们的思考实践。</p><p></p><h2>复杂光线下的视频体验</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/94/947523cb832b21c699eb22a3427d8bf1.png\" /></p><p></p><p>第一个话题是「复杂光线下的视频体验」。</p><p></p><p>前面提到，很多用户入会时所处的位置可能并没有很好的光照条件，比如晚间的户外，光线会严重不足；比如在室内，如果光源的位置不佳，会形成逆光或者侧光。恶劣的光照条件会严重影响视频体验，但我们一般人开会也不会像专业主播一样准备专用的打光设备，因此，一旦光线不好，拍摄效果就会差，而一旦拍摄基础效果差，仅仅靠视频后处理技术是没有办法很好地解决视频体验问题的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/28/2894ad493a5dd9c79beff4ddf1aa69df.png\" /></p><p></p><p>为了解决这些问题，我们引入了一系列的相机技术，包括自动对焦、自动曝光这些比较基本的相机技术。RTC 场景和其他场景有个不一样的地方，画面中一般都是人像占据主体，而当画面中人像占据主体时，如果不做特别处理，由于摄像头本身是“平均测光”的，当人像处于逆光环境时，由于背景很亮，会导致曝光不足，人脸会显得过暗。因此，我们在 AE 的基础上又增加了人脸检测算法，即 FaceAE，当检测到人脸时，把“平均测光”优化为“根据人脸检测结果”来做曝光处理，解决画面过曝、欠曝的问题。为了实现最佳效果，我们与国内外很多手机和芯片厂商保持良好的合作，把硬件的相机功能和我们自研的算法进行深度结合，让每一款设备都达到最佳性能。目前我们已经对线上 18000+ 款机型进行了适配，覆盖低中端各类机型。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4f/4f6ac548c0a67f51ca872ed63036e328.png\" /></p><p></p><p>我们使用了一些知名会议或社交 App 来和我们的拍摄效果做对比，大家可以感受一下基于 FaceAE 算法优化过的相机效果。第一组对比图是一个户外傍晚背景，画面中有一盏路灯，可以看到右边使用 FaceAE 算法优化过的采集效果，人脸更亮，天也更蓝，画面整体感觉更舒服。第二组是室内暗光场景，左边是个黑脸，右边人脸的亮度就比较正常；第三组是白天逆光场景，这种场景的背景很亮，普通 AE 给的曝光就会不足，人脸会显得非常黑，而使用 FaceAE 优化过的相机效果就会比较亮，五官也能看清晰；第四组是室内侧光场景，这种场景照出来很容易阴阳脸，可以看到左边图上一半的脸都是黑的，眼睛都看不见在哪儿，而右边虽然不可避免还是存在阴阳脸，但画面更亮，五官都能看清了。</p><p></p><p>以上是我们仅仅靠相机采集优化的效果，在没有开启任何美颜算法的情况下，就能达到比较理想的画质效果。而且，由于 FaceAE 调用的都是系统底层的能力，没有使用算法，不会引入额外的性能开销。当然，开启美颜之后，还能再锦上添花。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/04/049fd64b6cc1ff678df0cfa0b5b4b562.png\" /></p><p></p><p>前面提到会议场景的技术溢出，「相机采集优化」也是如此，它对于其他非会议场景也有非常广泛的应用。在视频社交场景中，参与平权聊天的大部分用户都是非专业主播，大家就是临时上线聊天，不会特别准备好的光源或打光设备；在直播连麦场景，主播是专业武装的，但连麦的观众或场外嘉宾往往是非专业主播，也不大会考虑光线的问题；在互动课堂场景，老师端一般有较好的开播条件，但学生端的条件就会差一些；还有一个是我们最近发现的很有趣的场景，也是我们遇到的一个真实场景——健身小班课，它和普通的“互动课堂”场景有点像又有些不一样，虽然健身老师可以算得上是“专业主播”，但传统主播用的打光设备没办法照顾到整体授课的场景，图上的瑜伽老师在客厅开播，客厅连着阳台，形成了一个大逆光场景，导致瑜伽老师的脸完全是黑的，影响与学员的互动效果。</p><p></p><h2>屏幕共享的优化</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b3/b379a5246cf87bb84570d446863060cd.png\" /></p><p></p><p>第二个话题是「屏幕共享的优化」。</p><p></p><p>屏幕共享是视频会议场景最常用的功能之一，用户对于共享文字/PPT的要求一般是高清晰度，对于共享视频内容的要求一般是高流畅。我们比较容易做到根据共享内容的文件属性来决定是“清晰度优先”还是“流畅度优先”的编码策略，比如共享 PPT 时自动切换为“清晰模式”，共享视频时自动切换为“流畅模式”，但这样设计会遇到一些问题：如果用户的 PPT 里嵌入了一段视频，在播放这段视频时理应追求“流畅模式”；如果用户视频其实是一段 PPT 的教学录屏，里面有大量的时间在播放静止的文字和画面，这时候理应是“清晰模式”。也就是说，我们共享的内容，它是是静止的还是运动的，是由用户决定的，而不是程序可以决定的；我们也不可能要求用户在共享的过程中手动地去不停选择切换当前的编码模式，这样会严重影响用户体验，而且用户很可能会忘记切换。</p><p>业务层面不能通过用户的输入来解决问题，这个挑战就落到了 RTC 上，RTC 要如何帮助用户及时调整最佳模式呢？</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9f/9f8fc1087758dabb1571fd6cac0d725f.png\" /></p><p></p><p>我们研究出了一个“智能编码模式”，在屏幕共享的过程中，让 RTC 自动识别用户传入的视频内容类型，并且不断自动调整最佳的策略。</p><p></p><p>我们来看一段视频。视频里的一个参会人在共享屏幕，一开始，他在浏览网页，共享画面是静止的图片和文字，所以分辨率非常高，帧率和码率非常低；然后参会人打开了一个视频网站，共享内容变成了一段视频，对应的帧率和码率慢慢地爬升，为了平衡性能，对应的分辨率也在慢慢地下降，帧率最后爬升到了 30 帧；然后他又换了一段视频播放，这段视频只有中间部分在动，运动部分占据画面比较小，所以帧率没降，但码率慢慢降低了；最后，他又回到了最初的网页，帧率和码率逐渐下降，而分辨率又慢慢地回升到了高清模式。这段视频演示了在共享内容类型切换时“智能编码模式”的自动调整策略。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/87/875e81917b6ea8254611848c68f38c4c.png\" /></p><p></p><p>“智能编码模式”带来的一个重要收益就是线上平均分辨率的提升。一些共享内容原来被系统认为是“视频”而采用了“流畅模式”，现在被算法纠正成了“高清模式”（实际上视频会议场景共享静态内容的概率更大），线上平均分辨率有了翻倍的提升。同时，因为系统永远选择最合适的编码策略，因此线上屏幕共享场景下的整体 CPU 消耗降低了 20%。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/51/518eaedf55b260ecbdebed1cfe2ed4ea.png\" /></p><p></p><p>我们来看看「屏幕共享」在非会议场景的应用。过去我们认为「屏幕共享」只应用在会议场景，随着着“线下活动线上化”的趋势，「屏幕共享」在会议以外的应用也越来越多了。在线教育就不多说了，它本来就是视频会议场景的一个子类，除了普通的“屏幕共享”以外，在线教育还有一个“云端录屏”的需求——把软件的 UI 一起录下来回看或作为直播对外分享，本质上这也是一种特殊的“屏幕共享”——通过在云端模拟一个虚拟学生上课，在云端打开应用软件的界面来进行「屏幕共享」。在远程协助场景，通过「屏幕共享」，子女可以告诉不会使用手机或智能电视的父母如何操作，甚至直接远程操作；在 VR 直播教学场景中，老师通过 VR 设备在虚拟空间进行操作，学生通过 VR 设备跟随老师的视角观看和学习，沉浸式、实时互动式的屏幕共享可以极大地提升教学效果。</p><p></p><h2>多宫格视图体验的提升</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ec/ec6037b8715c765796d3fe9d85403dc3.png\" /></p><p></p><p>第三个话题是「如何提升多宫格视图的体验」。</p><p></p><p>多宫格视图也是视频会议中的基本需求，它让尽可能多参会者的视频被播放出来，可以提升参会互动性，但也非常容易引起客户端性能和带宽的不足，因为你要订阅的视频流变多了。对此，RTC 一般会提供动态“弱网降级“和“性能降级”，但在视频会议中，一般的弱网降级和性能降级是不够的。</p><p></p><p>这个场景主要有三个特点：一是每个用户都可以自由选择自己喜欢的视图布局；二是不同布局对应不同阶梯的分辨率；三是任何一路流都可能会面临从高到低各种档位的分辨率的订阅请求。目前行业里 RTC 普遍支持「大小流」，也就是两档分辨率，但两档分辨率在视频会议中远不够用，而增加档位又会大大增加性能开销，如何既能灵活支撑用户自定义会议视图布局，又能兼顾设备和带宽性能？</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/05/054440fbd2dcdaf6dba34607b51a7add.png\" /></p><p></p><p>针对这个场景，我们设计了「10 级档位的 Simulcast」。既然两档分辨率不够，我们就来增加档位嘛。这里的主要难点在于，对于发布者来说，他相当于要做 10 路视频流的编码，这对于发布者的性能消耗是巨大的，绝大部分设备的性能是不够的。所以在实现的时候，我们会对档位进行聚合分组，最后分成四档，分组的原则是“按分辨率订阅人数的权重排序，尽量照顾更多人的体验需求”。也就是说，我们优先选择订阅人数多的分辨率进行编码，订阅人数少的排在后面。如果设备性能跑满了，档位不够分，就归并到最接近的已编码的分辨率档位。除此以外，动态弱网降级和动态性能降级也会与 Simulcast 结合，如果订阅端订阅太多流或者性能不足了，那么就自动降到下一个档位。相比大小流两个档位， 多档位的 Simulcast 降级会比较平滑，即不是直接从 1080P 降到 90P 这样的低分辨率，而是一档一档地逐档降级，直到降到一个最合适的档位。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6d/6d1cab567ca39c80b8b1a9ae78625097.png\" /></p><p></p><p>我们来看「Simulcast」的线上数据表现。「Simulcast」的主要作用是提升实时画面的清晰度，尤其是多宫格视图的清晰度。我们看到，2*2 宫格的清晰度从 360P 提升到了 540P，3*3 宫格的清晰度从 180P 提升到了 270P，一些中高端手机全屏模式下的清晰度从 360P 提升到了 720P，线上平均分辨率提升了 16%。在提升清晰度的同时，我们也要平衡一些其他的指标。在实时性方面，端到端延时与原先水平保持持平；在流畅性方面，视频百秒卡顿率也没有下降。「Simulcast」的最大挑战是给发布端带来的性能开销，但我们看到性能开销的上涨是非常轻微的，基本不影响发布端的性能。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/31/31f98c1a5e2a713889abc1fd8ddca6a2.png\" /></p><p></p><p>我们再看一下「Simulcast」在会议以外场景的应用。比如连麦场景，随着连麦的人数越来越多，“多视图布局”的需求也应运而生，在社交场景，我们叫它“动态麦位”。在“万物互联”的物联网生态中，各种类型的设备都在使用 RTC，小到手表，大到智慧电视，中间还有手机、Pad、电脑，电视机也有各种尺寸，想象一下，如果我们用手机和父母、小孩通话，父母使用电视，小孩使用手表，如果让电视和手表订阅相同分辨率的同一路视频是极不合适的，这个场景也适合「Simulcast」方案。</p><p></p><h2>实现会控的关键技术</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e9/e9e4f096fff943e7beaf3c883d78e13b.png\" /></p><p></p><p>第四个话题是关于「如何做好会控」，对于 RTC 来说，做好会控的关键是什么？</p><p></p><p>在会控中，和 RTC 相关的一个难点是“音视频状态和用户状态的一致性”的问题。比如一个用户在系统上显示是麦克风开启的状态，如果状态是错误的，实际上他是无法上麦的。反过来，系统上显示他已经闭麦了，但实际上他还在上麦，如果他说了一些不希望被会上其他参会者听到的话或者声音，就会涉及到严重的隐私泄漏问题。还有一个难点是“用户状态变化的及时性”，比如主持人要让某个人闭麦，当他操作闭麦该人的动作之后，需要能够马上、真正地把麦闭掉，一旦及时性做得不好，不仅让参会人的体验不好，还可能造成主持人无法及时控场的问题。</p><p></p><p>这两个问题的关键在于“信令的可靠性”，我们如何保证信令必达的同时，还拥有极低的延时，并且与音视频状态同步？</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/34/3455f1c9a9c90c0ceba2f97a906638e0.png\" /></p><p></p><p>我们的解决方案是，让信令复用 RTC 音视频流的传输链路与弱网对抗策略，确保音视频和信令的到达率相同，保证音视频状态的一致。</p><p></p><p>我们为信令定义了几个指标，一个是 200ms 到达率，一个是总到达率。总到达率我们做到了 100%——要确保“消息必达”，这也是信令的基本要求。而且，我们还要做到“低延迟”的“消息必达”，这就要求信令是在一定的时间范围内到达的，否则即使信令到达了，也会失去一部分的意义。我们选择了「200ms 到达率」这个指标，目前这个指标的线上数据表现是 98.6%，也就是说，在 98.6% 的情况下，信令可以在 200ms 之内到达目的地。</p><p></p><p>我们再看一下延时方面的指标。目前，「端到端平均延时」指标表现是 51 ms，但「平均延时」这个这个指标其实比较宽松，我们会看一个更严格的指标，就是「端到端延时九十分位值」，简称「PCT 90」，我们线上 PCT 90 的指标表现是 117ms，也就是说，线上 90% 的用户的端到端消息能够在 117ms 以内到达。能够做到这样的到达率和延时，主要就是因为我们的信令复用了 RTC 的传输链路。复用 RTC 传输链路还有一个很重要的好处 ，就是保证音视频数据和信令数据的延时和到达率是一致的，这样，用 RTC 信令来实现会控就不会出现状态不一致的问题，因为极端弱网是不可避免的，最极端的弱网就是断网，我们现在说到达率是 100%，前提是网络还是通的，如果断网了，任何信令都不可能传输了，而且数据上还无法统计到。但是，如果音视频和信令采用同一条链路，假设真的断网了，音视频传输和信令传输都无法到达，要断一起断。这样的话，不管是什么样的网络情况，音视频状态和用户状态永远都是一致的，我们做会控的目的也就达到了。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fa/fa2ea1b454e2462c296fef2b74d0c695.png\" /></p><p></p><p>我们打磨的「实时信令」在其他领域也有广泛的应用。我们刚刚说到会控，其实在很多 RTC 领域中，多多少少都存在一些会控的逻辑，像互娱社交场景中也会存在房间管理，如果一些主播、连麦嘉宾、上麦观众说了一些不合适的话，或者做了一些不合适的行为，管理员就需要制止，简单点就是禁言或踢人，如果制止不成功或不够及时，可能会引起更严重的问题。除了会控以外，「实时信令」也可以用到一些新的玩法中。这里举一个「一起看抖音」的场景，抖音上就有这个功能，两个朋友之间可以连麦一起刷视频，“主态”刷到哪儿“客态”的视频进度就跟到哪儿，两边的视频延时低于 100ms，而实现视频滑动状态主客态同步业务逻辑的技术就是「实时信令」。</p><p></p><h2>Web 端实现复杂算法的新解</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/50/5030b5bad206573c69b8a9a2b7d3961a.png\" /></p><p></p><p>最后一个话题是关于「Web 端实现复杂算法的新解」。我们先看一下 Web 端有哪些性能消耗的“杀手”。我们知道，RTC 的编码是很耗性能的，但和美颜、特效、虚拟背景比起来还是小巫见大巫。这些功能在视频会议场景中已经成为“刚需”，几乎每个居家办公的参会人都会使用，我们要如何既保证客户端设备性能，又达到媲美 Native 的效果呢？</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/46/46dccf2994f78f2b8b458677006d9f1a.png\" /></p><p></p><p>我们做了一系列的思考和尝试。</p><p></p><p>第一种是业内的普遍做法——在 Web 本地加载这些算法。Web 本地运行算法对于设备 CPU 的消耗都非常大，而且由于 Web 浏览器本身存在性能瓶颈，哪怕设备再好，在 Web 端做特效的效果都可能打折扣，一些复杂的特效甚至可能无法运行。浏览器的兼容性也是一个问题。还有一个问题是比较容易被忽略的，由于 Web 会把代码和模块下载到本地运行，如果在本地加载特效算法就会增加包体，支持的算法越多，包体就越大，它会影响页面加载速度，算法的丰富性也会受到限制。</p><p></p><p>我们也研究了业务端是如何解决这个问题的。行业里，业务端会使用虚拟摄像头的方案。虚拟摄像头自带美颜功能，Web 通过虚拟摄像头来采集视频，这个采集的视频已经经过了特效处理，因此浏览器不再需要有额外的性能消耗。但这种操作有个问题——用户必须安装虚拟摄像头，这和 Web 端追求“免安装即用”的便捷性理念是违背的。一般会采取这种方案的用户是专业主播，他们本来就在电脑中安装了很多美颜、虚拟摄像头的软件，可能是因为临时换一个网页开播的平台做直播所以使用虚拟摄像头，像参加面试、临时会议这种场景，普通人可能都不知道有“虚拟摄像头”，因此这种方案的适用性是比较局限的。</p><p></p><p>通过结合 RTC 的优势，我们探索出一种新的解法——边缘渲染。边缘渲染的原理是，当发布者在本地采集了视频之后，不是直接向订阅端发送流，而是先发送到 RTC 边缘，在边缘进行云端美颜和渲染，再发送给对端，同时也发回给发布端用于本地预览。这对“边缘”的要求很高，边缘要尽可能多，才能在边缘就快速把特效解决了。「边缘渲染」的好处是对本端几乎没有额外的性能消耗，完全不依赖本地设备算力，可以运行更酷炫、更复杂的算法。大家可能会担心「边缘渲染」会增加发布者本地预览以及发送到对端的延时，我们统计了一下线上数据，开启边缘渲染只比普通音视频通话增加了 30ms 的延时，本地预览延迟低于 200 ms，实时帧率可以达到 30+ fps。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/31/31654fd25abd3a9373b958cd381a2d71.png\" /></p><p></p><p>我们来看一下实际效果。视频左边是未渲染的预览画面，右边是经边缘渲染之后再返回本地的预览效果，延迟控制在了 200ms 以内，轻微的延迟基本不会影响正常的发言和交流。同时，像这样的虚拟头套是一个比较消耗性能的算法，「边缘渲染」的方案突破了 Web 运行精细特效算法的性能瓶颈。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/aa/aa08be16b448ee87aad5de347acc7a9b.png\" /></p><p></p><p>从视频会议场景孵化出的「边缘渲染」能力也可以用到其他应用场景。比如在一些美妆、电商场景，可以支持用户免下载软件，通过云渲染的方式即可体验试妆、试戴效果。像图上的一些万圣节特效、魔法变身特效、老年特效都是一些比较耗算力的特效算法，通过云端渲染，在低端机上也可以方便地实现。</p><p></p><p>作者简介：</p><p></p><p>杨若扬，火山引擎 RTC 产品负责人</p>",
    "publish_time": "2022-09-02 14:52:51",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "火山引擎发布数智平台VeDI，全面开放字节跳动数据技术能力",
    "url": "https://www.infoq.cn/article/8uCqRDgdyje2u30GdZbD",
    "summary": "<p>9月2日，火山引擎数据智能科技峰会在杭州举办。会上，火山引擎发布新一代企业级数据产品——数智平台VeDI（Volcengine Data Intelligence），包括数据引擎、数据建设和管理、数据分析应用及解决方案的全链路数据能力，在安全合规的前提下充分发挥数据资产价值，为企业数字化发展提供新的增长动力。</p><p></p><p><a href=\"https://www.infoq.cn/article/40g7cuisZjVkNjWvHmt9\">火山引擎</a>\"是字节跳动旗下的云服务业务板块，VeDI首次全面开放了字节跳动的数据技术。火山引擎总裁谭待认为，数据必须和业务场景结合，为业务价值服务，“火山引擎VeDI沉淀了字节跳动业务发展的数据驱动经验，希望也能够帮助客户用好数据”。</p><p></p><p>据字节跳动数据平台负责人<a href=\"https://www.infoq.cn/article/NePuifvKismCoTWecrLg\">罗旋</a>\"介绍，火山引擎数智平台VeDI分成PaaS层和SaaS层两部分，提供覆盖数据全生命周期的产品服务，帮助企业客户实现运维降本、运营提效和业务增长。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/6d/ec/6d006e1779ac1414a597e240868d0eec.png\" /></p><p></p><p>图：火山引擎正式发布数智平台VeDI</p><p></p><p>VeDI的PaaS层包括数据引擎和数据研发治理。以数据治理为例，VeDI沉淀了字节跳动各业务线的数据治理经验和规则，适合多种类型客户在业务的不同阶段使用。</p><p></p><p>VeDI的SaaS产品在数据分析应用的基础上，重点推出了场景模板。这些模板来自火山引擎服务抖音、今日头条等内外部客户的数据分析经验。罗旋表示，客户可以按照行业选择分析场景，一键生成数据看板，让数据驱动更大程度地融入业务，促进业务价值提升。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/f2/1d/f2c6c938705668ce957ab5fd5fa2d21d.png\" /></p><p>图：火山引擎数智平台技术栈，端到端的全链路数据能力输出</p><p></p><p>据悉，火山引擎数据产品已服务了平安银行、陕西旅游、蓝河、美的、上海家化、万达、吉利领克、赫基、南孚、联合利华、李维斯等不同行业的客户，并获得良好反馈。平安银行大数据平台技术总监沈百军在此次数据智能科技峰会上表示，平安银行与火山引擎深度合作落地了营销决策实验室，通过约300个数据实验有机组合和探索，用户活跃度提升接近40%。</p><p><img src=\"https://static001.infoq.cn/resource/image/88/43/88f7fdecf84e38908a189c5628a71843.png\" /></p><p></p><p>&nbsp;另外，在本次峰会上，火山引擎宣布了数据集成工具BitSail、大数据分析引擎ByConity的<a href=\"https://www.infoq.cn/article/SX9ZlzNrYsElIRYoHUqD\">开源计划</a>\"。罗旋表示：“在数据平台发展的过程中，我们也享受了开源社区带来的便利，所以我们也会将自己在实践中比较成熟的自研系统开源出来，回馈给广泛开发者。”后续InfoQ将会带来关于这两个开源项目的深度采访报道，请大家持续关注。</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2022-09-02 15:41:54",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "去哪儿旅行微服务架构实践",
    "url": "https://www.infoq.cn/article/0OOSDdvcwhu7DYCVukCR",
    "summary": "<p>作者 | 朱仕智</p><p>编辑 | 贾亚宁</p><p></p><p></p><blockquote>本文由极客时间整理自去哪儿旅行基础架构部高级技术总监朱仕智在 <a href=\"https://time.geekbang.org/qconplus/home\">QCon+ 案例研习社</a>\"的演讲<a href=\"https://time.geekbang.org/qconplus/detail/100110480\">《去哪儿旅行微服务架构实践》</a>\"。</blockquote><p></p><p></p><p>你好，我是朱仕智，在去哪儿网负责基础架构，主要包含后端架构、大前端架构、质量保障、基础云平台等工作，近期主要在公司落地云原生和数字化管理。</p><p></p><p>今天我带来的主题是去哪儿旅行微服务架构实践。我将从以下几个方面进行介绍：</p><p></p><p>背景介绍微服务架构模式的最佳实践微服务开发效率的提升实践微服务治理的实践ServiceMesh 尝试</p><p></p><h3>一、背景介绍</h3><p></p><p></p><p>首先介绍一下去哪儿网的业务。去哪儿网是一个典型的在线旅游平台，它上面的业务繁多，有机票、酒店、度假、火车票、汽车票等等。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/dc/dce1201bf598aa9b191a0d56e67d41bd.png\" /></p><p></p><p>这些业务都有不同的业务流程，其中机票的标准化和线上化是最高的，但是像酒店这样的业务，在线化和标准化就比较低，同样的名字可能是不一样的酒店。这些业务在从商品、库存到整个交易过程其实都是不一样的，所以这些业务从背后来看还是相对比较复杂的。</p><p></p><p>我们为什么要选择微服务，其实有以下几个方面的原因。第一个就是业务逐渐复杂，最早去哪儿网其实只有机票的比价，而且是一个搜索比价，是没有交易环节的。后来业务扩展就慢慢地发展出来了包含机票、酒店、火车票、度假、汽车票等等其他的业务。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e5/e5fd32bafe693f8496cc15664352c606.png\" /></p><p></p><p>所以业务是逐渐复杂的一个过程，那按照康威定律大家都知道，业务变化了之后，组织结构要进行相应的调整，组织架构其实也会跟着相应的膨胀，膨胀也会带来协作上和分工上的一定损耗，这也是我们要选择微服务的原因之一。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/6c/6c78cbc45c8a96f1f2ca2da150f58a45.png\" /></p><p></p><p>第三个就是开发效率的低下，我们之前开发的时候大部分都是以最早的模式，也就是通过 HTTP 协议，加上 JSON 这样的数据结构，然后使用 Nginx 作为网关，把服务治理的这些动作全部耦合在业务代码里面，比如重试的逻辑等等。这样的话就会导致我们每一个服务做对应开发的时候，都需要重复性地去考虑这些问题，开发效率相对就会比较低下。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d8/d86d160a7be1a3dc12a6f23cc3f25e62.png\" /></p><p></p><p>第四个就是服务质量是比较失控的，因为这些服务质量很难能在统一的一个地方去得到比较有效、及时地处理，就像刚才说的治理的逻辑其实是放在了业务代码里面，有一些治理逻辑可能会放在 Nginx 里面，但是 Nginx 是一个大统一的网关，这就意味着当我们想要去对它进行修改的时候，其实是需要非常谨慎的，这就面临了一个运维和开发诉求不对等的问题。使用微服务我们认为是可以比较有效地解决这些问题的。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/40/4023e1275f2be40df21595c4389f0b78.png\" /></p><p></p><p>接着介绍一下我们去哪儿网的在线数据。我们现在的应用数据是这样的：活跃的、在线跑着的应用大概有 3000 多个；提供了 18,000 多个 Dubbo 的 RPC 服务接口；有超过 3500 个 HTTP 域名；13,000 多个 MQ 的主题；公司内部大概有 5 种语言的技术栈，当然主要是以 Java 和 Node 为主。</p><p></p><h3>二、微服务架构模式的最佳实践</h3><p></p><p></p><p>接下来介绍一下架构模式，架构模式里面有几个方面不同的范畴。</p><p></p><h4>1. 服务发现模式</h4><p></p><p></p><p>第一个就是服务发现的模式，服务发现里面其实有三种模式，这三种模式对应不同的适用场景会有不同的效果。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/86/867222db4d410ca0ef352c48535eb3ae.png\" /></p><p></p><p>直联模式，客户端从注册中心发现服务端的列表并缓存在本地，这种模式适合于语言统一的这种内网通信，为什么呢？因为直连模式里面大部分 RPC 采用的这样的模式，主要是比较简单、高效，而且在统一语言的内网通信里面，这种服务端的实例的变更通知是比较简单的。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/75/759eea0431339e09e66b7eb07b243ad9.png\" /></p><p></p><p>代理模式，服务端注册到网关上，客户端对一个服务端其实是无感知的，这种模式比较适合于外网服务，为什么呢？是因为当你的服务端变更的时候，客户端其实是不需要去感知，也不需要对此进行任何变更，这样对外网来说，其实用户侧的设备是不需要去关注信息的，这样通知起来就比较简单。但是它也会面临一个问题，它会多一跳的通信，从性能或者效率上来说，肯定是不如直连模式的。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/24/24a23e2b41f24fb7d65b4c7a3459d691.png\" /></p><p></p><p>最后一个就是边车模式，Sidecar 去负责注册和发现，应用程序是无感知的，这种比较适合于多语言、多协议的这种内网通信，它其实跟直连模式相对来说是比较相似的，但是它其实是由边车的模式替代了业务程序里面混入的这种基础功能，所以简单来看其实就是直连模式里面把公共的基础设施的逻辑下沉到了边车里面。这样的话边车就可以统一地配合我们的灰度发布或者是其他的热更新的机制，能够做到比较容易地去对这些边车进行升级。</p><p></p><h4>2. 服务通信模式</h4><p></p><p></p><p>接下来我们说一下服务通信的模式，服务通信模式里面主要有两种，大家其实日常里面比较经常会碰到就是同步的编程模式，这种模式比较简单易懂，非常符合人类的思考习惯，它比较适用于时间比较敏感的、吞吐量也比较小的这种场景。但是这种通信的方式在吞吐量比较大、QPS 比较高的场景里面就会有一系列的问题，比如说可能会把你的资源耗尽，但其实这些资源都处于等待中。比如我们在 Java 里面可能会有线程池的资源，使用起来其实是比较低效的。然后在异步的这种场景里面，它其实比较适用于高吞吐、削峰填谷的作用。</p><p></p><p>其实这里面会有几种，从我们的实践上来看的话，比如说搜索系统它其实是一个非常高并发的场景，其实对于这种高吞吐的场景下是必须要用异步的，不然的话其实资源的损耗是非常高的，我们在某些系统上做过改造，由原来的同步改为异步的话，基本上可以节省掉 80% 左右的机器的资源。除此之外，交易系统的事件驱动也是比较适合异步的一个场景，因为交易系统的事件其实是非常关键的，但是它又不能每个人都去通知，因为很多人都需要关注这个事件，这个时候利用 MQ 等方式去做这种事件的驱动是比较合适的。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a8/a86e36eab43b845637b019676cc1cd1d.png\" /></p><p></p><p>在异步的这个场景里面，去哪儿网其实做了一些内部的支持，比如说我们封装了异步的 HttpClient，把公司内部其他的组件类似于 QTrace，还有一些其他基础的监控、日志等等之类的组件都做了统一的封装埋点。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/03/031e4b3f1afe3cbf42ce2595a5e5cc23.png\" /></p><p></p><p>第二个我们对 Dubbo 的异步通信进行了改善，Dubbo 里面原有的几种通信方式，其实是调用端和被调用端，是会存在一定的耦合逻辑的。比如说像参数回调这样的方式，其实是调用端需要进行异步，但是被调用端不得不配合这个方式进行改造，所以在这种背景下，我们对 Dubbo 的异步通信进行了魔改，其实现在的最新版的 Dubbo 的模式里面，跟这个是比较相似的。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3e/3ebe492789dff9969f05692cfba870e2.png\" /></p><p></p><p>第三个就是我们其实内部做了一个自研的消息队列叫 QMQ，它其实支持可靠的事务消息，广泛地应用在我们去哪儿网的交易系统里面。</p><p></p><h4>3. 协议</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/80/80c2e210801c337f5ee7241f4b32fefd.png\" /></p><p></p><p>第三个主要提一下协议这部分，我们公司里面主要有三种协议。第一种私有协议，主要负责 App 和外网网关之间的通信协议；第二个 HTTP 协议，主要是外网网关到 Node、Node 到 Java 之间，甚至有一些 Java 到 Java 之间也会有自己使用的这种 HTTP 协议，不过这种量其实是比较少的；第三 Dubbo 协议，后端的 Java 服务之间的通信基本上都是用 Dubbo 为主，只有少量的使用 HTTP。</p><p></p><h4>4. 设计模式</h4><p></p><p></p><p>从设计模式上来说的话，我们其实可以知道在互联网的架构里面，特别是在高并发的模式里面，我们有很多折中，这些折中里面其实会有不同的模式和它的沉淀。比如说像 BASE 这样的模式，它其实不追求强一致性，它是有这种基本的可用和软状态这样的优点，进而去避免因为强一致导致的其他的不可用性。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/0e/0e2d4baf8012850aed27275c1b65f6c8.png\" /></p><p></p><p>第二个就是 CQRS，这个模式其实非常有用，至少我发现很多场景是能够用上它的，换句话说其实只要是数据异构的这种场景，都是比较适合去使用它的，当然这取决于你的查询模式。大家都知道查询模式其实有很多种的，比如说像 KV 的查询模式、复杂条件的 Query，除此之外，还有 Scan 这种扫描形式，不同的查询形式会对应着不同的存储结构是比较合适的。但是我们在对这些数据进行操作的时候，其实它的数据载体是唯一的，那这个数据载体怎么样才能支持多种的查询模式呢？其实这里面就需要对这些数据进行异构，比如说像我们的订单、配置等等这些方式都需要去进行一定的异构。</p><p></p><p>比如说像去哪儿网内部的话，代理商在去哪儿网上就可以进行一定的调价，调价的配置其实就是一个比较适合去做数据异构的场景。代理商去录入的时候是比较复杂的，但其实是从航空公司拿到的一个配置，当它放到平台上来的时候，也是用同样的方式去放，但是对于检索来说的话，用户其实关心的是这个城市，到这个城市的时候，你的调价规则是什么样子，他并不需要一个大一统的调价规则。所以这里面就会面临一个数据异构的过程，我们在这个过程里面其实也使用了 CQRS 这个模式来解决问题。</p><p></p><h3>三、微服务开发效率提升实践</h3><p></p><p></p><p>然后我来说一下效率提升的这部分，大家都知道业界 Spring Cloud 在近期或者是近几年来说是一个最佳实践，特别是在微服务比较火之后，大家亟需一套成型的解决方案。这个里面包含不同的功能，比如说像分布式的配置、服务的注册、发现、通信，还有服务的熔断、服务调用、负载均衡、分布式消息等等。其实大家可以看到官方的一个实现，当然实现基本上都是来源于 Netflix 的，这里面会有不同的这些组件，但这些组件其实很多时候可能有一些已经不再维护了。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/8c/8cbc5c2a4ccf4bbcbf6de690fbfb39a7.png\" /></p><p></p><p>对应地可以看到 Spring Cloud Alibaba 也有自己的实现，像 Nacos、Sentinel、Dubbo、RocketMQ 等等。我们其实就在思考着去哪儿网自己有这么多自研的组件，是否能够适配 Spring Cloud 这样的一套标准，进而去达到开发提效、互相串通组件的目的？</p><p></p><h4>1.Spring Cloud Qunar</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/81/81b20429d1295ec51eeedc32c75194ea.png\" /></p><p></p><p>我们做了一个尝试，基于 Spring Cloud 做了配置中心、注册中心、服务治理等等之类的组件的串通，这样的话能够做到比较好的开发模式。然后值得一提的是我们在 Spring Cloud Qunar 里面，其实提供了两种通信的模式，一种是前面提到的直联模式，就是由应用本身包含的 SDK 来负责注册、发现和通信。除此之外，我们还有一个模式是基于 Sidecar 的这种 Mesh 模式，我们也可以由 Mesh 的 Sidecar 去负责注册、发现和通信，这两者之间的开启其实是比较简单的，只需要有一些特定的注解就可以开启 Mesh 模式。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/34/343305855f54d3b1dd592931db97d714.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/34/343305855f54d3b1dd592931db97d714.png\" /></p><p></p><p>大家可以看到这里面，比如上面的代码，有 Dubbo Service 这样一个服务的提供，下面就会有 Dubbo Reference 这样的一个服务的引用，并且在注解里大家可以看到 Qunar Mesh 这样的一个注解，这个注解就是用于开启我们的 Mesh 功能的，是对于 Dubbo 这个协议的。对于 HTTP 协议的话，其实跟官方的也是非常类似，我们使用了 OpenFeign 这样的一个组件来进行通信，下面也同样会有 Qunar Mesh 组件进行 Mesh 化。</p><p></p><h4>2. 开发插件</h4><p></p><p></p><p>下面说一下开发插件，我们为什么要做开发插件，以及开发插件为什么能够做到效率上的提升呢？其实这里面的话，我们分析了大量的业务研发的开发模式，能够发现存在一些重复性或者是低效的环节，比如说像手动编写很多的调用代码，甚至可能会出现要手写这些反序列化类等等。</p><p></p><p>第二个就是在交互的过程中大量地去使用类似于文档，或者是内部的 IM，甚至比如说大家做的比较好的场景下是有 apiDoc 这样的方式去沟通这些接口的语义和细节。</p><p></p><p>第三个就是服务上线之后才去考虑治理，这个里面就会面临开发和运维的不对等。你的服务上线了后，它不出问题时，其实你是很少会去考虑治理的，只有在你开发的时候可能会有一定的考虑，但是这个考虑其实不是基于真实数据的。比如说你设置一个超时时间，大家经常能够在代码里面看到 1 秒、30 秒、60 秒等等之类的数字，这些数据真的有意义吗？不一定，只是大家习惯性地这么写，然后还有成百上千个 HttpClient Wrapper，就是自己不停地去实现这些 HttpClient，这些都是一些开发比较低效的场景，我们怎么解决这个问题呢？</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/03/03bcd6d1966aaf1546e411be74e83f2f.png\" /></p><p></p><p>我们其实做了一个基于 idea 的 IDE 的开发插件。开发插件它可以满足以下的几个功能，比如像服务调用的代码自动生成，这个是一个什么样的场景？是说当你在 IDE 里面打开我这个插件，你就可以选择对方的应用、对方提供的服务，直接就一键生成调用的代码，甚至包括一些其他 jar 包的引入，比如如果它是 Dubbo 协议的，它会自动引入这些 Dubbo 的 SDK 和对方提供的这些 API 的 jar 包等等。</p><p></p><p>第二它可以快速地发现这些应用接口方法，集成对应的文档服务，这个就是刚才提到的我们其实打开了这个插件，就能快速地去检索它对应的应用和提供的服务，是比个人沟通要高效很多的。</p><p></p><p>第三它打通了服务治理。在编码生成的过程中，你需要去配置这些治理的参数，然后这些治理的参数通过上报的方式，把它统一地注册到我们的服务治理平台，然后跟 Mesh 的模式去进行打通。这样的话有一个非常有效的方式，在你去生成这些调用代码的时候，你就可以参考一些对应的指标、参数，比如对方提供的接口的监控是什么样子的，以及其他人设置的指标是什么样的，做一定的智能化推荐，这样能够保证我们的这些指标相对来说是配置的比较合理的。</p><p></p><p>第四个就是代码规范的最佳实践是能够比较好去落地的。我们都知道，很多时候这些代码规范是需要靠文档，比如我们出一个什么样的规范，什么样的标准去保障，或者是类似利用这些代码检查工具，比如 Sonar 等等之类的方式去保证我们的代码规范的落地。但是其实通过这种生成代码的方式，我们直接就可以把最佳实践嵌入到生成的过程里面，来保证它生成的代码一定是符合最佳实践的。</p><p></p><p>除了上面这四个方面之外，我们其实还在插件上做了大量的工作，比如说像 CI/CD 的左移，这个左移包含了我们可以在本地去跟远程的环境打通，以及它还提供了对应的 CI/CD 流水线的功能，还有代码覆盖率的功能等等。通过这样的一个开发插件，我们可以把日常的一些重复性的、低效性的工作就可以被完成掉，是一个比较好的提效方式，推荐大家去使用。</p><p></p><h3>四、服务治理实践</h3><p></p><p></p><p>然后在服务治理这里面，我们其实也做了一些自己的思考。首先我们来看一下，常规的这些服务治理的四板斧是什么样子。</p><p></p><h4>1. 常规四板斧</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/37/37a1b17981b98ae4b90df7d621b5dfbc.png\" /></p><p></p><p>不可避免地，第一，我们一定要设置超时；第二，要在一些场景里面去考虑重试的逻辑；第三，考虑熔断的逻辑，不要被下游拖死；第四，一定要有限流的逻辑，不要被上游打死。</p><p></p><h4>2. 最终目标</h4><p></p><p></p><p>这些都是非常普遍，也是非常有效的一些措施，但是有效建立在于你的配置，或者是你的这个动作是有效的场景，但实际上我们很大程度上其实是在滥用这四种技术。我认为服务治理的一个最终的目标就是稳定可用、可观测、防腐化，这是什么意思呢？</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/00/009ee8f695a5d2b3c1dda7316f51680c.png\" /></p><p></p><p>稳定可用指的就是我们通过各类的防控手段去达到在可用的容量场景下，提供有效的服务，这样才能叫稳定可用。第二个可观测，就是我们从多个维度，比如说像关系、性能、异常、资源等维度对它进行度量并且分析。第三个防腐化，我们的代码和架构其实不可避免地都是在腐化的一个过程之中，我们不停地往里面去添加东西的过程中，其实也会缺乏一定的治理。我们服务治理的目标，其中一点就是要做到如何去对它进行防腐，这个里面有一些考虑的维度，比如服务的层级，你的服务并不是越微越好，也不是层级越多越好，所以服务的层级一定要有所控制。</p><p></p><h4>3. 保护机制</h4><p></p><p></p><p>第二就是链路的分析，链路里面上下游的超时、串行、并行的调用等等之类的这些东西在编码的过程中可能会被忽略掉的，这些我们其实可以通过偏后置一点的方式对它进行一个分析和预警，这里面提一下我们在保护机制上做的一些工作，我们都知道在 RPC 的框架里面，其实特别是在直连的模式下，调用端 Consumer 端和 Provider 端其实是直连通信的。</p><p></p><p>对于注册中心来说，它只负责一个注册和变更通知的作用，但是在有一些特定的场景里面并不是这样子的。举个例子来说，当一个注册中心因为自身的原因处于一个半死不活的状态，它一会儿能服务、一会儿不能服务的时候，就会发生一个比较恐怖的事情，Provider 端因为它要跟注册中心去保持心跳判活的状态，所以需要和注册中心保持长期有效的连接。如果是失效的情况，作业中心就会判断这个 Provider 是不存活了。不存活的时候，注册中心就会把这个消息通知给 Consumer 端，Consumer 端只要接收过一次下线通知，Consumer 就会从它的列表里面把这个 Provider 从本地的缓存里面去移除掉。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d4/d4072d1d733cee4a2e66ed5aacf03121.png\" /></p><p></p><p>如果注册中心处于一个半死不活的状态，最后会处于一个什么状态呢？Consumer 端慢慢地会把所有的 Provider 都移除掉，这样就会导致我们的 Consumer 端到 Provider 端其实是不可通信的。对于这个问题，我们其实基于 Dubbo 做了一定的改造，做了一个保护机制。这个保护机制就是当 Provider，特别是注册中心上的 Provider 的数量少于一定的阈值的时候，我们的保护机制就会自动地启用，它的生效是在 Consumer 端的，也就意味着 Consumer 端需要缓存这段时间内所有历史的 Provider 的列表。</p><p></p><p>大家可能在这里会有一点担心，你缓存的 Provider 如果失效了怎么办？它是真的失效了，比如说它被下线了，或者是它本身经过迁移，像我们在容器场景里面，经过了一定的发布，其实它对应的信息都变化了，这个时候你再去通信不就有问题吗？其实我们在保护机制里面也考虑了这个问题，我们在通信之前还是会做一个直连的检查，Consumer 到 Provider 的连接存活是否是真正存在，如果不存在，我们会把这一个连接给扔掉，保证通信的时候使用的是一个可用的连接。</p><p></p><p>当这个信息机制启用了后，注册中心恢复到一定状态，这个 Provider 又能重新注册到注册中心里面了，接着我们又会把保护机制自动关闭掉，这样 Consumer 就只会调用注册中心上存活的 Provider，就可以避免掉因为注册中心半死不活，导致所有的这些分布式的应用里面的 RPC 调用是不可用的。</p><p></p><p>这其实是一个比较有效的方式，因为如果出现了这种场景，其实你内网里面的大部分应用通信其实是处于一个不可用的状态，甚至你想让它恢复都是非常困难的事情。比如你想启动的时候，其实 Consumer 发现 Provider 都不存活了，这也会导致启动失败等等各方面的问题。</p><p></p><h4>4. 动态限流</h4><p></p><p></p><p>接着我来介绍一下限流里面我们做的一些工作，这里面我们做的模式我把它叫做动态限流。普通的一个限流里面，通常来说是这样的一个方式，我们有 A、B、C 的服务都对 X 这个服务进行了调用，它的来源可能是不一样的，X 为了保护自身的状态是可用的，它不可避免就要对上游 A、B、C 的这些访问分配固定的一些配额，谁超过了配额就不可用了。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/26/26e8c022b3cae88c24c5486da61da423.png\" /></p><p></p><p>比如说像 A 分配了 100、B 也分配 100、C 分配给了 50。当 A 超过了 100 的时候，其实它的一些请求是会被拒绝掉的，这个是基于容量的考虑，X 不可能具备无限的容量，这时它需要一定的保护措施。但是这地方就会有一个问题，假如 A、B、C 里面，比如说 B 服务，它其实是从 App 过来的，它的价值不可避免来说的话，要更高一点。比如说第三个服务 C，它是从 Web 里面来，它的价值相对来说比较低一点。这个价值是基于你的业务形态来的，比如说你的 App 的成单、转化更高，那就意味着它的请求更珍贵。</p><p></p><p>这个里面就会出现一个问题，服务 B 和服务 C 自己都得到了一定数量的配额，但是假如 App 的流量上涨了，Web 的流量没有上涨，这时就会面临一个问题，服务 C 的配额没用完，但是服务 B 的配额又不够用，这个场景下怎么解决呢？就需要靠人工来不停地去调整它，而且这个调整需要相当实时才可以，我们有没有办法能够相对统一地解决这个问题呢，其实我们做了一个探索，这个探索从实践结果来看的话是比较有效的。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5f/5f0722e25737b8101fd88aff3c21c910.png\" /></p><p></p><p>我们对这些服务进行配额分配的时候，其实不是一个固定的配额，而是一个动态的分配。动态的分配意思就是，我只有一个总的容量，并不给每一个服务进行分配，总的容量我分配给所有人。但是我要对所有的调用方进行一个排序，也就是说谁的价值高谁就排在前面，这样的话就能得到一个比较有效的结果。你的限流模型是基于你的业务逻辑来的，也是基于你的业务价值来的，当你发生限流的时候，优先丢掉的一定是最没有价值的那部分的业务请求。</p><p></p><p>当然这里面也会有一个前提，你的请求来源是需要有差异化的。还有第二个点，你的这些 trace 连通性一定要高，也就意味着，你的这些标志要能够一路畅通地携带下去，如果只是基于某一层去做限流逻辑，其实是没有意义的。</p><p></p><h4>5. 防腐化</h4><p></p><p></p><p>接着就是防腐化，这里面其实我们需要对架构、应用的分布、应用的关系去做大量的分析，得出改进的措施，我们在这上面改进的措施其实有很多。比如我们会分析哪些应用是频繁修改的，这些频繁修改的意思是不是所有的需求，这些应用都相关地需要去做修改，那就意味着说它的业务域是一样的。如果这些业务域一样的情况下，你把它的微服务划分得很细，实际上它是一一绑定的话，其实并不符合微服务化的原则。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/1a/1a5c1a16ebf8e7dc534a668154380d61.png\" /></p><p></p><p>第二个是否存在重复的调用，这条链路里面，这些重复的调用是否能够去缓存化，或者是避免它重复调用。</p><p></p><p>第三个大量的串行调用是不是能够把它异步化，比如常见的，从数据库里面拿出一批记录，这一批记录通过循环的方式，挨个去对它发起远程调用，这些过程里面其实比较有效的方式就是通过异步化、并行化的方式去把速度给提上来。</p><p></p><p>第四个异步的整个链路的这些超时配置里面，其实会有一定的相关的关系。比如上游的超时是不应该比下游短的，如果下游的超时比上游的还长，那意味着说下游还在计算，上游可能已经超时了，这个计算的结果其实有可能返回不了上游，这些就是无用的配置。除了这之外其实整个链路里面大量的超时可能是不合理的，比如刚才提到的大量重复的调用，这些重复的调用或者循环的调用，再乘以同样的超时时间，可能就会比整个终端的操作时间要长很多，这些都需要去做一定的分析和考虑，才能达到它防腐化的目的。</p><p></p><h3>五、ServiceMesh 尝试</h3><p></p><p></p><p>最后一个介绍一下我们在 ServiceMesh 上的尝试。</p><p></p><h4>1. 背景</h4><p></p><p></p><p>先简单介绍一下背景，我们公司内部其实还是存在多语言、多协议的这样一个场景。</p><p></p><p>第二个它在多语言、多协议的场景里面不可避免地就会出现治理平台比较分散，比如像 Dubbo 的话，我们其实会有一个 RPC 的服务治理平台；HTTP 的话我们其实有类似于网关 Nginx 或者是 OpenResty 去对它进行治理；其他的也会相应的治理，甚至可能是在配置中心去对它进行治理等等。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/30/30c6353b93ad7099bce8f8b80f380e0f.png\" /></p><p></p><p>第三个组件的新功能迭代是相对比较慢的，因为这些组件都是嵌入在应用代码里面，因此它的迭代就需要跟随着业务代码去迭代，才能够去比较好地迭代，而且这些迭代里面其实需要付出一定的人工成本，其实业务的开发是不太愿意去主动地做这种组件的迭代的，在 ServiceMesh 的选型里面，我们也考量了一下当时业界里的选择。</p><p></p><h4>2. 技术选型</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/fd/fd47145405b2b648d07d08ade39e5f48.png\" /></p><p></p><p>从数据面上来看，envoy 还是占大头的，但是我们最终其实没有选择 envoy，主要是因为我们在 C++ 技术栈里面储备的人才是不够多的。第二个在控制面上，大家基本上都是基于 Istio 模式去做的，当然也大部分都做了二次的开源，我们最终也是选择这样的一个模式。</p><p></p><h4>3. 整体架构</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c7/c75e431d5b36db2452a73a68f6df5919.png\" /></p><p></p><p>我们最终的选择是，数据面上我们选择了 MOSN，而不是 envoy，MOSN 是基于 Go 开发的一个阿里巴巴官方出品的组件，这个组件其实是一个偏网关代理型的一个组件，但是在上面去实现 Mesh 的逻辑，其实是比较方便的，特别是针对基于 Dubbo 这个协议的 Mesh，MOSN 支持得是比较好的；在控制面上，我们也是基于 Istio 去做了二次开发，也有一定的自研组件，比如说 mcpServer、配置中心、注册中心这些都是我们自研的。在运维面的话，我们也是自研了一套运维相关的组件，比如 Sidecar 的部署、灰度的升级等等，还有一些规则治理、监控报警等。</p><p></p><h4>4. 注册模型</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e4/e4a0b8ccfa7efa530dc0da2418919570.png\" /></p><p></p><p>ServiceMesh 里面我主要介绍一下几个关键点：第一个就是注册模型，因为它是一个多协议、多语言的方式，其实比如 Dubbo 或者 HTTP，它在服务层面其实是不统一的，在注册中心我们想要以一个统一的注册中心去服务发现的时候，不可避免地就需要把它的维度统一掉，我们是怎么做到的呢？我们其实是参考了业界现在比较火的，或者基本上应该是事实上的标准，通过服务 - 实例这样的维度去抹除掉了类似 RPC 这种 Dubbo，这种接口的维度，与原来的注册中心去进行双写，来保证 Mesh 化的和非 Mesh 化的都能支持。</p><p></p><h4>5. 配置模型</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3e/3e05fe5ce3c693d9bce650b4069c18cd.png\" /></p><p></p><p>然后第二个就是配置的模型，这里面就是服务治理平台，我们其实自定义了一些存储的格式，然后通过 MCP 的方式，Server 的组件去转换 Istio 需要的数据格式。Istio 拿到了之后，通过标准的 XDS 的数据格式下发到 MOSN 里面，这一段我们基本上就是依赖原有的一个功能，主要是在左侧这部分，我们自定义的这部分组件的数据格式是比较关键的。</p><p></p><h4>6. 路由模型</h4><p></p><p></p><p>第三个说一下路由的模型，路由模型里面，大家其实见过非常多，但是我对这些治理的功能或者路由的功能，其实偏保守一点的观点。因为在我看来越灵活越可能会用错，这里面就需要我们去抽象一定的业务模式，把业务模式落地到或者固化到组件里面来。通过这个方式，我们其实发现只需要以应用和环境集群为主体，并且在这个场景上支持 trace 匹配的控制，就可以保证满足我们绝大部分的业务场景。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/19/1958b66090b107576cfa4eac7d3f1326.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/07/0719aa418ecb13c13d57dcd50600e70e.png\" /></p><p></p><p>因为我们线上经常会出现应用不同的环境集群，其实是为了不同的诉求去用的，比如像搜索集群和交易集群，它们需要进行物理隔离，然后比如上线的时候，可能需要做一定的灰度验证等等。这样的话我们就可以基于 trace 的参数匹配去控制它，只要以这样两种方式作为路由模型的支持，是满足绝大部分的业务诉求的。</p><p></p><h4>7. 控制面和运维面</h4><p></p><p></p><p>在控制面与运维面上，我们做了什么样的方式呢？其实我们当时也并不想要在这上面做自研，而我们参考了业界很多的解决方案，其实发现在配置中心和 MCP 的 Server 里面，是缺少开源方案的，特别是配置中心，我们发现基本上很少有可用的配置，基本上就是一个查看可观测的方式而已，但其实你想要对它进行一些服务的治理是不够用的。</p><p></p><p>第二个 Sidecar 运维，这里面无损的升级和切换非常关键，会涉及到不同组件之间的依赖关系和它的检测，比如 Consumer 对 MOSN Sidecar 的检测，和 MOSN 逆过来对 Consumer 的检测，这些逻辑都是不一样的，而且细节会比较多，有兴趣的话大家可以线下沟通一下。</p><p></p><p>第三个就是可观测性，参考了非 Mesh 化需要的一些指标，我们可以比较好地去把 Mesh 化的过程里面大量的可观性指标都内置地埋点进去。但是在 trace 链路里面，最好把 Mesh 的 Sidecar 的 span 给精简掉，不然你会发现所有的节点都比原来多了两跳，这样无疑会把 trace 因为中间件的逻辑，把它复杂化掉了。</p><p></p><p>第四个就是健康检查，这里面刚才提到的 Consumer 对 Sidecar 的可用性的检查，其实是一个非常关键的重点，因为取决于它需要怎么降级以及它能不能降级。</p><p></p><h4>8. 性能优化</h4><p></p><p></p><p>最后一个就是性能的优化，这里面主要有两点，在业界大部分的方案里面其实都会面临一个问题，因为这些调用关系是动态化的，就意味着运行时才能知道我需要调用哪一些服务，它对应的规则是什么，也就是说我需要把所有的服务信息都下发到 Sidecar 里面，这不可避免就会占用大量的内存，它的匹配效率都是非常低的，我们在这上面怎么去做优化呢？</p><p></p><p>其实配合前面的 Spring Cloud Qunar 能够做到比较友好的方式，当它做了 Spring Cloud Qunar 这样的 Qunar Mesh 注解之后，我们其实可以把这部分在编译期就采集上来，或者在启动的时候去把这些信息都给它上报上来，这样我们就只需要订阅我们需要的一些部分数据就好了，能够做到大量的数据减少。</p><p></p><p>第二个就是在服务通信里面，因为多了 Sidecar 的两跳，那就意味着说 Sidecar 的通信是带来一定时间、效率和性能损耗的，这里面的关键点就在于应用程序和 Sidecar 的通信是否能够存在优化空间。我们经过实验发现，使用 UDS 的通信来替代原有的这种要经过网卡的通信其实要高效不少的，把它在这两跳上带来的损耗降到足够低。</p><p></p><h3>六、总结</h3><p></p><p></p><p>总结来看的话，整个微服务的过程里面，我们最佳的实践其实存在好几个方面。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e8/e8cceee0a336e1821b1d774a879ed222.png\" /></p><p></p><p>第一个是在发现模式、通信模式上的，我们需要去因地制宜做一定的最佳实践；在架构模式里面，比如说像 BASE 模式和 CQRS 模式，我们都可以在合适的场景里面放心大胆，或是尽可能去启用它们的。</p><p></p><p>开发效率先行，微服务的初衷其实是提效，那问题复杂化了以后，就需要有这些有力的配套，比如开发插件等来解决我们开发的问题，否则微服务可能只会带来一地的鸡毛。</p><p></p><p>第三个就是有效的服务治理，简单的管控手段意义是不大的，它的手段虽然有效，但真实业务的意义是不大的，类似于动态限流这样的模式才能真正解决业务问题。</p><p></p><p>第四，ServiceMesh 不可避免地，或者说现在基本上已经成为事实上的下一代微服务通信的架构模式，这个里面模型的设计和性能优化就非常关键。</p><p></p><p>最后对于微服务里面的一些要点再进行一下简单的总结。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b4/b48b504d123aebda24270ec7e3a84e1b.png\" /></p><p></p><p>业务的拆分就是借鉴业界成熟的模型，本地化为最适合公司现状的业务结构。比如刚才提到的去哪儿网，它其实也是一个线上的电商系统结构，但是它又有旅游、民航或者酒店领域的特殊性，就不可避免地要本地化。</p><p></p><p>还有就是架构模式里面，不同场景下的架构模式的支持是不一样的，交易系统的事件驱动，异构数据的 CQRS 都是比较有效的方式。然后开发模式、开发支撑里面需要对微服务进行完善的工具支持。</p><p></p><p>在服务度量里面，我们关系、性能、异常、资源，还有刚才提到的防腐都需要比较有效。第五个就是治理的管控，限流、熔断这种方式需要实时生效，最好是把它统一化而且进行业务有效化。最后一个就是演进式，架构的演进需要平滑有序，避免大量的应用改造。</p><p></p><p>最后送给你一句话：架构演进，以提升效率为目标。</p><p></p><p></p><h3>作者介绍</h3><p></p><p></p><p>朱仕智 &nbsp;去哪儿旅行 基础架构部高级技术总监</p><p></p><p>去哪儿网高级总监。负责过公共业务、国际机票、基础技术等团队，擅长复杂实时业务的高并发、高可用、高性能的系统设计和落地。目前负责基础架构团队，包含后端架构、大前端架构、质量保障、基础云平台等领域。近期主要投入在公司整体技术演进和数字化技术运营方向。</p><p></p><p></p><h4>相关内容推荐</h4><p></p><p><a href=\"https://www.infoq.cn/video/3UaAmw4dFVESmYhOZaZ2\">聊聊微服务架构的稳定性保障｜InfoQ大会早班车第18期</a>\"</p><p><a href=\"https://www.infoq.cn/video/fXElHgo6F58QTluTYWyq\">架构师是怎样炼成的</a>\"</p><p><a href=\"https://xie.infoq.cn/article/314146050a1caec8c1071637a\">微服务治理框架对比</a>\"</p>",
    "publish_time": "2022-09-02 15:51:14",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "放弃SVN，苹果WebKit迁移到GitHub",
    "url": "https://www.infoq.cn/article/vVmdG3VN7CjIcdgm9RQd",
    "summary": "<p>版本控制系统 (VCS），又叫修订控制或源控制系统，是一种软件实用程序，用于跟踪和管理对文件系统的更改。几乎所有软件的代码的备份、历史追踪、协同编辑等任务都需要版本控制系统完成。</p><p></p><p>从最早本地 VCS 系统 RCS、1990 年 CVS、2000 年 SVN（Subversion），到如今开源世界风头正健的 Git，同语言编辑工具一样，SVN、Git 都是程序员的必备利器。近些年，随着 GitHub 的流行，很多软件纷纷转向 Git。</p><p></p><p>8 月 31 日，苹果 WebKit 项目运营工程师 Jonathan Bedard&nbsp;发布<a href=\"https://webkit.org/blog/13140/webkit-on-github/\">博文</a>\"称，在今年 6 月 23 日，WebKit 项目冻结了 Subversion 树，迁移到托管在<a href=\"https://github.com/WebKit/WebKit\"> GitHub </a>\"的 Git 源代码管理系统。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/71/71fbdeab5002122132e4de4c94b46218.png\" /></p><p></p><h2>为什么选择 Git？</h2><p></p><p></p><p><a href=\"https://www.infoq.cn/article/webkit-for-developers\">WebKit </a>\"原先使用 Apache 的源代码管理系统 SVN，这次之所以迁移，是因为 WebKit 社区意识到了 Git 分布式特性的重要性和其庞大的社区。</p><p></p><p>SVN 是集中式的系统，而 Git 的分布式特性使开发人员在项目协作方式方面更加灵活，允许多个组织协作。</p><p></p><p>“Git 的本地提交消息记录，以及 Git 日志将提交历史限制在存储库的某些部分的能力，意味着大型项目不再需要在每次提交时检查过时的 ChangeLog 文件，” Bedard 说。</p><p></p><p>而且，WebKit 项目的许多新贡献者更倾向于在 git-svn 镜像上工作，当涉及到现有的工具和工作流程时，这样的转换也被视为理所当然的。</p><p></p><p>Bedard 进一步表示，“选择托管在 GitHub 是因为它有庞大的 Web 开发者社区，WebKit 项目能与他们密切合作以改进引擎。我们还发现，GitHub的API让我们只需对现有的基础设施进行相对较小的修改，就能建立起先进的预提交和后提交自动化，并提供一个现代且安全的平台来审查和提供有关新代码更改的反馈。”</p><p></p><h2>迁移是好事吗</h2><p></p><p></p><p>用户可能会发现苹果此举令人沮丧的是，Git 哈希值并不是自然排序的，所以 WebKit 团队决定在需要分叉的工作流程中使用他们所谓的“提交标识符（commit identifiers）”。WebKit有一个“零容忍性能退步”政策，这意味着，能够轻松推理出存储库中的提交顺序是至关重要的。</p><p></p><p>许多开发者都在问为什么这样的迁移需要这么长时间，并不是所有的人都认为这是一个好主意。</p><p></p><p>“仅在今年，GitHub 就发生了 50 多次故障，而且在追索方面也有糟糕的历史，限制受美国贸易制裁国家的开发者。如果‘WebKit项目对世界各地的开发者的贡献和反馈感兴趣’，那么切换到GitHub是没有意义的。”一位用户在HackerNews论坛上评论道。</p><p></p><p>还有人表示，即使最终项目发展会变成更顺利，但过渡到 Git 的过程也是场噩梦。</p><p></p><p>但也正如一位用户所说：“鉴于 GitHub 是一个被普遍理解的主机，而且它有人们喜欢的所有UI/开发集成，所以使用它是有意义的。另外，拥有GitHub账户的人似乎越来越多，因此贡献者不必再创建另一个帐户来提供其他服务。”</p><p></p><p>Git 由 Linus 在 2005 年开发而来，演化至今<a href=\"https://www.infoq.cn/article/ahoxlss6g153hod0y5iz\">已经成为</a>\"了最流行和最先进的开源版本控制工具，不过仍然有很多的公司和团队还在使用 SVN 或者 CVS 对项目进行版本控制，部分公司确实有一些可能合理的原因来维持现状，但是使用 Git 在绝大多数的场景下确实能让我们的开发和合作变得更加高效。</p><p></p><p>参考链接：</p><p><a href=\"https://webkit.org/blog/13140/webkit-on-github/\">https://webkit.org/blog/13140/webkit-on-github/</a>\"</p><p><a href=\"https://www.theregister.com/2022/09/01/webkit_migrates/\">https://www.theregister.com/2022/09/01/webkit_migrates/</a>\"</p><p><a href=\"https://www.infoq.cn/article/ahoxlss6g153hod0y5iz\">https://www.infoq.cn/article/ahoxlss6g153hod0y5iz</a>\"</p>",
    "publish_time": "2022-09-02 15:54:53",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]