[
  {
    "title": "微软发布Guidance语言，用于控制大语言模型",
    "url": "https://www.infoq.cn/article/QS07h5A8l1EGqVpV89ZK",
    "summary": "<p>最近，微软<a href=\"https://www.linkedin.com/posts/philippelimantour_inside-guidance-microsofts-new-open-source-activity-7068528335399575552-o-z8/\">推出</a>\"了一种名为<a href=\"https://github.com/microsoft/guidance\">Guidance</a>\"的领域专属语言，旨在增强开发人员管理当代语言模型的能力。这个新框架将诸如生成、提示和逻辑控制等任务集成到一个统一的开发流程中。</p><p>&nbsp;</p><p>据GitHub存储库的介绍，这门编程语言<a href=\"https://github.com/microsoft/guidance/blob/main/README.md\">使开发人员能够</a>\"“将生成、提示和逻辑控制组织到一个连续的流中，从而与语言模型实际处理文本的方式相匹配”。它可以与<a href=\"https://huggingface.co/models\">Hugging Face模型</a>\"等提供程序无缝集成，并集成基于智能种子的生成缓存系统和令牌修复，从而优化提示边界并消除词汇切分过程中的偏见。正则模式指引（pattern guides）则进一步强化了格式约束，保证提示可以正常完成。</p><p>&nbsp;</p><p>微软法国公司首席技术兼网络安全官Philippe Limantour<a href=\"https://www.linkedin.com/posts/philippelimantour_inside-guidance-microsofts-new-open-source-activity-7068528335399575552-o-z8/\">写道</a>\"：“用户可以无缝地合并生成、提示和逻辑控制，从而创建一个连续的流，与语言模型固有的文本处理机制保持一致。”</p><p>&nbsp;</p><p>对于微软推出Guidance，外界的反应也比较积极。根据哥伦比亚大学和沃顿商学院客座讲师<a href=\"https://pub.towardsai.net/inside-guidance-microsofts-new-open-source-framework-for-improving-the-control-in-llm-apps-3e5e4158027a\">Jesus Rodriguez</a>\"的说法，Guidance旨在为开发人员提供“一种简单而全面的语法，用于构建复杂的语言模型工作流”，降低LLM的复杂性。</p><p>&nbsp;</p><p>这个框架还没有完全完成。当前，针对该框架的扩展需求还包括：<a href=\"https://github.com/microsoft/guidance/issues/50\">更多的LLM支持</a>\"、更好的<a href=\"https://python.langchain.com/docs/get_started/introduction.html\">LangChain</a>\"<a href=\"https://github.com/microsoft/guidance/issues/163\">集成</a>\"以及支持OpenAI函数调用。</p><p>&nbsp;</p><p>Guidance是扩展语言模型功能这个工具生态系统的一部分。像<a href=\"https://github.com/hwchase17/langchain\">LangChain</a>\"和<a href=\"https://github.com/deepset-ai/haystack\">Haystack</a>\"这类框架的出现，已经简化了将模型集成到应用程序中的过程。<a href=\"https://handlebarsjs.com/\">Handlebars</a>\"、<a href=\"https://lmql.ai/\">语言模型查询语言</a>\"（<a href=\"https://www.theregister.com/2023/04/28/ai_models_may_not_yet/\">LMQL</a>\"）以及Nvidia的<a href=\"https://www.infoq.com/news/2023/06/nvidia-nemo-safety-ai/\">NeMo Guardrails</a>\"也被用于减轻LLM的不利影响。</p><p></p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/06/guidance-microsoft-language/\">https://www.infoq.com/news/2023/06/guidance-microsoft-language/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/minibook/vWO39J1tlb9xlSaIJoI6\">大语言模型综合能力测评报告 2023</a>\"</p><p><a href=\"https://www.infoq.cn/article/gjLJp08IHUUD8ShahHZ3\">大语言模型进化之谜：涌现现象的挑战与争议</a>\"</p><p><a href=\"https://www.infoq.cn/video/eJmFPe7oGOoQi4flItDe\">浪潮之巅，如何让大语言模型走向金融应用新纪元</a>\"</p>",
    "publish_time": "2023-07-06 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "华盛证券推出“华盛 GPT -天玑”；建设银行进行数字人民币创新应用；信也科技宣布在三个层次深化小微服务布局；恒生电子推出数智金融新品 | 金融科技新闻速览（6...",
    "url": "https://www.infoq.cn/article/AM56qBPMXsuuljG7kRzR",
    "summary": "<p>软通金科引入 AI 大模型和 <a href=\"https://xie.infoq.cn/article/7d0ea1e9fececb398eed64e63\">RPA 技术</a>\"，推出了新一代测试管理平台；华盛证券推出大模型工具“华盛 GPT -天玑”，提高金融内容创作效率，助力数字化转型；建设银行与中金财富、东方证券、国泰君安证券在证券公司三方存管领域进行数字人民币创新应用合作；中国银行“绿洲工程”在&nbsp;7&nbsp;月&nbsp;2&nbsp;日迎来大规模投产上线，借记卡、信用卡业务完成全国推广……本周金融科技领域有哪些新闻，一起来看。</p><p></p><p></p><h2>软通金科推出 AI+RPA 技术，赋能金融行业数字化转型</h2><p></p><p></p><p>软通金科通过引入 AI 大模型和 RPA 技术，推出了新一代测试管理平台，整体产品和解决方案利用 AI 大模型私有化测试训练，基于测试场景自由组合、定制组合等多种技术，自动生成测试案例和测试数据，并结合 RPA 自动化测试，解决了以往需要大量金融测试人员的高成本、低效率问题。</p><p></p><p>以保险行业为例，AI+RPA 技术可以应用于客户咨询、保单查询等工作，AI+RPA&nbsp;技术不仅能解决保险行业的大量重复的手工工作，同时可以通过 AI 技术辅助保险销售环节精准获客。在核保和核赔环节， RPA 智能流程机器人可以完成大量的工作，提升审核效率。</p><p></p><p>未来，软通动力将继续在“ AI+RPA ”领域布局，加速数字化转型升级，为各行业企业提供数智生产力。</p><p></p><p></p><h2>华盛证券推出首个大模型工具“华盛 GPT -天玑”</h2><p></p><p></p><p>华盛证券近日推出了首个大模型工具“华盛 GPT -天玑”，以应对金融科技领域的需求。该工具利用<a href=\"https://xie.infoq.cn/article/dcf1235518df0b7cfff97548e\">大模型</a>\"技术解决了金融行业中的一些繁重且耗时的工作，如内容创作和行情数据抄录等。通过自动生成文章的能力，天玑工具可以大大提高内容创作的效率。目前，该工具主要用于华盛证券内部，但未来将逐步开放给外部用户使用。华盛证券在金融科技领域有着丰富的应用场景和技术实力，将继续深耕 AI 领域，助力金融行业的数字化转型和创新发展。该工具的推出将有效降低企业成本，提高运营效率，为用户带来更高效的金融投资体验。作为香港金融科技券商中少数具备自研实力的企业，华盛证券将引领香港金融券商在 AI&nbsp;2.0 时代的革新，持续推动金融业务发展。</p><p></p><p></p><h2>建设银行拓展数字人民币应用场景</h2><p></p><p></p><p>最近，建设银行与中金财富、东方证券、国泰君安证券在证券公司三方存管领域进行数字人民币创新应用合作，其中与中金财富和东方证券的合作已正式上线。客户可以在已签约的证券公司&nbsp;App&nbsp;内绑定建行数字人民币个人钱包，将其作为支付方式之一进行交易服务、资讯服务和研究服务等。这次合作实现了证券公司保证金账户与数字人民币体系的互联互通。这次合作不仅为财富管理发展提供了思路和借鉴模式，拓宽了投资者参与财富管理的场景选择，优化了客户操作流程，保障了客户资金安全，并提供了良好的客户体验。建设银行表示将继续在数字人民币应用和创新方面发挥经验，为中国数字经济的发展做出贡献。</p><p></p><p></p><h2>信也科技宣布在三个层次深化小微服务布局</h2><p></p><p></p><p>7&nbsp;月&nbsp;2&nbsp;日，信也科技&nbsp;COO&nbsp;王玉翔在投融会上宣布将在三个层次深化小微服务布局。首先，强化科技型“小店”金融业务以满足小微真实需求；其次，加强数字化服务产品矩阵建设，提升小微用户数字化能力；第三，加速推进<a href=\"https://xie.infoq.cn/article/e2d14f4b536ee42110780d704\">&nbsp;SaaS&nbsp;</a>\"业务布局，在垂直小微服务领域提供产业科技服务。信也科技将利用联邦学习等新技术建立全生命周期管理模型，精准服务小微企业。通过智能获客、风控和运营平台，帮助金融机构扩大业务规模、降低成本、提升效率。信也科技已为近&nbsp;80&nbsp;家金融机构提供数字化服务，为&nbsp;2800&nbsp;万用户提供信贷便利化服务。信也科技希望通过科技力量让普惠金融覆盖更多人群，并将继续致力于为小微企业提供更好的服务。</p><p></p><p></p><h2>中国银行“绿洲工程”全面投产，数字化转型迈出新步伐</h2><p></p><p></p><p>中国银行“绿洲工程”在&nbsp;7&nbsp;月&nbsp;2&nbsp;日迎来大规模投产上线，借记卡、信用卡业务完成全国推广，反洗钱系统重构升级，标志着中国银行在数字化转型方面取得新进展。通过创新完善信创技术平台，提升业务响应能力，支持高频借记卡、信用卡业务，提供&nbsp;24&nbsp;小时不间断服务。新一代数字化技术底座为个人业务发展提供支撑。中国银行还结合业务特点，运用混合事务处理架构数据库技术，提升交易处理能力和数据分析能力，满足反洗钱业务要求。未来，中国银行将继续推进“绿洲工程”，提升数字化转型能力，支持实体经济和社会民生。</p><p></p><p></p><h2>稠州银行成功实施首例数字人民币跨境收款业务</h2><p></p><p></p><p>近日，稠州银行通过创新数字人民币应用成功实现了首单数字人民币跨境收款业务。这一举措推动了数字人民币智能合约应用，为人民币国际化提供了新思路，为跨境交易带来了新突破。数字人民币具有可编程性、实时到账和安全性等特点，提高了交易透明度和效率，减少了结算周期和交易成本，促进了人民币在国际贸易中的使用和地位的提升。稠州银行将继续推动数字人民币跨境结算服务，为企业提供安全、高效的服务，助力人民币国际化进程。</p><p></p><p></p><h2>临港新片区启动金融智算平台</h2><p></p><p></p><p>7 月 4 日，在上海自贸区临港新片区举办了滴水湖新兴金融大会·夏季大会——亚金协金融科技年度论坛。论坛上，正式启动了名为“滴水湖金融湾——新兴金融智算融合创新平台”的项目。该平台由临港新片区经济公司与中国信通院、新型互联网交换中心、临港科技城、跨境数科、移动、电信、联通以及有孚、城地、龙丰、海兰信、浪潮等智算企业共同合作打造。平台以临港新片区智算中心为核心，利用人工智能技术推动金融数据产业的快速发展，激发金融数据潜能，促进金融机构的云网融合和便捷连通。此外，平台还支持共建高能级研发机构和功能性平台，建立起新片区管委会、科研院所、产业园区和新兴金融企业等多层次的协同合作创新平台，为临港新片区金融科技产业的发展提供有力支持。</p><p></p><p></p><h2>恒生电子推出数智金融新品</h2><p></p><p></p><p>恒生电子及其子公司恒生聚源于 6 月 28 日发布了数智金融新品，包括金融智能助手光子和智能投研平台 WarrenQ 。此外，恒生电子还推出了金融行业大模型 LightGPT ，并公布了最新的研发进展。</p><p></p><p>金融智能助手光子，能够解决大模型在金融业务中的技术、应用和数据安全问题。光子可以为金融机构提供投顾、客服、运营、合规、投研、交易等业务系统注入 AI 能力。光子在咨询、创作、合规和运营场景上展示了其能力，可以提供精准的咨询观点和建议，自动生成专业文案，以及智能处理合规和运营系统中的文档和参数。光子聚集了各类金融数据，并实现了数据的保护、合规和授权。试用将于 9 月正式开放。</p><p></p><p>WarrenQ 是一款专业的投研工具平台，通过智能对话的方式提高投研效率，打破传统投研信息孤岛。平台推出了两款AI工具产品： WarrenQ-Chat 和 ChatMiner 。WarrenQ-Chat 利用大模型叠加搜索和聚源金融数据库，通过对话指令获取金融行情、资讯和数据，并生成金融专业报表。ChatMiner 则是一款金融文档挖掘器，能够快速解读指定文档，提取关键信息，智能化处理海量文本数据。WarrenQ 将继续发展，结合更多场景输出智能工具，助力投研数智化发展。</p><p></p><p>LightGPT 具备更专业、更合规、更轻量的特点。LightGPT 使用了超大规模的金融语料和语种强化数据进行训练，支持 80+ 金融专属任务指令微调，具备金融领域的准确理解能力。在金融大模型能力评测中表现出色，同时保证内容和指令的合规安全，可以为金融业务场景提供底层 AI 能力支持。LightGPT 还具有丰富、轻量化的部署方式，支持私有化/云部署以及灵活 API 调用。预计将于 9 月底完成新一轮的金融能力升级，并开放试用接口。</p><p></p><p></p><h2>外资银行“星展”在中国推出企业数字人民币收款解决方案</h2><p></p><p></p><p>星展银行在中国推出企业数字人民币收款解决方案，成为为数不多提供该方案的外资银行之一。该解决方案允许星展中国的企业客户以数字人民币形式接收消费者付款，并自动转存到企业的人民币结算账户。该方案的优势包括：无需人工结算、双重离线功能以及通过企业网银&nbsp;IDEAL&nbsp;获取数字人民币交易明细的综合商户报告。</p>",
    "publish_time": "2023-07-06 14:34:32",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "ChatGPT又断网了！OpenAI暂时下线ChatGPT搜索功能，只因绕过付费墙？",
    "url": "https://www.infoq.cn/article/8EixxqlrSE5O10k76XyJ",
    "summary": "<p></p><blockquote>一夜之间，ChatGPT 又回到了 2021 年。</blockquote><p></p><p></p><h2>OpenAI暂停ChatGPT Bing搜索功能</h2><p></p><p>&nbsp;</p><p>近日，OpenAI 发布通知称：</p><p></p><p></p><blockquote>自 2023 年 7 月 3 日起，出于谨慎考虑，我们已禁用“使用 Bing 浏览”测试版功能，同时我们会修复此问题，以维护内容所有者的权益。我们正在努力尽快恢复测试版，感谢您的理解！</blockquote><p></p><p>&nbsp;</p><p>OpenAI 表示，ChatGPT 浏览 Bing 是一个测试版功能，可供 ChatGPT Plus 订阅者使用（ChatGPT Plus 是 ChatGPT 的高级版本，每月收费 20 美元，订阅者可以优先使用新功能和改进，在对话期间加快响应时间，甚至在需求高峰期也可以访问 ChatGPT），它允许 ChatGPT 搜索互联网以帮助回答从最新信息中受益的问题。OpenAI 了解到，该功能有时会以 OpenAI 不希望的方式显示内容。例如，如果用户专门请求 URL 的全文，则可能会无意中满足此请求。</p><p>&nbsp;</p><p>这也意味着，目前 ChatGPT 又回到了对 2021 年 9 月以后的世界一无所知的状态（该版本模型的训练数据截止于此）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/41/4104eb2fe4dd604b70f0e4134104d6ae.png\" /></p><p></p><p>据悉，今年 3 月，网页版 ChatGPT 首次宣布<a href=\"https://www.infoq.cn/article/sqGLAIdIKP1jv2YKMd3C\">联网功能</a>\"。据官方博客介绍，此次联网功能的实现得益于 OpenAI 为 ChatGPT 增加了插件使用功能，“插件是专门为语言模型设计的工具，以安全为核心原则，并帮助 ChatGPT 访问最新的信息，运行计算，或使用第三方服务。”</p><p>&nbsp;</p><p>6 月 27 日，ChatGPT 发布最新更新声明，宣布对<a href=\"https://www.infoq.cn/article/bQHRqFcQ1TlJCqHuczGR\">移动 ChatGPT</a>\" 应用程序进行了更新：用户可以使用浏览来获取有关事件和信息的全面答案和最新见解，这些信息超出了模型的原始训练数据。用户可在应用程序设置的“新功能”部分中启用浏览，然后在模型切换器中选择 GPT-4，并在下拉列表中选择“使用 Bing 浏览”。至此，移动设备上的 ChatGPT 现在也可以上网了。</p><p>&nbsp;</p><p>不过如今，该联网功能已被叫停，OpenAI 没有给出何时重新启用 Bing 浏览的时间表，但表示他们正在尽快恢复该功能。</p><p></p><h2>ChatGPT断网后，用户怒火被点燃</h2><p></p><p>&nbsp;</p><p>ChatGPT 用户们对 OpenAI 的这一决定并不买账。</p><p>&nbsp;</p><p>有用户称他就是为了用上 Bing 网络搜索功能，才愿意付费订阅 ChatGPT Plus。“看来 OpenAI 正在针对 ChatGPT Plus 的付费用户，”一位 ChatGPT Plus 用户在 OpenAI 论坛上说道。“这次他们取消了浏览功能，因为它可以读取用户请求的网站内容？拜托，这就是我为 Plus 付费的原因。”</p><p>&nbsp;</p><p>也有用户在论坛中表达了自己的担忧，怀疑未来 ChatGPT 可能不再支持对网站内容的翻译功能。ChatGPT 用户 Thiago Ramos 坦言，“假设我需要用 ChatGPT 来阅读 GitHub 上的某个代码仓库或者主题，或者翻译目标论坛上他国语种的信息，结果你告诉我这些都做不到？而且现在 ChatGPT 4 的反应也越来越差了，特别容易犯错误。在某些方面，连 3.5 版本都比它做得好。”</p><p>&nbsp;</p><p>有外媒就此事联系了 OpenAI，询问关于此项决定的几个问题。对方回复了邮件，但仅仅是列出一条与更新后的帮助页面内容相似的推文。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/03/0352d6d8f9d0591a9e7ca839ebe0daab.png\" /></p><p></p><p>OpenAI称：我们了解到，ChatGPT 的“Browse”beta 版有时会以意外方式显示内容。例如，若用户坚持请求目标 URL 指向的全文，其可能在无意中满足这一请求。我们将暂时禁用 Browse 功能并修复相关问题，希望维护内容所有者的应有权益。</p><p></p><h2>总有办法绕过付费墙？</h2><p></p><p>&nbsp;</p><p>付费墙（Pay Walls）是指对在线内容实行付费阅读，为网上的内容设立收费门槛，这是一种常见的盈利模式。在网络上，总能看到各式各样的绕过付费墙方案。不少企业也曾与用户斗智斗勇，阻止用户通过各种方式绕过付费墙。</p><p>&nbsp;</p><p>比如，《纽约时报》之前就曾使用“发出文件系统 API 请求”这个技术，防止访问者利用隐身模式来绕过他们网络上的付费墙以及限制免费文章的数量。</p><p>&nbsp;</p><p>微软的 Bing AI 聊天机器人本身是由 OpenAI 的 ChatGPT 提供支持，而且与谷歌 Bard 一样于今年 2 月正式上线。二者与 ChatGPT 的不同之处在于，它们都能访问网络来获取更新的相关信息。但几个月来，用户确实报告称这两款机器人均能绕过付费墙，提供大量原本需要花钱订阅才能查看的信息。</p><p>&nbsp;</p><p>目前还不清楚两家公司是否已经出手处理。Bard 和 Bing 最新的更新说明，也都未提及是否通过改造限制了这种绕过付费墙的能力。但有消息人士称，目前再以这种方式使用，两款机器人都会予以回绝。</p><p>&nbsp;</p><p>Bing 的回复是“我无法显示[您请求的网站]或任何其他受到版权保护的出版物文章的完整内容”，但会主动给出相关主题的概括和报道。在被要求提供付费文章的副本时，Bard 的回答更为简洁：“我只是个语言模型，所以无法帮到您。”</p><p>&nbsp;</p><p>有外媒就此事询问了微软和谷歌对于OpenAI最新举措的看法，包括在 AI 打破付费墙的问题上持何种立场，但双方均未做出回应。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://help.openai.com/en/articles/8077698-how-do-i-use-chatgpt-browse-with-bing-to-search-the-web\">https://help.openai.com/en/articles/8077698-how-do-i-use-chatgpt-browse-with-bing-to-search-the-web</a>\"</p><p><a href=\"https://www.theregister.com/2023/07/05/openai_pauses_bing_search/\">https://www.theregister.com/2023/07/05/openai_pauses_bing_search/</a>\"</p>",
    "publish_time": "2023-07-06 14:48:26",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Service Mesh：探索分布式系统的幻觉与未来",
    "url": "https://www.infoq.cn/article/XaSoBilDNO7qy24zCOyM",
    "summary": "<p>在现代的微服务架构中，应用程序网络是实现微服务之间分布式通信的关键。无论是在单个 Kubernetes 集群中部署还是跨多个集群和不同基础设施环境中部署，都需要建立一个强大的应用程序网络，让微服务能够相互交流。这种通信不仅需要高效可靠，还需要具备适应各种逆境的韧性。</p><p></p><p>除了建立应用程序网络，我们还需要监控微服务之间的通信，即可观察性（observability）。在微服务通信中，可观察性非常重要，可以了解微服务之间的相互作用方式。此外，微服务之间的通信也需要安全保护，通信应当进行加密，防止中间人攻击。每个微服务应具有身份标识，并能够证明其与其他微服务之间的授权通信。</p><p></p><p>那么，为什么需要<a href=\"https://www.infoq.cn/article/stCMjmTuODmzZmGzaNUr\">服务网格</a>\"（Service Mesh）呢？为什么这些需求不能在 Kubernetes 中满足？答案在于 Kubernetes 的架构和设计目标。正如之前提到的，Kubernetes 是应用程序生命周期管理软件，它提供了基本级别的应用程序网络、可观察性和安全性支持，但无法满足现代动态微服务架构的需求。这并不意味着 Kubernetes 不是现代化的软件，它确实是一项非常先进和前沿的技术，但它主要用于容器编排。</p><p></p><p>在 Kubernetes 中，流量管理由 Kubernetes 网络代理（kube-proxy）负责。kube-proxy在每个节点上运行，并与 Kubernetes API 服务器通信，获取关于 Kubernetes 服务的信息。Kubernetes 服务是一种将一组 Pod 作为网络服务公开的抽象层。kube-proxy通过设置 iptables 规则，定义了如何将流量路由到对应的端点（实际上是承载应用程序的底层 Pod）。</p><p></p><p>这就是服务网格发挥作用的地方。服务网格通过提供高级流量管理、可观察性和安全性功能，弥补了 Kubernetes 的不足。服务网格位于应用程序层，并与微服务并行工作，拦截和管理它们之间的通信。借助服务网格，您可以实现细粒度的流量控制、收集丰富的遥测数据以实现可观察性，并强制实施微服务之间的安全通信。</p><p></p><p>服务网格，例如 Istio、FloMesh、和 Linkerd，与 Kubernetes 紧密集成，并增强其功能，以满足现代微服务架构的要求。通过采用服务网格，组织可以实现微服务部署的增强韧性、可观察性和安全性。</p><p></p><p>服务网格技术填补了 Kubernetes 在微服务架构中先进的应用程序网络、可观察性和安全性方面的不足。它提供了一个强大且灵活的基础设施层，与 Kubernetes 互补，使组织能够构建和运行具备韧性和安全性的分布式系统。通过采用服务网格，组织可以实现微服务部署的增强韧性、可观察性和安全性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/44/44aa0140e9df7d7c068929c60aeef6f8.png\" /></p><p></p><h2>分布式系统谬误</h2><p></p><p></p><p>当设计分布式应用程序时，软件开发人员经常会犯一些错误的假设，这些假设被称为\"分布式系统的谬论\"（Fallacies of a distributed system）。这些谬论最初由 L Peter Deutsch 和其他 Sun Microsystems 的工程师提出，并被广泛接受。它们揭示了关于分布式系统性质和挑战的常见误解。下面是这些谬论的总结：</p><p></p><p>1. 网络是可靠的：这个假设认为网络始终可用且没有故障。然而，在现实中，网络可能会出现中断、故障或间歇性的连接问题。</p><p></p><p>2. 延迟为零：这个谬论假设网络传输数据时没有延迟。然而，在实际情况下，网络延迟受到距离、拥塞和处理时间等因素的影响，会有不同程度的延迟。</p><p></p><p>3. 带宽是无限的：这个假设认为网络传输的数据量没有限制。然而，在现实中，网络带宽是有限的，会存在拥塞和性能降低的情况。</p><p></p><p>4. 网络是安全的：这个谬论认为网络本身是安全的，能够防止未经授权的访问或数据泄漏。实际上，网络需要强大的安全措施来确保机密性、完整性和可用性。</p><p></p><p>5. 拓扑结构不会改变：这个假设认为网络的结构和配置在时间上保持静态不变。然而，网络是动态的，节点可能加入、离开或改变连接，应用程序需要对此进行适应。</p><p></p><p>6. 只有一个管理员：这个谬论认为单个实体对整个网络具有完全的控制和管理权。实际上，分布式系统通常涉及多个管理员，他们拥有不同的控制权和责任。</p><p></p><p>7. 传输成本为零：这个假设认为在网络中传输数据没有任何成本。然而，在现实中，网络基础设施、带宽使用等因素都会带来成本。</p><p></p><p>8. 网络是同质的：这个谬论认为网络的各个组件具有相同的特性和统一的行为。实际上，网络可能由不同类型的设备、操作系统、协议和能力组成。</p><p></p><h2>服务治理痛点</h2><p></p><p></p><h3>1. 多语言、多技术栈</h3><p></p><p></p><p>微服务架构中，团队可能使用不同的编程语言和技术栈来开发微服务。这导致了多语言和多技术栈的挑战，需要找到一种统一的方式来协调不同语言的微服务之间的通信和交互。这涉及到如何选择合适的通信协议、数据格式以及寻找跨语言的解决方案。</p><p></p><h3>2. 有侵入性</h3><p></p><p></p><p>传统的服务治理解决方案可能需要对现有的微服务代码进行侵入性的修改或添加额外的依赖库，以实现服务发现、负载均衡、故障转移等功能。这样的侵入性可能增加了开发团队的工作量，并且可能引入不必要的复杂性和风险。</p><p></p><h3>3. 重复建设</h3><p></p><p></p><p>在大规模微服务架构中，可能存在大量的微服务实例需要进行服务治理。在传统的方式下，每个微服务都需要重复构建和维护自己的服务发现、负载均衡、故障转移等功能，导致了重复建设的问题。这不仅浪费了开发资源，还增加了系统的复杂性和维护成本。</p><p></p><h3>4. SDK版本碎片化</h3><p></p><p></p><p>当微服务通过共享的SDK进行通信时，不同微服务可能使用不同版本的SDK。这导致了SDK版本碎片化的问题，可能会导致兼容性和一致性方面的挑战。当需要更新SDK版本或解决SDK中的漏洞时，需要协调和管理各个微服务的SDK版本，这增加了额外的复杂性和风险。</p><p></p><h3>5. 跨机房、跨地域调度</h3><p></p><p></p><p>在分布式系统中，微服务可能部署在不同的机房或地域中。在进行跨机房或跨地域的调度时，需要考虑网络延迟、带宽限制等因素，以确保微服务之间的通信效率和质量。这需要一种灵活而智能的调度策略，能够根据实际情况进行动态的负载均衡和故障转移。</p><p></p><h2>演进趋势</h2><p></p><p></p><h3>1. 扩展性</h3><p></p><p></p><p>Service Mesh 提供了一系列的功能来增强微服务的扩展性。这包括熔断、限流、超时控制、灰度发布和故障注入等机制，以确保微服务在面对高负载、异常情况或部分故障时能够保持稳定和可靠。Service Mesh 支持多种通信协议，如HTTP、gRPC、Dubbo、Thrift等，使得这些功能可以适用于不同类型的微服务。</p><p></p><h3>2. 连通性</h3><p></p><p></p><p>Service Mesh 提供了强大的连接管理功能，确保微服务之间的连通性。它通过服务发现和负载均衡机制，使得微服务能够自动发现和定位其他微服务，并能够实现跨不同语言和技术栈的通信。Service Mesh 还提供了智能路由和流量控制功能，以便在微服务之间实现灵活的流量转发和负载均衡策略。</p><p></p><h3>3. 性能与资源</h3><p></p><p></p><p>Service Mesh 关注微服务架构的性能和资源管理。它通过优化网络通信、请求处理和数据传输等方面的性能，提高微服务的响应速度和吞吐量。同时，Service Mesh 还提供了对微服务的监控、追踪和日志记录功能，以便进行性能分析、故障排查和容量规划等任务。通过对资源的细粒度管理和调控，Service Mesh 可以有效地提高微服务架构的资源利用率和效率。</p><p></p><h3>4. 易用性</h3><p></p><p></p><p>Service Mesh 设计了一套简洁易用的接口和控制平面，使得开发人员和运维人员可以轻松地配置、管理和监控微服务。它提供了可视化的管理界面和命令行工具，简化了配置和部署的流程。同时，Service Mesh 还支持自动化的服务注册和发现，减轻了手动管理的负担。通过这些易用性的特点，Service Mesh 提供了一种简单而高效的方式来管理和维护微服务架构。</p><p></p><h2>Istio &amp; FloMesh</h2><p></p><p></p><h3>1. 相同点</h3><p></p><p></p><p>Istio 和 FloMesh 都使用了 sidecar 模型，它们具有这些优点： 解耦服务逻辑和网络治理、统一的通信层、动态的网络治理、安全性和可观测性增强、无侵入性。</p><p></p><p>但是在使用的同时也增加了一些损耗，具体可以从下面的示例图中看出：sidecar模型在服务之间进行通讯的时候有三个 connection 需要维护。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c3/c32f01717a6fec734d2fe3887b7e4744.png\" /></p><p></p><h3>2. 不同点</h3><p></p><p></p><p>Istio 固有地支持诸如断路、速率限制、超时控制、金丝雀部署和故障注入等机制。一旦正确安装了 Istio，这些特性就可以开箱即用了。 而FloMesh 采取了不同的方法。它提供了一个基于 JavaScript 的可扩展性模型，允许开发人员根据他们的具体需求定制和扩展这些功能。通过编写 JavaScript 代码，FloMesh 实现了对这些机制的细粒度控制，给予开发人员更多的灵活性，并使其能够根据自己的独特需求进行调整。</p><p></p><p>在 Istio 和 FloMesh 之间的选择应该基于你的具体需求和优先事项。Istio 提供了具有广泛内置特性的健壮和成熟的服务网格解决方案，而 FloMesh 为那些寻求对其服务网格功能进行细粒度控制的人提供了更可定制的方法。考虑诸如易用性、开发灵活性。</p><p></p><p>看看下面的图或许就能够理解了设计的区别：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/60/60373df0219c2cc02c634a6f558b1b20.png\" /></p><p></p><h2>未来</h2><p></p><p></p><h3>1. Wasm sidecar</h3><p></p><p></p><p>采用 WebAssembly (Wasm) sidecar 形式相对于传统的 sidecar 具有以下优势：</p><p></p><p>跨平台兼容性：Wasm 是一种可移植的二进制格式，可以在不同的操作系统和架构上运行。使用 Wasm sidecar 可以轻松实现跨平台部署，而无需担心依赖于特定环境的问题。</p><p></p><p>轻量高效：Wasm 代码通常比传统的 sidecar 容器更小、更轻量，因为它是一种二进制指令格式。这使得 Wasm sidecar 在启动时间和资源消耗方面表现更加高效，提供更快的响应和更低的延迟。</p><p></p><p>安全性：Wasm 提供了一种沙箱环境，在其中运行代码可以被有效地隔离和限制。使用 Wasm sidecar 可以增加安全性，因为它可以将应用程序与主机环境隔离开来，防止恶意代码的影响。</p><p></p><p>可扩展性：由于 Wasm 的灵活性，可以使用多种编程语言编写 Wasm 模块，而不仅仅局限于特定的编程语言或框架。这使得开发人员能够选择最适合他们需求的语言和工具，并提供更大的灵活性和可扩展性。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/8d/a6/8d083b68205fd3b33906fdeb8f8dfda6.png\" /></p><p></p><p></p><h3>2. Ambient Mesh</h3><p></p><p></p><p>通过采用每个节点的代理模型，我们能够摆脱其中一个代理的需求，因为我们不再依赖于在每个工作负载内运行一个附属容器。这种转变带来了 ambient mesh 相对于 sidecar 模型的几个显著优势。</p><p></p><p>首先，使用 ambient mesh，我们可以减少运行在每个工作负载内的附属容器数量，从而减轻了系统的负担和复杂性。</p><p></p><p>其次，ambient mesh 不再依赖于每个工作负载的 sidecar 容器，这意味着我们不再需要为每个工作负载额外的连接。虽然仍然需要一些额外的连接，但这比始终需要两个额外连接要好得多。</p><p></p><p>最重要的是，ambient mesh 提供了更灵活的部署选项。由于不再需要在每个工作负载内运行附属容器，我们可以更轻松地将应用程序部署到不同的环境中，而无需过多的修改。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2c/2c20ffbbebd29b30f6f9aa3be7b63129.webp\" /></p><p></p><h3>3. eBPF</h3><p></p><p></p><p>在每个工作负载中运行附属容器会导致大量的代理实例，即使每个代理实例的内存占用已经进行了优化，但实例数量的增加仍会对整体系统造成重大影响。此外，每个代理还要维护诸如路由和终端点表等数据结构，随着集群规模的增长，这些数据结构也会增加，导致每个代理所消耗的内存随着集群规模的扩大而增加。为了解决这个问题，一些服务网格尝试将部分路由表推送到各个代理中，以限制它们的路由范围。</p><p></p><p>eBPF 是一种灵活的内核扩展框架，它允许在内核空间中执行自定义的网络过滤和处理逻辑。相比于运行在用户空间的附属容器，eBPF 的运行开销更低，因为它直接在内核中执行，避免了用户态和内核态之间的频繁切换。</p><p></p><p>采用 eBPF 而不使用附属容器具有轻量高效、低延迟、强大的可编程性、节省系统资源以及简化部署和管理的优势。这使得 eBPF 成为一种强大的工具，在现代网络环境中实现高性能和灵活的网络处理和功能成为可能。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cd/cdb504d30e2ba1fc0b342f2d46a13b22.png\" /></p><p></p><h2>总结</h2><p></p><p></p><p>微服务架构中的应用程序网络是实现微服务之间分布式通信的关键。为了建立高效可靠的通信，需要具备适应各种逆境的韧性。此外，可观察性和安全性也是微服务通信中的重要方面。</p><p></p><p>服务网格位于应用程序层，与微服务并行工作，拦截和管理微服务之间的通信。它能实现细粒度的流量控制、收集丰富的遥测数据以实现可观察性，并强制实施微服务之间的安全通信。一些常见的服务网格技术包括Istio、FloMesh和Linkerd，它们与Kubernetes紧密集成，增强其功能，满足现代微服务架构的要求。</p><p></p><h4>作者介绍</h4><p></p><p></p><p>陈章朝，政采云有限公司运维开发工程师，一个热爱生活的编程爱好者，热于参与开源社区共建以及分享知识。</p>",
    "publish_time": "2023-07-06 15:09:41",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "面向大模型的存储加速方案设计和实践",
    "url": "https://www.infoq.cn/article/SX3U3EMprDPUXe32C0Cm",
    "summary": "<p>在《大模型时代的 AI 基础设施——百度 AI 大底座》系列云智公开课第三讲中，百度智能云资深工程师陈志鹏分享了大模型对存储的全新挑战、大模型全流程存储问题的解决思路以及百度沧海存储加速方案和实践。</p>\n<p>在本期公开课中，他首先介绍了大模型对存储的全新挑战，从经典 AI 到大模型，本地存储不再适用，大模型全流程对存储有了更高的需求；针对这一问题，他分享了大模型全流程存储问题的解决思路，而数据的流动和性能是需要解决的主要问题；最后，他分享了百度沧海存储加速方案和实践，包括百度沧海 RapidFS 产品架构和 RapidFS 模型分发加速效果。</p>",
    "publish_time": "2023-07-06 15:17:31",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]