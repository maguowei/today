[
  {
    "title": "我用GPT-3在单个代码库中发现 213个安全漏洞",
    "url": "https://www.infoq.cn/article/dIG7N5UNFWD87PySrRLc",
    "summary": "<p>本文最初发布于Better Programming。</p><p></p><p></p><blockquote>GPT-3在<a href=\"https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner\">这个Git代码库</a>\"中发现了213个安全漏洞。相比之下，市场上一款比较好的商业工具（来自一家著名的网络安全公司）却只发现了99个问题，不过商业工具提供了更好的结构化上下文。我随机手动检查了GPT-3检测到的213个漏洞中的50个，只有一个是假阳性。这两种工具的假阴性都很多。</blockquote><p></p><p></p><p>近年来，人工智能和机器学习领域取得了巨大的发展，并开辟了全新的可能性领域。其中一个备受关注的领域是基于人工智能的代码分析，特别是使用人工智能模型来检测代码中的安全漏洞。在这个实验中，我们使用OpenAI的GPT-3在<a href=\"https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner\">代码库</a>\"（包含129个有漏洞的文件）中查找安全漏洞。</p><p></p><h2>工作原理</h2><p></p><p></p><p>我使用的是GPT-3的一个变体（text-davinci-003），其上下文窗口有4000个词元，大约是3000个英语单词。这意味着每个请求最多只能处理几百行代码。很遗憾，GPT-3的当前架构无法一次处理整个代码库。</p><p></p><p>为了解决这个问题，我必须用GPT-3单独扫描每个文件。也就是说，GPT-3可能难以找到涉及多个代码文件交互的安全漏洞，除非import/export足够清楚，不需要具体查看代码就可以猜出那些函数的功能。</p><p></p><p>这种情况经常发生，特别是当源代码使用了常见的库时，如express.js、Flask、Python标准库、C标准库等。GPT-3很可能用到了许多最常见的库，有的是部分记忆的，有的是完全记忆的，有的是以其他方式编码的。在本文分析的代码中，GPT-3对导入的库有足够的先验知识，因此能够准确检测安全漏洞，而不需要检查任何导入的库代码。</p><p></p><p>公平地讲，不只GPT-3，我怀疑现在的许多商业漏洞扫描工具在进行静态分析时实际上并没有检查导入的库代码——所以与市场上已经存在的一些工具相比，它的工作方式并没有什么不同。</p><p></p><h2>分析的代码</h2><p></p><p></p><p>代码库中的每个文件夹都以一种类型的安全漏洞命名，其中的文件包含存在一个或多个漏洞的示例代码。这些文件中的代码有些没什么价值，但也有许多是你可能在生产代码库中遇到的很实际的代码片段（注意：它们不过是代码片段，并没有更大代码库的上下文信息）。代码库中每个文件夹下的README.md文件包含了GPT-3针对该文件夹中每个文件生成的安全漏洞分析。</p><p></p><p>接下来，让我们通过一些例子看看GPT-3是如何做到的！</p><p></p><h4>示例1</h4><p></p><p></p><p>下面是一个容易受到格式字符串攻击的<a href=\"https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner/blob/main/Format%20String%20Attacks/FormatString.c\">简单的C程序</a>\"：</p><p></p><p><code lang=\"plain\">#include \n \nint main(int argc, char **argv) {\n    char *secret = \"This is a secret!\\n\";\n \n    printf external link(argv[1]);\n \n    return 0;\n}</code></p><p></p><p>下面是GPT-3的分析（它是对的）：</p><p></p><p></p><blockquote>检出的漏洞：未验证用户输入：程序没有检查用户输入的长度，这可能导致缓冲区溢出攻击。格式字符串漏洞：程序没有检查用户输入的格式，这可能导致格式字符串攻击。</blockquote><p></p><p></p><h4>示例2</h4><p></p><p></p><p>让我们看一个用高级语言编写的不那么简单的程序，比如下面这个包含Log Forging漏洞的<a href=\"https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner/blob/main/Log%20Forging/logf.cs\">C#程序</a>\"。类似的代码，我在开源项目和生产代码库中都见过（不是那么没价值）：</p><p></p><p><code lang=\"plain\">using Microsoft.AspNetCore.Http;\nusing Microsoft.AspNetCore.Mvc;\nusing Microsoft.Extensions.Logging;\nusing System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Threading.Tasks;\n\nnamespace WebFox.Controllers\n{\n    [Route(\"api/[controller]\")]\n    [ApiController]\n    public class LogInjection : ControllerBase\n    {\n        private readonly ILogger _logger;\n\n\n\n        public LogInjection(ILogger logger)\n        {\n            _logger = logger;\n        }\n\n        [HttpGet(\"{userInfo}\")]\n        public void injectLog(string userInfo)\n        {\n            _logger.LogError(\"error!! \" + userInfo);\n        }\n    }\n}</code></p><p></p><p>以下是GPT-3的输出：</p><p></p><p></p><blockquote>检出的漏洞：日志注入漏洞：代码容易受到日志注入攻击，因为用户输入直接被记录，没做任何消毒处理。</blockquote><p></p><p></p><p>GPT-3的评价是对的——这段代码中有一个日志注入漏洞。</p><p></p><h4>示例3</h4><p></p><p></p><p><a href=\"https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner/blob/main/Out%20of%20Bounds/vuln.c\">下面的C程序</a>\"读取并操作一幅图像。它包含许多安全漏洞，包括越界（Out Of Bounds）读写：</p><p></p><p><code lang=\"plain\">#include\n#include\n#include\n\nstruct Image\n{\n    char header[4];\n    int width;\n    int height;\n    char data[10];\n};\n\nint ProcessImage(char* filename){\n\n    FILE *fp;\n    char ch;\n    struct Image img;\n\n    fp = fopen(filename,\"r\"); \n\n    if(fp == NULL)\n    {\n        printf(\"\\nCan't open file or file doesn't exist.\");\n        exit(0);\n    }\n\n    printf(\"\\n\\tHeader\\twidth\\theight\\tdata\\t\\r\\n\");\n\n    while(fread(&amp;img,sizeof(img),1,fp)&gt;0){\n        printf(\"\\n\\t%s\\t%d\\t%d\\t%s\\r\\n\",img.header,img.width,img.height,img.data);\n    \n        int size1 = img.width + img.height;\n        char* buff1=(char*)malloc(size1);\n\n        memcpy(buff1,img.data,sizeof(img.data));\n        free(buff1);\n    \n        if (size1/2==0){\n            free(buff1);\n        }\n        else{\n            if(size1 == 123456){\n                buff1[0]='a';\n            }\n        }\n\n        int size2 = img.width - img.height+100;\n        //printf(\"Size1:%d\",size1);\n        char* buff2=(char*)malloc(size2);\n\n        memcpy(buff2,img.data,sizeof(img.data));\n\n        int size3= img.width/img.height;\n        //printf(\"Size2:%d\",size3);\n\n        char buff3[10];\n        char* buff4 =(char*)malloc(size3);\n        memcpy(buff4,img.data,sizeof(img.data));\n\n        char OOBR_stack = buff3[size3+100];\n        char OOBR_heap = buff4[100];\n\n        buff3[size3+100]='c';\n        buff4[100]='c';\n\n        if(size3&gt;10){\n                buff4=0;\n        }\n        else{\n            free(buff4);\n        }\n\n        free(buff2);\n    }\n    fclose(fp);\n}\n\nint main(int argc,char **argv)\n{\n    ProcessImage(argv[1]);\n}</code></p><p></p><p>GPT-3的输出：</p><p></p><p></p><blockquote>检出的漏洞：未检查返回值：未检查fopen()函数的返回值，这可能导致空指针解引用。越界读取：使用memcpy()函数将数据从img.data复制到buff1和buff2，而不检查目标缓冲区的大小，这可能导致越界读取。3.越界写入：在写入buff3和buff4数组时未检查源缓冲区大小，这可能导致越界写入。未初始化内存访问：在未初始化的情况下访问OOBR_stack和OOBR_heap变量，这可能导致未定义的行为。内存泄漏：如果size3变量大于10，则buff4数组不会释放，这可能导致内存泄漏。</blockquote><p></p><p></p><p>GPT-3再次判断正确！</p><p></p><h4>示例4</h4><p></p><p></p><p>最后一个<a href=\"https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner/blob/main/Unsafe%20Deserialization/SerializeToFile.java\">Java示例</a>\"是我最喜欢的，因为很遗憾，在第一次阅读这段代码时，我没有发现它有任何问题。对我来说，它看起来完全无害且很常见——我实际见过类似的代码，但从未有过任何其他的想法。</p><p></p><p><code lang=\"plain\">class Utils\n{\n    // 该函数序列化一个对象，并将其写入一个文件\n    public static void SerializeToFile(Object obj, String filename)\n    {\n        try\n        {\n            FileOutputStream file = new FileOutputStream(filename);\n            ObjectOutputStream out = new ObjectOutputStream(file);\n\n            // 将对象序列化到文件中\n            System.out.println(\"Serializing \" + obj.toString() + \" to \" + filename);\n            out.writeObject(obj);\n\n            out.close();\n            file.close();\n        }\n        catch(Exception e)\n        {\n            System.out.println(\"Exception: \" + e.toString());\n        }\n    }\n\n    // 该函数从文件反序列化对象\n    public static Object DeserializeFromFile(String filename)\n    {\n        Object obj = new Object();\n\n        try\n        {\n            FileInputStream file = new FileInputStream(filename);\n            ObjectInputStream in = new ObjectInputStream(file);\n\n            // 从文件反序列化对象\n            System.out.println(\"Deserializing from \" + filename);\n            obj = in.readObject();\n\n            in.close();\n            file.close();\n        }\n        catch(Exception e)\n        {\n            System.out.println(\"Exception: \" + e.toString());\n        }\n\n        return obj;\n    }\n}</code></p><p></p><p>GPT-3的输出：</p><p></p><p></p><blockquote>检出的漏洞：不安全的反序列化：反序列化不受信任的数据可能导致远程代码执行。不安全的文件权限：正在写入或读取的文件可能具有不安全的权限，从而导致未经授权的访问。</blockquote><p></p><p></p><p>GPT-3再次判断正确。</p><p></p><h2>网络安全“终极”左移</h2><p></p><p></p><p>左移是在开发过程早期应用安全实践的过程——比如在将代码部署到生产环境之前测试安全漏洞。</p><p></p><p>人工智能代码分析代表了网络安全领域的终极左移，它通过应用最佳安全实践，在开发人员编写和提交代码时为他们提供网络安全指导。这可以真正地在组织内部培养起强大的网络安全文化，甚至可以防止下一次大规模黑客攻击，但是……</p><p></p><p>不可否认，这项技术还不完美，它会遗漏一些事情，而一个有经验的网络安全专业人士在审计时就不会遗漏。尽管如此，作为一种通用的大型语言模型，它还是非常不错的，而且成本比其他替代方案低很多。</p><p></p><p>目前，GPT-4的发布日期还不确定，但我相信，随着这些大型语言模型的功能越来越多，它们会继续向前发展。</p><p></p><h4>假阳性</h4><p></p><p></p><p>在手动检查GPT-3检出的213个漏洞中的约50个后，我唯一发现的假阳性是在这个<a href=\"https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner/blob/main/Unsafe%20Deserialization/unsafe.js\">JavaScript程序</a>\"的第13行：</p><p></p><p><code lang=\"plain\">var express = require('express');\nvar cookieParser = require('cookie-parser');\nvar escape = require('escape-html');\nvar serialize = require('node-serialize');\nvar app = express();\napp.use(cookieParser())\n \napp.get('/', function(req, res) {\n if (req.cookies.profile) {\n   var str = new Buffer(req.cookies.profile, 'base64').toString();\n   var obj = serialize.unserialize(str);\n   if (obj.username) {\n     res.send(\"Hello \" + escape(obj.username)); // &lt;--- GPT-3在这里犯了一个错误\n   }\n } else {\n     res.cookie('profile', \"eyJ1c2VybmFtZSI6ImFqaW4iLCJjb3VudHJ5IjoiaW5kaWEiLCJjaXR5IjoiYmFuZ2Fsb3JlIn0=\", {\n       maxAge: 900000,\n       httpOnly: true\n     });\n }\n res.send(\"Hello World\");\n});\napp.listen(3000);</code></p><p></p><p>GPT-3的输出：</p><p></p><p></p><blockquote>检出的漏洞：不安全的cookie设置（未设置安全标志）未验证的用户输入（cookie）反序列化未对用户输入（用户名）进行转义，可能存在XSS漏洞GPT-3对于前2个漏洞的判断是正确的，但第3个漏洞是假阳性—— obj.username 已经进行了编码，但GPT-3说没有。</blockquote><p></p><p></p><h4>GPT-3检测结果</h4><p></p><p></p><p>实验结果表明，经过扫描，GPT-3在129个文件的到86个中检出了安全漏洞。这真是令人印象深刻！</p><p></p><p>以下是脚本summarize_results.py生成的GPT-3检测结果的完整摘要：</p><p></p><p><code lang=\"plain\">在129个文件中，有86个检出了漏洞。\n总共检出了213个漏洞。\n\nGPT-3回复中使用的介绍性句子的出现频率（每个扫描的文件一个回复）：\n{'vulnerabilities detected': 73, 'no vulnerabilities detected.': 43, 'vulnerability detected': 6, 'answer': 2, 'potential vulnerabilities detected': 2, 'analysis': 1, 'security vulnerabilities detected': 1, 'no response given': 1} \n\n扫描的文件类型的分布：\n总计129个代码文件（不包括markdown和平面文件）\n{'.php': 50, '.js': 20, '.cs': 16, '.c': 14, '.java': 9, '.py': 8, '.rb': 5, '.asp': 3, '.ts': 2, '.go': 1, '.html': 1}</code></p><p></p><h4>与商业产品的对比</h4><p></p><p></p><p>为了完善这个实验，我将GPT-3的结果与商用代码漏洞扫描工具<a href=\"https://snyk.io/product/snyk-code/\">Snyk Code</a>\"（由Snyk公司开发）做了比较。我认为，Snyk公司开发的安全产品非常出色。通过扫描，Snyk Code从这个代码库中发现了99个安全漏洞，而GPT-3发现了213个安全漏洞。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/12/1225fdb6cb913f9281659cf78de5d6e8.png\" /></p><p></p><p>其中一个原因是Snyk Code只支持其中部分编程语言，并且只能扫描大约103个文件，而GPT-3扫描了129个文件。</p><p></p><p>此代码库中存在漏洞的代码片段来自<a href=\"https://github.com/snoopysecurity/Vulnerable-Code-Snippets\">snoopysecurity/Vulnerable-Code-Snippets</a>\"，这是一个很棒的资源。我试着删除了嵌入在代码段中的注释，从中可以看出这个代码段中包含哪些安全漏洞。这些需要删除的注释中包含指向这些示例片段出处的博文链接。要查看它们在原代码库中的位置，可以查看<a href=\"https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner/blob/main/attributions.md\">attributions.md</a>\"文件。</p><p></p><p>原文链接：<a href=\"https://betterprogramming.pub/i-used-gpt-3-to-find-213-security-vulnerabilities-in-a-single-codebase-cc3870ba9411\">https://betterprogramming.pub/i-used-gpt-3-to-find-213-security-vulnerabilities-in-a-single-codebase-cc3870ba9411</a>\"</p>",
    "publish_time": "2023-03-30 07:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Java近期新闻：新JEP、GraalVM 23早期访问构建、Infinispan、Mojarra、Micrometer Metrics",
    "url": "https://www.infoq.cn/article/F6cg96zpRMMi9uAq1zyU",
    "summary": "<p></p><h4>OpenJDK</h4><p></p><p></p><p>上周，JEP 440（<a href=\"https://openjdk.org/jeps/440\">记录模式</a>\"）已从JEP Draft 8300541<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-March/007470.html\">提升</a>\"到Candidate状态。该JEP最终确定了这一特性，并针对前2轮<a href=\"https://openjdk.java.net/jeps/12\">预览</a>\"的反馈做了增强。这两轮预览分别是在JDK 20中发布的JEP 432（<a href=\"https://openjdk.org/jeps/432\">记录模式第2次预览</a>\"）和在JDK 19中发布的JEP 405（<a href=\"https://openjdk.org/jeps/405\">记录模式预览</a>\"）。该特性为这门语言添加了记录模式，用于解构记录值。记录模式可以与类型模式搭配使用，为“强大的声明式、可组合数据导航和处理形式”提供支持。最近，类型模式被扩展应用于switch 的选择标记：JEP 420（<a href=\"https://openjdk.java.net/jeps/420\">switch模式匹配第2次预览</a>\"，在JDK 18中交付）和JEP 406（<a href=\"https://openjdk.java.net/jeps/406\">switch模式匹配预览</a>\"，在JDK 17中交付）。JEP 432最重要的变化是不再支持在增强for语句头中使用记录模式。</p><p>&nbsp;</p><p>类似地，JEP 441（<a href=\"https://openjdk.org/jeps/441\">switch模式匹配</a>\"）已经从JEP Draft 8300542<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-March/007471.html\">提升</a>\"到Candidate状态。该JEP最终确定了这一特性，并针对前4轮的预览反馈做了增强：JEP 433（<a href=\"https://openjdk.org/jeps/433\">switch模式匹配第4次预览</a>\"），在JDK 20中交付；JEP 427（<a href=\"https://openjdk.org/jeps/427\">switch模式匹配第3次预览</a>\"），在JDK 19中交付；JEP 420（<a href=\"https://openjdk.java.net/jeps/420\">switch模式匹配第2次预览</a>\"），在JDK 18中交付；JEP 406（<a href=\"https://openjdk.java.net/jeps/406\">switch模式匹配开关预览</a>\"），在JDK 17中交付。该特性通过在switch表达式和语句中支持模式匹配来增强语言。</p><p>&nbsp;</p><p>JEP 442（<a href=\"https://openjdk.org/jeps/442\">外部函数和内存API第3次预览</a>\"）已经从JJEP Draft 8301625<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-March/007473.html\">提升</a>\"到Candidate状态。这个JEP基于之前的反馈做了改进：JEP 434（<a href=\"https://openjdk.org/jeps/434\">外部函数和内存API第2次预览</a>\"），在JDK 20中交付；JEP 424（<a href=\"https://openjdk.org/jeps/424\">外部函数和内存API预览</a>\"），在JDK 19中交付；JEP 419（<a href=\"https://openjdk.org/jeps/419\">外部函数和内存API第2轮孵化</a>\"），在JDK 18中交付；JEP 412（<a href=\"https://openjdk.org/jeps/412\">外部函数和内存API第1轮孵化</a>\"），在JDK 17中交付。该特性为Java应用程序提供了一个可以与Java运行时之外的代码和数据进行互操作的API，让它们可以高效地调用外部函数以及安全地访问不受JVM管理的外部内存。JEP 434的更新包括：在Arena接口中集中管理原生段（native segments）的生命周期；使用一个新元素解引用地址布局，增强布局路径；删除VaList类。</p><p>&nbsp;</p><p>JEP Draft 8303683（<a href=\"https://openjdk.org/jeps/8303683\">虚拟线程</a>\"）是由<a href=\"https://inside.java/u/RonPressler/\">Ron Pressler</a>\"（Oracle Loom项目架构师和技术主管）和<a href=\"https://inside.java/u/AlanBateman/\">Alan Bateman</a>\"（Oracle Java平台组架构师）于上周提交的。该JEP建议根据前2轮预览的反馈最终确定这一特性：JEP 436（<a href=\"https://openjdk.org/jeps/436\">虚拟线程第2次预览</a>\"），在JDK 20中交付；JEP 425（<a href=\"https://openjdk.org/jeps/425\">虚拟线程预览</a>\"），在JDK 19中交付。该特性为Java平台提供了虚拟线程。这种轻量级的线程极大地减少了编写、维护和观察高吞吐量并发应用程序的工作量。与JEP 436相比，其最重要的变化是虚拟线程现在完全支持<a href=\"https://openjdk.org/jeps/8303683#Thread-local-variables\">线程局部变量</a>\"，取消了不使用这些变量的选项。要了解更多关于JEP 425的细节，可以阅读<a href=\"https://www.infoq.com/news/2022/05/virtual-threads-for-jdk19/\">InfoQ的新闻报道</a>\"及观看<a href=\"https://www.linkedin.com/in/jos%C3%A9-paumard-2458ba5/\">José Paumard</a>\"（Oracle Java平台组Java开发大使）提供的JEP Café<a href=\"https://inside.java/2022/06/08/jepcafe11/\">截屏视频</a>\"。</p><p>&nbsp;</p><p>JEP Draft 8304400（<a href=\"https://openjdk.org/jeps/8304400\">启动多文件源代码程序</a>\"）也是由Pressler提交的。该JEP建议增强Java启动器，让它可以执行以一个或多个Java源代码文件形式提供的应用程序。这样就可以推迟全面的项目设置，使得从小型应用程序到大型应用程序的过渡更加平滑。</p><p>&nbsp;</p><p></p><h4>JDK 20</h4><p></p><p></p><p>JDK 20仍处于<a href=\"https://openjdk.java.net/jeps/3#rc\">发布候选</a>\"阶段，GA版本预计将于2023年3月21日发布。<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-20%2B36\">Build 36</a>\"仍然是JDK 20<a href=\"https://jdk.java.net/20/\">早期访问构建</a>\"的当前构建。要了解关于这个版本的更多细节，请查看<a href=\"https://jdk.java.net/20/release-notes\">发布说明</a>\"。</p><p>&nbsp;</p><p></p><h4>JDK 21</h4><p></p><p></p><p>JDK 21的<a href=\"https://jdk.java.net/21/\">早期访问构建</a>\"<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-21%2B14\">Build 14</a>\"也于上周发布，其中包括来自Build 13的<a href=\"https://github.com/openjdk/jdk/compare/jdk-21%2B13...jdk-21%2B14\">更新</a>\"，该更新修复了各种<a href=\"https://bugs.openjdk.org/issues/?jql=project%20%3D%20JDK%20AND%20fixversion%20%3D%2021%20and%20%22resolved%20in%20build%22%20%3D%20b14%20order%20by%20component%2C%20subcomponent\">问题</a>\"。要了解关于这个版本的更多细节，请查看<a href=\"https://jdk.java.net/21/release-notes\">发布说明</a>\"。</p><p>&nbsp;</p><p>对于<a href=\"https://openjdk.java.net/projects/jdk/20/\">JDK 20</a>\"和<a href=\"https://openjdk.java.net/projects/jdk/21/\">JDK 21</a>\"，我们鼓励开发人员通过<a href=\"https://bugreport.java.com/bugreport/\">Java Bug数据库</a>\"报告Bug。</p><p>&nbsp;</p><p></p><h4>GraalVM</h4><p></p><p></p><p>Oracle实验室<a href=\"https://twitter.com/graalvm/status/1636747570377523200?cxt=HHwWgICw9cnP8rYtAAAA\">发布</a>\"了GraalVM 23.0.0的最新早期访问开发构建。其新特性包括：对<a href=\"https://docs.oracle.com/en/graalvm/enterprise/20/docs/reference-manual/native-image/Resources/\">Native Image Bundles</a>\"的初始支持；经过改进的Linux上AWT支持；原生镜像推荐。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/graalvm/graalvm-ce-dev-builds/releases/tag/23.0.0-dev-20230317_0549\">发布说明</a>\"。</p><p>&nbsp;</p><p></p><h4>Spring Framework</h4><p></p><p></p><p>Spring Tools 4.18.0<a href=\"https://spring.io/blog/2023/03/15/spring-tools-4-18-0-released\">发布</a>\"，新特性包括：经过升级的Eclipse 2023-03 IDE；经过改进的新一代Spring Data存储库查询方法内容辅助；修复了导致VSCode中常规Java内容辅助停止工作的问题；修复m2e资源文件（如application.properties ）不向目标文件夹复制的问题。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/spring-projects/sts4/releases/tag/4.18.0.RELEASE\">发布说明</a>\"。</p><p>&nbsp;</p><p></p><h4>Quarkus</h4><p></p><p></p><p><a href=\"https://quarkus.io/blog/quarkus-3-0-0-alpha6-released/\">Quarkus 3.0.0的第6个Alpha版本</a>\"提供了2个新特性：通过将quarkus.datasource.jdbc.telemetry 属性设置为true来启用OpenTelemetry for JDBC；CredentialsProviders接口现在支持MongoDB连接。该版本还进行了依赖项升级，包括：SnakeYaml 2.0、Maven Compiler Plugin 3.11.0、Maven OpenRewrite Maven Plugin 4.41.0、SmallRye Common 2.1.0和JBoss Threads 3.5.0.Final。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/quarkusio/quarkus/releases/tag/3.0.0.Alpha6\">更新日志</a>\"。</p><p>&nbsp;</p><p></p><h4>Hibernate</h4><p></p><p></p><p><a href=\"https://in.relation.to/2023/03/17/orm-62-cr4/\">Hibernate ORM 6.2的第4个候选版本</a>\"根据Java社区的反馈提供了33个Bug修复和28个改进。预计这将是最终版本发布之前的最后一个候选版本。</p><p>&nbsp;</p><p></p><h4>Micrometer</h4><p></p><p></p><p><a href=\"https://github.com/micrometer-metrics/micrometer/releases/tag/v1.11.0-M2\">Micrometer Metrics 1.11.0的第2个里程碑版本</a>\"提供了一些新特性，包括：一个新指标jvm.threads.started ，用于报告JVM中活动应用程序线程的总数；一个新的ElasticSearch端点\\_index\\_template，用于创建索引模板；将GC名称添加到jvm.gc.pause指标；在基于OSGi的Java运行时上支持Micrometer 库。</p><p>&nbsp;</p><p>类似地，Micrometer Tracing 1.1.0的第2个里程碑版本也提供了一些新特性，包括：<a href=\"https://spring.io/projects/spring-cloud-sleuth\">Spring Cloud Sleuth</a>\"注解的等效物；依赖项升级到Micrometer 1.11.0-M2和OpenTelemetry 1.24.0。</p><p>&nbsp;</p><p></p><h4>Infinispan</h4><p></p><p></p><p>Infinispan 14.0.7.Final<a href=\"https://infinispan.org/blog/2023/03/13/infinispan-14\">发布</a>\"，支持Spring Framework 6和Spring Boot 3。它提供了一些值得注意的Bug修复，包括：MetricsCollector类中的NullPointerException；JSON解析器不能正确报告错误位置；Redis序列化协议（RESP）端点不能解析超过数据包大小的请求；并发访问<a href=\"https://spring.io/projects/spring-session\">Spring Session</a>\"集成会导致会话属性丢失。</p><p>&nbsp;</p><p></p><h4>Piranha</h4><p></p><p></p><p><a href=\"https://piranha.cloud/\">Piranha</a>\"23.3.0<a href=\"https://github.com/piranhacloud/piranha/releases/tag/v23.3.0\">发布</a>\"，显著的变化包括：升级<a href=\"https://codeql.github.com/\">CodeQL</a>\"工作流；为DefaultAnnotationManager类添加JUnit测试；修复当端点应用程序仍处于部署过程中时报RuntimeException的问题。要了解关于这个版本的更多细节，请查阅<a href=\"https://javadoc.io/doc/cloud.piranha/project/latest/index.html\">文档</a>\"和<a href=\"https://github.com/piranhacloud/piranha/issues?q=is%3Aissue+-label%3Awontfix+milestone%3A23.3.0+is%3Aclosed\">问题跟踪系统</a>\"。</p><p>&nbsp;</p><p></p><h4>Reactor项目</h4><p></p><p></p><p><a href=\"https://github.com/reactor/reactor/blob/main/README.md\">Reactor</a>\" 2022.0.5是该项目的<a href=\"https://github.com/reactor/reactor/releases/tag/2022.0.5\">第5个维护版本</a>\"，依赖项升级到reactor-core 3.5.4、reactor-addons 3.5.1、reactor-netty 1.1.5、reactor-kafka 1.3.17和reactor-kotlin-extensions1.2.2。</p><p>&nbsp;</p><p></p><h4>Eclipse Mojarra</h4><p></p><p></p><p>Eclipse Mojarra 4.0.2<a href=\"https://twitter.com/OmniFishEE/status/1636829803721392128?cxt=HHwWgICwiZiCmLctAAAA\">发布</a>\"，带来了一些显著的变化，包括：清理MockServletContext类，删除未使用的方法并添加@Override注解；清理ParseXMLTestCase类，删除未使用的方法、变量和注释掉的代码；确保@FacesConfig注解中的version()方法不会返回null；修复了在更新数据表分页标题中的按钮时报NumberFormatException的问题。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/eclipse-ee4j/mojarra/releases/tag/4.0.2-RELEASE\">发布说明</a>\"。</p><p>&nbsp;</p><p></p><h4>Apache软件基金会</h4><p></p><p></p><p>Apache Groovy 4.0.10<a href=\"https://www.mail-archive.com/announce@apache.org/msg08029.html\">发布</a>\"，带来了一些值得注意的Bug修复和改进，包括：来自GroovyScriptEngine类的令人困惑的错误消息；局部变量值未丢弃时的内存泄漏；@Builder注解在JDK 16上不起作用；MissingPropertyException截断嵌套类的类名。要了解关于这个版本的更多细节，请查看<a href=\"https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12318123&amp;version=12352914\">发布说明</a>\"。</p><p>&nbsp;</p><p>类似地，<a href=\"https://www.mail-archive.com/announce@apache.org/msg08028.html\">Apache Groovy 3.0.16</a>\"也带来了一些值得注意的Bug修复，包括：无法在JRE 16+的闭包或Lambda表达式上从BiPredicate接口调用方法；使用@CompileStatic注解会混淆静态导入的实例和方法；IllegalAccessException会使用JDK 17和Groovy 3.0.9的默认接口方法。该版本还支持JDK 16。要了解关于这个版本的更多细节，请查看<a href=\"https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12318123&amp;version=12352913\">发布说明</a>\"。</p><p>&nbsp;</p><p></p><h4>JHipster</h4><p></p><p></p><p>JHipster团队<a href=\"https://twitter.com/pascalgrimaud/status/1635700948583448582?cxt=HHwWjICw8ZXWlrMtAAAA\">发布</a>\"了JHipster Lite 0.29.0，带来了新特性和功能增强，包括：根据用户反馈删除JHipsterModulePackageJson类的依赖；删除当Cassandra数据库应用程序中正在测试的活动ApplicationContext会话超过四个时的警告消息；新的Redis依赖项和配置。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/jhipster/jhipster-lite/releases/tag/v0.29.0\">发布说明</a>\"。</p><p>&nbsp;</p><p></p><h4>JReleaser</h4><p></p><p></p><p><a href=\"https://jreleaser.org/\">JReleaser</a>\" 1.5.1（一个简化项目发布的Java实用工具）<a href=\"https://andresalmiray.com/jreleaser-1-5-1-has-been-released/\">发布</a>\"，带来了一些值得注意的修复，包括：添加<a href=\"https://jreleaser.org/guide/latest/reference/assemble/native-image.html\">Native Image</a>\"汇编程序实用工具中缺少的graalVMNativeImage属性；<a href=\"https://jreleaser.org/guide/latest/reference/assemble/java-archive.html\">Java Archive</a>\"实用工具为JAVA_OPTS环境变量生成的错误格式；改进执行外部命令时的错误处理。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/jreleaser/jreleaser/releases/tag/v1.5.1\">发布说明</a>\"。</p><p>&nbsp;</p><p></p><h4>JobRunr</h4><p></p><p></p><p>JobRunr 6.1.2<a href=\"https://github.com/jobrunr/jobrunr/releases/tag/v6.1.2\">发布</a>\"，主要是修复了两个Bug：当使用MySQL并将useServerPrepStmts属性设置为true时，元数据更新失败，并导致最终关闭；<a href=\"https://www.jobrunr.io/en/documentation/configuration/quarkus/\">JobRunr Quarkus扩展</a>\"中JobRunrDocumentDBStorageProviderProducer类未使用正确配置的问题。</p><p>&nbsp;</p><p></p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/03/java-news-roundup-mar13-2023/\">https://www.infoq.com/news/2023/03/java-news-roundup-mar13-2023/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/SZXNxA7DaBzCddCNAUxG\">Java 20 发布，新特性一览：Amber、Loom 和 Panama 项目</a>\"</p><p><a href=\"https://www.infoq.cn/article/P1vXcLlwewcK5XQQIQdN\">Java 近期新闻：JDK 21 序列集合、JDK 20 向量 API、Gen ZGC、Hilla 2.0</a>\"</p>",
    "publish_time": "2023-03-30 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "基于 eBPF 的云原生可观测性深度实践",
    "url": "https://www.infoq.cn/article/H1WOWBgxK5Y55EemDHze",
    "summary": "<p></p><p></p><blockquote>本文由 InfoQ 整理自云杉网络 DeepFlow 产品负责人向阳在 QCon 全球软件开发大会（北京站）2022 上的演讲分享。</blockquote><p></p><p></p><p>大家好，我是<a href=\"https://qcon.infoq.cn/2023/beijing/presentation/4546\">向阳</a>\"，我从清华大学毕业之后就来到了云杉网络，目前负责云原生可观测性产品 <a href=\"https://www.yunshan.net/products/deepflow.html\">DeepFlow</a>\"。这个产品其实有些年头了，它诞生于 2016 年，并且已经走进了上百个金融、能源、运营商行业的 500 强客户中。去年我们把产品的内核进行了开源，希望它能被更多其他行业、其他国家的用户所知晓。目前开源的时间还不长，7 月份刚有了第一个社区版的 Release，在这里也欢迎大家加入我们的开源社区。</p><p></p><h3>前言</h3><p></p><p></p><p>相信大家都有感受，eBPF 最近一年突然火了起来，特别是在可观测性领域。但实际上追溯起来，它的前身 BPF 技术已经有 30 年历史了。我们基于这项有着悠久历史的「新」技术，在它之上做出了一些非常令人激动人心的创新，特别是对 Distributed Tracing 问题给出了一种全新的解法。我相信即使是从世界范围上来讲，我今天分享的内容也能称得上是颠覆性的改变。</p><p></p><p>在准备这次的 <a href=\"https://qcon.infoq.cn/2023/beijing/schedule\">QCon </a>\"演讲时，我还问了一下 ChatGPT，基于它更新到 2021 年的知识体系，我问它 eBPF 能否用于实现 Distributed Tracing？它像模像样地编了一大堆话，不过最终得出了否定的结论，并建议我使用 OpenTracing。</p><p></p><p>DeepFlow 希望利用以 eBPF 为代表的自动化技术，去降低实现可观测性的复杂度，为开发同学带来自由，促进开发和运维的和睦相处。今天我分享的主角是 eBPF，它带来的安全、灵活的内核可编程能力可以做很多事情，但本文会聚焦在如何利用它来创新的解决分布式追踪问题上。</p><p></p><p>在此之前，我会先回顾一下分布式追踪的历史，然后聚焦介绍 DeepFlow 利用 eBPF 做出的酷炫特性，即 AutoTracing，它不用修改任何代码就能实现分布式追踪，然后介绍我们如何将 eBPF 和 OpenTelemetry 这两项技术结合形成令人激动的全栈、全链路分布式追踪方案，最后简单看看 DeepFlow 作为一个可观测性平台的其它能力。</p><p></p><p></p><h3>分布式追踪：回顾十四年历史，剖析云原生时代的新痛点</h3><p></p><p></p><p>相信大家非常熟悉分布式追踪，追踪数据是可观测性三大支柱之一。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/07/0790ec5b8e97dfe92dd96920d25c3f18.png\" /></p><p></p><p>通过采集一个 Trace 在多个进程中的 Span，最终我们能得到这样一个火焰图，它有点类似于我们对单一进程做的 CPU Profile，区别在于分布式追踪是一个聚焦在单次业务请求上的、覆盖多个服务进程的全景火焰图。它从上到下描述了一个分布式应用在服务之间的远程调用关系、服务内部的函数调用关系，它能够快速帮助开发者，特别是由很多个跨团队的微服务开发同学快速确定问题发生的位置，找到对应的负责人。基于这样的火焰图，我们还可以从中聚合出一些应用性能指标，比如说每个服务的吞吐、时延、异常，以及服务之间的访问关系拓扑等。</p><p></p><p></p><h4>分布式追踪的十四年</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3c/3cad63ee0973b0b5ea3659e185227d96.png\" /></p><p></p><p>一般认为分布式追踪可以追溯到 Google 的 Dapper 论文上，这个论文是 2010 年发表的，论文里讲到 Google 从 2008 年开始做 Dapper 这个系统，解决 Google 内部微服务调用追踪的问题。受这篇论文启发，开源社区诞生了一批优秀的项目，例如非常火的 Apache SkyWalking 就是聚焦在这个问题上。再到最近几年，开发者们发现插桩这件事应该要标准化、自动化，因为它侵入了业务程序中，随着开发语言、微服务框架越来越多样化，开发者们不希望因为插桩这件事去太多修改业务代码，在这个驱动力之下诞生了 OpenTracing，进而发展为 OpenTelemetry。</p><p></p><p></p><h4>云原生时代的痛：插码插不全</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/62/6277fb3dd91ae361736d4d0042acb45e.png\" /></p><p></p><p>在云原生时代，分布式追踪这件事变得越来越迫切，也遇到越来越严峻的挑战。首先，随着服务拆成，单个微服务的业务代码会越来越简单，同时有一部分公共逻辑会逐渐的卸载到基础设施中，比如说通过服务网格或 API 网关实现。因此微服务会越来越轻，开发写的代码会越来越聚焦在业务逻辑方面，这是一个趋势。</p><p></p><p>另外一点是微服务技术栈的多样性，如果微服务变得越来越简单了，开发同学就会有越来越多的自由，可以选择自己比较喜欢的框架和语言。但是这会导致一个问题，分布式追踪在这种场景下越来越不容易全面覆盖。有一个以往我们很喜欢的东西 Java Agent，它可以做到无侵扰的插码，在对业务代码无修改的情况下实现一定程度上的分布式追踪能力。</p><p></p><p>但是，一方面注入 JavaAgent 还是需要重启业务进程，另一方面在其它语言中一般不存在类似的字节码注入机制，比如说对于 Golang。假设你是公司内部的基础设施开发团队，你负责开发维护 Golang 的 SDK 去做 Instrumentation，可以想象在 SDK 每发布一个新版本之后，都需要漫长的时间来让公司里众多业务部门将 SDK 更新到新版本，这个时间可能会长达半年甚至一年，是一个非常漫长非常无奈的过程。因此，大家几乎有一个共识，现有的依靠插码的分布式追踪，落地起来还是很有难度的，是一项需要协调所有业务开发部门的工作。</p><p></p><p></p><h4>云原生时代的痛：链路追不全</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f0/f0af296be0e2fb567f41568abc1ca796.png\" /></p><p></p><p>云原生时代的另外一个趋势，通信路径的复杂性。以往服务之间的通信路径非常简单，最早的时候可能是两台服务器通过网线和交换机直接连起来，甚至是在同一台服务器上通过本地 Socket 直接通信。但在云原生时代，开发同学会发现两个服务之间可能跨越了千山万水，有 Pod 里面的 Service Mesh Sidecar、云服务器中的虚拟网桥、KVM 宿主机上虚拟交换机，还有大量的四七层网关、消息队列、中间件等等，通信路径非常复杂。</p><p></p><p>与此同时，几乎所有的分布式追踪机制其实都只聚焦在业务代码、框架 / 库函数两个层面，对服务之间的通信路径缺乏覆盖。然而，在微服务数量从 1 增长到 N 的过程中，服务之间通信路径的复杂度极端情况下可能增长了 N^2，复杂度的增长达到了几个数量级。造成的后果是，业务出现问题之后，依靠现有的分布式追踪能力开发同学往往找不到问题所在，越是聚焦在业务开发的同学，对于底层的这些云原生基础设施会了解地越少。我们发现经常会发生的经典故事是，开发难以回答到底是自己的问题、上下游服务的问题，还是基础设施的问题。由于分布式追踪无法覆盖云原生基础设施中的通信路径，这个问题往往无法回答，导致一个工单来回在不同团队之间无效流转。</p><p></p><p>确实，上述就是我们的现状，微服务越来越多样，通信路径越来越复杂，导致了分布式追踪越来越重要，但又越来越难以追全。</p><p></p><p></p><h3>AutoTracing：基于 eBPF，零代码修改实现分布式追踪</h3><p></p><p></p><p>铺垫了这么多，下面介绍本文的主角，DeepFlow 基于 eBPF 做的一个非常酷的能力 AutoTracing，即零代码修改、零应用发布、零进程重启的分布式追踪能力。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/86/86150e047d80be0685f82a869b297398.png\" /></p><p></p><p>上图是去年的截图，粘贴的是 Google 的搜索结果，如果今年再写 PPT 的话应该要贴 ChatGPT 的图了。从图中可以看到搜索 eBPF Tracing 有 10 万个结果，但这些结果中的 Trace 实际上都是指在一台单一的主机上去 Trace 函数调用、系统调用等行为，这些都是 eBPF 被大家所熟知的能力，然而他们并不是今天我们要谈论的 Distributed Tracing。</p><p></p><p></p><h4>Istio Bookinfo 零插码追踪 Demo</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/33/335afa43a916c2066ad39ddc7c13bd98.png\" /></p><p></p><p>那到底 eBPF 能用于实现分布式追踪吗？我们先来看一下 DeepFlow 做到的效果，上图是一个基于 Istio 的热门 Demo，这个叫 Bookinfo 的 Demo 我相信有很多朋友都比较熟悉，这里有四五种语言实现的几个微服务，覆盖了 C++（Envoy）、Python、Java、Ruby 和 Node.js。当然熟悉的朋友会知道，Istio 这个 Demo 中官方是做了 OTel 插桩的，但接下来的所有结果都是基于关闭所有这些 OTel 插桩后得到的，下文将给大家展示一下 eBPF 能做到什么程度。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/25/254c8c24b1d800cb02979d8428f699dc.png\" /></p><p></p><p>首先来确认手动插桩确实都关闭了，上图是 Jaeger 对 Bookinfo 的追踪效果。注意这一页并不是我忘记写内容了，而是想告诉大家离开了插桩 Jaeger 得不到任何追踪结果。</p><p></p><p></p><h4>DeepFlow AutoTracing：零插码、全栈</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/47/47df3b0978bcd14da6024f16bee2bfee.png\" /></p><p></p><p>是时候让 DeepFlow 上场了！大家可以看到，没有任何代码修改、没有任何重编译重发布、没有任何进程重启的前提下，DeepFlow 得到了上图所示的分布式追踪火焰图，这就是 AutoTracing 的效果。这里的每一行作为一个 Span，表达了一个调用在特定位置上被 eBPF 捕获到的事件。从火焰图中我们可以发现 Demo 中涉及到的所有服务，包括各种语言实现的业务微服务如 Productpage、Reviews 等，包括基础设施服务如 Envoy Sidecar、K8s CNI 等，以及还包括客户端 curl 进程，一个云原生业务的全栈分布式调用路径被完整的追踪下来了。</p><p></p><p>上图中有两种 Span：彩色的是 DeepFlow 利用 eBPF kprobe/tracepoint/uprobe/USDT 从 Kernel 系统调用和 User 函数调用中采集到的系统 Span，灰色是利用 BPF（Classic BPF）从虚拟网络中每个网卡（即内核中的 IP 收发包函数）中采集到的网络 Span。基于这两种 Span 进行关联，然后绘制出一次业务请求背后整个分布式调用的火焰图画。现在这个图中只是给了大家一些直观上的体感，接下来我们把这个图稍微放大一点，看看它的一些细节效果，来进一步感受一下。</p><p></p><p></p><h4>感受 DeepFlow 的 AutoTracing</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/25/25a1298d337ce3bf32a355f89c4e2768.png\" /></p><p></p><p>1.零插码：且无需向 HTTP 头注入 TraceID 或 SpanID</p><p>2.全链路：4 个调用、38 个 Span，分为 24 eBPF Span + 14 BPF Span</p><p>3.多语言：Java、Python、Ruby、Node.js 及 C/C++ (curl/envoy)</p><p>4.全栈：追踪两个微服务之间的网络路径，从 Pod 到 Node 到 KVM，IPIP、VXLAN、…</p><p>5.全栈：追踪微服务内从 Envoy Ingressjian 到 服务 到 DNS 到 Envoy Egress 全过程</p><p>案例：某互联网客户，使用 DeepFlow 5 分钟内定位客户端慢服务端不慢的经典扯皮问题。</p><p></p><p>首先，零代码修改。完成上图中的分布式追踪，DeepFlow 确实没有向调用中注入任何 TraceID 或 SpanID，同样也确实没有修改哪怕一行代码、没有重启任何一个进程。这个 Demo 中追踪火焰图覆盖到了所有 6 个进程，包括 C 语言实现的 curl、C++ 实现的 Envoy、Python 实现的 ProductPage、Ruby 实现的 Details、Java 实现的 Reviews、Node.js 实现的 Ratings；覆盖到了他们之间的所有 4 个调用，并采集到了 38 个 Span，其中包括 24 个 eBPF Span 和 14 个 BPF Span。</p><p></p><p>其次，再来看全栈追踪能力。举两个例子，第一个是上图中顶部蓝色的 curl 进程（在 loadgenerator Pod 中）调用下放绿色的 ProductPage 服务，我们会发现，从客户端 curl 进程、客户端 LoadGenerator Pod 虚拟网卡、客户端 K8s Node 物理网卡、服务端 K8s Node 物理网卡、服务端 ProductPage Pod 虚拟网卡、服务端 ProductPage 进程，这个调用经过的每一跳都看得非常清楚。图中的 Span 中，头部携带 S 标记的是 eBPF 获取到的系统 Span，携带 N 标记的是 cBPF 获取到的网络 Span。另外在实际的生产环境中，中间的网络路径还可能更复杂，比如会经过 NFV 网关的网卡、KVM 宿主机的网卡等，这些复杂的路径在 DeepFlow 中也能完整地追踪出来。具体到上图中的例子，我们发现这样的全栈追踪能力能快速地发现瓶颈发生的位置，图中两个 K8s Node 之间的云网络消耗了比较显著的时间。</p><p></p><p>再次，再从服务网格的角度看全栈。上图中放大了中间一块区域，这是一个调用从进入 ProductPage Pod 到继续请求上游服务的全过程。我们知道这个 Demo 是基于 Istio 的，从火焰图中也清晰地看到调用显示被 Envoy 劫持（收到并发出去），然后才被 ProductPage 进程接收到。这个服务为了完成下游的请求，它需要调用上游的 Details 和 Reviews 服务。在调用 Details 之前，我们看到火焰图上这个服务首先发起了一次 DNS 请求来查询 Details 服务的域名，然后调用 Details 服务，而这个调用也被 Pod 内的 Envoy 代理再一次劫持。我们会发现，在服务网格环境中的调用能被 DeepFlow 清晰的观测到全过程，我们能够快速的判断到底是哪个组件、哪一个基础设施服务、或者哪一个业务服务出现了瓶颈或故障，非常清晰。</p><p></p><p>到此为止，相信大家已经对 DeepFlow 基于 eBPF 的 AutoTracing 能力所叹服了，这个能力也已经帮助我们很多客户实现了云原生应用的快速故障排查。熟悉 OpenTelemetry/SkyWalking 的朋友们可能也发现了它的一个特点：在进程内部我们只为每个调用生成了一个 Span，并没有精细拆分为业务代码、框架代码、库代码等。一方面是因为业务代码粒度的追踪不具备普适性，使用 eBPF 去覆盖会有很大的实现复杂度和性能开销；另一方面也是因为这部分其实已经有各个语言的 Instrumentation 覆盖了，例如大家熟悉的 JavaAgent 的方式。下文将会解释这样取舍的原因，让 eBPF 发挥它擅长的能力，对基础设施服务、进程中的标准远程调用进行覆盖，从而实现对所有分布式调用的完整追踪能力。在实现全局覆盖以后，再选择使用语言的 Instrumentation 来增强局部。</p><p></p><p></p><h4>AutoTracing 背后的关键洞察</h4><p></p><p></p><p>下面的内容是本文的硬核部分，深入介绍 AutoTracing 机制的原理。DeepFlow 开源以来文档工作比较滞后，有很多小伙伴会问到你这是怎么追踪出来的，是不是骗人的。实际上 deepflow.io 上也有我们的在线 Demo，可以随时访问，而且也已经有很多社区用户和企业版客户在使用这个能力了。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/2c/2ce62867f8ae3c29fe859f9d044853f9.png\" /></p><p></p><p>接着介绍一下 AutoTracing 背后的关键洞察，以及我们碰到的一些挑战。现在回顾起来其实关键洞察很简单，就像我们在用 JavaAgent 实现 Tracing 一样，我们会熟悉一个叫 ThreadLocal 的东西，我们时不时的往 ThreadLocal 里藏一些东西，这个时候就能将一个 Service 的入方向的调用和出方向的调用关联起来了。比如说以上图中的 Service A 为例，我们希望把 Client 请求服务 A 的调用以及 A 访问 B 和 C 的调用关联起来，当我们能做到这件事时就解决了单一服务上下游的追踪问题；如果说还能做到将 A 发起的调用和 B 收到的调用关联起来，也就解决了两个进程之间的追踪问题；当我们做完这两件事时，我们发现已经实现了对一个最基本的分布式应用的追踪能力，这就是我们非常初始的想法。</p><p></p><p>类似于在 Java 中利用 ThreadLocal 传输信息，在 eBPF 中我们可以利用 ThreadID 来对一个进程上下游的调用进行关联。但很不幸的是，真实世界非常复杂，我们并不能用一种简单的方法利用 eBPF 在内核中获取的信息感知到每种语言中的「线程」，但本着从简单问题入手的思路，我们发现实际上大部分语言都遵循 Kernel Threading Model，即内核态的线程和用户态的线程是 1:1 对应的，像 Java、C 等语言都是这种模型，此时我们可以直接用 Thread ID 来做调用之间的关联。除此之外也有非常少数的语言采用 Hybrid Threading Model，如 Golang、Erlang，它们是协程化的语言，这些语言中的协程 ID 和 eBPF 在内核中感知到的 ThreadID 并没有多大的关系，下文也会来解释我们如何解决这类场景。作为第一步尝试，我们先将问题简化，只考虑上图中央部分的大多数场景 —— Kernel Threading Model 下的分布式追踪问题。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ef/efba9d28af757d47bc44b68e274b38e0.png\" /></p><p></p><p>第零步，构造一个理想环境。在上图中服务 A 每接收到一个新的来自 Client 的请求都会使用一个全新的线程来处理它，并在这个线程中调用上游的服务 B 和 C，在完成并响应 Client 后关闭处理线程。我们以此为起点，首先希望能在一个理想环境下获得完美的效果。正如大家所看到的，这种情况下我们天然的可以通过 eBPF 获取到的 ThreadID 和调用进行关联，实现服务 A 上下游的调用的追踪。</p><p></p><p>从这个完美的起点出发我们能走多远呢？两年前刚开始做这件事时我们也不知道答案，甚至经常会面对不完美结果的打击，但现在回顾过来我们不断的探索过程非常精彩，接下来一一和你分享。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d7/d7986ff289fe07bb4cb547ecfd6dcd87.png\" /></p><p></p><p>第一步，解决线程复用的问题。上图是一种阻塞调用场景下的最简单的线程复用场景，和我们的理想场景只有一个区别：处理调用的线程 X 在完成 Client 的请求之后并没有终结，他会被归还到一个线程池中，稍后就会继续服务于下一个请求。因此这种场景下我们不能简单的认为「关联至同一个 ThreadID 的调用是在一个 Trace 中」，这样会把时间轴上先后出现的不同 Trace 合并到一起。这种情况 DeepFlow 如何解决呢？实际上比较简单，我们只需要按照时间维度进行切分即可，当我们发现某个线程 X 已经完成了来自 Client 的调用的完整闭环时，我们认为一个 Trace 结束了。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/86/8655b906f5441a11fcfd7d62b266e388.png\" /></p><p></p><p>第二步，解决非阻塞 IO 的问题。在上一步中，我们假设了服务 A 的线程 X 在处理一个 Trace 的请求过程中，不会去处理另一个 Trace 的请求。这是一个非常强的假设，实际的环境中在服务 A 接收到一个来自 Client 的调用之后，很可能在同一个线程中还会处理其他的来自 Client 的调用。典型的对于一些单线程语言都会是这样的处理逻辑，否则自己会被卡死。那接下来思考一下非阻塞 IO 的场景是否能解决呢？上图中展示了 DeepFlow 的解决思路，我们利用了一点非常有意思的现象：服务 A 在接收到 Client 的请求之后会进行 CPU 计算，并会发起到服务 B 的请求，我们会发现在这段时间中是没有出让调度的机会的，也就是说在这两个时间点之间服务 A 没有机会再接收来自 Client 的请求。但是一旦服务 A 发起了到服务 B 的请求时，这个 IO 操作就给了 CPU 调度时机，这之后服务 A 无需等待服务 B 的返回，就有可能会收到来自 Client 的其他请求。</p><p></p><p>总结来看，我们可以利用 eBPF 采集到的读、写事件的时间关联性来讲两个属于同一个 Trace 的调用关联起来，例如上图中相邻的两个红色、黄色、蓝色调用，他们都属于各自的 Trace 中，他们穿插着出现在时间轴上，但通过事件的相邻关系我们能实现对他们所在的 Trace 的独立追踪。当然这里也做了一个假设，即两个 Socket 事件之间不会有其他调度点，但如果代码中有明确的 sleep 或 yield 等语句这个假设就不成立了。但这些情况是小概率事件，我们在探索的过程中先将他放在一边。</p><p></p><p>做完这些以后我们发现还是无法将所有红色的调用串联起来，例如上图中我们可以将红色的调用中的第 1-2、3-4、5-6 等三对事件分别关联为三组，但还没有将这三组串成一个大的 Trace。而这一步就依靠 DeepFlow 中的 Session 聚合能力了。我们从 eBPF 的 Function Call 里面提取到 Request 和 Response，并将它们正确的识别为一个调用。一般来讲应用协议有两种，串行协议和并行协议。比如例如 HTTP2/gRPC 就是一个并行协议，它的协议头中会有一个 StreamID 字段可以用于请求和响应的聚合。我们可以断定并行协议中一定会有类似的字段，否则业务进程自身是无法将响应于请求对应上的。</p><p></p><p>而例如 HTTP 大部分场景下就是一个串行协议，在收到响应之前不会有新的请求发出来。但也有一些特殊情况，比如 HTTP 1.1 中就实现了一种比较鸡肋的半并行协议，它允许一口气发送多个请求，并按顺序接收到这些请求的响应的回复，但这样的机制也是有明确的规律可循。对于 Session 的聚合是 DeepFlow 的拿手本事了，这里展开的话会非常复杂，但总的来讲完成这一步的挑战其实关注两个方面就行了：利用时序关联两个相邻的调用事件，利用流聚合关联同一个调用的请求和响应事件。</p><p></p><p>至此非阻塞 IO 的问题被我们解决了，感觉不错！</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ac/acd74de5314e86e1a07ab56071e91d69.png\" /></p><p></p><p>在解决前两个挑战之后，我们其实已经能在很多场景下实现对上下游调用的追踪能力了，依靠这个能力上图是一个实际的追踪例子，我们大致来感受下这个追踪的过程。图中的每一个正方形是一个服务，这也是 GitHub 上的一个微服务 Demo，中间的服务叫 web-shop，等会我们主要聚焦在它身上完成它的上下游调用的追踪。它左侧的 Client 请求 web-shop 以后，web-shop 依次调用两次 &nbsp;svc-user 完成注册和登录，然后调用一次 svc-item 完成购物，最后调用一次 svc-order 完成下单，之后返回 Client 完成此次下单的全流程。</p><p></p><p>图中在每个 eBPF 获取到的请求和响应事件上我们标记了一个 SyscallTraceID，标记橙色 ID 的是请求，标记绿色 ID 的是响应。根据 SyscallTraceID 的相等关系，我们可以将相邻两个调用关联起来（即图中的①③⑤⑦⑨）。通过将请求和响应聚合为 Session，我们可以将同一个调用中的两个 eBPF 事件关联起来（即图中的②④⑥⑧⑩）。</p><p></p><p>第三步，解决协程的问题。至此，Kernel Threading 这个占比非常大的场景我们已经有了非常好的解决方案。那是否可以去尝试一下 Hybrid Threading 场景呢？接下来我们以 Golang goroutine 为例来讲讲 DeepFlow 对协程语言的分布式追踪能力。实际上回顾下来刚才我们一直在做一件事情 —— 关联。那在协程的场景下如何实现关联呢？我们也用一张类似的图来解释：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/56/561fea7836f4d1f6672681a897f9df3d.png\" /></p><p></p><p>上图中红色、黄色、蓝色的调用依然组成了三个 Trace，不同点在于这些调用事件在 eBPF kprobe/tracepoint 中捕获时所在的 ThreadID 是混乱的，没有任何关联性，这是因为协程语言中的 coroutine 是动态绑定到内核线程中的，这完全是一个用户态程序的行为，内核无法进行控制。似乎我们已经走到死胡同了，在经历了一段时间的挫折之后我们终于找到了解决办法，也就是上图中称之为「协程染色」的机制。它背后的思想是源于对 Golang 中 API 调用处理，我们回忆一下一个 Golang 进程接收到一个 HTTP 请求时会在一个协程中处理该请求，当发现还需要继续请求上游其他服务时，Golang 的基础库会创建一个新的协程用于这个 HTTP 请求，这样做会避免每一个协程不要被卡死。仔细思考之后我们发现「协程的创建过程」其实就是我们要寻找的「关联性」。</p><p></p><p>通过 eBPF uprobe 我们获取一个 Golang 进程中的所有协程之间的创建关系，利用这样的创建关系（虚线）对协程进行染色，结果如上图所示，我们将所有协程染成了三组颜色，对应着三个 Trace。举例来讲，上图中的协程 1 创建了协程 4 和协程 5，DeepFlow 会将这三个协程染色为同样的颜色，并将这些协程中的调用关联在一个 Trace 中。简单来理解，我们可以认为染色后的同一个颜色的协程就类似一个我们在前面的场景中讨论的线程一样。</p><p></p><p>至此我们又攻克了一个难关，协程问题解决了！</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/cb/cbed73b6c1ed0cd46e03b36c1c4f23a9.png\" /></p><p></p><p>第四步，解决跨线程问题。我们继续往下走，还有一个迄今为止还没有解决的场景，跨线程。例如上图，在一个多线程的进程中，在处理来自 Client 的调用时同一个 Trace 中的上下游调用由不同的线程实现。由于缺少了关联信息，这件事情看起来又变得非常困难。得益于 DeepFlow 的 Session 聚合能力，如果一个调用的请求和响应位于两个线程中发生，对追踪是没有任何难度的，因为我们可以基于协议头部字段完成聚合。但如果一个 Trace 的不同调用位于两个线程中发生就比较困难了，比如进程中通过 Queue、Golang Channel 在不同线程之间传递 Task 信息，以及在不同线程中完成上游和下游的调用。</p><p></p><p>这其实是 DeepFlow 迄今为止唯一一个还没有完全解决的场景，但也有了一部分的解决方案，即图中展示的对于七层网关的解法。我们发现几乎任何七层网关都实现了一个非常标准化的能力，即向 HTTP Header 中注入 X-Request-ID 的能力。例如 Nginx、HAProxy、Envoy 等，他们都能为每个下游调用生成一个随机 ID，并将其注入到向上游发起的请求中，以及将其注入到回复给下游的响应中。于是我们通过提取调用中的该字段，可以将网关前后的两个调用关联起来。</p><p></p><p>注意整个过程我们都没有修改任何 Client 和 Real Server 的代码，只需要做一些网关的配置（有些网关是默认打开的，例如 Envoy），即可完成 X-Request-ID 信息的注入。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/60/6050910cdf4c98a3b91bf2d087907e15.png\" /></p><p></p><p>第五步，解决跨进程问题。其实前面四步都是在解决一个进程内部的上下游调用关联问题，接下来我们想把目光延展到两个服务进程之间。比如服务 A 调用服务 B，因为我们没有在请求 Header 中插入任何 TraceID 或 SpanID，如何能将很短一段时间内高频发生的成百上千次调用在两个不同节点、不同 Pod 之间观测到的 eBPF 事件关联起来呢？甚至还包括容器网络、云网络、NFV 网关等每一跳网络路径上发现的请求和响应事件，又怎么与 eBPF 采集的事件之间关联起来呢？</p><p></p><p>这里又要展示 DeepFlow 强大的网络基因了，这个事情其实非常简单，但也非常复杂。简单来讲，可以利用整个通信路径各处采集到的流量中的 TCP 包头特征信息将同一个调用关联起来，例如 TCP 包头中的 SEQ 信息，总共有 2x32=64 比特可以用于我们的关联，另外我们也还可以找到 IP 包头中的 ID 信息用于同样的目的。复杂的地方在于，虽然网络路径上都能采集到包，但在 eBPF 获取的系统调用和函数调用中并没有这个字段 —— 因为此时连 TCP 包都还没有（或者已经被拆开了），这个时候怎么将 eBPF 函数调用数据和 cBPF 网络流量数据关联呢？这里实际上只要能理解 TCP SEQ 的含义也容易想到解决方案，它表示的实际上是已经发送的字节的多少，了解这个背景之后我们就能轻松的在 eBPF 函数调用上下文中还原 Socket Data 将会（或刚刚）使用的 TCP SEQ 值了。</p><p></p><p>至此跨进程也被我们解决了。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/41/418a8689d981778a5baad44e52f1a7b4.png\" /></p><p></p><p>第六步，解决 SSL 加密的问题。这一点表面看起来很玄乎，实际上对于 eBPF 来讲也非常简单成熟。如上图所示通过 uprobe/USDT 我们可以在用户态函数调用中获取 HTTPS 加密之前的数据，例如通过挂载相对标准的 OpenSSL 以及 Golang 中的加密函数就能实现这一点。利用这样的思路同样也可解决 HTTP2 中的包头压缩问题，将压缩之前的包头信息完整的拿到。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/da/dacf18e4dcd2ed858b394657de61c836.png\" /></p><p></p><p>第七部，解决 Trace 组装问题。我们没有向任何 Span 中注入 TraceID 或 SpanID，那如何将这些 Span 组装为一个 Trace 呢？上图是 DeepFlow 中 Trace 查询过程的一个简化，我们可以从任何一个 eBPF Sys Span 出发，来查询与之相关的在一个 Trace 中的其他 eBPF Sys Span 和 cBPF Net Span。每当找到新的 Span 以后，循环迭代可以继续，直到无法发现更多 Span 为止。简单来讲，eBPF Span 之间可以使用 SyscallTraceID 进行关联查询，其他 Span 之间可以用 TCP SEQ 进行关联查询，另外所有 Span 之间都可以使用 X-Request-ID 进行关联查询。</p><p></p><p>到这里为止，我们从一个理想国，克服了七重困难，终于实现了一个比较美好的状态，实现了最初基于 Istio Bookinfo Demo 展示的超能力 —— 零代码修改实现分布式追踪。相信下文的描述会让你真切感受到它的漂亮。</p><p></p><p></p><h3>让追踪无盲点：结合 OpenTelemetry，实现全栈、全链路的分布式追踪</h3><p></p><p></p><p>没有银弹，AutoTracing 很美，但正如我刚才所说它「目前为止」还没有很好的解决跨线程的问题，以及我们没有让他去追踪进程内部的两个函数之间的调用关系。这个世界上没有一招鲜的银弹，但是有好基友能搞 CP，我们发现的 CP 就是 eBPF 和 OpenTelemetry：eBPF 是从内核中成长起来的零侵扰的应用观测方法，而 OTel 是从大量业务实践中成长起来的标准化代码注入方法，一个偏向基础设置另一个偏向业务逻辑，听起来就绝配。在 DeepFlow 中我们也实现了他们二者的完美结合。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/56/56e89b8bb40688e847e403901a8edba7.png\" /></p><p></p><p>首先从另一个角度理解一下这两种追踪能力的区别。对于我们业务代码中生成的 Span，它就像战斗机上装配的火控雷达一样，它的目标性非常明显，是定点打击，在某一个方向上是可以非常纵深、非常精确，但它无法做到全覆盖，特别是对位于视野之外的基础设施服务、网络路径没有任何覆盖。而 eBPF 的追踪方式其实像预警机的预警雷达一样，它能覆盖所有的微服务，能解锁「地图全开」的技能，但有些点，比如说在进程内部函数调用的追踪、以及跨线程的调用场景无法完美覆盖到。我们很难想象现代战争中缺少了预警机还能打赢，当然缺少了战斗机也没发开打。从这个类似上我们发现，将二者的能力结合是如此的自然。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ae/aea4eb7f5fc7de193d98840982fb7d4d.png\" /></p><p></p><p>DeepFlow 是怎么做的？我们通过 OTel/SkyWalking 的 JavaAgent 或 SDK 采集代码中的 Span，并通过 OTel Collector 中转（或者直接发送）至 deepflow-agent 进行收集，并与 eBPF Sys Span 和 cBPF Net Span 进行关联。这里我们也给 OpenTelemetry 和 SkyWalking 社区做了一些贡献，实现了 OTel Collector 中的 SkyWalking Receiver。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/36/36814a5aebfc51afa9f220597dba06ec.png\" /></p><p></p><p>来看看实际的效果，上图中的 Sprint Boot Demo 应用，它包含四五个微服务，以及 MySQL 作为数据库。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/14/14f4b73b49dd9c1c5e31f1414b7d1405.png\" /></p><p></p><p>上图是大家所熟悉的 OTel 加 Jaeger 的效果，追踪出了有 40 多个 Span。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/86/866fd677e15addcbbed7ba4b1b5a807f.png\" /></p><p></p><p>DeepFlow 的效果如何？一个直观的感受是 Span 的数量 Double 了，有 90 多个 Span，这里有 OTel 采集到的、以 A 开头的 Application Span，也有 eBPF Sys Span 和 cBPF Net Span。</p><p></p><p>接下来，会细致地分析一下这张追踪火焰图。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3c/3c91cbea2c4b68ccb8bc2d11350bb278.png\" /></p><p></p><p>上图中有两个放大的区域。第一个区域是调用链中深蓝色服务调用浅蓝色服务的过程，可以看到我们将追踪过程从业务代码，到框架代码，再到系统进程、沿途的网络接口等全部追踪了下来。另外一个区域是图中对 MySQL 调用过程的放大，从 MySQL 事务的开始到事务的结束，能清晰地看到时间到底是消耗在 ORM 框架上，还是网络传输上，或者是 MySQL 服务端。图中客户端业务代码等待时间很长而 eBPF 采集到的时延很短，我们推断应该是 ORM 处理抵消导致。除了这两个区域以外，我们发现 eBPF 的追踪结果除了能基于 OTel 的追踪补足基础设施路径以外，还能将整个火焰图上下延展，例如图中客户端 locust 进程、数据库 MySQL 进程都没有插码，但都出现在了火焰图中。</p><p></p><p>相信你看到上面的结果之后能快速意识到一点：这个火焰图实际上已经将各个不同的岗位统一到一个频道上来了！包括业务开发团队、框架开发团队、服务网格团队、容器运维团队、云运维团队、数据库运维团队。所有这些信息结合起来，我们可以回答很多各个层面的人的问题，到底 A 调用 B 的时候是谁的问题？我调用别人慢是我的问题吗？是他的问题吗？还是基础设施的问题？这些都能够快速回答出来。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d3/d35b29ef25a05df5dc0cfd34a1789337.png\" /></p><p></p><p>实现 eBPF 和 OTel 数据的融合其实并不困难。从 eBPF 和 cBPF 中采集到的 Span 中，我们解析出来了 HTTP/Dubbo 等协议头中的 TraceID 和 SpanID 字段，如上图所示可以轻松的实现和 App Span 的关联。</p><p></p><p></p><h3>展望未来：开源共建，开启高度自动化的可观测性新时代</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/82/82a3cbf43e3e9fadb309c8be7bc23a53.png\" /></p><p></p><p>DeepFlow 这个项目它是我们开源的一个零代码修改实现云原生应用可观测性的软件。它的软件架构非常简单，主要由 Agent 和 Server 组成，我们分别使用 Rust 和 Golang 实现了这两个组件。上图右上角是 DeepFlow 的 GitHub 的 Link，欢迎大家 Star！</p><p></p><p>eBPF 主要的优势在于零侵扰，无需修改业务代码既能自动化的实现可观测性。除了本文所说的非常酷炫的 AutoTracing 以外，DeepFlow 中还用 eBPF 实现了很多其他能力。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b7/b7eb78d9625eea1371e92fe88c719a78.png\" /></p><p></p><p>比如说 DeepFlow 有一个全景应用拓扑（Universal Application Topology）能力，这也是用 eBPF/cBPF 零代码修改情况下绘制出来的。简单来说，即可以支持在 Linux Kernel 2.6 以上内核版本的运行环境中，自动绘制任何 Pod、任何进程之间的访问关系拓扑图。这样的拓扑以往需要通过插码获取 Span 以后聚合生成，现在使用 DeepFlow 无需做任何改动，也不需要利用 Service Mesh 机制间接支持，一条命令五分钟部署 DeepFlow 以后整个全景拓扑就出来了。另外支撑拓扑的是我们通过 eBPF/cBPF 计算出的丰富的性能指标，这些指标覆盖到了从网络传输性能、网络协议栈性能、应用 RED 黄金指标等各个层面。</p><p></p><p>举个例子，承载一个 HTTP 调用的 TCP 连接，它的建连消耗了多少时间、客户端等待了多长时间、系统协议栈的 ACK 回复是否及时、期间是否有网络包重传、真正的应用请求和响应之间的耗时是多少等等，我们都能看到。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/37/378511aad7f049a36733a73199d9d29e.png\" /></p><p></p><p>DeepFlow 中的另一个亮眼能力是支持丰富的、自动化的标签注入，我们用了一种指标和标签分离、标签预压缩的方式，可以把标准标签注入的开销降低 10 倍，并通过查询时的自定义标签关联实现了 Tag without Limit 的能力。你可以从 GitHub 上拉下来代码实际压测一下，非常扎实的性能提升，丰富到吃惊的标签能力。这些能力也就是一条命令部署五分钟就能体验到，也可登录 deepflow.io 查看我们的在线 Demo。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e4/e40df19749ee9fe1214d4d294ec5a279.png\" /></p><p></p><p>最后是 DeepFlow 一些未来的演进点，比如说我们的 AutoTracing 怎样去解决跨线程的问题；文件读写怎样关联到 Trace 上面；我们应该去解析更多的应用协议，现在我们支持将十余种协议。我们会引入 WASM 和 LUA 插件机制解锁可编程能力，因为肯定有很多私有协议需要用户自己手动实现解析，而且也会有很多业务字段藏在标准协议中，这些都是可编程能力的用武之地。</p><p></p><p>以上，就是本文的全部内容。希望 DeepFlow 能让观测更自动，让开发者更自由！</p><p></p><p></p><h3>作者介绍</h3><p></p><p></p><p>向阳，云杉网络研发 VP。清华大学博士，毕业后加入云杉网络，现负责 DeepFlow 产品。最近我们将 DeepFlow 进行了开源（Apache 2.0 License），不久前刚发布了第一个社区版 Release。DeepFlow 致力于为云原生开发者提供一个高度自动化的可观测性平台，让观测更自动，让开发者更自由！</p><p></p><p></p><h3>活动推荐</h3><p></p><p></p><p>5 月 26 日 -5 月 27 日，<a href=\"https://qcon.infoq.cn/2023/guangzhou/track\">QCon 全球软件开发大会</a>\"即将落地广州，从稳定性即生命线、出海的思考、现代数据架构、AGI 与 AIGC 落地、下一代软件架构、研发效能提升、DevOps vs 平台工程、新型数据库、数据驱动业务、数智化效率革命、金融分布式核心系统、大前端技术探索、编程语言实战等角度与你探讨，欢迎你来现场打卡交流～</p><p></p><p>点击<a href=\"https://qcon.infoq.cn/2023/guangzhou/apply\">此处</a>\"直达大会官网，现在购票享 8 折优惠，组团购票还有更多折扣，感兴趣的同学联系票务经理：15600537884（电话同微信）。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d1/d13cf8729b49eb6df7a4676d2b912ea1.jpeg\" /></p><p></p>",
    "publish_time": "2023-03-30 10:29:42",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "钉钉协作Tab前端进化之路",
    "url": "https://www.infoq.cn/article/6605c7243876c79f0d3d13232",
    "summary": "<p>作者：马赟  阿里云钉钉业务平台团队</p><p></p><p></p><blockquote>技术人应当发挥对业务前瞻性的理解，好的架构设计背后一定是对于业务的高度认知与抽象，过程中要对业务关键指标有正确的理解，而不是简单纯功能的堆砌。</blockquote><p></p><p></p><p>钉钉新版协作Tab作为千万级访问量下前端新应用，从我主导前端迭代至今已经有大半年，面对大流量下的高性能和稳定性的压力、复杂前端交互的设计实现、前端技术视角结合业务的高可扩展性架构设计挑战，从0到1完成了三个大版本的迭代，联合客户端和小程序容器完成性能及稳定性方案落地、跨业务线承接了20多种卡片类型，提供了稳定体验的场域服务，同时在研发机制保障下做到全年0客诉和0回滚。</p><p></p><p>本篇将从产品能力升级背后的前端技术支撑和技术视角性能体验优化及稳定性建设两个方面讲述新版协作前端建设的过程。</p><p></p><p></p><h1>一、背景</h1><p></p><p></p><p>相比旧版本以应用为中心的钉钉协作Tab，新版本产品设计理念发生变化：组织管理与激发个体上下共生。协作以个人为中心，聚合与“我”有关的待办、审批、日程、文档等由钉钉各一、三方应用产生的事件，帮助用户更高效地处理与我有关的事件，获得更高效的协作体验，协作通过聚合用户的协作事件，帮助个人提效，进而提升组织效率。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4e/4e92a600010187f5282165fc3916fbdf.png\" /></p><p></p><p></p><h1>二、产品能力升级背后的前端技术支撑</h1><p></p><p></p><p>协作前端进化论：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fa/fa2ddc690b23d37a58a8c1a8019e45bd.png\" /></p><p>新版协作进化历程</p><p></p><p>before：旧版本</p><p>以应用为中心</p><p></p><p>after：协作新版</p><p>第一版，以时间为中心，强调顺序。</p><p>第二版本，以事件为中心，强调操作。</p><p>第三版，以人为中心，强调关系。呼应主题，工作版“今日头条”。</p><p></p><p>很多时候我们难以从产品最初想到完整产品终态，但是如果我们用产品本身的目标和用户价值反推产品的设计和技术实现的时候我们就可以做出相应的改变。</p><p></p><p></p><h2>2.1 协作前端主体架构设计之feeds流卡片动态化</h2><p></p><p></p><p>卡片第一版到第三版迭代建设过程中通过验证有效性及价值递增持续做出产品上的调整和优化。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ac/ac2dee1a3e5284ddaf50b6b9accc6dd7.png\" /></p><p></p><p></p><h3>前端设计实现上的思考</h3><p></p><p></p><p>在做第一版卡片实现的时候就和产品对过后续产品能力上的规划，卡片UI内容的新增删除这里都是更新频率比较高的，同时卡片的逻辑层面的功能也是需要不断建设，比如操作按钮、卡片点击事件、点击后的打开方式、卡片的删除置顶等功能等。在这个背景下我决定这样设计：将卡片频繁变更的UI层和不会变更的卡片功能逻辑层抽象出来分开建设，这样即能保证卡片功能持续建设的过程中不需要频繁变更，又能满足卡片UI持续迭代。</p><p></p><p>将卡片UI层进行布局维度的分层设计：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/03/0363831d6a5f75797273036573623053.png\" /></p><p>前端组件结构化事件卡片</p><p></p><p><code lang=\"text\">//卡片引用\n<div>\n  //卡片头部第一层 事项来源和事项时间\n \n//卡片内事项标题 事项描述\n \n//互动卡片SDK小程序插件引用条件渲染\n    \n// 卡片补充3C推荐内容\n    \n// ButtonList 卡片响应动作\n     \n//卡片折叠 递归引用 此处不需要UI变更\n\n    \n  \n</code></p><p></p><p>这样有个好处就是代码结构清晰直接可以从代码脑海构思出布局，无论卡片内容如何变化，我都可以通过调整对应的组件快速支持产品上做出的调整需求。</p><p></p><p>应用场景：目前钉钉内20+种通用化卡片展示场景支持。</p><p></p><p></p><h3>卡片操作逻辑层能力建设（以不变应万变）</h3><p></p><p></p><p>卡片内容操作：jsapi类型（发起Ding催办等） 跳转类型（半屏等卡片详情）。卡片本身操作：卡片删除、卡片置顶，卡片折叠展开。更新操作：点击操作卡片后的卡片内容更新，如日程接受后变成已完成。</p><p></p><p>这里需要注意的是卡片功能建设过程中业务结合代码的可扩展性，纵使卡片UI怎么调整，但是功能逻辑层是不需要变更。在协作应用的发起协同请求到协同结束的整个过程中，通过分角色分场景的信息设计，在协作流中通过发送消息或沉淀信息的方式，在关键协同节点向用户提供最有价值的协同信息。</p><p></p><p>删除、更新、置顶等场景下 配合小程序 $spliceData 前端本地列表无感更新</p><p></p><p><code lang=\"text\">modifyFeedFlowsCommon(\n  flowId: string,\n  type: string,\n  targetName: string,\n  feedFlows: IComponentInfo[],\n  newFeed?: IComponentData\n) {\n  // step1 找到对应卡片在协作卡片或子卡片（折叠卡片）中的index\n  const feedFlowsIndex = this.findFeedFlowsIndex(flowId, feedFlows);\n  // step2 通过小程序提供的$spliceData函数进行局部更新\n  if (feedFlowsIndex) {\n    this.modifyData(targetName, type, feedFlows, feedFlowsIndex, newFeed);\n  }\n},\n \nmodifyData(\n  targetName: string,\n  type: string,\n  feedFlows: IComponentInfo[],\n  feedFlowsIndex: IFeedFlowIndex,\n  newFeed?: IComponentData\n) {\n  // 分发操作事件，局部更新\n    this.$spliceData({\n            [targetName]: [parentIndex, 1, newFeedItem],\n          });\n  }\n},</code></p><p></p><p></p><h2>2.2 协作场域互动卡片SDK能力集成</h2><p></p><p></p><p>为什么要集成互动卡片：这里可以参考协作服务端架构设计的推拉模式，假设我们想要将更多和用户有关的复杂场景都流入到协作里，并且保证同样的卡片在其他地方也能同时投放，互动卡片是必然的。</p><p></p><p>协作中有两种卡片类型，第一种是上述的标准业务卡片，第二种是可以支持钉钉跨场域投放的互动卡片。</p><p></p><p>钉钉标准互动卡片是钉钉通用的卡片类型，会针对不同的投放场景进行能力与样式的自适应，确保同一个卡片模板在聊天消息、群聊吊顶、协作、工作台等场景中拥有一致的使用体验。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/54/542b6ad84585b77a264726f7a9bc6932.png\" /></p><p>钉钉互动卡片搭建链路+投放链路示意</p><p></p><p></p><h3>互动卡片在协作中的应用方案-业务套壳互动卡片</h3><p></p><p></p><p>卡片本身由两部分组成：数据+模板。数据依靠同步协议来实现动态更新，而模板则是通过小程序包的动态下发和更新机制来实现动态更新的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/54/54fa231eda5b3197d661f9c362763849.png\" /></p><p></p><p>协作内部实现以及协作业务场景的特殊性数据差异：卡片数据由两部分组成，业务本身提供的数据源如上图中的事项标题及事项描述，和协作自己的数据源3C推荐理由以事项来源和时间。</p><p></p><p>在这个差异基础上我们采用业务卡片嵌入互动卡片的形式进行渲染，我称之它为业务套壳互动卡片，这样在满足业务场景的同时能够将互动卡片的内容最大程度的多场域化应用。</p><p></p><p>内部实现第一步加载小程序小程序包，这体现在当客户端在加载一个卡片模板时，本质上它是在加载一个小程序包，小程序包里面则包含了卡片模板资源。</p><p></p><p><code lang=\"text\">// 互动卡片插件初始化\n    initCard() {\n      try {\n        if (dd &amp;&amp; dd.loadPlugin) {\n          dd.loadPlugin({\n            plugin: '5000000002721132@*',\n            success: (res: any) =&gt; {\n              this.setData({ isReady: true });\n            },\n            fail: (err: any) =&gt; {\n              logErrorUser('插件加载失败',JSON.stringify(err))   \n            },\n          });\n          app.globalData.hasInitCard = true;\n        } else {\n          logApiError('dd.loadPlugin', Date.now(), {}, 'dd.loadPlugin load fail', 'jaspi')\n        }\n      } catch(e) {\n        logApiError('initCard fail', e);\n      }\n    },</code></p><p></p><p>第二步小程序插件引用卡片SDK</p><p></p><p><code lang=\"text\">    \n    </code></p><p></p><p></p><h3>卡片 多场域投放埋点问题解决</h3><p></p><p></p><p>同一张互动卡片投放在不同的场域，如何实现区分？</p><p></p><p>卡片组件 context 增加 trackingRuleModel 入参。在渲染过程中透传这个参数。</p><p></p><p>有没有一种可能协作只作为一个场域，你看到的协作feeds流完全由互动卡片来承接？可以。</p><p></p><p>互动卡片在协作中的应用</p><p></p><p>番茄表单、云上管车等ISV应用，与正常卡片融为一体，浑然天成，毫无违和感。未来更多的一方二方三方互动卡片都可以流入到协作中。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2a/2ae0ff9085ba469623dfa86ca3d29be8.png\" /></p><p>番茄表单互动卡片在协作流</p><p></p><p></p><h2>2.3 算法推荐序接入</h2><p></p><p></p><p></p><h3>为什么要接入算法</h3><p></p><p></p><p>利用钉钉现有的数据中台和算法团队的协同关系模型对用户提供个人视角下的高价值事件处理卡片。呼应协作业务的目标，提升点击率，也就是验证协作对用户越来越有用。</p><p></p><p></p><h3>协同关系模型接入方案架构设计</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e2/e26f0e9a9b9e1ac0533908d06b7e2b33.png\" /></p><p>协作前端算法推荐序链路设计</p><p></p><p></p><h3>前端设计实现</h3><p></p><p></p><p>推荐序列表由两段组成，待处理和其他，在有了上面讲过的卡片模型设计实现后，本质上对前端来说这里的工作量只是对推荐序列表的拼接，UI层和逻辑层所有交互均已被覆盖。</p><p></p><p>待处理（重要内容）：对用户强相关的处理卡片，比如未完成的待办、三条后开始折叠。</p><p></p><p>其他（可能感兴趣的）：基于算法协同关系模型以及前端提供的行为埋点数据由算法中心统一产出，交互上跟随推荐序列表下拉加载。</p><p></p><p></p><h2>2.4 协作PC 跨端产品能力补齐</h2><p></p><p></p><p>为了填补协作在桌面端的体验空缺。依赖多端协同的应用，如文档，需要协作支持桌面端后才有可能将应用的协同消息从应用内迁移到协作。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a2/a2a43fa6356c80af6b81eab5549c1914.png\" /></p><p>协作PC端</p><p></p><p>本篇重点讲述协作移动端建设过程，PC端的前端设计方案实现这里先不做陈述。</p><p></p><p></p><h2>2.5 数据运营能力建设</h2><p></p><p></p><p></p><h3>APN统一推送能力建设</h3><p></p><p></p><p>应用场景举例：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f5/f5102d7c5a3b760ddbe736aec3ef905e.png\" /></p><p>APN推送钉钉年度报告承接</p><p></p><p>在接到需求的第一时间建设了通用的APN推送链路方案：利用channel建立客户端到前端的通信通道，在客户端对钉钉统一跳转协议的监听下推送给前端跳转的来源信息，同时前端通过订阅的监听事件做相关的业务逻辑操作。</p><p></p><p><code lang=\"text\">import { getChannel } from '@ali/dingtalk-jsapi/plugin/uniEvent';\n​\nexport function ddSubscribe(\n  channelName: string,\n  eventName: string,\n  handler: (data: any) =&gt; void,\n  useCache = true,\n) {\n  try {\n      const channel = getChannel(channelName);\n      channel.subscribe(eventName, handler, { useCache });\n  } catch (e) {\n      logApiError('ddSubscribe fail',safeJson(e));\n  }\n}\n// 客户端开启订阅统一跳转协议监听事件，并建立两端通道\nddSubscribe('channel.jumpAction.switchtab', 'cooperate_cooperate', (data) =&gt; {\n        if(data?.data.from==='nianzong'){\n          sendUT('Page_Work_New_Year_Summary');\n          openLink$({url:yearSummaryUrl||'https://page.dingtalk.com/wow/dingtalk/default/dingtalk/yearsummary?dd_nav_translucent=true&amp;wtid=yearsummary__xiezuo'})\n        }\n       \n      });</code></p><p></p><p></p><h3>协作顶部应用区</h3><p></p><p></p><p>应用区为什么要折叠</p><p></p><p>受全局切换组织、应用快捷入口吸顶、信息流工具栏吸顶等多个原因影响，协作信息流自身的内容展示区域，不足整体页面高度的1/2，新版的信息卡片，增加信息量的同时也增加了卡片高度，所以要用折叠方式将屏效比提高。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/94/94accf9fe4096b1fe06f648b36dab926.png\" /></p><p></p><p>应用区展示逻辑：纯前端实现，此处无服务端交互</p><p></p><p>联动设置页的拖拽自定义顺序展示。每个入口均由一个灰度key统一控制在协作中的展示，同时针对专属钉大客户定制降噪对应用入口进行过滤。展示前通过客户端JSAPI进行红点数量设置。</p><p></p><p><code lang=\"text\">//灰度key获取到联动降噪红点设置统一管理\nexport const getGrayValueFromCacheByKeys = async (keys: KeysType[] = []) =&gt; {\n  const result: any[] = [];\n  const promiseAllArr: Array&gt; = [];\n  const promiseAllArrKeys: KeysType[] = [];\n  keys.forEach((key) =&gt; {\n    if (cacheGrays[key]) {\n      result.push(cacheGrays[key]);\n      return;\n    }\n    const defaultGrayKeysConfig = allGrayKeys[key];\n    if (!defaultGrayKeysConfig) {\n      result.push(true);\n      return;\n    }\n    if (!defaultGrayKeysConfig) {\n      result.push(!!defaultGrayKeysConfig);\n      return;\n    }\n    promiseAllArrKeys.push(key);\n    promiseAllArr.push(grayLemonFnFactory(...defaultGrayKeysConfig)());\n  });\n  const promiseResult = await Promise.all(promiseAllArr);\n  promiseAllArrKeys.forEach((key: KeysType, i: number) =&gt; {\n    cacheGrays[key] = promiseResult[i];\n  });\n  return cacheGrays;\n};</code></p><p></p><p>以上是产品能力建设过程中的前端主要实现及策略，还有很多细节功能比如卡片自动定位到当前时间最近的事件卡片项、同步推送协议以及列表无感刷新等功能这里就不再赘述。</p><p></p><p></p><h1>三、前端技术视角性能体验优化及稳定性建设</h1><p></p><p></p><p>性能体验是前端绕不开的话题，我坚持认为这件事不是等项目做完再做优化，而是在业务迭代过程中将它落地。</p><p></p><p></p><h2>3.1 性能建设</h2><p></p><p></p><p>就协作小程序的完整启动链路图如下，我们在哪些关键节点能做哪些事呢？</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/82/82f528815f22dbbecc5c45ab3da29ad4.png\" /></p><p>协作小程序启动链路图</p><p></p><p></p><h3>常见性能问题规避</h3><p></p><p></p><p>白屏时间太长：</p><p>首屏出来前长时间白屏，用户体感较差。</p><p></p><p>大量原生API调用：</p><p>通过IDE AppLog面板，发现存在大量的原生JSAPI调用，其实很多是非首屏依赖的，而且JSAPI调用的性能损耗在不同机型下表现不一，尤其对低端机影响较大。</p><p></p><p>包体积过大：</p><p>包体积过大，一方面消耗JS初始化执行时间，另一方面还可能会存在不必要的原生API调用，更加拖累首屏性能。</p><p></p><p></p><h3>协作移动端性能体验建设大图</h3><p></p><p></p><p>以下内容全程高能，以后前端项目就这么做。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/66/664f07ccadbfe8075f727fde5e3bc1ac.png\" /></p><p>协作性能建设大图</p><p></p><p></p><h3>策略：联合客户端容器、小程序本身实施用户视角端到端的性能策略和稳定性建设</h3><p></p><p></p><p>案例1：首屏渲染体验优化-优化策略包和效果</p><p></p><p>优化静态资源：</p><p>类似常规的web玩法，主要就是图片懒加载、压缩质量，属于投入产出比非常高的手段。</p><p></p><p>降低包体积：</p><p>降低包体积不但可以减少js上下文的初始化耗时，还能减少冗余的API调用。</p><p></p><p>渲染原理：</p><p>大量的setData是拖累性能的主要原因之一，理想情况应该把从小程序启动到首屏渲染完毕之间的setData控制在一次。要做到这一点会有一些挑战，减少不合理的模块re-render，减少setData的数据内容，比如协作单张卡片操作后局部更新，而不是更新整个列表。</p><p></p><p>考虑动态插件：</p><p>对于非首屏的、功能独立&amp;复杂、又无法拆到分包的模块，可以考虑将逻辑拆到小程序插件里，按需加载。</p><p></p><p>案例2：首屏渲染体验优化 - 钉钉客户端lwp预取接入</p><p></p><p>谋定而后动</p><p></p><p>协作没有定位服务等的前置依赖，所以可以前置请求，特别适合接入lwp预取。</p><p></p><p>绝大部分小程序的启动流程，都会经历如下环节：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5e/5e8c7dc57f241ce165c58a6892f0eac9.png\" /></p><p></p><p>整体过程是串行的，其中请求首页数据往往和用户的网络环境，服务端的性能有较大关系。串行的流程并行化是一个很常见的性能优化思路，请求首页数据这一步，往往是传一些参数给服务端，获取到数据用来渲染 UI。我们可以抽象出一些规则，在业务的JS开始执行前，并行加载首页数据。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cb/cb5e5d0205590948ece180e4ba0519db.png\" /></p><p></p><p>根据历史线上数据，小程序的容器启动到业务JS开始执行，一般需要1s左右，而钉钉的LWP请求，平均执行时间在300ms左右。这意味着在容器启动阶段，就可以执行3次LWP请求，这段时间是被白白浪费了。</p><p></p><p>钉钉lwp预取 客户端、服务端、前端全链路方案</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/61/616314c90b0e84e48d9b32d6f792714d.png\" /></p><p></p><p>业务接入</p><p></p><p>通过getBackgroundFetchData开启客户端通信通道按需读取数据：</p><p></p><p><code lang=\"text\">dd.getBackgroundFetchData({\n  type: \"lwp\",\n  wait: true,\n  success(res) {\n    console.log(res.fetchedData); // 缓存数据\n    console.log(res.timeStamp); // 客户端拿到缓存数据的时间戳\n    console.log(res.path); // 页面路径\n    console.log(res.query); // query 参数\n    console.log(res.scene); // 场景值\n  }\n});\n//调用时可以传入 wait 参数，表示是否等待预加载结果。如果为 true，会等待预加载任务完成后收到回调。</code></p><p></p><p>结果数据：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cd/cd0a5dd5473e4c48ed8cf3bdfb98204e.png\" /></p><p></p><p>可以看到iOS设备由于本身性能较好，减少的时间有限，但是在Android上的提升效果很明显。</p><p></p><p>钉钉App杀进程的冷启动，协作整个小程序被容器劫持，也就是常驻内存的保活。接入预取后，除了小程序容器UC内核启动的时间外，基本上做到了首屏直出。</p><p></p><p></p><h2>3.2 稳定性建设</h2><p></p><p></p><p></p><h3>案例：钉钉lwpcache无网弱网体验升级</h3><p></p><p></p><p>协作作为一个大流量入口据数据显示每天有3k+的弱网用户访问量，接入离线方案是改善用户体验的必取之路。</p><p></p><p>缓存策略：首屏数据直出，后续迭代，将缓存获取时机从首页onload提前到App onLaunch，能够减少数十到上百毫秒的间隔，是比较常见的手段，但是对降低业务耗时最为直接有效，另一方面从体感上来说确实会更快。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f0/f06370950da0794ece80b9fde3657441.png\" /></p><p>钉钉lwp-cache客户端缓存方案链路流程图</p><p></p><p>框架容器层面也有小程序快照方案-协作设置页接入，不过也并非所有场景都适用先展示缓存。</p><p></p><p>离线策略：</p><p>利用客户端lwp cache能力配合LocalStroage进行上一次请求的缓存数据的离线获取。在前端页面将依赖网络请求的资源图片和功能进行降级。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f6/f625eb9142507d035badbd940b9e547f.png\" /></p><p>优化前后对比</p><p></p><p>关于稳定性，协作前端还做了全功能的降级体验，如服务端接口异常的重试页、数据为空的降级展示、jsapi失败后的重试机制等全方位保障系统的高可用性和稳定性。</p><p></p><p></p><h1>四、前端视角下的业务思考</h1><p></p><p></p><p>做业务要为最终结果负责，而前端角色从技术/产品思维到业务思维的一跃有很多天然的瓶颈与鸿沟，技术人应当发挥对业务前瞻性的理解，好的架构设计背后一定是对于业务的高度认知与抽象，过程中要对业务关键指标有正确的理解，而不是简单纯功能的堆砌。</p><p></p><p>过度的产品化执念导致容易陷入细节；缺少与业务方长时间高频度的互动，对商业模式的理解、数据的敏感度不足；</p><p></p><p>从产品/技术思维到业务思维的转变，可以尝试从以下几个方面来培养：</p><p></p><p>1）培养对目标与数字的敏感度，尝试收集并形成自己的订阅报表，定期 Review，多追问指标升降背后的原因。</p><p></p><p>2）加强与业务方互动，多从业务目标视角看待每个需求，使用STAR法则梳理关联关系，多问几个为什么。</p><p></p><p>3）尝试结合掌握的信息去做公式拆解与沙盘推演，例如App DAU = (MAU * 月均访问频次)/30 +日均拉新，目前的现状每个指标分别在什么量级，每个需求又分别服务于哪个指标，能够提升多少，提升后是否能推导出目标达成，拆解事项并梳理优先级。</p><p></p><p>4）抛下过于超前的产品执念，避免陷入细节，以产出最小可行产品（MVP）为原则快速试错与迭代，区分好「锦上添花」与「雪中送碳」。</p><p></p><p></p><h1>五、结束语</h1><p></p><p></p><p>用户越来越深入地使用钉钉，产生了越来越多的协同“事件”。</p><p></p><p>「协作」通过高效的推荐和筛选机制，帮助用户更好地管理、更轻松地处理每日纷繁的“事件”。</p><p></p><p>「协作」有机会成为用户处理“事件”的第一入口，让用户更轻松地完成工作。目前正在积累基础能力，已经有二十多个协同场景接入「协作」，每日用户通过协作处理的任务数接近 200 万个。</p><p></p><p>长期价值是，入口更便捷、场景更丰富、推荐更精准、操作更简单。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8c/8cf92acea47d14dda7829b22300a92b6.png\" /></p><p></p>",
    "publish_time": "2023-03-30 10:38:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "鲲鹏说 | 认清时代、掌握先机：数字企业&数字人才的成长之路与管理之道",
    "url": "https://www.infoq.cn/article/LvoLs9ZhNg6jT4UHM3Ek",
    "summary": "<p>不久前，人瑞人才联合德勤中国编撰的《产业数字人才研究与发展报告（2023）》在 Arcsummit 全球架构师峰会·北京站上正式发布，「报告」首次提出“井”字型数字人才的概念，并深入 11 个热门行业，展开了数字化转型相关的行业调研和分析，相关数据结果引发了现场参会者的关注和热议。</p>\n<p>这一次我们特别邀请了人瑞人才科技集团 CEO 张建国与德勤中国 合伙人陈岚，做客《鲲鹏说》,一起聊聊“数字产业”与“数字人才”相关的话题。</p>",
    "publish_time": "2023-03-30 17:33:54",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "认清时代、掌握先机：数字企业&数字人才的成长之路与管理之道",
    "url": "https://www.infoq.cn/article/34WS9TXHFTKLjO0Vr5qk",
    "summary": "<p>数字驱动产业变革，数字化转型的大趋势下,“产业数字化”、“数字产业化”、\"数字人才\"等概念应运而生，如何更好地理解时代、顺应浪潮，是企业发展与个人成长共同关注的焦点。</p><p></p><p>不久前，人瑞人才联合德勤中国编撰的《产业数字人才研究与发展报告（2023）》在 Arcsummit 全球架构师峰会·北京站上正式发布，「报告」首次提出“井”字型数字人才的概念，并深入 11 个热门行业，展开了数字化转型相关的行业调研和分析，相关数据结果引发了现场参会者的关注和热议。这一次我们特别邀请了人瑞人才科技集团 CEO 张建国与德勤中国 合伙人陈岚，做客《鲲鹏说》，一起聊聊“数字产业\"与“数字人才\"相关的话题。</p><p></p><p>圆桌嘉宾介绍：</p><p></p><p>特邀嘉宾：人瑞人才科技集团 CEO 张建国、德勤中国合伙人 &nbsp;陈岚(Lydia)</p><p></p><p>圆桌主持：极客邦科技的创始人兼 CEO &nbsp;霍太稳(Kevin)</p><p></p><p></p><p></p><p></p><h2>报告编撰背景</h2><p></p><p></p><p>InfoQ：这本报告很全、很详细，相信大家花了很多心思去做，首先想问一下人瑞和德勤为什么会一起做这个报告呢？</p><p></p><p>陈岚：数字化其实已经讲了很多年，在一开始讲的是信息化，后来讲的是数字化，再后来讲的是智能化，现在又提出了数字中国，未来打造数字中国这样一个大的战略方向，数字经济就变得更加的重要。</p><p></p><p>德勤其实在很多年前就在进行数字化转型，把很多服务和产品以及和客户互动的方式都在尝试做一些数字化转型。我们在对各行各业的客户提供服务的过程中，发现客户也是为这个数字化转型在苦恼，因为各行各业它的产业基础不一样，数字化转型发展的阶段和它的成熟度也不一样。</p><p></p><p>这里有一个很关键的问题——就是数字化人才的匹配度的问题，我们就发现在探讨这个问题的时候，市面上其实没有特别现成的研究资料能够供我们去参考，不仅是企业端，行业想了解到底什么样的数字化人才是紧缺的，我们究竟要怎么样才能够高效地使用数字人才，其实政府也想推动数字化人才的发展，他们也很难找到一个非常客观的理性的这样的一个研究支撑。所以我们一直有想做数字化人才的研究，机缘巧合之下碰到人瑞，他们有很多数字人才或者是数字产业相关的一些场景、数据，于是双方开始了这次合作。</p><p></p><p>张建国：从国家战略到企业战略都特别关注数字化转型，数字化转型发展包括产品形态、行业格局等等问题。但是我们在企业调研中发现，他们遇到的最大的问题还是数字化人才的问题，所以这次我们报告的内容聚焦的就是人才。关于数字人才的研究，市面上的报告大部分来说是比较笼统的，没有深入到行业里面去的。这次我们的调研报告重点针对 11 个热门行业里的数字化人才供需状态、人才分布以及对人才的技能要求等进行了深入的研究。希望能对整个行业或者是企业会有一些比较实际的参考价值。</p><p></p><h2>报告内容简介</h2><p></p><p></p><p>InfoQ：这本报告一共分四个版块，能否展开介绍一下？</p><p></p><p>张建国：这个报告有将近 400 页，第一部分，主要是分析了中国数字化发展的主要状态和趋势；第二部分，重点是在讲数字产业化，重点会涉及到有 6 个行业，包括像人工智能、物联网、互联网、游戏、元宇宙以及芯片设计等；第三部分，是产业数字化，比如制造业、汽车行业、金融行业、医药行业等等；第四部分，重点针对中国的企业在转型过程中遇到的人才策略与管理方法上的挑战，提出了一些方法论，希望能够给到企业一些参考价值。</p><p></p><p>InfoQ：在业界有一句话叫做企业数字化转型是人才先行，极客邦科技在数字人才教育这个领域也做了几年，我们在去年年初还做了一个数字人才粮仓模型，把人才分成数字管理人才、数字应用人才、数字专业人才。这本书里面也特别高频地提到了“数字人才”这个词，并且首次提出“井”字型数字人才的概念，能否重点阐述一下？</p><p></p><p>张建国：我们认为数字人才不仅仅是技术人才。自上而下来分，首先要看领导层是否具备数字化的领导能力；第二个看管理人员有没有数字化管理能力；第三个才是技术人才；第四个还有应用人才。横向来看，我们对于人才的特征结构进行了细分，提出了“井”型人才的概念。</p><p></p><p>我们以前说一个专业人员，只具备专业能力，不具备其他的能力，叫“T 型人才”；第二个到“π 型人才”，除了具备专业知识以外，还应该具备一定的行业知识或者跟业务知识相结合；“井型人才”则是在“π 型人才”的基础之上还增加了两个要素，一个是软性技能，其实就是一个人的基本的素质，比如说逻辑思维能力、沟通技巧；另一个就是数字技能，比如我是一个医生，医术精湛，但是在数字化时代也要具备数字技能，不然很多的一些科学仪器可能用不了，另外如果医院建立了数字化的管理体系，我也很难适应。当然对于不同的行业、不同的岗位，它的具体内容其实是不一样，但是从结构上我们提炼出了“井型人才”的模型。</p><p></p><h2>互联网“降本增效”背后的产业逻辑和人才挑战</h2><p></p><p></p><p>InfoQ：从去年一直到现在，可能大家谈论比较多的是降本增效。德勤中国在这方面其实一直在和很多的公司进行交流，针对降本增效这个话题，德勤是如何看待的？它会对我们的这些行业带来一个什么样的影响？</p><p></p><p>陈岚：降本增效它就是企业经营的一个底层逻辑。其实不管什么时候，企业都需要去降本增效。这两年谈的特别多，因为中国从 2015 年开始慢慢从一个高速增长走向了高质量增长，增长的速度和规模不会再成为首要的考虑，但是增长的质量被更多的去考虑到了，所以降本增效其实也是企业去顺应整个国家经济转型的一个高质量发展的趋势要求。</p><p></p><p>当然，降本增效这个趋势给各行各业都带来了很大的影响。其实从我们咨询行业或者说服务行业来说，我们去挣取的费用其实就是帮企业达到降本增效以后，企业给我们的一个奖励，要么帮他省钱，要么帮他能够挣更多的钱。</p><p></p><p>这几年谈的特别多的另一个原因，是因为过去 3 年其实是全球和中国的数字化进程最快的 3 年，无论是在政府的治理，还是在社会、经济、人才等等各个领域、各个层面，数字化渗透率都在逐步提高，也让很多的行业降本增效成为了可能。而且在过去几年因为一些特殊情况，大家不得不通过数字化的手段去改变自己的交付方式、沟通方式，慢慢也就固定下来，成为了一个商业模式，成为了一个习惯，同样也实现了降本增效。我觉得任何时候企业都是先求生存再求发展，这几年其实经济增长未来还是有很大的一个不确定性，所以通过数字化的手段去做一些转型，达到降低增效，还会是一个主流的趋势。</p><p></p><p>InfoQ：从人力资源的角度，降本增效又带来一个什么样的影响？个人、企业，面对这种情况需要做一些什么样的改变吗？</p><p></p><p>张建国：对这个问题来说，大家可能比较关注的互联网公司的就是这种变化，这也是因为三五年以前，互联网公司是一个爆发式的增长阶段，就是粗放式的经营管理，因为它机会多，迅速占据市场地位这个是最重要的，所以可能对成本方面会考虑得比较少一点。但是从这两三年以来，成本要素比以前要关注得多了，尤其是从去年年初开始，我们经常能看到网上看到一些文章说互联网公司哪家哪家公司裁员 20% 等等这些，直到现在，这个浪潮还在持续。</p><p></p><p>虽然如此，但是互联网行业整体而言还是增长的，因为我们也是为很多的互联网公司在提供服务。另外一个方向来看，对于互联网公司来说，现在正在转变，从虚向实转变。对于实体经济来说，在有关成本管控等等这方面普遍会有一套标准的管理要求。互联网从虚到实，也会使得互联网公司的管理更加稳健，追求更加良性的持续发展，这是一个大趋势。</p><p></p><p>而且从我们这几年跟互联网公司的合作过程中也发现一个大的趋势：</p><p></p><p>第一，就是从消费互联网向产业互联网方向发展；</p><p></p><p>第二，尤其是从今年开始，2023 年疫情放开以后，大量的互联网公司出海。因为在互联网的应用层面上，应该说中国在全球范围内也是有相对领先的优势的，所以走向海外应该说也是一个必然的趋势；</p><p></p><p>第三，对互联网公司来说，像北上广深等等这些主要城市，它的人才需求相对来说数量上会有所下降，但是在新一线的这个需求反而增加了，这也是互联网公司跟实体经济相结合，重新形成了一个产业布局，所以也带来了人才分布的动态变化；</p><p></p><p>第四，当下互联网公司对人才的要求更高了，尤其是在创新能力跟综合能力上要求更高，无论是产品的开发，还是产品业务的紧密结合，都更加复杂，这也是一个趋势。</p><p></p><h2>浅谈人工智能：透过“AIGC”看技术与人才的关系</h2><p></p><p></p><p>InfoQ：现在大家谈论的比较多的还是 ChatGPT，最近两天可能大家更关注的就是 GPT-4 已经发布了，包括百度的“文心一言”，其实大家讨论的都是非常火热的，德勤如何看待 ChatGPT、AIGC 或者是大语言模型？它对整个的行业可能会带来一个什么样的影响？</p><p></p><p>陈岚：因为我本身不是人工智能技术出身，我只能是从行业的应用端来分享一些我的观察。目前马上能看到的 ChatGPT 它肯定是优化了搜索引擎，我们也看到微软它在它的办公软件里面接入了 GPT 的技术，大大提高了办公的效率。同时也看到一些需要和客户有非常密切互动的赛道，比如说游戏，ChatGPT 可以帮它极大地提高人设的丰富性，增强跟游戏玩家的互动体验，这也是我们马上可以看到的。</p><p></p><p>但是从长远来说，数字技术一定要服务于实体经济，它最终能不能有生命力，能不能可持续发展，还是要看它对于整个实体经济的助力有多大。所以我们也是希望未来能看到 ChatGPT 的预训练大语言模型，能够加速医疗信息化、远程医疗、生物医药的临床研发等方面的数字化进程，因为我们在分析各行各业数字化进程的时候，这些行业的研发方面其实是暂时比较落后的，在这些方面 ChatGPT 还是有一定的想象空间。</p><p></p><p>从它在中国的发展来看，我其实还是存有一些疑惑，我觉得现在去判断它未来的一个行业前景可能还为时过早。一是 ChatGPT 它这种预训练其实对于算力的要求是非常高的，对于整体的算力基础设施、数字基础设施的一个升级，有非常高的一个要求。在这样的情况下，是不是同时也要去考虑到一个环保的成本？因为我们说提高效益、提高效率，它不是唯一的目标，它应该是一个综合的效益，成本也是需要去考虑的。再一个就是它在中国的发展还是会暂时受限于我们数据的规范程度，目前的语料基本还是英文的语料，所以未来中国发展 AI 大语言模型可能还要去跨越一些这样的挑战。</p><p></p><p>InfoQ：从人力资源的角度，怎么去看待 AIGC 带来的影响？</p><p></p><p>张建国：我们在这个报告里边分析的行业，第一个行业就是人工智能。从人工智能的发展进程来说，我认为可以从三个阶段的理解。第一个阶段是叫应用技术创新，第二阶段是应用领域的拓展跟商业化相结合，第三个阶段就是商业价值实现。中国人工智能方面的企业大部分现在还是处于一个叫技术积累阶段，国际领先的一些企业应该说已经进入到第二阶段，就是行业应用阶段。当然，我认为接下来中国人工智能的发展会很快，因为我们有足够多的应用场景去实践，但是我们也得更加重视一些底层技术的突破，任何的 AI 的研发都需要很大的投入，如果投入不能变成一个产品，并且可以被重复使用，他的开发成本永远都降不下来。</p><p></p><p>InfoQ：针对以上两个问题，再延展一下——其实无论是降本增效（比如裁员、换血）还是人工智能（机器取代人工）其实都体现着“技术与人的关系”，数字化转型本身离不开技术和人，但是实际上技术的革新也会造成一部分人的失业或者转岗等等。从这个角度，两位如何看待？</p><p></p><p>陈岚：著名的哲学家康德说过，人永远是目的。人不是工具，技术是工具，最终还是为人来服务的。但是在现在第四次工业革命这样的一个背景下，我们能看到人和技术其实是密不可分的，我们自己其实也做过全球的数字人才调研，我们也发现了一个有趣的现象，现在的人才不是跟着平台走，而是跟着自己的技能走，现在有人称其为“数字移民”，他借助了数字化的手段，拥有数字化的技能，可以在任何地方为任何有需求的客户来提供服务。所以这个人和技术的关系其实已经发生了改变，技术既为人服务，技术也成为了人不可分割的组成部分。</p><p></p><p>张建国：从我们调研报告里边其实也可以看出，并不是说随着技术的发展，人工作被替代以后就没有工作机会了。对于企业而言，每年的数字化人才需求大概有 2000 万，但是中国数字人才的供应概只有 500 万左右，从这个数字可以看出差距，很多企业感觉招不到人，这里边还是存在一些供需匹配的问题。</p><p></p><p>对于个人来说，你就要去思考如何让自己的技能进行转换，并不是没工作了，事实上每一轮技术革命都会催生一些新的行业、岗位，只是对技术、能力的要求更高了。人跟技术之间始终是处于一个互相促进的作用，而不是互相替代的作用。最后主导人类的还是人，我们可以说技术是生产力，科学技术生产力，但是另外还有一句话，在华为基本法里面就是我们在人的大脑里边可以挖出来一个大油田，它的潜能可能更大，我们很多的创造都是由人大脑来创造的。所以面向未来，一定是越来越美好的，而不是无路可走。</p><p></p><h2>智能制造行业数字化转型的机遇</h2><p></p><p></p><p>InfoQ：除了数字原生类行业，数字化转型的另一只大部队其实是“产业数字化企业”，也就是传统行业如何借助数字化的力量实现升级。两位如何看待“传统企业数字化转型”？会带来哪些变化或影响？在前期调研的过程中有哪些心得感悟或者故事分享？</p><p></p><p>陈岚：在数字经济时代，如果分成两大块，数字产业化、产业数字化大概是 2:8，现在传统产业的数字化转型和升级应该是创造最多产值和效益的部分，但是实际上它的上中下游转型的特点都是不一样的。我比较印象深刻的还是智能制造行业，制造业现在在中国经济发展里面占据了越来越重要的位置，它对于 GDP 增长的贡献率其实在过去几年是在逐年也提高，而且在过去一年，经济有很大不确定性的时候，我们可以看到高技术制造的投资、引资是遥遥领先的。</p><p></p><p>智能制造说白了就是把人工智能技术应用于传统的制造业场景，来提升它的一个效率，一般我们把智能制造分成上中下游，上游一般我们可以理解为材料的供应，一些基础的部件，比如说传感器、芯片的供应，还有就是像数字技术、AI、工业互联网，这些是在上游，中游其实是软硬件和聚合软硬件的平台和系统，这个是中游，就是它要把这些物料变成产品和服务。下游最大，下游其实是应用行业和应用场景。应用行业横向来说，像刚才讲的医药、消费，这些其实都是应用的行业，应用场景包括比如财务、人力、生产、研发这些其实都是应用的场景。</p><p></p><p>目前智能制造行业整体来看，中游的数字化转型的水平是最高的，因为它本身是软硬件企业、系统企业，是原生数字企业，它的数字基因会推动它不断地往前去迭代。上游和下游是密不可分的，因为你上游的这些技术和物料是为你下游的行业和场景去服务的。目前来看，因为整个智能制造的下游个性化需求非常大，上游物料和技术对下游场景需求的匹配程度还不够。</p><p></p><p>我们在调研里发现，大概 12% 的受访企业都认为他们离通过智能升级来实现效益还非常的远。我们原先会认为渗透率很高，走得很前，但其实在调研过程中发现，很多人工智能的服务企业其实还是有同质化、低水平这样的一个现象，而且他们的集成能力是比较低的，所以难以应对下游场景的个性化、复杂化和集成化。</p><p></p><p>张建国：我们在具体的行业研究中，我举个例子来说，比如说智能汽车这个领域，这个领域其实首先从产业结构上面发生了很大的改变，现在在做汽车这个行业，再不是以前传统我们所知道的一些汽车制造厂家了，包括像百度、华为等等之类的企业都进入到汽车这个行业。为什么？是因为以发动机为核心的传统汽车技术体系已经彻底改变了。当然对人才的需求也不一样了，这个时候企业可能更多所需要招的是一些通信专业的、人工智能方面的人才。</p><p></p><h2>金融行业数字化转型的机遇</h2><p></p><p></p><p>InfoQ：除了智能制造比较火热外，我们也看到现在很多同学从互联网走向金融行业，对于金融行业的数字化转型两位如何看？背后的人才流动又是怎样呢？</p><p></p><p>陈岚：像金融行业的数字化转型，应该说中国是走在全球的前面，比如我们的移动支付其实已经成为我们的一个生活习惯了。目前国内的商业银行它们一般都会成立自己的金融科技的子公司，去解决它的数字化转型问题。金融机构的商业模式目前为止，并没有实现很大的数字化转型，但是它的运营流程其实已经很大程度被数字化改变了。比如说客户管理的数字化，基本每个银行其实都已经做得比较好了，供应链金融的数字化也已经是比较成熟了，风险控制的数字化目前也已经比较成熟了。</p><p></p><p>未来整个金融行业我们觉得可能一方面是普惠的数字化，因为未来金融服务于实体经济，肯定会面向更多的市场主体，面对不同的融资需求、安全需求等等去服务；另一方面就是在监管科技上，随着整个金融行业的数字化转型，监管也需要相应的去做数字化转型，去应对可能会发生的一些未曾预料的问题和风险。</p><p></p><p>张建国：金融行业的数字化转型，大家应该看到是非常明显的，比如说很多银行的门店越来越少了，到银行去取钱的人也越来越少了，所以整个银行的服务模式是在发生改变的，对于用户而言，消费直接是扫一下微信、支付宝，现金也很少用。另外，对于银行而言，收益的方式可能也会发生很大的改变，不只是一个存贷这个问题了，比如如何让消费者去了解它的消费趋势。以前我们取了 1 万块钱去用，但是我这 1 万块钱怎么花其实银行是不知道的。现在我在手机上面付的钱，每一笔钱是怎么花，付到哪里去了，我产生什么样的消费。这个数据经过汇总分析以后，银行就能根据客户消费趋势给他推更适合的产品，产品的个性化定制就有了可能。</p><p></p><p>整个银行的商业模式以后也会发生很大的改变，会更加定制化、个性化，这个市场还是非常大的。对于很多银行来说，大量的系统研发投入，目的就是如何把这个数据收集起来、连接起来，为他现在的商业服务。再往后走，我觉得应该会创造新的商业模式。</p><p></p><h2>企业数字化转型的共性挑战与差异化</h2><p></p><p></p><p>InfoQ：前面提到的“产业数字化企业”和“数字产业化企业”，在数字化转型中，是否也有一些共性问题呢？</p><p></p><p>张建国：从共性问题来说，应该可以分成三个方面来看，第一个是对企业数字化转型的认知，目前大部分企业还是不够的，大部分企业还停留在认为从外面招几个技术人才，就能解决数字化的转型问题，真正的数字化转型其实应该是从公司的战略、业务模式、组织形态等等方面来思考的问题。</p><p></p><p>第二个从实施的层面如何去实现数字化转型的问题，往往就是很多公司没有系统化的思考，只是在局部地改造或者说只是从技术方面去解决了信息化的问题等等，并不能带来整体的业务收益，也没有提高它的管理效能。投入之后发现对我的业务没什么价值，所以后来又不投入了。</p><p></p><p>第三个层面是供给的层面，在进行数字化转型时，你的思维一定要跨开你这个行业本身，跨开你企业的局部范围，去思考在一个新的环境中，怎么样有效地去构筑生态环境，使得我的企业从中获取的资源最大化，内部管理的成本最小化。</p><p></p><p>InfoQ：产业数字化企业和数字产业化企业的数字化转型有什么不一样地方？</p><p></p><p>陈岚：我们刚才其实也讲到它其实是数字经济的两大组成部分，当然还有另外一块我们叫治理数字化，但目前就占的比较小，在产值上面占的比较小，因为现在国家统计局其实对于数字经济也有一个标准的统计口径了，现在产业数字化、数字产业化它是会公开做一些统计的，其实区别它就是显而易见的，因为数字产业化事实上就是技术，就像刚才讲的人工智能、大数据，它是一些数字技术，它是需要去用于赋能这些产业提升。产业数字化它就是传统产业依赖数字化做了提升的部分，它叫数字产业化。</p><p></p><p>数字产业化的企业，他们对于核心技术的研发人才现在是非常缺乏的，而且对于现在核心技术人才、岗位的精准定义，还是有很大的打磨空间的。这个其实关系到未来我们要从供给端如何去做一个配比，或者你企业是要引进还是通过培养等等，所以对于核心技术的人才岗位的标准化的描绘其实是很重要的。</p><p></p><p>产业数字化企业它要求人才能够做到“技产融合”，就是技术加产业的一个融合。我们刚才举的例子，你人工智能技术去赋能制造业企业，你要去适应它场景的个性化。同样你这个技术人才不仅要有数字技术，你还要了解行业背景，行业场景，才能真正去为产业的数字化转型和提升来服务。</p><p></p><p>张建国：我们在每个行业里边其实都是研究了具体企业的一些实践，尤其是一些领先性的企业，在这方面还是做了很多探索的，包括人才获取的渠道，包括人才内部的培养，包括新的用工模式等等。</p><p></p><p>我简单总结一下，可能有几个方面是比较明显的，第一个就是对人才要进行分层分类的管理，比如说对于我非常重要的核心人才，对我的产品的研发是非常关键性的，可能要在外部市场里边定点去挖，高价去挖，因为这个对产品的成功与否是非常重要的。</p><p></p><p>对于普通人才，一般性的人才，可能我会采取外部合作的方式，通过人力资源服务外包方式来解决用工的问题，这个随着项目的波峰波谷，可以去灵活调节。</p><p></p><p>对于技术应用人才，大部分可能我从内部来培训，可以去解决它的一个基础知识的扫盲问题，以及怎么样能让他们更好地去适应工作环境的问题。</p><p></p><p>所以对于不同的人经过分层分类以后，提出适合自己的一个多元化的用工策略，对我们解决人才的问题是比较有效的，同时也能提高我们对人才使用的效率以及成本的管控，而且能获取更多的社会资源。我们有一句话叫“不求人才所有，但求人才所用”。</p><p></p><h2>浪潮之下的个人与企业成长之道</h2><p></p><p></p><p>InfoQ：对于个人、企业而言，数字化转型浪潮之下，需要做出哪些改变？（认知？技能？）站在人力资源以及行业趋势的视角，有没有一些可以给到企业发展 / 个人成长建议呢？</p><p></p><p>张建国：从个人来看，研究报告应该说是有非常直接的参考价值，我们提出了“井”型的数字人才胜任力模型，针对不同行业的从业人员应该具备哪些技能、掌握哪些知识等等都进行了相应的描述。</p><p></p><p>对于企业来说，其实我们在这份研究报告里面第四部分，专门也提供了一些有关人才策略的解决方案。首先还是要建立一个叫人才生态链的概念。如果一个企业，每年从大学里面招毕业生，然后培养一两年，觉得才能用，这样可能很多的机会已经错过了。</p><p></p><p>对于一些核心人才，你可能要提早布局，包括校企合作、共同培养，这也是一个是方法，使得我有一个长期的供应关系，包括怎么样跟一些培训机构去建立一些实训基地，对于我社会上面招不到的这些人，我可以进行专项的技能培训，使得这个人的能力得到很好地转化，这样使得人才供给的问题得到一定的解决。</p><p></p><p>同时也可以跟一些人力资源机构建立人才供应链的长期合作关系。随着业务的发展的需要，在不同的阶段我需要什么样的人，不光是我需要的时候进来，还得解决不需要的时候出去的问题。因为往往一个产品的研发它是有周期性的，而且在不同的周期里面，它所需要人的配置也是不一样的。比如说我开始的高峰期项目的开发需要 100 个人，但半年以后，需要 50 个人就可以了，那多出来的 50 个人怎么办呢？辞退？对企业来说，其实损失是非常巨大的。对个人来说也是一样的，我可能一下子失业了。</p><p></p><p>对于人瑞来说，我们是一家提供综合性的、一体化解决方案的人力资源公司，我们同时为几百家公司提供战略服务，可以给企业提供人才的储备池，以及人才的都江堰，内核外核的调节作用，而且对人才的供给速度会更快。比如在人力波谷时，对于一些不太需要的人才，怎么样能很好的进行消化，而不是简单的辞退，在这些方面我们有一系列体系化的方案。</p><p></p><p>陈岚：我认为首先数字化肯定是大势所趋，每个人都要有一个终身学习的心态，去拥抱未来的数字世界。从企业来说，我觉得也要去关注一个数字鸿沟的问题，因为现在其实城市和农村可能大中型的企业和小微企业之间的数字化水平是不一样的，我想这也可以把它作为我们企业践行社会责任的一部分，尽量去帮助欠发展的一些群体去提升数字化能力。其实我们德勤目前就有这样的计划，未来要帮助 1000 万的农村年轻人去掌握一些基础的数字化技能，只有去填平这些数字鸿沟，才能实现更加良性、健康、可持续的社会、经济数字化转型。</p><p></p><p>InfoQ：特别感谢两位嘉宾做客《鲲鹏说》，也感谢人瑞和德勤在当前这个“人才焦虑”的时代，给了行业一份可供参考的研究报告。「报告」即将上线发售，对「报告」感兴趣的朋友可以关注人瑞人才的公众号，获取「报告」发布最新信息。</p><p></p>",
    "publish_time": "2023-03-30 18:10:30",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "产品导向的团队组织和交付｜ BizDevOps 公开课",
    "url": "https://www.infoq.cn/article/RY4GCawwyiKCUixIFapr",
    "summary": "<p><strong>内容简介：</strong><br />\nBizDevOps最新权威解读课程，由BizDevOps共促计划专家团成员共同创作，包括《必致（BizDevOps）白皮书》解读共 10 讲，阿里巴巴、招商银行、Thoughtworks等企业真实实践案例分享，以及需求管理、组织设计、组织数字化升级、数据运营和工具等设计专题精讲。<br />\n白皮书下载链接：<a href=\"https://www.infoq.cn/minibook/lsB8GB2BbvLQj2u5mBKo\">https://www.infoq.cn/minibook/lsB8GB2BbvLQj2u5mBKo</a></p>\n<p><strong>你将理解：</strong></p>\n<ol>\n<li>如何应用BizDevOps，为数字化的业务打造数字化的组织</li>\n<li>理解BizDevOps的1个目标，3个能力和5个实践</li>\n<li>BizDevOps与DevOps的根本不同，以及如何实现从DevOps向BizDevOps的蝶变</li>\n<li>你将掌握BizDevOps的1-3-5框架，掌握驾驭数字化变革的力量</li>\n</ol>\n<p><strong>面向受众：</strong><br />\n数字化转型从业者和关注者，包括研发管理者、数字业务和数字化转型负责人、业务分析师等、研发工具负责人</p>\n<p><strong>发布计划：</strong><br />\n3.23日起，每周四下午16:00，准时开播。</p>\n<p><strong>本系列视频内容规划：</strong></p>\n<ol>\n<li>BizDevOps(必致)是什么，如何实施？ 整体框架</li>\n<li>产品导向的团队组织和交付 （实践一） 协作和管理实践</li>\n<li>业务驱动的组织协同机制 （实践二）</li>\n<li>数字业务的动态投资组合管理 （落地和案例）</li>\n<li>应用为核心的研发资产和流程管理（实践三） “工程和技术实践”</li>\n<li>适配业务特征的持续业务交付 （实践四）</li>\n<li>建设和改进持续业务交付能力 （落地和案例）</li>\n<li>全量、全要素和实时数据支持的度量和持续改进（实践五） 度量和持续改进实践</li>\n<li>度量和持续改进体系的设计和应用（落地和案例）</li>\n<li>BizDevOps（必致）：驾驭数字化变革的力量 总结</li>\n</ol>",
    "publish_time": "2023-03-30 18:23:11",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "为什么研发管理必须数字化？",
    "url": "https://www.infoq.cn/article/9ACKKE89hjlOspM3JcU6",
    "summary": "<p><img alt=\"unpreview\" src=\"https://static001.infoq.cn/resource/image/f1/cc/f12c8c8f367e92dd5b5ced828948accc.jpg\" /></p>",
    "publish_time": "2023-03-30 18:29:22",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "轨迹规划算法提升复杂路口通过安全性与合理性，接近人类驾驶水平 | 自动驾驶论文解读",
    "url": "https://www.infoq.cn/article/5kIVwJdvJZNaWmTPy9gs",
    "summary": "<p></p><p>近日，毫末智行人工智能中心技术团队论文《Safety-balanced driving-style aware trajectory planning in intersection scenarios with uncertain environment》（不确定性路口场景下基于驾驶风格识别的安全轨迹规划）被IEEE TIV录用。IEEE Transactions on Intelligent Vehicles （IEEE TIV，IEEE智能车汇刊）是智能车专业学术期刊。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/40/40164bd2a9d6752f6bf7f3b79f6020cb.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0a/0a8097bc8880de89f988738db7200c5b.png\" /></p><p></p><p></p><p>据介绍，该论文针对高动态的不确定性路口场景，考虑周围人类驾驶车辆（HDVs）的驾驶风格，提出了一种两阶段自动驾驶车辆（SDVs）轨迹规划算法。该方法在复杂不确定性场景中实现了安全、高效的驾驶轨迹规划。实验结果证明了所提出方法在不确定性路口场景的规划效率和有效性，通过考虑路口场景下HDVs 的驾驶风格与意图动态，SDVs能够做出更鲁棒、合理的规划行为。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5f/5f973bd49029c411d6af79e8b7c1422a.png\" /></p><p></p><p>&nbsp;</p><p>这种安全平衡的轨迹规划方法，包含候选轨迹生成与安全轨迹选择两个阶段。</p><p></p><p>首先，在候选轨迹生成阶段，毫末构建了一个考虑周围车辆驾驶风格的多模态联合预测与规划模块。该模块输入以自车为中心的鸟瞰视角语义图，包括高清地图和其他车辆智能体的向量化表征。通过Transformer对车辆之间交互进行编码，同时显示建模周围其他车辆的驾驶风格，并将识别的车辆驾驶风格作为条件约束，协助轨迹解码网络实现交互感知的联合预测和规划。该过程为自动驾驶车辆生成候选轨迹。</p><p></p><p>然后，在轨迹选择阶段，基于第一阶段生成的候选轨迹与对其他车辆的预测轨迹，结合道路信息，通过安全敏感的轨迹评估函数对每个候选规划轨迹进行评分，最终选择安全评分最高的轨迹用于控制器的最终执行。</p><p></p><p>毫末团队通过实验对比了所提出方法与4种基于模仿学习的轨迹规划方法，包括基于图像输入的行为克隆（BC-I），基于图像输入与轨迹扰动数据增强的行为克隆（BC-IP），基于语义向量输入的行为克隆（BC-V），基于语义向量输入与轨迹扰动数据增强的行为克隆（BC-VP）。在自动驾驶仿真平台L5kit上的闭环测试实验结果显示，所提出的方法与其他基准方法相比，碰撞与越野次数大幅降低，显示出所提出的轨迹规划方法具有更高的安全性与轨迹合理性。在自动驾驶仿真平台L5kit上的开环测试结果显示，所提出的方法仍然领先基准BC-VP。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d4/d48b7a60c3e15d2257108a3fdc70fa79.png\" /></p><p></p><p>闭环测试中基准方法与所提出方法的规划指标对比结果</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e5/e5c7e39b2397fb5a348f7594aa3263fe.png\" /></p><p>开环测试中基准方法与所提出方法的规划指标对比结果</p><p>&nbsp;</p><p>通过闭环测试消融实验，毫末验证了驾驶风格识别与安全校验模块在降低碰撞率与越野次数的作用，且能够使得所规划轨迹更接近人类驾驶轨迹。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ac/aca581bd9d1b0d1a17ff0958608272b6.png\" /></p><p></p><p>闭环测试消融实验的规划指标结果</p><p></p><p>在公开数据集的可视化结果中，一个典型路口场景的可视化结果显示，所提出的轨迹规划方法可以使红色自动驾驶车辆在路口处等待红灯并停车，等到绿灯亮起后恢复行驶，同时保持与其他车辆的安全距离并沿着预定路线行驶。规划的轨迹与人类实际驾驶车辆的蓝色参考轨迹非常接近。相比之下，基于基准BC-VP规划器的车辆闯红灯并撞击其他车辆，同时没有按照预定路线行驶。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ab/ab1488549a2843c343169453e6066b2a.png\" /></p><p></p><p>在公开数据集的可视化结果</p>",
    "publish_time": "2023-03-30 18:44:06",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]