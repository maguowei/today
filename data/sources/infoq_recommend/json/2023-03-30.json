[
  {
    "title": "我用GPT-3在单个代码库中发现 213个安全漏洞",
    "url": "https://www.infoq.cn/article/dIG7N5UNFWD87PySrRLc",
    "summary": "<p>本文最初发布于Better Programming。</p><p></p><p></p><blockquote>GPT-3在<a href=\"https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner\">这个Git代码库</a>\"中发现了213个安全漏洞。相比之下，市场上一款比较好的商业工具（来自一家著名的网络安全公司）却只发现了99个问题，不过商业工具提供了更好的结构化上下文。我随机手动检查了GPT-3检测到的213个漏洞中的50个，只有一个是假阳性。这两种工具的假阴性都很多。</blockquote><p></p><p></p><p>近年来，人工智能和机器学习领域取得了巨大的发展，并开辟了全新的可能性领域。其中一个备受关注的领域是基于人工智能的代码分析，特别是使用人工智能模型来检测代码中的安全漏洞。在这个实验中，我们使用OpenAI的GPT-3在<a href=\"https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner\">代码库</a>\"（包含129个有漏洞的文件）中查找安全漏洞。</p><p></p><h2>工作原理</h2><p></p><p></p><p>我使用的是GPT-3的一个变体（text-davinci-003），其上下文窗口有4000个词元，大约是3000个英语单词。这意味着每个请求最多只能处理几百行代码。很遗憾，GPT-3的当前架构无法一次处理整个代码库。</p><p></p><p>为了解决这个问题，我必须用GPT-3单独扫描每个文件。也就是说，GPT-3可能难以找到涉及多个代码文件交互的安全漏洞，除非import/export足够清楚，不需要具体查看代码就可以猜出那些函数的功能。</p><p></p><p>这种情况经常发生，特别是当源代码使用了常见的库时，如express.js、Flask、Python标准库、C标准库等。GPT-3很可能用到了许多最常见的库，有的是部分记忆的，有的是完全记忆的，有的是以其他方式编码的。在本文分析的代码中，GPT-3对导入的库有足够的先验知识，因此能够准确检测安全漏洞，而不需要检查任何导入的库代码。</p><p></p><p>公平地讲，不只GPT-3，我怀疑现在的许多商业漏洞扫描工具在进行静态分析时实际上并没有检查导入的库代码——所以与市场上已经存在的一些工具相比，它的工作方式并没有什么不同。</p><p></p><h2>分析的代码</h2><p></p><p></p><p>代码库中的每个文件夹都以一种类型的安全漏洞命名，其中的文件包含存在一个或多个漏洞的示例代码。这些文件中的代码有些没什么价值，但也有许多是你可能在生产代码库中遇到的很实际的代码片段（注意：它们不过是代码片段，并没有更大代码库的上下文信息）。代码库中每个文件夹下的README.md文件包含了GPT-3针对该文件夹中每个文件生成的安全漏洞分析。</p><p></p><p>接下来，让我们通过一些例子看看GPT-3是如何做到的！</p><p></p><h4>示例1</h4><p></p><p></p><p>下面是一个容易受到格式字符串攻击的<a href=\"https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner/blob/main/Format%20String%20Attacks/FormatString.c\">简单的C程序</a>\"：</p><p></p><p><code lang=\"plain\">#include \n \nint main(int argc, char **argv) {\n    char *secret = \"This is a secret!\\n\";\n \n    printf external link(argv[1]);\n \n    return 0;\n}</code></p><p></p><p>下面是GPT-3的分析（它是对的）：</p><p></p><p></p><blockquote>检出的漏洞：未验证用户输入：程序没有检查用户输入的长度，这可能导致缓冲区溢出攻击。格式字符串漏洞：程序没有检查用户输入的格式，这可能导致格式字符串攻击。</blockquote><p></p><p></p><h4>示例2</h4><p></p><p></p><p>让我们看一个用高级语言编写的不那么简单的程序，比如下面这个包含Log Forging漏洞的<a href=\"https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner/blob/main/Log%20Forging/logf.cs\">C#程序</a>\"。类似的代码，我在开源项目和生产代码库中都见过（不是那么没价值）：</p><p></p><p><code lang=\"plain\">using Microsoft.AspNetCore.Http;\nusing Microsoft.AspNetCore.Mvc;\nusing Microsoft.Extensions.Logging;\nusing System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Threading.Tasks;\n\nnamespace WebFox.Controllers\n{\n    [Route(\"api/[controller]\")]\n    [ApiController]\n    public class LogInjection : ControllerBase\n    {\n        private readonly ILogger _logger;\n\n\n\n        public LogInjection(ILogger logger)\n        {\n            _logger = logger;\n        }\n\n        [HttpGet(\"{userInfo}\")]\n        public void injectLog(string userInfo)\n        {\n            _logger.LogError(\"error!! \" + userInfo);\n        }\n    }\n}</code></p><p></p><p>以下是GPT-3的输出：</p><p></p><p></p><blockquote>检出的漏洞：日志注入漏洞：代码容易受到日志注入攻击，因为用户输入直接被记录，没做任何消毒处理。</blockquote><p></p><p></p><p>GPT-3的评价是对的——这段代码中有一个日志注入漏洞。</p><p></p><h4>示例3</h4><p></p><p></p><p><a href=\"https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner/blob/main/Out%20of%20Bounds/vuln.c\">下面的C程序</a>\"读取并操作一幅图像。它包含许多安全漏洞，包括越界（Out Of Bounds）读写：</p><p></p><p><code lang=\"plain\">#include\n#include\n#include\n\nstruct Image\n{\n    char header[4];\n    int width;\n    int height;\n    char data[10];\n};\n\nint ProcessImage(char* filename){\n\n    FILE *fp;\n    char ch;\n    struct Image img;\n\n    fp = fopen(filename,\"r\"); \n\n    if(fp == NULL)\n    {\n        printf(\"\\nCan't open file or file doesn't exist.\");\n        exit(0);\n    }\n\n    printf(\"\\n\\tHeader\\twidth\\theight\\tdata\\t\\r\\n\");\n\n    while(fread(&amp;img,sizeof(img),1,fp)&gt;0){\n        printf(\"\\n\\t%s\\t%d\\t%d\\t%s\\r\\n\",img.header,img.width,img.height,img.data);\n    \n        int size1 = img.width + img.height;\n        char* buff1=(char*)malloc(size1);\n\n        memcpy(buff1,img.data,sizeof(img.data));\n        free(buff1);\n    \n        if (size1/2==0){\n            free(buff1);\n        }\n        else{\n            if(size1 == 123456){\n                buff1[0]='a';\n            }\n        }\n\n        int size2 = img.width - img.height+100;\n        //printf(\"Size1:%d\",size1);\n        char* buff2=(char*)malloc(size2);\n\n        memcpy(buff2,img.data,sizeof(img.data));\n\n        int size3= img.width/img.height;\n        //printf(\"Size2:%d\",size3);\n\n        char buff3[10];\n        char* buff4 =(char*)malloc(size3);\n        memcpy(buff4,img.data,sizeof(img.data));\n\n        char OOBR_stack = buff3[size3+100];\n        char OOBR_heap = buff4[100];\n\n        buff3[size3+100]='c';\n        buff4[100]='c';\n\n        if(size3&gt;10){\n                buff4=0;\n        }\n        else{\n            free(buff4);\n        }\n\n        free(buff2);\n    }\n    fclose(fp);\n}\n\nint main(int argc,char **argv)\n{\n    ProcessImage(argv[1]);\n}</code></p><p></p><p>GPT-3的输出：</p><p></p><p></p><blockquote>检出的漏洞：未检查返回值：未检查fopen()函数的返回值，这可能导致空指针解引用。越界读取：使用memcpy()函数将数据从img.data复制到buff1和buff2，而不检查目标缓冲区的大小，这可能导致越界读取。3.越界写入：在写入buff3和buff4数组时未检查源缓冲区大小，这可能导致越界写入。未初始化内存访问：在未初始化的情况下访问OOBR_stack和OOBR_heap变量，这可能导致未定义的行为。内存泄漏：如果size3变量大于10，则buff4数组不会释放，这可能导致内存泄漏。</blockquote><p></p><p></p><p>GPT-3再次判断正确！</p><p></p><h4>示例4</h4><p></p><p></p><p>最后一个<a href=\"https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner/blob/main/Unsafe%20Deserialization/SerializeToFile.java\">Java示例</a>\"是我最喜欢的，因为很遗憾，在第一次阅读这段代码时，我没有发现它有任何问题。对我来说，它看起来完全无害且很常见——我实际见过类似的代码，但从未有过任何其他的想法。</p><p></p><p><code lang=\"plain\">class Utils\n{\n    // 该函数序列化一个对象，并将其写入一个文件\n    public static void SerializeToFile(Object obj, String filename)\n    {\n        try\n        {\n            FileOutputStream file = new FileOutputStream(filename);\n            ObjectOutputStream out = new ObjectOutputStream(file);\n\n            // 将对象序列化到文件中\n            System.out.println(\"Serializing \" + obj.toString() + \" to \" + filename);\n            out.writeObject(obj);\n\n            out.close();\n            file.close();\n        }\n        catch(Exception e)\n        {\n            System.out.println(\"Exception: \" + e.toString());\n        }\n    }\n\n    // 该函数从文件反序列化对象\n    public static Object DeserializeFromFile(String filename)\n    {\n        Object obj = new Object();\n\n        try\n        {\n            FileInputStream file = new FileInputStream(filename);\n            ObjectInputStream in = new ObjectInputStream(file);\n\n            // 从文件反序列化对象\n            System.out.println(\"Deserializing from \" + filename);\n            obj = in.readObject();\n\n            in.close();\n            file.close();\n        }\n        catch(Exception e)\n        {\n            System.out.println(\"Exception: \" + e.toString());\n        }\n\n        return obj;\n    }\n}</code></p><p></p><p>GPT-3的输出：</p><p></p><p></p><blockquote>检出的漏洞：不安全的反序列化：反序列化不受信任的数据可能导致远程代码执行。不安全的文件权限：正在写入或读取的文件可能具有不安全的权限，从而导致未经授权的访问。</blockquote><p></p><p></p><p>GPT-3再次判断正确。</p><p></p><h2>网络安全“终极”左移</h2><p></p><p></p><p>左移是在开发过程早期应用安全实践的过程——比如在将代码部署到生产环境之前测试安全漏洞。</p><p></p><p>人工智能代码分析代表了网络安全领域的终极左移，它通过应用最佳安全实践，在开发人员编写和提交代码时为他们提供网络安全指导。这可以真正地在组织内部培养起强大的网络安全文化，甚至可以防止下一次大规模黑客攻击，但是……</p><p></p><p>不可否认，这项技术还不完美，它会遗漏一些事情，而一个有经验的网络安全专业人士在审计时就不会遗漏。尽管如此，作为一种通用的大型语言模型，它还是非常不错的，而且成本比其他替代方案低很多。</p><p></p><p>目前，GPT-4的发布日期还不确定，但我相信，随着这些大型语言模型的功能越来越多，它们会继续向前发展。</p><p></p><h4>假阳性</h4><p></p><p></p><p>在手动检查GPT-3检出的213个漏洞中的约50个后，我唯一发现的假阳性是在这个<a href=\"https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner/blob/main/Unsafe%20Deserialization/unsafe.js\">JavaScript程序</a>\"的第13行：</p><p></p><p><code lang=\"plain\">var express = require('express');\nvar cookieParser = require('cookie-parser');\nvar escape = require('escape-html');\nvar serialize = require('node-serialize');\nvar app = express();\napp.use(cookieParser())\n \napp.get('/', function(req, res) {\n if (req.cookies.profile) {\n   var str = new Buffer(req.cookies.profile, 'base64').toString();\n   var obj = serialize.unserialize(str);\n   if (obj.username) {\n     res.send(\"Hello \" + escape(obj.username)); // &lt;--- GPT-3在这里犯了一个错误\n   }\n } else {\n     res.cookie('profile', \"eyJ1c2VybmFtZSI6ImFqaW4iLCJjb3VudHJ5IjoiaW5kaWEiLCJjaXR5IjoiYmFuZ2Fsb3JlIn0=\", {\n       maxAge: 900000,\n       httpOnly: true\n     });\n }\n res.send(\"Hello World\");\n});\napp.listen(3000);</code></p><p></p><p>GPT-3的输出：</p><p></p><p></p><blockquote>检出的漏洞：不安全的cookie设置（未设置安全标志）未验证的用户输入（cookie）反序列化未对用户输入（用户名）进行转义，可能存在XSS漏洞GPT-3对于前2个漏洞的判断是正确的，但第3个漏洞是假阳性—— obj.username 已经进行了编码，但GPT-3说没有。</blockquote><p></p><p></p><h4>GPT-3检测结果</h4><p></p><p></p><p>实验结果表明，经过扫描，GPT-3在129个文件的到86个中检出了安全漏洞。这真是令人印象深刻！</p><p></p><p>以下是脚本summarize_results.py生成的GPT-3检测结果的完整摘要：</p><p></p><p><code lang=\"plain\">在129个文件中，有86个检出了漏洞。\n总共检出了213个漏洞。\n\nGPT-3回复中使用的介绍性句子的出现频率（每个扫描的文件一个回复）：\n{'vulnerabilities detected': 73, 'no vulnerabilities detected.': 43, 'vulnerability detected': 6, 'answer': 2, 'potential vulnerabilities detected': 2, 'analysis': 1, 'security vulnerabilities detected': 1, 'no response given': 1} \n\n扫描的文件类型的分布：\n总计129个代码文件（不包括markdown和平面文件）\n{'.php': 50, '.js': 20, '.cs': 16, '.c': 14, '.java': 9, '.py': 8, '.rb': 5, '.asp': 3, '.ts': 2, '.go': 1, '.html': 1}</code></p><p></p><h4>与商业产品的对比</h4><p></p><p></p><p>为了完善这个实验，我将GPT-3的结果与商用代码漏洞扫描工具<a href=\"https://snyk.io/product/snyk-code/\">Snyk Code</a>\"（由Snyk公司开发）做了比较。我认为，Snyk公司开发的安全产品非常出色。通过扫描，Snyk Code从这个代码库中发现了99个安全漏洞，而GPT-3发现了213个安全漏洞。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/12/1225fdb6cb913f9281659cf78de5d6e8.png\" /></p><p></p><p>其中一个原因是Snyk Code只支持其中部分编程语言，并且只能扫描大约103个文件，而GPT-3扫描了129个文件。</p><p></p><p>此代码库中存在漏洞的代码片段来自<a href=\"https://github.com/snoopysecurity/Vulnerable-Code-Snippets\">snoopysecurity/Vulnerable-Code-Snippets</a>\"，这是一个很棒的资源。我试着删除了嵌入在代码段中的注释，从中可以看出这个代码段中包含哪些安全漏洞。这些需要删除的注释中包含指向这些示例片段出处的博文链接。要查看它们在原代码库中的位置，可以查看<a href=\"https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner/blob/main/attributions.md\">attributions.md</a>\"文件。</p><p></p><p>原文链接：<a href=\"https://betterprogramming.pub/i-used-gpt-3-to-find-213-security-vulnerabilities-in-a-single-codebase-cc3870ba9411\">https://betterprogramming.pub/i-used-gpt-3-to-find-213-security-vulnerabilities-in-a-single-codebase-cc3870ba9411</a>\"</p>",
    "publish_time": "2023-03-30 07:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Java近期新闻：新JEP、GraalVM 23早期访问构建、Infinispan、Mojarra、Micrometer Metrics",
    "url": "https://www.infoq.cn/article/F6cg96zpRMMi9uAq1zyU",
    "summary": "<p></p><h4>OpenJDK</h4><p></p><p></p><p>上周，JEP 440（<a href=\"https://openjdk.org/jeps/440\">记录模式</a>\"）已从JEP Draft 8300541<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-March/007470.html\">提升</a>\"到Candidate状态。该JEP最终确定了这一特性，并针对前2轮<a href=\"https://openjdk.java.net/jeps/12\">预览</a>\"的反馈做了增强。这两轮预览分别是在JDK 20中发布的JEP 432（<a href=\"https://openjdk.org/jeps/432\">记录模式第2次预览</a>\"）和在JDK 19中发布的JEP 405（<a href=\"https://openjdk.org/jeps/405\">记录模式预览</a>\"）。该特性为这门语言添加了记录模式，用于解构记录值。记录模式可以与类型模式搭配使用，为“强大的声明式、可组合数据导航和处理形式”提供支持。最近，类型模式被扩展应用于switch 的选择标记：JEP 420（<a href=\"https://openjdk.java.net/jeps/420\">switch模式匹配第2次预览</a>\"，在JDK 18中交付）和JEP 406（<a href=\"https://openjdk.java.net/jeps/406\">switch模式匹配预览</a>\"，在JDK 17中交付）。JEP 432最重要的变化是不再支持在增强for语句头中使用记录模式。</p><p>&nbsp;</p><p>类似地，JEP 441（<a href=\"https://openjdk.org/jeps/441\">switch模式匹配</a>\"）已经从JEP Draft 8300542<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-March/007471.html\">提升</a>\"到Candidate状态。该JEP最终确定了这一特性，并针对前4轮的预览反馈做了增强：JEP 433（<a href=\"https://openjdk.org/jeps/433\">switch模式匹配第4次预览</a>\"），在JDK 20中交付；JEP 427（<a href=\"https://openjdk.org/jeps/427\">switch模式匹配第3次预览</a>\"），在JDK 19中交付；JEP 420（<a href=\"https://openjdk.java.net/jeps/420\">switch模式匹配第2次预览</a>\"），在JDK 18中交付；JEP 406（<a href=\"https://openjdk.java.net/jeps/406\">switch模式匹配开关预览</a>\"），在JDK 17中交付。该特性通过在switch表达式和语句中支持模式匹配来增强语言。</p><p>&nbsp;</p><p>JEP 442（<a href=\"https://openjdk.org/jeps/442\">外部函数和内存API第3次预览</a>\"）已经从JJEP Draft 8301625<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-March/007473.html\">提升</a>\"到Candidate状态。这个JEP基于之前的反馈做了改进：JEP 434（<a href=\"https://openjdk.org/jeps/434\">外部函数和内存API第2次预览</a>\"），在JDK 20中交付；JEP 424（<a href=\"https://openjdk.org/jeps/424\">外部函数和内存API预览</a>\"），在JDK 19中交付；JEP 419（<a href=\"https://openjdk.org/jeps/419\">外部函数和内存API第2轮孵化</a>\"），在JDK 18中交付；JEP 412（<a href=\"https://openjdk.org/jeps/412\">外部函数和内存API第1轮孵化</a>\"），在JDK 17中交付。该特性为Java应用程序提供了一个可以与Java运行时之外的代码和数据进行互操作的API，让它们可以高效地调用外部函数以及安全地访问不受JVM管理的外部内存。JEP 434的更新包括：在Arena接口中集中管理原生段（native segments）的生命周期；使用一个新元素解引用地址布局，增强布局路径；删除VaList类。</p><p>&nbsp;</p><p>JEP Draft 8303683（<a href=\"https://openjdk.org/jeps/8303683\">虚拟线程</a>\"）是由<a href=\"https://inside.java/u/RonPressler/\">Ron Pressler</a>\"（Oracle Loom项目架构师和技术主管）和<a href=\"https://inside.java/u/AlanBateman/\">Alan Bateman</a>\"（Oracle Java平台组架构师）于上周提交的。该JEP建议根据前2轮预览的反馈最终确定这一特性：JEP 436（<a href=\"https://openjdk.org/jeps/436\">虚拟线程第2次预览</a>\"），在JDK 20中交付；JEP 425（<a href=\"https://openjdk.org/jeps/425\">虚拟线程预览</a>\"），在JDK 19中交付。该特性为Java平台提供了虚拟线程。这种轻量级的线程极大地减少了编写、维护和观察高吞吐量并发应用程序的工作量。与JEP 436相比，其最重要的变化是虚拟线程现在完全支持<a href=\"https://openjdk.org/jeps/8303683#Thread-local-variables\">线程局部变量</a>\"，取消了不使用这些变量的选项。要了解更多关于JEP 425的细节，可以阅读<a href=\"https://www.infoq.com/news/2022/05/virtual-threads-for-jdk19/\">InfoQ的新闻报道</a>\"及观看<a href=\"https://www.linkedin.com/in/jos%C3%A9-paumard-2458ba5/\">José Paumard</a>\"（Oracle Java平台组Java开发大使）提供的JEP Café<a href=\"https://inside.java/2022/06/08/jepcafe11/\">截屏视频</a>\"。</p><p>&nbsp;</p><p>JEP Draft 8304400（<a href=\"https://openjdk.org/jeps/8304400\">启动多文件源代码程序</a>\"）也是由Pressler提交的。该JEP建议增强Java启动器，让它可以执行以一个或多个Java源代码文件形式提供的应用程序。这样就可以推迟全面的项目设置，使得从小型应用程序到大型应用程序的过渡更加平滑。</p><p>&nbsp;</p><p></p><h4>JDK 20</h4><p></p><p></p><p>JDK 20仍处于<a href=\"https://openjdk.java.net/jeps/3#rc\">发布候选</a>\"阶段，GA版本预计将于2023年3月21日发布。<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-20%2B36\">Build 36</a>\"仍然是JDK 20<a href=\"https://jdk.java.net/20/\">早期访问构建</a>\"的当前构建。要了解关于这个版本的更多细节，请查看<a href=\"https://jdk.java.net/20/release-notes\">发布说明</a>\"。</p><p>&nbsp;</p><p></p><h4>JDK 21</h4><p></p><p></p><p>JDK 21的<a href=\"https://jdk.java.net/21/\">早期访问构建</a>\"<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-21%2B14\">Build 14</a>\"也于上周发布，其中包括来自Build 13的<a href=\"https://github.com/openjdk/jdk/compare/jdk-21%2B13...jdk-21%2B14\">更新</a>\"，该更新修复了各种<a href=\"https://bugs.openjdk.org/issues/?jql=project%20%3D%20JDK%20AND%20fixversion%20%3D%2021%20and%20%22resolved%20in%20build%22%20%3D%20b14%20order%20by%20component%2C%20subcomponent\">问题</a>\"。要了解关于这个版本的更多细节，请查看<a href=\"https://jdk.java.net/21/release-notes\">发布说明</a>\"。</p><p>&nbsp;</p><p>对于<a href=\"https://openjdk.java.net/projects/jdk/20/\">JDK 20</a>\"和<a href=\"https://openjdk.java.net/projects/jdk/21/\">JDK 21</a>\"，我们鼓励开发人员通过<a href=\"https://bugreport.java.com/bugreport/\">Java Bug数据库</a>\"报告Bug。</p><p>&nbsp;</p><p></p><h4>GraalVM</h4><p></p><p></p><p>Oracle实验室<a href=\"https://twitter.com/graalvm/status/1636747570377523200?cxt=HHwWgICw9cnP8rYtAAAA\">发布</a>\"了GraalVM 23.0.0的最新早期访问开发构建。其新特性包括：对<a href=\"https://docs.oracle.com/en/graalvm/enterprise/20/docs/reference-manual/native-image/Resources/\">Native Image Bundles</a>\"的初始支持；经过改进的Linux上AWT支持；原生镜像推荐。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/graalvm/graalvm-ce-dev-builds/releases/tag/23.0.0-dev-20230317_0549\">发布说明</a>\"。</p><p>&nbsp;</p><p></p><h4>Spring Framework</h4><p></p><p></p><p>Spring Tools 4.18.0<a href=\"https://spring.io/blog/2023/03/15/spring-tools-4-18-0-released\">发布</a>\"，新特性包括：经过升级的Eclipse 2023-03 IDE；经过改进的新一代Spring Data存储库查询方法内容辅助；修复了导致VSCode中常规Java内容辅助停止工作的问题；修复m2e资源文件（如application.properties ）不向目标文件夹复制的问题。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/spring-projects/sts4/releases/tag/4.18.0.RELEASE\">发布说明</a>\"。</p><p>&nbsp;</p><p></p><h4>Quarkus</h4><p></p><p></p><p><a href=\"https://quarkus.io/blog/quarkus-3-0-0-alpha6-released/\">Quarkus 3.0.0的第6个Alpha版本</a>\"提供了2个新特性：通过将quarkus.datasource.jdbc.telemetry 属性设置为true来启用OpenTelemetry for JDBC；CredentialsProviders接口现在支持MongoDB连接。该版本还进行了依赖项升级，包括：SnakeYaml 2.0、Maven Compiler Plugin 3.11.0、Maven OpenRewrite Maven Plugin 4.41.0、SmallRye Common 2.1.0和JBoss Threads 3.5.0.Final。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/quarkusio/quarkus/releases/tag/3.0.0.Alpha6\">更新日志</a>\"。</p><p>&nbsp;</p><p></p><h4>Hibernate</h4><p></p><p></p><p><a href=\"https://in.relation.to/2023/03/17/orm-62-cr4/\">Hibernate ORM 6.2的第4个候选版本</a>\"根据Java社区的反馈提供了33个Bug修复和28个改进。预计这将是最终版本发布之前的最后一个候选版本。</p><p>&nbsp;</p><p></p><h4>Micrometer</h4><p></p><p></p><p><a href=\"https://github.com/micrometer-metrics/micrometer/releases/tag/v1.11.0-M2\">Micrometer Metrics 1.11.0的第2个里程碑版本</a>\"提供了一些新特性，包括：一个新指标jvm.threads.started ，用于报告JVM中活动应用程序线程的总数；一个新的ElasticSearch端点\\_index\\_template，用于创建索引模板；将GC名称添加到jvm.gc.pause指标；在基于OSGi的Java运行时上支持Micrometer 库。</p><p>&nbsp;</p><p>类似地，Micrometer Tracing 1.1.0的第2个里程碑版本也提供了一些新特性，包括：<a href=\"https://spring.io/projects/spring-cloud-sleuth\">Spring Cloud Sleuth</a>\"注解的等效物；依赖项升级到Micrometer 1.11.0-M2和OpenTelemetry 1.24.0。</p><p>&nbsp;</p><p></p><h4>Infinispan</h4><p></p><p></p><p>Infinispan 14.0.7.Final<a href=\"https://infinispan.org/blog/2023/03/13/infinispan-14\">发布</a>\"，支持Spring Framework 6和Spring Boot 3。它提供了一些值得注意的Bug修复，包括：MetricsCollector类中的NullPointerException；JSON解析器不能正确报告错误位置；Redis序列化协议（RESP）端点不能解析超过数据包大小的请求；并发访问<a href=\"https://spring.io/projects/spring-session\">Spring Session</a>\"集成会导致会话属性丢失。</p><p>&nbsp;</p><p></p><h4>Piranha</h4><p></p><p></p><p><a href=\"https://piranha.cloud/\">Piranha</a>\"23.3.0<a href=\"https://github.com/piranhacloud/piranha/releases/tag/v23.3.0\">发布</a>\"，显著的变化包括：升级<a href=\"https://codeql.github.com/\">CodeQL</a>\"工作流；为DefaultAnnotationManager类添加JUnit测试；修复当端点应用程序仍处于部署过程中时报RuntimeException的问题。要了解关于这个版本的更多细节，请查阅<a href=\"https://javadoc.io/doc/cloud.piranha/project/latest/index.html\">文档</a>\"和<a href=\"https://github.com/piranhacloud/piranha/issues?q=is%3Aissue+-label%3Awontfix+milestone%3A23.3.0+is%3Aclosed\">问题跟踪系统</a>\"。</p><p>&nbsp;</p><p></p><h4>Reactor项目</h4><p></p><p></p><p><a href=\"https://github.com/reactor/reactor/blob/main/README.md\">Reactor</a>\" 2022.0.5是该项目的<a href=\"https://github.com/reactor/reactor/releases/tag/2022.0.5\">第5个维护版本</a>\"，依赖项升级到reactor-core 3.5.4、reactor-addons 3.5.1、reactor-netty 1.1.5、reactor-kafka 1.3.17和reactor-kotlin-extensions1.2.2。</p><p>&nbsp;</p><p></p><h4>Eclipse Mojarra</h4><p></p><p></p><p>Eclipse Mojarra 4.0.2<a href=\"https://twitter.com/OmniFishEE/status/1636829803721392128?cxt=HHwWgICwiZiCmLctAAAA\">发布</a>\"，带来了一些显著的变化，包括：清理MockServletContext类，删除未使用的方法并添加@Override注解；清理ParseXMLTestCase类，删除未使用的方法、变量和注释掉的代码；确保@FacesConfig注解中的version()方法不会返回null；修复了在更新数据表分页标题中的按钮时报NumberFormatException的问题。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/eclipse-ee4j/mojarra/releases/tag/4.0.2-RELEASE\">发布说明</a>\"。</p><p>&nbsp;</p><p></p><h4>Apache软件基金会</h4><p></p><p></p><p>Apache Groovy 4.0.10<a href=\"https://www.mail-archive.com/announce@apache.org/msg08029.html\">发布</a>\"，带来了一些值得注意的Bug修复和改进，包括：来自GroovyScriptEngine类的令人困惑的错误消息；局部变量值未丢弃时的内存泄漏；@Builder注解在JDK 16上不起作用；MissingPropertyException截断嵌套类的类名。要了解关于这个版本的更多细节，请查看<a href=\"https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12318123&amp;version=12352914\">发布说明</a>\"。</p><p>&nbsp;</p><p>类似地，<a href=\"https://www.mail-archive.com/announce@apache.org/msg08028.html\">Apache Groovy 3.0.16</a>\"也带来了一些值得注意的Bug修复，包括：无法在JRE 16+的闭包或Lambda表达式上从BiPredicate接口调用方法；使用@CompileStatic注解会混淆静态导入的实例和方法；IllegalAccessException会使用JDK 17和Groovy 3.0.9的默认接口方法。该版本还支持JDK 16。要了解关于这个版本的更多细节，请查看<a href=\"https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12318123&amp;version=12352913\">发布说明</a>\"。</p><p>&nbsp;</p><p></p><h4>JHipster</h4><p></p><p></p><p>JHipster团队<a href=\"https://twitter.com/pascalgrimaud/status/1635700948583448582?cxt=HHwWjICw8ZXWlrMtAAAA\">发布</a>\"了JHipster Lite 0.29.0，带来了新特性和功能增强，包括：根据用户反馈删除JHipsterModulePackageJson类的依赖；删除当Cassandra数据库应用程序中正在测试的活动ApplicationContext会话超过四个时的警告消息；新的Redis依赖项和配置。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/jhipster/jhipster-lite/releases/tag/v0.29.0\">发布说明</a>\"。</p><p>&nbsp;</p><p></p><h4>JReleaser</h4><p></p><p></p><p><a href=\"https://jreleaser.org/\">JReleaser</a>\" 1.5.1（一个简化项目发布的Java实用工具）<a href=\"https://andresalmiray.com/jreleaser-1-5-1-has-been-released/\">发布</a>\"，带来了一些值得注意的修复，包括：添加<a href=\"https://jreleaser.org/guide/latest/reference/assemble/native-image.html\">Native Image</a>\"汇编程序实用工具中缺少的graalVMNativeImage属性；<a href=\"https://jreleaser.org/guide/latest/reference/assemble/java-archive.html\">Java Archive</a>\"实用工具为JAVA_OPTS环境变量生成的错误格式；改进执行外部命令时的错误处理。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/jreleaser/jreleaser/releases/tag/v1.5.1\">发布说明</a>\"。</p><p>&nbsp;</p><p></p><h4>JobRunr</h4><p></p><p></p><p>JobRunr 6.1.2<a href=\"https://github.com/jobrunr/jobrunr/releases/tag/v6.1.2\">发布</a>\"，主要是修复了两个Bug：当使用MySQL并将useServerPrepStmts属性设置为true时，元数据更新失败，并导致最终关闭；<a href=\"https://www.jobrunr.io/en/documentation/configuration/quarkus/\">JobRunr Quarkus扩展</a>\"中JobRunrDocumentDBStorageProviderProducer类未使用正确配置的问题。</p><p>&nbsp;</p><p></p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/03/java-news-roundup-mar13-2023/\">https://www.infoq.com/news/2023/03/java-news-roundup-mar13-2023/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/SZXNxA7DaBzCddCNAUxG\">Java 20 发布，新特性一览：Amber、Loom 和 Panama 项目</a>\"</p><p><a href=\"https://www.infoq.cn/article/P1vXcLlwewcK5XQQIQdN\">Java 近期新闻：JDK 21 序列集合、JDK 20 向量 API、Gen ZGC、Hilla 2.0</a>\"</p>",
    "publish_time": "2023-03-30 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "基于 eBPF 的云原生可观测性深度实践",
    "url": "https://www.infoq.cn/article/H1WOWBgxK5Y55EemDHze",
    "summary": "<p></p><p></p><blockquote>本文由 InfoQ 整理自云杉网络 DeepFlow 产品负责人向阳在 QCon 全球软件开发大会（北京站）2022 上的演讲分享。</blockquote><p></p><p></p><p>大家好，我是<a href=\"https://qcon.infoq.cn/2023/beijing/presentation/4546\">向阳</a>\"，我从清华大学毕业之后就来到了云杉网络，目前负责云原生可观测性产品 <a href=\"https://www.yunshan.net/products/deepflow.html\">DeepFlow</a>\"。这个产品其实有些年头了，它诞生于 2016 年，并且已经走进了上百个金融、能源、运营商行业的 500 强客户中。去年我们把产品的内核进行了开源，希望它能被更多其他行业、其他国家的用户所知晓。目前开源的时间还不长，7 月份刚有了第一个社区版的 Release，在这里也欢迎大家加入我们的开源社区。</p><p></p><h3>前言</h3><p></p><p></p><p>相信大家都有感受，eBPF 最近一年突然火了起来，特别是在可观测性领域。但实际上追溯起来，它的前身 BPF 技术已经有 30 年历史了。我们基于这项有着悠久历史的「新」技术，在它之上做出了一些非常令人激动人心的创新，特别是对 Distributed Tracing 问题给出了一种全新的解法。我相信即使是从世界范围上来讲，我今天分享的内容也能称得上是颠覆性的改变。</p><p></p><p>在准备这次的 <a href=\"https://qcon.infoq.cn/2023/beijing/schedule\">QCon </a>\"演讲时，我还问了一下 ChatGPT，基于它更新到 2021 年的知识体系，我问它 eBPF 能否用于实现 Distributed Tracing？它像模像样地编了一大堆话，不过最终得出了否定的结论，并建议我使用 OpenTracing。</p><p></p><p>DeepFlow 希望利用以 eBPF 为代表的自动化技术，去降低实现可观测性的复杂度，为开发同学带来自由，促进开发和运维的和睦相处。今天我分享的主角是 eBPF，它带来的安全、灵活的内核可编程能力可以做很多事情，但本文会聚焦在如何利用它来创新的解决分布式追踪问题上。</p><p></p><p>在此之前，我会先回顾一下分布式追踪的历史，然后聚焦介绍 DeepFlow 利用 eBPF 做出的酷炫特性，即 AutoTracing，它不用修改任何代码就能实现分布式追踪，然后介绍我们如何将 eBPF 和 OpenTelemetry 这两项技术结合形成令人激动的全栈、全链路分布式追踪方案，最后简单看看 DeepFlow 作为一个可观测性平台的其它能力。</p><p></p><p></p><h3>分布式追踪：回顾十四年历史，剖析云原生时代的新痛点</h3><p></p><p></p><p>相信大家非常熟悉分布式追踪，追踪数据是可观测性三大支柱之一。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/07/0790ec5b8e97dfe92dd96920d25c3f18.png\" /></p><p></p><p>通过采集一个 Trace 在多个进程中的 Span，最终我们能得到这样一个火焰图，它有点类似于我们对单一进程做的 CPU Profile，区别在于分布式追踪是一个聚焦在单次业务请求上的、覆盖多个服务进程的全景火焰图。它从上到下描述了一个分布式应用在服务之间的远程调用关系、服务内部的函数调用关系，它能够快速帮助开发者，特别是由很多个跨团队的微服务开发同学快速确定问题发生的位置，找到对应的负责人。基于这样的火焰图，我们还可以从中聚合出一些应用性能指标，比如说每个服务的吞吐、时延、异常，以及服务之间的访问关系拓扑等。</p><p></p><p></p><h4>分布式追踪的十四年</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3c/3cad63ee0973b0b5ea3659e185227d96.png\" /></p><p></p><p>一般认为分布式追踪可以追溯到 Google 的 Dapper 论文上，这个论文是 2010 年发表的，论文里讲到 Google 从 2008 年开始做 Dapper 这个系统，解决 Google 内部微服务调用追踪的问题。受这篇论文启发，开源社区诞生了一批优秀的项目，例如非常火的 Apache SkyWalking 就是聚焦在这个问题上。再到最近几年，开发者们发现插桩这件事应该要标准化、自动化，因为它侵入了业务程序中，随着开发语言、微服务框架越来越多样化，开发者们不希望因为插桩这件事去太多修改业务代码，在这个驱动力之下诞生了 OpenTracing，进而发展为 OpenTelemetry。</p><p></p><p></p><h4>云原生时代的痛：插码插不全</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/62/6277fb3dd91ae361736d4d0042acb45e.png\" /></p><p></p><p>在云原生时代，分布式追踪这件事变得越来越迫切，也遇到越来越严峻的挑战。首先，随着服务拆成，单个微服务的业务代码会越来越简单，同时有一部分公共逻辑会逐渐的卸载到基础设施中，比如说通过服务网格或 API 网关实现。因此微服务会越来越轻，开发写的代码会越来越聚焦在业务逻辑方面，这是一个趋势。</p><p></p><p>另外一点是微服务技术栈的多样性，如果微服务变得越来越简单了，开发同学就会有越来越多的自由，可以选择自己比较喜欢的框架和语言。但是这会导致一个问题，分布式追踪在这种场景下越来越不容易全面覆盖。有一个以往我们很喜欢的东西 Java Agent，它可以做到无侵扰的插码，在对业务代码无修改的情况下实现一定程度上的分布式追踪能力。</p><p></p><p>但是，一方面注入 JavaAgent 还是需要重启业务进程，另一方面在其它语言中一般不存在类似的字节码注入机制，比如说对于 Golang。假设你是公司内部的基础设施开发团队，你负责开发维护 Golang 的 SDK 去做 Instrumentation，可以想象在 SDK 每发布一个新版本之后，都需要漫长的时间来让公司里众多业务部门将 SDK 更新到新版本，这个时间可能会长达半年甚至一年，是一个非常漫长非常无奈的过程。因此，大家几乎有一个共识，现有的依靠插码的分布式追踪，落地起来还是很有难度的，是一项需要协调所有业务开发部门的工作。</p><p></p><p></p><h4>云原生时代的痛：链路追不全</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f0/f0af296be0e2fb567f41568abc1ca796.png\" /></p><p></p><p>云原生时代的另外一个趋势，通信路径的复杂性。以往服务之间的通信路径非常简单，最早的时候可能是两台服务器通过网线和交换机直接连起来，甚至是在同一台服务器上通过本地 Socket 直接通信。但在云原生时代，开发同学会发现两个服务之间可能跨越了千山万水，有 Pod 里面的 Service Mesh Sidecar、云服务器中的虚拟网桥、KVM 宿主机上虚拟交换机，还有大量的四七层网关、消息队列、中间件等等，通信路径非常复杂。</p><p></p><p>与此同时，几乎所有的分布式追踪机制其实都只聚焦在业务代码、框架 / 库函数两个层面，对服务之间的通信路径缺乏覆盖。然而，在微服务数量从 1 增长到 N 的过程中，服务之间通信路径的复杂度极端情况下可能增长了 N^2，复杂度的增长达到了几个数量级。造成的后果是，业务出现问题之后，依靠现有的分布式追踪能力开发同学往往找不到问题所在，越是聚焦在业务开发的同学，对于底层的这些云原生基础设施会了解地越少。我们发现经常会发生的经典故事是，开发难以回答到底是自己的问题、上下游服务的问题，还是基础设施的问题。由于分布式追踪无法覆盖云原生基础设施中的通信路径，这个问题往往无法回答，导致一个工单来回在不同团队之间无效流转。</p><p></p><p>确实，上述就是我们的现状，微服务越来越多样，通信路径越来越复杂，导致了分布式追踪越来越重要，但又越来越难以追全。</p><p></p><p></p><h3>AutoTracing：基于 eBPF，零代码修改实现分布式追踪</h3><p></p><p></p><p>铺垫了这么多，下面介绍本文的主角，DeepFlow 基于 eBPF 做的一个非常酷的能力 AutoTracing，即零代码修改、零应用发布、零进程重启的分布式追踪能力。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/86/86150e047d80be0685f82a869b297398.png\" /></p><p></p><p>上图是去年的截图，粘贴的是 Google 的搜索结果，如果今年再写 PPT 的话应该要贴 ChatGPT 的图了。从图中可以看到搜索 eBPF Tracing 有 10 万个结果，但这些结果中的 Trace 实际上都是指在一台单一的主机上去 Trace 函数调用、系统调用等行为，这些都是 eBPF 被大家所熟知的能力，然而他们并不是今天我们要谈论的 Distributed Tracing。</p><p></p><p></p><h4>Istio Bookinfo 零插码追踪 Demo</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/33/335afa43a916c2066ad39ddc7c13bd98.png\" /></p><p></p><p>那到底 eBPF 能用于实现分布式追踪吗？我们先来看一下 DeepFlow 做到的效果，上图是一个基于 Istio 的热门 Demo，这个叫 Bookinfo 的 Demo 我相信有很多朋友都比较熟悉，这里有四五种语言实现的几个微服务，覆盖了 C++（Envoy）、Python、Java、Ruby 和 Node.js。当然熟悉的朋友会知道，Istio 这个 Demo 中官方是做了 OTel 插桩的，但接下来的所有结果都是基于关闭所有这些 OTel 插桩后得到的，下文将给大家展示一下 eBPF 能做到什么程度。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/25/254c8c24b1d800cb02979d8428f699dc.png\" /></p><p></p><p>首先来确认手动插桩确实都关闭了，上图是 Jaeger 对 Bookinfo 的追踪效果。注意这一页并不是我忘记写内容了，而是想告诉大家离开了插桩 Jaeger 得不到任何追踪结果。</p><p></p><p></p><h4>DeepFlow AutoTracing：零插码、全栈</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/47/47df3b0978bcd14da6024f16bee2bfee.png\" /></p><p></p><p>是时候让 DeepFlow 上场了！大家可以看到，没有任何代码修改、没有任何重编译重发布、没有任何进程重启的前提下，DeepFlow 得到了上图所示的分布式追踪火焰图，这就是 AutoTracing 的效果。这里的每一行作为一个 Span，表达了一个调用在特定位置上被 eBPF 捕获到的事件。从火焰图中我们可以发现 Demo 中涉及到的所有服务，包括各种语言实现的业务微服务如 Productpage、Reviews 等，包括基础设施服务如 Envoy Sidecar、K8s CNI 等，以及还包括客户端 curl 进程，一个云原生业务的全栈分布式调用路径被完整的追踪下来了。</p><p></p><p>上图中有两种 Span：彩色的是 DeepFlow 利用 eBPF kprobe/tracepoint/uprobe/USDT 从 Kernel 系统调用和 User 函数调用中采集到的系统 Span，灰色是利用 BPF（Classic BPF）从虚拟网络中每个网卡（即内核中的 IP 收发包函数）中采集到的网络 Span。基于这两种 Span 进行关联，然后绘制出一次业务请求背后整个分布式调用的火焰图画。现在这个图中只是给了大家一些直观上的体感，接下来我们把这个图稍微放大一点，看看它的一些细节效果，来进一步感受一下。</p><p></p><p></p><h4>感受 DeepFlow 的 AutoTracing</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/25/25a1298d337ce3bf32a355f89c4e2768.png\" /></p><p></p><p>1.零插码：且无需向 HTTP 头注入 TraceID 或 SpanID</p><p>2.全链路：4 个调用、38 个 Span，分为 24 eBPF Span + 14 BPF Span</p><p>3.多语言：Java、Python、Ruby、Node.js 及 C/C++ (curl/envoy)</p><p>4.全栈：追踪两个微服务之间的网络路径，从 Pod 到 Node 到 KVM，IPIP、VXLAN、…</p><p>5.全栈：追踪微服务内从 Envoy Ingressjian 到 服务 到 DNS 到 Envoy Egress 全过程</p><p>案例：某互联网客户，使用 DeepFlow 5 分钟内定位客户端慢服务端不慢的经典扯皮问题。</p><p></p><p>首先，零代码修改。完成上图中的分布式追踪，DeepFlow 确实没有向调用中注入任何 TraceID 或 SpanID，同样也确实没有修改哪怕一行代码、没有重启任何一个进程。这个 Demo 中追踪火焰图覆盖到了所有 6 个进程，包括 C 语言实现的 curl、C++ 实现的 Envoy、Python 实现的 ProductPage、Ruby 实现的 Details、Java 实现的 Reviews、Node.js 实现的 Ratings；覆盖到了他们之间的所有 4 个调用，并采集到了 38 个 Span，其中包括 24 个 eBPF Span 和 14 个 BPF Span。</p><p></p><p>其次，再来看全栈追踪能力。举两个例子，第一个是上图中顶部蓝色的 curl 进程（在 loadgenerator Pod 中）调用下放绿色的 ProductPage 服务，我们会发现，从客户端 curl 进程、客户端 LoadGenerator Pod 虚拟网卡、客户端 K8s Node 物理网卡、服务端 K8s Node 物理网卡、服务端 ProductPage Pod 虚拟网卡、服务端 ProductPage 进程，这个调用经过的每一跳都看得非常清楚。图中的 Span 中，头部携带 S 标记的是 eBPF 获取到的系统 Span，携带 N 标记的是 cBPF 获取到的网络 Span。另外在实际的生产环境中，中间的网络路径还可能更复杂，比如会经过 NFV 网关的网卡、KVM 宿主机的网卡等，这些复杂的路径在 DeepFlow 中也能完整地追踪出来。具体到上图中的例子，我们发现这样的全栈追踪能力能快速地发现瓶颈发生的位置，图中两个 K8s Node 之间的云网络消耗了比较显著的时间。</p><p></p><p>再次，再从服务网格的角度看全栈。上图中放大了中间一块区域，这是一个调用从进入 ProductPage Pod 到继续请求上游服务的全过程。我们知道这个 Demo 是基于 Istio 的，从火焰图中也清晰地看到调用显示被 Envoy 劫持（收到并发出去），然后才被 ProductPage 进程接收到。这个服务为了完成下游的请求，它需要调用上游的 Details 和 Reviews 服务。在调用 Details 之前，我们看到火焰图上这个服务首先发起了一次 DNS 请求来查询 Details 服务的域名，然后调用 Details 服务，而这个调用也被 Pod 内的 Envoy 代理再一次劫持。我们会发现，在服务网格环境中的调用能被 DeepFlow 清晰的观测到全过程，我们能够快速的判断到底是哪个组件、哪一个基础设施服务、或者哪一个业务服务出现了瓶颈或故障，非常清晰。</p><p></p><p>到此为止，相信大家已经对 DeepFlow 基于 eBPF 的 AutoTracing 能力所叹服了，这个能力也已经帮助我们很多客户实现了云原生应用的快速故障排查。熟悉 OpenTelemetry/SkyWalking 的朋友们可能也发现了它的一个特点：在进程内部我们只为每个调用生成了一个 Span，并没有精细拆分为业务代码、框架代码、库代码等。一方面是因为业务代码粒度的追踪不具备普适性，使用 eBPF 去覆盖会有很大的实现复杂度和性能开销；另一方面也是因为这部分其实已经有各个语言的 Instrumentation 覆盖了，例如大家熟悉的 JavaAgent 的方式。下文将会解释这样取舍的原因，让 eBPF 发挥它擅长的能力，对基础设施服务、进程中的标准远程调用进行覆盖，从而实现对所有分布式调用的完整追踪能力。在实现全局覆盖以后，再选择使用语言的 Instrumentation 来增强局部。</p><p></p><p></p><h4>AutoTracing 背后的关键洞察</h4><p></p><p></p><p>下面的内容是本文的硬核部分，深入介绍 AutoTracing 机制的原理。DeepFlow 开源以来文档工作比较滞后，有很多小伙伴会问到你这是怎么追踪出来的，是不是骗人的。实际上 deepflow.io 上也有我们的在线 Demo，可以随时访问，而且也已经有很多社区用户和企业版客户在使用这个能力了。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/2c/2ce62867f8ae3c29fe859f9d044853f9.png\" /></p><p></p><p>接着介绍一下 AutoTracing 背后的关键洞察，以及我们碰到的一些挑战。现在回顾起来其实关键洞察很简单，就像我们在用 JavaAgent 实现 Tracing 一样，我们会熟悉一个叫 ThreadLocal 的东西，我们时不时的往 ThreadLocal 里藏一些东西，这个时候就能将一个 Service 的入方向的调用和出方向的调用关联起来了。比如说以上图中的 Service A 为例，我们希望把 Client 请求服务 A 的调用以及 A 访问 B 和 C 的调用关联起来，当我们能做到这件事时就解决了单一服务上下游的追踪问题；如果说还能做到将 A 发起的调用和 B 收到的调用关联起来，也就解决了两个进程之间的追踪问题；当我们做完这两件事时，我们发现已经实现了对一个最基本的分布式应用的追踪能力，这就是我们非常初始的想法。</p><p></p><p>类似于在 Java 中利用 ThreadLocal 传输信息，在 eBPF 中我们可以利用 ThreadID 来对一个进程上下游的调用进行关联。但很不幸的是，真实世界非常复杂，我们并不能用一种简单的方法利用 eBPF 在内核中获取的信息感知到每种语言中的「线程」，但本着从简单问题入手的思路，我们发现实际上大部分语言都遵循 Kernel Threading Model，即内核态的线程和用户态的线程是 1:1 对应的，像 Java、C 等语言都是这种模型，此时我们可以直接用 Thread ID 来做调用之间的关联。除此之外也有非常少数的语言采用 Hybrid Threading Model，如 Golang、Erlang，它们是协程化的语言，这些语言中的协程 ID 和 eBPF 在内核中感知到的 ThreadID 并没有多大的关系，下文也会来解释我们如何解决这类场景。作为第一步尝试，我们先将问题简化，只考虑上图中央部分的大多数场景 —— Kernel Threading Model 下的分布式追踪问题。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ef/efba9d28af757d47bc44b68e274b38e0.png\" /></p><p></p><p>第零步，构造一个理想环境。在上图中服务 A 每接收到一个新的来自 Client 的请求都会使用一个全新的线程来处理它，并在这个线程中调用上游的服务 B 和 C，在完成并响应 Client 后关闭处理线程。我们以此为起点，首先希望能在一个理想环境下获得完美的效果。正如大家所看到的，这种情况下我们天然的可以通过 eBPF 获取到的 ThreadID 和调用进行关联，实现服务 A 上下游的调用的追踪。</p><p></p><p>从这个完美的起点出发我们能走多远呢？两年前刚开始做这件事时我们也不知道答案，甚至经常会面对不完美结果的打击，但现在回顾过来我们不断的探索过程非常精彩，接下来一一和你分享。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d7/d7986ff289fe07bb4cb547ecfd6dcd87.png\" /></p><p></p><p>第一步，解决线程复用的问题。上图是一种阻塞调用场景下的最简单的线程复用场景，和我们的理想场景只有一个区别：处理调用的线程 X 在完成 Client 的请求之后并没有终结，他会被归还到一个线程池中，稍后就会继续服务于下一个请求。因此这种场景下我们不能简单的认为「关联至同一个 ThreadID 的调用是在一个 Trace 中」，这样会把时间轴上先后出现的不同 Trace 合并到一起。这种情况 DeepFlow 如何解决呢？实际上比较简单，我们只需要按照时间维度进行切分即可，当我们发现某个线程 X 已经完成了来自 Client 的调用的完整闭环时，我们认为一个 Trace 结束了。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/86/8655b906f5441a11fcfd7d62b266e388.png\" /></p><p></p><p>第二步，解决非阻塞 IO 的问题。在上一步中，我们假设了服务 A 的线程 X 在处理一个 Trace 的请求过程中，不会去处理另一个 Trace 的请求。这是一个非常强的假设，实际的环境中在服务 A 接收到一个来自 Client 的调用之后，很可能在同一个线程中还会处理其他的来自 Client 的调用。典型的对于一些单线程语言都会是这样的处理逻辑，否则自己会被卡死。那接下来思考一下非阻塞 IO 的场景是否能解决呢？上图中展示了 DeepFlow 的解决思路，我们利用了一点非常有意思的现象：服务 A 在接收到 Client 的请求之后会进行 CPU 计算，并会发起到服务 B 的请求，我们会发现在这段时间中是没有出让调度的机会的，也就是说在这两个时间点之间服务 A 没有机会再接收来自 Client 的请求。但是一旦服务 A 发起了到服务 B 的请求时，这个 IO 操作就给了 CPU 调度时机，这之后服务 A 无需等待服务 B 的返回，就有可能会收到来自 Client 的其他请求。</p><p></p><p>总结来看，我们可以利用 eBPF 采集到的读、写事件的时间关联性来讲两个属于同一个 Trace 的调用关联起来，例如上图中相邻的两个红色、黄色、蓝色调用，他们都属于各自的 Trace 中，他们穿插着出现在时间轴上，但通过事件的相邻关系我们能实现对他们所在的 Trace 的独立追踪。当然这里也做了一个假设，即两个 Socket 事件之间不会有其他调度点，但如果代码中有明确的 sleep 或 yield 等语句这个假设就不成立了。但这些情况是小概率事件，我们在探索的过程中先将他放在一边。</p><p></p><p>做完这些以后我们发现还是无法将所有红色的调用串联起来，例如上图中我们可以将红色的调用中的第 1-2、3-4、5-6 等三对事件分别关联为三组，但还没有将这三组串成一个大的 Trace。而这一步就依靠 DeepFlow 中的 Session 聚合能力了。我们从 eBPF 的 Function Call 里面提取到 Request 和 Response，并将它们正确的识别为一个调用。一般来讲应用协议有两种，串行协议和并行协议。比如例如 HTTP2/gRPC 就是一个并行协议，它的协议头中会有一个 StreamID 字段可以用于请求和响应的聚合。我们可以断定并行协议中一定会有类似的字段，否则业务进程自身是无法将响应于请求对应上的。</p><p></p><p>而例如 HTTP 大部分场景下就是一个串行协议，在收到响应之前不会有新的请求发出来。但也有一些特殊情况，比如 HTTP 1.1 中就实现了一种比较鸡肋的半并行协议，它允许一口气发送多个请求，并按顺序接收到这些请求的响应的回复，但这样的机制也是有明确的规律可循。对于 Session 的聚合是 DeepFlow 的拿手本事了，这里展开的话会非常复杂，但总的来讲完成这一步的挑战其实关注两个方面就行了：利用时序关联两个相邻的调用事件，利用流聚合关联同一个调用的请求和响应事件。</p><p></p><p>至此非阻塞 IO 的问题被我们解决了，感觉不错！</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ac/acd74de5314e86e1a07ab56071e91d69.png\" /></p><p></p><p>在解决前两个挑战之后，我们其实已经能在很多场景下实现对上下游调用的追踪能力了，依靠这个能力上图是一个实际的追踪例子，我们大致来感受下这个追踪的过程。图中的每一个正方形是一个服务，这也是 GitHub 上的一个微服务 Demo，中间的服务叫 web-shop，等会我们主要聚焦在它身上完成它的上下游调用的追踪。它左侧的 Client 请求 web-shop 以后，web-shop 依次调用两次 &nbsp;svc-user 完成注册和登录，然后调用一次 svc-item 完成购物，最后调用一次 svc-order 完成下单，之后返回 Client 完成此次下单的全流程。</p><p></p><p>图中在每个 eBPF 获取到的请求和响应事件上我们标记了一个 SyscallTraceID，标记橙色 ID 的是请求，标记绿色 ID 的是响应。根据 SyscallTraceID 的相等关系，我们可以将相邻两个调用关联起来（即图中的①③⑤⑦⑨）。通过将请求和响应聚合为 Session，我们可以将同一个调用中的两个 eBPF 事件关联起来（即图中的②④⑥⑧⑩）。</p><p></p><p>第三步，解决协程的问题。至此，Kernel Threading 这个占比非常大的场景我们已经有了非常好的解决方案。那是否可以去尝试一下 Hybrid Threading 场景呢？接下来我们以 Golang goroutine 为例来讲讲 DeepFlow 对协程语言的分布式追踪能力。实际上回顾下来刚才我们一直在做一件事情 —— 关联。那在协程的场景下如何实现关联呢？我们也用一张类似的图来解释：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/56/561fea7836f4d1f6672681a897f9df3d.png\" /></p><p></p><p>上图中红色、黄色、蓝色的调用依然组成了三个 Trace，不同点在于这些调用事件在 eBPF kprobe/tracepoint 中捕获时所在的 ThreadID 是混乱的，没有任何关联性，这是因为协程语言中的 coroutine 是动态绑定到内核线程中的，这完全是一个用户态程序的行为，内核无法进行控制。似乎我们已经走到死胡同了，在经历了一段时间的挫折之后我们终于找到了解决办法，也就是上图中称之为「协程染色」的机制。它背后的思想是源于对 Golang 中 API 调用处理，我们回忆一下一个 Golang 进程接收到一个 HTTP 请求时会在一个协程中处理该请求，当发现还需要继续请求上游其他服务时，Golang 的基础库会创建一个新的协程用于这个 HTTP 请求，这样做会避免每一个协程不要被卡死。仔细思考之后我们发现「协程的创建过程」其实就是我们要寻找的「关联性」。</p><p></p><p>通过 eBPF uprobe 我们获取一个 Golang 进程中的所有协程之间的创建关系，利用这样的创建关系（虚线）对协程进行染色，结果如上图所示，我们将所有协程染成了三组颜色，对应着三个 Trace。举例来讲，上图中的协程 1 创建了协程 4 和协程 5，DeepFlow 会将这三个协程染色为同样的颜色，并将这些协程中的调用关联在一个 Trace 中。简单来理解，我们可以认为染色后的同一个颜色的协程就类似一个我们在前面的场景中讨论的线程一样。</p><p></p><p>至此我们又攻克了一个难关，协程问题解决了！</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/cb/cbed73b6c1ed0cd46e03b36c1c4f23a9.png\" /></p><p></p><p>第四步，解决跨线程问题。我们继续往下走，还有一个迄今为止还没有解决的场景，跨线程。例如上图，在一个多线程的进程中，在处理来自 Client 的调用时同一个 Trace 中的上下游调用由不同的线程实现。由于缺少了关联信息，这件事情看起来又变得非常困难。得益于 DeepFlow 的 Session 聚合能力，如果一个调用的请求和响应位于两个线程中发生，对追踪是没有任何难度的，因为我们可以基于协议头部字段完成聚合。但如果一个 Trace 的不同调用位于两个线程中发生就比较困难了，比如进程中通过 Queue、Golang Channel 在不同线程之间传递 Task 信息，以及在不同线程中完成上游和下游的调用。</p><p></p><p>这其实是 DeepFlow 迄今为止唯一一个还没有完全解决的场景，但也有了一部分的解决方案，即图中展示的对于七层网关的解法。我们发现几乎任何七层网关都实现了一个非常标准化的能力，即向 HTTP Header 中注入 X-Request-ID 的能力。例如 Nginx、HAProxy、Envoy 等，他们都能为每个下游调用生成一个随机 ID，并将其注入到向上游发起的请求中，以及将其注入到回复给下游的响应中。于是我们通过提取调用中的该字段，可以将网关前后的两个调用关联起来。</p><p></p><p>注意整个过程我们都没有修改任何 Client 和 Real Server 的代码，只需要做一些网关的配置（有些网关是默认打开的，例如 Envoy），即可完成 X-Request-ID 信息的注入。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/60/6050910cdf4c98a3b91bf2d087907e15.png\" /></p><p></p><p>第五步，解决跨进程问题。其实前面四步都是在解决一个进程内部的上下游调用关联问题，接下来我们想把目光延展到两个服务进程之间。比如服务 A 调用服务 B，因为我们没有在请求 Header 中插入任何 TraceID 或 SpanID，如何能将很短一段时间内高频发生的成百上千次调用在两个不同节点、不同 Pod 之间观测到的 eBPF 事件关联起来呢？甚至还包括容器网络、云网络、NFV 网关等每一跳网络路径上发现的请求和响应事件，又怎么与 eBPF 采集的事件之间关联起来呢？</p><p></p><p>这里又要展示 DeepFlow 强大的网络基因了，这个事情其实非常简单，但也非常复杂。简单来讲，可以利用整个通信路径各处采集到的流量中的 TCP 包头特征信息将同一个调用关联起来，例如 TCP 包头中的 SEQ 信息，总共有 2x32=64 比特可以用于我们的关联，另外我们也还可以找到 IP 包头中的 ID 信息用于同样的目的。复杂的地方在于，虽然网络路径上都能采集到包，但在 eBPF 获取的系统调用和函数调用中并没有这个字段 —— 因为此时连 TCP 包都还没有（或者已经被拆开了），这个时候怎么将 eBPF 函数调用数据和 cBPF 网络流量数据关联呢？这里实际上只要能理解 TCP SEQ 的含义也容易想到解决方案，它表示的实际上是已经发送的字节的多少，了解这个背景之后我们就能轻松的在 eBPF 函数调用上下文中还原 Socket Data 将会（或刚刚）使用的 TCP SEQ 值了。</p><p></p><p>至此跨进程也被我们解决了。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/41/418a8689d981778a5baad44e52f1a7b4.png\" /></p><p></p><p>第六步，解决 SSL 加密的问题。这一点表面看起来很玄乎，实际上对于 eBPF 来讲也非常简单成熟。如上图所示通过 uprobe/USDT 我们可以在用户态函数调用中获取 HTTPS 加密之前的数据，例如通过挂载相对标准的 OpenSSL 以及 Golang 中的加密函数就能实现这一点。利用这样的思路同样也可解决 HTTP2 中的包头压缩问题，将压缩之前的包头信息完整的拿到。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/da/dacf18e4dcd2ed858b394657de61c836.png\" /></p><p></p><p>第七部，解决 Trace 组装问题。我们没有向任何 Span 中注入 TraceID 或 SpanID，那如何将这些 Span 组装为一个 Trace 呢？上图是 DeepFlow 中 Trace 查询过程的一个简化，我们可以从任何一个 eBPF Sys Span 出发，来查询与之相关的在一个 Trace 中的其他 eBPF Sys Span 和 cBPF Net Span。每当找到新的 Span 以后，循环迭代可以继续，直到无法发现更多 Span 为止。简单来讲，eBPF Span 之间可以使用 SyscallTraceID 进行关联查询，其他 Span 之间可以用 TCP SEQ 进行关联查询，另外所有 Span 之间都可以使用 X-Request-ID 进行关联查询。</p><p></p><p>到这里为止，我们从一个理想国，克服了七重困难，终于实现了一个比较美好的状态，实现了最初基于 Istio Bookinfo Demo 展示的超能力 —— 零代码修改实现分布式追踪。相信下文的描述会让你真切感受到它的漂亮。</p><p></p><p></p><h3>让追踪无盲点：结合 OpenTelemetry，实现全栈、全链路的分布式追踪</h3><p></p><p></p><p>没有银弹，AutoTracing 很美，但正如我刚才所说它「目前为止」还没有很好的解决跨线程的问题，以及我们没有让他去追踪进程内部的两个函数之间的调用关系。这个世界上没有一招鲜的银弹，但是有好基友能搞 CP，我们发现的 CP 就是 eBPF 和 OpenTelemetry：eBPF 是从内核中成长起来的零侵扰的应用观测方法，而 OTel 是从大量业务实践中成长起来的标准化代码注入方法，一个偏向基础设置另一个偏向业务逻辑，听起来就绝配。在 DeepFlow 中我们也实现了他们二者的完美结合。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/56/56e89b8bb40688e847e403901a8edba7.png\" /></p><p></p><p>首先从另一个角度理解一下这两种追踪能力的区别。对于我们业务代码中生成的 Span，它就像战斗机上装配的火控雷达一样，它的目标性非常明显，是定点打击，在某一个方向上是可以非常纵深、非常精确，但它无法做到全覆盖，特别是对位于视野之外的基础设施服务、网络路径没有任何覆盖。而 eBPF 的追踪方式其实像预警机的预警雷达一样，它能覆盖所有的微服务，能解锁「地图全开」的技能，但有些点，比如说在进程内部函数调用的追踪、以及跨线程的调用场景无法完美覆盖到。我们很难想象现代战争中缺少了预警机还能打赢，当然缺少了战斗机也没发开打。从这个类似上我们发现，将二者的能力结合是如此的自然。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ae/aea4eb7f5fc7de193d98840982fb7d4d.png\" /></p><p></p><p>DeepFlow 是怎么做的？我们通过 OTel/SkyWalking 的 JavaAgent 或 SDK 采集代码中的 Span，并通过 OTel Collector 中转（或者直接发送）至 deepflow-agent 进行收集，并与 eBPF Sys Span 和 cBPF Net Span 进行关联。这里我们也给 OpenTelemetry 和 SkyWalking 社区做了一些贡献，实现了 OTel Collector 中的 SkyWalking Receiver。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/36/36814a5aebfc51afa9f220597dba06ec.png\" /></p><p></p><p>来看看实际的效果，上图中的 Sprint Boot Demo 应用，它包含四五个微服务，以及 MySQL 作为数据库。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/14/14f4b73b49dd9c1c5e31f1414b7d1405.png\" /></p><p></p><p>上图是大家所熟悉的 OTel 加 Jaeger 的效果，追踪出了有 40 多个 Span。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/86/866fd677e15addcbbed7ba4b1b5a807f.png\" /></p><p></p><p>DeepFlow 的效果如何？一个直观的感受是 Span 的数量 Double 了，有 90 多个 Span，这里有 OTel 采集到的、以 A 开头的 Application Span，也有 eBPF Sys Span 和 cBPF Net Span。</p><p></p><p>接下来，会细致地分析一下这张追踪火焰图。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3c/3c91cbea2c4b68ccb8bc2d11350bb278.png\" /></p><p></p><p>上图中有两个放大的区域。第一个区域是调用链中深蓝色服务调用浅蓝色服务的过程，可以看到我们将追踪过程从业务代码，到框架代码，再到系统进程、沿途的网络接口等全部追踪了下来。另外一个区域是图中对 MySQL 调用过程的放大，从 MySQL 事务的开始到事务的结束，能清晰地看到时间到底是消耗在 ORM 框架上，还是网络传输上，或者是 MySQL 服务端。图中客户端业务代码等待时间很长而 eBPF 采集到的时延很短，我们推断应该是 ORM 处理抵消导致。除了这两个区域以外，我们发现 eBPF 的追踪结果除了能基于 OTel 的追踪补足基础设施路径以外，还能将整个火焰图上下延展，例如图中客户端 locust 进程、数据库 MySQL 进程都没有插码，但都出现在了火焰图中。</p><p></p><p>相信你看到上面的结果之后能快速意识到一点：这个火焰图实际上已经将各个不同的岗位统一到一个频道上来了！包括业务开发团队、框架开发团队、服务网格团队、容器运维团队、云运维团队、数据库运维团队。所有这些信息结合起来，我们可以回答很多各个层面的人的问题，到底 A 调用 B 的时候是谁的问题？我调用别人慢是我的问题吗？是他的问题吗？还是基础设施的问题？这些都能够快速回答出来。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d3/d35b29ef25a05df5dc0cfd34a1789337.png\" /></p><p></p><p>实现 eBPF 和 OTel 数据的融合其实并不困难。从 eBPF 和 cBPF 中采集到的 Span 中，我们解析出来了 HTTP/Dubbo 等协议头中的 TraceID 和 SpanID 字段，如上图所示可以轻松的实现和 App Span 的关联。</p><p></p><p></p><h3>展望未来：开源共建，开启高度自动化的可观测性新时代</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/82/82a3cbf43e3e9fadb309c8be7bc23a53.png\" /></p><p></p><p>DeepFlow 这个项目它是我们开源的一个零代码修改实现云原生应用可观测性的软件。它的软件架构非常简单，主要由 Agent 和 Server 组成，我们分别使用 Rust 和 Golang 实现了这两个组件。上图右上角是 DeepFlow 的 GitHub 的 Link，欢迎大家 Star！</p><p></p><p>eBPF 主要的优势在于零侵扰，无需修改业务代码既能自动化的实现可观测性。除了本文所说的非常酷炫的 AutoTracing 以外，DeepFlow 中还用 eBPF 实现了很多其他能力。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b7/b7eb78d9625eea1371e92fe88c719a78.png\" /></p><p></p><p>比如说 DeepFlow 有一个全景应用拓扑（Universal Application Topology）能力，这也是用 eBPF/cBPF 零代码修改情况下绘制出来的。简单来说，即可以支持在 Linux Kernel 2.6 以上内核版本的运行环境中，自动绘制任何 Pod、任何进程之间的访问关系拓扑图。这样的拓扑以往需要通过插码获取 Span 以后聚合生成，现在使用 DeepFlow 无需做任何改动，也不需要利用 Service Mesh 机制间接支持，一条命令五分钟部署 DeepFlow 以后整个全景拓扑就出来了。另外支撑拓扑的是我们通过 eBPF/cBPF 计算出的丰富的性能指标，这些指标覆盖到了从网络传输性能、网络协议栈性能、应用 RED 黄金指标等各个层面。</p><p></p><p>举个例子，承载一个 HTTP 调用的 TCP 连接，它的建连消耗了多少时间、客户端等待了多长时间、系统协议栈的 ACK 回复是否及时、期间是否有网络包重传、真正的应用请求和响应之间的耗时是多少等等，我们都能看到。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/37/378511aad7f049a36733a73199d9d29e.png\" /></p><p></p><p>DeepFlow 中的另一个亮眼能力是支持丰富的、自动化的标签注入，我们用了一种指标和标签分离、标签预压缩的方式，可以把标准标签注入的开销降低 10 倍，并通过查询时的自定义标签关联实现了 Tag without Limit 的能力。你可以从 GitHub 上拉下来代码实际压测一下，非常扎实的性能提升，丰富到吃惊的标签能力。这些能力也就是一条命令部署五分钟就能体验到，也可登录 deepflow.io 查看我们的在线 Demo。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e4/e40df19749ee9fe1214d4d294ec5a279.png\" /></p><p></p><p>最后是 DeepFlow 一些未来的演进点，比如说我们的 AutoTracing 怎样去解决跨线程的问题；文件读写怎样关联到 Trace 上面；我们应该去解析更多的应用协议，现在我们支持将十余种协议。我们会引入 WASM 和 LUA 插件机制解锁可编程能力，因为肯定有很多私有协议需要用户自己手动实现解析，而且也会有很多业务字段藏在标准协议中，这些都是可编程能力的用武之地。</p><p></p><p>以上，就是本文的全部内容。希望 DeepFlow 能让观测更自动，让开发者更自由！</p><p></p><p></p><h3>作者介绍</h3><p></p><p></p><p>向阳，云杉网络研发 VP。清华大学博士，毕业后加入云杉网络，现负责 DeepFlow 产品。最近我们将 DeepFlow 进行了开源（Apache 2.0 License），不久前刚发布了第一个社区版 Release。DeepFlow 致力于为云原生开发者提供一个高度自动化的可观测性平台，让观测更自动，让开发者更自由！</p><p></p><p></p><h3>活动推荐</h3><p></p><p></p><p>5 月 26 日 -5 月 27 日，<a href=\"https://qcon.infoq.cn/2023/guangzhou/track\">QCon 全球软件开发大会</a>\"即将落地广州，从稳定性即生命线、出海的思考、现代数据架构、AGI 与 AIGC 落地、下一代软件架构、研发效能提升、DevOps vs 平台工程、新型数据库、数据驱动业务、数智化效率革命、金融分布式核心系统、大前端技术探索、编程语言实战等角度与你探讨，欢迎你来现场打卡交流～</p><p></p><p>点击<a href=\"https://qcon.infoq.cn/2023/guangzhou/apply\">此处</a>\"直达大会官网，现在购票享 8 折优惠，组团购票还有更多折扣，感兴趣的同学联系票务经理：15600537884（电话同微信）。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d1/d13cf8729b49eb6df7a4676d2b912ea1.jpeg\" /></p><p></p>",
    "publish_time": "2023-03-30 10:29:42",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "钉钉协作Tab前端进化之路",
    "url": "https://www.infoq.cn/article/6605c7243876c79f0d3d13232",
    "summary": "<p>作者：马赟  阿里云钉钉业务平台团队</p><p></p><p></p><blockquote>技术人应当发挥对业务前瞻性的理解，好的架构设计背后一定是对于业务的高度认知与抽象，过程中要对业务关键指标有正确的理解，而不是简单纯功能的堆砌。</blockquote><p></p><p></p><p>钉钉新版协作Tab作为千万级访问量下前端新应用，从我主导前端迭代至今已经有大半年，面对大流量下的高性能和稳定性的压力、复杂前端交互的设计实现、前端技术视角结合业务的高可扩展性架构设计挑战，从0到1完成了三个大版本的迭代，联合客户端和小程序容器完成性能及稳定性方案落地、跨业务线承接了20多种卡片类型，提供了稳定体验的场域服务，同时在研发机制保障下做到全年0客诉和0回滚。</p><p></p><p>本篇将从产品能力升级背后的前端技术支撑和技术视角性能体验优化及稳定性建设两个方面讲述新版协作前端建设的过程。</p><p></p><p></p><h1>一、背景</h1><p></p><p></p><p>相比旧版本以应用为中心的钉钉协作Tab，新版本产品设计理念发生变化：组织管理与激发个体上下共生。协作以个人为中心，聚合与“我”有关的待办、审批、日程、文档等由钉钉各一、三方应用产生的事件，帮助用户更高效地处理与我有关的事件，获得更高效的协作体验，协作通过聚合用户的协作事件，帮助个人提效，进而提升组织效率。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4e/4e92a600010187f5282165fc3916fbdf.png\" /></p><p></p><p></p><h1>二、产品能力升级背后的前端技术支撑</h1><p></p><p></p><p>协作前端进化论：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fa/fa2ddc690b23d37a58a8c1a8019e45bd.png\" /></p><p>新版协作进化历程</p><p></p><p>before：旧版本</p><p>以应用为中心</p><p></p><p>after：协作新版</p><p>第一版，以时间为中心，强调顺序。</p><p>第二版本，以事件为中心，强调操作。</p><p>第三版，以人为中心，强调关系。呼应主题，工作版“今日头条”。</p><p></p><p>很多时候我们难以从产品最初想到完整产品终态，但是如果我们用产品本身的目标和用户价值反推产品的设计和技术实现的时候我们就可以做出相应的改变。</p><p></p><p></p><h2>2.1 协作前端主体架构设计之feeds流卡片动态化</h2><p></p><p></p><p>卡片第一版到第三版迭代建设过程中通过验证有效性及价值递增持续做出产品上的调整和优化。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ac/ac2dee1a3e5284ddaf50b6b9accc6dd7.png\" /></p><p></p><p></p><h3>前端设计实现上的思考</h3><p></p><p></p><p>在做第一版卡片实现的时候就和产品对过后续产品能力上的规划，卡片UI内容的新增删除这里都是更新频率比较高的，同时卡片的逻辑层面的功能也是需要不断建设，比如操作按钮、卡片点击事件、点击后的打开方式、卡片的删除置顶等功能等。在这个背景下我决定这样设计：将卡片频繁变更的UI层和不会变更的卡片功能逻辑层抽象出来分开建设，这样即能保证卡片功能持续建设的过程中不需要频繁变更，又能满足卡片UI持续迭代。</p><p></p><p>将卡片UI层进行布局维度的分层设计：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/03/0363831d6a5f75797273036573623053.png\" /></p><p>前端组件结构化事件卡片</p><p></p><p><code lang=\"text\">//卡片引用\n<div>\n  //卡片头部第一层 事项来源和事项时间\n \n//卡片内事项标题 事项描述\n \n//互动卡片SDK小程序插件引用条件渲染\n    \n// 卡片补充3C推荐内容\n    \n// ButtonList 卡片响应动作\n     \n//卡片折叠 递归引用 此处不需要UI变更\n\n    \n  \n</code></p><p></p><p>这样有个好处就是代码结构清晰直接可以从代码脑海构思出布局，无论卡片内容如何变化，我都可以通过调整对应的组件快速支持产品上做出的调整需求。</p><p></p><p>应用场景：目前钉钉内20+种通用化卡片展示场景支持。</p><p></p><p></p><h3>卡片操作逻辑层能力建设（以不变应万变）</h3><p></p><p></p><p>卡片内容操作：jsapi类型（发起Ding催办等） 跳转类型（半屏等卡片详情）。卡片本身操作：卡片删除、卡片置顶，卡片折叠展开。更新操作：点击操作卡片后的卡片内容更新，如日程接受后变成已完成。</p><p></p><p>这里需要注意的是卡片功能建设过程中业务结合代码的可扩展性，纵使卡片UI怎么调整，但是功能逻辑层是不需要变更。在协作应用的发起协同请求到协同结束的整个过程中，通过分角色分场景的信息设计，在协作流中通过发送消息或沉淀信息的方式，在关键协同节点向用户提供最有价值的协同信息。</p><p></p><p>删除、更新、置顶等场景下 配合小程序 $spliceData 前端本地列表无感更新</p><p></p><p><code lang=\"text\">modifyFeedFlowsCommon(\n  flowId: string,\n  type: string,\n  targetName: string,\n  feedFlows: IComponentInfo[],\n  newFeed?: IComponentData\n) {\n  // step1 找到对应卡片在协作卡片或子卡片（折叠卡片）中的index\n  const feedFlowsIndex = this.findFeedFlowsIndex(flowId, feedFlows);\n  // step2 通过小程序提供的$spliceData函数进行局部更新\n  if (feedFlowsIndex) {\n    this.modifyData(targetName, type, feedFlows, feedFlowsIndex, newFeed);\n  }\n},\n \nmodifyData(\n  targetName: string,\n  type: string,\n  feedFlows: IComponentInfo[],\n  feedFlowsIndex: IFeedFlowIndex,\n  newFeed?: IComponentData\n) {\n  // 分发操作事件，局部更新\n    this.$spliceData({\n            [targetName]: [parentIndex, 1, newFeedItem],\n          });\n  }\n},</code></p><p></p><p></p><h2>2.2 协作场域互动卡片SDK能力集成</h2><p></p><p></p><p>为什么要集成互动卡片：这里可以参考协作服务端架构设计的推拉模式，假设我们想要将更多和用户有关的复杂场景都流入到协作里，并且保证同样的卡片在其他地方也能同时投放，互动卡片是必然的。</p><p></p><p>协作中有两种卡片类型，第一种是上述的标准业务卡片，第二种是可以支持钉钉跨场域投放的互动卡片。</p><p></p><p>钉钉标准互动卡片是钉钉通用的卡片类型，会针对不同的投放场景进行能力与样式的自适应，确保同一个卡片模板在聊天消息、群聊吊顶、协作、工作台等场景中拥有一致的使用体验。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/54/542b6ad84585b77a264726f7a9bc6932.png\" /></p><p>钉钉互动卡片搭建链路+投放链路示意</p><p></p><p></p><h3>互动卡片在协作中的应用方案-业务套壳互动卡片</h3><p></p><p></p><p>卡片本身由两部分组成：数据+模板。数据依靠同步协议来实现动态更新，而模板则是通过小程序包的动态下发和更新机制来实现动态更新的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/54/54fa231eda5b3197d661f9c362763849.png\" /></p><p></p><p>协作内部实现以及协作业务场景的特殊性数据差异：卡片数据由两部分组成，业务本身提供的数据源如上图中的事项标题及事项描述，和协作自己的数据源3C推荐理由以事项来源和时间。</p><p></p><p>在这个差异基础上我们采用业务卡片嵌入互动卡片的形式进行渲染，我称之它为业务套壳互动卡片，这样在满足业务场景的同时能够将互动卡片的内容最大程度的多场域化应用。</p><p></p><p>内部实现第一步加载小程序小程序包，这体现在当客户端在加载一个卡片模板时，本质上它是在加载一个小程序包，小程序包里面则包含了卡片模板资源。</p><p></p><p><code lang=\"text\">// 互动卡片插件初始化\n    initCard() {\n      try {\n        if (dd &amp;&amp; dd.loadPlugin) {\n          dd.loadPlugin({\n            plugin: '5000000002721132@*',\n            success: (res: any) =&gt; {\n              this.setData({ isReady: true });\n            },\n            fail: (err: any) =&gt; {\n              logErrorUser('插件加载失败',JSON.stringify(err))   \n            },\n          });\n          app.globalData.hasInitCard = true;\n        } else {\n          logApiError('dd.loadPlugin', Date.now(), {}, 'dd.loadPlugin load fail', 'jaspi')\n        }\n      } catch(e) {\n        logApiError('initCard fail', e);\n      }\n    },</code></p><p></p><p>第二步小程序插件引用卡片SDK</p><p></p><p><code lang=\"text\">    \n    </code></p><p></p><p></p><h3>卡片 多场域投放埋点问题解决</h3><p></p><p></p><p>同一张互动卡片投放在不同的场域，如何实现区分？</p><p></p><p>卡片组件 context 增加 trackingRuleModel 入参。在渲染过程中透传这个参数。</p><p></p><p>有没有一种可能协作只作为一个场域，你看到的协作feeds流完全由互动卡片来承接？可以。</p><p></p><p>互动卡片在协作中的应用</p><p></p><p>番茄表单、云上管车等ISV应用，与正常卡片融为一体，浑然天成，毫无违和感。未来更多的一方二方三方互动卡片都可以流入到协作中。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2a/2ae0ff9085ba469623dfa86ca3d29be8.png\" /></p><p>番茄表单互动卡片在协作流</p><p></p><p></p><h2>2.3 算法推荐序接入</h2><p></p><p></p><p></p><h3>为什么要接入算法</h3><p></p><p></p><p>利用钉钉现有的数据中台和算法团队的协同关系模型对用户提供个人视角下的高价值事件处理卡片。呼应协作业务的目标，提升点击率，也就是验证协作对用户越来越有用。</p><p></p><p></p><h3>协同关系模型接入方案架构设计</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e2/e26f0e9a9b9e1ac0533908d06b7e2b33.png\" /></p><p>协作前端算法推荐序链路设计</p><p></p><p></p><h3>前端设计实现</h3><p></p><p></p><p>推荐序列表由两段组成，待处理和其他，在有了上面讲过的卡片模型设计实现后，本质上对前端来说这里的工作量只是对推荐序列表的拼接，UI层和逻辑层所有交互均已被覆盖。</p><p></p><p>待处理（重要内容）：对用户强相关的处理卡片，比如未完成的待办、三条后开始折叠。</p><p></p><p>其他（可能感兴趣的）：基于算法协同关系模型以及前端提供的行为埋点数据由算法中心统一产出，交互上跟随推荐序列表下拉加载。</p><p></p><p></p><h2>2.4 协作PC 跨端产品能力补齐</h2><p></p><p></p><p>为了填补协作在桌面端的体验空缺。依赖多端协同的应用，如文档，需要协作支持桌面端后才有可能将应用的协同消息从应用内迁移到协作。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a2/a2a43fa6356c80af6b81eab5549c1914.png\" /></p><p>协作PC端</p><p></p><p>本篇重点讲述协作移动端建设过程，PC端的前端设计方案实现这里先不做陈述。</p><p></p><p></p><h2>2.5 数据运营能力建设</h2><p></p><p></p><p></p><h3>APN统一推送能力建设</h3><p></p><p></p><p>应用场景举例：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f5/f5102d7c5a3b760ddbe736aec3ef905e.png\" /></p><p>APN推送钉钉年度报告承接</p><p></p><p>在接到需求的第一时间建设了通用的APN推送链路方案：利用channel建立客户端到前端的通信通道，在客户端对钉钉统一跳转协议的监听下推送给前端跳转的来源信息，同时前端通过订阅的监听事件做相关的业务逻辑操作。</p><p></p><p><code lang=\"text\">import { getChannel } from '@ali/dingtalk-jsapi/plugin/uniEvent';\n​\nexport function ddSubscribe(\n  channelName: string,\n  eventName: string,\n  handler: (data: any) =&gt; void,\n  useCache = true,\n) {\n  try {\n      const channel = getChannel(channelName);\n      channel.subscribe(eventName, handler, { useCache });\n  } catch (e) {\n      logApiError('ddSubscribe fail',safeJson(e));\n  }\n}\n// 客户端开启订阅统一跳转协议监听事件，并建立两端通道\nddSubscribe('channel.jumpAction.switchtab', 'cooperate_cooperate', (data) =&gt; {\n        if(data?.data.from==='nianzong'){\n          sendUT('Page_Work_New_Year_Summary');\n          openLink$({url:yearSummaryUrl||'https://page.dingtalk.com/wow/dingtalk/default/dingtalk/yearsummary?dd_nav_translucent=true&amp;wtid=yearsummary__xiezuo'})\n        }\n       \n      });</code></p><p></p><p></p><h3>协作顶部应用区</h3><p></p><p></p><p>应用区为什么要折叠</p><p></p><p>受全局切换组织、应用快捷入口吸顶、信息流工具栏吸顶等多个原因影响，协作信息流自身的内容展示区域，不足整体页面高度的1/2，新版的信息卡片，增加信息量的同时也增加了卡片高度，所以要用折叠方式将屏效比提高。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/94/94accf9fe4096b1fe06f648b36dab926.png\" /></p><p></p><p>应用区展示逻辑：纯前端实现，此处无服务端交互</p><p></p><p>联动设置页的拖拽自定义顺序展示。每个入口均由一个灰度key统一控制在协作中的展示，同时针对专属钉大客户定制降噪对应用入口进行过滤。展示前通过客户端JSAPI进行红点数量设置。</p><p></p><p><code lang=\"text\">//灰度key获取到联动降噪红点设置统一管理\nexport const getGrayValueFromCacheByKeys = async (keys: KeysType[] = []) =&gt; {\n  const result: any[] = [];\n  const promiseAllArr: Array&gt; = [];\n  const promiseAllArrKeys: KeysType[] = [];\n  keys.forEach((key) =&gt; {\n    if (cacheGrays[key]) {\n      result.push(cacheGrays[key]);\n      return;\n    }\n    const defaultGrayKeysConfig = allGrayKeys[key];\n    if (!defaultGrayKeysConfig) {\n      result.push(true);\n      return;\n    }\n    if (!defaultGrayKeysConfig) {\n      result.push(!!defaultGrayKeysConfig);\n      return;\n    }\n    promiseAllArrKeys.push(key);\n    promiseAllArr.push(grayLemonFnFactory(...defaultGrayKeysConfig)());\n  });\n  const promiseResult = await Promise.all(promiseAllArr);\n  promiseAllArrKeys.forEach((key: KeysType, i: number) =&gt; {\n    cacheGrays[key] = promiseResult[i];\n  });\n  return cacheGrays;\n};</code></p><p></p><p>以上是产品能力建设过程中的前端主要实现及策略，还有很多细节功能比如卡片自动定位到当前时间最近的事件卡片项、同步推送协议以及列表无感刷新等功能这里就不再赘述。</p><p></p><p></p><h1>三、前端技术视角性能体验优化及稳定性建设</h1><p></p><p></p><p>性能体验是前端绕不开的话题，我坚持认为这件事不是等项目做完再做优化，而是在业务迭代过程中将它落地。</p><p></p><p></p><h2>3.1 性能建设</h2><p></p><p></p><p>就协作小程序的完整启动链路图如下，我们在哪些关键节点能做哪些事呢？</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/82/82f528815f22dbbecc5c45ab3da29ad4.png\" /></p><p>协作小程序启动链路图</p><p></p><p></p><h3>常见性能问题规避</h3><p></p><p></p><p>白屏时间太长：</p><p>首屏出来前长时间白屏，用户体感较差。</p><p></p><p>大量原生API调用：</p><p>通过IDE AppLog面板，发现存在大量的原生JSAPI调用，其实很多是非首屏依赖的，而且JSAPI调用的性能损耗在不同机型下表现不一，尤其对低端机影响较大。</p><p></p><p>包体积过大：</p><p>包体积过大，一方面消耗JS初始化执行时间，另一方面还可能会存在不必要的原生API调用，更加拖累首屏性能。</p><p></p><p></p><h3>协作移动端性能体验建设大图</h3><p></p><p></p><p>以下内容全程高能，以后前端项目就这么做。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/66/664f07ccadbfe8075f727fde5e3bc1ac.png\" /></p><p>协作性能建设大图</p><p></p><p></p><h3>策略：联合客户端容器、小程序本身实施用户视角端到端的性能策略和稳定性建设</h3><p></p><p></p><p>案例1：首屏渲染体验优化-优化策略包和效果</p><p></p><p>优化静态资源：</p><p>类似常规的web玩法，主要就是图片懒加载、压缩质量，属于投入产出比非常高的手段。</p><p></p><p>降低包体积：</p><p>降低包体积不但可以减少js上下文的初始化耗时，还能减少冗余的API调用。</p><p></p><p>渲染原理：</p><p>大量的setData是拖累性能的主要原因之一，理想情况应该把从小程序启动到首屏渲染完毕之间的setData控制在一次。要做到这一点会有一些挑战，减少不合理的模块re-render，减少setData的数据内容，比如协作单张卡片操作后局部更新，而不是更新整个列表。</p><p></p><p>考虑动态插件：</p><p>对于非首屏的、功能独立&amp;复杂、又无法拆到分包的模块，可以考虑将逻辑拆到小程序插件里，按需加载。</p><p></p><p>案例2：首屏渲染体验优化 - 钉钉客户端lwp预取接入</p><p></p><p>谋定而后动</p><p></p><p>协作没有定位服务等的前置依赖，所以可以前置请求，特别适合接入lwp预取。</p><p></p><p>绝大部分小程序的启动流程，都会经历如下环节：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5e/5e8c7dc57f241ce165c58a6892f0eac9.png\" /></p><p></p><p>整体过程是串行的，其中请求首页数据往往和用户的网络环境，服务端的性能有较大关系。串行的流程并行化是一个很常见的性能优化思路，请求首页数据这一步，往往是传一些参数给服务端，获取到数据用来渲染 UI。我们可以抽象出一些规则，在业务的JS开始执行前，并行加载首页数据。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cb/cb5e5d0205590948ece180e4ba0519db.png\" /></p><p></p><p>根据历史线上数据，小程序的容器启动到业务JS开始执行，一般需要1s左右，而钉钉的LWP请求，平均执行时间在300ms左右。这意味着在容器启动阶段，就可以执行3次LWP请求，这段时间是被白白浪费了。</p><p></p><p>钉钉lwp预取 客户端、服务端、前端全链路方案</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/61/616314c90b0e84e48d9b32d6f792714d.png\" /></p><p></p><p>业务接入</p><p></p><p>通过getBackgroundFetchData开启客户端通信通道按需读取数据：</p><p></p><p><code lang=\"text\">dd.getBackgroundFetchData({\n  type: \"lwp\",\n  wait: true,\n  success(res) {\n    console.log(res.fetchedData); // 缓存数据\n    console.log(res.timeStamp); // 客户端拿到缓存数据的时间戳\n    console.log(res.path); // 页面路径\n    console.log(res.query); // query 参数\n    console.log(res.scene); // 场景值\n  }\n});\n//调用时可以传入 wait 参数，表示是否等待预加载结果。如果为 true，会等待预加载任务完成后收到回调。</code></p><p></p><p>结果数据：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cd/cd0a5dd5473e4c48ed8cf3bdfb98204e.png\" /></p><p></p><p>可以看到iOS设备由于本身性能较好，减少的时间有限，但是在Android上的提升效果很明显。</p><p></p><p>钉钉App杀进程的冷启动，协作整个小程序被容器劫持，也就是常驻内存的保活。接入预取后，除了小程序容器UC内核启动的时间外，基本上做到了首屏直出。</p><p></p><p></p><h2>3.2 稳定性建设</h2><p></p><p></p><p></p><h3>案例：钉钉lwpcache无网弱网体验升级</h3><p></p><p></p><p>协作作为一个大流量入口据数据显示每天有3k+的弱网用户访问量，接入离线方案是改善用户体验的必取之路。</p><p></p><p>缓存策略：首屏数据直出，后续迭代，将缓存获取时机从首页onload提前到App onLaunch，能够减少数十到上百毫秒的间隔，是比较常见的手段，但是对降低业务耗时最为直接有效，另一方面从体感上来说确实会更快。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f0/f06370950da0794ece80b9fde3657441.png\" /></p><p>钉钉lwp-cache客户端缓存方案链路流程图</p><p></p><p>框架容器层面也有小程序快照方案-协作设置页接入，不过也并非所有场景都适用先展示缓存。</p><p></p><p>离线策略：</p><p>利用客户端lwp cache能力配合LocalStroage进行上一次请求的缓存数据的离线获取。在前端页面将依赖网络请求的资源图片和功能进行降级。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f6/f625eb9142507d035badbd940b9e547f.png\" /></p><p>优化前后对比</p><p></p><p>关于稳定性，协作前端还做了全功能的降级体验，如服务端接口异常的重试页、数据为空的降级展示、jsapi失败后的重试机制等全方位保障系统的高可用性和稳定性。</p><p></p><p></p><h1>四、前端视角下的业务思考</h1><p></p><p></p><p>做业务要为最终结果负责，而前端角色从技术/产品思维到业务思维的一跃有很多天然的瓶颈与鸿沟，技术人应当发挥对业务前瞻性的理解，好的架构设计背后一定是对于业务的高度认知与抽象，过程中要对业务关键指标有正确的理解，而不是简单纯功能的堆砌。</p><p></p><p>过度的产品化执念导致容易陷入细节；缺少与业务方长时间高频度的互动，对商业模式的理解、数据的敏感度不足；</p><p></p><p>从产品/技术思维到业务思维的转变，可以尝试从以下几个方面来培养：</p><p></p><p>1）培养对目标与数字的敏感度，尝试收集并形成自己的订阅报表，定期 Review，多追问指标升降背后的原因。</p><p></p><p>2）加强与业务方互动，多从业务目标视角看待每个需求，使用STAR法则梳理关联关系，多问几个为什么。</p><p></p><p>3）尝试结合掌握的信息去做公式拆解与沙盘推演，例如App DAU = (MAU * 月均访问频次)/30 +日均拉新，目前的现状每个指标分别在什么量级，每个需求又分别服务于哪个指标，能够提升多少，提升后是否能推导出目标达成，拆解事项并梳理优先级。</p><p></p><p>4）抛下过于超前的产品执念，避免陷入细节，以产出最小可行产品（MVP）为原则快速试错与迭代，区分好「锦上添花」与「雪中送碳」。</p><p></p><p></p><h1>五、结束语</h1><p></p><p></p><p>用户越来越深入地使用钉钉，产生了越来越多的协同“事件”。</p><p></p><p>「协作」通过高效的推荐和筛选机制，帮助用户更好地管理、更轻松地处理每日纷繁的“事件”。</p><p></p><p>「协作」有机会成为用户处理“事件”的第一入口，让用户更轻松地完成工作。目前正在积累基础能力，已经有二十多个协同场景接入「协作」，每日用户通过协作处理的任务数接近 200 万个。</p><p></p><p>长期价值是，入口更便捷、场景更丰富、推荐更精准、操作更简单。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8c/8cf92acea47d14dda7829b22300a92b6.png\" /></p><p></p>",
    "publish_time": "2023-03-30 10:38:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]