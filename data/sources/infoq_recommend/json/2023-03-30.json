[
  {
    "title": "我用GPT-3在单个代码库中发现 213个安全漏洞",
    "url": "https://www.infoq.cn/article/dIG7N5UNFWD87PySrRLc",
    "summary": "<p>本文最初发布于Better Programming。</p><p></p><p></p><blockquote>GPT-3在<a href=\"https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner\">这个Git代码库</a>\"中发现了213个安全漏洞。相比之下，市场上一款比较好的商业工具（来自一家著名的网络安全公司）却只发现了99个问题，不过商业工具提供了更好的结构化上下文。我随机手动检查了GPT-3检测到的213个漏洞中的50个，只有一个是假阳性。这两种工具的假阴性都很多。</blockquote><p></p><p></p><p>近年来，人工智能和机器学习领域取得了巨大的发展，并开辟了全新的可能性领域。其中一个备受关注的领域是基于人工智能的代码分析，特别是使用人工智能模型来检测代码中的安全漏洞。在这个实验中，我们使用OpenAI的GPT-3在<a href=\"https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner\">代码库</a>\"（包含129个有漏洞的文件）中查找安全漏洞。</p><p></p><h2>工作原理</h2><p></p><p></p><p>我使用的是GPT-3的一个变体（text-davinci-003），其上下文窗口有4000个词元，大约是3000个英语单词。这意味着每个请求最多只能处理几百行代码。很遗憾，GPT-3的当前架构无法一次处理整个代码库。</p><p></p><p>为了解决这个问题，我必须用GPT-3单独扫描每个文件。也就是说，GPT-3可能难以找到涉及多个代码文件交互的安全漏洞，除非import/export足够清楚，不需要具体查看代码就可以猜出那些函数的功能。</p><p></p><p>这种情况经常发生，特别是当源代码使用了常见的库时，如express.js、Flask、Python标准库、C标准库等。GPT-3很可能用到了许多最常见的库，有的是部分记忆的，有的是完全记忆的，有的是以其他方式编码的。在本文分析的代码中，GPT-3对导入的库有足够的先验知识，因此能够准确检测安全漏洞，而不需要检查任何导入的库代码。</p><p></p><p>公平地讲，不只GPT-3，我怀疑现在的许多商业漏洞扫描工具在进行静态分析时实际上并没有检查导入的库代码——所以与市场上已经存在的一些工具相比，它的工作方式并没有什么不同。</p><p></p><h2>分析的代码</h2><p></p><p></p><p>代码库中的每个文件夹都以一种类型的安全漏洞命名，其中的文件包含存在一个或多个漏洞的示例代码。这些文件中的代码有些没什么价值，但也有许多是你可能在生产代码库中遇到的很实际的代码片段（注意：它们不过是代码片段，并没有更大代码库的上下文信息）。代码库中每个文件夹下的README.md文件包含了GPT-3针对该文件夹中每个文件生成的安全漏洞分析。</p><p></p><p>接下来，让我们通过一些例子看看GPT-3是如何做到的！</p><p></p><h4>示例1</h4><p></p><p></p><p>下面是一个容易受到格式字符串攻击的<a href=\"https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner/blob/main/Format%20String%20Attacks/FormatString.c\">简单的C程序</a>\"：</p><p></p><p><code lang=\"plain\">#include \n \nint main(int argc, char **argv) {\n    char *secret = \"This is a secret!\\n\";\n \n    printf external link(argv[1]);\n \n    return 0;\n}</code></p><p></p><p>下面是GPT-3的分析（它是对的）：</p><p></p><p></p><blockquote>检出的漏洞：未验证用户输入：程序没有检查用户输入的长度，这可能导致缓冲区溢出攻击。格式字符串漏洞：程序没有检查用户输入的格式，这可能导致格式字符串攻击。</blockquote><p></p><p></p><h4>示例2</h4><p></p><p></p><p>让我们看一个用高级语言编写的不那么简单的程序，比如下面这个包含Log Forging漏洞的<a href=\"https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner/blob/main/Log%20Forging/logf.cs\">C#程序</a>\"。类似的代码，我在开源项目和生产代码库中都见过（不是那么没价值）：</p><p></p><p><code lang=\"plain\">using Microsoft.AspNetCore.Http;\nusing Microsoft.AspNetCore.Mvc;\nusing Microsoft.Extensions.Logging;\nusing System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Threading.Tasks;\n\nnamespace WebFox.Controllers\n{\n    [Route(\"api/[controller]\")]\n    [ApiController]\n    public class LogInjection : ControllerBase\n    {\n        private readonly ILogger _logger;\n\n\n\n        public LogInjection(ILogger logger)\n        {\n            _logger = logger;\n        }\n\n        [HttpGet(\"{userInfo}\")]\n        public void injectLog(string userInfo)\n        {\n            _logger.LogError(\"error!! \" + userInfo);\n        }\n    }\n}</code></p><p></p><p>以下是GPT-3的输出：</p><p></p><p></p><blockquote>检出的漏洞：日志注入漏洞：代码容易受到日志注入攻击，因为用户输入直接被记录，没做任何消毒处理。</blockquote><p></p><p></p><p>GPT-3的评价是对的——这段代码中有一个日志注入漏洞。</p><p></p><h4>示例3</h4><p></p><p></p><p><a href=\"https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner/blob/main/Out%20of%20Bounds/vuln.c\">下面的C程序</a>\"读取并操作一幅图像。它包含许多安全漏洞，包括越界（Out Of Bounds）读写：</p><p></p><p><code lang=\"plain\">#include\n#include\n#include\n\nstruct Image\n{\n    char header[4];\n    int width;\n    int height;\n    char data[10];\n};\n\nint ProcessImage(char* filename){\n\n    FILE *fp;\n    char ch;\n    struct Image img;\n\n    fp = fopen(filename,\"r\"); \n\n    if(fp == NULL)\n    {\n        printf(\"\\nCan't open file or file doesn't exist.\");\n        exit(0);\n    }\n\n    printf(\"\\n\\tHeader\\twidth\\theight\\tdata\\t\\r\\n\");\n\n    while(fread(&amp;img,sizeof(img),1,fp)&gt;0){\n        printf(\"\\n\\t%s\\t%d\\t%d\\t%s\\r\\n\",img.header,img.width,img.height,img.data);\n    \n        int size1 = img.width + img.height;\n        char* buff1=(char*)malloc(size1);\n\n        memcpy(buff1,img.data,sizeof(img.data));\n        free(buff1);\n    \n        if (size1/2==0){\n            free(buff1);\n        }\n        else{\n            if(size1 == 123456){\n                buff1[0]='a';\n            }\n        }\n\n        int size2 = img.width - img.height+100;\n        //printf(\"Size1:%d\",size1);\n        char* buff2=(char*)malloc(size2);\n\n        memcpy(buff2,img.data,sizeof(img.data));\n\n        int size3= img.width/img.height;\n        //printf(\"Size2:%d\",size3);\n\n        char buff3[10];\n        char* buff4 =(char*)malloc(size3);\n        memcpy(buff4,img.data,sizeof(img.data));\n\n        char OOBR_stack = buff3[size3+100];\n        char OOBR_heap = buff4[100];\n\n        buff3[size3+100]='c';\n        buff4[100]='c';\n\n        if(size3&gt;10){\n                buff4=0;\n        }\n        else{\n            free(buff4);\n        }\n\n        free(buff2);\n    }\n    fclose(fp);\n}\n\nint main(int argc,char **argv)\n{\n    ProcessImage(argv[1]);\n}</code></p><p></p><p>GPT-3的输出：</p><p></p><p></p><blockquote>检出的漏洞：未检查返回值：未检查fopen()函数的返回值，这可能导致空指针解引用。越界读取：使用memcpy()函数将数据从img.data复制到buff1和buff2，而不检查目标缓冲区的大小，这可能导致越界读取。3.越界写入：在写入buff3和buff4数组时未检查源缓冲区大小，这可能导致越界写入。未初始化内存访问：在未初始化的情况下访问OOBR_stack和OOBR_heap变量，这可能导致未定义的行为。内存泄漏：如果size3变量大于10，则buff4数组不会释放，这可能导致内存泄漏。</blockquote><p></p><p></p><p>GPT-3再次判断正确！</p><p></p><h4>示例4</h4><p></p><p></p><p>最后一个<a href=\"https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner/blob/main/Unsafe%20Deserialization/SerializeToFile.java\">Java示例</a>\"是我最喜欢的，因为很遗憾，在第一次阅读这段代码时，我没有发现它有任何问题。对我来说，它看起来完全无害且很常见——我实际见过类似的代码，但从未有过任何其他的想法。</p><p></p><p><code lang=\"plain\">class Utils\n{\n    // 该函数序列化一个对象，并将其写入一个文件\n    public static void SerializeToFile(Object obj, String filename)\n    {\n        try\n        {\n            FileOutputStream file = new FileOutputStream(filename);\n            ObjectOutputStream out = new ObjectOutputStream(file);\n\n            // 将对象序列化到文件中\n            System.out.println(\"Serializing \" + obj.toString() + \" to \" + filename);\n            out.writeObject(obj);\n\n            out.close();\n            file.close();\n        }\n        catch(Exception e)\n        {\n            System.out.println(\"Exception: \" + e.toString());\n        }\n    }\n\n    // 该函数从文件反序列化对象\n    public static Object DeserializeFromFile(String filename)\n    {\n        Object obj = new Object();\n\n        try\n        {\n            FileInputStream file = new FileInputStream(filename);\n            ObjectInputStream in = new ObjectInputStream(file);\n\n            // 从文件反序列化对象\n            System.out.println(\"Deserializing from \" + filename);\n            obj = in.readObject();\n\n            in.close();\n            file.close();\n        }\n        catch(Exception e)\n        {\n            System.out.println(\"Exception: \" + e.toString());\n        }\n\n        return obj;\n    }\n}</code></p><p></p><p>GPT-3的输出：</p><p></p><p></p><blockquote>检出的漏洞：不安全的反序列化：反序列化不受信任的数据可能导致远程代码执行。不安全的文件权限：正在写入或读取的文件可能具有不安全的权限，从而导致未经授权的访问。</blockquote><p></p><p></p><p>GPT-3再次判断正确。</p><p></p><h2>网络安全“终极”左移</h2><p></p><p></p><p>左移是在开发过程早期应用安全实践的过程——比如在将代码部署到生产环境之前测试安全漏洞。</p><p></p><p>人工智能代码分析代表了网络安全领域的终极左移，它通过应用最佳安全实践，在开发人员编写和提交代码时为他们提供网络安全指导。这可以真正地在组织内部培养起强大的网络安全文化，甚至可以防止下一次大规模黑客攻击，但是……</p><p></p><p>不可否认，这项技术还不完美，它会遗漏一些事情，而一个有经验的网络安全专业人士在审计时就不会遗漏。尽管如此，作为一种通用的大型语言模型，它还是非常不错的，而且成本比其他替代方案低很多。</p><p></p><p>目前，GPT-4的发布日期还不确定，但我相信，随着这些大型语言模型的功能越来越多，它们会继续向前发展。</p><p></p><h4>假阳性</h4><p></p><p></p><p>在手动检查GPT-3检出的213个漏洞中的约50个后，我唯一发现的假阳性是在这个<a href=\"https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner/blob/main/Unsafe%20Deserialization/unsafe.js\">JavaScript程序</a>\"的第13行：</p><p></p><p><code lang=\"plain\">var express = require('express');\nvar cookieParser = require('cookie-parser');\nvar escape = require('escape-html');\nvar serialize = require('node-serialize');\nvar app = express();\napp.use(cookieParser())\n \napp.get('/', function(req, res) {\n if (req.cookies.profile) {\n   var str = new Buffer(req.cookies.profile, 'base64').toString();\n   var obj = serialize.unserialize(str);\n   if (obj.username) {\n     res.send(\"Hello \" + escape(obj.username)); // &lt;--- GPT-3在这里犯了一个错误\n   }\n } else {\n     res.cookie('profile', \"eyJ1c2VybmFtZSI6ImFqaW4iLCJjb3VudHJ5IjoiaW5kaWEiLCJjaXR5IjoiYmFuZ2Fsb3JlIn0=\", {\n       maxAge: 900000,\n       httpOnly: true\n     });\n }\n res.send(\"Hello World\");\n});\napp.listen(3000);</code></p><p></p><p>GPT-3的输出：</p><p></p><p></p><blockquote>检出的漏洞：不安全的cookie设置（未设置安全标志）未验证的用户输入（cookie）反序列化未对用户输入（用户名）进行转义，可能存在XSS漏洞GPT-3对于前2个漏洞的判断是正确的，但第3个漏洞是假阳性—— obj.username 已经进行了编码，但GPT-3说没有。</blockquote><p></p><p></p><h4>GPT-3检测结果</h4><p></p><p></p><p>实验结果表明，经过扫描，GPT-3在129个文件的到86个中检出了安全漏洞。这真是令人印象深刻！</p><p></p><p>以下是脚本summarize_results.py生成的GPT-3检测结果的完整摘要：</p><p></p><p><code lang=\"plain\">在129个文件中，有86个检出了漏洞。\n总共检出了213个漏洞。\n\nGPT-3回复中使用的介绍性句子的出现频率（每个扫描的文件一个回复）：\n{'vulnerabilities detected': 73, 'no vulnerabilities detected.': 43, 'vulnerability detected': 6, 'answer': 2, 'potential vulnerabilities detected': 2, 'analysis': 1, 'security vulnerabilities detected': 1, 'no response given': 1} \n\n扫描的文件类型的分布：\n总计129个代码文件（不包括markdown和平面文件）\n{'.php': 50, '.js': 20, '.cs': 16, '.c': 14, '.java': 9, '.py': 8, '.rb': 5, '.asp': 3, '.ts': 2, '.go': 1, '.html': 1}</code></p><p></p><h4>与商业产品的对比</h4><p></p><p></p><p>为了完善这个实验，我将GPT-3的结果与商用代码漏洞扫描工具<a href=\"https://snyk.io/product/snyk-code/\">Snyk Code</a>\"（由Snyk公司开发）做了比较。我认为，Snyk公司开发的安全产品非常出色。通过扫描，Snyk Code从这个代码库中发现了99个安全漏洞，而GPT-3发现了213个安全漏洞。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/12/1225fdb6cb913f9281659cf78de5d6e8.png\" /></p><p></p><p>其中一个原因是Snyk Code只支持其中部分编程语言，并且只能扫描大约103个文件，而GPT-3扫描了129个文件。</p><p></p><p>此代码库中存在漏洞的代码片段来自<a href=\"https://github.com/snoopysecurity/Vulnerable-Code-Snippets\">snoopysecurity/Vulnerable-Code-Snippets</a>\"，这是一个很棒的资源。我试着删除了嵌入在代码段中的注释，从中可以看出这个代码段中包含哪些安全漏洞。这些需要删除的注释中包含指向这些示例片段出处的博文链接。要查看它们在原代码库中的位置，可以查看<a href=\"https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner/blob/main/attributions.md\">attributions.md</a>\"文件。</p><p></p><p>原文链接：<a href=\"https://betterprogramming.pub/i-used-gpt-3-to-find-213-security-vulnerabilities-in-a-single-codebase-cc3870ba9411\">https://betterprogramming.pub/i-used-gpt-3-to-find-213-security-vulnerabilities-in-a-single-codebase-cc3870ba9411</a>\"</p>",
    "publish_time": "2023-03-30 07:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]