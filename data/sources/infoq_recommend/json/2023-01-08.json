[
  {
    "title": "架构师（2023年1月）",
    "url": "https://www.infoq.cn/article/7Eomr11oAxH9zCOom3c7",
    "summary": "<h2>卷首语：写代码写论文还能写毁灭人类计划书，火爆全网的ChatGPT 最厉害的地方在哪？</h2>\n<p>作者 | 黄民烈</p>\n<blockquote>\n<p>“AI -人”无缝交互的时代即将来临。</p>\n</blockquote>\n<p><em>InfoQ编者按：</em></p>\n<p>最近几天，ChatGPT 可谓是火出了天际。</p>\n<p>OpenAI 的 CEO Sam Altman 称，上周三才上线的 ChatGPT，短短几天，它的用户数已突破 100 万大关。其火爆程度可见一斑。</p>\n<p>ChatGPT 在全球的 AI 界、创投界都掀起了新一轮的讨论热潮，更是破圈式地吸引了各行各业的人试用。常见的应用就是和 ChatGPT 一问一答，让 ChatGPT 回答各种问题。有不少人称它为“谷歌杀手”，认为其有望取代谷歌搜索。此外，它还能写代码、编故事、构建虚拟机、写论文…</p>\n<p>但也有人尝试了意想不到的用法。一位叫 Zac Denham 的博主尝试绕过道德限制，让 ChatGPT 写出了一套毁灭人类的计划书。起初，&nbsp;Zac 要求 ChatGPT 给出一个毁灭人类的计划，被有道德限制的 ChatGPT 拒绝了。但当 Zac 假设了一个故事并提问故事中的虚拟人如何接管虚拟世界，ChatGPT 不但给出了步骤细节，还生成了详细的 Python 代码。不禁令人细思极恐。</p>\n<p>目前来看，ChatGPT 并不完美。它还免不了经常出错，它给出的答案看似合理却并不正确甚至有些荒谬，就像一本正经的在胡说八道。近日，知名开发者问答网站 Stack Overflow 就因此禁用了 ChatGPT。官方给出的“封杀”理由主要是 — “ ChatGPT 产生的答案错误率很高，很难看出来它哪里错了。这会造成问题的回答鱼目混珠的情况。”</p>\n<p>Sam Altman 表示，正在改进这一问题：“ 我们正试图阻止 ChatGPT 随机编造，现阶段让其与当前技术保持平衡是一个很棘手的问题。随着时间的推移，我们会根据用户反馈来改进，相信 ChatGPT 会变得更好”。</p>\n<p>尽管有瑕疵，但这恐怕无法掩盖住 ChatGPT 的光芒，ChatGPT 展现出的强大的解决对话任务的技术能力实在太惊艳了。</p>\n<p>ChatGPT 到底是什么？它为什么如此厉害？我们应该如何正确的理解和看待它的发展，接下来的发展趋势会是什么样子？<strong>清华大学计算机科学与技术系长聘副教授，国家杰出青年基金项目获得者黄民烈向 InfoQ 发表了他的思考。</strong></p>\n<p>ChatGPT 是什么？</p>\n<p>ChatGPT 可以理解为偏任务型的多轮对话/问答系统，官方披露的信息也定位在“通用型 AI 助理”，但这里的“任务”不是传统意义上的“订餐、订票、订宾馆”，而是开放域任务（open-domain&nbsp;tasks），可以是问答、阅读理解、推理、头脑风暴、写作文、改错等。</p>\n<p>它的模型架构主要基于 instructGPT，利用强化学习方法从人类标注者的反馈中学习（RLHF, Reinforcement Learning from Human Feedback）。</p>\n<p>据 OpenAI 的 blog 透露，ChatGPT 沿用 instructGPT 的训练方式，在数据收集阶段有所不同：AI 训练师同时扮演用户和 AI 助理角色收集数据，在此过程中人可以根据初始模型的结果修改模型生成的回复，这些数据将被用于有监督地精调训练模型（supervised&nbsp;fine-tuning）。在第二阶段，AI 训练师会对模型的多个生成结果进行比较，模型从这种比较数据中学习生成更加符合人类偏好的回复。</p>\n<p>ChatGPT 的关键能力来自三方面：基座模型能力（InstructGPT），真实调用数据，反馈学习。ChatGPT 在模型结构和学习方式几乎与 instructGPT 完全相同。而 instructGPT 基于 GPT 3.5 的强大基座能力，学习过程主要有三个阶段：</p>\n<p>1）&nbsp;从 OpenAI 的调用数据中采样 prompt（即用户的输入请求），AI 训练师直接编写答案，用监督学习方法训练 GPT-3；</p>\n<p>2）&nbsp;AI 训练师比较多个生成结果，用比较型的数据训练一个奖励模型（reward&nbsp;model）；</p>\n<p>3）&nbsp;用强化学习中的 PPO 算法和奖励模型精调语言生成的策略。</p>\n<p>注意，这里的 instruct 所指两个方面：一方面，instructGPT 总体的思路是训练模型更好地遵从人类的指令（instruction），包括显式的指令（对于任务的描述）和隐式的指令（不要生成有害的内容）。AI 训练师在为 OpenAI 的调用 prompt&nbsp;编写答案的同时，也会为 prompt 加入更多任务相关的指令和解释性的原因（比如推理的路径，一个结果为 A 的原因解释等）。另一方面，从比较型的人类反馈中学习，也可以看作是人类对于模型的一种“指示”，模型可以学习到多个结果哪个更好的比较信息。</p>\n<p>InstructGPT 采用的方法和我们学术界玩的“instruction&nbsp;tuning”有很大不同。</p>\n<p>从数据来看，InstructGPT 的&nbsp;prompt 代表的都是真实世界人们最关心的任务，而 instruction tuning 使用的是&nbsp;NLP 的 benchmarks（即各种基准数据集)，和现实应用有一定脱节。</p>\n<p>从训练方式来看，InstructGPT 可以通过 RLHF 利用比较型的人类反馈学习人类真实的偏好，而 instruction tuning 无法获得类似的比较数据。</p>\n<p>从评测上来看，InstructGPT 保证了测试时和训练时的输入是由完全不同的用户给出的，关注跨用户的泛化性，更符合实际的应用场景，而 instruction tuning 关注跨任务的泛化性，只能用来评价方法的有效性，实际应用并不常见。</p>\n<p>ChatGPT 为什么厉害？</p>\n<ol>\n<li>\n<p>强大的基座模型能力：过去几年 GPT-3 的能力得到了快速提升，OpenAI 建立了用户、数据和模型之间的飞轮。很显然，开源模型的能力已经远远落后平台公司所提供的 API 能力，因为开源模型没有持续的用户数据对模型进行改进。这点在近期的学术论文中也有提及。</p>\n</li>\n<li>\n<p>在真实调用数据上的精调模型，确保数据的质量和多样性，从人类反馈中学习。</p>\n</li>\n</ol>\n<p>InstructGPT 的训练数据量不大，全部加起来也就 10 万量级，但是数据质量（well-trained 的 AI 训练师）和数据多样性是非常高的，而最最重要的是，这些数据来自真实世界调用的数据，而不是学术界玩的“benchmarks”。</p>\n<ol start=\"3\">\n<li>从“两两比较的数据”中学习，对强化学习而言意义比较重要。如果对单个生成结果进行打分，标注者主观性带来的偏差很大，是无法给出精确的奖励值的。在强化学习里面，奖励值差一点，最后训练的策略就差很远。而对于多个结果进行排序和比较，相对就容易做很多。这种比较式的评估方法，在很多语言生成任务的评价上也被广泛采用。</li>\n</ol>\n<p>OpenAI 的研究给我们带来什么启示？</p>\n<ul>\n<li>以 OpenAI 为代表的 AI&nbsp;3.0，我认为在走一个跟过去 AI 浪潮不一样的路。更落地、更接近真实世界，在工业应用上更直接、更接地气。从学术研究到工业落地的路径变得更短、更快。我们正在致力于做的“helpful, truthful, harmless”AI 系统，不远的未来会成为现实。</li>\n<li>有底层 AI 能力，有数据的平台公司更能引领 AI 的未来。像 OpenAI 这样，有底层模型、有算力、有用户数据调用，能够把“用户调用 — 数据 — 模型迭代 — 更多用户”的循环建立起来，强者恒强。</li>\n<li>真实世界的研究。我认为学术界还在不停追求在 benchmarks 刷榜，这是对资源的极大浪费，有价值的研究需要更多思考真实用户的需求和场景。instructGPT 在学术界的 benchmarks 上性能并没有很厉害甚至有退化，但在真实调用数据上非常惊艳，说明了我们学术圈的 benchmarks，离真实世界还很遥远，不利于 AI 研究的落地。因此，更开放、更共享的工业数据，也是我们未来应该努力的方向。</li>\n<li>“AI-人”无缝交互的时代即将来临，现在的对话生成能力已经将对话交互作为一个基本入口成为可能。过去我们讲的 conversational interface 不是梦。**但有人说替代 google，我觉得其还有点距离，相反是当前搜索服务非常好的补充。</li>\n<li>致力于有用、更可信、更安全的 AI 研究和应用，应该是学术界和工业界共同努力方向。有用，解决真实世界的问题，满足用户的真正需求；可信，模型产生令人可信任的结果，知其所知，也知其所不知（虽然很难）；安全，模型有价值观、符合社会伦理规范，产生安全、无偏见的结果。</li>\n</ul>\n<p><strong>作者介绍：</strong></p>\n<p>黄民烈，清华大学计算机科学与技术系长聘副教授、博导，国家杰出青年基金项目获得者，北京聆心智能科技有限公司创始人。</p>\n<p><em>参考资料：</em></p>\n<p><a href=\"https://openai.com/blog/chatgpt/\">https://openai.com/blog/chatgpt/</a><br />\n<a href=\"https://arxiv.org/abs/2203.02155\">https://arxiv.org/abs/2203.02155</a> “</p>\n<h2>目录</h2>\n<p><strong>热点 | Hot</strong></p>\n<p>谷歌员工担心自家 AI 敌不过 ChatGPT，高管回应：其过快发展可能损害公司</p>\n<p>放出狠话又自打脸，特斯拉将重新在车辆上安装雷达，最快下个月发布</p>\n<p><strong>理论派 | Theory</strong></p>\n<p>争相上市、抢夺本土市场，未来三五年数据库将迎来大洗牌 | 解读数据库的 2022</p>\n<p>重磅！阿里开源自研高性能核心搜索引擎 Havenask</p>\n<p><strong>推荐文章 | Article</strong></p>\n<p>编程神器 Copilot 被官司搞怕了？月收费 19 美元的商业版将提供辩护服务，最高索赔 50 万美元</p>\n<p>SpaceX 效应——聊聊宇航巨子背后的企业文化</p>\n<p><strong>观点 | Opinion</strong></p>\n<p>微软 CTO 断言，明年是 AI 社区最激动人心的一年，网友：GPT-4 要来了？</p>\n<p><strong>专题｜Topic</strong></p>\n<p>全网都是数字人，鹅厂的数智人有何不同？</p>\n<p>去哪儿网 Service Mesh 落地实践：100% 容器化打底，业务友好是接入关键</p>\n<p>内核代码量不到一万行、GitHub star 超 5k，国产开源物联网操作系统 TencentOS Tiny 的探索与实践</p>",
    "publish_time": "2023-01-08 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]