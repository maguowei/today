[
  {
    "title": "AI技术2023第三季度速览：开源大模型发展迅猛，应⽤场景得到进一步探索",
    "url": "https://www.infoq.cn/article/zT7BgPgJaJU2jGdZpQ2Q",
    "summary": "<p></p><p><img src=\"https://static001.geekbang.org/infoq/5f/5fe2af1b2dd36c7e13d0528db5e15094.png\" /></p><p>2023年技术领域最亮眼的关键字非生成式AI莫属，从硅谷掀起的技术浪潮不断席卷和影响国内技术创新市场。这一年中生成式AI为首的人工智能领域的讨论度居高不下。2023年第三季度InfoQ研究中心根据大模型领域市场发展更新了<a href=\"https://www.infoq.cn/minibook/IV4VhedKw1E1tY8Hleje\">《2023中国人工智能领域技术成熟度模型报告》</a>\"，为技术的应用决策和未来投资参考提供研究分析工具。同时，InfoQ研究中心也将持续关注人工智能领域的发展动态与未来走势，并定期更新我们的研究成果，欢迎大家持续关注。</p><p>大模型产品方面，2023年第三季度生成式人工智能讨论热度不断升高，其中大模型相关技术发展整体呈现出迅速向行业贴近的走势。第三季度行业层面应用得到进一步拓展，金融、医疗、交通、营销、政务、法律、气象等行业均发布了国产大模型产品。其中金融和医疗行业表现最为突出，蚂蚁集团的AntFinGLM金融大模型、度小满的开源大模型轩辕70B等金融行业大模型；百度的医疗AI大模型灵医大模型、京东健康的京医千询医疗大模型纷纷落地。其他行业中，作业帮的银河教育大模型、携程的问道出行场景大模型、北京交通大学开源的交通大模型TransGPT·致远、北京大学开源的中文法律大模型ChatLaw等也纷纷在行业模型方面为市场做出了进一步的探索。</p><p>大模型发布机构方面，企业、高校与科研院所持续在大模型领域深耕，并且企业推出的大模型数量仍然远高于高校与科研院所。企业努力试图通过提升训练速度并降低训练成本，来实现技术的规模化经济。除头部互联网和科技企业如百度、阿里巴巴、腾讯、华为、字节跳动、京东、360等，更多玩家开始推出人工智能技术产品，如极光推出GPTBots平台、微脉推出健康管理领域大语言模型应用CareGPT&nbsp;等等。</p><p>在技术评价层面，上海交通大学、达摩院等分别发布大模型测试基准，中文大模型评价体系逐渐完善。</p><p>政策层面对生成式人工智能的监管也在迅速跟进，并成为生成式人工应用快速落地与安全性保障的有力支撑。7月，发改委、教育部、工业和信息化部等部门联合发布《生成式人工智能服务管理暂行办法》。百度的文心一言、抖音的云雀大模型、智谱的GLM大模型、中科院的紫东太初大模型、商汤的日日新大模型等首批通过备案的&nbsp;AI&nbsp;大模型产品已经开始陆续上线。该办法将进一步促进生成式人工智能健康发展和规范应用。</p><p>部分工信部备案大模型</p><p><img src=\"https://static001.geekbang.org/infoq/4f/4fa71b3ec152492ddebf974cf03f0c7f.png\" /></p><p>国际市场方面，人工智能和大模型的发展竞争依旧十分激烈。开源闭源均迅速发展，并且多模态大模型版本更新迅速。</p><p>在开源方面，开源大模型迭代迅速。Meta开源了免费可商用版本大模型&nbsp;Llama&nbsp;2，一度登顶Hugging&nbsp;Face开源大语言模型排行榜。榜首更替频繁，在LLama&nbsp;2发布后，FreeWilly&nbsp;1等大模型相继登顶榜首。虽然开源大模型迭代迅速并有很多企业依托其进行产品构建，但是开源大模型的能力表现仍然普遍逊色于闭源大模型。</p><p>已有的文生3D、文生图等多模态大模型，如DALL-E&nbsp;系列、Stable&nbsp;Diffusion等均推出新版本。同时，OpenAI、xAI等科技公司宣布将向打造AGI方向发展。</p><p>InfoQ研究中心认为，在人工智能领域接下来的发展中，人工智能技术将在应用受限的因素上优先取得一定突破，然后带动技术难点上的突破，并在安全层面上提出更成熟的解决方案。同时现有的产品在2023年第四季度和2024年将会面临更大的来自市场的竞争压力。只有进一步向实际需求贴近，在效果与成本上做出平衡，并向企业与公众展现产品价值，或者在技术实现上有较大的飞跃才能够在激烈的竞争中脱颖而出。期待飞速演化的人工智能领域不断探索和突破，为生产和生活带来更多积极的变革。</p>",
    "publish_time": "2023-11-21 10:28:40",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "中国专家主导的ISO隐私计算国际标准立项，蚂蚁集团专家担任主编",
    "url": "https://www.infoq.cn/article/xCz1CewwoLeS0OCkT7KN",
    "summary": "<p>近日，国际标准化组织（ISO）隐私计算系列标准第三部分（ISO/IEC JTC 1 SC27 4922-3 基于混淆电路的机制），正式通过立项投票，并将由中、日、韩、荷、英、法、爱尔兰、奥地利等8个国家的专家共同参与编撰。据了解，这是中国专家团队主导推动的首个ISO安全多方计算国际标准，将规范并指导业界对数据流通的算法安全及性能优化工作，加速数据价值释放。其中，三位标准负责人黄智聪、白晓媛、赵原均来自蚂蚁集团。</p><p><img src=\"https://static001.geekbang.org/infoq/55/55abc834f154a3999cfef7ebe1c93c91.png\" /></p><p></p><p>隐私计算是在保障数据安全的前提下，实现数据价值合规有序释放的技术体系。安全多方计算（MPC）是隐私计算的核心解决方案之一，已被广泛应用于跨机构数据协作。但由于各机构技术实现思路存在差异，安全水位参差不齐，影响协作信任和全链路安全。安全多方计算基础协议标准的制定，有助于规范并指导各机构实现安全和高效的基础算法组件，同时为应用协议的互联互通奠定基础。</p><p></p><p>ISO是全球最具权威性的国际标准化机构，其安全多方计算标准4922系列标准包括：第一部分“安全多方计算通则”、第二部分“基于秘密共享的机制”，以及中国专家主导的第三部分“基于混淆电路的机制”。混淆电路是安全多方计算的经典算法，在信贷风控、联合反诈等场景中被广泛使用。该立项标准对混淆电路的协议定义、推荐方案和接口定义等都进行了规范。标准负责人之一、蚂蚁摩斯算法专家赵原介绍，蚂蚁摩斯在混淆电路领域持续投入多年，基于自研的混淆电路算法库构建安全脚本、安全统计等多种商业化产品，已帮助上百家企业开展数字化协作。他表示：“希望通过推动该标准的制定，将摩斯在混淆电路领域的实践经验向业界分享，助力全行业的算法安全与高效实现。”</p><p></p><p>公开资料显示，蚂蚁商用隐私计算平台摩斯在权威研究机构IDC《2022年中国隐私计算平台市场份额》报告中，以36.9%的市场份额排名第一。</p>",
    "publish_time": "2023-11-21 10:32:45",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "淘天集团高级技术专家邓波确认出席 QCon 上海，分享 Tengine-Ingress 高性能高可用云原生网关",
    "url": "https://www.infoq.cn/article/EUv1rCb6TPsYiti4Ic1w",
    "summary": "<p><a href=\"https://qcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=8&amp;utm_term=1121&amp;utm_content=dengbo\">QCon 全球软件开发大会</a>\"，将于 12 月在上海召开。淘天集团高级技术专家邓波将发表题为《<a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5603?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=8&amp;utm_term=1121&amp;utm_content=dengbo\">Tengine-Ingress 高性能高可用云原生网关</a>\"》主题分享，探讨 Tengine-Ingress 云原生网关背景、网关架构、超大规模网关设计，以及其在淘天集团的应用。</p><p></p><p><a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5603?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=8&amp;utm_term=1121&amp;utm_content=dengbo\">邓波（花名：光锥）</a>\"，2016 年加入阿里巴巴，致力于淘天集团接入网关的技术演进，为淘天集团提供稳定、高效的接入网关能力，同时主导推进云原生网关 Tengine-Ingress 的技术开源。他在本次会议的演讲内容如下：</p><p></p><p>演讲：Tengine-Ingress 高性能高可用云原生网关</p><p></p><p>Tengine 作为淘宝网发起的 Web 服务器开源项目，具备高性能、高可用特点，在进入云原生时代之后，存在的一些限制逐步凸显出来，如缺乏配置动态编排功能，用户侧流量可配置性和可观测性能力弱等问题。随着云原生 Ingress 入口网关规范的事实标准化以及淘天集团 Kubernetes 的大范围落地，也为 Tengine 的云原生化奠定基础。</p><p></p><p>Tengine-Ingress 网关基于 Kubernetes Ingress 标准，实现接入层的架构升级，技术底座在深度优化 Kubernetes/Ingress-Nginx 基础上融合 Tengine，不断提升自身性能和可用性，彻底根除痛点问题。同时由于淘天集团对稳定性的极致要求，扩展配置一致性和配置灰度生效能力，并将其反哺 Tengine 开源社区，保持对 Tengine 开源社区的持续输出。</p><p></p><p>演讲提纲：</p><p></p><p>Tengine-Ingress 云原生网关背景超大规模网关设计</p><p>○ 高性能低延迟 </p><p>○ 云原生架构 </p><p>○ 配置实时动态更新 </p><p>○ 配置灰度发布 </p><p>○ 超大规模配置全局一致性保障 </p><p>○ 多维度精细化路由</p><p>Tengine-Ingress 网关在淘天集团的应用未来规划</p><p></p><p>听众收益点：</p><p></p><p>○ Tengine-Ingress 云原生网关架构，以及演进过程中的思考</p><p>○ 大规模网关稳定性保障所需具备因素</p><p>○ 云原生网关在大型场景下落地经验</p><p></p><p>除上述演讲外，QCon 上海还将围绕&nbsp;<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart\">GenAI和通用大模型应用探索</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1596?utm_source=infoqweb&amp;utm_medium=teacherart\">AI&nbsp;Agent&nbsp;与行业融合应用的前景</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart\">LLM&nbsp;时代的性能优化</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart\">智能化信创软件&nbsp;IDE</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart\">面向人工智能时代的架构</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart\">性能工程：提升效率和创新的新方法</a>\"等专题进行交流。</p><p></p><p>QCon 上海 2023，相约 12 月！ 现在购票，享 8 折优惠，立减￥1360！咨询购票请联系：18514549229（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/0113b3dfb187d5f9988b7eb16d2e0594.png\" /></p><p></p>",
    "publish_time": "2023-11-21 11:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "免费《大模型应用实践》实训营第二周课程来啦！这次百度算法工程师团队手把手教你构建大模型应用，另有第一周干货回顾！",
    "url": "https://www.infoq.cn/article/VycCdb9OIRSlU46zOJJv",
    "summary": "<p>11 月 16 日 百度智能云<a href=\"https://www.infoq.cn/article/o8abj2wff5yLfGWuB0E1?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">千帆大模型</a>\"平台官方出品《大模型应用实践》实训营课程拉开帷幕，在首周的课程中百度智能云千帆大模型平台产品经理以及知名技术 UP 主对整体平台应用做了系统讲解以及使用指导；本次实训营通过学习社群答疑 + 直播课程的形式展开，学习群中研讨氛围浓厚！同时每节课通过「课后作业」的互动形式来引导学员进行<a href=\"https://www.infoq.cn/article/o8abj2wff5yLfGWuB0E1?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">大模型</a>\"应用，当前已有 2000+ 学员加入了大模型学习，欢迎更多的学员加入我们！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3a/3a4fb8980cdd24696a3183db8d1458db.png\" /></p><p></p><p>首周【平台应用周】课程回顾</p><p></p><p></p><h4>&nbsp;第一节课程：百度智能云千帆平台明星大模型与工具链概览</h4><p></p><p></p><p>百度智能云千帆大模型平台 Ziqi 在本次课程中首先分析了当前大模型应用场景的四大痛点，如何在现有业务中找到高价值应用场景识别、如何针对大模型能力做选型、如何针对行业场景用大模型做深度调优以及如何用大模型做出大规模应用性价比。针对以上痛点，Ziqi 对平台中的十大明星大模型对应能力以及适用应用场景进行了详细解读，同时针对平台的 5 大工具链能力：<a href=\"https://www.infoq.cn/article/7FGafFFFYkbMxW11u0BT?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">Prompt 工程</a>\"、数据管理、模型精调、插件编排、应用样板间做出功能介绍。首次课程主要让学员了解大模型同时结合百度智能云千帆大模型平台一站式体验大模型应用！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/50/502de3f44c04886097fe01e280ad8b9a.jpeg\" /></p><p></p><p></p><h4>&nbsp;第二节课程：平台应用分享 - 基于文心大模型 4.0 打造大模型时代游戏 NPC</h4><p></p><p></p><p>本次课程邀请到知名技术 UP 主 - 同济子豪兄来进行应用层面的分享，他通过百度智能云千帆大模型平台进行了「让宿管阿姨开门」的小游戏开发。在课程中他针对当前热门的大模型应用游戏行业进行了行业观点分享，以及分享了可开发的游戏类型。他以自己开发的游戏为例进行了整体 demo 及开发演示，同时游戏中还通过百度智能云千帆大模型平台调用了百度自研最新的文心大模型 4.0 作为主要对话大模型，游戏演示中还验证了文心大模型 4.0 的超强逻辑能力；整体课程他为学员们在游戏行业的应用做出了一定的开发实践启发。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2d/2d9c8831225a180630428d00488174af.jpeg\" /></p><p></p><p></p><h4>&nbsp;Week 2 - 百度智能云算法工程师带队系列课程介绍</h4><p></p><p></p><p>结束首周与大模型的相互了解阶段，第二周课程将以热门大模型为例，由百度智能云算法工程师带队进行整体大模型应用及应用构建教程。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cf/cfae0a316699267b3506f427f489d6b0.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2a/2a35e973df2ff8a9401e625c5af8e65f.png\" /></p><p></p>",
    "publish_time": "2023-11-21 13:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "通明智云宣布完成数千万元A+轮融资， 引领云原生与信创两翼齐飞的应用交付解决方案",
    "url": "https://www.infoq.cn/article/WizzCg1frgjJ5fV5jFV9",
    "summary": "<p>近日，<a href=\"https://www.infoq.cn/article/v3fU1OOujPUhhiSUQqjs?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">通明智云</a>\"（北京）科技有限公司（简称：通明智云）宣布完成数千万元 A+ 轮融资，由全聚合与信公投资联合投资，明论资本担任本轮融资独家财务顾问。本轮融资资金将主要用于 NJet 云原生应用引擎、信创应用交付网关等核心技术研发及产品上下游产业布局、市场拓展、人才队伍和软硬件平台建设等。</p><p>&nbsp;</p><p>通明智云成立于 2021 年，主营业务聚焦在<a href=\"https://mp.weixin.qq.com/s?__biz=MzIzNjUxMzk2NQ%3D%3D&amp;chksm=e8d7e959dfa0604f53e8d9a7b5d0dd9539e9d371327b582fdc35af1a28e84ab864be68b0f8ca&amp;idx=1&amp;mid=2247489179&amp;scene=27&amp;sn=7d56cd99ba46e1f0e216188769237177&amp;utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search#wechat_redirect\">负载均衡</a>\"、应用交付、云原生应用引擎等软硬件技术的研发和产品解决方案销售。致力于通过革命性的技术, 帮助客户打通云、管、边、端, 构建以客户为中心的可持续性+ 可观测性的数字化应用发布平台，成为数字经济增长的新引擎。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/76/766a9919991d3a185bb22810d873facb.png\" /></p><p></p><p>通明智云联合创始人兼总经理<a href=\"https://www.infoq.cn/article/yz4BbsPGJrCsPzPPv4SS?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">吴若松</a>\"表示，“以容器、微服务、DevOps 等为核心的云原生技术和理念推动着云原生产业生态蓬勃发展。随着企业深入上云用云，业务应用走向全面云化，企业对云原生的需求升级，需要一个底层的云原生应用引擎来支撑业务应用的快速云化改造。在业界各方的帮助和支持下，通明智云将全力推进具有自主知识产权、自主创新的下一代云原生应用引擎。”</p><p>&nbsp;</p><p>NJet 云原生应用引擎实现了 NGINX 不具备的在云原生架构下提供东西向的应用流量控制能力、增加国密算法的 SSL 通信能力、兼容 Kubernetes 容器编排和 Istio 服务治理框架，具体包括：基于云原生服务网格的透明流量劫持技术、高性能低能耗、精简型引擎内核设计、多形态部署等关键技术。云原生开源应用引擎 OpenNJet 1.0 版本已经成为开放原子开源基金会的孵化项目。</p><p>&nbsp;</p><p>在布局云原生产业生态的同时，通明智云不断提升自身在信创企业市场的竞争力。通明智云联合创始人兼首席运营官吴静涛表示，“在数字化转型的过程中，企业从传统 IT 架构向云原生架构过渡，在企业内部形成了云原生、信创和传统 IT 架构等多元并举的态势。企业实现应用可持续性发展，需要站在架构的战略高度，通过统一的配置界面、统一的管理平台、统一的大数据采集分析，以及统一的服务平台等关键要素，来保证企业技术迭代创新过程中的应用可持续性和技术选型灵活性，尤其是实现核心信创的可靠过渡。”</p><p>&nbsp;</p><p>通明智云创始团队主要来自神州数码、F5 等知名企业。董事长郭为是神州数码创始人，专注数字科技产业30 余年；总经理吴若松具有 26 年应用交付从业经验，曾任 F5 中国区销售总经理、思科/IronPort 大中华区总经理；首席运营官吴静涛具有 24 年应用交付从业经验，曾任 F5 大中华区 CTO、Citrix 中国区销售总监。创始团队将持续通过技术创新、行业应用、人才培养等方面的努力，不断提升公司的整体竞争力。</p><p>&nbsp;</p><p>通明智云成立至今，在产品技术、销售市场、生态合作等方面一直保持高速增长渐入佳境，已累计获得发明专利 5 项，软件著作权 25 项。为金融、政府、军工、能源、公共服务等重要行业用户提供优质的产品、解决方案和服务。</p><p>&nbsp;</p><p>通明智云在成长的过程中，秉承“让应用永远在线”的愿景，始终以客户为中心，不断提升技术和产品的创新，以服务用户为导向深耕行业客户，不断凝聚上下游生态伙伴，在数字经济的浪潮中，走出一条适合于自身发展的创新之路。</p><p>&nbsp;</p>",
    "publish_time": "2023-11-21 14:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "StarRocks Summit 2023技术峰会：已有数十家企业在基于StarRocks实践湖仓新范式",
    "url": "https://www.infoq.cn/article/9EirXbavFEem9gxEzZ9G",
    "summary": "<p></p><p>2023年11月17日，由 StarRocks 社区发起、镜舟科技主办的 StarRocks 年度大型技术交流峰会 StarRocks Summit 2023 在上海成功举行。</p><p></p><p>本次峰会以「极速进化，融合\"新\"生」为主题，40余场分享演讲在全天密集开展，来自平安银行、华润、腾讯游戏、阿里云、伊利、美的、京东等头部企业的大数据专家围绕数据进化、需求进化、技术进化，细致讲解大数据分析的最新技术和最佳实践，为大数据分析行业呈现了一场精彩的技术盛宴。</p><p></p><p>峰会吸引了数百名企业用户代表和开发者到场聆听交流，另有数万名数据分析爱好者、从业者线上参会，通过多种渠道观看了峰会直播。</p><p></p><p></p><h2>新面孔：StarRocks 大用户阵容不断壮大</h2><p></p><p></p><p>这是 StarRocks 第三次举行年度技术交流峰会，峰会延续了以前的高规格，亮相的企业用户代表堪称全明星阵容，全都是所在行业头部，并且具有广泛的社会知名度和影响力。</p><p></p><p>其中，既有腾讯、阿里、京东等在去年峰会上分享过经验的互联网“老面孔”，也有不少来自金融、制造、零售等行业的新面孔，比如伊利、平安银行、芒果TV等企业就是首次派代表到场演讲。</p><p></p><p>作为一款技术领先的开源 OLAP 数据库产品，StarRocks 一直备受大用户青睐，随着 StarRocks 加速向各行各业渗透，大用户阵容也在不断扩大，截至目前，已有超过300家市值10亿美金的企业使用 StarRocks。</p><p>在大用户的示范和带动下，中小企业用户规模同样在迅速壮大，StarRocks 社区用户已突破1万，并依然保持着高速增长态势。</p><p></p><p>从应用场景来看，嘉宾们分享的场景包括金融营销、用户画像、自助分析、报表体验升级等，基本涵盖了当前实时数仓技术的所有经典应用场景。</p><p></p><p>镜舟科技CEO孙文现表示，StarRocks 开源社区为制胜场景的诞生提供了肥沃的土壤，各行各业、各种需求在社区中碰撞、交融，产生出 StarRocks 的制胜场景。</p><p></p><p>据孙文现介绍，镜舟科技基于 StarRocks 打造的企业级产品全年经历了近百次POC，成功率达到90%以上。</p><p></p><p>StarRocks 产品能力有多硬核，由此可见一斑，这也可解释为什么会有越来越多的用户选择 StarRocks。</p><p></p><p></p><h2>新范式：StarRocks 引领湖仓一体趋势</h2><p></p><p></p><p>本次峰会共设置了一个主论坛、四个分论坛，除了企业用户代表基于实践的经验分享，开发者代表进行的功能诠释同样精彩。</p><p></p><p>过去一年，StarRocks 先后发布了2.5、3.0、3.1三个重磅版本，其中 3.0 版本推出的存算分离架构为开源业界首创，曾在行业内引起巨大反响。</p><p></p><p>StarRocks TSC Member、镜舟科技 CTO 张友东介绍，升级到存算分离架构后，用户的存储成本能下降80%，而计算节点则因为无状态，可以通过快速弹性、跨可用区部署等方式来提高计算的可用性，并且计算资源能够进行物理隔离，按需独立弹性伸缩。</p><p></p><p>到 3.1 版本，开启 Local cache 的情况下，存算分离架构下的性能表现已接近本地存储的水平。</p><p>与此同时，现在 StarRocks 的湖仓分析能力已非常完备，不仅支持internal、Data lake、JDBC、ES等catalog，还支持跨数据源的联帮分析。</p><p></p><p>另外，主键模型的能力在过去一年也得到持续提升，已经同时支持全内存和持久化的索引，并支持了 partial update、conditional update 的能力，在性能方面，针对批量更新的场景，引入了按列更新的模式，性能相比按行更新提升10倍以上。</p><p></p><p>张友东表示，未来数据演进的趋势是湖仓一体，用户无需关注是建湖还是建仓，不管是构建数据湖还是构建数据仓库，企业最终的目标是低成本、高效的解决数据分析问题。StarRocks 在具备存算分离、湖仓分析、物化视图等一系列重量级特性后，实现了往 Lakehouse 引擎的升级，借助 StarRocks 可兼具数据湖和数据库仓库的优势。</p><p></p><p>目前已有数十家企业在基于 StarRocks 实践湖仓新范式，并取得非常好的业务效果。</p><p></p><p>其中，芒果 TV 采用 StarRocks 存算分离作为统一的 Lakehouse，所有数据导入到 StarRocks 进行统一管理；微信近实时的数据写入到 Iceberg，通过 Iceberg 直接分析；携程数据统一存储在 Hive，采用 StarRocks 直接查询加速报等等。</p><p></p><p></p><h2>新未来：StarRocks 的进化故事还在继续</h2><p></p><p></p><p>据张友东介绍，未来 StarRocks 还会朝着云原生方向继续迈进，推动实时分析链路进一步精简，通过 ETL on lakehouse，all in one 的作业模式，帮助企业低成本、高效率地发掘数据价值。</p><p></p><p>值得一提的是，StarRocks 社区是由镜舟科技与阿里云、腾讯、小红书、滴滴等互联网公司共同建设，包括全局字典函数、同步物化视图增强、Paimon Catalog等在内的许多feature都由互联网大厂贡献，以后注定也还会从大厂生产环境中持续吸收灵感和助力，给业界带来更多惊喜。</p><p></p><p>与此同时，围绕 StarRocks 形成的商业生态也越来越完善，以镜舟科技为代表的商业团队不断提升着产品的易用性、稳定性，将产品能力落地到复杂的需求环境中，创造更大价值。</p><p></p><p>随着此次峰会精彩内容的传播，相信会有越来越多的企业受到启发，利用OLAP领域的最前沿技术，完成自身业务场景的升级和进化。</p>",
    "publish_time": "2023-11-21 15:02:44",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "阿里云分拆紧急刹车；鸿蒙工程师火爆抢手，年薪最高达160万；上班“摸鱼”被辱骂，法院判其领导侵犯人格权 | Q资讯",
    "url": "https://www.infoq.cn/article/IZ2QJ4ADaRNpi6eBY2rv",
    "summary": "<p>&nbsp;</p><p></p><blockquote>阿里云分拆紧急刹车；字节营收已超腾讯；OpenAI重金挖角谷歌；下属上班“摸鱼”被领导辱骂，法院判侵犯人格权；京东科技再调整：“一部三中心”拆了；ChatGPT出现炸裂越权漏洞......</blockquote><p></p><p>&nbsp;</p><p></p><h2>科技公司</h2><p></p><p>&nbsp;</p><p></p><h4>阿里云分拆紧急刹车</h4><p></p><p>&nbsp;</p><p>11月16日晚间，据界面消息，阿里巴巴集团在新一季财报中披露，鉴于多方不确定性因素，不再推进云智能集团的完全分拆。同时，阿里巴巴称，将坚决加大对阿里云的持续战略投入，确保阿里云专注于“AI+云计算”发展战略。</p><p>&nbsp;</p><p>阿里巴巴在财报中表述了不再推进云集团拆分的原因。据其所述，美国近期扩大了对先进计算芯片出口的限制，给云智能集团的前景带来不确定性。阿里集团因此认为，云智能集团的完全分拆可能无法按照原先的设想提升股东价值，因而决定不再推进，而是面对不确定的环境，专注建立云智能集团可持续增长的模型。</p><p>&nbsp;</p><p>与此同时，阿里巴巴集团公布了新一季度业绩，其中，阿里云收入同比增长2%至276.48亿元，经调整EBITA利润从上个季度的3.87亿元，大幅提升至14.09亿元，环比增幅达264%。可见，通过主动削减项目制订单，阿里云正在提升收入质量。</p><p>&nbsp;</p><p>据《金融时报》及路透社消息，阿里巴巴还暂停了盒马鲜生上市的计划。另外，根据美国证券交易委员会（SEC）官网披露的144表格显示，马云家族信托JC Properties Limited（英属维尔京群岛公司）和JSP Investment Limited（英属维尔京群岛公司）拟于11月21日分别减持500万股阿里巴巴创始人股份。此次减持的1000万股阿里巴巴集团美国存托凭证，全部在2014年9月19日获得。这一天也是阿里巴巴集团在纽交所挂牌交易的时间。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/be/be482af2d82941fd4bc7f1727dc779b8.png\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>字节上半年营收达540亿美元，已超腾讯</h4><p></p><p>&nbsp;</p><p>据外媒报道，字节跳动第二季度收入增长超过40%，达到290亿美元；上半年营收约为540亿美元。腾讯控股的财报显示，今年上半年，其营收约为2992亿元，约合413亿美元。由于字节跳动未上市，财务信息不透明，在互联网企业的营收排名中常常缺席。此次曝光上半年的营收，字节跳动的营收已超过腾讯控股。</p><p>&nbsp;</p><p></p><h4>OpenAI重金挖角谷歌，年薪可达1000万美元</h4><p></p><p>&nbsp;</p><p>据 The Information 报道，OpenAI 向谷歌发起人才争夺战，该公司正通过高达数百万美元的薪酬包，以及顶尖的技术资源，如用于运行测试的人工智能加速器芯片，来吸引谷歌的一些最优秀的研究人员。</p><p>&nbsp;</p><p>据彭博社上个月报道，OpenAI 正在探索一项员工股份出售的方案，该方案将该公司的估值定为 860 亿美元。据报道，如果该公司的招聘人员成功地挖来了谷歌的顶尖人工智能研究人员，他们可能会在最近一次股票出售后获得 500 万至 1000 万美元的薪酬待遇。</p><p>&nbsp;</p><p>目前，OpenAI 已经从谷歌和 Meta 挖来了一些人才，来帮助开发其人工智能聊天机器人 ChatGPT。去年 11 月，OpenAI 宣布推出 ChatGPT 的博客文章的致谢部分列出了五名前谷歌研究人员。截至二月份，OpenAI 已经雇佣了至少 93 名曾经在谷歌和 Meta 工作过的人。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>上班“摸鱼”被辱骂，法院判其领导侵犯人格权</h4><p></p><p>&nbsp;</p><p>据南方周末消息，“00后打工人”万伊健曾供职于江西省南昌市一家考试培训公司，因在办公室打游戏被直属领导发现，被要求离职，并在随后的沟通中被辱骂。</p><p>&nbsp;</p><p>（2023）赣0104民初4464号判决书记载了刘某向法庭陈述的辱骂经过：2023年6月7日，刘某发现万伊健仍未将工作机交接给另一名员工，且在上班时间未到岗，他认为万伊健态度恶劣，在电话中对其辱骂“他×的”。2023年6月18日，刘某还在微信群中对万伊健说，“最适合你的工作可能是去坟场念悼念词”。</p><p>&nbsp;</p><p>觉得受侮辱的万伊健将直属领导告上法庭。2023年10月25日，南昌市青云谱区人民法院一审判令万伊健的领导向他公开道歉，并支付精神损害赔偿金100元，理由是侵犯了人格权。一审宣判后，万伊健和其原领导均未上诉。万伊健称，判决已经执行。</p><p>&nbsp;</p><p></p><h4>京东科技再调整：“一部三中心”拆了</h4><p></p><p>&nbsp;</p><p>据雷峰网消息，京东科技近期再次迎来架构调整：今年年初定下的“一部三中心”架构拆了，“三中心”重新整合成技术服务事业部，总裁徐丰任负责人。原销售中心、解决方案中心、交付中心解散，在技术服务事业部体系下整合为智能服务和交付业务部。</p><p>&nbsp;</p><p>此前有消息称，京东集团副总裁、京东科技解决方案中心负责人高礼强离职后解决方案中心可能要解散。据架构公示，不仅是解决方案中心，销售、交付中心也全部解散。调整后情况为：“交付”还是独立，原来销售中心、解决方案中心的员工受到的影响较大，绝大部分的员工需要再谋出路。</p><p>&nbsp;</p><p></p><h4>多个 App表示未收到苹果叫停摇一摇通知</h4><p></p><p>&nbsp;</p><p>11月13日，有消息称，苹果公司已通知国内多家头部 App，要求它们移除陀螺仪权限，摇一摇跳转广告被禁止。未来，头部 App 企业将发布取消摇一摇跳转广告功能的新版本。针对该消息，淘天、京东、拼多多、抖音、快手等多家头部 App 公司，未有厂商明确表示收到苹果通知，苹果也未给出回复。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>IT业界</h2><p></p><p>&nbsp;</p><p></p><h4>鸿蒙工程师火爆抢手，年薪最高达160万</h4><p></p><p>&nbsp;</p><p>11月16日，新浪集团与华为举办鸿蒙原生应用开发启动仪式，正式宣布开展微博、新浪新闻的鸿蒙原生应用开发，并在技术创新、产业应用、商业合作等领域展开全面深入合作。</p><p>&nbsp;</p><p>今年9月，余承东宣布鸿蒙原生应用全面启动，这意味着华为开始了全面抛弃安卓的进程。随后，越来越多重要互联网应用拥抱鸿蒙生态，多家互联网公司也发布了鸿蒙OS的App开发工程师的岗位，开启了抢人大战。有的企业开出了近百万的年薪招聘鸿蒙OS工程师，其中美团发布的鸿蒙基建工程师的岗位，薪资待遇为40-60k·15薪，京东发布的前端架构师（鸿蒙方向）岗位，薪资待遇为40-70k，要求5—10年工作经验，而华为甚至为鸿蒙OS资深架构师开出了100万-160万元的年薪。</p><p>&nbsp;</p><p></p><h4>ChatGPT出现炸裂越权漏洞</h4><p></p><p>&nbsp;</p><p>据“AGI安全”消息，他们经测试发现ChatGPT存在严重的越权漏洞。通过官网登录3.5模型以后加上特定的后缀可以直接访问GPT-4所拥有的功能。</p><p>&nbsp;</p><p>复现过程为：</p><p>&nbsp;</p><p>登录自己GPT-3.5账号；在官网url地址后面输入chat.openai.com?model=gpt-4*****；</p><p>&nbsp;</p><p>然后就可以直接访问gpt-4了。</p><p>&nbsp;</p><p>当前漏洞已经报告给OpenAI，预计不久就会被修复。造成漏洞的主要原因是对后端模型的调用没有做鉴权。当前漏洞属于0Day，截止目前漏洞依然可以被利用。</p><p>&nbsp;</p><p>另外，本周OpenAI的付费服务ChatGPT Plus也因使用量过大而暂停注册。</p><p>&nbsp;</p><p>11月15日，OpenAI首席执行官萨姆·奥特曼（Sam Altman）在X（原推特）上表示，“我们将暂停新的ChatGPT Plus用户注册。开发日后使用量的激增已经超出了我们的承受能力，我们希望确保每个人都有良好的体验。你仍然可以在应用程序内注册，以便在订阅者重新开放时收到通知。”随后，奥特曼在X（原推特）上公开致歉，称用户对于公司前一天发布的新功能的使用量远超预期。</p><p>&nbsp;</p><p></p><h4>阿里云故障原因曝光：访问密钥服务(Access Key) 异常</h4><p></p><p>&nbsp;</p><p>11月12日，阿里云的服务出现大面积故障。据阿里云公告，故障原因与某个底层服务组件有关。本次事故中，阿里旗下淘宝、云盘、饿了么、钉钉等产品未能幸免于难。</p><p>&nbsp;</p><p>吃瓜群众看热闹不嫌事大，在阿里云故障的当晚，一则所谓的马化腾聊天截图开始在圈内流传。截图显示，图片头像为“马化腾”的用户称“用阿里云不如用腾讯云啊朋友们”。腾讯云方面对此进行了辟谣。</p><p>&nbsp;</p><p>本周，网上流传说阿里云发给了客户一份官方故障报告，但内容相当简洁，缺少原因、影响和改进细节，同时阿里云官网也发布了“异常”说明。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/35/35096f5fbe85d2224b800e3e142dc2f8.jpeg\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>小米官宣 Xiaomi Vela 全面开源，底层内核为 NuttX</h4><p></p><p>&nbsp;</p><p>11 月 16 日，小米集团董事长雷军在微博宣布，Xiaomi Vela 面向全球软硬件开发者正式开源。根据小米官方网站的介绍，Vela 是小米基于开源实时操作系统 NuttX 打造的物联网嵌入式软件平台，Vela 在各种物联网硬件平台上提供统一的软件服务，支持丰富的组件和易用的框架，打通碎片化的物联网应用场景。</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-11-21 15:58:05",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "ClickHouse彪悍发言：云数仓死贵死贵的，Snowflake这种就不应该成为当前主流！",
    "url": "https://www.infoq.cn/article/wJWTp0sFxyrqMuS8ZdfZ",
    "summary": "<p></p><blockquote>ClickHouse版本的“云数据库是不是杀猪盘”？</blockquote><p></p><p>&nbsp;</p><p>ClickHouse 最近发表了一篇精彩的文章，描述了 Snowflake 和 Redshift 等云数据仓库已经不能满足新的客户需求，并且指出许多企业已经发现他们的云数据仓库成本是不可持续的。</p><p>&nbsp;</p><p>“云数据仓库的成本呈指数级增长”，“我们感谢云数据仓库多年来的辛勤付出，但它们引领的霸权时代即将落幕”。</p><p>&nbsp;</p><p>在这篇文章中，他们还探讨了数据库技术的发展，认为成本将成为一个重大的痛点，从而促使企业重新评估其数据堆栈。</p><p>&nbsp;</p><p></p><h2>数据生态系统的演变</h2><p></p><p>&nbsp;</p><p>数据生态的演变，经历了从大型机到关系数据库，再到传统数据仓库，再到早期的云提供商的过程。在过去十年里，像Snowflake这样的厂商推动了整个行业的现代化，打破了以往高度依赖封闭且专有的自我管理型部署生态（主要由甲骨文、Teradata等提供）的传统。</p><p>&nbsp;</p><p>新方案帮助组织将PB级关键工作负载迁移至云端，将这些数据集开放给更广泛的集成、协作与应用程序，由此实现了数据访问普及化并创造出巨大的市场价值。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fa/fa4814f74e7a01b9b906b06f725878ad.png\" /></p><p></p><p>&nbsp;</p><p>但随着时间推移，企业开始认真审视自己的数据存储架构，考虑其中信息的具体性质以及能够实现的潜在用途。随着组织数据获取门槛的逐渐降低，开发团队开始从静态批量报告转向建立交互式应用，在供内部使用的同时也可以对外发布。</p><p>&nbsp;</p><p>而到了这一步，云数据仓库的短板也开始暴露出来。此类存储方案专为离线报告模式而设计（目前仅运行在云基础设施当中），因此其架构与计费模式并未针对作为交互式数据驱动应用的后端进行优化。</p><p>&nbsp;</p><p>于是乎，组织往往面临着性能不佳（响应时间从数十秒到几分钟不等，无法做到亚秒甚至是毫秒级响应）、成本飙升（通常是替代方案的3到5倍）以及查询并发性过低（不适合对接外部应用）等现实难题。</p><p>&nbsp;</p><p></p><h3>传统云数据仓库的局限性日益凸显</h3><p></p><p>&nbsp;</p><p>传统数据仓库已有多年历史，在设计上主要服务于离线和批量处理时代下的统一内部业务报告，而且大多具有以下特征：</p><p>依靠大批量ETL作业从源系统中移出数据；对大表进行大规模join，借此将不同数据集统一起来进行集中查询；通过静态“views”或“marts”供不同团队使用特定数据集。</p><p>&nbsp;</p><p>以Snowflake、BigQuery及Redshift等平台为主导的云数据仓库，大多专为特定类型的重要数据工作负载提供可扩展性、便利性，以及最重要的灵活性与开放性，借此实现数据仓库的现代化改造。</p><p>&nbsp;</p><p>然而，随着这些数据登陆云端，数据仓库的固有应用边界也被很快打破，迫使云数据仓库成为一种“一刀切”式的解决方案，全面承担起服务器端转换、仪表板、可观察性、机器学习等各类面向用户的分析用例。但受其自身局限性影响，云数据仓库开始成为性能问题、用户体验下降及成本失控的根源，对数据架构的重新评估已经刻不容缓。</p><p>&nbsp;</p><p></p><h3>交互式、数据驱动的应用场景正成为主流</h3><p></p><p>&nbsp;</p><p>对于已经发展成熟的行业来说，人们更倾向于把构建各种新兴应用的趋势理解成利基性质的小众需求。如果去询问传统数据仓库架构师，他们很可能仍然坚称“批量数据摄取和报告”仍是正确答案……但事实并非如此。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b2/b2e4ec7d0348a8eddaec2c7df5b9da95.png\" /></p><p></p><p>&nbsp;</p><p>如今，营销、销售、工程、运营等各个部门的专业人士都需要频繁使用交互式、由数据驱动的生产力应用，其特征就是以高度交互的方式对大量数据执行分析。例如，作为营销人员，我们需要了解谁访问过产品网站、谁在关注社交媒体帖子，已发布广告的接受情况如何等——所有这些都必须实时获取答案。作为一名金融分析师，大家需要在快速变化的市场中迅速反应，每天多次做出决策。而对于负责24/7 SaaS服务的DevOps工程师，我们则很可能要对应用程序的可用性提出极为严苛的要求——正常运行时间至少要达到99.999%，即每年只能容忍5分钟的停机时间！</p><p>于是乎，全新的行业由此诞生，其服务对象就是那些无法通过传统数据仓库解决、而只能借助实时数据仓库的业务需求。</p><p>&nbsp;</p><p>营销分析，提供来自多种渠道（包括网络、社交媒体、广告活动）的宣传效果，对信息进行总结，并允许营销人员运行交互式查询及报告功能，主动显示海量数据中的异常值（例如快速增长的区域、子市场或行业），并提出营销支出优化建议。销售分析，显示各销售区域的具体活动，例如按来源划分的销售线索流、免费/试用产品接受情况、销售周期活动、售后消费、账户健康状况以及客户流失数据等。汇总这些数据并主动提取出重要信息之后，销售专业人士可以据此评估不同措施的机会或风险因素，把握住关键潜在客户并发现态度摇摆的风险客户。电子商务与零售分析，涵盖整个零售生命周期——从营销到库存、再到销售活动和商品配送，全程实现对数据的长期跟踪与交互式查询，并主动提出物流运营的优化方法。金融分析跟踪金融工具的具体操作，包括买入、卖出、看跌期权、看涨期权，并允许分析师根据此类信息选择标准及建议的行动（包括潜在的后续交易与对冲操作）。可观察性与物联网监控，要求从SaaS基础设施或制造车间/设备处获取结构化日志、指标并跟踪事件，将结果与设备和用户信息等元数据交叉引用，据此总结错误与延迟信息，并结合历史数据预测可能发生故障的区域。</p><p>&nbsp;</p><p>分析类应用的内部用户包括产品、营销及业务分析师，他们也是数据仓库系统上的主要目标受众。但这些用户明显不再满足于缓慢的分析体验。为了保持职能竞争力，他们必须加快数据驱动的决策速度，而如果内部数据平台无法满足要求，他们则会提议采用更快、交互式表现更好的第三方工具。</p><p>&nbsp;</p><p>除了现有内部用例之外，企业内部的AI/机器学习团队也在逐步扩大，内部数据科学家也需要访问并查询数据以开发出更好的机器学习模型与AI功能。数据科学家对于交互性能同样高度关注，因为查询速度将直接决定他们发布新机器学习模型、构建AI新功能的效率。</p><p>&nbsp;</p><p></p><h2>云数据仓库的短板</h2><p></p><p>&nbsp;</p><p>在这些场景下，云数据仓库的表现往往令人头痛。由于传统数据仓库的架构与计费模式缺少针对性优化，所以无法充当交互式数据驱动应用的高效后端。此类应用通常要求数据仓库具备以下能力：</p><p>将连续加载的数据与历史数据（周期长达数年）相结合以提供查询服务；在高交互访问模式下提供高并发查询，例如复杂的过滤与聚合操作；为沉浸式应用提供必要的低延迟查询（理想情况为亚秒级）；处理高达TB甚至PB级别的历史数据，且每秒能够处理数百万次事件摄取。</p><p>&nbsp;</p><p>而目前的云数据仓库明显表现乏力：</p><p>数据传播延迟。由于经由复杂ETL管道进行的数据传播往往会有数小时的延迟，而且高度依赖于非规范化的数据集（需要昂贵的JOIN并拖慢应用的运行速度），因此内部数据工程团队很利用传统数据仓库满足日益提高的服务需求，而且在遗留架构上支持实时查询将产生高昂的财务成本。查询性能低下。用户获取查询结果的响应时间往往长达几十秒甚至几分钟，远远达不到毫秒级的延迟需求。如果希望投入更多算力来提高查询性能，那么成本这个老问题又会制约可行性。成本飞涨。与替代方案相比，云数据仓库的用户往往需要承担3到5倍的高昂成本，且性能低于一般标准。而且在更高的成本之下，其架构需要消耗更多的系统资源才能处理相同的工作负载。查询并发性低下。如今，用户对于查询并发性的要求远高于传统数据仓库的设计预期——成百上千的用户会同时运行查询，希望把延迟控制在毫秒级别，同时要求把成本控制在合理水平。</p><p>&nbsp;</p><p>最终，云数据仓库只能通过成本方面的过度投入来暴力解决服务延迟、工作负载交互等需求——要么为Snowflake中的物化视图等高级功能支付更多费用，要么投入更多算力资源来加快BigQuery中的查询处理。</p><p>&nbsp;</p><p>这就像是投入巨资改造一辆旧车，指望它能在激烈的竞速比赛中获胜——正确的思路，显然是用更低的价格直接购买一台赛用车辆。</p><p>&nbsp;</p><p></p><h3>云数据仓库的成本呈指数级增长</h3><p></p><p>&nbsp;</p><p>有ClickHouse其他相关专家总结说，随着未来发展，云数据仓库已经变得不经济，它根本不是为实时工作负载和高度并发的访问模式而设计的。因此，我们唯一的选择是增加更多的计算量，这使得它们的扩展成本非常昂贵。</p><p>&nbsp;</p><p>从业务案例的角度来看，云数据仓库可以根据用户需求进行扩缩。许多具有普通 BI 需求的企业每月仅运行几个小时的云数据仓库来支持不频繁的访问模式和过时的数据就可以了。然而，在新世界中，我们需要有更多的服务器以更长的正常运行时间运行，以便支持所有并发用户的苛刻要求。这样的话，你会发现，如果我们假设它 24x7 运行，即使是 Snowflake 等平台的小型部署也会变得非常昂贵。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/89/89cccb56fab28c0cd0abfdf3a72900b4.jpeg\" /></p><p></p><p>在模拟的小型部署中，Snowflake 每月需额外花费 187 美元。</p><p>&nbsp;</p><p>如果在随后需要支持更多并发用户时，这种情况会显著放大。如果我们天真地通过添加更大或更多的服务器来进行扩展，那么我们将不可避免地面临昂贵的始终在线成本，并且这些成本将呈指数级变化。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b9/b95bbc54208b4503fd0f457e7dd998f4.jpeg\" /></p><p></p><p>&nbsp;</p><p>在模拟的大型部署中，Snowflake 每月需额外花费 11899 美元。</p><p>&nbsp;</p><p>在实际的大型企业部署中，这可能会迅速变成数百万美元的增量。对于高用户负载、始终在服务器上和高并发的云数据仓库来说，其经济性非常糟糕。</p><p>&nbsp;</p><p></p><h2>写在最后</h2><p></p><p>&nbsp;</p><p>现有数据技术栈高度依赖传统数据仓库，ClickHouse建议引入实时数据仓库概念，用数据湖+实时数仓方案，脱离单一云数据仓库的演变趋势。</p><p>&nbsp;</p><p>云数据仓库实现了许多人认为不可能的任务：将庞大的分析型任务从类似大型机管理的专有解决方案迁移到云端。这种演变最终引发了对如何利用仓库数据构建日益互动的数据驱动应用程序的深入研究，并导致了云数据仓库分拆的趋势不断增长。ClickHouse认为，通过分拆、采用单个分析数据库可以减少大量的ETL工作，借助简化的架构节省大量的工程和管理时间，同时降低潜在的许可和托管成本。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://mp.weixin.qq.com/s/qofX4mHYUy7TkR3JQ-dEsA\">https://mp.weixin.qq.com/s/qofX4mHYUy7TkR3JQ-dEsA</a>\"</p><p><a href=\"https://clickhouse.com/blog/the-unbundling-of-the-cloud-data-warehouse\">https://ClickHouse.com/blog/the-unbundling-of-the-cloud-data-warehouse</a>\"</p><p><a href=\"https://ensembleanalytics.io/blog/why-cloud-datawarehouses-too-expensive\">https://ensembleanalytics.io/blog/why-cloud-datawarehouses-too-expensive</a>\"</p>",
    "publish_time": "2023-11-21 16:01:37",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "OpenAI“生死存亡”时刻：95%员工或将加入微软，原OpenAI寻求与竞对合并？",
    "url": "https://www.infoq.cn/article/Vse4aLuyO2gLBozgyVbw",
    "summary": "<p>昨天，微软CEO Satya Nadella宣布Sam Altman、Greg Brockman 及其同事将加入微软，但这一决定似乎还未最终敲定。根据外媒The Verge的报道，如果让其余董事会成员下台，Sam Altman和Greg Brockman 仍然愿意重返 OpenAI 。</p><p>&nbsp;</p><p></p><h2>传Altman本人和投资人希望回归</h2><p></p><p>&nbsp;</p><p>在昨天的谈判破裂后，微软CEO Satya Nadella 迅速宣布了 Altman等人加入微软的消息，但在其之后接受 CNBC 和彭博社采访时，回答带着不确定的意味。</p><p>&nbsp;</p><p>当被问到“Sam Altman 是否会成为微软员工以及 700 名 OpenAI 员工是否会加入他的公司”时， Nadella仅表示“这由 OpenAI 董事会、管理层和员工选择”。他接着表示，微软“明确地选择与 OpenAI 合作，显然这取决于 OpenAI 的人员是留在微软还是来到微软，所以我对这两种选择都持开放态度。”</p><p>&nbsp;</p><p>此前，Atreides Management管理合伙人兼CIO Gavin Baker分析称，（ Altman等人加入后）微软的新研究实验室可能需要3-9个月才能接近OpenAI今天的水平。他们不太可能按下一个开关就立即拥有GPT-4。重要的是，OpenAI的董事会可以在达成AGI协议时解除商业协议。简单地说，如果董事会认为GPT-5是AGI，那么微软对GPT-5没有任何权利，如果使用GPT-5则将面临诉讼。</p><p>&nbsp;</p><p>当被问及微软是否要在 OpenAI 董事会中占有一席之地时，他在 CNBC 上表示，“很明显，治理方面必须做出一些改变——我们将就此与他们的董事会进行良好的对话，并随着情况的发展逐步解决这个问题。”&nbsp;在彭博社上他表示，“意外是不好的”，微软“肯定会希望进行一些治理上的变革。重要的是，我们希望确保必要的变革得以实施，以便我们能够继续与 OpenAI 合作。”</p><p>&nbsp;</p><p>当被问到“明天 OpenAI 的首席执行官是谁”时，Nadella也只是笑着说：“我会把这个问题留给 OpenAI 及其董事会。”</p><p>&nbsp;</p><p>据知情人士透露，新任首席执行官Emmett Shear 迄今为止无法获得董事会解雇奥特曼的详细理由的书面文件，该文件也没有与公司投资者分享。他在周日晚上给员工的一份说明中表示，他的首要任务是“聘请一名独立调查员，深入调查目前为止的整个过程，并生成一份完整的报告。”</p><p>&nbsp;</p><p>之后，Altman也发文道，“Satya 和我的首要任务仍然是确保 OpenAI 继续蓬勃发展。我们致力于为我们的合作伙伴和客户提供全面的运营连续性，OpenAI/微软的合作伙伴关系使该目标变得非常可行。”</p><p>&nbsp;</p><p>看得出来，Altman在努力维护OpenAI的未来发展。根据彭博社Emily Chang的说法，Altman本人和投资人都希望他回到OpenAI 。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e9/e9c9bf5d318afe580b60a6d7117c73d3.jpeg\" /></p><p></p><p>&nbsp;</p><p></p><h2>现在的OpenAI，一片混乱</h2><p></p><p>&nbsp;</p><p>目前的OpenAI已经深陷混乱之中。</p><p>&nbsp;</p><p>在OpenAI创始人Sam Altman突遭罢免后，OpenAI几乎所有的员工集体写信抗议，威胁要辞职，并加入由 Altman 负责的新宣布的微软 AI 子公司。OpenAI目前大约770名员工，截止发稿前，多达743多名员工已经签署了这封信。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d4/d45fefddc82b4c4c9aa75f18637e29e5.png\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>员工们在信中表示，微软已向他们保证，如果他们愿意加入，新子公司将给他们提供职位。信中指出，除非董事会辞职，并让Altman重新担任首席执行官，前OpenAI总裁Greg Brockman也重新归位。</p><p>&nbsp;</p><p>更为特殊的是，这封信的签名者名单中包括 OpenAI 联合创始人 Ilya Sutskever 的名字，他在X 账户上发布了一条信息，表示他对参与董事会的行为深感后悔，并补充说“我从未想过要伤害OpenAI。我热爱我们共同建立的一切，我将尽我所能让公司重新团结起来。”</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/34/3490c40fc4f3feb58850f179a7ef5f1d.jpeg\" /></p><p></p><p>&nbsp;</p><p>Altman对这条信息进行了点赞和转发。</p><p>&nbsp;</p><p>首席技术官 Mira Murati 在 Altman 离职后的混乱时期曾短暂担任临时首席执行官，她与首席运营官Brad Lightcap、首席战略官Jason Kwon、安全团队的研究科学家Joshua Achiam、产品设计Maddie Simens等人一起在 X 上发帖称，“没有员工，OpenAI 就一无是处（OpenAI is nothing without its people）。”</p><p>&nbsp;</p><p>Altman陆续给这些推文点赞，持续数个小时，看起来是一夜未眠。</p><p>&nbsp;</p><p>OpenAI员工在公开信中指出，该公司开发的ChatGPT等产品已被全球数百万人使用，迄今为止该公司“处于从未有过的强势地位”。</p><p>&nbsp;</p><p>信中写道：“解雇Sam Altman并将Greg Brockman从董事会中除名，危及了目前的这些成绩，破坏了我们的使命和我们公司。这些行为清楚地表明董事会已经没有能力监督 OpenAI。”</p><p>&nbsp;</p><p>OpenAI的董事会共6人，其中三人是公司的高管：</p><p>&nbsp;</p><p>Sam Altman，是OpenAI前CEO；Greg Brockman，是OpenAI前董事会主席兼总裁；Ilya Sutskever，是OpenAI创始人之一，首席科学家。</p><p>&nbsp;</p><p>另外三名是外部独立董事，非OpenAI员工：</p><p>&nbsp;</p><p>Adam D'Angelo，是 Quora 首席执行官，其职业生涯始于 Facebook，曾担任Facebook的首席技术官和工程副总裁。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/83/83cc12fc4b9a81a94929c768a6d4f4ba.png\" /></p><p></p><p>另一位是 Tasha McCauley， 一名女性技术创业者，GeoSim Systems的首席执行官，她有一个更为人熟知的身份是好莱坞明星囧瑟夫的妻子。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/24/24c0c817cd79657e8d06fdff7e117a24.jpeg\" /></p><p></p><p></p><p>&nbsp;</p><p>还有一位是Helen Toner，曾在牛津大学人工智能治理中心工作过，并担任乔治城安全和新兴技术中心战略总监近五年。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/af/af53401a0d013f7ba79b3c8aef2d6186.png\" /></p><p></p><p>&nbsp;</p><p>关于Altman被开除的原因，有各种猜测，阴谋论横飞。有人说是微软的布局，有人说首席科学家Ilya Sutskever先和这三位独立董事谈话，说服了他们，凑够了四票，快速的做出了开除Altman的决定。</p><p>&nbsp;</p><p>如今看来，不仅Ilya Sutskever后悔了，其他95%的员工也站到了董事会的对立面。</p><p>&nbsp;</p><p>据外媒消息，OpenAI的客户现在开始考虑转向竞争对手Anthropic、谷歌，以及微软。这些情况也让OpenAI投资者非常生气，Khosla Ventures的创始人、OpenAI 的早期支持者 Vinod Khosla 周一在《The Information》上撰写了一篇尖锐的社论，认为公司的董事会做出了 “严重的错误判断”。</p><p>&nbsp;</p><p>Thrive Capital 创始人 Josh Kushner 在 X 平台上写道，“每个问题都有解决方案”。Thrive Capital有望成为向投资者出售高达 10 亿美元 OpenAI 员工股票的主要买家，这笔交易预计将在未来几周内完成。</p><p>&nbsp;</p><p></p><h2>董事会不惜找竞对来做CEO</h2><p></p><p>&nbsp;</p><p>The Information消息，知情人士表示，OpenAI董事会与竞争对手Anthropic的联合创始人兼首席执行官Dario Amodei就两家公司合并的可能性进行了接触。该人士称，OpenAI董事会曾试图说服Amodei接替Altman 出任首席执行官。</p><p>&nbsp;</p><p>Anthropic 推出了“可与ChatGPT 匹敌”的AI 模型Claude，由OpenAI前研发主管Dario Amodei 在2021 年创立。2022 年，Anthropic 获得谷歌的3 亿美元投资，亚马逊亦在今年9 月宣布投资40 亿美元，谷歌不久前又向这家公司投资了20亿美元。据悉，谷歌和AI初创公司Anthropic 以及 Cohere正在合作开发专用的LLM。</p><p>&nbsp;</p><p>据悉，Anthropic 的7个创始人都来自OpenAI，曾经深度参与过 OpenAI 的 GPT-3、引入人类偏好的强化学习等多项研究。这些人对于为何离开OpenAI 指出，“从一开始就在模型安全性方面有着不同的愿景。”</p><p>&nbsp;</p><p>目前还不清楚合并提议是否引发了认真的讨论。但报道称，由于Amode在Anthropic的职位，他很快拒绝了CEO的邀请。</p><p>&nbsp;</p><p>据知情人士透露，OpenAl董事会还接洽了最近破产的联合办公公司WeWork的联合创始人Adam Neumann，讨论是否接任最近空缺的首席执行官一职。据了解，Neumann迅速拒绝了这一提议。</p><p>&nbsp;</p><p>另外，在Emmett Shear接受OpenAI的临时首席执行官职位之前，董事会还找过微软旗下GitHub的前首席执行官 Nat Friedman、Scale AI的联合创始人兼首席执行官 Alex Wang。知情人士表示，这两人都拒绝了。</p><p>&nbsp;</p><p>种种消息表明，OpenAI董事会在解雇Altman后，在寻找新领导人方面面临挑战。</p><p>&nbsp;</p><p>&nbsp;</p><p>相关链接：</p><p>&nbsp;</p><p><a href=\"https://www.theverge.com/2023/11/20/23969586/sam-altman-plotting-return-open-ai-microsoft\">https://www.theverge.com/2023/11/20/23969586/sam-altman-plotting-return-open-ai-microsoft</a>\"</p><p><a href=\"https://www.theinformation.com/articles/openai-approached-anthropic-about-merger\">https://www.theinformation.com/articles/openai-approached-anthropic-about-merger</a>\"</p>",
    "publish_time": "2023-11-21 16:15:41",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "是全部重做还是融合改造？揭秘京东云言犀升级全过程",
    "url": "https://www.infoq.cn/article/RyWksPY1TsNFQATOr4XD",
    "summary": "<p>采访嘉宾 | 京东云言犀团队</p><p>编辑 | Tina</p><p>&nbsp;</p><p>ChatGPT到来后，NLP（自然语言处理）这一行就有了一个梗儿：“一夜醒来，专业没了。”</p><p>&nbsp;</p><p>NLP是人工智能的一个子领域，指的是机器能够理解并解释人的写作或说话方式的能力，也是整个AI领域皇冠上的明珠，是AI领域最难、最前沿的事情。业界有说，至少五年工龄才算入门，做到得心应手也得小二十年时间，这也是不同于其他领域的地方。</p><p>&nbsp;</p><p>令人惊讶的是，这个艰深的领域，如今不断迎来技术变革。大模型的到来，更是让一些底层NLP任务不复存在。而这种变革也在以前所未有的速度卷到工业界。客服行业一直被认为是大模型最好的落地场景之一，而大型电商平台的智能客服早已打磨得十分“圆滑”。当新技术进入到一个成熟的行业，会产生哪些变化？</p><p>&nbsp;</p><p></p><h2>“老”团队遇上颠覆性的“大模型”</h2><p></p><p>&nbsp;</p><p>NLP一直以来都缺乏“杀手级”的应用和商业采用，从其历史发展历史可以分为两个阶段，前半段主要集中在“机器翻译”的发展，而后半段则伴随着互联网的蓬勃发展，涌现出一些尝试推出新产品的企业。</p><p>&nbsp;</p><p>然而，由于技术难度极高，应用场景极为复杂，这个领域的企业始终面临一个落地难、挣钱难的状况。典型的例子是，作为中国NLP初创公司的一个发展样本，追一科技倒在GPT大模型的狂潮到来前；去年底，亚马逊裁员万人对 Alexa 团队影响巨大，同时，谷歌也减少了对 <a href=\"https://arstechnica.com/gadgets/2022/10/report-google-doubles-down-on-pixel-hardware-cuts-google-assistant-support/\">Assistant</a>\" 的投资......</p><p>&nbsp;</p><p>这一系列事件反映出NLP领域技术创新与落地应用之间的不断博弈。智能客服的落地也是一样充满挑战。为了降低成本，一些组织希望引入客服机器人来代替人工，然而智能客服拟人度不够，所以很多企业，他们甚至在早几年尝试引入了客服机器人以后，很快又放弃了，就是因为他们被服务体验不足问题给吓退了。</p><p>&nbsp;</p><p>成本、效率与体验总是矛盾？在京东云言犀的介入后局面有所改变。</p><p>&nbsp;</p><p>近两三年，京东云言犀与包括大同、芜湖、东莞、保定等<a href=\"https://m.ebrun.com/516296.html\">10余个城市</a>\"合作打造了智能政务热线的大规模落地。接入言犀的大同12345政务便民热线接通率提升至100%，只要有电话进来，言犀就能够24小时不间断地接听电话。而且有市民知道接线员是智能语音接待机器人时，非常<a href=\"https://m.huanqiu.com/article/42XaItuKour\">惊讶</a>\"：“万万没想到，我说大同话机器人居然能听懂！”而且机器人态度很好，能听出电话那头“很着急”，“还安慰我说不要着急。”</p><p>&nbsp;</p><p>打造出这个智能化产品并能落地，京东花了十几年，在泛客服领域沉淀出了一支由三四百人组成的智能服务团队，涵盖了包括NLP算法、产品开发和工程交付在内的多个工种，其中不乏一二十年的老NLP人。</p><p>&nbsp;</p><p>言犀平台的打造过程，也可以划分为几个阶段。</p><p>&nbsp;</p><p>最初在2012年的时候，京东客服一年内规模翻了数倍，为了分担人工接线压力，京东成立了智能客服项目组，研发出了第一代机器人客服JIMI，功能相对简单，只能查询订单和物流情况。但将在线机器人用到大规模的电商场景中，京东是第一家。在这个阶段，能得到落地的机会，得益于企业给予团队的宽松探索环境，不怕走弯路，愿意让团队试验跟其他企业完全不同的方式。</p><p>&nbsp;</p><p>2017年，深度学习技术爆发，智能客服团队重构了这一套机器人，开始大力发展“无人客服”，该客服平台逐渐承接了自营业务60-70%的咨询量。这个阶段，京东也开始大力发展自己的AI技术，团队引入了一些更加专业的、世界级的科学家。他们带来了更先进的算法，让无人客服在原来的基础上增加了情感的分类，因此智能客服不仅学习了不同地区的方言，还能辨别人的情绪，这也是业界第一个大规模落地的商用智能客服。</p><p>&nbsp;</p><p>京东客服中心，从最开始的上百人，到2012年上千人，这么多年人数随着业务不断增长，到现在已增长至上万人，需要不断发展和提升智能客服的能力去分摊压力，也需要有智能管理平台去提升客服管理的效率。在这个时期，团队进一步将视野放大，除客服机器人之外，还有了面对C端的数字人咨询客服、直播数字人，并且涌现了新的产品形态，即客服管理，智能质检、智能培训、智能分析平台等。</p><p>&nbsp;</p><p>在满足了自有客服体系后，京东智能服务团队于2019年开始了商业化进程，并不断吸纳人才完善团队能力，形成了一支懂算法、能交付的“标杆团队”，智能服务开始对社会产生更大的价值，特别典型的就是和各地政府的12345城市热线合作。通过技术与服务的深度耦合，目前东莞12345热线咨询类直接解答率达99.4%。</p><p>&nbsp;</p><p>在智能客服行业都在争分夺秒地赶上“大模型”这趟列车的时候，京东已经开发出来了言犀大模型及配套客服产品，在内部投入使用，在客服中心取得了很好的前期试验成果，在今年的京东11.11中也发挥了巨大价值。</p><p>&nbsp;</p><p></p><h3>大模型有带来冲击吗？</h3><p></p><p>&nbsp;</p><p>人工智能发展时间非常长，从上个世纪五十年代到现在已经70多年的时间，有非常多的里程碑的节点值得大家去梳理。然而像ChatGPT这样和应用结合的这么紧密的大的技术突破，以前是没有的。每次突破都会更大一些，也是站在之前的技术的基础上做的。</p><p>&nbsp;</p><p>对于京东这样一个大企业来说，这样的技术肯定是必须要主动积极跟进的。早在2018年，一批顶级的科学家加入京东后，就开始主导底层大模型的研发。目前言犀平台依靠这五年来在大模型上的积累，在今年7月正式发布千亿级的言犀大模型，旨在服务真实业务场景，在产品革新上，发展出了下一代智能客服，即第四代智能客服。这一系统也汇聚了内部和外部的各方期望，可以说是“全村人的希望”。并且，大模型客服已在京东有了一些使用，取得了一些成效。</p><p>&nbsp;</p><p>一方面是用大模型提升C端的体验。人机对话在当前一些应用场景中发挥了巨大的价值，尤其是大促等流量高峰时段。通过阶段性的试验，这部分服务指标有比较明显的提升，言犀KA产品负责人介绍，“我们在一些环节转人工率会有明显的下降，甚至有十几个点的下降。”</p><p>&nbsp;</p><p>另一方面，大模型可以进一步提振B端应用创新，比如数字人和客服管理的效率，这部分甚至可以说是大力投入引入，并取得了实际成效。目前，言犀虚拟主播已经入驻超4000家品牌直播间，在京东等多平台都可以大规模使用数字人带货了，包括国台酒业、联想、伊利等这样的大品牌都有积极尝试。商家在直播后台上传商品链接，大模型技术驱动的数字人便能够“阅读”商品详情，找到关键的规格、卖点等信息，自动生成真实、生动、可阅读性强的直播文案，数字人还能接受咨询、提供导购、灵活互动......</p><p>&nbsp;</p><p>对于客服产品来说，大模型具有变革的力量，言犀KA产品负责人表示，“我们真的认为大模型会给未来业界带来很多的颠覆，一方面是用来解决上一代智能客服产品遇到的瓶颈问题。大模型的引入就好象注入‘活水’一样，能够把我们过去卡住、挂起来的用户体验上的问题，拿出来重新梳理并有望解决。另一方面，我们看到了一些服务模式、管理模式上的新机会，可能未来是通过人机协作的形态，有望优化这个行业多年的工作模式，这是一件让业界能兴奋起来的事情。”</p><p>&nbsp;</p><p>还有一件值得一提的事情是，大模型改造后的客服可以成为一个企业的“大脑”。客服是企业接触顾客最直接，也是最重要的一个通道，对于顾客、对于市场所有的判断，没有任何一个数据来源会比客服中心的数据更合适。因此所有的企业，都会希望客服中心能够为企业的市场决策，为企业的体验升级，为用户服务升级。通过源源不断输入客服中心的观察分析，驱动企业进行优化。这是一个一直以来没能实现的愿景。而现在，通过目前的初期试验，至少能够看到这个问题的曙光。</p><p>&nbsp;</p><p>“通过客服中心来驱动企业整体服务体验评估、服务体验管理，这其实一直是各行业的梦想和愿景。”“我们设想的愿景，还没有做得那么好，现在有了大模型，我们觉得能够利用大模型的能力，在将我们觉得效果不太好的场景里，长期持续地围绕大模型来做一些优化。”</p><p>&nbsp;</p><p></p><h3>大模型会取代原有技术吗？</h3><p></p><p>&nbsp;</p><p>那么利用大模型的智能客服，会冲击甚至取代之前经过十多年打磨出来的智能客服产品吗？特别是业界还有一个“大模型推翻了传统的NLP技术”的说法。</p><p>&nbsp;</p><p>京东云言犀团队里资深算法专家认为，大模型对一些传统技术确实有影响。因为LLM之前的模型几乎全都是专项的，任务越窄，表现越好。对于更通用、泛化的任务来说，大模型带来的效果确实是颠覆性的。拿情感分析来说，如果只是分一些正向情感、负向情感、中性情感，这样的任务上，用深度学习的方法需要有足够的标注数据。但大模型来了，就不再需要大量的标注数据了，直接判断就能达到想要的效果，和之前经过深度学习调优训练出来的效果，基本上持平。</p><p>&nbsp;</p><p>而且在理解的任务方面，很多传统的任务，大模型出来之后，确实不存在了，比如说摘要的任务，切词、分词这些中间任务。但放到客服领域来看，构建一个产品需要的并不只是理解的能力，还有推理的能力，比如说数学的加减法，大模型还不能进行精准的计算。在真实场景下，还会有一些比数学计算复杂很多的任务存在，现在大模型是解决不了的。</p><p>&nbsp;</p><p>因此，在智能客服的场景里，用户上线后，为了减少用户的费力度，智能客服会事先猜测用户大概想咨询什么问题。这个实现方式是根据用户各种各样历史的行为，比如说订单各种各样的状态，在页面上各种搜索点击的状态，以及个人用户画像等等综合信息，来判断用户当前可能会咨询什么。这样推理的问题直接交给大模型，它是很难做到的。</p><p>&nbsp;</p><p>虽然单纯NLP的理解任务，大模型很多任务能做到最好的效果，但考虑到成本的问题，其中一部分任务和之前相比也没有提升那么高，大概率也不会全部都换到大模型上面去。除了理解类任务之外的，还有很多任务可能是用传统的方法，基于一些人工标注的高质量的数据能达到的效果，而这些效果是大模型目前达不到的。</p><p>&nbsp;</p><p>所以，对于是否会取代以前的产品，言犀KA产品负责人的看法是目前并不是完全替代的关系。他进一步表示：“第四代智能客服是在前面的基础上进化的，引入大模型主要用于分析环节，对于分析之外的很多能力还是会用到第三代已经构建好的很多工程基础。”</p><p>&nbsp;</p><p>举例来说，通过分析平台，可以发现某位顾客对今天的咨询非常不满意，原因是货物配送错误，将货物发送到了错误的地方。分析平台能够快速识别这个问题并理解顾客的需求，例如重新发货和赔偿。这种能力在引入大模型后能够迅速被构建起来。但是，更深入的问题诊断需要利用第三代（即应用深度学习技术的）智能客服已经建立的基础。例如，要查明订单最初应该送到哪里以及出现错误的具体环节，可能是在收货环节出了问题，也可能是在中转过程中发生了错误。</p><p>&nbsp;</p><p>“在这些后续环节中，与第三代相比，我们会大量复用已经建立的能力基础。因此，可以理解这是一种平滑升级的能力平台，而不是完全替代的模式。”</p><p>&nbsp;</p><p></p><h2>如何重构和改造</h2><p></p><p>&nbsp;</p><p>第四代智能客服落地主要分为底层大模型和上层应用。</p><p>&nbsp;</p><p>底层大模型方面，并不能是通用的模型拿来就能用，言犀大模型面向知识密集型、任务型产业场景，解决真实产业问题，天然为零售、金融、物流等京东优势场景打造。而针对具体场景进行调优，基础模型训练和推理有专有技术团队来打造，推出了言犀AI开发计算平台。京东言犀大模型的一个优势就是部署成本低，该团队将部署成本降至了传统的1/10。</p><p>&nbsp;</p><p>降低成本一个靠的是模型量化，从浮点压到4bit、8bit，这是比较复杂的过程，因为压缩的时候会带来精度损失，怎么减少损失，保证推理效果不降，这是核心的技术。另一个是算子拆分，Transformer最核心的单元是多头注意机制，它有一系列的算子来算注意力权重，怎么把算子做的更加优化，这一块也是对提升速度有很大的帮助。还包括参数矢量的量化、内存优化、缓存等手段。“成本是非常严肃的问题，尤其是toB的时候，每一分钱都很重要。”</p><p>&nbsp;</p><p>进入新时代后，虽然算法是至关重要的因素，但现在竞争已经不再局限于算法这一单一因素，而是在于一个完整的技术和产品生态系统上的竞争。产品质量直接影响用户体验，塑造了用户的心智，一旦形成，要想改变用户偏好就变得困难重重。</p><p>&nbsp;</p><p>业内专家曾经阐述过一个观点，将大模型的竞争类比于搜索引擎，从搜索引擎的历史发展可以看出，我们可以将这个竞争划分为两个方面，即产品和技术。从技术角度来看，搜索技术迅速扩散，几乎所有垂直领域都有与之相关的搜索应用，例如美团、京东、小红书等。然而，搜索产品往往只有一个主要巨头，最多两个。搜索作为产品具有强烈的马太效应，用户本身成为了竞争壁垒，而不是技术本身。ChatGPT也面临着类似的情况。对于京东来说，大模型率先落地的产品就是智能服务系列产品。</p><p>&nbsp;</p><p></p><h3>架构融合</h3><p></p><p>&nbsp;</p><p>至于这些上层应用，不管是针对具体的任务调优，还是针对相对更通用的一个模型来端到端解决所有问题的模式，也需要针对这些任务来不断打磨大模型。</p><p>&nbsp;</p><p>以前要做好这样一个系统，其实是要把整个对话流分成很多很多，几十个、几百个模块，每个模块负责不同的任务。但大模型方法通常是端到端的，基本上是一个模块，输入一句话，输出一句话，相对比较简单。</p><p>&nbsp;</p><p>然而在实际应用中，通常并不是我们想象中的端到端的这样一步到位的方式，而是基于现有系统中的一些效果不太好的点，针对这些点，逐个将对应的模块结合大模型进行优化，能把现有的效果进一步提升。</p><p>&nbsp;</p><p>智能客服更多的时候是处理一些查询和办理任务，需要与现有系统进行交互，比如大模型在问答场景下要转人工时，需要知道转到什么样的技能组里面去。所以怎么和原有的系统结合，怎么和上下游的系统结合，怎么和内部的各种系统来打通等这些问题，都需要花费比较多的时间去梳理。</p><p>&nbsp;</p><p>在这种技术架构下，整体的堆栈不会发生巨大变化。但融入大模型之后的架构，从头到尾的复杂度相比之前也会减少一个数量级。总体而言，这个架构实际上是一个“减法”的过程，旨在优化和整合现有系统，以更好地融合大模型的能力。</p><p>&nbsp;</p><p>除了按模块进行优化之外，智能客服团队还探索性的进行重构，希望重新基于大模型来打造整个系统。这也意味着要放弃当前的框架，采用一种全新的思路，以达到让运营人员投入更少、C端用户感到更加流畅且效果更好的目标，实现一种终极的系统形态。</p><p>&nbsp;</p><p>从产品架构来看，京东的重构计划涉及到改进人与人之间的自然语言交流过程。</p><p>&nbsp;</p><p>对于智能问答系统，目前的问题在于首先需要识别用户的意图。在京东，用户的咨询问题有上万个不同的类别，例如价保、退货、订单修改等等。智能客服系统需要首先识别用户每句话所属的问题类别，然后整理与该问题相关的知识。每当用户提出问题，系统会将问题映射到相应的知识点，然后提供相关的解决方案。</p><p>&nbsp;</p><p>这对于B端来说是一项极具挑战性的工作，因为需要建立大量的知识库，而且每个知识点都需要详细梳理，有时候梳理起来非常复杂。举例来说，考虑催单这个场景，如果用户询问订单的位置，系统回应后用户表示未收到，这时系统可能需要建议联系门卫或家人是否已经代收。这只是一个小小的示例，实际上知识库中的内容是无穷无尽的，因为梳理知识的成本很高。如果知识梳理不全，应答的效果就不会很好。</p><p>&nbsp;</p><p>我们可以将这种交流比作两个人互相对话的过程，从听到一句话到做出回应，大脑中的思考过程是复杂而难以明确的。大模型的工作方式更像是这个过程的模拟，不再要求人们进行繁琐的知识整理，而是直接将原始知识提供给大模型。这包括所有与京东相关的帮助文档、政策文件、甚至历史咨询的对话记录，包括客服和人工接待的会话日志，全部交由大模型处理。基于这些知识，大模型可以直接回应当前问题。从B端的角度来看，以前需要逐一整理各种场景下的知识，而现在只需要收集数据，可能需要进行一些简单的数据清洗，但整理知识的成本大大降低了。</p><p>&nbsp;</p><p>为此，言犀沉淀了4层知识体系、40多个独立子系统、3000多个意图以及3000万个高质量问答知识点，覆盖超过1000万种自营商品的电商知识图谱，用以提升任务型对话技术能力，保障可用、可控、可信的智能对话体验。</p><p>&nbsp;</p><p>从B端的角度来看，重构能够实现成本降低和效率提高，需要的投入将大大减少，而大部分工作将交给大模型来完成。</p><p>&nbsp;</p><p></p><h3>精度提升</h3><p></p><p>&nbsp;</p><p>精度提升问题通常涉及编造问题，大模型会一本正经地胡说八道，这也是大家将大模型应用到生产时关键挑战。</p><p>&nbsp;</p><p>京东早在2020年就已经意识到Transformer技术生成的文案往往给人一种似是而非的感觉，虽然生成的文案表面上看起来很流畅，但实际内容存在问题。京东很在意这个事情，因为文案生成在电商领域被广泛应用，包括广告、推荐和新品介绍等各个方面。</p><p>&nbsp;</p><p>因此，自2020年起，京东团队开始着手研究改进这一问题，并提出了一种称为“知识注入”的预训练模型——Kplug，使文案更有忠实度、可信度和可靠度，然后还将大模型聚焦到“产业”中去调优，最终将其成功集成于言犀人工智能应用平台中。一般生成式语言模型生成的内容正确率是83%、85%左右，十个问题错一两个，一般toC用户用起来觉得还可以，但是商用是不可接受的。为了达到商用水平，京东将预训练模型正确率提升到了95%以上。</p><p>&nbsp;</p><p>为什么大模型有的时候会出现幻觉问题呢？京东云言犀团队里资深算法专家认为根本的原因是大模型底层技术原理导致的，大模型是基于历史经验来生成当前内容。这一原理下，大模型往往难以处理特别个性化的问题，尤其当缺少相关领域经验时，这一问题会更显著。</p><p>&nbsp;</p><p>在一些主观性较高的场景下，如创作较泛泛的文章，大模型表现得相对良好，因为这些情境较为主观，没有绝对的对错之分。然而，在严肃的场景中，哪怕很简单的对话，比如用户问客服自己昨天下单的苹果手机今天什么时候到，意图清晰，非常简短的问题，ChatGPT是回答不了的，它需要跟整个业务系统串起来，需要跟订单系统、物流系统等都串起来才行。</p><p>&nbsp;</p><p>言犀团队解决知识缺失问题主要分为两个阶段。第一个阶段是在初期学习时，要确定使用的语料和数据是否包含相关领域的知识。例如，像ChatGPT使用各种数据，但在零售领域，具体商品型号属性的数据相对较少，因此在这方面缺乏知识，容易编造信息。为了解决训练数据问题，京东聚焦于训练产业大模型，其中的关键在于使用多年来积累的与商品相关的数据，供大模型学习。京东训练产业大模型训练时融合70%的通用数据与30%数智供应链原生数据，包括零售、物流、健康、政务等领域的数据。尽管这些行业数据通常不在公共领域，但对于积累深度行业知识至关重要。</p><p>&nbsp;</p><p>第二个阶段是即使拥有丰富的知识，当有新产品推出时，例如此模型截至到2023年6月生成，对于在2023年6月之后推出的新产品，如何生成其文案，仍可能出现编造问题。解决知识更新的问题，言犀团队并不是直接将商品输入给大模型并让其生成文案，而是将商品的知识属性和卖点提供给大模型，并要求大模型在此基础上进行润色，以提高精度。更多地，大模型需要在预训练阶段就具备与特定领域强相关的知识，在这个基础上，在真正生成文案时再根据具体任务进行知识更新，以确保不出现编造信息的情况。</p><p>&nbsp;</p><p>在产品层面，言犀团队也根据不同场景进行了优化。目前比较有效的方式是按模块逐一优化，单独为每个任务启用大模型并进行独立调优。针对面向C端产品，提高精度主要依赖现有的专家系统，用专家系统确定系统中存在的主要问题，然后再根据问题调优模型。这意味着客服团队需要为业务定制和调整模型，以提高效果。而对于面向B端的应用，如人工客服，则是通过数据的回流和轮转来改进模型。首先使用大模型达到可用的效果，然后在上线过程中，根据B端用户的反馈和行为，不断迭代和提升模型效果。这样可以实现持续提高准确率和各项效果，达到80%甚至更高水平的目标。今年京东11.11，京小智、数字人、AI外呼等产品也接入了言犀大模型，不仅帮助品牌商家降低成本、提升效率，也给消费者们带来了全新的体验。</p><p>&nbsp;</p><p></p><h2>写在最后</h2><p></p><p>&nbsp;</p><p>京东云言犀技术团队的初衷始终如一，就是希望在严肃场景下让大模型产生价值。京东最初的出发点是利用智能客服解决内部痛点，减轻客服负担，提高营销效率。但他们也希望自家技术能深入到社会和经济领域，产生普惠价值。</p><p>&nbsp;</p><p>在ChatGPT出现之前，为了降低成本，电商、金融、政务行业已经在广泛使用智能客服替代人工客服。有研究报告指出，国内现在有88.2%的企业拥有客服业务。但它们在引入客服机器人来做智能化服务时，又存在一个很核心的矛盾，即大多数企业或政务行业都希望用比较低的成本进行运营，最多只能投入几个人的人力，所以难以打磨精致，机器人的体验难以达到大型电商智能客服的水平。京东希望能利用大模型最终实现用很少的运营成本达到满意的效果，从而让需要客服的行业都能受益。</p><p>&nbsp;</p><p>京东云言犀也在朝着这个最终目标推进，大模型客服的构建过程，还远没有结束，“现在也只能说是迈出了一小步，还在朝着最终的理想推进，还会投入更多资源和时间。”</p><p>&nbsp;</p><p></p><h4>内容推荐</h4><p></p><p></p><p>大模型风行一年多，创业新秀们都有哪些故事？实际落地中，软件产品中的 AIGC 能力又如何？本期《中国卓越技术团队访谈录 &amp; 架构师特刊》中，LeptonAI、智谱 AI、Dify.AI 和京东云言犀团队深度分享了他们的创业思路和产品经验，来自网易、百度、广推科技等企业的技术专家，也深入探讨关于 AIGC 编程、算法及应用等话题。</p><p></p><p>现在识别图中二维码即可下载电子书，查看更多、更详细的精彩内容！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d5/d56ad8016116fb700fe55eb7c8c613e5.png\" /></p><p></p>",
    "publish_time": "2023-11-21 16:43:03",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]