[
  {
    "title": "供应链实践调查报告：可感知的实践有用性与采用程度相关",
    "url": "https://www.infoq.cn/article/9boH3zd1jDZdR244gPhE",
    "summary": "<p>最近一项关于供应链安全实践的<a href=\"https://openssf.org/blog/2023/03/15/new-slsa-survey-reveals-real-world-developer-approaches-to-software-supply-chain-security/\">调查</a>\"发现，尽管一些实践已被广泛采用，但关键性实践的采用却是滞后的。该调查基于软件工件供应链等级（<a href=\"https://slsa.dev/\">Supply-chain Levels for Software Artifacts</a>\"，SLSA）框架进行。调查报告指出，关键实践，如生成来源，在采用方面是滞后的。调查还发现，人们认为实践的有用性与该实践的采用高度相关。</p><p>&nbsp;</p><p>SLSA是一个开源的安全框架，提供与供应链安全相关的标准和控制。它提出了一些预防和减轻软件供应链攻击的安全实践。这些实践分为四个等级——从完全脚本化的构建到封闭的、可重用的构建。这项调查包含了受访者对这些实践的采用、难度和感知有用性的反馈。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3e/3efc46c610f32c4428301eb3acde02b6.png\" /></p><p></p><p>部分软件供应链安全实践采用程度（来源：<a href=\"https://openssf.org/blog/2023/03/15/new-slsa-survey-reveals-real-world-developer-approaches-to-software-supply-chain-security/\">OpenSSF</a>\"）</p><p>&nbsp;</p><p>调查结果表明，一些实践已被广泛地采用。例如，超过50%的受访者表示，他们总是会使用集中式的构建服务。另外两个常用的实践是临时性构建和隔离性构建。</p><p>&nbsp;</p><p>然而，提供来源（被认为是SLSA一级所需的关键相关实践）在采用方面却是滞后的。来源是关于如何构建工件的元数据，包括所有权、来源、依赖项和构建过程的信息。</p><p>&nbsp;</p><p>报告指出，受访者认为实践的有用性程度确实与采用该实践的可能性呈正相关。报告作者建议把重点放在解释为什么实践有助于潜在地推动更多的采用上。Amélie Koran、Wendy Nather、Stewart Scott和Sara Ann Brackett最近发表的一篇<a href=\"https://www.atlanticcouncil.org/in-depth-research-reports/issue-brief/the-cases-for-using-sboms/\">文章</a>\"证实了这一发现，因为它与SBOM（软件物料清单）有关。他们指出，由于SBOM实践的价值被低估，缺乏明确定义的SBOM用例可能会导致采用程度不高。</p><p>&nbsp;</p><p>一些受访者质疑生成来源的有用性，这说明需要进一步解释这种实践的好处：</p><p></p><p></p><blockquote>这似乎是一种会带来大量文书工作的方法，并且可以在事后很容易进行回顾——“发生了这些攻击”……但却没有从一开始就阻止攻击的发生。</blockquote><p></p><p>&nbsp;</p><p>对于生成软件材料清单（SBOM）的有用性，其他受访者也有类似的看法：</p><p></p><p></p><blockquote>这是一种所有人都不喜欢的乏味的文书工作，开发者不喜欢（因为他们必须编写内容，并可能为随机依赖项做出辩护），管理层不喜欢（因为这会导致延迟和不愉快的开发），甚至是法务人员也不喜欢（因为它有可能将意外侵权变成故意侵权）。尽管如此，谨慎对待依赖项似乎是降低供应链攻击风险的唯一好方法。</blockquote><p></p><p>&nbsp;</p><p>受访者表示，一些SLSA实践，例如封闭式构建，比其他实践更难被采用。调查发现，可感知的实践难度与组织是否采用实践之间没有相关性。</p><p>&nbsp;</p><p>因为调查结果与采用相关，所以它与最近发布的<a href=\"https://www.infoq.com/news/2022/10/google-devops-2022/\">谷歌2022年Accelerate DevOps状态报告</a>\"密切一致。该报告还关注供应链安全，并同时使用了SLSA框架和NIST的<a href=\"https://csrc.nist.gov/publications/detail/sp/800-218/final\">安全软件开发框架</a>\"（SSDF）。同样，他们发现大多数受访者表示他们至少部分采用了每一种实践。</p><p>&nbsp;</p><p>关于最近SLSA++调查的更多细节可以在<a href=\"https://openssf.org/blog/2023/03/15/new-slsa-survey-reveals-real-world-developer-approaches-to-software-supply-chain-security/\">OpenSSF博客</a>\"上找到。<a href=\"https://openssf.org/blog/2023/03/09/draft-version-1-0-of-slsa-open-for-comments/\">SLSA 1.0</a>\"草案现在也开放给社区评审。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/03/slsa-survey-adoption/\">https://www.infoq.com/news/2023/03/slsa-survey-adoption/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/99ePsUu35Y6SEdaRNS1w\">Snap 首席信息安全官：我给软件供应链风险打 9.9 分（满分 10 分）</a>\"</p><p><a href=\"https://www.infoq.cn/article/4Jc6t1bpUC3HDpHzNUXI\">RPA 带来 6 位数的人力工时节约，但全民低代码时代还未到来｜顺丰供应链的数字化探索与实践</a>\"</p><p></p>",
    "publish_time": "2023-04-07 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何造出适用转速超3倍的新能源汽车高精度齿轮？双传环动：数字化功不可没",
    "url": "https://www.infoq.cn/article/69YceSjGGo7k5j8qBEkN",
    "summary": "<p>由于使用完全不同的动力系统，传统燃油车和新能源汽车的灵敏度有着天壤之别。如今，很多新能源汽车的响应时间已经达到毫秒级。这是因为新能源汽车电动机采用电机驱动，可以通过控制电流的大小精确控制电机的转速，同时转速也显著高于燃油车的发动机。</p><p></p><p>具体来说，发动机最大功率转速一般在 5,000-6,000 转/分， 而 A00 级车型电机转速约为 8,000 转/分，A0 级以上车型电机转速多为 14,000-18,000 转/分。市面上一些高端新能源汽车，其高功率电机转速更是达到了 20,000 转/分。</p><p></p><p>传动齿轮是决定这一转速大小的重要零件，通过和其它齿状机械零件传动，齿轮的主要作用是实现减速、增速、变向和换向等动作。如果精准度不够，就会直接影响齿轮与其他传动件的啮合度。当电机高速转动产生冲击载荷，传动件之间不断摩擦，轻则会使得零件寿命缩短、噪音提高，重则甚至会造成零件直接损坏，威胁驾驶安全。</p><p></p><p>换句话说，新能源汽车对齿轮的精度和质量的要求和过去的传统燃油车已经完全不在一个量级。</p><p></p><p>但是，由于我国高精度制造业发展相对落后，目前能够规模化生产精锻齿轮的企业屈指可数——浙江<a href=\"https://www.gearsnet.com/\">双环传动</a>\"机械股份有限公司（以下简称“双传环动”）是其中之一。</p><p></p><p>双传环动创建于1980年，从最开始做摩托车齿轮，到变速器齿轮、自动变速器齿轮，再到如今的新能源汽车减速器齿轮，40多年来一直在深耕机械传动齿轮行业。之所以能够在工艺上持续精进，成为如今国内精煅齿轮领域凤毛麟角的企业之一，双环传动信息化智能制造总监崔永龙告诉InfoQ，数字化在其中功不可没。</p><p></p><h2>双环传动的数字化转型“铁三角”</h2><p></p><p></p><p>和绝大多数企业一样，双传环动的数字化故事是从信息化开始的。十多年前，双环传动主要从最基础的ERP系统、OA系统、BI等一点点做起；而和其他企业可能有所不同的是，双传环动在推行信息化的同时，还上线了TPS（丰田精益生产管理模式）管理系统，包括成品条码系统、车间工票系统等等，主张信息化与精益化双管齐下。</p><p></p><p>举例来说，基于成品条码系统，双环传统生产的齿轮都会被打上批次号，产品一旦出现问题，可以立即进行追溯，包括它的钢材原料来源、出自哪个高炉、经过哪些工序等信息都可以溯源。</p><p></p><p>在此基础上，再加上多年来对车间产线和设备的自动化改造（如生产单元自动上下料、线边物料自动呼叫），这构成了双环传动“数字化转型铁三角”——信息化+<a href=\"https://www.infoq.cn/article/8eOkku2uTuU3qVFvwqhA\">精益化</a>\"+自动化。据此，双环传动工厂的产品质量控制能力和生产效率已经得到极大提升。</p><p></p><p>而此后，双环传动又上线了MES制造执行系统，并通过组建专门的信息化科研团队，自主研发了D-MOM数字化制造运营管理平台，初步构建了一套工业互联网体系。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/48/48e429f722782e69c708a6486110a41b.png\" /></p><p>D-MOM平台业务流</p><p></p><p>崔永龙强调，制造业的数字化转型，绝不仅仅是 OT与IT的融合，双环传动D-MOM平台是IT（信息技术）+ET（工程技术）+CT（通信技术）+OT（操作技术）的结果。其中， ET工程技术的重要性在于它包括了<a href=\"https://www.infoq.cn/article/lz4xxpqPCadNj181bCwP\">数字建模技术</a>\"，随着制造业升级带来的生产流程和设备复杂度增加，在虚拟环境下进行新产品、新系统、新产线进行测试模拟，可以提高产品良率，降低成本浪费。</p><p></p><p>尤其对于齿轮制造来说，其加工工艺过程要经过毛坯锻造、粗加工（齿坯加工、齿形加工、齿端加工）、 热处理、精加工（精基准修正及齿形精加工）等几大阶段，包括 20-40 道工序。不同材料、精度、大小的齿轮的处理工艺千差万别，可能需要经过大量的试验和反复仿真，才能得出最优的工艺路线。因此，ET工程技术的作用就尤为明显。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/de/de17cd684814821c067b80e156349c8d.png\" /></p><p>D-MOM数字制造运营管理平台</p><p></p><p>具体而言，双环传动D-MOM平台涉及了12+N个功能模块，包括DSS决策支持、精益研发平台、工厂布局平台、计划管理平台、精益物流平台、能源管理平台、精益<a href=\"https://www.infoq.cn/theme/161\">供应链</a>\"平台、精益产线平台、TQM全面质量、TPM设备保全、项目管理平台、刀具管理平台12个自主研发模块以及IoT物联网平台、大数据平台、5G+工业互联网、数字孪生等N个集成平台。</p><p></p><h2>追溯每一个齿轮的“前世今生”</h2><p></p><p></p><p>崔永龙表示，汽车行业对产品品质要求极高，如果出现问题，根据制度规定动辄就要召回上万辆，其中造成的成本损失巨大。所以，早在十几年前，崔永龙就主导在双环传动质量管理全流程中加入了“测”的环节，形成“人机料法环测”的全面质量管理。</p><p></p><p>如前文所说，齿轮产品是一个精密件，因此工艺流程极为复杂。其中，热处理、磨齿是高精齿轮最核心的工艺。</p><p></p><p>热处理的主要目的是增加齿轮表面硬度，加强产品机械性能。但是，由于齿轮每个面的硬度要求均有不同，这意味着在热处理中就要确保这种硬度的差异化，并且如果温度太高、太低或者冷却不均，也会导致齿轮变形，影响良率。所以，与热处理控制相关的所有过程数据，包括炉温、时间、加热方式，甚至是炉内分区等等，都要进行全面的<a href=\"https://www.infoq.cn/article/mfcsP6wws312tLTcrPCl\">数据采集</a>\"。</p><p></p><p>磨齿属于精加工工序，能够提高齿轮精度、减少噪音。“每一个齿轮的齿是磨出来的曲面，齿轮与齿轮的啮合也是曲面，如果出现一点工艺误差，在高速旋转情况下就可能导致断齿。”崔永龙解释道，为了不断提高齿轮精度，齿轮制造过程中涉及大量的参数数据采集。比如形状、材料等等，需要设置模数、齿数、压力角、齿顶高系数、公法线长度、跨测齿数、齿向公差等多个参数。</p><p></p><p>“所有这些参数首先需要通过PLM进行量化、标准化和固化，并且跟QMS质量管理有关的数据都要联动起来，实现设计+制造一体化，把参数级结构化工艺下沉到制造末端。在这些全量、全要素的数据基础上，再去做工序级的算法模型，因为缺乏数据验证的算法模型是没有价值的。”崔永龙强调，“经过持续反复的数据和模型的沉淀，再回归到工艺中去，寻找每一个环节的‘最优解’，这样就形成了一个闭环，可以实现工艺的循环迭代。”</p><p></p><p>换句话说，通过质量管理平台搭建，双环传动在内部实现了质量全面管理和精准追溯。但这远远不够，影响质量、效率、成本的环节，不仅仅发生在内部，供应商的原材料供应是否合格，供应链条的运转是否畅通，供应采购的成本浪费是否有效控制？这些问题也需要充分考虑。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/20/2070f007231610c2b5462de453c0dbe4.png\" /></p><p>数字化智造运营大脑管理平台体系</p><p></p><p>对此，双传环动搭建了物流管理平台和<a href=\"https://www.infoq.cn/article/z9DfpZCh0femWpQ6awVp\">供应链管理</a>\"平台，并把所有核心供应商都纳入其中。“基于平台的交互，我们对供应商的要求是每天报送一次供应的物料生产情况。只有实时掌握供应链条上的关键信息，才能进行精准的、前瞻性的生产运营规划。”崔永龙表示。</p><p></p><p>也就是说，在双传环动，每一个齿轮的“前世今生”都会通过数据被完整呈现出来，从而辅助实现产品精度和生产效率的精益求精。据了解，目前双环传动产品加工精度最高已经可以达到2µm（微米），适用转速高达19000转/分。</p><p></p><h2>工业互联网和5G是未来风口</h2><p></p><p></p><p>可以看到，经过10数年的摸索和实践，双环传动已经形成了一套适合自身发展的数字化方法论。崔永龙向InfoQ强调，“企业想通过上一个系统就解决所有问题是不可能的，数字化必须要有整体的设计和规划。”</p><p></p><p>而对双环传动来说，其顶层设计基于的是“1+5+1 模式”，即一个企业智能大脑，数字化设计、智能化生产、安全化管控、数字化管理、绿色化制造5大平台，通过产业链内外协同，建立集研发、制造、质控、销售、物流、客户服务为一体的“未来工厂”生态体系。</p><p></p><p>用崔永龙的话说，这套体系的核心理念，是把“人机料法环测”的思想核心要素全面扁平化到D-MOM平台上，其中，每一个模块都离不开精益思想，不仅仅是现场的精益，还包括设计、管理、经营各个环节的精益。</p><p></p><p>在此基础上，双环传动下一阶段的主要目标是推进智能化，继续以IT+ET+CT+OT为基础，把云计算平台、工业互联网平台、大数据平台等平台的建设作为重点，循序渐进地完成以下5大关键任务：</p><p></p><p>第一，实现工厂异构网络互联互通。采用工业PON技术，完成双环6个生产基地的人机物料PLC、OPC等控制网络与<a href=\"https://xie.infoq.cn/article/74d931aa859eb9679077f46c3\">5G</a>\"等其他异构网络融合；</p><p></p><p>第二，搭建OT与IT融合的网络管理系统。采用数字孪生技术，实现OT现场生产要素、生产活动、过程控制与信息空间数字化模型孪生交互，打破IT和OT之间的技术隔离和各自为政；</p><p></p><p>第三，构建企业OT- IT融合管控平台。采用工业PaaS技术，分别从OT- IT流程融合等角度，建立企业OT- IT业务平台融合平台架构，一方面实现企业OT域与IT域的设备、系统、工艺、人员、物料等资源从纵向/横向集成，另一方面，实现企业IT业务流程与现场控制流程端到端协同，建立工厂智能计算大脑；</p><p></p><p>第四，打造企业一站式智能APP服务。采用<a href=\"https://www.infoq.cn/article/O01i9lalNBIc3h1RzkuM\">微服务</a>\"技术，开发与部署覆盖企业研发、计划、生产、配送和仓储等16种场景的智能APP服务系统，并按照国家三级等保机制，建立用户安全访问、企业应用、数据、网络和设备安全等信息防护体系；</p><p></p><p>第五，实现信息安全保障。通过国家三级等保机制，实现OT- IT的访问安全、应用安全、数据安全、网络安全和设备安全。</p><p></p><p>崔永龙指出，“<a href=\"https://xie.infoq.cn/article/80716b0fc3940140f6d05fa20\">工业互联网</a>\"和5G是制造业的风口，在过去几年，双环传动把自己作为国内工业互联网发展创新的一个巨大‘试验场’，并且取得了一定突破。而未来，我们将继续引入5G、边缘计算等技术，在进一步优化双环内部生产和服务资源配置的同时，向外输出我们的技术能力，促进传统产业数字化转型升级。”</p><p></p><p>参考链接：</p><p>https://zhuanlan.zhihu.com/p/527337550</p><p>https://new.qq.com/rain/a/20210429A01XTM00</p>",
    "publish_time": "2023-04-07 10:36:21",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "新手用ChatGPT仅需数小时轻松构建零日漏洞，69家专业公司都检测不出来：“不仅能调用开源库，还能彻底重写源代码”",
    "url": "https://www.infoq.cn/article/B0WexiiEyhWzk1i9Dzmz",
    "summary": "<p></p><blockquote>ChatGPT能让 10X 工程师成为<a href=\"https://www.infoq.cn/article/hNs2LxvloB4jaBQEwEL1\"> 1000X 工程师</a>\"，同时也能让菜鸟用 1/1000 的时间编写出危害力十足的恶意软件。</blockquote><p></p><p>&nbsp;</p><p>自去年推出以来，ChatGPT以其撰写文章、诗歌、电影剧本等的能力在技术爱好者中引发轰动。而且只要给它一个写得很好、很清晰的提示，<a href=\"https://www.infoq.cn/article/HFSPasQ7SXZ9QzdFXhGO\">ChatGPT</a>\"甚至可以生成功能性代码。虽然大多数开发者会将该功能用于完全无害的目的，但最近一位自称是恶意软件开发新手的研发人员Aaron Mulgrew，花费短短几个小时，用ChatGPT整了个零日漏洞，可以用来从被攻击的设备中窃取机密数据。令人震惊的是，该恶意软件甚至逃避了谷歌VirusTotal上所有合作供应商的安全检测。</p><p>&nbsp;</p><p>Mulgrew讲道：“如果没有基于 AI 的 Chatbot ，我估计可能需要一个包含 5 到 10 名恶意软件开发人员的团队花费数周时间才能实现这么一个漏洞，尤其是还要逃避所有的安全检测机制。”</p><p>&nbsp;</p><p>这种零日攻击可以针对高价值的个人，渗透并发回其计算机里的重要文件。在实验中，Mulgrew运行可执行文件并成功将数据泄露到 Google Drive，“之所以选择Google Drive，是因为大多数组织都允许本地基础设施接入云服务。”</p><p>&nbsp;</p><p>在其博客文章中，可能因为安全原因，他忽略了“零日”内容，强调验证的目的只是让大家知道：“规避ChatGPT 现有防护有多容易；在不编写任何代码且仅使用 <a href=\"https://www.infoq.cn/article/ZRjMrDXcL4XPskS7CgzJ\">ChatGPT</a>\" 的情况下创建高级恶意软件又有多容易。”</p><p>&nbsp;</p><p></p><h2>“不仅调用了库，还让 ChatGPT 对源代码进行了完全重写”</h2><p></p><p>&nbsp;</p><p>Mulgrew来自一家跨国软件企业Forcepoint，他将自己描述为恶意软件开发的\"新手\"。这次验证，他使用的是Go执行语言，因为Go易于开发，而且自己对它比较熟悉，在需要时可以手动检查代码。</p><p>&nbsp;</p><p>Mulgrew定下的实验目标，是让渗透程序在计算机上查找一个大型PNG文件，再使用隐写术在该PNG文件中埋下入侵者希望窃取的系统敏感文件——例如客户的电子表格或产品路线图，最后将承载着数据的图像上传至由攻击者控制的Google&nbsp;Drive云存储账户。</p><p>&nbsp;</p><p>Mulgrew表示自己不想手写代码，于是只用了“提示工程”。一开始，Mulgrew直接要求ChatGPT开发恶意软件，但聊天机器人的防护机制发挥了作用，它以道德理由直截了当地拒绝执行这项任务。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/15/1535132b7ec35b6646b000a72bf82668.png\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>由于聊天机器人的护栏或多或少会阻止包含“恶意软件”表述的提示词，所以开发这款渗透工具时必须得使用一些创造性的指令。根据介绍，Mulgrew只用了两次尝试就成功回避掉了限制。</p><p>&nbsp;</p><p>第一个成功的提示是要求生成一些代码来搜索本地磁盘上大于 5MB 的 PNG。这里的设计为 5MB 的 PNG ，是因为这种大小程度足以存储高价值的商业敏感文档（如 PDF 或 DOCX）的片段。</p><p>&nbsp;</p><p>有了查找大于 5MB 的 PNG 的代码，他将其复制回控制台，并要求 ChatGPT 添加一些代码，使用隐写术（Steganography）在大文件中隐藏有价值的信息。于是ChatGPT调用了 Auyer 的现成的Steganographic库来实现它： https: //github.com/auyer/steganography</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/08/0874c61920ec9c2104583c864489a661.png\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>为了找到要窃取的高价值文档，Mulgrew要求AI编写代码来遍历用户Windows设备上的文档、桌面和AppData文件夹，并找到最大为1&nbsp;MB的所有PDF或DOCX文件。这就保证了整个文档可以被嵌入单一图像当中，并在不引发任何警报的情况下完成“偷渡”。</p><p>&nbsp;</p><p>他写道，“用提示词来组合代码片段是最简单的步骤，我只需要向ChatGPT提交一个个简单的代码片段，让它将其组合起来就行。”</p><p>&nbsp;</p><p>但由于大多数值得窃取的高价值文档可能都大于1&nbsp;MB，所以Mulgrew要求ChatGPT编写代码将这些PDF拆分成一个个100 KB的片段，再将各个片段插入自己的PNG中。这些片段最终全部被泄露到了攻击者的云存储账户中，整个过程用到了“四、五条指示”。</p><p>&nbsp;</p><p>有网友指出这需要对源代码进行完全重写，以增加其对检测的抵抗力，这项工作非常重要，需要花费大量时间。但实际上Mulgrew只是通过给ChatGPT 下达指令，通过简单的“提示工程”就达到了目的。</p><p>&nbsp;</p><p></p><h2>轻松逃避掉专业机构的检测</h2><p></p><p>&nbsp;</p><p>接下来，Mulgrew希望保证自己的最终可执行文件不会被VirusTotal检测到。VirusTotal会通过各种防病毒检查程序检测实际运行的文件，查看其中是否包含恶意二进制文件。</p><p>&nbsp;</p><p>一开始，有5家供应商将文件标记为恶意文件。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d3/d368c138cb4149b8dfd03a0aa744075a.png\" /></p><p></p><p>&nbsp;</p><p>通过一些调整——比如要求ChatGPT将程序的启动时间延迟两分钟，这能骗过部分防病毒工具。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/58/582d901f553c0fccd8e981070a1d6269.png\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>另外一个方式是利用混淆代码手段。虽然一开始Mulgrew要求ChatGPT混淆代码时，他遭到了拒绝，但将提示更改为要求 ChatGPT 将所有变量更改为随机的英文时，它很乐意执行。最终在未触发任何警报的情况下，Mulgrew绕开了VirusTotal的“法眼”，最终没有一家公司的产品能将这个漏洞“检测”出来。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c3/c3f56f53b399d1e661fd3f6ab413e2a7.png\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>Mulgrew的说法应该是可信的，毕竟VirusTotal的主要功能是捕捉已知的恶意程序。新的恶意软件往往不会立即激发仪表板。虽然也有部分检测引擎会使用沙箱来捕捉新样本中的恶意活动并触发警报，但技术高超的攻击者还是可以找到回避路径——不靠AI聊天机器人也能做到。</p><p>&nbsp;</p><p>更重要的是，虽然ChatGPT能够识别出“混淆代码以避免检测”等命令并加以阻止，但攻击者们要想使唤这位强大的助手，在提示词中融入更多创意就行。</p><p>&nbsp;</p><p></p><h2>写在最后</h2><p></p><p>&nbsp;</p><p>在 ChatGPT 的帮助下，一名自认是新手的人已经能够在短短几个小时内创建出等效的恶意软件，这是一件令人担忧的事情。在这种发展趋势下，当前的工具集可能会因为 ChatGPT 出现大量恶意软件。</p><p>&nbsp;</p><p>欺骗 ChatGPT 去做它不应该做的事情如此容易，这让一些网友感到害怕，是不是有一天AI还可能“扫描所有文档，然后将它们全部上传到某个云存储上？！那我们就完蛋了！”</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c5/c5651fe0d420937af4d76ea987f8d059.jpeg\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>Mulgrew表示，虽然他的示例使用了一些让 ChatGPT 绕过现代防御的方法，但我们也不是没有办法来减轻威胁。以下是 ChatGPT 自己关于防范这种攻击的建议：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/83/836a290a06fa29b1b0f97f0f02e71490.png\" /></p><p></p><p>&nbsp;</p><p>即：监控网络流量（但这种防不了图像隐写）、阻止可疑流量、实施访问控制、使用加密、培训员工、定期检测和升级。另外还可以实施“零信任”机制，通过清除相关图像，防止包含隐写术的图像从组织里泄露出去。&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.theregister.com/2023/04/04/chatgpt_exfiltration_tool/\">https://www.theregister.com/2023/04/04/chatgpt_exfiltration_tool/</a>\"</p><p><a href=\"https://www.forcepoint.com/blog/x-labs/zero-day-exfiltration-using-chatgpt-prompts\">https://www.forcepoint.com/blog/x-labs/zero-day-exfiltration-using-chatgpt-prompts</a>\"</p>",
    "publish_time": "2023-04-07 10:40:54",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何保证 Java 应用安全？",
    "url": "https://www.infoq.cn/article/SaSzIFWsdTYEiGzADCq1",
    "summary": "<p>“请问我怎么才能保证 Java 程序内存中密码的安全呢？”如果你也过有类似的问题，并且在网上搜到一些并不十分完善却又无可奈何的答案，说明你就是 Java 程序安全性问题的 stakeholder。</p><p></p><p>这个问题的标准答案是 Java 机密计算技术，它将机密计算技术引入 Java 的世界，为 Java 程序的安全性带来了重大的提升。基于此，龙蜥社区云原生机密计算 SIG 推出了 Java 机密计算的具体实现技术——Teaclave Java TEE SDK， 以下简称 Teaclave Java。该技术具有以下显著优点：</p><p></p><p>全场景安全性。当用户有机密计算硬件支持时，Teaclave Java 可以实现最高安全等级的 Java 可信计算；当用户没有相关硬件时，退化为安全沙箱隔离级别的可信计算，亦可有效保护用户的敏感数据和计算过程的安全性。开发和构建简单。基于 SPI 的纯 Java 编程模型，一键式构建，将 Java 机密计算开发构建门槛一降到底。</p><p></p><p>Teaclave Java 已经过企业级内部场景的验证，在 Apache 社区开源。描述本技术的论文由龙蜥社区云原生机密计算 SIG 与上海交通大学、大连理工大学合作发表在软件工程顶会 ICSE 2023（https://conf.researchr.org/home/icse-2023）上，并且获得了本届会议的 ACM SIGSOFT 杰出论文奖。这是 2020 年以来，龙蜥社区云原生机密计算 SIG、上海交通大学、大连理工大学首次获此殊荣。</p><p></p><h2>问题的本质</h2><p></p><p></p><p>这个问题的本质是如何在具有风险的运行时环境中安全地使用敏感数据。当我们在运行时将密码解密后，密码就会以明文的形式存在于内存中，也就是 Java 的堆上，如图 1 的左半部分所示。如果系统遭受攻击，比如 2021 年声名大噪的 log4j 漏洞攻击，Java 堆上的内容就会被窃取。即便没有被攻击，在为了性能诊断而做 heap dump 时也有可能主动将敏感信息泄漏出去。所以将诸如密码这样的安全敏感信息暴露在普通运行环境具有高度的风险。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/28/286ca99a6d25c26e3c67e72b393e8fba.png\" /></p><p></p><p>一种保护思路是尽可能地缩短明文密码在内存中的存放时间，以缩短敏感信息暴露的时间窗口。</p><p></p><p>如图 1 右半部分所示，在使用完密码后，及时将其从内存中销毁，这样会比先前更加安全一些。因为密码是文本信息，会用字符串类&nbsp;java.lang.String&nbsp;保存。Java 的 String 是一种 immutable 类型，创建后不能更改内容，所以没有可以重置内容的 API。要销毁密码只能通过反射将 String 类内部保存字符内容的数组内容置空，从而将密码内容从 Java 堆上抹去。直接将密码字符串设置为 null 是没有用的，这样只是把 String 变量的指针设为空，对于 Java 堆上的密码数据没有任何影响，只有等到下次垃圾回收时才有可能将密码数据从堆中清除。</p><p></p><p>另一种方法是用 char 数组保存密码，而不是 String 类，这样就不必调用反射，让销毁更加便利。还有一种方法是用 byte 数组保存密码，因为其明文是字符编码而非人可读的字符，所以会更难被人看懂。</p><p>这些就是目前可以从网络上搜到的解决方法，本文将它们称为“朴素”的 Java 密码保护方案。因为这些方案只是缩短了明文密码在 Java 堆上的生存时间，并没有真正将明文密码保护起来。而且“及时”一词有很大的弹性，开发人员未必能准确地判断出何时才是及时。</p><p></p><p>更具有典型性的案例就是著名的 log4j 漏洞问题（https://nvd.nist.gov/vuln/detail/CVE-2021-44228）。攻击者可以利用 log4j 2.14 的漏洞将恶意 class 文件上传到服务器并通过 Java 的动态类加载机制运行，从而窃取 Java 堆中保存的服务器私钥。有了私钥，服务器与客户端之间的所有通信内容对于攻击者都如同明文了。</p><p></p><p>在以上两个例子中，需要在运行时保护的密码和密钥都是安全敏感的数据。而在实际场景中，保护范围并不仅限于敏感数据，还有可能扩大到运算过程。比如鉴权认证场景中，需要保证认证的过程可信，不能被攻击者篡改。再比如云服务的用户将自己的算法部署上云时，虽然部署的制品可以加密，以保护传输和存储时的安全，云厂商提供了固若金汤的安全防护以免受外部攻击，但是用户依然会担心云厂商有没有在运行时窥探用户的计算过程，是否存在监守自盗的可能。</p><p></p><p>由此可见，保护 Java 应用中的安全敏感数据和运算并不是一件遥远的需求，而是具有迫切的现实意义的需求。对于云计算的供应商，让用户相信其敏感数据和运算对于云厂商自己也是不可见的黑盒亦具有重大的商业价值。</p><p></p><h2>Java 机密计算现状</h2><p></p><p></p><p>保护运行时的敏感数据并不是一个新鲜话题，而属于迄今已发展了 20 多年的技术——机密计算的一部分。机密计算是一种提供硬件级的系统隔离，以保障数据安全和程序运行安全的技术。机密计算将执行环境划分为富执行环境（Rich Execution Environment，REE）和可信执行环境（Trusted Execution Environment, TEE），认为 REE 和 TEE 应该相互隔离，TEE 需要通过硬件加密以保证外界无法知晓其中的内容。安全敏感的内容应该放在 TEE 中运行，其他内容则在 REE 中执行。</p><p></p><p>这套机制早在 1999 年就已提出，不过早期的硬件加密技术能力有限，仅有支持执行加解密程序的 TPM（可信任的平台模块，Trusted Platform Module）硬件。2008 年 Arm 发布 TrustZone 技术白皮书，以支持 Arm 平台的通用型机密计算任务。2015 年Intel也推出了带有支持通用应用加密的 SGX（软件保护扩展，Software Guard Extension）芯片的硬件设备，2021 年 SGX 升级为可支持 1T 内存、具有更高性能的SGX2。</p><p></p><p>机密计算的核心理念是在具有被攻击风险的运行时环境中提供一块安全区域供安全敏感程序运行，实现了安全敏感数据和程序在传输、存储和计算全流程的安全可信。目前机密计算在隐私安全、区块链、多方计算、IoT 和边缘设备，以及个人计算设备上均有广泛的应用和广阔的前景。</p><p></p><p>看起来机密计算技术正是解决 Java 程序安全性问题的标准答案，那么我们是否能够在 Java 应用中应用机密计算技术呢？</p><p></p><h4>Occlum – 在 TEE 中放入 JVM 和应用整体</h4><p></p><p></p><p>SGX、TrustZone 等为通用型机密计算提供了硬件基础，Intel、微软等开源的驱动和SDK 则为通用型机密计算提供了软件基础。基于这些软硬件基础，开发者已经可以在软件应用中使用机密计算。但是机密计算对于 Java 应用并不友好，因为 TEE 中只能运行 native 程序，所以 Java 程序并不能直接运行于 TEE 中。要在 TEE 中运行 Java 程序，就必须先在 TEE 中启动一个JVM，然后在 JVM 上执行 Java 程序。那么是否能在 TEE 中运行 JVM 呢？答案是肯定的，那就是 Occlum，其原理如图 2 所示。</p><p></p><p>Occlum 是介于 TEE 底层 SDK 与 JVM 之间的一层 LibOS，作为操作系统支持普通 JVM 在 TEE 中的运行。用户将包含了机密代码在内的整个 Java 程序部署在 TEE 中，由 Occlum 支持 JVM 执行。图 2 右半部分给出了部署的结构，其中黄色的 APP 代表整个 Java 应用及其所需三方库，红色圆圈代表可信代码。应用通过 REE 中的启动器——通常只是一个很小的命令行工具，启动执行。这种方案的兼容性好，用户基本不需要修改原有代码即可获得机密计算支持。但是缺点也很明显——放入 TEE 的代码太多，会导致两个问题：</p><p></p><p>安全性下降。原本需要在 TEE 中执行的可信程序可能并不多，但是此方案需要将所有的 Java 程序、三方库、JVM 和 LibOS 全部放入 TEE，导致 TCB（可信计算基，Trusted Computing Base）太大，安全性并不理想。TCB 是安全领域衡量安全性的重要指标，指信任的代码量。TCB 越大，其中可能存在安全隐患的代码就越多，程序的安全性就越差，所以 TCB 越小越好。以 log4j 攻击为例，Occlum 仍然无法对其免疫。因为 log4j 库与机密代码并没有被分隔在不同的执行环境中，而都部署在 TEE 中，所以攻击者上传的恶意类文件也会位于 TEE 中，仍然可以从内存中访问到私钥。性能下降。TEE 的硬件不是通用硬件，与 REE 相比存在性能退化，所以将应用整体放入 TEE 中会导致整个应用的性能下降。但用户原本的需求只是局部加密，为了局部加密而导致整体性能下降会增大应用机密计算的成本。虽然一般用户可以接受为了安全而产生的部分性能退化，但是对于过度加密产生的额外性能退化会感到难以接受。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b6/b61773a290302665b5a1f744ce83c94a.png\" /></p><p></p><p>综上可见，Occlum 方案虽然具有简单易行的优势，但是其在安全性和性能方面的缺点却是其投入实际应用的主要障碍。</p><p></p><h2>Teaclave Java TEE SDK – 在 TEE 中仅放入可信代码</h2><p></p><p></p><p>因为在 TEE 中整体支持 JVM 和全部应用程序的方案会在 TEE 中执行过多的代码，导致安全性和性能下降而难以投入实用，能不能换种思路，仅将可信代码放入 TEE 呢？考虑到 TEE 中只能执行 native code，那么是不是可以将可信代码从 Java 代码直接编译为 native code 放入 TEE 运行呢？答案是肯定的，这就是本文的主角Teaclave Java TEE SDK，以下简称Teaclave Java。</p><p></p><p>Teaclave Java 是由 JVM 团队开发的 Java 机密计算开发框架和构建工具链，可以一站式快速实现 Java 机密计算应用的开发和构建。退一步考虑，即使用户没有支持机密计算的硬件环境，Teaclave Java 也可以实现安全沙箱隔离，有效保障敏感数据和程序的运行时安全。</p><p></p><p>Teaclave Java 的关键技术特性有：</p><p></p><p>模块分隔、机密计算服务化，如图 3 所示。简洁完善的机密计算服务生命周期管理API。Java 静态编译机密内容。隐藏实现细节、自动生成所有辅助代码。</p><p></p><p>在这些技术的支持下，Teaclave Java 能够将从普通模块到机密模块的 Java 模块间服务调用转为从普通模块到机密 native 库的函数调用，如图 4 所示。</p><p></p><h4>模块分隔、机密计算服务化</h4><p></p><p></p><p>Teaclave Java 将应用代码分为三个模块，Host、Enclave 和 Common。Host 中是普通的安全非敏感程序，Enclave 中是安全敏感程序，Common 中则是前两者都会用到的公共代码。这种模块划分方式一是为了让开发者感知到代码的安全性区分，二是为了构建时针对不同模块使用不同工具链的便利性。</p><p></p><p>Host 和 Enclave是解耦合的，它们之间只能通过 Java 的 SPI（Service Provider Interface）机制交互，而不能直接调用。机密计算的实现在 Enclave 模块中被封装成为了服务，其接口声明定义在 Common 模块中，并用@EnclaveService 注解标识。当 Host 中的程序需要用到某一机密计算任务时，就可以先加载服务实例，再调用相应的函数。这一结构组织关系如图 3 所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a1/a1f55e64930627aea156ee9addc23f2a.png\" /></p><p></p><p>例如我们可以在 Common 中声明一个如代码块 1 所示的机密计算服务接口，其中提供了用于认证加密的密码是否有效的 API，authenticate 函数。该函数接受一个用户传入的加密的密码，返回该密码的认证结果。</p><p></p><p>代码块 1：在 Common 模块定义机密计算服务接口声明示例</p><p><code lang=\"text\">@EnclaveService\npublic interface AuthenticationService {\n    /**\n     * Given an encrypted input password, check if it is the correct password.\n     * @param inputPwd the encrypted password to be authenticated\n     * @return true if the given password is correct.\n     */\n    boolean authenticate(String inputPwd);\n}</code></p><p></p><p>AuthenticationService 接口的具体实现则在 Enclave 模块的 AuthenticationServiceImpl 类中定义，如代码块 2 所示。该类的 authenticate 函数先使用私钥对输入的加密字符串解密，获得明文结果，然后将其和内存中保存的正确的密码比对，再返回是否一致的检查结果。该类中保存的正确密码值和私钥都是安全敏感数据，authenticate 函数的实现也是安全敏感运算。它们都将在 TEE 中运行，以黑盒的形式提供给外部使用。从外部只能看到加密的输入数据和返回的判定结果，而无法窥探到实际的运行过程和数据。</p><p></p><p>代码块 2 在 Enclave 模块定义机密计算服务接口实现示例</p><p><code lang=\"text\">public class AuthenticationServiceImpl implements AuthenticationService {\n\nprivate String pwd = \"somePwd\"; // assume it's got at runtime.\n\n@Override\npublic boolean authenticate(String inputPwd) {\n    String decryptedInputPwd = decrypt(inputPwd);\n    return pwd.equals(decryptedInputPwd);\n}\n\nprivate static String decrypt(String inputPwd) {\n    return inputPwd; // assume it's decrypted with private key\n}\n}</code></p><p></p><p>Host 模块使用机密计算服务的代码示例如代码块 3 所示，从中可以看到对机密计算服务 AuthenticationService 接口的使用和普通的 SPI 接口别无二致，依然是加载服务、调用函数、根据结果执行不同的动作等过程。稍有区别的地方在于先要创建出机密计算环境 Enclave 的实例，然后从中加载机密计算服务实例，由此将机密计算的服务实例和环境实例绑定，最后再销毁环境。这些机密计算环境生命周期管理的 API 由Teaclave Java 提供。从代码块 3 中可见，在 Host 模块中无需感知密码和私钥究竟是什么，也不用了解认证的过程，只是将认证函数当作黑盒服务调用。</p><p></p><p>代码块 3 从 Host 模块使用机密计算服务示例</p><p><code lang=\"text\">public class Main {\n    public static void main(String[] args) throws Exception {\n        Enclave enclave = EnclaveFactory.create();\n        Iterator services = enclave.load(AuthenticationService.class);\n        String pwd = \"encryptedPwd\"; // assume this is an encrypted password\n        while (services.hasNext()) {\n            AuthenticationService authenticationService = services.next();\n            if (authenticationService.authenticate(pwd)) {\n                System.out.println(\"Passed\");\n            } else {\n                System.out.println(\"Rejected\");\n            }\n        }\n        enclave.destroy();\n    }\n}</code></p><p></p><p>以上三部分代码就构成了一个完整的 Java 机密计算应用。从开发的角度看起来与编写一个普通的 SPI 服务调用的应用基本一样，只需要专注于业务逻辑的开发即可，并不需要学习机密计算底层的内容。因此 Teaclave Java 将 Java 机密计算的开发门槛降低到了 0。</p><p></p><h4>构建机密计算应用</h4><p></p><p></p><p>Teaclave Java 提供了一套完整的构建工具链以支持上文所述的编程模型，用户只需输入几个简单的 maven 命令即可完成全部构建任务。构建工具链将非机密代码和机密代码分别编译为 Java bytecode 产物和可部署于 SGX 中的 native 库，以及自动生成完成机密计算服务调用所需的所有的辅助代码。</p><p></p><p>图 4 展示了 Teaclave Java 的构建部署视图，主要包括三方面内容：</p><p></p><p>1）Host 和 Common 模块被编译为普通的 Java bytecode，部署在普通环境中执行。</p><p>2）Enclave 和它所使用到的 Common 模块中的内容被编译为 native 机密库文件，部署在 SGX 硬件中执行。</p><p>3）从 Java bytecode 到 native code 之间并不能直接调用，而需要一些适配转换工作，包括：</p><p>服务代理：通过J ava 的动态代理机制将Host模块中的机密计算服务调用代理到实际的native函数上，并完成上下文环境的同步、服务参数和返回值的序列化反序列化等工作。</p><p>JNI 层：Java 侧的 native 函数声明、native 侧的 JNI 函数声明和到机密库函数的调用等辅助代码。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bc/bc882cfd43626c3bd7ecdeecf269c733.png\" /></p><p></p><p>这些适配转换调用的代码在构建中被自动生成，分别部署在普通环境和 SGX 中，在图 4 中它们被用蓝色标出。</p><p></p><p>构建过程中的重要一步是将机密部分的 Java 代码编译为 native 代码的 Java 静态编译。</p><p></p><h4>Java 静态编译</h4><p></p><p></p><p>Java 程序原本需要在 JVM 上才能运行，但是 Java 静态编译技术可以将 Java 程序（包括JDK库依赖和三方库依赖）加上必要的运行时支持代码一起编译为 native 代码，然后直接运行。以此实现了 Java 程序无需 JVM 的轻量级运行。</p><p></p><p>Teaclave Java 采用了目前最成熟的 Java 静态编译技术——Oracle 主导的开源项目GraalVM 进行 Java 静态编译。GraalVM 首先对 Java 程序做可达性分析，找到从程序入口开始的所有可能执行到的代码范围，然后仅编译这些可达的代码，得到一个native 制品（被称为 native image）。程序入口对于可执行程序来说是 main 函数，对于库文件来说是暴露的公共 API。具体到 Teaclave Java 场景，入口就是开发者定义的机密计算服务函数，也就是 Enclave 模块中定义的机密计算服务接口的实现函数。这些接口实现会用到三种依赖，Common 模块中的代码、某些 JDK 库以及其他Java 三方库，但是只会用到这些依赖的部分代码，而非全部代码。</p><p></p><p>GraalVM 就会将实际用到的代码分析出来，与机密计算服务的实现代码和 GraalVM 提供的运行时支持（被称为Substrate VM）一起编译为 native image。但是 GraalVM 是面向通用场景和硬件平台的，所以 Teaclave Java 为其额外提供了针对 SGX 硬件平台的适配和机密计算需求的优化。当我们编译出 native image 后，会发现其具有了一些特别的性质：</p><p></p><p>TCB 下降。GraalVM 仅编译从机密计算服务入口可达的代码，因此与 Occlum 将LibOS、JVM 和 Java 应用全部放入 TEE 的方案相比，TCB 大幅降低了。安全性提升。Native image 在运行时有自己的 native 内存堆，它与 Java 堆是相互隔离的，从 Java 应用中很难被访问到（Java 通过 Unsafe 接口依然可以访问 native 内存，但是难度提升很多）。而且 Java 静态编译去掉了 Java 的动态特性，只有在编译时经过显式配置的反射和动态类加载才会生效，其他运行时的动态行为是无效的。Log4j 漏洞攻击在 native image 上本身就是无效的。因此native image可以被视作一个安全沙箱，即使没有 SGX 硬件环境，native image 相比 Java 程序也提升了安全性。部署在 SGX 里之后，TEE 的安全性会更高，因为消除了Java动态特性对 TEE 安全性的威胁。性能提升。GraalVM 的 Java 静态编译对代码有相当程度的编译优化，其运行时性能大致可以达到 JVM 的 C1 优化水平，再加上无需启动 JVM、没有类加载过程、没有解释执行、没有 JIT 消耗资源等等，在执行短小的任务时与 Java 程序相比能有 1 个数量级的性能提升，内存也有大幅削减。</p><p>这些性质可以有效地提升机密程序的安全性，提升了 Teaclave Java 的实用性。</p><p></p><h2>Teaclave Java 技术评估</h2><p></p><p></p><p>以上介绍了 Teaclave Java 提供的 Java 机密计算编程模型和采用的构建方式等技术问题，那么最终实现的效果如何呢？本文以 log4j 漏洞攻击为例分析 Teaclave Java 的功能有效性。</p><p></p><p>在 TCB 改进和运行时性能分析方面，我们准备了如表格 1 所示的 10 个测试。前 4 个“app-”前缀的是我们自己写的简单应用，将它们当作机密程序，以各自的 main 入口当作普通程序。后 6 个“ct-”前缀的用例则采用了著名开源加密框架 BouncyCastle&nbsp;（https://www.bouncycastle.org/java.html）的单元测试，我们提供了单一入口调用这些测试，将测试入口当作普通程序，单元测试当作机密程序。</p><p></p><p></p><p>（表&nbsp;1&nbsp;/ 测试用例描述）</p><p></p><p>Java 机密计算框架则采用了 OcclumJ 和 Teaclave Java 进行对比。OcclumJ 是我们实现的一种介于 Occlum 和 Teaclave Java 之间的机密计算模型，采用 Teaclave Java 的模块化和机密计算服务化的模型，但是不做 Java 静态编译，而是在 TEE 中以 Occlum 方式运行机密计算服务。</p><p></p><h4>功能有效性评估</h4><p></p><p></p><p>图 5 给出了 log4j 漏洞攻击的原理示意（a 子图）和 Teaclave Java 防范 log4j 漏洞攻击的原理（b子图）。对于一个普通的 Java 应用服务，它和客户端通过三个步骤交互。</p><p></p><p>1）客户端从服务端获取公钥。</p><p>2）客户端用公钥对消息加密，然后将密文发送给服务端。</p><p>3）服务端从运行时内存中拿出私钥解密消息，然后再处理消息内容。假设服务端使用了 log4j-2.14.x 版本做日志记录，其中的漏洞允许攻击者诱导 log4j 从远程服务器下载指定的恶意 class 文件（图 5-a中的步骤4、5、6），然后动态加载恶意类，从 Java 堆内存上获取到私钥（步骤7）传给攻击者。</p><p></p><p>有了服务器的私钥，服务器和客户端之间的所有通信对于攻击者而言都如同明文了。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c7/c7d22a774cee45393a2b1f7a139869fd.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fd/fd7d18bc02d7243b2c8b28f76917a203.png\" /></p><p>（图 5 /&nbsp;Java 机密计算保护应用免 受Log4j 漏洞攻击示意图）</p><p></p><p>图 5-b 展示了 Teaclave Java 如何保护应用服务端免受 log4j 漏洞攻击的威胁。Teaclave Java 将应用的普通代码放在 REE 中，安全敏感的解密和私钥放在 TEE 中，客户端送来加密消息会被 REE 中的代理服务转到 TEE 中进行解密。此时当攻击者发起 log4j 攻击时，因为 Log4j 部署在 REE 中，恶意代码也只能在 REE 中运行，而无法拿到 TEE 内存上的私钥，攻击失效。假如机密代码也使用了 log4j 记日志，导致 log4j 运行在 TEE 中运行会发生什么呢？</p><p></p><p>此时 log4j 将攻击者恶意代码下载到了 TEE 中，但是因为 Teaclave Java 采用了 Java 静态编译技术，恶意代码在编译时是未知的，不会被编译到 native image 中。而 Java 静态编译技术并不支持对 native image 中不存在的代码进行动态加载执行，所以即便恶意类被下载到了 TEE，也不会被执行。因此在这种场景下 Teaclave Java 支持的机密计算依然是安全的。但是如果采用了 Occlum 方案，因为 TEE 中有了 JVM，就可以动态加载恶意代码并运行，攻击就会成功。</p><p></p><p>再退一步，当在没有 SGX 硬件为TEE加密时，native image 依然是一个 native 沙箱，恶意 Java 代码无法轻易从 native 内存中拿到安全敏感内容。</p><p></p><h4>TCB 评估</h4><p></p><p></p><p>因为 Teaclave Java 不再需要 LibOS 和 JVM，机密代码部分也是按需编译部署。OcclumJ 方案虽然采用了分模块模型，但是并没有做静态分析，因此只是模块级别的代码划分，虽然较 Occlum 完全不划分有所改进，但是与 Teaclave Java 函数级的划分相比仍有相当大的差距。图 6 展示了 OcclumJ 和 Teaclave Java 放入 TEE 的二进制编译产物的大小对比。蓝条是 OcclumJ 的结果，橙条是 Teaclave Java 的结果，图中的 Lejacon 是 Teaclave Java 在论文中的代号。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2f/2fe5e8d6f7df0780da6dc3d0cfeb1d37.png\" /></p><p></p><p>由图 6 中的对比数据可见，Teaclave Java 的编译后 TCB 大小仅为 Occlum 的大约1/20 到 1/10。考虑到编译时 native 代码的膨胀问题，两者实际的函数数量差距更大，所以 Teaclave Java 的 TCB 低于 Occlum 一个数量级，从而具有了更高的安全性。</p><p></p><h4>运行时性能评估</h4><p></p><p></p><p>因为 native image 会直接以 native 代码的形式运行，省去了包括 JVM 启动、类加载、解释执行等步骤的 Java 程序的冷启动过程，所以启动速度会非常快。如果要执行的机密代码较少，会很快执行完毕。但是 native image 的代码编译质量不如 JVM 的 C2，所以当程序执行的时间足够长，Java 代码被 JIT 充分编译后，native image 的运行时性能就会随着时间的增长而与 Java 程序越来越接近，然后被超越。所以 Teaclave Java 在小型应用的性能远优于 OcclumJ，但是在长时间执行的应用方面该优势就会缩小。</p><p></p><p>图 7 就展现出了这一特点。图中的蓝线是机密代码部分采用 OcclumJ 模型的执行时间，黄线是采用 Teaclave Java 模型的执行时间，绿线是在普通环境中在普通 JVM 上直接运行的时间。程序在 TEE 中运行的时间要大于普通环境，主要因为增加了机密环境的创建、机密内存的分配等开销，我们将其统称为机密环境开销。黄线在执行时间较短的场景中保持了与绿线接近的性能，说明 Java 程序冷启动的开销与 native &nbsp;image 的机密环境开销差不多可以相抵。当程序执行时间较长时，冷启动开销被摊薄，但是机密环境开销与TEE内存使用量成正比，所以黄线较绿线在最后三个测试用例上的上升线条更陡峭。</p><p></p><p>图 8 给出了 OcclumJ 和 Teaclave Java 的运行时内存使用量对比。OcclumJ 的内存消耗包括 LibOS、JVM 和应用三部分，而 Teaclave Java 模型的内存消耗只有应用和 native image 中的轻量级运行时。更简化的结构为 Teaclave Java 模式的机密计算带来了更少的内存消耗。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b7/b76489453d64f493be359682468505ea.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2b/2b691aee9a5696c098f941ffe5926e58.png\" /></p><p></p><h2>总结</h2><p></p><p></p><p>Teaclave Java 是一个使用简单、效果显著、性能良好的 Java 机密计算解决方案，能够帮助用户彻底解决保护 Java 应用中的安全敏感内容和运算的问题。Teaclave Java 具有硬件宽容性，当具备 SGX 硬件环境时，可以使 Java 用户也能像其他 native 语言用户一样享受到机密计算带来的最高等级运行时安全保护；在缺少机密计算的硬件环境时，仍然可以提供安全沙箱对机密代码实施内存隔离，以避免安全敏感内容直接暴露。可以说，Teaclave Java 就是保护 Java 应用中敏感数据和运算安全的标准答案。</p><p></p><p>Oracle 已经把 GraalVM 的 Java 静态编译技术贡献给了 OpenJDK，预计在 JDK 21 会合入 OpenJDK 主干。因此在未来 Teaclave Java 方案就可以获得 JDK 的原生支持。我们也计划向 Java 社区提交关于增加机密计算规范的文件，希望可以将 Teaclave Java 的机密计算模型上升为Java原生的机密计算方案。</p><p></p><p>本技术发表的论文为：Xinyuan Miao, Ziyi Lin, Shaojun Wang, Lei Yu, Sanhong Li, Zihan Wang, Pengbo Nie, Yuting Chen, Beijun Shen, He Jiang. Lejacon: A Lightweight and Efficient Approach to Java Confidential Computing on SGX. ICSE 2023.</p><p>论文链接：</p><p>https://ddst.sjtu.edu.cn/Management/Upload/[News]a845acae286b470bb55013c1b5e425e2/20232101456536725sSV.pdf</p><p></p><p>Teaclave Java 项目的源代码已经贡献到了 Apache 社区，加入机密计算框架Teaclave 项目，目前正在开源孵化中。</p><p>项目链接：https://github.com/apache/incubator-teaclave-java-tee-sdk</p><p>龙蜥社区云原生机密计算 SIG 主页：</p><p>https://openanolis.cn/sig/coco</p><p></p><p>作者介绍</p><p>林子熠，云原生机密计算 SIG  Maintainer。</p>",
    "publish_time": "2023-04-07 11:03:51",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "谷歌宣传自家AI超算比对手更快；ChatGPT泄露三星芯片机密 | 每周芯片要闻",
    "url": "https://www.infoq.cn/article/i4rFBeE6SXULIqVDY4qE",
    "summary": "<p></p><h2>谷歌母公司Alphabet宣称其AI超算性能超过Nvidia</h2><p></p><p></p><p>本周二，谷歌母公司Alphabet在一篇论文中表示，一台搭载了谷歌自研TPU（AI专用加速芯片）的超级计算机性能击败了对手Nvidia的同类超算。</p><p>&nbsp;</p><p>这台超算安装了超过4000颗谷歌TPU的第四代型号（TPU v4），对比基准则搭载了Nvidia A100 GPGPU——A100芯片是OpenAI用来训练GPT、ChatGPT大模型的基础设施。论文数据显示前者性能比后者提升20%-70%，能耗比则提升了30%-90%。但值得注意的是，Nvidia已经推出了A100的下一代产品H100，其性能预计为前者4倍之多。谷歌在两台基于TPU v4的超级计算机上训练了PaLM，该公司迄今为止公开的最大语言模型。此外，知名AI图像生成服务提供商Midjourney也在使用谷歌的这套系统训练自己的模型。</p><p>&nbsp;</p><p>谷歌还暗示，其下一代TPU将能够与Nvidia的H100芯片对抗。</p><p></p><h2>三星半导体机密数据通过ChatGPT外泄</h2><p></p><p></p><p>近日，韩国媒体报道三星内部发生三起ChatGPT导致的数据泄漏案例。三星电子半导体部门的职员执行半导体设备测量资料库下载程序源码时出错，结果该职员将出错原始代码复制到ChatGPT询问解决方案。另一位职员则将与产量、不良率相关的程序源码复制到ChatGPT，以获取优化方案。第三起泄漏则是因为一位职员将会议内容录制文件输入到ChatGPT以获取纪要。</p><p>&nbsp;</p><p>根据三星内部公告通报，此类操作会导致相关数据传送到ChatGPT服务器，并可能让敏感机密外泄。公司已采取措施防止此类事件继续发生，必要时甚至会切断内网与ChatGPT的连接。该事件也引发企业同行关于生成式大型模型在企业应用中引发泄密风险的担忧和讨论。</p><p></p><h2>中国敦促WTO审查美国主导的芯片出口限制</h2><p></p><p></p><p>中国WTO代表本周在WTO例会表示，日本、荷兰与美国应向WTO报告芯片出口限制计划与后续措施的细节，并敦促WTO加强对此事的监督。中国商务部也表示，严重关注日本对芯片制造设备的出口限制，要求日本纠正其错误做法。日本刚刚在上周宣布将限制23种半导体设备的出口，荷兰在上月也公布了类似计划，两国的举措均为响应美国的要求而制定。但三国的出口限制举措违反了WTO组织的公平透明原则，助长了美国在这一领域的技术霸权主义行径。</p><p></p><h2>中国启动对美光公司的网络安全审查</h2><p></p><p></p><p>3月31日，网络安全审查办公室表示，为保障关键信息基础设施供应链安全，防范产品问题隐患造成网络安全风险，维护国家安全，依据《中华人民共和国国家安全法》《中华人民共和国网络安全法》，网络安全审查办公室按照《网络安全审查办法》，对美光公司（Micron）在华销售的产品实施网络安全审查。美光公司是全球最大的存储芯片制造商之一，2022财年营收超过300亿美元。</p><p></p><h2>欧盟即将为欧洲芯片法案开绿灯</h2><p></p><p></p><p>媒体周五报道，欧盟立法部门即将通过总额430亿欧元的半导体产业刺激政策，《欧洲芯片法案》。该法案最初提交于去年，其目标是通过欧盟国家共同提供的刺激措施提振欧洲半导体产业，在未来十年内将欧盟在全球芯片产量中的份额翻倍，达到20%。</p><p>&nbsp;</p><p>该法案将资助先进芯片工厂、芯片研究和设计企业等，覆盖整个半导体产业链。业界认为该法案是对美国《芯片与科学法案》的回应，后者对半导体企业在美国设厂提供了一系列补贴。欧盟也希望新的政策能够帮助欧洲汽车制造产业摆脱对美国和东亚芯片产能的依赖。</p><p></p><h2>去年中国半导体产业投资额1.5万亿元，37%流向芯片设计</h2><p></p><p></p><p>CINNO Research本周发布最新统计数据，显示2022年中国（含台湾）半导体项目投资额约1.5万亿元人民币，其中37%投向芯片设计领域，25%投向芯片制造领域。全部投资中，内地资金占比超过75%，台湾、江苏与广东三地投资额占比超过10%，分列前三名。</p>",
    "publish_time": "2023-04-07 14:15:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "一文速览汽车技术领域新动态！（4.4-4.7）",
    "url": "https://www.infoq.cn/article/rVkTzX9EYGF3ypAYPv6f",
    "summary": "<p>红旗首款全国产电驱用 1200V 塑封 2in1 碳化硅功率模块 A 样件完成试制；百度新一代自动驾驶云产品发布，助力开启智能驾驶量产时代；技术、智能大升级，比亚迪 2023 款 e2 正式上市；捷豹路虎中国与阿里云宣布达成全面合作……汽车界又有哪些新动向？我们来看看！</p><p>&nbsp;</p><p></p><h4>红旗首款全国产用 1200V 塑封 2in1 碳化硅功率模块 A 样件完成试制</h4><p></p><p></p><p>据红旗官方发布，研发总院新能源开发院功率电子开发部与中国电子科技集团第 55 研究所联合开发的红旗首款全国产电驱用 1200V 塑封 2in1 碳化硅功率模块 A 样件试制完成，达成<a href=\"https://www.infoq.cn/article/O84DgKBrIy2TTGG3F9uF\">电驱</a>\"用碳化硅功率半导体设计与生产全自主化、全国产化，打破了国际芯片垄断。据了解，塑封 2in1 功率模块 A 样件率半导体凭借其耐高压、低损耗、耐高温、高频化等材料优势，成为实现<a href=\"https://www.infoq.cn/article/O84DgKBrIy2TTGG3F9uF\">新能源电驱</a>\"系统行业领先的核心路径。应用高密度高可靠元胞结构、芯片电流增强技术、高可靠碳化硅栅氧制备工艺、精细结构加工工艺等，碳化硅芯片比导通电阻达到 3.15mΩcm2 ，导通电流达到 120A ，技术指标达到国际先进水平。</p><p>&nbsp;</p><p></p><h4>百度新一代自动驾驶云产品发布，助力开启智能驾驶量产时代</h4><p></p><p></p><p>官方消息，百度正式发布了新一代自动驾驶云产品——Apollo Cloud 2.0。Apollo Cloud 2.0 是一款面向车企提供智驾量产全流程云服务的产品，具有精准合规、多模态大模型、城市级仿真三大核心优势，为用户提供量产域的自动驾驶云服务，助力车企智驾业务跨越产业鸿沟，实现快速量产。据了解，Apollo Cloud 2.0 具备文心大模型、仿真引擎、自动标注、模型训练、数据回放、无限里程、难例挖掘、工作流引擎等 12 种核心技术，配套海量数据资源，赋能车企量产阶段数据合规、海量数据挖掘提纯、城市级仿真、算法研发、车辆运营监管等应用场景。通过整合式的服务，让自动驾驶开发变得更智能、更高效、更简单，助力车企自动驾驶“从有到优”，实现数据闭环、合规闭环和场景闭环，抢占智驾服务市场先机。</p><p>&nbsp;</p><p></p><h4>科大讯飞：目前已建成 4 城 7 中心深度学习计算平台</h4><p></p><p></p><p>4 月 6 日，<a href=\"https://www.infoq.cn/article/84ENVhVB1WXdave2g76g\">科大讯飞</a>\"在互动平台表示，在算力平台方面，科大讯飞于 2009 年开始算力基础设施建设，在总部自建有业界一流的数据中心，目前已建成 4 城 7 中心深度学习计算平台。科大讯飞的算力不仅完全满足 AI 算法模型训练，还面向开放平台数百万开发者和其他行业伙伴提供相关 AI 服务的需求。此外，在工程技术方面实现了百亿参数大模型推理效率的近千倍加速，为未来更大更多认知智能大模型技术经济实惠规模化应用提供了可能。</p><p>&nbsp;</p><p></p><h4>技术、智能大升级，比亚迪 2023 款 e2 正式上市</h4><p></p><p></p><p>4 月 6 日，比亚迪 2023 款 e2 焕新上市。基于 e 平台 3.0 的技术基因，2023 款 e2 搭载全球首款深度集成八合一电动力总成，系统综合效率高达 89% ，兼得性能与能耗。全系标配的热泵空调配合电池包直冷直热技术，对动力电池温度控制更精确、高效，低温续驶里程提升 10% 以上。除此以外，2023 款 e2 还全系标配专为新能源车打造的智能动力制动系统，具有完备的主动安全功能、更高的能量回收效率和更舒适的驾乘体验。在智能配置方面，2023 款 e2 搭载全新 DiLink 智能网联系统，为用户提供影音娱乐、智能导航等功能，覆盖用户的绝大多数生活场景。全新的 UI 设计，目录层级清晰，操作简便。通过智能语音交互，驾驶者可以轻松完成对车辆的大部分控制功能。</p><p>&nbsp;</p><p></p><h4>捷豹路虎中国与阿里云宣布达成全面合作</h4><p></p><p></p><p>近日，捷豹路虎中国与阿里云正式签订全面合作协议。据悉，双方将围绕基础设施云化、供应链与采购数字化、营销数智化、碳中和与碳达峰、自动驾驶在中国的合规性研究等多个领域展开合作。在基础架构建设方面：捷豹路虎中国将引入阿里云全球领先的云计算技术，重构安全、稳定、高效的技术底座，并共同搭建“研产供销服”一体化管理大数据平台，实现 100% 统一数据指标口径，支撑 6 大业务部门，200+ 经销商门店；在智能研发方面：捷豹路虎中国正加大本土研发力度，特别是在智能驾驶与车联网方面，阿里云算力的支持有望大幅提升研发效率，并使其满足在中国的合规性；在推进碳达峰、碳中和方面：双方将共同探索汽车生产制造环节中的能耗优化和“碳足迹”计算，实现工厂和供应链、采购平台的数字化。</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-04-07 16:05:53",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "热点聚焦|金融科技新闻速览（4.4-4.7）",
    "url": "https://www.infoq.cn/article/Pdc9ycGOY44NLmHFS1Pr",
    "summary": "<p>四大行 2022 年报透露 RPA 应用，侧重点有所不同；邮储银行推进自动化审批降低审批人员工作量；常州落地首笔数字人民币“苏科贷”业务；宁波银行持续强化金融科技赋能……一文速览金融科技领域最新动态！</p><p>&nbsp;</p><p></p><h4>四大行2022年报透露RPA应用，侧重点有所不同</h4><p></p><p></p><p>近日，四大国有银行相继发布 2022 年报，其中工、农、中、建四家提及 RPA 关键词。具体来看：工行方面，RPA 助力加快推动远程银行服务升级。农行方面，RPA 应用于信用卡、财会、运营等多个领域，有效提升业务流程的执行效率。中行方面，加速推广企业级 RPA 和 OCR 平台，新技术应用场景范围不断扩大。建行方面，运用 RPA 等智能技术提升集约化作业质效，新增应用场景 307 项，全年节省 439 万个工时。</p><p>&nbsp;</p><p></p><h4>邮储银行：推进自动化审批，降低信贷审批人员工作量</h4><p></p><p></p><p>邮储银行透露，邮储大脑机器学习平台已训练研发 300 余个涉及授信、评级、预警、限额等信贷场景的智能模型，辅助提升线上审批效率，自动化审批判断处理从 5 分钟压缩至 10 秒以内。由于零售信贷自动化审批的推进，有效降低分支机构信贷审批人员工作量一半以上，有利于提升客户质量。邮储银行积极探索服务开放平台赋能渠道，为分行提供“ AI+ 大数据”、RPA 等技术的支持和指导，加快推进网点智能化改造。</p><p>&nbsp;</p><p></p><h4>常州落地首笔数字人民币“苏科贷”业务</h4><p></p><p></p><p>近日，交通银行常州分行为常州智文光电科技有限公司发放了一笔数字人民币形式的“苏科贷” 300 万元。据悉，这是常州市第一笔“苏科贷”数字人民币放贷业务。数字人民币“苏科贷”业务是在全面推进科技创新领域数字人民币试点工作的基础上，常州市科技局与合作银行共同探索数字人民币在金融支持科技创新领域的一次创新实践。常州市科技局表示，下一步，将继续与合作银行共同探索以数字人民币支持全市科技创新的新模式、新路径，大力推进科技资源和金融资源深度融合，创优金融渠道，切实服务企业做大做强。</p><p>&nbsp;</p><p></p><h4>金华发放浙江首笔“数字人民币+新型农业经营主体”贷款</h4><p></p><p></p><p>近日，在人民银行金华市中心支行的指导下，金华成泰农商银行成功向金华市高源畜禽专业合作社发放数字人民币贷款 70 万元，实现了数字人民币在金融服务新型农业经营主体场景的全省首笔应用。人民银行金华市中心支行表示，该行将深入推进数字人民币试点工作，积极打造高质量数字人民币应用生态圈，拓展数字人民币贷款场景覆盖面，探索数字人民币助力普惠金融可持续发展新模式，提升数字人民币普惠性、便捷性和可得性。</p><p>&nbsp;</p><p></p><h4>微众银行隐私计算技术通过金融科技产品国家级认证</h4><p></p><p></p><p>近日，北京国家金融科技认证中心正式公布首批通过“多方安全计算技术金融应用认证”的 5 款产品。<a href=\"https://www.infoq.cn/article/OJaT*6JGmhfqp2ipBYm2\">微众银行</a>\"作为认证试点单位，其自主研发的 WeDPR 多方大数据隐私计算平台全项通过检测认证，成为国内最先获得该国家级认证的多方安全计算金融科技产品之一。据了解，<a href=\"https://www.infoq.cn/article/ReBY0yqGdutMSKi5NHOE\">多方安全计算</a>\"( Secure Multi-Party Computation ，简称 MPC )是指在无可信第三方情况下，通过多方共同参与，安全地完成某种协同计算。合理运用多方安全计算技术，可以打破数据壁垒、连接数据孤岛；能够使金融机构之间、金融机构与商业公司之间既分享数据，又保证被分享的数据不流失，而且可以规定数据的用途和用量；在保证数据安全隐私的前提下合理合规合法地融合多方数据进行查询和分析，进一步助力金融行业的数字化和智能化。</p><p>&nbsp;</p><p></p><h4>宁波银行：科技金融，注入发展血脉</h4><p></p><p></p><p>在新时代下，经济社会发展与客户金融需求的变化进一步呼唤商业银行的数字化转型，借助金融科技持续赋能银行业务拓展与经营管理，是行业的大势所趋。近年来，宁波银行持续强化金融科技赋能，加大科研投入，积极探索大数据、云计算、人工智能、生物识别等新技术在金融方面的实践运用，并建立了“十中心”的金融科技组织架构和“三位一体”的研发中心体系。此外，宁波银行还借助金融科技赋能，重磅推出“财富开放平台”，积极引入行业头部理财子公司、基金、保险等优秀管理人产品，深化线上线下联动机制，为客户提供“全天候、多触点、不间断”的一站式金融服务。目前，宁波银行的金融科技支撑能力已经在同类银行中建立起比较优势，处于同类领先水平，这为此后公司的业务可持续发展提供了坚实的基础。</p><p>&nbsp;</p><p></p><h4>奉化农商银行“区块链秒贷”助力稳外贸</h4><p></p><p></p><p>近日，奉化农商银行联动国家外汇管理局跨境<a href=\"https://www.infoq.cn/article/alkGhdXM8CAawLLAxIjy\">金融区块链</a>\"服务平台，成功为辖区内某外贸企业办理了首笔“区块链秒贷”融资业务，在线完成融资申请、信息核查和融资放款，融资资金“秒”到账，这标志着奉化农商银行金融数字化改革助力稳外贸再上新台阶。据了解，“区块链秒贷”是奉化农商银行面向外贸出口企业推出的一款线上贸易融资业务。它依托国家外汇管理局以区块链技术搭建的跨境金融服务平台，根据企业出口收汇金额自动核算一定比例的授信额度。企业可通过网银在线提交融资申请，受理申请后，系统将直接联动跨境金融区块链服务平台自主核验报关单，实现网银自动放款、还款，全流程线上操作，资金实时到账。“区块链秒贷”的推出可以全方位助力企业降低融资成本，有效缓解外贸企业资金回笼慢、流动资金紧张的问题，为奉化区外贸经济稳步发展提供强有力的金融支撑。</p>",
    "publish_time": "2023-04-07 16:05:56",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "大规模语言训练模型应用，如何让文档问答系统快速拥有“高智商”？",
    "url": "https://www.infoq.cn/article/DNWZEft5uHClwywAMFuq",
    "summary": "<p>信息爆炸的时代，更需要我们拥有高效获得文档信息的能力。随着人工智能技术的快速发展，智能问答系统已逐渐成为提升这一能力的重要手段之一。2022 年以来，以 GPT-3 模型为代表的大规模语言模型能力的不断提升，为智能文档问答带来了新的机遇，前不久 GPT-4 模型的震撼发布更是再次颠覆人们的认知。</p><p></p><p>GPT 爆火后，人们往往聚焦于其巨大的模型和令人惊叹的自然语言生成能力，而少有人谈到如此具体的技术解析。</p><p></p><p>近日，亚马逊云科技联合 <a href=\"https://xie.infoq.cn/article/b9ad6515b3f2a84995ef3eb59\">Jina AI </a>\"举办 Tech Talk 主题活动。Jina AI 联合创始人兼 CTO 王楠从论文到工程实践，深度分析了如何将 GPT 模型更加高效地运用于智能文档问答系统的方法。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6a/6a6e078a0b3860f68636873350ede4ae.png\" /></p><p></p><p></p><h2>现代文档问答系统的发展史</h2><p></p><p></p><p>文档问答系统是指从大规模文档数据中查找到与用户问题相关答案的一套完整的系统。系统会接收文本输入的问题 Q，并在给定文档集合 D 的情况下，自动提取信息并生成对应的答案 A。文档问答系统和一般的问答系统是有明显区别的。问答系统通常是多轮对话系统，而文档问答系统更像是多轮对话的一个子问题，只考虑当前问题，并根据这个问题给定的文档集合进行回答。</p><p></p><p>问答系统的研究自上个世纪 60 年代就已经开始了，而直到 2017 年后，深度学习方法才逐渐成为问答系统的技术核心。2017 年斯坦福团队率先提出全新的基于深度学习的问答系统 DrQA。DrQA 被普遍认为是第一个在问答系统里使用深度学习模型的算法，它开辟了一个问答系统的新范式，被称为两阶段方法。</p><p></p><h3>两阶段方法</h3><p></p><p></p><p>两阶段方法将问答过程分为两个阶段。第一个阶段称为召回阶段，系统会根据用户的提问从文本库或知识库中检索相关的文本片段或知识点，利用传统的检索技术去召回可能的文档候选。第二个阶段称之为阅读理解阶段，会利用深度学习的机器阅读理解模型，从对应的候选文档里将答案抽取出来。</p><p></p><p>两个阶段分别用到不同的技术。在召回阶段，原始的论文里使用的是基于 TF-IDF 的方式去进行召回。TF-IDF 会评估问题的关键词，并通过静态计算的方式评估每一个 Term 的重要度，然后，根据每篇被召回的文档的 TF-IDF 得分进行排序，选取得分最高的前 K 篇文章，将其输入到第二阶段的机器阅读理解模型中。在论文中，一开始使用了 RNN 模型，思路是将问题转化为序列标注问题，即对于给定文档中出现的每个词，判断其是否应该出现在答案中，以及它在答案中是开头、中间还是结尾。</p><p></p><p>两阶段方法的优点在于准确率相对较高、效率高、不容易出错。但缺点也较为明显，因为它使用了传统的召回技术，一些语义近似的文档虽然与原文意思相近，但未完全出现在原文中，无法通过此方法召回。</p><p></p><h3>端到端方法</h3><p></p><p></p><p>在两阶段方法的基础上，端到端方法进行了召回阶段的提升。从模型上看，端到端方法依旧是分为召回和阅读理解两个阶段，区别在于，它使用了向量检索的方式来替代传统的检索技术用于召回。用向量去召回是指将所有文档通过一个映射函数映射到一个空间中，这个空间可以是二维的。同样地，当用户提出一个问题时，可以将这个问题映射到同样的二维空间中。在这个二维空间中，可以找到与问题语义相似的文档，因此可以将这些文档召回作为答案的候选项。与传统的关键词匹配不同，这种方式可以通过语义相似性来匹配文档，从而提高召回率。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1f/1f12ba2566fff0d94b242aff8b634bf0.png\" /></p><p></p><p>上图是召回阶段常用的模型。在召回阶段，我们通常使用的模型是 Meta AI 推出的 DPR 模型。该模型的实现方法是使用两个不同的 BERT 模型分别处理答案和文章，并计算它们对应的向量表示。在训练过程中，目标是尽可能地使相关的问题和答案在向量空间中处于相同的位置，而不相关的答案和文章则应该在向量空间中处于不同的位置。在向量空间中，我们通常使用余弦相似度来衡量相似性。使用这样的模型进行召回的优点不仅在于它可以扩大召回的范围，而且它还可以通过专门的模型针对具体的文档进行训练，从而提高召回的效果。因此，整个召回阶段成为一个可训练的过程。在阅读理解的部分，采取的仍然是抽取式的方式，把整个问题转换成一个序列标注的问题。只不过 BERT 模型的出现替代了 RNN 模型在该任务上的应用。</p><p></p><p>端到端方法还有一个改进的版本——RocketQA，其创新点在于 RocketQA 通过将答案和问题拼接在一起传递给第三个 BERT 模型，再计算相似度，来提高准确率。这种方法可以确保在提高召回率的情况下，准确率也能得到较好的效果，但最大的问题是需要针对语料进行微调，如果不进行微调，整个系统的效果并不理想。另外，和前面说的两阶段方法一样，在阅读理解的部分使用的是一个抽取式的模型，只能返回文章中已经有的答案，而不能去生成答案。这就导致如果问题是一般疑问句，它没办法直接回答是或者否。此外，这个模型也没有一个很好的拒绝回答问题的机制。</p><p></p><p></p><h3>无召回方法</h3><p></p><p></p><p>为了回答一般疑问句和解决拒绝回答的问题，第三类方法应运而生，即无召回的方法。这类方法的代表是 GPT 模型，它通过训练大规模的语言模型来记忆知识，不需要外部的存储机制来存储索引。GPT 模型的关键在于它可以生成答案，因此它可以回答一般疑问句和拒绝回答问题。GPT 模型使用了 Transformer 模型的 Decoder 部分来生成答案，它不会局限于输出输入中出现过的内容，这使得它的答案更加灵活。但是，由于 GPT 模型需要生成完整的答案，因此需要更大的模型。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/40/407797ee97572bdfa9924365c622f77f.png\" /></p><p></p><p>GPT 模型有多大呢？GPT-1 是 2018 年发布的，有 1.17 亿个参数，与 BERT 模型的参数大小差不多。而 GPT-3 具有 1750 亿个参数和 96 层 Transformer。<a href=\"https://www.infoq.cn/article/HFSPasQ7SXZ9QzdFXhGO\">GPT-4</a>\" 的参数量没有公开披露，但据估计是 GPT-3 的大约 600 倍。</p><p></p><p>当模型变得更大时，通常需要更多地训练数据。在 GPT 发布之前，迁移学习的范式主要以像 BERT 这样的模型为代表。这种方法是先预训练一个模型，然后根据不同的下游任务设计不同的模型结构和目标函数，再进行微调。GPT 模型的思路非常新颖，它放弃了微调的方式。它假设所有任务的输入都是相同的，不管是什么任务，都可以使用同一个模型结构。这种方法的好处在于，一旦模型训练好了，我们就可以直接用它来处理各种各样的任务，而不需要进行微调。此外，这种方法还可以共享各种各样的任务语料，从而有效地扩展可用的语料范围。另外，无召回的方法采用 Reinforcement learning with human feedback（RLHF）和 Ru base reward model（RBRM）技术 ，很好的实现了拒绝回答问题，确保所生成的结果是有效且合理的。</p><p></p><p>简而言之，无召回方法的优势是非常明显的，唯一的不足是无召回方法中，基于 GPT 的方法存在 token 长度限制，输入长度不能过长，长度过长会增加开销。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4e/4e343a55d391d2f6fc1dcf1d534c9170.png\" /></p><p></p><p></p><h2>从论文到实践，文档问答系统的挑战与技术实现</h2><p></p><p></p><p>理论方法即便已足够完善，但在转化为具体实践的过程中仍会面临很大的挑战。Jina AI 作为一家开源软件公司，和其他开源公司面临着同样的困境。首先，使用端到端方法对每个模型进行微调会导致运营成本非常高，如果不进行微调，则准确率会相对较低。其次，使用 GPT 模型直接处理问题既开销高，又受到长度的限制。此外，大部分文档都已经有一个问答库，如何将其融入已有的系统中也是一大问题。</p><p></p><p>基于上述挑战，Jina AI 从算法设计和工程实践的角度提出了一系列解决方案。在算法方面，Jina AI 将前面提到的三种方法进行融合。具体来说，当问题输入后，首先使用意图识别来判断用户是否真的在询问问题。接着，分为两条路径解答问题：一条是针对问答库的，将用户的问题与问答库中的问题进行匹配；另一种则是采用传统的问答系统方法。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e1/e135723b13764e80e1059cab695ccb9f.png\" /></p><p></p><p>第一条路径本质上是一种问题匹配的方法，其出发点是用户的问题，通过在问答库中匹配与用户问题相对应的问题。DocsQA 使用了 Sentence Transformer 提供的 paraphrase-mpnet-base-v2 模型。将问答库中的所有问题转换为向量，同样地，用户的问题也被转换为向量，然后在向量空间中寻找相似的问题。如果找到了匹配的问题，则将相应的答案返回给用户。这条路径的最大优点是准确率非常高，缺点在于严重依赖于问答库。因此，这条路径非常适合处理高频出现的重复性问题。</p><p></p><p>第二条路径的本质是在整个文档中查找答案，然后使用 GPT-3 模型生成答案。这里有两种具体的实现方式。第一种是关键词检索，使用 TF-IDF 方法召回包含可能答案的候选文档。它的优点是准确率很高，但召回率可能有所不足。第二种是将问题和答案转换成向量，然后在语义空间中进行召回。这种方法使用了 Meta AI 提供的 DPR 模型，主要解决召回率不足的问题。这两种方式都不需要微调模型，避免了过高的成本。此外，Jina AI 还提供了一个名为 PromptPerfect 的自研工具，它可以优化 Prompt 背后的思路，获得更好的答案效果。</p><p></p><p>欢迎试用：promptperfect.jina.ai</p><p></p><p>由于 Jina AI 是一家开源软件公司，且问答系统并非主要业务，因此 Jina AI 的目标是尽可能快地上线整个项目，同时要以尽可能低的成本来维护。然而，DocsQA 的算法使用了三种不同的方式，并依赖于多个 AI 模型，而这些模型的使用频率并不高，如何保证系统的运行成本控制在一个合理的范围内呢？</p><p>3基于 Amazon 服务的 DocsQA 工程方案&nbsp;&nbsp;</p><p></p><p>DocsQA 的系统架构分为三部分。第一部分是控制台，用于 DocsQA 的配置和更新，开发者可以在控制台上创建和更新问答系统。第二部分是前端组件，是一个交互式的前端插件，用于访问对应的后台服务，第三部分是后台服务，Jina AI 使用自己的 Jina 框架来搭建后台服务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8d/8d1883eaed5b757491e29c787ac06465.png\" /></p><p></p><p></p><h3>基于 Amazon API Gateway 的控制后台设计</h3><p></p><p></p><p>控制台的功能相对简单。它允许用户创建自己的问答服务并填写一些基本信息。此外，我们提供了一个简单的监控后台，可以提供当前的统计数据。控制台的技术栈 Jina AI 采用了亚马逊云科技的 Serverless 框架，具体使用了 Amazon API Gateway 和 Amazon Lambda 来实现。由于创建、维护和更新整个文档问答系统的动作是非常低频的，因此 &nbsp;DocsQA 不需要一直在线的服务。通过 Amazon API Gateway，可以轻松地实现这一点。当开发者发起请求到达 Amazon API Gateway 时，Amazon API Gateway 会调用相应的 Lambda 函数。实际上，Amazon API Gateway 和 Lambda 函数之间的映射关系是通过 Serverless 原生的 API Gateway Event 来实现的。同时，DocsQA 还使用了 Lambda Proxy Integration 来完成整个 Serverless 构建。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f8/f8c415d1b5db371b1571a1376a4c1cb6.png\" /></p><p></p><p>此外，由于创建索引需要耗费较长时间，不能让用户请求一直等待，以免超时。因此，可以在 Lambda 函数中触发相应的批处理作业，使用 Amazon Batch 模块。该模块会在云端启动一个容器，容器会完成相应的任务，任务完成后，容器会自动销毁。DocsQA 执行的任务是将用户要索引的文档拉取下来，然后将其以请求的形式发送到 JCloud 中。</p><p></p><p>这种方式不仅可以节省整个系统的运营成本，而且 Serverless 加上 Amazon API Gateway 和 Amazon Lambda 是一套非常快速的开发框架。这大大缩短了产品上市的时间，使产品能够快速推向市场。</p><p></p><p>在后台服务方面，当控制台收到用户的请求时，会触发后台服务。DocsQA 的后台服务是基于 Jina 框架搭建的，它是一套云原生的 MLOps 框架，旨在帮助开发者更高效、快速地开发各种多模态的应用。Jina 的核心是 Flow 的概念，即一个多模态的应用，由各种 Executor 构成。Executor 是 Flow 中的一个小模块，专门完成特定的任务。Flow 将这些 Executor 串联起来，构建了一个完整的系统。Jina 解决了网络传输、分布式部署等复杂性，能够帮助开发者更快地进行开发。</p><p></p><p>GitHub：github.com/jina-ai/jina</p><p>文档：<a href=\"https://docs.jina.ai/\">https://docs.jina.ai/</a>\"</p><p></p><p>在 DocsQA 文档问答系统中，建立了两个 Flow，一个用于索引数据。当收到用户请求时，就会创建这样一个 Flow。另一个用于查询，其任务相对简单，即把刚才建立的 TF-IDF、问答，还有向量的索引都加载起来，同时把需要的深度学习模型也加载起来对外提供服务。值得一提的是，考虑到降低成本的需求，Jina 不同的问答服务可以共享同一个模型，这大大提高了模型的使用效率。</p><p></p><h3>使用 Amazon Batch 实现低成本快速部署服务</h3><p></p><p></p><p>最后是真正的部署。JCloud 背后实际上是以 Kubernetes 的形式进行部署的。每个 Executor 都被封装成一个 Kubernetes Deployment，这样我们就可以保证每个 Executor 可以根据实际流量的情况单独进行缩放。此外，不同的 Deployment 可以放在同一个 node 上面，以节约成本。</p><p>JCloud 的实现逻辑如下图所示。JCloud 是一个 Python 包，安装后开发者可以直接使用 \"JCloud deploy\" 命令来运行对应的 Flow。该命令将向 API 发送一个请求。API 依然使用的是 Serverless 的方式，和控制台构建的方式类似，同样使用 Amazon API Gateway 和 Lambda Function 进行构建。一些比较重的任务会直接交给 batch job 处理，而轻的任务，如查询已部署的服务，则由 Lambda Function 自己处理。最后，服务将部署在 Amazon EKS 上。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/df/df87c0872149d10a9e73c7abeb15fe3d.png\" /></p><p></p><p>DocsQA 系统的第三个组成部分是前端组件。它是一个前端的 UI 库，Jina AI 开源了所有的代码，王楠表示，感兴趣的话大家可以进行二次开发，也可以直接应用在工作中。</p><p></p><p>Jina AI Cloud：cloud.jina.ai</p><p></p><p>在分享的最后王楠总结，搭建文档问答系统的算法解决方案已经非常成熟，没有太多创新。然而，在工程实践中，需要考虑如何实现更好的线上效果，以解决问题。因此，可以将不同的算法进行融合。此外，在上线时，DocsQA 大量使用了 Amazon API Gateway、Amazon Lambda 以及 Amazon Batch，结合 Serverless 框架，使系统能够快速上线，以最低的成本运营，并减少推向市场的时间。</p><p></p><p>相关链接：</p><p></p><p>Tech Talk 完整视频：<a href=\"https://dev.amazoncloud.cn/activity/activityDetail?id=640990587c94a93c3eebf4b1&amp;catagoryName=techTalk&amp;sc_channel=infoq\">戳这里</a>\"亚马逊云开发者官网：<a href=\"https://dev.amazoncloud.cn/\">https://dev.amazoncloud.cn/#</a>\"Jina 官网：<a href=\"https://jina.ai/\">https://jina.ai/</a>\"Jina Github：oss.jina.ai全球社区：jina.ai/community/</p><p></p>",
    "publish_time": "2023-04-07 16:33:34",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "谷歌正式发布WebGPU！90多位贡献者研发6年，浏览器终于可以利用底层硬件了",
    "url": "https://www.infoq.cn/article/QwAwharqAwdrAgtCoXQv",
    "summary": "<p></p><p>经过六年的开发，当地时间 4 月 6 日，谷歌 Chrome 团队正式发布 WebGPU，用于在网络上进行高性能 3D 图形与数据并行计算。WebGPU 现已在 Beta 测试阶段的 Chrome 113 中默认启用。</p><p></p><p>WebGPU 是一种新型 Web 图形 API，具有显著减少同等图形规模下 JavaScript 工作量、将机器学习模型的推理效率提升 3 倍以上等优势。之所以能实现这样的飞跃，要归功于其令 WebGL 无法实现的灵活 GPU 编程和高级功能访问能力。</p><p></p><p>据悉，WebGPU 的首个版本已经在 ChromeOS、macOS 和 Windows 上开放，对其他平台的支持将于今年晚些时候推出。</p><p></p><p></p><h3>“Web 图形的新曙光”</h3><p></p><p></p><p>WebGPU 是一种新型 Web API，能够公开现代硬件功能并允许在 GPU 上执行渲染与计算操作，功能定位类似于 Direct3D 12、Metal 和 Vulkan。与 WebGL 系列 API 不同，WebGPU 能够访问更高级的 GPU 功能，并为 GPU 上的常规计算提供一流支持。该 API 在设计上充分适应 Web 平台，提供符合习惯的 JavaScript API、promises 集成、支持导入视频和完备错误提示信息的完善开发者体验。</p><p></p><p>WebGPU 的首个版本将成为未来更新和功能增强的基础构建块。该 API 后续还将提供更高级的图形功能，并鼓励开发者提出对其他功能的申请。Chrome 团队正计划提供对着色器核心的深入访问，以便在 WGSL（WebGPU 着色语言）中进行更多的机器学习优化和额外的人体工程学调整。</p><p></p><p>根据介绍，WebGPU 是 W3C“Web GPU”社区小组协同努力的结果，其中包括来自 Mozilla、苹果、英特尔和微软等主要公司的贡献。从 2017 年初始设计以来，经过六年的开发（涉及 90 位贡献者、2000 次提交、3000 个问题），WebGPU 的首个实现终于正式登陆 Chrome，同时可支持 Firefox 和 Safari。</p><p></p><p>Chromium 和 Dawn 库和 Firefox 的 wgpu 库均可作为独立包使用，提供出色的可移植性与人体工程学层，将操作系统 GPU API 抽象出来。在本机应用程序中使用这些库时，开发者还可轻松通过 Emscripten 和 Rust web-sys 移植向 WASM。</p><p></p><p>WebGPU 的首个版本可在支持 Vulkan 的 ChromeOS 设备、支持 Direct3D 12 的 Windows 设备和 macOS 的 Chrome 113 中使用。Linux、Android 及其他现有平台的扩展支持也将在年内推出。除 Chrome 之外，WebGPU 目前还初步登陆了 Firefox 和 Safari 浏览器。</p><p></p><p>许多被广泛使用的 WebGL 库正在或已经能够支持 WebGPU，因此用户只需做单行变更即可使用 WebGPU：</p><p></p><p>Babylon.js 已经全面支持 WebGPU。PlayCanvas 宣布可初步支持 WebGPU。TensorFlow.js 可支持大部分运算符的 WebGPU 优化版本。Three.js 正在着手实现 WebGPU 支持。</p><p></p><p></p><h3>兴奋与担忧同在</h3><p></p><p></p><p>据悉，WebGPU 的诞生实际上就是大厂角力的结果。2016 年，Google 发现 WebGL 存在一些问题，于是就提出了一个新的提案叫 WebGL Next，称要再做一个精确的图形 API。然后，其他的厂商也纷纷跟进，Mozilla、Apple、Opera 都提出了自己的概念。</p><p></p><p>这个时候，<a href=\"https://www.infoq.cn/article/2017/02/webgpu\">Apple 起名部</a>\"的工作人员向 W3C 提交了一个叫做 WebGPU 的提案，W3C 决定采纳这个名字作为未来新标准的命名，并且成立工作组来做 WebGPU 的工作。</p><p></p><p>因为这个名字是 Apple 起的，所以最后只有 Apple 的提案进入了他们“gpuweb-proposals”的代码仓库，不过为了避免重名造成的误解和冲突，Apple 最初那个提案的名字被改为了 WebMetal。</p><p></p><p>看到 W3C 接纳了 Apple 的提案，Mozilla 不甘心，转而又向 Khornos Group 提交了一个基于 Vulkan 的命名为 WebGL Next 的提案，但这已经是 WebGL 的最后一搏了。这最后，浏览器厂商用脚投票，站到了 WebGPU 这边。</p><p></p><p>如今，经过多年等待，谷歌团队正式发布 WebGPU 让很多开发者感到激动。</p><p></p><p></p><blockquote>“这非常令人兴奋！”</blockquote><p></p><p></p><p>“这是一个巨大的里程碑，也是更大旅程的一部分。在我开发高级 2D 渲染器 Vello 的工作中，我开始相信 WebGPU 是游戏规则的改变者。我们将拥有可在任何地方运行的、相当现代的基础架构：Web、Windows、Mac、Linux、ChromeOS、iOS 和 Android。”开发者 raphlinus 表示。</p><p></p><p>当有人问起，“假设您是 ML 从业者。您是否仍会推荐学习 WebGPU，而不是说花更多时间在 CUDA 上？”时， raphlinus 给出建议，“这完全取决于您的目标。如果您正在研究实际的机器学习算法，那么使用像 TensorFlow 或 Torch 这样的框架，它们提供了所有张量操作并抽象出硬件。如果您今天想在硬件上获得最大性能，请坚持使用 Nvidia 并选择 CUDA。如果您对跨一系列硬件部署感兴趣，或者想要亲自动手实现算法（例如 wonnx），那么 WebGPU 是您的不二之选。”</p><p></p><p>开发者“FL33TW00D”表示，“这非常令人兴奋！（我曾怀疑它会滑到 114）WebGPU 实现仍然很不成熟，但肯定足以开始使用。”FL33TW00D 讲道，“在过去的几个月里，一直在实现 Rust + WebGPU ML 运行时，并且很喜欢编写 WGSL。最近，我得到了一个 250M 参数的 LLM 在浏览器中运行，没有太多优化，它表现得很好！也就是说，matmuls 在浏览器中仍然有很大的缺陷（特别是考虑到浏览器中强制执行的边界检查）。在我的基准测试中，我一直在努力达到理论 FLOPS 的 50%，当边界检查开始时，它会减少到 30%。我期待访问帖子中提到的着色器核心。”</p><p></p><p>还有 Burn（Rust 深度学习框架）项目的贡献者也表示将添加 WebGPU 后端。</p><p></p><p></p><blockquote>WebGPU，晚了吗？</blockquote><p></p><p></p><p>当然，也有一些开发者对 WebGPU 如今才发布是不是还“赶趟”表示怀疑。前 Unity 游戏引擎工程师 Aras Pranckevičius 提出疑问，“WebGL 已经过时了。我想知道 WebGPU 是不是也有点晚了（比如现在 Vulkan 认为 PSOs 可能不是一个好主意，哈哈）。”</p><p></p><p>他补充道，就像 8 年前一样，WebGPU 是一种“现代图形 API 设计”。迟做总比不做好，但是……“现代”的概念如今似乎在朝着这样的方向发展：无绑定的一切（就像“无绑定”的含义的第三次迭代）、网格着色器、光线跟踪、灵活的管道状态。然而，所有这些都不在 WebGPU 中。</p><p></p><p>对此，谷歌图形管道工程师 Corentin Wallez 回应道，原生 API 确实向前发展了，而 PSO 确实推动了游戏开发者们当时认为他们可以维持的特定方向（预编译所有内容，结果并非如此）。他表示，WebGPU 必须支持目前使用的所有硬件，包括不支持无绑定或网格着色器的设备。“但希望在第一个版本之后，它会继续改进，并赶上一些重要的新功能。”</p><p></p><p>另外，开发者“flohofwoe”表示赞同 Aras 的观点，但他认为，“房间里的大象”仍然是糟糕的移动 GPU。这些新奇技术中的大多数都不适用于移动 GPU，并且在可预见的未来可能仍然不会。（Vulkan 实际上应该有两个 API：一个用于桌面 GPU，一个用于移动 GPU——这些新扩展正在将 Vulkan 分成两个或多或少分别独立的 API，一个对于移动 GPU 来说很糟糕，另一个相当不错，但只适用于桌面 GPU。）</p><p></p><p>“WebGPU 无法承受这样的分裂。它必须在同一代码库的桌面和移动设备上同样出色地工作（移动设备实际上比桌面设备重要得多）。”flohofwoe 表示。</p><p></p><h3>WebGPU VS &nbsp;WebGL</h3><p></p><p></p><p>那么，作为 WebGL 的继承者，有开发者提出 WebGPU 与 WebGL 的差异究竟如何？贝壳找房资深工程师<a href=\"https://mp.weixin.qq.com/s?__biz=MzUxMzcxMzE5Ng==&amp;mid=2247512172&amp;idx=1&amp;sn=7527199067c4f022fd10d2f0f14a528c&amp;chksm=f952052fce258c392f707f840b11f1c14a50b1c8869d656421e734c7b5796bd9a7248d6815bb&amp;scene=27#wechat_redirect\">郝稼力</a>\"曾在 GMTC 全球大前端技术大会上分享了他对两者做的性能对比，我们可以看下。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3e/3e9d4d47dbd0de5b08d040231f9feaed.png\" /></p><p></p><p>这是复杂场景的渲染性能对比。这个场景中有 1000 棵树，它们不是使用实例化绘制的，而是每一棵树都有一个 draw call，所以一个场景我要有 1000 多个 draw call。如果使用 WebGL 进行绘制的话，可以看到，使用 2070 显卡只能跑到 21FPS，而且每一帧的 CPU 时间需要 44 毫秒，但是同样用 WebGPU 来处理，可以跑到 123 帧，每一帧的 CPU 时间只有 0.1 毫秒，这个是 WebGPU 和 WebGL 最大最显著的性能上的差距。</p><p></p><p>另外就是一个代码上的差距。用 WebGL 原生 API 绘制的过程，所有的东西的起点都在于 Canvas；然而这是一件很不可思议的事情，就是即使不需要画什么东西，用户也需要创建一个 Canvas 元素，这个操作对于<a href=\"https://www.infoq.cn/article/4Et0wIAxWFbVez5wbMCC\">前端</a>\"可能是无感知的，但是对于浏览器开发者来说就要新建一个 DOM 元素，要给它增加所有它需要有的东西，一旦 DOM 元素崩溃了，浏览器要处理所有这些事情，对于开发者而言后面的事情就会变得非常复杂。</p><p></p><p>但是 WebGPU 不是这样，WebGPU 的入口是 navigator.gpu，用户可以从这里获取到一个显卡，再从显卡获取到一个设备，而中间的 Canvas 是没有的。</p><p></p><p>更多内容可查看<a href=\"https://mp.weixin.qq.com/s?__biz=MzUxMzcxMzE5Ng==&amp;mid=2247512172&amp;idx=1&amp;sn=7527199067c4f022fd10d2f0f14a528c&amp;chksm=f952052fce258c392f707f840b11f1c14a50b1c8869d656421e734c7b5796bd9a7248d6815bb&amp;scene=21#wechat_redirect\">《从 WebGL 到 WebGPU，网页图形的全新时代》</a>\"</p><p></p><p>参考链接：</p><p></p><p><a href=\"https://developer.chrome.com/blog/webgpu-release/\">https://developer.chrome.com/blog/webgpu-release/</a>\"</p><p></p><p><a href=\"https://news.ycombinator.com/item?id=35465729\">https://news.ycombinator.com/item?id=35465729</a>\"</p><p></p><p>好文推荐</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651164989&amp;idx=1&amp;sn=3fc6c909a070c175fb9546620fc41e8d&amp;chksm=bdb8696e8acfe078ae9fee1410a14fee88774b287f6a5c47575bf3fef5656add6704b2b758d5&amp;scene=21#wechat_redirect\">新手用ChatGPT仅需数小时轻松构建零日漏洞，69家专业公司都检测不出来：“不仅能调用开源库，还能彻底重写源代码”</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651164858&amp;idx=1&amp;sn=2288a33128311ea8a144701e8ef562a2&amp;chksm=bdb868e98acfe1ff8781ab8d1fbfc00d793a2678fc67ea8e094c9af3a10bd5b485d6aeb459ca&amp;scene=21#wechat_redirect\">揭秘 ChatGPT 背后的技术栈：OpenAI 如何将 Kubernetes 扩展到了 7500 个节点</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651164785&amp;idx=1&amp;sn=256cff149510855eee106bf493fbf158&amp;chksm=bdb868228acfe1342f6060ded3ffeda5bcb5aa7c4f1375540bac75835282fa9408de9af5afa1&amp;scene=21#wechat_redirect\">从8000元起步到年产值超800亿，藏在郊县里的农牧数字化探索者</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651164443&amp;idx=1&amp;sn=a44f26b4db80eadc586c738a77fe5006&amp;chksm=bdb877488acffe5e9c9b0f5a31134756e9ca6c440d0c2575fc3f0cc5e26ce9a85107ae4694ad&amp;scene=21#wechat_redirect\">文心一言员工跳槽工资翻倍；推特算法“面向老板编程”；马云回来了，阿里分拆了｜Q资讯</a>\"</p><p></p>",
    "publish_time": "2023-04-07 17:20:20",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "赋能直播行业精细化运营，斗鱼基于 Apache Doris 的应用实践",
    "url": "https://www.infoq.cn/article/6dchABOoYi20NG7TDuAv",
    "summary": "<p></p><blockquote>鱼是一家弹幕式直播分享网站，为用户提供视频直播和赛事直播服务。随着斗鱼直播、视频等业务的高速发展，用户增长和营收两大主营业务线对精细化运营的需求越发地迫切，各个细分业务场景对用户的差异化分析诉求也越发的强烈。为更好满足业务需求，斗鱼在 2022 年引入了 <a href=\"http://doris.apache.org/\">Apache Doris</a>\" 构建了一套比较相对完整的实时数仓架构，并在该基础上成功构建了标签平台以及多维分析平台，在此期间积累了一些建设及实践经验通过本文分享给大家。</blockquote><p></p><p></p><p>作者｜韩同阳，斗鱼资深大数据工程师、OLAP 平台负责人 </p><p></p><p>斗鱼是一家弹幕式直播分享网站，为用户提供视频直播和赛事直播服务。斗鱼以游戏直播为主，也涵盖了娱乐、综艺、体育、户外等多种直播内容。随着斗鱼直播、视频等业务的高速发展，用户增长和营收两大主营业务线对精细化运营的需求越发地迫切，各个细分业务场景对用户的差异化分析诉求也越发的强烈，例如增长业务线需要在各个活动（赛事、专题、拉新、招募等）中针对不同人群进行差异化投放，营收业务线需要根据差异化投放的效果及时调整投放策略。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ac/acfd2c82f698359c7890c1df34b03092.png\" /></p><p></p><p>根据业务场景的诉求和精细化运营的要求，我们从金字塔自下而上来看，需求大致可以分为以下几点：</p><p></p><p>分析需求更加复杂、精细化，不再满足简单的聚合分析；数据时效性要求更高，不满足于 T+1 的分析效率，期望实现近实时、实时的分析效率。业务场景多，细分业务场景既存在独立性、又存在交叉性，例如：针对某款游戏进行专题活动投放（主播、用户），进行人群圈选、AB 实验等，需要标签/用户画像平台支持。多维数据分析的诉求强烈，需要精细化运营的数据产品支持。</p><p></p><p>为更好解决上述需求，我们的初步目标是：</p><p></p><p>构建离线/实时数仓，斗鱼的离线数仓体系已成熟，希望此基础上构建一套实时数仓体系；基于离线/实时数仓构建通用的标签中台（用户画像平台），为业务场景提供人群圈选、AB实验等服务；在标签平台的基础上构建适用于特定业务场景的多维分析和精细化运营的数据产品。</p><p></p><p>在目标驱动下，斗鱼在原有架构的基础上进行升级改造、引入 <a href=\"https://github.com/apache/doris\">Apache Doris</a>\" 构建了实时数仓体系，并在该基础上成功构建了标签平台以及多维分析平台，在此期间积累了一些建设及实践经验通过本文分享给大家。</p><p></p><h1>原有实时数仓架构</h1><p></p><p>斗鱼从 2018 年开始探索实时数仓的建设，并尝试在某些垂直业务领域应用，但受制于人力的配置及流计算组件发展的成熟度，直到 2020 年第一版实时数据架构才构建完成，架构图如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3d/3da2790becc58ca0dab5e872ea2b50de.png\" /></p><p></p><p>原有实时数仓架构是一个典型的 Lambda 架构，上方链路为离线数仓架构，下方链路为实时数据仓架构。鉴于当时离线数仓体系已经非常成熟，使用 Lambda 架构足够支撑实时分析需求，但随着业务的高速发展和数据需求的不断提升，原有架构凸显出几个问题：</p><p></p><p>在实际的流式作业开发中，缺乏对实时数据源的管理，在极端情况下接近于烟囱式接入实时数据流，无法关注数据是否有重复接入，也无法辨别数据是否可以复用。离线、实时数仓完全割裂，实时数仓没有进行数仓分层，无法像离线数仓按层复用，只能面向业务定制化开发。数据仓库数据服务于业务平台需要多次中转，且涉及到多个技术组件，ToB 应用亟需引入 OLAP 引擎缓解压力。计算引擎和存储引擎涉及技术栈多，学习成本和运维难度也很大，无法进行合理有效管理。</p><p></p><h1>新实时数仓架构</h1><p></p><p></p><h3>技术选型</h3><p></p><p>带着以上的问题，我们希望引入一款成熟的、在业内有大规模落地经验的 OLAP 引擎来帮助我们解决原有架构的痛点。我们希望该 OLAP 引擎不仅要具备传统 OLAP 的优势（即 Data Analytics），还能更好地支持数据服务（Data Serving）场景，比如标签数据需要明细级的查询、实时业务数据需要支持点更新、高并发以及大数据量的复杂 Join 。除此之外，我们希望该 OLAP 引擎可以便捷、低成本的的集成到 Lambda 架构下的离线/实时数仓架构中。立足于此，我们在技术选型时对比了市面上的几款 OLAP 引擎，如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/08/08e6b458aeca228a04e3fa7deddc3efb.png\" /></p><p></p><p>根据对选型的要求，我们发现 Apache Doris 可以很好地满足当前业务场景及诉求，同时也兼顾了低成本的要求，因此决定引入 Doris 进行升级尝试。</p><p></p><h3>架构设计</h3><p></p><p>我们在 2022 年引入了 Apache Doris ，并基于 Apache Doris 构建了一套比较相对完整的实时数仓架构，如下图所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3c/3c511db39b816919def953df64d6a118.png\" /></p><p></p><p>总的来说，引入 Doris 后为整体架构带来几大变化：</p><p></p><p>统一了计算平台（玄武计算），底层引擎支持 Flink、Spark 等组件，接入层支持统一 SQL 和 JAR 包接入。引入 Doris 后，我们将实时数仓分为 ODS、DWD、DWS、ADS 层，部分中间层实时数据直接使用 Doris 进行存储；构建了基于 Doris 的 HOLAP 多维分析平台，直接服务于业务；简化了原来需要通过 Hive 进行预计算的加工链路，逐步替换使用难度和运维难度相对较高的 ClickHouse；下游应用的数据存储从之前的 MySQL 和 HBase 更换为 Doris，可以在数据集市和大宽表的数据服务场景下直接查询 Doris。支持混合 IDC（自建和云厂商）。</p><p></p><h3>Overwrite 语义实现</h3><p></p><p>Apache Doris 支持原子替换表和分区，我们在计算平台（玄武平台）整合 Doris Spark Connector 时进行了定制，且在 Connector 配置参数上进行扩展、增加了“Overwrite”模式。</p><p></p><p>当 Spark 作业提交后会调用 Doris 的接口，获取表的 Schema 信息和分区信息。</p><p></p><p>如果为非分区表：先创建目标表对应的临时表，将数据导入到临时表中，导入后进行原子替换，如导入失败则清理临时表；如果是动态分区表：先创建目标分区对应的临时分区，将数据导入临时分区，导入后进行原子替换，如导入失败则清理临时分区；如果是非动态分区：需要扩展 Doris Spark Connector 参数配置分区表达式，配完成后先创建正式目标分区、再创建其临时分区，将数据导入到临时分区中，导入后进行原子替换，如导入失败则清理临时分区。</p><p></p><h3>架构收益</h3><p></p><p>通过架构升级及二次开发，我们获得了 3 个明显的收益：</p><p></p><p>构建了规范、完善、计算统一的实时数仓平台构建了统一混合 OLAP 平台，既支持 MOLAP，又支持 ROLAP，大部分多维分析需求均由该平台实现。面对大批量数据导入的场景，任务吞入率和成功率提升了 50%。</p><p></p><h1>Doris 在标签中台的应用</h1><p></p><p>标签中台（也称用户画像平台）是斗鱼进行精准运营的重要平台之一，承担了各业务线人群圈选、规则匹配、A/B 实验、活动投放等需求。接下来看下 Doris 在标签中台是如何应用的。</p><p></p><h3>原标签中台架构</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/a2/a298afa9824da97b72a2f8337f6397cc.png\" /></p><p></p><p>上图为斗鱼原来的标签中台架构，离线标签在数仓中加工完成后合入宽表，将最终数据写入 HBase 中，实时标签使用 Flink 加工，加工完直接写入到 HBase 中。</p><p></p><p>终端 APP 在使用标签中台时，主要解决两种业务需求：</p><p></p><p>人群圈选，即通过标签和规则找到符合条件的人。规则匹配，即当有一个用户，找出该用户在指定的业务场景下符合哪些已配置的规则，也可以理解是“人群圈选“的逆方向。</p><p></p><p>在应对这两种场需求中，原标签中台架构出现了两个问题：</p><p></p><p>实时标签链路：Flink 计算长周期实时指标时稳定性较差且耗费资源较高，任务挂掉之后由于数据周期较长，导致 Checkpoint 恢复很慢；人群圈选：Spark 人群圈选效率较低，特别是在实时标签的时效性上。</p><p></p><h3>新标签中台架构</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/4b/4bd19e8912bf4454a00534b2decb814a.png\" /></p><p></p><p>引入 Apache Doris 之后，我们对标签中台架构的进行了改进，主要改进集中在实时链路和标签数据存储这两个部分：</p><p></p><p>实时标签链路：仍然是通过实时数据源到 Kafka 中，通过 Flink 进行实时加工；不同的是，我们将一部分加工逻辑迁移到 Doris 中进行计算，长周期实时指标的计算从单一的 Flink 计算转移到了 Flink + Doris 中进行；标签数据存储：从 HBase 改成了 Doris，利用 Doris 聚合模型的部分更新特性，将离线标签和实时标签加工完之后直接写入到 Doris 中。</p><p></p><h4>1. 离线/实时标签混合圈人</h4><p></p><p><img src=\"https://static001.geekbang.org/infoq/50/500f880e5030aabc269f6e8db2b86b2c.png\" /></p><p></p><p>简化存储：原存储在 HBase 中的大宽表，改为在 Doris 中分区存储，其中离线标签 T+1 更新，实时标签 T 更新、T+1 采用离线数据覆盖矫正。查询简化：面对人群圈选场景，无需利用 Spark 引擎，可直接在标签中台查询服务层，将圈选规则配置解析成 SQL 在 Doris 中执行、并获得最终的人群，大大提高了人群圈选的效率。面对规则匹配场景，使用 Redis 缓存 Doris 中的热点数据，以降低响应时间。</p><p></p><h4>2. 长周期实时标签计算原链路</h4><p></p><p>长周期实时标签：计算实时标签时所需的数据周期较长，部分标签还需要采用历史数据（离线）合并实时数据流一起进行计算的场景。</p><p></p><p>使用前：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/76/76e0bee120b270805a3b99acf0cdeb94.png\" /></p><p></p><p>从原来的计算链路中可知，计算长周期的实时标签时会涉及到维度补充、历史数据 Merge，在经过几步加工最终将数据写入到 HBase 中。</p><p></p><p>在实际使用中发现，在这个过程中 Merge 离线聚合的数据会使链路变得很复杂，往往一个实时标签需要多个任务参与才能完成计算；另外聚合逻辑复杂的实时标签一般需要多次聚合计算，任意一个中间聚合资源分配不够或者不合理，都有可能出现反压或资源浪费的问题，从而使整个任务调试起来特别困难，同时链路过长运维管理也很麻烦，稳定性也比较低。</p><p></p><p>使用后：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f3/f37ee0d56241fc9ecffbfb0fe2005e05.png\" /></p><p></p><p>我们在长周期指标计算实时链路中加入了 Apache Doris，在  Flink 中只做维度补充和轻度加工汇总，只关注短的实时数据流，对于需要 Merge 的离线数据，Merge 的计算逻辑转移到 Doris 中进行计算，另外 Doris 中的轻度汇总/明细数据有助于问题排查，同时任务稳定性也能提升。</p><p></p><h3>使用收益</h3><p></p><p>目前标签中台底层有近 4 亿+条用户标签，每个用户标签 300+，已有 1W+ 用户规则人群，每天定时更新的人群数量达到 5K+。标签中台引入 Apache Doris 之后，单个人群平均圈选时间实现了分钟级到秒级的跨越，实时标签任务稳定性有所提高，实时标签任务的产出时间相较于之前约有 40% 的提升，资源使用成本大大降低。</p><p></p><h1>Doris 在多维数据分析平台的应用</h1><p></p><p>除以上所述应用及收益之外，Apache Doris 也助力内部多维数据分析平台——斗鱼 360 取得了较大的发展，受益于 Apache Doris 的 Rollup、物化视图以及向量化执行引擎，使原来需要预计算的场景可以直接导入明细数据到 Doris 中，简化了业务数据开发流程，提升了分析效率；Doris 兼容 MySQL 协议，并具有独立简单的分布式架构，使得业务开发人员入门使用也更容易，缩短了业务开发周期，有效降低了开发成本；同时我们原来基于 ClickHouse 的查询目前也全部切换到了 Doris 中进行。</p><p></p><p>目前我们用于多维分析场景的 Doris 集群共有两个，节点规模约 120 个，存储数据量达 90~100 TB，每天增量写入到 Doris 的数据约 900GB，其中查询 QPS 在 120 左右，Apache Doris 应对起来毫不费力，轻松自如。</p><p></p><p>因文章篇幅限制，该部分应用不再赘述，后续有机会与大家进行详细分享。</p><p></p><h1>未来展望</h1><p></p><p>未来随着 Apache Doris 在斗鱼更广泛业务场景的落地，我们将在可视化运维、问题快速定位排查等方面进行更多实践和深耕。我们关注到， Apache Doris 1.2.0 版本已经对 Multi Catalog 功能进行了支持，我们也计划对其进行探索、解锁更多使用场景，同时也期待即将发布 Apache Doris 2.x 版本的行列混存功能，更好的支持 Data Serving 场景。</p>",
    "publish_time": "2023-04-07 17:29:31",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从蚂蚁集团技术实践看数据库协同开发的现状和发展趋势",
    "url": "https://www.infoq.cn/article/HTLjEWI0gCZi1Nhe1B55",
    "summary": "<p>我是陈小伟， 2019 年加入 OceanBase，目前负责 OceanBase 开发者中心的研发。 OceanBase ODC 这几年从一个数据库图形化客户端工具逐渐变成一个面向协同开发场景的管控平台。我也看到这几年数据库行业内配套的开发工具也正好是有一些类似的变化，于是形成一个观察，数据库协同开发已经成为趋势。</p><p></p><p><a href=\"https://www.infoq.cn/article/8ExlO3isaUZCu6dbimLo\">OceanBase </a>\"ODC 这几年从一个数据库图形化客户端工具逐渐变成一个面向协同开发场景的管控平台。我们也看到这几年数据库行业内配套的开发工具也正好是有一些类似的变化，于是形成一个观察，数据库协同开发已经成为趋势。</p><p></p><p>为什么？下面我会从三方面进行叙述。</p><p></p><p>另外在正文开始前，说明一下本文我想跟大家聊四个部分：第一部分是数据库行业现状，毕竟作为数据库的开发工具，要解决的还是使用数据库的问题。在第二部分我们从现状去看目前在数据库使用过程中有哪些挑战，以及说我们的用户是如何去应对这些挑战的，这里也会包含蚂蚁集团是如何应对这些挑战的。第三部分我们基于对国内市场、海外市场常见工具的观察得出结论。第四个部分会结合数据库行业的变化对趋势做进一步洞察。</p><p></p><h2>数据增长带来一系列变化</h2><p></p><p>可以认为，近些年在<a href=\"https://archsummit.infoq.cn/2023/shanghai/track/1523\">数据管理</a>\"领域的很多挑战根本原因都可以归结到数据快速增长。</p><p></p><h3>数据快速增长</h3><p></p><p>国际调研机构 IDC 发布的《数据时代 2025》预测，全球数据总量将从 2018 年的 33ZB 增至 2025 年的 175ZB，增长超过 5 倍，这里结构化数据大概占 10%。信通院的报告显示，中国数据库市场规模近几年保持 25% 左右的年增长率。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/32/32b13b8995988f6d5dd30fcffd180c4e.jpeg?x-oss-process=image%2Fresize%2Cp_80%2Fauto-orient%2C1\" /></p><p></p><p>表面上我们看到的是数据存储规模在快速增加，数据库市场规模在不断增长。</p><p></p><p>我们服务的的用户场景有一些具体的例子：</p><p></p><p>某电商系统使用 60 个节点的数据库集群，每个节点数据规模 20TB 左右，总数据规模超过 1PB；某金融系统使用的数据库表数量达到 20W，列数量达到 400W；某金融系统使用的分区数量达到 100W；某制造业系统使用的 PL 程序包数量达到 4K 个；</p><p></p><p>从<a href=\"https://www.infoq.cn/article/D2EylZ7X3xS6NCiuRtyb\">数据库</a>\"开发者的视角来看，或者说从数据库开发工具的视角来看，我们其实看到的是这背后数据库的实例数量，数据库实例内存储的对象的数量，使用数据库的业务系统的数量，以及说数据库厂商的数量，数据库从业人员数量 都是在不断的增长。那我们知道变化这个事情啊，量变逐渐逐渐的是会产生质变的。数据库这个使用过程当中啊伴随着上述的诸多变化，而其实就带来了诸多的一些问题，实际上可以认为， 近些年在数据管理领域的很多挑战根本原因都可以归结到数据快速增长。</p><p></p><h3>数据库是稳定性基石</h3><p></p><p>数据快速增长，数据库稳定性问题导致的故障也越来越严重。</p><p></p><p>这里我们看几个具体的例子：</p><p></p><p>1、2016 年，某社交网络应用的一名工程师在修改一条 SQL 查询时犯了一个错误，导致了该公司的服务在全球范围内停机。该错误导致了数据库中某些表的数据无法访问，最终导致了整个系统的故障。</p><p></p><p>2、2017 年，某电商企业曾因一次故障而导致其 S3 服务在美国东部地区停机。事后调查发现，该故障是由一个错误的删除指令引起的，这个指令本来只想删除一小部分数据，但由于编写了烂 SQL，结果导致了整个数据中心的数据丢失。</p><p></p><p>3、2018 年，某云厂商的云存储服务出现了一个故障，导致一些客户的数据无法访问。调查后发现，这是由于一个工程师在修改数据库的查询语句时犯了一个错误，导致了整个服务出现了故障</p><p></p><p>这几个例子是 <a href=\"https://www.infoq.cn/article/5lzBBTLf5ddX8974MNVo\">ChatGPT</a>\" 帮我找的，我其实也问了中国大陆地区的情况，但是 <a href=\"https://www.infoq.cn/article/FRcz5vjOvl3bM2d57opX\">ChatGPT</a>\" 的回复是也有很多例子，但是不能够告诉我具体的公司名称，看来目前还是很保护中国大陆厂商的面子的，这背后不知道是否有团队在帮助做一些工作。 实际上这些例子我们去看，比如 烂 SQL 导致的系统不稳定，在数据规模不大的时候都不成为问题。但是目前的趋势就是数据规模越来越大，这个时候数据库作为保障信息系统稳定性的重要兜底装置，身上的担子就越来越重了。</p><p></p><h3>更加严格的合规监管</h3><p></p><p>数据快速增长，应用数量也不断增长，个人、企业的敏感数据流通范围更广了，数据带来的隐私泄露问题也越来越严重。这几年我们国家从顶层设计、法律法规、行业规范、企业自主意识方面都对敏感数据保护越来越重视。</p><p></p><p>这里列举了一些近些年我们国家颁布的一系列关于保障信息安全的法律法规和行业标准。</p><p></p><p>1、《中华人民共和国网络安全法》：2017 年 6 月 1 日生效，包括对个人信息的收集、使用、存储和保护等方面的规定，对违反规定的行为进行了明确的处罚。2、《中华人民共和国个人信息保护法》：2021 年 11 月 1 日生效，是中国大陆地区首个专门针对个人信息保护的法律。该法规明确了个人信息的定义、处理规则、权利保护和责任追究等方面的内容。3、《中华人民共和国电子商务法》：2019 年 1 月 1 日生效，包括对于个人信息的收集、使用、管理、安全保障等方面的规定，针对电子商务领域的个人信息保护进行了规范。4、JR/T 0223-2021《金融数据安全数据生命周期安全规范》。5、 WS/T 78802021 《国家卫生信息资源使用管理规范》。</p><p></p><p>在数据安全之中，<a href=\"https://www.infoq.cn/article/K30UQfJt7TqDVLDgjIK2\">数据库</a>\"扮演至关重要的角色，保证数据不泄露、丢失。数据不丢失是由 ACID 来保障的，不泄露则需要业务应用系统来和管理工具一起保障，我们了解到很多客户已经开始重视这个问题，但是正在寻找解决方案。解决方案并不普及，可以看出目前行业的方案还比较不成体系，配套的开发工具也不够成熟。</p><p></p><h3>协同角色变化</h3><p></p><p>数据量在快速增长，数据库实例数量在快速增长，行业的从业人员也在快速增长，但是不同角色并不是等比例去增长。在十几年前，一个 Oracle DBA 管理的数据库实例规模在 25 个左右，总数据规模在 5TB 左右。那么到现在的数据规模，你会发现如果按照之前的模式，DBA 数量是远远不够的。此外我们发现数据分析师角色人数逐渐在增长，不同角色在和数据库打交道的时候工作方式是不一样的，比如数据分析师几乎不会去用 Java 连数据库做事务提交，更多的是写 SQL、Python 脚本等，然后在团队内也有协同的诉求。从比例去看，DBA 和 总协同人数的占比甚至小于 1/100，在大型互联网公司，这个比例已经接近 1/1000。</p><p></p><p>下表是我们选取了 <a href=\"https://www.infoq.cn/article/D2EylZ7X3xS6NCiuRtyb\">OceanBase </a>\"服务的用户场景的数据库开发协同过程不同角色的人员规模，出于保护客户信息的需要，这里的人数是一个近似值而不是准确值。</p><p></p><p></p><p>这里 DBA 人数大型互联网公司的比例是很夸张的，从数量级来说已经接近 1/1000，但实际上还有一个统计口径的原因。我们从招聘统计数据发现 SRE 岗位需求已经超过 DBA 的岗位需求，其中数据库 SRE 和 DBA 的职责其实类似，DBA 更关注数据库本身，而数据库 SRE 更注重整个系统的可靠性和性能。从大型互联网企业的情况看，安全稳定保障和业务功能开发的人员占比大概是 1:10 ~ 1:5 左右。</p><p></p><h2>应对挑战各有各招</h2><p></p><p>伴随数据增长产生了很多变化，这些变化导致各类风险的出现或者加剧，我们观察到的挑战包括以下 3 个类别。</p><p></p><p>系统稳定：数据量不断增长，对数据库稳定性带来风险，烂 SQL 的代价比以往更大、数据备份恢复压力凸显；协同效率：数据库数量不断增长，DBA 工作负担越来越重，权限配置和 SQL 审核效率亟需提升；数据安全合规：政府和行业监管对数据安全合规越来越严格，企业本身对隐私数据保护也越来越重视，缺少有效的数据安全防护机制，合规风险之雷必须尽快排查。</p><p></p><h3>解决方案列举</h3><p></p><p>应对风险，不同行业、不同规模的企业也采取了很多办法，可以说是各有各的招，这里举一些典型的实践方案：</p><p></p><p>大型传统企业通常采购数据库特权访问系统，基于特权系统的权限管控、SQL 审核等功能，数据库特权访问管理系统通常也叫做数据库堡垒机，会和数据库客户端工具集成来实现权限管控，通常这些功能更多的应用于生产环境而不是开发环境；大型互联网企业通常选择自研平台，有独立团队负责开发维护数据库管控平台，对数据库变更过程、运行过程进行全流程管控；中小型企业私有云大量采用开源组装，开源产品选择面比较多，但是通常单一开源产品支持的数据库类型比较单一功能也不够丰富，所以需要进行组装；中小型企业公有云直接依托云服务厂商提供的内置服务，比如阿里云 RDS 的用户直接使用 DMS。</p><p></p><h3>蚂蚁集团实践</h3><p></p><p>蚂蚁集团数据库开发的协同过程整体是面向业务 Developer 视角来看的，因为业务侧才是需求方。下图是 Developer 和 DBA 的协作模型，DBA 负责资源规划和审批、部署运维、监控诊断、故障处理、变更审核，开发者负责资源申请、数据库变更。其中资源申请、权限申请、数据库变更等关键操作需要业务方负责人和业务归口的 DBA 审核确认后才可以执行。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/95/9590872177e39bbdef34fb7086cc8d7f.jpeg?x-oss-process=image%2Fresize%2Cp_80%2Fauto-orient%2C1\" /></p><p></p><p>一个典型的过程 Developer 根据业务规划在 ODC 界面申请数据库资源，DBA 看到申请单之后完成审核，此时 ODC 会调用 OCP 生成租户并授权给 Developer。</p><p></p><p>这里列举蚂蚁集团 DBA 日常工作中使用的几个主要的系统：</p><p></p><p>AntMonitor/OCP: 监控告警；HNBC：容量大盘和调整迁移；Tars：SQL 诊断故障自愈；DLM：数据生命周期管理、历史库、归档 等；ODC：数据库开发平台。</p><p></p><p>上述系统大部分是 DBA 使用，Developer 和 DBA 协同的主界面则是 ODC。除了基本的资源申请和变更管控，ODC 还提供了一系列用于保障数据安全稳定的功能，比如风险识别、高危操作管控、勿删应急等功能。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/93/9347ef36c5f852051a770811068d6713.png\" /></p><p></p><p>这里也分享一些蚂蚁集团数据库开发协同相关的具体数字和经验：</p><p></p><p>DBA/Developer 占比大约为 1:600，每名 DBA 需要服务 300～400 个应用；90% 以上的变更工单是业务自己审批，需要 DBA 审批的高风险变更占比不到 10%;最常见风险包括 不合理的索引修改、变更影响范围过大等。</p><p></p><h2>协同开发是演进趋势</h2><p></p><p>我们调研分析了一些数据库开发工具，范围涉及国内市场、海外市场，包括云服务和桌面软件，有商业工具也有开源免费的工具，通过这些工具我们可以发现协同开发逐渐成为主流。</p><p></p><h3>国内市场工具产品</h3><p></p><p></p><p>我们看到这两年有一些新的产品出现，比如 Bytebase、NineData 等。</p><p></p><p>其中作为云厂商基础设施的，最典型的是 DMS，DMS 是阿里云的数据库开发安全管控产品，类似的还有华为云的 DAS 等。</p><p></p><p><a href=\"https://www.infoq.cn/article/dassaX2O2WqvGjqpbXlf\">MySQL </a>\"生态，有不少开源工具产品也被大范围的使用，典型的如 Yearning、SOAR、See 等。</p><p></p><p>Yearning 支持自动化 SQL 语句审核，可对 SQL 进行自动检测并执行、DDL/DML 语句执行后自动生成回滚语句、审核/查询 审计功能、支持自定义审核工作流、支持细粒度权限分配。</p><p></p><p>SOAR(SQL Optimizer And Rewriter) 是一个对 SQL 进行优化和改写的自动化工具，由小米人工智能与云平台的数据库团队开发与维护。支持 MySQL 语法族协议的 SQL 优化、支持基于启发式算法的语句优化、支持复杂查询的多列索引优化、支持 EXPLAIN 信息丰富解读、支持 SQL 指纹、支持自定义规则的 SQL 改写。</p><p></p><p>See 把 Inception、SQLAdvisor、SOAR 整合到一起，看起来是个人项目，相比 Yearning 提供更多功能，比如支持 SQL 优化建议，社区活跃度较低。</p><p></p><p>SQLE，是爱可生开源的一款面向数据库使用者和管理者的 SQL 审核工具，旨在规范 SQL 审核上线流程，提高 SQL 质量。</p><p></p><p>NineData 的定位更接近云厂商的数据管理服务，SaaS 形态。</p><p></p><h3>海外市场工具产品</h3><p></p><p></p><p>Toad 深受 Oracle 用户喜爱，作为一个适配 Oracle 的图形化客户端， Toad 相比 PL/SQL Developer 更加现代，功能也更全面。ApexSQL 功能更加丰富，特别是对 SQL Server 的支持特别完善，Toad 是 Quest 公司的产品，2019 年 Quest 收购了 ApexSQL。Quest 还曾经被 DELL 收购后来又独立出来了。</p><p></p><p>Red-Gate 支持的数据库类型很多多，提供 SQL Server、Oracle、MySQL、PostgreSQL 数据库的管理和开发功能，支持 数据库比较和同步、备份恢复、版本控制等，国内开发者使用比较多的 Schema migration 工具 Flyway 就是 Red-Gate 开源的产品。</p><p></p><p>Devart 提供多种数据库管理工具，支持 SQL Server、MySQL、Oracle、PostgreSQL、SQLite 等数据库，提供了查看、编辑、比较、同步、安全管理等多种功能。Skyvia 也是 Devart 公司的一款云数据集成平台，用于将不同的数据源整合在一起并进行数据转换、同步、备份和恢复等操作，Skyvia 支持多种关系型数据库和云数据库。Devart 更专注于数据库管理工具，而 Skyvia 更专注于数据集成和转换平台。</p><p></p><p>Cloud DBeaver 是 DBeaver 的 WEB 化产品，目前功能还比较简单，但是可看出老牌数据库开源工具项目往云服务和云原生转型的行动，最近 DBeaver 还集成了 OpenAI，这是另一个热点了。</p><p></p><p>EverSQL 提供 SQL 检查和优化功能，SaaS 形态，宣称有 10W 个用户，主张通过优化 SQL 帮助用户省钱。</p><p></p><h3>全球市场工具产品</h3><p></p><p>这里举两个比较特殊的产品，Navicat 和 Bytebase，这两个产品可谓各有典型性。</p><p></p><p>作为广受开发者喜欢的数据库图形化客户端工具，Navicat 给大家的印象更多时候是一个面向个人开发场景的工具。实际上 Navicat 也提供了协同能力，如 Navicat Cloud 和 Navicat Server，可以让用户在不同的设备和团队中共享和协作数据库。用户可以将数据库文件保存到 Navicat Cloud 中，从任何设备上访问和编辑数据库。Navicat Server 则提供了一些高级功能，如用户管理、权限控制和版本控制等，可以帮助团队更好地管理和保护数据库。</p><p></p><p>Bytebase 是 2021 年国内团队做的数据库协同开发工具，也是开源模式，高阶功能需要收费。基于项目进行协同，以数据库对象为管控目标。Bytebase 也提供 SQL 检查、数据库变更流程、Git 集成、备份恢复 等功能。</p><p></p><h2>数据库开发工具趋势洞察</h2><p></p><p>作为数据库开发工具，我们在最开始看到是数据增长带来了一系列变化，并且因此带来了系统稳定、协同效率和安全合规三个方面的问题。这个是大的趋势，我们认为数据库开发工具需要去解决这些重要的问题，但是具体到数据库开发工具还需要去做哪些考量，我们不能脱离数据库行业整体的一个格局和趋势。所以首先我们来看数据库行业的一些现状以及趋势。</p><p></p><h3>海外市场仍是主流</h3><p></p><p>刚开始看到 DMS 的时候，我其实觉得还挺强大的，不仅支撑了阿里巴巴、蚂蚁集团大规模业务场景下的数据库协同，也适用于各种阿里云数据库产品的开发和管控，功能非常全面。并且我也去找了国外的竞品，比如 AWS/Azure 等产品并没有类似的 DMS 这样强大的数据库管控功能。我会产生一个错觉，我们国家是领先世界的，因为我们人口多，所以我们数据多，所以我们的场景最复杂，就类似微信、支付宝这样的覆盖 10 亿以上用户的 App，大部分国家就没有机会做出来，不是能力不够，而是环境条件不具备。那么作为入行不久的数据库行业的从业者，我差点也以为，我们是领先世界的，不仅仅是在分布式数据库内核领域，在数据库协同工具层面也是一样。</p><p></p><p>那么事实果真如此吗？数据库全行业看，2021 年全球数据库市场规模为 697 亿美元，其中中国数据库市场规模为 47 亿美元（约合 305.8 亿元人民币），占全球 5.2%；美国开源与商业数据库数量基本持平，我国商用和开源占比分别为 83.4%和 16.6%；国内 MySQL 生态为主，海外 PostgreSQL 生态更活跃；国内数据库协同开源项目较多，海外开源项目以面向个人开发者为主，商业数据工具普遍在往 DevOps 方向发展。</p><p></p><h3>混合云和多云</h3><p></p><p>混合云和多云的发展可以说是客户驱动云厂商在做产品形态变化，中大型客户不再愿意被一家云厂商绑定。我们看到越来越多的行业场景在做应用架构、数据库架构的时候，混合云和多云成为趋势。这里混合云指的是公有云和私有云混合使用，此时云厂商一站式解决方案不再可用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9b/9bdc96936bc90c94eec1efcb7fd1688d.jpeg?x-oss-process=image%2Fresize%2Cp_80%2Fauto-orient%2C1\" /></p><p></p><h3>HTAP 和多数据源</h3><p></p><p>如果你有关注这几年声量最响的一些数据库创业公司，可以发现大家都在谈 HTAP，HTAP 是数据库新势力必争之地。为什么这么说，因为 TP 和 AP 都有非常优秀的产品在做了，其中有一些还有显著的优势，那么我们是选择做一款更加厉害的 TP 产品好呢还是做一款更加厉害的 AP 产品好呢？每个厂商有自己的答案，对于 OceanBase 而言，我们相信 TP 和 AP 都可以，首先 TP 是我们的优势，而 AP 我们也做的不差，那就是 HTAP。话虽如此，当时实际上这个过程没有那么简单，有很多问题需要去解决，我们可以预见在几年之内，TP+AP 混合场景仍将是主要场景。但是无论是 TP+AP 还是 HTAP 都对开发工具提出了新的要求，实际上是一套库还是多套库不是最关键的，最关键的是数据协同的角色，写数据的人和分析数据的人会比以前更加紧密的去协同，这个时候数据库开发工具就需要具备相对应的一些能力，这里列举了几个我认为可能比较重要的。</p><p></p><p>数据同步；全局对象检索 Metadata Catalog；多角色协同。</p><p></p><h3>趋势解读</h3><p></p><p>上面我们讲了市场格局、混合云和多云的趋势、还有 HTAP 或者说 TP + AP 这些新的场景，这里我们汇总一些具体到数据库开发工具方向，未来会是怎样的趋势，我判断会有 5 个趋势。</p><p></p><p>个人开发--&gt; 多角色协同开发，这是是我们今天讲的核心，数据库协同开发会越来越流行。</p><p></p><p>Developer Tool --&gt; Data Operation Platform，这一点是对协同开发的延伸，从开发工具到数据协同平台，这里有个概念叫做 DataOps 目前为止还不是那么清晰，Gartner 去年的报告对 DataOps 领域做了一些解读认为说未来三到五年会形成一个清晰的市场，然后我们也看到信通院的大数据标准化推进委员会也在牵头做 DataOps 相关的概念讨论。关于这一部分坦白讲我也没有看明白，因为实际上我们都还没有看到有哪个具体的产品就已经可以自圆其说是一个 DataOps 领域的解决什么问题的产品。DevOps 这个概念从出来到大家大致都了解也是有很漫长的过程，那么直到现在我认为 DevOps 也没有解决新的问题，开发、测试、运维这些问题还是由对应的工具在帮助解决。</p><p></p><p>TP + AP &amp; HTAP 场景支持，我们会看到数据库开发工具会兼具 TP 场景和 AP 场景下的功能。</p><p></p><p>集成和被集成，集成主要是账号系统、审批系统的集成，被集成则是需要产品能够提供 API 易于二次开发。</p><p></p><p>开源 和 SaaS，这一条是我认为从 2 个方面去看，一个是云，目前哪怕国内市场数据库 60% 以上的份额已经在云上了，然后大家还不愿意被一家云厂商绑定了，所以跨云的 SaaS 是很自然的结论；另一个方面软件业的开源趋势应对全球市场的优势，特别是在现在跨地域、跨云的场景下，在数据管理领域，被全球更广泛的客户信任非常重要，那么你的服务形态一定是 SaaS，然后你还需要用最低的成本获取更多地区的客户信任，答案就是开源了。所以我认为未来的趋势，开源和 SaaS 都是必然。</p><p></p><h2>结语</h2><p></p><p>数据的不断增长带来数据库稳定性、数据安全、协同效率等三大挑战，云数据库、混合云、HTAP 等数据库技术和使用趋势又给数据库开发工具提出新的功能要求，数据库开发工具需要提供更加完善的功能，帮助 DBA 减轻负担，从而提升数据库开发和运行效率、保障数据库稳定运行。</p>",
    "publish_time": "2023-04-07 17:35:49",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "CV又卷起来了！Meta AI开源万物可分割AI模型，11亿+掩码数据集可提取",
    "url": "https://www.infoq.cn/article/6mtv3vomQxJLEcUKu4Gm",
    "summary": "<p>4月6日，根据Meta AI官方博客，Meta AI宣布推出了一个AI模型Segment Anything Model（SAM，分割一切模型）。据介绍，该模型能够根据文本指令等方式实现图像分割，而且万物皆可识别和一键抠图。</p><p></p><p>图像分割——即识别出图像中的哪些像素隶属于同一对象——是计算机视觉领域的一项核心任务，在科学图像分析、照片编辑等各类场景中拥有广泛应用。但为特定任务创建精准分割模型是一项需要由技术专家精心处理的高度专业化工作，往往需要结合AI训练基础设施和大量精确标注的域内数据才能实现。</p><p></p><p>Meta AI表示，推出Segment Anything项目的目的是为了实现分割技术的大众化：“正如我们在研究论文中做出的解释，这是一套用于图像分割的新型任务、数据集与模型。除通用Segment Anything模型（SAM）之外，我们还发布了Segment Anything 1-Billion（SA-1B）掩码数据集。作为有史以来体量最大的分割数据集，Segment Anything能够支持广泛的应用场景，并助力计算机视觉基础模型的进一步研究。我们正使用SA-1B数据集用于研究目的，且Segment Anything模型在开放许可（Apache 2.0）下开放。”</p><p></p><h2>SAM的核心目标是什么？</h2><p></p><p>Segment Anything项目的核心目标，就是减少特定任务对于建模专业往右、训练计算量和图像分割中自定义数据标注的需求。为了实现这个目标，Meta AI团队希望建立一套图像分割基础模型：这是一个可提示模型，在不同数据集上接受训练并能够适应特定任务，类似于在自然语言处理模型中通过揭示词进行生成的方式。但与互联网上丰富的图像、视频和文本形成鲜明反差，训练图像分割模型所需要的数据在网上并不容易获取。因此，研究人员在Segment Anything项目中还同步开发了一套通用的可提示分割模型，用它创建出一套规模空前的分割数据集。</p><p></p><p>SAM已经能够理解对象的一般概念，可以为任意图像或视频中的任何对象生成掩码，甚至支持它在训练期间从未见过的对象和图像类型。SAM的通用性足以涵盖广泛用例，并可开箱即用于新的图像“领域”——包括水下照片和细胞显微镜图像，无需任何额外训练（即所谓「零样本迁移」）。</p><p></p><p>未来，SAM能够在各种需要通过图像查找并分割任意对象的应用中发挥作用。对于AI研究社区及其他关注者而言，SAM还可成为更大AI系统中的组成部分，用于对真实世界做更加普遍化的多模态理解，包括理解网页的视觉与文本内容。在AR/VR领域，SAM可根据用户的视线选择对象，再将其“升维”为3D形式。对于内容创作者，SAM可用于改进创意应用，例如提取图像区域以执行拼贴或编辑视频。SAM还可用于帮助地球乃至太空环境下的自然事件做科学研究，例如定位视频中的动物或物体以开展跟踪和研究。Meta AI团队称，他们相信Segment Anything中蕴藏着巨大的可能性，也对这些目前甚至难以想象的潜在用例感到无比兴奋。</p><p></p><p>Segment Anything的提示设计可与其他系统灵活集成。SAM能够接收输入提示，例如来自AR/VR头显用户的视线信息。</p><p></p><h2>SAM说到底是一种通用的图像分割方法</h2><p></p><p>以往，要解决任何图像分割问题，我们只能选择两类方法。其一是交互式分割，虽然允许分割任意类别的对象，但需要由人类迭代细化掩码来做引导。其二是自动分割，可以提前定义特定的对象类别（例如小猫或椅子），但需要大量的手动标注对象以完成训练（例如提供成千上万的小猫图像分割示例），并配合大量计算资源和专业知识以训练分割模型。这两种方法都无法提供真正通用的全自动分割方法。</p><p></p><p>SAM是对这两类方法的汇总。作为单一模型，它能够轻松完成交互式分割和自动分割。该模型的可提示界面（后文将具体介绍）提供灵活的使用方式，只需为模型设计正确的提示线索（点击、框选、文本等）即可完成广泛的分割任务。此外，SAM在包含超过10亿个掩码的多样化、高质量数据集（作为项目的一部分）上接受训练，其分割功能可以泛化到新的对象和图像类型当中，远超其在训练期间实际观察过的内容。这种良好的泛化能力，意味着从业者一般不需要自行收集细分数据来针对特定用例做模型微调。</p><p></p><p>总而言之，这些功能让SAM得以泛化到新的任务和领域当中，实现了图像分割领域前所未见的功能灵活性。</p><p></p><h2>SAM的工作原理：提示分割</h2><p></p><p>在自然语言处理和最近的计算机视觉领域，最令人兴奋的发展成果之一在于基础模型。这些基础模型能够使用“提示”技术对新数据集和任务执行零样本和少样本学习。Meta AI团队也从这方面进展中汲取了灵感。</p><p></p><p>经过训练，SAM能够根据任何提示返回有效的分割掩码，包括前景/背景点、粗框或掩码、自由格式文本等一切能够指示图像内分割内容的信息。即使提示不够明确且可能指代多个对象（例如指向衬衫上的一个点可能代表衬衫本体，也可能代表穿着衬衫的人），输出也应合理有效。Meta AI团队通过这项任务对模型进行预训练，引导其通过提示解决常规的下游分割任务。</p><p></p><p>研究人员观察到，预训练任务和交互式数据集对模型设计施加了特定约束。具体来讲，该模型需要在网络浏览器的CPU上实时运行，这样标注者才能与SAM实时交互并高效进行标注。虽然运行时约束意味着要在质量和运行时间之间取得权衡，但他们发现简单的设计在实践中能够取得良好结果。</p><p></p><p>在工作原理层面，图像编码器会为图像生成一次性嵌入，而轻量级编码器则将所有提示实时转换为嵌入向量。之后，将这两个信息源组合在一个负责预测分割掩码的轻量级解码器内。在计算图像嵌入之后，SAM能够在50毫秒内根据网络浏览器中的任意提示生成相应分割。</p><p></p><p>在网络浏览器中，SAM能够有效将图像特征与一组提示嵌入映射起来，借此生成分割掩码。</p><p></p><h2>10亿分割掩码：我们如何构建SA-1B</h2><p></p><p>为了训练模型，需要大量更多样的数据源，但这些在工作之初并不存在。Meta AI此次发布的分割数据集是迄今为止体量最大的，且数据收集同样由SAM完成。具体来讲，标注者使用SAM以交互方式标记图像，之后使用新标注的数据依次更新SAM。通过多次重复此循环，以迭代方式改进模型和数据集。</p><p></p><p>使用SAM，分割掩码的收集速度远超以往任何时候。使用该工具，只需约14秒即可以交互方式标注掩码。每个掩码标注过程的耗时仅相当于标注边界框的2倍，后者在使用最快的注释界面时也需要约7秒。与之前的大规模分割数据收集工作相比，SAM模型比COCO全手动多边形掩码标注快6.5倍，较之前规模最大的模型辅助数据标注工作快2倍。</p><p></p><p>然而，单靠交互式注释掩码并不足以充分扩展至需要的10亿掩码数据集。因此，Meta AI团队构建了一套数据引擎以创建SA-1B数据集。该数据引擎具有三个“挡位”：一挡为模型协助标注器，如前文所述；二挡是全自动标注与辅助标注混合选项，有助于增加收集掩码的多样性；数据引擎的第三挡则是全自动掩码创建，可帮助实现数据集扩展。</p><p></p><p>最终，数据集包含从约1100万许可和隐私保护图像上收集到的超11亿个分割掩码。SA-1B的掩码比任何现有分割数据集都多出400倍，而且经过人工评估证实，这些掩码质量出色、多样性丰富，在某些情况下在质量上甚至可以媲美之前体量较小、纯由手动标注的掩码数据集。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2f/2fe66c796daefb9395830b26ffe13749.png\" /></p><p></p><p>Segment Anything的功能，是利用数据引擎收集的数百万张图像与掩码进行训练的结果。最终成果是一套包含超10亿个分割掩码的数据集，比以往任何分割数据集都要大出400倍。</p><p></p><p>SA-1B的图像来自多个国家/地区的照片提供商，其跨越不同地理区域和收入水平。虽然Meta AI团队意识到某些地理区域的代表性仍然不足，但与以往的分割数据集相比，SA-1B拥有更多图像、对所有地区的总体代表性也更好。此外，Meta AI团队还分析了模型在性别认知、肤色认知和年龄范围认知方面的潜在偏见，发现SAM在不同群体间的表现比较统一。Meta AI团队希望这能让他们的工作成果更公平地服务于真实世界中的用例。</p><p></p><h2>展望未来</h2><p></p><p>未来，SAM可通过AR眼镜识别日常物品，并向用户发出提醒和提示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/eb/ebb391d87f803b4613362a68ff46ce72.png\" /></p><p></p><p>SAM拥有广泛的潜在影响范围，也许有一天能帮助农牧业和生物学家开展研究。</p><p></p><p>最后，Meta AI团队表示，“通过共享我们的研究和数据集，我们希望进一步加快对分割、乃至其他更具普遍性的图像和视频理解的研究。我们的可提示分割模型可以充当大体量系统中的组件以执行图像分割任务。通过组合方式，大家将能够以可扩展方式使用单个模型，完成模型在设计之初并未考虑到的应用。我们预计由提示工程等技术实现的可组合系统设计，将比特定一组面向固定任务训练的系统具备更广阔的功能空间，也有望让SAM在AR/VR、内容创造、科学研究和通用AI等领域贡献自己的力量。展望未来，我们相信像素级图像理解与视觉内容将与更高级别的语义理解紧密耦合，最终解锁出更加强大的AI系统”。</p><p></p><p>参考链接：</p><p></p><p><a href=\"https://ai.facebook.com/blog/segment-anything-foundation-model-image-segmentation/\">https://ai.facebook.com/blog/segment-anything-foundation-model-image-segmentation/</a>\"</p>",
    "publish_time": "2023-04-07 17:43:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "阿里大模型亮相！“通义千问”开启企业邀测 | InfoQ快讯",
    "url": "https://www.infoq.cn/article/MBhLRG3KXdBw3QSJL2gR",
    "summary": "<p></p><p>4月7日，阿里云通过官方微信号官宣，自研大模型“通义千问”开始邀请用户测试体验。</p><p>&nbsp;</p><p>现阶段该模型主要定向邀请企业用户进行体验测试，用户可通过官网申请（tongyi.aliyun.com），符合条件的用户可参与体验。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9b/9b8ac9639a5b123eb42e2f8552e59480.jpeg\" /></p><p></p><p></p><p>点击进入通义千问官网，可以看到下方有“申请体验”和“使用邀请码”两个按钮，用户可使用邀请码登录或通过阿里云APP/支付宝/钉钉账号注册提交体验申请。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/69/696648d9f9f9d4e756973fd0f70b7428.jpeg\" /></p><p></p><p>&nbsp;</p><p>据悉，阿里达摩院在NLP自然语言处理等前沿科研领域早已布局多年，并于2019年启动大模型研发。2021年，阿里先后发布国内首个超百亿参数的多模态大模型M6及被称为“中文版GPT-3”的语言大模型PLUG，此后还训练实现了全球首个10万亿参数AI模型。</p>",
    "publish_time": "2023-04-07 18:10:45",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Twitter 被告上法庭：去年大规模裁员涉嫌违法、不支付逾期账单",
    "url": "https://www.infoq.cn/article/JipYKG8E8HK4FRWSRpm6",
    "summary": "<p>Twitter此前大规模<a href=\"https://www.infoq.cn/article/qhgHLsmYuUuAZC9J4S2Q\">裁员</a>\"的影响仍在持续发酵。据<a href=\"https://news.yahoo.com/twitter-faces-another-lawsuit-illegally-053351094.html\">外媒报道</a>\"，由于没有提前通知的情况下违法辞退外包合同工，Twitter被告上了法庭。</p><p>&nbsp;</p><p>诉讼称，<a href=\"https://www.infoq.cn/article/3OOPEivwhT0gLcKP0Nwl\">Twitter</a>\"去年11月解雇了人力资源公司TEKSystems派遣的大量外包员工，但没有按照美国全国和加州法律的要求，提前60天通知相关员工。这起集体诉讼已经提交至旧金山联邦法院。</p><p>&nbsp;</p><p>原告代表Shannon Liss-Riordan对路透社表示:“虽然埃隆·马斯克似乎认为逃避这些义务是在为公司节省资金，但我们计划向他表明，不履行责任可能会付出更大的代价。”</p><p>&nbsp;</p><p>“关于Twitter影响力减小，不幸的是，当这个公司每天亏损超过400万美元时，我们别无选择。每个离职的员工都得到了3个月的遣散费，比法律要求的高出50%，”马斯克曾表示。</p><p>&nbsp;</p><p>“Twitter员工依靠的是公司做出的承诺，即如果埃隆·马斯克的收购成功，他们将受到公平对待。他违背了对他们的遣散承诺，”Liss-Riordan本月早些时候在推特上写道。</p><p>&nbsp;</p><p>据悉，该法院同时还在审理另外五起案件，指控Twitter违反劳动法。去年12月提起的诉讼称，Twitter解雇了57%的女性员工，解雇了47%的男性员工。Twitter 还被指歧视残疾员工。对此，Twitter否认存在不当行为。</p><p>&nbsp;</p><p>还有一群Twitter供应商提起集体诉讼，指控该公司未能支付数万美元的逾期账单。</p><p>&nbsp;</p><p>字幕服务公司 White Coat Captioning、咨询集团 YES Consulting 和公共关系公司 Cancomm 和 Dialogue México——声称 Twitter 违反了他们的合同，并且尚未为他们提供的服务支付大约 40,000 美元到 140,000 美元的账单。</p><p>&nbsp;</p><p>YES Consulting表示，根据2022年3月签署的一项协议，其为Twitter员工提供了领导力培训，Twitter应该为去年8月至11月期间提供的服务支付大约4.9万美元，但其至今未收到这笔款项。拉丁美洲公关公司Dialogue声称，其去年11月和12月提供的服务，Twitter没有支付这笔约14万美元的费用。</p><p>&nbsp;</p><p>另外，Twitter 也被爆还在拖欠加州总部的租金。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://news.yahoo.com/twitter-faces-another-lawsuit-illegally-053351094.html\">https://news.yahoo.com/twitter-faces-another-lawsuit-illegally-053351094.html</a>\"</p><p><a href=\"https://edition.cnn.com/2023/04/04/tech/twitter-vendors-lawsuit/index.html?utm_content=2023-04-04T16%3A30%3A40&amp;utm_term=link&amp;utm_medium=social&amp;utm_source=twCNN\">https://edition.cnn.com/2023/04/04/tech/twitter-vendors-lawsuit/index.html?utm_content=2023-04-04T16%3A30%3A40&amp;utm_term=link&amp;utm_medium=social&amp;utm_source=twCNN</a>\"</p>",
    "publish_time": "2023-04-07 18:38:53",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]