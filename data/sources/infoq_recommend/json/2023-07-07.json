[
  {
    "title": "可信数据库发展大会｜深化数据库产业协作，着力推进我国数据库产业高质量发展",
    "url": "https://www.infoq.cn/article/vC4h2rWRyOylw0I4soj1",
    "summary": "<p>2023 年 7 月 4 日- 5 日，由中国通信标准化协会大数据技术标准推进委员会（ CCSA TC601 ）主办的“ <a href=\"https://www.infoq.cn/article/tQtvumNcUUEZuf4Tglex\">2023 可信数据库发展大会</a>\"” 在北京国际会议中心召开。中国移动信息技术中心政企业务支撑中心副总经理梁恩磊受邀参加了“共话数据库产业自立自强高水平发展”圆桌论坛，论道我国数据库自立自强之路，探索新形势下我国数据库产业的可持续、高质量发展。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f0/f0b7a5d2f4cdb415e34ccd0d322841a5.jpeg\" /></p><p></p><p>论坛围绕四个议题展开：</p><p></p><p></p><h2>一、把握数据库发展趋势，迎接海量数据处理与存储场景下新挑战</h2><p></p><p></p><p>梁恩磊表示，随着 5G 、物联网等业务的快速发展，数据库技术也面临新的要求和挑战。下一阶段，数据库最亟待解决的问题是如何进一步提升在海量高并发场景下的数据处理能力以及存储能力。</p><p></p><p>高性能数据处理：5G 和物联网技术的快速发展，给数据库在超高并发场景下的数据处理带来了巨大的挑战。下一阶段，数据库仍需要不断降低响应时延、提高并发处理能力，进一步降低 5G 、物联网等技术带来的数据处理压力，以满足在线计费、实时信控等各类实时业务场景的需求。</p><p></p><p>海量数据存储：5G 及物联网将以前所未有的速度生成海量数据。以物联网计费话单为例，每天产生数百亿条话单且仍在高速增长，对数据库的存储能力提出了更高的要求。因此需要数据库拥有快速扩展的能力，以便有效地存储和处理海量数据。</p><p></p><p>在应对方案上，梁恩磊表示，目前分布式是个大趋势，也是解决海量数据处理与存储的金钥匙。从传统的 Shared-Everything 架构，再到当前的 Shared-Nothing 、Shared-Disk 等分布式架构，都是为了更高效、更低成本地解决海量数据处理问题。未来，随着<a href=\"https://xie.infoq.cn/article/d866b6d5a158c9a7f44ad2263\">分布式数据库</a>\"的不断成熟，数据库在各类实时业务场景下对海量数据处理与存储的能力必将跨上一个新台阶。</p><p></p><p></p><h2>二、关注核心技术动向，实现数据库领域新发展</h2><p></p><p></p><p>梁恩磊表示，未来应重点关注数据安全、数据库智能化、分布式与云原生等技术方向。</p><p></p><p>首先是数据安全方向。随着国内大众的数据安全意识提升，以及《数据二十条》等政策标准的陆续出台，可以窥见安全审计、数据加密、身份验证等正在成为数据库领域新的关注热点。未来行业将逐步补齐传统数据库在安全领域的短板。</p><p></p><p>其次是数据库智能化方向。伴随着 ChatGPT 等技术的发展，<a href=\"https://xie.infoq.cn/article/1746e9a1bec2bfa64fd07293f\">向量数据库</a>\"以及数据库与这类 AIGC 技术的结合逐渐火热。前者解决此类技术在训练过程中的数据库存储问题，后者通过与 AIGC 技术的结合可以极大地降低数据库的使用门槛。</p><p></p><p>最后是分布式与云原生方向。万物互联时代，数据库也将从传统的存储“人”的数据转变为存储“物”的数据，给数据库层造成的压力将提升成百上千倍。未来，通过存储和计算分离等分布式技术以及与云原生技术的结合，将实现计算资源、存储的弹性伸缩，极大地降低业务架构的复杂度，为高效低成本地解决海量数据的处理与存储带来更多可能。</p><p></p><p></p><h2>三、围绕“三高一低”的主旋律，助力产业高速发展</h2><p></p><p></p><p>梁恩磊表示，在未来十年里，数据库领域毫无疑问地将发生各种变革和创新，但不变的是数据库的发展始终会围绕着“三高一低”（高性能、高稳定、高安全、低成本）的主旋律。</p><p></p><p>在性能方面，以电信行业为例：在集中式数据库时代，业务场景主要是通话与短信，相对单一且数据量较小，采用传统的集中式数据库即可满足大部分业务对数据库性能和成本的要求。随着通信行业快速发展，对数据库的性能有了更高的要求，逐步过渡到分库、分表时代。同时各类垂直、水平拆分技术也在快速发展，在运营商中最常见的是按省份、地市进行垂直拆分，但分片间数据的不均衡、业务分片架构的高复杂度等因素给这类方案带来了巨大的压力。随着移动互联网、物联网、5G 技术的发展，数据库也通过与分布式、云原生等技术的深度的结合有了更进一步的发展。</p><p></p><p>同理，业务对高性能、高稳定、高安全、低成本的诉求与数据库的发展也是相辅相成、互相促进的。围绕着“三高一低”的主旋律，数据库始终会将不断革新，持续满足业务发展需求。</p><p></p><p></p><h2>四、深化数据库产学研结合，推动我国数据库行业高水平发展</h2><p></p><p></p><p>梁恩磊表示，如果把数据库的自立自强比喻为一场攻坚战，那么学术侧主要提供武器的研究，产业侧负责武器的供应，应用侧则提供一线的实战。只有通过产学研的通力配合，才能实现优势互补，共同为数据库技术的发展奠定坚实的技术基础，实现从“攻出来”到“用起来”的紧密衔接。</p><p></p><p>为了进一步推动数据库产业的高质量快速发展，中国移动信息技术中心充分发挥多应用场景优势，联合深圳大学和香港科技大学（广州分校）成立广东省重点实验室，并作为组长单位参与信通院组织的数据库创新实验室，针对数据库产业、技术、生态发展等问题及对策展开研究，助力数据技术的联合攻关。</p><p></p><p>梁恩磊表示，科技自立自强是国家强盛之基、安全之要。未来，中国移动将进一步加深与政府、高校和研究机构的合作，共同推进数据库技术研究成果的产业化进程，推动国内数据库技术迅速走向世界前列。</p>",
    "publish_time": "2023-07-07 09:35:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "6大场景、7步精进，极狐星帮助「蔚来」千人团队，建立「标准研发效能管理体系」",
    "url": "https://www.infoq.cn/article/Im8lhBm1NlZWOHAwOxGI",
    "summary": "<p>极狐GitLab《研发效能管理的双模模型》聚焦效能管理痛点，提供【6大场景、7步精进】详实理论方法和行动指南，更有【蔚来】客户案例分享！</p>\n<p>亮点&amp;收获：</p>\n<ul>\n<li>行动升级：研发效能管理 7 步走，稳扎稳打，步步精进</li>\n<li>方法升级：Get GDAI 经典方法，建立标准研发效能管理体系</li>\n<li>实践升级：明晰 6 大角色场景，有的放矢，构建全局视角</li>\n</ul>\n<p><a href=\"https://mp.weixin.qq.com/s?__biz=Mzg5MTg2MDQ4NQ==&amp;mid=2247496014&amp;idx=1&amp;sn=449cfec844bea56cf6c4a55bd5f66acc&amp;chksm=cfc45224f8b3db32b695d8d6b4c3afb533eabd1c72e8d5b1cd28c71b8d2a14a3774522fc155b#rd\">查看【直播回顾文字稿】，立即试用极狐星！</a></p>",
    "publish_time": "2023-07-07 10:09:02",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "边缘计算之道：如何在数字时代“挖金山”？",
    "url": "https://www.infoq.cn/article/xDd95ddmJubtrFu3zE6c",
    "summary": "<p>随着制造业、石油、天然气、能源以及交通等行业加速数字化转型，数据容量呈现持续增长的趋势。然而，这种边缘数据爆炸需要得到有效的管理。在面对系统复杂性、数据隐私、延迟问题、有限的带宽连接，以及不断上升的存储和处理数据成本等众多挑战时，边缘计算应运而生。</p><p></p><p>边缘计算的核心理念是将计算资源尽可能地靠近数据源，减少设备与远程服务器之间的长距离连接，从而改善数据的处理、处理和传输方式。尤其是在制造业、石油和天然气、能源以及交通等大型行业中，工业边缘计算已经开始广泛应用，以实时分析和管理资产端的所有数据。通过实时分析或将聚合的数据用于进一步的云端处理，工业边缘计算能够提供实时的数据分析和更高效的数据处理。</p><p></p><h2>边缘计算关键要素</h2><p></p><p></p><p>边缘计算相关的的设备，如智能手机、智能手表和电器等，首先通过安全通信与物联网平台进行交互。这些平台收集和分析来自各种设备的数据，并通过应用程序将最有价值的数据发送回设备。</p><p></p><p>一些支持重要通信技术（如Wi-Fi、NarrowBand-IoT（NB-IoT）和Sigfox）以及诸如消息队列遥测传输（MQTT）、约束应用协议（CoAP）和超文本传输安全协议（HTTPS）等协议的物联网边缘设备可以直接连接到物联网平台。然而，并非所有设备都具备这些通信能力，因此需要一个抽象层来进行转换，提供多个协议和通信技术之间的桥梁，以实现数据的流动。</p><p></p><p>这个抽象层的作用是通过提供适应不同协议和通信技术的技术和流程来进行数据的中介转换。它充当了一个桥梁，使得不同类型的设备能够与物联网平台进行通信，无论它们使用的是哪种通信技术或协议。这样一来，物联网平台就能够充分发挥作用，连接和整合各种类型的设备，实现数据的流动和交互。</p><p></p><p>一个典型的物联网平台的架构如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/39/393e1efb17a053bc6362f6f46c51ce84.jpeg\" /></p><p></p><p>下面是对架构的每个层次的详细解析：</p><p></p><p>基础设施层（infrastructure）：该层包含了使整个平台正常运行所需的组件。在这里，你会找到各种计算/存储/网络解决方案、容器管理选项、数据湖、内部平台消息传递以及监控和存储解决方案。集成层（integration）：该层主要负责接收来自连接的边缘设备的数据，进行分析，并将其分发给业务应用程序，同时管理设备。在这一层中，数据会经过预处理、聚合和转换，以满足后续应用的需求。此外，集成层还负责处理设备注册、控制和管理等功能。安全层（security）：该层负责确保数据的有效性、安全性和隐私性，通过实施数据安全和权限原则以及采取补救控制和行动来进行监督。这包括对数据进行加密、身份验证、访问控制、漏洞管理等安全措施，以保护数据免受潜在的威胁。应用层（application）：该层包含使用集成层的基本物联网功能来实现业务目标的应用程序。这是承载复杂数据分析、条件监测、改装/配置和预测性维护等应用程序的地方。应用层的主要任务是根据业务需求开发和部署各种应用程序，以提供特定的功能和洞察力。</p><p></p><h2>物联网与边缘计算的关系</h2><p></p><p></p><p>物联网受益于处理能力更接近于物理设备或数据源。为了能够更快地对物联网传感器和设备收集的数据进行分析并做出反应，必须在边缘进行分析，而不是将数据传输回中央站点。</p><p></p><p>通过为物联网设备的数据和计算需求提供本地的处理和存储资源，边缘计算减少了物联网设备与连接的中央信息技术（IT）网络之间的通信延迟。</p><p></p><p>如果没有边缘计算，物联网将依赖于云端或数据中心的连接和计算服务。在物联网设备与云端之间来回传输数据可能会降低响应时间并降低操作效率。</p><p></p><p>在云计算模型下，计算资源和服务通常集中在大型数据中心。云端经常提供连接物联网设备与互联网所需的网络基础设施。边缘设备需要网络访问，以提供设备与中央数据库之间的双向通信。云端通常用于提供网络连接。例如，边缘设备通过云端将数据传输到数据中心，或边缘设备将其决策记录传输回数据中心进行数据存储、处理或大数据分析，这些都是云端的通信能力的示例。</p><p></p><p>下图是工厂制作车间与边缘云交互架构：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0d/0d6460df37ebf08a7536ce60fb158c04.jpeg\" /></p><p></p><h2>边缘计算的关键技术与架构</h2><p></p><p></p><h4>Microk8s：</h4><p></p><p></p><p>MicroK8s是一个功能强大、轻量级和可靠的适用于生产环境的Kubernetes发行版。它专为企业提供，具有较小的内存和磁盘占用，并具有一些关键特点如下：</p><p></p><p>下方是 Google 云 Anthos 与 MicroK3s 架构图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/50/50df8d1447c0f2e8476dcaa99ae52146.jpeg\" /></p><p></p><h4>K3s</h4><p></p><p></p><p>K3s是一个轻量级的Kubernetes发行版，专为在资源受限的环境中部署和运行的场景而设计。它是Kubernetes的简化版本，旨在提供更小、更快速和更易于管理的解决方案。</p><p></p><p>下方是其架构图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/30/302a7fb8351ff5811a9beca726e5fb63.jpeg\" /></p><p></p><h4>KubeEdge：</h4><p></p><p></p><p>KubeEdge是一个开源的边缘计算平台，旨在扩展Kubernetes的能力到边缘设备和边缘节点。它提供了一个统一的管理平台，用于部署、运行和管理容器化应用程序和服务，使得边缘设备能够高效地进行计算、存储和数据处理。</p><p></p><p>下方是其架构图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/26/26bafa06cdbc43cdaba08ea460bcbdfa.jpeg\" /></p><p></p><h4>OpenYurt</h4><p></p><p></p><p>OpenYurt 是业界首个非侵入的边缘计算云原生平台开源项目。主推“Kubernetes零修改”，“云边端一体化”等设计理念，提供诸如边缘自治、 跨网络域的云边流量治理、大规模边缘业务管理、边缘设备的云原生管理，异构资源支持等能力。OpenYurt 旨在帮助用户解决在海量边、 端资源上完成大规模应用交付、运维、管控的问题，同时为用户提供与云上Kubernetes集群一致的使用体验。</p><p></p><p>下方是其架构图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fc/fcfd20b12b7b24c476695e1aa62bca01.png\" /></p><p></p><h2>边缘计算中设备如何受益</h2><p></p><p></p><p>可扩展性：对于许多物联网解决方案来说，可扩展性是主要关注点。边缘计算基础设施需要能够独立水平或垂直扩展，以支持额外的设备和实时处理大量数据。与传统的虚拟机相比，容器生成速度更快，因为它们更轻量化。高可用性：对于物联网解决方案来说，边缘设备必须始终可用和可信。由于每个容器都有自己的IP地址，很容易在它们之间分配负载，并在容器停止运行时重新启动应用程序。资源有效利用：由于其有效的资源管理，Kubernetes降低了托管物联网应用的成本。MicroK8s、K3s等是经过精简优化的Kubernetes版本，它们在托管的虚拟机、裸金属实例或云上提供了一个抽象层。管理员可以专注于将应用服务部署在尽可能多的基础设施上，从而降低运行物联网应用的总体成本。部署到边缘：在不中断服务的情况下将软件更新部署到边缘设备是物联网的重要挑战。通过Kubernetes可以运行逐步推出服务更新的微服务。在Kubernetes安装中，通常使用滚动更新策略来推出Pod版本的更新。通过在更新进行期间保留某些实例运行（例如Pod Disruption Budgets），可以实现零服务停机时间。只有在新部署版本的可用且准备好替换它们的Pod已启用时，旧的Pod才会被删除。因此，可以通过单个命令实现应用的水平或向上扩展。支持IoT的DevOps：为了满足消费者需求，物联网解决方案必须平滑地进行更新，而无需用户停机时间。借助可用于Kubernetes的CI/CD工具，开发团队可以有效验证、推出和部署对IoT服务的更改。</p><p></p><h2>边缘计算架构及场景</h2><p></p><p></p><p>接下来主要是演示使用 K3 作为下一个边缘计算的主要平台的架构图。</p><p></p><h3>1. 边缘集群和公有云</h3><p></p><p></p><h4>架构分析</h4><p></p><p></p><p>云层（Cloud Layer）：这一层位于公有云和云服务提供商中。云服务提供商可以提供基于Intel或ARM处理器的实例。一般来说，这一层为远端和微小边缘层提供存储或数据处理支持。近端边缘（Near Edge）：在这一层中，您可以找到用于在云层和远端层之间传输所有数据的网络设备。通常包括电信设备、5G网络等。远端边缘（Far Edge）：在这一层中，您可以找到K3s集群、类似KubeEdge的轻量级集群以及Docker或containerd等软件。一般来说，这是您的本地处理层。微小边缘（Tiny Edge）：这是远端边缘内的一个层次，在这里您可以找到智能手表、物联网设备等边缘设备，它们将数据发送到远端边缘。</p><p></p><p>简而言之，这种配置方式通过公有云或私有云与边缘层共享和处理数据。云层位于公有云和云服务提供商之间，支持远端和微小边缘层的存储或数据处理。近端边缘层包括用于数据传输的网络设备。远端边缘层包括K3s集群、轻量级集群和容器化软件，用于本地数据处理。微小边缘层是远端边缘内的一个层次，包括智能手表、物联网设备等边缘设备，它们将数据发送到远端边缘进行处理。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a5/a5671bed195bf9cd397a241a3cd47df5.jpeg\" /></p><p></p><h4>适用场景</h4><p></p><p></p><p>在互联网或私有云中必须共享数据的不同系统之间的情景。在云端和边缘之间分配数据处理的场景，例如机器学习模型的生成或预测。需要扩展物联网应用程序，并且应用程序的响应时间至关重要的场景。希望使用数据分布和加密的聚合策略来保护数据的场景。</p><p></p><h3>2. 区域集群和公有云</h3><p></p><p></p><h4>架构分析</h4><p></p><p></p><p>此配置的重点是在不同区域之间分布处理策略，并在公共云之间共享数据。让我们来解释一下不同的层次:</p><p></p><p>云层（Cloud Layer）：这一层包含了像数据库这样的托管服务，用于在不同地区分布数据。近端边缘（Near Edge）：在这一层中，您可以找到网络设备，用于在云层和远端层之间传输所有数据。通常包括电信设备、5G网络等。远端边缘（Far Edge）：在这一层中，您可以找到跨不同地区的K3s集群。这些集群或节点可以共享或更新存储在公有云中的数据。微小边缘（Tiny Edge）：在这里，您可以找到靠近每个地区的不同边缘设备，远端边缘集群会因为这种分布式配置而处理这些信息。</p><p></p><p>简而言之，这种配置的重点是在不同地区分布处理策略，并在公有云之间共享数据。云层包含托管服务，用于将数据分布到不同的地区。近端边缘层包括网络设备，用于在云层和远端层之间传输数据。远端边缘层包括跨不同地区的K3s集群，它们可以共享和更新存储在公有云中的数据。微小边缘层包括靠近每个地区的边缘设备，远端边缘集群会根据这种分布式配置来处理这些设备传输的信息。这种配置将处理策略分布在不同地区，并实现了公有云之间的数据共享。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ab/aba6b81267d6a3b5ce6a2b94df27c1c6.jpeg\" /></p><p></p><h4>适用场景</h4><p></p><p></p><p>在不同地区使用不同的集群配置：边缘计算可以支持在不同地区设置具有不同配置的集群，以满足特定地区的需求。例如，根据特定地区的数据处理要求，您可以在某些地区配置更强大的处理节点，而在其他地区配置更轻量级的节点。减少应用程序的响应时间：在物联网应用程序中，应用程序的响应时间至关重要。边缘计算可以通过选择最近的数据或处理节点位置来减少应用程序的响应时间。通过将数据处理放置在靠近数据源的边缘节点上，可以减少数据传输的延迟，并实现更快的响应。在不同地区共享数据：边缘计算可以帮助在不同地区之间共享数据。这对于需要在全球范围内共享数据的组织或应用程序非常有用。通过在不同地区的边缘节点之间共享数据，可以实现数据的快速访问和共享，无需在云端进行大量的数据传输。在不同地区分布处理：边缘计算可以将处理任务分布在不同地区。这对于需要在不同地区进行数据处理的应用程序非常有用。通过将处理任务分配给就近的边缘节点，可以降低数据传输的延迟，并提高处理的效率。</p><p></p><h3>3. 单节点集群和（公有/私有）云</h3><p></p><p></p><h4>架构分析</h4><p></p><p></p><p>在这种基本配置中，一台计算机处理来自微小边缘设备的所有信息。</p><p></p><p>云层（Cloud Layer）：在这一层中，您可以找到系统的数据存储。它可以放置在公有云或私有云中。近端边缘（Near Edge）：在这一层中，您可以找到网络设备，用于在云层和远端层之间传输所有数据。通常包括电信设备、5G网络等。远端边缘（Far Edge）：在这一层中，您可以找到单个节点的K3s集群，它从微小边缘设备中收集数据。微小边缘（Tiny Edge）：这些设备用于捕捉数据，例如智能手表、平板电脑、摄像头、传感器等。这种配置更适合在本地或小规模上进行处理。</p><p></p><p>简而言之，这是一种基本配置，其中一台计算机用于处理来自微小边缘设备的数据。云层用于存储系统的数据，可以位于公有云或私有云中。近端边缘层包括网络设备，用于在云层和远端层之间传输数据。远端边缘层包括单个节点的K3s集群，用于从微小边缘设备中收集数据。微小边缘层包括用于捕捉数据的设备，例如智能手表、平板电脑、摄像头、传感器等。这种配置更适合在本地或小规模上进行处理，而不需要复杂的边缘计算架构。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8b/8b40bd1b0b554113e4f74c9113d4c4e2.jpeg\" /></p><p></p><h4>适用场景</h4><p></p><p></p><p>低成本和低能耗环境：这种基本配置适用于低成本和低能耗的环境。由于只有一台计算机进行处理，因此所需的硬件和能源成本相对较低。这对于资源有限或经济有限的场景非常有用。绿色边缘应用：这种配置适用于可由太阳能电池板或风力涡轮发电的绿色边缘应用。由于只有一台计算机进行处理，所需的能源消耗相对较低，可以与可再生能源一起使用，实现能源的环保和可持续。小型处理或用例：这种配置适用于处理小规模数据或小型用例的情况。例如，分析健康记录或自动化住宅系统等。这些用例通常不需要复杂的边缘计算架构，而是可以在本地进行处理，因此这种基本配置足够满足需求。</p><p></p><h2>总结</h2><p></p><p></p><p>边缘计算框架和工具在实现边缘计算的灵活性、可扩展性和协同性方面发挥着重要作用。KubeEdge、OpenYurt、K3s、MicroK8s都提供了不同的优点和适用场景，可以根据具体的需求和环境选择合适的框架和工具。它们使得边缘设备能够无缝地与云计算进行协同工作，实现数据的实时处理、资源的弹性利用和应用的高可用性，推动边缘计算的发展和应用。</p><p></p><p>随着企业拥抱数字化转型、行业4.0、工业自动化、智能制造以及这些举措提供的所有先进用例，Kubernetes、 edge 和云协作推动智能商业决策的相关性正变得越来越明显。</p><p></p><h4>作者介绍</h4><p></p><p></p><p>陈章朝，政采云有限公司运维开发工程师，一个热爱生活的编程爱好者，热于参与开源社区共建以及分享知识。</p>",
    "publish_time": "2023-07-07 10:10:45",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "深化数据库产业协作，着力推进我国数据库产业高质量发展｜2023 可信数据库发展大会",
    "url": "https://www.infoq.cn/article/vC4h2rWRyOylw0I4soj1",
    "summary": "<p>2023 年 7 月 4 日- 5 日，由中国通信标准化协会大数据技术标准推进委员会（ CCSA TC601 ）主办的“ <a href=\"https://www.infoq.cn/article/tQtvumNcUUEZuf4Tglex\">2023 可信数据库发展大会</a>\"” 在北京国际会议中心召开。中国移动信息技术中心政企业务支撑中心副总经理梁恩磊受邀参加了“共话数据库产业自立自强高水平发展”圆桌论坛，论道我国数据库自立自强之路，探索新形势下我国数据库产业的可持续、高质量发展。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f0/f0b7a5d2f4cdb415e34ccd0d322841a5.jpeg\" /></p><p></p><p>论坛围绕四个议题展开：</p><p></p><p></p><h2>一、把握数据库发展趋势，迎接海量数据处理与存储场景下新挑战</h2><p></p><p></p><p>梁恩磊表示，随着 5G 、物联网等业务的快速发展，数据库技术也面临新的要求和挑战。下一阶段，数据库最亟待解决的问题是如何进一步提升在海量高并发场景下的数据处理能力以及存储能力。</p><p></p><p>高性能数据处理：5G 和物联网技术的快速发展，给数据库在超高并发场景下的数据处理带来了巨大的挑战。下一阶段，数据库仍需要不断降低响应时延、提高并发处理能力，进一步降低 5G 、物联网等技术带来的数据处理压力，以满足在线计费、实时信控等各类实时业务场景的需求。</p><p></p><p>海量数据存储：5G 及物联网将以前所未有的速度生成海量数据。以物联网计费话单为例，每天产生数百亿条话单且仍在高速增长，对数据库的存储能力提出了更高的要求。因此需要数据库拥有快速扩展的能力，以便有效地存储和处理海量数据。</p><p></p><p>在应对方案上，梁恩磊表示，目前分布式是个大趋势，也是解决海量数据处理与存储的金钥匙。从传统的 Shared-Everything 架构，再到当前的 Shared-Nothing 、Shared-Disk 等分布式架构，都是为了更高效、更低成本地解决海量数据处理问题。未来，随着<a href=\"https://xie.infoq.cn/article/d866b6d5a158c9a7f44ad2263\">分布式数据库</a>\"的不断成熟，数据库在各类实时业务场景下对海量数据处理与存储的能力必将跨上一个新台阶。</p><p></p><p></p><h2>二、关注核心技术动向，实现数据库领域新发展</h2><p></p><p></p><p>梁恩磊表示，未来应重点关注数据安全、数据库智能化、分布式与云原生等技术方向。</p><p></p><p>首先是数据安全方向。随着国内大众的数据安全意识提升，以及《数据二十条》等政策标准的陆续出台，可以窥见安全审计、数据加密、身份验证等正在成为数据库领域新的关注热点。未来行业将逐步补齐传统数据库在安全领域的短板。</p><p></p><p>其次是数据库智能化方向。伴随着 ChatGPT 等技术的发展，<a href=\"https://xie.infoq.cn/article/1746e9a1bec2bfa64fd07293f\">向量数据库</a>\"以及数据库与这类 AIGC 技术的结合逐渐火热。前者解决此类技术在训练过程中的数据库存储问题，后者通过与 AIGC 技术的结合可以极大地降低数据库的使用门槛。</p><p></p><p>最后是分布式与云原生方向。万物互联时代，数据库也将从传统的存储“人”的数据转变为存储“物”的数据，给数据库层造成的压力将提升成百上千倍。未来，通过存储和计算分离等分布式技术以及与云原生技术的结合，将实现计算资源、存储的弹性伸缩，极大地降低业务架构的复杂度，为高效低成本地解决海量数据的处理与存储带来更多可能。</p><p></p><p></p><h2>三、围绕“三高一低”的主旋律，助力产业高速发展</h2><p></p><p></p><p>梁恩磊表示，在未来十年里，数据库领域毫无疑问地将发生各种变革和创新，但不变的是数据库的发展始终会围绕着“三高一低”（高性能、高稳定、高安全、低成本）的主旋律。</p><p></p><p>在性能方面，以电信行业为例：在集中式数据库时代，业务场景主要是通话与短信，相对单一且数据量较小，采用传统的集中式数据库即可满足大部分业务对数据库性能和成本的要求。随着通信行业快速发展，对数据库的性能有了更高的要求，逐步过渡到分库、分表时代。同时各类垂直、水平拆分技术也在快速发展，在运营商中最常见的是按省份、地市进行垂直拆分，但分片间数据的不均衡、业务分片架构的高复杂度等因素给这类方案带来了巨大的压力。随着移动互联网、物联网、5G 技术的发展，数据库也通过与分布式、云原生等技术的深度的结合有了更进一步的发展。</p><p></p><p>同理，业务对高性能、高稳定、高安全、低成本的诉求与数据库的发展也是相辅相成、互相促进的。围绕着“三高一低”的主旋律，数据库始终会将不断革新，持续满足业务发展需求。</p><p></p><p></p><h2>四、深化数据库产学研结合，推动我国数据库行业高水平发展</h2><p></p><p></p><p>梁恩磊表示，如果把数据库的自立自强比喻为一场攻坚战，那么学术侧主要提供武器的研究，产业侧负责武器的供应，应用侧则提供一线的实战。只有通过产学研的通力配合，才能实现优势互补，共同为数据库技术的发展奠定坚实的技术基础，实现从“攻出来”到“用起来”的紧密衔接。</p><p></p><p>为了进一步推动数据库产业的高质量快速发展，中国移动信息技术中心充分发挥多应用场景优势，联合深圳大学和香港科技大学（广州分校）成立广东省重点实验室，并作为组长单位参与信通院组织的数据库创新实验室，针对数据库产业、技术、生态发展等问题及对策展开研究，助力数据技术的联合攻关。</p><p></p><p>梁恩磊表示，科技自立自强是国家强盛之基、安全之要。未来，中国移动将进一步加深与政府、高校和研究机构的合作，共同推进数据库技术研究成果的产业化进程，推动国内数据库技术迅速走向世界前列。</p>",
    "publish_time": "2023-07-07 09:35:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "工业“智”造转型，如何兼顾技术效益与经济效益",
    "url": "https://www.infoq.cn/article/axF9GTTK8NAZpglDfCsb",
    "summary": "<p><img alt=\"unpreview\" src=\"https://static001.infoq.cn/resource/image/23/0b/237138648b7e88e782bbf1f4d2c2aa0b.jpg\" /></p>",
    "publish_time": "2023-07-07 13:46:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "2023 Microsoft Build 中国（上）",
    "url": "https://www.infoq.cn/article/L36SYlUMts0CvE7shHaJ",
    "summary": "<p>2023 年 6 月 15 日，Microsoft Build 中国圆满落幕。微软携手合作伙伴、技术社区的专家，共同展望下一代 AI 技术趋势，解读 Microsoft Build 全球大会新发布。</p>\n<p>特别值得一提的是，为了帮助开发者将晦涩难懂的技术内容转换为更易理解、吸收的内容，InfoQ 还特别联合微软策划了「第二直播间」。InfoQ 极客传媒主编赵钰莹与微软公司副总裁、微软大中华区首席运营官康容和微软生态伙伴事业部首席技术官徐明强博士，共同对大会的主题演讲进行了深度剖析。</p>",
    "publish_time": "2023-07-07 14:29:01",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "2023 Microsoft Build 中国（下）",
    "url": "https://www.infoq.cn/article/sBB9TU4Wor6ulMo4Um4s",
    "summary": "<p>2023 年 6 月 15 日，Microsoft Build 中国圆满落幕。微软携手合作伙伴、技术社区的专家，共同展望下一代 AI 技术趋势，解读 Microsoft Build 全球大会新发布。</p>\n<p>特别值得一提的是，为了帮助开发者将晦涩难懂的技术内容转换为更易理解、吸收的内容，InfoQ 还特别联合微软策划了「第二直播间」。InfoQ 极客传媒主编赵钰莹与微软公司副总裁、微软大中华区首席运营官康容和微软生态伙伴事业部首席技术官徐明强博士，共同对大会的主题演讲进行了深度剖析。</p>",
    "publish_time": "2023-07-07 14:38:32",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "LinkedIn图数据库LIquid：为9.3亿会员提供实时数据访问",
    "url": "https://www.infoq.cn/article/HcNBNAE4M3dI41AhZbSC",
    "summary": "<p>最近，LinkedIn分享了其<a href=\"https://engineering.linkedin.com/blog/2023/how-liquid-connects-everything-so-our-members-can-do-anything?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODg3MTE4MjEsImZpbGVHVUlEIjoiYlFUbTQ1a29OVUVKWmVTRiIsImlhdCI6MTY4ODcxMTUyMSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.h7-trVxuvE4x1rDLfW_cGCq6_6n0t80VdNN8FyMCJu4\">图数据库LIquid是如何自动索引和实时访问会员、学校、技能、公司、职位、工作、事件等之间的关系数据的</a>\"。这个知识图谱被称为LinkedIn的“Economic Graph”，有2700亿条边，并且还在不断增长，目前每秒处理200万次查询。</p><p></p><p>LinkedIn将其“你可能认识的人（People You May Know，PYMK）”推荐系统从传统的GAIA系统迁移到了LIquid。这一变化显著改善了每秒查询数（QPS）、延迟和CPU利用率。QPS从120增加到18000，延迟从超过15秒下降到平均50毫秒以下，CPU利用率下降了3倍以上。LIquid还引入了新的数据库索引技术，支持实时数据查询，实现了即时推荐。</p><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4f/4f0905ca0891ef0a5ff4aadc93c79004.webp\" /></p><p></p><p>图片来源：<a href=\"https://engineering.linkedin.com/blog/2023/how-liquid-connects-everything-so-our-members-can-do-anything?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODg3MTE4MjEsImZpbGVHVUlEIjoiYlFUbTQ1a29OVUVKWmVTRiIsImlhdCI6MTY4ODcxMTUyMSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.h7-trVxuvE4x1rDLfW_cGCq6_6n0t80VdNN8FyMCJu4\">https://engineering.linkedin.com/blog/2023/how-liquid-connects-everything-so-our-members-can-do-anything</a>\"</p><p></p><p>上图是系统的架构图，使用了LIquid，可以以较小的延迟和可接受的硬件成本来执行图查询。通过LIquid对<a href=\"https://economicgraph.linkedin.com/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODg3MTE4MjEsImZpbGVHVUlEIjoiYlFUbTQ1a29OVUVKWmVTRiIsImlhdCI6MTY4ODcxMTUyMSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.h7-trVxuvE4x1rDLfW_cGCq6_6n0t80VdNN8FyMCJu4\">Economic Graph</a>\"的查询生成数百个候选对象，并应用第二个排名函数。这个排名函数使用<a href=\"https://github.com/linkedin/venice?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODg3MTE4MjEsImZpbGVHVUlEIjoiYlFUbTQ1a29OVUVKWmVTRiIsImlhdCI6MTY4ODcxMTUyMSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.h7-trVxuvE4x1rDLfW_cGCq6_6n0t80VdNN8FyMCJu4\">Venice</a>\"的机器学习功能和<a href=\"https://github.com/apache/pinot?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODg3MTE4MjEsImZpbGVHVUlEIjoiYlFUbTQ1a29OVUVKWmVTRiIsImlhdCI6MTY4ODcxMTUyMSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.h7-trVxuvE4x1rDLfW_cGCq6_6n0t80VdNN8FyMCJu4\">Apache Pinot</a>\"的分析见解来评分并选择最佳候选对象。过滤步骤为呈现和最终评分准备好了这个排名列表。</p><p></p><p>LIquid的设计使其能够伸缩到当前十倍的规模，可以支持LinkedIn 9.3亿多会员的有机增长和新的语义领域。它提供99.99%的可用性，并可以自动根据图的大小和活动量的增加进行自动伸缩。</p><p></p><p>图数据库使用基于<a href=\"https://engineering.linkedin.com/blog/2020/liquid--the-soul-of-a-new-graph-database--part-2?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODg3MTE4MjEsImZpbGVHVUlEIjoiYlFUbTQ1a29OVUVKWmVTRiIsImlhdCI6MTY4ODcxMTUyMSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.h7-trVxuvE4x1rDLfW_cGCq6_6n0t80VdNN8FyMCJu4\">Datalog</a>\"的可组合声明式查询语言，帮助开发人员高效地访问和使用数据。可组合语言能够让开发人员在现有的特性（叫作模块）上进行构建，声明式语言能够让开发人员专注于表达他们想要开发的东西，而LIquid自动化了高效的访问过程。开发人员因此可以快速变更数据集，大大减少了调整和更新数据库所需的时间。</p><p></p><p>LinkedIn工程总监<a href=\"https://www.linkedin.com/in/bogdanarsintescu/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODg3MTE4MjEsImZpbGVHVUlEIjoiYlFUbTQ1a29OVUVKWmVTRiIsImlhdCI6MTY4ODcxMTUyMSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.h7-trVxuvE4x1rDLfW_cGCq6_6n0t80VdNN8FyMCJu4\">Bogdan Artintescu</a>\"描述了LIquid的发展路线图：</p><p></p><p></p><blockquote>要让会员能够做更多的事情，我们需要在回答会员的问题方面提供更加完善的能力。我们可以沿着两个方向做出改进。首先，复杂的查询和添加到Economic Graph的数据源的多样性将会驱动新特性的开发和呈现。其次，丰富数据将提高推理能力。这可以通过创建派生数据（通过确定性算法或概率机器学习方法）或通过知识图谱（KG）模式中更丰富的语义改进推理来实现。我们计划专注于高性能图形计算和分析，并建立一个KG生态系统，让我们的开发人员能够进一步增强会员体验。</blockquote><p></p><p></p><p>LIquid的成功激励了LinkedIn的其他团队和微软的姐妹团队将它作为图数据索引。</p><p></p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/06/linkedin-liquid-graph-database/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODg3MTE4MjEsImZpbGVHVUlEIjoiYlFUbTQ1a29OVUVKWmVTRiIsImlhdCI6MTY4ODcxMTUyMSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.h7-trVxuvE4x1rDLfW_cGCq6_6n0t80VdNN8FyMCJu4\">https://www.infoq.com/news/2023/06/linkedin-liquid-graph-database/</a>\"</p>",
    "publish_time": "2023-07-07 14:57:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "蚂蚁隐私计算“隐语技术栈“开源升级，推出隐语框架 1.0 并开源 HyperEnclave",
    "url": "https://www.infoq.cn/article/5KJiUZKVdGQDHOczrupV",
    "summary": "<p>7 月 7 日，<a href=\"https://www.infoq.cn/article/PogNN4aPEROGoKWJ1ZfN\">2023 世界人工智能大会</a>\"“数据要素与隐私计算高峰论坛”开幕。蚂蚁集团发布两项隐私计算开源产品：“<a href=\"https://www.infoq.cn/article/q5jpzKT7FQPXGihouEQR\">隐语</a>\"开源框架 1.0 ”和首个国产金融安全级 TEE 方案“ HyperEnclave ”。据了解，这两项技术产品是蚂蚁“可信隐私计算隐语技术栈”里的重要产品，该技术栈历时 6 年研发，可实现隐私计算工业级应用，也曾在 2022 年获得世界人工智能大会“八大镇馆之宝”。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7c/7c548a0c97f2d5d0409a3edd6082a76a.png\" /></p><p>蚂蚁隐私计算隐语技术栈中的隐语开源框架正式发布 1.0 版</p><p></p><p>据介绍，“隐语开源框架”是“隐语技术栈”中的计算引擎层，HyperEnclave 是其可信基座。该技术栈完全自研，积累了千余项专利，集合了隐语开源框架、Occlum TEE 开源操作系统，HyperEnclave 等领先的隐私计算技术产品，孵化了可信密态计算（TECC）等新型隐私计算技术。此次开源两个新产品功能，有望为隐私计算在易用、通用性上带来跨越式提升，从而帮助行业用 <a href=\"https://www.infoq.cn/article/g2dxkXzWCtLEpuizIxqR\">AI 智能</a>\"中更安全更可信，充分释放数据价值。</p><p></p><p>蚂蚁集团认为，人工智能的深度应用，不仅对数据、算法、算力提出了更高要求，也对安全、隐私、伦理提出更多挑战。在确保数据安全和隐私保护、健全人工智能伦理与安全的前提下，才能让 AI 技术真正地释放应用价值。隐私计算作为其重要技术支撑，正在迎来技术突破和产业发展的新动力，但易用通用性一直是行业掣肘。</p><p></p><p>记者了解到，此次隐语 1.0 无论从开源范围、性能，还是易用性上都取得了跨越式提升。隐语框架去年 7 月首次开源，历时 1 年正式升级到 1.0 版。新版本有三大优势：首先，开源 Kuscia 隐私计算任务编排框架，可以解决业务在使用隐语时端口合并、API 接入等集成问题，支持通过互联互通或者内置部署第三方系统等不同模式与第三方系统互通。&nbsp;其次，新增支持 SS-LR 开放算法协议，致力于打造黑白盒全栈互联互通能力。同时，隐语 1.0 推出了“开箱即用”轻量化部署体验包，再次降低了隐私计算应用门槛。</p><p></p><p>在本次论坛上，蚂蚁也正式开源了基于 TEE 技术的金融安全级方案“ HyperEnclave ”。TEE 是隐私计算的技术路线之一，被认为是数字化时代数据安全上云和隐私保护计算的最有效技术手段。据了解，HyperEnclave 的优势是安全、兼容。它支持国内外主流 CPU 硬件平台，提供统一 TEE 抽象，核心代码经过形式化验证。同时，HyperEnclave 将硬件技术最重要的信任根托管在可信权威机构，满足国产自研要求，已具备规模化商业场景的落地经验。此次开源也有望为行业带来更透明、更可信、更统一、更通用的国产 TEE 技术方案。</p><p></p><p>记者注意到，一些技术“软基建”也在论坛上带来了重要进展。IEEE（电气与电子工程师协会）正式发布了行业首个“可信执行环境安全”国际标准 IEEE2952-2023 。该标准由蚂蚁集团牵头，制定了基于 TEE 技术的安全计算系统的技术框架，为业界提供了有效指导。中国信通院、中国移动、中国联通、中国电信、蚂蚁集团和洞见科技联合发布了《隐私计算 跨平台互联互通开放协议 第 2 部分：SS-LR 》。该协议将搭建更加开放、透明、安全的隐私计算互联互通平台，保护数据安全。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/41/41cac447b0fc194e7b72408f05d994e6.png\" /></p><p>IEEE 正式发布行业首个“可信执行环境安全”国际标准</p><p></p><p>蚂蚁集团副总裁兼首席技术安全官韦韬表示，“历史的机遇、技术的变革，将数据智能推向了前所未有的高潮，也带来了更加严峻的数据安全挑战，数据流通迈向密态化是未来趋势。数据密态要求下，隐私计算的方法体系、平台框架、技术标准都面临全新变革”。韦韬也呼吁更多的同行参与到开源和生态建设工作当中，“开源隐私计算核心产品一直是我们对行业的态度，未来蚂蚁将持续加大隐私计算的开放力度和广度，与行业一道构筑 AI 智能时代数据安全护城河。”</p><p></p><p>本场论坛汇聚了国内外研究机构和顶尖学者以及产业人士等，从不同视角分享了 AI 数据智能和数据要素化大潮下的隐私计算研究、应用和趋势，这些深入的讨论，也将为隐私计算如何护航 AI 智能、助力数字经济发展提供更加明确的前进方向。</p>",
    "publish_time": "2023-07-07 15:24:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "齐心集团 CTO 于斌平确认出席 ArchSummit 深圳，分享企业数字化实践经验",
    "url": "https://www.infoq.cn/article/Xfulpc40oKvvHfgp3sMR",
    "summary": "<p>7&nbsp;月&nbsp;21&nbsp;日&nbsp;-&nbsp;22&nbsp;日，&nbsp;在&nbsp;<a href=\"https://archsummit.infoq.cn/2023/shenzhen?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">ArchSummit&nbsp;全球架构师峰会（深圳站）</a>\"，齐心集团&nbsp;CTO&nbsp;于斌平，将于会上发表题为《数字化加持的产业供应链革新》的演讲，用实际案例与大家一起探索数字化技术如何才能真正落地为企业为客户产生价值。</p><p></p><p>于斌平是前国美零售控股有限公司副总裁、CTO，前国美控股集团技术委员会主席。产业互联网领域、数字供应链领域技术专家，零售、电商、物流领域技术专家。十多年&nbsp;500&nbsp;人以上技术团队带头人角色。从零开始一手建立了国美互联网和国美零售的技术体系，主导建立了国美零售的产品、研发、大数据、云平台、AI&nbsp;智能平台、及中台系列等核心技术系统，并主导建立了行业首家大型数字化服务平台和物流平台。成功建立了年销售超千亿的零售电商平台、线下线上统一融合的共享数智化平台。现致力于产业互联网领域和数字供应链领域的数字化研究和建设工作。</p><p></p><p>相信通过于斌平的分享，你将了解在产业互联网领域，数字化如何落地才能为企业为客户降本增效，学习到如何在个性中找共性、如何重新理解数字化理解技术、如何构建数字化平台来为企业和客户服务。</p><p></p><p>除上述议题外&nbsp;，ArchSummit&nbsp;深圳还将围绕<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1537?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">基础架构技术</a>\"、<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1532?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">DataOps、Data&nbsp;Fabric&nbsp;等高效数据开发与服务模式</a>\"、<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1534?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">Mesh&nbsp;技术实践案例</a>\"、<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1535?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">QUIC&nbsp;传输和架构优化</a>\"等进行分享。</p><p></p><p>数十位业界专家，上百个国内外一线大厂前沿技术案例，一定会给你带来很多全新的开发灵感。期待与你线下交流！咨询购票请联系&nbsp;18514549229（微信同手机号）</p><p><img src=\"https://static001.infoq.cn/resource/image/9d/aa/9d6a27547062ee2e089f91bdc4ba1eaa.png\" /></p><p></p>",
    "publish_time": "2023-07-07 16:01:12",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "蚂蚁集团发布 AI 安全检测平台“蚁鉴 2.0 ”，可实现用生成式能力检测生成式模型",
    "url": "https://www.infoq.cn/article/KvxWGt1PKhSaE1WSq5bf",
    "summary": "<p>7 月 7 日，2023 世界人工智能大会（ WAIC ）“聚焦·大模型时代 AIGC 新浪潮—可信 AI ”论坛举行，<a href=\"https://www.infoq.cn/article/xNYUNddIBuiIdtRi8smB\">蚂蚁集团</a>\"联合清华大学发布 AI 安全检测平台“蚁鉴 2.0 ”。<a href=\"https://www.infoq.cn/article/PogNN4aPEROGoKWJ1ZfN\">蚁鉴 2.0</a>\" 可实现用生成式 AI 能力检测生成式 AI 模型，可识别数据安全、内容安全、科技伦理三大类的数百种风险，覆盖表格、文本、图像等多种数据和任务类型，是业内首个实现产业级应用的全数据类型 AI 安全检测平台。据了解，该产品还入选了本届大会的“镇馆之宝”。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e9/e9877eb1500a5ebfe8b7ca459cbc3909.png\" /></p><p>蚂蚁集团联合清华大学共同发布 AI 安全检测平台“蚁鉴 2.0 ”</p><p></p><p>AIGC 安全成为当前人工智能研究发展的重要议题。中国科学院院士何积丰发表《可信人工智能展望》主题演讲。他认为，“不能再将人工智能视为简单的技术工作，而是成为整个组织的变革引擎。可信人工智能要致力于保障数据安全可信、系统行为可追责、算法模型可解释、网络环境可信、法律伦理可信等问题。”</p><p>&nbsp;</p><p>在该论坛上，蚂蚁集团同时宣布，“蚁鉴 2.0 ”全面开放，面向全球开发者免费提供 AIGC 安全性、AI 可解释性、<a href=\"https://www.infoq.cn/article/iBHmuLWBH14YgWjhD1Xq\">AI 鲁棒性</a>\"三项检测工具，可服务于数字金融、教育、文化、医疗、电商等领域的大规模复杂业务场景。</p><p>&nbsp;</p><p>据了解，“蚁鉴 2.0 ”的两项硬核能力，一是实现了用生成式能力检测生成式模型。检测标准覆盖内容安全、数据安全、伦理安全三大类，可对大模型生成式内容完成包含个人隐私、意识形态、违法犯罪、偏见与歧视等数百个维度的风险对抗检测，并会生成检测报告，帮助大模型更加有针对性地持续优化。</p><p></p><p>蚂蚁集团大安全事业群技术部总裁李俊奎表示，“生成式大模型是一种‘深黑盒’技术，‘蚁鉴 2.0 ’通过智能博弈对抗技术，模拟黑产以及自动化生成海量测试集，可实现「生成式机器人」对「AIGC 生成式模型」的诱导式检测计算，很像一个 24 小时不眠不休的‘安全黑客’在找茬大模型，从而找到大模型存在的弱点和安全问题所在。这种 AI 对 AI 的评测，也是教学相长。好比生成式考官考核生成式运动员，在对抗中双方能力互相提升，进一步提高整个行业的 AI 安全水位。”</p><p>&nbsp;</p><p>另一项硬核能力是，“蚁鉴 2.0 ”融入了可解释性检测工具。综合 AI 技术和专家先验知识，通过可视化、逻辑推理、因果推断等技术，从完整性、准确性、稳定性等 7 个维度及 20 余项评估指标，对 AI 系统的解释质量量化分析，帮助用户更清晰验证与优化可解释方案。</p><p>&nbsp;</p><p>据了解，“蚁鉴 2.0 ”集成了蚂蚁近 10 年可信 AI 实践、1000 余项可信 AI 专利，支持零编码测评。开发者通过 API 接口，将 AI 模型接入蚁鉴，就可以一键识别和挖掘模型漏洞。</p><p>&nbsp;</p><p>蚂蚁集团认为，人工智能的深度应用，不仅对数据、算法、算力提出了更高要求，也对安全、隐私、伦理提出更多挑战。在确保数据安全和隐私保护、健全人工智能伦理与安全的前提下，才能让 AI 技术真正地释放应用价值。</p><p>&nbsp;</p><p>此次论坛上，中国信通院、上海人工智能实验室、武汉大学、蚂蚁集团等多家单位共同发起的《 AIGC 可信倡议》。该倡议得到数十家单位参与，围绕人工智能可能引发的经济、安全、隐私和数据治理等问题，提出构建 AIGC 可信发展的全球治理合作框架，采用安全可信的数据资源、技术框架、计算方法和软件平台等全面提升 AIGC 可信工程化能力，最大限度确保生成式 AI 安全、透明、可释。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4c/4c5f5770e91ef1bca53feccf119477f5.png\" /></p><p>在 2023 WAIC 可信 AI 论坛上，“产学研用”界共同发起 AIGC 可信倡议</p><p></p><p>论坛现场还发布了由中国信通院、清华大学、蚂蚁集团联合编纂的《可信 AI 技术和应用进展白皮书（ 2023 ）》。该报告基于统一的可信 AI 认知维度，梳理总结可信 AI 发展现状，提练了面向新阶段大模型和 AIGC 引发的新需求，形成以技术为保障的可信 AI 评估体系和工具，探索新一代可信人工智能发展。</p><p>&nbsp;</p><p>公开资料显示，蚂蚁从 2015 年开启可信 AI 的实践和探索，是蚂蚁集团在人工智能领域的重点布局之一。通过可信 AI 技术的突破，蚂蚁集团建设了一套世界领先的智能风控解决方案；蚁鉴 AI 安全检测平台先后获得 2022 年上海金融科技中心建设三周年优秀成果、信通院可信人工智能实践标杆案例等认可。</p><p></p>",
    "publish_time": "2023-07-07 16:39:06",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "OpenAI 宣布 GPT-4 API 全面开放使用！",
    "url": "https://www.infoq.cn/article/WKOc9Wtqh3tVAWRF0fvP",
    "summary": "<p>当地时间7月6日，OpenAI 在<a href=\"https://openai.com/blog/gpt-4-api-general-availability\">官网宣布</a>\"，GPT-4 API全面开放使用。现所有付费API用户都可直接访问8K上下文的GPT-4，无需任何等待。该公司计划在本月底之前向新开发人员开放访问权限，然后“根据计算可用性”开始提高可用性限制。这意味着全球开发者都能使用GPT-4大型语言模型，来增强自己的应用程序或开发全新的生成式AI应用。</p><p>&nbsp;</p><p><a href=\"https://openai.com/blog/gpt-4-api-general-availability\">OpenAI 在博客文章</a>\"中写道：“自 3 月份以来，数百万开发者请求访问 GPT-4 API，并且利用 GPT-4 的创新产品范围每天都在增长。”&nbsp;“我们设想基于对话的模型未来可以支持任何用例。”</p><p>&nbsp;</p><p>GPT-4 可以生成文本（包括代码）并接受图像和文本输入，GPT-3.5只接受文本并在各种专业和学术基准上表现出“人类水平”。与 OpenAI 之前的 GPT 模型一样，GPT-4 是使用公开数据进行训练的，包括来自公共网页的数据以及 OpenAI 许可的数据。目前，图像理解功能尚未提供给所有 OpenAI 客户。OpenAI 与单一合作伙伴<a href=\"https://techcrunch.com/tag/be-my-eyes/\">Be My Eyes进行了测试</a>\"，但没有表示什么时候向更广泛的客户群开放。</p><p>&nbsp;</p><p>即使是当今最好的生成式 AI 模型，GPT-4 也并不完美。OpenAI 表示，未来将允许开发人员微调 GPT-4 和<a href=\"https://techcrunch.com/2023/03/01/openai-launches-an-api-for-chatgpt-plus-dedicated-capacity-for-enterprise-customers/\">GPT-3.5 Turbo</a>\"。据 OpenAI 称，该功能将于今年晚些时候推出。</p><p></p><p>此外，基于这些模型的稳定性和生产规模使用的准备程度，OpenAI还推出了GPT-3.5 Turbo、DALL·E和Whisper API。DALL-E 2是 OpenAI 的图像生成模型，“ Whisper ”指该公司的开源语音识别翻译模型。</p><p></p><p>该公司还表示，计划弃用一些使用 Completions API 的旧模型，以“优化计算能力”。从 2024 年 1 月 4 日开始，某些较旧的 OpenAI 模型（特别是 GPT-3 及其衍生物）将不再可用，并将被新的“base GPT-3”模型所取代。使用旧模型的开发人员必须在 1 月 4 日之前手动升级其集成，而那些希望在 1 月 4 日之后继续使用经过微调旧模型的开发人员将需要在新的 base GPT-3 模型之上微调替换模型。</p><p></p><p>更多信息可查看：</p><p>https://openai.com/blog/gpt-4-api-general-availability</p>",
    "publish_time": "2023-07-07 16:50:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "以大模型“对抗”大模型，2023WAIC 专家热议大模型时代如何保护隐私和安全",
    "url": "https://www.infoq.cn/article/LHxY4zv2dPgJfWaJYxtC",
    "summary": "<p>凭借大数据、大算力的“大力出奇迹”，&nbsp;AI 大模型带来的“智能涌现”，让人类又一次站在了技术革命的转折点。与之伴生的用户隐私泄漏、数据滥用等问题被敲响了警钟。作为平衡数据使用与隐私安全的关键技术，隐私计算面临新的机遇和挑战。</p><p>&nbsp;</p><p>在<a href=\"https://www.infoq.cn/article/PogNN4aPEROGoKWJ1ZfN\"> 2023 世界人工智能大会</a>\"（ WAIC ）“数据要素与隐私计算高峰论坛”上，复旦大学教授、上海市数据科学重点实验室主任肖仰华与中国信通院云大所大数据与区块链部副主任闫树展开高端对话，深入研讨了大模型时代隐私计算研究发展。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/73/737f3d63ee97805915f538eafb2930ea.png\" /></p><p>“数据要素与隐私计算高峰论坛”对话大模型时代的隐私计算</p><p></p><p>两位专家共同认为，总体上大模型是先进生产力，不能因为隐私等的顾虑放弃对大模型的应用。某种程度上，大模型是一种不确定市场，要正面正视隐私等问题，积极应用大模型。</p><p>&nbsp;</p><p>但大模型的破坏性已经显化，要兼顾安全，不能盲目发展。要建立大模型安全底线和合规规范，从数据源头把关，加快大模型语料合规性认证等。非常重要的一点是，要用大模型“对抗”大模型，如利用大模型对生成内容的评估，用大模型自身的能力来保护我们的隐私。要用隐私计算的随机性、匿名化等方法，优化大模型数据分层，同时提升隐私计算本身的性能。</p><p></p><p></p><h2>“隐私安全是老问题，但是在大模型时代变得特别突出”</h2><p></p><p></p><p>“对于 AI 的发展来说，今年可能是比较特殊的一年。各类大模型‘智能涌现’，再一次诠释了数据的重要价值。然而 AI 大模型是把双刃剑，带来了突出的隐私和安全问题，隐私计算作为保护数据安全的技术可以做什么？”闫树强调了加速隐私计算研究的必要性。</p><p>&nbsp;</p><p>肖仰华认为，大模型对隐私保护问题带来了前所未有的挑战，主要表现在侵权识别和保护两个层面，比如隐私泄露、版权侵犯。首先，大模型是一个大规模参数化的模型，训练数据来源多样，隐私保护非常困难。其次，生成式大模型往往是一种概率化的生产，是一种海量拼接式的生产，大模型是否侵犯隐私的识别本身很困难。所以传统意义上的隐私侵犯认定，在大模型时代往往会失效。另外，从保护角度来说更困难。大模型是基于深度神经网络的架构，本质上是黑盒模式。它的不同的参数到底习得了什么样的知识或能力我们无从得知。“问题是老问题，但是在大模型时代这些问题变得特别突出”。</p><p></p><p></p><h2>解决使用大模型时的隐私安全问题，隐私计算技术已有探索</h2><p></p><p></p><p>不止训练大模型带来隐私安全问题，大模型使用的安全问题也是当前的重点。隐私计算如何保证大模型使用的隐私安全？当前业界已经有了一些探索。</p><p>&nbsp;</p><p>闫树介绍，现在隐私计算各种各样的路线，包括可信执行环境 TEE 、多方安全计算 MPC 等都有与大模型结合的探索，比如在云端部署 TEE ，用户在推理时将输入数据加密传输至云端，在其内部解密然后进行推理；还有在模型推理阶段使用多方安全计算来提升隐私保护能力，但不可避免地会对模型训练和推理的性能造成影响。</p><p>&nbsp;</p><p>肖仰华认为，一是要建立系统性防范体系。从用户角度讲，要建立大模型隐私安全意识，充分意识到使用过中数据有可能被服务方收集；从提供服务的厂商来看，要提升服务的规范性，在用户完全授权的情况下收集用户相关的使用数据，不能超出用户授权范畴。二是从技术本身做创新，比如通过设置网络中间层，在中间层来自很多用户的查询或者使用可以混淆打乱，这时平台方就无法知道哪个用户在查哪个数据。所以传统的随机化匿名化，在大模型时代仍然还是有一定的适用性。</p><p>&nbsp;</p><p></p><h2>大模型时代隐私计算研究的机遇与挑战</h2><p></p><p>&nbsp;</p><p>大模型一定程度上也会改变隐私计算技术的发展和研究，那么该如何更好地适用与大模型？</p><p>&nbsp;</p><p>闫树认为，首先可以重点关注隐私计算的可用性研究。就是目前来讲，隐私计算用于大部分训练时，性能是主要问题。另外合规性的探讨也是需要各界携手来，加强技术和法律领域的联合研究，共同探讨隐私计算技术的应用场景和效果，明确隐私计算技术的合规性。</p><p>&nbsp;</p><p>肖仰华认为，大模型时代隐私计算迎来全新机遇。传统的隐私计算如差分隐私、联邦学习多是算法层开展工作。但算法工作前提是保护对象是明确的，协作机制清晰。但大模型时代是海量参数化的模型，不透明、无边界、不可解释，对于以前的基于可解释、清晰、可控的技术路线的隐私计算方法提供了全新挑战。包括上升到技术架构层面，大模型的隐私保护，要分层分级保护数据，大模型做基本的智能能力，要保护的数据还是在传统的加密数据库，二者如何协同，这个是从架构层面要研究的。</p><p>&nbsp;</p><p>行业已有很多动作助力隐私计算未来更复杂更高要求的应用。在本次论坛上<a href=\"https://www.infoq.cn/article/iBHmuLWBH14YgWjhD1Xq\">蚂蚁</a>\"就开源了自研隐语技术栈中的<a href=\"https://www.infoq.cn/article/5KJiUZKVdGQDHOczrupV\">隐语</a>\"框架 1.0 版，和国产金融安全级 TEE 方案“ HyperEnclave ”，将为行业提供易用通用的技术方案。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f7/f73ad592f6833a0703bca2b0dac61062.png\" /></p><p>2023WAIC，业内首个金融安全级国产 TEE 方案 HyperEnclave 正式开源</p><p></p><p>由蚂蚁牵头的行业首个“可信执行环境安全”国际标准 IEEE2952-2023 在论坛上正式发布，制定了基于 TEE 技术的安全计算系统的技术框架，为将为业界提供有效指导。</p>",
    "publish_time": "2023-07-07 16:58:22",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "黄东旭：我对数据库如何Serverless 化的一些思考",
    "url": "https://www.infoq.cn/article/gEogP4tDBz3LQv5ym4Ek",
    "summary": "<p></p><p>写这篇文章的起因是有一次和朋友聊到一个很有趣的话题：如果我要为 1 亿用户提供免费的数据库云服务，这个系统应该如何设计？为了回答这个问题，我在之前的两篇 Blog 中隐隐约约提到，我们在使用一些全新的视角和思路去看待和构建数据库服务，并将这些思考变成了实际的产品：tidb.cloud/serverless，很多朋友很想了解 TiDB Cloud Serverless （下面会简称为 TiDB Serverless）的更多细节，所以便有了这篇博客。</p><p></p><p>有些朋友可能还不太了解<a href=\"https://www.infoq.cn/article/c15XzsQPYQUl8g5lyCo8\"> TiDB</a>\"，请允许我先快速介绍一下 TiDB 本身。对 TiDB 比较熟悉的朋友可以跳过这段，主要是一些关键的名词和定义：</p><p></p><p>TiDB：特指由 tidb （负责 SQL 解析和执行） / tikv （负责数据存储） / pd （负责元信息和调度） 等组件组成的分布式数据库系统。TiDB Cloud：一个提供 TiDB 的云服务，在云上提供全托管的 TiDB。TiDB Cloud Serverless：一个提供 TiDB 的云服务，云原生 / 多租户，拥有极低的使用成本与启动时间，使用 Pay-As-You-Go 的付费模式，并在小规模的场景上完全面向开发者免费。</p><p></p><p>2015 年初，我们启动了一个非常有野心的计划。受到 Google Spanner 和 F1 的启发（我更愿意称之为鼓舞），我们希望构建一个理想的分布式数据库：支持 SQL、使用 MySQL 协议和语法、支持 ACID 事务语义、不对一致性妥协；对业务透明且无上限的水平扩展能力，能够根据而业务流量和存储特征动态调整数据的物理分布达到极高的硬件利用率；高可用及故障自愈能力，降低人工运维的负担。</p><p></p><p>在这些目标的驱动下，从一开始我们就做出了如下的技术决定：</p><p></p><p>高度模块化。例如：tidb-server 负责 SQL 的解析和优化，tikv / tiflash 负责存储（和一部分分布式计算），pd 负责元信息存储及发起调度指令。存储层采用一个支持 ACID 事务的 Share-Nothing 架构的 Key-Value Database （tikv）以支撑弹性扩展，其他模块尽量设计成无状态的模式。如：当基础的 TiDB bootstrap 完毕后，很多信息都可以存储在 TiDB 自己的系统表中，如 SQL 优化要使用的统计信息等。尽量避免局部状态（例如不单独区分本地索引和全局索引）以降低故障恢复逻辑的复杂度。</p><p></p><p>可以看得出，这个设计就是奔着极强的扩展性和超大规模的场景去的，早期也确实如此。最初，TiDB 的想法来自于替换一些超大规模的 MySQL 分库分表方案，这个策略很成功，在无数的客户那已经得到验证，甚至还替换了一些以规模见长的 NoSQL 的系统，例如 Pinterest 在他们的 Blog 中提到他们将他们的 HBase 成功替换成了 TiDB（<a href=\"https://medium.com/pinterest-engineering/online-data-migration-from-hbase-to-tidb-with-zero-downtime-43f0fb474b84%EF%BC%89\">https://medium.com/pinterest-engineering/online-data-migration-from-hbase-to-tidb-with-zero-downtime-43f0fb474b84）</a>\"</p><p></p><p>回顾当年做的一些决定，TiDB 是很正确的：</p><p></p><p>大的模块上清晰的分离设计。计算、存储、调度、元信息管理都在不同的服务中，这样的好处是把复杂性限制在模块内部和无状态的组件（例如 TiDB 的 SQL 层）中，很容易水平扩展以及负载均衡。尽管用户看到的是一个关系型数据库，但是 TiDB 的存储层使用简单的 KV 作为抽象 + 极其细粒度的调度单元（region，96MB 的连续 Key-Value Pairs）+ 灵活的数据移动原语。好处是能够以很细的粒度移动数据，这让业务层理论上可以以任意的方式摆放任意数据，这是后来的 Placement Rules 等功能实现的基础。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/8c/8c7476a8034ad044a68a6176715cd980.png\" /></p><p></p><p>但是随着时间的推移，我们渐渐发现了两个趋势：</p><p></p><p>当<a href=\"https://www.infoq.cn/article/select-the-appropriate-rdmbs-for-the-oltp\"> OLTP</a>\" 业务可以很好地支持横向水平扩展后，对于一个支持 SQL 的数据库来说，用户在上面进行简单的实时 OLAP 请求是很自然的选择，这个观察催生了 TiFlash。并不是所有的业务一开始都有如此巨大的数据需要分布式的存储，但是增长的预期是普遍存在的，所以更重要的问题是：当数据量和业务量真的增长到需要分布式数据库的容量时，开发体验是否还能保持一致（例如分库分表就是一个破坏开发体验的行为），而在刚开始数据量较小的时候又能以一个很低的成本起步。</p><p></p><p>上面的需求，在传统的 Shared-nothing 架构下，会有以下几点限制。</p><p></p><p>对于第一个趋势来说，OLTP 和 OLAP 确实在融合，但是在传统的 Shared-nothing 架构下其实是成本很高的，原因是对于 OLAP 应用来说，大多数时候 CPU 会成为瓶颈，CPU 是最昂贵且的资源。为了追求性能，我们只能增加更多的计算资源（也就是物理服务器），而 OLAP 业务通常又不是在线服务，所以这些 workload 其实并不要求 7x24 小时独占这些资源，但是为了运行这些 workload，我们不得不提前将这些资源准备好，即使 TiFlash 在存储层已经能很好的弹性伸缩（可以按需对特定的表 Ad-hoc 的创建 TiFlash 副本）但很难在非云的环境下对计算资源进行弹性伸缩。</p><p></p><p>对于第二个趋势，传统 shared-nothing 架构的分布式数据库通常假设所有物理节点的硬件配置对等，否则会加大调度的难度；另外为了追求极致的性能，通常会放弃多租户的设计，因为在云下大多数的数据库部署对于应用来说都是独占式的。而要降低数据库的使用成本不外乎两条路：</p><p></p><p>多业务（租户）共享一个数据库集群冷热数据分离，使用更便宜的硬件存储冷数据。</p><p></p><p>另外就是业务开始上云，这点提的比较多，就不赘述了。</p><p></p><p>基于以上的假设，我们思考一个问题：如果今天重写 TiDB，应该有哪些新的假设、作出哪些选择，去覆盖更多应用场景和更高的稳定性。</p><p></p><p>假设：</p><p></p><p>人人都爱低成本起步。按需计价，能够支持 Scale-to-Zero，不用的时候不收钱是很好的体验，而且当有海量用户时绝大多数用户是非活跃的，workload 的分布也满足二八定律。对于关系型数据库市场来说，OLTP 仍然是主流，OLAP 最重要的是弹性和低成本（其实并非性能）。另外一个容易被忽略的场景是轻量的 data transformation（一个好的例子是 dbt），频繁在不同的数据服务商之间移动数据并不是好体验。大量冷数据、少量热数据，但是常常没有办法很清楚地划分冷热边界（就像你不能突然阻止我在 3 年前的朋友圈上回复某个对话一样）。大数据量的在线服务场景是存在的（例如社交网络），但是一定会配合有区分度极高的二级索引使用（例如：user_id / account_id 等），在这个索引的覆盖下，一个查询扫描的数据量不会太大。这种场景下，内存缓存的命中率及其重要。CPU 很难拓展，存储很好扩展；CPU 很贵，存储很便宜。云基础设施在云上和云下都会普及（对象存储、容器平台等）。“稳定 + 可预测的性能”，比不稳定的高性能更好。</p><p></p><p>选择：</p><p></p><p>Built-in 的多租户隔离能力：需要能够低成本支持粒度很细（小）的海量租户，毕竟只有共享资源才能将单位成本持续降低。存储层：利用不同的存储和计算服务，而不是对等的物理机器，尤其是利用好对象存储。仍然沿用分离的设计，但不再是以一个软件的形式交付，而是以一组微服务组成的平台服务进行交付。</p><p></p><p>更重要的选择是我在之前文章提到的：与其把数据库放到云上运维，更应该将云数据库作为一个完整的云服务设计。在这个指导思想下，我们开始了 TiDB Cloud<a href=\"https://www.infoq.cn/article/vHCG1pJpsLapBBMvbvZM\"> Serverless</a>\"，因为细节太多，我不可能在这篇文章内一一照顾到，思来想去挑了两个重点在这篇文章中介绍一下：存储引擎和多租户。</p><p></p><h3>存储引擎设计</h3><p></p><p></p><p>在传统的上下文中，我们提到存储引擎时一般都想到 LSM-Tree、B-Tree、Bitcask 什么的，另外在传统的语境中，这些存储引擎都是单机的，对于一个分布式数据库来说，需要在本地存储引擎之上再构建一层 Sharding 逻辑决定数据在不同物理节点上的分布。</p><p></p><p>但是在云上，尤其对于构建一个 Serverless 的存储服务，数据的物理分布不再重要，因为 S3 (对象存储，这里包含但也并不特指 AWS S3) 已经将扩展性和分布式可用性的问题解决得足够好（而且在开源社区也有高质量的对象存储实现，如 MinIO 等）。如果我们将在 S3 的基础之上构建的一个新的“存储引擎“看成整体的话，我们会发现整个分布式数据库的设计逻辑被大大简化了。</p><p></p><p>为什么强调存储引擎？因为计算层抽象得好的话是可以做到无状态的（参考 TiDB 的 SQL 层），无状态系统的弹性伸缩相对容易做到，真正的挑战在于存储层。从 AWS S3 在 2022 年的论文中我们可以看到，AWS 在解决 S3 的弹性和稳定性问题上花了极大的功夫（其实 S3 才是 AWS 真正的 Serverless 产品！）。</p><p></p><p>但是 S3 的问题在于小 I/O 的延迟，在 OLTP workload 的主要读写链路上不能直接穿透到 S3，所以对于写入而言，仍然需要写入本地磁盘，但是好在只要确保日志写入成功就好。实现一个分布式、低延迟、高可用的日志存储（append-only）比起实现一个完整的存储引擎简单太多了。所以日志的复制仍然是需要单独处理的，可以选择 Raft 或者 Multi-Paxos 之类的 RSM 算法，偷懒一点也可以直接依赖 EBS。</p><p></p><p>对于读请求来说，极低的延迟（&lt;10ms） 基本上只有依靠内存缓存，所以优化的方向也只是做几级的缓存，或者是否需要用本地磁盘、是按照 page 还是按照 row 来做缓存的问题。另外在分布式环境下还有一个好处是，由于可以在逻辑上将数据分片，所以缓存也可以分散在多台机器上。</p><p></p><p>对于这个新的存储引擎，有以下的几个设计目标：</p><p></p><p>支持读写分离</p><p></p><p>对于 OLTP 业务来说，通常读是远大于写的，这里的一个隐含假设是对于强一致读（read after write）的需求可能只占全部读请求的很小部分，大多数读场景可以容忍 100ms 左右 inconsistent gap，但是写请求对于硬件资源的消耗是更大的（不考虑 cache miss 的场景）。在单机的环境下，这其实是无解的，因为就那么一亩三分地，读 / 写 /compaction 都要消耗本地资源，所以能做的只能有平衡。</p><p></p><p>但是在云的环境下，完全可以将读写的节点分开：本地通过 Raft 协议复制到多个 Peer 上，同时在后台持续异步同步日志数据到 S3（远端的 compact 节点进行 compaction）。如果用户需要强一致读，那么可以在 Raft Leader 上读，如果没有强一致的需求，那么可以在其他的 Peer 节点上读（考虑到即使异步复制日志的 gap 也不会太长，毕竟是 Raft），即使在 Non-Leader Peer 上想实现强一致读，也很简单，只需要向 Leader 请求一下最新的 Log Index，然后在本地等待这个 Index 的 log 同步过来即可；新增的读节点，只需要考虑从 S3 上加载 Snapshot 然后缓存预热后即可对外提供服务。</p><p></p><p>另外，通过 S3 传输 snapshot 数据的额外好处是，在同一个 region 内部，跨 az 的流量是不计的。而且对于 HTAP 场景中的分析请求，因为数据都已经在 S3 上，且大多数分析的场景大约只需要 Read-committed 的隔离级别 + Stale Read 就能满足需求，因此只需要按照上面描述的读节点来处理即可，ETL 的反向数据回填也可以通过 S3 完成。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/89/8959dfb65c9d21a6935fe01f462f9200.png\" /></p><p></p><p>Before</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a3/a3dc7fc39d51db6506174a9933e2256b.png\" /></p><p></p><p>After</p><p></p><p>支持冷热分离</p><p></p><p>对于 OLTP 场景来说，我们观察到尽管总数据量可能很大，有时 OLTP 单个业务上百 TB 我们也经常见到，但是绝大多数场景下都有冷热之分，而且对于冷数据来说，只需要提供“可接受”的体验即可，例如读写冷数据的延迟容忍度通常会比较高。</p><p></p><p>但是就像开始提到的，我们多数时候并不能二元地划分冷热，但是我们又希望能通过冷热分离将冷数据使用更便宜的硬件资源存储，同时不牺牲热数据的访问体验。在 Serverless TiDB 中，很自然的，冷数据将只存储在 S3 上，因为分层的存储设计会很自然地将热数据保留在本地磁盘和内存中，冷数据在最下层也就是 S3 上。这个设计的坏处是牺牲了冷数据缓存预热时的延迟，因为要从 S3 上加载。但是就像上面说到的，在现实的场景中，这个延迟通常是可以被容忍的，想要提升这种情况的用户体验也很容易，再加入一级缓存即可。</p><p></p><p>支持极快的弹性伸缩（Scale-out / in)，并支持 Scale-to-Zero</p><p></p><p>在提到冷热分离的时候，有两个隐含的话题没有 cover：</p><p></p><p>&gt;写请求热点如何处理？</p><p>&gt;如何快速感知到热点？</p><p></p><p>要回答这两个问题，需要讨论：数据分片，请求路由以及数据调度，这三个话题也是支持弹性伸缩的关键。</p><p></p><p>我们先说数据分片。传统 Shared Nothing 架构的数据分片方式在逻辑上和物理上是一一对应的，例如 TiKV 的一个 region 对应的就是某台 TiKV 节点上的 RocksDB 一段物理数据。另一个更好理解的例子是 MySQL 分库分表，每个分片就是一台具体的 MySQL。</p><p></p><p>但是在云上，如果有这样一个云原生的存储引擎，那我们其实已经不太需要关心数据的物理分布，但是逻辑分片仍然是重要的，因为涉及到计算资源的分配（以及缓存）。过去 Shared-nothing 架构的分布式数据库的问题是：如果要调整分片就会涉及到数据移动和搬迁，例如添加 / 删除存储节点后的 Rebalance。这个过程是最容易出问题的，因为只要涉及到物理数据的移动，保证一致性和高可用都将是复杂的工作，TiKV 的 Multi-Raft 花了无数的精力在这块。但是对于基于 S3 的存储引擎来说，数据在分片之间的移动其实只是一个元信息修改，所谓的物理的移动也只是在新的节点上的缓存预热问题。</p><p></p><p>有数据的逻辑分片就意味着需要有对应的请求路由层，需要根据规则将请求定位到具体某台机器上。目前我仍然认为就像 TiKV 一样，KV Range 是一个很好分片方式。像字典一样，当你拿到一个单词，通过字典序就能很精准的定位。在 TiDB Serverless 中我们仍然保留了 KV 的分片和逻辑路由，但是会在原本的 TiDB 之上增加一层 Proxy 用于保持不同租户的 Session ，我们姑且叫它 &nbsp;Gateway。</p><p></p><p>Gateway 是租户隔离及流量感知的重要一环（后边会提到）， &nbsp;Gateway 感知到某个租户的连接被创建后，会在一个缓存的计算资源池中（tidb-server 的 container pool）捞出一个 idle 状态的 tidb-server pod 来接管客户端的请求，然后当连接断开或者超时一段时间后自动归还给 pool。这个设计对于计算资源的快速伸缩是非常有效的，而且 tidb-server 的无状态设计，也让我们在给 TiDB Serverless 实现这部分能力的时候简单了很多，而且在 &nbsp;Gateway 感知到热点出现后可以很快的弹性扩容。计算的扩容很好理解，存储层的扩容也很简单，只需修改一下元信息 + 在新的节点上挂载远端存储并预热缓存即可。</p><p></p><p>经济性</p><p></p><p>在云上，一切资源都是需要付费的，而且不同的服务定价差别巨大，对比一下 S3 / RDS / DynamoDB 的定价即可看到很大的区别，而且相比服务费用和存储成本，大家很容易忽略流量的费用（有时候你看账单会发现其实比起存储成本，流量会是更大的开销）。节省成本有几个关键：</p><p></p><p>&gt;利用 S3 进行跨 AZ 的数据移动和共享，节省跨 AZ 流量费用。</p><p>&gt;利用 Spot Instances ，进行离线任务。离线任务定义：无状态（持久化在 S3 上）、可重入。典型的离线任务是 LSM-Tree 的 compaction 或者备份恢复什么的。</p><p></p><p>能够重用原来 TiDB 的大部分代码</p><p></p><p>TiKV 对于存储引擎有着很好的抽象，其实主要修改的地方大概只有原来 RocksDB 的部分。关于 Raft 和分片的逻辑基本是能够复用的。至于 SQL 引擎和事务的部分，因为原本就和存储的耦合比较低，所以主要修改的部分就是添加租户相关的逻辑。这也是为什么我们能使用一个小团队，大概一年时间就能推出产品的原因。</p><p></p><h3>多租户</h3><p></p><p></p><p>想象一下，如果你需要支撑一个庞大规模的用户数据库，集群中有成千上万的用户，每个用户基本上只访问自己的数据，并且有明显的冷热数据区分。而且就像一开始提到的那样，可能有 90% 的用户是小型用户，但你无法确定这些用户何时会突然增长。你需要设计一个这样的系统，以应对这种情况。</p><p></p><p>最原始的方法很简单，就是直接将一批机器提供给一个用户，将另一批机器提供给另一个用户。这样的物理隔离方法非常简单，但缺点是资源分配不够灵活，并且有许多共享成本。例如，每个租户都有自己管控系统和日志存储等方面的成本。显然，这是最笨重的物理隔离方法。</p><p></p><p>第二种方法是在容器平台上进行部署，利用虚拟化，尽可能利用底层云平台的资源。这种方法可能比第一种方案稍好一些，至少可以更充分地利用底层硬件资源。然而，仍然存在前面提到的共享成本问题。</p><p></p><p>以上两种方案的核心思想是：隔离。其实包括所谓的在 SQL 引擎内部做虚拟机之类的方式本质上都是在强调隔离。但如果要实现用户数量越多、单位成本会越低的效果，光强调隔离是不够的，还需要共享：在共享的基础上进行调度，以实现隔离的效果。</p><p></p><p>TiDB Serverless 允许多个租户共享一个物理 Cluster 但是从不同用户的视角来看是相互隔离的。这是降低单位成本的关键所在，因为多个用户共享同一资源池。不过，这种基于共享的方案也存在一些问题，例如资源共享不足以满足大租户的需要、租户之间的数据可能会混淆、无法对每个租户的需求进行个性化的定制等。此外，如果一个租户需要定制化的功能，整个系统需要被更改以适应这个租户的需要，这会导致系统的可维护性下降。因此，需要一种更灵活且可定制化的多租户实现方式，以满足不同租户的不同需求。</p><p></p><p>我们看看在 TiDB Serverless 中是如何解决这些问题的。在介绍设计方案前，我们先看看一些重要的设计目标：</p><p></p><p>不同租户之间可以不会相互影响 SLA，不同用户的数据互相不可见。不同租户之间可以灵活的共享 / 隔离硬件资源。系统故障的时候尽可能小的爆炸半径。</p><p></p><p>对于第一点，不同租户的数据如何隔离而且互相不可见，要回答这个问题需要从两个方面考虑：物理存储和元信息。</p><p></p><p>物理存储的隔离反而是容易的。在上面提到了 TiKV 内部是会对数据进行分片的，即使数据存储在 S3 上，我们也可以利用不同的 Key 的编码很好地区分不同租户的数据。TiDB 5.0 中也引入了一套名为 Placement Rules 的机制在语意层提供用户控制数据物理分布的操作介面（目前还没有在 TiDB 的云产品产品线中直接暴露给用户）（<a href=\"https://docs.pingcap.com/tidb/stable/placement-rules-in-sql%EF%BC%89%E3%80%82TiDB\">https://docs.pingcap.com/tidb/stable/placement-rules-in-sql）。TiDB</a>\" 在设计之初为了性能考虑尽可能精简存储层对 key 的编码，并没有引入 namespace 的概念也没有对用户的数据进行额外的前缀编码，例如：不同用户的数据加上租户 id，为了实现租户的区分，这些工作现在都需要做，在存储层这部分并不算困难，更多要考虑的是兼容性和迁移方案。</p><p></p><p>传统的分布式数据库中，元信息存储是系统的一部分，例如在传统的 TiDB 中，PD 组件存储的元信息的主要部分是 TiKV 的 Key 和 Value 与具体的某个存储节点的对应关系。但是在一个 DBaaS 中，元信息远不止如此，更好的设计是将源信息存储单独抽离出来作为一个公共服务为多个集群服务，理由如下：</p><p></p><p>元信息应该是多级的。就像上面提到除了最底层 Key-Value 和存储节点的对应关系外，还有 DB/Table Meta 与 Key-Value 的关系，租户信息和 DB/Table 的关系，租户和 Cluster Deployment 的关系等，这些信息对于调度是很有价值的。现在回头反思早期设计 的 TiDB，其中一个重要的 lesson learned 是元信息应该设计多一些逻辑分层，而不只是简单的 KV Range 的映射（这个在 Spanner 的设计中做的很好）。元信息服务应该是可扩展的。当元信息服务化后，意味着它可能需要支撑成千上万个集群的信息，这意味着元信息的数据量可能会很大，如果去看 Google Colossus 的元信息事实上是存储在一个 Big Table 上（<a href=\"https://cloud.google.com/blog/products/storage-data-transfer/a-peek-behind-colossus-googles-file-system%EF%BC%89%E7%9A%84%E3%80%82\">https://cloud.google.com/blog/products/storage-data-transfer/a-peek-behind-colossus-googles-file-system）的。</a>\"元信息会被数据库内核之外的其他各种服务依赖。最典型的例子是计费和联邦查询服务或者数据共享等场景。</p><p></p><p>关于实现租户之间的不可见性，还有另一个重要的模块，就是上面提到的 Gateway。如果没有这个模块，要共享一个底层的 TiDB Cluster 是不现实的。这很好理解，就像你不能拥有多个 root 账号一样。因为 TiDB 使用的是 MySQL 协议，为了实现多租户，总是要在一个地方识别租户的名字，但是 MySQL 的网络协议并没有为多租户系统设计。</p><p></p><p>为此，我们选择了一个“取巧”的方案：既然要识别租户信息，那就应该在 Session 建立之初识别，只需要在鉴权的时候将租户 id 传进来就好，之后 session 建立起来，我们自然知道这个链接属于哪个租户，至于如何兼容标准的 MySQL 协议？session variable？No，直接在用户名前加个前缀就行了，这就是为什么在 TiDB Serverless 的用户名前面有一些奇怪前缀的原因：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/46/469a40896d674e1762a8c1b16c155318.png\" /></p><p></p><p>在连接建立之初就知道了租户 id 后，所有的逻辑隔离都可以通过这个 id 实现。</p><p></p><p>Gateway 会干比起普通 Proxy 更多的事情，事实上在 TiDB Serverless 中，我们直接将原本 TiDB 代码中的 Session 管理模块的代码单独抽出来，用于实现 Gateway。这个设计带来的好处很多：</p><p></p><p>区分租户，感知连接的来源（地理 region），这个很明显就不用说了。流量感知 / 控制。Flow control 这类事情做在越上层越好，存储层都已经感受到压力山大的时候通常留给流控的空间就不大了。由于 Gateway 是一切流量的出入口，而且 TiDB Serverless 和 AWS Dynamo 在论文中提到的一样，引入了 RU (Request Unit，<a href=\"https://www.pingcap.com/tidb-cloud-serverless-pricing-details/\">https://www.pingcap.com/tidb-cloud-serverless-pricing-details/</a>\") 的概念，在这里进行 RU 的控制是最精确的。无感升级 / 扩缩容。和第二点类似，当 Gateway 感知到突发流量或者长时间没有流量的时候，可以很方便告诉底层的 tidb-server（SQL processing） 资源池增减计算节点，或者对于不同类型的请求申请不同规格的计算节点。这点也是支持 Scale-to-Zero 的关键。计费。结合第二、第三点以及前面提到的存储层的自动冷热分离设计，Gateway 上针对具体租户的流量信息是：准确 + 底层可以根据实际流量动态调整底层的计算资源 + 通常成本很低的（S3）冷存储，这几点让我们都能够实现 Pay-as-you-go 的付费模式。即使 Gateway 本身是常驻的，但这部分成本均摊到海量的用户上是可以接受的。用户无感的升级。传统方案中如果底层数据库需要更新，必然会中断用户的连接，这对于有些保持数据库长链接的应用是不友好的（很多开发者基本上都不太会考虑断开重连的情况🤷）。而 Gateway 模块是比较轻量的也很少升级，于是我们可以在这层保持用户的连接，底层就可以做到无缝地更新进程。在用户侧观察到的显现无非就是某几个请求的延迟稍稍升高，之后就恢复正常了。极快的新集群启动时间。新集群的创建只是添加一些元信息 + 从 tidb-server 的资源池里捞一个 pod 出来的代价 ：）</p><p></p><p>Gateway 作为常驻模块，本身也是无状态的。增加的延迟和与带来的好处相比，我们认为是可以接受的。</p><p></p><p>我们通过 Gateway 和元信息的修改实现了多租户在一个物理集群上的逻辑层的隔离，但是如何避免 Noisy Neiberhood 的问题？在上面提到我们引入了 RU 的概念，这里就不得不提一下我们在 TiDB 7.0 中引入的名为 Resource Control 的新框架（<a href=\"https://docs.pingcap.com/tidb/dev/tidb-resource-control%EF%BC%89%E3%80%82%E5%92%8C\">https://docs.pingcap.com/tidb/dev/tidb-resource-control）。和</a>\" Dynamo 类似，TiDB 的 Resource Control 也是使用了 Token bucket 的算法（<a href=\"https://en.wikipedia.org/wiki/Token_bucket%EF%BC%89%E3%80%82%E5%B0%86%E4%B8%8D%E5%90%8C%E7%B1%BB%E5%9E%8B%E7%9A%84%E7%89%A9%E7%90%86%E8%B5%84%E6%BA%90%E5%92%8C\">https://en.wikipedia.org/wiki/Token_bucket）。将不同类型的物理资源和</a>\" RU 对应起来，然后通过 Token bucket 进行全局的资源控制：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/34/34dbf4db4083f3196b8ff2352f51f806.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/1d/1dae35ba5857eb46d8eecab993cbc063.png\" /></p><p></p><p>比起硬性的物理隔离，这样实现资源隔离方式的好处是很明显的：</p><p></p><p>灵活。因为这套机制对用户的访问层是没有侵入的，也就是和 TiDB 原本的 Data Placement 机制是正交的：如果一个大客户需要完全隔离的环境，可以配合 Placement Rule 将用户的数据移动到一批额外的硬件资源上，就完成了硬隔离；反向的话，也很容易实现。支持 Burst 和抢占式的资源共享方式。在总资源有限的情况下，应对重要业务突发流量的很重要的应对方式是 Burst 和抢占，也就是将低优先级的资源（或者预留的资源）临时借给高优先级的应用，这点对于降低总成本的同时获得一个良好的用户体验（对于付费客户）很重要。资源预留以实现 Predictable 的性能。这点和上面类似，但是不太一样。在 Dynamo 2022 年的新论文中提到类似的 DBaaaS 更重要的是提供 Predictable 性能的概念，我非常认同，而且我认为 Predictable 的关键在于尽可能避免硬件资源过载，而避免硬件资源过载最有效的办法就是提前预留资源，因为所有资源都被这套 Resource Control 框架精确控制，所以预留资源也是很容易实现的。</p><p></p><p>其实还有更多好处也在 Dynamo 那篇论文里提到，这和我们实际的感受是一致的。</p><p></p><p>但是，基于共享大集群的多租户服务实现，会带来一个挑战：爆炸半径的控制。例如当某一个服务出现故障或者发现严重的 Bug，可能影响的范不是一个租户，而是一片。目前我们的解法是简单的 sharding，至少一个 region 故障不会影响到另一个 region。另外对于大租户，我们也提供传统的 dedicated cluster 服务，也算是在业务层对这个问题提供了解决方案。当然，这方面我们也仍然在持续的探索中，有些工作很快会有一些可以看到的效果，到时候再与大家分享。</p><p></p><p>还有很多很有趣的话题，例如上面提到整个系统都是通过 Kubernetes 串联在一起的，那么为这样一个复杂的 DBaaS 提供 Devops，如何池化云上资源和多 region 支持？另外设计思路的改变不仅影响了上面提到的内容，对于数据库的周边工具的设计也会有重大的影响，例如 CDC、备份恢复什么的。因为篇幅关系就不在这里写了，以后有机会再说。</p><p></p><p></p>",
    "publish_time": "2023-07-07 17:21:04",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "201天！太平洋保险核心系统迁至国产数据库OceanBase稳定运行",
    "url": "https://www.infoq.cn/article/XqtmPkq5RguulkSRrLYc",
    "summary": "<p>7 月 7 日，2023 全球数字经济大会上，国内首个全险种核心迁移至国产数据库的系统正式亮相。</p><p></p><p>因支撑未来海量并发、海量数据业务发展需求，太平洋保险（集团）股份有限公司（以下称“太平洋保险”）与 OceanBase 联合对 P17 核心系统进行适配迁移攻坚。2022 年 12 月 18 日凌晨，第一个子系统正式上线，截至今年 7 月 7 日，这个基于 OceanBase 的核心系统，已经安全稳定运行 201 天。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/05/05aaf765ae43e196c675df2a274ecac7.png\" /></p><p>太平洋保险林春在会上分享实践经验</p><p></p><p>当天举行的数据库专题论坛上，太平洋保险数智研究院首席数据库专家林春分享了实践经验。双方首先攻坚的 P17，是关联最复杂、商业数据库绑定程度最深、业务影响最多的海量数据核心系统，涵盖了几乎太保所有子公司全业务的服务入口功能，对接周边系统几百个。</p><p></p><p>林春说：“升级过程中，业务平稳过渡，OceanBase 产品压缩特性价值明显，在保持高性能的同时，最终实现存储成本节约 80% 以上，经济效益显著。OceanBase 完全自研的根基表现出厂商很强的技术兜底能力”。</p><p></p><p>OceanBase 是<a href=\"https://www.infoq.cn/article/g2dxkXzWCtLEpuizIxqR\">蚂蚁集团</a>\"旗下科技产品，开始于 2010 年，是完全自主研发的原生<a href=\"https://www.infoq.cn/article/1oB9cOsUtxZS2jq9SwBk\">分布式数据库</a>\"。通过原生分布式技术，在普通的 PC 服务器上实现了金融级的高可用，解决了数据库的可扩展性和硬件高成本的问题。</p><p></p><p>2022 年，OceanBase 发布 4.0 单机分布式一体化数据库，解决了数据库通用易用的难题，新版本支持私有云、公有云和混合云，可部署在国内外各种云基础设施上，既适用于<a href=\"https://xie.infoq.cn/article/5cc54e10e2a09850dfee8cf0e\">大规模</a>\"的海量数据存储，也可实现单机部署，满足中小企业的需求。</p><p></p><p>经过 13 年的发展，OceanBase 从金融走向通用，已助力多个行业的 400 多家客户实现关键业务系统的升级。</p><p></p><p>在金融领域，OceanBase 已成为全国 1/4 头部金融机构核心系统升级首选；在政企领域，已在人社、运营商、能源电力、交通等领域广泛应用；在服务中小企业方面，OceanBase 通过“云+开源”，不断降低使用数据库的门槛。</p><p></p><p>本次数字经济大会，OceanBase 展出了金融核心系统升级解决方案及“三地五中心”解决方案架构模型。</p><p></p><p>OceanBase CEO 杨冰表示：“中国基础软件行业已经有能力‘根创新’，坚持长期投入，中国数据库必将迎来大爆发。作为一款完全自研的企业级原生分布式数据库，我们希望通过不断地技术创新，为不同类型客户降低企业数据库的使用门槛，助力产业数字化。”</p>",
    "publish_time": "2023-07-07 17:50:07",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "用计算机视觉识别模型种生菜？“科技+农业”还能这么玩！",
    "url": "https://www.infoq.cn/article/S5BgtwyKpWD3uqeWVhVk",
    "summary": "<p>“计算机视觉识别模型”和“生菜”是怎么关联在一起的？</p><p></p><p>第三届多多农研科技大赛参赛队伍 LettUs Grow 队给出了一个方案：运用计算机视觉识别模型识别并计算生菜投影面积，根据叶片遮挡判断作物状态及密度变更时间、数值；再根据植物模型，预测植物生长，指导上市时间及产量，指导茬口安排和种植计划，根据市场需求，灵活调节生产速率……</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/79/79de5c05db8586bff4f2b503474299b0.png\" /></p><p></p><p>民以食为天。在数字化转型趋势下，工业产业飞速发展，现代农业也不再仅仅是农业这一个领域的工作。如今，现代农业的发展建设牵涉计算机、软件工程、工学、材料学、机械制造与自动化等多个学科的专业知识。党的二十大报告指出，要树立大食物观，发展设施农业，构建多元化食物供给体系。所以，如何通过跨学科的技术应用，促进农业科技成果的转化和应用，推动农村经济的高质量可持续发展，成为当下农业产业重点关注的发展方向之一。</p><p></p><p>在这样的背景下，拼多多已连续三届举办“多多农研科技大赛”。拼多多高级副总裁王坚表示：“我们希望通过赛事的举办促进农业领域的技术交流、创新和发展，吸引更多的青年农业创新人才和优秀的现代农业企业参与到农业领域的科技创新中来，推动农业技术的升级和转型，推动我国农业技术的高质量发展。”</p><p></p><p>那么，科技能否为传统种植注入新活力？</p><p></p><p></p><h2>“接地气”的 AI 和大数据</h2><p></p><p></p><p>“翠恬”，是一种因嚼起来声音清脆而得名的水果生菜品种。第三届多多农研科技大赛要求参赛队伍使用技术手段在全封闭的集装箱内，以更低能耗种植更优品质、更高产量的全新生菜品种“翠恬”。参赛队伍在比赛期间总共种植三茬，其中，最终茬的种植结果计入决赛成绩。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b4/b4ecb03a2387d92d3b042ea876f55869.png\" /></p><p></p><p>据悉，本届比赛以集装箱式植物工厂为种植场景，能够最大程度阻隔外界环境的影响。经过激烈比拼，上海农科院队、CyberFamer 队、“生生不息”队和 LettUs Grow 队从全球 15 支初赛队伍中脱颖而出，入围决赛。</p><p></p><p>文章开篇提到的“生菜重量预测模型”就是 LettUs Grow 队提出的参赛方案。据悉，他们的团队成员包括生菜栽培专家、生菜生长模型专家、数据科学家、植物生理学专家、农业商业模式专家以及 AI 算法工程师，分别来自荷兰瓦赫宁根大学及研究中心、北京极星农业有限公司、拜耳作物科学等机构。他们在比赛中研发了硬件设备报警系统、生菜重量预测模型等，能够帮助提升植物工厂生菜产量和品质。</p><p></p><p>上海农科院队给出了更加系统的解题思路。他们构建了一套相对成熟的智慧种植决策管理系统，基于大数据云平台的数据库构建，融合了植株的生长模型、光截获模型、蒸腾模型等算法，实时收集各类传感器回传的数据用于种植策略分析和决策。</p><p></p><p>“我们遇到的困难包括品种特性不了解，集装箱设备不熟悉、LED 光照不均匀，灌溉控制系统不够精确等。”上海农科院队队长何立中表示，“我们将凭经验总结的一些种植技术，通过跨学科的团队协作，交叉融合，通过这次比赛开发了一个决策管理系统。”基于数据平台精准地数据获取和分析能力，上海农科院队最早采收了生菜，也获得了这次大赛的冠军，并夺得“最高产量奖”。</p><p></p><p>其实从参赛选手背景上看，CyberFamer 队和上海农科院队是四支决赛队伍中的农业团队。他们习惯从作物栽培的需求与规律入手，将传统种植经验与人工智能结合，获取更佳的种植结果。CyberFamer 队和“生生不息”队是工学团队，他们将生菜种植作为应用场景，以前沿技术解决农业生产的现实难题。</p><p></p><p>据 CyberFamer 队队长郑建锋介绍，他们将生菜生长速率作为集装箱内环境参数调整的重要依据之一，所以生菜生长速率的监测方法至关重要。为了找到一种简单、易行、可靠的监测方法，他们通过固定在生菜正上方的摄像头获取生菜的冠层图像，设计群落状态下的单株生菜冠层面积识别算法，建立冠层面积与鲜重之间的关系模型，最终实现基于机器视觉识别的生菜生物量监测。</p><p></p><p>CyberFamer 队在比赛中沉淀的基于作物生理反馈的植物工厂智能环控方法、基于CO2&nbsp; 质量平衡的生菜净同化量动态监测技术以及生菜冠层面积识别模型，让他们在维持生菜较高的生长速率的同时，保证了生菜的质量。可以看到，用机器视觉识别技术种生菜，并持续进行模型调优，可以节省人工、提高了监测数据的精准度。</p><p></p><p>两支农学团队和两支工学团队的较量，被大赛评委、中国农业大学贺冬仙教授视为决赛的最大看点。</p><p></p><p></p><h2>农学团队 VS 工学团队，谁更胜一筹？</h2><p></p><p></p><p>由于比赛仅以最终茬的种植结果记入决赛成绩，所以最终茬的种植数据是关键。农学团队之一上海农科院队的队长何立中表示：“通过前两茬（生菜种植）设置不同密度试验、不同光质配比试验、不同光周期试验、生长检测、能耗记录模拟、营养液配方控制、环境温湿度调控，团队人员熟悉了比赛品种特性，掌握并适应了集装箱使用，完善了我队比赛策略，控制了烧心、绿藻等问题，优化了植株生长和能耗之间的平衡关系。”</p><p></p><p>据悉，上海农科院队最后一茬生菜的生产效率达到 0.18kg/m2&nbsp;/&nbsp;天。“此次使用集装箱式植物工厂并非生产型，仅安装了三层层架，如果增加种植架层数，提高空间利用效率，以我们的种植方案推算，生产效率完全可能达到 0.4 kg/m2&nbsp;&nbsp;/ 天的国际先进水平。”何立中表示。品质方面，该队送检生菜的可溶性糖含量达到 0.43%，为四支团队之最。</p><p></p><p>工学团队的上海交大“生生不息”队从技术视角大幅提升了生菜的产量。他们构建了“生生不息”信息化平台，通过远程采集并可视化超过 13 万组数据，构建智慧栽培提供“基础设施”，解决因对新品种了解有限、数据有限及专家经验有限的情况下实现产量提升。据悉，经过三轮的迭代与优化，“生生不息”队第三茬的生物量较第二茬增长 86%，较第一茬增长 135%。这也让不少评审专家感慨，“如果多种几茬，冠军可能就是工学家了。”</p><p></p><p>“生生不息”队队长鲍华谈道：“我们前期花费较多精力在硬件适应上，团队成员多次前往现场亲自调试，并积极与中科三安工程师线上探讨如何解决问题，我们自己开发了‘生生不息数据平台’，实现数据自动导入和后续模型分析，最终我们想要的功能基本实现。”</p><p></p><p>他们以节能为导向，综合环控算法，调控室内种植的温湿度和CO2&nbsp;&nbsp;浓度；通过数据平台的环境参数监控植物生长变化，初步证明以节能为导向的环控算法在室内种植场景的可行性和有效性。</p><p></p><p>冠军只有一个，但农学团队和工学团队的表现都可圈可点。“四支团队都将数字科技与农业紧密结合起来了”，大赛评审组代表、中国工程院赵春江院士表示，“数字技术手段始终是一种工具和方法，要解决农业问题，必须将农业理解透彻，如此，工学与农学的结合才会有更好的效果。”</p><p></p><p></p><h2>AI 时代需要“新农具”</h2><p></p><p></p><p>从刀耕火种、石器锄耕到无人机播种，机械化收割，现代农业是在现代工业和现代科学技术基础上发展起来的农业。农具的进化是推动现代农业发展的重要发展动力。从“多多农研科技大赛”中，我们可以看到，AI 时代，云、大数据等技术已经成为推动农业产业发展的新动能。</p><p></p><p>首届“多多农研科技大赛”获奖团队“智多莓”在比赛过程中看到技术产品化的市场前景，成立了“智多莓”公司，帮助中小种植者提升效益。据悉，在乡村振兴重点帮扶地云南省怒江州老窝村，“智多莓”为当地搭建数字化草莓生产体系，使得老窝村草莓产业用工成本下降 30% 以上，包括肥料支出减少 2500 元 / 亩、植保支出减少 1000 元 / 亩，草莓产量增加 30%。目前，“智多莓”已形成智能灌溉、智能温室环控等硬件、软件、算法产品，截至今年一季度已在辽宁、云南、安徽、内蒙古、上海、北京等地输出 40 套系统，用于辅助草莓、蓝莓生产。</p><p></p><p>CyberFamer 队长郑建锋认为，如果将他们的种植方案运用到大型植物工厂，每千克生菜的耗电量可以降低到 9.5 度，“优于 1 千克生菜 10 度电的行业较高水平”。目前，CyberFamer 队在比赛中积累的营养液配方动态调整技术，已被写成科普论文，所有数据也已嵌入模型，形成了标准算法，正在北京小汤山基地应用。</p><p></p><p>拼多多党委书记、高级副总裁王坚表示表示：“决赛队伍让我们看到汗水农业向智慧农业转型的方向与路径。拼多多将持续举办创新赛事，鼓励大家把论文写在大地上，把成果留在农民家。”</p><p></p><p>用好 AI 时代的“新农具”，第三届多多农研科技大赛只是开始。</p>",
    "publish_time": "2023-07-07 19:11:37",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]