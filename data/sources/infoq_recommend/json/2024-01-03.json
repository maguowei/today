[
  {
    "title": "谷歌发布新的AI SDK，简化Gemini模型与Android应用程序的集成",
    "url": "https://www.infoq.cn/article/uwpJ3k2KsBcetJUEdAzA",
    "summary": "<p><a href=\"https://android-developers.googleblog.com/2023/12/leverage-generative-ai-in-your-android-apps.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDQxNjExODAsImZpbGVHVUlEIjoiOE5rNmU3WHY2ZVVFMkRxTCIsImlhdCI6MTcwNDE2MDg4MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IKc_xtWvDmYJAEenQfh_8xNeyXzvKKun9wwJN9Ix3PI\">谷歌推出全新的Google AI SDK</a>\"，旨在简化将其至今表现最好的Gemini Pro模型集成到Android应用程序中。使用最新的SDK，开发者无需构建和管理自己的后端基础设施。</p><p></p><p>据谷歌表示，Gemini Pro是他们最好的模型，具备广泛的文本和图像推理能力。Gemini Pro运行在谷歌的数据中心，可通过Gemini API访问。谷歌称，使用Gemini最简单的方法是使用<a href=\"https://ai.google.dev/tutorials/ai-studio_quickstart?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDQxNjExODAsImZpbGVHVUlEIjoiOE5rNmU3WHY2ZVVFMkRxTCIsImlhdCI6MTcwNDE2MDg4MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IKc_xtWvDmYJAEenQfh_8xNeyXzvKKun9wwJN9Ix3PI\">Google AI Studio</a>\"，这是一个基于Web的工具，可用于在浏览器中进行原型设计和输入提示词。等你获得满意的结果，可以将模型导出并在你首选的语言（例如Python）中使用，在后端运行。</p><p></p><p>对于Android应用程序，Google提供了<a href=\"https://ai.google.dev/tutorials/android_quickstart?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDQxNjExODAsImZpbGVHVUlEIjoiOE5rNmU3WHY2ZVVFMkRxTCIsImlhdCI6MTcwNDE2MDg4MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IKc_xtWvDmYJAEenQfh_8xNeyXzvKKun9wwJN9Ix3PI\">Google AI Client SDK for Android</a>\"，它将Gemini REST API封装为惯用的Kotlin API。开发者无需直接使用REST API，也无需为在Android应用程序中访问Gemini模型实现服务器端服务。</p><p></p><p>下面的代码片段演示了如何使用Google AI SDK基于文本提示词生成文本。</p><p></p><p><code lang=\"java\">val generativeModel = GenerativeModel(\n    modelName = \"gemini-pro\",\n    apiKey = BuildConfig.apiKey\n)\n\nval prompt = \"Write a story about a magic backpack.\"\nval response = generativeModel.generateContent(prompt)\nprint(response.text)</code></p><p></p><p>除了纯文本模型，Gemini还提供了一个多模态模型，能够基于文本和图像输入生成文本（gemini-pro-vision），并支持<a href=\"https://ai.google.dev/tutorials/android_quickstart#streaming?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDQxNjExODAsImZpbGVHVUlEIjoiOE5rNmU3WHY2ZVVFMkRxTCIsImlhdCI6MTcwNDE2MDg4MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IKc_xtWvDmYJAEenQfh_8xNeyXzvKKun9wwJN9Ix3PI\">流式传输</a>\"，实现更快速的交互。在这种情况下，你应该使用generateContentStream而不是generateContent，如下所示：</p><p></p><p><code lang=\"java\">var fullResponse = \"\"\ngenerativeModel.generateContentStream(inputContent).collect { chunk -&gt;\n    print(chunk.text)\n    fullResponse += chunk.text\n}</code></p><p></p><p>为了进一步简化开发者的工作流程，<a href=\"https://developer.android.com/studio/preview?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDQxNjExODAsImZpbGVHVUlEIjoiOE5rNmU3WHY2ZVVFMkRxTCIsImlhdCI6MTcwNDE2MDg4MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IKc_xtWvDmYJAEenQfh_8xNeyXzvKKun9wwJN9Ix3PI\">最新版本的Android Studio预览版引入了一个新的项目模板</a>\"，该模板将引导开发人员完成使用Gemini Pro所需的步骤，从在Google AI Studio生成API密钥开始。</p><p></p><p>除了Gemini Pro，谷歌还提供了一个更小的模型，<a href=\"https://android-developers.googleblog.com/2023/12/a-new-foundation-for-ai-on-android.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDQxNjExODAsImZpbGVHVUlEIjoiOE5rNmU3WHY2ZVVFMkRxTCIsImlhdCI6MTcwNDE2MDg4MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IKc_xtWvDmYJAEenQfh_8xNeyXzvKKun9wwJN9Ix3PI\">Gemini Nano</a>\"，可以在设备上运行。这使得应用程序可以确保数据永远不离开设备，并确保可预测的延迟，即使在网络不可用的情况下。Gemini Nano可通过<a href=\"https://developer.android.com/ml/aicore?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDQxNjExODAsImZpbGVHVUlEIjoiOE5rNmU3WHY2ZVVFMkRxTCIsImlhdCI6MTcwNDE2MDg4MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IKc_xtWvDmYJAEenQfh_8xNeyXzvKKun9wwJN9Ix3PI\">AICore</a>\"在特定的设备上提供，AICore是一项针对Android 14的新系统服务，旨在通过处理模型管理、运行时、安全性等来简化AI与Android应用程序的集成。</p><p></p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/12/gemini-pro-android-sdk/\">https://www.infoq.com/news/2023/12/gemini-pro-android-sdk/</a>\"</p>",
    "publish_time": "2024-01-03 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "金融业采用大模型，是“用大炮轰蚊子”吗 | 年度技术盘点与展望",
    "url": "https://www.infoq.cn/article/VrUUu7ClZjWqhCud3wOg",
    "summary": "<p></p><p><img src=\"https://static001.geekbang.org/infoq/cb/cb999af17df70cd30d1724d9b1ea4107.jpeg\" /></p><p></p><p></p><blockquote>本文是“2023 InfoQ 年度技术盘点与展望”系列文章之一，由 InfoQ 编辑部制作呈现。&nbsp;&nbsp;</blockquote><p></p><p></p><p>今天，无人不谈大模型。</p><p></p><p>根据麦肯锡《2023 年 AI 现状：生成式 AI 的爆发之年》报告显示，60% 的组织机构正在使用生成式 AI 工具。而 IDC 日前发布的《2023-2024 年中国人工智能计算力发展评估报告》中也有相似数据，67% 的中国企业已经开始探索生成式 AI 在企业内的应用机会或进行相关资金投入。</p><p></p><p>金融行业是受影响最大的行业之一。知识密集、场景丰富、数据和技术基础好、资源相对充足...... 这些得天独厚的条件为大模型在金融行业的落地应用培育了温热土壤。</p><p></p><p>那么经过过去一年的探索与实践，金融行业是否找到了大模型落地应用的最佳路径？取得了哪些具体应用成果? 又存在哪些难以逾越的挑战与桎梏？本文是 “<a href=\"https://www.infoq.cn/theme/229\">2023 InfoQ 年度盘点与展望</a>\"” 系列文章之一，通过与金融领域各行业专家的交流，希望进一步明晰金融机构在大模型这一趋势下的实践思路和路径。</p><p></p><h2>金融大模型“抢滩”之战</h2><p></p><p></p><p>放眼全球，摩根士丹利作为首家正式接入 GPT-4 的金融机构，已经把相关技术应用到了投资策略分析领域；高盛更进一步，已经使用大语言模型辅助风险管理分析。聚焦国内，当前我国金融领域发布的大模型已经超过 20 个，并且数量还在不断增加；在 42 家上市银行中，也有 9 家银行在2023年的半年报中明确提及正在探索大模型应用。</p><p></p><p>比如<a href=\"https://www.infoq.cn/article/OXrxX4NmLQS2ggjsfvN6?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">工商银行</a>\"在年中财报中提及，已经完成人工智能 AI 大模型能力建设应用规划，实现百亿级基础大模型在知识运营助手、金融市场投研助手等场景的应用。</p><p></p><p>举例来说，工商银行将大模型应用到了客服全流程：在事前智能客服知识运营阶段，利用大模型自动完成数据标注与知识维护，帮助提升传统智能客服分流质效；在事中服务客户阶段，利用大模型打造前情摘要功能、知识随行功能、工单智能填写功能，从而提升坐席运营效率，压降通话时间；在事后质量检查阶段，生成传统质检 AI 模型数据，即模拟坐席及客户问答，提升传统质检模型准确率。</p><p></p><p>建设银行旗下金融科技公司建信金科，实行的是更为全局化和体系化的大模型布局。具体而言，从通用能力、安全合规、金融需求三方面为出发点，设计了金融行业的大模型能力体系。该能力体系设定了 7 大一级能力和 23 项二级能力，用于帮助建信金科实现模型能力评估与生成式 AI 场景应用。</p><p></p><p>此外，基于大模型的能力矩阵，建信金科还将金融大模型的表现评估细分为通用能力和金融领域能力。其中，通用能力主要考评金融大模型在信息总结、信息推断、文本转换、信息扩展、安全与价值观、复杂推理六个维度的能力；金融领域能力评估主要考评金融大模型在金融领域的任务处理能力，即银行业务基础、保险业务基础、证券业务基础、信托业务基础、基金业务基础。</p><p></p><p>从业务特性来看，保险能从大模型上借的力甚至可能比银行更大，且速度更快。因为保险产品和理赔流程的复杂度相当高，涉及大量的人与人沟通，并且整个过程非常依赖个人的沟通技巧。通过大模型的引入，对人效的提升和成本的节约效果更为明显。</p><p></p><p><a href=\"https://www.infoq.cn/article/jT23W6bD7qmk5OpZRf8P?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">平安人寿</a>\"科技总监魏政刚告诉 InfoQ，其内部在探讨技术与业务应用结合点时主要聚焦行业价值链，关注从营销、销售、新业务、核保到理赔的五大环节。比如，平安人寿推出了基于大模型的数字人产品，主要用于协助代理人与客户沟通。这对初入行业的代理人提供了极大帮助，可以指导他们与客户交流、更好地理解客户的需求、痛点及潜在风险，并设计有针对性的解决方案。</p><p></p><p>“当然，我们对大模型的探讨会以应用为主，不会从纵向上扎到算法层面。”有消息称，平安集团层面正在研发上千亿参数的模型。看起来集团旗下类似平安人寿等机构将会基于集团的统一部署，直接采用其底层的模型能力。</p><p></p><p>除了实力雄厚的传统金融机构之外，新兴金融科技公司同样不会错过这场金融大模型“抢滩”之战。</p><p></p><p>2023年 5 月，<a href=\"https://www.infoq.cn/article/Kmuok7Y278ktUSZox2PS?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">度小满</a>\"率先推出国内首个开源的千亿级中文金融大模型“轩辕”；8 月，马上消费发布首个零售金融大模型“天镜”；9 月，蚂蚁集团 AntFinGLM 亮相。</p><p></p><p>“蚂蚁集团的大模型策略分为三层：第一，训练自己的金融大模型，配套推出评估集；第二，推出金融智能体框架；第三，基于大模型和框架搭建产业应用（如面向 C 端的支小宝和面向 B 端的支小助），实现服务增强。”蚂蚁集团资深技术专家徐万青表示。</p><p></p><p>总结下来，金融机构布局大模型主要是以下三种方式：AI 技术基础好的企业投入自研行业大模型；资源、数据、场景基础较好的企业引入通用大模型上，在此基础上做微调，然后输出给内部或同行；而更多中小企业最终会选择直接调用大模型接口，落地一些相对成熟的大模型技术和应用。</p><p></p><h2>机器学习时代的故事重演？大模型落地应用面临 4 大挑战</h2><p></p><p></p><p>“金融大模型要往纵向‘卷’，不要再向水平‘卷’，我们不需要那么多大模型，而要真正深入核心，解决金融业务的问题。”魏政刚这样强调。</p><p></p><p>然而，值得关注的是，现在的很多“智能化故事”，在机器学习时代已经讲了一遍。</p><p></p><p>从应用角度看大模型，目前仍然主要集中在办公、开发、营销、客服等非核心业务场景，对于投研、交易、风控等核心业务，多数金融机构的相关动作仍然相对保守。例如，即便是对大模型全局化投入的建信金科，目前在场景落地应用方面也是以对内为主、对外为辅。</p><p></p><p>这与金融行业强监管的特殊属性不无关系，而这种行业特性也在一定程度上制约了大模型在金融业的规模化应用进程。从 IDC 中国人工智能行业渗透度排名来看，过去 5 年一直位列前三的金融行业，2023年已经被电信和政府反超，仅排名第四。这与最初业界的预判似乎有一定出入。</p><p></p><p>太平金科保险科技实验室副总经理叶俊锋表示：在机器学习和深度学习的人工智能时代，太平实际上做了大量的实践并产生了成效，OCR、RPA、NLP 等技术都得到了广泛的应用，在 NLP 领域的场景包括客联场景下的外呼机器人，面向内部的知识库问答系统太平百科等等。面对大模型时代，我们在思想上积极拥抱，在场景上业不断探索，但是<a href=\"https://www.infoq.cn/article/e2I9pGCU2A633B1sJGxZ\">投入时还是要考虑产出</a>\"。太平针对大模型制定了一份内部研究报告，对于大模型应用场景和存在的风险进行了详细的分析，并提出了分步推进的规划的建议，目前开展了一些面向内部探索和试用，但在推动应用，尤其是面向客户应用时还是很谨慎的。”</p><p></p><p>可见，那些在传统 AI 应用方面已经有不错基础的企业和行业，对大模型的接纳度和响应度也不一定要更好。令金融机构既充满期待又望而生畏的因素有很多，总结下来主要包括几点：第一，大模型的可解释性和稳定性不足；第二，数据的质量、规模和安全问题；第三，算力焦虑；第四，人才缺失。</p><p></p><h4>可解释性这道题如何解？</h4><p></p><p></p><p>金融是经济的“压舱石”，其稳定性关乎民生，所以行业监管高要求是一道底线。这也是大模型的“黑盒”特性注定在其核心业务场景走不通的重要原因。</p><p></p><p>以银行最关键的<a href=\"https://www.infoq.cn/article/2J7bFWYuhBcJ01K04tLd?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">风控场景</a>\"为例，当某笔申请贷款审批通过或被拒绝，确定了某个贷款额度，背后的原因要能够解释，比如申请人的收入状况、违约记录等等，这些都是依据。但是，大模型在面对千亿级的参数或特征时，背后是没有对这些风险特征进行定义的，其中间恰恰缺少了一层可解释性。</p><p></p><p>“在大模型兴起之前，我们说服银行内部使用 AI 模型进行审批贷款，就花了足足三年时间。大模型来了之后，一切又要从头开始。”某银行机构技术负责人向 InfoQ 感叹道。</p><p></p><p>有业内人士举了另一个例子：过去某国有银行使用基于小模型的金融交易对话机器人进行银行间的债务订单意向确定，内部采纳率已经高达 99% 以上。但是，在尝试采用大模型做替代的过程中，他们发现机器人的回答变得特别发散，无法聚焦到具体的交易意向，最终导致效果极差无法替换。</p><p></p><p>不过话说回来，在 InfoQ 与多位业内从业人员交流的过程中发现，大家绝大多数都相信，大模型进入金融核心场景，也只是时间问题。</p><p></p><p><a href=\"https://www.infoq.cn/video/x0q9GJJQAMIWyI3juNGo?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">光大信托</a>\"信息技术部副总经理、数据中心总经理祝世虎博士针对可解释性问题，提出了一种目前可行的解决思路：把大模型放在中央，小模型放在外围，大模型驱动具有可解释性的小模型去处理问题，进而解决可解释性的难题。</p><p></p><h4>数据是“背锅侠”？</h4><p></p><p></p><p>大模型本身只是一张“白纸”，上面会长出什么样的一幅“画”，由数据决定。</p><p></p><p>对企业来说，首先是要“有数据”，其次要“有足够的数据”，再者“数据质量要足够高”。</p><p></p><p>魏政刚指出，语料是制约金融业落地大模型的关键桎梏。“一方面，金融业务复杂性特别高，很多业务知识和经验实际上是在人脑里而不是在系统里，如何把这些信息从业务人员大脑里剥离出来是个非常大的挑战；另一方面，监管制度不断调整，这会频繁对金融机构业务经营活动产生影响，数据会实时变化，这就对 AI 落地的工程性能力提出了非常高的要求。”</p><p></p><p><a href=\"https://www.infoq.cn/article/VyXbmPO3scWlqDhJq0z8\">中关村科金</a>\"技术副总裁 &amp; TGO 鲲鹏会学员张杰博士向 InfoQ 进一步介绍，数据问题中容易解决的是预训练数据部分，但指令数据部分是比较难的，对数据质量要求更高。因为大模型时代仍然面临一个法则——好用的不通用，通用的不好用。</p><p></p><p>“在具体场景下，如果想要把准确度调整到 95％，难度还是非常大的，可能需要专门的指令对数据进行微调。对此，一方面企业需要有自己的场景来逐渐积累；另一方面，可能需要考虑通过行业联盟，共享数据。”</p><p></p><p>以风控场景为例，<a href=\"https://www.infoq.cn/video/pg5aKfMKTtUKabm0xJzd?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">上海华瑞银行</a>\"风控数据团队负责人丁清华表示，目前某个金融机构自身说掌握的数据是特别有限的，可能是某一部分人群的数据特征，或者某个地域人群的数据特征。行业里还没有任何一家机构可以掌握能够达到如此庞大规模和覆盖面的风险特征数据（比如全国所有个人的基本信息、违约记录、消费习惯、交易流水等等），绝大部分全国性数据主要还是在政府机构、监管机构（人行、银保监会等）部门。</p><p></p><p>“所以，如果要实现风控领域的大模型落地，我认为还是需要自上而下去推进。基于某个领域大模型，各个金融机构再按照自身的客群定位进行参数的微调。”丁清华指出。</p><p></p><p>然而，在祝世虎博士看来，“数据质量”问题可能只是一个“背锅侠”。“事实上，一是不存在没有质量问题的完美数据；二是数据质量的提升，数据治理只是一方面；三是顶层的数据应用决定底层的数据质量。数据只有用起来，质量才会越来越高，只有形成闭环，数据才能治理好”。祝世虎博士表示，“大模型一方面需要高质量的数据，另一方面也从应用的角度推进了数据质量，并且在机器学习的样本标注中大模型已经有了很好的落地实践。”</p><p></p><h4>消除算力焦虑必须从信创上下功夫</h4><p></p><p></p><p>算力是一个基础设施问题，更是一个成本问题。</p><p></p><p>大模型意味着大算力，但“骨感”的现实是，我国市场面临着严重的算力供给短缺。虽然有机构赶在限购之前囤了不少卡，但根本的自研能力一天不能补齐，“卡脖子”问题就会一直出现。</p><p></p><p>因此，要从根本上消解算力焦虑，必须从信创上下功夫。可以看到，在国家层面，近期工业和信息化部联合发布了关于算力技术的设置和高质量发展的指导意见，推进中国算力发展一个新时期；在市场层面，我国 AI 芯片行业近年来也在持续发展。</p><p></p><p>比如，以海光信息为代表的开放路线，此前的深算一号已经具备大模型运行能力。但是，它的算力只相当于英伟达 P100 的水平。虽然海光在第三季度很快推出了深算二号，据介绍已经具有全精度浮点数据和各种常见整型数据计算能力，性能在深算一号基础上翻了一番。不过，如果和<a href=\"https://www.infoq.cn/article/3QgC2C2JQghLz4RZBNgi?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">英伟达</a>\"产品相比，也仍然有很大差距。</p><p></p><p>再比如，华为昇腾，被视为业界算力最强的 AI 处理器。但其走的是自生态路线，也就是说，它只适用于自身生态中的大模型业务。</p><p></p><p>与此同时，算力部署不是一个单一问题，对于金融机构而言，还要考虑异构算力的融合、机房和网络等其它基础设施的统一建设等等。用建信金科基础技术中心人工智能工程部总经理刘东东的话说——这是一个短板效应比较明显的系统工程。“也就是说，如果算力要好，那么网络、存储、机架密度所有的相关配置都要与之匹配，这样才能把算力价值发挥出来，但这背后不但涉及的成本巨大，并且在落地中也非常复杂且具有挑战。</p><p></p><p>所以，算力问题可以一分为二来考虑。对于实力雄厚或者希望自建大模型的大型金融机构来说，有钱可以“任性”；但是，如果资源有限，那不妨考虑“借力”。每个金融机构自己去建算力中心、自研大模型显然并不明智，因此越来越多的企业开始采用混合部署方式。也就是说，从公有云调用大模型接口，然后采用私有化部署方式处理本地数据服务。一方面确保隐私敏感数据留在安全域，另一方面也可以节约大量的算力成本。</p><p></p><h4>供需失衡，人才短缺问题不断叠加</h4><p></p><p></p><p>无一例外，所有的技术革新都会带来社会人才结构的改变。</p><p></p><p>比如前不久大数据分析师还是企业的“香饽饽”，眼下却成了一个“危机职业”。技术更迭之快“渐欲迷人眼”，行业的人才缺口却越来越凸显。那么，大模型时代下，企业究竟需要什么人才？</p><p></p><p>张杰博士认为，大模型于金融机构而言关键在于场景落地，而具体场景对模型调校的经验要求较高，不仅需要算法能力，还需要考虑如何实现算法工程化，结合具体业务进行落地。因此，需要既懂算法、又懂工程、产品和业务等知识的六边形人才。</p><p></p><p>由此来看，<a href=\"https://www.infoq.cn/article/PQFkc7K5Dxdf3hbiWSgs?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">人才</a>\"短缺问题是不断在叠加的。企业在数字化转型过程中所需的业务和技术复合型人才还未能补齐，企业对人才能力需求的边界却还在不断延展。</p><p></p><p>“我国传统 IT 人员做的多是交付式开发，这导致大家的产品设计能力和深度建模能力天然缺失。而反观业务人员，同样在逻辑思维、技术思维方面有所欠缺。”魏政刚表示，为了弥合二者之间的鸿沟，平安人寿采取了一系列手段。比如，把 IT 前置到业务部门，让技术更深入地参与到业务中去；再比如，通过轮岗制度，让业务和技术交叉学习。</p><p></p><p>当然，在有限资源的前提下，人才培养也要有优先级。</p><p></p><p><a href=\"https://www.infoq.cn/article/eLIiWldQ2SVEUQFuYp2j?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">太保寿险</a>\"首席架构师周建华表示，虽然算法人才必不可少，但在大模型的基建方面，由于门槛高、成本大、问题复杂，金融行业自己可能并不需要过多涉足，更重要的是考虑大模型应用。在这方面，两类人才至关重要：一类是智能化战略规划人才，他们能够通过对其他领域的成功案例中的借鉴，对企业自身的战略规划做出部署；另一类是智能化应用人才，他们不需要成为顶尖的算法专家，需要的是智能化应用实战能力。</p><p></p><h4>金融 + 大模型，可以但没必要？</h4><p></p><p></p><p>面对这一系列严峻的挑战，技术本身反倒成了最简单的问题。“用或者不用”、“如何用”才是现阶段企业最关心的。</p><p></p><p>有人发出这样的“灵魂拷问”——模型是不是越大越好？如果小模型就能解决的问题，是否还有必要使用大模型？</p><p></p><p>“这本质上是一个经济性问题。”叶俊锋举例，在大模型应用的成本中，有一项特别容易被忽视但占比并不小的投入——电费。“所以，当我们站在经济性角度去考虑这个问题的时候，就不难得出这样的结论，如果原有技术已经能够符合业务预期，投产比更优，那就不要急着用大模型去替代。大模型能够切实发挥作用，一定是因为基于大模型产生了新的业务模式，带来新的业务收益，而非仅仅用大模型替代现有小模型。”</p><p></p><p>祝世虎博士进一步介绍，企业“用或者不用”大模型可以从以下两个方面做考虑：</p><p></p><p>第一，投入产出比。</p><p></p><p>虽然如今的大模型被标榜能够降本增效，但效益的产生是依托于一定程度的规模化应用的。有业内人士向 InfoQ 透露，他们内部曾经做过一个实验，让人和 GPT4 分别对一篇文章做总结，最终的结果是，GPT4 的投入成本要高得多。</p><p></p><p>对此，张杰博士强调，金融机构在立项时要“算好账”，设置好中间的业绩指标、过程指标等等。其中，过程指标的设置相对简单，以文档问答为例，主要看大模型对 PDF 文档或图片解析的准确度，以及解析完成后大模型问答的准确率，这些都可以用一些技术指标来衡量。</p><p></p><p>而衡量业绩指标最简单的方法是与人工进行比较。例如与人工坐席或与后台职能部门的人员效率进行比较，或者与软硬件成本以及人员成本比较。</p><p></p><p>“当然，不同企业对投入产出比的衡量指标不太一样。有的企业把大模型视为战略性投入，所以试错容忍度更高。有的企业则不一样，他们会非常关注周期，如短期、中期、长期等不同阶段的成果。具体来说，可以先找到一个具体场景，设定一个破冰期（通常是半年左右的时间），让公司内部人员看到大模型在降本增效方面的价值，然后再进一步推广落地。”</p><p></p><p>第二，模型的效果表现。</p><p></p><p>目前大模型的应用落脚点主要还只是辅助人，而不是完全替代人；效率提升的同时，也许还会增加人的工作量。</p><p></p><p>“对此，我们可以从几个方面来评估为什么要用大模型替代小模型：一是同行在用，企业为了保持竞争力必须采纳；二是需要解决小模型解决不了，而大模型可以解决的问题，比如效能；三是解决虽然小模型能做，但大模型表现更好的问题，比如一岗多能；四是把大模型视为新的生产力，虽然弓箭也是武器，但和现代武器相比差距巨大。”祝世虎博士指出。</p><p></p><p>在他看来，基于以上，资金实力比较雄厚的大公司会更多考虑效果问题，而中小型企业则更多考虑成本投入。在中短期内，大模型和小模型将会共存。</p><p></p><p>那么，在具体落地过程中，大小模型如何有机搭配？</p><p></p><p>徐万青这样比喻：大模型更像是一个文科生，小模型更像是一个理科生，在协同的过程中，可以把大模型作为认知与语言交互的中枢，把各类小模型当作各个领域和场景的专家，然后进行协调调用。</p><p></p><p>当然，这个问题没有标准答案。找到可结合的业务场景，从中进行突破，这可能比搞大模型本身更重要。</p><p>“在过去的智能化应用中，很多公司都因为未能找到业务流程上的痛点，导致创新停滞。解决这个问题并不容易，技术应用必须回到目标和业务价值，生产力的提升如何带来生产关系的改变。”周建华表示。</p><p></p><h2>热思考，冷启动</h2><p></p><p></p><p>所以，金融行业广泛采用大模型是“用大炮轰蚊子”吗？目前行业普遍共识是——并不。</p><p></p><p>“总体上，技术投入与其带来的收益是值得的。这不仅是基于我们的增长预期，也基于我们对技术，尤其是人工智能和大语言模型，能够真正为业务赋能的信心。平安人寿的改革成果也印证了这一点，从中我们可以看到生产力和收入水平的提升。”魏政刚表示。</p><p></p><p>然而，如何精确计算这种技术投入与业务收益之间的<a href=\"https://www.infoq.cn/article/eZ8J5Z7SuUSM4ql4ioVW?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">平衡点</a>\"仍然是个挑战。</p><p></p><p>“不可否认，企业必须积极拥抱大模型。但是，从投入角度来看，我认为还是应该谨慎投入，不要脑子发热，先小成本地去体验和探索。”叶俊锋认为，企业在这个过程中要做好两个平衡：第一，平衡好短期利益和长期利益；第二，平衡好降本增效和创新。</p><p></p><p>可见虽然大模型还没有从根本上改变人们的生活，颠覆式的爆款应用还没有出现。但没有人会质疑，它将成为技术发展史上不亚于蒸汽机的伟大创新。</p><p></p><p>那么，在那个“伟大时刻”到来之前，企业应该如何做好迎接它的准备？徐万青强调，除了技术能力、数据基础、人才储备之外，思维的转变也必不可少。</p><p></p><p>“就像我们在移动时代来临时，如果只是想着把电脑上的功能和软件照搬到手机上，那必定不会成功。在大模型时代，更要以智能原生的视角重新审视金融业务的运转，所有金融场景都值得被大模型重塑一遍。”</p><p></p><p></p><blockquote>InfoQ 2023 年度技术盘点与展望专题重磅上线！与 50+ 头部专家深度对话，探明 AIGC 创新浪潮下，重点领域技术演进脉络和行业落地思路，点击<a href=\"https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MjM5MDE0Mjc4MA==&amp;action=getalbum&amp;album_id=2717978015128879106&amp;scene=173&amp;subscene=227&amp;sessionid=1704178990&amp;enterid=1704178995&amp;from_msgid=2651192070&amp;from_itemidx=2&amp;count=3&amp;nolastread=1#wechat_redirect\">订阅</a>\"/<a href=\"https://www.infoq.cn/theme/229\">收藏</a>\"内容专题，更多精彩文章持续更新 ing~另，InfoQ 年度展望系列直播将于 2024 年 1 月 2 日首场开播，持续输出精彩内容，关注 InfoQ 视频号，与行业技术大牛连麦~</blockquote><p></p>",
    "publish_time": "2024-01-03 15:05:26",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AIGC 将如何落地？IDC、钉钉联合发布 2024 AIGC 应用层十大趋势",
    "url": "https://www.infoq.cn/article/9ypzmJoecvGUlOgRW8VX",
    "summary": "<p>1 月 3 日，钉钉联合国际知名咨询机构 IDC 发布首份《2024 AIGC 应用层十大趋势白皮书》（下称《白皮书》）。随着 AIGC 技术的发展，智能化应用将呈现爆发式增长，IDC 预测，到 2024 年全球将涌现出超过 5 亿个新应用，这相当于过去 40 年间出现的应用数总和。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/5c/5cc4fc5633fe860aa3f13564da7c008b.png\" /></p><p></p><p>大模型价值实现路线图</p><p>&nbsp;</p><p>根据《白皮书》，2024 年 AIGC 应用的十大趋势关键词涵盖应用层创新、AI Agent、专属模型、超级入口、多模态、AI 原生应用、AI 工具化、AI 普惠化。</p><p></p><h4>趋势一：应用层创新成为 2024 AIGC 产业发展确定方向</h4><p></p><p>&nbsp;</p><p>《白皮书》认为，应用创新是AIGC技术落地、链接用户价值的关键路径。AIGC 应用将率先在 B 端办公和生产力场景中落地，其中知识管理是现在最受企业青睐的应用场景，这将为 B 端企业客户提供更多的生产优化路径选择，实现直观的降本增效成果。</p><p>&nbsp;</p><p>IDC预测，到2024年，数字经济的发展将在全球范围内孕育出超过5亿个新应用，相当于过去40年间出现的应用数量的总和。</p><p>&nbsp;</p><p></p><h4>趋势二：大模型从“赶时髦”到“真有用”，成为提效手段</h4><p></p><p>&nbsp;</p><p>IDC的调研显示，企业当前最希望通过AIGC来实现的商业利益包括：改善客户体验/服务、提高开发人员生产力、实现差异化竞争优势以及创新商业模式等。IDC预测，到 2026 年，GenAI将承担 42%的传统营销琐事，如搜索引擎优化、内容和网站优化、客户数据分析与细分、潜在客户评分和超个性化。</p><p>&nbsp;</p><p>而想要达成行业AI应用的准确性、安全性目标，一方面要确保基础大模型的成熟稳定，另一方面也可以通过PaaS层对大模型的应用过程进行约束与管控。</p><p>&nbsp;</p><p></p><h4>趋势三：专属、自建模型将在中大型企业涌现</h4><p></p><p>&nbsp;</p><p>大模型的未来发展将趋向于通用化与专用化并行。通用预训练大模型在面对很多领域长期存在的痛点问题时，难以承担起更多专业化任务。企业对于大模型的要求不仅仅是实现“通识”，更需要其成为特定领域的“最强大脑”。因此，企业客户会产生越来越多的专属、自建模型需求，特别是一些中大型企业，通过对大模型的领域化适配，有望获得更加理想的综合收益。</p><p>&nbsp;</p><p>IDC的调研显示：目前有60%的企业使用大模型的公开版本，但这一比例在两年后会迅速降至 17%，更多企业会将AI应用建立在私有、专属模型基础上；同时，高达88%的企业选择通过内部团队开发相关应用。由此可见，行业专属大模型已经成为企业未来的热点目标，企业也要持续建设自己的人才队伍，修炼AIGC应用的“内功”。</p><p>&nbsp;</p><p></p><h4>趋势四：多模态大模型塑造“多边形战士”应用</h4><p></p><p>&nbsp;</p><p>多模态大模型与语言大模型、视觉大模型均为当前大模型训练和开发的重要方向。从赋能应用的视角出发，多模态大模型能更充分地利用海量、异构的数据资源，提升应用的效率和能力上限。</p><p>&nbsp;</p><p>多模态大模型可以帮助用户构建出一个更加丰富、友好的界面，使应用与人的交互过程 无限趋近于人类自身的习惯。此外，多模态大模型如果与VR/AR、元宇宙等技术体系进一步融合， 还可以打造更深层、更多维、更丰满的全新体验。</p><p>&nbsp;</p><p>目前，多模态信息识别与理解技术、 群体智能技术等，已经成为研究开发的关键领域，有望加速人工智能从感知到认知的转化。</p><p>&nbsp;</p><p></p><h4>趋势五：AI Agent 是大模型落地业务场景的主流形式</h4><p></p><p>&nbsp;</p><p>IDC的调研表明：所有企业都认为AI Agent是AIGC发展的确定性方向；同时，50%的企业已经在某项 工作中进行了AI Agent的试点，另有34%的企业正在制定AI Agent的应用计划。</p><p>&nbsp;</p><p>AI Agent 让 AIGC 技术拥有感知、记忆、规划和行动能力，可以跨应用程序做复杂任务的执行，使得“人机协同”成为新常态。未来，AI Agent 将变革生产力的组织形式，越来越多的创新将会源自于超级个体和小型组织。一个人加上 AI 工具，就可以成为一家公司，个人与企业正在步入 AI 助理时代。</p><p>&nbsp;</p><p>未来，企业工作任务将在AIGC的助推作用下变得日益原子化和碎片化，复杂的流程将被无限拆解， 再进行灵活的编排和组合，每个环节的效能和潜力都将被AI持续挖掘。而从供给端看，“人+AI数字 员工”的高效协同模式将为大型企业对抗组织熵增提供理想的解法。</p><p>&nbsp;</p><p></p><h4>趋势六：AIGC 将加速超级入口的形成</h4><p></p><p>&nbsp;</p><p>新一代应用将会被对话式交互模式（LUI）重新塑造。所有的SaaS公司都将全面拥抱AI，软件公司最终会变成智能系统运行商，软件操作方式被大幅简化，应用之间的集成度更高，多应用之间也更加融合。</p><p>&nbsp;</p><p>AIGC重塑应用形态的过程将重点体现在两个方面：一是对既有软件进行智能化改造与升级，以API 的形式增加重要环节的可交互性和认知能力；二是对软件的应用架构和模式进行全新重构。 “No APP”理念将重塑移动互联网时代形成的入口和用户格局。应用功能会被碎片化地融入到一些超级应用中，用户通过对话就能在一个应用里直接调取、使用各种工具。</p><p>&nbsp;</p><p>IDC 的调研显示，97% 的企业认可超级入口将成为未来的主流应用形态（调研对象：100家制造、医疗、互联网、金融、零售行业年收入超过5亿的大型企业）。未来，软件公司将变成智能系统运行商，应用之间广泛的调动与协同，将塑造全新的生态格局，钉钉这类软件有望成为智能时代的超级APP。</p><p>&nbsp;</p><p></p><h4>趋势七：业务流程迈向“无感智能”</h4><p></p><p>&nbsp;</p><p>AI与业务的融合进程在未来几年将达到前所未有的高度。AIGC给业务流程带来的智能革新，一方面打开了新的需求空间，产生了规模化的流程重组效应；另一方面，也可能让传统行业多年来一成不 变的业务规则转变为持续迭代的态势。</p><p>&nbsp;</p><p>AIGC持续提升自动化执行、优化协作以及智能决策等能力，以更原子化的方式深入到碎片化的设计、开发、制造、营销、财务等环节中，帮助企业实现AI与业务流程的无缝融合。在AIGC最擅长的内容生成、数据处理、实时分析、客户服务等领域，支持客户快速完成重复性和时间密集型的任务。</p><p>&nbsp;</p><p></p><h4>趋势八：应用从云原生走向 AI 原生</h4><p></p><p>&nbsp;</p><p>如今，大模型和AIGC驱动正在重新定义基础设施，AI原生设计思想也正在渗入各行业的应用开发过程中，形成软件开发新范式。</p><p>&nbsp;</p><p>随着 AI 向行业纵深的不断挺进，AI应用不应仅被视为模型能力的搬运工，而是从产品和方案的设计之初就开始思考 AI 的融入，突破更多企业的深层需求。应用将从“+AI”向“AI+”转变，“+AI”是一种技术路线的进步，而“AI+”则意味着整体发展思想的转变，意味着所有的应用都将以AI能力为核心驱动力，由AI定义场景将成为一种新范式。</p><p>&nbsp;</p><p>IDC的调研表明：企业认为AI原生将带来一系列变革，包括技术栈的变化、工具链的变化、基 础设施的变化、开发流程的变化、安全策略的变化、设计理念的变化以及组织层面的变化等。在迈向AI原生的过程中，企业应积极做好准备。</p><p>&nbsp;</p><p></p><h4>趋势九：AIGC逐步普惠化</h4><p></p><p>&nbsp;</p><p>AIGC的收费模式仅仅是AIGC货币化趋势的初始体现。随着AIGC向各行各业的渗透，更多的企业希 望从AIGC所创造的潜在增量收益中进行利益分成。因此，在巨大的潜在商业前景下，AIGC将驱动全 社会产生新商业模式的涌现。IDC预测，到 2024 年，33% 的 G2000 企业将利用创新商业模式，使 GenAI 的货币化潜力翻番。</p><p>&nbsp;</p><p>从未来的发展趋势看，全栈式AI PaaS、SaaS化服务会进一步成为主流，AI产业链将持续发展成熟， 包括数据采集、数据标注、定制化模型开发、场景共创等在内的AI产业链将产生很多新的岗位需求。</p><p>&nbsp;</p><p>对于未来 AI 人才缺口的问题，IDC预测，到 2026 年，2/3 云应用将使用AI，致使高达八成的企业难以找到熟练的 AI 专业人员。</p><p></p><h4>趋势十：智能涌现是把双刃剑，需要与之匹配的安全措施</h4><p></p><p>&nbsp;</p><p>AIGC作为一种新兴的技术，仍带有较强的双面性，其在推动AI新浪潮发展的同时，也存在许多可预料和不可预料的风险，诸如隐私保护、结果失控、数据泄露等，都是当前企业决策者最为担忧的问题。各参与方有必要采取有效的措施来确保AI应用的安全和可靠性，保证其更安全地服务于人类。</p><p>&nbsp;</p><p>对于智能涌现与安全管控的平衡问题，IDC 调研发现，73% 的企业表示会制定全公司 AIGC 范围适用的标准规范。</p><p>&nbsp;</p><p>此外，IDC 对终端用户提出了应用场景导向、合理选择介入的深度和关注商业模式的变化三个建议；对生态开发企业提出了加入有竞争力的生态和转变产品设计思路的建议。</p><p></p><p>相关链接：</p><p>https://files.alicdn.com/tpsservice/1d3f483aa9792524f9b5647def429211.pdf?spm=a1zmmc.index.0.0.f1b7719deobDIN&amp;file=1d3f483aa9792524f9b5647def429211.pdf</p>",
    "publish_time": "2024-01-03 15:35:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "《云上新视界》特别筹划：使用 BMF 加速 GPU 视频处理流水线",
    "url": "https://www.infoq.cn/article/s855NRuXWtxHkzK6EeBq",
    "summary": "<p>本期课程，NVIDIA 加速计算专家方杰将介绍如何使用 BMF 加速 GPU 视频处理流水线。课程围绕视频处理流水线的组成部分来介绍，具体包括如何做GPU的视频编解码、利用 CV-CUDA 加速图片处理、如何利用 TensorRT 加速模型以及使用 Maxine 获得开箱即用的视频特效。</p>",
    "publish_time": "2024-01-03 15:53:12",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "2023 英特尔 On 技术创新大会：让 AI 无处不在！",
    "url": "https://www.infoq.cn/article/hdMmtWZtSkHkWG7addtg",
    "summary": "<p>2023 英特尔 On 技术创新大会中国站已于 12 月 19 日正式上线官网！点击下方视频，速览这场面向智算时代开发者的技术盛宴。</p><p></p><p></p><p></p><p>英特尔中国专家深度解读最新一代加速 AI 能力的计算平台，支持开放、多架构的软件方案和工具，塑造未来的技术和应用创新。查看下方海报，看看英特尔如何助力开发者，让 AI 无处不在。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/04/0488af789f54f0f8e6fb7a4adc2039fa.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7a/7af4e0661d1bc3691a398ac93c84b176.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/27/2776895b4f988f5a259643baa756f8ff.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7d/7ddb4ca9d4c1186d4effb06c6d3eecc9.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1e/1e567d9f7ae8f2b6431e862aa30b4bdb.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3a/3abe28793e2685f55c18416e9885b689.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/99/993f217340fbd3f9321357b87d9cf7fc.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/54/54adfdbb8d5700d3885618ce9d29f45b.png\" /></p><p></p><p></p><h3>芯生无限，赋能 AI 创新</h3><p></p><p></p><h4>助力开发者，让 AI 无处不在</h4><p></p><p>帕特·基辛格 (Pat Gelsinger) 英特尔公司首席执行官</p><p><img src=\"https://static001.geekbang.org/infoq/49/4997d45fb0cce83a4899527b277a43a8.jpeg\" /></p><p>AI 时代，“芯经济”蓬勃发展，开发者成为驱动者</p><p>“芯经济”指的是“在芯片和软件的推动下，正在不断增长的经济形态”，如今，芯片形成了规模达 5740 亿美元的产业，以满足 AI 时代对算力提升的不断追求。帕特·基辛格表示：对开发者而言，这将带来巨大的社会和商业机遇，以创造更多可能，为世界上的重大挑战打造解决方案，并造福地球上每一个人。</p><p></p><h4>芯生无限，赋能 AI 创新</h4><p></p><p>王锐博士 英特尔公司高级副总裁、英特尔中国区董事长</p><p><img src=\"https://static001.geekbang.org/infoq/de/de7b00ec8456b605b514f87c23a112fb.png\" /></p><p>英特尔提供从云到端的算力底座，加速开发者创新</p><p>在云端，基于英特尔® 至强® 可扩展处理器内设的 AI 加速功能，能大幅缩短模型响应时间；在客户端，基于英特尔® 酷睿™ Ultra 处理器的笔记本电脑，能快速地推动生成式 AI 场景在 PC 的落地。开发者可以在英特尔的硬件平台上，使用各种加速器与特性来优化工作负载，让 AI 开发更高效、优化、节约成本。</p><p></p><h4>芯生无限，赋能 AI 创新</h4><p></p><p>李映博士 英特尔公司副总裁、英特尔中国软件生态事业部总经理</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d1/d182a3c1d9b46995efe399504a9923d0.png\" /></p><p></p><p>英特尔提供端到端的 AI 软件组合，并深度融合中国生态，帮助开发者提升效率</p><p>英特尔正在通过一系列的开源软件架构的支持，使得大语言的应用模型可以拓展到边缘侧以及终端，让每个人都可以成为 AI 开发者。同时，英特尔与中国的开发者社区紧密配合，将最新的平台加速技术，贡献到各个开放社区，让 AI 开发者可以充分利用本土的技术软件生态。</p><p></p><p></p><h3>助力开发者，让 AI 无处不在</h3><p></p><p></p><h4>智能生产力和性能的新范式</h4><p></p><p>戴金权 英特尔院士</p><p><img src=\"https://static001.geekbang.org/infoq/9b/9b66f8583d16d0e2f079086e54b37989.png\" /></p><p>英特尔为各行各业全面解锁 AI 应用，释放创新潜力基于开放的软件生态，软硬协同，简化 AI 工作流程优化从数据中心到终端的基础设施，提升 AI 的性能对 AI 软件、模型进行优化，加速开发者工作负载</p><p></p><h4>新一代 AI PC 计算平台，全面重塑 PC 应用体验</h4><p></p><p>刘骏 英特尔客户端计算事业部高级首席工程师</p><p><img src=\"https://static001.geekbang.org/infoq/e6/e6623a346978c315bd8e61530badb98f.png\" /></p><p>基于 Intel 4 制程工艺的英特尔® 酷睿™ Ultra 处理器平台（代号 Meteor Lake），在 CPU、GPU 和神经网络处理单元（NPU）的架构中集成了专属 AI 加速功能，从而成为英特尔历史上 AI 性能最强、能效最佳的客户端处理器英特尔系统及技术解决方案，确保软件与硬件无缝的协作，让开发平台更高效、灵活安全性是所有英特尔硬件和平台解决方案的基础，帮助开发者节省时间用于开发</p><p></p><p>新一代至强为云与人工智能构筑安全高效、广泛可用的算力基石</p><p>李志明 英特尔数据中心与 AI 事业部中国区 CTO 首席工程师</p><p><img src=\"https://static001.geekbang.org/infoq/88/88a43f94e74858f83c1f8b432f1255af.png\" /></p><p>新一代至强为云与人工智能构筑安全高效、广泛可用的算力基石李志明 英特尔数据中心与 AI 事业部中国区 CTO 首席工程师未来的英特尔®至强®处理器将兼顾性能核和能效核，满足多样化性能和效率要求的最佳处理器第五代英特尔®至强®可扩展处理器，为 AI 加速，筑智算基石基于英特尔®至强® 的机密计算，实现数据全流程保护</p><p></p><p></p><h4>混合 AI：边云协同加速 AI 解决方案商业化落地</h4><p></p><p>张宇博士 英特尔高级首席 AI 工程师，英特尔网络与边缘事业部中国区首席技术官</p><p><img src=\"https://static001.geekbang.org/infoq/06/064eab15c5dcbc4561ddc930e5450e8e.png\" /></p><p>计算模式正在边缘与云间建立新的平衡，基于边云协同的混合人工智能是实现应用快速部署的有效途径英特尔软硬协同，硬件上同步发展通用的 CPU、GPU、IPU, 持续助力边缘人工智能的发展在软件上，OpenVINO™最新版本助力 LLM 性能提升，提供多平台的支持，加速生成式 AI 应用开发以及在行业落地</p><p></p><p></p><h4>计算创新演进，探索智能未来</h4><p></p><p>宋继强 英特尔研究院副总裁，英特尔中国研究院院长</p><p><img src=\"https://static001.geekbang.org/infoq/7c/7c0902818828ced910b4f2157e08c352.png\" /></p><p>摩尔定律通过对芯片的尺寸缩小、创新材料和设计结构、设计技术和系统技术的联合优化不断演进，稳步推进“四年五节点”英特尔积极投入神经拟态计算和量子计算，探索未来计算领域英特尔研究院从稳定性、可信任性、可编程性、计算效率、可扩展性和可持续性几个维度持续探索人工智能及其应用</p><p></p><p>大会设立了主题演讲、技术洞察、专题论坛和课程、DEMO 演示，目前均已上线官网，为参会者呈现包括人工智能、新一代 AI PC 计算平台、新一代至强平台、边云协同以及先进技术的全面分享。从前沿趋势到应用方案，从云到端，赋能开发者 AI 创新。</p><p></p><p>强大技术阵容，尽在 2023 英特尔 On 技术创新大会中国站！On-demand 内容持续在线，助力开发者，让 AI 无处不在。欢迎大家点击<a href=\"https://marketing.intel.cn/innovation?tc=dt8d1z0hkv&amp;cid=23prcinnovation#/?block=26\">链接</a>\"，浏览活动官网。</p>",
    "publish_time": "2024-01-03 16:03:45",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "老师木新创业项目曝光：瞄准大模型成本问题，推理性能将得到数量级的提升",
    "url": "https://www.infoq.cn/article/3L4va9oqqew1EfXDOuMt",
    "summary": "<p>整理 ｜ Tina</p><p>&nbsp;</p><p>1月2日，OneFlow创始人袁进辉（老师木）有了新动向，其创立的新公司“硅基流动”正式进入公众视野，这是一家关注AI基础设施层的公司。</p><p>&nbsp;</p><p>袁进辉是AI架构界的资深人才，他于2017年创立了一流科技OneFlow。去年大模型爆火后，光年之外收购了OneFlow，此后美团又收购了光年之外。</p><p>&nbsp;</p><p>实际不久前，袁进辉就已经在朋友圈宣布了OneFlow团队近期重新创业的消息。</p><p>&nbsp;</p><p>袁进辉表示，重新创业的计划目标是瞄准大模型推理成本问题。</p><p>&nbsp;</p><p>“计划第一个推出的产品是大模型推理和部署系统，解决AIGC和LLM行业推理部署成本太高的痛点，我们判断这是大模型时代最好的商业机会之一。”</p><p>&nbsp;</p><p>提高大模型推理和部署的效率已成为大模型时代提供基础设施服务的重要课题。在依赖数据、算法和算力的支持下，大模型的能力才能得以充分展现。数据显示，在过去的4年里，大模型的参数量以年均400%的复合增长，而AI算力需求增长超过15万倍。传统以CPU为中心的计算基础设施已经无法满足大模型和生成式AI的新需求。由此引发的成本不断膨胀，成为大模型企业负担沉重的账单。因此，一些领先的厂商正寻求降低成本的方法。</p><p>&nbsp;</p><p>硅基流动提供的方案，跟云厂商之间“本质一样，取决于谁做的更好。而实际上我们的确做得也更好。现在AI算力很分散，公有云只占其中的一小部分，还有就是跨云和多云。”袁进辉回复AI前线询问时表示。</p><p>&nbsp;</p><p>“Stable Diffusion进行了公开评测，反馈很好。在大模型产品初次推出时，我们进行了内部测试，并与国内外产品进行了比较，结果显示我们的产品具有明显的优势。我们在海外获得了一批付费客户，其中包括stability.ai，也覆盖东南亚、巴基斯坦、中东等地。”</p><p>&nbsp;</p><p>“海外市场主要比拼的还是产品力，”袁进辉表示道，“目前我们正在做大模型推理方案，并且很快会推出极具竞争力的产品，性能上比市面上现有方案会有数量级的提升。”</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ab/ab327b896c59de29f4e152d785e96758.jpeg\" /></p><p></p><p>截图来源：<a href=\"https://github.com/siliconflow/onediff\">https://github.com/siliconflow/onediff</a>\"</p><p>&nbsp;</p><p>袁进辉因读书时成绩优异，保送清华大学直博生，师从人工智能领域张钹院士。期间多篇论文在国际顶级会议上发表，在竞争激烈的国际技术评测（TRECVID）中连续多年名列第一。2013 年，加入微软亚洲研究院（MSRA），在 MSRA 期间，专注于研发大规模机器学习平台，以出色的科研和工程综合能力，发明了世界上最快主题模型算法 LightLDA 及分布式训练系统：只用几十台服务器就能完成之前需要数千服务器才能完成的训练任务。之后创业并打造了分布式学习框架oneflow。</p><p>&nbsp;</p><p>对于这次创业，不少技术圈人士给予了高度评价：“从LightLDA到siliconflow，袁老师教了我们太多，这次siliconflow，我相信还能教我们不少技术，支持就对了！”“分布式系统软件研发难度大，做好技术创新和工程开发还不够，还要懂应用负载、生态系统、商业模式等等。”</p><p>&nbsp;</p><p>而且，袁进辉一直关注的领域都相当前沿和准确。用他自己的话说，在深度学习开始火爆之前几年，他就已经涉足神经网络领域（2008年开始研究计算神经科学）。在大模型成为热点之前几年，他就开始构思面向大模型的深度学习系统（2015年从MSRA开始，并于2016年创业，一直贯彻这个理念）。</p><p>&nbsp;</p><p>AI前线早于2017年就曾跟他探讨过算力对AI的重要性，如今到了生成式AI时代，算力利用问题愈加凸显。我们正好可以借此机会重温一下他的观点：</p><p>&nbsp;</p><p>InfoQ：为什么计算力会成为深度学习的一个突破方向？</p><p></p><blockquote>老师木：首先，计算力是极其关键的一项支撑技术。最近发生的人工智能革命通常被认为是三驾马车驱动，数据，算法和计算力。与上世纪九十年代相比，深度学习在算法原理上并无二致，在数据和计算力方面进步更大，各行各业积累了大量的优质数据，GPU 作为新的计算手段引爆了此次深度学习的热潮。&nbsp;其次，计算力方面还有现成的红利可吃，相同的算法，如果能用上更多的数据，或者用更大规模的模型，通常能带来效果的显著提升，能不能做的更大取决于计算力的水平。&nbsp;再次，算法和原理的研究进展依赖于计算能力，好的计算力平台可以提高算法和原理研究的迭代速度，一天能实验一个新想法就比一星期才能实验一个新想法快的多。有些理论问题本身是一个大规模计算问题，譬如神经网络结构的自动学习等价于在一个超大规模假设空间的搜索问题，没有强大计算力的支持就只能停留在玩具数据上。深度学习是受生物神经网络启发而设计出来的，现在人工神经网络的规模还远远小于人脑神经网络的规模，人脑有上千亿神经元细胞，每个神经元平均有成千上万的连接。&nbsp;最后，如何在低功耗约束下完成高通量的计算也是制约了深度学习在更多终端上应用的一大因素。</blockquote><p></p><p></p><p>InfoQ：计算力具有什么样的商业价值？</p><p></p><blockquote>老师木：一方面，计算力的商业价值体现在它是数据驱动型公司的大部头营业支出（硬件采购，人力成本等）。数据驱动型业务的完整链条包括数据收集，预处理，深度分析和在线预测，无论是私有部署还是上公有云，建设高扩展性的基础设施等支撑技术，都是一笔不可忽视的开销。另一方面，计算力也是数据驱动型公司获得竞争优势的关键，人工智能可提高公司业务效率，而计算力又可提高人工智能的效率。目前，围绕着计算力已经出现了诸多成功的商业模式，譬如公有云，面向私有部署的商业技术服务，深度学习加速器（GPU，DPU）等。</blockquote><p></p><p></p><p>InfoQ：计算力在技术上有哪些瓶颈？</p><p></p><blockquote>老师木：从硬件看，我们现在使用的都是冯诺依曼结构的计算机，它的主要特点是计算单元和存储单元分离，主要瓶颈表现在摩尔定律（Moore’s law）的失效和内存墙（Memory wall）问题上。克服摩尔定律的主要途径是增加中央处理器上集成的核心（core）数量，从单核，多核发展到现在众核架构（GPU, Intel Xeon Phi），但芯片的面积及功耗限制了人们不可能在一个处理器上集成无穷无尽个核心。内存墙的问题是指内存性能的提升速度还赶不上 CPU 性能的提升速度，访存带宽常常限制了 CPU 性能的发挥。纯从硬件角度解决这些瓶颈问题，一方面要靠硬件制造工艺本身的发展，另一方面可能要靠新型的计算机体系结构来解决，譬如计算和存储一体化的非冯诺依曼结构计算机。除了高通量的计算，在电池技术没有大的突破的前提下，终端应用场景（物联网，边缘计算）里低功耗也是计算力的一项重要指标。当前，深度学习专用硬件创业如火如荼，有可能会被忽视的一点是：对突破计算力瓶颈，软件至少和硬件一样关键。</blockquote><p></p><p></p><p>InfoQ：为什么软件会成为计算力突破的关键？</p><p></p><blockquote>老师木：计算力的基础设施要满足上层用户对易用性，高效率，扩展性的综合需求，仅有硬件是不够的。一方面，数据科学家和算法研究员不像系统研发工程师那样深刻立刻硬件的工作机理，不擅长开发释放硬件计算潜能的软件，对数据科学家最友好的界面是声明式编程，他们只需要告诉计算力平台他们想做什么，具体怎样算的快要由软件工具链来解决。另一方面，尽管单个众核架构的协处理设备（如 GPU）吞吐率已远超 CPU，但出于芯片面积 / 功耗等物理限制，任何一个单独的设备都无法足够大到处理工业级规模的数据和模型，仍需由多个高速互联的设备协同才能完成大规模任务。出于灵活性需求，设备之间的依赖必定由软件定义和管理，软件怎样协调硬件才能提高硬件利用率和释放硬件潜能极具挑战，至关重要。在相关领域，软件定义硬件已是大势所趋：上层软件决定底层硬件的发展方向，底层硬件要取得成功离不开完善的上层软件生态。</blockquote><p></p><p></p><p>InfoQ：长江后浪推前浪，这样一个先进的技术架构生命力会有多久？</p><p></p><blockquote>老师木：首先，我们可以探讨一下深度学习的范式还有多久生命力，毕竟技术架构应需求而生。可以从这几方面看：从数据流计算模型是生物体采用的信息处理机制，是人工智能的效仿对象；人工神经网络已经在多个领域取得成功，而且深度学习本质上还是统计学习理论，利用算法在数据种挖掘统计规律性，这种学习机制的本质不会变化；深度学习算法便于利用并行硬件的威力，算法和硬件的天作之合，还看不出取代它的必要。其次，从计算机体系结构及硬件演化方向上看，软硬件结合的数据流计算机代表着突破摩尔定律和内存墙限制的方向。</blockquote><p></p><p></p><p>InfoQ：是不是只有大公司才需要这样的基础设施？</p><p></p><blockquote>老师木：并不是。目力所及，这样的基础设施已经不是大公司的独享的专利，拥有数十台服务器的中小企业，大学研究院所比比皆是。数据驱动是一种先进的生产力，所有行业最终都会变成数据驱动，每个行业的每个公司的数据都在积累，每个公司对数据分析的需求都在进化，从浅层的分析到深度分析，这个大趋势呼之欲出不可逆转。十年前，会有多少公司需要 Hadoop，现今几乎所有的公司都要用到 Hadoop。历史一再证明，无论计算能力发展到多强大，应用总能把它用满。多年以前，有人还觉得 640K 内存对于任何人来说都足够了，今天 64G 的内存都开始捉襟见肘，一辆自动驾驶测试车每天收集的数据达数 TB 之多。从来不是强大的计算力有没有用的问题，而是计算力够不够用的问题。</blockquote><p></p><p>&nbsp;</p><p>更多阅读：</p><p><a href=\"https://www.infoq.cn/article/software-platform-deep-learning-compute-capability\">微博技术大 V 老师木：软件平台是深度学习计算力突破的关键</a>\"（<a href=\"https://www.infoq.cn/article/software-platform-deep-learning-compute-capability\">https://www.infoq.cn/article/software-platform-deep-learning-compute-capability</a>\"）</p><p><a href=\"https://www.infoq.cn/article/vwLNsabkqDpr*oRDdgN5\">让 AI 简单且强大：深度学习引擎 OneFlow 技术实践</a>\"（<a href=\"https://www.infoq.cn/article/vwLNsabkqDpr\">https://www.infoq.cn/article/vwLNsabkqDpr</a>\"*oRDdgN5）</p><p><a href=\"https://mp.weixin.qq.com/s/m0pV4yaZFI3bTg_-mUcaoQ\">TensorFlow和PyTorch迎来了“后浪”</a>\"</p><p>&nbsp;</p>",
    "publish_time": "2024-01-03 18:01:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]