[
  {
    "title": "一个品牌、三个提升、五维布局｜工行数字化转型的思路和实践",
    "url": "https://www.infoq.cn/article/pc7ihipY5vPdizqktlE5",
    "summary": "<p>数字化转型没有放之四海而皆准的标准定义，但确实存在一些共同点，比如都“以用户为中心，以数据为驱动，以科技创新引领变革，以构建生态连接资源”。而工商银行对于数字化转型的定义是“以服务实体经济和人民群众需要为主线，以数据和技术为关键要素，以全行各领域业务科技煲汤式融合为重要推动力，以业务模式和管理模式变革为突出特征，进一步强化以客户为中心，高质量提升用户体验、业务效率和经营价值。”</p><p></p><p>基于以上定义，工商银行制定了数字化转型的整体思路——“1、3、5”。其中，“1”是指打造“数字工行(D-ICBC)”品牌，“3”是指三个提升目标，“5”是指五维数字化转型布局。本分享将对工行围绕这一思路的具体实践和场景应用进行拆解，希望给各行业数字化带来启发。</p><p></p><p>本文整理自中国工商银行软件开发中心总经理室金融科技专家许宜在高质量数字化转型创新发展大会暨中国信通院“铸基计划”年度会议的演讲分享，主题为《工商银行高质量数字化转型实践》。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/f8/98/f86a07f828bffc3907c55df9da3ef498.jpeg\" /></p><p></p><p>以下是演讲实录（经InfoQ编辑整理）：</p><p></p><p></p><h2>为什么要做数字化转型？</h2><p></p><p></p><p>当前全球新一代的科技革命和产业革命深入发展，以数字化、智能化为主要特征的第四次工业革命，对各行各业都产生了深刻的影响，同时也带来了前所未有的机遇和挑战。可以说，数字化转型已经成为了当今时代全球每一个企业的必答题。</p><p></p><p>此外，当前数字化转型也已经纳入了我们国家的战略，国家通过政策引领和顶层设计，对我国现阶段科技创新发展和数字化转型做出了系统谋划和战略部署，明确了数字经济发展的战略地位。最近，国务院印发了《数字中国建设整体布局规划》，其中指出建设数字中国是数字时代推进中国式现代化的重要引擎，也是构建国家竞争新优势的有力支撑。</p><p></p><p>工商银行一直坚持数字化的发展，及时把握科技与产业变革的趋势。去年2月份，工商银行发布了集团的数字化品牌：数字工行(D-ICBC)，全面开启数字工行的新征程，全力融入金融数字化转型的浪潮，为数字经济的高质量发展贡献工行智慧和力量。</p><p></p><p></p><h2>工商银行的数字化转型方法论</h2><p></p><p></p><p>数字化转型没有放之四海而皆准的标准定义，但确实存在一些共同点，比如都“以用户为中心，以数据为驱动，以科技创新引领变革，以构建生态连接资源”。而工商银行对于数字化转型的定义是“以服务实体经济和人民群众需要为主线，以数据和技术为关键要素，以全行各领域业务科技煲汤式融合为重要推动力，以业务模式和管理模式变革为突出特征，进一步强化以客户为中心，高质量提升用户体验、业务效率和经营价值。”</p><p></p><p>基于以上的定义，工行制定了数字化转型的整体思路，可以用“1、3、5”进行概括。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/ec/86/ecb68228225820bf9ec87e6a43061d86.png\" /></p><p></p><p>“1”是打造数字工行（D-ICBC）品牌。</p><p></p><p>“3”是三个提升目标：第一，提升用户体验，以用户为中心，解决好服务过程中的断点、堵点、难点等体验问题；第二，提高业务效率，从业务流程的视角进行审视，进行流程的优化改进甚至再造，并且实现自动化的处理，以实现高效的决策和运营；第三，提升经营的价值，通过数字化的手段实现业务模式和管理模式的重塑与创新，强调创造性地改变原有核心业务的模式，实现业务的跨越式升级。</p><p></p><p>“5”是五维的数字化转型布局，也就是数字技术、数字资产，数字生态，数字基建和数字基因。</p><p></p><p>重点来看一看五维具体的含义。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/cb/7b/cbf81bf4f819dcfa031c2897529cd07b.png\" /></p><p></p><p>其中，数字基建是基础部分，重在高水平的科技自立自强，适度超前打造支撑未来发展的信息基础设施。数字技术和数字资产是两大关键驱动力，数字技术重在打造先进可控的硬核科技，提升数字技术创新驱动能力，掌握发展的自主权。而数字资产成为了一个新型的生产要素，重在做实做强做活数据的新要素，提升数字资产智能应用的能力。数字生态是通过API开放平台、金融云平台，构建开放的生态，打造金融与消费互联网、产业互联网、政务互联网紧密融合的数字共同体。数字基因则是贯穿以上四个方面的内在动力，重在建设敏捷协同的组织机制，培养和集聚高水平的人才，提升数字化灵活创新的能力。</p><p></p><p>在五维布局中，数字技术是数字化转型的第一动力。我们从2015年开始就通过自主研发，全面布局了云计算、分布式、&nbsp;大数据、人工智能、区块链等，加上5G的新技术，推出了自主可控的十大技术体系，形成了企业级技术能力，为数字化转型和业务创新提供技术上的支撑。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/ce/ab/ce0e728c51288a2340718eb5a79d94ab.png\" /></p><p></p><p>其中，“云+分布式”的技术体系具备了15万+的节点，34万+的容器，行内有95%的应用都采用了开放平台，日均服务调度次数超过160亿，从而提供了高性能的联机服务能力。此外，我们还有全栈信创的大数据服务云同业，具备EB级的存储，拥有5000多个节点。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/cb/7b/cbf81bf4f819dcfa031c2897529cd07b.png\" /></p><p></p><p>数据资产是加快数字化转型的新动能，工行充分发挥数据要素的作用，做实数据基础，盘活数据资产，驱动运营模式、风控模式和业务模式的创新，目前已经建立起了功能完备，算法齐全的数据中台体系，沉淀数据超过40PB，形成6万个共享指标，推出1000多个数据服务，夯实了用数赋智的基础。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/fc/e2/fc40463617e91a931466e787947387e2.png\" /></p><p></p><p>数字生态方面，工行主要依托“API体系+金融生态云”双轮驱动的开放服务生态体系，重点在数字政务、数字产业、数字乡村等领域，为政府和企业提供端到端的解决方案，更好支持生态融合共建。API平台的价值，实际就是把我们的能力输出出去，融入到企业的场景当中去提供服务，也就是开放银行的思路。目前API对外输出16大类4600余个服务，金融生态云提供了21个SAAS产品，租户已达到7.4万。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/76/75/76d78dabeaebde1b019ac108dfece375.png\" /></p><p></p><p></p><p>值得注意的是，技术也是一把双刃剑，通过大数据、人工智能等新技术提高金融服务能力的同时，同样可能派生风险。如果不加以管控，甚至滥用，就会破坏数字化转型的可持续性。工行在数字化转型的过程中，积极应对算法歧视、信息泄露、数字鸿沟等金融科技伦理的挑战，本着科技向善的理念，通过夯实安全的基础、推动金融普惠、加强共享输出等方面的实践，持续推进金融科技伦理的建设。</p><p></p><p></p><h2>工行数字化转型实际应用场景</h2><p></p><p></p><p>数字政务方面，依托数字技术基座，工商银行打造了1+N（1个政务服务平台+N个政务垂直行业）的数字政务服务体系，目前在全国落地了300多个政务合作场景，积极助力政务服务的一网通办，具体已经上线了10项全国通办的政务事项，以及400余项属地专有的政务事项。向社保、财政、政法等垂直领域输出“行业+金融”一站式服务，让“数据多走路、群众少跑腿”。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/0y/18/0yy2c5b9888889f7e9de767790c58418.png\" /></p><p></p><p></p><p>以“工银安心链”为例：面对教培行业退费难、甚至卷款跑路等监管难题，面对公益慈善捐款专款专用，农民工工资按时足额发放等资金监管领域的民生诉求，我们利用区块链数据可追溯、防篡改等特性，打造了“工银安心链”数据产品，解决各方信息不对称、资金流向不透明、资金监管难等痛点问题，实现源头可溯、过程可查和责任可追，助力国家监管政策高效落地，加强全社会的信用体系建设。目前上线的资金管理单位达到了844家，监管资金的体量达到了4184亿元。</p><p></p><p>数字产业服务方面，我们利用数字技术重构了金融服务。比如，产业链建设上通过数字供应链平台，服务20余万家上下游企业；普惠金融生态上面向小微企业搭建了金融生态圈，同时推出了一系列的普惠数据产品，更好服务于客户的融资需求；通用支撑上，通过像党建工会云，财务管理云等金融生态云，为各行业提供了垂直领域的解决方案。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/b2/7a/b2afcbed31fbf2cc6b714587e85a3e7a.png\" /></p><p></p><p></p><p>以普惠金融应用创新为例：通过切入小微企业的生产经营各类场景，充分挖掘企业结算、收单、资产等等多维度的数据价值，通过“数据+模型”驱动，打造了商户贷、e抵快贷、e企快贷等普惠的拳头产品，满足小微企业各类的融资需求。其中商户贷是最近的产品创新之一，我们和银联合作，同业首家应用了隐私计算的技术，推出了“商户贷”数字产品，保障客户数据安全的同时，实现了小微收单商户的精准授信，上线8个月，贷款的余额超过64亿，服务小微商户达到3.4万户。</p><p></p><p>数字乡村方面，为响应国家乡村振兴战略，工行一直致力于深化“业务+科技”的双向融合，期望将工行打造成金融服务乡村振兴主力银行，乡村客户满意银行。在服务渠道方面，线上打造了“兴农通”APP，用户数达到298.6万人，线下挂牌了普惠金融服务点近4千家；平台创新方面，通过数字乡村综合服务平台与一千余家的县级农业农村部门合作，通过兴农撮合平台撮合农产品的供需意向1万余项，服务的农业经营主体超过10万家；在产品创新方面，在“工银兴农贷”提供贷款达到3.4万亿的同时，种植E贷也已经实现了种植领域上涉农贷款的创新突破。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/8a/9f/8a79da1bc29e3267123ed9f638d1ce9f.png\" /></p><p></p><p>以“数字乡村”综合服务平台为例：这个平台结合了人工智能、区块链以及卫星遥感等新技术，通过“一窗受理”的方式，为农业农村的管理部门、村委会提供了涵盖“党务、政务、村务、财务、金融服务”的一站式数字化综合解决方案，协助建立集体资产的监督管理服务的体系，提高乡村数字化治理的效能。</p><p></p><p></p><h2>关于数字化转型的未来展望</h2><p></p><p></p><p>我们认为，目前工行的数字化转型与很多企业一样，仍然在路上。为了在数字化道路上能够走得更深更远，我们将着重做好三个方面的转变和两个方向的转型：</p><p></p><p>三个转变：一是转意识，我们认为需要保持开放的心态，避免固步自封，提高数字化的认知高度，把握时代发展的机遇；二是转模式，要积极探索业务模式、管理模式和运营模式的创新与重塑；三是转组织，要鼓励组织架构和体制机制的创新，加快科技创新与市场响应。</p><p></p><p>两个转型：一是推动好从局部到全链路的转型，重点关注面向客户交互的局部数字化，也就是触点的数字化，更加转向全链路的数字化转型，对银行的前、中、后台都需要重点关注；二是因地制宜推动部门级、产品级、企业级的数字化转型，以问题为导向，因地制宜选择数字化转型的路径，在部门级、产品级和企业级分别都能够做好重点的突破。</p><p></p><p>数字化转型任重而道远，但是我们相信，道虽远，行则将至，事虽难，做则必成。工行愿意与各机构和企业加大合作，共建开放共赢的“数字共同体”，为“数字中国”建设增砖添瓦，共同服务于人民对于美好生活的向往与追求。</p>",
    "publish_time": "2023-03-17 11:06:28",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "软件架构决策指北：怀疑主义的软件架构设计",
    "url": "https://www.infoq.cn/article/K7QazDeyGYFS8NWBK54V",
    "summary": "<p>人们普遍认为态度是成功的关键，这是有道理的。正如亨利·福特说的：</p><p>&nbsp;</p><p></p><blockquote>“不管你认为自己是否能够做到——你都是对的。”</blockquote><p></p><p>&nbsp;</p><p>如果你不相信自己能做好一件事，而且不去尝试，就可能永远做不好，这一点似乎是显而易见的。</p><p>&nbsp;</p><p>然而，只是相信自己能够做到也仅止步于此，准备和计划也很重要。</p><p>&nbsp;</p><p>怀疑也是如此，但这是一种特定的类型，这里我们指的是怀疑主义。更具体地说，哲学怀疑主义是这样一种信念，即在没有证据的情况下，至少在软件领域，不可能知道某事的真相。</p><p>&nbsp;</p><p>在我们的经验中，怀疑主义是一种架构超能力，可以帮助我们在错误的假设走得太远之前——在它们占用了你太多的时间并给你带来了太多的工作，以至于你永远无法完成之前——识破它们。</p><p>&nbsp;</p><p>稍后有更多详细的内容。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2a/2a98b045e9ae9e6bb5a981068b6dc898.png\" /></p><p></p><p>图1：一些话头，它们在告诉你，这些假设可能需要进行测试</p><p>&nbsp;</p><p></p><h2>“过度的实证主义（Positivism）”会导致盲目</h2><p></p><p>&nbsp;</p><p>积极思考的力量是真实存在的，然而，如果用得太过头了，可能会导致我们无法甚至不愿意看到的与乐观预期不符的结果。我们不止一次地遇到这样的经理，当他们看到数据中出现了一个重要的利益相关者喜欢但对客户来说没有价值的特征，他们会命令开发团队压制这些信息，这样利益相关者就不至于“看起来很糟糕”。</p><p>&nbsp;</p><p>即使高管没有让团队去做他们怀疑是错误的事情，展示积极结果的压力也会让他们不敢提出可能表明他们不在正确轨道上的问题。或者，团队可能会经历<a href=\"https://en.wikipedia.org/wiki/Confirmation_bias\">确认偏差</a>\"，忽略那些不会加强他们“知道”是正确的决策的数据，而将它们视为“噪音”。</p><p>&nbsp;</p><p>当一个团队试图理解为什么一个客户非常需要的功能在发布几周后还没有被客户接受，就可能会出现这种情况。团队可能认为这个功能很难被客户找到，所以需要重新设计UI。然而，真正的原因可能是新功能并没有解决用户的问题，在调查清楚之前，他们不应该忽略这个可能性。如果他们只是简单地假设功能是有价值的，可能会着手进行高成本而徒劳的UI重构，而这并不是问题所在。</p><p>&nbsp;</p><p>泰坦尼克号已经收到其他船只的警告，在她航行的区域有浮冰，但船长爱德华·史密斯决定继续全速航行，这是<a href=\"https://en.wikipedia.org/wiki/Titanic\">当时的标准做法</a>\"。如果他质疑“冰山对大型船只几乎不构成危险”和“泰坦尼克号不会沉没”的信念，那么这一起在和平时期最致命的游轮沉没事故可能就不会发生了。</p><p>&nbsp;</p><p></p><h2>怀疑主义（Skepticism）并不等同于否定主义（Negativism）</h2><p></p><p>&nbsp;</p><p>人们经常将“怀疑主义”这个词作为“否定主义”的同义词，而否定主义被<a href=\"https://www.merriam-webster.com/dictionary/negativism\">定义</a>\"为“一种以怀疑为标志的心态，尤其是对几乎所有别人肯定的事情。”怀疑的态度会变成否定主义，特别是被犬儒主义放大时。尽管如此，我们认为在应对复杂的挑战（未知的东西比已知的东西多）时，怀疑主义是有它的用处的。</p><p>&nbsp;</p><p>当我们使用怀疑主义这个词时，我们指的是之前提到的哲学怀疑主义。在应对复杂的挑战时，尤其是在早期，我们所知甚少——不仅对解决方案知之甚少，有时甚至对问题本身也知之甚少。在这种情况下，哲学怀疑主义可以帮助我们看穿错误的假设，克服我们的认知偏见，为现实问题找到更好的解决方案。这就是为什么我们认为怀疑主义是一种架构超能力：它就像X光透视，帮助我们看到世界的本来面目，而不是我们心中希望看到的样子。</p><p>&nbsp;</p><p>怀疑主义的概念与经验主义（Empiricism）有着相似的根源，后者是形成敏捷方法的基础，而怀疑主义这个词起源于希腊单词σκέψη（sképsi̱），它的意思是思考或调查，其中的调查部分对软件架构来说非常重要。</p><p>&nbsp;</p><p></p><h2>怀疑主义的软件架构是怎样的</h2><p></p><p>&nbsp;</p><p>正如前一篇<a href=\"https://www.infoq.com/articles/what-software-architecture/\">文章</a>\"所述，构建和设计现代软件应用程序基本上是探索性的。构建应用程序的团队每天都会遇到新的挑战：前所未有的技术挑战和为客户提供解决新问题的新方法。这种不断的探索意味着架构不能被预先确定。</p><p>&nbsp;</p><p>软件架构设计是由质量属性需求（QAR）驱动的，而不是由功能需求驱动的。在初始迭代中不考虑QAR通常会在软件系统部署超出初始试验阶段并拥有少量用户时出现问题。每一个需求，包括驱动架构设计的QAR，都代表了一个关于价值的假设。当我们采用怀疑主义的方法时，目标之一是让这些假设变得明确，并有意识地设计实验，专门测试需求的价值。</p><p>&nbsp;</p><p>可惜的是，QAR通常没有被明确地定义。模糊的需求，如“系统的速度必须快”或“系统必须可伸缩”，对架构设计没有多大帮助。过度膨胀的可伸缩性QAR（如“新系统能够处理的业务量必须至少是当前的10倍”）也是，因为这些需求通常是基于系统利益相关者不切实际的期望。对这些模糊的需求持怀疑态度是很重要的，因为它们可能会导致过度设计，并构建出不必要的功能。对需求的价值进行验证也很重要，研究表明，大多数需求实际上是没有用的，我们需要通过实验将它们与其他需求分开。</p><p>&nbsp;</p><p>团队不需要在完全满足整个需求的情况下才能确定其价值，他们只需要构建简单且足够的系统来执行测试，验证（或反驳）假设并证明或否定需求价值就足够了。类似地，团队也不需要构建整个解决方案来评估解决方案所依赖的关键假设。但只是识别出假设是不够的，团队还需要对假设进行测试。</p><p>&nbsp;</p><p>然而，团队在构建足够的系统来测试假设时，必须对测试系统做一些增强。最后，团队需要运行可能会失败或用于确定何时会失败的测试，这一点也很重要。</p><p>&nbsp;</p><p>更好地了解正在做出的隐性架构决策，让这些决策变得明确，这样有助于开发团队使用他们从sprint/迭代中获得的经验数据做出更好的决策。基于过去的经验，团队必须找到新的可以满足质量需求的方法。</p><p>&nbsp;</p><p></p><h2>怀疑主义有助于做出决策</h2><p></p><p>&nbsp;</p><p>团队有时会经历<a href=\"https://en.wikipedia.org/wiki/Analysis_paralysis\">分析瘫痪</a>\"，这使他们害怕做出决策。产生怀疑往往是其中的一个原因，但这也可能把他们引向解决方案。我们假设团队认为没有在没有实验的情况下就无法知道一个决策是对是错。这个时候，他们可以通过对替代方案进行实证测试来避免出现分析瘫痪。当团队试图在没有任何信息的情况下评估决策时，分析瘫痪尤其会成为问题：由于没有新的信息来指导他们，他们会不断地忽略相同的替代方案。</p><p>&nbsp;</p><p>对于与解决方案相关的决策来说，唯一有用的数据来自于执行代码，其他一切都是猜测。熟悉某项特定技术的团队成员可能会认为这项技术决策是正确的，但要确定其正确与否的唯一方法仍然是编写一些代码并测试代码背后的假设。编写代码是解决架构师之间争论的唯一方法，再多的信念也不能证实或否定一个假设。</p><p>&nbsp;</p><p></p><h2>实践中的怀疑主义</h2><p></p><p>&nbsp;</p><p>应用怀疑主义应该像确定假设和提出诸如“我们需要看到什么证据才能知道这是对的”这样的问题一样简单，然后建立度量方法对假设进行测试。但根据我们的观察，提出怀疑似乎很难。考虑下面的例子：</p><p>&nbsp;</p><p>一家保险公司的一些高级技术团队成员一直在试验规则引擎技术。他们似乎发现了这个<a href=\"https://www.martinfowler.com/bliki/RulesEngine.html\">规则引擎</a>\"的许多用途，比如可以取代应用程序中的“if-then-else”代码。他们发现，有了规则引擎，他们就可以在不修改、编译和部署代码的情况下改变应用程序的行为。可能根本不需要技术人员参与，可以直接由运营人员负责维护规则。</p><p>&nbsp;</p><p>在早期成功实现了控制保单发行和定价（主要是幕后工作）的规则之后，他们开始跌跌撞撞地进入了一个似乎更具挑战性的阶段。一些规则的变更不仅会改变程序逻辑，还会改变UI的外观和行为。经过一番考虑，团队发现UI行为是一种不一样的应用程序逻辑，他们可以开发定义UI行为的规则。</p><p>&nbsp;</p><p>于是，他们开始雄心勃勃地重新设计应用程序的UI，编写与UI观感和行为相关的规则。从技术上讲，这是可以实现的，但其影响相当大：应用程序变慢了，管理UI规则的人需要具备开发经验。这样一来，开发灵活性没有得到提升，反而产生了一个更复杂的问题：在缺乏良好开发和测试工具（规则引擎）的环境中编写UI行为。当出现问题时，系统中的行为变得不可追踪。</p><p>&nbsp;</p><p>这个例子与一句古话如出一辙：“如果你只有一把锤子，那么所有东西看起来都像钉子。”规则引擎对于问题的某些部分是有效的，但这个比喻也仅限于与之相匹配的问题。如果采用一种怀疑主义方法，确定与可维护性相关的QAR，然后基于它们测试所提出的解决方案，很快就可以看出这一点。规则引擎有它的作用，但团队在UI设计中对它的使用超出了这些工具的预期用途。</p><p>&nbsp;</p><p></p><h4>一个非决策类型的例子：可伸缩性假设</h4><p></p><p>&nbsp;</p><p>传统上，可伸缩性不被认为是软件系统的重要QAR，但这种看法在过去几年发生了变化，可能是因为大型电子商务和社交媒体公司对可伸缩性的关注。可伸缩性可以被认为是系统通过增加（或减少）系统成本来处理增长（或减少）的工作负载的属性。可伸缩系统是一种常见的简化说法。可伸缩性是一个多维度概念，因为它可能指应用程序可伸缩性、数据可伸缩性或基础设施可伸缩性。</p><p>&nbsp;</p><p>令人感到惊讶的是，软件系统通常被认为是可伸缩的，特别是如果托管在商业云上，正如《持续架构实践》中所说的：</p><p>&nbsp;</p><p></p><blockquote>“云计算提供了允许应用程序以合理的成本处理意外工作负载的承诺，并且不会对应用程序的用户造成任何明显的服务中断，因此，云计算对可伸缩性来说非常重要。”</blockquote><p></p><p>&nbsp;</p><p>然而，只有设计良好的系统才能在云环境中进行良好的伸缩。换句话说，将一个设计糟糕的系统移植到云环境中不太可能获得良好的可伸缩性，特别是如果没有设计好<a href=\"https://wa.aws.amazon.com/wat.concept.horizontal-scaling.en.html\">水平可伸缩性</a>\"的话。</p><p>&nbsp;</p><p>例如，一个为新软件系统开发<a href=\"https://www.infoq.com/articles/minimum-viable-architecture/\">最小可行产品</a>\"（MVP）的团队通常专注于尽可能快地交付系统，它并不关心MVP成功后会发生什么。如果系统的用户基础在最初的发布之后出现快速且意外的增长，系统可能需要进行快速的伸缩，而这超出了团队最初的工作负载假设。他们可能认为在商业云平台上托管系统就把可伸缩性问题转交给了云供应商！商业云平台确实可以提供有效的伸缩性，但前提是应用程序需要被设计为可以利用这些云平台的特性。即使是这样，云平台也不能解决所有的可伸缩性问题，比如当设计中存在资源瓶颈问题时。</p><p>&nbsp;</p><p>有时候，我们会混淆了可伸缩性与性能。与可伸缩性不同，性能是关于软件系统满足其时间需求的能力，并且比可伸缩性更容易测试。如果系统的性能在初始版本中是足够的，团队可能会认为系统能够应付未来增长的工作负载。问题是，如果在架构设计期间不将可伸缩性作为重要的QAR之一，就不是这么回事了。</p><p>&nbsp;</p><p>当然，我们通常不会很明确地指定可伸缩性需求，特别是对于实现了MVP的系统来说，因为通常没有人能够猜测有多少用户会对新的MVP感兴趣，但这不应该成为不做决策和忽略可伸缩性的理由。另一方面，为了“以防万一”而过度构建系统的可伸缩性，以及基于大量膨胀的工作负载来估计架构设计也不是一个好方法。</p><p>&nbsp;</p><p>例如，谷歌、亚马逊、Facebook和奈飞系统具有出色的伸缩能力，但这些公司使用的设计策略并不一定适用于需要处理不同工作负载的公司。在理解这些策略的含义并将QAR和假设明确地作为一系列架构决策之前，我们应该谨慎地使用可伸缩性策略，如基于微服务的架构、异步通信、数据库分片和复杂的分布式系统。</p><p>&nbsp;</p><p>对这些估计持怀疑态度可以防止团队过度设计系统和构建出不必要的功能。</p><p>&nbsp;</p><p></p><h4>基于怀疑主义测试提出的解决方案</h4><p></p><p>&nbsp;</p><p>公司也可以利用怀疑主义来达到更积极的结果。一些团队成员对某个开源框架的经验有限，他们认为可以用它开发一个新的全球制造商的保修管理系统。每个国家的法律限制和业务要求略有不同，但全球的核心流程是相同的。这个团队认为，开源框架可能可以帮助他们开发系统的基本功能，因此，与从头开发基本功能相比，针对当地国家的需求进行定制会更容易、更快、成本更低。使用这个框架做出的有限的原型让他们看到了希望，但还不足以评估其整体适用性。</p><p>&nbsp;</p><p>他们没有直接开发整个系统，而是决定采用怀疑主义方法：他们从代表系统整体功能的功能中剥离出一部分。在一个多月的时间里，他们使用这个框架构建并测试了这个部分，甚至将其部署到一个较小的业务部门进行内部测试和反馈。开发这个部分的成本接近50万美元。尽管如此，开发团队认为，由于这部分是他们的“最小可行产品”，被用于测试他们提出的“最小可行架构”，因此支出是合理的。</p><p>&nbsp;</p><p>在这个过程中，他们发现了一些问题：</p><p>&nbsp;</p><p>他们能够构建所需的功能，并且确实能够在与生产环境类似的环境中运行，但是……开源框架并不像他们所希望的那样灵活和高效。事实上，这个框架让代码变得更加难以维护，而不是更容易维护，因为这个框架与底层工作流所需的模型不完全匹配。</p><p>&nbsp;</p><p>作为实验的结果，公司决定在开发中不使用开源框架，而是自己构建更适合用来解决手头问题的框架。如果他们只使用外部框架开发整个系统，预计开发成本将达到2000万美元。如果在开发的后期发现不合适的话将导致大量的返工，需要移除外部框架，并重新构建系统。在我们所观察到的项目中，这有时候意味着需要重新开始，原始的投入将功亏一篑。</p><p>&nbsp;</p><p></p><h2>如何巧妙地应用怀疑主义</h2><p></p><p>&nbsp;</p><p>应用怀疑主义是具有挑战性的，不仅仅是在技术层面。在一个组织中，人们可能不习惯他们提出的陈述被质疑，无论背后有什么积极的意图。为了培养怀疑主义文化，团队必须开放地验证断言，无论这些断言是谁提出的。</p><p>&nbsp;</p><p>这里有一些方法，可以让看似尖锐的东西变得柔和。团队可以先制定一个原则，即所有假设都需要进行测试，无论它们的来源是什么。当一个团队同意这是“工作方式”的一部分时，团队成员就不会觉得自己的想法受到了挑战。当特定的断言或假设需要进行测试时，这样做就成了团队决定如何工作的一部分。</p><p>&nbsp;</p><p>另一个方法是让团队问自己：“如果我们的假设被证明是错误的，那么哪些假设可能会阻止我们实现我们需要实现的目标？”这是一个关于所有假设的一般性问题，而不是针对某一个人的假设或断言。</p><p>&nbsp;</p><p>还一个方法是参考这句格言——“事实总是是友好的”，这意味着更多或更好的信息将帮助我们实现目标，而不是伤害我们。为工作方式制定一个原则，即“没有不好的想法，只有不完整的信息”，这样也有助于消除对假设和断言的挑战。</p><p>&nbsp;</p><p>有趣的是，天主教会在16世纪建立了“信仰捍卫者”角色（也就是人们所熟知的“<a href=\"https://en.wikipedia.org/wiki/Devil%27s_advocate\">魔鬼代言人</a>\"”），使怀疑主义成为他们册封圣徒过程中不可或缺的一部分。“信仰捍卫者”通过对候选人的性格和行为持怀疑态度来反对他们被封为圣徒。这个角色今天已经不存在了，但机智的怀疑主义仍然是封圣过程中不可或缺的一部分。例如，候选人的批评者可能会接受天主教会的评审，这是这个过程的一部分。</p><p>&nbsp;</p><p></p><h2>结论</h2><p></p><p>&nbsp;</p><p>怀疑主义是一种有价值的对抗手段，可以对抗那种只看最好结果的不合理的美好图景。虽然积极的态度是必不可少的，但通常最好的做法是“抱最好的希望，做最坏的打算”。</p><p>&nbsp;</p><p>在实践中，应用怀疑主义通常意味着为团队成员创造空间，通过寻找证明（或反驳）团队假设的方法来质疑假设和断言。怀疑主义不仅仅是简单地对假设进行分类，还需要积极判断这些假设是否有效。</p><p>&nbsp;</p><p>团队需要认识到，每一个需求，包括驱动架构设计的QAR都代表了关于价值的假设。当我们采用怀疑主义的方法时，目标之一是让这些假设变得明确，并有意识地设计实验，专门测试需求的价值。</p><p>&nbsp;</p><p>怀疑并不代表对人的不尊重，这实际上是对在混乱的世界中为客户提供卓越成果的复杂性的尊重。这意味着需要认真对待团队为产出产品目标和QAR理想结果所做的努力。怀疑有助于团队以积极的方式对假设和隐藏的偏见提出质疑。</p><p>&nbsp;</p><p>谨慎地应用怀疑主义是每一个软件开发团队必不可少的工具，它可以帮助他们在开发早期以更低的成本做出更好的决策。</p><p></p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/architecture-skeptics-guide/\">https://www.infoq.com/articles/architecture-skeptics-guide/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/7Ps0qyHfQhp59g7YrEvZ\">当你的技术栈不能满足每个人需求时，下一步是什么呢？</a>\"</p><p><a href=\"https://www.infoq.cn/article/OyexDC2CWghbD2MsNJoA\">Netflix 构建可伸缩注解服务：使用 Cassandra、Elasticsearch 和 Iceberg</a>\"</p><p><a href=\"https://www.infoq.cn/article/FAxivpNAGHAIyYMupEJG\">提高软件质量：如何处理数据发现更多 Bug</a>\"</p><p></p>",
    "publish_time": "2023-03-17 11:26:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "微软抛出王炸，GPT-4接入Office全家桶！PPT一键生成，又一批打工人要下岗了？",
    "url": "https://www.infoq.cn/article/CPYvD9o4TtNjxXW4xLUg",
    "summary": "<p></p><blockquote>微软强调 AI 工具只是为了给用户提供帮助，而不是取代用户。</blockquote><p></p><p>&nbsp;</p><p>3 月 16 日，微软召开发布会，正式推出基于 <a href=\"https://www.infoq.cn/article/HFSPasQ7SXZ9QzdFXhGO\">GPT-4</a>\" 的 Microsoft 365 <a href=\"https://www.infoq.cn/article/93kD4l5m0pye7k5CrKRT\">Copilot</a>\"。这也意味着，微软热门的 Microsoft 365 商业软件，如 Word、PowerPoint、Excel、Outlook 等都可以使用 AI 功能。</p><p>&nbsp;</p><p>“ChatGPT 版的 Office”来了！</p><p>&nbsp;</p><p>据介绍，Microsoft 365 Copilot 将大语言模型（LLM）的强大功能与 Microsoft Graph 和 Microsoft 365 应用中的数据相结合，致力于成为最强生产力工具。</p><p>&nbsp;</p><p>微软强调，Copilot 绝不仅仅是嵌入至 Microsoft 365 当中的 OpenAI&nbsp;ChatGPT，它更是一套复杂的处理与编排引擎。</p><p>&nbsp;</p><p>微软公司董事长兼 CEO 萨提亚·纳德拉在发布会上表示，“今天标志着我们与计算之间交互方式演变迈下了下一个重要阶段，这将从根本上改变我们的工作方式，并开启新一波生产力增长。通过我们的全新领航工具，人们将获得更有力的智能体支持，真正以最通用的界面——自然语言——轻松获取技术方案。”</p><p>&nbsp;</p><p>目前，微软正通过 Microsoft 365（Word、Excel、PowerPoint、Outlook、Teams 等）和 Business Chat 两种方式和客户一道测试 Copilot 功能，其中，Business Chat 将跨越大语言模型、Excel、PowerPoint、Outlook、Teams 等应用程序和用户的数据（日历、电子邮件、聊天、文档、会议和联系人），帮助用户完成工作。</p><p>&nbsp;</p><p>用户只需发出自然语言提示，比如“通知我的团队要如何更新产品策略”，它就会根据当天早会、电子邮件和聊天线程生成状态更新。在使用工作账户或通过 Teams 登录后，即可在 Microsoft 365.com、Bing 或 Teams 上访问Business Chat。</p><p>&nbsp;</p><p>微软方面并没有明确具体的上线时间，但其透露，Microsoft 365 Copilot 的定价和许可方案，将很快公之于众。</p><p>&nbsp;</p><p>视频演示：</p><p><a href=\"https://youtu.be/S7xTBa93TX8\">https://youtu.be/S7xTBa93TX8</a>\"</p><p></p><h2>Office 全家桶引入 GPT-4，将带来哪些改变？</h2><p></p><p></p><h3>通过三种方式颠覆工作的基本形态</h3><p></p><p>&nbsp;</p><p>据微软介绍，Microsoft 365 Copilot 将通过以下三种方式颠覆工作的基本形态：</p><p></p><h4>1、释放创造力</h4><p></p><p>&nbsp;</p><p>凭借 Copilot in Word，用户可以快速启动创作过程，不必再真正从零开始完全手动操作。Copilot 为用户提供可供编辑和迭代的初稿，大大节约写作、搜索资源和编辑内容的时间。</p><p>&nbsp;</p><p>微软承认，Copilot 有时也会犯错，身为作者，用户将始终掌控全局，按照自己的独特思路向前推进，要求 Copilot 精简、重写或提供反馈。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d2/d2d6c32172382f7c3b6ef6710afcb455.gif\" /></p><p></p><p>Copilot in PowerPoint 能根据用户提供的简单提示创建出精美的演示文稿，添加上周或者去年文档中的相关内容。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a1/a1ab6774eaf9c8dfee02d9f9272ab898.gif\" /></p><p></p><p>Copilot in Excel 则能在几秒钟内分析用户的数据趋势，并创建出具备专业水准的数据可视化成果。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/db/db7a4bd753bc69d9abd5e9a7f954953c.gif\" /></p><p></p><h4>2、释放生产力</h4><p></p><p>&nbsp;</p><p>职场人都希望全身心倾注于真正重要的 20% 工作上，但在实际工作中，却又不得不把 80% 的时间都浪费在枯燥繁琐的小事当中。Copilot 能帮助用户减轻这份负担。</p><p>&nbsp;</p><p>从总结冗长的邮件内容到快速起草回复内容，Copilot in Outlook 将把邮件回复工作从以往的几小时缩短到区区几分钟。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bf/bf8c22206e20b56dff43c3fe857ec467.gif\" /></p><p></p><p>&nbsp;Copilot in Teams 能总结关键讨论要点（包括谁说了什么、大家建立了哪些共识、在哪些问题上未能达成一致等）并给出建议行动，而且是随会议推进实时进行。</p><p>&nbsp;</p><p>Copilot in Power Platform 能帮助用户自动执行重复性任务、创建聊天机器人，并在几分钟内将创意转化为真实可用的应用程序。</p><p>&nbsp;</p><p>GitHub 数据显示，Copilot 具有帮助每个人释放生产力的潜能。在使用 GitHub Copilot 的开发者中，有 88% 的受访者表示工作效率有所提高，74% 的受访者表示 Copilot 能让他们更专注于重要工作，77% 的人表示可以加快信息或示例的搜索速度。</p><p>&nbsp;</p><p>Copilot 的意义还不止于提高个人生产力，更将为各个组织建立起新的知识模型，利用此前几乎无法访问也未被运用的大量数据和见解。</p><p></p><h4>3、提升技能</h4><p></p><p>&nbsp;</p><p>Copilot 能帮助用户在自己擅长的领域做得更好，同时快速掌握尚未学习的内容。Microsoft 365 提供数千个命令选项，但普通用户往往只使用极少一部分，例如“制作幻灯片动画”或“插入表格”。现在，所有这些丰富功能都将解锁自然语言激活模式，而且这仅仅只是开始。</p><p>&nbsp;</p><p>Copilot 将从根本上改变人们与 AI 之间的交互与合作方式。与一切新的工作模式一样，这当然会带来新的学习曲线——但谁能快速接纳新的方式，谁就将获得竞争优势。</p><p></p><h2>超越“ChatGPT版的Office”</h2><p></p><p>&nbsp;</p><p>微软还将通过 Copilot System 发布企业级 AI 方案。微软表示，Copilot 绝不仅仅是嵌入至 Microsoft 365 当中的 OpenAI&nbsp;ChatGPT，它更是一套复杂的处理与编排引擎。它在幕后默默工作，将包括 GPT-4 在内的大语言模型同 Microsoft 365 应用程序和 Microsoft Graph 中的业务数据结合起来，并以自然语言的形式开放给每一位用户。</p><p>&nbsp;</p><p>以用户业务数据为基础：AI 大语言模型是由海量数据集训练而成，但素材仍不足以涵盖所有场景。因此要真正释放企业生产力，关键在于以安全、合规且尊重隐私的方式将大语言模型接入业务数据。Microsoft 365 Copilot 能够实时访问 Microsoft Graph 中的内容和上下文，根据用户的业务内容（包括文档、电子邮件、日历、聊天、会议、联系人和其他业务数据）生成答案，并将其与当前工作环境（用户正在参加的会议、正在编辑的邮件、正在进行的对话）结合起来，提供准确、关联性强且符合上下文的响应结果。</p><p>&nbsp;</p><p>在微软的安全性、合规性与隐私综合体系之上构建。Copilot 被集成至 Microsoft 365 中，并将自动继承企业设置的一切重要安全、合规及隐私政策和流程。通过双因素身份验证、合规边界、隐私保护等机制，Copilot 将成为用户值得信赖的 AI 解决方案。</p><p>&nbsp;</p><p>在架构设计上保护租户、组和个人数据。Copilot 大语言模型不会利用用户的租户数据或提示进行训练。在单一租户之内，许可模型也能确保数据不会跨用户组泄露。至于个人层面，Copilot继承了微软多年来保护客户数据的技术积累，保证只显示用户可以访问到的数据内容。</p><p>&nbsp;</p><p>当前，Microsoft 365 Copilot 已被整合进千万用户在日常工作和生活中高度依赖的生产力应用，包括 Word、Excel、PowerPoint、Outlook 和 Teams 等。直观且统一的用户体验，确保它在 Teams 和 Outlook 中拥有相同的观感、体验和行为，并在提示、优化和命令等层面共享同一种设计语言。</p><p>&nbsp;</p><p>此外，Microsoft 365 Copilot 的基础技能已经颠覆了生产力，能够结合特定业务内容和上下文实现创建、总结、分析、协作和自动化。但它的本事不止于此，Copilot 知道如何操作应用程序（例如「制作幻灯片动画」）和跨应用工作，比如将 Word 文档转换为 PowerPoint 演示文稿。Copilot 还会随时学习新技能。例如，借助 Viva Sales，Copilot 可以学习如何接入 CRM 记录系统，将客户数据（例如交互内容和订单历史）提取至通信当中。随着 Copilot 不断探索新的领域和流程，它将能够执行愈发复杂的任务和查询。</p><p>&nbsp;</p><p>本月初，微软还公布了 Dynamics 365 Copilot——全球首款面向 CRM 与 ERP 领域的 AI Copilot，尝试将下一代 AI 引入各行各业。据微软介绍，在接下来几个月里，微软将把 Copilot 引入微软的所有生产力应用——Word、Excel、PowerPoint、Outlook、Teams、Viva、Power Platform 等等。微软将很快发布定价和许可信息。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-for-work/\">https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-for-work/</a>\"</p>",
    "publish_time": "2023-03-17 11:32:11",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "JDK 20和JDK 21最新动态",
    "url": "https://www.infoq.cn/article/o4cLTZJXMgC7pJwfA8og",
    "summary": "<p><a href=\"https://openjdk.java.net/projects/jdk/20/\">JDK 20</a>\"是自<a href=\"https://www.infoq.com/news/2021/09/java17-released/\">JDK 17</a>\",以来的第三个非长期支持（LTS）版本，正如甲骨文Java平台组的首席架构师<a href=\"https://www.linkedin.com/in/markreinhold\">Mark Reinhold</a>\"所<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-February/007364.html\">宣布</a>\"的那样，它已经进入了初始候选版本阶段。主线源代码库已于2022年12月中旬（Rampdown第一阶段）分支到JDK<a href=\"https://github.com/openjdk/jdk19\">稳定代码库</a>\"，并定义了JDK 20的特性集。严重错误，如回归或严重的功能问题，可能会得到修复，但必须通过<a href=\"https://openjdk.java.net/jeps/3#Fix-Request-Process\">修复请求（Fix-Request）</a>\"流程获得批准。根据<a href=\"https://openjdk.org/projects/jdk/19/#Schedule\">发布时间表</a>\"，JDK 20将于2023年3月21日正式发布。值得注意的是，JEP 438已于2023年3月初被添加到了特性集中。</p><p>&nbsp;</p><p>最终包含了7个JEP形式的新特性，它们可以被分为两类：核心Java库和Java规范。</p><p>&nbsp;</p><p>这些新特性中的5个被归类到了核心Java库中：</p><p>&nbsp;</p><p>JEP 429：<a href=\"https://openjdk.org/jeps/429\">作用域值（孵化器）</a>\"JEP 434：<a href=\"https://openjdk.org/jeps/434\">外部函数和内存API（第二次预览）</a>\"JEP 436：<a href=\"https://openjdk.org/jeps/436\">虚拟线程（第二次预览）</a>\"JEP 437：<a href=\"https://openjdk.org/jeps/437\">结构化并发（第二个孵化器）</a>\"JEP 438:&nbsp;<a href=\"https://openjdk.org/jeps/438\">Vector API (第五个孵化器)</a>\"</p><p>&nbsp;</p><p>这些新特性中有2个被归类到了Java规范中：</p><p>&nbsp;</p><p>JEP 432：<a href=\"https://openjdk.org/jeps/432\">记录模式（第二次预览）</a>\"JEP 433：<a href=\"https://openjdk.org/jeps/433\">switch模式匹配（第四次预览）</a>\"</p><p>&nbsp;</p><p>我们研究了这些新特性以及支持它们的四个主要Java项目（<a href=\"https://openjdk.java.net/projects/amber/\">Amber</a>\"、<a href=\"https://wiki.openjdk.java.net/display/loom\">Loom</a>\"、<a href=\"https://openjdk.java.net/projects/panama/\">Panama</a>\"和<a href=\"https://openjdk.java.net/projects/valhalla/\">Valhalla</a>\"&nbsp;），这些项目旨在孵化一系列组件，然后通过精心策划的合并最终将其纳入到JDK中。</p><p>&nbsp;</p><p></p><h4>Amber项目</h4><p></p><p></p><p>JEP 432，<a href=\"https://openjdk.org/jeps/432\">记录模式（第二次预览）</a>\"，为了响应上一轮<a href=\"https://openjdk.java.net/jeps/12\">预览</a>\"JEP 405，<a href=\"https://openjdk.org/jeps/405\">记录模式（预览版）</a>\"的反馈，它结合了增强功能。提议使用记录模式来增强语言，以解构记录值。记录模式可以与类型模式结合使用，以“实现一种强大的、声明式的、可组合的数据导航和处理形式”。类型模式最近通过JDK 17中提供的JEP 406，<a href=\"https://openjdk.java.net/jeps/406\">switch模式匹配（预览版）</a>\"和JDK 18中提供的JEP 420，<a href=\"https://openjdk.java.net/jeps/420\">switch模式匹配（第二次预览）</a>\"扩展到了 switch 语句标签中。与JEP 405相比，变化包括：增加了对泛型记录模式类型参数的推断支持；增加了对记录模式出现在增强for语句条件判断中的支持；并删除对了对命名记录模式的支持。</p><p>&nbsp;</p><p>类似地，JEP 433：<a href=\"https://openjdk.org/jeps/433\">switch</a>\"<a href=\"https://openjdk.org/jeps/433\">模式匹配（第四次预览</a>\"<a href=\"https://openjdk.org/jeps/433\">）</a>\"，结合了增强功能以响应前三轮预览的反馈：JEP 427，<a href=\"https://openjdk.org/jeps/427\">switch模式匹配（第三次预览）</a>\"，在JDK 19中提供；JEP 420，<a href=\"https://openjdk.java.net/jeps/420\">switch模式匹配（第二次预览）</a>\"，在JDK 18中提供；以及JEP 406，<a href=\"https://openjdk.java.net/jeps/406\">switch模式匹配（预览版）</a>\"，在JDK 17中提供。与JEP 427相比，变化包括：简化了 switch 标签语法；现在， switch 表达式和语句以及其他支持模式的构造体都支持泛型类型模式和记录模式的类型参数推断。</p><p>&nbsp;</p><p></p><h4>Loom项目</h4><p></p><p></p><p>JEP 429，<a href=\"https://openjdk.org/jeps/429\">作用域值（孵化器）</a>\"，一个正在孵化的JEP，最初名为范围局部变量（孵化器，Extent-Local Variables），提议在线程内部和线程之间共享不可变数据。这比线程局部变量更可取，尤其是在使用大量虚拟线程时。</p><p>&nbsp;</p><p>JEP 436，<a href=\"https://openjdk.org/jeps/436\">虚拟线程（第二次预览）</a>\"，提议基于JDK 19中所提供的JEP 425，<a href=\"https://openjdk.org/jeps/425\">虚拟线程（预览版）</a>\"对该特性进行第二次预览，以便留出时间来为该特性的演进提更多的反馈和体验。该特性为Java平台提供了虚拟线程，这是一种轻量级线程，可以极大地减少编写、维护和观察高吞吐量并发应用程序的工作量。需要注意的是，除了少量在JDK19中被被固化的JEP 425 API外，本预览版本没有进行任何更改，因此没有在第二次预览中提出。有关JEP 425的更多详细信息，请参阅InfoQ的<a href=\"https://www.infoq.com/news/2022/05/virtual-threads-for-jdk19/\">新闻报道</a>\"和甲骨文Java平台组Java开发人员倡导者<a href=\"https://www.linkedin.com/in/jos%C3%A9-paumard-2458ba5/\">José Paumard</a>\"的JEP Café<a href=\"https://inside.java/2022/06/08/jepcafe11/\">屏幕截图</a>\"。</p><p>&nbsp;</p><p>JEP 437，<a href=\"https://openjdk.org/jeps/437\">结构化并发（第二</a>\"<a href=\"https://openjdk.org/jeps/437\">个</a>\"<a href=\"https://openjdk.org/jeps/437\">孵化器）</a>\"，提议基于JDK 19中所提供的JEP 428，<a href=\"https://openjdk.org/jeps/428\">结构化并发（孵化器）</a>\"重新孵化，以便留出时间来为该特性的演进提更多的反馈和体验。此特性的目的是通过引入一个库来将在不同线程中运行的多个任务视为单个工作单元，从而简化多线程编程。这可以简化错误处理和撤销，提高可靠性，并增强可观测性。唯一的变化是更新了 StructuredTaskScope 类，以支持在任务作用域中创建的线程可以继承作用域的值。这简化了线程间不可变数据的共享。有关JEP 428的更多详细信息，请参阅InfoQ<a href=\"https://www.infoq.com/news/2022/06/java-structured-concurrency/\">新闻报道</a>\"。</p><p>&nbsp;</p><p></p><h4>Panama项目</h4><p></p><p></p><p>JEP 434，<a href=\"https://openjdk.org/jeps/434\">外部</a>\"<a href=\"https://openjdk.org/jeps/434\">函数</a>\"<a href=\"https://openjdk.org/jeps/434\">和内存API（第二次预览</a>\"<a href=\"https://openjdk.org/jeps/434\">）</a>\"，基于反馈进行了改进，并基于JDK 19中所提供的JEP 424，<a href=\"https://openjdk.org/jeps/424\">外部函数和内存API（预览版）</a>\"进行了第二次预览。相关孵化包括JEP 419，<a href=\"https://openjdk.org/jeps/419\">外部函数和内存API（第二个孵化器）</a>\"，在JDK 18中交付；以及JEP 412，<a href=\"https://openjdk.org/jeps/412\">外部函数和内存API（孵化器）</a>\"，在JDK 17中交付。该特性为Java应用程序提供了一个API，通过高效地调用外部函数和安全地访问不受JVM管理的外部内存，在Java运行时之外与代码和数据进行互操作。JEP 424的更新包括：统一了 MemorySegment 和 MemoryAddress 接口，即，内存地址由零长度的内存段建模；并且增强了 MemoryLayout 密封接口，以便于与在JDK 19中提供的JEP 427，<a href=\"https://openjdk.org/jeps/427?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2Njc5NTcwNzQsImZpbGVHVUlEIjoiSm5mVnpmNG5ZdThBcDFsdyIsImlhdCI6MTY2Nzk1Njc3NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo4NTA5NTIwOX0.9fQ4yI44wd5QQLZv8_85Xhtv4-M8HKKZQzqwaeEbaM4\">switch中的模式匹配（第三次预览）</a>\"一起使用。</p><p>&nbsp;</p><p>JEP 438，<a href=\"https://openjdk.org/jeps/438\">Vector API</a>\"<a href=\"https://openjdk.org/jeps/438\">(</a>\"<a href=\"https://openjdk.org/jeps/438\">第五</a>\"<a href=\"https://openjdk.org/jeps/438\">个</a>\"<a href=\"https://openjdk.org/jeps/438\">孵化器</a>\"<a href=\"https://openjdk.org/jeps/438\">)</a>\"，结合了对前四轮孵化器反馈进行了增强：JEP 426，<a href=\"https://openjdk.org/jeps/426\">Vector API（第四个孵化器）</a>\"，在JDK 19中交付；JEP 417，<a href=\"https://openjdk.java.net/jeps/417\">Vector API（第三个孵化器）</a>\"，在JDK 18中交付；JEP 414，<a href=\"https://openjdk.java.net/jeps/414\">Vector API（第二个孵化器）</a>\"，在JDK 17中交付；JEP 338，Vector API（孵化器），作为JDK 16中的<a href=\"https://openjdk.java.net/jeps/11\">孵化器模块</a>\"提供。该特性旨在增强Vector API，以根据JEP 424，<a href=\"https://openjdk.org/jeps/424\">外部函数和内存API（预览版）</a>\"的定义，从 MemorySegment 中加载并存储向量。</p><p>&nbsp;</p><p></p><h4>JDK 21</h4><p></p><p></p><p>计划于2023年9月发布一个GA和下一个LTS版本，目前<a href=\"https://jdk.java.net/20/\">JDK 21</a>\"的Proposed to Target有两（2）个JEP。</p><p>&nbsp;</p><p>JEP 430，<a href=\"https://openjdk.org/jeps/430\">字符串模板（预览版）</a>\"，一种JEP类型的特性，提议使用字符串模板来增强Java编程语言，字符串模板类似于字符串字面量，但包含在运行时合并到字符串模板中的嵌入式表达式。该特性已被归类为JDK 21的Proposed to Target，但尚未正式公布审查日期。</p><p>&nbsp;</p><p>JEP 431，<a href=\"https://openjdk.org/jeps/431\">序列集合</a>\"，提议引入“一个组能新表示集合概念的接口，这些集合的元素按照定义良好的序列或顺序排列，作为集合的结构属性。”其动因是由于集合框架（Collections Framework）中缺乏定义良好的排序和统一操作集。该特性已被归类为JDK 21的Proposed to Target，但尚未正式公布审查日期。</p><p>&nbsp;</p><p>我们可以根据一些JEP草案和候选版本来推测哪些额外的JEP有可能会被包含在JDK21中。</p><p>&nbsp;</p><p>JEP草案8303358，<a href=\"https://openjdk.org/jeps/8303358\">作用域值（预览版）</a>\"，由红帽公司的杰出工程师<a href=\"https://www.linkedin.com/in/andrew-haley-3546112/\">Andrew Haley</a>\"和<a href=\"https://www.infoq.com/profile/Andrew-Dinn/\">Andrew Dinn</a>\"提交，对即将发布的JDK 20中所提供的JEP 429，<a href=\"https://openjdk.org/jeps/429\">作用域值（孵化器）</a>\"进行了改进。其最初名为范围局部变量（孵化器，Extent-Local Variables），由<a href=\"https://wiki.openjdk.java.net/display/loom/Main\">Loom</a>\"项目支持，该特性旨在实现线程内部和线程之间不可变数据的共享。这比线程局部变量更可取，尤其是在使用大量虚拟线程时。虽然这个草案还没有达到Candidate状态，但描述中明确指出，这个JEP将被添加到JDK21中。</p><p>&nbsp;</p><p>JEP草案8277163，<a href=\"https://openjdk.java.net/jeps/8277163\">值对象（预览版）</a>\"，是由Valhalla项目赞助的一个JEP特性，提议创建价值对象——无身份标识的值类，指定其实例的行为。该草案与JEP 401，<a href=\"https://openjdk.java.net/jeps/401\">原语类（预览版）</a>\"相关，目前仍处于Candidate状态。</p><p>&nbsp;</p><p>JEP 435，<a href=\"https://openjdk.org/jeps/435\">异步堆栈跟踪VM API</a>\"，一种JEP类型的特性，提议定义一个有效的API，用于收集堆栈跟踪信息，以便根据包含Java和本地堆栈帧信息的信号处理器进行分析。</p><p>&nbsp;</p><p>JEP 401，<a href=\"https://openjdk.java.net/jeps/401\">原语类（预览版）</a>\"，在Valhalla项目的支持下，引入了开发人员声明的原语类——特殊类型的值类——如前面提到的值对象（预览版）JEP Draft中所定义——定义了新的原语类型。</p><p>&nbsp;</p><p>JEP草案8301034，<a href=\"https://openjdk.org/jeps/8301034\">密钥封装机制API</a>\"，一种JEP类型的特性，提议：满足标准<a href=\"https://cseweb.ucsd.edu/~btackmann/papers/CoMaTa13b.pdf\">密钥封装机制</a>\"（Key Encapsulation Mechanism，KEM）算法的实现；通过更高级别的安全协议满足KEM的用例；并且允许可插拔的KEM算法的Java或本地实现。该草案最近进行了更新，其中包括一项重大更改，即取消了 DerivedKeyParameterSpec 类，转而将字段放在 encapsulate(int from, int to, String algorithm) 方法的参数列表中。</p><p>&nbsp;</p><p>JEP草案8283227，<a href=\"https://openjdk.org/jeps/8283227?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjMyOTkwNjAsImZpbGVHVUlEIjoiQ1pBYVhUYWZxUFlwWXpZcSIsImlhdCI6MTY2MzI5ODc2MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P70chYf8kq5aaY1VqbJ-c26BjR29KeJXEA-UkR-O69s\">JDK源结构</a>\"，一种信息类的JEP，用于描述JDK源代码和JDK代码库中相关文件的总体布局和结构。该JEP提议帮助开发人员适应在JDK9中提供的JEP 201，<a href=\"https://openjdk.java.net/jeps/201\">模块化源代码</a>\"中所描述的源代码结构。</p><p>&nbsp;</p><p>JEP草案8280389，<a href=\"https://openjdk.org/jeps/8280389?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjMyOTkwNjAsImZpbGVHVUlEIjoiQ1pBYVhUYWZxUFlwWXpZcSIsImlhdCI6MTY2MzI5ODc2MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P70chYf8kq5aaY1VqbJ-c26BjR29KeJXEA-UkR-O69s\">ClassFile API</a>\"，提议提供一个用于解析、生成和转换Java类文件的API。该JEP最初将作为JDK中<a href=\"https://asm.ow2.io/\">ASM</a>\"（Java字节码操作和分析框架）的内部替代品，并计划将其作为公共API开放出来。甲骨文（Oracle）的Java语言架构师<a href=\"https://www.linkedin.com/in/briangoetz\">Brian Goetz</a>\"将ASM描述为“一个带有大量遗留包袱的旧代码库”，并提供了有关该草案将如何演进并最终取代ASM的背景信息。</p><p>&nbsp;</p><p>JEP草案8278252，<a href=\"https://openjdk.org/jeps/8278252?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjMyOTkwNjAsImZpbGVHVUlEIjoiQ1pBYVhUYWZxUFlwWXpZcSIsImlhdCI6MTY2MzI5ODc2MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P70chYf8kq5aaY1VqbJ-c26BjR29KeJXEA-UkR-O69s\">JDK打包和安装指南</a>\"，一个信息型的JEP，提议为macOS、Linux和Windows提供创建JDK安装程序的指南，以降低不同JDK提供程序在JDK安装之间发生冲突的风险。其目的是通过规范化安装目录名称、包名称和其他可能导致冲突的安装程序元素，在安装JDK更新版本时提升更好的用户体验。</p><p>&nbsp;</p><p>我们预计甲骨文将会很快开始为JDK 21提供更多的额外JEP。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/03/java-20-so-far/\">https://www.infoq.com/news/2023/03/java-20-so-far/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/UbJ7lV4OWYjY7UN4JGBD\">Java 近期新闻：NetBeans 17、Spring 及 Tomcat 多项更新、JDk 20 版本 GraalVM</a>\"</p><p><a href=\"https://www.infoq.cn/article/YaBqqD7fd6kX97GbhkGm\">虚拟线程：大规模 Java 应用的新基石</a>\"</p><p><a href=\"https://www.infoq.cn/article/KUFfYLk4zWcQ1VZXflpp\">Just：Spring Boot 应用的新命令行界面</a>\"</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-03-17 11:35:11",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "全面升级未来数据智能战略，柏睿数据发布全新数据智能产品矩阵",
    "url": "https://www.infoq.cn/article/gDNkrkUMbSdBl7q9UW8O",
    "summary": "<p>3月16日，<a href=\"https://www.infoq.cn/article/Je9iE2vCQcMJSVbZxXiS\">柏睿数据</a>\"在北京举办“数智引领 睿创新机——柏睿数据2023新品发布媒体见面会”，全面升级未来数据智能战略，发布全新数据智能产品矩阵，针对五大行业全面数智化转型提出场景解决方案，赋能客户、生态伙伴从智慧数据中释放生产力，加速千行百业数智化转型。</p><p>&nbsp;</p><p>柏睿数据总裁梁雪青表示，未来将进入数字经济全面、高质量发展的黄金时代，柏睿数据期冀与合作伙伴携手，在数智时代发展的新征程上勇踏前人未至之境。</p><p></p><h2>“Data+AI”已成为企业数字化转型的重要技术趋势和驱动力</h2><p></p><p>&nbsp;</p><p>当前，“Data+AI”已成为企业数字化转型的重要技术趋势和驱动力，能够充分激活数据要素潜能。</p><p>&nbsp;</p><p>而现阶段制约数据新价值释放的基础性核心因素在于数据质量和数据算力，亟需个性化、云化、智能化、标准化的数据算力产品和服务，以实现高性能、高成效比、随需随用的数据算力，保障数据可靠性和合规性。&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/11/11fff8dd565156473fe0dc9523e4ce05.png\" /></p><p></p><p>柏睿数据董事长、首席科学家刘睿民表示：“柏睿数据长期致力于大数据智能与云端战略升级，以及产业智慧落地升级，以‘全内存分布式计算引擎’为基础，以建构‘数据智能’技术为核心，构建高性能、安全合规、自动化的数据洞察数字化平台，同时通过数据智能技术在五大关键行业场景的创新应用，助力客户伙伴以智慧数据创造行业新价值。”同时提出坚持信创引领，立足技术产品核心，联合信创产业上下游生态伙伴，共建信创生态；坚持标准先行，牵引大数据产业规范化、高质量发展。</p><p>&nbsp;</p><p>柏睿数据联合创始人、全球副总裁、首席技术官马珺正式发布了拥有完全自主知识产权的全新数据智能产品矩阵：全内存分布式数据库RapidsDB核心数据算力引擎、一体化流湖仓、智能开发平台和数据智能交付平台四大产品系列，打造了从数据管理到数据分析的完整产品体系，为客户提供个性化的、基于超强算力和云原生的现代数据智能产品体系和服务，覆盖数据全生命周期应用，满足客户高性能、标准化、高可用、自动化、高成效比的数据算力需求。</p><p><img src=\"https://static001.geekbang.org/infoq/e2/e22d8bc329d0b17dc339a0b880a9c226.png\" /></p><p></p><p>会议现场，柏睿数据行业咨询总监顾冉介绍了基于数据智能算力底座打造的柏睿数据五大行业场景解决方案。</p><p>&nbsp;</p><p>面向运营商、金融、能源、政务和智能制造五大重数据资产的行业，为用户提供深入行业场景的数据智能全栈服务能力，助力用户实现降本增效、业务增长与业务创新，加速各行业构建全面感知、无缝连接、高度智能的全域数字能力，推动数实融合和数字经济高质量发展。目前，柏睿数据已服务各行业领先企业500+项目。</p><p></p><h2>从数据资产到数据要素，数字中国还有多远？</h2><p></p><p>&nbsp;</p><p>在圆桌对话环节，来自华录光存储研究院、国信优易、飞诺门阵的合作伙伴代表与柏睿数据副总裁李远志就“从数据资产到数据要素，数字中国还有多远？”展开了深入讨论。</p><p>&nbsp;</p><p>飞诺门阵代表表示，统一的技术和产品标准、数据产权的明确划分，能够有效避免数据资产的浪费，是充分激活数据要素潜能的基础。</p><p>&nbsp;</p><p>华录光存储研究院代表指出，硬件基础+软件应用，将是数据资产升级为数据要素的重要基础。</p><p>&nbsp;</p><p>柏睿数据副总裁李远志指出，柏睿数据全新数据智能产品矩阵建立了从数据管理到数据分析的完整产品体系，其中数据分析是数据要素的生产过程，是用户完成数据资产价值兑现的必由之路。</p><p>&nbsp;</p><p>国信优易代表指出，未来国家数据局的组建，将为大数据企业提供更加明确的发展路径和发展依据，加速数字中国高质量发展。</p>",
    "publish_time": "2023-03-17 14:46:23",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "开源泰斗陆首群教授：开源创新已成为数字化转型、智能化重构的基础",
    "url": "https://www.infoq.cn/article/fHpvaHg8Oo6ATW2g18RU",
    "summary": "<p>3月15日，机械工业出版社、中国计算机学会联合主办了由中国计算机学会出版基金赞助项目支持的“计算机开源丛书·开源创新在中国系列”首部作品《开源创新：数字化转型与智能化重构》的新书发布会。</p><p>&nbsp;</p><p>《开源创新：数字化转型与智能化重构》不仅详细展示了中国开源事业的发展历史和未来走向，也生动记述了陆首群教授在这一历史进程中的实践、观察和思考，可看作<a href=\"https://www.infoq.cn/article/REXcTWWYJptLJ0stJY8L\">中国开源发展</a>\"的缩影和见证，具有重要史料价值和现实指导意义。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/81/812c8406d5ab4b1de954468e69a114cf.png\" /></p><p></p><p>本书作者、中国开源界领军人物陆首群教授在题为《开源创新在中国》的演讲中指出，如今开源已经成为全球的一种创新和协同模式，成为创新国家的战略需求。人们更加重视开源的溢出效应：开源创新已成为数字化转型、智能化重构的基础。从围绕企业产品的操作系统及其生态建设到结合研发基于开源的新一代信息技术及其应用，再到在经济双循环基础上规范建设或改造我国供应链，促进供应链数字化、开源化，中国开源的发展在经历了三个阶段后现已进入世界先进行列。</p><p>&nbsp;</p><p>发布会结束后，陆首群教授接受了 InfoQ 在内的少数几家媒体的采访。以下为采访实录，经编辑。</p><p></p><h2>对话开源泰斗陆首群教授</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0c/0c25cfb90b64b6f0e7a52c4757c54a95.jpeg\" /></p><p></p><p></p><h4>《开源创新：数字化转型与智能化重构》的创作故事</h4><p></p><p>&nbsp;</p><p>问：《开源创新：数字化转型与智能化重构》这本书的创作动机以及定位是什么？</p><p>&nbsp;</p><p>陆首群教授：这本书的定位可以说是面向全球各行各业各阶层。另外，也照顾到国际同行，这本书也值得国际上很多开源大师、专家们看一看。在之前的一个活动中，国外的开源大师看这本书时也津津有味，因为这本书里有很多照片，即使看不懂文字，他们也能通过照片里的人，了解当时大概在研究什么问题。要给这本书准确定位的话，就比较复杂了。现在各方面都在拥抱开源，所以开源发展得很快，不是说几个专业单位、开源社区、开源基金会关心开源，还有很多人都在研究开源，像官员、教师，都是能受益的。</p><p>&nbsp;</p><p>总体来说，写这本书的动机就是把开源进一步普及，进一步提高，促进开源的崛起。创作背景就是开源热度很高，大家都很关心，包括出版行业也很关心。我希望写个比较广泛的内容，希望能把开源观念讲清楚。</p><p>&nbsp;</p><p>问：在本书的第二章中，您列举了一些重要事件，您个人认为其中最难、最艰辛的事件是什么？</p><p>&nbsp;</p><p>陆首群教授：开源是一个学术体系。这个体系跟原来我们传统的体系完全不一样，它的法律概念也不一样。所以有人就把传统的法律体系称为右版体系，而开源所在的是左版体系。有时候对于某件事，右版体系认为它违法了，开源认为它没有违法；开源认为合法的，右版体系可能又认为违法了，所以好多概念就不一样。</p><p>&nbsp;</p><p>因此，最关键的就是要理解开源的概念，理解开源的观念，理解开源的本质，这个是最难的。</p><p></p><h4>对开源的理解</h4><p></p><p>&nbsp;</p><p>问：您从 20 世纪 90 年代就已经投入到开源中了，到今天已经 30 多年了，在整个过程中，中国开源整体的发展发生了哪些变化？</p><p>&nbsp;</p><p>陆首群教授：我从 90 年代初就开始搞开源，工作的几条线都是平行的。一个是“信息技术”这条线，现在我们叫深度信息技术，也叫新一代的信息技术，包括云计算、区块链、大数据、人工智能。我们要把开源跟这些结合在一起，这些技术基于开源发展得会更好。另外一个是“互联网技术”，我们中国发展互联网建设也要结合开源往上推进。</p><p>&nbsp;</p><p>很多技术都离不开开源，这里我举个人工智能的例子。2015 年，美国在人工智能方面做得好的四大企业：谷歌、微软、Facebook、IBM。后来它们发现人工智能做不下去了，达到瓶颈了。这四家大企业就把所有的人工智能框架、工具、软件内容通通开源，一下子解决了人工智能的发展瓶颈。</p><p>&nbsp;</p><p>联合国在研究互联网的治理问题时，曾经找过几家组织：第一家是印度政府；第二家是谷歌公司；第三家是我们中国开源软件推进联盟；第四家是哈佛商学院；第五家是GitHub。这五家组织共同来讨论互联网的治理下一步怎么做。我们联盟在这次会议的讨论中，举了一个百度 Apollo 无人驾驶项目的开源案例。有人就问我说，技术开源给别人了，我们还有什么优势？我说你放心好了，这是两码事。</p><p>&nbsp;</p><p>百度的 Apollo 成为全球最活跃的自动驾驶跟无人驾驶的平台之一，汇集了 7 个国家的 65,000名 志愿开发者一块来开发，完成了 60 万行的开源代码。另外它还跟全世界的 210 家合作伙伴建立了供应关系，这个就是开源的优势。原本只有 1 个人开发，现在有 10 个人帮你一块来开发，效果就好多了。</p><p>&nbsp;</p><p>问：最近几年，国内越来越重视开源，如果我们想更好地构建国产化的开源生态体系，还需要各方做出哪些努力？</p><p>&nbsp;</p><p>陆首群教授：开源生态跟开源发展的关系非常之大。拿华为来说，我认为华为手机必须国际化，不能只在中国卖，要有国际化的生态。从技术层面上，华为要搞生态是没问题的，但这里面有好多因素在干预。开源有一个重要的特征叫协同。企业自己要主动，也要在国内找开源组织，帮企业一块来链接生态。</p><p>&nbsp;</p><p>问：构建一个良好的开源社区的生态和实现一个开源项目的商业化盈利之间怎么把握平衡？</p><p>&nbsp;</p><p>陆首群教授：关于开源商业化的问题，国内一些企业还是没有搞清楚。现在社区开发的版本都是开源的、免费的，是可以从网上自由下载的。但如果我们从头到尾都免费拿走，谁还搞产业？这样开源是发展不起来的。</p><p>&nbsp;</p><p>所以就有了从社区版发展而成的企业的商业发行版，这里包含了社区版，但是又不同于社区版。当企业要引领产业的时候，要在这上面加一个透明的环，这个环是什么呢？就是针对原来社区版的框架改造。由于社区版不够成熟，稳定性不好，所以还要进一步测试。另外还要做好维护，因为不管是开源还是闭源软件，都会产生大量的 Bug。</p><p>&nbsp;</p><p>另外生态建设也包含几个方面：硬件的生态，软件的生态。生态建设有开源的，也有闭源的。其次产品还要有安全模块和质量认证保障，这些也不一定是开源的。所以要把开源的社区版本跟开源的商业发行版本区别开来。</p><p>&nbsp;</p><p>将来要引领产业的主要是商业版本，不是开源版本。中国现在有几种情况，一种是我拿到你的开源社区版，我自己就做产品了，别的东西不要了，这个是不行的。第二种是企业拿到社区版本后自己封起来了，这个更不行。所以，开源发展的概念和做法要明确，这样的话才能保证开源发展引领产业。</p><p>&nbsp;</p><p>问：企业面对现在的数字化浪潮，怎样利用开源来进行转型升级和创新？</p><p>&nbsp;</p><p>陆首群教授：我个人的观点是，现在的中国要从工业社会向信息社会发展，但是现在从工业社会向信息社会发展还缺少条件，因为我们现在连个试点地区都没有。我们现在是工业社会，再进一步发展是后工业级社会，比如像美国现在已经进入后工业级社会，当然它也不是信息社会，而只是有信息技术。</p><p>&nbsp;</p><p>另外关于创新的问题，我希望是社会各界来把它重新演变，所以这里面就要找两个空间，一个是虚拟化的数字空间，一个是现实的物理空间。这样可以解决工业社会的业态到现代化的创新，一种从 0 到 1 的创新。</p><p>&nbsp;</p><p>高阶社会是信息社会，空间也是信息空间，低阶社会是工业社会，也是现实的空间，物理空间。信息社会实际上也是分层次的，底层是数据层或者数字层，数字层上面是信息层，信息层上面是知识层，知识层上面是智能层。这 4 个层次里面，最基础的、最关键的就是数据层。按照欧洲人的说法，就叫Cyber-Physical（信息物理）。</p><p>&nbsp;</p><p>现在我们都说发展数字化就是这个意思。数字化再扩大一点，就是数字网络化，再扩大才是数字经济。数字化实际上是代表信息化，从底层到高层基本上是这样一个概念。</p><p>&nbsp;</p><p>问：Linux 系统目前的部分代码存在于美国的一些托管平台，如果因为地缘政治的关系，托管平台不对中国开放了，那中国的企业应该如何应对？</p><p>&nbsp;</p><p>陆首群教授：这有几个条件。第一，Linux 系统是开源的；第二，Linux 系统现在发展得很快。Linus 做出来操作系统以后，以现在的视角来看，当初的开源发展是有问题的。作为一个产品，Linus 告诉我，最初的社区是不收费的，后来我知道的也只是收取很少的费用。所以这种情况下，开发者都是利用业余时间从事开发，平时需要找一份工作，来满足生活、家庭和开发的需求。这些问题是要解决的，后来 Linus 做出来操作系统后，他也在一家公司打工，有了 IBM 等多家公司提供资金支持研究后，Linux 的发展才开始加速。</p><p>&nbsp;</p><p>我们之前做过一场圆桌会议，讨论现在美国 IT 领域排名前 20% 的企业做开发，曾经 80%~100% 是企业内部开发，现在则大多是企业外部开发，就是因为有开源的资源，它们等于站在巨人的肩膀上向前走，所以开发速度很快。我国还不能完全利用外面的资源，为了解决这个问题，首先，不仅要把开源发展好，还要把科学国际关系发展好；其次，我现在组织了一个开源高地，开源高地也是科技的高地，新兴的高地，人才的高地。我希望将来的开源，能沟通全世界。</p><p></p><h4>“ChatGPT 不开源是说不过去的”</h4><p></p><p>&nbsp;</p><p>问：能否讲讲您理解的 ChatGPT？</p><p>&nbsp;</p><p>陆首群教授：人类很喜欢让计算机跟人来对话。机器能“翻译”人说的话，但目前还不够准确，所以在这种情况开发了 <a href=\"https://www.infoq.cn/theme/173\">ChatGPT</a>\"。但是还有些麻烦。机器不能识别很多综合性事物。举个例子，比如汽车，其实训练一个三四岁的小孩两三个月，他不管是红汽车、绿汽车、蓝汽车，他认为都是汽车，这是人类的思考。计算机可不行，绿汽车和红汽车是两码事，蓝汽车更是另外一回事。有好多程序的东西，计算机不识别，就卡在那里。这说明，计算机缺少知识的逻辑特例，得推理，要是把概念弄在一块了就推理不了了。</p><p>&nbsp;</p><p>所以 OpenAI 一开始做了个类似字典的东西，就会把蓝汽车、红汽车都叫汽车，甚至把卡车也叫汽车。字典不行的话，就用大数据，把字典换成语料库，里面是语义，这样一来精确度就很高了。这些都是基于机器学习，或者叫深度学习。如果想更准确，那就把由语义构成的“字典”弄厚一些，但它终究还是弱人工智能，还是做不到强人工智能的事情。</p><p>&nbsp;</p><p>问：您构想的未来的人工智能是什么样子？</p><p>&nbsp;</p><p>陆首群教授：这个问题在全世界都有争论。现在的人工智能属于弱人工智能，其中的代表技术叫机器学习、深度学习，这个是弱的。现在的人工智能能做到什么事呢？比如人脸识别、语音识别、图像识别、自动驾驶，一些新药和新材料的发现，也能够依靠人工智能去解决。但进一步的，现在都做不到。</p><p>&nbsp;</p><p>我认为人工智能发展到未来会是什么样？现在看起来，接下来的挑战是类人人工智能——和人的思考是类似的。这方面的研究现在有一些苗头了，如果再进一步，能不能是超人人工智能，现在谁也说不准。如果人工智能超过人，那么人就变成人工智能的奴隶了，听起来恐怕有点夸大其词。但是，现在看起来，弱人工智能迈向强人工智能，这一步是很艰难的。</p><p>&nbsp;</p><p>问：ChatGPT 到目前为止还没有开源，但市面上已经出现了一些开源的替代品，有人说开源最终会吞噬人工智能，您怎么看这个问题？</p><p>&nbsp;</p><p>陆首群教授：最近很多专家问我这个问题。ChatGPT 现在不开源，是因为公共保障还没有完善，因为你真的要在市场上面宣布全面开源，还要做好多事情，法律、商业、技术的，现在还顾不上这些问题，但我估计它是肯定要开源的。ChatGPT 是基于机器学习的，机器学习技术是开源的，ChatGPT 不开源是说不过去的。</p><p></p><h4>如何保持对新技术的敏锐度？</h4><p></p><p>&nbsp;</p><p>问：您是 20 世纪 30 年代生人，1953 年上大学，现在快 90 岁了，精神状态这么好，实现了清华的“为祖国健康工作 50 年”，请问您是怎么做到的？</p><p>&nbsp;</p><p>陆首群教授：我 1953 年进北京，到八几年的时候，我已经工作了好几十年了。那时候清华大学没有计算机系，也没有自动化系，电机系是最有名的，我是奔着清华电机系去的。那时的清华大学，在教育战线上的目标是要培养又红又专的红色工程师。那时我们分配工作，祖国需要我们到哪个地方去，我们就去哪里。我们甚至愿意到西藏去，到边疆去，没有二话的。生命力跟年龄有关系，但是更主要的跟你的精神状态有关系。</p><p>&nbsp;</p><p>问：您对新知识包括 ChatGPT 等新技术还能保持这么敏锐的捕捉度，随时能跟上现代知识的更新，您是怎么做到的？</p><p>&nbsp;</p><p>陆首群教授：我的学习有个特点，就是干哪一行，就把原来干的跟这个无关的都抛掉，抛掉之后我就钻进去研究这一行，我必须要弄清楚它的基本概念以及整个行业的思路，否则的话就别搞这个东西。</p><p>&nbsp;</p><p>比如数学，我当时学数学还是下功夫的。我曾经就统计数学的相关理论在日本做过讲义，也曾与斯坦福大学数学系主任进行过深入的学术探讨。有一次在我国举办的数学年会上，日方问工作人员“你们有一位陆先生，怎么不请他参加？他在日本还挺有声望的”。工作人员说：“哪一位陆先生，我们大学里没有陆先生，科学家也没有陆先生。”后来才知道，这位“陆先生”不在教育领域，也不在科研领域，这个人在工业领域。</p><p></p><p>问：您喜欢理论数学还是应用数学？</p><p>&nbsp;</p><p>陆首群教授：应用数学。</p><p>&nbsp;</p><p>问：您觉得人工智能是应用的还是理论的，或者两者皆有？</p><p>&nbsp;</p><p>陆首群教授：现在国内好多人都在做人工智能，现在的人工智能是弱人工智能，它的一个理论是统计理论。人工智能当时在我国发展较缓慢，在这种情况下，我们自己就办两件事，一个我自己在这里面进行研究，另外一个是得从头到尾弄清楚人工智能的发展情况，这些你只要下点功夫就行。于是，我们做了一个平台，通过这个平台展现人工智能发展的情况，同时也促进国内外业内人士的交流。</p>",
    "publish_time": "2023-03-17 16:23:21",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "柏睿数据发布全新数据智能产品矩阵",
    "url": "https://www.infoq.cn/article/gDNkrkUMbSdBl7q9UW8O",
    "summary": "<p>3月16日，<a href=\"https://www.infoq.cn/article/Je9iE2vCQcMJSVbZxXiS\">柏睿数据</a>\"在北京举办新品发布会，发布全新数据智能产品矩阵，针对五大行业全面数智化转型提出场景解决方案，赋能客户、生态伙伴从智慧数据中释放生产力，加速千行百业数智化转型。</p><p>&nbsp;</p><p>柏睿数据总裁梁雪青表示，未来将进入数字经济全面、高质量发展的黄金时代，柏睿数据期冀与合作伙伴携手，在数智时代发展的新征程上勇踏前人未至之境。</p><p></p><h2>“Data+AI”已成为企业数字化转型的重要技术趋势和驱动力</h2><p></p><p>&nbsp;</p><p>当前，“Data+AI”已成为企业数字化转型的重要技术趋势和驱动力，能够充分激活数据要素潜能。</p><p>&nbsp;</p><p>而现阶段制约数据新价值释放的基础性核心因素在于数据质量和数据算力，亟需个性化、云化、智能化、标准化的数据算力产品和服务，以实现高性能、高成效比、随需随用的数据算力，保障数据可靠性和合规性。&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/11/11fff8dd565156473fe0dc9523e4ce05.png\" /></p><p></p><p>柏睿数据董事长、首席科学家刘睿民表示：“柏睿数据长期致力于大数据智能与云端战略升级，以及产业智慧落地升级，以‘全内存分布式计算引擎’为基础，以建构‘数据智能’技术为核心，构建高性能、安全合规、自动化的数据洞察数字化平台，同时通过数据智能技术在五大关键行业场景的创新应用，助力客户伙伴以智慧数据创造行业新价值。”同时提出坚持信创引领，立足技术产品核心，联合信创产业上下游生态伙伴，共建信创生态；坚持标准先行，牵引大数据产业规范化、高质量发展。</p><p>&nbsp;</p><p>柏睿数据联合创始人、全球副总裁、首席技术官马珺正式发布了拥有完全自主知识产权的全新数据智能产品矩阵：全内存分布式数据库RapidsDB核心数据算力引擎、一体化流湖仓、智能开发平台和数据智能交付平台四大产品系列，打造了从数据管理到数据分析的完整产品体系，为客户提供个性化的、基于超强算力和云原生的现代数据智能产品体系和服务，覆盖数据全生命周期应用，满足客户高性能、标准化、高可用、自动化、高成效比的数据算力需求。</p><p><img src=\"https://static001.geekbang.org/infoq/e2/e22d8bc329d0b17dc339a0b880a9c226.png\" /></p><p></p><p>会议现场，柏睿数据行业咨询总监顾冉介绍了基于数据智能算力底座打造的柏睿数据五大行业场景解决方案。</p><p>&nbsp;</p><p>面向运营商、金融、能源、政务和智能制造五大重数据资产的行业，为用户提供深入行业场景的数据智能全栈服务能力，助力用户实现降本增效、业务增长与业务创新，加速各行业构建全面感知、无缝连接、高度智能的全域数字能力，推动数实融合和数字经济高质量发展。目前，柏睿数据已服务各行业领先企业500+项目。</p><p></p><h2>从数据资产到数据要素，数字中国还有多远？</h2><p></p><p>&nbsp;</p><p>在圆桌对话环节，来自华录光存储研究院、国信优易、飞诺门阵的合作伙伴代表与柏睿数据副总裁李远志就“从数据资产到数据要素，数字中国还有多远？”展开了深入讨论。</p><p>&nbsp;</p><p>飞诺门阵代表表示，统一的技术和产品标准、数据产权的明确划分，能够有效避免数据资产的浪费，是充分激活数据要素潜能的基础。</p><p>&nbsp;</p><p>华录光存储研究院代表指出，硬件基础+软件应用，将是数据资产升级为数据要素的重要基础。</p><p>&nbsp;</p><p>柏睿数据副总裁李远志指出，柏睿数据全新数据智能产品矩阵建立了从数据管理到数据分析的完整产品体系，其中数据分析是数据要素的生产过程，是用户完成数据资产价值兑现的必由之路。</p><p>&nbsp;</p><p>国信优易代表指出，未来国家数据局的组建，将为大数据企业提供更加明确的发展路径和发展依据，加速数字中国高质量发展。</p>",
    "publish_time": "2023-03-17 14:46:23",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Docker正在淘汰开源组织，CTO硬刚开发者，网友：想赚钱可以，但沟通方式烂透了",
    "url": "https://www.infoq.cn/article/8lGiLHiAfbyateIF9Blr",
    "summary": "<p></p><h2>事件回顾</h2><p></p><p>&nbsp;</p><p>当地时间3月15日，Docker向所有 Free Team 的 Docker Hub 用户发送了一封<a href=\"https://github.com/docker/hub-feedback/issues/2314#issuecomment-1468574145\">电子邮件</a>\"，声称如果未来一个月内没有升级到付费团队，他们的帐户就会被删除，包括所有镜像。任何受影响组织的“订阅”栏都被标记为“Docker Free Team”。</p><p>&nbsp;</p><p>邮件大意：</p><p>&nbsp;</p><p></p><blockquote>Docker 正在淘汰 Free Team组织，因为该免费功能与付费的 Docker Team 订阅有很多相同的特性、费率和功能。&nbsp;如果您使用的是旧版 Free Team组织，则将于 2023 年 4 月 14 日（UTC 时间晚上 11:59）暂停访问一切付费功能（包括私有存储库）。需要在 2023 年 4 月 14 日之前升级订阅，才能继续访问您的组织。&nbsp;如果您不升级到付费订阅，Docker 将保留您的组织数据 30 天，之后将其删除。在此期间会保留你对公共存储库的访问权限，但将进行速率限制。&nbsp;如果您升级到付费订阅，则可以在 30 天内的任何时候恢复对组织帐户的访问权限。</blockquote><p></p><p>&nbsp;</p><p>这一决定引发了遗留 Free Team 组织的用户不满。网友“josegonzalez”表示，目前为止，这件事情的惊人之处在于电子邮件没有表明：</p><p>&nbsp;</p><p>如果没有付费，团队会得到什么后果在什么时间、具体什么内容会被删掉组织账户被删除后，其他人是否可以复制这些镜像OSS组织拥有组织账户该怎么办，他们还不存在中心计费的情况(相当常见)如何更好地将机器人用户作为付费团队的一部分</p><p>&nbsp;</p><p>“我了解这件事的唯一方法是查看我的电子邮件——我很快去看了他们的博客，但没有找到与这封电子邮件相关的任何内容。”josegonzalez说道，“如果有的话，我想将我的团队（dokku 和 gliderlabs）转换为单一帐户，但似乎没有办法做到这一点。”</p><p>&nbsp;</p><p>“我知道公司盈利是必要的，但可能花 5 分钟以上的时间来制作电子邮件并为您的用户考虑下结果（他们已经对您的定价变化感到生气）并不费力。现在这样只会让我觉得我应该将我的主机转移到付费的东西（ECR？）、删除账户，然后对镜像做URL劫持。”josegonzalez补充道。</p><p>&nbsp;</p><p>在社区开发者对于Docker的行为群雄激愤之际，公司 CTO Justin Cormack在Twitter上回复网友问题时却表现出了强硬态度，他表示Docker会关闭不付费的账户，而且不允许任何其他人接管账户。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/ac/acd9af48e05ade69957e3bd010cffa9c.png\" /></p><p></p><p>&nbsp;当地时间3月16日，随着社区“声讨”之声越来越大，Docker终究顶不住压力在主页发布了另外一篇<a href=\"https://www.docker.com/blog/we-apologize-we-did-a-terrible-job-announcing-the-end-of-docker-free-teams/\">公告</a>\"，为结束Free Team 时采取的不当方式道歉。</p><p>&nbsp;</p><p>Docker表示，他们此举仅影响了不到2%的社区内的活跃组织账户。其他服务包括Docker Personal、Docker Pro、Docker Team 或 Docker Business 帐户、Docker-Sponsored Open Source成员、Docker Verified Publishers或Docker Official Images将不会受到影响。&nbsp;</p><p>&nbsp;</p><p>对于Free Team 订阅被弃用的原因，Docker解释称：“部分原因是它的针对性很差。特别是，它没有像我们最近更新的 Docker-Sponsored开源项目那样为开源受众服务，后者提供的好处超过了已弃用的 Free Team 订阅”。</p><p>&nbsp;</p><p>此外，Docker还澄清一点——只有当维护者决定删除公共镜像时，它们才会从 Docker Hub 中删除，很抱歉在最初的沟通中他们未能明确说明这一点。</p><p>&nbsp;</p><p>值得一提的是，截至发稿时，InfoQ再次访问Justin Twitter主页时，发现上述Twitter回复已不见踪影。</p><p></p><h2>清退开源组织，对开发者有什么影响？</h2><p></p><p>&nbsp;</p><p>在Docker做出此更改后，如果开发者不付钱升级服务，那么很多免费用户的系统就会崩溃。</p><p>&nbsp;</p><p>不过，Docker 团队也给出了一个针对开源项目的特定 DSOS 程序，只要成为DSOS 的用户，那么Docker将继续为开源项⽬提供特定的 Docker-Sponsored Open Source (DSOS) 程序，并且不受 Free Team 组织停⽤的影响。</p><p>&nbsp;</p><p>Docker 表示，对于有兴趣从以前 Free Team 组织加⼊ DSOS 的用户，其将在 DSOS 申请审核期间推迟任何组织暂停或删除，如果申请最终被拒绝，Docker也将在暂停组织账户前⾄少给出 30 天的处理时间。但有开发者反映2021年7月的申请至今没有得到通过。</p><p>&nbsp;</p><p><a href=\"https://github.com/odpi/egeria/issues/7530#issue-1623820321]%20and%20Kind%20[https://github.com/kubernetes-sigs/kind/issues/3124\">Egeria</a>\"（开放元数据标准）、 Kind（使用容器进行 Kubernetes 测试）等开源项目被迫在短时间内<a href=\"https://github.com/kubernetes-sigs/kind/issues/3124\">做出响应。</a>\"</p><p>&nbsp;</p><p>AIUI Kubernetes项目维护者Benjamin Elder表示他们已经接到通知，必须在4月14日之前解决这个问题。目前他们依赖于kindest/组织。</p><p>&nbsp;</p><p>AIUI Kubernetes 项目此前拒绝加入 OSS 计划，目前尚不清楚 KIND 是否会自行同意。</p><p>&nbsp;</p><p>Benjamin Elder表示：虽然他们可以离开 Docker hub，但这还将带来其他影响：</p><p>&nbsp;</p><p>用户已经在各个地方的管道中依赖这些镜像，如果只是镜像/迁移他们将没有太多时间来切换；Dockerd 仍然只支持镜像 Docker hub，因此对于无法访问上游的用户来说会有些困难；</p><p></p><p>“如果不采取任何行动，人们的 CI 管道就会被破坏，因为旧镜像将在 Docker hub 上不可用（至少不在同一位置）。成为付费团队的成本是每年 300 美元，”&nbsp;GitHub 上 Mamba 开源包管理器的维护者<a href=\"https://github.com/mamba-org/micromamba-docker/issues/276\">说。</a>\"</p><p>&nbsp;</p><p>对于未付费的公司使用者来说，Docker此举对公司带来了诸多不可控的风险。</p><p>&nbsp;</p><p>Dbingham是一名SRE经理，他们公司主要依赖于相对较大的组织（`alpine`、`node`、`golang` 等）的镜像，但依赖的这些镜像可能会消失。人们认为相信Docker吧，不会出问题的——这些镜像要么在开源程序中，要么支付了费用就还会有。但Dbingham表示他还是无法安心。如果这些镜像消失了，他们就没办法发布了，这是不可接受的。他们没办法查看哪些组织付了款，哪些没有，哪些是开源计划的成员，哪些不是。甚至无法判断哪些镜像可能存在风险。因此，Dbingham强调，“30 天的时间不足以找到替代方案和迁移。”</p><p>&nbsp;</p><p>Docker的做法，除了逼得免费用户不得不离开外，也损失了不少付费用户。</p><p>&nbsp;</p><p>有付费网友公然表示：</p><p>&nbsp;</p><p></p><blockquote>我在 Docker Hub 上有两个组织，一个是为我公司的产品和服务的私有图像付费的，另一个是我们维护并提供给社区的免费图像的组织。通过此更改，我们必须将免费组织转移到其他地方……我们既然能迁走免费组织，当然也可以迁走付费组织。所以现在他们正在损失收入，因为我不想在两个不同的平台上分配我的东西。我们将迁移到一个新的注册中心，该注册中心也将获得我们的付费团队。</blockquote><p></p><p>&nbsp;</p><p>对于开源维护者来说，Docker的做法也让人寒心。组织托管公共镜像的成本从免费增长至420 美元/年。多年以来，很多开源项目一直在以这种方式向 Docker Hub 发布镜像，OpenSaaS 最早可以追溯到 2016 年。OpenSaaS 项目如今虽然将免费的社区版镜像发布至 GitHub 的 Container Registry，但仍有很多用户在继续使用 Docker Hub 上的几千种旧镜像。</p><p>&nbsp;</p><p>Docker 制定的开源计划意味着除了业余项目和完全被捐赠给开源基金会的项目，任何其他项目都得向 Docker 交钱。</p><p>&nbsp;</p><p>还有开发者表示：“如果有针对小型开发商的额外计划将会非常感谢。强迫我们为每月5个用户花掉300美元的最低费用，这是很过分的。为什么不能是每月1个用户最低5美元?那会让我留下来，否则就搬到 GitHub Container Registry（GitHub 镜像仓库）。”</p><p>&nbsp;</p><p>可见，无论是对于公司使用者、个人使用者、Docker开源项目维护者、付费使用者还是免费使用者，Docker的这一决定都或多或少带来了一些影响。</p><p></p><h2>Docker态度放软后，网友不买账并质疑声明前后矛盾</h2><p></p><p>&nbsp;</p><p>在Docker最初发给开发者的结束Free Team的邮件中，Docker称如果用户不升级到付费订阅，Docker 将保留用户的组织数据 30 天，之后将被删除。在此期间，用户可以继续访问自己的任何公共镜像。</p><p>&nbsp;</p><p>但Docker在最新的相关声明中却澄清道，只有当维护者决定删除公共镜像时，他们才会从 Docker Hub 中删除。</p><p>&nbsp;</p><p>到底是30天后删除数据？还是用户同意后再删除数据而不受时间限制？</p><p>&nbsp;</p><p>这样前后明显矛盾的表述又再次引来网友质疑，并且有网友表示Docker团队可能改变了实际策略，避重就轻，不再围绕着这些数据是否被删的问题打转。</p><p>&nbsp;</p><p>鉴于这些陈述相互矛盾的问题，Docker DevRel 团队给出了回复：</p><p>&nbsp;</p><p></p><blockquote>其实这并不矛盾。组织数据将保留 30 天，并可能会被删除。这些可能被删除的数据包括团队、会员资格等。但是，我们不清楚我们将如何处理这些镜像。保留公共镜像很重要，因为许多其他镜像都建立在它们之上。</blockquote><p></p><p>&nbsp;</p><p>此外，关于网友提到的转变策略问题，Docker DevRel的解释是：</p><p>&nbsp;</p><p></p><blockquote>之前没有想到大家会如此关心镜像问题，所以根本没有谈论这个问题。在得到了社区反馈后，我们认识到了这一点，所以想把它说清楚。</blockquote><p></p><p>&nbsp;</p><p>但这些回复和解释并没有浇灭网友的怒火。</p><p>&nbsp;</p><p>事实上，网友们还是会认为在规定的30天到期后，Docker就会不允许用户再提取镜像，即便允许访问镜像但不允许做任何删改也是件很糟糕的事儿，仅比删除镜像能好一点点。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://web.docker.com/rs/790-SSB-375/images/privatereposfaq.pdf\">https://web.docker.com/rs/790-SSB-375/images/privatereposfaq.pdf</a>\"</p><p><a href=\"https://mp.weixin.qq.com/s/iurQPG8ROswy5mYrLFTbVw\">https://mp.weixin.qq.com/s/iurQPG8ROswy5mYrLFTbVw</a>\"</p><p><a href=\"https://twitter.com/BenTheElder/status/1479592601938317314\">https://twitter.com/BenTheElder/status/1479592601938317314</a>\"</p><p><a href=\"https://news.ycombinator.com/item?id=35187250\">https://news.ycombinator.com/item?id=35187250</a>\"</p>",
    "publish_time": "2023-03-17 17:17:32",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "备受云厂商们推崇的 Serverless，现在究竟发展到什么水平了？",
    "url": "https://www.infoq.cn/article/vHCG1pJpsLapBBMvbvZM",
    "summary": "<p></p><p></p><h2>Serverless是什么</h2><p></p><p></p><p>根据CNCF的定义，Serverless的概念是指构建和运行不需要服务器管理的应用程序。它描述了一种更细粒度的部署模型，在该模型中，应用程序被捆绑为一个或多个功能，被上传到一个平台，然后根据当前所需的确切需求执行、扩展和计费。</p><p></p><p>所以首先需要明确的一点是，Serverless并非指托管和运行我们的应用程序不再需要服务器，而是指从前耗费研发和运维人员无数精力和资源的CI/CD、服务器配置维护更新、IT资源容量的规划和伸缩等工作，被Serverless这个概念下包含的技术体系所封装了。研发专注于业务逻辑的编写，运维向SRE转型，负责技术SLA的制定和保障工作。这也是技术体系又一维度的分层体现（其它类比汇编语言和高级语言，OS和应用软件）。</p><p></p><h2>Serverless发展历程</h2><p></p><p></p><h3>什么背景下诞生了Serverless</h3><p></p><p></p><p>Serverless所指向的基础设施架构，历史上经历了多次的迭代：从早期的MVC（模型-试图-控制器）为主的单体形式，到后来的SOA，再到最近十年兴起的微服务架构和云原生。整个基础支撑功能是逐步在拆分解耦，以垂直提升研发和运维效率。横向分层上，虚拟化技术打通了物理资源的隔阂，减轻了用户管理基础架构的负担。容器/PaaS 平台则进一步抽象，提供了应用的依赖服务、运行环境和底层所需的计算资源。这使得应用的开发、部署和运维的整体效率再度提升。在这样的背景下，Serverless其实代表了一种更彻底的屏蔽与分层，将应用架构堆栈中的各类资源的管理全部委托给平台，免去基础设施的运维，使用户能够聚焦高价值的业务领域，进一步提高软件应用和运营的生产力。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/c4/80/c497383050fe0350d1248e31yyf3ae80.png\" /></p><p></p><p>                                         图1：应用架构与计算抽象的演进示意图</p><p></p><h3>发展大事记                               </h3><p></p><p>2006 年，伦敦的一家公司发布了名为 Zimki 的平台，该平台提供了端到端的 JavaScript 开发能力，并且最早提出了“Pay as you go”的概念，但在商业上并未取得显著成功。2008 年，谷歌发布 App Engine 服务，用户的开发方式得到了根本的变革，无须考虑预分配多少资源，也无须考虑操作系统的实现。2012 年，Ken Fromm 在《软件和应用的未来是 Serverless》中率先提出了Serverless的概念。2014 年，AWS 重磅发布函数计算产品 Lambda，开启了Serverless架构的新时代。            2016 年，Azure Function、GCP（Google Cloud Platform）以及 IBM Open Whisk 相继发布 Serverless 计算平台。2017 年，腾讯云和阿里云先后发布了 Serverless 计算产品——云函数和函数计算；同年，谷歌 GCP 发布了 Firebase 产品，提供多端一体化开发的 Serverless 解决方案。2018 年，谷歌开源 Knative，尝试将Serverless架构标准化。同年，全球知名 IT 咨询调研机构 Gartner 发布报告，将 Serverless 架构列为十大未来将影响基础设施和运维的技术趋势之一。2019 年，腾讯云和 Serverless.com 达成战略合作，共同开发 Serverless Framework 产品，提供 Serverless 开发的一站式解决方案；Microsoft Azure 也于 2019 年推出了 Azure Functions。2020年，Google Cloud推出Cloud Run 服务，AWS Lambda 支持 Ruby等更多语言。2021 年，AWS Lambda 引入新的 Lambda Edge 服务，它可以将内容置于全球 CDN 网络上，从而提供快速和可靠的服务2022年，阿里云宣布核心产品全面Serverless化。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/45/bc/459aa2bced1292b4b4e0ac26970740bc.png\" /></p><p></p><p></p><h3>模型架构及原语                              </h3><p></p><p></p><p>Serverless是一种“全托管”的架构理念，包括两个核心特征：一是按实际使用量付费，类似“电网”模式，按请求调用次数或是实际数据存储量，用多少付多少；二是自适应弹性、免运维。根据使用情况，云产品对底层资源进行自动伸缩，客户不需要提前预购资源，用完即回收。</p><p></p><p>Serverless将提供服务资源的基础设施抽象成各种服务，以 API 接口的方式供给用户按需调用，真正做到按需伸缩、按使用收费。这种架构体系结构消除了对传统的海量持续在线服务器组件的需求，降低了开发和运维的复杂性，降低运营成本并缩短了业务系统的交付周期，使得用户能够专注在价值密度更高的业务逻辑的开发上。</p><p></p><p>目前业界较为公认的Serverless架构主要包含两个方面，即提供计算资源的函数服务平台 FaaS和提供托管云服务的后端服务 BaaS。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/24/aa/248da3ba76428eb5c4bb889d56fe4faa.png\" /></p><p></p><h4>函数即服务 (Function as a Service)       </h4><p></p><p>                    </p><p>函数即服务是一项基于事件驱动的函数托管计算服务。通过函数服务，开发者只需编写业务函数代码并设置运行的条件，无需配置和管理服务器等基础设施。函数代码运行在无状态的容器中，由事件触发且短暂易失，并完全由第三方管理，基础设施对应用开发者完全透明。函数以弹性、高可靠的方式运行，并且按实际执行资源计费，如不执行则不产生费用。典型代表有 AWS Lambda、Azure Functions、Google Cloud Functions和OpenFaaS。</p><p></p><p>但现阶段函数即服务的局限性也较为明显。首先，代码调试较为复杂。FaaS 平台的代码调试大多需要下载到本地，调试成功后上传至函数，在线调试工具功能尚不完善，调试的复杂度较高。其次，低延时业务暂不适用。FaaS 中的代码通过事件触发，如果执行结束一段时间没有再次触发，执行函数的容器会销毁，再次启动会有启动的开销，增加启动延迟，所以目前不适用低延迟的业务，如金融交易等。 </p><p></p><h4>后端即服务 (Backend as a Service)   </h4><p></p><p>                               </p><p>BaaS 的概念涵盖范围较广，覆盖了应用有可能依赖的所有第三方服务，如云数据库、身份验证 (如 Auth0、AWS Cognito)、对象存储等服务，开发人员通过 API 和由 BaaS 服务商提供的 SDK，能够集成所需的所有后端功能，而无需构建后端应用，更不必管理虚拟机或容器等基础设施，就能保证应用的正常运行。 典型产品有APICloud、Bmob、友盟等。   </p><p>              </p><p>目前常见的 BaaS 服务包括数据库管理、云存储、用户认证、推送通知、远程更新、消息队列。</p><p></p><h2>Serverless行业生态现状                         </h2><p></p><p>         </p><p>目前 Serverless 的技术生态主要活跃在公有云的云函数服务领域，国内外主要云服务商都具备云函数产品。这主要是因为公有云的云函数服务拥有一系列完善的云计算资源，这使得 Serverless 能够更快地开发和部署应用程序。而且，公有云还提供了完整的安全体系，可以确保 Serverless 技术的安全性。此外，公有云的云函数服务也能够提供便捷的数据存储和管理，从而使 Serverless 应用更便捷、更高效。公有云服务基本可满足用户Serverless应用的搭建需求。私有云的解决方案领域仍旧以国外开源技术为主。                             </p><p></p><p>工具层来看，独立 BaaS 服务（开源、商业产品）主要由国外服务商提供，国内服务商提供的相关工具主要供给各自产品使用，普适多云平台的工具产品多集中在开发框架层面。 </p><p></p><h3>平台层                      </h3><p></p><p>       </p><p>平台层提供全托管的运行环境，提供函数单元所需的计算环境并自行维护服务器资源、网络资源、消息分发和负载均衡等功能，是整个Serverless 架构的基础。     </p><p>                                    </p><p>国内主要公有云服务商均已推出云函数产品，开源的Serverless架构框架也层出不穷，下文将选取较为典型的几个平台进行介绍。</p><p></p><h4>公有云函数计算服务</h4><p></p><p></p><h5>阿里云函数计算</h5><p></p><p></p><p>事件驱动的全托管计算服务。通过函数计算，无需管理服务器等基础设施，只需编写代码并上传。函数计算会准备好计算资源，以弹性、可靠的方式运行代码，并提供日志查询、性能监控、报警等功能。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/6d/bb/6dcb294c65575401466c97bcef6de6bb.png\" /></p><p>                                                     阿里云函数计算工作流程示意图 </p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/83/c7/83b09de3667047963b82c1450d9e6ec7.png\" /></p><p>阿里云函数计算在视频解码场景中的流程架构</p><p></p><h5>华为云函数工作流 (FunctionGraph)</h5><p></p><p></p><p>华为云提供的一款无服务器 (Serverless) 计算服务，无服务器计算是一种托管服务，服务提供商会实时为你分配充足的资源，而不需要预留专用的服务器或容量，真正按实际使用付费。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/c9/a2/c931cb9f1dde257e358a4a31ef87a4a2.png\" /></p><p>华为云函数工作流在实时数据流处理中的流程架构</p><p></p><h5>腾讯云</h5><p></p><p></p><p>腾讯云云函数（Serverless Cloud Function，SCF）是腾讯云为企业和开发者们提供的无服务器执行环境，帮助用户在无需购买和管理服务器的情况下运行代码，是实时文件处理和数据处理等场景下理想的计算平台。 用户只需使用 SCF 平台支持的语言编写核心代码并设置代码运行的条件，即可在腾讯云基础设施上弹性、安全地运行代码。</p><p><img src=\"https://static001.infoq.cn/resource/image/34/8c/344463ec3ff553396115926c19ee428c.png\" /></p><p></p><p>腾讯云云函数在移动及Web应用后端中的流程架构</p><p></p><h5>AWS</h5><p></p><p></p><p>AWS Lambda 是一项计算服务，帮助用户无需预配置或管理服务器即可运行代码。Lambda 在可用性高的计算基础设施上运行代码，执行计算资源的所有管理工作，其中包括服务器和操作系统维护、容量调配和弹性伸缩和记录。借助 Lambda，用户可以为几乎任何类型的应用程序或后端服务运行代码，用户只需要以 Lambda 支持的一种语言提供自己的代码。</p><p></p><p>用户可以将代码组织到 Lambda 函数。只有在需要时 Lambda 才运行用户的函数，并且能自动扩展，从每天几个请求扩展到每秒数千个请求。用户只需为消耗的计算时间付费，代码未运行时不产生费用。</p><p><img src=\"https://static001.infoq.cn/resource/image/15/9f/157d54d4a3af2b98458f86519f5cdb9f.png\" /></p><p></p><p>AWS Lambda在文件处理中的流程架构</p><p></p><h4>开源无服务器框架</h4><p></p><p></p><h5>Knative    </h5><p></p><p></p><p>Kubernetes 已经成为容器编排的事实标准。但是 Kubernetes 的定位是一个容器平台而不是代码平台。作为运行和管理容器的平台，Kubernetes 功能强大，但是这些容器是如何构建、运行、扩展和路由，很大程度上是由用户自己决定。Knative基于 Kubernetes平台，是用来构建、部署和管理现代无服务器架构的工作负载的框架，它将云原生应用开发的三个领域的最佳实践结合起来，即构建容器（和函数）、为工作负载提供服务（和动态扩展）以及事件。Knative 是由谷歌与 Pivotal、IBM、Cisco、Red Hat 等云原生技术厂商紧密协作开发的。   </p><p></p><p>Knative 扩展了 Kubernetes，提供了一组中间件组件，它们对于构建现代、源码中心化以及基于容器的应用至关重要，这些应用可以运行在企业内部、云端或第三方数据中心中。  </p><p>Knative 构建在 Kubernetes 的基础上，为构建和部署Serverless架构和基于事件驱动的应用程序提供了一致的标准模式。Knative 减少了这种全新的软件开发方法所产生的开销，同时还把路由和事件的复杂性抽象出来。</p><p><img src=\"https://static001.infoq.cn/resource/image/d8/b4/d85dyy370ed9d1a1e085d1482751a1b4.png\" /></p><p></p><h5>Apache OpenWhisk</h5><p></p><p></p><p>Apache OpenWhisk 是一个开源的分布式无服务器平台，可以执行函数以响应任何规模的事件。OpenWhisk 使用 Docker 容器管理基础架构、服务器和扩展，因此用户可以专注于构建出色且高效的应用程序。</p><p></p><p>OpenWhisk 平台支持一种编程模型，在该模型中，开发人员可以使用任何支持的编程语言编写功能逻辑（称为Actions），这些逻辑可以动态调度和运行以响应来自外部源（Feeds）或 HTTP 请求的关联事件（通过触发器）。该项目包括一个基于 REST API 的命令行界面 (CLI) 以及其他工具来支持打包、目录服务和许多流行的容器部署选项。</p><p></p><h5>Riff Project                                   </h5><p></p><p></p><p>Riff 是与 Knative 紧密相关的一个项目，主要贡献者为 Pivotal 和 Google 公司。Riff CLI 帮助开发人员使用Knative 构建和运行函数。Riff 包括在 Kubernetes 集群中安装 Knative 以及管理函数、服务、通道和订阅的命令。Riff 允许开发人员编写响应事件的函数。函数被部署为 Kubernetes pods，其中包含自定义函数的特定语言调用程序，以及用于在函数范围内外获取数据的 I/O bound Sidecar。SideCar 负责读/写消息主题，并使用参数分派调用程序。</p><p></p><p>Riff 使用自定义资源定义来枚举 Kubernetes 中的函数和主题。此外，它还部署了一对控制器盒来管理这些资源——主题和功能控制器。主题控制器使用基础事件代理处理主题状态更改。功能控制器监听主题事件并管理功能部署、销毁和扩展需求，包括：Riff CLI 安装Knative 和使用 Knative serving 基于 Kaniko-based 集群的 builds、developer workflow 等等。</p><p></p><h2>生态工具链</h2><p></p><p></p><h3>应用框架                               </h3><p></p><p></p><h5>蚂蚁金服 SOFAStack</h5><p></p><p></p><p>SOFAStack 是蚂蚁金服自主研发的分布式中间件，为用户提供安全、稳定、可靠、高效、敏捷的基础架构能力，用于打造大规模高可用的分布式系统架构。SOFAStack 以轻量级服务框架为基础，兼容Spring Boot、Spring Cloud、Dubbo工程，提供应用中心、微服 务、消息队列、数据访问代理、分布式链路跟踪、分布式事务、Serverless 等服务。   </p><p>               </p><p>蚂蚁金服的 Serverless 服务配备文件储存、数据储存、服务托管和函数计算等诸多能力。文件储存方面，Serverless 平台为开发者提供了基于 CDN 的文件 BaaS 服务，开发者只需将文件通过接口上传，即可直接享受到 CDN 的能力，为文件带来最佳的访问性能以及海量的访问量。数据储存方面，用户可以通过客户端的 SDK 操作数据库里的数据，无需服务端参与，即可完成数据的存取操作。通过服务托管，开发者无需再关心底层环境、后端运维的各种细节。开发者只需将业务代码提交到云端即可。通过函数计算，开发者可以将原有的复杂计算逻辑拆分为多个计算函数，然后通过事件或者 HTTP 方式串接起计算业务，在实现对业务解耦的同时，减少对后端资源成本的依赖。        </p><p></p><h5>腾讯云Serverless框架 </h5><p></p><p></p><p>TCSAM 是用于在腾讯云上定义 Serverless 应用的模型。基于 TCSAM，腾讯云提供了 TCF 命令行工具，用于云函数的管理和部署。</p><p></p><p>TCF全称为 Tencent Cloud Function，是腾讯云Serverless云函数 SCF (Serverless Cloud Function) 产品的命令行工具。通过 TCF 命令行工具，用户可以方便地实现函数打包、部署、本地调试，也可以方便地生成云函数的项目并基于 demo 项目进行进一步开发。</p><p></p><p>TCF 通过 TCSAM 规范的模板配置文件，完成函数及相关周边资源的描述，并基于配置文件实现本地代码及配置部署到云端的过程。同时，TCF 命令行工具提供本地事件模拟、本地调试等用于调试的相关功能，方便用户进行本地调试及测试。TCF 还提供了通过使用命令行工具将函数的管理、测试、部署、发布对接到持续集成及持续发布流程中的能力。</p><p></p><h4>可视化</h4><p></p><p></p><p>无服务架构的应用通常会部署成百上千个函数，访问调用的复杂性急剧上升。通过监控/可视化工具，可帮助用户或运维人员监测链路状态，掌握函数运行状态，快速定位问题源头。</p><p></p><h4>Grafana </h4><p></p><p>Grafana 是一个跨平台的开源的度量分析和可视化工具，可以通过将采集的数据查询然后可视化展示，并对监测指标做告警通知，常用于对基础设施和应用程序分析的时间序列数据进行可视化。Grafana 搭载后端的 Prometheus 数据源，可以为多种开源 Serverless 框架构建函数计算监测平台。</p><p></p><h4>测试                                    </h4><p></p><p></p><p>由于公有云的函数服务没有开发环境，开发人员必须运行函数查看它们真实的运行情况，因此创建模拟测试环境并用于代码调试的工具变得非常必要。</p><p></p><h5>华为云函数服务 Serverless Sandbox (HSS)                                          </h5><p></p><p>用户开发的函数在部署到华为云之前，可以使用华为云 Serverless Sandbox (HSS) 在本地开发和测试 Serverless 应用。该工具可以用来在本地测试函数功能，验证华为Serverless应用模型 (HSAM)，并为各种事件源本地生成样本有效载荷；提供了丰富的cloud event 命令，可以将来自华为云服务的事件直接路由到本地环境来调试本地函数功能。                                        </p><p></p><h5>百度云 CFC BSAM 工具</h5><p></p><p></p><p>BSAM CLI是一个基于BCE SAM规范的命令行工具，它提供了本地开发环境，帮助用户在把函数上传到百度云 CFC 之前，在本地进行函数的开发、分析和执行。</p><p></p><h4>CI/CD                             </h4><p></p><p>函数应用跨区域移植部署的配置非常繁琐，极易出问题。能够将应用的配置描述分离，复用给多个应用可以大大简化移植部署的难度。</p><p></p><h5>阿里云 Fun 2.0 </h5><p></p><p>阿里云 Fun 2.0 是一款 Serverless 应用开发的工具，可以帮助用户定义函数计算、API 网关、日志服务等资源。Fun 2.0 引入了全新设计的 Serverless Application Model (SAM) 规范。</p><p></p><p>SAM 作为一种基础设施即代码 (Infrastructure as Code)，允许用户描述函数计算及其相关云资源。用户可以使用同一份模板文件，跨 region 或者账户部署云应用。描述云资源的模板文件，也会成为项目代码的一部分，在不同开发者之间共享。这极大地降低了 Serverless 应用的交付难度、管理难度、移植难度。除了1.0版本支持的函数、API 网关的配置，2.0 还有以下功能更新：</p><p></p><p>增强了对函数的描述能力：环境变量、日志服务、角色属性、VPC 属性等。支持配置新的应用资源，比如 Table Store、日志服务等。代码上传可以指定文件、目录、压缩包以及 OSS 路径。更多的 API 网关参数配置。</p><p></p><h2>Serverless的适用场景</h2><p></p><p></p><p>当前阶段，结合Serverless架构的基于事件驱动、应用代码动态部署、完全动态地进行大规模资源扩缩等特点，可以把Serverless架构的适用场景分为下面几类：</p><p></p><h3>基于时间的内容处理应用                                         </h3><p></p><p></p><h4>实时文件处理 </h4><p></p><p></p><p>有些应用会根据不同的应用需求将图片裁剪成不同尺寸，或添加不同的标签水印。视频类的应用会将视频流转码成不同的清晰度推送给不同服务。当图片或者视频流通过对象存储上传时便会触发相应的函数计算，根据计算规则自动按需处理，整个过程无需再搭建额外服务器，也无需人工干预。                        </p><p></p><h4>定制事件触发 </h4><p></p><p></p><p>以用户注册时发邮件验证邮箱地址的场景举例，可以通过定制的事件来触发后续的注册流程，而无需再配置额外的应用Serverless来处理后续的请求。                      </p><p></p><h3>大规模数据处理和计算类 </h3><p></p><p></p><h4>人工智能推理预测 </h4><p></p><p></p><p>人工智能推理预测的调用需求会随着业务的起伏而变化，具有一定的波动性，这和人工智能训练时的较固定计算周期和运行时长有所不同。同时 AI 推理一般会使用 GPU 加速，这种明显的峰值变化会导致大量的资源浪费。使用Serverless架构技术可以有效解决上述问题。高业务请求到来时，云函数的执行实例自动扩容，满足业务需求；而在请求低谷或无请求到来时，云函数自动缩容甚至完全停止，节省资源使用。</p><p></p><h4>批处理或计划任务 </h4><p></p><p></p><p>每天只需短期运行就能以异步计算的方式进行强大的并行计算能力，I/O 或网络访问的任务非常适合Serverless架构。这些任务可以以弹性方式运行时消费所需的资源，并且，在不被使用的当天剩余时间内，不消耗资源成本。典型场景有定期的数据备份等。                                         </p><p></p><h3>轻后端服务 </h3><p></p><p></p><p>通过将Serverless云函数和其他云服务紧密结合，开发者能够构建可弹性扩展的移动或 Web 应用程序，轻松创建丰富的Serverless后端，而且这些程序可在多个数据中心高可用运行，无需在可扩展性、备份冗余方面执行任何管理工作。</p><p></p><h4>移动应用</h4><p></p><p></p><p>使用Serverless架构技术构建移动后端服务是非常常用的场景。开发人员可基于云平台的后端服务来构建应用，这使得开发人员可以更加专注在移动应用的优化上，只要按需选择云服务商提供的丰富的后端服务即可。典型案例有微信小程序的开发等。                                      </p><p></p><h4>IoT</h4><p></p><p></p><p>物联网的应用场景中，设备传输数据量小，且往往是以固定时间间隔进行数据传输，数据传输存在明显的波峰波谷特征。数据传输的波峰时段触发后端函数服务集中处理，处理结束后快速释放，提升资源的利用效率。</p><p></p><h2>Serverless典型落地案例</h2><p></p><p></p><h3>高德出行</h3><p></p><p></p><p>高德是中国领先的数字地图内容、导航和位置服务解决方案提供商。自主出行是高德地图的核心业务，涉及到用户出行相关的功能诉求，承载了高德地图 APP 内最大的用户流量。自主出行核心业务中应用 Node FaaS 的部分场景包括主图场景页、路线规划页和导航结束页等。</p><p></p><p>此场景类型属于无状态服务，基于阿里云 Serverless 成熟的生态，高德最终选择接入 Node FaaS（阿里云函数计算）服务能力，出行前端搭建了场景推荐卡片服务。卡片的 UI 模版获取、数据请求聚合&amp;逻辑处理、拼接生成 Schema 的能力均在 FaaS 层得到实现，客户端根据服务下发的 Schema 直接渲染展示，达到更加轻便灵活的目标。在“十一出行节”峰值场景中，Serverless 整体服务成功率均大于99.99% ，总计100W+ 次触发/分钟，数十万QPS，各场景的服务平均响应时间均在 60ms 以下，服务稳定性超出预期。</p><p><img src=\"https://static001.infoq.cn/resource/image/08/82/08f139be1672564874a1b9380c71b182.png\" /></p><p></p><p></p><h3>支付宝小程序                </h3><p></p><p></p><p>传统模式下，小程序开发遭遇挑战。在传统模式中，程序员开发一个小程序的时候，依旧需要采用像开发传统 APP 一样的方式进行业务开发。在整体业务开发中，需要前端开发、后台开发、运维人员、安全人员等多个角色的协同，导致人力成本和资源成本高昂，不利于小程序的开发。   </p><p>                      </p><p>蚂蚁金服采用 Serverless 模式这种更高效的研发方式来实现小程序的快速布局。基于蚂蚁的 Serverless 产品 Basement，可以用更高效、简单的方式快速实现稳定、可靠的小程序后台服务。Basement 的技术架构如下图所示：</p><p><img src=\"https://static001.infoq.cn/resource/image/9d/b5/9d44ae3772bfd16106f956c363c25cb5.png\" /></p><p></p><p>蚂蚁金融云 Serverless 应用服务 (SAS) 和函数计算共同组成了小程序 Serverless 的后端解决方案。SAS 提供的关键后端能力包括：</p><p></p><p>1)  稳定的 Serverless 服务引擎：提供了服务所在集群的运行状态和日志等基本信息。</p><p>2)  丰富的应用服务能力：支持从镜像、代码包等方式多维部署应用。</p><p>3)  灵活的触发器配置：提供基于事件、定时任务和网络访问等方式的触发器配置以及弹性伸缩策略。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/c9/50/c999672b5b0be241601d522f0be1fd50.png\" /></p><p></p><p>支付宝小程序 Serverless 模式带来的优势显而易见：</p><p></p><p>1)  研发效率提升：实现了复杂底层逻辑的托管，用户只需完成自己业务逻辑的开发即可，开发时间大大缩短，研发效率大大提升。</p><p>2)  高可用的服务能力：支持了同城多机房的容灾能力，所有服务的数据都会进行多机房的互备，同时在应用层提供动态切换能力，可以保障服务高可靠性和业务高稳定性。</p><p>3)  专业的安全管控：为用户的服务提供了全方位的安全管控，包括流量防护、防火墙防护等接入层控制；涉黄、涉政、暴力等内容安全控制，保障数据不发生非法访问以及泄漏的访问控制。</p><p>4)  低成本：Serverless 模式下，人力投入成本低，资源成本低，收益高。</p><p>总体而言，Serverless 模式帮助支付宝提供可靠、稳定、安全的小程序服务，为开发者提供简单、高效的小程序开发方式。                                                                                                        </p><p></p><h3>美团Serverless前端体系</h3><p></p><p></p><p>美团早期业务快速发展，各业务在 Node 应用上各取所长，但在可用性和运维上需要付出额外的维护成本。随着美团建设了 Serverless 平台，前端也紧随其后，将 Node 应用由传统架构向 Serverless 架构演进，通过 Serverless 方式升级 Node 基础设施。</p><p></p><p>Serverless 前端主要包括研发套件、PaaS 平台、技术组件，以及业务层的解决方案。美团通过研发套件的建设和技术组件的建设来提升业务的开发效率，通过 PaaS 平台的建设来为业务提供服务的架构和稳定保障能力，同时 PaaS 的弹性特点可以很好地解决原来系统与部署的问题。Serverless 前端全景如下图所示：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/6a/b8/6a42979ea5affe9b09cc1321cc40d9b8.png\" /></p><p></p><p>对于云函数平台，美团大体上将其分为运行态和管理态。运行态要负责事件流转的过程。首先由触发源来产生事件，经过事件网关分发到具体业务实例当中的函数里去处理，业务函数会对事件做出处理和响应。事件网关除了分发流量之外，还会做一些限流降级、流量统计等相关的工作。实例这一层提供了函数沙箱，里面运行的是业务函数，对业务函数起隔离的作用。管理系统里提供函数的管理、发布以及监控等运维能力。</p><p></p><h2>Serverless的问题及发展趋势        </h2><p></p><p></p><h3>供应商锁定</h3><p></p><p></p><p>从一个供应商使用的任何无服务器功能将由另一个供应商以不同的方式实现。如果想更换供应商，几乎肯定用户需要更新操作工具（部署、监控等），可能需要更改代码（例如，以满足不同的 FaaS 接口），甚至如果竞争供应商实现的行为方式存在差异，则需要更改设计或架构。</p><p></p><p>即使设法轻松迁移了生态系统的一部分，也可能会受到另一个架构组件的更大影响。例如，假设正在使用 AWS Lambda 响应 AWS Kinesis 消息总线上的事件，虽然 AWS Lambda、 Google Cloud Functions 和 Microsoft Azure Functions 之间的差异可能相对较小，但仍然无法将后两个供应商实现直接连接到用户的 AWS Kinesis 流。这意味着如果不移动基础设施的其他部分，就不可能将代码从一个解决方案移动或移植到另一个解决方案。</p><p></p><p>为解决该问题，跨厂商的标准和模型互通成为未来趋势之一，即要向上标准化，屏蔽各个Serverless供应商的底层实现差异。</p><p></p><p>比如，AWS SAM (Serverless Application Model) 就是一个用于构建无服务器应用程序的开源框架。它提供简写语法来表达函数、API、数据库和事件源映射。每个资源只需几行就可以定义所需的应用程序并使用 YAML 对其建模。在部署期间，SAM 将 SAM 语法转换并扩展为 AWS CloudFormation 语法，使用者能够更快地构建无服务器应用程序。</p><p></p><h3>冷启动延时        </h3><p></p><p></p><p>在Serverless架构中，当一个函数没有被调用一段时间后，其资源被系统释放；等再次调用时，系统需要重新初始化资源，从而导致首次请求响应时间变长。同理，对于新到达的并发请求，会产生并发的冷启动问题。这是Serverless最被诟病的地方之一。    </p><p>                      </p><p>常规解决思路是热点函数预热，用类似LRU的方式保证大部分热点函数始终不会被驱离，资源不会被销毁，这其中体现的是性能和成本的折中和妥协。</p><p></p><p>一些前沿企业比如Amazon，引入KVM虚拟化技术，以microVM的思路，将容器启动速度及占用资源大大降低，并且针对主力语言比如Java的函数冷启动加载时间进行优化（最高可达90%的优化效果），从根本上解决冷启动问题，但是需要关注其可扩展性及平台绑定问题。</p><p></p><h3>函数生命周期有限，已加载状态无法复用 </h3><p></p><p></p><p>当前主流的 Serverless 平台对于函数的生命周期都有时间限制，函数不能长时间运行，只能在有限的时间执行，如 900s (15min)。当函数没有新的请求时，函数所在的执行环境被销毁，函数执行的中间状态、缓存等会被删除。当新的函数调用发起时，不能直接利用上次计算的缓存状态。</p><p></p><p>针对以上问题，有状态函数编程模型提供了方便的函数定义方式，以及语言无关的状态定义方式。由于不需要频繁地和外部存储进行交互，该模型减少了网络访问的次数，从而能够获得更低的时延。数据不需要分发到外部存储中，也不需要缓存到其它节点上，在可用性和一致性方面得到提升。由于用户请求与节点存在粘性连接，用户只需和一个函数实例发生交互，存取状态数据更为容易，通常只需要对函数中的一个简单结构体进行操作即可。</p><p></p><p>另外，由于FunctionGraph 服务接管了状态的管理，可以为用户提供多种数据一致性模型，以及处理并发场景下死锁的问题，从而使得编程模型更加容易理解、用户程序更加简洁。</p><p></p><h2>展望</h2><p></p><p></p><p>随着技术发展，云计算技术已经成为现代计算领域的新兴技术，而 Serverless 架构正是云计算技术的最新应用。根据Gartner的预测，全球Serverless架构市场的规模将在2024年达到1000亿美元。在技术发展方面，Serverless架构也将发展出新的功能和特性，从而更好地服务于开发者和企业。</p><p></p><p>作者介绍</p><p></p><p>舒超，前美团基础研发负责人，存储中心总架构师，负责美团公司级云原生服务治理系统的开发及演进；前腾讯微博微群及消息流广告负责人。目前任职星汉未来CTO。星汉未来是一家拥有先进云原生和 Serverless 能力的基础软件服务商，坚定相信 Serverless 是云计算的下一个型态，并将现有产品矩阵全面转向 Serverless。</p>",
    "publish_time": "2023-03-17 17:39:34",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "字节跳动开源dynamicgo ：基于原始字节流的高性能 + 动态化 Go 数据处理",
    "url": "https://www.infoq.cn/article/pjIHZCB7JOSfe1ZU6iQU",
    "summary": "<p></p><blockquote>仓库地址：https://github.com/cloudwego/dynamicgo</blockquote><p></p><p></p><h2>背景</h2><p></p><p></p><p>当前，Thrift 是字节内部主要使用的 RPC 序列化协议，在 CloudWeGo/Kitex 项目中优化和使用后，性能相比使用支持泛型编解码的协议如 JSON 有较大优势。但是在和业务团队进行深入合作优化的过程中，我们发现一些特殊业务场景并不能享受静态化代码生成所带来的高性能：</p><p></p><p>动态反射：动态地 读取、修改、裁剪 数据包中某些字段，如隐私合规场景中字段屏蔽；数据编排：组合多个子数据包进行 排序、过滤、位移、归并 等操作，如某些 BFF (Backend For Frontent) 服务；协议转换：作为代理将某种协议的数据转换另一种协议，如 http-rpc 协议转换网关；泛化调用：需要秒级热更新或迭代非常频繁的 RPC 服务，如大量 Kitex 泛化调用（generic-call）用户。</p><p></p><p>不难发现，这些业务场景都具有难以统一定义静态&nbsp;IDL的特点。即使可以通过分布式 sidecar 技术规避这个问题，也往往因为业务需要动态更新而放弃传统代码生成方式，诉诸某些自研或开源的 Thrift 泛型编解码库进行泛化 RPC 调用。</p><p></p><p>我们经过性能分析发现，目前这些库相比代码生成方式有巨大的性能下降。以字节某 BFF 服务为例，仅仅 Thrift 泛化调用产生的 CPU 开销占比就将近 40%，这几乎是正常 Thrift RPC 服务的4到8倍。因此，我们自研了一套能动态处理 RPC 数据（不需要代码生成）同时保证高性能的 Go 基础库 —— dynamicgo。</p><p></p><h2>设计与实现</h2><p></p><p></p><p>首先要搞清楚当前这些泛化调用库性能为什么差呢？其核心原因是：采用了某种低效泛型容器来承载中间处理过程中的数据（典型如 thrift-iterator 中的 map[string]interface{}）。众所周知，Go 的堆内存管理代价是极高的 （GC +heap bitmap），而采用 interface 不可避免会带来大量的内存分配。但实际上相当多的业务场景并不真正需要这些中间表示。比如 http-thrift API 网关中的纯协议转换场景，其本质诉求只是将 JSON（或其它协议）数据依据用户 IDL 转换为 Thrift 编码（反之亦然），完全可以基于输入的数据流逐字进行翻译。</p><p></p><p>同样，我们也统计了抖音某 BFF 服务中泛化调用的具体代码，发现真正需要进行读（Get）和写（Set）操作的字段占整个数据包字段不到5%，这种场景下完全可以对不需要的字段进行跳过（Skip）处理而不是反序列化。而 dynamicgo 的核心设计思想是：基于 原始字节流 和 动态类型描述 原地（in-place） 进行数据处理与转换。为此，我们针对不同的场景设计了不同的 API 去实现这个目标。</p><p></p><h4>动态反射</h4><p></p><p></p><p>对于 thrift 反射代理的使用场景，归纳起来有如下使用需求：</p><p></p><p>有一套完整结构自描述能力，可表达 scalar 数据类型， 也可表达嵌套结构的映射、序列等关系；支持增删查改（Get/Set/Index/Delete/Add）与遍历（ForEach）；保证数据可并发读，但是不需要支持并发写。等价于 map[string]interface{} 或 []interface{}</p><p>这里我们参考了 Go reflect 的设计思想，把通过IDL解析得到的准静态类型描述（只需跟随 IDL 更新一次）TypeDescriptor 和 原始数据单元 Node 打包成一个完全自描述的结构——Value，提供一套完整的反射 API。</p><p><code lang=\"null\">//&nbsp;IDL&nbsp;类型描述\ntype&nbsp;TypeDescriptor&nbsp;interface&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;Type()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Type&nbsp;//&nbsp;数据类型\n&nbsp;&nbsp;&nbsp;&nbsp;Name()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;string&nbsp;//&nbsp;类型名称\n&nbsp;&nbsp;&nbsp;&nbsp;Key()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*TypeDescriptor&nbsp;&nbsp;&nbsp;//&nbsp;for&nbsp;map&nbsp;key\n&nbsp;&nbsp;&nbsp;&nbsp;Elem()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*TypeDescriptor&nbsp;&nbsp;&nbsp;//&nbsp;for&nbsp;slice&nbsp;or&nbsp;map&nbsp;element\n&nbsp;&nbsp;&nbsp;&nbsp;Struct()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*StructDescriptor&nbsp;//&nbsp;for&nbsp;struct\n}\n//&nbsp;纯TLV数据单元\ntype&nbsp;Node&nbsp;struct&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;t&nbsp;Type&nbsp;//&nbsp;数据类型\n&nbsp;&nbsp;&nbsp;&nbsp;v&nbsp;unsafe.Pointer&nbsp;//&nbsp;buffer起始位置\n&nbsp;&nbsp;&nbsp;&nbsp;l&nbsp;int&nbsp;//&nbsp;数据单元长度\n}\n//&nbsp;Node&nbsp;+&nbsp;类型描述descriptor\ntype&nbsp;Value&nbsp;struct&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;Node\n&nbsp;&nbsp;&nbsp;&nbsp;Desc&nbsp;thrift.TypeDescriptor\n}</code></p><p></p><p>这样，只要保证 TypeDescriptor 包含的类型信息足够丰富，以及对应的 thrift 原始字节流处理逻辑足够健壮，甚至可以实现&nbsp;数据裁剪、聚合&nbsp;等各种复杂的业务场景。</p><p></p><h4>协议转换</h4><p></p><p></p><p>协议转换的过程可以通过有限状态机（FSM）来表达。以 JSON-&gt;Thrift 流程为例，其转换过程大致为：</p><p></p><p>预加载用户 IDL，转换为运行时的动态类型描述 TypeDescriptor；从输入字节流中读取一个 json 值，并判断其具体类型（object/array/string/number/bool/null)：如果是 object 类型，继续读取一个 key，再通过对应的 STRUCT 类型描述找到匹配字段的子类型描述；如果是 array 类型，递归查找类型描述的子元素类型描述；其它类型，直接使用当前类型描述。基于得到的动态类型描述信息，将该值转换为等价的 Thrift 字节，写入到输出字节流中 ；更新输入和输出字节流位置，跳回2进行循环处理，直到输入终止（EOF）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d6/d668409832ad76e8b6d9616d28bc5439.png\" /></p><p></p><p>整个过程可以完全做到 in-place 进行，仅需为输出字节流分配一次内存即可。</p><p></p><h4>数据编排</h4><p></p><p></p><p>与前面两个场景稍微有所不同，数据编排场景下可能涉及&nbsp;数据位置的改变（异构转换），并且往往会&nbsp;访问大量数据节点（最坏复杂度O(N) )。在与抖音隐私合规团队的合作研发中我们就发现了类似问题。它们的一个重要业务场景：要横向遍历某一个 array 的子节点，查找是否有违规数据并进行整行擦除。这种场景下，直接基于原始字节流进行查找和插入可能会带来大量重复的&nbsp;skip 定位、数据拷贝开销，最终导致性能劣化。</p><p></p><p>因此我们需要一种高效的反序列化（带有指针）结构表示来处理数据。根据以往经验，我们想到了&nbsp;DOM&nbsp;（Document Object Model）&nbsp;，这种结构被广泛运用在 JSON 的泛型解析场景中（如 rappidJSON、sonic/ast），并且性能相比 map+interface 泛型要好很多。</p><p></p><p>要用 DOM 来描述一个 Thrift 结构体，首先需要一个能准确描述数据节点之间的关系的定位方式&nbsp;—— Path。其类型应该包括 list index、map key 以及 struct field id等。</p><p></p><p><code lang=\"null\">type&nbsp;PathType&nbsp;uint8&nbsp;\n\nconst&nbsp;(\n&nbsp;&nbsp;&nbsp;&nbsp;PathFieldId&nbsp;PathType&nbsp;=&nbsp;1&nbsp;+&nbsp;iota&nbsp;//&nbsp;STRUCT下字段ID\n&nbsp;&nbsp;&nbsp;&nbsp;PathFieldName&nbsp;//&nbsp;STRUCT下字段名称\n&nbsp;&nbsp;&nbsp;&nbsp;PathIndex&nbsp;//&nbsp;SET/LIST下的序列号\n&nbsp;&nbsp;&nbsp;&nbsp;PathStrKey&nbsp;//&nbsp;MAP下的string&nbsp;key\n&nbsp;&nbsp;&nbsp;&nbsp;PathIntkey&nbsp;//&nbsp;MAP下的integer&nbsp;key\n&nbsp;&nbsp;&nbsp;&nbsp;PathObjKey//&nbsp;MAP下的object&nbsp;key\n)\n\ntype&nbsp;PathNode&nbsp;struct&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;Path&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;相对父节点路径\n&nbsp;&nbsp;&nbsp;&nbsp;Node&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;原始数据单元\n&nbsp;&nbsp;&nbsp;&nbsp;Next&nbsp;[]PathNode&nbsp;//&nbsp;存储子节点\n&nbsp;}</code></p><p></p><p>在 Path 的基础上，我们组合对应的数据单元&nbsp;Node，然后再通过一个&nbsp;Next 数组动态存储子节点，便可以组装成一个类似于&nbsp;BTree&nbsp;的泛型结构。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/11/1139f29c977438ce32ab31b4b3776576.png\" /></p><p></p><p>这种泛型结构比 map+interface 要好在哪呢？首先，底层的数据单元 Node 都是对原始 thrift data 的引用，没有转换 interface 带来的二进制编解码开销；其次，我们的设计保证所有树节点 PathNode 的内存结构是完全一样，并且由于父子关系的底层核心容器是 slice， 我们又可以更进一步采用内存池技术，将整个 DOM 树的子节点内存分配与释放都进行池化从而避免调用 go 堆内存管理。测试结果表明，在理想场景下（后续反序列化的DOM树节点数量小于等于之前反序列化节点数量的最大值——这由于内存池本身的缓冲效应基本可以保证），内存分配次数可为0，性能提升200%！（见【性能测试-全量序列化/反序列化】部分）。</p><p></p><h2>性能测试</h2><p></p><p></p><p>这里我们分别定义&nbsp;简单（Small)、复杂（Medium) 两个基准结构体分别在比较 不同数据量级 下的性能，同时添加&nbsp;简单部分（SmallPartial）、复杂部分（MediumPartial） 两个对应子集，用于【反射-裁剪】场景的性能比较：</p><p></p><p>Small：114B，6个有效字段SmallPartial：small 的子集，55B，3个有效字段Medium: 6455B，284个有效字段MediumPartial: medium 的子集，1922B，132个有效字段</p><p></p><p></p><blockquote>Small：https://github.com/cloudwego/dynamicgo/blob/main/testdata/idl/baseline.thrift#L3Medium：https://github.com/cloudwego/dynamicgo/blob/main/testdata/idl/baseline.thrift#L12SmallPartial：https://github.com/cloudwego/dynamicgo/blob/main/testdata/idl/baseline.thrift#L12MediumPartial：https://github.com/cloudwego/dynamicgo/blob/main/testdata/idl/baseline.thrift#L36</blockquote><p></p><p></p><p>其次，我们依据上述业务场景划分为 反射、协议转换、全量序列化/反序列化 三套 API，并以代码生成库&nbsp;kitex/FastAPI、泛化调用库&nbsp;kitex/generic、JSON 库&nbsp;sonic&nbsp;为基准进行性能测试。其它测试环境均保持一致：</p><p></p><p>Go 1.18.1CPU intel i9-9880H 2.3GHZOS macOS Monterey 12.6</p><p></p><p></p><blockquote>kitex/FastAPI：https://github.com/cloudwego/kitex/blob/aed28371eb88b2668854759ce9f4666595ebc8de/pkg/remote/codec/thrift/thrift.gokitex/generic：https://github.com/cloudwego/kitex/tree/develop/pkg/genericsonic：https://github.com/bytedance/sonic</blockquote><p></p><p></p><h4>反射</h4><p></p><p></p><p>1. 代码</p><p></p><p>dynamicgo/testdata/baseline_tg_test.go</p><p></p><p>2. 用例</p><p></p><p>GetOne：查找字节流中最后1个数据字段GetMany：查找前中后5个数据字段MarshalMany：将 GetMany 中的结果进行二次序列化SetOne：设置最后一个数据字段SetMany：设置前中后3个节点数据MarshalTo：将大 Thrift 数据包裁剪为小 thrift 数据包 （Small -&gt; SmallPartial 或 Medium -&gt; MediumParital）UnmarshalAll+MarshalPartial：代码生成/泛化调用方式裁剪——先反序列化全量数据再序列化部分数据。效果等同于 MarshalTo。</p><p></p><p>3. 结果</p><p></p><p>简单（ns/OP）</p><p><img src=\"https://static001.geekbang.org/infoq/38/38aae2b5e5a3ce7adc61de87cf414eaa.png\" /></p><p>复杂（ns/OP）</p><p><img src=\"https://static001.geekbang.org/infoq/3a/3aa0bec270448fce74dd672f99174868.png\" /></p><p>4. 结论</p><p></p><p>dynamicgo 一次查找+写入 开销大约为代码生成方式的 2 ~ 1/3、为泛化调用方式的 1/12 ~ 1/15，并随着数据量级增大优势加大；dynamicgo thrift 裁剪 开销接近于代码生成方式、约为泛化调用方式的 1/10～1/6，并且随着数据量级增大优势减弱。</p><p></p><h4>协议转换</h4><p></p><p></p><p>1. 代码</p><p></p><p>JSON2Thrift:&nbsp;dynamicgo/testdata/baseline_j2t_test.goThriftToJSON:&nbsp;dynamicgo/testdata/baseline_t2j_test.go</p><p></p><p>2. 用例</p><p></p><p>JSON2thrift：JSON&nbsp;数据转换为等价结构的 thrift 数据thrift2JSON：将 thrift&nbsp;数据转换为等价结构的 JSON 数据sonic + kitex-fast：表示通过 sonic 处理 json 数据（有结构体），通过&nbsp;kitex&nbsp;代码生成处理&nbsp;thrift&nbsp;数据</p><p></p><p>3. 结果</p><p></p><p>简单（ns/OP）</p><p><img src=\"https://static001.geekbang.org/infoq/2e/2e1d3880d16ea2cc9e9d2817abcc2554.png\" /></p><p>复杂（ns/OP）</p><p><img src=\"https://static001.geekbang.org/infoq/57/57628560c2360e76bbc4122889ac92f4.png\" /></p><p>4. 结论</p><p></p><p>dynamicgo 协议转换开销约为代码生成方式的 1～2/3、泛化调用方式的 1/4～1/9，并且随着数据量级增大优势加大；</p><p></p><h4>全量序列化/反序列化</h4><p></p><p></p><p>1. 代码</p><p></p><p>dynamicgo/testdata/baseline_tg_test.go#BenchmarkThriftGetAll</p><p></p><p>2. 用例</p><p></p><p>UnmarshalAll：反序列化所有字段。其中对于 dynamicgo 有两种模式：new：每次重新分配 DOM 内存；reuse：使用内存池复用 DOM 内存。MarshalAll：序列化所有字段。</p><p></p><p>3. 结果</p><p></p><p>简单（ns/OP）</p><p><img src=\"https://static001.geekbang.org/infoq/b9/b966a5b49005711306a6afa488ed0134.png\" /></p><p>复杂（ns/OP）</p><p><img src=\"https://static001.geekbang.org/infoq/4b/4b1862ca7626e8de814c92d30f817da2.png\" /></p><p>4. 结论</p><p></p><p>dynamicgo 全量序列化 开销约为代码生成方式的 6～3倍、泛化调用方式的 1/4～1/2，并且随着数据量级增大优势减弱；Dynamigo 全量反序列化+内存复用 场景下开销约为代码生成方式的 1.8～0.7、泛化调用方式的 1/13～1/8，并且随着数据量级增大优势加大。</p><p></p><h2>应用与展望</h2><p></p><p></p><p>当前，dynamicgo 已经应用到许多重要业务场景中，包括：</p><p></p><p>业务隐私合规 中间件（thrift 反射）；抖音某 BFF 服务下游数据按需下发（thrift 裁剪）；字节跳动某 API 网关协议转换（JSON&lt;&gt;thrift 协议转换）。</p><p></p><p>并且逐步上线并取得收益。目前 dynamic 还在迭代中，接下来的工作包括：</p><p></p><p>集成到 Kitex 泛化调用模块中，为更多用户提供高性能的 thrift 泛化调用模块；Thrift DOM 接入 DSL（GraphQL）组件，进一步提升 BFF 动态网关性能；支持 Protobuf 协议。</p><p></p><p>也欢迎感兴趣的个人或团队参与进来，共同开发！</p><p></p><p>项目地址</p><p>GitHub：https://github.com/cloudwego</p><p>官网：www.cloudwego.io</p>",
    "publish_time": "2023-03-17 17:46:59",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Akamai推出Akamai Hunt 和 Akamai 无代理分段",
    "url": "https://www.infoq.cn/article/ahcgyqx8YzX9ojSebNsC",
    "summary": "<p></p><p>3月 15日，支持和保护网络生活的云服务提供商<a href=\"https://www.akamai.com/zh\">阿卡迈技术公司</a>\"（Akamai Technologies, Inc.，以下简称：Akamai）（NASDAQ：AKAM），于今天推出了 Akamai Hunt 安全服务。</p><p>&nbsp;</p><p>据悉该服务使用户能够利用 Akamai Guardicore Segmentation 的基础架构、Akamai 的全球攻击监测能力以及专业的安全研究人员来搜寻和修复其环境中逃逸的威胁和风险。Akamai 还发布了无代理分段，帮助 Akamai Guardicore Segmentation 用户将 Zero Trust 的优势扩展到联网的物联网和 OT 设备（此类设备无法运行基于主机的安全软件）。</p><p>&nbsp;</p><p>在企业拥抱数字化转型、员工队伍不断发展之际，勒索软件和其他高级攻击仍然困扰着企业，会影响业务连续性和整体品牌信任度，仅在 2021 年，这些威胁就给企业造成 <a href=\"https://www.akamai.com/zh/resources/research-paper/akamai-ransomware-threat-report\">200 多亿美元</a>\"的损失。为了应对这些威胁，IT 管理员必须采取新的方法，通过 Zero Trust 框架和微分段来保护他们的网络、知识产权和员工，阻止网络内的横向移动。</p><p>&nbsp;</p><p>Akamai 企业安全高级副总裁兼总经理 Pavel Gurvich 表示：“事实证明，微分段技术能够在复杂和动态的环境中大大减少攻击面，从而抵御勒索软件和其他攻击。为 Akamai Guardicore Segmentation 客户提供的这些新产品将把保护范围扩大到历来难以保护的设备上，并将提供必要的额外监测能力和分析，以抵御逃逸威胁。”</p><p>&nbsp;</p><p></p><h3>Akamai Hunt</h3><p></p><p>&nbsp;</p><p>Akamai Hunt 结合了 Akamai Guardicore Segmentation 的基础架构、遥测和控制，以及 Akamai 通过交付全球大量互联网流量而掌握的数据。</p><p>&nbsp;</p><p>现在，用户可以消除其环境中的威胁，通过虚拟方式修补漏洞，并改善其 IT 安全状况。其他优势包括：</p><p>&nbsp;</p><p>独特的数据集：Hunt 将来自客户环境的丰富遥测数据与全球优先威胁数据相关联，因此能查找逃逸的威胁和风险。</p><p>&nbsp;</p><p>大数据分析：关联并查询海量数据，以发现其他工具漏掉的可疑和异常活动。</p><p>&nbsp;</p><p>专家调查：专门的安全专家会对检测开展调查，确保团队不被误报所困扰。</p><p>&nbsp;</p><p>&nbsp;警报和月度报告：详细的警报提供了抵御所需的信息，而月度报告则提供了执行概述。</p><p>&nbsp;</p><p>&nbsp;引导式抵御：Hunt 专家协助修复威胁、修补漏洞，并为 IT 基础架构实施安全强化。</p><p>&nbsp;</p><p></p><h3>Akamai 无代理分段</h3><p></p><p>&nbsp;</p><p>对于大多数企业来说，确保物联网和 OT 设备的安全历来都是一项挑战。借助 Akamai 无代理分段，企业现在能够缩小攻击面，并在无法运行基于主机的安全软件的设备上执行 Zero Trust 策略。其他功能包括：</p><p>&nbsp;</p><p>持续设备发现：自动发现新的联网设备，并执行预定义的设备登入工作流程。</p><p>&nbsp;</p><p>集成的设备指纹：识别、评估和归类所有连接的设备，以确保应用适当的安全策略。</p><p>&nbsp;</p><p>企业资产的可视化：查看整个企业的物联网和 OT 设备、流量以及与端点、服务器和云资产的交互。</p><p>&nbsp;</p><p>无代理 Zero Trust 分段：通过与网络控制点的直接集成，执行无代理最小权限分段策略，并隔离可疑设备。</p><p>&nbsp;</p><p>漫游设备感知：当设备在有线和无线网络基础架构的不同区域之间移动时，维持设备监测、上下文和控制。</p><p>&nbsp;</p><p>Akamai 无代理分段将于 2023 年第二季度面向 Akamai Guardicore Segmentation 推出。</p><p>&nbsp;</p>",
    "publish_time": "2023-03-17 18:38:20",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]