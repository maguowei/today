[
  {
    "title": "Canva 选择 Amazon KDS 而非 SNS+SQS，每天处理 250 亿个事件，节省了 85%的成本",
    "url": "https://www.infoq.cn/article/TkRjo8yPL8ik7Jes7Ie6",
    "summary": "<p>Canva 对其产品分析平台评估了多种不同的数据处理解决方案，包括 AWS SNS 和 SQS 的组合、MKS 以及 Amazon KDS，最终选择了后者，主要是因为其成本要低得多。该公司比较了这些解决方案的许多方面，比如性能、维护工作量以及成本等。</p><p></p><p>Canva 每天处理约 250 亿个产品分析事件，以支持许多面向用户的功能，如个性化及推荐、使用统计及见解。所捕获的数据也是支持任意新产品特性 A/B 测试的关键。</p><p></p><p>收集和分发产品分析事件的数据管道不仅需要支持非常高的吞吐量，还需要支持高可用性（99.999% 的正常运行时间），并且还要具有成本效益、可靠性和用户友好性。负责为产品分析提供事件驱动架构（EDA）的团队在 MVP 的早期阶段使用了 AWS SQS 和 SNS 的组合。这些服务易于设置，并提供了出色的弹性和可扩展性，但它们的成本占了运行架构的 80%。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/48/484511f30e7879ddb60529c494718e9b.png\" /></p><p></p><p>使用 Amazon KDS 的产品分析数据管道（来源：Canva 工程博客）</p><p></p><p>基于最初的 MVP 经验，该团队决定寻找能够以较低成本满足性能要求的替代方案，并考虑了另外两种 AWS 服务：Amazon Managed Streaming for Apache Kafka （MSK） 和 Amazon Kinesis Data Stream（KDS）。工程师们比较了这些服务的成本、性能和可维护性，最终选择了 KDS，因为它本身的成本低（比 SQS+SNS 便宜 85%），而且维护的成本也极低，尽管与 MSK 相比延迟更高（高 10-20 毫秒，但可以接受）。</p><p></p><p>为了提高基于 KDS 的解决方案的成本效益，该团队使用了事件批处理和 zstd 压缩，压缩比为 10 倍，每批压缩延迟为 100 毫秒。工程师估算，使用压缩技术每年可节省 60 万美元。</p><p></p><p>使用 KDS 时需要特别注意的一个方面是尾部延迟高（超过 500 毫秒），并且当吞吐量峰值超过每个分片 1MB/s 的硬限制阈值时会进行限流。工程师们实现了一种利用 SQS 队列的回退逻辑，结果实现了低于 20 毫秒的 p99 延迟，同时每月为 SQS 支付的费用不到 100 美元。回退选项还兼作了故障转移机制，以防 KDS 遇到严重的服务降级或中断。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/59/59189bc8310a465ab5517b79f5268bf4.png\" /></p><p></p><p>在 KDS 限流情况下，回退到 SQS（来源：Canva 工程博客）</p><p></p><p>该团队使用 Protocol Buffers 来确保架构的可描述性以及随着时间推移来演进事件定义。Canva 已经在使用 Protocol Buffers 来定义微服务之间的契约，但对于事件定义，它还需要完全的向后和向前兼容性。工程师们还在 protoc 之上创建了一个自主研发的代码生成工具。</p><p></p><p>Datumgen 用于验证兼容性要求并生成多种语言的代码。此外，该工具从事件定义中提取元数据，以增强事件目录数据，其中包含有关技术和业务所有者的详细信息以及字段描述。文档完备且最新的事件模式有助于 Canva 保持数据质量，避免运行时因模式不兼容而导致的代价高昂的问题，并使工程师能够发现可用的产品分析事件。</p><p></p><p>作者介绍</p><p></p><p>Rafal Gancarz 是一位经验丰富的技术领导者和专家。他目前正在帮助星巴克打造可扩展、弹性和成本效益高的商务平台。此前，Rafal 曾为思科、埃森哲、凯德、ICE、Callsign 等公司设计和构建大规模、分布式和基于云的系统。他的兴趣涵盖了架构与设计、持续交付、可观测性和可维护性，以及软件交付的社会技术和组织方面。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2024/08/canva-amazon-kinesis-data-stream/\">https://www.infoq.com/news/2024/08/canva-amazon-kinesis-data-stream/</a>\"</p><p></p>",
    "publish_time": "2024-09-05 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "作业帮在多云环境下的高可用双活架构优化实践",
    "url": "https://www.infoq.cn/article/5LpIjWWAL7mokMOVgul7",
    "summary": "<p></p><blockquote>作者｜刘强，就职于作业帮基础架构 DBA 团队，负责分布式数据库的探索和使用，协同研发团队在公司内部推进分布式数据库在业务上的落地。</blockquote><p></p><p></p><p>在作业帮刚上线<a href=\"https://github.com/oceanbase/oceanbase\">OceanBase 4.0</a>\"&nbsp;时，我分享过<a href=\"https://open.oceanbase.com/blog/27200125\">作业帮的业务架构痛</a>\"点。目前，作业帮是多云架构（阿里云、百度云、腾讯云），并同时使用 MySQL、Redis-Cluster、MongoDB、Elastisearch、TiDB 、OceanBase这几款数据库。出于高可用和降本需求，我们决定将更多 MySQL业务场景用 OceanBase 代替，本文将和大家分享具体原因，以及OceanBase 4.0 与 MySQL5.7 的对比数据。</p><p></p><h2>高可用双活架构方案升级需求</h2><p></p><p></p><p>由于作业帮业务的多样性和复杂性，我们对于分布式数据库的使用需求主要基于以下几个方面。</p><p></p><p>第一，在海量数据的情况下希望减少分库分表的复杂度，并解决单机存储瓶颈。</p><p></p><p>第二，对 I/O 密集型的 SQL 及 CPU 密集型的 SQL 来说，我们希望能够提高响应速度，减少它在 MySQL 中对线上业务的影响。</p><p></p><p>第三，每个业务内部都需要业务人员频繁查询、录取线上数据，并有相应的报表服务以供上级 Leader 查看，而且大数据部门也会有报表需求接入线上数据，这对于线上 MySQL 来说难以支撑，在数据归档及汇总的情况下，也缺乏良好方案。</p><p></p><p>第四，由于MySQL的特性限制，我们需要基于一个外部的高可用组件来实现 MySQL 的高可用架构，在多云环境下，网络环境相对复杂，这对高可用的稳定性提出了更高要求。如果部分业务的请求链路长或复杂，跨云访问会使业务相应耗时增加，影响用户体验。</p><p></p><p>因此，我们需要探索良好的双活架构方案，初步方案是基于 MySQL ，并引入 DTS 来实现双活架构。这种架构的复杂性及引入过程中 DTS 的异常或中断，对于数据的一致性有很大的挑战。同时在使用公有云的情况下，也希望能够最大程度降低硬件的使用成本。</p><p></p><p>出于高可用和降本需求，我们决定将更多 MySQL 的业务场景替换为 OceanBase，并对OceanBase 和 MySQL5.7 进行了多方面的对比。</p><p></p><h2>OceanBase 4.0 对比 MySQL5.7</h2><p></p><p></p><h3>1、性能对比</h3><p></p><p>我们使用32C64GB的硬件规格分别对 OceanBase 和 MySQL 进行性能、CPU使用率、磁盘空间占用的测试。首先，从图1可见，OceanBase性能明显超过 MySQL。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/16/166de6ab79feed5326973d27a4235d78.png\" /></p><p></p><p>图1 OceanBase 和 MySQL 的性能对比</p><p></p><p>其次，从图2得知，在相同的并发环境下，OceanBase 的 CPU 使用率比 MySQL 低至少一倍以上。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b9/b91031fe4600db015b07304ec14b484a.png\" /></p><p></p><p>图2 OceanBase 和 MySQL 的CPU使用率对比</p><p></p><p>另外，由于 OceanBase 数据压缩及编码的技术相较于 MySQL，能够节约 2/3 以上的磁盘空间，因此，综合上述三方面的对比结果，我们认为 OceanBase 能为作业帮的降本增效提供极大帮助。</p><p></p><p>在性能方面，我们还测试了DDL的执行速度。对于耗时较长的 DDL，MySQL 会有补充延时问题，需要我们引用额外的审核工具来控制它的延迟，而 OceanBase 不存在延时问题。对于执行速度，MySQL 和 OceanBase 相差不大，这让我们更加期待 OceanBase 4.1 的数据旁路导入功能，可以将 DDL 的执行速度大幅提升。不过，我们也发现了一些语法兼容性的问题，例如，OceanBase 对主键的操作语法不支持多个 DDL 合并执行，只能各自单独执行。</p><p></p><h3>2、架构对比</h3><p></p><p></p><p>除了降本增效的需求，高可用也是我们在探索双活架构中最看重的一方面。相较于 MySQL ，OceanBase 的高可用是有延伸的，不需要额外的高可用组件，这有利于解决数据不一致的问题。再加上OceanBase 的日志具备多副本特性，能够支持在多机房或多城市灵活部署。OceanBase 还便于作业帮实现一些单元化的需求，我们可以将业务单元内的 Leader 数据调度在某一个机房内，实现业务访问的流量闭环，减少跨域读写。</p><p></p><h3>3、字符集对比</h3><p></p><p></p><p>最后，我们测试了字符集的支持程度。作业帮成立十年，我们使用 MySQL 的场景和字符集种类都比较多。OceanBase 4.0当前支持图3 中显示的几种字符集，在4.1版本中增加了对拉丁字符的支持。后续我们也希望 OceanBase 能够扩展字符集及校验集的支持种类。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/26/26e3d85c4ae4250dbdaf6db270b7a504.png\" /></p><p></p><p>图3 OceanBase 4.0支持的字符集</p><p></p><p>以上就是作业帮对 OceanBase 和 MySQL的主要对比数据。在将更多业务场景切换至 OceanBase 的过程中，我们发现，在高可用双活架构方案之外， OceanBase 4.0 的HTAP和资源隔离能力也为我们带来许多意外之喜。</p><p></p><h2>低成本与低延时，更好地降本增效</h2><p></p><p></p><p>OceanBase 是一个具备 HTAP 能力的原生分布式数据库，如何理解 HTAP？引用 OceanBase CTO 的一句话：HTAP 就是在高性能 OLTP 数据库的基础上扩展 OLAP 的能力，能很好支持实时分析。</p><p></p><p>在作业帮的业务场景中，我们感受到 HTAP 的两大显著优势：低成本和低延时。</p><p>•&nbsp;低成本：我们希望一套系统能同时支持OLTP场景和OLAP场景，相比两套系统拥有更高的性价比。</p><p>•&nbsp;低延时：省去了繁琐费时的ETL过程，降低延时，更好支持实时分析。</p><p></p><p>我们知道，在一套系统同时实现OLTP和OLAP的能力，其中一项挑战是资源隔离，使业务之间互不影响。这便是OceanBase 带给我们惊喜的地方。</p><p></p><p>对于核心业务来说，我们希望能够使用物理资源管理，比如行存副本服务 OLTP，列存副本服务 OLAP，这两种业务是不共享物理资源的，可以做到绝对的隔离。 OceanBase 可以增加额外的只读副本，再通过配置 OBProxy 的 proxy_idc_name&nbsp;实现读写分离。</p><p></p><p>图 4 为OceanBase 的物理资源隔离方案，基于只读副本，再增加逻辑机房的情况下，在 OBProxy 中配置逻辑机房的位置。所有 OLAP 的只读流量都会录入只读副本中，避免与 OLTP 副争抢资源。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b1/b1275422092a3a0e09aa100448957b8f.png\" /></p><p></p><p>图4 OceanBase 的物理资源隔离方案</p><p></p><p>对于成本敏感的逻辑资源隔离，OceanBase 在同一租户内就可能实现 OLAP 和 OLTP 的物理资源共享，进而实现资源隔离。</p><p></p><p>对于逻辑隔离来说，首先 OceanBase 定义了一个大查询，默认将执行时间超过 5 秒的请求判定为大查询，当大查询和短查询同时争抢 CPU 时，大查询会被降低优先级，待 CPU 资源充足时再被挂起，我们可以设置Large_query_worker_percentage 在同一租户内，大查询最多可以占用30%的用户线程数。在这种情况下，我们可以有效隔离大查询对 OLTP 业务的影响，优先保证了 OLTP 业务的执行。</p><p></p><p>我们使用了一些线上业务数据和 SQL 来对比 MySQL 和 OceanBase。在作业帮的业务场景中，一个大业务部门的报表需要多级 Leader甚至上百人频繁查看，因此，即使是 OLAP 类型的业务，QPS也可以达到几十甚至上百。我们使用了60个并发去压测较复杂的 SQL，通过图 5 可以看出，OceanBase 比 MySQL 最起码快了一倍以上。OceanBase 的CPU使用率也基本控制在25%以下。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/81/81e6689eb636c0637694a5043e721d1b.png\" /></p><p></p><p>图5 OceanBase 与 MySQL执行SQL耗时</p><p></p><p>在60个并发执行 OLAP 业务的同时，我们也用256个并发去运行 Sysbench 任务，在 OLAP SQL 扫描量较大的情况下，我们可以看到它的耗时出现了一些抖动（见图6）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4f/4f3d1fd0fecc71dd321751b9d7997137.png\" /></p><p></p><p>图6 并发量256 运行 Sysbench 任务</p><p></p><p>以上就是作业帮对OceanBase 4.0 的探索过程，目前，我们已经使用 OceanBase 半年了，总结出一些心得及建议，供大家参考。</p><p></p><h2>使用 OceanBase 的心得和建议</h2><p></p><p></p><p>首先，对于 OceanBase OCP 管理平台有如下几点建议。</p><p>• 建议增加 DDL 任务列表显示，需要在每一个租户下，可以看到有多少任务正在执行。</p><p>• 建议增加 SQL 审核的功能，如果有业务正在从 MySQL 迁移，可以尽快保证业务上线，减少 DBA 工作，聚焦于对业务的落地。</p><p>• 在使用过程中我们发现，每个租户下磁盘的使用量、数据库的大小及表的大小，这一部分数据的监控是缺失的，需要完善。</p><p>• 在集群中测试时，需要实时监控性能数据，比如 QPS 响应时间、CPU 的使用率等，建议在现有能力上再缩短延迟。</p><p></p><p>其次，对 OceanBase 集群的一些问题，我们也给出反馈，希望得以提升。</p><p>• DDL无法实时查看任务的进度百分比，希望后续可以增加该功能。</p><p>• 现在集群升级时需要确保每个租户的 leader 都聚集在单个 Zone 下，这样对于每个集群有上百个租户来说，操作会比较繁琐，希望可以优化。</p><p>• 对于大家在使用过程中需要注意大小写敏感的参数设置，一旦创建后业务上线不合理则无法通过 SQL 语句进行修改，希望优化。</p><p>• 建议注意redo log 磁盘跟内存大小的配比，防止出现当磁盘空间还有富裕的时候，创建 redo log ，显示磁盘空间不够的问题。</p><p></p><p>最后，还有一些关于 OMS 数据迁移平台的小建议：目前存在的问题有三个，一是在数据迁移过程中不支持新增 DB 的同步，对于数据归档或汇总的需求不友好；二是 OpenAPI 开放的太少，不利于我们内部平台的改造；三是 ghc 的临时表忽略写法过于繁琐，需要每一个 DB 都写一个配。由于 OMS 数据迁移是测试中常用的功能，我们希望后续能有统一的配置，可以将 ghc 临时表统一过滤掉。</p>",
    "publish_time": "2024-09-05 09:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "人工智能缺乏“激励机制”，如何重新定位和思考 AI 的发展？",
    "url": "https://www.infoq.cn/article/pAk7bZJOQeQg2Ss3rOWJ",
    "summary": "<p>9月5日上午，2024 Inclusion·外滩大会在上海黄浦世博园区开幕。会上众多专家分享了关于<a href=\"https://s.geekbang.org/search/c=0/k=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/t=?referrer=InfoQ\">人工智能</a>\"的最新见解。</p><p>&nbsp;</p><p>其中，著名未来学家、《连线》杂志创始主编凯文·凯利在开幕主论坛上的演讲中指出，当人工智能深刻影响经济和文化，必将涌现三大趋势：全球主义、创新加速和AI驱动生成。</p><p>&nbsp;</p><p>具体而言，全球主义正在迅速推进，因为我们正在共同构建一个基于技术的“超级有机体”。“我们正将全球的手机、笔记本电脑和所有的数据服务器连接成一个巨大的计算系统。每一台设备就像这个庞大计算机的一个神经元。这台超级计算机在一个前所未有的规模上高速运行。”</p><p>&nbsp;</p><p>同时，AI技术加速了创新的步伐，这种加速体现在多个方面，包括新发明和新思想的传播速度越来越快、通过增强现实（AR）和虚拟现实（VR）技术来提高学习效率，甚至AI也通过机器及其他传感器来感知世界等。此外，ChatGPT等人工智能工具，也极大地加快了人们学习的速度。</p><p></p><p>“这正是人工智能带来的真正巨大革命，”凯文·凯利说，人工智能系统正在生成新的事物——它们还不完美，但正在变得越来越好。</p><p>&nbsp;</p><p>机器学习泰斗、美国“三院院士”迈克尔·乔丹则指出，“缺乏对集体性、不确定性和激励机制的关注，是当前对人工智能的讨论中缺失的三个方面。”他强调，AI系统的发展不能仅依赖单个智能设备，而是要通过集体协作，构建去中心化的智能系统，特别是在面对不确定性时需要集体智能来应对。</p><p>&nbsp;</p><p>“AI拥有海量的数据，但有些不能生成价值，通过设计激励机制才能驱动AI智能体贡献和协作。”迈克尔·乔丹提出了“三层数据市场（Three-Layer Data Markets）”模型，其中用户、平台和数据买家通过“出让数据”、“购买数据”、“提供服务”形成了闭环。他强调，数据购买者也就是企业可以结合“数据和服务”建立与用户的激励机制，从而为他们带来真正的价值。</p><p>&nbsp;</p><p>对此，迈克尔·乔丹援引了统计契约理论，这是一种结合了统计学和经济学的新型理论。在契约理论中，代理人拥有私有信息，而委托人通过激励机制形成了数据和服务相互促进的市场，维持了供需双方的利益平衡。</p><p>&nbsp;</p><p>例如航空公司分“商务舱”和“经济舱”，航空公司作为委托人能够根据代理人的不同支付意愿提供不同的价格，而不需要代理人透露其个人信息。由于过去十年间，全球范围内对数据隐私的监管不断增加，他也建议“我们可以通过非一致的隐私要求进一步提高用户效用，对低成本平台施加更高的要求。”</p><p>&nbsp;</p><p>最后，迈克尔·乔丹将AI系统的发展类比于化学工程和电气工程的发展，前者建立在化学、流体力学等领域，后者基于建立在电磁学、光学等技术的基础上。而AI的基础是建立在推理、算法和经济理念上，并应以人类福祉为目标。“但人工智能正被置于那些未经深思熟虑的、朴素的旧式愿景之中，它的兴起和发展受到扭曲。”其提醒道。</p><p></p><p>香港科技大学校董会主席、美国国家工程院外籍院士沈向洋在演讲中谈到大模型时代人机交互方式的演变，从图形界面到搜索、推荐，再到对话，大模型的发展将推动这些交互方式的进一步迭代。</p><p>&nbsp;</p><p>沈向洋认为，AI为人类提供了与技术共生的全新语境，人机交互的新方式指向“AI与IA”的融合共进。IA（Intelligent Augmentation），即智能增强，代表着一种以人为本的 AI 发展路径。它聚焦于运用技术提升人类的能力，而非取代人类，强调了人类与 AI 之间的协作关系。</p><p>&nbsp;</p><p>在谈到AI agent时，沈向洋指出，agent从愿景到落地的过程中，需要始终以需求为圆点，深刻理解模型的能力，并构建一个AI深度参与的工作流程。他表示，AI agent时代的到来，不会是一个神奇而强大的模型突然代替了所有的工作流，它涉及到技术、工程与市场的不断磨合，最终以超预期的服务呈现给人类。</p><p>&nbsp;</p><p>此外，他强调，在AI迅速发展的同时，全球需要新的治理框架和体系来应对不同地区的需求和挑战。AI的治理至关重要，必须打造负责任的AI系统，才能确保其对社会产生积极的长期影响。</p>",
    "publish_time": "2024-09-05 13:47:32",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "《云上新视界》第二季第三期：抖音巴黎奥运会赛事直播技术揭秘",
    "url": "https://www.infoq.cn/article/P6oJpDhSjDulLhQosVfc",
    "summary": "<p>2024 年全球赛事迎来大爆发，据不完全统计，有 48 个体育赛事和电竞项目在今年启幕。<br />\n在这样一个赛事大年，赛事直播、转播也成为了各大平台新发力的内容领域。各平台持续发力 AI、沉浸式、低延迟、XR 等新赛道，将观赛体验再度升级，这也为赛事直播带来了新的技术挑战。</p>",
    "publish_time": "2024-09-05 14:30:17",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "中国AI Agent应用研究报告 2024",
    "url": "https://www.infoq.cn/article/bTgj82D3gFJK9ZLRM5Ci",
    "summary": "<h3>研究背景</h3>\n<p>InfoQ 研究中心自创立以来就持续关注 AI 领域的发展和更新，并持续推出了<a href=\"https://www.infoq.cn/minibook/6WyXxdu179Di1O75JPUM\">《中国AGI市场发展研究报告 2024》</a>、<a href=\"https://www.infoq.cn/minibook/3ElKmiQIzsFC8ThhFfst\">《中国开源生态图谱 2023——人工智能领域》</a>、<a href=\"https://www.infoq.cn/minibook/vWO39J1tlb9xlSaIJoI6\">《大语言模型综合评测报告 2023》</a>、<a href=\"https://www.infoq.cn/minibook/IV4VhedKw1E1tY8Hleje\">《2023 中国人工智能成熟度模型报告》</a>、<a href=\"https://www.infoq.cn/minibook/0xhGee6fTUuzDNbj7FdU\">《大语言模型综合评测报告 2024》</a>等人工智能相关的研究报告。</p>\n<p>关于 AI Agent 的讨论愈加深入，大模型大脑更新技术框架，市场上涌现出众多厂商竞相推出创新产品。此前，InfoQ研究中心对中国AI Agent产品进行总结，发布<a href=\"https://www.infoq.cn/minibook/58tl2yZ8KAtwO9gia9Bz\">《中国AI Agent 产品罗盘》</a>。</p>\n<p>在本报告《中国AI Agent应用研究报告 2024》中，我们总结了截至2024年第二季度的大模型最新进展，深入剖析了AI Agent的技术架构，并探讨了理想与现实中AI Agent的差距。</p>\n<p>同时，本研究还将全面审视AI Agent产品在当前市场的多元化应用，重点聚焦<strong>教育、金融、文娱游戏、消费</strong>等关键行业。通过深入分析现有应用案例，本报告将揭示<strong>平台类和垂直类Agent产品</strong>在实际业务场景中的应用深度及潜在价值，为行业发展提供洞察。</p>\n<h3>报告亮点</h3>\n<ul>\n<li>拆解AI Agent技术框架，厘清理想与现阶段之间的差距</li>\n<li>平台型和垂直型Agent产品大解析，产品间有何不同</li>\n<li>办公、财税、数据分析、营销、教育、金融、文娱游戏、消费AI Agent应用现状大揭秘</li>\n</ul>\n<h3>中国AI Agent产品罗盘</h3>\n<p><img alt=\"\" src=\"https://static001.infoq.cn/resource/image/23/b8/233c003f0ed1e82bb6087c95952aa7b8.jpg\" /></p>\n<h3>专家致谢</h3>\n<ul>\n<li>董大祥 千帆AppBuilder总架构师，百度 主任研发架构师</li>\n<li>方高林 用友网络 助理总裁兼iuap智能平台部总经理</li>\n<li>辜斯缪 百度 搜索策略首席架构师</li>\n<li>韩艾 京东集团 算法总监</li>\n<li>孔淼 容联云 产业云VP及诸葛智能创始人</li>\n<li>李飞 数势科技 AI 负责人</li>\n<li>刘红杰 腾讯元器 产品专家</li>\n<li>杨蜀 深圳标普云科技 创始人&amp;董事长</li>\n<li>邹盼湘 彩讯股份 AI产研中心总经理</li>\n</ul>",
    "publish_time": "2024-09-05 15:01:13",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "支付宝宣布推出独立AI原生App“支小宝”",
    "url": "https://www.infoq.cn/article/OWQFBhjChhJWYcu0dQ37",
    "summary": "<p>9月5日，支付宝在2024外滩大会上宣布发布AI生活管家App“支小宝”，目前苹果及安卓应用商店均可下载。</p><p>&nbsp;</p><p>据官方介绍，基于蚂蚁百灵大模型推出的“支小宝”，是国内首个服务型的AI独立App——连接支付宝生态，“支小宝”可通过对话快速订票、点餐、打车、查询附近吃喝玩乐等，说句话就能办事；“支小宝”还拥有场景感知系统，能根据用户的生活习惯和使用场景，智能推荐专属的服务，做到“越用越懂用户”。</p><p>&nbsp;</p><p>区别于传统的图形用户界面，“支小宝”采用极简对话式交互，用户下达口语指令后，不用再寻找或输入，就能快速找到各种服务。同时，它也内嵌在支付宝中，在支付宝App首页下拉也能体验。</p><p>&nbsp;</p><p>与此同时，支付宝面向行业正式启动智能体生态开放计划，并推出了智能体开发平台“百宝箱”，依托智能体构建能力，商家机构可通过“百宝箱”0代码、最快1分钟创建专属智能体，并一键发布到支付宝小程序、支付宝App、支小宝App等。</p><p></p><p>目前支付宝“百宝箱”，分为基础版与专业版。基础版面向普通用户开放，可快速搭建并体验智能体；专业版则面向专业伙伴开放，支持与生态伙伴的深度定制。</p><p></p><p></p><blockquote>专业版了解网址：<a href=\"https://tbox.alipay.com/pro-about\">https://tbox.alipay.com/pro-about</a>\"可用支付宝扫码登录体验基础版：https://tbox.alipay.com/community</blockquote><p></p><p>&nbsp;</p><p>“大模型正从‘拼参数’走向‘拼应用’。”蚂蚁集团总裁韩歆毅在外滩大会上表示。</p><p>&nbsp;</p><p>支付宝AI新产品接连落地的背后，是蚂蚁集团AI First战略的全面提速。2023年，蚂蚁自研的百灵大模型完成备案。过去两年，蚂蚁以支付宝为核心加速AI应用布局，将百灵大模型能力运用在出行、政务、医疗等超500个场景，日均调用量超2亿，日均处理千亿级Tokens。</p><p>&nbsp;</p><p>据悉，除了“支小宝”，本次大会上，蚂蚁还将发布AI金融管家“蚂小财”和AI健康管家等AI产品。</p><p>&nbsp;</p><p>InfoQ将在这篇报道下持续关注和更新后续动态。</p><p></p><p></p>",
    "publish_time": "2024-09-05 15:23:12",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "国产 GPU 公司被曝“流氓式解散”！员工欠薪记账、明星创始人成“老赖”，总部已人去楼空",
    "url": "https://www.infoq.cn/article/YjDEkxaFvEpOcZbTXmCt",
    "summary": "<p>整理 | 华卫</p><p></p><p>近日，一封国产 GPU 公司向员工发出的内部邮件引发热议。据悉，象帝先突然决定开始大规模裁员，补偿标准为 N+1。有象帝先员工对外透露，该公司今年以经营困难为由还拖欠着许多员工的薪水和奖金未发，其中包括 7 到 8 月的全部工资、 4 到 5 月的部分工资，以及承诺补发 2023 年一半的年终奖。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a5/a5a4393b9097297f66d9a1df9b111509.jpeg\" /></p><p></p><p>而此前又有消息称，象帝先于 8 月 30 日召开全员会议，宣布公司因遭遇资金危机暂停运营，400 多位员工全部终止合同，高管们会继续融资，有钱了再给员工结算，股权资金全部退还员工，但没有透露具体执行方案。</p><p></p><p>9 月 1 日，国产 GPU 公司象帝先通过官方公众号发布公告，针对此前的“全员解散”等传言进行澄清说明。该公司表示，其由于国产 GPU 的发展未达到预期而面临一定“市场调整压力”，但目前并未采取解散或清算的措施；正在进行组织结构和人员配置优化，包括对部分团队成员的调整；正在寻找外部融资机会，对国产 GPU 的未来发展充满信心。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/93/93a9954b023bf199593d6257cdb3b863.png\" /></p><p></p><p>由于该公告中未提及具体的员工优化比例、结薪赔偿时间及明确的公司调整措施，因此有不少网友都仍对象帝先的未来发展保有质疑，评其为“流氓式解散”。还有知情人士在国内某职场社交平台进一步透露象帝先现状，员工全都走了，校招生全部毁约。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/cd/cd0f01c1bec885c0885c3780721080d6.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/50/50dbcbf5e2d682078dfeeeec5a5059be.jpeg\" /></p><p></p><p>据悉，位于重庆的象帝先总部大楼现已上锁，多位物业人员都表示，近期没有看到该公司的人来了。</p><p></p><p></p><h1>“吸金”的创始人，变成了失信人</h1><p></p><p></p><p>公开信息显示，象帝先成立于 2020 年 9 月，是一家高性能通用 / 专用处理器芯片设计企业，已在北京、上海、重庆、成都、苏州等地设立了研发中心。公司研发适用于桌面、工作站、边缘计算等领域的高性能、低功耗、具有完全自主知识产权的通用 CPU/GPU 及相关专用芯片产品。</p><p></p><p>在 2022 年和 2023 年，象帝先分别发布了天钧一号 GPU 和天钧二号 GPU，今年 8 月 20 日象帝先还宣布和超云数字全面战略合作，在数据中心建设、云桌面、云渲染、数字化办公运营等方面深入合作。</p><p></p><p>成立以来至今，四年的时间里，象帝先先后进行了五轮融资，获得融资金额共计 25 亿元，在 2022 年估值高达 150 亿元。而象帝先如此得投资人青睐的一个重要原因便是其创始人兼董事长、CEO 唐志敏在业内的盛名。</p><p></p><p>据了解，唐志敏是国内计算机系统与处理器芯片设计领域的战略级科学家，曾担任龙芯项目负责人、海光信息总经理兼首席科学家，先后领导龙芯一号、二号 CPU、海光系列 CPU、海光 DCU 等国内高端通用芯片项目取得成功。过去曾在中科院技术研究所担任主任研究员、博士生导师，还担任过先进微处理器技术国家工程实验室主任、“十三五”国家重点研发计划“高性能计算”重点专项总体专家。</p><p></p><p>而如今，一位知情人士在国内某职场社交平台透露，唐志敏目前已被中信银行列为失信人，消息来源于银行经理。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/22/22b40223f19e2fa3b5ac51787a16264c.jpeg\" /></p><p></p><p></p><h1>资金危机的导火索：一份对赌协议</h1><p></p><p></p><p>2023 年 12 月后，象帝先便再无新的投资消息。而象帝先之所以到了今日危境，似乎也与其融资情况有密不可分的关系。</p><p></p><p>据了解，在 8 月 30 日的全员会议上，唐志敏声称，象帝先目前遭到股东起诉，资金账户已被冻结，当前及未来也无资金进来。被起诉的具体原因是该公司曾经与股东签署过一份对赌协议，承诺 B 轮融资规模要达到 5 亿元，但最终未达成协议条款，对方现在发起了诉讼。</p><p></p><p>在过去的五轮融资中，象帝先的投资方近 20 家，包括两江资本、中信集团、乾瞻投资、点豹基金、雅瑞资本、方正和生、朗空韩亚、水木春锦基金、盛世投资、千山资本、扬子江基金等。其中，B 轮融资披露的一共有水木春锦基金等 6 家机构。但目前，象帝先并未公开起诉的股东。</p><p></p><p>不过，据首都在线日前公布的 2024 年半年度报告，象帝先有一笔涉案金额为 1881.17 万元的诉讼 (仲裁) 尚未结案，北京仲裁委已于 2024 年 7 月 15 日出具受理通知书，待排期开庭中。重庆市渝北区人民法院已于 2024 年 8 月 1 日冻结象帝先 804.04 万元财产款项。</p><p></p><p>知情人士表示，公司资金问题由来已久，无法自行造血的前提下又因外部环境难以融资续命，走到最后一步实际是意料之中。有消息显示，5 月中旬开始，象帝先就有员工被裁，部分员工 2023 年年终奖从 12 月底拖到今年 4 月也未发放，随后又被告知部分员工 5 月工资只发一部分。</p><p></p><p></p><h1>结&nbsp; &nbsp;语</h1><p></p><p></p><p>象帝先的困境并不是中国半导体行业的个例。近几年国产 GPU 公司百花齐放，算力也在逐步提升，但实则仍面临困境。</p><p></p><p>在盈利方面上，不止象帝先存在问题，国内其他能真正盈利的 GPU 公司也很少。</p><p></p><p>此前被曝烧光 3 亿融资的砺算科技，今年已处于破产边缘，多名研发员工在社交平台上称遭遇裁员欠薪，涉及近百名员工。8 月，东芯股份发布公告称，拟通过自有资金人民币 2 亿元向砺算科技”）增资，另其他投资人拟以合计 12,800 万元向其增资。但据某职场社交平台上的砺算科技员工爆料，目前砺算科技尚未拿到融资，且已经拖欠了员工 6 个月的工资。</p><p></p><p>日前，寒武纪发布了 2023 年上半年财报，营收同比下滑，净亏损虽然收窄，但依然亏损严重。财报还显示，上半年研发人员减少了 225 人。综合寒武纪招股书及近三年上市数据来看，寒武纪一直是处于亏损当中，自 2017 年至今年上半年，累计亏损超过 46.6 亿元。</p>",
    "publish_time": "2024-09-05 17:30:59",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "拒绝“零和”游戏！腾讯新一代混元Turbo降价 50%，RAG方案支持快速定制AI应用",
    "url": "https://www.infoq.cn/article/TwHb0T8fqBUBMIe2Jrzi",
    "summary": "<p>“增长是企业当下最重要的事。以数提效、顺势而为、扬帆出海是企业破局增长的三个方向。”</p><p></p><p>9月5日，在2024腾讯全球数字生态大会上，腾讯集团高级执行副总裁、云与智慧产业事业群CEO汤道生表示，当下很多企业面临内外部多重挑战，甚至陷入“内卷式竞争”，但如果蛋糕不增长，结果就是“零和”游戏。企业增长的核心在于跳出框架，探索产业的新发展。</p><p></p><p>汤道生表示，第一个增长方法是以数提效，聚焦核心场景。“指望大模型给一般企业在短期内带来巨大变化并不现实。用人工智能在已有业务场景中降本增效，提高经营效率，是行稳致远的可靠路径。”</p><p></p><p>第二个增长思路是抓住新产业机会。汤道生特别强调，“如果芯片或硬件设备是计算的躯体，那软件就是脑袋。软件往往定义了硬件发展的方向，让硬件设备释放出更大价值。”</p><p></p><p>第三个增长机会是开拓全球市场。相关机构调研显示，90%的中国企业对拓展海外业务有兴趣，有近四分之一的企业，将出海列为未来1到3年的首要任务之一。腾讯云可以提供包括音视频、边缘加速、云原生产品、大数据与数据库、安全与合规、AI等技术产品能力。</p><p></p><p></p><h1>新一代混元Turbo定价低 50%，推理效率提升一倍</h1><p></p><p>大会上，腾讯宣布推出“混元Turbo”，相比前代模型性能显著提升，训练效率提升108%，推理效率提升 100%，推理成本降低 50%，效果在多个基准测试上对标GPT-4o。</p><p></p><p>作为新一代旗舰大模型，腾讯混元Turbo在语言理解、文本创作、数学和代码等领域都有较大提升，跟前代模型相比，复杂数学解决能力提升38%，代码能力提升32%。</p><p></p><p>目前，混元Turbo已经在腾讯云上线，输入和输出价格只有前代模型的一半。企业和开发者可以通过API、专属模型、精调模型等方式使用混元大模型相关能力。</p><p></p><p>汤道生表示，随着大模型与生成式AI的技术突破，图片、视频、语言的理解与生成已经有很大进步，人与人的沟通、人与系统的交互方式，都可能会被重塑。最近半年，产业界对AI大模型的关注重点，开始从模型技术本身，转到智能应用落地上。用人工智能在已有业务场景中降本增效，提高经营效率，是行稳致远的可靠路径。</p><p></p><p>据介绍，腾讯已经构建起了全链路的大模型产品矩阵，包括底层基础设施、帮助企业训练专属模型的TI平台和行业大模型解决方案、自研的混元大模型、构建应用的平台工具，以及基于大模型的各类智能应用。</p><p></p><p>此外，腾讯元宝品牌智能体专区正式上线，首批邀请 11 家合作伙伴入驻，打造精品AI智能体应用生态，涵盖工作提效和生活娱乐多个场景，用户可以直接在“腾讯元宝”APP上体验丰富的品牌智能体应用。“面向场景创造价值才是大模型发展的意义。”腾讯云副总裁、腾讯云智能负责人、优图实验室负责人吴运声表示。</p><p></p><p>腾讯云还宣布推出AI infra品牌“腾讯云智算”，整合了腾讯云高性能计算HCC、高性能网络IHN星脉、高性能云存储、加速框架、容器、向量数据库、智算套件等腾讯云优势产品，能够为AI输出性能领先、多芯兼容、灵活部署的智算产品能力。</p><p></p><p></p><h1>推出RAG解决方案，支持“量身定制”AI大模型应用</h1><p></p><p>大会上，腾讯集团副总裁、云与智慧产业事业群COO兼腾讯云总裁邱跃鹏在会上发布腾讯云RAG解决方案，帮助企业结合自身信息知识、快速打造大模型应用。</p><p></p><p>据介绍，腾讯云RAG解决方案包含兼容Elastic开源生态的腾讯云智能搜索（腾讯云Elasticsearch Service ）、以及腾讯云自研的向量数据库，便于企业根据自身架构、数据类型、技术生态灵活选择。</p><p></p><p>其中，腾讯云智能搜索提供从模型管理、向量生成、向量存储、混合搜索、结果重排到LLM大模型集成的一站式RAG能力，企业仅用Elastic一套技术栈就能快速构建AI应用；针对数据规模大、数据类型多样的企业，腾讯云向量数据库提供2倍于业界平均水平的吞吐能力，毫秒级的响应延迟，以及千亿级的单表存储规模，构建企业的AI数据中台，打造RAG应用基础设施。</p><p></p><p>例如，腾讯云智能搜索成功支持了微信读书“AI问书”功能上线，为亿级用户提供毫秒级别的检索服务，同时相比传统单点解决方案降低了90%的机器成本。借助腾讯云向量数据库，学而思实现了在亿级的资料库中毫秒级完成检索，同时检索的准确率达到了95%，大大提升了学而思学习机的语音检索体验。</p><p></p><p>“大模型和云是密不可分的，大模型在云上训练，同时大模型能力通过云向外输出；另一方面，云产品也通过与大模型的深度融合，显著的增强能力，通过这样不断地迭代，让客户在云上获得更全面的业务增长。”</p><p></p><p>邱跃鹏表示，云和大模型越来越深度捆绑到一起，腾讯云也持续打磨云上大模型取用体验。例如，基于混元大模型打造的腾讯云AI代码助手目前已经覆盖腾讯集团内部超过50%的程序员，编码时间平均缩短了40%。腾讯会议的智能录制、AI小助手、多语言翻译等AI能力，每月助力超过1500万用户提升协作效率，也在和更多场景深度结合。</p><p></p><p></p><h1>腾讯云三大数字化产品体系</h1><p></p><p>数字化正在成为创新增长的核心引擎，AI大模型正在产业中加速落地，自主创新软件成为场景提效的核心，而云端也成为企业国际化的重要载体。面向智能化、国际化、融合创新三大领域，大会上，腾讯云联合30家合作伙伴，共同发布了一系列针对具体行业应用场景的数字化解决方案。</p><p></p><p>腾讯云在大会上公布了完整的融合创新产品体系，助力产业转型升级。在基础软件领域，数据库TDSQL、操作系统TencentOS、专有云TCE、大数据TBDS、人工智能开发平台TI等核心产品（简称“5T”），兼容国内主流的芯片厂商，在多个大规模的集群上稳定运行，落地覆盖金融、交通、政务、互联网、医疗、传媒等多个行业。</p><p></p><p>基础软件之外，腾讯的系列自研应用软件如腾讯会议、企业微信、腾讯文档、腾讯乐享等，凭借腾讯产品积累超过20年的用户服务经验，具有便捷的交互体验与服务界面、独特的C2B连接能力。腾讯会议等产品在多个行业头部客户渗透率超过了50%。</p><p></p><p>本次大会上，腾讯云首次披露了企业出海数字化解决方案全景图，包括云原生、音视频、边缘加速、大数据与数据库、安全与合规等技术和产品能力，覆盖游戏、社交互娱、跨境电商、消费电子、金融科技、在线教育、汽车出行等七大行业的全球化实践。</p><p></p><p>其中，腾讯云边缘安全加速平台EdgeOne将服务器的端到端 HTTP/HTTPS 访问时延降低了30%，中国前十大出海音视频社交应用里有八家在用EdgeOne。腾讯会议的海外会议数较年初增长将近50%，面对全球各地差异化的网络、多语言环境，腾讯会议自研了AI降噪算法、Penguins AI语音引擎，上线多语言实时翻译等功能，助力用户流畅无障碍开会。</p><p></p><p>目前，腾讯产业互联网的生态伙伴数量突破11000家，共同服务的客户总数超过200万家。三年间，年收入达到百万级的伙伴数量增长了150%；腾讯会议等SaaS伙伴的收入过去两年也翻了4.5倍。</p><p></p><p>在企业出海方面，腾讯云泛互行业出海业务的增速超过70%，智能制造、新能源汽车等产业出海也快速增长。腾讯集团副总裁、腾讯智慧出行总裁钟翔平表示，作为汽车智能化产业链的重要一环，腾讯已经与超过100家车企和出行科技公司合作，九成的车企选择了腾讯云。</p><p></p><p></p><p></p><p></p>",
    "publish_time": "2024-09-05 18:11:31",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]