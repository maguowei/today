[
  {
    "title": "微软更新其Well-Architected框架",
    "url": "https://www.infoq.cn/article/zJqBVpZMmwo8viWXFcpu",
    "summary": "<p>微软最近宣布全面更新用于在Azure上设计和运行优化工作负载的<a href=\"https://learn.microsoft.com/en-us/azure/well-architected/\">Well-Architected框架（Well-Architected Framework，WAF）</a>\"。</p><p>&nbsp;</p><p>微软的WAF是一套质量驱动原则、架构决策点和审查工具，其目标是帮助解决方案架构师为其工作负载建立技术基础。此次更新不仅为用户工作负载的架构权衡提供了指导，而且还就如何在组织范围内实施这一指导提供了更精确的说明。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bf/bf38cd49b568bfd5c0488376d468d94a.png\" /></p><p></p><p>Well-Architected框架的更新概述（图片来源：<a href=\"https://learn.microsoft.com/en-us/azure/well-architected/\">微软网站</a>\"）</p><p>&nbsp;</p><p>微软公司的副总裁<a href=\"https://www.linkedin.com/in/ulrichhomann/\">Uli Homann</a>\"这样写道：</p><p></p><blockquote>在过去的六个月中，微软的云解决方案架构师通过整理10000多个利用WAF及其评估的项目所得到经验和教训，更新了Well-Architected框架。现在，Well-Architected框架的所有五大支柱都采用了通用的结构，均由设计原则、设计审查清单、权衡、建议指南和云设计模式组成。</blockquote><p></p><p>&nbsp;</p><p>设计原则提出了面向目标的原则，为工作负载奠定了基础；设计审查清单粗略定义了已成文的建议，以便于推动行动的开展；权衡描述了与其他支柱之前的取舍。同时，建议指南是与一个或多个设计审查清单相关联的，而云设计模式则提供了经过验证的通用架构模式。</p><p>&nbsp;</p><p>此次更新尤其关注作为“<a href=\"https://learn.microsoft.com/en-us/assessments/azure-architecture-review/\">Well-Architected审查评估</a>\"”一部分的“核心Well-Architected审查”，现在它与Well-Architected框架中的新内容保持一致。此外，正如<a href=\"https://learn.microsoft.com/en-us/azure/well-architected/whats-new#well-architected-framework-assessments\">文档</a>\"所述，每个支柱中的每个问题都与该支柱的设计审查清单相对应。所有问题的选项都与相关检查清单条目的推荐指南相关联。</p><p>&nbsp;</p><p>微软架构内容负责人<a href=\"https://www.linkedin.com/in/stephen-t-sumner/\">Stephen Sumner</a>\"在一篇Azure的架构博客中解释说：</p><p></p><blockquote>评估更新以通用工作负载设计的最佳实践为目标。你可以在任何平台的任何工作负载上运行评估，而不仅仅是Azure中的工作负载。评估在更深的技术层面涵盖了工作负载的更多方面。</blockquote><p></p><p>而且：</p><p></p><blockquote>相对于上一版的评估，它增加了20多条建议（总计375条），但是它也减少了124个选项。这意味着你只需更少的输入，就能获得更具针对性的指导。</blockquote><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4a/4ade9d6239caccdf2b0a2f51a9d10630.png\" /></p><p></p><p>Well-Architected评估的样例（图片来源：<a href=\"https://techcommunity.microsoft.com/t5/azure-architecture-blog/azure-well-architected-review-assessment-updates/ba-p/3981023\">微软架构博客</a>\")</p><p>&nbsp;</p><p>另外的两大云提供商AWS和Google也通过Well-Architected框架为其平台提供指导。此外，AWS最近<a href=\"https://www.infoq.com/news/2023/04/aws-well-architected-framework/\">更新</a>\"并<a href=\"https://www.infoq.com/news/2023/11/aws-well-architected-framework/\">重构</a>\"了其<a href=\"https://aws.amazon.com/architecture/well-architected/\">Well-Architected框架</a>\"。</p><p>&nbsp;</p><p>最后，你可以通过名为“Well-Architected框架的新变化”的<a href=\"https://www.youtube.com/watch?v=XV_E4WtqNrE\">视频</a>\"了解有关更新的更多详情。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/11/azure-well-architected-framework/\">Microsoft Refreshes Its Well-Architected Framework</a>\"</p>",
    "publish_time": "2023-11-29 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "全方位深度测评 AI 代码助手 Amazon CodeWhisperer",
    "url": "https://www.infoq.cn/article/W5RzCzfZ6imJQrCk2lW9",
    "summary": "<p></p><h3>背景</h3><p></p><p></p><p>随着互联网技术的不断发展，<a href=\"https://so.csdn.net/so/search?q=%E7%A8%8B%E5%BA%8F%E5%91%98&amp;spm=1001.2101.3001.7020\">程序员</a>\"们面临着越来越多的挑战，如代码复杂度不断提高、代码错误难以避免、团队协作效率低下等。传统的开发工具已经无法满足程序员们的需求，因此这几年基于人工智能技术的代码助手应运而生。AI代码助手的目的是通过自动化的方式帮助程序员提高开发效率、减少错误、提高代码质量，同时还可以帮助程序员快速学习新技术、更快，更安全地构建应用程序，提高团队协作效率。可以说AI代码助手成为当今软件开发领域的重要趋势之一。本篇文章就来深度测评一下AI 代码助手&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer</a>\"。</p><p></p><h3><a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer 介绍</a>\"</h3><p></p><p></p><p>Amazon CodeWhisperer&nbsp;是亚马逊云科技推出的AI代码助手，目的是帮助开发者更快，更安全地构建应用程序。作为智能编程助手，它经过了非常多的优秀开源代码训练，参与训练的代码都是具有良好的扩展性，安全性，优雅等特点，利用它编写的代码能够很快地写出健壮，优雅，具有很高扩展性的代码。 此外它还可以扫描代码来检测难以发现的漏洞，获取代码建议来立即修复漏洞。总的来说它具有以下特性：</p><p></p><h4>特性</h4><p></p><p>实时生成代码片段或全函数的代码建议获取相关开源项目的存储库信息扫描代码漏洞，给出修复建议支持 Python，Java，JavaScript 等15中编程语言支持 VS Code，IntelliJ IDEA，Amazon Cloud9、Amazon Lambda 控制台、JupyterLab 和 Amazon SageMaker Studio 等集成开发环境</p><p>以上就是&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer</a>\"&nbsp;的介绍，下面进入正在的测评阶段。</p><p></p><p>主要从以下几方面进行测评：</p><p>用户体验 （包括，安装，配置，文档资料）功能使用（包括，上手难度，使用复杂度，安全，准确度）场景实践（以具体业务场景体验功能）</p><p>安装，配置也是测评的一部分，下面就从最开始的安装开始体验。</p><p></p><h3>安装配置&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer</a>\"</h3><p></p><p></p><p>本次安装使用的在 Windows 10 的 VS Code 上进行的。作为 AI 智能代码助手，它是以 IDE 插件的方式存在的。这样能够很好地与 IDE 相关功能无缝结合。提升开发效率，增强用户体验。</p><p>打开 VS Code，在插件列表中搜索&nbsp;&nbsp;Amazon Toolkit</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f6/f6001aab889f12da44c240e236b393a0.png\" /></p><p></p><p>找到名称为&nbsp;Amazon Toolkit&nbsp;的插件，点击 Install 按钮进行安装。有时安装后，需要重载一下 VS Code 才能用。</p><p></p><p>笔者写这篇文章时，Amazon Toolkit 最新的版本是&nbsp;1.91.0，如果有读者安装的与笔者的功能不同，请检查下版本是否一致。以下是该插件的一些基本信息：</p><p></p><p>版本：1.91.0</p><p>下载次数：1,663,326</p><p>Git仓库：<a href=\"https://github.com/aws/aws-toolkit-vscode\">amazon-toolkit-vscode</a>\"</p><p>插件地址：<a href=\"https://marketplace.visualstudio.com/items?itemName=AmazonWebServices.aws-toolkit-vscode\">Amazon Toolkit</a>\"</p><p>开源协议：<a href=\"https://marketplace.visualstudio.com/items/AmazonWebServices.aws-toolkit-vscode/license\">Apache License Version 2.0</a>\"</p><p>从下载次数来看，Amazon Toolkit 是一个非常受欢迎的插件。</p><p></p><p>在安装完成后，你可以在左侧的侧边栏，看到一个 Amazon 的图标，点击它就会出现插件的面板。如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cf/cf5282612c54c8bbfe19fc90a4330893.png\" /></p><p></p><p>该插件主要包括三种功能：</p><p>Amazon CodeCatalyst 统一的软件开发服务，可在 Amazon 上快速构建和交付应用程序。CDK 云应用程序资源<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer</a>\"&nbsp;智能代码助手。</p><p></p><p>要使用这些功能，需要用户先连接 Amazon 服务。</p><p>当我们需要使用&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer</a>\"， 只需要点击 CodeWhisperer 下的 Star 按钮，然后再点击 Sign in 按钮，如下图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1e/1eef9b4b08c3caf3531f5de0359ea4ef.png\" /></p><p></p><p>如果你没有 Amazon 账号，也没关系，点击按钮后，会弹出一个重定向弹窗，点击 Proceed To Brower，使用浏览器继续。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0d/0dfbfdcf8bf635a46abd91a6d1c87101.png\" /></p><p></p><p>点击按钮会 页面显示大致如下</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/38/38a25646300243dc95df751500b13575.png\" /></p><p></p><p>点击确认并继续</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/00/001bf944dc6ac743c9447bda273ba7d3.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/af/af604608b158437bc40c52737e655a4b.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0d/0d1b5f33d305b5bcc8814fb78275e49d.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/22/22751317effcc0fd3da7517310242f5b.png\" /></p><p></p><p>总体步骤就是，输入邮箱，姓名 → 验证邮箱 → 填写密码 → 允许 Amazon Toolkit 访问数据</p><p>整体流程非常顺畅，安装，配置三分钟内就能完成。</p><p>授权后，插件就开始工作了。我们也可以开始愉快地工作了。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/04/049a734c47975b7b61254a680a2ea7a7.png\" /></p><p></p><p>此外值得一提的是，该插件还提供了一种专业版的功能，不过要配置 IAM 身份中心，这部分我们暂时不表。</p><p></p><p>在安装并配置&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer</a>\"&nbsp;后，在编码时会自动开启代码建议。同时你也可以收到去获取代码建议。在 Windows 平台的 VS Code 上，使用 Alt + C 键，使用 Tab 键来插入当前的建议代码块。使用左右键来切换代码块。</p><p></p><h3>具体场景</h3><p></p><p></p><p>下面我们在具体的场景中来体验&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer</a>\"。</p><p></p><h4>使用&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Code Whisperer</a>\"&nbsp;开发数据可视化图表</h4><p></p><p></p><p>场景一：作为一名前端开发者，我们经常会遇到使用图表库开发一些可视化的图表，比如使用 Echarts 来开发一个折线图。</p><p></p><p>我们创建一个简单的 html，在页面内写入必要的信息，并在 script 标签中写入注释：</p><p></p><p><code lang=\"text\"></code></p><p></p><p>然后按下 Alt + C 键，这时在 VS Code 会调出，html is currently not supported by CodeWhisperer。</p><p>如下图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f2/f2da98c8bac8acc7f71497714af82c2d.png\" /></p><p></p><p>目前&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">CodeWhisperer</a>\"&nbsp;还不支持 html 文件的代码建议。所以我们需要先创建一个 js，然后在 html 文件中引入。</p><p></p><p>我们在 js 文件中，使用注释写下需要实现的功能，然后按下 Alt + C 键。就会出现如下图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/71/716980467f988fd2dcdacba2d6a3d3bf.png\" /></p><p></p><p>在检查过给出的建议代码后，确定是我们需要的，按下 Tab 键，来获取插入当前区域。</p><p>更加具体的交互可以先下面的动图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d2/d22e5bdeb330a5005e81a78905ad46c3.gif\" /></p><p></p><p>这是一个非常实用的场面，避免了花费大量时间去查询 Echarts 文档。要知道 Echarts 的配置文档是非常多的。下图是密密麻麻的 Echarts 图表配置项：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f0/f009865a68020e1730d96b161fc79a89.png\" /></p><p></p><p></p><h4>编写一个 Python 的浏览器自动化脚本</h4><p></p><p></p><p>作为一名开发人员，我们经常会遇到一些重复的工作，比如这样一个场景，在某个网站上有一个销售榜单，我们需要实时监控这个表单，并将每天的数据汇总发到邮箱里。对于这样的重复性没有技术含量的工作，我们通常使用脚本来编写自动化脚本。下面我们就使用&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer</a>\"&nbsp;来编写一个这样的脚本，看看它是否能够帮助我们快速实现功能。</p><p></p><p>创建一个 auto-run.py 的文件，在文件里引入 selenium，并且使用代码注释写下要实现的功能，按下 Alt + C 键。交互动图如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/72/72dc7a512bd67b79380a853d44a65105.gif\" /></p><p></p><p>根据动图大家可以看到，当按下 Alt + C 键时，只提供了一行代码建议，在按下左箭头键后，出现了四行的代码建议。整个流程是非常快速的。</p><p></p><p>给出的代码建议地完整地实现了， 使用 webdriver 打开 Chrome 浏览器，并且访问百度首页，但在输入关键词时，却把\"拿我格子衫\" 写成了“拿战校衫”。个人猜测是由于中文在大模型中有偏差造成的。换成英文就无此问题。</p><p></p><p>使用&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer</a>\"&nbsp;时，代码建议是非常快速的，这个快，除了靠个人感觉来评估，也有一些更为准确的数字来评估。<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer</a>\"&nbsp;提供了一个日志面板，我们可以在 VS Code 的 Setting 配置面板里，找到 Amazon Toolkit 的配置项，找到 Log Level，将其调整为 debug。如下图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f5/f57ad175da4f88acfaa7ca349b5a8e18.png\" /></p><p></p><p>调整后，我们选中 OUTPUT 面板，并将输出选位 Amazon Toolkit Logs，如下图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9b/9b2ea6250202ee1d78e1fe58cace1c75.png\" /></p><p></p><p>当我们在编辑器中按下 Alt + C 键，底部的日志面板会打印出整个流程的日志：</p><p>打印信息大致如下</p><p></p><p><code lang=\"text\">2023-09-25 11:36:41 [DEBUG]: command: running \"aws.codeWhisperer\"\n2023-09-25 11:36:41 [DEBUG]: command: running \"_aws.auth.autoConnect\"\n2023-09-25 11:36:41 [VERBOSE]: telemetry: emitted metric \"vscode_executeCommand\"\n2023-09-25 11:36:41 [DEBUG]: codewhisperer: Connection expired = false,\n                           secondaryAuth connection expired = false,\n                           connection is undefined = false\n2023-09-25 11:36:41 [DEBUG]: codewhisperer: isValidCodeWhispererConnection = true\n2023-09-25 11:36:41 [VERBOSE]: telemetry: emitted metric \"vscode_executeCommand\"\n2023-09-25 11:36:41 [DEBUG]: CodeWhisperer finished fetching crossfile context out of 0 files\n2023-09-25 11:36:41 [DEBUG]: CodeWhispererSupplementalContext:\n    isUtg: false,\n    isProcessTimeout: false,\n    contentsLength: 0,\n    latency: 0.2452000007033348,\n\n2023-09-25 11:36:41 [DEBUG]: SSO token cache: loaded key: 5fa44ff1-8f20-4ed5-89be-548baeb748aa\n2023-09-25 11:36:42 [DEBUG]: Request ID: db72446b-5ee6-439f-af87-87800aa93d90,\n                timestamp(epoch): 1695613002378,\n                timezone: Asia/Shanghai,\n                datetime: 9/25/2023, 11:36:42 AM,\n                vscode version: '1.82.2',\n                extension version: '1.91.0',\n                filename: 'hello-selenium.py',\n                left context of line:  '',\n                line number: 2,\n                character location: 0,\n                latency: 1047.5229000002146 ms.\n2023-09-25 11:36:42 [VERBOSE]: Recommendations:\n2023-09-25 11:36:42 [VERBOSE]: [0]\ndriver = webdriver.Chrome()\n2023-09-25 11:36:42 [VERBOSE]: telemetry: emitted metric \"codewhisperer_serviceInvocation\"\n2023-09-25 11:36:42 [DEBUG]: SSO token cache: loaded key: 5fa44ff1-8f20-4ed5-89be-548baeb748aa\n2023-09-25 11:36:42 [VERBOSE]: telemetry: emitted metric \"codewhisperer_perceivedLatency\"\n2023-09-25 11:36:43 [DEBUG]: Request ID: b69b0f19-bf91-4fe3-b335-96268b567126,\n                timestamp(epoch): 1695613003423,\n                timezone: Asia/Shanghai,\n                datetime: 9/25/2023, 11:36:43 AM,\n                vscode version: '1.82.2',\n                extension version: '1.91.0',\n                filename: 'hello-selenium.py',\n                left context of line:  '',\n                line number: 2,\n                character location: 0,\n                latency: 1041.122000001371 ms.\n2023-09-25 11:36:43 [VERBOSE]: Recommendations:\n2023-09-25 11:36:43 [VERBOSE]: [0]\ndriver = webdriver.Chrome()\ndriver.get(\"http://www.baidu.com\")\ndriver.find_element_by_id(\"kw\").send_keys(\"拿战校衫\")\ndriver.find_element_by_id(\"su\").click()\n2023-09-25 11:36:43 [VERBOSE]: [1]\ndriver = webdriver.Chrome()\ndriver.get(\"http://www.baidu.com\")\ndriver.find_element_by_id(\"kw\").send_keys(\"拿战校衣\")\ndriver.find_element_by_id(\"su\").click()</code></p><p></p><p>根据打印日志的信息，基本的流程大致是这样的：</p><p></p><p>时间戳：2023-09-25 11:36:41，日志以DEBUG级别开始，表示调试信息。命令执行：运行\"aws.codeWhisperer\"和\"_aws.auth.autoConnect\"两个命令。遥测数据：emitted metric “vscode_executeCommand”，表示执行了一个 VS Code 命令。检查&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">CodeWhisperer</a>\"&nbsp;连接状态：isValidCodeWhispererConnection为true，连接有效。检查&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">CodeWhisperer</a>\"&nbsp;获取 crossfile 上下文的结果：完成从一个文件中获取crossfile上下文。检查&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">CodeWhisperer</a>\"&nbsp;补充上下文信息： isUtg 为 false，isProcessTimeout 为 false，contentsLength 为0，latency 为0.245秒。SSO令牌缓存：加载了SSO令牌缓存的键值对。请求ID、时间戳、时区、日期时间、VS Code 版本、扩展版本、文件名、行号、字符位置、延迟等信息被记录。推荐建议：[0]，建议使用 webdriver.Chrome() 来创建一个 Chrome 浏览器驱动对象。遥测数据：emitted metric “codewhisperer_serviceInvocation”，表示服务调用的度量数据。…</p><p></p><p>使用 token 发起的 Request，整个请求中包含了这些信息：</p><p></p><p><code lang=\"text\">timestamp(epoch): 1695613003423,\ntimezone: Asia/Shanghai,\ndatetime: 9/25/2023, 11:36:43 AM,\nvscode version: '1.82.2',\nextension version: '1.91.0',\nfilename: 'hello-selenium.py',\nleft context of line:  '',\nline number: 2,\ncharacter location: 0,\nlatency: 1041.122000001371 ms.</code></p><p></p><p>其中有一个指标是 latency，表明延迟，即从用户按下 Alt+ C 键，到代码块出现这段时间。可以看到生成4行代码只用了 1s 左右，非常的迅速。</p><p></p><p>通过上述的两个实战案例，相信大家已经了解&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer</a>\"&nbsp;的常规使用。在使用时需要以下几点</p><p></p><h4>使用时注意点</h4><p></p><p></p><p>实现功能需要提供一些上下文，比如使用的库和功能注释最好使用英文，中文可能出现乱码或繁体使用左箭头键和右箭头键选择最合适的代码块html 和 yaml 文件暂时不支持</p><p></p><p>另外在使用的过程中，发现了一个不知是 VS Code 的问题还是插件的问题，就是在用鼠标切换代码建议时，当前索引没有改变，详见下图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/52/5251601e3e9e3553667a3607f4d627bc.gif\" /></p><p></p><p>根据上图 可以看到 切换代码建议，&nbsp;1/5&nbsp;一直都没有变， 用户无法感知当前显示的是第几个代码块。</p><p></p><h4>插件代码解析</h4><p></p><p></p><p>为了更加了解这个产品，我仔细阅读了该插件的源码，它的代码托管在 GitHub，主要功能代码存放在&nbsp;src/codewhisperer&nbsp;目录里。</p><p></p><p>Amazon CodeWhisperer 的插件入口在此处，<a href=\"https://github.com/aws/aws-toolkit-vscode/blob/master/src/codewhisperer/views/securityPanelViewProvider.ts\">https://github.com/aws/aws-toolkit-vscode/blob/master/src/codewhisperer/views/securityPanelViewProvider.ts</a>\"</p><p>这段代码是一个名为&nbsp;SecurityPanelViewProvider&nbsp;的类，它实现了&nbsp;vscode.WebviewViewProvider&nbsp;接口。这个类主要用于在 Visual Studio Code 中打开一个特定的文件并在安全扫描面板中显示代码扫描结果。</p><p></p><p>以下是该类的主要方法和功能：</p><p></p><p>makeUri(...args: Parameters): vscode.Uri：&nbsp;这个方法用于根据给定的路径和行号范围创建一个 URI，用于在 openEditorAtRange 方法中打开编辑器。</p><p>openEditorAtRange(path: string, startLine: number, endLine: number)：&nbsp;这个方法接受一个文件路径和开始、结束行号，然后在 VS Code 中打开该文件并在指定的行范围内高亮显示问题。</p><p>persistLines()：&nbsp;这个方法用于持久化处理过的行信息。</p><p>addLines(securityRecommendationCollection: AggregatedCodeScanIssue[], editor: vscode.TextEditor | undefined)：&nbsp;这个方法用于将扫描结果添加到安全面板中，并更新视图。</p><p>update()：&nbsp;这个方法用于更新视图，将处理好的HTML内容设置到 webview 中。</p><p>persistLine(panelSet: SecurityPanelSet, index: number)：&nbsp;这个方法用于持久化单个处理过的行信息。</p><p>addUnclickableWarningItem(item: SecurityPanelItem) 和 addUnclickableInfoItem(item: SecurityPanelItem)：&nbsp;这两个方法分别用于添加不可点击的警告项和信息项。</p><p>addClickableWarningItem(item: SecurityPanelItem) 和 addClickableInfoItem(item: SecurityPanelItem)：&nbsp;这两个方法分别用于添加可点击的警告项和信息项，它们会生成一个包含文件路径和行号范围的 URI，并将其设置为链接的 href 属性，以便用户可以点击查看文件并在 VS Code 中打开。</p><p></p><h4>学习资料与文档</h4><p></p><p></p><p>虽然 Amazon CodeWhisperer 使用起来非常简单，但官方还是提供了很多学习资料，覆盖各个阶段的学习者。</p><p>如果你想要获取更多有关它的资料 可以查阅官方文档&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/\">https://aws.amazon.com/cn/codewhisperer/</a>\"下面是几篇帮助你快速了解 Amazon CodeWhisperer 的视频教程。</p><p><a href=\"https://dev.amazoncloud.cn/video/videoDetail?id=6445fcdec9a819396b2fe24a\">利用 VS Code 开始使用 Amazon CodeWhisperer</a>\"</p><p><a href=\"https://dev.amazoncloud.cn/video/videoDetail?id=6445fa2413eafe780ecafaac\">利用 Amazon CodeWhisperer 创建基于 Python 的事件驱动型 Serverless App</a>\"</p><p><a href=\"https://dev.amazoncloud.cn/video/videoDetail?id=6445fb816afa68650f58e0df\">利用 Amazon CodeWhisperer 创建基于 Java 的事件驱动型 Serverless App</a>\"</p><p></p><h3>总结</h3><p></p><p></p><p>总的来讲，<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer</a>\"&nbsp;是一款非常优秀的智能编程助手，它能够理解代码的功能和结构，并根据这些信息自动生成注释。这有助于提高代码的可读性和可维护性，同时也能帮助开发人员更好地理解他们正在编写的代码。</p><p></p><p>本文介绍了<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer</a>\"&nbsp;的背景和特性，并测评了它在实际开发场景中的优秀表现。此外，也给出了一些&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer</a>\"&nbsp;的教程视频。</p><p></p><p>总之，<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer</a>\"&nbsp;是一种借助AI大模型创新性的工具，它有助于改善代码质量和软件开发效率，并帮助开发人员更快速，更安全地开发应用，大家快快用起来，也期待&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer</a>\"&nbsp;能够更新更多的功能。</p>",
    "publish_time": "2023-11-29 10:40:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "楷同科技有限公司 CEO 黄益聪确认出席 QCon 上海，分享基于时间序列数据预测模型的智能量化交易系统性能优化实践",
    "url": "https://www.infoq.cn/article/r14f5E9kJAxbaN7dMWdS",
    "summary": "<p><a href=\"https://qcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=8&amp;utm_term=1129&amp;utm_content=huangyicong\">QCon 全球软件开发大会</a>\"，将于 12 月在上海召开。快手基础平台部系统软件中心 / 系统软件负责人熊刚将发表题为《<a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5626?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=8&amp;utm_term=1129&amp;utm_content=huangyicong\">基于时间序列数据预测模型的智能量化交易系统性能优化实践</a>\"》主题分享，探讨系统全链路从数据采集 - 数据计算 - 模型预测 - 交易下单，全流程进行优化的实践，包括怎样高效的在 Java 处理计算 C++ 高频产生的时间序列数据，怎么降低高频产生、长生命周期数据对 Java GC 的影响等。</p><p></p><p><a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5626?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=8&amp;utm_term=1129&amp;utm_content=huangyicong\">黄益聪</a>\"，曾担任 Intel 高级工程师，阿里巴巴高级技术专家，中国互联网百强独角兽企业技术副总裁、CTO，有 15 项中国发明专利，3 项美国发明专利，专注于大数据与人工智能领域，AI 量化交易系统实践。他在本次会议的演讲内容如下：</p><p></p><p>演讲：基于时间序列数据预测模型的智能量化交易系统性能优化实践</p><p></p><p>金融市场的行情数据，如股票价格、成交量、交易队列等是典型的时间序列数据，具有很强的时间性和顺序依赖性。智能量化交易系统需要对市场上高频产生的时间序列数据进行处理计算，输入深度学习模型进行预测，执行交易策略，生成交易行为进行交易。整个过程需要覆盖全市场一万以上的品种，并且需要在很小的时间窗口，比如秒级完成。进一步的，我们使用了多语言进行系统开发。其中数据采集模块使用了 C++ 以达到高性能，交易策略引擎使用了 Java Spring Boot 搭建服务，AI 模型使用了 Python 基于 TensorFlow 和 Torch 框架。</p><p></p><p>业务需求的系统低延迟计算和多语言系统模块的交互，给我们的性能优化带来了挑战。这次分享，将带来我们对系统全链路从数据采集 - 数据计算 - 模型预测 - 交易下单，全流程进行优化的实践分享，包括怎样高效的在 Java 处理计算 C++ 高频产生的时间序列数据，怎么降低高频产生、长生命周期数据对 Java GC 的影响，怎么高效部署调用低延迟、多模型、多版本的 AI 模型预测服务，系统故障的数据断点快速恢复等。</p><p></p><p>演讲提纲：</p><p></p><p>背景与项目概况</p><p>○ 量化交易系统介绍</p><p>○ 项目技术架构</p><p>○ C++/ Java / Python 多语言交互</p><p>全链路数据流优化</p><p>○ 实时行情数据收集与处理</p><p>○ 低延迟、高吞吐性能挑战</p><p>○ 尝试的优化手段：GC Tuning，Direct Buffer</p><p>○ 我们的解决方案</p><p>○ 性能优化效果</p><p>服务化 AI 模型预测</p><p>○ Tensorflow 模型性能优化实践</p><p>○ Torch 模型转换</p><p>总结与展望</p><p>○ 复杂模型和低延迟预测性能的权衡</p><p>○ 目标展望：更快、更准</p><p></p><p>听众收益点：</p><p></p><p>○ 构建高性能、低延迟的智能量化交易系统</p><p>○ 多语言开发的复杂系统的全链路性能分析和优化</p><p>○ AI 模型在智能量化交易系统的实践</p><p></p><p>除上述演讲外，QCon 上海还将围绕&nbsp;<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart\">GenAI和通用大模型应用探索</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1596?utm_source=infoqweb&amp;utm_medium=teacherart\">AI&nbsp;Agent&nbsp;与行业融合应用的前景</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart\">LLM&nbsp;时代的性能优化</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart\">智能化信创软件&nbsp;IDE</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart\">面向人工智能时代的架构</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart\">性能工程：提升效率和创新的新方法</a>\"等专题进行交流。</p><p></p><p>QCon 上海 2023，相约 12 月！ 8 折优惠还剩最后 3 天，现在购票立减￥1360！咨询购票请联系：18514549229（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/0113b3dfb187d5f9988b7eb16d2e0594.png\" /></p><p></p>",
    "publish_time": "2023-11-29 11:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "聚焦 AI 和大数据，2023 全球 AI 前沿科技大会等你来打卡！",
    "url": "https://www.infoq.cn/article/TjHG4EwAoLByAMi0VWXz",
    "summary": "<p>大模型正在以前所未有的速度掀起创新型变革，站在时代的交叉路口，企业若想更好地洞察市场、提升生产效率、优化运营管理，无疑需要更大规模、更复杂的数据分析和 AI 应用进行支撑。</p><p></p><p>当数据和 AI 已经成为企业核心竞争力的重要组成部分，推进数据和 AI 基础设施的现代化便是企业数字化转型的重要举措。但摆在企业面前的挑战却层出不穷：</p><p></p><p>如何才能提升大规模数据处理能力？如何准确把握 AI 和大数据分析的最新落地实践与前沿趋势？又该如何解决 GPU 稀缺、数据工程复杂以及资源未充分利用等挑战？</p><p></p><p>上述提到的种种挑战都严重阻碍了数据价值的释放，然而，在这样的背景下，依旧不乏一批先行者与实践者率先找到了最佳实践路径。在 12 月 9 日的“2023 全球 AI 前沿科技大会”上，将为你奉上 AI 和大数据分析在不同行业的最新进展、趋势及对未来的展望。</p><p></p><p>此次大会由 Alluxio 与北京大学计算机学院、中关村融创企业开放创新促进会、中关村创业大街联合举办。</p><p>大会将邀请中国科学院院士梅宏、Databricks 和 Anyscale 联合创始人兼执行主席 Ion Stoica、Alluxio 创始人兼首席执行官李浩源、美国卡内基梅隆大学计算机学院软件研究所助理教授方飞、面壁智能联合创始人、CEO 李大海、Alluxio 创始成员兼开源社区副总裁范斌以及科大讯飞北京研究院副院长李家琦等国内外知名学者、企业技术专家，他们将围绕“智算加速，建瓴未来”这一主题，带来最佳实践与趋势洞察。</p><p></p><p>不仅大咖云集，本场大会的主会场内容还涵盖了 6 大前沿主题 +1 场圆桌会议，从数据基础设施软件基座到大模型应用探索，从面向未来的建设展望到挖掘大模型的无限潜能。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/55/550864d8bacfb28f6cfd714551aef00d.jpeg\" /></p><p></p><p>此外，还单独设置大数据分析专场 +AI/ML 专场。在【AI/ML】会场中，来自知乎、Shopee、快手、MemVerge、PingCAP、Alluxio 的 6 位嘉宾，将围绕 AI 场景中 Alluxio 加速模型训练与模型上线的实战经验展开分享；在【大数据分析】会场中，来自联通、Uber、微软、B 站、携程、Alluxio 的 6 位嘉宾将围绕大数据时代背景下，多样化应用与探索，为同行业其他品牌带来诸多应用借鉴。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f4/f405ef4156f658a1a46d6209abc71d7f.png\" /></p><p></p><p>众多专家齐聚，前沿趋势与最佳落地实践结合，相信这场理论与实践兼备的大会，定会让你不虚此行！如果你对前沿 AI 和大数据分析技术感兴趣，并期待收获一次沉浸式的学习体验，欢迎大家参与“2023 全球 AI 前沿科技大会”。</p><p></p><p>报名通道现已开启，欢迎扫描下方二维码提前占位，12 月 9 日 09:00-17:30，我们在北京中关村国家自主创新示范区会议中心，与你不见不散！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6d/6d9edfa411cd3a0823c4936862bea5e2.png\" /></p><p></p><p>不仅议程安排足够丰富，到场的小伙伴还会获得由 Alluxio 准备的 5 重精美礼品，品类多达 20+ 种，欢迎到场赢取惊喜哦～<a href=\"https://www.infoq.cn/form/?id=1928&amp;utm_source=gzh&amp;sign=iq_655f138c0be1e\">也可点击此链接，直接报名！</a>\"</p>",
    "publish_time": "2023-11-29 13:11:33",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "手把手教你在JavaScript中使用LangChain，解锁AI应用能力",
    "url": "https://www.infoq.cn/article/mtCjWCpbmQWGIbVjKcyE",
    "summary": "<p>JS 版的 LangChain，是一个功能丰富的 JavaScript 框架。不管你是开发者还是研究人员都可以利用该框架通过创建语言分析模型和 Agents 来开展各项实验。该框架还提供了十分丰富的功能设置，基于这些功能设置，NLP 爱好者可以通过构建自定义模型来提高文本数据的处理效率。与此同时，作为一个 JS 框架，开发人员可以轻松的将他们的 AI 应用集成到自己的 Web 应用中。</p><p></p><p></p><h2>环境准备</h2><p></p><p></p><p>安装下面的步骤，我们创建一个新目录并且安装 LangChain 的 npm 包：</p><p></p><p>1.执行如下命令，安装 LangChain 的 npm 包</p><p></p><p><code lang=\"null\">npm install -S langchain\n</code></p><p></p><p>2.在目录下面创建一个以.mjs 为后缀的文件（例如：test1.mjs）</p><p></p><p></p><h2>Agents（智体）</h2><p></p><p></p><p>在 LangChain 中，一个 Agent 代表的是一个具备理解和生成文本能力的实例。通过给这些 Agent 设置特定行为和数据源，就可以训练他们执行各种与语言相关的任务，从而使他们具备为更多的应用提供服务的能力。</p><p></p><p></p><h3>创建 LangChain 的 Agent</h3><p></p><p></p><p>利用 LangChain 框架创建的 Agent 在数据获取和响应优化上都支持“工具”的配置。请看下面的示例代码。该例中，Agent 体使用 Serp API（一个网络搜索 API）在互联网上搜索与输入内容相关的信息，然后根据搜索得到的内容完成响应数据的生成，与此同时，它还使用 llm-math 工具来执行诸如 转换单位、百分比对比等 数学运算任务。</p><p></p><p><code lang=\"null\">// langchain 智能体引入\nimport { initializeAgentExecutorWithOptions } from \"langchain/agents\";\n// 引入语言模型：OpenAi\nimport { ChatOpenAI } from \"langchain/chat_models/openai\";\n// 引入网络搜索工具\nimport { SerpAPI } from \"langchain/tools\";\n// 引入计算函数 工具\nimport { Calculator } from \"langchain/tools/calculator\";\n// OpenAI 的 API 访问的密钥\nprocess.env[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_KEY\"\n// SerpAPI 访问密钥\nprocess.env[\"SERPAPI_API_KEY\"] = \"YOUR_SERPAPI_KEY\"\n// 创建工具链\nconst tools = [new Calculator(), new SerpAPI()];\n// 模型配置，这里用的是 OpenAI gpt-3.5-turbo\nconst model = new ChatOpenAI({ modelName: \"gpt-3.5-turbo\", temperature: 0 });\n// 智能体初始化\nconst executor = await initializeAgentExecutorWithOptions(tools, model, {\n  agentType: \"openai-functions\",\n  verbose: false,\n});\n// 执行，这里给出的问题是：\"通过搜索互联网，找出自 2010 年以来 Boldy James 发行了多少张专辑，以及 Nas 自 2010 年以来发行了多少张专辑？找出谁发行了更多的专辑，并显示百分比的差异。\"\nconst result = await executor.run(\"By searching the Internet, find how many albums has Boldy James dropped since 2010 and how many albums has Nas dropped since 2010? Find who dropped more albums and show the difference in percent.\");\nconsole.log(result);</code></p><p></p><p>上述代码，在模型创建之后，通过 initializeAgentExecutorWithOptions 函数将模型和工具（SerpAPI 和 Calculator）进行合并，生成了一个 executor（执行者）。在输入端，我们要求 LLM（大语言模型） 通过搜索 Internet（使用 SerpAPI），找出自 2010 年以来，Nas 和 Boldy James 这两位艺术家中谁发行了更多专辑，并技术差值百分比（使用计算器）。</p><p></p><p>在该例子中，我通过明确地告诉 LLM“通过搜索互联网…”，以使它通过互联网获取最新数据，而不使用 OpenAI 的的默认数据（该数据截止 2021 年），从而得出正确答案。</p><p></p><p></p><blockquote>译者注：OpenAI于2023年11月2日发布会上，表示其模型数据已经更新到了2023年4月。</blockquote><p></p><p></p><p>下面是上面代码的输出：</p><p></p><p><code lang=\"null\">&gt; node test1.mjs从 2010 年至今，Boldy James 发了 4 张专辑，Nas 发了 17 张因此，Nas 比 Boldy James 发行的专辑要多，两者发行专辑的差值是 13我们将使用如下公式：(差值 / 总值)*100，来计算差值百分比在这里，差值是 13，总值是 17因此差值百分比是：(13/17)*100 = 76.47%所以，从 2010 年至今，Nas 发布的专辑比 Boldy James 多了 76。47%\n</code></p><p></p><p></p><h2>模型（Models）</h2><p></p><p></p><p>LangChain 中支持三种类型的模型使用方式：</p><p></p><p>LLM（大语言模型）Chat Model（对话模型）Embeddings（Embeddings 技术是一种将高纬数据转为低维数据的技术）</p><p></p><p>下面通过示例，我们一起来了解这三种模型的使用。</p><p></p><p></p><h3>语言模型</h3><p></p><p></p><p>LangChain 为 JavaScript 提供了使用语言模型能力，通过该能力 JS 可以根据文本输出生成文本输出。它不像聊天模型那么复杂，最适合处理简单的输入 - 输出的语言任务。下面是一个基于 OpenAI 模型的代码示例：</p><p></p><p><code lang=\"null\">import { OpenAI } from \"langchain/llms/openai\";\nconst llm = new OpenAI({\n  openAIApiKey: \"你自己的 OpenAI 的密钥\",\n  model: \"gpt-3.5-turbo\",\n  temperature: 0\n});\nconst res = await llm.call(\"List all red berries\");\nconsole.log(res);</code></p><p></p><p>如你所见，该例是要求 OpenAI 的 gpt-3.5-turbo 模型罗列所有的红色浆果。其中，我将 temperature 设为 0，其目的是为了确保 LLM 输出结果的准确性。下面是输出的结果：</p><p></p><p><code lang=\"null\">1. Strawberries\n2. Cranberries\n3. Raspberries\n4. Redcurrants\n5. Red Gooseberries\n6. Red Elderberries\n7. Red Huckleberries\n8. Red Mulberries</code></p><p></p><p></p><h3>对话模型</h3><p></p><p></p><p>如果你需要更复杂的答案和对话，则需要使用对话模型。对话模型在技术上与语言模型有何不同？好吧，用 LangChain 官方文档 的话来说：</p><p></p><p></p><blockquote>对话模型是语言模型的一个变体。虽然对话模型在底层使用的依然是大语言模型，但是他们在接口上略有不同。对话模型没有使用“文本输入、文本输出”格式的API，而是使用了一个基于“聊天消息”来实现输入输出的接口。</blockquote><p></p><p></p><p>下面是一个简单的 JavaScript 对话模型脚本（该示例相当无用但很有趣）。</p><p></p><p><code lang=\"null\">import { ChatOpenAI } from \"langchain/chat_models/openai\";\nimport { PromptTemplate } from \"langchain/prompts\";\n// 创建对话，配置密钥、模型版本、和 temperature\nconst chat = new ChatOpenAI({\n  openAIApiKey: \"YOUR_OPENAI_KEY\",\n  model: \"gpt-3.5-turbo\",\n  temperature: 0\n});\n// 通过提示词模版，创建提示词\nconst prompt = PromptTemplate.fromTemplate(`你现在扮演一个诗人的角色，在回答时请保持语言的韵律: {question}`);\nconst runnable = prompt.pipe(chat);\n// 对话执行\nconst response = await runnable.invoke({ question: \"Djokovic, Federer 和 Nadal，三人中谁是最好的网球运动员?\" });\nconsole.log(response);</code></p><p></p><p>如你所见，上面的代码首先发送了一条系统消息给对话机器人，告诉它，当前扮演的是一个诗人角色，且在回答的时候要始终使用押韵的方式。然后再向对话机器人发送一条用户消息，让它给出 Djokovic、Federer 和 Nadal 这三人中，谁是最好的网球运动员。如果你运行这个脚本，将会看到如下内容：</p><p></p><p><code lang=\"null\">// AI 消息体\nAIMessage.content:\n'In the realm of tennis, they all shine bright,\\n' +\n'Djokovic, Federer, and Nadal, a glorious sight.\\n' +\n'Each with their unique style and skill,\\n' +\n'Choosing the best is a difficult thrill.\\n' +\n'\\n' +\n'Djokovic, the Serb, a master of precision,\\n' +\n'With agility and focus, he plays with decision.\\n' +\n'His powerful strokes and relentless drive,\\n' +\n\"Make him a force that's hard to survive.\\n\" +\n'\\n' +\n'Federer, the Swiss maestro, a true artist,\\n' +\n'Graceful and elegant, his game is the smartest.\\n' +\n'His smooth technique and magical touch,\\n' +\n'Leave spectators in awe, oh so much.\\n' +\n'\\n' +\n'Nadal, the Spaniard, a warrior on clay,\\n' +\n'His fierce determination keeps opponents at bay.\\n' +\n'With his relentless power and never-ending fight,\\n' +\n'He conquers the court, with all his might.\\n' +\n'\\n' +\n\"So, who is better? It's a question of taste,\\n\" +\n\"Each player's greatness cannot be erased.\\n\" +\n\"In the end, it's the love for the game we share,\\n\" +\n'That makes them all champions, beyond compare.'</code></p><p></p><p></p><blockquote>译注：这是一首诗，实在翻译不来，就不翻译了哈。</blockquote><p></p><p></p><p></p><h3>Embeddings</h3><p></p><p></p><p>Embeddings 支持将文本数据转换为向量数据，以便于和其他相关的内容进行关联。这可能听起来有点抽象，让我们直接来看一个例子：</p><p></p><p><code lang=\"null\">import { OpenAIEmbeddings } from \"langchain/embeddings/openai\";\n\nprocess.env[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_KEY\"\n\nconst embeddings = new OpenAIEmbeddings();\n\nconst res = await embeddings.embedQuery(\"谁是万维网之父?\");\nconsole.log(res)</code></p><p></p><p>这里是数据返回，是一大串的浮点数据：</p><p></p><p><code lang=\"null\">[\n  0.02274114,  -0.012759142,   0.004794503,  -0.009431809,    0.01085313,\n  0.0019698727,  -0.013649924,   0.014933698, -0.0038185727,  -0.025400387,\n  0.010794181,   0.018680222,   0.020042595,   0.004303263,   0.019937797,\n  0.011226473,   0.009268062,   0.016125774,  0.0116391145, -0.0061765253,\n  -0.0073358514, 0.00021696436,   0.004896026,  0.0034026562,  -0.018365828,\n  ... 1501 more items\n]</code></p><p></p><p>这就是 Embeddings 的形态。仅仅是为了六个单词，就用了那么多浮点数！利用 Embeddings 技术，可以将输入文本与潜在答案、相关文本、名称等进行关联。</p><p></p><p>下面让我们来看一个 Embeddings&nbsp;模型的一个使用案例。</p><p></p><p>在下面的脚本中，我们向模型提问：“世界上最重的动物是什么？”。然后我们借助 Embeddings 技术让模型能从我们提供的参考答案中找出最佳答案。</p><p></p><p><code lang=\"null\">import { OpenAIEmbeddings } from \"langchain/embeddings/openai\";\n\nprocess.env[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_KEY\"\n\nconst embeddings = new OpenAIEmbeddings();\n// 余弦相似度函数\nfunction cosinesim(A, B) {\n    var dotproduct = 0;\n    var mA = 0;\n    var mB = 0;\n\n    for(var i = 0; i &lt; A.length; i++) {\n        dotproduct += A[i] * B[i];\n        mA += A[i] * A[i];\n        mB += B[i] * B[i];\n    }\n\n    mA = Math.sqrt(mA);\n    mB = Math.sqrt(mB);\n    var similarity = dotproduct / (mA * mB);\n\n    return similarity;\n}\n// 嵌入 1：蓝鲸是世界上最重的动物\nconst res1 = await embeddings.embedQuery(\"The Blue Whale is the heaviest animal in the world\");\n// 嵌入 2：乔治·奥威尔写了《一九八四》这本书\nconst res2 = await embeddings.embedQuery(\"George Orwell wrote 1984\");\n// 嵌入 3：随机内容\nconst res3 = await embeddings.embedQuery(\"Random stuff\");\n// 源内容数组\nconst text_arr = [\"The Blue Whale is the heaviest animal in the world\", \"George Orwell wrote 1984\", \"Random stuff\"]\n// 利用 embeddings 转换之后的数据数组\nconst res_arr = [res1, res2, res3]\n// 问题：世界上最重的动物是什么？\nconst question = await embeddings.embedQuery(\"What is the heaviest animal?\");\n// 相似度数组\nconst sims = []\nfor (var i=0;i<=\"\" code=\"\"></code></p><p></p><p><code lang=\"null\">在上面的代码中，先定义了一个计算相识度的函数：cosinesim(A, B)，其次利用 embeddings 技术将每个答案转换为了向量数据，接着使用 cosinesim 函数计算出了每个答案和输入问题的相识度值，最高拿到相识度最高的答案，完成输出。下面是输出的结果：</code></p><p></p><p><code lang=\"null\"><code lang=\"null\">The Blue Whale is the heaviest animal in the world\n// 蓝鲸是世界上最重的动物</code></code></p><p></p><p></p><h2><code lang=\"null\">Chunks（数据块）</code></h2><p></p><p></p><p><code lang=\"null\">由于 LangChain 模型在生产响应的时候不支持大文本的输入。所以需要用到诸如文本分割等数据分块的技术将大文本数据分割成多个 Chunk。下面我向你演示 LangChain 中两种简单的文本数据分割方法，以实现大文本输入。</code></p><p></p><p></p><h4><code lang=\"null\">方法一、CharacterTextSplitter</code></h4><p></p><p></p><p><code lang=\"null\">为了避免分割之后，Chunk 中内容中断，可以使用换行符来进行文本拆分，该方法是在每次出现换行符时执行分割，可以通过 CharacterTextSplitter 来实现，示例代码如下：</code></p><p></p><p><code lang=\"null\"><code lang=\"null\">import { Document } from \"langchain/document\";import { CharacterTextSplitter } from \"langchain/text_splitter\";// 创建一个分割器，使用换行符进行分割，每个区块的大小是 7，区块的重叠度是 3const splitter = new CharacterTextSplitter({  separator: \"\\n\",  chunkSize: 7,  chunkOverlap: 3,});const output = await splitter.createDocuments([your_text]);\n</code></code></p><p></p><p><code lang=\"null\">这是拆分文本的一种有用的方法，同时，你可以使用任何字符作为 Chunk 的分隔符，而不仅仅是换行符（\\n）</code></p><p></p><p></p><h4><code lang=\"null\">方法二、RecursiveCharacterTextSplitter</code></h4><p></p><p></p><p><code lang=\"null\">如果要严格按一定长度的字符拆分文本，可以使用 RecursiveCharacterTextSplitter 来实现，示例代码如下：</code></p><p></p><p><code lang=\"null\"><code lang=\"null\">import { RecursiveCharacterTextSplitter } from \"langchain/text_splitter\";const splitter = new RecursiveCharacterTextSplitter({  // chunk 的大小  chunkSize: 100,  // chunk 的重叠度  chunkOverlap: 15,});const output = await splitter.createDocuments([your_text]);\n</code></code></p><p></p><p><code lang=\"null\">在此示例中，会将文本按照每 100 个字符进行一次拆分，每个 Chunk 的重叠度为 15 个字符。</code></p><p></p><p></p><h4><code lang=\"null\">Chunk 的大小和重叠度</code></h4><p></p><p></p><p><code lang=\"null\">通过上面的示例，想必你已经迫不及待的想知道 Chunk 的大小和重叠度这两个参数确切的含义以及它们对性能的影响了吧。下面我简单从两方面解释下：</code></p><p></p><p><code lang=\"null\">chunkSize 决定了每个 Chunk 中的字符数量。chunkSize 的值越大，那么 Chunk 中的字符数就越多，LangChain 处理该 Chunk 和产生对应输出所需的时间就越长，反之亦然。chunkOverlap 是用于设置了每个 Chunk 之间共享上下文的大小。chunkOverlap 的值越高，Chunk 的冗余度就越高 ;chunkOverlap 的值越低，Chunk 之间共享的上下文就越少。通常将 chunkOverlap 设置在 Chunk 大小的 10% 到 20% 之间会比较理想，当然，真正理想 chunkOverlap 值还是要根据不同的文本类型和使用场景来确定。</code></p><p></p><p></p><h2><code lang=\"null\">Chains（模型链）</code></h2><p></p><p></p><p><code lang=\"null\">通过单个 LLM 的输入输出是无法完成一些更为复杂的任务，因此需要利用 Chains，通过将多个 LLM 的功能链接一起来完成。下面是一个很有意思的例子：</code></p><p></p><p><code lang=\"null\"><code lang=\"null\">import { ChatPromptTemplate } from \"langchain/prompts\";\nimport { LLMChain } from \"langchain/chains\";\nimport { ChatOpenAI } from \"langchain/chat_models/openai\";\n\nprocess.env[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_KEY\"\n\n// 这是一段知识库\nconst wiki_text = `\nAlexander Stanislavovich 'Sasha' Bublik (Александр Станиславович Бублик; born 17 June 1997) is a Kazakhstani professional tennis player. \nHe has been ranked as high as world No. 25 in singles by the Association of Tennis Professionals (ATP), which he achieved in July 2023, and is the current Kazakhstani No. 1 player...\n\nAlexander Stanislavovich Bublik was born on 17 June 1997 in Gatchina, Russia and began playing tennis at the age of four. He was coached by his father, Stanislav. On the junior tour, Bublik reached a career-high ranking of No. 19 and won eleven titles (six singles and five doubles) on the International Tennis Federation (ITF) junior circuit.[4][5]...\n`\nconst chat = new ChatOpenAI({ temperature: 0 });\nconst chatPrompt = ChatPromptTemplate.fromMessages([\n  [\n    \"system\",\n    \"You are a helpful assistant that {action} the provided text\",\n  ],\n  [\"human\", \"{text}\"],\n]);\n// 这里将 2 个模型进行了链接\nconst chainB = new LLMChain({\n  prompt: chatPrompt,\n  llm: chat,\n});\n\nconst resB = await chainB.call({\n  action: \"lists all important numbers from\",\n  text: wiki_text,\n});\nconsole.log({ resB });</code></code></p><p></p><p><code lang=\"null\">在上面的代码中，我在提示词中设置了一个变量，同时通过将 LLM 的 temperature 设置为 0，以要求 LLM 给出一个基于事实的回答。该例中，我要求 LLM 基于给定的简短知识库，输出我最喜欢网球运动员的关键数据。以下是 LLM 给出的回答：</code></p><p></p><p><code lang=\"null\"><code lang=\"null\">{\n  resB: {\n    text: 'Important numbers from the provided text:\\n' +\n      '\\n' +\n      \"- Alexander Stanislavovich 'Sasha' Bublik's date of birth: 17 June 1997\\n\" +\n      \"- Bublik's highest singles ranking: world No. 25\\n\" +\n      \"- Bublik's highest doubles ranking: world No. 47\\n\" +\n      \"- Bublik's career ATP Tour singles titles: 3\\n\" +\n      \"- Bublik's career ATP Tour singles runner-up finishes: 6\\n\" +\n      \"- Bublik's height: 1.96 m (6 ft 5 in)\\n\" +\n      \"- Bublik's number of aces served in the 2021 ATP Tour season: unknown\\n\" +\n      \"- Bublik's junior tour ranking: No. 19\\n\" +\n      \"- Bublik's junior tour titles: 11 (6 singles and 5 doubles)\\n\" +\n      \"- Bublik's previous citizenship: Russia\\n\" +\n      \"- Bublik's current citizenship: Kazakhstan\\n\" +\n      \"- Bublik's role in the Levitov Chess Wizards team: reserve member\"\n  }\n}</code></code></p><p></p><p><code lang=\"null\">很酷，但这还没有真正展示 Chains 的全部能力。再看一个更实际的例子：</code></p><p></p><p><code lang=\"null\"><code lang=\"null\">import { z } from \"zod\";\nimport { zodToJsonSchema } from \"zod-to-json-schema\";\nimport { ChatOpenAI } from \"langchain/chat_models/openai\";\nimport {\n  ChatPromptTemplate,\n  SystemMessagePromptTemplate,\n  HumanMessagePromptTemplate,\n} from \"langchain/prompts\";\nimport { JsonOutputFunctionsParser } from \"langchain/output_parsers\";\nprocess.env[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_KEY\"\nconst zodSchema = z.object({\n  albums: z\n    .array(\n      z.object({\n        name: z.string().describe(\"The name of the album\"),\n        artist: z.string().describe(\"The artist(s) that made the album\"),\n        length: z.number().describe(\"The length of the album in minutes\"),\n        genre: z.string().optional().describe(\"The genre of the album\"),\n      })\n    )\n    .describe(\"An array of music albums mentioned in the text\"),\n});\nconst prompt = new ChatPromptTemplate({\n  promptMessages: [\n    SystemMessagePromptTemplate.fromTemplate(\n      \"List all music albums mentioned in the following text.\"\n    ),\n    HumanMessagePromptTemplate.fromTemplate(\"{inputText}\"),\n  ],\n  inputVariables: [\"inputText\"],\n});\nconst llm = new ChatOpenAI({ modelName: \"gpt-3.5-turbo\", temperature: 0 });\nconst functionCallingModel = llm.bind({\n  functions: [\n    {\n      name: \"output_formatter\",\n      description: \"Should always be used to properly format output\",\n      parameters: zodToJsonSchema(zodSchema),\n    },\n  ],\n  function_call: { name: \"output_formatter\" },\n});\nconst outputParser = new JsonOutputFunctionsParser();\nconst chain = prompt.pipe(functionCallingModel).pipe(outputParser);\nconst response = await chain.invoke({\n  inputText: \"My favorite albums are: 2001, To Pimp a Butterfly and Led Zeppelin IV\",\n});\nconsole.log(JSON.stringify(response, null, 2));</code></code></p><p></p><p><code lang=\"null\">此脚本通过读取输入的文本信息，识别所有提到的音乐专辑以及将每张专辑的名称、艺术家、长度和流派，最后将所有数据转换为 JSON 格式进行输出。以下是输入“我最喜欢的专辑是：2001 年、To Pimp a Butterfly 和 Led Zeppelin IV”的输出：</code></p><p></p><p><code lang=\"null\"><code lang=\"null\">{\n  \"albums\": [\n    {\n      \"name\": \"2001\",\n      \"artist\": \"Dr. Dre\",\n      \"length\": 68,\n      \"genre\": \"Hip Hop\"\n    },\n    {\n      \"name\": \"To Pimp a Butterfly\",\n      \"artist\": \"Kendrick Lamar\",\n      \"length\": 79,\n      \"genre\": \"Hip Hop\"\n    },\n    {\n      \"name\": \"Led Zeppelin IV\",\n      \"artist\": \"Led Zeppelin\",\n      \"length\": 42,\n      \"genre\": \"Rock\"\n    }\n  ]\n}</code></code></p><p></p><p><code lang=\"null\">虽然这只是一个有趣的例子，但通过该技术可以将非结构化的文本数据转为结构化的数据，从而使用在其他应用系统中。</code></p><p></p><p></p><h2><code lang=\"null\">不止 OpenAI</code></h2><p></p><p></p><p><code lang=\"null\">尽管在演示 LangChain 不同功能的示例中，我一直都是使用 OpenAI 模型。但其实 LangChain 并不局限于 OpenAI 模型。你可以将 LangChain 与许多其他 LLM 和 AI 服务一起使用。在 LangChain 的官方文档中可以找到 LangChain 的 JS 版本所支持集成的完整 LLM 列表。</code></p><p></p><p><code lang=\"null\">例如，你可以将 Cohere 与 LangChain 一起使用。再使用 npm install cohere-ai 安装 Cohere 之后，你就可以像下面示例代码一样，使用 LangChain 和 Cohere 编写一个简单的问答脚本：</code></p><p></p><p><code lang=\"null\"><code lang=\"null\">import { Cohere } from \"langchain/llms/cohere\";\nconst model = new Cohere({\n  maxTokens: 50,\n  apiKey: \"YOUR_COHERE_KEY\", // In Node.js defaults to process.env.COHERE_API_KEY\n});\nconst res = await model.call(\n  \"Come up with a name for a new Nas album\" // 给 Nas 的新专辑起个名字\n);\nconsole.log({ res });</code></code></p><p></p><p><code lang=\"null\">输出的结果如下：</code></p><p></p><p><code lang=\"null\"><code lang=\"null\">{\n  res: ' Here are a few possible names for a new Nas album:\\n' +\n    '\\n' +\n    \"- King's Landing\\n\" +\n    \"- God's Son: The Sequel\\n\" +\n    \"- Street's Disciple\\n\" +\n    '- Izzy Free\\n' +\n    '- Nas and the Illmatic Flow\\n' +\n    '\\n' +\n    'Do any'\n}</code></code></p><p></p><p></p><h2><code lang=\"null\">总结</code></h2><p></p><p></p><p><code lang=\"null\">读完本篇文章，相信你已经对 JS 版的 LangChain 各方面能力都有所了解了。现在你可以通过 LangChain 用 JS 开发各种基于 AI 的应用和体验 LLM 了。当然，也请你必参考 LangChainJS 的官方文档，以了解更多有关特定功能的详细信息。</code></p><p></p><p><code lang=\"null\">最后，预祝你在 JavaScript 中愉快的使用 LangChain 进行编码和体验！如果你喜欢这篇文章，你可能还想阅读如何在 Python 中使用 LangChain 这篇文章：</code></p><p></p><p><code lang=\"null\"><a href=\"https://www.sitepoint.com/langchain-python-complete-guide/\">https://www.sitepoint.com/langchain-python-complete-guide/</a>\"</code></p><p></p><p><code lang=\"null\">原文链接：</code></p><p></p><p><code lang=\"null\"><a href=\"https://www.sitepoint.com/langchain-javascript-complete-guide/\">https://www.sitepoint.com/langchain-javascript-complete-guide/</a>\"</code></p><p></p><p></p><h5><code lang=\"null\">相关阅读：</code></h5><p></p><p><code lang=\"null\"><a href=\"https://www.infoq.cn/article/Rujx6tv3Grxh3HYMZJqK?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">LangChain&nbsp;的问题所在</a>\"</code></p><p><code lang=\"null\"><a href=\"https://www.infoq.cn/article/67vMj2F2HTC24fDdE64a?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">OpenAI 用 45 分钟重塑游戏规则！干掉 MJ、LangChain，创造“不会编程的应用开发者”新职业</a>\"</code></p><p><code lang=\"null\"><a href=\"https://www.infoq.cn/article/yl8eJoSfkHbOCyFzCcgw?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">LangChain：2023 年最潮大语言模型 Web 开发框架</a>\"</code></p><p><code lang=\"null\"><a href=\"https://xie.infoq.cn/article/d9e58b3a7e0fe2a369269c923?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">理论 + 实践详解最热的 LLM 应用框架 LangChain</a>\"</code></p>",
    "publish_time": "2023-11-29 13:58:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "JetBrains发布了Kotlin Multiplatform的首个稳定版本",
    "url": "https://www.infoq.cn/article/FiuarMFJgHpYsARFIrb0",
    "summary": "<p>JetBrains提供了Kotlin Multiplatform的首个稳定版本，支持跨iOS、Android、桌面、Web和服务器进行代码共享——尽管用于共享用户界面（UI）代码的部分，Compose Multiplatform，仅适用于Android和桌面。</p><p>&nbsp;</p><p>Kotlin是由JetBrains开发的一种JVM（Java虚拟机）语言，并被谷歌（Google）用作Android开发的首选语言。既然Java已经是为跨平台代码而设计的了，那么Kotlin Multiplatform又增加了什么呢？答案是Kotlin不仅仅是一种JVM语言。<a href=\"https://kotlinlang.org/docs/native-overview.html#why-kotlin-native\">Kotlin/Native</a>\"使用MinGW（适用于Windows的GCC工具链）和Android NDK编译成适用于macOS、iOS、Linux、Windows的独立可执行文件。<a href=\"https://kotlinlang.org/docs/js-overview.html\">Kotlin/JS</a>\"将Kotlin转换为JavaScript。Kotlin Wasm仍处于实验阶段，可编译成WebAssembly。</p><p>&nbsp;</p><p><a href=\"https://kotlinlang.org/lp/multiplatform/\">Kotlin Multiplatform</a>\"是一种跨所有这些平台共享非GUI代码的技术。它解决了代码共享的两个常见问题，即对于所有目标平台的一个子集，仅需部分共享某些代码的需求，以及需要访问特定于平台的API。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/62/626b86de787d7d3c3bc4aea2d812185f.png\" /></p><p></p><p>Kotlin Multiplatform中的Expect和Actual，解决了调用本机平台API的需求</p><p>&nbsp;</p><p>本机API问题是通过<a href=\"https://kotlinlang.org/docs/multiplatform-connect-to-apis.html\">预期声明和实际声明</a>\"的机制来解决的。 expect 关键字将声明标记为将与用actual关键字标记的代码匹配，actual关键字可能是特定于平台的。JetBrains建议仅对平台API使用expect/actual，其他情况使用普通接口。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c6/c6a98abd1a214e39d3daf29f724a4547.png\" /></p><p></p><p>2022年的一项调查显示，Kotlin Multiplatform应用程序的代码共享率高达63%</p><p>&nbsp;</p><p>Kotlin Multiplatform适用于非GUI代码，但有一个相关项目<a href=\"https://www.jetbrains.com/lp/compose-multiplatform/\">Compose Multiplatform</a>\"，它可用于创建共享的用户界面（UI）。 Compose Multiplatform基于谷歌的<a href=\"https://developer.android.com/jetpack/compose\">Jetpack Compose</a>\"，用于构建Android用户界面。 Compose Multiplatform在桌面平台、macOS、Linux和Windows上也是稳定版本，但在iOS上是Alpha版本，在Web上是实验性的。根据JetBrains的说法，Kotlin Multiplatform已经被包括Netflix和VMWare在内的公司所使用。</p><p>&nbsp;</p><p>如果Compose Multiplatform还没有准备好，那么开发者如何支持iOS呢？这可以通过使用<a href=\"https://developer.apple.com/xcode/swiftui/\">SwiftUI</a>\"来实现，SwiftUI是苹果（Apple）的官方UI设计语言，它是基于声明式代码的。有一些代码示例正是采用了这种方式实现的。</p><p>&nbsp;</p><p>JetBrains还表示，他们的目标是在2024年发布面向iOS的Compose Multiplatform测试版本，Kotlin/Wasm也在积极开发中。</p><p>&nbsp;</p><p>去年，谷歌通过<a href=\"https://android-developers.googleblog.com/2022/10/announcing-experimental-preview-of-jetpack-multiplatform-libraries.html\">引入</a>\"其他一些Jetpack库的“实验预览”，表达了对Kotlin Multiplatform的一些支持，这些库不是用于生产的，而是用于“在针对Android和iOS应用程序的多平台项目中使用这些Jetpack库的反馈”。请注意，谷歌还提供了使用Dart语言和Flutter UI进行跨平台开发的Flutter。</p><p>&nbsp;</p><p>使用Kotlin而不是Java的另一个原因是<a href=\"https://kotlinlang.org/docs/comparison-to-java.html#what-kotlin-has-that-java-does-not\">它的语言特性</a>\"，包括lambda表达式、扩展函数、类型推理、null安全等等。Kotlin没有检查异常，因为这些不会提高生产力或代码质量。</p><p>&nbsp;</p><p>Kotlin Multiplatform和Compose Multiplatform均可免费使用。<a href=\"https://github.com/JetBrains/kotlin\">Kotlin的代码</a>\"位于Github上，许可证是Apache2.0。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://devclass.com/2023/11/01/jetbrains-offers-first-stable-release-of-kotlin-multiplatform/\">https://devclass.com/2023/11/01/jetbrains-offers-first-stable-release-of-kotlin-multiplatform/</a>\"</p><p></p><p></p><h5>相关阅读：</h5><p></p><p><a href=\"https://xie.infoq.cn/article/942bb329c38cd72544c860f41\">浅谈 Kotlin 编程 01. 初识 Kotlin 和入门示例</a>\"</p><p><a href=\"https://xie.infoq.cn/article/ba7cceea4b506026b9cb0d42f\">从 HelloWorld 看 Java 与 Kotlin</a>\"</p><p><a href=\"https://www.infoq.cn/article/aTY2ysTOjaEwUv9Hzls6\">Meta 将百万行代码从 Java 移植到 Kotlin</a>\"</p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MzAxODcyNjEzNQ==&amp;mid=2247571124&amp;idx=1&amp;sn=93bb6d6dc0678677eb89f03fbc256824&amp;chksm=9bd27b2caca5f23a436467fe7b5f6c3809a9bba3d7ccd4091bc2c70ac714814e7092709758a5&amp;scene=27#wechat_redirect\">又一巨头从 Java 迁移到 Kotlin ！</a>\"</p>",
    "publish_time": "2023-11-29 14:02:06",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "OpenAI发布了GPTs，可以创建无代码、定制版本的ChatGPT",
    "url": "https://www.infoq.cn/article/u4VX7rDm5rw1sdXa7YOI",
    "summary": "<p>在<a href=\"https://www.infoq.com/news/2023/11/openai-announcements-1stdevday/\">最近的OpenAI开发者大会</a>\"上，OpenAI宣布将推出GPTs，这是专为特定任务创建的ChatGPT的定制版本。该公司表示，开发者还能够在即将推出的ChatGPT商店中分享他们的GPTs并从中获利。</p><p>&nbsp;</p><p>GPTs提供了一种将ChatGPT与定制指令、外部知识和任何技能组合在一起的机制。它们试图满足定制化ChatGPT以适应特定用途的需求，例如学习棋盘游戏规则、帮助教授数学或设计贴纸等。</p><p>&nbsp;</p><p></p><blockquote>许多高级用户都会维护一个仔细制作的提示和指令集列表，手动将它们复制到ChatGPT中。现在，GPT可以为你完成所有这些操作。</blockquote><p></p><p>&nbsp;</p><p>在GPT出现之前，提示工程是专门定制ChatGPT行为的最常见方法。根据OpenAI的说法，构建GPT不需要编码技能，非常适合教育工作者、教练或任何喜欢构建有用工具的人。</p><p>&nbsp;</p><p></p><blockquote>创建一个GPT就像开始一次对话，给它指令和额外的知识，并选择它可以做的事情，比如搜索互联网、制作图片或分析数据。</blockquote><p></p><p>&nbsp;</p><p>使用OpenAI的界面，创建GPT的第一步是与ChatGPT进行对话，描述你想要实现的目标。完成这一步后，你可以定义指令、对话启动问题、知识、能力和动作。</p><p>&nbsp;</p><p>指令部分极为关键。在这里，你需要确定使用哪些资源、选择什么风格和语调，以及定义期望的行为模式。比如，你可以设定当用户提供特定数据时，你的 GPT 应如何利用这些数据进行网上搜索，接着运行某些脚本来处理搜索结果等等。</p><p>&nbsp;</p><p>对话启动问题是你提供的一些示例句子，帮助用户了解他们可以向 GPT 咨询哪些问题。而知识，则是你上传的资源集，这些资源会作为模型的一部分，供 GPT 使用。功能指的是 GPT 能够利用的各种工具，而动作则是指 GPT 调用外部服务的操作。</p><p>&nbsp;</p><p>GPTs 可供订阅了 ChatGPT Plus 的用户使用，并且用户还需启用“Beta 选项”功能。</p><p>&nbsp;</p><p>正如前面提到的，OpenAI 最近还推出了 GPT 商店，这使得用户可以公开分享自己的 GPT。据公司透露，GPT 商店预计将从 2023 年 11 月末开始提供服务，接下来几个月将支持进行货币交易。</p><p>&nbsp;</p><p>此前，ChatGPT 通过集成第三方应用程序，提供了 <a href=\"https://openai.com/blog/chatgpt-plugins\">ChatGPT 插件</a>\" 来修改 ChatGPT 的行为。虽然从这个角度看，GPTs 似乎让插件变得过时，但 <a href=\"https://platform.openai.com/docs/plugins/introduction\">OpenAI 表示他们正推广动作功能</a>\"，这是在插件基础上的进一步发展，旨在利用插件的许多核心理念。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/11/openai-gpts-custom-chatgpt/\">https://www.infoq.com/news/2023/11/openai-gpts-custom-chatgpt/</a>\"</p>",
    "publish_time": "2023-11-29 14:09:02",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]