[
  {
    "title": "微软更新其Well-Architected框架",
    "url": "https://www.infoq.cn/article/zJqBVpZMmwo8viWXFcpu",
    "summary": "<p>微软最近宣布全面更新用于在Azure上设计和运行优化工作负载的<a href=\"https://learn.microsoft.com/en-us/azure/well-architected/\">Well-Architected框架（Well-Architected Framework，WAF）</a>\"。</p><p>&nbsp;</p><p>微软的WAF是一套质量驱动原则、架构决策点和审查工具，其目标是帮助解决方案架构师为其工作负载建立技术基础。此次更新不仅为用户工作负载的架构权衡提供了指导，而且还就如何在组织范围内实施这一指导提供了更精确的说明。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bf/bf38cd49b568bfd5c0488376d468d94a.png\" /></p><p></p><p>Well-Architected框架的更新概述（图片来源：<a href=\"https://learn.microsoft.com/en-us/azure/well-architected/\">微软网站</a>\"）</p><p>&nbsp;</p><p>微软公司的副总裁<a href=\"https://www.linkedin.com/in/ulrichhomann/\">Uli Homann</a>\"这样写道：</p><p></p><blockquote>在过去的六个月中，微软的云解决方案架构师通过整理10000多个利用WAF及其评估的项目所得到经验和教训，更新了Well-Architected框架。现在，Well-Architected框架的所有五大支柱都采用了通用的结构，均由设计原则、设计审查清单、权衡、建议指南和云设计模式组成。</blockquote><p></p><p>&nbsp;</p><p>设计原则提出了面向目标的原则，为工作负载奠定了基础；设计审查清单粗略定义了已成文的建议，以便于推动行动的开展；权衡描述了与其他支柱之前的取舍。同时，建议指南是与一个或多个设计审查清单相关联的，而云设计模式则提供了经过验证的通用架构模式。</p><p>&nbsp;</p><p>此次更新尤其关注作为“<a href=\"https://learn.microsoft.com/en-us/assessments/azure-architecture-review/\">Well-Architected审查评估</a>\"”一部分的“核心Well-Architected审查”，现在它与Well-Architected框架中的新内容保持一致。此外，正如<a href=\"https://learn.microsoft.com/en-us/azure/well-architected/whats-new#well-architected-framework-assessments\">文档</a>\"所述，每个支柱中的每个问题都与该支柱的设计审查清单相对应。所有问题的选项都与相关检查清单条目的推荐指南相关联。</p><p>&nbsp;</p><p>微软架构内容负责人<a href=\"https://www.linkedin.com/in/stephen-t-sumner/\">Stephen Sumner</a>\"在一篇Azure的架构博客中解释说：</p><p></p><blockquote>评估更新以通用工作负载设计的最佳实践为目标。你可以在任何平台的任何工作负载上运行评估，而不仅仅是Azure中的工作负载。评估在更深的技术层面涵盖了工作负载的更多方面。</blockquote><p></p><p>而且：</p><p></p><blockquote>相对于上一版的评估，它增加了20多条建议（总计375条），但是它也减少了124个选项。这意味着你只需更少的输入，就能获得更具针对性的指导。</blockquote><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4a/4ade9d6239caccdf2b0a2f51a9d10630.png\" /></p><p></p><p>Well-Architected评估的样例（图片来源：<a href=\"https://techcommunity.microsoft.com/t5/azure-architecture-blog/azure-well-architected-review-assessment-updates/ba-p/3981023\">微软架构博客</a>\")</p><p>&nbsp;</p><p>另外的两大云提供商AWS和Google也通过Well-Architected框架为其平台提供指导。此外，AWS最近<a href=\"https://www.infoq.com/news/2023/04/aws-well-architected-framework/\">更新</a>\"并<a href=\"https://www.infoq.com/news/2023/11/aws-well-architected-framework/\">重构</a>\"了其<a href=\"https://aws.amazon.com/architecture/well-architected/\">Well-Architected框架</a>\"。</p><p>&nbsp;</p><p>最后，你可以通过名为“Well-Architected框架的新变化”的<a href=\"https://www.youtube.com/watch?v=XV_E4WtqNrE\">视频</a>\"了解有关更新的更多详情。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/11/azure-well-architected-framework/\">Microsoft Refreshes Its Well-Architected Framework</a>\"</p>",
    "publish_time": "2023-11-29 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "全方位深度测评 AI 代码助手 Amazon CodeWhisperer",
    "url": "https://www.infoq.cn/article/W5RzCzfZ6imJQrCk2lW9",
    "summary": "<p></p><h3>背景</h3><p></p><p></p><p>随着互联网技术的不断发展，<a href=\"https://so.csdn.net/so/search?q=%E7%A8%8B%E5%BA%8F%E5%91%98&amp;spm=1001.2101.3001.7020\">程序员</a>\"们面临着越来越多的挑战，如代码复杂度不断提高、代码错误难以避免、团队协作效率低下等。传统的开发工具已经无法满足程序员们的需求，因此这几年基于人工智能技术的代码助手应运而生。AI代码助手的目的是通过自动化的方式帮助程序员提高开发效率、减少错误、提高代码质量，同时还可以帮助程序员快速学习新技术、更快，更安全地构建应用程序，提高团队协作效率。可以说AI代码助手成为当今软件开发领域的重要趋势之一。本篇文章就来深度测评一下AI 代码助手&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer</a>\"。</p><p></p><h3><a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer 介绍</a>\"</h3><p></p><p></p><p>Amazon CodeWhisperer&nbsp;是亚马逊云科技推出的AI代码助手，目的是帮助开发者更快，更安全地构建应用程序。作为智能编程助手，它经过了非常多的优秀开源代码训练，参与训练的代码都是具有良好的扩展性，安全性，优雅等特点，利用它编写的代码能够很快地写出健壮，优雅，具有很高扩展性的代码。 此外它还可以扫描代码来检测难以发现的漏洞，获取代码建议来立即修复漏洞。总的来说它具有以下特性：</p><p></p><h4>特性</h4><p></p><p>实时生成代码片段或全函数的代码建议获取相关开源项目的存储库信息扫描代码漏洞，给出修复建议支持 Python，Java，JavaScript 等15中编程语言支持 VS Code，IntelliJ IDEA，Amazon Cloud9、Amazon Lambda 控制台、JupyterLab 和 Amazon SageMaker Studio 等集成开发环境</p><p>以上就是&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer</a>\"&nbsp;的介绍，下面进入正在的测评阶段。</p><p></p><p>主要从以下几方面进行测评：</p><p>用户体验 （包括，安装，配置，文档资料）功能使用（包括，上手难度，使用复杂度，安全，准确度）场景实践（以具体业务场景体验功能）</p><p>安装，配置也是测评的一部分，下面就从最开始的安装开始体验。</p><p></p><h3>安装配置&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer</a>\"</h3><p></p><p></p><p>本次安装使用的在 Windows 10 的 VS Code 上进行的。作为 AI 智能代码助手，它是以 IDE 插件的方式存在的。这样能够很好地与 IDE 相关功能无缝结合。提升开发效率，增强用户体验。</p><p>打开 VS Code，在插件列表中搜索&nbsp;&nbsp;Amazon Toolkit</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f6/f6001aab889f12da44c240e236b393a0.png\" /></p><p></p><p>找到名称为&nbsp;Amazon Toolkit&nbsp;的插件，点击 Install 按钮进行安装。有时安装后，需要重载一下 VS Code 才能用。</p><p></p><p>笔者写这篇文章时，Amazon Toolkit 最新的版本是&nbsp;1.91.0，如果有读者安装的与笔者的功能不同，请检查下版本是否一致。以下是该插件的一些基本信息：</p><p></p><p>版本：1.91.0</p><p>下载次数：1,663,326</p><p>Git仓库：<a href=\"https://github.com/aws/aws-toolkit-vscode\">amazon-toolkit-vscode</a>\"</p><p>插件地址：<a href=\"https://marketplace.visualstudio.com/items?itemName=AmazonWebServices.aws-toolkit-vscode\">Amazon Toolkit</a>\"</p><p>开源协议：<a href=\"https://marketplace.visualstudio.com/items/AmazonWebServices.aws-toolkit-vscode/license\">Apache License Version 2.0</a>\"</p><p>从下载次数来看，Amazon Toolkit 是一个非常受欢迎的插件。</p><p></p><p>在安装完成后，你可以在左侧的侧边栏，看到一个 Amazon 的图标，点击它就会出现插件的面板。如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cf/cf5282612c54c8bbfe19fc90a4330893.png\" /></p><p></p><p>该插件主要包括三种功能：</p><p>Amazon CodeCatalyst 统一的软件开发服务，可在 Amazon 上快速构建和交付应用程序。CDK 云应用程序资源<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer</a>\"&nbsp;智能代码助手。</p><p></p><p>要使用这些功能，需要用户先连接 Amazon 服务。</p><p>当我们需要使用&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer</a>\"， 只需要点击 CodeWhisperer 下的 Star 按钮，然后再点击 Sign in 按钮，如下图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1e/1eef9b4b08c3caf3531f5de0359ea4ef.png\" /></p><p></p><p>如果你没有 Amazon 账号，也没关系，点击按钮后，会弹出一个重定向弹窗，点击 Proceed To Brower，使用浏览器继续。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0d/0dfbfdcf8bf635a46abd91a6d1c87101.png\" /></p><p></p><p>点击按钮会 页面显示大致如下</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/38/38a25646300243dc95df751500b13575.png\" /></p><p></p><p>点击确认并继续</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/00/001bf944dc6ac743c9447bda273ba7d3.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/af/af604608b158437bc40c52737e655a4b.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0d/0d1b5f33d305b5bcc8814fb78275e49d.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/22/22751317effcc0fd3da7517310242f5b.png\" /></p><p></p><p>总体步骤就是，输入邮箱，姓名 → 验证邮箱 → 填写密码 → 允许 Amazon Toolkit 访问数据</p><p>整体流程非常顺畅，安装，配置三分钟内就能完成。</p><p>授权后，插件就开始工作了。我们也可以开始愉快地工作了。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/04/049a734c47975b7b61254a680a2ea7a7.png\" /></p><p></p><p>此外值得一提的是，该插件还提供了一种专业版的功能，不过要配置 IAM 身份中心，这部分我们暂时不表。</p><p></p><p>在安装并配置&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer</a>\"&nbsp;后，在编码时会自动开启代码建议。同时你也可以收到去获取代码建议。在 Windows 平台的 VS Code 上，使用 Alt + C 键，使用 Tab 键来插入当前的建议代码块。使用左右键来切换代码块。</p><p></p><h3>具体场景</h3><p></p><p></p><p>下面我们在具体的场景中来体验&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer</a>\"。</p><p></p><h4>使用&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Code Whisperer</a>\"&nbsp;开发数据可视化图表</h4><p></p><p></p><p>场景一：作为一名前端开发者，我们经常会遇到使用图表库开发一些可视化的图表，比如使用 Echarts 来开发一个折线图。</p><p></p><p>我们创建一个简单的 html，在页面内写入必要的信息，并在 script 标签中写入注释：</p><p></p><p><code lang=\"text\"></code></p><p></p><p>然后按下 Alt + C 键，这时在 VS Code 会调出，html is currently not supported by CodeWhisperer。</p><p>如下图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f2/f2da98c8bac8acc7f71497714af82c2d.png\" /></p><p></p><p>目前&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">CodeWhisperer</a>\"&nbsp;还不支持 html 文件的代码建议。所以我们需要先创建一个 js，然后在 html 文件中引入。</p><p></p><p>我们在 js 文件中，使用注释写下需要实现的功能，然后按下 Alt + C 键。就会出现如下图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/71/716980467f988fd2dcdacba2d6a3d3bf.png\" /></p><p></p><p>在检查过给出的建议代码后，确定是我们需要的，按下 Tab 键，来获取插入当前区域。</p><p>更加具体的交互可以先下面的动图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d2/d22e5bdeb330a5005e81a78905ad46c3.gif\" /></p><p></p><p>这是一个非常实用的场面，避免了花费大量时间去查询 Echarts 文档。要知道 Echarts 的配置文档是非常多的。下图是密密麻麻的 Echarts 图表配置项：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f0/f009865a68020e1730d96b161fc79a89.png\" /></p><p></p><p></p><h4>编写一个 Python 的浏览器自动化脚本</h4><p></p><p></p><p>作为一名开发人员，我们经常会遇到一些重复的工作，比如这样一个场景，在某个网站上有一个销售榜单，我们需要实时监控这个表单，并将每天的数据汇总发到邮箱里。对于这样的重复性没有技术含量的工作，我们通常使用脚本来编写自动化脚本。下面我们就使用&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer</a>\"&nbsp;来编写一个这样的脚本，看看它是否能够帮助我们快速实现功能。</p><p></p><p>创建一个 auto-run.py 的文件，在文件里引入 selenium，并且使用代码注释写下要实现的功能，按下 Alt + C 键。交互动图如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/72/72dc7a512bd67b79380a853d44a65105.gif\" /></p><p></p><p>根据动图大家可以看到，当按下 Alt + C 键时，只提供了一行代码建议，在按下左箭头键后，出现了四行的代码建议。整个流程是非常快速的。</p><p></p><p>给出的代码建议地完整地实现了， 使用 webdriver 打开 Chrome 浏览器，并且访问百度首页，但在输入关键词时，却把\"拿我格子衫\" 写成了“拿战校衫”。个人猜测是由于中文在大模型中有偏差造成的。换成英文就无此问题。</p><p></p><p>使用&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer</a>\"&nbsp;时，代码建议是非常快速的，这个快，除了靠个人感觉来评估，也有一些更为准确的数字来评估。<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer</a>\"&nbsp;提供了一个日志面板，我们可以在 VS Code 的 Setting 配置面板里，找到 Amazon Toolkit 的配置项，找到 Log Level，将其调整为 debug。如下图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f5/f57ad175da4f88acfaa7ca349b5a8e18.png\" /></p><p></p><p>调整后，我们选中 OUTPUT 面板，并将输出选位 Amazon Toolkit Logs，如下图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9b/9b2ea6250202ee1d78e1fe58cace1c75.png\" /></p><p></p><p>当我们在编辑器中按下 Alt + C 键，底部的日志面板会打印出整个流程的日志：</p><p>打印信息大致如下</p><p></p><p><code lang=\"text\">2023-09-25 11:36:41 [DEBUG]: command: running \"aws.codeWhisperer\"\n2023-09-25 11:36:41 [DEBUG]: command: running \"_aws.auth.autoConnect\"\n2023-09-25 11:36:41 [VERBOSE]: telemetry: emitted metric \"vscode_executeCommand\"\n2023-09-25 11:36:41 [DEBUG]: codewhisperer: Connection expired = false,\n                           secondaryAuth connection expired = false,\n                           connection is undefined = false\n2023-09-25 11:36:41 [DEBUG]: codewhisperer: isValidCodeWhispererConnection = true\n2023-09-25 11:36:41 [VERBOSE]: telemetry: emitted metric \"vscode_executeCommand\"\n2023-09-25 11:36:41 [DEBUG]: CodeWhisperer finished fetching crossfile context out of 0 files\n2023-09-25 11:36:41 [DEBUG]: CodeWhispererSupplementalContext:\n    isUtg: false,\n    isProcessTimeout: false,\n    contentsLength: 0,\n    latency: 0.2452000007033348,\n\n2023-09-25 11:36:41 [DEBUG]: SSO token cache: loaded key: 5fa44ff1-8f20-4ed5-89be-548baeb748aa\n2023-09-25 11:36:42 [DEBUG]: Request ID: db72446b-5ee6-439f-af87-87800aa93d90,\n                timestamp(epoch): 1695613002378,\n                timezone: Asia/Shanghai,\n                datetime: 9/25/2023, 11:36:42 AM,\n                vscode version: '1.82.2',\n                extension version: '1.91.0',\n                filename: 'hello-selenium.py',\n                left context of line:  '',\n                line number: 2,\n                character location: 0,\n                latency: 1047.5229000002146 ms.\n2023-09-25 11:36:42 [VERBOSE]: Recommendations:\n2023-09-25 11:36:42 [VERBOSE]: [0]\ndriver = webdriver.Chrome()\n2023-09-25 11:36:42 [VERBOSE]: telemetry: emitted metric \"codewhisperer_serviceInvocation\"\n2023-09-25 11:36:42 [DEBUG]: SSO token cache: loaded key: 5fa44ff1-8f20-4ed5-89be-548baeb748aa\n2023-09-25 11:36:42 [VERBOSE]: telemetry: emitted metric \"codewhisperer_perceivedLatency\"\n2023-09-25 11:36:43 [DEBUG]: Request ID: b69b0f19-bf91-4fe3-b335-96268b567126,\n                timestamp(epoch): 1695613003423,\n                timezone: Asia/Shanghai,\n                datetime: 9/25/2023, 11:36:43 AM,\n                vscode version: '1.82.2',\n                extension version: '1.91.0',\n                filename: 'hello-selenium.py',\n                left context of line:  '',\n                line number: 2,\n                character location: 0,\n                latency: 1041.122000001371 ms.\n2023-09-25 11:36:43 [VERBOSE]: Recommendations:\n2023-09-25 11:36:43 [VERBOSE]: [0]\ndriver = webdriver.Chrome()\ndriver.get(\"http://www.baidu.com\")\ndriver.find_element_by_id(\"kw\").send_keys(\"拿战校衫\")\ndriver.find_element_by_id(\"su\").click()\n2023-09-25 11:36:43 [VERBOSE]: [1]\ndriver = webdriver.Chrome()\ndriver.get(\"http://www.baidu.com\")\ndriver.find_element_by_id(\"kw\").send_keys(\"拿战校衣\")\ndriver.find_element_by_id(\"su\").click()</code></p><p></p><p>根据打印日志的信息，基本的流程大致是这样的：</p><p></p><p>时间戳：2023-09-25 11:36:41，日志以DEBUG级别开始，表示调试信息。命令执行：运行\"aws.codeWhisperer\"和\"_aws.auth.autoConnect\"两个命令。遥测数据：emitted metric “vscode_executeCommand”，表示执行了一个 VS Code 命令。检查&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">CodeWhisperer</a>\"&nbsp;连接状态：isValidCodeWhispererConnection为true，连接有效。检查&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">CodeWhisperer</a>\"&nbsp;获取 crossfile 上下文的结果：完成从一个文件中获取crossfile上下文。检查&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">CodeWhisperer</a>\"&nbsp;补充上下文信息： isUtg 为 false，isProcessTimeout 为 false，contentsLength 为0，latency 为0.245秒。SSO令牌缓存：加载了SSO令牌缓存的键值对。请求ID、时间戳、时区、日期时间、VS Code 版本、扩展版本、文件名、行号、字符位置、延迟等信息被记录。推荐建议：[0]，建议使用 webdriver.Chrome() 来创建一个 Chrome 浏览器驱动对象。遥测数据：emitted metric “codewhisperer_serviceInvocation”，表示服务调用的度量数据。…</p><p></p><p>使用 token 发起的 Request，整个请求中包含了这些信息：</p><p></p><p><code lang=\"text\">timestamp(epoch): 1695613003423,\ntimezone: Asia/Shanghai,\ndatetime: 9/25/2023, 11:36:43 AM,\nvscode version: '1.82.2',\nextension version: '1.91.0',\nfilename: 'hello-selenium.py',\nleft context of line:  '',\nline number: 2,\ncharacter location: 0,\nlatency: 1041.122000001371 ms.</code></p><p></p><p>其中有一个指标是 latency，表明延迟，即从用户按下 Alt+ C 键，到代码块出现这段时间。可以看到生成4行代码只用了 1s 左右，非常的迅速。</p><p></p><p>通过上述的两个实战案例，相信大家已经了解&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer</a>\"&nbsp;的常规使用。在使用时需要以下几点</p><p></p><h4>使用时注意点</h4><p></p><p></p><p>实现功能需要提供一些上下文，比如使用的库和功能注释最好使用英文，中文可能出现乱码或繁体使用左箭头键和右箭头键选择最合适的代码块html 和 yaml 文件暂时不支持</p><p></p><p>另外在使用的过程中，发现了一个不知是 VS Code 的问题还是插件的问题，就是在用鼠标切换代码建议时，当前索引没有改变，详见下图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/52/5251601e3e9e3553667a3607f4d627bc.gif\" /></p><p></p><p>根据上图 可以看到 切换代码建议，&nbsp;1/5&nbsp;一直都没有变， 用户无法感知当前显示的是第几个代码块。</p><p></p><h4>插件代码解析</h4><p></p><p></p><p>为了更加了解这个产品，我仔细阅读了该插件的源码，它的代码托管在 GitHub，主要功能代码存放在&nbsp;src/codewhisperer&nbsp;目录里。</p><p></p><p>Amazon CodeWhisperer 的插件入口在此处，<a href=\"https://github.com/aws/aws-toolkit-vscode/blob/master/src/codewhisperer/views/securityPanelViewProvider.ts\">https://github.com/aws/aws-toolkit-vscode/blob/master/src/codewhisperer/views/securityPanelViewProvider.ts</a>\"</p><p>这段代码是一个名为&nbsp;SecurityPanelViewProvider&nbsp;的类，它实现了&nbsp;vscode.WebviewViewProvider&nbsp;接口。这个类主要用于在 Visual Studio Code 中打开一个特定的文件并在安全扫描面板中显示代码扫描结果。</p><p></p><p>以下是该类的主要方法和功能：</p><p></p><p>makeUri(...args: Parameters): vscode.Uri：&nbsp;这个方法用于根据给定的路径和行号范围创建一个 URI，用于在 openEditorAtRange 方法中打开编辑器。</p><p>openEditorAtRange(path: string, startLine: number, endLine: number)：&nbsp;这个方法接受一个文件路径和开始、结束行号，然后在 VS Code 中打开该文件并在指定的行范围内高亮显示问题。</p><p>persistLines()：&nbsp;这个方法用于持久化处理过的行信息。</p><p>addLines(securityRecommendationCollection: AggregatedCodeScanIssue[], editor: vscode.TextEditor | undefined)：&nbsp;这个方法用于将扫描结果添加到安全面板中，并更新视图。</p><p>update()：&nbsp;这个方法用于更新视图，将处理好的HTML内容设置到 webview 中。</p><p>persistLine(panelSet: SecurityPanelSet, index: number)：&nbsp;这个方法用于持久化单个处理过的行信息。</p><p>addUnclickableWarningItem(item: SecurityPanelItem) 和 addUnclickableInfoItem(item: SecurityPanelItem)：&nbsp;这两个方法分别用于添加不可点击的警告项和信息项。</p><p>addClickableWarningItem(item: SecurityPanelItem) 和 addClickableInfoItem(item: SecurityPanelItem)：&nbsp;这两个方法分别用于添加可点击的警告项和信息项，它们会生成一个包含文件路径和行号范围的 URI，并将其设置为链接的 href 属性，以便用户可以点击查看文件并在 VS Code 中打开。</p><p></p><h4>学习资料与文档</h4><p></p><p></p><p>虽然 Amazon CodeWhisperer 使用起来非常简单，但官方还是提供了很多学习资料，覆盖各个阶段的学习者。</p><p>如果你想要获取更多有关它的资料 可以查阅官方文档&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/\">https://aws.amazon.com/cn/codewhisperer/</a>\"下面是几篇帮助你快速了解 Amazon CodeWhisperer 的视频教程。</p><p><a href=\"https://dev.amazoncloud.cn/video/videoDetail?id=6445fcdec9a819396b2fe24a\">利用 VS Code 开始使用 Amazon CodeWhisperer</a>\"</p><p><a href=\"https://dev.amazoncloud.cn/video/videoDetail?id=6445fa2413eafe780ecafaac\">利用 Amazon CodeWhisperer 创建基于 Python 的事件驱动型 Serverless App</a>\"</p><p><a href=\"https://dev.amazoncloud.cn/video/videoDetail?id=6445fb816afa68650f58e0df\">利用 Amazon CodeWhisperer 创建基于 Java 的事件驱动型 Serverless App</a>\"</p><p></p><h3>总结</h3><p></p><p></p><p>总的来讲，<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer</a>\"&nbsp;是一款非常优秀的智能编程助手，它能够理解代码的功能和结构，并根据这些信息自动生成注释。这有助于提高代码的可读性和可维护性，同时也能帮助开发人员更好地理解他们正在编写的代码。</p><p></p><p>本文介绍了<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer</a>\"&nbsp;的背景和特性，并测评了它在实际开发场景中的优秀表现。此外，也给出了一些&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer</a>\"&nbsp;的教程视频。</p><p></p><p>总之，<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer</a>\"&nbsp;是一种借助AI大模型创新性的工具，它有助于改善代码质量和软件开发效率，并帮助开发人员更快速，更安全地开发应用，大家快快用起来，也期待&nbsp;<a href=\"https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail\">Amazon CodeWhisperer</a>\"&nbsp;能够更新更多的功能。</p>",
    "publish_time": "2023-11-29 10:40:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "楷同科技有限公司 CEO 黄益聪确认出席 QCon 上海，分享基于时间序列数据预测模型的智能量化交易系统性能优化实践",
    "url": "https://www.infoq.cn/article/r14f5E9kJAxbaN7dMWdS",
    "summary": "<p><a href=\"https://qcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=8&amp;utm_term=1129&amp;utm_content=huangyicong\">QCon 全球软件开发大会</a>\"，将于 12 月在上海召开。快手基础平台部系统软件中心 / 系统软件负责人熊刚将发表题为《<a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5626?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=8&amp;utm_term=1129&amp;utm_content=huangyicong\">基于时间序列数据预测模型的智能量化交易系统性能优化实践</a>\"》主题分享，探讨系统全链路从数据采集 - 数据计算 - 模型预测 - 交易下单，全流程进行优化的实践，包括怎样高效的在 Java 处理计算 C++ 高频产生的时间序列数据，怎么降低高频产生、长生命周期数据对 Java GC 的影响等。</p><p></p><p><a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5626?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=8&amp;utm_term=1129&amp;utm_content=huangyicong\">黄益聪</a>\"，曾担任 Intel 高级工程师，阿里巴巴高级技术专家，中国互联网百强独角兽企业技术副总裁、CTO，有 15 项中国发明专利，3 项美国发明专利，专注于大数据与人工智能领域，AI 量化交易系统实践。他在本次会议的演讲内容如下：</p><p></p><p>演讲：基于时间序列数据预测模型的智能量化交易系统性能优化实践</p><p></p><p>金融市场的行情数据，如股票价格、成交量、交易队列等是典型的时间序列数据，具有很强的时间性和顺序依赖性。智能量化交易系统需要对市场上高频产生的时间序列数据进行处理计算，输入深度学习模型进行预测，执行交易策略，生成交易行为进行交易。整个过程需要覆盖全市场一万以上的品种，并且需要在很小的时间窗口，比如秒级完成。进一步的，我们使用了多语言进行系统开发。其中数据采集模块使用了 C++ 以达到高性能，交易策略引擎使用了 Java Spring Boot 搭建服务，AI 模型使用了 Python 基于 TensorFlow 和 Torch 框架。</p><p></p><p>业务需求的系统低延迟计算和多语言系统模块的交互，给我们的性能优化带来了挑战。这次分享，将带来我们对系统全链路从数据采集 - 数据计算 - 模型预测 - 交易下单，全流程进行优化的实践分享，包括怎样高效的在 Java 处理计算 C++ 高频产生的时间序列数据，怎么降低高频产生、长生命周期数据对 Java GC 的影响，怎么高效部署调用低延迟、多模型、多版本的 AI 模型预测服务，系统故障的数据断点快速恢复等。</p><p></p><p>演讲提纲：</p><p></p><p>背景与项目概况</p><p>○ 量化交易系统介绍</p><p>○ 项目技术架构</p><p>○ C++/ Java / Python 多语言交互</p><p>全链路数据流优化</p><p>○ 实时行情数据收集与处理</p><p>○ 低延迟、高吞吐性能挑战</p><p>○ 尝试的优化手段：GC Tuning，Direct Buffer</p><p>○ 我们的解决方案</p><p>○ 性能优化效果</p><p>服务化 AI 模型预测</p><p>○ Tensorflow 模型性能优化实践</p><p>○ Torch 模型转换</p><p>总结与展望</p><p>○ 复杂模型和低延迟预测性能的权衡</p><p>○ 目标展望：更快、更准</p><p></p><p>听众收益点：</p><p></p><p>○ 构建高性能、低延迟的智能量化交易系统</p><p>○ 多语言开发的复杂系统的全链路性能分析和优化</p><p>○ AI 模型在智能量化交易系统的实践</p><p></p><p>除上述演讲外，QCon 上海还将围绕&nbsp;<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart\">GenAI和通用大模型应用探索</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1596?utm_source=infoqweb&amp;utm_medium=teacherart\">AI&nbsp;Agent&nbsp;与行业融合应用的前景</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart\">LLM&nbsp;时代的性能优化</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart\">智能化信创软件&nbsp;IDE</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart\">面向人工智能时代的架构</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart\">性能工程：提升效率和创新的新方法</a>\"等专题进行交流。</p><p></p><p>QCon 上海 2023，相约 12 月！ 8 折优惠还剩最后 3 天，现在购票立减￥1360！咨询购票请联系：18514549229（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/0113b3dfb187d5f9988b7eb16d2e0594.png\" /></p><p></p>",
    "publish_time": "2023-11-29 11:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "聚焦 AI 和大数据，2023 全球 AI 前沿科技大会等你来打卡！",
    "url": "https://www.infoq.cn/article/TjHG4EwAoLByAMi0VWXz",
    "summary": "<p>大模型正在以前所未有的速度掀起创新型变革，站在时代的交叉路口，企业若想更好地洞察市场、提升生产效率、优化运营管理，无疑需要更大规模、更复杂的数据分析和 AI 应用进行支撑。</p><p></p><p>当数据和 AI 已经成为企业核心竞争力的重要组成部分，推进数据和 AI 基础设施的现代化便是企业数字化转型的重要举措。但摆在企业面前的挑战却层出不穷：</p><p></p><p>如何才能提升大规模数据处理能力？如何准确把握 AI 和大数据分析的最新落地实践与前沿趋势？又该如何解决 GPU 稀缺、数据工程复杂以及资源未充分利用等挑战？</p><p></p><p>上述提到的种种挑战都严重阻碍了数据价值的释放，然而，在这样的背景下，依旧不乏一批先行者与实践者率先找到了最佳实践路径。在 12 月 9 日的“2023 全球 AI 前沿科技大会”上，将为你奉上 AI 和大数据分析在不同行业的最新进展、趋势及对未来的展望。</p><p></p><p>此次大会由 Alluxio 与北京大学计算机学院、中关村融创企业开放创新促进会、中关村创业大街联合举办。</p><p>大会将邀请中国科学院院士梅宏、Databricks 和 Anyscale 联合创始人兼执行主席 Ion Stoica、Alluxio 创始人兼首席执行官李浩源、美国卡内基梅隆大学计算机学院软件研究所助理教授方飞、面壁智能联合创始人、CEO 李大海、Alluxio 创始成员兼开源社区副总裁范斌以及科大讯飞北京研究院副院长李家琦等国内外知名学者、企业技术专家，他们将围绕“智算加速，建瓴未来”这一主题，带来最佳实践与趋势洞察。</p><p></p><p>不仅大咖云集，本场大会的主会场内容还涵盖了 6 大前沿主题 +1 场圆桌会议，从数据基础设施软件基座到大模型应用探索，从面向未来的建设展望到挖掘大模型的无限潜能。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/55/550864d8bacfb28f6cfd714551aef00d.jpeg\" /></p><p></p><p>此外，还单独设置大数据分析专场 +AI/ML 专场。在【AI/ML】会场中，来自知乎、Shopee、快手、MemVerge、PingCAP、Alluxio 的 6 位嘉宾，将围绕 AI 场景中 Alluxio 加速模型训练与模型上线的实战经验展开分享；在【大数据分析】会场中，来自联通、Uber、微软、B 站、携程、Alluxio 的 6 位嘉宾将围绕大数据时代背景下，多样化应用与探索，为同行业其他品牌带来诸多应用借鉴。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f4/f405ef4156f658a1a46d6209abc71d7f.png\" /></p><p></p><p>众多专家齐聚，前沿趋势与最佳落地实践结合，相信这场理论与实践兼备的大会，定会让你不虚此行！如果你对前沿 AI 和大数据分析技术感兴趣，并期待收获一次沉浸式的学习体验，欢迎大家参与“2023 全球 AI 前沿科技大会”。</p><p></p><p>报名通道现已开启，欢迎扫描下方二维码提前占位，12 月 9 日 09:00-17:30，我们在北京中关村国家自主创新示范区会议中心，与你不见不散！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6d/6d9edfa411cd3a0823c4936862bea5e2.png\" /></p><p></p><p>不仅议程安排足够丰富，到场的小伙伴还会获得由 Alluxio 准备的 5 重精美礼品，品类多达 20+ 种，欢迎到场赢取惊喜哦～<a href=\"https://www.infoq.cn/form/?id=1928&amp;utm_source=gzh&amp;sign=iq_655f138c0be1e\">也可点击此链接，直接报名！</a>\"</p>",
    "publish_time": "2023-11-29 13:11:33",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "手把手教你在JavaScript中使用LangChain，解锁AI应用能力",
    "url": "https://www.infoq.cn/article/mtCjWCpbmQWGIbVjKcyE",
    "summary": "<p>JS 版的 LangChain，是一个功能丰富的 JavaScript 框架。不管你是开发者还是研究人员都可以利用该框架通过创建语言分析模型和 Agents 来开展各项实验。该框架还提供了十分丰富的功能设置，基于这些功能设置，NLP 爱好者可以通过构建自定义模型来提高文本数据的处理效率。与此同时，作为一个 JS 框架，开发人员可以轻松的将他们的 AI 应用集成到自己的 Web 应用中。</p><p></p><p></p><h2>环境准备</h2><p></p><p></p><p>安装下面的步骤，我们创建一个新目录并且安装 LangChain 的 npm 包：</p><p></p><p>1.执行如下命令，安装 LangChain 的 npm 包</p><p></p><p><code lang=\"null\">npm install -S langchain\n</code></p><p></p><p>2.在目录下面创建一个以.mjs 为后缀的文件（例如：test1.mjs）</p><p></p><p></p><h2>Agents（智体）</h2><p></p><p></p><p>在 LangChain 中，一个 Agent 代表的是一个具备理解和生成文本能力的实例。通过给这些 Agent 设置特定行为和数据源，就可以训练他们执行各种与语言相关的任务，从而使他们具备为更多的应用提供服务的能力。</p><p></p><p></p><h3>创建 LangChain 的 Agent</h3><p></p><p></p><p>利用 LangChain 框架创建的 Agent 在数据获取和响应优化上都支持“工具”的配置。请看下面的示例代码。该例中，Agent 体使用 Serp API（一个网络搜索 API）在互联网上搜索与输入内容相关的信息，然后根据搜索得到的内容完成响应数据的生成，与此同时，它还使用 llm-math 工具来执行诸如 转换单位、百分比对比等 数学运算任务。</p><p></p><p><code lang=\"null\">// langchain 智能体引入\nimport { initializeAgentExecutorWithOptions } from \"langchain/agents\";\n// 引入语言模型：OpenAi\nimport { ChatOpenAI } from \"langchain/chat_models/openai\";\n// 引入网络搜索工具\nimport { SerpAPI } from \"langchain/tools\";\n// 引入计算函数 工具\nimport { Calculator } from \"langchain/tools/calculator\";\n// OpenAI 的 API 访问的密钥\nprocess.env[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_KEY\"\n// SerpAPI 访问密钥\nprocess.env[\"SERPAPI_API_KEY\"] = \"YOUR_SERPAPI_KEY\"\n// 创建工具链\nconst tools = [new Calculator(), new SerpAPI()];\n// 模型配置，这里用的是 OpenAI gpt-3.5-turbo\nconst model = new ChatOpenAI({ modelName: \"gpt-3.5-turbo\", temperature: 0 });\n// 智能体初始化\nconst executor = await initializeAgentExecutorWithOptions(tools, model, {\n  agentType: \"openai-functions\",\n  verbose: false,\n});\n// 执行，这里给出的问题是：\"通过搜索互联网，找出自 2010 年以来 Boldy James 发行了多少张专辑，以及 Nas 自 2010 年以来发行了多少张专辑？找出谁发行了更多的专辑，并显示百分比的差异。\"\nconst result = await executor.run(\"By searching the Internet, find how many albums has Boldy James dropped since 2010 and how many albums has Nas dropped since 2010? Find who dropped more albums and show the difference in percent.\");\nconsole.log(result);</code></p><p></p><p>上述代码，在模型创建之后，通过 initializeAgentExecutorWithOptions 函数将模型和工具（SerpAPI 和 Calculator）进行合并，生成了一个 executor（执行者）。在输入端，我们要求 LLM（大语言模型） 通过搜索 Internet（使用 SerpAPI），找出自 2010 年以来，Nas 和 Boldy James 这两位艺术家中谁发行了更多专辑，并技术差值百分比（使用计算器）。</p><p></p><p>在该例子中，我通过明确地告诉 LLM“通过搜索互联网…”，以使它通过互联网获取最新数据，而不使用 OpenAI 的的默认数据（该数据截止 2021 年），从而得出正确答案。</p><p></p><p></p><blockquote>译者注：OpenAI于2023年11月2日发布会上，表示其模型数据已经更新到了2023年4月。</blockquote><p></p><p></p><p>下面是上面代码的输出：</p><p></p><p><code lang=\"null\">&gt; node test1.mjs从 2010 年至今，Boldy James 发了 4 张专辑，Nas 发了 17 张因此，Nas 比 Boldy James 发行的专辑要多，两者发行专辑的差值是 13我们将使用如下公式：(差值 / 总值)*100，来计算差值百分比在这里，差值是 13，总值是 17因此差值百分比是：(13/17)*100 = 76.47%所以，从 2010 年至今，Nas 发布的专辑比 Boldy James 多了 76。47%\n</code></p><p></p><p></p><h2>模型（Models）</h2><p></p><p></p><p>LangChain 中支持三种类型的模型使用方式：</p><p></p><p>LLM（大语言模型）Chat Model（对话模型）Embeddings（Embeddings 技术是一种将高纬数据转为低维数据的技术）</p><p></p><p>下面通过示例，我们一起来了解这三种模型的使用。</p><p></p><p></p><h3>语言模型</h3><p></p><p></p><p>LangChain 为 JavaScript 提供了使用语言模型能力，通过该能力 JS 可以根据文本输出生成文本输出。它不像聊天模型那么复杂，最适合处理简单的输入 - 输出的语言任务。下面是一个基于 OpenAI 模型的代码示例：</p><p></p><p><code lang=\"null\">import { OpenAI } from \"langchain/llms/openai\";\nconst llm = new OpenAI({\n  openAIApiKey: \"你自己的 OpenAI 的密钥\",\n  model: \"gpt-3.5-turbo\",\n  temperature: 0\n});\nconst res = await llm.call(\"List all red berries\");\nconsole.log(res);</code></p><p></p><p>如你所见，该例是要求 OpenAI 的 gpt-3.5-turbo 模型罗列所有的红色浆果。其中，我将 temperature 设为 0，其目的是为了确保 LLM 输出结果的准确性。下面是输出的结果：</p><p></p><p><code lang=\"null\">1. Strawberries\n2. Cranberries\n3. Raspberries\n4. Redcurrants\n5. Red Gooseberries\n6. Red Elderberries\n7. Red Huckleberries\n8. Red Mulberries</code></p><p></p><p></p><h3>对话模型</h3><p></p><p></p><p>如果你需要更复杂的答案和对话，则需要使用对话模型。对话模型在技术上与语言模型有何不同？好吧，用 LangChain 官方文档 的话来说：</p><p></p><p></p><blockquote>对话模型是语言模型的一个变体。虽然对话模型在底层使用的依然是大语言模型，但是他们在接口上略有不同。对话模型没有使用“文本输入、文本输出”格式的API，而是使用了一个基于“聊天消息”来实现输入输出的接口。</blockquote><p></p><p></p><p>下面是一个简单的 JavaScript 对话模型脚本（该示例相当无用但很有趣）。</p><p></p><p><code lang=\"null\">import { ChatOpenAI } from \"langchain/chat_models/openai\";\nimport { PromptTemplate } from \"langchain/prompts\";\n// 创建对话，配置密钥、模型版本、和 temperature\nconst chat = new ChatOpenAI({\n  openAIApiKey: \"YOUR_OPENAI_KEY\",\n  model: \"gpt-3.5-turbo\",\n  temperature: 0\n});\n// 通过提示词模版，创建提示词\nconst prompt = PromptTemplate.fromTemplate(`你现在扮演一个诗人的角色，在回答时请保持语言的韵律: {question}`);\nconst runnable = prompt.pipe(chat);\n// 对话执行\nconst response = await runnable.invoke({ question: \"Djokovic, Federer 和 Nadal，三人中谁是最好的网球运动员?\" });\nconsole.log(response);</code></p><p></p><p>如你所见，上面的代码首先发送了一条系统消息给对话机器人，告诉它，当前扮演的是一个诗人角色，且在回答的时候要始终使用押韵的方式。然后再向对话机器人发送一条用户消息，让它给出 Djokovic、Federer 和 Nadal 这三人中，谁是最好的网球运动员。如果你运行这个脚本，将会看到如下内容：</p><p></p><p><code lang=\"null\">// AI 消息体\nAIMessage.content:\n'In the realm of tennis, they all shine bright,\\n' +\n'Djokovic, Federer, and Nadal, a glorious sight.\\n' +\n'Each with their unique style and skill,\\n' +\n'Choosing the best is a difficult thrill.\\n' +\n'\\n' +\n'Djokovic, the Serb, a master of precision,\\n' +\n'With agility and focus, he plays with decision.\\n' +\n'His powerful strokes and relentless drive,\\n' +\n\"Make him a force that's hard to survive.\\n\" +\n'\\n' +\n'Federer, the Swiss maestro, a true artist,\\n' +\n'Graceful and elegant, his game is the smartest.\\n' +\n'His smooth technique and magical touch,\\n' +\n'Leave spectators in awe, oh so much.\\n' +\n'\\n' +\n'Nadal, the Spaniard, a warrior on clay,\\n' +\n'His fierce determination keeps opponents at bay.\\n' +\n'With his relentless power and never-ending fight,\\n' +\n'He conquers the court, with all his might.\\n' +\n'\\n' +\n\"So, who is better? It's a question of taste,\\n\" +\n\"Each player's greatness cannot be erased.\\n\" +\n\"In the end, it's the love for the game we share,\\n\" +\n'That makes them all champions, beyond compare.'</code></p><p></p><p></p><blockquote>译注：这是一首诗，实在翻译不来，就不翻译了哈。</blockquote><p></p><p></p><p></p><h3>Embeddings</h3><p></p><p></p><p>Embeddings 支持将文本数据转换为向量数据，以便于和其他相关的内容进行关联。这可能听起来有点抽象，让我们直接来看一个例子：</p><p></p><p><code lang=\"null\">import { OpenAIEmbeddings } from \"langchain/embeddings/openai\";\n\nprocess.env[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_KEY\"\n\nconst embeddings = new OpenAIEmbeddings();\n\nconst res = await embeddings.embedQuery(\"谁是万维网之父?\");\nconsole.log(res)</code></p><p></p><p>这里是数据返回，是一大串的浮点数据：</p><p></p><p><code lang=\"null\">[\n  0.02274114,  -0.012759142,   0.004794503,  -0.009431809,    0.01085313,\n  0.0019698727,  -0.013649924,   0.014933698, -0.0038185727,  -0.025400387,\n  0.010794181,   0.018680222,   0.020042595,   0.004303263,   0.019937797,\n  0.011226473,   0.009268062,   0.016125774,  0.0116391145, -0.0061765253,\n  -0.0073358514, 0.00021696436,   0.004896026,  0.0034026562,  -0.018365828,\n  ... 1501 more items\n]</code></p><p></p><p>这就是 Embeddings 的形态。仅仅是为了六个单词，就用了那么多浮点数！利用 Embeddings 技术，可以将输入文本与潜在答案、相关文本、名称等进行关联。</p><p></p><p>下面让我们来看一个 Embeddings&nbsp;模型的一个使用案例。</p><p></p><p>在下面的脚本中，我们向模型提问：“世界上最重的动物是什么？”。然后我们借助 Embeddings 技术让模型能从我们提供的参考答案中找出最佳答案。</p><p></p><p><code lang=\"null\">import { OpenAIEmbeddings } from \"langchain/embeddings/openai\";\n\nprocess.env[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_KEY\"\n\nconst embeddings = new OpenAIEmbeddings();\n// 余弦相似度函数\nfunction cosinesim(A, B) {\n    var dotproduct = 0;\n    var mA = 0;\n    var mB = 0;\n\n    for(var i = 0; i &lt; A.length; i++) {\n        dotproduct += A[i] * B[i];\n        mA += A[i] * A[i];\n        mB += B[i] * B[i];\n    }\n\n    mA = Math.sqrt(mA);\n    mB = Math.sqrt(mB);\n    var similarity = dotproduct / (mA * mB);\n\n    return similarity;\n}\n// 嵌入 1：蓝鲸是世界上最重的动物\nconst res1 = await embeddings.embedQuery(\"The Blue Whale is the heaviest animal in the world\");\n// 嵌入 2：乔治·奥威尔写了《一九八四》这本书\nconst res2 = await embeddings.embedQuery(\"George Orwell wrote 1984\");\n// 嵌入 3：随机内容\nconst res3 = await embeddings.embedQuery(\"Random stuff\");\n// 源内容数组\nconst text_arr = [\"The Blue Whale is the heaviest animal in the world\", \"George Orwell wrote 1984\", \"Random stuff\"]\n// 利用 embeddings 转换之后的数据数组\nconst res_arr = [res1, res2, res3]\n// 问题：世界上最重的动物是什么？\nconst question = await embeddings.embedQuery(\"What is the heaviest animal?\");\n// 相似度数组\nconst sims = []\nfor (var i=0;i<=\"\" code=\"\"></code></p><p></p><p><code lang=\"null\">在上面的代码中，先定义了一个计算相识度的函数：cosinesim(A, B)，其次利用 embeddings 技术将每个答案转换为了向量数据，接着使用 cosinesim 函数计算出了每个答案和输入问题的相识度值，最高拿到相识度最高的答案，完成输出。下面是输出的结果：</code></p><p></p><p><code lang=\"null\"><code lang=\"null\">The Blue Whale is the heaviest animal in the world\n// 蓝鲸是世界上最重的动物</code></code></p><p></p><p></p><h2><code lang=\"null\">Chunks（数据块）</code></h2><p></p><p></p><p><code lang=\"null\">由于 LangChain 模型在生产响应的时候不支持大文本的输入。所以需要用到诸如文本分割等数据分块的技术将大文本数据分割成多个 Chunk。下面我向你演示 LangChain 中两种简单的文本数据分割方法，以实现大文本输入。</code></p><p></p><p></p><h4><code lang=\"null\">方法一、CharacterTextSplitter</code></h4><p></p><p></p><p><code lang=\"null\">为了避免分割之后，Chunk 中内容中断，可以使用换行符来进行文本拆分，该方法是在每次出现换行符时执行分割，可以通过 CharacterTextSplitter 来实现，示例代码如下：</code></p><p></p><p><code lang=\"null\"><code lang=\"null\">import { Document } from \"langchain/document\";import { CharacterTextSplitter } from \"langchain/text_splitter\";// 创建一个分割器，使用换行符进行分割，每个区块的大小是 7，区块的重叠度是 3const splitter = new CharacterTextSplitter({  separator: \"\\n\",  chunkSize: 7,  chunkOverlap: 3,});const output = await splitter.createDocuments([your_text]);\n</code></code></p><p></p><p><code lang=\"null\">这是拆分文本的一种有用的方法，同时，你可以使用任何字符作为 Chunk 的分隔符，而不仅仅是换行符（\\n）</code></p><p></p><p></p><h4><code lang=\"null\">方法二、RecursiveCharacterTextSplitter</code></h4><p></p><p></p><p><code lang=\"null\">如果要严格按一定长度的字符拆分文本，可以使用 RecursiveCharacterTextSplitter 来实现，示例代码如下：</code></p><p></p><p><code lang=\"null\"><code lang=\"null\">import { RecursiveCharacterTextSplitter } from \"langchain/text_splitter\";const splitter = new RecursiveCharacterTextSplitter({  // chunk 的大小  chunkSize: 100,  // chunk 的重叠度  chunkOverlap: 15,});const output = await splitter.createDocuments([your_text]);\n</code></code></p><p></p><p><code lang=\"null\">在此示例中，会将文本按照每 100 个字符进行一次拆分，每个 Chunk 的重叠度为 15 个字符。</code></p><p></p><p></p><h4><code lang=\"null\">Chunk 的大小和重叠度</code></h4><p></p><p></p><p><code lang=\"null\">通过上面的示例，想必你已经迫不及待的想知道 Chunk 的大小和重叠度这两个参数确切的含义以及它们对性能的影响了吧。下面我简单从两方面解释下：</code></p><p></p><p><code lang=\"null\">chunkSize 决定了每个 Chunk 中的字符数量。chunkSize 的值越大，那么 Chunk 中的字符数就越多，LangChain 处理该 Chunk 和产生对应输出所需的时间就越长，反之亦然。chunkOverlap 是用于设置了每个 Chunk 之间共享上下文的大小。chunkOverlap 的值越高，Chunk 的冗余度就越高 ;chunkOverlap 的值越低，Chunk 之间共享的上下文就越少。通常将 chunkOverlap 设置在 Chunk 大小的 10% 到 20% 之间会比较理想，当然，真正理想 chunkOverlap 值还是要根据不同的文本类型和使用场景来确定。</code></p><p></p><p></p><h2><code lang=\"null\">Chains（模型链）</code></h2><p></p><p></p><p><code lang=\"null\">通过单个 LLM 的输入输出是无法完成一些更为复杂的任务，因此需要利用 Chains，通过将多个 LLM 的功能链接一起来完成。下面是一个很有意思的例子：</code></p><p></p><p><code lang=\"null\"><code lang=\"null\">import { ChatPromptTemplate } from \"langchain/prompts\";\nimport { LLMChain } from \"langchain/chains\";\nimport { ChatOpenAI } from \"langchain/chat_models/openai\";\n\nprocess.env[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_KEY\"\n\n// 这是一段知识库\nconst wiki_text = `\nAlexander Stanislavovich 'Sasha' Bublik (Александр Станиславович Бублик; born 17 June 1997) is a Kazakhstani professional tennis player. \nHe has been ranked as high as world No. 25 in singles by the Association of Tennis Professionals (ATP), which he achieved in July 2023, and is the current Kazakhstani No. 1 player...\n\nAlexander Stanislavovich Bublik was born on 17 June 1997 in Gatchina, Russia and began playing tennis at the age of four. He was coached by his father, Stanislav. On the junior tour, Bublik reached a career-high ranking of No. 19 and won eleven titles (six singles and five doubles) on the International Tennis Federation (ITF) junior circuit.[4][5]...\n`\nconst chat = new ChatOpenAI({ temperature: 0 });\nconst chatPrompt = ChatPromptTemplate.fromMessages([\n  [\n    \"system\",\n    \"You are a helpful assistant that {action} the provided text\",\n  ],\n  [\"human\", \"{text}\"],\n]);\n// 这里将 2 个模型进行了链接\nconst chainB = new LLMChain({\n  prompt: chatPrompt,\n  llm: chat,\n});\n\nconst resB = await chainB.call({\n  action: \"lists all important numbers from\",\n  text: wiki_text,\n});\nconsole.log({ resB });</code></code></p><p></p><p><code lang=\"null\">在上面的代码中，我在提示词中设置了一个变量，同时通过将 LLM 的 temperature 设置为 0，以要求 LLM 给出一个基于事实的回答。该例中，我要求 LLM 基于给定的简短知识库，输出我最喜欢网球运动员的关键数据。以下是 LLM 给出的回答：</code></p><p></p><p><code lang=\"null\"><code lang=\"null\">{\n  resB: {\n    text: 'Important numbers from the provided text:\\n' +\n      '\\n' +\n      \"- Alexander Stanislavovich 'Sasha' Bublik's date of birth: 17 June 1997\\n\" +\n      \"- Bublik's highest singles ranking: world No. 25\\n\" +\n      \"- Bublik's highest doubles ranking: world No. 47\\n\" +\n      \"- Bublik's career ATP Tour singles titles: 3\\n\" +\n      \"- Bublik's career ATP Tour singles runner-up finishes: 6\\n\" +\n      \"- Bublik's height: 1.96 m (6 ft 5 in)\\n\" +\n      \"- Bublik's number of aces served in the 2021 ATP Tour season: unknown\\n\" +\n      \"- Bublik's junior tour ranking: No. 19\\n\" +\n      \"- Bublik's junior tour titles: 11 (6 singles and 5 doubles)\\n\" +\n      \"- Bublik's previous citizenship: Russia\\n\" +\n      \"- Bublik's current citizenship: Kazakhstan\\n\" +\n      \"- Bublik's role in the Levitov Chess Wizards team: reserve member\"\n  }\n}</code></code></p><p></p><p><code lang=\"null\">很酷，但这还没有真正展示 Chains 的全部能力。再看一个更实际的例子：</code></p><p></p><p><code lang=\"null\"><code lang=\"null\">import { z } from \"zod\";\nimport { zodToJsonSchema } from \"zod-to-json-schema\";\nimport { ChatOpenAI } from \"langchain/chat_models/openai\";\nimport {\n  ChatPromptTemplate,\n  SystemMessagePromptTemplate,\n  HumanMessagePromptTemplate,\n} from \"langchain/prompts\";\nimport { JsonOutputFunctionsParser } from \"langchain/output_parsers\";\nprocess.env[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_KEY\"\nconst zodSchema = z.object({\n  albums: z\n    .array(\n      z.object({\n        name: z.string().describe(\"The name of the album\"),\n        artist: z.string().describe(\"The artist(s) that made the album\"),\n        length: z.number().describe(\"The length of the album in minutes\"),\n        genre: z.string().optional().describe(\"The genre of the album\"),\n      })\n    )\n    .describe(\"An array of music albums mentioned in the text\"),\n});\nconst prompt = new ChatPromptTemplate({\n  promptMessages: [\n    SystemMessagePromptTemplate.fromTemplate(\n      \"List all music albums mentioned in the following text.\"\n    ),\n    HumanMessagePromptTemplate.fromTemplate(\"{inputText}\"),\n  ],\n  inputVariables: [\"inputText\"],\n});\nconst llm = new ChatOpenAI({ modelName: \"gpt-3.5-turbo\", temperature: 0 });\nconst functionCallingModel = llm.bind({\n  functions: [\n    {\n      name: \"output_formatter\",\n      description: \"Should always be used to properly format output\",\n      parameters: zodToJsonSchema(zodSchema),\n    },\n  ],\n  function_call: { name: \"output_formatter\" },\n});\nconst outputParser = new JsonOutputFunctionsParser();\nconst chain = prompt.pipe(functionCallingModel).pipe(outputParser);\nconst response = await chain.invoke({\n  inputText: \"My favorite albums are: 2001, To Pimp a Butterfly and Led Zeppelin IV\",\n});\nconsole.log(JSON.stringify(response, null, 2));</code></code></p><p></p><p><code lang=\"null\">此脚本通过读取输入的文本信息，识别所有提到的音乐专辑以及将每张专辑的名称、艺术家、长度和流派，最后将所有数据转换为 JSON 格式进行输出。以下是输入“我最喜欢的专辑是：2001 年、To Pimp a Butterfly 和 Led Zeppelin IV”的输出：</code></p><p></p><p><code lang=\"null\"><code lang=\"null\">{\n  \"albums\": [\n    {\n      \"name\": \"2001\",\n      \"artist\": \"Dr. Dre\",\n      \"length\": 68,\n      \"genre\": \"Hip Hop\"\n    },\n    {\n      \"name\": \"To Pimp a Butterfly\",\n      \"artist\": \"Kendrick Lamar\",\n      \"length\": 79,\n      \"genre\": \"Hip Hop\"\n    },\n    {\n      \"name\": \"Led Zeppelin IV\",\n      \"artist\": \"Led Zeppelin\",\n      \"length\": 42,\n      \"genre\": \"Rock\"\n    }\n  ]\n}</code></code></p><p></p><p><code lang=\"null\">虽然这只是一个有趣的例子，但通过该技术可以将非结构化的文本数据转为结构化的数据，从而使用在其他应用系统中。</code></p><p></p><p></p><h2><code lang=\"null\">不止 OpenAI</code></h2><p></p><p></p><p><code lang=\"null\">尽管在演示 LangChain 不同功能的示例中，我一直都是使用 OpenAI 模型。但其实 LangChain 并不局限于 OpenAI 模型。你可以将 LangChain 与许多其他 LLM 和 AI 服务一起使用。在 LangChain 的官方文档中可以找到 LangChain 的 JS 版本所支持集成的完整 LLM 列表。</code></p><p></p><p><code lang=\"null\">例如，你可以将 Cohere 与 LangChain 一起使用。再使用 npm install cohere-ai 安装 Cohere 之后，你就可以像下面示例代码一样，使用 LangChain 和 Cohere 编写一个简单的问答脚本：</code></p><p></p><p><code lang=\"null\"><code lang=\"null\">import { Cohere } from \"langchain/llms/cohere\";\nconst model = new Cohere({\n  maxTokens: 50,\n  apiKey: \"YOUR_COHERE_KEY\", // In Node.js defaults to process.env.COHERE_API_KEY\n});\nconst res = await model.call(\n  \"Come up with a name for a new Nas album\" // 给 Nas 的新专辑起个名字\n);\nconsole.log({ res });</code></code></p><p></p><p><code lang=\"null\">输出的结果如下：</code></p><p></p><p><code lang=\"null\"><code lang=\"null\">{\n  res: ' Here are a few possible names for a new Nas album:\\n' +\n    '\\n' +\n    \"- King's Landing\\n\" +\n    \"- God's Son: The Sequel\\n\" +\n    \"- Street's Disciple\\n\" +\n    '- Izzy Free\\n' +\n    '- Nas and the Illmatic Flow\\n' +\n    '\\n' +\n    'Do any'\n}</code></code></p><p></p><p></p><h2><code lang=\"null\">总结</code></h2><p></p><p></p><p><code lang=\"null\">读完本篇文章，相信你已经对 JS 版的 LangChain 各方面能力都有所了解了。现在你可以通过 LangChain 用 JS 开发各种基于 AI 的应用和体验 LLM 了。当然，也请你必参考 LangChainJS 的官方文档，以了解更多有关特定功能的详细信息。</code></p><p></p><p><code lang=\"null\">最后，预祝你在 JavaScript 中愉快的使用 LangChain 进行编码和体验！如果你喜欢这篇文章，你可能还想阅读如何在 Python 中使用 LangChain 这篇文章：</code></p><p></p><p><code lang=\"null\"><a href=\"https://www.sitepoint.com/langchain-python-complete-guide/\">https://www.sitepoint.com/langchain-python-complete-guide/</a>\"</code></p><p></p><p><code lang=\"null\">原文链接：</code></p><p></p><p><code lang=\"null\"><a href=\"https://www.sitepoint.com/langchain-javascript-complete-guide/\">https://www.sitepoint.com/langchain-javascript-complete-guide/</a>\"</code></p><p></p><p></p><h5><code lang=\"null\">相关阅读：</code></h5><p></p><p><code lang=\"null\"><a href=\"https://www.infoq.cn/article/Rujx6tv3Grxh3HYMZJqK?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">LangChain&nbsp;的问题所在</a>\"</code></p><p><code lang=\"null\"><a href=\"https://www.infoq.cn/article/67vMj2F2HTC24fDdE64a?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">OpenAI 用 45 分钟重塑游戏规则！干掉 MJ、LangChain，创造“不会编程的应用开发者”新职业</a>\"</code></p><p><code lang=\"null\"><a href=\"https://www.infoq.cn/article/yl8eJoSfkHbOCyFzCcgw?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">LangChain：2023 年最潮大语言模型 Web 开发框架</a>\"</code></p><p><code lang=\"null\"><a href=\"https://xie.infoq.cn/article/d9e58b3a7e0fe2a369269c923?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">理论 + 实践详解最热的 LLM 应用框架 LangChain</a>\"</code></p>",
    "publish_time": "2023-11-29 13:58:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "JetBrains发布了Kotlin Multiplatform的首个稳定版本",
    "url": "https://www.infoq.cn/article/FiuarMFJgHpYsARFIrb0",
    "summary": "<p>JetBrains提供了Kotlin Multiplatform的首个稳定版本，支持跨iOS、Android、桌面、Web和服务器进行代码共享——尽管用于共享用户界面（UI）代码的部分，Compose Multiplatform，仅适用于Android和桌面。</p><p>&nbsp;</p><p>Kotlin是由JetBrains开发的一种JVM（Java虚拟机）语言，并被谷歌（Google）用作Android开发的首选语言。既然Java已经是为跨平台代码而设计的了，那么Kotlin Multiplatform又增加了什么呢？答案是Kotlin不仅仅是一种JVM语言。<a href=\"https://kotlinlang.org/docs/native-overview.html#why-kotlin-native\">Kotlin/Native</a>\"使用MinGW（适用于Windows的GCC工具链）和Android NDK编译成适用于macOS、iOS、Linux、Windows的独立可执行文件。<a href=\"https://kotlinlang.org/docs/js-overview.html\">Kotlin/JS</a>\"将Kotlin转换为JavaScript。Kotlin Wasm仍处于实验阶段，可编译成WebAssembly。</p><p>&nbsp;</p><p><a href=\"https://kotlinlang.org/lp/multiplatform/\">Kotlin Multiplatform</a>\"是一种跨所有这些平台共享非GUI代码的技术。它解决了代码共享的两个常见问题，即对于所有目标平台的一个子集，仅需部分共享某些代码的需求，以及需要访问特定于平台的API。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/62/626b86de787d7d3c3bc4aea2d812185f.png\" /></p><p></p><p>Kotlin Multiplatform中的Expect和Actual，解决了调用本机平台API的需求</p><p>&nbsp;</p><p>本机API问题是通过<a href=\"https://kotlinlang.org/docs/multiplatform-connect-to-apis.html\">预期声明和实际声明</a>\"的机制来解决的。 expect 关键字将声明标记为将与用actual关键字标记的代码匹配，actual关键字可能是特定于平台的。JetBrains建议仅对平台API使用expect/actual，其他情况使用普通接口。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c6/c6a98abd1a214e39d3daf29f724a4547.png\" /></p><p></p><p>2022年的一项调查显示，Kotlin Multiplatform应用程序的代码共享率高达63%</p><p>&nbsp;</p><p>Kotlin Multiplatform适用于非GUI代码，但有一个相关项目<a href=\"https://www.jetbrains.com/lp/compose-multiplatform/\">Compose Multiplatform</a>\"，它可用于创建共享的用户界面（UI）。 Compose Multiplatform基于谷歌的<a href=\"https://developer.android.com/jetpack/compose\">Jetpack Compose</a>\"，用于构建Android用户界面。 Compose Multiplatform在桌面平台、macOS、Linux和Windows上也是稳定版本，但在iOS上是Alpha版本，在Web上是实验性的。根据JetBrains的说法，Kotlin Multiplatform已经被包括Netflix和VMWare在内的公司所使用。</p><p>&nbsp;</p><p>如果Compose Multiplatform还没有准备好，那么开发者如何支持iOS呢？这可以通过使用<a href=\"https://developer.apple.com/xcode/swiftui/\">SwiftUI</a>\"来实现，SwiftUI是苹果（Apple）的官方UI设计语言，它是基于声明式代码的。有一些代码示例正是采用了这种方式实现的。</p><p>&nbsp;</p><p>JetBrains还表示，他们的目标是在2024年发布面向iOS的Compose Multiplatform测试版本，Kotlin/Wasm也在积极开发中。</p><p>&nbsp;</p><p>去年，谷歌通过<a href=\"https://android-developers.googleblog.com/2022/10/announcing-experimental-preview-of-jetpack-multiplatform-libraries.html\">引入</a>\"其他一些Jetpack库的“实验预览”，表达了对Kotlin Multiplatform的一些支持，这些库不是用于生产的，而是用于“在针对Android和iOS应用程序的多平台项目中使用这些Jetpack库的反馈”。请注意，谷歌还提供了使用Dart语言和Flutter UI进行跨平台开发的Flutter。</p><p>&nbsp;</p><p>使用Kotlin而不是Java的另一个原因是<a href=\"https://kotlinlang.org/docs/comparison-to-java.html#what-kotlin-has-that-java-does-not\">它的语言特性</a>\"，包括lambda表达式、扩展函数、类型推理、null安全等等。Kotlin没有检查异常，因为这些不会提高生产力或代码质量。</p><p>&nbsp;</p><p>Kotlin Multiplatform和Compose Multiplatform均可免费使用。<a href=\"https://github.com/JetBrains/kotlin\">Kotlin的代码</a>\"位于Github上，许可证是Apache2.0。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://devclass.com/2023/11/01/jetbrains-offers-first-stable-release-of-kotlin-multiplatform/\">https://devclass.com/2023/11/01/jetbrains-offers-first-stable-release-of-kotlin-multiplatform/</a>\"</p><p></p><p></p><h5>相关阅读：</h5><p></p><p><a href=\"https://xie.infoq.cn/article/942bb329c38cd72544c860f41\">浅谈 Kotlin 编程 01. 初识 Kotlin 和入门示例</a>\"</p><p><a href=\"https://xie.infoq.cn/article/ba7cceea4b506026b9cb0d42f\">从 HelloWorld 看 Java 与 Kotlin</a>\"</p><p><a href=\"https://www.infoq.cn/article/aTY2ysTOjaEwUv9Hzls6\">Meta 将百万行代码从 Java 移植到 Kotlin</a>\"</p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MzAxODcyNjEzNQ==&amp;mid=2247571124&amp;idx=1&amp;sn=93bb6d6dc0678677eb89f03fbc256824&amp;chksm=9bd27b2caca5f23a436467fe7b5f6c3809a9bba3d7ccd4091bc2c70ac714814e7092709758a5&amp;scene=27#wechat_redirect\">又一巨头从 Java 迁移到 Kotlin ！</a>\"</p>",
    "publish_time": "2023-11-29 14:02:06",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "OpenAI发布了GPTs，可以创建无代码、定制版本的ChatGPT",
    "url": "https://www.infoq.cn/article/u4VX7rDm5rw1sdXa7YOI",
    "summary": "<p>在<a href=\"https://www.infoq.com/news/2023/11/openai-announcements-1stdevday/\">最近的OpenAI开发者大会</a>\"上，OpenAI宣布将推出GPTs，这是专为特定任务创建的ChatGPT的定制版本。该公司表示，开发者还能够在即将推出的ChatGPT商店中分享他们的GPTs并从中获利。</p><p>&nbsp;</p><p>GPTs提供了一种将ChatGPT与定制指令、外部知识和任何技能组合在一起的机制。它们试图满足定制化ChatGPT以适应特定用途的需求，例如学习棋盘游戏规则、帮助教授数学或设计贴纸等。</p><p>&nbsp;</p><p></p><blockquote>许多高级用户都会维护一个仔细制作的提示和指令集列表，手动将它们复制到ChatGPT中。现在，GPT可以为你完成所有这些操作。</blockquote><p></p><p>&nbsp;</p><p>在GPT出现之前，提示工程是专门定制ChatGPT行为的最常见方法。根据OpenAI的说法，构建GPT不需要编码技能，非常适合教育工作者、教练或任何喜欢构建有用工具的人。</p><p>&nbsp;</p><p></p><blockquote>创建一个GPT就像开始一次对话，给它指令和额外的知识，并选择它可以做的事情，比如搜索互联网、制作图片或分析数据。</blockquote><p></p><p>&nbsp;</p><p>使用OpenAI的界面，创建GPT的第一步是与ChatGPT进行对话，描述你想要实现的目标。完成这一步后，你可以定义指令、对话启动问题、知识、能力和动作。</p><p>&nbsp;</p><p>指令部分极为关键。在这里，你需要确定使用哪些资源、选择什么风格和语调，以及定义期望的行为模式。比如，你可以设定当用户提供特定数据时，你的 GPT 应如何利用这些数据进行网上搜索，接着运行某些脚本来处理搜索结果等等。</p><p>&nbsp;</p><p>对话启动问题是你提供的一些示例句子，帮助用户了解他们可以向 GPT 咨询哪些问题。而知识，则是你上传的资源集，这些资源会作为模型的一部分，供 GPT 使用。功能指的是 GPT 能够利用的各种工具，而动作则是指 GPT 调用外部服务的操作。</p><p>&nbsp;</p><p>GPTs 可供订阅了 ChatGPT Plus 的用户使用，并且用户还需启用“Beta 选项”功能。</p><p>&nbsp;</p><p>正如前面提到的，OpenAI 最近还推出了 GPT 商店，这使得用户可以公开分享自己的 GPT。据公司透露，GPT 商店预计将从 2023 年 11 月末开始提供服务，接下来几个月将支持进行货币交易。</p><p>&nbsp;</p><p>此前，ChatGPT 通过集成第三方应用程序，提供了 <a href=\"https://openai.com/blog/chatgpt-plugins\">ChatGPT 插件</a>\" 来修改 ChatGPT 的行为。虽然从这个角度看，GPTs 似乎让插件变得过时，但 <a href=\"https://platform.openai.com/docs/plugins/introduction\">OpenAI 表示他们正推广动作功能</a>\"，这是在插件基础上的进一步发展，旨在利用插件的许多核心理念。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/11/openai-gpts-custom-chatgpt/\">https://www.infoq.com/news/2023/11/openai-gpts-custom-chatgpt/</a>\"</p>",
    "publish_time": "2023-11-29 14:09:02",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "华东政法大学高富平：数据不急于变现，先聚焦治理提升决策效率",
    "url": "https://www.infoq.cn/article/Yo3oeKSHhUtP92sWm4lE",
    "summary": "<p>随着数字化时代的深入发展，数据的重要性日益凸显。当前的趋势是数据不再仅仅被视为一种被动的存储对象，而是成为了活跃的、可以流通和创造价值的资产。然而，这一转变也带来了诸多挑战，尤其是在数据持有权和数据流通的法律和伦理层面。传统的数据所有权概念已不足以适应这种新的数据环境，迫切需要对数据持有权进行重新定义和规范。</p><p>在这样的背景下，我们专访了华东政法大学的教授、《数据二十条》的主要起草者和解读者高富平。在谈及数据持有权时，高教授明确指出，其核心在于保护数据使用者的合法利益，而非仅仅赋予持有者对数据的排他性控制。他特别强调，企业在数据策略上应首先注重治理和标准化，以数据为核心提升智能决策能力。在此基础上，企业可以探索如何有效输出并重用数据集或知识，既支持数据的社会化利用，又为企业创造更多价值。</p><p></p><p>编辑：李忠良</p><p>嘉宾：高富平</p><p></p><p></p><h4>1.&nbsp;数据持有权的核心理念</h4><p></p><p></p><h5>InfoQ：您如何界定“数据持有权”？与我们传统理解中的数据所有权有何本质的区别？</h5><p></p><p>高富平：数据持有权是数据持有者权的简称，它并不是持有者对数据支配权，而是数据使用权，其本质是对数据持有者合法利益的保护。数据持有权并没有给持有者排他控制和使用数据的权利，而是基于持有者合法取得和价值创造而享有使用数据权利。</p><p></p><h5>InfoQ：在制定《数据二十条》的背景下，“数据持有权”这一概念的提出是基于什么样的考虑？</h5><p></p><p>高富平：之所以提出数据持有权是基于数据本身没有价值，而是因为使用而产生价值，因而重要的建立促进数据不断流通利用的制度，使需要数据者能够高效低成本获取和汇集足够大的数据，用于训练算法或机器学习。由于数据是人类认知客观世界的媒介，是可获取、可分享、非排他使用的资源，不能适用传统的排他支配范式，构建数据流通利用秩序。但是，完全采纳“公开即可自由使用”又导致数据的无序利用和滥用。</p><p>为构建数据流通利用的秩序，就按照“合法获取可使用，创造价值的使用者可流通”逻辑，设计出数据持有者权，以创造出与传统排他范式不同的产权范式。其核心是，数据持有者在获取、加工、使用和变现整个过程中，必须协同考虑数据上利益相关者利益，在合规和安全前提使用数据。</p><p></p><h5>InfoQ：为什么“数据持有权”更能适应当前的数据特征，而不是其他的权利形式？</h5><p></p><p>高富平：根本上，数据是客观世界和社会主体存在和活动数字化记录或反映，是认知客观世界、从事各项活动的媒介，不允许任何一个主体排他支配使用；同时，由于数据只是因使用产生价值，而且可以非排他、非竞争性使用，因而奉行合法正当的持有者有权使用是最适合数据资源特征和数据价值特征的产权安排。</p><p>数据虽然有无形性可以视为无形资产，但是，数据的流通利用先要解决的是将不可用或不好用的数据治理成为可用、好用、可重用数据要素，这虽然需要技术工具，但并不属于创造性劳动，其改变也仅仅是数据的质量、可互操作性等，因而数据要素还不易直接纳入到知识产权体系。</p><p>但是，经过不断汇集/融合计算或自主机器学习训练出的算法模型，或者利用算法挖掘分析数据形成的预测、洞察等可以纳入知识产权范畴，寻找合适的保护方式。单就数据要素来讲，无论是物权范式，还是知识产权范式，均不适合。</p><p>&nbsp;</p><p></p><h4>2.&nbsp;数据持有权与数据流通</h4><p></p><p></p><h4>InfoQ：您如何评价“数据持有权”在当前数据流通中的核心地位？</h4><p></p><p>高富平：数据持有权不是一种权利形态，而是构建数据流通秩序的制度体系或工具。如果说，数据流通是数据要素化利用的核心，那么数据持有权就是整个数据要素基础制度的基础。问题在于，目前大家还是简单地在传统产权意义上理解数据持有权，在产权交易基础上理解和建设数据要素市场。没有配套制度设计，解决数据流通信任和安全，权责利配置，徒有有数据持有权概念，不足以开启数据流通。</p><p>&nbsp;</p><p></p><h5>InfoQ：《数据二十条》中，基于“数据持有权”的数据流通制度有哪些关键条款或规定？</h5><p></p><p>高富平：《数据二十条》对数据流通作出基本规范，“支持依法依规在场内和场外采取开放、共享、交换、交易等方式流通数据”，并要求“建立数据流通准入标准规则，强化市场主体数据全流程合规治理，确保流通数据来源合法、隐私保护到位、流通和交易规范。”但流通仍然是建立在“公共数据、企业数据、个人数据的分类分级确权授权制度”基础上，实现“数据使用权交换和市场化流通”。显然，《数据二十条》旨在建立了持有权为基础，以数据使用权流转为核心制度架构，只是仍有许多制度规则和体制机制尚待建立。</p><p></p><h5>InfoQ：在这一制度框架下，如何确保企业和个人的数据权益不受侵犯？</h5><p></p><p>高富平：《二十条》创新性地提出来源者利益保护，显然这是数据持有者享有权利的前提。这也是数据持有权属于治理范式的重要含义。来源者利益是针对依据现行法律在数据上存在合法利益，但因不控制数据的主体而言的。</p><p>为保护社会主体获取和使用数据的权利，允许其他主体获取、持有和使用数据，但必须保护数据上合法权益。这需要数据持有者建立强有力的数据合规体系，同时也有赖国家执法机构，加强执法扼制数据违法和滥用，尤其是支撑灰黑产的数据买卖。</p><p>&nbsp;</p><p></p><h4>3.&nbsp;建立可信安全的数据流通规则及未来展望</h4><p></p><p></p><h5>InfoQ：基于“数据持有权”，构建可信安全的数据流通规则应该遵循哪些原则？</h5><p></p><p>高富平：建立可信安全数据流通规则至少需要建立和遵循以下三个方面的规则：（1）数据流通应当尊重各方数据权益，在促进数据数据流通利用过程中，公平地分享数据利益；（2）营造安全可信的数据流通环境，建立数据交易主体之间的信任关系，以确保数据受控下的安全流通交易；（3）数据流通需要适配的治理，需要建立由数据流通中介机构主导和运营的以数据持有者和数据使用者共同参与的促进共赢、开放的数据治理体系和生态系统。</p><p></p><h5>InfoQ：在推进这一规则的实际应用中，您预测会遇到哪些主要的挑战？</h5><p></p><p>高富平：推进可信安全数据流通，实现数据要素价值，是人类社会面临的新课题，面临许多挑战。</p><p>首先，什么样的数据可以成为要素或资产或产品需要有共识和规则。显然，数据无处不在，无处不有，也并不是特定数据为一个组织控制就成为要素或资产。只有可用、可产生价值的数据才是要素或资产，只有可变现的数据且存在安全流通环境，才可以视为产品。所有这些都需要达成共识，形成大家接受的规则；</p><p>其次，任何产权均是为了构建数据资源利用秩序，产权并不等同于所有权或排他支配权。在构建数据流通利用秩序过程中，我们要克服传统的简单的支配范式，而转向协同各方利益的治理范式。在无法界定出清晰产权情形下，仍然在归属、支配、产权转让概念下思考数据流通，一定是死胡同；</p><p>最后，即使是承认经治理的可重用数据可流通，是经济资源或资产，我们也不能够忽略数据的社会性、公共性。本质上，数据的价值在于认知，在数据挖掘分析形成智能成果（模型或知识）并在智能成果的应用于特定场景才能产生经济价值。而智能或知识的生产本身具有社会性。因此，数据流通产生的价值首先是社会价值，而不仅仅是特定场景下一次使用可能经济效益。在这个意义上，单纯考虑数据交易价值或市场化交易是误导性，难以支撑数据智能对数据需求——高效率低成本大规模集成使用。</p><p></p><h5>InfoQ：对于企业，尤其是其技术和数据部门，您建议他们如何调整策略来适应这一新的数据流通规则？</h5><p></p><p>高富平：数据是新型要素，企业必须围绕数据价值实现部署技术设施、建立制度规则，采取相应管理措施。而这一过程显然不是技术或数据部门的事情，而是各个部门的事情，尤其是企业必须有清晰统一的数据资产化战略，才能实现一目标。</p><p>我给企业的建议是，先不要寻求变现，先要按照统一标准和产品化思维治理数据，应用数据，提升企业智能决策水平。在这个基础上，尝试输出事重用数据集或知识，在支撑数据社会化利用同时，给企业带来更多价值。</p><p></p><h5>InfoQ：在“数据持有权”这一理念的指导下，您如何看待中国未来的数据经济发展？</h5><p></p><p>高富平：关于是有良好的制度设计，在保持数据开放或可获取前提下，通过数据持有权制度为数据流通提供提供制度基础。数据经济不是直接产生效益的经济，而是赋予整个社会以价值的经济。因此，必须有长远宏观社会目标，才能将数据经济发展好。</p><p></p><h5>InfoQ：对于新兴的数字经济型企业，您有哪些建议或策略上的推荐？</h5><p></p><p>高富平：主要建议是从商业、技术和法律三个维度架构面向未来发展的基础设施和制度框架，从切块式逐渐实现数智转型，而不是盲目地上高大上的项目。</p><p>&nbsp;</p><p></p><h4>嘉宾介绍：</h4><p></p><p>高富平&nbsp;华东政法大学教授，华东政法大学智能法学科带头人，任财产法研究院院长、互联网法治研究院院长、数据法律研究中心主任、电子商务法研究所所长，兼任互联网法治研究院（杭州）常务副院长。&nbsp;高教授曾承担并完成了多项国家和省部级课题，出版著作&nbsp;20&nbsp;余本、发表论文&nbsp;100&nbsp;余篇。&nbsp;高教授为“数据二十条”的起草者和解读者，获国家发改委感谢信，为国家医保局、上海数据交易所等大数据机构提供咨询服务，承担上海市经信委、市场监督管理局等大数据相关专项课题研究，并为上海市政府大数据政策制定提供咨询。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d2/d28de41c85dd81008a770fe33ba375ab.png\" /></p><p></p>",
    "publish_time": "2023-11-29 17:12:50",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "了解你的系统和数据库！两天能升级上千Java应用：生成式AI大杀器Amazon Q 才是开发专家？",
    "url": "https://www.infoq.cn/article/jdL3qXcpcgESlLYmsXI9",
    "summary": "<p>OpenAI 神秘项目“Q*”刚曝光不久，亚马逊云科技就推出了有着相似名字的企业级生成式AI助手Q。</p><p></p><p>在日前于拉斯维加斯召开的re: Invent大会主题演讲中，亚马逊云科技CEO Adam Selipsky正式宣布推出Amazon Q，“您可以使用Q轻松进行对话、内容生成并执行操作。Q完全了解你的系统、数据存储库和运营需求。”Selipsky说道。</p><p></p><p>据悉，Amazon Q由亚马逊云科技17年来积累的知识和经验训练而成，可以提出满足业务需求的云基础设施建议、输出博客文章、帮助应用程序代码，以及搜索和分析企业数据。订阅起价为每用户每年20美元，且已经提供公开预览版。</p><p><img src=\"https://static001.infoq.cn/resource/image/6e/7f/6ef2bb20072ee091eac7e275c7e97c7f.jpeg\" /></p><p></p><p></p><h2>如何帮助开发者</h2><p></p><p></p><h4>加速业务开发</h4><p></p><p></p><p>Amazon Q是用户在亚马逊云科技上构建、部署和操作应用程序及工作负载的专家。根据官方介绍，用户可以将Q接入组织指定的应用程序和软件（例如Salesforce、Jira、Zendesk、Gmail以及Amazon S3存储实例等），并据此进行自定义配置。</p><p></p><p>Q能够根据所有关联数据及内容进行索引，“学习”关于当前业务的方方面面，包括组织结构、核心概念和产品名称等。</p><p></p><p>例如，公司可以通过Web应用程序要求Q分析用户在使用哪些功能时遇到了问题、应该如何改进这些功能；也可以像使用ChatGPT那样直接上传文件（支持Word文档、PDF、电子表格等）并询问与内容相关的问题。Q则通过联系、整合和数据（包括特定业务数据）提供响应与参考。基于这些问题，Amazon Q会给出明确答案并列出引用出处。</p><p></p><p>用户可以追问任意多轮的问题，来获取更加详尽的答案，找到实现其工作负载的最佳选项，并得到基本操作的步骤指导。</p><p></p><p>Q不仅能够回答问题，还能作为助手生成或总结博文内容、新闻稿和电子邮件。它还为工作中的常规操作提供一组可配置的插件，包括自动创建服务工单、通过Slack中的特定团队以及更新ServiceNow中的仪表板等。</p><p></p><p></p><p></p><p>为了防止错误，Q要求用户在行动之前检查其操作建议，并展示结果以供验证。</p><p></p><p>Q可以通过亚马逊云科技的管理控制台、各类Web应用程序以及Slack等聊天应用进行访问，而且对亚马逊云科技家族的产品和服务有着透彻了解。亚马逊云科技表示，Q能够理解亚马逊云科技上各种应用工作负载间的细微差别，哪怕是只需运行短短几秒的应用、或者极少访问存储内容的程序也可以接受Q的指引和操作。</p><p></p><p>Q还能解决网络连接等常见问题，分析网络配置以提供修复建议。“如果控制台出现错误，您可以按下 Amazon Q 按钮进行故障排除。Q 将研究该错误并建议如何修复它。Amazon Q 还了解网络，“可以帮助快速解决连接问题，”Selipsky说道。</p><p></p><p>Selipsky表示，“我坚信这将是一场生产力层面的变革，希望来自不同行业、从事不同岗位的人们都能从Amazon Q身上获益。”</p><p><img src=\"https://static001.infoq.cn/resource/image/6e/7f/6ef2bb20072ee091eac7e275c7e97c7f.jpeg\" /></p><p></p><h4>生成、解释代码</h4><p></p><p></p><p>Q与Amazon CodeWHisperer服务相结合，可以生成并解释应用程序代码。在受支持的IDE（例如Amazon CodeCatalyst）当中，Q可以为用户代码生成测试，借此衡量其质量水平。</p><p></p><p>此外，Q还能创建软件新功能、执行代码转换，并为代码包、存储库和框架更新草案和文档，使用自然语言对计划进行完善和执行。</p><p></p><p>Selipsky表示，亚马逊云科技内部的一支小团队就成功在短短两天之内，使用Q将上千款应用程序从Java 8升级到了Java 17，甚至完成了相应的测试。</p><p></p><p>Q的代码转换功能仅支持从Java 8和Java 11升级至Java 17（后续将推出.NET Framework到跨平台.NET转换），且所有代码相关功能（包括代码转换）都需要配合CodeWhisperer Professional订阅服务。不清楚这方面要求后续是否会有所放松。</p><p></p><p>Selipsky补充道，Amazon Q 将能够将应用程序从 Windows .NET Framework 迁移到 Linux 上的跨平台 .NET，这是一个好主意，但由于仅依赖于 Windows，因此在实践中常常面临挑战。</p><p></p><p>亚马逊云科技表示，他们也在利用Q增强更多第一方产品，例如Supply Chain和QuickSight（一种商业分析服务）。</p><p></p><p>Q能够在QuickSight中为商业报告提供可视化选项，自动调整格式，或者根据报告中的引用及数据回答用户提问。而在Supply Chain当中，Q能够通过最新分析结果响应诸如“为什么我的配送单延误了？”之类的查询。</p><p></p><p>Q还在逐步进入联络中心软件Amazon Connect。在Q的支持下，客服人员现在可以快速获得关于用户提问的答复建议，对应的操作步骤以及背景资料链接，由此告别繁琐低效的手动搜索。Q还能生成通话摘要，帮助主管后续跟踪服务进度。</p><p></p><p></p><h4>隐私安全</h4><p></p><p></p><p>在整场演讲中，Selipsky多次强调Q给出的答案及操作建议完全可控且支持筛查。Q只会返回用户有权查看的信息，管理员可以限制敏感主题，要求Q在必要时过滤掉不当问题和答案。</p><p></p><p>为了缓解幻觉问题（即生成式AI系统中常见的捏造事实行为），管理员可以要求Q仅从公司内部文档中提取知识，而不得使用来自底层模型的知识。Selipsky表示，驱动Q的底层模型是Amazon AI开发平台Bedrock提供的模型组合，包括Amazon原研的Titan系列，且绝不会利用用户数据进行模型训练。</p><p></p><p>当前，已经有十几家公司明确禁止或限制使用ChatGPT，反映出了当下人们对向聊天机器人输入数据可能导致泄露风险的担忧。Selipsky强调，“如果你的用户本来就无权访问某些内容，那么在使用Q之后也仍然无权访问。Q理解并尊重用户的当前身份、角色和权限……我们也永远不会使用业务内容来训练底层模型。”</p><p></p><p>除了对隐私的高度重视，从各个方面来看，Q似乎都是亚马逊云科技对于微软Azure Copilot做出的有力回应，而Azure Copilot又是微软对谷歌Duet AI的回应。Azure Copilot与Duet AI均采用聊天助手的形式，负责为云用户提供应用程序和环境配置建议，并通过发现潜在问题和给出答案的方式协助故障排查。</p><p></p><p></p><h2>题外话</h2><p></p><p></p><p>Constellation Research 创始人兼首席分析师 Ray Wang在采访中表示，他认为Q是本届re: Invent上最具份量的发布。“这是在用AI武装开发者，帮助他们取得成功。”</p><p></p><p>很明显，亚马逊云科技看到了近期调查给出的关键结论，即大多数试用生成式AI的厂商都不知道该怎么将新技术纳入业务用例、将其真正转化为生产力。</p><p></p><p>宝马集团数据工程和分析顾问Christoph Albrecht&nbsp;表示：“宝马团队需要快速提取和解释新数据，以提供客户期望的精确体验。Amazon&nbsp;QuickSight中新增的Amazon Q功能可帮助我们的分析师在数小时内构建仪表板，而以前需要数天时间。”</p><p>&nbsp;</p><p>值得注意的是，Anthropic 首席执行官兼联合创始人 Dario Amodei 也在 re:Invent 上与 Selipsky 一起登台。9 月份，亚马逊云科技向这家人工智能初创公司进行了高达 40 亿美元的投资，为 Anthropic 提供更多云基础设施和芯片来训练和运行其模型。Anthropic 的 Claude LLM 将为一系列 AWS 产品提供支持，包括AppFabric。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/8e/97/8ea56eeb793ecd4a83874251de300797.png\" /></p><p></p><p>Anthropic 的 7 个创始人都来自 OpenAI，曾经深度参与过 OpenAI 的 GPT-3、引入人类偏好的强化学习等多项研究。对于离开 OpenAI的原因 ，据说是因为其“从一开始就在模型安全性方面有着不同的愿景。”Anthropic在OpenAI 高层斗争大戏落幕之后不久后亮相re: Invent，这也彰显了亚马逊云科技发力生成式AI的决心。</p><p></p><p>接下来，就让我们一同期待Q的更多使用案例和反馈，看看它是否真如宣传的这么神奇。</p><p></p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://aws.amazon.com/cn/q/\">https://aws.amazon.com/cn/q/</a>\"</p><p><a href=\"https://techcrunch.com/2023/11/28/amazon-unveils-q-an-ai-powered-chatbot-for-businesses/\">https://techcrunch.com/2023/11/28/amazon-unveils-q-an-ai-powered-chatbot-for-businesses/</a>\"</p><p></p><p></p>",
    "publish_time": "2023-11-29 17:18:39",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Amazon Bedrock全家桶升级，推出新的定制和管理工具",
    "url": "https://www.infoq.cn/article/lg88Uvf77NyZbSbdtiJi",
    "summary": "<p>亚马逊云科技日前发布全新工具，能够轻松定制其公有云端的大语言模型，并将成果整合至应用程序当中。</p><p></p><p>这些工具在亚马逊于拉斯维加斯召开的re: Invent 2023大会上首度亮相。会议期间，这家云巨头还发布了新的云实例，可供企业客户训练并运行AI模型。与此同时，名为Amazon Q的新型AI助手也横空出世，可帮助用户快速编写代码并总结冗长的文档资料。</p><p></p><h3>定制化AI</h3><p></p><p>亚马逊公布一项名为Amazon Bedrock的服务，可对一组托管基础模型进行访问。其中既包括亚马逊内部开发的Amazon Titan系列大语言模型（LLM），也提供来自其他厂商及开源生态系统的神经网络选项。亚马逊此次还公布两项新功能：微调与持续预训练，允许客户针对特定任务对Bedrock中的大模型进行定制。</p><p></p><p>定制神经网络就是使用知识库中未包含的新数据进行模型训练。例如，电子商务企业可以利用产品文档进行模型训练，使其学会回答客户提出的产品相关问题。这种定制过程能够显著提高大模型的回答准确率。</p><p>亚马逊此次推出的首个定制化功能为fine-tuning微调，允许开发人员在标记数据集上训练受支持的Bedrock模型。此类数据集包含样本输入、常见提示词以及针对这些提示词预先编写的AI答案。这些记录以问答形式组织而成，可供AI模型通过示例快速进行学习。</p><p></p><p>亚马逊推出的另一项定制功能为continued pretraining持续预训练，面向的则是另外一组用例。它允许企业在规模极大的数据集上对Bedrock大模型进行定制，例如涉及数十亿token的代码库。所谓token，就是对应几个字符或数字的数据单元。这项新功能还可使用新信息对训练数据集做定期刷新。</p><p></p><p>亚马逊允许客户在未经标注的数据集上进行持续预训练。此类数据集包含样本输入，但往往并不具备AI模型所需要的输出示例。现在用户无需创建输出示例，因此能够大大减少创建训练数据集的工作量，从而降低AI定制成本。</p><p></p><p>亚马逊生成式AI首席开发者布道师Antje Barth在博文中表示，“用户可以指定最多10万条训练数据记录，且一般在至少提交10亿条token后即可看到显著的定制效果。”</p><p></p><p>发布之后，Amazon Titan Text大模型将以公共预览的形式迎来持续预训练轻盈。而微调功能不仅适用于Titan模型，还将对接开源Llama 2和Cohere Command Light模型。</p><p></p><h3>基于云的AI Agent</h3><p></p><p></p><p>AI应用往往需要执行涉及多个步骤的任务。例如，客服聊天机器人可能需要接收产品查询、为每条查询生成摘要，再将摘要转发给相关业务部门。亚马逊为此发布了Agents for Amazon Bedrock工具，能够简化这类多步骤任务的AI应用开发过程。</p><p></p><p>该工具于今年7月首度亮相，当时为Bedrock中的预览功能。而在本次re: Invent大会上，亚马逊将Agents for Amazon Bedrock全面开放，并添加了多项增强功能。</p><p></p><p>在AI开发领域，agent智能体代表一款程序，能够将多步骤任务作为输入、将各个步骤拆分成独立操作，再将每项操作分配给AI模型。Agent能够生成提示词，引导底层AI模型分步执行任务。Agent本身由机器学习技术所支持，开发人员则通过自然语言来设置其需要执行哪些操作、各项操作的具体执行方式等。</p><p></p><p>Agents for&nbsp;Amazon Bedrock简化了AI agent的创建过程。据亚马逊介绍，此次推出的新版工具允许开发者监控agent如何完成多步骤任务执行中的各个阶段。在必要时，开发人员还可以修改各子步骤的执行方式以提高输出质量。</p><p></p><p>如果还需要进一步定制，软件团队可以更新agent的所谓编排模板。编排模板是一种AI揭示词，用于通知agent需要执行哪些任务、具体如何执行。根据亚马逊的说法，开发人员现在可以自定义任务解释及其他细节，例如AI输出的呈现方式。</p><p></p><p>Barth解释道，“只有在专注于特定任务时，agent才能发挥最佳表现。目标和说明越清晰，可用的操作集（API）越集中，推理和确定正确步骤的效果也就越好。”</p><p></p><h3>AI护栏</h3><p></p><p>在使用Bedrock大模型、各模型的定制版本以及AI agent时，开发人员现在还能配合Guardrails for Amazon Bedrock这项新的预览功能，防止AI应用程序摄取敏感数据或生成有害输出。</p><p></p><p>此项功能允许开发者为AI应用定义需要回避的一组主题，例如银行可以通过配置要求其客服聊天机器人不得提供投资建议。该功能提供拖放界面，可轻松调整相应过滤强度。</p><p></p><p>Amazon Bedrock Guardrails的另一项作用是保护敏感数据，例如个人身份信息（PII）。据亚马逊介绍，此功能允许AI应用阻止用户输入包含个人身份的提示词，并可编辑掉AI生成输出中的敏感内容。</p><p></p><p>原文链接：</p><p><a href=\"https://siliconangle.com/2023/11/28/aws-rolls-new-ai-customization-management-tools/\">https://siliconangle.com/2023/11/28/aws-rolls-new-ai-customization-management-tools/</a>\"</p>",
    "publish_time": "2023-11-29 17:43:56",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "同盾科技阅微：预防重于打击，以决策智能构建新一代反欺诈体系",
    "url": "https://www.infoq.cn/article/QkU1lSzJtaAPruBcDh6r",
    "summary": "<p>在大数据、AI和机器学习等数字技术迅速发展的背景下，互联网金融业务种类日益丰富。但随之而来的是信息泄露和欺诈攻击风险的持续增加。面对欺诈手段和模式的多样化和伪装性，金融机构必须加强对欺诈风险的态势感知、及时研判、预警和实时决策，以维护业务安全和客户信任。</p><p></p><p>在11月19日，InfoQ 主办了<a href=\"https://fcon.infoq.cn/2023/shanghai/\"> FCon 全球金融科技大会</a>\"，旨在为金融科技界的专业人士提供一个交流和学习的平台。此次大会在上海召开，吸引了国内金融行业的众多高端技术管理者和技术专家共同探讨数字化转型过程中的痛点和解决方案。</p><p></p><p>我们很荣幸邀请到了同盾科技软件产品及方案部的总监<a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5573\">阅微</a>\"作为演讲嘉宾。阅微在会上进行了题为《黑灰产欺诈攻防体系的研究与实践》的主题分享。他深入分析了当前黑灰产欺诈的发展态势和攻击模式，并分享了关于欺诈攻防的相关思考，以及同盾科技在建立欺诈风险对抗模型体系方面的行业实践。阅微</p><p>的分享为与会者提供了宝贵的行业见解和实用的解决策略，有助于推动金融科技行业的健康发展。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/2a/6a/2a032f82255e55cc586ecf991c56a46a.jpg\" /></p><p>同盾科技软件方案部总监阅微发表《黑灰产欺诈攻防体系的研究与实践》主题分享</p><p></p><h5>不知攻、焉知防 黑灰产欺诈态势解析</h5><p></p><p></p><p>所谓“不知攻、焉知防”，黑灰产欺诈风险对抗需要贯彻“知己知彼”的攻防策略。金融机构既要了解当前黑灰产欺诈发展态势，更要知悉欺诈手段背后的行为逻辑，如此才能构建一套完备的欺诈风险对抗体系，改变被动防守的局面，增强防守的主动性和可预测性。</p><p></p><p>阅微首先分析了当下黑灰产欺诈的新态势和作案特点。他认为，互联网与移动技术的发展使得金融业务场景日渐复杂，攻击面、攻击点呈爆发式增长。在此基础上，黑灰产利用社会工程学和新的AI技术进行欺诈升级，推动欺诈行为趋于产业化、精准化、移动化、技术化，导致欺诈现象在金融领域呈现全范围蔓延的趋势。从场景来看，涉诈金融产品逐步从网银PC端向手机银行、移动金融、线上贷款、数字货币转移，欺诈场景逐步从广撒网、单一场景向定向精准、复杂场景、专业工具对抗转变。</p><p></p><p>生成式AI及大模型的兴起，使欺诈者的深度造假能力大幅度提升，导致涉诈攻防形势愈发严峻。例如利用AIGC技术编写恶意代码和钓鱼网站、针对网站及APP漏洞实行恶意渗透、深度伪装人声及视频，骗过机器和程序，进而达到账户盗用、信用透支、资金盗取的目的。</p><p></p><p>阅微强调，AI技术的进步降低了欺诈的门槛及成本。犯罪分子通过传统诈骗工具获取账号、声音、面容等素材后，利用AI技术制作逼真的视频素材。随着AI的持续发展，犯罪分子制作伪视频等物料所需的素材要求越来越少，成品却越来越逼真。</p><p></p><p>欲知己之所防，先知彼之所攻。基于对金融领域欺诈模式发展演变的深刻洞察，阅微表示，欺诈的本质为欺诈者与受害人之间存在信息差，即信息的不对称。黑灰产围绕获取、加工和使用个人信息,已然形成成熟的产业链条，利用社工库及暗网等信息搜集渠道获取相关物料，对数据进行分析、萃取，进而通过黑产业务工具及套利手段对目标人群实施定向攻击。</p><p></p><p>此外，除业务流程存在的缺陷及技术存在的漏洞因素之外，敏感信息泄露已成为涉诈安全过程中的最薄弱环节。</p><p></p><h5>以决策智能为主线 有效构建反欺诈体系</h5><p></p><p></p><p>黑灰产利用信息不对称实施欺诈，阅微认为，反欺诈本质是在解决信息差，其核心在于借助技术的力量，实现对数据身份的识别，对行为虚实、真假、善恶的研判。他表示，反欺诈工作中，预防重于打击，建立起实时、精准、自动化的反欺诈技术体系，在事前或者事中阶段才能阻止大部分欺诈事件。</p><p></p><p>经过多年来在金融风控与反欺诈领域的技术与实践积累，同盾科技已形成了诱敌深入、纵深打击的欺诈攻防层级梯度，即“一点出险、多点布控、全面布防”。</p><p></p><p>通过活体识别、生物探针、设备指纹等手段检测用户是否为真人，通过身份识别、人脸对比、实名认证、声纹识别等手段判断用户是否为本人，通过风险行为、稳定性、可信因子等判断交易是否为个体欺诈行为，最后通过集中度检测、知识图谱等方式分析是否为团伙欺诈行为。</p><p></p><p>阅微认为，实施欺诈风险防控的关键三要素为数据要素、算力/工具以及场景/算法。数据作为反欺诈基础，可实现尽小者大、积微者著的效果，金融机构可通过整合多维度数据，补充数据短板，加强内外部数据融合使用，解决数据孤岛问题。算力及工具包含终端态势感知平台、智能决策平台、模型平台、知识图谱、量化运营系统等，可实现反欺诈体系的平台能力支撑。在场景/算法要素中，金融机构可通过深度了解欺诈攻防场景，沉淀欺诈标签、发现欺诈规则，进而生成机器学习模型或自学习策略模型持续优化，以及自迭代大模型应用。</p><p></p><p>侦测识别层面，可将不同欺诈识别手段应用于反欺诈的不同成熟度阶段，组合应用以侦测复杂的欺诈风险。根据欺诈侦测率由低到高，包含四个阶段，分别为专家规则判断、行为特征分析、智能模型识别、运用知识图谱进行关联分析，以此对欺诈风险实行层层递进的管控措施。</p><p></p><p>决策层面，同盾科技实现了反欺诈决策体系的三态设计：稳态、敏态和动态。所谓稳态，指的是稳定可靠的量化决策；敏态即为金融机构可针对当前交易进行即时分析、实时决策；动态决策则是指交互式风控、自适应、可量化及多模式的动态决策。通过三态设计，实现针对交易行为的漏点分析、意图分析、链路分析、时序分析、行为分析，最终通过态势感知和持续对抗，实现对于欺诈风险浓度的准确度量。</p><p></p><p>阅微表示，随着数字经济的持续发展，金融机构与犯罪分子之间的反欺诈斗争将是持久战，攻击永远存在，要做到的是欺诈风险可控与业务有效经营。对于反欺诈而言，自适应、可量化的动态决策才是可持续对抗的关键。在未来，同盾科技将与金融机构携手，持续提升行业反诈技术能力，实现风险防控的主动出击，以决策智能先进技术研发和应用守卫金融业务安全。</p>",
    "publish_time": "2023-11-29 17:49:09",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "联手OpenAI最强竞对展开生成式AI反击战：亚马逊云科技将S3写入速度提升10倍、推出全新三层技术栈",
    "url": "https://www.infoq.cn/article/KMJf53gIuk9mhQSgeOH6",
    "summary": "<p>一年前的re: Invent 2022大会上，生成式AI几乎没有被提及。但几天之后横空出世的OpenAI&nbsp;ChatGPT聊天机器人瞬间掀起变革的狂潮，裹挟着整个世界进入生成式AI新时代。</p><p>&nbsp;</p><p>短短一年之间，生成式AI已经成为科技领域的发展重心。亚马逊云科技在今年的re: Invent 2023会议上突显了该技术如何成为这家云巨头议程的首要任务。</p><p>&nbsp;</p><p>在今天的主题演讲中，亚马逊云科技首席执行官Adam Selipsky表示：“围绕生成式AI模型的创新具有爆炸性。”他补充说：“它将重塑我们在工作和家庭中交互的每一个应用程序。我们正在以一种跟以往完全不同的方式来探讨生成式AI的整个概念。”</p><p>&nbsp;</p><p>并且他还具体介绍了亚马逊云科技的“生成式AI技术堆栈”，旨在为客户提供生成式AI应用程序、用于构建大型语言模型的新工具，以及加速模型训练和推理的基础设施。</p><p>&nbsp;</p><p></p><h2>全新生成式AI技术堆栈</h2><p></p><p>&nbsp;</p><p>在快速发展的AI领域中构建和部署生成式AI模型与应用，往往会带来一系列独特的挑战。亚马逊云科技的应对之法是一套新的生成式AI基础设施，由三层技术栈组成，分别是基础设施层、基础模型服务层和AI应用层，希望能帮助客户在这三层之上轻松进行创新。</p><p>&nbsp;</p><p>“拥有最广泛和最深入的能力很重要，”Selipsky说。“我们开始利用亚马逊云服务彻底重新思考 IT 基础设施。”</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3c/3cdebc01560441e58b287d1fb44b624e.jpeg\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>在今天 re:Invent 上近两个半小时的主题演讲中，Selipsky 提供了有关生成式 AI 策略的很多细节，Selipsky认为，他们的全新AI技术栈在模型选择、芯片成本和性能方面都有优势，能够帮助AI开发者在构建、训练和运行生成式AI应用时立足基础模型占得先机。</p><p>&nbsp;</p><p></p><h2>堆栈第一层：存储和计算重大革新</h2><p></p><p>&nbsp;</p><p>随着对生成式AI的需求不断增长，GPU供应出现了短缺。据报道，Nvidia性能最优越的芯片在2024年之前可能已经售罄。台积电首席执行官最近表示对前景不太乐观，认为Nvidia以及Nvidia竞争对手的GPU短缺情况可能会一直持续到2025年。为了减少对GPU的依赖，一些有能力的科技巨头正在研发定制芯片，用于创建、迭代和产品化人工智能模型，亚马逊就是其中之一。</p><p>&nbsp;</p><p>凭借着Nitro虚拟机管理程序以及Graviton、Trainium和Inferentia等芯片家族，亚马逊云科技已经积累起丰富的芯片开发技术经验，这也使其在云和生成式AI领域拥有显著优势。Selipsky在此前接受外媒采访时解释了这些创新的切实好处，并强调了在计算能力与成本水平间取得平衡的重要意义。“生成式AI工作负载有着极高的计算密度，因此性价比绝对至关重要。”</p><p>&nbsp;</p><p>今天，亚马逊云科技推出了为生成式AI和机器学习训练设计的云端AI芯片Amazon Trainium2，以及第四代自研服务器CPU芯片Amazon Graviton4。</p><p>&nbsp;</p><p>Amazon Trainium2为拥有数千亿甚至数万亿个参数的基础模型训练做了优化，性能相比2020年12月推出的第一代Trainium提高了4倍，同时能效提高了2倍。Trainium2将在亚马逊云中的Amazon EC Trn2实例中使用，这是一个由16个芯片组成的集群，同时在Amazon EC2 UltraCluster产品中可扩展到多达10万个芯片。亚马逊表示，用由 10 万个 Trainium 芯片组成的集群来训练 3000 亿个参数的 AI 大模型，可将训练时间从数月缩短为仅几个星期。</p><p>&nbsp;</p><p>今天早上发布的另一款芯片是基于 Arm 的Graviton4，专注于推理环节。Selipsky称，与在 Amazon EC2 上运行的上一代 Graviton 处理器Graviton3（但不是更新的Graviton3E ）相比，Graviton4 的处理速度提高了 30%，内核增加了 50%，内存带宽增加了 75%。Selipsky 还强调，“我们现在已经在短短五年内推出了第四代芯片。其他云提供商甚至还没有交付他们的第一个服务器处理器。”</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0a/0ad8affe0a079a050c5a9f689da7b61e.png\" /></p><p></p><p>&nbsp;</p><p>此外，亚马逊云科技宣布其S3对象存储服务推出重大更新：一种新的高性能、低延迟层S3存储类别Amazon S3 Express One Zone，旨在为延迟敏感的应用提供个位数、毫秒级的每秒数十万次数据访问。Amazon S3 Express One Zone的数据访问速度比Amazon S3标准版快10倍，请求成本降低50%，计算成本降低60%。</p><p>&nbsp;</p><p></p><h2>堆栈第二层：联手OpenAI最强竞争对手反击微软</h2><p></p><p>&nbsp;</p><p>跟广大吃瓜群众一样，Selipsky也注意到了最近OpenAI和微软曝出的“宫斗大戏”。</p><p>&nbsp;</p><p>在此前接受外媒采访时，针对Sam Altman 的突然离职和最终回归这一列事件，Selipsky分享了自己的看法，“对企业来说，必须努力扩大技术获取来源；任何单一模型或者供应商都不应占据主导地位。最近发生的一切，也再次证明亚马逊云科技所选定路线的合理性。”Selipsky认为“可靠的模型与可靠的供应商至关重要，而提供选项并致力于支持相关技术的云服务商也同样重要。”</p><p>&nbsp;</p><p>“不会有一种模式能够统治一切，”在今天的大会上，Selipsky说。“你需要尝试不同的模型，你需要选择合适的模型提供商。我认为过去 10 天发生的事件已经非常清楚地表明了这一点。”</p><p>&nbsp;</p><p>Selipsky在这个环节里重点介绍了Amazon Bedrock平台，表示已经有上万用户在使用Bedrock。Amazon Bedrock平台是亚马逊4月推出、9月全面开放的大模型开发平台，支持用户调用来自亚马逊自己的泰坦（Titan）模型，以及AI21 Labs、Anthropic、Stability AI等第三方的多样化模型进行调用和定制化开发。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a8cfaac1ea3e6bb4ed4e9778e0e98621.png\" /></p><p></p><p>&nbsp;</p><p>特别的是，亚马逊云科技还特地邀请了Anthropic CEO Dario Amodei到现场分享。在对谈中，他们提到Anthropic围绕亚马逊云服务打造了独家定制功能，用户只能通过Amazon Bedrock加Anthropic的第一方产品才能享受得到。“这些服务将提供重要的微调与定制功能，且在限定时期内仅在Amazon Bedrock上通过Anthropic的第一方产品对外发布。只此一家，别无分号。”</p><p>&nbsp;</p><p>Anthropic由前OpenAI工程师于2021年创立，其创始人“从一开始就在模型安全性方面有着不同的愿景”。今年9月25日，亚马逊云科技与Anthropic宣布达成战略合作，亚马逊云科技称将向Anthropic投资至多40亿美元，在体量上几乎可以与OpenAI同微软之间的合作相媲美。可以说，在争夺先进AI基础模型的竞赛当中，亚马逊云科技与Anthropic之间的战略合作伙伴关系已经成为其基础模型服务层中的重要组成部分。</p><p>&nbsp;</p><p></p><h3>定制化AI</h3><p></p><p>&nbsp;</p><p>具体来说，Amazon Bedrock是一个可对托管基础模型进行访问的平台。其中既包括亚马逊云科技内部开发的Amazon Titan系列大语言模型（LLM），也提供来自其他厂商及开源生态系统的神经网络选项。亚马逊云科技此次还公布两项新功能：微调与持续预训练，允许客户针对特定任务对Bedrock中的大模型进行定制。</p><p>&nbsp;</p><p>定制神经网络就是使用知识库中未包含的新数据进行模型训练。例如，电子商务企业可以利用产品文档进行模型训练，使其学会回答客户提出的产品相关问题。这种定制过程能够显著提高大模型的回答准确率。</p><p>&nbsp;</p><p>亚马逊云科技此次推出的首个定制化功能为fine-tuning微调，允许开发人员在标记数据集上训练受支持的Bedrock模型。此类数据集包含样本输入、常见提示词以及针对这些提示词预先编写的AI答案。这些记录以问答形式组织而成，可供AI模型通过示例快速进行学习。</p><p>&nbsp;</p><p>亚马逊云科技推出的另一项定制功能为continued pretraining持续预训练，面向的则是另外一组用例。它允许企业在规模极大的数据集上对Bedrock大模型进行定制，例如涉及数十亿token的代码库。所谓token，就是对应几个字符或数字的数据单元。这项新功能还可使用新信息对训练数据集做定期刷新。</p><p>&nbsp;</p><p>它还允许客户在未经标注的数据集上进行持续预训练。此类数据集包含样本输入，但往往并不具备AI模型所需要的输出示例。现在用户无需创建输出示例，因此能够大大减少创建训练数据集的工作量，从而降低AI定制成本。</p><p>&nbsp;</p><p>亚马逊云科技生成式AI首席开发者布道师Antje Barth在博文中表示，“用户可以指定最多10万条训练数据记录，且一般在至少提交10亿条token后即可看到显著的定制效果。”</p><p>&nbsp;</p><p></p><h3>AI安全性</h3><p></p><p>&nbsp;</p><p>这个月，有报道称，微软员工被禁止使用其斥巨资投资的OpenAI的产品ChatGPT。“出于安全和数据方面的考虑，许多人工智能工具不再供员工使用，”据说当时这是在微软内部网站上的消息。微软称，“虽然微软确实投资了OpenAI，ChatGPT也有内置的保护措施来防止不当使用，但该网站仍然是第三方外部服务。”</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/28/2825d26016afd44fb7cffcc9e1b03bbf.png\" /></p><p></p><p>&nbsp;</p><p>在今天的主题演讲中，有一个很有意思的点，在Selipsky讲述Bedrock很注重安全性和隐私保护能力时，大屏幕上则展示出了这则有关ChatGPT的新闻报道。</p><p>&nbsp;</p><p>Selipsky并没有点名微软，但他表达了对“友商”在缺少全面安全保障的情况下发布AI产品早期版本的行为表示惊讶，“令我难以置信的是，某友商居然在缺少全面安全保障的情况下发布AI产品的早期版本。他们对自己的模型以及数据的安全性没有信心。”</p><p>&nbsp;</p><p></p><h2>堆栈第三层：AI助手Amazon Q预览版正式发布</h2><p></p><p>&nbsp;</p><p>在今天的主题演讲中，亚马逊云科技还宣布推出Amazon Q 预览版，该应用处于技术栈的最上层。有分析师认为Amazon Q是本届re: Invent上最具份量的发布。“这是在用AI武装开发者，帮助他们取得成功。”</p><p>&nbsp;</p><p>Amazon Q能够回答诸如“怎样使用亚马逊云科技构建Web应用程序？”之类的问题。经过亚马逊过去17年积累下的知识进行训练，Amazon Q能够解答各种问题并提供相应的原因解释。</p><p>&nbsp;</p><p>亚马逊云科技CEO Adam Selipsky在演讲中表示，“你可以使用Amazon Q轻松进行对话、内容生成并执行操作。Amazon Q完全了解你的系统、数据存储库和运营需求。”</p><p>&nbsp;</p><p>用户可以将Amazon Q接入组织指定的应用程序和软件（例如Salesforce、Jira、Zendesk、Gmail以及Amazon S3存储实例等），并据此进行自定义配置。Amazon Q能够根据所有关联数据及内容进行索引，“学习”关于当前业务的方方面面，包括组织结构、核心概念和产品名称等。</p><p>&nbsp;</p><p>例如，公司可以通过Web应用程序要求Amazon Q分析客户在使用哪些功能时遇到了问题、应该如何改进这些功能；也可以像使用ChatGPT那样直接上传文件（支持Word文档、PDF、电子表格等）并询问与内容相关的问题。Amazon Q则通过联系、整合和数据（包括特定业务数据）提供响应与参考。</p><p>&nbsp;</p><p>Amazon Q不仅能够回答问题，还能作为助手生成或总结博文内容、新闻稿和电子邮件。它还为工作中的常规操作提供一组可配置的插件，包括自动创建服务工单、通过Slack中的特定团队以及更新ServiceNow中的仪表板等。为了防止错误，Amazon Q要求用户在行动之前检查其操作建议，并展示结果以供验证。</p><p>&nbsp;</p><p>如大家所想，Amazon Q可以通过亚马逊云科技的管理控制台、各类Web应用程序以及Slack等聊天应用进行访问，而且对亚马逊云家族的产品和服务有着透彻了解。亚马逊云科技表示，Amazon Q能够理解亚马逊云科技上各种应用工作负载间的细微差别，哪怕是只需运行短短几秒的应用、或者极少访问存储内容的程序也可以接受Amazon Q的指引和操作。</p><p>&nbsp;</p><p>在台上，Selipsky展示了一段高性能视频编码与转码应用示例。Selipsky表示，在被问及哪种EC2实例最适合当前用例时，Amazon Q列出了一份涵盖性能与成本因素的清单。</p><p>&nbsp;</p><p>“我坚信这将是一场生产力层面的变革，希望来自不同行业、从事不同岗位的人们都能从Amazon Q身上获益。”</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/00/0082f9b35f074b4d54558b1a4c6d4f0d.png\" /></p><p></p><p>&nbsp;</p><p>Amazon Q与Amazon CodeWhisperer服务相结合，可以生成并解释应用程序代码。在受支持的IDE（例如亚马逊云科技的CodeCatalyst）当中，Amazon Q可以为客户代码生成测试，借此衡量其质量水平。Amazon Q还能创建软件新功能、执行代码转换，并为代码包、存储库和框架更新草案和文档，使用自然语言对计划进行完善和执行。</p><p>&nbsp;</p><p>Selipsky表示，亚马逊云科技内部的一支小团队就成功在短短两天之内，使用Amazon Q将上千款应用程序从Java 8升级到了Java 17，甚至完成了相应的测试。</p><p>&nbsp;</p><p>Amazon Q的代码转换功能仅支持从Java 8和Java 11升级至Java 17（后续将推出.NET Framework到跨平台.NET转换），且所有代码相关功能（包括代码转换）都需要配合CodeWhisperer Professional订阅服务。不清楚这方面要求后续是否会有所放松。</p><p>&nbsp;</p><p>Selipsky还再次强调了亚马逊云科技重视安全责任，让潜在生成式AI客户更加放心，“如果你的用户本来就无权访问某些内容，那么在使用Amazon Q之后也仍然无权访问。Amazon Q理解并尊重用户的当前身份、角色和权限……我们也永远不会使用业务内容来训练底层模型。”</p><p>&nbsp;</p><p></p><h2>写在最后</h2><p></p><p>&nbsp;</p><p>很明显，亚马逊云科技在AI云领域维持统治地位的核心战略，就是继续增强其云基础设施并为市场开发出独特的生成式AI技术栈。</p><p>&nbsp;</p><p>Selipsky认为亚马逊云科技的生成式AI技术栈有独特优势，“我们独特的生成式AI技术栈为客户提供了优于其他云厂商的比较优势。并不是每家竞争对手都愿意在各个层上开展创新，而客户也不清楚他们需要多长时间才能消弭这部分差距。”</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a88f6075878819e10a1695877ee6e2ed.jpeg\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>生成式AI的兴起为大型云提供商开辟了一个巨大的新市场，在这个快速发展变化的过程中，行业已经深切感受到生成式AI适应性和创新能力的重要性。正如Selipsky所说，“适应能力是你可以拥有的最有价值的能力。”亚马逊云科技也通过Graviton前沿芯片、Trainium等专用芯片、模型平台以及Amazon Q应用产品展示了这些创新要素。</p><p>&nbsp;</p><p>可以看到，亚马逊云科技在其独特的三层生成AI技术栈上投入了巨大心力，希望借此支撑起多样化的AI模型与平台、战略合作伙伴关系、最具性价比的服务以及更丰富的技术选项。</p>",
    "publish_time": "2023-11-29 18:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]