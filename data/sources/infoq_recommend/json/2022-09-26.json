[
  {
    "title": "Java近期新闻：Helidon Níma、Spring Framework、MicroProfile、MicroStream、Kotlin和Piranha",
    "url": "https://www.infoq.cn/article/d9jp2N9XlIiCbfgWpd9P",
    "summary": "<p>本期的Java新闻包括JDK 19、JDK 20、Spring框架的更新、Spring Cloud与Spring Tools、Helidon Níma、MicroProfile Reactive规范、Quarkus 2.12.2、MicroStream 7.1.0、Reactor项目2022.0.0-M6、Hibernate Search 6.1.7、JHipster Lite 0.15.1、Piranha Cloud 22.9.0、Kotlin 1.7.20-RC和Apache Tika 1.28.5。</p><p></p><h4>JDK 19</h4><p></p><p><a href=\"https://openjdk.org/projects/jdk/19/\">JDK 19</a>\"已经于2022年9月20日正式发布。<a href=\"https://jdk.java.net/19/release-notes\">发布说明</a>\"包含了文档的链接，比如<a href=\"https://cr.openjdk.java.net/~iris/se/19/latestSpec//api/index.html\">完整的API规范</a>\"以及一个<a href=\"https://cr.openjdk.java.net/~iris/se/19/latestSpec/apidiffs/overview-summary.html\">标注的API规范</a>\"，后者对比了JDK 18（<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-18%2B36\">Build 36</a>\"）和JDK 19（<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-19%2B36\">Build 36</a>\"）的差异。关于JDK 19的更多细节和对JDK 20的预测可以参阅InfoQ的<a href=\"https://www.infoq.com/news/2022/09/java-19-so-far/\">新闻报道</a>\"。</p><p></p><h4>JDK 20</h4><p></p><p>JDK 20的<a href=\"https://jdk.java.net/20/\">早期访问构建</a>\"版本<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-20%2B15\">Build 15</a>\"发布，它是对Build 14的<a href=\"https://github.com/openjdk/jdk/compare/jdk-20%2B14...jdk-20%2B15\">更新</a>\"，包括对各种[问题](https://bugs.openjdk.org/issues/?jql=project %3D JDK AND fixversion %3D 20 and \"resolved in build\" %3D b15 order by component%2C subcomponent)的修复。关于该版本的更多细节，请参阅<a href=\"https://jdk.java.net/20/release-notes\">发布说明</a>\"。</p><p></p><p>对于<a href=\"https://openjdk.java.net/projects/jdk/19/\">JDK 19</a>\"和<a href=\"https://openjdk.java.net/projects/jdk/20/\">JDK 20</a>\"，鼓励开发者通过<a href=\"https://bugreport.java.com/bugreport/\">Java Bug数据库</a>\"报告缺陷。</p><p></p><h4>Spring框架</h4><p></p><p>Spring框架向Java社区<a href=\"https://spring.io/blog/2022/09/15/spring-framework-6-0-0-m6-and-5-3-23-available-now\">发布了</a>\"6.0.0-M6和5.3.23版本版本。这两个版本都提供了新特性、缺陷修复和依赖升级。5.3.23版本引入的新特性是<a href=\"https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/core/annotation/AnnotationUtils.html\">AnnotationUtils</a>\"类中定义的**isSynthesizedAnnotation()方法，它能够让开发人员放弃已废弃的<a href=\"https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/core/annotation/SynthesizedAnnotation.html\">SynthesizedAnnotation</a>\"接口。6.0.0-M6版本定义了七个废弃的功能，并且将会移除两个之前定义的废弃功能，其中包括SynthesizedAnnotation**接口。关于这两个版本的更多细节可以参阅<a href=\"https://github.com/spring-projects/spring-framework/releases/tag/v5.3.22\">5.3.23</a>\"和<a href=\"https://github.com/spring-projects/spring-framework/releases/tag/v6.0.0-M6\">6.0.0-M6</a>\"版本的发布说明。</p><p></p><p>Spring Cloud Dataflow 2.9.6<a href=\"https://spring.io/blog/2022/09/14/spring-cloud-dataflow-2-9-6-released\">发布</a>\"，特性包括升级PostgreSQL驱动版本至42.2.26以解决CVE-2022-31197漏洞，即<a href=\"https://github.com/advisories/GHSA-r38f-c4h4-hqq2\">通过恶意的列名能够在ResultSet.refreshRow()中触发PostgreSQL JDBC驱动的SQL注入</a>\"，该漏洞是由于**ResultSet类中refreshRow()**方法的实现没有正确的转义列名，所以包含语句终结符（比如分号）的恶意列名会导致SQL注入。关于该版本的更多细节可以参阅<a href=\"https://github.com/spring-cloud/spring-cloud-dataflow/releases/tag/v2.9.6\">发布说明</a>\"。</p><p></p><p><a href=\"https://github.com/spring-projects-experimental/spring-cloud-sleuth-otel/blob/main/README.adoc\">Spring Cloud Sleuth OpenTelemetry</a>\" 1.1.0版本<a href=\"https://spring.io/blog/2022/09/16/spring-cloud-sleuth-opentelemetry-otel-1-1-0-has-been-released\">发布</a>\"，这是<a href=\"https://spring.io/projects/spring-cloud-sleuth\">Spring Cloud Sleuth</a>\"的一个实验性扩展，其中包括了对Spring Cloud 2021.0.4和OpenTelemetry 1.18.0的依赖升级。关于该版本的更多信息请参阅<a href=\"https://github.com/spring-projects-experimental/spring-cloud-sleuth-otel/releases/tag/v1.1.0\">发布说明</a>\"。</p><p></p><p>Spring Tools 4.16.0<a href=\"https://spring.io/blog/2022/09/16/spring-tools-4-16-0-released\">发布</a>\"，特性包括：支持<a href=\"https://eclipseide.org/\">Eclipse 2022-09</a>\"；适用于ARM上Linux环境的实验性发行版；更新<a href=\"https://www.eclipse.org/m2e/\">M2Eclipse</a>\"（m2e）2.0.5。关于该版本的更多细节，可以参阅<a href=\"https://github.com/spring-projects/sts4/wiki/Changelog#2022-09-16-4160-release-incl-language-servers-version-1390\">变更日志</a>\"。</p><p></p><h4>Helidon</h4><p></p><p>甲骨文<a href=\"https://medium.com/helidon/please-welcome-helidon-n%C3%ADma-9a882c5b6f1e\">引入了</a>\" Helidon Níma，这是一个基于虚拟线程的微服务框架，它提供了一个低开销、高并发的服务器，同时保持了阻塞式的线程模型。在<a href=\"https://helidon.io/\">Helidon项目</a>\"的协助下，这个新的框架随Helidon 4.0.0发布了<a href=\"https://medium.com/helidon/helidon-n%C3%ADma-helidon-on-virtual-threads-130bb2ea2088\">第一个alpha版本</a>\"，但是Java社区需要2023年底才能等到正式的GA版本。关于Helidon Níma的更多细节，可以参阅InfoQ的<a href=\"https://www.infoq.com/news/2022/09/introducing-helidon-nima/\">新闻报道</a>\"。</p><p></p><h4>MicroProfile</h4><p></p><p>在通往<a href=\"https://microprofile.io/\">MicroProfile</a>\" 6.0的路上（计划2022年10月发布），<a href=\"https://github.com/eclipse/microprofile-reactive-streams-operators/releases/tag/3.0\">Reactive Streams Operators 3.0</a>\"和<a href=\"https://github.com/eclipse/microprofile-reactive-messaging/releases/tag/3.0\">Reactive Messaging 3.0</a>\"规范向Java社区发布，其特性与Jakarta EE 9.1保持了一致。</p><p></p><h4>Quarkus</h4><p></p><p>Red Hat<a href=\"https://quarkus.io/blog/quarkus-2-12-2-final-released/\">发布</a>\"了Quarkus 2.12.2.Final，包括了SnakeYAML 1.3.2、Hibernate Validator 6.2.5.Final和JBoss Threads 3.4.3.Final的依赖升级。关于该版本的更多细节可以参阅<a href=\"https://github.com/quarkusio/quarkus/releases/tag/2.12.2.Final\">变更日志</a>\"。</p><p></p><h4>MicroStream</h4><p></p><p>MicroStreams<a href=\"https://microstream.one/blog/article/release-of-microstream-version-7-1/\">发布</a>\"了其7.1.0版本的对象-图持久化框架，特性包括：集成Spring Boot；改善与CDI和MicroProfile Config运行时的集成；改进了数据通道的垃圾收集。此外，他们还开源了所有的连接器，现在包括Oracle和SAP HANA数据库、 Cloud存储（AWS S3、Azure Storage、Google Firestore、Oracle Object Storage）以及其他资源（Hazelcast、Kafka、Redis、DynamoDB、Oracle Coherence）。关于该版本的更多信息请参阅<a href=\"https://github.com/microstream-one/microstream/releases/tag/07.01.00-MS-GA\">发布说明</a>\"。</p><p></p><h4>Reactor项目</h4><p></p><p>在通往<a href=\"https://github.com/reactor/reactor/blob/main/README.md\">Reactor项目</a>\"2022.0.0的路上，<a href=\"https://github.com/reactor/reactor/releases/tag/2022.0.0-M6\">第六个历程碑版本</a>\"发布，其特性是对**reactor-core** 3.5.0-M6和**reactor-netty** 1.1.0-M6制品的依赖升级。此外，还对第六个里程碑版本进行了调整，reactor-pool 1.0.0-M6、reactor-addons 3.5.0-M6和**reactor-kotlin-extensions** 1.2.0-M6这些制品保持不变。</p><p></p><h4>Hibernate</h4><p></p><p><a href=\"https://hibernate.org/search/\">Hibernate Search</a>\" 6.1.7.Final发布，它将依赖升级到了Hibernate ORM 5.6.11.Final；将所有包含**-orm6**名称的制品与Hibernate ORM的依赖保持一致；以及Java模块相关缺陷的修复。</p><p></p><h4>JHipster Lite</h4><p></p><p><a href=\"https://github.com/jhipster/jhipster-lite/blob/main/README.md\">JHipster Lite</a>\"的0.15.0和0.15.1版本<a href=\"https://twitter.com/pascalgrimaud/status/1570138502850920448\">发布</a>\"，它是JHipster的启动项目，包含许多功能增强、错误修复、依赖性升级和重构。关于这个版本的更多细节可以在<a href=\"https://github.com/jhipster/jhipster-lite/releases/tag/v0.15.0\">0.15.0</a>\"和<a href=\"https://github.com/jhipster/jhipster-lite/releases/tag/v0.15.1\">0.15.1</a>\"版本的发布说明中找到。</p><p></p><h4>Piranha</h4><p></p><p>Piranha 22.9.0<a href=\"https://github.com/piranhacloud/piranha/releases/tag/v22.9.0\">发布</a>\"。这个新版本被称为2022年9月的“Core Profile just landed”版本，其特性包括：支持通过<a href=\"https://github.com/piranhacloud/piranha/issues/2775\">Piranha Core Profile</a>\"引入Jakarta EE Core Profile；以及对<a href=\"https://jakarta.ee/specifications/transactions/2.0/\">Jakarta Transactions</a>\"和<a href=\"https://jakarta.ee/specifications/persistence/3.1/\">Jakarta Persistence</a>\"规范的初始支持。关于这个版本的更多细节可以在他们的<a href=\"https://javadoc.io/doc/cloud.piranha/project/latest/index.html\">文档</a>\"和<a href=\"https://github.com/piranhacloud/piranha/issues?q=is%3Aissue+-label%3Awontfix+milestone%3A22.9.0+is%3Aclosed\">问题跟踪页面</a>\"中找到。</p><p></p><h4>Kotlin</h4><p></p><p>KotlinJetBrains<a href=\"https://blog.jetbrains.com/kotlin/2022/09/kotlin-news-august/\">发布了</a>\"Kotlin 1.7.20-RC，其特性包括：支持多个新的<a href=\"https://kotlinlang.org/docs/whatsnew-eap.html#support-for-kotlin-k2-compiler-plugins\">插件</a>\"；预览用于开闭式范围的**..&lt;**操作符；默认启用Kotlin/Native内存管理器；以及增加具有通用底层类型的内联类，这是一个实验性功能。</p><p></p><h4>Apache软件基金会</h4><p></p><p>Apache Tika 1.28.5<a href=\"https://www.mail-archive.com/announce@apache.org/msg07572.html\">发布</a>\"，其特性包括：安全问题修复；修复从PDF中提取书签时出现无限循环的问题；以及依赖性升级。该版本的详细信息可以在<a href=\"https://downloads.apache.org/tika/1.28.5/CHANGES-1.28.5.txt\">更新日志</a>\"中找到。1.x版本的发布列车将在2022年9月30日结束生命周期。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/09/java-news-roundup-sep12-2022/\">Java News Roundup: Helidon Níma, Spring Framework, MicroProfile, MicroStream, Kotlin, Piranha</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/pQ7VDmaij1aCT9TD0R06\">在 Java 中如何加快大型集合的处理速度</a>\"</p><p><a href=\"https://www.infoq.cn/article/3IgHpkRJIsFXm0vPNvFc\">甲骨文新微服务框架Helidon Níma：使用虚拟线程实现高性能</a>\"</p>",
    "publish_time": "2022-09-26 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "不要指望下一个像GPT这样的大型语言模型会民主化",
    "url": "https://www.infoq.cn/article/UrFKiffb44jcffwP5FbH",
    "summary": "<p></p><blockquote>5月初，Meta公司发布了Open Pretrained Transformer（OPT-175B），这是一个可以执行各种任务的大型语言模型（LLM）。在过去几年中，大型语言模型已经成为人工智能研究最热门的领域之一。</blockquote><p></p><p></p><p>本文最初发布于TeckTalks。</p><p></p><p><a href=\"https://www.infoq.cn/article/4iDmM3PgXmvELorwQ8M3\">OPT-175B</a>\"是由OpenAI的<a href=\"https://www.infoq.cn/article/Z46h9vTIL3dBx5Z3hAjO\">GPT-3</a>\"引发的LLM军备竞赛的最新参与者。GPT-3是一种具有1750亿个参数的深度神经网络。GPT-3表明，LLM可以在没有任何额外训练以及只学习几个样本（零样本或小样本学习）的情况下完成许多任务。微软后来将GPT-3集成到了它的几个产品中，不仅展示了LLM在科学研究上的前景，也展示了其在商业应用上的前景。</p><p></p><p>让OPT-175B与众不同的是Meta对“开放性”的承诺，正如模型的名字所暗示的那样。Meta已经向公众提供了这个模型（以及一些注意事项），它还公布了大量关于训练和开发过程的细节。在Meta AI博客上发表的一篇文章中，该公司将OPT-175B的发布描述为“大规模语言模型的民主化访问”。</p><p></p><p>Meta朝着透明的方向发展值得称赞。然而，大型语言模型的竞争已经达到了无法再民主化的地步。</p><p></p><h2>关于该大型语言模型的几个细节</h2><p></p><p></p><p>Meta发布的OPT-175B有一些关键特性，包括预训练的模型以及训练和使用LLM所需的代码。对于没有计算资源用于训练模型的组织，预训练模型特别有用（训练神经网络比运行它们消耗的资源更多）。它有助于减少训练大型神经网络所需的计算资源所造成的巨大碳排放量。</p><p></p><p>与<a href=\"https://www.infoq.cn/article/w1lxxO4qtaVPxZUdqzwi\">GPT-3</a>\"一样，OPT也有不同的大小，参数从1.25亿到1750亿不等（参数越多模型学习能力越强）。在撰写本文时，OPT-30B以下的所有模型都已提供下载。拥有全部1750亿个参数的模型将仅提供给被选中的研究人员和机构（他们需要填写一张申请表）。</p><p></p><p>根据Meta AI博客，“为了保持完整性和防止滥用，我们将在非商业许可下发布我们的模型，专注于研究用例。该模型将授权给学术研究人员，与政府、民间团体和学术机构有关的组织，以及世界各地的行业研究实验室。”</p><p></p><p>除了模型，Meta还发布了一份完整的日志，提供了关于该大型语言模型开发和训练过程的详细的技术时间线。通常，发表的论文只包含最终模型的信息。Meta表示，该日志提供了一些有价值的信息，包括“用于训练OPT-175B的计算资源的数量，以及当底层基础设施或训练过程本身因为规模太大而变得不稳定时所需的人力开销。”</p><p></p><h2>与GPT-3比较</h2><p></p><p></p><p>Meta公司在其博文中指出，大型语言模型大多是通过“付费API”访问的，对LLM的限制性访问“限制了研究人员了解这些大型语言模型如何工作以及为何有效的能力，妨碍了他们提高模型鲁棒性以及缓解偏见和数据中毒等已知的问题”。</p><p></p><p>这对于OpenAI（以及微软的独家GPT-3许可）无疑是一记重击，后者将GPT-3作为黑盒API服务发布，而不是将其模型权重和源代码公开。OpenAI没有公开GPT-3的原因之一是控制有害应用程序的滥用和开发。</p><p></p><p>Meta相信，把模型提供给更广泛的受众，他们将可以更好地研究和预防它们可能造成的任何伤害。</p><p></p><p>Meta是这样描述这项工作的：“我们希望，OPT-175B将为大型语言模型创建前沿带来更多的声音，帮助社区共同设计负责任的发布策略，并为该领域大型语言模型的开发增加前所未有的透明度和开放性。”</p><p></p><h2>大型语言模型的成本</h2><p></p><p></p><p>然而，值得注意的是，“透明和开放”并不等同于“民主化大型语言模型”。训练、配置和运行大型语言模型的成本仍然很高，而且未来可能还会增长。</p><p></p><p>根据Meta的博文，模型的研究人员已经大幅降低了训练大型语言模型的成本。该公司表示，这个模型的碳排放量已减少到GPT-3的七分之一。据我之前采访过的专家估计，GPT-3的训练成本高达2760万美元。</p><p></p><p>这意味着，OPT-175B的训练成本仍将高达数百万美元。幸运的是，预训练的模型可以避免模型训练过程，并且Meta表示，他们将提供“只使用16块NVIDIA V100 GPU”就可以完成整个模型训练和部署的代码库。这相当于一台英伟达（Nvidia）DGX-2，成本约为40万美元。对于资金紧张的研究实验室或个体研究人员来说，这不是一个小数目。(根据一篇提供了更多OPT-175B细节的论文，Meta使用992块A100 80GB GPU训练了自己的模型，这款GPU明显比V100快。)</p><p></p><p>Meta AI的日志进一步证实，训练大型语言模型是一项非常复杂的任务。OPT-175B的时间线上到处都是服务器崩溃、硬件故障和其他需要高级技术人员才能解决的并发症。研究人员还不得不多次重启训练过程，调整超参数，修改损失函数。所有这些都会产生小型实验室无法承担的额外费用。</p><p></p><h2>大型语言模型的未来</h2><p></p><p></p><p>语言模型如OPT和GPT都是基于转换器架构的。转换器的关键特性之一是它们能够大规模地并行处理海量时序数据（如文本）。</p><p></p><p>近年来，研究人员已经证明，增加转换器模型的层数和参数，可以提高它们在语言任务上的性能。一些研究人员认为，达到更高的智能水平只是一个规模问题。因此，像Meta AI、DeepMind（由Alphabet拥有）和OpenAI（由微软支持）这样现金充足的研究实验室正在朝着创建越来越大的神经网络前进。</p><p></p><p></p><blockquote>某人的观点文章。我的看法是：现在都是规模问题了！游戏结束了！现在只要让这些模型更大、更安全、计算效率更高、采样更快、记忆更智能、模式更多样、数据更有创新性，无论在线还是离线......1/N <a href=\"https://t.co/UJxSLZGc71?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjM4MTUxNzMsImZpbGVHVUlEIjoiR1E5NVBaWE55VEVjbGlYdSIsImlhdCI6MTY2MzgxNDg3MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyNTY1MTE5Nn0.Nskx-jA73oq2h4Mm1yBBSTg5klykj1PGjBvHJVLq0Hc\">https://t.co/UJxSLZGc71</a>\"—— Nando de Freitas（@NandoDF）</blockquote><p></p><p></p><p>去年，微软和英伟达创建了一个有5300亿个参数的语言模型，名为Megatron-Turing （MT-NLG）。上个月，谷歌推出了路径语言模型（PaLM）。这是一个有5400亿个参数的LLM。有传言称，OpenAI将在未来几个月发布GPT-4。</p><p></p><p>然而，神经网络越大需要的财政和技术资源也越多。虽然更大的语言模型会带来新的东西（和新的问题），但不可避免地，它们将把权力集中在少数富有的公司手中，使得较小的研究实验室和独立的研究人员更难研究大型语言模型了。</p><p></p><p>在商业方面，大型科技公司将拥有更大的优势。运行大型语言模型是非常昂贵和具有挑战性的。像谷歌和微软这样的公司有特殊的服务器和处理器，他们能够大规模运行这些模型并从中获利。对于比较小的公司来说，运行自己的LLM（如GPT-3）版本开销太大了。正如大多数企业使用云托管服务，而不是构建自己的服务器和数据中心一样，随着大型语言模型变得越来越流行，像GPT-3 API这样的开箱即用系统将越来越有吸引力。</p><p></p><p>这反过来又会使人工智能进一步集中在大型科技公司的手中。越来越多的人工智能研究实验室将不得不与大型科技公司建立合作伙伴关系，以获得资助。而这将使大型科技公司有更多的权力来决定人工智能研究的未来方向（这可能会与他们的经济利益相一致）。这可能要以那些短期内无法产生投资回报的研究领域为代价。</p><p></p><p>最后，当我们庆祝Meta为LLM带来透明度的时候，请不要忘记，大型语言模型本质上就是不民主的，而是有利于推广它们的公司。</p><p></p><p>英文原文：<a href=\"https://bdtechtalks.com/2022/05/16/opt-175b-large-language-models?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjM4MTUxNzMsImZpbGVHVUlEIjoiR1E5NVBaWE55VEVjbGlYdSIsImlhdCI6MTY2MzgxNDg3MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyNTY1MTE5Nn0.Nskx-jA73oq2h4Mm1yBBSTg5klykj1PGjBvHJVLq0Hc\">Can large language models be democratized?</a>\"</p>",
    "publish_time": "2022-09-26 08:20:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "基于微服务和低代码，网易数帆推出软件生产力新模型",
    "url": "https://www.infoq.cn/article/fqygd7M5v6MlKUx3acIw",
    "summary": "<p>9月23日，2022网易数字+大会在杭州召开。针对数字化转型下的企业软件研发需求，网易数帆在会上发布了轻舟云原生、轻舟低代码两大产品线的一系列升级，并基于此推出了以资产为中心的软件生产力模型和技术方案。网易数帆云原生及低代码产品线总经理陈谔表示，该方案旨在通过微服务和低代码在帮助企业沉淀内部标准化的原子服务与数据，形成可组装的业务资产，并采用组装的开发方式快速进行创新业务生产和交付，云原生底座提供服务运行保障。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/89/89c8db0560c83f694813f2dc5f23091a.png\" /></p><p></p><p>网易数帆云原生及低代码产品线总经理陈谔</p><p></p><h2>云原生升级：探索共享复用，促进业务创新</h2><p></p><p>陈谔首先介绍了网易数帆云原生产品线在行业的落地进展以及产品升级方向。在过去一年，网易数帆轻舟云原生平台支撑了金融行业众多核心业务场景，包括从小型机向分布式架构迁移、国产信创适配、个贷业务交易安全、生态缴费业务高可用保障等。在此过程中，网易数帆云原生平台的着眼点，也从帮助企业应用进行微服务化改造，转向提供稳定性治理和高可用性保障，并开启了共享复用的探索。</p><p></p><p>以中间件稳定性治理为例，网易数帆全新推出了中间稳定性管控产品，提供巡检和辅助定位能力，基于网易内部中间件稳定性治理实践，不仅将超过300条运维经验交付给用户，还通过“知识引擎”能力，帮助业务建立稳定性改进循环。</p><p></p><p>网易数帆认为，复杂系统的稳定性应当不断主动改进，而这个改进思路就是“发现问题-&gt;分析整改-&gt;将沉淀经验加入检查避免同类问题-&gt;发现新问题”这样不断进行的“稳定性改进循环”。知识引擎可以根据企业情况不断进行经验沉淀和规则迭代的平台，而巡检系统相当于稳定性检查执行工具，从而辅助用户建立这样的“稳定性改进循环”。</p><p></p><p>在高可用层面，网易数帆在支撑业务“两地三中心”部署架构解决方案的基础上，通过轻舟微服务提供资源感知、区域路由、增强多中心应用监控等产品化能力，通过轻舟中间件提供数据复制、集群联邦等产品化能力，并在此基础上结合API网关流量调度、多活管控服务等能力，新推出异地多活解决方案，帮助客户业务进行多活改造。</p><p></p><h2>低代码演进：构建超1000复杂应用，开发效率提升100%</h2><p></p><p></p><p>对于轻舟低代码平台，网易数帆希望它能成为企业信息化建设的通用平台工具，从而使企业不会迷失在形形色色的工具之中。基于此，网易数帆轻舟低代码平台的演进主要聚焦复杂应用开发能力、开发效率和易用性等三个方面。</p><p></p><p>陈谔介绍，轻舟低代码平台目前能够构建超1000个业务逻辑函数的复杂应用而用户体验不妥协，并实现100%的开发效率提升，同时成本降低超60%。从普及程度来说，过去一年，轻舟低代码的开发者已在全国13省市开发了200多个企业级应用。</p><p></p><p>在这背后，网易数帆为轻舟低代码加入了多项有特色的新特性，包括支持源码导出、客制化、多人协作等。轻舟低代码独门的NASL，支持将应用乃至前后端编译成通用编程语言，这意味着低代码应用可脱离平台独立部署，无缝衔接企业软件生产运维体系，从而解决了企业低代码应用开发面临的网络隔离、安全性要求严格、代码合规等挑战。</p><p></p><p>客制化能力不仅支持低代码组件、逻辑、API协议通过传统语言进行扩展开发，还可以将企业原有SDK复用到低代码应用中。这对于企业定制自有组件、沉淀具有行业特性的IT资产而言非常实用。在陈谔的现场演示中，轻舟低代码对客户需求的还原能力趋近100%。</p><p></p><p>多人协作则是当前企业通过任务分解的方式应对高复杂度业务开发的有效途径，轻舟低代码带来的研发效能提升，也从这一特性中受益匪浅。</p><p></p><h2>软件研发新模式：资产即生产力</h2><p></p><p></p><p>为帮助企业加速业务创新，利用数字化软件系统快速应对市场变化、提质增效，网易数帆提出了一个新的软件生产力模型，这一模型与Gartner此前提出的可组装业务能力（PBC）及经典的DDD（领域驱动设计）理论一脉相承。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/53/53ca8ecee50020131bf38a1dd88b247d.png\" /></p><p>网易数帆软件生产力模型</p><p></p><p>组装式架构能够让业务更快速在生产环境运行起来，避免重复建设，提高资产复用比，并且生产方式更标准化，变更更安全可靠。凭借在云原生和低代码领域的深厚积累，网易数帆打造了以资产为中心的软件生产力解决方案，让这一方法论得以在企业落地。</p><p></p><p>陈谔介绍，这一方案帮助企业基于内部服务沉淀标准化的原子服务与数据（如API、服务、流程、数据等），可以通过统一集成平台的集成和编排等能力，将其合成可组装的业务能力（PBC），也可以通过低代码平台形成可复用的低代码资产。这些资产将在软件资产中心统一管理和运营（包括资产认证、安全合规验证、资产入驻、访问控制和运营统计等），专业开发人员和低代码开发者都基于可复用的资产，快速组装和交付数字化业务。同时，强大的云原生底座为业务运行保驾护航，提供架构治理、研发流程管理、服务治理和运维保障等能力支撑。</p><p></p><p>陈谔介绍了一个DevOps资产包的实践案例。在该案例中，网易数帆基于DevOps基础服务沉淀DevOps资产包，包括112个UI组件、12个集成页面、169个API和128个页面模板，采用组装式开发思想，借助轻舟低代码平台为企业快速组装了一个客制化的DevOps平台。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/77/77521af8d441a69b376b8920c2d62537.png\" /></p><p>DevOps资产包实践案例</p><p></p><p>从中可见，在软件生产力模型下，IT资产的丰富度意味着业务创新的速度，而行业资产的沉淀，必将使得整个行业具备更为成熟的数字化水平。</p><p></p><p>陈谔表示，未来，网易数帆在云原生、低代码产品持续演进的同时，也将不断完善这一方法论和工具平台，让数字化业务的构建不再受限于专业开发资源，让行业创新不再有技术门槛。</p>",
    "publish_time": "2022-09-26 10:06:23",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "数据中台不是“无中生有”，而是让企业更快去做眼前的事",
    "url": "https://www.infoq.cn/article/SEJ62iIqiEpPfW0pRm7f",
    "summary": "<p>在商业市场竞争加剧以及国家政策扶持的大背景下，如何进行数字化转型成为了企业所关注的重点。</p><p></p><p>数据作为企业数字化转型的关键要素，同时也是赋能业务以及管理的重要生产资料，究竟企业应该如何打通数据壁垒，构建出数据采集、治理、分析和使用的完整闭环？如何深度挖掘数据的价值，提高企业运营效率，使得企业可以灵活应对迅速变化的市场环境？为了解答这一系列问题，有一个概念不得不提，那就是：<a href=\"https://xie.infoq.cn/article/69e8879ff199fff7fb0ae2c3c\">数据中台</a>\"。</p><p></p><p>2015年，阿里为了提高业务效率、支持产品创新、减少成本投入，开创了“大中台，小前台”的组织机制和业务模式，提出中台战略。后来的几年，数据中台的概念一路走红，逐渐深入互联网公司甚至是传统行业。</p><p></p><p>然而，几乎是在一夜之间，数据中台的“彩色泡泡”被戳破——一方面，提出这一理念的阿里被指忙着“<a href=\"https://www.infoq.cn/article/HwD2iMWxZ3MW7HloOHiD\">拆中台</a>\"”；另一方面，许多企业在大张旗鼓地建设完数据中台之后，发现其带来的回馈和价值并不明显。业界对数据中台的争议声接连不断。</p><p></p><p>但即便如此，仍然有企业把数据中台始终作为数据能力建设的关键部分。比如，近几年来，中国<a href=\"https://www.infoq.cn/article/TvHZGbm4EToxCb98PO0r\">光大银行</a>\"（以下简称“光大银行”）一直在加速数据平台的中台化、敏态化发展，通过建设数据中台沉淀数据资产价值，为“用数据驱动业务”夯实基础。</p><p></p><p>而关于数据中台的争议点，作为光大银行数据体系建设的核心参与者，光大银行资深数据架构师<a href=\"https://time.geekbang.org/column/intro/100057401?tab=catalog\">王磊</a>\"在日前接受InfoQ采访时表示，其中既有概念不明确的原因，也有企业对数据中台期待过高的原因。用他的话说——数据中台就像是“巨人的肩膀”，但它不是让企业去做一些不能做的事，而是能够更快地去做现在能做的事。</p><p></p><p>换句话说，企业建设数据中台，归根结底还是要回归业务本身，从自身情况出发。而不是无中生有，让企业去做与业务发展方向不匹配的事情。</p><p></p><h1>数据中台的核心价值是实现数据复用</h1><p></p><p></p><p>那么，具体来说，在企业数字化转型的过程中，数据中台的定位究竟是什么？我们或许可以从<a href=\"https://www.infoq.cn/article/zz3JtiokOUIrJXHl4wLE\">银行数据体系</a>\"的建设历程中来找到答案。</p><p></p><p>银行数据体系的建设，可以追溯到初步信息化的时期，银行一方面将业务从线下转到线上，形成协同效应；另一方面将省级IT力量逐渐向总行迁移，实现集中电子化。</p><p></p><p>“在早期信息化阶段，手工业务逐渐被信息系统取代，但系统仍然在各分行单独部署，而后随着技术的进步，各家银行纷纷将地方的IT力量逐渐集中到总行，原有的分行开发系统不断消失，这是银行系统的大集中时期，主要为了解决银行电子化的工作需求。”王磊在谈及银行不同时期的发展特点时说道。</p><p></p><p>王磊表示，在这个阶段，银行对单机处理能力的依赖程度还较高，大多数银行面对日益增长的数据量，还是会优先选择更换硬件设备来提高系统负载量。</p><p></p><p>传统银行与客户接触都是通过柜台，从资产层面来说，它的设备容量比较容易评估。而当用户和银行的接触由传统的线下物理网点变为互联网平台时，对银行系统的冲击也随之而来。</p><p></p><p>“互联网电商的运营模式，制造出来像双十一这样的消费高峰，最终会体现在银行的交易层面。这时，怎样解决弹性资源的分配？怎样才能抵御系统的高并发？大多数银行会把总系统按照类别进行拆分，如用户中心、支付中心、产品中心等。换句话说，银行会把相对聚焦的业务拆分成更小颗粒度的单元，来保证系统整体的性能。”王磊说道。</p><p></p><p>如果说互联网时代是以人为核心，企业聚焦的是链接，为人提供平衡的供需关系，那么，随之而来的数字经济时代，则是以价值为核心，企业追求的是共同创造利润，从业务模式出发，利用海量数据，由彼及己，为自身赢取增长。</p><p></p><p>因此，在数字经济的时代背景下，王磊认为数字化转型的重点，不纯粹发生在IT<a href=\"https://archsummit.infoq.cn/202212/beijing?utm_source=infoq&amp;utm_medium=conference\">技术架构</a>\"层面，而在于企业的业务发展。</p><p></p><p>他以银行互联网贷款的场景为例。传统方式下，用户向银行贷款递交申请主要是通过线下柜台，审核贷款申请可能需要几天甚至十几天；如今这种模式发生了明显的变化，银行后台通过算法模型以及引入各种辅助决策工具，让用户在线上递交的申请审核，变成一个自动化的过程，不少银行小额贷款可以做到实时反馈。</p><p></p><p>王磊表示，在前两个阶段，银行数据体系建设还主要是“烟囱式”，强调聚焦于某一条线、某一个业务板块去集成数据能力，而在不同条线之间会存在“<a href=\"https://www.infoq.cn/article/29uvshLBl6ZIeuxTdNOx\">部门墙</a>\"”，系统层面也会存在互不相通的障碍。这些阻碍导致各系统之间的数据无法打通，可能存在数据不一致、难调用等一系列的问题，很难满足前台业务的高效甚至是实时响应的需求。</p><p></p><p>“而数据中台的主要作用就是解决系统横向打通的问题，在系统层面最大程度实现数据复用。”王磊指出。也就是说，数据中台拥有可以为不同形式的业务，提供通用数据服务的能力。</p><p></p><h1>数据交付更加强调实时性</h1><p></p><p></p><p>但是，由于业界对数据中台的概念一直没有统一的共识，有的公司会把原有数据类的能力和技术统一打包，就叫做数据中台——其中的核心内容仍然是过去的元数据管理、数仓、数据湖，前台的BI系统、报表文件、多维分析，以及大数据等技术。</p><p></p><p>“这类所谓的数据中台，没有带来新的东西。一个新的名词出现时，它如果没有区别于之前已经存在的概念，就只是‘新瓶装旧酒’，并没有什么实质性的创新。”王磊强调。</p><p></p><p>在他看来，要想正确理解数据中台，需要一种务实的态度。从银行角度来讲，数据中台一定是要从前台业务价值出发，提供一些数据拆解的能力。比如，要灵活支持前台，中台就必须与前台同频率变化，实时满足业务场景的需求。</p><p></p><p>但是，由于前台覆盖的业务面非常广泛，要想保持同频，对数据中台的交付能力又会提出挑战。</p><p></p><p>过去，数据分析主要服务于特定的场景。比如，银行会依托业务模型，把交易系统产生的数据，通过一种批量处理的方式，整理成企业所关注的各种指标，然后工作人员会根据这些指标来制定管理者所关注的数据，最终以报表资料的形式，辅助不同层级的管理者进行决策。</p><p></p><p>“如今，在银行数字化阶段，数据的使用方式已经发生了实质性的变化，不是单纯只从管理者做决策这一个场景出发，而是融入在一线业务的每一个场景。比如，前面说到的银行发放网络贷款的场景中，怎么去识别客户提交的数据？最终银行是否应该发放贷款？具体应该发放多少额度？再比如，在银行的营销场景下，如何能够与客户接触，为客户提供他们更感兴趣的产品？为了做出决策，数据的支持发生在每时每刻，并且离不开场景。”王磊说道。</p><p></p><p>具体从时间维度来看，传统数据处理的时效性是“T+1”天，也就是说，今天输出的数据报表，实际上是通过昨天的数据进行批量处理而得到的。但现在，数据使用、交付不单纯体现在产出数据报表的时间节点上，而是只要有正常的业务开展，就需要有数据赋能，会反应在任何一个时间点上。“比如，当客户在手机APP端提交了一个操作请求，银行后台需要及时反馈这个请求，所以，数据的交付必须更加强调实时性。”王磊解释道。</p><p></p><p>从系统架构层面上来看，当数据交付方式变化，数据中台服务能力的建设模式也会发生变化。过去，银行会先从数据库中读取批量数据，然后经过计算处理，最后以报表文件方式输出数据，这时数据能力的复用跟数据批量加工的形式之间，有着很强的耦合关系。</p><p></p><p>“但为了满足时效性，如今数据交付方式正在向服务化的方向发展，整个数据中台服务能力的架构方式，也由传统烟囱式架构向着<a href=\"https://xie.infoq.cn/article/59f058d2221ed257c938f53d5\">微服务化</a>\"架构转型。”王磊说道。</p><p></p><p>具体来说，微服务架构运用的是围绕业务需求的轻量级架构，所以具有诸多好处。比如，因为服务的设计是围绕特定业务开展的，例如商品服务只管理商品、客户服务只管理客户等，这意味着开发人员足够专注，可以大大提高开发效率；再比如，微服务架构中的每一个服务都是一个独立应用，可以访问自己的数据库，通过提供公共API，服务之间还可以相互调用，如此一来就可以满足不同业务的快速开展和交互。</p><p></p><p>“所以，在我们的数据交付和应用交付过程中，服务化成为非常重要的承接方式，而微服务化架构也发挥着重要的作用。”王磊强调。</p><p></p><h1>数据中台可以这样考虑投入产出比</h1><p></p><p></p><p>但话说回来，建设数据中台的确是一件高投入且长期的工作，短期内很难看到直接效益。对于企业而言，不得不考虑到一件事就是“投入产出比”。</p><p></p><p>“如果数据中台非常划算，那么企业很早就会建设了，也不会等到现在。企业之所以都做烟囱式的系统，就是因为烟囱式系统的短期效益更好，做了一个系统、加了一个功能，立马可以用上。”王磊解释道，因此，短期来说，未必所有的企业都需要建设数据中台。不同的企业处于不同的发展阶段，拥有不同的盈利模式，自然对数据的需求也就千企千面。</p><p></p><p>但是，就<a href=\"https://www.infoq.cn/theme/149\">金融</a>\"机构而言，长期来看，当面临业务日新月异的变化，传统的IT系统建设模式，大概率比数据中台的建设成本更高。</p><p></p><p>王磊表示：“拿银行业来举例，为了适应客户需求的变化，银行在组织架构方面的调整也越来越频繁。很多时候会遇到今年系统要合并，明年再拆分的情况，如果按照原本的投入方式，反而会让IT系统成本越来越高。”</p><p></p><p>而如前文所说，数据中台的核心是企业级的能力复用，这种能力虽然不能快速建立起来，但是通过项目经验稳定沉淀，长此以往，可以大大降低企业的应用开发风险和成本。</p><p></p><p>那么，从未来中长期来看，企业应该如何权衡数据中台的投入产出比呢？</p><p></p><p>王磊认为，数据中台是不是能够带来效益，可以在构建新场景的过程中计算。比如，在固定场景中，数据中台投入了多大的成本，如果是按照传统烟囱式系统进行建设的话，其投入成本又有多少，二者进行对比分析，可以直接量化得出结果。未来，也可以采用同样的量化方式，复盘数据能力的复用可以为企业带来多少的增长价值。</p><p></p><p>“对于任何投入，企业都会理性地关注它的价值点。当我们去看数据中台时，最开始一定是看数据中台在哪些范围、哪些场景能发挥作用。企业一定也希望自己能够尽早的触达这些场景。如果数据中台在某个能力点上的复用率很高，应用场景自然也很广泛，那么，这一点的投入在未来带来收益的可能性就更很大。如果是复用率比较低的节点，企业投入就可以少一些。”王磊进一步说道。</p><p></p><p>他举了个例子，“比如，大多数银行都会对客户资产进行一个评估，这个指标会在不同条件、不同场景下被重复使用。因此，企业可以将这种关键性的指标放在数据中台的建设过程中，从而获得更大的收益。”</p><p></p><p>总的来说，企业应该通过自身的实践出发，找到具有潜力的业务场景，有针对性地投入资源、费用、人力等成本，才有更大可能从中挖掘价值、创造收益。</p><p></p><h1>让业务人员参与其中</h1><p></p><p></p><p>那么，建设完数据中台之后，如何确保它能够发挥最大的价值？这是大部分企业的另一个疑问。</p><p></p><p>王磊指出：“由于数据和业务之间具有关联性，数据的实际使用是以业务上的定义为前提的，换句话说，数据中台发挥价值的一个重要前提便是——要在业务语义上进行标准化、成体系的管理。”</p><p></p><p>他拿“客户”一词进行举例，对于不同分行、不同业务线、不同部门而言，这个词的定义、界限、分类可能完全不同。“但如果我们对客户都没有一个明确定义的话，那么客户的价值、客户的资产就不知道应该采用什么样的规则去计算，更不用提让数据能够复用了。这归根到底还是业务口径不一致带来的问题。”</p><p></p><p>由此可见，数据中台所形成的技术能力实际上是业务能力的体现，业务人员需要参与到整个数据中台的建设过程中，对数据有更好的管控，才能让数据中台更好地赋能于业务场景。</p><p></p><p>然而，业务与技术的鸿沟是天然存在的，这是企业面临的普遍问题，也是决定了数据中台价值能不能有效发挥的关键要素。 “从这两年银行业的实践可以看到，很多银行都在成立独立的数据部门，去负责数据能力建设或者数据中台建设的工作，目的就是拉通业务和技术，通过一种通力协作的方式去重新构建企业能力。具体来说，这个数据部门通常既有传统的IT技术能力，又会融合企业的业务能力。”王磊说道。</p><p></p><p>同样，我们也看到光大银行在数月前的公告中对外公布，银行的组织架构将有所调整，数据资产管理部也会随之建立起来。对此，王磊表示，“我觉得，未来数据资产管理部会在很大程度上推进我们共同去完善数据中台的建设。”</p><p></p><p>但是，另一个问题是，新技术的应用一定有一个周期。比如，目前还有很多银行的一线业务人员由于缺少对新技术工具的驾驭能力，所以仍旧会使用Excel这种非常传统的数据分析工具，进行计算、分析。</p><p></p><p>这其中既有业务人员思维意识的原因，也有技术本身的原因。“短时间来看，用Excel报表确实可以更灵活的完成一些工作。但是毕竟这只是一种轻量级的数据统计分析工具，随着银行数据量级的增长、<a href=\"https://www.infoq.cn/news/AkzC5erKpwNFTELuPAGQ\">业务场景</a>\"的复杂化，像Excel这种传统的数据统计分析工具会无法承载。另一方面，由于工具级别的不同，它们处理问题的逻辑也是不一样的，因此，系统对现在的业务支持可能也会存在一些盲点，这会导致一线业务人员不得不用报表去分析业务情况。”王磊表示。</p><p></p><p>所以，在他看来，业务人员使用数据的能力和技术人员构建的数据平台之间需要一个桥梁，在这个桥梁之上，还需要业务人员和技术人员的共同学习、互相奔赴，努力扩大“共通的意义空间”。只有这样，才能够真正发挥数据中台的价值，才能让<a href=\"https://www.infoq.cn/article/YcvRvZaOoez9sKJ92jHR\">数据</a>\"流向业务、驱动业务、赋能业务。</p>",
    "publish_time": "2022-09-26 11:44:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "聊聊可观测在企业的实践应用与实际价值｜InfoQ大会早班车第23期",
    "url": "https://www.infoq.cn/article/hTRCXPdd3Cphkdpf0bMi",
    "summary": "<p>可观测性如何服务好上层业务？自建还是引入？可观测运维对开发的价值有哪些？本次大会早班车聚焦可观测问题，邀请到阿里云资深技术专家承嗣、字节跳动可观测性平台负责人孔罗星进行分享，不妨来听一听他们的观点与分析。</p>",
    "publish_time": "2022-09-26 12:03:39",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "旧工厂如何用AI玩出新花样？",
    "url": "https://www.infoq.cn/article/ZGkKXpk51tTmHwOYCVKx",
    "summary": "<p>不少人认为，所谓的<a href=\"https://www.infoq.cn/article/8EjU56MwtgBcwB8ML8AT\">智能工厂</a>\"一定要有最完善的智能化产线，以及机械操作臂、AGV搬运车、码垛机器人等最先进的设备。但是，很多企业在智能化转型的初期，往往无法一次性到位，对旧工厂、旧设备的改造，几乎无法避免。</p><p></p><p><a href=\"https://www.auo.com/en-global\">友达</a>\"是全球头部的显示面板设计、研发、制造和销售公司，最早的工厂筹建于20多年前，所以很多设备在早期也不具备良好的数据采集和联网基础。但是，这些令很多传统制造企业在数字化和智能化转型过程中非常头大的旧设备和旧产线，似乎没有变成友达的“拖油瓶”，反而，友达利用<a href=\"https://www.infoq.cn/article/7vTfCLYoKzuIZTjdLGk0\">AIoT</a>\"技术为它们焕发出了新的生命力。</p><p></p><p>几年前，笔者曾经在参观友达苏州工厂时看到这样一幕：很多老旧设备的监测表头前都加装了一个摄像头，通过对表头数据（包括温度、压力等）进行图像识别和读取，把无法进行数据采集的关键设备信息也上传到了后台，供后续数据分析使用。这就解决了既要保护原始投资，又想实现数据获取、传输和应用的问题。</p><p></p><p>而这其实不过是友达借助AI、IoT、大数据等数字技术实现智能化升级的一个缩影。从2015年开始布局智能制造以来，除了对旧设备的改造，友达还布局了大量智能化设备和软硬件基础设施，在智能化的技术、场景、人才等方面积累了大量经验，这些经验先是在公司内部得到了广泛且深入的复制落地，随后又转化为技术产品向外部进行智慧工业服务输出，成为友达的另一增长曲线。并且，就在2021年，友达还凭此转型成效获评了世界经济论坛的“全球灯塔工厂”。</p><p></p><h1>是什么让友达“积极转型”</h1><p></p><p></p><p>故事要从2015年讲起。那一年，友达开始在全集团范围内投入大量资源进行数字化建设，其中包括数据整合与数据分析技术提升等。2016年，阿尔法狗大战世界围棋冠军李世石，并以4:1的总分获胜，AI技术迎来高光时刻；一年之后，友达很快启动了全面智能化战略，开始在内部通过AI等技术与先进制造融合，构建自感知、自决策、自执行的智能系统。</p><p></p><p>“所谓的自感知就是数据能被采集侦测，比如设备的状况能通过IoT技术做到实时监测；自决策就是数据采集后可以借助AI技术进行数据分析建模，从而实现自主决策，例如是否要调整参数或者停机等等，并且不管数据是在边缘、云端还是本地；自执行就是在决策完成后，可以把决策动作反馈到后台，让智能系统做自执行、自调整，形成闭环。”艾聚达信息技术（苏州）有限公司（以下简称“艾聚达”）总经理赖骏凯在接受InfoQ采访时解释，从技术角度而言，这样的智能系统正是AI与IoT技术融合的表现形式，是<a href=\"https://www.infoq.cn/article/a9ChVY8DGJRbXqTHqjah\">AIoT落地</a>\"的成果。</p><p></p><p><a href=\"https://ati.auodigitech.com/\">艾聚达</a>\"是友达在2018年成立的工业服务全资子公司之一，主要提供 AI 赋能的 HaaS 平台解决方案，透过 AI 技术赋能边缘硬件产生数据价值，助力企业智慧化升级。具体来说，艾聚达基于AI技术，可以帮助企业提取数据价值并将算法模型赋予终端，让边缘硬件产生智慧决策能力。凭借在制造行业多年积累的丰富场景应用技术与算法模型，能够为各企业提供工业自动化、边缘智能化、工业大脑、工业人工智能平台四大解决方案和服务。</p><p></p><p>和艾聚达同年成立的，还有另一家工业服务子公司友达智汇，主要提供规划咨询服务解决方案、数字化工厂解决方案、智能工厂解决方案和绿色智慧园区解决方案。2021年，友达在全球的智慧工业服务全新事业：友达数位成立，艾聚达和友达智汇都划归为旗下子公司，共同为制造业转型升级贡献力量。</p><p></p><p>事实上，变革是一件需要强驱动力的事情，和大多数企业一样，友达最初做数字化和智能化，也有很多外部因素的推动。赖骏凯告诉InfoQ，光电是一个竞争非常激烈的行业，尤其是在过去十年间，国内面板市场出现了大规模的扩产，对于友达这样的光电制造领导企业来说，必须提前布局思考如何从规模竞争转向价值竞争。</p><p></p><p>所谓价值转型主要表现在两方面：首先，是产品形态的转变，专注于高附加值的产品；其次，是订单形态的变化，从规模化生产转变为少量多样的订单生产。举例来说，“现在大家打游戏对画面的要求越来越高，我们就必须做超高刷新率的产品，以前这种产品的标准是90赫兹，也就是一秒刷新90次，但现在在电竞领域，我们已经可以做到领先业界的500赫兹。”赖骏凯表示，“外部环境的这些变化，要求我们必须做高度定制化，必须少量多样地去生产，但是这种生产方式会带来一个很大的挑战，比如产能会有所损失、成本会增加、良率会变差，这就是我们转型过程中的‘痛’。”</p><p></p><p>除此之外，还有一个关键的矛盾点——市场需求变快、产品周期变短，但面板产品的制造周期却相对长。用赖骏凯的话说，产品优化和生产的速度都不一定能跟上产品需求的变化速度。“所以，正是这些源源不断的问题促使我们很早就开始思考，如何通过新的技术提升内部的竞争力，如何用新方法解决旧问题。”</p><p></p><h1>AI解决了哪些问题</h1><p></p><p></p><p>2017年开始，AI成了友达应对这些问题的那个“新的技术”和“新的方法”。具体来说，赖骏凯认为AI在制造行业主要有三大应用场景——数据科学、<a href=\"https://www.infoq.cn/article/MDuweEQy7Qr1FNHFXzfN\">工业质检</a>\"和智能监控。</p><p></p><p>以生产排程计划为例，赖骏凯表示，在面板制造的过程中有一个关键制程，每个产线配备的设备比较有限，所以作为一个稀缺资源，这类设备的排程计划会直接影响生产效率。</p><p></p><p>“比如，这个设备一次要生产多少片面板、一天要产出多少量，如果产品在A设备上良率比较低，这时候就必须在B设备上生产，这些都是限制式。而这些限制式一旦达到一定数量，比如十几种甚至几十种，用人工去计算的工作量是大且繁复的。”赖骏凯表示，过去这个工作需要由最有经验的工程师每天花时间用Excel表格手工完成。</p><p></p><p>但这种“传统”的模式不只效率低、调整次数有限，而且很难与MES（生产执行系统）联动生产。“而利用AI模型，我们只要把限制式输入进去，它就能直接输出一个最佳排程结果，告诉我们今天最多可以生产多少产品，甚至什么时间点要产出这些产品。这么做的好处不只是效率变高了，也使得该关键设备的产能得以提升。</p><p></p><p>同样的道理，面向员工的排班工作也可以由AI完成。在友达工厂，基于由AI自动化进行的排岗、调休和操作规范知识库实时支持，员工每天上岗后就可以非常清楚自己当天的主要工作、具体的生产任务、操作注意事项等等。</p><p></p><p>另外，其中还有一个令人拍案的巧思之处在于，友达在每个关键岗位也加设了摄像头，结合AI技术可以分析员工的作业节拍，判断动作是否标准等。这样一来，传统工位就摇身一变变成了智能工位，过去可控性比较低的人工作业也实现了相对的标准化，在生产环节就提高了对产品质量的把控。</p><p></p><p>而为了提高产线的可控性，除了对人的操作做追踪，还要对设备的运行状态做监测。比如我们在开篇中提到的那一幕，通过摄像头读取表头数据的目的，事实上就是为了对设备做监控，一旦设备出现故障，可能直接表现为温度、压力等数据异常，这时候就可以立即给设备工程师下维修订单。</p><p></p><p>赖骏凯介绍，如今在友达工厂，早期那些加挂固定式的摄像头很多已经升级成了移动式的摄像头，通过加装在机械臂上，不但可以用来读取数据，还可以去完成一些不适合人工完成的操作。比如在车间的一些角落，人要进去比较困难，很容易撞头或者发生危险，这时候，机械臂的摄像头和自动巡检机器人配合就可以替代人工作业，完成点检的工作，用来规避这些安全隐患。</p><p></p><h1>如何搞定“人”的问题</h1><p></p><p></p><p>由于友达的智能化转型起步较早，当时行业内几乎没有可参考的案例和路径，所以回顾这7年的历程，赖骏凯坦言他们也走过一些弯路。</p><p></p><p>赖骏凯回忆，最开始友达对于AI这样的新技术也不熟悉，如何把它与制造流程结合更没有概念，所以初期只能先依托外部资源进行项目合作。“他们的确给我们带来了新的技术思维，对我们视野产生了新的扩展，但是在这个过程中我们还是遇到了两个问题。一方面，这些公司不够了解工业现场的场景和一线的真正需求，这使得我们之间的沟通成本很高；另一方面，当技术公司在项目完成撤出后，除了产品本身，他们的能力并没有留存下来，使得我们无法基于新的技术能力持续进行制程优化。”</p><p></p><p>友达很快意识到，这个困境的症结出在“人”上。于是，从2018年开始，友达每年都会安排遍布于各地、各个产线、各个部门的工程师进行<a href=\"https://time.geekbang.org/resource?m=0&amp;d=8&amp;c=8\">脱岗学习</a>\"，他们不只是技术人员，还可能来自生产部门、研发部门或者品质管理部门。在这个过程中，他们会先花大概数个月的时间学习AI、RPA等最新的技术，然后再用近一年的时间做专案，让每一个人了解除了过去他专精的业务领域之外，AI技术还可以解决哪些业务问题。</p><p></p><p>“随着我们AI落地经验的不断积累, 也摸索出工业应用的核心场景, 即将过去积累的经验转化为AI工具平台，也就是说，后进的人只要通过已平台化的工具就可以快速获得AI能力去解决问题。比如，我们有一个AI平台，它可以帮助员工在上面快速做数据分析，做最佳参数推荐。”赖骏凯表示，这一平台的使用门槛非常低，只要对制程机理有一定了解，进公司大概半年时间，就能在上面灵活运用AI工具帮助自己探索数据价值，而不一定要懂代码、懂Python。</p><p></p><p>那么，有了技术又找对了场景就能万事大吉了吗？真相往往没有那么简单。据了解，友达最初通过MES、ERP、IoT等系统的融合把数据做了统一的整合管理，然而，转型初期的<a href=\"https://www.infoq.cn/article/YcvRvZaOoez9sKJ92jHR\">数据利用率</a>\"偏低。很多企业在数字化、智能化的推进过程中也会遇到类似的问题。</p><p></p><p>在赖骏凯看来，这一方面是管理的问题。还以设备故障维修为例，虽然AI可以帮助工厂做数据读取、数据分析，实现故障预警。但是，后续的维修动作还是由人来完成。过去，产线生产员工和设备工程师之间的关键矛盾在于，设备出现故障会直接影响生产人员的业绩，但与工程师的业绩无关。所以，设备维修这件事最后往往是后者不急前者急。</p><p></p><p>为了解决这个问题，友达的办法是装预警灯+APP“抢单”。如果设备出现故障没有及时维修，预警灯就会长亮。而在后台，通过“抢单”的方式可以快速匹配工程师进行故障维修，并且所有维修结果，包括平均用时等等都会通过数据结果呈现到后台，与工单价格直接挂勾。通过这种管理模式的改变，友达的工厂车间从“有故障没人修”变成了“有故障抢着修”，从反应式管理变成了预测式管理。</p><p></p><p>另一方面，数据利用率低也是人的思维因素使然。“比如，那么多数据呈现在眼前，但不知道如何将其价值充分发挥出来。这时候我们就需要通过一些培训和机制培养员工在这方面的能力，让大家知道自己关心的指标什么情况下异常，如果发生异常应该采取什么动作，其中的数据量够不够，如果不够是否需要通过IoT再补充收集数据等等。通过这样的方式慢慢培养工程师的数据思维，让大家的能力螺旋式上升。”赖骏凯解释道。</p><p></p><p>也就是说，要让<a href=\"https://www.infoq.cn/article/k0Lr2oVo3EdPqVR6CLo0\">数据驱动</a>\"形成闭环是一个系统工程，既要有技术维度，也要有管理维度，二者融合才能让效果最大化。</p><p></p><h1>写在最后</h1><p></p><p></p><p>其实，变革这件事就像是过河，有人早早上岸，有人正在蹚水，有人还在观望。</p><p></p><p>赖骏凯表示，这是一个从0到1、从1到10、从10再到100的过程。企业不需要急于求成，一开始就投入大量的资源。而是找准自己的问题点，在几个关键的业务场景先针对性地投入做试点，取得一定改善成效之后再进一步复制平展。</p><p></p><p>比如，对于友达来说，并没有一上来就把老旧设备都抛弃，也不是一步到位全做了改造，而是先从关键设备开始，逐步对旧设备实现了数据联网，再逐步实现AI自决策与异常自调整。</p><p></p><p>“并且，我们在做任何流程改善的时候，都会先做流程梳理，然后再做流程精益，在精益化完成之后，才能把一些新的技术逐步放进去，形成新的智能化制造流程。”赖骏凯强调，“这么做的原因，一是避免资源浪费，二是让内部员工看到新技术的价值。”</p><p></p><p>如此一来，无论是数字化还是<a href=\"https://www.infoq.cn/article/UlxmUYElHHjTsU55rFUP\">智能化</a>\"，才能在企业内部形成自上而下、自下而上的可持续正循环，形成滚雪球式的效应放大，让企业真正从中受益，实现降本增效、提质转型的最终目的。</p>",
    "publish_time": "2022-09-26 12:42:11",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]