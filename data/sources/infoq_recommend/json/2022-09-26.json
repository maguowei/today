[
  {
    "title": "Java近期新闻：Helidon Níma、Spring Framework、MicroProfile、MicroStream、Kotlin和Piranha",
    "url": "https://www.infoq.cn/article/d9jp2N9XlIiCbfgWpd9P",
    "summary": "<p>本期的Java新闻包括JDK 19、JDK 20、Spring框架的更新、Spring Cloud与Spring Tools、Helidon Níma、MicroProfile Reactive规范、Quarkus 2.12.2、MicroStream 7.1.0、Reactor项目2022.0.0-M6、Hibernate Search 6.1.7、JHipster Lite 0.15.1、Piranha Cloud 22.9.0、Kotlin 1.7.20-RC和Apache Tika 1.28.5。</p><p></p><h4>JDK 19</h4><p></p><p><a href=\"https://openjdk.org/projects/jdk/19/\">JDK 19</a>\"已经于2022年9月20日正式发布。<a href=\"https://jdk.java.net/19/release-notes\">发布说明</a>\"包含了文档的链接，比如<a href=\"https://cr.openjdk.java.net/~iris/se/19/latestSpec//api/index.html\">完整的API规范</a>\"以及一个<a href=\"https://cr.openjdk.java.net/~iris/se/19/latestSpec/apidiffs/overview-summary.html\">标注的API规范</a>\"，后者对比了JDK 18（<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-18%2B36\">Build 36</a>\"）和JDK 19（<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-19%2B36\">Build 36</a>\"）的差异。关于JDK 19的更多细节和对JDK 20的预测可以参阅InfoQ的<a href=\"https://www.infoq.com/news/2022/09/java-19-so-far/\">新闻报道</a>\"。</p><p></p><h4>JDK 20</h4><p></p><p>JDK 20的<a href=\"https://jdk.java.net/20/\">早期访问构建</a>\"版本<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-20%2B15\">Build 15</a>\"发布，它是对Build 14的<a href=\"https://github.com/openjdk/jdk/compare/jdk-20%2B14...jdk-20%2B15\">更新</a>\"，包括对各种[问题](https://bugs.openjdk.org/issues/?jql=project %3D JDK AND fixversion %3D 20 and \"resolved in build\" %3D b15 order by component%2C subcomponent)的修复。关于该版本的更多细节，请参阅<a href=\"https://jdk.java.net/20/release-notes\">发布说明</a>\"。</p><p></p><p>对于<a href=\"https://openjdk.java.net/projects/jdk/19/\">JDK 19</a>\"和<a href=\"https://openjdk.java.net/projects/jdk/20/\">JDK 20</a>\"，鼓励开发者通过<a href=\"https://bugreport.java.com/bugreport/\">Java Bug数据库</a>\"报告缺陷。</p><p></p><h4>Spring框架</h4><p></p><p>Spring框架向Java社区<a href=\"https://spring.io/blog/2022/09/15/spring-framework-6-0-0-m6-and-5-3-23-available-now\">发布了</a>\"6.0.0-M6和5.3.23版本版本。这两个版本都提供了新特性、缺陷修复和依赖升级。5.3.23版本引入的新特性是<a href=\"https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/core/annotation/AnnotationUtils.html\">AnnotationUtils</a>\"类中定义的**isSynthesizedAnnotation()方法，它能够让开发人员放弃已废弃的<a href=\"https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/core/annotation/SynthesizedAnnotation.html\">SynthesizedAnnotation</a>\"接口。6.0.0-M6版本定义了七个废弃的功能，并且将会移除两个之前定义的废弃功能，其中包括SynthesizedAnnotation**接口。关于这两个版本的更多细节可以参阅<a href=\"https://github.com/spring-projects/spring-framework/releases/tag/v5.3.22\">5.3.23</a>\"和<a href=\"https://github.com/spring-projects/spring-framework/releases/tag/v6.0.0-M6\">6.0.0-M6</a>\"版本的发布说明。</p><p></p><p>Spring Cloud Dataflow 2.9.6<a href=\"https://spring.io/blog/2022/09/14/spring-cloud-dataflow-2-9-6-released\">发布</a>\"，特性包括升级PostgreSQL驱动版本至42.2.26以解决CVE-2022-31197漏洞，即<a href=\"https://github.com/advisories/GHSA-r38f-c4h4-hqq2\">通过恶意的列名能够在ResultSet.refreshRow()中触发PostgreSQL JDBC驱动的SQL注入</a>\"，该漏洞是由于**ResultSet类中refreshRow()**方法的实现没有正确的转义列名，所以包含语句终结符（比如分号）的恶意列名会导致SQL注入。关于该版本的更多细节可以参阅<a href=\"https://github.com/spring-cloud/spring-cloud-dataflow/releases/tag/v2.9.6\">发布说明</a>\"。</p><p></p><p><a href=\"https://github.com/spring-projects-experimental/spring-cloud-sleuth-otel/blob/main/README.adoc\">Spring Cloud Sleuth OpenTelemetry</a>\" 1.1.0版本<a href=\"https://spring.io/blog/2022/09/16/spring-cloud-sleuth-opentelemetry-otel-1-1-0-has-been-released\">发布</a>\"，这是<a href=\"https://spring.io/projects/spring-cloud-sleuth\">Spring Cloud Sleuth</a>\"的一个实验性扩展，其中包括了对Spring Cloud 2021.0.4和OpenTelemetry 1.18.0的依赖升级。关于该版本的更多信息请参阅<a href=\"https://github.com/spring-projects-experimental/spring-cloud-sleuth-otel/releases/tag/v1.1.0\">发布说明</a>\"。</p><p></p><p>Spring Tools 4.16.0<a href=\"https://spring.io/blog/2022/09/16/spring-tools-4-16-0-released\">发布</a>\"，特性包括：支持<a href=\"https://eclipseide.org/\">Eclipse 2022-09</a>\"；适用于ARM上Linux环境的实验性发行版；更新<a href=\"https://www.eclipse.org/m2e/\">M2Eclipse</a>\"（m2e）2.0.5。关于该版本的更多细节，可以参阅<a href=\"https://github.com/spring-projects/sts4/wiki/Changelog#2022-09-16-4160-release-incl-language-servers-version-1390\">变更日志</a>\"。</p><p></p><h4>Helidon</h4><p></p><p>甲骨文<a href=\"https://medium.com/helidon/please-welcome-helidon-n%C3%ADma-9a882c5b6f1e\">引入了</a>\" Helidon Níma，这是一个基于虚拟线程的微服务框架，它提供了一个低开销、高并发的服务器，同时保持了阻塞式的线程模型。在<a href=\"https://helidon.io/\">Helidon项目</a>\"的协助下，这个新的框架随Helidon 4.0.0发布了<a href=\"https://medium.com/helidon/helidon-n%C3%ADma-helidon-on-virtual-threads-130bb2ea2088\">第一个alpha版本</a>\"，但是Java社区需要2023年底才能等到正式的GA版本。关于Helidon Níma的更多细节，可以参阅InfoQ的<a href=\"https://www.infoq.com/news/2022/09/introducing-helidon-nima/\">新闻报道</a>\"。</p><p></p><h4>MicroProfile</h4><p></p><p>在通往<a href=\"https://microprofile.io/\">MicroProfile</a>\" 6.0的路上（计划2022年10月发布），<a href=\"https://github.com/eclipse/microprofile-reactive-streams-operators/releases/tag/3.0\">Reactive Streams Operators 3.0</a>\"和<a href=\"https://github.com/eclipse/microprofile-reactive-messaging/releases/tag/3.0\">Reactive Messaging 3.0</a>\"规范向Java社区发布，其特性与Jakarta EE 9.1保持了一致。</p><p></p><h4>Quarkus</h4><p></p><p>Red Hat<a href=\"https://quarkus.io/blog/quarkus-2-12-2-final-released/\">发布</a>\"了Quarkus 2.12.2.Final，包括了SnakeYAML 1.3.2、Hibernate Validator 6.2.5.Final和JBoss Threads 3.4.3.Final的依赖升级。关于该版本的更多细节可以参阅<a href=\"https://github.com/quarkusio/quarkus/releases/tag/2.12.2.Final\">变更日志</a>\"。</p><p></p><h4>MicroStream</h4><p></p><p>MicroStreams<a href=\"https://microstream.one/blog/article/release-of-microstream-version-7-1/\">发布</a>\"了其7.1.0版本的对象-图持久化框架，特性包括：集成Spring Boot；改善与CDI和MicroProfile Config运行时的集成；改进了数据通道的垃圾收集。此外，他们还开源了所有的连接器，现在包括Oracle和SAP HANA数据库、 Cloud存储（AWS S3、Azure Storage、Google Firestore、Oracle Object Storage）以及其他资源（Hazelcast、Kafka、Redis、DynamoDB、Oracle Coherence）。关于该版本的更多信息请参阅<a href=\"https://github.com/microstream-one/microstream/releases/tag/07.01.00-MS-GA\">发布说明</a>\"。</p><p></p><h4>Reactor项目</h4><p></p><p>在通往<a href=\"https://github.com/reactor/reactor/blob/main/README.md\">Reactor项目</a>\"2022.0.0的路上，<a href=\"https://github.com/reactor/reactor/releases/tag/2022.0.0-M6\">第六个历程碑版本</a>\"发布，其特性是对**reactor-core** 3.5.0-M6和**reactor-netty** 1.1.0-M6制品的依赖升级。此外，还对第六个里程碑版本进行了调整，reactor-pool 1.0.0-M6、reactor-addons 3.5.0-M6和**reactor-kotlin-extensions** 1.2.0-M6这些制品保持不变。</p><p></p><h4>Hibernate</h4><p></p><p><a href=\"https://hibernate.org/search/\">Hibernate Search</a>\" 6.1.7.Final发布，它将依赖升级到了Hibernate ORM 5.6.11.Final；将所有包含**-orm6**名称的制品与Hibernate ORM的依赖保持一致；以及Java模块相关缺陷的修复。</p><p></p><h4>JHipster Lite</h4><p></p><p><a href=\"https://github.com/jhipster/jhipster-lite/blob/main/README.md\">JHipster Lite</a>\"的0.15.0和0.15.1版本<a href=\"https://twitter.com/pascalgrimaud/status/1570138502850920448\">发布</a>\"，它是JHipster的启动项目，包含许多功能增强、错误修复、依赖性升级和重构。关于这个版本的更多细节可以在<a href=\"https://github.com/jhipster/jhipster-lite/releases/tag/v0.15.0\">0.15.0</a>\"和<a href=\"https://github.com/jhipster/jhipster-lite/releases/tag/v0.15.1\">0.15.1</a>\"版本的发布说明中找到。</p><p></p><h4>Piranha</h4><p></p><p>Piranha 22.9.0<a href=\"https://github.com/piranhacloud/piranha/releases/tag/v22.9.0\">发布</a>\"。这个新版本被称为2022年9月的“Core Profile just landed”版本，其特性包括：支持通过<a href=\"https://github.com/piranhacloud/piranha/issues/2775\">Piranha Core Profile</a>\"引入Jakarta EE Core Profile；以及对<a href=\"https://jakarta.ee/specifications/transactions/2.0/\">Jakarta Transactions</a>\"和<a href=\"https://jakarta.ee/specifications/persistence/3.1/\">Jakarta Persistence</a>\"规范的初始支持。关于这个版本的更多细节可以在他们的<a href=\"https://javadoc.io/doc/cloud.piranha/project/latest/index.html\">文档</a>\"和<a href=\"https://github.com/piranhacloud/piranha/issues?q=is%3Aissue+-label%3Awontfix+milestone%3A22.9.0+is%3Aclosed\">问题跟踪页面</a>\"中找到。</p><p></p><h4>Kotlin</h4><p></p><p>KotlinJetBrains<a href=\"https://blog.jetbrains.com/kotlin/2022/09/kotlin-news-august/\">发布了</a>\"Kotlin 1.7.20-RC，其特性包括：支持多个新的<a href=\"https://kotlinlang.org/docs/whatsnew-eap.html#support-for-kotlin-k2-compiler-plugins\">插件</a>\"；预览用于开闭式范围的**..&lt;**操作符；默认启用Kotlin/Native内存管理器；以及增加具有通用底层类型的内联类，这是一个实验性功能。</p><p></p><h4>Apache软件基金会</h4><p></p><p>Apache Tika 1.28.5<a href=\"https://www.mail-archive.com/announce@apache.org/msg07572.html\">发布</a>\"，其特性包括：安全问题修复；修复从PDF中提取书签时出现无限循环的问题；以及依赖性升级。该版本的详细信息可以在<a href=\"https://downloads.apache.org/tika/1.28.5/CHANGES-1.28.5.txt\">更新日志</a>\"中找到。1.x版本的发布列车将在2022年9月30日结束生命周期。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/09/java-news-roundup-sep12-2022/\">Java News Roundup: Helidon Níma, Spring Framework, MicroProfile, MicroStream, Kotlin, Piranha</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/pQ7VDmaij1aCT9TD0R06\">在 Java 中如何加快大型集合的处理速度</a>\"</p><p><a href=\"https://www.infoq.cn/article/3IgHpkRJIsFXm0vPNvFc\">甲骨文新微服务框架Helidon Níma：使用虚拟线程实现高性能</a>\"</p>",
    "publish_time": "2022-09-26 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "不要指望下一个像GPT这样的大型语言模型会民主化",
    "url": "https://www.infoq.cn/article/UrFKiffb44jcffwP5FbH",
    "summary": "<p></p><blockquote>5月初，Meta公司发布了Open Pretrained Transformer（OPT-175B），这是一个可以执行各种任务的大型语言模型（LLM）。在过去几年中，大型语言模型已经成为人工智能研究最热门的领域之一。</blockquote><p></p><p></p><p>本文最初发布于TeckTalks。</p><p></p><p><a href=\"https://www.infoq.cn/article/4iDmM3PgXmvELorwQ8M3\">OPT-175B</a>\"是由OpenAI的<a href=\"https://www.infoq.cn/article/Z46h9vTIL3dBx5Z3hAjO\">GPT-3</a>\"引发的LLM军备竞赛的最新参与者。GPT-3是一种具有1750亿个参数的深度神经网络。GPT-3表明，LLM可以在没有任何额外训练以及只学习几个样本（零样本或小样本学习）的情况下完成许多任务。微软后来将GPT-3集成到了它的几个产品中，不仅展示了LLM在科学研究上的前景，也展示了其在商业应用上的前景。</p><p></p><p>让OPT-175B与众不同的是Meta对“开放性”的承诺，正如模型的名字所暗示的那样。Meta已经向公众提供了这个模型（以及一些注意事项），它还公布了大量关于训练和开发过程的细节。在Meta AI博客上发表的一篇文章中，该公司将OPT-175B的发布描述为“大规模语言模型的民主化访问”。</p><p></p><p>Meta朝着透明的方向发展值得称赞。然而，大型语言模型的竞争已经达到了无法再民主化的地步。</p><p></p><h2>关于该大型语言模型的几个细节</h2><p></p><p></p><p>Meta发布的OPT-175B有一些关键特性，包括预训练的模型以及训练和使用LLM所需的代码。对于没有计算资源用于训练模型的组织，预训练模型特别有用（训练神经网络比运行它们消耗的资源更多）。它有助于减少训练大型神经网络所需的计算资源所造成的巨大碳排放量。</p><p></p><p>与<a href=\"https://www.infoq.cn/article/w1lxxO4qtaVPxZUdqzwi\">GPT-3</a>\"一样，OPT也有不同的大小，参数从1.25亿到1750亿不等（参数越多模型学习能力越强）。在撰写本文时，OPT-30B以下的所有模型都已提供下载。拥有全部1750亿个参数的模型将仅提供给被选中的研究人员和机构（他们需要填写一张申请表）。</p><p></p><p>根据Meta AI博客，“为了保持完整性和防止滥用，我们将在非商业许可下发布我们的模型，专注于研究用例。该模型将授权给学术研究人员，与政府、民间团体和学术机构有关的组织，以及世界各地的行业研究实验室。”</p><p></p><p>除了模型，Meta还发布了一份完整的日志，提供了关于该大型语言模型开发和训练过程的详细的技术时间线。通常，发表的论文只包含最终模型的信息。Meta表示，该日志提供了一些有价值的信息，包括“用于训练OPT-175B的计算资源的数量，以及当底层基础设施或训练过程本身因为规模太大而变得不稳定时所需的人力开销。”</p><p></p><h2>与GPT-3比较</h2><p></p><p></p><p>Meta公司在其博文中指出，大型语言模型大多是通过“付费API”访问的，对LLM的限制性访问“限制了研究人员了解这些大型语言模型如何工作以及为何有效的能力，妨碍了他们提高模型鲁棒性以及缓解偏见和数据中毒等已知的问题”。</p><p></p><p>这对于OpenAI（以及微软的独家GPT-3许可）无疑是一记重击，后者将GPT-3作为黑盒API服务发布，而不是将其模型权重和源代码公开。OpenAI没有公开GPT-3的原因之一是控制有害应用程序的滥用和开发。</p><p></p><p>Meta相信，把模型提供给更广泛的受众，他们将可以更好地研究和预防它们可能造成的任何伤害。</p><p></p><p>Meta是这样描述这项工作的：“我们希望，OPT-175B将为大型语言模型创建前沿带来更多的声音，帮助社区共同设计负责任的发布策略，并为该领域大型语言模型的开发增加前所未有的透明度和开放性。”</p><p></p><h2>大型语言模型的成本</h2><p></p><p></p><p>然而，值得注意的是，“透明和开放”并不等同于“民主化大型语言模型”。训练、配置和运行大型语言模型的成本仍然很高，而且未来可能还会增长。</p><p></p><p>根据Meta的博文，模型的研究人员已经大幅降低了训练大型语言模型的成本。该公司表示，这个模型的碳排放量已减少到GPT-3的七分之一。据我之前采访过的专家估计，GPT-3的训练成本高达2760万美元。</p><p></p><p>这意味着，OPT-175B的训练成本仍将高达数百万美元。幸运的是，预训练的模型可以避免模型训练过程，并且Meta表示，他们将提供“只使用16块NVIDIA V100 GPU”就可以完成整个模型训练和部署的代码库。这相当于一台英伟达（Nvidia）DGX-2，成本约为40万美元。对于资金紧张的研究实验室或个体研究人员来说，这不是一个小数目。(根据一篇提供了更多OPT-175B细节的论文，Meta使用992块A100 80GB GPU训练了自己的模型，这款GPU明显比V100快。)</p><p></p><p>Meta AI的日志进一步证实，训练大型语言模型是一项非常复杂的任务。OPT-175B的时间线上到处都是服务器崩溃、硬件故障和其他需要高级技术人员才能解决的并发症。研究人员还不得不多次重启训练过程，调整超参数，修改损失函数。所有这些都会产生小型实验室无法承担的额外费用。</p><p></p><h2>大型语言模型的未来</h2><p></p><p></p><p>语言模型如OPT和GPT都是基于转换器架构的。转换器的关键特性之一是它们能够大规模地并行处理海量时序数据（如文本）。</p><p></p><p>近年来，研究人员已经证明，增加转换器模型的层数和参数，可以提高它们在语言任务上的性能。一些研究人员认为，达到更高的智能水平只是一个规模问题。因此，像Meta AI、DeepMind（由Alphabet拥有）和OpenAI（由微软支持）这样现金充足的研究实验室正在朝着创建越来越大的神经网络前进。</p><p></p><p></p><blockquote>某人的观点文章。我的看法是：现在都是规模问题了！游戏结束了！现在只要让这些模型更大、更安全、计算效率更高、采样更快、记忆更智能、模式更多样、数据更有创新性，无论在线还是离线......1/N <a href=\"https://t.co/UJxSLZGc71?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjM4MTUxNzMsImZpbGVHVUlEIjoiR1E5NVBaWE55VEVjbGlYdSIsImlhdCI6MTY2MzgxNDg3MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyNTY1MTE5Nn0.Nskx-jA73oq2h4Mm1yBBSTg5klykj1PGjBvHJVLq0Hc\">https://t.co/UJxSLZGc71</a>\"—— Nando de Freitas（@NandoDF）</blockquote><p></p><p></p><p>去年，微软和英伟达创建了一个有5300亿个参数的语言模型，名为Megatron-Turing （MT-NLG）。上个月，谷歌推出了路径语言模型（PaLM）。这是一个有5400亿个参数的LLM。有传言称，OpenAI将在未来几个月发布GPT-4。</p><p></p><p>然而，神经网络越大需要的财政和技术资源也越多。虽然更大的语言模型会带来新的东西（和新的问题），但不可避免地，它们将把权力集中在少数富有的公司手中，使得较小的研究实验室和独立的研究人员更难研究大型语言模型了。</p><p></p><p>在商业方面，大型科技公司将拥有更大的优势。运行大型语言模型是非常昂贵和具有挑战性的。像谷歌和微软这样的公司有特殊的服务器和处理器，他们能够大规模运行这些模型并从中获利。对于比较小的公司来说，运行自己的LLM（如GPT-3）版本开销太大了。正如大多数企业使用云托管服务，而不是构建自己的服务器和数据中心一样，随着大型语言模型变得越来越流行，像GPT-3 API这样的开箱即用系统将越来越有吸引力。</p><p></p><p>这反过来又会使人工智能进一步集中在大型科技公司的手中。越来越多的人工智能研究实验室将不得不与大型科技公司建立合作伙伴关系，以获得资助。而这将使大型科技公司有更多的权力来决定人工智能研究的未来方向（这可能会与他们的经济利益相一致）。这可能要以那些短期内无法产生投资回报的研究领域为代价。</p><p></p><p>最后，当我们庆祝Meta为LLM带来透明度的时候，请不要忘记，大型语言模型本质上就是不民主的，而是有利于推广它们的公司。</p><p></p><p>英文原文：<a href=\"https://bdtechtalks.com/2022/05/16/opt-175b-large-language-models?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjM4MTUxNzMsImZpbGVHVUlEIjoiR1E5NVBaWE55VEVjbGlYdSIsImlhdCI6MTY2MzgxNDg3MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyNTY1MTE5Nn0.Nskx-jA73oq2h4Mm1yBBSTg5klykj1PGjBvHJVLq0Hc\">Can large language models be democratized?</a>\"</p>",
    "publish_time": "2022-09-26 08:20:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "基于微服务和低代码，网易数帆推出软件生产力新模型",
    "url": "https://www.infoq.cn/article/fqygd7M5v6MlKUx3acIw",
    "summary": "<p>9月23日，2022网易数字+大会在杭州召开。针对数字化转型下的企业软件研发需求，网易数帆在会上发布了轻舟云原生、轻舟低代码两大产品线的一系列升级，并基于此推出了以资产为中心的软件生产力模型和技术方案。网易数帆云原生及低代码产品线总经理陈谔表示，该方案旨在通过微服务和低代码在帮助企业沉淀内部标准化的原子服务与数据，形成可组装的业务资产，并采用组装的开发方式快速进行创新业务生产和交付，云原生底座提供服务运行保障。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/89/89c8db0560c83f694813f2dc5f23091a.png\" /></p><p></p><p>网易数帆云原生及低代码产品线总经理陈谔</p><p></p><h2>云原生升级：探索共享复用，促进业务创新</h2><p></p><p>陈谔首先介绍了网易数帆云原生产品线在行业的落地进展以及产品升级方向。在过去一年，网易数帆轻舟云原生平台支撑了金融行业众多核心业务场景，包括从小型机向分布式架构迁移、国产信创适配、个贷业务交易安全、生态缴费业务高可用保障等。在此过程中，网易数帆云原生平台的着眼点，也从帮助企业应用进行微服务化改造，转向提供稳定性治理和高可用性保障，并开启了共享复用的探索。</p><p></p><p>以中间件稳定性治理为例，网易数帆全新推出了中间稳定性管控产品，提供巡检和辅助定位能力，基于网易内部中间件稳定性治理实践，不仅将超过300条运维经验交付给用户，还通过“知识引擎”能力，帮助业务建立稳定性改进循环。</p><p></p><p>网易数帆认为，复杂系统的稳定性应当不断主动改进，而这个改进思路就是“发现问题-&gt;分析整改-&gt;将沉淀经验加入检查避免同类问题-&gt;发现新问题”这样不断进行的“稳定性改进循环”。知识引擎可以根据企业情况不断进行经验沉淀和规则迭代的平台，而巡检系统相当于稳定性检查执行工具，从而辅助用户建立这样的“稳定性改进循环”。</p><p></p><p>在高可用层面，网易数帆在支撑业务“两地三中心”部署架构解决方案的基础上，通过轻舟微服务提供资源感知、区域路由、增强多中心应用监控等产品化能力，通过轻舟中间件提供数据复制、集群联邦等产品化能力，并在此基础上结合API网关流量调度、多活管控服务等能力，新推出异地多活解决方案，帮助客户业务进行多活改造。</p><p></p><h2>低代码演进：构建超1000复杂应用，开发效率提升100%</h2><p></p><p></p><p>对于轻舟低代码平台，网易数帆希望它能成为企业信息化建设的通用平台工具，从而使企业不会迷失在形形色色的工具之中。基于此，网易数帆轻舟低代码平台的演进主要聚焦复杂应用开发能力、开发效率和易用性等三个方面。</p><p></p><p>陈谔介绍，轻舟低代码平台目前能够构建超1000个业务逻辑函数的复杂应用而用户体验不妥协，并实现100%的开发效率提升，同时成本降低超60%。从普及程度来说，过去一年，轻舟低代码的开发者已在全国13省市开发了200多个企业级应用。</p><p></p><p>在这背后，网易数帆为轻舟低代码加入了多项有特色的新特性，包括支持源码导出、客制化、多人协作等。轻舟低代码独门的NASL，支持将应用乃至前后端编译成通用编程语言，这意味着低代码应用可脱离平台独立部署，无缝衔接企业软件生产运维体系，从而解决了企业低代码应用开发面临的网络隔离、安全性要求严格、代码合规等挑战。</p><p></p><p>客制化能力不仅支持低代码组件、逻辑、API协议通过传统语言进行扩展开发，还可以将企业原有SDK复用到低代码应用中。这对于企业定制自有组件、沉淀具有行业特性的IT资产而言非常实用。在陈谔的现场演示中，轻舟低代码对客户需求的还原能力趋近100%。</p><p></p><p>多人协作则是当前企业通过任务分解的方式应对高复杂度业务开发的有效途径，轻舟低代码带来的研发效能提升，也从这一特性中受益匪浅。</p><p></p><h2>软件研发新模式：资产即生产力</h2><p></p><p></p><p>为帮助企业加速业务创新，利用数字化软件系统快速应对市场变化、提质增效，网易数帆提出了一个新的软件生产力模型，这一模型与Gartner此前提出的可组装业务能力（PBC）及经典的DDD（领域驱动设计）理论一脉相承。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/53/53ca8ecee50020131bf38a1dd88b247d.png\" /></p><p>网易数帆软件生产力模型</p><p></p><p>组装式架构能够让业务更快速在生产环境运行起来，避免重复建设，提高资产复用比，并且生产方式更标准化，变更更安全可靠。凭借在云原生和低代码领域的深厚积累，网易数帆打造了以资产为中心的软件生产力解决方案，让这一方法论得以在企业落地。</p><p></p><p>陈谔介绍，这一方案帮助企业基于内部服务沉淀标准化的原子服务与数据（如API、服务、流程、数据等），可以通过统一集成平台的集成和编排等能力，将其合成可组装的业务能力（PBC），也可以通过低代码平台形成可复用的低代码资产。这些资产将在软件资产中心统一管理和运营（包括资产认证、安全合规验证、资产入驻、访问控制和运营统计等），专业开发人员和低代码开发者都基于可复用的资产，快速组装和交付数字化业务。同时，强大的云原生底座为业务运行保驾护航，提供架构治理、研发流程管理、服务治理和运维保障等能力支撑。</p><p></p><p>陈谔介绍了一个DevOps资产包的实践案例。在该案例中，网易数帆基于DevOps基础服务沉淀DevOps资产包，包括112个UI组件、12个集成页面、169个API和128个页面模板，采用组装式开发思想，借助轻舟低代码平台为企业快速组装了一个客制化的DevOps平台。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/77/77521af8d441a69b376b8920c2d62537.png\" /></p><p>DevOps资产包实践案例</p><p></p><p>从中可见，在软件生产力模型下，IT资产的丰富度意味着业务创新的速度，而行业资产的沉淀，必将使得整个行业具备更为成熟的数字化水平。</p><p></p><p>陈谔表示，未来，网易数帆在云原生、低代码产品持续演进的同时，也将不断完善这一方法论和工具平台，让数字化业务的构建不再受限于专业开发资源，让行业创新不再有技术门槛。</p>",
    "publish_time": "2022-09-26 10:06:23",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]