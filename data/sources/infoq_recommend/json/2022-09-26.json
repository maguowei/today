[
  {
    "title": "Java近期新闻：Helidon Níma、Spring Framework、MicroProfile、MicroStream、Kotlin和Piranha",
    "url": "https://www.infoq.cn/article/d9jp2N9XlIiCbfgWpd9P",
    "summary": "<p>本期的Java新闻包括JDK 19、JDK 20、Spring框架的更新、Spring Cloud与Spring Tools、Helidon Níma、MicroProfile Reactive规范、Quarkus 2.12.2、MicroStream 7.1.0、Reactor项目2022.0.0-M6、Hibernate Search 6.1.7、JHipster Lite 0.15.1、Piranha Cloud 22.9.0、Kotlin 1.7.20-RC和Apache Tika 1.28.5。</p><p></p><h4>JDK 19</h4><p></p><p><a href=\"https://openjdk.org/projects/jdk/19/\">JDK 19</a>\"已经于2022年9月20日正式发布。<a href=\"https://jdk.java.net/19/release-notes\">发布说明</a>\"包含了文档的链接，比如<a href=\"https://cr.openjdk.java.net/~iris/se/19/latestSpec//api/index.html\">完整的API规范</a>\"以及一个<a href=\"https://cr.openjdk.java.net/~iris/se/19/latestSpec/apidiffs/overview-summary.html\">标注的API规范</a>\"，后者对比了JDK 18（<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-18%2B36\">Build 36</a>\"）和JDK 19（<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-19%2B36\">Build 36</a>\"）的差异。关于JDK 19的更多细节和对JDK 20的预测可以参阅InfoQ的<a href=\"https://www.infoq.com/news/2022/09/java-19-so-far/\">新闻报道</a>\"。</p><p></p><h4>JDK 20</h4><p></p><p>JDK 20的<a href=\"https://jdk.java.net/20/\">早期访问构建</a>\"版本<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-20%2B15\">Build 15</a>\"发布，它是对Build 14的<a href=\"https://github.com/openjdk/jdk/compare/jdk-20%2B14...jdk-20%2B15\">更新</a>\"，包括对各种[问题](https://bugs.openjdk.org/issues/?jql=project %3D JDK AND fixversion %3D 20 and \"resolved in build\" %3D b15 order by component%2C subcomponent)的修复。关于该版本的更多细节，请参阅<a href=\"https://jdk.java.net/20/release-notes\">发布说明</a>\"。</p><p></p><p>对于<a href=\"https://openjdk.java.net/projects/jdk/19/\">JDK 19</a>\"和<a href=\"https://openjdk.java.net/projects/jdk/20/\">JDK 20</a>\"，鼓励开发者通过<a href=\"https://bugreport.java.com/bugreport/\">Java Bug数据库</a>\"报告缺陷。</p><p></p><h4>Spring框架</h4><p></p><p>Spring框架向Java社区<a href=\"https://spring.io/blog/2022/09/15/spring-framework-6-0-0-m6-and-5-3-23-available-now\">发布了</a>\"6.0.0-M6和5.3.23版本版本。这两个版本都提供了新特性、缺陷修复和依赖升级。5.3.23版本引入的新特性是<a href=\"https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/core/annotation/AnnotationUtils.html\">AnnotationUtils</a>\"类中定义的**isSynthesizedAnnotation()方法，它能够让开发人员放弃已废弃的<a href=\"https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/core/annotation/SynthesizedAnnotation.html\">SynthesizedAnnotation</a>\"接口。6.0.0-M6版本定义了七个废弃的功能，并且将会移除两个之前定义的废弃功能，其中包括SynthesizedAnnotation**接口。关于这两个版本的更多细节可以参阅<a href=\"https://github.com/spring-projects/spring-framework/releases/tag/v5.3.22\">5.3.23</a>\"和<a href=\"https://github.com/spring-projects/spring-framework/releases/tag/v6.0.0-M6\">6.0.0-M6</a>\"版本的发布说明。</p><p></p><p>Spring Cloud Dataflow 2.9.6<a href=\"https://spring.io/blog/2022/09/14/spring-cloud-dataflow-2-9-6-released\">发布</a>\"，特性包括升级PostgreSQL驱动版本至42.2.26以解决CVE-2022-31197漏洞，即<a href=\"https://github.com/advisories/GHSA-r38f-c4h4-hqq2\">通过恶意的列名能够在ResultSet.refreshRow()中触发PostgreSQL JDBC驱动的SQL注入</a>\"，该漏洞是由于**ResultSet类中refreshRow()**方法的实现没有正确的转义列名，所以包含语句终结符（比如分号）的恶意列名会导致SQL注入。关于该版本的更多细节可以参阅<a href=\"https://github.com/spring-cloud/spring-cloud-dataflow/releases/tag/v2.9.6\">发布说明</a>\"。</p><p></p><p><a href=\"https://github.com/spring-projects-experimental/spring-cloud-sleuth-otel/blob/main/README.adoc\">Spring Cloud Sleuth OpenTelemetry</a>\" 1.1.0版本<a href=\"https://spring.io/blog/2022/09/16/spring-cloud-sleuth-opentelemetry-otel-1-1-0-has-been-released\">发布</a>\"，这是<a href=\"https://spring.io/projects/spring-cloud-sleuth\">Spring Cloud Sleuth</a>\"的一个实验性扩展，其中包括了对Spring Cloud 2021.0.4和OpenTelemetry 1.18.0的依赖升级。关于该版本的更多信息请参阅<a href=\"https://github.com/spring-projects-experimental/spring-cloud-sleuth-otel/releases/tag/v1.1.0\">发布说明</a>\"。</p><p></p><p>Spring Tools 4.16.0<a href=\"https://spring.io/blog/2022/09/16/spring-tools-4-16-0-released\">发布</a>\"，特性包括：支持<a href=\"https://eclipseide.org/\">Eclipse 2022-09</a>\"；适用于ARM上Linux环境的实验性发行版；更新<a href=\"https://www.eclipse.org/m2e/\">M2Eclipse</a>\"（m2e）2.0.5。关于该版本的更多细节，可以参阅<a href=\"https://github.com/spring-projects/sts4/wiki/Changelog#2022-09-16-4160-release-incl-language-servers-version-1390\">变更日志</a>\"。</p><p></p><h4>Helidon</h4><p></p><p>甲骨文<a href=\"https://medium.com/helidon/please-welcome-helidon-n%C3%ADma-9a882c5b6f1e\">引入了</a>\" Helidon Níma，这是一个基于虚拟线程的微服务框架，它提供了一个低开销、高并发的服务器，同时保持了阻塞式的线程模型。在<a href=\"https://helidon.io/\">Helidon项目</a>\"的协助下，这个新的框架随Helidon 4.0.0发布了<a href=\"https://medium.com/helidon/helidon-n%C3%ADma-helidon-on-virtual-threads-130bb2ea2088\">第一个alpha版本</a>\"，但是Java社区需要2023年底才能等到正式的GA版本。关于Helidon Níma的更多细节，可以参阅InfoQ的<a href=\"https://www.infoq.com/news/2022/09/introducing-helidon-nima/\">新闻报道</a>\"。</p><p></p><h4>MicroProfile</h4><p></p><p>在通往<a href=\"https://microprofile.io/\">MicroProfile</a>\" 6.0的路上（计划2022年10月发布），<a href=\"https://github.com/eclipse/microprofile-reactive-streams-operators/releases/tag/3.0\">Reactive Streams Operators 3.0</a>\"和<a href=\"https://github.com/eclipse/microprofile-reactive-messaging/releases/tag/3.0\">Reactive Messaging 3.0</a>\"规范向Java社区发布，其特性与Jakarta EE 9.1保持了一致。</p><p></p><h4>Quarkus</h4><p></p><p>Red Hat<a href=\"https://quarkus.io/blog/quarkus-2-12-2-final-released/\">发布</a>\"了Quarkus 2.12.2.Final，包括了SnakeYAML 1.3.2、Hibernate Validator 6.2.5.Final和JBoss Threads 3.4.3.Final的依赖升级。关于该版本的更多细节可以参阅<a href=\"https://github.com/quarkusio/quarkus/releases/tag/2.12.2.Final\">变更日志</a>\"。</p><p></p><h4>MicroStream</h4><p></p><p>MicroStreams<a href=\"https://microstream.one/blog/article/release-of-microstream-version-7-1/\">发布</a>\"了其7.1.0版本的对象-图持久化框架，特性包括：集成Spring Boot；改善与CDI和MicroProfile Config运行时的集成；改进了数据通道的垃圾收集。此外，他们还开源了所有的连接器，现在包括Oracle和SAP HANA数据库、 Cloud存储（AWS S3、Azure Storage、Google Firestore、Oracle Object Storage）以及其他资源（Hazelcast、Kafka、Redis、DynamoDB、Oracle Coherence）。关于该版本的更多信息请参阅<a href=\"https://github.com/microstream-one/microstream/releases/tag/07.01.00-MS-GA\">发布说明</a>\"。</p><p></p><h4>Reactor项目</h4><p></p><p>在通往<a href=\"https://github.com/reactor/reactor/blob/main/README.md\">Reactor项目</a>\"2022.0.0的路上，<a href=\"https://github.com/reactor/reactor/releases/tag/2022.0.0-M6\">第六个历程碑版本</a>\"发布，其特性是对**reactor-core** 3.5.0-M6和**reactor-netty** 1.1.0-M6制品的依赖升级。此外，还对第六个里程碑版本进行了调整，reactor-pool 1.0.0-M6、reactor-addons 3.5.0-M6和**reactor-kotlin-extensions** 1.2.0-M6这些制品保持不变。</p><p></p><h4>Hibernate</h4><p></p><p><a href=\"https://hibernate.org/search/\">Hibernate Search</a>\" 6.1.7.Final发布，它将依赖升级到了Hibernate ORM 5.6.11.Final；将所有包含**-orm6**名称的制品与Hibernate ORM的依赖保持一致；以及Java模块相关缺陷的修复。</p><p></p><h4>JHipster Lite</h4><p></p><p><a href=\"https://github.com/jhipster/jhipster-lite/blob/main/README.md\">JHipster Lite</a>\"的0.15.0和0.15.1版本<a href=\"https://twitter.com/pascalgrimaud/status/1570138502850920448\">发布</a>\"，它是JHipster的启动项目，包含许多功能增强、错误修复、依赖性升级和重构。关于这个版本的更多细节可以在<a href=\"https://github.com/jhipster/jhipster-lite/releases/tag/v0.15.0\">0.15.0</a>\"和<a href=\"https://github.com/jhipster/jhipster-lite/releases/tag/v0.15.1\">0.15.1</a>\"版本的发布说明中找到。</p><p></p><h4>Piranha</h4><p></p><p>Piranha 22.9.0<a href=\"https://github.com/piranhacloud/piranha/releases/tag/v22.9.0\">发布</a>\"。这个新版本被称为2022年9月的“Core Profile just landed”版本，其特性包括：支持通过<a href=\"https://github.com/piranhacloud/piranha/issues/2775\">Piranha Core Profile</a>\"引入Jakarta EE Core Profile；以及对<a href=\"https://jakarta.ee/specifications/transactions/2.0/\">Jakarta Transactions</a>\"和<a href=\"https://jakarta.ee/specifications/persistence/3.1/\">Jakarta Persistence</a>\"规范的初始支持。关于这个版本的更多细节可以在他们的<a href=\"https://javadoc.io/doc/cloud.piranha/project/latest/index.html\">文档</a>\"和<a href=\"https://github.com/piranhacloud/piranha/issues?q=is%3Aissue+-label%3Awontfix+milestone%3A22.9.0+is%3Aclosed\">问题跟踪页面</a>\"中找到。</p><p></p><h4>Kotlin</h4><p></p><p>KotlinJetBrains<a href=\"https://blog.jetbrains.com/kotlin/2022/09/kotlin-news-august/\">发布了</a>\"Kotlin 1.7.20-RC，其特性包括：支持多个新的<a href=\"https://kotlinlang.org/docs/whatsnew-eap.html#support-for-kotlin-k2-compiler-plugins\">插件</a>\"；预览用于开闭式范围的**..&lt;**操作符；默认启用Kotlin/Native内存管理器；以及增加具有通用底层类型的内联类，这是一个实验性功能。</p><p></p><h4>Apache软件基金会</h4><p></p><p>Apache Tika 1.28.5<a href=\"https://www.mail-archive.com/announce@apache.org/msg07572.html\">发布</a>\"，其特性包括：安全问题修复；修复从PDF中提取书签时出现无限循环的问题；以及依赖性升级。该版本的详细信息可以在<a href=\"https://downloads.apache.org/tika/1.28.5/CHANGES-1.28.5.txt\">更新日志</a>\"中找到。1.x版本的发布列车将在2022年9月30日结束生命周期。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/09/java-news-roundup-sep12-2022/\">Java News Roundup: Helidon Níma, Spring Framework, MicroProfile, MicroStream, Kotlin, Piranha</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/pQ7VDmaij1aCT9TD0R06\">在 Java 中如何加快大型集合的处理速度</a>\"</p><p><a href=\"https://www.infoq.cn/article/3IgHpkRJIsFXm0vPNvFc\">甲骨文新微服务框架Helidon Níma：使用虚拟线程实现高性能</a>\"</p>",
    "publish_time": "2022-09-26 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "不要指望下一个像GPT这样的大型语言模型会民主化",
    "url": "https://www.infoq.cn/article/UrFKiffb44jcffwP5FbH",
    "summary": "<p></p><blockquote>5月初，Meta公司发布了Open Pretrained Transformer（OPT-175B），这是一个可以执行各种任务的大型语言模型（LLM）。在过去几年中，大型语言模型已经成为人工智能研究最热门的领域之一。</blockquote><p></p><p></p><p>本文最初发布于TeckTalks。</p><p></p><p><a href=\"https://www.infoq.cn/article/4iDmM3PgXmvELorwQ8M3\">OPT-175B</a>\"是由OpenAI的<a href=\"https://www.infoq.cn/article/Z46h9vTIL3dBx5Z3hAjO\">GPT-3</a>\"引发的LLM军备竞赛的最新参与者。GPT-3是一种具有1750亿个参数的深度神经网络。GPT-3表明，LLM可以在没有任何额外训练以及只学习几个样本（零样本或小样本学习）的情况下完成许多任务。微软后来将GPT-3集成到了它的几个产品中，不仅展示了LLM在科学研究上的前景，也展示了其在商业应用上的前景。</p><p></p><p>让OPT-175B与众不同的是Meta对“开放性”的承诺，正如模型的名字所暗示的那样。Meta已经向公众提供了这个模型（以及一些注意事项），它还公布了大量关于训练和开发过程的细节。在Meta AI博客上发表的一篇文章中，该公司将OPT-175B的发布描述为“大规模语言模型的民主化访问”。</p><p></p><p>Meta朝着透明的方向发展值得称赞。然而，大型语言模型的竞争已经达到了无法再民主化的地步。</p><p></p><h2>关于该大型语言模型的几个细节</h2><p></p><p></p><p>Meta发布的OPT-175B有一些关键特性，包括预训练的模型以及训练和使用LLM所需的代码。对于没有计算资源用于训练模型的组织，预训练模型特别有用（训练神经网络比运行它们消耗的资源更多）。它有助于减少训练大型神经网络所需的计算资源所造成的巨大碳排放量。</p><p></p><p>与<a href=\"https://www.infoq.cn/article/w1lxxO4qtaVPxZUdqzwi\">GPT-3</a>\"一样，OPT也有不同的大小，参数从1.25亿到1750亿不等（参数越多模型学习能力越强）。在撰写本文时，OPT-30B以下的所有模型都已提供下载。拥有全部1750亿个参数的模型将仅提供给被选中的研究人员和机构（他们需要填写一张申请表）。</p><p></p><p>根据Meta AI博客，“为了保持完整性和防止滥用，我们将在非商业许可下发布我们的模型，专注于研究用例。该模型将授权给学术研究人员，与政府、民间团体和学术机构有关的组织，以及世界各地的行业研究实验室。”</p><p></p><p>除了模型，Meta还发布了一份完整的日志，提供了关于该大型语言模型开发和训练过程的详细的技术时间线。通常，发表的论文只包含最终模型的信息。Meta表示，该日志提供了一些有价值的信息，包括“用于训练OPT-175B的计算资源的数量，以及当底层基础设施或训练过程本身因为规模太大而变得不稳定时所需的人力开销。”</p><p></p><h2>与GPT-3比较</h2><p></p><p></p><p>Meta公司在其博文中指出，大型语言模型大多是通过“付费API”访问的，对LLM的限制性访问“限制了研究人员了解这些大型语言模型如何工作以及为何有效的能力，妨碍了他们提高模型鲁棒性以及缓解偏见和数据中毒等已知的问题”。</p><p></p><p>这对于OpenAI（以及微软的独家GPT-3许可）无疑是一记重击，后者将GPT-3作为黑盒API服务发布，而不是将其模型权重和源代码公开。OpenAI没有公开GPT-3的原因之一是控制有害应用程序的滥用和开发。</p><p></p><p>Meta相信，把模型提供给更广泛的受众，他们将可以更好地研究和预防它们可能造成的任何伤害。</p><p></p><p>Meta是这样描述这项工作的：“我们希望，OPT-175B将为大型语言模型创建前沿带来更多的声音，帮助社区共同设计负责任的发布策略，并为该领域大型语言模型的开发增加前所未有的透明度和开放性。”</p><p></p><h2>大型语言模型的成本</h2><p></p><p></p><p>然而，值得注意的是，“透明和开放”并不等同于“民主化大型语言模型”。训练、配置和运行大型语言模型的成本仍然很高，而且未来可能还会增长。</p><p></p><p>根据Meta的博文，模型的研究人员已经大幅降低了训练大型语言模型的成本。该公司表示，这个模型的碳排放量已减少到GPT-3的七分之一。据我之前采访过的专家估计，GPT-3的训练成本高达2760万美元。</p><p></p><p>这意味着，OPT-175B的训练成本仍将高达数百万美元。幸运的是，预训练的模型可以避免模型训练过程，并且Meta表示，他们将提供“只使用16块NVIDIA V100 GPU”就可以完成整个模型训练和部署的代码库。这相当于一台英伟达（Nvidia）DGX-2，成本约为40万美元。对于资金紧张的研究实验室或个体研究人员来说，这不是一个小数目。(根据一篇提供了更多OPT-175B细节的论文，Meta使用992块A100 80GB GPU训练了自己的模型，这款GPU明显比V100快。)</p><p></p><p>Meta AI的日志进一步证实，训练大型语言模型是一项非常复杂的任务。OPT-175B的时间线上到处都是服务器崩溃、硬件故障和其他需要高级技术人员才能解决的并发症。研究人员还不得不多次重启训练过程，调整超参数，修改损失函数。所有这些都会产生小型实验室无法承担的额外费用。</p><p></p><h2>大型语言模型的未来</h2><p></p><p></p><p>语言模型如OPT和GPT都是基于转换器架构的。转换器的关键特性之一是它们能够大规模地并行处理海量时序数据（如文本）。</p><p></p><p>近年来，研究人员已经证明，增加转换器模型的层数和参数，可以提高它们在语言任务上的性能。一些研究人员认为，达到更高的智能水平只是一个规模问题。因此，像Meta AI、DeepMind（由Alphabet拥有）和OpenAI（由微软支持）这样现金充足的研究实验室正在朝着创建越来越大的神经网络前进。</p><p></p><p></p><blockquote>某人的观点文章。我的看法是：现在都是规模问题了！游戏结束了！现在只要让这些模型更大、更安全、计算效率更高、采样更快、记忆更智能、模式更多样、数据更有创新性，无论在线还是离线......1/N <a href=\"https://t.co/UJxSLZGc71?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjM4MTUxNzMsImZpbGVHVUlEIjoiR1E5NVBaWE55VEVjbGlYdSIsImlhdCI6MTY2MzgxNDg3MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyNTY1MTE5Nn0.Nskx-jA73oq2h4Mm1yBBSTg5klykj1PGjBvHJVLq0Hc\">https://t.co/UJxSLZGc71</a>\"—— Nando de Freitas（@NandoDF）</blockquote><p></p><p></p><p>去年，微软和英伟达创建了一个有5300亿个参数的语言模型，名为Megatron-Turing （MT-NLG）。上个月，谷歌推出了路径语言模型（PaLM）。这是一个有5400亿个参数的LLM。有传言称，OpenAI将在未来几个月发布GPT-4。</p><p></p><p>然而，神经网络越大需要的财政和技术资源也越多。虽然更大的语言模型会带来新的东西（和新的问题），但不可避免地，它们将把权力集中在少数富有的公司手中，使得较小的研究实验室和独立的研究人员更难研究大型语言模型了。</p><p></p><p>在商业方面，大型科技公司将拥有更大的优势。运行大型语言模型是非常昂贵和具有挑战性的。像谷歌和微软这样的公司有特殊的服务器和处理器，他们能够大规模运行这些模型并从中获利。对于比较小的公司来说，运行自己的LLM（如GPT-3）版本开销太大了。正如大多数企业使用云托管服务，而不是构建自己的服务器和数据中心一样，随着大型语言模型变得越来越流行，像GPT-3 API这样的开箱即用系统将越来越有吸引力。</p><p></p><p>这反过来又会使人工智能进一步集中在大型科技公司的手中。越来越多的人工智能研究实验室将不得不与大型科技公司建立合作伙伴关系，以获得资助。而这将使大型科技公司有更多的权力来决定人工智能研究的未来方向（这可能会与他们的经济利益相一致）。这可能要以那些短期内无法产生投资回报的研究领域为代价。</p><p></p><p>最后，当我们庆祝Meta为LLM带来透明度的时候，请不要忘记，大型语言模型本质上就是不民主的，而是有利于推广它们的公司。</p><p></p><p>英文原文：<a href=\"https://bdtechtalks.com/2022/05/16/opt-175b-large-language-models?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjM4MTUxNzMsImZpbGVHVUlEIjoiR1E5NVBaWE55VEVjbGlYdSIsImlhdCI6MTY2MzgxNDg3MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyNTY1MTE5Nn0.Nskx-jA73oq2h4Mm1yBBSTg5klykj1PGjBvHJVLq0Hc\">Can large language models be democratized?</a>\"</p>",
    "publish_time": "2022-09-26 08:20:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]