[
  {
    "title": "Uber 如何实现 Go 代码中的动态数据竞争检测",
    "url": "https://www.infoq.cn/article/S4QqJIDa40dwg9WUlNdH",
    "summary": "<p></p><blockquote>本文是Uber在Go代码中数据竞争经验两篇文章中的第一篇。详细版本将在 2022 年 ACM SIGPLAN 编程语言设计与实现（Programming Languages Design and Implementation，PLDI）中发表。在本文系列的第二部分，我们将介绍关于 Go 中竞争模式的学习。</blockquote><p></p><p></p><p>Uber 已将 Go 作为主要编程语言，广泛用于开发微服务。我们的 Go 单体仓库由大约 5000 万行代码组成，包含大约 2100 个独特的 Go 服务。Go 使并发性成为一流公民；在函数调用前加上 go 关键字，就会异步运行调用。在 Go 中，这些异步函数调用被称作 goroutines。开发人员通过在单个运行的 Go 程序中创建 goroutines，从而隐藏了延迟（例如，对其他服务的 IO 或 RPC 调用）。goroutines 被认为是 “轻量级的”，Go 的运行时上下文在操作系统（OS）线程上切换它们。Go 程序员经常随意使用 goroutines。两个或多个 goroutines 可以通过消息传递（通道）或共享内存进行数据通信。共享内存恰好是 Go 中最常用的数据通信方式。</p><p></p><p>在 Go 中，如果两个或更多的 goroutines 访问同一个内存地址时，那么至少有一块是写入的，而且它们之间没有排序，这就是 Go 内存模型所定义的数据竞争。在我们的微服务中，由于数据竞争而导致的 Go 程序的中断是一个反复出现的、令人头疼的问题。由于上述问题，我们关键的、面向客户的服务总共瘫痪了数个小时，造成客户的不便，也影响了我们的收益。在本文中，我们将会讨论 Go 的一个默认动态竞争检测器，它将会在 Go 的开发环境中不断检测数据竞争。这一部署实现了对 2000 多个竞争的检测，使两百多名工程师修复了约 1000 个数据竞争。</p><p></p><p></p><h2>动态检测数据竞争</h2><p></p><p></p><p>动态竞争检测包括通过检测共享内存访问和同步构造来分析程序的执行。在 Go 中进行单元测试，生成多个 goroutine，这是一个很好的开始，可以进行动态竞争检测。Go 有一个内置的竞争检测器，可以用来在编译时检测代码，以及检测执行过程中的数据竞争。在内部，Go 的竞争检测器采用了 ThreadSanitizer 运行时库，通过结合锁集和基于之前的算法来报告数据竞争。</p><p></p><p>与动态竞争检测相关的重要属性如下：</p><p></p><p>由于动态竞争检测依赖于分析的执行，所以不会报告源代码中的所有竞争。检测到的竞争集依赖于线程交错，甚至程序的输入没有变化，但会在多次运行中发生变化。</p><p></p><h2>何时部署动态数据竞争检测器？</h2><p></p><p></p><p>我们在仓库中使用了超过 10 万个 Go 单元测试来执行代码和检测数据竞争。然而，我们面临着一个具有挑战性的问题，即何时部署竞争检测器。</p><p></p><p>在拉取请求（pull request，PR）时，运行动态数据竞争检测器存在以下问题：</p><p></p><p>竞争检测具有不确定性。这样，拉取请求所引起的竞争可能不会被曝光，并且可能不会被检测到。这种行为的后果是，随后的良性拉取请求可能会受到检测到的休眠竞争的影响，从而被错误地阻止，进而影响开发人员的生产力。此外，由于在我们 5000 万行的代码库中存在预先存在的数据竞争，这也是一件不可能的事情。动态数据竞争检测器占用的空间是 2~20 倍，内存开销是 5~10 倍，这可能导致违反我们的 SLA，或者增加硬件成本。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bf/bfb5ba570d13e4e58662a2f544d13af3.jpeg\" /></p><p>图 1：动态竞争检测工作流的架构</p><p></p><p></p><p>基于这些考虑，我们决定在事后定期在代码快照上部署竞争检测器，这包括以下步骤：</p><p></p><p>(a) 通过执行仓库中的所有单元测试来进行动态竞争检测。</p><p>(b) 通过向适当的 bug 所有者提交任务来报告所有未解决的竞争。</p><p></p><p>一个检测到的竞争报告包含以下细节：</p><p></p><p>冲突的内存地址。2 个冲突访问的调用链（又称调用上下文或堆栈跟踪）。与每个访问相关的内存访问类型（读取或写入）。</p><p></p><p>我们解决了几个问题，通过对报告的堆栈竞争进行散列，并应用启发式方法来确定负责修复该错误的潜在开发人员，这样就可以避免重复的竞争。尽管我们已经选定了这种部署路径，但是，如果所检测到的竞争不会妨碍构建，并作为警告通知开发人员，或者对动态竞争检测进行了改善，使得 CI 时间的确定性检测是可行的，那么 CI 时间的部署是可以实现的。</p><p></p><h2>部署的效果</h2><p></p><p></p><p>我们在 2021 年 4 月推出了这一部署，并在 6 个月里收集数据。我们的方法帮助检测了单体仓库中的 2000 个数据竞争，每天有数百名 Go 开发人员提交的数据。在报告的 2000 个竞争中，有 1011 个竞争被 210 个不同的工程师修复。我们观察到，有 790 个独特的补丁来修复这些竞争，这表明了独特的根源数量。我们还收集了 6 个多月期间未解决的故障总数的统计数据，并将其报告如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/35/35dc0b58ef2ddbc23ecf92987f1f348b.jpeg\" /></p><p>图 2：6 个月内未解决的数据竞争的数量（2021 年 4 月~2021 年 9 月）</p><p></p><p></p><p>在推出的初始阶段（2~3 个月），我们向受让方提供了关于解决数据竞争问题的建议。在这一阶段，未解决的竞争已经出现了明显的减少。后来，随着指导工作的减少，我们注意到，未解决的竞争总数在逐渐增加。该图还表明，未解决的竞争数的波动，这是由于对竞争的修复、新竞争的引入、开发人员对测试的启用和禁用，以及动态竞争检测的基本非确定性。在报告了所有预先存在的竞争后，我们还观察到，工作流平均每天会创建大约 5 个新的竞争报告。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/37/37caefe7eaae2a58a95cc0d36fbe088b.jpeg\" /></p><p>图 3：提交和修复的 Jira 任务的数量说明</p><p></p><p>就运行我们的离线数据竞争检测器的开销而言，我们注意到，在没有数据竞争检测的情况下，在所有的测试中，95% 的运行时间是 25 分钟，而在启用数据竞争之后，增加了 4 倍，达到约 100 分钟。在数十名工程师的调查中，大约在推出该系统 6 个月后，52% 的开发人员认为该系统有用，40% 的人没有参与该系统，8% 的人认为该系统没有用。</p><p></p><h2>展望未来</h2><p></p><p></p><p>我们在这次部署中的经验表明有以下进展：</p><p></p><p>需要建立可在持续集成（CI）期间部署的动态竞争检测器。这需要新的检测器有效解决由于非确定性和开销带来的挑战。在这之前，设计算法为检测到的数据竞争寻找根源并确定适当的拥有者，有助于加速数据竞争的修复。我们已经确定了与 Go 中的数据竞争有关的基本编码模式（在本博客系列的第二部分中将会介绍），而 CI 时间的静态分析检测可能会捕捉到其中一个子集。所检测的竞争集依赖于输入的测试套件。能够在其他类型的测试（除单元测试外）上运行竞争检测，如集成测试、端到端测试、黑盒测试，甚至生产跟踪，都能帮助检测更多的竞争。我们还认为，对输入测试套件的时间表进行模糊处理的程序分析工具可以暴露出线程交错，从而增强检测到的竞争集。最后，目前的方法依赖于通过单元测试的多线程执行的可用性，而手动构建此类测试时，不一定能考虑到所有可能的情况。自动生成多线程执行，其中包含 racy 行为，并且利用检测器来验证竞争，这是一种高效的调试工具。</p><p></p><p>作者介绍：</p><p></p><p>Murali Krishna Ramanathan 是一名高级软件工程师，负责 Uber 工程的多项代码质量计划。他是 Piranha 的架构师，Piranha 是一个重构工具，可以自动删除因特性标记过期而导致的代码。他的兴趣是开发工具来解决软件开发的挑战，包括特性标记、自动代码重构和开发人员的工作流，以及自动测试生成以提高软件质量。</p><p></p><p>Milind Chabbi 是 Uber 编程系统研究团队的一名员工研究员。他领导整个 Uber 在编译器优化、高性能并行计算、同步技术和性能分析工具方面的研究计划，使大型复杂的计算系统变得可靠和高效。</p><p></p><p>原文链接：</p><p></p><p>https://eng.uber.com/dynamic-data-race-detection-in-go-code/</p>",
    "publish_time": "2022-07-12 09:09:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Java近期新闻：Payara平台、JReleaser、Quarkus、Hibernate、Spring Cloud和Apache Beam",
    "url": "https://www.infoq.cn/article/yHdjimHkDKlM1VWpJT0B",
    "summary": "<p>最近，Java社区相对比较平静，本期的新闻包括JDK 19、JDK 20、Spring Cloud 2020.0.6、Quarkus 2.10.1、Payara平台企业版5.40.0、JReleaser 1.1.0、Hibernate ORM 6.1.1、Apache Beam 2.40.0和Apache Camel 3.14.4。</p><p></p><h3>JDK 19</h3><p></p><p>JDK 19<a href=\"https://jdk.java.net/19/\">早期访问构建</a>\"版本的<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-19%2B29\">Build 29</a>\"发布，该版本是对Build 28的<a href=\"https://github.com/openjdk/jdk/compare/jdk-19%2B28...jdk-19%2B29\">更新</a>\"，包括对<a href=\"https://bugs.openjdk.java.net/issues/?jql=project%20%3D%20JDK%20AND%20fixversion%20%3D%2019%20and%20%22resolved%20in%20build%22%20%3D%20b29%20order%20by%20component%2C%20subcomponent\">各种问题</a>\"的修复。更多细节可以在<a href=\"https://jdk.java.net/19/release-notes\">发布说明</a>\"中找到。</p><p></p><h3>JDK 20</h3><p></p><p>JDK 20<a href=\"https://jdk.java.net/20/\">早期访问构建</a>\"版本的<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-20%2B4\">Build 4</a>\"发布，它是对Build 3的<a href=\"https://github.com/openjdk/jdk/compare/jdk-20%2B3...jdk-20%2B4\">更新</a>\"，包括对各种<a href=\"https://bugs.openjdk.java.net/issues/?jql=project%20%3D%20JDK%20AND%20fixversion%20%3D%2020%20and%20%22resolved%20in%20build%22%20%3D%20b04%20order%20by%20component%2C%20subcomponent\">问题</a>\"的修复。目前它还没有发布说明。</p><p></p><p>对于<a href=\"https://openjdk.java.net/projects/jdk/19/\">JDK 19</a>\"和<a href=\"https://openjdk.java.net/projects/jdk/20/\">JDK 20</a>\"，鼓励开发者通过<a href=\"https://bugreport.java.com/bugreport/\">Java Bug数据库</a>\"报告缺陷。</p><p></p><h3>Spring框架</h3><p></p><p><a href=\"https://spring.io/projects/spring-cloud\">Spring Cloud</a>\"&nbsp;2020.0.6版本<a href=\"https://spring.io/blog/2022/06/30/spring-cloud-2020-0-6-is-available\">发布</a>\"，它为所有Spring Cloud子项目提供了缺陷修复和升级，特别是<a href=\"https://spring.io/projects/spring-cloud-commons\">Spring Cloud Commons</a>\"、<a href=\"https://spring.io/projects/spring-cloud-openfeign\">Spring Cloud OpenFeign</a>\"和<a href=\"https://spring.io/projects/spring-cloud-netflix\">Spring Cloud Netflix</a>\"。该版本还修复了之前2021.0各版本所发现的问题。关于这个版本的更多细节，可以在<a href=\"https://github.com/spring-cloud/spring-cloud-release/wiki/Spring-Cloud-2020.0-Release-Notes\">发布说明</a>\"中找到。</p><p></p><h3>Quarkus</h3><p></p><p>在Quarkus 2.10.0<a href=\"https://quarkus.io/blog/quarkus-2-10-0-final-released/\">发布</a>\"一周后，Red Hat提供了一个<a href=\"https://quarkus.io/blog/quarkus-2-10-1-final-released/\">维护版本</a>\"，即Quarkus 2.10.1.Final，其中包括缺陷修复、文档改进以及依赖升级，如SmallRye Fault Tolerance 5.4.1、Keycloak 18.0.1、Scala Maven Plugin 4.6.3和Flyway 8.5.13。关于这个版本的更多细节，可以在<a href=\"https://github.com/quarkusio/quarkus/releases/tag/2.10.1.Final\">更新日志</a>\"中找到。</p><p></p><h3>Payara</h3><p></p><p>Payara<a href=\"https://blog.payara.fish/whats-new-in-the-june-2022-payara-platform-release\">发布</a>\"了2022年6月版的<a href=\"https://www.payara.fish/\">Payara平台</a>\"，这是一个企业专有版。Payara平台企业版5.40.0版提供了三个缺陷修复、一个组件升级和两项改进，包括对<a href=\"https://jakarta.ee/specifications/concurrency/3.0/\">Jakarta Concurrency 3.0</a>\"的增强，增加了<a href=\"https://jakarta.ee/specifications/platform/8/apidocs/javax/enterprise/concurrent/managedexecutorservice\">ManagedExectorService</a>\"接口的功能；企业版文档的改进；安全性和稳定性的提高，以及对<a href=\"https://www.igniterealtime.org/projects/smack/\">Smack</a>\"&nbsp;4.4.6的依赖性升级。这个版本还包括Payara 5企业版的向后更新。关于这个版本的更多细节可以在<a href=\"https://docs.payara.fish/enterprise/docs/Release%20Notes/Release%20Notes%205.40.0.html\">发布说明</a>\"中找到。</p><p></p><h3>JReleaser</h3><p></p><p><a href=\"https://jreleaser.org/\">JReleaser</a>\"&nbsp;1.1.0版<a href=\"https://andresalmiray.com/jreleaser-1-1-0-has-been-released/\">发布</a>\"，这是一个简化项目发布的Java工具，该版本的特性包括：在assemble、announce和download中添加active属性；下载组装或发布时所需资产的选项；HTTP认证，以及对下载和上传的FTP支持。关于这个版本的更多细节可以在<a href=\"https://github.com/jreleaser/jreleaser/releases/tag/v1.1.0\">更新日志</a>\"中找到。</p><p></p><h3>Hibernate</h3><p></p><p>Hibernate ORM 6.1.1.Final是一个<a href=\"https://in.relation.to/2022/07/01/hibernate-orm-611-final/\">维护版本</a>\"，其特性包括缺陷修复，优化了<a href=\"https://docs.jboss.org/hibernate/orm/6.1/javadocs/org/hibernate/persister/entity/AbstractEntityPersister.html\">AbstractEntityPersister</a>\"类中resolveDirtyAttributeIndexes()方法的内存占用，并解除了在使用嵌入式ID或ID类时选择对一（to-one）关联的限制。</p><p></p><h3>Apache Beam</h3><p></p><p>Apache软件基金会<a href=\"https://www.mail-archive.com/announce@apache.org/msg07409.html\">发布</a>\"了Apache Beam 2.40.0，其特性包括：针对<a href=\"https://go.dev/\">Go SDK</a>\"的新功能；对<a href=\"https://hive.apache.org/\">Apache Hive</a>\"&nbsp;3.1.3的依赖性升级；以及新的<a href=\"https://s.apache.org/inference-sklearn-pytorch\">RunInference API</a>\"，这是面向Apache Beam的机器学习推理。破坏性的变更包括最低需要Go SDK 1.18，以支持泛型。关于这个版本的更多细节可以在<a href=\"https://github.com/apache/beam/releases/tag/v2.40.0\">发布说明</a>\"中找到，关于Apache Beam的更深入介绍可以参阅InfoQ的<a href=\"https://www.infoq.com/articles/apache-beam-intro/\">技术文章</a>\"。</p><p></p><h3>Apache Camel</h3><p></p><p>Apache Camel 3.14.4<a href=\"https://camel.apache.org/blog/2022/06/RELEASE-3.14.4/\">发布</a>\"，其中包括缺陷修复、模块升级至camel-spring-boot&nbsp;2.6.8、依赖升级至<a href=\"https://jakarta.ee/specifications/mail/1.6/\">Jakarta Mail 1.6.7</a>\"，以及修正camel-karaf模块中camel-azure-storage-datalake特性的错误定义。关于这个版本的更多细节可以在<a href=\"https://camel.apache.org/releases/release-3.14.4/\">发布说明</a>\"中找到。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/07/java-news-roundup-jun27-2022/\">Java News Roundup: Payara Platform, JReleaser, Quarkus, Hibernate, Spring Cloud, Apache Beam</a>\"</p>",
    "publish_time": "2022-07-12 09:15:48",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "案例研究：Apache DolphinScheduler的云原生之路",
    "url": "https://www.infoq.cn/article/ysqf8pBg813zH7qa7ajj",
    "summary": "<p>&nbsp;</p><p><a href=\"https://dolphinscheduler.apache.org/\">DolphinScheduler</a>\"是由易观开源的一个分布式可伸缩的可视化工作流任务调度平台。</p><p>&nbsp;</p><p>在我所工作的领域，DolphinScheduler可以快速解决企业数据开发的十大痛点：</p><p>&nbsp;</p><p>多源数据连接和访问：可以访问常见的数据源，不需要进行太多的修改就可以添加新数据源；多样化、专业化、海量数据任务管理：围绕大数据（Hadoop家族、Flink等）任务调度问题展开，与传统调度器有明显的区别；图形化的任务安排：提供了便捷的用户体验，可与商业产品竞争，尤其是针对大多数国外开源产品无法通过拖放直接生成数据任务的情况；任务详情：丰富的任务查看、日志、时间运行轴显示，满足开发人员对数据任务精细化管理的需求，可帮助快速定位慢SQL和性能瓶颈；支持各种分布式文件系统：丰富了用户可选择的非结构化数据选项；原生多租户管理：满足大型组织的数据任务管理和隔离需求；全自动分布式调度算法，均衡所有调度任务；原生集群监控：可监控CPU、内存、连接数、ZooKeeper状态，适合中小型企业的一站式运维；原生任务告警功能：最大限度降低任务操作风险；强大的社区运营：倾听用户真实的声音，不断添加新功能，持续优化用户体验。</p><p>&nbsp;</p><p>DolphinScheduler以早期微服务技术为基础，采用了服务注册表的概念，使用ZooKeeper对集群进行分布式管理（很多大数据技术都使用ZooKeeper进行去中心化集群管理）。Worker主节点可以任意添加，也可以单独部署API管理和告警管理。作为企业级技术模块，它实现了微服务隔离、独立部署、模块化管理等技术特点。然而，在容器化云原生应用快速发展的时代，这种技术模式存在一些不足：</p><p>&nbsp;</p><p>需要从头部署，无论是安装在物理机器还是虚拟机器上。一个DolphinScheduler节点需要数百个shell操作，一个包含多个节点的集群可能需要数千个shell操作；标准的企业级DolphinScheduler涉及大量的基础设施环境管理，通常需要8个以上的节点、主机和IP地址。这些基础设施信息给管理带来了一定的困难；添加节点需要执行一系列操作，如安装Java、配置主机、设置DS Linux用户、设置无密码登录、修改安装节点配置文件，而且需要停止并重启整个集群；大型企业通常有多个集群用于支持不同的业务，这会造成大量的重复性工作；调度器具有一定的可观测性功能，但不能与主流工具集成；总的说来，调度器仍然需要进行日常的检查，例如诊断Java核心进程异常退出问题；对于不同需求和场景下的调度器配置，没有有效的管理机制或工具。</p><p>&nbsp;</p><p>解决这些技术缺陷的核心想法是：</p><p>&nbsp;</p><p>如何将DolphinScheduler集成到当今主流的云原生技术中；如何以较少的人力资源部署DolphinScheduler，能否实现全自动集群安装部署模式；如何拥有一个完全无服务器的DolphinScheduler，并大大降低配置管理成本；如何标准化技术组件实现规范；是否能在无人监督的情况下运行，系统是否能自我修复；如何将其集成到现有的可观测平台中。</p><p></p><h2>利用Kubernetes技术</h2><p></p><p>&nbsp;</p><p>作为云原生技术的事实上的标准，Kubernetes给整个IT应用技术体系带来了革命性的改变。Kubernetes主要以服务注册和发现、负载均衡、自动发布和回滚、容器隔离、软件自我修复和分布式配置管理等核心技术为基础。</p><p>&nbsp;</p><p>不仅仅是Kubernetes，我们的团队还集成了来自CNCF（云原生计算基金会）的许多优秀项目，开展了以下工作：</p><p>&nbsp;</p><p>对DolphinScheduler的部署技术进行了改进。我们使用Helm和Argo CD来极大简化一键式部署。使用Argo CD实现了GitOps配置内容管理机制，使DevOps具备了完整的审计能力。Kubernetes的Pod水平自动伸缩技术大大降低了伸缩应用程序的操作难度。Kubernetes标准化的健康探测技术让调度器的所有技术组件具有强大的自我修复能力。Kubernetes和Argo CD的滚动发布技术让DolphinScheduler工具实现了优雅而简单的升级。Kube-Prometheus技术的使用为DolphinScheduler带来了标准化的可观测性。强大的UI技术简化了CMDB可视化管理、基于Kubernetes的组件配置管理、应用程序日志管理等。</p><p>&nbsp;</p><p>我们还向DolphinScheduler引入了更强大的工具，以获得更丰富的云原生功能：</p><p>&nbsp;</p><p>通过Kubernetes服务注册发现和摄入技术实现了更容易的服务访问；引入的Linkerd为DolphinScheduler带来了服务网格功能，提高了所有API的管理和监控能力；将DolphinScheduler与Argo工作流或标准Kubernetes作业相结合；引入了对象存储技术MinIO，统一了非结构化数据存储技术。</p><p>&nbsp;</p><p>我们所做的工作都是为了使DolphinScheduler更强大、运行更稳定、要求更少的运营时间、具备更好的可观测性、更丰富更完整的生态。</p><p></p><h2>向云原生平台的初步过渡</h2><p></p><p>&nbsp;</p><p>为了完全拥抱云原生技术，DolphinScheduler首先需要快速实现云原生部署和操作，即将大多数企业应用程序迁移到Kubernetes环境中。</p><p>&nbsp;</p><p>感谢开源社区的贡献，我们快速构建了DolphinScheduler的JAR包Docker镜像，并使用Helm工具包实现了基于Kubernetes的声明式部署脚本。成为Kubernetes托管对象是集成到云原生最重要的一步。这些不仅让云原生用户和组织更方便、更快地使用工具，而且大大提高了DolphinScheduler用户的工作效率。</p><p>&nbsp;</p><p>要在Kubernetes上部署DolphinScheduler，你可以这么做：</p><p>&nbsp;</p><p>从GitHub下载<a href=\"https://github.com/apache/dolphinscheduler/archive/refs/tags/1.3.9.tar.gz\">dolphinscheduler-1.3.9.tar.gz</a>\"，在./dolphinscheduler-1.3.9/docker/kubernetes/dolphinscheduler文件夹中找到Helm包。</p><p>&nbsp;</p><p>使用下面的命令部署DolphinScheduler实例：</p><p><code lang=\"null\">kubectl create ns ds139\nhelm install dolphinscheduler . -n ds139</code></p><p>&nbsp;</p><p>有时候，为了进行ETL和连接数据库，DolphinScheduler用户需要集成DataX、MySQL JDBC驱动程序或Oracle JDBC驱动程序。我们可以下载必要的组件，构建新的Docker镜像，并升级DolphinScheduler实例：</p><p><code lang=\"null\">#Download the additional components\nhttps://repo1.maven.org/maven2/mysql/mysql-connector-java/5.1.49/mysql-connector-java-\n5.1.49.jar\nhttps://repo1.maven.org/maven2/com/oracle/database/jdbc/ojdbc8/\nhttps://github.com/alibaba/DataX/blob/master/userGuid.md\n\n\n#Create a new docker image with new tag by this Dockerfile\nFROM apache/dolphinscheduler:1.3.9\nCOPY *.jar /opt/dolphinscheduler/lib/\nRUN mkdir -p /opt/soft/datax\nCOPY datax /opt/soft/datax\n\n\n#Edit image tag of helm value.yaml file, and execute helm upgrade.\nhelm upgrade dolphinscheduler -n ds139</code></p><p>&nbsp;</p><p>一般来说，我们建议在生产环境中使用独立部署的外部PostgreSQL作为管理数据库。我们发现，在切换到外部数据库后，即使完全删除并重新部署Kubernetes中的DolphinScheduler，也不需要重新创建DolphinScheduler的应用程序数据（例如，用户定义的数据处理任务）。这再次证明了系统具备高可用性和数据完整性。此外，我们建议为DolphinScheduler组件配置PersistentVolume，因为如果Pod重启或升级，DolphinScheduler的历史应用程序日志将会丢失。</p><p>&nbsp;</p><p>与传统模型中使用上百个shell命令的操作相比，我们只需要修改一个配置文件，再加上一行安装命令，就可以自动安装DolphinScheduler的8个组件，节省了大量的人工成本，减少了大量的操作错误。如果有多个DolphinScheduler集群，这将大大降低人力成本，业务部门的等待时间将从几天减少到不到一小时，甚至可能是十分钟。</p><p></p><h2>加入GitOps（Argo CD）</h2><p></p><p>&nbsp;</p><p>Argo CD是一种声明式的<a href=\"https://about.gitlab.com/topics/gitops/\">GitOps</a>\"持续交付工具，它基于Kubernetes和CNCF的孵化项目，是GitOps的最佳实践工具。</p><p>&nbsp;</p><p>GitOps可以为DolphinScheduler带来以下的好处。</p><p>&nbsp;</p><p>图形化和一键式安装集群软件；Git可以记录完整的发布过程，并支持一键回滚；方便的DolphinScheduler工具日志查看。</p><p>&nbsp;</p><p>然后，我们可以看到由Argo CD自动部署的Pod、configmap、secret、service、ingress和其他资源，它还会显示提交信息和用户名，完全记录了所有的发布事件信息。与此同时，你还可以一键回退到历史版本。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/52/528c5818c7470ffbb602325b7ff74b5a.png\" /></p><p></p><p>&nbsp;</p><p>通过kubectl命令可以查看相关的资源信息：</p><p><code lang=\"null\">[root@tpk8s-master01 ~]# kubectl get po -n ds139\n                           NAME                               READY   STATUS  RESTARTS           AGE\nDolphinscheduler-alert-96c74dc84-72cc91/1Running022m\nDolphinscheduler-api-78db664b7b-gsltq1/1Running022m\nDolphinscheduler-master-01/1Running022m\nDolphinscheduler-master-11/1Running022m\nDolphinscheduler-master-21/1Running022m\nDolphinscheduler-worker-01/1Running022m\nDolphinscheduler-worker-11/1Running022m\nDolphinscheduler-worker-21/1Running022m\n\n\n[root@tpk8s-master01 ~]# kubectl get statefulset -n ds139\n              NAME                                READY              AGE\nDolphinscheduler-master3/322m\nDolphinscheduler-worker3/322m\n\n\n[root@tpk8s-master01 ~]# kubectl get cm -n ds139\n          NAME                                     DATA                AGE\nDolphinscheduler-alert1523m\nDolphinscheduler-api123m\nDolphinscheduler-common2923m\nDolphinscheduler-master1023m\nDolphinscheduler-worker723m\n\n\n[root@tpk8s-master01 ~]# kubectl get service -n ds139\nNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\nDolphinscheduler-apiClusterIP10.43.238.5 12345/TCP 23m\nDolphinscheduler-master-headless ClusterIP None 5678/TCP 23m\nDolphinscheduler-worker-headless ClusterIP None  1234/TCP,50051/TCP 23m\n\n\n[root@tpk8s-master01 ~]# kubectl get ingress -n ds139\n      NAME                               CLASS                       HOSTS ADDRESS\nDolphinschedulerds139.abc.com</code></p><p>&nbsp;</p><p>你还可以看到，所有的Pod部署在Kubernetes集群的不同主机上，例如，worker 1和worker 2位于不同的节点上。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/83/8305337e0f7b78be4d22733f281fdc38.png\" /></p><p></p><p>&nbsp;</p><p>在配置好了ingress后，我们就可以使用域名来访问公司内网中的DolphinScheduler Web UI。我们以DNS子域名abc.com为例：<a href=\"http://ds139.abc.com/dolphinscheduler/ui/#/home\">http://ds139.abc.com/dolphinscheduler/ui/#/home</a>\"。我们可以在Argo CD上查看DolphinScheduler每个组件的内部日志：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e8/e8663c1f364f8ff618c4e0f46e13f895.png\" /></p><p></p><p>有了Argo CD，我们就可以非常方便地修改组件（如master、worker、API或alert）的副本数量。DolphinScheduler的Helm配置还保留了CPU和内存的设置信息。我们修改了value.yaml文件中的副本设置。修改好之后，我们将其推送到公司内部的源代码系统：</p><p><code lang=\"null\">master:\n  podManagementPolicy: \"Parallel\"\n  replicas: \"5\"\nworker:\n  podManagementPolicy: \"Parallel\"\n  replicas: \"5\"\nalert:\n  replicas: \"3\"\napi:\n  replicas: \"3\"</code></p><p>&nbsp;</p><p>只需在Argo CD上点击“同步”即可开始同步，并根据需要添加相应的Pod。</p><p><code lang=\"null\">[root@tpk8s-master01 ~]# kubectl get po -n ds139\n                   NAME                                      READY   STATUS              RESTARTS            AGE\nDolphinscheduler-alert-96c74dc84-72cc91/1Running043m\nDolphinscheduler-alert-96c74dc84-j6zdh1/1Running02m27s\nDolphinscheduler-alert-96c74dc84-rn9wb1/1Running02m27s\nDolphinscheduler-api-78db664b7b-6j8rj1/1Running02m27s\nDolphinscheduler-api-78db664b7b-bsdgv1/1Running02m27s\nDolphinscheduler-api-78db664b7b-gsltq1/1Running043m\nDolphinscheduler-master-01/1Running043m\nDolphinscheduler-master-11/1Running043m\nDolphinscheduler-master-21/1Running043m\nDolphinscheduler-master-31/1Running02m27s\nDolphinscheduler-master-41/1Running02m27s\nDolphinscheduler-worker-01/1Running043m\nDolphinscheduler-worker-11/1Running043m\nDolphinscheduler-worker-21/1Running043m\nDolphinscheduler-worker-31/1Running02m27s\nDolphinscheduler-worker-41/1Running02m27s</code></p><p>&nbsp;</p><p>不仅是Helm，基于Argo CD的GitOps技术也为整个DolphinScheduler工具提供了图形化、自动化、可跟踪、可审计的强大DevOps、回滚和监控功能，而无需对DolphinScheduler进行任何代码修改。</p><p></p><h2>为DolphinScheduler添加自我修复能力</h2><p></p><p>&nbsp;</p><p>众所周知，当今的IT环境总是处于一个不稳定的状态。换句话说，我们的技术系统将服务器、操作系统和网络的各种故障视为发生在集群中的常规事件。当用户无法通过浏览器正常访问DolphinScheduler的任务管理页面，或者当DolphinScheduler无法正常运行大数据任务时，为时已晚。</p><p>&nbsp;</p><p>在DolphinScheduler迁移成云原生之前，它只能依靠日常监控来检查master/worker/API和其他组件是否正常运行，比如使用DolphinScheduler的管理UI，或通过jps检查Java进程是否存在。当一家企业有数百个调度环境时，不仅成本会很高，更重要的是，系统的可用性也会面临巨大的风险。</p><p>&nbsp;</p><p>值得注意的是，Kubernetes本身可以为部署类型标准化的有状态应用程序进行自动重启和恢复，甚至CRD（定制资源定义）本身也可以自动重启和恢复。当应用程序出现故障时，一个异常事件会被记录下来，然后重新拉取应用程序并重启，Kubernetes会记录Pod重启的次数，帮助技术人员快速定位故障。</p><p>&nbsp;</p><p>除了标准化的自我修复能力外，还有主动健康监测方法，即构建一个服务接口，通过livenessProbe主动探测正在运行DolphinScheduler的Pod，当检测到的故障超过重试次数后将自动重启Pod。此外，通过使用readinessProbe，Kubernetes集群可以在探针捕获到异常时自动切断到异常Pod的流量，并在异常事件消失后自动恢复到异常Pod的流量。</p><p><code lang=\"null\">livenessProbe:\n  enabled: true\n  initialDelaySeconds: \"30\"\n  periodSeconds: \"30\"\n  timeoutSeconds: \"5\"\n  failureThreshold: \"3\"\n  successThreshold: \"1\"\nreadinessProbe:\n  enabled: true\n  initialDelaySeconds: \"30\"\n  periodSeconds: \"30\"\n  timeoutSeconds: \"5\"\n  failureThreshold: \"3\"\n  successThreshold: \"1\"</code></p><p></p><h2>增强DolphinScheduler的可观测性</h2><p></p><p>&nbsp;</p><p>我们知道，Prometheus已经是云原生系统中监控工具的事实上的标准，将DolphinScheduler的标准监控纳入Prometheus系统对我们来说意义重大。Kube-Prometheus技术可以监控Kubernetes集群中的所有资源。有状态集合、命名空间和Pod是DolphinScheduler的三个主要资源特性。借助Kube-Prometheus技术可以自动实现对CPU、内存、网络、IO、复制等资源的日常监控，无需任何额外的开发和配置。</p><p>&nbsp;</p><p>我们利用Kubernetes中的Kube-Prometheus操作技术，在部署后自动监控DolphinScheduler各个组件的资源。但需要注意的是，<a href=\"https://github.com/prometheus-operator/kube-prometheus\">Kube-Prometheus的版本</a>\"需要与Kubernetes的主版本相对应。</p><p></p><h2>服务网格集成</h2><p></p><p>&nbsp;</p><p>作为数据服务提供者，DolphinScheduler将服务网格技术集成到内部服务治理系统中，实现了服务链接的可观察性管理。</p><p>&nbsp;</p><p>DolphinScheduler不仅需要一般的资源监控，还需要对服务调用链进行监控的技术。借助服务网格技术，实现了DolphinScheduler内部服务调用和DolphinScheduler API外部调用的可观测性分析，优化了DolphinScheduler产品的服务。</p><p>&nbsp;</p><p>此外，作为数据工具的服务组件，DolphinScheduler可以通过服务网格工具无缝集成到企业内部的服务模式中。它可以在不修改DolphinScheduler代码的情况下启用TLS服务通信、客户端服务通信重试和跨集群服务注册发现等功能。</p><p>&nbsp;</p><p>我们集成了Linkerd，将其作为我们的服务网格，它也是CNCF的一个优秀的项目。通过修改value.yaml文件中的annotations，并重新部署，就可以为master、worker、API、警报和DolphinScheduler的其他组件快速注入网格代理边车。</p><p><code lang=\"null\">annotations:\n  linkerd.io/inject: enabled</code></p><p>&nbsp;</p><p>你还可以观察组件之间的服务通信质量，包括每秒请求数。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fd/fd770a6244435fb7c39d99505f28c0e0.png\" /></p><p></p><p></p><h2>加入云原生工作流调度能力</h2><p></p><p>&nbsp;</p><p>要成为真正的云原生调度工具，DolphinScheduler需要能够调度云原生作业流。</p><p>&nbsp;</p><p>由DolphinScheduler调度的任务都是在固定的Pod中执行的。在这样的模式下，对任务开发技术的隔离性具有较高的要求。</p><p>&nbsp;</p><p>特别是在Python语言环境中，一个团队中会有不同版本的Python基本包和依赖包，版本之间的差异甚至可能出现数百种组合。一个细小的依赖包差异将导致Python程序运行错误。这也是阻止DolphinScheduler运行大量Python应用程序的障碍。我们推荐下面的方法，快速将DolphinScheduler与Kubernetes作业系统集成，具有强大的任务隔离性和并发能力：</p><p>&nbsp;</p><p>使用标准的Kubernetes API提交作业。你可以直接通过kubectl命令或REST API提交任务。将kubectl命令文件上传到DolphinScheduler，并通过DolphinScheduler的shell任务来提交。使用Argo Workflows的Argo CLI命令或Rest API命令提交作业。</p><p>&nbsp;</p><p>无论是Kubernetes还是Argo Workflows，都需要添加watch功能，因为Kubernetes是异步的，需要等待任务完成。</p><p>&nbsp;</p><p>这里我们使用了Argo Workflows，我们可以在DolphinScheduler创建一个新的shell任务或步骤，并粘贴下面的命令。我们可以将普通的数据作业（如数据库SQL作业、Spark作业或Flink作业）和云原生作业组合在一起，执行一个更加全面的作业流。例如，这是一个Hive SQL任务，用于导出Web应用程序的用户点击数据：</p><p><code lang=\"null\">beeline -u \"jdbc:hive2://192.168.1.1:10006\" --outputformat=csv2 -e \"select * from database.user-click\" &gt; user-click.csv </code></p><p>&nbsp;</p><p>这个示例作业是一个Python Tensorflow任务，通过训练数据来构建机器学习模型。这个作业通过HTTP来运行。首先，我们运行作业：</p><p><code lang=\"null\">#通过HTTP执行Python Tensorflow作业\ncurl --request POST -H \"Authorization: ${ARGO_TOKEN}\" -k \\\n       --url https://argo.abc.com/api/v1/workflows/argo \\\n       --header 'content-type: application/json' \\\n       --data '{\n                \"namespace\": \"argo\",\n                \"serverDryRun\": false,\n                \"workflow\": {\n                \"metadata\": {\n                    \"name\": \"python-tensorflow-job\",\n                    \"namespace\": \"argo\"\n                },\n                \"spec\": {\n                    \"templates\": [\n                    {\n                        \"name\": \"python-tensorflow\",\n                        \"container\": {\n                        \"image\": \"tensorflow/tensorflow:2.9.1\",\n                        \"command\": [\n                            \"python\"\n                        ],\n                        \"args\": [\n                            \"training.py\"\n                        ],\n                        \"resources\": {}\n                        }\n                    }\n                    ],\n                    \"entrypoint\": \"python-tensorflow\",\n                    \"serviceAccountName\": \"argo\",\n                    \"arguments\": {}\n                   }\n                }\n               }'</code></p><p>&nbsp;</p><p>然后我们可以查看作业的信息和状态：</p><p><code lang=\"null\">#通过HTTP查看Python Tensorflow作业的和状态\ncurl --request GET -H \"Authorization: ${ARGO_TOKEN}\" -k \\\n       --url https:/argo.abc.com/api/v1/workflows/argo/python-tensorflow-job</code></p><p></p><h2>将文件系统从HDFS升级到S3</h2><p></p><p>&nbsp;</p><p>分布式算法是云原生赋能的一个领域，例如谷歌的Kubeflow技术，它完美地结合了TensorFlow和Kubernetes。分布式算法通常会使用文件，而S3是存储易于访问的大数据文件的事实上的标准。当然，DolphinScheduler还集成了MinIO技术，通过简单的配置即可实现S3文件管理。</p><p>&nbsp;</p><p>首先修改value.yaml文件的configmap部分，指定MinIO服务器。</p><p><code lang=\"null\">configmap:\n  DOLPHINSCHEDULER_OPTS: \"\"\n  DATA_BASEDIR_PATH: \"/tmp/dolphinscheduler\"\n  RESOURCE_STORAGE_TYPE: \"S3\"\n  RESOURCE_UPLOAD_PATH: \"/dolphinscheduler\"\n  FS_DEFAULT_FS: \"s3a://dfs\"\n  FS_S3A_ENDPOINT: \"http://192.168.1.100:9000\"\n  FS_S3A_ACCESS_KEY: \"admin\"\n  FS_S3A_SECRET_KEY: \"password\"</code></p><p>&nbsp;</p><p>MinIO中保存文件的桶的名字叫“dolphinscheduler”。用户通过DolphinScheduler UI上传的共享文件都保存在这个文件夹中。</p><p></p><h2>结论</h2><p></p><p>&nbsp;</p><p>作为新一代云原生大数据工具，DolphinScheduler有望在未来集成Kubernetes生态系统中更多优秀的工具和功能，以满足更多多样化用户群体和场景的需求。我们目前路线图中的一些项目包括：</p><p>&nbsp;</p><p>利用边车定期删除worker作业日志，实现轻松的操作和维护；与Argo Workflows进行更多的集成，用户可以通过API、CLI等方式在DolphinScheduler中调用Argo Workflows进行单个作业、DAG作业和周期性作业；使用HPA（水平Pod自动伸缩）自动伸缩DolphinScheduler组件，以实现更有弹性的运行环境和处理不确定的工作负载；集成Spark 和Flink Operator，实现全面的基于云原生的分布式计算；实现多云、多集群的分布式作业调度，强化无服务器和FAAS的架构属性。</p><p>&nbsp;</p><p>想要了解更多关于DolphinScheduler的信息，或者想要加入开发者社区，请通过我们的<a href=\"https://s.apache.org/dolphinscheduler-slack\">Slack</a>\"频道联系我们。</p><p></p><p>作者简介：</p><p>&nbsp;</p><p>Yang Dian是深圳城市交通规划中心的副总工程师。他目前的技术专长主要是关于数据算法平台实现和云原生转型。他曾参与中国顶级物流企业的IT架构咨询项目。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/cloud-native-apache-dolphinscheduler/\">Embracing Cloud-Native for Apache DolphinScheduler with Kubernetes: a Case Study</a>\"</p>",
    "publish_time": "2022-07-12 09:27:41",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "押注.NET是件好事",
    "url": "https://www.infoq.cn/article/UctWIdgVtkt5gUrFrL7w",
    "summary": "<p></p><p>作为一个在.NET上构建了不止一个流行平台的人，我经常被问到它的相关性，以及它是不是一个值得投入的生态系统。这个问题在旧金山湾区的技术世界里尤为流行，这里的技术潮流就像四季一样变更交替，但.NET始终是一个坚定、持续流行的平台。而在我看来，它还是最具整体生产力、最令人愉快和最易访问的平台。</p><p></p><p>这个世界上确实还有其他很棒的编程语言，比如Rust；还有其他很棒的App UX平台，比如Flutter。但说到全面的生产力和优雅，可能没有能与.NET一较高下的了。</p><p></p><p>今天的.NET已经不是老一辈的.NET了，在一年一度的StackOverflow开发者调查中，它连续3年成为最受喜爱的平台，这是有原因的。事实上，.NET Framework和新.NET Core的结合远远超过了其他所有东西。甚至可以说，在这些问卷调查的所有框架当中，.NET体现了最强烈的爱与恐惧的正面情绪。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/0a/21/0a3f019bbedbe5205524e6d38f1ee221.png\" /></p><p></p><p></p><p>为了理解为什么开发者如此热爱.NET，让我们全面考察一下.NET的开发者体验。</p><p></p><p></p><h1>一流的工具</h1><p></p><p></p><p>首先是工具。Windows和Mac的Visual Studio为.NET提供了一流的支持，VS Code也为其提供了有限的支持（微软的一个疏忽，我们将在下面讨论）。它们代表了世界上使用率最高的IDE，事实上，VS Code是IDE的绝对统治者，使用人数是Visual Studio（位居第二）的两倍多。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/48/a5/48ff1ef584a3e31a3b8b7646a566fca5.png\" /></p><p></p><p>JetBrains Rider被许多人认为是现有最好的IDE，它不仅与Visual Studio一样为.NET提供支持，而且在此基础上进行了相当大的改进，带来了可能是所有工具中最好的.NET工具体验。</p><p></p><p>工具本身是基于底层的平台功能（如健壮的一键式构建和部署系统）而构建的，提供了轻松的首次运行体验，开发者能够在几分钟内完成从平台安装到应用程序部署的过程。事实上，无需纠缠于复杂的工具链、构建文件或平台版本控制就能从零开始使用.NET来部署应用程序，这种能力已经为其他平台树立了标准，并提升了开发者对平台的忠诚度。</p><p></p><p></p><h1>随处运行</h1><p></p><p></p><p>就像20世纪90年代的Java梦一样，.NET也运行在所有的主流平台上，并拥有定制的集成工具来充分利用每一个平台。虽然它最初被锁定在Windows上，但在今天，它已经可以运行在Windows、macOS、iOS、Android、Linux、大型机甚至微控制器上。它也运行在云端，Azure、AWS和谷歌云都提供了内置的.NET应用程序支持。</p><p></p><p></p><h1>一系列优雅的编程语言</h1><p></p><p></p><p>公共语言运行时(CLR)是.NET的一个核心特性，开发者可以使用超过25种语言编写应用程序，包括C#和F#——世界上最好的两种编程语言，以及VB.NET——虽然人们喜欢调侃它，但它本身确实非常强大。</p><p></p><p></p><h1>强大的社区和开发者</h1><p></p><p></p><p>根据具体的计算方式，活跃的开发者数量在200万到250万之间。而根据我们自己的研究，世界上将近一半的活跃开发者知道或者正在用.NET。</p><p></p><p>自.NET诞生以来，开发者生态系统每年都在增长。因此，在难以招到开发人员的时候，你可以放心，.NET是最大的开发人才库之一。</p><p></p><p>它还在快速增长。最新的TIOBE编程语言指数显示，在过去的一年中，C#的受欢迎程度增长最快，有望进入前三，取代C语言。事实上，如果与VB.NET一起，它将轻松位居榜首。</p><p></p><p></p><h1>技术之美</h1><p></p><p></p><p>2016年的.NET Core重构对.NET进行了彻底的改造，提供了一种现代的、轻量级的、可组合的、点菜式的方式，直接通过Nuget从它的现代包生态系统中获取必要的平台库。它放弃了传统的Win32平台连接，融合了Mono和Xamarin团队在运行时和工具上带来的创新，为真正的跨平台体验铺平了道路。</p><p></p><p>.NET Core也带来了更好的性能。通过打破旧有.NET Framework运行时的限制，微软带来了一系列性能改进。</p><p></p><p>说到性能，Xamarin的预先编译器（现在已被纳入.NET）让开发人员可以直接在构建时为特定芯片架构的汇编代码编译出二进制文件，从而在内存托管的应用程序中实现原生的C/C++性能。</p><p></p><p>这种内在的内存托管方式也为可靠性和安全性带来了好处。从可靠性角度来看，它实际上消除了非托管应用程序（如用C/C++编写的应用程序）中常见的内存泄漏所造成的不稳定和崩溃。从安全性角度来看，内存托管平台的安全性消除了由内存使用引起的一系列安全问题，谷歌的安全数据显示，内存使用引起的Bug大约占所有非托管安全性的三分之二。</p><p></p><p></p><h1>百分百开源</h1><p></p><p><img src=\"https://static001.infoq.cn/resource/image/ff/ee/ff6ec962c8809127fc2b59f6137ba3ee.png\" /></p><p></p><p>.NET的所有东西都是开源的，可以免费使用，包括类库、运行时、编译器、编程语言和应用程序框架。你可以在GitHub上的<a href=\"https://github.com/dotnet?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJhdWQiOiJhY2Nlc3NfcmVzb3VyY2UiLCJleHAiOjE2NTc1OTI3NTcsImZpbGVHVUlEIjoiZnl1REI1UGlKN1F4a1pyNyIsImlhdCI6MTY1NzU5MjQ1NywidXNlcklkIjoyNDM2MDc5MH0.tK2xbjYpDDnb4guyXsPdgdxRLmHEt5PZK6nWKJ75RWg\">DotNet</a>\"存储库中找到所有的源代码。</p><p></p><p></p><h1>一流的生态系统</h1><p></p><p></p><p>除了微软的投入之外，第三方生态系统也非常庞大，拥有大量高质量的库、插件、工具和框架。</p><p></p><p>下面列出了几个非常引人注目的第三方集成的例子：</p><p></p><p><a href=\"https://platform.uno/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJhdWQiOiJhY2Nlc3NfcmVzb3VyY2UiLCJleHAiOjE2NTc1OTI3NTcsImZpbGVHVUlEIjoiZnl1REI1UGlKN1F4a1pyNyIsImlhdCI6MTY1NzU5MjQ1NywidXNlcklkIjoyNDM2MDc5MH0.tK2xbjYpDDnb4guyXsPdgdxRLmHEt5PZK6nWKJ75RWg\">Uno Platform</a>\"和<a href=\"https://avaloniaui.net/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJhdWQiOiJhY2Nlc3NfcmVzb3VyY2UiLCJleHAiOjE2NTc1OTI3NTcsImZpbGVHVUlEIjoiZnl1REI1UGlKN1F4a1pyNyIsImlhdCI6MTY1NzU5MjQ1NywidXNlcklkIjoyNDM2MDc5MH0.tK2xbjYpDDnb4guyXsPdgdxRLmHEt5PZK6nWKJ75RWg\">Avalonia</a>\"——两个成熟的MAUI替代解决方案，Uno Platform和Avalonia提供了一个优雅的、令人愉快的、高性能、跨平台UX框架。<a href=\"https://www.wildernesslabs.co/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJhdWQiOiJhY2Nlc3NfcmVzb3VyY2UiLCJleHAiOjE2NTc1OTI3NTcsImZpbGVHVUlEIjoiZnl1REI1UGlKN1F4a1pyNyIsImlhdCI6MTY1NzU5MjQ1NywidXNlcklkIjoyNDM2MDc5MH0.tK2xbjYpDDnb4guyXsPdgdxRLmHEt5PZK6nWKJ75RWg\">Meadow</a>\"——由Wilderness Labs开发，可以用它为运行在微控制器上的.NET构建物联网解决方案。<a href=\"https://www.telerik.com/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJhdWQiOiJhY2Nlc3NfcmVzb3VyY2UiLCJleHAiOjE2NTc1OTI3NTcsImZpbGVHVUlEIjoiZnl1REI1UGlKN1F4a1pyNyIsImlhdCI6MTY1NzU5MjQ1NywidXNlcklkIjoyNDM2MDc5MH0.tK2xbjYpDDnb4guyXsPdgdxRLmHEt5PZK6nWKJ75RWg\">Telerik</a>\"——几乎在任何平台上都可以使用的可插拔UI控件。</p><p></p><p>还有其他无数的咨询公司、解决方案提供商和.NET商店，它们都获得了构建.NET解决方案的认证和资格。</p><p></p><p></p><h1>受企业信任</h1><p></p><p></p><p>众所周知，.NET是企业的中流砥竿，虽然微软没有公开发布.NET的采用情况，但有95%的财富500强企业都在使用Azure。而且，我私下里也被告知，至少80%的财富500强企业在使用.NET，但实际数字可能更高，因为遥测技术经常会被关闭。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/74/9e/7436a1eecd9aea6326ef69b06405c89e.png\" /></p><p></p><p>.NET尤其适用于关键任务型应用程序，在这些应用程序中，.NET的可靠性和久经考验的运行时让人心情舒畅。事实上，美国国防部在广泛使用.NET。</p><p></p><p></p><h1>它并不完美</h1><p></p><p></p><p>尽管.NET有这些神奇之处，但它并不完美。我要指出的是，尽管微软用它提供了这么多好东西，但它也有缺点。其中，大部分直接归因于微软内部优先级的转变，以及领导团队一直在艰难地跟上一线的开发者文化。</p><p></p><p>MAUI是微软的旗舰跨平台UI库，Xamarin的继承者，同时也结合了之前的Windows UI框架WPF，但长期以来资金不足，这使得Flutter成为当今最好的跨平台UX平台。在Linux平台上尤其如此，因为Linux目前还不支持MAUI。</p><p></p><p>同样是这些领导团队，他们有时候也错误地处理了与社区的关系，缺失方向感的.NET基金会和Hot-Reload的惨败就足以证明。</p><p></p><p>优先级转变也可能是限制为VS Code提供支持的原因，虽然有了基本的.NET支持，但仍然缺少适当的插件来处理.NET的多项目解决方案格式，而这对于支持更复杂的项目来说是必要的。这是由于微软一直以来优先将.NET开发者引向Visual Studio的销售，以此来实现变现，而不是为他们提供免费的VS Code。</p><p></p><p>话虽如此，很明显，微软内部的优先级正在转移到提供更好的跨平台工具支持上，而且我听说一个完整的VS Code解决方案正在进行当中。</p><p></p><p></p><h1>结束语</h1><p></p><p></p><p>然而，即使有一些小缺点，.NET仍然可以轻松地成为世界上最高效、最值得信赖的开发者平台生态系统。没有什么比.NET更完整、更开放、更高效的平台了。</p><p></p><p>所有迹象表明，在可预见的未来，.NET将继续保持这种态势，因为它将继续发展，团队和生态系统将继续创新。因此，把赌注押在.NET上是件好事！</p><p></p><p>原文链接：</p><p></p><p><a href=\"https://medium.com/@bryancostanich/its-good-to-bet-on-net-c22853f501c7?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJhdWQiOiJhY2Nlc3NfcmVzb3VyY2UiLCJleHAiOjE2NTc1OTI3NTcsImZpbGVHVUlEIjoiZnl1REI1UGlKN1F4a1pyNyIsImlhdCI6MTY1NzU5MjQ1NywidXNlcklkIjoyNDM2MDc5MH0.tK2xbjYpDDnb4guyXsPdgdxRLmHEt5PZK6nWKJ75RWg\">https://medium.com/@bryancostanich/its-good-to-bet-on-net-c22853f501c7</a>\"</p>",
    "publish_time": "2022-07-12 10:42:58",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]