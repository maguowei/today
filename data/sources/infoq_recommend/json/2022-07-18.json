[
  {
    "title": "智源就“抄袭事件”发布最新通报：2处属于抄袭，已得到原作者谅解，相关责任人均已主动离职",
    "url": "https://www.infoq.cn/article/6EZ2UkwU0DA3ZWtmBYyJ",
    "summary": "<p>今年4月，一篇名为《A Roadmap for Big Model》（大模型路线图）的论文被爆出抄袭，该篇论文中涉及国内19家机构和百名AI学者，其中不乏业内知名AI学术大佬。</p><p></p><p>事件一出，舆论哗然，也把国内的AI学术圈推上了风口浪尖。</p><p></p><p>作为此篇论文第一单位，<a href=\"https://www.infoq.cn/article/WRKqEaLvQwlcCyt8hSHh\">北京智源研究院</a>\"立即对此事做出了积极回应，并邀请第三方专家对此事展开独立调查。智源研究院还就IEEE手册条款的理解和抄袭严重程度的认定，通过邮件咨询了IEEE学术出版规范负责人的意见。</p><p></p><p>历时三个月，7月15日，根据<a href=\"https://mp.weixin.qq.com/s?__biz=MzAxNDU2MTU5MA==&amp;mid=2649971323&amp;idx=1&amp;sn=155dd01fe9951449b4c81f13f491f856&amp;chksm=83968222b4e10b34d439e7ddb6aa06247a2dc9eab2ed01334ccb9177de38ed80ece2cdf5a4bb&amp;scene=27#wechat_redirect\">CCF</a>\"调查报告和IEEE专家反馈，智源研究院与16篇文章的通讯作者进行了沟通，对于存在问题文章的作者责任进行了核查与认定，并将调查和处理情况在官网上进行了通报。</p><p></p><p>以下为通报全文：</p><p></p><h3>1. 组织失察责任认定</h3><p></p><p>该综述报告由智源研究院大模型研究中心牵头组织、邀请国内外 19 个机构共 100 位科研人员分别撰写的 16 篇独立专题文章组成，每篇文章都有对应的撰写作者和通讯作者（除第 12 篇外），所有作者共同署名整个报告（这种组织模式参考了斯坦福大学“On the Opportunities and Risks of Foundation Models” (https://arxiv.org/pdf/2108.07258v2.pdf)&nbsp;一文的编撰方式）。综述报告首先上传至预印本网站 arXiv，原计划经过修改完善后再正式出版。</p><p></p><p>智源研究院大模型研究中心作为组织单位，对综述报告撰写中可能存在的风险隐患缺少充分考虑，未采取必要措施避免相关问题出现，对整个事件负有监督失察责任。</p><p></p><p>综述报告的第一作者（智源大模型研究中心人员）未严格按照学术出版规范的流程执行，在未与其他作者确认的情况下，于 2022 年 3 月 26 日将综述报告上传至 arXiv，负有主要组织责任。</p><p></p><h3>2.&nbsp;两处抄袭的责任认定</h3><p></p><p>综述报告 10 处被质疑片段中，2 处属于抄袭。</p><p></p><p>第 2 篇文章的 2.3.1 节存在共计 179 个单词的多句重复，在最开始明确标注了引用文献，但未明确区别引用文字，且篇幅较大，属于《学术出版规范 期刊学术不端行为界定》“三、论文作者学术不端行为类型”中的 “1.5 文字表述剽窃”：“成段使用他人已发表文献中的文字表述，虽然进行了引注，但对所使用文字不加引号，或者不改变字体，或者不使用特定的排列方式显示”，达到《IEEE 出版物服务和产品委员会操作手册》“对不同等级的抄袭行为进行判定的指南” 中“第 5 级”（认定要点为“对一篇文章的主要部分逐字复制，虽有引注但缺乏清晰区分”。</p><p></p><p>说明：抄袭共分 5 级，第 1 级最严重，第 5 级最轻微），由该文章的第二作者（智源大模型研究中心人员）完成，应负直接责任。该文章的通讯作者（智源大模型研究中心人员），未对该文章进行有效审查，应负失察责任。该篇文章第 2.4.3 节存在多句重复，有明确参考文献标注，属于规范引用。参与文章的其他作者撰写的部分未发现抄袭。</p><p></p><p>第 8 篇文章的 8.3.1 节存在 74 个单词的整句重复，无明确引用，属于抄袭，相关段落由该文章第一作者（智源大模型研究中心人员）完成，应负直接责任。该文章其他作者是文章初稿完成人，初稿不涉及被质疑内容。该文章第一作者未经通讯作者及其他作者同意将自己加为第一作者并对文章进行了大篇幅修改，文章发布前未与通讯作者确认，因此通讯作者和其他作者均没有责任。</p><p></p><p>上述两名作者已经按照 IEEE 手册的对应纠正措施向原作者致歉，并得到原作者谅解，履行了应该承担的相关学术责任。</p><p></p><h3>3.&nbsp;四处引用不规范的责任认定</h3><p></p><p>除前述 2 处抄袭外，综述报告 10 处被质疑片段中，尚有部分片段属于引用不规范，但不构成抄袭，其他被质疑部分属于规范引用。具体认定如下：</p><p></p><p>第 10 篇文章存在少数重复文字，是在明确添加标注引用参考文献情况下的转述，属于规范引用。</p><p></p><p>第 12 篇文章的 12.2.3 节存在共计 36 个单词的重复，无整句重复，相关内容由该文章第二作者完成。重复内容包括两个部分，一部分包含 17 个重复单词，属于规范引用参考文献；另一部分包含 19 个重复单词，在对相关领域介绍时，引用了其他论文引言部分对于本领域的总结，但在本句中未标注引用参考文献，属于引用不规范，但不构成抄袭。该文章无通讯作者，其他作者是文章的完成人，所撰写的部分未发现抄袭。</p><p></p><p>第 14 篇文章 14.2.2 节一处多句 63 个单词重复，有明确参考文献标注，属于规范引用。14.2.3 节一处一句 30 个单词重复，有明确参考文献标注，属于规范引用。14.2.2 节另存在一处一句 29 个单词的重复，文字上指明了引用对象，但本句没有直接添加引用，相关段落由该文章的第二作者完成；14.2.3 节另存在一处一句 27 个单词重复，在 14.2.3 节中有参考文献标注，在本句中没有直接标注，相关段落由该文章的第四作者完成，上述两处属于引用不规范，但不构成抄袭。该文章其他作者撰写的部分未发现抄袭。</p><p></p><p>第 16 篇文章 16.1 节一处存在多句重复，相关段落由第二作者完成。该段落起始处对参考文献有明确引用，后续其他句子存在本句未直接标注的情形，属于引用不规范，但不构成抄袭。该文章其他作者撰写的部分未发现抄袭。</p><p></p><p>综述报告第 3、4、5、6、7、9、11、13、15、17 篇文章未发现抄袭。</p><p></p><h3>4. 处理和整改情况通报</h3><p></p><p>智源研究院在质疑发生后，对照国家新闻出版署《学术出版规范 期刊学术不端行文界定》标准并参照《IEEE 出版物服务和产品委员会操作手册》对抄袭的认定指南，从严要求，安排可能存在问题文章的作者向原作者进行了书面致歉，均已得到原作者反馈和谅解。同时，安排第一作者完成从 arXiv 撤稿。上述的抄袭和引用不规范的调查结论也已通知所有作者并获得确认。对照《IEEE 出版物服务和产品委员会操作手册》对抄袭行为的处罚措施，智源研究院和相关责任人已经从严履行了应该承担的相关学术责任。</p><p></p><p>鉴于上述两处抄袭和组织失察责任人均为智源研究院大模型研究中心人员，智源研究院决定重组该部门，上述相关责任人均已主动离职。</p><p></p><p>除上述智源研究院相关责任人外，综述报告其他所有作者没有抄袭及学术不端行为。在此对此次事件给这些作者造成的负面影响和困扰表示诚挚歉意！</p><p></p><p>针对此次事件发现的论文发表流程中的风险漏洞，智源研究院已经整改了论文发表流程，并修订完善了科研诚信与学风建设制度。后续，智源研究院计划与学界和业界合作，制定更严谨的文献引用规范，开发论文和代码开源检测工具和系统，避免再次出现类似问题。</p><p></p><h2>事件回溯</h2><p></p><p>4月8日，谷歌大脑研究员Nicholas Carlini发文指出：</p><p></p><p></p><blockquote>我发现了机器学习研究领域发生了一件论文抄袭事件。一篇名为<a href=\"https://arxiv.org/abs/2203.14101\">《A Roadmap for Big Model》</a>\"（以下简称“大模型论文”）的论文，抄袭了我发表的名为<a href=\"https://nicholas.carlini.com/writing/2022/a-case-of-plagarism-in-machine-learning.html\">《Deduplicating Training Data Makes Language Models Better》</a>\"的论文中的几个段落&nbsp;。Nicholas Carlini表示，更令人沮丧的是，自己发表的论文并不是唯一被抄袭对象，这篇大模型论文至少抄袭了十几篇其他论文。</blockquote><p></p><p></p><p>此外，Nicholas Carlini还将论文中内容相似度比较高的地方用绿色进行了标注（左侧是大模型论文中的文本，右侧是原始论文中的相应文本）：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d0/d0295f83d27b9207a5ae9fa26d7b9c71.gif\" /></p><p></p><p>由于大模型论文最后的署名中涉及19家机构和100位AI领域知名作者，因此此事一出，在国内外学术圈里引发了极高的关注。</p><p></p><p>针对质疑，4 月 13 日，北京智源人工智能研究院发布了《关于 “A Roadmap for Big Model” 综述报告问题的致歉信》，首先向相关原文作者和学术界、产业界的同仁和朋友致歉，并公布了初步调查结果：</p><p></p><p>该报告是一篇大模型领域的综述，希望尽可能涵盖国内外该领域的所有重要文献，由智源研究院牵头，负责框架设计和稿件汇总，并邀请国内外100位科研人员分别撰写了16篇独立的专题文章，每篇文章分别邀请了一组作者撰写并单独署名，共200页。报告发布后，根据反馈持续进行修改完善，到4月2日在arXiv网站上已经更新到第三版。4月13日，我们获悉谷歌研究员Nicholas Carlini在个人博客上指出该报告抄袭了他们论文的数个段落，同时还有其他段落和语句抄袭其他论文。我们对此进行了逐项核查，经查重确认第2篇文章的第3.1节179个词，第8篇文章的第3.1节74个词、第12篇文章的第2.3节55个词、第14篇文章的第2节159个词、第16篇文章的第1节146个词与其他论文重复，应属抄袭。我们决定立即从报告中删除相应内容，报告修订版今天将提交arXiv进行更新。目前已通知所有文章的作者对所有内容进行全面审查，后续经严格审核后再发布新版本。智源作为该报告的组织者，理应对各篇文章的所有内容进行严格审核，出现这样的问题难辞其咎。对此我们深感自责，特别感谢学术界和媒体的朋友们帮助我们发现问题。我们将深刻吸取教训，整改科研管理和论文发表流程，希望各界朋友监督我们工作。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4f/4f88b45b89600a65c1c241cf3867d28e.png\" /></p><p></p><p>此外，智源研究院还表示：“确认部分文章存在问题后，已启动邀请第三方专家开展独立审查，并进行<a href=\"https://www.baai.ac.cn/portal/article/index/cid/5/id/423.html\">相关追责</a>\"。”</p><p></p><p>随后，4月15日，智源研究院邀请的第三方专家——中国计算机学会（CCF）组成了调查组，就此事展开独立调查。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a2/a244974e37cfb1f294a9a32306bd368f.png\" /></p><p></p><p>历时3个月，7月15日，智源在官网通报了调查结果。</p><p></p><p>至此，此次论文抄袭事件最终以第三方介入、独立开展调查的方式为大众交付了一个公开透明的结果。</p><p></p><p>参考链接：</p><p></p><p><a href=\"https://nicholas.carlini.com/writing/2022/a-case-of-plagarism-in-machine-learning.html\">https://nicholas.carlini.com/writing/2022/a-case-of-plagarism-in-machine-learning.html</a>\"</p><p></p><p><a href=\"https://www.baai.ac.cn/portal/article/index/cid/5/id/423.html\">https://www.baai.ac.cn/portal/article/index/cid/5/id/423.html</a>\"</p><p></p><p><a href=\"https://www.baai.ac.cn/portal/article/index/cid/5/id/504.html\">https://www.baai.ac.cn/portal/article/index/cid/5/id/504.html</a>\"</p><p></p><p><a href=\"https://www.baai.ac.cn/portal/article/index/cid/5/id/422.html\">https://www.baai.ac.cn/portal/article/index/cid/5/id/422.html</a>\"</p>",
    "publish_time": "2022-07-18 13:37:08",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "瞬时流量高峰场景下的高可用架构设计：Kubernetes集群如何调优？",
    "url": "https://www.infoq.cn/article/a1rIzRu3CAsC5LXKwJ3f",
    "summary": "<p>谈起瞬时流量高峰场景下的高可用架构设计，那首先要解决的肯定是高并发问题。</p><p></p><p>类似电商大促就是典型的高并发场景，当业务突发波动（如秒杀、限量抢购）时，无法准确预估流量，企业会苦恼需提前准备多少台机器，突发流量过后，这些机器往往又处于空载状态。这就意味着系统需要承担 100% 的业务和流量，需要具备超强的稳定性和容灾能力，并可以紧急处理各种故障：</p><p></p><p>应对快速增长的用户访问：流量短时间内达到峰值，系统面临宕机危险；应对大量业务数据和用户数据：计算资源需求突增，技术上需做到弹性自如；紧急故障处理能力：业务场景越来越复杂，宕机概率增加。</p><p></p><p>虽然这些是老生常谈的话题，但要解决并不容易，性能优化永无止境，系统高可用优化亦然。</p><p></p><h2>实现系统的高可用，Kubernetes 集群是常见解决方案</h2><p></p><p></p><p>想要实现系统的高可用，首先要明确，什么样的系统可以称之为“高可用”。简单来讲，就是不宕机。“高可用性”常常被定义为 IT 系统的运营综合指标，系统的稳定可靠程度越靠近 100%，就代表系统越稳定，这种“稳定”往往需要多方面技术调优才能实现。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/6b/6b3e70e0a032dbd77e10617300843283.png\" /></p><p></p><p>而 Kubernetes 的核心特点就是能够自主地管理容器来保证容器按照用户的期望状态运行，现在 Kubernetes 更是聚焦于不间断的服务状态（如 web 服务器、缓存服务器）和原生云平台应用（Nosql），极大程度地保障系统的稳定性，所以 Kubernetes 被称为云原生时代实现系统高可用的最佳解决方案。</p><p></p><p>作为云原生时代的操作系统，Kubernetes 的采用率正在企业内不断攀升。京东是全球容器化最彻底的互联网企业之一，目前运营着全球最大规模的 Kubernetes 集群。为了应对 如618 的订单洪峰，京东容器云平台带宽扩容数百G，抵挡了数十次攻击，实现了订单百分百云上交易。</p><p></p><p>瞬时流量高峰场景下，京东通过在 Kubernetes 集群上运行业务，以最优成本处理突发流量，实现电商系统的高可用。Kubernetes 集群无需人工管理节点和容量规划，高效实现全自动容器无限弹性扩容，同时还可以做到在保持和降低系统响应时间的前提下，不断提高系统访问量、吞吐量，从而不断提升流量高峰时的服务可用性。</p><p></p><p>即便如京东这种研发实力强悍的互联网大厂也会发现软件层面的性能优化很容易达到瓶颈，当达到某一个值之后，就很难再有提升，这就需要在硬件层面寻求突破。作为京东云底层软件的服务商，为了应对系统高可用性能需求，英特尔从硬件层面给出了解决方案：使用第三代英特尔® 至强® 可扩展处理器提供更强算力来满足高并发需求，英特尔® 傲腾™ 持久内存提供更大容量内存或持久性数据存储，以及各种类型的软硬件加速技术，辅助实现高并发。针对高并发场景下的 HTTPS 请求和处理需求，还可使用英特尔® QAT 卡来卸载 TLS 请求和加解密处理，释放 CPU 应对关键计算，从而提高 HTTPS 高并发访问量、减少相应时间。</p><p></p><p>当以上这些底层硬件能力暴露给 Kuberntes 后，容器开发者或集群运维者可以充分利用资源实现并优化具体业务，还可以借助这些硬件能力来创新，收获不一样的业务、性能体验。除此之外，这些硬件能力还可帮助开发者快捷优化应用负载，确保预测性，并实现资源的可观察性。</p><p></p><p>坦率来讲，分布式系统相对会比较复杂，性能问题也并不那么容易解决，且系统层次比较深，相关性能问题的追踪和定位也不太容易，底层软件层面的优化也是个“慢活儿”，但硬件性能的提升对于 Kuberntes 技术架构体系的优化影响还是很大的。目前已经被验证的，英特尔软、硬结合的方式能够有效优化 Kuberntes 集群技术架构，以便充分利用硬件性能，通过释放硬件潜力来优化软件、提升服务性能。</p><p></p><p></p><h2>对 Kubernetes 的美好期待，前提是完成集群的高效管理</h2><p></p><p></p><p>Kubernetes 本身并没有提供一个高可用的、开箱即用的集群使用方式，实际构建和管理过程中产生的复杂度，往往会带来各种各样的问题和挑战。虽然 Kubernetes 集群可以解决单集群资源隔离、故障隔离的难题，打破可支持节点数、Pod 数的限制，但同时也带来了集群管理复杂度增加的问题，运维成本成倍增加。所以说，Kubernetes 确实能解决很多包括瞬时流量高峰场景在内的系统高可用问题，但这一切的前提是完成 Kubernetes 集群的顺利构建和高效管理。</p><p></p><p>Kubernetes 的插件模式给英特尔等各厂商带来了与 Kubernetes 兼容的便利，同时降低了用户的设备使用成本，并且可以一致访问、管理。Kubernetes 为了兼容业界各厂商的加速设备，通过扩展设备模式来管理设备，为此定义了一个支持硬件设备的设备插件框架（device plugin framework），只要厂商按照这个框架标准 API 来实现相应的函数接口，就可以在不修改现有 Kubernetes 代码的情况下，轻松安装，集成到 Kubernetes 集群环境中来使用这些设备。</p><p></p><p>在这个背景下，英特尔使用硬件设备插件、高级容器网络功能等技术，极大促进了 Kubernetes 集群高效管理。英特尔开发的所有硬件设备插件都是开源的，开发者可以访问（<a href=\"https://github.com/\">https://github.com/</a>\" intel / intel -device-plugins-for-kubernetes/）&nbsp;获取详细信息。</p><p></p><p>从高级容器网络功能层面来看，为了方便集成，Kubernetes 支持英特尔等第三方网络提供商的网络技术方案，也定义和复用了容器网络接口（CNI），也就是说只要是符合 CNI 规范的网络解决方案都可以很方便的集成到 Kubernetes 环境中。</p><p></p><p>因为网络的使用模式非常多，场景也非常复杂，Kubernetes 基于英特尔硬件网络设备开发了多种 CNI 来满足其功能、性能等方面的需求。英特尔 为厂商和用户提供了更多的网络选项，比如用户需要聚合网络接口，可以部署 Bond CNI；如果需要多网络接口，可以安装 Multus CNI；如果是性能方面的需求，则可以使用 DPDK。</p><p></p><p>可以说，设备插件和网络模块极大地丰富和提升了集群的能力，同时也为这些设备的可观测性提供了机会。英特尔也使用多项数据中心关键技术，帮助 Kubernetes 构建功能模块和全栈解决方案，从而确保最终用户获得底层硬件的全部优势。</p><p></p><p>对于 Kubernetes 来说，其社区核心开发集中在应用编排上，对于底层硬件资源的对接。在架构设计上，Kubernetes 从兼容的角度出发，定义了相应的 API，如 CSI、CNI、CRI、Device Plugin 等，开发者无需修改代码便可快速构建功能模块。</p><p></p><p>对于运维人员来说，有了 Kubernetes 更高层的资源访问接口和管理能力，他们就可以实现其自动化全周期运维和监控，其可靠性和弹性得到大大提升，同时也获得了提高整个集群效率和资源利用率的能力。</p><p></p><p>当然了，探讨 Kubernetes 集群的高效管理的前提还是要保证其“稳定性”。只有保障了集群的稳定性，才能谈高效管理。如果想要有效避免云宕机事件的发生，首先要做到的是有效降低内存错误问题。因为在云场景下，一旦出现内存故障问题，往往会造成严重的灾难性后果，比如主机操作系统挂起、系统崩溃、宕机等，将严重影响企业用户的服务质量。</p><p></p><p>通常来讲，内存错误一般可分为可纠正错误和不可纠正错误，其中“可纠正错误”是可以通过纠错码克服双页值之差的内存模块的一些可纠正错误，而“不可纠正错误”又分为由于内存条实体硬件错误造成严重后果的（Fatal Error）、不需要处理的（UCNA）、必须处理的（SRAR）和选择处理的（SRAO）。然而，云主机出现内存错误的原因是多种多样的，而且很多时候难以复现，面对这种情况，就要具体事件具体分析。</p><p></p><p>当下解决“内存错误”问题比较理想的方案是应用英特尔® MCA Recovery 与 MFP 技术，目前第三代英特尔® 至强® 可扩展处理器已经支持这两项技术，这两项技术基于对内存错误的分析和了解，能够对 SRAR 和 SRAO 这两种错误进行预测和恢复，可以有效降低内存故障对主机的影响，可以帮助企业用户的云服务完善故障预警，并降低内存故障影响，为用户提供更稳定、更高效的云服务。</p><p></p><p></p><h2>Kubernetes 从中心走向边缘，应用编排被重新定义</h2><p></p><p></p><p>CNCF 在年度调研中提到，作为云原生最重要的编排工具之一的 Kubernetes 已经是无处不在，在包括边缘计算的不同场景里面均有使用。其调查显示，“在边缘计算领域，大概 76% 都会使用到 Kubernetes。”</p><p></p><p>多云环境在边缘计算领域已经变得越来越普遍，Kubernetes 也将云原生技术从中心拓展到边缘，云边基础设施技术架构实现统一，业务侧也实现了云边自由编排部署。举一个例子，在边缘计算场景下往往存在着大量异构设备，而且每种设备都具独特性，利用 Kubernetes 提供的扩展的 API 资源（如 CRD 功能）对这些设备进行数据建模，可以实现设备的统一管理。</p><p></p><p>Kubernetes 在边缘侧的优点确实很明显，但 Kubernetes 毕竟是从集中式数据中心的场景里诞生出来的技术，在边缘场景下也出现了水土不服，比如在“高效管理多云以进行应用程序编排”方面就出现了新挑战：</p><p></p><p>延迟：对新的低延迟应用程序用例（如 AR/VR）的要求。例如，IIOT 需要超低延迟响应。这需要在更靠近用户的边缘上支持一些应用程序功能；带宽：在边缘处理数据避免了将数据传输到云中进行处理的相关成本；上下文 /‍Promixity‍：当边缘服务器需要本地上下文时，在用户附近的边缘服务器上运行应用程序的某些部分；隐私 / 法律：某些数据可能需要保留在某个地理位置。</p><p></p><p>面对这些新挑战，英特尔积极寻求解决方案，如今英特尔的边缘多集群编排器（EMCO）与 Kubernetes 的合作，已经可以很好地把这些问题解决掉。EMCO 是 Kubernetes 的地理分布式应用程序编排器，运行级别高于 Kubernetes，并与运行 Kubernetes 的多个边缘服务器 (和云）交互。</p><p></p><p>EMCO 的主要目标就是跨多个集群自动化应用程序和服务的部署，其充当中央协调器，可以跨不同第三方的地理分布边缘群集管理边缘服务和网络功能。与其他多集群编排相比，EMCO 侧重于以下功能：</p><p></p><p>注册多个地理上分布的群集；跨不同集群编排组合应用程序（由多个单独的应用程序组成）；将边缘服务和网络功能部署到分布在不同群集上的不同节点；监视跨不同群集部署的边缘服务和网络功能的运行状况；根据计算、加速和存储需求，通过部署意图协调边缘服务和网络功能；支持来自不同企业的多个租户，同时确保租户之间的机密性和完全隔离。</p><p></p><p>在 EMCO 的加持下，从中心走到边缘的 Kubernetes，应用编排将重新被定义，编排能力变得更强壮。</p><p></p><p></p><h2>写在最后</h2><p></p><p></p><p>Kubernetes 的先进性和集群的高可用是毋庸置疑的，但当所有企业都选择 Kubernetes 后，却因为其复杂性陷入了新思考，甚至 Kubernetes 的创立者和核心推动者 Google 本身都逃避不开这个问题，“Kubernetes 就像一把双刃剑，既是最佳的容器编排技术，同时也存在相当高的复杂性和应用的高门槛，这个过程中往往会导致一些常见性错误”。</p><p></p><p>在实际的应用场景中，除了认知复杂性和开发复杂性，Kubernetes 带来的最重要的影响是其颠覆了传统的运维模式。Kubernetes 是一个非常复杂的系统，拥有多样的 API 及模块插件，这便直接增加了可被攻击面，让很多企业在安全性运维方面都无从下手。而且随着 Kubernetes 集群规模的增长，运维难度呈线性增长。</p><p></p><p>但我们要知道的是，所有技术都有双面性。容器革新了云计算的基础设施，而 Kubernetes 则搭建了一个统一的基础设施抽象层。通过 Kubernetes 集群，我们无需关心任何基础设施层的细节，就能快捷地构建出任何我们想要的且高可用的业务系统，这也是 Kubernetes 被称为云计算界的 Linux 以及 “Platform for Platforms” 的根本原因。</p><p></p><p>好在，随着英特尔等多家厂商不断提供硬件设备及技术供给，Kubernetes 的复杂性问题在逐渐弱化。在未来，集群的稳定性和系统的高可用将不是问题，在软件技术的调教下，硬件潜力将发挥到极致，软硬件的完美配合将交付最佳实践。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/05/05ef2590f5fbfcb13bc83fe93a57b825.png\" /></p><p></p>",
    "publish_time": "2022-07-18 14:04:45",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "数据爆炸时代，要怎样应对云存储挑战？",
    "url": "https://www.infoq.cn/article/aRF1vxkot7iYMpagqW8b",
    "summary": "<p>2022年，远程办公已经变得常态化，拥有可靠的云端数据存储系统或服务比以往任何时候都更加重要。</p><p>&nbsp;</p><p>个人云存储概念的兴起始于 2007 年，当时 Dropbox CEO Drew Houston在无数次丢失U盘后创建了第一个个人小型企业云存储服务。这在当时是一个激进的想法，但却受到了广泛关注。</p><p>&nbsp;</p><p>在今天，每个业务都应该是数据驱动的业务，覆盖各行各业。数据的爆发性增长，尤其是云上数据增长已经是新常态。</p><p></p><h2>大数据的下半场，是存储的较量</h2><p></p><p>&nbsp;</p><p>随着全社会<a href=\"https://www.infoq.cn/article/xcGOTqX6kvWPcczM1uaN\">数字化转型</a>\"进入深水区，数据大爆炸带来业务突飞猛进发展的同时，数据增长也会带来很多问题，存储并不是简单的只是把0和1的比特放在物理介质上这么简单，这里存在大量业务层面需要关注的问题。</p><p>&nbsp;</p><p>第一是敏捷和成本。如何应对海量数据增长所带来的成本急速上升与<a href=\"https://www.infoq.cn/article/Czgb3NcFAta4rzx35RBI\">数据存储</a>\"服务敏捷性能之间根深蒂固的矛盾；第二是数据本身多样化的需求。我们的业务数据来源是纷繁复杂的。数据以各种方式来自各种渠道，而且各个业务数据本身的性质不同，所使用的方式也是不一样的，我们要思考的是如何设计不同的存储服务满足不同业务的需求。第三，在数据安全合规被提到空前重要的大背景下，数据存储如何解决安全与合规问题，也是当下面临的主要挑战之一。</p><p></p><h2>亚马逊云科技在云端存储上的技术实践</h2><p></p><p></p><p>为了应对数据存储方面的挑战，<a href=\"https://www.infoq.cn/article/SmqdcS8oCNKROtYECzjF\">亚马逊云科技</a>\"自2006年就推出第一个云存储服务Amazon S3。时至今日，Amazon S3已经走过了16年。</p><p>&nbsp;</p><p>亚马逊云科技大中华区产品部总经理陈晓建表示： “存储服务是亚马逊云科技在成立之初就开始提供的云服务，16年来我们仍然像创立之初一样，通过不断创新来夯实这一基础服务在市场上的优势地位。如今，亚马逊云科技的存储服务已经全面覆盖了对象存储、块存储、文件存储、数据备份、数据容灾、以及数据传输与边缘处理各个方面，客户可根据自身需求灵活选择。随着企业工作负载上云的常态化，云端数据量持续爆发式增长，企业对存储成本、性能等也提出了更高的要求。我们希望能通过存储服务的不断创新，为客户提供功能更强大并兼具成本效益的存储服务，帮助他们在云端开展业务创新。”</p><p>&nbsp;</p><p>为了解决上述提到的种种挑战，亚马逊云科技在存储服务产品的设计上给出了三种不同的解决对策：</p><p>&nbsp;</p><p>1、智能分层。通过智能分层彻底解决<a href=\"https://qcon.infoq.cn/2022/guangzhou/track/1379\">数据</a>\"的成本和数据的可用性、敏捷性之间的矛盾。</p><p>2、专门构建。开发多种针对于不同场景下<a href=\"https://qcon.infoq.cn/2022/guangzhou/track/1379\">数据应用</a>\"的存储产品来解决企业应用多种多样，需求各有不同的问题。</p><p>3、统一数据保护。通过一站式云服务备份系统，解决数据安全合规的问题，同时也解决数据备份所带来成本增加的问题。</p><p></p><h3>智能分层</h3><p></p><p>&nbsp;</p><p>无论在任何业务中，用户都会面临数据增多，存储成本也就随之上升的问题。而数据成本只是其中一个最容易解决的问题，光解决成本问题不能解决存储本身带来的所有问题——数据来源多种多样，使用方法也不同，针对不同数据的类型我们应该有不同存储的产品相对应。</p><p>&nbsp;</p><p>那么，应该怎么定义数据的类型？陈晓建表示，“这里有一种比较直观而且比较准确的方式：数据的温度。”</p><p>&nbsp;</p><p>数据使用有不同的频率，比如说交易系统里的交易数据，To C系统里的用户日志，这些数据需要被频繁访问，这些数据称之为热数据；一些企业的业务数据，包括网站的数据，这些数据有可能需要按周或者按月的频率访问，因为不像热数据一样被访问得这么频繁，这些数据我们称之为温数据；再往下一层，手机相册数据、企业的其他数据，这些数据可能是几个月，甚至是一两年才会访问一次，这些数据我们可以把它作为归档数据，一旦存储之后它的访问频率并不是很高，这样的数据我们称之为冷数据；还有一种数据，一旦写入之后访问频率非常低，但是由于合法合规的要求，这些数据必须要能够进行持久化的存储，比如医疗影像的数据，国家规定这些数据必须存放30年，任何时候要用都可以及时拿出来。从业务特点来讲，这些数据本身对于存储读写性要求并不很高，但是要求数据的持久性，而且数据的量非常大，所以用户对于数据整个存储成本有着非常高的要求，这是冻数据。</p><p>&nbsp;</p><p>从这一点上看，可以简单把一些数据分为热、温、冷、冻四个层次，对于云厂商来说，显然对于这四种不同的数据要有不同的存储服务才是最合理的。</p><p></p><h3>专门构建不同的云存储服务</h3><p></p><p>&nbsp;</p><p>成本问题解决了，但是不同数据类型的来源各不相同，使用方式不一样，需求也不一样，用户要怎样构建不同存储的服务来满足业务的需求？亚马逊云科技提出的对策是专门构建不同的云存储服务。</p><p>&nbsp;</p><p>实际上，到今天为止IT化已经基本完成，每个应用和业务都会产生大量的数据。我们面对的数据类型也已经足够多了，如果要把这么多种类的数据做一个大概的区分，基本可以分为两大类：第一类是云原生的现代化应用产生的数据，第二类是传统的云端企业应用产生的数据。</p><p>&nbsp;</p><p>云原生应用产生的数据指的是电商、游戏、社交等等，这些应用大部分本来就是诞生在公有云上的应用所产生的数据；第二类企业应用不是公有云之后才产生的，相反这些企业应用，像ERP、CRM、EDA已经存在很多年了，公有云之前它们就存在了，它们依赖的技术和架构并不会考虑云的存在，所以很显然这两个应用产生的数据在处理上是非常不一样的。</p><p>&nbsp;</p><p>数据存储对于云原生应用来说非常简单。社交媒体、电商本身在云上构建，大量的业务依赖云的微服务架构，也很适应云的应用方式，很显然对云原生应用来说希望存储是一样的架构。云的特点是用户不用考虑底层架构，无论是伸缩、全覆盖、运维，这些事情都是云来完成的，用户只需调用简单的API接口就全搞定了，自然存储也应该是这样。</p><p>&nbsp;</p><p>陈晓建表示，对于云原生应用的云存储服务问题，亚马逊云科技的解决办法有两个：第一个是Amazon S3，第二个Amazon EFS。</p><p>&nbsp;</p><p>Amazon S3 就是一个简单的API，不用管任何背后的细节。大量的应用和非常多的云存储都是放在Amazon S3上的，它已经成为了对象存储工业界的事实标准。</p><p>&nbsp;</p><p>有很多的业务依然依赖于传统的文件系统的调研方式，所以亚马逊云科技还提供了Amazon EFS。Amazon EFS是共享文件系统，是完全兼容容器、无服务器化的应用。Amazon EFS系统不光是跟云原生一样不用做任何的配置和运维，而且和其他亚马逊云科技的服务高度集成，用户一旦用容器就可以非常容易的挂载到Amazon EFS里。所以Amazon EFS和Amazon S3能够很好地解决云原生业务的需求。</p><p>&nbsp;</p><p>而企业应用就复杂多了。在公有云诞生之前，就存在大量的各种各样的企业应用。对企业应用来说，</p><p>&nbsp;</p><p>首先，已经存在很多之前就有的特点，比如说快照、镜像、远程复制、多种存储协议等等，如果要上云必须要支持这些，如果在ERP和企业应用上云的时候需要按照Amazon S3和Amazon EFS的接口重新改变代码，那么没有企业用户愿意这样做。所以保证兼容对企业来说是非常重要的工作。其次，企业应用还有各个行业的特点，比如说高性能计算、大数据分析，可能对网络、机器性能各方面都有很高的要求，这些是在提供企业应用存储服务的时候必须要考虑的。</p><p>&nbsp;</p><p>企业在云端有各类不同的业务场景，对共享文件存储有着不同的要求，陈晓建列举了一些目前存在的比较主要的四大类企业应用：</p><p>&nbsp;</p><p>第一类是Windows为主的应用，底层服务要完全满足Windows的环境，包括ACL文件访问控制权限，包括Active Directory兼容。第二是<a href=\"https://qcon.infoq.cn/2022/guangzhou/track/1383\">高性能计算</a>\"，不可能通过单个节点完成，一定是多节点协同的，数据是共享的。真正在跑的高性能集群往往是几百个节点，甚至几千个节点共享一份数据，这样就带来一个问题，首先第一个需要共享的存储，第二个由于这份数据要被几百个、几千个节点同时访问，所以对整个存储的性能和吞吐率也提出了非常高的要求。第三是基于各类多种多样的企业应用，这些应用要上云必须完美的兼容和支持好之前提供的功能。第四是大数据的环境，往往需要一些特殊的支持，包括像ZFS，需要具备高吞吐、低延时的技术。</p><p>&nbsp;</p><p>陈晓建表示：“从存储角度来说这四类代表了企业应用里四个主要的不同的场景，是需要我们考虑的，所以我们专门构建了一个场景化应用FSx家族，X意味着多种文件存储类型，专门为企业不同业务需求构建”。</p><p></p><h3>统一数据保护</h3><p></p><p>安全与合规也是数据存储时不容忽视的重要一环。</p><p>&nbsp;</p><p>尽管市场上数据备份工具的种类多种多样，但数据备份在技术层面来讲，仍然存在着很多问题。</p><p>&nbsp;</p><p>首先很多系统都是使用起来非常复杂的，操作起来有一定门槛；第二，怎么保证安全合法合规的要求又是一大挑战；第三，由于做备份一定会带来额外的成本，如何解决这个问题？</p><p>&nbsp;</p><p>基于以上问题，亚马逊云科技推出了Amazon Backup，用户可以借助可Amazon Backup来满足其业务连续性和合规要求。</p><p>&nbsp;</p><p>Amazon Backup可统一保护客户应用程序的数据，跨越亚马逊云科技的计算、数据库以及文件，对象和块存储服务。在过去一年，亚马逊云科技将Amazon Backup扩展至Amazon S3和VMware工作负载，让客户使用统一的数据保护策略，即可配置、管理和监督数据的备份与恢复，此外还涵盖Amazon Elastic Compute Cloud (Amazon EC2)、 Amazon EBS、Amazon Relational Database Service (Amazon RDS)、Amazon Aurora、Amazon DynamoDB、Amazon DocumentDB、Amazon Neptune、Amazon FSx、Amazon EFS和Amazon Storage Gateway。用户还可以使用Amazon Backup Audit Manager生成审计报告来帮助其满足合规要求，并使用Amazon Backup中内置的细粒度访问控制以及Amazon Backup Vault Lock，保持备份不变，防止意外或恶意删除。</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2022-07-18 14:07:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何搭建云原生大数据平台的K8s底座 | 《InfoQ技术公开课》",
    "url": "https://www.infoq.cn/article/H6zC2DAM0momQ9wpqQi5",
    "summary": "<p></p><blockquote>作者：金津，智领云科技云平台研发经理，华中科技大学计算机系硕士。加入智领云6年多，长期从事云原生、容器化编排领域研发工作，主导了智领云自研的BDOS应用云平台产品开发，并在多个大规模项目中成功实施落地，在大规模容器化编排系统方向有丰富的实践经验。</blockquote><p></p><p></p><p>伴随着数字化转型脚步的加快，大数据已成为企业经营管理的主要手段之一，越来越多的行业也选择通过大数据来实现业绩增长。今年年初，CNCF中国区总监陈泽辉在2022云原生超级英雄会上表示，Kubernetes (K8s)已无处不在，越来越多的人在使用云原生和Kubernetes。数据时代，企业如何让云原生大数据平台借力K8s以发挥最大价值，今天我们就跟着智领云科技云平台研发经理Jason一起来深入了解一下。</p><p></p><h1>&nbsp;一、背景介绍</h1><p></p><p>&nbsp;</p><p>什么叫云原生架构</p><p>&nbsp;</p><p></p><blockquote>并不是运行在云主机上的程序或者容器化的程序就是云原生程序。</blockquote><p></p><p>&nbsp;</p><p>过去十年，随着云计算的发展，云原生技术架构逐步被更多的科技企业采纳和应用，其概念可归纳为以下几点：</p><p>&nbsp;</p><p>Containerization：可运行代码必须容器化发布</p><p>Dynamic management：动态配置服务，按使用量付费</p><p>Micro-service：使用类似于K8s的云操作系统面向资源池发布和运维微服务，而不是自己面向节点操作</p><p>Orchestration:&nbsp;&nbsp;使用底层云平台操作系统的分布式管理体系，而不是自己独立管理</p><p>Automation:&nbsp;&nbsp;大部分运维操作由代码完成，而不是手工操作</p><p>&nbsp;</p><p>云原生架构的优势</p><p>&nbsp;</p><p>使用云原生架构带来的好处很多，其优势归纳起来大概可以有以下几点：多租户、按需扩容、高效迭代、降低成本，以及安全性和合规性。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/b5/b5bda8df7d93c5e67619678f68c035bb.png\" /></p><p></p><p>智领云联合创始人 &amp; CEO彭锋博士曾以Twitter公司为例，强调云原生架构的优势。</p><p></p><p></p><blockquote>“Twitter从2011年开始建设自己内部的私有云平台，我们看到的是业务开发效率数量级的增长，同时避免了部门墙，避免了数据孤岛和应用孤岛（因为都必须遵守云平台和其上的大数据平台的发布规范）。从80台机器的Hadoop集群，到8000台机器的全局数据平台，在统一集群中不断扩展数据能力矩阵，支撑业务运营。很多数据能力建设的工作，也因为应用的云原生化成为可能。”&nbsp;</blockquote><p></p><p></p><p>对比企业在使用传统大数据平台时遇到的困难和难点，云原生架构的优势便能够更好地凸显出来。那么，云原生架构又是如何解决这些难点，成为如今大数据平台搭建的市场趋势呢？</p><p>&nbsp;</p><p>传统大数据平台的难点，主要体现在其组件安装运维复杂：</p><p>&nbsp;</p><p>每个大数据组件都有自己的安装流程，系统要求，第三方库支持要求独立的分布式管理，高可用，容错，日志，授权，鉴权机制难以实现对于多租户，资源隔离，审计，计费的支持工具体系复杂，无法支持CI/CD，系统测试，质量控制无法实现大数据组件及应用的混合调度，资源使用率低</p><p>&nbsp;</p><p>因此，数据应用的开发流程及管理散布在各个系统组件中，缺乏统一全局的管理，开发运营效率低。</p><p>&nbsp;</p><p>传统大数据平台存在的问题，已经逐渐无法支撑数据驱动业务运营更为丰富的需求，所以呈现出来的市场趋势就是大数据平台的云原生化。具体来看：</p><p>&nbsp;</p><p>K8s基本已成为云平台的标配，我们只需要适配K8s即可新的大数据组件更多的以云原生的方式发布Hadoop会被云原生存储+资源调度取代，现有Hadoop集群的工作负载需要迁移原始的大数据平台已经建设完毕，DataOps的需求出现云原生应用的普及，数据源逐渐标准化，在线集成处理成为可能数字化转型需要低门槛，低代码的自助型平台</p><p></p><h1>二、规划设计</h1><p></p><p>&nbsp;</p><p>接下来，我们要讨论的是怎样规划设计这样的云平台系统，这部分可以从基础设施层（IaaS）、平台服务层(PaaS)，以及应用交付层来看，而每个层面都需要结合当前的业务规模和需求来权衡一些问题，比如</p><p>&nbsp;</p><p>IaaS：基础设施管理成本的权衡PaaS：K8s的版本管理、监控告警日志集成应用交付：如何隔离容器编排层的复杂概念，专注于应用开发</p><p>&nbsp;</p><p>我们的目标是要去交付一个K8s云平台，需求可以先拆分为以下三大方面：</p><p>&nbsp;</p><p>首先，IaaS 层的建设，我们要决定是托管在公有云，还是自建私有云，或者是最复杂的混合云架构；</p><p>&nbsp;</p><p>其次，PaaS 层的建设，我们要决定是用原生的K8s，还是发型版的K8s（各公有云厂商的K8s服务，或者像Kubesphere、Rancher、OpenShift这些面向私有发布的发行版等）；</p><p>&nbsp;</p><p>最后是应用交付的体系，我们的目的不是为了搭建K8s而搭建，交付了K8s平台之后，更重要的是如何快速、灵活地将业务系统“搬”到K8s平台上来，并在未来能够充分利用好K8s容器编排的各种特性，例如容器运行时/网络/存储接口、故障自动迁移、弹性伸缩、租户控制等。</p><p>&nbsp;</p><p>针对以上三个方面的设计规划，其现状及问题包括：</p><p>&nbsp;</p><p>IaaS层：最主要的是管理成本的权衡，公有云搭建最快，具备公有云产品使用的能力即可，管理成本相对较低，但产品价格很贵；私有云需要有虚拟化平台建设及运维的能力，管理成本相对较高；混合云前两者的能力都需要，还需要具备网络基础设施建设的能力，管理成本最高。</p><p>&nbsp;</p><p>PaaS层：官方开源版本无任何定制，但要构建一套完整的生态系统，需要自行搭建例如仓库、监控、报警、日志、负载均衡等额外的系统，技术选型可控但对团队能力要求高；发行版一般提供一套比较完备的生态系统，但技术选型往往不可控，容易被绑定，另外难以满足自定义需求的时候，还是需要自行建设；除此之外，K8s的版本发布非常快，如果想用新的特性或者修复bug，需要跟上新版本，但底层平台升级往往是非常吃力且容易出事故的。</p><p>&nbsp;</p><p>应用交付：K8s的优势是容器化编排能力很强，一开始看上去像海面上一座优美的小岛；劣势是它的系统架构、概念原理、管理使用非常复杂，等深入了解了之后才发现小岛原来只是露出海面的冰山一角；对于应用开发者来说，平台工程师应该把容器编排层的能力抽象隔离并封装简化，让上层用户专注于应用开发，不需要承受整个冰山的重量。&nbsp;</p><p></p><h1>三、实现路径</h1><p></p><p>&nbsp;</p><p>结合规划设计各层面的具体实践，接下来要讲一讲我们自己的实现路径。</p><p></p><p>首先，在基础设施层和平台服务层，面向公有云场景，我们的实践是基于阿里云容器服务ACK去构建在公有云场景的K8s平台。</p><p>&nbsp;</p><p>ACK 整合了阿里云虚拟化、存储、网络和安全能力，提供高性能可伸缩的容器应用管理能力，支持企业级容器化应用的全生命周期管理。</p><p>&nbsp;</p><p>ACK当前支持的版本为：1.22.3 和 1.20.11，仅发布Kubernetes双数号的大版本，版本支持策略如下：</p><p>&nbsp;</p><p>集群创建：ACK支持Kubernetes两个大版本的创建，例如v1.16、v1.18。当新版本Kubernetes发布时，较老的一个版本将不再开放创建功能。</p><p>&nbsp;</p><p>升级和运维保障：ACK保障最近的三个Kubernetes大版本的稳定运行，同时支持最新版本往前两个大版本的升级功能，例如当前最新版本为v1.20，则ACK支持v1.18、v1.16的升级功能。</p><p>&nbsp;</p><p>工单答疑：ACK仅提供最近的三个Kubernetes大版本的技术支持。</p><p>&nbsp;</p><p>那么，在私有云场景中，我们的建设实践是采用了VMware的一套技术架构，物理机采用DELL的PowerEdge系列。</p><p>并在物理机上部署VMware ESXi，通过VMware vCenter Server将多台物理机资源组成资源池，组成虚拟化管理平台。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/eb/ebcde34049964c017d9044b0524199f2.png\" /></p><p>&nbsp;</p><p>除此之外，在私有发布场景中，还需要去部署K8s的整个系统，我们选用了青云的KubeKey。</p><p>这款开源K8s安装器项目，可以轻松、高效、灵活地单独或整体安装 Kubernetes 和 KubeSphere。</p><p>&nbsp;</p><p>支持的Linux 发行版本</p><p>Ubuntu 16.04, 18.04, 20.04Debian Buster, StretchCentOS/RHEL 7SUSE Linux Enterprise Server 15</p><p>&nbsp;</p><p>支持的Kubernetes 版本</p><p>v1.17: &nbsp; v1.17.9v1.18: &nbsp; v1.18.6v1.19: &nbsp; v1.19.8v1.20: &nbsp; v1.20.6v1.21: &nbsp; v1.21.5 (default)v1.22: &nbsp; v1.22.1</p><p><img src=\"https://static001.geekbang.org/infoq/1d/1d84216ba7ff1e977649377a295ae19b.png\" /></p><p>&nbsp;</p><p>使用起来也比较简单，具体操作如下：</p><p>&nbsp;</p><p>创建集群</p><p>./kk create cluster -f config.yaml</p><p>添加节点</p><p>./kk add nodes -f config.yaml</p><p>删除节点</p><p>./kk delete node  -f config.yaml</p><p>删除集群</p><p>./kk create cluster -f config.yaml</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/58/58aed2a3176d17309625543f6b09c1d7.png\" /></p><p>&nbsp;</p><p>在应用交付层，我们的实践是基于KubeVela这一引擎来做平台建设。</p><p>&nbsp;</p><p>KubeVela 作为一个开箱即用的现代化应用交付与管理平台，使得应用在面向混合云环境中的交付更简单、快捷。使用 KubeVela 的软件开发团队，可以按需使用云原生能力构建应用，随着团队规模的发展、业务场景的变化扩展其功能，一次构建，随处运行。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/80/80e7c795d22f28bcad1c487cde693ce7.png\" /></p><p>&nbsp;</p><p>KubeVela 围绕着云原生应用交付和管理场景展开，背后的应用交付模型是 Open Application Model，简称 OAM ，其核心是将应用部署所需的所有组件和各项运维动作，描述为一个统一的、与基础设施无关的“部署计划”，进而实现在混合环境中标准化和高效率的应用交付。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/56/56b5936fa949a6663cb762d17eacda30.png\" /></p><p>&nbsp;</p><p>为什么要用 KubeVela？</p><p>&nbsp;</p><p>云原生技术的发展趋势正在朝着利用 Kubernetes 作为公共抽象层来实现高度一致的、跨云、跨环境的应用交付而不断迈进。然而，尽管 Kubernetes 在统一底层基础架构细节方面表现出色，它并没有在混合的分布式部署环境之上提供应用层的软件交付模型和抽象。我们已经看到，这种缺乏统一上层抽象的软件交付过程，不仅降低了生产力、影响了用户体验，甚至还会导致生产中出现错误和故障。</p><p>&nbsp;</p><p>然而，为现代微服务应用的交付过程建模是一个高度碎片化且充满挑战的事情。到目前为止，绝大多数试图解决上述问题的技术方案，要么过于简单以至于无法覆盖实际生产使用中的问题，要么过于复杂难以落地使用。云原生带来的基础设施能力爆发式增长也决定了新一代的应用管理平台不能以硬编码的方式做能力的集成和 UI 的构建，除了满足基础的功能和场景，平台本身的扩展能力成为了新时代应用管理平台的核心诉求。这就意味着平台不仅要简单易用，还要能够随着应用交付和管理的需求复杂度提升来不断扩张，让开发者自助式的接入和使用，充分享受云原生生态的红利。</p><p>&nbsp;</p><p>这也是 KubeVela 出现的核心价值：它既能够简化面向混合环境（多集群/多云/混合云/分布式云）的应用交付过程；同时又足够灵活可以随时满足业务不断高速变化所带来的迭代压力。它本身是一个面向混合交付环境同时又高可扩展的应用交付引擎，满足平台构建者的扩展和自建需求；同时又附加了一系列开箱即用的扩展组件，能够让开发者自助式的开发、交付云原生应用。</p><p>&nbsp;</p><p>KubeVela 核心功能</p><p>&nbsp;</p><p>统一的应用交付模型：KubeVela 创新性地提出了开放应用模型（OAM）来作为应用交付的顶层抽象，该模型支持交付任意类型的工作负载包括容器、数据库甚至是虚拟机到不同的云和 Kubernetes 集群中。用户无需关心任何基础设施细节，只需要专注于定义和部署应用即可。应用只需要一次编排，就可以随处运行，免去了适配不同平台的痛苦。</p><p>&nbsp;</p><p>声明式交付工作流：KubeVela 的整个交付模型完全是由用户声明式驱动的，兼顾用户体验和健壮性，其控制循环能够有效避免配置漂移，且具备多租权限控制能力。用户可以通过 CUE 语言（一种源自 Google Borg 系统的数据配置语言）自由的根据需求场景来设计和选用交付工作流中的每一个步骤，满足业务快速增长的需求，同时持续保证生产环境面向终态的稳定性。</p><p>&nbsp;</p><p>多集群/混合云应用交付控制平面：KubeVela 原生支持丰富的多集群/混合环境持续交付策略，也支持跨环境交付。这些交付策略为你的分布式交付流程提供了充足的效率和安全的保证。KubeVela 提供的中心化管控能力也减轻了到每一个集群去排查问题的负担，针对不同的平台提供统一的体验，为了享受自动化交付的便利，你再也不需要成为 Kubernetes 专家。</p><p>&nbsp;</p><p>KubeVela vs.&nbsp;传统&nbsp;PaaS 平台</p><p>&nbsp;</p><p>传统 PaaS (如 Heroku，Cloud Foundry 等) 提供完整的应用程序部署和管理功能，旨在提高开发人员的体验和效率。在这个场景下，KubeVela 也有着相同的目标。</p><p>&nbsp;</p><p>不过，KubeVela 和它们最大的区别在于其可扩展性。</p><p>&nbsp;</p><p>KubeVela 是可编程的。它的交付工作流乃至整个应用交付与管理能力集都是由独立的可插拔模块构成的，这些模块可以随时通过编写 CUE 模板的方式进行增/删/重定义且变更会即时生效。与这种机制相比，传统的 PaaS 系统的限制非常多：它们需要对应用类型和提供的能力进行各种约束来实现更好的用户体验，但随着应用交付需求的增长，用户的诉求就一定会超出 PaaS 系统的能力边界。这种情况在 KubeVela 平台中则永远不会发生。</p><p>&nbsp;</p><p>此外，KubeVela 是一个独立于运行时集群的应用交付控制平面（这是我们认为的下一代 PaaS 系统的合理形态），而现有的 PaaS 则往往选择以插件形式部署在运行时集群当中。</p><p>&nbsp;</p><p>下面，我们来举一个最简单的示例来看一看怎样将一个应用或服务，能够快速的在K8s上以容器化的方式运行起来：</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/f7/f72a8eac917c9066bd257731726c8038.png\" /></p><p>&nbsp;</p><p>交付Helm组件</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/b2/b266a8b2242703bdffd199d74427a1fc.png\" /></p><p>&nbsp;</p><p>在交付应用后，我们需要运维该应用来观测它的指标和日志。</p><p>&nbsp;</p><p>基于此，我们在KubeVela引擎构建云平台时，在日志、监控告警等层面做了相应的自动化的集成。主要的四个方面包括监控目标、监控面板、日志采集、告警规则特征上做了相应的开发。</p><p>&nbsp;</p><p>下图为监控目标特征、监控面板特征、日志采集特征、告警规则特征：</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/1b/1b21a5f3de93778091c059b5dadd982b.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8b/8b1238e9d83e1a39871675fadab888cf.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/08/08aa2bcba17925f2e4fb17de9fae73bd.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6f/6ff040018e5262c351bde82423d7fdad.png\" /></p><p>&nbsp;</p><p>四、向上赋能</p><p>&nbsp;</p><p>基于前面构建好的底层云平台系统，最后我们讲讲它的能力。</p><p>由于我们公司核心产品是一个一站式的云原生DataOps平台，底层的云平台系统搭载了上层的容器化大数据平台、数据集成开发平台、数据资产运营平台、数据质量平台等各种数据平台系统。</p><p>&nbsp;</p><p>从应用交付的角度，云平台赋能了数据平台的大数据及各种中间件快速容器化集成落地，例如典型的离线计算平台开源组件Hive、Spark、HDFS以及流处理平台开源组件Kafka、Flink等从多租户的角度，云平台赋能了数据平台的多租户管理，例如资源配额管理、鉴权、授权等从弹性的角度，云平台赋能了数据平台服务的弹性伸缩，以及集群级别的伸缩等从调度的角度，云平台赋能了数据平台服务的K8s原生调度（Spark on K8s），以及增强型调度框架如Volcano的集成等</p><p>&nbsp;</p><p>由于核心引擎提供的灵活、可扩展性，未来我们的云平台还能够将更多的K8s生态及系统能力纳入进来，向上面的业务层提供更强大的功能及性能支撑。</p><p>&nbsp;</p><p>具体来说，目前的阶段性成果体现在：</p><p>&nbsp;</p><p>大数据组件的快速交付：Hive、Spark、HDFS、Kafka、Flink...数据应用的快速开发集成：自定义程序发布统一的可观测性集成和展示：监控、告警、日志全系统的多租户实现：租户配额管理、服务/数据的鉴权+授权</p><p>&nbsp;</p><p>未来更进一步向上赋能DataOps的能力则体现在：</p><p>&nbsp;</p><p>开发运维：CI/CD，多环境管理可观测性：大数据平台全链路追踪弹性伸缩：大数据作业资源弹性、自适应增强型调度：Volcano Scheduler，提供更适合大数据系统的使用</p><p></p><p>欢迎收看《InfoQ技术公开课》了解更多精彩内容</p>",
    "publish_time": "2022-07-18 15:33:39",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何采用最适合团队的Ops文化，看看脸书、字节、深信服、三七互娱 | QCon",
    "url": "https://www.infoq.cn/article/7HvE4ZUCVNMyMqG1CheO",
    "summary": "<p>各种 <a href=\"https://qcon.infoq.cn/2022/guangzhou/track/1380\">Ops </a>\"文化概念激增，izOps、MarketingOps、<a href=\"https://qcon.infoq.cn/2022/guangzhou/presentation/4784\">DevOps</a>\"、<a href=\"https://qcon.infoq.cn/2022/guangzhou/presentation/4792\">AIOps</a>\"、<a href=\"https://qcon.infoq.cn/2022/guangzhou/presentation/4835\">MLOps</a>\"、DataOps……对于一个部门或团队来说，拥有正确的技能组合以及采用合适的 Ops 文化日渐重要。</p><p></p><p><a href=\"https://qcon.infoq.cn/2022/guangzhou/track/1383\">MLOps</a>\" 和 AIOps 是两个听起来比较相似的术语，用于指代当今行业内截然不同的两个学科。自从几年前引入这些术语以来，Google Zeitgeist 对它们的关注激增，正如谷歌趋势的图表所示。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/6d/6de79bac15b2f80b725cbdf154a780b3.png\" /></p><p></p><p>然而，除了少数从事这些领域项目的从业者之外，对于大多数人或对该领域有兴趣的人来说，MLOps 和 AIOps 的概念及其各自优势，都显得模棱两可，甚至认为没有差别。根据我的经验，这有两个原因。</p><p></p><p>首先，MLOps 和 AIOps 都隐含了对 DevOps 更广泛理解实践的引用。这让人不禁好奇——MLOps 和 AIOps 与 DevOps 有关吗？它们是从它派生出来的吗？如果是这样，它们又有何不同？</p><p></p><p>第二点便是关于 ML 与 AI 的区别，因为它们经常被互换使用。那它们是否一样？是否具有连续性？如何是，两者的终点和起点又分别在哪里?</p><p></p><p>我们必须先回答这些问题才能更好地理解 MLOps 和 AIOps，记住这些问题，我们将在本文的最后进行回复。</p><p></p><p>同样重要的是，我们要知道目前这两种学科相对来说还是处于婴儿期。术语 MLOps 和 AIOps 的出现也仅有 6-7 年，相对于其语义、应用程序和好处的可理解性而言，这意味着它们的炒作 / 流行因素目前很高。这种情况可能会持续一段时间，直到技术成熟，用例变得更加普遍和广泛理解。</p><p></p><p>O’Reilly 在《2021 年企业人工智能应用报告》中使用这个引人注目的饼状图说明了这一点，该饼图显示，只有四分之一的受访者表示他们已经成熟部署了人工智能技术。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/70/70bf145125a7bae50fda6f7fd24efd61.png\" /></p><p></p><p>据报道，该技术成熟采用的主要障碍是缺乏技术人员、数据质量存在问题、难以识别相关业务用例、缺乏公司文化支撑以及技术基础设施问题。该报告还发现，目前用于部署、监控、版本控制和跟踪模型和训练数据的工具之间明显缺乏标准化。</p><p></p><p>考虑到这些挑战，今天非该领域从业者在关于 MLOps 和 AIOps 技术、工具集和实践的可理解性上存在障碍也就不足为奇了。</p><p></p><p>在这篇文章中，我将阐明 MLOps 和 AIOps 的各自含义，它们旨在解决哪些问题，以及对于希望将其采用到其产品和服务构建策略中的团队来说，存在哪些工具。</p><p></p><p>在此之前，我们必须快速了解一下 DevOps 的概念，根据它的含义和解决的问题来构建上下文。这将有助于我们更好地理解 MLOps 和 AIOps 的基本原理，并明确它们之间的区别。</p><p></p><p></p><h3>DevOps</h3><p></p><p></p><p>DevOps 在 2007 年左右开始成为主流，以应对一个常见的组织问题，该问题影响了产品团队快速交付软件的能力。虽然遵循敏捷方法，但发布软件版本并将其部署到生产环境中，仍需要数周甚至数月的时间。</p><p></p><p>原因在于，开发团队和运营团队，各自为营。他们向组织内的不同执行领导汇报工作，彼此独立工作，有时甚至在一栋大楼的不同楼层或不同的大楼里工作。</p><p></p><p>DevOps 则是一种让开发人员和运营团队在软件开发生命周期（SDLC）的每个阶段共同协作的方式，并共享共同的目标和 KPI，这样使用敏捷可以更频繁地交付高质量的软件。</p><p></p><p>DevOps 的核心是三件事：</p><p></p><p>多学科技能：DevOps 团队共同具备编写、测试、部署、监控和管理产品堆栈组件的能力，包括核心代码、持久性存储、数据库以及正在使用的任何第三方库和服务。在此过程中，消除孤岛。工具：工具帮助并加速软件版本控制、自动化和监视，以便软件能够以连续的方式开发和部署。这称为持续集成和持续部署（CICD）。流程：DevOps 团队遵循敏捷方法，将路线图项目分解为较小的里程碑和任务。他们使用长篇故事和故事作为冲刺计划的一部分，将工作分配给团队成员。开发和运维之间的紧密联系确保了每个人在即将发布的版本方面都处于同一页面上。这样避免了意外，并加快了高质量产品和服务的交付速度。</p><p></p><p>DevOps 生命周期有六个阶段，此处使用众所周知的 Infinity Loop 进行演示。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/02/026a72cc1a38d6367ae2ab36bed50547.png\" /></p><p></p><p>在此上下文中，让我们深入了解 MLOps。</p><p></p><h3>MLOps</h3><p></p><p></p><p>MLOps 在 2015 年左右开始崭露头角，它承诺解决机器学习管道端到端交付的关键操作问题，类似于 DevOps 在近十年前解决的问题。</p><p></p><p>你一定想知道 - 机器学习管道的这些问题具体是什么？为了让它更具体，先看一下典型的 ML 管道（来源：Gartner）是什么样的，</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f2/f2061b6fa376fd2517a79868d8e72b40.png\" /></p><p></p><p>要操作这一流程，必须具备三种不同的技能。首先，数据管道本身是数据来源、清理和转换的地方，数据归数据工程师所有。然后是对训练数据集的管理，接着是模型的创建和验证，这些都属于数据科学家。最后，部署、监视和持续维护属于操作部门。</p><p></p><p>因此，我们有三个具有专业技能的团队，他们需要相互协调，以端到端的方式拥有和运营整个管道。如果这些团队在孤岛后面独立运作，并且无法使用敏捷实践进行协作，则会导致整个产品的交付延迟和质量问题。</p><p></p><p>回想一下，这些问题与 DevOps 要解决的问题类似，当拥有专业技能的团队但是团队之间没有紧密协作时，就会出现这些问题。所以在这方面，你可以把 MLOps 看作是 DevOps 原则在机器学习管道中的应用。DevOps 是一个由开发人员和 IT/ 运维人员组成的多学科团队，而 MLOps 则加入了数据工程师和数据科学家，消除了他们之间的隔阂。</p><p></p><p>MLOps 生命周期有九个阶段，此处使用 DevOps Infinity 循环的修改版本进行演示。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/0c/0cea35412727d11cb866b880a7d82c80.png\" /></p><p></p><p></p><h3>AIOps</h3><p></p><p></p><p>术语 AIOps（IT 运营的人工智能）是由 Gartner 在 2016 年创造的，但与 MLOps 不同，它几乎与 DevOps 没有任何关系! 相反，它指的是使用智能算法解决已知的 IT 问题，并自动化重复的工作。</p><p></p><p>在我们深入探讨 AIOps 之前，这是重新审视并回答我们在文章开头提出的两个问题的最佳时机。这将使接下来的内容更易理解。</p><p></p><p>问题 1：MLOps 和 AIOps 是否与 DevOps 相关？如果是这样，如何？</p><p></p><p>是的，MLOps 与 DevOps 相关，因为它将 DevOps 的多学科和敏捷原则引入了 ML 管道。MLOps 使数据工程、数据科学和运营团队能够更高效地管理这些管道。不，AIOps 与 DevOps 无关，AIOps 指的是使用智能算法解决已知的 IT 问题，并自动化重复的工作。AIOps 使 IT 团队更加高效。</p><p></p><p>问题 2：由于 ML 和 AI 倾向于互换使用，那么它们在 MLOps 和 AIOps 这两个词中的含义是什么？</p><p></p><p>在 MLOps 上下文中，ML 指的是完整的机器学习管道，包括数据源和清理、模型创建和验证以及部署和监控。在 AIOps 中，AI / ML 指的是用于异常检测、根本原因分析和帮助台自动化的技术和算法，例如决策树、随机森林等。</p><p></p><p>随着上述两个基本问题的解决，让我们继续关注 AIOps。</p><p></p><p>AIOps 的目标是什么? 可以使用 AIOps 自动化的常见 / 重复性 IT 任务有哪些例子?</p><p></p><p>Gartner 使用以下框架来定义 AIOps 的适用性和优势。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/cc/cc4643a05a2ddc76768421499b6519f9.png\" /></p><p></p><p></p><p>正如我们总结的那样，AIOps 的核心是将机器学习应用于大数据，以实现以下业务成果：</p><p></p><p>监控：从安全性、可用性、性能或客户体验角度检测异常行为，以便主动响应潜在问题。服务台：自动执行票务任务，使用智能自动聊天代理解决客户问题，或从知识库中回答问题，以便快速有效地解决帮助台问题。自动化：AI 驱动的根本原因分析（例如，确定不兼容的库版本作为笔记本电脑出现故障的原因），或预测性分析，以便在潜在的流量峰值时发出警报，快速做出基础架构设施调整决策。</p><p></p><p>如果你所在的公司不同开发团队之间的合作还不够互通高效，那么不妨来关注下业界不同行业 XOps 的最新实践进展。将于 7 月 31 日 -8 月 1 日举办的 <a href=\"https://qcon.infoq.cn/2022/guangzhou/schedule\">QCon 全球软件开发大会</a>\"（广州站）上，组委会策划了【<a href=\"https://qcon.infoq.cn/2022/guangzhou/track/1380\">XOps</a>\"】专题，特别邀请了来自 <a href=\"https://qcon.infoq.cn/2022/guangzhou/presentation/4785\">Meta（Facebook）</a>\"、<a href=\"https://qcon.infoq.cn/2022/guangzhou/presentation/4792\">字节跳动</a>\"、<a href=\"https://qcon.infoq.cn/2022/guangzhou/presentation/4756\">深信服</a>\"、<a href=\"https://qcon.infoq.cn/2022/guangzhou/presentation/4784\">三七互娱</a>\"、<a href=\"https://qcon.infoq.cn/2022/guangzhou/track/1380\">虎牙直播</a>\"等国内外不同业务方向的技术专家，希望给你的团队答疑解惑。</p><p></p><p>QCon 全球软件开发大会广州站<a href=\"https://qcon.infoq.cn/2022/guangzhou/schedule\">日程</a>\"已上线官网，50+ 技术实践案例首次对外公开分享，点击<a href=\"https://qcon.infoq.cn/2022/guangzhou/track\">此处</a>\"一览专题详细演讲提纲。门票限时优惠即将结束，前沿案例分享不可错过。感兴趣的同学联系票务经理报名：15600537884（同微信）</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f3/f3d4382dc7daf57be6a887ee098123ec.jpeg\" /></p><p></p><p>原文地址：</p><p></p><p><a href=\"https://www.dragonsegg.xyz/mlops-vs-aiops-whats-the-difference/\">https://www.dragonsegg.xyz/mlops-vs-aiops-whats-the-difference/</a>\"</p><p></p>",
    "publish_time": "2022-07-18 15:50:29",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "这群WebAssembly大佬创业失败了：有时从 JS 迁移到 Wasm 并不值当？",
    "url": "https://www.infoq.cn/article/lx1NyUdpRJ03XTuU8x4J",
    "summary": "<p></p><p>&nbsp;</p><p></p><blockquote>通常能找到比WebAssembly或Rust更简单的方法来做性能改进。</blockquote><p></p><p>&nbsp;</p><p>WebAssembly（Wasm） 最早是在 2015 年由 JavaScript 的创造者 Brendan Eich 提出的。继 JavaScript（JS） 之后，它是第一种得到普遍支持的语言。万维网联盟（W3C）在 2017 年开发了 WebAssembly，WebAssembly 允许网站用诸如Rust、C/C++、Java、Python等编程语言编写代码，并像 JavaScript 一样在 Web 浏览器中运行它。</p><p>&nbsp;</p><p>随后，WebAssembly 迅速成为一种主流技术，被主要的浏览器供应商采用。从 WebAssembly开始崭露头角那一天起，很多开发人员就在讨论一个问题：“WebAssembly 是否会杀死 JavaScript？”</p><p>&nbsp;</p><p>虽然有很多人猜测 WebAssembly 的出现意味着 JavaScript 的寿终正寝，但Zaplib开源库的创建者现在给大家带来了一个否定的答案。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d1/d19899f3460e7d78cf1e5858f67ff6e4.png\" /></p><p></p><p>&nbsp;</p><p>Zaplib团队从编写代码到探索实际应用场景，总共花了一年时间，以失败告终后，他们发布了一篇出色的事后分析文章，告诉大家为什么说有时候“从JavaScript迁移到 WebAssembly 不值得”。</p><p>&nbsp;</p><p>从失败中学到的东西往往比从成功中学到的要多得多，但是显然很少有人愿意把失败的经验拿出来分享。Zaplib团队显然诚意十足，有网友评价说：“很多软件工程师都想方设法证明他们在一个问题上花费的时间和工作量是合理的”，“Zaplib是我见过的不屈服于沉没成本谬误的最好例子。”</p><p>&nbsp;</p><p></p><h2>Zaplib团队想干什么</h2><p></p><p>&nbsp;</p><p>Zaplib是一套开源库，用于使用 WebAssembly 和 Rust加速 Web 应用程序。它能帮助大家使用简单的 API&nbsp;在Rust中编写高性能代码，并与现有JavaScript代码顺畅匹配。</p><p>&nbsp;</p><p>Zaplib的目标是降低在浏览器中构建性能密集型应用程序的门槛。虽然在JS之内也有办法让运行速度加快，但随着时间推移，大量优化元素也可能提升应用的维护难度。而在Rust中，开发者只需少量优化就能获得高性能，从而解放出时间和精力处理更重要的内容。</p><p>&nbsp;</p><p>自从 2005 年左右开始转向多核处理器以来，越来越多的场景需要实现更高的性能，软件需要变得更加并行。Rust 是一种针对性能和安全性进行了优化的编程语言，许多应用程序已经使用 Rust 来显着提高加载时间和响应速度。而另一方面，Wasm 也一直在给大家带来一些非常惊人的性能提升，Figma是使用Wasm的典型案例，Figma文件是在C++/Wasm中处理的，这确实能他们带来巨大的速度提升。</p><p>&nbsp;</p><p>另一方面，Zaplib创始人<a href=\"https://janpaulposma.nl/cv/\">JP Posma</a>\"，他是一位具有18年编程经验的计算机科学家，认为使用手动内存管理（大量 ArrayBuffers）、WebWorkers 等在浏览器里开发密集内容的应用程序非常痛苦。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d1/d1cf095f83d3ee1d29be2965a65cf6bf.png\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>所以，他联合一些技术大佬一起开发了Zaplib ，希望借此帮助大家提升应用程序的性能。5个月前，他们还根据 MIT 许可和 Apache 许可（2.0 版）条款将Zaplib进行了开源：<a href=\"https://github.com/Zaplib/zaplib\">https://github.com/Zaplib/zaplib</a>\"</p><p>&nbsp;</p><p>他们表示，Zaplib解决的是JS与浏览器速度很慢的问题，希望用户能将JS增量移植为Rust/Wasm加速应用程序运行，可以从小端口入手再逐步扩展，进而接管整个应用程序。从长远来看，这就是面向下一代堆栈（「Unity for apps」）的演变。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/96fde8129d889d895e0111184ad9b28c.png\" /></p><p></p><p>&nbsp;</p><p>今年2月初，他们宣布基于这个开源库成立一家创业公司，并努力探索商业模式，希望有客户可以使用Zaplib，围绕渐进式移植到 WebAssembly。</p><p>&nbsp;</p><p>他们也希望借此弄清楚这个库到底适合哪些用户的需求，作为尝试，他们还曾把这套实验方案发布在Hacker News上，想看看会不会启发出某些有趣的Zaplib用例。</p><p>&nbsp;</p><p>他们写了两篇流量非常好的文章，《Typescript的速度与Rust持平：Typescript++诞生》（<a href=\"https://news.ycombinator.com/item?id=30947680\">https://news.ycombinator.com/item?id=30947680</a>\"）和《Show HN：Zaplib——使用Rust+Wasm加速你的webapp》（<a href=\"https://news.ycombinator.com/item?id=30960509\">https://news.ycombinator.com/item?id=30960509</a>\"）。</p><p>&nbsp;</p><p>但显然好流量也没有转化成“任何实际应用”，他们认为这已经很能说明问题了：“缺乏实际应用场景”。</p><p>&nbsp;</p><p></p><h2>为什么Zaplib毫无用处？</h2><p></p><p>&nbsp;</p><p>Zaplib 希望在 Rust 驱动的 WebAssembly 中一次一个部分地重写 Web 应用程序，从而将性能提升多达 10 倍。虽然想法不错，但在与试点用户合作之后，他们发现之前的预想并不完全靠谱。</p><p>&nbsp;</p><p>在事后分析文章中，他们讲了四个试点合作案例：</p><p>&nbsp;</p><p>用户1：他们不仅实现了最终将整个应用移植为Rust的“整体愿景”，同时也似乎获得了增量移植的加速空间。Zaplib团队花了一周时间，把此用户的模拟器移植到Rust，并希望速度能够显著提升。然而，最终速度只快了5%。在加速方法上，Zaplib团队主要使用的是更快的线性代数库，但JS中也有类似的库。Rust并未起到任何有决定意义的帮助。</p><p>&nbsp;</p><p>用户2：Zaplib团队将此用户的渲染器移植到由GPU加速的2d渲染器。结果非常理想，但良好效果源自渲染的GPU加速特性，也就是WebGL，跟Rust/Wasm没什么关系。用户也很犹豫到底要不要在自己的代码库中引入全新Rust工具链，而实际来看确实没有必要。</p><p>&nbsp;</p><p>用户3：他们是Zaplib的优秀用户，但使用的并非渐进式应用。如果Zaplib团队打算从零开始构建新应用，那他们的需求倒是比较合适，可问题在于：1）这样需要更大的API表面；2）无法与现有业务对接。</p><p>&nbsp;</p><p>用户4：在对设计原型进行基准测试时，Zaplib团队确实看到了10倍性能改进。然而，这些原型是从零开始构建而成的，所以并不能直接拿来做一对一性能比较。换句话说，Zaplib团队用JS重写没准也能得到类似的加速效果。性能提升的另一个重要来源，是使用了GPU加速渲染器，同样跟Rust/Wasm完全无关（与用户2的情况相同）。整个易用性（线性、零成本抽象）确实更好，原生构建也带来了2倍提速，但还不足以推动人们彻底转向新的堆栈。</p><p>&nbsp;</p><p>最后，Zaplib团队指出，在某些情况下，Rust确实比JS更快，但这类情况比预想的要少，而且性能一般也就翻一倍，大多数情况下达不到10倍。</p><p>&nbsp;</p><p>“只有真正依赖Rust的零成本抽象特性时，才能实现10倍的巨大收益——这要归功于内存布局和对垃圾回收（GC）的规避，因此处理100万个Rust微结构的速度确实比处理100万个JS对象更快。但这种情况其实相当罕见，在增量调整中就更别指望了。即使10倍性能改进基本不成立，工程师们自然不会愿意接受这样一套需要重新学习、重新维护的工具链和技术堆栈。</p><p>&nbsp;</p><p>我们自己肯定不愿意，自然也不能强迫其他人。总之，要想实现性能改进，一般都有比转向Rust/Wasm更简单的方法。”</p><p>&nbsp;</p><p>另外，他们还特地强调，虽然Figma在用Wasm，但仔细观察就会发现，他们使用Wasm其实更多是个“历史遗留问题”——他们的目标是在C++中构建以保护原生应用，而不是追求更高性能。Figma文件是在C++/Wasm中处理的，这确实能带来巨大的速度提升，但真正让Figma性能脱颖而出的其实是他们的WebGL渲染器。</p><p>&nbsp;</p><p></p><h2>写在最后</h2><p></p><p>&nbsp;</p><p>大佬们的创业最终宣告失败了，否定了基于 Zaplib 建立初创公司的核心假设。</p><p>&nbsp;</p><p>这并不意味着 WebAssembly 很糟糕或没有帮助。谷歌地球和Photoshop都被 WebAssembly 移植到了网络浏览器上，像微软这样的公司正在为更多的开发人员构建框架以进行同样的过渡，它的存在绝对是有原因的。但 JavaScript 在过去几年中也发生了显着的变化，在 Chrome、Microsoft Edge 和其他基于 Chromium 的浏览器中处理 JavaScript 代码的“V8”引擎不断变得更快。虽然WebAssembly 已经为Web带来了几年前不可能存在的新一波应用程序，但不要指望所有 JavaScript 很快就会消失。</p><p>&nbsp;</p><p>在博客文章最后，他们为自己失败的创业发出了感慨：“事实证明，基准测试和客户访谈很容易被自欺欺人式地理解成确凿证据。这次失利也让我们意识到：如果必然失败，那快速失败一定好过缓慢失败！”</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://zaplib.com/docs/blog_post_mortem.html?continueFlag=7dfc40344266025cf05d7577e9e0492b\">https://zaplib.com/docs/blog_post_mortem.html?continueFlag=7dfc40344266025cf05d7577e9e0492b</a>\"</p><p><a href=\"https://sktodaysnews.com/03/05/2022/technology/javascript-web-apps-arent-going-anywhere/\">https://sktodaysnews.com/03/05/2022/technology/javascript-web-apps-arent-going-anywhere/</a>\"</p><p>&nbsp;</p>",
    "publish_time": "2022-07-18 16:13:09",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "智能家居浪潮来袭，如何让机器看懂世界",
    "url": "https://www.infoq.cn/article/SGzD2ixLIJifmcQ9r858",
    "summary": "<p>从智能单品到全屋智能，随着消费者对生活品质追求的提升，智能化产品逐渐走入大众家庭，从而推动智能家居市场蓬勃发展。从 2017 年开始，智能家居设备已经应用于日常生活各项任务。2017 年其市场规模约为 4.3 亿美元。据 IDC 预测，智能家居市场年复合增长率为 18.5%，2022 年智能家居设备销售额将达到 9.4 亿美元。面对潜力无限的智能家居市场，各企业纷纷发力，然而由于智能家居产品多涉及音视频技术，自行开发往往门槛过高。如何轻松构建具有实时计算机视觉功能的应用程序？亚马逊云科技 Tech Talk 特别邀请解决方案架构师李寅祥带来分享《基于 Amazon KVS 打造智能视觉产品》。</p><p></p><h1>智能家居应用场景与挑战</h1><p></p><p></p><p>早在 2015 年左右，智能家居设备就已经出现。2017 年，智能家居开始应用于生活的各个场景。早期的智能家居产品还是手动控制，如通过开关去控制酒店窗帘。近两年，智能家居产品已转变为远程遥控的形式，如可远程控制通电和断电的智能插座，手机可操控的智能扫地机器人等。目前，智能家居的应用场景主要可分为三个部分。</p><p></p><p>第一类，家庭智能自动化。常见的智能控制类产品有智能照明系统，可以手机远程控制灯的开关与灯光模式，此外，扫地机器人、智能家庭助手等产品也属于此类。</p><p>第二类，家居网络的连接。这类比较普通和普遍，应用最广泛的就是无线路由器类设备。</p><p>第三类，家居安全。不管在国内还是海外，家居安全类智能产品都是近年比较热门的品类，如安防摄像头、可视门铃等。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fc/fc995d9870bec1e12846f1ea19a03bbf.png\" /></p><p></p><p>在智能家居的三大应用场景中，智能视觉类产品占有相当大的比重，但这类产品的开发却存在一定的复杂性。原因主要在于两个方面：</p><p></p><p>第一，打造和管理 IoT 应用的复杂性。智能视觉类的物联网设备大多需要进行数据交互。首先，需要保证设备连接及所产生数据的安全性；其次，设备的数量极有可能到达百万级，如何以可扩展、低成本的方式来管理成千上万的设备也是一大难题；此外，保证多种供应商设备及语音助手的互操作性也比较复杂。</p><p>第二，复杂的媒体服务设计和实现。智能视觉产品因为涉及音视频流的传输、处理，也存在一定的技术复杂性。其一，编码对技术有一定门槛，需支持多种媒体流技术、协议、编码以及开发环境；其二，需要创建及管理基础设施以实现安全、快速及可靠的流媒体传输；其三，扩展性需求高，要能够支持百万级设备，视频流对于带宽的要求是文本消息流的多倍，设备数量达到百万级时，如何保证后端服务器的可靠性和稳定性是非常棘手的问题；其四，音视频涉及非常专业的技术，如视频的编解码、压缩、传输等，存在技术壁垒，需要拥有音视频专业知识的工程师团队。</p><p></p><h1>为视觉设备附加人工智能能力</h1><p></p><p></p><p>亚马逊云科技在智能视觉和可视化类智能家居产品进行了深入地探索与创新实践。家居安防监控类的产品有安防摄像头、可视化门铃，集成摄像头电器有宠物喂食器，还有健身器材、健身设备等品类相关的智能产品等等。亚马逊云科技是如何解决视觉类智能家居产品存在的问题呢？主要是依托于 Amazon IoT+KVS 的解决方案。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/62/62c401224f42f32cff6042fd4849a3f9.png\" /></p><p></p><p>如图所示，从左到右分别是设备端、云平台端、消费端。设备端通常是带有摄像头的设备或 IoT 设备，如安防摄像头、无线路由器、语音助手等。云平台端主要提供 IoT 相关的能力以及管理设备连接。Amazon KVS 主要用来进行视频接收存储和处理，此外，亚马逊云科技还提供机器学习、数据库等产品，帮助开发者完成业务目标。Amazon IoT+ Amazon KVS 一站式解决方案具体是如何工作的呢？</p><p></p><p>Amazon KVS（Amazon Kinesis Video Streams），其名字直接翻译的意思是实时的动态流的视频流。具体来说，它是一个完全托管的媒体流服务，能够从百万设备中安全的接收视频流数据，并按照时间进行存储。当用户想要回看某个特定时段的视频，可按照时间进行检索，快速方便地获取原始视频。</p><p></p><p>Amazon KVS 将视频存储起来后，最重要的是将视频给到消费端去消费。在消费方面，Amazon KVS 提供实时与按需回放、实时与批处理两种方式。实时查看用于查看摄像头现在所处的实时环境、状态；按需回放就是定位到一个特定的时间段进行查看。那么，基于 Amazon KVS 是如何打造智能视觉产品的呢？</p><p></p><p>首先，是媒体摄取。Amazon KVS 的媒体摄取主要有两种方式，第一，它可以直接从摄像机中获取视频流。第二，它可以使用与同一网络上的设备连接的代理 / 网关。两种方式都可以使用?Kinesis Video Streams producer SDKs。</p><p></p><p>其次，是 Producer SDK。Producer SDK 其实就是通过 SDK 将视频流的信号打到 Amazon 打到 Amazon KVS 上。它提供的 SDK 多种多样，比如，最底层的 C SDK 层，适用于期望固件级集成的硬件设备制造商。上层的 Docker 镜像层则适用于针对特定操作系统的应用开发者。</p><p></p><p>第三，是储存和检索媒体。媒体流进入 Amazon KVS 之后可以时间为索引进行存储，最长可以存储十年，并且支持按小时或者按天检索。不仅如此，开发者还可以通过简单的 API 实现存储策略的修改、检索实时与历史媒体，并能够轻松监控和审计使用情况。另外，比较重要的一点是 Amazon KVS 在开始传输或者接收视频流和存储视频流的时候都是可以加密的。</p><p></p><p>第四，实时 / 历史视频回放。Amazon KVS 的回放支持 HTTP Live Streaming (HLS) 、Dynamic Adaptive Streaming over HTTP (DASH) 两种协议。HLS 相对来说比较标准，Web 浏览器可直接播放。DASH 是有对应的播放器来提供播放。在音视频编码方面，Amazon KVS 支持多种音频和视频编码格式。</p><p>通过 Amazon KVS 视频流完成接收后，如何通过机器学习的方式来进行内容感知？大致有以下几种方式：</p><p></p><p>第一，采用 Amazon KVS 与 Amazon Rekogniton Video 整合参考架构。Amazon Rekogniton 是一个 API 服务，可直接用来进行图片或者视频的分析，也就是说，视频流可以在 Rekogniton 里面进行常见的人脸识别或者物品检测。</p><p></p><p>第二，当 Amazon Rekogniton 中常用的图片或者视频识别能力，无法满足用户的场景需求的时候，就需要进行更加个性化地识别场景定制。这种情况就需要借助 Amazon SageMaker 去训练模型，模型训练完成后再进行推理。Amazon SageMaker 是一个托管式机器学习平台，代码可直接放在 Amazon SageMaker 上进行训练，当训练完成后，可以很方便的把模型部署到 EC2 上并进行后续的推理。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0f/0fd6a39ab661d7c6a9cef95b1b163b20.png\" /></p><p></p><p>上图是 Amazon KVS 和 Amazon Rekognition Video 整合的参考架构。由采集端、存储端、处理 / 分析端三部分组成。该实例在 Raspberry Pi 环境中运行，用 RTSP 摄像头去拉流，拉流完成之后，通过 C++ 的 Producer SDK 打到 KVS 上，后面用 Rekognition Video Processor 处理实时的视频流，处理完成后，会把结果放到 Kinesis Date Streams 消息管道中，消息管道将数据给到 Kinesis Data Firehose，对消息管道的数据稍作转换加工，然后投递到 Amazon S3，由 Amazon S3 将结果存储起来。另外一条线路，可以触发 Amazon Lambda，Amazon Lambda 将调用 IoT Core 对设备下发控制指令。</p><p></p><p>在实际应用过程中，首先，需要创建一个 Rekognition &nbsp;Video stream Processor 来处理视频流；然后指定一个 Kinesis Date Streams 的位置；第三，也是比较重要的一点是指定搜索目标，比如在人脸识别场景中就是进行人脸的 ID。用户可按需调整阈值，来控制检测的相似度，检测完成后可对应定义名称及备注。</p><p></p><h1>WebRTC 实现双向实时通讯</h1><p></p><p></p><p>实时双向通讯在安防摄像头或可视门铃场景下是比较常见的需求。Kinesis Video Streams WebRTC 的定位就是满足此需求。它具有超低延迟的流媒体直播，支持数百万相机设备的双向交互，其特点有：</p><p>低延迟的实时媒体流：点对点音视频直播，1 秒以下的播放延时；实时，双向通讯：嵌入式设备、移动设备与 Web 应用程序实现双向通讯；兼容标准：与 Web 和移动平台兼容，轻松实现无插件播放；全托管：完全托管的 WebRTC 信令, TURN, STUN 服务 。易于使用的 SDK。</p><p></p><p>WebRTC 不仅仅是一个媒体流协议。它是一个开放的标准实时通信与技术规范。它的技术组成中有四点比较关键。</p><p></p><p>第一，信令。信令用于交换连接元数据，也就是双方支持哪些协议，支持哪些编码等。第二，联通。联通即建立点对点的连接。很多设备都是在防火墙后面，点对点的连接也叫打洞，如果点对点连接失败，还要通过中继服务器来进行转发，通过中继服务器建立连接。第三，媒体交换。它能够低延迟交换媒体和任意数据。第四，加密。这一点所有服务都类似，端到端的加密对于保障安全性非常重要。</p><p>分享中，李寅祥以可视门铃的案例介绍了实时通讯大概的流程，如下图。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5c/5c7e1c49c5fd3d7b36e5d832114e9525.png\" /></p><p></p><p>左边是一个可视门铃，右边是手机 APP。假如有人按门铃。可视门铃会向服务器发出请求，请求再转到手机端，手机端接受请求后将尝试互相交换信息，交换的信息主要是协议编码等。交换完成后，会尝试通过 STUN 打洞，如果打洞不成功，那么就会通过 TURN 服务进行中继转发。通常来说，两个设备处于同样的网络的情况下比较容易打通。</p><p></p><p>在 Kinesis Video Streams WebRTC 中有几个比较重要的概念：</p><p></p><p>首先是信令频道。信令频道允许应用程序通过交换信令消息来发现、设置、控制和终止点对点连接的资源。其次是 Peer。Peer 通常指移动客户端、Web 应用程序、Camera 等。第三是 Master。Master 用于连接到 Channel，与任意的 Viewer 实现点对点通信，一个 Channel 只有一个 Master。第四是 Viewer。Viewer 用于连接到 Channel，只能与 Master 实现点对点通信，一个 Channel 最多可以有十个 Viewer。</p><p>此外，还有服务组件和 SDK。SDK 主要支持协议嵌入式 SDK 和客户端 SDK。嵌入式 SDK 支持的视频编码协议有 H264 和 VP8，以及支持的音频编码协议有 Opus 和 G711。客户端的 SDK 是与 WebRTC 兼容的浏览器和移动平台无缝协作的开源客户端 SDK。</p><p></p><p>Kinesis Video Streams WebRTC 还可以与 Alexa 语言助手进行协作。假设有人在按智能可视门铃，但是用户刚好在厨房做饭，不方便去直接查看，可以语言控制 Alexa。Alexa 会与 WebRTC 交换数据，交换完数据后可建立双向语言通讯，可视门铃的视频信号将直接显示到 Echo Show 上，就可以直接看到门口是谁。</p><p></p><p>视觉安防相关的产品，安全是企业和用户关注的重点。亚马逊云科技针对智能产品的安全性也有相应的解决方案。摄像头在向 Amazon KVS 做推流的过程中，是需要进行验证的，只有验证通过后，经过授权才能获取资源的访问权限。摄像头利用 &nbsp;IoT 设备的证书来访问资源，流程如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cd/cd85ab75c3682d2e1d80e072e8a70334.png\" /></p><p></p><p>首先，认证的 IoT 设备发起一个 Credentials provider 的认证请求，IoT 的认证请求会去检测证书是否合法、有效。如果合法，就会生成一个临时凭证，设备端拿到临时凭证后就可以基于这个临时凭证去调动亚马逊云科技的其他服务，如 Amazon KVS。临时凭证是有有效期的，当有效期过期后，将无法再进行访问。由此借助 Amazon IoT，就可以以一种安全的方式访问 KVS 资源。</p><p></p><h1>打造智能视觉产品的参考架构</h1><p></p><p></p><p>针对如何用 Amazon KVS 打造智能视觉产品，亚马逊云科技提供了一些比较推荐的方案。</p><p></p><p>基于 Amazon &nbsp;KVS 实现 IPC 云存</p><p></p><p>亚马逊云科技提倡无服务器架构。设备端按需推送视频流及其元数据至亚马逊云，视频数据保存至 Amazon KVS，视频原信息保存至 DynamoDB。手机端按需基于视频元数据获取回放 URL，通过播放器观看。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/27/27b10fa90115ab2f2662b07829ab9aa9.png\" /></p><p></p><p>基于 Amazon KVS 为 IPC 附加人工智能</p><p></p><p>相对来说，基于 Amazon KVS 为 IPC 附加人工智能 / 机器学习能力属于更高阶的功能，如检测门口是否有宠物或者包裹，甚至一些更加个性化的定制场景。它的实现分为三个步骤。首先，设备端推送视频流至 KVS；第二步，根据需要从视频提取图片保存至 S3；第三步，AI 处理模块可组合使用自建模型、Rekognition API 对图片、视频实现同步、异步推理，结果异常时通知手机客户端。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f1/f196080612aab741dc80c0940b944c76.png\" /></p><p></p><p>Amazon KVS 整合 Alexa</p><p></p><p>主要依赖 WebRTC 集成。左边是硬件设备，如安防摄像头、可视门铃等，里面会包含各种 SDK，中间是 Amazon KVS，右边是消费端。通过 WebRTC 连接到 Alexa 云，实现双向实时通讯。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/aa/aa33a3996a245daa927f4b127dac7100.png\" /></p><p></p><p>基于 Amazon KVS 打造智能视觉产品目前已有丰富的实践案例。</p><p></p><p>科技公司 Wyze Labs (Wyze) 将 Amazon Kinesis Video Streams 与 WebRTC 结合使用，以提高实时视频流的质量和在其相机产品和智能助手 (如 Alexa) 之间实现更好地连接。凭借此功能，Wyze 能够将 Wyze 新功能的上市时 间缩短 50%。Wyze 的高级首席架构师 Keith Ho 解释说:“在亚马逊云科技 上， 我们能够将时间线缩短 6 个月，并将工程成本减少两倍，因为基础设施、可扩展性、性能和系统已经存在。”</p><p>九安智能 2021 年起，正式和亚马逊云科技进入深度合作阶段，利用亚马逊云科技提供的全球广泛而深入的云服务，构建九安智能最新一代的音视频监控云平台。利用 Amazon KVS 构建九安智能的新一代音视频监控云平台，主要为用户提供远程实时的视频预览和录像查看、存储、云端的 AI 识别服务、智能音箱链接和推送报警信息。</p><p></p><p>分享的最后，李寅祥总结了 Amazon KVS 的几大优势，并提供了相关的参考资料供大家了解。</p><p></p><p>智能视觉市场技术复杂 &nbsp; &nbsp;Amazon IoT 使得您可以简便的构建可扩展的 IoT 应用管理物联网设备，而不需要维护任何基础设施。KVS 提供可扩展的方案用于接收、存储、分析及回放摄像头传输的媒体流。安全保障 &nbsp; &nbsp;使用亚马逊云科技提供的内置设备认证机制初始化设备，根据需要授权资源访问、加密数据，并主动检测威胁来确保设备、数据的安全。扩展性及互操作性 &nbsp; &nbsp;利用亚马逊云科技的基础设施便捷的批量注册百万级设备。使用 Amazon IoT 及 KVS 实现与 Alexa、Google Home 之类的语音助手集成。易于实现且实用的功能 &nbsp; &nbsp;通过 WebRTC 实现实时、双向音视频通信。无需额外软件，灵活存储不同的文件格式（mp4/mkv)。通过简单的 API 使用 HLS/MPEG-DASH 协议回看与其他亚马逊云科技服务集成进行分析从视频获取信息。专注于更快地打造解决方案 &nbsp; &nbsp;通过托管服务释放精力用于产品创新、研发。</p><p></p><p>参考资料</p><p></p><p>Fleet Provisioning -</p><p>https://aws.amazon.com/blogs/iot/how-to-automate-onboarding-of-iot-devices-to-aws-iot-core-at-scale-with-fleet-provisioning/?</p><p>IoT Authorization Calls -&nbsp;</p><p>https://docs.aws.amazon.com/iot/latest/developerguide/authorizing-direct-aws.html?</p><p>KVS Producer Libraries -&nbsp;</p><p>https://docs.aws.amazon.com/kinesisvideostreams/latest/dg/producer-sdk.html?</p><p>KVS Playback documentation -&nbsp;</p><p>https://docs.aws.amazon.com/kinesisvideostreams/latest/dg/how-playback.html?</p><p>KVS Developer Guide -</p><p>https://docs.aws.amazon.com/kinesisvideostreams/latest/dg/kinesisvideo-dg.pdf?</p><p>KVS Security -&nbsp;</p><p>https://docs.aws.amazon.com/kinesisvideostreams/latest/dg/security.html?</p><p>KVS WebRTC FAQs -&nbsp;</p><p>https://docs.aws.amazon.com/kinesisvideostreams-webrtc-dg/latest/devguide/what-is-kvswebrtc.html?</p><p>Wyze Labs-</p><p>https://youtu.be/c9crp1vQ0lI?t=1643?</p><p>感兴趣的开发者可扫描下方二维码</p><p></p><p>领取IoT行业资料大礼包👇</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cf/cf444a752f08570d09f83f4dc8746fc2.jpeg\" /></p><p></p><p>扫码加入IoT行业交流群👇</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/f4/f4e11981f4d081910c68f3e08319b002.jpeg\" /></p><p></p>",
    "publish_time": "2022-07-18 16:50:33",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Flink & 低代码：为应用实时计算铺平道路",
    "url": "https://www.infoq.cn/article/fIIRma2YkYYOMH0uVITY",
    "summary": "<p></p><p>嘉宾 ｜ 张颖</p><p>编辑 ｜ 贾亚宁</p><p></p><p>目前京东实时计算平台已经发展到了一定规模，且在 Flink 的应用上也积累了很多经验与反思。本次我们专访了京东数据分析优化部的算法工程师张颖老师，期待能从京东落地 Flink 的过程中获得一些应用 Flink 的经验和启发。</p><p></p><p>同时张颖老师也是已经上线的 QCon+ 案例研习社「Flink 在实时计算应用场景中的落地实践」专题的讲师，带来了<a href=\"https://time.geekbang.org/qconplus/detail/100110427\">「基于 Alink 实现 Prophet 时间序列模型」</a>\"的分享。</p><p></p><h5>InfoQ：你最近主要在做什么呢？</h5><p></p><p></p><p>我在京东数据分析优化部主要负责实时计算相关的工作，目前京东实时计算平台已经发展到了一定的规模，它紧跟社区，先后推动了批流一体、云原生等多个技术的落地。为了降低各业务实时计算的开发和学习成本，我们在原有的 Flink 计算引擎基础上研发了一套低代码的配置化编程系统，他学习成本低、易用性强、可移植性高，并且支持配置化编程。</p><p></p><h5>InfoQ：方便重点讲讲这个低代码的系统吗？它和传统的低代码平台相比有什么不同？</h5><p></p><p></p><p>这个低代码平台原计划是小白用户来使用的，可以通过拖拉拽直接生成一个 Flink 任务的引擎，但在实际使用的过程中，我们发现有开发经验的用户更倾向于通过简单编码来实现。这里举一个例子：对于复杂的 Flink SQL 而言，囿于产品本身的特性，需要限制部分操作或增加用户配置才能实现拖拉拽；但是有开发经验的用户直接修改 SQL 就可以直接达到目标。于是我们将这个平台调整了一下，在实现拖拉拽功能的同时开放一些配置，用户可以直接编程实现，这就完美地解决了上述问题。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/15/1597c63c75d60616c1079e91a57a267c.png\" /></p><p>上面这张图是我们实时框架的主要结构，包含：</p><p>process 层：这里统一了 DataStream、StreamSQL 和 Batch SQL（社区基本不再维护 DataSet），支持用户 UDF；operator 层，这里是具体的业务层，包括一些算子的执行策略，operator 之间的串联方式是有向无环图，可以实现用户任何方式的算子组装；node 层，这里支持用户将每个业务串联执行，用户将任务放在 AIFlow 里面，AIFlow 负责将各个任务正常调度。</p><p></p><h5>InfoQ：京东目前在哪些场景中使用 Flink，未来还会拓展哪些新的场景呢？</h5><p></p><p></p><p>京东的大部分场景在实时计算方面都已经切换到 Flink 了，像比如说京东的榜单服务，流式计算就已经完全切到 Flink 上了。这个榜单任务流式计算类似一个 TopN 的 Flink 任务，因为数据量比较大，我们把数据经过过滤、排序等操作，再放到 HBase 里面来实现 TopN。</p><p></p><p>还有机器学习场景，除了使用 Alink 的固有模型之外，我们还支持了 Alink 分布式调用 Python 和基于 Python 的小模型分布式训练。还有诸如样本拼接、Label 拼接、Feature 拼接等拼接场景，我们都希望可以实现批流一体。如果模型实时训练时出现了效果降低的情况，我们就需要回退一个版本，与此同时样本也全部都回滚。但是直接回滚 Kafka 里面的数据可能已经过期了，这时就需要借助离线，这里面会涉及到一些数据的 gap，但是如果在代码层面上完全实现了批流一体的话，会非常有利于这种 back filled 的场景。</p><p></p><p>既然样本分实时和离线的话，那么 Feature 和 Label 势必也是要分实时和离线的，所以代码层面流批一体的统一对开发者来说有非常大的好处。我们希望利用 Flink 将大数据生态以及机器学习生态紧密联合起来，让数据和机器学习更好地支持和服务于业务场景。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/47/479409fa39141c236c71ec650e830d27.jpeg\" /></p><p></p><h5>InfoQ：你认为 Flink 会取代 Spark 吗？为什么呢？</h5><p></p><p></p><p>Flink 在实时计算方面已趋于成熟，但是批流一体还是有待发展的，比如说我们在某个业务中用批式来实现，但是后来发现它不能完全解决问题，就想利用 Flink SQL 的批流一体无缝切换到实时，但在实现的过程中发现有些流式的 SQL 和批式的 SQL 写起来就是不一样的，并且他们包括 shuffle 等的底层原理也不一样。</p><p></p><p>经过实际的验证之后，我们发现当流式资源是批式资源的三倍时，它才能稳定下来，且相同数据量的情况下，批式的处理时间也比流式小。这是因为流式的数据是一条一条的，大部分的数据都存在于内存中，涉及到 join 的话，哪怕是用到了 RocksDB，也还是需要配置一定的内存（WriteBuffer、BlockCache 等）。</p><p></p><p>但是对于 Batch Mode 是有很多数据直接 shuffle 到了硬盘上，并且它是分阶段来执行的。在这种情况下 Batch Mode 需要的资源相对来说要少很多，但是资源问题没有解决的话，我们又没有办法将这些批流一体的代码上线。如果社区能够逐步解决这些问题，相对 Spark 来说 Flink 的优势会持续增大，接下来社区也会着重发展这部分。</p><p></p><h5>InfoQ：你对数据报警研究的比较深入，你认为一个好的报警系统要满足什么要求？</h5><p></p><p></p><p>传统的同环比、统计类报警过度依赖规则与阈值超参数的设定，存在报警不稳定、误报率高等问题，且从故障发生到报警时间较长，会给业务带来困扰，要检查一个报警系统的好坏，除了报警的延时，报警的准确之外，还有很多其他的评判标准，在这里我们只关心一种情况，就是如何将这个报警智能化。</p><p></p><p>比如京东榜单服务每天高低峰分别是 2000、1000 QPS，我们在设置报警时，大概率会将最高值和最低值设置为：2000 和 1000，也可能会有一个浮动的报警（一般浮动值设置后误报的几率也会增加）。我们假设某一天晚高峰的流量是 1200 QPS，由于它高于最低值，报警是不会预测到的，但是晚高峰应该是 2000 呀，这就偏离了业务的需求。</p><p></p><p>于是，我们研发了一个基于机器学习的报警，一般分为三步：</p><p>FFT 检查数据是否有周期性特点Prophet 进行时序预测DBSCAN 检测异常点</p><p></p><p>任何一个公司或者是业务的报警数据量都非常庞大，在海量数据实时涌入的情况下，我们一般会采用根据数据指标的数据并行的方式来进行模型的训练及预测，映射到 Flink 里面，我们就是将这些指标数据作为 key，然后以此 key 来进行 keyBy，达到让这些数据都分别落到相同的 subtask 里面去的目的。</p><p></p><p>在实现的过程中我们采用数据并行的方式训练模型，并且采用了模型训练和预估一体化的技术策略。这种基于机器学习模型的报警模式完美地解决了传统链路的不足，因此也解决了业务问题，可以做到提供人性化的报警服务。</p><p></p><h5>InfoQ：最后，对想要深入了解并应用 Flink 的小伙伴说些什么吧！</h5><p></p><p></p><p>我给大家分享一个我平常学习 Flink 的时候，经常采用的方式。</p><p></p><p>大家在遇到 Flink 的一些相对来说比较陌生的函数或者功能的时候，一般可能会去百度或是 Google，这种学习方式肯定没问题。但是对我自身而言最快的一种方式是，在使用搜索引擎之前先去 Flink 官网查资料，也可以直接把 Flink 的代码从 GitHub 上 Clone 下来，当我遇到一些问题时（比如遇到一个 Left join 不会写或是一个 data set 应该如何使用）就可以直接去代码库里全文搜索，得到的结果一般甚至都是带有测试用例的，这样就非常高效地解决了问题。</p><p></p><p>另外一种情况是遇到的新场景不知应该如何处理，大家最常见的应对方式可能是按照自己已有的思维来解决，这可能会因为自身的认识不足，使得方案明显不完善。我是这样应对的：访问一些 Flink learning 的网站，或者在社区内搜索相关的场景，有的时候也添加一些相关的钉钉群，在群里面问问别人的实现方案，这个时候往往都会有意想不到的收获。类似大厂案例的技术落地最佳实践的分享，也可以带来一些启发和指导。</p><p></p><p>概括来讲，我们日常就需要拓展一下自己的技术范畴和技术视野，比如 Flink learning 网站、社区公众号、钉钉群、Flink AI extend、Ververica 和 InfoQ 等媒体都会发一些相应的代码或者是测试包，这也是解决问题非常便捷的方式。</p><p></p><h5>作者简介</h5><p></p><p></p><p>张颖，京东数据分析优化部算法工程师，数据分析优化部实时方向负责人Alink、dl-on-flink Contributor，专注于 Flink 数据处理方向和机器学习方向。</p>",
    "publish_time": "2022-07-18 17:01:11",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]