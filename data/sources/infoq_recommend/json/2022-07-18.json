[
  {
    "title": "智源就“抄袭事件”发布最新通报：2处属于抄袭，已得到原作者谅解，相关责任人均已主动离职",
    "url": "https://www.infoq.cn/article/6EZ2UkwU0DA3ZWtmBYyJ",
    "summary": "<p>今年4月，一篇名为《A Roadmap for Big Model》（大模型路线图）的论文被爆出抄袭，该篇论文中涉及国内19家机构和百名AI学者，其中不乏业内知名AI学术大佬。</p><p></p><p>事件一出，舆论哗然，也把国内的AI学术圈推上了风口浪尖。</p><p></p><p>作为此篇论文第一单位，<a href=\"https://www.infoq.cn/article/WRKqEaLvQwlcCyt8hSHh\">北京智源研究院</a>\"立即对此事做出了积极回应，并邀请第三方专家对此事展开独立调查。智源研究院还就IEEE手册条款的理解和抄袭严重程度的认定，通过邮件咨询了IEEE学术出版规范负责人的意见。</p><p></p><p>历时三个月，7月15日，根据<a href=\"https://mp.weixin.qq.com/s?__biz=MzAxNDU2MTU5MA==&amp;mid=2649971323&amp;idx=1&amp;sn=155dd01fe9951449b4c81f13f491f856&amp;chksm=83968222b4e10b34d439e7ddb6aa06247a2dc9eab2ed01334ccb9177de38ed80ece2cdf5a4bb&amp;scene=27#wechat_redirect\">CCF</a>\"调查报告和IEEE专家反馈，智源研究院与16篇文章的通讯作者进行了沟通，对于存在问题文章的作者责任进行了核查与认定，并将调查和处理情况在官网上进行了通报。</p><p></p><p>以下为通报全文：</p><p></p><h3>1. 组织失察责任认定</h3><p></p><p>该综述报告由智源研究院大模型研究中心牵头组织、邀请国内外 19 个机构共 100 位科研人员分别撰写的 16 篇独立专题文章组成，每篇文章都有对应的撰写作者和通讯作者（除第 12 篇外），所有作者共同署名整个报告（这种组织模式参考了斯坦福大学“On the Opportunities and Risks of Foundation Models” (https://arxiv.org/pdf/2108.07258v2.pdf)&nbsp;一文的编撰方式）。综述报告首先上传至预印本网站 arXiv，原计划经过修改完善后再正式出版。</p><p></p><p>智源研究院大模型研究中心作为组织单位，对综述报告撰写中可能存在的风险隐患缺少充分考虑，未采取必要措施避免相关问题出现，对整个事件负有监督失察责任。</p><p></p><p>综述报告的第一作者（智源大模型研究中心人员）未严格按照学术出版规范的流程执行，在未与其他作者确认的情况下，于 2022 年 3 月 26 日将综述报告上传至 arXiv，负有主要组织责任。</p><p></p><h3>2.&nbsp;两处抄袭的责任认定</h3><p></p><p>综述报告 10 处被质疑片段中，2 处属于抄袭。</p><p></p><p>第 2 篇文章的 2.3.1 节存在共计 179 个单词的多句重复，在最开始明确标注了引用文献，但未明确区别引用文字，且篇幅较大，属于《学术出版规范 期刊学术不端行为界定》“三、论文作者学术不端行为类型”中的 “1.5 文字表述剽窃”：“成段使用他人已发表文献中的文字表述，虽然进行了引注，但对所使用文字不加引号，或者不改变字体，或者不使用特定的排列方式显示”，达到《IEEE 出版物服务和产品委员会操作手册》“对不同等级的抄袭行为进行判定的指南” 中“第 5 级”（认定要点为“对一篇文章的主要部分逐字复制，虽有引注但缺乏清晰区分”。</p><p></p><p>说明：抄袭共分 5 级，第 1 级最严重，第 5 级最轻微），由该文章的第二作者（智源大模型研究中心人员）完成，应负直接责任。该文章的通讯作者（智源大模型研究中心人员），未对该文章进行有效审查，应负失察责任。该篇文章第 2.4.3 节存在多句重复，有明确参考文献标注，属于规范引用。参与文章的其他作者撰写的部分未发现抄袭。</p><p></p><p>第 8 篇文章的 8.3.1 节存在 74 个单词的整句重复，无明确引用，属于抄袭，相关段落由该文章第一作者（智源大模型研究中心人员）完成，应负直接责任。该文章其他作者是文章初稿完成人，初稿不涉及被质疑内容。该文章第一作者未经通讯作者及其他作者同意将自己加为第一作者并对文章进行了大篇幅修改，文章发布前未与通讯作者确认，因此通讯作者和其他作者均没有责任。</p><p></p><p>上述两名作者已经按照 IEEE 手册的对应纠正措施向原作者致歉，并得到原作者谅解，履行了应该承担的相关学术责任。</p><p></p><h3>3.&nbsp;四处引用不规范的责任认定</h3><p></p><p>除前述 2 处抄袭外，综述报告 10 处被质疑片段中，尚有部分片段属于引用不规范，但不构成抄袭，其他被质疑部分属于规范引用。具体认定如下：</p><p></p><p>第 10 篇文章存在少数重复文字，是在明确添加标注引用参考文献情况下的转述，属于规范引用。</p><p></p><p>第 12 篇文章的 12.2.3 节存在共计 36 个单词的重复，无整句重复，相关内容由该文章第二作者完成。重复内容包括两个部分，一部分包含 17 个重复单词，属于规范引用参考文献；另一部分包含 19 个重复单词，在对相关领域介绍时，引用了其他论文引言部分对于本领域的总结，但在本句中未标注引用参考文献，属于引用不规范，但不构成抄袭。该文章无通讯作者，其他作者是文章的完成人，所撰写的部分未发现抄袭。</p><p></p><p>第 14 篇文章 14.2.2 节一处多句 63 个单词重复，有明确参考文献标注，属于规范引用。14.2.3 节一处一句 30 个单词重复，有明确参考文献标注，属于规范引用。14.2.2 节另存在一处一句 29 个单词的重复，文字上指明了引用对象，但本句没有直接添加引用，相关段落由该文章的第二作者完成；14.2.3 节另存在一处一句 27 个单词重复，在 14.2.3 节中有参考文献标注，在本句中没有直接标注，相关段落由该文章的第四作者完成，上述两处属于引用不规范，但不构成抄袭。该文章其他作者撰写的部分未发现抄袭。</p><p></p><p>第 16 篇文章 16.1 节一处存在多句重复，相关段落由第二作者完成。该段落起始处对参考文献有明确引用，后续其他句子存在本句未直接标注的情形，属于引用不规范，但不构成抄袭。该文章其他作者撰写的部分未发现抄袭。</p><p></p><p>综述报告第 3、4、5、6、7、9、11、13、15、17 篇文章未发现抄袭。</p><p></p><h3>4. 处理和整改情况通报</h3><p></p><p>智源研究院在质疑发生后，对照国家新闻出版署《学术出版规范 期刊学术不端行文界定》标准并参照《IEEE 出版物服务和产品委员会操作手册》对抄袭的认定指南，从严要求，安排可能存在问题文章的作者向原作者进行了书面致歉，均已得到原作者反馈和谅解。同时，安排第一作者完成从 arXiv 撤稿。上述的抄袭和引用不规范的调查结论也已通知所有作者并获得确认。对照《IEEE 出版物服务和产品委员会操作手册》对抄袭行为的处罚措施，智源研究院和相关责任人已经从严履行了应该承担的相关学术责任。</p><p></p><p>鉴于上述两处抄袭和组织失察责任人均为智源研究院大模型研究中心人员，智源研究院决定重组该部门，上述相关责任人均已主动离职。</p><p></p><p>除上述智源研究院相关责任人外，综述报告其他所有作者没有抄袭及学术不端行为。在此对此次事件给这些作者造成的负面影响和困扰表示诚挚歉意！</p><p></p><p>针对此次事件发现的论文发表流程中的风险漏洞，智源研究院已经整改了论文发表流程，并修订完善了科研诚信与学风建设制度。后续，智源研究院计划与学界和业界合作，制定更严谨的文献引用规范，开发论文和代码开源检测工具和系统，避免再次出现类似问题。</p><p></p><h2>事件回溯</h2><p></p><p>4月8日，谷歌大脑研究员Nicholas Carlini发文指出：</p><p></p><p></p><blockquote>我发现了机器学习研究领域发生了一件论文抄袭事件。一篇名为<a href=\"https://arxiv.org/abs/2203.14101\">《A Roadmap for Big Model》</a>\"（以下简称“大模型论文”）的论文，抄袭了我发表的名为<a href=\"https://nicholas.carlini.com/writing/2022/a-case-of-plagarism-in-machine-learning.html\">《Deduplicating Training Data Makes Language Models Better》</a>\"的论文中的几个段落&nbsp;。Nicholas Carlini表示，更令人沮丧的是，自己发表的论文并不是唯一被抄袭对象，这篇大模型论文至少抄袭了十几篇其他论文。</blockquote><p></p><p></p><p>此外，Nicholas Carlini还将论文中内容相似度比较高的地方用绿色进行了标注（左侧是大模型论文中的文本，右侧是原始论文中的相应文本）：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d0/d0295f83d27b9207a5ae9fa26d7b9c71.gif\" /></p><p></p><p>由于大模型论文最后的署名中涉及19家机构和100位AI领域知名作者，因此此事一出，在国内外学术圈里引发了极高的关注。</p><p></p><p>针对质疑，4 月 13 日，北京智源人工智能研究院发布了《关于 “A Roadmap for Big Model” 综述报告问题的致歉信》，首先向相关原文作者和学术界、产业界的同仁和朋友致歉，并公布了初步调查结果：</p><p></p><p>该报告是一篇大模型领域的综述，希望尽可能涵盖国内外该领域的所有重要文献，由智源研究院牵头，负责框架设计和稿件汇总，并邀请国内外100位科研人员分别撰写了16篇独立的专题文章，每篇文章分别邀请了一组作者撰写并单独署名，共200页。报告发布后，根据反馈持续进行修改完善，到4月2日在arXiv网站上已经更新到第三版。4月13日，我们获悉谷歌研究员Nicholas Carlini在个人博客上指出该报告抄袭了他们论文的数个段落，同时还有其他段落和语句抄袭其他论文。我们对此进行了逐项核查，经查重确认第2篇文章的第3.1节179个词，第8篇文章的第3.1节74个词、第12篇文章的第2.3节55个词、第14篇文章的第2节159个词、第16篇文章的第1节146个词与其他论文重复，应属抄袭。我们决定立即从报告中删除相应内容，报告修订版今天将提交arXiv进行更新。目前已通知所有文章的作者对所有内容进行全面审查，后续经严格审核后再发布新版本。智源作为该报告的组织者，理应对各篇文章的所有内容进行严格审核，出现这样的问题难辞其咎。对此我们深感自责，特别感谢学术界和媒体的朋友们帮助我们发现问题。我们将深刻吸取教训，整改科研管理和论文发表流程，希望各界朋友监督我们工作。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4f/4f88b45b89600a65c1c241cf3867d28e.png\" /></p><p></p><p>此外，智源研究院还表示：“确认部分文章存在问题后，已启动邀请第三方专家开展独立审查，并进行<a href=\"https://www.baai.ac.cn/portal/article/index/cid/5/id/423.html\">相关追责</a>\"。”</p><p></p><p>随后，4月15日，智源研究院邀请的第三方专家——中国计算机学会（CCF）组成了调查组，就此事展开独立调查。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a2/a244974e37cfb1f294a9a32306bd368f.png\" /></p><p></p><p>历时3个月，7月15日，智源在官网通报了调查结果。</p><p></p><p>至此，此次论文抄袭事件最终以第三方介入、独立开展调查的方式为大众交付了一个公开透明的结果。</p><p></p><p>参考链接：</p><p></p><p><a href=\"https://nicholas.carlini.com/writing/2022/a-case-of-plagarism-in-machine-learning.html\">https://nicholas.carlini.com/writing/2022/a-case-of-plagarism-in-machine-learning.html</a>\"</p><p></p><p><a href=\"https://www.baai.ac.cn/portal/article/index/cid/5/id/423.html\">https://www.baai.ac.cn/portal/article/index/cid/5/id/423.html</a>\"</p><p></p><p><a href=\"https://www.baai.ac.cn/portal/article/index/cid/5/id/504.html\">https://www.baai.ac.cn/portal/article/index/cid/5/id/504.html</a>\"</p><p></p><p><a href=\"https://www.baai.ac.cn/portal/article/index/cid/5/id/422.html\">https://www.baai.ac.cn/portal/article/index/cid/5/id/422.html</a>\"</p>",
    "publish_time": "2022-07-18 13:37:08",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "瞬时流量高峰场景下的高可用架构设计：Kubernetes集群如何调优？",
    "url": "https://www.infoq.cn/article/a1rIzRu3CAsC5LXKwJ3f",
    "summary": "<p>谈起瞬时流量高峰场景下的高可用架构设计，那首先要解决的肯定是高并发问题。</p><p></p><p>类似电商大促就是典型的高并发场景，当业务突发波动（如秒杀、限量抢购）时，无法准确预估流量，企业会苦恼需提前准备多少台机器，突发流量过后，这些机器往往又处于空载状态。这就意味着系统需要承担 100% 的业务和流量，需要具备超强的稳定性和容灾能力，并可以紧急处理各种故障：</p><p></p><p>应对快速增长的用户访问：流量短时间内达到峰值，系统面临宕机危险；应对大量业务数据和用户数据：计算资源需求突增，技术上需做到弹性自如；紧急故障处理能力：业务场景越来越复杂，宕机概率增加。</p><p></p><p>虽然这些是老生常谈的话题，但要解决并不容易，性能优化永无止境，系统高可用优化亦然。</p><p></p><h2>实现系统的高可用，Kubernetes 集群是常见解决方案</h2><p></p><p></p><p>想要实现系统的高可用，首先要明确，什么样的系统可以称之为“高可用”。简单来讲，就是不宕机。“高可用性”常常被定义为 IT 系统的运营综合指标，系统的稳定可靠程度越靠近 100%，就代表系统越稳定，这种“稳定”往往需要多方面技术调优才能实现。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/6b/6b3e70e0a032dbd77e10617300843283.png\" /></p><p></p><p>而 Kubernetes 的核心特点就是能够自主地管理容器来保证容器按照用户的期望状态运行，现在 Kubernetes 更是聚焦于不间断的服务状态（如 web 服务器、缓存服务器）和原生云平台应用（Nosql），极大程度地保障系统的稳定性，所以 Kubernetes 被称为云原生时代实现系统高可用的最佳解决方案。</p><p></p><p>作为云原生时代的操作系统，Kubernetes 的采用率正在企业内不断攀升。京东是全球容器化最彻底的互联网企业之一，目前运营着全球最大规模的 Kubernetes 集群。为了应对 如618 的订单洪峰，京东容器云平台带宽扩容数百G，抵挡了数十次攻击，实现了订单百分百云上交易。</p><p></p><p>瞬时流量高峰场景下，京东通过在 Kubernetes 集群上运行业务，以最优成本处理突发流量，实现电商系统的高可用。Kubernetes 集群无需人工管理节点和容量规划，高效实现全自动容器无限弹性扩容，同时还可以做到在保持和降低系统响应时间的前提下，不断提高系统访问量、吞吐量，从而不断提升流量高峰时的服务可用性。</p><p></p><p>即便如京东这种研发实力强悍的互联网大厂也会发现软件层面的性能优化很容易达到瓶颈，当达到某一个值之后，就很难再有提升，这就需要在硬件层面寻求突破。作为京东云底层软件的服务商，为了应对系统高可用性能需求，英特尔从硬件层面给出了解决方案：使用第三代英特尔® 至强® 可扩展处理器提供更强算力来满足高并发需求，英特尔® 傲腾™ 持久内存提供更大容量内存或持久性数据存储，以及各种类型的软硬件加速技术，辅助实现高并发。针对高并发场景下的 HTTPS 请求和处理需求，还可使用英特尔® QAT 卡来卸载 TLS 请求和加解密处理，释放 CPU 应对关键计算，从而提高 HTTPS 高并发访问量、减少相应时间。</p><p></p><p>当以上这些底层硬件能力暴露给 Kuberntes 后，容器开发者或集群运维者可以充分利用资源实现并优化具体业务，还可以借助这些硬件能力来创新，收获不一样的业务、性能体验。除此之外，这些硬件能力还可帮助开发者快捷优化应用负载，确保预测性，并实现资源的可观察性。</p><p></p><p>坦率来讲，分布式系统相对会比较复杂，性能问题也并不那么容易解决，且系统层次比较深，相关性能问题的追踪和定位也不太容易，底层软件层面的优化也是个“慢活儿”，但硬件性能的提升对于 Kuberntes 技术架构体系的优化影响还是很大的。目前已经被验证的，英特尔软、硬结合的方式能够有效优化 Kuberntes 集群技术架构，以便充分利用硬件性能，通过释放硬件潜力来优化软件、提升服务性能。</p><p></p><p></p><h2>对 Kubernetes 的美好期待，前提是完成集群的高效管理</h2><p></p><p></p><p>Kubernetes 本身并没有提供一个高可用的、开箱即用的集群使用方式，实际构建和管理过程中产生的复杂度，往往会带来各种各样的问题和挑战。虽然 Kubernetes 集群可以解决单集群资源隔离、故障隔离的难题，打破可支持节点数、Pod 数的限制，但同时也带来了集群管理复杂度增加的问题，运维成本成倍增加。所以说，Kubernetes 确实能解决很多包括瞬时流量高峰场景在内的系统高可用问题，但这一切的前提是完成 Kubernetes 集群的顺利构建和高效管理。</p><p></p><p>Kubernetes 的插件模式给英特尔等各厂商带来了与 Kubernetes 兼容的便利，同时降低了用户的设备使用成本，并且可以一致访问、管理。Kubernetes 为了兼容业界各厂商的加速设备，通过扩展设备模式来管理设备，为此定义了一个支持硬件设备的设备插件框架（device plugin framework），只要厂商按照这个框架标准 API 来实现相应的函数接口，就可以在不修改现有 Kubernetes 代码的情况下，轻松安装，集成到 Kubernetes 集群环境中来使用这些设备。</p><p></p><p>在这个背景下，英特尔使用硬件设备插件、高级容器网络功能等技术，极大促进了 Kubernetes 集群高效管理。英特尔开发的所有硬件设备插件都是开源的，开发者可以访问（<a href=\"https://github.com/\">https://github.com/</a>\" intel / intel -device-plugins-for-kubernetes/）&nbsp;获取详细信息。</p><p></p><p>从高级容器网络功能层面来看，为了方便集成，Kubernetes 支持英特尔等第三方网络提供商的网络技术方案，也定义和复用了容器网络接口（CNI），也就是说只要是符合 CNI 规范的网络解决方案都可以很方便的集成到 Kubernetes 环境中。</p><p></p><p>因为网络的使用模式非常多，场景也非常复杂，Kubernetes 基于英特尔硬件网络设备开发了多种 CNI 来满足其功能、性能等方面的需求。英特尔 为厂商和用户提供了更多的网络选项，比如用户需要聚合网络接口，可以部署 Bond CNI；如果需要多网络接口，可以安装 Multus CNI；如果是性能方面的需求，则可以使用 DPDK。</p><p></p><p>可以说，设备插件和网络模块极大地丰富和提升了集群的能力，同时也为这些设备的可观测性提供了机会。英特尔也使用多项数据中心关键技术，帮助 Kubernetes 构建功能模块和全栈解决方案，从而确保最终用户获得底层硬件的全部优势。</p><p></p><p>对于 Kubernetes 来说，其社区核心开发集中在应用编排上，对于底层硬件资源的对接。在架构设计上，Kubernetes 从兼容的角度出发，定义了相应的 API，如 CSI、CNI、CRI、Device Plugin 等，开发者无需修改代码便可快速构建功能模块。</p><p></p><p>对于运维人员来说，有了 Kubernetes 更高层的资源访问接口和管理能力，他们就可以实现其自动化全周期运维和监控，其可靠性和弹性得到大大提升，同时也获得了提高整个集群效率和资源利用率的能力。</p><p></p><p>当然了，探讨 Kubernetes 集群的高效管理的前提还是要保证其“稳定性”。只有保障了集群的稳定性，才能谈高效管理。如果想要有效避免云宕机事件的发生，首先要做到的是有效降低内存错误问题。因为在云场景下，一旦出现内存故障问题，往往会造成严重的灾难性后果，比如主机操作系统挂起、系统崩溃、宕机等，将严重影响企业用户的服务质量。</p><p></p><p>通常来讲，内存错误一般可分为可纠正错误和不可纠正错误，其中“可纠正错误”是可以通过纠错码克服双页值之差的内存模块的一些可纠正错误，而“不可纠正错误”又分为由于内存条实体硬件错误造成严重后果的（Fatal Error）、不需要处理的（UCNA）、必须处理的（SRAR）和选择处理的（SRAO）。然而，云主机出现内存错误的原因是多种多样的，而且很多时候难以复现，面对这种情况，就要具体事件具体分析。</p><p></p><p>当下解决“内存错误”问题比较理想的方案是应用英特尔® MCA Recovery 与 MFP 技术，目前第三代英特尔® 至强® 可扩展处理器已经支持这两项技术，这两项技术基于对内存错误的分析和了解，能够对 SRAR 和 SRAO 这两种错误进行预测和恢复，可以有效降低内存故障对主机的影响，可以帮助企业用户的云服务完善故障预警，并降低内存故障影响，为用户提供更稳定、更高效的云服务。</p><p></p><p></p><h2>Kubernetes 从中心走向边缘，应用编排被重新定义</h2><p></p><p></p><p>CNCF 在年度调研中提到，作为云原生最重要的编排工具之一的 Kubernetes 已经是无处不在，在包括边缘计算的不同场景里面均有使用。其调查显示，“在边缘计算领域，大概 76% 都会使用到 Kubernetes。”</p><p></p><p>多云环境在边缘计算领域已经变得越来越普遍，Kubernetes 也将云原生技术从中心拓展到边缘，云边基础设施技术架构实现统一，业务侧也实现了云边自由编排部署。举一个例子，在边缘计算场景下往往存在着大量异构设备，而且每种设备都具独特性，利用 Kubernetes 提供的扩展的 API 资源（如 CRD 功能）对这些设备进行数据建模，可以实现设备的统一管理。</p><p></p><p>Kubernetes 在边缘侧的优点确实很明显，但 Kubernetes 毕竟是从集中式数据中心的场景里诞生出来的技术，在边缘场景下也出现了水土不服，比如在“高效管理多云以进行应用程序编排”方面就出现了新挑战：</p><p></p><p>延迟：对新的低延迟应用程序用例（如 AR/VR）的要求。例如，IIOT 需要超低延迟响应。这需要在更靠近用户的边缘上支持一些应用程序功能；带宽：在边缘处理数据避免了将数据传输到云中进行处理的相关成本；上下文 /‍Promixity‍：当边缘服务器需要本地上下文时，在用户附近的边缘服务器上运行应用程序的某些部分；隐私 / 法律：某些数据可能需要保留在某个地理位置。</p><p></p><p>面对这些新挑战，英特尔积极寻求解决方案，如今英特尔的边缘多集群编排器（EMCO）与 Kubernetes 的合作，已经可以很好地把这些问题解决掉。EMCO 是 Kubernetes 的地理分布式应用程序编排器，运行级别高于 Kubernetes，并与运行 Kubernetes 的多个边缘服务器 (和云）交互。</p><p></p><p>EMCO 的主要目标就是跨多个集群自动化应用程序和服务的部署，其充当中央协调器，可以跨不同第三方的地理分布边缘群集管理边缘服务和网络功能。与其他多集群编排相比，EMCO 侧重于以下功能：</p><p></p><p>注册多个地理上分布的群集；跨不同集群编排组合应用程序（由多个单独的应用程序组成）；将边缘服务和网络功能部署到分布在不同群集上的不同节点；监视跨不同群集部署的边缘服务和网络功能的运行状况；根据计算、加速和存储需求，通过部署意图协调边缘服务和网络功能；支持来自不同企业的多个租户，同时确保租户之间的机密性和完全隔离。</p><p></p><p>在 EMCO 的加持下，从中心走到边缘的 Kubernetes，应用编排将重新被定义，编排能力变得更强壮。</p><p></p><p></p><h2>写在最后</h2><p></p><p></p><p>Kubernetes 的先进性和集群的高可用是毋庸置疑的，但当所有企业都选择 Kubernetes 后，却因为其复杂性陷入了新思考，甚至 Kubernetes 的创立者和核心推动者 Google 本身都逃避不开这个问题，“Kubernetes 就像一把双刃剑，既是最佳的容器编排技术，同时也存在相当高的复杂性和应用的高门槛，这个过程中往往会导致一些常见性错误”。</p><p></p><p>在实际的应用场景中，除了认知复杂性和开发复杂性，Kubernetes 带来的最重要的影响是其颠覆了传统的运维模式。Kubernetes 是一个非常复杂的系统，拥有多样的 API 及模块插件，这便直接增加了可被攻击面，让很多企业在安全性运维方面都无从下手。而且随着 Kubernetes 集群规模的增长，运维难度呈线性增长。</p><p></p><p>但我们要知道的是，所有技术都有双面性。容器革新了云计算的基础设施，而 Kubernetes 则搭建了一个统一的基础设施抽象层。通过 Kubernetes 集群，我们无需关心任何基础设施层的细节，就能快捷地构建出任何我们想要的且高可用的业务系统，这也是 Kubernetes 被称为云计算界的 Linux 以及 “Platform for Platforms” 的根本原因。</p><p></p><p>好在，随着英特尔等多家厂商不断提供硬件设备及技术供给，Kubernetes 的复杂性问题在逐渐弱化。在未来，集群的稳定性和系统的高可用将不是问题，在软件技术的调教下，硬件潜力将发挥到极致，软硬件的完美配合将交付最佳实践。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/05/05ef2590f5fbfcb13bc83fe93a57b825.png\" /></p><p></p>",
    "publish_time": "2022-07-18 14:04:45",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "数据爆炸时代，要怎样应对云存储挑战？",
    "url": "https://www.infoq.cn/article/aRF1vxkot7iYMpagqW8b",
    "summary": "<p>2022年，远程办公已经变得常态化，拥有可靠的云端数据存储系统或服务比以往任何时候都更加重要。</p><p>&nbsp;</p><p>个人云存储概念的兴起始于 2007 年，当时 Dropbox CEO Drew Houston在无数次丢失U盘后创建了第一个个人小型企业云存储服务。这在当时是一个激进的想法，但却受到了广泛关注。</p><p>&nbsp;</p><p>在今天，每个业务都应该是数据驱动的业务，覆盖各行各业。数据的爆发性增长，尤其是云上数据增长已经是新常态。</p><p></p><h2>大数据的下半场，是存储的较量</h2><p></p><p>&nbsp;</p><p>随着全社会<a href=\"https://www.infoq.cn/article/xcGOTqX6kvWPcczM1uaN\">数字化转型</a>\"进入深水区，数据大爆炸带来业务突飞猛进发展的同时，数据增长也会带来很多问题，存储并不是简单的只是把0和1的比特放在物理介质上这么简单，这里存在大量业务层面需要关注的问题。</p><p>&nbsp;</p><p>第一是敏捷和成本。如何应对海量数据增长所带来的成本急速上升与<a href=\"https://www.infoq.cn/article/Czgb3NcFAta4rzx35RBI\">数据存储</a>\"服务敏捷性能之间根深蒂固的矛盾；第二是数据本身多样化的需求。我们的业务数据来源是纷繁复杂的。数据以各种方式来自各种渠道，而且各个业务数据本身的性质不同，所使用的方式也是不一样的，我们要思考的是如何设计不同的存储服务满足不同业务的需求。第三，在数据安全合规被提到空前重要的大背景下，数据存储如何解决安全与合规问题，也是当下面临的主要挑战之一。</p><p></p><h2>亚马逊云科技在云端存储上的技术实践</h2><p></p><p></p><p>为了应对数据存储方面的挑战，<a href=\"https://www.infoq.cn/article/SmqdcS8oCNKROtYECzjF\">亚马逊云科技</a>\"自2006年就推出第一个云存储服务Amazon S3。时至今日，Amazon S3已经走过了16年。</p><p>&nbsp;</p><p>亚马逊云科技大中华区产品部总经理陈晓建表示： “存储服务是亚马逊云科技在成立之初就开始提供的云服务，16年来我们仍然像创立之初一样，通过不断创新来夯实这一基础服务在市场上的优势地位。如今，亚马逊云科技的存储服务已经全面覆盖了对象存储、块存储、文件存储、数据备份、数据容灾、以及数据传输与边缘处理各个方面，客户可根据自身需求灵活选择。随着企业工作负载上云的常态化，云端数据量持续爆发式增长，企业对存储成本、性能等也提出了更高的要求。我们希望能通过存储服务的不断创新，为客户提供功能更强大并兼具成本效益的存储服务，帮助他们在云端开展业务创新。”</p><p>&nbsp;</p><p>为了解决上述提到的种种挑战，亚马逊云科技在存储服务产品的设计上给出了三种不同的解决对策：</p><p>&nbsp;</p><p>1、智能分层。通过智能分层彻底解决<a href=\"https://qcon.infoq.cn/2022/guangzhou/track/1379\">数据</a>\"的成本和数据的可用性、敏捷性之间的矛盾。</p><p>2、专门构建。开发多种针对于不同场景下<a href=\"https://qcon.infoq.cn/2022/guangzhou/track/1379\">数据应用</a>\"的存储产品来解决企业应用多种多样，需求各有不同的问题。</p><p>3、统一数据保护。通过一站式云服务备份系统，解决数据安全合规的问题，同时也解决数据备份所带来成本增加的问题。</p><p></p><h3>智能分层</h3><p></p><p>&nbsp;</p><p>无论在任何业务中，用户都会面临数据增多，存储成本也就随之上升的问题。而数据成本只是其中一个最容易解决的问题，光解决成本问题不能解决存储本身带来的所有问题——数据来源多种多样，使用方法也不同，针对不同数据的类型我们应该有不同存储的产品相对应。</p><p>&nbsp;</p><p>那么，应该怎么定义数据的类型？陈晓建表示，“这里有一种比较直观而且比较准确的方式：数据的温度。”</p><p>&nbsp;</p><p>数据使用有不同的频率，比如说交易系统里的交易数据，To C系统里的用户日志，这些数据需要被频繁访问，这些数据称之为热数据；一些企业的业务数据，包括网站的数据，这些数据有可能需要按周或者按月的频率访问，因为不像热数据一样被访问得这么频繁，这些数据我们称之为温数据；再往下一层，手机相册数据、企业的其他数据，这些数据可能是几个月，甚至是一两年才会访问一次，这些数据我们可以把它作为归档数据，一旦存储之后它的访问频率并不是很高，这样的数据我们称之为冷数据；还有一种数据，一旦写入之后访问频率非常低，但是由于合法合规的要求，这些数据必须要能够进行持久化的存储，比如医疗影像的数据，国家规定这些数据必须存放30年，任何时候要用都可以及时拿出来。从业务特点来讲，这些数据本身对于存储读写性要求并不很高，但是要求数据的持久性，而且数据的量非常大，所以用户对于数据整个存储成本有着非常高的要求，这是冻数据。</p><p>&nbsp;</p><p>从这一点上看，可以简单把一些数据分为热、温、冷、冻四个层次，对于云厂商来说，显然对于这四种不同的数据要有不同的存储服务才是最合理的。</p><p></p><h3>专门构建不同的云存储服务</h3><p></p><p>&nbsp;</p><p>成本问题解决了，但是不同数据类型的来源各不相同，使用方式不一样，需求也不一样，用户要怎样构建不同存储的服务来满足业务的需求？亚马逊云科技提出的对策是专门构建不同的云存储服务。</p><p>&nbsp;</p><p>实际上，到今天为止IT化已经基本完成，每个应用和业务都会产生大量的数据。我们面对的数据类型也已经足够多了，如果要把这么多种类的数据做一个大概的区分，基本可以分为两大类：第一类是云原生的现代化应用产生的数据，第二类是传统的云端企业应用产生的数据。</p><p>&nbsp;</p><p>云原生应用产生的数据指的是电商、游戏、社交等等，这些应用大部分本来就是诞生在公有云上的应用所产生的数据；第二类企业应用不是公有云之后才产生的，相反这些企业应用，像ERP、CRM、EDA已经存在很多年了，公有云之前它们就存在了，它们依赖的技术和架构并不会考虑云的存在，所以很显然这两个应用产生的数据在处理上是非常不一样的。</p><p>&nbsp;</p><p>数据存储对于云原生应用来说非常简单。社交媒体、电商本身在云上构建，大量的业务依赖云的微服务架构，也很适应云的应用方式，很显然对云原生应用来说希望存储是一样的架构。云的特点是用户不用考虑底层架构，无论是伸缩、全覆盖、运维，这些事情都是云来完成的，用户只需调用简单的API接口就全搞定了，自然存储也应该是这样。</p><p>&nbsp;</p><p>陈晓建表示，对于云原生应用的云存储服务问题，亚马逊云科技的解决办法有两个：第一个是Amazon S3，第二个Amazon EFS。</p><p>&nbsp;</p><p>Amazon S3 就是一个简单的API，不用管任何背后的细节。大量的应用和非常多的云存储都是放在Amazon S3上的，它已经成为了对象存储工业界的事实标准。</p><p>&nbsp;</p><p>有很多的业务依然依赖于传统的文件系统的调研方式，所以亚马逊云科技还提供了Amazon EFS。Amazon EFS是共享文件系统，是完全兼容容器、无服务器化的应用。Amazon EFS系统不光是跟云原生一样不用做任何的配置和运维，而且和其他亚马逊云科技的服务高度集成，用户一旦用容器就可以非常容易的挂载到Amazon EFS里。所以Amazon EFS和Amazon S3能够很好地解决云原生业务的需求。</p><p>&nbsp;</p><p>而企业应用就复杂多了。在公有云诞生之前，就存在大量的各种各样的企业应用。对企业应用来说，</p><p>&nbsp;</p><p>首先，已经存在很多之前就有的特点，比如说快照、镜像、远程复制、多种存储协议等等，如果要上云必须要支持这些，如果在ERP和企业应用上云的时候需要按照Amazon S3和Amazon EFS的接口重新改变代码，那么没有企业用户愿意这样做。所以保证兼容对企业来说是非常重要的工作。其次，企业应用还有各个行业的特点，比如说高性能计算、大数据分析，可能对网络、机器性能各方面都有很高的要求，这些是在提供企业应用存储服务的时候必须要考虑的。</p><p>&nbsp;</p><p>企业在云端有各类不同的业务场景，对共享文件存储有着不同的要求，陈晓建列举了一些目前存在的比较主要的四大类企业应用：</p><p>&nbsp;</p><p>第一类是Windows为主的应用，底层服务要完全满足Windows的环境，包括ACL文件访问控制权限，包括Active Directory兼容。第二是<a href=\"https://qcon.infoq.cn/2022/guangzhou/track/1383\">高性能计算</a>\"，不可能通过单个节点完成，一定是多节点协同的，数据是共享的。真正在跑的高性能集群往往是几百个节点，甚至几千个节点共享一份数据，这样就带来一个问题，首先第一个需要共享的存储，第二个由于这份数据要被几百个、几千个节点同时访问，所以对整个存储的性能和吞吐率也提出了非常高的要求。第三是基于各类多种多样的企业应用，这些应用要上云必须完美的兼容和支持好之前提供的功能。第四是大数据的环境，往往需要一些特殊的支持，包括像ZFS，需要具备高吞吐、低延时的技术。</p><p>&nbsp;</p><p>陈晓建表示：“从存储角度来说这四类代表了企业应用里四个主要的不同的场景，是需要我们考虑的，所以我们专门构建了一个场景化应用FSx家族，X意味着多种文件存储类型，专门为企业不同业务需求构建”。</p><p></p><h3>统一数据保护</h3><p></p><p>安全与合规也是数据存储时不容忽视的重要一环。</p><p>&nbsp;</p><p>尽管市场上数据备份工具的种类多种多样，但数据备份在技术层面来讲，仍然存在着很多问题。</p><p>&nbsp;</p><p>首先很多系统都是使用起来非常复杂的，操作起来有一定门槛；第二，怎么保证安全合法合规的要求又是一大挑战；第三，由于做备份一定会带来额外的成本，如何解决这个问题？</p><p>&nbsp;</p><p>基于以上问题，亚马逊云科技推出了Amazon Backup，用户可以借助可Amazon Backup来满足其业务连续性和合规要求。</p><p>&nbsp;</p><p>Amazon Backup可统一保护客户应用程序的数据，跨越亚马逊云科技的计算、数据库以及文件，对象和块存储服务。在过去一年，亚马逊云科技将Amazon Backup扩展至Amazon S3和VMware工作负载，让客户使用统一的数据保护策略，即可配置、管理和监督数据的备份与恢复，此外还涵盖Amazon Elastic Compute Cloud (Amazon EC2)、 Amazon EBS、Amazon Relational Database Service (Amazon RDS)、Amazon Aurora、Amazon DynamoDB、Amazon DocumentDB、Amazon Neptune、Amazon FSx、Amazon EFS和Amazon Storage Gateway。用户还可以使用Amazon Backup Audit Manager生成审计报告来帮助其满足合规要求，并使用Amazon Backup中内置的细粒度访问控制以及Amazon Backup Vault Lock，保持备份不变，防止意外或恶意删除。</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2022-07-18 14:07:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]