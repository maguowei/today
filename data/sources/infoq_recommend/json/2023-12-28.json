[
  {
    "title": "领导者如何告别责备文化，营造容纳失误、鼓励创新的组织文化",
    "url": "https://www.infoq.cn/article/PrK9S9oUZfeRccQ8yfo9",
    "summary": "<p>Diana Larsen 认为，责备文化是对人类潜力的浪费。当人们的精力都用在避免羞耻和责备上时，就无法完成最好、最有创造性的工作。她认为，要做到无责备领导，需要向学习和保持好奇心的方向转变。这需要建立或恢复与人们之间的信任和可信赖关系。</p><p></p><p>Diana Larsen 在 ScanAgile 2023 大会上发表了关于无责备领导的主题演讲。</p><p></p><p>Larsen 表示，企业在招聘最优秀的人才上投入了大量的时间、精力和金钱，但从实际的角度来看，将这些人带入一个责备盛行的文化中意味着这些投资的浪费：</p><p></p><p></p><blockquote>如果一个人总是担心自己会成为责备的对象，那么他就不可能达到自己的最佳状态。这会分散注意力，让人伤心，是对人类潜力的浪费。</blockquote><p></p><p></p><p>Larsen 提到，当人们感觉到责备即将降临在他们头上时，他们会尽其所能来避免。他们会回避、转移责任、隐藏错误。当责备来临时，他们会因为被认为不称职而感到羞耻。她说，当人们的精力用在这些反应上面时，就无法完成最佳或最有创造力的工作。</p><p></p><p>要想实现无责备领导，就需要转变思维方式，并深刻理解当指责盛行时，每个人都会受到伤害。Larsen 表示，责备的对立面是学习和好奇心。她建议，与其寻求指责，不如寻找导致意外、令人失望的事情的系统性根源，比如交付失误、编码错误或旷工等。</p><p></p><p>Larsen 提到，学习式领导可以表现为领导者在员工向其提出问题时承认自己并不了解所有答案。例如，你可以说：“我不知道该怎么做，让我们一起去找出解决办法！”当出现新的、意想不到的问题时，鼓励员工去探索、保持好奇心和学习。</p><p></p><p>无责备领导的第一步是建立或恢复与人们之间的信任和可信赖关系，正如 Larsen 所说的：</p><p></p><p></p><blockquote>我听到过一个挪威谚语：“他们的肩膀耷拉下来了。”我喜欢这句话。问问员工和团队成员，怎样才能让他们停止紧张地耸肩，以一种更顺畅、更放松、更投入的方式专注于工作。很多时候，我们可以很容易得到答案。</blockquote><p></p><p></p><p>Larsen 建议提出类似这样的问题：“怎样才能在把更多的时间投入到工作中？”、“你目前的工作环境缺少什么？”、“怎样才能让你学到完成团队工作所需的知识？”然后，采纳他们的建议，或解释你为什么不能（解释理由必须充分），并要求他们与你一起努力改进，这对你作为领导者以及他们作为团队成员来说都是更好的做法。</p><p></p><p>InfoQ 就无责备领导的话题对 Diana Larsen 进行了采访。</p><p></p><p>InfoQ：责备是如何成为领导方式中根深蒂固的一部分？</p><p></p><p>Diana Larsen：这是人们和人类系统很早就养成的习惯。回想一下，直到一二十年前，责备和打孩子仍然还是学校和家长公认的做法。现在，大多数人都对这种想法感到恐惧。人们把他们在家里和学校里学到和看到的习惯带到了工作场所。</p><p></p><p>甚至还有一些关于责备的传统格言，好像责备是一种预期行为。“让他们受点压力吧。”、“呆在你自己的泳道里！”、“你为什么不能像某某同事一样？”、“谁对这个错误负责？”还有很多其他的回应，比如“在这里，你必须想办法开脱罪责！”、“低调行事”，等等。员工、经理和企业高层领导都已经习惯了这种模式。</p><p></p><p>InfoQ: 领导者必须培养哪些技能才能实现学习式领导？</p><p></p><p>Larsen：如果他们在软件 /IT 行业工作，就需要培养识别、理解、影响和与复杂系统（技术和人文）协同工作的能力。其他的技能还包括学习领导团队而不是个体贡献者，了解动机的变化和团队环境中的重要因素。将领导者的注意力转移到为团队预期的工作性质创造最佳的工作环境上。</p><p></p><p>大多数软件开发团队在学习工作上花费的时间远远超过应用知识的时间。当工作环境充满不确定性、复杂性、模糊性和快速变化（VUCA）时，他们必须关注新的学习相关技能和了解信息的方法。</p><p></p><p>英文原文：</p><p></p><p><a href=\"https://www.infoq.com/news/2023/12/leading-without-blame/\">https://www.infoq.com/news/2023/12/leading-without-blame/</a>\"</p><p></p>",
    "publish_time": "2023-12-28 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "OpenAI 的超级对齐团队是在做什么",
    "url": "https://www.infoq.cn/article/AhtiFVSLXkudHJq3XLNd",
    "summary": "<p>OpenAI 不久前宣布了该公司超级对齐团队的第一项成果。这个团队是该公司的一项内部计划的产物，致力于预防一种超级智能体（一种假象的未来计算机，可以比人类更聪明）走向失控。</p><p>&nbsp;</p><p>与该公司的许多公告不同的是，这次的公告并没有包含什么重大突破。在一篇低调的研究论文中，该团队描述了一种技术，可以让一个水平较低的大型语言模型监督一个能力更强大的语言模型，论文声称这可能是向着“弄清楚人类如何监督超人类水平的机器”这一目标迈出的一小步。</p><p>&nbsp;</p><p>此前 OpenAI 陷入了危机，首席执行官 Sam Altman 被监督委员会解雇（这显然是由首席科学家 Ilya Sutskever 领导的政变），三天后他又重新上任。这次的公告距离这桩风波不到一个月，而它传达的信息很明确：公司又回到了正轨，一切如常。</p><p>&nbsp;</p><p>然而 OpenAI 的业务并不寻常。许多研究人员仍然质疑机器是否能够媲美人类的智能水平，更不用说超越人类智能了，但 OpenAI 团队认为机器最终一定会取得优势。“过去几年中人工智能的进步非常快，”超级对齐团队的研究员 Leopold Aschenbrenner 说：“我们不断刷新所有基准测试纪录，而且这种势头有增无减。”</p><p>&nbsp;</p><p>对于 Aschenbrenner 和公司的其他人来说，行业出现具有接近人类能力水平的模型是指日可待的。 “但它不会就此止步，”他说：“我们将拥有超人模型，也就是比我们聪明得多的模型。这样的未来将会带来很多全新的、直击根本的技术挑战。”</p><p>&nbsp;</p><p>7 月，Sutskever 和 OpenAI 科学家 Jan Leike 成立了超级对齐团队来应对这些挑战。 “我这样做是为了我自己的利益，”Sutskever 在 9 月份告诉《麻省理工科技评论》：“我们得保证任何人构建的任何超级智能都不会失控，这一点显然非常重要。”</p><p>&nbsp;</p><p>人们猜测 Altman 因他在公司的人工智能安全策略方面的做法反复无常而被解雇，现在 Sutskever 的超级对齐团队又成了头条新闻。许多人都在期待着，想知道到底发生了什么。</p><p>&nbsp;</p><p></p><h2>该做什么和不该做什么</h2><p></p><p>&nbsp;</p><p>该团队想要回答的问题是如何控制或“调整”假想中的、比我们聪明得多的未来模型，即所谓的超人模型。对齐意味着让模型确保执行你希望它执行的操作，而不执行你不希望它执行的操作。超对齐的理念把这种思想应用到了超人模型上。</p><p>&nbsp;</p><p>用于调整现有模型的一项非常流行的技术称为“通过人类反馈的强化学习”。简而言之，人类测试人员会对模型的反应打分，对他们希望看到的行为投赞成票，对他们不希望看到的行为投反对票。然后这些反馈会被用于训练模型，使其仅产生人类测试人员喜欢的响应类型。这项技术是让 ChatGPT 变得如此吸引人的一个重要原因。</p><p>&nbsp;</p><p>问题在于，这种方法要求人类首先能够辨别什么是理想的行为、什么是不理想的行为。但超人模型这种情况下，模型可能会做出一些人类测试人员无法理解的事情，因此测试人员无法对它们评分。（Sutskever 告诉我们，它甚至可能试图向人类隐藏其真实行为。）</p><p><img src=\"https://static001.geekbang.org/infoq/8b/8bac53e88ab1172dec77d0990f410645.jpeg\" /></p><p>OpenAI 解决超对齐问题的方法</p><p>&nbsp;</p><p>研究人员指出，这个问题很难研究，因为超人机器目前并不存在，所以他们使用了一种替代方法。他们没有研究人类该如何监督超人类机器，而是研究了 OpenAI 五年前发布的模型 GPT-2 该如何监督 OpenAI 最新、最强大的模型 GPT-4。 “如果你能做到这一点，这也许就能证明你可以使用类似的技术来让人类监督超人类模型，”超级对齐团队的另一位研究员 Collin Burns 说。</p><p>&nbsp;</p><p>该团队引入 GPT-2，并训练它执行一些不同的任务，包括一组国际象棋谜题和 22 个评估推理、情感分析等常见自然语言处理测试。他们利用 GPT-2 对这些测试和谜题的反应来训练 GPT-4 执行相同的任务，这就好像让三年级学生教十二年级学生如何完成任务一样。诀窍是在不让 GPT-4 的性能受到太大影响的情况下做到这一点。</p><p>&nbsp;</p><p>结果好坏参半。该团队测量了根据 GPT-2 最佳猜测结果训练的 GPT-4 与根据正确答案训练的 GPT-4 之间的性能差距。他们发现，经过 GPT-2 训练的 GPT-4 在语言任务上比 GPT-2 表现好 20% 到 70%，但在国际象棋难题上表现较差。</p><p>&nbsp;</p><p>团队成员 Pavel Izmailov 表示，GPT-4 完全超越了它的老师，这一事实令人印象深刻：“这是一个非常令人惊讶和积极的结果。”但他说，它远远没有发挥出它自己的潜能。他们的结论是，这种方法很有前景，但还需要做更多的工作。</p><p>&nbsp;</p><p>“这是一个有趣的想法，”德国斯图加特大学从事对齐研究的人工智能研究员 Thilo Hagendorff 说道。但他认为 GPT-2 可能太笨了，无法成为一名好老师。 “GPT-2 往往会对任何稍微复杂或需要推理的任务给出无意义的响应，”他说。 Hagendorff 想知道如果改用 GPT-3 会发生什么事情。</p><p>&nbsp;</p><p>他还指出，这种方法并没有解决 Sutskever 所假设的一种场景，也就是超级智能会隐藏其真实行为，并假装和人类保持一致，虽然它实际上可能已经跑偏了。 “未来的超人模型可能会拥有研究人员也不了解的新兴能力，” Hagendorff 说：“在这些情况下，对齐方法该如何发挥作用呢？”</p><p>&nbsp;</p><p>但他说，指出缺点是很容易的事情。他很高兴看到 OpenAI 开始从猜想转向实验：“我对 OpenAI 的努力表示赞赏。”</p><p>&nbsp;</p><p>OpenAI 现在希望招募其他人加入他们的事业。除了这项研究成果更新之外，该公司还宣布了一项新的 1000 万美元资金计划，计划用于资助从事超级对齐工作的人员。它将向大学实验室、非营利组织和个人研究人员提供高达 200 万美元的赠款，并向研究生提供 15 万美元的一年期奖学金。 “我们对此感到非常兴奋，” Aschenbrenner 说：“我们的确认为新加入的研究人员可以做出很多贡献。”</p><p>&nbsp;</p><p>相关链接：</p><p><a href=\"https://www.technologyreview.com/2023/12/14/1085344/openai-super-alignment-rogue-agi-gpt-4\">https://www.technologyreview.com/2023/12/14/1085344/openai-super-alignment-rogue-agi-gpt-4</a>\"</p><p><a href=\"https://openai.com/blog/introducing-superalignment\">https://openai.com/blog/introducing-superalignment</a>\"</p>",
    "publish_time": "2023-12-28 09:39:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AI Agent 在全球化背景下的机遇和挑战 ｜InfoQ《极客有约》",
    "url": "https://www.infoq.cn/article/WDwBxN02ZSHlpLZ5vpfF",
    "summary": "<p></p><blockquote>嘉宾｜杨晶生，字节跳动飞书技术Leader特约主持人｜吴少杰，InfoQ社区编辑，高级算法专家</blockquote><p></p><p></p><p>在全球化背景下，AI&nbsp;Agent的发展面临着前所未有的机遇和挑战。作为一种具有高度智能和自主性的技术，AI&nbsp;Agent正在改变着各行各业的运作方式，为人们的生活和工作带来巨大的便利。</p><p></p><p>AI&nbsp;Agent的应用使得跨国企业和全球协作变得更加高效和便捷。通过智能化的交互和自主性的决策，AI&nbsp;Agent能够快速地处理和分析全球范围内的数据和信息，帮助企业做出更加明智的决策，加速全球化进程。然而，随着技术的不断发展和普及，AI&nbsp;Agent也面临着越来越多的挑战和问题。本期《极客有约》，我们邀请到了字节跳动飞书技术Leader&nbsp;杨晶生老师，一同来探讨&nbsp;AI&nbsp;Agent&nbsp;面临的机遇与挑战及未来的发展趋势。</p><p></p><p>InfoQ：各位亲爱的InfoQ的新老朋友，大家晚上好，欢迎来到《极客有约》直播，我是今天的特邀主持人，也是InfoQ社区编辑的吴少杰。目前，我的工作主要涉及垂直行业，专注于大模型和推荐系统相关领域。之前，我在新浪微博和58同城从事推荐和NLP相关工作。</p><p></p><p>在本期直播中，我们有幸邀请到了字节跳动飞书技术Leader，杨晶生老师，为我们分享他在全球化背景下面临的挑战以及与AI&nbsp;Agent相关的经验。杨晶生老师目前负责字节跳动飞书AI方面的研发工作。接下来，请让我们欢迎杨晶生老师，请杨老师与直播间的朋友们打个招呼。</p><p></p><p>杨晶生：我非常荣幸能够参加InfoQ《极客有约》的活动。回顾我的职业发展，最初加入计算机行业时，与吴少杰有些相似，我也是从推荐领域入手的。随着NLP技术的不断成熟，我逐渐转向了NLP，并拓展了一些与语音相关的工作。</p><p></p><p>近年来，我主要在飞书工作，负责AI方面的研发工作。尤其是在今年以来，由于大模型和AI&nbsp;Agent等技术的演进，我们在这个领域做了很多工作。今天，我很高兴能够从行业和技术演变的角度与大家分享一些我个人的学习积累和感受。</p><p></p><p>InfoQ：我了解到杨老师您是在飞书负责AI相关的研发工作，您一直从事与AI相关的工作，想请问下您是如何看待最近两年AIGC引发的技术变革的？</p><p></p><p>杨晶生：最近两年，确切地说是最近一年，整个AI领域的发展迎来了一波新的高潮。回溯过去，上一波高潮可能是在自动驾驶兴起的时候。去年，自动驾驶领域似乎略显停滞，但在ChatGPT之前，我们也看到有一些与CV相关的技术进展，如Midjourney和Stable&nbsp;Diffusion。</p><p></p><p>现在，大家对于AIGC这个词可能有不同的概念，比如GAI、AGI，它们之间存在一些区别。在国外，通常更多地使用GAI这个术语，指的是生成式AI。原先AI主要执行判别式任务，如分类等，从去年开始，生成文字和图像的技术有了巨大的突破。而人工通用智能（AGI）其中G代表通用，特别是OpenAI认为，追求更加通用的人工智能是一个长期的目标。</p><p></p><p>在过去几年里，我一直在飞书从事与AI相关的工作，包括智能纠错等工作。过去，实现这些任务通常需要大量的数据积累和模型训练，每个任务都需要一个独立的模型，这导致了扩展性和可复用性的问题。然而，引入大模型后，最大的差异不仅体现在最终用户体验方面，更在于加速了探索和扩展业务的速度。</p><p></p><p>现在，很多人都在用提示词工程，只需输入几个词、几句话，即可帮助完成任务。与以前需要标注大量数据并进行长时间的训练相比速度快很多。虽然许多大模型在任务上的精度可能不如以前专门设计的模型高，但它们确实使我们能够以非常快的速度尝试许多事情，这也是为什么今年以来AI领域发展迅速的原因之一。</p><p></p><p>从大模型的工作中，我们发现可能有一些“涌现”出的AGI可能性，今天关于Agent这个概念，我们也认为AI&nbsp;Agent可能是AGI早期表现之一。</p><p></p><p>InfoQ：AIGC的火爆也带火了AI&nbsp;Agent，您能先跟我们聊聊到底什么是AI&nbsp;Agent吗？它的定义是什么？</p><p></p><p>杨晶生：关于Agent这个词，目前有很多看法。实际上，这个词的定义并没有一个特别精确的界定。首先，Agent这个概念已经存在很久了，根据一些论文，可以追溯到古希腊或古罗马时代。最初，它指的是能够接受人的指令并完成任务的实体。起初，这个角色主要由人类担任，但随着时间的推移，在蒸汽工业时代，机器也开始扮演这个角色，所以Agent这个概念并不新鲜。</p><p></p><p>然而，在过去的几年中，特别是在大约2001年之后，随着深度学习的引入，人们开始更加关注与人工智能相关的Agent，并将其与图灵测试等概念联系起来。因此，Agent这个词在基于人工智能的背景下引起了更多关注，现在很多人也称之为“智能体”。</p><p></p><p>目前，有很多对于Agent的定义，比如来自OpenAI应用人工智能安全研究负责人翁丽莲（Lilian&nbsp;Weng）的定义。她在自己的博客中提到，我们现在可以更好地使用Agent来实现更多任务。她认为，Agent应该具有记忆规划和工具的概念。在较早的时候，比如去年底，随着GPT模型出现，出现了LangChain的框架，LangChain也对Agent进行了定义。他们认为，如果只是按照必须的步骤使用模型来完成任务，那么这个东西还是机械的。如果让模型决定如何使用工具或API，让模型理解问题并决定如何调用工具，那么这个模块就被称为Agent。</p><p></p><p>最近，OpenAI在DevDay上提出了一个新功能叫做GPTs，提到GPTs能够通过一些配置来构建一个早期Agent。因此，虽然对于Agent有各种不同的定义，但整体概念相似，它首先要通过环境和人类给定的指令获取一些输入，然后通过自身的能力进行记忆、推理，最终使用工具完成给定的任务。在我们的生活中，这实际上在一定程度上能够以一种更加人类可理解的方式进行交流。</p><p></p><h2>AI&nbsp;Agent落地的瓶颈有哪些？</h2><p></p><p></p><p>InfoQ：AI&nbsp;Agent落地的瓶颈在哪里？您了解到的有哪些已经落地的AI&nbsp;Agent可以分享吗？</p><p></p><p>杨晶生：刚刚我们提到了AI&nbsp;Agent的几个方面，其中包括它如何理解指令输入、执行工具以及思考的过程。在谈论这些具体步骤之前，我想提及一个问题，那就是当前对AI&nbsp;Agent的评测非常困难，这也是它在实际应用中面临的一个重要问题。</p><p></p><p>我们目前看到许多新模型的出现，包括一些涉及AI&nbsp;Agent能力的榜单，人们会进行比较，但实际上，即使分数很高，当真正使用时，我们可能会发现它的理解仍然存在一些偏差。这主要是因为评测本身确实非常难以精确执行，目前仍然高度依赖人工评测，并且如何实现更全面的评测覆盖也是一个难题。我认为这可能是当前应用落地中最大的瓶颈之一。</p><p></p><p>关于AI&nbsp;Agent的实现方面的挑战，我认为有几个方面需要考虑。首先是观察，即它如何接受指令和环境输入。目前，很多工作都基于大语言模型，主要以文本为输入。但实际上，要处理图像、语音以及其他传感器数据等多样的输入，是相当困难的。然后执行工具方面，如何安全地执行，也是一个非常难以解决的问题。</p><p></p><p>另一个方面是AI&nbsp;Agent的推理能力，这是目前大语言模型中“涌现”出的一个惊喜。然而，因为它最初主要用于生成任务，现在虽然我们发现它具有一定的推理能力，但在这方面它可能显得有些笨拙。特别是在纠正错误方面，可能变得更加困难。例如，最近流行的AutoGPT框架在一个演示中展示了输入任务并要求制定一套股票购买策略，看起来很华丽，但实际应用时可能遇到一些困难，因为在推理过程中的把控难度较大。</p><p></p><p>综上所述，当前AI&nbsp;Agent在广义场景中的实际应用仍然面临着一些困难。当然，在某些相对狭窄的领域，由于其要求较低，一些具体场景的应用可能会相对顺利。</p><p></p><p>InfoQ：AI&nbsp;Agent能否从专用抵达通用？</p><p></p><p>杨晶生：关于AI&nbsp;Agent，根据我们刚才的讨论，它实际上是为了帮助解决任务。你给它一个任务，然后它会根据手上拥有的工具，自己想出如何使用这些工具来解决任务。因此，它本身具有相当强的领域定制性。</p><p></p><p>Agent的领域性与大语言模型相比，可能在概念上略有不同。大语言模型的领域性体现在其学习到的知识的范围。不同参数量的大模型所能学到的知识量级不同。另外，由于一些数据的隔离性，可能会有一些所谓的行业或领域的大模型。</p><p></p><p>而对于Agent来说，比如，某个Agent的工具可能是用于文档编辑，那么它自然就是文档编辑领域的Agent。如果它的工作是用于指挥机器人完成一些机器人的操作，那么它自然就是关于机器人的Agent。所以，这种Agent本身的领域性是很自然的，即使在虚拟领域，我们也发现给予不同的输入、输出定义，它也能够形成一个具有领域性的Agent。在这方面，一个很好的例子是国内最近启动的项目，称为MetaGPT。这个项目的理念是创建一个虚拟的软件公司，其中有一个虚拟的Agent，即老板。这个Agent的输入是用户的需求，然后它将任务分配给产品经理、研发和测试，然后它定义了不同的产品经理、研发和测试，他们会使用基于语言模型的虚拟工具完成不同的任务。由于定义了不同的工具，因此它可以自然地包含不同的领域模型，而在推理时，我们也可以通过召回不同的背景知识，从而形成具有领域性的Agent。</p><p></p><p>InfoQ：通用AI&nbsp;Agent实现的路径是什么？</p><p></p><p>杨晶生：这是一个极具挑战性的问题。我们刚才已经定义了AI&nbsp;Agent，它的能力取决于所定义的工具，使其自然地成为特定领域的Agent。如果我们反过来看所谓的通用Agent，它不需要特定定义一堆工具，而是可以从用户那里获得一些通用的能力，比如上网和文件编写，并自行完成任务，这实际上是一个极具挑战性的问题，从某种程度上来说，如果达到这个程度，它就已经是我们所谓的AGI，即通用人工智能的一种形式。</p><p></p><p>在回答这个问题时，我们可以稍微再谈一下AGI。前两天我看到DeepMind发表了一篇关于AGI级别的定义。他们的AGI定义与我们之前讨论的相似，但将其分为所谓的狭义AI和通用AI。</p><p></p><p>狭义AI指的是对某一领域非常精通的AI或者Agent，类似于自动驾驶，分为L0到L5，其中L0表示没有，L5表示完全超越人类。有趣的是，在狭义AI列中，L5实际上已经被填满，即在某些领域，例如AlphaFold在发现蛋白质结构方面超越了人类实验。然而，在通用AI的这条线上，他们将ChatGPT仅放在了L1，即“涌现”的阶段，甚至都没有说能够在某个固定的比例上超越人类，这表明了对于通用AI或通用AI&nbsp;Agent的认知。在目前来看，一旦我们涉及通用领域，问题就变得非常困难。</p><p></p><p>谈到实现路径，目前有很多探索，包括中国的智源研究院以及美国的一些机构，大家对于如何走向通用AI或AGI有很多考虑，众说纷纭，因为目前还没有确定的路径，很难说哪条路是正确的。然而，我个人认为MetaAI的负责人杨立昆（Yann&nbsp;LeCun）提出的三个点是比较有帮助的。首先是关于系统的反思能力，即如何让通用AI能够在执行过程中更灵活并及时纠正问题。其次是关于规划和目标的能力，即如何使通用AI能够像人类一样在长期和短期目标之间进行规划。最后一个难点是复杂能力的训练过程，即如何让通用AI在面对非常复杂的任务时能够更好地在训练中体现，而不是仅仅依靠涌现。这些是通用AI或AI&nbsp;Agent的难点，但从实际执行的角度来看，现在全世界都在探索，但还没有人敢说自己一定知道正确的路径。</p><p></p><p>InfoQ：您了解到的有哪些已经落地的AI&nbsp;Agent可以分享吗？</p><p></p><p>杨晶生：正如我们之前所讨论的，垂直领域的Agent由于专精于某个领域，因此它所面对的任务相对明确。目前，这方面已经在多个场景中尝试，并且已经在一些领域取得了显著的成果。其中一个概念是Copilot，由微软提出，在其Office和GitHub平台上得到了应用。Copilot可以看作是一种虚拟的协作工具，尤其是GitHub的Copilot。在编写代码的过程中，它根据上下文来预测接下来的代码，实时指出潜在问题，并辅助生成单元测试等。Copilot在实际应用中表现出色，尤其在在线协作场景下，为任务导向的工作提供了良好的支持。</p><p></p><p>这种趋势不仅体现在办公软件中，如飞书等，而且在设计软件（如Adobe的产品）和销售工具（如Salesforce）中也有所体现。虽然在实践中，人们对Agent在这些流程中到底能够提供多大的帮助还在研究中，但引入Agent的概念在这些环节中应该是有意义的。</p><p></p><p>另一个有趣的方向是Agent在与人类互动中也有一定的平等性。比如近期一些游戏中采用了大语言模型来加强与NPC的对话，使得互动更加丰富，甚至包括一些数字、唇动和动画生成，使得与机器之间的对话更加平等。</p><p></p><p>因此，总体来说，Agent在一些垂直领域中已经发挥了重要作用，即使在大语言模型出现之前也是如此。而随着大语言模型的应用，这一领域的发展速度显著提升。</p><p></p><p>InfoQ：随着大模型多模态能力的提升，您认为多模态会为Agent带来什么？</p><p></p><p>杨晶生：在多模态方面，我认为它非常重要。因为刚刚在讨论&nbsp;Agent&nbsp;面临的难题时，提到了一个关键点，即现实世界或虚拟世界中，并非所有信息都通过文字表达。因此，更好地理解图像和语音，使&nbsp;Agent&nbsp;能够执行更多任务，尤其是在机器人场景下，变得至关重要。</p><p></p><p>目前，机器人的驱动力背后采用的方式已经发生了变化。以前，大多数方法是通过规则或者某些硬件机械的方式来驱动机器人。然而，如今包括&nbsp;DeepMind&nbsp;在内的一些机构，以及国内的一些公司，正致力于利用大模型或&nbsp;Agent&nbsp;来驱动机器人。在这种情况下，仅仅通过文本输入显得力不从心。因此，我们认为在现实世界应用&nbsp;Agent&nbsp;的情境下，多模态处理变得至关重要。</p><p></p><p>InfoQ：在您看来，AI&nbsp;Agent的发展在国内和国外有什么差异吗？您认为什么样的公司能在这场技术变革中跑出来？有哪些机遇是我们可以把握住的？</p><p></p><p>杨晶生：国内和国外在当前全球化市场中的区别在逐渐模糊。在技术领域，国际交流频繁，许多公司也在海外拓展业务。因此，从地理角度看，国内和国外在做许多事情上存在较大的共性，尽管在不同行业和地区，由于用户需求的差异，实际落地时可能存在一些差异，形成了业务上的不同。</p><p></p><p>对于&nbsp;Agent&nbsp;技术而言，我认为差异更多地体现在业务层面，而不是技术路线上。在狭义上来说，尤其是考虑到目前许多&nbsp;Agent&nbsp;的基础是大语言模型，而使用这些模型在合规方面有明确要求。所以，由于在海外&nbsp;GPT&nbsp;是一个合规使用的基座，国外业务整体上可能处于领先地位，推动了该领域能力的发展。国外公司在&nbsp;GPT&nbsp;基础上进行应用的情况相当活跃，很多小公司可能并不涉足模型功能的开发，而是基于&nbsp;GPT&nbsp;进行应用开发。当然，近期随着GPTs和Assistant&nbsp;API的出现，出现了对创业空间压缩的担忧。确实，一些中间层公司在信息和语言模型基础设施方面受到了一些挤压，但我们也能看到许多应用型公司受益颇丰。</p><p></p><p>在国内，虽然可能相对于&nbsp;GPT&nbsp;来说，目前合规的大语言模型基座可能稍显早期，但我们可以看到国内在销售和营销等方面的实际应用上非常领先。特别是在多模态理解方面，国内公司在处理复杂数据理解上做得非常出色。在激烈竞争的市场中，很多公司在复杂数据理解方面的细致工作要比国外公司更为出色。这种对复杂格式数据的深刻理解，对&nbsp;Agent&nbsp;应用的提升有很大帮助。总体而言，无论是与机器人结合还是与办公软件结合，国内外在&nbsp;Agent&nbsp;技术应用方面的共性大于差异。</p><p></p><p>InfoQ：AI&nbsp;Agent的伦理和隐私问题如何解决？我们应该如何规范和引导AI&nbsp;Agent的发展？</p><p></p><p>杨晶生：这个话题涉及到一些宏观层面的问题。坦白说，我个人可能不是专业的伦理、隐私、法律方面的专家，我更愿意从技术和安全的角度谈一些观点。</p><p></p><p>首先，关于隐私问题，最近有一例涉及到&nbsp;GPTs&nbsp;的情况。有人上传了一个文件用于对话生成的资料，但发现其他人通过对话可以获取该文件的下载地址。虽然这引起了一些关注，但我认为这并不是一个特别严重的问题。即便不通过下载文件，通过对话，使用者仍然可以获取文件内容的很多信息。从理论上讲，这更像是一个安全问题，可能会暴露系统的实现，而不是一个侵犯隐私的问题。总的来说，许多隐私问题并不是由&nbsp;AI&nbsp;Agent&nbsp;或者对话式&nbsp;AI&nbsp;引入的，而是系统之前就存在的问题，只是由于引入了&nbsp;AI，使得这些问题更容易引发关注。</p><p></p><p>另一个例子涉及到&nbsp;API&nbsp;的鉴权问题。在一些场景中，用户可能通过对话请求获取其他用户的文档，这需要通过&nbsp;API&nbsp;进行身份验证。解决这类问题并不是仅仅依赖于&nbsp;AI&nbsp;Agent&nbsp;的技术设计，而更需要在&nbsp;API&nbsp;设计阶段做好权限管理，确保用户只能访问其有权限的内容。</p><p></p><p>关于伦理问题和规范引导，当&nbsp;AI&nbsp;Agent&nbsp;代替用户执行操作时，责任归属变得复杂。例如，在法律助手的场景中，如果&nbsp;AI&nbsp;理解错误导致合同出现问题，责任究竟是用户还是系统的提供方？这是一个复杂的问题，目前在法律专家中也存在一些争议。从我个人的看法来看，AI&nbsp;应该被看作是一种辅助工具，而在生成内容之后，我们需要进行一些确认环节来规避潜在的问题。</p><p></p><p>此外，有一些实验性的工作涉及到多个&nbsp;AI&nbsp;Agent&nbsp;之间的互动，例如斯坦福创建的虚拟小镇项目，小镇上25个Agent互相驱动，对话并产生故事。再比如在类似微博的平台上，所有发言都是由&nbsp;AI&nbsp;生成的。这引发了一些关于创作权和责任的问题。如果某人不知道发言者是&nbsp;AI，而将其当作真实的言论，责任归属于谁？这些问题仍然需要深入探讨。</p><p></p><p>总的来说，随着技术的发展，我们可能需要不断探索并适应，先进行实验性的应用，发现问题后再进行修正和规范。这也许是一个逐步认知的过程。</p><p></p><h2>AI&nbsp;Agent的发展趋势和前景</h2><p></p><p></p><p>InfoQ：未来，AI&nbsp;Agent的发展趋势和前景是什么？您看好AI&nbsp;Agent未来的发展吗？您认为多久我们会迎来AI&nbsp;Agent的大规模落地？</p><p></p><p>杨晶生：对于垂直领域，特别是随着大语言模型的不断改进和多模态语言模型的发展，我对未来感到比较乐观。随着这些技术的进步，我们可以期望它们能够更全面地理解知识，特别是在一些协作平台上充当助手的角色。尽管整个行业普遍认为这仍处于早期阶段，但我个人认为，作为助手或者在特定垂直领域的智能代理，在不久的将来，AI助手或代理可能会更多地采用对话式进行交互，而不是以前更倾向于依赖图形用户界面（GUI）的方式。</p><p></p><p>然而，对于所谓的通用Agent，目前还很难预测。尽管大家普遍认为它在加速发展，但我们回顾一下之前的自动驾驶技术，它也曾经经历了一段加速发展的阶段，但后来也遇到了一些瓶颈。</p><p></p><p>通用性意味着Agent能够非针对性的胜任各种任务，你让它针对性的精通100个任务甚至1万个任务，可能都不算通用，实现真正的通用性是非常困难的。尽管我们相信这个领域正在加速发展，但真正的通用人工智能何时实现，我们只能拭目以待。</p><p></p><p>InfoQ：对于想要进入这个领域的公司或个人来说，需要了解哪些相关知识？您有什么意见给到这些人吗？</p><p></p><p>杨晶生：关于这个问题，我的观点可能更倾向于开发者或者初创公司的视角。投资机构和孵化器在创业投资时不仅需要考虑技术和用户，更需要考虑商业层面的因素，我就不细讲了。</p><p></p><p>从个人和项目的角度出发，我将其分为两个层面。</p><p></p><p>第一个层面，当我们基于当前的基础设施，也就是大语言模型或多模态模型来进行应用开发的时候，我们必须对通过这些AI能够解决问题保持信心，这可能需要一些fine-tuning、提示词工程或者进行更底层的模型工作。比如像GPT&nbsp;3.5这样的模型，在最初接触时可能感觉它不那么“聪明”，但我们仍然需要相信通过大语言能够解决问题，而不是用太多的策略妥协。在这方面，我们需要相信这些模型能够从“婴儿状态”进化为“小学生状态”，能够理解并遵循指令，尽管可能需要通过思维链等方式来逐步引导。</p><p></p><p>第二个层面是关于做应用的算法工作者的思维方式。与做工程开发不同，算法工作者更加注重评测。评测在整个过程中至关重要，不仅仅是为了调通，更是为了指导优化和迭代。这种思维方式的改变可能是很大的，需要更深入地理解业务，拆解需求为算法任务并制定指标。最终，理解业务比纯粹的技术能力更为重要。</p><p></p><p>另外，对于那些转入AI应用领域的开发者来说，深入了解机器学习的基础知识和一些计算学的知识可也能是有益的。同样，对于算法研究出身的人，补充一些工程和业务理解的能力也是必要的。总体而言，尽管我们要解决的任务没有发生变化，但如何有效地利用技术来加速这一过程变得更为关键。</p><p></p><p>InfoQ：有观众提出一个问题，是否可以对Agent的Benchmark进行分级，对于这个思路的可行性，我想进行一些讨论。</p><p></p><p>杨晶生：我认为这个思路在理论上是合理的，就像自动驾驶技术一样，它最初也经历了从L1到L5的分级。这位同学提出的建议非常不错，分层评测在不同的阶段可能会更为有益。</p><p></p><p>然而，从实际评测的角度来看，特别是对于通用Agent的评测，目前存在一些挑战。首先，许多评测方法已经为大家所熟知，容易受到过拟合的影响。虽然大多数从业者可能不会真的将评测数据直接训练到模型中，但由于对评测问题的关注，模型在实际训练中可能会有所偏向。我认为评测的同时，我们也需要关注模型在实际业务中的表现，就像自动驾驶技术一样。我们需要观察模型在真实业务环境中的反馈指标，这同样重要。</p><p></p><p>InfoQ：下一位小伙伴可能在金融行业，他想了解下在金融垂直领域方面，开发工作需要涉及哪些方面？考虑到金融行业的竞争可能较激烈，你对于在这个领域从事算法开发有何建议？</p><p></p><p>杨晶生：在金融领域，尽管我个人没有深入从事相关工作，但通过我的理解，我认为金融领域也涉及协作系统。这一部分与其他领域相似，首先要充分利用当前的工具，如Copilot，以提高日常工作效率。对于程序员而言，这可能涉及到处理代码，而对于从事文案工作的人，则可以利用各种文案助手。</p><p></p><p>进一步而言，如果涉及到金融科技，例如量化领域或投资顾问方面，人工智能在这个领域一直备受关注。在金融科技领域，尤其是量化和投资方面，行业内也曾尝试过一些执行策略。这些方法可能是值得尝试的，但在涉及实际交易时，务必保持谨慎。</p><p></p><p></p>",
    "publish_time": "2023-12-28 10:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "领导者如何告别责备，营造容纳失误、鼓励创新的组织文化",
    "url": "https://www.infoq.cn/article/PrK9S9oUZfeRccQ8yfo9",
    "summary": "<p>Diana Larsen 认为，责备文化是对人类潜力的浪费。当人们的精力都用在避免羞耻和责备上时，就无法完成最好、最有创造性的工作。她认为，要做到无责备领导，需要向学习和保持好奇心的方向转变。这需要建立或恢复与人们之间的信任和可信赖关系。</p><p></p><p>Diana Larsen 在 ScanAgile 2023 大会上发表了关于无责备领导的主题演讲。</p><p></p><p>Larsen 表示，企业在招聘最优秀的人才上投入了大量的时间、精力和金钱，但从实际的角度来看，将这些人带入一个责备盛行的文化中意味着这些投资的浪费：</p><p></p><p></p><blockquote>如果一个人总是担心自己会成为责备的对象，那么他就不可能达到自己的最佳状态。这会分散注意力，让人伤心，是对人类潜力的浪费。</blockquote><p></p><p></p><p>Larsen 提到，当人们感觉到责备即将降临在他们头上时，他们会尽其所能来避免。他们会回避、转移责任、隐藏错误。当责备来临时，他们会因为被认为不称职而感到羞耻。她说，当人们的精力用在这些反应上面时，就无法完成最佳或最有创造力的工作。</p><p></p><p>要想实现无责备领导，就需要转变思维方式，并深刻理解当指责盛行时，每个人都会受到伤害。Larsen 表示，责备的对立面是学习和好奇心。她建议，与其寻求指责，不如寻找导致意外、令人失望的事情的系统性根源，比如交付失误、编码错误或旷工等。</p><p></p><p>Larsen 提到，学习式领导可以表现为领导者在员工向其提出问题时承认自己并不了解所有答案。例如，你可以说：“我不知道该怎么做，让我们一起去找出解决办法！”当出现新的、意想不到的问题时，鼓励员工去探索、保持好奇心和学习。</p><p></p><p>无责备领导的第一步是建立或恢复与人们之间的信任和可信赖关系，正如 Larsen 所说的：</p><p></p><p></p><blockquote>我听到过一个挪威谚语：“他们的肩膀耷拉下来了。”我喜欢这句话。问问员工和团队成员，怎样才能让他们停止紧张地耸肩，以一种更顺畅、更放松、更投入的方式专注于工作。很多时候，我们可以很容易得到答案。</blockquote><p></p><p></p><p>Larsen 建议提出类似这样的问题：“怎样才能在把更多的时间投入到工作中？”、“你目前的工作环境缺少什么？”、“怎样才能让你学到完成团队工作所需的知识？”然后，采纳他们的建议，或解释你为什么不能（解释理由必须充分），并要求他们与你一起努力改进，这对你作为领导者以及他们作为团队成员来说都是更好的做法。</p><p></p><p>InfoQ 就无责备领导的话题对 Diana Larsen 进行了采访。</p><p></p><p>InfoQ：责备是如何成为领导方式中根深蒂固的一部分？</p><p></p><p>Diana Larsen：这是人们和人类系统很早就养成的习惯。回想一下，直到一二十年前，责备和打孩子仍然还是学校和家长公认的做法。现在，大多数人都对这种想法感到恐惧。人们把他们在家里和学校里学到和看到的习惯带到了工作场所。</p><p></p><p>甚至还有一些关于责备的传统格言，好像责备是一种预期行为。“让他们受点压力吧。”、“呆在你自己的泳道里！”、“你为什么不能像某某同事一样？”、“谁对这个错误负责？”还有很多其他的回应，比如“在这里，你必须想办法开脱罪责！”、“低调行事”，等等。员工、经理和企业高层领导都已经习惯了这种模式。</p><p></p><p>InfoQ: 领导者必须培养哪些技能才能实现学习式领导？</p><p></p><p>Larsen：如果他们在软件 /IT 行业工作，就需要培养识别、理解、影响和与复杂系统（技术和人文）协同工作的能力。其他的技能还包括学习领导团队而不是个体贡献者，了解动机的变化和团队环境中的重要因素。将领导者的注意力转移到为团队预期的工作性质创造最佳的工作环境上。</p><p></p><p>大多数软件开发团队在学习工作上花费的时间远远超过应用知识的时间。当工作环境充满不确定性、复杂性、模糊性和快速变化（VUCA）时，他们必须关注新的学习相关技能和了解信息的方法。</p><p></p><p>英文原文：</p><p></p><p><a href=\"https://www.infoq.com/news/2023/12/leading-without-blame/\">https://www.infoq.com/news/2023/12/leading-without-blame/</a>\"</p><p></p>",
    "publish_time": "2023-12-28 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "QCon上海站 15 周年盛大开幕，樊文飞、代闻、周靖人、刘向阳、戴金权等行业领袖呈现精彩演讲",
    "url": "https://www.infoq.cn/article/8WjWTHeWhipZerhv55To",
    "summary": "<p>今天，由极客邦旗下 InfoQ 中国主办的 <a href=\"https://qcon.infoq.cn/2023/shanghai?utm_source=infoqweb&amp;utm_medium=kaimuart&amp;utm_campaign=10&amp;utm_term=1228\">QCon 全球软件开发大会</a>\" 15 周年，在上海中优城市万豪酒店隆重举行。会议汇聚了来自阿里巴巴、腾讯、字节跳动、亚马逊云科技等领先企业的技术专家，深入探讨大模型时代下的技术趋势和最佳实践。大会由行业专家领导，聚焦于软件开发的最新动态、创新技术和新兴趋势。与会者将有独特机会与业界精英交流思想、分享观点，并从领域内的最前沿人物那里获得知识。</p><p></p><h3>开幕精华：激动人心的序幕</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ad/ad490c066808e5afeb8f0cd9603d97af.jpeg\" /></p><p></p><p>本次大会于早上 8 点 30 分准时开幕，极客邦科技首席执行官 霍太稳 为大会致开幕辞，他带领大家回顾了 QCon 的 15 年历程，揭示了 InfoQ 如何坚守内容专业性和深度，并表彰了一直以来支持 QCon 的众多合作伙伴和传播者。霍太稳特别向那些支持 QCon 的众多合作伙伴表达了感谢，正是有了这些不懈的支持，极客邦得以成长为国内顶尖的技术大会传播者。霍太稳还介绍了莅临本次大会的部分专家，其中包括樊文飞、代闻、周靖人、刘向阳院士和戴金权等业界知名人士。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/70/70ee4f8a1a42d910c734efe889dbdc26.jpeg\" /></p><p></p><p>接着，霍太稳隆重揭晓了“2023 数字化践行者年度力量榜”，共有 56 个项目获得认可。这份榜单涵盖了 20 家杰出的年度数字化践行者标杆企业，如福建宁德核电有限公司、中国联合网络通信有限公司、汇丰银行 (中国) 有限公司等。同时，还颁发了 10 个年度数字化践行者基石奖，包括麦当劳中国 IT Digital Customer Journey 团队、温氏数字化转型先行示范区团队、国泰君安数据创新应用团队等。此外，表彰了 10 位在企业数字化人才发展方面表现出高潜力的个人，以及 16 位在极客时间企业服务领域光芒四射的璀璨明星导师；</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f8/f846485d3b49f5c31b4cf4342b6ebb4d.jpeg\" /></p><p></p><p>接着，霍太稳正式发布了《基础软件之路 - 企业级实践与开源战略》一书，进一步加深了参会者对企业级软件实践与开源战略的理解。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e4/e4f54b76e181994c7a2f85248aa76eb0.jpeg\" /></p><p></p><p>紧接着，极客时间宣布正式成为亚马逊认证品牌，这一成就不仅标志着其认证范围的进一步扩大，也继阿里云之后，迎来了亚马逊云科技的重要合作。在此次大会上，亚马逊云科技大中华区解决方案架构部总经理代闻先生与极客邦科技 CEO 霍太稳先生共同主持了授牌仪式，并对极客时间在技术教育领域取得的成就表示了高度认可和肯定。</p><p></p><h3>主题演讲：洞察前沿技术趋势</h3><p></p><p></p><h4>主题演讲：Big Data：From Theory to Systems</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c8/c8228d4f3d1fd64b16953ebde6f891fd.jpeg\" /></p><p></p><p>大会的首场演讲由<a href=\"https://qcon.infoq.cn/202312/shanghai/presentation/5623?utm_source=infoqweb&amp;utm_medium=kaimuart&amp;utm_campaign=10&amp;utm_term=1228\">中国科学院外籍院士、国际知名数据库专家樊文飞教授</a>\"分享 ， 他深入阐述了大数据的五大挑战——体量、速度、多样性、真实性和价值，特别强调了在数字经济时代下，大数据处理面临的新挑战和新机遇。他介绍的 YashanDB 数据库管理系统，是专为处理复杂的混合工作负载而设计，通过有界评估理论，有效控制在处理 PB 级别数据时的查询和存储成本。</p><p></p><p>此外，樊教授还讨论了大数据的真实性问题，特别是如何通过系统改善数据质量和准确性。他的研究还涉及到了如何利用机器学习和逻辑推理来挖掘大数据的潜在价值，以及如何通过 Fishing Fort 和 Rock 系统增量化算法处理动态数据。这些研究不仅提供了理论上的创新，还展示了如何在金融、智能城市和生物医药等领域实际应用这些先进的技术。</p><p></p><h4>主题演讲：云端俭约之道：如何设计出成本优先的技术架构</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b8/b89f6cde2f987b5da61d25d7d9d434c9.jpeg\" /></p><p></p><p>随后，<a href=\"https://qcon.infoq.cn/202312/shanghai/presentation/5685?utm_source=infoqweb&amp;utm_medium=kaimuart&amp;utm_campaign=10&amp;utm_term=1228\">亚马逊云科技大中华区解决方案架构部总经理代闻</a>\"分享了“云端俭约架构”的设计理念。</p><p></p><p>随着全球云计算支出不断增长，作为全球云计算引领者的亚马逊云科技也意识到，这个行业所带来的成本压力正在随着生成式 AI 等技术的广泛采用而不断增加。因此，“成本效益”这一话题对于架构师而言变得愈发重要。基于亚马逊云科技多年在云计算领域的技术与客户经验，提出了以成本为核心的一系列架构设计准则，让架构师能够在云端发挥更为关键的作用，以帮助企业实现更好的成本控制和效率优化。</p><p></p><p>从对成本的感知、设计，再到度量和优化，代闻分享了在架构设计的不同阶段的七条原则，并给出了亚马逊云科技的建议以及案例，这些原则包括了对关于成本需求的定义，与业务、系统的匹配与权衡，对成本的观测及感知，以及如何实现持续的架构优化。</p><p></p><p>在技术领域，并没有什么工具或理论是完美的，因此，架构师需要进行持续的取舍与平衡，企业也需要根据业务需求和成本效益进行权衡，以探索如何在各种约束下做出最佳决策，以及如何通过创新和适时调整架构来适应不断变化的业务环境和技术进步。代闻分享了亚马逊云科技所提倡持续地改进和学习的态度，鼓励架构师们走出舒适区，挑战现状，通过不断的优化和创新来提升业务的可持续性和成本效率。世界瞬息万变，新的技术不断被提出，组织面临的成本压力、驱动应用程序所需的资源也在不断增加，即使在有限的资源和大环境的约束下，创新和精细管理也能找到优化的空间。因此，“俭约架构”也将成为未来一段时间云计算领域的重要议题之一。</p><p></p><h4>主题演讲：MaaS 模型即服务的创新实践</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/68/6817e245b4df8dcf460f0efc724701a6.jpeg\" /></p><p></p><p>接着，阿里云 CTO&nbsp;周靖人以《MaaS模型即服务的创新实践》为主题展开了分享。周靖人特别提到了云计算在所有 AI 发展中的基础作用，并讨论了为了进行大模型训练所需解决的一系列问题，例如高吞吐量存储、计算节点的构建，以及网络架构的重要性。他还强调了在分布式训练过程中，系统可用性、故障处理以及资源管理的技术难题，并介绍了阿里云在这方面的解决方案。</p><p></p><p>接下来，周靖人分享了模型的服务化 MaaS，即如何将这些大模型有效地应用于业务场景。他强调了模型推理的重要性，尤其是在大模型时代，模型服务的成本昂贵，因此需要优化技术来减轻企业负担。他提到了模型量化、模型弹性伸缩等关键技术，以及如何在业务高峰期快速提供服务的挑战。</p><p></p><p>最后，他详细介绍了阿里云的几个大模型产品，包括为开发者服务的各种模型和工具，如通义星尘、通易听悟等，以及其它支持企业内部业务和客户服务的 AI 工具。这些产品的目标是利用大模型的强大能力来提高工作效率、创新产品和服务，以及优化客户体验。他还提到了阿里云推动模型的开源，以及建立模型社区的努力，旨在促进更广泛的创新和应用。</p><p></p><h4>主题演讲：系统稳定与信息安全——体系建设与实战经验</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/76/7646dae9b21e37c688ce2ae068484694.jpeg\" /></p><p></p><p>接下来，<a href=\"https://qcon.infoq.cn/202312/shanghai/presentation/5630?utm_source=infoqweb&amp;utm_medium=kaimuart&amp;utm_campaign=10&amp;utm_term=1228\">美的集团首席信息安全官兼软件工程院院长，欧洲科学院院士，IEEE Fellow 刘向阳</a>\"， 他分享了在工业界的实战经验，特别聚焦于系统的稳定性和安全性这两个方面。</p><p></p><p>首先，他指出互联网大厂面临的稳定性挑战，包括因软件 bug、系统升级或数据中心故障等原因导致的系统崩溃。他提到，尽管技术日益精密和复杂，但这也使得系统更加脆弱，容易出现故障。为了应对这些挑战，刘老师强调了预防故障、减少风险、快速响应故障等策略的重要性；</p><p></p><p>其次，刘向阳深入讨论了安全性问题，尤其是在面对日益复杂的网络攻击时，如何构建强大的安全防御体系。他详述了黑客攻击、内部泄露、数据盗窃等安全威胁，并介绍了一系列安全策略和技术，包括数据加密、访问控制和风险评估。刘老师特别强调了应对策略的多层次性和全面性，包括技术解决方案、组织管理和员工培训等方面；</p><p></p><p>最后，刘向阳强调了技术和业务层面的变更管理的重要性。他讨论了如何通过有效的变更管理策略，包括预案、监控、定位、演练和培训等，来减少由于变更带来的潜在风险。通过综合考虑技术、过程和人员的各个方面，可以确保业务的连续性和服务的稳定性，即使在不断变化和更新的环境中也能保持效率和安全。</p><p></p><h4>主题演讲：大语言模型的低比特计算</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1c/1c0d5fb713f3ca2985a64e08b89c964f.jpeg\" /></p><p></p><p>最后，英特尔大数据技术全球 CTO 戴金权 登台发表演讲，他深入介绍了大语言模型低比特计算的前沿技术，并展示了 BigDL-LLM 这一基于英特尔 XPU 平台的轻量级大模型开源加速库。他详细阐述了如何通过模型量化、数据类型优化和低比特算子来提升大语言模型的运算效率和性能。BigDL-LLM 作为一个支持标准 PyTorch 模型和 API 的加速库，仅需简单几行代码即可实现对现有应用的加速，涵盖了模型压缩、低比特优化等技术，旨在为处理大型模型提供一个全面且高效的解决方案；戴金权还特别强调了 BigDL-LLM 在实际应用中的表现，如其在英特尔笔记本、英特尔锐炫显卡等多种硬件上构建大型语言模型应用的能力。</p><p></p><h3>现场回顾：技术热潮中的激情交汇</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/e7/e7a4774b1ea82743554dd03518ba26cb.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ec/ece93fa51a4eaee85d4a8f90dbe9ea7d.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cb/cb5c2cd17b20fb582f9eea883ae201a6.jpeg\" /></p><p></p><p>大会上午人气爆棚，现场座无虚席，甚至有不少热情的听众站立聆听。许多参与者反馈，QCon 提供的内容实用且深具价值，是业界的干货集中地。我们深受鼓舞，希望在大家的不断支持与鼓励下，继续努力成为技术传播领域的佼佼者，不断提供高质量的内容和交流平台，共同推动技术界的发展与进步。</p><p></p><h3>精彩瞬间：活动亮点集锦</h3><p></p><p></p><h4>大模型体验馆：前沿技术亲历之旅</h4><p></p><p>自 5 月份广州站以来，QCon 在每一站的现场都精心设置了大模型体验区，为参会者提供了一个亲自动手实操大模型的宝贵机会，并与相关开发者进行面对面的深入交流。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/61/61b370bd2f9eed22b428601335c342e6.png\" /></p><p></p><p>在本次 QCon 15 周年庆典中，我们将对大模型展区进行前所未有的升级。十二家与大模型相关的顶尖企业将亲临现场，国内最强大的大模型力量将集结一堂，带来前所未有的阵容和体验。让我们一起期待见证这些精彩瞬间吧！</p><p><img src=\"https://static001.geekbang.org/infoq/e0/e01398664752f112c6146dd7fe637afc.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4b/4b90833ee65c1d6dbcc454183d7ff4e2.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e3/e338abe03acf6dcde47a2e4dce5eddb2.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/02/02cd40dc8c9977f04ca9e9a366a14d45.jpeg\" /></p><p></p><p></p><h4>赞助商展示区：技术创新的支持者</h4><p></p><p>每一届的会议都离不开赞助商的鼎力支持，InfoQ 尤其如此。正是得益于各界的慷慨助力，我们得以年复一年地持续推动技术的传播与创新。本次 QCon 大会得到了众多赞助商的大力支持，包括矩阵起源、The Trade Desk、Azul、IPIP、PingCode、Coupang、亚马逊云科技、北极九章、Authing 等。他们的参与不仅为大会增色不少，也为技术共享和行业发展提供了坚实基础。接下来，请和我们一同回顾这些精彩瞬间。</p><p><img src=\"https://static001.geekbang.org/infoq/c6/c69a734fe7154084d155712b457f808a.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b3/b359041d0ed8fe2969a566321e180ef7.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c9/c973e074552d10955b0f32ac1d5fd7d7.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/38/388d1fb3d8593692f943af68a2973169.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/62/62a6679b15c90af8cbaced9a0c23cb72.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0f/0f47bd4da0e69b180241079e00dce773.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/48/48d68c704231d4d52edd39c23cad843e.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/10/1061552c31821f15a192ebc1cd1e0687.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2c/2c1478980e0c2268fd8efb079009f8ae.jpeg\" /></p><p></p>",
    "publish_time": "2023-12-28 14:59:27",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "百度CTO王海峰：文心一言用户规模破1亿",
    "url": "https://www.infoq.cn/article/dL3HCBjbuL6H9ezZxcaL",
    "summary": "<p>“文心一言用户规模突破1亿。”12月28日，百度首席技术官、深度学习技术及应用国家工程研究中心主任王海峰在第十届WAVE SUMMIT深度学习开发者大会上宣布。会上，王海峰以《文心加飞桨，翩然赴星河》为题作了主旨演讲，分享了飞桨和文心的最新成果。</p><p></p><p>WAVE SUMMIT深度学习开发者大会始于2019年4月，每年两次与开发者相聚，如今已是五载十届。&nbsp;</p><p></p><h2>飞桨开发者已达1070万</h2><p></p><p></p><p>回顾五年，大会一路见证了百度对人工智能技术和产业趋势的前瞻判断，指引了技术创新和产业实践的方向。2019年王海峰在首届大会上提出，深度学习框架是智能时代的操作系统。深度学习的通用性特点，以及深度学习框架及平台的发展，推动人工智能标准化、自动化和模块化，进入工业大生产阶段。2020年，王海峰提出了打造AI新型基础设施，云智一体加速产业智能化，将AI大生产平台升级为云智一体的新型基础设施，为产业智能化奠定坚实的基础。2021年，王海峰表示，人工智能呈现出“融合创新”和“降低门槛”的特点：一方面，AI技术及产业的融合创新越来越多；另一方面，虽然AI技术越来越复杂，但AI开发与应用的门槛却越来越低。2022年，王海峰进一步提出，深度学习平台加上大模型，贯通了从硬件适配、模型训练、推理部署，到场景应用的AI全产业链，夯实了产业智能化基座。今年，大语言模型的出现，为通用人工智能带来曙光。</p><p></p><p>五年来，在持续技术创新和赋能产业的发展历程中，飞桨自身也在不断升级，从深度学习框架，到平台生态，发展成为技术领先、功能丰富的产业级深度学习开源开放平台。飞桨集核心框架、基础模型库、开发套件、工具组件，以及助力开发者成长的星河社区于一体，具有动静统一的深度学习框架、端到端自适应大规模分布式训练、云边端全场景高性能推理等关键核心技术。</p><p>&nbsp;</p><p>飞桨生态愈加繁荣，2019年，凝聚在飞桨平台的开发者规模150万，到今年8月的Wave Summit，已经达到800万，服务的企业数量、基于飞桨创建的模型数量，也都高速增长。王海峰现场公布了飞桨生态最新成果，截至2023年12月底，飞桨已凝聚1070万开发者，服务23.5万家企事业单位，基于飞桨创建了86万个模型。</p><p></p><h2>文心一言用户规模破亿，日提问量快速增长</h2><p></p><p>&nbsp;</p><p>据了解，百度自2019年起深耕预训练模型研发，发布了文心大模型1.0。经过近四年积累，百度于今年3月在全球科技大厂中率先发布了知识增强大语言模型文心一言。10月，文心一言的基础模型升级到4.0，理解、生成、逻辑和记忆四大人工智能基础能力全面提升。文心大模型4.0过去两个多月整体效果又提升了32%。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/19/195211511d8c6d61dd777a25f4508376.png\" /></p><p></p><p>王海峰现场披露，文心一言用户规模已突破1亿，自8月31日获准开放对公众提供服务以来，文心一言的用户提问量一路上扬，基本与文心大模型的效果提升同步。越来越多的用户在信任和使用文心一言。</p><p>&nbsp;</p><p>王海峰最后表示：“五载十届，我们与所有开发者一起，踔厉奋发，笃行不怠。愿继续与所有开发者携手并肩，在飞桨和文心的支持下，共赴通用人工智能的星辰大海！”</p>",
    "publish_time": "2023-12-28 16:02:51",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]