[
  {
    "title": "Lyft如何检测生产中安卓的内存泄漏",
    "url": "https://www.infoq.cn/article/MuATtLq6R00gEssCOwzj",
    "summary": "<p>尽管现代的安卓和iOS工具都能通过本地构建检测内存泄露风险，但应用程序在生产环境中的内存表现却依旧得不到百分百的保障。生产环境中的程序可能在各种条件下运行在各种设备上，为此，<a href=\"https://eng.lyft.com/detecting-android-memory-leaks-in-production-29e9c97e2ba1\">Lyft的工程师将A/B测试与内存可观察性相结合</a>\"，从而检测可能造成内存泄漏的应用功能。</p><p></p><p></p><blockquote>在发布大型且复杂的功能点时，我们需要特别关注其在内存使用方面是否会造成回归。这点在包含本地C/C++代码的功能发布时更为关键，因为这部分代码更易于引入内存泄漏。</blockquote><p></p><p></p><p>在一般情况下，Lyft工程师所遵循的方式是用测量的应用程序的标准内存行为基线，对比在A/B测试中所采集的特定功能受众子群数据。在评估应用的整体内存使用上，Lyft工程师考虑了几款<a href=\"https://developer.android.com/topic/performance/memory-management\">安卓上可用来检索内存使用指标的API</a>\"：比例集大小（PSS）、唯一集大小（USS）、常驻内存大小（RSS）。其中RSS因其在性能方面的特点，以及可以不受采样率限制的特性而脱颖而出。其他Lyft工程师们感兴趣的指标，如JVM堆和本地堆大小等，都支持在安卓运行时直接采集。</p><p></p><p>内存指标的重要采集场景有两种：每次UI界面关闭时，以及用户在同一界面长时间停留的情况下每分钟的采集间隔。</p><p></p><p>因此，为判断一项功能是否会造成内存回归，Lyft工程师对比了用户群组在运行禁用该功能时的原始版本，与启用该功能应用版本的情况。内存使用情况随用户而异，故而将应用内存使用足迹以曲线形式显示，如果两种情况下内存足迹曲线出现，则表示可能存在内存回归情况，如下图表示：</p><p></p><p><img src=\"https://imgopt.infoq.com/news/2023/01/lyft-android-memory-leaks/en/resources/1lyft-memory-leaks-production-1674813678638.jpg\" /></p><p></p><p>一个有趣的发现是，内存泄漏只影响一小部分用户。因此，除了百分比较高的部分（取决于用户群组大小），内存足迹曲线实际是会几乎重合的。如下图中所示，内存泄漏只会发生在极特殊的情况下，仅影响用户群组的最后一段百分比。</p><p></p><p><img src=\"https://imgopt.infoq.com/news/2023/01/lyft-android-memory-leaks/en/resources/1lyft-memory-leaks-prod-2-1674813678638.jpg\" /></p><p></p><p>Lyft的工程师称，这种方式已被证明可以有效检测内存泄漏，尤其是特殊情况下极易在本地测试时遗漏的内存泄露。还请不要错过Lyft原文中的全部细节。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/01/lyft-android-memory-leaks/\">How Lyft Detects Android Memory Leaks in Production</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/pz1YayKHBuqqtvHQpbOC\">探索 Android 14：首个开发者预览版的新功能与特性</a>\"</p><p><a href=\"https://www.infoq.cn/article/DQRTjfuXwqDQCbwAtVYl\">Spotify 移动工程平台迁移：将 Android 和 iOS 代码库迁移到 Bazel</a>\"</p>",
    "publish_time": "2023-03-22 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "2023 “Kubernetes 管理” 将路走何方？",
    "url": "https://www.infoq.cn/article/Y5Hitdvoha3By3HNb3jd",
    "summary": "<p>Kubernetes 从 2014 年开源至今，在云原生领域的地位已经逐渐稳固。从宏观层面来看，Kubernetes 解决方案的引进路径十分清晰，在许多企业的落地实践中均得到了成功的验证。目前企业级 Kubernetes 解决方案逐渐成为大势所趋，但不少企业对此仍持观望态度。那么，2023 年 <a href=\"https://www.infoq.cn/article/2fHFRAFOYTE5QZaXbU43\">Kubernetes</a>\" 管理将路走何方？</p><p>&nbsp;</p><p>为了得到这个问题的答案，InfoQ 极客有约邀请到了一直活跃在研发一线、经历了 OpenStack 到 Kubernetes 技术变革的 <a href=\"https://www.infoq.cn/article/HmppHMJseJVj7sZkR7Te\">Rancher</a>\" 大中华研发总监张智博老师，听他跟我们聊聊 Kubernetes 在企业中的落地实践，共同探讨一下关于 K8s 的发展现状及未来趋势。</p><p>&nbsp;</p><p>以下为直播内容整理：</p><p></p><p></p><p></p><p></p><h4>InfoQ：您认为，企业为什么需要 Kubernetes？</h4><p></p><p></p><p>张智博：企业不断采用 IT 变革技术，本质上它需要的是容器技术给它带来生产力的提升，而非完全依赖 K8s。实际上，容器技术也确实提升了企业应用的分发效率、打包效率以及整个生产的迭代效率。</p><p> </p><p>就目前行业发展情况来看，要将容器进行整体管理，K8s 仍是最佳选择。此前虽出现过同类软件，但已经在近几年的发展过程中逐渐消亡。尽管还有其他一些小众选择，但那些选择要么缺少生态维护，要么得不到大的云厂商支持。即便想要落地，也找不到可用且相对稳固的技术工具和技术栈。因此，我们认为 K8s 可能是当前时代已有的、唯一的选择。</p><p></p><p></p><h4>InfoQ：企业使用 Kubernetes，究竟是走开源自建路线，还是购买商业服务路线？Kubernetes 开源版和商业版的区别究竟在哪？为什么现在 Kubernetes 商业化是大势所趋？</h4><p></p><p></p><p>张智博：对于企业而言，无论怎样选择，采用新的技术就要付出成本。而企业到底关注人员成本还是 IT 成本，不同企业有不同的选择。关注 IT 成本的企业可能会选择开源自建，在它看来企业投入资金去采购新的软件，这些费用会算在 IT 的支出费用里面，所以它更倾向于开源自建。开源自建只需满足开源的 License，便可以免费使用。而企业如果比较关注人员成本，希望把精力聚焦在企业自身业务上，选择购买商业服务就更好。</p><p> </p><p>开源自建相当于把依赖新技术带来生产力变革的这些关键战略绑定到了具体的人员身上，这对企业来说存在一定的风险。开源软件并非完美无瑕，也难以一直保持稳定，它需要持续地维护。在这过程中如不能深入到开源项目里面，自建就存在长期的技术风险。在这种背景下，企业负责人就要深度评估企业是否真正具备自建的技术能力。虽然当前很多开源软件的开箱即用做得确实不错，但这并不代表它背后没有相应的技术成本。</p><p>   </p><p>商业服务有别于开源自建，它相当于把带来生产力变革的关键战略锁定到了外部的第三方公司。在这个过程中，一旦供应商的产品或者迭代方向发生改变，或者服务不能满足企业的使用期望，亦或者在使用过程中价格被锁定，均会影响 IT 的变革。如果企业被某个商业公司所独有的技术锁定，随之带来的风险是非常大的。</p><p> </p><p>根据我的工作经验，我还是很看好 <a href=\"https://www.infoq.cn/article/5PtWSi6llYP4ji0HXmMV\">SUSE</a>\" 这类公司的未来的。IT 主流的选择应该是用户去选择开源产品的商业服务，去购买开源产品的订阅，这样可以较好地屏蔽供应商锁定的问题。能够提供开源商业支持的公司很多，即使一家公司出现了问题，或者它的产品无法满足你的需求，由于你依赖的仅仅是开源的技术或产品，因此可以很容易地把供应商换掉。</p><p> </p><p>即便企业未来不希望再受供应商和商业服务公司的牵制，或者企业具备技术自建能力且业务发展很好，它依然可以在之前复用的开源产品的技术底座上再往前走，甚至可以抛弃这些商业服务，因此这本质上是一种风险对冲。所以我认为真正的大势所趋就是开源产品的商业服务。</p><p> </p><p>开源版和商业版的区别主要在于：你作为使用者是否愿意付费。开源产品具有 license，有的 license 允许商用，也允许二次分发。在这过程中，有的用户有意愿付费，他希望通过付费获取保障。但有的用户则认为不需要付费，因为这已经是开源了。当然，从产品功能角度两者也有区别。通常来讲，商业版本有比开源版本更稳定的产品迭代，更稳定的服务，可以使生产环境运行得到保障。至于内部功能性的差异，不同的厂商有各自的表述。总之，开源版和商业版的区别第一是付费意愿，第二在于增强的一些功能。</p><p> </p><p>关于第三个问题，我个人的观点是，开源产品的商业服务是大势所趋。提到 K8s 商业化是大势所趋，我第一印象会认为这个观点是错的。K8s 本身是一个成功的开源软件，它的采用量势必会不断攀升，随着采用量的攀升，必然会产生一定数量的商业客户。商业客户增加、付费市场规模扩大，整个环境就会更好，但是真正的趋势应该是更多的用户为开源软件的商业服务付费。</p><p></p><p></p><h4>InfoQ：过去一年里，企业都在优化人力成本、运营成本，都很关注降本增效，基于企业降本增效这个大目标，Kubernetes 是如何帮助企业降本增效的？ “Kubernetes 商业化”、企业级的 Kubernetes 管理软件，究竟能为企业降本增效提供多少助力？</h4><p></p><p></p><p>张智博：降本增效的确是今年大家普遍在提的一个话题。需要先明确一个事实，即：通过一个软件实现降本增效是非常复杂的。究其本质，真正提升效率、降低整个迭代成本的是容器技术，容器技术助力生产力提升，效率也随之提升。因此，一定是在走完容器化改造之后，才能看到降本增效的优势。绝不是随意创建几个 K8s，再布置几个业务上去，就能实现降本增效。有的用户可能会在大量的虚拟机上跑一些纯粹的东西，导致资源利用率很低，又执意要创建 K8s，这其中的成本反而是上升的。</p><p>&nbsp;</p><p>因此，第一步应该是有一个合理的规划，即容器化达到何种程度后再迁移到 K8s 里面。机器的使用率降低，资源利用率提高，如此才能达到降本增效。值得注意的是，容器化改造应是真正系统化的梳理、改造，而非简单建几个 K8s 就草草了事。系统改造之后，真正上到 K8s 就会发现，目前所有的云厂商都提供 K8s 服务。也就是说，一旦你的业务体系全部容器化到 K8s 上，你就拥有了面向多云使用的天然便利。面向多云使用，必然会增加议价权以及使用的多样性，这样你就可以选择成本低的地方去部署业务。</p><p>&nbsp;</p><p>此外，我们讲基础设施，自己公司内部的基础设施就做了一个很好的抽象。以前我们讲叫 DevOps，现在可能又改头换面叫平台工程。在我们厂商看来其实没有太大区别，因为我们有的客户在没有平台工程这个概念之前就有这种理念。他把东西容器化之后放到 K8s 里面，业务就可以跟着 K8s 去走，整套环境的部署，无论是开发、测试，都可以通过 API 对接起来。依托 K8s 基础设施，包括上层应用这一整套的业务系统，可以到任意的云上去部署。这个就是我们讲基础设施即代码所具备的能力。</p><p>&nbsp;</p><p>综合来看，企业降本增效的关键在于整套 IT 系统和业务流程能否真正实现工程化，是更多地依靠人来部署、接入，还是通过自动化的平台去做。借助 K8s，你不需要自己去抽象 API，也不需要自己去打通生态，K8s 均可实现。由此我们可以看到 K8s 助力企业降本增效的效果。</p><p></p><p></p><h4>InfoQ：您认为，企业级的 Kubernetes 管理软件最关键的功能是什么？</h4><p></p><p></p><p>张智博：肯定是多集群群管理。为什么是多集群管理？我们可以回看历史发展进程，针对 K8s 落地大厂之初如何引导用户。我们创建了一个超大集群，其中可能包括几千甚至上万节点。由于这些超大的集群里面涉及很多深度的技术优化、内核优化，甚至还可能会模仿 K8s,所以他们最终实现起来，资源利用率的确很高。但是这个所谓的最佳实践或是说工程经验，是没有办法复用到更多的企业用户手里面的。</p><p>&nbsp;</p><p>原因在于大厂的人员、技术实力是绝大部分用户所不具备的。为什么开始有多集群这个概念出现，就是因为多集群的管理更适合绝大部分用户。我们说尽量不要去魔改一些开源软件，因为一旦改完之后却无法做到长期维护、长期更新、长期升级，你的这些东西跟它的生态便不再兼容，从而很容易锁定到一个版本之上。即便有了解这些功能的人，也无法避免这些人离开后技术无人维护的情况发生，最终反而变成技术负担。</p><p>&nbsp;</p><p>在后面的发展过程中，我们看到越来越多的商业厂商开始研究 K8s 的发行版，且各具特色。但是如果你所用的管理软件不是多集群管理，你就没有办法把你需要且有特色的发行版纳入到你的管理体系当中。相当于我们本希望依托开源软件的开放性吸纳更多的生态来支撑自己的业务，但是由于没有选择这条技术路线，反而又被自己设定的牢笼锁定了，这就错失了开源生态带来的红利。</p><p>&nbsp;</p><p>因此长期来看，多集群管理模式肯定有利于企业，也有利于 IT 行业长期的风险管理和成本控制。</p><p></p><p></p><h4>InfoQ：在多云环境下运行 Kubernetes，复杂性大幅增加，企业运维难度也大大提升，目前市面上有没有企业级的 Kubernetes 管理软件已经解决了？在解决这些问题时主要会遇到哪些挑战？除此之外，有什么其他的比较好的解决方案吗？</h4><p></p><p></p><p>张智博：当前，K8s 对云厂商来说已经是非常重要的基础设施了，而且变成了一种服务。每个用户只要有云的账号，就很容易拿到一些资源。但是我们要明确，对于一个企业而言，选择哪朵“云”就意味着它的业务在哪里。海外有 AWS、Azure、GCP，国内有阿里云、华为云、腾讯云，包括新近崛起的天翼云等，每朵“云”都有自己的特色。面向不同属性的客户，每朵“云”也都有自己的技术优势。</p><p>&nbsp;</p><p>对于企业级的 K8s 管理软件来说，有这么多的云，每朵“云”都有类似的服务，该支持哪个？是聚焦海外还是专注国内，还是全都支持？每个云都有自己 K8s 发行版的生态演进计划，它并不会跟其他云相互搭配、相互沟通。虽然上游有 K8s，但是每朵“云”都有各自的版本跟踪计划，所以这个挑战很大。管理软件所支持的云越多，复杂程度会越高。</p><p>&nbsp;</p><p>虽然云厂商有 K8s，但也有用户喜欢在云上自建。他们认为这样自由度更大，可以更多地去控制。其实，我们在很早就改变了 Rancher 这个软件的产品理念。我们本身就把云上的用户设定为第一优先级的用户，因为从整个市场份额来看，K8s 的绝大部分市场份额在公有云这一侧。虽然有人更关注私有化部署，但是绝大部分用户仍在公有云这一侧。而在公有云这一侧的又有自建的，有托管的，这给管理软件又增加了一层挑战。不仅要支持公有云的托管，还要支持面向公有云的虚拟机的服务，帮助用户自建 K8s。这就使得软件的知识矩阵变得很复杂，对软件维护者的要求也相应提高了。</p><p>&nbsp;</p><p>具体有哪些挑战，我结合前面内容进行一下总结。第一是云有很多种，种类不同，接入生态就会很复杂。第二是知识矩阵很复杂，用户既有自建的需求，又有用托管的需求。到底有没有特别好的方案？其实，现在市面上所有的主流管理软件，都声称具备多元的 K8s 管理功能。但是要细看其到底支持多少种云，支持自建的模式还是公有云托管模式，这方面我认为 Rancher 做的比较好。</p><p></p><p></p><h4>InfoQ：Rancher 有一个非常著名的开源产品 K3s，由于其轻量级的属性，很多用户将其放到边缘场景。企业级的 Kubernetes 管理软件在边缘环境下主要需要解决哪些问题？目前市面上的产品已经解决了吗？</h4><p></p><p></p><p>张智博：除了 Rancher 这个软件主打的 K8s 多集群管理，K3s 确实是我们另一款发展非常好的软件。最早我们设定 K3s 是很轻量的，由于边缘计算正处于发展中，大家就开始尝试将容器化落地到边缘场景中，K3s 自然而然就开始有了一些边缘的场景。但是针对边缘的场景需求，不同厂商、不同用户的理解均不同。每个厂商都是聚焦在自己的认知之下，帮助自己的用户来解决这个问题。</p><p>&nbsp;</p><p>K3s 的定位是比较专一的，本质上我们设定 K3s 是满足 K8s 一致性测试标准的一个发行版，意思是 CNCF 推出 K8s Conformance，你要去跑它的一系列的端到端测试才能验证这是一个标准的发行版，K3s 将永远聚焦于这个点。这也意味着 K3s 不会为了某个特定的场景去魔改，因为魔改之后会造成兼容性问题。如果强行把 K3s 落地到边缘，部分用户场景就会出现问题。因此，从产品的原生设定角度跟大家做出解释。</p><p>&nbsp;</p><p>关于管理软件在边缘环境下解决的是什么问题，我没有办法从整个行业的角度去讲，因为每家厂商都不一样。从我们的角度来看，边缘上如果在用 K8s，或者要用 K3s 技术把你的业务打包到 K8s 这种抽象的 API 里面然后再去部署，我们认为它并不能解决全部的边缘场景，它只是在解决一个近端的边缘场景。在我们的解决范畴内，目前 K3s 就只能到这一层，因为它需要依赖于一个有一定计算能力的设备，这样才有能力在上面跑 K8s 的编排引擎和容器化组件。如果没有这个计算能力，只能供给业务，那再弄一个基础引擎上来完全是浪费资源。</p><p>&nbsp;</p><p>我们目前先解决近端边缘场景之下的问题，因为近端边缘是具备一定算力的。通常无论是 ARM 架构还是 X86 架构，都需要一个操作系统，需要有编排引擎去承载业务，我们把它抽象成一个不可变的基础设施。相当于 OS 加上 K3s，由于 SUSE 本身就是 Linux os 厂商，所以我们做这个东西的产品化做得还是很好的。</p><p>&nbsp;</p><p>目前，我们在边缘领域的确能够解决问题，但是边缘这个市场十分庞大，更多的内容我也讲不了。用纯粹的容器化或者 K8s，去尝试解决所有的边缘问题，包括远端的、IOT 设备管理的，其实非常复杂，起码目前从我们这边还没有看到一个特别稳定的市场机会。</p><p>&nbsp;</p><p></p><h4>InfoQ：整体来看，国内企业对于 Kubernetes 落地及管理的要求是怎样的？</h4><p></p><p></p><p>张智博：国内企业我们要分开来看，有一些企业要求自主可控；有的企业要求标准的商业化生产场景，你能够解决问题就可以。其实无论是国内还是海外，都没有太大区别。对于自主可控，国内的企业更关注 ARM 的支持，因为有很多用户都在依赖 ARM 去运行 K8s。</p><p>&nbsp;</p><p>目前，ARM 开始在公有云上普及，整个软件生态也都在支持。所以提到要求，我认为首先要支持 ARM，这样你才有机会参与到这些自主可控的企业里面。第二是自主可控更深层次的需求，即软件的供应链，它跟工业品或者其他有限制性的商品的供应链是一样的。</p><p>&nbsp;</p><p>现在都在提软件供应链的等级，即你提供出来的软件的构建、编译是不是可溯源？你构建出来的产物，有没有软件物料清单？构建出来的东西，用户使用验证时，能否做到不被篡改？以上这些是国内当前在自主可控领域开始关注的方向。</p><p>&nbsp;</p><p>我们确实也在进行全新的探索。比如，国内自主可控领域在操作系统层面更多地运用 openEuler 或者 openEuler 衍生系列。同时，我们也在尝试构建一个 K8s 的发行版，相当于把 openEuler 的生态变成一个生产车间，把 K8s 依赖的上游源代码全部灌入到生产车间里，通过生产车间来生产 K8s 的发行版。在发行版里面，我们可以把软件的物料清单、工程量等信息公示出来。<a href=\"https://mp.weixin.qq.com/s/1-5dGH8IC5IQznoKKrU0pA\">目前，Rancher For openEuler 的发行版已经 GA</a>\"。</p><p></p><p></p><h4>InfoQ：从产品角度，Kubernetes 需要哪些增强来支持这一轮商业化的发展？</h4><p></p><p></p><p>张智博：技术发展是有规律的。想知道今年商业化有什么新动向，就去看去年开源的领域在研究什么新东西。去年 K8s 到 1.24 版本后就开始把软件供应链相关的信息融入进自己的发布流程里面，我们不难发现今年很多 K8s 的商业化公司都在提软件供应链。上游社区技术演进涉及到的方向，商业公司绝不能错过。因为商业公司至少要把上游社区所能实现的东西呈现出来，也就是所谓的软件供应链，然后才能进一步加强。</p><p>&nbsp;</p><p>关于如何“加强”，现在大的趋势是技术布道。K8s 已经走过了飞速发展的创新阶段，现在它要做的是企业落地，并且加速企业落地。随着越来越多的企业开始采用这个软件，安全合规也变得越来越重要，必须要有各种防护措施来保障生产环境。这其实是所有新技术走向成熟的一个客观规律。</p><p>&nbsp;</p><p>关于如何支撑这个领域的商业化发展。我们发现，由于 K8s 上游迭代的速度非常快，云厂商包括 Rancher，虽然做了很多年 K8s 的商业供应商，依然很难完全跟得上上游的版本迭代，这就出现了碎片化严重的问题。就像安卓时代，手机多起来之后，你发现安卓最可怕的就是 4 点几和 6 点几，那个时代各种各样的版本都有。对于用户来说，有的用户可能需要不断地更新，有的用户则不需要频繁地更新，但是他用的版本已经过了生命周期。这个时候，企业在一个相对不那么新的版本上提供一个长期支持服务，是非常关键的一点。</p><p></p><p></p><h4>InfoQ：这几年，国内软件供应链安全问题、容器安全问题、合规问题受到越来越多的关注，这为企业级的 Kubernetes 管理软件的研发提出了怎样的新要求？</h4><p></p><p></p><p>张智博：就我个人近一年的经历来看，工程化的难度加大了很多，因此最关键的肯定是工程化。由于人力是有限的，我们要用有限的人力去支持现有版本的不断演进，就要持续地做好工程化。任何一个软件，只要有人投入就要保证效率，无论是资金还是时间总会有成本，因此最终一定要有个合理的毛利率，而非无限的投入。要解决 K8s 版本碎片化，又要确保容器安全合规，还要引入软件供应链，以上种种如果仅靠人去治理，完全消耗不起。我个人最近一年也在做产品，包括带产品研发团队做工程。我们去年一年做的工程化的量，可能比前几年加起来还要多。这些与前一年相比，可能就是一个简单的 CI，但现在的工作量比以前大很多，因此关键还是工程化。</p><p>&nbsp;</p><p></p><h4>InfoQ：您觉得 Kubernetes 商业化在 2023 年有怎样的发展趋势？将完成怎样的技术演进？为什么？</h4><p></p><p></p><p>张智博：一年的时间很短，很难称得上演变到一种趋势。不过从已经过去的两个月时间来看，包括也在跟客户聊，确实得到一些反馈。企业现在对 K8s 的需求不似前几年，“K8s is everything”，那个时代大家认为新技术可以做很多事情，大家都在天马行空地设想，但现在并不这样。大家不再期望技术实现复杂的创新，而是把它作为一个高效率的工具引进并落地下来。由于容器管理确实给企业带来了生产力的提升，因此企业的根本需求就是做容器管理，即 K8s 的根本。</p><p>&nbsp;</p><p>很多客户不再去投入一些过于前瞻性的创新，而是逐渐认识到软件究竟能做什么、不能做什么，因此商业化在今年应该会有一个比较好的发展。</p><p></p><p></p><h4>InfoQ：目前市面上基于 Kubernetes 的解决方案都有哪些形式？整个市场发展处在什么阶段？</h4><p></p><p></p><p>张智博老师：提到解决方案那一定是商业化，商业化形式就是公有云的托管服务，每一个云厂商只要有账号就能去建他的 K8s，就像 AWS 有 EKS，阿里云有 ACK。还有 SUSE 提供 Rancher 这种企业级的容器管理软件，你无需特别关注是私有云还是公有云，Rancher 都可以帮你把所有 K8s 资源统一管理起来。还有一些特定的发行版，在 K8s 的基础框架之上做创新，这些都是大家做商业化的形式。</p><p>&nbsp;</p><p>市场发展正处于什么阶段，我想应该是：商业化的市场正处于上升阶段，但是技术创新的热度明显在下降。印象中我看过一个海外<a href=\"https://www.soft6.com/news/2020/06/29/367292.html\">Gartner 报告</a>\"，报告显示 2020 年全球企业采用容器化技术的比例占 5%左右，预计 2024 年可能达到 15%-20%。Gartner 采访的应该是真正有实力付费的用户，而不是纯粹的社区用户。所以商业化市场的空间和付费的空间还是非常大的，不过这也需要 K8s 不断地成熟起来。</p><p></p><p></p><h4>InfoQ：在 Kubernetes 企业级解决方案供给领域，全球的竞争格局是怎样的？</h4><p></p><p></p><p>张智博：SUSE 在国内与海外都有涉猎，算是一个在全球卖这种产品的公司。从我们接触到的很多客户来看，公有云应该是一个真正的赢家。关于公有云，无论是打开虚拟机还是打开任何一个服务资源，我们都默认是需要付费的。它的商业模式决定了它很容易把开源软件和 K8s 变现，因此它是真正的赢家。</p><p>&nbsp;</p><p>从全球范围来看，我们目前在海外碰到更多的厂商是 OpenShift 这类的，国内目前竞争还是非常激烈的。我有统计，去年几乎每个月都有厂商突然要开源自己的 K8s 管理平台。随着厂商越来越多，大家开始内卷竞争，低价的情况随之出现。由于没有长期的正向收益，国内的这类软件就无法成长为有国际竞争力的产品，企业也难以在国际市场站稳脚跟。结合国内市场来看，当前的竞争格局难言乐观。</p><p></p><p></p><h4>InfoQ：刚提到国内的市场形式，在 Kubernetes 领域，国内介入也是比较早的，和海外相比，出现当前状况的原因？&nbsp;</h4><p></p><p></p><p>张智博：这也是我个人在这几年的职业生涯中感到非常遗憾的一点。国内对这一波技术的介入非常早，而且原先 K8s 落在国内是全球最好的一个 user case。但是，为什么在后续成长中我们没有出现具有国际竞争力的产品？</p><p>&nbsp;</p><p>除了前面提到的厂商过多以外，还有一个原因就是我们的市场规模没有发展起来。海外虽然也有一些小众厂商，但是它的市场规模是可观的，无论是小厂商还是头部厂商都能拿到正向的收益。</p><p>&nbsp;</p><p>我的理解是，我们没能在关键阶段制定出行业标准。对于长期从事这个领域的技术人员而言，可能认为这个东西不需要标准。但是市场要在各行各业铺开，并非只针对 IT 企业和互联网企业。如果没有一个行业标准，对于其他企业来说，采用 K8s 和容器技术可谓天方夜谭，这也就造成了市场规模发展不起来的局面。</p><p>&nbsp;</p><p>我最近在做一些研究，发现美国的国防部从 2020 年开始大力引入 K8s，它制定了非常详细的厂商准入标准及产品标准。而且这个标准是完全公开的，公开则意味着国防部这一套基于 K8s 建设的软件交付平台，其他非 IT 行业可以直接参考。这套标准在国内并没有看到，所以市场规模一定是上不来的，大家就只能在仅有的付费客户领域里不断地相互挤压。</p><p>&nbsp;</p><p>Rancher 在海外有很多客户，这些客户既可能是某个农业公司，也可能是某地区的一个县政府，这在国内很少能看到。行业没有标准化，就没有办法实现可复制，从而导致市场规模发展不起来。</p><p></p><p></p><h4>InfoQ：SUSE 在这个领域也是关键厂商，在整个领域的发展和企业用户痛点来看，你们是否有提出相应对策？</h4><p></p><p></p><p>张智博：今年，产品层面我们还是定位于多集群和多云。目前这已经是一个标配，是一个固定的基础需求。入到这个行业门槛，就得提供这个能力。</p><p>&nbsp;</p><p>在此基础上，我们尝试扩展边缘领域的产品能力。前面我们提到 SUSE 有自己的操作系统，也有 K3s，因此我们尝试用产品化解决近端边缘领域的一些问题。这就是我们在做的 2.7 版本，它将是我们整个 2023 年运作的一个大版本。</p><p>&nbsp;</p><p>然后再走入生产化这个大趋势，我们判断产品质量、迭代质量是非常重要的一块。为什么今年要特别提出来，确实是现在生态和 K8s 碎片化很复杂。我们前面也提到了工程化，如果不做好，Rancher 是开源软件，我们在全球非常多的用户，每个版本出来大家都会发现有一些瑕疵。不过开源软件也有好处，这些信息都是公示出来的，会有临时解决方案，发现问题了可以及时规避。</p><p>&nbsp;</p><p>而且场景确实太多了，有的用户用 AWS，有的用户用 Azure，不同的云效果也不同。现在如果不去做更多的工程化来治理产品质量，情况就会愈发艰难。如果把软件范围限定在某个特定领域，就失去了 K8s 企业管理软件的核心。我们要让大家在不同的场景、不同的资源池里去使用它。</p><p>&nbsp;</p><p>除了前面讲到的 2.7 版本，我们也在尝试去凸显社区版本和商业版本间的差异性。Rancher 本身开源，它相当于提供了一个社区版本，但我们也研发了一个商业版本，叫 Rancher prime。不过它完全是在社区版本的基础之上，再去为商业客户服务。它更加关注于企业付费客户看中的东西，包括安全性的增强、漏洞的及时修复、合规性、软件供应链等。</p><p>&nbsp;</p><p>当然我们也面临着激烈的竞争，我们的策略是，在国内的生态里面用本地的研发团队去治理。国内的 IT 环境有其特殊性，因此我们要有一个独立的治理体系去做这个产品。很明显，在国内大家用的都是国内的几朵“云”，很少去用 AWS、Azure 之类的。操作系统基本选择自主可控的 Linux，而不会采用国际上主流标准的几个大的 Linux。当然也有一些想出海的企业，它们要面临海外的监管标准，那么就需要有软件帮忙辅助。针对于此我们也在积极探索，作为一个外企的软件本身具有优势，在支持国内企业出海的时候，我们也可以把这个经验复用给它。</p><p></p><p></p><h4>InfoQ：Rancher Prime 目前是 V2.7 版本，下一个版本或者是说 Rancher Prime 未来的迭代方向规划是怎样的？主要会解决哪些问题？</h4><p></p><p></p><p>张智博：2.7 版本是去年 10 月份发布的，2.8 版本预计在 2023 年的 11 月底或者 12 月发布。现在是 2023 年初，其实谈不上特别大的未来迭代。</p><p>&nbsp;</p><p>不过总体思路是不会变的。我们判断现在的趋势是 K8s 向生产环境落地，所以我们所有的产品都将朝着这个方向努力。当然，除了自身的产品迭代以外，我们也会通过技术收购来围绕 Rancher 去建设整体的产品能力。</p><p></p><p></p><h4>InfoQ：回溯到主题，企业想要实现降本增效的目标，企业进行 Kubernetes 落地，您有什么建议？</h4><p></p><p></p><p>张智博：技术要关注其本质，即 K8s 在解决什么问题，它其实就是为企业采用容器化带来便利。容器化在真正变革企业的应用交付方式，而在这个过程中，使用 K8s 肯定是必不可少的经历。K8s 在走入生产环境后，我们要去关注它整体的稳定性，包括 K8s 整个社区 API 组件的稳定性以及管理平台的稳定性。此外就是安全问题，容器运行时的安全问题、镜像安全的治理、容器网络安全、包括现在提倡的供应链安全。</p><p>&nbsp;</p><p>现在追求的是整体的安全性，它并不是简单几个点。容器化改造，供应链势必会更加复杂。不像以前用虚拟机只需固定一个版本，容器化打包会有多个版本。由于供应链变得愈发复杂，整个行业也急需跟进治理。</p><p>&nbsp;</p><p>考虑完整的稳定性，前提要看清本质。你要知道依靠 K8s 不能帮你立即达成效果，而是在建设过程中，基础设施经过不断地演进，K8s 才能够跟你的业务完整地整合起来。容器化是先行，再是迁移，迁移后具备了标准化的基础设施，进而把它面向多云。</p><p>&nbsp;</p><p>多云之后就拥有了议价权。你可以在不同的云上尝试无状态应用的多元部署，还可以去做 ARM 的实例迁移。我们知道云上 ARM 的价格比 X86 要便宜大概 30%，在这种操作之下，节省成本立竿见影。而且对业务的影响、对架构的影响均是完全可控的。</p><p></p><p></p><p></p><h2>直播间互动精华整理：</h2><p></p><p></p><h5>Q1：对于企业级开源软件来说，他们在企业运作中扮演着重要角色，大家对于其安全性有一定的顾虑，如何解决企业用户这部分的担忧？</h5><p></p><p></p><p>张智博：越来越多的企业开始采用开源软件，公有云的很多云服务也都是建立在开源软件的基础之上，这是目前全球 IT 行业的大趋势。</p><p>&nbsp;</p><p>首先，开源软件的代码是公开的，它为我们带来便利的同时也潜藏着隐患。所有代码都公开，一些不法分子如黑客，他们也可以阅读代码。他们可以快速找到漏洞，并利用漏洞去入侵你的 IT 系统。所以，好的开源软件定期会有安全公告，它们有安全员不断地去更新公告，并提醒使用者更新版本来修复安全漏洞。所以这里涉及的是一个治理问题。采用开源软件后，如果你只锁定一个版本且永不更新，那必然会有安全风险。</p><p>&nbsp;</p><p>第二个风险是合规性的问题。我们知道开源软件有自己的 license，现在整个业界把开源软件的 license 弄得越来越复杂，有传染性，又不能做二次商业分发。即便有商业分发，可能还会涉及分成。所以企业要用开源软件，必须要确保你所在的行业、你的公司是可以采用它的，一旦采用，就存在合规风险。</p><p>&nbsp;</p><p>第三是开源软件的供应链安全。就像购买一件商品我们要看这个商品的成分表，其实软件也一样。现在提倡要生成一个软件物料清单，就是让使用者去看这个软件所依赖的成分，但是并不是所有开源软件都会提供这份清单，所以企业想去使用开源软件就需要多加考虑。要想在公司里长期运行，并不是改几个参数或者增加几个新功能就可以，必须要考虑到安全风险。</p><p>&nbsp;</p><p>最后说如何解决，在我看来其实没有所谓的“银弹”，不存在一个固定策略供我们解决这个问题。一旦使用了开源软件，就需要建立一个持续治理的机制。</p><p></p><p></p><h5>Q2：（Kubernetes 企业落地及管理）对企业技术管理者提出了怎样的要求？从技术布道和人员管理方面是否提出了新要求？</h5><p></p><p></p><p>张智博：这要看具体是什么企业，是要求标准化商业场景的企业，还是要求自主可控的企业，不同企业间采购的需求肯定是有区别的。要说对技术管理者有怎样的要求，还是要回到我们最初的问题，用这些软件到底是要采购商业软件，然后二次整合到自己的业务里；还是要完全走开源自建路线。如果看中前者，就要看它的供应链。标准场景关注是否会被它锁定，自主可控则看它的供应链是不是满足合规需求。</p><p>&nbsp;</p><p>如果要走开源自建，就要好好算一个成本账。虽然省下了购买商业软件的资金，但投入的人力成本绝不容忽视。自建带来的技术风险，公司的资金和业务能否支持长期的建设。一旦走入自建就很难中断，中断后前面的努力就变成零了。此外，如果你是自主可控类型的企业，你还要关注你所用的软件成分是否可用，以及能否在自己的生产车间生产，而不能下载下来直接用。</p><p>&nbsp;</p><p>针对技术布道，我建议技术布道者应该尝试去获取一些流量眼球并传递一些新的技术理念。因为 K8s 本身已经不算是新鲜领域，现在并不是布道 K8s 的合适时间节点，去挖掘一些创新点可能更好。</p><p></p><p></p><h5>Q3：除了 Rancher&nbsp;Prime，SUSE 在 2023 年还有什么大动作吗？</h5><p></p><p></p><p>张智博：其实，我们在去年年底就已经有了对今年的预测。2023 年不会是激进扩张的一年，不止我们，包括全球许多企业也都倾向于持防御姿态，因此并没有特别夸张的大动作。目前我们的目标就是真正扎实地做好商业化的落地，在市场商业化的份额上升的时候，我们能够吃掉匹配我们现在市场地位的份额，对我们来说已经非常值得努力的一件事了。</p><p>&nbsp;</p><p>在这个过程中，安全肯定是我们非常看重的，未来我们将继续围绕着这个点去做，在 Rancher 的基础能力上做安全扩展。</p><p></p><p></p><h5>Q4：Rancher&nbsp;prime 有较为成熟的应用案例吗？目前已经合作的企业里面主要应用于哪些行业？</h5><p></p><p></p><p>张智博： SUSE 有一个专门的站点来收集、展示客户的应用案例。大家知道，Rancher 这个软件已经存在很多年了，那么它必然积累了大量的、成熟的案例。它遍布的行业也很多，包括金融、保险、银行、制造业、汽车等。</p><p></p><p></p><p>1、关于 K3s 在边缘侧的解决方案和应用案例，请参考：</p><p><a href=\"https://mp.weixin.qq.com/s/gyqeCjHr3RjhTUVcmjtg-w\">设备太分散？如何一站式管理边缘 OS、K8s 和应用？</a>\"<a href=\"https://mp.weixin.qq.com/s/505jPbQk9VroM9sEwa55Fw\">SUSE 助力橘盒实现能碳管理平台标准化</a>\"</p><p>2、关于Rancher Prime更多信息，<a href=\"https://more.suse.com/rancher_prime_whitepaper_cn.html?utm_source=infoq&amp;utm_medium=other_advertising&amp;utm_campaign=FY23Q1_DM_GCC_ECM_ALL_ECMC_LP_rancher_prime,_whitepaper,_cn_RG_GC\">请下载《Rancher Prime 产品概述白皮书》</a>\"进行了解；</p><p>3、了解更多SUSE 成功案例，请点击 <a href=\"https://www.suse.com/zh-cn/success/\">https://www.suse.com/zh-cn/success/</a>\"查看。</p>",
    "publish_time": "2023-03-22 09:09:54",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "2023 “Kubernetes 管理” 将路走何方？",
    "url": "https://www.infoq.cn/article/iQNVqZE7mYm4I4KZDGtk",
    "summary": "<p>Kubernetes 从 2014 年开源至今，在云原生领域的地位逐渐稳固。从宏观来看，Kubernetes 解决方案的演进路径是非常清晰的，在许多企业的落地实践中也得到了成功验证。企业级 Kubernetes 解决方案也逐渐成为大势所趋，但不少企业对此还是保持着观望态度。于是本次对话，InfoQ 与 Rancher 大中华区研发总监张智博一起梳理 Kubernetes 企业级管理方案的发展情况，探讨其趋势，并为企业 Kubernetes 实践沉淀出一套可落地的方法论。</p>",
    "publish_time": "2023-03-22 09:12:05",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "ChatGPT带火AI芯片，赚翻了的英伟达发布新核弹：ChatGPT专用GPU，让推理提速10倍！",
    "url": "https://www.infoq.cn/article/99bQgZ9PmtBOYfiqRWPB",
    "summary": "<p></p><blockquote>老黄的新宣言：决胜 AI 的 iPhone 时刻。</blockquote><p></p><p></p><p>北京时间 3 月 21 日晚间，在英伟达 GTC2023 上，英伟达创始人兼首席执行官黄仁勋穿着他标志性的皮夹克，站在位于英伟达总部的垂直绿墙前，发表了一场主题演讲。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ce/ced7427c187c9ff9948b43c9b1a5c7d6.png\" /></p><p></p><p>这场发布会几乎完全聚焦于人工智能。</p><p></p><p>演讲中，黄仁勋介绍了新一轮技术突破，从 AI 训练到模型部署，再到半导体、软件库、系统乃至云服务，分享了英伟达的加速计算平台如何推动人工智能、元宇宙、云技术和可持续计算的下一波浪潮。英伟达持续推进 AI 硬件，并重点关注这些技术在科技、医疗、金融、图像、物流配送等行业的应用场景，让各行各业的企业更容易使用其技术。</p><p></p><p>“我们正处于 AI 的 iPhone 时刻，”黄仁勋表示 “初创公司正在竞相打造颠覆性产品和商业模式，科技巨头也在寻求突破。”</p><p></p><p>最近站在风口浪尖之上的“顶流” — 生成式人工智能和 ChatGPT 也在本场发布会占了较大篇幅。“推动这波浪潮的引擎是加速计算，燃料则是 AI。生成式 AI 凭借令人印象深刻的能力令众多企业产生了紧迫感，开始重新构思自己的产品和商业模式。”</p><p></p><p>面对逐渐放缓的摩尔定律以及各行业对于可持续性、生成式 AI 和数字化的旺盛需求，加速计算和 AI 的到来可谓恰逢其时。黄仁勋表示，“工业企业正竞相推动数字化转型，并将自身重塑为软件驱动型科技公司，保证自己成为颠覆的力量、而非被颠覆的对象。”</p><p></p><p>最近 AIGC 和 ChatGPT 的走后也让英伟达成为背后赢家，大型语言模型需要规模庞大的算力，目前大模型竞赛中的很多玩家都依赖英伟达的 GPU 芯片。据悉，受益于 ChatGPT 相关产品的热度，英伟达 A100、H100 及 A800 系列 GPU 等三款针对数据中心的 GPU 代工订单增加。</p><p></p><p>投资公司 Baird 认为，ChatGPT 的“有意义的”订单正在到来，并帮助该英伟达上调了下半年数据中心收入预期。Baird 分析师 Tristan Gerra 表示，英伟达的 Hopper 芯片很可能受益于大型语言模型的增长，并成为一种“长期趋势”。</p><p></p><p>据悉，自今年年初以来，英伟达股价涨幅已超 80%。英伟达 2023 财年第四季度财报显示，AI 数据中心业务再次成为该公司最大的收入来源。</p><p></p><p>以下为英伟达 GTC 2023 的重要发布概览：</p><p></p><p></p><h2>AI 的 iPhone 时刻</h2><p></p><p></p><p>英伟达提供的技术可以说是 AI 发展的基础，黄仁勋讲述了显卡巨头如何在生成式 AI 革命之初为其提供助力。早在 2016 年，他就向 OpenAI 交付了第一台英伟达 DGX AI 超级计算机，这也正是支持 ChatGPT 大语言模型实现突破的底层引擎。</p><p></p><p>去年年底亮相以来，ChatGPT 迅速进入公众视野，吸引到超 1 亿用户，成为历史上增长速度最快的应用程序。黄仁勋感慨，“我们正处于 AI 的 iPhone 时刻 。”</p><p></p><p>英伟达 DGX 超级计算机最初仅供 AI 研究，但如今已经在世界各地的企业中全天候运行，负责提炼数据和处理 AI。</p><p></p><p>目前，财富百强企业中有一半都在使用 DGX AI 超级计算机。“DGX 超级计算机已经成为现代 AI 的工厂。”</p><p></p><p></p><h2>面向数据中心的英伟达&nbsp;H100、Grace Hopper 和 Grace</h2><p></p><p></p><p>如今，部署 ChatGPT 这类大语言模型已经成为新的重要推理工作负载。</p><p></p><p>为了更好地应对这类需求，黄仁勋公布了新的双 GPU NVLink 产品 H100 NVL。</p><p></p><p>基于英伟达的 Hopper 架构，H100 内置一个 Transformer Engine，能够高效承载 GPT 这类大体量模型。与处理 GPT-3 的 HGX A100 相比，通过双 GPU NVLink 接入四对 H100，从而将速度提升 10 倍。</p><p></p><p>“H100 能够将大语言模型的处理成本降低一个数量级。”</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ea/ea10c679370b2cff74da1ef32c7f5431.png\" /></p><p></p><p>H100</p><p></p><p>与此同时，过去十年间，云计算年均增长 20% 并发展出价值万亿美元的新产业。英伟达为 AI 和云优先时代设计出 Grace CPU，其中 AI 负载由 GPU 加速。目前 Grace 已经向部分客户提供样片。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6b/6b074fe7f68bb44ceb0164ad378e6b94.png\" /></p><p></p><p>NVIDIA Grace 超级芯片</p><p></p><p>英伟达的新型超级芯片 Grace Hopper 可通过 900 GB/ 秒高速接口将 Grace CPU 与 Hopper GPU 连接起来。Grace Hopper 专为大型数据集而生，特别是用于推荐系统和大语言模型的 AI 数据库。</p><p></p><p>“客户希望将 AI 数据库再扩大几个数量级，而 Grace Hopper 正是这类用例中的理想引擎。”</p><p></p><p></p><h2>DGX — AI 基础设施的蓝图</h2><p></p><p></p><p>最新版本的 DGX 采用 8 个相互连通的英伟达 H100 GPU，将其作为巨大的单一 GPU 使用。“英伟达 DGX H100 堪称全球客户构建 AI 基础设施的蓝图”，而且目前这款产品已经全面投产。</p><p></p><p>H100 AI 超级计算机也已筹备上线。</p><p></p><p>甲骨文 Oracle Cloud Infrastructure 宣布将先期提供搭载 H100 GPU 的新型 OCI Compute 裸机 GPU 实例。此外，亚马逊云科技也宣布即将为 P5 实例推出 EC2 UltraClusters 选项，最大规模可扩展至 2 万个互连 H100 GPU。上个星期，微软 Azure 也刚刚发布其 H100 虚拟机 ND H100 v5 的内部预览版。</p><p>Meta 已经其 AI 生产和研究团队部署了由 H100 驱动的 Grand Teton AI 超级计算机。还有 OpenAI，他们在 Azure 超级计算机上使用 H100 以支持 AI 研究。</p><p></p><p>其他接纳 H100 的合作伙伴还包括 Cirrascale 和 CoreWeave、Google Cloud、Lambda、Paperspace 以及 Vult。</p><p></p><p>现在英伟达的客户已经可以从各领先服务器制造商处购买配备有英伟达 H100 GPU 的服务器和系统，包括源讯、思科、戴尔科技、技嘉、HPE、联想和 Supermicro 等。</p><p></p><p></p><h3>DGX Cloud：将 AI 引入每一家企业</h3><p></p><p></p><p>为了帮助初创公司和大企业运用 DGX 的强大能力加快新产品开发和 AI 战略的推进，黄仁勋还公布了 NVIDIA DGX Cloud。</p><p></p><p>通过与微软 Azure、Google Cloud 和 Oracle Cloud Infrastructure 的合作，DGX Cloud 将把 DGX AI 超级计算机“通过浏览器引入每一家企业”。</p><p></p><p>DGX Cloud 专门针对 NVIDIA AI Enterprise 进行了优化，这是一套全球领先的端到端 AI 开发与部署加速软件套件。“DGX Cloud 将为客户提供最好的英伟达 AI 与领先云服务商的最佳服务。”</p><p></p><p>英伟达将与领先云服务商合作托管 DGX 云基础设施，第一步就是携手 Oracle Cloud Infrastructure。微软 Azure 预计将从下季度起托管 DGX Cloud，该服务也将很快扩展至 Google Cloud。</p><p></p><p>企业客户可以按月租用 DGC Cloud 集群，借此轻松实现大规模多节点训练负载的开发。</p><p></p><p></p><h3>为生成式 AI 提供“增压加速”</h3><p></p><p></p><p>为了帮助生成式 AI 开发者加快探索的脚步，黄仁勋又公布了 NVIDIA AI Foundations。这个云服务系列主要面向希望构建、改进和操作定制化大语言模型的客户，能够利用专有数据训练出适应特定领域任务的生成式 AI 成果。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/16/164ac9376626124b67799847391a3935.png\" /></p><p></p><p>Nvidia AI Foundations 是针对语言、视觉模型和生物学的云服务</p><p></p><p>AI Foundations 服务包含用于构建定制化语言文本到文本生成模型的 NVIDIA NeMo；可利用许可或专有内容训练自定义模型的视觉语言模型服务 Picasso；以及服务于总值达 2 万亿美元的药物发现行业研究人员的 BioNeMo。</p><p></p><p>Adobe 也在与英伟达合作，共同为未来的创造性工作构建下一代 AI 功能。Getty Images 则与英伟达合作训练负责任的文本到图像与文本到视频生成式基础模型。Shutterstock 与英伟达合作训练文本到 3D 生成式基础模型，希望简化 3D 资产的创建流程。</p><p></p><p></p><h2>加速医学进步</h2><p></p><p></p><p>英伟达宣布 Amgen 正通过 BioNeMo 加速药物发现。此外，Alchemab Therapeutics、阿斯利康、Evozyne、Innophore 和 Insilico 也都是 BioNemo 的早期用户。</p><p></p><p>BioNeMo 能够帮助研究人员利用专有数据创建、微调和交付定制化模型。</p><p></p><p>黄仁勋还宣布，英伟达已经与全球最大医疗保健技术提供商美敦力建立合作，共同构建用于软件定义医疗设备的 AI 平台。双方将合作为美敦力系统构建通用平台，将手术指引、机器人辅助手术等各类成果纳入其中。</p><p></p><p>美敦力此次也公布了利用 NVIDIA Holoscan 软件库打造的实时传感器处理系统 GI Genius，能够利用 AI 技术实现结肠癌的早期检测，计划于今年年底左右正式上线。</p><p></p><p>黄仁勋总结道，“市值 2500 亿美元的全球医疗器械市场，正经历一场根本性变革。”</p><p></p><p></p><h3>为生成式 AI 应用的部署加速</h3><p></p><p></p><p>为了帮助企业快速部署生成式 AI 艺术形式，黄仁勋公布了用于 AI 视频、图像生成、大语言模型部署和推荐的推理平台。</p><p></p><p>这些功能将与英伟达的全栈推理软和最新的英伟达 Ada、Hopper 及 Grace Hopper 处理器相结合，包括此次推出的英伟达 L4 Tensor Core GPU 及 H100 NVL GPU。</p><p></p><p>• 英伟达 L4 for AI Video 可将 AI 视频处理性能提升至 CPU 的 120 倍，能效优化达 99%。</p><p>• 英伟达 L40 for Image Generation 针对图形生成和 AI 支持的 2D、视频及 3D 图像生成进行了优化。</p><p>• 英伟达 H100 NVL for Large Language Model Deployment 可高效部署 ChatGPT 等大语言模型。</p><p>• 英伟达 Grace Hopper for Recommendation Models 适用于图推荐模型、矢量数据库和图神经网络等用例。</p><p></p><p>Google Cloud 是首家向客户交付 L4 的云服务商，此次发布了新的 G2 虚拟机内部预览版。谷歌还计划将 L4 集成至 Vertex AI 模型商店当中。</p><p></p><p></p><h3>把 Omniverse 带向“数亿用户”</h3><p></p><p></p><p>黄仁勋宣布英伟达将与微软合作，将 NVIDIA Omniverse Cloud 全托管云服务推向各个行业，为每一家企业赋予前所未有的模拟和协作能力。</p><p></p><p>“微软和英伟达将把 Omniverse 带向数亿 Microsoft 365 与 Azure 用户。”同时推出的还有新的 NVIDIA OVX 服务器和新一代工作站，其中搭载 NVIDIA RTX Ada Generation GPU 和英特尔针对 NVIDIA Omniverse 优化的最新 CPU。</p><p></p><p>黄仁勋还播放了一段视频，展示了英伟达为 3D 设计协作与数字孪生模型构建的这套 Omniverse 开放平台。在 Omniverse 平台之上打造的机器人模拟与合成生成方案 NVIDIA Isaac Sim，已经成功帮助亚马逊建立起高保真度数字孪生副本，同时显著节约了时间和资金。</p><p></p><p>在演示中，亚马逊借此开发出首款全自动库管机器人 Proteus，它能与人类员工一道在巨大的配货仓库中将商品搬来挪去。</p><p></p><p></p><h3>推动 3 万亿美元的汽车产业实现数字化</h3><p></p><p></p><p>为了表达 Omniverse 的影响力和强大实力，黄仁勋还介绍了 Omniverse 在价值 3 万亿美元的汽车产业中发挥的数字化推动作用。到 2030 年，汽车制造商将建设 300 家工厂、生产 2 亿辆电动汽车，电池制造商则着手兴建 100 多处超级工厂。“数字化将提高行业的整体效率、生产力和行动速度。”</p><p></p><p>谈到 Omniverse 在整个行业的未来应用，黄仁勋分享了 Lotus 利用 Omniverse 建立虚拟组装焊接站，奔驰利用 Omniverse 来构建、优化和规划新车型的装配线。Rimac and Lucid Motors 则使用 Omniverse 开发出能忠实反映车辆设计参数的数字商店。</p><p></p><p>宝马与 Idelworks 合作，在 Omniverse 中利用 Issac Sim 生成合成数据与场景，借此训练工厂内的工程机器人。黄仁勋表示，宝马正使用 Omniverse 规划全球工厂运营，甚至在一家新电动车工厂开业两年前就完全在 Omniverse 中建立了孪生模型。</p><p></p><p>另外，英伟达还宣布与全球领先的新能源汽车制造商比亚迪合作，在生产体系中广泛引入 NVIDIA DRIVE Orin 集中式计算平台。</p><p></p><p></p><h3>加速半导体突破</h3><p></p><p></p><p>面对当前生产工艺已接近物理极限的事实，黄仁勋公布了 NVIDIA cuLitho 计算光刻库，将帮助阿斯麦尔、台积电和新思科技等半导体领先企业加速新一代芯片的设计和制造。这套全新软件库已经被全球芯片代工巨头台积电和电子设计自动化领军企业新思科技集成至其最新一代 NVIDIA Hopper 架构的 GPU 软件、制造流程和系统当中。</p><p></p><p>芯片制造商阿斯麦尔与英伟达就 GPU 和 cuLitho 库开展密切合作，计划在所有计算光刻软件产品中支持 GPU 集成。黄仁勋谈到，随着光刻技术逼近物理极限，英伟达推出的 cuLitho 有望帮助半导体行业迈向 2 纳米甚至更远的新节点。</p><p></p><p>“芯片行业，是几乎一切其他行业的基础。”</p><p></p><p>&nbsp;参考链接：</p><p>https://blogs.nvidia.com/blog/2023/03/21/gtc-keynote-spring-2023/</p><p></p><p>https://register.nvidia.cn/flow/nvidia/gtcspring2023/registrationcn/page/sessioncatalog/session/1673303350236001hW73</p>",
    "publish_time": "2023-03-22 11:30:29",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "中国开源生态图谱2022——人工智能领域",
    "url": "https://www.infoq.cn/article/3ElKmiQIzsFC8ThhFfst",
    "summary": "<h3>研究背景</h3>\n<p>2022 年 8 月，InfoQ 研究中心推出《中国开源发展研究分析 2022》。报告中对中国开源的宏观发展的背景、目前取得的成绩、整体发展的特征进行了分析。同时也推出了基于 InfoQ 研究中心研究成果的 InfoQ 开源项目指数。但是因为时间等因素，《中国开源发展研究分析 2022》聚焦研究了中国 TOP30 开源项目。我们深知，中国开源发展百花齐放，仍有大量的项目深植于各技术领域中，并且取得了亮眼的成绩。另外，不同的技术领域开源也具有各自独特的特征。</p>\n<p>所以，InfoQ 研究中心策划启动了《中国开源生态图谱系列研究》工作，技术领域涉及操作系统、数据库、云原生、大数据、前端、架构等。希望系列研究能够帮助关注中国开源世界的朋友绘制更为完整的开源全景图谱。通过对不同技术领域的研究分析，帮助读者获得更为具体的开源领域洞察。</p>\n<p>此篇是《中国开源生态图谱系列研究》的第三篇，聚焦在人工智能领域，通过统计目前的人工智能开源项目，并进行分类，同时结合开源基金会、开源产业联盟等生态，完整构成中国人工智能开源的生态图谱。</p>\n<p>随后，通过在《中国开源发展研究分析 2022》中使用的 InfoQ 开源项目指数，和拓展的 Gitee 指数，分析和评价现有人工智能开源项目，并从中选择优秀案例供广大开发者和开源社区研究。相关指数的详细计算方式可见报告完整内容。<br />\n<img alt=\"\" src=\"https://static001.infoq.cn/resource/image/67/9c/67e15df5bcdeyy92d73fb16c11aa129c.png\" /></p>\n<p>截至目前，InfoQ研究中心已经发布了3个领域的开源生态图谱，并预计在未来推出涵盖操作系统、数据库、人工智能、云原生、前端和中间件等七大领域的中国开源生态图谱全景图，将涵盖500+中国开源项目，敬请期待。</p>\n<h3>目录</h3>\n<ul>\n<li>生态图谱解读</li>\n<li>生态图谱企业洞察</li>\n</ul>",
    "publish_time": "2023-03-22 11:52:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "降本为根，沟通为线，构建企业数字化办公平台的实用指南",
    "url": "https://www.infoq.cn/article/b9oQ0zdLVdGDFlEF2Fut",
    "summary": "<p>随着全球经济下行、流量红利结束、内外竞争加剧等问题逐步显现，在充满挑战和不确定性的存量市场环境下，企业管理和经营者正愈发重视夯实企业基本盘，期望借助数字化将数字技术和解决方案集成到各业务领域，优化各项流程和支出，以适应供需关系变化，增强企业竞争力。数字化办公作为数字化转型的关键一环，也愈发受到各方关注。</p><p></p><p>本文旨在探讨企业数字化办公产品的建设思路及落地价值。以数字化办公为切入点，分享构建企业数字化基座的方式方法，帮助推进企业数字化转型。当下落实数字化办公能为企业带来什么？</p><p></p><h2>我们需要数字化办公做什么？</h2><p></p><p></p><p>如史凯在《精益数据方法论》中所提到，数字化转型将从业务价值出发，减少浪费，提升效益。推行企业数字化办公本质上实现降本增效，提升竞争力。</p><p></p><p>同样地，我们可以从如何提升企业的盈利能力，降本增效的实际价值角度去思考，<a href=\"https://xie.infoq.cn/article/d669d1e399fbecbc8488a23fd\">数字化办公</a>\"可以带来以下几个方面的价值：</p><p></p><h4>企业运营决策能力提升</h4><p></p><p></p><p>通过数字化办公，激励不同角色或部门的员工全体参与，相互协作，提升员工、部门、组织间信息传递效率，方便从管理者到一线员工及时获得关键信息，更好地决策和执行。从过往经验上看，仅针对一个话题的讨论，邮件需要反复多次沟通，效率低下。而使用以微信、QQ 为首的 C 端聊天工具进行沟通协作，则会模糊工作和个人生活边界，难以令员工保持专注。</p><p></p><h4>组织及业务流程优化</h4><p></p><p></p><p>通过数字化办公，将组织搬到线上，依托数字化办公平台，实现应用和工具的统一接入，All in one，让“人、财、事、物”集于一处，方便员工随时随地跟踪、响应、处理日常事务。对于当代企业来说，业务信息化早已不是主要矛盾，不同的行业、不同岗位角色，每天需要访问各式各样的网页、应用，查看、上报、分析业务数据，审批工单，编辑文档。纷繁复杂的登录用户名和密码，不完善的单点登录，应用、网页间的频繁切换，不断撕扯员工精力，令日常工作碎片化。</p><p></p><h4>企业风险控制能力增强</h4><p></p><p></p><p>以数字化办公平台为安全工具载体，对企业资产进行有效地识别、管理、防护，及时甄别风险事件和行为，并予以警告和阻断。传统安全工具往往游离在业务之外，如何既保证业务用户的体验又能保障企业安全是业务数字化领域存在已久的难题。理论上讲，实现这一点要做到安全和业务的深度融合，并提供开放性和灵活性，即在技术实现上业务域和安全域充分解耦，在端侧用户感知上无缝对接融为一体。</p><p></p><h4>切实的财务收益</h4><p></p><p></p><p>追求利润是资本的天性，运营企业本质上是运营资本，企业家的根本职责就是用好资本，让它带来更多利润并使自身增值，这是永恒不变的主题。尽管全面推行数字化办公的投资金额巨大，但其根本目的仍是为企业带来收益，此处的收益可以是狭义上的金钱，例如在相同用户规模和产品数据下，节省采购竞品所需的费用，也可以是广义上的时间、商誉、研发实力、发展潜力等。</p><p></p><h4>商业模式重构和创新</h4><p></p><p></p><p>企业的商业模式主要由创造价值、传递价值和获取价值三个组成部分构成。创造价值是基于客户需求，提供相应的解决方案，即生产。传递价值是通过资源配置、活动安排，交付产品，即运输。获取价值则是通过一定的盈利模式，获得利润，即销售。简单来说，借助数字化办公解构并重塑产、销、运的各个环节，帮助企业实现商业模式创新，增强企业活力。</p><p></p><h2>如何自建企业数字化基座？</h2><p></p><p></p><p>企业数字化不是软件，是战略。它不是为了全盘抛弃旧事物迎接新事物，不是做取舍，而是以降本增效为核，沟通协作为线打造载体，整合并改善新旧碎片化供给，在充分吸纳平台能力的基础上，识别高频业务场景，关注用户体验，实现对企业的全局优化。</p><p></p><p>整个建设过程，从项目管理过程角度进行拆解可以分为以下几步：</p><p></p><h4>启动</h4><p></p><p></p><p>首先是要基于组织的实际需要，明确产品定位。需求源自问题，当下企业正面临内外竞争加剧、信息安全挑战、上下游沟通不畅、协作效率低下、业务与办公工具联系不紧密、移动 / 远程办公不便捷等问题。笔者总结多年企业数字化产品建设领域经验，建议从四个方面分析产品定位以及核心能力的问题，分别是业务融合、协同办公、开放平台、信息安全。</p><p></p><p>业务融合，通过门户融合将企业的各类服务应用进行有序分类的管理，实现消息统一提醒，流程统一待办，数据统一展现，信息统一检索，数据统一存储，多端一致体验。</p><p></p><p>协同办公，提供功能丰富、交互友好的协同办公能力，涵盖即时通讯、搜索、音视频会议、日程管理、协同编辑、通讯录、群管理、待办审批、日志、考勤打卡、云盘等。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f1/f10aef8847e9ec13a7e393417da11f34.jpeg\" /></p><p></p><p>开放平台，支持统一的帐号与权限管理，提供相应的 SSO 接口及服务。开放 Web、RN、H5、小程序设计和接入框架，以及围绕 IM 的消息收发、群管理等核心功能的 Restful API，支持第三方 SDK 接入和插件管理。</p><p></p><p>信息安全，落实 ZTNA（<a href=\"https://xie.infoq.cn/article/14062d3145a724849969382d3\">零信任</a>\"网络安全架构），关注 IAM、SDP 建设，实现数据安全、客户端安全、服务器安全、网络准入与防御等全方位覆盖，端上支持沙箱、文件不落地、安全隧道、水印、UEBA 等众多安全防护场景。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8d/8d25944ce10d9a67e5c9af65bc9eb531.jpeg\" /></p><p></p><p>零信任网络安全架构（简版）, 图片来源:<a href=\"https://www.skyflow.com/post/what-is-zero-trust\">https://www.skyflow.com/post/what-is-zero-trust</a>\"</p><p></p><h4>规划</h4><p></p><p></p><p>识别相关方，包括项目核心成员、部门、客户、供应商、竞品等，完成顶层设计，明确产品架构、技术架构、资源需求、推广运营阶段和相关指标，以及项目迭代规则和规范。</p><p></p><p>“一个篱笆三个桩，一个好汉三个帮”，建设企业数字化基座是一项系统工程，需要多方参与。平台提供者专注于基础平台保障和核心服务提供，更多更具体的业务相关的、专业性的服务由第三方来提供。通过融合、共创，平台将极大丰富自身能力并拓展用户的功能适用范围，合作伙伴也可以借由平台数据增长和开放接口完善，丰富自身功能，加深与平台融合，最终实现多赢局面。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/67/679882862d9644d3417c3856139ed187.jpeg\" /></p><p>云原生互联网技术架构</p><p></p><p>需要注意的是，在规划阶段就要高度重视统一身份认证（IAM）建设，企业数字化本身就依赖统一授权认证，以串联所有业务功能，在产品规划初期就需要明确账号的注册和使用规范，考虑面向生态圈的产品功能拓展，以支撑后续总部、子公司、上下游伙伴、客户、外包员工的正常使用。</p><p></p><h4>执行</h4><p></p><p></p><p>区别于传统产品从引入、成长、成熟再到衰退，笔者更愿意将自建的 To B 企业级 SaaS 产品的生命周期拆分为 MVP、PEF、快速成长期和成熟期四个阶段。</p><p></p><p>MVP（Minimum Viable Product）阶段，主要解决产品可用的问题，在明确产品和技术方案整体框架的前提下，确保产品核心功能的主流程可用，这与 To C 的产品设计存在显著区别。以企业协同办公平台为例，本阶段需要完成用户帐号注册登录、通讯录、单聊、群聊、音频会议、在线存储等基础功能的研发上线。</p><p></p><p>PEF（Product Enterprise Fit）阶段，需要解决的是产品适配和推广的问题。本阶段产品已具备基本功能，但相比于市面上成熟产品，完成度上必定相差很大。此时，切勿盲目追赶竞品，需要顶住压力，结合自研产品高度灵活的优势，识别企业的迫切需要，打造亮点功能，实现在整体资源和产品功能劣势的情况下创造出局部优势，完成自研平台的落地。</p><p></p><p>快速成长期阶段，需要加速推进人、财、物、事在线进程，设计并完善企业数字化管理和运营体系。此阶段，产品形态已经确立，并面向全网公共服务，在持续丰富、优化、改进平台功能的同时，还必须能支撑企业生产资料和生产关系在线。当下，大多数字化办公平台与业务的融合，仅是在业务信息化基础上，将业务入口和数据搬到平台上，实现业务和数据的统一访问。</p><p></p><p>完善的数字化管理体系，必须以数字化办公平台为基础，让企业在各个业务领域、各个产业链都实现数字化转型，实现从生产一线到管理层的数据互通，让数据充分发挥作用，利用平台能力提高沟通协作、客户服务、市场营销、数据收集、资源分配效率，寻找业务增长新动力。重视将生产运营数据转化为<a href=\"https://xie.infoq.cn/article/60089bf5f00bd6fd2c83c58bd\">数据资产</a>\"，以支持决策智能化，帮助企业在经济低迷时通过降低成本增加收益实现收入稳定、毛利提升的经营目标。</p><p></p><p>过程中，项目组一方面要从内部打破各种部门墙和系统孤岛，积极探索系统融合和共创方案。另一方面还要重视平台开放能力建设，强化内外连接能力提升平台灵活性，实现系统的全方位打通。成熟期阶段，在继续丰富完善平台功能，强化连接，支撑企业数字化管理和运营基础上，探索第二条发展曲线。重视产品的对外宣发运营，打造行业内数字化转型标杆，构建行业云平台。</p><p></p><h4>监控</h4><p></p><p></p><p>监控需要贯穿项目始终。为了应对技术和管理上的不足，需要时刻对项目的各个方面进行监控和评估，提出改进意见，采取有效措施，防止项目出现差错，保障项目成功实施和稳定运行。项目实施过程中，不同阶段对产品迭代节奏的要求存在差异，项目早期要给产品和技术的顶层设计留足时间，推广期追求小步快跑，做到快速交付、快速修复，成熟期则适当放慢节奏，保证功能完整性和服务的稳定性。这些都需要在监控过程中，由项目或产品经理结合团队实际情况，灵活调整。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e5/e5ce5689a49356329addb11c73451a47.jpeg\" /></p><p>项目管理过程</p><p></p><p>常见的诸如需求评审、交互评审、技术评审、功能研发、测试用例评审、功能提测、准入、准出、UAT 等各时间节点都需要关注。涉及跨部门、第三方软件供应商合作的，还需要关注接口联调或交付时间，必要时需要与财务、法务、采购协商，严格遵守采购和审批流程，提前识别交付风险。</p><p></p><h4>收尾</h4><p></p><p></p><p>基于敏捷迭代的项目管理过程，将此阶段定义为阶段性复盘或许会更加合适，以实现持续改进。复盘的前提是要建立明确考核管理体系，定期收集和评估项目实施情况，衡量项目产出和价值。可以使用 OKR（目标与关键结果）辅助项目管理，通过对齐领导层和各方期望，形成项目定性的总目标（业务融合、协同办公、开放平台、信息安全），依此拆分阶段目标，并进一步拆分关键结果。</p><p></p><p>需要注意的是，项目不同阶段的 OKR，要因“时”制宜。MVP 阶段多为定性，聚焦基础能力提供。PEF 阶段，关注产品运营、功能落地，定量指标较多，如产品和用户数据、应用接入数等。快速增长及成熟期阶段，在持续关注原有定量指标的基础上，开放平台能力提升情况也是重点观察的对象。通过设立定量指标，可以很好地辅助评估关键结果价值和项目落地进展。以协同办公平台为例，常见的定量指标有：用户量、应用接入量、消息量、会议时长、日志使用量、会议室投屏硬件替换数等。</p><p></p><h2>实施建议和心得体会</h2><p></p><p></p><p>数字化转型及企业数字化基座建设宜早不宜晚，这是一个长期的、战略性的、复杂的工程，笔者认为在建设过程中需要特别注重以下几点：</p><p></p><p>首先，企业高层需要持续关注和推动，根据企业发展需求和竞争压力，科学制定产品定位和目标需求，协调各业务部门进行战略规划和顶层设计，按照路线图分阶段实施。</p><p></p><p>第二，产研团队时刻关注把用户需求转化成产品能力组件化，重视平台对业务发展的支撑作用，明确需求的业务边界。</p><p></p><p>第三，企业用户是产品服务的对象，产品需求源于用户并最终服务于用户，要把常用功能做深，关注高频使用场景的用户体验，特别是移动化体验。</p><p></p><p>第四，重视产品运营和用户客诉渠道建设，新功能上线前做好预告，功能上线时配套完整的培训教程。关于用户客诉渠道建设，定期组织用户满意度调查，组织创建客户服务群，针对经常提问题和需求的用户给予一定的奖励，缩短问题反馈流程，例如，上线问题页面截图一键上传功能。</p><p></p><p>第五，提高合规风控意识，谨防新型安全漏洞。尽管应用数字化平台带来了效率提升、资源配置的优化，但值得注意的是，在员工安全意识没有整体提升的情况下，随着数字化的快速普及，风险暴露面亦会扩大，社工和网络安全攻击的潜在威胁也会增加。另一方面，在全球不断加码对用户个人信息保护的当下，部分信息采集行为可能涉及法律风险，重视产品合规建设。</p><p></p><h2>写在最后</h2><p></p><p></p><p>在近期举办的 CES 2023（消费电子展）上，三星提出了「数字化生活」概念。通过「数字化生活」的故事线，三星在展示区串起了与人们日常生活有关的方方面面，而不是像过去一样单讲一款冰箱、电视、手机产品。通过这样的展示，三星期望回答的是：智能家居到底解决什么问题？这里面不只是说有很多新科技，而是讲清楚这些科技到底创造什么样的生活价值。</p><p></p><p>笔者认为，企业建设数字化基座的意图应当与三星的殊途同归，通过「数字化办公」串联起人们有关工作的方方面面，以降本增效为核心，沟通协作为线打造载体，整合并优化新旧碎片化供给，在充分吸纳平台能力的基础上，识别高频业务场景并加以融合，关注用户体验，实现对企业商业模式和管理运营的全局优化，为客户、企业和员工带来全新的数字化价值提升，增强企业在数字经济环境下的核心竞争能力。</p><p></p><h4>关于作者</h4><p></p><p>何鹏飞，数字化协作平台产品负责人，长期从事 ToB 企业数字化转型产品规划与设计，关注企业协同办公、零信任网络架构、NLP 自然语言处理等领域。</p>",
    "publish_time": "2023-03-22 12:26:01",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "八年“老网红”Flink：揭秘实时流计算引擎全球化落地的演进历程",
    "url": "https://www.infoq.cn/article/W7Sjg9omNIgWh8fRZpN7",
    "summary": "<p>“Flink 已经成为全球范围内实时流计算的事实标准。”用这句话来描绘 Flink 在当前大数据技术领域的地位并不为过。</p><p></p><p>虽然大数据领域的技术和潮流方向在不断发生改变，但是 Flink 一直处于核心驱动的位置。从流式计算引擎的兴起，到流批一体在企业内部的落地，再到为实现端到端全链路的实时化分析能力而走向舞台中央的流式数仓，Flink 均在其中扮演着重要的角色。</p><p></p><p>以上每个过程的推进和实现都并不容易，Flink 到底是如何做到的？其背后的推动力是什么？凭什么受到全球企业和开发者的青睐？带着这些问题，InfoQ 有幸采访到了 Apache Flink 中文社区发起人、阿里巴巴开源大数据平台负责人王峰（莫问），以期深度了解 Flink 从实时流计算引擎到全球化落地的演进历程。</p><p></p><h1>流式计算引擎的纷争：Flink 靠什么打破瓶颈期？</h1><p></p><p></p><p>在 Flink 诞生之前，大数据领域的计算框架不在少数，先后出现的 Hadoop 和 Spark 已是业界的主流选择。</p><p></p><p>彼时，专为批处理而生的 Hadoop，在实时数据处理方面存在着明显不足。在此背景下，Spark 推出了流计算解决方案——Spark Streaming。但由于 Spark 不是一款纯流式计算引擎，所以其在动态调整、事物机制、延迟性、吞吐量等方面的表现也并不亮眼。直到 Flink 出现以后，才提供了一个真正的流引擎，将 Streaming 计算和状态存储进行有机融合，在框架层支持整个流计算状态的精准数据一致性，填补了大数据市场的空白。</p><p></p><p>时至今日，Flink 已经成为全球范围内被广泛使用的开源大数据计算引擎。但据 InfoQ 了解，即便是这样一款性能优秀的流计算引擎，其在一开始的推广阶段也曾陷入瓶颈。这背后，一方面是市场需求所致，早在七八年前，大多数企业对于数据处理的实效性需求还未大规模显露；另一方面是受学习门槛的影响，当时大数据处理领域的通用语言是 SQL，而早期开发 Flink 需要通过 DataStream 的 API 写 Java 代码，学习门槛过高成为了 Flink 陷入推广瓶颈的核心因素之一。</p><p></p><p>那么，在未经大规模验证的情况下，Flink 到底是如何走向公众视野的？“阿里其实是在其他企业还没有需求的时候，就已经把 Flink 打磨好了。”王峰在接受 InfoQ 采访时回忆道。</p><p></p><p>相比于其他没有实时化计算需求的企业，阿里在业务量方面走得比较靠前。尤其是在双 11 这类特殊的业务场景下，对数据做实时的收集、分析、处理成为强需求。当时，阿里的商品数据处理就经常需要面对增量和全量两套不同的业务流程问题，如何用一套统一的大数据引擎技术，在各种不同的场景下提供支持，成为阿里面临的技术挑战。</p><p></p><p>于是，阿里在 2015 年启动了对 Flink 的调研，决定用 Flink 做一个统一的、通用的大数据引擎作为未来的选型，并在 2016 年首次将 Flink 应用在了双 11 搜索推荐场景中。</p><p></p><p>但正如前文所言，阿里在使用阶段也发现了 Flink 在稳定性、易用性等方面的不足。基于此，阿里也开启了对 Flink 的优化之路，在内部建立起了一个 Flink 的分支——Blink，实现了 Flink 流批一体架构的高度融合，含统一 Flink SQL、统一 SQL 架构以及与 Hive 生态系统集成。在 2019 年，阿里将内部积累的 Blink SQL 贡献给了 Flink 社区，将 Blink 中比较通用的部分悉数回馈给 &nbsp;Flink 社区，贡献了超过一百万行代码，这其中包括 Runtime、SQL、PyFlink 以及 ML Pipeline。</p><p></p><p>历经阿里庞大业务量洗礼的 Blink，对 Flink SQL 产生了深远的影响，不仅推动了 Flink SQL 的发展，使其比以前快了 10 倍，还把 Flink SQL 塑造成了如今我们看到的样子。此外，阿里云还在2019年收购了Flink母公司Data Artisans（更名Ververica），并推出了全球统一的Flink企业版平台——Ververica Platform。</p><p></p><p>由此也能看出，Flink 能够在 2019 年将 GitHub 上的 Star 数量翻了一倍，这样的数据波动绝非偶然，很大程度是阿里在背后推动。</p><p></p><h1>从计算引擎到流批一体和流式数仓：Flink 从项目成为“标准”</h1><p></p><p></p><p>如果说 2019 年仅仅是阿里向 Flink 全球化社区迈出的一小步，那么至此以后，阿里便一直在推动着 Flink 全球化社区的发展。据统计，阿里 /Ververica 主导了 211 个 Flink 核心设计提案，贡献了 Flink 70%+ 的核心改进。</p><p></p><p>在 2020 年，社区一共发布了 Flink 1.10 &amp; 1.11 &amp; 1.12 三个大版本，对 Flink 流批一体架构做了重要的升级和落地；在 2021 年，推出的 Flink Remote Shuffle 项目，解决了 Flink 大规模批处理作业的稳定性问题。这两年间，Flink 在持续优化流计算核心能力的同时，还在逐步推进流批一体的技术理念。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/30/302dd14a42f1bd14e7598b6d23132c68.png\" /></p><p></p><p>直到 2022 年，我们在 Flink Forward Asia 2021 看到了 Flink 的下一步发展方向——流式数仓，即让整个数仓的数据全实时地流动起来，且是以纯流的方式而不是微批的方式流动。为了实现流批一体的存储能力，Flink 社区还在去年推出了全新子项目 Table Store（近期已升级为 Apache 孵化项目 Paimon）。本文，我们不对流式数仓过多赘述，在 InfoQ 发布的 <a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651103253&amp;idx=1&amp;sn=00a177fe011033893870fbd64f40ab5f&amp;chksm=bdb958468aced150b6ab1c4d6300f3d70b46126cd6f3524362bdd7feed5627721c5ecfeb3dc9&amp;scene=21#wechat_redirect\">《Apache Flink 不止于计算，数仓架构或兴起新一轮变革》</a>\" 中已有详尽解读。</p><p></p><p>但回溯 2019 年 -2022 年 Flink 的版本迭代情况可以看出，Flink 的迭代速度相对比较快，基本每三到四个月就会发布一个大版本。动作频频的背后，我们也在好奇，阿里为何总能洞察到大数据行业的真实需求？其背后的迭代思路来自何处？关于这个问题，王峰总结“实践经验 + 理论洞察”是两个关键要素。</p><p></p><p>众所周知，阿里是 Flink 的早期实践者，在丰富业务形态与庞大业务量的驱动下，阿里内部对实时化计算的要求越来越高，这也就倒逼 Flink 的良性发展和沉淀。例如，在2020年，阿里巴巴首次在双11最核心的天猫营销活动分析大屏场景中落地Flink流批一体；<a href=\"https://www.infoq.cn/article/XHuvlsYrPhxhvFOcHjDs\">在 2021 年双 11 中</a>\"，Flink 承载的实时计算峰值达到了每秒 40 亿条记录，数据体量也达到 7 TB 每秒...... 正是在阿里大规模应用 Flink 的实战经验之下，真实的业务需求能够帮助 Flink 做输入，并反哺 Flink 全球化社区向前发展。</p><p></p><p>然而，只有业务场景这一个要素并不足够，Flink 的每次迭代能够顺应大数据行业的发展需求，还离不开阿里在全球化方面的全局洞察。据统计，阿里联合 Ververica 已累计培养了近 70 位 Flink 核心贡献者（含项目管理委员会 PMC 成员和活跃贡献者 committer），占比超 70%。因此，阿里在推动 Flink 的发展过程中，其技术视野并不会只聚焦在国内，对标国外头部大数据公司的技术理念促使 Flink 的每次规划都更具前瞻性。</p><p></p><p>总体而言，我们发现，无论是持续强化流计算引擎，还是推动流批一体技术理念的落地应用，亦或是提出流式数仓的新目标，Flink 核心特色其实一直都没有改变，其本质都是基于 Streaming 这个核心理念进行持续强化。</p><p></p><p>这也就不难理解，Flink 如今能够成为大数据实时计算业界事实标准，与其在一条赛道保持专注是密不可分的。“开源项目只有做到业界的头部才有生存空间，Flink 就是要成为全球范围内最好的流式计算引擎。”王峰在采访中进一步补充道。</p><p></p><h1>开源之余，Flink 的全球化落地之路</h1><p></p><p></p><p>基于全球化的开源理念，Flink 吸引了全球开发者的加入，截至目前已经积累了超过 1600 名开发者为 Flink 社区做贡献，2022 年又新增加了 200 多名开发者。在下载量方面，Flink 在 2022 年再创新高，月度峰值的下载量最高已经突破 1400 万次。</p><p></p><p>不仅于此，Flink 还吸引了全球企业的应用落地，Apple、Capital One、eBay、Ericsson 等全球知名公司都在使用 Flink 处理实时数据。而这样的实践，又反推整个项目不断更新迭代，进而发展得更好。从某种程度来讲，Flink 其实为我们展现了一个全球化开源项目应该有的良性循环。</p><p></p><p>目前，阿里巴巴不仅是 Flink 最大的贡献者和使用者，还基于 Apache Flink 推出了实时计算 Flink 云产品和全球统一的 Flink 企业版平台 Ververica Platform，在政务、金融、制造、零售、交通出行、传媒、游戏、科技等行业大规模应用，帮助上千家全球企业更高效地进行实时业务升级。</p><p></p><p>根据不完全统计，使用 Flink 的非互联网企业占比已超过 30%。而通过这组数据，我们的一个明显感知是，实时化计算已经从早期只能被少数互联网企业玩转，逐渐演变成一种更为普适化的技术。</p><p></p><p>正如王峰在采访时所说：“如果大多数企业都不会用、用不起，大数据技术永远只能高高在上，很难再往下发展。”如何持续降低大数据的使用门槛以及使用成本，已经成为业界的共识，而从 Flink 在非互联网企业的加速普及中，我们已经看到了阿里取得的阶段性成果。</p><p></p><p>谈及 Flink 全球化运作的后续规划，王峰提到，接下来迭代商业化产品会沿着两条路径来走，以满足国内外企业的不同需求。</p><p></p><p>“在帮助上千家全球企业高效地进行实时业务升级的过程中，能够发现国内、国外企业在使用 Flink 商业化版本的关注点也有所不同。”</p><p></p><p>例如，国内企业更加关注运行成本，以及使用 Flink 云产品以后能否提供服务支持等等，后续实时计算 Flink 版会着重从软硬一体结合的角度来降低成本；反观国外企业，他们更加关注 Ververica Platform 的产品力，即产品的用户体验、安全性、易用性等方面是不是做得足够好。据王峰透露，Ververica Platform 预计在 4 月份会推出云中立的特性，让企业不仅能在阿里云上运行 Flink，还可以在 AWS、Azure、Google Cloud 等公有云上使用。</p><p></p><p>除此之外，前文提到的 Flink Table Store 子项目也迎来新动态。近期，阿里已经将其独立孵化成 Apache 的顶级项目 Paimon，并且会开放对接Spark、Presto/Trino、StarRocks/Doris等主流的计算引擎，目的便是为了让用户通过一套存储实现数据的更新、分析等等。</p><p></p><p>从上述释放的信号我们能够感受到，阿里不仅在技术生态方面具备了全球化的发展态势，伴随着云中立特性的补充以及独立子项目的孵化，Flink 商业生态、开源生态的全球化也将得到进一步的完善。</p><p></p><h1>写在最后</h1><p></p><p></p><p>Flink 能够成为全球范围内被广泛使用的开源大数据计算引擎，不仅靠阿里一家的努力，同时需要更多开发者与企业的参与、共建。据统计，Flink 全球化社区已经有超过 20 万开发者关注、超过 100 家国内外知名公司参与代码贡献。在如此庞大的用户和开发者生态之中，有 45% 是来自于中国的开发者，这足以体现中国开发者对 Flink 全球化社区的推动作用。</p><p></p><p>今后，我们也很乐于看到在阿里的持续引领下，Flink 全球化社区能够在实时计算层面有更大的突破。</p>",
    "publish_time": "2023-03-22 13:50:49",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "第二届“鼎新杯”数字化转型应用征集大赛在京启动",
    "url": "https://www.infoq.cn/article/e2d398ddd6cf930ad8b2fcc58",
    "summary": "<p></p><h4>引言</h4><p></p><p>2023年3月21日，由中国信息通信研究院（以下简称“中国信通院”）、中国通信企业协会联合主办的第二届“鼎新杯”数字化转型应用征集大赛正式启动。工业和信息化部信息通信发展司政策标准处处长陆洋、中国通信标准化协会理事长闻库、中国通信企业协会副会长兼秘书长赵中新、中国互联网协会副理事长兼副秘书长何桂立、中国信通院副院长魏亮等领导出席会议致辞，中国工程院院士邬贺铨发表主旨演讲。</p><p><img src=\"https://static001.geekbang.org/infoq/d6/d6567d3d82e774c87cb3ca65391a726e.jpeg\" /></p><p>第二届“鼎新杯”数字化转型应用征集大赛启动会现场</p><p></p><h3>嘉宾致辞环节</h3><p></p><p>陆洋表示，以互联网、大数据、云计算为代表的信息通信技术快速发展，并与经济社会发展各领域深度融合，促进数字经济加速发展。工信部围绕夯实新型基础设施，推动数字化转型发展开展了一系列工作，取得良好成效。并从强化基础设施建设、加强技术产业创新、深化行业融合发展等方面提出了建议。</p><p><img src=\"https://static001.geekbang.org/infoq/88/881b44f1496df8850714d72f4d6c57be.jpeg\" /></p><p>工业和信息化部信息通信发展司政策标准处处长陆洋致辞</p><p></p><p>闻库介绍，数字化转型浪潮已由概念普及快速走向实践落地，新一代信息通信技术加速迭代创新，信息通信业与各行业融合程度不断加深，信息通信领域标准工作稳步推进，为助力企业数字化转型发展提供了标准化支撑和发展路径参考。</p><p><img src=\"https://static001.geekbang.org/infoq/93/93c7a66bdb3d99fec7f60c045114c5ac.jpeg\" /></p><p>中国通信标准化协会理事长闻库致辞</p><p></p><p>赵中新指出，我国产业数字化进程不断提升，信息通信行业融合应用加速向工业、医疗、教育、交通等各个领域进行拓展，为数字经济的发展增添新的动能，带来新的活力。中国通信企业协会希望通过持续办好“鼎新杯”数字化转型应用征集活动，推动行业数字化转型融合创新，积极培养储备数字化专业人才，为经济社会各个领域的数字化转型智能升级贡献力量。</p><p><img src=\"https://static001.geekbang.org/infoq/e9/e91c5c338dc55d80465dc58e23874ce5.jpeg\" /></p><p>中国通信企业协会副会长兼秘书长赵中新致辞</p><p></p><p>何桂立提到，在党中央、国务院的领导下，国内互联网行业和我国经济社会的全面数字化转型相互促进、共同发展，新型基础设施建设加速推进，数字技术应用水平进一步提升，互联网治理体系不断优化完善，行业融合共享能力持续增强，产业生态建设取得新成效。并从提高转型认识、利用政策红利、坚持创新驱动、加强产业合作四方面提出建议。</p><p><img src=\"https://static001.geekbang.org/infoq/88/8856be4c8068b284273fdb9693566e91.jpeg\" /></p><p>中国互联网协会副理事长兼副秘书长何桂立致辞</p><p></p><p>魏亮表示，现阶段，各行业企业积极开展数字化转型探索，从生产方式、业务形态、产业组织、商业模式、创新范式、技术架构等方面带来提升变革。未来，中国信通院将继续加强数字化转型领域相关技术发展和行业应用研究工作，持续深化与各界的合作，携手推进我国数字经济转向深化应用、规范发展、普惠共享的新阶段。</p><p><img src=\"https://static001.geekbang.org/infoq/0b/0b3332eb4089e78ff5c162cee5a7fe94.jpeg\" /></p><p>中国信通院副院长魏亮致辞</p><p></p><p>中国信通院云计算与大数据研究所所长何宝宏主持嘉宾致辞和启动仪式环节。何宝宏表示，为践行“十四五”规划关于数字化发展相关指引，打造一批具有产业引领与推广应用效应的企业数字化转型示范案例，中国信通院与中国通信企业协会在去年联合发起第一届“鼎新杯”数字化转型应用大赛，获得了业界广泛关注和积极参与。</p><p><img src=\"https://static001.geekbang.org/infoq/ff/ff00e3bee60e1462ea8d3616fbcbf65c.jpeg\" /></p><p>中国信通院云计算与大数据研究所所长何宝宏主持</p><p></p><h3>启动发布环节</h3><p></p><p>在启动和发布环节，中国工程院院士邬贺铨、工业和信息化部信息通信发展司政策标准处处长陆洋、中国通信标准化协会理事长闻库、中国互联网协会副理事长兼副秘书长何桂立、中国通信企业协会副会长兼秘书长赵中新、中国信通院副院长魏亮上台，共同启动本次大赛。</p><p><img src=\"https://static001.geekbang.org/infoq/17/17581142626ab11f6102144deb72bc8a.jpeg\" /></p><p>第二届“鼎新杯”数字化转型应用征集活动启动仪式</p><p></p><p>邬贺铨院士发表题为《腾云驾物加持 数字转型加速》的主旨演讲，提出数字化转型可以充分运用各种技术，并从5G多样化应用、算网协同、通用人工智能、云上融合创新等方面详细介绍了实现数字化转型的多种方式，通过详实案例剖析了多种前沿数字技术在赋能数字化转型方面的巨大价值。</p><p><img src=\"https://static001.geekbang.org/infoq/60/602f642c8b1b067849fc6a474095a5b4.jpeg\" /></p><p>中国工程院院士邬贺铨发表主旨演讲</p><p></p><h3>数字化转型实践分享环节</h3><p></p><p>中国信通院云计算与大数据研究所政企数字化转型部副主任董恩然主持了数字化转型实践分享环节。在此环节，中国信通院云计算与大数据研究所政企数字化转型部副主任（主持工作）徐恩庆对第二届“鼎新杯”数字化转型应用大赛进行了解读。第二届“鼎新杯”大赛以“数字扬帆 鼎新引领”为主题，在首届大赛成功经验基础上全面升级，从数字基础设施、数字技术平台、数字化业务、行业数字化融合、数字原生、数字专项创新等六大方向设置相关专题赛道，从赛道组织形式上广泛开放合作创新，并邀请超过30家行业媒体深度参与推广，充分助力各行业企业沉淀转型经验、彰显转型价值、发挥示范作用。</p><p><img src=\"https://static001.geekbang.org/infoq/66/66b510acb7f0c3d92bd3cb817a599b00.jpeg\" /></p><p>中国信通院云计算与大数据研究所政企数字化转型部副主任（主持工作）徐恩庆进行解读</p><p></p><p>人民日报、央视网、人民邮电报、中国财富网、数智观察、中国IDC圈、极客邦科技、51CTO、中国信通院云大所共同启动第二届“鼎新杯”数字化转型应用征集大赛媒体聚能助燃活动。</p><p><img src=\"https://static001.geekbang.org/infoq/7e/7e3cc12c27e3ac6856a97c77542ab52a.jpeg\" /></p><p>第二届“鼎新杯”数字化转型应用征集媒体聚能助燃正式发布</p><p></p><p>招商蛇口数字城市科技有限公司运营总监曹红波，中国联通软件研究院党委委员、副院长马秀发，中国工商银行软件开发中心资深经理朱敏，腾讯集团高级总监刘峰发表了主题演讲。</p><p><img src=\"https://static001.geekbang.org/infoq/19/191bdc4350b97fbf80a69c2ea649706b.png\" /></p><p>嘉宾发表主题演讲</p><p></p><p>五矿集团、广汽集团、中国移动、中国铁塔、建设银行、中国人寿、中国航信、招商新智、中邮信息、阿里云、浪潮云、金蝶、中兴通讯、中电太极、亚信科技、优刻得、中金数据、博云科技、明源云等企业相关负责人，以及人民日报、央视网、新华网、人民邮电报、中国财富网、InfoQ极客传媒、51CTO、中国IDC圈、数智观察等媒体代表出席会议。</p><p></p><h4>关于“鼎新杯”数字化转型应用征集</h4><p></p><p>“鼎新杯”数字化转型应用征集活动，以落实国家“十四五”规划关于“加快数字化发展，建设数字中国”的总体要求为目的，意在打造一批具有产业引领与推广应用效应的企业数字化转型应用示范案例。首届活动于2022年3月正式启动，由中国信息通信研究院与中国通信企业协会联合主办，云计算与大数据研究所政企数字化转型部承办。</p><p>首届“鼎新杯”活动得到了业界高度关注和广泛参与，从活动启动至初审、复审、专家评审等环节，历时三个月，各行业企业踊跃报名，最终征集应用案例共计 649 个，其中 数字技术创新专题 283个，行业融合应用专题 366 个，最终评选出 149 个应用案例分获得一二三等奖。2023年第二届“鼎新杯”数字化转型应用征集活动于3月21日正式启动！</p><p></p><p>欢迎访问大赛官网：<a href=\"http://www.idcquan.com/dxb\">http://www.idcquan.com/dxb</a>\"</p><p>大赛组委会联系人：</p><p>董    伟 13810413143（微信同号） dongwei1@caict.ac.cn&nbsp;</p><p>董恩然 18601280900（微信同号） dongenran@caict.ac.cn</p><p>彭海燕 18310385068（微信同号）</p>",
    "publish_time": "2023-03-22 15:07:07",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "迎战ChatGPT，谷歌聊天机器人Bard正式开放测试",
    "url": "https://www.infoq.cn/article/4i445bkgQvd6yoNSGu5v",
    "summary": "<p></p><p>3月21日晚间，谷歌开放了其聊天机器人 Bard 的测试。</p><p></p><p>Bard 最初将可供美国和英国的部分用户使用，用户可以在<a href=\"http://bard.google.com/\">bard.google.com</a>\"上注册申请测试。</p><p></p><p>不过谷歌表示推出速度会很慢，且没有提供完全公开访问的日期。</p><p></p><p>自 OpenAI 的 ChatGPT 推出后，谷歌就在加紧研发人工智能聊天机器人Bard ，谷歌也对这款ChatGPT竞品寄予厚望。谷歌希望借助 Bard，巩固其在 AI 聊天机器人领域的地位，同时保持其在搜索引擎市场的主导地位。</p><p></p><p><a href=\"https://www.theverge.com/2022/12/8/23499728/ai-capability-accessibility-chatgpt-stable-diffusion-commercialization\">与OpenAI 的 ChatGPT</a>\"和<a href=\"https://www.theverge.com/2023/2/8/23590873/microsoft-new-bing-chatgpt-ai-hands-on\">微软的 Bing 聊天机器人</a>\"一样，Bard 为用户提供了一个空白文本框，用户可以就他们喜欢的任何话题提问。</p><p></p><p>下图展示了Bard 如何回答问题：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a2/a28f2ebebbd98ad156d16a0a22ab746c.png\" /></p><p></p><p>Bard由研究型大型语言模型 (LLM) 提供支持—— LaMDA 的轻量级优化版本。LaMDA 是两年前在 2021 年谷歌 I/O 主题演讲中<a href=\"https://searchengineland.com/googles-lamda-will-enable-open-ended-voice-conversations-348729\">宣布的，作为谷歌的下一代语言和对话功能。</a>\"</p><p></p><p>LaMDA建立在 <a href=\"https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html\">Transformer</a>\" 上，由这个架构生成的模型可以训练阅读许多单词（例如，一个句子或段落），注意这些单词之间的关系，然后预测它认为接下来会出现什么单词。但与其他大多数语言模型不同的是，LaMDA 接受的是对话训练。在训练过程中，它发现一些区别于其他语言形式的开放式对话的细微差异。LaMDA现在被用在Bard 上为用户创建答案。</p><p></p><p>谷歌表示， LaMDA 的轻量级模型版本，意味着LaMDA 需要“显著更少的计算能力”，这将使LaMDA 能够扩展到更多用户，同时也允许获得更多反馈。</p><p></p><p>谷歌强调 Bard ，不是其搜索引擎的替代品，而是谷歌搜索的补充&nbsp;，旨在提高生产力、加速创意并培养好奇心，用户可以从中“反弹”想法、生成的机器人写草稿，或者只是聊聊生活。 Bard允许用户检查其响应或探索网络上的资源。作为一个独立的网页运行，BARD 由一个单一的问题框组成，而不是集成到谷歌的搜索引擎中。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/35/359512346b687ea49bbc1cde73e76b51.png\" /></p><p></p><p>此图展示了Google 如何很快将 AI 生成的答案直接集成到 Google 搜索。</p><p></p><p>皮采表示，很快，用户将在谷歌搜索中看到 AI 支持的功能，这些功能将复杂的信息和多个视角提炼成易于理解的格式，帮助用户可以快速了解全局并从网络上了解更多信息。</p><p></p><p>在该项目的两位负责人 Sissie Hsiao 和 Eli Collins 撰写的博客文章中，他们谨慎地将 Bard 描述为“一项早期实验......旨在帮助人们提高生产力，加速他们的想法，并激发他们的好奇心。”&nbsp;他们还将Bard描述为一种让用户“与生成人工智能协作”的产品。</p><p></p><p>谷歌还表示，在 Bard 上的工作以 AI 原则为指导，专注于质量和安全，该公司使用人工反馈和评估来增强其系统，并为Bard实施了护栏，例如限制对话中的交流次数，以保持互动有益和切合主题。</p>",
    "publish_time": "2023-03-22 17:49:31",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]