[
  {
    "title": "生成式AI碳排放堪比开车往返月球？这个问题该如何解决",
    "url": "https://www.infoq.cn/article/EGdxPRvIZexgBCvtaeJP",
    "summary": "<p>生成式人工智能的发展正在改变我们的行业和社会。像ChatGPT和CoPilot这样的语言模型可以码字和写代码，图像和视频生成模型可以根据简单的提示词生成引人注目的内容，音乐和语音模型可以轻松地合成任何人的声音，并创作出复杂的音乐。</p><p></p><p>世界各地都在讨论这项技术的威力和潜在价值。与此同时，人们也在谈论它可能带来的风险和威胁。</p><p></p><p>从对超级智能人工智能消灭人类的担忧，到对歧视的进一步自动化以及对仇恨和错误信息被进一步放大的担忧，人们正在努力评估和减轻这项新技术的潜在负面影响。</p><p></p><p>人们也越来越关注这些模型的能源使用和相应的碳排放。最近几个月又出现了一些关于碳排放的比较。</p><p></p><p>例如，在一篇文章中，作者戏谑<a href=\"https://www.theregister.com/2020/11/04/gpt3_carbon_footprint_estimate/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw\">训练GPT-3的碳排放等同于开车往返月球</a>\"，另一篇文章则解释说<a href=\"https://www.forbes.com/sites/glenngow/2020/08/21/environmental-sustainability-and-ai/?sh=314a59cc7db3&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw\">训练人工智能模型比飞机长途飞行排放更多的碳</a>\"。</p><p></p><p>最终的影响将取决于这项技术是如何被使用的，以及它在多大程度上融入了我们的生活。</p><p></p><p>我们很难准确预测它将如何影响我们的日常生活，但目前已经有一个很明显的例子，即搜索巨头将生成式人工智能<a href=\"https://blog.google/products/search/search-generative-ai-tips/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw\">集成</a>\"到他们的产品中。</p><p></p><p>Wired网站最近的一篇<a href=\"https://www.wired.com/story/the-generative-ai-search-race-has-a-dirty-secret/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw\">文章</a>\"写道：</p><p></p><p></p><blockquote>加拿大数据中心公司QScale联合创始人Martin Bouchard表示，基于他对微软和谷歌搜索发展计划的了解，在搜索过程中添加生成式人工智能需要让“每次搜索至少增加4到5倍的计算量”。</blockquote><p></p><p></p><p>显然，生成式人工智能技术是不容忽视的。</p><p></p><p></p><h2>生成式人工智能的碳排放是否被夸大了？</h2><p></p><p></p><p>人们对生成式人工智能碳排放的担忧可能被放大了。我们要正确看待这个问题：全球整个科技行业的温室气体排放量占全球温室气体排放量的1.8%至3.9%，但其中只有一小部分是由人工智能[1]造成的。人工智能与航空或其他碳排放源的规模存在巨大差异：每天都会有许多汽车和飞机行驶数百万公里，但训练像GPT模型这样的现代人工智能模型的次数却相对较少。</p><p></p><p>诚然，我们尚不清楚究竟人类究竟训练了多少大型人工智能模型，这取决于我们如何定义“大型人工智能模型”。如果说大模型指的是GPT-3或更大规模的模型，那么可能只有不到1000个。我们来做一个简单的数学运算：</p><p></p><p></p><blockquote>根据最近的一项<a href=\"https://www.technologyreview.com/2022/11/14/1063192/were-getting-a-better-idea-of-ais-true-carbon-footprint/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw\">估计</a>\"，训练GPT-3排放了500吨的二氧化碳。Meta的LLaMA模型<a href=\"https://www.google.com/url?q=https://arxiv.org/pdf/2302.13971.pdf&amp;sa=D&amp;source=docs&amp;ust=1686736622103395&amp;usg=AOvVaw0EOH1_3alOGQm9Nh_pUddt&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw\">估计</a>\"排放了173吨。训练1000个500吨的模型将涉及约50万吨二氧化碳的总排放量。新模型可能会在一定程度上增加排放量，但几乎可以肯定的是，这1000个模型的碳排放被高估了。2019年，商业航空业排放了约9.2亿吨二氧化碳[2]， 几乎是大模型训练的2000倍，而且这是将一年的航空业碳排放与多年的大模型训练碳排放进行的比较。大模型训练的碳排放仍然不容忽视，但这种戏剧性的比较具有误导性。我们需要更细致入微的思考。</blockquote><p></p><p></p><p>当然，这只是考虑到这些模型的训练。模型的服务和使用也需要能源，也会有相关的碳排放。<a href=\"https://towardsdatascience.com/the-carbon-footprint-of-chatgpt-66932314627d?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw\">一项分析</a>\"表明， ChatGPT运行一年可能会排放约15000吨二氧化碳。<a href=\"https://medium.com/@chrispointon/the-carbon-footprint-of-chatgpt-e1bc14e4cc2a?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw\">另一项分析</a>\"则表明实际的排放量要要少得多，约为1400吨。尽管都不可忽略，但与航空业相比仍然微不足道。</p><p></p><p></p><h2>碳排放透明度</h2><p></p><p></p><p>但是，即使对人工智能碳排放的担忧有些言过其实，但仍然值得我们关注，特别是当生成式人工智能越来越多地融入到我们的现代生活中时。随着人工智能系统的不断演化和投用，我们需要关注它们对环境的影响。我们可以遵循许多成熟的实践，也有一些方法可以减少生成式人工智能的碳排放。</p><p></p><p>首先，透明度至关重要。我们建议提高透明度，便于监测与人工智能模型的训练和使用相关的碳排放。这将使那些部署这些模型的人以及最终用户能够根据人工智能的碳排放量做出明智的决定。同时，将人工智能相关的碳排放纳入温室气体清单和净零目标。这是<a href=\"https://foundation.mozilla.org/en/research/library/ai-transparency-in-practice/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw\">人工智能透明度</a>\"的一个组成部分。</p><p></p><p>举个这方面的例子，法国<a href=\"https://www.euractiv.com/section/digital/news/new-law-forces-french-operators-to-disclose-carbon-footprint-to-public/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw\">最近通过了一项法律</a>\"，要求电信公司就其在可持续性方面的措施提供透明度报告。我们也可以出台类似的法律，例如要求包含人工智能系统的产品向其客户报告碳排放信息，并要求模型提供商将碳排放数据集成到其API中。</p><p></p><p>更高的透明度可以带来更强的动力来建立节能的生成式人工智能系统，我们有很多方法可以提高效率。在InfoQ最近发布的一篇<a href=\"https://www.infoq.com/articles/impact-machine-learning-climate/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw\">文章</a>\"中，微软高级软件工程师Sara Bergman呼吁人们注意人工智能系统的生命周期，并建议如何应用<a href=\"https://greensoftware.foundation/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw\">绿色软件基金会</a>\"的工具和实践来提高人工智能系统的能源效率，包括如何选择服务器硬件和架构，以及选择低碳密集型电力的时段和地区。而生成式人工智能为提高效率提供了一些独有的可能性。</p><p></p><p></p><h2>效率：能源使用与模型性能</h2><p></p><p></p><p>正如<a href=\"https://arxiv.org/pdf/2302.08476.pdf?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw\">碳计算：影响机器学习排放的因素调查</a>\"中所探讨的那样，与训练或使用生成式人工智能模型相关的碳排放取决于许多因素，包括：</p><p></p><p>模型参数个数；量化(数值精度)；模型架构；使用GPU或其他硬件的效率；电力的碳密度。</p><p></p><p>后两个因素与其他软件一样，人们已经对其进行了探讨，例如我们上面提到InfoQ的<a href=\"https://www.infoq.com/articles/impact-machine-learning-climate/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw\">文章</a>\"。因此，我们这里关注的是前三个因素，它们都涉及能源使用和模型性能之间的一些权衡。</p><p></p><p>效率的价值不仅体现在可持续性方面，更高效的模型可以在可用数据较少的情况下提供高效的表现性能、降低成本，并有在边缘设备上运行的可能性。</p><p></p><p></p><h3>模型参数个数</h3><p></p><p></p><p>OpenAI论文<a href=\"https://arxiv.org/pdf/2005.14165.pdf?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw\">Language Models are Few-Shot Learners</a>\"中的一张图告诉我们，模型越大表现越好。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/30/306f6fe67271b428b99facc4841a4f9a.webp\" /></p><p></p><p></p><p><a href=\"https://openreview.net/pdf?id=yzkSU5zdwD&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw\">大型语言模型的涌现能力</a>\"中也提到了同样的观点：</p><p></p><p></p><blockquote>扩大语言模型已经被证明可以在广泛的下游任务上可预见地提高性能和样本效率。本文讨论的是一种不可预测的现象，我们称之为大型语言模型的涌现能力。如果一种能力在较小的模型中不存在，但在较大的模型中存在，我们称之为”涌现“。</blockquote><p></p><p></p><p>我们发现，不仅更大的模型在处理给定的任务时表现得更好，而且实际上只有当模型变得更大时，才会涌现出新的能力。这种能力涌现的例子包括对大数的加减、毒性分类和数学单词问题的思维链技术。</p><p></p><p>但是训练和使用更大的模型需要更多的计算，因此需要更多的能源。因此，我们可以看到模型的能力和性能与其计算强度之间的权衡，进而可以看出与碳密度的关系。</p><p></p><p></p><h3>量化</h3><p></p><p></p><p>我们对模型的<a href=\"https://huggingface.co/docs/optimum/concept_guides/quantization?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw\">量化</a>\"进行了大量研究。我们在模型计算中使用低精度数字来降低计算密度，尽管会牺牲一些精度。它允许模型在普通的硬件上运行，例如，在消费级笔记本电脑上。减少计算量和降低精度之间的权衡通常是非常有利的，对于特定能力水平的计算，量化模型非常节能。还有一些相关的技术，如“<a href=\"https://aitechtrend.com/the-power-of-knowledge-distillation-in-creating-smaller-and-faster-models/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw\">蒸馏（Distillation）</a>\"”，它使用较大的模型来训练小模型，这个小模型可以很好地完成给定的任务。</p><p></p><p>蒸馏技术需要训练两个模型，因此很可能会增加与模型训练相关的碳排放，不过它会通过减少模型在使用中的碳排放来弥补。对已训练好的模型进行蒸馏也是一个很好的解决方案，我们甚至可以同时利用蒸馏和量化来为给定的任务创建更高效的模型。</p><p></p><p></p><h3>模型架构</h3><p></p><p></p><p>模型架构对计算密度有很大的影响，因此选择更简单的模型可能是减少人工智能系统碳排放最有效的方法。GPT的Transformer非常强大，越是简单的架构就越可以有效地用于许多应用程序。像ChatGPT这样的模型被认为是“通用的”，这意味着这些模型可以被用于许多不同的应用程序。然而，对于相对固定的应用程序来说，就没有必要使用复杂的模型。为任务定制的模型可以使用更简单和更小的架构达到所需的性能，从而减少碳排放。另一种有用的方法是微调——论文<a href=\"https://arxiv.org/pdf/2205.05638.pdf?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw\">Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning</a>\"讨论了微调如何“提供更好的准确性以及显著降低计算成本”。</p><p></p><p></p><h2>将碳排放和精度指标放在一起</h2><p></p><p></p><p>“准确性”一词很容易让我们陷入“越多越好”的认知。我们需要明白的是，对于特定的应用程序来说——“适可而止”才是最好的。在某些情况下，可能需要最新和最好的模型，但对于有些应用程序来说，老的、较小的模型（可能是量化的模型）可能就完全足够了。在某些情况下，系统做出正确的行为可能需要所有可能的输入，但有些应用程序可能具有更强的容错能力。在正确地了解了所需的应用程序和服务级别之后，可以通过比较各种模型的性能和碳排放量来选择合适的模型。也可能存在使用一组模型的情况。默认情况下将请求传给更简单、更小的模型，对于简单模型无法处理的任务，可以将其传给更复杂的模型。</p><p></p><p>为此，我们需要将碳排放指标集成到DevOps(或MLOps)流程中。一些工具，如<a href=\"https://codecarbon.io/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw\">codecarbon</a>\"，可以很容易地跟踪和计算与模型训练和服务相关的碳排放。将这个工具或类似的工具集成到持续集成测试套件中，可以同时分析碳排放、计算精度和其他指标。例如，在试验模型架构时，测试用例可以立即报告精度和碳排放，从而更容易找到正确的架构并选择正确的参数，以满足精度要求，同时最大限度地减少碳排放。</p><p></p><p>同样需要注意的是，实验本身也会导致碳排放。在MLOps周期的实验阶段，使用不同的模型和架构进行实验，以确定最佳选择，我们可以综合考虑准确性、碳排放和潜在的其他指标。从长远来看，随着模型不断接受实时数据的训练和/或投用，可以减少碳排放，但过度的实验会浪费时间和精力。做出权衡将取决于许多因素，但当碳排放指标可用于实验以及模型的训练和服务时，我们的工作会变得更容易。</p><p></p><p></p><h2>绿色提示词工程</h2><p></p><p></p><p>说到与生成式模型的服务和使用相关的碳排放时，提示词工程就变得不可忽视了。对于大多数生成式人工智能模型(如GPT)来说，使用的计算资源和碳排放取决于传给模型和由模型生成的文本节点的数量。</p><p></p><p>虽然具体的细节取决于实际的实现，但提示词通常会被“一次性全部”传给模型。这可能会使计算量看起来不依赖于提示词的长度，但实际上，自注意力机制特点决定了优化会抑制未使用的输入部分，这意味着更短的提示词可以节省计算量，从而节省能源。</p><p></p><p>对于输出，很明显，计算成本与生成的文本节点数量成正比，因为模型需要为生成的每个节点“再运行”一次。</p><p></p><p>这可以从访问OpenAI GPT4 API的费用中看出来。在撰写本文时，GPT4基础模型的成本为0.03美元每千个提示词节点和0.06美元每千个样本节点。提示词长度和输出节点的长度都包含在价格中，说明了两者都会影响所需的计算量。</p><p></p><p>因此，更短的提示词和生成更短的输出将使用更少的计算量。人们为此提出了一种“绿色提示词工程”提议。MLOps平台为此提供了一些实验性支持，这让在持续评估碳排放和系统性能影响的同时进行缩短提示词的实验变得相对容易。</p><p></p><p>除了提示词，人们还提出了一些有趣的方法，通过更复杂的使用方式来改进大模型的效率，如这篇<a href=\"https://arxiv.org/abs/2305.18323?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw\">论文</a>\"所述。</p><p></p><p></p><h2>结论</h2><p></p><p></p><p>尽管人工智能的碳排放可能被夸大了，但仍然令人感到担忧，我们需要采取适当的措施来应对它们。提高透明度是支持有效决策和提高消费者意识的必要条件。此外，将碳排放指标集成到MLOps工作流中有助于在进行模型架构、规模、量化和绿色提示词工程时做出更明智的选择。本文的内容只是概述，只触及表面，对于那些真正想要做绿色生成式人工智能的人，可以关注<a href=\"https://arxiv.org/pdf/2209.00099.pdf?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw\">最新的研究</a>\"。</p><p></p><p></p><h3>脚注</h3><p></p><p></p><p>[1] <a href=\"https://www.technologyreview.com/2022/11/14/1063192/were-getting-a-better-idea-of-ais-true-carbon-footprint/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw\">\"We’re getting a better idea of AI’s true carbon footprint\" - by Melissa Heikkilä</a>\"[2] <a href=\"https://www.statista.com/statistics/1056469/co2-emissions-commercial-aviation-industry-globally-by-operation/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw\">Carbon dioxide emissions from the commercial aviation industry worldwide in 2019, by operation</a>\"</p><p></p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/carbon-emissions-generative-ai/\">https://www.infoq.com/articles/carbon-emissions-generative-ai/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/news/NuKxISZRb5sjg1lXgmeN\">AI 大模型背后的惊人数字：问 ChatGPT 5 个问题，耗水 500 毫升？训练一次 GPT-3，碳排放量相当于开车往返月球？</a>\"</p><p></p>",
    "publish_time": "2023-09-30 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "领导力视角下的复杂性与新兴趋势",
    "url": "https://www.infoq.cn/article/l96EdyzNTPXJZIOQR99T",
    "summary": "<p>关注实际的新兴组织和人们正在做的工作，可以在拥抱复杂性和更好地处理复杂性方面发挥作用。心理安全对于人们在不担心报复或负面后果的情况下提供反馈至关重要。Fred Hebert在纽约QCon 2023上谈到了拥抱复杂性。</p><p>&nbsp;</p><p>Fred Hebert在<a href=\"https://qconnewyork.com/\">纽约QCon 2023（QCon New York 2023）</a>\"上谈到了拥抱复杂性。</p><p>&nbsp;</p><p>Hebert认为，一个关键的假设是，组织架构的关键要素来自于所做的决策、权衡、目标冲突以及团队之间的日常互动。他解释道，当群体试图用自己对整体的不完整看法来实现个人目标时，组织会以一种动态且往往不协调的方式发生变化：</p><p>&nbsp;</p><p></p><blockquote>组织内部存在着各种意想不到的关系，并且依赖这些关系可以有效地使事情运转起来。试图根据理想化的组织架构图进行重组，可能只会消除推动现有新兴架构的极少数关键压力，而且这些压力还会一直存在。</blockquote><p></p><p>&nbsp;</p><p>Hebert说，每个组织都有自己的背景，并在一个略有不同的生态系统中发展，且动态各异。只要有合适的环境，几乎任何行为都可以成功一段时间。但Hebert补充道，大多数基于合作、更好沟通和互惠的行为似乎能以一种更可持续的方式表现得更好，尤其是在受到新环境挑战时。</p><p>&nbsp;</p><p>Hebert说到，在处理复杂问题时，心理安全至关重要。进入人们的决策过程的唯一方法是让他们能够报告他们认为具有挑战性、风险性、困难甚至容易的事情。Hebert提到，当人们可以在不担心报复或负面后果的情况下这样做时，就会发生这种情况。他说，向你提供反馈还取决于他们是否相信，提供这些信息会带来积极的结果，并采取行动，而不仅仅是相信不会发生坏事。</p><p>&nbsp;</p><p>Herbert说到，当某些事情发生时，你没有在现有的指标中看到反映，这表明事件和互动可能比你计划的更复杂，或者你的整个系统——可能是动态的、快速变化的——已经发生了变化。倾听这些小小的不和谐的感觉，并深入其中，他总结道。</p><p>&nbsp;</p><p>InfoQ采访了<a href=\"https://www.linkedin.com/in/fredth/\">Fred Hebert</a>\"，采访内容涉及如何处理心理安全并通过反馈循环来处理复杂性。</p><p>&nbsp;</p><p>InfoQ：我们能做些什么来增加心理安全和信任呢？</p><p>&nbsp;</p><p></p><blockquote>Fred Hebert：失去它们比获得它们容易得多。如果你处于这样的位置，那么无论何时做决策，维护它们都应该是你的首要任务之一。&nbsp;信任和安全是双向的；如果你想让人们更加信任你，你也要问问自己是否也信任他们。你如何将决策权委托给这些人？听听你从他们那里得到的信息。问问自己，当事情变得糟糕时，值得信赖的人应该得到什么样的支持，然后给他们提供这种支持。这些模式需要很长的时间才能建立起来，并且可能会融入你的组织架构及其层级结构中。&nbsp;你必须首先尊重人们和他们的努力，并理解他们的出发点。在改变工作之前，要认真考虑他们的处境——他们很可能和你一样已经考虑了很多，但我们都是在不同的环境中工作。很抱歉，我没有更好的秘诀了。</blockquote><p></p><p>&nbsp;</p><p>InfoQ：反馈循环是如何帮助处理复杂性的？</p><p>&nbsp;</p><p></p><blockquote>Hebert：更短的反馈周期意味着你可以更好地理解行动和变化对系统各部分的影响。有些行动必然是缓慢的——比如发现快速启动的新微服务间接阻碍了对现有服务的协作，因为这需要更多的时间——但许多其他有用的信号要直接得多，也更容易获得；它们只是需要我们的关注。&nbsp;我最喜欢的一个例子是，人们在寻找与他们试图调试的服务不同的服务的仪表板，因为有故障的服务的仪表板是不受信任的。这种行为有很多值得深入研究的地方！</blockquote><p></p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/08/embrace-complexity-emergence/\">https://www.infoq.com/news/2023/08/embrace-complexity-emergence/</a>\"</p>",
    "publish_time": "2023-09-30 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]