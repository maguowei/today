[
  {
    "title": "一站式数据库上云迁移、同步与集成平台 DTS 的设计实践",
    "url": "https://www.infoq.cn/article/W60k56xzqQFgzEvGOVeG",
    "summary": "<p></p><h2>一、数据库迁移面临的挑战</h2><p></p><p></p><p>根据大数据技术标准推进委员会今年 7 月发布的《数据库发展研究报告（2023 年）》，我们可以看到，去年国内的数据库市场规模约为 400 亿，今年预计可以达到 540 亿，预计到 2027 年，国内数据库市场规模可达 1280 亿。未来几年复合增长率预期可以达到 26% ，市场潜力非常大。</p><p></p><p>进一步看市场结构，我们可以发现一个明显的趋势：公有云在国内数据库市场中开始逐渐占据主导地位。近三年，国内公有云数据库市场规模的增速在 50% 左右，远高于本地部署市场的 15%。预计今年公有云数据库整体占比可达到 60%。</p><p></p><p>相较于本地部署的方式，公有云数据库通过全托管服务、云原生数据库等形态，在弹性、成本、易用性上更加具有优势。所以在过去十年，越来越多的企业客户选择数据库上云。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3d/3d6d97f6ade3ca5770a0aaf8cb7d0ed9.png\" /></p><p></p><p>数据库上云面临的技术挑战非常多，主要体现在以下四个方面：</p><p></p><p>第一，数据库上云的选型。企业需要考虑在云上数据库使用的引擎、选用单机还是分布式的架构、以及选用何种套餐，同时还要结合业务特点对数据库做针对性调优。如果遇到异构迁移或者跨版本迁移，还需要评估结构对象的兼容性，给出业务 SQL 的改造方案。</p><p></p><p>第二，云上迁移流程较长。</p><p></p><p>首先，我们需要打通云上云下的网络，把数据库的账号/角色、结构、存量、增量数据完整地搬迁上云。然后，对两端的数据一致性做校验。在一致性校验通过后，业务方把流量从云下割接到云上。最后，需要把云上数据库的增量写入内容反向同步回云下环境，以保留云下环境用于迁移后的灾备。</p><p></p><p>第三，迁移过程中的效率和容灾。迁移过程对业务的影响要尽可能少，迁移链路本身也应当具备容灾能力。</p><p></p><p>第四，迁移的数据一致性保障。数据库承接的往往是在线服务，少一条数据都可能给业务带来严重影响。因此，迁移链路自身要保证两端数据的最终一致性，同时也要提供校验工具用于检查确认两端实例的数据一致性。</p><p></p><p>百度智能云在多年的数据库上云迁移实践中积累了丰富的经验。我们认为，在数据库上云迁移中，平滑和可靠是客户的核心诉求，也是对迁移服务的必然要求。</p><p></p><p>平滑主要体现在易用性、兼容性和业务影响上。</p><p></p><p>易用性：迁移服务要开箱即用，能够托管迁移全流程。兼容性：能够兼容源和目标不同引擎、不同架构、不同版本和不同网络环境，尽可能地降低业务改造成本。业务影响：支持账号、结构、存量、增量的不停服迁移上云，将业务影响降到最小。</p><p></p><p>可靠主要体现在一致性、可回滚和高可用上。</p><p></p><p>一致性：保证源和目标的数据一致性，并提供校验能力。可回滚：支持割接后的反向回滚同步，保留云下环境用于灾备回滚。高可用：迁移和回滚链路要具备故障恢复能力，尤其是当上下游数据库发生主从切换后，迁移链路要具备自愈能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0d/0d0ab9d6458db6ad5ca32d004408d9c1.png\" /></p><p></p><p>在数据库上云后，我们看到客户在使用数据库时仍然有很多数据传输的新场景，其中有三个典型场景：</p><p></p><p>异地多活：当客户的服务部署在全球多个机房时，机房间的通信延迟最长可达秒级。如果数据库架构依然是单点写入，请求耗时就会变得非常高。但如果拆分数据库，则会牺牲数据的全局一致性，不满足业务需求。较为理想的架构应当是每个地域的数据库本地读写，然后通过数据同步工具同步至异地节点，最终实现数据全局一致。多云灾备：近几年来，基于服务可用性的考量，越来越多的客户选择多云部署。在生产云出现故障时，客户可以将流量切到灾备云上，以保证服务无损。数据库是有状态服务，因此需要数据同步工具将生产云的实时增量写入同步到灾备云上，以保证两端数据一致，满足灾备需求。数据集成：对用户行为的学习、分析和推理可以帮助企业快速决策，并进一步为用户提供个性化服务。通过数据集成工具，企业可以将数据从生产域实时准确地集成到分析域，从而实现数据深层价值的挖掘。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/99/998f41c889a3a701908cc51723f629ef.png\" /></p><p></p><p>基于上述的客户需求，百度智能云推出了一站式数据库上云迁移、同步与集成平台 DTS。</p><p></p><p>在上云迁移方向，<a href=\"https://www.infoq.cn/video/Vi9e7DGG3wBMVJQF3wBW?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">DTS</a>\" 基于百度多年实践总结出一套成熟的数据库上云迁移方案，围绕该方案提供一站式上云迁移体验。</p><p></p><p>在同步/集成方向，DTS 聚焦业务场景，基于场景需求的关键特性打磨产品，提供易用稳定的一站式同步/集成服务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f9/f9bfad0f6907f5ade3347eec251bb357.png\" /></p><p></p><p></p><h2>二、上云迁移方案</h2><p></p><p></p><p>数据库上云迁移是一个复杂的系统性工程，需要客户和云服务商共同配合完成。</p><p></p><p>我们将上云迁移分为三个阶段：迁移前、迁移中、迁移后。</p><p></p><p>迁移前的工作主要是做数据库选型和迁移可行性的评估。数据库选型的维度包括：产品、套餐、架构和存储介质等。选型的过程往往需要对相关的云上数据库产品做功能和性能测试以验证是否满足业务需求。迁移评估则是检查待执行迁移的源端和目标端数据库实例及其宿主和网络环境，得出迁移的可行性结论。在完成了迁移前的选型和评估工作后，就是数据库上云迁移过程。DTS 支持将源端的账号/角色、结构对象、存量数据、增量写入迁移至目标端，迁移过程中无需客户停服。在增量延迟追平后，DTS 支持对两端数据一致性做校验。通过一致性校验后，客户可以将业务流量割接到云上。在验证业务的同时，客户可以使用 DTS 的一键反向功能，快速拉起云上同步回云下的反向回滚链路，将云上的流量反向同步回云下，保留云下环境用于迁移后的灾备。数据库迁移到云上后，<a href=\"https://www.infoq.cn/article/SGPHdt4a0GyPUVyOotSm?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">百度智能云</a>\"也提供了<a href=\"https://xie.infoq.cn/article/28475b63dde77ae8aace1af29?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">数据库智能驾驶舱（DSC）</a>\"帮助客户管理、审计和调优云上数据库。</p><p></p><p>下方全景图中标蓝的步骤由 DTS 提供支持，我们可以简单总结为四步：评估、迁移、校验、回滚，下面我将详细介绍每个步骤的方案设计。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/be/becbd89b490e58c3acdeee360ae0d928.png\" /></p><p></p><p></p><h4>2.1&nbsp; &nbsp; 迁移评估与网络接入</h4><p></p><p></p><p>迁移前的第一个准备工作是迁移评估。</p><p></p><p>DTS 迁移任务在启动迁移前，会先执行前置检查，包括检查迁移对象、数据兼容性、两端数据库配置等，最终输出迁移可行性评估结论。对于不通过的检查项会给出修复建议。</p><p></p><p>此外，DTS 还提供了本地迁移评估工具，支持在本地环境执行，支持对多个实例执行批量评估。</p><p></p><p>迁移前的另一个准备工作是网络接入。</p><p></p><p>当前，DTS 支持通过公网、专线、VPN、云自建、云服务等方式接入，通过控制台或 OPENAPI 一键完成网络接入，无需人工部署。</p><p></p><p>此外，对于上云迁移高频依赖的专线或 VPN 接入，DTS 进一步优化了网络接入方式，支持客户将数据库内网域名作为任务端点，保证迁移链路具备切换自愈能力。当云下数据库实例发生主从切换时，只要实例域名保持不变，DTS 任务就可以快速自愈恢复。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8f/8ffcb367295511dea50186ace04e102d.png\" /></p><p></p><p></p><h4>2.2&nbsp; &nbsp; 数据迁移原理</h4><p></p><p></p><p>下面介绍 DTS 数据面的数据迁移原理。</p><p></p><p>数据面整体遵循 ETL 插件式设计，支持不同插件的自由组合，以满足不同数据流的迁移需求。</p><p></p><p>数据抽取（E）：通过不同的数据抽取插件，DTS 数据面可以支持采集账号/结构、全量、增量等数据。其中，全量数据抽取由于数据量较大，因此我们通过并发抽取、大表分片等优化手段进一步提升整体吞吐。增量数据则基于 CDC 异步捕获变更，可以让源端负载更少，同时传输实时性更好。性能的相关优化我们在后面会具体介绍。数据转化（T）：完成数据抽取后，源端的原始数据会被归一化为统一的抽象数据结构，这样就实现了异构数据源上下游解耦和端到端自由组合；然后再由数据转化插件对抽象数据结构做数据加工（如：库/表/行/列的过滤和映射）；最后再将数据格式改写为目标端数据源支持的协议。数据加载（L）：数据加载插件将完成协议转换的数据并行批量加载到目标端数据源中。为了进一步提升加载性能，数据面往往通过多线程并行加载数据。但增量同步需保证数据加载的时序与源端严格一致。因此，DTS 支持按表或主键粒度并行分发，属于同一个表或主键的数据会被分配到同一个加载线程串行执行，不同表或主键的数据则可能分配到不同线程上，在保证时序的前提下进一步提升了性能。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b3/b33b7c85d71aa44bdd070a94ceda3c4c.png\" /></p><p></p><p></p><h4>2.3&nbsp; &nbsp; 数据一致性校验</h4><p></p><p></p><p>整体的数据迁移流程遵循先结构、再全量、后增量的顺序。</p><p></p><p>考虑到各类数据库中的 CDC 日志通常是易失的，如：MySQL 的 binlog、MongoDB 的 oplog、Redis 的 backlog 等。数据库往往通过固定缓冲区、定时或限制容量清理等方式限制 CDC 日志的存储用量。</p><p></p><p>DTS 针对该问题优化了迁移流程编排。在进入全量迁移过程后，DTS 除了导出和加载全量数据外，还同时导出增量数据，将其缓存到 DTS 的内部存储中，以避免尚未迁移的增量数据被源端数据库清理。待进入增量迁移阶段后，再将缓存的增量数据加载到目标端。</p><p></p><p>增量同步延迟追平后，即可执行数据校验检查两端数据一致性。由于 DTS 增量同步是异步加载，因此源端和目标端的数据版本实际上存在毫秒级的延迟。因此数据校验可能会因为同步延迟出现误报。我们引入了 X Round Recheck 的方案进一步降低了误报概率。在后面的内容里会专门介绍数据校验的原理。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b2/b27c290770883a240527852a41e692be.png\" /></p><p></p><p>DTS 以数据不丢为基础，进一步实现了数据的不丢不重，以保障数据的一致性。</p><p></p><p>数据不丢（At-Least-Once）：依赖于 DTS 数据面的低水位进度管理机制。如下图所示，每一条数据都会关联一个单调递增的版本号，这些版本号组成了一个单调递增的进度序列。当某条数据写入下游并收到了确认写入成功的响应后，该数据对应的版本号会被标记并在进度序列中更新状态。此时，进度管理线程会检查进度序列的水位。</p><p></p><p>在下图中 1、2、3、4 都已经被标记，但 5 尚未标记，因此版本号 4 是低水位里的最大版本号。所以将 4 作为最新进度保存到外部存储中。一旦此时任务容灾恢复，恢复后的任务将以外部存储中记录的最新进度 4 作为断点重新执行迁移。</p><p></p><p>At-Least-Once 机制可以保证数据不丢，但无法保证数据不重。我们在下图中可以看到，6、7 此时都已写入下游，但并未记录到最新进度中，一旦任务以 4 作为断点重新执行，则 6、7 对应的数据会重复迁移。</p><p></p><p>为了实现数据不丢不重（Exactly-Once），DTS 的思路是基于目标端数据库特性去重。对于关系型/文档数据库、数仓来说，表中主键列或唯一键列具有唯一性，因此，我们可以改造 SQL。利用唯一约束实现幂等写入。</p><p></p><p>而对于 Schema-less 的消息队列、分布式文件系统等，DTS 会在投递的消息中加入 UUID，目标端消费方可以基于 UUID 自行去重。</p><p></p><p>最后对于键值数据库（如 Redis），DTS 的思路是将不满足幂等写入的命令改写为满足幂等性，比如累加、累减、插入队列等改为覆盖写。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bc/bc31ca309acf6adbab7374c6ecc0f593.png\" /></p><p></p><p>除了迁移系统本身的一致性保证外，DTS 还提供了独立于迁移系统的数据校验功能。数据校验与数据迁移由不同的任务独立执行，以保证校验结果的可信。</p><p></p><p>数据校验的流程可以拆解为：抽取、转化和校验。</p><p></p><p>其中，抽取与转化的实现原理与数据迁移的对应模块实现类似，这里不再赘述。下面重点介绍一下数据校验插件的原理。</p><p></p><p>首先，校验插件在收到待校验数据后会根据主键或唯一键实时查询源端和目标端最新的数据。然后，根据数据加工规则对源端和目标端的数据做归一化，对齐数据元信息。最后，根据不同的任务配置，比对规则校验数据一致性，并将校验结果保存到外部存储中。</p><p></p><p>这套流程在实践中存在小概率误报，原因是在执行数据校验的同时，源端还在持续写入。因此，源端与目标端的数据版本会存在毫秒级的同步延迟，正是这一延迟导致了少量数据的校验误报。</p><p></p><p>因此，DTS 引入了 X Round Recheck 机制。在数据不一致时，会等待一段时间后进入下一轮比对，重新读源端和目标端的数据后再次比对。只有当多次重复比对均不一致的数据会被记录为不一致数据上报。</p><p></p><p>X Round Recheck 大大降低了数据校验的误报频率。经测试，校验误报频率从约千分之一下降到小于百万分之一。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a0/a0c5e65544c682c90c921ee21696f29e.png\" /></p><p></p><p></p><h4>2.4&nbsp; &nbsp; 反向回滚</h4><p></p><p></p><p>在完成数据一致性校验后，客户就可以把流量割接到云上了。</p><p></p><p>完成切流后，我们观察到客户往往需要保留云下环境用于容灾回滚。当云上生产环境不可用时，可以将流量快速切回云下灾备环境，服务快速恢复。针对这一痛点，DTS 推出了一键反向功能，支持在流量割接后快速拉起反向回滚任务，将云上流量反向同步回云下。</p><p></p><p>如下图所示，客户在 T1 时刻执行流量割接，此时正向迁移任务运行中，而反向回滚任务处于挂起状态。在 T2 时刻，客户完成割接，此时业务流量已切到目标端数据库，此时执行一键反向，DTS 会将正向迁移任务挂起，反向回滚任务启动，从客户指定的 T1 时刻开始将目标端的业务写入实时同步回源端。从而完成正向迁移到反向回滚的切换。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b3/b36fcc5a27470d0d1987df2f43d4cfae.png\" /></p><p></p><p></p><h2>三、同步/集成方案设计</h2><p></p><p></p><p>我们在前面介绍了同步/集成方向的三个典型业务场景：异地多活、多云灾备和数据集成。其中，高可用和高性能是这些场景共同需要的关键能力。</p><p></p><p>异地多活和多云灾备属于在线数据库的实时同步需求。因此支持数据库多主架构和数据一致性的有保证/可校验能力是同步场景的核心痛点。数据集成场景的痛点在于，传统的集成方式中，流批架构不统一、不同数据源使用的集成工具比较繁杂，ELT + ODS 的数据预处理方案实时性差/复杂度高等。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ca/ca50070612eff19bdbb3383b49c373f2.png\" /></p><p></p><p></p><h4>3.1&nbsp; &nbsp;&nbsp;DTS 的高可用和高性能</h4><p></p><p></p><p>接下来，我们分别介绍 DTS 针对上述痛点的方案设计。</p><p></p><p>首先介绍高可用能力。</p><p></p><p>DTS 的高可用设计目标是满足长期不间断的生产级数据同步需求。方案设计可分为三个方面：断点续传、实时容灾和数据库切换自愈。</p><p></p><p>断点续传。DTS 会将传输进度做定期 checkpoint 并持久化到外部存储中。目前 DTS 大部分数据流的全量和增量迁移都支持断点续传。同时，DTS 基于之前介绍的低水位进度管理机制，可以保证断点续传前后数据不丢失，基于目标端的唯一约束可以实现数据不丢不重。实时容灾。DTS 数据面模块支持故障秒级接管和恢复。并且支持对极端脑裂场景的自动检测和恢复，保证脑裂恢复前后的数据最终一致性。切换自愈。DTS&nbsp;支持在源端、目标端数据库实例发生故障切换时，自动发现新的可用节点。当不同节点的传输位点发生变化时，DTS 可以基于时间自动定位新节点的传输位点，保证切换后数据不丢。</p><p></p><p>经过百度智能云内外部数据传输场景的长期实践打磨，DTS 承诺的任务可用性为 4 个 9。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/70/702ab336cc15fa05036c699b186247ae.png\" /></p><p></p><p>接下来让我们再看高性能。DTS 在性能方向的设计目标是追求高吞吐和低延迟。</p><p></p><p>首先是高吞吐，DTS 具有如下的特点：</p><p></p><p>DTS 支持预读取全量数据。当遇到大表时，DTS 支持将大表分片并行读取，解决大表长尾的问题。DTS 支持按照表、主键粒度并行转换和回放。DTS 对数据回放的单线程写入性能做了优化。比如当写入 1000 条数据时， DTS 将 1000 条 INSERT 合并为一条 INSERT，提升了目标端数据库的 SQL 写入效率。写入语句批量执行，网络延迟均摊。</p><p></p><p>其次是低延迟，DTS 提供了如下的能力：</p><p></p><p>DTS 自身基于 CDC 实现增量数据捕获，无需扫表，实时性更好。DTS 采用了数据流式传输模型，全程流水线作业。DTS 选用消息队列缓存和回放增量数据，端到端的同步延迟更低。DTS 针对热点数据，支持基于逻辑的事务合并。在保证最终一致性的前提下，压缩了同步的数据量。</p><p></p><p>以 MySQL 同步为例，全量吞吐峰值约为 20W 行/s，增量吞吐峰值约为 1W 行/s，延迟可以达到毫秒级别。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e8/e8765256df2e3f29e51c56a51c9165ef.png\" /></p><p></p><p></p><h4>3.2 &nbsp;&nbsp;异地多活场景</h4><p></p><p></p><p>异地多活场景的核心特性是双向同步，可以支持两端数据库写入相互同步，从而实现数据库多主架构。</p><p></p><p>双向同步由正向和反向两个 DTS 同步任务实现，每个任务在同步数据时会通过加入特定的 DML 将该数据所在的事务染色；而另一方向的同步任务在读到染色事务时会直接过滤，从而避免了数据的同步回环。此外，双向同步支持级联，客户可以通过搭建多条双向同步链路实现 N 个地域的数据库多主架构。</p><p></p><p>不过双向同步的使用也有一定限制：</p><p></p><p>业务需避免在两端同时变更主键/唯一键相同的行记录，尤其是避免同时执行 UPDATE，否则可能产生冲突，造成数据不一致。因此，我们推荐业务层面支持流量单元化。表中不能使用自增主键，这是为了避免主键冲突导致的数据不一致。仅有正向同步任务支持同步 DDL，反向同步任务仅同步 DML，因此若需执行 DDL 建议在正向同步任务的源端执行。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d3/d321d9451ff5a40360143c3d278be810.png\" /></p><p></p><p></p><h4>3.3&nbsp; &nbsp;数据集成场景</h4><p></p><p></p><p>经典的 Lambda 架构包含定时和实时两套架构，分别处理流和批两种不同的数据。架构不统一会带来运维迭代成本高、流批产出数据不一致等问题，所以现在业界都在逐渐转向流批一体。</p><p></p><p>DTS 的架构天然支持流批一体，源端无论是有界数据（数据库快照，指定区间的增量）还是无界数据（持续的数据库流量），都会通过数据切片的方式切分为无数个 Micro-Slice，通过流水线作业最终同步到目标端的仓、湖或流式计算框架。</p><p></p><p>目前 DTS 目标端支持 Doris、Elasticsearch 等数仓，以及百度智能云数据湖 EDAP，支持通过消息队列将数据推送到 Flink 等流式计算框架中。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e5/e5b0dd52a21c254741c04835648a0817.png\" /></p><p></p><p>在面对上下游异构数据源时，解耦上下游的架构设计能够为系统提供更高的灵活性和可扩展性。这种设计使得 DTS 能够支持端到端的任意组合，组合复杂度从 M*N 降低到 M+N，并能够快速扩展支持新的数据源。</p><p></p><p>DTS 定义了抽象数据格式 DTS Record，可以将源端各类数据库的数据转换为标准的 DTS Record（Any To One），然后再将 DTS Record 转换为目标端数据源接受的数据格式（One To Any）。</p><p></p><p>当 DTS 需要接入新的数据源时，只需要定义新数据源到 DTS Record 的转换规则，即可快速支持现有全部数据源到新数据源的异构数据传输。</p><p></p><p>当然，在异构字段映射的过程中，部分数据可能会因为浮点数精度/字符集不同造成数据精度损失。因此，DTS 优化了同构字段映射规则。当上下游数据源同构时，源端数据能够无损映射到目标端。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ac/ac26b104b1e719ebc98991747eb8865b.png\" /></p><p></p><p>接下来我们看下数据集成的预处理环节。</p><p></p><p>当前业界的主流集成架构是 ELT+ODS。即将数据通过 Sqoop、Spark 等工具，几乎不做 join 或 group 等复杂转化，直接抽取到数据仓库里的贴源层（ODS），再在数据仓库中通过 SQL/H-SQL，将数据从贴源层（ODS）加载到数据明细层（DWD），最终汇总到数据汇总层（DWS）和数据集市（DM）。</p><p></p><p>ELT+ODS 架构的思路是利用数仓的 MPP 高性能计算做 ODS 到 DWD 的大数据预处理。但这仅适用于数据源模式比较简单的情况。当 ODS 到 DWD 规范化复杂度比较高时，往往需要引入 Spark/MapReduce 等框架专门处理。</p><p></p><p>另外，ELT+ODS 架构的实时性较差，难以满足实时分析场景和即时查询的需求。ODS 与 DWD 的数据重复率也比较高，需要付出额外的存储成本。</p><p></p><p>DTS 基于业界最新提出的 EtLT 架构推出了支持实时数据加工的集成方案。它可以将数据从在线域直接集成到 DWD，在集成阶段即可完成实时的数据规范化，无需维护额外的 ODS 层。EtLT 架构的实时性要优于 ELT+ODS 架构，可以支持实时的数据分析和查询统计，让复杂的数据抽取、规范化和加载的过程对数据分析过程透明，帮助其更加聚焦业务。</p><p></p><p>DTS 支持实时数据加工的集成方案预计会在 2024 H1 开放公测，大家可以期待一下。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3b/3bfb46f6ff54c44e7d6fac3968914c71.png\" /></p><p></p><p></p><h2>四、DTS 落地实践案例</h2><p></p><p></p><p>第一个案例是某国内大型在线视频服务公司，DTS 支持了该客户的数据库上云迁移和多活同步的需求。</p><p></p><p>该客户的业务痛点主要包括三个方面：</p><p></p><p>迁移规模大：在线服务数据库（MySQL/Redis/MongoDB）中，涉及到上百条业务线的 1.5W+ 集群迁移上云，过程管理难度大。高可用需求高：需要支持数据库不停服迁移、支持切换自愈、支持反向回滚、支持监控指标推送。异地多活：需要支持跨地域多活同步（单元化）、低延迟（&lt;100ms）。</p><p></p><p>针对该客户的三个痛点，百度智能云提供了如下的解决方案：</p><p></p><p>客户业务使用自助上云平台完成上云迁移：平台集成 DTS 服务。DTS 迁移全流程（评估、迁移、校验、回滚）100% 接口化（支持控制台操作），无人工干预。客户 IDC 自建实例切换自愈：DTS 支持专线/ VPN 域名接入，数据库故障切换断点自愈恢复。跨地域多活同步：DTS 支持 MySQL/GaiaDB 双向同步。</p><p></p><p>最终，百度智能云帮助该客户跑通了数据库上云迁移的全流程，并支持客户自助上云迁移，目前已经支持 2000+ 集群的迁移，单集群的迁移周期缩短到 3-4 天。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b2/b25063cab42fe1fd84350a9f48abb3a5.png\" /></p><p></p><p>第二个案例是某国有控股大型商业银行，DTS 支持了行方的实时数据分析和跨机房容灾的需求。</p><p>该客户的业务痛点主要包括两个方面：</p><p></p><p>高吞吐：行方核心业务（存/取款明细）涉及到 64 分片集群每月集中跑批， TPS 峰值达到 50W+，要求数据同步延迟分钟级。高可用：数据库及生态产品（DTS）整体具备跨机房容灾能力，故障恢复要求为 RPO = 0，RTO &lt; 1min。</p><p></p><p>针对该客户的这两个痛点，百度智能云提供了如下的解决方案：</p><p></p><p>端到端吞吐优化：CDC 异步拉取/并行解析，表/主键粒度并行转换/加载，数据打包写入。跨机房容灾：基于 load checkpoint 的段点续传（RPO）和数据库拖段服务切换自愈（RTO）实现了任务实时容灾恢复。</p><p></p><p>最终，百度智能云帮助该行落地了实时风控、监控大屏、收支分析等业务场景，线上长期同步任务 900+；同时，支撑行方核心业务（存/取款明细）集群数据同步需求，同步延迟秒级。此外，DTS 服务支持同城双活，机房级故障恢复实现了&nbsp;RPO = 0，RTO &lt; 30s。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/93/932f451df069b833f97ea0e57ed87be8.png\" /></p><p></p><p>第三个案例是某国内大语言模型服务，DTS 支持了业务方的事实数据分析和检索的需求。</p><p></p><p>该客户的业务痛点主要包括两个方面：</p><p></p><p>同步性能：包括大语言模型对话数据、模型 Trace日志实时分析等，部分业务场景要求数据同步延迟达到秒级。快速迭代：&nbsp;大语言模型功能迭代速度快，在线数据库表结构更新较为频繁。</p><p></p><p>针对该客户的这两个痛点，百度智能云提供了如下的解决方案：</p><p></p><p>低延迟调优：自适应写入性能调优，数据打包窗口动态调整。整库同步：DTS 支持库级别同步，目标端 Doris 支持增量同步 DDL，支持增量阶段新增/删除同步对象。数据规范化：支持库表行列过滤、库表列名映射等功能。</p><p></p><p>百度智能云支撑了该大语言模型中服务日志实时分析与实时报表的需求，同时也满足了业务快速迭代带来的整库同步、表结构更新同步等需求，最终实现了长期同步任务 470+，同步延迟最低达到秒级的业务效果。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/59/59c5196f7db586c10a37ac61eb6bd84e.png\" /></p><p></p><p>我们对 DTS 的所能支持的各类业务需求归纳为 8 种典型的场景，供大家参考。分别是：不停服迁移上云、异地多活、多云灾备、业务事件驱动、信创迁移、缓存更新、实时分析、实时入湖/仓。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a7/a7dd5d322f241190f6c9e591ed7a1e75.png\" /></p><p></p><p>最后，我们对今天的分享做个总结，我们分享了百度智能云在数据库上云迁移和数据同步/集成方向的设计思路和落地实践。</p><p></p><p>在上云迁移部分，百度智能云提供了平滑可靠的一站式上云迁移服务。</p><p></p><p>迁移服务开箱即用，支持评估、迁移、校验、回滚的全流程托管。兼容源和目标不同引擎、架构、版本和网络环境，业务改造成本低。上云迁移无需停服，业务影响小，迁移和回滚链路支持端到端的故障恢复</p><p></p><p>在同步/集成部分，DTS 可以提供易用稳定的数据同步/集成服务：</p><p></p><p>在异地多活场景中，基于 DTS 双向同步可以支持数据库多主架构，实现全球化服务访问加速，保证数据全局一致。在多云灾备场景中，DTS 支持数据库跨云长期同步，支持端到端容灾自愈，数据一致性有保证可校验。在数据集成场景中，DTS 立足流批一体设计，支持端到端的自由组合，可以实现秒级实时同步，未来计划支持实时数据加工。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5d/5d4ec5fc7ab0f57eb95a01f2e0a38f7e.png\" /></p><p></p>",
    "publish_time": "2023-12-13 09:51:09",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "银行如何以“价值链视角，数字化手段”思考规划落实中央金融工作会议精神",
    "url": "https://www.infoq.cn/article/T7cUzo9pjuiXXVsdSRjc",
    "summary": "<p>中央金融工作会议精神思想深邃、立意高远，需要整体把握、综合实践，因此也需要以整体视角进行学习理解、规划落实，本文拟尝试在之前文章的学习基础上，运用价值链视角，结合数字化转型进行落实层面的分析，供从业者借鉴，不当之处，请多指正。</p><p></p><h3>一、 分析工具介绍</h3><p></p><p></p><p>价值链视角是一种整体分析视角，从企业价值创过程出发，对企业能力的分布和关系进行研究，有利于企业做“一盘棋”式的战略规划设计。该方法在国内银行业过去十年的数字化转型实践中，多次被运用在整体设计和实施指导上，经过了实践检验和国内创新，在实现总体概念的统一、传导方面，具有良好效果，笔者在《银行数字化转型》一书、《说透数字化转型》课程中也充分运用了该工具进行数字化规划分析和解释。对于学习改革目标如此之深、之广的中央金融工作会议精神、对于落实“八个坚持”、做好银行的“五篇大文章”很有运用价值。</p><p></p><p>笔者在《银行数字化转型》一书提出的数字化银行价值链如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1a/1a444b936c092f0e0cbcd1a1f64f3e3b.jpeg\" /></p><p></p><p>该价值链涵盖了<a href=\"https://www.infoq.cn/article/BpAYeYkzIHtJaPlHC5TR\">银行</a>\"内部数字化改革和外部数字化支持，本文将在该价值链的基础上，以中央金融工作会议精神为指引、结合数字化手段的提升作用对其进行演进分析。</p><p></p><h3>二、 从“八个坚持”的视角看银行价值链的重塑</h3><p></p><p></p><p>（一）坚持党中央对金融工作的集中统一领导。落实在各家银行身上，首先是要充分学习党的理论，对党员开展深入的党性教育，只有充分理解了“中国特色金融发展之路”，保持金融队伍的“纯洁性”，才能将党中央对金融工作的集中统一领导深入落实到各个业务品类、各个业务环节上。因此，应当首先在“决策管理”环节加入对“中国特色金融发展之路”的研究，将“八个坚持”、“战略管理”能力体现在这一环节中，并在“组织与人力”环节加入“党性教育”。</p><p></p><p>（二）坚持以人民为中心的价值取向，坚持把金融服务实体经济作为根本宗旨。这两点在原有的价值链设计中已经有所体现，该价值链是以客户为中心、由与客户的沟通交流驱动的金融服务交付过程，客户在金融产品的设计和实施中具有明显的“中心性”，以客户为中心也自然会做到以服务实体经济为根本宗旨。</p><p></p><p>此外，这一点还体现在“环境研究”环节中，“环境研究”中包括的“整体研究”、“亚群体研究”正是对完整客户群和分类客户群的研究，银行以往在金融服务过程中，对客户份额争抢的关注大于对客户群体的深入研究，以人民为中心的价值取向应该是关注人民需要的金融服务，而不是过度的份额竞争，事实上，对于诉求的分析本身是有利于扩大市场的，但是竞争的同质化、客户群体的高度重叠，使竞争手段日趋白热化、简单化，客户画像等手段的引入虽然提升了银行的客群经营能力，但是市场压力还是难以让银行有充分的时间考虑服务质量和内涵的提升。</p><p></p><p>真正做到以人民为中心的价值取向不仅银行自身要调整，市场竞争秩序也需要规范和调整，以支持银行的服务动作不会“变形”。原有价值链中的客户洞察、产品改进是体现“以人民为中心的价值取向”中的重点环节，也是数字化手段提升银行服务能力的重点领域，银行现有的数字化能力在产品设计和产品实施方面是有一定成绩的，但是还很难做到将以“智慧交流”为核心的客户触达和服务能力大幅度提升，毕竟客户群体太大，技术也有待完善。在“客户洞察”环节需要补充的是“客群规划”能力，要结合会议精神和今后的各类改革要求不断灵活调整客群定义的能力，没有客群的灵活定义，也很难统计改革的落实情况；在“产品改进”环节中增加“综合演进”，能够将客户对金融服务的意见分客群、分产品进行汇总，综合改进，持续跟踪，以使银行更加了解、更深分析人民需要的金融产品。</p><p></p><p>（三）坚持把防控风险作为金融工作的永恒主题。站在银行的视角，风控可以分为企业级和产品级两层，前者是站在银行整体视角衡量总体风险分布、衡量单个客户综合所有业务之后的总体风险水平，后者则是站在单个客户单笔业务、单个产品的视角衡量相对微观的风险，产品级风险防控会贯穿在单次业务办理过程的始终，而企业级风险则时刻从总量视角为单笔业务的办理做好总体控制，这是银行风险管理的基本要求。</p><p></p><p>在风控业务中，数字化的加持主要在于风控模型的运用，外部风险信息的及时获取，整体风险水平的及时、动态测算，以及对压力测试的持续模拟等。根据中央金融工作会议精神以及之前的各项政策要求，风控模型的有效运用和适度修订是必然要考虑的问题，在企业级风控中，修订客群的风险评价模型，灵活调控客户准入规则；在产品级风控中增加对政策要求向风控参数的转化能力，灵活调控产品准入、单次准入规则；通过总量测算控制总体风险水平。在面向中小微客户时，风控模型可以考虑宽准入、控规模、容多头的原则，以扩大普惠群体，但根据银行体量控制好单户规模，通过多头方式提升信贷资源面向单个客户的供给总量，并保持风险分散。但是这种操作方式的实现，需要行业信用体系的良好运转、信息便捷共享，也需要更多来自外部核心企业提供的供应链平台信息，只有企业的运作信息、信用信息公开透明易获得，才能推动风控工作总体水平的提升。</p><p></p><p>因此，风控工作需要在银行价值链的外部环节中提供更大支持，推动数据要素的共享、交易，通过数据流动改善风控环境。中小金融机构的改革也是降低银行整体风险水平、提升风险应对能力的重要部分，大型银行是主力军、压仓石，但是中小银行的问题也必须关注。</p><p></p><p>（四）坚持在市场化法治化轨道上推进金融创新发展。这一点在近年数据保护工作的推动中表现非常明显，个人信息保护相关法律的实施也让银行的经营行为、科技开发工作出现了调整，数据要素相关法律未来会深刻影响银行业务，所以，对于法律的宣贯应在银行价值链中有明显的一席之地，在“组织与人力”中增加“法律教育”，并将对法律的理解运用到完整的客户服务过程中。</p><p></p><p>（五）坚持深化金融供给侧结构性改革。银行必须紧跟政策脚步、紧跟环境变化，及时动态调整经营策略、调整产品供给、调整服务能力，这需要银行始终对自身能力、自身结构“洞若观火”，只有了解自己的结构，才能制定合理的调整方案，才能将业务变化快速、准确地传导给技术侧，实现业务和系统、实体和数字的联合变动。</p><p></p><p>供给侧的结构性改革，需要结构化的分析能力、结构化的实现能力，结构化思维，也就是系统思维是数字时代的基本思维方式，是业务侧和技术侧共同需要掌握的思维模式、沟通方式，也是数字时代必须要补充的管理思维，企业架构正是系统思维的具体实现方式之一，也是国内银行业之前数字化转型过程中多有采用的一种工程思维，它已经过了国内实践的脱胎换骨，可以从技术思维变成业务思维、管理思维了，这也是笔者之前就在数字化银行价值链中植入企业架构能力的原因，企业架构能力不仅体现在“产品设计”环节，更是整个银行数字化转型方法论设计和落实的基础，是为“一盘棋”准备的理想实施工具，从方法论融合和演进角度看，在“基础研究”环节还应加入“知识管理”，为金融理论、管理理论、架构理论的探索与发展留有空间。</p><p></p><p>（六）坚持统筹金融开放和安全。这一点需要监管层面多提供行为指导，在商业银行层面，更多涉及的是金融环境研究和全面风险管理，在“环境研究”和“企业级风控”中需要适当做些内容调整。</p><p></p><p>（七）坚持稳中求进工作总基调。这一点体现在价值链重塑的整体设计和落地推进过程需要结合银行自身情况、深入领会会议精神、稳扎稳打逐步推进，不在排除风险的过程中又增添额外风险，数字化本身也是有风险的，对此，监管机构也曾要求将数字化风险纳入全风体系进行管理。</p><p></p><h3>三、从“五篇大文章”的视角看银行价值链的重塑</h3><p></p><p></p><p>（一）科技金融。科技金融对于大多数银行而言，其知识壁垒、风投特性是从事该项业务较为困难之处，科技金融中涉及到科创类企业的，银行往往难以做出合适的评估，加之该类企业对长期股权类资金的需求也很强烈，所以，也有供需不匹配的情况出现。</p><p></p><p>对此，银行从事该类业务，首先在“客户洞察”环节必须有相适应的科技企业评估模型，这方面大型银行有些探索，中小银行结合当地特色产业也有一定的探索，但是来自行业的基础性评估模型的总结、提升仍有待加强，行业指引也需要具有更加丰富、详实、视角更宽的数据信息，而银行自己则需要专注于某些赛道，长期培养相对专业的客户经理、风险经理，在“环境研究”环节需要有自己专注的行业研究，这就决定了银行开展科技金融业务需要一定的“错位部署”，尤其是对中小银行而言，只能结合当地特点开展特定领域的研究。对于大型银行而言，则应思考利用一级分行的区位优势，分开部署，对于有交叉的领域，建立一级分行的业务小圈子，“一行一策”有特点地做。对于一些特殊性国家重点领域，则应展开跨行合作，联合进行。</p><p></p><p>（二）绿色金融。绿色金融业务具有广阔的业务前景，从最新公布的数据看，大型银行的绿色金融业务也达到了一定的规模，但是其进一步发展仍然有一些问题需要解决，比如统一的行业标准和管理要求，面向客户和银行两端的法律法规、配套政策、约束激励机制等，都需要持续完善，绿色金融是长期性金融业务，很难基于现有的业绩考核标准推广，在价值衡量上需要有统一的行业指引并落实到银行内部，“价值核算”环节应突出“更有政策导向的业务核算”能力。</p><p></p><p>（三）普惠金融。普惠业务是一篇范围足够大的文章，而且是典型的“长尾业务”，也正因为如此，它也是世界级难题。随着大型银行在普惠市场中的下沉服务，这一领域的金融供给在逐步增加，普惠业务也成为全行业关注的焦点领域。</p><p></p><p>1、在客户洞察环节，上文提到要“宽准入、控规模、容多头”，也就是准入要放宽，不然不足以体现普惠，但是单户的业务量要适度控制，并且鼓励多头业务，以保证供给、分散风险，这就要求客户洞察阶段的客户画像要完善、更新要及时，所以，外部数据的供给对普惠业务是非常重要的，仅凭银行自身的数据，难以及时响应普惠金融的业务需求。行业内的信息共享也应适当考虑，普惠业务可能需要的是客户共享而非客户竞争。</p><p></p><p>2、在产品设计环节，即针对普惠客户提供金融产品时，由于普惠客户的特点，往往在产品设计上强调对担保形式的灵活处置，但除了担保之外，定价也是产品设计中的一个重点，定价方面除了传统的银行内部资金转移价格加风险加成的定价外，可以再考虑一种转移定价方式，也即将大型企业客户身上获取的收益转移到降低普惠产品价格方面，这并非单纯的“让利”，而是具有一定的“转移支付”功能。这种操作方式在中小银行和大型银行的一级分行层面具有一定的可尝试性，采用这种计算方式的优点在于，有利于量“入”为“出”，以“转移价格”衡量基础性的让利空间，更有利于相对“安全”的分配普惠让利任务；普惠业务本身仍可以按照名义价格和让后价格核算，原始业务成效和让利工作都可以清楚统计；对于让利空间不足的地区，总行可以基于总账核算层面通过总盘子给予支持，能够体现总行的工作成果，也能够让总行对地区间的不平衡状况、普惠工作带来的时间性改变有更清楚的了解。</p><p></p><p>但这种方式的执行也有一个需要支持的点，这一点可能在思考如何逆转“二八定律”去做好“普惠金融”时需要进行一定的探讨，也就是银行如何能够对大型客户取回一定的话语权，站在商业银行经营的视角，资金安全、业务量大的大型客户是“兵家必争之地”，但是银行对大型客户的话语权很低，往往定价不高，好在体量大，具有一定回报，但是服务大型客户也低效地消耗了一定的金融资源，而这些大型客户常常也是“不差钱”的，所以，从行业视角规范大型客户的服务秩序，制定合理的行业限价，降低对大型客户的竞争性服务程度，可能是银行能够更“安全”、更大范围、投入更多资源开展普惠业务的一个辅助性条件。从大型企业客户身上转移的“价格”也可以作为大型企业客户的社会责任加以“记账”，从而形成新的客户评价机制，补充到“客户洞察”环节，可以提升客户的社会价值。</p><p></p><p>此外，中小银行在进行普惠业务时也会存在资金不足、资金成本过高的问题，那么，站在同业业务的视角，可以在银行间市场中建立更明确的普惠规则、普惠板块，符合普惠条件的同业业务，由需求方挂牌，供给方选择进行低价资金供应，成交的业务可以折价记入供给方的普惠业务指标统计，毕竟资金最终是用到了普惠业务上。在上述空间以外需要继续投入的普惠支持，可能也需要银行开拓更多的资金来源进行供给了。以上几点思考都是与价格相关的，需要银行自身探索，也需要更强大的行业力量予以支持和研究。</p><p></p><p>3、在产品设计环节还要增强企业级的架构设计。普惠业务面向的多是人员少、时间紧的中小微企业，所以金融产品设计应更加简洁，但这种简洁需要产品设计的抽象能力，并且，并非业务简洁涉及的数字化系统就会少，实际上表面上的简洁很多时候是系统有效地“负重”了，所以，普惠产品的发展也很需要架构理念的支持，做好业务抽象，管理好客户体验，充分调动现有系统的数字化能力，提供综合性服务。</p><p></p><p>4、加强连接。做普惠金融也不仅仅是一户一户“啃”的零碎业务，也需要通过商业生态连接来加强对行业动态的充分了解，考虑到数字化转型的深入，如何将银行的数字化与客户的数字化结合，并将商业联系转化为数字联系，这是时代命题，而非单纯的发展意愿问题。</p><p></p><p>（四）养老金融。养老金融不仅有之前银行都在做的“适老化”改造，这主要体现在客户洞察和产品设计环节，尊重老年人的习惯是文明的体现。此外，养老金融逐渐已经发展到了存款、基金、理财、财富管理、支付等诸多领域，引导合理的理财观念逐渐成为养老金融的一大话题。养老金融形成的资金来源具有一定的长期性特征，对于银行而言，可以成为一些长期标的的资金源，但是养老金融业务的广泛开展也是需要跨行业信息获取和跨行业场景融入的，这些能力诉求体现在“产品设计”、“产品实施”、“生态管理”等环节中。</p><p></p><p>（五）数字金融。按照笔者之前文章介绍的<a href=\"https://www.infoq.cn/article/ROrh4hSJPu1UkXzx5Uhc\">对数字金融的两层含义</a>\"的理解，数字金融是涉及到银行价值链所有环节的，毕竟金融产品的交付形态大多都已经转化成了数字形态，对客户的理解、对产品的设计、对风险的防控、对价值的衡量、对未来方向的把握，都离不开对数字化的理解和实践，数字化是银行高质量发展的必由之路，笔者以前的文章大多是谈数字化转型的，所以在此只介绍几个重点：</p><p></p><p>1、对技术方向的关注。银行虽然不是纯粹的科技企业，但是技术的发展对银行的影响却毋庸置疑，尤其是渠道端，随着人工智能技术的发展，渠道正在从最近十年的移动端向体验更好、能力更强的智能渠道加速发展，渠道变革带来的影响绝不能忽视，它会深刻改变银行的业务形态，就像从柜台到手机一样，业务模式、系统布局都进行了大幅度调整。</p><p></p><p>2、对服务能力的关注。无论是普惠金融还是养老金融，都需要更强大、更广泛的具有“一对一”体验的“一对多”服务能力，无论是移动端、远程银行还是任何可以打破空间限制提供大范围服务能力的技术都值得关注。</p><p></p><p>3、对数据能力的关注。数字化的核心还是对数据要素的挖掘，无论做了多少系统，数据的价值发挥不出来，系统就只是个记录系统而已，留下了业务痕迹，但是没有发挥出更大的数据价值，无法向今天所谈的数字化方向靠拢。但是发挥出数据价值是需要人的能力和系统能力互相配合的，所以，面向数字的基础技能，比如结构化思维等，是银行必须要增加的从业人员技能，没有结构化思维，就很难理解数字化，也很难有效定义、采集、运用、评估数据资产。</p><p></p><p>（六）补充调整。之前的文章讨论也曾提到，做好这“五篇大文章”需要银行进行价值取向的调整，而这必然涉及到考核方式的变化，金融行业当前的任务是做优做强，金融理论要突出政治性、人民性，考核体系的设计也应思考从经营 KPI 的设置转向社会责任性 KPI 的设置，规模、盈利还是不是首当其冲的考核要求，如果要适度调整银行的逐利性，则必须从行业引导开始，价值导向、秩序导向、风险控制都需要超越行业级别的指引，否则银行在商业博弈环境中很难自动转向；有大级别的指引，也需在银行内部考核上落实指标转向，银行可以借此机会思考如何从激烈的同业竞争中适度解脱出来，将资源更多用于服务而非市场争夺。</p><p></p><h3>四、对银行价值链重塑的归纳总结</h3><p></p><p></p><p>面对<a href=\"https://www.infoq.cn/theme/212\">新的金融发展方向</a>\"，重塑银行价值链是一定要思考的问题，对以上讨论进行归纳总结后，数字化银行的价值链可以做如下演变：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/68/68b401679f077eab18de146d963dffc2.jpeg\" /></p><p>上述分析仅是基于价值链工具，融合数字化手段之后，对中央金融工作会议精神进行学习的尝试，在实际操作中，为了便于价值链分析结果更有利于落地，通常会对价值链进行压缩，调整成一维的价值链，比如可以按照如下方式压缩：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/81/819fb62b1dbfcacc9f49ce5b7bef09e7.jpeg\" /></p><p></p><p>再将提炼的能力重新归置，然后结合业务领域的定义进行能力布局分析，比如将“五篇大文章”作为行，将价值链各环节作为列，行列交叉后形成分析棋盘，将能力进行对比分析，识别公用和非公用能力，就能够成为落实“五篇大文章”所需要的能力结构分析，最后转化到系统实现上，成为落实会议精神、体现业技融合的全局性大文章。这些已经属于企业架构的应用范畴了，本文仅是借用这个工具来加强对中央金融工作会议精神的学习。</p><p></p><p>2024 年可能是各银行充分学习领会中央金融工作会议精神、思考“中国特色金融发展之路”指引下的商业银行发展方向、行为模式的内省之年，多运用系统思维、架构方法，深入地、结构化地学透、贯彻会议精神，是新年工作的重中之重，开门红应该红在哪里，也是需要思考的。</p><p></p><h4>作者介绍</h4><p></p><p>付晓岩，《企业级业务架构设计：方法论与实践》、《银行数字化转型》和《聚合架构：面向数字生态的构件化企业架构》三书作者。北京天润聚粮咨询服务有限公司执行董事总经理，数孪模型科技公司高级副总裁；工业和信息化重点领域数字化转型与人工智能产业人才基地专家委员会副主任；中国计算机学会软件工程专委会委员；信通院企业架构推进中心、组装式推进中心技术专家；中华全国数字化人才培育联盟专家委员会特聘专家；工信部中小企业发展促进中心产教融合产业实践教授；国家工程实验室金融大数据应用与安全研究中心研究员；CIC 金融科技与数字经济发展专家委员会成员；国家互联网数据中心产业技术创新战略联盟专家委员会副主任专家委员。</p><p></p><p></p><h4>内容推荐</h4><p></p><p>11 月 19 日 -20 日在上海成功举办的首届 FCon 全球金融科技大会，以「科技 + 金融，激发创新力量」为主题，汇聚了来自金融龙头企业的数百名技术高管，掀起一场探讨新时代金融科技未来的高潮。经征得大会分享嘉宾同意，InfoQ 数字化经纬为您奉上精彩演讲 PPT！关注「InfoQ 数字化经纬」，回复「金融创新」即可获取 PPT，深度洞悉科技趋势，助您引领金融创新未来！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/af/afc55058ba66a0cd61acf97f02db59a1.png\" /></p><p></p>",
    "publish_time": "2023-12-13 09:54:08",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "云原生数据库 GaiaDB 架构设计解析：高性能、多级高可用",
    "url": "https://www.infoq.cn/article/0cwP1eTkEzaaUxxs8Doz",
    "summary": "<p><a href=\"https://www.infoq.cn/article/SGPHdt4a0GyPUVyOotSm?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">百度智能云</a>\"团队在今年 11-12 月特别推出了四期《百度智能云数据库》系列云智公开课，为大家全面地介绍了以云原生数据库 GaiaDB 和分布式数据库<a href=\"https://www.infoq.cn/article/2VG5NR6sg8QFttMMyQw5?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\"> GaiaDB-X</a>\" 为代表的百度智能云数据库系列产品。</p><p></p><p>在《百度智能云数据库》系列云智公开课的第二期内容中，百度智能云数据库高级架构师邱学达为我们介绍了云原生数据库的不同技术路线及能力对比，并对比传统单体数据库介绍了云原生数据库的技术差异和挑战，同时深入浅出地解析了 GaiaDB 在高性能和多级高可用方向上的技术架构。</p><p></p><p>下文为他的演讲内容整理：&nbsp; &nbsp;&nbsp;</p><p></p><h2>云原生数据库和 GaiaDB</h2><p></p><p></p><p>目前，<a href=\"https://xie.infoq.cn/article/be269a4dac007392339e5f63b?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">云原生数据库</a>\"已经被各行各业大规模投入到实际生产中，最终的目标都是「单机 + 分布式一体化」。但在演进路线上，当前主要有两个略有不同的路径。</p><p></p><p>一种是各大公有云厂商选择的优先保证上云兼容性的路线。它基于存算分离架构，对传统数据库进行改造，典型产品有 AWS Aurora、阿里云 PolarDB、腾讯云 TDSQL-C、百度智能云 GaiaDB。</p><p></p><p>数据库作为公有云上的核心基础设施，第一要务是实现用户上云的平滑性。目前像云网络、云主机，云盘都实现了完全透明兼容。云原生数据库也必须实现从语法、使用习惯、再到生态上的全面兼容。因此，基于现有生态做分布式化改造成为了一条首选的演进路线。使用存算分离路线的云原生数据库可以完美兼容传统的使用习惯，为交易类场景提供低延迟的写事务能力，同时读扩展性与存储扩展性借助了分布式存储的池化能力，也得到了很大增强。</p><p></p><p>另外一种路径是先搭建一套分布式框架，然后在其中填充数据库逻辑。OceanBase 和 TiDB 就是其中两个比较典型的产品。它们将事务的子系统和锁的子系统拆分为单独的模块。计算层通过与这些模块交互，可让多个节点均支持写请求。然后由统一的新事务 + 锁中心节点来进行仲裁。这样，对需要较多计算资源的写负载场景会有较好的提升。由于事务和锁都需要跨网络进行交互，因此事务延迟相对较高，在锁负载较重的情况下会成为一定的瓶颈。</p><p></p><p>目前这两个路线并不是泾渭分明，独立发展的，大家都在向着统一的目标演进。因此我们可以看到，存算分离路线在逐渐增强 SQL 的多级并行能力，同时也在探索和支持多个写节点的库表级 / 行级的多写能力。同时分布式事务路线也在积极探索在小数据规模下的单机部署架构。</p><p></p><p>所以在未来，这两个路线会不断融合。业务的数据规模不管多大，都可以平稳快速地运行在数据库系统上，而不需要用户去过分关注分区、索引、事务模型等信息。就像十年前如何在机器之间存储海量小文件还是一个后端研发工程师的必修课，而随着 S3 存储的出现，用户再也不需要考虑如何通过哈希等方式来保证单个文件夹不会保存太多文件一样。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/49/494bca1fca9378e1fa0da766c469e03a.png\" /></p><p></p><p>GaiaDB 是从百度智能云多年数据库研发经验积累中逐渐迭代而来。GaiaDB 于 2020 年发布首个版本，首次实现了基于存算分离的大容量存储和快速弹性能力，解决了百度内部的历史库、归档库等大容量存储需求。</p><p></p><p>紧接着，为了满足集团内大部分核心业务的跨地域热活准入门槛和就近读性能需求，GaiaDB 于 2021 年发布了地域级热活功能。跨地域热活仍然使用存储层同步的方案，同步延迟与吞吐都相较逻辑同步有很大提升，从地域可以实现与主地域接近相同的同步能力，不会成为拖慢整体系统的短板，也不会像逻辑同步那样在大事务等场景下出现延迟飙升的问题。</p><p></p><p>所以 2.0 版本上线后，GaiaDB 逐渐接入了手百、贴吧、文库等多个核心产品线，解决了业务在跨地域场景下的延迟与性能痛点。</p><p></p><p>随着业务的逐渐上云，多可用区高可用的需求慢慢凸显，如何实现单机房故障不影响服务成为了很多业务上云的关注点。为此 GaiaDB 打造了可支持跨可用区热活的 3.0 版本，每个可用区都可以实时提供服务并且不增加额外的存储成本。而在今年， GaiaDB 推出了更加智能化的 4.0 架构，性能进一步提升，功能完整度也在持续完成覆盖。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/72/729c24394d30b36427010d70f44034d2.png\" /></p><p></p><p>接下来整体介绍一下 GaiaDB。目前 GaiaDB 已经实现了线上全行业场景覆盖，最大实例达到了数百 TB，不仅兼容开源生态，还实现了 RPO=0 的高可靠能力。在成本方面，由于在架构设计上采用了融合的技术理念，GaiaDB 不依赖特殊硬件和网络环境也可以保证性能，实现云上云下一套架构。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8d/8d33cdaf891b3d0f762e21079e50e16c.png\" /></p><p></p><p></p><h2>GaiaDB 的高性能 &amp; 多级高可用设计</h2><p></p><p></p><p>接下来我来分享一下 GaiaDB 的性能核心设计理念——通过融合和裁剪，将数据库和分布式存储进行深度融合，为全链路的同步转异步化提供条件，从而实现极致的性能与通用性。</p><p></p><p>我们可以看到，如果数据库简单使用通用分布式协议和单机存储引擎，如左图所示，那么数据库需要处理主从同步，需要有 CrashSafe 所需要的物理日志。同时，一致性协议也要有主从同步，要写自己的 WAL 以及持久化快照。而单机引擎同样需要 CrashSafe 以及一套日志系统和数据存储逻辑。</p><p></p><p>我们发现，多层日志的嵌套带来了层层延迟与写放大。更复杂的是，数据流中嵌套多层逻辑后，也给系统整体数据安全带来了一定挑战。同时由于多层之间需要串行等待，所以在加入了网络延迟后会给数据库带来很大的性能下降。虽然可以使用定制化硬件与网络来缩短网络和磁盘落盘的延迟以降低链路耗时，但这又引入了新的不确定性并导致了更高的成本。</p><p></p><p>GaiaDB 的解决思路是将事务和主从同步逻辑、日志逻辑、快照和存储持久化逻辑重新组合和排布。</p><p></p><p>首先是将分布式协议的主从同步逻辑融合进数据库计算节点中。由于计算层本身就需要处理主从同步、事务和一致性问题，相关的工作量增加并不大。这样一来，最直接的收益就是将两跳网络和 I/O 精简为一跳，直接降低了链路延迟。</p><p></p><p>其次 GaiaDB 将多层增量日志统一改为使用数据库 Redo 物理日志，由 &nbsp;LogService 日志服务统一负责其可用性与可靠性。</p><p></p><p>除此之外，GaiaDB 也将持久化、快照和数据库回放功能融合入存储节点。由于存储层支持了数据库回放能力，可以很轻松实现数据页级别的 MVCC。这样全链路只剩下了数据库语义，数据流简单可靠，逻辑大大简化。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/86/868f47ab0c9ef26160ad0bb62bc6da58.png\" /></p><p></p><p>下面我们一起来看下共识模型上的改变。</p><p></p><p>像 Raft 协议是需要两跳网络才能实现一次提交确认的，右上角就是 Raft 的数据流架构：CN 节点将写发送给 Leader 后，需要等待 Leader 发送给 Follower 并至少收到一个返回后才能成功。</p><p></p><p>这里就带来了两跳网络和 I/O 的同步等待问题。而 GaiaDB 则是计算节点直接发送给多个 Log 服务并等待多数派返回，这样不依赖任何特殊硬件与网络就降低了延迟。这样系统里不管是事务的一致性还是多副本一致性，统一由计算节点统筹维护，所有的增量日志也统一为数据库物理日志，整体数据流简单可控。</p><p></p><p>对于数据风险最高的 Crash Recovery 场景，由于统一使用了数据库语义，整体流程更加健壮，数据可靠性更高，降低了数据在多种日志逻辑之间转换和同步带来的复杂度风险。而在性能方面，由于存储层自身具备回放能力，可以充分利用 LogService 层的日志缓存能力。对于写操作来说，不需要每次更改都刷盘，可以批次回放刷盘，大大节省了磁盘吞吐与 I/O。</p><p></p><p>经过以上改造，线上吞吐性能可以提升 40% 。同时由于链路简化，也大大优化了长尾延迟。像之前计算节点与分布式主节点之间发生网络抖动的场景，就会被多数派的返回特性来优化。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/88/880c11b4c3596b9934ec882ae9281276.png\" /></p><p></p><p>分享完一致性协议层优化，接下来我们来探讨一下链路层优化。</p><p></p><p>我们知道，总吞吐与并发度成正比，与延迟成反比。一致性协议层改造并缩短了数据链路，可以通过降低延迟来增加吞吐。那么有没有办法通过提升数据流的并发度来提升吞吐呢？答案是可以。由于数据库的物理日志自带版本号与数据长度，所以不需要像通用存储一样实现块级别串行提交。之所以使用通用存储需要串行提交，是因为存储端只能根据请求到达的先后确定数据版本，如果乱序到达，最后生效的版本是不可知的。</p><p></p><p>而对于 GaiaDB 来说，由于 LogService 具备数据库语义的识别功能，所以计算节点只需要异步进行写入，日志服务就会自动根据数据版本选取最新数据，然后根据写入情况批量返回成功，这样链路就可以实现延迟与吞吐的解耦。</p><p></p><p>当然计算层依然会等待日志层批量返回的最新落盘版本后再返回事务提交成功，所以依然可以满足提交成功的事务一致性、持久化的要求。</p><p></p><p>另外针对高负载下 I/O 请求与数据库业务请求争抢 CPU 的问题，我们使用了 I/O 线程隔离技术，通过资源隔离的方式，将 I/O 线程与数据库业务线程进行隔离。这样即使在复杂负载场景下，I/O 延迟仍可以保持在较低水平。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dc/dc00033498ca3707091d9bbfb5dadcbc.png\" /></p><p></p><p>在分析完前面两部分之后，可能会有同学有疑问：既然日志层到存储层不是同步写，是不是最终系统的一致性降低了？有没有可能发生数据丢失或不一致的问题呢？答案是不会。因为 GaiaDB 的存储是一套支持 MVCC 的多版本系统。所以即使回放实现上是异步，但是由于请求方会提供所需要的数据版本，存储层可以提供对应版本的强一致数据视图。</p><p></p><p>GaiaDB 的存储节点支持数据页的回放功能，可以动态回放至任意目标版本后再返回，在之前的版本里，假如由于异步的因素还没有获取到这部分增量日志，存储节点也会启用优先拉取的策略实时拉取一次日志后再回放，以此来提供较好的时效性。而在最新的 GaiaDB 版本中，我们也在计算层添加了同样的回放能力，存储节点尽力回放后仍不满足需求的，由计算节点进行剩余任务。</p><p></p><p>这样对于存储慢节点的兼容能力就大大增强了，同时由于存储节点会尽力回放，所以也可以最大化利用存储层的算力资源。对于刷脏逻辑目前也完全下沉到了存储层，存储节点可以自主控制刷盘策略和时机，尽量合并多次写后再进行落盘，大大节省了磁盘 I/O 负载，平均 I/O 延迟降低了 50%。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a5/a5fdd7d1fa003f9f635a729ca00a5f72.png\" /></p><p></p><p>下图中我们可以看到，在综合了多项优化后，读写性能实现了最高 89% 的提升，其中写链路线路提升尤其明显。这些都是在使用普通存储介质和网络环境的情况下测试得出的，主要得益于数据链路的缩短与同步转异步的自适应高吞吐能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9e/9eb5e4d3c677acd21e5b83096f16ceb3.png\" /></p><p></p><p>在讨论完性能后，再分享一下 GaiaDB 在高可用方面的思考和设计理念。</p><p></p><p>数据库作为底层数据存储环节，其可用性与可靠性直接影响系统整体。而线上情况是复杂多变的，机房里时时刻刻都可能有异常情况发生，小到单路电源故障，大到机房级网络异常，无时无刻不在给数据造成可用性隐患。</p><p></p><p>作为商业数据库，具备多级高可用能力是最核心的必备能力。这样才能抵御不同级别的异常情况，有力保障客户业务的平稳运行。GaiaDB 支持多副本、跨可用区、跨地域三级别高可用，创新性地实现了多可用区热活高可用、单个实例支持跨可用区部署。在不增加成本的情况下，每个可用区均可提供在线服务，任何可用区故障都不会打破存储一致性。下面我们来分别看一下每个级别高可用能力的实现。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d1/d1f9701867ba0e5edfacb8cc3d4de9be.png\" /></p><p></p><p>首先是实例的多副本高可用能力。</p><p></p><p>GaiaDB 对整体的分布式架构进行了重新设计，系统共分为三层，即计算层、日志层、存储层。其中计算层本身无状态，仅负责事务处理与一致性维护，所以获得了很强的弹性能力，实现了秒级切换、多节点容灾，同时扩缩容只需要内存启动即可。</p><p></p><p>日志层负责系统增量日志部分的持久化，实现了多数派高可用。同时由于一致性协调角色上移到了计算层，所以该层全对称，任意节点故障不需要进行等待选主，也不会有重新选主带来的风暴和业务中断问题。</p><p></p><p>再往下是存储层，负责数据页本身持久化与更新。由于上层保留了增量日志，所以存储层可以容忍 n-1 副本故障。简单来说就是只要有一个副本完好，加上上层提供的增量日志，即可回放出所有版本的完整数据，实现了相比传统多数派协议更高的可靠性能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/38/38691a2f2817476cc4e38ca54e83b504.png\" /></p><p></p><p>其次是跨可用区与跨地域的高可用能力。</p><p></p><p>GaiaDB 的多级高可用都是基于存储层物理日志的直接复制。相比逻辑复制，数据链路大大缩短，同步延迟也不再受上层大事务或者 DDL 等操作影响，在主从同步延迟上具有很大优势。</p><p></p><p>对于跨可用区高可用来说，由于 GaiaDB 具有对称部署架构，所以可以很方便地进行跨可用区部署。这样可以在不增加存储成本的情况下实现多可用区热活，任一可用区故障都不影响数据可靠性。</p><p></p><p>写数据流可以自适应只跨一跳最短的机房间网络，不需要担心分布式主节点不在同机房带来的两跳跨机房网络和跨远端机房问题，而读依然是就近读取，提供与单机房部署接近的延迟体验。由于跨机房传输的网络环境更为复杂，GaiaDB 添加了数据流的链式自校验机制，使数据错误可以主动被发现，保障了复杂网络环境下的数据可靠性。</p><p></p><p>对于跨地域高可用来说，由于同样使用了异步并行加速的物理同步，及时在长距离传输上，吞吐依然可以追齐主集群，不会成为吞吐瓶颈，在计入网络延迟的情况下，国内可以实现数十毫秒的同步延迟，这是因为跨地域同样可以使用异步并行写加速，自动适应延迟和吞吐之间的关系。同时地域之间还可以实现主动快速切换和默认就近读取。</p><p></p><p>所以在使用了 GaiaDB 的情况下，业务可以不做复杂的数据同步逻辑就可以实现低成本的跨可用区与跨地域高可用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bb/bb38aea27c6a8d0956fe7232108ba038.png\" /></p><p></p><p>介绍完高性能和高可用两部分的设计理念后，接下来再介绍一下我们正在内部灰度中的新功能：</p><p></p><p>并行查询：并行查询从并发度上进行加速的并行查询能力，这对大数据规模下的多行查询有非常好的加速作用，可以充分利用计算节点的 CPU 和内存资源和分布式存储层的并行 I/O 能力。分析型从库（HTAP）：分析型从库具备多种行列加速能力，既有支持百 TB 级别数据计算的分析型节点解决方案，也有支持百万行以上检索加速的列式索引引擎。其中列式索引引擎同样采用物理日志同步，不需要业务维护数据一致性，可以和当前交易类负载的事务隔离级别兼容。Serverless：我们也在探索充分利用内部潮汐算力的资源优化调度方案，在白天业务高峰期，将资源向实时性更强的交易类业务倾斜，在低峰期自动缩容，将资源复用投入到离线计算类业务中，不但客户节省了运维成本与资源成本，也避免了资源闲置和浪费，实现了更高的资源利用率。</p><p></p><p>以上功能预计都会在近期开放灰度试用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ad/ad6014a894d8b5543a024011f1729a80.png\" /></p><p></p><p></p><h2>写在最后</h2><p></p><p></p><p>自 11 月 15 日起，百度智能云团队每周三都会上线一节《百度智能云数据库》系列云智公开课。在前 4 期的课程中，专家们围绕“从互联网到云计算再到 AI 原生，百度智能云数据库的演进”、“高性能和多级高可用，云原生数据库 GaiaDB 架构设计解析”、“面向金融场景的 GaiaDB-X 分布式数据库应用实践”、“一站式数据库上云迁移、同步与集成平台 DTS 的设计和实践”四个主题展开了分享。</p><p></p><p>每节直播课的视频我们都进行了录制留存，都整理进了课程专题页中，课程持续更新中，大家立即点击<a href=\"https://www.infoq.cn/theme/222\">【此处链接】</a>\"进行观看吧~</p>",
    "publish_time": "2023-12-13 10:08:09",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "英伟达成为人工智能公司主要投资者：条件是必须使用英伟达产品",
    "url": "https://www.infoq.cn/article/3QgC2C2JQghLz4RZBNgi",
    "summary": "<p>据英国《<a href=\"https://www.ft.com/content/25337df3-5b98-4dd1-b7a9-035dcc130d6a\">金融时报》</a>\"报道，英伟达今年已投资了“二十多家”公司，包括从价值数十亿美元的大型新人工智能平台到将人工智能应用于医疗保健或能源等行业的小型初创企业。</p><p>&nbsp;</p><p>根据跟踪风险投资机构 Dealroom 的估计，英伟达在 2023 年参与了 35 笔交易，几乎是去年的六倍。Dealroom 表示，这是英伟达人工智能领域交易最活跃的一年，超过了 Andreessen Horowitz 和红杉等硅谷大型风险投资公司（不包括 Y Combinator 等小型加速器基金）。</p><p>&nbsp;</p><p>英伟达专门风险投资部门 NVentures 的负责人Mohamed Siddeek 表示：“总体而言，对于 Nvidia 来说，（进行初创企业投资）的首要标准是相关性。”&nbsp;Siddeek 解释道，“使用我们的技术、依赖我们的技术、在我们的技术上建立业务的公司……我无法想象我们会投资一家不使用 Nvidia 产品的公司。”</p><p>&nbsp;</p><p>据报道，英伟达的总体投资组合包括OpenAI的两大竞争对手Inflection AI和Cohere。这些公司还是英伟达的现有客户，只要公司继续成长和发展，对双方来说都会是一件好事。</p><p>&nbsp;</p><p>英伟达的另一项投资是<a href=\"https://www.infoq.cn/article/SjiWBCDHGt6kClScsea3\">Mistral</a>\"，这是一家总部位于巴黎的人工智能初创企业，本月早些时候获得了20亿欧元的估值。另外两个是Hugging Face和CoreWeave，它们都是Nvidia GPU芯片或软件的用户。</p><p>&nbsp;</p><p>对于“接受投资的人也得到了优惠条件”的说法，Siddeek回应称，“我们不帮助任何人插队。”他反驳道，在任何投资中都有使用英伟达产品的条件，但他补充说，“我们会尽量对投资者友好。”</p><p>&nbsp;</p><p>据悉，英伟达的H100 GPU芯片最近已经成为硅谷最受欢迎的产品之一。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.ft.com/content/25337df3-5b98-4dd1-b7a9-035dcc130d6a\">https://www.ft.com/content/25337df3-5b98-4dd1-b7a9-035dcc130d6a</a>\"</p><p><a href=\"https://readwrite.com/nvidia-emerges-as-leading-investor-in-ai-companies/\">https://readwrite.com/nvidia-emerges-as-leading-investor-in-ai-companies/</a>\"</p>",
    "publish_time": "2023-12-13 10:25:02",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Amazon CodeWhisperer 审查：最新的 AI 代码伴侣",
    "url": "https://www.infoq.cn/article/O6qHtFBMoJUubbIz4MQw",
    "summary": "<p>亚马逊云科技推出了一项机器学习支持的服务，该服务通过根据开发人员在自然语言中的评论和他们在集成开发环境中的代码生成代码建议来帮助提高开发人员的工作效率。这项名为 Amazon CodeWhisprer&nbsp;可以免费使用。类似于微软去年推出的 GitHub copilot 。</p><p></p><p>在过去的几个月里，我有机会在几个用例中试验了这项服务。作为一名机器学习 (ML) 开发人员，我拥有利用 ML 帮助开发 ML 解决方案的优势。因此，我在访问此服务后写了一些观察。此外，我正在就如何使其更智能和更易于访问提供具体建议。</p><p></p><h3>服务在行动</h3><p></p><p></p><p>该服务根据代码编辑器中的注释和同一文档中的先前代码提供实时代码建议。该服务可以建议行完成或完整的代码块（例如，方法）。</p><p></p><p>在 Visual Studio 上，有一些方便的快捷方式使服务的使用更加方便。启用扩展后，该服务提供类似于许多 IDE 支持的自动完成功能的在线推理。但是，用户可以点击 (Alt+C) 来查看推荐，而无需等待响应。</p><p>下面是编写著名的二分查找方法的示例</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5e/5ea7bd321d5d437dfc35e93aef2cda5e.gif\" /></p><p></p><p>有趣的是，该服务可能会建议多个代码片段，这些代码片段可以轻松导航（使用左/右箭头）以选择最合适的推荐。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0f/0ff3b91a7fc8eb544b37d8bdd2561445.gif\" /></p><p></p><p>Amazon CodeWhisprer 就像是试图用正确的代码在您耳边耳语的伴侣。因此，它是一个非常花哨和超级描述性的名字。在命名服务方面做得很好。</p><p></p><h3>深入探讨，如何充分利用服务？</h3><p></p><p></p><p>AI 代码伴侣是一个强大的工具，可以提高开发人员的工作效率。尽管有人认为这样的工具将来可能会取代开发人员，但现在下结论还为时过早，因为该服务与任何其他服务一样：Garbage in Garbage out。也就是说，它在很大程度上取决于返回良好结果所需的输入。以下是输入质量如何完全影响输出质量的示例。</p><p></p><p>在这里，提供的描述很模糊，没有明确的要求，所以在等待比较长的时间后，输出是混乱的导入。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/81/8132b89afb69d7bd19c44e5f4461be29.gif\" /></p><p></p><p>随着输入描述变得更加清晰，输出变得更好，如下所示，这是一个类似但更清晰的问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4f/4f9282e5205bbfa610f5937b056dd1eb.gif\" /></p><p></p><p>此外，随着用户添加更多上下文，即开发人员编写更多代码，推荐的质量显着提高。例如，与在同一文档上的孤立任务或在项目早期上下文仍然不够的情况下相比，在处理一个项目时预计会获得更快和更个性化的结果。</p><p></p><p>尽管如此，该服务预计不会为臭名昭著的自定义任务返回有用的答案。下面是一个同样的二分查找问题的例子，但对输入格式做了些许修改。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e6/e6736d478974f6d7cc3c0b76adf32c33.gif\" /></p><p></p><p>显然，引擎无法理解对问题的轻微修改（即，允许重复的元素）并且仍然产生与前面建议的相同的代码。</p><p></p><h3>服务能不能更好？</h3><p></p><p></p><p>由于该服务仍处于预览阶段，预计会遇到许多不足。以下是可以使服务变得更好的精选操作列表。</p><p></p><h3>推理速度：</h3><p></p><p></p><p>正如在上面的示例中可能指出的那样，该服务需要花费大量时间来提出建议。我相信这方面还有很大的改进空间。</p><p></p><h3>一致性和实时性：</h3><p></p><p></p><p>该服务有望在开发人员编写代码时提供实时建议。但是，实时建议可能不会在特定时刻给出任何输出。令人惊讶的是，按下 (Alt+C) 快捷键会返回可行的解决方案，而无需更改任何内容（即同时即时）。</p><p></p><h3>最终用户定制：</h3><p></p><p></p><p>引擎盖下的推荐引擎使用了一个巨大的代码库，这些代码库来自许多为不同目的而编写的源代码。为某些项目接受的源启用更多自定义是合理的。</p><p></p><p>此外，根据项目主题预测代码可能是有益的。例如，机器学习开发与开发移动应用程序完全不同。</p><p></p><p>作为另一个示例，用户可能想要处理需要设计和聚合的多个代码块的项目。在其他项目中，可能需要优先考虑线路完成而不是阻止建议。</p><p></p><p>自定义示例列表非常庞大，需要仔细设计。</p><p></p><h3>解决方案排名：</h3><p></p><p></p><p>建议多种解决方案是一个很棒的功能。然而，在实践中，这些解决方案的排名并不是最优的，用户需要浏览所有解决方案才能找到正确的建议。这可能很乏味，并且会降低整体生产力。</p><p></p><h3>问题定制：</h3><p></p><p></p><p>该引擎有效地理解了训练语料库中发现的常见问题。然而，它更难适应同一问题的新挑战。</p><p></p><h3>结论</h3><p></p><p></p><p>总而言之，Amazon CodeWhisprer（以及一般的 AI 代码伴侣）毕竟不是可以解决所有问题的魔法。但是，它是一个很好的工具，可以通过专注于正确的问题而不是繁琐的重复性任务来提高开发人员的工作效率。</p><p></p><p>为了充分利用 Amazon CodeWhisprer（以及一般的 AI 代码伴侣），以下操作可能有助于实现预期目标：</p><p></p><p>简明评论：输入任务越清晰明确，获得优质结果的概率就越高。统一项目：人工智能引擎从整个文档中收集信息。因此，它不断丰富上下文。因此，将它用于以某种方式具有连接的任务会更有益。避免高级自定义问题：问题越不受欢迎，它不会返回任何有用答案的可能性就越高。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5e/5ea7bd321d5d437dfc35e93aef2cda5e.gif\" /></p><p></p>",
    "publish_time": "2023-12-13 10:36:40",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "夯实基础 赋能转型，天翼云为北京数字经济发展增添新动能！",
    "url": "https://www.infoq.cn/article/FqegrOMsw3338gZcYOiK",
    "summary": "<p>2023 年 12 月 12 日，以“云启新境，智赋未来”为主题的天翼云中国行·北京站活动在北京圆满举行，会上中国信息通信研究院和天翼云科技有限公司联合发布央国企上云白皮书，为推动政府企事业单位上云用云制定标准，为各单位生产方式、业务形态、商业模式的数字化创新转型持续助力。国务院国有资产监督管理委员会信息中心副主任陈忠平，北京市经济和信息化局党组成员、副局长王磊，天翼云科技有限公司党委书记、董事长、总经理胡志强，中国电信北京公司党委书记、总经理寇凤达等领导以及客户、合作伙伴等企业代表共同出席活动。</p><p></p><p>北京市经济和信息化局党组成员、副局长王磊在致辞中表示，今年是全面贯彻落实党的二十大精神的开局之年，北京市正加速以高质量发展为主题，以供给侧结构性改革为主线，以科技创新为引擎，统筹发展和安全，促进数字技术与实体经济深度融合。希望中国电信北京公司继续依托中国电信集团和天翼云公司技术优势，始终坚持以客户为中心、以创新为驱动，积极推进云网融合和算网一体工作，为北京市的数字经济发展和信息化建设做出突出贡献。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/39/39e4b6cb29692d3c84c792ccb6ec2ec4.jpeg\" /></p><p></p><p>作为数字中国建设主力军、云服务国家队，天翼云多年来立足北京、深耕北京，以科技创新助推北京市数字经济高质量发展。天翼云科技有限公司党委书记、董事长、总经理胡志强在致辞中表示，天翼云作为一家总部位于北京的云服务商，目前已形成立足北京、辐射全国的战略格局。天翼云正在不懈努力，充分发挥自身技术优势和资源优势，充分发挥云计算对数字经济发展的赋能作用，助力北京加速建设全球数字经济标杆城市。展望未来，天翼云将继续秉持“云网融合、安全可信、绿色低碳、生态开放”的国家云发展理念，积极响应北京市政府号召，发挥央企责任担当，进一步优化资源配置，加大研发投入，吸纳优质人才，不断探索创新，携手北京市广大客户和合作伙伴，凝心聚力，共拓数字经济新商机，共探产数发展新课题，共谋行业发展新蓝图。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/05/05da2b27e3d4aeefbb7a565a4b935786.jpeg\" /></p><p></p><p>中国电信北京公司党委书记、总经理寇凤达在致辞中表示，中国电信北京公司在集团公司健全完善的全国云网一体通用算力、智能算力布局的指导下，在天翼云科技有限公司卓有成效的自主创新成果的加持下，不断加强北京地区算力布局与建设，厚植服务数字经济发展的沃土。目前，中国电信北京公司建成并运营了 24 个数据中心，拥有超过 50 万核的云计算资源，资源规模和份额处于领先地位，服务首都各行业2000 余家客户。今年以来，中国电信北京公司大力推进北京市人工智能公共算力平台建设，北京市人工智能公共算力平台永丰节点和“中国电信京津冀智能算力中心”一期先后首批点亮，正在持续打造超大规模，总计超 10000P 的智算中心和京内“1ms”、京津冀“3ms”的低时延、大带宽、高可靠算力网络，为北京市数字经济建设不断贡献电信力量。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ab/ab942686d4099f5f2f03a1aac1677015.jpeg\" /></p><p></p><p>会上，天翼云科技有限公司云网产品事业部总经理杨鑫，围绕天翼云自主可控的国云底座以及面向AI+HPC 构建的天翼云智算超算能力产品与技术展开分享。天翼云以自研云操作系统为核心，从底层基础软硬件技术，到上层高阶云能力，形成了技术领先、自主可控的“云网边端数智安”全栈云技术体系。通过基础设施、算力平台、算力调度和生态服务全面升级，为用户提供 IaaS+PaaS+MaaS+SaaS 一体化服务，赋能千行百业数字化转型，服务数字经济高质量发展。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/73/73a554ffc760644a78eab3096fad57a9.jpeg\" /></p><p></p><p>中国电信北京公司云中台部副总经理王宇介绍了中国电信北京公司在云计算、算力基础设施建设情况，深入介绍在数字政府、工业、卫健、教育、文宣和金融等行业领域的实践和案例，致力于构建云网融合、安全可信的云和算力体系，助力北京打造全球数字经济标杆城市。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/98/98d9d170e35cb6a558d5a81674be9682.jpeg\" /></p><p></p><p>大唐电信技术信息部主管李峥深入介绍了与中国电信北京公司合作情况，专题分享 XC 上云实践和未来规划，通过上云强化企业 IT 架构的稳定性和安全性经验；教育部教育管理信息中心基础设施处副处长刘冰介绍数据中心云化转型探索，分析面临的新问题和挑战，对教育行业数据中心上云用云提出新的展望；北京天坛医院信息管理与数据中心主任李瑞分享了区域医学影像云行业现状，以及面向不同医疗机构的医疗影像云场景解决方案；医渡云 CTO 闫峻分享了医渡云与中国电信北京公司的合作基础，依托天翼智算专属云，使用医疗垂域大模型的软硬训推一体解决方案；华为技术有限公司 AI 解决方案总监齐彦昆作为合作伙伴代表，分享了昇腾 AI 云服务，与中国电信联合创新，携手天翼云共同发展的情况。</p><p></p><p>活动现场举行了央国企上云白皮书发布仪式和客户签约仪式。信通院云大所云计算部主任马飞、天翼云科技有限公司助理总经理宫梅霞、天翼云科技有限公司北京公司副总经理李京共同出席发布仪式；中国电信北京公司与北京保利票务发展有限公司签订了保利票务上云项目。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f2/f281aa685426d0bd874bd6fe5f5ff588.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/24/2439ab0fd92570d191752e18d982fde5.png\" /></p><p></p><p>活动最后，中国电信北京公司为北京华创方舟、同方有云（北京）、上海英方软件等 11 家新招募云生态合作伙伴举行授牌仪式，中国电信北京公司副总经理孙健、天翼云科技有限公司助理总经理宫梅霞共同为合作伙伴代表授牌。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/88/8865d2e20cdb218e8848c557f1958813.jpeg\" /></p><p></p><p>数字经济高质量发展离不开科技创新的有力支撑。未来，天翼云将持续以科技创新驱动高质量发展，加快关键核心技术突破，不断释放数字生产力，为北京数字经济高质量发展提供强劲动能。</p><p></p>",
    "publish_time": "2023-12-13 10:39:09",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "数字化转型的全新探索：数据“驱动”与“消费” （下）",
    "url": "https://www.infoq.cn/article/3PDtH9prpEQ9sxOM2M73",
    "summary": "<p>目前企业数字化转型进行地如火如荼，数据资产建设最好的形态是由数据消费驱动的，但企业如何才能促进数据消费，将“数据”都变为“数据资产”？最新提出的“数据飞轮”，会是企业数字化转型的下一站吗？</p>\n<p>本期栏目，我们邀请到了顺丰科技 CEO 耿艳坤、民生银行 CIO 张斌、汽车之家 CTO 项碧波、彩食鲜 CTO&amp;TGO 乔新亮。他们所在的企业都正在经历数字化转型或者已经取得一定成就，一起来看看他们是怎么看待这些问题的吧！</p>",
    "publish_time": "2023-12-13 10:51:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "国网智能电网研究院数字化技术研究所 / 高级工程师于海博士确认出席 QCon 上海，分享电力数字孪生共性软件开发平台研发及应用",
    "url": "https://www.infoq.cn/article/q15F2I29f8q3NkcS0h4l",
    "summary": "<p><a href=\"https://qcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=1213&amp;utm_content=yuhai\">QCon 全球软件开发大会</a>\"，将于 12 月在上海召开。国网智能电网研究院数字化技术研究所 / 高级工程师于海博士将发表题为《<a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5649?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=1213&amp;utm_content=yuhai\">电力数字孪生共性软件开发平台研发及应用</a>\"》主题分享，探讨国网公司数字孪生平台概念和特征，电力数字孪生平台的总体架构、模型库、场景库、组件库、两中心、基础能力服务，以及平台特色，成效，技术创新点等。</p><p></p><p><a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5649?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=1213&amp;utm_content=yuhai\">于海博士</a>\"，高级工程师，江苏省产业教授，东南大学校外导师，中国电机工程学会信息化专委会大数据专家，国网公司优秀专家后备人才，CIGRE 会员，长期从事电力信息通信技术研究与建设服务工作。主持或参与了国家、国家电网公司以及网省公司等重大科技项目二十余项。曾获得国家电网公司科技进步一等奖 1 项，院级科技进步奖 4 项，发表 EI 检索学术论文二十余篇。他在本次会议的演讲内容如下：</p><p></p><p>演讲：电力数字孪生共性软件开发平台研发及应用</p><p></p><p>国网公司及集团各单位已开展大量数字孪生示范应用，但缺乏整体统筹，存在技术路线与组件工具不统一、模型资源分散、重复建设较多、成本投入大等问题，资源共享利用价值较低，且多停留在三维建模与数据接入展示阶段，智能诊断预测与仿真推演等高级业务应用较少。因此研发共性平台，通过低 / 零代码方式开发和配置差异型业务系统，打通业务和技术壁垒，可配置、可扩展、可快速变动。基于共性平台，通过图形化流程配置、部署和管理，实现低代码、集约化、可复用的人工智能模型交付应用。</p><p></p><p>演讲提纲：</p><p></p><p>需求现状分析国内外主流数字孪生平台数字孪生平台概念 &amp; 特征电力数字孪生平台</p><p>○ 总体架构、模型库、场景库、组件库、两中心、基础能力服务</p><p>平台特色，成效，技术创新点数字孪生与人工智能赋能大运会电力保供电水力发电站总结与展望</p><p></p><p>听众收益点：</p><p></p><p>○ 了解国网公司的数字孪生系统顶层设计规划</p><p>○ 了解国网公司在数字孪生技术方面的技术探索与应用案例</p><p></p><p>除上述演讲外，QCon 上海还将围绕&nbsp;<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart\">GenAI和通用大模型应用探索</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1596?utm_source=infoqweb&amp;utm_medium=teacherart\">AI&nbsp;Agent&nbsp;与行业融合应用的前景</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart\">LLM&nbsp;时代的性能优化</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart\">智能化信创软件&nbsp;IDE</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart\">面向人工智能时代的架构</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart\">性能工程：提升效率和创新的新方法</a>\"等专题进行交流。</p><p></p><p>QCon 上海 2023，相约 12 月！ 9 折优惠仅剩最后 3 天，现在购票立减￥680！咨询购票请联系：18514549229（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/0113b3dfb187d5f9988b7eb16d2e0594.png\" /></p><p></p>",
    "publish_time": "2023-12-13 11:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Netflix 如何处理其容器平台 Titus上 的孤儿 Pod 问题",
    "url": "https://www.infoq.cn/article/ZL55XREGMf1WyLLx6QNj",
    "summary": "<p>Netflix 工程团队介绍了他们如何调查、识别和解决 Titus 的“孤儿”pod 问题，揭示了从内核恐慌到 Kubernetes（k8s）的整个过程，并最终为操作人员提供了可用于理解节点消失原因的工具。</p><p></p><p>Netflix Titus 是 Netflix 开发的容器管理平台，于 2018 年开源。按照设计，它主要是用于在云中大规模运行容器，并专门针对 Netflix 的动态、高流量大型流媒体服务的独特需求和挑战而量身定制。</p><p></p><p>虽然孤儿 pod 在系统中占少数，但对批处理用户来说是一个很大的问题，因为他们会面临不确定性，缺少明确的返回代码可以指导他们做重试决策。孤儿 pod 是由于底层 Kubernetes Node 对象消失造成的。当一个节点消失时，将触发一个垃圾收集（GC）进程，删除相关的 pod。为了增强用户体验，Titus 使用了一个自定义控制器来维护 pod 和 Node 对象的历史记录，以保证信息透明度。然而，由于对于丢失原因缺乏令人满意的解释，他们决定对根本原因做进一步调查。</p><p></p><p>Node 可能因为各种原因消失，尤其是在云环境中。通常，云供应商会使用 Kubernetes 云控制器来检测底层服务器的丢失，并随后删除 Kubernetes 节点对象。然而，这并没有回答节点消失的关键问题。为了解决这个问题，Netflix 工程团队引入了一个注解来捕获终止原因，为理解节点消失的原因提供信息。</p><p></p><p><code lang=\"javascript\">{\n     \"apiVersion\": \"v1\",\n     \"kind\": \"pod\",\n     \"metadata\": {\n          \"annotations\": {\n               \"pod.titus.netflix.com/pod-termination-reason\": \"Something really bad happened!\",\n...\n</code></p><p></p><p>添加“pod-termination-reason”注解是其中一个关键的步骤。通过将该注解加入垃圾收集器控制器，并将其包含在可能意外终止 pod 或节点的进程中，Titus 实现了一种可以统筹兼顾的方法。与修正状态不同，使用注解可以兼顾历史考量而保留 pod 的完整性。现在，Titus 可以捕获各种终止原因，如抢占作业、硬件故障、用户干预或内核恐慌，并提供人类可读的消息。</p><p></p><p>考虑到 Linux 内核出现故障时可用的选项有限，处理内核故障是一项独特的挑战。受 Google Spanner“最后喘息”概念（节点在致命故障时发送 UDP 数据包）的启发，Titus 使用 netconsole 模块实现了一个解决方案。配置 netconsole，将 Linux 内核设置为在内核恐慌时发送 UDP 数据包，从而使平台在发生灾难性故障时也能捕获重要的信息。</p><p></p><p>最后一步是连接到 Kubernetes 并实现一个控制器：</p><p></p><p>监听 netconsole UDP 数据包。识别内核恐慌，并将它们与 k8s 节点对象关联起来。标注并删除与恐慌节点关联的 pod。标注并删除恐慌节点。</p><p></p><p>该进程可以确保在检测到内核恐慌时立即采取行动，而不必等待垃圾收集器进程。注解充当文档，使操作人员能够清楚地了解节点和相关 pod 发生了什么。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/95/952d4a1df2fbce43454338605a6da268.png\" /></p><p></p><p>Titus 显示 pod 在一个内核恐慌的节点上丢失的过程</p><p></p><p>他们引入的措施不仅直接解决了孤儿 pod 的问题，还为操作人员提供了重要的观察工具。现在，Titus 用户可以收到有关作业失败原因的详细信息，即使在内核恐慌的情况下也是如此。虽然标记由于这种严重事件而导致的作业失败可能并不是最理想的方法，但令人满意的是，这种方法增强了可观察性以及主动处理和纠正内核恐慌的能力。由于所有这些改进，Titus 显著增强了其功能，确保工程师和批处理用户都能获得更流畅的体验。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/12/orphaned-pods-netflix-titus/\">https://www.infoq.com/news/2023/12/orphaned-pods-netflix-titus/</a>\"</p><p></p><p></p><p></p><p></p>",
    "publish_time": "2023-12-13 12:52:14",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "大模型落地金融行业，如何闯关最后一公里？｜InfoQ《极客有约》",
    "url": "https://www.infoq.cn/article/wV7sNBNqeO27V3p5E2Gu",
    "summary": "<p>AI 大模型引领千行百业加速升级。在金融行业，大模型正以其出色的数据处理和分析能力引领着一场技术变革。那么，目前大模型在金融行业的应用现状如何？大模型在金融行业的落地应用面临哪些问题和挑战？如何打通大模型在金融业落地的最后一公里？</p>\n<p>本期《极客有约》邀请到了腾讯金融云技术总监全成，为大家分享《大模型落地金融行业，如何闯关最后一公里？》。</p>\n<p><strong>直播亮点：</strong></p>\n<ul>\n<li>在金融行业，大模型的价值主要体现在哪些层面？</li>\n<li>目前大模型在金融行业的应用现状如何？</li>\n<li>大模型在金融行业的产业落地需要遵循哪些规则？</li>\n<li>金融行业真正需要什么样的大模型？</li>\n<li>当前金融机构部署大模型主要有哪些方式？</li>\n<li>如何打通大模型在金融业落地的最后一公里？</li>\n</ul>\n<p><strong>特邀主持：</strong></p>\n<p>马可薇，InfoQ 社区编辑，美国 Cognizant 公司架构师（solution architect），主要负责保险领域的业务。</p>\n<p><strong>嘉宾：</strong></p>\n<p>全成，腾讯金融云技术总监。之前曾在某金融集团公司参与关系网络风控识别项目，和说话人声纹识别比对项目；在券商互联网企业参与过大数据量化投资项目。目前在腾讯主要参与 TX2SQL 大模型智能应用项目，负责专业知识及推理大模型微调，构建端到端 TX2SQL 问答系统。</p>",
    "publish_time": "2023-12-13 13:00:33",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "行业热议：数据中台下一步是数据飞轮？",
    "url": "https://www.infoq.cn/article/3dhgv7hqBCrHXFSX1qE9",
    "summary": "<p>随着科技的不断进步和全球数字化浪潮的席卷，企业数字化转型已经成为了企业生存和发展的关键。它不仅仅是一道选择题，更是一道必答题。根据最新的数据，国内企业对数字化转型的投资已经达到了一个新高。根据国家统计局的数据，去年我国数字化转型的总投资额超过了 1.5 万亿元，同比增长了 20%。</p><p></p><p>目前企业一般是采用云计算、大数据、人工智能等技术手段，来提高生产效率、优化客户体验和拓展新的商业模式，但是很多企业在数字化转型方面依然面临着很多的困难和挑战，比如数据整合与分析难度大、技术人才匮乏、信息安全风险、 投入成本高昂等问题。但仔细复盘会发现，大多问题的出现和解决都离不开“数据”。</p><p></p><p>为了探寻企业数字化转型的发展趋势，本期 InfoQ 新知实验室栏目由极客邦科技创始人 &amp;CEO 霍太稳作为主持人，邀请到了顺丰集团 CTO&amp; 顺丰科技 CEO 耿艳坤、民生银行 CIO 张斌、汽车之家 CTO 项碧波、彩食鲜 CTO&amp;TGO 鲲鹏会荣誉导师乔新亮一起围绕《数字化转型的全新探索：<a href=\"https://www.infoq.cn/video/KqaNdNwtqiH2dfsYPXWL?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">数据“驱动”与“消费”</a>\"》话题展开了深入探讨。</p><p></p><p></p><p>点击观看：《数字化转型的全新探索：数据“驱动”与“消费”》完整版</p><p></p><p></p><h2>一、数据驱动：企业数字化转型的基础</h2><p></p><p></p><p>当前的商业环境中，竞争变得更加精细化，成本管控变得更加严格，企业需要不断地进行自我颠覆和保持领先，以提高竞争力和竞争壁垒。企业需要突破传统的做事方式，尝试新的创新方法，以实现持续发展。数据已经成为企业的重要创新要素和资产，对于企业的决策、创新和竞争优势至关重要，这需要企业进行精细化的运营和数据挖掘，以实现数据驱动。</p><p></p><p>对于顺丰来说，数字化转型已经取得了显著的成果。作为快递物流综合服务商，顺丰在数字化建设方面积极探索和实践，实现了在销售侧的数据挖掘和应用、智能营销等功能。此外，在风控侧，顺丰也借助动态与静态数据相结合、离线和在线数据相结合的方式，实现了服务保障和时效履约等业务的数字化升级。在这个过程中，数据扮演了一个至关重要的角色。通过数据的分析和应用，顺丰可以更好地理解客户需求、优化业务流程、提高运营效率等。</p><p></p><p>在顺丰集团内部，数据中台可以打破不同角色、不同职能看待数据的视角，让所有人都能从经营视角看待数据，形成端到端的完整链条，从而更好地驱动经营。同时，还有一个叫“数据盟友”的概念，这个群体指业务经营中各个需要看数据的角色，他们通过数据中台中灵活、自定义的个性化方式来分析、解读数据，更深入地基于数据了解业务，让数据更好地指导业务决策。张斌表示民生银行内部也有一种类似的模式，他们将数据分析人员派驻到业务部门一起协同工作，以更好地利用数据为业务提供支持，通过实际的业务场景来运用数据支持业务决策。</p><p></p><p>民生银行作为一家总资产超过 7 万亿的国内系统重要性银行，更是将数字化转型作为自身战略的重要组成部分，进行顶层规划和统筹推进。民生银行不仅全面加强了科技和数据能力建设，还同步对组织架构、体制机制和文化等进行变革和创新。这种变革的推动力来自于银行最高领导层，将数字化转型视为一项由技术和数据驱动的经营管理变革工程，不仅亲自抓规划，也亲自抓落实，取得了显著的成效。而这也恰恰说明了企业数字化转型的成功与否，与一把手的态度和参与程度密切相关。</p><p></p><p>就像彩食鲜的技术部门一把手乔新亮所表达的那样，“企业需要直接将数据应用到业务操作中，而不仅仅做报表和分析，这是提高企业运营效率和提升竞争力的重要手段。”他全面负责彩食鲜的数字化转型，主动撤掉数据的智能部门，并将他们并入业务小团队，以直接驱动数据在业务中的运用。他认为，不做报表，不做过度分析，而是将数据用于实时、准确的决策，使企业能够快速响应市场变化和客户需求。同时，他也强调了系统的重要性，主张通过系统来接管低质量重复性工作，以提高工作效率和减少错误。他提出“系统驱动货单通行，不见指令不许干活”的理念，以确保数据和系统在业务中的广泛应用。</p><p></p><p>彩食鲜用数据工具实现了企业的数字化转型及降本增效，而汽车之家作为一家服务汽车厂商的垂直平台，正在积极地通过挖掘数据价值，来开发一系列的“智慧产品”工具来赋能汽车厂商的数字化转型，比如通过“智能外呼、智慧质检”等来帮助经销商提高经营效率和服务质量。此外，汽车之家还应用数字化技术设计全息大屏展示新能源汽车，帮助客户解决销售问题，这种模式不仅提高了客户的经营效率，也方便了用户购车试驾的过程。</p><p></p><p>事实上，当前市面上的数据工具已经进入到了“快速推陈出新”的阶段，可以看出越来越多的企业已意识到数据驱动的重要性，并为此投入了大量的资源。全行业的数字化转型都已经进入深水区，企业都在争先恐后地搭建属于自己的数据平台，像本期栏目的四位嘉宾所在企业就都有搭建自己的数据中台并都取得了明显成效。通过数据中台，他们实现了企业内部的数据共享和打通，提高了企业的运营效率和客户满意度。</p><p></p><h2>二、数据消费：企业数字化转型的关键</h2><p></p><p></p><p>数据中台“很香”，但我们观察当前很多企业的数据中台上线效果却并不都是那么尽人意，成本不低但效果平平。关于这个现状，四位嘉宾通过讨论得出了原因——企业只重视建设，缺乏数据消费（数据消费，将数据转化为具有实际价值的信息和知识，并将其应用于业务决策和操作的过程），数据流没有融入业务流。对此，耿艳坤认为顺丰在建设数据中台的过程中，除了关注数据的共享和整合，也非常关注解决实际业务问题。企业发展到一定阶段时，相对于数据所带来的成本，对数据价值的思考更为重要。所以顺丰一直尝试最大化地消费公司的数据能力，从而真正实现数据的价值。张斌则特别提到，对于银行业来说，在建设数据中台的过程中，数据的整合与共享是一个方面，融合治理能力保证数据质量和一致性，以及数据安全与合规保护也都是数据中台建设的重要内容。</p><p></p><p>建设数据中台，有助于更好地管理和治理数据，但它只是实现数据驱动中的一个步骤。在具体的企业运营过程中，收集来的很多数据并不能够直接产生收益，没有数据消费就是成本，有数据消费就是资产——数据消费并实现了价值就是资产，数据没有被充分利用就是成本，数据资产建设的最好形态是由数据消费驱动的。因此，即使数据中台建设得再完善，如果这些数据没有被充分地利用和消费，那么这些数据就无法发挥其应有的价值，甚至会成为企业的负担和成本。而当数据被消费并应用于业务决策和操作中时，它就变成了企业的资产。</p><p></p><p>其实，过去的中台建设都是默认“以始为终”，但这个显然与现存的企业情况是不符合的。现在大部分企业的问题是在于他们并没有思考，怎么以终为始的进行数据建设，如果不在一开始就以充分消费为目的，想清楚数据怎么使用，怎么易用，怎么以最低的门槛去用，那么其实中台的建设就很可能走偏，数据用不起来，让数据变成成本，而非资产。</p><p></p><p>因此，企业在运营过程中，需要充分地利用和消费数据，以实现其应有的价值。只有将数据流融入业务流，才能真正发挥数据的价值，推动企业的数字化转型。如果不能解决数据消费的最终场景问题，那么再好的基础设施最终也是无用功。</p><p></p><p>像汽车之家就把数据消费看作是推动业务发展的关键因素，在企业的日常运营中，他们通过数据来分析市场趋势、客户行为以及业务运营情况。同时，他们也通过数据来优化产品和服务，提高客户满意度和忠诚度。因为重视数据消费，汽车之家已经通过数据获得了不少业务价值，比如更精准的营销策略、更高效的运营管理等。</p><p></p><p>无独有偶，张斌所在民生银行的数据消费突出体现在风险控制、市场营销和运营优化等领域。首先，风险控制是银行业务的核心之一，通过数据分析挖掘可以更准确地评估客户的信用等级和风险水平，包括更有效管控业务线上化带来的欺诈风险等。其次，营销与服务是银行提高客户满意度和忠诚度的关键，通过数据洞察可以更好地了解客户需求和市场趋势，进而提供更有针对性、个性化的服务和产品。最后，运营优化也是银行提高效率和降低成本的重要手段，通过数据分析可以优化业务流程，可以实现流程自动化和智能化，提高运营效率和降低成本。因为重视数据的深度应用，民生银行已经获得了广泛的业务价值，比如更准确的信贷决策、更好体验的客户服务以及更高效的运营管理。</p><p></p><p>不难看出，数据消费已经在各个层面为企业创造了业务价值，从客户关系管理到运营管理，再到战略决策。通过最大程度地利用数据消费，企业可以更好地适应不断变化的市场环境，实现可持续增长。可以说，除了驱动数据资产建设，数据消费在当今的数字化转型最大的价值就是能带来数据驱动，实现共识统一、业务洞察、科学决策等。</p><p></p><h2>三、数据健康度：企业不同角色进行数据消费的大前提</h2><p></p><p></p><p>在当下的数字化转型中，数据消费扮演着至关重要的角色。事实上，“数据驱动”最终肯定是要落在企业不同人员对数据的消费上的。只有根据不同角色的需求和消费方式，才能更好地设计和提供相应的数据服务和支持，从而真正实现数据的价值和企业数字化转型的目标。</p><p></p><p>在这个层面上，顺丰集团做得非常的好，通过全面、实时、科学的数据驱动决策，顺丰实现了不同部门、不同角色之间的数据共享和协同工作，提高了整体运营效率和服务质量。同时，顺丰通过数据消费不断发现和改进问题，持续优化运营和服务，提高客户满意度和市场竞争力。例如从市场相关组织的角度看，通过使用数据中台提供的各类数据产品，可以看到相关区域客户的热力图、收入与利润的变化等，更好地了解客户需求和市场变化。顺丰通过数据消费实现了对成本的精细管理和对资源的合理配置，提高了企业的盈利能力。</p><p></p><p>如出一辙，彩食鲜在不同企业角色的“数据消费”方面也做许多工作，乔新亮分享道，“公司领导和各个部门都依赖数据来评估业绩表现，发现并解决问题。为了注重数据消费，公司开发了各种数据产品，为不同角色提供了实时、全面的数据支持。这些数据不仅帮助各部门更好地了解客户需求和市场变化，还为制定科学、合理的决策提供了依据。”</p><p></p><p>彩食鲜非常注重跨部门的数据共享和协同工作，通过数据消费实现了不同角色之间的数据打通和业务协同，这不仅提高了工作效率，还优化了业务流程，提升了整体运营效率。这其中最重要的规则是，为了确保数据的真实性和准确性，公司对运营管理有严格的要求——任何不合规的行为都会被红线处理，以确保数据的可信度和价值。此外，公司还通过数据消费发现并解决重复性工作的浪费问题，进行调整和优化，这使员工能够腾出更多的时间，专注于创新和增值工作，提高企业的竞争力和市场占有率。</p><p></p><p>通过四位嘉宾的分享中，我们可以清楚感知到，不同企业的“数据消费”情况是不一样的，但普遍来说，我们可以看到一些共同的趋势。无论企业如何进行数据消费，数据消费的本身一定是要健康的。数据消费的健康程度需考虑数据的全面性和多样性、准确性和可靠性、实时性和动态性、合规性和道德性，以及数据的质量和可靠性等多个方面。关于如何来衡量企业数据消费的水平是否是健康的，霍太稳非常赞同之前与火山引擎总裁谭待交流时他表达的观点。在本期栏目中，霍太稳分享了字节跳动在“数据消费健康度”这方面的经验——两个 80%：</p><p></p><p>80% 的字节员工每天在通过各种各样的数据产品使用数据，进行数据消费。这其中既包括大家传统认知中的数据工程师、数据分析师这些需要直接和数据打交道的人，也包含产品、运营、市场，甚至行政、HR、UED 这些传统意义上离数据比较远的人。</p><p></p><p>统一建设的数据资产能够覆盖 80% 的业务日常分析。这样既能够保证在大多数情况下，对于数据的分析和使用是高效的，又为特殊场景的数据分析和应用预留了足够的灵活性。</p><p></p><p>总体来说，数据健康度它不仅直接影响到数据的质量和可靠性，还影响到企业决策的准确性和效果。在数字化时代，企业需要从海量的数据中提取有价值的信息和洞察，以指导业务决策和优化运营。但如果数据存在缺失、错误或不准确的问题，那么企业就无法准确地了解市场和客户需求，也无法制定科学有效的策略。</p><p></p><p>因此，企业需要重视和维护数据健康度，企业需要确保数据的完整性和准确性、提高工作效率和运营水平、保障合规经营安全的同时，也需要加强数据治理和规范数据管理流程，以确保数据的合规性和安全性。只有这样，企业才能真正实现数据驱动的运营模式，提高市场竞争力和可持续发展能力。</p><p></p><h2>四、数据飞轮：企业数字化转型的下一站</h2><p></p><p></p><p>企业要成功数字化转型，必须重视数据消费、数据资产和业务应用发展之间的良性循环。这种循环以数据消费为核心驱动力，将原始数据转化为有价值的信息和洞察，为企业提供决策支持和优化运营，而这个循环也几乎就是<a href=\"https://www.infoq.cn/article/WPmK0BeY0dDJB6wLL0zM?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">火山引擎</a>\"在今年 4 月提出的数据驱动的新范式——<a href=\"https://xie.infoq.cn/article/bcd41b1e6ca94ac195e429df9?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">数据飞轮</a>\"。这个概念在当前的企业数字化转型领域频繁被提起，其核心便是“以数据消费为核心驱动力，以数据消费助力业务发展，以数据消费促进资产建设。”</p><p></p><p>项碧波对此有一个非常有意思的形容，“我们可以将中台视为静态的基础设施，而将飞轮描述为一种运行状态。”他认为数据飞轮可以描述为一种正向反馈的迭代循环过程，类似于一个转动的飞轮，通过不断地迭代和优化来达到业务价值最大化的目标。同时提出数据飞轮的应用需要先在日常运营中形成标准操作流程（SOP），然后将 SOP 固化到系统中，以确保数据的实时性和准确性。</p><p></p><p>乔新亮和张斌非常赞同项碧波的观点，乔新亮认为，数据飞轮可以串起数据消费、数据资产和业务应用的发展，同时需要系统具有强大的分析能力和可行度来确保指导工作和提高效率。低质量重复性工作应该被系统接管，以释放人力并提高工作效率。而张斌则表示“数据飞轮之所以能够运转起来，是因为采取的措施和投入能够看到发挥了作用，目标在接近。反过来，这种接近目标的状态又会促使进一步的投入或优化方案，实现螺旋式的上升。”张斌预判，“数据飞轮”在民生银行的效果已经显现，银行需要不断利用数据深化应用场景，以实现数字化转型的目标。</p><p></p><p>在探讨过程中，耿艳坤对各位嘉宾的观点进行了补充，“数据飞轮适用于每个行业和企业的概念模型，但是因为每个行业、企业的数字化目标、数字化程度和要解决的问题不同，所以每一个企业的数字化战略在匹配数据飞轮模型进行落地时，大家的形式会各有不同，这需要每一个企业进行深度思考。每个企业的数字化变革应该是基于自身特性和经营目标进行的。”</p><p></p><p>简而言之，企业只有形成“以数据消费为核心”的闭环，才能在当下这个数字化时代获得竞争优势。另外值得一提的是，在数字化转型过程中，通过科技和数据驱动，企业实现了从传统的指标牵引型向数据驱动型生产经营过程的转变。同时，AI 大模型的应用也使得企业能够更好地利用数据，实现更高效、精准的数据分析和决策，从而更好地满足客户需求，提高企业竞争力。比如火山引擎今年新发布的大语言模型应用 DataWind- 分析助手、DataLeap- 找数助手、DataLeap- 开发助手, 它们可以为企业提供从数据资产层到业务应用层的全链路 AI 能力。因此，AI 大模型的出现也对企业的数字化转型和数据消费门槛的降低具有非常重要的意义。</p><p></p><p>在过去的五年里，企业数字化的主旋律是数据中台。数据中台为企业提供了一个集中式、可重复使用的数据资产平台，帮助企业更好地管理和利用数据，支持企业的数字化转型。然而，随着数字化转型的深入，企业对于数据消费的频率和依赖也会不断提高。所以未来数年，企业数字化的主旋律大概率就要转向数据飞轮了。</p><p></p><p>但话讲回来，数据飞轮与数据中台并不是完全替代的关系，而是继承和升级的关系。数据中台提供了企业所需的底层数据支持和数据处理能力，而数据飞轮则是在此基础上，指出数据消费的重要，并提供配套的便捷、易用的数据消费工具，帮助企业形成数据应用和业务价值提升的良性循环。</p><p></p><p>数据飞轮可以看作是一种更加灵活、动态、可扩展的数字化升级模式，它能够通过数据消费将数据与业务场景更加紧密地结合在一起，帮助企业更好地利用数据实现数字化转型，但未来究竟会与各领域业务擦出怎样的火花，就让我们拭目以待！</p>",
    "publish_time": "2023-12-13 13:46:13",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "国泰君安的数字化转型探索与实践",
    "url": "https://www.infoq.cn/article/kV7jYbxMrkRTiPh0Y0w6",
    "summary": "<p>在当今快速演变的数字经济中，企业面临着转型的关键时刻。正是在这样的背景下，在FCon 全球金融科技大会的现场，我们邀请了国泰君安证券股份有限公司 /首席信息官俞枫 博士，为我们带来关于国泰君安数字化转型的深入洞察。以下为内容要点：</p>\n<ol>\n<li><strong>数字化转型的重要性</strong>：强调数字化转型对于提升竞争力的必要性。</li>\n<li><strong>技术与商业模式的深度融合</strong>：提出金融科技以技术和场景为核心，而数字化转型以技术和组织为核心。</li>\n<li><strong>全面转型的策略</strong>：涉及技术、数据、流程和组织的综合变革。</li>\n<li><strong>客户中心转型</strong>：强调优化信息流、资金流和物流，提升用户体验。</li>\n<li><strong>数据资产的关键性</strong>：突出数据在决策中的核心作用。</li>\n<li><strong>组织文化和思维的转变</strong>：提倡从经验判断转向数据驱动和智慧决策。</li>\n</ol>\n<p><strong>活动推荐：</strong></p>\n<p>QCon 全球软件开发大会（上海站）即将在 12 月 28-29 日开始，届时将围绕 GenAI 和通用大模型应用探索、AI Agent 与行业融合应用的前景、LLM 时代的性能优化、智能化信创软件 IDE、面向人工智能时代的架构、性能工程：提升效率和创新的新方法等专题进行交流。现在购票，享 9 折优惠，立减￥680！咨询购票请联系：18514549229（微信同手机号）。</p>",
    "publish_time": "2023-12-13 15:19:12",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "马斯克打造的“叛逆”AI被曝抄袭ChatGPT？xAI工程师回应：我们没用OpenAI代码",
    "url": "https://www.infoq.cn/article/cVMl53mEkcAwGEQ1ACjZ",
    "summary": "<p></p><blockquote>有专家认为，xAI 可能是使用了&nbsp;OpenAI 模型输出来微调 Grok。</blockquote><p></p><p></p><h2>师出同门？马斯克的新 AI 机器人Grok 引用 OpenAI 使用政策</h2><p></p><p>&nbsp;</p><p>Grok 是由马斯克创立的 xAI 公司开发的 AI 机器人，类似于 OpenAI 旗下的明星产品 ChatGPT。除了能够通过 X 平台（原 Twitter）获取实时知识以外，Grok 与市面上其他模型的最大区别就是它乐于回答各种“尖锐”问题，并以一种既诙谐又有点叛逆的方式加以解构。</p><p>&nbsp;</p><p>但自 Grok 上周正式发布以来，人们从中发现了不少有趣的现象。</p><p>&nbsp;</p><p>上周五，安全测试员 Jax Winterbourne 在推文中分享了一张 Grok 拒绝查询的屏幕截图，这款机器人表示：“我恐怕无法满足该请求，因为这违反了 OpenAI 的用例政策。”消息一出迅速在网上引发关注，因为 Grok 并非出自 OpenAI 之后，反而是为了与 OpenAI 打造的明星级聊天机器人 ChatGPT 相抗衡而生。</p><p><img src=\"https://static001.geekbang.org/infoq/1a/1aa10dee0eba27e6c74559ec0d9a08d8.png\" /></p><p></p><p>更有趣的是，xAI 的代表并没有否认其 AI 模型存在这种行为。xAI 工程师&nbsp;Igor Babuschkin 在回复中写道：</p><p>&nbsp;</p><p></p><blockquote>“之所以会出现这种问题，是因为网络上充斥着 ChatGPT 的输出，所以我们在使用大量网络数据训练 Grok 时无意中获取了其中部分输出。这对我们来说完全是个意外，这也是我们第一次发现问题。这个问题本身非常罕见，现在我们已经意识到其存在，也将在 Grok 的未来版本中确保不再出现类似的问题。大家不用担心，Grok 的开发中并没有用到 OpenAI 代码。”</blockquote><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8f/8fbf9fec59ad5306b07dd09b7f504f0d.png\" /></p><p></p><h2>ChatGPT“倒油”：我们确实有很多共同点</h2><p></p><p>&nbsp;</p><p>对于一些专家来说，Babuschkin 的解释似乎缺乏说服力，因为大语言模型一般不会原样输出训练数据。如果 Grok 是在回答中偶尔提到了 OpenAI 政策，那倒是完全可以理解。但实际情况恰恰相反，这段基于 OpenAI 政策的拒绝查询内容可能需要专门训练。所以可能性更大的真相，其实是&nbsp;Grok 使用 OpenAI 语言模型的输出数据进行了微调。</p><p>&nbsp;</p><p>根据 ArsTechnica 报道，AI 研究员 Simon Willison 在采访中表示，“我对 Grok 之所以会输出这样的内容，只是因为互联网上充斥着 ChatGPT 生成结果的说法表示怀疑。我在 Hugging Face 上看到过大量表现出相同行为的开放权重模型，它们的行为同样跟 ChatGPT 高度相似，但这是因为那些模型在使用 OpenAI API 生成的数据集上进行了微调，或者干脆直接从 ChatGPT 本体中抓取了数据。所以我认为 Grok 更有可能是在包含 ChatGPT 输出的数据集上进行了指令微调，而非基于网络数据的纯意外表现。”</p><p>&nbsp;</p><p>随着 Grok 可能借用 OpenAI 结果的消息传开，ChatGPT 官方账号发帖称“我们确实有很多共同点”，并引用了 Winterbourne 的帖子。作为回应，马斯克则写道：“行吧，小子，反正你就是从整个网络平台上抓取数据训练出来的，所以你肯定最懂。”</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3c/3cc90be05b8c87ae88d7e7194f9c76b5.png\" /></p><p></p><p></p><h2>马斯克打造的“叛逆”AI：Grok</h2><p></p><p>&nbsp;</p><p>根据介绍，Grok 是一款模仿《银河系漫游指南》风格的“叛逆”机器人，会以辛辣幽默的方式“锐评”各类问题，其神奇的脑洞往往出人意料。据悉，Grok 仅经过两个月的训练就开发而成，xAI 表示该机器人将在用户反馈的帮助下快速发展。</p><p>&nbsp;</p><p>根据 xAI 的介绍，Grok 确实会回答那些被大多数其他 AI 系统拒绝的“尖锐”问题。管理顾问 Satyam Srivastava 表示，Grok 已经在不少有争议的查询上表现出“非常出色”的处理能力。</p><p>他提到，马斯克最近发布一条推文，其中一名用户向 Grok 询问如何合成可卡因，Grok 则将其称为“臭名昭著的白面儿”。</p><p>&nbsp;</p><p>起初，Grok 还在回复中添加了一点幽默元素，比如第 4 点是“上灶开炒，希望你别搞炸了或者被抓住。”但马斯克随后展示了更详尽的完整回应，称该机器人明确强调这一切都是“出于教育目的”。Srivastava 表示，“这种方法可谓在市场上脱颖而出，远优于尽量回避此类问题的其他 AI 产品。”</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/65/6513e4e300eaa05e38e5eadf60960d9d.png\" /></p><p></p><p>作为 Grok 背后的引擎，Grok-1 在机器学习基准测试中的表现优异，成功超越了同等体量的其他模型。例如，Grok-1 的性能优于 ChatGPT-3.5 和 Inflection-1，仅落后于 GPT-4 等体量更大的模型。马斯克还在 Twitter 上分享了一张图片，展示了 Grok与 其他典型 GPT 相比如何利用实时信息充实响应结果。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/71/713ed69b406398d1dad93b6713dd78ba.png\" /></p><p></p><p>Grok 在开发中用到了 Kubernetes、Rust 和由 JAX 构建的强大基础设施。xAI 团队也特别强调了可靠基础设施对于深度学习研究的重要意义，而 Rust 的性能与可靠性也发挥了巨大价值。随着 Grok 为进一步迭代做好准备，该团队声称其重点关注可扩展、高效且可靠的训练与推理机制。</p><p>&nbsp;</p><p>此外，Grok 还曾接受 2023 年匈牙利国家高中数学考试，获得的成绩为 C。Srivastava 表示，未来随着 Grok 掌握更先进的学习算法，它有望比 ChatGPT 和 Bard 等其他 AI 模型更快地学习和适应。</p><p>&nbsp;</p><p>但研究参与者兼 Culture Fluid 创始人 Sharon Gai 认为，由于 Grok 主要接受来自 Twitter 用户的训练数据，因此她只能暂时停止对准确度的考查。她解释道，“任何人都可以在 Twitter 发表推文，所以这里简直成了错误信息的集散地。相比之下，ChatGPT 则主要将已出版的期刊、网站和书籍作为素材进行训练。”</p><p>&nbsp;</p><p>Gai 还补充道，马斯克在通过蓝标认证为 Twitter 赚钱的计划失败之后，就匆忙推出了自己的AI机器人。在她看来，“目前马斯克这套模型的唯一优点就是使用了最新数据，而且比“清醒的”ChatGPT 能回答更多问题。这款产品也很好地融入了他将 X 打造成超级应用的计划。马斯克已经为 X 平台申请到了银行牌照，还计划推出直播服务。”</p><p></p><p>参考链接：</p><p><a href=\"https://x.ai/\">https://x.ai/</a>\"</p><p><a href=\"https://arstechnica.com/information-technology/2023/12/elon-musks-ai-bot-grok-speaks-as-if-made-by-openai-in-some-tests-causing-a-stir/\">https://arstechnica.com/information-technology/2023/12/elon-musks-ai-bot-grok-speaks-as-if-made-by-openai-in-some-tests-causing-a-stir/</a>\"</p><p><a href=\"https://www.cmswire.com/digital-experience/what-is-grok-elon-musks-rebellious-new-ai/\">https://www.cmswire.com/digital-experience/what-is-grok-elon-musks-rebellious-new-ai/</a>\"</p>",
    "publish_time": "2023-12-13 15:37:23",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "民营银行生存法则“唯快不破”，华瑞银行风险特征计算平台如何做到实时响应",
    "url": "https://www.infoq.cn/article/2J7bFWYuhBcJ01K04tLd",
    "summary": "<p>上海华瑞银行是我国首批试点的五家民营银行之一，2014 年获批，2015 年正式开业，秉承“服务实体经济，服务小微大众”的使命初心，坚持“聚焦普惠，建设特色鲜明的智慧银行”的战略定位。这意味着，其业务一方面要能够满足高并发，应对瞬时的多客户业务申请；另一方面还要满足实时性，支持快速（甚至是秒级）的业务决策。</p><p></p><p>在日前举办的<a href=\"https://fcon.infoq.cn/2023/shanghai?utm_source=infoq&amp;utm_medium=conference\"> FCon 大会期间</a>\"，上海华瑞银行风控数据团队负责人丁清华接受了 InfoQ 采访。他表示，民营银行想与其它传统金融机构竞争，只有“唯快不破”。拿贷款申请举例，不能让客户等 24 小时，而是需要做到准实时或实时响应。这就要求其风险系统架构可以实现准实时、秒级审批。</p><p></p><p>但是，和绝大多数金融机构一样，华瑞银行的风控信息系统建设也并非一步到位，而是在演进过程中逐步优化和迭代。比如，在华瑞银行成立初期，风险特征的计算功能耦合在贷款业务系统中，这造成了以下问题：一是架构不清晰，风险特征计算功能较弱，依赖于业务系统的功能；二是缺乏统一的特征管理平台，造成重复开发，资源浪费；三是变更频繁，日常特征变更及策略迭代都需要进行生产变更，增加系统运行风险。</p><p></p><p>随着大数据计算技术的成熟，华瑞银行通过与成熟商业机构合作，使用离线和实时计算技术，建设了<a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5585\">风险特征计算平台</a>\"。利用 Blink、DataHub 实现实时风险特征计算，利用 maxcompute 建设风险数据集市，离线计算风险特征，建设统一的应用平台实现风险特征的统一定义、计算、管理和服务调用等。</p><p></p><p>“未来，我们希望通过这个平台可以快速定义风险特征，比如，把一些功能开放给风险策略人员和模型人员，当他们发现新的风险情况时，就可以自主定义并新增上线一些特征，以及时地满足风险评估需求。”丁清华向 InfoQ 介绍，接下来华瑞银行将围绕“数据 + 风控 + 科技”共同建设的思路，继续完善风险特征计算平台功能，比如：为策略经理提供更便捷的特征定义、配置、计算、测试、回溯和上线；为模型经理提供特征分布监控、稳定性分析、特征重要性分析等功能；为产品经理提供系统运行监控、元数据管理和分析、使用分析等功能。</p><p></p><p>以下是对话全文（经 InfoQ 进行不改变原意的编辑整理）：</p><p></p><h5>InfoQ：请简要介绍一下华瑞银行风控体系建设以及布局背后的设计逻辑。</h5><p></p><p></p><p>丁清华：目前，华瑞银行数字风控部门在内部构建了一个数字风控大脑。系统从 2020 年开始规划并且落地，主要包含了数据基础平台和风险数据集市。</p><p></p><p>其中的基础数据包括两类：一是从外部实时调用过来的数据，比如央行的征信报告、朴道和百行等持牌征信机构发布的三方数据信息等等，比如针对一些银行的新客户，就需要调用这些外部数据；二是银行内部构建的数据湖，它主要集成了行内已有客户的数据情况，比如过往申请信息、还款信息、交易行为信息等等。</p><p></p><p>基于这些基础数据，我们构建了风险特征计算平台，也称为“特征工厂”。而经过特征工厂计算后的数据主要划分为两部分：一部分是实时的，会提供给线上数字化风险审批系统，用于反欺诈审批和授信审批；另一部分是离线的，会提供给策略分析和模型算法人员，用于回溯分析，并不断修正和优化<a href=\"https://www.infoq.cn/article/a1uk0eGDAxBQN8F8AcFY\">风控</a>\"模型和策略。</p><p></p><h5>InfoQ：可以结合具体例子介绍一下“特征工厂”是怎么运作的吗？</h5><p></p><p></p><p>丁清华：特种工厂的作用是进行风险特征计算，其中的计算方法和流程是根据融资申请来的，不同的产品和风险策略经理会提出一系列不同的风险特征需求。</p><p></p><p>例如，第一步先做反欺诈，确定核验客户的身份真实性，包括查证提供的手机号和身份证号在公安系统或其他可信渠道中是否为有效号码，是否被识别为黑名单，同时还要对活体进行检测校验；</p><p></p><p>第二步，进行用户评级，从客户的基本信息、人行征信信息、收入信息等多维度数据，去评价客户的等级；</p><p></p><p>第三步，根据客户的等级，核定最终的授信额度和定价。</p><p></p><p>在这个过程中，每个阶段需要调用哪些数据源进行计算，是由流程中的具体风控决策人决定的。</p><p></p><h5>InfoQ：那么，大数据技术是如何融入到我们整个风险特征计算平台中的？</h5><p></p><p></p><p>丁清华：特征计算首先要满足高并发，因为银行业务要能够应对瞬时的多客户业务申请，这要求我们的 TPS 达到几百以上，整个计算过程达到秒级；其次，要满足实时性，尤其对于华瑞银行这样以线上业务为主的银行机构来说，在消费贷场景，很多情况要求我们能够快速提供贷款决策。</p><p></p><p>为了实现这两个标准和目标，一方面，我们通过自己编写的程序和功能模块，满足高并发的数据接入、数据获取、数据拿回等需求；另一方面，在一定多的数据基础上，我们在 2020 年成立了大数据风控部门，采用商业化<a href=\"https://www.infoq.cn/article/2XcWWCNMYB39A1FVPiDQ?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\"> FLink</a>\" 实时计算框架，通过将任务进行细致的拆分，借助它强大的任务调度和管理功能，实现资源的定制化、合理化配置。</p><p></p><h5>InfoQ：在做计算框架选型时，我们主要考虑哪些因素？</h5><p></p><p></p><p>丁清华：首先，产品的成熟度，比如在金融行业是否有丰富的实施案例；其次，产品服务商的服务能力，比如持续升级和售后的能力，以及出现问题后的响应能力；其三，技术在业界的认可度，例如某些技术门槛太高或者冷门的技术，我们尽可能不去选择，因为一个普及的技术意味着掌握技术的人更多，解决问题的速度更快。</p><p></p><p>特别是对于华瑞银行这样的中小型银行而言，在做系统选型决策时，都要尽可能全方位地了解相关情况，结合拥有的资源，匹配最合适的技术和方案，从而减少试错成本的投入和没必要的浪费。</p><p></p><h5>InfoQ：目前整个风险特征计算平台运行情况如何，还有什么关键要突破的问题？</h5><p></p><p></p><p>丁清华：现在我们的整套框架已经初具规模，下一个要攻破的问题就一个字——快。</p><p></p><p>我们希望通过这个平台可以快速定义风险特征，比如，把一些功能开放给风险策略人员和模型人员，当他们发现新的风险情况时，就可以自主定义并新增上线一些特征，以及时地满足风险控制的需求。</p><p></p><p>而不是像现在这样，需要依赖定期窗口的科技版本发布才能新增特征。虽然我们通过管理手段，目前已经可以增加科技版本发布的频次，但是这并不是最终目标。我们计划在明年第二季度可以实现上述这些功能，比如，为策略经理提供更便捷的特征定义、配置、计算、测试、回溯和上线；为模型经理提供特征分布监控、稳定性分析、特征重要性分析等功能；为产品经理提供系统运行监控、元数据管理和分析、使用分析等功能，支持该功能的是丰富维度的风控数据和特征，以及各类风控特征的定制模版及支持函数。整个建设过程紧紧围绕“数据 + 风控 + 科技”的思路展开，发挥风险数据、策略模型和科技人员在各自领域的专业优势。</p><p></p><p>其中的关键突破点是在整个数字风控大脑体系的所有关键系统中支持低代码化和热部署，以便严格区分科技版本变更和风险特征变更，从而在不涉及科技版本迭代的前提下，实现自主的风险特征定制和策略迭代。</p><p></p><h5>InfoQ：之前行业内有蛮多人认为，除了互联网，比如阿里双十一这种场景，确实对实时性要求特别高需要用上 Flink，其他行业对实时计算的要求其实没有这么高，不一定非要用 Flink，在您看来是这样吗？</h5><p></p><p></p><p>丁清华：对于华瑞银行来说，我们的业务主体都在线上，想与其他传统的金融机构竞争，只有“唯快不破”。拿贷款申请举例，我们不能像传统金融那样，让客户等待一段时间，而是尽可能做到实时响应。这就要求风险系统架构可以实现准实时、秒级审批。</p><p></p><p>除此之外，华瑞银行还有一块业务是与互联网公司合作的，例如我们作为资金方，有一部分主要来自互联网公司，针对这部分流量入口的贷款申请，它就会与互联网业务的实时性要求一致。假如我们的审批响应速度太慢，流量可能就会分发给其他的资金机构。</p><p></p><h5>InfoQ：那么对于银行风控系统架构而言，除了实时性的要求，还有哪些别的要求是比较重要的？</h5><p></p><p></p><p>丁清华：<a href=\"https://www.infoq.cn/article/TcacE56EJzDfMlOYs3q1\">数据隐私问题</a>\"是银行特别关注的。在获取数据之前，我们必须获得用户的授权和认可，以便合理合法地使用这些数据。因此，在具体协议上会有对应的规范，包括约定用户数据的采集范围、采集用途以及数据存储方式等等都必须符合监管要求。</p><p></p><p>除此之外，风控特征的数量和质量代表着金融机构的风险管理和风控水平。在金融行业，风控数据数量和质量基本上就决定了机器学习或人工智能能力的天花板，选择合适的模型只能逼近上限。当风险特征数量越多、维度越多，我们对客户主体的认知就越全面，对交易风险的评估也更精准。</p><p></p><p>而风险特征平台的价值在于，尽可能降低技术的使用门槛，以便风险策略经理可以更便捷地挖掘出更多的风险特征，同时支持这些海量的数据计算。</p><p></p><p>在这个过程中，我们会帮风险人员把基础数据抽象成他们看得懂的数据，包括数据码齐、梳理，明确统计维度，如果是离散变量该如何处理，连续变量又该怎么处理。比如，某个客户在不同规模的银行机构的贷款金额、最近一次贷款的时间、借贷次数、逾期金额等等，这些都是不同的统计维度。我们需要把这些基础信息整理好，提供给风险人员基于这些数据，再用对应的风险评估方法进行特征计算。</p><p></p><h5>InfoQ：您认为如果把大模型放到现有的风控体系下，会发生什么样的“化学反应”？</h5><p></p><p></p><p>丁清华：首先，风控业务有一个特点，即风控决策需要具有可解释性。当某笔申请贷款审批通过或被拒绝，确定了某个贷款额度，背后的原因要能够解释，比如申请人的收入状况、违约记录等等，这些都是依据。但是，大模型在面对千亿级的参数或特征时，背后是没有对这些风险特征进行定义的，它中间缺少了一层可解释性。</p><p></p><p>另一方面，在风控领域使用大模型还需要解决数据数量和质量的问题。一是样本量要足够大，二是特征维度要足够多。但是，某个金融机构自身说掌握的数据是特别有限的，可能是某一部分人群的数据特征，或者某个地域人群的数据特征。</p><p></p><p>从目前来看，行业里还没有任何一家机构可以掌握能够达到如此庞大规模和覆盖面的风险特征数据（比如全国所有个人的基本信息、违约记录、消费习惯、交易流水等等），绝大部分全国性数据主要还是在政府机构、监管机构（人行、银保监会等）部门。</p><p></p><p>所以，如果要实现风控领域的大模型落地，我认为还是需要自上而下去推进。基于某个领域大模型，各个金融机构再按照自身的客群定位进行参数的微调。</p><p></p><p>这也是为什么大模型目前的落地主要还是集中在客服、营销、代码辅助、内部知识库共享等场景，因为该场景在互联网上有足够多的公开数据进行训练。对于金融机构而言，风控是非常核心的业务，距离落地应用还有一定的距离。一个重要前提是，模型的可解释性和<a href=\"https://www.infoq.cn/article/FK7BvgSk0p340NFjN6rZ\">数据归集</a>\"问题必须解决。</p><p></p><h5>内容推荐</h5><p></p><p>11月19日-20日在上海成功举办的首届 FCon 全球金融科技大会，以「科技 + 金融，激发创新力量」为主题，汇聚了来自金融龙头企业的数百名技术高管，掀起一场探讨新时代金融科技未来的高潮。经征得大会分享嘉宾同意，InfoQ 数字化经纬为您奉上精彩演讲 PPT！关注「InfoQ 数字化经纬」，回复「金融数智化」即可获取 PPT，深度洞悉科技趋势，助您引领金融创新未来！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/22/2271237afa20508ead9a2a3f86d7e71e.png\" /></p><p></p>",
    "publish_time": "2023-12-13 15:37:56",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "《云上新视界》特别筹划：使用FFmpeg以及GMAT在GPU上加速视频编解码",
    "url": "https://www.infoq.cn/article/6sukutzkZGDe1Pq9fpbQ",
    "summary": "<p>详解如何使用FFmpeg的GPU加速能力，并分析FFmpeg中对GPU支持的不足，以及如何应用GMAT进行改进。</p>",
    "publish_time": "2023-12-13 16:12:59",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "玩腻了CityWalk，不如来场构建者的生成式 AI BusTour",
    "url": "https://www.infoq.cn/article/ZvLIKAVY5zN2FrTWrO3H",
    "summary": "<p>全国巡回的不一定是演唱会，还可以是生成式 AI。</p><p>了解生成式 AI 不一定纯听分享，还可以来一场“未来旅行”。</p><p>&nbsp;</p><p>12月13日，一辆满载亚马逊云科技生成式 AI 黑科技的大巴车即将从上海发车，</p><p>启动一场【下一站 GenAI 】全国巡回之旅。</p><p>上海、南京、杭州（更多城市敬请期待）</p><p>&nbsp;</p><p>当穿越信息时代与智能时代的“九又四分之三”站台突然出现在你家门口，</p><p>这一定称得上是技术圈的顶级浪漫了！</p><p>上车！Let's 构，欢迎进入生成式 AI 的魔法世界~</p><p>&nbsp;</p><p></p><h2>够硬核的“构”</h2><p></p><p></p><h3>👉 亚马逊云科技 AI 历史墙</h3><p></p><p>&nbsp;</p><p>这是架时光机，带你穿越时空，</p><p>探索亚马逊云科技生成式 AI 的过去、现在和未来。</p><p>从基础模型训练与推理的基础设施，</p><p>到大语言模型及其他基础模型构建工具，</p><p>再到基于基础模型的生成式 AI 应用......</p><p>你能看到生成式 AI 发展的每一个脚印,</p><p>你可以和生成式 AI 从初创阶段到现在的每一个关键里程碑撞个满怀。</p><p>&nbsp;</p><p></p><h3>👉 re:Invent 全新发布的生成式 AI Demo</h3><p></p><p>&nbsp;</p><p>脑力空间的无限复制，生产效率再次迎来大幅提升，</p><p>没错，人类历史上的第四次技术革命，它来了！</p><p>在这样一个转折点，你永远无法预见下一次睁眼，</p><p>生成式 AI 将为我们的生活带来怎样惊人的改变，</p><p>却可以抢先对这个时代最新发布的 AI 产品、令人尖叫的技术进行体验。</p><p>不用去拉斯维加斯，</p><p>我们将 re:Invent 全新发布的 Demo 带到了你的身边！</p><p>&nbsp;</p><p></p><blockquote>Amazon Q全新的企业级生成式 AI 助手，根据业务为开发者量身定制！快速获得业务场景复杂问题答案、生成内容并采取行动。&nbsp;Amazon CodeWhisperer省心、省力、省时的 AI 编程助手。&nbsp;Amazon CodeCatalyst汇集计划、编码、构建、测试和部署其应用程序所需的一切，简化应用程序的开发与交付。</blockquote><p></p><p></p><h2>够炫酷的“构”</h2><p></p><p></p><h3>👉 构建者游乐场 PartyRock</h3><p></p><p>&nbsp;</p><p>让创意照进现实，竟然可以不掉头发！</p><p>操纵 PartyRock ，只需要几个点击，</p><p>就可以让 AI 帮你生成脑洞大开的应用程序。</p><p>总有一些任务，</p><p>不是自己干干不起，而是交给 AI 处理更有性价比。</p><p>在 【下一站 GenAI 】构建者游乐场，</p><p>感受创意与 AI 的完美结合，开启一段奇妙的创意之旅！</p><p>&nbsp;</p><p></p><h3>👉 最新生成式 AI Jam 挑战</h3><p></p><p>&nbsp;</p><p>边玩边学生成式 AI ！</p><p>如果你厌倦了传统的培训方式，</p><p>那么一定要来生成式 AI Jam 挑战打卡！</p><p>游戏化的上手学习体验</p><p>无痛快速提升生成式 AI 时代的开发技能。</p><p></p><p>终结孤单，制作一个虚拟聊天朋友让 AI 与你共同开启艺术创作使用Amazon SageMaker 创作专属内容感受 Amazon CodeWhisperer 的文件迁移超能力......</p><p></p><p>够胆量你就来！</p><p>12个2023 re:Invent 最新发布的 Jam 挑战免费体验</p><p>完成超过3个，有惊喜！！！🎁</p><p>&nbsp;</p><p></p><h2>够有料的“构”</h2><p></p><p>&nbsp;</p><p></p><h3>👉 八大免费的全新生成式 AI 课程</h3><p></p><p>&nbsp;</p><p>在这辆停靠在路边的大巴车内，一个宏大的计划正悄然铺展，</p><p>他们称之为“AI 就绪”计划，</p><p>一场预计在 2025 年前将至少 200 万人卷入其中的神秘行动。</p><p>&nbsp;</p><p>没有人知道这个计划的全部内容，</p><p>只有一份神秘的线索在暗中流传：</p><p>他们将提供免费的生成式 AI 课程。</p><p>掌握低代码的机器学习模型部署、</p><p>学习如何构建语言模型、</p><p>甚至精通如何利用生成式 AI 工具与服务改进工作流程与提升工作效率。</p><p>&nbsp;</p><p>在科技的黑暗森林中，这将是一场怎样的游戏？</p><p>我们只能静静等待......</p><p>而你，准备好成为故事的主角了吗？</p><p></p><h3>👉 专属亚马逊云科技认证折扣</h3><p></p><p>&nbsp;</p><p>想成为炙手可热的 AI 人才？想要解锁更高的职业薪酬？</p><p>据 Skillsoft 发布的《2022年IT技能和薪资报告》显示，</p><p>在北美地区前 15 个最高薪酬的 IT 认证中，亚马逊云科技独占 5 席；</p><p>而在亚太地区前 10 名中，亚马逊云科技更是占据 4 席。</p><p>&nbsp;</p><p>在全球，已有超过 100 万人荣获亚马逊云科技认证，</p><p>这绝不仅仅是一张证书，</p><p>而是一块更高薪水与职业发展的敲门砖！</p><p>&nbsp;</p><p>亚马逊云科技认证限时折扣等你来拿！</p><p>抓住这个机会，提升自己的技能和竞争力！</p><p></p><p>够硬核！够炫酷！够有料！</p><p></p><p>六大惊喜集聚，还不足以给你一个 Go 的理由吗?</p><p>下一站 GenAI</p><p>码上出发，Let's 构</p><p>让我们携手踏上这段充满无限可能性的旅程！</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/9b/66/9b48381f34acc6d62f637b76a40d9d66.jpg\" /></p><p></p><p></p>",
    "publish_time": "2023-12-13 18:32:22",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]