[
  {
    "title": "经历了千锤百炼，火山引擎RTC如今怎么样了？",
    "url": "https://www.infoq.cn/article/Ue0E2ZXpr2BwaYxlQ0fL",
    "summary": "<p>Qcon 上海站 2022 年大会在上海降温前的最后一个周末落下了帷幕。</p><p></p><p>近两年，随着音视频行业的快速发展，RTC 相关的话题在 QCon 的比重也逐步上升。本次 QCon 除了腾讯云音视频、网易智企两家熟悉的身影，火山引擎 RTC 也首次以专场的形式亮相，并为观众带来了 RTC 与业务增长、用户体验优化、特效协同、全球化架构四个主题的技术分享，现场一度座无虚席，甚至连门口和过道都挤满了观众。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/60/60e2f4d896a1af0ffa298d3cb4a683d4.png\" /></p><p>火山引擎 RTC 专场以<a href=\"https://www.infoq.cn/album/88\">《实时音视频技术在抖音上的深度磨砺》</a>\"为主题</p><p></p><h2>火山引擎 RTC 的破圈之道</h2><p></p><p></p><p>2021 年，字节跳动正式推出云服务——火山引擎，并发布面向体验的视频云服务，覆盖视频直播、点播、实时音视频、云游戏和云渲染等多个场景所需的核心中台、产品及解决方案。2022 年下半年，快手正式推出“ StreamLake ”视频云品牌，主要聚焦“音视频 + AI ”。两家互联网大厂的接连入局，让原本就已经硝烟弥漫的视频云江湖厮杀得越发激烈，特别是在 RTC 领域，前有声网 Agora、网易云信等垂直 PaaS 玩家，后有阿里云、腾讯云、华为云等老牌云计算平台，字节、快手以自家产品技术中台 ToB 的方式入局，让这条视频云新赛道“卷”上了一个新台阶。</p><p></p><p><a href=\"https://www.infoq.cn/article/yaV5V1R0iuUvpbrBIJYq\">火山引擎 RTC </a>\"凭什么卷？在本次专场分享中，火山引擎 RTC 传达了它的破圈门道：从业务视角出发，持续在对业务有增长的技术上进行打磨和沉淀。</p><p></p><p>作为偏底层的音视频服务，RTC 和应用的业务表现似乎没有什么关系，然而，火山引擎 RTC 通过大量的 A/B test 发现，RTC 的表现会对业务的增长有着不小的影响。在连麦场景，当建联越快、建联成功率越高、主播画面越清晰、卡顿越低，人均的连麦时长、看播人数、打赏金额就会越多。换句话说，这几个指标是连麦场景的核心关注指标，RTC 需要更关注这几个指标的迭代优化。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/13/13f08e230d9e10b669b771c160383c44.png\" /></p><p>目前，火山引擎 RTC 为抖音连麦提供的建联信令 200ms 达到率为 98.6%，端到端延时平均 51ms，首帧延时控制在 100-200ms 之间</p><p></p><p>新玩法为业务带来了增长，也为 RTC 带来了挑战，当功能越来越复杂，性能消耗越来越大，如何在保证用户体验的同时降低性能消耗，以覆盖更多中低端机型，降低用户互动的准入门槛？在边聊边看、边聊边玩、在线唱 K 等场景中，当人声、媒体声、噪声混在一起，用户音频体验如何保证？在和业务方打磨的过程中，火山引擎 RTC 在全链路路径上不放过每一个可优化的细节，并通过与美颜、播放器、深度学习算法等技术的协同优化，以及与线上机型、声卡设备的全量适配，为所有用户带去一致的、高质量的音视频互动体验。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a2/a20687cfa322f31e2417a4c355111943.png\" /></p><p></p><p>火山引擎 RTC 支持抖音世界杯<a href=\"https://www.infoq.cn/article/VhJrF0rKTF1fDRGlTcdo\">“边聊边看”</a>\"功能，利用“音频托管”，避免了直播解说音频和用户聊天音频的回声效果，同时，当有用户说话时，解说的音量会自动“闪避”压低，确保用户聊天内容被清楚听到</p><p></p><h2>至今无统一标准，用户体验该如何衡量</h2><p></p><p></p><p>一直以来，字节跳动都以“数据驱动增长”和“全链路的数据体系构建”作为和其他互联网厂商的能力区别之一，火山引擎 RTC 把这套方法论也用到了“衡量用户体验”上。</p><p></p><p>衡量用户体验不是一件容易的事，至今业内也未形成统一的标准。专场的第二部分是关于数据驱动的 RTC 体验优化，第一件事就是介绍如何把 QoS 指标定义准确，让它能够真实地反映用户体验。火山引擎在定义 QoS 指标时做了三个“对齐”——对齐最小用户行为粒度、对齐最小用户感受的阈值、以及在计算时对齐用户行为和反馈，前两个对齐让 QoS 指标更严苛、灵敏，后者则可以消除幸存者偏差，让 QoS 指标尽可能的客观、透明，可验证性更强。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0b/0b1a4e9ed0e86cfea7ebc18c2bf2a54a.png\" /></p><p>以“首帧发送成功率”为例，火山引擎 RTC 不仅关注用户进房瞬间的首帧成功率，也关注每次关闭 / 打开摄像头、关闭 / 打开麦克风的首帧成功率</p><p></p><p>通过优化 QoS 指标可以优化 QoE，进而影响业务指标。然而，总有一些用户体验不好的问题落在 QoS 指标之外，比如无声、回声、模糊等异常问题，它们很难通过标准的 QoS 指标来监控，排查起来很困难——这可能是业务最大的痛了，又要解决用户体验，又不知从何处下手。</p><p></p><p>火山引擎 RTC 基于抖音集团产品、每天 3 万 + 的用户的真实评价，提炼出这些反馈背后的数据特征，并通过一系列校准和验证，建立了一个超大的“异常特征库”——以后一旦用户埋点数据命中异常特征库的规则，就可以认为这个用户很可能遇到了历史用户反馈过的异常问题，因此可以非常快地定位问题根因并及时处理，这对于处理那些无法用 QoS 监控的 QoE 问题有非常大的价值。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/58/58e501e76bdeeaabb462081855c1c0cc.png\" /></p><p>以“无声”为例，火山引擎 RTC 将“无声”问了拆解成“听不到对方声音”（上行无声）和“对方听不到我声音”（下行无声）两类，总结了 mic 被占用、声道选择错误、播放帧率异常等 30+ 归因</p><p></p><p>一方面，通过 QoE 来去验证和打磨 QoS 指标，让 RTC 的 QoS 指标能够更真实地反映用户的体验，同时找到技术优化的最佳路径；一方面，建立业内最大的“异常特征库”来处理 QoS 无法覆盖的 QoE 问题，这是火山引擎 RTC 独一无二的数据分析方法论和实践经验。</p><p></p><h2>端云协同，1+1 如何大于 2</h2><p></p><p></p><p>除了 RTC，专场还邀请到音视频特效负责人来分享抖音集团在做“极致”美颜特效过程中的沉淀和思考。</p><p>音视频场景离不开美颜、滤镜、贴纸等特效的使用，AI 特效技术在视频云业务中是不可或缺的重要能力。今年 7 月，火山引擎在 2022 火山引擎 FORCE 原动力大会上发布的音视频云端一体 veVOS 便是整合了视频直播、实时音视频、智能视频创作、视频点播、智能美化特效、智能音频美化等音视频能力的一站式解决方案。</p><p></p><p>抖音画质，特别是美颜，名声在外，如何让 RTC 和美颜特效算法做到真正协同，发挥最强效果，同时尽可能优化这两个“性能消耗大户”叠加后的能耗，让高质量的互动特效可以在更多手机，特别是中低端手机上跑起来，是视频云和特效一起在努力做的事。</p><p></p><p>“有一些客户会认为画质是美颜引起的，我用的美颜和抖音一样，就可以有和抖音一样的完整流程体验了”。实际上，画质并不仅仅依赖美颜一个环节，音视频采集、编解码、算法、视频云架构、播放，这些过程中的组件都对画质的整体链路负责，正如讲师所说，“我们非常认真的去对待、优化画质的每一方面，希望用户在最后使用时能对这个产品有更好的认同度”。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/55/55d30a6eca6f1097e2cedeeda7623108.png\" /></p><p>通过一份”剪映与同类产品的画质评测报告”，讲师和观众介绍画质优化的价值</p><p></p><h2>出海或将成为 RTC 的必选项？</h2><p></p><p></p><p>这几年，国内视频云市场增长稍显乏力，而各类优秀出海应用层出不穷，“出海”也因此成为了视频云厂商寻找增量市场的重要方向，声网、腾讯云音视频等都在不断加快海外布局的脚步。专场的最后一个分享主题是关于 RTC 全球化架构设计，火山引擎通过多中心网络架构、边缘下沉、媒体 - 信令统一接入等关键架构设计，来保证媒体与信令的实时性和同步性。不难想象，有着全球实时传输网络架构的基础和诸多产品的打磨沉淀，火山引擎 RTC 在应对海外参差的网络基建、复杂的运营商、繁杂海量的机型等问题时，也能表现得一如既往的出色。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/45/4503773d052ec31a3c42dd51f4646092.png\" /></p><p>讲师在介绍 RTC 媒体全球化架构设计要点</p><p></p><p>IDC 在《超视频时代视频云演进趋势》白皮书提出，超视频时代用户的三大核心需求是：更加高清、更加交互、更加沉浸。当我们在抖音上看着 4K 超高清的画面，为梅西的贴地斩和朋友一起欢呼时，谁能想到，几年前，我们不得不牺牲清晰度来观看一场流畅的赛事直播，同时还要忍受“对面已然进球欢呼，而我还在屏气流汗”的尴尬。RTC 赛道“众人拾柴火焰高”的局面将推动迎来音视频玩法和体验的新时代，至于谁能笑到最后，就看谁真正掌握了业务需求和破解密码。</p>",
    "publish_time": "2022-12-14 10:13:15",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "谷歌发布安卓应用模块化指南，重点关注代码库增长出现的问题",
    "url": "https://www.infoq.cn/article/XX3FLiGmtb9phU80VyRH",
    "summary": "<p>最近，谷歌发布了一份关于安卓应用模块化的指南。该指南旨在为开发人员提供构建多模块安卓应用的最佳实践和模式，重点关注在代码库增长时出现的问题，如可伸缩性、可读性、稳定性和可测试性。</p><p>&nbsp;</p><p>在一项关于开发者模块化经验的调查中，54%的参与者表示很难找到关于模块化的学习资料，95%的人表示developer.android.com网站上的资料不足够，于是谷歌决定发布一份<a href=\"https://developer.android.com/topic/modularization\">安卓应用模块化指南</a>\"。需要注意的是，该指南针对的是中级和高级开发人员，他们通常对<a href=\"https://developer.android.com/topic/architecture\">推荐的应用架构</a>\"更为熟悉。</p><p>&nbsp;</p><p>据谷歌称，他们的一些应用已经在使用模块化，如Play Store、Google News和YouTube。</p><p>&nbsp;</p><p>模块化就是将代码库组织成松散耦合的多个部分，这些部分通常叫作模块。每个模块必须是独立的，且有明确的职责。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fa/faed052d65fbada17991380c6ee14a07.png\" /></p><p></p><p>（图片来自<a href=\"https://developer.android.com/topic/modularization\">https://developer.android.com/topic/modularization</a>\"）</p><p>&nbsp;</p><p>模块化带来了许多好处，降低了设计复杂性，让大型系统的维护和演化变得更容易。让我们来看看这些好处：</p><p>&nbsp;</p><p>可重用性——提供了共享代码和使用相同模块构建多个应用的可能性。一个应用由许多模块组成，其中每个模块负责特定的功能。严格的可见性控制——开发人员可以很容易控制应该向代码库和模块的其他部分公开哪些东西。自定义交付——<a href=\"https://developer.android.com/guide/playcore/feature-delivery\">Play Feature Delivery</a>\"允许开发者有条件地或按需交付应用的特定功能。</p><p>&nbsp;</p><p>模块化还有其他好处，例如：</p><p>&nbsp;</p><p>可伸缩性——如果项目进行了适当的模块化，通常会有<a href=\"https://en.wikipedia.org/wiki/Separation_of_concerns\">关注点分离</a>\"和松散耦合的代码库，从而更容易维护和演变。所有权——模块可用于加强问责，有专门的所有者负责维护代码、修复bug、添加测试和评审变更。封装性——一个模块对其他部分的了解应该尽可能少。独立的代码更容易阅读、理解和演化。可测试性——测试代码的能力，测试模块比测试大型紧密耦合的系统更容易、更快。构建时间——与增量构建、构建缓存或并行构建相关，<a href=\"https://gradle.org/\">Gradle</a>\"的一些功能可以利用模块化来提高构建性能。</p><p>&nbsp;</p><p>谷歌在<a href=\"https://github.com/android/nowinandroid\">GitHub代码库</a>\"中提供了多模块应用Now in Android的代码，还提供了一个<a href=\"https://github.com/android/nowinandroid/blob/main/docs/ModularizationLearningJourney.md#types-of-modules-in-now-in-android\">模块化之旅</a>\"指南，介绍了模块的功能以及它们之间的交互方式。</p><p>&nbsp;</p><p>该指南还有一部分是关于<a href=\"https://developer.android.com/topic/modularization/patterns\">常见模块化模式</a>\"的，你可以在这部分看到低耦合高内聚、<a href=\"https://developer.android.com/topic/modularization/patterns#data-modules\">数据模块</a>\"、<a href=\"https://developer.android.com/topic/modularization/patterns#feature-modules\">特性模块</a>\"、<a href=\"https://developer.android.com/topic/modularization/patterns#app-modules\">应用模块</a>\"、<a href=\"https://developer.android.com/topic/modularization/patterns#common-modules\">公共模块</a>\"等等。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/11/android-modularization-guide/\">https://www.infoq.com/news/2022/11/android-modularization-guide/</a>\"</p><p></p><p>相关链接：</p><p><a href=\"https://www.infoq.cn/article/4u0MQ4321CGS7uEAygpY\">你的 Flutter 应用该考虑迁移代码了：Dart 3 将在 2023 年成为 100% 健全的空安全语言</a>\"</p><p><a href=\"https://www.infoq.cn/article/F1F3Q7Ptb1jM2ptmGbOG\">Vue 3 不是最佳选择? 耗时两周从 Vue 2 迁移到 Svelte 后：代码执行更快、体验更佳</a>\"</p>",
    "publish_time": "2022-12-14 10:31:12",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Dubbo 正式支持 Spring 6 & Spring Boot 3",
    "url": "https://www.infoq.cn/article/LAvbFBiTzeXeqQ2CzAsi",
    "summary": "<p></p><h2>背景</h2><p></p><p>Spring Framework 6.0 于11月16日正式发布 GA 版本，Spring Boot 3.0 也于11月25日正式发布 GA 版本，并且Spring 6 &amp; SpringBoot 3最低支持JDK17，意味着如果升级使用Spring 6 &amp; Spring Boot 3时就必须需要升级使用JDK17。</p><p></p><p>然而Java 8 目前是国内主流生产环境 Java 版本之一。虽然近几年陆续发布了 Java 11、Java 17 官方 LTS 版本，但是大部分开发者依然本着 “你发任你发，我用Java8” 的看法看待JDK的升级。不过 Java 17 版本在性能上确实做了大量的优化特别是 ZGC 的发布，促进了国内不少企业升级到 Java 17。</p><p></p><p>而Spring 框架在 Java 生态中的重要程度不言而喻，我们相信在Spring 这波“最低支持JDK17” 推动下，Spring Framework 6.0 &amp; Spring Boot 3.0 一定会在不久的将来被大家接受，并成为主流技术栈。</p><p></p><p>Dubbo 社区非常重视 Spring 社区的更新迭代，总会积极支持适配，这点在最近Spring 6.0 和 Spring Boot 3.0 发布中同样得到了验证。Dubbo 社区早在Spring 6.0.0-RC4 和 Spring Boot 3.0.0-RC2 时已经做好了大致的兼容适配，但是为了保证Dubbo 能够完全适配 Spring 6 和 Spring Boot 3.0 的正式版，我们一直等到Spring Boot 3.0 GA 后，才选择宣布这个令人高兴的事情。</p><p></p><h2>为什么要升级到 Spring 6.0 &amp; Spring Boot 3.0</h2><p></p><p>首先是，升级到 Spring 6.0 &amp; Spring Boot 3.0 将获得未来很长年限的由官方提供的免费技术支撑。Spring 6 和 Spring Boot 3 是 Spring 下一代技术框架基石，尽管官方当前同时维护了 Spring 5.3 和 Spring Boot 2.6.x 和 Spring Boot 2.7.x，但它们最终都会在 2025 年和 2026 年结束其 OSS support（Open Source Software Support）。</p><p></p><p>其次是，您将在新一代框架中获得大量新特新，这些新特性都可以在 <a href=\"https://github.com/spring-projects/spring-boot/wiki/Spring-Boot-3.0-Release-Notes\">Spring Boot 3.0 Release Notes</a>\"（https://github.com/spring-projects/spring-boot/wiki/Spring-Boot-3.0-Release-Notes） 和 <a href=\"https://github.com/spring-projects/spring-framework/wiki/What's-New-in-Spring-Framework-6.x\">What's New in Spring Framework 6.x</a>\"（https://github.com/spring-projects/spring-framework/wiki/What's-New-in-Spring-Framework-6.x） 中获得。</p><p></p><p>最后是，Spring 6.x 和 Spring Boot 3.x 将会最广泛的支持 JDK 17-29，需要额外说明的是 JDK17 作为当前最新的LTS 版本，它提供了一组累积的最新语言、API 和 JVM 增强功能，使其成为更具吸引力的编译版本的升级，这也是为什么最低支持 JDK17 的原因。</p><p></p><h2>Dubbo 支持 Spring 6 &amp; Spring Boot 3</h2><p></p><p>现在很高兴向大家宣布，Dubbo 已经开始兼容Spring 6 &amp; Spring Boot 3，所以当前Dubbo 3.2.0-beta.2 版本可以同时兼容支持Spring Boot 1.x、2.x、3.x。您现在可以使用dubbo-3.2.0-beta.2版本体验其兼容性。</p><p></p><p><code lang=\"java\">\n  org.apache.dubbo\n  dubbo-spring-boot-starter\n  3.2.0-beta.2\n\n</code></p><p></p><p>更多关于Spring Boot 3.0 集成 Dubbo 使用示例可参见apache/dubbo-sample：<a href=\"https://github.com/apache/dubbo-samples/tree/master/1-basic\">https://github.com/apache/dubbo-samples/tree/master/1-basic</a>\"</p><p></p><h2>升级总结</h2><p></p><p>我们根据Dubbo 兼容适配Spring 6 &amp; Spring Boot 3 过程中总结的经验整理如下，其他组件维护者也可以参考以下经验进行适配或者升级，更早适配升级到最新版本：</p><p></p><h3>Jakarta EE</h3><p></p><p>Jakarta EE 9 将所有API包名从javax.*命名空间变更到了jakarta.*。而造成这一变化的原因是Oracle拒绝交出相关权益，详情可以查看：https://www.oschina.net/news/106465/oracle-killed-java-ee。</p><p></p><p>因为Jakarta EE 的迁移，对于Web Apps，确保升级使用Tomcat 10, Jetty 11, or Undertow 2.2.19。</p><p></p><p>以下列出了一系列工具可以帮助你完成这部分的迁移：</p><p></p><p><a href=\"https://docs.openrewrite.org/reference/recipes/java/migrate/javaxmigrationtojakarta\">OpenRewrite recipes</a>\".<a href=\"https://github.com/spring-projects-experimental/spring-boot-migrator\">The Spring Boot Migrator project</a>\".<a href=\"https://blog.jetbrains.com/idea/2021/06/intellij-idea-eap-6/\">Migration support in IntelliJ IDEA</a>\".</p><p></p><h3>移除META-INF/spring.factories文件对Auto-configuration的支持</h3><p></p><p>Spring Boot 3.0移除了META-INF/spring.factories文件对Auto-configuration的支持，为了兼容性，SpringBoot 2.7.x 是最后一个支持的版本。</p><p></p><p>适配支持按照下面两个步骤即可完成。</p><p></p><p>Step1: [可选] 使用 <a href=\"https://www.infoq.cn/AutoConfiguration\">@AutoConfiguration </a>\" 注解代替 [@Configuration(proxyBeanMethods ](/Configuration(proxyBeanMethods ) = false)</p><p></p><p><a href=\"https://www.infoq.cn/AutoConfiguration\">@AutoConfiguration </a>\" 注解是SpringBoot 2.7中的新引入的注解，旨在专门标识Auto-configuraton class name。</p><p></p><p>依然使用@Configuration注解标识自动适配类也是可以的，Dubbo 正是基于这个便利点完美支持了Spring Boot 1.x、2.x、3.x所有版本。</p><p></p><p>Step2: 使用 AutoConfiguration.imports 文件代替 META-INF/spring.factories 文件</p><p></p><p>Spring Boot 2.7是最后一个依然兼容使用spring.factories 的版本，SpringBoot 3 以后不再兼容，此时您应该使用META-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports文件替换。</p><p></p><p>在该文件列举你所有的configuration classes，每行一个class name，例如：</p><p></p><p><code lang=\"java\">com.mycorp.libx.autoconfigure.LibXAutoConfiguration\ncom.mycorp.libx.autoconfigure.LibXWebAutoConfiguration\n</code></p><p></p><h3>为了对齐ISO-8601，使用yyyy-MM-dd'T'HH:mm:ss.SSSXXX作为默认日志日期格式</h3><p></p><p></p><p>原来默认日志日期格式：yyyy-MM-dd HH:mm:ss.SSS当前默认日志日期格式：yyyy-MM-dd'T'HH:mm:ss.SSSXXX。</p><p></p><p>原来的默认日志日期格式不具有timezone / offset 信息。</p><p></p><p><code lang=\"java\">yyyy-MM-dd'T'HH:mm:ss.SSSXXX &gt;&gt;&gt; e.g.: 2014-12-03T10:06:04.646+08:00\n</code></p><p></p><h3>移除YamlJsonParser</h3><p></p><p>Spring Boot 官方测试发现YamlJsonParser并不能很好的解析JSON，Spring Boot 3决定不再支持使用它来作为解析JSON的备选。</p><p></p><p></p><blockquote>YamlJsonParser 封装的是 snakeyaml。</blockquote><p></p><p></p><p>Spring Boot 3 解析JSON 的解析器使用优先级如下：</p><p></p><p>1）JacksonJsonParser2）GsonJsonParser3）BasicJsonParser</p><p></p><h3>移除spring.session.store-type 配置键</h3><p></p><p>移除了spring.session.store-type配置项，当存在多个可用存储库，将会按照Redis，JDBC，Hazelcast，Mongo 顺序使用。</p><p></p><h3>更新spring data 配置键使其清楚地反应该配置键是否依赖Spring Data</h3><p></p><p>如果存储库（redis、mongo等）相关的配置键不依赖Spring Data存在，则只需要 spring 前缀，否则需要使用 spring.data 前缀。</p><p></p><p>举例说明：</p><p></p><p><code lang=\"java\">spring.redis.host &gt;&gt; spring.data.redis.host\n\nspring.redis.port &gt;&gt; spring.data.redis.port\n\nspring.data.cassandra.port &gt;&gt; spring.cassandra.port\n</code></p><p></p><h3>重构HttpMethod 枚举为类</h3><p></p><p>根据最新的<a href=\"https://datatracker.ietf.org/doc/html/rfc2616#section-5.1.1\">rfc2616</a>\"，HTTP Method已经属于不可枚举属性，所以重构HttpMethod enum类为class类。</p><p></p><p>除了我们熟知的GET, HEAD, PUT, POST等方法，现在还存在了可扩展方法，当前可扩展方法包含了LOCK, COPY, 和 MOVE。这些扩展方法定义在WebDAV。</p><p></p><h3>不允许URI尾部斜杠匹配</h3><p></p><p>Spring 6之前，访问 “/resources” 和 “/resources/” 都可以进入resources()方法。</p><p></p><p><code lang=\"java\">@GetMapping(\"/resources\")\nString resources() {\n    return \"Hello from /resources\";\n}\n</code></p><p></p><p>Spring 6之后，您只能通过看到的path “/resources” 进入mapping 方法。</p><p></p><p>如果您依然想让“/resources/” 和 “/resources” 进入相同的mapping方法，可以通过其他手段，诸如“反向代理”、“Servlet/Web 过滤器”或“在控制器配置显式重定向”。</p><p></p><h3>提供基于 <a href=\"https://www.infoq.cn/HttpExchange\">@HttpExchange </a>\" 服务接口的 HTTP 客户端</h3><p></p><p>Spring 6 介绍了<a href=\"https://www.infoq.cn/HttpExchange\">@HttpExchange </a>\" 注解，基于@HttpExchange注解可以简化HTTP远程调用。</p><p></p><h3>增强Spring SPI 加载器 SpringFactoriesLoader 允许加载多自定义文件</h3><p></p><p>Spring 6 之前，SpringFactoriesLoader 只允许加载\"META-INF/spring.factories\"文件内容。</p><p></p><p>Spring 6 之后，SpringFactoriesLoader 可以加载自定义文件或文件名文件，并且可以通过链式编程加载多个文件。</p><p></p><h3>早期兼容JDK19预览版的虚拟线程（virtual threads）</h3><p></p><p>可以在Spring 6 和Spring Boot 3 中使用虚拟线程处理请求来提前体验。</p><p></p><p>这部分详细说明参见：<a href=\"https://spring.io/blog/2022/10/11/embracing-virtual-threads\">https://spring.io/blog/2022/10/11/embracing-virtual-threads</a>\"</p><p></p><h3>支持RFC 7807 Problem Details</h3><p></p><p>Spring 6 以后，Spring MVC 可以使用 application/problem+json media 类型自定义 错误信息响应体，像下面这样：</p><p></p><p><code lang=\"java\">{\n  \"type\": \"https://example.org/problems/unknown-project\",\n  \"title\": \"Unknown project\",\n  \"status\": 404,\n  \"detail\": \"No project found for id 'spring-unknown'\",\n  \"instance\": \"/projects/spring-unknown\"\n}\n</code></p><p></p><h2>展望</h2><p></p><p>在云原生时代，Java 的跨平台特性，已经不算是其亮眼特性了，而其 Jar 包体积大、启动慢、占用内存多、需要另装 JVM 是 Java 应用的痛点问题。</p><p></p><p>而通过使用 GraalVM 可以很好的解决这些问题。并且通过 GraalVM 的 AOT（Ahead-Of-Time）可以将应用编译成单独可执行文件并直接运行。</p><p></p><p>未来 Dubbo 将会积极地在 Native 方面做一些工作以此能够使应用程序达到下面的目标</p><p></p><p>支持 Spring &amp; Spring Boot native-image较小的本地应用程序和容器镜像占用空间快速启动，快速启动（几十毫秒）低内存消耗，减少 RSS（驻留集大小），低内存有助于优化需要多个容器的微服务架构部署中的容器密度快速的第一请求响应，避免 Hotspot 的预热问题</p><p></p><p>相关阅读</p><p><a href=\"https://www.infoq.cn/article/F3I9jfBsZ4cyE2aD7K8U\">Spring Modulith使用模块和事件组织Spring Boot 3应用</a>\"</p><p><a href=\"https://www.infoq.cn/article/GGdb3Y7cO9Pw2Bf8NfIW\">Java新闻汇总：Spring发布，Resilience4j，Open Liberty，GlassFish，Kotlin 1.8-Beta</a>\"</p>",
    "publish_time": "2022-12-14 11:44:33",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "有奖征文 | “用 TDengine，写 TDengine”，万元大奖等你来瓜分！",
    "url": "https://www.infoq.cn/article/381585f92975e45476d557fe6",
    "summary": "<p></p><p>2022 年即将走过，而&nbsp;<a href=\"https://www.taosdata.com/\">TDengine</a>\"&nbsp;在这一年的进步大家有目共睹，不仅 GitHub 突破了&nbsp;20000&nbsp;Star，全球安装实例直线上涨到了&nbsp;178.1k，受到国内外开发者更广泛的关注。在产品迭代上更是推出了&nbsp;3.0 版本，叠加了云原生、流计算等创新元素，解决了时序数据库业内难解的高基数难题，还对查询引擎、存储引擎进行了进一步的优化与升级……</p><p></p><p>如果你也一直在关注着 TDengine，那你也一定有很多想对 TDengine 说的话，或者想分享的 TDengine 实用经验，那不妨用键盘把它们“敲”出来，和我们一起共同推动和记录 TDengine 的每一次进步。</p><p></p><p>叮铃铃铃~~2022 年度“用 TDengine，写 TDengine”有奖征文活动如期而至，赶快打开你的电脑，把你与 TDengine 在 2022 年发生的故事用文字说给大家。只要参与投稿，你就有机会获得我们精心准备的精美奖品，如果你能在投票环节脱颖而出，那就可以拿走科技感十足的前三等大奖了（下滑揭晓奖品名单）！所有的奖品我们都会赶在大年三十之前邮寄给获奖选手，也希望这份“新年礼品”能为大家新的一年带来一份“好彩头”~</p><p></p><h2>Part.1 如何参与</h2><p></p><p></p><h4>内容创作范围</h4><p></p><p>（字数要求：1000字以上）</p><p>TDengine 3.0 的学习和使用经验TDengine 业务落地实践TDengine 改造原有架构的经验分享TDengine 集群使用实践TDengine 业务建模思考TDengine 3.0 代码分析</p><p></p><h4>了解 TDengine 的渠道</h4><p></p><p>官网：https://www.taosdata.com/GitHub 社区：https://github.com/taosdata/TDengine</p><p></p><h4>投稿方式</h4><p></p><p>第一步：稿件完成之后发布至官方合作媒体平台“InfoQ 写作平台”，标注好作者名</p><p>第二步：加小助手小T微信号（ID：tdengine），将发布后的链接推送给小T</p><p><img src=\"https://static001.geekbang.org/infoq/68/68037f42af81f0920a043221ce20c0fb.png\" /></p><p>第三步：小T会给参赛者同步发送一则原创声明，参赛者签署后立即生效以上所有操作完成后投稿即成功。</p><p></p><h4>活动时间节点</h4><p></p><p><img src=\"https://static001.geekbang.org/infoq/e7/e7c52bfac87f107f995af23d4be61599.jpeg\" /></p><p>本次活动的截止投稿日期为 2023 年 1 月 6 日24:00，稿件收集到位之后我们会基于上述创作条件先进行一轮筛选，筛选时间为 1 月 7 日-8 日 24:00；符合上述创作条件的优质稿件将会通过 TDengine 公众号进行公示投票评选，投票时间为 1 月 9 日-11 日 24:00；最后我们会在 1 月 12 日进行最终的获奖人选揭晓并进行线上“颁奖”，为最终的获奖选手邮寄我们的大奖！</p><p></p><h2>Part.2 你将获得</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/18/18b9c18b205e7e5dfc663bdf3ba9147d.jpeg\" /></p><p>关于奖品如何获得，在此我们也做下详细说明。只要你的投稿按规则发布在了官方合作媒体平台InfoQ上，就能收获一份参与奖（TDengine 精美周边），作为对 TDengine 支持的感谢礼。</p><p>如果你的投稿在投票环节中以前六名的好成绩胜出，那恭喜你~我们会按照名次依次送出一二三等奖。还在等什么，赶紧构思一下你的行文思路吧！</p><p></p><p>书写技术实践上的每一次灵感</p><p>我们以文汇友</p><p>让这些经验以文字的形式沉淀下来帮助到更多的伙伴愿你我都能成为技术创新的引路人</p>",
    "publish_time": "2022-12-14 14:48:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "想彻底改变云行业！Spark发源地UC伯克利分校再推开源项目应对云成本飙升：平均降至三分之一",
    "url": "https://www.infoq.cn/article/S3tRHVqd5Al23NOMpVXS",
    "summary": "<p></p><p>近日，加州大学伯克利分校的 Sky Computing 实验室发布了开源框架 SkyPilot，这套框架能够在任何云环境上无缝、且经济高效地运行机器学习与数据科学批量作业，适用于多云和单云用户。SkyPilot 的目标是大大降低云使用门槛、控制运行成本，而且全程无需任何云基础设施专业知识。</p><p></p><p>SkyPilot GitHub 地址：</p><p><a href=\"https://github.com/skypilot-org/skypilot\">https://github.com/skypilot-org/skypilot</a>\"</p><p></p><p>据悉，Sky Computing 实验室研发了一年多的时间，SkyPilot 现在已经被 10 多家组织用于多种不同的场景，包括：GPU/TPU 模型训练（将成本降低至三分之一）、分布式超参数调优及百余个 CPU 竞价实例上的生物信息学批量作业 （循环运行成本降低至 1/6.5）等。</p><p></p><h4>将云成本平均降至三分之一？</h4><p></p><p></p><p>根据官方介绍，只要给定一项作业及其资源需求（CPU/GPU/TPU），SkyPilot 就能自动找出哪些位置（区 / 区域 / 云）具备运行该作业的计算资源，之后将负载发送至成本最低的位置执行。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/77/77301a5d93f94f5097c1bb103588a8e5.png\" /></p><p></p><p>SkyPilot 自动在云端执行各项作业，主要包括：</p><p></p><p>以高可靠方式交付集群，如果发生容量或配额错误，则自动故障转移至其他位置。将用户代码及文件（从本地或云存储桶）同步至集群。管理作业排队和执行。</p><p></p><p>根据官方数据，SkyPilot 能帮助用户大幅减少云成本，一般均可降至三分之一左右：</p><p></p><p>自动寻找能够提供所需资源的最便宜区 / 区域 / 云（将成本降低至二分之一）；Managed Spot 功能通过使用竞价实例将成本降低至三分之一到六分之一，并可在发生资源抢占时自动恢复；Autostop 可自动清理空闲集群，化解这一造成云超支的最大“凶手”。</p><p></p><p>过去几个月来，该实验室逐渐将 SkyPilot 交付给 10 多个组织的数十位机器学习 / 数据科学从业者和研究人员手中。SkyPilot 已被广泛用于交互式开发（例如运行 Jupyter 的 CPU 服务器）、管理各类项目（跨多云环境），甚至扩展至数百项作业。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/43/433f384c767a21826d4c3591add7a937.png\" /></p><p></p><p>比如，伯克利 AI 研究所（BAIR）和斯坦福大学的领先机器学习团队，一直在使用 SkyPilot 在云端运行机器学习训练。他们通常会在不更改代码的情况下启动自己的现有机器学习项目，而 SkypIlot 可以配置 GPU 实例、打理集群上的作业排队，并同时运行上百个超参数试验。此外，对于运行在 AWS 上的作业，用户只需要修改一个参数即可将其转由 Google Cloud Platform/Azure 运行。</p><p></p><h4>作为“云际经纪人”的角色</h4><p></p><p></p><p>SkyPilot 开发者和博士后研究员 Zongheng Yang 介绍道，构建 SkyPilot 的初衷就是为了契合多云和多区域的发展趋势。他指出，组织越来越倾向于使用多云环境，借此获得更高可靠性、避免云服务商锁定、掌握更强的谈判杠杆等。</p><p></p><p>Zongheng 对多云带来的成本优势进行了解释。他表示，在硬件相同 / 相似的前提下，选择价格最优的云服务能够节约大量成本。</p><p></p><p>以 GPU 为例，截至 11 月份时，Azure 的英伟达 A100 GPU 实例价格最低，GCP 和 AWS 分别要比其高出 8% 和 20%。CPU 同样存在价格差异：对于最新的通用实例（配备同样的 vCPU 和内存），不同云服务商的定价差异可能超过 50%。因此，为某项任务选择最合适的云厂商和相应硬件，无疑能显著降低成本、提高性能。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ea/eab4795b7ca0a31c15006d0efd45d62e.png\" /></p><p></p><p>不同硬件的云价格差异，取各家云平台最低价区域内的按需实例价格</p><p></p><p>用过的开发者可能知道，AWS EC2 instance 的时候经常出现 Insufficient Capacity 错误，即 AWS 这个区没有用户需要的资源了。实际上，优质的云实例资源非常稀缺，搭载英伟达 V100 和 A100 等高端 GPU 的按需实例并不常有，更不要说附带 GPU 或强劲 CPU 的竞价实例。根据经验，用户往往需要等待几十甚至上百小时才能获取如此宝贵的资源。</p><p></p><p>为了提高获取此类资源的机会，靠谱的办法就是使用多云。假设每家云厂商有 40% 的概率可以提供优质资源，则使用 3 家云服务商就会把成功概率提升至 78%（1–0.6³）。</p><p></p><p>当然，这些对于跨多个区域的单云用户也同样适用。</p><p></p><p>首先，不同区 / 区域间的价格差异也很大。对于普通的 GPU/CPU 资源，跨区按需实例的价差可能高达 20%。对于竞价实例，价差更是轻松达到 3 倍。简单来讲，用户可以在同一云服务商的多个区 / 区域间进行选择以降低设施成本。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c3/c30ae0ca2f0dd15726c6b0ce1e6628fe.png\" /></p><p></p><p>云内价格差异，“+20%”代表最贵区域的收费比最便宜区域高出 20%</p><p></p><p>其次，硬件 / 服务产品因云区域而异。例如，GCP 在全球部署有 35 个区域，但 TPU V3 只登陆了其中 2 个区域。另外，跨多个区域时，获取稀缺资源的成功率也更高。</p><p></p><p>但是不管有多少好处，跨云 / 区域运营确实会极大提升基础设施的管理复杂性。加州大学AMPLab、RISELab 和现在的 Sky Computing Lab 团队在使用公有云运行机器学习、数据科学、系统、数据库和安全方面的项目时就体会到了。</p><p></p><p>“使用一个云已经够难了，使用多云会加重最终用户的操作负担，SkyPilot 的开发人员就是想要减轻这种负担。”Zongheng 说道。</p><p></p><h4>“Sky Computing”构想</h4><p></p><p></p><p>“今天，越来越多的计算和数据正在进入云端。”Databricks 联合创始人、领导 Sky Computing Lab 的伯克利计算机科学教授 Ion Stoica 说道：“没有回头路可走。”</p><p></p><p>Stoica 还是 AMPLab 共同创始人、Spark 的核心设计者。他在去年提出了“Sky Computing”构想，这一构想的实质就是想让开发人员构建多云应用程序像构建在单个云上运行的应用程序一样容易。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f2/f22a9d79b606cfd8f252703882b0b100.png\" /></p><p></p><p>Sky Computing 与互联网对比</p><p></p><p>Sky Computing 构想的底层是云兼容层，通过抽象出云计算服务，使在该层之上开发的应用程序无需更改即可在不同的云上运行。兼容层可以从当前很多 OSS 解决方案中构建出来，如操作系统 Linux，集群资源管理器 Kubernetes、Mesos，数据库 MySQL、Postgres，⼤数据执⾏引擎 Spark、Hadoop，机器学习库 PyTorch 、Ten sorflow，通⽤分布式框架 Ray、Erlang 等等。</p><p></p><p>云兼容层之上云间层，用户可以指定有关其作业应在何处运行的策略。云间层之上是对等层，旨在让云间可以通过建立高速连接互相传递数据，使数据传输又快又便宜，实现更大的工作流动自由。</p><p></p><p>Sky Computing Lab 的成立就是要建立一个以服务为中介的双向市场，为用户识别和使用最适合他们需求的多云组合。云计算领域的一些知名企业，如谷歌、IBM、英特尔、三星 SDS 和 VMware 都是该实验室的创始赞助商。该实验室的团队包括 60 多名伯克利教职员工和学生。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/34/34f9f92d4e0dbdc5679f85e07e94747d.png\" /></p><p></p><p>为彻底改变云行业，加州大学伯克利分校启动 Sky Computing Lab</p><p></p><p>作为该实验室的产品，SkyPilot 就是 Sky Computing 构想下的产品之一。目前，已经有企业在 SkyPilot 的编程化 API 上构建多云库，这些应用程序从设计之初就具备了跨云能力，可以通过云中立接口驰骋在不同云环境之间。另外，Stoica 参与研发的项目 Skyplane 可以以 10 Gbps 的速度在云 / 区域之间迁移大型数据集，同时压缩数据来降低费用。</p><p></p><h4>结束语</h4><p></p><p></p><p>“我已经在 ML 项目中使用 SkyPilot 3 个月了，它确实和听起来一样棒。启动和管理计算的整体体验是经过深思熟虑且符合人体工程学的。”开发者“donnygreenberg”说道。</p><p></p><p>但并不是所有人叫好，除了对产品本身的质疑外，还有很多人因云成本负担而对云本身失去信心。“有时，人们会发现，先租赁设备直到可以低价购买，并以传统方式托管通常比支付无休止的云费用要便宜得多。”开发者“walrus01”表示。还有人直呼被当时云“降低成本”的炒作迷住了，云实际上并不适合所有企业。</p><p></p><p>一方面，业内在努力解决各种问题。另一方面，如何消除人们现在的怀疑，也是云提供商需要思考的问题。</p><p></p><p>参考链接：</p><p></p><p><a href=\"https://medium.com/@zongheng_yang/skypilot-ml-and-data-science-on-any-cloud-with-massive-cost-savings-244189cc7c0f\">https://medium.com/@zongheng_yang/skypilot-ml-and-data-science-on-any-cloud-with-massive-cost-savings-244189cc7c0f</a>\"</p><p><a href=\"https://www.infoq.cn/article/WIm2YhkS1I3z6Zds8tcq\">https://www.infoq.cn/article/WIm2YhkS1I3z6Zds8tcq</a>\"</p><p><a href=\"https://news.ycombinator.com/item?id=33964285\">https://news.ycombinator.com/item?id=33964285</a>\"</p><p></p>",
    "publish_time": "2022-12-14 15:39:20",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "让开发人员all in IDE！工商银行沉浸式研发体系建设实践",
    "url": "https://www.infoq.cn/article/wmu464ZcCqg7iAAbNoRh",
    "summary": "<p></p><h2>前&nbsp; &nbsp;言</h2><p></p><p></p><p>什么是沉浸式研发？可能很多人都没听说过这个名词，我们不妨从一次数据调研的结果开始讲起。在不久之前的一次一线开发人员每日编码时长的数据调研中，我们惊讶地发现，每个编码人员一天中使用 IDE 的平均时长只有不到两小时，与我们的预期有较大的差距。因此我们对这些开发人员的一天投入时间分布展开了深入调研，调研发现身为编码人员，除了在 IDE 中编码，其他需要投入时间的工作包括：找软需、查历史资产、查接口文档、查表结构、执行测试案例、模拟器调试接口… 这些工作似乎都是研发的必要环节，但零散的产品导致编码人员“来回奔波”于各个系统之间，减少了编码人员真正用于编写代码的时间。而沉浸式研发的目标就是让研发人员无需关注基础设施，而能够更专注于代码本身。</p><p></p><h2>业界现状</h2><p></p><p></p><p>随着云原生和 Kubernetes 的普及，应用架构在横向及纵向不断扩大和调整，微服务的数量变得越来越多，为保证研发质量，业界致力于提供微服务应用在开发、测试和生产阶段的一致性环境。现有 DevOps 流水线通过编译、打包、推送、部署等操作，降低了系统的运维成本，但是由于无法快速启动完整的开发环境、无法去除上下游的依赖、无法快速调试微服务等问题，导致开发阶段需要快速验证、快速反馈的诉求很难得到满足。2020 年腾讯 CODING 团队发布了自主研发的 Nocalhost，实现本地 IDE 和云端开发环境相互连接，无需运行 docker build 构建镜像和重新部署工作负载，开发者仅需在本地修改要开发的微服务代码并保存后，即可在云端开发环境中验证，可以实现本地开发代码实时生效和调试，有效缩短开发循环反馈。</p><p></p><p>为了降低开发人员的开发门槛，让开发人员更快、更准确地完成需求，业界以 IDE 为中心，通过集成 DevOps 研发辅助工具，打通需求、设计、研发、部署全流程，为开发人员提供一站式研发辅助生态。</p><p></p><h2>工行金融科技研发体系痛点</h2><p></p><p></p><p>业界不断探索如何提升“研发效能”的同时，工商银行金融科技也在积极尝试形成一套属于自己的高效研发体系，目前行内比较共性的研发痛点如下：</p><p></p><p>资产布局分散: 为了给开发人员赋能，行内积累了一系列标准资产、标准代码和标准工具，但是也引发了资产布局分散的问题，软需、应用信息、接口服务文档、表结构等资产均需要在不同系统获取，而应用资产则会出现在社区、共享盘、云文档甚至个人本地电脑、邮箱，各种资产无法形成合力给开发人员赋能，也导致开发人员在使用过程中需频繁切换和被打断，严重影响研发效能。</p><p></p><p>资产孤岛现象严重：各应用间的标准资产自建与隔离，造成标准资产重复建设、过时资产再次建设等资源浪费，且开发人员无统一、便利渠道检索和参考其他应用资源。打通应用、部门甚至基地间的资产孤岛，是推进资产标准化、提高资产复用率、推进低代码建设的必要一环。</p><p></p><p>研发自测困难：个人开发环境无专人维护，功能环境欠稳定且受部署时间限制，开发人员无法随时完成对代码的快速迭代，导致不少时间浪费在等待上，一套可定制的标准自测环境成为了开发人员可望不可及的梦想，也成为了提高研发质量的主要瓶颈之一。</p><p></p><p>研发断点严重：综合上述系统多、资产检索难、自测环境差等问题，研发人员需要在系统间来回切换与等待，基础设施的依赖度极高，导致投入实际编码的时间不足工作时长的 1/3。如何针对性降低日常研发断点、提高编码人员沉浸式研发时长，是提高产能的关键一环。</p><p></p><h2>沉浸式研发构想与落地</h2><p></p><p></p><p>对比业界实践，结合我行研发流程，我们从编码辅助、自测环境供给以及打通 DevOps 研发流程出发尝试建设一站式 IDE，避免开发人员不断被各种工具打断，实现“沉浸式”研发。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/eb/eb6dd200b1561771e19fb269e67945fc.png\" /></p><p></p><h3>一、资产辅助一键触达</h3><p></p><p></p><p>以开发人员研发 IDE 为触点，通过可扩展插件方式提供研发辅助资产快速检索、不同 IDE 间和系统间资产共享、资产一键引入、代码规范扫描等一系列能力，为研发人员提供统一、便利的交互入口，形成合力对开发人员赋能。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/52/523cb7f684b7ffb0424839bc6d81f507.png\" /></p><p></p><p>在资产检索功能上，为契合程序员操作习惯，以极简的界面为开发人员提供基于关键字、主题标签检索标准资产的功能；同时为提高检索效率，搜索引擎采用 Elasticsearch，IDE 内毫秒级获取相关资产，最大程度节约无效检索的时间。在标准资产共享上，为了做好资产管理，用中心级、基地级、部门级、应用级四个等级区分资产的适用范围，规范资产定级；用资产类型、资产所属大类、小类等标签区分资产适用场景，规范资产分类；由各级别资产审核人严格审核，确保资产质量。</p><p></p><h3>二、研发流程一站贯通</h3><p></p><p></p><p>打通研发工具和流水线，自测完成自动提交构建流水线进行质量守护，从而为开发人员提供详细设计、编码、单元测试、自测、部署五个研发阶段的沉浸式开发体验，无需频繁切换不同支撑系统，打断研发流程，有效提升 DevOps 研发运维一体化能力水平。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/0f/0fa97382cb5ad81c5d89cabda96f0f58.png\" /></p><p></p><p>详细设计：通过打通与各个研发管理系统的壁垒，IDE 内一键查询开发设计阶段所需的服务 /API 接口文档，无需系统间来回切换。编码：通过代码补全、标准化代码模板等工具辅助，无需再去各个系统检索资产，提高研发效率。</p><p></p><p>单元测试：通过嵌入单元测试覆盖率检测、MOCK 等工具，IDE 内快速完成单元测试，提高代码质量守护能力。</p><p></p><p>自测：通过接口模拟测试、本地提交构建流水线预检、云测试环境创建工具嵌入，IDE 内完成自测，降低自测门槛，提高自测质量。</p><p></p><p>部署：通过 git 插件提交代码入库，入库后在通过 VCDS 接口触发流水线。提供代码的全流程视图，方便跟踪代码。</p><p></p><h3>三、云端实时自测验证</h3><p></p><p></p><p></p><h4>1、环境搭建</h4><p></p><p></p><p>实现为开发人员快速提供云原生自测子环境能力，以稳态环境为基础，提供环境快速复制能力，开发者可以低成本建立不同的子环境，编码完成后通过本地插件快速同步到云端开发环境，快速部署，快速验证，在子环境中开发、变更目标服务，子环境与基准环境的服务交互实现联调，从传统编译、打包、推送、部署、调用、修改的六步骤转为编译、调用、修改的三步骤秒级程序循环验证反馈模式，有效提高开发自测环境的稳定性和验证效率。</p><p></p><p>基于 PaaS 的 K8s 集群和云管平台，搭建开发自测环境的 K8s 集群和云管平台，通过 IDE 直连 K8s 集群，形成开发环境预分配、随用随申请、用完即销毁的机制。制作开发基础镜像，实现容器内编译打包部署，减少部署等待时长，提升自测验证速度。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/65/651fb6ca45254ef1be84bd0af4058c3d.png\" /></p><p></p><p>K8s 集群：由 PaaS 云平台提供自测环境的 K8s 集群。</p><p></p><p>云管平台：基于 PaaS 云管平台，实现自测环境 Pod 的的集中管理，包括开发容器的创建、监控和销毁等功能。</p><p></p><p>IDE 插件：适配目前主流的 IDE，通过配置集群信息连接 K8s 集群，完成开发容器的配置、申请和销毁功能。</p><p></p><p>开发基础镜像：制作适配行内主流开发环境的基础镜像。</p><p></p><p></p><h4>2、自测流程</h4><p></p><p></p><p>基于全链路路由机制，实现请求自由发送到特色自测环境：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/23/23a29aef5a0a1a094fa70486f5430941.png\" /></p><p></p><p>特色标签：根据开发人员个人属性，自动生成唯一标签。</p><p></p><p>流量路由：根据标签路由，基于我行已有 CTP 与 DSF 等框架提供的全链路路由能力转发流量。</p><p></p><p>默认服务：基准容器提供默认的服务，若未指明标签或者未找到指定的标签，则访问基准容器的服务。</p><p></p><p>联调测试：开发联调测试过程，启动带有标签 V1 的开发容器，并通知联调方同样使用带有标签 V1 的服务来请求。完成基于开发容器 A（V1）、基准容器 B、开发容器 C（V1）的开发环境联调测试。</p><p></p><p></p><h2>结&nbsp; 尾</h2><p></p><p></p><p>话题的最后，我们再次表达下我们沉浸式研发体系规划愿景：减少研发断点，提高研发产能？不不不，直白一点，我们最终的愿景是：带你走进沉浸式研发，除非你想，否则你再也不需要离开你的 IDE，即 ALL IN IDE！</p>",
    "publish_time": "2022-12-14 15:39:56",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何升级数字化思维，助力企业组织变革？ Part 1 ：定义数字思维",
    "url": "https://www.infoq.cn/article/L3hxYJykCWaFt1xLqJVO",
    "summary": "<p>发展数字经济，培育数字人才，『 数字思维 』不可或缺。<br />\n数字思维，不是简单用数字来考虑问题，而是以数字为核心生产要素，以数字经济为引擎，系统性配置资源和重塑价值。对于很多企业来说，激发员工的数字思维是实施数字化转型建设的重要任务。<br />\n那么，对企业管理者而言，如何提升数字认知，强化数字思维，帮助员工理解数字战略，推动企业数字转型落地呢？<br />\n我们将邀请涂益华老师、刘正周老师、李海鸥老师、司巧蕾老师来一起探讨！</p>",
    "publish_time": "2022-12-14 19:19:49",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "元年科技助力数字化转型：“低代码+PaaS”的技术创新实践",
    "url": "https://www.infoq.cn/article/QSTOa2HCmQOmSxRrD9mB",
    "summary": "<p>数字化转型已经成为必然趋势，几乎所有传统行业都喊出了数字化转型的口号。在数字化转型中，很多企业面临着成本高、周期长的难题，那低代码就是一种破解难题的方式，低代码是一种可视化的应用开发方法，用较少的代码、以较快的速度来交付应用程序，实现软件开发的自动化。低代码作为一组数字技术工具平台，可基于图形化拖拽、参数化配置等更为高效的方式，实现快速构建、数据编排、连接生态、中台服务。通过少量代码或不用代码实现数字化转型中的场景应用创新。可以说，如今的低代码已经是企业数字化的核心引擎。</p>\n<p>如今市面上的低代码平台越来越多，如何做好平台选型也成为了另企业头疼的问题。如今市面上的低代码平台已经发展成什么样了？低代码技术实现了哪些技术突破？遇到一个具体的业务需求，如何通过高度可配置、可扩展的低代码能力，在项目的需求调研-实施-运维阶段提供服务、提升效率、降低成本？</p>\n<p>元年科技高级产品经理徐帆就在本视频中为大家一一解密，与大家聊聊低代码平台的那些事儿！</p>\n<h2><strong>演讲大纲</strong></h2>\n<ul>\n<li>企业数字化转型的困境与问题根源</li>\n<li>低代码平台助力企业数字化转型的理念与核心价值</li>\n<li>元年方舟低代码平台核心引擎能力拆解</li>\n<li>元年方舟低代码平台云原生技术架构介绍</li>\n<li>案例实践与方法论</li>\n</ul>",
    "publish_time": "2022-12-14 19:20:47",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "突破 etcd 限制！字节开源自研 K8s 存储 KubeBrain",
    "url": "https://www.infoq.cn/article/RhZUG069XVR5Z5bhHTIv",
    "summary": "<p></p><p>KubeBrain 是字节跳动针对 Kubernetes 元信息存储的使用需求，基于分布式 KV 存储引擎设计并实现的取代 etcd 的元信息存储系统，支撑线上超过 20,000 节点的超大规模 Kubernetes 集群的稳定运行。</p><p></p><p>项目地址：github.com/kubewharf/kubebrain</p><p></p><p></p><h2>背&nbsp; &nbsp;景</h2><p></p><p></p><p>分布式应用编排调度系统 Kubernetes 已经成为云原生应用基座的事实标准，但是其官方的稳定运行规模仅仅局限在 5,000 节点。这对于大部分的应用场景已经足够，但是对于百万规模机器节点的超大规模应用场景， Kubernetes 难以提供稳定的支撑。</p><p></p><p>尤其随着“数字化””云原生化”的发展，全球整体 IT 基础设施规模仍在加速增长，对于分布式应用编排调度系统，有两种方式来适应这种趋势：</p><p></p><p>水平扩展 ： 即构建管理多个集群的能力，在集群故障隔离、混合云等方面更具优势，主要通过集群联邦（Cluster Federation）来实现；垂直扩展 ： 即提高单个集群的规模，在降低集群运维管理成本、减少资源碎片、提高整体资源利用率方面更具优势。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e1/e19503be14eb5ff3b58aa52388c40835\" /></p><p></p><p>K8s 采用的是一种中心化的架构，所有组件都与 APIServer 交互，而 APIServer 则需要将集群元数据持久化到元信息存储系统中。当前，etcd 是 APIServer 唯一支持的元信息存储系统，随着单个集群规模的逐渐增大，存储系统的读写吞吐以及总数据量都会不断攀升，etcd 不可避免地会成为整个分布式系统的瓶颈。</p><p></p><p></p><h3>1.1 Kubernetes 元信息存储需求</h3><p></p><p></p><p>APIServer 并不能直接使用一般的强一致 KV 数据库作为元信息存储系统，它与元信息存储系统的交互主要包括数据全量和增量同步的 List/Watch，以及单个 KV 读写。更近一步来说，它主要包含以下方面：</p><p></p><p>在版本控制方面，存储系统需要对 APIServer 暴露数据的版本信息，APIServer 侧依赖于数据的版本生成对应的 ResourceVersion；在写操作方面，存储系统需要支持 Create/Update/Delete 三种语义的操作，更为重要的是，存储系统需要支持在写入或者删除数据时对数据的版本信息进行 CAS；在读操作方面，存储系统需要支持指定版本进行快照 List 以此从存储中获取全量的数据，填充 APIServer 中的 WatchCache 或供查询使用，此外也需要支持读取数据的同时获取对应的数据版本信息；在事件监听方面，存储系统需要支持获取特定版本之后的有序变更，这样 APIServer 通过 List 从元信息存储中获取了全量的数据之后，可以监听快照版本之后的所有变更事件，进而以增量的方式来更新 Watch Cache 以及向其他组件进行变更的分发，进而保证 K8s 各个组件中数据的最终一致性。</p><p></p><p></p><h3>1.2 etcd 的实现方式与瓶颈</h3><p></p><p></p><p>etcd 本质上是一种主从架构的强一致、高可用分布式 KV 存储系统：</p><p></p><p>节点之间，通过 Raft 协议进行选举，将操作抽象为 log 基于 Raft 的日志同步机制在多个状态机上同步；单节点上，按顺序将 log 应用到状态机，基于 boltdb 进行状态持久化 。对于 APIServer 元信息存储需求，etcd 大致通过以下方式来实现:</p><p></p><p>在版本控制方面，etcd 使用 Revision 作为逻辑时钟，对每一个修改操作，会分配递增的版本号 Revision，以此进行版本控制，并且在内存中通过 TreeIndex 管理 Key 到 Revision 的索引；在写操作方面，etcd 以串行 Apply Raft Log 的方式实现，以 Revision 为键，Key/Value/Lease 等数据作为值存入 BoltDB 中，在此基础上实现了支持对 Revision 进行 CAS 的写事务；在读操作方面，etcd 则是通过管理 Key 到 Revision 的 TreeIndex 来查询 Revision 进而查询 Value，并在此基础上实现快照读；在事件监听方面，历史事件可以从 BoltDB 中指定 Revision 获取 KV 数据转换得到，而新事件则由写操作同步 Notify 得到。</p><p></p><p>etcd 并不是一个专门为 K8s 设计的元信息存储系统，其提供的能力是 K8s 所需的能力的超集。在使用过程中，其暴露出来的主要问题有：</p><p></p><p>etcd 的网络接口层限流能力较弱，雪崩时自愈能力差；etcd 所采用的是单 raft group，存在单点瓶颈，单个 raft group 增加节点数只能提高容错能力，并不能提高写性能；etcd 的 ExpensiveRead 容易导致 OOM，如果采用分页读取的话，延迟相对会提高；boltdb 的串行写入，限制了写性能，高负载下写延迟会显著提高；长期运行容易因为碎片问题导致写性能发生一定劣化，线上集群定期通过 defrag 整理碎片，一方面会比较复杂，另一方面也可能会影响可用性。</p><p></p><p></p><h2>新的元数据存储</h2><p></p><p></p><p>过去面对生产环境中 etcd 的性能问题，只能通过按 Resource 拆分存储、etcd 参数调优等手段来进行一定的缓解。但是面对 K8s 更大范围的应用之后带来的挑战，我们迫切的需要一个更高性能的元数据存储系统作为 etcd 的替代方案，从而能对上层业务有更有力的支撑。</p><p></p><p>在调研了 K8s 集群的需求以及相关开源项目之后，我们借鉴了 k3s 的开源项目 kine 的思想，设计并实现了基于分布式 KV 存储引擎的高性能 K8s 元数据存储项目—— KubeBrain 。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/6c/6c094ecf80ff43bbb2ce900f897f091c\" /></p><p></p><p>KubeBrain 系统实现了 APIServer 所使用的元信息存储 API ，整体采用主从架构，主节点负责处理写操作和事件分发，从节点负责处理读操作，主节点和从节点之间共享一个分布式强一致 KV 存储，在此基础上进行数据读写。下面介绍 KubeBrain 的核心模块。</p><p></p><p></p><h3>2.1 存储引擎</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/33/3377cf5bb6ca48b1ed26bc672a938dcc\" /></p><p></p><p>KubeBrain 统一抽象了逻辑层所使用的 KeyValue 存储引擎接口，以此为基础，项目实现了核心逻辑与底层存储引擎的解耦：</p><p></p><p>逻辑层基于存储引擎接口来操作底层数据，不关心底层实现；对接新的存储引擎只需要实现对应的适配层，以实现存储接口。</p><p></p><p>目前项目已经实现了对 ByteKV 和 TiKV 的适配，此外还实现了用于测试的适配单机存储 Badger 的版本。需要注意的是，并非所有 KV 存储都能作为 KubeBrain 的存储引擎。当前 KubeBrain 对于存储引擎有着以下特性要求：</p><p></p><p>支持快照读支持双向遍历支持读写事务或者带有 CAS 功能的写事务对外暴露逻辑时钟</p><p></p><p>此外，由于 KubeBrain 对于上层提供的一致性保证依赖于存储引擎的一致性保证， KubeBrain 要求存储引擎的事务需要达到以下级别（定义参考 HATs ：<a href=\"http://www.vldb.org/pvldb/vol7/p181-bailis.pdf%EF%BC%89%EF%BC%9A\">http://www.vldb.org/pvldb/vol7/p181-bailis.pdf）：</a>\"</p><p></p><p>Isolation Guarantee: Snapshot IsolationSession Guarantee: Linearizable</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/70/70898356199d22e56480c0902649686a\" /></p><p></p><p>在内部生产环境中， KubeBrain 均以 ByteKV 为存储引擎提供元信息存储服务。ByteKV 是一种强一致的分布式 KV 存储。在 ByteKV 中，数据按照 key 的字典序有序存储。当单个 Partition 数据大小超过阈值时， Partition 自动地分裂，然后可以通过 multi-raft group 进行水平扩展，还支持配置分裂的阈值以及分裂边界选择的规则的定制。此外， ByteKV 还对外暴露了全局的时钟，同时支持写事务和快照读，并且提供了极高的读写性能以及强一致的保证。</p><p></p><p></p><h3>2.2 选主机制</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/99/992ae403833b3fefbbdeb0b82eaf6008\" /></p><p></p><p>KubeBrain 基于底层强一致的分布式 KV 存储引擎，封装实现了一种 ResourceLock，在存储引擎中指向一组特定的 KeyValue。ResourceLock 中包含主节点的地址以及租约的时长等信息。</p><p></p><p>KubeBrain 进程启动后均以从节点的身份对自己进行初始化，并且会自动在后台进行竞选。竞选时，首先尝试读取当前的 ResourceLock。如果发现当前 ResourceLock 为空，或者 ResourceLock 中的租约已经过期，节点会尝试将自己的地址以及租约时长以 CAS 的方式写入 ResourceLock，如果写入成功，则晋升为主节点。</p><p></p><p>从节点可以通过 ResourceLock 读取主节点的地址，从而和主节点建立连接，并进行必要的通信，但是主节点并不感知从节点的存在。即使没有从节点，单个 KubeBrain 主节点也可以提供完成的 APIServer 所需的 API，但是主节点宕机后可用性会受损。</p><p></p><p></p><h3>2.3 逻辑时钟</h3><p></p><p></p><p>KubeBrain 与 etcd 类似，都引入了 Revision 的概念进行版本控制。KubeBrain 集群的发号器仅在主节点上启动。当从节点晋升为主节点时，会基于存储引擎提供的逻辑时钟接口来进行初始化，发号器的 Revision 初始值会被赋值成存储引擎中获取到的逻辑时间戳。</p><p></p><p>单个 Leader 的任期内，发号器发出的整数号码是单调连续递增的。主节点发生故障时，从节点抢到主，就会再次重复一个初始化的流程。由于主节点的发号是连续递增的，而存储引擎的逻辑时间戳可能是非连续的，其增长速度是远快于连续发号的发号器，因此能够保证切主之后， Revision 依然是递增的一个趋势，旧主节点上发号器所分配的最大的 Revision 会小于新主节点上发号器所分配的最小的 Revision。</p><p></p><p>KubeBrain 主节点上的发号是一个纯内存操作，具备极高的性能。由于 KubeBrain 的写操作在主节点上完成，为写操作分配 Revision 时并不需要进行网络传输，因此这种高性能的发号器对于优化写操作性能也有很大的帮助。</p><p></p><p></p><h3>2.4 数据模型</h3><p></p><p></p><p>KubeBrain 对于 API Server 读写请求参数中的 Raw Key，会进行编码出两类 Internal Key 写入存储引擎索引和数据。对于每个 Raw Key，索引 Revision Key 记录只有一条，记录当前 Raw Key 的最新版本号， Revision Key 同时也是一把锁，每次对 Raw Key 的更新操作需要对索引进行 CAS。数据记录 Object Key 有一到多条，每条数据记录了 Raw Key 的历史版本与版本对应的 Value。Object Key 的编码方式为 magic+raw_key+split_key+revision，其中：</p><p></p><p>magic 为\\x57\\xfb\\x80\\x8b；raw_key 为实际 API Server 输入到存储系统中的 Key ；split_key 为 $；revision 为逻辑时钟对写操作分配的逻辑操作序号通过 BigEndian 编码成的 Bytes 。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c5/c58ece57d28d395fe410d114d522c5ab\" /></p><p></p><p></p><blockquote>根据 Kubernetes 的校验规则，raw_key 只能包含小写字母、数字，以及’-’ 和 ‘.’，所以目前选择 split_key 为 $ 符号。</blockquote><p></p><p></p><p>特别的，Revision Key 的编码方式和 Object Key 相同，revision 取长度为 8 的空 Bytes。这种编码方案保证编码前和编码后的比较关系不变。</p><p></p><p>在存储引擎中，同一个 Raw Key 生成的所有 Internal Key 落在一个连续区间内。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b8/b838428297de18be448009666d9fd289\" /></p><p></p><p>这种编码方式有以下优点：</p><p></p><p>编码可逆，即可以通过 Encode(RawKey,Revision) 得到 InternalKey，相对应的可以通过 Decode(InternalKey) 得到 Rawkey 与 Revision；将 Kubernetes 的对象数据都转换为存储引擎内部的 Key-Value 数据，且每个对象数据都是有唯一的索引记录最新的版本号，通过索引实现锁操作；可以很容易地构造出某行、某条索引所对应的 Key，或者是某一块相邻的行、相邻的索引值所对应的 Key 范围；由于 Key 的格式非单调递增，可以避免存储引擎中的递增 Key 带来的热点写问题。</p><p></p><p></p><h3>2.5 数据写入</h3><p></p><p></p><p>每一个写操作都会由发号器分配一个唯一的写入 revision ，然后并发地对存储引擎进行写入。在 创建、更新 和 删除 Kubernetes 对象数据的时候，需要同时操作对象对应的索引和数据。由于索引和数据在底层存储引擎中是不同的 Key-Value 对，需要使用 写事务 保证更新过程的 原子性，并且要求至少达到 Snapshot Isolation 。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e1/e16690e17e93871a83514a4c38879e32\" /></p><p></p><p>同时 KubeBrain 依赖索引实现了乐观锁进行并发控制。KubeBrain 写入时，会先根据 APIServer 输入的 RawKey 以及被发号器分配的 Revision 构造出实际需要到存储引擎中的 Revision Key 和 Object Key，以及希望写入到 Revision Key 中的 Revision Bytes。在写事务过程中，先进行索引 Revision Key 的检查，检查成功后更新索引 Revision Key，在操作成功后进行数据 Object Key 的插入操作。</p><p></p><p>执行 Create 请求时，当 Revision Key 不存在时，才将 Revision Bytes 写入 Revision Key 中，随后将 API Server 写入的 Value 写到 Object Key 中；执行 Update 请求时，当 Revision Key 中存放的旧 Revision Bytes 符合预期时，才将新 Revision Bytes 写入，随后将 API Server 写入的 Value 写到 Object Key 中；执行 Delete 请求时，当 Revision Key 中存放的旧 Revision Bytes 符合预期时，才将新 Revision Bytes 附带上删除标记写入，随后将 tombstone 写到 Object Key 中。</p><p></p><p>由于写入数据时基于递增的 Revision 不断写入新的 KeyValue ， KubeBrain 会进行后台的垃圾回收操作，将 Revision 过旧的数据进行删除，避免数据量无限增长。</p><p></p><p></p><h3>2.6 数据读取</h3><p></p><p></p><p>数据读取分成点读和范围查询查询操作，分别对应 API Server 的 Get 和 List 操作。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/4e/4eb49e9f9701c8ba70313451c3e87d2a\" /></p><p></p><p>Get 需要指定读操作的 ReadRevision，需要读最新值时则将 ReadRevision 置为最大值 MaxUint64， 构造 Iterator ，起始点为 Encode(RawKey, ReadRevision)，向 Encode( RawKey, 0) 遍历，取第一个。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/af/af2b3eac1982b1995d7896d27a527aba\" /></p><p></p><p>范围查询需要指定读操作的 ReadRevision 。对于范围查找的 RawKey 边界 [RawKeyStart, RawKeyEnd) 区间， KubeBrain 构造存储引擎的 Iterator 快照读，通过编码将 RawKey 的区间映射到存储引擎中 InternalKey 的数据区间</p><p></p><p>InternalKey 上界 InternalKeyStart 为 Encode(RawKeyStart, 0)InternalKey 的下界为 InternalKeyEnd 为 Encode(RawKeyEnd, MaxRevision)</p><p></p><p>对于存储引擎中 [InternalKeyStart, InternalKeyEnd) 内的所有数据按序遍历，通过 Decode(InternalKey) 得到 RawKey 与 Revision，对于一个 RawKey 相同的所有 ObjectKey，在满足条件 Revision&lt;=ReadRevision 的子集中取 Revision 最大的，对外返回。</p><p></p><p></p><h3>2.7 事件机制</h3><p></p><p></p><p>对于所有变更操作，会由 TSO 分配一个连续且唯一的 revision ，然后并发地写入存储引擎中。变更操作写入存储引擎之后，不论写入成功或失败，都会按照 revision 从小到大的顺序，将变更结果提交到滑动窗口中，变更结果包括变更的类型、版本、键、值、写入成功与否 。在记录变更结果的滑动窗口中，从起点到终点，所有变更数据中的 revision 严格递增，相邻 revision 差为 1。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/89/899d02c87bc345930181703127b3a2dc\" /></p><p></p><p>记录变更结果的滑动窗口由事件生成器统一从起点开始消费，取出的变更结果后会根据变更的 revision 更新发号器的 commit index ，如果变更执行成功，则还会构造出对应的修改事件，将并行地写入事件缓存和分发到所有监听所创建出的通知队列。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/13/13a8afdde3c7c0183812e7beab625263\" /></p><p></p><p>在元数据存储系统中，需要监听指定逻辑时钟即指定 revision 之后发生的所有修改事件，用于下游的缓存更新等操作，从而保证分布式系统的数据最终一致性。注册监听时，需要传入起始 revision 和过滤参数，过滤参数包括 key 前缀等等。</p><p></p><p>当客户端发起监听时，服务端在建立事件流之后的处理，分成以下几个主要步骤：</p><p></p><p>处理监听注册请求时首先创建通知队列，将通知队列注册到事件生成组件中，获取下发的新增事件；从事件缓存中拉取事件的 revision 大于等于给定要求 revision 所有事件到事件队列中，并放到输出队列中，以此获取历史事件；将通知队列中的事件取出，添加到输出队列中， revision 去重之后添加到输出队列；按照 revision 从小到大的顺序，依次使用过滤器进行过滤；将过滤后符合客户端要求的事件，通过事件流推送到元数据存储系统外部的客户端。</p><p></p><p></p><h2>落地效果</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/68/686096350a469ce1d112664befd37613\" /></p><p></p><p>在 Benchmark 环境下，基于 ByteKV 的 KubeBrain 对比于 etcd 纯写场景吞吐提升 10 倍左右，延迟大幅度降低， PCT 50 降低至 1/6 ，PCT 90 降低至 1/20 ，PCT 99 降低至 1/4 ；读写混合场景吞吐提升 4 倍左右；事件吞吐大约提升 5 倍；</p><p></p><p>在模拟 K8s Workload 的压测环境中，配合 APIServer 侧的优化和调优，支持 K8s 集群规模达到 5w Node 和 200w Pod；在生产环境中，稳定上量至 2.1w Node ，高峰期写入超过 1.2w QPS，读写负载合计超过 1.8w QPS。</p><p></p><p></p><h2>未来演进</h2><p></p><p></p><p>项目未来的演进计划主要包括四个方面的工作：</p><p></p><p>探索实现多点写入的方案以支持水平扩展 现在 KubeBrain 本质上还是一个单主写入的系统，KubeBrain 后续会在水平扩展方面做进一步的探索，后续也会在社区中讨论；提升切主的恢复速度 当前切主会触发 API Server 侧的 Re-list ，数据同步的开销较大，我们会在这方面进一步做优化；实现内置存储引擎 实现两层存储融合，由于现在在存储引擎、KubeBrain 中存在两层 MVCC 设计，整体读写放大较多，实现融合有助于降低读写放大，更进一步提高性能；完善周边组件 包括数据迁移工具、备份工具等等，帮助用户更好地使用 KubeBrain 。</p><p></p><p>关于作者：</p><p></p><p>字节基础架构编排调度团队，负责构建字节跳动内部的容器云平台，为产品线提供运行基石；以超大容器集群规模整体支撑了字节内产品线，涵盖今日头条、抖音、西瓜视频等。</p><p></p><p>团队支持业务同时覆盖在线、离线机器学习，推荐 / 广告 / 搜索等多种应用场景；在持续多年的超高速增长中，积累了丰富的 Kubernetes/ 容器超大规模应用经验，旨在打造覆盖多场景，多地域的千万级容器的大平台。欢迎志同道合的同学们加入我们。</p><p></p><p>简历投递：lijiazhuo@bytedance.com</p><p></p><p>今日好文推荐</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651149473&amp;idx=1&amp;sn=8b33f2806e2430c6b6b317f6757180bf&amp;chksm=bdb8acf28acf25e475682f83248ac8415de5d5f326c334bd26c6cfede431d0bf2cb8a9efa3a6&amp;scene=21#wechat_redirect\">如何破解Web3的「存力」难题？</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651149124&amp;idx=1&amp;sn=8d51a752aa7c44957dc2243325da0f6d&amp;chksm=bdb8ab178acf220134e9666b111c9a024a9cca8c9fb6569fc64c0e1a1e9c92ec51a41d84617d&amp;scene=21#wechat_redirect\">后Kubernetes时代的未来？Wasmer 3.0 发布，可在浏览器外运行 WebAssembly</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651149060&amp;idx=1&amp;sn=4b6bacfb8ae7b595393ca989a71290e2&amp;chksm=bdb8ab578acf224169891abbddb1f441667585c48a9bc128a0fccc1a9a2e62bf6ec94363534a&amp;scene=21#wechat_redirect\">马斯克要求推特程序员写周报，具体到代码行数；刘强东称将末位淘汰部分京东高管；闰秒终于要被取消了！｜ Q资讯</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651148978&amp;idx=1&amp;sn=bdb44f93a7b5cc11d1a846cb10ba6394&amp;chksm=bdb8aae18acf23f7bea8e24fa0e6bf2d8235344a3f6d3674c2c4046d595fa06fe6b965d47152&amp;scene=21#wechat_redirect\">阿里云李飞飞：用5年让PolarDB成为“国货之光”｜ 开源人说</a>\"</p><p></p><p></p><p></p>",
    "publish_time": "2022-12-14 19:54:53",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "已来到 “后云原生时代” 的我们，如何规模化运维？",
    "url": "https://www.infoq.cn/article/XlvGBzRVawlwHIBhdBoI",
    "summary": "<p></p><p>作者 | 李大元（Kusion 项目负责人）</p><p></p><p></p><h2>后云原生时代</h2><p></p><p></p><p>距离 Kubernetes 第一个 commit 已经过去八年多了，以其为代表的云原生技术早已不再是什么新技术，而是现代化应用的“标配”。现代化应用依赖的基础服务远不止 Kubernetes 一种，稍微复杂点的应用往往会同时使用到 Kubernetes 生态云原生技术、IaaS 云服务、企业内部自建系统等各种异构基础设施，可能还会有多云、混合云的部署需求，我们已经进入到了 ”后云原生时代”，只针对 Kubernetes 的运维工具早已不能满足我们的诉求。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/4c/4cf8c7f73362f29cede6dacb0ed62709.png\" /></p><p></p><p>更复杂的是，在企业内部，这些服务一般是由不同团队维护的，一次规模化运维需要多个团队的成员互相配合才能完成，但是 App Dev，Platform Dev，SRE 各个团队之间缺少高效的协作方式。技术自身的复杂性加上低效的团队协作，使得 “后云原生时代” 的规模化运维难度有了指数级的提高。</p><p></p><p></p><h2>规模化运维的问题一直都在</h2><p></p><p></p><p>复杂异构基础设施的规模化运维，这并不是后云原生时代特有的问题，自分布式系统诞生以来，一直都是一个难题，只是在后云原生时代，这个问题变得更加困难。十多年前业界提出了 DevOps 理念，无数企业基于此理念构建了自己的 DevOps 平台，希望解决此问题，但在实际落地的过程中往往不尽人意，Dev 团队和 Ops 团队之间如何合作？职责如何划分？几十人的平台团队，如何支持几万工程师的运维诉求？底层基础设施复杂多样，能力日新月异，如何快速让一线 Dev 享受到技术红利？这些问题一直没有得到很好的解决，最近又有人提出了 DevOps 已死，Platform Engineering 才是未来的说法。抛开概念定义，无论是 DevOps 还是 Platform Engineering，本质上都是企业规模化运维这同一命题下的不同理念，我们更需要的是一个符合技术发展趋势，能解决当前问题的解决方案。</p><p></p><p></p><h2>传统架构不再适用</h2><p></p><p></p><p>在传统的运维思路中，解决上述问题的方法一般是构建一个 PaaS 平台，例如我们早期的蚂蚁 PaaS 平台，他是一个 Web 控制台，有 UI 界面，用户（通常是 App Dev 或 SRE）通过 UI 交互可以完成诸如发布、重启、扩缩容等操作。在技术实现上大体可以分为三部分，一个前端系统，提供用户交互的能力，作为系统入口；中间是一个后端系统，对接各个基础设施；底层是各个基础设的 API。这种架构运行了近十年，一直运行的很好，既有用户友好的交互界面，又可以屏蔽基础设施复杂性，而且各个团队之间还职责分明，但是到了如今后云原生时代，这种架构不再适用，暴露出有两个致命缺点，“费人”、“费时”。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/2f/2f3c8e9a101e946e45121e3539aa36bc.png\" /></p><p></p><p>举一个常见的例子，网络团队为其负责的 Loadbalancer（负载均衡器）开发了一种新的负载算法，需要提供给用户使用。在上述架构下，整个工作流程是这个样子：</p><p></p><p>网络团队开发好能力，提供出 APIPaaS 后端通过编码对接底层 API，进行互联互通，屏蔽复杂性，提供面向用户的更高级别 APIPaaS 前端根据新功能修改 UI，利用后端 API 把能力透出给最终用户</p><p></p><p>这里存在一个问题，即使一个再小的功能，也需要 PaaS 后端和前端修改代码，整个流程下来最快也要一周才能上线，而且涉及的基础设施团队越多，效率越低。这个问题在十年前并不算是一个问题，但是在今天就是一个很大的问题，一个后云原生时代的现代化应用，使用三个云原生技术（Kubernetes + Istio + Prometheus），两个云服务（Loadbalancer + Database），一个内部自建服务，已经是一个很常见的形态了，复杂应用只会依赖的更多。如果每个基础设施都由 PaaS 团队硬编码对接一遍，PaaS 团队的人再扩大十倍也不够用。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/fd/fd4bcf0009ea7c1d3224e75b16c47bab.png\" /></p><p></p><p>“费人”讲完了，我们再看看“费时”的问题。上面例子里的一个小功能，需要进行两次跨团队的协作，一次基础设施和 PaaS 后端，另一次是 PaaS 后端与 PaaS 前端。团队协作是一个很难的问题，有时候比技术本身还要难。应用的架构已经很复杂了，如果要做一次规模化运维，一次运维 100 个应用，这要和多少个团队沟通协作？要花费多少时间？没有好的协作机制，这就变成了一个不可能完成的任务。</p><p></p><p></p><h2>探索与实践</h2><p></p><p></p><p>我们在蚂蚁集团内部进行了近两年的探索，kustomize、helm、argoCD、Terraform 这些常见的工具我们都实践过，甚至还为一些工具自研了一些辅助系统，但结果并不尽人意。这些工具要么太局限于 Kubernetes 生态，运维不了其他类型的基础设施，要么就是支持了异构基础设施，但对于 Kubernetes 生态支持的不友好，无法发挥出云原生技术的优势，而且只是运维工具的升级对于团队协作效率几乎没有提升，我们需要一套更加体系化的方案。</p><p></p><p>回到问题本身，针对“费人”、“费时”的问题，我们提出两个思路：</p><p></p><p>能否不让 PaaS 做中转，而是由 App Dev 通过一种高效自助的方式，使用到互联互通的各种基础设施能力？能否构建一个中心化的协作平台，用技术的手段规范大家的行为，标准化的进行沟通？</p><p></p><p>从技术的角度来看，PaaS 平台需要提供灵活的工具链和工作流，基础设施所有能力都通过模块化的方式暴露出来，App Dev 利用这些平台的基本能力，自己组合、编排来解决自己的问题，过程中不需要平台层的参与。并且整个过程中涉及的所有团队，都使用统一的语言和接口进行交流，全程无需人工参与。</p><p></p><p></p><h2>我们的实践</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/9f/9f53aeac6ee68d2eb53de6464fe1a724.png\" /></p><p></p><p>经过在蚂蚁内部 PaaS 平台近两年的探索与实践，沉淀出一套端到端的完整方案， 取名为 KusionStack，目前已经开源。试图从统一异构基础设施运维与团队协作两个角度解决传统 PaaS “费人”、“费时”的问题。整个体系主要分为三个部分：</p><p></p><p>Konfig：Git 大库，是多团队协作的中心化平台，存放着各个团队的运维意图KCL：蚂蚁自研的配置策略 DSL，所有团队间交流的工具Kusion：KusionStack 引擎，负责所有的运维操作</p><p></p><p>Platform Dev 通过 KCL 定义好基础能力模型，App Dev 通过 import、mixin 等语言特性在应用配置模型（AppConfig）里复用这些预定义好的能力，快速在 Konfig 里描述运维意图。AppConfig 是一个精心设计过的模型，只暴露 App Dev 需要关心的属性，屏蔽基础设施的复杂性。</p><p></p><p>永远不要低估基础设施的专业性与复杂性，即使已经成为云原生技术标准的 Kubernetes，对普通用户来说依然有很高的门槛，一个 Deployment 就有几十个字段，再加上自定义的 labels、annotations 就更多了，普通用户根本无法全部理解。或者说普通 AppDev 不应该去了解 Kubernetes，他们需要的只是发布，甚至不需要关心底层是不是 Kubernetes。</p><p></p><p>AppConfig 经过编译后会生成多个异构基础设施的资源，通过 CI、CLI、GUI 等方式把数据传输给 KusionStack 引擎。引擎是整个体系的核心，负责所有运维操作，是运维意图真正生效到基础设施的地方。他通过统一的方式对接异构基础设施，并对这些资源进行校验、编排、预览、生效、观测、健康检查等一系列操作。</p><p></p><p>值得一提的是，整个过程对运维 Kubernetes 资源非常友好。使用过 Kubernetes 的同学都知道，由于其面向终态、自调和的特点，apply 成功并不代表资源已经可以用，需要等资源调和成功后才能提供服务，如果调和失败了，还需要登陆到集群中，通过 get、describe、log 等命令查看具体报错，整个过程十分繁琐。我们通过技术的手段对这些操作进行了简化，把调和过程中的重要信息以用户友好的方式透露出来。下面的动图是一个简单的示例，当命令下发后，可以清晰的看到所有资源及其关联资源调和过程，直到资源真正的可用。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/10/10b8be58f506f5cf994c3bc1e9f9de73.gif\" /></p><p></p><p>整个体系有如下几个特点</p><p></p><p>以应用为中心</p><p></p><p>应用全方位配置管理，包括计算、网络、存储等所有与应用有关配置应用全生命周期管理，从第一行配置代码到生产可用统一运维“后云原生时代”应用的异构基础设施Kubernetes 友好的工作流，为 Kubernetes 资源提供可观测性、健康检查等高阶能力，释放云原生技术红利复用 Terraform 生态，统一的工作流运维 Kubernetes、Terraform 多运行时资源规模化协同平台灵活的工作流，用户可利用平台的基本能力，自己组合、编排来解决自己的问题App Dev 和 Platform Dev 关注点分离，底层能力迭代无需平台介入，直接供 App Dev 使用纯客户端方案，风险“左移”，尽早发现问题</p><p></p><p></p><h2>一切才刚刚开始</h2><p></p><p></p><p>这套体系经过近两年的探索，已广泛应用在蚂蚁多云应用交付运维，计算及数据基础设施交付，建站运维，数据库运维等多个业务领域，目前 400+ 研发者直接参与了 Konfig 大库代码贡献，累计近 800K Commits，其中大部分为机器自动化代码修改，日均 1K pipeline 任务执行和近 10K KCL 编译执行，全量编译后可产生 3M+ 行的 YAML 文本。</p><p></p><p>不过，这一切才刚刚开始，后云原生时代也才刚刚到来，我们把这套系统开源的目的也是希望邀请业内各方的力量，一起构建一个符合技术发展趋势，能真正解决当下企业规模化运维这个难题的解决方案。蚂蚁 PaaS 团队还有很多经过内部规模化验证的技术沉淀，后续也会开源出来，只有我们远远不够，真诚的邀请大家一起来玩。</p><p></p><p>作者简介</p><p></p><p>李大元（花名：达远），Kusion 项目负责人，来自蚂蚁集团 PaaS 核心团队，PaaS IaC 基础平台负责人。</p><p></p><p>Ref</p><p></p><p>Github：欢迎 Star⭐️</p><p></p><p>Kusion：<a href=\"https://github.com/KusionStack/kusion\">https://github.com/KusionStack/kusion</a>\"KCL：<a href=\"https://github.com/KusionStack/KCLVM\">https://github.com/KusionStack/KCLVM</a>\"Konfig：<a href=\"https://github.com/KusionStack/konfig\">https://github.com/KusionStack/konfig</a>\"</p><p></p><p>官网：<a href=\"https://kusionstack.io/\">https://kusionstack.io</a>\"</p><p></p><p>PPT：KusionStack：“后云原生时代” 应用模化运维解决方案(<a href=\"https://kusionstack.io/blog/2022-kusionstack-application-scale-operation-solution-in-the-post-cloudnative-era/\">https://kusionstack.io/blog/2022-kusionstack-application-scale-operation-solution-in-the-post-cloudnative-era/</a>\")</p><p></p><p>今日好文推荐</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651150837&amp;idx=1&amp;sn=c90a5c8c1b69e55feddeb85649bab64f&amp;chksm=bdb8a1a68acf28b01ae97fd7b1ea3ce4420b0daa3835b487b060eca6e4ac8e8f2775465509fd&amp;scene=21#wechat_redirect\"></a>\"<a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651150838&amp;idx=1&amp;sn=4915ac418c5c39ccf153fb9c0273db83&amp;chksm=bdb8a1a58acf28b379c0a19edb84433459b53ee89c11a7570eb21b7c410d1cfd63242ca79e6b&amp;scene=21#wechat_redirect\">重磅！阿里开源自研高性能核心搜索引擎Havenask</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651150837&amp;idx=1&amp;sn=c90a5c8c1b69e55feddeb85649bab64f&amp;chksm=bdb8a1a68acf28b01ae97fd7b1ea3ce4420b0daa3835b487b060eca6e4ac8e8f2775465509fd&amp;scene=21#wechat_redirect\">程序员离职后为泄私愤远程锁公司服务器硬盘；前程无忧宣传语嘲讽“996”职场人；Twitter 开源工作停摆｜ Q资讯</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651150619&amp;idx=1&amp;sn=ffbfc3cb9c2db61b61fc8602c0e74675&amp;chksm=bdb8a1488acf285efe51cabeb7f3f813d3e3922c725bafda08de24976abe225577e38c4a7fa2&amp;scene=21#wechat_redirect\">再不重视软件开发工具就晚了</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651150511&amp;idx=1&amp;sn=882407d9b730ebf9500c929e88cf254e&amp;chksm=bdb8a0fc8acf29eaf997981aa0c3106f7ff08ee4aec0eafbcf658bae227f621e3294d1631886&amp;scene=21#wechat_redirect\">“睡车间”、削减一切，马斯克为SpaceX定制的文化，不能照搬到互联网公司</a>\"</p><p></p><p></p><p></p>",
    "publish_time": "2022-12-14 20:03:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "字节跳动 kube-apiserver 高可用方案 KubeGateway",
    "url": "https://www.infoq.cn/article/GMRG9IvXoBWHWEtQTsyF",
    "summary": "<p></p><blockquote>本文整理自 2022 年稀土开发者大会，字节跳动云原生工程师章骏分享了 Kubernetes 集群 kube-apiserver 请求的负载均衡和治理方案 KubeGateway。</blockquote><p></p><p></p><p>KubeGateway 是字节跳动针对 kube-apiserver 流量特征专门定制的七层网关，它彻底解决了 kube-apiserver 负载不均衡的问题，同时在社区范围内首次实现了对 kube-apiserver 请求的完整治理，包括请求路由、分流、限流、降级等，显著提高了 Kubernetes 集群的可用性。</p><p>项目地址：https://github.com/kubewharf/kubegateway</p><p></p><h1>1. 背景</h1><p></p><p>在 Kubernetes 集群中，kube-apiserver 是整个集群的入口，任何用户或者程序对集群资源的增删改查操作都需要经过 kube-apiserver，因此它的高可用性决定了整个集群的高可用能力。kube-apiserver 本质上是一个无状态的服务器，为了实现其高可用，通常会部署多个 kube-apiserver 实例，同时引入外部负载均衡器（以下简称 LB）进行流量代理。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e7/e7866543136f05ea917ac07c56ed988c.png\" /></p><p></p><p>为了保证集群的安全，kube-apiserver 对请求进行认证和授权的准入控制，其中认证是为了识别出用户的身份。Kubernetes 支持多种认证策略，比如 Bootstrap Token、Service Account Token、OpenID Connect Token、TLS 双向认证等。</p><p>目前 kube-apiserver 的客户端使用得较多的策略是 TLS 双向认证。TLS 双向认证需要 LB 将请求中的 Client X509 Cert 正确传递给 kube-apiserver，但是传统的七层 LB 无法做到这一点，在转发过程中会丢失 Client X509 Cert，导致 kube-apiserver 无法认证用户。</p><p>因此目前 LB 的选型一般为 LVS、云厂商的 SLB 或 nginx、HAProxy 的四层负载均衡方案。</p><p></p><blockquote>四层负载均衡工作在 OSI 的第四层即传输层，使用 NAT 技术进行代理转发七层负载均衡工作在 OSI 的第七层即应用层，一般是基于请求 URL 地址的方式进行代理转发。</blockquote><p></p><p>但是使用四层 LB 会引起另外的问题，具体如下：</p><p>请求负载不均衡：由于 kube-apiserver 和 client 是使用 HTTP2 协议连接，HTTP2 的多个请求都会复用底层的同一个 TCP 连接并且长时间不断开。在 kube-apiserver 滚动升级或者某个实例重启时，很容易引起迟些启动的 kube-apiserver 在长时间内只有很少的请求数。极端情况下，负载较高的实例会出现 OOM，甚至引起雪崩。</p><p><img src=\"https://static001.geekbang.org/infoq/18/18f975c47e233f1951a580cbab68edd0.png\" /></p><p>缺乏请求治理的灵活性：4 层负载均衡在传输层工作，它只负责消息的传递，但是无法处理应用层的 HTTP 协议的信息，因此相较于 7 层负载缺乏对请求治理的“灵活性”和 “智能性”。比如无法根据请求的内容（比如 verb、url 等字段）制定灵活的负载均衡和路由策略，也无法在网关层对请求级别进行限流降级等处理。</p><p>社区中有一些相关工作试图解决上述问题，但均没有根治问题：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a9/a9a172419a9c95c81bc94251ad63f57d.png\" /></p><p></p><p>随着云原生技术的发展，目前字节跳动 95% 以上的业务跑在 Kubernetes 上，对集群高可用提出了更高的要求。事实上，在生产环境中，我们也曾遇到过多次由于 kube-apiserver 负载不均衡或者缺乏请求治理能力带来的事故，面对以上问题，我们针对 kube-apiserver 的流量特征自研了七层网关 KubeGateway。</p><p></p><h1>2. 架构设计</h1><p></p><p>KubeGateway 作为七层网关接入和转发 kube-apiserver 的请求，它具有以下特点：</p><p>对于客户端完全透明，客户端无需任何改造即可以接入 KubeGateway；支持同时代理多个 K8s 集群的请求，不同 K8s 集群通过不同的域名或者虚拟地址（vip）进行区分。负载均衡从 TCP 连接级别变为 HTTP 请求级别，进而实现快速、有效的进行负载均衡，彻底解决 kube-apiserver 负载不均衡的问题。高扩展性的负载均衡策略，目前支持 Round Robin、Random 策略，负载均衡策略插件化，易于扩展。支持灵活的路由策略，KubeGateway 根据请求信息，包括但不限于 resource/ verb/ user/ namespace/ apigroup 等进行路由。为 kube-apiserver 分组提供基础能力，以低运维成本实现 kube-apiserver 组之间的隔离性，提高集群稳定性。配置管理云原生化，以 K8s 的标准 API 形式管理网关配置，支持配置热更新。支持限流、降级、动态服务发现、优雅退出、upstream 异常检测等网关的通用能力。</p><p>KubeGateway 对外以 K8s 标准 API 的形式提供代理配置管理的服务，主要提供路由转发规则、上游集群 kube-apiserver 地址、集群证书信息、限流等请求治理策略等配置信息的维护变更。它代理 kube-apiserver 的请求的流程如下图所示，主要分为五个步骤：请求解析、路由匹配、用户认证、流量治理和反向代理。下面依次对这些步骤进行详细介绍：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c9/c90df11a2b0e685e3d07ae1561a19e0d.png\" /></p><p></p><p></p><h2>2.1 请求解析</h2><p></p><p>KubeGateway 可以深入理解 kube-apiserver 请求模型，从中解析出更多的信息，它将 kube-apiserver 的请求分为两种类型：</p><p>资源请求，如对 Pod 的 CRUD（增删改查）。非资源请求，如访问 /healthz 查看 kube-apiserver 的健康情况，访问 /metrics 查看暴露的指标等。</p><p>对于资源请求，可以从请求的 URL 和 Header 中解析出以下的内容：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/39/3904812adac07c95bf4d70430e7b1908.png\" /></p><p></p><p>最终一个请求可以解析出多维度的路由字段，如下图所示，这些字段将作为路由选择的依据。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a2/a2908f7dffba1220eaa88ed4de34cef4.png\" /></p><p></p><p></p><h2>2.2 路由匹配</h2><p></p><p>从请求中解析出多维度的路由字段后，可以很方便地组合出非常强大的路由规则来区分不同的 API 请求，比如</p><p>通过 Verb 和 Resource 的结合，我们可以直接匹配到所有的 list pod 的请求。通过 User，UserGroup，ServiceAccount 等，我们可以匹配出 kube-controller-manager，kube-scheduler 等核心控制组件的请求。</p><p>将不同的请求经过路由规则匹配后，我们能对它们做更精细化的分流，限流，熔断等流量控制。</p><p>匹配规则可以直接通过修改 KubeGateway 的配置管理服务对外暴露的 API -- UpstreamCluster 实时生效。</p><p></p><h2>2.3 用户认证</h2><p></p><p>为了能够正确地代理 kube-apiserver 的七层流量，让请求经过代理后的在 upstream kube-apiserver 能被正确地进行认证授权，KubeGateway 需要将请求中的用户信息透传给 kube-apiserver，这要求 KubeGateway 也能认证出请求中的用户信息。</p><p>KubeGateway 将 kube-apiserver 支持的认证方式可以分为以下几类</p><p>基于 x509 客户端证书的认证方式：KubeGateway 通过规则 upstream kube-apiserver 中的 CA 证书，解析出客户端证书中用户和用户组信息基于 Bearer Token 的认证方式：KubeGateway 通过给 upstream kube-apiserver 发送 TokenReview 请求，要求 upstream kube-apiserver 对 Bearer Token 进行认证，从而得到对应的用户信息。</p><p>识别出用户后，KubeGateway 通过 kube-apiserver 提供的 Impersonate（用户扮演）机制进行转发，详细内容会在 2.5.1 部分进行介绍。此外，KubeGateway 只会对请求进行认证，并不会对请求进行授权判断，授权操作由 upstream kube-apiserver 进行。</p><p></p><h2>2.4 请求治理</h2><p></p><p>KubeGateway 作为七层网关，有着丰富的流量治理能力，具体包括：</p><p></p><h3>2.4.1 负载均衡</h3><p></p><p>UpstreamCluster 确定后，Upstream Servers 也随之确定。KubeGateway 按照负载均衡策略从 Upstream Servers 中选择出一个进行请求转发。良好的负载均衡策略可以优化资源效率，最大化吞吐量，减少延迟和容错。</p><p>目前 KubeGateway 支持 Round Robin 和 Random 负载均衡策略，这两种策略简单有效，能够满足大部分场景的需求。此外，KubeGateway 支持灵活的负载均衡策略扩展，可以快速实现 Least Request 等算法，以满足更多场景的需求。</p><p></p><h3>2.4.2 健康监测</h3><p></p><p>KubeGateway 会定期主动地访问 kube-apiserver 的&nbsp;/healthz&nbsp;接口进行健康监测。代理流量只会转发给健康的 kube-apiserver；而不健康的 kube-apiserver 会被临时屏蔽，当它被恢复健康后才会重新有新的流量</p><p></p><h3>2.4.3 限流</h3><p></p><p>KubeGateway 默认提供限流的能力，可以有效地防止 upstream kube-apiserver 在某些情况下过载。它的限流方案相比于 Kubernetes 本身的 APF（API Priority and Fairness）更容易理解和配置。请求经过请求解析和路由匹配之后，KubeGateway 会确定这个请求的限流规则。</p><p>比如我们想要限制普通用户 list pod 的 QPS 但是又要对管控组件（如 controller-manager，scheduler）进行豁免，可以在路由匹配中区分出两种类型的用户然后为他们单独配置 FlowControl 限流规则。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5c/5c33364e436c670c7e97ba11d2b43407.png\" /></p><p></p><p>KubeGateway 提供了两种限流策略：</p><p>token bucket：令牌桶是常用的限流方式，它能有效地限制请求的 QPS 并在一定程度上允许突发的请求。max requests inflight：最大请求数是比令牌桶更严格的限制方式，它限制在某个时刻能够执行的最大请求数量，通常用来限制一些更加耗时的请求，比如在大集群 list 全量 pods，这种请求会可能会持续好几分钟，而且会占用 kube-apiserver 大量的资源，只通过令牌桶的限流会放入过多的请求而造成 kube-apiserver OOM 等问题。</p><p></p><h3>2.4.4 降级</h3><p></p><p>KubeGateway 支持降级以应对集群管控面异常的情况。</p><p>在 kube-apiserver 或者 ETCD 发生故障的时候，可能引起集群的雪崩。在雪崩情况下，部分请求会返回成功，部分请求返回失败，加上客户端不断重试，容易导致集群出现非预期行为，比如 Node NotReady、 Pod 大量驱逐和删除等。</p><p>在这种情况下，开发人员可以通过 KubeGateway 进行降级操作拒掉所有流量。在降级状态下集群相当于被冻结了，所有写入都无法成功，可以保证存量的 Pod 进程保持存活状态，避免对业务造成影响。在集群恢复正常后，首先放开限制允许 Node 上报心跳，然后再恢复集群的其他流量。</p><p></p><h2>2.5 反向代理</h2><p></p><p>KubeGateway 在反向代理部分，有以下关键的技术点：</p><p></p><h3>2.5.1 Impersonate（用户扮演）</h3><p></p><p>在通过流量治理后，KubeGateway 会根据选择出的 kube-apiserver 进行转发。在转发的时候 KubeGateway 通过 impersonate 的机制将用户信息通过 Request Header 传递给 upstream kube-apiserver。在 Request Header 中添加以下信息：</p><p><code lang=\"null\">Impersonate-User:&nbsp;Client&nbsp;用户名\nImpersonate-Group:&nbsp;Client&nbsp;用户组\n</code></p><p>Impersonate 是 kube-apiserver 对外提供的一种机制，它允许一个用户扮演成另外一个用户执行 API 请求。在使用这个机制之前，我们需要在 upstream kube-apiserver 为 KubeGateway 的客户端配置好 Impersonate 的权限，Impersonate 的请求具体的流程如下：</p><p></p><p>kube-apiserver 认证 KubeGateway 用户，识别出用户扮演的行为。kube-apiserver 确保 KubeGateway 具有 Impersonate 权限。kube-apiserver 根据 HTTP Header 识别出 KubeGateway 扮演的用户名和用户组，然后将请求执行者替换成被扮演的用户。对被扮演的用户进行授权验证，检查他是否有权限访问对应的资源。</p><p>kube-apiserver 对于 Impersonate 机制支持的很完善，审计日志中也兼容了 Impersonate。</p><p>最终 KubeGateway 依靠用户认证和 Impersonate 机制，完成原始用户信息的透传，解决了传统七层 LB 无法代理 kube-apiserver 请求的问题。而且在代理过程中，对于客户端是完全透明的，客户端无需进行任何修改即可接入 KubeGateway。</p><p></p><h3>2.5.2 HTTP2 多路复用</h3><p></p><p>KubeGateway 默认使用 HTTP2 协议，基于 HTTP2 协议的多路复用能力，单条连接上默认支持 250 个 Stream，即单个连接上支持 250 个并发的请求，使得 upstream 单个 kube-apiserver 的 TCP 连接数可以降低两个数量级。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e8/e80237af4aacdfed3017c0503123dd31.png\" /></p><p></p><p></p><h3>2.5.3 Forward &amp; Exec 类请求处理</h3><p></p><p>KubeGateway 支持所有原生 kube-apiserver 请求的透明代理。由于 Forward 、Exec 等部分请求需要通过 HTTP 1.1 建立的链接之上使用其他的协议（比如 SPDY、WebSocket 等）来进行通信，KubeGateway 在转发这类请求时会禁止 http2，且支持 Hijacker 处理。</p><p></p><h1>3. 落地效果</h1><p></p><p>经过压测，KubeGateway 性能优异，经过代理后，请求延迟增加在 1ms 左右。目前 KubeGateway 已经平滑的接管了字节所有的 Kubernetes 集群，总 QPS 20w+。在 KubeGateway 的帮助下，研发团队彻底解决了 kube-apiserver 流量不均衡的问题，而且极大增强了 kube-apiserver 请求的治理能力，包括请求分组、路由、限流、降级等，有效提高了集群的稳定性和可用性。</p><p>同时，我们在 KubeGateway 优雅升级、多集群动态证书管理、可观测性上也做了很多优化，具体技术细节以后会进行更多的介绍，敬请期待。</p><p></p><h1>4. 未来演进</h1><p></p><p>目前，KubeGateway 已在 GitHub 开源，未来它会在以下几个方面持续演进：</p><p>提供更完整的 7 层网关能力，比如黑白名单，缓存等。持续提高可观测性，可以在异常情况下能够快速定位到问题，辅助排障。探索基于 KubeGateway 网关实现新型的联邦方案，通过 KubeGateway 可以将多个 K8s 集群透明地聚合成一个集群。</p><p>期待有更多朋友关注和加入 KubeGateway 社区，也欢迎大家在 GitHub 给我们提出各种建议！</p><p></p><h1>5. 关于我们</h1><p></p><p>字节基础架构编排调度团队，负责构建字节跳动内部的容器云平台，为产品线提供运行基石；以超大容器集群规模整体支撑了字节内产品线，涵盖今日头条、抖音、西瓜视频等。</p><p>团队支持业务同时覆盖在线、离线机器学习，推荐/广告/搜索等多种应用场景；在持续多年的超高速增长中，积累了丰富的 Kubernetes/容器超大规模应用经验，旨在打造覆盖多场景，多地域的千万级容器的大平台。欢迎志同道合的同学们加入我们。简历投递：lijiazhuo@bytedance.com</p>",
    "publish_time": "2022-12-14 20:12:30",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "金山云 ：基于JuiceFS 的 Elasticsearch 冷热数据管理实践",
    "url": "https://www.infoq.cn/article/62Qrh3dhfwYQXzPPCLrg",
    "summary": "<p></p><h2>01 Elasticsearch 广泛使用带来的成本问题</h2><p></p><p>Elasticsearch（下文简称“ES”）是一个分布式的搜索引擎，还可作为分布式数据库来使用，常用于日志处理、分析和搜索等场景；在运维排障层面，ES 组成的 ELK（Elasticsearch+ Logstash+ Kibana）解决方案，简单易用、响应速度快，并且提供了丰富的报表；高可用方面， ES 提供了分布式和横向扩展；数据层面，支持分片和多副本。</p><p>ES 的使用便捷，生态完整，在企业之中得到了广泛的应用。随之而来的是物理资源和费用的增加，如何降低 ES 场景的成本成为了大家普遍关心的话题。</p><p></p><h3>如何降低 ES 的成本</h3><p></p><p>ES 的主要的成本是主机成本，主机成本又分为计算资源和存储资源。</p><p>计算资源简单理解就是 CPU 和内存，如果降低 CPU 和主机的数量，意味着计算能力会下降，因此通常会采用冷热节点；热节点使用高配的机器，冷节点使用低配的机器；比如 CPU 内存比从 1:4 降低为 1:8，如8C32G-&gt;4C32G。但是没有降低内存，因为 ES 对内存有更高的需求，来提高响应速度。或者采用低频的 CPU，更老的硬件。</p><p>存储成本是远大于计算成本的，是要重点考虑的成本。现在的存储介质通常是 SSD 和 HDD 这种两种介质，在云厂商 SSD 的成本是 0.8元/G，HDD 的成本是 0.35元/G，对象存储的价格是 0.12元/G。但前两种设备是块设备，提供的是文件系统的协议，但对象存储支持是 S3 协议的，彼此之间不兼容。</p><p><img src=\"https://static001.geekbang.org/infoq/33/332c5753ec45ef7707bf64d102f9fb17.png\" /></p><p>如何将对象存储和 ES 结合起来，我们调研了两种方案。</p><p>第一种方案，修改 ES 存储引擎，适配对象存储调用。这种方式需要修改 ES 的源码，团队要投入很多的人力来做开发设计调研以及最后的验证，投入产出比是非常低的。</p><p>第二种方案是将对象存储作为磁盘来使用，将其挂载到操作系统。把 ES 分为 hot 和 warm 节点。hot节点存储热数据，挂载的是块设备。warm 节点使用对象存储。</p><p></p><h2>02 对象存储文件系统选型</h2><p></p><p>文件系统选型的时候主要考虑了三个方面。第一个是功能，首先要满足最基本的功能需求，第二个是性能，第三个是可靠性。我们调研了 s3fs、 goofys 和 JuiceFS。</p><p><img src=\"https://static001.geekbang.org/infoq/18/18b7df5e9df40736e0f8fa8990d861d3.png\" /></p><p>性能方面， s3fs 和 goofys 在 read 和 write 方面没有本地缓存，其性能是依靠 s3 的性能来支撑的，这两个文件系统整体的性能相比JuiceFS 会低一些。</p><p>最明显的是 mv，对象存储没有 rename 操作，在对象存储中进行 rename 操作就是一个 copy 加 delete，性能代价是非常大的。</p><p>ls 方面，对象存储的存储类型是 kv 存储，不具备目录语义，所以 ls 整个目录结构对于 s3 来说，其实是对整个元数据的遍历，调用代价非常大。在大数据的场景下，性能是非常低的，并且有一些特性功能是不支持的。</p><p>元数据方面，s3fs 和 goofys 没有自己独立的元数据，所有的元数据都是依赖于s3的，JuiceFS 有自己的独立的元数据存储，</p><p>易用性方面，这几个产品都是非常简单易用，通过一个简单的命令就可以实现 s3的挂载；从可维护性来说，JuiceFS 有自己的独立的元数据引擎，我们需要对元数据服务进行运维；从社区的角度来说，JuiceFS 的社区活跃度是最高的。基于以上综合考虑，金山云选择了JuiceFS。</p><p></p><h3>基于 JuiceFS 的测试</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/22/223775cb24633bb747d55e15f69a3148.png\" /></p><p>JuiceFS 产品介绍中第一句话就是 “像本地盘一样使用对象存储”，恰恰是我们做 ES 时所需要的功能。JuiceFS 已经集成了很多种对象存储，金山云的 KS3 也已经完整兼容，只需要再选一个元数据库即可。</p><p>第二功能验证。元数据库常用的有 Redis，关系型据库、 KV 数据库等。我们从这三个层面，元数据库支撑的数据量、响应速度、可运维性来做判断。</p><p><img src=\"https://static001.geekbang.org/infoq/1b/1b23f01470027b1aede210f4f7775a57.png\" /></p><p>从数据量上来说，TiKV 无疑是最高的，但是我们的设计初衷是让每套 ES 集群独立一个元数据库实例，因此不同集群之间的元数据是不进行共享的，为了高可用彼此间需要互相隔离。</p><p>其次在响应速度方面， ES 把 JuiceFS 作为冷节点存储，冷节点存储的数据 IO 要比元数据的调用性能损耗更大，所以我们认为元数据的调用性能不是核心考虑的点。</p><p>从运维的角度来说，关系型数据库大家都比较熟，开发人员都可以很轻松的上手，其次公司是有公司有 RDS For MySQL 产品，有专业的 DBA 团队来负责运维，所以最终是选择了MySQL 作为的元数据引擎。</p><p></p><h3>JuiceFS 可靠性测试</h3><p></p><p>元数据选型完以后，我们对 JuiceFS 进行了可靠性测试，JuiceFS 挂载到主机上只需要三步：第一步，创建文件系统，我们要指定 bucket 来确定它的 AK、SK 以及元数据库；第二步，把文件系统 mount 到磁盘上；第三步，把 ES软链到 JuiceFS 的 mount 目录上。</p><p>虽然设计初衷是将 JuiceFS 作为冷节点，但是在测试的过程中，我们想用一种极限的方式来压测 JuiceFS。我们设计了两种极限压测。</p><p>第一个：将 JuiceFS + KS3 挂载到 hot 节上，把数据实时写到 JuiceFS 。</p><p><img src=\"https://static001.geekbang.org/infoq/03/03d1c14f1761a9f6decbeb3b2776a415.png\" /></p><p>ES 的写入流程是先写到 buffer 中也就是内存里面，当内存满或者是到达索引设定的时间阈值以后，会刷新到磁盘上，这时候会生成 ES 的 segment。它是由一堆的数据和元数据文件来构成的，每次刷新就会生成一系列的 segment，这时候就会产生频繁的 IO 调用。</p><p>我们通过这种压测的方式来测试 JuiceFS 整体的可靠性，同时 ES 本身它会有一些segment merge。这些场景在 warm 节点是不具备的，所以我们是想用一种极限的方式来压测。</p><p>第二种策略，通过生命周期管理来做热数据到冷数据的迁移。</p><p><img src=\"https://static001.geekbang.org/infoq/08/08424f53501c90fdd34b54ffaf9c4254.png\" /></p><p>测试的时候 JuiceFS1.0 还没有发布，测试的过程中确实发现了问题，在实时写的过程中会出现了数据损坏的情况，跟社区沟通后可以通过修改缓存的大小来避免：</p><p></p><blockquote>--attr-cache=0.1 属性缓存时长，单位秒 (默认值: 1)--entry-cache=0.1 文件项缓存时长，单位秒 (默认值: 1)--dir-entry-cache=0.1 目录项缓存时长，单位秒 (默认值: 1)</blockquote><p></p><p>这三个参数的缓存默认是 1，把时长改成 0.1，它确实解决了索引损坏的问题，但是会带来一些新的问题，因为元数据的缓存和数据缓存的时间变短，会导致在执行系统命令的时候，比如 curl 一个系统命令，查看索引数量或者集群状态，正常的情况下，调用可能在秒级，而这种变化可能导致需要数 10 秒才能够完成。</p><p><img src=\"https://static001.geekbang.org/infoq/56/5639397a2fe04347bc122d6f4951dfcf.png\" /></p><p>第二个问题就是写入的 QPS 有明显下降。我们可以看到监控图中 Write QPS 非常不稳定，这并不代表 ES 真实的 QPS，因为监控图中的 QPS 是通过两次得到的 documents 数量来做差得到的，由于旧版 JuiceFS 存在一些内核缓存问题，导致 ES 读到了一些旧数据。我们把该问题反馈给了社区， JuiceFS 1.0 正式发布后问题得到解决。</p><p>我们就进行了新一轮的测试，新一轮的测试确定了 hot 节点 3 台，8C16G 500G SSD， warm 节点 2 台，4C16G 200G SSD，测试时长 1 周，每天写入数据量 1TB(1 副本)，1 天后转到 warm 节点 。没有再出现索引数据损坏情况，通过这次压测没有再出现之前遇到的问题，这就给了我们信心，接下来我们把整个的 ES 逐渐的往这方面来做迁移。</p><p></p><h3>JuiceFS 数据存储和对象存储的差异</h3><p></p><p>JuiceFS 有自己的元数据，所以在对象存储上和 JuiceFS 当中看到的目录结构是不一样的。</p><p><img src=\"https://static001.geekbang.org/infoq/3c/3cc8f9868538cee3935288bb12e1e306.png\" /></p><p>JuiceFS 分为三层结构，chunk、slice、block，因此我们在对象存储上面看到的是 JuiceFS 对文件做拆分之后的数据块。但是所有的数据是通过 ES 来管理，所以这一点用户不需要关注，只需要通过 ES 来执行所有的文件系统操作即可。JuiceFS 会恰当管理对象存储中的数据块。</p><p>经过这一系列的测试后， 金山云将 JuiceFS 应用在日志服务（ Klog）中，为企业用户提供一站式日志类数据服务，实现了云上的数据可以不出云，直接就完成数据采集，存储分析以及告警的一站式服务；云下的数据提供了 SDK 客户端，通过采集工具来实现数据上云的整个整条链路，最后可以把数据投递到 KS3 和 KMR，来实现数据的加工计算。</p><p><img src=\"https://static001.geekbang.org/infoq/b6/b6f61c9aa6f2ac5b6a1beb54e6f57cb1.png\" /></p><p>（金山云日志服务&nbsp;Klog）</p><p></p><h2>03 Elasticsearch冷热数据管理</h2><p></p><p>ES 有几个常用概念：Node Role 、Index Lifecycle Management 、 Data Stream。</p><p>Node Role，节点角色。每一个 ES 节点会分配不同的角色，比如 master、data、ingest。重点介绍一下 data 节点，老版本是分为三种，就是 hot、warm、cold 节点，在最新的版本里面增加了 freeze ，冷冻节点。</p><p>Index Lifecycle Management（ILM）我们分为了 4 个阶段：</p><p>• hot: 索引正在被频繁更新和查询。• warm:索引不再被更新，但查询量一般。• cold: 索引不再被更新，并且很少被查询。这些信息仍然需要可搜索，但如果查询速度较慢也没关系。• delete: 索引不再需要，可以安全地删除。</p><p><img src=\"https://static001.geekbang.org/infoq/2b/2bb3b5cd8ec5730e7c1f65eb4c0ce159.png\" /></p><p>ES 官方提供了一个生命周期的管理工具，我们可以基于索引的大小，docs 数量的大小以及时间策略，把一个大的索引拆分成成多个小索引。一个大索引从管理运维查询，它的开销的代价是非常大的。生命周期管理功能方便我们更灵活地管理索引。</p><p>Data Stream 是在 7.9 版本提出推出了一个新功能，它是基于索引生命周期管理来实现了一个数据流写入，可以很方便地处理时间序列数据。</p><p><img src=\"https://static001.geekbang.org/infoq/33/33f1f494ac53cd5d1b1c158d6bd9604b.png\" /></p><p>在查询多个索引时，通常是把这些索引合并在一起来查询，我们可以使用 Data Stream，他就像一个别名一样，可以自行路由到不同的索引里面。Data Stream 对时序数据的存储管理和查询来说更友好，这个是来对 ES 的冷热管理上面是来更近了一步，方便整个的运维管理。</p><p>合理规划冷节点大小 当我们把冷数据放到对象存储上时，会涉及到冷节点的管理，主要是分为三个方面：</p><p>第一：内存和 CPU 以及存储空间。内存的大小决定了分片的数量。我们通常会在 hot 节点会把物理内存按照一半一半进行划分: 一半给 ES 的 JVM，另外一半是给 Lucene。Lucene 是 ES 的检索引擎，为其分配足够的内存，能提升 ES 查询表现。因此相应地，我们在冷数据节点可以适当的把 JVM 内存，然后减少 Lucene 内存，不过 JVM 的内存不要超过 31G。</p><p>第二：CPU/内存比从前面提到的 1:4 降到 1:8。在存储空间上使用了 JuiceFS 和对象存储可以认为存储空间是无限的，但因为它是挂在冷节点上的，虽然有无限的空间可以使用，但是受限于内存大小，所以这就决定了无限存储空间的只是理想状态。如果再扩大，整个 ES 的在冷节点的稳定性上面就会有比较大的隐患。</p><p>第三：存储空间。以 32G 内存 为例，合理的存储空间为 6.4 TB。可以通过扩大分片的数量来扩大空间，但在 hot 节点，分片数量是要严格控制的，因为需要考虑到 hot 节点的稳定性，在冷节点适当放大这个比例是可以的。</p><p>这里需要重点考虑的因素有两个，就是一个是稳定性，第二个数据恢复时长。因为当节点挂掉，比如 JuiceFS 进程挂掉，或者冷节点挂掉，或者运维的时候需要重新挂载，这时候就需要把所有的数据重新加载到 ES 里面，将会在 KS3 产生大量的频繁读数据请求，如果数据量越多，那么整个的 ES 的分片时间恢复时长会越长。</p><p></p><h3>常用的索引分片管理方法</h3><p></p><p>管理方法主要考虑三个方面：</p><p>• shard 过大: 导致集群故障后恢复缓慢;容易造成数据写热点，导致 bulk queue 打满，拒绝率上升；• shard 过小: 造成更多的 shard，占用更多的元数据，影响集群稳定性;降低集群吞吐；• shard 过多: 造成更多的 segment，IO 资源浪费严重，降低查询速度;占用更多内存，影响稳定性。</p><p>数据在写入的时候，整个的数据大小是不确定的，通常会先创建模板，先确定固定的分片的大小，确定分片的数量，然后再创建 mapping 以及创建索引。</p><p>这时候就可能会出现两个问题，第一个就是分片过多，因为在预期的时候不知道到底要写入到多少数据，有可能我创建的分片多，但是没有更多的数据进来。</p><p>第二个就是创建的分片数量过少，会导致索引过大，这时候会需要把小的分片进行合并，需要把采用更长的时间做数据的 rotate，再把一些小的 segment 合并成更大的 segment，避免占用更多的 IO 和内存。同时还需要删除一些空索引，空索引虽然没有数据，但是它会占用内存。建议合理的分片大小是控制在 20～50g。</p><p></p><h2>04 JuiceFS 使用效果及注意事项</h2><p></p><p>以某线上集群为例，数据规模：每天写入 5TB，数据储存 30 天，热数据储存一周，节点数量：5 个热节点，15 个冷节点。</p><p>采用 JuiceFS 后，热节点保持不变，冷节点从 15 个降到了 10 个，同时我们用了一个 1TB 的机械硬盘做给 JuiceFS 来做缓存。</p><p><img src=\"https://static001.geekbang.org/infoq/25/25592e077279dd91bec1d2c2f98b09c7.png\" /></p><p>可以看到在凌晨的时候会有大量对象存储调用，这因为我们把整个的生命周期的管理操作放到了低峰期来运行。</p><p><img src=\"https://static001.geekbang.org/infoq/d1/d13ebaf632e5b59545dc48e0102910d2.png\" /></p><p>JuiceFS 内存占用通常会在几百 MB，它在高峰期调用的时候会在不到 1.5G 以及它的 CPU 的占用，表现无异常。</p><p>以下是 JuiceFS 的使用注意事项：</p><p>第一：不共用文件系统。因为我们把 JuiceFS 挂载到冷节点上，那么每一台机器上所看到的是一个全量的数据，更友好的方式是采用多个文件系统，每一个 ES 节点采用一个文件系统，这样能做到隔离，但是会带来相应的管理问题。</p><p>我们最终选定的是一套 ES 对应一个文件系统的模式，这个实践带来的问题是：每一个节点都会看到全量数据，这时候就会容易有一些误操作。如果用户要在上面做一些 rm ，有可能会把其他机器上的数据删掉了，但是综合考虑我们是在不同集群之间不共享文件系统，而在同一个集群里，我们还是应该平衡管理和运维，所以采用了一套 ES 对应一个 JuiceFS 文件系统 的模式。</p><p>第二：手动迁移数据到 warm 节点。在索引生命周期管理，ES 会有一些策略，会把热节点的数据迁到冷节点。策略在执行时，有可能是在业务高峰期，这时候会对热节点产生 IO， 然后把数据 copy 到冷节点，再把热节点的数据删除，整个热节点的系统的代价是比较大的，所以我们是采用的手动，来控制哪些索引什么时间迁移到冷节点。</p><p>第三：低峰错期进行索引迁移。</p><p><img src=\"https://static001.geekbang.org/infoq/d0/d03a4a05afb743f2b643102c1c166503.png\" /></p><p>第四：避免大索引。在删除大索引时，它的 CPU 以及 IO 性能要比热节点要差一些，这时候会导致冷节点和 master 失联，失联以后就会出现了重新加载数据，然后重新恢复数据，整个就相当于 ES 故障了，节点故障了，这个代价是非常大的。</p><p>第五：合理的分片大小。</p><p>第六：关闭回收站。在对象存储上， JuiceFS 默认保存一天的数据，但在 ES 的场景下是不需要的。</p><p>还有一些其他涉及到一些大量 IO 的操作，要在 hot 节点完成。比如索引的合并、快照的恢复、以及分片的减少、索引以及数据的删除等，这些操作如果发生在冷节点，会导致 master 节点失联。虽然对象存储成本比较低，但是频繁的 IO 调用成本会升高，对象存储会要按照 put 和 get 的调用次数来收费，因此需要把这些大量的操作来放到热节点上，只供业务侧冷节点来做一些查询。</p><p></p><p>本文作者：&nbsp;</p><p>侯雪峰，金山云研发专家，2017加入金山云，目前负责云存储大数据方面的研发，曾就职于百度，对大数据架构有着深入的研究与学习，云原生时代对计算、存储计算分离、流计算、消息队列方面有着深入学习和成功案例。</p>",
    "publish_time": "2022-12-14 20:22:32",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "veImageX演进之路：FPGA HEIF 静图编码服务性能优化",
    "url": "https://www.infoq.cn/article/yJIWXbAyTAa9AGIP15pL",
    "summary": "<p></p><h2>前言</h2><p></p><p></p><p>压缩技术对于图像、视频应用十分重要。在保证同样主观质量的前提下，如何将图像压缩到更小体积便于互联网信息传输，火山引擎视频云团队不断突破压缩技术“天花板”。</p><p></p><p>字节跳动在公司成立之初就建设了图像处理平台，起初主要服务于今日头条APP的图文资源。随着业务扩展，后逐步服务于抖音图集、短视频封面、图虫等几乎用户能看到的所有图片展示场景。火山引擎视频云团队将字节跳动图像处理的实践，整理为《<a href=\"https://www.infoq.cn/theme/157\">veImageX演进之路</a>\"》系列，将从产品应用、后端技术、前端技术、算法、客户端SDK 详细解读字节跳动背后的图像技术。</p><p></p><p>veImageX是火山引擎基于字节跳动内部服务实践，推出的图像一站式解决方案 ，覆盖上传、存储、处理、分发、展示、质量监控全链路应用。</p><p></p><h1>背景</h1><p></p><p></p><p>互联网内容的展示离不开图片，通过 CDN 展示分发图片可以提升图片访问速度，但是也需要为带宽付费。HEIF 图片格式有着卓越的压缩性能，相比 WebP 可以节省 30% 的图片码率，由此可以为业务节省相当规模的带宽成本。</p><p></p><p>但HEIF 格式是一把双刃剑，相比其他格式，在提升压缩率的同时，也需要消耗更多 CPU 计算资源。为了降低 HEIF 格式的编码计算成本，veImageX 采用了 FPGA 异构架构，逐步将 HEIF 编码的流量从 CPU 计算集群迁移到 FPGA 计算集群。</p><p></p><p>在流量迁移过程中，最初整体流量较小，FPGA 编码服务看起来很稳定。但随着迁移过程递进，当 FPGA 的单卡 QPS 上涨到一定阈值后，FPGA 卡所在宿主机的性能瓶颈逐渐暴露出来，影响了整体的迁移工作。</p><p></p><p>本文会对迁移过程中遇到的性能瓶颈做分析，并给出优化解决方案。经过这一系列优化措施，veImageX整体 CPU 负载从 80% 降低为 30%，相应的服务延时从 140ms 降低为 4ms。</p><p></p><h1>架构</h1><p></p><p>首先，我们看一下 FPGA HEIF 静图分发链路的整体架构。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/38/380f1cb75f731b9cb325a207369d6e63.png\" /></p><p></p><p>链路分为三块：</p><p>●&nbsp;业务 App：一般会集成 veImageX 的图片 SDK。既可以兼容各类图片格式（自然也包括 HEIF），提供了图片的下载、解码、展示功能。也支持将访问图片过程中产生的指标数据上报，这样可以方便在控制台查看这些性能指标，比如解码耗时、图片加载成功率等。</p><p>●&nbsp;veImageX 分发基础链路：主要解决了图片分发问题，提供了基础的图片实时处理能力。其中 CDN 缓存了图片请求，提供了加速访问的能力；veImageX 源站服务主要负责访问权限的校验、流量控制、图片资源下载以及静态图片的主体处理流程。对于 HEIF 静图编码场景，veImageX 源站服务则需要和 FPGA HEIF 编码服务互动，协作完成。</p><p>●&nbsp;FPGA HEIF 编码服务：自上而下可以分为编码服务层、编码驱动层、编码硬件层。</p><p></p><p>为了解决计算资源异构引入的耦合问题，FPGA HEIF 的编码能力通过 HTTP 服务化的方式提供出来。所有的 FPGA 卡部署于字节跳动自研的 Lambda 计算平台。通过 Lambda 函数+资源虚拟化的方式，将 HEIF 编码功能抽象为上游可直接调用的服务，并能确保将编码请求均衡地调度到各个 FPGA 卡上。物理机上的每一张 FPGA 卡和对应的主机 CPU 和内存资源都被打包，经由 Executor 管理。此外，为了防止 FPGA 卡被突发流量打挂，Executor 内置了一个执行队列，用于控制 FPGA 卡的并发吞吐。</p><p></p><p>编码服务层主要负责解析 HTTP 请求，获取待编码的图片数据。待编码的图片数据一般通过 JPEG 格式传入，因此其中内嵌了一个 JPEG 解码器。此外，veImageX HEIF 支持自适应编码选项，通过服务层内的自适应模型预测编码所用到的质量参数。服务层中的 HEIF 编码器是一个适配层，屏蔽了底层计算架构的差异，对于 CPU 和 FPGA 都可以提供相同的编码接口，将传入的 RGBA 像素矩阵编码为 HEIF 码流。</p><p></p><p>编码驱动层中的 FBVC1 编码器可以将图片像素序列编码为二进制码流，上层的 HEIF 编码器拿到这个码流后，按照 HEIF 标准格式封装即可。FBVC1 编码过程中，依赖了 FPGA 驱动库和编码硬件层打交道，发送指令，读写 FPGA 设备。</p><p></p><h1>优化方向</h1><p></p><p></p><h2>降低线程数</h2><p></p><p>在迁移测试FPGA编码服务过程中，我们也遇到了一些性能瓶颈的问题。首当其冲的是，当单机 QPS 达到 2K 时，CPU 负载高达到 60%。通过分析热点，我们可以看到问题出现在 onnxruntime 这个库上。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d8/d8963faf78aaf6d192d4e971e0d0979f.png\" /></p><p>从调用的 API 很容易联想到，这是一个线程相关问题。我们都知道，如果没有手动设置线程数的话，默认会使用物理机核数作为线程数，导致整体的调度开销比较严重。</p><p>因此，需要根据宿主机的CPU配置情况，手动配置线程数，不要使用默认配置，最终将 CPU 负载从 57% 降低到 7%。</p><p></p><h2>调优 GOMAXPROCS</h2><p></p><p>HEIF 的编码服务层是使用 Golang 实现的。而 Golang 中使用了 GOMAXPROCS 这个环境编码来控制底层并发度。默认情况下，GOMAXPROCS 是和物理机核数相关。所以这里也遇到了和上一个问题相同的根因，需要限制整体的并发度。</p><p>针对 GOMAXPROCS 做了调优，在单机 QPS 达到 8K 时，CPU 负载下降了 6% 。</p><p></p><h2>限制磁盘 IO</h2><p></p><p>首先通过 statio 查看磁盘情况，</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e7/e7730ab20c6e48ef74c5ecccdb1502ce.png\" /></p><p>再结合下面的火焰图（黑框内有明显的磁盘 IO 操作）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c8/c8087d6b12f15f3a22a2e9ca0839e422.png\" /></p><p>这里很容易能想到这些磁盘 IO 操作导致了整体延迟的升高。但从结果来看，平均 8ms 还在预期范围内。但 HEIF 编码服务对处理的延迟要求较严格，请求处理过慢会导致请求堆积，此时 FPGA 的计算潜力无法做到完全释放。</p><p>针对这块定向优化，相关延时下降至 0.5ms，CPU 负载下降 3%。</p><p>另外，我们观察到磁盘和 cached memory 较高，这显然不太正常。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9f/9f65fc35c95f010bff2d558be43cf4cb.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/44/44b7084bb2f2dba7b06bf4b63755998f.png\" /></p><p>进一步定位后，确定是编码服务造成的。详细排查后发现，编码驱动层中的 FPGA 驱动程序的部分调试日志未关闭，导致大量的日志写磁盘。当关闭驱动的调试日志后，CPU 负载下降 5% 。</p><p></p><h2>合并 CGO 调用</h2><p></p><p>编码服务包括两部分的 CGO 调用：</p><p>●&nbsp;自适应编码模型预测：每个请求会有最多 5 次的推理，合并为 Batch，减少为 1 次调用</p><p>●&nbsp;FPGA 编码：直接调用 SDK 需要 6 次 CGO 调用，对这部分实现 C 的封装，减少为 2 次调用</p><p>这部分优化影响较小，在延迟数据层面不是很明显，模型预测部分可能有几百 us 的优化。</p><p></p><h2>减少 GC</h2><p></p><p>编码服务每次处理请求都需要获取图像 raw data，因此服务会多次创建 []byte 的图像数据对象，容易导致频繁 GC。</p><p>一个解决问题的思路是在服务启动前预分配一个固定的对象池，每次请求需要的 []byte 对象直接从对象池里拿。此外，也曾尝试过使用 Golang 标准库中的 sync.Pool，但效果不好，可能的原因是 sync.Pool里依然有一些 GC 相关的策略，不符合我们这个场景。</p><p>这部分优化后，CPU 负载下降了 6% 。</p><p></p><h2>均衡中断</h2><p></p><p>从系统的监控中，我们观察到各 CPU 负载不是很均匀。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/34/345edeb1effebdc8c9c443673531d816.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2a/2a4b50cdba7869632298f9267cb7709f.png\" /></p><p>编码过程中发生的中断情况</p><p></p><p>我们可以得出结论，FPGA 的相关中断被只绑定到了特定的 CPU 上，没有分布均匀。这个在当时并没有成为瓶颈，所以优化后没有明显提升。</p><p></p><h2>加速图片解码</h2><p></p><p>我们从火焰图可以看到解码时间占服务延时的较大部分。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d4/d41f05da287557a98684f9a07d1b86bf.png\" /></p><p>对火焰图中黑框内调用栈分析后，观察到有相当部分时间消耗在了 JPEG 解码上。调查后，发现底层 SDK 解码使用了 libjpeg，整体性能不佳。这里我们替换为使用 SIMD 实现的 libjpeg-turbo 解码库后，CPU 负载降低了 10%，耗时减少 2ms。</p><p></p><h1>优化总结</h1><p></p><p>基于优化后的版本再次做性能压测，使用 300x400 分辨率的测试图片，当单机 QPS 达到 10K 时，编码服务整体性能指标变化如下：</p><p>●&nbsp; CPU 负载从 80% 降低为 30%</p><p>●&nbsp;服务延时从 140ms 降低为 4ms</p><p>可以看到，经过我们一套“组合拳”优化后，整体编码服务的性能有了明显提升。</p><p></p><h1>写在最后</h1><p></p><p>目前火山引擎 veImageX已经上述实践形成端到端的解决方案对外输出，帮助每一个互联网企业用更低的成本达到更好的图片加载效果。除了商务降本之外，也可以用更“绿色”的算法降本，为行业降本增效提供了一种创新可能性。</p><p></p><p>了解更多veImageX，点击阅读原文：https://www.volcengine.com/products/imagex</p>",
    "publish_time": "2022-12-14 21:14:26",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]