[
  {
    "title": "Uber将4000多个微服务迁移到新的多云平台Up",
    "url": "https://www.infoq.cn/article/L6OstRwrReRhRCOk8DZN",
    "summary": "<p>Uber将其大部分容器化微服务从µDeploy<a href=\"https://www.uber.com/en-GB/blog/up-portable-microservices-ready-for-the-cloud/\">迁移</a>\"到一个叫作Up的新多云平台，准备将相当一部分计算迁移到云端。Uber花了两年时间将其许多微服务变得可移植，以便可以在不同的计算基础设施和容器管理平台之间进行迁移。</p><p>&nbsp;</p><p>2014年，Uber还只是一个单体应用程序，随着业务的增长，开始迁移到微服务架构。Uber开发了<a href=\"https://www.uber.com/en-DK/blog/micro-deploy-code/?uclick_id=108114e5-eff8-44df-a68f-1ead4dbb5dd1\">µDeploy</a>\"来帮助标准化大规模的应用服务部署。这一措施抽象了主机管理方面的东西，但服务管理仍然是高度手动的，这意味着服务工程师仍然需要决定哪些服务应该在哪个特定区域的哪个区域(物理数据中心)内运行。</p><p>&nbsp;</p><p>Uber高级工程师<a href=\"https://www.linkedin.com/in/mathiasschwarz/\">Mathias Schwarz</a>\"和工程经理<a href=\"https://www.linkedin.com/in/andrewneverov/\">Andrew Neverov</a>\"解释了Uber决定将工程团队与基础设施团队完全解耦的原因：</p><p>&nbsp;</p><p></p><blockquote>在运营本地数据中心时，由于芯片短缺和供应链问题，我们的交付周期较长。2023年2月13日，<a href=\"https://www.forbes.com/sites/danielnewman/2023/02/21/uber-goes-big-on-cloud-with-google-and-oracle-as-cloud-architecture-debate-continues/\">Uber与甲骨文和谷歌</a>\"合作，致力于多元化和降低公司在供应链问题上的风险。如果没有一个可以将底层基础设施与数千名负责为业务提供数百种不同的服务Uber工程师解耦的系统，那么执行这一战略是不可能的。</blockquote><p></p><p>&nbsp;</p><p>2018年，Uber的平台团队开始研究一个新的多云、多租户联合控制平面，负责自动化服务部署和基础设施级迁移。这个叫作Up的新平台旨在成为服务工程师与基础设施系统交互的主要工具。它还将管理和执行最佳实践，以推动安全的代码部署。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/13/13bff7cc61397b396c9b93782e2f3118.png\" /></p><p></p><p>Up的高级架构(来源：<a href=\"https://www.uber.com/en-GB/blog/up-portable-microservices-ready-for-the-cloud/\">Uber工程博客</a>\")</p><p>&nbsp;</p><p>Up平台采用了分层架构，其中体验层负责用户交互和系统管理，包括工作负载管理和伸缩。平台层为体验层组件提供通用的抽象和概念模型，用来表达基于主机能力和计算能力的服务部署约束。联邦层实现与计算集群的集成，并负责基于可用容量和定义的部署约束来执行服务部署。变更管理组件提供渐进式发布功能。最底层包含实际的集群实例，使用了基于<a href=\"https://mesos.apache.org/\">Apache Mesos</a>\"而构建的<a href=\"https://github.com/uber/peloton\">Peleton</a>\" （<a href=\"https://www.uber.com/en-GB/blog/open-sourcing-peloton/\">Uber自己的开源容器编排平台</a>\"）和<a href=\"https://kubernetes.io/\">Kubernetes</a>\"。</p><p>&nbsp;</p><p>为了准备迁移到云端，Uber花了两年时间使所有无状态微服务都变得可移植，可以在无需服务工程师参与的情况下在区域之间进行集中式管理。他们使用现有工具在区域之间移动服务，确保它们是可移植的。首先，他们允许将服务移回原始区域以解决可移植性问题，一旦解决了可移植性问题，就定期移动服务以验证其可移植性并防止出现回归。</p><p>&nbsp;</p><p>在变得可移植之后，微服务逐步自动迁移到Up上，得益于自动伸缩和效率，节省了大量的资金，并大大减少了服务团队的维护负担。Uber的大部分微服务平台现在都通过Up来管理，可以自由地启动其云迁移工作，而不会对服务团队产生太大影响。他们也关注自动化持续交付和部署安全方面的东西。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/10/uber-up-cloud-microservices/\">https://www.infoq.com/news/2023/10/uber-up-cloud-microservices/</a>\"</p>",
    "publish_time": "2023-10-27 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "2023深圳国际金融科技大赛-西丽湖金融科技大学生挑战赛线上公开课",
    "url": "https://www.infoq.cn/article/0pfpxtWTUHylwJFbl1I6",
    "summary": "<p>“2023 深圳国际金融科技大赛（FinTechathon）——西丽湖金融科技大学生挑战赛”已经于 10 月 16 日正式开赛。本次公开课邀请了来自微众的三位技术专家、大赛评委为参赛同学进行干货主题分享，并且将分享人工智能、区块链、产品经理三个赛道的参赛指南。</p>",
    "publish_time": "2023-10-27 09:51:26",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "腾讯混元大模型升级：正式开放“文生图”功能，代码能力大幅提升20%",
    "url": "https://www.infoq.cn/article/w3xGZUPWdyM0iZ1IRUvc",
    "summary": "<p>10月26日，腾讯宣布，腾讯混元大模型迎来全新升级，升级后的腾讯混元中文能力整体超过GPT3.5，代能力大幅提升20%，达到业界领先水平。同时，腾讯混元大模型正式对外开放“文生图”功能。</p><p></p><h2>再升级：代码处理效果胜出ChatGPT 6.34%</h2><p></p><p>&nbsp;</p><p>据混元大模型首次亮相已经过去一个多月。现在除了千亿参数规模大主模型之外，腾讯自研的面向垂直领域的7B和13B模型也首次亮相，这些都是基于Angel机器学习平台打造，业务形态形式也是通过API接入。</p><p>&nbsp;</p><p>目前，千亿模型训练数超过了2.5T，支持多语言高压缩比Tokemizer，单token信息量更大。对于中小Size模型，混元系列与其他开源模型类似：具备多强言能力；同等效果下仅需较少的tokans，并兼顾通用和行业等业参场景。</p><p>&nbsp;</p><p>对于大模型来说，指令遵循上有几个挑战：一是模型泛化能力差，需要解决多任务训练过程的抗干扰问题；二是多轮对话指令记忆弱，需要解决长记忆问题；三是逻辑思维差，代码能力的背后就是逻辑推理；四是优质指令获取非常难，人工标注质量不稳定且周期长，需要人机配合的方式获得更大量的优质数据，开源数据有限，质量参差不齐。</p><p>&nbsp;</p><p>对此，混元LLM-SFT技术主要采取了动态锯齿注意力机制提升泛化能力与对话上文抗干扰能力，使用渐进思维链激发模型逐渐思考的逻辑推理能力，使用Ghost Attention增强模型在多轮对话下的指令跟随能力，并做了复杂指令自动进化。腾讯方面表示，通过这些优化之后，混元综合测评达到国内第一梯队，中文指令下超过GPT-3.5。</p><p>&nbsp;</p><p>腾讯机器学习平台算法负责人康战辉重点介绍了混元大模型代码方面的能力。代码技术主要是两个方向进行了优化：一是代码预训练，二是&nbsp;SFT指令微调。腾讯表示，经过对32种主流语言代码文件、各类计算机书籍和博客的学习增训，腾讯混元代码处理水平提升超过20%，代码处理效果胜出ChatGPT 6.34%，在HumanEval公开测试集指标上全面超过Starcoder、Codellama等业界头部开源代码大模型。具体效果如下：</p><p></p><p></p><p></p><p>腾讯内部目前已经有多个开发平台接入了腾讯混元大模型，工程师们可以使用腾讯混元来进行代码生成、代码补全、代码漏洞检测和修复、表格数据处理、数据库查询等工作。</p><p>&nbsp;</p><p>据悉，目前超过180个腾讯内部业务已接入腾讯混元，包括腾讯会议、腾讯文档、企业微信、腾讯广告和微信搜一搜等。另外，已有来自零售、教育、金融、医疗、传媒、交通、政务等多个行业的客户，通过腾讯云调用腾讯混元大模型API，应用领域涉及智能问答、内容创作、数据分析、代码助手等多个场景。</p><p>&nbsp;</p><p>今年9月首批通过备案后，腾讯混元大模型也已经面向C端用户陆续开放体验，用户通过小程序或网页端，就能与腾讯混元对话。</p><p></p><h2>开放文生图功能，发丝、皱纹等细节效果提升30%</h2><p></p><p>&nbsp;</p><p>文生图是AIGC领域的核心技术之一，也是体现通用大模型能力的试金石，对模型算法、训练平台、算力设施都有较高的要求。混元文生图模型主要围绕着算法模型、数据系统和工程平台三个方面演进。</p><p>&nbsp;</p><p>大模型文生图的难点体现在对提示词的语义理解、生成内容的合理性以及生成图片的效果。针对这三个技术难点，腾讯提出了一系列原创算法，来保证生成图片的可用性和画质。</p><p>&nbsp;</p><p>在语义理解方面，腾讯混元采用了中英文双语细粒度的模型。模型同时建模中英文实现双语理解，并通过优化算法提升了模型对细节的感知能力与生成效果，有效避免多文化差异下的理解错误。</p><p>&nbsp;</p><p>在内容合理性方面，AI生成人体结构和手部经常容易变形。混元文生图通过增强算法模型的图像二维空间位置感知能力，并将人体骨架和人手结构等先验信息引入到生成过程中，让生成的图像结构更合理，减少错误率。</p><p>&nbsp;</p><p>在画面质感方面，混元文生图基于多模型融合的方法，提升生成质感。经过模型算法的优化之后，混元文生图的人像模型，包含发丝、皱纹等细节的效果提升了30%；场景模型，包含草木、波纹等细节的效果提升了25%。</p><p>&nbsp;</p><p>例如，输入提示词“生成可爱的亚洲 4 岁女孩穿着棉质连衣裙，大眼睛，古代中国，摄影风格，汉服”，腾讯混元大模型生成如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ba/bafbb6462bd24649891aed1ec8d931cb.png\" /></p><p>&nbsp;</p><p>目前，腾讯混元文生图能力已经被用于素材创作、商品合成、游戏出图等多项业务中，此外在广告业务下的多轮测评中，腾讯混元文生图的案例优秀率和广告主采纳率分别达到86%和26%，均高于同类模型。</p><p>&nbsp;</p><p>据了解，腾讯混元大模型持续升级背后，离不开腾讯自研一站式机器学习平台Angel的支撑。自研AngelPTM训练框架可提供高效的分布式训练解决方案，具备业界领先的内存利用率和训练吞吐效率，训练速度相比业界主流框架提升1 倍；自研AngelHCF训练框架，具备从蒸馏、微调、压缩到模型加速的完整能力，支持多种模型并行，保证模型的最小化部署及最大化吞吐，推理速度相比业界主流框架FasterTransformer快1.3倍。</p>",
    "publish_time": "2023-10-27 10:28:44",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "大几千的少儿编程课程直接省了！用 Amazon CodeWhisperer 激发孩子的编程兴趣",
    "url": "https://www.infoq.cn/article/tE4JARIoKzaSVav57McG",
    "summary": "<p>我是一个程序员，也是一个父亲。工作之余我会经常和儿子聊他们小学信息技术课学习的 Scratch 和 Kitten 这两款图形化的少儿编程工具。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/65/65b4e9086b642ee460374078474fef26.webp\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f9/f94bd5d82c81449a3e449a9521c7be28.webp\" /></p><p></p><p>我儿子有一次指着书房里显示器上显示的 Visual Studio Code 问我，“为什么我们上课用的开发界面，和爸爸你每天工作用的样子不一样？”</p><p></p><p>所以我也在想一个问题，什么时候可以让我儿子，从 Scratch，Kitten 这种少儿图形化编程工具，过渡到 Visual Studio Code 这种更专业的编程工具去？</p><p></p><p>最近火出圈的 ChatGPT，被很多程序员用来作为自己工作中的代码生成辅助工具。我也在思考如何将 ChatGPT 用到少儿编程领域。由于众所周知的原因，ChatGPT 在国内使用有一定的门槛。但我最近了解到另一款基于人工智能的代码生成器，叫做 <a href=\"https://www.infoq.cn/article/C6ZjsPGuFWk6LBP7i48E?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">Amazon CodeWhisperer</a>\", 我已经将它用来辅导我儿子学习编程了。</p><p></p><p>我和儿子用的开发工具是 Visual Studio Code，我教他在里面写一些最基础的 Python 和 Node.js 代码。</p><p></p><p>Amazon CodeWhisperer, 属于 AWS Toolkit 的一部分，在 Visual Studio Code 打开 Extension Marketplace 面板，通过搜索关键字&nbsp;AWS tool&nbsp;即可安装。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/99/99ec8e803a75b2670f28854947435636.webp\" /></p><p></p><p>安装完毕后，在 Visual Studio Code 左侧多出一个 Developer Tools 的面板，展开&nbsp;CodeWhisperer&nbsp;下拉列表，点击 Start，然后选择&nbsp;Use a personal email to sign up and sign in with AWS Builder ID&nbsp;即可在 AWS 网站上注册一个帐号并登录：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4b/4bd1bb3794139e7d69a29145794d17b9.webp\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d5/d566be9b326d184299d7346e6461c6f8.webp\" /></p><p></p><p>等到我们看到 Developer Tools 面板里，CodeWhisperer 下面显示出&nbsp;Pause Auto-Suggestions&nbsp;显示，说明这个基于 AI 的代码生成器已经成功启用了。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c3/c3a545c64d01bdf8751ceb1c596a665c.webp\" /></p><p></p><p>下面就是孩子们发挥自己的想象，随意向 CodeWhisperer 发出指令进行编程学习了。</p><p></p><p>为什么 CodeWhisperer 可以用来辅助孩子学习编程？职业程序员都清楚，包括 ChatGPT，CodeWhisperer 这些 AI 工具，生成的代码仅仅用来作为参考，绝对不能直接用在生产系统里，因此这些 AI 自动生成的代码，可能存在安全风险，缺乏足够的出错处理等等。而相对来说，孩子通过工具自学编程，不需要考虑这些软件产品开发需要注意的产品标准，只需要把注意力放在工具生成代码的语法，编程逻辑和 API 的调用上就行了。</p><p></p><p>另一方面，CodeWhisperer 的安装和配置非常方便，也不需要像 ChatGPT 那样科学上网。</p><p>下面是一些具体的使用例子。</p><p></p><p>假设小朋友想用 Python 编程，打印出当前目录下所有文件的列表。</p><p></p><p>在 Visual Studio Code 里新建一个 1.py 文件，然后录入如下注释，可以类比成是 ChatGPT 里的 Prompt：</p><p></p><h2>list all files in current folder</h2><p></p><p></p><p>我孩子的英语学习我是全程陪伴的，我觉得现在少儿英语的教育比我上学的时候卷多了。现在小学五年级就已经开始学很多我以前初中才学到的复杂语法，什么定语从句，被动语态，各种完成时等等。这种内卷倒也有一个好处：小朋友用英语编写简单的 Prompt 没有什么障碍：这些 Prompt 都是简单的命令式短句，无非是动词+名词即谓语+宾语的搭配结构。</p><p></p><p>我们在 1.py 里输入&nbsp;#&nbsp;开头的 Prompt，回车之后，稍等片刻，CodeWhisperer 就会以灰色的字体颜色，显示出完成这个 Prompt 所需的第一行代码：import os</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8e/8e7f4e1a539a021f80d2cfdee2d553d3.webp\" /></p><p></p><p>如果我们觉得这行代码能够接受，敲击键盘 Tab 键，就能将其正式书写在 1.py 文件里。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/06/06e488de89fd7bfec1dcf04c835b7189.webp\" /></p><p></p><p>这种一行一行交互式的代码生成方式，适合家长和小朋友坐在一起，出来一行，给孩子讲解一行，也就是逐行理解。</p><p></p><p>我们在&nbsp;import os&nbsp;之后点击回车，稍后片刻，会看到 CodeWhisperer 给我们生成的下一行代码：for file in os.listdir(\".\"):</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5c/5c747b20ac765fe7124adb1404428b6b.webp\" /></p><p></p><p>同理，点击 tab 按钮之后，for file in os.listdir(\".\")&nbsp;这行代码也被我们选定。继续按回车，就会出现下一行代码提示：print(file)</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/10/103c52044b185946f531b1df137e6398.webp\" /></p><p></p><p>就这样，三次回车和三次 Tab 键，就完成了这个需求的编码工作。直接使用 python 命令执行这个编辑好的文件，能得到期望的正确输出。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c2/c2b1f77b521b4297a07b112c6a37576d.webp\" /></p><p></p><p>我又继续做了测试，针对 Node.js，使用同样的 Prompt，也能得到令人满意的代码和执行结果：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fd/fd13d3cdb36be8fe1ee2dbb0afd23bd4.webp\" /></p><p></p><p></p><h2>总结</h2><p></p><p>Amazon CodeWhisperer 作为一款免费使用的基于 AI 的代码生成工具，不仅能够帮助专业的程序员减少机械的代码编写时间，同时也能作为少儿图形化编程的一个补充，给那些学有余力又对编程感兴趣的小朋友，打开一扇新的通往编程世界的大门。</p><p></p><p></p>",
    "publish_time": "2023-10-27 10:53:32",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "“MySQL之父”二次创业失败？MariaDB叫停两款核心产品并裁员28%，分析师：该行为无异于自毁长城",
    "url": "https://www.infoq.cn/article/ZERqNPB6jM9beFELCaQ7",
    "summary": "<p>MariaDB 在重组中放弃产品和员工，获得 2650 万美元贷款以缓冲下跌。</p><p>&nbsp;</p><p>近日， 据外媒报道，MySQL数据库创始人二次创业创办的公司MariaDB在遭遇重组，现正在放弃战略性产品，并裁员28%，因为它正在努力克服上市以来面临的财务挑战。该公司还宣布获得 2650 万美元的新贷款额度。</p><p>&nbsp;</p><p></p><h2>MariaDB停止销售其数据库即服务 SkySQL 和 Xpand</h2><p></p><p>&nbsp;</p><p>在美国证券交易委员会近期发布的一份<a href=\"https://d18rn0p25nwr6d.cloudfront.net/CIK-0001929589/30366574-a5f7-4512-ab57-e643d1fb148d.pdf\">通知中</a>\"，这家从开源MySQL的数据库公司分离出来的公司表示，将停止销售其数据库即服务 SkySQL 和 Xpand。据悉，Xpand是其全球分布式数据库后端。</p><p>&nbsp;</p><p>根据Stack Overflow公布的2023年调查结果，MariaDB在专业开发人员最受欢迎数据库榜单中排名第七，得到近18%专业开发者的使用，这一结果甚至领先于Oracle。DB-Engines则将MariaDB排在市场的第13位，领先于思科最近以280亿美元收购的Splunk。</p><p>&nbsp;</p><p>SkySQL于2020年推出，主要是为了与 Google、Microsoft 和 AWS 等云厂商的 RDBMS（Relational Database Management System，“关系数据库管理系统”） 展开竞争。</p><p>&nbsp;</p><p>2021 年，MariaDB 在 SkySQL 中添加了Xpand 分布式后端，并于今年 5 月为该服务提供了兼容 PostgreSQL 的前端。MariaDB 因其产品背后的工程设计而赢得了分析师的赞扬。</p><p>&nbsp;</p><p>在此情况下，MariaDB被迫发表了一份声明，向客户解释为什么它竭尽全力说服他们购买这些产品，结果却停止了这些产品。</p><p>&nbsp;</p><p>在声明中，MariaDB解释称：“作为重组计划的一部分，公司将把注意力集中在其核心 MariaDB Enterprise Server 数据库产品上。”&nbsp;“与核心 MariaDB Enterprise Server 业务无关的产品，包括 SkySQL 和 Xpand，将不再销售，公司已实施一项计划来帮助现有客户迁移这些产品。”</p><p>&nbsp;</p><p>其中受到打击的将是消费电子巨头三星，因为三星使用了50个Xpand节点作为单个数据库运行，每天维持数百亿笔交易，以帮助三星客户管理设备和用户配置文件。</p><p>&nbsp;</p><p></p><h2>分析师：该行为无异于自毁长城</h2><p></p><p>&nbsp;</p><p>MariaDB在财务状况如此艰难的时刻选择放弃两款核心数据库产品的行为惹来了诸多争议。IDC研究副总裁Carl Olofson祝愿该公司一切顺利，但也表示“目前来看，他们的未来可谓晦暗不明。”</p><p>&nbsp;</p><p>Olofson指出，DBaaS SkySQL及Xpand（该服务的分布式后端）产品其实是“推动该公司未来增长的最佳动力”。</p><p>&nbsp;</p><p>他解释称，“现在我们很难对MariaDB抱乐观态度。数据库用户非常重视技术供应商的稳定性和长期生存能力，还希望看到未来的发展方向，包括能够满足未来数据库需求的功能。”</p><p>&nbsp;</p><p>由于停止了上述两项产品的服务，MariaDB称将实施一项计划，“帮助现有客户从这些产品中迁移出去”。</p><p>&nbsp;</p><p>Gartner公司数据管理与分析副首席分析师Adam Ronthal警告称，小型供应商在部署云服务时确实经常发生类似的问题。</p><p>&nbsp;</p><p>在他看来，“即使能够成功，这类厂商也得远远抢在需求出现之前就投资建设云基础设施。而且这部分业务不太可能在几年之内实现盈利，反而得等待市场需求酝酿成熟。就MariaDB而言，我甚至怀疑相应的市场需求从来就不足以支持数据库平台即服务的可持续发展。”</p><p>&nbsp;</p><p>自2019年以来，Gartner就已经在暗示数据库市场将转向基于云的服务形式。今年的报告更提到，预计到2027年，全球数据库管理系统市场中超70%的收入都将来自云服务。</p><p>&nbsp;</p><p>Ronthal表示，“在这样的背景下叫停云数据库平台即服务项目，与我们认知的市场发展方向明显不符。相比之下，采用开源API（包括PostgreSQL或MySQL）的竞争产品则拥有巨大的市场动力，将使MariaDB越来越难以有效参与竞争。”想要继续使用云SkySQL的用户可以选择MariaDB Cloud，“但这更多只是一项托管服务，并不能算完整的数据库平台即服务产品。”当然，客户也可以转向其他替代服务。</p><p>&nbsp;</p><p>&nbsp;“我怀疑很多用户都会选择迁移。因为需要明确的是，MariaDB只是MySQL的一个分支，它在很大程度上与实现MySQL API的产品相兼容。所以市场上的替代性选项并不少，包括甲骨文的MySQL Heatwave、Amazon Aurora，甚至是基于Vitess的PlanetScale等产品。”</p><p>&nbsp;</p><p>技术外媒The Register就此事采访了MariaDB公司，希望了解项目停止后DBaaS客户们该何去何从。该公司一位发言人指出，“最近2650万美元的融资，表明我们的金融合作伙伴对MariaDB的业务和战略仍拥有坚定的信心。我们仍然专注于发展我们的核心MariaDB Enterprise Server业务，而我们的生态系统合作伙伴也对此番变革给予了积极的认可。”</p><p>&nbsp;</p><p>英国数据库咨询公司Vettabase的创始人兼董事Federico Razzoli表示，MariaDB正在对自己的“财务问题”做出反应，但似乎并没有找到最好的问题解决方式。</p><p>&nbsp;</p><p>Razzoli表示，“该公司投入了大量资源来开发和营销SkySQL及Xpand，但现在他们显然已经决定放弃。Xpand是一套基于ClustrixDB的可靠存储引擎，ClustrixDB则是该公司于2018年收购来的技术。MariaDB公司选择只通过SkySQL这款云解决方案来应用这项技术，其实将其开源可能更有助于拉高其普及度。”</p><p>&nbsp;</p><p>Razzoli还表示，该公司目前仅专注于MariaDB Enterprise，并为开源软件提供支持与现成配置的业务定位，恐怕将很难取得成功。</p><p>&nbsp;</p><p>“说明SkySQL等托管数据库用户在供应商的支持下转向非托管解决方案的确不容易，需要在诸多层面上做出努力，包括配合新的技能。相反，对客户来说直接迁移至兼容MariaDB的其他云服务（例如Amazon RDS）明显更为简单。”</p><p>&nbsp;</p><p>与此同时，那些仍然喜爱SkySQL数据库的用户也可以选择由MariaDB基金会提供的开源选项。MariaDB及MySQL创始人Michael“Monty” Widenius就是该基金会的常务理事。</p><p>&nbsp;</p><p>Razzoli表示，该基金会正努力提高开源MariaDB的市场采用率。</p><p>&nbsp;</p><p>根据Razzoli的预测，“开源版本将越来越独立于MariaDB公司之外，最近将亚马逊列为钻石赞助商就是最直接的证明。MariaDB公司的财务困境和业务决策已经在对客户造成实质性影响，但相信他们不会让MariaDB项目的命运陷入危机。”</p><p></p><h2>MariaDB还将裁员28%以削减成本</h2><p></p><p>&nbsp;</p><p>除了停止销售SkySQL 和 Xpand外，MariaDB还将裁减84个工作岗位，即约28%的劳动力，以降低运营成本。首席营销官弗朗茨·阿曼（Franz Aman）就是裁员名单中的一员。</p><p>&nbsp;</p><p>MariaDB 在一份声明中表示，产品剔除和裁员是董事会批准的重组计划的一部分，以应对今年早些时候开始出现的财务压力。</p><p>&nbsp;</p><p>值得一提的是，MariaDB于2022 年 12 月进行了 IPO，筹集了 1.04 亿美元资金，并通过促成上市的特殊目的收购公司对公共股权的私人投资筹集了 1,800 万美元。</p><p>&nbsp;</p><p>但今年7月份，IPO后仅半年多，纽约证券交易所通知 MariaDB，在该公司股价在 30 天内跌破 1 美元后，该公司未遵守其上市手册。</p><p>&nbsp;</p><p>MariaDB的财务危机早在年初时就已显现。</p><p>&nbsp;</p><p>4月份，该公司裁员26人，并向投资者反复发出“持续经营”警告。其中一个问题是在IPO不稳定后寻求融资。该公司在 3 月份表示：“我们目前正在寻求额外资金，以满足 2023 年 9 月 30 日之后预计的营运资金、运营和债务偿还需求。”</p><p>&nbsp;</p><p>8月份，MariaDB表示正在与一家大型商业银行进行谈判，并更换了首席执行官。</p><p>&nbsp;</p><p>上周，该公司还宣布了一项新的融资方案。RP Ventures 已同意提供 2650 万美元的“高级担保本票”（一种信贷协议形式），年利率为 10%。</p><p>&nbsp;</p><p>该贷款将用于偿还欧洲投资银行贷款，到期日为 2023 年 10 月 11 日。</p><p>&nbsp;</p><p>新的风险投资贷款的到期日最长为 2024 年 1 月 10 日。在此之前，MariaDB 不得进行合并或资本重组。</p><p>&nbsp;</p><p>参考链接：</p><p>&nbsp;</p><p><a href=\"https://www.theregister.com/2023/10/13/mariadb_restructure/\">https://www.theregister.com/2023/10/13/mariadb_restructure/</a>\"</p><p><a href=\"https://d18rn0p25nwr6d.cloudfront.net/CIK-0001929589/30366574-a5f7-4512-ab57-e643d1fb148d.pdf\">https://d18rn0p25nwr6d.cloudfront.net/CIK-0001929589/30366574-a5f7-4512-ab57-e643d1fb148d.pdf</a>\"</p><p><a href=\"https://www.theregister.com/2023/10/19/mariadb_restructure_analysts/\">https://www.theregister.com/2023/10/19/mariadb_restructure_analysts/</a>\"</p>",
    "publish_time": "2023-10-27 10:58:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "建信金科人工智能工程部总经理刘东东确认出席 FCon，分享大语言模型带来金融行业范式转换",
    "url": "https://www.infoq.cn/article/wUH5whLMhBYfZXUvfxVf",
    "summary": "<p><a href=\"https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle\">FCon 全球金融科技大会</a>\"，将于 11 月在上海召开。建信金科人工智能工程部总经理刘东东将发表题为《<a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5593?utm_source=infoqweb&amp;utm_medium=article\">大语言模型带来金融行业范式转换</a>\"》主题分享，介绍在大模型时代下，金融范式在何种场景下进行了转换，如何让建设金融大模型，以及如何建设金融领域大模型的实践探索。</p><p></p><p><a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5593?utm_source=infoqweb&amp;utm_medium=article\">刘东东</a>\"，拥有多年的技术架构实践，曾经在华为、百度、好未来等多家互联网公司担任过技术架构师和技术负责人的岗位。目前主要负责建设银行 AI 技术中台与 AI 领域能力开发。他在本次会议的演讲内容如下：</p><p></p><p>演讲：大语言模型带来金融行业范式转换</p><p></p><p>ChatGPT4 的出现，开启了 AGI 帷幕，重新定义了人与机器的关系。被认为是 250 年不遇的第四次工业革命，必将导致行业洗牌。这次工具升级不是短期技术热点，科技部也意识到大模型是和芯片一样的根技术，不仅关乎公司竞争力，也必将影响国家竞争话语权。我将分享如何建设金融领域大模型的实践探索，期待对你有所启发。</p><p></p><p>演讲提纲：</p><p></p><p>GPT4 - AGI 的小火花范式转换 - 人机关系改变金融的范式转换场景如何建设金融大模型</p><p></p><p>你将获得：</p><p></p><p>○ 了解大模型时代，金融范式在何种场景下进行了转换</p><p>○ 了解如何建设金融大模型</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle\">DevOps&nbsp;在金融企业落地实践</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle\">金融行业大模型应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle\">创新的金融科技应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle\">金融实时数据平台建设之路</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle\">金融安全风险管控</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle\">数据要素流通与数据合规</a>\"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，享 7 折优惠 ，立省 ￥2040！咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png\" /></p><p></p>",
    "publish_time": "2023-10-27 11:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Gartner：2023分布式混合基础设施魔力象限报告（英文版）",
    "url": "https://www.infoq.cn/article/EuvbYTgKuND04zBouKkQ",
    "summary": "<p>根据Gartner的定义，分布式混合基础设施是指提供云原生属性的解决方案，可以根据客户的喜好进行部署和操作。这与基于集中式方法的公共云基础设施服务（IaaS）存在关键区别。这些解决方案是具有统一控制平面的软件或集成硬件。<br />\n分布式混合基础设施为以云或受云启发的方式进行分布式应用部署提供了基础。通过这种方式来提高在公共云基础设施之外的工作负载的灵活性和适应性。<br />\nGartner认为，分布式混合基础设施必备的能力包括：灵活性和可扩展性、统一控制平面、安全性、云原生兼容性、高性能和可靠性、多云互操作性、数据管理和移动、成本管理，这些能力有助于确保分布式混合基础设施能够满足多样化的应用需求，并在保持云思维和灵活性的同时提供稳定和高效的基础设施支持。</p>",
    "publish_time": "2023-10-27 13:54:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AI巨头混战，微软赢麻了？",
    "url": "https://www.infoq.cn/article/C1ucVHUXtSwRNi69o6Ts",
    "summary": "<p></p><blockquote>群雄逐鹿，谁能笑到最后？</blockquote><p></p><p>&nbsp;</p><p>近日，微软和谷歌同时发布了季度财报（2023 年 6-9 月为谷歌三季报和微软 2024 财年第一财季财报）。两大科技巨头同日发布财报，难免被拿来作比较。外媒 The Information 认为，从这两份季度财报来看，微软正在 AI 领域超越其最大的竞争对手——谷歌。</p><p>&nbsp;</p><p>微软方面，第一财季各项业绩全面超过华尔街预期。根据市场咨询服务集团 LSEG 公布的数据，截至 9 月 30 日的当财季，微软公司收入增长 13% 至 565 亿美元，超出分析师们普遍预期的 545.2 亿美元。微软股价在盘后交易中应声上涨 4.2%。Investing.com 高级分析师 Jesse Cohen 表示，“从结果来看，AI 产品正在刺激销售提升，并且已经为营收和利润增长做出了贡献。”</p><p>&nbsp;</p><p>相比之下，谷歌母公司 Alphabet 的云业务增速降至最近 10 个季度以来的最低点，导致该公司股价盘后下跌 5.7%。尽管谷歌的利润和销售额同样超出华尔街预期，但仍无法阻止股价下跌，这意味着投资者更希望该公司能够在 AI 领域取得进展，借此证明其云业务在强大的微软 Azure 和亚马逊云科技面前拥有一战之力。</p><p></p><h2>AI 大战：微软赢了谷歌</h2><p></p><p>&nbsp;</p><p>LSEG 数据显示，坐拥 Azure 云计算平台的微软智能云部门的收入增长至 243 亿美元，高于分析师预计的 234.9 亿美元。Azure 收入增长 29%，高于市场研究公司 Visible Alpha 26.2% 的增幅预期。微软公司并未公布 Azure 的绝对收入数据，而这部分业务正是微软旗下获得 AI 驱动效果最明显的分支。</p><p>&nbsp;</p><p>华尔街正在研究生成式 AI 服务如何为微软带来收益。凭借对初创公司 OpenAI的前瞻性投资，微软已经在市场上建立起早期领先地位。但目前仍有不少 AI 服务尚未广泛落地。微软负责投资者关系的副总裁 Brett Iversen 表示，周二报告的销售额增长，大部分来自客户出于对 AI 方案的期待而重新回归 Auzre 云。</p><p>&nbsp;</p><p>Iverson 在接受路透社采访时指出，“AI 技术的主要作用……包括吸引新客户、拓展现有客户，或者拉拢那些曾经脱离微软的客户重新回归。”</p><p>&nbsp;</p><p>而谷歌母公司 Alphabet 云部门的营收未达预期。</p><p>&nbsp;</p><p>对全球经济放缓的担忧，促使企业客户开始压缩云服务相关支出，其中也包括对昂贵 AI 工具的采用量。这导致谷歌云部门第三季度的收入增幅放缓至 22.5%，低于上个季度的 28%。谷歌云第三季度收入增长 22.5%，达到 84.1 亿美元，增幅回落至 2021 年第一季度以来的最低点。云部门报告的运营收益为 2.66 亿美元，扭转了上年同期 4.4 亿美元的亏损态势。尽管扭亏为盈，但云计算收入未达到华尔街预期的 86.2 亿美元。</p><p>&nbsp;</p><p>谷歌财务主管 Ruth Porat 在周二的电话会议上表示，第三季度的云计算增长主要归功于“客户优化工作”，但并未做出进一步解释。</p><p>&nbsp;</p><p>在 AI 产品融合方面，显然微软做得更好。</p><p>&nbsp;</p><p>微软正着手将 AI 融入自家产品组合，包括每月 30 美元的 Microsoft 365 服务“Copilot”，可用于将当天邮件快速汇总为内容摘要。虽然该工具在下月正式发布前仅向少数试点客户开放，但微软仍要求企业在多次升级系统之后才能使用 Copilot 功能。分析师们认为，这可能意味着 Copilot 还未全面开放，就已经在为微软公司贡献销售额。</p><p>&nbsp;</p><p>投资者还在持续关注微软的大规模数据中心投入，希望了解其花费多少资金来支持 AI 软件。微软本周二表示，其第一财季的资本支出为 112 亿美元，高于上一季度的 107 亿美元，也创下自 2016 财年以来的最高单季支出纪录。</p><p>&nbsp;</p><p>根据 LSEG 的数据，微软 Windows 操作系统及其他相关产品的销售额增长至137亿美元，高于分析师们普遍预期的 128.2 亿美元。此外，包括 LinkedIn 社交网络及办公生产力软件的细分业务增长至 186 亿美元，高于分析师们普遍预期的 182 亿美元。</p><p></p><h2>OpenAI 研发，微软获利</h2><p></p><p>&nbsp;</p><p>此外，The Information 近日的报道指出，微软与开源正两面合围 OpenAI。一边是以企业安全为卖点的微软同质化“倾销”，另一边则是开源阵营迎头赶上，两面夹击又令 OpenAI 倍感压力。</p><p>&nbsp;</p><p>据悉，随着 Salesforce 和 Wix 等大客户转向成本更低的选项，OpenAI 的业务增长正面临压力。买家已经意识到，生成式 AI、特别是 GPT-4，在业务场景下的部署成本相当夸张。如果大型企业想要把这些 AI 工具全部扩展给成千上万的员工，无疑会增添一笔沉重的额外负担。而其他模型提供商及开源大语言模型的涌现，则带来了更为廉价的选择。</p><p>&nbsp;</p><p>Salesforce 公司 AI 高级副总裁 Jayesh Govindarajan 表示，“我们正处于 AI 降本工作的起步阶段。随着这些 AI 产品规模的不断扩大，我们开始专注于实现成本效益，而且对这方面工作的重视程度只会越来越高。”</p><p>&nbsp;</p><p>云原生编排初创公司 Dagster 创始人兼 CEO Pete Hunt 也指出，他最近开始将视频与音频文件摘要服务从 GPT-3.5 迁移到了 Mistral-7B-Instruct 模型。结果就是运营成本从每月约 2000 美元降低到了不足 1000 美元，而且用户并未发现质量有显著降低。</p><p>&nbsp;</p><p>另一边，微软则开始将研究重点放在如何提高 AI 模型效率身上。与此同时，微软似乎也通过自家 Azure 云从 OpenAI GPT 产品组合身上赚得不少收入。其最新一季的云业务数据也支持这个结论，从结果来看，生成式 AI 已经推动 Azure 云业务再次步入增长快车道。</p><p>&nbsp;</p><p>对 OpenAI GPT 模型的独家访问权可能是其中的重要驱动因素，特别是欧洲用户只能通过符合 GDPR 的微软云使用 OpenAI 模型，其中大部分收入也归微软所有。此外，与初创公司相比，微软拥有更强大的企业安全信任优势，因此客户更倾向于通过微软获取生成式 AI 服务。</p><p>&nbsp;</p><p>另外，用户还可以在微软云中获取多种不同模型，例如 Meta 的 Llama 2。即使 Auzre 客户目前只使用 OpenAI，后续也很有可能转向成本更低、或者更加强大的其他模型选项。而如果牢牢绑定 OpenAI，那么选择范围就将仅限于 GPT 模型。</p><p>&nbsp;</p><p>因此，似乎没有什么理由非要跟 OpenAI 直接合作，从微软那边获取 AI 服务反而是更合乎逻辑的方案。OpenAI 公司 CEO&nbsp;Sam Altman&nbsp;最近在谈到与微软的合作时，也表示双方之间确有一些小摩擦。当然，OpenAI 凭借着 ChatGPT 仍在聊天机器人领域占据着绝对的统治地位。但即使如此，目前还难以判断这项业务是否能够盈利。据报道，OpenAI 当前的目标是将年收入提升至 13 亿美元。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.theinformation.com/articles/the-briefing\">https://www.theinformation.com/articles/the-briefing</a>\"</p><p><a href=\"https://www.theinformation.com/articles/openais-corporate-sales-come-under-pressure-as-ai-customers-eye-cheaper-options\">https://www.theinformation.com/articles/openais-corporate-sales-come-under-pressure-as-ai-customers-eye-cheaper-options</a>\"</p><p><a href=\"https://the-decoder.com/microsoft-and-open-source-give-openai-a-hard-time/\">https://the-decoder.com/microsoft-and-open-source-give-openai-a-hard-time/</a>\"</p><p><a href=\"https://globalnews.ca/news/10046550/microsoft-alphabet-sales-google-ai/\">https://globalnews.ca/news/10046550/microsoft-alphabet-sales-google-ai/</a>\"</p>",
    "publish_time": "2023-10-27 14:09:03",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "颠覆式“下云”？英特尔 4400 万美元投资基础设施初创公司，硬刚公有云",
    "url": "https://www.infoq.cn/article/s3FKND2dGscQFzg6FvEi",
    "summary": "<p>编译 | 核子可乐、Tina</p><p>&nbsp;</p><p>云计算是所有计算基础设施的未来。运行云的计算机应该能够购买而不仅仅是租用。仅租赁的云模式是不可持续的。真正认真对待软件的人应该制造自己的硬件，在云计算领域更应该如此。绕开BIOS，我们自主开发的Hubris操作系统，纯由Rust编写而成。</p><p>&nbsp;</p><p>多年以来，已经有不少厂商努力将云功能引入私有数据中心。从Mesosphere到OpenStack，他们软硬件实验背后的开发理念，就是立足本地重现与云类似的计算形式，帮助客户摆脱对亚马逊、谷歌及谷歌等大型云服务商的设施依赖。</p><p>&nbsp;</p><p>Oxide是一家由多位计算技术资深人士建立的初创公司，他们精心打造出自己的性能巨兽、一套强大的新型软硬件技术栈。其运行方式与云资源池非常相似，但却位于客户的自有数据中心之内，强调在安全性与延迟优势两方面满足严苛需求。</p><p>&nbsp;</p><p>如今，这家年轻的企业宣布宣布完成了4400万美元A轮融资，正式将自己的技术愿景推向市场。本轮4400万美元融资由Eclipse领投，英特尔投资公司、Riot Ventures、Counterpart Ventures和Rally Ventures 跟投。截至目前，该公司融资总额已达7800万美元，之前的资金已被用于构建和测试其系统。Oxide 将利用今天宣布的 4400 万美元融资来扩大其系统的采用。&nbsp;在接下来的几个月中，该公司预计将向多家财富 1000 强客户运送更多云计算机。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6c/6c049c68c634e92e1997b9317078d1f8.jpeg\" /></p><p></p><p>&nbsp;</p><p></p><h2>基础设施领域里的“一件大事儿”？</h2><p></p><p>&nbsp;</p><p>今天，该公司的创始人兼CTO Bryan Cantrill在其博客上正式宣布他们的“全球第一台商用云计算机全面上市”。</p><p>&nbsp;</p><p>Cantrill提出了一种范式的转变，他认为云本身并非终点，而是一种简化软件部署和管理的手段，而云服务也不应该被视为租用计算资源的地方。企业应该能够自由选择租用或拥有资源，并能自己充分利用大规模的计算、存储和网络资源。为此，Oxide的新型软硬件技术栈的设计有别于传统本地部署方式，在硬件上该机架级系统包含32个支架，每个支架都搭载着AMD CPU、DRAM和存储设备。在网络方面，Oxide 提供了在所谓的 VPC（即虚拟私有云）服务，可以和云上链接，而且速度也有保证。同时在软件方面配备了自有的固件、虚拟化监控器和控制平台，实现了对技术堆栈的完全掌控。这种高度自主性让Oxide与公共云方案区分开来，允许构建高度可定制和高效的基础设施。</p><p>&nbsp;</p><p>许多公司都曾尝试、但却未能找到能在本地设施内重现云计算的方法，所以Oxide的业务定位堪称大胆。因此，Bryan Cantrill发布消息后仅过了几个小时，Hacker News上的讨论热度就迅速升至第一位。</p><p>&nbsp;</p><p>网友们纷纷表示这是一件相当重要的事情：“ a pretty big deal”、“Its a huge deal”。</p><p>&nbsp;</p><p>有网友点评道：“这不是混合了各种第三方组件的杂乱产品。选择自己集成的方式一旦出现问题，供应商通常会摊手不负责。Oxide 已经将其集成在一起，还包含了构建云所需的所有功能。</p><p>&nbsp;</p><p>此外，他们自己编写了软件，并且所有源代码都是开放的。所以，即使 Oxide 破产，你仍然可以有挽救的机会。具有讽刺意味的是，这看起来像是理查德·斯托曼（Richard Stallman）的梦想的实现，用户可以相互帮助解决问题，而不受第三方供应商的各种限制。”</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3c/3c1f16ceada936881e6f38c9a7d79116.jpeg\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>一种范式的转变</h2><p></p><p>&nbsp;</p><p>公司两位创始人CEO Steve Tuck与CTO Bryan Cantrill，分别曾经在戴尔、Sun Microsystems以及Joyent（一家云基础设施初创公司，于2016年被三星收购）等企业的硬件和云领域积累下超20年工作经验，其中在Joyent的经历更是长达10年。</p><p>&nbsp;</p><p>他们意识到，企业客户对于云资源的态度存在一个根本问题：单纯将云视为租用容量的目的地，而非可以在自己或他人数据中心内使用的资源。但运行云的计算机应该能够购买而不仅仅是租用。“但对于其他人来说，这更多的是一种启示——自从我们创办 Oxide 以来，我们发现越来越多的人意识到仅租赁的云模式是不可持续的。”</p><p>&nbsp;</p><p>另外，他们还有一个信念：云计算机的开发需要硬件和软件的机架级设计。“对于那些只从软件角度思考的人来说，这似乎是反传统的，但事实上，这在技术专家中并没有争议。正如计算先驱艾伦·凯（Alan Kay）所说：真正认真对待软件的人应该制造自己的硬件。”</p><p>&nbsp;</p><p>在云计算领域尤其如此，大型公共云公司很早就得出结论，他们需要设计自己的整体系统。“像Facebook、谷歌和微软这样的超大规模企业掌握着所谓「基础设施特权」，因为他们多年以前就完成了规划，认定自建软硬件能比其他供应商更好地满足业务需求。”</p><p>&nbsp;</p><p>“应该将硬件与软件栈之间进行更好地集成、功率分配和密度规划”，Oxide创始工程师Joshua Clulow有长达15年的服务器采购经历，他指出了其中的关键问题：“现有服务器的软件和硬件往往不是共同设计出来的——现成方法灵活性不足，因此带来很多不必要的复杂性……”</p><p>&nbsp;</p><p>所以，这可以说是一件没有争议但有难度的事情。首先，要有意义地构建云计算机，必须摆脱1U或2U服务器的束缚，并真正将机架视为设计单位。其次，共同设计跨越计算、网络和存储的硬件和软件需要建立一个跨不同学科的非凡团队，需要多领域的深厚的专业知识以及团队合作。</p><p>&nbsp;</p><p>Cantrill表示，正因为之前没有人真正从集成化机架层级的角度看待软硬件，再以此为基础建立起能够运行在自有数据中心之内的产品，所以Oxide公司才能面对这一空白，应运而生。</p><p>&nbsp;</p><p>Tuck指出，“我们投入了十年时间运营公有云基础设施业务，并坚信云计算代表着计算的未来发展方向。但云计算并非最终目的地，相反，这只是一种以编程方式对接大规模计算、存储与网络连接的方法，为的是帮助开发人员更轻松地编写、部署和管理软件。”为此，这些硬件专家决定打造出全新的硬件机架，彻底颠覆人们对于数据中心的理解方式，确保其更管理难度更低、部署效率更高且资源用量更少。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/20/208e9c55214adc70df02230efe1c772a.jpeg\" /></p><p></p><p>&nbsp;</p><p>他们也充分认识到，传统本地部署的最大问题就在于价值转化的速度太慢。在如今这个形势瞬息万变的时代下，缓慢的资源部署与获取速度显然无法接受。为了解决这个问题，他们开发出一套包含32个托架的机架级系统。Cantrill解释称，用户可以将每个托架视为独立系统，其搭载有AMD CPU、DRAM和存储，且全部汇聚至同一资源池当中。</p><p>&nbsp;</p><p>&nbsp;“如果需要添加托架，那么直接将其插入系统即可。”Cantrill还表示，从散装设备到接入机架、连通电源和网络并实际使用，整个部署过程已经从以往的几个月压缩到短短三个小时。</p><p>&nbsp;</p><p>在操作软件层面，该公司开发了自己的底层软件。Cantrill强调，“我们已经开发了自己的固件、自己的虚拟机管理程序和自己的控制平面。”他们认为，与公有云相比，Oxide方案对于技术栈具有显著的控制力优势。</p><p>&nbsp;</p><p>两位创始人很清楚，开发这样的解决方案需要时间。之前曾有批评者表示，如果Oxide真能鼓捣出可交付的产品、他们就把自己的鞋吃了。幸运的是，其产品在正式推广之前，第一台机器已于今年6月30日交付到第一家客户手中。</p><p>&nbsp;</p><p></p><h2>“整体思维”带来了什么样的实际效果？</h2><p></p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fb/fb215825411ceaba5348995e6a038e08.jpeg\" /></p><p></p><p>&nbsp;</p><p></p><blockquote>很难表达我对整个团队的自豪感，以及达成里程碑的兴奋之情。一切才刚刚开始。可以肯定地说，计算世界将从此不同。</blockquote><p></p><p>&nbsp;</p><p>虽然Oxide是一家很年轻的企业，但Oxide在服务器供应商领域却拥有不少狂热的关注者。今年年中，他们交付了第一台产品后发布了一条宣布开发里程碑的推文。这条推文很快就获得2302个赞，其他社交媒体用户也纷纷表示祝贺（其中包括来自Rust缔造者Graydon Hoare的致意）。</p><p>&nbsp;</p><p>至于首位客户对产品的反馈，Cantrill表示，“客户很欣赏这台新机架从安装到虚拟机配置的整个过程，而且运行速度也比以往高了整整一个数量级！”“传统的服务器往往乱乱糟糟、运行起来声音很大，但我们的服务器非常安静……占用的功耗也更低”。Cantrill认为，当前数据中心内的声学管理效果“就像一种无法消除的异味。而造成这些问题的根源，就是整个领域缺乏真正的系统整体思维。”</p><p>&nbsp;</p><p>“每个人在建立自有基础设施时都面临着巨大挑战，而且几乎全部供应商都忽视了这部分实际需求……”Cantrill&nbsp;分享了其中的难点，“现有的服务器生态基础设施已经高度僵化，客户根本没必要只采纳其中的一部分。想用就得接受一切，我们也是这么做的。但在做全盘考量时，我们发现这项工作根本就不能用单一创新来概括，其中包含大量不同要素。”</p><p>&nbsp;</p><p>Cantrill补充道，要想研发新型机架，Oxide还需要开发自己的网络交换机和电源控制器。“我们曾经开玩笑，说Oxide根本就不是一家初创公司，而是九家合一。”但也正因为如此，“我们才能真正把一切整合起来，解决其中真正棘手的问题，并交付给最终用户。”</p><p>&nbsp;</p><p>让Cantrill特别感到自豪的一件事，就是2019年他发表的《我不是要开启BIOS，而是要将其埋葬》（<a href=\"https://www.osfc.io/2022/talks/i-have-come-to-bury-the-bios-not-to-open-it-the-need-for-holistic-systems/\">I have come to bury the BIOS, not to open it</a>\"）的演讲。他还专门强调，Oxide的系统并未使用AMI公司的传统BIOS固件。“AMI是一家上世纪80年代建立的BIOS制造商，不知何故一直在服务器端计算领域保持着核心地位。如今的x86部件，无论是英特尔还是AMD，其中都有AMI代码的身影。这些可都是专有AMI代码，用户看不到、碰不到、更操作不了，却又是设备启动和平台支持的固有组成部分。这当然是个大问题……”</p><p>&nbsp;</p><p>“因为首要得说，BIOS固件质量堪忧。没错，我就是说它写得不好。BIOS固件位于技术栈的最底层，但却不知道其上运行的是什么，所以它会劫持机器来达成自己的目的……这显然与构建可靠系统的目标相违背，也不符合统一的软件/硬件协同设计原则。”Cantrill同时指出，Oxide系统中甚至没有UEFI，“我们不需要这些允许任意软件层在其上运行的东西。”</p><p>&nbsp;</p><p>Cantrill提到在Oxide机架当中，就连负责硬件管理的基板管理控制器（BMC）也被“相应的服务处理程序”所取代。“它运行我们自主开发的Hubris操作系统，纯由Rust编写而成。”Cantrill还强调Oxide彻底绕开了BIOS，“AMD Platform Security Processor执行后的第一条指令将直接指向我们的操作系统，再陆续启动系统的其余部分。”</p><p>&nbsp;</p><p>Cantrill承认，绕开BIOS“绝非易事”，但最终也带来了性能优势。“我们掌控了自己的命运……我很庆幸自己做出了这个艰难的决定。现在的系统启动速度像跟火箭一样迅猛。”</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://oxide.computer/podcasts/oxide-and-friends/1411249\">https://oxide.computer/podcasts/oxide-and-friends/1411249</a>\"</p><p><a href=\"https://oxide.computer/blog/the-cloud-computer\">https://oxide.computer/blog/the-cloud-computer</a>\"</p><p><a href=\"https://news.ycombinator.com/item?id=38023891\">https://news.ycombinator.com/item?id=38023891</a>\"</p><p><a href=\"https://techcrunch.com/2023/10/26/oxide-is-the-latest-startup-to-try-and-bring-the-power-of-the-cloud-on-prem/\">https://techcrunch.com/2023/10/26/oxide-is-the-latest-startup-to-try-and-bring-the-power-of-the-cloud-on-prem/</a>\"</p><p><a href=\"https://thenewstack.io/in-pursuit-of-a-superior-server-oxide-computer-ships-its-first-rack/\">https://thenewstack.io/in-pursuit-of-a-superior-server-oxide-computer-ships-its-first-rack/</a>\"</p><p><a href=\"https://www.osfc.io/2022/talks/i-have-come-to-bury-the-bios-not-to-open-it-the-need-for-holistic-systems/\">https://www.osfc.io/2022/talks/i-have-come-to-bury-the-bios-not-to-open-it-the-need-for-holistic-systems/</a>\"</p><p><a href=\"https://siliconangle.com/2023/10/26/intel-backs-44m-round-private-cloud-infrastructure-startup-oxide-computer/\">https://siliconangle.com/2023/10/26/intel-backs-44m-round-private-cloud-infrastructure-startup-oxide-computer/</a>\"</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-10-27 14:17:40",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "三年投入超3000万，中国计算机大会蚂蚁再发两支科研基金",
    "url": "https://www.infoq.cn/article/ube9oMGXhoVGIG56mQxk",
    "summary": "<p>（图：2023年度“CCF-蚂蚁科研基金”绿色计算及隐私计算专项发布仪式）&nbsp;</p><p></p><p>10月26日，中国计算机学会（CCF）主办的第二十届中国计算机大会(CNCC2023)在沈阳举行。在“CCF-蚂蚁科研基金及产学研合作交流活动”上，蚂蚁集团发布了2023年度“CCF-蚂蚁科研基金”绿色计算及隐私计算两支百万级专项基金，以及多项科研基金成果。“CCF-蚂蚁科研基金”三年已累计投入超3000万，是蚂蚁集团支持前沿科技研究、产学研协同的重要举措。</p><p>&nbsp;</p><p>大模型及AI技术的爆发，为科技创新带来了活力，也产生了算力紧缺和数据安全等问题，亟需学术和产业界联手攻关。本次会上发布的两支专项科研基金皆为二期发布。2023年度“CCF-蚂蚁科研基金”绿色计算专项旨在探讨利用绿色计算相关技术和理念，提升数据中心通用算力、智能算力的使用效率等问题，将在通用计算绿色化、智能算力绿色化、AI助力算力绿色化三个方向开展18个课题研究。</p><p>&nbsp;</p><p>2023“CCF-蚂蚁科研基金” 隐私计算专项聚焦数据要素流通关键技术，围绕隐私计算+大模型、隐私安全增强、隐私计算硬件加速等开展12个前沿探索类课题，重点突出隐私计算与AI算法和算力的深度融合,构建“隐私增强AI算力”。同时开展5个实践论证类课题，将以“隐语”开源框架为研究载体，开展隐私计算产业应用场景研究，形成具有可落地性的技术能力与方法论，以技术手段助力数据要素市场化。</p><p>&nbsp;</p><p>“CCF-蚂蚁科研基金”由蚂蚁集团与中国计算机学会于2020年联合发起，面向全球高校学者，设立人工智能、隐私与安全、区块链、基础系统、数据库等多个研究方向。截至2023年，“CCF-蚂蚁科研基金” 已发布绿色计算、隐私计算、软硬件协同、数据库实验室等专项基金，累计发布超百个前沿科技领域课题，清华大学、北京大学等在内的全球数百所顶尖高校的数百位高校青年学者参与申报，多项研究成果已在蚂蚁集团业务场景得到实际应用。&nbsp;&nbsp;</p><p>&nbsp;</p><p>蚂蚁技术研究院院长陈文光在会上表示，“蚂蚁集团长期以来致力于推动产学研合作，与清华大学、浙江大学、武汉大学等高校建立了科研项目，也希望CCF-蚂蚁科研基金能够吸引更多的青年学者参与到前沿技术攻坚中。希望通过产学研合作和生态建设，把蚂蚁的技术经验和高校的创新、人才培养密切结合，推动科技创新。”</p><p>&nbsp;</p><p>本次交流活动上还发布了“CCF-蚂蚁科研基金”绿色计算专项绿色计算英文研究综述、“CCF-蚂蚁科研基金”优秀应用项目等成果。此外，蚂蚁集团“安心赔”项目还获得了2023年度CCF科技成果奖科技进步二等奖。该项目围绕保险行业理赔难、理赔慢的痛点，通过AI、隐私计算等关键技术，开发了申请快、审核快、调查快的“2日”快赔系统，大幅提升理赔效率，并在17家保险公司93款产品中成功应用，取得了较好的经济效益及行业引领效应。</p><p>&nbsp;</p><p>中国计算机大会是计算领域学术、技术、产业、教育各界宏观探讨发展趋势的年度盛会。围绕数据处理、数据安全与网络安全等议题，蚂蚁集团还主办了数据库、机密计算和可信切面等分论坛。</p><p>&nbsp;</p><p>数据库分论坛从集中式与分布式数据库架构的融合、数据库与大数据的融合、数据库与AI 的融合以及多数据模型的融合等方面，探讨了下一代数据融合技术趋势。机密计算分论坛多位专家学者分享了最新研究与实践进展，希望通过构建健康的机密计算产业生态以及发展国产机密计算技术等方式，推动机密计算真正成为数据“可用不可见”的有力保障 。“可信切面”分论坛围绕安全平行切面技术理论和实践，探讨了企业数字生命体的高质量安全发展路径，并发布了《安全平行切面白皮书2.0》，为营造网络安全新环境，助力数字免疫屏障建设带来技术指引。</p>",
    "publish_time": "2023-10-27 14:53:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "工行宁夏分行将RPA 用于多个业务场景；交通银行推出“交银湾通” 2.0；​人行上海总部牵头成立上海科创金融联盟｜金融科技资讯",
    "url": "https://www.infoq.cn/article/1xuJTsDKwNiFQMMWNQtw",
    "summary": "<p></p><h3>交通银行推出“交银湾通” 2.0</h3><p></p><p></p><p>近日，<a href=\"https://www.infoq.cn/article/wMdyWeSZl6chYwht8ZDz?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">交通银行</a>\"正式推出“交银湾通”2.0 版综合金融服务方案，将重点关注大湾区科技创新、要素市场化和投融资等关键领域。方案整合交行四大业务特色——普惠金融、贸易金融、科技金融和财富金融，并充分利用金融科技手段，迭代升级包括汇兑通、企融通、理财通、乐融通和服务通在内五大系列场景服务方案，旨在为大湾区提供更多元、更普惠、更绿色、更便捷的一体化金融服务。</p><p></p><h3>工行宁夏分行：RPA 技术应用于多个业务场景</h3><p></p><p></p><p>近年来，<a href=\"https://www.infoq.cn/article/uhgZm4TRELfXgizNFtGM?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">工商银行</a>\"宁夏分行以引领数字金融为己任，积极探索数字化转型之路。在这一过程中，机器人流程自动化（Robotic Process Automation，简称 RPA）技术成为了一项关键利器。通过 RPA 技术，工商银行宁夏分行不仅提高了运营效率，还实现了一系列业务场景的智能化应用，为客户和员工创造了价值。</p><p></p><p>RPA 技术是一种基于软件机器人的自动化技术，是一种模拟和执行人类操作计算机任务的软件解决方案。RPA 技术不仅能提高工作效率，还能降低人工错误率，极大地解放人力，使其能够更专注于创新性的工作。RPA 技术在金融领域得到广泛应用，在提高业务效率、强化风险管理、提高客户体验等方面具有显著成效。</p><p></p><h3>宇信科技推出大模型应用产品和解决方案</h3><p></p><p></p><p>近日，<a href=\"https://xie.infoq.cn/article/b4141d13a28606991dac03268?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">宇信科技</a>\"基于对金融业务的深刻理解以及 20 余年积累的应用落地能力和经验，通过自主研发率先推出了首批金融行业大模型应用产品和解决方案，包括 4 个应用级产品和 1 个开发平台，即：开发助手 CodePal、金融数据安全分级分类助手 DataSherpa、AI+ 信贷助手（客户尽调）、AI+ 营销助手、大模型应用开发平台。在垂直行业，大模型的应用将伴随着越来越多的项目应用实践以及市场反馈，不断进行迭代完善，这个不断迭代的过程也是公司的价值贡献体现过程。</p><p></p><h3>人民银行上海总部牵头成立上海科创金融联盟</h3><p></p><p></p><p>10 月 23 日，人民银行上海总部、上海市科委、金融监管总局上海监管局等 9 单位联合发布了上海科创金融服务能力提升专项行动方案，并宣布成立上海科创金融联盟。</p><p></p><p>据悉，方案包括推动银行保险机构建立与科技型企业相适应的组织架构、内部管理制度和产品体系，加大科技保险运用的深度和广度、推动知识产权质押融资提质增效，支持辖区科技型企业借助多层次资本市场发展壮大，充分发挥政策引领作用，加强银企对接、做好政策宣传解读等五方面 20 条举措。</p><p></p><p>上海科创金融联盟由辖内 10 家主要商业银行作为创始会员单位，整合政府、银行、证券、保险、股权投资机构等资源，为上海辖内科创企业提供全生命周期的多元化接力式金融服务。</p><p></p><h3>民生银行启动“民生 e 家”平台建设</h3><p></p><p></p><p>近日，<a href=\"https://xie.infoq.cn/article/4da6f792c0c288a5c468158ce?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">民生银行</a>\"联合多家数字化服务商，举办“民生 e 家”平台建设启动会，旨在通过与线上化软件应用（SaaS）服务商共建生态平台，解决中小微企业数字化转型痛点。中智股份、京东等十余家服务商现场参会。</p><p></p><p>“民生 e 家”是民生银行携手众多 SaaS 服务商共同打造的生态服务平台。平台主要围绕企业的“人事、财务、业务经营”，提供人事薪税、工资代发、员工福利等服务，融合银行账户及快捷支付账户管理能力，为中小微企业提供金融级安全、极简化操作、超流畅体验、普惠式服务的数字化转型综合解决方案，助力企业降本增效，提升经营能力。</p><p></p><p></p><h4>活动推荐</h4><p></p><p>首届<a href=\"https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">FCon全球金融科技大会</a>\"将于 11 月 19-20 日在上海举办。本次大会已邀请到工商银行、招商银行、汇丰银行、兴业银行、中信银行、北京银行、平安人寿、度小满、蚂蚁集团等业界知名银行以及金融机构的大咖，前来分享大模型、 Web 3.0 、隐私计算、数字货币、区块链等前沿技术在金融领域的落地案例。</p><p></p><p>我们诚挚地邀请您加入我们，共同探索金融科技的未来，<a href=\"https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">点击链接</a>\"即可查看全部演讲专题。</p><p></p><p>目前是 <a href=\"https://fcon.infoq.cn/2023/shanghai/apply?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">7 折特惠购票</a>\"，报名立减 ¥2040，咨询购票可联系：17310043226（微信同手机号）。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/e2/ca/e205602269fc52b1557a8c4a4e7b91ca.png\" /></p><p></p>",
    "publish_time": "2023-10-27 14:57:27",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "2023年AI与开源行业：今年第一篇盘点文章出炉了",
    "url": "https://www.infoq.cn/article/f2NZ2bR5H5YrHK5Gzqvh",
    "summary": "<p></p><p>&nbsp;我们正一步步迈向2023年的终点，也许是时候对这一年来AI研究、行业动态以及开源领域发生的主要变化做一番简要回顾了。当然，这篇文章不可能面面俱到。我们只挑干货，一同审视这风云变幻的一年中都有哪些大事值得回味。</p><p>&nbsp;</p><p></p><h2>2022年的趋势进一步扩展</h2><p></p><p>&nbsp;</p><p>这一年中，AI产品并没有表现出任何根本性的发展或者方法创新。相反，2023年的重点就是对过去一年已经生效的趋势做进一步扩展：</p><p>ChatGPT依托的GPT 3.5升级到了GPT 4。DALL-E 2升级到了DALL-E 3。Stable Diffusion 2.0升级到了Stable Diffusion XL。还有更多...</p><p>&nbsp;</p><p>有个有趣的传言说，GPT-4是由16个子模块组成的混合专家模型（MoE）。据传这16个子模块各自拥有1110亿个参数（作为参考，GPT-3总共也只有1750亿个参数）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f9/f9801afa5817941240fc3497febc32b1.png\" /></p><p></p><p>2023年AI现状报告中的GPT-3/GPT-4示意图。</p><p>&nbsp;</p><p>GPT-4属于混合专家模型的情况可能是真的，但我们还无法确定。从趋势上看，行业研究人员在论文中分享的信息要比以往更少。例如，虽然GPT-1、GPT-2、GPT-3乃至InstructGPT论文都公开了架构和训练细节，但GPT-4的架构却一直是个谜。再举另外一个例子：虽然Meta AI的第一篇Llama论文详细介绍了用于模型训练的数据集，但从Llama 2模型开始也不再公布这方面信息。关于这个问题，斯坦福大学上周公布了基础模型透明度指数。根据该指数，Llama 2以54%领先，而GPT-4则以48%排名第三。</p><p>&nbsp;</p><p>当然，要求这些企业发布自己的商业秘密也不太合理。总之，逐渐封闭本身是个有趣的趋势，而且就目前来看我们可能会在2024年继续沿着这个路子走下去。</p><p>&nbsp;</p><p>关于规模扩展，今年的另一大趋势在于输入上下文的长度不断增长。例如，GPT-4竞争对手Claude 2的主要卖点之一，就是其支持最多100k的输入token（GPT-4目前仅支持32k&nbsp;token），也就是说其在为长文档生成摘要方面具备鲜明的优势。另外，Claude 2还支持PDF输入，因此在实践应用中更加灵活实用。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/07/07ba24dc6895780a2ec85f2c42cb4a5c.png\" /></p><p></p><p>使用Claude 2为PDF文档生成摘要。</p><p>&nbsp;</p><p></p><h2>开源与研究趋势</h2><p></p><p>&nbsp;</p><p>我还记得，去年开源社区的主要关注对象还是潜在扩散模型（最典型的代表就是Stable Diffusion）等计算机视觉模型。扩散模型与计算机视觉与一直高度相关、牢牢绑定。但短短一年过去，如今的开源与研究社区新贵已然变成了大语言模型。</p><p>&nbsp;</p><p>开源（更确切地讲，是公开可用）大语言模型的爆发式增长，一定程度上要归功于Meta发布的首个预训练Llama模型。尽管其仍有许可限制，但已经启发了Alpaca、Vicuna、Llama-Adapter、Lit-Llama等衍生成果和众多研究人员/从业者的关注。</p><p>&nbsp;</p><p>几个月后，Llama 2模型正式亮相，在基本取代Llama 1的基础之上表现出更为强大的功能，甚至还提供了微调版本。</p><p>&nbsp;</p><p>然而，目前的大多数开源大语言模型仍然是纯文本模型。好在Llama-Adapter v1和Llama-Adapter v2微调版本有望将现有大模型转化为多模态模型。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/17/1771efc7d07497f4d2423c6261da694a.png\" /></p><p></p><p>Llama-Adapter V2示意图，<a href=\"https://arxiv.org/abs/2304.15010\">https://arxiv.org/abs/2304.15010</a>\"</p><p>&nbsp;</p><p>Fuyu-8B是个值得关注的例外模型，此模型刚刚在10月17日正式发布。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a5/a52f412b49851905e69d2a9598e5e41f.png\" /></p><p></p><p>&nbsp;Fuyu示意图及注释&nbsp;<a href=\"https://www.adept.ai/blog/fuyu-8b\">https://www.adept.ai/blog/fuyu-8b</a>\"</p><p>&nbsp;</p><p>值得注意的是，Fuyu能够将输入补丁直接传递至线性投影（或者叫嵌入层）处以学习其自身图像补丁嵌入，而不会像其他模型/方法那样依靠额外的预训练图像编码器（例如LLaVA和MiniGPT-V），这就极大简化了架构和训练设置。</p><p>&nbsp;</p><p>除了前面提到的少数多模态尝试之外，目前最大的研究重点仍然是如何将GPT-4文本性能迁移至参数范围&lt;100 B的小模型当中。目前的主要技术难点则包括硬件资源成本与限制、可访问数据量不足，以及开发时间太短（受到发布计划的影响，大多数研究人员不可能投入数年时间来训练单一模型）。</p><p>&nbsp;</p><p>然而，开源大语言模型的未来突破并不一定来自将模型扩展至更大规模。在新的一年中，我们将继续关注混合专家模型能否将开源模型提升到新的高度。</p><p>&nbsp;</p><p>另一个有趣的现象，就是我们在研究前沿还看到了一些针对基于Trasnformer大语言模型的替代方案，包括循环RWKV大模型和卷积Hyena大模型，希望能够提供运行效率。但必须承认，基于Transformer的大语言模型仍然是当前最先进的技术方案。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e0/e0845a957314a5673c1997a0032c6e97.png\" /></p><p></p><p>带注释的Hyena大模型架构示意图：&nbsp;<a href=\"https://hazyresearch.stanford.edu/blog/2023-06-29-hyena-dna\">https://hazyresearch.stanford.edu/blog/2023-06-29-hyena-dna</a>\"</p><p>&nbsp;</p><p>总的来讲，2023年是开源活动高度活跃的一年，也带来了不少突破和进步，并切实证明了技术研究工作有着一加一大于二的协同效应。但令人遗憾的是，仍有声音在积极反对和打击开源AI技术。希望我们能够继续保持住这股积极的势头，建立起更高效的解决方案和替代方案，而不仅仅是继续依赖科技巨头们发布的类ChatGPT产品。</p><p>&nbsp;</p><p>在本小节的最后，我们要感谢开源和研究社区的付出。你们的努力让可以运行在单个GPU上的小型高效模型成为现实，包括1.3B参数的phi 1.5、7B参数的Mistral和7B&nbsp;Zephyr，这些都拥有接近大型专有模型的性能表现。这样的趋势令人兴奋，期待相关工作能在2024年带来更多进展。</p><p>&nbsp;</p><p></p><h2>关于生产力的承诺</h2><p></p><p>&nbsp;</p><p>在我看来，开源AI就是开发高效、定制大语言模型的主要途径，其中包括根据各种个人/特定领域数据、针对不同场景进行微调的大模型。我自己经常在社交媒体上讨论Lit-GPT，这是我正在积极贡献的一个开源大语言模型。而且我觉得开源并不代表粗糙，我也希望能在保持开源的同时、让成果拥有出色的设计水平。</p><p>&nbsp;</p><p>自从ChatGPT发布以来，我们看到大语言模型几乎被应用在各个领域。屏幕前的读者可能已经体验过ChatGPT，所以这里就不具体解释大模型在不同场景下的实际效果了。</p><p>&nbsp;</p><p>关键在于，我们得把生成式AI之力用在“正确”的地方。比如说，ChatGPT肯定不擅长回答我们常去的杂货店晚上几点关门。我个人最喜欢的用法之一，就是让它帮我修改文章中的语法、或者是集思广益，包括给句子和段落做做润色等。从更宏观的角度看，大语言模型做出了关于生产力的承诺，可能很多朋友都体验过它带来的效率提升。</p><p>&nbsp;</p><p>除了常规文本大模型之外，微软和GitHub的Copilot编码助手也在日趋成熟，并受到越来越多程序员们的喜爱。今年早些时候，Ark-Invest发布的报告估计，代码助手有望将编码任务的完成时间缩短约55%。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8c/8c736baf931b578fe0828e2dda51ab70.png\" /></p><p></p><p>编码助手示意图&nbsp;<a href=\"https://ark-invest.com/home-thank-you-big-ideas-2023/\">https://ark-invest.com/home-thank-you-big-ideas-2023/</a>\"</p><p>&nbsp;</p><p>实际效果究竟有没有55%尚有争议，但如果大家已经体验过编码助手，就会发现它们确实很有帮助，能够将繁琐的编码相关任务变得更加轻松。</p><p>&nbsp;</p><p>而且有一点是肯定的：编码助手将长期存在，并随着时间推移变得越来越强大。它们最终会取代人类程序员吗？我希望不会，但它们无疑会让现有程序员变得更具生产力。</p><p>&nbsp;</p><p>那这对于Stack Overflow又意味着什么？《AI技术现状》报告中包含一份图表，展示了Stack Overflow与GitHub网站之间的流量对比，后者的逐渐胜出可能就跟Copilot的采用率提升有关。但我个人认为形成这种趋势的应该不只是Copilot，ChatGPT/GPT-4在编码任务方面的表现也相当出色，所以我怀疑Stack Overflow下滑是整个生成式AI阵营发展壮大的共同结果。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b9/b94b244522d10dcf26e825a3510ea43c.png\" /></p><p></p><p>《2023年AI现状报告》（<a href=\"http://stateof.ai/\">http://stateof.ai/</a>\"）中的图表</p><p>&nbsp;</p><p></p><h2>AI仍不完善</h2><p></p><p>&nbsp;</p><p></p><h3>幻觉问题</h3><p></p><p>&nbsp;</p><p>2022年困扰大语言模型的问题在今年仍未得到解决：它们会生成负面内容，而且经常产生幻觉。这一年中倒确实出现了有望解决问题的几种方法，包括利用人类反馈的强化学习（RLHF）以及英伟达的NeMO Guardrails等。然而，这些方法要么过于严格、要么只能算是松散的补丁。到目前为止，还没有任何方法（甚至没有可靠的思路）能够在不削弱大模型能力的同时，100%解决掉幻觉问题。在我看来，这一切都取决于我们如何使用大语言模型：别指望在所有场景下都使用大模型——数学计算还是交给计算器比较好；尽量用大模型处理它最擅长的文本创作等工作，并保证认真检查它的输出内容。</p><p>&nbsp;</p><p>此外，对于特定的业务类应用，探索检索增强（RAG）也是一种值得考虑的折衷方案。在RAG中，我们需要从语料库中检索相关文档段落，再根据检索到的内容微调大模型所生成的文本。这种方式让模型能够从数据库和文档中提取外部信息，而不必记住所有知识。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a6/a68ea9ae615d5aab815c4ae6beccb540.png\" /></p><p></p><p>&nbsp;我自己的新书《Machine Learning Q and AI》（<a href=\"https://leanpub.com/machine-learning-q-and-ai/\">https://leanpub.com/machine-learning-q-and-ai/</a>\"）中的RAG示例。</p><p></p><h3>版权问题</h3><p></p><p>另一个更紧迫的问题，则是围绕AI出现的版权争论。根据维基百科的解释，“对于受版权保护的素材训练而成的大语言模型，模型自身的版权应如何对待仍悬而未决。”总的来说，相关规则似乎仍在起草和修改当中。我希望无论最终规则如何，其内容都应尽可能明确，以便AI研究人员和从业者能够做出相应的调整和行动。</p><p>&nbsp;</p><p></p><h3>评估问题</h3><p></p><p>长久以来，困扰学术研究的一大难题在于，目前流行的基准测试和排行榜所采取的评估方法早就半公开了，其测试集甚至已经被某些大模型用作训练数据。phi 1.5和Mistral就都存在这样的问题。</p><p>&nbsp;</p><p>也有人在用其他大模型自动做评估，但这种方式不擅长处理那些跟偏好相关的问题。总之，不少论文已经在依赖GPT-4作为辅助性质的模型评估方案。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9b/9b0e58f8e55d818ae3262b3852a84a18.png\" /></p><p></p><p>LIMA论文中的人类与GPT_4偏好评估示例。</p><p></p><h3>收入问题</h3><p></p><p>生成式AI目前仍处于探索阶段，不过文本和图像生成器已经能够在特定场景下带来不错的表现。然而，由于高昂的托管和运行时间成本，这些工具能够为企业产生正向现金流仍是个备受争议的问题。例如，有报道称OpenAI过去一年亏损了5.4亿美元。另一方面，最近的报道指出OpenAI目前的单月收入为8000美元，已经足以抵偿或超过其运营成本。</p><p>&nbsp;</p><p></p><h3>伪造图像</h3><p></p><p>由生成式AI引发的另一个大问题，就是伪造图像和视频。这类隐患在当前的社交媒体平台上已经相当明显。伪造图像和视频一直是个大麻烦，而且凭借远低于Photoshop等内容编辑软件的准入门槛，AI技术已经将严重性提升到了新的水平。</p><p>&nbsp;</p><p>目前有一部分AI系统在尝试检测由AI生成的内容，但这些系统在文本、图像和视频检测中的表现都不够可靠。某种程度上，遏制并解决这些问题的唯一方法仍然要依靠人类专家。就如同我们不能轻易相信网上某个论坛或者网站中的医疗或者法律建议一样，我们也绝不能在未经认真核实的情况下，就盲目相信网络上散播的图像和视频。</p><p>&nbsp;</p><p></p><h3>数据集瓶颈</h3><p></p><p>跟之前提到的版权争议相关，不少企业（包括Twitter/X和Reddit）都关闭了免费API以增强经营收入，同时也防止爬取者收集其平台数据用于AI训练。</p><p>&nbsp;</p><p>我见过不少由数据集专职收集厂商打出的宣传广告。从这个角度来看，尽管AI确实会用自动化取代一部分工作岗位，但似乎同时也创造出了新的职务类型。</p><p>&nbsp;</p><p>目前来看，为开源大模型做贡献的最佳方式之一，就是建立一个众包性质的数据集平台，在这里搜集、整理并发布明确允许大语言训练使用的数据资源。</p><p>&nbsp;</p><p></p><h2>RLHF会是破解难题的正确答案吗？</h2><p></p><p>在Llama 2模型套件发布时，我很高兴看到其中包含了可通过聊天进行微调的模型。Meta AI也使用人类反馈强化学习（RLHF）提高了模型的实用性和无害性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b6/b63ec4577538c4d2d18fc452dfc89c91.png\" /></p><p></p><p>Llama 2论文中的注释图：开放基础与微调聊天模型，&nbsp;<a href=\"https://arxiv.org/abs/2307.09288\">https://arxiv.org/abs/2307.09288</a>\"</p><p>&nbsp;</p><p>我一直觉得RHLF是种非常有趣、而且极具前景的方法。但除了InstructGPT、ChatGPT和Llama 2之外，大多数模型并没有广泛采用。可在无意之中，我还是找到了下面这份RLHF流行度统计图表。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cf/cff653f92dad9e5d458d773e8a7f7a5f.png\" /></p><p></p><p>《2023年AI现状报告》中的RLHF流行度图表。</p><p>&nbsp;</p><p>由于RLHF的实施难度比较大，所以大部分开源项目仍然采取指令微调的有监督微调方式。</p><p>RLHF的最新替代方案是直接偏好优化（DPO）。在相关论文中，研究人员表示RLHF中拟合奖励模型的交叉熵损失可以直接用于大模型的微调。根据他们的基准测试，DPO的效率更高，而且在对质量的响应方面一般也优于RLHF/PPO。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/07/0788840d627217fe1376a32e3c2d53c7.png\" /></p><p></p><p>DPO论文（<a href=\"https://arxiv.org/abs/2305.18290\">https://arxiv.org/abs/2305.18290</a>\"）中的注释图。</p><p>&nbsp;</p><p>但DPO似乎还未得到广泛使用。而令我兴奋的是，两周之前Lewis Tunstall及其同事通过DPO训练了首个公开可用的大语言模型，该模型的性能似乎优于由RLHF训练而成的大型Llama-2 70b聊天模型：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f9/f92e39e0ea386cf0b9ebaeb68b302b51.png\" /></p><p></p><p>Zephyr 7B模型公告截图。</p><p>&nbsp;</p><p>而且值得注意的是，RLHF并非专门用于优化基准性能；目前这种方法的主要用途仍是由人类用户评估模型的“实用性”和“无害性”。</p><p>&nbsp;</p><p></p><h2>分类专用模型</h2><p></p><p>&nbsp;</p><p>我上周刚刚在Packt生成式AI大会上做了演讲，特别强调目前文本模型最典型的用例之一就是内容分类。比如说垃圾邮件分类、文档分类、客户评论分类以及对社交媒体上的有毒言论做标记等等。</p><p>&nbsp;</p><p>根据个人经验，使用“小型”大模型（例如DistilBERT）完全可以在单个GPU上实现非常好的分类性能。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/70/70c5d650c538d9caa218d1d73a257c7c.png\" /></p><p></p><p>大家可以通过微调，将“小型”大模型用作文本分类器。</p><p>&nbsp;</p><p>我曾经尝试使用“小型”大模型进行过文本分类演练，其中的Sylvain Payot源自对现成Roberta模型的微调，并成功在IMDB电影评论数据集上实现了高于96%的预测准确率。（作为对比，我在该数据集上训练过的最佳机器学习词袋模型，其准确率也仅有89%。）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f1/f15b5e86e73c4bf29dfdec59e057e62b.png\" /></p><p></p><p>我在深度学习基础课上讨论最佳分类模型。</p><p>&nbsp;</p><p>话虽如此，但目前我还没看到任何将大语言纳入分类场景的尝试或者趋势。大多数从业者在这类场景中仍然使用基于BERT的编码器模型或编码器-解码器模型，例如2022年推出的FLAN-T5。这可能是因为此类架构的效果已经足够令人满意。</p><p>&nbsp;</p><p></p><h2>表格数据集现状</h2><p></p><p>2022年，我写过一篇《表格数据的深度学习简史》（<a href=\"https://sebastianraschka.com/blog/2022/deep-learning-for-tabular-data.html\">A Short Chronology Of Deep Learning For Tabular Data</a>\"），其中涵盖了很多关于深度学习的有趣表格数据方法。而且跟前面提到的分类大模型类似，表格数据集在这一年中同样没有多少进展……也可能是因为我太忙了，没有注意到。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9b/9b8327fce84a251066a0bc03a7dcc124.png\" /></p><p></p><p>表格数据集示例。</p><p>2022年，Grinsztajn等人发表了名为《为什么树状模型在表格数据上仍然优于深度学习？》（<a href=\"https://arxiv.org/abs/2207.08815\">Why do tree-based models still outperform deep learning on tabular data?</a>\"）的文章。我相信对于中小型数据集（10k训练样本）上的表格数据，树状模型（随机森林和XGBoost）优于深度学习方法这个主要结论仍然正确。</p><p>&nbsp;</p><p>以该结论为基础，XGBoost在诞生近十年之后发布了2.0版本大更新。新版本拥有更高的内存效率、支持不适合内存存储的大型数据集以及多目标树等。</p><p>&nbsp;</p><p></p><h2>2023年计算机视觉现状</h2><p></p><p>虽然今年的重头戏都在大语言模型这边，但计算机视觉领域也取得了不少进展。考虑到本文的篇幅已经很长了，这里就不赘述计算机视觉的最新研究成果。具体可以看我在今年CVPR 2023大会上发表的这篇文章（<a href=\"https://magazine.sebastianraschka.com/p/ahead-of-ai-10-state-of-computer\">https://magazine.sebastianraschka.com/p/ahead-of-ai-10-state-of-computer</a>\"）。</p><p>&nbsp;</p><p>除了研究之外，与计算机视觉相关的AI技术还激发出更多新产品和新体验，而且这一切都在2023年内逐步发展成熟。</p><p>&nbsp;</p><p>例如，当我今年参加奥斯汀召开的夏季SciPy大会时，就看到一辆真正无人驾驶的Waymo汽车在街道上驶过。</p><p>&nbsp;</p><p>而在观看电影时，我也看到AI在电影行业中得到愈发普遍的应用。比如《夺宝奇兵5》中哈里森·福特的去衰老特效，就是由制作团队利用演员旧素材训练出的AI模型完成的。</p><p>&nbsp;</p><p>此外，生成式AI功能现已广泛纳入知名软件产品当中，比如说Adobe公司的Firefly 2。</p><p>&nbsp;</p><p></p><h2>2024年展望</h2><p></p><p>终于来到最后的预测环节，这也是最具挑战的部分。去年，我预计大语言模型有望在文本和代码以外的其他领域迎来更多应用。这个结论基本得到证实，比如说DNA大模型HyenaDNA；另外还有Geneformer，这是一个由3000万单细胞转录组预训练而成的transformer模型，用于促进网络生物学的研究。</p><p>&nbsp;</p><p>到2024年，相信大语言模型将在计算机科学之外给STEM研究带来更加广泛的影响。</p><p>&nbsp;</p><p>另一个新兴趋势，则是随着GPU供应不足加之需求旺盛，将有更多企业开发自己的定制化AI芯片。谷歌将加大力度开发TPU硬件，亚马逊推出了Trainium芯片，而AMD可能会逐渐缩小与英伟达之间的差距。现如今，就连微软和OpenAI也在开发自己的定制化AI芯片，唯一的挑战就是各主要深度学习框架能不能为这些新硬件提供全面且有力的支持。</p><p>&nbsp;</p><p>至于开源大模型，其整体水平仍然落后于最先进的闭源模型。目前，最大的开放模型是Falcon 180B。但这应该不是太大的问题，因为多数人根本承受不了如此巨大模型所占用的海量硬件资源。正如前文所提到，我更希望看到由多个小型子模块组成的开源混合专家模型（MoE）。</p><p>我对众包数据集问题也抱持乐观态度，并相信DPO的崛起将给先进开源模型带来新的监督微调选项。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://magazine.sebastianraschka.com/p/ai-and-open-source-in-2023\">https://magazine.sebastianraschka.com/p/ai-and-open-source-in-2023</a>\"</p><p>&nbsp;</p>",
    "publish_time": "2023-10-27 15:48:45",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]