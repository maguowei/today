[
  {
    "title": "谷歌深夜炸场！发布最强开放模型Gemma：性能碾压LLaMA，可在笔记本上运行",
    "url": "https://www.infoq.cn/article/MNJ8kPf81k5ZG6ssPjqp",
    "summary": "<p></p><blockquote>谁将成为开放模型最强王者？</blockquote><p></p><p></p><h2>谷歌发布Gemma开放模型</h2><p></p><p>&nbsp;</p><p>在推出最新版Gemini 型号不到一周后，当地时间2月21日，谷歌再次公布Gemma项目——一个新的轻量化开放权重模型家族，自即日起已开始面向全球开放，可用于商业和研究用途。据悉，Gemma由Google DeepMind及谷歌旗下其他团队开发而成，采用与Gemini模型相同的研究与创建技术，并因拉丁语的gemma“宝石”一词而得名。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2b/2b1a3165d1c68578e08ded340b3ddd18.png\" /></p><p></p><p>谷歌表示，经过预训练及指令微调的Gemma模型能够在用户的笔记本电脑、工作站或者Google Cloud上运行，并可被轻松部署在Vertex AI及Google Kubernetes Engine（GKE）之上。谷歌称，希望Gemma能希望帮助开发人员和研究群体以负责任的方式构建AI方案。</p><p>&nbsp;</p><p>本次谷歌共发布两种模型权重版本：Gemma 2B与Gemma 7B，每个版本都将公开经过预训练与指令微调的变体。除了模型权重之外，谷歌还发布了用于支持开发者创新、促进协作并指导受众以负责任方式使用Gemma模型的更多配套工具。比如新的Responsible Generative AI Toolkit（负责任生成式AI套件）将为使用Gemma创建安全AI应用提供引导与基础工具。此外，谷歌还通过原生Keras 3.0提供跨越各主要框架的推理与监督微调（SFT）工具链，包括JAX、PyTorch及TensorFlow等。</p><p>&nbsp;</p><p>除了即开即用的Colab和Kaggle notebooks以外，谷歌还将整合Hugging Face、MaxText、英伟达NeMo以及TensorRT-LLM等流行工具，帮助用户轻松开始使用Gemma。</p><p>&nbsp;</p><p>用户可以利用自己的数据对Gemma模型进行微调，从而适应特定应用场景需求，例如摘要或检索增强生成（RAG）。此外，Gemma还支持多种工具和系统：</p><p>&nbsp;</p><p>多框架工具：用户可以随意挑选自己最喜爱的框架，并跨越多框架Keras 3.0、原生PyTorch、JAX以及Hugging Face Transformers等建立推理与微调的参考实现。跨设备兼容：Gemma模型能够跨越多种流行设备实现运行，包括笔记本电脑、台式机、物联网、移动设备和云，从而实现AI功能的广泛可及。顶尖硬件平台：谷歌与英伟达合作，针对英伟达GPU对Gemma做出优化，范围涵盖从数据中心到云端、再到本地RTX AI PC，确保既保持行业领先的性能、又与顶尖硬件适配良好。针对Google Cloud进行优化：Vertex AI提供广泛的MLOps工具集，其中包含一系列微调选项以及包含内置推理优化的一键部署方案。全托管Vertex AI工具或自管理GKE还可提供高级自定义功能，包括立足任一平台跨越GPU、TPU和CPU部署起经济高效的AI基础设施。</p><p></p><h2>谷歌：Gemma是同等规模内性能最强模型</h2><p></p><p>&nbsp;</p><p>谷歌并未发布具体的说明文件，将这些模型与Meta和Mistral等厂商的同类模型做性能对比，而只是泛泛提到Gemma模型“行业领先”。目前唯一可以确定的，就是Gemma模型家族为密集纯解码器模型，与Gemini模型（以及更早的PaLM模型）拥有相同的技术和基础设施组件。</p><p>&nbsp;</p><p>谷歌表示，与其他开放模型相比，Gemma 2B与7B均在同等规模范围内拥有最出色的性能表现。Gemma模型能够直接在开发人员的笔记本电脑或台式计算机上运行，而且值得注意的是，Gemma在关键基准测试中甚至超越了更大模型，同时严格遵守谷歌提出的安全与负责任输出标准。关于Gemma性能、数据集构成以及建模方法等细节信息，谷歌还专门发布了一份技术报告：<a href=\"https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf\">https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf</a>\"。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/a1/a1ee73332462cf988b0d47f7beb9a0a3.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dc/dca8eec4bbbccda35c2b20a08ae26777.png\" /></p><p></p><p>Gemma在设计之初就以谷歌的AI原则为核心。为了确保Gemma预训练模型安全可靠，谷歌采用自动化技术从训练集中筛除掉了某些个人信息及其他敏感数据。此外，谷歌还利用人类反馈（RLHF）对模型进行广泛微调与强化学习，确保指令微调模型始终遵循负责任的行为准则。为了了解并降低Gemma模型的风险状况，谷歌还开展了稳健性评估，包括手动红队演练、自动对抗测试以及危险活动模型能力评估等。</p><p>&nbsp;</p><p>谷歌还随Gemma模型一道发布新的Responsible Generative AI Toolkit负责任生成式AI套件，旨在帮助开发人员和研究群体优先构建起安全且负责任的AI应用程序。这套工具包中包括：</p><p>&nbsp;</p><p>安全分类：谷歌提供一种新颖方法，能够以最少的示例构建起强大的安全分类器。调试：模型调试工具，可帮助用户调查Gemma的行为并解决潜在问题。指引：用户可以根据谷歌在开发和部署大语言模型方面的经验，获取模型构建方面的最佳实践。</p><p></p><h2>开放模型正成为主流</h2><p></p><p>&nbsp;</p><p>虽然谷歌一直强调这些模型的开放属性，但需要注意的是，它们并不属于开源成果。实际上，在之前的新闻发布会上，谷歌公司的Jeanine Banks在强调搜索巨头对于开源的承诺之余，曾专门指出谷歌对于Gemma模型的开源态度十分谨慎。</p><p>&nbsp;</p><p>Banks解释称，“开放模型如今在行业内已经相当普遍，而且所指的通常是开放权重模型。也就是说，开发人员和研究人员可以广泛使用这些模型，对模型进行定制和微调；但与此同时，使用条款对于重新分发及所开发变体的所有权问题，往往须根据模型自身的特定情况而有所差异。因此，我们认为开放模型与传统意义上的开源模型及开源代码存在一定区别，将Gemma模型称为开放模型可能最为贴切。”</p><p>&nbsp;</p><p>也就是说，开发人员可以使用该模型进行推理、也可随意对模型进行微调。谷歌团队还认为，这样规模的模型在多种场景下都非常适用。</p><p>&nbsp;</p><p>谷歌DeepMind产品管理总监Tris Warkentin表示，“过去一年以来，生成式AI的质量迎来了大幅提升。以往需要超大模型才能完成的工作，如今已经可以在最先进的小型模型上实现。这无疑开发了AI应用开发的全新方向，我们对此深感兴奋。如今，我们甚至可以在本地开发者台式机或笔记本电脑上使用RTX GPU，或者在Google Cloud Platform上的单一主机中利用云TPU运行大模型推理和微调。”</p><p>&nbsp;</p><p>谷歌在这一领域的其他竞争对手也纷纷入场，拿出自己的开放模型。年轻的Gemma家族能不能在对抗中胜出，恐怕只有时间能给出答案。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://blog.google/technology/developers/gemma-open-models/\">https://blog.google/technology/developers/gemma-open-models/</a>\"</p><p><a href=\"https://techcrunch.com/2024/02/21/google-launches-two-new-open-llms/\">https://techcrunch.com/2024/02/21/google-launches-two-new-open-llms/</a>\"</p>",
    "publish_time": "2024-02-22 11:58:03",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "收入翻三倍，市值超谷歌！英伟达凭人工智能创营收纪录，黄仁勋：生成式AI已到临界点",
    "url": "https://www.infoq.cn/article/dFjJJT7PRCVpg2GoW4As",
    "summary": "<p>当地时间2月21日，英伟达 (Nvidia) 公布季度收入飙升 265%，并预计由于人工智能方面的支出狂潮，销售额将进一步强劲，该公司股价大幅上涨。目前，英伟达市场估值约为 1.7 万亿美元，已超过谷歌母公司 Alphabet，成为第三大最有价值的上市公司。</p><p>&nbsp;</p><p>具体看，英伟达去年第四季度营收221亿美元，远超华尔街预期的204亿美元，较第三季度增长 22%，比去年同期增长 265%。全年营收创历史新高 609 亿美元，增长 126%。</p><p><img src=\"https://static001.geekbang.org/infoq/f5/f5590f1966c44a8b83815df39c23ca90.png\" /></p><p></p><p>英伟达表示第四季度每股收益达到 4.93 美元，超出分析师预期的 4.59 美元。净利润较上年同期增长近770%，达到约123亿美元，也超出分析师预期的104亿美元。财报发布后，该股盘后涨幅超过 8%</p><p>&nbsp;</p><p>Synovus Trust Company 副总裁 Dan Morgan 表示，尽管 Meta、亚马逊、IBM 和微软都已经开始生产一些自己的芯片，但英伟达占据了人工智能半导体销售额的 70% 左右。</p><p>&nbsp;</p><p>英伟达创始人兼首席执行官<a href=\"https://www.ft.com/stream/5ca7302b-b782-44a0-97d7-d9d2b98262e0\">黄仁勋</a>\"表示：“加速计算和生成式人工智能已经达到了临界点。 ”&nbsp;“全球各地公司、行业和国家的需求正在激增。”</p><p>&nbsp;</p><p>英伟达股价在过去一年中飙升：2023 年股价增长了约 230%，这意味着英伟达现在对更广泛的市场也非常重要。</p><p>&nbsp;</p><p>在当地周二的一份报告中，高盛分析师称英伟达是“地球上最重要的股票”。据报道，英伟达是2023年标准普尔 500 指数上涨的最大单一推动者，约占该指数涨幅的四分之一。它的重要性变得如此之大，以至于一些投资者和分析师担心财报的发布将带来类似于通胀数据发布的市场风险。</p><p>&nbsp;</p><p>英伟达对于蓬勃发展的人工智能领域至关重要，为各家的人工智能系统提供了大规模算力。得益于与谷歌、亚马逊和思科等基础设施巨头的合作，该公司第四季度核心数据中心业务的销售额同比增长 409%，达到创纪录的 184 亿美元。英伟达去年动作包括：</p><p>&nbsp;</p><p>与 Google 合作，针对Google 开放语言模型Gemma 推出了跨 NVIDIA 数据中心和 PC AI 平台的优化。扩大与 Amazon Web Services 的战略合作，在 AWS 上托管 NVIDIA ® DGX™ 云。宣布Amgen将使用 NVIDIA DGX SuperPOD ™ 来增强对药物发现、诊断和精准医疗的洞察力。推出 NVIDIA NeMo™ Retriever，这是一种生成式 AI 微服务，可让企业将自定义大型语言模型与企业数据连接起来，为 AI 应用程序提供高度准确的响应。&nbsp;推出NVIDIA MONAI™ cloud APIs&nbsp;，帮助开发人员和平台提供商将 AI 集成到他们的医疗成像产品中。&nbsp;新加坡电信公司采用 NVIDIA Hopper™ 架构 GPU 构建的节能数据中心，为新加坡带来生成式 AI 服务。与思科推出合作计划，帮助企业部署和管理安全的人工智能基础设施。支持美国国家人工智能研究资源试点计划。</p><p>&nbsp;</p><p>大型科技公司占 Nvidia 收入的近 40%，但随着越来越多的行业争相投资人工智能计算硬件，其客户已经多元化。黄仁勋表示，汽车、金融服务和医疗保健等行业目前在其芯片上的支出“高达数十亿美元”。他补充称，日本、加拿大和法国等主权国家正在成为 Nvidia 的更大客户，因为它们在利用公民数据创建自己的人工智能模型。</p><p>&nbsp;</p><p>但一些股东担心大规模增长无法永远持续。美国去年对向中国出口先进人工智能芯片实施了限制，影响了英伟达的 H800 和 A800 芯片等产品，有可能阻碍中国进入这个庞大且快速增长的市场。</p><p>&nbsp;</p><p>该公司承认，由于这些限制，中国的数据中心销售额“大幅下降”，尽管其他地区仍然对该部门的强劲增长做出了贡献。“然而，如果英伟达没有找到解决这些限制的长期解决方案，则可能影响其未来的增长，”摩根评论称。</p><p>&nbsp;</p><p>英伟达高管在财报电话会议上表示，该公司已经开始向中国运送不违反限制的替代芯片。首席财务官Colette Kress表示，第四季度中国业务在其数据中心业务中所占比例为中位数，预计本季度仍将维持在类似的区间。</p><p>&nbsp;</p><p>尽管中国市场令人不安，但华尔街的其他人士认为该公司仍有很大的运营空间。</p><p>&nbsp;</p><p>Insider Intelligence 高级分析师 Gadjo Sevilla 在本周早些时候的一份报告中表示：“英伟达的前景乐观，因为来自英特尔、AMD、Meta 和微软的人工智能芯片竞争可能还需要几个月的时间，而行业对英伟达芯片的需求只会激增。”</p><p>&nbsp;</p><p>Kress 在电话会议上表示，目前市场上对该公司先进人工智能芯片的需求继续“超过供应”。“构建和部署人工智能解决方案几乎已经触及每个行业。”</p><p>&nbsp;</p><p>确保供应满足蓬勃发展的需求可能是该公司今年面临的挑战。然而，该公司的“生产周期正在改善……总体而言，我们的供应量增长得非常好，”黄仁勋说道。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://investor.nvidia.com/news/press-release-details/2024/NVIDIA-Announces-Financial-Results-for-Fourth-Quarter-and-Fiscal-2024/\">https://investor.nvidia.com/news/press-release-details/2024/NVIDIA-Announces-Financial-Results-for-Fourth-Quarter-and-Fiscal-2024/</a>\"</p><p><a href=\"https://www.ft.com/content/44b95cc8-9c94-452c-a35b-1f25ba9b540a\">https://www.ft.com/content/44b95cc8-9c94-452c-a35b-1f25ba9b540a</a>\"</p><p><a href=\"https://edition.cnn.com/2024/02/21/tech/nvidia-ai-sales-boom/index.html\">https://edition.cnn.com/2024/02/21/tech/nvidia-ai-sales-boom/index.html</a>\"</p>",
    "publish_time": "2024-02-22 11:58:37",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "NVIDIA Maxine 结合 AI 重新发明 Real-Time Communication",
    "url": "https://www.infoq.cn/article/v6qH6c9i9wH6uZ03h0A5",
    "summary": "<ul>\n<li>Target Market</li>\n<li>Value Proposition</li>\n<li>Maxine Audio</li>\n<li>Maxine Video &amp; Maxine Augmented Reality</li>\n</ul>",
    "publish_time": "2024-02-22 14:24:34",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "效率升级：酷家乐的脚本引擎如何服务数十商家，改写行业规则？",
    "url": "https://www.infoq.cn/article/0yGD8PULJ5y7avPCXEGA",
    "summary": "<p></p><h3>背景与目标</h3><p></p><p>酷家乐云设计工具在服务客户过程中，开发了OpenApi、规则检测、工具小程序等多种个性化定制方案，以满足商家的广泛需求。OpenApi实现系统间的对接，规则检测确保设计方案的合规性，而工具小程序允许第三方在工具中运行自定义应用。尽管如此，定制化需求的实际应用中仍面临诸多挑战：客户虽然希望利用酷家乐的众多功能，但也期望这些功能的每个流程环节能够满足他们的特定需求。</p><p>&nbsp;</p><p>在这种情况下，无论是使用OpenApi进行系统对接，还是创建新的小程序，都难以将常规功能流程转变为自定义节点。而规则检测虽然对用户方案进行校验，但难以深入到每一个功能的详细流程。以往，我们通过提供大量配置项来应对这种精细化的定制需求，用户可以通过不同的配置组合以产生各种效果，但这反而引发了更多的问题。</p><p>&nbsp;</p><p>配置项的组合需要既满足商家的个性化需求，又保持通用性。这导致配置项的总体功能必须覆盖所有客户的需求，尽管大部分客户只按需使用其中的子集，但是还是有一些客户可能做出出乎意料的组合。随着组合数量的增加，穷举所有可能性变得越发困难，即使是开发人员也越来越难以理解整个功能的逻辑。尽管已经引入了大量的配置项，但它们依旧难以迅速适应客户的突发需求。每当客户提出新的需求时，我们仍需进行深入研究以探索如何满足这些新的要求。配置项的错误设置可能会对客户的业务造成负面影响。因此，如何确保每次用户修改配置时都能保持高质量，成为了我们面临的一个新挑战。</p><p>&nbsp;</p><p>为了解决这种问题，我们寻求一个能够通用地描述用户逻辑的脚本引擎，并对我们的需求进行了详细分析。</p><p>&nbsp;</p><p>由于设计工具中有小程序的存在能够提供前端的定制功能，我们更需要考虑如何扩展后端逻辑中的流程，需要运行在JVM中。它需要是零散的，可以在功能流程的各个环节中方便的暴露出自定义的接入点。同时不同的环节会有不同的上下文，要求的输入和输出也不一样。业务本身已经有预置逻辑，想要以预置的逻辑为模板，客户在此基础上扩展出自己的定制逻辑。可扩展的除了函数还有数据结构。客户需要自己定义数据结构，这不止体现在中间数据，还体现在最终在工具中的样式，和对接生产的数据上。客户的定制逻辑可能过于复杂，比如全屋定制场景中对脚线顶线等工艺规则的需求，需要自定义的函数可复用。客户的规则经常需要非常个性化的想要持久化的数据表格：让客户管理员能够自己定义新的数据表格，以及增删改数据；并且可以在脚本中查询配置的数据。在设计工具中，有时候即使小程序也太重了，客户希望用已有的功能，同时希望能直接定制相应功能的参数面板。</p><p>&nbsp;</p><p>此外，酷家乐是一家Saas公司，服务很多商家。因此还对这个脚本引擎还有技术上的需求，需要它能够服务多租户的场景。</p><p>&nbsp;</p><p>1.&nbsp;安全性：避免一些恶意脚本的攻击。</p><p>2.&nbsp;租户间的逻辑隔离：客户的所有配置需要按商家维度隔离开。而物理隔离的硬件成本和维护成本太高，只能逻辑隔离，既包括客户自定义的数据结构、数据配置、函数逻辑等功能方面，也包括cpu、内存等硬件资源放方面，避免互相影响。另一方面又不排除租户间可能出现脚本共享的问题</p><p>3.&nbsp;测试和生产的隔离：规模比较大的商家通常有自己的IT系统，他们内部需要测试发布流程，但是都对接酷家乐的线上系统。因此需要我们的脚本引擎也能够实现用户配置脚本的测试生产隔离，用户自定义的数据结构、脚本等都需要区分“测试”和“正式”环境。客户的脚本配置都需要先在测试账号上测试通过后，才发布给本商家的所有用户。</p><p>4.&nbsp;由于后端都是无状态服务，因此我们希望这个脚本引擎是轻量的，能够方便的加载、缓存、执行和销毁。</p><p></p><h3>整体方案</h3><p></p><p></p><p>我们考虑了多种在JVM上运行的脚本引擎，包括Groovy、Scala、JavaScript、Jython和Drools。虽然这些语言能够提供一定程度的隔离性，但它们不太适合实现与商家的持续共享。特别是在数据结构经过商家扩展后，将我们的更新同步到商家的定制数据结构中会相当困难。我们需要一种方式能够在符号引用的粒度管理依赖关系。Clojure可以以较低的成本实现这一点，但其学习曲线对新手来说相对陡峭。同时，我们也尝试了低代码引擎，使用JSON表示的抽象语法树（AST）来表达逻辑，但这在人工阅读和维护方面过于复杂，且不支持自定义数据结构。</p><p>&nbsp;</p><p>最后我们选择了自研一个脚本引擎，实现符号引用粒度的依赖管理，目前看运行良好，除了满足上述需求外，有一些额外发现：</p><p>&nbsp;</p><p>参考了TypeScript语法，但是去掉了很多复杂的语法。我们并不追求引擎有完备的表达能力，只要能够支撑用户“组装”我们提供的基础能力就行。很多不必要的语法都干掉了，拒绝多态，甚至for循环和while循环都干掉了，使用lambda代替。脚本引擎可以做到完全的静态强类型。可以实现限制API访问、CPU资源限制。复杂的代码可以转换成基于依赖树的数据，可以用于逻辑的分析管理。可以做面向用户的脚本代码调试器，方便处理工单。与直接使用改造现成的开源脚本引擎相比，开发一个约束了语法范围的脚本引擎的成本并不高，而且有完全的掌控能力，不需要受完全用不到的特性的影响。除了支持一期特定的TypeScript子集，还可以支持兼容Drools的语法，提供直接运行Drools脚本的可行性。相比直接维护AST树的好处：脚本形式易于理解和版本化。加上细粒度的依赖管理，增强了AI生成的可行性。</p><p></p><h4>架构</h4><p></p><p></p><p>经过持续的演化，目前脚本引擎逻辑上大概拆分成以下模块：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1f/1fd0ca4ddf97b61f12056ede4f82e497.png\" /></p><p></p><p>&nbsp;</p><p>为了实现酷家乐与商家间的共享、以及商家之间的隔离，我们把所有的引用都划分成了多个空间。每个空间有一部分数据结构或者函数定义。不同的用户会看到不同的空间组合，组合内不同空间的所有定义合并后就是用户看到的完整的数据结构或者函数定义。组合内空间之间有优先级，优先级高的会覆盖掉优先级低的。我们希望用户能够扩展的主要是数据结构和函数，因此定义了自定义对象和函数这两种定义。此外还有支撑用户编排逻辑的基本数据类型，它是不允许用户修改的。加上管理定义的元数据管理器，一起构成了元数据系统。为了减少脚本编写的错误率，我们希望不管脚本是用什么语法写的，都需要是完全静态强类型的，因此定义了一套类型系统，能够支持类型校验和类型推演。执行引擎是指脚本的编译、连接和执行整个过程。另外在元数据定义的基础上，定义了基本的数据结构和函数。这样就可以编写并执行基本的脚本。提供预置API的机制。客户自定义逻辑不可能从头开始写，需要对应的功能模块提供一些基础数据和功能函数，客户做的更多是对基础能力的组装。此外也限制客户只能访问预置的API和基本的数据结构。提供客户自定义对象和函数的界面，并且用户的定义有测试和发布两种状态。客户的普通账号只会执行发布状态的定义，而测试账号则会执行测试状态的定义。数据实例存储模块支持客户能够增删改查自定义对象的数据实例。</p><p></p><h4>空间划分</h4><p></p><p></p><p>在描述商家间的逻辑隔离与共享时，我们将其建模为空间划分。简而言之，每个商家和环境都对应着一个独立的空间，同时酷家乐的预置功能也占据一个单独空间。这些空间彼此隔离，确保数据与功能的独立性。然而，用户可以跨空间访问，通过所拥有权限的多个空间进行数据和功能访问。这些访问的空间集合，连同其内部的优先级设置，构成了用户的搜索空间。当用户编译或链接脚本时，系统将在用户的搜索空间内寻找所需的符号引用，优先考虑先找到的符号。用户可以在其有权限的空间内定义新的数据结构或函数，但需保证这些定义不会破坏脚本从搜索空间角度观察的编译正确性。</p><p>&nbsp;</p><p>目前，我们主要处理三种空间：酷家乐的预置空间、商家的正式空间以及测试空间。预置空间包含酷家乐的核心功能，而商家的数据结构和函数最初在测试空间中创建或扩展，一旦经过测试并发布，就会被迁移到正式空间。商家可以通过三种角色来交互这些空间：测试账号、正式账号和脚本管理员。测试账号专门用于测试新脚本，其搜索空间包括测试空间、正式空间和预置空间；正式账号用于日常业务，其搜索空间包括正式空间和预置空间；脚本管理员则依据其管理内容的不同，搜索空间会在测试账号和正式账号之间变化。</p><p>&nbsp;</p><p>比如下图中，酷家乐预置了数据结构A和B、函数C和D，商家曾经对A和D进行过扩展并且发布到正式空间了。这样商家的正式账号访问到的就是正式空间中的A和D，以及预置空间中的B和C。如果B和C引用了A或者D，正式账号在执行B、C脚本时调用的A和D是正式空间中的。现在商家新对D进行了修改，但是还未发布，此时正式账号还是使用的正式空间的D；但是测试账号使用的D就是测试空间的。当测试账号测试没问题了，把D发布后，正式账号才会访问到。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/75/75b7105898f52e556dfaa3bd5f7d1b59.png\" /></p><p></p><p>如果商家没有开启定制脚本功能，这些商家的搜索空间就只是酷家乐预置空间。当一个商家开启后就会多出测试空间和正式空间两个空间。</p><p></p><h4>元数据</h4><p></p><p></p><p>我们希望用户能够自定义数据结构，从而更精确地反映他们的领域需求。为此，我们在元数据模块中引入了“自定义对象”，它类似于简单的Java对象（POJO），主要由各种属性组成，并允许用户直接添加新属性或通过继承进行扩展。自定义对象可以通过多种方式实现，包括从Json构建、编写代码或使用Java类注解。特别是通过Java注解方式，自定义对象能够与Java代码直接交互，这样不仅方便了用户构建自定义对象，同时也允许用户在酷家乐预置的基础上进行扩展。</p><p>&nbsp;</p><p>同样，我们希望用户能够根据需求自定义函数的逻辑和复用性，以实现和优化他们的业务流程。因此，我们在元数据中定义了“函数”，作为一段具有输入参数和返回值的可执行逻辑。这些函数可以对应Java中的静态方法或单例Bean的方法，也可以是用户可编辑的脚本。如果是脚本，用户可以直接查看和修改内容，只需确保修改后的脚本可以成功编译。</p><p>&nbsp;</p><p>在用户组装业务数据对象和业务逻辑流程时，我们会为用户提供一些基础数据结构，比如我们在实现功能业务时积累的几何数据或者支撑业务领域的数据结构。这些基础数据结构也体现在元数据定义类型中。基础数据结构有属性和方法，可以在Java代码中通过注解的方式进行声明。</p><p>&nbsp;</p><p>此外我们还定义了“插件”，他可以对对象、函数的定义进行修改。在构建完对象和函数的定义后，会解析定义上是否启用了插件。如果启用了插件就会调用插件对定义进行处理。这个处理过程可能会影响对象或者函数的定义，也可能只是触发了一些事件。比如为了让用户能够自定义可持久化的数据表，我们构建了“配置数据”插件，可以对自定义对象进行处理。</p><p></p><h4>编译执行引擎</h4><p></p><p></p><p>用户脚本的执行流程基本上分为两个阶段：首先是将脚本编译链接成可执行对象，其次是执行这个对象。在这个过程中，降低用户编写脚本时的错误率是我们需要重点考虑的业务需求。为此，我们倾向于使用静态强类型语法，实现及时的类型检查，同时为了减轻用户的编码负担，我们的系统支持类型自动推断功能，避免用户频繁地声明类型。</p><p>&nbsp;</p><p>在编译和链接阶段，我们构建了一个强大的类型系统，能够进行静态类型检查和类型推断。这个系统将类型统一描述为Type，包括用于描述元数据的“定义”类型（类似Java的Class），基础简单类型，范型类型，类型参数，函数类型，Void类型，以及“任意”类型等。</p><p>&nbsp;</p><p>为了未来能够低成本地支持多种语言，包括难以维护的“机器语言”，我们的目标是构建一个能够统一进行语义和逻辑分析、性能优化、依赖管理、版本管理和调试的引擎，而忽略掉具体语法的影响。整体编译链接的过程如下图所示，包括根据特定语法对脚本文本解析成标准AST的Compiler，以及将标准AST连接成可执行结构的Linker。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ec/eceb3b093d0731a6ec8bebd3bdeaf5ff.png\" /></p><p></p><p>这里除了编译都是与具体语法无关的。目前编译只支持类似TypeScript的语法，大体与Ts相似，但是有些区别：</p><p>砍掉了很多不需要的语法，甚至for/while/try-cactch也砍掉了。通过对已有业务的drools脚本的观察，其实for/while都是可以用lambda代替的，for/while循环能够提供的自由度是不需要的并且给代码增加太多细节。try-catch也会大幅增加代码复杂度，我们参考了函数式编程中的Maybe语义，用Maybe代替try&nbsp;catch。彻底的静态强类型。去掉了Statement，全部都是Expression，即每个完整的代码元素都有类型和值。编译后通过链接，形成可执行的数据结构，都继承自Value，这里只举出其中一些Value子类：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2f/2f5424b938c416cc6e0cc79057362130.png\" /></p><p></p><p>&nbsp;</p><p>为了确保单个商家的脚本运行不会过度消耗CPU资源，进而影响其他商家脚本的性能，我们实施了一项资源保护机制。具体来说，在需要执行函数时，流程执行器会将待执行的函数流程登记至保护器，并将其提交至专用的线程池执行。保护器负责监控每个脚本的执行时间，以顶层脚本为监控单位。如果脚本的执行时间超过预设的阈值，保护器将主动中断脚本执行。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/21/2196527b95a5e87378721890cb7937d6.png\" /></p><p></p><p>&nbsp;</p><p>用户脚本依赖于酷家乐提供的基础设施和能力来实现其功能。我们通过注解来配置哪些基础数据结构和API可以被用户访问。具体来说，包扫描器会识别并处理这些带有特定注解的类和方法，将它们转换成脚本引擎可以识别和处理的结构。目前，我们的脚本引擎与Java数据结构相兼容，实现了双向调用。</p><p>&nbsp;</p><p>同时，酷家乐业务允许声明接口，并让用户实现这些接口以定制特定的业务逻辑。用户可以在配置页面中查看这些接口，并利用脚本来实现它们。当流程执行器在业务逻辑中运行这些接口时，它会使用用户脚本提供的结果，并将这些结果应用到实际的业务场景中。</p><p>&nbsp;</p><p>执行引擎的整体架构如下图：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/42/423139527be8003c959591466612afb9.png\" /></p><p></p><p></p><h3>未来展望</h3><p></p><p></p><p>目前脚本引擎已经应用在酷家乐的多个业务中，已经解决了多个领域的50+个性化需求。目前服务于数十个商家，他们配置了数百个脚本或者对象。此外有更多的业务计划接入脚本引擎。已经使用和计划接入的业务通常有个共同特征：</p><p>&nbsp;</p><p>有比较多的用户自定义的功能细节。现有配置已经比较复杂，基本是支持到多种配置项再配合SPEL表达式的方式进行配置，甚至要多个SPEL配置项协作来完成功能。配置功能本身已经比较难以理清。然而用户还是有更复杂的自定义需求，已经超出SPEL的表达能力。</p><p>&nbsp;</p><p>脚本引擎目前基本上能够满足特定场景的需求，但它还存在一些不足之处。在设计初期，我们希望脚本引擎能够支持多种编程语言，但现在看来，初版设计与特定语法过于耦合，实现这一目标将需要一定的重构工作。此外，脚本引擎的线上运营能力还有较大的提升空间，尤其是在线调试功能目前还非常有限。</p><p>&nbsp;</p><p>我们还希望脚本语法能尽可能简洁，便于梳理和表达业务逻辑，但实际上这很难实现。即使对于经验丰富的开发者，也容易回归到过程化的思维方式，这使得自动化语法流程分析变得复杂。从业务角度来看，目前还无法实现“Write&nbsp;once，Run&nbsp;everywhere”</p><p>&nbsp;</p><p>未来，我们计划根据业务方的需求，从补全脚本引擎的功能能力、建立代码数据化的元数据平台、以及为主要业务场景构建高级参数化模型工具包等三个方向对脚本引擎进行优化和扩展。</p><p></p><p>嘉宾介绍：</p><p></p><p>郑虎，一位经验丰富的后端开发专家，拥有10年的工作经验。他擅长多种编程语言，包括Java、Scala和Clojure等。他对处理高并发问题有着深入的了解，并能够通过技术手段有效地解决这些挑战。此外，嘉宾也擅长系统性分析，以点带面系统性的规划和解决软件系统中的问题。</p>",
    "publish_time": "2024-02-22 15:06:17",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "硅谷 AI 企业卷出新高度，谷歌推出开放大语言模型 Gemma，声称超越 Meta Llama-2 ，谁将成为最强王者？ | 讨论",
    "url": "https://www.infoq.cn/article/2hgvNSuRdHqGjkWLy1zJ",
    "summary": "<p>当地时间 2 月 21 日，谷歌开放了2个新的不同参数规模的模型，分别是Gemma 7B和Gemma 2B，其技术与Gemini模型一致。但是这两个模型完全公开，可以商用授权。具体报道请看这篇文章：<a href=\"https://www.infoq.cn/news/MNJ8kPf81k5ZG6ssPjqp\">谷歌深夜炸场！发布最强开放模型 Gemma：性能碾压 LLaMA，可在笔记本上运行</a>\"。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/9a/54/9a1da21c8cc1b7b10667974813bfdc54.jpeg\" /></p><p></p><p></p><p>从开放的内容看，本次Google的诚意满满，不仅模型能力很强，在生态和社区支持方面也非常好。关于模型具体的代码示例、预训练开源地址可以参考如下信息：</p><p></p><p>Gemma 模型HuggingFace链接：</p><p></p><p>7B：<a href=\"https://huggingface.co/google/gemma-7b\">https://huggingface.co/google/gemma-7b</a>\"2B：<a href=\"https://huggingface.co/google/gemma-2b\">https://huggingface.co/google/gemma-2b</a>\"体验链接：<a href=\"https://huggingface.co/chat\">https://huggingface.co/chat</a>\"</p><p></p><p>在线演示地址：<a href=\"https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/gemma/docs/lora_tuning.ipynb\">https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/gemma/docs/lora_tuning.ipynb</a>\"</p><p></p><p>官方博文：<a href=\"https://blog.google/technology/developers/gemma-open-models/\">https://blog.google/technology/developers/gemma-open-models/</a>\"</p><p></p><p>谷歌的深夜王炸在 AI 领域引起了轩然波澜，也引发了人们对于大语言模型发展趋势的思考。Gemma 的发布意味着什么？目前有以下几个观点可以讨论，欢迎投票：</p><p></p><p>最后放个这两天最火的网络梗图。</p><p><img src=\"https://static001.geekbang.org/infoq/13/139bf672610daa86cd691dd9b8c79967.png\" /></p><p></p><p></p><p></p><p></p><p>AI革新时代，InfoQ AIGC学习资料包限时免费领取！我们精心准备了一系列独家学习资料，涵盖从基础到高级的AI知识，助您在人工智能领域一飞冲天！</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/5e/61/5e188189cbcefa3f62a0f34e8727yy61.png\" /></p><p></p><p></p><p>📚 资料包内容概览：</p><p>《中国人工智能成熟度模型报告》：本报告基于三大关键指标，参考市场规模、融资事件等公开资料，并结合了AI行业内硬件、模型、应用不同领域的各位专家观点，构建涵盖40+技术点的中国人工智能成熟度模型，为技术的应用决策和未来投资参考提供研究分析工具。《InfoQ大模型测评报告2024》：InfoQ 研究中心本研究围绕语义理解、文学创作、知识问答、逻辑推理、编程、上下文理解、语境感知、多语言处理及多模态交互等十大核心领域，对包括 ChatGPT-4、文心一言专业版、通义千问 V2.1.1、Bard2.0、讯飞星火 V3.0、Kimi Chat 网页版、百川大模型 V1.0、智谱清言网页版、360 智脑 4.0 和豆包在内的十款热门模型进行了全面评估，测试题目数量超过 3000 道。《AIGC热潮下的技术百态》：聚焦 AIGC 引发的变革，与50多位头部专家深度对话，细数过去一年不同领域的创新和进展，希望能为你揭示未来技术发展方向，明晰不同行业大模型应用思路和路径。《软件产品中的AIGC》：我们深度采访了LeptonAI、智谱AI、Dify.AI 和京东云言犀团队，讲述他们的大模型故事。另外，我们还与来自网易、百度、广推科技等企业专家，就AIGC 编程、算法及应用等话题做了深入探讨。</p><p></p><p>🎯 适合人群：</p><p>AI行业从业者：获取行业深度分析，把握市场脉搏。技术研究者：了解AI技术的最新进展和应用案例。产品经理和开发者：探索AIGC在产品开发中的创新应用。</p>",
    "publish_time": "2024-02-22 16:06:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]