[
  {
    "title": "Hugging Face 大语言模型优化技术",
    "url": "https://www.infoq.cn/article/dAjSEe0AZw1GHuXZDROZ",
    "summary": "<p>大语言模型的生产部署存在两个主要的挑战，一个是需要大量的参数，一个是需要处理非常长的用于表示上下文信息的输入序列。Hugging Face基于他们提供大模型服务的经验<a href=\"https://huggingface.co/blog/optimize-llm?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY2NDU0NTYsImZpbGVHVUlEIjoiVk1BUExhOXp4UlRRWDRBZyIsImlhdCI6MTY5NjY0NTE1NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.nS1BUkwmY8dZaPmT8rfOJsLYT8fQGvZdsjLh1n39W-s\">分享了一些克服这些障碍的技术</a>\"。</p><p></p><p>Patrick von Platen在文中介绍的Hugging Face研究的三种技术是降低数值精度、使用一种叫作Flash Attention的注意力算法，以及使用专门的推理架构。</p><p></p><p>大语言模型需要大量的VRAM来加载，从几十(bigcode/starcoder)到数百GB (Llama、Bloom、GPT3)。第一个优化手段是从float32切换到bfloat16精度：</p><p></p><p></p><blockquote>现在几乎所有的模型都是基于bfloat16训练的，如果你的GPU支持bfloat16，就没有理由基于全float32精度运行模型。float32不会给出比训练模型所使用的精度更好的推理结果。</blockquote><p></p><p></p><p>这可以使总体内存消耗减少一半，但可惜的是，在许多情况下仍然需要很大的内存。一种更激进的方法是将模型权重量化为8位或4位，这<a href=\"https://arxiv.org/abs/2208.07339?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY2NDU0NTYsImZpbGVHVUlEIjoiVk1BUExhOXp4UlRRWDRBZyIsImlhdCI6MTY5NjY0NTE1NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.nS1BUkwmY8dZaPmT8rfOJsLYT8fQGvZdsjLh1n39W-s\">已经被证明不会导致显著的性能下降</a>\"。</p><p></p><p></p><blockquote>量化对于文本生成来说特别有效，因为我们所关心的是选择最有可能的下一个标记集合，而不是下一个标记Logit分布的确切值。</blockquote><p></p><p></p><p>这将进一步减少所需的内存，使得在只有16GB VRAM的GPU上运行较小的模型成为可能，尽管代价是推理时间稍长。</p><p></p><p>von Platen写道，使用<a href=\"https://arxiv.org/abs/2205.14135?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY2NDU0NTYsImZpbGVHVUlEIjoiVk1BUExhOXp4UlRRWDRBZyIsImlhdCI6MTY5NjY0NTE1NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.nS1BUkwmY8dZaPmT8rfOJsLYT8fQGvZdsjLh1n39W-s\">Flash Attention</a>\"是另一相关键的优化，它是大语言模型用来理解输入标记上下文关系的自注意力层的一种算法，有可能打破输入标记数量的二次增长。</p><p></p><p>因为该算法太过复杂，无法在这里描述，但可以这么说，它利用了softmax规范化统计数据和一些数学手段，在只需要随输入标记线性增长的内存的情况下提供相同的输出。推理性能也得益于算法使用了更快的SRAM而不是更慢的GPU VRAM。</p><p></p><p></p><blockquote>在实践中，目前绝对没有理由不使用Flash Attention。该算法在数学层面给出了相同的输出，并且速度更快，内存效率更高。</blockquote><p></p><p></p><p>Here recent research can help to make the right choice with two components that quickly become bottlenecks, says von Platen, _positional embeddings_ and the _key-value cache_.</p><p></p><p>在生产环境中部署大语言模型的第三项优化措施是选择正确的架构，让它们能够有效地处理长文本输入。von Platen写道，最近的研究有助于我们如何对两个很快成为瓶颈的组件做出选择——一个是_位置嵌入(positional embeddings)_，一个是_键值缓存_。</p><p></p><p>位置嵌入通过将每个标记的位置编码为数字表示来帮助语言大模型理解序列顺序。对于需要处理大型文本输入任务的大语言模型，应该使用<a href=\"https://arxiv.org/abs/2104.09864?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY2NDU0NTYsImZpbGVHVUlEIjoiVk1BUExhOXp4UlRRWDRBZyIsImlhdCI6MTY5NjY0NTE1NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.nS1BUkwmY8dZaPmT8rfOJsLYT8fQGvZdsjLh1n39W-s\">RoPE</a>\"和<a href=\"https://arxiv.org/abs/2108.12409?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY2NDU0NTYsImZpbGVHVUlEIjoiVk1BUExhOXp4UlRRWDRBZyIsImlhdCI6MTY5NjY0NTE1NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.nS1BUkwmY8dZaPmT8rfOJsLYT8fQGvZdsjLh1n39W-s\">ALiBi</a>\"等相对位置嵌入技术进行训练。</p><p></p><p></p><blockquote>RoPE和ALiBi位置编码都可以外推到训练期间未遇到过的输入长度，而事实证明，与RoPE相比，外推对于开箱即用的ALiBi的效果要好得多。</blockquote><p></p><p></p><p>目前的许多大语言模型中已经在使用这两种算法。</p><p></p><p>键值缓存可以作为对对话上下文进行编码的一种方法。键值缓存在发生每个新交互时增加一个元素，这比为每个请求编码/解码上下文的方法要有效得多。von Platen详细介绍了两类键值缓存，即<a href=\"https://arxiv.org/abs/1911.02150?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY2NDU0NTYsImZpbGVHVUlEIjoiVk1BUExhOXp4UlRRWDRBZyIsImlhdCI6MTY5NjY0NTE1NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.nS1BUkwmY8dZaPmT8rfOJsLYT8fQGvZdsjLh1n39W-s\">Multi-Query-Attention (MQA)</a>\"和<a href=\"https://arxiv.org/abs/2305.13245?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY2NDU0NTYsImZpbGVHVUlEIjoiVk1BUExhOXp4UlRRWDRBZyIsImlhdCI6MTY5NjY0NTE1NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.nS1BUkwmY8dZaPmT8rfOJsLYT8fQGvZdsjLh1n39W-s\">Grouped-Query-Attention(GQA)</a>\" 。</p><p></p><p>von Platen的文章所涵盖的内容不只有本文所概述的这些，他的文章中还提供了实际的例子来证明他的观点，所以请不要错过他的文章。</p><p></p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/09/hugging-face-optimizing-llms/\">https://www.infoq.com/news/2023/09/hugging-face-optimizing-llms/</a>\"</p>",
    "publish_time": "2023-10-07 10:22:15",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "一小时12元，我在北欧监狱里训练AI",
    "url": "https://www.infoq.cn/article/4v7RrYDw8M0ECaa6TBc2",
    "summary": "<p>芬兰工资水平普遍较高，并且很少有人从事互联网行业。外媒&nbsp;wired 实地走访发现，一家名为 Metroc 的大模型创业公司发现了一种新型劳动力——囚犯。</p><p></p><h2>芬兰囚犯的新工作：帮创业公司训练大模型</h2><p></p><p>&nbsp;</p><p>在一个没有窗户的房间里，隔着一张消过毒的白色桌子，我被介绍给了一位四十多岁的女性，她有着方形下巴，用一个淡蓝色的发带把金色的头发扎成了马尾。她说：“大家都叫我果酱”，让我也这么称呼她。</p><p>&nbsp;</p><p>一个星期三的早晨，在这座芬兰的监狱里，果酱给我们演示了一种新型的监狱劳动形式。</p><p>&nbsp;</p><p>桌子上只有一小塑料瓶水和一台 HP 笔记本电脑。她们每三小时轮班一次，每小时可以获得 1.54 欧元（约合 12 元人民币）的报酬。这台笔记本电脑用来向果酱展示关于房地产的短文，并就她刚刚读到的内容问她是或否的问题。其中一个问题是：“上面这段话说的是房地产决策而不是申请，对吗？”</p><p>&nbsp;</p><p>“有点无聊，”果酱耸了耸肩，她也不太清楚这项任务的目的。她认为，\"也许她正在帮助创建一个客服聊天机器人\"。</p><p>&nbsp;</p><p>事实上，她正在训练一款由芬兰创业公司 Metroc 开发的大型语言模型。该公司创建了一个搜索引擎，旨在帮助建筑公司找到新批准的建设项目。为了做到这一点，Metroc 需要标注员帮助其模型理解新闻和市政文件中关于即将开展的建设项目的线索。例如，人工智能必须能够区分已经委托给建筑师或正在安装窗户的医院项目和可能仍在招人的项目。</p><p>&nbsp;</p><p>在全球范围内，有数百万所谓的“网络工作者”在训练人工智能模型，教机器区分行人和棕榈树，或者描述暴力或性侵害的词语组合。通常，这类工作人员来自南半球，因为那里的工资比较低。例如，OpenAI 就用了一家外包公司，该公司在肯尼亚、乌干达和印度招聘了网络工作者。这种安排非常适合美国公司，因为它们使用全球使用最广泛的语言英语，但在南半球很难找到讲芬兰语的人。</p><p>&nbsp;</p><p>这就是为什么 Metroc 转向了监狱劳动力。该公司获得了廉价的、会讲芬兰语的工人，而监狱系统则可以为囚犯提供就业机会，也为他们出狱后进入数字化领域工作做好准备。利用囚犯来训练人工智似乎有点像科技领域下游经常存在的对廉价劳动力的剥削。但在芬兰，这个项目得到了广泛的支持。</p><p>&nbsp;</p><p>“数据劳动力是一个全球性的概念。但如果你仔细观察一下就会发现，芬兰的情况截然不同。”来自赫尔辛基大学的研究员图卡·莱赫蒂尼米（Tuukka Lehtiniemi）说，他一直在研究芬兰监狱中的数据劳动力。</p><p>&nbsp;</p><p>果酱在哈米纳林纳监狱已经呆了四个月。这座现代化的建筑有着很大的窗户。空旷的走廊上，色彩丰富的艺术品正努力营造出愉快的氛围。要不是因为厚重的灰色安全门挡住了每个进出口，你很容易就会以为，这些房间属于一所毫无灵魂的大学。</p><p>&nbsp;</p><p>芬兰监狱的开放性是出了名的，囚犯可以在附近的城镇工作或学习，但哈米纳林纳监狱不属于这一类。相反，哈米纳林纳监狱是芬兰安全级别最高的监狱，只收容女性囚犯。果酱被判了六年。根据监狱的隐私规定，wired&nbsp;不能发布她的真实姓名、确切年龄或其他任何可能让人识别出她身份的信息。在这个无期徒刑囚犯服刑 12 年后就可以申请刑满释放的国家里，六年是重刑。和其他 100 名住在这里的囚犯一样，她也不被允许离开监狱。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/04/04e874cfd11a928cf1522b07438b7a59.png\" /></p><p>&nbsp;</p><p>当果酱第一次来到监狱的时候，她会看着其他女囚每天早上起床去工作：她们可以自愿做清洁、洗衣或缝纫。每六小时轮班一次，她们可以获得大约 6 欧元（约合 46.6 元人民币）的报酬。但果酱无法忍受这些工作。“我会觉得非常累，”她说。为此，有很长一段时间，她就呆在牢房里，直到有一位监狱辅导员建议她尝试“人工智能工作”。三小时一轮班吸引了她，至于报酬，有总比没有强。“虽然不多，但比呆在牢房里强，”她说。截至目前，她只轮过三次班，但已经获得了成就感。</p><p>&nbsp;</p><p>这所监狱允许囚犯通过数据工作赚钱。在芬兰，这样的监狱只有三所。每所监狱都备有三台笔记本电脑，供囚犯参与这项人工智能工作时使用。这项工作没有具体的目标，囚犯按小时取酬，而不是按工作速度或质量。</p><p>&nbsp;</p><p>在哈米纳林纳监狱，大约有 20 名囚犯尝试过这项工作。监狱工作导师米娜·英基宁（Minna Inkinen）留着红色的短发，她坐在果酱旁边和我们交谈。她说：“有些人确实比其他人更喜欢人工智能工作。”当我在一个星期三的早晨到到达这所监狱时，缝纫室已经忙碌了起来。囚犯们或忙着操作缝纫机，或在织物旁商量事情。但在果酱到达之前，开展人工智能工作的小房间里空无一人。英基宁解释说：”总共只有三名囚犯自愿定期参加人工智能工作，而另外两人目前正在上法庭。“果酱补充说：“我更喜欢在一个团队中做事。”她房间的门一直敞开着，这样她就可以在回答问题的间隙，与隔壁正在缝纫的狱友聊天。</p><p>&nbsp;</p><p>那些问题是我在监狱以南 100 公里外的赫尔辛基的一家现代化共享办公室内手写的。在那里，我见到了个子高挑、少年感十足的 Metroc 创始人兼首席执行官尤西·维尔纳拉（Jussi Virnala）。他带着我路过一排室内秋千、一张台球桌和一群西装革履的男士，来到一个异常闷热的电话间。他解释说，这一周真让人兴奋，公司刚刚完成了一轮 200 万欧元（约合 1554 万元人民币）的融资，他计划用这笔钱来扩展北欧市场，投资者对公司与芬兰监狱的关系很感兴趣。他说：“每个人都激动不已，对这种创新方式很感兴趣，我认为从产品方面来看，这非常有价值。”</p><p></p><h2>数据标注是个好工作吗？</h2><p></p><p>&nbsp;</p><p>将囚犯发展为劳动力的想法是维尔纳拉提出的。他们公司需要母语为芬兰语的人来帮助他们改进其大型语言模型理解建筑行业特有的语言。但在像芬兰这样的高薪经济体中，很难找到这样的数据劳动力。芬兰的福利体系可以提供可观的失业救济金，这就意味着很少有芬兰人会主动在类似亚马逊网络交易平台这样的网络工作平台上注册。“上面没有多少芬兰语工作人员，”维尔纳拉说，同时他还补充道，“自动翻译工具仍然不能很好地处理芬兰语，毕竟以芬兰语为母语的人总共也才 500 万。”</p><p>&nbsp;</p><p>当维尔纳拉向芬兰监狱和青少年教养所的智能监狱项目负责人皮娅·普拉卡（Pia Puolakka）提出他的想法时，她立刻表现出了浓厚的兴趣。她说，在人工智能火起来之前，另一家名为 Vainu 的芬兰科技公司曾经也试过用囚犯做数据劳动力，但其联合创始人之间的分歧导致项目负责人图奥马斯·拉西拉（Tuomas Rasila）离开了公司，Vainu 也就退出了这个项目。</p><p>&nbsp;</p><p>到 2022 年维尔纳拉提出他的提议时，普拉卡非常想恢复人工智能工作。她的工作是设法加强芬兰监狱与互联网之间的联系，使监狱更接近日益数字化的外部世界。到目前为止，监狱的独立牢房一直都配有笔记本电脑，以便囚犯可以浏览有限的网站并申请视频通话许可。她认为，数据劳动力也是这项任务的一部分。</p><p>&nbsp;</p><p>这项工作的目的不是为了取代传统的监狱劳动力，比如制作道路标志或园艺工作，它的目标是为囚犯提供更多的工作类型。数据标注员三小时就轮一次班。“如果一天八小时都只做这种工作，可能会让人觉得很累，”她补充说，如果囚犯可以将数据标注与其他类型的监狱工作并行开展，那就更好了。她说，“这项工作是面向未来的，如果要为囚犯出狱后的生活做准备，那么这些技能至少与监狱提供的传统工作类型一样重要”。</p><p>&nbsp;</p><p>然而，数据标注可以为囚犯提供多少可用于出狱后的工作技能还不清楚。作为 Vainu 公司联合创始人之一的图奥马斯·拉西拉（Tuomas Rasila）曾在那里管理了一年的监狱项目，他承认自己没有这方面的证据。他说，这个项目的运行时间还不足以收集证据，“我认为，让可能与社会脱节的人去学习现代社会最先进的技术是一个不错的赋能理念。”</p><p>&nbsp;</p><p>其他人认为，这种新形式的监狱劳动力可能会加剧人工智能革命所带来的廉价劳动力问题。“我们正朝着一个更便捷高效的全自动化社会发展，但这往往掩盖了这样一个事实，即许多系统实际上都是依赖于人的”，来自人权观察的人工智能高级研究员阿莫斯·陶（Amos Toh）如是说。</p><p>&nbsp;</p><p>在陶看来，对于网络工作者需求的增加已经引发了一种趋势，即公司更多地转向了那些几乎没有其他选择的人群：难民、国家陷入经济危机的人，现在是囚犯。</p><p>&nbsp;</p><p>“这种情况很常见，”陶说，“我们这里看到的只是一个更广泛的现象的一部分，即企业正在将技术开发背后的工作外包给可能在剥削性工作条件下劳动的工人。”</p><p>&nbsp;</p><p>对于数据工作是否能帮助囚犯培养数字技能，陶还也是持怀疑态度。“在监狱里，囚犯有很多提升自己的方式，比如考取证书和参加高等教育，”他说，“但我觉得，以每小时一欧元的价格为一家公司标注数据未必能帮他们取得有意义的进步。”哈米纳林纳监狱确实为囚犯提供了人工智能在线课程，但当工作人员试图解释其好处的时候，果酱坐在那里，面无表情。</p><p>&nbsp;</p><p>在我与来自赫尔辛基大学的研究员莱赫蒂尼米见面后，我对于监狱项目的优点有些不那么确定了。从监狱来到 Metroc 的办公室，监狱里的女性干着每小时 1.54 欧元的工作，而公司正在庆祝 200 万欧元的融资轮，这感觉非常不协调。在赫尔辛基大教堂对面的一家咖啡馆里，莱赫蒂尼米耐心地听我描述了这种感觉。</p><p>&nbsp;</p><p>但对囚犯的采访让莱赫蒂尼米有了不同的看法——他对这个项目总的来说是持积极态度的。至于薪酬差距，他认为，这些人是在监狱里，并不是主流社会中的普通劳动力。“将我作为研究员所获得的报酬与囚犯在监狱里劳动所获得的报酬进行比较，是没有意义的，”他说，“我唯一听到的负面意见是这样的工作不够多，只有很少的人可以做。”他提到了每所监狱只有三台笔记本电脑这个限制。</p><p>&nbsp;</p><p>“当我们提起数据劳动力时，我们往往会想到网络交易平台，全球南部或美国农村的人，”他说。但对他来说，这是数据劳工的一个独特的本地版本，它带来了有益于社会的转变。与其他监狱劳动力相比，它为囚犯提供了认知刺激的工作，同时也代表了芬兰语言在人工智能革命中的地位。</p><p>&nbsp;</p><p>莱赫蒂尼米担心，如果没有这种主动性，英语之外的语言将被下一代技术所淘汰，智能音箱仍然难以理解芬兰语。“并非所有芬兰人都能说一口流利的英语，所以在当地进行的数据标注还是有必要的，”莱赫蒂尼米说。Metroc 并不是唯一一家被迫寻找芬兰数据劳动力的公司。2011 年，国家图书馆发明了一款游戏，以激励志愿者帮助他们数字化其归档资料。2020 年，广播公司 YLE 与赫尔辛基大学及国家发展公司 VAKE 合作，请求志愿者捐赠他们的芬兰语录音。</p><p>&nbsp;</p><p>在某种意义上，芬兰的监狱项目只是一个开始。有些人担心，这可能会开创一个先例：在监狱中引入更具争议的数据标签类型，比如弱化暴力内容。“即使目前在芬兰进行的数据标注没有争议，我们也必须考虑它所开创的先例，”陶说，“有什么能防止公司将有创伤性和不雅内容的数据标注外包给监狱中的人，尤其是如果他们认为那是一个待开发的劳动力资源？”</p><p>&nbsp;</p><p>芬兰的监狱以帮助犯人改过自新而闻名，不知道芬兰监狱里的劳动条件在其他司法没那么先进的国家是否同样适用。根据公民权利团体美国公民自由联盟（ACLU）的数据，76% 的囚犯说监狱劳动是强制性的。拉西拉说，“美国的监狱系统与芬兰或北欧国家有很大的不同，理念完全不同。在芬兰，人们会积极推动这个项目，因为每个人都知道这是自愿的。”</p><p>&nbsp;</p><p>人工智能公司需要的数据劳动力只会越来越多，为了跟上发展的步伐，它们就不得不寻找非同寻常的劳动力。随着 Metroc 规划扩展到北欧以及芬兰以外的语言，维尔纳拉正在考虑是否将监狱劳动力项目扩展到其他国家，她说“这是我们需要探索的事情”。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.wired.com/story/prisoners-training-ai-finland\">https://www.wired.com/story/prisoners-training-ai-finland</a>\"</p>",
    "publish_time": "2023-10-07 10:26:19",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "阳光保险集团人工智能部大模型首席专家张晗确认出席 FCon ，分享大模型技术在保险行业的创新应用与未来发展",
    "url": "https://www.infoq.cn/article/1AT3vxwwWpMKeZt8pXNb",
    "summary": "<p><a href=\"https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle\">FCon 全球金融科技大会</a>\"，将于 11 月在上海召开。阳光保险集团人工智能部大模型首席专家张晗将发表题为《<a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5560?utm_source=infoqweb&amp;utm_medium=article\">大模型技术在保险行业的创新应用与未来发展</a>\"》主题分享，介绍大模型技术以及它在保险行业中的具体应用、通用能力全员应用的发展和应用范围，并分析保险领域专业大模型的关键突破，以及智能理赔机器人在人伤赔偿模式上的革新应用。</p><p></p><p><a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5560?utm_source=infoqweb&amp;utm_medium=article\">张晗</a>\"，现任阳光保险集团人工智能部大模型首席专家，毕业于北京理工大学，曾就职于腾讯、美团等互联网公司，长期从事搜索推荐算法相关工作，2021 年加入阳光保险集团人工智能部，负责“知周”智能对话平台、正言大模型开放平台的研发建设。他在本次会议的演讲内容如下：</p><p></p><p>演讲：大模型技术在保险行业的创新应用与未来发展</p><p></p><p>大模型技术正蓬勃发展，渗透至各行各业中，阳光保险也紧跟潮流，展开了一系列的创新探索和实践，并已取得了显著的效果提升。在本次演讲中，我将向大家详细介绍大模型技术以及它在保险行业中的具体应用，重点探讨阳光正言 GPT 战略工程与保险领域的紧密结合与其重要性，并分享通用能力全员应用的发展和应用范围。最终，我将深入分析保险领域专业大模型的关键突破，以及智能理赔机器人在人伤赔偿模式上的革新应用。</p><p></p><p>演讲提纲：</p><p></p><p>大模型技术带来的新机遇</p><p>○ 大模型技术简介 </p><p>○ 大模型技术在保险业的应用形势</p><p>阳光正言 GPT 战略工程与保险领域结合的重要性</p><p>○ 阳光正言 GPT 战略工程的重点规划 </p><p>○ 大模型底座的建设与重构科技能力 </p><p>○ 全面赋能保险业务的阳光 GPT 工程底座整体架构</p><p>通用能力全员应用的推进与应用范围</p><p>○ 文本生成的通用能力应用 </p><p>○ 文生图与寿险营销的应用实践 </p><p>○ 常青藤编程的全员应用探索</p><p>保险领域专业大模型的重点突破</p><p>○ 保险领域专业大模型的打造机器人产品生态 </p><p>○ 机器人独立完成寿险销售新范式 </p><p>○ AI 全流程独立销售车险产品的新模式 </p><p>○ 改写人伤赔偿模式的智能理赔机器人</p><p></p><p>你将获得：</p><p></p><p>○ 了解阳光正言大模型在保险领域的实践</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle\">DevOps&nbsp;在金融企业落地实践</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle\">金融行业大模型应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle\">创新的金融科技应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle\">金融实时数据平台建设之路</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle\">金融安全风险管控</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle\">数据要素流通与数据合规</a>\"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，前 100 人可享 5 折特惠购票，咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png\" /></p><p></p>",
    "publish_time": "2023-10-07 11:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]