[
  {
    "title": "“初代”数字孪生巨头，如何把虚拟孪生应用于产品全生命周期管理",
    "url": "https://www.infoq.cn/article/N2gWCU0NhYWjmyxwwy2R",
    "summary": "<p>达索系统（Dassault Systemes）成立于1981年，最初是法国达索宇航（Dassault Aviation，欧洲战斗机三雄之一“阵风”制造商）的信息化部门，1981年从达索宇航分离独立发展。如今，<a href=\"https://www.3ds.com/zh-hans/?utm_campaign=202306_chi_3dxp_dassaultsystemes_zh_CMP2164_gilt&amp;utm_medium=cpc&amp;utm_source=baidu&amp;utm_content=search&amp;utm_term=site-dassault-brand-dassault-dasuoxitong-pc\">达索系统</a>\"已经是全球头部工业软件提供商，主要提供三维体验平台（3DExperience），涵盖设计、仿真、制造、协作、数据智能等解决方案，服务于11大行业，是全球几乎所有飞机制造商的技术服务商，也为全球90%的汽车制造企业提供一体化的解决方案。</p><p></p><p>经过40多年的积淀，达索系统跨越了从三维建模（CAD）、数字样机（DMU）到产品生命周期管理（PLM）再到三维体验平台的技术升级，并且在上世纪末就提出了对产品从设计研发、仿真验证到生产制造、使用维护的全生命周期进行数字化的理念。而在<a href=\"https://xie.infoq.cn/article/dc15615d5d5f0eae10972fb89\">数字孪生</a>\"受关注度持续攀升的今天，达索系统进一步提出了虚拟孪生的概念，强调关注数字化对象的历史演进和对未来发展进行预测。</p><p></p><p>在最新一期的 InfoQ《<a href=\"https://www.infoq.cn/theme/192\">超级连麦. 数智大脑</a>\"》直播中，达索系统技术咨询部业务咨询高级经理杨宠介绍了虚拟孪生的概念及其与数字孪生的异同，同时揭示了虚拟孪生技术在产品全生命周期中具体如何发挥作用，从而帮助企业更好地反馈和优化业务结果，减少成本浪费，实现高质量发展。</p><p></p><p>以下是分享全文（经 InfoQ 进行不改变原意的编辑整理）（点击链接可查看完整<a href=\"https://www.infoq.cn/video/axF9GTTK8NAZpglDfCsb\">直播回放</a>\"）：</p><p></p><h2>虚拟孪生≠数字孪生</h2><p></p><p></p><p>达索系统的企业宗旨是利用我们的软件和产品，去推动企业持续创新，最终实现产品、自然和生命的和谐状态。而这个宗旨的实现与虚拟孪生技术紧密相连。</p><p></p><p>大家可能对数字孪生的概念比较熟悉，根据Gartner的定义，它指的是现实世界实体的数字表达，体现的形式和核心要素是软件对象或者模型镜像。在这基础上，达索在2020年提出了虚拟孪生的概念，它不仅仅是现实世界实体的数字表达，还包含了这个数字化对象的演进历史，比如它从哪里来，如何经过设计、仿真、验证，最终制造出来成为一个实体。除此之外，还包括对它未来的预测，比如这个实体产品在使用过程中如何运作、如何更好地进行维修保养服务等等。</p><p></p><p>换句话说，虚拟孪生涵盖了产品全生命周期的过程。那么，我们为什么要提出这样一个概念呢？</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/55/5550bf06ac9ef5141f00dd5e11afa2c4.png\" /></p><p></p><p>从上图中，我们可以看到，左边是实体在虚拟世界的一个数字镜像，右边是现实世界的产品。我们认为，一个产品最早都是从虚拟开始的，包括需求调研、功能设计、逻辑设计，到三维模型定义，以及后面的仿真验证、工艺设计，再到产线上把实物制造出来。</p><p></p><p>虚实之间的关系，首先是一个从虚到实的过程（称为V2R，Virtual to Real）。在虚拟世界里，经过研发、设计并且制造出来的物理实体，最后要交付给客户进行实际的使用或者运行。而在运行过程中，会产生大量的数据，包括IoT数据以及使用过程中机器的传感器数据等等。</p><p></p><p>所以，这时候还会有另外一个回路，我们称为R2V，即从Real到Virtual的过程。也就是说，我们在现实世界中获取到的知识、积累的数据会反馈到虚拟世界，对虚拟世界的下一代产品提供更多提升、创新的机会。</p><p></p><p>这就是虚拟孪生的重要目的，即利用数字化的手段从性能表现、成本控制等各个方面去更好地改造我们的现实世界。</p><p></p><p>另外，对于我们国家而言，虚拟孪生的意义可能还要更加具像化。根据我国的发展规划，到2035年，要实现人均国民生产总值2万到3万美元的跨越，而要实现这个远景目标，一个重要的途径就是高质量发展。落实高质量发展，主要有两大抓手，一是<a href=\"https://www.infoq.cn/article/LBC3Rujd6xFoYfS2duGf\">数字经济</a>\"，二是绿色发展，其中数字经济又包括了数字产业化和产业数字化。而我们认为，虚拟孪生概念很好地贴合了产业数字化的发展课题，它能够更好地帮助企业利用数字技术改造传统制造业。</p><p></p><p>那么，如何构建虚拟孪生呢？它有三个基本要素，分别是数字模型、全量全要素数据，以及人的协作。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a9/a9c7b87b9bb719e02a9f893f09815698.png\" /></p><p></p><p>其中，模型指的就是在数字世界中的精准模型，从广义上来说，它们不仅仅是大家比较熟悉的三维模型，还包含了产品前端市场需求分解后的工程需求模型体系，以及前面提到的功能设计、逻辑设计、仿真、工艺设计再到三维建模的体系化的工程模型体系，同时也包括产线的布局规划，比如产线机器人如何运作等等；</p><p></p><p>第二个要素是<a href=\"https://www.infoq.cn/article/Au8A0GLJcHPNJQp3Vizx\">数据</a>\"，也就是在模型的基础上叠加全量、全要素的数据。所谓全量，指的是深度的问题，也就是说数据数量必须要足够完整，而全要素指的是数据的种类和维度必须齐全，它们将影响模型的精准度；</p><p></p><p>第三个要素是人的协作。因为不管技术如何演进，最终的产品都是为人服务的，因此，我们希望在构建虚拟孪生的过程中，不仅要整合企业内部的员工，还要从研发、工艺到设计和供应链，实现跨生态链的连接，把供应商体系、消费者等角色也纳入进来，从而确保产品在整个全生命周期过程中，都有更好的体验。</p><p></p><h2>虚拟孪生如何在产品全生命周期发挥作用</h2><p></p><p></p><p>下面具体看看虚拟孪生在整个产品全生命周期的各个阶段如何发挥作用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f6/f60bd6b5fbe5fdd8513be223dfcfed5d.png\" /></p><p></p><p>首先，从设计阶段开始，以动力电池行业为例，对于电芯、电池包等这些原材料的选择，整个过程就可以放到虚拟环境中进行，比如对电池的分子级别的分析，对电池包热分析、老化分析、强度的仿真等等；再比如汽车行业的自动驾驶技术研发，如果要在物理世界对自动驾驶进行合规性认证，需要一辆车日夜不停地跑数百年的时间，才能完成所有场景的验证，这时候，只需要把车辆的动力学模型，叠加上环境模型，放到虚拟世界进行充分的仿真验证，就可以快速推动自动驾驶技术的研发速度和技术成熟度。</p><p></p><p>往下，进入工艺设计、规划阶段，这个过程要看工装设备、<a href=\"https://www.infoq.cn/article/1fSLGpl1K3OYX6AgLZ34\">产线机器人</a>\"、总装线的布局等等是否合理。还以汽车为例，比如从冲压、焊装、涂装再到总装，机器人效率是否够高，产线整体节能减排效果是否最优，机械臂是否都达到了规范的操作角度等等，这些问题都可以反馈到虚拟孪生系统中进行仿真和评估。</p><p></p><p>再往后是制造和供应链环节，在这个过程中，企业需要考虑市场需求与产线生产能力的匹配，包括生产的排程等等，这些规划在正式投产之前就可以先在虚拟环境进行分析验证。而在具体制造过程中，关键是生产的执行、产线设备状况、产品质量管理、仓库管理等等，每个环节相关数据的收集，最后都会反馈到具体的制造执行中。</p><p></p><p>最后是服务环节，比如利用大数据分析和仿真模拟，可以进行预防性的维修保养，在产品还没有发生问题的时候，就可以提前提出维修保养的时间建议，甚至为其提前准备好维护的零部件，从而降低产品运行过程中可能发生的宕机的概率和时间。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/da/da3763085134407613094b00b983e61b.png\" /></p><p>虚拟孪生在航空业产品全生命周期的应用</p><p></p><h2>虚拟孪生应用案例及未来展望</h2><p></p><p></p><p>以下跟大家分享几个虚拟孪生的典型应用案例：</p><p></p><p>第一个是优化产线布局的案例。大家知道，如果一个产线真正布置到车间里之后发现问题再进行调整和优化，成本是非常高的，因此，我们帮助一个客户在产线设计阶段就完成了完整的虚拟验证，验证每个机器人和工作单元是不是进行了最优的操作，产线的节拍是否合适，从而保证产线在真正进入工厂之后，能够一次性成功投产，并且布局效能最高。</p><p></p><p>第二个是服务优化的案例。以航空发动机为例，它是飞机的核心部件，只有使得飞机飞起来才能创造价值，停在地面都是成本，所以，我们可以利用虚拟孪生为航空发动机提供设备服务保障，确保它的可靠运行，减少故障带来的成本损失。</p><p></p><p>比如，在运行过程中，航空发动机上大量传感器会持续把运行数据传输到地面的数据中心，在拿到这些数据之后，我们就可以进行充分的分析，一旦发现故障可能性，就可以及时采取应对措施，包括预测分析发动机可能在多长时间后发生什么类型的故障，然后提前在相应的维修网点配备维修备件，在飞机抵达目的地之后及时提供备件更换服务，确保发动机的可靠性。</p><p></p><p>第三个是产品设计环节的案例。我们知道，快消品行业非常注重对用户需求满足和体验优化，但与此同时，还要兼顾成本控制。这时候，可以在设计研发阶段引入虚拟孪生，通过反复的What-If分析，评估采用方案A和方案B的结果，目标成本可以达到什么程度，具体可以满足哪些客户需求等等，通过在设计阶段进行多方案的比对，从而在成本控制和客户需求之间达到一个更优的平衡。</p><p></p><p>最后，展望虚拟孪生技术，我们认为，它不仅可以赋能制造业的产品生命周期过程，甚至还可以在生命科学等领域创造价值。比如，对于医生来说，可以在为病人进行手术之前，在虚拟孪生环境基于相关的模型进行虚拟演练，从而提高手术的成功率，为病人提供更好的医疗服务。这实际上就体现了达索系统通过虚拟孪生实现产品、自然与生命的和谐状态的企业宗旨。</p><p></p><h4>嘉宾介绍：</h4><p></p><p>杨宠，达索系统技术咨询部业务咨询高级经理。华中科技大学工学博士。曾供职于盖德信息技术有限公司 、国际商业机器有限公司（IBM） 、参数技术软件有限公司（PTC） ，为多家制造业企业提供过业务咨询和数字化咨询服务。</p><p></p><p>延展阅读：<a href=\"https://www.infoq.cn/article/1fSLGpl1K3OYX6AgLZ34\">《揭秘“灯塔工厂”的 AI 应用案例和规模化策略》</a>\"</p>",
    "publish_time": "2023-07-24 08:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "我眼中的CSS革命：新特性潜力无限",
    "url": "https://www.infoq.cn/article/E5uA6Gtd7VkIoaebIHzd",
    "summary": "<p></p><h2>变化</h2><p></p><p>&nbsp;</p><p>我从2000年初那会开始用CSS了。在那之前，我们一直用表格加GIF图来设计网页布局，CSS出现之后我们终于走进了“文明社会”。从此CSS成了我最喜欢的编程语言，而回顾它这么多年来的发展，有一件事是肯定的：CSS不再是当初的样子了。我们在2003年编写的CSS跟2013年总有很大区别，而如今又一个十年过去，我们如今编写的CSS比之前更强大、但也更加复杂。</p><p>&nbsp;</p><p>当然，CSS的进化绝非一蹴而就。就如同Web一样，CSS也是逐步演进，最终成了今天的样子。大家还记得第一次用上box-shadow、background-size还有border-radius时的兴奋之情吗？对，这就是CSS前进路上的一个个脚印。</p><p>&nbsp;</p><p>不知道大家有没有关注今年在阿姆斯特丹举办的CSS Day大会，我看了现场直播，而且明显感觉这次跟以往不同。CSS此番迎来了一系列根本层面的变化，甚至有种到了技术奇点的意思。也就是说，CSS由此分成了2020年代前与2020年代后两大阶段。想要选定某个元素的父元素，但浏览器本身又不支持解析CSS？没关系，现在可以直接用:has()。想根据容器大小调整元素，又担心可能造成无限循环？别担心，现在可以用容器查询和随附的新长度单位。这些功能都对CSS乃至整个Web平台做出了有益且大家睽违已久的补充。与其他现代功能（例如自定义属性、min（）、max（）、clamp（））以及关键字大小调整（例如min-content、max-content和fit-content）相结合，我们就能打造出前所未有的灵活组件和强大布局。总而言之，我们如今理解和编写CSS的基本方式已经发生了根本性转变。</p><p>&nbsp;</p><p></p><h2>根本性变革</h2><p></p><p>&nbsp;</p><p>除此之外，标志CSS进入新时代的其实是另一个更大、更加根本性的转变：</p><p>&nbsp;</p><p>CSS现已成为最强大的Web设计工具。</p><p>&nbsp;</p><p>多年以来，设计师必须经历一场艰难卓绝的斗争，才能打造出高质量的网站成果、把自己的想法真正在浏览器当中呈现出来。与此同时，诸如“我真的很抱歉，但您的设计无法用CSS实现”每天都被前端开发者们无奈地说出。设计师设想中的漂亮构图虽然备受好评，但对于CSS这种仍在发展的语言来说显得太过先进。谁能理解并克服CSS中的种种局限甚至说“怪癖”，谁才有望开发出杀手级的出色网站。</p><p>&nbsp;</p><p>于是乎，设计师们吸取一教训，开始创建兼容性更强的布局，比如几乎全部使用12列平均网格。这明显就是开发平台本身的不足所导致。</p><p>&nbsp;</p><p>但如今，情况已经大为不同。</p><p>&nbsp;</p><p>想在Figma、Adobe XD或者Sketch等主流设计工具中模拟并设计出一个能充分发挥CSS网格潜力的布局？做不到。想通过取色器等工具在OKLCH等广色域色彩空间中定义某种颜色，从而在现代屏幕上呈现出更加鲜艳自然的色彩？不可能。想要模拟流体排版，根据窗口或容器大小动态缩放字体，并像在CSS中使用clamp()那样定义最小值和最大值？不可能。或者说定义一种备用字体，在默认网络字体无法加载时立刻顶上？还是不可能。是的，目前市面上任何一种设计工具都已经跟不上CSS的发展。在这个新时代，CSS上只需几行就能轻松实现的功能，反而在设计端找不到对应的选项。设计工具成了前端开发中的新瓶颈。</p><p>&nbsp;</p><p>在去年的一场演讲中，我曾提到应该解决设计工具和CSS间差距越拉越大的问题。从自身出发，我们能做的也只有密切协作、推出更多原型设计，让更多人能在网页设计和开发的交叉点上工作。但这一切并不容易，而且都需要时间。有些团队已经展开了探索，并以新的、协同度更高的方式荼。但对大多数人而言，打破旧习惯显然不是易事。</p><p>&nbsp;</p><p></p><h2>工具的变化</h2><p></p><p>&nbsp;</p><p>总体而言，我希望看到人们对于CSS在设计过程中的认知和作用得到扭转，将瀑布式流程末尾的样式演示工具变成早期设计决策中的核心工具。如此一来，熟悉使用CSS进行原型设计和Web组件构建的设计师将更具价值。作为设计工程领域的自由职业者，我对这一点充满信心。</p><p>&nbsp;</p><p>在CSS Day的演讲上，曾有人问现在的设计师到底要不要学CSS。而专家Heyton给出的答案是：CSS已经成为一种设计工具、一种达成目的的手段，一种可供探索和使用的素材。更重要的是，它成为一种可供思考和决策的工具，开始步入设计舞台的最中央。</p><p>&nbsp;</p><p>“我是按设计工具来学习CSS的，这就是我对设计的理想。设计代表着一种思维过程……它非常抽象，反映的是我们尝试成就某事的路径。在路径当中，我们需要借助各种各样的工具。这种工具可能是Figma，可能是Photoshop，也可能是CSS。”</p><p>&nbsp;</p><p>这就是新CSS，有史以来最强大的Web设计工具。只有用好CSS，我们才能发挥平台上的现代功能；只有将CSS引入设计，我们才能建立起能灵活适应不同环境、不同内容类型的设计方案；也只有使用新CSS，我们才能真正打造出优雅高效、简洁有力的真Web成果。正如Heyton所言：“我不知道到底该不该用CSS，但它肯定值得一用。”</p><p>&nbsp;</p><p></p><h5>原文链接：</h5><p></p><p></p><p><a href=\"https://matthiasott.com/notes/the-new-css?utm_source=CSS-Weekly&amp;utm_campaign=Issue-554&amp;utm_medium=web\">https://matthiasott.com/notes/the-new-css?utm_source=CSS-Weekly&amp;utm_campaign=Issue-554&amp;utm_medium=web</a>\"</p><p>&nbsp;</p><p></p><h5>相关阅读：</h5><p></p><p></p><p><a href=\"https://xie.infoq.cn/article/ff08f11ef5199eac739bcd96d\">一文吃透 CSS 样式中颜色与颜色值的应用</a>\"</p><p><a href=\"https://xie.infoq.cn/article/b43f7080697e3b13f8f1de01a\">CSS 样式中颜色与颜色值的应用</a>\"</p><p><a href=\"https://www.infoq.cn/article/9cUfR6WbcwTyXJzsFxMY\">CSS 选择器的一场革命，:has() 高级使用指南</a>\"</p><p><a href=\"https://xie.infoq.cn/article/329a83f021eebaf46f1ffccf2\">css 过去及未来展望—分析 css 演进及排版布局的考量</a>\"</p>",
    "publish_time": "2023-07-24 11:15:25",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "npm前员工自曝，生态内部存在严重bug | 附避坑指南",
    "url": "https://www.infoq.cn/article/NhSzg8cH4eHfWMppRDV9",
    "summary": "<p></p><p></p><blockquote>最近，npm 前工程经理 Darcy Clarke 在一份报告中指出，npm 注册没有根据相应 tarball 包的内容验证清单信息。Clarke 说，这会导致双重事实来源，攻击者可以利用它来隐藏脚本或依赖项。&nbsp;这一点影响很大。例如，npm 上有个包可能会显示它没有依赖项，而实际上它有。同样，它显示的包名或版本可能与 package.json 中的不同，而这可能会导致缓存中毒。更糟糕的是，它可以隐藏它将在安装期间运行脚本的事实。</blockquote><p></p><p>&nbsp;</p><p>在接受 InfoQ 采访时，Sonatype 安全研究员 Ax Sharma 强调，这种不一致不一定是恶意的，可能是源于合法的克隆或分叉，或者是由于开发人员在更新包时没有清理过时的元数据。他还提出了一点小小的异议：</p><p>&nbsp;</p><p></p><blockquote>相信 package.json 并不一定比相信包的 npmjs 页面更好——两者都不是完全可靠的。</blockquote><p></p><p>&nbsp;</p><p>根据 Sharma 的说法，要解决这个问题需要借助安全工具进行更深入的分析，例如，对恶意文件或受到攻击的文件进行基于散列的分析，即高级二进制指纹。</p><p>&nbsp;</p><p>另一个有用的建议来自 J. M. Rossy 的推特，他建议默认关闭脚本。</p><p>&nbsp;</p><p>如果你对这个清单之惑感兴趣，请阅读 Clarke 的原文，其中有许多其他的见解。</p><p>&nbsp;</p><p>以下为原文翻译。</p><p>&nbsp;</p><p></p><blockquote>简单自我介绍，2019 年 7 月至 2022 年 12 月期间，我负责 npm CLI 团队的工程管理。2020年我参与了 GitHub 收购 npm 项目.。2022年12 月，我因各种原因离开了 GitHub。</blockquote><p></p><p>&nbsp;</p><p>如今，各类新兴供应链攻击可谓层出不穷，而本文要向大家分享的则是其中一例——我个人称之为“manifest混淆”（manifest confusion）。</p><p>&nbsp;</p><p></p><h2>故事背景</h2><p></p><p>&nbsp;</p><p>在Node生态系统发展到如今全球用户达数千万、创建超过310万个软件包、月下载量高达2080亿次的规模之前，当初该项目的贡献者数量曾非常有限。当然，社区越小，大家就越感觉安心，毕竟没有哪个黑客团队会找这么“瘦”的目标下手。但随着时间推移，npm注册表被逐步开发出来，人们可以免费贡献并检查其中的开源代码，语料库的组织政策和实践也迎来同步发展。</p><p>&nbsp;</p><p>从诞生之初，npm项目就非常信任注册表的客户端与服务器端。现在回想起来，这种高度依赖客户端来处理数据验证的作法真的很有问题。但也正是凭借这项策略，是让JavaScript工具生态得以快速成长并在数据形态中有所体现。</p><p>&nbsp;</p><p></p><h2>发生甚么事了？</h2><p></p><p>&nbsp;</p><p>npm公共注册表不会使用包tarball中的内容来验证manifest信息，反而是依赖npm兼容的客户端进行解释和强制验证/一致性。事实上，在研究这个问题时，我发现服务器似乎从未承担过验证任务。</p><p>&nbsp;</p><p>如今，registry.npmjs.com 允许用户通过PUT请求将软件包发布至相应的包URI，例如：</p><p>&nbsp;</p><p>https://registry.npmjs.com/-/。</p><p>&nbsp;</p><p>该端点会接收一条请求body，内容如下所示（请注意：在经历近15年的发展之前，如今的npm及其他注册表API仍然严重缺乏记录信息）：</p><p>&nbsp;</p><p><code lang=\"null\">{\n  _id: ,\n  name: ,\n  'dist-tags': { ... },\n  versions: {\n    '': {\n      _id: '@`,\n      name: '',\n      version: '',\n      dist: {\n        integrity: '',\n        shasum: '',\n        tarball: ''\n      }\n      ...\n    }\n  },\n  _attachments: {\n    0: {\n      content_type: 'application/octet-stream',\n      data: '',\n      length: ''\n    }\n  }\n}</code></p><p>&nbsp;</p><p>目前的问题是，version元数据（也就是「manifest」数据）是独立于存放有软件包package.json的tarball而独立提交的。这两部分信息之间从未进行过相互验证，而且我们往往搞不清依赖项、脚本、许可证等数据的“权威事实来源”究竟是谁。据我所知，tarball才是唯一拥有签名，且有着可离线存储及验证的完整性值的工件。从这些角度看，它应该才是正确的来源；但令人意外的是，package.json当中的name&nbsp;&amp;&nbsp;version&nbsp;字段实际上很可能与manifest中的字段不同，因为二者间不会进行相互验证。</p><p></p><h3>示例</h3><p></p><p></p><p>在npmjs.com上生成身份验证令牌(例如：&nbsp;https://www.npmjs.com/settings//tokens/new&nbsp;- 选择 \"Automation\" 以方便测试)启动一个新项目 (例如：&nbsp;mkdir test &amp;&amp; cd test/ &amp;&amp; npm init -y)安装helper库（例如：npm install ssri libnpmpack npm-registry-fetch)创建一个子目录，作为“真实”的软件包及内容（例如&nbsp;mkdir pkg &amp;&amp; cd pkg/ &amp;&amp; npm init -y)修改该包的内容……在项目根目录中创建一个&nbsp;publish.js&nbsp;文件，内容如下：</p><p>&nbsp;</p><p><code lang=\"null\">;(async () =&gt; {\n  // libs\n  const ssri = require('ssri')\n  const pack = require('libnpmpack')\n  const fetch = require('npm-registry-fetch')\n\n\n  // pack tarball &amp; generate ingetrity\n  const tarball = await pack('./pkg/')\n  const integrity = ssri.fromData(tarball, {\n    algorithms: [...new Set(['sha1', 'sha512'])],\n  })\n\n\n  // craft manifest\n  const name = ''\n  const version = ''\n  const manifest = {\n    _id: name,\n    name: name,\n    'dist-tags': {\n      latest: version,\n    },\n    versions: {\n      [version]: {\n        _id: `${name}@${version}`,\n        name,\n        version,\n        dist: {\n          integrity: integrity.sha512[0].toString(),\n          shasum: integrity.sha1[0].hexDigest(),\n          tarball: '',\n        },\n        scripts: {},\n        dependencies: {},\n      },\n    },\n    _attachments: {\n      0: {\n        content_type: 'application/octet-stream',\n        data: tarball.toString('base64'),\n        length: tarball.length,\n      },\n    },\n  }\n\n\n  // publish via PUT\n  fetch(name, {\n    '//registry.npmjs.org/:_authToken': '',\n    method: 'PUT',\n    body: manifest,\n  })\n})()</code></p><p>&nbsp;</p><p>可随意修改其中&nbsp;manifest&nbsp;键（例如，我在这里去掉了&nbsp;scripts&nbsp;&amp;&nbsp;dependencies&nbsp;)；运行程序（例如：&nbsp;node publish.js)；导航至&nbsp;https://registry.npmjs.com//&nbsp;&amp;&nbsp;https://www.npmjs.com/package//v/?activeTab=explore&nbsp;以查看差异。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/9f/9f86efed26016ca9cabcf62ae88c6740.png\" /></p><p></p><p>&nbsp;</p><p>以上示例中的软件包是用不同manifest发布的，其各有对应的package.json，请参考：</p><p>&nbsp;<a href=\"https://www.npmjs.com/darcyclarke-manifest-pkg\">https://www.npmjs.com/darcyclarke-manifest-pkg</a>\"&nbsp;</p><p>&nbsp;<a href=\"https://registry.npmjs.com/darcyclarke-manifest-pkg/\">https://registry.npmjs.com/darcyclarke-manifest-pkg/</a>\"</p><p></p><h2>&nbsp;Bug, bug, 到处是bug</h2><p></p><p>&nbsp;</p><p>如果大家想用更简单的办法重现这种不一致性，现在也可以使用 npm CLI。一旦在项目中发现binding.gyp文件，它就会在npm发布期间改变manifest内容。这种行为似乎在我加入npm团队之前（即6.x或更早版本）就已经存在于客户端内，而且已经给众多用户惹出了不少麻烦。</p><p>&nbsp;</p><p>npm init -ytouch binding.gypnpm publish可以看到，&nbsp;\"node-gyp rebuild\"&nbsp;scripts.install&nbsp;条目已被自动添加至manifest当中，但却未被添加至tarball的&nbsp;package.json&nbsp;当中。例如：</p><p>&nbsp;<a href=\"https://registry.npmjs.com/darcyclarke-binding\">https://registry.npmjs.com/darcyclarke-binding</a>\"&nbsp;&nbsp;<a href=\"https://unpkg.com/darcyclarke-binding@1.0.0/package.json\">https://unpkg.com/darcyclarke-binding@1.0.0/package.json</a>\"</p><p>&nbsp;</p><p>这种不一致现象在&nbsp;node-canvas中经常出现：</p><p><a href=\"https://www.npmjs.com/package/node-canvas/v/2.9.0?activeTab=explore\">https://www.npmjs.com/package/node-canvas/v/2.9.0?activeTab=explore</a>\"<a href=\"https://registry.npmjs.com/node-canvas/2.9.0\">https://registry.npmjs.com/node-canvas/2.9.0</a>\"<a href=\"https://github.com/npm/cli/issues/5234\">https://github.com/npm/cli/issues/5234</a>\"</p><p>&nbsp;</p><p></p><h2>相关影响</h2><p></p><p>&nbsp;</p><p>这个bug可能会以多种方式影响消费者/最终用户：</p><p>缓存中毒（即保存的包可能与注册表/URI中的名称+版本规格不匹配；安装未知/未列出的依赖项（欺骗安全/审计工具）；安装未知/未列出的脚本（欺骗安全/审计工具）；引发潜在降级攻击（保存到项目中的版本规格，为不符合要求/易受攻击的包版本）。</p><p>&nbsp;</p><p></p><h2>已知受到影响的第三方组织/实体：</h2><p></p><p>&nbsp;</p><p>Snyk:&nbsp;<a href=\"https://security.snyk.io/package/npm/darcyclarke-manifest-pkg\">https://security.snyk.io/package/npm/darcyclarke-manifest-pkg</a>\"CNPMJS/Chinese Mirror:&nbsp;<a href=\"https://npmmirror.com/package/darcyclarke-manifest-pkg\">https://npmmirror.com/package/darcyclarke-manifest-pkg</a>\"Cloudflare Mirror:&nbsp;<a href=\"https://registry.npmjs.cf/darcyclarke-manifest-pkg/2.1.15\">https://registry.npmjs.cf/darcyclarke-manifest-pkg/2.1.15</a>\"Skypack:&nbsp;<a href=\"https://cdn.skypack.dev/-/darcyclarke-manifest-pkg@v2.1.15\">https://cdn.skypack.dev/-/darcyclarke-manifest-pkg@v2.1.15</a>\"UNPKG:&nbsp;<a href=\"https://unpkg.com/darcyclarke-manifest-pkg@2.1.15/package.json\">https://unpkg.com/darcyclarke-manifest-pkg@2.1.15/package.json</a>\"JSPM:&nbsp;<a href=\"https://ga.jspm.io/npm:darcyclarke-manifest-pkg@2.1.15/package.json\">https://ga.jspm.io/npm:darcyclarke-manifest-pkg@2.1.15/package.json</a>\"Yarn:&nbsp;<a href=\"https://yarnpkg.com/package/darcyclarke-manifest-pkg\">https://yarnpkg.com/package/darcyclarke-manifest-pkg</a>\"</p><p>&nbsp;</p><p>&nbsp;</p><p></p><blockquote>更新：前文提到，Socket Security易受到manifest混淆问题的影响。自2022年9月5日起，Socket方面已开始使用tarball内的package.json文件作为事实来源，且要求显示包的准确信息（例如依赖项、许可证、脚本等）。截至本文发布时，darcyclarke0-manifest-pkg的软件包页面错误地引用了过时的数据，但Socket团队很快解决了这个问题。这里要称赞一声，Socket可能是首个正确处理此问题的项目团队。</blockquote><p></p><p>&nbsp;</p><p>此问题还会以下面介绍的几种方式，影响到所有已知的主要JavaScript包管理器。jFrog的Artifacory等第三方注册表实现似乎也继承了该API的设计/问题，因此使用这些私有注册表实例的所有客户端也会出现相同的问题/不一致。</p><p>&nbsp;</p><p>注意，各类包管理器和工具对应不同的应用场景。它们要么使用/引用软件包的注册表manifest，要么使用/引用tarball的package.json（主要是为了通过缓存机制提高安装性能）。</p><p>&nbsp;</p><p>这里需要强调的是，生态系统目前仍普遍存在错误假设，即manifest的内容始终与tarball的package.json内容一致（这主要是因为注册表API说明文档过少，且docs.npmjs.com多次提到注册表会将package.json的内容存储为元数据——但却没有强调其实是由客户端负责确保一致性）。</p><p>&nbsp;</p><p></p><h2>npm@6</h2><p></p><p></p><h3>执行manifest/tarball中不存在的脚本</h3><p></p><p></p><p>重现步骤：</p><p>安装一个格式经过篡改的依赖项:&nbsp;npx npm@6 install darcyclarke-manifest-pkg@2.1.13See that lifecycle scripts are being executed even though none are present in the manifest &amp; the registry has not registered the package as having install script (ie.可以看到，虽然在manifest中并不存在/注册表尚未将包注册为具有安装脚本，但生命周期脚本仍在执行（即&nbsp;hasInstallScript&nbsp;为&nbsp;undefined/false) 参考：</p><p>&nbsp;<a href=\"https://registry.npmjs.org/darcyclarke-manifest-pkg/2.1.13\">https://registry.npmjs.org/darcyclarke-manifest-pkg/2.1.13</a>\"&nbsp;</p><p></p><p>代码/包请参考：</p><p><a href=\"https://github.com/npm/minify-registry-metadata/blob/main/lib/index.js\">https://github.com/npm/minify-registry-metadata/blob/main/lib/index.js</a>\"</p><p>node_modules/darcyclarke-manifest-pkg当中的package.json反映tarball条目。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/71/71cbb2e4e858254b0c5c93e13a633440.png\" /></p><p></p><p>&nbsp;</p><p></p><h3>安装manifest/tarball中不存在的依赖项</h3><p></p><p>&nbsp;</p><p>由于包tarball会被缓存在全局存储当中，所以如果--prefer-offline配置与--no-package-lock共同使用，则下一次在系统中对该包运行install时，隐藏在tarball中的依赖项也会被安装。</p><p>重现步骤：</p><p>安装&nbsp;npx npm@6 install darcyclarke-manifest-pkg@2.1.13再次运行安装…&nbsp;npx npm@6 install --prefer-offline --no-package-lock</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5a/5a3580cf29effdeddd197f7c654b897c.png\" /></p><p></p><p></p><h2>npm@9</h2><p></p><p></p><h3>安装manifest/tarball中不存在的依赖项</h3><p></p><p></p><p>与npm@6,类似，npm@9在使用--offline配置时也会直接安装经过缓存的tarball package.json当中引用的依赖项。</p><p>&nbsp;</p><p></p><blockquote>注意：其中似乎存在争用条件，即--offline可能会/可能不会被从缓存内提取，因此重现结果并不稳定。</blockquote><p></p><p>&nbsp;</p><p>重现步骤：</p><p>安装格式经过篡改的依赖项以将其缓存；在安装时使用--offline配置并/或关闭可用网络（例如： npm install --offline --no-package-lock)可以看到，manifest中并未引用的依赖项也会被安装。</p><p>&nbsp;</p><p></p><h2>yarn@1</h2><p></p><p>&nbsp;</p><p></p><h3>执行manifest/tarball中不存在的安装脚本</h3><p></p><p>&nbsp;</p><p>与 npm@6 &amp; npm@9类似，yarn@1 会tarball中引用、但manifest并未引用的脚本，反之亦然。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c3/c3e208eaf879533f7bd33cdbeb3cec3d.png\" /></p><p></p><p>&nbsp;</p><p></p><h3>使用tarball中的version字段——暴露潜在降级攻击向量</h3><p></p><p></p><p>现在大家已经了解，tarball的内容定义可以与manifest有所不同；在这种情况下，yarn@1顺理成章地在升级/降级之后，再把错误版本保存回当前项目的package.json当中（可能令用户在后续安装中遭受降级攻击）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/35/35f32f33193f0fa1a584950cf83e1df2.png\" /></p><p></p><p>&nbsp;</p><p></p><h2>pnpm@7</h2><p></p><p></p><h3>执行manifest/tarball中不存在的安装脚本</h3><p></p><p></p><p>重现步骤：</p><p>与之前几个案例类似，pnpm会运行tarball中存在、但manifest并未引用的脚本，反之亦然。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a5/a53c4e8ea43a751ce77609d6097480d2.png\" /></p><p></p><p>&nbsp;</p><p></p><h2>CWE分类/细分</h2><p></p><p>&nbsp;</p><p>此漏洞可能涉及多种CWE分类。至少如果我们把此问题视为“特例”，则以上情况应该被归纳为“服务端安全的客户端实施”（即CWE-602——但我严重怀疑这种判断并不适用。我在下文中会具体分析各种问题及其相应CWE分类，且分别提供参考代码）。</p><p></p><p><a href=\"https://cwe.mitre.org/data/definitions/602.html\">CWE-602: 服务端安全的客户端实施</a>\"长期以来，我们一直严重依赖客户端（即npm&nbsp;CLI）完成本应在服务器端完成的工作；代码参考：&nbsp;<a href=\"https://github.com/npm/cli/blob/latest/workspaces/libnpmpublish/lib/publish.js\">https://github.com/npm/cli/blob/latest/workspaces/libnpmpublish/lib/publish.js#L63</a>\"<a href=\"https://cwe.mitre.org/data/definitions/94.html\">CWE-94: 代码生成控制不当（「代码注入」）</a>\"这会影响全体用户（包括&nbsp;npm等包管理器）; 如下所述，这会导致其出现各种问题<a href=\"https://cwe.mitre.org/data/definitions/295.html\">CWE-295: 证书生成不当</a>\"即使内容（包括&nbsp;name,&nbsp;version,&nbsp;dependencies,&nbsp;license,&nbsp;scripts&nbsp;等)与相关注册表索引有所不同，tarball仍可获得签名并被赋予完整性值<a href=\"https://cwe.mitre.org/data/definitions/325.html\">CWE-325: 缺少加密步骤</a>\"manifest数据未经签名，因此无法离线缓存或验证；缺少与tarball的package.json及包manifest相符的数据子集的哈希值/验证；<a href=\"https://cwe.mitre.org/data/definitions/656.html\">CWE-656: 依赖构建于封闭的安全性</a>\"由于缺乏关于注册表API的说明文档，因此很难发现该问题。</p><p></p><h2>GitHub为此做了哪些努力？</h2><p></p><p>&nbsp;</p><p>据我所知，GitHub大概在2022年11月4日左右发现了这个问题；经过独立研究之后，我认为这个问题的潜在影响/风险要比最初的判断大得多，因此于3月9日提交了一份包含个人发现的HackerOne报告。3月21日，GitHub关闭了该工单，表示他们正在“内部”处理这个问题。据我了解，之后GitHub没有取得任何&nbsp;重大进展，也没有公开发布这个问题。相反，他们在过去半年间逐渐放弃了npm的产品地位，且拒绝更新或提供关于补救措施的相关说明。</p><p></p><h2>可行的解决方案</h2><p></p><p>&nbsp;</p><p>GitHub正陷入不可逆转的困境。事实上，npmjs.com就是在这样的状态下运行了十余年，意味着目前的安全状况已经被深深嵌入代码当中，再难实现广泛修复。如前所述，npm&nbsp;CLI本身也依赖于这种设计，而且目前还可能存在其他非恶意用途。</p><p></p><p>该做点什么……应开展进一步调查，确定注册表内受影响条目的具体范围，这将有助于确定滥用情况。如果差异量不太大（但考虑到当前manifest变体的可观规模，这种可能性恐怕很低），那么也许可以根据tarball的package.json重新生成包含差异的manifest。从现在起，根据研究/发现对manifest中高权限/已知密钥强制执行/验证。尽快将npm公共注册表API及其相应的请求/响应对象记录下来。</p><p></p><h2>用户能做点什么？</h2><p></p><p>&nbsp;</p><p>与认识的任何使用npm注册表manifest数据的已知工具作者/维护者联系，确保他们知情并想办法在适当时转而使用包内容作为元数据（即除了name&nbsp;&amp;&nbsp;version之外的所有内容）。另外，请从现在起严格执行/验证注册表代理的一致性。</p><p></p><h5>原文链接：</h5><p></p><p><a href=\"https://blog.vlt.sh/blog/the-massive-hole-in-the-npm-ecosystem\">https://blog.vlt.sh/blog/the-massive-hole-in-the-npm-ecosystem</a>\"</p><p></p><h5>相关阅读：</h5><p></p><p><a href=\"https://xie.infoq.cn/article/68c7b3477e46c8cb05402a1aa\">前端开发：node.js 的 node 包管理器&nbsp;npm&nbsp;安装以及...</a>\"</p><p><a href=\"https://xie.infoq.cn/article/7404283d515ca3de1bedd14fc\">NPM&nbsp;实用命令与快捷方式</a>\"</p><p><a href=\"https://xie.infoq.cn/article/a64989cdc2b9cdee73fea23bb\">前端包管理工具&nbsp;npm&nbsp;yarn cnpm npx</a>\"</p><p><a href=\"https://www.infoq.cn/article/DvD8AkqdMqvuQpAw1heP\">Npm,Inc. 发布&nbsp;Npm&nbsp;Pro，面向独立 JavaScript 开发人员</a>\"</p><p></p><p>&nbsp;</p>",
    "publish_time": "2023-07-24 11:16:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "中国研发效能管理白皮书—从价值流管理到研发效能管理",
    "url": "https://www.infoq.cn/article/y6K49q7Ctmir5ro9wFZC",
    "summary": "<p></p><h3>研究背景</h3><p></p><p>近年来，中国企业研发正在从粗放型走向精益型，研发工作的“高效能”成为几乎每个研发团队的共同追求。</p><p></p><p>中国软件服务产业也在近 5 到 10 年中得到了飞速发展，技术服务的边界不断拓展，赋能高效研发的产品层出不穷，适合中国研发环境的技术服务体系在不断完善。从结果上看，中国企业正在高效能研发的路径上快速前进。</p><p></p><p>本份报告以中国高效能研发企业为研究对象，尝试解读市场中具有代表性的高效能研发解决方案。本次报告由五个篇章组成，包括 CI/CD 、企业级软件架构、研发效能管理等主题。研究小组期待可以通过研究，帮助中国企业研发团队获得高效能研发新知。</p><p></p><p>作为本次报告的最后一个篇章，本书先是讨论了价值流管理相关的定义、特征、主要分析指标、发展历程。再从价值流管理面临的问题出发，讨论并得出中国场景下需要在需求价值流和工程实践流的双流模型，最终落地研发效能管理。</p><p></p><p>最后，本书分析研发效能管理的关键要素，并总结输出研发效能管理的方法论体系（GDAI），四步走帮助企业落地研发效能管理。再结合成功案例，在案例中展现研发效能管理的效果与价值。</p><p></p><h3>目录</h3><p></p><p>价值流管理定义与背景价值流管理行业发展现状极狐 GitLab 研发效能管理</p><p></p><p>扫码下载</p><p><img src=\"https://static001.geekbang.org/infoq/fe/fe0e3878a03224cf558ab25affb46248.jpeg\" /></p><p></p>",
    "publish_time": "2023-07-24 12:00:31",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "npm前员工自曝生态内部存在严重bug | 附避坑指南",
    "url": "https://www.infoq.cn/article/NhSzg8cH4eHfWMppRDV9",
    "summary": "<p></p><p></p><blockquote>最近，npm 前工程经理 Darcy Clarke 在一份报告中指出，npm 注册没有根据相应 tarball 包的内容验证清单信息。Clarke 说，这会导致双重事实来源，攻击者可以利用它来隐藏脚本或依赖项。&nbsp;这一点影响很大。例如，npm 上有个包可能会显示它没有依赖项，而实际上它有。同样，它显示的包名或版本可能与 package.json 中的不同，而这可能会导致缓存中毒。更糟糕的是，它可以隐藏它将在安装期间运行脚本的事实。</blockquote><p></p><p>&nbsp;</p><p>在接受 InfoQ 采访时，Sonatype 安全研究员 Ax Sharma 强调，这种不一致不一定是恶意的，可能是源于合法的克隆或分叉，或者是由于开发人员在更新包时没有清理过时的元数据。他还提出了一点小小的异议：</p><p>&nbsp;</p><p></p><blockquote>相信 package.json 并不一定比相信包的 npmjs 页面更好——两者都不是完全可靠的。</blockquote><p></p><p>&nbsp;</p><p>根据 Sharma 的说法，要解决这个问题需要借助安全工具进行更深入的分析，例如，对恶意文件或受到攻击的文件进行基于散列的分析，即高级二进制指纹。</p><p>&nbsp;</p><p>另一个有用的建议来自 J. M. Rossy 的推特，他建议默认关闭脚本。</p><p>&nbsp;</p><p>如果你对这个清单之惑感兴趣，请阅读 Clarke 的原文，其中有许多其他的见解。</p><p>&nbsp;</p><p>以下为原文翻译。</p><p>&nbsp;</p><p></p><blockquote>简单自我介绍，2019 年 7 月至 2022 年 12 月期间，我负责 npm CLI 团队的工程管理。2020年我参与了 GitHub 收购 npm 项目.。2022年12 月，我因各种原因离开了 GitHub。</blockquote><p></p><p>&nbsp;</p><p>如今，各类新兴供应链攻击可谓层出不穷，而本文要向大家分享的则是其中一例——我个人称之为“manifest混淆”（manifest confusion）。</p><p>&nbsp;</p><p></p><h2>故事背景</h2><p></p><p>&nbsp;</p><p>在Node生态系统发展到如今全球用户达数千万、创建超过310万个软件包、月下载量高达2080亿次的规模之前，当初该项目的贡献者数量曾非常有限。当然，社区越小，大家就越感觉安心，毕竟没有哪个黑客团队会找这么“瘦”的目标下手。但随着时间推移，npm注册表被逐步开发出来，人们可以免费贡献并检查其中的开源代码，语料库的组织政策和实践也迎来同步发展。</p><p>&nbsp;</p><p>从诞生之初，npm项目就非常信任注册表的客户端与服务器端。现在回想起来，这种高度依赖客户端来处理数据验证的作法真的很有问题。但也正是凭借这项策略，是让JavaScript工具生态得以快速成长并在数据形态中有所体现。</p><p>&nbsp;</p><p></p><h2>发生甚么事了？</h2><p></p><p>&nbsp;</p><p>npm公共注册表不会使用包tarball中的内容来验证manifest信息，反而是依赖npm兼容的客户端进行解释和强制验证/一致性。事实上，在研究这个问题时，我发现服务器似乎从未承担过验证任务。</p><p>&nbsp;</p><p>如今，registry.npmjs.com 允许用户通过PUT请求将软件包发布至相应的包URI，例如：</p><p>&nbsp;</p><p>https://registry.npmjs.com/-/。</p><p>&nbsp;</p><p>该端点会接收一条请求body，内容如下所示（请注意：在经历近15年的发展之前，如今的npm及其他注册表API仍然严重缺乏记录信息）：</p><p>&nbsp;</p><p><code lang=\"null\">{\n  _id: ,\n  name: ,\n  'dist-tags': { ... },\n  versions: {\n    '': {\n      _id: '@`,\n      name: '',\n      version: '',\n      dist: {\n        integrity: '',\n        shasum: '',\n        tarball: ''\n      }\n      ...\n    }\n  },\n  _attachments: {\n    0: {\n      content_type: 'application/octet-stream',\n      data: '',\n      length: ''\n    }\n  }\n}</code></p><p>&nbsp;</p><p>目前的问题是，version元数据（也就是「manifest」数据）是独立于存放有软件包package.json的tarball而独立提交的。这两部分信息之间从未进行过相互验证，而且我们往往搞不清依赖项、脚本、许可证等数据的“权威事实来源”究竟是谁。据我所知，tarball才是唯一拥有签名，且有着可离线存储及验证的完整性值的工件。从这些角度看，它应该才是正确的来源；但令人意外的是，package.json当中的name&nbsp;&amp;&nbsp;version&nbsp;字段实际上很可能与manifest中的字段不同，因为二者间不会进行相互验证。</p><p></p><h3>示例</h3><p></p><p></p><p>在npmjs.com上生成身份验证令牌(例如：&nbsp;https://www.npmjs.com/settings//tokens/new&nbsp;- 选择 \"Automation\" 以方便测试)启动一个新项目 (例如：&nbsp;mkdir test &amp;&amp; cd test/ &amp;&amp; npm init -y)安装helper库（例如：npm install ssri libnpmpack npm-registry-fetch)创建一个子目录，作为“真实”的软件包及内容（例如&nbsp;mkdir pkg &amp;&amp; cd pkg/ &amp;&amp; npm init -y)修改该包的内容……在项目根目录中创建一个&nbsp;publish.js&nbsp;文件，内容如下：</p><p>&nbsp;</p><p><code lang=\"null\">;(async () =&gt; {\n  // libs\n  const ssri = require('ssri')\n  const pack = require('libnpmpack')\n  const fetch = require('npm-registry-fetch')\n\n\n  // pack tarball &amp; generate ingetrity\n  const tarball = await pack('./pkg/')\n  const integrity = ssri.fromData(tarball, {\n    algorithms: [...new Set(['sha1', 'sha512'])],\n  })\n\n\n  // craft manifest\n  const name = ''\n  const version = ''\n  const manifest = {\n    _id: name,\n    name: name,\n    'dist-tags': {\n      latest: version,\n    },\n    versions: {\n      [version]: {\n        _id: `${name}@${version}`,\n        name,\n        version,\n        dist: {\n          integrity: integrity.sha512[0].toString(),\n          shasum: integrity.sha1[0].hexDigest(),\n          tarball: '',\n        },\n        scripts: {},\n        dependencies: {},\n      },\n    },\n    _attachments: {\n      0: {\n        content_type: 'application/octet-stream',\n        data: tarball.toString('base64'),\n        length: tarball.length,\n      },\n    },\n  }\n\n\n  // publish via PUT\n  fetch(name, {\n    '//registry.npmjs.org/:_authToken': '',\n    method: 'PUT',\n    body: manifest,\n  })\n})()</code></p><p>&nbsp;</p><p>可随意修改其中&nbsp;manifest&nbsp;键（例如，我在这里去掉了&nbsp;scripts&nbsp;&amp;&nbsp;dependencies&nbsp;)；运行程序（例如：&nbsp;node publish.js)；导航至&nbsp;https://registry.npmjs.com//&nbsp;&amp;&nbsp;https://www.npmjs.com/package//v/?activeTab=explore&nbsp;以查看差异。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/9f/9f86efed26016ca9cabcf62ae88c6740.png\" /></p><p></p><p>&nbsp;</p><p>以上示例中的软件包是用不同manifest发布的，其各有对应的package.json，请参考：</p><p>&nbsp;<a href=\"https://www.npmjs.com/darcyclarke-manifest-pkg\">https://www.npmjs.com/darcyclarke-manifest-pkg</a>\"&nbsp;</p><p>&nbsp;<a href=\"https://registry.npmjs.com/darcyclarke-manifest-pkg/\">https://registry.npmjs.com/darcyclarke-manifest-pkg/</a>\"</p><p></p><h2>&nbsp;Bug, bug, 到处是bug</h2><p></p><p>&nbsp;</p><p>如果大家想用更简单的办法重现这种不一致性，现在也可以使用 npm CLI。一旦在项目中发现binding.gyp文件，它就会在npm发布期间改变manifest内容。这种行为似乎在我加入npm团队之前（即6.x或更早版本）就已经存在于客户端内，而且已经给众多用户惹出了不少麻烦。</p><p>&nbsp;</p><p>npm init -ytouch binding.gypnpm publish可以看到，&nbsp;\"node-gyp rebuild\"&nbsp;scripts.install&nbsp;条目已被自动添加至manifest当中，但却未被添加至tarball的&nbsp;package.json&nbsp;当中。例如：</p><p>&nbsp;<a href=\"https://registry.npmjs.com/darcyclarke-binding\">https://registry.npmjs.com/darcyclarke-binding</a>\"&nbsp;&nbsp;<a href=\"https://unpkg.com/darcyclarke-binding@1.0.0/package.json\">https://unpkg.com/darcyclarke-binding@1.0.0/package.json</a>\"</p><p>&nbsp;</p><p>这种不一致现象在&nbsp;node-canvas中经常出现：</p><p><a href=\"https://www.npmjs.com/package/node-canvas/v/2.9.0?activeTab=explore\">https://www.npmjs.com/package/node-canvas/v/2.9.0?activeTab=explore</a>\"<a href=\"https://registry.npmjs.com/node-canvas/2.9.0\">https://registry.npmjs.com/node-canvas/2.9.0</a>\"<a href=\"https://github.com/npm/cli/issues/5234\">https://github.com/npm/cli/issues/5234</a>\"</p><p>&nbsp;</p><p></p><h2>相关影响</h2><p></p><p>&nbsp;</p><p>这个bug可能会以多种方式影响消费者/最终用户：</p><p>缓存中毒（即保存的包可能与注册表/URI中的名称+版本规格不匹配；安装未知/未列出的依赖项（欺骗安全/审计工具）；安装未知/未列出的脚本（欺骗安全/审计工具）；引发潜在降级攻击（保存到项目中的版本规格，为不符合要求/易受攻击的包版本）。</p><p>&nbsp;</p><p></p><h2>已知受到影响的第三方组织/实体：</h2><p></p><p>&nbsp;</p><p>Snyk:&nbsp;<a href=\"https://security.snyk.io/package/npm/darcyclarke-manifest-pkg\">https://security.snyk.io/package/npm/darcyclarke-manifest-pkg</a>\"CNPMJS/Chinese Mirror:&nbsp;<a href=\"https://npmmirror.com/package/darcyclarke-manifest-pkg\">https://npmmirror.com/package/darcyclarke-manifest-pkg</a>\"Cloudflare Mirror:&nbsp;<a href=\"https://registry.npmjs.cf/darcyclarke-manifest-pkg/2.1.15\">https://registry.npmjs.cf/darcyclarke-manifest-pkg/2.1.15</a>\"Skypack:&nbsp;<a href=\"https://cdn.skypack.dev/-/darcyclarke-manifest-pkg@v2.1.15\">https://cdn.skypack.dev/-/darcyclarke-manifest-pkg@v2.1.15</a>\"UNPKG:&nbsp;<a href=\"https://unpkg.com/darcyclarke-manifest-pkg@2.1.15/package.json\">https://unpkg.com/darcyclarke-manifest-pkg@2.1.15/package.json</a>\"JSPM:&nbsp;<a href=\"https://ga.jspm.io/npm:darcyclarke-manifest-pkg@2.1.15/package.json\">https://ga.jspm.io/npm:darcyclarke-manifest-pkg@2.1.15/package.json</a>\"Yarn:&nbsp;<a href=\"https://yarnpkg.com/package/darcyclarke-manifest-pkg\">https://yarnpkg.com/package/darcyclarke-manifest-pkg</a>\"</p><p>&nbsp;</p><p>&nbsp;</p><p></p><blockquote>更新：前文提到，Socket Security易受到manifest混淆问题的影响。自2022年9月5日起，Socket方面已开始使用tarball内的package.json文件作为事实来源，且要求显示包的准确信息（例如依赖项、许可证、脚本等）。截至本文发布时，darcyclarke0-manifest-pkg的软件包页面错误地引用了过时的数据，但Socket团队很快解决了这个问题。这里要称赞一声，Socket可能是首个正确处理此问题的项目团队。</blockquote><p></p><p>&nbsp;</p><p>此问题还会以下面介绍的几种方式，影响到所有已知的主要JavaScript包管理器。jFrog的Artifacory等第三方注册表实现似乎也继承了该API的设计/问题，因此使用这些私有注册表实例的所有客户端也会出现相同的问题/不一致。</p><p>&nbsp;</p><p>注意，各类包管理器和工具对应不同的应用场景。它们要么使用/引用软件包的注册表manifest，要么使用/引用tarball的package.json（主要是为了通过缓存机制提高安装性能）。</p><p>&nbsp;</p><p>这里需要强调的是，生态系统目前仍普遍存在错误假设，即manifest的内容始终与tarball的package.json内容一致（这主要是因为注册表API说明文档过少，且docs.npmjs.com多次提到注册表会将package.json的内容存储为元数据——但却没有强调其实是由客户端负责确保一致性）。</p><p>&nbsp;</p><p></p><h2>npm@6</h2><p></p><p></p><h3>执行manifest/tarball中不存在的脚本</h3><p></p><p></p><p>重现步骤：</p><p>安装一个格式经过篡改的依赖项:&nbsp;npx npm@6 install darcyclarke-manifest-pkg@2.1.13See that lifecycle scripts are being executed even though none are present in the manifest &amp; the registry has not registered the package as having install script (ie.可以看到，虽然在manifest中并不存在/注册表尚未将包注册为具有安装脚本，但生命周期脚本仍在执行（即&nbsp;hasInstallScript&nbsp;为&nbsp;undefined/false) 参考：</p><p>&nbsp;<a href=\"https://registry.npmjs.org/darcyclarke-manifest-pkg/2.1.13\">https://registry.npmjs.org/darcyclarke-manifest-pkg/2.1.13</a>\"&nbsp;</p><p></p><p>代码/包请参考：</p><p><a href=\"https://github.com/npm/minify-registry-metadata/blob/main/lib/index.js\">https://github.com/npm/minify-registry-metadata/blob/main/lib/index.js</a>\"</p><p>node_modules/darcyclarke-manifest-pkg当中的package.json反映tarball条目。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/71/71cbb2e4e858254b0c5c93e13a633440.png\" /></p><p></p><p>&nbsp;</p><p></p><h3>安装manifest/tarball中不存在的依赖项</h3><p></p><p>&nbsp;</p><p>由于包tarball会被缓存在全局存储当中，所以如果--prefer-offline配置与--no-package-lock共同使用，则下一次在系统中对该包运行install时，隐藏在tarball中的依赖项也会被安装。</p><p>重现步骤：</p><p>安装&nbsp;npx npm@6 install darcyclarke-manifest-pkg@2.1.13再次运行安装…&nbsp;npx npm@6 install --prefer-offline --no-package-lock</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5a/5a3580cf29effdeddd197f7c654b897c.png\" /></p><p></p><p></p><h2>npm@9</h2><p></p><p></p><h3>安装manifest/tarball中不存在的依赖项</h3><p></p><p></p><p>与npm@6,类似，npm@9在使用--offline配置时也会直接安装经过缓存的tarball package.json当中引用的依赖项。</p><p>&nbsp;</p><p></p><blockquote>注意：其中似乎存在争用条件，即--offline可能会/可能不会被从缓存内提取，因此重现结果并不稳定。</blockquote><p></p><p>&nbsp;</p><p>重现步骤：</p><p>安装格式经过篡改的依赖项以将其缓存；在安装时使用--offline配置并/或关闭可用网络（例如： npm install --offline --no-package-lock)可以看到，manifest中并未引用的依赖项也会被安装。</p><p>&nbsp;</p><p></p><h2>yarn@1</h2><p></p><p>&nbsp;</p><p></p><h3>执行manifest/tarball中不存在的安装脚本</h3><p></p><p>&nbsp;</p><p>与 npm@6 &amp; npm@9类似，yarn@1 会tarball中引用、但manifest并未引用的脚本，反之亦然。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c3/c3e208eaf879533f7bd33cdbeb3cec3d.png\" /></p><p></p><p>&nbsp;</p><p></p><h3>使用tarball中的version字段——暴露潜在降级攻击向量</h3><p></p><p></p><p>现在大家已经了解，tarball的内容定义可以与manifest有所不同；在这种情况下，yarn@1顺理成章地在升级/降级之后，再把错误版本保存回当前项目的package.json当中（可能令用户在后续安装中遭受降级攻击）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/35/35f32f33193f0fa1a584950cf83e1df2.png\" /></p><p></p><p>&nbsp;</p><p></p><h2>pnpm@7</h2><p></p><p></p><h3>执行manifest/tarball中不存在的安装脚本</h3><p></p><p></p><p>重现步骤：</p><p>与之前几个案例类似，pnpm会运行tarball中存在、但manifest并未引用的脚本，反之亦然。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a5/a53c4e8ea43a751ce77609d6097480d2.png\" /></p><p></p><p>&nbsp;</p><p></p><h2>CWE分类/细分</h2><p></p><p>&nbsp;</p><p>此漏洞可能涉及多种CWE分类。至少如果我们把此问题视为“特例”，则以上情况应该被归纳为“服务端安全的客户端实施”（即CWE-602——但我严重怀疑这种判断并不适用。我在下文中会具体分析各种问题及其相应CWE分类，且分别提供参考代码）。</p><p></p><p><a href=\"https://cwe.mitre.org/data/definitions/602.html\">CWE-602: 服务端安全的客户端实施</a>\"长期以来，我们一直严重依赖客户端（即npm&nbsp;CLI）完成本应在服务器端完成的工作；代码参考：&nbsp;<a href=\"https://github.com/npm/cli/blob/latest/workspaces/libnpmpublish/lib/publish.js\">https://github.com/npm/cli/blob/latest/workspaces/libnpmpublish/lib/publish.js#L63</a>\"<a href=\"https://cwe.mitre.org/data/definitions/94.html\">CWE-94: 代码生成控制不当（「代码注入」）</a>\"这会影响全体用户（包括&nbsp;npm等包管理器）; 如下所述，这会导致其出现各种问题<a href=\"https://cwe.mitre.org/data/definitions/295.html\">CWE-295: 证书生成不当</a>\"即使内容（包括&nbsp;name,&nbsp;version,&nbsp;dependencies,&nbsp;license,&nbsp;scripts&nbsp;等)与相关注册表索引有所不同，tarball仍可获得签名并被赋予完整性值<a href=\"https://cwe.mitre.org/data/definitions/325.html\">CWE-325: 缺少加密步骤</a>\"manifest数据未经签名，因此无法离线缓存或验证；缺少与tarball的package.json及包manifest相符的数据子集的哈希值/验证；<a href=\"https://cwe.mitre.org/data/definitions/656.html\">CWE-656: 依赖构建于封闭的安全性</a>\"由于缺乏关于注册表API的说明文档，因此很难发现该问题。</p><p></p><h2>GitHub为此做了哪些努力？</h2><p></p><p>&nbsp;</p><p>据我所知，GitHub大概在2022年11月4日左右发现了这个问题；经过独立研究之后，我认为这个问题的潜在影响/风险要比最初的判断大得多，因此于3月9日提交了一份包含个人发现的HackerOne报告。3月21日，GitHub关闭了该工单，表示他们正在“内部”处理这个问题。据我了解，之后GitHub没有取得任何&nbsp;重大进展，也没有公开发布这个问题。相反，他们在过去半年间逐渐放弃了npm的产品地位，且拒绝更新或提供关于补救措施的相关说明。</p><p></p><h2>可行的解决方案</h2><p></p><p>&nbsp;</p><p>GitHub正陷入不可逆转的困境。事实上，npmjs.com就是在这样的状态下运行了十余年，意味着目前的安全状况已经被深深嵌入代码当中，再难实现广泛修复。如前所述，npm&nbsp;CLI本身也依赖于这种设计，而且目前还可能存在其他非恶意用途。</p><p></p><p>该做点什么……应开展进一步调查，确定注册表内受影响条目的具体范围，这将有助于确定滥用情况。如果差异量不太大（但考虑到当前manifest变体的可观规模，这种可能性恐怕很低），那么也许可以根据tarball的package.json重新生成包含差异的manifest。从现在起，根据研究/发现对manifest中高权限/已知密钥强制执行/验证。尽快将npm公共注册表API及其相应的请求/响应对象记录下来。</p><p></p><h2>用户能做点什么？</h2><p></p><p>&nbsp;</p><p>与认识的任何使用npm注册表manifest数据的已知工具作者/维护者联系，确保他们知情并想办法在适当时转而使用包内容作为元数据（即除了name&nbsp;&amp;&nbsp;version之外的所有内容）。另外，请从现在起严格执行/验证注册表代理的一致性。</p><p></p><h5>原文链接：</h5><p></p><p><a href=\"https://blog.vlt.sh/blog/the-massive-hole-in-the-npm-ecosystem\">https://blog.vlt.sh/blog/the-massive-hole-in-the-npm-ecosystem</a>\"</p><p></p><h5>相关阅读：</h5><p></p><p><a href=\"https://xie.infoq.cn/article/68c7b3477e46c8cb05402a1aa\">前端开发：node.js 的 node 包管理器&nbsp;npm&nbsp;安装以及...</a>\"</p><p><a href=\"https://xie.infoq.cn/article/7404283d515ca3de1bedd14fc\">NPM&nbsp;实用命令与快捷方式</a>\"</p><p><a href=\"https://xie.infoq.cn/article/a64989cdc2b9cdee73fea23bb\">前端包管理工具&nbsp;npm&nbsp;yarn cnpm npx</a>\"</p><p><a href=\"https://www.infoq.cn/article/DvD8AkqdMqvuQpAw1heP\">Npm,Inc. 发布&nbsp;Npm&nbsp;Pro，面向独立 JavaScript 开发人员</a>\"</p><p></p><p>&nbsp;</p>",
    "publish_time": "2023-07-24 11:16:58",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "使用AI工作后觉得自己像“小白鼠”：工资不变，工作量超级加倍",
    "url": "https://www.infoq.cn/article/gsO6fD0RwvshDSydW8lw",
    "summary": "<p>我们已经在无数报道中听到这样的言论：新一代AI工具有望简化日常任务、提高工作效率并整体拉升办公场所内的生产力水平。但现在的实际情况似乎不像宣传的那样，甚至还给员工带来了更多的工作量。</p><p></p><h2>AI 完成一部分工作，那剩下的呢？</h2><p></p><p>&nbsp;</p><p>Clarke是一名编辑兼发行人，他表示在自己的团队被一大波“糟糕透顶”的AI生成投稿淹没之后，自己被迫暂时关闭了科幻/奇幻杂志《克拉克世界》的在线投稿通道。</p><p>&nbsp;</p><p>Clarke在回忆起这段“惨痛”经历时，表示他的团队现在只能亲自动手，逐条筛选哪些稿件是由AI生成。“实际上，这是我们见过的最差劲的故事。但AI投稿的数量实在太大了，甚至不考虑质量的问题的话，光是数量就足够把我们吞没。”</p><p>&nbsp;</p><p>“它反而让我们的工作量几乎加倍。”他坦言，最新的AI工具已经成了他们过去几个月来“最想拔掉的眼中钉。”Clarke估计，用不了多久他的编辑团队肯定又得再次关闭投稿通道，“情况终将发展到我们无法应对的地步。”</p><p>&nbsp;</p><p>也许AI的种种利弊在媒体行业中体现得最为明显。这些工具虽能显著推动方案编写、广告设计和某些编辑工作的自动化，但在此期间却也总会犯下各种错误。</p><p>&nbsp;</p><p>新闻媒体CNET在今年早些时候，就曾尝试使用AI工具撰写故事。但其随后被迫发布“实质性”更正，给自己的发布内容打补丁。本月早些时候，美国知名科技博客Gizmodo发表一篇由AI撰写的简单《星球大战》故事，但其中同样存在不少错误并引发员工抗议。不过两家媒体态度坚定，表示仍将继续使用AI技术协助编辑部门。</p><p>&nbsp;</p><p>而像Clarke这样的发行人，则希望借助AI自身来应对AI崛起带来的影响。Clarke表示，他的编辑团队正尝试使用生成式AI检测器来快速处理大量投稿内容，但却发现这些工具没啥实际作用。它们“误报和漏报”的可能性极高，而且在处理母语非英语的作者投稿时情况更加糟糕。</p><p>&nbsp;</p><p>在最近一项研究中，麻省理工学院的研究人员发现，使用ChatGPT确实能提高负责撰写申请信、答谢类电子邮件和成本效益分析等工作的执行效率。论文合著者、麻省理工经济系博士生Shakked&nbsp;Noy在声明中表示，“从我们的研究结果来看，这项技术在白领工作中确实有着重要的应用前景，其现实意义客观存在。但现在要判断它是好是坏、究竟会导致社会结构发生哪些变化，明显还为时过早。”</p><p>&nbsp;</p><p></p><h2>有些员工觉得自己就像“小白鼠”</h2><p></p><p>&nbsp;</p><p>微软联合创始人比尔·盖茨最近在一篇博文中表示，“未来几年间，AI对工作的主要影响就是帮助人们更高效地完成工作。”但科技领域向来以快步探索、迅速失败而著称，相关成果在不同行业和市场上的长期影响也总是不尽相同。</p><p>&nbsp;</p><p>另外，通往技术乌托邦的道路往往崎岖不平，经常带来意想不到的后果。就以生成式AI为例，前有律师因提交ChatGPT虚构的判例资料而被罚款，后有出版社因大量计算机生成投稿而几近崩溃。</p><p>&nbsp;</p><p>但科技巨头们倒是无所畏惧，正急于赶上AI掀起的这波浪潮。他们承诺对各类新型AI驱动工具进行大量投资，号称新成果将有望简化日常工作。例如，这些工具能帮助人们快速起草电子邮件、制作演示文稿并总结大规模数据集或文本库中的内容。</p><p>&nbsp;</p><p>国际机械师与航空航天工人协会研究主任伊万娜·绍拉 (Ivana Saula)表示，随着雇主急于在工作场景下推出AI工具，该协会的不少工人都觉得自己就像是“小白鼠”。</p><p>&nbsp;</p><p>Saula 强调，新技术的部署往往并非一帆风顺。随着新工具的普及，人类员工往往是“给比以往更多的任务做收尾”，其中包括处理机器根本解决不了的额外配送任务，因此AI的引用反而给员工们的日常流程增加了更多负担和压力。</p><p>&nbsp;</p><p>Saula 所在的机械师协会，代表着来自航空运输、医疗保健、公共服务、制造业和核工业等多个领域的众多工人的切身利益。她在采访中强调，“用机器完全取代人类，从来就不是简简单单能做到的事情。它只能取代人类员工的某些工作环节，但其余做不了的部分仍然要由人类负责。”</p><p>&nbsp;</p><p>Saula还解释道，在采用新的AI工具之后，工人们感觉“自己的工作负担更重了”，“工作节奏也更快了，因为现在得跟着机器的脚步走。”根据她从工人那边得到的反馈来看，“让工人真正参与AI实施”才是决定技术成败的关键因素。</p><p>&nbsp;</p><p>“因为雇主们必须了解生产前沿的情况。而根据观察，我发现一线工作与车间里的实际情况，往往跟高管人员的思维之间存在严重脱节。更不用说CEO了，他们往往连活是怎么干成的都不清楚。”Saula 表示。</p><p>&nbsp;</p><p>就像Clarke总结的，“听听那帮AI专家在说什么，他们总能带来这项技术在不同领域取得惊人突破的案例。是真是假我不好说，但AI在目前的实际应用中真的还差很远。”</p><p>&nbsp;</p><p>经济合作与发展组织秘书长马蒂亚斯·科尔曼（Mathias Cormann）最近表示，经合组织发现AI确实能在某些方面改善工作质量，但同时也带来了新的权衡与取舍。</p><p>&nbsp;</p><p>Cormann在公开讲话中指出，“但员工们的确表示，在将AI技术引入工作场所之后，他们的工作强度反而有所增加。”经合组织发布的一份报告也提到，对于非AI专家和非管理人士来说，AI应用“截至目前对工资的影响还很小”。也就是说，AI的普及在扩大普通员工的工作量之余，并没有同步改善他们的薪酬待遇。</p><p>&nbsp;</p><p></p><h2>人工智能是新的“生产力悖论”吗？</h2><p></p><p>&nbsp;</p><p>追踪技术对经济影响的一个关键指标是工人生产力的增长。这个看似枯燥的统计数据对每个工人都很重要，因为它直接关系到工人每小时工作的预期收入。换句话说，更高的生产率预计会带来更高的工资。</p><p>&nbsp;</p><p>经济学家看到了提高整个劳动力生产率的巨大潜力。高盛预测，仅由于生成式AI的采用，生产力每年会增长 1.5%，这将是<a href=\"https://www.bls.gov/opub/mlr/2021/article/the-us-productivity-slowdown-the-economy-wide-and-industry-level-analysis.htm#:%7E:text=In%20the%20years%20since%202005,percent%20from%202010%20to%202018\">2010 年和 2018 年的近两倍</a>\"。麦肯锡则更加激进，称这项技术和其他形式的自动化将迎来“<a href=\"https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier#introduction\">下一个生产力前沿</a>\"”，到 2040 年将其每年提高至 3.3%。</p><p>&nbsp;</p><p>根据《财富》发表的文章称，<a href=\"https://www.imf.org/external/pubs/ft/fandd/2016/06/gordon.htm#:%7E:text=Measures%20and%20mismeasures%20of%20progress&amp;text=The%20growth%20rate%20of%20labor,extends%20from%201970%20to%202014.\">从1920年到1970年，美国生产率以每年约3%</a>\"的速度飞速增长，提高了实际工资和生活水平。但有趣的是，生产力增长在 20 世纪 70 年代和 1980 年代放缓，这个时间恰好是计算机和早期数字技术引入的时间。该现象也被称之为“<a href=\"https://cs.stanford.edu/people/eroberts/cs181/projects/productivity-paradox/index.html\">生产力悖论”</a>\"。</p><p>&nbsp;</p><p>“是人工智能还是人类更有生产力”的答案是复杂的，人工智能和人类都有独特的优势和局限性。人工智能擅长重复的、数据驱动的任务，而人类更擅长创造性地解决问题和复杂的决策。例如，人工智能可以用于自动化重复的任务和数据分析类工作，使人类能够专注于更复杂和更具创造性的工作。但人工智能也只能在其编程范围内运行，不能像人类那样作出创造性的决定或跳出框框思考。</p><p>&nbsp;</p><p>《财富》的文章指出，考虑到经济学家和其他专家过去犯下的错误，可以肯定地说，今天关于人工智能技术对工作和工人生产力影响的许多预测也将被证明是错误的。诸如“3 亿个就业岗位受到影响”或“每年为全球经济带来 4.4 万亿美元的增长”等数字引人注目，但人们往往对这些数字的信任度过高。</p><p>&nbsp;</p><p>如何利用人工智能和人类智能的优势，创建一个更高效和有效的劳动力，同时解决围绕AI的潜在限制和伦理担忧，还有很长的路要走。</p><p>&nbsp;</p><p>参考链接：</p><p>&nbsp;</p><p><a href=\"https://edition.cnn.com/2023/07/22/tech/ai-jobs-efficiency-productivity/index.html\">https://edition.cnn.com/2023/07/22/tech/ai-jobs-efficiency-productivity/index.html</a>\"</p><p><a href=\"https://www.linkedin.com/pulse/ai-vs-humans-whos-more-productive-sakib-saadat/\">https://www.linkedin.com/pulse/ai-vs-humans-whos-more-productive-sakib-saadat/</a>\"</p><p><a href=\"https://fortune.com/2023/06/25/ai-effect-jobs-remote-work-productivity-paradox-computers-iphone-chatgpt/\">https://fortune.com/2023/06/25/ai-effect-jobs-remote-work-productivity-paradox-computers-iphone-chatgpt/</a>\"</p>",
    "publish_time": "2023-07-24 14:15:58",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "微信取消秋招；谷歌软件工程师基本年薪超500万；通报批评员工到点下班？比亚迪回应｜Q资讯",
    "url": "https://www.infoq.cn/article/kSU4cDJ37SlTu6p6x5Nv",
    "summary": "<p></p><blockquote>看看本周都有哪些大事发生吧！</blockquote><p></p><p></p><p></p><h2>科技公司</h2><p></p><p></p><h4>研究称 ChatGPT 性能下降，OpenAI 否认</h4><p></p><p>&nbsp;</p><p>本周二斯坦福大学和加州伯克利的研究人员在预印本网站 arXiv 上发表论文《How Is ChatGPT’s Behavior Changing over Time?》，对 OpenAI 大模型 GPT-3.5 和 GPT-4 的性能一致性提出质疑。这项研究再次引发了有关 OpenAI 是否为节省费用而调整模型的议论。</p><p>&nbsp;</p><p>OpenAI 一直否认这一说法，公司产品副总裁 Peter Welinder 称他们没有让 GPT-4 变笨，用户认为 GPT-4 变笨可能是也因为使用越频繁就会遇到愈来愈多以前没有遇到的问题。专家也对最新这项研究提出质疑，认为研究方法可能存在问题。</p><p>&nbsp;</p><p></p><h4>世界头号黑客凯文去世，曾造成最大的损失达4亿美元</h4><p></p><p>&nbsp;</p><p>在业界被认为是“世界头号黑客”的凯文・米特尼克（Kevin David Mitnick）确认于 2023 年 7 月 16 日去世，享年 59 岁。他 16 岁因进行社交工程破解太平洋电信公司的密码，在付费电话系统中修改上万美国家庭的电话号码，而被电脑信息跟踪机跟踪逮捕，因此成为了全球第一名网络少年犯。出狱后，他又成功入侵了诺基亚、摩托罗拉、升阳以及富士通等公司计算机，盗取企业重要资料，FBI 曾统计他给这些公司带来的损失高达 4 亿美元。</p><p>&nbsp;</p><p></p><h4>React 核心开发者 Dan Abramov 官宣从 Meta 离职</h4><p></p><p>&nbsp;</p><p>7 月 20 日，Meta 工程师、React 项目核心人员、Redux 原作者 Dan Abramov 在 Twitter 上连发 15 条推文，以“我感到苦乐参半，几周后我就要辞去 Meta 的工作了”为开场白，官宣了自己即将从这座围城中离开的消息。</p><p>&nbsp;</p><p>Dan 表示，如今有关 React 的新文档网站已上线，现在任何开发者可以开始使用 Suspense 在 Relay、Next.js、Hydrogen 或 Remix 等框架中获取数据。同时，如今的&nbsp;React 已经成为一个多公司项目，团队中也有几位独立工程师可以挑大梁了。接下来，Dan Abramov 将作为独立工程师留在 React 团队，这意味着他不会得到任何公司的全职赞助，继续参与团队的工作与相关会议。</p><p>&nbsp;</p><p></p><h4>唯品会 1.2 亿租楼，300 元每月租给员工</h4><p></p><p>&nbsp;</p><p>7月19日，一条“公司1.2亿租楼300元每月租给员工住”的消息登上热搜。近日，一家公司多名员工在微信朋友圈、抖音、小红书等平台上“晒房”，分享自己300元/月在广州市中心租到的一室一厅，房间厨卫衣柜家电齐全，可拎包入住，公共区域还有图书馆、健身房等生活设施，引发众多网友关注。</p><p>&nbsp;</p><p>据悉，该公司是位于广州的特卖电商唯品会，投资 1.2 亿元在市中心核心地段改造 672 套公寓并交付给员工入住，租金仅为市场价的1折。这处员工公寓名为“唯家公寓”，总计建筑面积约 3 万平方米，地处广州大道南，距离海珠万达广场直线距离 200 米。</p><p></p><h4>微信取消秋招，微信团队今年全实习不秋招</h4><p></p><p>&nbsp;</p><p>日前，据腾讯招聘官网，腾讯微信事业群 2023 实习生招聘补录中，但今年微信团队全实习不秋招。而据此前的消息，今年，只有在微信团队实习满 2 个月的同学，才有参加正式校招的资格。这意味着，2024 届留学生只有参加实习才有进微信团队的机会。</p><p>&nbsp;</p><p>微信团队在其实习招聘公告中表示，这样变化的初衷是希望同学们通过至少 2 个月的实习和团队更加深入了解，考核后再最终入职。</p><p>&nbsp;</p><p></p><h4>字节回应员工“死亡威胁”女性事件：已劝退</h4><p></p><p>&nbsp;</p><p>有网友爆料称：自己近期受到字节员工陈某的“死亡威胁”，诱因是该网友拒绝了陈Y哲的朋友、某已婚男老板进一步的性骚扰。该女生表示，“2022年11月15号，已婚前男老板在离职时的聚会趁我喝醉亲了我的脸，还企图带走我。”半年后，这位前男老板又发消息单独约她，该女生直接把他拉黑。</p><p>&nbsp;</p><p>随后，该女生又遭到字节员工陈Y哲的无端辱骂。据悉，陈Y哲疑为前小红书高管陈延哲。该事件或发生在两人在小红书工作期间，后该涉事男子加入字节跳动。针对此事件，抖音生活服务相关负责人表示：经调查，该员工于今年6月5日入职，7月12日晚因过往纠纷参与辱骂他人，并造成了不良影响，公司已劝退该员工，与其解除劳动合同。</p><p>&nbsp;</p><p></p><h4>网传比亚迪通报批评员工到点下班，官方予以否认</h4><p></p><p>&nbsp;</p><p>近期网上流传出一张比亚迪考勤数据图片，图中统计了“经常一到点就下班的人数”，统计范围为各部门 F-D 级员工，涵盖比亚迪下属的大量单位，并包括王朝网、海洋网、腾势、仰望、方程豹各大车系或子品牌。7月19日，比亚迪回应称，上述内容是“假的”，且“相关内容已在处理中”。&nbsp;</p><p>&nbsp;</p><p>此外，网上另有一张名为“违纪榜”的截图传播，图片显示比亚迪对国内不同区域各部门员工存在的“与工作无关的行为”进行批评公示，包括不限于看小说、刷手机、看新闻等。</p><p>&nbsp;</p><p></p><h4>美团入股中文大模型公司智谱AI</h4><p></p><p>&nbsp;</p><p>天眼查 App 显示，近日，中文认知大模型平台智谱 AI 关联公司北京智谱华章科技有限公司发生工商变更，股东新增美团旗下天津三快科技有限公司，注册资本由约 1480.69 万人民币增至约 1652.86 万人民币。北京智谱华章科技有限公司成立于 2019 年 6 月，法定代表人为刘德兵，经营范围含技术服务、人工智能基础软件开发、数据处理和存储支持服务、科技中介服务等。</p><p>&nbsp;</p><p></p><h4>谷歌员工薪资遭泄露，软件工程师基本年薪超70万美元</h4><p></p><p>&nbsp;</p><p>据一份泄露的内部数据显示，2022 年谷歌员工的总薪酬中位数为 279802 美元，其中软件工程师拿到了高达 71.8 万美元（当前约 519.1 万元人民币）的基本工资，成为该公司薪资的最高职位。除了基本工资，谷歌员工的收入还包括期权和奖金。数据显示，软件工程师在 2022 年能够获得最高 150 万美元的股权。谷歌的前十大最高薪职位中，无论是工程、商业还是销售，最低的基本工资也达到了 30 万美元。</p><p>&nbsp;</p><p>与其他科技巨头相比，2022 年谷歌员工的中位数基本工资落后于 Meta（29.6 万美元），但远高于 Salesforce（19.9 万美元）和 Adobe（17 万美元）。</p><p>&nbsp;</p><p></p><h2>IT 业界</h2><p></p><p></p><h4>Meta AI 模型“两连发”</h4><p></p><p>&nbsp;</p><p>Meta 终于发布了大家期待已久的免费可商用版本 Llama 2。Llama 2 包含了 70 亿、130 亿和 700 亿参数的三个版本模型，其微调模型接受了超过 100 万个人类注释训练，上下文长度限制也翻了一倍。Meta 与微软 Azure 合作，向全球开发者首发基于 Llama 2 模型的云服务；Llama 2 将能够在高通芯片上运行，打破了市场上英伟达、AMD 处理器对 AI 产业的垄断。</p><p>&nbsp;</p><p>Meta 还宣布开发出一款名为 CM3Leon 的 AI 模型，该模型可以根据文本生成高质量的图像，也能为图像生成文本描述。Meta 称这款模型在文本到图像生成方面达到了业界最高水平，超过了谷歌、微软等。</p><p>&nbsp;</p><p></p><h4>苹果正在内部测试类 ChatGPT 产品 Apple GPT</h4><p></p><p>&nbsp;</p><p>外媒消息，苹果正在内部开发类 ChatGPT 的产品，与微软、OpenAI、谷歌、Meta 等科技巨头在生成式 AI 赛道展开竞争。该消息使得苹果股价上涨了 2%。据苹果工程师透露，苹果在内部构建了代号为“Ajax”的大语言模型开发框架，并构建了一款生成式 AI 聊天机器人 “Apple GPT”。</p><p>&nbsp;</p><p>据悉，Ajax 在 Google Cloud 上运行，由谷歌的机器学习框架 Google JAX 构建而成。由于担忧安全的原因，Apple GPT 在内部暂停了一段时间，现在只向少数苹果员工提供服务。</p><p>&nbsp;</p><p></p><h4>微信将推出“公务员专供版”？腾讯：这玩笑开大了</h4><p></p><p>&nbsp;</p><p>近日，有传言称，微信撤回消息的时间将延长至 2 小时，引起舆论关注。传闻中提到，微信将推出“公务员专供版”，打破微信以往的撤回时限，由原本的 2 分钟延长至 2 小时，且部分领导的撤回时间可延长至 2 天。</p><p>&nbsp;</p><p>7 月 18 日，腾讯公关总监张军在朋友圈否认了这则传闻的真实性，并表示：“这玩笑开大了。”</p><p>&nbsp;</p><p></p><h4>63年来首次全面停摆，好莱坞大罢工抵制 AI 入侵</h4><p></p><p>&nbsp;</p><p>当地时间7月13日，代表16万演艺人员的美国演员工会及广播电视艺人联合工会（SAG-AFTRA）宣布，他们与制片公司的谈判破裂，确定从即日起进行罢工。此前，美国编剧工会（WGA）已在5月2日开始罢工。</p><p>&nbsp;</p><p>本次大罢工，原因除了演员、编剧与资方的薪资矛盾外，人工智能（AI）可能取代演员和编剧的威胁成为主要原因。因此，这不仅是好莱坞63年来首次全行业罢工，也被认为是人类抵抗人工智能威胁的首次集体行动。SAG-AFTRA 主席法兰·德瑞雪13日在新闻发布会上表示：“如果现在不昂首挺胸，我们就会陷入困境，都将面临被机器取代的危险。”</p><p>&nbsp;</p><p>1000字：</p><p>&nbsp;</p><p>本周，Meta、苹果继续发力大模型，互联网企业员工展现部分现状……</p><p>&nbsp;</p><p>研究称 ChatGPT 性能下降，OpenAI 否认</p><p>世界头号黑客凯文去世，曾造成最大的损失达4亿美元</p><p>React 核心开发者 Dan Abramov 官宣从 Meta 离职</p><p>唯品会 1.2 亿租楼，300 元每月租给员工</p><p>微信取消秋招，微信团队今年全实习不秋招</p><p>字节回应员工“死亡威胁”女性事件：已劝退</p><p>网传比亚迪通报批评员工到点下班，官方予以否认</p><p>美团入股中文大模型公司智谱AI</p><p>谷歌员工薪资遭泄露，软件工程师基本年薪超70万美元</p><p>Meta AI 模型“两连发”</p><p>苹果正在内部测试类 ChatGPT 产品 Apple GPT</p><p>微信将推出“公务员专供版”？腾讯：这玩笑开大了</p><p>63年来首次全面停摆，好莱坞大罢工抵制 AI 入侵</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>推荐文章：</p><p>&nbsp;</p><p>马斯克等人热捧：高薪缺人，但要懂全栈懂LLM，一个全新职业正在兴起！</p><p>微软赢麻了！联合Meta 重磅发布开源、可直接商用大模型Llama 2，网友：OpenAI 感觉如何？</p>",
    "publish_time": "2023-07-24 14:20:29",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "国内航空巨头如何从 NGINX 迁移至 APISIX？",
    "url": "https://www.infoq.cn/article/HVLkNv8FAjSjG2ob53XH",
    "summary": "<p></p><p>作者 | 卞弘智</p><p></p><p></p><blockquote>本文主要介绍了航空公司互联网能力持续提升的大背景下，国内某大型航空公司移动互联网基础架构团队针对南北向网关从 NGINX 升级到 APISIX 的历程。</blockquote><p></p><p></p><p></p><h4>深入解析 NGINX 网关的痛点</h4><p></p><p></p><p>我们一直使用 NGINX 作为南北向网关。随着业务规模的发展和产品的增加，从流量的角度来说，NGINX 仍然能很好地满足我们的需求，然而，在其他方面我们遇到了越来越多的痛点：</p><p></p><p>多节点配置管理：我们管理着多台 NGINX 和多套不同的域名，NGINX 的核心是其配置文件。随着 NGINX 数量的增加，单纯依靠 scp 复制文件的方式来管理 NGINX 配置文件已经变得越来越困难，尤其是在后端大量使用微服务、容器化部署后，对反向代理配置灵活度要求更高，配置一致性工作量也越来越大。NGINX 及其插件的升级：由于历史原因，我们同时在使用多个版本的 NGINX ，同时还使用了很多 NGINX 的插件。每次需要升级时，NGINX 自身的升级并不困难，难点在于各种插件的升级、编译和适配，因为很多是非官方插件，编译时遇到各种问题排查起来非常困难，并且与 NGINX 版本的适配也得不到保障。NGINX 配置的标准化：由于我们接手来自不同团队的系统，各自使用的 NGINX 配置习惯不尽相同，缺乏统一的配置标准。现代网关功能不足：虽然 NGINX 很好地满足了我们对南北向网关的基本需求，如反向代理和负载均衡等，但随着业务发展，我们对南北向网关提出了更多的需求，例如服务熔断、安全防控、灰度发布等，单纯依赖 NGINX 实现这些功能并不容易。</p><p></p><h4>剖析网关选型，精准匹配业务需求</h4><p></p><p></p><p>针对 NGINX 所遇到的各种痛点，我们认真梳理了对新网关产品的三个主要基本需求：</p><p></p><p>易于管理和配置：我们需要在多个网关节点的场景下，方便而统一地管理和发布路由、上游服务等各种配置。满足现代 API 网关基础需求：新网关必须能实现现代 API 网关的业务需求，如服务熔断、安全防控、灰度发布等。易用性和上手门槛：鉴于我们团队成员人数有限，并且中间件领域没有专职的开发和运维人员，我们希望新网关产品能通过配置和低代码的方式，让我们轻松完成大部分基本需求。</p><p></p><p>在明确了对现有南北向网关的迭代升级和基本需求之后，我们对市面上流行的多款产品进行了调研，并最终选择了 APISIX 作为我们的新网关。</p><p></p><p>OpenResty: 在调研过程中，我们首先考虑了 OpenResty，它被很多大厂，例如 Bilibili，广泛采用作为网关。对于我们来说，OpenResty 最大的优点是其配置文件与 NGINX 完全兼容。由于我们有大量复杂的域名配置，而且有些配置相当复杂，部分网关从 NGINX 升级到 OpenResty 时，能实现无缝衔接，只需复制配置文件即可使用。然而，相较于我们后面调研的 Kong 和 APISIX，OpenResty 的开源版本默认自带的插件不够完善，也没有可视化的配置界面，我们需要自己进行 Lua 开发来满足部分基本功能。Kong：其次，我们对 Kong 进行了初步的调研。Kong 的默认自带插件可以满足我们大部分需求。但是，它的开源版本的可视化界面，即 Dashboard，基本几年内没有更新。尤其是在了解了 APISIX 后，我们更希望能够拥有一个可视化界面，以简化配置过程。Envoy：我们还留意到了 Envoy，尤其在网易和阿里相继发布基于 Envoy 的下一代网关之后。Envoy 基于 C++，对于我们这样规模的团队来说还存在较高的门槛，因此我们最终没有选择它。</p><p></p><p>最终，我们决定采用 APISIX 作为新的网关产品，因为它在功能和性能上均得到了市场的认可。根据测试结果，APISIX 在压力测试下的性能表现相当出色，在没有开启插件的情况下，其性能是 Kong 的 2 倍；而在开启限流和 prometheus 插件后，性能甚至高出 Kong 的 10 倍，延迟仅为 Kong 的十分之一。此外，APISIX 基于 OpenResty 实现，拥有出色的路由功能，进一步增加了我们的信心。另外，与 Kong 相比，APISIX 吸引我们的特点主要集中在以下两个方面：</p><p></p><p>APISIX Dashboard：基于 Dashboard，我们能更便捷地管理各种路由和插件的配置。特别值得一提的是，APISIX Dashboard 本身就是开源项目的一部分，我们相信未来会随着 APISIX 的发展而持续更新，为我们提供更好的管理体验。Apache 开源项目：APISIX 作为 Apache 软件基金会的顶级项目，相较于 Kong，我们更容易在网络上搜索到相关的技术文档。在遇到各种问题时，我们能够得到 Apache 社区的支持，与其他开发者共同解决疑难问题，为我们的项目提供更加可靠的技术支持。</p><p></p><p>在前面提到的关于 NGINX 的痛点，也能够通过 APISIX 很好地解决：</p><p></p><p>多节点配置管理：APISIX 将配置存储于 etcd 中，因此我们只需要部署一套 etcd 集群即可方便地管理多个不同域名的多个 APISIX 节点。NGINX 及其插件的升级：APISIX 内置了常用的健康检查等插件，与 NGINX 中常用的插件相同，这使得我们无需再考虑升级和兼容性等问题。现代网关的功能：APISIX 自带多种安全性和流量控制插件，轻松实现服务熔断、安全防控、灰度发布等功能。总体来说， APISIX 是对我们团队现阶段最适合的产品。</p><p></p><p></p><h4>NGINX 迁移 APISIX：探索先进解决方案</h4><p></p><p></p><p>在 NGINX 中所有的域名管理以及其上的功能实现都是基于 NGINX 的配置文件来实现的。虽然 APISIX 仍然基于 NGINX 和 Openresty，但在 APISIX 中，我们采用了完全不同的方式，不再使用 NGINX 的配置文件来管理域名和实现功能。我们首先根据域名配置路由（route）和其上游（upstream），然后通过插件的形式实现路由上的各种附加功能。</p><p></p><p>从 NGINX 向 APISIX 的迁移的主要工作是将 NGINX 的各路由以及相关配置用 APISIX 的相关插件进行重构。实际迁移过程远比前面一句话更复杂，我们将这个迁移过程拆分为以下三个主要步骤：</p><p></p><p>提取独立功能配置：首先从 NGINX 配置中提取出一个独立的功能配置，并深入理解其配置的含义。网络协议层面理解配置：其次，需要从网络协议层面理解相关配置，并借助各种网络工具进行验证测试。寻找合适的插件实现功能：最后，在 APISIX 中找到适合的插件来实现与 NGINX 配置相同的功能，并再次通过各种网络工具进行验证测试，以确保 NGINX 和 APISIX 能够实现相同的效果。</p><p></p><p>这里我们以一个 CORS 跨域相关的配置来进行举例，我们先把 NGINX 中跨域相关配置提取出来。</p><p></p><p><code lang=\"nginx\">\n    add_header 'Access-Control-Allow-Origin' $corsHost;\n    add_header 'Access-Control-Allow-Methods' 'GET,POST,OPTIONS';\n    add_header 'Access-Control-Allow-Credentials' 'true';\n    add_header 'Access-Control-Allow-Headers' 'DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Accept,Authorization,appver';\n    if ($request_method = 'OPTIONS') {\n            return 204;\n     }\n</code></p><p></p><p>首先理解这段 NGINX 的含义，用 add_header 在 NGINX response 中添加了一些关于跨域配置 header，然后如果 request 方法为 OPTIONS 的话就直接返回 204。在赋值的时候，这里我们还使用了一个变量 corsHost，其定义如下：</p><p></p><p><code lang=\"php\">    map $http_origin $corsHost {\n        default 0;\n        \"~http://wap.test.com\" http://wap.test.com;\n        \"~https://wap.test.com\" https://wap.test.com;\n    }\n</code></p><p></p><p>再从网络层面去理解下这段 NGINX 配置的含义，这一段配置其实是为了实现 CORS 跨域访问， 允许来自于 Access-Control-Allow-Origin 源的请求能够进行跨域访问，请求的方法由 Access-Control-Allow-Methods 定义，同时定义了允许的 Header 和请求可以包含 Cookie 等 credentials 信息。Options 返回 204 是 CORS 的预检要求的。更详细的信息可以在 mozilla 的网站上查看相关定义：<a href=\"https://developer.mozilla.org/%E3%80%82\">https://developer.mozilla.org/。</a>\"</p><p></p><p>要将这段 NGINX 的配置，在 APISIX 中进行实现，我们并不需要一行行的进行配置转换，而是可以基于 APISIX 的 cors 插件进行实现：</p><p></p><p><code lang=\"javascript\">    \"cors\": {\n      \"allow_credential\": true,\n      \"allow_headers\": \"DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Accept,Authorization,appver\",\n      \"allow_methods\": \"GET,POST,PUT,OPTIONS\",\n      \"allow_origins\": \"https://wap.test.com,http://wap.test.com,\",\n    },\n</code></p><p></p><p>针对 OPTIONS 请求返回 204 这部分配置，我们使用了 response-rewrite 插件来实现：</p><p></p><p><code lang=\"cs\">\"response-rewrite\": {\n    \"status_code\": 204,\n    \"vars\": [\n        [ \"request_method\",\n            \"==\",\n            \"OPTIONS\"\n]\n    ]\n}\n</code></p><p></p><p>在 APISIX 中使用 cors 插件和 response-rewrite 插件实现了这段配置之后， 我们可以使用浏览器自带的网络工具进行迁移后的测试验证：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/76/7611a7d7fa6eacd3d97a9b3a6eb7fe32.png\" /></p><p></p><p>从截图可以看到，针对 Options 返回 204，在响应 Header 中也配置好了 Access-Control-Allow-Origin 等要求的值。</p><p></p><p></p><h4>APISIX 和 NGINX 配置对比</h4><p></p><p></p><p>这里我们直接对比下 NGINX 和 APISIX 的配置代码：</p><p></p><p><code lang=\"nginx\">#   NGINX  conf\n    add_header 'Access-Control-Allow-Origin' $corsHost;\n    add_header 'Access-Control-Allow-Methods' 'GET,POST,OPTIONS';\n    add_header 'Access-Control-Allow-Credentials' 'true';\n    add_header 'Access-Control-Allow-Headers' 'DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Accept,Authorization,appver';\n    if ($request_method = 'OPTIONS') {\n            return 204;\n     }\n</code></p><p></p><p><code lang=\"cs\">#  APISIX  plugins config\n    \"cors\": {\n      \"allow_credential\": true,\n      \"allow_headers\": \"DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Accept,Authorization,appver\",\n      \"allow_methods\": \"GET,POST,PUT,OPTIONS\",\n      \"allow_origins\": \"https://wap.test.com,http://wap.test.com,\",\n    },\n    \"response-rewrite\": {\n      \"status_code\": 204,\n      \"vars\": [\n        [\n          \"request_method\",\n          \"==\",\n          \"OPTIONS\"\n]\n      ]\n    }\n</code></p><p></p><p>NGINX 的配置看起来更加简洁，但对于不熟悉 NGINX 和跨域的人来说，理解其背后的含义可能并不容易。相比之下，APISIX 对不同的业务功能进行了插件封装，使得配置更加模块化，基本上一眼就可以看出其实现的业务功能和背后的含义。</p><p></p><p>类似的 NGINX 的配置向 APISIX 进行迁移的代码案例我们还有很多，例如在 NGINX 中 websocket 协议需要进行如下配置：</p><p></p><p><code lang=\"nginx\">proxy_set_header Upgrade $http_upgrade;\nproxy_set_header Connection \"\"Upgrade\"\";\nproxy_http_version 1.1;\n</code></p><p></p><p>而在 APISIX 就进行了封装，非常简单明了：</p><p></p><p><code lang=\"javascript\">  \"enable_websocket\": true,\n</code></p><p></p><p></p><h4>成功迁移后的回顾与展望</h4><p></p><p></p><p>自从我们在 2023 年 4 月份首次接触 APISIX，到 7 月份在生产环境成功完成了从 NGINX 到 APISIX 的升级，整个迁移过程取得了令人满意的成果。在迁移初期，由于接手的生产 NGINX 存在各种历史遗留配置，有些甚至不清楚其真正意义，我们曾对 APISIX 的插件能否完全实现我们现有 NGINX 的所有功能感到担心。但最终的结果表明，APISIX 的插件完全胜任这一挑战。</p><p></p><p>NGINX 向 APISIX 迁移的核心是重新在 APISIX 中实现 NGINX 配置文件，这并不是一行 APISIX 配置对应一行 NGINX 的配置转换。我们需要深入理解相关 NGINX 配置模块背后的含义。在 APISIX 中，往往可以通过插件实现更加优雅的解决方案，例如跨域支持（cors）、WebSocket 等。</p><p></p><p>在整个升级过程中，我们发现在原有的 NGINX 中存在不少上古配置，其中很多地方甚至是毫无意义的复制粘贴配置。这次升级的过程也是对我们整个南北向网关的一次全面梳理，特别是基于 APISIX 的 plugin_config 等功能，我们在网关配置层面更容易实现模块化的管理和复用。</p><p></p><p>总体来说，APISIX 完美地解决了我们之前在 NGINX 中遇到的各种痛点，其丰富的插件使我们能够轻松应对客户端提出的各种新需求。在迁移过程中，社区小伙伴的大力帮助也为我们解决了一些故障，对此我们表示衷心的感谢。</p><p></p><p>作者简</p><p></p><p>卞弘智：国内某大型航空公司研发工程师，拥有超过十年的 SRE 经验，工作经历涵盖 DevOps、监控和告警系统、日志处理系统、WAF 和网关等系统基础架构领域，致力于通过优秀的开源软件推动自动化和智能化基础架构平台的演进。</p><p></p><p>好文推荐</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651175917&amp;idx=1&amp;sn=8f8999901f79dc2767d76a241481e755&amp;chksm=bdb843be8acfcaa8cd09fda48fd14edb825752589af5a6876a4a1d943da721709016b3c18afd&amp;scene=21#wechat_redirect\">终于找到 ChatGPT “智商”下降的原因了！OpenAI 侧面回应，GPT 可能真被你们玩坏了？</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651175916&amp;idx=1&amp;sn=f39c16446d17094831bf6ca5c8347b70&amp;chksm=bdb843bf8acfcaa96449283e5424283f366b4c0c56e33c9374716c0df6955eadbd9eeed525ea&amp;scene=21#wechat_redirect\">微信取消秋招；谷歌软件工程师基本年薪超 500 万；通报批评员工到点下班？比亚迪回应 | Q资讯</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651175820&amp;idx=1&amp;sn=c69663d4c99bdfaf5b0f44f548376a8e&amp;chksm=bdb843df8acfcac952cc2f40f51bc0d624df81ff90f59d97c7bc57ab8a5899368203a72d0f87&amp;scene=21#wechat_redirect\">十年磨砺，持续闯入“无人区”，这家公司如何做好金融科技？</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651175753&amp;idx=1&amp;sn=a827e7385beacaa6c253dd6511d46e1c&amp;chksm=bdb8431a8acfca0c2e53b02084ac61526d17164cfc08e46536226cd31447a4e51b2b351ad7fb&amp;scene=21#wechat_redirect\">马斯克等人热捧：高薪缺人，但要懂全栈懂LLM，一个全新职业正在兴起！</a>\"</p><p></p><p></p>",
    "publish_time": "2023-07-24 14:25:38",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "腾讯会议开放战略新进展：“不做硬件”依然是主要策略之一",
    "url": "https://www.infoq.cn/article/1zi3OFCBN2EXrXNtWkhZ",
    "summary": "<p>7月19日， 北京InfoComm China 2023展会现场，腾讯会议首发轻量化混合式教学解决方案和4K共享屏幕，并且与MAXHUB、亿联网络等多家硬件厂商联合推出新的场景方案和产品能力。</p><p>&nbsp;</p><p>腾讯会议宣布，生态合作伙伴数量达到200家，腾讯会议认证的硬件厂商超过30家，覆盖产品型号超过120款。</p><p>&nbsp;</p><p>据了解，北京InfoComm China展是亚太地区首屈一指的专业视听盛会，聚焦专业视听解决方案及集成体验技术，引领着视听行业发展的风向标。InfoComm China于2007年首次展出，是国内每年最备受行业期待的年度技术展会活动之一。</p><p></p><h2>“不做硬件”的腾讯会议，将生态伙伴发展到了多200家</h2><p></p><p></p><p>一直以来，腾讯会议的策略是，坚持不做硬件，主打发挥“连接”作用。</p><p>展会现场，腾讯会议与MAXHUB联合发布行业首创超宽屏沉浸式会议解决方案，搭载21：9的105英寸屏幕，预装腾讯会议Rooms，并将嵌入腾讯天籁inside音频解决方案。该方案支持展示更多的参会者视频、以独立区域呈现聊天弹幕、中英字幕等更多的会议信息，满足跨国会议等更高专业性会议室需求。</p><p>&nbsp;</p><p>腾讯会议还携手亿联网络联合发布预装腾讯会议Rooms的MeetingBar A10智能安卓视讯一体机及MeetingEye 500 超清分体式视讯终端，进一步提升会议室协作效率。基于腾讯会议认证，腾讯会议Rooms与亿联网络已推出超过10款覆盖大中小会议室及音视频外设的解决方案。</p><p>&nbsp;</p><p>据了解，天籁inside音频解决方案作为腾讯会议旗下天籁实验室研发的软硬一体声学解决方案，目前已覆盖一体机大屏、扩展麦、天花麦等产品，与MAXHUB、Newline、耳目达、海信、皓丽、希沃、TCL等厂商达成合作。</p><p>&nbsp;</p><p>腾讯云副总裁、腾讯会议负责人吴祖榕现场表示，腾讯会议是完全开放的，能够自由的运行在硬件设备上，这对于用户、硬件厂商、企业主来说，是解耦的。</p><p>&nbsp;</p><p>数据显示，目前腾讯会议生态合作伙伴数量达到200家，认证的硬件厂商超过30家，覆盖产品型号超过120款。未来，腾讯会议将持续创新技术产品，为企业提供更高效、便捷的混合会议解决方案，并携手生态合作伙伴，在会议领域实现创新模式的突破，共同为千行百业提供高效便捷的协同服务。</p><p>&nbsp;</p><p>值得一提的事，在展会之前，InfoQ记者注意到，外界对于腾讯会议部分功能开始收费这件事产生了许多不同的声音。展会现场，吴祖榕也就外界关注的腾讯会议商业化问题做了介绍。</p><p>&nbsp;</p><p>吴祖榕称，“在由免费切换到付费的过程中，我们也曾担心用户会因为收费而流失。但是通过一系列运营，我们了解到我们内部最关心的数据指标几乎没有什么发生变化，这个事情给了我们非常大的触动，一方面可以说明大家已经比较熟悉和信赖腾讯会议了。另一方面可以看到用户数量并没有比较大的变化，大家已经形成了一种习惯。”</p><p>&nbsp;</p><p>“合理的商业化，对团队进行合适的投入，这是我们的共识，我们希望把这个市场做大，团队能够得到合理的回报，能够支撑持续的发展。”吴祖榕说道。</p><p></p><h2>首发轻量化混合式教学解决方案、4K共享屏幕，满足更多垂直行业需求</h2><p></p><p>&nbsp;</p><p>近年来，云会议的普及促使线上线下混合式协同需求猛增。在教育行业，混合式教学已经成为数字化教学的重要建设方向。</p><p>&nbsp;</p><p>展会现场，腾讯会议首发轻量化混合式教学解决方案，方案基于腾讯会议教育版、Rooms会议室解决方案、腾讯天籁inside音频解决方案打造，助力各大教育机构实现教学数字化升级。</p><p>&nbsp;</p><p>借助云端视频语音沟通，智慧教室解决方案能够实现高质量的跨校区、跨国跨区域视频连接，打通教学过程中的“实体空间与虚拟空间”。同时，通过腾讯会议的云录制、AI智能纪要等能力，课后也能自动形成知识点摘要，从而高效、智能完成知识沉淀，提升教学质量。</p><p>&nbsp;</p><p>此外，腾讯会议还开放了会控API与相关的中控API，帮助学校集成到自有教学教务管理系统，满足不同云会议系统一键智能切换、设备远程管理、异常告警等多种需求。</p><p>&nbsp;</p><p>面对游戏、设计等对画面显示要求高的行业，如果在共享屏幕时无法准确还原原有效果，则会大大地影响沟通进展。</p><p>&nbsp;</p><p>展会现场，腾讯会议发布4K共享屏幕，通过软件算法实现最高60fps帧率，高动态、低时延、高保真画质共享，流畅呈现游戏级的实时动态效果。&nbsp;</p><p>&nbsp;</p><p>此外，基于深入不同行业所积累的技术和服务经验，腾讯会议的服务还覆盖了金融、医疗、工业等30多个行业，在路演、财报会、远程医疗等细分业务场景积累了丰富的实践经验。</p>",
    "publish_time": "2023-07-24 14:53:14",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "字节跳动架构 / 服务框架团队负责人成国柱，确认担任 QCon 北京微服务架构治理专题出品人",
    "url": "https://www.infoq.cn/article/BpIkJTBIHyvJhwzai8x7",
    "summary": "<p>9 月 3 日 - 5 日，在<a href=\"https://qcon.infoq.cn/202309/beijing/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=0724\"> QCon 全球软件开发大会（北京站）</a>\"，字节跳动架构 / 服务框架团队负责人成国柱将担任「微服务架构治理」的专题出品人。在此次专题中，你将了解到如何解决微服务存在的一些问题，比如数量增长失控带来的运维管理问题、快速排查链路和容量估计的问题，以及对于简单业务逻辑，微服务架构消耗在非业务侧的成本较高带来的成本优化问题。</p><p></p><p>成国柱有 11 年互联网研发经验，当前在字节主要负责 Golang/Java/Rust RPC 框架、Service Mesh、流量治理等方向。从 0 到 1 完成字节 Service Mesh 落地，线上数万服务、数百万容器接入，是业界最大的服务网格落地企业之一，首批获得信通院服务网格先进级别证书。所负责的 Golang RPC 框架 KiteX/Hertz，全面应用于字节内部业务线。同时开源的 KiteX 框架，在 Golang RPC 领域也极具竞争力。在 CCF/GIAC/QCon 等大会上多次分享技术经验。</p><p></p><p>相信成国柱的到来，可以帮助提升此专题的质量，让你深入了解并学习到针对于微服务数量爆炸、链路深度、服务域隔离等架构复杂度问题治理的道与术，为解决架构问题提供了更好的思路。</p><p></p><p>除上述专题外，QCon 北京还将围绕<a href=\"https://qcon.infoq.cn/202309/beijing/track/1553?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">异构计算</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1554?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">向量数据库</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1556?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">FinOps&nbsp;落地</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1558?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">业务安全技术</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1557?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">从&nbsp;BI&nbsp;到&nbsp;BI+AI，新计算范式下的大数据平台</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1559?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">从&nbsp;MLOps&nbsp;到&nbsp;LLMOps</a>\"等进行分享。</p><p></p><p>近 100 名讲师、近 30 个精彩专题、8 种交流活动，QCon 北京 2023，相约 9 月！ 现在购票，享 9 折特惠，立省 ¥880！咨询购票请联系 18514549229（微信同手机号）。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/36/33/36d186975c75c0fff5f9506587d74833.jpg\" /></p><p></p>",
    "publish_time": "2023-07-24 15:22:27",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "基于量化分析的低代码平台体验优化实践 | 低代码技术内幕",
    "url": "https://www.infoq.cn/article/ESUcuSA6d7pAlAhgfSfw",
    "summary": "<p></p><blockquote>自 2020 年来，网易数帆探索可视化低代码编程已两年有余，打造了 CodeWave 智能开发平台（原轻舟低代码平台）用于企业应用开发。然而，不少编程技术人员对这一领域还比较陌生。我们开设<a href=\"https://www.infoq.cn/article/GyeL9Dk8DLyeSOv6EYhb\">《低代码技术内幕》专栏</a>\"，旨在讨论低代码编程领域中的困难、问题，以及高效的解决方案。本文为第四篇，将介绍基于净推荐值（Net Promoter Score，NPS）和结构方程模型（Structural Equation Model，SEM）方法的低代码用户体验管理体系。SEM 侧重从定量的方法，通过用户侧视角、数据驱动，量化各级指标对于 NPS 的贡献度（权重）。在本文中，我们将展示 SEM 在搭建指标体系中的关键步骤，并给出使用 SEM 结果改良用户体验的方法。专栏内容回顾：<a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651165383&amp;idx=2&amp;sn=556042253f71e05a1fdf98511c2fe069&amp;chksm=bdb86a948acfe3828c787e27ab418cc7c8a2d491815476b0909dff6c6b3e4ebe1980770b12e9&amp;scene=21#wechat_redirect\">低代码编程及其市场机遇剖析 | 低代码技术内幕&nbsp;&nbsp;</a>\"<a href=\"https://www.infoq.cn/article/ssRCU5cgGPGxJNHH2TRU\">基于 Vue 和 Canvas，轻舟低代码 Web 端可视化编辑器设计解析 | 低代码技术内幕</a>\"<a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651168168&amp;idx=2&amp;sn=b8b5c68aac84a917d502969aa93ac66a&amp;chksm=bdb865fb8acfeced3fac6c9d812d8079284dc37bf572cc9005f1aada1d4657c6da8979b13eff&amp;scene=21#wechat_redirect\">面向数字化提质提效的低代码架构设计 | 低代码技术内幕</a>\"</blockquote><p></p><p></p><h2>净推荐值、结构方程模型和它们的价值</h2><p></p><p></p><p>我们首先简要地说明净推荐值和结构方程模型的价值，让读者对它们“是什么、有什么用”有一个比较具象的理解。</p><p></p><h3>净推荐值和其价值</h3><p></p><p></p><p>净推荐值（Net Promoter Score，缩写为 NPS）主要通过一个单一的问题，来测量用户 / 客户（后文简称用户）向他人推荐某个企业 / 产品 / 服务可能性。</p><p></p><p>具体的测量问题如下，向用户询问：</p><p></p><p></p><blockquote>“您有多大的可能将 XX 产品和服务推荐给身边的同事或亲朋好友，0 分表示非常不推荐，10 分表示非常推荐”</blockquote><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/1d/1d4b74096b2de4d96dd094b4834e59f4.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a0/a073e72459c7a127b1d6e3a26b5cdae3.png\" /></p><p></p><p>按照用户不同的打分，将用户分成三组人群：</p><p></p><p>推荐者：打 9 和 10 分的用户；被动者：打 7 和 8 分的用户；贬损者：打分 0-6 分的用户。</p><p></p><p>最终产品 NPS = (推荐者人数 - 贬损者人数) / 受访者总人数。</p><p></p><p>已有许多研究表明，NPS 与商业结果强相关：提升 NPS 能有效降低客户流失率、提升复购率、提升市场占有率。例如：</p><p></p><p>美国云计算管理公司 Rackspace，其 NPS 监测数据显示，NPS 值提升 20% 后，客户流失率下降了 30%。百度智能云 NPS 监测数据显示其 NPS 连续三年逐年提高，而其市场占有率也逐年上升。</p><p></p><p>Temkin Group 的研究结果显示：</p><p></p><p>客户的打分越高，越可能在这家公司产生购买行为，打分数与购买行为的 相关系数高达 0.81（相关系数绝对值的区间为 0-1，越接近 1 说明相关性越强。）与贬损者相比：推荐者的复购率是贬损者的 5 倍。推荐者对公司行为的容错度是贬损者的 7 倍。推荐者购买公司新品或者增值服务的可能性是贬损者的近 9 倍。</p><p></p><h3>结构方程模型和其价值</h3><p></p><p></p><p>在许多用户体验管理体系中，为了量化抽象概念，需要建构指标体系、确定各级指标权重，以 NPS 为核心的用户体验管理体系就是这样的一种分级指标体系。次级指标的拆解、指标的信效度、及其权重的准确性，就成为该项工作的重中之重。</p><p></p><p>由于产品不同，用户群体不同，对同一抽象概念所构建的指标体系，无论是在框架还是在权重分配上都会有差异，甚至大相径庭，不会有一个统一的方案。在一些垂直细分的行业内，部分指标系统的构建是通过访谈行业专家（如相关公司产品负责人）来进行归纳的，这些来自专家侧视角指标权重划分当然很重要，操作成本也相对简单，不失为一种高效的操作方法，但也可能存在专家意见不一、指标系统缺乏用户侧视角的问题。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b2/b29cfbc12d5170446ba6877382807169.jpeg\" /></p><p></p><p>结构方程模型（Structural Equation Model，简称 SEM）是基于变量的协方差矩阵来分析变量之间关系的一种统计方法，是多元数据分析的重要工具。它旨在使用反映潜变量和显变量之间关系的一组方程，来尽量缩小样本协方差矩阵与由模型估计出的协方差矩阵之间的差异。SEM 可以从显变量中推断潜变量、测试假设模型的正确性、提供修改模型的指导建议。与专家评分相比，SEM 弥补了缺乏用户视角的缺憾。</p><p></p><h2>构建以 NPS 为核心的用户体验管理体系</h2><p></p><p></p><p>低代码产品的用户体验管理体系的终极目标是达成商业结果、推动商业成单，因此我们使用了同商业结果强相关的 NPS 作为低代码的北极星指标和一级指标。</p><p></p><h3>指标说明</h3><p></p><p></p><p>NPS 会受多种因素的影响，我们通过专家访谈、用户调研、头脑风暴、桌面研究，最后梳理出 5 个二级指标——产品易用性、学习探索和求助、功能需求满足程度、性能感知、服务感知——作为低代码产品的核心驱动因素，以及 21 个三级指标作为测量指标。</p><p></p><p>低代码易用性指标的来源主要分为两大部分：第一部分主要结合了可视化编程领域的经典文献——《Usability Analysis of Visual Programming Environments: A ‘Cognitive Dimensions’ Framework》，它针对可视化编程系统提出的“认知维度”可用性分析框架，对科学地衡量与分析可视化编程系统很有帮助&nbsp;[1]。第二部分则主要借鉴国内 B 端云计算产品的易用性研究成果，包括阿里云的《阿里云易用性量表》等。</p><p></p><p>“学习探索和求助”、“功能需求满足程度”、“性能感知和服务感知”这几个指标则主要通过专家访谈、用户调研、头脑风暴获取。</p><p></p><p>各级指标说明梳理如表 3-1 所示：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/cf/cfd045f184b9cc133b13f01fc6399e5a.png\" /></p><p></p><p>在一个三级指标体系中，抽象概念是结构方程模型中的潜变量，测量指标是显变量，维度（仍然是抽象的）也属于潜变量，同时，概念是内生变量，维度是外生变量，指标则是外生变量。因此，综合起来看，概念是内生潜变量，维度是外生潜变量，指标是外生显变量。</p><p></p><p>（第三级）测量指标的数据主要通过向用户询问对于该维度的满意度评价或态度得分来进行获取，其取值范围为 1-10，举个例子，帮助文档的的测量指标：您对低代码帮助文档的使用满意度如何评价，1 分表示非常不满意，10 分表示非常满意。</p><p></p><p>下图即为结构方程模型的路径分析示意图：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/76/760d8fdf4ea952d372bc1e13aae1780b.png\" /></p><p></p><p>结构方程模型技术，针对主观建构的各种不同指标体系，以采集的客观数据为基础，对它们进行拟合、修正与评估，找出相对最准确、最简洁的指标体系，并通过拟合出来的 路径系数 来分配指标体系维度以及指标的权重&nbsp;[2]。</p><p></p><h2>低代码的 SEM 计算分析</h2><p></p><p></p><p>注：由于公司数据的合规要求，本章涉及的指标系数、权重均为脱敏后数据，仅供方法参考。</p><p></p><p>在进行结构方程模型分析之前，须先进行指标的信度（reliability）检验和效度（validity）检验。因为如果指标的信度、效度条件无法满足，即便结构方程模型的结果成立，其结论依然是不能被接受的。</p><p></p><p>样本说明：研究者通过网易数帆 CodeWave 低代码大赛（SaaS 用户）、网易公司内部用户、外部私有化部署用户三个渠道，尽可能覆盖全不同的用户类型群体，共回收有效问卷 1000+。</p><p></p><h3>指标的信度检验</h3><p></p><p></p><p>学术界普遍采用内部一致性系数，即 Cronbach’s α 系数，来验证指标的信度。表 3-1 展示了模型中所涉及的潜变量的一致性系数（通过 SPSS 22.0 计算得出)。</p><p></p><p>Hair、Anderson、Tatham、Black 指出，内部一致性系数 大于 0.7 表明量表的可靠性较高；在探索性研究中，内部一致性系数可以小于 0.7，但应大于 0.6；本研究各个潜变量的 Cronbach’s α 系数处于 0.732-0.925（见表 4-2），均超过了 0.7，表明各个概念的量表都具有较高的可靠性。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a4/a4731f81baf81c86378b158ee7fffb7a.png\" /></p><p></p><h3>指标的效度检验</h3><p></p><p></p><p>统计学上，因子分析是检验指标结构效度的最常用方法。按照惯例，我们使用了 KMO 样本测度 和 巴特勒球形检验 来检验数据是否适合做因子分析。数据显示：产品易用性、学习探索和求助、功能需求满足程度、性能感知、服务感知五个构面数据的 KMO 值分别为 0.901、0.847、0.813、0.715、0.703。同时，各构面数据的巴特勒球形检验的卡方统计值（Sig）的显著性概率均小于 0.001。</p><p></p><p>学者 Kaiser 指出，当 KMO 值大于 0.6，则表示样本数据适合做因子分析，因此，本研究的样本数据适合做因子分析。</p><p></p><h3>计算路径系数</h3><p></p><p></p><p>在因子分析的基础上，我们利用 AMOS 22.0 软件进行结构方程的建模与运算。（没有统计软件时也可以用 R、Java 等语言编码计算。）</p><p></p><p>对方程模型进行路径分析，得到模型的方程分析、有效性和拟合优度等指标。研究计算结果参见下表（表中标准化路径系数为脱敏后数据）。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/32/327f32549517ff36a35a7cdeb372fb07.png\" /></p><p></p><p>表：结构方程模型结果 &nbsp;注：&nbsp;*p &lt; 0.05, **p &lt;0.01, ***p &lt; 0.001</p><p></p><p>模型路径系数如下图所示，图中的数值均为标准化路径系数（图中路径系数为脱敏后数据）</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/dd/dd063b7a343d39f7ffa6c6a2a60ed02a.png\" /></p><p></p><h3>模型的调试和拟合优度</h3><p></p><p></p><p>建立路径系数后，需要对模型的拟合优度进行评价。评价指标包括两类：</p><p></p><p>绝对匹配测试：其评价指标是只基于假设模型隐含的协方差矩阵和样本方差矩阵的指数，包括 CMIN/DF（卡方值比自由度）、P 值。CMIN/DF 小于 3 可以接受，但一般以小于 2 为宜（CMIN/DF 是直接检验样本协方差矩阵和估计协方差矩阵间相似程度的统计量，理论期望值为 1）；卡方检验中的 P 值一般要大于 0.05，表明结构方程模型对数据的拟合良好&nbsp;[3] 。相对匹配测试：评价标准为描述性指标，包括 GFI（拟合优度指标）、TLI（不规范拟合指数）、CFI（比较拟合指数）、RMSEA（近似误差的均方根）等。GFI、TLI、CFI 这些指标越接近 1，模型拟合得越好：如果这些指标都大于 0.9，表示观测数据支持假设构想，大于 0.95 则表示拟合非常好。RMSEA 一般要求不应超过 0.08&nbsp;[3]。</p><p></p><p>本模型拟合度指标参见下表，可以认为设定模型能够较好的拟合样本数据。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e8/e87dccbab494f896076fd8f1e951d7b2.png\" /></p><p></p><h2>指标权重计算</h2><p></p><p></p><p>通过拟合优度检验后，我们需要确定二级指标、三级指标的权重，计算方式如下。</p><p></p><h3>二级指标权重</h3><p></p><p></p><p>利用上述模型所得路径系数大小，对各级指标进行权重分配。将五个二级指标（影响因素）的路径系数相加，每个维度的路径系数除以该值即为该维度的权重。产品易用性、学习探索和求助、功能需求满足程度、性能感知、服务感知的路径系数分别为 0.27、0.22、0.35、0.23、0.17，它们的和为 1.24，则关键业务操作体验的权重为 0.27/1.24 = 22%。以此类推，可计算出其他二级指标权重，二级指标权重之和为 100%，参见下表。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/da/da9ed3b022438b5a678c658d35ecd008.png\" /></p><p></p><h3>三级指标权重</h3><p></p><p></p><p>以“上手难度”指标为例：</p><p></p><p>先算出“上手难度”对于用户体验指数（一级指标）的系数，该系数等于两个路径系数的乘积，即:0.81 * 0.27=0.219，记为 A1。同理，可计算抽象坡度的系数 A2、文案信息的易理解性系数 A3……服务人员解决问题的能力系数 A21；则“上手难度”此三级指标的权重 = A1 / (A1 + A2 + A3……A21)。</p><p></p><p>同理可计算出其它三级指标的权重，所有三级指标权重之和等于 100%。</p><p></p><p>另外，我们可以用已确立的权重，计算出相应的二级指标得分。例如，在我们的发放的问卷调研中，并没有直接测量产品易用性的得分（因为这是一个复合的抽象化概念，并不容易直接测量其得分），但现在我们可以通过 10 项指标和其相应的权重（由结构方程模型得出），然后计算出产品易用性的得分。</p><p></p><h2>用户体验管理体系的运转</h2><p></p><p></p><p>经过 SEM 建模计算后，我们便可以根据指标得分、指标对 NPS 的影响权重绘制二维散点图，并根据以下步骤优化产品。</p><p></p><p>1. 确定优化抓手：对 NPS 影响权重高 &amp; 指标得分低</p><p></p><p>下图中的亟待改善区即为优化抓手：对 NPS 影响权重高，同时指标得分低</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ab/ab95c183576962851973be7d421878ab.png\" /></p><p></p><p>2. 识别优化抓手的核心驱动要素 &amp; 用户触点</p><p></p><p>优化抓手通常是方向性问题，如性能问题，产品的上手门槛问题，后续则需要进一步通过用户调研或梳理用户已有反馈问题，定义好问题场景及范围，进而确认具体问题的优先级。</p><p></p><p>3. 推动优化举措落地</p><p></p><p>定义好高优先级体验问题后，相关业务方会根据实际情况进行优化、排期。</p><p></p><p>4. 效果验证、体验闭环</p><p></p><p>通过迭代的 NPS 和指标得分，验证改版或产品改进的效果。</p><p></p><h2>SEM 的使用方式小结</h2><p></p><p></p><p>根据业务领域和目标，选取一个一级指标（如净推荐值）。一级指标是抽象概念。根据业务，以合适的方式（如专家访谈、用户调研、头脑风暴、桌面研究等）获取二级指标和三级指标。二级指标是维度，三级指标是测量指标。对指标进行信度检验和效度检验。通过结构方程模型，计算出各个二级指标、三级指标的标准化路径系数。评估模型的拟合优度，调试模型，直到模型的各种参数符合相应标准。计算各个二级指标、三级指标的权重。</p><p></p><p></p><h2>总&nbsp; &nbsp;结</h2><p></p><p></p><p>本文介绍了基于 NPS 和 SEM 的低代码用户体验管理体系，它们引入了用户视角，一定程度解决了专家打分评估的主观性、随意性问题。文章通过低代码产品的例子，展示了 SEM 在搭建指标体系中的关键步骤：澄清与界定概念、建立指标体系、形成调查问卷、指标信效度检验、模型拟合与评估、权重分配等。</p><p></p><p>本文虽以低代码产品为例，但介绍的方法具有普适性，并不仅仅局限于低代码产品。</p><p></p><p>作者简介：</p><p></p><p>网易杭州研究院设计部，致力于为公司产品提供优质的用户体验设计，核心专业能力包括用户体验管理与业务增长，提供数字化转型、增长策略规划、品牌升级、体验创新等解决方案。</p><p></p><p>网易数帆编程语言实验室，负责 CodeWave 智能开发平台核心编程能力的设计，包括类型系统、语义语法、声明式编程、可视化交互等 NASL 的语言设计，Language Server、可视化引擎等，以及后续演进方案的规划和预研，旨在创造低门槛高上限的低代码开发体验。</p><p></p><p>参考文献</p><p></p><p>[1] Green T R G, Petre M. Usability analysis of visual programming environments: a ‘cognitive dimensions’ framework[J]. Journal of Visual Languages &amp; Computing, 1996, 7(2): 131-174</p><p></p><p>[2] 武海东，用结构方程模型构建图书馆读者满意度评价指标体系 [J]，情报科学，2011,29(02):227-230</p><p></p><p>[3] 史雅翼，线性结构方程模型评价指标的应用 [J]，中国医院统计，2001,8(4):237-238</p>",
    "publish_time": "2023-07-24 15:54:19",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "云器科技产品发布会",
    "url": "https://www.infoq.cn/article/22GhZyjOkqJEzbHD9o3I",
    "summary": "<p>7 月 20 日，云器科技举行首次对外的产品发布会，首次推出新一代“多云、一体化”的数据平台云器 Lakehouse，提出增量计算新范式，并基于增量计算构建 “Single-Engine”一体化平台，在湖仓架构之上，实现批、流、交互三种分析模式的统一。为企业提供开箱即用、高性能、低成本的数据平台，帮助企业真正让数据变为生产力，向科技型数字化企业转型。</p>\n<p>InfoQ 作为战略合作媒体支持了本次发布会的落地。</p>",
    "publish_time": "2023-07-24 16:09:46",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "日增320TB数据，行为分析系统从ClickHouse迁移至ByConity的实践",
    "url": "https://www.infoq.cn/article/SY22mCZDwlSU1uBkih3q",
    "summary": "<p></p><h2>背景介绍</h2><p></p><p></p><p>ByConity适合多种业务场景，在实时数据接入、大宽表聚合查询、海量数据下复杂分析计算、多表关联查询场景下有非常好的性能。我们用一个实际的业务场景来介绍下，这套行为分析系统是基于用户多维度行为分析平台，提供事件分析、留存分析、转化分析、用户分群、用户留存等多种分析方式和场景。本文将介绍下该用户多维度行为分析平台在使用原ClickHouse集群遇到的问题和挑战，以及通过迁移ByConity后如何解决这些问题并给业务带来的收益。</p><p><img src=\"https://static001.geekbang.org/infoq/1a/1a843c479a8c5b5bd321eb3201eaa41d.jpeg\" /></p><p>图1 行为分析系统架构设计</p><p></p><h2>问题和挑战</h2><p></p><p></p><p>早期这套系统部署在ClickHouse集群，一方面，由于业务的高速发展导致数据量日益膨胀，每日最大新增数据超过320TB，每日新增行数超过2.3万亿条，用户数据维度超过2万多个；另一方面，用户查询需求更加灵活和多样化，需要同时支持明细查询、聚合查询以及交互式分析查询，并快速给出响应结果。</p><p></p><p>此外，在数据量不断增加的情况下（年增长35%），我们既要能支撑这么大的数据增量带来的挑战，又要把成本增速控制在一定范围内。</p><p></p><p>但是在已有的ClickHouse集群上我们很难做到。原因是ClickHouse是基于Shared-Nothing的架构，每个节点是独立的，不会共享存储资源，因而计算资源和存储资源是紧耦合的，会导致如下问题：</p><p></p><p>扩缩容成本变高，且会涉及到数据迁移，使我们不能实时按需的扩缩容，而且会导致资源的浪费，成本不可控紧耦合的架构会导致多租户在共享集群环境相互影响，造成用户查询相互影响由于集群上节点的读写在同一个节点完成，导致读写相互影响在复杂查询上例如多表Join等操作的性能支持并不是很好，无法满足用户查询多样化的需求</p><p></p><h2>技术选型</h2><p></p><p></p><p>因此在2022年初业务开始使用计算存储分离架构的ByConity来作为主要的OLAP引擎。ByConity是一个开源的云原生数据仓库，它采用计算存储分离的架构，支持多个关键功能特性，如计算存储分离、弹性扩缩容、多租户资源隔离和数据读写的强一致性等。通过利用主流的OLAP引擎优化，如列存储、向量化执行、MPP执行、查询优化等，ByConity可以提供优异的读写性能。</p><p><img src=\"https://static001.geekbang.org/infoq/97/97813d81e346953f5f20e5c492b42db1.png\" /></p><p>图2 ByConity三层技术架构图</p><p></p><p>ByConity是在开源的ClickHouse架构基础上进行了升级，引入了计算与存储分离的架构，将原本计算和存储分别在每个节点本地管理的架构，转换为在分布式存储上统一管理整个集群内所有数据的架构，使得每个计算节点成为一个无状态的单纯计算节点，并利用分布式存储的扩展能力和计算节点的无状态特性实现动态的扩缩容。正是由于这种改进，使得ByConity具有以下重要特性：</p><p></p><p>资源隔离：对不同的租户进行资源的隔离，租户之间不会受到相互影响。读写分离：计算资源和存储资源解耦，确保读操作和写操作不会相互影响。弹性扩缩容：支持弹性的扩缩容，能够实时、按需的对计算资源进行扩缩容，保证资源的高效利用。数据强一致：数据读写的强一致性，确保数据始终是最新的，读写之间没有不一致。高性能：采用了主流的OLAP引擎优化，例如列存、向量化执行、MPP执行、查询优化等提供优异的读写性能</p><p></p><h2>业务收益</h2><p></p><p></p><p>在我们引入了ByConity后，整体性能可以达到91%用户查询都可以在10秒内完成，通过来自用户的反馈调研，这个性能指标也是在用户可接受的范围内。这里总结下我们迁移ByConity带来的总体收益和经验：</p><p></p><p>避免资源抢占，查询性能百分百稳定：</p><p>在原来ClickHouse的集群上，我们经常会遇到资源挤占的问题，由于ClickHouse并没有做到资源隔离和租户隔离，在多个用户共用集群进行查询时，当一个用户查询资源开销非常大，会涉及资源的抢占，导致这个集群上所有共用的用户查询都不稳定，服务质量达不到满足。但在迁移到ByConity后，由于计算组是完全物理隔离，可以达到天然的资源隔离和租户隔离，不同用户的查询相互不受到影响，整体查询性能可以达到91%用户查询都可以在10秒内完成。再者ByConity提供了自研的复杂查询链路，自研 Disk Cache以减少冷数据读取，并对于高频使用的Array 建立索引等，而且热读效率也优于原ClickHouse集群，相比在原Clickhouse集群上性能折损在10%以内。</p><p></p><p>运维成本低，故障节点秒级替换：</p><p>原本在Clickhouse集群上，如果发现集群中某个节点坏掉，需要先下掉整台机器维修，这是因为ClickHouse的计算资源、存储资源、以及元数据信息都在这个节点上，相当于集群少了一个计算资源，也少了一个存储副本，在替换新的节点之前，需要把对坏掉节点的本地磁盘进行备份迁移到新的节点上，维护成本比较高，且数据一致性很难得到保障。而对于ByConity来讲，如果发生计算组坏掉的情况，由于计算组不存储数据，只包含无状态的计算节点，因此只需要替换新的计算组即可，数据的可靠性和一致性由HDFS来保障，且本地热读数据缓存的丢失对业务查询性能是可控的，这部分也主要得益于了ByConity存储和计算分离架构实现。</p><p></p><p>无感扩缩容，节约资源成本：</p><p>ByConity是可以实现无感扩缩容，它是一个模块化和容器化的部署，基于Kubernetes的弹性伸缩能力，如果有足够的机器可以无限的扩容，同时如果服务器发生故障，我们也不用担心，因为ByConity的节点只一个无状态的计算节点，直接下掉对整个集群影响不大。而且通过自适应调度回避慢节点，提升吞吐能力，提高节点资源利用率。同时ByConity的压缩率极高，以其中一个业务为例，每日新增460TB数据，压缩后达到100TB，压缩比达到65%，并支持低基数编码 &amp; ZSTD等等压缩方式，极端情况下存储占用小于parquet。</p><p></p><p>数据一致性强保障，维护复杂度接近为零：</p><p>在迁移到ByConity后，我们完全解决了数据一致性问题，因为ByConity不存在本地的主备同步问题，数据一致性问题直接交给底层的对象存储解决，例如HDFS/S3等。这样对一致性维护的复杂度大大降低，错误概率也更低，目前也少有用户再反馈数据一致性问题。但在之前是经常遇到，因为ClickHouse集群是多个副本通过节点间通信去维护的，通过一致性队列去维护一致性问题，实现上也很复杂，容易出错。另外，ByConity可以通过HDFS直接访问到数据文件，不同计算引擎适配不同连接器，即可读入数据，具备通用能力。</p><p></p><h2>未来展望</h2><p></p><p></p><p>通过长达一年半的实践摸索，ByConity已经成为内部使用的主要OLAP引擎，后期会有大量的用户和数据迁入，最终取代原本的ClickHouse集群。可以看出ByConity作为一款计算存储分离的OLAP引擎，具有高性能、高可扩展性和高稳定性等优点，能够满足大规模体量的数据处理和分析的需求。同时，通过在社区的交流，以及社区发布的Roadmap讨论https://github.com/ByConity/ByConity/issues/26，未来阶段ByConity会主要聚焦在以下几个方向：</p><p></p><p>支持执行层的多Stage执行、ETL能力等支持数据湖联邦查询如Hudi、Iceberg等</p><p>ByConity社区拥有大量的用户，同时是一个非常开放的社区，我们邀请大家和我们一起在Github上讨论共建。</p><p></p><blockquote>GitHub：https://github.com/ByConity/ByConity</blockquote><p></p>",
    "publish_time": "2023-07-24 17:42:58",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "敏捷宣言并未改变任何事情",
    "url": "https://www.infoq.cn/article/OqeCI3ygcRkyJdzmLaza",
    "summary": "<p>当<a href=\"https://agilemanifesto.org/\">《敏捷宣言</a>\"》于2001年首次出现时，整个行业刚刚从互联网泡沫的灾难性破灭中走出来。大量的资本涌入科技市场，每家公司都在“采用”互联网，但当不可避免的经济衰退到来时，许多软件工程师失去了工作。</p><p></p><p>由于1998年和1999年的低利率，90年代末现金充裕，催生了一种新型的初创公司：互联网初创公司。许多企业家（通常没有能力真正执行自己的想法）被这个全新且蓬勃发展的市场可能性所蒙蔽，成功地将自己的企业推销给风险投资公司。虽然有一些非常成功的独角兽从这个泡沫中走了出来（比如谷歌的互联网搜索引擎、易趣的在线拍卖网站和亚马逊的互联网书店），但许多其他独角兽都失败了，不可避免地倒闭了，并重创了市场。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d9/d9a0002f2c71e9b35c424fe8ec39d8ec.jpeg\" /></p><p></p><p>撇开糟糕的技术市场不谈，2001年的软件世界是一个非常混乱、竞争激烈且“重流程”的地方。许多工程师都受制于可怕的瀑布式（Waterfall）软件开发方法：这是一种使用难以更改的严格需求来创建软件的系统。而且固定的软件产品交付期限几乎没有为任何迭代或集成测试留下空间。</p><p></p><p>在其他工程领域，瀑布式的效果不错：如果你正在建造一座桥梁，我当然希望你在开始建造之前就有一份要求、测量、材料和结构计算的清单。</p><p></p><p>但在软件领域，情况变化的很快，集成经常被中断，客户需求会毫无征兆地发生改变，因此通常需要一种更短、更简单的开发方法。你可能花了几个月的时间用瀑布式开发了一些软件，然后发现另一个部门的另一个团队提供的一些关键API集成与你所构建的软件完全不兼容（需要更长的瀑布周期）。或者，如果不是完全取消的话，你的项目可能会被业务降低优先级，（如果我们几个月前就能收到用户的反馈，这样我们就知道该做什么了……）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b7/b782312c780024355518ef1cec2453f3.jpeg\" /></p><p></p><p>上世纪90年代末和本世纪初，试图“采用互联网”的公司发现自己陷入到了冗长的工程流程和开发周期的泥潭中。这至少在一定程度上导致了互联网泡沫的经济崩溃：大量经济部门停滞不前，未能履行其对互联网业务价值和稳定性的夸大评估。我想知道，如果企业在早期技术革命期间采用更简单的敏捷方法，世界将会是什么样子：失败的企业会不会更少？如果是今天，我们的技术水平还会进一步提高吗？</p><p></p><p>值得庆幸的是，敏捷提出了一种不同的方法。</p><p></p><p>让我们想象一下，假设你团队的任务是构建并交付一辆软件汽车。在瀑布式开发中，你可能首先要建造车架，然后建造车轮，最后建造发动机，依此类推。很多事情都可能出错：如果最终产品不能满足客户的需求怎么办？如果你与道路软件套件的集成在交付时发生中断怎么办？或者你发现发动机部件实际上从未按预期工作，最终导致整个产品被损坏。汽车的计划和要求通常是由“业务部门”负责的，并在开发之初就交给了开发团队，但他们几乎没有进行更改的灵活性，也没有能力从真正的用户那里获取早期反馈。</p><p></p><p>相反，使用敏捷来构建这辆软件汽车，你将始终不断地交付可工作且经过测试的软件，并与了解客户需求的人员密切合作。你可以先交付一个滑板类型的东西。这建造起来足够简单；它有四个轮子，开门即用。然后，你可以把框架做得更大。你可以为小型推车式车辆添加一个发动机。为一辆汽车增加足够的座位。配置方向盘。添加收音机。最终，该项目将会完成，并且在此过程中，开发团队能够从真实用户那里获得反馈，并不断与现有系统集成，边开发边测试（团队在早期就能发现与道路系统的集成失败！）。</p><p></p><p>敏捷软件开发提出的原则对2023年的工程师来说似乎是显而易见的，但在当时，这些想法有趣、微妙且强大：始终交付可工作的软件，测试代码，持续集成，进行面对面的对话，优先考虑与团队中人的关系，快速适应不断变化的需求，与业务人员密切合作，让团队自组织以获得最佳结果。</p><p></p><p>就像任何好的“宣言”一样，所有这些都被包含在一个简单而优雅的文档中：<a href=\"https://agilemanifesto.org/\">《敏捷宣言》</a>\"。这并不是来自业内权威人士的；它是由从事实际工作的软件工程师编写并签署的。它的诞生听起来就像是小说中的情节：2001年的冬天，17名软件开发人员聚集在犹他州的雪鸟城（Snowbird），滑雪、吃饭、喝酒，并讨论软件行业（但不幸的是，他们并没有进行什么史诗般的探索）。像Kent Beck（后来建立了极限编程）、Andrew Hunt和David Thomas（《程序员修炼之道——The Pragmatic Programmer的合著者）以及Jeff Sutherland（scrum项目管理方法的先驱）这样的人。他们都出席了。输出了一个单一、简单的文档，概述了一个理想、精益且高效的软件组织工程过程。</p><p></p><p>敏捷开发最终将成为其他软件开发系统的基石，如Scrum、DevOps、极限（Extreme）编程和平台工程。这些后续的开发系统在很大程度上强调了敏捷中的不同原则；如持续交付、持续集成自动化套件、各个贡献者之间的关系，以及轻松地为个人贡献者和开发团队部署和交付优化的开发环境。但贯穿所有这些方法的方法论是敏捷。敏捷仍然是支柱。敏捷赋予了这些方法生命。</p><p></p><p>尽管敏捷看起来是关于过程和如何完成工作的，但《敏捷宣言》首先也是最重要的是对一个正在分崩离析、从内到外自相残杀并耗尽人才的行业的回应。</p><p></p><p>《敏捷宣言》的核心是：</p><p></p><p></p><blockquote>一套基于相互信任和尊重的价值观，促进以人为本、协作为基础的组织模式，并建立我们希望为其工作的组织社区类型。</blockquote><p></p><p></p><p>接受敏捷工程流程也意味着接受了围绕并包含敏捷的文化理想。经常测试、发布工作代码、持续集成等工程流程仅服务于支持自组织团队蓬勃发展的工程组织类型，在这里，人们热爱他们所做的工作，并且信任其工程师同事。</p><p></p><p>如今，大多数软件组织都会说他们已经采用了敏捷（或者至少采用了某种敏捷的派生形式）。然而，我认为该行业在采用敏捷的真正核心方面并没有达到目标。</p><p></p><p>我们发现自己的处境与2001年的网络泡沫破灭非常相似；利率不断上升，大批软件人才以最糟糕的方式被解雇，优先事项从协作和心理安全的工程组织转移到更高效地交付产品上。</p><p></p><p>似乎整个行业都在抵制敏捷的理念。</p><p></p><p>我最担心的是，《敏捷宣言》并未改变任何事情，因为越来越多的部门都变成了我不想为之工作的地方。</p><p>我首先要承认：敏捷需要时间、精力和奉献精神。但这并不总是那么容易。回顾、规划会议、用户研究（等等）都需要时间和工程资源。 时间并没有花在编码或直接处理产品上。但是，如果说过去20多年的科技繁荣市场向我们展示了什么，那就是敏捷在行业中被广泛采用了，这就是敏捷的作用。快乐的工程师热爱他们的工作，提供了令人惊叹的解决方案，从长远来看，他们打造更具可持续性的组织，这些组织可以持续交付客户喜爱的稳定和创新的产品。</p><p></p><p>如果到目前为止，你还在读这篇文章，会发现自己在说“嗯，网络泡沫有点像今天的科技市场”，那是因为它确实如此。从经济、文化和工程流等程角度来看。当经济不景气时，工程组织似乎都会变得更糟。</p><p>埃隆·马斯克（Elon Musk） 收购推特（Twitter） 就是一个主要且引人注目的例子：<a href=\"https://www.theguardian.com/technology/2023/mar/08/spike-in-twitter-outages-since-musk-takeover-hint-at-more-systemic-problems\">大多数工程师都被解雇了，出现了多次长时间的停机，有传言称内部基础设施系统严重受损</a>\"，以及出现了一种新的“极端硬核”文化，所有这些都是为了寻找盈利能力和交付软件需求的运动。</p><p></p><p>但埃隆·马斯克不应该受到指责。<a href=\"https://www.nytimes.com/2021/08/16/technology/twitter-culture-change-conflict.html?searchResultPosition=1\">推特的问题早在收购之前就已经存在了</a>\"：</p><p></p><p></p><blockquote>在2019年加入推特不久，Dantley Davis 将他的员工聚集在公司旧金山总部的一个会议室里……他要求员工们在会议室里四处走动，相互赞扬和批评。他说，严厉的批评将有助于推特的改进。倒刺很快就飞了起来。据在场的三名人士说，在两个小时的会议中，有几名与会者都哭了。</blockquote><p></p><p></p><p>这听起来肯定不像是“我们希望在其中工作的组织社区类型”。</p><p></p><p>这一点意义重大，因为科技市场是一只自食其力、总是自相残杀的野兽：无论大公司做什么，尤其是像谷歌、Meta和亚马逊这样公司，科技市场的其他公司都会紧随其后。工程文化、薪酬、面试等方面的这些趋势总会渗透到行业的其他领域。所以，在你不自知的情况下，埃隆·马斯克对推特的收购可能就已经影响到了你。</p><p></p><p>2023年的裁员和缩编可能还没有结束。许多经济学家认为，我们正走向衰退（如果还没有衰退的话），这可能会加速许多公司的文化和工程组织变革。就像2001年互联网泡沫破灭时一样，今天的软件和科技行业必须要面对经济的冲击。</p><p></p><p>但我对未来的希望是，工程组织和领导层认识到这一正在重复的历史，改变方向，并继续专注于为他们工作的精益和敏捷流程。否则，我们可能会看到更多像推特这样的公司，它们的商业模式失败了，基础设施崩溃了，稳定性令人遗憾，也许最糟糕的是，它们是一个没有人愿意加入的工程组织。</p><p></p><p>原文链接：<a href=\"https://onengineering.substack.com/p/how-the-agile-manifesto-changed-nothing\">https://onengineering.substack.com/p/how-the-agile-manifesto-changed-nothing</a>\"</p>",
    "publish_time": "2023-07-24 18:34:24",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]