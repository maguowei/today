[
  {
    "title": "AI近期新闻：OpenAI、微软、Meta及Bloomberg",
    "url": "https://www.infoq.cn/article/Bpz3oN3tByqK3z0r5YY6",
    "summary": "<p>2023年4月3日的综述包括来自数据科学、机器学习和人工智能领域的最新新闻和信息。我们主要关注的是OpenAI、微软、Meta和Bloomberg的新突破和创新，他们是市场上仅有的几个主要竞争对手。</p><p></p><p>以下是自然语言处理（NLP）模型、人工智能（AI）新开发工具、道德人工智能（ethical AI）实践和其他学科的最新发展。</p><p></p><h2>OpenAI的GPT-4</h2><p></p><p></p><p><a href=\"https://www.infoq.com/news/2023/04/openai-gpt4/\">OpenAI最近发布了GPT-4</a>\"，这是其GPT大语言模型（LLM）系列的下一代产品。GPT-4可以接受文本和图像输入，并在多个自然语言处理（NLP）基准测试中优于最先进的系统。该模型在模拟律师资格考试中的成绩超过了90%的考生。</p><p></p><p>此外，<a href=\"https://openai.com/blog/our-approach-to-ai-safety\">OpenAI还宣布了他们的人工智能安全方法</a>\"，即通过提高人工智能系统从人类反馈中学习并帮助人类评估人工智能的能力。其目标是构建一个充分对齐的人工智能系统，以帮助解决所有其他对齐问题（Alignment Problems）。</p><p></p><h2>微软的SK</h2><p></p><p></p><p><a href=\"https://www.infoq.com/news/2023/03/microsoft-semantic-kernel/\">微软开源了语义内核（Semantic Kernel，SK）</a>\"，这是一种轻量级的SDK，可以将大语言模型（LLM）与传统程序集成，从而可以利用提示模板、矢量化内存、智能规划和其他功能。</p><p></p><p>此外，<a href=\"https://arxiv.org/abs/2303.16434\">微软研究人员还推出了TaskMatrix.AI</a>\"。这是一种新的人工智能生态系统，将基础模型与数百万个API连接起来，以完成任务。这一概念涉及将基础模型与数百万个现有模型和系统API的集成，从而产生可以执行各种数字和物理任务的超级人工智能。虽然人工智能模型和系统目前旨在有效地解决特定领域的问题，但其实现和工作机制的多样性可能会使基础模型难以访问。这个新的生态系统旨在通过提供一个统一框架来连接这些人工智能模型和系统，以克服这些障碍。</p><p></p><h2>Meta的SAM</h2><p></p><p></p><p>Meta刚刚发布了<a href=\"https://ai.facebook.com/blog/segment-anything-foundation-model-image-segmentation/\">Segment Anything Model（SAM）</a>\"。这一新模型允许人工智能通过一次点击即可提取图像或视频中的对象。它利用了先进的计算机视觉技术，使计算机能够分析并理解图像或视频等视觉信息，其方式类似于人类如何感知并解释其所见的内容。</p><p></p><h2>Bloomberg的GPT</h2><p></p><p></p><p><a href=\"https://www.infoq.com/news/2023/04/bloomberg-gpt-ai/\">Bloomberg发布了BloombergGPT</a>\"，这是一种新的大语言模型（LLM），它经过了大量金融数据的训练，可以帮助金融部门进行一系列的自然语言处理（NLP）活动。BlooombergGPT是一种尖端的人工智能，可以快速评估财务数据，以帮助进行风险评估、衡量财务情绪，甚至可以实现会计和审计活动自动化。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/04/ai-ml-data-news-april3-2023/\">https://www.infoq.com/news/2023/04/ai-ml-data-news-april3-2023/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/RL7iFW2SqO0Ppv4msCsL\">防止AI胡说八道！OpenAI公布最新大模型训练方法，监督AI像人类一样思考</a>\"</p><p><a href=\"https://www.infoq.cn/article/ARJEOOh2M5oAmwRCpzfk\">字少事大！OpenAI 创始人等超350名大牛再签联名信，一句话声明简短有力：AI或引发灭绝风险</a>\"</p>",
    "publish_time": "2023-06-06 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "ByConity与主流开源OLAP引擎（Clickhouse、Doris、Presto）性能对比分析",
    "url": "https://www.infoq.cn/article/SQCArsXNtZ9N1vEbLBqx",
    "summary": "<p>随着数据量和数据复杂性的不断增加，越来越多的企业开始使用 OLAP（联机分析处理）引擎来处理大规模数据并提供即时分析结果。在选择 OLAP 引擎时，性能是一个非常重要的因素。因此，本文将使用 TPC-DS 基准测试的 99 个查询语句来对比开源的 ClickHouse、Doris、Presto 以及 ByConity 这 4 个 OLAP 引擎的性能表现，以便为企业选择合适的 OLAP 引擎提供参考。</p><p></p><h2>TPC-DS 基准测试简介</h2><p></p><p></p><p>TPC-DS（Transaction Processing Performance Council Decision Support Benchmark）是一个面向决策支持系统（Decision Support System，简称 DSS）的基准测试，该工具是由 TPC 组织开发，它模拟了多维分析和决策支持场景，并提供了 99 个查询语句，用于评估数据库系统在复杂的多维分析场景下的性能。每个查询都设计用于模拟复杂的决策支持场景，包括跨多个表的连接、聚合和分组、子查询等高级 SQL 技术。</p><p></p><h2>OLAP 引擎介绍</h2><p></p><p></p><p>ClickHouse、Doris、Presto 和 ByConity 都是当前比较流行的开源 OLAP 引擎，它们都具有高性能和可扩展性的特点。</p><p></p><p>ClickHouse 是由俄罗斯搜索引擎公司 Yandex 开发的一个列式数据库管理系统，它专注于大规模数据的快速查询和分析。Doris 是一个分布式列式存储和分析系统，它支持实时查询和分析，并可以与 Hadoop、Spark 和 Flink 等大数据技术进行集成。Presto 是一个分布式 SQL 查询引擎，它由 Facebook 开发，可以在大规模数据集上进行快速查询和分析。ByConity 是由字节<a href=\"https://www.infoq.cn/article/VKvhBbZq1OBtO3wF76Sf\">开源</a>\"的云原生数仓，采用了存储计算分离的架构，实现租户资源隔离、弹性扩缩容，并具有数据读写的强一致性等特性，它支持主流的 OLAP 引擎优化技术，读写性能非常优异。</p><p></p><p>本文将使用这四个 OLAP 引擎对 TPC-DS 基准测试的 99 个查询语句进行性能测试，并对比它们在不同类型的查询中的性能差异。</p><p></p><h2>测试环境和方法</h2><p></p><p></p><h4>测试环境配置：</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f8/f819d696ed8d4344a225e325ba30885d.png\" /></p><p></p><h4>服务器配置：</h4><p></p><p></p><p><code lang=\"properties\">Architecture:          x86_64\nCPU op-mode(s):        32-bit, 64-bit\nByte Order:            Little Endian\nCPU(s):                48\nOn-line CPU(s) list:   0-47\nThread(s) per core:    2\nCore(s) per socket:    12\nSocket(s):             2\nNUMA node(s):          2\nVendor ID:             GenuineIntel\nCPU family:            6\nModel:                 79\nModel name:            Intel(R) Xeon(R) CPU E5-2650 v4 @ 2.20GHz\nStepping:              1\nCPU MHz:               2494.435\nCPU max MHz:           2900.0000\nCPU min MHz:           1200.0000\nBogoMIPS:              4389.83\nVirtualization:        VT-x\nL1d cache:             32K\nL1i cache:             32K\nL2 cache:              256K\nL3 cache:              30720K\nNUMA node0 CPU(s):     0-11,24-35\nNUMA node1 CPU(s):     12-23,36-47\n</code></p><p></p><h4>测试方法：</h4><p></p><p></p><p>使用 TPC-DS 基准测试的 99 个查询语句，和 1TB（28 亿行）的数据测试 4 个 OLAP 引擎的性能。在每个引擎中使用相同的测试数据集，并保持相同的配置和硬件环境。对于每个查询，多次执行并取平均值，以减少测量误差，设置每次查询超时时间为 500 秒。记录查询执行的细节，例如查询执行计划、I/O 和 CPU 使用情况等。</p><p></p><h2>性能测试结果</h2><p></p><p></p><p>我们使用了相同的数据集和硬件环境来测试这四个 OLAP 引擎的性能。测试数据集大小为 1TB，硬件和软件环境如上介绍，我们使用了 TPC-DS 基准测试中的 99 个查询语句分别在四个 OLAP 引擎上进行了连续三次的测试，并取三次平均结果。其中 ByConity 跑通了所有 99 个查询测试。Doris 在 SQL15 出现 Crash，另外有 4 次的 Timeout，分别是 SQL54、SQL67、SQL78 和 SQL95。Presto 只在 SQL67 和 SQL72 发生 Timeout，其他查询测试都跑通了。而 Clickhouse 只跑通了 50% 的查询语句，大概有一部分是 Timeout，另一部分是系统报错，分析原因是 Clickhouse 不能有效的支持多表关联查询导致，只能把这类 SQL 语句做手动改写拆分才能执行。因此在对比总耗时我们暂时排除 Clickhouse，其他三个 OLAP 引擎 TPC-DS 测试总耗时如下图 1 所示，从图 1 中我们可以看出开源的 ByConity 查询性能明显优于其他引擎，性能约是其他的 3-4 倍。（注：以下所有图表纵坐标单位为秒）</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ab/ab910a37225ae9e1f377a31f7efdd5ad.png\" /></p><p>图 1 TPC-DS 99 条查询总耗时</p><p></p><p>针对 TPC-DS 基准测试的 99 个查询语句，我们接下来按照查询场景的不同进行分类，例如基础查询、连接查询、聚合查询、子查询、窗口函数查询等。下面我们将使用这些分类方式来对 ClickHouse、Doris、Presto 和 ByConity 四个 OLAP 引擎进行性能分析对比：</p><p></p><h3>基础查询场景下</h3><p></p><p></p><p>该场景包含简单的查询操作，例如从单个表中查询数据，过滤和排序结果等。基础查询的性能测试主要关注处理单个查询的能力。其中 ByConity 的表现最佳，Presto 和 Doris 的性能也表现都不错，这是因为基础查询通常只涉及到少量的数据表和字段，因此能够充分利用 Presto 和 Doris 的分布式查询特性和内存计算能力，Clickhouse 对多表关联支持不好，出现一些跑不通的现象，其中 SQL5、8、11、13、14、17、18 均超时，我们按 Timeout=500 秒计算，但希望显示更清晰截取 Timeout=350 秒。下图 2 是基础查询场景下四个引擎的平均查询时间：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f6/f6d61816eaa0cb986f9a405d286dbb83.png\" /></p><p>图 2 TPC-DS 基础查询的性能对比</p><p></p><h3>连接查询场景</h3><p></p><p></p><p>连接查询是常见的多表查询场景，它通常使用 JOIN 语句连接多个表，并根据指定条件进行数据检索。如图 3 我们看到 ByConity 的性能最佳，主要得益于对查询优化器的优化，引入了基于代价的优化能力（CBO），在多表 Join 时候进行 re-order 的等优化操作。其次是 Presto 和 Doris，Clickhouse 在多表 Join 的效果相比其他三个性能不是很好，且对很多复杂语句的支持不够好。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/05/05f14bdcca7fefdd1a978a63faf3cffc.png\" /></p><p>图 3 TPC-DS 连接查询的性能对比</p><p></p><h3>聚合查询场景</h3><p></p><p></p><p>聚合查询是对数据进行统计计算的场景，例如测试 SUM、AVG、COUNT 等聚合函数的使用。ByConity 依然表现优异，其次是 Doris 和 Presto，Clickhouse 出现了四次 Timeout，为了方便看出差异，我们截取 Timeout 值到 250 秒。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/da/da607fbe30253f049ec9b9895d1825c2.png\" /></p><p>图 4 TPC-DS 聚合查询的性能对比</p><p></p><h3>子查询场景</h3><p></p><p></p><p>子查询是在 SQL 语句中嵌套使用的查询场景，它通常作为主查询的条件或限制条件。如下图 5 所示，ByConity 表现最佳，原因是 ByConity 实现了基于规则的优化能力（RBO）进行查询优化，通过算子下推、列裁剪和分区裁剪等技术，把复杂的嵌套查询进行整体优化，替除所有的子查询，把常见算子转化成 Join+Agg 的形式。其次是 Doris 和 Presto 表现相对较好，但 Presto 在 SQL68 和 SQL73 出现 Timeout，Doris 也在 3 个 SQL 查询出现 Timeout，Clickhouse 同样出现了部分超时和系统报错，原因上面有提到。同样为方便看出差异，我们截取 Timeout 值等于 250 秒。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ed/ed2dbbf75f67fe3c76103d22fdac0371.png\" /></p><p>图 5 TPC-DS 子查询的性能对比</p><p></p><h3>窗口函数查询场景</h3><p></p><p></p><p>窗口函数查询是一种高级的 SQL 查询场景，它可以在查询结果中进行排名、分组、排序等操作。如下图 6 所示，ByConity 的性能最优，其次是 Presto，Doris 出现了一次 Timeout 的情况，Clickhouse 依然有部分没有跑通 TPC-DS 测试。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/89/896e350707850f7b2bba2fb3553c5d80.png\" /></p><p>图 6 TPC-DS 窗口函数查询的性能对比</p><p></p><h2>总结</h2><p></p><p></p><p>本文对 ClickHouse、Doris、Presto 和 ByConity 四个 OLAP 引擎在 TPC-DS 基准测试的 99 个查询语句下的性能进行了分析和比较。我们发现，在不同的查询场景下，四个引擎的性能表现存在差异。ByConity 在所有 TPC-DS 的 99 个查询场景下都表现优异，超过其他三个 OLAP 引擎；Presto 和 Doris 在连接查询、聚合查询和窗口函数查询场景下表现较好；由于 Clickhouse 的设计和实现并不是专门针对关联查询进行优化，因此在多表关联查询方面整体表现差强人意。</p><p></p><p>需要注意的是，性能测试结果取决于多个因素，包括数据结构、查询类型、数据模型等。在实际应用中，需要综合考虑各种因素，以选择最适合自己的 OLAP 引擎。在选择 OLAP 引擎时，还需要考虑其他因素，如可扩展性、易用性、稳定性等。在实际应用中，需要根据具体业务需求进行选择，并对引擎进行合理的配置和优化，以获得最佳的性能表现。</p><p></p><p>总之，ClickHouse、Doris、Presto、ByConity 都是非常优秀的 OLAP 引擎，具有不同的优点和适用场景。在实际应用中，需要根据具体业务需求进行选择，并进行合理的配置和优化，以获得最佳的性能表现。同时，需要注意选择具有代表性的查询场景和数据集，并针对不同的查询场景进行测试和分析，以便更全面地评估引擎的性能。</p><p></p><p>延伸阅读：</p><p><a href=\"https://www.infoq.cn/article/eDuYRT4rzgHBpqfV1T49\">谈谈ByConity存储计算分离架构和优势</a>\"</p><p><a href=\"https://www.infoq.cn/article/VKvhBbZq1OBtO3wF76Sf\">字节跳动开源ByConity：基于ClickHouse的存算分离架构云原生数仓</a>\"</p><p></p><p></p>",
    "publish_time": "2023-06-06 09:57:24",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "深化敏捷研发转型，金融行业逐浪数字化“深水区”",
    "url": "https://www.infoq.cn/article/eGczayNgBWlMjb1I6Xq8",
    "summary": "<p>金融行业数字化转型正在进入深水区。数字化转型是金融机构构建差异化核心竞争力的关键，既可以优化现有业务场景，实现提质增效，还可以创新金融服务场景，为用户带来全新体验。&nbsp;</p><p></p><p>政策支持上，《金融科技发展规划（2022-2025年）》等诸多重磅文件发布，明确了金融行业数字化转型的目标、任务、路径；市场发展上，金融科技新场景开始不断满足不同用户需求；技术融合上，加快金融科技赋能可以推动金融行业实现降本增效。</p><p></p><p>研发是金融行业数字化转型的底座，金融机构的研发需要与业务需求有效对接，既要稳健又要敏捷，在长开发周期中保证研发质量提升效能。腾讯&nbsp;TAPD 作为国内最早一批上线的敏捷研发协作平台，积累了腾讯 10 余年敏捷研发精髓，为金融、游戏、社交文娱、电商零售、高科制造、企业服务等数十万行业客户量身打造了产品研发全生命周期解决方案，并帮助客户解决项目管理问题，提升研发效能。</p><p>&nbsp;</p><p>2022年12月，腾讯TAPD联合InfoQ、36kr等平台举办了「TAPD 思享汇」系列线上分享课，希望为客户企业搭建沟通与交流的桥梁，助力客户企业在各自的赛道上成为行业翘楚。2023年5月16日第二期「TAPD思享汇」，旨在探讨金融企业如何释放科技与数据价值，实现数字化敏捷转型。某头部券商精益敏捷教练于剑和刘健峰、五矿信托科技发展部质量中心负责人杨旭刚、某知名保险公司研发效能负责人罗冰鑫，分享了金融机构当前在数字化转型中的痛点，以及“牵手”研发项目管理平台腾讯TAPD后，在提升研发效能，缩短交付周期，实现组织协同方面的敏捷之变。</p><p><img src=\"https://static001.geekbang.org/infoq/e5/e55c7373116c24a01a9a0f825dc817e8.png\" /></p><p></p><h2>三大痛点困扰金融行业研发效能提升</h2><p></p><p>&nbsp;</p><p>无论是券商、信托，还是保险机构，普遍存在业务团队与研发团队之间信息割裂、流程不规范的问题。以五矿信托为例，在构建&nbsp;DevOps&nbsp;平台前，由于组织内部各个团队分别管理需求，使用的工具也没有统一，知识库和应用制品库相对割裂，难以统一管理。</p><p>&nbsp;</p><p>缺乏统一的研发协作工具，导致数据分散割裂，研发进度难以把控，也是不少金融机构面临的问题。罗冰鑫直言，一些保险机构的研发团队内部不仅面临老旧的技术栈、各个团队的协同能力参差不齐，而且在面对复杂的需求管理时，内部也有着繁琐复杂的流程。</p><p>&nbsp;</p><p>研发质量难以保证则是金融机构在研发管理中的又一难题。五矿信托在建立&nbsp;DevOps&nbsp;研发过程中，缺少全流程度量统计，端到端的跟踪报表甚至需要人工完成。由于缺少团队、个人的数据分析，衡量研发团队的产出成为一件难事。同时，不同团队之间的技术架构难以统一，研发人员需要聚焦多个框架，研发的效率和质量更是难以保证。</p><p></p><p>总体来看，业务与研发团队之间的割裂、缺乏统一的研发协作平台和质量保障机制不健全，成为制约金融机构研发效能提升的难题。</p><p></p><h2>TAPD“出鞘”提质增效</h2><p></p><p>&nbsp;</p><p>研发效能提升主要是解决好价值、效率、成本三者之间的关系，并实现可持续发展。某头部券商、五矿信托以及该知名保险公司利用TAPD的解决方案，结合各自的优势和业务特点，走出了一条敏捷研发的特色之路。</p><p>&nbsp;</p><p>对齐组织OKR，基于TAPD需求分层级管理，实现业务价值流快速流动。</p><p></p><p>某头部券商利用&nbsp;TAPD&nbsp;敏捷研发管理工具，实现了需求的分层与管理。于剑表示，“我们利用&nbsp;OKR&nbsp;管理，将数字化的战略目标通过层层分解，与部门、团队、个人的工作目标保持对齐，让每个角色有清晰的目标及可视化信息”，同时基于&nbsp;TAPD，对需求的源头做了分层分级管理，即分为管理层的需求池、部落层的需求池以及小队层面的需求池。“这样做的好处就是，业务人员在我们的需求池中提需求，研发团队与需求池建立关联。业务人员可以随时在&nbsp;TAPD&nbsp;系统中，查看需求当前的状态，无论是待开发、研发中还是已经部署上线，非常清晰明了。”</p><p><img src=\"https://static001.geekbang.org/infoq/3e/3e83d8acaa4e2bd3dddc0d05860b7075.png\" /></p><p></p><p>在于剑看来，研发的关键是要把任务需求与组织目标一一对应，而&nbsp;TAPD&nbsp;能够有效把企业目标和具体的实现需求进行层级分解，有利于提升研发效率和组织目标的达成。</p><p>&nbsp;</p><p>提升敏捷研发效率的关键在于关注人和流程。罗冰鑫分享到，她们通常采用访谈观察来识别各个团队上下游交互的规则，发现不同规模的团队都有各自的交互规则，不可避免地会造成信息壁垒，对此，她们的做法是借助&nbsp;TAPD&nbsp;需求分级，明确明细流程，形成规则，并确定优先级需求，然后深入团队内部做好培训，达成共识，并通过&nbsp;TAPD&nbsp;制定需求可视化看板，把涉及团队和项目进展定期公示，保证信息一致。</p><p><img src=\"https://static001.geekbang.org/infoq/da/da842517b8fc18bca70a8708aba9e672.png\" /></p><p></p><p>研发全生命周期管理，减少浪费，提升交付效率和质量。</p><p>&nbsp;</p><p>对于金融机构来说，不仅需要满足监管的合规要求，还有来自团队内部复杂多样的需求。“我们要基于产品全生命周期进行项目评估，而不是关注某一个指标。”罗冰鑫表示，“保险机构有着多样化的需求，从需求确定、设计开发，我们整个流程都是通过&nbsp;TAPD&nbsp;实现的，甚至将&nbsp;30&nbsp;多个系统放在同一&nbsp;TAPD&nbsp;项目下，有效减少了各个团队之间因为信息不对称导致的互相等待和浪费严重的问题。”</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/15/15c83e5fb132e822758e2a55b986f356.png\" /></p><p>&nbsp;</p><p>某头部券商基于TAPD工具集成，建立&nbsp;DevOps&nbsp;一体化平台。把&nbsp;UTP&nbsp;测试工具平台、DevOps流水线平台和研发一体化平台进行打通，统一度量平台和管控交付周期，建立适合团队的迭代规则，确保组织的整体提效。在TAPD系统中，不仅支持查看团队的迭代、指标情况，分析合理性和有效性数据，还能识别改进措施，推动基于度量的持续改进。&nbsp;</p><p>&nbsp;</p><p>推进企业级敏捷体系建设，提升研发效能。</p><p>&nbsp;</p><p>某头部券商借助&nbsp;TAPD，在内部标准、内部教练、内部平台进行规模化敏捷的探索，持续提升效能，并基于成熟度模型，针对不同的业务特点，建立了分层教辅策略，即“深专广”。所谓“深”即深度陪跑。一般会选择一些业务成熟度高的项目进行深度陪跑，通过这样的方式牵引成熟度的提升。“专”是指建立敏捷实战营，帮助团队实现专项能力的突破。目前已经覆盖产品创设、敏捷迭代、工程效能、测试质量等在内的多个领域。“广”是指广泛落地规范+平台赋能以整体提升效能。</p><p></p><p>以某一深度陪跑项目为例，通过&nbsp;TAPD&nbsp;拆解需求颗粒度和交付颗粒度，强化各团队度量平台数据运用和解读等实现多团队敏捷协同运作，建立产研运节拍，从上到下整体节奏对齐，经过三个月的精耕，质量、产能、交付效率等研发效能有了明显提升与进步，做到&nbsp;1&nbsp;周发布&nbsp;2&nbsp;次的灵活按需发布；月度平均产能即交付产品需求个数提升了&nbsp;66%；生产缺陷率下降&nbsp;33%；需求平均周期缩短&nbsp;44.1%。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/eb/eba6e8bf19674b98fae43e8e5077637b.png\" /></p><p>&nbsp;</p><p>TAPD&nbsp;在五矿信托的&nbsp;DevOps&nbsp;建设中同样发挥了重要的作用，尤其是加强了流程化体系建设，用统一的工具链实现稳敏双态开发、测试及发布流程，并导入过程管理、持续交付、测试管理等功能构建起全新的&nbsp;DevOps&nbsp;能力体系，确保项目质量与管理的“可视、可管、可控、可信”。同时，还支持用工具来反馈数据来源，减少人工干预，进行精益的敏捷管理与分析，更好的从体系层面支撑团队实践推广以提速增效。</p><p>不仅如此，五矿信托通过&nbsp;TAPD&nbsp;单点登录实现用户和组织的同步。在代码仓库上，通过工作项目&nbsp;ID&nbsp;能够与代码进行关联，并在&nbsp;TAPD&nbsp;上可以看到需求信息、开发信息和反馈信息，包括流水线的执行记录、测试用例以及一些&nbsp;bug&nbsp;情况。</p><p><img src=\"https://static001.geekbang.org/infoq/7f/7fe3f1dd0aac319a45770f06b340e0a6.png\" /></p><p></p><p>对于五矿信托而言，引入&nbsp;TAPD&nbsp;建设企业级的&nbsp;DevOps&nbsp;，将稳态、敏态相融合，缩短了研发周期，降低了需求研发、运维测试的协同成本。在跨团队信息共享上，增强了工具主动获取信息的作用，减少了沟通成本。</p><p>&nbsp;</p><p>得益于&nbsp;TAPD&nbsp;的敏捷协作，罗冰鑫和团队也明显感觉到交付效率、交付质量和交付能力的提升。数据显示，与&nbsp;2021&nbsp;年相比，产研交付周期缩短了&nbsp;10%，系统上线率提升了&nbsp;25%，每个阶段项目的月均完成率提升&nbsp;15%。</p><p></p><h2>结语</h2><p></p><p>&nbsp;</p><p>于剑所在的头部券商借助&nbsp;TAPD&nbsp;实现了敏捷的数字化转型，目前有&nbsp;95%&nbsp;以上的项目接入TAPD，效率持续提升。无论是从经营模式、管理模式、组织机构，还是响应速度、团队协同、思维模式上都带来了显著的改变。</p><p></p><p>五矿信托通过&nbsp;TAPD&nbsp;在建设&nbsp;DevOps&nbsp;平台过程中，不仅增加了数字化的分析能力，进一步完善了平台生态链，而且在这样的过程中减少了维护和高额成本的投入，实现了研发效率的提升。</p><p></p><p>罗冰鑫所在的保险机构利用&nbsp;TAPD&nbsp;实现了研发全生命周期的效能评估和管理，提升了整个组织效能。</p><p>以敏捷研发支撑业务变革，TAPD&nbsp;和这些金融机构一起，真正做到了让研发提质增效，使数字化转型之路“稳”“敏”兼具。</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-06-06 10:19:16",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "《大语言模型综合能力测评报告 2023》发布",
    "url": "https://www.infoq.cn/article/cuTAVv7W3CjkhiXZW0Y2",
    "summary": "<p>2022 年年末以来，人工智能大模型成为技术领域乃至全球创新领域最炙手可热的话题。以 ChatGPT 引领的大模型产品发展日新月异，有预测数据显示，到 2030 年，AIGC 的市场规模或将超过万亿人民币。2023 年国内主要厂商也相继推出自研的大语言模型产品，另外国内也推出了大量的大语言模型应用，逐步构建起基于中文语言特色的大语言模型生态。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/62/02/627bb129b9df54275169a17e75b9a002.png\" /></p><p></p><p>InfoQ 研究中心本次针对大语言模型产品的研发要素、大语言模型产品的核心特征进行研究， 并选取语言模型准确性、数据基础、模型和算法的能力、安全和隐私四个大维度，拆分出语义理解、语法结构、知识问答、逻辑推理、代码能力、上下文理解、语境感知、多语言能力、多模态能力、数据基础、模型和算法的能力、安全和隐私 12 个细分维度，分别对 ChatGPT、Claude、Sage、天工 3.5、文心一言、通义千问、讯飞星火、Moss、ChatGLM、vicuna-13B 进行了超过 3000+ 道题的评测。另外，本次研究特别关注了技术视角中大模型产品的编程能力，提高了问题的权重和比例；同时也专门设置了关于中文语境的特色测试题目， 如方言测试、中文特色推理、对对联等题目。InfoQ 研究中心希望可以通过本次测评帮助更多技术领域同仁获得对于中外大模型产品能力的逻辑认知，以帮助大家在 AGI 创业方向选择、工作实际应用等方面获得最新认知。</p><p></p><h3>研究结论</h3><p></p><p><img src=\"https://static001.infoq.cn/resource/image/e9/48/e991efc8c59437a674eyye48f1a78948.png\" /></p><p></p><h4>目录</h4><p></p><p>大语言模型发展背景大语言模型产品核心能力解读大语言模型产品测评结果和特征大语言模型产品未来发展展望</p><p></p><p>未来， InfoQ 研究中心还将继续持续关注大模型领域的持续发展，也欢迎各位行业内的专家就本报告的内容进行交流和讨论。下半年， InfoQ 研究中心还将推出关于大模型应用的研究报告， 欢迎正在该领域耕耘的厂商报名参与案例的制作和报告的研发工作。</p><p></p><p>识别下图二维码，立即获得大语言模型、AGI 创业方向选择、工作实际应用的最新认知吧！</p><p><img src=\"https://static001.geekbang.org/infoq/a9/a9d06275dc95a7ec864fc7f3d6990817.jpeg\" /></p><p></p>",
    "publish_time": "2023-06-06 11:36:43",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "微软Fabric正式发布，面向人工智能时代的数据分析",
    "url": "https://www.infoq.cn/article/ljYBv7FS7UCtPpIlkMdx",
    "summary": "<p>近日，微软推出了微软 Fabric 国际版——一个端到端的统一数据分析平台，汇集了企业需要的所有数据和分析工具。Fabric 将&nbsp;Azure 数据工厂、Azure&nbsp;Synapse Analytics&nbsp;和&nbsp;Power BI&nbsp;等技术集成到一个统一的产品中，能够让数据和业务专员更好地发掘、探索企业的数据，也为人工智能时代的到来奠定了基础。</p><p></p><p>人类正在进入由人工智能定义的新时代，数据的重要性愈发不言而喻。人工智能的应用正在融入工作中的方方面面，重新定义工作方式，这更需要纯净的数据与高度集成的分析系统进行支撑。然而，大多数企业正在使用的数据分析系统却像迷宫一样复杂。</p><p></p><p>这并不令人意外，因为大数据和人工智能技术市场高度分散，拥有数百个供应商和成千上万种服务。客户需要自行整合这些来自不同供应商的、彼此独立的服务，还要承担让这些服务协同运行的成本。</p><p></p><p>Fabric 是一个端到端的分析平台，涵盖了组织在数据分析中各个方面的需求。而下面这五个方面的特点，让 Fabric 在市场中脱颖而出：</p><p></p><h2>Fabric 是一个完整的分析平台</h2><p></p><p></p><p>每个分析项目都有多个子系统，每个子系统需要不同的能力组合，通常需要使用来自多个供应商的产品。集成这些产品的过程可能会非常复杂、不稳定且昂贵。&nbsp;</p><p></p><p>有了 Fabric，客户只需要使用这一款产品，它具有一体化的用户体验和架构，提供了开发人员从数据中提取有价值信息并最终呈现给用户所需要的所有功能。通过自动集成和优化所有内容，提供独特的用户体验，用户只需用几秒钟注册，就可以体验其中蕴含的商业价值。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/76/76b8b5cae5fdb50cc708c75ac47c7d5d.png\" /></p><p></p><p>Fabric 为不同角色的团队成员提供了符合其需求的特定体验，因此无论是数据工程师、数据仓库专员、数据科学家、数据分析师、还是业务用户，都能得心应手地使用 Fabric。</p><p></p><h2>Fabric是以数据湖为核心的开放平台</h2><p></p><p></p><p>数据湖非常混乱且复杂，用户难以创建、整合、管理和操作。而且，一旦数据湖开始运行，使用不同数据格式的不同数据产品部署在同一个数据湖中，可能会导致严重数据重复以及企业对供应商的依赖。</p><p></p><p>OneLake数据的 Onedrive</p><p></p><p>Fabric 内置了一款叫做&nbsp;OneLake&nbsp;的多云数据湖，所有 Fabric 都可直接使用。所有Fabric的工作都会自动与 OneLake 连接，就像所有的 Microsoft 365 应用程序与 OneDrive 连接一样。数据会在一个直观的数据中心进行组织，并自动建立索引，以供发现、共享、治理和进行合规性管理。</p><p></p><p>OneLake 同时为开发人员、业务分析师和业务用户提供服务，有助于消除因为不同开发人员自行配置和管理自己的独立存储账户而造成的数据孤岛现象。OneLake 为所有开发人员提供了一个单一、统一的存储系统，在该系统中，数据的发现和共享会变得更容易，并可以通过集中执行的策略和安全设置来管理。</p><p></p><p>OneLake 的一个关键功能是“快捷方式（Shortcuts）”。OneLake 允许用户和应用程序在不必要地移动和复制信息的情况下轻松共享数据。快捷方式使得 OneLake 可以在&nbsp;ADLSg2、Amazon Simple Storage Service&nbsp;(Amazon S3)和Google Storage（即将推出）中虚拟化数据湖存储，使开发人员能够跨云平台组合和分析数据。</p><p></p><p>采用开放的数据格式进行分析</p><p></p><p>Fabric 在所有的工作和层面上都致力于采用开放的数据格式。Fabric 将 Delta 和 Parquet 文件视为原生数据格式，并将其作为所有工作的默认格式。这种对共同开放数据格式的坚持意味着客户只需将数据加载到数据湖中一次，所有的工作都可以在同一份数据上操作，而不需要单独导入数据。这也意味着 OneLake 支持任何格式的结构化数据和非结构化数据，为客户提供了灵活的选择。</p><p></p><p>通过将 OneLake 作为我们的存储系统，并将 Delta 和 Parquet 作为所有工作的通用格式，我们为客户提供了在最基本层面上统一的数据堆栈。客户不需要为数据库、数据湖、数据仓库、商业智能或实时分析维护不同的数据副本。相反，在&nbsp; OneLake &nbsp;中只需要维护一份数据副本，就可以直接为所有工作提供支持。</p><p></p><p>对于客户来说，在不同数据引擎之间管理数据安全（表级、列级和行级）可能会很痛苦。Fabric 提供了一个通用的安全模型，该模型在 OneLake 中进行管理，并且所有引擎在处理查询和作业时会统一执行这个模型。这一模型即将发布。</p><p></p><h2>Fabric 是以人工智能技术驱动的平台</h2><p></p><p></p><p>Fabric 在各个层面都融入了&nbsp;Azure OpenAI&nbsp;服务，旨在帮助客户充分发掘其数据的潜力，使开发人员能够利用人工智能技术对其数据进行分析，并帮助业务用户深入了解数据。在 Fabric 的数据体验中，通过&nbsp;Copilot，用户可以使用对话式语言来创建数据流和数据管道、生成代码和完整的函数、构建机器学习模型或可视化结果。客户甚至可以创建自己的对话式语言体验，将 Azure OpenAI &nbsp;服务模型与其数据相结合，并将其作为插件发布。</p><p></p><p>Fabric 的 Copilot 建立在我们对企业数据安全和隐私的现有承诺的基础上。Copilot 会集成组织的安全、合规和隐私政策。微软承诺不会使用用户数据来训练支持 Copilot 的基础语言模型。</p><p></p><h2>Fabric 为所有角色赋能</h2><p></p><p></p><p>客户希望在企业中建立数据文化，使每个人都能基于数据做出更好的决策。为了帮助客户培养这种文化，Fabric 与人们每天都使用的&nbsp;Microsoft 365&nbsp;应用程序进行了深度集成。</p><p></p><p>Power BI&nbsp;是 Fabric 的核心组成部分，并已经在 Microsoft 365 中广泛应用。通过 Power BI 与诸如 Excel、Microsoft Teams、PowerPoint 和 SharePoint 等流行应用程序的深度集成，用户可以轻松地从 Microsoft 365 中发现和访问来自 OneLake 的相关数据，帮助客户从数据中获得更多的价值。这样的集成使用户能够在他们已经熟练使用的 Microsoft 365 工具中直接访问和分析数据，提高了数据的可发现性和可用性，帮助客户充分发挥数据的潜力，从而推动其业务获得更大的价值。</p><p></p><h2>Fabric 通过统一容量降低成本</h2><p></p><p></p><p>目前的分析系统通常会将来自多个供应商的产品组合在一个项目中。这导致计算的资源在数据集成、数据工程、数据仓库和商业智能等多个系统中进行分配。当其中一个系统处于空闲状态时，其算力无法被其他系统利用，从而造成了巨大的资源浪费。</p><p></p><p>Fabric 极大地简化了购买和管理资源。客户可以购买一种能够为所有 Fabric 工作供能的算力池。采用这种全包的方式，客户可以自由地创建解决方案，整合各种工作，而不需要面临复杂的集成或协调问题。统一的算力容量大大降低了成本，因为任何一个工作负载中未使用的算力都可以被其他工作负载利用。这种统一容量的使用方式使资源的利用更加高效，从而最大程度地降低了成本。</p><p></p><p>Fabric 目前处于海外版预览阶段。用户可以通过注册免费试用 Fabric 海外版来体验 所有功能。每个注册用户都可以获得固定的 Fabric 试用容量，可用于集成数据、创建机器学习模型等任何功能。现有的 Power BI Premium 客户可以通过 Power BI 管理门户启用 Fabric。2023年7月1日后，Fabric 将对所有 Power BI 租户启用。<a href=\"https://app.fabric.microsoft.com/singleSignOn?clientSideAuth=0&amp;ru=https:%2f%2fapp.fabric.microsoft.com%2f%3fclientSideAuth%3d0%26noSignUpCheck%3d1\">点击链接，即可报名注册免费试用微软 Fabric。</a>\"</p>",
    "publish_time": "2023-06-06 11:59:24",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "响应式编程的复杂度和简化",
    "url": "https://www.infoq.cn/article/d821b9fbb1bfdb04d9e067e8b",
    "summary": "<p>作者：蒋文豪</p><p></p><p></p><blockquote>响应式系统不是今天的主题，我们要讨论更具体的话题，即响应式代码的编写会有哪些复杂度，应该如何简化。</blockquote><p></p><p></p><p></p><h1>一、什么是响应式编程</h1><p></p><p></p><p>什么是响应式编程，它是一种编程范式？还是一种设计模式？抑或是其他？响应式系统和响应式编程有什么关系？又比如，响应式编程它适用于什么场景？解决什么问题？</p><p></p><p>微软于2011年率先建设了.Net上的Rx库，以简化容易出错的异步和事件驱动编程，迈出了响应式编程的第一步，随后业界为许多编程语言提供了对应的实现。</p><p></p><p>.Net上的Rx库地址：https://docs.microsoft.com/en-us/previous-versions/dotnet/reactive-extensions/hh242985(v=vs.103)</p><p></p><p>什么是响应式，我们从一个例子开始。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f3/f3692ba7c4cf70bc9ef472a6f78d709c.jpeg\" /></p><p></p><p>在上面的表格中，建立了单元格之间的关系：A1 = B1 + C1，建立关系之后A1将响应任何对于B1和C1的变化，毫无疑问，这就是一种响应式行为。</p><p></p><p>我觉得这个例子很棒的地方在于，它显然很简单，同时又足够深刻，首先，它充分的体现了响应式的概念，其次，变化发生时，肯定触发了某些过程的执行，说明背后存在关系的建立和沿着关系传播的变化，再次，稍微深入一点看，B1和C1的变化可以是一系列的变化，可以很自然的引申到流的概念，最后，它有一个很高级的抽象，对使用方来说，整个过程是声明式的。</p><p></p><p>当然，举例子来说明一个概念的时候，本质上是用一个外延在解释一个概念的内涵，往往是会将内涵缩小的，所以我们可以尝试推广这个外延。列出这个例子的特征：</p><p></p><p>描述了一个单元格里的整数等于另外两个单元格里整数相加，当后者每次发生变化时，变化都会传播到第一个单元格，并进行求值。</p><p></p><p>关键词为整数、等于、相加、变化、每次、传播、求值。前三个关键词仅仅和例子相关，可以直接去掉。变化可以推广为数据，每次可以在逻辑上等价于流的概念，流可以有0个、1个或多个数据，传播可以推广为通信（在这个意义上，函数调用、RPC、socket、MQ都是通信），求值推广为执行一个过程。所以我们可以得出响应式编程的定义：</p><p></p><p>通过声明式的通信定义，将数据流与过程组合起来，从而实现数据驱动过程的一种复合编程范式。</p><p></p><p>时至今日，业界对于响应式的定义仍然是不统一的，因此这是我自己的理解。响应式的基础概念是数据流，理念是过程的执行是通过响应数据来驱动的，核心是构造数据和过程的响应关系，并且能够让数据沿着关系传播驱动过程，因此响应式编程本质上是一种对通信的抽象，说它是一种编程范式，是因为它提供一种对于数据与过程组合方式的看法，说它是复合范式而不是基本范式，是因为它不像OOP或者FP一样提供的是对于数据和过程的看法，而是以两者为基础，所以可以有对象响应式和函数响应式。</p><p></p><p>当我们基于响应式构建系统时，就是响应式系统，响应式系统的构建原则可以参考此处（地址：https://www.reactiveprinciples.org/patterns/communicate-facts.html），总的来说，系统会分割成一个一个的分区，分区内部对状态进行本地化，分区之间通过通信进行异步解耦，可以通过控制这个通信的过程，实现系统的弹性扩缩容和部分组件失败的回弹性。</p><p></p><p>响应式系统不是今天的主题，我们要讨论更具体的话题，即响应式代码的编写会有哪些复杂度，应该如何简化。</p><p></p><p></p><h1>二、响应式编程的复杂度</h1><p></p><p></p><p>响应式编程的复杂度来自于4个方面：</p><p></p><p>可以有0次、1次或多次数据产生，也就是数据流；除了数据之外，还有能够标识错误和完成（正常结束）；数据流和数据流、数据流和过程的组合复杂度很高；在上面的基础上，需要处理整个过程中线程切换、并发同步、数据缓冲等问题。</p><p></p><p>为了支持数据流的概念，可以产生0次、1次或多次数据产生，API设计需要把数据回调和结果回调分开，通常也会把错误回调和完成回调分开，这种接口被称为流式接口，一个标准的流式接口设计如下所示：</p><p></p><p><code lang=\"text\">typealias Func = () -&gt; ()\ntypealias OnData = (Data) -&gt; ()\ntypealias OnError = (Error) -&gt; ()\ntypealias OnComplete = Func\ntypealias StreamFunc = (@escaping OnData, @escaping OnError, @escaping OnComplete) -&gt; ()</code></p><p></p><p>显然，流式接口是普通异步接口将一次结果向多次结果的推广，这种推广同时也增加了逻辑的复杂度。</p><p></p><p>我们可以通过一个逻辑上简单的例子来看一下流式接口的使用过程，为了关注于核心的复杂度，只会体现前3个方面，一方面是由于加入第4点的话会导致代码过于冗长混淆关注点，另一方面相信各位对第4点本身的复杂度和它引起的众多问题已经非常熟悉了。</p><p></p><p>这个例子很简单，只有三步：</p><p></p><p>1）﻿假设需要为一个店铺提供一个订单展示页面，这些订单来自两个不同的平台“鹅鹅鹅”和“鸭鸭鸭”，他们各自提供了查询的接口（listOrders，为了简单假设他们提供的模型和接口完全一致）；</p><p></p><p>2）订单列表需要展示用户的昵称等信息，需要通过对应平台的另外一个接口（queryUserInfo）查询；</p><p></p><p>3）由于SDK缓存、持久化、网络请求策略，数据无法一次性获取，这两个接口可能存在多次数据回调。</p><p></p><p>进一步简化问题，我们忽略变更处理、UI渲染和用户交互处理，仅仅考虑数据加载，这需要组合2个阶段的4次接口调用，先分别请求两个平台的订单，使用订单请求对应平台的userInfo，最后合并成完整数据：</p><p></p><p><code lang=\"text\">// 数据怎么回调，什么情况结束，onError和onComplete分别在什么情况回调，保证有且仅有一次回调\nfunc load(onData : OnData&lt;[OrderObject]&gt;?, onError : OnError?, onComplete : OnComplete?) {\n    let orderServices = [OrderService(\"鹅鹅鹅\"), OrderService(\"鸭鸭鸭\")]\n    // 记录整体请求的完成状态\n    var listOrderFinish = false\n    var queryUserFinish = false\n    // 记录各个请求的结果\n    var listOrderResults = orderServices.map{_ in false}\n    var queryUserResults = [Bool]()\n    for (index, orderService) in orderServices.enumerated() {\n        orderService.listOrders { orders in\n            // 已结束不处理\n            if (listOrderFinish) {\n                return;\n            }\n​\n            let index = queryUserResults.count\n            queryUserResults[index] = false\n            if let userService = getUserService(site: orderService.site){\n                let userIds = orders.map { order in\n                    order.userId\n                }\n​\n                userService.queryUserInfo(userIds: userIds) { userInfoDict in\n                    if (listOrderFinish &amp;&amp; queryUserFinish) {\n                        return;\n                    }\n​\n                    let orderObjects = orders.map { order in\n                        OrderObject(order: order, userInfo: userInfoDict[order.userId])\n                    }\n                    onData?(orderObjects)\n                } onError: { error in\n                    // 如果是第一个错误，直接回调，同时标记为结束\n                    if (!listOrderFinish || !queryUserFinish) {\n                        listOrderFinish = true\n                        queryUserFinish = true\n                        onError?(error)\n                    }\n                } onComplete: {\n                    // 外层结束，内层也结束，才是最终结束\n                    if (!listOrderFinish || !queryUserFinish) {\n                        queryUserResults[index] = true\n                        // 所有都结束，回调\n                        if (listOrderFinish &amp;&amp; !queryUserResults.contains(false)) {\n                            listOrderFinish = true\n                            onComplete?()\n                        }\n                    }\n                }\n            } else {\n                let orderObjects = orders.map { order in\n                    OrderObject(order: order)\n                }\n                onData?(orderObjects)\n​\n                queryUserResults[index] = true\n                // 所有都结束，回调\n                if (listOrderFinish &amp;&amp; !queryUserResults.contains(false)) {\n                    listOrderFinish = true\n                    onComplete?()\n                }\n            }\n        } onError: { error in\n            // 如果是第一个错误，直接回调，同时标记为结束\n            if (!listOrderFinish) {\n                listOrderFinish = true\n                onError?(error)\n            }\n        } onComplete: {\n            // 注意，即使所有的请求都结束了，也不能回调结束，因为这里的结束只是代表Order请求结束，userInfo请求不一定结束\n            if (!listOrderFinish) {\n                listOrderResults[index] = true\n                // 所有都结束，回调\n                if (!listOrderResults.contains(false)) {\n                    listOrderFinish = true\n                }\n            }\n        }\n​\n    }\n}</code></p><p></p><p>在这个接口的实现中，数据回调最简单，在没有结束的情况下，多次回调的数据可以直接回调，问题是如何保证错误和完成有且仅有一次回调，且结果回调后不再回调数据，即：</p><p></p><p>什么时候回调错误？什么时候回调完成？</p><p></p><p>如果我们认为一个接口出错，就回调错误，这是最简单的错误处理，只需要检查和设置结束状态，在没有结束时的第一个错误进行回调即可，注意，我们需要在userInfo的请求中也做类似的处理，并保证错误回调后不再执行任何回调。</p><p></p><p>完成的回调要比错误复杂的多，我们可以来思考一下：</p><p></p><p>首先，我们不能在listOrders的onComplete里面取回调完成，因为这里不能代表queryUserInfo这个接口也完成了；其次，我们也不能简单的通过所有queryUserInfo都完成了就回调完成，因为listOrders在完成前仍然有可能返回新的订单数据。</p><p></p><p>也就是说，这里的完成需要在queryUserInfo进行判断，并且也需要考虑外层请求的完成情况，比普通异步接口的级联要多了两个维度。这仅仅是2种接口4次请求，在真实的编程中，接口数量会多得多，并且需要把第4点加进来，线程/队列、并发、同步、缓冲区，还要处理新数据推送响应，再考虑调试、监控、排查，复杂度显然会继续大幅增长，保证这个过程的正确性是一件痛苦的事情。</p><p></p><p></p><h1>三、响应式编程的复杂度使用Rx/Combine简化响应式编程</h1><p></p><p></p><p>为了解决这些问题，业界搞出了Reactive Streams规范（地址：https://www.reactive-streams.org/），也出现了若干的实现，都以工具库的形式提供，包括Rx系列、Reactor，以及苹果功能类似的Combine。作为一个iOS开发，我对RxSwift和Combine比较了解，两者主要的区别在于Combine多了一个Subscription的抽象来协调Publisher和Subscriber之间的行为，尤其是Back Pressure相关的控制，但总的来说，都提供了对于异步数据流的抽象和组合能力，用法上也很类似，这里以RxSwift为例来重写上面的过程。</p><p></p><p>第一步，实现一个将流式函数转换成Observable的工具类，这个是通用的，非常直观：</p><p></p><p><code lang=\"text\">func makeObservable(f : @escaping StreamFunc) -&gt; Observable {\n    Observable.create { observer in\n        f { data in\n            observer.onNext(data)\n        } _: { error in\n            observer.onError(error)\n        } _: {\n            observer.onCompleted()\n        }\n        return Disposables.create()\n    }\n}</code></p><p></p><p>第二步，针对这个例子，将listOrder和queryUserInfo转换成StreamFunc形式，listOrder本来就是StreamFunc，对queryUserInfo进行偏应用也可以转换为StreamFunc形式，这是具体接口相关的：</p><p></p><p><code lang=\"text\">func makeStreamFunc(orders : [Order], userInfoService : UserService?) -&gt; StreamFunc&lt;[OrderObject]&gt; {\n    if let userInfoService = userInfoService {\n        // 核心是对queryUserInfo的userIds参数进行偏应用\n        let userInfoF : StreamFunc&lt;[OrderObject]&gt; = { onData, onError, onComplete in\n            let userIds = orders.map{$0.userId}\n            userInfoService.queryUserInfo(userIds: userIds, onData: { userInfoDict in\n                let orderObjects = orders.map { order in\n                    OrderObject(order: order, userInfo: userInfoDict[order.userId])\n                }\n                onData(orderObjects)\n            }, onError: onError, onComplete: onComplete)\n        }\n        return userInfoF\n    } else {\n        return { onData, onError, onComplete in\n            onData(orders.map{OrderObject(order: $0)})\n            onComplete()\n        }\n    }\n}</code></p><p></p><p>第三步，这样就可以将load方法简化为：</p><p></p><p><code lang=\"text\">func rxLoad() -&gt; Observable&lt;[OrderObject]&gt; {\n    let orderService = [OrderService(\"鹅鹅鹅\"), OrderService(\"鸭鸭鸭\")]\n​\n    // 通过map构造Observable，通过flatMap对listOrder和queryUserInfo进行复合\n    let observables = orderService.map { orderService in\n        makeObservable(f: orderService.listOrders).flatMap { (orders) -&gt; Observable&lt;[OrderObject]&gt; in\n            let userLoadF = makeStreamFunc(orders: orders, userInfoService: getUserService(site: orderService.site))\n            return makeObservable(f: userLoadF)\n        }\n    }\n​\n    // merge两个平台的Observable\n    return Observable.merge(observables)\n}</code></p><p></p><p>可以看到，第一步是通用的，实际代码中只需要做第二步和第三步，这就对上面的接口进行了大量的简化，并且库以统一的方式处理掉了合并、级联、多数据返回的复杂逻辑，我们有相当的把握来保证正确性。当然，除了学习成本较高以外，也还是有缺点的，主要是使用方式仍然是异步形式，在部分环节仍然需要处理异步带来的复杂度：</p><p></p><p><code lang=\"text\">// 使用方调用\nrxLoad().subscribe { orderObjects in\n    // onNext闭包中处理数据\n} onError: { error in\n    // onError闭包中处理错误\n} onCompleted: {\n    // onCompleted闭包中处理完成\n} onDisposed: {\n​\n}</code></p><p></p><p>Rx确实大大简化了异步编程，但是还不够，因为它的使用仍然是异步形式。</p><p></p><p></p><h1>四、使用AsyncSequence简化响应式编程</h1><p></p><p></p><p></p><h2>4.1 迭代器与序列</h2><p></p><p></p><p>迭代器是很多语言都有的一个概念，一个迭代器的核心是next()函数，每次调用都会返回下一个数据，这些数据构成了一个序列（Sequence），迭代器也意味着序列可以被遍历。</p><p></p><p></p><h2>4.2 异步序列</h2><p></p><p></p><p>如果让迭代器的next()方法支持异步，就产生了异步序列。Swift对此提供了一个AsyncSequence的协议，并对它提供了语言级别的支持，使得开发者可以以同步的形式遍历一个异步序列：</p><p></p><p><code lang=\"text\">for try await data in asyncDataList {\n    print(\"async get data : + \\(data)\")\n}</code></p><p></p><p>实际上，Swift在Combine中支持了Publisher的同步遍历：</p><p></p><p><code lang=\"text\">// Combine的同步调用\nfor try await data in publisher.values {\n    print(\"async get publiser value \\(data)\")\n}</code></p><p></p><p></p><h2>4.3 CPS变换</h2><p></p><p></p><p>如果能将流式接口转换为异步序列，那么就可以实现响应式代码的同步编写，这个转换过程可以通过CPS变换实现。</p><p></p><p>CPS变换全称Continuation-Pass-Style，这个概念来自Lisp语系，是一种显式传递控制流的编程风格，其传递控制流的载体就是continuation。continuation可以理解为当前代码执行的后续，如果一个函数f有一个continuation参数，我们就可以把当前的continuation传递进去，当函数产生结果时，通过continuation回到函数f外，继续执行，这种函数调用方式成为call/cc（call with current continuation）。</p><p></p><p>这种变换，称为CPS变换。</p><p></p><p>作为一个类比，我觉得可以将continuation理解为return的在两个方面的推广形式，首先，continuation是first-class的，可以作为变量存储，可以作为函数的参数和返回值，其次，continuation可以多次使用，而return只能有一次。</p><p></p><p></p><h2>4.4 响应式编程的同步形式</h2><p></p><p></p><p>回头看最原始的代码，当我们调用orderService.listOrders时，传进去的callback，其实就相当于一个弱化版的continuation。这意味着，如果我们可以将使用continuation将数据表示为AsyncSequence，那么就可以将响应式代码写成同步形式，从而大幅简化响应式编程。</p><p></p><p>Swift提供了continuation的概念，提供了AsyncStream和AsyncThrowingStream来实现这个过程，对上节Rx的实现稍作改动即可。</p><p></p><p>第一步，实现一个将流式函数转换成AsyncThrowingStream的工具类，这个是通用的：</p><p></p><p><code lang=\"text\">func makeSequence(f : StreamFunc) -&gt; AsyncThrowingStream {\n    AsyncThrowingStream{ continuation in\n        f { data in\n            continuation.yield(data)\n        } _: { error in\n            continuation.finish(throwing: e)\n        } _: {\n            continuation.finish()\n        }\n    }\n}</code></p><p></p><p>第二步，由于AsyncSequence还不支持merge，需要自己实现一个merge工具方法来实现多个流的组合，这个也是通用的：</p><p></p><p><code lang=\"text\">//多个AsyncSequence merge成一个AsyncSequence\nfunc mergeSequence(seqs : [Seq]) -&gt; AsyncThrowingStream {\n    makeSequence(f: mergeF(fs: seqs.map(makeLoadFunc)))\n}\n​\nfunc makeLoadFunc(ats : Seq) -&gt; StreamFunc{\n    { onData, onError, onComplete in\n        Task {\n            do {\n                for try await data in ats {\n                    onData(data)\n                }\n                onComplete()\n            } catch {\n                onError(error)\n            }\n        }\n    }\n}\n​\nfunc mergeF(fs : [StreamFunc]) -&gt; StreamFunc {\n    { onData, onError, onComplete in\n        var finish = false\n        var results = fs.map{_ in false}\n        for (index, f) in fs.enumerated() {\n            f { data in\n                if (!finish) {\n                    onData(data)\n                }\n            } _: { e in\n                // 如果是第一个错误，直接回调，同时标记为结束\n                if (!finish) {\n                    finish = true\n                    onError(e)\n                }\n            } _: {\n                // 注意，即使所有的请求都结束了，回调成功\n                if (!finish) {\n                    results[index] = true\n                    // 所有都结束，回调\n                    if (!results.contains(false)) {\n                        finish = true\n                        onComplete()\n                    }\n                }\n            }\n        }\n    }\n}</code></p><p></p><p>第三步，将listOrder和queryUserInfo转换成StreamFunc形式，与Rx中的第二步实现完全相同；</p><p></p><p>第四步，这样就可以将load方法简化为：</p><p></p><p><code lang=\"text\">func asLoad() -&gt; AsyncThrowingStream&lt;[OrderObject], Error&gt; {\n    let orderService = [OrderService(\"鹅鹅鹅\"), OrderService(\"鸭鸭鸭\")]\n​\n    // 通过map构造AsyncSequence，通过flatMap对listOrder和queryUserInfo进行复合\n    let streams = orderService.map { orderService in\n        makeSequence(f: orderService.listOrders).flatMap { (orders) -&gt; AsyncThrowingStream&lt;[OrderObject], Error&gt; in\n            makeSequence(f: makeLoadFunc(orders: orders, userInfoService: getUserService(site: orderService.site)))\n        }\n    }\n​\n    // merge两个平台的AsyncSequence\n    return mergeSequence(seqs: streams)\n}</code></p><p></p><p>可以发现，代码与RxSwift几乎是完全相同的，所以我们仍然有对于代码正确性的信心，不同的是，现在使用方也得以获得同样的信心：</p><p></p><p><code lang=\"text\">for try await orderObject in asLoad() {\n    print(\"async get orderObject \\(orderObject.first?.order.orderId)\")\n}</code></p><p></p><p></p><h1>五、总结</h1><p></p><p></p><p>同步是编程中的田园世界，而流式接口作为异步接口最复杂的形态，我们通过CPS变换的控制流技术，将流式接口表示为AsyncSequence，实现了对异步序列遍历的同步形式，从而将响应式编程在形式上统一回了田园世界。</p><p></p><p>上面的第一步和第二步实现了AsyncSequence和StreamFunc的相互转换，所以实际上我们证明了它们是同构的，更进一步的，我们可以证明它们与Rx、Combine也是同构的。换言之，它们是同一个概念的不同形式，理论上它们的表达能力是等价的，这个概念就是数据流，这个概念在Rx中叫做Observable，在Combine中叫做Publisher。</p><p></p><p>在实际实现上，Rx和Combine提供了大量的操作符，因此目前它们的能力远远强于AsyncSequence和StreamFunc，比如AsyncSequence居然不支持merge。</p><p></p><p>AsyncSequence的优势是可以支持同步写法，在我看来这个优势是很大的。看到社区有过AsyncSequence替换Combine的相关的讨论，我认为逻辑上是讲得通的。</p><p></p><p>AsyncSequence替换Combine的相关讨论地址：https://forums.swift.org/t/should-asyncsequence-replace-combine-in-the-future-or-should-they-coexist/53370</p>",
    "publish_time": "2023-06-06 14:23:44",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "苹果发布革命性的操作系统visionOS：这是从“sudo”到“Siri”的改变",
    "url": "https://www.infoq.cn/article/h1TXPvJWSZLPqHvajCUa",
    "summary": "<p>今天，在一年一度的WWDC全球开发者大会上，苹果发布了一款名为 Vision Pro 的增强现实耳机，这是 Tim Cook自 2011 年上任以来，继 Apple Watch 之后的第二个主要产品线扩展。</p><p>&nbsp;</p><p>Tim Cook告诉听众：“这一天我们期待已久。” “我相信增强现实是一项深奥的技术。将数字内容与现实世界融合可以解锁前所未有的体验。”</p><p>&nbsp;</p><p>“Vision Pro 是一种新型计算机。这标志着计算新时代的开始。”“Mac 带来了个人计算，iPhone 带来了移动计算，而 Apple Vision Pro 为我们带来了空间计算。”</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b5/b5f96bf13b4c2b9f6b2b4baa13286f73.png\" /></p><p></p><p>&nbsp;</p><p>Apple Vision Pro 足够轻薄，外形酷似滑雪护目镜，还具有一个外向显示屏，可以通过 EyeSight 系统显示眼球运动和面部表情。当用户正在通过 Vision Pro 查看内容时，显示屏会出现光环闪烁，向其他人表明这位用户正沉浸在 AR 世界中。但当任何人或物体进入视线之内，Vision Pro 会将其聚焦。&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e3/e36cf78a943e99afee0a06087082b200.png\" /></p><p></p><p>&nbsp;</p><p>苹果表示， Vision Pro 是苹果数十年高性能、移动和可穿戴设备设计经验的结晶，最终造就了 苹果有史以来最雄心勃勃的这一产品，它可以改变沟通、写作、工作、娱乐等场景。</p><p>&nbsp;</p><p>Vision Pro 售价 3499 美元（约 24860 元人民币），将于明年上市。</p><p>&nbsp;</p><p></p><h2>革命性的操作系统</h2><p></p><p>&nbsp;</p><p>正如 iPhone、iPad、Mac 和 Apple Watch 一样，Apple 硬件性能的好坏取决于它所基于的操作系统。为了匹配 Vison Pro，苹果今天也发布了与之相配的操作系统 VisonOS，称之为“世界上第一个空间操作系统”。</p><p>&nbsp;</p><p>visionOS 建立在 macOS、iOS 和 iPadOS 的基础上，包括了 iOS 和空间框架、多应用 3D 引擎、音频引擎、专用渲染器子系统和实时子系统。在架构层面，visionOS 与 MacOS 和 iOS 共享核心模块，新增加的“实时子系统”，用于处理 Apple Vision Pro 上的交互式视觉效果。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5e/5ee55d086504a3100906cc6cb3ffd548.png\" /></p><p></p><p>&nbsp;</p><p>visionOS 具有全新的三维界面，让用户在物理世界中看到并感受数字内容。新的三维界面将应用程序从传统显示器的边界中解放出来，让它们可以以不同的比例并排显示，通过动态响应自然光和投射阴影，它可以帮助用户了解比例和距离。</p><p>&nbsp;</p><p>与其他 AR/VR 操作系统不同，visionOS 真正改变了用户操作 Vision Pro 耳机的方式。苹果无控制器输入系统消除了对任何额外硬件组件的需求。要与 UI、应用程序或其他操作系统组件进行交互，你可以通过简单地注视、轻敲手指或使用语音指令来浏览应用程序。</p><p>&nbsp;</p><p>具体来说，首先你只需要看向虚拟空间中的应用程序或按钮。然后将手指悬停在空中，Vision Pro 耳机将毫无延迟地响应你的手势。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/72/7261a6f497d4d867b032c4540124b2e8.jpeg\" /></p><p></p><p>&nbsp;</p><p>为此，苹果在机身上放置了12 部摄像头、5 个传感器和 6 个麦克风组成的传感器阵列，捕捉动作，让用户无需遥控器或者手柄，就可以通过眼神的挪动，手指的开合以及语音指令与 Apple Vision Pro 进行交互。</p><p>&nbsp;</p><p>visionOS还包含两个4K 分辨率的微型 OLED 屏幕（每只眼睛 5120x4096？每只眼睛的像素比 4K 电视还多！）将12个摄像头、三块屏幕（加上外向显示屏）集中在同一个设备上，实际上是一个前所未闻的产品设计方式。Apple Vision Pro 还用了一颗 R1 芯片，解决画面的延迟和抖动问题，R1 可在12 毫秒内将新影像串流至显示器，比眨眼还要快 8 倍。</p><p>&nbsp;</p><p>而要让这么多硬件联动起来发挥出作用，让计算变得无处不在，背后的操作系统必须同样优秀。Apple 技术开发副总裁 Mike Rockwell 说，“通过硬件和软件的紧密集成，我们设计了一款紧凑型可穿戴外形的独立空间计算机，这是有史以来最先进的个人电子设备。”</p><p>&nbsp;</p><p>更为夸张的是，苹果还将机器学习融入到了产品中。根据苹果的一位前设计师发布的推文，我们还可以看出Vision Pro并不是简单地响应，它还会进行“预测”：</p><p>&nbsp;</p><p></p><blockquote>“最酷的结果之一是会用户实际行动之前预测用户会点击某些东西。这是一项艰巨的工作，也是我引以为豪的事情。你的瞳孔在你点击之前会做出反应，部分原因是你自己会预测在你点击之后发生的事情。因此，苹果可以通过监视用户的眼睛行为，并实时重新设计 UI 以创建更多这种预期的瞳孔反应，从而创建用户大脑的生物反馈。这是一个通过眼睛进行的粗糙的脑机接口，但非常酷。”</blockquote><p></p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3c/3c5b61c226d0211728aee057bbf269d8.jpeg\" /></p><p></p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e3/e38a87f938828574dcbec3b6871800fa.jpeg\" /></p><p></p><p>&nbsp;</p><p>截图来源：<a href=\"https://twitter.com/sterlingcrispin/status/1665792422914453506\">https://twitter.com/sterlingcrispin/status/1665792422914453506</a>\"</p><p>&nbsp;</p><p>&nbsp;</p><p>同时，该操作系统也一样注重安全和隐私，系统中融入了一种新的安全身份验证系统Optic ID，可在各种不可见的 LED 光照射下分析用户的虹膜，然后将其与受 Secure Enclave 保护的注册 Optic ID 数据进行比较，以立即解锁 Apple Vision Pro。用户的 Optic ID 数据已完全加密，应用程序无法访问，眼动追踪信息也不会与 Apple、第三方应用程序或网站共享。</p><p>&nbsp;</p><p>换句话说，来自摄像头和传感器的数据在系统级别进行处理，应用程序无法使用，这意味着它们无法秘密捕捉用户的周围环境。</p><p>&nbsp;</p><p>就像Tim Cook所说的，Vision Pro定位是一台全功能“新型计算机”，这个和Quest等产品“头戴显示器”本质不同，所以会有前置摄像头拍3D视频这样的惊艳应用，也才有虹膜识别这样的安全需求。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>为开发者培育新市场</h2><p></p><p>&nbsp;</p><p>新操作系统的发布对 Apple 和开发者来说都是一个重要时刻。随着 Apple 发布这款新耳机，我们几乎肯定会看到大量开发人员开发应用程序，尝试利用新平台，希望成为下一个热门产品。</p><p>&nbsp;</p><p>苹果表示，visionOS 将拥有一个全新的 App Store，人们可以在其中下载 Vision Pro 应用程序，而 Vision Pro 将能够运行“数十万熟悉的 iPhone 和 iPad 应用程序”。visionOS 支持第三方开发人员重新设计的 Apple 应用程序套件和体验，iPad 应用程序可以相对轻松地被移植到该平台上。</p><p>&nbsp;</p><p>Apple 已经与多家媒体公司合作，将他们的产品和内容带入新的 Vision Pro 生态系统。迪士尼首席执行​​官 Bob Iger 宣布 Disney+ 从第一天起就可以在 Vision Pro 上使用。鉴于这款头戴式耳机从首次发布到上市之间的时间很长，我们预计会有更多的开发人员加入。</p><p>&nbsp;</p><p>在发布时，visionOS 将提供来自 Adob​​e（特别是 Lightroom）、微软（Teams 和 Office）、思科（WebEx）Zoom 和其他主要开发商的应用程序——包括在 Vision Pro 上本地运行的 Unity 应用程序。</p><p>&nbsp;</p><p>此外，该操作系统还能运行特定的教育应用程序。给我们印象最深的是一款用于查看人体渲染图的医疗软件。公告视频显示了人体心脏的分解图，包括心室和肺动脉。有一个工程应用程序可以帮助人们形象化某些物理现象，例如空气是如何流过赛车的。&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a2/a220b2d4007cfd693175e17598c06e0c.png\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>Apple 肯定希望它的新操作系统有朝一日成为 iOS 级别的主宰，成为一款未来的金钱“虫洞”。</p><p>&nbsp;</p><p>这个能够同时运行多个应用程序，拥有3D 引擎，让每只眼睛都拥有 5120x4096高分辨率屏幕的全新软件平台，无疑能成功地吸引到开发者的关注。为这个平台重新设计现有的iOS 应用程序将是开发者竞相尝试的下一件大事。一位Linux开发者对此激动评价道：“我迫不及待地想看看这会带来什么可能性。现在我需要收拾下震撼的心情并开始为这项未来技术做些储备。谁知道会不会在不久的将来，我只用小声说‘Siri’，而不再输入‘sudo’。”</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.apple.com/sg/newsroom/2023/06/introducing-apple-vision-pro/\">https://www.apple.com/sg/newsroom/2023/06/introducing-apple-vision-pro/</a>\"</p><p><a href=\"https://twitter.com/edleonklinger/status/1665802712875769860\">https://twitter.com/edleonklinger/status/1665802712875769860</a>\"</p><p><a href=\"https://www.theregister.com/2023/06/05/apple_vision_pro/\">https://www.theregister.com/2023/06/05/apple_vision_pro/</a>\"</p><p><a href=\"https://escapebigtech.info/posts/wwdc2023/\">https://escapebigtech.info/posts/wwdc2023/</a>\"</p><p><a href=\"https://www.theverge.com/2023/6/5/23749156/apple-wwdc-hey-siri-wake-word-voice-assistant\">https://www.theverge.com/2023/6/5/23749156/apple-wwdc-hey-siri-wake-word-voice-assistant</a>\"</p><p><a href=\"https://www.theverge.com/2023/6/5/23733874/apple-vision-pro-visionos-augmented-reality-os-specs-wwdc-2023\">https://www.theverge.com/2023/6/5/23733874/apple-vision-pro-visionOS-augmented-reality-os-specs-wwdc-2023</a>\"</p><p><a href=\"https://developer.apple.com/visionos/\">https://developer.apple.com/visionOS/</a>\"</p>",
    "publish_time": "2023-06-06 14:34:34",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "北纬三十度集团 CTO 技术合伙人孔凡勇确认担任 ArchSummit 深圳专题出品人",
    "url": "https://www.infoq.cn/article/4rS8J4XEtAPi2ERFzduE",
    "summary": "<p>7&nbsp;月&nbsp;21&nbsp;日&nbsp;-&nbsp;22&nbsp;日，&nbsp;在&nbsp;<a href=\"https://archsummit.infoq.cn/2023/shenzhen?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">ArchSummit&nbsp;全球架构师峰会（深圳站）</a>\"，北纬三十度集团&nbsp;CTO&nbsp;技术合伙人孔凡勇，将担任<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1533\">「低代码架构实践」</a>\"的专题出品人，在此次专题中，我们将一同探讨当前低码化架构面临的问题以及对未来的展望。</p><p></p><p>孔凡勇拥有&nbsp;15&nbsp;年开发、架构与团队管理经验，经历了程序员、架构师和团队&nbsp;Leader&nbsp;等多种角色，曾先后在阿里云企业应用事业部担任技术负责人、中国电子云担任技术VP、SRM&nbsp;SaaS&nbsp;公司担任CTO，在电商、企业应用、云计算、SaaS、PaaS&nbsp;领域积累了丰富行业经验，参与过多个大型项目的系统架构设计与开发，在高并发、高性能、高可用、可伸缩的分布式系统架构设计领域拥有丰富经验，Cloud&nbsp;Native&nbsp;坚定拥护者，坚守开发一线，坚持打磨匠艺的架构师。</p><p></p><p>除上述专题外&nbsp;，ArchSummit&nbsp;深圳还将围绕<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1537?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">基础架构技术</a>\"、<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1536?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">智能化数据治理</a>\"、<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1532?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">DataOps、Data&nbsp;Fabric&nbsp;等高效数据开发与服务模式</a>\"、<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1534?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">Mesh&nbsp;技术实践案例</a>\"、<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1535?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">QUIC&nbsp;传输和架构优化</a>\"等进行分享。</p><p></p><p>数十位业界专家，上百个国内外一线大厂前沿技术案例，一定会给你带来很多全新的开发灵感。期待与你线下交流！&nbsp;现在购票，享&nbsp;8&nbsp;折特惠，立省&nbsp;¥1760！咨询购票请联系&nbsp;18514549229（微信同手机号）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9d/9d6a27547062ee2e089f91bdc4ba1eaa.png\" /></p><p></p><p></p><h4>【直播推荐】</h4><p></p><p>本周三（6.7）晚&nbsp;20:00，我们特邀&nbsp;Mobvista&nbsp;技术&nbsp;VP&nbsp;蔡超，科大讯飞&nbsp;AI&nbsp;研究院副院长&nbsp;李鑫，共同探讨&nbsp;AI&nbsp;大模型时代，架构师面临哪些机遇和挑战？更有&nbsp;ArchSummit&nbsp;深圳站精彩专题提前剧透！知识豪礼任性送！</p><p>扫码预约直播，戳此查看&nbsp;&gt;&gt;&gt;&nbsp;<a href=\"https://archsummit.infoq.cn/2023/shenzhen/speaker?utm_source=0607as&amp;utm_medium=zhibo\">ArchSummit&nbsp;深圳站讲师阵容</a>\"</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/59/59c9053a8407d1597bd0e7023a466634.png\" /></p><p></p>",
    "publish_time": "2023-06-06 16:15:20",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "FATE-LLM新版本发布，支持中文大语言模型ChatGLM-6B联邦化训练",
    "url": "https://www.infoq.cn/article/8zfeEZcsDD7JSBLZYg6j",
    "summary": "<p>当前，AI大模型已成为科技创新和数字经济领域的热点，其高速进程中面临的诸多问题也引发了业内关注。FATE开源社区技术指导委员会主席杨强教授指出：“即将消耗殆尽的公域数据，日趋高涨的隐私安全保护需求，以及众多异构小模型的整合需求，已成为AI 大模型发展之路上亟待突破的瓶颈。而联邦大模型正是解决这些问题的有效路径。”在此背景下，FATE社区开源了FATE-LLM联邦大模型功能模块，以联邦学习+大模型的技术解决方案破局数据隐私保护与数据不足等问题，以应对行业发展的新挑战。</p><p></p><p>近期，联邦大模型开源平台FATE-LLM最新版发布，在横向联邦场景支持ChatGLM-6B中文语言大模型。集成GLM的FATE-LLM将会为国内用户提供更好的中文大模型应用落地选择。</p><p></p><p>GLM系列大模型由清华大学和智谱AI联合研发，其中ChatGLM-6B是一个开源的、支持中英双语问答的对话语言模型，并针对中文进行了优化。该模型基于 General Language Model (GLM) 架构，具有 62 亿参数。结合模型量化技术，用户可以在消费级的显卡上进行本地部署（INT4 量化级别下最低只需 6GB 显存）。开源两个月以来，ChatGLM-6B在全球最大开源软件平台GitHub上获得超过26万星，超过斯坦福同期模型的关注度和好评度,全球下载量超过200万，并连续两周登上全球最大开源大模型平台 Hugging Face大模型趋势榜榜首。</p><p></p><p>此次更新的FATE-LLM v1.1版本在横向联邦场景支持Adapter，Prompt这类高效聚合方法，可以显著提升联邦大模型训练效率，其中参数微调方法支持Lora以及P-Tuning V2 。而在框架层，FATE实现对DeepSpeed的集成，使得FATE-LLM支持多机多卡训练，支持分布式GPU集群资源调度和管理，支持数据、模型参数等不同并行化加速方法。用户只需要任务提交阶段直接增加配置即可享受到多机多卡的加速能力。</p><p></p><p>项目链接：https://github.com/FederatedAI/FATE-LLM/releases/tag/v1.1.0</p><p></p><h2>FATE-LLM v1.1功能介绍</h2><p></p><p></p><h3>亮点概述</h3><p></p><p>1）集成业界开源的主流中文语言大模型ChatGLM-6B，支持高效的参数微调机制Lora、P-Tuning V2等方法，提升联邦训练的通信效率和训练效率；</p><p>2）FATE实现对DeepSpeed框架集成，使得FATE具备多机多卡联邦大模型加速训练能力：支持分布式GPU集群资源调度和管理；支持数据、模型参数等不同并行化加速方法。</p><p></p><h3>功能一览</h3><p></p><p>1）ChatGLM-6B联邦化支持，并支持LoRa、P-Tuning V2 高效微调方案；</p><p>2）FATE多机多卡联邦大模型训练能力支持，在任务提交阶段增加相关配置即可使用数据、模型等不同阶段的训练加速能力，与用户模型训练代码解耦；</p><p>3）FATE支持分布式GPU集群资源管理功能；</p><p>4）支持使用transformers库的data collator类，可以更灵活地处理训练输入数据；</p><p>5）支持只保存可训练参数，降低训练阶段checkpoints保存的硬盘占用，方便模型拷贝使用。</p><p></p><h3>实验数据</h3><p></p><p>1）高效参数微调机制的参数量及其训练参数占比</p><p><img src=\"https://static001.geekbang.org/infoq/32/32cc926f7d4860c5a16cf7690c65535f.jpeg\" /></p><p></p><p>2）场景及数据、以及配置</p><p>联邦场景：横向联邦，两个参与；应用场景：两个参与方各持有部分数据，数据格式:&lt;广告关键字，广告宣传语&gt;，希望模型可以根据输入的广告关键字去自动生成广告宣传语，通过联邦建模去提升广告生成词的效果。</p><p></p><p>下面给出效果示例：</p><p><img src=\"https://static001.geekbang.org/infoq/42/428cd3ceabf05bc93026a965f2672e4b.jpeg\" /></p><p>数据集：AdvertiseGen，可参考https://aclanthology.org/D19-1321.pdf，为广告生成数据集；训练数据随机切分，其中client-1数据量为57478，client-2数据量为57121环境：局域网环境，client-1和client-2机器配置完全一致，单个client使用2台机器，每台机器有4张V100 32G 资源；配置：DeepSpeed: stage=2，batch_size_per_device=4；数据集的提问(content)及回答(summary)两列tokenize后，token_ids长度超过64的会截断。</p><p>3）训练效果：</p><p><img src=\"https://static001.geekbang.org/infoq/08/081232c54e29a64b6cc81e40c5c68c91.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/70/70dbf71189638dde58741da373721b15.jpeg\" /></p><p></p><h2>开源共建，是助推联邦大模型快速发展的不竭动力</h2><p></p><p>未来，支持中文大语言模型ChatGLM-6B联邦化训练的FATE-LLM将通过联合多家公司和组织，充分利用分散数据，融合联邦学习和AIGC相关技术，实现异构数据分布式安全训练。其中针对中文方面的优化，将为金融、教育、医疗等领域的应用带来更强大的支持，例如人工智能助手、智能问答、自然语言处理等场景将会得到进一步的效果提升。</p><p></p><p>FATE-LLM模块将持续迭代，未来将持续解决训练、微调和使用推理阶段的隐私保护问题，并坚持推出后续版本。联邦大模型将大模型与隐私计算核心技术手段融合，使大模型的“野蛮生长”转向更加安全可靠的发展赛道，在提升AI通用性的同时不违背监管与伦理的要求，推进AI技术高质量发展。</p><p><img src=\"https://static001.geekbang.org/infoq/b2/b20a828b8adc8d77b1da8d1cfd878792.jpeg\" /></p><p>清华大学教授唐杰表示：“作为科研人员，我们希望在开展大模型技术研究与应用落地的同时，也进一步降低人工智能的使用门槛，实现技术普惠，为行业良性发展做出一些贡献。”</p><p></p><p>饮其流者怀其源。开源不仅是一种技术选择，更是一种分享态度与沟通方式。开源平台和开源生态将助推大模型的快速迭代与落地应用。</p>",
    "publish_time": "2023-06-06 16:23:43",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "百度智能云推出代码助手Comate，覆盖30种编程语言，正式开放邀测",
    "url": "https://www.infoq.cn/article/ONi9RGciXT9EKSAHNcRz",
    "summary": "<p></p><h2>百度智能云推出代码助手Comate</h2><p></p><p>&nbsp;</p><p>6月6日，在文心大模型技术交流会（成都）上，百度智能云推出 Comate 代码助手，并正式开放邀测。借助<a href=\"https://www.infoq.cn/article/9GvpKWM3ruDNt4phSMNp\">文心大模型</a>\"的理解、推理能力，Comate可实现代码的快速补齐、自然语言推荐代码、自动查找代码错误，全面提升开发者研发效率。未来，开发者可以通过插件等形式，在主流开发软件中使用Comate代码助手。</p><p>&nbsp;</p><p>目前，Comate目前已经覆盖了30余种编程语言，尤其在 C/C++、Python、Java、Go、PHP、JavaScript 等多个主流语言表现出色。此外，Comate还支持程序员最常使用的主流IDE，开发者可以通过插件等形式，在不同软件中使用Comate。同时，结合<a href=\"https://xie.infoq.cn/article/f1487254108f28f0660855f2b\">飞桨深度学习框架</a>\"与文心大模型，Comate可确保推理单次请求300ms左右，以极快的响应速度保障用户使用体验。</p><p>&nbsp;</p><p>百度集团副总裁侯震宇表示，Comate代码助手是基于大模型打造的新一代编码辅助工具，已经在百度内部进行了大量测试。测试结果显示，在Comate辅助编写的代码中，近50%的建议代码被开发者采纳，目前在百度内部已经广泛应用到各类产品开发中。</p><p>&nbsp;</p><p>据悉，百度在2021年就开始基于文心大模型进行代码辅助工具的研究；2022年4月，代码辅助工具内测成效明显；2022年9月，代码辅助工具已全面应用于百度内部开发。</p><p>&nbsp;</p><p>基于高质量GitHub代码库以及百度内部代码的积累，Comate代码助手将实现编码、回看、测试等全流程的辅助编码。例如，在编写程序时，可实现代码智能搜索、推荐、自动补全；在回看程序时，可查找代码错误；在测试阶段，也可基于代码直接生成单元测试脚本，实现代码验证。更值得一提的是，基于文心大模型在中文理解上的独特优势，Comate可以理解代码中的中文注释，并通过上下文触发、语义触发等能力，完成相应指令，更匹配中国开发者的习惯。</p><p>&nbsp;</p><p>会上，百度智能云AI平台副总经理施恩还对Comate进行了现场演示，通过Comate现场快速开发“贪吃蛇”小游戏。开发者只需输入“canvas”，以及“弹性布局，水平居中，垂直居中”等中文备注，Comate即可自动识别语义，生成游戏画布代码。再输入“param color”、“left”、”food=”等颜色、方向、食物的简单词汇，Comate自动联系上下文理解指令，补全代码，并在多条推荐代码之间切换，选择合适代码，直接生成了可运行的“贪吃蛇”小游戏。</p><p>&nbsp;</p><p>百度智能云表示，辅助代码撰写是第一阶段的主要产品功能，并且当前Comate代码助手已经可以部分实现通过自然语言的方式写代码，彻底改变人机交互方式和程序开发模式。百度内部人士表示；第二阶段，Comate将实现在特定领域、场景的自然语言代码生成；第三阶段，Comate将实现全领域的自然语言开发。</p><p></p><h2>大模型为AI研发和应用范式带来了哪些变革？</h2><p></p><p>&nbsp;</p><p>会上，侯震宇表示，<a href=\"https://www.infoq.cn/article/cuTAVv7W3CjkhiXZW0Y2\">大模型</a>\"为AI研发和应用范式带来了四个方向的变革：</p><p>&nbsp;</p><p>第一，AI应用的模型训练从以往单任务的定制化建模，变成了跨任务、跨模态、跨语言的统一建模；第二，应用的交互方式从人适应机器，变成了机器适应人；第三，应用问题从编程解决，变为数据化驱动，通过prompt engineering的方式，提问题就能得到答案；第四，大模型的分解及复杂问题处理能力，结合调起、执行外部插件的能力，可实现从思考到行动的无缝衔接。通过这些变革，将全面提升开发效率、应用效果，以及产品创新的速度。</p><p>&nbsp;</p><p>在人工智能与大模型的加持下，每个开发者都可以十倍、百倍的放大自己的能力。百度工程师在使用Comate后表示：“第一次发现手敲代码、改格式的时间被压缩到如此之短，只需专心思考代码结构，即可飞速实现功能”。目前，Comate已经开始邀测中，开发者很快即可体验。</p>",
    "publish_time": "2023-06-06 17:12:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "解决真实工业场景痛点问题，工业互联网技术产业应用走向深水区",
    "url": "https://www.infoq.cn/article/EcggKzqrrl9lFk6AOCaW",
    "summary": "<p>“我们是解决一个工程的问题，不是做一个数学题，做出来的结果要真的具有可行性”，在第六届工业互联网数据创新应用大赛决赛答辩现场，评审团老师语重心长地说。这句话也折射了第六届工业互联网大数据创新大赛的举办初衷：采用真实的工业场景的数据，通过问题众包和人才众创这样的竞赛方式解决企业实际痛点问题。</p><p>&nbsp;</p><p>据了解，工业互联网数据创新应用大赛起始于2017年。2023年，第六届工业互联网数据创新应用大赛以“赋能制造 因你而耀”为主题，由中国信息通信研究院和深圳市宝安区人民政府联合中国东方电气集团有限公司、东方电气（成都）氢燃料电池科技有限公司、TCL华星光电技术有限公司、阿里云计算有限公司天池平台共同主办。</p><p>&nbsp;</p><p>5月18日，第六届工业互联网大数据创新大赛决赛在深圳市宝安区成功举办。29支参赛队伍经过4个月的激烈角逐，从12000名参赛选手中脱颖而出，齐聚深圳市宝安区参与决赛现场答辩并最终决出名次。他们带来的技术方案让参会者眼前一亮，也让我们看到了技术向实，助力数字经济腾飞的新生力量。</p><p></p><h1>以赛促产，挖掘工业互联网复合人才</h1><p></p><p>&nbsp;</p><p>工业互联网是新型基础设施建设的重要组成部分，是数字经济和实体经济深度融合的关键路径。国家互联网信息办公室发布的《数字中国发展报告(2022年）》（以下简称“报告”）指出，数字中国建设取得显著成效。报告显示，2022年数字经济规模达50.2万亿元，总量稳居世界第二；工业互联网已覆盖工业大类的85%以上；工业互联网核心产业规模超1.2万亿元，同比增长15.5%；全国工业企业关键工序数控化率、数字化研发设计工具普及率分别增长至58.6%和77.0%。我们可以看到，工业互联网技术与产业应用的融合正逐步走向深水区。</p><p>&nbsp;</p><p>但是，工业互联网的发展依然在场景发掘、产业融合中存在不少难点。</p><p>&nbsp;</p><p>第六届工业互联网数据创新应用大赛围绕国家战略布局重点以及制造业应用中亟须解决的难点痛点以及创新问题，通过场景化的赛题设置，面向面向高等院校、科研单位、互联网企业等开放选手招募，在氢燃料电池系统性能均值预测、电子信息行业液晶面板产品量测值预测和化工行业工业生产反应装置的建模预测等三个赛题的角逐中，切实为工业发展提供新的解决方案或解题思路。</p><p>&nbsp;</p><p>《电子信息行业的液晶面板产品量测值预测》赛题技术支持方，来自格创东智（深圳）科技有限公司的大数据分析工程师傅益龙表示，液晶面板和芯片同属半导体行业，工艺制程复杂，对几百道生产工序的精度要求高，所以在每道工序后都设有量测站点来评估产品是否符合生产要求，但由量测站点在工艺量测的时候耗费的时间比较长，没办法做到每一片产品都能去做一次量测，所以抽检是目前企业常用的办法。因此，如何准确识别量测值异常的产品，对企业而言是关乎生产效益的重要事情之一，也是这个赛题的关键。</p><p>&nbsp;</p><p>在这个赛题中拿到现场最高评分的“haha”队伍表示，在拿到匿名数据后，他们先去了解了工业背景、摸索实际业务工作场景，“经过实际场景和数据的角度，总结出赛题存在复杂的交互作用、非线性关系、数据质量问题以及特征参数变化范围比较广、关系比较复杂”，最终选择通过数据扩充等方式建立高精度模型，获得了评审团老师的高度认可。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/ab/ab7a7cc1e020a61e858588dd5b7ff3e5.png\" /></p><p></p><p>评审专家之一，国家智能制造专业委员会、石化英科原高级副总裁蒋白桦表示，如何让数据与制造业更好地融合合应用是推动高质量发展的重要一环。蒋白桦表示，工业大数据是新一代信息技术与传统制造业结合的新领域，然而兼具工业工程生产经验、数据建模、软件开发的复合型人才极度缺乏，特别希望借助此次大赛，让选手深入工业去感受制造创新的魅力和价值，开阔视野、取长补短、团结合作、互相学习。</p><p></p><h1>星光成炬，数字化推动宝安工业高质量发展</h1><p></p><p>&nbsp;</p><p>这次大赛的举办也得到了深圳市宝安区政府的大力支持。2021年以来，宝安区陆续发布了大力发展工业互联网赋能制造业转型升级的若干措施，从供给端和应用端两侧发力。</p><p>&nbsp;</p><p>从区域发展的视角来看，一个更开放、更具包容性的工业互联网平台，将更好地连接支撑发展的多种要素资源，促进人流、物流、信息流、资金流等在区域内的充分整合和更优配置。深圳市宝安区一直在向着此目标努力。</p><p>&nbsp;</p><p>宝安区工业和信息化局二级调研员杨辉在致辞中提到，在宝安区397平方公里的面积里面，有超过5万家的工业企业。同样，也正是这超过5万多家企业，用点点星光汇聚成了宝安区强大的工业数据的规模优势。不可否认的是，宝安工业大数据的资源是丰富的，数据要素的价值一旦得到充分的释放，数据生产力就必将是倍增的扩大。</p><p>&nbsp;</p><p>杨辉表示，工业互联网数据创新应用大赛作为工业大数据领域的国家级的权威的赛事，大赛采用真实工业场景的数据，通过问题众包和人才众创的竞赛方式解决企业实际痛点问题，将有效推动工业企业开展工业大数据的应用。而工业互联网的数据创新应用大赛在宝安举办，也将引起区内企业对数据的重视，引导企业对数据深度的挖掘、分析和应用，推动产业由数字化向智能化方向发展。</p><p>&nbsp;</p><p>近年来，宝安区积极开展工业互联网工作，推动制造业数字化转型；2020年、2021年连续两年被工信部评为全国唯一一个五星级工业互联网领域产业示范基地，2022年9月获国家工信部“平台赋能基地产业链数字化升级”试点。</p><p>&nbsp;</p><p>而工业互联网数据创新应用大赛自2017年启动至今，覆盖440所知名高校以及华为、百度、昆仑数据、工业富联等在内的超百家知名技术解决方案企业；获得中国计算机学会、中国机器人协会、中国互联网协会在内的几十个行业协会/联盟的关注，并与天池、CSDN、DataWhale等国内多个顶级数据大赛组织进行联动。诸多新力量汇入，将“为企业探索数据价值挖掘，提供可以复制的、可推广的实施的路径”，也将进一步推动宝安工业互联网的高质量发展。</p><p></p><h1>向新而行，第七届竞赛蓄势待发</h1><p></p><p>&nbsp;</p><p>历经四个多月的角逐，第六届工业互联网数据创新应用大赛尘埃落定。据介绍，7月份，颁奖仪式将在深圳市宝安区举行，部分选手及嘉宾将受邀现场参加到颁奖活动中，为这段时间的拼搏画上一个圆满的句号。</p><p>&nbsp;</p><p>工业互联网数据创新应用大赛作为中国信息通信研究院发起的专注于大数据领域的权威赛事，多年来累计获得2亿的曝光量，报名参赛选手超过4万名，为工业大数据人才培育、产业创新、生态打造提供强有力的支持。</p><p>&nbsp;</p><p>2023年4月，为更好服务于工业互联网发展，引导科技与产业实体相融合，大赛品牌全面升级为“数境·大数据创新应用大赛”，赛制赛程从一年一赛升级为一年多赛，大赛内容从工业数据应用拓展升级到更广泛的数据要素全生命周期，覆盖“数据要素的流通与治理”、“数据创新应用驱动企业数字化转型”、“数据要素激活制造业生态发展”等，进一步推动产、学、研界在大数据创新应用领域的落地。&nbsp;&nbsp;&nbsp;</p>",
    "publish_time": "2023-06-06 19:46:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]