[
  {
    "title": "如何构建高效的事件管理流程",
    "url": "https://www.infoq.cn/article/twsM1Dshp5o4cd5oiuMI",
    "summary": "<p>本文提供了一个可以有效进行事件管理的通用框架，其灵感来自LinkedIn的内部流程，不同组织可以根据自己的需要进行定制。事件管理有标准化的<a href=\"https://www.cio.com/article/272361/infrastructure-it-infrastructure-library-itil-definition-and-solutions.html\">ITIL</a>\"流程，但下面要介绍的框架有所不同，它是为解决实时生产中断而定制的。</p><p>&nbsp;</p><p>大多数公司提供在线服务，任何中断都会带来糟糕的终端用户体验。反复中断会影响业务和品牌价值。在高速、复杂的分布式系统中，生产中断经常会频繁发生。组织应该接受事件总会出现的现实，创建事件管理流程，缩短事件解决时间。</p><p></p><h2>什么是事件？</h2><p></p><p>事件是计划外的生产中断，会严重破坏终端用户的体验，需要组织立即进行干预。</p><p>&nbsp;</p><p>根据受影响的用户不同，事件可以分为内部事件和外部事件。</p><p>内部事件是指由于用于完成工作的工具出现问题而影响员工工作效率的中断（例如，部署工具在很长一段时间内无法正常使用，员工不能登录到VPN）。外部事件是指影响公司产品/服务的终端用户体验的中断（例如，用户不能从电子商务网站购买商品，用户不能在即使通讯软件中发送消息）。</p><p>&nbsp;</p><p>上述事件可以根据严重程度进一步划分成次要（Minor）、中等（Medium）和重大（Major）。</p><p>重大 —— 严重影响许多终端用户的体验，并对业务（由于收入损失）或品牌价值产生了明显的影响。中等&nbsp;—— 事件影响了相当一部分服务，但不同于重大事件，通常只限于特定的区域。次要&nbsp;—— 影响面向少数用户的服务的非关键工作流的事件。</p><p>&nbsp;</p><p>假如有一个社交媒体网站发生了严重的事件，那么大部分用户的服务中断超过30分钟就可以归类为重大事件。相比之下，中东用户无法使用私聊消息功能可能就只是一个中等事件，而如果是印尼用户的个人资料中没有出现验证徽章则可以归类为次要中断。</p><p>&nbsp;</p><p>强烈建议以业务目标为依据，以数据为基础建立严格的事件分类指南，提高透明度，防止在非关键事件上浪费工程带宽。</p><p></p><h2>什么是事件管理？</h2><p></p><p>事件管理是一系列有序采取的行动，旨在缓解和解决关键事件，使服务尽快恢复健康。</p><p></p><h3>事件管理阶段</h3><p></p><p>检测</p><p>通过在基础设施监控/预警或各种客户支持渠道的用户报告主动检测中断。</p><p>&nbsp;</p><p>创建</p><p>针对检测到的中断创建事件，触发事件管理流程。在理想情况下，组织可以使用一个类似于<a href=\"https://www.atlassian.com/software/jira\">Atlassian JIRA</a>\"的工单管理系统来记录事件详情。</p><p>&nbsp;</p><p>分类</p><p>根据既定的原则对事件进行分类。强烈建议根据业务需求起草这些原则。如今，行业中使用了多种术语，但简单起见，我们将使用重大、中等和次要的分类方式。对于所有事件，事件管理流程和紧迫感都是相同的，但当多个事件同时发生时，确定事件类别有助于确定优先级。</p><p>&nbsp;</p><p>排查</p><p>最初报告事件的人会查阅内部值班记录，然后根据自己的知识将其升级到相应服务的值班工程师。升级会继续，直到查明问题的根本原因；有时，一个事件可能需要多个团队协作来发现问题。</p><p>&nbsp;</p><p>解决</p><p>相关团队首先要做的是确定步骤，以在尽可能短的时间内缓解正在发生的事件。关键是承担该承担的风险，并在接下来的步骤中果断行事。一旦问题得到缓解，团队就会专注于解决根本原因，以防止问题再次发生。在整个解决过程中，与内部和外部利益相关方的沟通是必不可少的。</p><p>&nbsp;</p><p>回顾</p><p>通常，事件回顾是在查明根本原因之后进行。事件中涉及的团队和关键利益相关方聚在一起仔细回顾事件。事件回顾的目标是确定哪里出了问题，可以做什么改进，以便未来可以防止或更快地解决类似的问题，并确定短期/长期的行动项以预防问题或改进流程/技术栈。</p><p>&nbsp;</p><p>跟踪</p><p>定期在管理层面审查事件行动项，以确保所有与事件相关的行动项都得到处理。评估关于事件的关键指标，如TTD（检测时间）、TTM（缓解时间）、TTR（解决时间）和SLA（服务水平协议），确定事件管理的有效性，识别战略投资领域，提高服务的可靠性。</p><p>&nbsp;</p><p></p><h2>事件管理角色&amp;职责</h2><p></p><p>在事件处理期间，要有一组经过专门培训的人员承担特定的角色，在妥善处理生产事件的同时，尽量减少混乱，这至关重要。在理想情况下，一人承担一项职能，因为责任重大，需要特定的技能。也可以根据业务需求和事件的严重程度合并和自定义角色。</p><p></p><h3>事件经理</h3><p></p><p>事件经理（下文简称为IM）是事件的负责人，负责以适当的紧迫感引导事件解决。在事件处理期间，应该有一个人负责事件管理过程的一般组织，包括沟通和决策。这个人有权做出决策，并确保事件根据既定策略得到有效处理。</p><p>&nbsp;</p><p>职责：</p><p>事件经理负责事件管理的四个主要方面：组织、沟通、决策管理和事后跟踪。</p><p>事件的组织对于事件的有效解决至关重要。IM将负责召集合适的团队和利益相关方，以确保事件得到快速解决。IM将与利益相关方合作，分配在调查和补救期间提出的工作项并进行跟踪。需要在事件处理期间做出许多决策。IM负责识别调查和快速解决之间的拐点，并确保可以迅速做出决策，让合适的利益相关方参与/了解。当故障排查期间无法达成共识时，IM有权判定谁拥有决策权。事件结束后，IM是事件的沟通联络点。由于IM积极参与了事件，所以他们要负责与服务所有者和利益相关方合作，主导事后分析。IM将与服务所有者合作，提供从事后分析到高层管理的事件概述和基本行动项。</p><p>&nbsp;</p><p></p><h3>值班工程师</h3><p></p><p>在事件发生期间，受影响服务和拥有服务的值班工程师将参与调查和缓解导致事件的问题。</p><p>&nbsp;</p><p>职责：</p><p>受影响服务的值班工程师负责评估客户影响和服务影响，并在发出解除预警信号、关闭事件之前验证缓解/解决步骤。</p><p>&nbsp;</p><p>对导致中断/问题的服务负责的值班工程师负责调查根本原因，并采取补救措施以缓解/解决事件。</p><p>&nbsp;</p><p></p><h3>沟通主管</h3><p></p><p>利益相关者、客户和管理层之间的有效沟通对于事件的快速解决至关重要。将信息传递给利益相关者、管理层，甚至是执行者，可以避免事件的意外恶化，帮助应对混乱局面，在组织中避免重复工作/单打独斗，缩短解决问题的时间。</p><p>&nbsp;</p><p>职责：</p><p>沟通经理负责所有与内外部各利益相关方（员工和高管的最新情况、社交媒体更新和状态页面）围绕事件进行的书面沟通。</p><p>&nbsp;</p><p></p><h3>客户升级经理</h3><p></p><p>对于大公司来说，因为要迎合各种各样的企业客户，而且有严格的SLA，所以他们通常由专门的客户升级经理来架起客户与内部事件团队之间的沟通桥梁。</p><p>&nbsp;</p><p>职责：</p><p>与客户保持联系，收集当前事件的详细信息，并将信息传递给调试这个问题的内部团队。从沟通经理处获取最新的沟通信息，并定期将定制的信息传递给客户。确定缓解步骤，让客户试着缓解问题，直到问题得到完全解决。</p><p>&nbsp;</p><p></p><h3>执行经理</h3><p></p><p>对于影响客户的服务，执行经理会持续更新事件状态和客户影响详情。对于可能影响业务的事件，执行经理还会在相关决策中扮演重要角色，分配资源，加速事件解决过程。</p><p></p><h2>事件管理工具</h2><p></p><p>为了更快地缓解问题，事件管理生命周期的每个阶段都需要许多工具。大公司会推出自定义的工具，可以与生态系统的其他部分很好地进行互操作。相比之下，对于不需要构建自定义工具的组织来说，市场上有许多工具可供他们使用，有开源的，也有商业的。本节将回顾事件管理过程中用到的基本工具的几个标准类别。</p><p></p><h3>预警管理</h3><p></p><p>预警管理可以帮助设置告警，并监控特定时间段内时序指标的异常情况。当检测到运营指标异常时，它会向值班人员发送通知。经过适当的配置，预警管理工具可以通过多种媒介将报告升级到值班工程师：紧急预警通过寻呼机/电话，非紧急预警通过短信息/电子邮件。</p><p>&nbsp;</p><p>预警管理工具应该支持不同的媒介，并能够与可观察性工具（如Prometheus、Datadog、New Relic、Splunk和Chronosphere）互操作。Grafana Alert Manager是一个开源的预警管理工具；市场上也有一些商业预警管理工具，如PagerDuty、OpsGenie和Firehydrant等。</p><p></p><h3>值班管理</h3><p></p><p>在一个拥有数千工程师和微服务的大型组织中，在合理的时间内让合适的人参与进来，对于更快地解决事件至关重要。值班管理工具通过值班调度和升级功能，跨团队分担值班职责，并提供值班工程师映射服务，在严重的大规模事件中促成无缝协作。</p><p>&nbsp;</p><p>值班管理工具应该支持调度和服务所有权详情的自定义。<a href=\"https://www.splunk.com/en_us/products/on-call.html\">PagerDuty</a>\"和<a href=\"https://www.splunk.com/en_us/products/on-call.html\">Splunk Oncall</a>\"是其中最著名的两个商业选项，而<a href=\"https://github.com/linkedin/oncall\">LinkedIn的Oncall</a>\"工具是一个开源版本，适合寻找低成本选项的组织。</p><p></p><h3>协作工具</h3><p></p><p>在发生严重事件时，数百名员工参与其中的情况并不罕见。协作和沟通对于管理混乱和有效解决事件至关重要。如今，每家软件公司都有通讯或视频会议软件，工程师们可以随时使用这些软件进行协作。可以轻松快速获取信息，弄清楚要在即时通讯应用中加入哪个组或要在视频会议软件中加入哪个会议通道，对于缩短解决事件的时间至关重要。</p><p>&nbsp;</p><p>为每个事件设置单独的讨论渠道，对于简化协作过程至关重要。通常，会议通道的链接会固定放在群聊的描述中，方便新工程师加入会议。完善的流程可以减少诸如“我应该加入哪里”或“谁帮忙分享下会议通道链接”等协调方面的问题的干扰，并保持事件排查的沟通渠道畅通。</p><p></p><h3>事件跟踪</h3><p></p><p>事件会生成大量的重要数据，可能来自自动处理流程，也可能是手动记录以供将来参考的数据。由于缺少结构化，传统的笔记应用程序不会有太大的发展。支持多个自定义字段和协作功能的工单平台会更适合这种情况。获取历史事件数据的API接口也至关重要。</p><p>&nbsp;</p><p>许多公司都使用Atlassian的JIRA跟踪所有事件，但<a href=\"https://www.notion.so/\">Noti</a>\"<a href=\"https://www.notion.so/\">on</a>\"、<a href=\"https://www.airtable.com/\">Airtable</a>\"、<a href=\"https://coda.io/\">Coda</a>\"等类似的工具也同样有效。<a href=\"https://www.bugzilla.org/\">Bugzilla</a>\"是一个可以帮助我们跟踪事件的开源替代方案。</p><p></p><h3>知识共享</h3><p></p><p>知识共享工具不可或缺，可以帮助工程师轻松找到正确的信息。运行手册、服务信息、事后分析文档和待办事项都是知识共享应用程序的一部分。在这方面，谷歌文档、维基和Notion都是很好的商业软件，可以帮助我们在组织内部撷取和共享知识。</p><p></p><h3>状态页面</h3><p></p><p>状态页面是为了方便外部利益相关方了解服务当前的健康状况。感兴趣的人士可以订阅有关的最新资料，了解有关事件处理进展的更多信息。当发生外部事件时，状态页面可以减少客户服务部门收到的咨询系统健康状况的入站请求。</p><p></p><h2>事件响应周期</h2><p></p><p>在前面几节中，我们讨论了事件管理中的不同阶段、角色和工具。本节将使用上述信息详细说明事件响应过程的各个阶段。</p><p></p><h3>检测</h3><p></p><p>通过内部监控系统或是客户支持或社交媒体的用户报告发现问题。一种很常见的情况是，内部员工首先发现问题并将其升级到集中式的站点运营团队。组织应该采用合理的可观察性解决方案来更快地检测问题，从而尽可能地缩短检测时间（Time To Detect，TTD）。</p><p>&nbsp;</p><p>对于用户升级的问题，应该实现一个流程，让员工使用可用的值班管理工具将问题快速升级到相关团队。问题的升级标志着事件管理生命周期的开始。</p><p></p><h3>创建</h3><p></p><p>团队收集有关事件的必要信息，并创建事件跟踪工单。其他有助于工程师排查问题的信息也应该收集，如受影响的产品、开始时间、受影响用户等。</p><p>&nbsp;</p><p>一旦创建了工单，值班事件经理就需要使用内部事件管理工具参与进来。为了方便协作，应在内部消息服务和视频桥中创建共享的沟通渠道。</p><p></p><h3>分析</h3><p></p><p>事件经理与团队一起确定受影响服务的值班工程师，并与他们一起进一步了解用户影响。根据事件的影响大小，事件经理将事件分为重大、中等或次要。重大事件非常严重，通常需要全体出动。</p><p></p><h3>排查</h3><p></p><p>一旦问题被归类为重大事件，就需要向所有利益相关方发出事件初步通报，说明发生了重大事件，并提供当前掌握的有关该事件的信息。最初的通报缺少细节，但应该为接收方提供足够的上下文，使其理解中断会产生什么影响。应及时更新面向外界的状态页面，承认出现了问题，组织正在努力解决。</p><p>&nbsp;</p><p>事件经理应将问题升级，并根据能够获得的最佳信息召集所有相关的值班工程师。沟通主管将负责沟通，客户升级经理应向客户提供最新信息。事件跟踪工单应该包含所有必要的事件跟踪数据。</p><p>&nbsp;</p><p>如果需要其他团队参与，那么事件经理应分别与他们联系，直到解决事件所需的所有人员都到场。</p><p></p><h3>解决</h3><p></p><p>团队应集中精力缓解事件，并在之后找到根本原因和解决方案。在这种情况下，团队可以探索将所有流量从受影响区域重定向到可用健康区域的选项，设法缓解问题。使用任何临时手段缓解事件都有助于缩短事件的TTM（Time to Mitigate，缓解时间），为工程师消除导致问题的根本原因提供急需的空间。</p><p>&nbsp;</p><p>在整个排查过程中，要详细记录稍后可能需要修复的东西、调试过程中遇到的问题和流程效率低下的情况。一旦问题得到解决，临时缓解步骤将被删除，系统恢复正常状态。</p><p>&nbsp;</p><p>要根据发现的问题、解决问题的详细步骤和下一步可能采取的步骤更新事件通讯。然后，向客户提供最新解决方案。</p><p></p><h3>回顾</h3><p></p><p>定位到根本原因后，编写一份详细的事件文档，其中包含事件期间捕获的所有细节。参与事件管理的所有利益相关方和团队聚在一起，进行事后分析，其间任何人都不会受到指责。这样的回顾会议旨在反思该事件，并识别任何改进技术或流程的机会，帮助更快地缓解问题，防止类似事件的再次发生。要仔细研究事件的时间轴，以便发现事件检测或管理过程中任何效率低下的地方。确定所有必要的行动项，定义好优先级并分配给各自的所有者。高优先级行动项最紧急，应尽快处理，其余优先级比较低的行动项也必须有截止日期。要指定专人帮助跟踪这些行动项，并确保团队承担起相应的责任，完成好各自的工作。</p><p></p><h2>度量指标</h2><p></p><p>就像SRE圈里所说的：“可度量的东西才会被修复。”以下是应该在所有事件和组织中度量和跟踪的标准指标。</p><p>&nbsp;</p><p>检测时间（TTD）</p><p>检测时间是指从故障开始到检测到故障（手动或自动报警）所花费的时间。团队可以扩大报警覆盖，使用最新的信息来加快故障检测。</p><p>&nbsp;</p><p>缓解时间（TTM）</p><p>缓解时间是指从事件发生到缓解用户影响所花费的时间。缓解措施只是解决导致问题的根本原因之前所采用的临时解决办法。设法缩短TTM有助于提高服务的可用性。许多公司借助Active-Active模式为多个区域的用户提供服务，并将流量重定向到健康区域，从而更快地缓解事件影响。类似地，在某些情况下，服务或节点级的冗余有助于更快地缓解事件影响。</p><p>&nbsp;</p><p>解决时间（TTR）</p><p>解决时间是指从事件发生到完全解决事件所花费的时间。解决时间有助于更好地理解组织检测和解决根本原因的能力。由于排查是事件解决周期的重要组成部分，所以团队可以采用复杂的可观察性工具来帮助工程师更快地发现根本原因。</p><p>&nbsp;</p><p>关键事件元数据</p><p>事件元数据包括事件数量、根本原因类型、受影响的服务、根源（root cause）服务以及帮助组织识别TBF（故障间隔时间）的检测方法。组织的目标是增加平均故障间隔时间。分析这些元数据有助于识别组织运营方面的热点。</p><p>&nbsp;</p><p>服务可用性</p><p>服务可用性是指在一段时间内服务正常运行时间的占比。可用性指标被用作弹性的衡量标准。</p><p>&nbsp;</p><p></p><h2>小结</h2><p></p><p>本文讨论了事件管理过程，并介绍了它如何帮助组织更快地管理混乱和解决事件。事件管理框架有各种风格，但这里提出的思想非常通用，任何规模的组织都可以进行定制和调整适配。</p><p>&nbsp;</p><p>计划引入事件管理框架的组织可以从小事做起，收集事件相关的数据。这些数据有助于我们了解现有系统的低效或不足之处，并提供比较资料，衡量即将推行的新事件管理流程的进步之处。一旦对需求有了更好的了解，就可以从一个与组织规模相匹配的基本框架入手，而这不会产生任何额外的开销。可以根据需要在流程中引入其他步骤或工具。</p><p>&nbsp;</p><p>如果你正在寻找其他关于改进和扩展事件管理流程的信息，则可以从以下几个地方入手：</p><p><a href=\"https://learning.oreilly.com/library/view/anatomy-of-an/9781098113759/\">事件剖析——Ayelet Sachto，Adrienne Walcer</a>\"<a href=\"https://learning.oreilly.com/library/view/incident-management-for/9781491917619/\">面向运营的事件管理——Rob Schnepp，Ron Vidal，Chris Hawley</a>\"<a href=\"https://www.atlassian.com/incident-management/handbook#what-is-an-incident\">Atlassian事件管理手册</a>\"<a href=\"https://www.youtube.com/watch?v=FYYTglQoS3w\">SREcon21 —— Slack事件管理演进</a>\"</p><p>&nbsp;</p><p>希望改进当前事件管理流程的组织必须进行仔细地测试、度量、调整并重复该方法。重点应该是找出当前过程中出现的问题，进行增量改进，并衡量进展。务必从小事做起。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/effective-incident-management/\">https://www.infoq.com/articles/effective-incident-management/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/j1jm5Qehr1jiEQubY0ot\">Kafka 3.3 使用 KRaft 共识协议替代 ZooKeeper</a>\"</p><p><a href=\"https://www.infoq.cn/article/TTDS1pC6Cz6MRqJTpMir\">为什么说可观察性是解锁 GitOps 的关键</a>\"</p>",
    "publish_time": "2022-11-13 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "腾讯内容千亿级实时计算和规则引擎实践优化之路",
    "url": "https://www.infoq.cn/article/3stR0gTgyrhy7hpMKqM0",
    "summary": "<p></p><h2>1.系统背景</h2><p></p><p></p><p>腾讯内容中台提供从内容生产、内容加工、内容分发、内容结算等全链路环节的一站式服务，在这个过程中，会产生大量的数据以及围绕这些数据衍生的实时流业务应用，如智能审核、运营决策、在线学习等，从底层去看这些内容生态场景的本质，它需要我们提供一套完善的基于规则引擎的实时流信号服务来控制信号和业务流转，且实时信号场景具有内容数据源复杂、吞吐量高、计算量大、准确度高等特点。因此，我们利用业界前沿的实时流技术，并结合一些核心内容生态实时流场景的自研关键技术，沉淀了一套数据复用度高、可用性强、需求响应快的实时流服务，高效赋能腾讯内容生态产品。</p><p></p><h3>2. 问题与挑战</h3><p></p><p></p><h4>问题 1：多实时数据源动态感知、内容 OneID 数据</h4><p></p><p></p><p>腾讯内部各个业务方生产的数据各异，且拥有各自的 ID 体系；随着业务发展，数据源还会动态添加消息 Topic，需要实时动态感知新增的数据源，并以中台统一的 ID 视角串联各个业务的内容数据。</p><p></p><h4>问题 2：TB 级多流数据拼接、批数据重建流状态</h4><p></p><p></p><p>内容加工时会产生较多的复杂计算需求，比如，我们需要在有限资源内保障 TB 级多条实时数据拼接工作，以及长时间运行下需要对实时流应用的计算口径进行调整而面临的批数据重建流式数据状态等问题，我们探索了一系列自研技术，解决了海量数据实时流计算问题。</p><p></p><h4>问题 3：规则引擎日千亿次实时信号触发</h4><p></p><p></p><p>内容生态系统很多场景依赖实时信号，并且基于规则进行控制和流转，烟囱式开发有较大成本，我们需要构建一套日千亿次匹配的规则引擎信号服务，保障资源共享，实现新增场景一键配置即可支持。</p><p></p><h4>问题 4：全链路全生命周期信号服务质量保障</h4><p></p><p></p><p>内容场景中实时信号通常用于审核、运营等核心在线场景，稳定性要求极高。而数据往往面对依赖组件多、链路长、吞吐高等问题，会引起反压、偶发崩溃等多种质量问题，需要我们建设一套通用的质量保障体系，包括可观测性、状态高可用等。</p><p></p><h2>3. 整体架构</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a9/a96756d885e065951ac042c2aeb7119a.png\" /></p><p></p><p>图 3-1 内容生态实时信号系统架构图</p><p></p><p>数据接入：构建准确统一的基础数据，通过动态新增数据 Topic 自适应感知、十万级 QPS 的 ID 映射等手段，解决数据源消息 Topic 动态拓展无法自动感知、数据孤岛等接入问题。</p><p></p><p>信号生产：提供滑动大窗口计算、多流 TB 级数据拼接、融合批数据重建流状态、单体流量适应水平扩展等通用解决方案，保障大吞吐下的信号生产的时效性、稳定性。</p><p></p><p>规则引擎：结合业务个性化触发逻辑，提供统一的规则引擎触发系统，支持日千亿次的实时规则匹配、信号高效去重分发，保障多样场景一键快速支持。</p><p></p><p>信号工厂：一些信号特征无需经过规则引擎流转，按照主题管理，直接透传给业务应用。</p><p></p><p>服务质量：我们构建了全链路全生命周期的服务质量保障体系。包括全链路可观测性系统，Flink 核心状态高可用设计、全生命周期质量监控和解决流程、元数据管理等。</p><p></p><h3>3.1 数据接入</h3><p></p><p></p><h4>3.1.1 动态实时源自适应感知</h4><p></p><p></p><p>腾讯内容中台，提供一站式工业化的内容加工能力，每个业务方可自定义编排加工内容的任务流拓扑。为了稳定性和隔离性，每条任务流拓扑内容加工操作流水会生成一个 Topic，随着业务发展，新的 Topic 会不断增加，同时存量 Topic 数据量可能变大。因新增 Topic 所属集群地址差异大，Flink Source 无法用正则匹配到，导致程序无法自动感知。因此，我们设计了 Topic 动态添加的自适应感知的技术方案，可以做到：</p><p></p><p>数据完整性：自动感知新添加的拓扑 Topic，保证数据不遗漏。数据时效性：存量的 Topic 数据量级变大时，能够自动扩容，保障整体时效性。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/8c/8cabe2a3d04fa4251f29f99ac15e0df2.png\" /></p><p></p><p>图 3-2 动态实时源自适应感知示意图</p><p></p><p>主要由以下几个模块构成：</p><p></p><p>控制器模块：监测消息队列并通过配置中心异步控制 Flink 的消费。新增 Topic 时，注册到配置中心。Topic 数据量变大导致消费延迟时，增加该 Topic 的消费并行度。配置中心：存放所有拓扑的消息队列，如拓扑 ID、消费并行度、Kafka 配置。Flink 自适应 Source：自适应消费 Kafka 数据，保障数据完整性和时效性。在 Task 内开启消费线程池，负责 Kafka 的消费；并有自适应 Client，负责控制线程池的消费，每分钟执行一次，保障消费的完整性和时效性。步骤 1：拉取所有消息队列配置。步骤 2：生成本 Task 消费的 Topic 消费列表，保障并行度 N 的 Topic 会被 N 个 Task 消费。总 Task 数目是 M，每个 Task 会被分到如下 Task 中：hash(pipeline_id) % M 到 (hash(pipeline_id) + N) % M。遍历 Topic 可能被消费的 Task 列表，如果其中包含本 Task，则可对其进行消费。步骤 3：调整线程池消费列表，如果步骤 2 中添加了 Topic，则添加对应 Topic 的消费。</p><p></p><h4>3.1.2 十万级 QPS 高并发 ID 映射</h4><p></p><p></p><p>因每个业务渠道（如腾讯新闻、QQ 浏览器等）有自己的内容 ID 体系，为此，在整合各渠道的消费流水时，我们需要将业务 ID 映射成腾讯内容中台统一的内容 One ID 体系。如果直接请求现有的 ID 映射服务，大量的网络 IO 会消耗较大的实时流计算资源。</p><p></p><p>为此，我们构建了基于二级缓存的 ID 映射解决方案，大幅降低对远程服务的访问，可节约上百倍的计算资源。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/cf/cf3ccf269dc5861cc4d9e8e2fb947abb.png\" /></p><p></p><p>图 3-3 基于二级缓存的实时 ID 映射</p><p></p><p>如上图所示，具体步骤如下：</p><p></p><p>获取中台 ID：首先判断应用内状态中是否有该 ID 的缓存，如果有则直接返回中台 ID；如果没有，则访问 ID 映射服务，并将其更新到 State 中。一级缓存：在程序中构建 Flink 应用内状态（Flink State），缓存渠道 ID 到中台 ID 的映射。因为远程拉取中台 ID 时有缺失，缺失时无法判断是当时映射服务有遗漏但是后续请求能映射上，还是该渠道 ID 本身无法映射到中台 ID，为保障数据准确性，我们构建了 2 种 State 控制 ID 映射：可以映射的 State：存放渠道 ID 到中台 ID 的映射，为规避状态膨胀，TTL 设置成 7 天，过期时间从最近一次访问时间开始计算。不能映射的 State：存放未映射上的渠道 ID。为保障整体数据可用性，需要定期强制重新拉取中台 ID，将 TTL 设置成 1 小时，过期时间从第一次访问时间开始计算。二级缓存：远程 ID 映射服务，通过 Rest Api 访问。拼接 ID：在消费流水中，拼接上中台 ID。</p><p></p><h3>3.2 信号生产</h3><p></p><p></p><p>在实际应用场景中，需要提供多样的实时特征信号，信号生产过程中，我们遇到了多种挑战，本章将结合实际问题，介绍我们通用自研的解决方案。</p><p></p><h3>3.2.1 千亿次滑动大窗口计算</h3><p></p><p></p><p>在内容场景中，需要对内容消费数据的大时间窗口 (如 1 天、30 天等) 的每分钟滑动指标进行日千亿次的实时流计算，并基于这样的数据指标来控制业务流转，如果我们直接基于 Flink 内部的窗口函数，进行实时计算窗口指标时，因不能及时关闭窗口，状态数据会占用大量的内存，导致计算出现反压的情况，程序稳定性差，容易出现卡死现象。</p><p></p><p>基于上述挑战，我们设计了一种高性能的大窗口计算方法，主要有如下优点：</p><p></p><p>传统的方式需要每次对大窗口中的全量数据做计算，而现有方式可以复用前一次计算结果，可极大减少计算量。我们方案中大窗口是逻辑上的大窗口，相比 Flink 原生的窗口计算会保留大窗口时间内的原始数据，我们在内存中并不存放这些原始数据，只存放算法提到的聚合维度的数据，同时利用数据淘汰机制，防止内存占用过大，节约大量的内存资源。</p><p></p><p>我们针对大窗口（如 1 天）、超大窗口（如 30 天等），结合计算复杂度和精度要求，采用了不同的计算方案，保障小成本高精准计算多种窗口指标。</p><p></p><p>大窗口计算</p><p></p><p>对实时流数据根据数据自身的事件时间是否连续分为如下不同的几种情况：</p><p></p><p>情况一：分钟级别滑动，每分钟窗口连续有流量的情况</p><p></p><p>当数据自身的事件时间连续的时候，我们需要拿到上次大窗口的计算结果值，在上次计算结果的基础上，对窗口的头部和尾部进行加减操作就可以得到新的大窗口的值。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/33/339715766eb781fb32800cb0872c3102.png\" /></p><p></p><p>图 3-4 分钟级滑动每分钟连续的大窗口</p><p></p><p>其中，T(6, 4) 代表的是 6min 时候近 4min 的累计值大小，其中 6 代表的是当前最新时间，4 代表的是需要统计的窗口大小，是人为规定的。M(5) 代表的是第 5min 的值。</p><p></p><p>情况二：分钟级别滑动，每分钟窗口流量不连续情况</p><p></p><p>当间隔的时间小于窗口大小的情况下，计算当前窗口的值需要得到上一个窗口的值进行加减操作，由于数据自身的事件时间中断，所以要对最后一次窗口的值进行校准。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3c/3c2286a6a2794deb183551a34203b20f.png\" /></p><p></p><p>图 3-5 分钟级滑动每分钟不连续大窗口</p><p></p><p>其中，T(5, 4) 代表的是 5min 时候近 4min 的累计值大小，其中 5 代表的是当前最新时间，4 代表的是需要统计的窗口大小，是人为规定的，M(5) 代表的是第 5min 的值。</p><p></p><p>情况三：分钟级别滑动，每分钟窗口流量不连续并且当间隔的时间大于窗口的情况</p><p></p><p>当间隔的时间大于窗口大小的情况下，由于窗口时间内没有出现流量，可以直接认为大窗口的计算值为当前分钟流量值。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/8a/8ad2e15ead655c5fec5db71da8d301cb.png\" /></p><p></p><p>图 3-6 分钟级滑动每分钟不连续大窗口</p><p></p><p>其中，T(6, 4) 代表的是 6min 时候近 4min 的累计值大小，其中 6 代表的是当前最新时间，4 代表的是需要统计的窗口大小，是人为规定的，M(5) 代表的是第 5min 的值。</p><p></p><p>超大窗口（如 30 天）</p><p></p><p>针对 30 天等超大滑动窗口计算，资源开销会成数十倍的膨胀，成本难以承受。我们构建了一套解决方案，成本降低到千分之一，精度只损失了百分之一，在成本和精度间达到了高效平衡。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e1/e1ccb19d54e70fe09357434d5829d172.png\" /></p><p></p><p>图 3-7 超大滑动窗口指标计算</p><p></p><p>如上图所示，计算单个内容 ID 的超大滑动窗口指标过程如下。</p><p></p><p>状态更新：读取消费流水，更新该 ID 的状态值。计算超大窗口指标：基于应用内状态进行计算。如果内容产生时间在 N 天内：取累计流量。如果内容产生时间在 N 天前：基于输入流量的时间取不同范围的数据，整体半天精度，如 30 天超大窗口的误差约 1.6%。00:00—12:00：取过去 N 天 + 当天流量值。12:00—23:59：取过去 N-1 天 + 当天流量值。</p><p></p><h4>3.2.2 延迟流数据滚动大窗口计算</h4><p></p><p></p><p>在内容生态场景中，由于历史原因和服务器时钟问题导致会出现超自然时间的数据，以及网络原因造成的延迟的数据。传统通过设置窗口水印的方式存在一定问题，对于超自然数据，会导致窗口立刻关闭；对于延迟数据，窗口关闭后，延迟到来的数据未能被统计到窗口指标中。</p><p></p><p>为了解决上述问题，我们设计了一种可以同时处理超自然数据和延迟数据的方案，优点如下：</p><p></p><p>对于大窗口的计算有绝对的优势，普通的方式大窗口计算时候由于窗口太大，窗口不能及时关闭，当内存中存在大量的窗口时性能会急速下降。此技术通过聚合 Key 设计，极大的提高了大窗口情况下计算的稳定性、时效性、准确性。提供了及时的内存清理机制，保证聚合 Key 在过期时候能够被及时的清理，保证程序不会随着时间的推移而出现性能的损耗。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/02/0234f630c1581328913fa03d665576a2.png\" /></p><p></p><p>图 3-8 延迟流数据滚动大窗口计算</p><p></p><p>我们窗口计算转换为 Key 的分类聚合问题，通过对要参与聚合计算的 Key 进行巧妙设计，进而实现聚合统计。</p><p></p><p>步骤 1：计算数据所属的窗口起始值，窗口起始时间值 = 事件时间 / &nbsp;窗口大小 &nbsp;* &nbsp;窗口大小，窗口大小是根据业务需求来指定的。对于超自然数据，需要基于业务场景进行时间矫正。</p><p></p><p>步骤 2：根据窗口的起始值对数据进行分配，正常数据直接放入正确的窗口中，延迟数据由于只是晚到，但是数据的生成时间是正确的，所以可以根据窗口标记找到对应的窗口，放入对应的窗口中。</p><p></p><p>步骤 3：对窗口中的数据生成独有的聚合 Key，聚合 Key= 计算 Key+ 日期 + 窗口起始时间值。</p><p></p><p>步骤 4：按照聚合 Key 的值进行 Shuffle 分组，聚合 Key 相同的数据会被发送到同一个计算任务，进行聚合或者更加复杂的计算，并且清理内存中过期的聚合 Key，避免程序随着时间推移出现性能下降问题。</p><p></p><h4>3.2.3 TB 级实时流数据拼接</h4><p></p><p></p><p>Flink 原生实现进行 TB 级数据拼接时，计算较慢，且状态备份时可能异常导致难以升级 APP。</p><p></p><p>因此，我们构建了可以解决大状态下多流拼接的时效性和稳定性问题的技术方案，并保证最终一致性。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/65/654f42f1a28a4c78ff104b9abb878d6e.png\" /></p><p></p><p>图 3-9 基于 HBase 实现 TB 级实时多流拼接</p><p></p><p>主要思路如上图所示，我们借助第三方 HBase 存储完成多流关联。</p><p></p><p>阶段 1：特征拼接，每个源单独加工，抽取自身特征后，进行如下过程：</p><p>步骤 1：将自身特征同步到 HBase 中，每个源只更新自身属性对应的列。HBase 中会包含每个内容最新最全的属性。步骤 2：将有变更的内容推送到消息队列中。当前实现是将所有有变更的内容实时推送下游，可改造该过程，多流水位对齐后再推送，以支持多流拼接的多种语义。</p><p></p><p>在本阶段的存储设计中，HBase 的 Rowkey 为待关联的 Key，列分别为属性 Key 和属性值。同时，我们进行了大量优化设计：</p><p></p><p>批量访问：每 50 个 Key 合并访问，减少 IO。随机主键：将 Key 进行 md5 哈希，让数据均匀分布在 HBase 中，防止热点，提高随机访问性能。存储压缩：部分属性值较大，将其序列化后，使用 GZIP 压缩，减少存储。过期机制：按需设置 TTL，防止数据无限膨胀。</p><p></p><p>阶段 2：特征输出，通过一个程序统一加工处理，可将每个内容的全量特征输出到目标业务系统中。</p><p>步骤 3：实时感知特征有变更的内容。步骤 4：批量拉取内容的全量特征，HBase 中每一列对应一个特征，某个内容的全部列即为其全部特征。步骤 5：入库，将从 HBase 中获取的全量特征，转换成目标存储格式，输出到目标系统。</p><p></p><h4>3.2.4 融合批数据重建流状态</h4><p></p><p></p><p>在内容生态的实时计算场景中，我们经常会遇到累计指标的统计，比如某一条内容的实时总点击数、展现数等。传统的方式主要是用 Lambda 架构进行加工，面对口径发生变化等情形时，会有如下问题：</p><p></p><p>批处理计算和实时流计算两份代码可能由多人维护开发，因此容易造成计算结果不一致。批处理计算和实时流计算切换的时候出现数据抖动，影响用户体验。</p><p></p><p>因此，我们设计了批流状态融合架构，主要优点如下：</p><p></p><p>只需要维护一份实时流计算代码，通用性较好，适合所有实时流需要计算业务历史数据的场景。解决了实时流计算批量回溯历史数据时的算力问题，利用存量批处理计算资源回溯历史全量数据，同时，结合仅需从 T 日零点零分零秒开始的实时流数据，得到口径变化后的完整指标数据。规避了数据的抖动，提供好了良好的用户体验。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/34/34bfbd2ee8ed5818c4876688005c4a0f.png\" /></p><p></p><p>图 3-10 批量融合状态重建架构</p><p></p><p>首先计算业务历史全量累计数据存入 Key-Value 缓存中作为基准数据，把实时数据和基准数据进行融合计算得到最新累计值，并可根据下游系统的负载能力调整数据的输出间隔。</p><p></p><p>步骤 1：初始化时或者业务口径变更后，通过离线批处理计算历史全量数据，作为每个 Key 的基准数据，导入到 Key-Value 存储系统。</p><p></p><p>步骤 2：重启实时流计算应用程序后，每个 Key 根据是否初始化过基准数据，从 Key-Value 中初始化基准数据。</p><p></p><p>步骤 3：将基准数据和实时数据进行合并计算，通过流量控制把数据写入到下游业务存储系统中，供业务查询使用。</p><p></p><h4>3.2.5 单体流量适应水平扩展</h4><p></p><p></p><p>内容生态面临着内容的消费数据越来越大的情况，单个实时流计算程序在 Flink 状态不断增大的情况下，由于单个程序需要维护的状态越来越大，程序频繁出现反压问题，增加程序的并发度也提高不了稳定性。</p><p></p><p>通常我们会增加实时流应用来适应流量水平扩容的架构，但是增加应用后，如果把数据随机发往扩容后的程序，会有一些潜在的问题，例如在计算某个内容 ID 累计值的场景，需要这个内容 ID 对应的所有数据严格发送到同一个程序，才能保证最终结果的准确性。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/36/366a5b35e859fcb56ccfa61e81acbd68.png\" /></p><p></p><p>图 3-11 单体流量适应水平扩容</p><p></p><p>为了解决以上问题，我们设计了如下可以适应流量水平扩展的架构。步骤如下：</p><p></p><p>步骤 1：记录数据首次进入系统的时间，为了防止数据丢失做高可用的持久化存储。</p><p></p><p>步骤 2：维护系统扩容前后的 buckets 的值，当数据过来之后根据数据首次进入系统时间所处的时间段找到对应的 buckets 的值。</p><p></p><p>步骤 3：对内容进行寻址，将内容 ID 哈希后分配到 buckets 个桶中，而下游每个 App 对应一个桶。</p><p></p><h4>3.2.6 输出小文件数自适应流量</h4><p></p><p></p><p>在内容加工场景中，需要将消息队列数据同步到 HDFS 中。同步时，会有 N 个同步子任务，其中 N 由流量峰值决定，N 在同步过程中不能调整，当数据时效性为分钟时，每分钟会有 N 个子文件。然而，在流量低峰期时，由于 N 不会改变，会产生大量的小文件。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/9a/9a5b8c813eba25c1b19d718c3b9a7c12.png\" /></p><p></p><p>图 3-12 输出文件数自适应流量</p><p></p><p>如上图所示，我们构建了一种输出小文件数自适应流量减少的解决方案。取单个文件为目标大小 S（如 64MB），以控制文件数目。我们将整个过程由原来的 1 个阶段拆分成了 2 个阶段：Map 阶段和 Reduce 阶段，其中 Map 任务数是 M，Reduce 任务数是 N。以下两个阶段，每分钟调度一次：</p><p></p><p>Map 阶段：读取数据进行自适应映射。缓存数据：每个任务缓存 1min 的数据。计算本批次产生的目标文件数 K：缓存的数据大小乘以 M 得到本批次所有数据输出大小 total_size，计算当前批次目标文件数 K=total_size/S。均匀映射：每条数据依次加上 1 到 K 的 Key，data 转换成 (k, data)，以方便 Shuffle 控制。Reduce 阶段：Reduce 子任务 k 只拉取 Key 为 k 的数据，这样，子任务 1 到 K 之间会有数据，剩下的任务无数据。因为空任务不会产生文件，这样可以保障本批次输出的文件数为 K。</p><p></p><h3>3.3 规则引擎</h3><p></p><p></p><p>在内容生态中除了实时流信号的生产服务，往往我们还需要进一步基于实时流信号，结合规则引擎管理业务个性化的触发逻辑，以此来支持内容周期智能管理等多种应用场景。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/40/40e3a2d81603eced694930db9a1aa6d2.png\" /></p><p></p><p>图 3-13 基于规则引擎的实时信号触发</p><p></p><h4>3.3.1 规则管理平台</h4><p></p><p></p><p>规则类型</p><p></p><p>基于不同的业务需求场景，规则定义区分了固定规则和动态规则：</p><p></p><p>固定规则：同一规则下所有内容阈值相同。动态规则：同一规则下不同内容阈值可以精细化设置，用于满足基于内容特征属性需要不同的信号触发阈值的需求场景。</p><p></p><p>规则管理</p><p></p><p>提供规则以及内容阈值的增加、更新、查询等能力，并支持如下数据管理能力：</p><p></p><p>规则增删改查：用户可以通过管理端查询规则列表，录入和修改规则。动态阈值增删改查：提供 Rest Api 对规则下内容的阈值进行新增、更新和查询。该能力可支持预估模块训练阈值后，将相应阈值更新到规则配置中；同时供规则执行引擎查询规则配置。</p><p></p><p>规则定义</p><p></p><p>配置模块旨在对规则进行进行抽象，通过定义通用的规则抽象定义，把用户在管理配置信息进行接入存储。解耦用户规则定义和规则引擎，降低用户输入和规则引擎的依赖，这样可以便于我们无负担去升级替换规则引擎而对用户无感。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/58/589f5aeb70dd54f019806f227651a9de.png\" /></p><p></p><p>图 3-14 规则信息</p><p></p><p>规则描述包括两部分，规则条件表达式 + 规则动作：</p><p></p><p>表达式条件：上层逻辑支持且 / 或，支持多个运算算子；表达式动作：支持设置触发优先级以及携带特定信息等</p><p></p><h4>3.3.2 规则执行引擎</h4><p></p><p></p><p>基于上面信号产生的实时信号和规则管理提供的规则信息，我们探索了开源的 Aviator、Flink CEP 等组件。Flink CEP 构建规则执行引擎时有如下问题：</p><p></p><p>不支持规则信息的动态更新，用户使用体验较差。不支持多规则，导致难以平台化。</p><p></p><p>Aviator 支持丰富的运算符和表达式，同时具有轻量级和高性能特点，能够完全覆盖我们的场景。为此，我们选取了 Aviator 作为规则匹配引擎。</p><p></p><p>规则执行引擎主要有如下三个模块：</p><p></p><p>规则加载</p><p></p><p>负责进行执行器所需配置的加载和实时感知，主要提供如下能力：</p><p></p><p>规则变更秒级感知：负责加载规则列表，并保障规则变更后能及时同步，包括规则信息变更、规则添加、规则删除等；动态规则的阈值同步：动态规则中，每个内容有自己的阈值。在进行动态规则匹配时，可以实时获取（内容 ID、规则 ID）对应的阈值。</p><p></p><p>规则路由</p><p></p><p>从输入信号中提取业务渠道，和规则中业务渠道进行关联匹配，依次路由到不同的规则匹配算子中。</p><p></p><p>规则匹配</p><p></p><p>为不同规则提供相应的匹配能力：</p><p></p><p>固定规则：将获取到的信号和每个规则进行轮询匹配。匹配时将规则中表达式和信号作为作为输入，通过 Aviator 进行匹配，如果信号满足规则，则将信号和规则关联，输出到下游。动态规则：整体流程和固定规则一致，但因为规则中阈值是动态的，需要进行设计以适配 Aviator：动态阈值作为实体元素放入表达式中（如 vv_1_day&gt;=dynamic_value）中，将拉取的（内容 ID、规则 ID）的阈值拼接入输入信号中，字段为 dynamic_value，即可以实现动态规则的匹配。</p><p></p><h4>3.3.3 规则匹配优化</h4><p></p><p></p><p>并发匹配：由于单个任务计算能力有限，把数据分为若干份，在多个任务中进行规则匹配，极大的提高了规则引擎在大数据量场景下的匹配能力。</p><p></p><p>二级缓存：动态规则匹配时，需获取（内容 ID、规则 ID）的阈值，因输入信号峰值 QPS 数十万，拉取阈值会有较大网络 IO，造成极大资源开销。参考前文 ID 映射的解决方案，我们构建了（内容 ID、规则 ID）-&gt; 阈值的二级缓存，可以极大节省匹配资源。</p><p></p><p>预编译技术：进行规则匹配时，首先将规则编译成机器能理解的字节码，然后将上游信号作为数据输入进行匹配运算。该过程主要耗时在将规则编译成字节码阶段，我们将规则对应的字节码进行缓存，可以节省上千倍的算力开销。</p><p></p><h4>3.3.4信号去重分发</h4><p></p><p></p><p>信号去重</p><p></p><p>经过规则执行引擎后，仍然能召回大量信号，针对审核等场景，一个内容触发后，短时间内不需要再次输出，以免重复审核。为此，我们进行了个性化去重模块，支持灵活的去重周期，如永久去重、天级去重等，为不同的业务场景召回所需的信号。</p><p></p><p>信号分发</p><p></p><p>下游有多个业务系统，基于规则和业务场景的关系，将信号分发给对应的业务模块。分发方式支持消息队列投递以及接口回调，业务可以根据需要进行定制。</p><p></p><h3>3.4 服务质量</h3><p></p><p></p><h4>3.4.1 端到端全链路服务可观测性</h4><p></p><p></p><p>实时流服务对接的数据源多、加工链路长，会导致如下问题：</p><p></p><p>问题发现慢：因为很难衡量端到端时效性，导致很难感知整体延迟，往往业务反馈后才知道。定位时间长：需一步一步联系上游环节，以确认数据延迟源头。</p><p></p><p>我们构建了全链路端到端端的可观测性系统，可以监控端到端延迟并快速定位问题环节，主要分位以下 4 个模块：</p><p></p><p>数据染色：如图 3-15 所示，本模块集成到各个加工程序中，将本环节和上游各个环节的时效性信息染色到输出数据中，如事件时间、输出时间等。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/10/10e79f0f760efd2efa0e987764924ecf.png\" /></p><p></p><p>图 3-15 数据染色示意图</p><p></p><p>时效性统计：因为每个环节的输出包含自身以及上游各个环节的时间信息，可基于某个环节的输出数据，统计从数据源到当前环节端到端分环节、分数据源的时效性信息。延迟监控：基于统计模块计算的数据，监控端到端的延迟。可观测分析工具：基于统计产生的数据，可以构建全链路实时拥堵分析工具，快速定位问题源头。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/72/72da6285bb0b54075e8c552eb740f35c.png\" /></p><p></p><p>图 3-16 全链路实时拥堵分析</p><p></p><h4>3.4.2 旁路系统保障状态高可用</h4><p></p><p></p><p>内容生态中，计算内容的累计值、首次时间等场景，强依赖于 Flink 自身状态，但是因为依赖组件异常等原因，导致 Flink 有概率丢失状态，无法满足对数据一致性要求非常高的场景的需求。</p><p></p><p>我们构建了旁路系统，保障 Flink 状态异常丢失后，作业重启后核心状态的高可用。架构如图所示，主要由 2 个模块构成</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ed/edbb4adab1f825f96f9449861f36c35d.png\" /></p><p></p><p>图 3-17 旁路系统保障状态高可用</p><p></p><p>旁路系统：程序外起一个异步作业，将核心状态从输出中实时同步到 Redis 中。Flink 应用内状态恢复模块：为访问 State 的前置逻辑，如果 Key 在应用内状态中丢失，则从远程 Redis 中恢复。</p><p></p><h2>4. 信号应用</h2><p></p><p></p><h3>4.1 内容质量智能审核</h3><p></p><p></p><p>创作者文章发布后，需要进行相关必要审核，以保障线上内容的安全、优质、健康。因此，我们构建了智能审核机制，可以保障内容更高效的分发，更快地触达用户。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3a/3a1bee771be5d90515aef1b1c3b17c69.png\" /></p><p></p><p>图 4-1 内容质量智能审核流程</p><p></p><p>整体流程如上图所示，主要有 2 个模块：</p><p></p><p>模型训练：每个个性化审核流程对应一个规则，需要为不同规则训练各自的模型。实时审核：接入内容的消费流水后，计算其 1 天、30 天等滑动窗口指标，然后基于规则引擎进行匹配，将匹配的内容转换成信号输出，送入审核系统进行个性化审核。</p><p></p><h3>4.2 内容周期智能管理</h3><p></p><p></p><p>为满足不同用户的体验，需要给内容进行多种场景适配，随着内容不断增加，服务商成本非常高。为此，我们提供了一种基于内容周期提供分级服务的能力，在保障整体体验的前提下，可有效降低成本。当内容访问量达到一定阈值时，提供可适配多种场景的服务能力，保障用户体验；当内容访问量极低时，只提供基础服务，降低成本。</p><p></p><h3>4.3 内容加工智能路由</h3><p></p><p></p><p>内容从生产到消费，中间会有大量的个性化加工需求，围绕其构建了一套微服务编排系统。其中会有调度器控制任务的分发、路径寻优、弹性伸缩等工作，在不同的算法选择中，通过性能效果的实时反馈，可以极大提升调度效果，减少加工耗时，提高处理成功率。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/25/25fb5403e2a20ab5e0a66e83fe2d3d72.png\" /></p><p></p><p>图 4-2 实时信号赋能网络流量智能路由</p><p></p><p>如上图所示，主要有以下几个过程：</p><p></p><p>采集模块：采集执行节点的性能数据，如事件、算法、模块、耗时、加工状态（成功或者失败）等信息。加工引擎：实时计算不同算法的 PT95，PT99 等分位耗时、成功率等指标，并反馈给调度器。智能路由：调度器里根据实时反馈，选择合适的算法，进行任务分发、路径寻优等。</p><p></p><h3>4.4 内容创作精细运营</h3><p></p><p></p><p>内容创作运营平台会发起各种精细化运营活动，围绕实时信号，可以进行分析、达标判断等，高效的对作者进行拉新、留存。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/92/92d2165e3ad58de5fb3f8d4a12d3fb30.png\" /></p><p></p><p>图 4-3 内容创作精细运营</p><p></p><p>如上图所示，运营人员发起运营活动后，创作者领取相应运营任务，并进行发文。基于实时计算的消费量、互动量等特征信号，可以进行活动达标判断，进而将激励实时触达给创作者，提升运营活动效率。</p><p></p><h2>5. 未来计划</h2><p></p><p></p><p>目前，我们已经在基于 Hudi 数据湖进行了一些批流一体的基础场景的探索，后面我们会进一步的将本文一些复杂、成本高的场景迁移到数据湖中，比如探索数据湖上实现 TB 级别实时流数据拼接、批流融合状态重建等场景的可能性，实现一套代码，两种执行模式；一套系统，统一技术栈；一套运维，统一资源调度。</p><p></p><p>另外，当前计算模式能较快、较好地满足业务发展需求，随着行业降本增效的大环境，我们未来会围绕快、好、省的方向更好的支持业务。比如探索计算资源动态弹性自适应、存储等方向，技术赋能业务。</p><p></p><p>作者介绍： </p><p></p><p>王冬，腾讯内容中台研发工程师，熟悉技术产品、技术优化、技术赋能、技术管理等领域。</p><p></p><p>杨浩，腾讯内容中台数据研发工程师，专注数据平台、内容处理的架构设计与研发。</p><p></p><p>李文斌，腾讯内容中台数据研发工程师，专注海量实时数据高性能处理，通用性架构设计。</p><p></p><p>王玢，腾讯内容处理中台产品设计师，专注内容处理全链路设计，智能化处理工具设计。</p><p></p><p>李会珠，腾讯内容处理中台后端研发工程师，关注微服务、内容处理、流程引擎、高并发架构领域</p><p></p><p>最后，感谢 kyler、richard（飞哥）、stan、mars、gavin、jamie 等的大力支持指导，以及腾讯数据科学与分析中心、腾讯内容处理中心、相关业务团队每一位成员的共同付出。</p>",
    "publish_time": "2022-11-13 11:57:11",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "基金交易场景下，如何利用 Apache APISIX 来稳固 API 安全",
    "url": "https://www.infoq.cn/article/3FUgUiSw2fL7Pjv0hrqk",
    "summary": "<p></p><h2>背景介绍</h2><p></p><p></p><p>金融领域的企业中，安全是非常重中之重的因素。通常各类金融企业都会花费大量成本去采购安全相关的设备和硬件，基金管理相关企业更是如此。</p><p></p><p>根据相关国内基金管理行业发展现状分析报告中可以看到：“我国基金管理行业在经历野蛮生长、严监管规范以及次贷危机冲击等阶段后，目前已经形成了监管规范化不断加强、公司格局完善的局面。在大众投资理念转变的背景下，基金管理行业规模稳步增长，行业发展空间有望持续扩大。”</p><p></p><p>从现实数据来看，大环境和人们理财意识的逐渐增强，使得基金行业在业务发展的过程中，对于技术业务上的呈现也开始有着更高的追求。</p><p></p><p>比如稳定性，这里说的稳定性并不是应对类似双十一那种突增流量时的业务表现，而是保证业务长久线上的稳定性和持续性。</p><p></p><p>其次就是有效性和准确性，它与稳定性是相辅相成的。因为金融领域有着非常严格的交易时间，尤其是证券和基金行业。大量的交易都会发生在固定的时间段内，因此相关时间内的有效性和准确性是必须要保障的。即业务场景下允许系统慢，但不允许崩。</p><p></p><p>最后就是开头内容中提到的严监管规范，也就是政策层面的监管强度。因为行业的特殊性，在业务安全和企业治理中，很多时候它是需要考虑行业色彩和大环境的。</p><p></p><p>得益于这些业务色彩，我们也会对基金行业的一些业务架构产生兴趣，比如他们是运用哪些方式来保障高监管要求下的业务安全。在这里，我们选取了目前使用 APISIX 的一家基金行业用户，带来他们的业务网关架构演进与基于 APISIX 进行的业务安全实践细节。</p><p></p><h2>行业现状与痛点</h2><p></p><p></p><p>这家公司是从 2012 年开始搭建相关交易系统，API 规模大概在 12000+ 数量，包含 PaaS、BaaS、两地三中心、安全、运维、中间件和 DevOps 平台等等。公司业务的整个系统架构演进大体经历了三个阶段。</p><p></p><p>在业务刚起步阶段（1.0 时代），业务架构还非常单一，基本是能应对基金买卖的简单场景即可，属于单体架构模式。随着后续业务的扩充和国内市场环境的影响，架构也随之进行了初步的更新迭代。在这个阶段下，开始对业务进行了简易分割。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/4d/4d7be94eca4deb4aefb04f2faa1cd82b.png\" /></p><p></p><p>上图就是当时最简单的架构模式，相信大家对这种架构类型都比较熟悉。即有一套简单的前端配置，包括应用、网站等等。从整体来看，业务模型比较简单，因为只需搭建好交易体系即可，搭配上完整的支付业务和鉴权服务。后端主要是去维护相关的基金交易数据，然后存储到数据库里。</p><p></p><p>当然这里的鉴权服务并不是指网关层面的呈现，而是基金业务与其他第三方基金公司之间的连接鉴权。比如跟外部的基金业务对接时，需要进行双方数据的对接，这种时候就需要有一些 Token 去进行鉴别和限制等等。</p><p></p><p>当时还没有网关的概念。在这个架构下类似现在网关概念的就是图中的 HSB（服务总线），它其实就是网关的前身，主要用来控制南北向流量。</p><p></p><p>人们总说，在公司业务或者行业发展过程中，总会出现一些节点来加速或者改变某个行业的进程。2015 年国内股市的业务爆发，也导致了基金业务公司开始进行业务扩展。市场方向的快速推动下，业务也开始加速前进。</p><p></p><p>这种情况下，该基金公司的后端业务就需要进行大量的变动，开始演进到如下图所示的架构类型（2.0 时代）。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/9d/9d0e1ada01dd03cc4380209ee48c1b41.png\" /></p><p></p><p>如上图红线圈出来的地方，可以明显看到，之前的服务总线模块开始变得复杂，各种业务组件纷纷出现。之所以变得复杂，是因为在业务野蛮生长阶段时，它会因为一些需求现状各自进行产出。</p><p></p><p>举个最简单的例子，就像各地的健康码系统一样，各省都不一样，甚至有的同一个省的不同地市还会有单独的系统。因为在产出过程中，我们会发现「自己造自己家的烟囱」是最快最快速的方式。</p><p></p><p>那么这种情况下就衍生出另外一个问题，也就是在系统发展过程中，一定会伴随所谓的技术债务问题。就是不同负责人在位时，所选择的技术栈或系统模型各不相同。</p><p></p><p>这个过程中就会出现一些业务库的拼装，因为当下的服务场景开始变得复杂。所有的这些新增动作等都需要通过后台系统的组合，来完成前端的某一个动作。因此这种组合的过程中将，势必要用到很多种类的组件以及经历几次产品更替，系统就开始变得复杂和繁重。</p><p></p><p>上述业务现状的演变下，不少问题就开始涌现。如下图所示，从三个层面进行了一些汇总。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/4c/4c538b81c901aac0cec4ca1068512950.png\" /></p><p></p><p>当然除了上述提到的这些在外，在业务层面还会有其他一些问题。比如：</p><p></p><p>技术成本开始变高，整体性能有所影响。网关技术栈的不统一，导致需要同时维护多种协议与微服务框架，开发维护成本较高；随着业务的规模越来越大，像大部分金融企业都选择基于 Java 做中间件，在处理大流量 QPS 时所需的服务器资源越来越多，整体性能冗杂。微服务框架的侵入性强，存在安全隐患。当下无论是 API 治理、审计还是鉴权，基本都依赖微服务框架和 SDK 来进行。因此每次版本的更新，不仅带来运维风险，还容易引发大量内部业务矛盾。缺少更高阶功能的需求满足。如果一个架构中，业务系统网关都是自研的，那么任何功能都要从 0 进行开发编写，这个过程中需要考虑一些时间成本问题，同时在业务层面可能只会实现相对简单的功能，比如缺少服务发现和部分监控指标等功能。这对于后续的业务发展就会造成一些技术上的瓶颈。</p><p></p><h2>技术选型与架构更新</h2><p></p><p></p><p>在后续业务发展过程中，这家基金公司在 2020 年时开始对网关产品进行单独选型。</p><p></p><p>在 2018 年左右时，Spring Cloud 其实非常盛行，金融行业内有很多企业都开始使用 Spring Cloud Gateway。同时金融行业的架构中，大多都是基于 Java 进行的，所以开发人员中大多都是熟悉 Java 的。</p><p></p><p>而当时这家基金公司并没有跟随行业的普遍方案，去选择 Spring Cloud Gateway，而是最终确定了 Apache APISIX 作为他们的网关。之所以没有选择 Spring Cloud Gateway，主要原因如下图所示。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/fb/fb9fa8156c9a888c86ed8a1c789726ad.png\" /></p><p></p><p>当然除了上述原因外，还有一些实际大环境的因素。2019 年左右，P2P 事件开始曝光，很多 P2P 公司倒闭。当时整个金融领域尤其是基金交易领域，发生了翻天覆地的变化。各家企业都开始进行成本压缩，所以在架构选型中，还需要面对成本压缩的考虑因素，去进行选型。</p><p></p><p>因为公司要压成本，同时也开始要求把一些非交易系统放置到云上。作为技术人员，这种情况下就会考虑如何让上云时更方便更高效，因此面临这种场景时，技术栈能被统一地越少越好。所以他们就开始往云原生方向的网关产品去观望。最终，结合业务表现和技术栈统一相关的成本因素，最终选择了 APISIX。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/84/849ecc473b154dab3df0b8b4de635f38.png\" /></p><p></p><p>基于 APISIX，该基金公司的业务架构更新成了如下图所示的全新模块（3.0 时代），这其中将架构分成了前中后模式，并对代码进行了分层。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/4a/4a3e676a8b1fe3f781ddfbd1a34d64ec.png\" /></p><p></p><p>从外部进入的流量（南北向流量）经过 APISIX 后，可以进行一些安全控制、流量管控和准入控制（比如灰度）等。而在应用层与业务层以及业务层与基础层中间，会用 APISIX 来解决东西向的流量。由于该基金公司当时大部分的系统是运行在 VMWare 虚拟机上，只有测试的交易系统是跑到 K8s 上的，所以他们的 CI/CD 比较复杂，因此 APISIX 在这里处理东西向流量时，主要是进行统一入口、监控报警、分流和鉴权相关操作。</p><p></p><h2>基于 APISIX 的业务安全实践</h2><p></p><p></p><h3>微服务治理</h3><p></p><p></p><p>微服务主要解决东西向流量。APISIX 在进行整个微服务治理的过程中，主要会帮助企业解决统一入口、API 配置管理、分流鉴权、服务监控、协议转换等问题，具有分布式和可拓展的特性。</p><p></p><p>前文我们提到过该公司业务架构中也存在比如鉴权模块，但当时他们用 Java 的一些扩展包进行了自研。但发展到后期，业务开始进行统一时，各个平台都需要对接进来，问题就开始出现了。</p><p></p><p>因为除了产品、中间件等等业务平台，还包括账户中心等等，这些之间的相互联动，不止需要进行 HTTPS 的相关加密，还会存在一些单点必要需求等。</p><p></p><p>为了满足这些业务间联动和相关加密处理需求等，该基金公司就利用 APISIX 在中间件部分（APISIX 作为网关是其中一部分）作为单点入口，去处理这些联动和安全层面的需求对接，如下图所示。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/96/96b05523c83f164cd71e67028f0a4ada.png\" /></p><p></p><p>其中在服务治理层，会涉及到一些协议转换，而 APISIX 具备成熟的服务治理框架去对接 Dubbo 以及进行 MQ 服务之间解耦。APISIX 的基础协议支持的类型非常多，包括 HTTPS、MQTT、Dubbo、gRPC 和 WebSocket 等多种类型。比如在实际使用时，可以通过 APISIX 内置的 dubbo-proxy 插件来实现代理 Dubbo 协议，无需再进行相关配置的从 0 到 1，而是直接开箱即用，轻松地将 Dubbo Service 发布为 HTTP 服务。</p><p></p><h3>认证授权</h3><p></p><p></p><p>身份认证在日常生活当中是非常常见的一项功能，大家平时基本都会接触到。比如用支付宝消费时的人脸识别确认、公司上班下班时的指纹 / 面部打卡以及网站上进行账号密码登录操作等，其实都是身份认证的场景体现。可以说身份认证是保证基金交易安全稳定运行的重要因素之一。</p><p></p><p>之前该公司是利用 Java 的一些自研组件或者程序逻辑等来作为「类似网关作用」进行相关的认证授权。但整体会出现负载压力大，且不支持流量控制和灰度等能力，同时还缺少相关项目维护人员。在使用 APISIX 后，他们开始利用 APISIX 去提供认证和授权的相关能力，来帮助自家业务进行统一管理和高效运维。目前 APISIX 所支持的插件也已达到 80+，其中也内置不少认证鉴权相关的插件。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c9/c9e5d82042cee9ac43eae50bd515ee67.png\" /></p><p></p><p>比如借助 APISIX 内置的 jwt-auth 插件或 openid-connect 插件，在业务内部和外部之间进行一些认证交互，实现如下一些场景：</p><p></p><p>应用级：内部应用通过应用级 AT 到账号系统，然后根据用户 ID 等数据直接查询用户的信息，无需用户授权；用户级：用户授权应用，应用通过用户授权生产的用户级 AT，到账号查询用户的 openid、unionid 和头像等用户信息。</p><p></p><h3>SSL 证书</h3><p></p><p></p><p>在系统建设的初期，该公司架构基本都是基于 HTTP 协议或一些自定义协议进行互相调用。但是通过 HTTP 协议传输的是明文数据，不会对数据进行加密。但在基金交易系统中，无论是因为政策监管还是安全需要，即使在内网也需要通过 HTTPS 访问数据。</p><p></p><p>在之前的安全功能呈现上，该公司都是直接采购安全类产品进行防护，但是使用过程中必然少不了三方的维护等环节。在架构演进过程中引入 APISIX 后，刚好解决了该场景下的一些需求。从而方便根据业务需要进行灵活调整，同时在成本层面抛弃防火墙等产品，优化了运维流程，最重要的是也满足了相关监管需求。</p><p></p><p>比如 APISIX 在 SSL 证书功能上就支持单一域名、泛域名、多域名和单域名多证书的多种场景。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a9/a9fac7246280efda5d086dcf90d5e776.png\" /></p><p></p><p>APISIX 支持通过 TLS 扩展 SNI 实现加载特定的 SSL 证书，以实现对 HTTPS 的相关支持。启用该特性后，将允许客户端在服务器端向其发送证书之前向服务器端发送请求的域名，服务器端将会根据客户端请求的域名选择合适的 SSL 证书发送给客户端。</p><p></p><p>所以在安全相关的功能准备中，很多东西都是顺应着大环境的要求和一些架构更新过程中的业务统一而进行的。并不是说因为有了 APISIX 这种类型的云原生网关，才开始去重视业务上的安全问题，而是说有了 APISIX 网关，可以让企业业务安全更高效更简易地进行管理和操作。</p><p></p><h2>总&nbsp; &nbsp; 结</h2><p></p><p></p><p>以上就是从基金交易业务的场景下，带来了泛金融行业在进行业务架构迭代过程中的变更与相关安全实践。在业务机构更新的过程中，如果没有类似 APISIX 这种网关中间件的能力加持，或许就没法轻易地满足业务上的高速发展，也没有办法轻易解决行业野蛮增长过程之后的复杂技术债问题。</p><p></p><p>所以不管是企业治理还是稳固业务安全，选择一个健康持续发展的中间件产品，是非常有利于业务架构的升级与后续拓展的，同时可以最大限度地帮助企业去解决技术债务。为什么选择技术债务这个点，因为它是我们在社区通过一些企业用例反馈之后，发现的一些企业选择 APISIX 的痛点之一。</p><p></p><p>所以纵观该基金企业的整个系统演化过程，都是用业务去推动选型。通过对性能、可拓展性以及安全等层面，Apache APISIX 都用更实际的数据和效果证明了它作为网关和中间件属性的作用，在保证性能的同时，也为金融行业的业务安全带来了最稳定的保障。</p><p></p><p>讲师介绍： </p><p></p><p>王晔倞，现任 API7 VP，Apache APISIX Committer。公众号「头哥侃码」作者，曾在好买财富、大智慧、中通服软件、东方购物任职，21 年 IT 从业经验，对技术管理和架构设计有一定的经验。TGO 鲲鹏会上海理事会成员，腾讯云 TVP，QCon 北京 2017 明星讲师，QCon 北京 2018 优秀出品人。</p><p></p>",
    "publish_time": "2022-11-13 12:02:43",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "收购推特后，马斯克称每周工作120小时； Meta被裁员工吐槽小扎领导力太差；周鸿祎称360基本不触碰用户数据 | AI一周资讯",
    "url": "https://www.infoq.cn/article/fyhrSOCD8a44xSRiJ6YU",
    "summary": "<p></p><blockquote>宇视科技总裁：管理层不主动降薪就是格局问题；周鸿祎称 360 基本不触碰用户数据；高中老师花半小时将“羊了个羊”改成“历了个史”后爆红；GitHub 面临集体起诉，索赔 647 亿元；95后记者1.96亿收购上市公司 ；vivo 自研芯片 V2 亮相......</blockquote><p></p><p></p><h2>资讯</h2><p></p><p></p><h4>收购Twitter后，马斯克称每周工作120小时，但公司仍有可能破产</h4><p></p><p></p><p>近日，在第29届年度巴伦投资大会上，<a href=\"https://www.infoq.cn/article/1jdi4LDTycjblozS8QwV\">马斯克</a>\"接受采访时表示，“我的工作量从每周大约70-80个小时增加到可能120个小时（平均每天 17 个小时以上），一旦Twitter走上正轨，我认为它要比SpaceX或特斯拉更容易管理得多。”另外，马斯克还谈到了Twitter目前的问题和未来展望，他表示，Twitter的收购价格偏高。</p><p></p><p>此外，据外网报道，马斯克本周三曾表示，他计划把推特打造成一个人们可以在这里购物，甚至提供货币市场账户的地方。这个计划有些像支付宝之前推出的余额宝。</p><p></p><p>马斯克表示，“下一步将是提供一个极具吸引力的货币市场账户，以便让用户获得极高的余额收益率”，“我准备在推特上执行 22 年前 X.com（PayPal 前身）的商业计划，并作出一些改进”。</p><p></p><p>据了解，马斯克在接手Twitter后进行了大刀阔斧的改革，继上周大幅裁员后，本周开始要求结束硅谷技术企业常用的远程办公模式，理由是Twitter前路“艰难”，必须“加紧工作”，找到盈利新办法。11月9日晚，马斯克向全体Twitter员工发送电子邮件，要求员工停止远程办公，10日一早到办公室上班，每周在岗时间至少40小时。</p><p></p><p>马斯克在给Twitter员工的电子邮件中警告称，他不能排除公司破产的可能性。“如果Twitter不能通过增加订阅收入以抵消广告收入下降的影响，那么公司很可能无法在即将到来的经济衰退中幸存下来。”</p><p></p><p>当地时间周五，马斯克又面向全体员工发送了一封电子邮件，感谢他们自10月28日（马斯克接管推特）以来的长时间工作。马斯克在邮件中称：“我周四重返推特总部，一直呆到深夜。我要对那些和我呆在一起的人，以及那些远程办公的员工表示感谢，他们其中一些人的工作时间甚至更长。” “我要重申的是，如果你确实无法到公司办公，而且你的表现也非常出色，那么远程办公也是可以的。尽管如此，我还是非常相信团队精神，以及办公室办公的有效性。今天，我还会在办公室。如果你想谈谈推特的未来，可以来10楼找我。”</p><p></p><h4>Meta暴裁1.1万人，被裁员工吐槽：扎克伯格领导力太差，元宇宙部门受过多关注</h4><p></p><p></p><p>据《华尔街日报》报道，<a href=\"https://www.infoq.cn/article/HV3jCMXQZEdCZUNgeevH\">Meta</a>\" 正着手裁员 1.1 万人，约占其员工总数的 13%。为此，公司高管要求员工本周取消非紧急旅行。尽管就裁员百分比而言，裁员幅度明显小于 Twitter 50% 的裁员幅度，但从绝对值来看，预计这将是当前期间科技行业中裁员人数最多的一次。</p><p></p><p>公司 CEO 扎克伯格在周三致员工的一封信中表示，实施裁员的原因是 Meta 收入下滑 ，且科技行业整体态势不佳。</p><p></p><p>扎克伯格指出，他当初做出了积极的招聘决定，认为在新冠隔离结束后，业务仍会保持快速增长。“但很遗憾，事态的发展与我当初的预期有所偏离。不单电子商务回落到疫情前的水平，而且宏观经济低迷、竞争加剧和广告业务缩水导致我们的收入远低于预期。我的判断是错的，我要对此负责。”</p><p></p><p>据外媒报道，那些在裁员中失去工作的人，则将此归咎于扎克伯格糟糕的领导力。一位Meta员工讽刺扎克伯格“真了不起”。</p><p></p><p>据了解，扎克伯格与前员工之间的主要分歧在于，他对元宇宙的过分关注在内部引发了不满。一位受到裁员影响的员工说：“元宇宙和Reality Labs受到的关注太多了。”该公司的一位前招聘官甚至说：“我们之所以会落入这般境地，都拜糟糕的领导力和管理不善所赐。”</p><p></p><h4>国家虚拟现实创新中心在南昌揭牌</h4><p></p><p></p><p>11月12日，在2022世界VR产业大会开幕式上，国家虚拟现实创新中心正式揭牌。资料显示，国家虚拟现实创新中心由工业和信息化部批复，依托南昌虚拟现实研究院有限公司组建，建设地位于江西南昌，股东单位汇聚了虚拟现实硬件、软件、内容制作与分发、应用与服务等环节的行业骨干力量。</p><p></p><h4>美国最大芯片代工厂格芯开始裁员并冻结招聘</h4><p></p><p></p><p>据《科创板日报》11 月 12日报道，格芯周五向员工通报了即将进行的裁员，但没有透露具体的裁员时间或哪些部门将受到影响。格芯的一位发言人证实了裁员和招聘冻结事宜，但拒绝透露具体的裁员人数。发言人指出，公司正在“对我们的员工队伍采取目标明确的行动”。该发言人补充称，格芯“在第三季度表现强劲，第四季度的业绩指引也很稳健，但基于目前的宏观经济环境”，公司正在寻求控制成本。</p><p></p><h4>苹果宣布拨款4.5亿美元用于开发支持SOS服务的关键基础设施</h4><p></p><p></p><p>据界面新闻11月11日消息，苹果公司当地时间11月10日宣布，将从先进制造基金中拨款4.5亿美元，用于开发支持卫星紧急求救（SOS）服务的关键基础设施。其中大部分资金用于卫星服务供应商Globalstar，包括扩大和加强阿拉斯加、佛罗里达、夏威夷、内华达、波多黎各和德克萨斯州的Globalstar地面站。</p><p></p><h4>又一家 AI 芯片公司倒下？创业10年烧完 1.6 亿多美元，员工开始跳槽</h4><p></p><p></p><p>本周二，美国领先模拟 AI 处理器公司 <a href=\"https://www.infoq.cn/article/uMkRA2sFBBmtzSLKO0TF\">Mythic</a>\" 工程副总裁 Ty Garibay 在 LinkedIn 发布帖子表示，“我们没有赚到钱，投资者也没有办法了。”Garibay 和其他几名 Mythic 员工在社交网络上表示，他们正在寻找新工作。</p><p></p><p>Garibay 表示，Mythic 开发了一种“独特的新技术”，承诺为边缘人工智能提供极致的性能和收益。然而，这显然不足以成为这家拥有 10 年历史的公司持续获得投资者投资的吸引力。</p><p></p><p>据悉，Mythic 是 2012 年成立的美国领先模拟 AI 处理器公司，拥有突破性的模拟内存计算技术。去年获得 C 轮融资后，Mythic 的总资金达到了 1.652 亿美元。</p><p></p><h4>中芯国际发布2022年第三季度业绩报告：单季度营收19.07亿美元</h4><p></p><p></p><p>11月10日晚，中芯国际发布2022年第三季度财报。财报显示，中芯国际单季度营收为19.07亿美元，同比成长34.7%；毛利为7.422亿美元，同比增长58.6%，毛利率为38.9%。</p><p></p><p>对比今年前两个季度，中芯国际三季度收入增长有放缓迹象，该公司还预期四季度收入将环比下降13%至15%。中芯国际称，结合当前宏观经济的走势和去库存的节奏，还未看到行业有复苏的迹象。由于这一次周期叠加多重复杂的外部因素，调整持续时间可能更长。根据前三季度业绩和四季度指引中值，中芯国际预计2022年全年收入在73亿美元左右，同比增长约34%。</p><p></p><p>中芯国际CEO赵海军在11月11日的财报电话会上表示，公司依据市场长期需求进行中长期的资本开支规划，建设进度有可能根据市场变化、采购周期、成本等因素进行适当调整。“未来5-7年，公司有中芯深圳、中芯京城、中芯东方等总共约34万片12英寸新产线的建设项目。”</p><p></p><h4>vivo 自研芯片 V2 亮相</h4><p></p><p></p><p>11 月 10 日，vivo 正式对外发布自研芯片 V2，这是 vivo 自主研发的最新款专业影像芯片。</p><p></p><p>据介绍，自研芯片 V2 对片上内存单元、Al 计算单元、图像处理单元进行大幅升级。提出 FIT 双芯互联技术，在自研芯片 V2 与天玑 9200 旗舰平台之间建立起全新的高速通信机制，使两颗架构和指令集完全不同的芯片在 1/100 秒内完成双芯互联同步，实现数据和算力的优化协调与高速协同。</p><p></p><p>此前在去年 9 月，vivo 正式发布 V1 芯片，并搭载在 vivo 旗舰手机 X70 系列上。据透露，V1 芯片开发历时 24 个月，投入研发人力超过了 300 人。</p><p></p><h4>周鸿祎称 360 基本不触碰用户数据，所以广告没有同行做得好</h4><p></p><p></p><p>11 月 9 日，360 创始人周鸿祎在 2022 世界互联网大会乌镇峰会上表示：“360 公司广告做得没有同行那么好，主要是因为我们基本不怎么触碰用户的数据。”</p><p></p><p>周鸿祎称，360 没有用户账号体系，每天在电脑上更多采集的是黑客的不良行为，比如哪个软件在后台偷偷运行等等。他强调，也是因此才使得 360 能利用网络安全大数据，发现众多国家级网络攻击。据周鸿祎此前称，360 发现的国家级黑客组织数量占国内整个行业的大约 98%，在全球范围内领先。</p><p></p><h4>数学家张益唐北大讲座：本质上已证明“零点猜想”</h4><p></p><p></p><p>11 月 8 日上午 9 点，数学家张益唐在北京大学作“关于朗道 - 西格尔零点猜想”学术报告。张益唐表示，在本质上，他已经证明了朗道 - 西格尔<a href=\"https://www.infoq.cn/article/3HlT22mMTe2ETLpLc9oQ\">零点猜想</a>\"。只是像他此前关于孪生素数猜想的研究结果一样，其结果可以被改进。最新研究突破将有很多应用，带来很多定理。</p><p></p><p>换句话说，张益唐的最新论文表明，在特定范围内，朗道 - 西格尔零点不存在。在这一情况下，朗道 - 西格尔零点猜想正确或成立。（郎道 - 西格尔零点猜想要回答的核心问题就是：是否存在朗道 - 西格尔零点？）</p><p></p><h4>GitHub 面临集体起诉，索赔 647 亿元</h4><p></p><p></p><p>消息显示，GitHub 和它的母公司微软，以及 OpenAI，正在面临一项集体诉讼。诉讼案中，广大程序员们指控 OpenAI 涉嫌违反开源许可。程序员们认为，OpenAI 和微软使用他们贡献的代码训练专有 AI 工具 GitHub Copilot。</p><p></p><p>据悉，该诉讼已提交到美国加州北区地方法院，要求法院批准 90 亿美元（约 649 亿人民币）的法定损害赔偿金。</p><p></p><p>根据集体诉讼文件：“每当 Copilot 提供非法输出，它就违反第 1202 条三次，即分发没有（1）注明出处，（2）版权通知，（3）许可条款的许可材料。”</p><p></p><p>“因此，如果每个用户在使用 Copilot 的整个过程中（早期用户使用 Copilot 最多长达 15 个月之久）只收到一个违反第 1202 条的输出，那么 GitHub 和 OpenAI 就违反了 DMCA 360 万次。每次违反的最低法定赔偿金为 2500 美元，换算后相当于 90 亿美元。”</p><p></p><h4>英伟达用 SPARK 换掉 C：和 Rust 一样好，编程更安全？</h4><p></p><p></p><p>近日，知名编程语言 Ada 与 SPARK 所属公司 AdaCore 表示，英伟达的产品运行着许多经过正式验证的 SPARK 代码。对于安全较为敏感的应用程序或组件，英伟达安全团队正在用 SPARK 语言取代 C 语言。</p><p></p><p>在将 SPARK 模块与 C 中的等效模块进行了比较后，英伟达首席软件工程师 Cameron Buschardt 表示，SPARK 生成的程序集几乎与 C 代码中的程序集相同，“我根本没有看到任何性能差异。”</p><p></p><h4>被网站算法错误认定为“杀猪盘”，网友侵权之诉被驳回</h4><p></p><p></p><p>据《北京青年报》报道，某征婚交友平台运营者实施算法时认定用户李某为“杀猪盘”，并对其进行风控，导致李某被好友误认为骗子。李某一气之下将平台诉至法院，要求道歉并赔偿2万元。</p><p></p><p>11月10日，北京青年报记者从北京互联网法院获悉，该院审结了首例涉及算法风控系统引发人身权益侵权纠纷的案件。法院判决平台并无主观过错，不构成侵权，驳回了李某的诉讼请求。</p><p></p><p>据了解，李某为某金融公司员工，注册了某征婚交友平台，提交了真实照片作为头像以及实名认证手机号。在李某正常使用平台期间，征婚平台对其账户进行了封号处理，并向其他网友提示称“账号可能存在异常”“不要与之发生金钱来往”等。该情况导致李某多位朋友误认为其是骗子，造成李某名誉受损。</p><p></p><h2>IT 业界热评新闻</h2><p></p><p></p><h4>95后记者1.96亿收购上市公司</h4><p></p><p></p><p>近日，一位曾经担任财经记者的“95后”耗资1.96亿元买下一家上市公司元。据交易文件披露，这位年轻人名叫褚一凡，生于1995年，研究生学历。2014年7月-2019年11月期间，先后任鸿胜网络执行总经理、蓝鲸财经记者、雅博科技董事长助理。</p><p></p><p>她作为实控人的公司收购的公司名叫“国立科技”，是一家高分子材料（塑料及橡胶品）公司，集研发、销售、生产为一身，主要客户为休闲鞋材、智能家居、运动器材等公司。2022年前三季度，该公司营收10.02亿，净利润1.46亿，市值约20.5亿。</p><p></p><h4>北京建议正常经营企业涨薪7.09%</h4><p></p><p></p><p>近日，北京市人力资源和社会保障局发布北京市2022年企业工资指导线，规定2022年全市企业工资指导线的基准线为7.09%，即生产经营正常、经济效益增长的企业建议涨薪7.09%。</p><p></p><p>根据2021年北京市宏观经济状况和2022年经济发展预测，结合国家工资收入分配政策，2022年全市企业工资指导线的基准线为7.09%，下线为3.12%。效益情况与往年持平或略有下降的企业，可结合自身实际安排本企业的工资增长3.12%。</p><p></p><h4>宇视科技总裁：管理层不主动降薪就是格局问题</h4><p></p><p></p><p>11 月 9 日消息，脉脉网友及职场博主王落北爆料称，宇视科技全体管理层主动向总裁发邮件申请降薪 10%，对此总裁回复称：“这是有责任感的体现，管理团队若不主动降薪就是格局问题。”</p><p></p><p>公开资料显示，宇视科技定位为全球 AIoT 产品、解决方案与全栈式能力提供商。根据财报，宇视科技 2021 年实现总营收 60.73 亿元，净利润 5.72 亿元。</p><p></p><p>网友热评：利润高的时候老板格局多大？</p><p></p><h4>高中老师花半小时将“羊了个羊”改成“历了个史”后爆红</h4><p></p><p></p><p>近日，浙江湖州一 90 后高中历史老师徐娇娇将“羊了个羊”游戏改编成“历了个史”，这一创新教学方法让历史课变得趣味无穷，深受学生们喜爱。很快，“历了个史”小游戏登上热搜，徐老师也瞬间爆红。</p><p></p><p>在接受封面新闻记者采访时，徐老师表示自己此前玩“羊了个羊”只过了第一关，但她想到可以把这个灵感运用到教学中，于是，她结合历史的教学内容，对“羊了个羊”游戏进行了一些图片更改，只用了半个小时就完成了。据其介绍，整个游戏更改有基础模板，网上也有一些教程，不需要编程即可修改。</p><p></p><p>网友热评：这才是真正的寓教于乐啊。</p>",
    "publish_time": "2022-11-13 15:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]