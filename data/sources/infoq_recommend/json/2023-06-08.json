[
  {
    "title": "架构师（2023 年 6 月）",
    "url": "https://www.infoq.cn/article/YfSrmISxZaJhgjIvSMJ4",
    "summary": "<h2>卷首语</h2>\n<p><strong>作者｜褚杏娟</strong></p>\n<p>“用 Rust 重写”正流行。</p>\n<p>一直以来，在 Windows 内核中的主要语言是 C，内核之外的大部分代码是 C++。但在最新的 Windows 11 Insider Preview 版本中，微软纳入了内存安全编程语言 Rust，这无疑又添了一把火。还有个人开发者用 Rust 写了类似 Kubernetes 的应用。</p>\n<p>但同时也有开发者指出，单纯用 Rust 重写大型 C/C++ 系统组件只会引入额外的攻击面：新组件和现有代码间的外部函数接口（FFI）。在一些情况下，“安全”Rust 函数其实比原本的“不安全”C 函数更糟糕。</p>\n<p>Rust 还是 C/C++，似乎是个问题：Rust 使用相似的语法并且可用于许多与 C++ 相同的任务，但 C++ 拥有更大的社区、更广泛的用例、更多的框架，并且得到了很多公司的认可。而由于其静态类型特性，Rust 在安全性、编写速度和防止不正确/不安全的代码方面更好。</p>\n<p>近日，在黑客新闻上有关于选择<a href=\"https://news.ycombinator.com/item?id=36206908\">Rust 还是 C 或 C++</a>的讨论。</p>\n<p>“我会选择 Rust，因为它相比C更符合开发者的‘人体工程学’。即使是像标准 linter 和包管理器 (Cargo) 这样的小东西，在编写惯用代码方面也大有帮助。”有开发者表示。</p>\n<p>“C是永远的选择。它是社区希望尽早制定规范的唯一语言，这使 C 掌握在程序员手中，而不是编译器创建者手中。”也有开发者说道。</p>\n<p>还有“端水”的开发者说道，“把 C 学得足够好来解决 C++ 和 Rust 试图解决的痛点，C 简单但并不容易；再学习足够多的 Rust 以提高工作效率；然后学习足够的 C++ 以便与现有的大量 C++ 代码进行交互。”</p>\n<p>作为一名开发者，你更支持哪种语言呢？</p>\n<h4></h4>\n<p><strong>目录</strong></p>\n<p><strong>热点 | Hot</strong></p>\n<p>纪念陈皓（左耳朵耗子）</p>\n<p>微软 Bing Chat 全面开放，所有人可用！官宣多项重大升级，日活用户超过 1 亿</p>\n<p>比 Python 快 35000 倍！LLVM&amp;Swift 之父宣布全新编程语言 Mojo：编程被颠覆了</p>\n<p>从微服务转为单体架构、成本降低 90%，亚马逊内部案例引发轰动！</p>\n<p>“TypeScript 不值得！”前端框架 Svelte 作者宣布重构代码，反向迁移到 JavaScript 引争议</p>\n<p><strong>访谈文章 | Interview</strong></p>\n<p>一个价值 70 亿美元的教训！如何避免平台工程变成“大灾难”？</p>\n<p>云原生网关当道，三大主流厂商如何“竞技”？</p>\n<p><strong>案例研究 | Case Study</strong></p>\n<p>喜马拉雅 KV 存储演进之路</p>\n<p>通用电气在平台工程上浪费70亿美元的教训</p>\n<p>天眼查基于 Apache Doris 构建统一实时数仓实</p>\n<p>平安开放银行模式探索实践：从物联网金融到开放联盟</p>\n<p><strong>推荐文章 | Article</strong></p>\n<p>探索 OpenAI 平台架构</p>\n<p>花 8 年转型微服务却得不到回报，问题出在哪儿？</p>\n<p>云原生时代，如何建设稳定性可观测体系？</p>\n<p>不谈技术了，聊聊车企研发效能和文化冲突问题怎么解</p>\n<p><strong>特别专题｜eBPF 探索与应用：如何掀起平台革命</strong></p>\n<p>从石器时代到成为“神”，一文讲透 eBPF 技术发展演进史</p>\n<p>颠覆传统、应用大爆发，eBPF 何以改变 Linux？</p>\n<p>无声的平台革命：eBPF 是如何从根本上改造云原生平台的</p>\n<p>网易伏羲私有云基于 eBPF 的云原生网络可观测性探索与实践</p>\n<p><strong>特别专栏 | Video</strong></p>\n<p>本月，这些视频值得一看！</p>",
    "publish_time": "2023-06-08 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Istio的未来：无Sidecar和带有Ambient Mesh的Sidecar",
    "url": "https://www.infoq.cn/article/hh12UJcPhkRmKoQLKyK7",
    "summary": "<p><a href=\"https://istio.io/latest/blog/2022/introducing-ambient-mesh/\">Istio的Ambient Mesh（环境网格）</a>\"为Istio服务网格引入了一个新的无Sidecar（Sidecar-Less）数据平面选项，其目的是简化应用程序的启动，增加增量采用，并降低Istio网格用户的基础设施成本。</p><p></p><p>Ambient Mesh能同时支持Sidecar数据平面架构和无Sidecar数据平面两种架构，因此我们可以根据应用程序的需求来选择其中一种或两者。在Istio 1.16中，Sidecar得到了增强，以支持<a href=\"https://istio.io/latest/blog/2022/introducing-ambient-mesh/#building-an-ambient-mesh\">HBONE</a>\"&nbsp;（HTTP-Based Overlay Network Environment），因此它们可以通过<a href=\"https://www.solo.io/blog/understanding-istio-ambient-ztunnel-and-secure-overlay/\">ztunnel</a>\"（零信任隧道，提供安全覆盖层）或/和waypoint代理（提供第7层处理层）与无Sidecar应用程序进行互操作，这些应用程序也需要能理解HBONE。</p><p></p><h2>Ambient无Sidecar的优势</h2><p></p><p></p><p>Ambient的最大优势是它不需要对应用程序进行任何更改，这就是它被称为ambient的原因。Ambient无Sidecar数据平面被设计成对应用程序是透明的，例如，不需要为应用程序改变CI/CD管道，也不需要在数据平面出现新漏洞（基于Envoy的waypoint代理或基于Rust的ztunnel，更多详细信息请参阅下文）时重启应用程序。除了不需要更改应用程序外，无Sidecar数据平面还消除了Istio的许多Sidecar<a href=\"https://istio.io/latest/docs/ops/deployment/requirements/\">应用程序要求</a>\"，如服务器发送优先协议、无法支持Kubernetes Jobs或保留的sidecar端口列表，从而扩大了对应用程序的支持。</p><p></p><p>Ambient中的两层（安全覆盖层和L7处理层）数据平面方式允许我们更好地逐步采用Ambient无Sidecar数据平面，而不是全有或全无sidecar注入。我们可以从安全覆盖层开始，同时享受该层带来的所有好处，比如具有加密身份的mTLS、简单的第4层授权策略和遥测。在没有任何L7处理的情况下，安全覆盖层显著地减少了CVE和其他补丁的攻击面和更新数据平面的频率。两层架构使我们能够根据所需付费，并独立于工作负载扩展服务网格数据平面，从而降低了基础设施的成本。</p><p></p><h2>Istio Ambient的开发有什么新动向?</h2><p></p><p></p><p>Istio团队正在努力将Ambient Mesh作为下一个Istio版本的一部分，我们已经建立了ztunnel和ambient<a href=\"https://github.com/orgs/istio/projects\">项目委员会</a>\"来跟踪我们的进展，并衷心欢迎来自社区的贡献。所有Ambient Mesh贡献者会在<a href=\"https://github.com/istio/community/blob/master/WORKING-GROUPS.md#working-group-meetings\">美国东部时间每周三的下午1点开会</a>\"，讨论新的设计文档或贡献者的任何担忧。以下是我想强调的两大变化：</p><p></p><h3>基于Rust的ztunnel</h3><p></p><p></p><p>当Istio的Ambient服务网格于2022年9月7日发布时，ztunnel组件是使用Envoy代理实现的，因为我们想让每个人都能尽早安装并探索Istio的Ambient Mesh。在最初发布后不久，社区评估了ztunnel是应该继续使用Envoy还是应该用Rust从头开始重写，John Howard开始了<a href=\"https://github.com/istio/ztunnel/\">基于Rust的ztunnel项目</a>\"。关于如何简化基于Envoy的ztunnel，并消除对内部监听器的需求，我们进行了大量的思考，但最终，社区决定加入基于Rust的ztunel项目，原因如下：</p><p>Rust天生适合做高性能、低利用率的网络代理。Ztunnel提供的安全覆盖层，其功能和攻击面都大大减少了，因此与全特性代理相比，它更容易编写。Rust有丰富的库可供使用，包括<a href=\"https://tokio.rs/\">Tokio异步运行时</a>\"。Rust有一个明确的CVE流程可供我们利用。最后但同样重要的是，与Envoy不同，Rust通过其Tokio库原生支持工作窃取（work stealing）。这对于ztunnel有效地重用连接非常重要。</p><p></p><p>想要了解更多关于基于Rust的ztunnel与基于Envoy的ztunel的决定，请参阅<a href=\"https://istio.io/latest/blog/2023/rust-based-ztunnel/\">这篇博客文章</a>\"，其中详细解释的我们想法。</p><p></p><h3>只包含目的服务的waypoint代理</h3><p></p><p></p><p>当Istio的Ambient服务网格最初发布时，waypoint代理配置比ztunnel配置更容易理解，因为它只处理共享同一服务帐户的工作负载，例如每个服务帐户一个waypoint代理。然而，waypoint代理配置仍然非常复杂，因为源waypoint代理知道Kubernetes集群中的所有其他服务，而不管这些服务是否是实际的目的服务。</p><p></p><p><img src=\"https://imgopt.infoq.com/articles/istio-ambient-mesh/en/resources/2Image-1-1678453126032.jpeg\" /></p><p></p><p>图1：源waypoint代理能感知所有的其他服务（此处只展示了无Sidecar服务，但它们也可能是网格外服务的Sidecar）</p><p></p><p>Istio v1.1中引入的<a href=\"https://istio.io/latest/docs/reference/config/networking/sidecar/\">Sidecar</a>\"资源通常用于Istio环境中，以减少Envoy Sidecar的配置，从而提高Envoy Sidecar的性能和资源利用率。当我们开始评估是否需要为waypoint代理（也是基于Envoy的）支持Sidecar资源时，我们意识到我们可以通过提供一个仅支持目的服务的waypoint代理即可大幅削减waypoint代理的配置。</p><p></p><p>通过只关注目的服务的waypoint代理，waypoint代理配置仅需包含非常有限的动态集群、端点和路由相关的详细信息即可，其中waypoint代理需要连接到这些动态集群、端点和路由，而无需将所有潜在连接到其运行的Kubernetes集群中的任何服务的详细信息都包含内。这一更改有效地消除了对waypoint代理支持Sidecar资源的需求，也避免了用户手动配置Sidecar资源。</p><p></p><p><img src=\"https://imgopt.infoq.com/articles/istio-ambient-mesh/en/resources/3image2-1678453126032.jpeg\" /></p><p></p><p>图 2：目的waypoint知道目的服务，但不知道其他服务</p><p></p><p>例如，在我的Kubernetes集群中，我将sleep、helloworld和httpbin应用程序以无Sidecar的形式部署在了default命名空间中。我还将httpbin应用程序与Sidecar一起部署在foo命名空间中。</p><p></p><p><img src=\"https://imgopt.infoq.com/articles/istio-ambient-mesh/en/resources/4image3-1678453126032.jpeg\" /></p><p></p><p>图3：在没有Sidecar的情况下部署的helloworld、httpbin和sleep应用程序，以及foo命名空间中使用Sidecar部署的httpbin</p><p></p><p>以下是foo命名空间中httpbin的sidecar的路由配置，这与源waypoint代理非常相似，因为两者都知道所有其他服务的路由：</p><p></p><p><img src=\"https://imgopt.infoq.com/articles/istio-ambient-mesh/en/resources/4image4-1678453126032.jpeg\" /></p><p></p><p>图4：httpbin的sidecar路由配置</p><p></p><p>相比之下，以下是httpbin大大减少了waypoint代理的路由配置。请注意，在foo命名空间中没有与helloworld或sleep应用程序或httpbin应用程序相关的路由。虽然这里使用动态路由作为示例，但与Sidecar相比，动态集群和端点也减少了仅限于目的的waypoint代理。</p><p></p><p><img src=\"https://imgopt.infoq.com/articles/istio-ambient-mesh/en/resources/1Iamge5-1678453126032.jpeg\" /></p><p></p><p>图5：httpbin的waypoint代理路由配置</p><p></p><p>只包含目的服务的waypoint代理意味着不会包含任何的源waypoint代理。如果没有源waypoint代理，如果我们的目的服务没有waypoint代理（例如AWS Lambda服务），并且我们想在连接到目的服务时添加弹性，会发生什么呢？</p><p></p><p>在这种情况下，我们需要一个出口网关或专用代理来处理出口流量。这个代理的优点在于，它将包含一个精简的列表，其中列出了我们需要连接的外部服务，而不会出现前面提到的臃肿配置问题，也不需要使用Sidecar资源或目的服务中的 networking.istio.io/exportTo 注解来修剪不必要的配置。</p><p></p><h2>Ambient无Sidecar模式这么好，那Sidecar呢？</h2><p></p><p></p><p>Sidecar不会很快消失，我们可以继续使用Sidecar，只要我们觉得舒服，或者仅仅是因为我们已经从安全团队那里获得了所有的必要批准。即使Ambient无Sidecar已经成熟了，我预计Sidecar仍将继续在以下用例中发挥重要作用：</p><p></p><p></p><h3>1. 源服务需要特定的客户端配置</h3><p></p><p></p><p>对于只包含目的服务的waypoint，waypoint就像是目的服务的网关，其中waypoint代理实现流量管理和政策执行功能。这也意味着所有源服务共享相同的实施，缺乏配置特定于客户端配置覆盖的能力。在Istio的VirtualService资源中，我们可以使用sourceLabels配置特定于给定源的故障注入或重试或超时的覆盖；例如，<a href=\"https://istio.io/latest/docs/reference/config/networking/virtual-service/#HTTPFaultInjection-Delay\">仅为带有标签“env:prod”的客户端pod添加HTTP故障注入</a>\"。</p><p></p><p>如果我们的特定源服务想要对重试/超时/故障注入/负载均衡器配置执行客户端覆盖，该怎么办呢？我们可以使用Sidecar，它能为每个客户端提供细粒度的配置覆盖，这样我们的客户端就不需要使用目的服务提供的默认值了。</p><p></p><p><img src=\"https://imgopt.infoq.com/articles/istio-ambient-mesh/en/resources/1Image6-1678453126032.jpeg\" /></p><p></p><p>图6：Source1使用Sidecar进行配置覆盖</p><p></p><p></p><h3>2. 目的服务需要特定于目的工作负载的策略</h3><p></p><p></p><p>waypoint代理是按服务帐户或名称空间来设计的；对于共享同一服务帐户的服务来说，如果其需要比服务帐户更细粒度的配置，该怎么办呢？例如，对于共享同一个服务帐户的Destination1服务和Destination2服务来说，Destination1服务需要特定的Telemetry或WasmPlugin或RequestAuthentication或EnvoyFilter配置，而Destination2服务不需要。当我们需要比每个服务帐户更细粒度的特定于目的服务的配置时，我们可以继续使用Sidecar。或者，我们可以使用自己的服务帐户为Destination1创建一个专用的waypoint代理，而不是使用Sidecar代理运行。</p><p></p><p><img src=\"https://imgopt.infoq.com/articles/istio-ambient-mesh/en/resources/3image7-1678453126032.jpeg\" /></p><p></p><p>图7：使用Sidecar在Destination 1服务上执行特定于目的服务的策略</p><p></p><p></p><h3>3.Sidecar和无Sidecar可以共存和互操作</h3><p></p><p></p><p>Sidecar和无Sidecar的起始边界是在命名空间级别，在命名空间级别上，我们可以通过istio.io/dataplane mode=ambient命名空间标签将一个或多个特定的命名空间定义为sidecar-less。当sidecar注入标签与命名空间上的ambient sidecar-less标签共存时，sidecar注入标签总是获胜。这种设计确保了我们可以根据特定的业务需求轻松地从Sidecar迁移到无Sidecar，或者从是无Sidecal迁移到Sidecar。</p><p></p><h2>Istio Ambient Mesh的未来</h2><p></p><p></p><p>Istio社区正在为Ambient Mesh做很多令人兴奋的事情。Ambient Mesh已经从实验分支中分离出来，<a href=\"https://istio.io/latest/blog/2023/ambient-merged-istio-main/\">并合并到了上游的主干上</a>\"，这样它就可以很容易地与即将发布的Istio 1.18或更新版本一起安装。我们正在继续发展Ambient Mesh，以提高其性能、可扩展性和可调试性，正如上述基于Rust的ztunnel和仅包含目的服务的waypoint代理的更新所显示的那样。随着社区致力于使Ambient Mesh生产成为Istio的默认产品，我们邀请你共同参与这一旅程，请在Istio&nbsp;<a href=\"https://istio.slack.com/\">Slack</a>\"或<a href=\"https://github.com/istio/istio\">GitHub</a>\"的ambient频道中提供反馈或贡献，以帮助我们共同塑造Ambient Mesh。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/istio-ambient-mesh/\">https://www.infoq.com/articles/istio-ambient-mesh/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/iyuaBJ1GmJ3xwk8uJQLf\">国内首例社区双栈Istio方案落地经验，实现代码已开源</a>\"</p><p><a href=\"https://www.infoq.cn/article/qMrc8W6ZtODZyb7214wv\">在 Istio 中使用 Kata 容器注入工作负载</a>\"</p><p><a href=\"https://www.infoq.cn/article/stCMjmTuODmzZmGzaNUr\">再见 Sidecar：eBPF 能抢过 Istio 服务网格的风头吗？</a>\"</p>",
    "publish_time": "2023-06-08 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "InfoQ 极客传媒迎来 16 周年生日，创新创业“成长计划”重磅发布",
    "url": "https://www.infoq.cn/article/DwEzKgqx258mdr46jFbI",
    "summary": "<p>2007-2023，InfoQ&nbsp;陪伴中国开发者见证了科技行业高速发展的&nbsp;16&nbsp;年，而在&nbsp;6&nbsp;月&nbsp;8&nbsp;日，InfoQ&nbsp;也迎来了自己&nbsp;16&nbsp;岁的生日。</p><p></p><p>16&nbsp;年来，InfoQ&nbsp;荣幸地与数百万开发者，共同见证了中国&nbsp;IT&nbsp;行业的多重变革，为行业内许多工程师、架构师、CTO、CEO&nbsp;和技术爱好者提供了以技术实践分享和创新技术趋势为核心的精彩内容。InfoQ&nbsp;致力于不断加强内容报道的速度、质量、深度，我们笃信开发者不仅需要产业资讯，也需要经过筛选的、有质量保证的技术新闻，他们由理解技术、热爱技术的专家生产，并最终服务于整个生态的发展和进步。</p><p></p><p>16&nbsp;年来，InfoQ&nbsp;初心不变，并正在扩大内容服务的阵地，结合行业发展趋势，调整内容重心。今天的&nbsp;InfoQ&nbsp;不仅是创新技术的报道阵地，也是数字化转型、数字人才培养的报道阵地，是将无数开发者与数字经济发展大势连接在一起的媒体社区。我们同时组建了&nbsp;InfoQ&nbsp;研究中心，秉承客观、深度的内容原则，追求研究扎实、观点鲜明、生态互动的目标，聚焦创新技术与科技行业，围绕数字经济观察、数字人才发展进行研究。</p><p></p><p>在&nbsp;6&nbsp;月&nbsp;8&nbsp;日活动当天，InfoQ&nbsp;将联合二十余家生态合作伙伴，共同面向广大开发者，发起精彩直播活动。极客邦科技创始人&nbsp;&amp;&nbsp;CEO&nbsp;霍太稳，极客邦科技事业部合伙人&nbsp;&amp;&nbsp;InfoQ&nbsp;极客传媒总经理汪丹，中国信通院泰尔终端实验室数字生态发展部主任王景尧都将出现在直播间，送出祝福，并展望国内技术社区发展的未来。</p><p></p><p>网易数帆云原生技术专家、架构师裴斐，梅赛德斯-奔驰集团企业架构负责人白克宇，NIO自动驾驶系统&nbsp;云端工程平台研发负责人顾仲贤，云器科技联合创始人、CTO&nbsp;关涛将悉数出现在直播现场，分享参与技术社区分享的经验和故事。</p><p></p><p>裴斐是云原生网关的资深专家，也是国内最早在企业级环境采用&nbsp;Envoy&nbsp;方案的专家之一，为&nbsp;InfoQ&nbsp;社区的读者贡献了大量的相关实践内容；白克宇将车企数字化工作的主体思路和架构理念带给了&nbsp;InfoQ&nbsp;线上、线下的读者、用户，启发了许多优秀的架构师；顾仲贤五年来坚持更新《数据库内核杂谈》，为无数读者带来了数据库方面的技术启发；关涛在大数据领域建树颇丰，其年度大数据领域技术盘点，帮助读者对大数据领域的发展有了更清晰的把握。</p><p></p><p>极客邦科技研发总监韩磊，钉钉文档套件研发负责人、阿里巴巴高级技术专家雷德斌，也将汇聚于直播间，发起一场针对&nbsp;AIGC&nbsp;在企业级环境做二次开发的实践经验分享。</p><p></p><p>本场直播预约二维码：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a8670edba8ffe09693a178438c24b736.png\" /></p><p></p><p>值得一提的是，InfoQ&nbsp;创新创业“成长计划”也将在本场直播中发布。InfoQ&nbsp;将面向行走在创业旅途中的创新企业，提供媒体传播、创新创业演示区、链接&nbsp;500&nbsp;位&nbsp;CXO&nbsp;群体等多重助力。该计划报名仅限&nbsp;1&nbsp;周，欢迎大家积极参与，让创新技术落地千行百业。</p><p></p><p>创新创业“成长计划”面向对象</p><p></p><p>Pre-A&nbsp;轮的企业大模型研发、大模型应用、大模型工具的企业</p><p></p><p>线上权益&nbsp;&nbsp;</p><p></p><p>InfoQ&nbsp;资深编辑专访一次，收录至&nbsp;InfoQ&nbsp;技术创新创业专栏（暂定名）精准触达&nbsp;500&nbsp;位&nbsp;CXO&nbsp;的电子邮件联合发布一次</p><p></p><p>线下权益</p><p></p><p>极客邦技术会议创新创业演示区一次，审核制北京&nbsp;|&nbsp;QCon&nbsp;全球软件开发大会深圳&nbsp;|&nbsp;ArchSummit&nbsp;全球架构师峰会上海&nbsp;|&nbsp;GTLC&nbsp;全球技术领导力峰会、金融科技峰会新加坡&nbsp;|&nbsp;GTLC&nbsp;全球技术领导力峰会香港&nbsp;|&nbsp;科技科技峰会</p><p></p><p>创新创业“成长计划”报名二维码</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5a/5ae99e3708cf96368e1e4c35f08bb248.png\" /></p><p></p><p>在未来，我们将进一步深入中国广袤的中小企业市场、深入数字化转型市场，探寻能帮助企业、开发者共赢的创新技术、研发模式和数字化理念，继续打造良性的开发者生态。同时也感谢&nbsp;InfoQ&nbsp;众多生态合作伙伴在社区传播、共建层面的大力支持：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b9/b92dacb3f13f643a535a4496ce1e01ab.jpeg\" /></p><p></p>",
    "publish_time": "2023-06-08 10:27:38",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "让文物“活”起来：揭秘火山引擎视频云三维重建技术",
    "url": "https://www.infoq.cn/article/z1CW0cFhLxLi2KYk258t",
    "summary": "<p>中国历史悠久，文化底蕴深厚，文物数目众多，文物作为前人智慧的结晶，其文献价值不言而喻。古籍是记录中华文明的重要载体，也是流传至今的宝贵文化遗产，文物保护也是一项长期重要的基础工作。全国 2800 多家图书馆收藏有超过 5000 万册的古籍，其中 1/3 存在不同程度的破损。按现有的文物修复人员数量，需要数百年的时间才能把馆藏文物全部修复好。</p><p></p><p>《古籍寻游记》是字节跳动联合中国第一历史档案馆、敦煌研究院、甘肃简牍博物馆、国家图书馆（国家典籍博物馆），共同打造的古籍活化项目，还原古文献四大发现 — 殷墟甲骨、居延汉简、敦煌遗书、明清档案，让古籍以数字化的形式“活”起来。</p><p></p><p>该项目以 VR 互动纪录片为核心，依托火山引擎多媒体实验室最新的三维重建技术，复刻线下文物到 PICO 虚拟场景中，并应用自研光场视频技术，采集并惟妙惟肖的还原动态人物的光场信息，在 VR 场景中提供高自由度的观看和交互体验。在这些纪录片中，观众可以通过 PICO、抖音裸眼 VR 等方式，足不出户穿越时空，亲自参与历史事件，零距离接触与欣赏古籍。</p><p></p><p>本文重点介绍<a href=\"https://www.infoq.cn/article/CGeRpGMFTWRHRvsiWtwf\">火山引擎</a>\"多媒体实验室的三维重建技术以及光场视频技术的原理、先进性及应用领域，帮助大家能更好的了解和认识三维重建技术，助力相关技术在实际产品和应用中落地。</p><p></p><h2>一、技术挑战与难点</h2><p></p><p></p><p>文物的数字化需要对文物做三维重建和数字复原，同时也对三维重建技术提出了很大挑战：</p><p></p><p>文物采集需要使用对于文物无侵害的设备，传统的高精度激光等设备就无法使用。文物通常保护在陈列柜内，难以拿出，也对重建的采集提出了更高的要求；文物往往形状复杂，且具有一定的材质，尤其是古籍类文物，往往很薄，如何重建这种很薄的文物，是物品重建的一个难点。如何高真实感复现文物并表现其真实感纹理，包括漫反射、镜面反射、半透明，等复杂材质的恢复与微细表面的重建，也对技术提出了挑战；对于石窟等文物，需要采集并重建一定的空间，如何采用纯视觉的方式，在石窟内进行漫游采集，并进行完整重建，是项目的一个难点；为了更好地实现博物馆的文化推广，实现历史情景的在线还原，需要对动态人物和场景进行高真实度重建，然而，当前动态人物和场景的高真实度重建缺乏完整的有效解决方案。</p><p></p><p></p><h2>二、三维重建技术介绍</h2><p></p><p></p><p>三维重建是计算机辅助几何设计(CAGD)、计算机图形学(CG)、计算机动画、计算机视觉、医学图像处理、科学计算和虚拟现实、数字媒体创作等领域的共性科学问题和核心技术。三维重建技术，一般包括数据采集、预处理、点云拼接、特征分析、网格及纹理生成等步骤。传统的三维重建采用基于视觉或者基于多模态（深度数据，e.g.，激光）重建图像三维信息的过程，能够对静态物体和场景进行建模，但缺乏有效的对于动态物体和场景建模的整体解决方案。火山引擎多媒体实验室具备自研的物品重建技术、场景重建技术，及光场视频技术，能够对静态物体构建高保真的形态，并恢复其复杂材质；能够对大场景，包括城市，园区，房屋空间等进行有效的建模，是数字孪生的重要基础；且能够对动态物体和动态场景，采用先进光场视频技术进行重建和复现，实现点播和直播，具备整套的技术解决方案。</p><p></p><h4>2.1  物品重建技术：既要保护文物又要精确扫描</h4><p></p><p></p><p>在“古籍寻游记”项目中，<a href=\"https://www.infoq.cn/article/edlcBLOis2uvazgQjxea\">火山引擎</a>\"多媒体实验室做了四十多样文物的数字复原。在做文物数字复原的过程中，遇到的第一个难点就是，文物是需要重点保护的，对于采集设备有一定的限制，比如，常用的高精度激光设备是不能够用来扫描文物的，这就驱使火山引擎多媒体实验室团队采用基于视觉的方式对文物进行三维重建。然而传统基于视觉的重建方法无法处理弱纹理物体，而且对于形状比较复杂的物品也难以重建（例如狭长的简牍、扁平的甲骨）。为此，采用符号距离场（Signed Distance Fields，简称SDF）的技术方案来表示三维物体，结合深度学习的方法克服了以上重建难点。SDF 表示了空间中每个点到物体的有向距离，是一种隐式表示，二维 SDF 的示意图如下。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/9c/37/9c9f70356251041c41a06f73c47bc137.png\" /></p><p>图：SDF示意图</p><p></p><p>如何监督神经网络使其准确地拟合该 SDF 是需要研究的问题。先用运动恢复结构（Structure from Motion，简称SfM）算法，精确计算拍摄图像的相机姿态。有了相机姿态，利用可微渲染的方法将 SDF 所表示的空间信息渲染到图像上，把渲染得到的图像和该视角下采集的图像做比较，不断优化神经网络，使 SDF 在各个采集视角下的渲染结果尽可能与实际采集的图像一致。为了进一步提高重建精细度，在优化 SDF 的时候加入稀疏重建得到的三维点做约束，能更好的还原物体的细节特征。</p><p></p><p>为了达到完整重建的目的， 火山引擎多媒体实验室还将分割算法和重建算法相结合，能够有效的重建出物体的底部区域。由于物体在扫描过程中是要固定在某个位置，物体的底面采集不到图片的。物体的完整重建就是要解决物体底部重建的问题，通常的做法是悬线法或多段重建加后处理拼接。悬线法对文物来说不够安全，拼接后处理流程较长，不能自动化。为此，火山引擎多媒体实验室在重建算法中加入了自动化图像分割，能够将正反两次拍摄的数据统一起来一起重建，直接得到完整的重建结果，完整重建的结果对比如下图所示。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/1b/52/1b7c233c7978d8f910247f989b00ca52.png\" /></p><p>图：未使用完整重建技术建模结果</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/6b/b8/6bc0c11b3d8a9cf1cf553509a60cdbb8.png\" /></p><p>图：使用完整重建技术建模结果</p><p></p><p>高光是物体重建的一大挑战，一方面高光影响特征点匹配，导致恢复的相机位姿不准确，再一个高光也会破坏不同视角间观测结果的一致性，对重建造成干扰。为此， 火山引擎多媒体实验室总结出一套利用偏振光消除高光的方法，能有效去除大量高光，高光消除的结果对比如下图所示。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/1d/8e/1d70deb089605a73f27c459b836f908e.png\" /></p><p>图：消除高光前</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/a7/d3/a73cca383b1603d53673db7979817cd3.png\" /></p><p>图：消除高光后</p><p></p><p>火山引擎多媒体实验室的方法还可以模拟不同物体的反射/折射性质，实现对特殊材质物体的建模，文物重建的结果展示如下图所示。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/a1/42/a18a9b06e1360c8433a94ffd0beef042.jpg\" /></p><p>图：文物原图</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/de/33/de99ebc5366378380fb1da51e5e0a233.png\" /></p><p>图：文物重建</p><p></p><p></p><p>甲骨文重建结果四大博物馆的文物，有一些是纸质、竹简类的珍贵文物，这些文物也难以从陈列柜中取出并采集。针对这种情况，火山引擎多媒体实验室自研了加入光学偏振片的采集设备，可以消除玻璃陈列柜带来的杂光、高光和反射问题，使得我们在有一层玻璃保护壳的状态下，仍对文物进行高保真的扫描和重建。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/9e/2e/9e10e4127bce060a6b08cc59aa1abd2e.png\" /></p><p>图：玻璃陈列柜中文物</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/79/71/7954218a3e149cec0b4638f470739a71.png\" /></p><p>图：文物重建结果</p><p></p><p>此外，火山引擎多媒体实验室的物品重建技术还包含精确位姿估计、真实感纹理(漫反射、镜面反射、半透明)等复杂材质的恢复与微细表面的重建，也均在“古籍寻游记”项目中得以运用，将宝贵的文物实现高真实度的 1:1 还原，并转换为数字化资源，让观众“沉浸式”逛馆，让藏品更加深入人心。火山引擎多媒体实验室的物体重建技术具备很强的普适性，不仅适用于文物，一般物体也同样适用，而且对一些传统重建难以处理的物体，比如，刀刃等非常薄的物体等，也能有不错的重建结果。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/16/f9/161f6f3a3d4ecbaa779a105bc35ca5f9.png\" /></p><p></p><h4>2.2  自建场景重建算法：更高效率、更高精度</h4><p></p><p></p><p>场景重建是计算机视觉和摄影测量中的重要研究课题，也在智慧城市、虚拟现实、数字导航与数字遗产保护等方面有着重要的应用。通过视觉进行三维重建具有采集效率高、采集成本低、精度上限高、适应场景广等优点，同时可以避免其他扫描设备对场景带来不必要的损害，但在算法层面面临诸多挑战。对此，火山引擎多媒体实验室结合 AI 技术与多视角几何基本原理，搭建了一套先进的鲁棒、精确完整视觉重建算法框架。重建过程包括三个关键步骤：图像处理、点云优化和网格重建。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/b6/6b/b61a1acc801e6452ae1525eb76831d6b.png\" /></p><p></p><p>火山引擎多媒体实验室利用先进的人工智能技术，对图像进行去噪、超分、特征提取与匹配等处理，从而克服了诸多传统方法限制。然后利用 SfM 算法以及捆集约束(Bundle Adjustment，简称 BA)从图像中提取稀疏几何结构和相机参数。同时团队开发了支持全景相机、多相机组、RGBD 相机、激光雷达、 GPS/IMU 等多传感器数据输入的位姿估计算法，实现高精度、多模态、自适应的稀疏重建。为了处理大规模数据，团队开发分块重建和地图合并策略，实现分布式集群并行重建，显著提高了重建效率。</p><p></p><p>在完成场景稀疏重建后，通过立体视觉 (Multiple View Stereo，简称MVS)技术将二维图像信息转化为三维点云信息。团队自研基于单目相机、双目相机和多目立体视觉的深度估计算法，通过神经网络进行稠密深度估计，在任意视差、各种纹理环境获得稳定优秀的表现。获得点云信息后，进行点云去噪和补全，并通过点云配准实现场景几何一致性。最后，通过基于 VoxelHash 和图像语义信息的点云融合策略，进一步滤除噪声，生成更加平滑一致的完整场景点云。</p><p></p><p>获得场景点云后，进行 Mesh 重建。<a href=\"https://www.infoq.cn/news/WPmK0BeY0dDJB6wLL0zM\">火山引擎</a>\"多媒体实验室自研多种网格优化算法，实现网格平滑、去噪、简化和补洞，获得更加精细、完整的高质量网格模型。得益于图像处理期间高精度的相机位姿估计以及图像超分等画质优化，结合自研贴图算法，获得更高清、拼缝更少的高质量纹理贴图。同时通过纹理重打包算法优化，实现更高的纹理利用率，降低存储资源浪费，提升纹理有效分辨率。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/c0/62/c09376deed166deef13dfa6ae7b3a962.png\" /></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/57/97/57b8b7df92ffc49f99b722b38b0c9897.png\" /></p><p></p><p></p><p></p><p>火山引擎多媒体实验室的物品重建技术和场景重建技术可以等比例、高精度的复原不同大小、不同形状的文物。上述的技术可以将线下文物转换到线上，在 PICO、抖音里实现文物的虚拟呈现，用户可以把甲骨文把玩在手里，清晰的看到上面的文字，实现传统参观没有的文物观赏体验，同时也可以跨越空间限制，置身并漫游在敦煌石窟里。另外，该项技术可以将线下珍贵文物转换为线上的永久数字资源，实现文物的数字化保护，可以让后世的人们身临其境体验到文物的全貌。</p><p></p><h4>2.3  自研光场视频技术：平衡成本与精确度之间的难题</h4><p></p><p></p><p>为了能够在虚拟敦煌石窟内，身临其境地观看一场盛世舞蹈，感受超越现实的体验，火山引擎多媒体实验室自研的光场视频技术，能够对动态人物和场景进行高真实度重建，达到行业先进水平。</p><p></p><p>动态三维网格数据（Dynamic Mesh），可以表示动态人物和场景，但是如何重建出高质量的动态三维网格，并使得新渲染出的图像能够如照片般逼真是一个难题。 若通过三维场景设计师对场景进行手工重建，将获得较好的重建质量，但将付出较大的人力成本； 若通过 SFM/MVS 等算法自动重建三维场景，则需要重建场景纹理有一定要求，且重建结果可能包含不精确的几何细节和纹理失真。</p><p></p><p>神经辐射场技术，采用神经网络对隐式重建，利用可微渲染模型，从已有视图中学习如何渲染新视角下的图像，从而实现照片级逼真的图像渲染， 即神经辐射场（NeRF）技术。可微渲染模型建模了从三维空间模型及纹理到图像的渲染过程，其可微特性使得在已有视角图像的监督下，通过神经网络对三维空间几何及纹理进行学习。在未知新视角下，可以对学习到的三维空间几何进行重新渲染，从而获得新视角下的图像。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/c0/11/c03bf5b82b4654878a9e6faa73844f11.png\" /></p><p>图：可微渲染模型</p><p></p><p>火山引擎多媒体实验室融合神经辐射场技术与传统的网格建模技术。在具体实践中，首先重建出人物的大致几何轮廓，并改进NeRF技术，融入几何轮廓作为先验加入训练指导，隐式学习三维空间几何，并重新渲染出稠密新视角下的图像。在神经辐射场训练过程中，针对动态人物场景，团队通过一些优化策略以提升该场景下的新视角生成效果，如借助基于哈希编码的层次化表达提升模型训练速度，借助流式训练提升动态场景的帧间一致性等。最后采用视频融合技术， 能够自动学习背景信息，实现前景的重光照，使得前景演员与背景场景能够无缝融合。</p><p></p><p></p><p>光场视频重建结果</p><p></p><p>同时，火山引擎多媒体实验室的光场视频技术，可以实现 NeRF 的编辑，重建并复现复杂的动态大场景。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/2c/4a/2c1829e0a7673d168c40e9e45296734a.gif\" /></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/e2/51/e2927cae2e728bdcd813d10e92c17e51.gif\" /></p><p>图：光场视频后编辑结果</p><p></p><p>火山引擎多媒体实验室的光场视频技术，仅仅需要稀疏的多相机输入，就能够生成稠密的光场数据，这主要是采用基于深度学习的新视角生成技术。光场视频数据相对传统视频数据，具有数据量大的特点，团队采用多视角聚合编码技术压缩光场数据，降低传输和存储的压力。结合大规模直播技术以及 RTC 传输技术，能够实现光场视频的点播和直播。</p><p></p><p></p><p>光场视频高自由度观看结果（PICO内录制）</p><p></p><h2>三、总结与展望</h2><p></p><p></p><p>随着 3D 技术的不断成熟，火山引擎多媒体实验室的 3D 技术不仅在 VR 领域、自动驾驶、视频直播、游戏等场景落地具体的应用，而且将会在在工业、医疗、建筑家居、航空航天等领域持续探索。火山引擎希望能够将物品重建技术、场景重建技术及光场视频技术广泛应用到各行各业的产品和项目中去，服务于企业客户，为用户带来更高清、更互动、更沉浸的创新体验。</p>",
    "publish_time": "2023-06-08 10:34:11",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "极客时间企业版 AI 学习助手上线，引领学习体验全面升级",
    "url": "https://www.infoq.cn/article/LmIIReRSO6MGxe2Nk6jc",
    "summary": "<p>ChatGPT 发布之后，人工智能新一轮浪潮汹涌而来，世界进入技术爆发的新一轮寒武纪时代。在技术发展和数字化的双重驱动下，企业人才培养和技能升级成为可持续创新发展的重中之重。</p><p></p><p>由世界经济论坛发布的《2023 年未来就业报告》显示，42% 的受访企业将在未来五年优先培训员工使用人工智能和大数据的能力。每个员工平均约有 44% 的技能需要升级&nbsp;。企业培训在未来一段时间内将扮演越来越重要的角色，以满足人才培养和升级的需求。</p><p></p><p>随着 AI 的持续发展，人工智能在教育领域的渗透程度越来越深入，带来了学习场景的重塑。AI 的重要进展是提升了 AI 与人的协同和交互学习的效率，这使得教育更加个性化、智能化和高效化，企业与组织机构可利用 AI 提质增效。企业培训平台也亟需进行数智化升级，从个性化的学习体验、智能化的评估与指导、可视化的学习运营、便捷化的知识管理等方面助力企业提升人才培养效率，解决传统培训方式面临的培训内容精准性不高、学员参与感和思考性不足、培训内容与实际业务融入度不够、培训过程及培训效果难以追踪等诸多难点。</p><p></p><p>作为企业级一站式数字技术学习平台，极客时间企业版一直致力于通过好内容、好产品、好服务的“三好体验”，助力企业打造行业领先的数字人才团队，驱动企业的数字化转型和高质量发展。新 AI 时代，极客时间紧跟技术趋势，结合行业洞察，对好产品、好内容和好服务做了全面升级。在近日举办的 DTDS 全球数字人才发展线上峰会上，极客邦科技联合创始人、企业学习服务总经理司巧蕾，发布全新极客时间企业版智能化学习平台，并现场演示首发上线的 AI 学习助手，利用智能化力量切实提高企业学习培训效率，加强人才综合竞争力。</p><p></p><h3>AI&nbsp;学习助手首发上线&nbsp;&nbsp;打造专属全天候私人助教</h3><p></p><p></p><p>首发上线的 AI 学习助手，背后是包含 10000+ 小时的极客时间课程内容，3000+ 位行业专家经验，300+ 个企业岗位技能要求在内的行业垂直模型，同时支持学员端和管理员端，全面提升学习体验和工作效率。</p><p></p><p>个性化推荐学习资源&nbsp;</p><p></p><p>通过推荐多样化的学习资源及学习路径，满足学员个性化的学习需求，缩短培训成本和时间成本。结合学员反馈，分析学员的能力掌握程度，帮助学员更全面地了解自己的能力水平。比如，当发现研发项目总是拖延，希望通过管理手段来提升研发效率时就可以提问 AI 学习助手，在给出建议的同时还可以推荐技术管理领域相关的课程进行针对性学习。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/bb/d8/bbd8aa24aa1bfb1f7780yy2b160869d8.gif\" /></p><p></p><p>学习内容的总结和概括&nbsp;</p><p></p><p>AI 学习助手可以对学习内容进行总结和概括，综合运用多种科学方法，在适当的时间提醒学员进行复习，真正帮助学员将所学知识内化于自身。比如，可以请 AI 学习助手总结《增长黑客的核心公式》这篇文章的主要内容，即可快速提炼知识要点。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/5c/b8/5cf6a76d7dddf873412277edb2f64ab8.gif\" /></p><p></p><p>培训相关问题随时响应</p><p></p><p>HR 在工作中遇到的基础问题，都可以随时召唤 AI 学习助手来解答。&nbsp;企业不再需要花费大量时间和精力对员工进行基础培训，而可以更多地关注于高层次的技能培训和专业发展，提高培训效率和质量。比如，当 HR 想要对企业的产品经理人才进行技能提升时，就可以提问AI学习助手“产品经理需要掌握哪些数字化技能”，回答后还可进一步推荐建议学习路径和课程资源。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/c6/d2/c6168f1cb10ff852fdd500e62affb5d2.gif\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/18/186da8c37c16561f6e1d704970bebb3f.png\" /></p><p>扫描二维码，预约产品体验</p><p></p><h3>多岗位人才能力模型重磅发布，重新定义数字时代人才能力评估标准</h3><p></p><p></p><p>极客时间联合数百位行业专家，采用 PTK（即专业能力、通用能力和领域知识）框架，全新梳理发布数字时代下的产品经理、Java 工程师、技术架构师等多岗位能力模型，重新定义了数字时代下的人才能力评估标准。支持通过平台功能快速配置不同行业、不同企业、不同发展阶段、不同职位等级的数字化专业人才能力模型，并提供对应的能力测评和学习路径，为企业人才培训、招聘等场景提供决策依据。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/27/64/27166bca4d79727073ab030c250af664.png\" /></p><p></p><h3>平台功能持续升级，打造智能高效的学习培训体验</h3><p></p><p></p><p>极客时间企业版学习平台在前沿技术的底座支撑下，结合双数研究院的研究洞察及AI技术与 3000+ 位专家共创产出高品质内容及各行业不同层级人才的数字化学习解决方案。面向企业管理者和学员构建组织管理、人才发展中心、课程中心、考练中心、认证中心、培训中心、运营中心、数据中心，打造学习培训闭环，并提供多终端的学习体验。可针对 OD 组织发展、TD 人才发展、LD 学习发展提供轻咨询服务，帮助企业搭建培训体系和人才梯队，承接企业战略，提升组织韧性。</p><p></p><p>极客时间企业版将从以下六个方面持续升级平台功能，提供个性化的学习服务，缩短学习成果的转化周期，助力企业数字人才培养提质增效。</p><p></p><p>定制岗位能力模型：汇聚数百位行业专家，采用 PTK 框架，提供全面的岗位能力视角，定义数字人才能力评估标准，为企业人才招聘、培训等场景提供决策依据。</p><p></p><p>AI 测评：预置版权独家、专家共研、区分难度等级、贴合实际工作场景的10000&nbsp;道官方测试题库，并支持企业定制化测评题目。采用单选/多选/判断/实操等不同测评形式，通过平台的自适应测评算法，动态考察学员真实的能力水平，明确人岗匹配度，识别关键岗位核心人才。</p><p></p><p>智能学习路径：运用 AI 技术结合工作绩效表现，定性与定量相结合，了解学员掌握能力与不足，根据其学习进度和能力要求，为学员匹配个性化课程内容，打造“千人千面”的学习体验。</p><p></p><p>AI 学习助手：AI 学习助手作为学员的一对一私教，通过实时调动大模型中的信息和数据，分析学员的能力掌握程度，推荐多样化的课程资源及学习路径，激发学生的学习兴趣和学习动力，缩减短培训成本和时间成本。</p><p></p><p>智能学习报告：通过数据可视化分析报告，全方位呈现学员的学习行为、培训前后的能力水平差距，反映学员真实需求和课程资源质量，对培训过程进行全链路效果跟踪，降低项目风险，提升项目的完成率和质量。</p><p></p><p>AI 制课：通过模块化功能设计，轻松创建企业内部课程，沉淀企业知识资产。通过虚拟数字人等智能制课工具制作企业自有课程，提高知识萃取效率，降低制课成本。</p><p></p><p></p><p></p><h3>多维度高品质学习内容，满足数字人才全方位成长需求</h3><p></p><p></p><p>极客邦双数研究院发布《数字人才发展体系：数字人才粮仓模型白皮书》，在业内首倡数字人才五层粮仓模型，即数字思维管理者、数字思维业务人才、业务架构人才、技术架构人才、专项技术人才五层数字人才，为企业数字化战略落地构筑更加扎实的人才体系。针对五层数字人才，重点进行了课程资源建设，目前平台在线课程已达2900+&nbsp;门，包括视频、音频、图文多种课程形式，覆盖 100+ 数字化岗位成长所需知识技能和 5 大热门行业，满足员工全职涯培训及企业培训全场景应用需求，多维度全方位促进员工能力提升。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/f5/ef/f52414a7f6d04917691f56562f122cef.png\" /></p><p></p><p>另一方面，极客时间紧跟前沿技术趋势，推出 AI 主题学习月，内容涵盖 AI 认知、应用场景、工作效率提升、技术知识和创新思维。课程形式多样，线上线下结合，通过理论结合实践的内容实现学习培训效果闭环。课程采取极客时间一贯坚持的 PGC 内容生产模式，邀请优质一线技术专家与极客时间的专业教研团队一起通过稳定、可复制的内容设计生产流程，打磨出体系化精品课程。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/18/186da8c37c16561f6e1d704970bebb3f.png\" /></p><p>扫描二维码，预约产品体验</p><p></p><p>数字化转型的关键在于人，而不是技术本身。数智升级不仅是企业的迫切需求，也是每一个人在这个时代必须要面对的问题。全新的极客时间企业版学习平台，打破传统的培训方式，让员工在专业化的教学资源中获得启迪，在个性化的学习服务中快速成长，让培训管理者从智能的数据分析中获得依据，从高效的项目管理中转化成果，助力企业数字人才培养提质增效。</p>",
    "publish_time": "2023-06-08 11:43:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从本地到云端：豆瓣如何使用 JuiceFS 实现统一的数据存储",
    "url": "https://www.infoq.cn/article/0TWtLD5bQtFZIXM9g7dN",
    "summary": "<p>豆瓣成立于 2005 年，是中国最早的社交网站之一。在 2009 到 2019 的十年间，豆瓣数据平台经历了几轮变迁，形成了 DPark + Mesos + MooseFS 的架构。</p><p></p><p>由机房全面上云的过程中，原有这套架构并不能很好的利用云的特性，豆瓣需要做一次全面的重新选型，既要考虑未来十年的发展趋势，也需要找到与现有组件兼容且平滑过渡的解决方案。一番改造后， 豆瓣数据平台目前形成了 Spark + Kubernetes + JuiceFS 的云上数据湖架构，本文将分享此次选型升级的整体历程。</p><p></p><p></p><h2>01 豆瓣早期数据平台</h2><p></p><p>在 2019 年，豆瓣所使用的数据平台主要由以下组件构成：</p><p>Gentoo Linux，内部使用的 Linux 发行版；MooseFS ，分布式文件系统；Apache Mesos 负责整个集群的资源管理，以及 Dpark 作为分布式计算框架提供给开发者使用。</p><p><img src=\"https://static001.geekbang.org/infoq/f3/f38d3f90cc65c3ae9018bf2a361ac91e.png\" /></p><p>（豆瓣早期数据平台架构）</p><p></p><p>从上图可以看到在这个数据平台中，计算和存储是一体的，每个计算任务是由 Mesos 进行调度的。计算任务的 I/O 操作都是通过 MooseFS 的 Master 获取元数据，并在本地获取需要计算的数据。此外，GPU 计算集群也是通过 Mesos 进行管理，不同的是， GPU 会基于显存进行共享。</p><p></p><h3>平台组件介绍</h3><p></p><p></p><h4>Gentoo Linux</h4><p></p><p>Gentoo Linux 是一个较为小众的 Linux 发行版，具有几乎无限制的适应性特性，是一个原发行版。Gentoo Linux 采用滚动更新的方式，所有软件包都直接从社区中获取二进制包，我们则通过源代码构建我们所需的软件包。Gentoo Linux 有一个强大的包管理器，使用它也会带来很多便利，也同时存在一些问题。比如，滚动更新的速度非常快，但对于服务器来说，可能存在一定的不稳定性。</p><p></p><p>使用源代码构建软件包的好处是当社区没有预编译好我们所需的软件包时，我们可以非常简单地构建出自己所需的软件包，并且当已有的软件包无法满足我们的需求时，也可以很容易地进行定制调整。但这也会带来较高的维护成本。</p><p></p><p>另外，如果所有软件包都能按照规范进行编写的话，依赖冲突问题几乎是不存在的，因为在打包过程中就已经可以发现。但实际情况是并不是所有软件包都能遵守一个好的依赖描述的约定，因此依赖冲突问题可能仍然存在。</p><p></p><p>Gentoo Linux 是较为小众的选择，尽管社区质量很高，但是用户也比较少，一些新项目可能没有用户进行足够的测试，我们在实际使用过程中会遇到各种各样的问题。这些问题大部分需要我们自己解决，如果等待其他人回复的话，响应会比较慢。</p><p></p><h4>MooseFS</h4><p></p><p>MooseFS 是一个开源的、符合 POSIX 标准的分布式文件系统，它只使用 FUSE 作为 I/O 接口，并拥有分布式文件系统的标准特性，如容错、高可用、高性能和可扩展性。</p><p></p><p>对于几乎所有需要使用标准文件系统的场景，我们都使用 MooseFS 作为替代品，并在其基础上开发了一些自己的小工具。例如，我们可以直接使用分布式文件系统来处理 CDN 的回源。在早期版本中，MooseFS 没有主节点的备份功能，因此我们开发了一个 ShadowMaster 作为元数据的热备节点，并编写了一些分析 MooseFS 元数据的工具，以解决一些运维问题。作为一个存储设施，MooseFS 整体比较稳定，并且没有出现重大的问题。</p><p></p><h4>Apache Mesos</h4><p></p><p>Mesos 是一个开源的集群管理器，与YARN 有所不同，它提供公平分配资源的框架，并支持资源隔离，例如 CPU 或内存。Mesos 早在 2010 年就被 Twitter 采用， IBM 在 2013 年开始使用。</p><p></p><h4>Dpark</h4><p></p><p>由于公司全员使用 Python，因此使用了 Python 版的 Spark，即 Dpark，它扩展了RDD API，并提供了 DStream。</p><p></p><p>公司内部还开发了一些小工具，例如 drun 和 mrun，可以通过 Dpark 将任意 Bash 脚本或数据任务提交到 Mesos 集群，并支持 MPI 相关的任务提交。Dgrep 是用于快速查询日志的小工具，JuiceFS 也提供了类似的工具。虽然 Dpark 本身可以容器化，但公司主要的数据任务是在物理服务器上运行的。支持容器化可以让场内任务更好地利用线上业务的模型代码。</p><p></p><h2>02 平台演进的思考</h2><p></p><p>在 2019 年，公司决定将基础设施转移到云端并实现计算和存储分离，以提高平台的灵活性。由于以前的计算任务在物理机上运行，随着时间的推移，出现了越来越多的依赖冲突问题，维护难度不断增加。</p><p></p><p>同时，公司希望内部平台能够与当前的大数据生态系统进行交互，而不仅仅是处理文本日志或无结构化、半结构化的数据。此外，公司还希望提高数据查询效率，现有平台上存储的数据都是行存储，查询效率很低。最终，公司决定重新设计一个平台来解决这些问题。</p><p><img src=\"https://static001.geekbang.org/infoq/a8/a8e00f587d614250d54551fcfdab2cb8.png\" /></p><p>平台演进时，我们没有非常强的兼容性需求。只要成本收益合理，我们就可以考虑将整个平台替换掉。这就像是环法自行车比赛中，如果车有问题就会考虑换车，而不是只换轮子。在更换平台时，我们如果发现现有平台的任务无法直接替换，可以先保留它们。在切换过程中，我们有以下主要需求：</p><p>Python 是最优先考虑的开发语言。必须保留 FUSE 接口，不能直接切换到 HDFS 或者 S3。尽可能统一基础设施，已经选用了部分 Kubernetes，就放弃了 Mesos 或其他备选项。新平台的学习成本应尽可能低，让数据组和算法组的同事能够以最低的成本切换到新的计算平台上。</p><p></p><h2>03 云上构建数据平台</h2><p></p><p>目前的云上数据平台几乎是全部替换了，Gentoo Linux 的开发环境变成了 Debian based container 的环境， MooseFS 是换用了现在的 JuiceFS，资源管理使用了 Kubernetrs，计算任务的开发框架使用了 Spark，整体进行了彻底替换的，其他的设施是在逐渐缩容的过程，还会共存一段时间。</p><p><img src=\"https://static001.geekbang.org/infoq/0f/0f33a5e0cf8214d57c721c119259e38b.png\" /></p><p>（豆瓣数据平台架构）</p><p></p><h3>JuiceFS 作为统一存储数据平台</h3><p></p><p>为了更好地满足不同的 I/O 需求和安全性考虑，我们会为不同的使用场景创建不同的 JuiceFS 卷，并进行不同的配置。JuiceFS 相对于之前的 MooseFS，创建文件系统更加简单，实现了按需创建。除了 SQL 数据平台外，我们的使用场景基本上都是由 JuiceFS 提供的服务。</p><p><img src=\"https://static001.geekbang.org/infoq/72/72120eccc30c6af0f20968b58a3b5b9a.png\" /></p><p>在 JuiceFS 中，数据有几种类型：在线读写、在线读取离线写入、在线写入离线读取、离线读写。</p><p>所有的读写类型都在 JuiceFS 上进行，比如日志汇聚到卷中，Spark 可能会读取并进行 ETL，然后将数据写入数据湖。此外，从 Kafka 数据源读取的数据也会通过 Spark 进行处理并写入数据湖。</p><p></p><p>Spark 的 Check Point 直接存储在另一个 JuiceFS 卷中，而数据湖的数据则直接提供给算法组的同学进行模型训练，并将训练结果通过 JuiceFS 写回。我们的运维团队则通过各种脚本或工具来管理 JuiceFS 上的文件生命周期，包括是否对其进行归档处理等。因此，整个数据在 JuiceFS 中的流转过程大致如上图所示。</p><p></p><h3>新数据平台组件介绍</h3><p></p><p></p><h4>Debian based container</h4><p></p><p>首先，运维团队选择了 Debian based container 作为基础镜像，我们就直接使用了。我们的计算平台的镜像很大，为了解决任务启动速度的问题，团队在每个节点上预拉取了镜像。</p><p></p><h4>JuiceFS</h4><p></p><p>切换到 JuiceFS 存储系统时，用户感受不到变化，JuiceFS 非常稳定。JuiceFS 比 MooseFS 更好的一点是，它拥有 HDFS 的 SDK，方便了团队将来切换到 Spark 等工具。团队在 Kubernetes 上使用了 JuiceFS CSI，可以直接使用 JuiceFS 作为 Persist Volume，用起来十分方便。JuiceFS 团队沟通高效，解决问题迅速。例如，当 stream 的 checkpoint 频率太高时，JuiceFS 团队早早通知并迅速解决。</p><p></p><h4>Kubernentes</h4><p></p><p>我们早在 1.10 版本的时候就开始试用 Kubernetes。后来豆瓣对外的服务集群在 1.12 版本开始逐步迁移到 Kubernetes，基本上是在现有机器上完成了原地的替换。计算集群则是在上云后开始搭建的，基于1.14 版本。我们在版本升级方面可能比其他公司更为激进，目前我们的 Kubernetes 版本已经升级到了1.26 版。</p><p></p><p>我们选择 Kubernetes 作为计算平台的原因之一是它有比较统一的组件。此外，通过 scheduling framework 或者 Volcano，我们可以影响它的调度，这是我们比较希望拥有的一个特性。</p><p></p><p>我们还可以利用社区的 Helm 非常快速地部署一些需要的东西，比如 Airflow、Datahub 和 Milvus 等服务，这些服务都是通过 Helm 部署到我们的离线 Kubernetes 集群中提供的。</p><p></p><h4>Spark</h4><p></p><p>在最开始测试 Spark 时，我们像使用 Dpark 一样将任务运行在 Mesos 集群上。之后我们选定了 Kubernetes，使用 Google Cloud Platform 上的 spark-on-k8s-operator 将 Spark 任务部署到 Kubernetes 集群中，并部署了两个 Streaming 任务，但并未进行大规模的部署。</p><p></p><p>随后，我们确定了使用 Kubernetes 和 Airflow，计划自己实现一个 Airflow Operator，在 Kubernetes 中直接提交 Spark 任务，并使用 Spark 的 Cluster Mode 将任务提交到 Kubernetes 集群中。</p><p></p><p>对于开发环境，我们使用 JupyterLab 进行开发。厂内有一个 Python 库对 Spark Session 进行了一些小的预定义配置，以确保 Spark 任务能够直接提交到 Kubernetes 集群上。</p><p></p><p>目前，我们使用 Kubernetes Deployment 直接部署 Streaming 任务，这是一个很简单的状态，未来可能会有一些改进的地方。另外，我们正在准备试用 Kyuubi &amp; Spark Connect 项目，希望能够为线上任务提供更好的读写离线数据的体验。</p><p></p><p>我们的版本升级非常激进，但确实从社区中获益匪浅。我们解决了日常计算任务中许多常见的优化场景。我们激进升级的原因是希望能够尽可能多地利用社区的资源，提供新特性给开发者。但我们也遇到了问题，例如 Spark 3.2 的 parquet zstd 压缩存在内存泄漏。为了规避这个问题，我们提前引入了未发布的补丁。</p><p></p><p>现在，我们使用两种方式来读写 JuiceFS 数据：FUSE 和 HDFS。FUSE 主要用于 ETL 任务，例如读写日志和 CSV 文件。我们也会将 Hive 表转存为 CSV 文件下载供未切换到 Spark 的任务进行计算。其他的数据，则直接通过预先配置好的 HDFS（如 Hive Table 和 Iceberg Table）进行读写，这大大简化了我们的工作。</p><p></p><p>在数据湖的选择上，我们一开始考虑了 Delta Lake，但由于它不支持 Merge on Read，在目前的使用场景存在写放大，我们放弃了它。取而代之，我们选择了 Iceberg，并将其用于 MySQL CDC 处理。我们将数据直接存储在 JuiceFS 上进行读写，并且目前没有遇到任何性能上的问题。未来，如果我们需要扩大规模使用，可能需要与 JuiceFS 的团队沟通一下，看看有哪些优化措施。</p><p></p><h2>04 收获与展望</h2><p></p><p>我们切换到新的计算平台之后，获得了很多原来没有的功能。例如，我们现在可以使用基于 SQL 的大量任务，这些任务的性能比以前好得多，各种报表的实时性也更好了。</p><p></p><p>与 Mesos 的情况不同，Spark 声明了多少资源就使用多少资源，这与以前的 Dpark 相比有很大的差异，因为以前大家都是公平分享，相互之间会有影响。现在，每个任务的执行时间都比较可预测，任务评估也比较容易预测，整个新平台对于业务数据的读取也有更好的时效性。</p><p></p><p>以前的历史包袱是相当沉重的，现在我们已经赶上了社区的步伐。去年年末的各种统计和排名都已经迁移到了新的计算平台上，并且运行非常稳定。</p><p></p><p>我们正在优先考虑采取一些成本下降措施，以实现整个计算集群的动态扩缩容。我们正积极努力实现此目标，并希望提供更加稳定的 SQL 接口。为此，我们计划采用支持 Multi-tenant 的 SQL 服务器，并尝试引入 Spark 3.4 的最新特性。</p><p></p><p>长远来看，我们希望通过 Spark Remote Shuffle Service 进一步实现存算分离，以便更有效地利用资源。也许未来我们会开发一个“Spark as a Service”，提供给开发者使用。总之，我们正在追赶社区的步伐，并不断努力提升我们的技术水平。</p><p></p><p>直播回顾：https://www.bilibili.com/video/BV1oM41137Rp/</p><p></p><h3>关于作者</h3><p></p><p>曹丰宇，负责豆瓣数据平台的功能开发和维护</p><p></p><p>延伸阅读：</p><p><a href=\"https://www.infoq.cn/article/douban-infrastructure-2014\">豆瓣的基础架构</a>\"</p><p><a href=\"https://www.infoq.cn/article/douban-dev-management\">豆瓣的研发管理</a>\"</p><p><a href=\"https://www.infoq.cn/article/sa*aTPRbs3whkd1xrpUY\">洪强宁：编程三十年，因 Python 结识豆瓣，想用技术改变世界</a>\"</p>",
    "publish_time": "2023-06-08 14:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "黑盒不黑：跨端 C/C++ 库一键源码调试方案",
    "url": "https://www.infoq.cn/article/1feb73c6aa76a0dc4bd502a6c",
    "summary": "<p>作者：王森</p><p></p><p></p><blockquote>C/C++二进制库对底层模块开发者和业务接入层开发者来说都是个黑盒，通过这几十行的脚本，让C/C++二进制库在各平台上能够使用默认的IDE快速进行源码调试，有助于提升问题排查效率和打破上下游边界。</blockquote><p></p><p></p><p></p><h1>一、双向黑盒</h1><p></p><p></p><p>C/C++具有天然的跨平台特性，丰富的构建工具、Native的性能以及成熟的社区生态，近年来移动端也越来越多的集成了一些使用C/C++开发一些逻辑内聚且对性能要求较高的模块，特别是各类引擎模块例如音视频编解码、RPC网络库、数据库、神经网络库等。</p><p></p><p>但并不完美的是，C/C++技术栈在获得上述收益的同时，也使得原本用原生语言进行开发的体验产生了割裂，导致了不小的“隐性成本”，这点Dropbox在其分享的一系列C++文章中也有提到。</p><p></p><p>https://dropbox.tech/mobile/the-not-so-hidden-cost-of-sharing-code-between-ios-and-android</p><p></p><p>C/C++工具链和构建环境比较复杂，Makefile、cmake、gn、ninja等构建工具繁多，对环境的要求极高，因此这些库通常都是以链接后的静态库或者动态库的方式进行二进制分发，app再进行二次链接之后进行调用。</p><p></p><p>在模块层和接入层都保障自己Unit不出问题的情况下，这一切看似都井井有条。但一旦出现问题需要排查的时候，C/C++二进制库对双方来说都是个黑盒：</p><p></p><p>1）对于底层模块开发者来说，代码的调用是在平台代码层，提供出去的二进制没法调试，“破案”就只能靠程序员传统艺能“打日志”的方式了；</p><p></p><p>2）对于业务接入层开发者来说，对方提供的二进制也无法调试，只能看到一行行难以理解的汇编代码，问题只能定位到自己输入输出，无法定位到更深层次的原因。</p><p></p><p>因此导致出现问题后的排查效率极低，甚至出现过一个问题来来回回排查好几天，影响项目进展。</p><p></p><p></p><h1>二、源代码调试</h1><p></p><p></p><p>LLDB源码调试的原理是根据二进制中的DWARF调试信息找到对应源代码路径和行号等信息，在Mach-O格式文件中，这部分信息存放在__DWARF相关的Section中，我们可以使用dwarfdump命令查看结构化的调试信息，elf格式文件可以使用objdump查看：</p><p></p><p><code lang=\"null\">0x00000ed8:     DW_TAG_inlined_subroutine\n                  DW_AT_abstract_origin (0x00000ec6 \"AbcAppContext\")\n                  DW_AT_ranges  (0x000004e0\n                     [0x00000506, 0x00000560)\n                     [0x00000576, 0x000005a2))\n                  DW_AT_call_file (\"/Users/abc/.abc/build/123456/workspace/ios_out/arm/../../abc_core/src/abc_engine_impl.cc\")\n                  DW_AT_call_line (37)\n                  DW_AT_call_column (0x0a)\n​\n0x00000ee4:       DW_TAG_inlined_subroutine\n                    DW_AT_abstract_origin (0x00000ec1 \"AbcAppContext\")\n                    DW_AT_ranges  (0x000004f8\n                       [0x00000506, 0x00000560)\n                       [0x00000576, 0x000005a2))\n                    DW_AT_call_file (\"/Users/abc/.abc/build/123456/workspace/ios_out/arm/../../abc_core/public/abc_core/abc_app_context.h\")\n                    DW_AT_call_line (12)\n                    DW_AT_call_column (0x08)\n</code></p><p></p><p>由于DWARF中定义的源码路径本地并不存在，因此LLDB并不能进入源码调试模式，这时候要实现本地源码调试有两个方案：</p><p></p><p>在本机重新进行源码编译，这样生成的二进制库中定义的源码路径是本地真实存在的，但这又面临编译环境复杂问题；免编译调试，想办法将二进制中的源码路径映射成本地真是存在的源码路径，这样不用重新编译也无需替换本地二进制库。</p><p></p><p></p><h1>三、免编译调试</h1><p></p><p></p><p>幸运的是LLDB提供了命令可以修改路径，将二进制中的路径前缀映射到本地的真实路径，因此你可以在Debug控制台中输入以下指令实现本地调试：</p><p></p><p><code lang=\"null\">settings set target.source-map [二进制中的源码路径] [本地代码路径]\n</code></p><p></p><p>再次点击单步调试后，我们就可以看到熟悉的源码调试界面：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9d/9dff8f9ae2e4a58678305e1b99ebabb5.png\" /></p><p></p><p>但这还是太麻烦了，首先这个命令不一定记得住，然后还要从二进制中找到需要映射的路径地址，而且每次重新运行app之后又得重新输入一遍；因此，我们利用LLDB提供的lldbinit和Python API，这些步骤都自动化完成，真正实现一键调试体验。</p><p></p><p>lldbinit是LLDB在启动调试的时候提供给开发者自定义调试命令的接口文件，我们可以在源码根目录下放置一个lldbinit用于自定义源码映射的逻辑，于是调试的流程就变成：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ab/ab717956d2d30a9081c5ef517f60703b.png\" /></p><p></p><p></p><h1>四、自动映射源码</h1><p></p><p></p><p>增加一个Python文件，例如debug.py，存放在源码目录下，用Python实现以下伪代码步骤：</p><p></p><p>1）通过Python API查找指定的Symbol调试信息：</p><p></p><p><code lang=\"null\"># symbol_name 为这个库中的任意一个符号名\nfuncs = target.FindGlobalFunctions(symbol_name, 0, lldb.eMatchTypeNormal)\n# 通过 lldb API 获取到这个符号的源码文件信息\nsymbol = funcs.GetContextAtIndex(0)\nsymbol_file = \"%s\" % symbol.GetCompileUnit().GetFileSpec()\n</code></p><p></p><p>2）约定规则，将Python文件默认认为存放在源代码的根目录，这样可以比较方便的获取本地源码路径：</p><p></p><p><code lang=\"null\">local_source_path = os.path.dirname(__file__)\n</code></p><p></p><p>3）然后需要找到调试信息中存储的路径与本地路径之间的前缀映射关系，可以通过遍历路径目录的方式逐级查找本地对应的源码是否存在：</p><p></p><p><code lang=\"null\">src_comps = symbol_file.split(\"/\")\nfor i in range(len(src_comps)):\n  if len(src_comps[i]) == 0:\n    continue\n​\n  suffix_path = \"/\".join(src_comps[i:])\n  detect_path = \"/\".join([local_source_path, suffix_path])\n  detect_file = Path(detect_path)\n​\n  if detect_file.is_file() == False:\n    continue\n​\n  print(\"-&gt; Matched:\", detect_path)\n  prefix_path = \"/\".join(src_comps[:i])\n</code></p><p></p><p>4）再调用lldb命令将源码路径映射到本地路径：</p><p></p><p><code lang=\"null\">target.GetDebugger().HandleCommand(\"settings set target.source-map '%s' '%s'\" % (prefix_path, local_source_path))\n</code></p><p></p><p>5）以上替换的主要逻辑实现，需要通过一个lldbinit将这个方法添加给lldb运行时，我们可以通过添加stop-hook的方式让上述脚本自动运行：</p><p></p><p><code lang=\"null\">lldbinit:\n​\ncommand script import -c debug.py\n# 这里通过指定一个 Library 中一定存在符号名用于查找调试符号中的源码目录\ntarget stop-hook add -P debug.DebugHook -k \"symbol\" -v \"::FuncAbc\"\n</code></p><p></p><p></p><h1>五、工程改造</h1><p></p><p></p><p>最后，通过一些简单的工程改造，便可以将调试应用到Android和iOS的日常开发环境中：</p><p></p><p>1）编译参数增加变量调试信息，大部分情况下不需要处理，但基于不同工具链或编译参数构建的二进制库中，有的缺少了变量的调试信息（通过dwarfdump可以查看是否存在DW_TAG_variable信息），导致在单步调试的过程中无法打印或者查看变量，只需要编译参数中增加或修改-gfull即可；</p><p></p><p>2）DoNotStrip，Android工程中，为了包大小通常会将so strip掉调试信息，因此在Debug环境下，可以将so改造成DoNotStrip。</p><p></p><p></p><h1>六、最后</h1><p></p><p></p><p>通过这几十行的脚本，让C/C++二进制库在各平台上能够使用默认的IDE快速进行源码调试，有助于提升问题排查效率和打破上下游边界。</p><p></p><p>除了应用在C/C++模块，以上原理同样适用于Swift或者ObjC、Rust等其他任何能够生成DWARF调试信息并支持使用lldb调试的语言。</p><p></p><p></p><h2>附实现源码</h2><p></p><p></p><p>lldbinit：</p><p></p><p><code lang=\"null\"># LLDB commands for quickly debug C/C++ libraries with source code\n​\ncommand script import -c debug.py\ntarget stop-hook add -P debug.DebugHook -k \"symbol\" -v \"::FuncAbc\"\n</code></p><p></p><p>debug.py：</p><p></p><p><code lang=\"null\">import lldb\nimport os\nfrom pathlib import Path\n​\nclass DebugHook:\n  def __init__(self, target, extra_args, internal_dict):\n    self.source_mapped = False\n    self.symbol_name = extra_args.GetValueForKey(\"symbol\").GetStringValue(100)\n    print(\"With Symbol:\", self.symbol_name)\n​\n  def handle_stop(self, exe_ctx, stream):\n    if self.source_mapped and exe_ctx != None:\n      # 已经做过源码映射，无需再次映射\n      return\n​\n    target = exe_ctx.GetTarget()\n    print(\"-&gt; Target Stopped:\", target)\n​\n    print(\"-&gt; Searching Symbol:\", self.symbol_name)\n    funcs = target.FindGlobalFunctions(self.symbol_name, 0, lldb.eMatchTypeNormal)\n    if funcs.GetSize() == 0:\n      print(\"** No Symbol Found\")\n      return\n​\n    symbol = funcs.GetContextAtIndex(0)\n    symbol_file = \"%s\" % symbol.GetCompileUnit().GetFileSpec()\n    print(\"-&gt; Symbol Source:\\n  \", symbol_file)\n    local_source_path = os.path.dirname(__file__)\n    print(\"-&gt; Local Source:\\n  \", nest_path)\n​\n    # 便利二进制中源码路径的各层级目录，查找与本地源码匹配的目录路径\n    src_comps = symbol_file.split(\"/\")\n    source_mapped = False\n    for i in range(len(src_comps)):\n      if len(src_comps[i]) == 0:\n        continue\n      suffix_path = \"/\".join(src_comps[i:])\n      detect_path = \"/\".join([nest_path, suffix_path])\n      detect_file = Path(detect_path)\n​\n      if detect_file.is_file() == False:\n        continue\n​\n      print(\"-&gt; Matched:\", detect_path)\n      prefix_path = \"/\".join(src_comps[:i])\n​\n      print(\"-&gt; Mapping Source:\\n  '%s' -&gt; '%s'\" % (prefix_path, nest_path))\n      target.GetDebugger().HandleCommand(\"settings set target.source-map '%s' '%s'\" % (prefix_path, nest_path))\n      print(\"-&gt; Done, Feel free to deubg now!\")\n​\n      # Mark this time as mapped\n      source_mapped = True\n      break\n​\n    if source_mapped == False:\n      print(\"-&gt; Source Mapping Failed: No local source path matched\")\n​\ndef __lldb_init_module(debugger, internal_dict):\n    print('source-debug enabled')</code></p><p></p>",
    "publish_time": "2023-06-08 14:10:16",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Sam Altman、Yann LeCun等多位大佬站台！2023智源大会6月9日正式启航",
    "url": "https://www.infoq.cn/article/gWSmwZ6V4sN7HTr3rHyA",
    "summary": "<p>第五届北京智源大会将于6月9日启航！本届智源大会汇聚人工智能领域最关键的人物、最重要的机构、最核心的话题与最内行的观众，将为专业精英人士献上本年度人工智能的巅峰盛会。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e0/e05f7ae5f83ec9d96762f6a784d871f1.png\" /></p><p></p><p>智源大会嘉宾阵容</p><p></p><h2>大咖云集：影响未来的关键问题讨论</h2><p></p><p></p><p>2023智源大会现场，将会有图灵奖得主Yann LeCun等领衔探讨大模型发展现状与未来趋势；图灵奖得主Joseph Sifakis，Midjourney创始人David Holz，中国工程院院士郑南宁，智源研究院理事长张宏江，清华大学智能产业研究院（AIR）院长张亚勤，智源研究院院长黄铁军，智源首席科学家、清华大学教授朱军等将进行一系列面向未来的特邀报告与尖峰对话。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/44/440b81ddd3edf2a1dde8a3eb0fb4fd3a.png\" /></p><p></p><p>2023智源大会主席</p><p>&nbsp;</p><p>未来生命研究所创始人Max Tegmark，图灵奖得主Geoffrey Hinton、姚期智，OpenAI创始人Sam Altman，中国科学院院士张钹，UC伯克利分校教授Stuart Russell等嘉宾将进行一系列安全伦理问题和风险防范的讨论。</p><p></p><p>AI生命科学方向的讨论将由诺贝尔化学奖得主 Arieh Warshe、2021年科学突破奖生命科学奖得主 David Baker、美国国家科学院和医学院双院士谢晓亮等顶尖专家引领探讨。</p><p></p><h2>星辰大海：纵览前沿研究趋势</h2><p></p><p>大模型的引爆人工智能概念不是偶然，算法的进步提供了重要支持。本届大会邀请过去一年领域突破的重要工作完成人，亲身讲解技术成果。</p><p></p><p>如PaLM-E、OPT、NLLB、T5、Flan-T5、LAION-5B、RoBERTa等重要工作完成人届时将出席，其中多位将亲临北京，与现场观众面对面交流，讲解研究成果背后最激动人心的故事。</p><p></p><p>大会还汇聚了国际明星团队，一览人工智能发展前沿趋势，如OpenAI、DeepMind、Anthropic、HuggingFace、Midjourney、Linux基金会等代表机构，以及Meta、Google、微软等企业，斯坦福、UC伯克利、MIT等学府齐聚一堂。</p><p></p><h2>深度研讨：全面、专业、前沿</h2><p></p><p>两天3场特邀报告，13场专题论坛，百场精彩讨论。不同于对热度的追逐，智源大会极为注重为人工智能专业人士献上兼具专业深度与创意启发的思想交流体验，力争将每个值得探讨的话题拉到极致。</p><p></p><p>6月9日首日议程包括基础模型前沿技术论坛，类脑计算论坛，视觉与多模态大模型论坛，具身智能与强化学习论坛，大模型新基建与智力运营论坛。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/6b/f5/6bb7c7635d8ed1a9b7ca39efdfdcd5f5.jpg\" /></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/e8/d9/e8f3191c5f46e160473baf0a40af50d9.jpg\" /></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/yy/y5/yya57a3a8e3d098bba6df3yy08af8yy5.jpg\" /></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/47/77/4734f91ca12043d1fb2cb927010c4a77.jpg\" /></p><p></p><p>智源大会主要议程</p><p>&nbsp;</p><p>6月10日议程包括生成模型论坛、AI系统论坛、基于认知神经科学的大模型论坛、AI生命科学论坛、AI安全与对齐论坛、自动驾驶论坛、AI开源论坛、智能的物质基础论坛。</p><p></p><h2>智源大模型全面开源，旗舰评测项目启航</h2><p></p><p>智源研究院是中国大模型研究的先行科研机构之一。本次大会上，“悟道3.0”迈向全面开源崭新阶段，将在大会上发布系列大模型研究成果。</p><p></p><p>此外，智源研究院一直致力于通过开源开放，促进人工智能领域协同创新，构建大模型时代的“新 Linux 生态”。本次大会，“FlagOpen 大模型技术体系”也将带来大模型评测方面的最新进展，帮助大模型训练效率提升。</p>",
    "publish_time": "2023-06-08 14:32:34",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "市值暴涨10519%，原来全世界搞大模型的企业都在给这位华人打工！",
    "url": "https://www.infoq.cn/article/e8OgM5MKRGP3ps8f6hLX",
    "summary": "<p></p><blockquote>英伟达过去近20年间一直积蓄着软硬件力量，为2023年AI大爆发这一历史性时刻做好了准备。他们能够成为这场风暴的核心绝非偶然。</blockquote><p></p><p></p><h2>乘着AI这股东风，英伟达“赢麻了”</h2><p></p><p><a href=\"https://www.infoq.cn/article/e95bPU2tu1o9eGQqmQvP\">英伟达</a>\"是一家主要生产图形处理单元（简称GPU）的厂商。但今时今日看来，“图形”这个表述已经不太准确，GPU真正擅长的其实是工作量巨大的浮点数学运算。其早期用途就是支撑起计算机上搭配的高帧率与高分辨率显示器，也是图形处理这种说法的由来。毕竟在那个时代，这就是GPU最常见的应用场景。</p><p></p><p>大约在2005年左右，英伟达敏锐意识到图形虽然确实在疯狂吞噬浮点算力，但却绝对不是唯一的实际应用场景。于是他们踏上了一段漫长的研发旅程，积蓄下的力量也让他们成为如今这场AI风暴的绝对核心。从2007年的CUDA开始，英伟达开发的软件允许更多人使用<a href=\"https://www.infoq.cn/article/1UyH2okZUKWlbwby3dQV\">GPU</a>\"处理图形之外的更多工作负载。</p><p></p><p>2012年，<a href=\"https://www.infoq.cn/article/99bQgZ9PmtBOYfiqRWPB\">英伟达</a>\"的投入得到了初步回报。全球首个高质量图像识别AI，也就是AlexNet，正是建立在英伟达的GPU加软件之上，还成功在一年一度的ImageNet竞赛中碾压其他竞争对手。从那时起，英伟达的软硬件组合就成为除谷歌之外，所有厂商开展AI研究时的默认配置。</p><p></p><p>接下来，<a href=\"https://www.infoq.cn/article/7QaqOxHdropQbIKX7v3L\">英伟达</a>\"又把后续GPU研发划分成两条赛道：其一是PC端与加密货币采矿设备，其二则是数据中心GPU。PC端的GPU产品相当昂贵，最高售价可达1600美元左右；数据中心GPU的价格则更加夸张，往往高达1万到1.5万美元，甚至出现过4万美元的旗舰单卡。英伟达的数据中心GPU拥有约75%的毛利空间，在硬件领域简直是前所未闻。</p><p></p><p>但这也是一家厂商在AI软硬件领域获得实质性垄断地位后，自然能够摘取的胜利果实。2012年之后还有另一件大事，就是英伟达的GPU和软件让<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1542\">AI模型</a>\"的体量获得了指数级增长。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/59/59dd1415ed5544c7a91fe3223a432cde.png\" /></p><p></p><p>这里的Y轴递增为对数尺度，因此在右端的“现代”部分呈现出的其实是恐怖的指数级增长。</p><p></p><p>在2012年之前的几年间，模型体量大致按照摩尔定律每两年增加一倍。但从2012年开始，每家技术企业都开始用<a href=\"https://www.infoq.cn/article/66Vpqhp4hXbGBrwk7H9K\">英伟达</a>\"GPU研究机器学习，模型体量折线也开始一路飙升，每3到4个月就翻一番。这样的速度一路持续到ChatGPT亮相。期间出现的最大模型就是AlphaGo，它最擅长的是在棋坪之上狂虐人类选手。甚至一直到2021年，当时最大的AI模型还只能玩玩游戏。</p><p></p><p>模型大小很重要，因为在生产环境中构建和运行这些模型的成本，也随着模型体量呈现出指数级增长。GPT-4的体量就是同族大哥GPT-3.5的3到6倍。但<a href=\"https://www.infoq.cn/article/xZaNyw2QsZcxmNXUvkZv\">OpenAI</a>\"为GPT-4 API开出的订阅费却要高出15到60倍。另外需要强调，OpenAI开放的并不是GPT-4的最佳版本。负责托管OpenAI大语言模型的微软Azure拿不出足够的GPU来支撑这项业务，所以大部分手头拮据的客户暂时还与最强大语言模型无缘。不止如此，GPU供应短缺还阻碍着其他种种服务的实现。</p><p></p><p>我们举个简单的例子。请ChatGPT为即将召开的美联储会议写首诗，输入3句提示词，让它输出一首28行诗。看看这样一项简单任务，在OpenAI API上要花多少钱：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f7/f73a4f76174e2d621cf552b870453155.png\" /></p><p></p><p>谷歌上一次公布搜索指数还是在2012年，当时的搜索量为1.2万亿次。这里采取较为保守的数字：3万亿次。（采用ChatGPT Plus、token计算软件、OpenAI API计费标准）</p><p></p><p>价格之所以大幅上涨，原因就在于英伟达的数据中心GPU太过紧俏。受资源所限，第三列中的GPT-4 32k服务目前仍无法全面推开。</p><p></p><p>虽然大语言模型在最初的研究阶段，就已经确立了体量越大、成本越高的基本趋势，但生产层面的大规模推理带来了更加夸张的资源需求和设施开销。于是突然之间，AI技术的基本经济逻辑发生了变化。过去十年间，每个人都在用英伟达的软硬件搞模型研究，所以如今钱都被英伟达给赚走了。</p><p></p><p>是的，我是说所有的钱：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/10/10c978c3f48b0edae6925c1963c9b1d4.png\" /></p><p></p><p>微软季度财报</p><p></p><p>多年以来，随着收入的快速增长，微软在其智能云领域建立起强大的市场影响力。但随着被迫大量采购GPU以支撑<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1542\">ChatGPT</a>\"的生产应用时，好日子正式宣告结束。微软的云运营利润率已经连续四个季度下降，原因自然就是英伟达数据中心GPU那高达75%的毛利率。</p><p></p><p>面对英伟达DGX H100这样一台AI服务器时，我们会发现其中的利润分配极其不均衡。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/34/343fad740f1aabffedb055565540e584.png\" /></p><p></p><p>英伟达产品中各第三方组件的估算成本</p><p></p><p>作为AI服务器领域的绝对主力，英伟达DGX H100总体销售额的约九成都落进了芯片巨头的口袋。这甚至还没算英伟达认证授权设备的钱。</p><p></p><p>如果大家碰巧想打造自己的高性能服务器，可以选择回避英伟达认证、搭载廉价CPU，或者压缩内存/存储空间的方式来降低成本。当然，回避英伟达网络DPU，换成博通或者Mellanox（好像也跟英伟达有关系）等更便宜的硬件似乎也行，但这可能会导致性能瓶颈。但无论怎么节约，8个H100 GPU和负责GPU互连的4个NVSwitch肯定躲不掉，光这些就要花掉你近18万美元。</p><p></p><p>钱确实都被英伟达给赚了，他们花了近20年时间为2023年的AI大爆发积蓄力量。虽然巨额利润让英伟达成为市场上的众矢之的，但其捍卫AI硬件主导权的护城河就是英伟达掌握着唯一完整的软硬件组合，而且这套组合是研究人员们自2012年以来就长期依赖的默认选项。随着我们将这些超大体量模型投入生产，这个默认选项正令每家参与厂商都“血流不止”。</p><p></p><p>那么，业界又有怎样的应对之道？目前来看主要分三点：</p><p></p><p>硬件：采用“AI加速器”这类替代性硬件，以低得多的成本执行相同的工作。模型体量：在近期开发中，研究人员正努力在更小的模型上达成更好的效果，借此显著降低对GPU算力的需求。软件：将训练和推理负载从硬件上剥离出来，抽干英伟达的护城河。</p><p></p><h2>AI加速器：暗渡陈仓之策</h2><p></p><p>AI加速器其实是多种不同硬件类型的松散组合。这项技术始于2015年，当时谷歌的AI训练需求已经超过了英伟达的GPU供应能力。因此在同年，谷歌首次公布了供内部使用的张量处理单元（TPU）。目前TPU 2、3和4版已经在Google Cloud上开放租用，在执行相同工作负载时能比云GPU节约40%到50%成本。</p><p></p><p>这些加速器拥有多种设计方式，但底层技术逻辑是相同的——以计算成本更低的整数运算，模拟处理成本极高的浮点运算。这虽然会导致数学精度降低，但大量研究表明除科学应用之外，大多数AI模型并不需要<a href=\"https://www.infoq.cn/article/UwLvArX4teBpNOxYTMoL\">英伟达</a>\"GPU提供的极高精度。</p><p></p><p>所以这就像是在作弊，但效果似乎不错。现在我们已经看到了AMD/Xilinx、高通和英特尔等厂商的AI加速器，再加上Google Cloud的原研TPU。亚马逊旗下的AWS也开发出了自己的加速顺。另据报道，微软也打算为Azure研发加速器，可能会与AMD合作分担OpenAI的工作负载。</p><p></p><p>但这一步也得走得小心谨慎。一方面，厂商们希望慢慢从英伟达手中夺回业务利润；另一方面，在可预见的未来，各厂商仍须采购大量英伟达GPU。只有长袖善舞者才能在这样微妙的局面下始终占据主动地位。</p><p></p><p>在后文中，我们还会聊聊阻碍硬件发展的最大因素——英伟达的软件护城河。</p><p></p><h2>模型体量：小即是美</h2><p></p><p>2012年以来，AI模型的体量开始迅速膨胀，每3到4个月就翻一番。经过多年积累，模型体量已经极为惊人。以OpenAI为例：</p><p></p><p>GPT-1 (2018年): 多达1.17亿参数GPT-2 (2019年): 多达15亿参数GPT-3 (2020年): 多达1750亿参数GPT-4 (2023年): OpenAI没有公布，但可能已经达到万亿级别这样的体量在研究阶段还能承受，但到生产应用阶段已经开始产生恐怖的成本。受到Azure设施端GPU供应能力的限制，OpenAI甚至无法将GPT-4的最佳版本对外开放。</p><p></p><p>这些根本就不是秘密，从去年秋季开始，每个人都已经感受到了新的发展方向。“越大越好”在商业环境中没有任何意义，“小即是美”才是AI时代的新母题。</p><p></p><p>而这一切的开端，就是ChatGPT公布的那一刻。之前不少大大小小的公司都在做自然语言处理，ChatGPT如同一记响亮的耳光，昭示世人什么叫更大更好、什么叫引领时代。恐慌情绪也由此开始蔓延。</p><p></p><p>去年，Stability AI的开源Stable Diffusion图像生成模型得到了人们的普遍关注。不少厂商很快决定开源自家模型，看看能不能在社区的支持下更上一层楼。Facebook就是其中之一，他们开源了自家LLaMA语言模型，其参数规模高达650亿，约为GPT-3的三分之一，比GPT-4小9到18倍。之后，斯坦福大学的研究人员又开发出了Alpaca版本，能够在几乎所有硬件上运行。</p><p></p><p>转机就此出现。</p><p></p><p>只有拥有关注和热度，社区的开源开发速度往往相当惊人。如今，已经有大量应用程序被构建在Alpaca和其他开放模型之上。人们还在努力提升模型性能的同时，想办法控制它们的参数体量。</p><p></p><p>最重要的是，这些模型已经开始在消费级硬件，包括个人电脑甚至是智能手机上运行。而且它们完全免费，于是基础模型领域的分界线不再按企业划分，而是呈现出商业与开源两大阵营。</p><p></p><p>谷歌当然也注意到了这股趋势。本届I/O大会上，他们就公布了一套比前代更小、但性能却更强的语言模型。</p><p></p><p>LaMDA (2021年): 多达1370亿参数PaLM (2022年): 多达5400亿参数PaLM 2 (2023年): 根据未经证实的内部消息，参数多达3400亿，基本符合谷歌所谓比上代模型“明显更小”的说法这是我印象中AI模型第一次小型化转变。其中最小的PaLM 2模型甚至能够运行在PC或智能手机之上。</p><p></p><p>必须承认，GPT-4仍然是最好最强的语言模型，但也是体量最大、运行成本最高的方案。这对英伟达有利，但也激起了业界打造高性能小模型的热情。谷歌已经迈出了第一步，开源贡献者也在微调自己的领域模型，而且主要以LLaMA/Alpaca为底材。</p><p></p><p>随着更多工作负载运行在消费级硬件之上，英伟达也必须接受市场对GPU算力的依赖度日益降低的现实。</p><p></p><h2>软件：抽干护城河</h2><p></p><p>非英伟达阵营的AI软件基础设施既不够完善又有严重的碎片化问题，在这样的硬件上构建系统往往会把人带进死胡同。唯一的例外就是谷歌，他们自2015年开始就在围绕TPU构建内部工具，并用实际行动证明这条路绝对走得通。</p><p></p><p>对英伟达来说，目前业务优势中最重要的部分并不是硬件——那只是表象，只是赚钱的载体。真正的核心，是他们研究了近20年的软件。软硬件之间的紧密结合，才形成了英伟达如今这坚不可摧的技术护城河。然而，高昂的生产运营开销已经令客户们不堪重负。</p><p></p><p>多年以来，非英伟达研究人员会各自根据需求编写软件，这种一盘散沙的组织形式根本拿不出统一且稳定的生产环境，也是颠覆英伟达霸权中最困难的一环。</p><p></p><p>目前同类最佳方案来自Chris Lattner创立的Modular公司。Lattner在软件行业可谓是传奇人物，在研究生期间编写的LLVM成为目前各类主流软件编译器的基础。LLVM的创新核心在于其模块化结构，能够扩展至任意编程语言和硬件平台。他曾在苹果主导创立了<a href=\"https://www.infoq.cn/article/GFfVLVpkIGOcKYB85Opb\">Swift编程语言</a>\"团队，随后又在谷歌、特斯拉和SiFive任职。Modular公司也在A轮融资中获得了谷歌的资助。</p><p></p><p>Modular目前的一大工作重点是打造推理引擎，也就是负责在生产环境中运行模型的部分，且同样采用LLVM那样的模块化设计。它能够扩展至一切开发框架、云或硬件平台。无论模型本身如何构建，都可被放入模块化推理引擎之内，并在云端的任意硬件上运行……至少Modular公司承诺如此。</p><p></p><p>此举堪称釜底抽薪，誓要抽干英伟达的护城河，攻下皇城夺其鸟位。</p><p></p><h2>英伟达的反击之战</h2><p></p><p>英伟达正独力对抗整个世界，对手不只有自己的客户，还有客户的客户。而英伟达的思路非常简单——永不自满、永不止步。关注英伟达近期展会的朋友，一定都能感受到这种居安思危的强烈信念。</p><p></p><p>但有时候倾覆可能就有一瞬之间，而且真正的对手并不是看得见的洪水猛兽，而是看不见的涓流渗透——也就是那些更便宜、性能极差但却无处不在的普通硬件。</p><p></p><p>历史上类似的经典案例是<a href=\"https://www.infoq.cn/article/wAM6PJiYjiyyj3l2jt4x\">IBM</a>\"与英特尔之争。1970年代，IBM的客户发现英特尔等厂商正着手打造“微型计算机”，但因为性能太差而表示不感兴趣。IBM相信了客户的判断，认为不必管它。可英特尔的芯片在业余爱好者群体中掀起狂潮，健康的现金流也支撑起芯片巨头不断投资并改进自家CPU。</p><p></p><p>随着首款PC电子表格软件Visicalc的面世，<a href=\"https://www.infoq.cn/article/EDSy8OCKbCRc9TiB48PI\">英特尔</a>\"的微型计算机突然间足以胜任商业应用。IBM客户立马改旗易帜，就连IBM自己也成为英特尔的第一位大客户。之后的故事，大家应该都知道了。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/15/15c2c5a89d62824edccfd6371416efcf.png\" /></p><p></p><p>所以在我看来，英伟达也得拿出自己的AI加速器来护住自己的侧翼，哪怕削弱利润和增长空间也在所不惜。如果英伟达不做，就一定会有其他厂商出来做这件事。</p><p></p><h2>英伟达的估值</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/ea/ead40fb50da96798e8784b69157ddff3.png\" /></p><p></p><p>网上各色讨论不绝于耳</p><p></p><p>英伟达的估值如今绝对是热门议题。按照最乐观的假设，英伟达的市场估值也至少相当于50年的经营收益。但这么理想的状况只可能存在于理论模型当中。</p><p></p><p>2023年的英伟达，其实与1999到2000年的思科颇为相似：</p><p></p><p>成为新一波技术的领先硬件基础设施供应商：1999年的互联网与2023年的人工智能尽管都保持着快速增长，但思科在2000年的市盈率已达到200+（即经营200多年才能赚到市场估值），而英伟达上周五的市盈率为204倍。</p><p></p><p>一位推特用户分享的数据显示，过去十年回报率最高的十大科技股中，英伟达以10519%居首。排名第二的是AMD，回报率达4342%；特斯拉以2756%的回报率名列第三。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/df/df65548d34cb30552472e835c2b990ed.png\" /></p><p></p><p>但随着2001年经济衰退的结束，对思科的看涨风潮也很快偃旗息鼓。下面来看思科在那个时期的股价变化：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f9/f9cd92b49a8cbdbd028a5326b028adcc.png\" /></p><p></p><p>必须承认，估值非常重要。但十多年来的宽松金融环境已经基本结束，至少目前来看没有恢复的迹象。而思科也再没能回到2000年时的巅峰状态。</p><p></p><p>当然，二者之间还有不少具体差异。思科虽然是当时毫无争议的市场领导者，但一直面临着激烈竞争。而目前的英伟达仍堪称天下无敌。只是这种无知状态能持续多久，是否足以支持截至上周那高达万亿美元的恐怖估值？</p><p></p><p>我还发现，思科的发展轨迹跟Gartner的技术成熟度曲线高度重合。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3e/3e4a7b8b1779e64566c5bf12feae9cd2.png\" /></p><p></p><p>请注意Gartner整理的生成式AI技术成熟度曲线。</p><p></p><p>这张图表发布于2022年7月，也就是ChatGPT掀起全球热潮之前。可以看到，Gartner认为生成式AI已经接近“预期峰值”。</p><p></p><p>英伟达要想让自己的市场估值继续增长，就必须想办法消弭以下五大风险。</p><p></p><p>加密货币挖矿收入已经永远无法恢复。这一点在估值中并未体现，但我认为极有可能发生。AI投资与加密货币投资一样属于金融泡沫。我认为这种可能性很低，但至少应该把这个因素计入估值结果。英伟达在AI硬件领域的主导地位遭到颠覆，被迫压缩现有毛利率。从长远来看，发生这种风险的可能性极大，毕竟这背后可是个万亿美元的问题。具体时间可能是在2025年、2030年，或者是2035年。今年年底或明年年初可能出现经济衰退，发生几率可能高达50%。摩尔定律再次陷入瓶颈，在突破之前进一步提升性能的成本会更高，毕竟硅材料的物理极限就摆在那里。在2020年成为唯一真神之前，我对英伟达一直相当看好。虽然如今的英伟达仍然遵循着自己的商业逻辑和经营规则，但我已经无法理解哪怕是最乐观情况下也高达50年的市盈率到底有什么依据。</p><p></p><p>所以作为行业中的一员，我会密切关注这场有趣的商业冲突，也迫不及待想看到接下来会发生什么。技术市场乃至整个世界一直瞬息万变，只有时间能够给出最终答案。</p><p></p><p>原文链接：</p><p></p><p><a href=\"https://seekingalpha.com/article/4609485-ai-nvidia-is-taking-all-the-money\">https://seekingalpha.com/article/4609485-ai-nvidia-is-taking-all-the-money</a>\"</p>",
    "publish_time": "2023-06-08 14:52:49",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "“百亿生态”下的“新农业”，拼多多发力商家生态全面提质",
    "url": "https://www.infoq.cn/article/bMbCBz7HGhUJvI35yHWT",
    "summary": "<p>5 月 26 日，拼多多集团发布了截至 3 月 31 日的 2023 年第一季度业绩。财报显示，拼多多集团一季度实现营收 376.4 亿元，同比增长 58.2%。在发布财报业绩的同时，拼多多还发布了继百亿补贴、百亿农研之后的第三个百亿项目——“百亿生态”，想要通过“百亿生态”项目提升平台商户的整体服务效率与品质。其中，农业商户一直以来都是拼多多平台商户的重要组成部分。财报显示，<a href=\"https://s.geekbang.org/search/c=0/k=%E6%8B%BC%E5%A4%9A%E5%A4%9A/t=\">拼多多</a>\"平台上的新农人数量已达 1600 万，相比 3 年前增加了 400 万。为什么继“百亿补贴”和“百亿农研”后，拼多多又推出了“百亿生态”？农业作为拼多多一直以来实现高质量发展的重要立足点，将在“百亿生态”项目背景下有怎样的发展？</p><p></p><h1>拆解拼多多“百亿生态”</h1><p></p><p></p><p>“百亿补贴”曾一度成为拼多多的“杀手锏”，长期高额补贴的策略让拼多多在竞争激烈的电商行业站稳了脚跟。从“百亿补贴”到“百亿农研”，拼多多在 2021-2022 年完成了对外形象从“重营销”到“重研发”的转变。据悉，“百亿农研”专项不以商业价值和盈利为目的，致力于推动农业科技进步。拼多多在 2022 年曾拿出将近三分之一的净利润用于技术研发，技术员工占比约 60%。</p><p></p><p>如果说“百亿补贴”让拼多多发展更快，“百亿农研”让拼多多发展质量更高，那么“百亿生态”或将让拼多多发展更稳。</p><p></p><p>据悉，拼多多“百亿生态”旨在对优质商户和商品进行资源倾斜，推动中小企业、优质商家实现有质量地增长，提升平台商户的整体服务效率与品质。据悉，拼多多内部已形成共识，全面拥抱高质量发展，希望将高质量发展落实到平台治理、商家生态、高质量供应链、高质量消费等方方面面。其中，商家生态是重要一环。</p><p></p><p>在这样的背景下，“百亿生态”将对商家做以下帮扶：</p><p>推出百亿规模帮扶资金，支持并帮扶优质商户、品牌及中小企业；通过流量等资源倾斜，激发需求侧的“数字化新消费”，辅助产业带商家建设“数字化新供给”；通过爆品打造、加“数”发展、拓展国际市场等举措，助力优质商户做大做强，推动中小企业、优质商家实现有质量的增长，提升平台商户的整体服务效率与品质。</p><p></p><p>拼多多希望通过“百亿生态”项目让高信用、合规经营的优质商家获得更多机会，从而带动平台商品及服务的品质提升。</p><p></p><h1>由量到质，“百亿生态”下的拼多多新农人</h1><p></p><p></p><p>“百亿补贴”和“百亿农研”在过往培育了大量新农人，为拼多多推出“百亿生态”打下了坚实的基础。成立至今，拼多多扎根各大产区和产业带，已培育了一批兼具供应链与电商运营实力的农业优质商家。拼多多 2023 年第一季度财报显示，目前平台上有 1600 万新农人，越来越多的商家正通过拼多多将产品销往全国乃至全球。这一数字的实现离不开“10 万名新农人培育计划”的实施和“百亿补贴”、“百亿农研”等系列助农活动的落地。</p><p></p><p>早在 2015 年 9 月成立之初，拼多多就提出“平台 + 新农人”的体系，通过新市场机制下合理的利益分配，引导受过高等教育、了解互联网的新型职业人才返乡创业，“百亿补贴”的重点也是农产品。公开信息显示，2020 年疫情期间，拼多多来自农（副）产品的成交额为 2700 亿元，规模同比翻倍，占全年成交额的 16.2%，高于行业 3% 左右的平均占比。至 2022 年“百亿补贴”3 周年，拼多多已经覆盖超过 4 万款农产品。</p><p></p><p>一些拼多多农业商家依托“拼单 + 产地直发”的模式逐渐建立价格优势，尝到规模效应带来的甜头。与此同时，拼多多“百亿补贴”宣布通过面向农产品、农副产品加码补贴，降低了供需两端的采销成本，链接全国数百个农业产业带，助力区域农产品发展成大产业。越来越多的新农人通过电商平台将农产品发送至全国各地。2022 年，全国农产品网络零售额突破 5000 亿元。拼多多也同平台上的新农人一样，得到了规模效应带来的效益提升。据悉，2022 年拼多多全年营收为 1306 亿元，同比增长 39%，净利润达到 315.3 亿元，同比猛增 306%。</p><p></p><p>“百亿农研”的两个主要方向“农产品流通”和“农产品种植”，也在 2022 年让田间地头的新农人感受到了科技的力量。从“农地云拼”到“农云行动”，拼多多先将分散的农业产能和分散的农产品需求在云端“拼”成一个农产品产销直联的大市场，再通过帮助农产品标准化、品牌化、数字化，进而让整个产业实现数字化。拼多多至今保持农产品零佣金的政策，农业商家的综合费用大概是其它平台的 1/3-1/2。因此，我们可以大胆猜测，农业商家作为拼多多平台商家的重要组成部分和“最强标签”，或将最先在“百亿生态”中受益。</p><p></p><h1>用技术创新提质提效，推动农业产业数字化升级</h1><p></p><p></p><p>与此同时，辅助产业带商家建设“数字化新供给”也是“百亿生态”中重要的一项举措。如何帮助商家实现数字化？技术创新走到田间地头是拼多多一直以来的愿景。据悉，拼多多在不断加强与高校的合作，落地“拼多多杯”科技小院大赛、多多农研科技大赛等赛事，推动行业数字化升级。</p><p></p><p>从 2020 年开始，拼多多联合中国农业大学连续举办了三届“多多农研科技大赛”，这项“人工智能 VS 顶尖农人”的数字农业种植竞赛，是拼多多在智慧农业方面的尝试与拓展。2022 年，拼多多“百亿农研”专项支持中国农业大学小麦研究中心培育出了系列突破性小麦新品种。2023 年 5 月 9 日，拼多多向中国农业大学捐赠 1 亿元人民币设立“拼多多 - 中国农业大学研究基金”，支持中国农业大学围绕国家重大战略需求，立足全球农业领域相关学科前沿，在基础研究和农业卡脖子技术攻关方面进行积极探索。</p><p></p><p>“重研发是拼多多的长期战略。前沿技术的研发与储备，对我们构建健康有活力的平台生态非常重要。通过精进技术，提升供需两端‘产消直连’的质量与效率，也将有助于整个行业进一步释放潜能。”拼多多集团董事长、联席首席执行官陈磊表示，“未来我们仍将坚定不移地继续重投研发。”</p><p></p><p>“我们将以实为本，持续加码供应链投入，为高质量发展寻找更强驱动力。我们还将继续重投实体供应链建设，稳链强链、补链延链，让更多工业、农业产业带跑出扎根本地的领头羊，带领当地产业走向全国乃至全球市场。”拼多多集团执行董事、联席首席执行官赵佳臻表示。</p><p></p><p>“百亿生态”与“百亿补贴”和“百亿农研”一脉相承，顺势而为。不仅仅是农业商户，“百亿生态”下，拼多多平台上所有高信用、高品质的都将迎来新的发展机会。</p>",
    "publish_time": "2023-06-08 16:58:29",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "资深开发者眼中的开源云原生数仓 ByConity",
    "url": "https://www.infoq.cn/article/ZWwcgX40forP2vyObp0V",
    "summary": "<p></p><blockquote>5月22日，字节跳动宣布开源 ByConity 云原生数据仓库，项目地址：https://github.com/ByConity/ByConity。ByConity 基于 ClickHouse 内核开发，采用计算存储分离的架构、主流的 OLAP 引擎和自研的表引擎，提供便捷的弹性扩缩容和极速的分析性能，覆盖实时分析和海量数据的离线分析，帮助企业更好地挖掘数据价值。</blockquote><p></p><p>文章专题推荐：<a href=\"https://www.infoq.cn/theme/193\">《开源云原生数仓ByConity技术与实践全解》</a>\"</p><p></p><p>ByConity 于 2022 年计划开源，2023 年 1 月发布 beta 0.1.0 版本，一些关注字节 ClickHouse 使用情况的的开发者在 ByConity 开源初期便进行了一些测试，如华为终端云、唯品会、展心展力、中电云、传音控股等团队。部分团队使用 ByConity 进行了 TPC-DS 测试，也有一些深度试用的团队采用生产数据和具体场景进行了测试。</p><p></p><p>在此期间，社区收到了很多团队对于 ByConity 性能的积极反馈，当然也有团队遇到了一些部署中的难题和阻碍，并为社区提供了许多非常不错的改进建议。在和社区用户交流的过程中我们发现，不同的团队可能会遇到一些相似的问题，也会基于各自的业务需求设计对应的解决方案。</p><p></p><p>今年5月 ByConity 正式开源发布 GA 0.1.0 版本，为了帮助更多关注者在早期更好地使用 ByConity，社区邀请了几位参与 ByConity 测试和试用的团队成员与 ByConity 资深研发工程师进行了一次交流，希望将社区的经验分享给遇到同样问题和正在考虑解决方法的团队。</p><p></p><p>参与此次交流的几位嘉宾为：</p><p>Kevin Fang，字节跳动 ByConity 资深研发工程师赵金涛，华为大数据研发工程师徐庆岳，中电云数据库内核技术专家程伟，MetaApp 大数据研发工程师</p><p></p><p>本文根据此次交流中的部分要点整理而成。</p><p></p><h3>Q1：各位在平时工作中会使用大数据的哪些技术和产品？是什么契机让你们接触到 ByConity？</h3><p></p><p></p><p>程伟：我们主要是做了一个 OLAP 日志分析平台，开始选的是 ClickHouse，中间存在一些问题。后来通过字节跳动 ClickHouse 技术沙龙了解到字节对 ClickHouse 进行了优化，输出到 ByConity 中，做了开源 ，我们就开始尝试。</p><p></p><p>徐庆岳：我们是在做定制云计算，自己也有一些数据库产品。在私有云的部分项目中遇到了一些问题，比如说有些产品数据量特别大，每天会有 2 个 PB 的数据进来，查询一般需要是秒级，响应要求也比较高。在产品中，除了查询需求，也有汇入的需求，比如单节点汇入需求要达到差不多 400 兆每秒，查询也要比较快。</p><p></p><p>按照我们自己目前的方法，汇入需求能达到，但查询的时候，甲方会希望“能不能再快一点？” 。当时我们基于自己开发团队的一些产品感觉有点吃力，就对其他产品做了一些了解，比如 ClickHouse、腾讯云和字节的产品，当然也有一些创业型公司的项目。当时得知 ByConity 开源了，我们想有更多了解，就邀请 ByConity 负责人进行了交流。沟通后发现有些技术方面确实值得借鉴，于是我们做了一些针对性测试，看看某些功能点上是不是可以使用。</p><p></p><p>赵金涛：我们内部也在广泛使用 ClickHouse，在使用过程中发现它存在一些架构上的短板，比如说扩缩容的成本很高，扩缩容的时候需要刷元数据、停 merge、停 mutate、搬迁数据等代价非常大，集群的资源难以根据负载灵活调整，存在浪费。这个时候看到包括 ClickHouse 公司在内，大数据领域有非常多的产品都在构建云原生能力。</p><p></p><p>我们认为云原生是大数据的必然趋势。也是这个时候，我们从网上得知字节把在 ClickHouse 领域多年的技术积累贡献出来，开源给社区了。基于这个契机，我们投入到社区里面来，希望借鉴 ByConity 的一些思想，把 ClickHouse 打造成一个高性能的云原生数据库。</p><p></p><h3>Q2：其实咱们碰到的很多的问题都是有共性的，例如在应用 ClickHouse 解决业务问题的时候，遇到扩缩容、性能方面的一些问题。那想问各位老师，大家觉得在解决这些问题的过程中有哪些难点，我们最需要攻克的关键技术点是什么？</h3><p></p><p></p><p>程伟：一是在计算方面，希望能够计算得快一些；再就是能够支持更多的数据源；另外是能够支持更庞大的数据量。</p><p></p><p>徐庆岳：通过对 ByConity 技术的了解，它应该是按 Snowflake 论文来走的，包括元数据、数据的存算分离以及分布式的 MPP。在扩缩容这一块，S3 或者 HDFS 确实是一个很高的提高。但是在计算方面，未来怎么能够感知每个查询所需的计算资源多少？比如一个查询需要一台机器，下一个查询可能需要 100 台机器，从计算方面如何弹性？这可能也是云计算本身存在的最大的一个理由，就是能够感知什么时候把计算资源根据租户来分配，或者根据不同的查询来分配。如果是根据租户，比如根据每个租户的节点拓扑走不同的查询，ByConity 应该是这种路线实现的。但是如果能够更智能地感知当前的查询需要多少个计算资源，那就更好了。</p><p></p><p>赵金涛：我认为在大数据多维分析领域有两点是需要平衡的，第一是性能，第二是灵活性，极高的性能必然会损失灵活性。比如像 ClickHouse，它的各节点是完全对等的，元数据和数据都分片保存在节点上，这种 ShareNothing 的架构结合 ClickHouse 强大的 MPP 计算能力和极致的细节优化使得 ClickHouse 性能非常快。如果我们想在保证 ClickHouse 性能的基础上，具备更高的灵活性，让它灵活扩缩容，这种诉求和 ClickHouse 原生架构存在冲突。所以基于 ClickHouse 的原生架构去发展很难实现类似弹性伸缩这样的灵活性。</p><p></p><p>那我们就需要对 ClickHouse 架构改造升级，需要在比较高的灵活性下，仍然能保证性能。在这个过程中，就存在技术挑战，比如需要将数据和节点的绑定解耦，需要实现节点的彻底无状态，元数据要从本地磁盘抽到统一的元数据中心，数据要从本地磁盘推到 HDFS 或者是 S3 等的这些对象存储上。对于大数据分析引擎来讲，这种架构升级涉及的细节非常多，牵一发而动全身，技术挑战也很大。而这种改造必然会带来性能的降低。这时我们要采取其他的一些技术手段，比如缓存等，来提升性能。</p><p></p><h3>Q3：在了解项目之后是如何上手的？是否遇到了一些障碍？体验如何？</h3><p></p><p></p><p>程伟：我们最初使用 ByConity，是基于社区提供的 TPC-DS 测试项目来上手的。社区有一个比较详细的教程介绍如何通过 Docker 来部署 ByConity。把 ByConity 部署以后，跑了 TPC-DS 数据。在教程中会涉及到一些不清楚的点，加上我们想修改一些配置，由于对这些配置的了解情况并不是很多，所以就没有达到需要的效果。目前经过跟社区进行沟通，已经解决了这些问题。我们现在已经将 ByConity 部署在 K8s 上，并且基于 ByConity 提供了日志分析服务。</p><p></p><p>我们团队对 ByConity 社区一个最大印象就是沟通的成本非常低，非常有效果，我们遇到一个问题的时候，在社区提出，很快就有社区的相关同学，以及社区中的一些其他爱好者来协助我们解决这些问题。</p><p></p><p>徐庆岳：我们团队也在 Docker 上对 ByConity 进行了部署和测试，主要是看对 SQL 兼容性。但由于项目原因我们更关注 ByConity 写入和读取的速度，更多关注技术细节，比如说跟 HDFS 打交道的时候做的一些优化细节，我们会从源码级角度去看。和社区接触的过程中，团队的响应很快。在测试中我们也给社区找出了一个 bug。</p><p></p><p>在使用中感觉 ByConity 的性能提升很多，比如查询性能。如果说把单个 libHDFS 上拿出来做对比的话，跟 ClickHouse 社区比可以达到百分之四五十的性能提升。后续我们还会再测一测优化函数性能提升如何。</p><p></p><p>赵金涛：ByConity 开源以后，我们首先跑了雏形，然后分析了 ByConity 的源码和基于 ClickHouse 的一些改进点。在此过程中，发现 ByConity 是想构建一个比较完善的云原生的数据库，对 ClickHouse 的各种功能角色解耦非常彻底。</p><p></p><p>我们也和社区一起共建，比如 MergeTree 支持对象存储，Hive 外表支持对象存储，Hive 外表的功能完善等等。在过程此中我们多次和社区一起讨论，一起把能力打磨成熟。近期我们在使用的时候发现某些场景下相比 ClickHouse 性能大幅劣化，也正在和社区一起去分析瓶颈，提升性能。</p><p></p><h3>Q4：后续团队希望将 ByConity 用于什么业务场景，有什么短期和长期的规划？</h3><p></p><p></p><p>程伟：现阶段我们主要将 ByConity 用在日志分析平台的搭建。我们使用了 ByConity 的一个 Map 类型来将日志保存起来。一般来说大家都会采用固定的一些字段来做。但我们用了 Map，是因为我们日志中不确定的字段太多，所以我们根据名字和类型，通过创建 3 个 Map 来将我们的日志保存起来。这样日志查询的时候只需要拿到日志的 schema，就可以根据 schema 对应的类型来拿到对应的日志。现在我们每天会打入几百万条数日志数据，目前表现还是非常不错的。</p><p></p><p>另外我们有一个 OLAP 的数据分析平台，会有 A/B 测试，数据指标分析等功能，现阶段是基于 ClickHouse 来做的，未来我们可能会用 ByConity 来进行尝试，替代 ClickHouse 来把这一部分的业务给推起来。</p><p></p><p>徐庆岳：云计算公司，像大家都知道的比如火山引擎、华为云都有自研的产品，但不可能每个产品都自研，也会使用开源项目。 ByConity 跟社区版的 ClickHouse 架构差异比较大，也会在某些场景下符合我们的一些需求，在选型的时候就会考虑使用 ByConity。同时我们也会考虑 ByConity 的团队怎么样，以及社区的活跃度。 社区如果不能继续推进的话，对于后续一些功能的使用就会有影响。</p><p></p><p>未来我们也会和社区和团队做交流，看我们有哪些合适的使用场景，有哪些技术点是双方可以一起来提升的，以及哪些是可以回馈社区的。因为大家都是技术爱好者，希望能够相互成就。</p><p></p><p>赵金涛：我们的首版本还在构建中，会用于多维分析场景。首先会借鉴 ByConity 构建一个比较完善的云原生的数据库，实现资源弹性伸缩。我们还会借鉴 ByConity 的架构，构建湖仓一体的能力，不仅仅能够用于分析场景，还能用于数仓的场景，比如说可以分析 Hive 外表、Iceberg、Hudi 等等。</p><p></p><p>首先我们会聚焦第一个场景，会和社区一起解决一些迫在眉睫的问题。比如查询性能，ByConity 热读的性能比较理想，但冷读的查询性能还有比较大的提升空间。所以这段时间我们会把精力放在提升 ByConity 的冷读性能上，我们正在分析冷读的情景，想方法让 ByConity 能够持平或者至少接近 ClickHouse 的原生版本。</p><p></p><p>我们还发现某些异常场景下偶现数据丢失等现象，我们会着重提升可靠性，确保运行稳定可靠。</p><p>性能和可靠性提升后我们会借鉴 ByConity 资源隔离以及云原生的能力，来构建一个比较完善的云原生数据库，能够实现集群的弹性伸缩，集群能够根据查询量的大小动态的去分配资源等等，这些是我们未来的目标。</p><p></p><h3>Q5：对 ByConity 技术路线的看法和诉求</h3><p></p><p></p><p>程伟：我们对 ByConity 目前的功能，包括未来想要做的云原生数仓的愿景，都非常看好。之后是否能够支持 ClickHouse 相关的一些数据迁移工作，或者说能够给出一些迁移 ClickHouse 的帮助？这样的话能够让 ByConity 可以更好地去应用起来。</p><p></p><p>再就是 ByConity 未来是否可以变成一个更通用的分布式计算引擎，可以对更多的数据源进行一些计算。</p><p>徐庆岳：这个问题还是比较大的，我觉得每个产品都有自己的场景，对于使用方来说可能主要是看产品的成熟度，如果做得好，甚至可以培养用户的习惯。不同的数据库产品大多使用方法不同，可能使用的 SQL 语句都不同，如果对产品不熟悉，更换产品的对于大多数人来说上手都比较困难。如果 ByConity 成熟之后，在很多场景下，性能和灵活性都兼具了，用户多了，也就慢慢培养了用户的习惯。</p><p></p><p>数据库的技术路线，我想做数据库的应该都知道，比如存算分离、读写分离等，但是如何把一个产品做成功，可能跟产品未来的发展、社区的发展相关。比如多云部署是否支持等。</p><p></p><p>赵金涛： ByConity 的 GA 版本已发布，我认为接下来首先要把 ByConity 的能力继续完善，补齐功能，增强冷读性能，提升可靠性，构建一个比较完善的云原生数据库。第二点是把 ByConity 强大的性能拓宽到其他领域，比如说能够把它用到数仓领域，在一定程度上或者在某些场景下能够替代 Spark，能够加速模型层的计算。</p><p></p><h3>Q6：在社区建设方面大家有什么看法</h3><p></p><p></p><p>程伟：作为资深用户，对社区的最大的诉求，一是能够有更详细的文档帮助用户快速上手，以及一些比较详细的配置文档，能够让我们对 ByConity 的一些参数进行调整，达到一个更好的状态。再就是与社区沟通中快速反馈的方式。另外就是社区进度的同步，是否有定期的活动。</p><p></p><p>Kevin：文档化建设是社区非常重要的一部分，后面会有两种类型的文档，一种是给用户看的，比如用户手册，另外一个是面向开发者，会有更多的技术细节。大家在看文档中遇到一些问题也欢迎随时提出。</p><p>关于问题反馈，我们最推荐的还是 GitHub 的 issue，大家都能看到，也能帮助遇到相同问题的人。</p><p></p><p>定期活动我们肯定是有的，比如我们每月都会举办的 webinar，就会有一个专题去讲这些内容。前面讲了 ByConity 的一些技术架构的点，后面会分享一些计划要做的内容。</p><p></p><p>徐庆岳：之后希望看到 ByConity 技术点和功能迭代更加完善，也希望看到一些好的实现方法。社区共建这块，我觉得可以针对运维同学做一些事情，比如做开设一些课程培训，并进行认证，可以加深对于产品的熟悉程度，也培养了更多的用户。</p><p></p><p>Kevin：这个角度特别好，目前我们面向的更多是开发人员，随着被用了更多之后，第一手接触的大部分是运维人员。对于这批人我们如何提供更友好的支持，比如教程、上手以及解决问题的通道。后续我们也可以一起商量，通过社区一起来做。</p><p></p><p>赵金涛：后续可以定期组织一些 meetup，邀请不同企业的开发人员来分享各自的实践。另外还可以组织一些代码解读的活动，解读 ByConity 的架构和关键技术，比如它的查询优化器、导入、集群管理等等，尤其一些关键流程是如何实现的，这样也能让更多的开发者参与进来繁荣社区。</p><p></p><h3>总结</h3><p></p><p></p><p>Kevin：非常欢迎大家参与社区共建，一起形成技术的输出。比如每个团队侧重做的模块不一样，可能对某个模块会有非常深的理解，这些我们是不是可以用文章的形式发布出来，汇总起来，放到社区中，让其他的开发者都能够从中受益。</p><p></p><p>最后希望大家在平时业务当中总结出来的，包括在自己业务上得到验证的一些经验方法，一方面能够回馈给社区，让有共性的这些业务场景能够去使用；另外一方面也希望业界的各位专家们一起加入 ByConity，把 ByConity 打造得更好。</p><p></p><h3>彩蛋</h3><p></p><p></p><p>此次访谈中还有一些精彩的技术沟通未在本文章展开，如：</p><p>在 Map 使用过程中的一些建议和处理方式ByConity 冷读和热读的查询性能差异数据湖在 ByConity 未来发展中的考虑与应用场景数据迁移工具的相关讨论如何使用云原生进行降本增效Keeper 高可用的探讨</p><p></p><p>本次访谈完整视频已上传 ByConity B站：<a href=\"https://www.bilibili.com/video/BV1AX4y187yW/?spm_id_from=333.999.0.0&amp;vd_source=71f3be2102fec1a0171b49a530cefad0\">开源云原生数仓 ByConity，社区共建让技术走得更远_哔哩哔哩_bilibili</a>\"</p><p></p><p>ByConity 是一个开放的社区，欢迎更多对云原生数据仓库感兴趣的小伙伴加入社区，一起交流，一起共建。</p><p></p><p>文章专题推荐：<a href=\"https://www.infoq.cn/theme/193\">《开源云原生数仓ByConity技术与实践全解》</a>\"</p>",
    "publish_time": "2023-06-08 17:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Apache Doris 冷热分层技术如何实现存储成本降低 70%？",
    "url": "https://www.infoq.cn/article/FfrIHAP52kMXTx0ly3TV",
    "summary": "<p>在数据分析的实际场景中，冷热数据往往面临着不同的查询频次及响应速度要求。例如在电商订单场景中，用户经常访问近 6 个月的订单，时间较久远的订单访问次数非常少；在行为分析场景中，需支持近期流量数据的高频查询且时效性要求高，但为了保证历史数据随时可查，往往要求数据保存周期更为久远；在日志分析场景中，历史数据的访问频次很低，但需长时间备份以保证后续的审计和回溯的工作...往往历史数据的应用价值会随着时间推移而降低，且需要应对的查询需求也会随之锐减。而随着历史数据的不断增多，如果我们将所有数据存储在本地，将造成大量的资源浪费。</p><p></p><p>为了解决满足以上问题，冷热数据分层技术应运而生，以更好满足企业降本增效的趋势。顾名思义，冷热分层是将冷热数据分别存储在成本不同的存储介质上，例如热数据存储在成本更高的 SSD 盘上、以提高时效数据的查询速度和响应能力，而冷数据则存储在相对低成本的 HDD 盘甚至更为廉价的对象存储上，以降低存储成本。我们还可以根据实际业务需求进行灵活的配置和调整，以满足不同场景的要求。</p><p></p><p>冷热分层一般适用于以下需求场景：</p><p></p><p><a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1536\">数据</a>\"存储周期长：面对历史数据的不断增加，存储成本也随之增加；冷热数据访问频率及性能要求不同：热数据访问频率高且需要快速响应，而冷数据访问频率低且响应速度要求不高；数据备份和恢复成本高：备份和恢复大量数据需要消耗大量的时间和资源。......</p><p></p><h2>更高存储效率的冷热分层技术</h2><p></p><p>自 Apache Doris 0.12 版本引入动态分区功能，开始支持对表分区进行生命周期管理，可以设置热<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1536\">数据</a>\"转冷时间以及存储介质标识，通过后台任务将热数据从 SSD 自动冷却到 HDD，以帮助用户较大程度地降低存储成本。用户可以在建表属性中配置参数 storage_cooldown_time 或者 dynamic_partition.hot_partition_num 来控制数据从 SSD 冷却到 HDD，当分区满足冷却条件时，Doris 会自动执行任务。而 HDD 上的数据是以多副本的方式存储的，并没有做到最大程度的成本节约，因此对于冷数据存储成本仍然有较大的优化空间。</p><p></p><p>为了帮助用户进一步降低存储成本，社区在已有功能上进行了优化，并在 Apache Doris 2.0 版本中推出了冷热 数据 分层的功能。冷热数据分层功能使 Apache Doris 可以将冷数据下沉到存储成本更加低廉的对象存储中，同时冷数据在对象存储上的保存方式也从多副本变为单副本，存储成本进一步降至原先的三分之一，同时也减少了因存储附加的计算资源成本和网络开销成本。</p><p></p><p>如下图所示，在 Apache Doris 2.0 版本中支持三级存储，分别是 SSD、HDD 和对象存储。用户可以配置使数据从 SSD 下沉到 HDD，并使用冷热分层功能将数据从 SSD 或者 HDD 下沉到对象存储中。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0b/0b942755c478c1d9a581ba1989933fd2.png\" /></p><p></p><p>以公有云价格为例，云磁盘的价格通常是对象存储的 5-10 倍，如果可以将 80% 的冷数据保存到对象存储中，存储成本至少可降低 70%。</p><p></p><p>我们使用以下公式计算节约的成本，设冷数据比率为 rate，对象存储价格为 OSS，云磁盘价格为 CloudDisk</p><p></p><p></p><p></p><p>这里我们假设用户有 100TB 的数据，我们按照不同比例将冷数据迁移到对象存储，来计算一下如果使用冷热分层之后，相较于全量使用普通云盘、SSD 云盘 可节约 多少 成本。</p><p></p><p>阿里云 OSS 标准存储成本是 120 元/ T /月阿里云普通云盘的价格是 300 元/ T /月阿里云 SSD 云盘的价格是 1000 元/ T /月</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/02/02d15af1245ef3a18e6acba7b8b25378.png\" /></p><p></p><p>例如在 80% 冷数据占比的情况下，剩余 20% 使用普通云盘每月仅花费 80T120 + 20T * 300 = 15600元，而全量使用普通云盘则需要花费 30000 元，通过冷热数据分层节省了 48% 的存储成本。如果用户使用的是 SSD 云盘，那么花费则会从全量使用需花费的 100000 元降低到 80T120 + 20T * 1000 = 29600元，存储成本最高降低超过 70%！</p><p></p><h2>使用指南</h2><p></p><p>若要使用 <a href=\"https://www.infoq.cn/article/YXq3zrAT5vx2zAcP3o1j\">Doris </a>\"的冷热分层功能，首先需要准备一个对象存储的 Bucket 并获取对应的 AK/SK。当准备就绪之后，下面为具体的使用步骤：</p><p></p><p>1.  创建 Resource</p><p></p><p>可以使用对象存储的 Bucket 以及 AK/SK 创建 Resource，目前支持 AWS、Azure、阿里云、华为云、腾讯云、百度云等多个云的对象存储。</p><p></p><p><code lang=\"text\">CREATE RESOURCE IF NOT EXISTS \"${resource_name}\"\n        PROPERTIES(\n            \"type\"=\"s3\",\n            \"s3.endpoint\" = \"${S3Endpoint}\",\n            \"s3.region\" = \"${S3Region}\",\n            \"s3.root.path\" = \"path/to/root\",\n            \"s3.access_key\" = \"${S3AK}\",\n            \"s3.secret_key\" = \"${S3SK}\",\n            \"s3.connection.maximum\" = \"50\",\n            \"s3.connection.request.timeout\" = \"3000\",\n            \"s3.connection.timeout\" = \"1000\",\n            \"s3.bucket\" = \"${S3BucketName}\"\n        );\n</code></p><p></p><p>2.  创建 Storage Policy</p><p></p><p>可以通过 Storage Policy 控制数据冷却时间，目前支持相对和绝对两种冷却时间的设置。</p><p></p><p><code lang=\"text\">CREATE STORAGE POLICY testPolicy\nPROPERTIES(\n  \"storage_resource\" = \"remote_s3\",\n  \"cooldown_ttl\" = \"1d\"\n);\n</code></p><p></p><p>例如上方代码中名为 testPolicy 的 storage policy 设置了新导入的数据将在一天后开始冷却，并且冷却后的冷数据会存放到 remote_s3 所表示的对象存储的 root path 下。除了设置 TTL 以外，在 Policy 中也支持设置冷却的时间点，可以直接设置为：</p><p></p><p><code lang=\"sql\">CREATE STORAGE POLICY testPolicyForTTlDatatime\nPROPERTIES(\n  \"storage_resource\" = \"remote_s3\",\n  \"cooldown_datetime\" = \"2023-06-07 21:00:00\"\n);\n</code></p><p></p><p>3.  给表或者分区设置 Storage Policy</p><p></p><p>在创建出对应的 Resource 和 Storage Policy 之后，我们可以在建表的时候对整张表设置 Cooldown Policy，也可以针对某个 Partition 设置 Cooldown Policy。这里以 TPCH 测试数据集中的 lineitem 表举例。如果需要将整张表都设置冷却的策略，则可以直接在整张表的 properties 中设置：</p><p></p><p><code lang=\"text\">CREATE TABLE IF NOT EXISTS lineitem1 (\n            L_ORDERKEY    INTEGER NOT NULL,\n            L_PARTKEY     INTEGER NOT NULL,\n            L_SUPPKEY     INTEGER NOT NULL,\n            L_LINENUMBER  INTEGER NOT NULL,\n            L_QUANTITY    DECIMAL(15,2) NOT NULL,\n            L_EXTENDEDPRICE  DECIMAL(15,2) NOT NULL,\n            L_DISCOUNT    DECIMAL(15,2) NOT NULL,\n            L_TAX         DECIMAL(15,2) NOT NULL,\n            L_RETURNFLAG  CHAR(1) NOT NULL,\n            L_LINESTATUS  CHAR(1) NOT NULL,\n            L_SHIPDATE    DATEV2 NOT NULL,\n            L_COMMITDATE  DATEV2 NOT NULL,\n            L_RECEIPTDATE DATEV2 NOT NULL,\n            L_SHIPINSTRUCT CHAR(25) NOT NULL,\n            L_SHIPMODE     CHAR(10) NOT NULL,\n            L_COMMENT      VARCHAR(44) NOT NULL\n            )\n            DUPLICATE KEY(L_ORDERKEY, L_PARTKEY, L_SUPPKEY, L_LINENUMBER)\n            PARTITION BY RANGE(`L_SHIPDATE`)\n            (\n                PARTITION `p202301` VALUES LESS THAN (\"2017-02-01\"),\n                PARTITION `p202302` VALUES LESS THAN (\"2017-03-01\")\n            )\n            DISTRIBUTED BY HASH(L_ORDERKEY) BUCKETS 3\n            PROPERTIES (\n            \"replication_num\" = \"3\",\n            \"storage_policy\" = \"${policy_name}\"\n            )\n</code></p><p></p><p>用户可以通过 show tablets 获得每个 Tablet 的信息，其中 CooldownReplicaId 不为 -1 并且 CooldownMetaId 不为空的 Tablet 说明使用了 Storage Policy。如下方代码，通过 show tablets 可以看到上面的 Table 的所有 Tablet 都设置了 CooldownReplicaId 和 CooldownMetaId，这说明整张表都是使用了 Storage Policy。</p><p></p><p><code lang=\"text\">               TabletId: 3674797\n              ReplicaId: 3674799\n              BackendId: 10162\n             SchemaHash: 513232100\n                Version: 1\n      LstSuccessVersion: 1\n       LstFailedVersion: -1\n          LstFailedTime: NULL\n          LocalDataSize: 0\n         RemoteDataSize: 0\n               RowCount: 0\n                  State: NORMAL\nLstConsistencyCheckTime: NULL\n           CheckVersion: -1\n           VersionCount: 1\n              QueryHits: 0\n               PathHash: 8030511811695924097\n                MetaUrl: http://172.16.0.16:6781/api/meta/header/3674797\n       CompactionStatus: http://172.16.0.16:6781/api/compaction/show?tablet_id=3674797\n      CooldownReplicaId: 3674799\n         CooldownMetaId: TUniqueId(hi:-8987737979209762207, lo:-2847426088899160152)\n</code></p><p></p><p>我们也可以对某个具体的 Partition 设置 Storage Policy，只需要在 Partition 的 Properties 中加上具体的 Policy Name 即可：</p><p></p><p><code lang=\"text\">CREATE TABLE IF NOT EXISTS lineitem1 (\n            L_ORDERKEY    INTEGER NOT NULL,\n            L_PARTKEY     INTEGER NOT NULL,\n            L_SUPPKEY     INTEGER NOT NULL,\n            L_LINENUMBER  INTEGER NOT NULL,\n            L_QUANTITY    DECIMAL(15,2) NOT NULL,\n            L_EXTENDEDPRICE  DECIMAL(15,2) NOT NULL,\n            L_DISCOUNT    DECIMAL(15,2) NOT NULL,\n            L_TAX         DECIMAL(15,2) NOT NULL,\n            L_RETURNFLAG  CHAR(1) NOT NULL,\n            L_LINESTATUS  CHAR(1) NOT NULL,\n            L_SHIPDATE    DATEV2 NOT NULL,\n            L_COMMITDATE  DATEV2 NOT NULL,\n            L_RECEIPTDATE DATEV2 NOT NULL,\n            L_SHIPINSTRUCT CHAR(25) NOT NULL,\n            L_SHIPMODE     CHAR(10) NOT NULL,\n            L_COMMENT      VARCHAR(44) NOT NULL\n            )\n            DUPLICATE KEY(L_ORDERKEY, L_PARTKEY, L_SUPPKEY, L_LINENUMBER)\n            PARTITION BY RANGE(`L_SHIPDATE`)\n            (\n                PARTITION `p202301` VALUES LESS THAN (\"2017-02-01\") (\"storage_policy\" = \"${policy_name}\"),\n                PARTITION `p202302` VALUES LESS THAN (\"2017-03-01\")\n            )\n            DISTRIBUTED BY HASH(L_ORDERKEY) BUCKETS 3\n            PROPERTIES (\n            \"replication_num\" = \"3\"\n            )\n</code></p><p></p><p>这张 Lineitem1 设置了两个分区，每个分区 3 个 Bucket，另外副本数设置为 3，可以计算出一共有 23 = 6 个 Tablet，那么副本数一共是 63 = 18 个 Replica，通过 show tablets 命令可以查看到所有的 Tablet 以及 Replica 的信息，可以看到只有部分 Tablet 的 Replica 是设置了CooldownReplicaId 和 CooldownMetaId 。用户可以通过 ADMIN SHOW REPLICA STATUS FROM TABLE PARTITION(PARTITION)`` 查看 Partition 下的 Tablet 以及Replica，通过对比可以发现其中只有属于 p202301 这个 Partition 的 Tablet 的 Replica 设置了CooldownReplicaId 和 CooldownMetaId，而属于 p202302 这个 Partition 下的数据没有设置，所以依旧会全部存放到本地磁盘。 以上表的 Tablet 3691990 为例，该 Tablet 属于 p202301，截取 show tablets 拿到的部分关键信息如下：</p><p></p><p><code lang=\"text\">*****************************************************************\n               TabletId: 3691990\n              ReplicaId: 3691991\n      CooldownReplicaId: 3691993\n         CooldownMetaId: TUniqueId(hi:-7401335798601697108, lo:3253711199097733258)\n*****************************************************************\n               TabletId: 3691990\n              ReplicaId: 3691992\n      CooldownReplicaId: 3691993\n         CooldownMetaId: TUniqueId(hi:-7401335798601697108, lo:3253711199097733258)\n*****************************************************************\n               TabletId: 3691990\n              ReplicaId: 3691993\n      CooldownReplicaId: 3691993\n         CooldownMetaId: TUniqueId(hi:-7401335798601697108, lo:3253711199097733258)\n</code></p><p></p><p>可以观察到 3691990 的 3 个副本都选择了 3691993 副本作为 CooldownReplica，在用户指定的 Resource 上也只会保存这个副本的数据。</p><p></p><p>4.  查看数据信息</p><p></p><p>我们可以按照上述 3 中的 Linetem1 来演示如何查看是使用冷热数据分层策略的 Table 的数据信息，一般可以通过 show tablets from lineitem1 直接查看这张表的 Tablet 信息。Tablet 信息中区分了 LocalDataSize 和 RemoteDataSize，前者表示存储在本地的数据，后者表示已经冷却并移动到对象存储上的数据。具体信息可见下方代码：</p><p></p><p>下方为数据刚导入到 BE 时的数据信息，可以看到数据还全部存储在本地。</p><p></p><p><code lang=\"text\">*************************** 1. row ***************************\n               TabletId: 2749703\n              ReplicaId: 2749704\n              BackendId: 10090\n             SchemaHash: 1159194262\n                Version: 3\n      LstSuccessVersion: 3\n       LstFailedVersion: -1\n          LstFailedTime: NULL\n          LocalDataSize: 73001235\n         RemoteDataSize: 0\n               RowCount: 1996567\n                  State: NORMAL\nLstConsistencyCheckTime: NULL\n           CheckVersion: -1\n           VersionCount: 3\n              QueryHits: 0\n               PathHash: -8567514893400420464\n                MetaUrl: http://172.16.0.8:6781/api/meta/header/2749703\n       CompactionStatus: http://172.16.0.8:6781/api/compaction/show?tablet_id=2749703\n      CooldownReplicaId: 2749704\n         CooldownMetaId:\n</code></p><p></p><p>当数据到达冷却时间后，再次进行 show tablets from table 可以看到对应的数据变化。</p><p></p><p><code lang=\"text\">*************************** 1. row ***************************\n               TabletId: 2749703\n              ReplicaId: 2749704\n              BackendId: 10090\n             SchemaHash: 1159194262\n                Version: 3\n      LstSuccessVersion: 3\n       LstFailedVersion: -1\n          LstFailedTime: NULL\n          LocalDataSize: 0\n         RemoteDataSize: 73001235\n               RowCount: 1996567\n                  State: NORMAL\nLstConsistencyCheckTime: NULL\n           CheckVersion: -1\n           VersionCount: 3\n              QueryHits: 0\n               PathHash: -8567514893400420464\n                MetaUrl: http://172.16.0.8:6781/api/meta/header/2749703\n       CompactionStatus: http://172.16.0.8:6781/api/compaction/show?tablet_id=2749703\n      CooldownReplicaId: 2749704\n         CooldownMetaId: TUniqueId(hi:-8697097432131255833, lo:9213158865768502666)\n</code></p><p></p><p>除了通过上述命令查看数据信息之外，我们也可以在对象存储上查看冷数据的信息。以腾讯云为例，可以在 Policy 指定的 Bucket 的 Path 下可以查看冷却过后的数据的信息：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/97/971ed4a58c719bcf7a52623a4519beec.png\" /></p><p></p><p>进入对应文件后可以看到数据和元数据文件</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0d/0d7483a1d4b5e718240f97f55faa35c2.png\" /></p><p></p><p>我们可以看到在对象存储上数据是单副本。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1e/1e817735af4e796e8c7e78b0f55c5167.png\" /></p><p></p><p>5.  查询</p><p></p><p>假设 Table Lineitem1 中的所有数据都已经冷却并且上传到对象存储中，如果用户在 Lineitem1 上进行对应的查询，Doris 会根据对应 Partition 使用的 Policy 信息找到对应的 Bucket 的 Root Path，并根据不同 Tablet 下的 Rowset 信息下载查询所需的数据到本地进行运算。</p><p></p><p>Doris 2.0 在查询上进行了优化，冷数据第一次查询会进行完整的 S3 网络 IO，并将 Remote Rowset 的数据下载到本地后，存放到对应的 Cache 之中，后续的查询将自动命中 Cache，以此来保证查询效率。(性能对比可见后文评测部分）。</p><p></p><p>6.  冷却后继续导入数据</p><p></p><p>在某些场景下，用户需要对历史数据进行数据的修正或补充数据，而新数据会按照分区列信息导入到对应的 Partition中。在 Doris 中，每次数据导入都会产生一个新的 Rowset，以保证冷数据的 Rowset 在不会影响新导入数据的 Rowset 的前提下，满足冷热数据同时存储的需求。Doris 2.0 的冷热分层粒度是基于 Rowset 的，当到达冷却时间时会将当前满足条件的 Rowset 全部上传到 S3 上并删除本地数据，之后新导入的数据生成的新 Rowset 会在到达冷却时间后也上传到 S3。</p><p></p><h2>查询性能测试</h2><p></p><p>为了测试使用冷热分层功能之后，查询对象存储中的数据是否占用会较大网络 I/O，从而影响查询性能，因此我们以 SSB SF100 标准集为例，对冷热分层表和非冷热分层表进行了查询耗时的对比测试。</p><p></p><p>配置：均在 3 台 16C 64G 的机器上部署 1FE、3BE 的集群</p><p></p><p>暂时无法在飞书文档外展示此内容</p><p></p><p>如上图所示，在充分预热之后(数据已经缓存在 Cache 中)，冷热分层表共耗时 5.799s，非冷热分层表共耗时 5.822s，由此可知，使用冷热分层查询表和非冷热分层表的查询性能几乎相同。这表明，使用 Doris 2.0 提供的冷热分层功能，不会对查询性能造成的影响。</p><p></p><h2>冷热分层技术的具体实现</h2><p></p><p></p><h3>存储方式的优化</h3><p></p><p>在 Doris 之前的版本中，数据从 SSD 冷却到 HDD 后，为了保证数据的高可用和可靠性，通常会将一个 Tablet 存储多份副本在不同 BE 上，为了进一步降低成本，我们在 Apache Doris 2.0 版本引入了对象存储，推出了冷热分层功能。由于对象存储本身具有高可靠高可用性，冷数据在对象存储上只需要一份即可，元数据以及热数据仍然保存在 BE，我们称之为本地副本，本地副本同步冷数据的元数据，这样就可以实现多个本地副本共用一份冷却数据的目的，有效避免冷数据占用过多的存储空间，从而降低数据存储成本。</p><p></p><p>具体而言，Doris 的 FE 会从 Tablet 的所有可用本地副本中选择一个本地副本作为上传数据的 Leader，并通过 Doris 的周期汇报机制同步 Leader 的信息给其它本地副本。在 Leader 上传冷却数据时，也会将冷却数据的元数据上传到对象存储，以便其他副本同步元数据。因此，任何本地副本都可以提供查询所需的数据，同时也保证了数据的高可用性和可靠性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a84bea3de4d399e1c8bad3722a5ae930.png\" /></p><p></p><h3>冷数据 Compaction</h3><p></p><p>在一些场景下会有大量修补数据的需求，在大量补数据的场景下往往需要删除历史数据，删除可以通过 delete where实现，Doris 在 Compaction 时会对符合删除条件的数据做物理删除。基于这些场景，冷热分层也必须实现对冷数据进行 Compaction，因此在 Doris 2.0 版本中我们支持了对冷却到对象存储的冷数据进行 Compaction（ColdDataCompaction）的能力，用户可以通过冷数据 Compaction，将分散的冷数据重新组织并压缩成更紧凑的格式，从而减少存储空间的占用，提高存储效率。</p><p></p><p>Doris 对于本地副本是各自进行 Compaction，在后续版本中会优化为单副本进行 Compaction。由于冷数据只有一份，因此天然的单副本做 Compaction 是最优秀方案，同时也会简化处理数据冲突的操作。BE 后台线程会定期从冷却的 Tablet 按照一定规则选出 N 个 Tablet 发起 ColdDataCompaction。与数据冷却流程类似，只有 CooldownReplica 能执行该 Tablet 的 ColdDataCompaction。Compaction下刷数据时每积累一定大小（默认5MB）的数据，就会上传一个 Part 到对象，而不会占用大量本地存储空间。Compaction 完成后，CooldownReplica 将冷却数据的元数据更新到对象存储，其他 Replica 只需从对象存储同步元数据，从而大量减少对象存储的 IO 和节点自身的 CPU 开销。</p><p></p><h3>冷数据 Cache</h3><p></p><p>冷数据 Cache 在数据查询中具有重要的作用。冷数据通常是数据量较大、使用频率较低的数据，如果每次查询都需要从对象中读取，会导致查询效率低下。通过冷数据 Cache 技术，可以将冷数据缓存在本地磁盘中，提高数据读取速度，从而提高查询效率。而 Cache 的粒度大小直接影响 Cache 的效率，比较大的粒度会导致 Cache 空间以及带宽的浪费，过小粒度的 Cache 会导致对象存储 IO 效率低下，Apache Doris 采用了以 Block 为粒度的 Cache 实现。</p><p></p><p>如前文所述，Apache Doris 的冷热分层会将冷数据上传到对象存储上，上传成功后本地的数据将会被删除。因此，后续涉及到冷数据的查询均需要对对象存储发起 IO 。为了优化性能，Apache Doris 实现了基于了 Block 粒度的 Cache 功能，当远程数据被访问时会先将数据按照 Block 的粒度下载到本地的 Block Cache 中存储，且 Block Cache 中的数据访问性能和非冷热分层表的数据性能一致（可见后文查询性能测试）。</p><p></p><p>具体来讲，前文提到 Doris 的冷热分层是在 Rowset 级别进行的，当某个 Rowset 在冷却后其所有的数据都会上传到对象存储上。而 Doris 在进行查询的时候会读取涉及到的 Tablet 的 Rowset 进行数据聚合和运算，当读取到冷却的 Rowset 时，会把查询需要的冷数据下载到本地 Block Cache 之中。基于性能考量，Doris 的 Cache 按照 Block 对数据进行划分。Block Cache 本身采用的是简单的 LRU 策略，可以保证越是使用程度较高数据越能在 Block Cache 中存放的久。</p><p></p><h2>结束语</h2><p></p><p>Apache Doris 2.0 版本实现了基于对象存储的冷热数据分层，该功能可以帮助我们有效降低存储成本、提高存储效率，并提高数据查询和处理效率。未来，Apache Doris 将会基于冷热数据分层以及弹性计算节点，为用户提供更好的资源弹性、更低的使用成本以及更灵活的负载隔离服务。</p><p></p><p>在前段时间推出的 <a href=\"https://github.com/apache/doris/releases/tag/2.0.0-alpha1\">Apache Doris 2.0 Alpha 版本</a>\"中，已经实现了<a href=\"http://mp.weixin.qq.com/s?__biz=Mzg3Njc2NDAwOA==&amp;mid=2247516978&amp;idx=1&amp;sn=eb3f1f74eedd2306ca0180b8076fe773&amp;chksm=cf2f8d35f85804238fd680c18b7ab2bc4c53d62adfa271cb31811bd6139404cc8d2222b9d561&amp;scene=21#wechat_redirect\">单节点数万 QPS 的高并发点查询能力</a>\"、<a href=\"http://mp.weixin.qq.com/s?__biz=Mzg3Njc2NDAwOA==&amp;mid=2247519079&amp;idx=1&amp;sn=a232a72695ff93eea0ffe79635936dcb&amp;chksm=cf2f8560f8580c768bbde99ef8ca97d3a42ecc03b5d8d106b85f5474c90b6068781a79b3611e&amp;scene=21#wechat_redirect\">高性能的倒排索引</a>\"、<a href=\"http://mp.weixin.qq.com/s?__biz=Mzg3Njc2NDAwOA==&amp;mid=2247520488&amp;idx=1&amp;sn=bba80bdbf939e7ab63bf08379eabf99b&amp;chksm=cf2f9eeff85817f9e8e93e7fc886993f1c81e8415ec3133a8dd8eeb6f3ce119b7fda101c498a&amp;scene=21#wechat_redirect\">高效稳定的内存管理</a>\"、基于代价模型的全新查询优化器以及 Pipeline 执行引擎等，欢迎大家下载体验。与此同时， Apache Doris 2.0 Beta 版本也将于近两周上线。除了已知功能外，还会进一步支持 Unique 模型上的部分列更新，并将 Pipeline 执行引擎、查询优化器、主键模型 Merge-on-Write 等最新特性作为稳定功能默认开启，并包含了社区近期对性能方面的诸多优化，详细性能测试结果敬请期待后续社区动态。</p><p></p><p>为了让用户可以体验社区开发的最新特性，同时保证最新功能可以收获到更广范围的使用反馈，我们建立了 2.0 版本的专项支持群，<a href=\"https://wenjuan.feishu.cn/m?t=sF2FZOL1KXKi-m73g\">请大家填写申请</a>\"，欢迎广大社区用户在使用最新版本过程中多多反馈使用意见，帮助 Apache Doris 持续改进。</p><p></p><p>作者介绍：</p><p>杨勇强，SelectDB 联合创始人、技术副总裁</p><p>岳靖、程宇轩，SelectDB 存储层研发工程师</p>",
    "publish_time": "2023-06-08 17:30:05",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Metrics监控方案的思考和实操（面向微服务组件）",
    "url": "https://www.infoq.cn/article/UepHIPhJaXMUK9hBypiC",
    "summary": "<p></p><h2>背景介绍</h2><p></p><p></p><h3>1. 现状</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c3/c3d8b04504ccf9402e066c1a17ee37f8.png\" /></p><p></p><p>众所周知，业界各种大中型软件系统在生产运行时，总会有一些手段来进行保驾护航。如上图所示，Metric机制作为一个非常重要的监控手段，与日志系统，告警系统，APM等，共同守护业务系统运行安全。没有“运行时监控机制”的软件系统都是不合格的系统，是根本没有资格上到生产环境上去的，因为掌握不了软件系统的运行状况，就像一个瞎子开着汽车上路了，是极其危险的。Metric机制承担着收集软件系统各种监控指标的职责，提供的各个监控指标能够帮助运维人员进行系统运行状态的研判，配合告警系统及时进行预警，在出现异常情况的时候，给日志分析团队指明“问题查找”的方向。总之，Metric的重要程度非常高，可以认为是不可或缺的非功能性需求。</p><p></p><h3>2. 痛点</h3><p></p><p></p><p>在日常的软件项目开发测试过程中，由于监控设施不完备所带来的问题非常的明显，特别是在对组件进行“性能测试”的时候尤为突出，导致在性能测试过程中，需要查看的性能指标如TPS，Latency，并发，吞吐等一些关键指标根本无从读取，特别是遇到“性能瓶颈”的时候，根本不知道去进行问题定位和性能优化的方向是什么，慌乱之下迫于压力就开始病急乱投医，时常舍本逐末，采用一些野路子(如手工日志打点，借助其他的性能分析工具，人肉统计等)来临时救场，最后的结果就是事倍功半，解决问题不在点上，吃力不讨好。</p><p></p><p>另外一个问题就是有些组件有配置一些对应的监控指标，但是风格格式，展示方式都不尽相同，无法针对组件特点进行合理的统一化GUI展示；不统一的结果就是“各自为政”，五花八门，抓不住关注的重点。如果我们的Metrics机制是完备的，开发和测试过程中很多的问题都可以轻松应对，各种推诿扯皮都可以迎刃而解，工作起来就自然轻松。</p><p></p><h3>3. 原因分析</h3><p></p><p></p><p>细节是魔鬼。以上问题的根源，在于很多的软件研发团队在“最后一公里”没有准备好，尽管我们在系统架构层面都一些Solution,但是落实的情况不理想，没有构建起来一个完善可控的监控系统。但是又是什么原因导致了我们做不好这件事情呢？不外乎下面的几个原因</p><p></p><p>涉及的技术栈比较长，有一定的学习成本。以目前采用的Micrometer + Prometheus + Grafana的监控方案为例，一套完整的监控系统涉及到规划，埋点，采集，传输，存储，展示等各个环节，需要对整个方案有全局性的理解，特别是对Prometheus的一些基本的“时序运算函数”需要有正确的理解，才能够实现对展示指标的灵活定制和自主可控。同时需要能够正确对各个开源软件进行操作和配置，确实存在一定的学习成本。相关依赖太重目前DevOps的体制下，想去构建一套能够RUN起来的监控系统，是一件复杂的事情，需要找很多的相关team的同事去申请资源，开通各种账号和访问权限，在各种系统上提交不同的ticket，各种各样的协调和沟通在所难免，总之需要依赖很多的其他资源，通常的情况下就是事情还没走完一半，热情已经被浇灭了一半，除非被KPI考核，否则很难有继续推动下去的动力。人的惰性人都是有惰性的，当能够从别的地方Copy &amp; Paste过来一个Metrics面板，能够临时应付，基本就不会去深入研究其中的一些细节了。比方面板中用到了哪些PromSql表达式，各种函数的意义是什么，如何基于该面板进行客制化。久而久之，就停留在这个浅尝则止的初级层面了，丧失了去深入学习的能力了。</p><p></p><h2>目的和范围</h2><p></p><p></p><h3>1. 目的</h3><p></p><p></p><p>本文的目的是“系统性”阐述构建一个可用的metrics监控系统所需要掌握的完整的理论知识，方法，基础工具软件的配置和使用，一起搞懂一些常用的PromSql函数的含义和正确打开的方式。在掌握了这些基本的知识技能之后，按照文末的实操步骤，任何人都可以在自己的工作电脑上花费不超过15分钟的时间将一个完整可以用，并且满足主流微服务组件核心指标监控的Dashboard给运行起来，并且进行GUI展示和测试。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/05/054ab799cdf516d629ab45b141fab6e4.png\" /></p><p></p><p></p><p>本文的终极目标是希望能够和大家一起对metrics方案的构建进行一次比较系统性的梳理和回顾，从理论到实践，帮助大家扫清一些技术和流程方面的障碍，希望能够起到抛砖引玉的作用。希望读完此文后，大家能够在构建metrics系统的时候不再嫌麻烦，怕困难，能够做到了然于胸，理解原理，懂得实操，心情舒畅。本文没有介绍任何的高深知识，所有的资料来源都可以在互联网上找到，基于这些基础的材料，本文叙述尽力做到通俗易懂，目的明确，条理清晰，逻辑严谨，铺陈有序，干货满满。</p><p></p><h3>2. 范围和限制</h3><p></p><p></p><p>本文聚焦于微服务的Metrics方案，重点关注的是基于HTTP的请求和回应建立的指标监控系统，我们把这些核心监控指标统称为“通用的Metrics”。以下的资源对象的监控不是本文描述的重点，因为这些监控基本都可以通过三方的exporter来构建。</p><p></p><p>Database缓存（Redis）MQ (Kafka)FilesystemVMKubernetes runtime</p><p></p><h2>理论和方法</h2><p></p><p></p><h3>1. 微服务的特点</h3><p></p><p>本文前面部分非常地小心进行铺垫，就是想尽量圈小想涉及的知识范围，控制冲动，因为一旦有了想将所有细节囊括其中的想法，注定了难逃烂尾的结局，最终会变成一堆裹脚布。</p><p></p><p>所以，我们只以“微服务组件”为切入点，看看如何基于微服务的特点去构建合理的Metrics监控系统。从监控的角度来看，微服务有以下的几个显著的特点：</p><p></p><p>大部分基于HTTP协议：采集指标基于HTTP协议特点进行埋点实例是可以扩展的：采集的监控指标数据可以基于多实例进行聚合运算每个采集指标都可以设置对应的label信息：采集指标可以基于Label进行过滤</p><p></p><h3>2. 监控原则</h3><p></p><p>一般来讲，作为监控软件厂商，如Prometheus,它是会鼓励你监控所有东西的，指标越多越好。生态链位决定立场，可以理解。但是我们作为商业软件开发团队，监控系统是“基础设施”，是“非功能性”需求，目的是为了解决问题，不要只朝着大而全去做，尤其是不必要的指标采集，浪费人力和存储资源（除非有商业上的合理性）。</p><p></p><p>对于监控系统的建设，可以遵循如下的几个原则：</p><p></p><p>只关注重要的Metrics指标（大板展示）需要处理的告警才发出来，发出来的告警必须得到处理尽量做得简单和高可用，业务系统都挂了，监控也不能挂</p><p></p><p>本文重点对第一个原则进行论述，其他的不展开。那么，一个基于微服务的系统，需要监控哪些指标是合理的呢？目前业务普遍采用的方法是遵循Google的“黄金四信号”（Four Golden Signals）方法来定制业务系统的监控面板。</p><p></p><h3>3. Four Golden Signals</h3><p></p><p>Four Golden Signals是Google在“SRE Handbook”中提出的一个理论，建议业务团队在构建监控系统的时候有限关注“四个黄金信号”：延迟、流量、错误数、饱和度。Four Golden Signals是Google针对大量分布式监控的经验总结，4个黄金指标可以在服务级别帮助衡量终端用户体验、服务中断、业务影响等层面的问题。</p><p>延迟：服务请求所需时间。记录用户所有请求所需的时间，重点是要区分成功请求的延迟时间和失败请求的延迟时间。 例如在数据库或者其他关键端服务异常触发HTTP 500的情况下，用户也可能会很快得到请求失败的响应内容，如果不加区分计算这些请求的延迟，可能导致计算结果与实际结果产生巨大的差异。除此以外，在微服务中通常提倡“快速失败”，开发人员需要特别注意这些延迟较大的错误，因为这些缓慢的错误会明显影响系统的性能，因此追踪这些错误的延迟也是非常重要的。流量：监控当前系统的通信流量，用于衡量服务的容量需求。流量对于不同类型的系统而言可能代表不同的含义。例如，在HTTP REST API中，流量通常是每秒HTTP请求数；错误：监控当前系统所有发生的错误请求，衡量当前系统错误发生的速率。对于失败而言有些是显式的(比如，HTTP 500错误)，而有些是隐式(比如，HTTP响应200，但实际业务流程依然是失败的)。对于一些显式的错误如HTTP 500可以通过在负载均衡器(如Nginx)上进行捕获，而对于一些系统内部的异常，则可能需要直接从服务中添加钩子统计并进行获取。饱和度：衡量当前服务的饱和度。主要强调最能影响服务状态的受限制的资源。 例如，如果系统主要受内存影响，那就主要关注系统的内存状态，如果系统主要受限与磁盘I/O，那就主要观测磁盘I/O的状态。因为通常情况下，当这些资源达到饱和后，服务的性能会明显下降。同时还可以利用饱和度对系统做出预测，比如，“磁盘是否可能在4个小时候就满了”。</p><p></p><h3>4. Metrics监控方案</h3><p></p><p></p><h4>1) 实现原理</h4><p></p><p></p><p>一个完整的监控系统，一般需要涵盖如下几个环节的建设：指标规划，埋点采集，爬取和传输，存储，计算，展示等。监控系统稳定运行之后，同时可以基于监控数据构建告警系统，也可在系统出现问题的时候第一时间为问题排查团队提供解决问题的方向。</p><p></p><p>我们采用业界主流的 **Prometheus + Grafana **为基础框架来构建自己的监控系统。核心架构如下图所示:</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/86/86c20956fbf3a7bc6171d0319e5807ef.png\" /></p><p></p><p>因为我们的微服务一般是采用的Springboot2.0以上的版本进行开发的，这个版本以上的Springboot已经将Prometheus的监控指标的“埋点和采集”等功能都无缝集成到了starter中了，所以开发人员几乎可以做到“**不写一行代码（零编码）”**就将一套满足业务需求的监控系统给构建起来，非常方便，这个在后面的实操部分也有介绍的。所以如果你了解到了这些，就会发现其实我们搭建Metrics系统也不是很复杂的事情。如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b6/b64c4481655a5ab3d721b6437d911994.png\" /></p><p></p><p>Springboot项目中只需要将下面的两个maven依赖包引入到项目中，不需要写一行代码，就可以轻松实现和Prometheus的无缝集成。</p><p></p><p>micrometer-registry-prometheus负责自动产生符合Prometheus metrics格式的所有指标样本。这些指标样本的设计都很巧妙，基本可以满足大部分的HTTP协议业务请求的监控功能。默认方式下会缓存在本地。spring-boot-starter-actuator负责暴露一个endpoint给到Prometheus，Prometheus会启动一个Job线程，定期到这个endpoint将metrics数据爬取回来进行处理。</p><p></p><p>可以看到，micrometer-registry-prometheus其实已经帮我们把采集指标规划，埋点的工作做完了，spring-boot-starter-actuator通过和Prometheus爬取Job的配合，将数据的传输，和存储，计算工作也完成了，最后，Grafana完成了数据的展示工作。其实整个过程，代码开发量约等于0。只需要进行几行简单的配置即可。</p><p></p><p>这里需要重点关注的是micrometer-registry-prometheus为我们自动生成的HTTP的metrics指标数据，整个设计非常巧妙，这块在后面的章节会单独介绍。这些设计精巧的监控指标将作为数据样本被Prometheus采集到，然后进行一些内部函数的运算及一些聚合操作处理，最终就产出了满足我们需求的各种监控面板。</p><p></p><p>具体的实现原理，我们继续往下看。</p><p></p><h4>2) 样本格式</h4><p></p><p>Prometheus Server运行起来之后，自动拉起配置好的Job任务，去到指定的endpoint去pull数据，这些被爬取到的数据统称为“样本”。样本由以下三部分组成：</p><p></p><p>指标(metric)：metric name和描述当前样本特征的labelsets;时间戳(timestamp)：一个精确到毫秒的时间戳;值(value)：表示该时间的样本的值。</p><p></p><p><code lang=\"text\">&lt;--------------- metric ---------------------&gt;&lt;-timestamp -&gt;&lt;-value-&gt;\nhttp_request_total{status=\"200\", method=\"GET\"}@1434417560938 =&gt; 94355\nhttp_request_total{status=\"200\", method=\"GET\"}@1434417561287 =&gt; 94334\nhttp_request_total{status=\"404\", method=\"GET\"}@1434417560938 =&gt; 38473\nhttp_request_total{status=\"404\", method=\"GET\"}@1434417561287 =&gt; 38544\nhttp_request_total{status=\"200\", method=\"POST\"}@1434417560938 =&gt; 4748\nhttp_request_total{status=\"200\", method=\"POST\"}@1434417561287 =&gt; 4785\n</code></p><p></p><h4>3) 指标类型</h4><p></p><p></p><p>Prometheus根据目标功能和内容的不同，把指标分了4种类型(metric type)：Counter（计数器）、Gauge（仪表盘）、Histogram（累积直方图）、Summary（摘要）；但是本质上都是指标，都是时间序列，只是进行了简单的分类，更方便理解和沟通。可以通过“聚合操作”和“内置函数”对采集到的指标数据进行操作。</p><p></p><p>Counter：只增不减的计数器Counter类型的指标其工作方式和计数器一样，只增不减（除非系统发生重置）。常见的监控指标，如http_requests_total，node_cpu都是Counter类型的监控指标。Counter是一个简单但有强大的工具，例如我们可以在应用程序中记录某些事件发生的次数，通过以时序的形式存储这些数据，我们可以轻松的了解该事件产生速率的变化。PromSql内置的聚合函数可以用户对这些数据进行进一步的分析。</p><p><img src=\"https://static001.geekbang.org/infoq/d0/d0dfa646b74d4554ef30ad8e513f7364.jpeg\" /></p><p>例如：通过rate()函数获取HTTP请求量的增长率：</p><p></p><p><code lang=\"text\">  rate(http_requests_total[5m])\n</code></p><p></p><p><code lang=\"text\">查询当前系统中，访问量前10的HTTP地址：\n</code></p><p></p><p><code lang=\"text\">  topk(10, http_requests_total)\n</code></p><p></p><p><code lang=\"text\">一般而言，counter数值本身所产生的意义不是很大，实际使用中多是通过counter数据来进行rate计算**变化率，增长率。**（问题，如果counter采集到的数据，突然变小了会怎么样？）\n</code></p><p></p><p>Gauge：可增可减的仪表盘，用于采集瞬时数据与Counter不同，Gauge类型的指标侧重于反应系统的当前状态。因此这类指标的样本数据可增可减。常见指标如：node_memory_MemFree（主机当前空闲的内容大小）、node_memory_MemAvailable（可用内存大小）都是Gauge类型的监控指标。</p><p><img src=\"https://static001.geekbang.org/infoq/e9/e9c86b347d595d20161354b23bc9cf7c.jpeg\" /></p><p>还可以直接使用predict_linear() 对数据的变化趋势进行预测。例如，预测系统磁盘空间在4个小时之后的剩余情况：这个函数是用来做预测的，predict_linear()这个函数对于磁盘空间来说的话是非常有用的，因为磁盘在实际使用的过程当中一下子就增长起来了，这是一个缓慢的过程，所以可以根据这个函数来判断4个小时之后磁盘剩余的情况，根据这个情况就可以提前去将磁盘空间清理或者扩容。</p><p></p><p><code lang=\"text\">  predict_linear(node_filesystem_free_bytes[1h], 4 * 3600)\n</code></p><p></p><p>Histogram和Summary：主用用于统计和分析样本的分布情况。在大多数情况下人们都倾向于使用某些量化指标的平均值，例如CPU的平均使用率、页面的平均响应时间，这种方式也有很明显的问题，以系统API调用的平均响应时间为例：如果大多数API请求都维持在100ms的响应时间范围内，而个别请求的响应时间需要5s，那么就会导致某些WEB页面的响应时间落到中位数上，而这种现象被称为长尾问题。为了区分是平均的慢还是长尾的慢，最简单的方式就是按照请求延迟的范围进行分组。例如，统计延迟在0~10ms之间的请求数有多少而10~20ms之间的请求数又有多少。通过这种方式可以快速分析系统慢的原因。Histogram和Summary都是为了能够解决这样的问题存在的，通过Histogram和Summary类型的监控指标，我们可以快速了解监控样本的分布情况。Summary摘要用于记录某些东西的平均大小，可能是计算所需的时间或处理的文件大小，摘要显示两个相关的信息：count（事件发生的次数）和sum（所有事件的总大小），如下图计算摘要指标可以返回次数为3和总和15，也就意味着3次计算总共需要15s来处理，平均每次计算需要花费5s。下一个样本的次数为10，总和为113，那么平均值为11.3，因为两组指标都记录有时间戳，所以我们可以使用摘要来构建一个图表，显示平均值的变化率，比如图上的语句表示的是5分钟时间段内的平均速率</p><p><img src=\"https://static001.geekbang.org/infoq/64/649ab969fdc287c5703d07fb25127401.jpeg\" /></p><p>Histogram摘要非常有用，但是平均值会隐藏一些细节，上图中10与113的总和包含非常广的范围，如果我们想查看时间花在什么地方了，那么我们就需要直方图了。直方图以bucket桶的形式记录数据，所以我们可能有一个桶用于需要1s或更少的计算，另一个桶用于5秒或更少、10秒或更少、20秒或更少、60秒或更少。该指标返回每个存储桶的计数，其中3个在5秒或更短的时间内完成，6个在10秒或更短的时间内完成。Prometheus中的直方图是累积的，因此所有10次计算都属于60秒或更少的时间段，而在这10次中，有9次的处理时间为20秒或更少，这显示了数据的分布。所以可以看到我们的大部分计算都在10秒以下，只有一个超过20秒，这对于计算百分位数很有用。</p><p><img src=\"https://static001.geekbang.org/infoq/4c/4c3eed30ee68c18eebd41ad9bfb2aa47.jpeg\" /></p><p>Histogram和Summary的区别Summary的分位数是直接在客户端计算完成的，histogram则在服务端完成histogram存储的是区间的样本数统计值，不能得到精确的分为数，而Summary可以**。**如果需要聚合（aggregate），选择histograms。如果比较清楚要观测的指标的范围和分布情况，选择histograms。如果需要精确的分位数选择summary。</p><p></p><h4>4) 内置函数与聚合操作</h4><p></p><p>这里列一下Prometheus中常用的一些内置函数，但是其实我们真正需要彻底搞懂原理，懂得运用的只有一个,那就是rate()。后面会有重点介绍。</p><p></p><p><code lang=\"text\">absent()               #取布尔值\nabs()                  #绝对值\nsqrt()                 #平方根\nceil()                 #向上取整\nfloor()                #向下取整\nchanges()              #显示变更次数\nround()                #四舍五入取整\nclamp_max()            #当大于最大值时，则为最大值\nclamp_min()            #当小于最小值时，则为最小值\nlable_join()           #新增标签\nlable_replace()        #替换标签\npredict_linear()       #基于一段时间内的增长值来预测多久后会溢出\nrate()                 #计算区间向量里的平均增长率\nirate()                #计算区间向量内最新和最后的瞬时向量的增长率\nsort()                 #升序排序\nsort_desc()            #降序排序\ndelta()                #计算区间向量里最大最小的差值\nincrease()             #计算区间向量里最后一个值和第一个值的差值\n</code></p><p></p><p>常用的一些聚合操作函数也列一下，同样需要理解和掌握的只有** sum, avg**，后面会重点介绍，其他的基本可以触类旁通，忽略就行。</p><p></p><p><code lang=\"text\">sum：                  #求和。\nmin：                  #最小值。\nmax：                  #最大值\navg：                  #平均值\nstddev：              #标准差\nstdvar：              #方差\ncount：                  #元素个数\ncount_values：          #等于某值的元素个数\nbottomk：              #最小的k个元素\ntopk：                #最大的k个元素\nquantile：            #分位数</code></p><p></p><p>如果在实际开发中，想深入了解一些高级用法，建议直接去阅读<a href=\"https://prometheus.io/docs/prometheus/latest/querying/functions/#rate\">官方文档</a>\"，一手资料最为权威和详实。</p><p></p><h4>5) 重点公式</h4><p></p><p></p><p>√ SUM() 操作的理解误区：不要误认为sum是求指标在某个时间段的和。查询可能会返回多条满足指定标签的时间序列，可是有时候我们并不希望分开查看，恰恰大多数情况其实是想查询一条时间序列的结果，例如查询请求总数时想要的结果是：</p><p></p><p><code lang=\"text\">  http_requests_total{} 170\n</code></p><p></p><p><code lang=\"text\">而并不是想要：\n</code></p><p></p><p><code lang=\"text\">  http_requests_total{environment=\"product\"} 30\n  http_requests_total{environment=\"test\"} 60\n  http_requests_total{environment=\"developement\"} 80\n</code></p><p></p><p>为了实现这个需求，PromSql提供的聚合操作可以用来对这些时间序列进行处理，通过处理形成一条新的时间序列，上述需求的表达式应该是：sum(http_requests_total)，例如下图会自动将所有时间序列的值相加后形成一条新的时间序列作为结果。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/11/11775f70095b598b7ef209d0eff96003.png\" /></p><p></p><p></p><p></p><p>√ RATE() 函数的理解<a href=\"https://prometheus.io/docs/prometheus/latest/querying/functions/#rate\">“rate(v range-vector)&nbsp;calculates the per-second average rate of increase of the time series in the range vector.”</a>\"官方文档的介绍是：计算范围向量中时间序列每秒的平均增长速率，通俗的讲，就是“一段时间内平均每秒的增量”。描述它的算法实现就是：范围向量的差值/持续时长。采用官方提供的一个用来辅助说明的表达式如下：</p><p></p><p><code lang=\"text\">  rate(http_requests_total{status=\"200\", method=\"GET\"}[5m])\n</code></p><p></p><p><code lang=\"text\">假定其在最近5M之内采样数据如下：\n</code></p><p></p><p><code lang=\"text\">  &lt;--------------- metric ---------------------&gt;&lt;-timestamp -&gt;&lt;-value-&gt;\n  http_request_total{status=\"200\", method=\"GET\"}@1434417560938 =&gt; 10\n  http_request_total{status=\"200\", method=\"GET\"}@1434417561287 =&gt; 200\n  ………\n  http_request_total{status=\"200\", method=\"POST\"}@1434417560938 =&gt; 389\n  http_request_total{status=\"200\", method=\"POST\"}@1434417561287 =&gt; 510\n</code></p><p></p><p><code lang=\"text\">**那么这个rate()表达式的计算结果 = (510 – 10) / (5 \\* 60) = 1.667**\n\n但是需要注意的是一般来讲，rate值**很少是绝对精确的**。由于针对不同目标的抓取发生在不同的时间，因此随着时间的流逝会发生抖动，计算时很少会与抓取时间完美匹配，并且抓取有可能失败。rate计算出来的数据，都会比我们按照它的算法公式直接结算出来的**稍微大那么一丢丢**，因为Prometheus会默认在分母那里乘一个1.X的[系数](https://segmentfault.com/a/1190000040595000)。\n\nrate函数的用途非常广泛，可以说是在Grafana配置的时候使用**最多**的一个函数，包括我们接下来需要使用到的**Latency**和**TPS**之类的核心监控指标，都是需要通过rate函数的计算之后，才能够展现在监控面板上的。那么，究竟是如何实现的呢？这里先卖一个关子，等到下一个章节的知识点介绍完了，你就会茅塞顿开，恍然大悟！\n</code></p><p></p><p>√ PXX() 分位图函数的反直觉分位数统计是Prometheus常用的一个功能，比如经常把某个服务的P95响应时间来衡量服务质量。它到底是什么意思呢？和平均数（中位数）又有何关系呢？比方说，我们算出来的P95平均响应延迟是100ms，实际上是指对于收集到的所有响应延迟，有5%的请求大于100ms，95%的请求小于100ms。Prometheus里面的histogram_quantile函数接收的是0-1之间的小数，将这个小数乘以100就能很容易得到对应的百分位数，比如0.95就对应着P95，而且还可以高于百分位数的精度，比如0.9999。当我们用分位图数据绘制响应时间的趋势图时，可能经常会被问：为什么P95大于或小于我的平均值(或者中位数)？正如中位数可能比平均数大也可能比平均数小，P99比平均值小也是完全有可能的。通常情况下P99几乎总是比平均值要大的，但是如果数据分布比较极端，最大的1%可能大得离谱从而拉高了平均值。一种可能的例子：</p><p></p><p><code lang=\"text\">  1, 1, ... 1, 901 // 共 100 条数据，平均值=10，P99=1\n</code></p><p></p><p><code lang=\"text\">类似的疑问很多。其实，对于分位数统计结果，记住一个结论就可以了：**分位数统计结果和平均数，中位数都无必然的关联关系，也没有比较的意义**。分位数的统计学意义在于**描述数值的分布区间情况**。所以，**分位数无论大于或者小于平均数（中位数）都是合理的！**\n\n自此，如果你理解了这三个函数的原理，那么恭喜你，你已经可以处理大部分我们常用到的Metrics指标了。同样，本文的后面章节也只需要用到这点知识就可以了。是不是挺简单的呢？\n</code></p><p></p><h4>6) 默认指标</h4><p></p><p></p><p>前面章节已经介绍过了，通过引入micrometer和actuator两个依赖库，就已经会默认自动生成一些metrics数据了，并且这些metrics数据针对HTTP业务而言，是足够的了，大部分的监控数据可以基于这些默认的metrics通过各种运算生产出来。</p><p></p><p>通过访问微服务通过actuator暴露出的一个专门为Prometheus爬取数据所用到的endpoint：localhost:8080/actuator/prometheus可以看到默认产生的metrics数据长下面的样子：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/01a6ba359c8547ca0b8f64cd069156d4.png\" /></p><p></p><p></p><p>之前在样本格式这个章节已经介绍过了，每个样本数据都是一条包含了“[metrics-timestamp-value]”三部分关键信息的记录，所以上面的数据就可以理解了，全部都是符合这个格式规范的。在所有的默认采集样本中，我们只需要彻底理解两条就够了，因为基于这两条样本数据，结合前面介绍过的**rate()和count()**算法，就可以把几乎所有的HTTP微服务相关的监控面板给配置出来。同时，理解了这两条数据后，其他的数据也可以做到触类旁通。</p><p></p><p>两个重要的重要的监控指标：</p><p></p><p>http_server_requests_seconds_count：从上次服务重启到现在所有的HTTP的请求数量http_server_requests_seconds_sum：从上次服务重启到现在所有的HTTP的请求的耗时时长，单位是秒</p><p></p><p>基于这两个非常基础但是非常重要的监控指标，我们利用Prometheus提供的函数就可以非常方便地得到我们需要的监控信息了。</p><p></p><p>a) 比方，TPS/RPS/OPS数据(AVG数据)，可以采用下面的方式计算得到：</p><p></p><p><code lang=\"text\">rate(http_server_requests_seconds_count [5m])\n</code></p><p></p><p>b) 过去一段时间内的平均处理时间可以使用如下的方式计算得到：</p><p></p><p><code lang=\"text\">increase(http_server_requests_seconds_sum [5m])/\nincrease(http_server_requests_seconds_count [5m])\n</code></p><p></p><p>c) 我们用平时用的最多的HTTP平均响应时间（RT）：</p><p></p><p><code lang=\"text\">rate(http_server_requests_seconds_count [$__rate_interval])/\nrate(http_server_requests_seconds_count [$__rate_interval])*1000\n</code></p><p></p><h4>7) 客制化指标</h4><p></p><p></p><p>需要注意的是，另外一个常用的监控指标“平均响应时间分位图“，即俗称的PXX分布图，micrometer默认是不提供的，需要开发者自行添加几行代码才能够显示出来。可以参考后面提供的Demo代码如果不想通过默认的tomcat的线程并发数来监控线程并发指标，可以可以拦截器的方式来实现客制化，参考后面的HTTP BUSY SESSION面板关于对“系统级别资源”的监控大板展示，建议选用4701号公共模板资源关于客制化metrics的开发方面，基本所有的问题都可以在网络在很方便地找到对应的答案，没啥高深的东西</p><p></p><p>到此，我们对理论，方法及知识点的系统性梳理已经结束了。基于我们掌握的知识，按照下文的实操步骤，任何人，不管会不会写代码，都可以在不超过15分钟的时间内在自己的机器上搭建一套基本完整的监控系统对微服务业务组件进行监控。</p><p></p><p>Let's try it! 😊</p><p></p><h2>落地实操</h2><p></p><p></p><h3>1. 实操方案</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c6/c6473fb3df7a900380da40fca6814764.png\" /></p><p></p><p></p><p>本文设计的实操例子如上图所示，操作步骤如下：</p><p></p><p>本地运行Springboot服务程序代码，代码集成micrometer和actuator.模拟业务组件。本地机器下载和安装好单机版的Prometheus程序本地机器下载和安装好单机版的Grafana程序本地机器下载和安装好单机版的Apache JMeter程序，用于模拟产生HTTP并发请求</p><p></p><p>监控面板上要展示什么呢？按照前面提及的“黄金四信号”，我们本地的测试例子准备将如下的信息通过监控面板展示出来，这些指标对于我们日常微服务组件的运维监控，性能测试，问题排查等都非常重要。</p><p></p><p>流量指标：OSP/RPS：响应延迟指：Average Response Time Latency， PXX RT Latency错误指标：Error Rate/Count饱和度指标：这块主要是关注系统的硬件资源的利用率，采用4701通用模板</p><p></p><p>好了，实操方案的设计和构思基本结束，下面开始进行实操。</p><p></p><h3>2. Springboot Code</h3><p></p><p></p><p>测试代码主要是模拟运行一个微服务组件，接受请求，然后进行处理（随机休眠）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b4/b43454efb901ced1de374684f56b2222.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cd/cd836d875d3a181b83a35d3d6cf384b2.png\" /></p><p></p><p>整个测试过程这个Springboot程序需要一直运行着。</p><p></p><h3>3. Promethues</h3><p></p><p></p><p>√ 下载点击以下链接通过官网下载prometheus-2.35.0.windows-amd64<a href=\"https://github.com/prometheus/prometheus/releases/download/v2.35.0/prometheus-2.35.0.windows-amd64.zip\">https://github.com/prometheus/prometheus/releases/download/v2.35.0/prometheus-2.35.0.windows-amd64.zip</a>\"√ 配置解压zip包，然后打开prometheus.yml，在里面配置一个Metrics数据的爬取Job，指定到本地去进行pull.配置也非常简单，只需要在增加阴影部分行的配置数据就可以了，其他的全部保持不变。如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/79/7919c474d89edce646fdef8c42e5ab7f.png\" /></p><p></p><p><code lang=\"text\">    - job_name: \"metrics-demo\"\n      metrics_path: '/actuator/prometheus'\n      static_configs:\n        - targets: ['localhost:8080']\n          labels:\n            instance: springboot2-prometheus\n            service: demo-service\n</code></p><p></p><p>√ 运行最后，双击prometheus.exe运行起来即可。访问http://localhost:9090/有GUI出来即说明安装OK</p><p></p><h3>4. Grafana</h3><p></p><p></p><p>√ 下载点击以下链接通过官网下载grafana-enterprise-8.5.3.windows-amd64.zip<a href=\"https://dl.grafana.com/enterprise/release/grafana-enterprise-8.5.3.windows-amd64.zip\">https://dl.grafana.com/enterprise/release/grafana-enterprise-8.5.3.windows-amd64.zip</a>\"√ 配置和Prometheus都跑到同一台机器上了，没啥要配置的，开箱即用√ 运行到bin目录找到grafana-server.exe，双击运行就可以了。访问http://localhost:3000/；admin/admin.有GUI出来即说明安装OK</p><p></p><h3>5. JMeter</h3><p></p><p></p><p>√ 下载<a href=\"https://dlcdn.apache.org//jmeter/binaries/apache-jmeter-5.4.3.zip\">https://dlcdn.apache.org//jmeter/binaries/apache-jmeter-5.4.3.zip</a>\"√ 配置和Springboot程序都跑到同一台机器上了，没啥要配置的，开箱即用√ 启动找到apache-jmeter-5.4.3\\bin\\jmeter.bat双击启动即可。启动成功后可见如下的GUI</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c6/c67f80b1e8a5c640015f4b70951fb6b5.png\" /></p><p>√ 添加case添加一个并发测试的case用来模拟用户向微服务发送HTTP请求：1：添加一个Thread Group:</p><p><img src=\"https://static001.geekbang.org/infoq/62/62724921b25229e9e418caecf1d6da72.png\" /></p><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/79/7909526b7f8b639c221f40cc78cc4c04.png\" /></p><p>2：添加两个类型为HTTP Requester的采样器：</p><p><img src=\"https://static001.geekbang.org/infoq/23/237ba14027f3b1ea61c4550462a68edf.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7e/7e2aa9517d8118b1a9ecad186ada4990.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ab/ab026793f982b645d0ac2f3bae7fa8cb.png\" /></p><p>√ 执行配置完case之后，回到Thread Group界面，点击绿色箭头即可启动测试；</p><p><img src=\"https://static001.geekbang.org/infoq/f8/f892a4e678c6ef88d15bcd8187b9d530.png\" /></p><p>测试启动之后，相应的一些metrics数据就已经开始被采集到Prometheus中了。这个时候我们就可以去到Grafana上面去配置我们的监控面板了。需要注意的是，配置的前提是先要有时序样本数据。这就是为什么要先开启JMeter进行数据生产的原因。</p><p></p><h3>6. 配置Dashboard</h3><p></p><p></p><p>前面的步骤做完了，接下来就可以开始实现我们的实操的终极目的：配置出一个可以用于对微服务进行监控的监控大板了. 以下的所有的操作都在Grafana上进行。</p><p></p><p>登陆Grafana访问http://localhost:3000/登陆到Grafana，如果需要账号密码，就是admin/admin。可以见到如下的Welcome首页。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ec/ec383786cf70a318f16e77ebf237c7cd.png\" /></p><p>配置数据源首先，需要告诉Grafana去哪个数据源获取数据。在Welcome界面上，点击 “Add your first data source”，进入到添加数据源的界面，然后选择第“Prometheus”,进行配置，将Prometheus作为其数据源。</p><p><img src=\"https://static001.geekbang.org/infoq/7a/7acc25b4dfd46731f100feb0b6c9dc26.png\" /></p><p>这里URL是需要手工添加进去的。只设置这个URL就可以了，其他的所有配置保持默认即可。最后拖到底部，保存并测试。如一切正常，可以看到绿色的测试成功信息提示。配置面板</p><p></p><p>接下来，我们就需要利用我们前面掌握的相关知识，将我们设计好的监控面板给配置出来。在Welcome界面上点击“Create your first dashboard”，然后点击“Add a new panel”开始创建监控面板。RPS/OPS面板在创建面板的时候，将Panel的名字设置为HTTP RPS/OPS。同时注意要将visualization里面的图形样式改为**Graph (old),**否则会出现很多的时序图形无法展示的问题。另外在“Metrics browser”这里的输入栏，相关的指标会智能提示的，不需要去一个个记的。</p><p><img src=\"https://static001.geekbang.org/infoq/b4/b4da7283804d0acbfa614b25f77a56b0.png\" /></p><p>这里，我们使用如下的PromSql表达式：</p><p></p><p><code lang=\"text\">  rate(http_server_requests_seconds_count{uri=~\"/user|/vehicle\"}[$__rate_interval])\n</code></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7a/7aa70dc7881881b9423b504d5fefb774.png\" /></p><p></p><p></p><p>可以看到，OPS数据的监控面板已经产生了。 Apply保存即可。</p><p></p><p>AVG RT面板</p><p></p><p>接下来，同样的操作用来构建我们用的最多的Latency监控面板，</p><p></p><p>使用到的PromSql表达式如下：</p><p></p><p><code lang=\"text\">  rate(http_server_requests_seconds_sum{exception=\"None\",method=\"GET\",service=\"demo-service\",status=\"200\",uri=~\"/user|/vehicle\"}[$__rate_interval])/rate(http_server_requests_seconds_count{exception=\"None\",method=\"GET\",service=\"demo-service\",status=\"200\",uri=~\"/user|/vehicle\"}[$__rate_interval]) * 1000\n</code></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c0/c05e360718c9c234732e1e332ab8d812.png\" /></p><p></p><p>这里要注意的是需要将单位显示这里设置为ms，因为我们计算的时候扩大了1000倍。同样apply保存即可</p><p></p><p>ERROR面板</p><p></p><p>Error面板主要用来监控HTTP的非2XX的返回数据，相对简单，它是不需要啥计算的，直接过滤一下counter数据就可以了。注意：ERROR的图表适用用Stat格式来进行展示。</p><p></p><p>使用下面的PromSql表达式来实现:</p><p></p><p><code lang=\"text\">  http_server_requests_seconds_count{status=\"404\",uri=\"/vehicle\"}\n</code></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2d/2dbe51a3f73d4e2abb81e0e0b0a04508.png\" /></p><p></p><p>同样，5XX之类的监控指标也可以采用同样的操作实现.</p><p></p><p>接下来再配置一个监控系统HTTP请求ERROR速率的面板</p><p></p><p>使用如下的PromSql表达式：</p><p></p><p><code lang=\"text\">  sum(rate(http_server_requests_seconds_count{application=\"metrics-demo\", instance=\"springboot2-prometheus\", status=~\"5..|4..\"}[1m]))\n</code></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/15/159e2a4ccdac6058056d087c385f0871.png\" /></p><p></p><p></p><p>保存即可。</p><p></p><p>PXX分位图&amp;并发数</p><p></p><p>前面的章节已经提过了，micrometer默认产生的监控指标中是不包含PXX数据HTTP并发数指标的，这两个指标是需要在代码中写几行代码进行定制，其实很很简单，模式都是固定的，固定写法而已。有兴趣可以参考代码。</p><p></p><p>采用如下的PromSql来计算HTTP的平均响应时间的分位图：</p><p></p><p><code lang=\"text\">  avg(http_server_requests_seconds{service=\"demo-service\",quantile =~ \"0.5|0.9|0.95|0.99\",uri=\"/user\"} * 1000) by (uri,quantile)\n</code></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/47/4777e4edef8da72a9c67fa6bb2518a9e.png\" /></p><p></p><p>保存即可。</p><p></p><p>使用如下的表达式来监控HTTP当前真正在处理请求的Session数量。</p><p></p><p><code lang=\"text\">  demo_rest_inprogress_req{}\n</code></p><p></p><p>该指标同样是一个客制化的Metrics.</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1b/1b114bd54573f668ba1d42a9cbd44a49.png\" /></p><p></p><p></p><p>保存即可。</p><p></p><p>自此，一个完整的针对HTTP微服务组件的监控面板就创建起来了，最终的效果如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/05/054ab799cdf516d629ab45b141fab6e4.png\" /></p><p></p><p></p><p>饱和度指标面板</p><p></p><p>细心的读者可以发现了，我们还缺少一个可以用来监控系统资源饱和度的面板。这里我们就直接使用在业界应用非常广泛，大名鼎鼎的4701模板了。这个模板依然是直接导入，开箱即用。</p><p></p><p>在Welcome界面左侧点击那个小+，进入到import界面：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f7/f71e6b48798d507f9c39d6cee6dc46e1.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/78/78ae84e3c6130e0a9b7230af5665bff8.png\" /></p><p></p><p></p><p>输入4701然后load一下。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/41/414efb43edc63caf2e2acc8625228942.png\" /></p><p></p><p></p><p>配置好面板名称，选择数据源，就可以了。然后import进来就完事了。</p><p></p><p>导入后的4701面板效果如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a1/a18dd7400a857dd4155a500cc9f49fac.png\" /></p><p></p><p></p><h2>总结</h2><p></p><p>最终，针对微服务组件的监控，我们得到了如下的两个监控面板，能够很好地完成针对微服务组件（HTTP）进行监控的目标了。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/05/054ab799cdf516d629ab45b141fab6e4.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a1/a18dd7400a857dd4155a500cc9f49fac.png\" /></p><p></p><p></p><p>自此，本文开头提出的想法已经被我们一一实现了。从发现问题，分析问题，然后系统性地进行知识梳理，学习，再进行落地实操，如果你完整地走过了一遍，相信你此刻面对监控系统，应该会多了一份自信，少了一份彷徨了，以后类似的问题基本都可以举一反三，从而应对了。</p><p></p><p>希望这个文档能够给你带来一些小小的帮助！谢谢！</p>",
    "publish_time": "2023-06-08 17:52:20",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "继Stability AI、AI21 Labs和LG AI之后，TII也用亚马逊云科技训练大模型",
    "url": "https://www.infoq.cn/article/h5zqC9Cq8UK4iOKrwPc7",
    "summary": "<p>2023年6月7日，亚马逊云科技宣布，位于阿联酋首都阿布扎比的全球领先科研中心TII（Technology Innovation Institute）在亚马逊云科技上训练了其性能卓越的开源模型Falcon 40B。</p><p>&nbsp;</p><p>据悉，TII是一家全球领先的科研中心，一直致力于探索前沿的知识领域。TII的科学家、研究员和工程师团队竭力提供探索性科学成果和变革性技术。据TII介绍，基于一万亿个字符（token）训练的TII Falcon大语言模型不仅在性能上表现突出，同时具有超高的成本效益。</p><p>&nbsp;</p><p>Falcon大语言模型项目地址：</p><p>&nbsp;</p><p><a href=\"https://www.tii.ae/news/abu-dhabi-based-technology-innovation-institute-introduces-falcon-llm-foundational-large\">https://www.tii.ae/news/abu-dhabi-based-technology-innovation-institute-introduces-falcon-llm-foundational-large</a>\"</p><p>&nbsp;</p><p></p><h2>Falcon 40B是什么？</h2><p></p><p>&nbsp;</p><p>Falcon 40B是拥有400 亿参数的大语言模型（LLM），在Apache 2.0许可下提供，并在Hugging Face的开源大语言模型排行榜上位列榜首（该排行榜在多个基准测试中跟踪、排名和评估大语言模型，最终评选出最佳模型）。</p><p>&nbsp;</p><p>Falcon 大语言模型提供两种不同规模的开源版本——Falcon 40B和Falcon 7B, 两者均是使用Amazon SageMaker的数据预处理和模型训练任务从零开始构建。开源的Falcon 40B让用户能够构建和定制满足独特用户需求的AI工具，便于无缝集成，并确保长期保存数据资产。模型权重可供下载，检查和部署在任何地方。</p><p>&nbsp;</p><p>为了提高科学质量和训练速度方面的水准，该项目在各个层面都进行了前所未有的定制创新。其中，TII在所有深度学习训练系统层级上都进行了优化。</p><p>&nbsp;</p><p>从6月7日起，两个开源Falcon大语言模型也将在Amazon SageMaker JumpStart中可用。这是SageMaker的机器学习中心，它提供了预训练模型、内置算法和预构建的解决方案模板，可以帮助用户快速上手机器学习。用户只需在SageMaker Studio中轻点鼠标就可以部署和使用Falcon模型，或者通过SageMaker Python SDK以编程方式使用。</p><p>&nbsp;</p><p>SageMaker是一个托管API集合，用于开发、训练、调优和托管机器学习（ML）模型，包括大语言模型。许多用户使用SageMaker处理其大语言模型工作负载，例如<a href=\"https://aws.amazon.com/blogs/machine-learning/new-performance-improvements-in-amazon-sagemaker-model-parallel-library/\">Stability AI</a>\", <a href=\"https://www.youtube.com/watch?v=0CHyMYFy94c&amp;list=PL2yQDdvlhXf9XsB2W76_seM6dJxcE2Pdc&amp;index=20\">AI21 Labs</a>\"和<a href=\"https://aws.amazon.com/solutions/case-studies/lg-ai-research-case-study/\">LG AI</a>\"。<a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-training.html\">SageMaker Training</a>\"提供了具有用户自定义硬件配置和代码的计算集群。计算作业按运行次数计费，按秒分配任务，这意味着用户在未使用服务时无需为GPU资源付费。TII使用SageMaker Training API提供的瞬态集群来训练Falcon大语言模型，最多支持48个ml.p4d.24xlarge实例（384个英伟达A100 GPU）。现在，TII正在训练下一代Falcon大语言模型，将训练扩展到3136个A100 GPU（392个ml.p4d实例）。</p><p>&nbsp;</p><p>TII 跨AI研究中心执行总监、代理首席AI研究员兼大语言模型项目负责人Ebtesam Almazrouei博士表示：“我们自豪地宣布Falcon 40B开源版正式发布，这是TII开发的世界一流的开源语言模型。Falcon 40B超过了Hugging Face开源大语言模型排行榜上的LLaMA-65B、StableLM、RedPajama和MPT等知名模型，展示了无需专门微调的卓越性能。”</p><p>&nbsp;</p><p></p><h2>参数越大，性能越好？</h2><p></p><p>&nbsp;</p><p>大语言模型是经过训练以完成自然文本序列的软件算法。得益于庞大的规模和与之交互的训练数据量，大语言模型拥有出色的文本处理能力，包括总结摘要、问题回答和上下文学习等能力。</p><p>&nbsp;</p><p>2020年年初，全球各地的研究机构都将研究重点放在模型大小上，并观察到准确性与参数数量之间存在关联。例如，GPT-3（2020）和BLOOM（2022）拥有约1750亿个参数，Gopher（2021）拥有2300亿个参数， MT-NLG（2021）拥有5300亿个参数。</p><p>&nbsp;</p><p>但是最近两年，情况似乎有所不同。2022年，Hoffman等人观察到当前模型参数和数据集大小之间的计算平衡不是最优的，并发表了经验性的缩放定律，建议将计算预算转向使用更多数据训练的较小模型，可以获得性能更好的模型。他们在拥有700亿参数的Chinchilla（2022）模型中实践了这一想法，结果显示该模型的表现超过了更大的模型。</p><p>&nbsp;</p><p>由此可见，模型性能的好坏并不能和参数的多少完全正相关。</p><p>&nbsp;</p><p></p><h2>大模型之战正酣，亚马逊云科技从未缺席</h2><p></p><p>&nbsp;</p><p>在关注大模型参数和性能之余，大模型应用和生成式AI开发才是当前AI领域的主旋律。</p><p>&nbsp;</p><p>日前，全球市场分析机构Gartner®发布《2023 云 AI 开发者服务魔力象限》报告，亚马逊云科技被评为“领导者”，且在执行能力轴上排名最高。</p><p>&nbsp;</p><p>榜单之外，Amazon SageMaker功不可没。</p><p>&nbsp;</p><p>今年4月，亚马逊云科技还重磅推出了Amazon Bedrock托管服务和Amazon Titan模型。借此，亚马逊云科技提供了非常简单的途径，让开发者借助基础模型构建和扩展生成式AI应用程序。</p><p>&nbsp;</p><p>Amazon Bedrock让开发者可以通过API访问AI21Labs、Anthropic和Stability AI等热门AI公司的预训练基础模型，还提供对亚马逊云科技开发的基础模型系列Amazon Titan的独家访问。</p><p>&nbsp;</p><p>Amazon Bedrock提供的无服务器体验可以让客户轻松找到适合自身业务的模型，快速上手，在确保数据安全和隐私保护的前提下，使用自有数据基于基础模型进行定制，并使用已经熟悉的亚马逊云科技工具和能力，将定制化模型集成并部署到应用程序，无需自己管理基础设施。</p><p>&nbsp;</p><p>此外，亚马逊云科技的AI编程助手Amazon CodeWhisperer面向个人开发者免费开放。</p><p>&nbsp;</p><p>Amazon CodeWhisperer从数十亿行公开代码中学习之外，还基于亚马逊的代码进行了训练，可以为Amazon EC2、Amazon Lambda和Amazon S3等云服务生成最准确、最快和最安全的代码。开发者使用Amazon CodeWhisperer，完成任务的速度平均快57%，成功率高27%。</p><p>&nbsp;</p><p>埃森哲已经开始用 Amazon CodeWhisperer 加快编码任务，作为其Velocity 平台软件工程最佳实践计划的一部分。CodeWhisperer可以帮助不太熟悉亚马逊云科技的开发人员更快地熟悉使用亚马逊云科技服务开发的项目。借助 CodeWhisperer，埃森哲新的开发人员就能够为Amazon S3和 Amazon DynamoDB 等亚马逊云科技服务编码。在短时间内，他们就能够高效工作并为项目做出贡献。</p>",
    "publish_time": "2023-06-08 18:48:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "百度智能云技术委员会主席王耀确认担任QCon联席主席并将发表主题演讲",
    "url": "https://www.infoq.cn/article/arylU49hvmhd5asKopai",
    "summary": "<p>近日，<a href=\"https://cloud.baidu.com/?track=9de7f051a04b3f5b7ae36307c7352a023c0394441f60e99c\">百度智能云</a>\"技术委员会主席王耀确认担任<a href=\"https://qcon.infoq.cn/202309/beijing/\"> QCon全球软件开发大会</a>\"联席主席并将发表主题演讲。&nbsp;</p><p></p><p>王耀自 2010 年加入百度以来，参与和负责了百度和百度智能云的基础技术建设工作。目前作为百度智能云的技术委员会主席，负责百度智能云的基础设施，包含存储、边缘计算、私有云、云原生、AI Cloud 等技术方向的规划和落地。据了解，百度智能云今年将重点建设 AI Cloud，包括 AI PaaS 与 AI IaaS 深度技术融合以及文心千帆大模型开发平台的研发。QCon 大会今年的主题是「AIGC 软件工程变革」，他将从大模型和 AI 基础设施的角度给大会的专题策划提供前瞻视角，给听众带来真正有价值的内容。</p><p>&nbsp;</p><p>QCon全球软件开发大会采用联席主席、出品人和讲师的三级组织机制。在根据业界趋势和用户调研、专家调研结果产出会议专题方向之后，大会将邀请业界有影响力的顶级专家作为联席主席，进一步探讨选题方向，确保会议的前沿、专业、实用，此后再邀请某个领域有代表性的专家作为出品人，为专题质量进行深度把关。</p><p>&nbsp;</p><p>据悉，9 月 3-5 日，<a href=\"https://qcon.infoq.cn/202309/beijing?utm_source=infoq&amp;utm_medium=arti&amp;utm_campaign=8&amp;utm_term=0608&amp;utm_content=wangyao\">QCon全球软件开发大会</a>\"将在北京举办。作为联席主席，王耀与 QCon 组委会在 6 月 7 日围绕 QCon北京站会议内容的顶层设计做了深入沟通，此次沟通也为本次会议的成功举办奠定了坚实的基础。当日，他还接受了 InfoQ 的采访，分享了百度智能云各个阶段的技术发展历程、整个产业的趋势，以及对于大模型带来的开发新范式、云智一体融合的思考，敬请期待后续的文章。</p><p>&nbsp;</p><p>值得一提的是，为向业界呈现大模型时代的 AI 基础设施全景图，帮助大家搞定大模型，从 6 月 20 日 开始，InfoQ 联合百度智能云推出<a href=\"https://mp.weixin.qq.com/s/sAVYNRtRAnixUMg3G9sSzg\"> 「AI 大底座」系列公开课</a>\"。该系列课程共 8 节，将从云和智两个维度，围绕大模型落地的关键环节进行技术解析和实践分享，预约方式见下方二维码。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/2e/20/2ea9487e8054fa153dcccb8aec2fc920.png\" /></p><p></p><h4>活动推荐</h4><p></p><p>QCon全球软件开发大会·北京站主题最终确定为「启航·AIGC 软件工程变革」，会议将于 9 月3-5 日在北京•富力万丽酒店举办，此次大会策划了大模型应用落地、LLMOps、AIGC 浪潮下的研发效能提升、异构算力、微服务架构治理、业务安全技术、面向 AI 的存储、构建未来软件的编程语言、FinOps 等方向。目前大会议题同步征集中，<a href=\"https://qcon.infoq.cn/202309/beijing?utm_source=infoq&amp;utm_medium=arti&amp;utm_campaign=8&amp;utm_term=0608&amp;utm_content=wangyao\">点击查看详情</a>\"，期待与各位开发者现场交流。</p>",
    "publish_time": "2023-06-08 19:35:06",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "趣丸科技媒体算法负责人马金龙确认出席 ArchSummit 深圳",
    "url": "https://www.infoq.cn/article/jh0K1kUyrsJrooSuTOmF",
    "summary": "<p>7&nbsp;月&nbsp;21&nbsp;日&nbsp;-&nbsp;22&nbsp;日，&nbsp;在&nbsp;<a href=\"https://archsummit.infoq.cn/2023/shenzhen?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">ArchSummit&nbsp;全球架构师峰会（深圳站）</a>\"，趣丸科技媒体算法负责人马金龙，将于会上发表题为《AI多媒体技术在内容审核场景实践探索》主题分享，通过对特定场景的分析和优化，建设性的提出了基于多模态内容识别的怒骂和炸房标签，为进一步净化语音生态提供了技术支撑。</p><p></p><p>马金龙拥有&nbsp;9&nbsp;年媒体算法开发经验，涉及音视频图像文本，负责过音频前后端处理，弱网优化，音视频质量提升，智能内容安全审核“T&nbsp;网”，内容理解“T&nbsp;悟”等大型项目。曾作为“灵声讯”创始人，参与智能媒体技术自媒体运营和推广。</p><p></p><p>相信通过马金龙的分享，你将了解到最新的端对端语音识别系统，多模态处理，Transformer&nbsp;音频事件检测，AIGC&nbsp;内容审核以及多媒体审核场景的算法优化方法。</p><p></p><p>除上述专题外&nbsp;，ArchSummit&nbsp;深圳还将围绕<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1537?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">基础架构技术</a>\"、<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1536?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">智能化数据治理</a>\"、<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1532?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">DataOps、Data&nbsp;Fabric&nbsp;等高效数据开发与服务模式</a>\"、<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1534?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">Mesh&nbsp;技术实践案例</a>\"、<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1535?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">QUIC&nbsp;传输和架构优化</a>\"等进行分享。</p><p></p><p>数十位业界专家，上百个国内外一线大厂前沿技术案例，一定会给你带来很多全新的开发灵感。期待与你线下交流！&nbsp;现在购票，享&nbsp;8&nbsp;折特惠，立省&nbsp;¥1760！咨询购票请联系&nbsp;18514549229（微信同手机号）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9d/9d6a27547062ee2e089f91bdc4ba1eaa.png\" /></p><p></p>",
    "publish_time": "2023-06-08 19:49:46",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]