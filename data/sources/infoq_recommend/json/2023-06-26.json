[
  {
    "title": "亚马逊云科技开源PBAC领域特定语言Cedar",
    "url": "https://www.infoq.cn/article/CC2RaXSKw5oRwzpymyxx",
    "summary": "<p><a href=\"https://www.infoq.com/aws/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODc2NjUwMjUsImZpbGVHVUlEIjoibkdoOGVlUG4yT2tOZDhKaCIsImlhdCI6MTY4NzY2NDcyNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.3_IK-LTZ2Fts1a8lgQxj-7sHEsQd1W4aFe3ckViFsSA\">亚马逊云科技</a>\"<a href=\"https://aws.amazon.com/blogs/opensource/using-open-source-cedar-to-write-and-enforce-custom-authorization-policies/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODc2NjUwMjUsImZpbGVHVUlEIjoibkdoOGVlUG4yT2tOZDhKaCIsImlhdCI6MTY4NzY2NDcyNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.3_IK-LTZ2Fts1a8lgQxj-7sHEsQd1W4aFe3ckViFsSA\">开源</a>\"了他们用来定义策略访问权限的领域特定语言<a href=\"https://github.com/cedar-policy?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODc2NjUwMjUsImZpbGVHVUlEIjoibkdoOGVlUG4yT2tOZDhKaCIsImlhdCI6MTY4NzY2NDcyNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.3_IK-LTZ2Fts1a8lgQxj-7sHEsQd1W4aFe3ckViFsSA\">Cedar</a>\"。Cedar已集成在<a href=\"https://aws.amazon.com/verified-permissions/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODc2NjUwMjUsImZpbGVHVUlEIjoibkdoOGVlUG4yT2tOZDhKaCIsImlhdCI6MTY4NzY2NDcyNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.3_IK-LTZ2Fts1a8lgQxj-7sHEsQd1W4aFe3ckViFsSA\">Amazon Verified Permissions</a>\"和<a href=\"https://aws.amazon.com/verified-access/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODc2NjUwMjUsImZpbGVHVUlEIjoibkdoOGVlUG4yT2tOZDhKaCIsImlhdCI6MTY4NzY2NDcyNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.3_IK-LTZ2Fts1a8lgQxj-7sHEsQd1W4aFe3ckViFsSA\">AWS Verified Access</a>\"中，还可以通过SDK和语言规范将Cedar直接集成到应用程序中。</p><p></p><p><a href=\"https://www.infoq.com/news/2023/02/aws-policy-language-cedar/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODc2NjUwMjUsImZpbGVHVUlEIjoibkdoOGVlUG4yT2tOZDhKaCIsImlhdCI6MTY4NzY2NDcyNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.3_IK-LTZ2Fts1a8lgQxj-7sHEsQd1W4aFe3ckViFsSA\">Cedar</a>\"可以在应用程序代码之外定义访问策略，这种分离使得它们能够独立地进行编写、分析和审计。Cedar支持基于角色的访问控制（RBAC）和基于属性的访问控制（ABAC）。</p><p></p><p>SDK可用于编写和验证策略和授权访问请求。Cedar是用Rust编写的，但同时提供了Rust crate和Java包，可以在<a href=\"https://github.com/cedar-policy/cedar-java?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODc2NjUwMjUsImZpbGVHVUlEIjoibkdoOGVlUG4yT2tOZDhKaCIsImlhdCI6MTY4NzY2NDcyNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.3_IK-LTZ2Fts1a8lgQxj-7sHEsQd1W4aFe3ckViFsSA\">Java</a>\"中使用Cedar。</p><p></p><p>可以通过调用Cedar授权引擎来验证请求是否被授权。请求信息会被转换为Cedar请求并传给Cedar授权引擎。下面是在Rust中使用Cedar的示例：</p><p></p><p><code lang=\"java\">pub fn is_authorized(\n    &amp;self,\n    principal: impl AsRef,\n    action: impl AsRef,\n    resource: impl AsRef,\n) -&gt; Result&lt;()&gt; {\n    let es = self.entities.as_entities();\n    let q = Request::new(\n        Some(principal.as_ref().clone().into()),\n        Some(action.as_ref().clone().into()),\n        Some(resource.as_ref().clone().into()),\n        Context::empty(),\n    );\n    info!(\n        \"is_authorized request: principal: {}, action: {}, resource: {}\",\n        principal.as_ref(),\n        action.as_ref(),\n        resource.as_ref()\n    );\n    let response = self.authorizer.is_authorized(&amp;q, &amp;self.policies, &amp;es);\n    info!(\"Auth response: {:?}\", response);\n    match response.decision() {\n        Decision::Allow =&gt; Ok(()),\n        Decision::Deny =&gt; Err(Error::AuthDenied(response.diagnostics().clone())),\n    }\n}</code></p><p></p><p>可以使用self.authorizer.is_authorized(&amp;q, &amp;self.policies, &amp;es)self.authorizer来调用Cedar授权引擎。参数包括访问请求、Cedar策略和实体集合。访问请求包含了所需的主体、操作和资源信息。根据具体的分析结果，授权引擎将返回Decision::Allow或Decision::Deny。</p><p></p><p>策略也可以通过SDK来创建。在下面的Java示例中，我们创建了一个策略，允许主体Alice对Vacation资源的子资源执行View_Photo操作：</p><p></p><p><code lang=\"java\">private Set buildPolicySlice() {\n   Set ps = new HashSet&lt;&gt;();\n   String fullPolicy = \"permit(principal == User::\\\"Alice\\\", action == Action::\\\"View_Photo\\\", resource in Album::\\\"Vacation\\\");\";\n   ps.add(new Policy(fullPolicy, \"p1\"));\n   return ps;\n}</code></p><p></p><p>在Java中，可以调用isAuthorized方法来查询授权情况：</p><p></p><p><code lang=\"java\">public boolean sampleMethod() throws AuthException {\n    AuthorizationEngine ae = new WrapperAuthorizationEngine();\n    AuthorizationQuery q = new AuthorizationQuery(\"User::\\\"Alice\\\"\", \"Action::\\\"View_Photo\\\"\", \"Photo::\\\"pic01\\\"\");\n    return ae.isAuthorized(q, buildSlice()).isAllowed();\n}</code></p><p></p><p>在亚马逊云科技宣布开源Cedar之后，<a href=\"https://www.permit.io/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODc2NjUwMjUsImZpbGVHVUlEIjoibkdoOGVlUG4yT2tOZDhKaCIsImlhdCI6MTY4NzY2NDcyNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.3_IK-LTZ2Fts1a8lgQxj-7sHEsQd1W4aFe3ckViFsSA\">Permit.io</a>\"发布了<a href=\"https://www.permit.io/blog/oss-aws-cedar-is-a-gamechanger-for-iam?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODc2NjUwMjUsImZpbGVHVUlEIjoibkdoOGVlUG4yT2tOZDhKaCIsImlhdCI6MTY4NzY2NDcyNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.3_IK-LTZ2Fts1a8lgQxj-7sHEsQd1W4aFe3ckViFsSA\">Cedar-Agent</a>\"，一个HTTP服务器，作为基于Cedar的策略的策略存储和数据存储。策略存储支持创建、检索、更新和删除策略，数据存储支持在内存中存储应用程序数据。Cedar-Agent可以针对存储的数据执行授权检查，这些检查可以基于传入的请求进行。</p><p></p><p>HackerNews上的一位用户<a href=\"https://news.ycombinator.com/item?id=34867332&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODc2NjUwMjUsImZpbGVHVUlEIjoibkdoOGVlUG4yT2tOZDhKaCIsImlhdCI6MTY4NzY2NDcyNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.3_IK-LTZ2Fts1a8lgQxj-7sHEsQd1W4aFe3ckViFsSA\">dadadad100</a>\"评论说，他们看到Cedar可能填补了应用程序授权领域的空白：</p><p></p><p></p><blockquote>Cedar介于OPA（基于数据的搜索方法）和<a href=\"https://zanzibar.tech/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODc2NjUwMjUsImZpbGVHVUlEIjoibkdoOGVlUG4yT2tOZDhKaCIsImlhdCI6MTY4NzY2NDcyNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.3_IK-LTZ2Fts1a8lgQxj-7sHEsQd1W4aFe3ckViFsSA\">Zanzibar</a>\"之间。目前还不清楚哪一方会胜出，但不管怎样，现在这个问题开始引起人们的关注了。</blockquote><p></p><p></p><p>其他用户，如<a href=\"https://news.ycombinator.com/item?id=34867799&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODc2NjUwMjUsImZpbGVHVUlEIjoibkdoOGVlUG4yT2tOZDhKaCIsImlhdCI6MTY4NzY2NDcyNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.3_IK-LTZ2Fts1a8lgQxj-7sHEsQd1W4aFe3ckViFsSA\">Oxbadcafebee</a>\"，对亚马逊云科技没有为Open Policy Agent提供支持表示失望。</p><p></p><p>Cedar采用了Apache License 2.0，托管在GitHub上。更多细节可以在最近的亚马逊云科技的博客中找到，或者加入<a href=\"http://cedar-policy.slack.com/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODc2NjUwMjUsImZpbGVHVUlEIjoibkdoOGVlUG4yT2tOZDhKaCIsImlhdCI6MTY4NzY2NDcyNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.3_IK-LTZ2Fts1a8lgQxj-7sHEsQd1W4aFe3ckViFsSA\">Cedar Policy Slack</a>\"频道。</p><p></p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/06/aws-cedar-open-source/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2ODc2NjUwMjUsImZpbGVHVUlEIjoibkdoOGVlUG4yT2tOZDhKaCIsImlhdCI6MTY4NzY2NDcyNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.3_IK-LTZ2Fts1a8lgQxj-7sHEsQd1W4aFe3ckViFsSA\">https://www.infoq.com/news/2023/06/aws-cedar-open-source/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/YgsLlr5LXF1yvoZfkm2i\">亚马逊云科技 Lambda引入响应有效负载流</a>\"</p><p><a href=\"https://www.infoq.cn/article/NU2Y3XiazG1cqiaNoXXa\">从微服务转为单体架构、成本降低 90%，亚马逊内部案例引发轰动！CTO：莫慌，要持开放心态</a>\"</p>",
    "publish_time": "2023-06-26 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "出门问问工程 VP 李维博士确认出席 ArchSummit 深圳站演讲",
    "url": "https://www.infoq.cn/article/kWCAvxyCEIHUC9fNI8dl",
    "summary": "<p>7&nbsp;月&nbsp;21&nbsp;日&nbsp;-&nbsp;22&nbsp;日，&nbsp;在&nbsp;<a href=\"https://archsummit.infoq.cn/2023/shenzhen?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">ArchSummit&nbsp;全球架构师峰会（深圳站）</a>\"，出门问问工程&nbsp;VP&nbsp;李维博士，将于会上发表题为《AI&nbsp;大模型落地的前景和痛点，兼谈工程师、架构师所面临的机会和挑战》的演讲，详细阐述&nbsp;IT&nbsp;生态大模型（LLM）的洗牌和洗礼，直击架构师工程师面临的问题和挑战。</p><p></p><p>李维博士是自然语言处理（NLP）资深架构师，目前在出门问问大模型（LLM）团队担任工程&nbsp;VP。</p><p>在加入出门问问之前，李维的工作经历也很精彩。曾在&nbsp;Trend&nbsp;担任首席科学家，利用 LLM 和 Deep Parser，聚焦医疗领域病友社区的媒体挖掘；也是弘玑前首席科学家，聚焦&nbsp;RPA+AI&nbsp;的&nbsp;NLP&nbsp;低代码多领域落地，设计&nbsp;NLP&nbsp;核心引擎雕龙，落地多领域场景，包括金融、电力、航空、水利、客服等；更早前担任科大讯飞&nbsp;AI&nbsp;研究院副院长，研发支持对话的多语言平台。也在京东硅谷研究院担任过主任科学家，主攻深度解析和知识图谱及其应用。Netbase&nbsp;前首席科学家，期间指挥研发了&nbsp;18&nbsp;种语言的理解和应用系统。成为美国工业界&nbsp;NLP&nbsp;落地的成功案例，舆情（social&nbsp;listening）赛道的领跑者。Cymfony&nbsp;前研发副总，曾荣获第一届问答系统第一名（TREC-8&nbsp;QA&nbsp;Track），并赢得&nbsp;17&nbsp;个小企业创新研究的信息抽取项目（PI&nbsp;for&nbsp;17&nbsp;SBIRs）。</p><p></p><p>相信通过李维博士的分享，你将了解到&nbsp;AI&nbsp;的革命性巨变（大模型&nbsp;LLM）意味着什么，对&nbsp;LLM&nbsp;提示工程与外挂形态有大概的了解，拥抱大模型而不是惧怕大模型。</p><p></p><p>除上述议题外&nbsp;，ArchSummit&nbsp;深圳还将围绕<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1537?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">基础架构技术</a>\"、<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1532?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">DataOps、Data&nbsp;Fabric&nbsp;等高效数据开发与服务模式</a>\"、<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1534?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">Mesh&nbsp;技术实践案例</a>\"、<a href=\"https://archsummit.infoq.cn/2023/shenzhen/track/1535?utm_source=infoqweb&amp;utm_medium=teacherarticle&amp;utm_campaign=8&amp;utm_term=0531\">QUIC&nbsp;传输和架构优化</a>\"等进行分享。</p><p></p><p>数十位业界专家，上百个国内外一线大厂前沿技术案例，一定会给你带来很多全新的开发灵感。期待与你线下交流！&nbsp;现在购票，享&nbsp;9&nbsp;折特惠，立省&nbsp;¥880！咨询购票请联系&nbsp;18514549229（微信同手机号）</p><p><img src=\"https://static001.infoq.cn/resource/image/9d/aa/9d6a27547062ee2e089f91bdc4ba1eaa.png\" /></p><p></p><p></p>",
    "publish_time": "2023-06-26 09:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "35 亿+66 亿参数双模型，消费级显卡上也能跑！Stability AI 发布重大升级，生成图像真假难辨",
    "url": "https://www.infoq.cn/article/boeCIGt9SLlHk4X4kU5t",
    "summary": "<p></p><blockquote>即使公众对创始人产生了诸多质疑，但不影响Stability AI在文本生成图像领域的持续推进。</blockquote><p></p><p>&nbsp;</p><p>日前，Stability AI发布了SDXL 0.9，这是其 Stable Diffusion 文本到图像模型的最新版本，代表Stability AI文本到图像模型套件迎来了新的发展里程碑。</p><p>&nbsp;</p><p>继今年4月成功发布Stable Diffusion XL beta之后，SDXL 0.9在图像和构图细节方面继续做出大幅突破。SDXL 0.9是一款强大的工具，可用于在各种创意产业中创建高度逼真的图像。与之前的版本相比，此更新的模型对生成图像的质量和细节带来了重大改进。</p><p></p><h2>SDXL 0.9有哪些重大升级？</h2><p></p><p>&nbsp;</p><p>现在用户已可通过ClipDrop访问该模型，API也将在不久后推出。研究人员正在努力完善1.0版本，相关成果包括权重设置预计将在七月中旬与大家见面。</p><p>&nbsp;</p><p>SDXL 0.9在继续保持通过现代消费级GPU运行的能力之外，在生成AI图像的创意用例方面也实现了飞跃。SDXL能够为影视剧、音乐和教学视频生成超现实风格的创作结果，也具备在设计和工业用途中一展身手的水平。</p><p>&nbsp;</p><p>示例：</p><p>在SDXL beta（左）和0.9版本上以相同提示词进行测试，即可体现该模型在短短两个月内取得的重大进展。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/bd/bdad21d457f9f1fc99cb5491a7007e32.png\" /></p><p></p><p>提示词:&nbsp;美学、外星人拉在拉斯维加斯的人群中，粗砺的胶片摄影</p><p></p><p>(左图 - SDXL Beta, 右图- SDXL 0.9)</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3e/3e06ea34de4c3dba79dfd4cf6793ed68.png\" /></p><p></p><p>提示词:&nbsp;优胜美地国家公园的狼，冷冽的自然纪实胶片摄影</p><p>负提示: 3d渲染、平滑、塑料、模糊、颗粒感、低分辨率、动漫、过饱和、奶油感</p><p>(左图&nbsp;- SDXL Beta, 右图 - SDXL 0.9)</p><p>&nbsp;</p><p>SDXL系列还提供一系列超出基础文本提示的功能。其中包括图像到图像提示（输入一张图像，以获取该图像的更多变体）、填充（重建图像内的缺失部分）和外延（根据现有图像无缝向外扩展）。简单来说，它可以让用户更有创意，以更高级有趣的方式对图像进行更改。</p><p></p><h2>SDXL 0.9 背后的力量</h2><p></p><p>&nbsp;</p><p>那么，SDXL 0.9的底层技术到底是怎样的？</p><p>&nbsp;</p><p>据Stability AI介绍，SDXL 0.9之所以取得重大进展，核心驱动因素在于参数数量（模型训练时神经网络中所有权重和偏差的总和）较Beta版本有了显著增加。</p><p>&nbsp;</p><p>SDXL 0.9是目前所有开源图像模型中参数量最大的模型之一，基础模型拥有35亿参数，模型集成管线拥有66亿参数（最终输出由两套模型的运行聚合结果创建而成）。管线的第二阶段模型，专门用于向第一阶段模型生成的输出添加更多精巧细节。</p><p>&nbsp;</p><p>相比之下，之前的beta版权拥有31亿参数并使用单一模型。</p><p>&nbsp;</p><p>SDXL 0.9运行在两个CLIP模型之上，其中包括迄今为止训练的最大OpenCLIP模型之一OpenCLIP&nbsp;ViT-G/14。它增强了SDXL 0.9的处理能力，使其能够创建出更具深度和1024 x 1024更高分辨率的逼真图像。</p><p>&nbsp;</p><p>SDXL团队将很快发布一篇研究博客，详细介绍该模型的规格和测试情况。</p><p>&nbsp;</p><p>尽管具有强大的输出和更先进的模型架构，但SDXL 0.9仍能够在现代消费级GPU上运行。具体配置要求为：</p><p>&nbsp;</p><p>Windows 10或11/Linux操作系统；16 GB内存、英伟达GeForce RTX 20系列显卡（或更高版本）且至少配备8&nbsp;GB显存；Linux用户也可以使用配备16 GB显存的AMD兼容显卡。</p><p></p><h2>测试版发布期间获得积极反响</h2><p></p><p>&nbsp;</p><p>Stability AI 因于 2022 年 8 月推出开源图像生成器 Stable Diffusion 而闻名，进一步加剧了其与 OpenAI 的 Dall-E 和 MidJourney 的竞争。</p><p>&nbsp;</p><p>近日，Stability AI 刚被《时代》周刊评为2023 年最具影响力的公司之一。其他出现在榜单上的人工智能公司还有OpenAI（ChatGPT）、Hugging Face（协作开源人工智能平台）、Runway AI（生成视频）、Nvidia和谷歌DeepMind。</p><p>&nbsp;</p><p>自4月13日SDXL&nbsp;beta版发布以来，Stability AI在Discord社区上收到近7000名用户的热烈响应。用户们生成了超过70万张图像，平均每天超过2万张。超过5.4万张图像进入Discord社区的“Showdowns”评选，最终有3521张SDXL图像被评为优秀作品。</p><p></p><h2>可用性和未来计划</h2><p></p><p>SDXL 0.9现已在Clipdrop by Stability AI平台上发布。Stability AI API及DreamStudio客户端将于6月26日星期一开放该模型，同时提供NightCafe等其他领先的图像生成工具。</p><p>&nbsp;</p><p>SDXL 0.9目前暂时仅供研究学习目的使用，希望在全面发布前收集反馈并充分完善模型。相关代码后续将在GitHub（<a href=\"https://github.com/Stability-AI/generative-models\">https://github.com/Stability-AI/generative-models</a>\"）上公开。</p><p>&nbsp;</p><p>如果研究人员希望访问这些模型，请通过以下链接申请：SDXL-0.9-Base模型（<a href=\"https://huggingface.co/stabilityai/stable-diffusion-xl-base-0.9\">https://huggingface.co/stabilityai/stable-diffusion-xl-base-0.9</a>\"）、SDXL-0.9-Refiner（<a href=\"https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-0.9\">https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-0.9</a>\"）。</p><p>&nbsp;</p><p>Stability AI一再强调，目前SDXL 0.9仅用于研究学习目的。</p><p>&nbsp;</p><p>SDXL 1.0计划在今年七月中旬（时间选定）全面发布。SDXL 0.9遵循非商用、仅供研究的许可证发布，并受相关使用条款的约束。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://stability.ai/blog/sdxl-09-stable-diffusion\">https://stability.ai/blog/sdxl-09-stable-diffusion</a>\"</p><p>&nbsp;</p>",
    "publish_time": "2023-06-26 14:07:10",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "ChatGPT再次成为焦点：学生放弃导师，改用ChatGPT自学！科技与狠活席卷高校？",
    "url": "https://www.infoq.cn/article/aM5zaAOM7aGEsmNHIXxs",
    "summary": "<p>据外媒报道，近日，知名高等教育规划平台<a href=\"https://www.intelligent.com/\">Intelligent.com</a>\"的一项<a href=\"https://www.intelligent.com/new-survey-finds-students-are-replacing-human-tutors-with-chatgpt/\">调查显示</a>\"，学生和家长越来越喜欢使用<a href=\"https://venturebeat.com/ai/mind-your-language-risks-using-ai-powered-chatbots-chatgpt/\">ChatGPT</a>\"而不是真人导师来进行学习了。</p><p>&nbsp;</p><p>调查结果显示，学生对教育援助的看法发生了重大的转变。在最近的学年中，85%的高中生和大学生同时使用了ChatGPT和传统辅导课程，他们断言<a href=\"https://qcon.infoq.cn/202309/beijing/track/1557\">ChatGPT</a>\"作为一种学习工具在有效性上超越了传统辅导。</p><p>&nbsp;</p><p>同样，96%的学龄儿童的父母也持有这种观点，他们坚信使用ChatGPT来进行学习可以为他们的后代带来更好的效果。</p><p>&nbsp;</p><p>对ChatGPT的这种信心导致了一个显著的转变：39%的学生和30%的家长已经完全用这个人工智能平台取代了他们的辅导课程。</p><p>&nbsp;</p><p>接受调查的家长确信，<a href=\"https://qcon.infoq.cn/202309/beijing/track/1559\">ChatGPT</a>\"的纠错能力有助于孩子获得更准确的学习体验。他们还报告称，他们的孩子更喜欢使用该软件来进行口语练习，从而显著改善了结果。</p><p>&nbsp;</p><p>“学生和他们的父母认为，ChatGPT是一种非常高效的学习工具，比传统辅导更方便、更高效，以至于许多人实际上已经放弃了辅导课程，转而使用ChatGPT。”</p><p>&nbsp;</p><p>Intelligent.com的高等教育顾问、伊萨卡学院战略传播教授Diane Gayeski在接受VentureBeat采访时表示。“家长们认为ChatGPT是一个很有吸引力的导师，因为它免费、随时可用，而且回答问题迅速。它非常擅长提供基本概念，甚至是提供代数、地理和外语等常见主题的练习题。”</p><p>&nbsp;</p><p>这项研究收集了来自3017名高中生和大学生以及3234名年轻学生家长的反馈。在这些参与者中，有801人来自美国。</p><p>&nbsp;</p><p>对于学生受访者，采用了严格的人口统计过滤器，以确保他们的年龄在16至24岁之间，并确保他们在就业状况方面将自己定位为“学生”。至于父母，受访者也经过了严格的人口统计过滤，以确认他们至少有一个孩子，然后进行了初步筛查，以核实他们至少有一个读小学、初中或高中的孩子。</p><p></p><h2>学生认为使用ChatGPT能提高成绩和效率</h2><p></p><p>报告显示，几乎所有的学生都用ChatGPT来代替了一些辅导课程。十分之九的学生表示更喜欢使用ChatGPT来进行学习，而不是跟随导师一起学习。</p><p>&nbsp;</p><p>此外，调查结果还强调，在将ChatGPT纳入日常学习后，95%的学生和家长受访者都看到了学习成绩的提高。</p><p>&nbsp;</p><p>ChatGPT主要取代了数学和“硬”科学（如化学、生物学）等学科的辅导课程。</p><p>&nbsp;</p><p>“这可能是因为这些学科往往是技术性的，概念更难，而ChatGPT可以为这些类型的问题提供清晰、提炼的答案，这可以帮助学生掌握复杂的概念。”Intelligent.com的Gayeski告诉VentureBeat。“当然，这是假设学生有足够的背景知识来给ChatGPT提供正确类型的prompt。”</p><p></p><h2>ChatGPT真的有效吗？</h2><p></p><p>Gayeski指出，尽管调查清楚地表明了ChatGPT的受欢迎程度，但专家们普遍认为，它在短期内不会长期完全取代导师。</p><p>&nbsp;</p><p>“ChatGPT无法完成有经验的真人导师能做的所有事情，因为它依赖于用户输入良好的prompt。例如，如果我很难结合意大利动词，我可能会要求它进行一些练习。但真人导师是教授某个主题的专家。”Gayeski说道。“他们知道该问什么问题来评估学习者对内容的掌握程度，他们也可以诊断学生的错误理解并提供具体的反馈。”</p><p>&nbsp;</p><p>她强调，真人导师拥有关于标准化考试中常见问题类型的宝贵知识，并了解他们所在学区各科教师对作业的期望。</p><p>&nbsp;</p><p>Gayeski解释道：“导师可以为15岁的儿童量身定制示例。然而，虽然ChatGPT也可以提供此类示例，但用户必须具备有效表达请求的技能。”</p><p>&nbsp;</p><p>她怀疑，一个不喜欢生物学的青少年是否会擅长制定prompt，从而产生引人入胜的内容，并有效地评估他们对主题的掌握程度。</p><p>&nbsp;</p><p>Gayeski补充道：“通常，学生们在课堂上很吃力，因为他们无法预测老师可能会问什么样的问题来评估他们的知识。这就是为什么我们经常会听到学生们说，他们为了考试而努力学习，但仍然考得不好。在某些情况下，老师们希望从他们使用的文本中获得非常直接的术语或列表，而ChatGPT无法做到这一点。”</p><p>&nbsp;</p><p>她强调，尽管95%的学生和家长受访者报告称，自从将ChatGPT纳入到他们的学习日程后，成绩有所提高，但真人导师在提供结构方面仍发挥着至关重要的作用。</p><p>&nbsp;</p><p>“这就是为什么许多人在健身房使用私人教练的原因——这并不一定是因为他们不知道如何锻炼或使用器械，而是因为预约可以让人们从教练那里获得积极的反馈和鼓励，从而坚持住，培养毅力。”Gayeski说到。“为了获得有效的结果，ChatGPT完全依赖于用户输入良好的prompt。学生必须具备足够的背景知识才能给ChatGPT提供正确类型的prompt。”</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://venturebeat.com/ai/chatgpt-takes-center-stage-students-ditch-tutors-in-favor-of-ai-powered-learning/\">https://venturebeat.com/ai/chatgpt-takes-center-stage-students-ditch-tutors-in-favor-of-ai-powered-learning/</a>\"</p>",
    "publish_time": "2023-06-26 14:32:38",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "扎克伯格和马斯克线上约架；马云：接下来是淘宝的机会；谷歌新广告嘲笑 iPhone 过时 | Q资讯",
    "url": "https://www.infoq.cn/article/hOHFSJ7zHp5NUM09EWjA",
    "summary": "<p></p><p></p><h2>科技公司</h2><p></p><p>&nbsp;</p><p></p><h4>马云：接下来是淘宝的机会</h4><p></p><p>&nbsp;</p><p>据报道，5月下旬，阿里巴巴创始人马云召集淘天集团各业务负责人，开了一场小范围内的沟通会。马云判断，接下来是淘宝而不是天猫的机会，阿里电商应该“回归淘宝”。马云在会上称，阿里过去那些赖以成功的方法论可能都不适用了，应该迅速改掉。他为淘天集团指出了三个方向：回归淘宝、回归用户、回归互联网。此外，马云认为淘天在组织上应该进一步扁平化。</p><p>&nbsp;</p><p>据多位阿里员工转述，马云认为淘天集团当前面临的竞争局势十分严峻，他以诺基亚和柯达举例，认为一个企业从行业标杆到死亡，半年到一年就足够了，在互联网行业这个速度可能会更快。</p><p></p><h4>阿里巴巴重大人事调整：蔡崇信接替张勇</h4><p></p><p>&nbsp;</p><p>6月20日消息，阿里巴巴控股集团董事会主席兼 CEO 张勇通过全员信宣布，他将于今年9月10日卸任阿里巴巴集团董事会主席兼 CEO 职务，继续担任阿里云智能集团董事会主席兼 CEO。蔡崇信将出任阿里巴巴控股集团董事会主席；吴泳铭出任阿里巴巴控股集团 CEO，同时继续兼任淘天集团董事长。</p><p>&nbsp;</p><p>据悉，蔡崇信现任阿里集团执行副主席，是公司创始人之一，他曾担任集团十几年的 CFO，并在2014年带领公司在纽约上市。吴泳铭同样是阿里集团创始人之一，有着深厚的技术背景，曾担任过 B2B、淘宝、支付宝等多个重要业务的 CTO，构建了相关业务的底层技术架构。</p><p></p><h4>扎克伯格和马斯克线上约架，两大科技领袖将上演笼斗大戏</h4><p></p><p>&nbsp;</p><p>本周早些时候，Meta 表示发布了代号为“92项目”的新产品。据悉，这款应用预计将被命名为“Threads”，旨在与 Twitter 竞争。马斯克随即毫不留情地进行了嘲讽：“我确信地球已经迫不及待地想完全受扎克控制了。”有人提醒马斯克注意他在扎克伯格面前的言论：“最好小心点，我听说他现在会柔术了。”马斯克回应道：“如果他真会，我准备和他来一场笼斗。”</p><p>&nbsp;</p><p>当地时间周三，特斯拉 CEO 马斯克在自己推特上表示，要和 Meta CEO 扎克伯格进行一场“笼斗”（cage fight）。扎克伯格转发了该推文的截图，并配文“把地址发给我”。Meta 发言人 Iska Saric 告诉媒体称，已确认扎克伯格发表的回复并不是在开玩笑。</p><p></p><h4>美图秀秀 CEO 回应 AI 冲击：已经是生死存亡之秋了</h4><p></p><p>&nbsp;</p><p>6月19日，在回应公司因 AI 到了“生死存亡之秋”时，美图创始人、董事长兼 CEO 吴欣鸿表示在他看来，AI时代美图机会与挑战并存，“机会要看我们能不能抓得住，但挑战是实实在在存在的。”</p><p>&nbsp;</p><p>3个月前，一张流传甚广的微信聊天截图侧面透露出AI给美图带来的冲击：“我在厦门本来要约美图秀秀的人，结果他们说公司因为 AI，已经是生死存亡之秋了，没空见。”</p><p></p><h4>“618”各平台均未公布销售战绩，全网销售总额增速至近3年最低</h4><p></p><p>&nbsp;</p><p>今年“618”促销节落下帷幕，各平台均未公布今年官方销售额数据。据不完全统计，京东、淘宝天猫、苏宁易购和拼多多均未公布各自“618”官方销售总额，仅表述为文字概述或部分销售情况。其中京东发布“增速超预期，再创新纪录”成绩单总结，淘宝天猫、苏宁易购和拼多多也分别对部分成交额和订单量等公布最新数据。</p><p>&nbsp;</p><p>今年“618”全网商品交易总额达7987亿元，创近6年来新高，较去年多1028亿元，比2019年增长4806.25亿元，但增速已连续3年放缓，今年同比增长仅14.77%，增速降至近3年来最低点。</p><p>&nbsp;</p><p></p><h4>国内多个大语言模型通过算法备案</h4><p></p><p>&nbsp;</p><p>根据网信办公布的《境内深度合成服务算法备案清单》，截至 2023 年 6 月，阿里、腾讯、百度、美团、快手等公司的 40 个算法通过备案，包括图像合成、语音合成（智能客服场景）以及文本生成等算法。</p><p>&nbsp;</p><p>备案清单中也有多个大型语言模型，包括智谱华章的智谱 ChatGLM 生成算法、百度 PLATO 大模型算法（不是文心一言）、达摩院开放域自然对话合成算法（不是通义千问）、讯飞星火认知大模型算法等，市场上开始出现大模型驱动的生成式人工智能产品即将落地的猜测。目前，《生成式人工智能服务管理办法》还没有正式发布实施。</p><p></p><h4>腾讯首次披露行业大模型进展：不追求参数高，希望成本预算可控</h4><p></p><p>&nbsp;</p><p>近日，腾讯首次对外披露行业大模型研发进展，发布依托腾讯云TI平台打造行业大模型精选商店，为客户提供 MaaS（Model-as-a-Service）一站式服务，助力客户构建专属大模型及智能应用。</p><p>&nbsp;</p><p>腾讯云副总裁、腾讯云智能负责人吴运声日前接受采访时表示，“目前大模型和产业结合还在早期阶段，随着算力发展速度不断提高，行业对大模型的理解程度也在不断加深。”吴运声称，希望能以最低的成本、最合适的模型和最好的服务把大模型真正做好，会在预算和成本可控的情况下提供最符合逻辑的模型，让其在场景中达到目的，解决问题。吴运声也透露，目前腾讯云行业大模型能力已在腾讯企点、腾讯会议、腾讯云AI代码助手等多款产品中落地使用。</p><p></p><h4>微软在香港正式推出 Bing 聊天机器人</h4><p></p><p>&nbsp;</p><p>6月22日，据报道，微软在香港正式推出 Bing 聊天机器人，用户不用再每日储分数、排队等待，只须使用 Microsoft Edge 浏览器，即可直接使用聊天机器人。微软在网页表示，Bing 由AI提供支持，可以了解并产生文字和图像，因此可能会出现意外和错误。请务必查核事实，和分享意见反应，让 Bing 可以学习及改进。根据聊天机器人回答，Bing 是使用OpenAI 的 GPT-4.0 模型，是一个自然语言处理模型，可以理解和回答问题。</p><p></p><h4>谷歌新广告嘲笑 iPhone 过时</h4><p></p><p>&nbsp;</p><p>谷歌本周推出了一系列幽默的 Pixel 手机广告，嘲笑苹果的 iPhone 手机已经过时，无法与 Pixel 手机的新功能相比。</p><p>&nbsp;</p><p>这些广告以“BestPhonesForever”为标签，暗示 Pixel 手机是最好的手机，而 iPhone 手机只是曾经的辉煌。这个广告中，iPhone 手机嫉妒地数落 Pixel 手机的各种功能，Pixel 手机展示了其最新功能 —— 折叠，而 iPhone 则震惊地晕倒了。“现在是哪年了？我们有飞行汽车了吗？”iPhone 问道。</p><p></p><h4>OpenAI 考虑为人工智能软件创建应用程序商店</h4><p></p><p>&nbsp;</p><p>6月20日消息，有知情人士称，<a href=\"https://www.infoq.cn/article/ibZCSBmGqUt6UsOvRZX3\">OpenAI </a>\"正在考虑为人工智能软件创建一个应用程序商店，供客户向企业出售定制的AI模型。</p><p>&nbsp;</p><p>据悉，OpenAI 首席执行官山姆·阿尔特曼上个月在英国伦敦与开发者的一次会议上披露了潜在计划。OpenAI 的一位发言人表示，公司并未积极寻求开发上述市场，此外对“阿尔特曼同开发者开会”的报道内容不予置评。</p><p></p><h2>IT业界</h2><p></p><p></p><h4>苹果推出 VisionPro 开发者工具，7月起在上海等地提供实践体验</h4><p></p><p>&nbsp;</p><p><a href=\"https://www.infoq.cn/article/BhAJ2DJhhH73fB7zpfl6\">苹果</a>\"宣布，为加速 Apple Vision Pro 的开发推出开发者工具。不仅包含 visionOS 软件开发包，还可于7月起在上海等地开设的开发者实验室进行实际体验，加速迭代自己开发的 App。</p><p>&nbsp;</p><p>从现在开始，全球苹果生态开发者将可利用 Vision Pro 的无限空间打造一类全新的空间计算 App，无缝融合数字内容与实体世界。依托 visionOS SDK，开发者可利用 Vision Pro 与 visionOS 独特的功能打造涵盖效率、设计、游戏等多种类别的全新 App 体验。</p><p>&nbsp;</p>",
    "publish_time": "2023-06-26 15:10:59",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "52家企业，48家要降本：FinOps 能否拯救“下云潮”",
    "url": "https://www.infoq.cn/article/1XBepSHeJPTzd0IVdfcb",
    "summary": "<p></p><p>“2020 年起，我们走访了很多客户，发现大家云资源的使用其实并不是很好，浪费很严重。”<a href=\"https://www.infoq.cn/article/91E8yFsbE71OuM3ioLAF\">腾讯云 </a>\"FinOps 产品负责人孟凡杰说道。今年初的一个月，腾讯云原生团队集中走访的 52 家客户中，48 家有降本需诉求，企业不只关心产品新能力，反而对降本能力更感兴趣。</p><p></p><p>近几年，企业为了迅速发展，上云时很少考虑过成本问题，即使有企业有成本控制的意识，但上云带来的整个预算模式的改变，也让企业在实践中感到无从下手。</p><p></p><p>传统 IDC 是强管控的模式：企业先做年度预算，然后集中采购硬件设备再放到机房，这个周期很长，而且期间通常不会再增加新的设备。但云计算改变了这种模式：云厂商通常会无限提供云资源，这相当于取消了资源管控。</p><p></p><p>现在，越来越多的云资源由边缘化团队来购买，每个人都可能发生采购行为，比如工程师做一次自动化扩容可能就会有一次采购。原来传统的集中式采购变成了分布式采购。但这种采购方式很难集中管控，如果缺乏预算管理、配额管理，那么很多人同时采购就会造成浪费。</p><p></p><p>同时，云上资源的计费模型非常灵活，有的按年或月计费，有的按量计费，可能预付费也可能后付费，最终导致企业的云帐单有成千上万条，甚至可能上十万条。面对这些多账单，财务部门很难核对这些钱的去处，因此也很难做后续的管控。</p><p></p><p>FinOps 基金会分享过国外某企业的真实案例，开始企业只顾技术创新，积极上云，不顾成本。直到有一天，高层介入喊停：“这个云不能再上了，成本已经远大于收益了！”。该企业因为成本失控导致上云进度延迟两年，严重影响企业技术创新。</p><p></p><p>2021 年开始，很多企业把成本降低、利用率提升变成了公司关键的 OKR，指导云财务管理的 FinOps 理念便吸引了大家的注意，并开始用这个理念做云成本优化。</p><p></p><h3>FinOps 没有特定技术栈</h3><p></p><p></p><p>FinOps 的历史并不悠久，公有云早期用户 Adobe 和 Intuit 在 2012 年首次描绘出了 FinOps 的雏形。FinOps 本质上是一个理论框架，没有特定的技术栈，其方法论来自各个云厂商最佳实践的整合和抽象，从组织流程、识别浪费、优化措施等方面给出建议。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a5/a5c97471e96b53dfe22e91f608bd9cf1.png\" /></p><p></p><p><a href=\"https://www.infoq.cn/article/5sguhHPR6futW9Cc8DwK\">FinOps 基金会</a>\"的这张图被引用了很多次，图里简单列出了 FinOps 理论的原则、目标和参与方等。</p><p></p><p>FinOps 理论的最终目的是要最低的成本来创造最大的价值，但这个理论非常抽象。简单来说，FinOps 理论倡导开发团队、运维团队、业务团队和财务团队彼此合作，数据驱动，构建成本可视化能力，并将成本考核分配给每个团队和项目。FinOps 理论指出了成本优化的三个阶段：成本感知节点关注成本可视化、成本分摊等；成本优化阶段可聚焦目标制定，然后通过费率优化和用量优化来节省成本；运维阶段通过持续优化流程、规范和资源运营手段等实现持续成本优化。FinOps 还有一些成熟度评估模型，来评估企业做得好不好。</p><p></p><p>孟凡杰表示，FinOps 主要涉及三个方面：第一，财务管理层面，做成本分摊和成本可视化，将云账单上的成本分配到业务单元，并提供可视化能力；第二，经营管理层面，把云资源进行盘活，将采购的云资源的利用率达到最高；第三，制定成本优化措施，平台侧和业务侧的开发运维人员配合做相应的优化动作。</p><p></p><p>这三个方面牵扯广、执行难，是一个需要拉动企业全员参与的系统工程，因此成功的前提是组织目标的高度对齐，全员经营意识的建立，组织坚定的执行力和不断提升的执行效率，实践的本身就是对组织效率的大练兵。</p><p></p><h3>开源还是商业化？</h3><p></p><p></p><p>云原生技术栈跟 FinOps 息息相关，云原生本身对工作负载、业务归属等信息非常清晰，又基于统一的监控、统一的 API，所以面向云原生的 FinOps 很容易定义一些标准化模型和组件。</p><p></p><p>不过，目前 FinOps 相关的开源项目不是特别多。OpenCost 目前是 CNCF 沙盒项目，开源的部分希望能够在成本模型领域形成统一共识，优化能力收费，背后是商业化公司 Kubecost。腾讯 2021 年开源的 Crane 是 FinOps 基金会首个开源认证方案，不仅定义了成本模型，也定义了全球首个面向云原生应用的碳排放模型，同时提供了面向业务的资源配置优化建议、面向平台的调度优化能力和面向差异化 SLA 业务的混部能力。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/34/34baa9275391afd3ac34e70181619937.png\" /></p><p></p><p>FinOps 开源产品<a href=\"https://www.infoq.cn/article/P73fOXwEPXOXlYjUDlGT\"> Crane</a>\" 的架构展示</p><p></p><p>在孟凡杰看来，开源产品是厂商中立的。“开源产品通常是通用技术，面向的场景很窄的话不会有很多人拥抱这个项目。而开源项目所使用的通用技术，可以支持在腾讯、华为、阿里、AWS 等云原生平台上面运行。”</p><p></p><p>除了开源，现在更多的是各厂商提供的商业化产品，尤其国外跨厂商提供 FinOps 产品的公司非常多，如 CloudZero、ProsperOps、Harness、Densify 等，生态更加丰富。</p><p></p><p>孟凡杰介绍道，云商业化产品通常跟自身的内部基础架构息息相关，比如腾讯的商业化产品更多立足于腾讯内部上下产品的全栈打通，追求一个极致的利用率。</p><p></p><p>孟凡杰举例道，混部场景下的 TencentOS，利用率达到 60%、70% 时，对在线业务的干扰率依然低于 1%，这在开源技术上很难做到。“所以，如果一个企业的资源利用率目标是 30%，开源产品可能是一个可选项。如果企业希望得到极致的利用率，那商业化产品是更优的选择。”</p><p></p><p>那么，商业化产品会产生厂商锁定问题吗？孟凡杰对此表示，Kubernetes 基于统一 API，天然支持多云，FinOps 商业化产品支持多云也是可以的，由上层调度层抽象 API，并适配每个厂商的内核能力即可。</p><p></p><h3>企业如何实践</h3><p></p><p></p><p>实际上，各厂商的实践是优先于 FinOps 理论的，是厂商的反馈和抽象形成了 FinOps 理论。拿腾讯来说，其数年前就开始盘整闲置资源加入统一调度平台，通过货币化结算做精细化运营，通过考核方式推动业务资源利用率提高。这些经营手段在 FinOps 系统理论出现之前就已经存在，但在 2021 加入 FinOps 基金会以后，随着对 FinOps 理论的更加深入的理解，腾讯才意识到这与 FinOps 的概念不谋而合，并这些实践经验回馈给社区，进一步丰富 FinOps 理论框架。</p><p></p><p>现在，虽然像得物、作业帮这样的先行企业有了优秀的实践成果，但总体来看大部分企业还是处在比较早期的阶段，并不知道如何去做这件事情。</p><p></p><p>《FinOps 云成本优化》（《Cloud FinOps》）一书指出，成功的 FinOps 实践包括三部分：实时报告 + 即时流程 + 团队协作 =FinOps 实践。在孟凡杰看来，在具体实践之前，一项重要工作就是企业必须在战略层面确认成本优化是不是全公司自上而下的共同目标。</p><p></p><h4>先有共识</h4><p></p><p></p><p>根据孟凡杰的经验，有些企业并没有将 FinOps 作为公司自上而下的战略目标去执行，只是某个团队自己去实行，这种情况往往不会成功，因为这个团队没有拉通所有团队来理解和配合，自然也不会有结果，毕竟“业务稳定性高于一切”是无法反驳的真理。</p><p></p><p>团队协作重要性的本质在于，FinOps 实践更多是一种涉及到各个部门的企业文化重塑：</p><p></p><p>管理层，常为 CIO、CTO 或事业群负责人，介入制定公司战略目标，确定职责边界，确保公司员工认同理念并愿意配合执行，保证团队的执行效率。FinOps 专业团队，真正推动整个事情的核心团队，主要职责就是定义原则和最佳实践，制定考核机制，并指导大家怎样实践并达成目标。面向用户业务的产品负责人或类似角色，对业务中产生的收益和成本负责，确保投入产出比保持在较高水平。工程运维团队，需要花费很多精力来建设整个支撑系统。比如自动扩缩容该怎样分配成本、怎样识别闲置资源、怎样优化，成本监控体系的建设等等都要技术支撑。因此，无论是面向平台还是业务，都需要工程运维团队的支持。财务和采购团队。财务团队主要保证财务安全，确保每个业务部门不超支。采购团队统一谈判和采购云资源，借此享受较好的折扣等。</p><p></p><p>上述目标对齐后，企业需要做文化建设，让大家理解为什么成本这么重要、为什么每个人都要为成本负责。当大家达成共识后，企业要建立面向成本的考核机制，用考核的方式推动和执行。</p><p></p><p>“在整个流程中，谁来牵头拉通不同的团队、谁定目标、谁推动执行等等都要明确，只有大家配合好，再加上产品能力的支持，这件事情才能做好。”孟凡杰说道，“初创型公司可能业务部门、平台运维可能就是一个团队，这种可以直接闭环搞定。但对于一定规模的企业来说，内部角色划分比较明确，通常需要一系列的机制保证。”</p><p></p><h4>面向成本的监控</h4><p></p><p></p><p>相比传统平台，云原生平台在运行某个工作负载时就会定义该工作负载属于哪个部门的哪个产品下的哪个项目，类似带上了业务属性标签。做数据采集时，企业可以把这些标签一起采集下来形成监控指标，再基于业务属性归类和汇总，这是虚拟机时代没有办法轻易做到的。</p><p></p><p>但业界一直缺少细粒度的成本可视化。很多云原生平台是混合调度平台，相当于一个账户购买资源，不同的业务共用该资源池。理论上，资源共享意味着高利用率、低成本，但数十或数百个业务共用一个资源池，很难分清楚每个业务用了多少。另外，研发人员在用资源时候也会偏向选择最好规格的资源，买最大规格、性能最好的。但很多时候，真实需求远低于预期。</p><p></p><p>面向 FinOps 的监控系统会有很多成本指标，包括利用率、申请量等多个维度。</p><p></p><p>只看利用率层面，FinOps 监控跟传统监控会有一些差异。传统的运维监控通常以稳定性为目标，利用率越低说明系统资源越充足，系统越不会出问题。一旦把成本作为监控目标，监控思路就不一样了：利用率越低，意味着浪费越严重。可以看出，两者的监控目标是完全相反的。</p><p></p><p>面向成本的监控，不仅看峰值还要看均值，当峰值来临的时候有资源保障，峰值过去能及时把资源退回，这样总体的平均利用率才会提升。所以，均值利用率也是一个重要的考核目标。</p><p></p><p>FinOps 的指导理论是越及时越好。腾讯内部现在每天上报资源数据、利用率数据和核算数据，第二天就会在绩效看板中呈现各种数据，如利用率、成熟度、核算数据等，每个业务的负责人、平台成熟度负责团队和个人都要为结果负责，促进大家去做实时决策。</p><p></p><p>孟凡杰坦言，成本确实给了大家非常大的压力，但这样的压力却是必要的。比如系统的一些 Bug 造成资源飙升，如果每天多采购 1000 核，一个月就是 30000 核，造成了很大的浪费。“可能不需要每天盯看板，但需要有监控告警机制及时发现问题，避免长周期浪费。”</p><p></p><p>当然，频次越高的实时数据意味着建设成本和运营成本越高，所以体量越大的企业，从中获得的收益也会越高。</p><p></p><h4>找到投入产出的平衡</h4><p></p><p></p><p>优化永远没有尽头，企业要找到一个平衡点，判断投入产出比。优化过程中要抓大放小，哪里浪费最严重就从哪里优化。</p><p></p><p>那么，企业需要优化到什么程度呢？孟凡杰表示，第一是看损益，如果一个业务亏钱就要一直优化，优化到不亏钱为止；第二个是看成熟度，比如成熟度的考核目标是 80 分，那不到 80 分就应该一直优化。当然，一个部门可能有多个业务，部分业务赚钱部分业务亏钱，如果整体损益是正的，也没问题。</p><p></p><p>在孟凡杰看来，任何企业都应该采用或参考 FinOps，并且在上云的第一天就应该有成本意识，成本控制越早越好。</p><p></p><p>“云上费用很多是按周期计费的，比如 12 月份和 1 月份去做相同的优化，1 月份做的话相当于前 11 个月都有节省。但拖到 12 月的话，前 11 个月的浪费就真实地发生了。”孟凡杰举例道，“在日常运营中，很多优化措施门槛非常低，不一定要留到某个时间点才去做优化。”</p><p></p><p>小规模企业由于人数较少，整个文化建设、目标对齐相对比较简单。也没有必要自己建设一套平台能力建设，可以使用 FinOps 能力相关的商业化产品或者开源项目解决。而很多大规模企业通常会自己建一套完整的流程和工具体系，包括考核机制、二次定价的货币化结算机制等，配合云上产品的 FinOps 能力实现成本优化。</p><p></p><p>当然，FinOps 实践中涉及到的大量的人力和流程成本问题。对此，Gartner 在去年发布的新兴技术趋势中提出了增强型 FinOps 理念，即 AI 驱动决策，AI 根据监控信息判断好坏、预测未来走势，并给出智能化建议。</p><p></p><h3>腾讯的实践</h3><p></p><p></p><p>腾讯有海量的自研业务，CPU 规模达到了 5000 万核，云成本优化总节省 30 亿元。下面，我们看下腾讯内部多年的 FinOps 实践。</p><p></p><p>FinOps 理念首先在腾讯内部已经从公司层面得到认可，降本增效是自研上云过程中重要的目标之一，并将这个目标给到了每个团队和部门进行考核。</p><p></p><p>腾讯内部海量自研业务上云过程中同时进行成本优化是全公司的共识，经过高层的充分授权，且设立了专门的运管团队从资源效能管理、目标设定、绩效追踪、进展推动等全面推进成本优化的落实。运管团队充当着 FinOps 专业团队的角色，没有运管团队的规划与推进，FinOps 就是空中楼阁，不可能走向成功。</p><p></p><p>腾讯内部构建了丰富的成本和利用率绩效看板，每天晾晒绩效，做得好或不好都会及时披露。腾讯内部的成本看板主要包括两个维度：第一个是哪个帐号买了哪些资源，第二个是哪些业务使用了这些资源，包括一些分摊细节。此外，还有面向平台和业务的利用率、成熟度等成熟度指标看板，主要了解资源大盘的整体情况，看投入使用部分用得好不好，同时盘活闲置资源、减少浪费。</p><p></p><p>平台侧提供的 FinOps 能力从以下几个角度助力业务和平台达成目标：</p><p></p><p>业务优化。在云控制台上提供了资源优化专项页面，基于业务的资源用量历史进行预测，构建业务资源画像，并给出资源优化建议。规格建议：通过对比业务资源的申请量和使用量，可以告诉业务可以节省的成本数据，然后业务可以通过系统的控制台直接做优化。弹性建议：比如某个工作日资源使用非常高，但周末基本没有流量，这时候周末就要缩容，这些业务也可以通过控制台自己优化。平台优化。云平台在进行业务调度时，提供了众多基于资源画像的调度能力。调度优化：提出了面向真实利用率的动态调度能力，管理员设定节点目标利用率，只要利用率还未达标，调度器就可以调度更多业务进来。混部能力：引入差异化 SLA，允许高优在线业务和低优近离线业务混部，压榨每一分算力，同时离线服务可以在发生资源竞争时立即让渡资源需求，实现对在线业务零干扰。</p><p></p><p>据悉，腾讯内部的在线业务通过调度优化手段把资源利用率拉到 48%，再加上离线混部，部分集群资源利用率可以达到 65% 以上。</p><p></p><p>资源运营最核心的目标就是降低单位成本，让云平台上的海量自研业务以更低的成本运行。但海量资源场景下的货币化定价与结算也并非易事。业务和地域的匹配度、不同代次的设备怎么支撑不同的业务、采购资源的最优购买、买了资源后如何做更好地售卖等等，这些因素都会影响最终的单价。同时，差异化定价也是牵引业务更高效的利用资源的有效手段。</p><p></p><p>云厂商下场做 FinOps 产品，部分人持有疑虑，他们觉得这其中的逻辑似乎是冲突的：企业努力省钱，云厂商帮着他们省钱的话，怎么盈利？目前腾讯的做法是在产品溢价与企业节省成本之间，定义一个双赢区间，通过技术赋能，实现企业成本降低、厂商净利提升的双赢。这种方式下，企业通常需要一定的试用期做 PoC，效果好的话才会做大规模生产部署。</p><p></p><p>这种做法目前在腾讯被验证是行得通的。孟凡杰透露，今年腾讯相关产品附加了 FinOps 能力后呈现了健康快速的增长趋势。</p><p></p><h3>结束语</h3><p></p><p></p><p>在 Google Trends 上，“FinOps”关键字的搜索量在 2019 年到 2023 年的四年间增长了 410 倍。在国外，有 18000 多人把 FinOps 技能列在了自己的 LinkedIn 简历里。</p><p></p><p>“我因为担任 CNCF 大使要公开 LinkedIn 资料，在加上了 FinOps 关键字后，一个月里面有十几个猎头问我，‘我这边有 FinOps 的职位，你愿不愿意聊一下？’”孟凡杰开玩笑说道。但可以看出，业界对 FinOps 人才是非常渴求的，孟凡杰感叹道，“有点像 Kubernetes 早期那几年了。”</p><p></p><p>FinOps 是大趋势，而且正处于快速发展的早期阶段，这也意味着很大的机会。比如很多企业开始实行多云战略，但云厂商提供的 FinOps 产品更多是面向自己的基础架构的，更广泛的跨云支持还没有起步，这给了中立的第三方很大机会。</p><p></p><p>对于企业来说，早期的实践和转变总会带来阵痛，实践者需要做好这样的心理准备。而 FinOps 未来如何帮助企业把云“用好”，还需要全行业的不懈努力和探索。</p><p></p><p></p>",
    "publish_time": "2023-06-26 15:25:59",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "红帽对 RHEL 下游造成毁灭性打击！停止公开企业版源代码，要挤占开源份额实现盈利？",
    "url": "https://www.infoq.cn/article/fSOuw5Oy9X9dNMzAOdvF",
    "summary": "<p></p><p>当地时间6月21日，红帽<a href=\"https://www.redhat.com/en/blog/furthering-evolution-centos-stream\">发布公告称</a>\"，停止向第三方提供 RHEL 源代码，CentOS Stream 将成为公共 RHEL 相关源代码发布的唯一仓库。红帽的客户和合作伙伴可以付费获得源代码，但无权二次发布这些代码。</p><p>&nbsp;</p><p>“在CentOS Stream之前，Red Hat将RHEL的公共资源推送到 git.centos.org 上。当CentOS项目转移到CentOS Stream上时，即使CentOS Linux不再是RHEL的下游构建，我们仍然维护这些存储库。CentOS Stream的参与、投资的工程水平以及我们为客户和合作伙伴解决问题的新优先级，使得现在维护独立、冗余、存储库的效率低下。”红帽核心平台副总裁Mike McGrath 在公告中表示。</p><p>&nbsp;</p><p>红帽的这一决定将影响 Red Hat Enterprise Linux（RHEL）的所有重建和分支，（<a href=\"https://www.theregister.com/2023/05/19/rhel_92/\">例如</a>\"AlmaLinux、Rocky Linux、EuroLinux 和 Oracle Unbreakable Linux），这些项目都依赖已发布的源代码。在无法访问所使用的源代码的情况下，保持与现有版本的 1:1 二进制兼容性会是很大的挑战。</p><p>&nbsp;</p><p>目前，各种线上论坛的下游发行版用户正在强烈抗议，气势不输几年前红帽宣布取消CentOS Linux之时，最常见的字眼包括“背信弃义”、“违反GPL”等等。“红帽做的事情很糟糕，但微软、IBM 和在后台运作的公司之间一直存在着一场更大的战斗。这是一个丑陋的局面，自由软件和开源被夹在中间。”有网友说道。</p><p>&nbsp;</p><p></p><h2>为了 Stream？</h2><p></p><p>&nbsp;</p><p>2020 年底，红帽宣布停更 CentOS 8 后，CentOS Stream成了CentOS 的替代品。在 Linux 生态中，一般认为&nbsp;Fedora 是中上游，CentOS Stream 是中游，RHEL 是下游。</p><p>&nbsp;</p><p>RHEL 是基于 Fedora 某个特定版本拉取分支，逐渐在这个版本上做增强，保证新旧版本之间的兼容性，并保证最终版本的稳定性。CentOS Stream 则与 RHEL 的版本相对应，其 Git 提交记录完全一致，二者通过同样的构建流程、同样的测试用例。但CentOS Stream 永远只对应 RHEL 最新的稳定版。只有通过全部的测试用例，CentOS Stream 新版本才会发布，这些测试用例与 RHEL 可能重合，也可能不重合。</p><p>&nbsp;</p><p>红帽决定停止向公众提供RHEL源代码，这个变化的区别在于：CentOS Stream 又是RHEL的上游，又代表着RHEL下个版本的发展方向。从这个角度看，红帽相当于把公布 RHEL 源代码调整为滚动发布 RHEL 的 beta 版代码。</p><p>&nbsp;</p><p>而Alma、Rocky 以及之前的 CentOS Linux 都属于RHEL的下游：使用同样的源代码重构而成以保证完美兼容。原本的业务基础，就是无需向红帽支付任何费用即可进行重构，使用相同的驱动程序并实现与RHEL应用程序间的完美兼容。</p><p>&nbsp;</p><p>但单纯开放CentOS Stream显然做不到这一点：它只是RHEL的未来预览版。如果企业希望在RHEL上开发产品或驱动程序，又或者想要提前把握RHEL的后续发展方向，那CentOS Stream倒是基本够用。但如果只想免费运行RHEL，则开放CentOS Stream可以说意义不大，更遑论构建自己的RHEL变体了。</p><p>&nbsp;</p><p>有媒体怀疑，红帽很清楚RHEL社区的用户其实并不关注Stream，这也正是此次调整想要达到的效果。</p><p>&nbsp;</p><p></p><h4>Fedora会不会受到影响？</h4><p></p><p>&nbsp;</p><p>Fedora的用户和贡献者们倒是不必担心，但Fedora-Devel邮件列表中也透露出了严重的不满情绪。</p><p>&nbsp;</p><p>Fedora位于RHEL的上游：在Fedora中开发和测试的软件会先流入CentOS Stream，之后再进驻RHEL。实际上，Fedora的大部分工作都是由RHEL完成的。如果说CentOS Stream就是RHEL的滚动beta版，那么Fedora就是RHEL的滚动alpha版。所以是RHEL在技术上依赖于Fedora，而非Fedora依赖于RHEL。原则上，Fedora仅仅是在经济层面倚仗RHEL的支持。</p><p>&nbsp;</p><p>Fedora还提供服务器版本，需要免费RHEL的红帽用户可以随意使用这些版本。最大的区别就是，Fedora始终基于较新的代码，所以与当前RHEL永远不会完全兼容。另外，Fedora也不提供稳定的长期支持版本。</p><p>&nbsp;</p><p></p><h2>下游发行商：乐观但不掩担忧</h2><p></p><p>&nbsp;</p><p>目前，Alma Linux和Rocky Linux的官方反应都表示谨慎乐观。</p><p>&nbsp;</p><p>“虽然这个决定确实改变了我们用于构建Rocky Linux的自动化，但我们已经创建了一个短期的缓解措施，并正在制定长期的策略。对于任何不稳定的Linux用户、合作者或合作伙伴来说，不会有任何干扰或改变。”<a href=\"https://rockylinux.org/news/2023-06-22-press-release/\">Rocky Linux官方</a>\"表示。</p><p>&nbsp;</p><p>“我相信开源应该始终免费且完全稳定。它不应该隐藏在付费专区后面，也不应该由一家公司控制。”Rocky Linux 项目的创始人、该项目的主办方 Rocky Enterprise Software Foundation 董事会主席 Gregory Kurtzer 表示。</p><p>&nbsp;</p><p><a href=\"https://almalinux.org/blog/impact-of-rhel-changes/\">Alma Linux官方</a>\"则表示，“短期内，我们将与 RHEL 生态系统的其他成员合作，确保我们继续以众所周知的速度和稳定性提供安全更新。从长远来看，我们将与这些合作伙伴以及我们的社区合作，确保 AlmaLinux 作为企业 Linux 生态系统一部分的最佳前进道路。”</p><p>&nbsp;</p><p>AlmaLinux 用户仍然可以获得该操作系统服务器的安全更新。短期内， AlmaLinux 计划停止 CentOS Stream 更新和 Oracle Linux 更新，以确保继续发布安全补丁。这些更新将经过精心策划，以确保它们与 RHEL 1:1 兼容，同时不违反红帽的许可，并将像所有其他版本一样进行审查和测试。</p><p>&nbsp;</p><p>但是， AlmaLinux 的论坛帖子则弥漫着担忧的情绪：“这对整个红帽生态系统造成破坏。”AlmaLinux 表示，在 AlmaLinux 操作系统的整个生命周期中，其与红帽建立了令人难以置信的合作关系，他们希望这种关系可以继续下去。</p><p>&nbsp;</p><p>“我们并不惊慌，因为我们使用AlmaLinux，而且你们从多年前就开始认真对待你们的产品（Cloud Linux）。我不怕。”在AlmaLinux 安抚社区的<a href=\"https://twitter.com/AlmaLinux/status/1671556693308604417?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1671556693308604417%7Ctwgr%5E037e2c41f570d40a057938191ae3617fc13476f4%7Ctwcon%5Es1_&amp;ref_url=https%3A%2F%2Fwww.itpro.com%2Fsoftware%2Fopen-source%2Fwhat-red-hats-source-code-restrictions-mean-for-businesses\">推文</a>\"下有支持者如是说道。</p><p>&nbsp;</p><p>早在2011年，红帽就调整过源代码包的分发方式，看起来就是专门给重构工作“挖坑”。但当时的举措并不成功，实际上只导致越来越多企业开始拥抱CentOS。</p><p>&nbsp;</p><p>有媒体在CentOS Stream 9发布时就曾断言，红帽犯下的最大错误就是力推CentOS Linux。此举相当于支持了跟自家付费商业产品竞争的免费方案，属于典型的“资敌”行为。这项计划不仅没能给甲骨文带来多大阻力，反而显著削减了RHEL的销售额。</p><p>&nbsp;</p><p>当时，下游发行商也找到了绕过限制的方法，而且规避的思路并不复杂。红帽恐怕也对新生代重构厂商的崛起感到了不安。</p><p>&nbsp;</p><p>虽然Rocky和Alma Linux背后的机构都属于非营利组织（Rocky来自由Greg Kurtzer创立并运营的公益企业），但有一说一，这两家的表现确实不错。就在上周，NASA授权在内部使用Rocky Linux；CERN和Fermilab等科研机构则选择使用Alma Linux。</p><p>&nbsp;</p><p>红帽倒是认为这些并不是什么大事，似乎都是在为自己的Stream市场普及率做贡献。但从实际效果来看，红帽在CentOS Linux被取消之后，一刻也没有放松对蓬勃发展的重构生态发起攻击。</p><p>&nbsp;</p><p></p><h4>难以获得源代码</h4><p></p><p>&nbsp;</p><p>目前开源之门还没有彻底关闭。预计每当有新的主要版本即将发布时，Stream都会定期与RHEL对齐同步。就是说当RHEL 11.0发布时，Stream将暂时与其保持同步，而下游发行版也能在相应的时间点获取代码副本，并构建起与RHEL大版本相兼容的产品。但目前下游生态面临的最大挑战是在各个主要版本之间，他们再无法获得源代码层面的小规模迭代和更新。</p><p>&nbsp;</p><p>有评论人士指出，用户可以注册免费红帽开发者账户，借此合法获取源代码。说得没错，但问题是大家需要签名同意才能获取账户，而许可协议中明确禁止对软件的重新分发。所以，哪怕下游发行版仍能获得软件源代码，实际上也无法拿来使用。虽然原则上可以做出实质性修改，再把修改后的结果共享出去，但RHEL兼容发行版能够存在的核心意义，就是避免大幅变更、保留“完美兼容性”。</p><p>&nbsp;</p><p>当然，下游发行商也可以选择“挨骂也要搞”的态度，硬着头皮继续推出自己的版本。而红帽一旦发现，至少也会立即封禁其订阅权限和账户。这必然掀起一场“猫鼠游戏”：下游发行商不断开设新的免费开发者账户，而红帽则通过跟踪和封禁违规者账户的方式予以还击。这显然不是什么可以长期持续的发展模式。至于最差的结果，发行商甚至可能面临起诉并就此消失。</p><p>&nbsp;</p><p>总而言之，获取源代码的途径并不能说没有，只是大部分受到非常严格地限制和管控。</p><p>&nbsp;</p><p></p><h2>遏制社区发展，转为企业利润？</h2><p></p><p>&nbsp;</p><p>虽然社区反映强烈，但单从事件本身分析，红帽的行为其实完全符合GPL条款，毕竟条款只要求向使用所构建二进制文件的群体提供源代码：换句话说，向付费客户群体提供源代码。关键在于要获取这些二进制文件，客户及免费账户的开发人员必须同意许可协议并遵守合同条款，而合同条款的优先级要高于代码所遵循的GPL许可证。</p><p>&nbsp;</p><p>从某种程度来讲，此举可以说是红帽公司2014年将CentOS收归专有这条逻辑线的延续。此项举措将收窄合法空间，仅留CentOS Stream一根“独苗”，其余重构项目将基本没有发展的可能。当然甲骨文除外，其拥有雄厚的资金继续支撑Oracle Linux，同时也能提供更便宜的企业支持合同、增强的Btrfs兼容内核等。</p><p>&nbsp;</p><p>外媒评价道，红帽的这一套组合拳已经打得相当熟练，在逐步干掉大部分克隆产品之后，他们应该会故伎重施、取消自家旗舰产品的官方免费版本。作为配合，红帽会提供免费beta版本，并在发布公告上大谈“这是为了鼓励社区参与”等看似积极的话语。但事实上，红帽真正想打击的其实是那波所谓“贪图便宜”的家伙。毕竟开发人员仍可以免费使用RHEL进行生产部署，只是最多仅可支持16台设备。</p><p>&nbsp;</p><p>如果此举最终导致Alma和Rocky等下游生态投入数年建立的企业和社区走向消亡，那么相应的市场空间可能会转化为IBM的利润，但也意味着公众舆论将对蓝色巨人猛烈开炮。</p><p>&nbsp;</p><p>自30年前成立以来，红帽就一直允许下游生态对其操作系统进行克隆和重构，就连早期Red Hat Linux也不例外。例如，Mandrake Linux就是由此起步，向Red Hat Linux引入了KDE桌面。当时红帽以违反Qt许可证为由，一举消灭了这股社区力量。除了IBM的股东，其他各方显然都不会认可这样的粗暴行径。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.redhat.com/en/blog/furthering-evolution-centos-stream\">https://www.redhat.com/en/blog/furthering-evolution-centos-stream</a>\"</p><p><a href=\"https://www.theregister.com/2023/06/23/red_hat_centos_move/\">https://www.theregister.com/2023/06/23/red_hat_centos_move/</a>\"</p><p><a href=\"https://www.infoq.cn/article/NGt234WtjgPOwITMlXWo\">https://www.infoq.cn/article/NGt234WtjgPOwITMlXWo</a>\"</p>",
    "publish_time": "2023-06-26 15:37:13",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从Microsoft Build ，我们看到了开发者的新机遇",
    "url": "https://www.infoq.cn/article/zAro9WUBP8PX3kaizO2N",
    "summary": "<p>身处智能化的时代，无论是企业还是开发者，大家都额外关注如何能够把握机遇，迎接时代浪潮。2023年6月15日，Microsoft Build中国圆满落幕。微软携手合作伙伴、技术社区的专家，共同展望下一代AI技术趋势，解读Microsoft Build全球大会新发布。</p><p></p><h1>AI技术将助力开发者迎接技术革命</h1><p></p><p>&nbsp;</p><p>在今年的微软Build上，微软发布了一系列AI全家桶，包括Azure OpenAI、Copilot Stack、开发工具到协作应用等领域，为开发者提供了AI应用的开发工具。微软大中华区首席运营官康容和微软生态伙伴事业部首席技术官徐明强博士分享了AI 技术爆发能为开发者带来哪些机遇。</p><p>&nbsp;</p><p>随着微软在Build&nbsp;2023大会发布一系列AI“全家桶”，微软将AI融入现有的软件和服务生态，大有All in AI的势头。拿Copilot来说，它可以帮助开发者处理很多重复性工作，康容在演讲中提到：GitHub Copilot已经上市超一年，全球每天有超100万个开发者在使用它，经调研，现在已经有超45%的代码是GitHub Copilot写的。在写新应用时，开发者可以将重复性的工作交由Copilot来处理。此外，微软还发布了Windows Copilot，该工具可以总结文本、控制系统设置、协助搜索等等，让每个人在PC上都可以拥有一个AI小助理，也彻底改变人类与计算机的交互方式。</p><p>&nbsp;</p><p>Copilot的出现向业界展示了应用开发带来的便利，但另一方面，大型语言模型能力的突破很大程度来源于对数据的处理，大多企业需要自己花时间归类本公司数据，以及其它数据库。此外，微软还发布了Microsoft Fabric大数据分析平台服务，可以让企业实现统一存储和计算、用户体验、数据治理、商务模式，形成企业的数据湖，让企业训练、使用、可以展示、分析的数据都被打通。为了确保安全合规，微软坚持\"负责任的人工智能\"原则，该原则包含隐私保障、可靠安全、包容、负责任、公平、透明六大原理。</p><p>&nbsp;</p><p>微软生态伙伴事业部首席技术官徐明强博士在演讲时谈道，他认为所有业务问题都可以拿来聊。在Copilot和丰富的数据之间，插件可以成为\"一座桥梁\"，数据资源通过插件能力带给Copilot。他认为，微软发布的超50个新功能有一个共同的主题，就是把业务问题转换成Chat问题。</p><p></p><h1>企业需要思考如何让 AI 技术与业务融合</h1><p></p><p>&nbsp;</p><p>微软大中华区Azure事业部总经理陶然在演讲时提到，AI时代会有两大改变，一是现有的APP都将会被AI重新改造，二是新的数字化APP的构建方式将被颠覆。</p><p>&nbsp;</p><p>未来可能通过两个Copilot 的交互，就帮用户把酒店、参观都预定完成了。这也是Copilot未来能联通整个世界的意义所在。利用AI完成智能任务的应用程序也会有很大变化，包括增强AI访问API的能力、检索有帮助的信息、执行新的计算、安全地帮助用户执行操作。他补充说，这些能力现在可能还达不到，但是是微软下一步的愿景。</p><p>&nbsp;</p><p>Copilot Stack把微软现有的Copilot经验、工具链开放出来，从应用层、交互设计到安全性等，开发者可以直接调用。企业用户还可以将私域数据和大模型进行整合优化，让Copilot以企业想要的交互的风格来回答问题。</p><p>&nbsp;</p><p>在基础模型层，微软已将大型语言模型GPT-1到GPT-4，都作为接口公布。此外，如果企业要自研大模型，微软也会提供Azure AI基础架构层，开放支持OpenAI的底层架构，帮助企业自研行业大模型。微软Azure OpenAI Plugins插件平台开放的是微软自己的插件，开发者可以互相调用。并且通过GitHub，微软提供了全栈功能，包括云服务、开发工具等。</p><p>&nbsp;</p><p>此外，微软的新产品Microsoft Fabric是一个统一的一站式分析平台，其整合了数据工程、数据整合、数据存储、数据科学、实时分析、应用可观测性和商业智能服务，所有这些都连接到一个被称为OneLake的数据仓储中。</p><p></p><h1>第二直播间，持续挖掘大会精彩看点</h1><p></p><p>&nbsp;</p><p>特别值得一提的是，为了帮助开发者将晦涩难懂的技术内容转换为更易理解、吸收的内容，InfoQ还特别联合微软策划了「第二直播间」。InfoQ极客传媒主编赵钰莹与微软公司副总裁、微软大中华区首席运营官康容和微软生态伙伴事业部首席技术官徐明强博士，共同对大会的主题演讲进行了深度剖析。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/b8/df/b8a074b01da7e169a9fc605caaf3f4df.png\" /></p><p>&nbsp;</p><p>在智能化时代下，康容也为开发者提供了建议，他认为每个人都可以作为使用者去尝试，理解怎么使用所谓大语言的模型来辅助自己的工作。对于新推出的Copilot，微软对其定义也是非常清晰的，回归到负责任AI的角度来看，AI永远是辅助、支持人工作的。</p><p>&nbsp;</p><p>但由于新技术层出不穷，开发者也难免会感到焦虑，如何才能紧跟时代步伐呢？徐博士在「第二直播间」也分享了自己的看法。他提到，资深开发者通过&nbsp;Copilot可以进一步提高生产力，将释放出的精力用于其他有价值的工作；对于新入门的开发者而言，&nbsp;Copilot可以保障代码的质量，助力其弥补与资深开发者的差距。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/d1/13/d13ebb0ac216a32e925501bf76c90d13.png\" /></p><p></p><p>除了对重磅内容进行解读，「第二直播间」还安排了一个新书发布的环节。《人、伦理、机器人：一本孩子写给孩子的书》首次在直播间亮相，几位新书的主创人员也在直播间分享了创作的历程和初衷。而这本书的特别之处在于，这是一本青少年自己为同龄人创作的人工智能读物，文章以漫画的形式，深入浅出地描绘了科技伦理相关的内容。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/db/db5b9b9fd2d2f351a13d27452f81f71d.png\" /></p><p></p><p>此外，微软Cloud Advocate卢建辉还在「第二直播间」对“代码对战”环节进行了解读，一同见证了&nbsp;AIGC开放社区、&nbsp;ChatU社区、&nbsp;IDCF社区、OpenVINO™中文社区、Power Platform中文社区、&nbsp;365学院、&nbsp;.NET中文社区等7家技术社区的现场PK。从生活到办公，从前端应用到后端编码能力，我们真切地感受到了技术在多样化的实际场景中的应用。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/00/29/00bdd5459614d102eb7e096dcf55ee29.png\" /></p><p></p><h1>写在最后</h1><p></p><p>&nbsp;</p><p>回顾本次Build大会，我们可以从微软提供的新一代人工智能产品、工具、应用程序中发现，其始终秉承着降低开发成本的原则，不断前行。可以说，微软是将人工智能技术融入到了核心业务中，让更多人能够与人工智能一起工作。如同萨提亚曾在演讲中提到，未来要让所有公司都成为技术公司。我们也有理由相信，随着以微软为代表的科技公司的不断探索，这样的愿景也终将能够实现。</p><p>&nbsp;</p>",
    "publish_time": "2023-06-26 15:55:02",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]