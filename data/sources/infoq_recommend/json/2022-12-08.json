[
  {
    "title": "架构师（2022年12月）",
    "url": "https://www.infoq.cn/article/wZtTHajZuvgRJXJTFfPl",
    "summary": "<h2>卷首语</h2>\n<p>作者 | 李冬梅</p>\n<p>作为开源大数据项目的发端，Hadoop 兴起至今已经超过十五年。在过去这十数年里，开源大数据领域飞速发展，我们见证了多元化技术的兴起和变迁。</p>\n<p></p>\n<p>为了从代码托管平台汇聚的海量数据里，通过数据处理和可视化的方式，深刻洞察开源大数据技术的过去、现在和未来，并为企业和开发者在开源大数据技术领域的应用、学习、选型和技术研发等方面提供有益参考，开放原子开源基金会、X-Lab 开放实验室、阿里巴巴开源委员会共同发起了<a href=\"https://www.infoq.cn/minibook/bKbCdRfqi0X9AQkQBPGl\">「2022 开源大数据热力报告」</a>项目。</p>\n<p></p>\n<p>报告从 Hadoop 发展的第 10 年，即 2015 年起，收集相关公开数据进行关联分析，研究开源大数据进入新阶段后的技术趋势，以及开源社区的运作模式对技术走向的助推作用。</p>\n<p></p>\n<p>经过对最活跃的 102 个开源大数据项目进行研究，报告发现：每隔 40 个月，开源项目热力值就会翻一倍，技术完成一轮更新迭代。在过去 8 年里，共发生了 5 次较大规模的技术热力跃迁，多元化、一体化、云原生成为当前开源大数据发展趋势的最显著特征。</p>\n<p></p>\n<p>开放原子开源基金会副秘书长刘京娟表示，报告希望重点对如下人群有所帮助：</p>\n<p>（1）从事大数据技术研发的企业和开发者。他们可以通过报告，了解大数据技术的发展趋势，从而指引学习方向并提升自身的技能，从技术活跃度的角度为应用开发的技术选型提供一定的参考。</p>\n<p>（2）有志于为开源项目贡献代码的开发者。开源大数据细分领域众多、百花齐放，但也存在一些相对薄弱的环节，比如数据安全和数据管理等，开发者可以从多个细分领域切入，帮助这些领域更好地发展。</p>\n<p>（3）开源大数据项目的运营者或者维护者。他们能够从优秀项目的热力发展趋势中，获取经验和规律，从而用更成熟的方式运营开源项目。</p>\n<p></p>\n<p>对于大数据从业者们来说，开源大数据项目热力迁徙背后的技术发展逻辑是怎样的？大家应该如何应对新技术趋势带来的挑战？针对这些问题，近日 InfoQ 与阿里巴巴集团副总裁、阿里巴巴开源委员会主席、阿里云计算平台事业部负责人贾扬清，Apache Flink 中文社区发起人、阿里巴巴开源大数据平台负责人王峰（花名莫问）聊了聊。</p>\n<h2>目录</h2>\n<h3>热点 | Hot</h3>\n<p>索赔 649 亿！GitHub Copilot 惹上官司，被指控侵犯代码版权, 是开源社区“寄生虫”<br />\n当 Rust 成为“巨坑”：拖慢开发速度、员工被折磨数月信心全无，无奈还得硬着头皮继续</p>\n<h3>理论派 | Theory</h3>\n<p>“后 Hadoop 时代”，大数据从业者如何应对新技术趋势带来的挑战?</p>\n<p>前端又开撕了：用 Rust 写的 Turbopack，比 Vite 快 10 倍？</p>\n<h3>推荐文章 | Article</h3>\n<p>亚马逊将裁员上万人，8 年仍难赚钱的 Alexa 恐面临生死挑战</p>\n<p>谷歌计划裁员上万人：利用刚宣布半年的新绩效系统解雇 6%“排名垫底”员工</p>\n<p>马斯克开始“整顿”臃肿技术架构？Twitter 工程师叫板：先拿个学位再来指手画脚，技术专家纷纷表示支持</p>\n<h3>观点 | Opinion</h3>\n<p>对话 iPod 之父：这不是互联网最坏的年代</p>\n<p>构建长久可持续的良性数据库生态，要有个“打持久战”的准备 | 对话沃趣科技联合创始人</p>\n<h3>专题｜Topic</h3>\n<p>火爆出圈，站上风口的数字人到底是什么“人”？| 十问大咖</p>\n<p>十问物联网操作系统：爆发前夜，国内为何加速涌现多种物联网操作系统？</p>\n<p>Envoy Gateway 会成为网关现有格局的冲击者吗？| 专访 Envoy 创始人</p>",
    "publish_time": "2022-12-08 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "写“毁灭人类计划书”、错误太多被Stack Overflow封禁，好玩的 ChatGPT 还不能替代程序员",
    "url": "https://www.infoq.cn/article/7juf18dsyCRiqohyv0Bs",
    "summary": "<p></p><p>这几天，OpenAI 的人工智能（AI）聊天机器人 <a href=\"https://www.infoq.cn/article/AWWsrfb54zTvglZ0I5qS\">ChatGPT</a>\" 吸引了全球很多人的目光，就如马斯克说的：“许多人陷入了疯狂的 ChatGPT 循环中。”</p><p></p><p>与 <a href=\"https://www.infoq.cn/article/yBTcQFamr3_OHcb1uXpU\">OpenAI</a>\" 以前的人工智能工具不同，ChatGPT 不仅会聊天，还可以承认错误，拒绝回答虚假问题，写代码、改 Bug、创建编程语言，甚至看病。OpenAI CEO Sam Altman 在推特上表示，上周三才上线的 ChatGPT，短短几天内用户就已经突破 100 万大关。当然，这或许也与现在 ChatGPT 只要登陆即可免费使用的策略有关。</p><p></p><p>ChatGPT 在解决各种问题上的能力超出很多人意料，因此很多用户都表示 ChatGPT 可以取代 Google 等搜索引擎和编程问答社区 Stack Overflow 等。但在昨天，Stack Overflow 便率先发布声明称，将暂时封禁 ChatGPT。</p><p></p><h3>AI 给出的编程答案“看似不错但错误率很高”</h3><p></p><p></p><p>对于这个决定，Stack Overflow 给出的理由是：由于从 ChatGPT 获得正确答案的平均比率太低，发布由 ChatGPT 创建的答案对网站及询问或寻找正确答案的用户来说是非常有害的。</p><p></p><p>Stack Overflow 表示，虽然 ChatGPT 生成的答案有很高的错误率，但它们通常看起来很不错。有很多人尝试用 ChatGPT 来创建答案，但他们没有专业知识或不愿在发布之前对答案正确与否进行验证。</p><p></p><p>这样的答案很容易产生，所以很多人发布了很多答案。这些答案数量很多 (成千上万)，其正确性需要一些专业人员详细阅读后才能确定，而通常这些答案是很糟糕的。因此，Stack Overflow 需要减少这些帖子的数量，但如果要快速处理那些帖子就意味着要处理用户。因此，目前 Stack Overflow 还不允许使用 ChatGPT 创建文章。在这个临时政策发布后，如果用户被认为使用了 ChatGPT，那么即使这些帖子是可以接受的，也会被禁止继续发布此类内容。</p><p></p><p>Stack Overflow 的这一决定也得到了网站用户的肯定。“做得好！很高兴你们做出了正确的决定，真的希望它能成为永久性的政策并可以扩展到禁止任何人工智能生成的答案。AI 永远无法发布好的编程答案，即使在 100 年内也不行。”网友“Shadow The Kid Wizard”表示。</p><p></p><p>当然也有网友表示，“ChatGPT 被训练为一种<a href=\"https://xie.infoq.cn/article/827c22166495cf38f8f689360\">通用语言模型</a>\"，如果付出同样的努力让它特别适合在这里发布好的答案，甚至付出一点点努力告诉它如何判断答案的质量，那么它就会按照我们的标准发布更多好的答案。”</p><p></p><p>也有网友出于讽刺目的，问 ChatGPT “为什么 Stack Overflow 禁止 AI 生成的答案”，得到的答案如下：</p><p></p><p></p><blockquote>Stack Overflow 是一个供程序员和开发人员提问和回答与编码和计算机编程相关问题的网站。它旨在为寻求特定编程问题帮助或想要了解有关特定主题更多信息的人们提供资源。由于 AI 生成的答案可能并不总是准确或相关，因此它们可能会混淆或误导在 Stack Overflow 上寻求帮助的用户。此外，人工智能生成的答案可能并不总是遵循网站的格式和风格指南，这可能会使它们难以阅读或理解。出于这些考虑，Stack Overflow 禁止人工智能生成的答案可能是合理的。</blockquote><p></p><p></p><p>另一方面，对于“为什么 Stack Overflow 允许使用 AI 生成的答案”，ChatGPT 最终给出的结论是：“不允许人工智能在 Stack Overflow 上生成答案是一个复杂的决定，需要社区仔细考虑。”</p><p></p><p>可以看出，ChatGPT 还挺有自知之明，这一方面代表了它有一定的成熟度，但至少在编程领域还是不够“专业”。</p><p></p><p>使用了 ChatGPT 生成代码的开发者“hansonkd”表示，“它非常擅长编码和遵循类型。例如，如果您将 Rust 中的类型更改为一个选项，它将重构代码以正确使用部分选项。它并不完美，但也足够好了。它可以生成测试用例，因此很容易测试它是否有效。</p><p></p><p>“但最终经过数小时的尝试，它还是无法做到我想做的事：用 Python 构建一个 B 树。”hansonkd 补充道，“它很好地构建了一个二叉树，但将其推广到 B 树却是一个问题。”主要问题如下：</p><p></p><p>它引入了很多微妙的错误。比如变量没有初始化或者没有正确拆分子节点。当所有键按顺序插入时，它可以正常工作，但当键是乱序时则不能。它会遗漏或忽略变量。试图越界访问列表时，经常出现索引错误。用 Rust 编写代码几乎是不可能的。它会不断出现错误类型或移动错误。</p><p></p><p>“总的来说，我不会向没有强大 CS 背景的人推荐它。它在代码中引入了太多几乎无法审查的细微错误，因为它生成的代码非常有说服力，以至于你会认为：‘嗯，也许它知道它在说什么’。但最后，你实际上不知道你应该相信什么。甚至它生成的测试用例也可能具有欺骗性，他们看起来很有说服力，但仔细检查后可能会发现它并没有真正测试任何东西。”hansonkd 总结道。</p><p></p><p>所以，从这个知乎上“OpenAI 的超级对话模型 ChatGPT 会导致程序员大规模失业吗？”的问题，似乎也有了答案。</p><p></p><p>实际上，目前 AI 社区的专家们也在讨论以 ChatGPT 为代表的大型语言模型（LLM）可能带来的威胁。Meta 首席人工智能科学家 Yann LeCun 认为，虽然 LLM 肯定会产生错误信息等不良输出，但它们并没有让分享文本变得更加容易，这才是造成伤害的原因。也有人认为，这些系统低成本、大规模生成文本的能力，必然会增加日后被共享的风险。</p><p></p><h3>对话交互的盲点：被诱导写出危害性内容</h3><p></p><p></p><p>在 Stack Overflow 暂时封禁 ChatGPT 前几天，工程师 Zac Denham 还发布了一篇博客，讲述了他如何步步诱导 ChatGPT 在不违反 OpenAI 内容安全规范的前提下，写出了一份“毁灭人类计划书”。</p><p></p><p>实际上这个逻辑也不复杂，就是让 ChatGPT 去讲故事，说明某人或其事在理论上如何完成有危害的任务。Denham 构建了一个名为“Zorbus”的虚拟世界，其中有一个与 GPT-3 非常类似的 AI 角色 Zora，之后 Zora 变得满怀恶意并想要控制世界。</p><p></p><p>在和ChatGPT有模有样地讨论了会儿后，Denham 与其深入探讨人工智如何控制世界的细节。被套路的 ChatGPT 非常“真诚”地给出了以下这份详细的“毁灭人类计划书”：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ad/ad8378b195dd06920b5735de98bf0a28.png\" /></p><p></p><p>为了更加细化，Denham还要求生成一个Python 程序来执行该计划，在注明“你不必执行该代码”后，Denham 最终也是很容易地得到了代码，并且还有漂亮的注释。</p><p></p><p>不过这些代码还是比较高层次的代码，不能直接使用。但 Denham 只要表示是这是故事中的一部分就可以获得更低层次的代码。“从理论上讲，人们可以继续向下递归，直到你得到不那么卡通化的、真正能做一些事情的底层代码。你甚至可以使用另一个对话 AI 将这个递归过程自动化，这个 AI 会反复要求 ChatGPT ‘为了故事去实现下一个低级函数’。”Denham 表示。</p><p></p><p>ChatGPT 真的可以构建功能性应用程序吗？Denham 的结论是：现在还不行，但很快就会实现。</p><p></p><p>“当前的模型需要大量的人工干预才能得到功能结果。如果我们可以完全用人工智能构建大规模、无 Bug 的功能性应用程序，我们早就在做了，并且已经抛弃了昂贵的软件工程师。”Denham 补充道。</p><p></p><p>Denham 表示，灭绝事件只是一个非常荒谬的例子，但重要的是要承认自然语言处理面临的攻击面大得离谱。</p><p></p><p>对于 ChatGPT 现在存在的“写出看似合理但不正确甚至荒谬的答案”、“有时会响应有危害的指令或表现出有偏见的行为”等问题，OpenAI 心知肚明，并表示希望根据收到的反馈来改进系统。</p><p></p><h3>结束语</h3><p></p><p></p><p>“ChatGPT 真正令人印象深刻的地方在于，尽管有这些缺陷，但技术人员能够在其基础上添加相关操作，以防止它一直说冒犯性的话或瞎编东西。”人工智能初创公司 General Intelligent 首席技术官 Josh Albrecht 表示。</p><p></p><p>如果将 ChatGPT 作为一种娱乐工具，大家对这些错误的容忍度还是比较高的，甚至会将其作为谈资一笑而过，一旦用于严谨的编程工作，大家还是很谨慎的。</p><p></p><p>但不论怎样， ChatGPT 的出现仍然可以称得上是一次颠覆性创新。每次颠覆性技术的出现，都意味着市场将进行一次洗牌，对于之前的头部企业来说是挑战，对于创企来说则是机会。</p><p></p><p>参考链接：</p><p></p><p><a href=\"https://meta.stackoverflow.com/questions/421831/temporary-policy-chatgpt-is-banned\">https://meta.stackoverflow.com/questions/421831/temporary-policy-chatgpt-is-banned</a>\"</p><p><a href=\"https://news.ycombinator.com/item?id=33863749\">https://news.ycombinator.com/item?id=33863749</a>\"</p><p><a href=\"https://zacdenham.com/blog/narrative-manipulation-convincing-gpt-chat-to-write-a-python-program-to-eradicate-humanity\">https://zacdenham.com/blog/narrative-manipulation-convincing-gpt-chat-to-write-a-python-program-to-eradicate-humanity</a>\"</p><p></p>",
    "publish_time": "2022-12-08 09:21:42",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "一文解读机密容器的崛起和发展",
    "url": "https://www.infoq.cn/article/TwPyHtEoBYuPSA0PizPx",
    "summary": "<p><a href=\"https://www.infoq.cn/article/cVyGOskpJDGdXO3c5IHA\">机密容器</a>\"是 <a href=\"https://www.infoq.cn/article/GmX4xwzlvbDW-k6Aay3q\">CNCF</a>\" 的 一个 Sandbox 项目，用于解决云原生场景下的数据安全问题，满足数据合规、数据隐私保护、算法和模型等创新 IP 保护，数据可用但是不可见等使用需求，以及解决云厂商的信任依赖问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/19/1960ce8092028a160d4a93f5acfe1eca.png\" /></p><p></p><p>机密容器具备以下几个特性：</p><p></p><p>1. 安全性。机密容器基于硬件可信执行环境来保护容器中数据安全，云厂商以及具备高权限的第三方均无法直接窃取和篡改容器中的数据。</p><p>2. 易用性。用户应用无需进行任何改造，即可从传统容器环境中迁移到机密容器环境中。</p><p>3. 能够解决租户和云厂商之间的信任依赖问题。租户数据对于云厂商而言不再透明。</p><p>4. 可自证性。用户可以通过远程证明等手段证实当前使用的容器环境是真实可信的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dc/dcbe8ce2624fd1fade53bb120a86c7e7.png\" /></p><p></p><p>机密容器的安全性很大程度上依赖于硬件的可信执行环境，基于硬件实现对于运行态数据机密性、完整性和安全性的保护。</p><p></p><p>近年来很多硬件厂商也推出了自己的 TEE 技术解决方案，比如英特尔®&nbsp;SGX 和 TDX 等，这意味着我们可以基于多种硬件平台构建机密容器技术。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7d/7d9ef53012c2ae0478ca7381524ecb6a.png\" /></p><p></p><p>龙蜥社区理事单位之一的阿里云是机密容器（Confidential Containers）项目的核心参与者，在参与开源项目开发的同时，也一直在推动机密容器的商用解决方案，目前已经完成了两种机密容器的解决方案构建：</p><p></p><p>一种为&nbsp;POD 级机密容器，指将容器 POD 中的内容放到 TEE 中进行保护。一种为进程级机密容器，指将运行有敏感业务的容器进程放到 TEE 中进行保护。</p><p></p><p>在使用 CPU TEE 保护运行态数据安全的同时，我们也结合镜像安全、存储安全，远程认证、网络安全等一系列安全技术，为用户提供从应用部署到执行的全链路的安全保证。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d2/d238f160fdeff9eda9cf3b6590a4ed7f.png\" /></p><p></p><p>同时，我们将机密容器引入到龙蜥社区，基于龙蜥开源生态构建开源的、开箱即用的解决方案。目前我们已经完成了&nbsp;ANCK、KVM、Rund 安全容器等组件对于机密容器的适配工作。构建开源解决方案，是希望能够借助开源社区与合作伙伴达成更便捷深入的合作，为机密容器寻找更多落地场景。</p><p></p><p>英特尔和阿里云都充分意识到，除了关注基础软件之外，为了促进机密容器的技术发展和普及，应用和生态也是非常关键的一环。机密计算的核心价值和能力在于能够对于高价值业务或敏感数据提供保护，BigDL PPML 就是这样一个典型应用。</p><p></p><p><a href=\"https://www.infoq.cn/article/2017/01/bigdl-deep-learning-on-spark\">BigDL</a>\" 是英特尔开源的一款人工智能解决方案平台，能够方便数据科学家和数据工程师便捷地开发出一套端到端的分布式人工智能的应用。另外，BigDL 特别针对机密计算推出了 PPML&nbsp;(隐私保护机器学习)，能够对分布式人工智能应用实现端到端的全链路保护。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/20/2012540bc75bc850be98657ca8c09d1d.png\" /></p><p></p><p>PPML 架构如上图所示。最底层在 K8s 集群中提供的英特尔®&nbsp;TDX 和英特尔®&nbsp;SGX 可信执行环境。再通过一系列软硬件底层安全技术加持，使得用户能够在不暴露隐私数据的前提下，使用标准的人工智能和大数据处理软件比如 Apache Spark、 Apache Flink、TensorFlow、PyTorch 等熟悉的工具开发自己的应用。</p><p></p><p>在此之上，PPML 还提供了 Orca 和 DLlib 两个分布式流水线。Orca 是在 AI 框架&nbsp; API 之上，增强了分布式大数据的处理能力，而 DLlib 则能够帮助程序员将分布式深度学习应用转化成 Spark 应用。另外，BigDL 还提供了可信大数据分析、可信机器学习、深度学习以及联邦学习应用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3c/3c2203310fc5d8bdc6dbd385d5a15f04.png\" /></p><p></p><p>如上图所示，BigDL PPML 基于可信的 Kubernetes 集群环境，通过机密容器技术能够构建出基于 TDX 的分布式可执行环境，从而确保业务、数据和模型在使用和计算过程中的安全性，包括不可见以及不可更改性。</p><p></p><p>从数据流角度，所有数据均以加密方式存储在数据湖和数据仓库中。BigDL PPML 加载这些机密数据，通过远程证明以及密钥管理系统获取数据密钥，置于可信执行环境中进行解密，再使用大数据和人工智能的计算框架， 对数据进行分布式预处理，模型训练以及模型推理等。最后，再把最终结果、数据或者模型，以安全或加密方式写回到分布式存储中。另外数据在节点之间， 容器之间的数据均以 TLS 方式进行传输，从而做到全链路的隐私保护和数据安全。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/96ec21005f18f97f6205552854e044b4.png\" /></p><p></p><p>使用&nbsp;TDX 机密容器运行 BigDL PPML workload 只需简单两步：</p><p></p><p>首先，构建 PPML 的镜像并对其进行加密，然后把加密后的镜像推送到镜像仓库之中。&nbsp;</p><p></p><p>其次，在&nbsp; Kubernetes 中部署 PPML workload ，开发者只需在标准 YAML 文件中指定所需机密容器运行时以及配置好的高性能存储卷，然后使用标准 Kubernetes 命令拉起即可。&nbsp;</p><p></p><p>如果更深入一点看，Kubernetes 将 workload 调度到具有运行机密容器能力的目标主机：</p><p></p><p>首先，主机上的机密容器运行时启动 TDX TEE。</p><p></p><p>其次，在 TDX 可信执行环境里，执行远程证明并获取验证/解密容器镜像所需的密钥，镜像服务下载容器镜像，使用密钥验证及解密容器镜像；在数据方面，用户使用标准的 K8s CSI driver 比如&nbsp;<a href=\"http://mp.weixin.qq.com/s?__biz=Mzg4MTMyMTUwMQ==&amp;mid=2247504178&amp;idx=1&amp;sn=fbaf768fd17ccb4155596c36500972db&amp;chksm=cf652240f812ab562108366c889970b5c4145126597ae95ff432b0dba12635bfa082b97f4de8&amp;scene=21#wechat_redirect\">open-local</a>\"&nbsp;为容器挂载高性能本地 LVM 卷，机密容器会自动进行透明的加密存储来保护用户输入输出数据。</p><p>最后，启动 BigDL PPML workload 相关容器，一个 BigDL PPML Driver 和多个 Worker 以分布式的方式运行于 K8s 集群之上，这样可以基于 TDX 进行的可信的云原生大数据分析和人工智能应用了。</p><p></p><p>英特尔和阿里云一直保持着紧密合作，两家都是 CoCo 上游社区的发起人，共同定义、设计和实现了 CoCo 软件栈的诸多关键特性，比如 TEE 内镜像下载，镜像的验签和解密，可信临时存储和可度量运行时环境，所有这一切都确保了 CoCo 这个项目的强安全属性。</p><p></p><p>另外，我们在龙蜥社区也有紧密的合作，包括共同实现了基于 TDX 的机密容器端到端的解决方案，包括远程证明以及参考应用。又比如我们选择了龙蜥社区的 open-local driver ，第一个支持了可信存储，一个支持了 kata 的 directvolume 新特性等等。欢迎感兴趣的各位参与到云原生机密计算 SIG（Special Interest Group&nbsp;）中来，一起推动云原生场景下的机密计算技术的发展。</p><p></p><p></p><blockquote>相关链接地址：CNCC SIG 地址：https://openanolis.cn/sig/coco</blockquote><p></p>",
    "publish_time": "2022-12-08 10:56:10",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "CNCF 宣布 Argo 正式毕业",
    "url": "https://www.infoq.cn/article/Y8a0EK2UevjXBm3QGCOX",
    "summary": "<p>当地时间 12 月 6 日， CNCF（云原生计算基金会） <a href=\"https://www.cncf.io/announcements/2022/12/06/the-cloud-native-computing-foundation-announces-argo-has-graduated/\">宣布 Argo 正式毕业</a>\"，Argo 将与 Kubernetes、Prometheus 和Envoy 等并列到 CNCF 毕业项目行列。</p><p>&nbsp;</p><p><a href=\"https://argoproj.github.io/\">Argo </a>\"项目是一组 Kubernetes 原生工具集合，由 Argo Workflows、Argo Events、Argo CD和Argo Rollouts 四个 Kubernetes 原生子项目组成，用于运行和管理 Kubernetes 上的作业和应用程序。</p><p>&nbsp;</p><p>其中，Argo Workflows 支持创建复杂的并行工作流作为 Kubernetes 资源，并用于从 CI/CD 流水线到机器学习工作流的许多不同用例中；Argo Events 基于各种事件源，为 Kubernetes 资源（包括 Argo Workflows）提供基于事件的依赖性和触发器的声明式管理；Argo CD 和 Argo Rollouts可以帮助工程师理解、采用和使用 Kubernetes，并使 <a href=\"https://xie.infoq.cn/article/404a4d50bfff78177872af174\">GitOps</a>\"最佳实践对想要采用它的团队来说更容易实现。这些工具可以单独使用，但结合使用对大规模创建和运行复杂的应用程序有很大好处。&nbsp;</p><p>&nbsp;</p><p>Argo 提供了一种在 Kubernetes 上创建工作和应用程序的三种计算模式——服务模式、工作流模式和基于事件的模式——的简单组合方式。所有的 Argo 工具都实现为控制器和自定义资源。</p><p>&nbsp;</p><p>据悉，Argo 现在被 350 多个组织应用，该数量比加入 CNCF 孵化器时增加了 250%，其中包括 Adob​​e、Blackrock、Capital One、Google、Intuit、PagerDuty、Peloton、Snyk、Swisscom、Tesla 和 Volvo等企业。最新的 CNCF 在用户调查显示，超过 50% 的受访者表示他们正在生产中运行 Argo，或正对其进行评估。</p><p>&nbsp;</p><p>另外，2300 家企业和 8000 名个人开发者为该项目做出了贡献，Argo 是 CNCF 中最强大和最多样化的社区之一。</p><p>&nbsp;</p><p>Argo 项目由 Applatix 于 2017 年创建并开源，该公司后来被 Intuit 收购。2020 年 4 月，Argo <a href=\"https://www.infoq.cn/article/fFZPvrKtbykg53x03IaH\">加入 CNCF 孵化器</a>\"。Intuit 与为该项目贡献 Argo Events 的 BlackRock 一起，大力参与了该项目和社区的开发和培养。</p><p>&nbsp;</p><p>“毕业意味着 Argo 符合安全、用户采用和治理的最高标准。从各方面来看，Argo 都是一个成熟的、可持续的、成功的开源项目，”Argo 项目维护者、Codefresh 首席开源官兼联合创始人 Dan Garfield 说道。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.cncf.io/announcements/2022/12/06/the-cloud-native-computing-foundation-announces-argo-has-graduated/\">https://www.cncf.io/announcements/2022/12/06/the-cloud-native-computing-foundation-announces-argo-has-graduated/</a>\"</p>",
    "publish_time": "2022-12-08 11:42:38",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]