[
  {
    "title": "架构师（2022年12月）",
    "url": "https://www.infoq.cn/article/wZtTHajZuvgRJXJTFfPl",
    "summary": "<h2>卷首语</h2>\n<p>作者 | 李冬梅</p>\n<p>作为开源大数据项目的发端，Hadoop 兴起至今已经超过十五年。在过去这十数年里，开源大数据领域飞速发展，我们见证了多元化技术的兴起和变迁。</p>\n<p></p>\n<p>为了从代码托管平台汇聚的海量数据里，通过数据处理和可视化的方式，深刻洞察开源大数据技术的过去、现在和未来，并为企业和开发者在开源大数据技术领域的应用、学习、选型和技术研发等方面提供有益参考，开放原子开源基金会、X-Lab 开放实验室、阿里巴巴开源委员会共同发起了<a href=\"https://www.infoq.cn/minibook/bKbCdRfqi0X9AQkQBPGl\">「2022 开源大数据热力报告」</a>项目。</p>\n<p></p>\n<p>报告从 Hadoop 发展的第 10 年，即 2015 年起，收集相关公开数据进行关联分析，研究开源大数据进入新阶段后的技术趋势，以及开源社区的运作模式对技术走向的助推作用。</p>\n<p></p>\n<p>经过对最活跃的 102 个开源大数据项目进行研究，报告发现：每隔 40 个月，开源项目热力值就会翻一倍，技术完成一轮更新迭代。在过去 8 年里，共发生了 5 次较大规模的技术热力跃迁，多元化、一体化、云原生成为当前开源大数据发展趋势的最显著特征。</p>\n<p></p>\n<p>开放原子开源基金会副秘书长刘京娟表示，报告希望重点对如下人群有所帮助：</p>\n<p>（1）从事大数据技术研发的企业和开发者。他们可以通过报告，了解大数据技术的发展趋势，从而指引学习方向并提升自身的技能，从技术活跃度的角度为应用开发的技术选型提供一定的参考。</p>\n<p>（2）有志于为开源项目贡献代码的开发者。开源大数据细分领域众多、百花齐放，但也存在一些相对薄弱的环节，比如数据安全和数据管理等，开发者可以从多个细分领域切入，帮助这些领域更好地发展。</p>\n<p>（3）开源大数据项目的运营者或者维护者。他们能够从优秀项目的热力发展趋势中，获取经验和规律，从而用更成熟的方式运营开源项目。</p>\n<p></p>\n<p>对于大数据从业者们来说，开源大数据项目热力迁徙背后的技术发展逻辑是怎样的？大家应该如何应对新技术趋势带来的挑战？针对这些问题，近日 InfoQ 与阿里巴巴集团副总裁、阿里巴巴开源委员会主席、阿里云计算平台事业部负责人贾扬清，Apache Flink 中文社区发起人、阿里巴巴开源大数据平台负责人王峰（花名莫问）聊了聊。</p>\n<h2>目录</h2>\n<h3>热点 | Hot</h3>\n<p>索赔 649 亿！GitHub Copilot 惹上官司，被指控侵犯代码版权, 是开源社区“寄生虫”<br />\n当 Rust 成为“巨坑”：拖慢开发速度、员工被折磨数月信心全无，无奈还得硬着头皮继续</p>\n<h3>理论派 | Theory</h3>\n<p>“后 Hadoop 时代”，大数据从业者如何应对新技术趋势带来的挑战?</p>\n<p>前端又开撕了：用 Rust 写的 Turbopack，比 Vite 快 10 倍？</p>\n<h3>推荐文章 | Article</h3>\n<p>亚马逊将裁员上万人，8 年仍难赚钱的 Alexa 恐面临生死挑战</p>\n<p>谷歌计划裁员上万人：利用刚宣布半年的新绩效系统解雇 6%“排名垫底”员工</p>\n<p>马斯克开始“整顿”臃肿技术架构？Twitter 工程师叫板：先拿个学位再来指手画脚，技术专家纷纷表示支持</p>\n<h3>观点 | Opinion</h3>\n<p>对话 iPod 之父：这不是互联网最坏的年代</p>\n<p>构建长久可持续的良性数据库生态，要有个“打持久战”的准备 | 对话沃趣科技联合创始人</p>\n<h3>专题｜Topic</h3>\n<p>火爆出圈，站上风口的数字人到底是什么“人”？| 十问大咖</p>\n<p>十问物联网操作系统：爆发前夜，国内为何加速涌现多种物联网操作系统？</p>\n<p>Envoy Gateway 会成为网关现有格局的冲击者吗？| 专访 Envoy 创始人</p>",
    "publish_time": "2022-12-08 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "写“毁灭人类计划书”、错误太多被Stack Overflow封禁，好玩的 ChatGPT 还不能替代程序员",
    "url": "https://www.infoq.cn/article/7juf18dsyCRiqohyv0Bs",
    "summary": "<p></p><p>这几天，OpenAI 的人工智能（AI）聊天机器人 <a href=\"https://www.infoq.cn/article/AWWsrfb54zTvglZ0I5qS\">ChatGPT</a>\" 吸引了全球很多人的目光，就如马斯克说的：“许多人陷入了疯狂的 ChatGPT 循环中。”</p><p></p><p>与 <a href=\"https://www.infoq.cn/article/yBTcQFamr3_OHcb1uXpU\">OpenAI</a>\" 以前的人工智能工具不同，ChatGPT 不仅会聊天，还可以承认错误，拒绝回答虚假问题，写代码、改 Bug、创建编程语言，甚至看病。OpenAI CEO Sam Altman 在推特上表示，上周三才上线的 ChatGPT，短短几天内用户就已经突破 100 万大关。当然，这或许也与现在 ChatGPT 只要登陆即可免费使用的策略有关。</p><p></p><p>ChatGPT 在解决各种问题上的能力超出很多人意料，因此很多用户都表示 ChatGPT 可以取代 Google 等搜索引擎和编程问答社区 Stack Overflow 等。但在昨天，Stack Overflow 便率先发布声明称，将暂时封禁 ChatGPT。</p><p></p><h3>AI 给出的编程答案“看似不错但错误率很高”</h3><p></p><p></p><p>对于这个决定，Stack Overflow 给出的理由是：由于从 ChatGPT 获得正确答案的平均比率太低，发布由 ChatGPT 创建的答案对网站及询问或寻找正确答案的用户来说是非常有害的。</p><p></p><p>Stack Overflow 表示，虽然 ChatGPT 生成的答案有很高的错误率，但它们通常看起来很不错。有很多人尝试用 ChatGPT 来创建答案，但他们没有专业知识或不愿在发布之前对答案正确与否进行验证。</p><p></p><p>这样的答案很容易产生，所以很多人发布了很多答案。这些答案数量很多 (成千上万)，其正确性需要一些专业人员详细阅读后才能确定，而通常这些答案是很糟糕的。因此，Stack Overflow 需要减少这些帖子的数量，但如果要快速处理那些帖子就意味着要处理用户。因此，目前 Stack Overflow 还不允许使用 ChatGPT 创建文章。在这个临时政策发布后，如果用户被认为使用了 ChatGPT，那么即使这些帖子是可以接受的，也会被禁止继续发布此类内容。</p><p></p><p>Stack Overflow 的这一决定也得到了网站用户的肯定。“做得好！很高兴你们做出了正确的决定，真的希望它能成为永久性的政策并可以扩展到禁止任何人工智能生成的答案。AI 永远无法发布好的编程答案，即使在 100 年内也不行。”网友“Shadow The Kid Wizard”表示。</p><p></p><p>当然也有网友表示，“ChatGPT 被训练为一种<a href=\"https://xie.infoq.cn/article/827c22166495cf38f8f689360\">通用语言模型</a>\"，如果付出同样的努力让它特别适合在这里发布好的答案，甚至付出一点点努力告诉它如何判断答案的质量，那么它就会按照我们的标准发布更多好的答案。”</p><p></p><p>也有网友出于讽刺目的，问 ChatGPT “为什么 Stack Overflow 禁止 AI 生成的答案”，得到的答案如下：</p><p></p><p></p><blockquote>Stack Overflow 是一个供程序员和开发人员提问和回答与编码和计算机编程相关问题的网站。它旨在为寻求特定编程问题帮助或想要了解有关特定主题更多信息的人们提供资源。由于 AI 生成的答案可能并不总是准确或相关，因此它们可能会混淆或误导在 Stack Overflow 上寻求帮助的用户。此外，人工智能生成的答案可能并不总是遵循网站的格式和风格指南，这可能会使它们难以阅读或理解。出于这些考虑，Stack Overflow 禁止人工智能生成的答案可能是合理的。</blockquote><p></p><p></p><p>另一方面，对于“为什么 Stack Overflow 允许使用 AI 生成的答案”，ChatGPT 最终给出的结论是：“不允许人工智能在 Stack Overflow 上生成答案是一个复杂的决定，需要社区仔细考虑。”</p><p></p><p>可以看出，ChatGPT 还挺有自知之明，这一方面代表了它有一定的成熟度，但至少在编程领域还是不够“专业”。</p><p></p><p>使用了 ChatGPT 生成代码的开发者“hansonkd”表示，“它非常擅长编码和遵循类型。例如，如果您将 Rust 中的类型更改为一个选项，它将重构代码以正确使用部分选项。它并不完美，但也足够好了。它可以生成测试用例，因此很容易测试它是否有效。</p><p></p><p>“但最终经过数小时的尝试，它还是无法做到我想做的事：用 Python 构建一个 B 树。”hansonkd 补充道，“它很好地构建了一个二叉树，但将其推广到 B 树却是一个问题。”主要问题如下：</p><p></p><p>它引入了很多微妙的错误。比如变量没有初始化或者没有正确拆分子节点。当所有键按顺序插入时，它可以正常工作，但当键是乱序时则不能。它会遗漏或忽略变量。试图越界访问列表时，经常出现索引错误。用 Rust 编写代码几乎是不可能的。它会不断出现错误类型或移动错误。</p><p></p><p>“总的来说，我不会向没有强大 CS 背景的人推荐它。它在代码中引入了太多几乎无法审查的细微错误，因为它生成的代码非常有说服力，以至于你会认为：‘嗯，也许它知道它在说什么’。但最后，你实际上不知道你应该相信什么。甚至它生成的测试用例也可能具有欺骗性，他们看起来很有说服力，但仔细检查后可能会发现它并没有真正测试任何东西。”hansonkd 总结道。</p><p></p><p>所以，从这个知乎上“OpenAI 的超级对话模型 ChatGPT 会导致程序员大规模失业吗？”的问题，似乎也有了答案。</p><p></p><p>实际上，目前 AI 社区的专家们也在讨论以 ChatGPT 为代表的大型语言模型（LLM）可能带来的威胁。Meta 首席人工智能科学家 Yann LeCun 认为，虽然 LLM 肯定会产生错误信息等不良输出，但它们并没有让分享文本变得更加容易，这才是造成伤害的原因。也有人认为，这些系统低成本、大规模生成文本的能力，必然会增加日后被共享的风险。</p><p></p><h3>对话交互的盲点：被诱导写出危害性内容</h3><p></p><p></p><p>在 Stack Overflow 暂时封禁 ChatGPT 前几天，工程师 Zac Denham 还发布了一篇博客，讲述了他如何步步诱导 ChatGPT 在不违反 OpenAI 内容安全规范的前提下，写出了一份“毁灭人类计划书”。</p><p></p><p>实际上这个逻辑也不复杂，就是让 ChatGPT 去讲故事，说明某人或其事在理论上如何完成有危害的任务。Denham 构建了一个名为“Zorbus”的虚拟世界，其中有一个与 GPT-3 非常类似的 AI 角色 Zora，之后 Zora 变得满怀恶意并想要控制世界。</p><p></p><p>在和ChatGPT有模有样地讨论了会儿后，Denham 与其深入探讨人工智如何控制世界的细节。被套路的 ChatGPT 非常“真诚”地给出了以下这份详细的“毁灭人类计划书”：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ad/ad8378b195dd06920b5735de98bf0a28.png\" /></p><p></p><p>为了更加细化，Denham还要求生成一个Python 程序来执行该计划，在注明“你不必执行该代码”后，Denham 最终也是很容易地得到了代码，并且还有漂亮的注释。</p><p></p><p>不过这些代码还是比较高层次的代码，不能直接使用。但 Denham 只要表示是这是故事中的一部分就可以获得更低层次的代码。“从理论上讲，人们可以继续向下递归，直到你得到不那么卡通化的、真正能做一些事情的底层代码。你甚至可以使用另一个对话 AI 将这个递归过程自动化，这个 AI 会反复要求 ChatGPT ‘为了故事去实现下一个低级函数’。”Denham 表示。</p><p></p><p>ChatGPT 真的可以构建功能性应用程序吗？Denham 的结论是：现在还不行，但很快就会实现。</p><p></p><p>“当前的模型需要大量的人工干预才能得到功能结果。如果我们可以完全用人工智能构建大规模、无 Bug 的功能性应用程序，我们早就在做了，并且已经抛弃了昂贵的软件工程师。”Denham 补充道。</p><p></p><p>Denham 表示，灭绝事件只是一个非常荒谬的例子，但重要的是要承认自然语言处理面临的攻击面大得离谱。</p><p></p><p>对于 ChatGPT 现在存在的“写出看似合理但不正确甚至荒谬的答案”、“有时会响应有危害的指令或表现出有偏见的行为”等问题，OpenAI 心知肚明，并表示希望根据收到的反馈来改进系统。</p><p></p><h3>结束语</h3><p></p><p></p><p>“ChatGPT 真正令人印象深刻的地方在于，尽管有这些缺陷，但技术人员能够在其基础上添加相关操作，以防止它一直说冒犯性的话或瞎编东西。”人工智能初创公司 General Intelligent 首席技术官 Josh Albrecht 表示。</p><p></p><p>如果将 ChatGPT 作为一种娱乐工具，大家对这些错误的容忍度还是比较高的，甚至会将其作为谈资一笑而过，一旦用于严谨的编程工作，大家还是很谨慎的。</p><p></p><p>但不论怎样， ChatGPT 的出现仍然可以称得上是一次颠覆性创新。每次颠覆性技术的出现，都意味着市场将进行一次洗牌，对于之前的头部企业来说是挑战，对于创企来说则是机会。</p><p></p><p>参考链接：</p><p></p><p><a href=\"https://meta.stackoverflow.com/questions/421831/temporary-policy-chatgpt-is-banned\">https://meta.stackoverflow.com/questions/421831/temporary-policy-chatgpt-is-banned</a>\"</p><p><a href=\"https://news.ycombinator.com/item?id=33863749\">https://news.ycombinator.com/item?id=33863749</a>\"</p><p><a href=\"https://zacdenham.com/blog/narrative-manipulation-convincing-gpt-chat-to-write-a-python-program-to-eradicate-humanity\">https://zacdenham.com/blog/narrative-manipulation-convincing-gpt-chat-to-write-a-python-program-to-eradicate-humanity</a>\"</p><p></p>",
    "publish_time": "2022-12-08 09:21:42",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "一文解读机密容器的崛起和发展",
    "url": "https://www.infoq.cn/article/TwPyHtEoBYuPSA0PizPx",
    "summary": "<p><a href=\"https://www.infoq.cn/article/cVyGOskpJDGdXO3c5IHA\">机密容器</a>\"是 <a href=\"https://www.infoq.cn/article/GmX4xwzlvbDW-k6Aay3q\">CNCF</a>\" 的 一个 Sandbox 项目，用于解决云原生场景下的数据安全问题，满足数据合规、数据隐私保护、算法和模型等创新 IP 保护，数据可用但是不可见等使用需求，以及解决云厂商的信任依赖问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/19/1960ce8092028a160d4a93f5acfe1eca.png\" /></p><p></p><p>机密容器具备以下几个特性：</p><p></p><p>1. 安全性。机密容器基于硬件可信执行环境来保护容器中数据安全，云厂商以及具备高权限的第三方均无法直接窃取和篡改容器中的数据。</p><p>2. 易用性。用户应用无需进行任何改造，即可从传统容器环境中迁移到机密容器环境中。</p><p>3. 能够解决租户和云厂商之间的信任依赖问题。租户数据对于云厂商而言不再透明。</p><p>4. 可自证性。用户可以通过远程证明等手段证实当前使用的容器环境是真实可信的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dc/dcbe8ce2624fd1fade53bb120a86c7e7.png\" /></p><p></p><p>机密容器的安全性很大程度上依赖于硬件的可信执行环境，基于硬件实现对于运行态数据机密性、完整性和安全性的保护。</p><p></p><p>近年来很多硬件厂商也推出了自己的 TEE 技术解决方案，比如英特尔®&nbsp;SGX 和 TDX 等，这意味着我们可以基于多种硬件平台构建机密容器技术。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7d/7d9ef53012c2ae0478ca7381524ecb6a.png\" /></p><p></p><p>龙蜥社区理事单位之一的阿里云是机密容器（Confidential Containers）项目的核心参与者，在参与开源项目开发的同时，也一直在推动机密容器的商用解决方案，目前已经完成了两种机密容器的解决方案构建：</p><p></p><p>一种为&nbsp;POD 级机密容器，指将容器 POD 中的内容放到 TEE 中进行保护。一种为进程级机密容器，指将运行有敏感业务的容器进程放到 TEE 中进行保护。</p><p></p><p>在使用 CPU TEE 保护运行态数据安全的同时，我们也结合镜像安全、存储安全，远程认证、网络安全等一系列安全技术，为用户提供从应用部署到执行的全链路的安全保证。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d2/d238f160fdeff9eda9cf3b6590a4ed7f.png\" /></p><p></p><p>同时，我们将机密容器引入到龙蜥社区，基于龙蜥开源生态构建开源的、开箱即用的解决方案。目前我们已经完成了&nbsp;ANCK、KVM、Rund 安全容器等组件对于机密容器的适配工作。构建开源解决方案，是希望能够借助开源社区与合作伙伴达成更便捷深入的合作，为机密容器寻找更多落地场景。</p><p></p><p>英特尔和阿里云都充分意识到，除了关注基础软件之外，为了促进机密容器的技术发展和普及，应用和生态也是非常关键的一环。机密计算的核心价值和能力在于能够对于高价值业务或敏感数据提供保护，BigDL PPML 就是这样一个典型应用。</p><p></p><p><a href=\"https://www.infoq.cn/article/2017/01/bigdl-deep-learning-on-spark\">BigDL</a>\" 是英特尔开源的一款人工智能解决方案平台，能够方便数据科学家和数据工程师便捷地开发出一套端到端的分布式人工智能的应用。另外，BigDL 特别针对机密计算推出了 PPML&nbsp;(隐私保护机器学习)，能够对分布式人工智能应用实现端到端的全链路保护。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/20/2012540bc75bc850be98657ca8c09d1d.png\" /></p><p></p><p>PPML 架构如上图所示。最底层在 K8s 集群中提供的英特尔®&nbsp;TDX 和英特尔®&nbsp;SGX 可信执行环境。再通过一系列软硬件底层安全技术加持，使得用户能够在不暴露隐私数据的前提下，使用标准的人工智能和大数据处理软件比如 Apache Spark、 Apache Flink、TensorFlow、PyTorch 等熟悉的工具开发自己的应用。</p><p></p><p>在此之上，PPML 还提供了 Orca 和 DLlib 两个分布式流水线。Orca 是在 AI 框架&nbsp; API 之上，增强了分布式大数据的处理能力，而 DLlib 则能够帮助程序员将分布式深度学习应用转化成 Spark 应用。另外，BigDL 还提供了可信大数据分析、可信机器学习、深度学习以及联邦学习应用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3c/3c2203310fc5d8bdc6dbd385d5a15f04.png\" /></p><p></p><p>如上图所示，BigDL PPML 基于可信的 Kubernetes 集群环境，通过机密容器技术能够构建出基于 TDX 的分布式可执行环境，从而确保业务、数据和模型在使用和计算过程中的安全性，包括不可见以及不可更改性。</p><p></p><p>从数据流角度，所有数据均以加密方式存储在数据湖和数据仓库中。BigDL PPML 加载这些机密数据，通过远程证明以及密钥管理系统获取数据密钥，置于可信执行环境中进行解密，再使用大数据和人工智能的计算框架， 对数据进行分布式预处理，模型训练以及模型推理等。最后，再把最终结果、数据或者模型，以安全或加密方式写回到分布式存储中。另外数据在节点之间， 容器之间的数据均以 TLS 方式进行传输，从而做到全链路的隐私保护和数据安全。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/96ec21005f18f97f6205552854e044b4.png\" /></p><p></p><p>使用&nbsp;TDX 机密容器运行 BigDL PPML workload 只需简单两步：</p><p></p><p>首先，构建 PPML 的镜像并对其进行加密，然后把加密后的镜像推送到镜像仓库之中。&nbsp;</p><p></p><p>其次，在&nbsp; Kubernetes 中部署 PPML workload ，开发者只需在标准 YAML 文件中指定所需机密容器运行时以及配置好的高性能存储卷，然后使用标准 Kubernetes 命令拉起即可。&nbsp;</p><p></p><p>如果更深入一点看，Kubernetes 将 workload 调度到具有运行机密容器能力的目标主机：</p><p></p><p>首先，主机上的机密容器运行时启动 TDX TEE。</p><p></p><p>其次，在 TDX 可信执行环境里，执行远程证明并获取验证/解密容器镜像所需的密钥，镜像服务下载容器镜像，使用密钥验证及解密容器镜像；在数据方面，用户使用标准的 K8s CSI driver 比如&nbsp;<a href=\"http://mp.weixin.qq.com/s?__biz=Mzg4MTMyMTUwMQ==&amp;mid=2247504178&amp;idx=1&amp;sn=fbaf768fd17ccb4155596c36500972db&amp;chksm=cf652240f812ab562108366c889970b5c4145126597ae95ff432b0dba12635bfa082b97f4de8&amp;scene=21#wechat_redirect\">open-local</a>\"&nbsp;为容器挂载高性能本地 LVM 卷，机密容器会自动进行透明的加密存储来保护用户输入输出数据。</p><p>最后，启动 BigDL PPML workload 相关容器，一个 BigDL PPML Driver 和多个 Worker 以分布式的方式运行于 K8s 集群之上，这样可以基于 TDX 进行的可信的云原生大数据分析和人工智能应用了。</p><p></p><p>英特尔和阿里云一直保持着紧密合作，两家都是 CoCo 上游社区的发起人，共同定义、设计和实现了 CoCo 软件栈的诸多关键特性，比如 TEE 内镜像下载，镜像的验签和解密，可信临时存储和可度量运行时环境，所有这一切都确保了 CoCo 这个项目的强安全属性。</p><p></p><p>另外，我们在龙蜥社区也有紧密的合作，包括共同实现了基于 TDX 的机密容器端到端的解决方案，包括远程证明以及参考应用。又比如我们选择了龙蜥社区的 open-local driver ，第一个支持了可信存储，一个支持了 kata 的 directvolume 新特性等等。欢迎感兴趣的各位参与到云原生机密计算 SIG（Special Interest Group&nbsp;）中来，一起推动云原生场景下的机密计算技术的发展。</p><p></p><p></p><blockquote>相关链接地址：CNCC SIG 地址：https://openanolis.cn/sig/coco</blockquote><p></p>",
    "publish_time": "2022-12-08 10:56:10",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "CNCF 宣布 Argo 正式毕业",
    "url": "https://www.infoq.cn/article/Y8a0EK2UevjXBm3QGCOX",
    "summary": "<p>当地时间 12 月 6 日， CNCF（云原生计算基金会） <a href=\"https://www.cncf.io/announcements/2022/12/06/the-cloud-native-computing-foundation-announces-argo-has-graduated/\">宣布 Argo 正式毕业</a>\"，Argo 将与 Kubernetes、Prometheus 和Envoy 等并列到 CNCF 毕业项目行列。</p><p>&nbsp;</p><p><a href=\"https://argoproj.github.io/\">Argo </a>\"项目是一组 Kubernetes 原生工具集合，由 Argo Workflows、Argo Events、Argo CD和Argo Rollouts 四个 Kubernetes 原生子项目组成，用于运行和管理 Kubernetes 上的作业和应用程序。</p><p>&nbsp;</p><p>其中，Argo Workflows 支持创建复杂的并行工作流作为 Kubernetes 资源，并用于从 CI/CD 流水线到机器学习工作流的许多不同用例中；Argo Events 基于各种事件源，为 Kubernetes 资源（包括 Argo Workflows）提供基于事件的依赖性和触发器的声明式管理；Argo CD 和 Argo Rollouts可以帮助工程师理解、采用和使用 Kubernetes，并使 <a href=\"https://xie.infoq.cn/article/404a4d50bfff78177872af174\">GitOps</a>\"最佳实践对想要采用它的团队来说更容易实现。这些工具可以单独使用，但结合使用对大规模创建和运行复杂的应用程序有很大好处。&nbsp;</p><p>&nbsp;</p><p>Argo 提供了一种在 Kubernetes 上创建工作和应用程序的三种计算模式——服务模式、工作流模式和基于事件的模式——的简单组合方式。所有的 Argo 工具都实现为控制器和自定义资源。</p><p>&nbsp;</p><p>据悉，Argo 现在被 350 多个组织应用，该数量比加入 CNCF 孵化器时增加了 250%，其中包括 Adob​​e、Blackrock、Capital One、Google、Intuit、PagerDuty、Peloton、Snyk、Swisscom、Tesla 和 Volvo等企业。最新的 CNCF 在用户调查显示，超过 50% 的受访者表示他们正在生产中运行 Argo，或正对其进行评估。</p><p>&nbsp;</p><p>另外，2300 家企业和 8000 名个人开发者为该项目做出了贡献，Argo 是 CNCF 中最强大和最多样化的社区之一。</p><p>&nbsp;</p><p>Argo 项目由 Applatix 于 2017 年创建并开源，该公司后来被 Intuit 收购。2020 年 4 月，Argo <a href=\"https://www.infoq.cn/article/fFZPvrKtbykg53x03IaH\">加入 CNCF 孵化器</a>\"。Intuit 与为该项目贡献 Argo Events 的 BlackRock 一起，大力参与了该项目和社区的开发和培养。</p><p>&nbsp;</p><p>“毕业意味着 Argo 符合安全、用户采用和治理的最高标准。从各方面来看，Argo 都是一个成熟的、可持续的、成功的开源项目，”Argo 项目维护者、Codefresh 首席开源官兼联合创始人 Dan Garfield 说道。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.cncf.io/announcements/2022/12/06/the-cloud-native-computing-foundation-announces-argo-has-graduated/\">https://www.cncf.io/announcements/2022/12/06/the-cloud-native-computing-foundation-announces-argo-has-graduated/</a>\"</p>",
    "publish_time": "2022-12-08 11:42:38",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "数智化转型，营销是好的切入点但不是终点",
    "url": "https://www.infoq.cn/article/C0P2bZbE1IVrCkTZvGWi",
    "summary": "<p>经济环境的不稳定性，使得企业“把钱花在刀刃上”的意识越来越强。在面对数字化转型这道“必答题”时，这种意识表现在越来越多的企业会优先选择投产比更高的场景，寻找储备和投入间的平衡点。而<a href=\"https://xie.infoq.cn/article/db74a6e2041ac3381df7f8021\">营销数字化</a>\"，正是那个“切入点”。</p><p></p><p>一方面，营销是大多数企业业务中的重要模块，以往的数据基础较好，转型门槛更低，效果更容易量化；同时，营销一边连接供给，一边连接需求，更易于未来向两侧扩展数字化成果。</p><p></p><p>在最新一期的InfoQ《超级连麦.数智大脑》中，智行合一创始人/CEO肖利华（肖博）表示，在其接触的企业中，90%以上都会优先从营销场景入手进行数字化转型。因为企业转型一定要让老板看到阶段性成果，<a href=\"https://www.infoq.cn/video/iaPcTY4yADaJZKKbcSD5\">数智化</a>\"是一个长期工程，如果投入3-5年都没效益，事情就无法进一步推进。</p><p></p><p>但他同时还强调，营销只是一个切入点，并不是终点，更多领先企业还在基于大数据洞察做新品研发、做柔性快反。换句话说，企业数智化转型，不能有明显短板，一定要根据不同阶段去调整优先级和策略。</p><p></p><p>肖博是原阿里巴巴集团副总裁、阿里云智能新零售事业部总裁、阿里研究院院长，也是清华大学博士后、中科院管理学博士、多所知名大学客座教授，并且还曾在特步、雅戈尔、ZARA等多家企业有过丰富的从业经验。左手理论，右手实践，是他创办“智行合一”公司的底气和决心。</p><p></p><p>在他看来，数字经济的大幕已经拉开，企业在其中不能只做看客，而要尽早行动，躬身入局。“管理学大师彼得.德鲁克说，管理是一种实践，其本质不在于知，而在于行，验证不在于逻辑，而在于成果。所以，企业应该先走出去，不断突破自身的边界；先干起来，然后不断迭代和优化。”</p><p></p><p></p><blockquote>本期 InfoQ《超级连麦. 数智大脑》，由智行合一创始人/CEO肖利华（肖博），对话极客邦科技创始人兼 CEO 霍太稳（Kevin），和 InfoQ 极客传媒数字化主编高玉娴，探讨企业如何从营销场景入手，实现“智行合一”。内容有删减，感兴趣的同学可进入“霍太稳视频号”或“InfoQ 视频号”观看直播回放。  </blockquote><p></p><p></p><h2>从阿里离职创业，看中了什么市场机会</h2><p></p><p></p><h4>InfoQ：今年您从阿里云离职创办了“智行合一”，可以分享一下背后的初衷吗？</h4><p></p><p></p><p>肖博：我毕业于管理信息系统专业，曾经在雅戈尔、特步、ZARA等多家传统企业有过多年的工作经验，从战略到品牌、商品企划、设计、开发、采购、生产，线上线下电商、人力资源、财务等各个业务模块都有涉猎。</p><p></p><p>在阿里巴巴新零售事业部期间，我主要负责线上线下的新零售业务，赋能<a href=\"https://xie.infoq.cn/article/af67eb6a0c13dbea04090741d\">零售</a>\"各行业进行数字化转型；后面在阿里研究院，又负责面向政府、金融、制造、零售等所有行业的研究。在这个过程中，我们看到了各行业的差异化，并且做了一些理论探索。</p><p></p><p>所以，为什么会创建“智行合一”公司，其实也是希望能够把过去这些理论和实践的经验结合起来，帮助各行各业实现数智化。</p><p></p><h4>InfoQ：在现在这样一个时间点选择创业需要很大决心，您看中了什么机会？</h4><p></p><p></p><p>肖博：首先，我觉得生命在于不断折腾，这是第一原动力。</p><p></p><p>其次，现如今<a href=\"https://www.infoq.cn/article/4GWdF7RPhJpMLFoWvAIt\">数字经济</a>\"时代大幕已经开启，在巨大的不确定下，企业必须更快地动态感知环境变化，源源不断地去设计研发新品，更深入地了解消费者需求，需要更柔性化的供应链板块，从外到内、从端到端构建敏捷的组织形式，从而响应各种各样的需求。这意味着，各行各业都会加速数智化转型。</p><p></p><p>其三，从改革开放到现在40多年，这期间我们的经济经历了快速发展。但是，今天大家为什么会焦虑，就是因为增速慢下来了，市场进入存量的博弈阶段。对于企业来说，必须不断寻找新的增长动力，寻找新的业务增长曲线、组织增长曲线和技术增长曲线。</p><p></p><p>第四，科技迎来寒武纪时代，云计算、大数据、人工智能、物联网等技术，经过多年发展和积累，基本上都已经到了窗口期。我们认为，此时此刻，这个时代，就是为我们准备的，如果我们再不跳进去，可能就会错失一个大好的机会。</p><p></p><h4>InfoQ：“智行合一”是一家什么样的公司？</h4><p></p><p></p><p>肖博：在中国市场，实际上没有比较大型的咨询公司、软件公司和运营公司，因此背后蕴藏着巨大的需求和机会。所以，我们对“智行合一”的定位，一句话总结，就是一个集咨询、软件、运营为一体的大型科技公司。我们的愿景，是希望能够成为全球数智化转型的首选伙伴，长期陪伴客户成长、成功；我们的使命，是让商业更高效、更智能。</p><p></p><p>我们的目标客户主要有三类：第一类是各行各业的头部品牌企业，比如雅戈尔、波司登、安踏、特步、蒙牛、飞鹤等等；第二类是致力于成为头部企业的高成长新锐品牌；第三类是包括福建、广东、浙江、江苏、山东等沿海地区的产业集群、产业带和产业互联网平台。</p><p></p><h4>InfoQ：企业在数字化转型过程中，既有共性问题，也有差异化问题，智行合一在服务客户的过程中，怎么考虑这些不同因素？</h4><p></p><p></p><p>肖博：这跟医生给病人看病很像，在掌握了医药知识之后，通过望闻问切，才能对症下药。</p><p></p><p>每个企业都是独特的，对我们来说，首先要基于通用的情况和规律，总结出一套方法论，这个方法论会涉及一些共性问题，包括战略、品牌、研发、制造、渠道、营销、服务、<a href=\"https://www.infoq.cn/theme/161\">供应链</a>\"、组织等等；然后，根据每个企业不同的情况，比如所处的行业特点、所处的发展阶段、具备的基础能力等等，用实践指导理论，最后得出更适合企业自身的解决方案。</p><p></p><p></p><h2>数智化战略制定，要“站在月球看地球，站在未来看现在”</h2><p></p><p></p><h4>InfoQ：企业转型往往要从战略开始，那么，数智化转型的战略应该从哪些方面着手制定？需要注意什么问题？</h4><p></p><p></p><p>肖博：企业转型从战略到业务、组织、技术、运营，各个环节缺一不可。</p><p></p><p>从战略角度来说，首先要对市场环境、行业趋势有洞察，要顺势而为，必要时还要借助外脑。企业不能只局限在自己内部，要去做端到端全链路的诊断，否则很容易造成断点、堵点、卡点。</p><p></p><p>举例来说，现在年轻人的消费行为都在线化了，但企业门店、商品、组织、生态、服务、协同如果都没在线，你就很难触达消费者。这意味着，企业的增长路径、增长动力都要根据这些变化重新规划。</p><p></p><p>但是，很多企业在制定战略的时候，组织能力又往往滞后于规划，导致很多事情无法落地。比如，企业知道会员运营很重要、线上线下打通很重要、知道柔性供应链很重要，但是并没有专门的人对这件事负责，这样的问题非常普遍。</p><p></p><p>再者，即便企业战略、组织都准备好了，但是系统如果还是原来的烟囱式的系统，是一座座孤岛，那业务也是跑不起来的。所以，企业一定要去建数字高速公路，以前很多工作的落实是靠经验驱动，未来世界要靠流程、数据、算力、算法去驱动。</p><p></p><h4>InfoQ：企业在这个转变过程中，面临的普遍挑战有哪些？</h4><p></p><p></p><p>肖博：我们在给企业提供咨询服务的过程中，发现经常会有一些误区：第一，只关注企业现阶段的需求，很少关注企业未来5-10年的目标，成果导向比较少；第二，只关注本企业、本行业，很少关心外面的世界，或者其它行业的最新实践；第三，用传统的调研方式做战略，只关注有利因素，忽略不利因素。</p><p></p><p>所以，我们经常会告诉企业在制定战略的时候，一定要先“跳出行业看行业，跳出企业看企业”，然后再“跳进行业看行业，跳进企业看企业”，要“站在月球看地球，站在未来看现在”。</p><p></p><p>此外，现在90%以上的企业所做的数字化，事实上都是信息化。二者的区别在于，信息化偏向于事后记录，包括入库、销售、回款等各种各样的单子，都是记录下来，然后就没有然后了。</p><p></p><p>数智化不一样，它要求企业关注大盘、关注行业、关注竞品，如果企业上下、内外不协同，中间是一堆的烟囱和孤岛，<a href=\"https://xie.infoq.cn/article/61981f4c978d6566399cb9520\">数据准确性</a>\"、及时性、完整性、一致性无法实现，那么很多事就做不了。</p><p></p><p>而在有了数据之后，企业还要能够根据数据进行分析，把内外部数据相结合，快速捕捉商机，进行更精准的产品研发和细分市场投入。以我们推出的“新品宝”为例，它可以帮助企业构建全渠道的洞察，缩短新品研发周期，降低业务风险和成本。比如，企业要推一个新品，甚至都不用打样，可以先放到网上进行测试，结合点击率、收藏率，再倒推去做生产。</p><p></p><p>过去，企业产品研发的普遍做法是进行调研，而调研样本是比较有限的，超过1000个样本已经很大了，但当我们把它放到14亿人的体量下，这些样本数据并不具有足够的代表性。所以，我们认为企业一定要用好私域，把更多权利交给消费者，然后通过更柔性化的供应链，快速上新、快速翻单。</p><p></p><h2>业务断点是营销数智化做不好的主要原因</h2><p></p><p></p><h4>InfoQ：在企业数智化战略中，营销的数智化处于什么样的位置？</h4><p></p><p></p><p>肖博：在我接触的企业中，90%以上的企业都是优先选择从营销场景入手进行数智化转型的。因为企业转型一定要让老板看到阶段性成果。数智化是一个长期工程，如果投入3-5年都没效益，事情就无法进一步推进。</p><p></p><p>所以，数智化才会被视为是“一把手”工程，这里的“一把手”不只是老板，也包括各个业务部门的一号位。他们重视的是第一生产力，比如业绩增长、利润增长、售罄率提升，库存周转率提升等等。</p><p></p><p>但需要强调的是，数智化转型不仅仅是系统升级、能力升级、技术升级，更是通过大数据洞察，不断的创造并且满足消费者需求，倒逼内部的流程和组织持续优化，以及内部资源的重新配置，不断提升业务效率。</p><p></p><p>目前那些数智化转型的领先企业，已经不止在营销端下功夫了。他们还在基于大数据洞察做新品研发、做<a href=\"https://www.infoq.cn/article/czA8H1c8QRtM1hOEW2Gw\">柔性快反</a>\"。换句话说，企业做数智化转型，不能有明显短板，一定要根据不同阶段去调整优先级和策略。</p><p></p><h4>InfoQ：越来越多的企业已经意识到这些问题的重要性，为什么还是做不好呢？</h4><p></p><p></p><p>肖博：从知道到做到，中间还有巨大的鸿沟。由于大部分企业还停留在信息化阶段，很多业务开展还是断点式的。比如，一些企业做营销数字化只做获客，实现私域与公域的打通的只有5%，其中，能够基于全域数据洞察再做精准研发的，只有1%不到。</p><p></p><p>过去企业上了<a href=\"https://xie.infoq.cn/article/2c63029c4a37890cea758ae89\">CRM</a>\"系统，就只盯着成交的老客户，天天给他们发信息。试想一下，你再喜欢一个品牌，也不可能在他们家天天买。所以，除了那些已经成交的客户，还要看那些进店但没有成交的人都去哪了，经过店铺但没有进店的人都去哪了，店铺周边的人都去哪了，甚至是店铺所在城市的所有消费者都去哪了。</p><p></p><p>这就是传统信息化系统的局限，企业一定要跳出系统，更广泛地和消费者沟通和互动，了解市场的流行趋势，以及大家关注的品类、价格，带着这些洞察去做产品研发。不仅如此，就像前面说的，再往后还要做柔性快反，提高供应链的弹性，解决高库存、高脱销、高退货这“三高”问题。同时，还要擅用销售渠道，比如直播等等，通过各种各样的手段盘活门店、盘活员工、盘活商品。</p><p></p><h4>InfoQ：能不能分享几个在数智化营销方面做得比较成功的案例？他们都做对了什么？</h4><p></p><p></p><p>肖博：这里分享几个案例：第一个是成立于2017年的HXZ，作为一个新锐品牌，HXZ去年的营收已经突破54个亿。在如此快速的增长背后，是公司从营销到商品研发、供应链体系的全链条构建和打通。在这基础上，它可以非常清楚地掌握全网的流行趋势，并且通过与消费者的互动，快速去做试销、研发、翻单。</p><p></p><p>第二个例子是BSD。不知道大家有没有发现，BSD最近几年的风格变得越来越时尚了。他们其实在多年前就上了全域的<a href=\"https://www.infoq.cn/article/SEJ62iIqiEpPfW0pRm7f\">数据中台</a>\"，如今已经能根据消费者洞察去做销量预测、智能铺货、智能补货、智能调货等一整套体系，实现端到端全产业链的联动。</p><p></p><p>第三个例子是TG集团。据了解，他们在疫情期间，对全国100多万的零售柜做了改造，通过和支付宝打通，可以精准掌握消费者画像，了解消费者的偏好，同时，商品陈列、补货信息都可以通过后端系统得到反馈，然后提供给生产端，指导生产计划。</p><p></p><p>当然，我把这样一些企业称作先锋企业，而不是标杆企业，因为，我认为在数智化转型这件事上，大家都还在路上。对于绝大多数企业来说，应该多去先锋企业看看，多参考，多借鉴，才能不断坚定自己的信心，找到适合自己的发展路径。</p><p></p><h4>InfoQ：爆品测试和宣发渠道是比较关键的，其中的投入产出应该怎么计算？</h4><p></p><p></p><p>肖博：企业一定要学会算大账。首先，对于爆品测试其实不一定要花很多钱，企业的私域、社群等等，都是很好的测试渠道。测试完，可以先试销生产一批，如果市场反馈比较好再翻单，反复迭代。但是，如果企业不去做这些测试，就把成千上万的货品都生产出来，一旦出错，就会变成巨额的库存成本。</p><p></p><p>之前，我总结过一个模型，叫“C2B2C的n次方”。也就是一切以消费者C为中心，洞察他们喜欢什么品类、价格、元素、色彩等等，然后打造爆款，toB端倒逼企业做好用户运营、新品创新、设计、研发、智能制造、渠道管理、销售和分销、品牌建设、数字化营销、配送等服务。然后精准推广服务全网、全渠道更多的消费者（C），n次方就是用“数据+算力+算法”反复迭代，反复对整个端到端全产业链路、全流程、全场景、全触点、全网、全渠道、全域、全生命周期进行优化。</p><p></p><p>所以，算账不要只算小账，很多企业经常会关注小钱，却忽视了机会成本和库存折损这些更大的风险。</p><p>用体系化的制度、流程、技术，缩短人才培养周期</p><p></p><h4>InfoQ：随着数智化转型加速，很多传统企业都表示在数字人才方面严重欠缺，对此，您有什么建议吗？</h4><p></p><p></p><p>肖博：我认为<a href=\"https://www.infoq.cn/video/Q7iEvAi0XxZdtkcFgHlB\">人才培养</a>\"光靠引进是不太靠谱的，还是应该以内部培养为主，外部引进为辅。在这个过程中，应该多走出去，一起去游学、交流。同时，还要做好培训体系和激励体系，要让卓越被看见，让进步持续发生。</p><p></p><p>首先，组织能力一定不能依赖于个人能力，通过体系建设，才能把个人知识组织化，隐性知识显性化，显性知识标准化，标准知识系统化，系统知识智能化；其次，针对人才的培养一定要因材施教，并且要有激励措施做配合，要让优秀的人被看见，要有对应的晋升通道；除此之外，工欲善其事必先利其器，企业还应该通过技术工具，为员工提供赋能，无论是做营销、全渠道、门店运营等等，都要有对应的工具去支撑。</p><p></p><p>智行合一强调的是长期陪伴客户，通过营销宝、直播宝、成长宝等一系列工具，帮企业先把最头疼的问题解决了，然后慢慢盘活各个业务环节，持续不断地循环、迭代、发展。</p><p></p><h4>InfoQ：智行合一自身是怎么培养数字化人才的？</h4><p></p><p></p><p>肖博：关于数字化人才，我们大概分为5类，包括数智化基础人才、数智化应用人才、数智化专业人才、数智化管理人才和数智化领袖人才。其中，数智化领袖人才是目前企业最稀缺的，他们往往需要具备宏观的视角、具有顶层设计的能力，以及对大趋势的判断能力。</p><p></p><p>从企业的角度来看，这意味着，企业领导一定要先把思维转变过来，如果他们不转型，只有应用、只有技术是不行的。当然，在这基础上，其它类型的数字化人才也要去持续培养。</p><p></p><p>我们认为，员工的能力培养是可以通过制度规范和组织流程缩短周期的。20年前，我曾经参观过一个苏州企业，他们的人才培养主要靠以老带新，新员工入职后，需要经过12个月的培训，才能形成与老员工一致的生产力。</p><p></p><p>而今天，在智行合一，我们的目标是把新人的培训周期压缩到1个月。比方说，在见客户之前，我们会要求每一位小伙伴先进行事前推演，包括准备跟客户怎么聊，重点客户的需求是什么等等，假设这个团队有10几位小伙伴，那么每个人就等于在心里把这件事过了10几遍。并且，在见完客户之后，每个人还会对整件事进行复盘，这相当于又学习了一轮。通过这样的方式，新的员工可以得到更快速的成长，缩短培训的周期。</p><p></p><p>当然，制度只是一方面，除此之外，我们还开发了一个产品叫“成长宝”，通过技术实现经验的沉淀和复制。包括每一位员工的职业生涯规划、绩效测评、课程市场、学习任务等等，通过数据分析，可以识别他们的优势和不足，然后针对性地分配学习任务。</p><p></p><p>我们认为，企业间的竞争，很关键的一点在于效率的竞争，而只有员工成长更快，组织才能越来越敏捷，企业竞争力才会越来越强。</p><p></p><h4>InfoQ：极客邦一直致力于数字人才培养，对于这个问题，您怎么看？</h4><p></p><p></p><p>霍太稳：我们在今年年初成立了极客邦双数研究院，并且发布了“<a href=\"https://www.infoq.cn/minibook/WvG2KwN4tFfpjtTaxNve\">数字人才粮仓模型</a>\"”，其中，我们同样把数字人才分为5类，包括：数字思维管理人才、数字思维业务人才、业务架构人才、技术架构人才和专项技术人才。</p><p></p><p>比如，企业在转型的过程中，数字思维管理者主要负责战略制定；在此基础上，还需要业务架构人才把企业的业务架构根据最新的战略梳理来；再往下，还要有对应的技术架构进行承接，要有专项技术人才去开发落地。而对照这样一个数字人才粮仓模型，企业再去做人才培养的时候能更具有参考性，可以根据欠缺的能力有针对性地进行人才培养。</p><p></p><p>具体来说，企业可以根据“数字人才粮仓模型”对人才先做解构，另外，我们还提供“研测学考评”一体化服务，可以帮助企业明确内部的<a href=\"https://time.geekbang.org/?from=jump&amp;code=11R3K%EF%BC%89\">岗位模型</a>\"，然后根据模型评测企业内部人才所处的阶段，并据此匹配相应的培训内容，让每个人可以根据自己的实际情况补足短板、完成学习，并通过考试评估学习成果，最后还会有相应的评估报告。</p><p></p><h3>嘉宾介绍</h3><p></p><p></p><p>肖利华博士，智行合一创始人兼CEO；原阿里巴巴集团副总裁、阿里云智能新零售事业部总裁、阿里研究院院长；清华大学博士后，中科院管理学博士，多所知名大学客座教授。曾任特步集团副总裁兼电子商务总经理、特步大学电商学院院长；雅戈尔集团CTO&amp;副CIO、多家女装企业常务副总、COO、CIO、供应链总监、ZARA项目总监等职。</p><p></p><p>霍太稳，极客邦科技创始人兼 CEO，InfoQ 中国创始人，极客时间创始人，TGO 鲲鹏会发起人。2007 年创立 InfoQ 中国，2014 年创立极客邦科技，2015 年发起 TGO 鲲鹏会，2017 年创立在线职业教育学习品牌极客时间，2019 年开创极客时间企业版，拓展企业服务市场。</p>",
    "publish_time": "2022-12-08 15:48:16",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "【精彩剧透】PyCon China 2022 邀您共赴技术Party！",
    "url": "https://www.infoq.cn/article/dd8d241f986f599971d096187",
    "summary": "<p></p><p><img src=\"https://static001.geekbang.org/infoq/17/17d385b18a04bb621660f50dc874f62f.png\" /></p><p>PyCon China 每年由 PyChina 社区定期举办，现如今已成为中国大型的 Python 技术会议。我们希望汇聚更多的开发者们，一起交流 Python 技术，包括人工智能、Python 特性、网络安全、服务端开发、运维、医疗、金融、开源项目等更多 Python 相关的技术领域。</p><p></p><p></p><h4>PyCon China 2022</h4><p></p><p>今年是 PyCon China 的第十二个年头，我们将一如既往为大家提供一个展现自我，也倾听他人的舞台，让大家能在这里尽情地享受 Python 带来的乐趣。</p><p></p><p>PyCon China 2022 继续采用线上➕线下相结合的模式举办，我们将在北京举办线上分会场，同时上海/深圳/杭州三个城市举办线下会场，直播为大家提供线下、线上面对面的交流机会。</p><p></p><p>大会时间：2022年12月17日</p><p>大会形式：线下相聚、线上直播</p><p>线下城市：上海、深圳、杭州</p><p>线上城市：北京</p><p>扫码报名：</p><p><img src=\"https://static001.geekbang.org/infoq/9d/9d042413c297ebbe1a2ee239b284b6df.png\" /></p><p>上海站/线下</p><p><img src=\"https://static001.geekbang.org/infoq/d6/d66749ab59ea4a076a11c50d36ffe668.png\" /></p><p>深圳站/线下</p><p><img src=\"https://static001.geekbang.org/infoq/98/9848e5765521427ca9eb2f44ddab0708.png\" /></p><p>杭州站/线下</p><p><img src=\"https://static001.geekbang.org/infoq/0b/0be5cf0fc47d15952b985722d954963a.png\" /></p><p>北京站/线上</p><p></p><p>嘉宾阵容剧透</p><p>大会正在紧锣密鼓的筹备中</p><p>今年有什么新鲜的玩法和惊喜呢？</p><p>PyCon China 2022 提前剧透来啦</p><p>！！！！！</p><p>&nbsp;</p><p>我们邀请了</p><p>互联网大厂的技术专家</p><p>Python领域活跃的伙伴</p><p>分别在线下上海/深圳/杭州站</p><p>线上北京站</p><p>为我们带来精彩的分享盛宴</p><p>👇👇👇</p><p></p><h4>主会场</h4><p></p><p><img src=\"https://static001.geekbang.org/infoq/40/4043c6fb19ff8e856905f3e419c16c9a.png\" /></p><p>Keming</p><p>TensorChord</p><p>演讲主题：《在容器中开发机器学习应用程序》</p><p>主题简介：随着快速增长的机器学习生态系统，环境变得越来越复杂。为新项目建立一个方便的环境可能需要几天时间。同时，容器也变得成熟。公司将其服务部署到 Kubernetes 集群的生产环境中，平台正在努力提供云 IDE 环境，以帮助人们顺利入门。同样的事情也发生在机器学习行业。envd' 旨在将这些特性引入机器学习开发管道。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4e/4e01ec6d1e1cb55e5a0d5c0405c9654d.png\" /></p><p>严懿宸</p><p>阿里云高级工程师</p><p>演讲主题：《Python 启动加速探索及实践》</p><p>主题简介：通过 PyCDS（代码对象共享）技术，将三方库的加载速度提升至与 Python 3.11内置模块持平的速度。在不修改应用代码的情况下，实现15%-20%的启动加速。该方案还被集成到了 Serverless 解决方案中，能够显著减少 Serverless 场景下的冷启动开销。</p><p>我们将从 CPython 社区相关工作、本方案的设计及实现、以及业务层面的集成等方面进行介绍。</p><p></p><h4>上海站</h4><p></p><p>活动报名：</p><p>线下参会：<a href=\"http://hdxu.cn/fMxVb\">http://hdxu.cn/fMxVb</a>\"</p><p>线上参会：<a href=\"http://hdxu.cn/fn0z1\">http://hdxu.cn/fn0z1</a>\"</p><p><img src=\"https://static001.geekbang.org/infoq/a8/a8b7f1f2fedb3752e6e3c2b108c123fd.jpeg\" /></p><p>Ai兔兔</p><p>上海九方云智能科技有限公司</p><p>演讲主题：《在 AIGC 元年抛一块砖》</p><p>主题简介：2022年被定义为 AIGC 元年。那么，什么是 AIGC？这个概念又是如何兴起的？它主要包含哪些方向和技术？它的未来又如何？哪些方向是我们该关注并下功夫去做的？在该演讲中，演讲者将作为一名不那么大型的公司中一名小小的程序员，谈谈自己对 AIGC 非常具有局限性的认识和看法。作为抛出的小小一块砖，希望能一石激起千层浪，引出更多的美玉。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0d/0dc1c647342c87caf9a0249cc42d4738.png\" /></p><p>古思为</p><p>NebulaGraph 项目开发者布道师，微软 MVP</p><p>演讲主题：《搭建基于图神经网络的实时欺诈检测系统》</p><p>主题简介：在这个主题中，为大家解谜基于图技术的欺诈检测方法，并给出他基于 Nebula-DGL（NebulaGraph-Deep Graph Library-Adaptor) 开源项目，端到端的设计代码实现，帮助大家快速了解整套 GNN 与图数据库结合的方法。&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/90/90697e544482f1d4b8e32ccc5ad2350d.png\" /></p><p>羿莉/YiLi</p><p>阿里云高级开发工程师&nbsp;</p><p>演讲主题：《Python Profiling 原理深入探索与实践》</p><p>主题简介：使用 Profiling 是监控代码的资源开销、定位问题的有效手段，基于已有的 Profiling 工具链，目前也出现了一些新兴的持续监控方案。此次分享我们将从 Python Profiling 的原理出发，讨论其最新的监控方案 Continuous Profiling 等，并动手实战完成 Python系统的剖析与分析流程。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ee/ee8ecdc64a57d62afda0afef5bf984c3.jpeg\" /></p><p>李枫</p><p>独立开发者</p><p>演讲主题：《Cocotb--硬件验证中的瑞士军刀》</p><p>主题简介：</p><p>本议题将包含下列子话题：</p><p>1) 基于 Python 的硬件测试验证综述；</p><p>2)基于Cocotb的SpinalHDL的测试验证，并在ARM开放硬件平台(如树莓派4)上实践；</p><p>3)使用Cocotb进行测试验证的智能网卡项目Corundum，并在ARM开放硬件平台(如树莓派4)上实践；</p><p>4) 探索 Cocotb 的未来--CocotbD 项目的设想与设计。</p><p></p><h4>闪电演讲</h4><p></p><p>韩骏：微软开发平台事业部高级软件工程师</p><p>演讲主题：《在浏览器中运行 Python》</p><p>主题简介：在 2019 年 12 月，W3C 正式宣布，WebAssembly 将成为除现有的 HTML、CSS 以及 JavaScript 之外的第四种，官方推荐在 Web 平台上使用的“语言”。</p><p>WebAssembly 的出现，使得不同的编程语言运行在浏览器中，成为了可能。</p><p>那么，我们如何能让 Python 运行在浏览器中？背后还需要用哪些技术？更进一步地，在纯浏览器环境中调试 Python 是否可行？</p><p></p><p>刘凡平：连续创业者</p><p>演讲主题：《基于 Python 的深度学习框架设计与实现》</p><p>主题简介：大致介绍思路：</p><p>（1）首先介绍深度学习框架的基本逻辑及原理；</p><p>（2）其次介绍 Python 针对深度学习框架的设计思路与架构；</p><p>（3）然后通过一个示例介绍该深度学习框架的实现，并通过2-3个案例，介绍该深度学习框架的应用方式及案例；</p><p>（4）最后延伸性介绍自实现的深度学习框架在不同场景中应用；</p><p></p><p>杨华：海豚跃跃联合创始人、首席运营官</p><p>演讲主题：《基于海量数据的实体关系抽取实践》</p><p>主题简介：通过案例综合介绍实体关系抽取，使得听众进一步了解Python在人工智能的相关应用。</p><p></p><h4>杭州站</h4><p></p><p>活动报名：</p><p>线下参会：<a href=\"http://hdxu.cn/52bJH\">http://hdxu.cn/52bJH</a>\"</p><p>线上参会：<a href=\"http://hdxu.cn/7cxLP\">http://hdxu.cn/7cxLP</a>\"</p><p><img src=\"https://static001.geekbang.org/infoq/7c/7c307085ce994927bef44a649aefa7b7.png\" /></p><p>朱宏林</p><p>阿里云程序语言与编译器研发工程师</p><p>演讲主题：《ARM 芯片的 Python+AI 算力优化》</p><p>主题简介：本次演讲，将向大家介绍我们在倚天710 ARM 芯片上开展的 Python+AI 优化工作，以及在 ARM 云平台上部署 Python+AI 任务的最佳实践。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/37/375b05d072f9ad5aea1021e7a48f0ff7.jpeg\" /></p><p>张翔</p><p>Python committer since 2016</p><p>PingCAP Cloud Ecosystem&nbsp;Service Team Leader</p><p>演讲主题：《使用 Streamlit 在 Python 脚本中快速构建一个可共享数据应用程序》</p><p>主题简介：streamlit 是一个开源库，它可以在几分钟内将数据脚本转换为可共享的 web 应用程序，全部使用纯 Python。本次演讲将向用户展示如何使用 streamlit 和 streamlit Cloud 来构建和部署一个数据应用程序，以及 streamlit 如何改变数据应用程序开发的工作流。结合 DBaaS（如 TiDB Cloud） ，用户可以安全地存储状态，并在数据应用程序中使用它们。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e7/e7186202e28a076b594b003556422b94.png\" /></p><p>张凯莉</p><p>中兴通讯股份有限公司人工智能算法工程师</p><p>演讲主题：《Adlik 深度学习推理加速工具链的应用》</p><p>主题简介：Adlik 是一种将深度学习模型从训练完成，到部署到特定硬件并提供应用服务的端到端工具链，能够实现模型从研发状态到生产应用环境的高效切换；Adlik 与多种推理引擎协作（TensorFlow、TensorFlow_lite、PyTorch、TensorRT、OpenVINO、PaddlePaddle 和燧原芯片等），提供灵活的模型加速、部署、推理方案，助力用户构建高性能AI应用。</p><p></p><p>对于训练好的模型，Adlik 可以通过剪枝和量化对模型进行优化；优化好的模型可以使用 Adlik 的模型编译器进行模型转换（这部分通过简单的 Python 脚本即可完成），方便用户部署到云端、边侧或者端侧，Adlik 模型编译器目前支持大多数格式的模型文件（ckpt、pb、h5、onnx、pth等），方便用户对于不同训练框架的模型进行操作；对于编译好的模型，用户可以使用 Adlik serving 进行服务部署，然后使用部署好的服务进行推理，同一个模型部署的不同类型的服务可以使用同一套 Python 客户端代码进行推理，方便用户测试最优的服务部署方案。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/74/74636a5d7ffc8265420e3d0ef90c7cc1.png\" /></p><p>王铁震</p><p>hugigingface 工程师</p><p>前谷歌TensorFlow团队成员。</p><p>演讲主题：《人人都可以用的 AI 工具》</p><p>主题简介：</p><p>- 用 transformers 进行自然语言处理</p><p>- 用 diffusers 生成艺术作品</p><p>- 用 gradio 在线部署 AI 产品</p><p></p><h4>闪电演讲</h4><p></p><p>沈达：比图科技数据工程师</p><p>演讲主题：《Pants:Python工程化必备构建工具》</p><p>主题简介：在数据与 AI 领域，Python 语言正大放异彩！但和 Python 在各个领域的广泛应用相比，其主流的构建工具非常羸弱。在 Python 项目变得更加复杂，参与的工程师数量攀升时，除了 Python 作为动态语言的固有缺点以外，构建和部署也是大型 Python 项目难以驾驭的一大原因。</p><p>Pants 正是解决大型 Python 项目的不二选择！沈达将从 Pants 用户的角度，阐释如何用 Pants 构筑 Python 工程化的基石。</p><p></p><h4>深圳站</h4><p></p><p>活动报名：</p><p>线下参会：<a href=\"http://hdxu.cn/8c4nd\">http://hdxu.cn/8c4nd</a>\"</p><p>线上参会：<a href=\"http://hdxu.cn/52VeE\">http://hdxu.cn/52VeE</a>\"</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/33/3329838134108b61ff89adf59e2e7688.png\" /></p><p>康昊/Nemo</p><p>资深开发工程师</p><p>演讲主题：《Python 赋能智慧物流》</p><p>&nbsp;主题简介：随着电商发展及智能制造2025的加速落地，物流无人化、智能化优势显现。Python完备的开源生态，使我们实现了基于云端的 AMR 智能调度系统，具备任务控制、交通管制、自动回充、异常/断点处理，机器学习等基本功能。其良好的 OOP &nbsp;特性，契合了场景中地图、任务、AMR 等基本属性，根据不同场景继承基本功能再派生出各自属性，适配场景广，也便于功能迭代和维护。</p><p>同时开发了 AMR 仿真模型，剥离本体导航逻辑，实现适配 slam/二维码场景，具备状态机、运动、定位、任务模块的 AMR 仿真模型，用于场景仿真及方案论证。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/95/9505747ed606b9a4246ca7db893328b3.jpeg\" /></p><p>刘宇宙</p><p>资深开发工程师</p><p>演讲主题：《云原生场景下的 AI 落地》</p><p>主题简介：云原生业已成为了云计算行业下一代的标准。目前，除了传统应用与基础架构的云原生化，AI 与大数据也开始拥抱云原生的架构。云原生下 AI 的落地旨在利用云原生的思想和技术，为 AI 场景的数据处理、模型训练、模型上线推理等需求构建弹性可扩展的系统架构的技术，在支持更广泛、多样的用户需求的同时，提高开发、运维和设备的效率。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/46/463c1a23f4cc896eec214e2ca54ad759.png\" /></p><p>卢建晖</p><p>微软云技术布道师</p><p>演讲主题：《用 GitHub 完成 Python 的全技术栈开发》</p><p>主题简介：大家有在 GitHub 做开源项目吗？新一代的 GitHub 不仅有代码，CI/CD 等项目管理的功能，还可以结合 GitHub CodeSpaces 完成跨终端跨应用场景的代码编译更好维护你的开源项目。本次课程会用 GitHub CodeSpaces 和 GitHub CodeSpaces 打造一个全场景 AIoT 解决方案。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b1/b1b27b1017b49c54ae87db1786a18918.png\" /></p><p>付杰</p><p>Jina AI 高级软件工程师</p><p>演讲主题：《多模态应用场景下的高性能 Embedding 计算服务》</p><p>主题简介：本次演讲的主题是介绍多模态场景下的向量搜索技术，以及如何使用 CLIP-as-Service 的服务快速搭建跨模态向量检索引擎。本演讲首先会阐述目前多模态技术的发展应用及其多模态表征模型（尤其是 CLIP）的原理及一些相关的下游应用，然后讲述如何使用预训练好的多模态模型获得输入数据的 embedding，以及一个满足工业界需求的 embedding service 需要包含哪些功能。最后展示我们的 CLIP-as-Service 的一些现有功能以及一些简单的 demo。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/55/55359dc35426fd2f9f287d4af55d5551.jpeg\" /></p><p>黄志武</p><p>华世界集团创始人</p><p>演讲主题：《Python Web 大型项目开发进击之路》</p><p>主题简介：本议题主要介绍当时为什么选择 Django 作为 web 开发框架，今天我们还有哪些更好的选择。我们遇到了哪些问题，怎么解决的？主要从研发和平台发展的过程中分享遇到的实际的问题讲解如何解决。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8d/8dd2fc29aae2bfacd61d0ba2378e4ff0.png\" /></p><p>王文洋</p><p>腾讯 TEG 编译器研发程序猿</p><p>演讲主题：《大规模生产环境下的 faster-cpython》</p><p>主题简介：CPython3.11&nbsp;的出现给&nbsp;Python&nbsp;被人诟病的执行性能带来一丝惊喜。然而，作为软件基石的&nbsp;Python&nbsp;解释器，在大规模生产环境下如果贸然升级必然会带来难以预料的后果。</p><p>如何在生产环境下安全的享受&nbsp;CPython3.11&nbsp;带来的性能提升？相比较于&nbsp;Cython、Numba&nbsp;之类的库，从解释器层面进行优化又有哪些好处？作为&nbsp;Python&nbsp;开发者，如何评估代码的性能问题？让我们一起聊一聊&nbsp;Python&nbsp;性能提升那些事儿。</p><p></p><h4>闪电演讲</h4><p></p><p>代少飞：某互联网公司金融量化开发从业者，现从事&nbsp;web3&nbsp;相关工作</p><p>演讲主题：《使用&nbsp;Python&nbsp;分析&nbsp;alpha vaults&nbsp;策略》</p><p>主题简介：alpha vaults&nbsp;已经被证明是非常成功的产品，让我们使用&nbsp;Python&nbsp;来解读他。</p><p></p><p>缪振海：Web3从业者</p><p>演讲主题：《一个文科生的&nbsp;Python&nbsp;应用进阶之路》</p><p>主题介绍：如何使用&nbsp;Python&nbsp;提高效率，赋能工作和生活。</p><p></p><h4>北京站</h4><p></p><p>活动报名：<a href=\"http://hdxu.cn/RYxNJ\">http://hdxu.cn/RYxNJ</a>\"</p><p><img src=\"https://static001.geekbang.org/infoq/2f/2f2555e78523f380df3f83b102551f9c.jpeg\" /></p><p>李奕澎 / Yipeng Li</p><p>NVIDIA 企业级开发者社区高级经理</p><p>演讲主题：《基于 Python 实现语音 AI 的快速开发 — Azure+NeMo 实战》</p><p>主题简介：通过本次活动 Python 的开发者将学习到语音识别、语音合成工作流程和原理，熟悉 Azure 与 NeMo 的使用，了解语音数据集构建、实践模型的训练与推理。掌握对话式 AI 的基础开发流程。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8f/8f77ecb8a9ace160e4e825a592e4c88c.png\" /></p><p>王博</p><p>Jina AI Engineering Manager</p><p>演讲主题：《我们的构建模型微调服务之旅》</p><p>主题简介：Jina 是构建跨模式和多模式应用程序的 MLOps 平台。我们的主要应用之一是神经搜索。神经搜索的目的是将不同形式的数据编码为向量表示，并在向量空间中找到最相似的项目。然而，由于预先训练的模型和应用领域的分布变化，模型微调对于弥补差距至关重要。在本次演讲中，我想分享我们如何对搜索嵌入进行微调，以及如何将模型微调作为一种服务，以更好地服务于最终用户。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ed/ed79edf5e99bfc6d0507b6cea3757da9.png\" /></p><p>张晋API7.ai 云原生技术专家</p><p>演讲主题：《用 Python 给 Kubernetes 写个自定义控制器》</p><p>主题简介：Kubernetes 提供了多种灵活的方式进行扩展，在实际使用过程中，我们也会遇到各种需要自定义扩展的场景。本次分享将介绍如何使用 Python 为 Kubernetes 开发一个自定义控制器，并实现一些常规的需求。</p><p></p><p>后续将为大家详细介绍</p><p>每个城市站对应的嘉宾阵容</p><p>敬请期待……</p><p>❤️❤️❤️</p><p></p><h4>主办方合作伙伴</h4><p></p><p>每一届的大会都离不开大家的支持</p><p>欢迎老朋友、新朋友</p><p>非常感谢各位的支持与赞助</p><p>合作伙伴持续招募中～</p><p></p><p>主办方</p><p><img src=\"https://static001.geekbang.org/infoq/fc/fc730389bbbc9711cc317370382770f8.jpeg\" /></p><p>白金赞助</p><p><img src=\"https://static001.geekbang.org/infoq/60/605ffa0846e0a9c684f9f767e6f3b1fb.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/45/45bb46c8ef5350edec79bde1f9e1d264.png\" /></p><p></p><p>白银赞助</p><p><img src=\"https://static001.geekbang.org/infoq/e2/e25c0dad6840e7bb068ed412294b4e0a.png\" /></p><p></p><p>特别支持伙伴</p><p><img src=\"https://static001.geekbang.org/infoq/68/68f10634704dac30174d67e63ccdb9ce.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/47/4716e72b6358f70880660a762581bf0e.png\" /></p><p></p><p>战略媒体伙伴</p><p><img src=\"https://static001.geekbang.org/infoq/33/332c9f4f6651b7b4b76cf899a7b82d43.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bd/bdac964686af6de33a6f891043cef6d7.png\" /></p><p></p><p></p>",
    "publish_time": "2022-12-08 16:15:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "重写 50 万行代码，从 0 自研的云原生 HSTAP 能否成为数据库的未来？",
    "url": "https://www.infoq.cn/article/Dm4VbCIzLpDADad7GIPy",
    "summary": "<p>HTAP，一个为满足实时性业务分析场景而存在的数据库。</p><p></p><p>从 2005 年被 Gartner 首次提出以来，HTAP 已经历经数十年的发展期。在当下，如果再次提起 HTAP，不免让人觉得它是个既“友好”又“矛盾”的存在。</p><p></p><p>“友好”在于，HTAP 数据库能够同时支撑业务系统和在离线数据分析系统运行，避免在传统架构中，在线与离线数据库之间大量的数据交互，对简化企业的数据系统的复杂度将起到至关重要的作用；但“矛盾”在于，用户在 AP 场景和 TP 场景负载模型差异很大，对数据库的诉求也完全不同，如何通过技术手段来平衡他们之间的矛盾成为了 HTAP 数据库的核心问题，因此，一定要有东西在这两者之间做桥梁。</p><p></p><p>至此，问题也就显露出来了。用户如何能在 TP 还是 AP 负载下，随心所欲地去创建各种表，也可以随心所欲地用一个流呢？在超融合趋势的推动之下，HSTAP 的概念呼之欲出，多出来的“S”格外让人好奇到底是不是在造概念。为了深入了解 HSTAP 的技术架构与产品特性，InfoQ 特别采访了<a href=\"https://www.infoq.cn/u/matrixorigin/publish\">矩阵起源</a>\"技术 VP 秦姝琦。</p><p></p><h2>技术的发展有迹可循，先谈谈为何提出 HSTAP</h2><p></p><p></p><p>要知道，一个技术概念之所以被提出，究其根本还是为了解决某一类痛点问题。比如，近几年 IoT 产业以及 AI 行业的兴起，产生了大量的时序数据以及图数据，在底层数据类型愈发多样的前提下，直接催生出了一批时序数据库和图数据库。</p><p></p><p>那么，<a href=\"https://xie.infoq.cn/article/2ecb15c650ea1dc82f8f3d41e\">HSTAP </a>\"为何会被提出呢？若想真正理解 HSTAP 的内核，不妨先看看它到底要解决业界的哪些问题。</p><p></p><p>拿一个典型的融合型场景为例，一款股票 APP 本身是交易系统，所以它需要一个 OLTP 数据库做支撑，但是用户又希望其提供股市的预测和分析，这里自然就出现了对 OLAP 系统的需求，即在做大规模交易的同时，还需要基于交易数据和用户行为数据进行分析建模。</p><p></p><p>要想解决上述问题，常规的技术方案是怎样的呢？如下图所示，企业需要用到非常多的中间件来搭建一个复杂的数据系统，其中包括 OLTP 数据库、OLAP 数据库，消息队列、流引擎、ETL 工具等等，这样一来，会导致系统变得非常复杂，难以保证稳定性；其次，数据流转的链路也变得很长，实时性无法保证，数据血缘管理难度很大，这种基于“缝合”方式搭建的系统，在稳定性、实时性以及运维管理成本和开发成本上存在很多痛点。</p><p><img src=\"https://static001.geekbang.org/infoq/11/11a4dcca917cc0925b46d43bcc6c60ee.png\" /></p><p></p><p>在刚刚结束的 2022 re:Invent 大会中，亚马逊云科技提出了一个新的名词——“Zero-ETL”，其本质也是识别到了数据流转已经成为企业很大的痛点。不难看出，简化复杂架构，降低运维使用成本的需求正在不断增长。为了让企业只用一款数据库，就能把最基础的业务中台和数据中台以最低的成本建设好，矩阵起源对 HTAP 进行了重新定义，融入了串联 AP 和 TP 的 Streaming 能力。因此，在秦姝琦看来，HSTAP 的出现便是为了简化数据系统的复杂性，提供极简的用户体验，降低数据使用的难度，让企业可以将精力从繁杂的技术细节中释放出来，专注于数据价值的挖掘，最终达到降本增效的目标。</p><p></p><h2>从 0 开始自研，MatrixOne 的架构解析</h2><p></p><p></p><p>在数据库的起步阶段，选择一些现成的数据库进行改写往往是一种较为容易的方案，但如果再做深入定制便会比较痛苦。为了避免不受历史包袱的影响，MatrixOne &nbsp;从设计之初便放弃了一条相对容易的路，选择从 0 开始自研，用时七个月将 Share Nothing 迁移到云原生架构，从 AOE（Append Optimized Engine）存储切换到 TAE（Transactional Analytical Engine），重写了计算引擎（Parser，执行计划，优化器等），并且完成了分布式事务框架和高性能日志服务的研发，累计删除代码 30 万行，新增 20 万行。</p><p></p><p>这背后的工作量与执行力足以让我们叹为观止，但回忆起 MatrixOne 的起步期，秦姝琦提到：“在真正设计开发这样一款云原生 HSTAP 数据库的时候，我们面临非常多的艰难选择。”</p><p></p><p>具体来说，用户对于 TP 和 AP 数据库系统的需求基本可以归纳为以下五点：ACID，并发性能，吞吐，成本和数据新鲜度。HSTAP 数据库若想兼容以上能力，实现起来却没那么容易，由于高并发、短时延的 OLTP 负载与带宽密集型、高时延的 OLAP 负载的访问模式不同且它们互相干扰，把他们融合到一个系统里存在很多的冲突点。</p><p><img src=\"https://static001.geekbang.org/infoq/22/2210848a2764cf048227b5f4accef181.png\" /></p><p>谈及如何平衡上述矛盾，秦姝琦以通信领域中两个耳熟能详的概念为例：频分复用和时分复用，即当突破资源粒度划分得足够小，资源隔离做得足够好，调度能力足够强时，就可以把一些看似矛盾的功能平衡起来。“因此，在设计 HSTAP 数据库时，我们不会追求以上提到的五点在同一时间都做到 100 分，而是基于统一存储引擎，对象存储，自适应计算优化，计算存储独立扩缩容，全局的资源调度和资源隔离策略动态平衡这五个看似矛盾的特性，来适应不同的负载场景需求。”</p><p></p><p>基于这样的设计理念，MatrixOne 引擎的顶层设计架构，可以大致分为三层：计算层、分布式事务层和共享存储层。</p><p><img src=\"https://static001.geekbang.org/infoq/cd/cd707f1133582f033bc352caac82a02a.png\" /></p><p></p><p>其中，计算层是由多组计算资源组成的，其中计算单元我们称之为 CN，每个 CN 可以承担不同的任务，但无论 CN 用于何种用途它本身是不保存任何状态的，以保证计算层是可以任意扩缩容的；再往下面一层是 Transaction Layer，这一层承担了分布式事务处理的相关工作。分布式事务层选择了 share-nothing 的模式，由于每个 DN 之间需要处理的数据范围各不相关，这样做的好处在于，每个 DN 只需要负责自己这部分数据的冲突检测，从设计上简化了 DN 的实现复杂度和扩缩容的难度；再往下是两个服务，一个是 Log service，为 DN 提供高性能的分布式高可用的日志读写服务，它直接决定事务写性能的关键；另外一个是共享存储，这里不仅支持 S3 这类对象存储，还支持 NFS 以及 HDFS。</p><p></p><p>此外，为了让 MatrixOne 在云上和私有化场景能够保持统一的架构和接口，还在底层架构中抽象了一层 fileservice 接口，它会将底层不同的共享存储实现细节屏蔽掉。比如，在云上选择S3作为底层共享存储，那么在私有化场景不一定有 S3，客户如果能提供 HDFS 集群，就可以通过 fileservice 在保持引擎接口一致的前提下，支持多种的共享存储。</p><p></p><p>除此之外，MatrixOneGA版本将会有一个重要的特性——实现了Streaming的方案，即HSTAP中的“S”。秦姝琦坦言，目前的 Streaming 还处于早期阶段，团队关注的核心问题还是 framework 的设计、有界数据和无界数据的处理以及增量计算的优化等等。</p><p></p><h2>MatrixOne 上云的价值与实现路径</h2><p></p><p></p><p>有了上述方案以后，MatrixOne 是否就可以为用户带来简单、易用的最终体验呢？显然还不够，一个普遍的现象是，当云逐渐变成新的基础设施以后，开发者几乎不会触碰到云服务下层的基础设施，这对于数据库厂商而言，也需要思考如何利用云服务作为底座来构建数据库。因此，在此基础上，MatrixOne 也计划上线全托管 MatrixOne 服务 -MO Cloud，目前已经处于开发阶段，目标支持多个国内外公有云如 AWS、GCP、华为云、阿里云等等，其具备的主要特点是 SaaS 化的使用体验，免部署、自动化运维、按量计费、成本低。</p><p></p><p>为了实现自动化运维的特性，MO Cloud 也选择拥抱了 Kubernetes 生态，然而 MatrixOne 作为一个有状态的系统，它具有自己独有的状态编排的领域知识，如果 Kubernetes 没有这些领域知识，便无法很好地对 MatrixOne 进行编排和调度。因此，MatirxOne 还上线了专属的 MO-Operator，它封装了编排调度 MatrixOne 所需要的全部领域知识，再利用 Kubernetes API 添加自定义 API 类型的能力，来保证运行中的集群状态永远向用户定义的期望状态转移。目前，MO-Operator 已经实现了创建集群、资源伸缩调度，故障转移，滚动更新等功能。“MO-Operator 就像一个经验丰富的运维同学时刻监控 MatrixOne 集群的状态，而且一切按规则执行永不休息。” 秦姝琦比喻道。</p><p></p><p>实际上，上述所提到的 MO-Operator 只是 MOCloud 的冰山一角，下图展示了 MOCloud 的架构图，包含平台（Platform）和编排（ COS） 两套系统以及旁路观测系统。架构图的上半部分是 MOCloud 的控制面，Platform 包含了一组微服务，比如用户管理，集群管理，计费等，是整个 MOCloud 中唯一需要跟用户进行交互的部分，中间的 Global API Server 是 COS 的核心，也是 Platform 跟 COS 之间的纽带，架构图的下半部分是 MOCloud 的数据面，也就是真正运行工作负载的地方。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/46/46f30a0a41b1c6a1c25c767ef9889458.png\" /></p><p>值得一提的是，自 Serverless 被认为是新一代云计算发展方向以来，业内就开始关注、推进 Serverless 化，试图从资源视角转换为服务视角。在今年的阿里云栖大会上，阿里云宣布将坚定推进核心产品全面 Serverless 化；在 2022 re: Invent 大会上，亚马逊云科技宣布将数据分析服务全面 Serverless 化. MOCloud 也开始了对于 Serverless 的探索。</p><p></p><p>秦姝琦认为实现 Serverless 化有两方面好处：一方面，Serverless 对于很多中小型企业很友好，注册即可使用，无需关心任何底层资源，当企业不使用数据库时，也不用付出任何成本；另一方面，站在数据库厂商的角度来看，虽然 Serverless 在前期的投入成本相对较高，但后期可以带来更大的商业回报，是提升收益的一种技术手段。</p><p></p><p>尽管 Serverless 对于供需双方的价值已经趋向清晰，但是数据库 Serverless 化的实现难度却很高，在秦姝琦看来，主要技术挑战大致可以分为三个部分：第一是安全性，即多租户的资源隔离；第二点资源调度，如何让系统负载达到最优；第三点是整个系统的弹性、高可用。</p><p></p><p>在采访过程中，秦姝琦主要为我们介绍了 MOCloud 在资源隔离方面的实现进展。在数据的可见性上，MOCloud 可以保证逻辑上的隔离，一个 Session 只能看到这个租户权限范围内的数据，在资源隔离上，还计划用 Proxy+rule engine+CN 来完成一个全局的流控和资源调度，CN 支持独占 Set 来满足更多元化的要求。此外，针对大家关注的安全问题，MOCloud 也会保证持久化的数据是加密的，未来将支持“ bring your own key”的模式，支持租户维度的数据加密。</p><p></p><h2>未来发展方向</h2><p></p><p></p><p>数据库从来都不会单独被使用，尤其对于初创的数据库厂商而言，完善生态也是非常重要的工作。秦姝琦透露，在更完整的生态对接方面，MatirxOne 将在明年陆续在开源项目上开展对接，还计划针对制造业、能源、新兴互联网等行业，制定相应的解决方案，为此也会在 MatirxOne 中接入相应的生态。</p><p></p><p>与此同时，她还介绍了 MatirxOne 在未来的产品规划。预计在明年，MatirxOne 将会推出第一个 GA 版本，接下来还将继续融入流的能力，力争通过一个 HSTAP 数据库满足通用场景的需求。虽然实现起来还需要一定的开发周期，但我们也很乐于看到，未来有更多的数据库厂商能够通过创新的架构实践、极简的设计理念，来不断降低企业使用数据系统的复杂度和门槛。</p>",
    "publish_time": "2022-12-08 16:38:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "SpaceX效应——聊聊宇航巨子背后的企业文化",
    "url": "https://www.infoq.cn/article/ZCIUqvc0qJpWhAZSsM9l",
    "summary": "<p></p><p></p><p>用使命、影响力、高度强调输出的工作环境，“帮助”员工发挥出最大潜能，同时也挤占了他们的生活空间，这些管理文化体现在马斯克的多家公司里：SpaceX、Tesla、OpenAI、Neuralink 和 The Boring Company。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b1/b1a862befa3d9187e543b3f8000d2815.png\" /></p><p></p><p></p><h2>执行：简化流程，快速行动</h2><p></p><p></p><h3>1. 让需求不再那么蠢</h3><p></p><p></p><p>首先接受一个观念，“你的很多要求非常愚蠢”。多年之前，马斯克曾专门拿出时间解决Model 3车型的电池组生产问题。当时，玻璃纤维面板成了整个生产流程中的瓶颈。</p><p></p><p>最终，他问电池安全团队，“这块板子是干啥用的？”团队说它的意义就是减少噪音和振动。于是马斯克又去找噪声振动分析团队，对方给出的解释是“为了防火”。两边相互指指点点，都不承认自己的理解有问题。最终，他们测试了一下声音，发现加不加板子没有任何影响。这就是所谓“非常愚蠢的要求”。</p><p>但这类错误一直在发生。人们往往无脑遵循着长久以来的惯例，却很少问问为什么要这样。马斯克还特别提出，有些愚蠢的要求是非常聪明的人提出的，所以其他同事可能不太敢质疑他们。但无论是谁，“对就是对，错就是错。要接受每个人都可能犯错。”</p><p></p><p>为了解决这个问题，SpaceX要求“每条要求都对应具体的人，而不是一整个部门。”把责任归咎于整个部门基本等于不问责，而归咎于个人则可以：1）加快追踪速度；2）明确度和关注度都会更高。</p><p></p><h3>2. 清除愚蠢的部分</h3><p></p><p></p><p>在发现了愚蠢的部分或流程后，当然要将其消除。还是以玻璃纤维板为例，去掉这个环节帮公司节省了200万美元。但这是个明显的案例，还有很多情况没那么明显，我们得用更积极的态度加以解决。</p><p></p><p>大型组织往往有种偏见，就是与其废弃、不如保留。人们特别害怕在决定清除某些部分后，又被迫把它们再找回来。没错，这确实会浪费时间，但同样的心态也让我们保留了无数用来“以防万一”的部分或流程，这些东西加起来严重拖慢了整个体系的运转速度。</p><p></p><p></p><blockquote>&nbsp;“如果你没有偶尔加点东西回去，就说明你清除得不够彻底。”——埃隆·马斯克</blockquote><p></p><p></p><p>例如，马斯克就讨论了星舰上的网格鳍为什么不能折叠。他们其实做过尝试，但后来发现没必要。项目组最终没有放任不管，而是明确决定去掉折叠功能。折叠动作只是单纯增加了复杂性，却没有任何实质性的好处，所以不予保留。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/00/001eaabcd5c6964804240504947d7a73.png\" /></p><p></p><p>SpaceX的目标就是将不可能转化为可能。利润空间有限，养不起白白占位置的功能。而大多数企业正是因为没有这样的紧迫性，反而难以剔除身上的“寄生虫”。</p><p></p><h3>3.&nbsp;简化或者优化</h3><p></p><p></p><p>在去掉了愚蠢的需求和不必要的步骤之外，接下来就是简化和优化。</p><p></p><p></p><blockquote>“聪明的工程师们最常犯的错误，就是优化了本该去掉的东西。”</blockquote><p></p><p></p><p>高中和大学的教育经历，让我们学会了给问题找答案。但如果我们面对的是个蠢问题，又该如何？还是以玻璃纤维板为例，教授可能在卷子上这样出题：“这些玻璃纤维面板由于A、B和C等原因而难以正常生产……你要如何解决这个制造难题？”</p><p></p><p>但我们首先该问的是，“这块板子真有必要吗？能不能改用其他材料？课题小组的具体目标是什么？”这才是问题的核心。</p><p></p><p>所以不妨破除对问题本身的敬畏心态，真正探究背后的答案。马斯克认为，很多人其实在无意识当中一直穿着这件“精神紧身衣”。</p><p></p><h3>4. 加快实施周期</h3><p></p><p></p><p></p><blockquote>“你走得太慢了，还能更快……实施周期总有进一步缩短的空间。”</blockquote><p></p><p></p><p>在采取前面三个步骤之后，工作肯定会推进得相当快。从SpaceX的运作就能看到，这是一家高度强调速度的企业。他们虽然打破了大多数人甚至闻所未闻的障碍，但马斯克认为还不够、还可以更快！</p><p>除非拦路的是物理学的基本限制，否则并不存在真正的硬性边界。对速度的追求应当永无止境。</p><p></p><h3>5. 自动化</h3><p></p><p>最终，加快实施周期的最简单方法就是……自动化！只要执行得当，自动化能够同时提升速度和质量。</p><p>但自动化中最关键的部分，在于实现目标的途径。大多数人其实是倒果为因，从后向前做设计：我们能够怎样实现自动化？能够怎样加快速度？最终发现，可能需要做点简化，比如删除某些难以自动化的环节等。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ab/ab9aecc19ce1e44094246ce08aa464b2.png\" /></p><p></p><p>但请别忘记，自动化才是最后一步。无论自不自动化，那些愚蠢的要求和不必要的环节本来就不应该存在。我们应当先做简化，等确定了最为精简高效的流程之后，再向其中引入自动化设计。</p><p></p><h2>文化：使命感与主人翁精神</h2><p></p><p>这是个典型的说起来容易、做起来难的问题。到底该如何实现？包括SpaceX在内，任何企业都不可能在热情满满的创始人的时刻监督之下运行。要真正培养起使命感与主人翁精神，首先得创造出有感染力的企业文化。</p><p></p><h3>6. 对使命的承诺</h3><p></p><p>一切都源自马斯克提出的使命：让人类成为跨行星物种。这听起来很疯狂，但却极具号召力。</p><p>就在几年之前，“专家”们还说不可能存在重复使用的火箭，但SpaceX已经证明他们错了。</p><p></p><p>而对使命的认同和承诺，也在SpaceX公司之内的三大层面发挥着重要作用：</p><p>招聘筛选促进激励均衡调和</p><p></p><p>首先，这是一项雄心勃勃的计划，而且是有意为之。SpaceX正在追求将不可能转化为可能，他们从来不回避这一点。时至今日，我们还是很难相信火箭居然不再是耗材、而是可回收的持续性组件。同样的想法放在2008年，甚至是SpaceX刚刚成立的2002年，那简直是个天大的笑话。</p><p></p><p>但这实际上帮助了SpaceX，因为他们可以靠这一点筛选应聘者。很多人觉得SpaceX风险太大，没准不久之后就破产了。只有最乐于冒险、积极向上且渴望打造酷炫产品的工程师，才愿意为SpaceX效力。而事实证明，这就是SpaceX最需要的人才类型。</p><p></p><p>其二，这项使命有着促进和激励的作用。跨行星探索非常紧迫，这里的原因有两点。首先，在马斯克看来，文明实现跨星球壮举是要依托于机会窗口的。一种极端观点认为，人类可能撑不到下一轮机会窗口来临就会发生人口缩减导致的种群崩溃。万一爆发了第三次世界大战，那探索太空就更是痴人说梦了。因此在这波机会窗口过去之前，只有寥寥数次冲击极限的机会。其次，从地球到火星也有最佳发射时间，两星距离最近的机会每26个月才会出现一次。也就是说，只要SpaceX错过一次机会，就得把火星登陆计划再往后推迟两年多。</p><p></p><p>在本质上，SpaceX的目的不是为了赚钱，马斯克很清楚这一点。帕金森定律认为，工作量会随着时间推移而必要扩展。所以期限越是延后，工作范围就越大。缩短最后期限，人们反而会优先解决核心问题、把事情办成。人类抵达火星需要几年时间，对于一般的组织，整个项目大概要耗费几十年时间。但SpaceX的行动要快得多，因为使命已经成为缩短实施周期的动力（参见第四条）。</p><p></p><p></p><blockquote>“面对最后期限，我们别无选择，只能努力完成。因为我们知道其他人正指望着这一点，我们不想成为拖慢整个任务进度的罪人。”——某前SpaceX员工</blockquote><p></p><p></p><p>最后，使命是均衡调和的要素。一旦发生争议，公司内部不会看谁的民意支持更有力，而更多是在做逻辑论证。哪种方案更有助于完成任务、能够带来更高的效率，就会成为团队的共识性选择。换句话说，这在SpaceX内部形成了以结果为导向、而非以人为导向的争端解决习惯。</p><p></p><h3>7. 质疑一切</h3><p></p><p>设计流程的起点，就是前文提到的“让需求不那么愚蠢”和“清除部分或流程”。但是，这到底要怎么实现？</p><p></p><p>马斯克给出的答案非常直接：坚持第一性原理，摒弃简单粗暴的类比思维。第一性原则思维侧重于最基础的命题或假设；而类比思维则是用现有例子推测可能的情况。</p><p></p><p></p><blockquote>我认为第一性原理比类比思维重要得多。没错，我们在生活中经常会举一反三，好像之前已经做成的事情就肯定能用来指导其他还没做的事情一样，仅仅是主题上稍稍有所区别。类比思维的难度确实比第一性原则低得多，但后者才是看待世界的客观方法，也就是把事情归结于其遵循的基本原理，然后考虑哪些可信、哪些可疑。这确实更耗心神，但也更加安全有效。——马斯克和凯文·罗斯</blockquote><p></p><p></p><p>类比思维并不是坏事，它能帮助人们根据已经见过的事物来推理相对陌生的状况。但这里头有可能蕴藏着风险，让我们无意中就用到了也许并不正确的假设。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9c/9c89f7f35bf7cc9a94077cd0ad696cad.png\" /></p><p></p><p>还是说回玻璃纤维板的例子，这东西的存在单纯是因为每个人都觉得它该存在。一位前SpaceX员工还分享过经典的肉饼故事：按照一份世代相传的食谱，一家人在烹饪肉饼前会先把它的末端给切掉。有人问他们为什么，他们四处打听，最终发现只是因为当初曾祖母的烤箱太小了、放不下整个饼。现在完全没这个问题，可他们还是在照做！</p><p></p><p>但基于第一性原理的思维非常困难。我们可以参考一下Peter Thiel的表述：</p><p></p><p></p><blockquote>这种从1推导到n的经验复制思维更容易理解，因为我们已经看到了成功的“1”。但还有另一种更困难的思维，就是如何从0到1。这种创造性探索较难理解，因为要做的是他人从未做过的事。</blockquote><p></p><p></p><p>SpaceX正在尝试前人从未成就过的伟业。他们需要从零开始，而能够作为指导的就只有第一性原理。因此在SpaceX，员工们必须质疑一切，这主要体现在两个关键层面：</p><p>测试、测试、再测试做有罪推定</p><p></p><p>首先，对一切加以测试。如果我们相信某件事，那有没有数据能够证明？如果不能，为什么会这样？在考虑最佳答案前，只要不受物理定律的制约，就一定先进行测试。别谈什么假设，用真实测试结果说话。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6b/6bcc3d4657d97e6274a9b5131dd8113e.png\" /></p><p></p><p>第二点则是“默认做有罪推定”。听到别人说了个观点……先质疑它！这种习惯在大多数企业都会被归类成“刺头”，但在SpaceX，整个公司都强调这种文化，包括马斯克自己。</p><p></p><p></p><blockquote>&nbsp;“如果你说还得四个月才能完成，马斯克就会让你一一列出这期间要实现的几十项子任务。不是因为他不信任你，而是因为他想知道你有没有认真考虑过自己给出的截止时间，想知道这里还有没有优化的余地。”——某前SpaceX员工</blockquote><p></p><p></p><p>SpaceX的团队内部和各团队之间都是这样的关系。员工乐于接受质疑，因此会准备得更加充分，甚至提供相应的书面记录材料。另外，员工很享受这种质疑他人的权利，这让他们可以充分理解决策、再进一步传播和解释。这是一种健康的摩擦，提高了整个企业的效能水平。</p><p></p><p>当然，质疑绝不会是单向的。大家在质疑他人之前，先要做好被他人质疑的准备。所以在真正“开火”之前，最好先认真阅读对方提供的文档和推理流程，整理出具体的争论点。如果不做好预习，对方就得先解释半天才能进入正式讨论，这只会拖慢组织的前进速度。做好功课，就是尊重对方。</p><p></p><p>而这也成为对人才的又一道筛选屏障。只有那些能够适应这种文化、并具备思维能力的人们，才能在SpaceX长期工作下去，最终形成集群效应。</p><p></p><h3>8. 扁平化的职级结构</h3><p></p><p>在这种文化的带动下，SpaceX的员工们并不怎么关心职级和头衔。相反，他们更在意使命和产出。在早期，SpaceX并没有采取传统的官僚体系，而是保持着扁平的职级结构，大体分为以下四层：</p><p>L1：工程师/个人贡献者L2：团队负责人/经理L3：副总裁/部门负责人L4：马斯克</p><p></p><p>在数百员工中，个人贡献者跟马斯克之间的职级差只有一、两层，这在其他类似规模的公司绝对是难以想象的。一位SpaceX员工提到，在离职时本想找个类似的职位，却发现在其他企业担任的职务比SpaceX这边高了4级。以“软件工程师”或“首席工程师”为例，SpaceX这边从纯新手到拥有10经验的开发者都可能分布在这些岗位上。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/93/93b53dc3de1d9616c23ba1fd2e7e6787.png\" /></p><p></p><p>这一点非常重要，因为：</p><p>组织一致性更强避免职级膨胀鼓励公平竞争</p><p></p><p>扁平化的组织结构其实跟强调使命感密不可分，而且同样说起来容易做起来难。在很多由创始人领导的企业中，规模的迅速扩大引发了严重的官僚主义，导致普通员工很难感受到企业所秉持的使命。但SpaceX不是这样，无论工龄如何、经验怎样，大家都只比马斯克本人低一到两个职级。</p><p></p><p>另外，这也消除了职级膨胀之下的过度自负。别忘了，头衔只是虚名，只会让人分心。当然，有人很享受自己职级比别人高的感觉，那很抱歉，SpaceX不适合你。</p><p></p><p>这最终引出了第三点，鼓励公平竞争。如果有人对任务做出了贡献，那么无论其经验如何，成绩都会被看到。曾经有位二十多岁的年轻员工穿州过省，抢在最后一刻对发射台上的火箭进行了优化。这样的热情和透明度，正是SpaceX旺盛生命力的最好体现。</p><p></p><h3>9. 人才密度</h3><p></p><p>如果说世界上真有10倍工程师，那他们的诉求只有一个——创造。美国国防部之所以遭遇人才流失，最大的问题就在于此：他们的行动速度太慢，优秀的人待在那里只会百无聊赖。</p><p></p><p>相反，哪里能让我们承担最雄心勃勃的使命、享受最具挑战的工作环境、获得最透明的个人表现与贡献空间，我们就会义无反顾地奔向哪里，对吧？</p><p></p><p>SpaceX就是这样一家企业，所以这里云集着众多10倍工程师。而且加入进来之后，你会发现每位同事都是那么聪明、迅捷而且积极。</p><p></p><p>这样的氛围促使每个人都竭尽全力。他们知道自己的分析必须严谨，否则就会受到他人质疑。他们知道需要快速行动，否则就会成为阻碍他人推进工作的绊脚石。如同冠军级别的团队，大家既竞争又相互补充的技能组合最终提高了每位队友的自身水平。</p><p></p><h3>10. 永不止步</h3><p></p><p>航天级别的硬件设计，在资源密集度和挑战难度方面一直远超软件设计。毕竟软件开发往往有着：</p><p>更快、更清晰的反馈循环更短的部署时间更低的变更门槛</p><p></p><p>这些都是非常直观的因素。网站或者应用程序的更新往往只需要几分钟或者几个小时，就能完成相应的代码编写、测试和覆盖操作。但如果想开发一台电视，产品的更新就意味着调整生产线、供应链，这样成本更高、时间周期也更漫长。</p><p></p><p>正因如此，硬件设计往往需要经历体量可观的前期流程。设计出的电视至少要能在市场上坚持个一到两年，之后再推出下一款机型。</p><p></p><p>如果把这种复杂度再提升1000倍，那就差不多是火箭研究的级别了。但马斯克坚持把自己的软件开发背景引入SpaceX，在这里不存在“足够好”的成果，只有永不止步的追求。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2e/2e19ec2e6663f79c384bce7ce6a463a0.png\" /></p><p></p><p>比如说，最初的任务是造一台最高时速能到100公里的汽车。几个月后，这台车已经完成，传统企业就会觉得大功告成、可以休息了。但SpaceX不同，他们会立刻思考如果想让它的时速上到200公里，需要做哪些改动。或者说，能不能把它100公里巡航时的能源效率提高个0.1%？又或者，能不能更安全或者质量更可靠呢？</p><p></p><p>这些目标在硬件中是很难实现的，所以大多数企业对此毫无兴趣。可SpaceX的文化就是永止步，欢迎一切对火箭做出改进的新设计。成果会接受复杂软件的测试和分析，在证实有效后即被纳入迭代调整。SpaceX的火箭甚至会在发射台上接受改装。正是这些细小的变化综合起来，才让SpaceX在硬件的设计和构建方面比所有竞争对手都快得多。</p><p></p><h2>请您自行权衡</h2><p></p><p></p><p>这就是SpaceX的传奇经历——令人惊叹，但同时也会快速耗尽员工的精力。文章中出现的之所以多是“前员工”，就是因为他们感到筋疲力尽。</p><p></p><p>使命、影响力、高度强调输出的工作环境，虽然能帮助人们发挥出最大潜能，但同时也挤占了生活的空间。对很多人来说，这不是一条可持续的发展道路。但SpaceX似乎是在刻意为之，即宁愿让员工的任职时间较短，也要敦促他们发挥出10倍效能。</p><p></p><p>当然，这肯定不适合所有人。当下，马斯克入主Twitter又激发了类似的大讨论。他似乎想把同样的高产出、顶级效能文化也带进Twitter，但这样无疑会挤走那些想在Twitter享受工作生活均衡体验的员工。不知道如今的SpaceX会不会成为马斯克构想中的“Twitter 2.0”，结果如何让我们拭目以待。</p><p></p><p>参考链接：</p><p>https://jeffburke.substack.com/p/the-spacex-effect-the-culture-behind</p><p>https://www.youtube.com/watch?v=t705r8ICkRw</p><p></p><p>&nbsp;</p>",
    "publish_time": "2022-12-08 16:41:14",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "不影响开发体验，如何将单体Node.js变成Monorepo",
    "url": "https://www.infoq.cn/article/7M0cRaLzGYjUSivqu8Lv",
    "summary": "<p>将单体拆分成服务会带来维护多个存储库（每个服务一个存储库）的复杂性，每个存储库都有独立（但相互依赖）的构建流程和版本控制历史。Monorepo 已经成为一种降低复杂性的流行解决方案。</p><p></p><p>尽管 Monorepo 工具开发商有时会提供建议，但在现有代码库中配置 Monorepo 并不容易，尤其是单体代码库。更重要的是，迁移到 Monorepo 可能会给代码库开发团队带来巨大影响。例如，需要将大多数文件移动到子目录中，这会与团队当前正在进行的其他更改产生冲突。</p><p></p><p>本文将探讨如何平滑地将单体 Node.js 代码库变成 Monorepo，并将可能带来的影响和风险降到最低。</p><p></p><p></p><h2>简介：单体代码库</h2><p></p><p></p><p>假如存储库包含两个 Node.js API 服务器：api-server 和 back-for-front-server。它们是用 TypeScript 编写的，并转译为 JavaScript 在生产环境中运行。这两个服务器共用一套开发工具（用于检查、测试、构建和部署服务器）和 npm 依赖。它们还共用 Dockerfile 打成一个包，运行哪个 API 服务器要通过指定不同的入口点来选择。</p><p></p><p>迁移之前的文件结构：</p><p><code lang=\"text\">├─ .github\n│  └─ workflows\n│     └─ ci.yml\n├─ .yarn\n│  └─ ...\n├─ node_modules\n│  └─ ...\n├─ scripts\n│  ├─ e2e-tests\n│  │  └─ e2e-test-setup.sh\n│  └─ ...\n├─ src\n│  ├─ api-server\n│  │  └─ ...\n│  ├─ back-for-front-server\n│  │  └─ ...\n│  └─ common-utils\n│     └─ ...\n├─ .dockerignore\n├─ .eslintrc.js\n├─ .prettierrc.js\n├─ .yarnrc.yml\n├─ docker-compose.yml\n├─ Dockerfile\n├─ package.json\n├─ README.md\n├─ tsconfig.json\n└─ yarn.lock</code></p><p></p><p>迁移之前的 Dockerfile（经过简化）：</p><p><code lang=\"text\">FROM node:16.16-alpine\nWORKDIR /backend\nCOPY . .\nCOPY .yarnrc.yml .\nCOPY .yarn/releases/ .yarn/releases/\nRUN yarn install\nRUN yarn build\nRUN chown node /backend\nUSER node\nCMD exec node dist/api-server/start.js</code></p><p></p><p>在共享存储库中维护多个服务器有以下好处。</p><p></p><p>开发工具（TypeScript、ESLint、Prettier……）的配置和部署过程是共享的，这减少了维护工作，而且可以保证所有贡献团队的做法一致。方便开发人员跨服务器重用模块，例如日志模块、数据库客户端、外部 API 封装器等。版本控制简单，因为所有服务器共用版本，任何服务器的任何更新都会产生新版本的 Docker 镜像，其中包含所有服务器。也很容易编写覆盖多个服务器的端到端测试，并将它们包含在存储库中，因为所有东西都在一个地方。遗憾的是，这些服务器的源代码是单体的。我的意思是，各服务器的代码是分不开的。为其中一个服务器编写的代码（例如 SQL 适配器）最终也会被其他服务器导入。因此，要防止服务器 A 的代码更改也影响到服务器 B，这非常复杂，可能会导致意想不到的回归。而且，随着时间的推移，代码的耦合度会变得越来越高，代码会越来越脆弱，越来越难维护。</p><p></p><p>“Monorepo 结构”是一个有趣的折衷方案：在共享存储库的同时将代码库分割成包。这种划分使得接口更加清晰，因此，可以有意识的选择包之间的依赖关系。它还实现了一些工作流优化，例如，只在更改过的包上构建和运行测试。</p><p></p><p>如果代码库很大，集成了很多工具（例如代码分析、转译、打包、自动化测试、持续集成、基于 Docker 的部署……），那么将单体代码库迁移到 Monorepo 很快就会变得困难和反复。此外，由于存储库做了结构更改，所以在迁移期间，操作任何 Git 分支都会导致冲突。让我们看下将代码库转换为 Monorepo 的必要步骤，最大限度减少迁移问题。</p><p></p><p></p><h2>所需的更改</h2><p></p><p></p><p>将代码库迁移到 Monorepo 需要遵循以下步骤。</p><p></p><p>文件结构：一开始，创建包含所有源代码的惟一包，这样，所有文件都将被移动。Node.js 模块解析的配置：使用 Yarn 工作空间来实现包之间的相互导入。Node.js 项目和依赖的配置：package.json （包括 npm/yarn 脚本）将被拆分：主脚本在根目录，然后每个包里有一个。开发工具的配置：tsconfig.json、.eslintrc.js、 .prettierrc.js 和jest.config.js 也将拆分成两部分：一个“基础”部分，然后每个包里有一个对它的扩展。持续集成工作流的配置：.github/workflows/ci.yml 需要做多处调整，例如，确保其中的步骤会针对每个包运行，多个包的指标（如测试覆盖率）会合并成一个。构建和部署流程的配置：优化 Dockerfile，使其只包含要构建的服务器所需的文件和依赖。跨包脚本的配置：使用 Turborepo 编排影响多个包的 npm 脚本的执行（如构建、测试、分析）。迁移之后的文件结构：</p><p><code lang=\"text\">├─ .github\n│  └─ workflows\n│     └─ ci.yml\n├─ .yarn\n│  └─ ...\n├─ node_modules\n│  └─ ...\n├─ packages\n│  └─ common-utils\n│     └─ src\n│        └─ ...\n├─ servers\n│  └─ monolith\n│     ├─ src\n│     │  ├─ api-server\n│     │  │  └─ ...\n│     │  └─ back-for-front-server\n│     │     └─ ...\n│     ├─ scripts\n│     │  ├─ e2e-tests\n│     │  │  └─ e2e-test-setup.sh\n│     │  └─ ...\n│     ├─ .eslintrc.js\n│     ├─ .prettierrc.js\n│     ├─ package.json\n│     └─ tsconfig.json\n├─ .dockerignore\n├─ .yarnrc.yml\n├─ docker-compose.yml\n├─ Dockerfile\n├─ package.json\n├─ README.md\n├─ turbo.json\n└─ yarn.lock</code></p><p></p><p>由于 Node.js 及其工具生态系统非常灵活，所以共享一个通用的方法会很复杂，因此请记住，为了让开发人员的体验至少与迁移前一样好，将需要进行大量的优化迭代。</p><p></p><p></p><h2>如何将影响降至最低</h2><p></p><p></p><p>所幸，虽然迭代优化可能需要几周的时间，但影响最大的是第一步：更改文件结构。</p><p></p><p>如果你的团队借助 Git 分支并行开发，那么这一步骤将导致这些分支发生冲突，在合并到存储库的主分支时解决冲突就会非常麻烦。</p><p></p><p>因此，我们有三方面的建议，特别是当需要就迁移到 Monorepo 说服整个团队时。</p><p></p><p>提前计划（短时间的）代码冻结：为了避免迁移时发生冲突，定义一个日期和时间，到时所有分支都必须合并。提前计划，以便开发人员可以做出适当的调整。但在可行的迁移计划确认前，不要选定日期。将迁移计划中最关键的部分编写 bash 脚本，这样就可以确保开发工具在迁移前后都能工作，包括在持续集成管道上。这样应该可以打消怀疑者的疑虑，在代码冻结的实际日期和时间上获得更大的灵活性。在团队的帮助下，列出他们日常工作所需的所有工具、命令和工作流（包括 IDE 的特性，如代码导航、代码分析和自动补全）。这个需求列表（或验收标准）将帮助我们检查将开发体验迁移到 Monorepo 设置的步骤。这有助于确保在迁移时不会忘掉重要事项。以下是我们决定满足的需求列表：yarn install 仍然安装依赖；所有自动化测试仍能运行并通过；yarn lint 仍然能够发现代码风格违规的情况（如果有的话）；eslint 错误（如果有的话）仍然会在 IDE 中报告；prettier 仍然会在 IDE 保存文件对其进行格式化；IDE 仍然会发现错误的导入和 / 或违反tsconfig.json 文件中定义的 TypeScript 规则的情况（如果有的话）；在使用外部包暴露的符号时，如果它被声明为依赖，那么 IDE 仍然能够提出导入正确模块的建议；生成的 Docker 镜像在部署后仍然能够启动且和预期一样正常运行；生成的 Docker 镜像大小仍然（大致）一样；整个 CI 工作流都可以通过，而且不会消耗更多的时间；集成的第三方代码分析器（SonarCloud）仍然能够和预期一样工作。下面是迁移脚本示例：</p><p><code lang=\"lua\"># 这个脚本使用 Yarn 工作空间和 Turborepo 将存储库转换为 Monorepo\n\nset -e -o pipefail # stop in case of error, including for piped commands\n\nNEW_MONOLITH_DIR=\"servers/monolith\" # 第一个工作空间的路径：\"monolith\"\n\n# 清理临时目录，即没有存储在 Git 中的那些\nrm -rf ${NEW_MONOLITH_DIR} dist\n\n# 创建目标目录\nmkdir -p ${NEW_MONOLITH_DIR}\n\n# 将文件和目录从 root 移动到 ${NEW_MONOLITH_DIR}目录\n# ……除了那些绑定到 Yarn 和 Docker 的（目前）\nmv -f \\\n    .eslintrc.js \\\n    .prettierrc.js\\\n    README.md \\\n    package.json \\\n    src \\\n    scripts \\\n    tsconfig.json \\\n    ${NEW_MONOLITH_DIR}\n\n# 将新文件复制到 root 目录\ncp -a migration-files/. . # 包括 turbo.json, package.json, Dockerfile,\n                          # 和 servers/monolith/tsconfig.json\n\n# 更新路径\nsed -i.bak 's,docker\\-compose\\.yml,\\.\\./\\.\\./docker\\-compose\\.yml,g' \\\n  ${NEW_MONOLITH_DIR}/scripts/e2e-tests/e2e-test-setup.sh\nfind . -name \"*.bak\" -type f -delete # delete .bak files created by sed\n\nunset CI # to let yarn modify the yarn.lock file, when script is run on CI\nyarn add --dev turbo  # 安装 Turborepo\nrm -rf migration-files/\necho \"✅ You can now delete this script\"</code></p><p></p><p>我们在持续集成工作流中添加了一个作业（GitHub Actions），用于检查测试和其他常规 Yarn 脚本在迁移之后是否仍然可以正常工作：</p><p></p><p><code lang=\"lua\">jobs:\n  monorepo-migration:\n    timeout-minutes: 15\n    name: Test Monorepo migration\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - run: ./migrate-to-monorepo.sh\n        env:\n          YARN_ENABLE_IMMUTABLE_INSTALLS: \"false\" # 允许 yarn.lock 变化\n      - run: yarn lint\n      - run: yarn test:unit\n      - run: docker build --tag \"backend\"\n      - run: yarn test:e2e\n</code></p><p></p><p></p><h2>从单体的源代码转换生成第一个包</h2><p></p><p></p><p>看看迁移之前我们唯一的package.json 文件是什么样子：</p><p></p><p><code lang=\"lua\">{\n  \"name\": \"backend\",\n  \"version\": \"0.0.0\",\n  \"private\": true,\n  \"scripts\": {\n    /* 所有 npm/yarn 脚本... */\n  },\n  \"dependencies\": {\n    /* 所有运行时依赖 ... */\n  },\n  \"devDependencies\": {\n    /* 所有开发依赖 ... */\n  }\n}</code></p><p></p><p>以下片段摘自迁移之前 TypeScript 配置文件tsconfig.json ：</p><p></p><p><code lang=\"typescript\">{\n    \"compilerOptions\": {\n        \"target\": \"es2020\",\n        \"module\": \"commonjs\",\n        \"lib\": [\"es2020\"],\n        \"moduleResolution\": \"node\",\n        \"esModuleInterop\": true,\n        /* ... 多条让 TypeScript 更严谨的规则 */\n    },\n    \"include\": [\"src/**/*.ts\"],\n    \"exclude\": [\"node_modules\", \"dist\", \"migration-files\"]</code></p><p></p><p>在将单体拆分成包时，我们必须：</p><p></p><p>告诉包管理器（这里是 Yarn）代码库包含多个包；更明确地指出可以在哪里找到这些包。为了使包可以作为其他包的依赖项导入（也就是workspaces），我们建议使用 Yarn 3 或其他支持工作空间的包管理器。</p><p></p><p>所以我们在package.json中添加了\"packageManager\": \"yarn@3.2.0\" ，并在其旁边创建了一个.yarnrc.yml 文件：</p><p></p><p><code lang=\"text\">nodeLinker: node-modules\nyarnPath: .yarn/releases/yarn-3.2.0.cjs</code></p><p></p><p>根据 Yarn 迁移路径 的建议：</p><p></p><p>提交.yarn/releases/yarn-3.2.0.cjs 文件；我们还是坚持使用node_modules目录，至少目前如此。在将单体代码库（包括package.json 和tsconfig.json）移动到 servers/monolith/之后，在项目的根目录下新建一个package.json 文件，其中 workspaces 属性列出了工作空间的位置：</p><p></p><p><code lang=\"typescript\">{\n  \"name\": \"@myorg/backend\",\n  \"version\": \"0.0.0\",\n  \"private\": true,\n  \"packageManager\": \"yarn@3.2.0\",\n  \"workspaces\": [\n    \"servers/*\"\n  ]\n}\n</code></p><p></p><p>从现在开始，每个工作空间必须有自己的package.json 文件，用于指定其包名和依赖。截至目前，我们只有一个工作空间“monolith”。在servers/monolith/package.json文件中使用组织名作为其名称的前缀，明确标明它现在是一个 Yarn 工作空间：</p><p></p><p><code lang=\"typescript\">{\n  \"name\": \"@myorg/monolith\",\n  /* ... */\n}</code></p><p></p><p>在运行完yarn install 之后，我们又修复了一些路径：</p><p></p><p>yarn build 及其他 npm 脚本（从 servers/monolith/运行时）应用仍然有效；Dockerfile 应该仍然可以生成一个有效的构建；所有的 CI 检查应该仍然可以通过。</p><p></p><h2>提取第一个包：common-utils</h2><p></p><p></p><p>到目前为止，我们的 Monorepo 只定义了一个“monolith”工作空间。它在servers目录下，这表明它无意让其他工作空间导入其模块。</p><p></p><p>让我们定义一个可以被这些服务器导入的包。为了更好地传达这种差异，我们在servers目录旁增加了一个packages目录。要提取一个包的话，目录common-utils（来自servers/monolith/common-utils）是首选，因为“monolith”工作空间的多个服务器都使用了它的模块。当每个服务器都在自己的工作空间中定义时，common-utils包将被声明为两个服务器的依赖项。</p><p></p><p>现在，我们将common-utils 目录从servers/monolith/ 移动到新建的目录packages/ 。</p><p></p><p>为了将其转换成一个包，创建packages/common-utils/package.json 文件，其中包含所需的依赖和构建脚本：</p><p></p><p><code lang=\"typescript\">{\n  \"name\": \"@myorg/common-utils\",\n  \"version\": \"0.0.0\",\n  \"private\": true,\n  \"scripts\": {\n    \"build\": \"swc src --out-dir dist --config module.type=commonjs --config env.targets.node=16\",\n    /* 其他脚本 ... */\n  },\n  \"dependencies\": {\n    /* common-utils 的依赖 ... */\n  },\n}</code></p><p></p><p>注意：我们使用swc 将 TypeScript 转译为 JavaScript，但使用tsc 应该也可以获得类似的效果。此外，我们尽力让它的配置（使用命令行参数）与servers/monolith/package.json 中的配置一致。确保包会按预期构建：</p><p></p><p><code lang=\"text\">$ cd packages/common-utils/\n$ yarn\n$ yarn build\n$ ls dist/ # 应该包含 src/ 中所有文件的.js 构建</code></p><p></p><p>接下来，更新根package.json 文件，将packages/ 的所有子目录（包括common-utils）也声明为工作空间：</p><p></p><p><code lang=\"typescript\">{\n  \"name\": \"@myorg/backend\",\n  \"version\": \"0.0.0\",\n  \"private\": true,\n  \"packageManager\": \"yarn@3.2.0\",\n  \"workspaces\": [\n    \"packages/*\",\n    \"servers/*\"\n  ],\n  /* ... */\n}</code></p><p></p><p>将common-utils 添加为服务器包monolith 的依赖：$ yarn workspace @myorg/monolith add @myorg/common-utils 。</p><p></p><p>你可能已经注意到，Yarn 创建了一个到packages/common-utils/ （源代码就在这里）的符号链接node_modules/@myorg/common-utils 。</p><p></p><p>完成此操作后，我们必须修复所有有问题的common-utils 导入。实现这一目标的一种低成本方法是在servers/monolith/中重新引入common-utils目录，并使用一个从新生成的包@myorg/common-utils导出函数的文件：</p><p></p><p>export { hasOwnProperty } from \"@myorg/common-utils/src/index\"</p><p></p><p>更新服务器的Dockerfile ，以便构建包并包含在镜像中：</p><p></p><p><code lang=\"lua\"># 使用以下命令从项目根目录构建：\n# $ docker build -t backend -f servers/monolith/Dockerfile .\n\nFROM node:16.16-alpine\n\nWORKDIR /backend\nCOPY . .\nCOPY .yarnrc.yml .\nCOPY .yarn/releases/ .yarn/releases/\nRUN yarn install\n\nWORKDIR /backend/packages/common-utils\nRUN yarn build\n\nWORKDIR /backend/servers/monolith\nRUN yarn build\n\nWORKDIR /backend\nRUN chown node /backend\nUSER node\nCMD exec node servers/monolith/dist/api-server/start.js</code></p><p></p><p>这个Dockerfile 必须从根目录构建，那样它才能访问yarn 环境和那里的文件。注意：可以通过在Dockerfile 中将yarn install 替换为yarn workspaces focus --production来从 Docker 镜像中除去开发依赖，这要感谢 plugin-workspace-tools 插件，参考“使用 Yarn 3 和 Turborepo 编排和 Docker 化 Monorepo”一文中的介绍。</p><p></p><p>至此，我们已经成功地从单体中提取出了一个可导入的包，但是：</p><p></p><p>生产构建因为Cannot find module 错误运行失败；common-utils 的导入路径过于冗长。</p><p></p><h2>修复开发和生产环境的模块解析</h2><p></p><p></p><p>我们从@myorg/types-helpers导入函数的方法是有问题的，因为 Node.js 从子目录src/中查找模块，即使它们被转译到子目录dist/中。</p><p></p><p>我们宁愿采用一种子目录无关的方式导入函数：</p><p></p><p>import { hasOwnProperty } from \"@myorg/common-utils\"</p><p></p><p>即使我们在包的package.json 文件里指定\"main\": \"src/index.ts\" ，在运行转译构建时路径仍然会被破坏。</p><p></p><p>作为补救使用 Node 的 条件导入，以使包的入口点可以适配运行时上下文：</p><p></p><p><code lang=\"typescript\"> {\n    \"name\": \"@myorg/common-utils\",\n    \"main\": \"src/index.ts\",\n+   \"exports\": {\n+     \".\": {\n+       \"transpiled\": \"./dist/index.js\",\n+       \"default\": \"./src/index.ts\"\n+     }\n+   },\n    /* ... */\n  }</code></p><p></p><p>简而言之，增加一个exports配置项，关联包根目录的两个入口点：</p><p></p><p>default条件指定 ./src/index.ts 为包的入口点；transpiled条件指定./dist/index.js 为包的入口点。根据 Node 的文档，default 条件应该始终放在最后。transpiled条件是自定义的，所以你可以随意指定其名称。</p><p></p><p>为了让这个包在转译后的运行时上下文中运行，需要修改相应的 node 命令，指定自定义条件。例如，在Dockerfile中：</p><p></p><p><code lang=\"typescript\">- CMD exec node servers/monolith/dist/api-server/start.js\n+ CMD exec node --conditions=transpiled servers/monolith/dist/api-server/start.js</code></p><p></p><p></p><h2>确保开发工作流和以前一样</h2><p></p><p></p><p>现在，我们有了一个 Monorepo。它包含两个工作空间，每一个都可以从另一个导入模块、构建并运行。</p><p></p><p>但是，每增加一个工作空间，就需要更新Dockerfile ，因为必须针对每个工作空间手动运行yarn build 命令。</p><p></p><p>此时，像 Turborepo 这样的 Monorepo 编排器就派上用场了：我们可以让它根据声明好的依赖关系递归地构建包。</p><p></p><p>在将 Turborepo 作为 Monorepo 的开发依赖项添加以后（命令：$ yarn add turbo --dev ），可以在turbo.json中定义一个构建管道：</p><p></p><p><code lang=\"typescript\">{\n    \"pipeline\": {\n        \"build\": {\n            \"dependsOn\": [\"^build\"]\n        }\n    }\n}</code></p><p></p><p>这个管道定义的意思是，对于任何包，$ yarn turbo build 会从它依赖的包开始构建，以此类推。这样就可以简化Dockerfile：</p><p></p><p><code lang=\"text\"># 使用以下命令从项目根目录构建：\n# $ docker build -t backend -f servers/monolith/Dockerfile .\n\nFROM node:16.16-alpine\nWORKDIR /backend\nCOPY . .\nCOPY .yarnrc.yml .\nCOPY .yarn/releases/ .yarn/releases/\nRUN yarn install\nRUN yarn turbo build # builds packages recursively\nRUN chown node /backend\nUSER node\nCMD exec node --conditions=transpiled servers/monolith/dist/api-server/start.js</code></p><p></p><p>注意：可以利用 Docker 多阶段构建和turbo prune 来优化构建时间和镜像大小，但在本文写作时，生成的yarn.lock 文件与 Yarn 3 还不兼容。（关于这个问题，可以查看 这个 pull 请求 了解最新进展。）借助 Turborepo，在定义好管道后（和构建时类似），只需一条命令（yarn turbo test:unit ）就可以运行所有包的单元测试。</p><p></p><p>也就是说，大多数开发工作流的依赖项和所依赖的配置文件都移到了servers/monolith/目录下，因此，它们大部分都无法正常工作了。</p><p></p><p>我们可以把这些依赖项和文件留在根目录一级，那样所有包都可以共用。或者在每个包中复制一份。当然，还有更好的方法。</p><p></p><p></p><h2>将通用配置提取到包中并扩展它</h2><p></p><p></p><p>现在，最关键的构建和开发工作流已经可以正常工作了，接下来，要让测试执行器、代码分析器和格式化器在针对不同的包执行时行为一致，同时还要留出定制空间。</p><p></p><p>一种方法是创建保存基础配置的包，然后让其他包扩展它。</p><p></p><p>就像我们对common-tools所做的那样，创建以下包：</p><p></p><p><code lang=\"text\">├─ packages\n│  ├─ config-eslint\n│  │  ├─ .eslintrc.js\n│  │  └─ package.json\n│  ├─ config-jest\n│  │  ├─ jest.config.js\n│  │  └─ package.json\n│  ├─ config-prettier\n│  │  ├─ .prettierrc.js\n│  │  └─ package.json\n│  └─ config-typescript\n│     ├─ package.json\n│     └─ tsconfig.json\n├─ ...</code></p><p></p><p>然后，把它们作为依赖项添加到每个包含源代码的包中，并创建配置文件扩展它们：</p><p></p><p><code lang=\"typescript\">packages/*/.eslintrc.js:\n\nmodule.exports = {\n    extends: [\"@myorg/config-eslint/.eslintrc\"],\n    /* ... */\n}\n\npackages/*/jest.config.js:\n\nmodule.exports = {\n    ...require(\"@myorg/config-jest/jest.config\"),\n    /* ... */\n}\n\npackages/*/.prettierrc.js:\n\nmodule.exports = {\n    ...require(\"@myorg/config-prettier/.prettierrc.js\"),\n    /* ... */\n}\n\npackages/*/tsconfig.json:\n\n{\n    \"extends\": \"@myorg/config-typescript/tsconfig.json\",\n    \"compilerOptions\": {\n        \"baseUrl\": \".\",\n        \"outDir\": \"dist\",\n        \"rootDir\": \".\"\n    },\n    \"include\": [\"src/**/*.ts\"],\n    /* ... */\n}</code></p><p></p><p>可以使用像 plop 这样的样板文件生成器来简化使用这些配置文件设置新包的过程，加快设置速度。</p><p></p><p></p><h2>下一步：每个服务器一个包</h2><p></p><p></p><p>我们已经逐项核对了“如何将影响降至最低”一节所列出的所有需求，现在可以冻结代码贡献、运行迁移脚本、并将更改提交到源代码存储库了。</p><p></p><p>从现在起，该存储库可以正式称为“Monorepo”了！所有开发人员都应该能够创建自己的包，并在单体中导入它们，而不是直接向其中新增代码。基础已经打好，可以开始将单体拆分成多个包了，就像我们对common-tools 所做的那样。</p><p></p><p>我们不打算讨论实现这一目标的详细步骤，但这里有一些关于如何做好拆分准备的建议：</p><p></p><p>从提取小的实用程序包开始，例如类型库、日志记录、错误报告、API 封装器等；然后，提取计划跨所有服务器共享的代码的其他部分；最后，复制不计划共享但不只一个服务器依赖的部分。这些建议的目标是逐步解耦各服务器。以此为基础将每个服务器提取成一个包应该和提取common-utils 一样简单。</p><p></p><p>此外，在这个过程中，你应该可以利用以下几项特性优化构建、开发和部署工作流的持续时间：</p><p></p><p>Docker 多阶段构建（参见 Dockerfile 文件编制最佳实践） ；重用主机的 Yarn 缓存（参见 Docker Build Mounts）；Turborepo 的 远程缓存。</p><p></p><h2>小结</h2><p></p><p></p><p>我们已经把一个单体 Node.js 后端变成了 Monorepo，同时将对团队的影响和风险降到最低：</p><p></p><p>将单体拆分为多个相互依赖的、解耦的包；跨包共享通用 TypeScript、ESLint、Prettier 和 Jest 配置；安装 Turborepo 优化开发和构建工作流。使用迁移脚本让我们可以在准备和测试迁移时避免代码冻结和 Git 冲突，确保构建和开发工具不会因为迁移脚本添加 CI 作业而遭到破坏。</p><p></p><p>感谢 Renaud Chaput （Notos 联合创始人、CTO）、Vivien Nolot（Choose 软件工程师）和 Alexis Le Texier （Choose 软件工程师）在这次迁移中的通力合作。</p><p></p><h5>原文链接：<a href=\"https://www.infoq.com/articles/nodejs-monorepo/\">https://www.infoq.com/articles/nodejs-monorepo/</a>\"</h5><p></p><p></p><h5>相关阅读：</h5><p></p><p><a href=\"https://xie.infoq.cn/article/3554ecc815a0c7d5e8f429c62\">Node.js 基于区块链的游戏应用的首选</a>\"</p><p><a href=\"https://xie.infoq.cn/article/8eb3e25e164a3077482b2c53f\">【异常】window 10 安装 node.js 时遇到 2502 2503 错误解决方法</a>\"</p><p><a href=\"https://xie.infoq.cn/article/27f21a5f5903c489e172b9430\">JXcore 打包在企业级项目里的合理运用和模块系统以及网络的配置详解【node.js】</a>\"</p>",
    "publish_time": "2022-12-08 16:56:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "百度App Feed 流业务架构变迁思考和升级实践",
    "url": "https://www.infoq.cn/article/coiYkGs5vIgrz1XRB8Yp",
    "summary": "<p>本文整理自百度技术专家、推荐产品研发部架构师李哲浩在 2022 年 8 月 ArchSummit 全球架构师峰会北京站的演讲分享，主题为“百度 App Feed 流业务架构变迁思考和升级实践”。</p><p></p><p>本次分享主要从五个部分展开：第一部分介绍我们过去架构的概况，第二部分介绍在经历一些环境的变化后，架构上有哪些改变，第三部分介绍我们团队对于架构设计的一些思想和原则，第四部分例举几个架构场景的实例，最后介绍架构维护控制相关的内容。</p><p></p><p></p><h2>过去的架构漫步</h2><p></p><p></p><p>我们过去一开始的架构是一个个小作坊，比方最开始的时候有一个频道页叫频道 A，然后假设我们突然想做一个进攻的项目，比如想去创建一个垂类频道 B，这时候我们就会把整套代码拷贝过去，因为我们过去采用的是 MVC 架构，如图所示，整个架构都拷贝了一份，架构只剩下了概念，没有实体架子支撑，由于这时往往都是一种“征战”的状态，时间比较紧迫，当时的用例也不多，迭代的深度也不够，觉得还好，可以实现快速开发，基本够用。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e3/e397b9fd1213ba43dcf180c139352ace.png\" /></p><p></p><p>后来我们出现了人手不够的情况，PM 对发版有了更高的要求，不再满足于随版，而希望去“非随”，或者说双端变成单端想加快迭代效率，这种背景下，我们很多频道已经开始采用类似 RN 的方案，或者基于 Hybrid 上 H5 的方案去创建。</p><p></p><p>再这之后，中台的概念在各大公司飞起，大家一块见证，我们也不例外，从公司层面做中台化的架构调整和延伸，我们的业务也搭建中台组件平台。由于之前并没有梳理和建设好合理的耦合边界，各种似同非同的架构，想要响应公司号召，短期的输出方式，我们基本上只能选择整体输出（文档也没法看），也就是说，某个 APP 要创新孵化的时候，我们会把整套组件打包成一个大的组件（或者说 SDK）提供给用户，他们也想快速上线也很急，那就让他们基于原码去定制改造并使用，就是真实的共建仍未产生。</p><p></p><p>我们在实践后期发现，当在频道 A 里做了一些实验，证明了某个行为有正向的收益后，频道 B 也想用怎么办？如果从频道 A 里把这个能力复制到频道 B，当这种操作多了以后，就会出现很多捉襟见肘的情况，系统会变得比较脆弱，当代码一直在拷贝复用时，很快会变得臃肿，但一直都没有去做大的重构或者架构升级，所以遗留代码、技术债也就堆积如山。以上是过去架构的状况。但不是说拷贝复用一定是坏的，咱后面再述。</p><p></p><p></p><h2>大环境的冲击</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/2a/2a61967334e96593ed1ebbfe3d14c2ee.png\" /></p><p></p><p>后面大环境发生了变化，首先肯定是公司内部的组织变化带来的老问题加剧，新问题产生，然后是业界技术和架构上的成果对我们视野上的变化。后来我就潜心研究了一下行业内先进的架构模式，看是否能帮我们解决存在的问题。不过这部分我们放在第三部分重点详述。还是先介绍下现在内部组织结构的情况。下图是 19 年架构升级时的组织结构。仅作为示意。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/6b/6b312a47783a2a1c0049d6594b008263.png\" /></p><p></p><p>我们是中间部分的 Feed 团队，中间部分并立的还有一个搜索团队。</p><p></p><p>上游有两个团队依赖于我们这两个团队，比如说商业团队和其它产品线的一些团队会依赖到我们的 Feed，比如，我们上游的产品线期望能有快速孵化 app 工厂的能力，同时又对包体积比较敏感，希望 Feed 这边可以能找到组件动态裁减和拼装，在这种情况下，我们需要把粒度做的更细。商业这边是独立的团队，他们有他们的关注点和任务，Feed 迭代又快，不清楚 Feed 内部代码的很多细节，直接改容易出问题，但又有很大的概率要织入到 Feed 代码来实现一些效果，所以非常痛苦。这就要求 Feed 这边将各种时机做成稳定的回调接口，或者挖个空让他们填下。</p><p></p><p>另一方面，可能每个公司都会搞一些类似 RN 的定制方案，我们的叫 Talos，现在已经完全跟原来的 RN 完全不一样了，但一开始起步就是这样开始的，像美团有一个 MRN，阿里有 Cube，大家都做差不多类似的定制研究，并作出一定的创新。再比如我们也研究 Hybrid，他们可能也在研究 Hybrid，我们有一个 OEM Mapping 的方案叫 Crius，他们可能也有一个类似的方案，我们也会调研现在比较前沿的 Flutter、KMM、Jetpack Compose 这些东西，去关注并持续落地到某个场景中去。所以慢慢地，我们就有了自己的组件化、动态化、插件化这些一整套框架，这些大部分是我们依赖的下游的基础平台提供的，比如说他们现在就在做 DevOps 大平台，当然也有业务团队下沉的基础设施。</p><p></p><p>那作为业务团队，我们没有必要重复造轮子，只需要运用这些基础设施的能力来助力业务的快速发展。</p><p></p><p>另一个问题，我们现在整个 Feed 团队有几十上百号人，怎么合理分工，另外测试人员越来越少，整个研发流程主要依赖手工测试，这样每次发版迭代的时候就会突显出一些问题，比如会阻塞整体的开发效率，但是有的人却仍处在空闲。不仅如此，团队间的责任边界意识会越来越清晰，经常扯皮决定哪方去改，但是代码上的边界可不一定是这样清晰，经常你中有我，我中有你。</p><p></p><p>所以，我们想来一次业务架构的升级换代。去拥抱新的变化。</p><p></p><p></p><h2>采用的架构思想和原则</h2><p></p><p></p><h3>架构影响因素</h3><p></p><p></p><p>我们在架构升级的时候，考虑了哪些因素呢。首先围绕业务价值是必须的。否则所有的工作都失去了开展的必要。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/2e/2e21feafd25bba12f4836c9b6f901fc8.png\" /></p><p></p><p>组织架构：组织结构决定了整个边界，比如说我们一开始有 Feed 团队和视频团队，原来是一个团队，但后来被分开了，分开以后就会有一些边界划分，或者说两个库之间会脱的越来越开，这个时候应该做出合理的共建和隔离权衡。</p><p></p><p>开发方式：比如我们是不是在做敏捷开发模式，一个真正敏捷的团队，它的日常重构是比较容易实现的，比如可能他们不仅有完备的测试覆盖，团队成员每个人也有非常好的代码洁癖和设计追求。但有的敏捷可能是伪敏捷，比如是领导人说了算的一个敏捷，比如他完全无视利特尔法则，不去关心在制品的消化，或者人月神话，而是以人力是否空闲，甚至以团队成员的工作时长作为指标，那架构优化将变得没有意义。所以开发模式和开发流程量化到什么程度，是以可定义级别还是以可量化级别的流程为标准，都是会影响到整个架构的设计导向的。团队的成熟度：成熟的团队更加能接受解耦，模块化的价值，很多不成熟的团队倾向于在一个文件中维护一整个业务模块。这个后面再展开。环境行业特征：我们整个 Feed 流是以广告展现的收入为导向，我们会更关注如 DAU、 时长等指标，为了指标的增长，某些方面会变得越来越复杂，比如实验越来越多，再比如我们的内容是不会重复展现的，但另一方面可能会变得很轻量级。不同 APP 和行业可能很不一样，比如说如果主营外卖业务，能想象商品列表不会重复展现吗？而且他们更注重从下单到用户收货的整个流程，但我们更注重列表的刷新策略，推荐策略。技术约束：这个在另一个领域叫人的视野受限于生产力水平，比如 ArkUI 之类的成为主力，和没有产生这样的技术，对展示层的开发模式会有很大的不同，这也是影响架构的因素。干系人的构成：有些事情驱动力来源于团队成员，比如他们表示某某某非常难用，再比如，PM 和领导会上重要的干系人，我们要让 PM 认同你的架构，让你的领导认同你的架构，但很可能他们不同等技术，那我们需要积攒一些原始的数据，用可以量化的指标来做事。把量化纳入到架构设计的开始处，以终为始。</p><p></p><p></p><h3>投入成本比</h3><p></p><p></p><p>说到量化，我们展开聊聊投入成本比，比如我们的节奏大概是这样的，一个需求发布了，我是做这个需求的人，今天周一，我评估大概 4.5 天差不多能完成，但是我会给自己留一些 Buffer，所以名义上可能将此任务估成六天工作量，但是可能下周二就需要上线，这样 QA 说他们需要一天的人力测试，这种情况下，我只有本周 5 天的时间可以安排了，倒排以后我只能按 5 天来排期，言外之意我预计要自己加班一天，实际开发的时候我发现 4 天就搞定了，搞定了以后我并没有闲着，因为这之间，虽然出了线上问题，我还在做上一个版本的 bugfix。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3f/3f70a5079a02c20762ceb19077237341.png\" /></p><p></p><p>这一周下来后，测试花了一天的时间，当然大量的时间可能是在借调人力，因为 QA 人力也不足，不过整体下来平台上统计的可能是名义粗估和排期，但真正的实际粗估以及实际真正所用天数可能是无法体现的，那么这到底怎么去衡量？如果无法衡量，那比如说我们的架构，或者说我们的某个设计得到了一些改进之后，它的效率有没有提高？维护性有没有变好？怎么确定？（当然事实上无法准确量化也是共识）</p><p></p><p>我们希望重塑原始数据的积累情况，比如说刚刚那个例子，假设说需要一个人投入一个 Q，但是如果领导和 PM 感知不到效率的提升，就不会投入资源，如果没有这些干系人的持续投资，很多上马的研发项目可能也会停摆，造成更大的岔口。而我们的平台统计恰恰显示没有提升。而有些事不做技术债会越来越多，直到系统性风险。</p><p></p><p>可是由于没有采用故事点或者理想人天等形式，而是直接采用了排期这种手段，总不应该去怪团队成员怎么不把真实的估计填上去。那是因为他们也无法准确的估计工作量，而且也要适应请假、应对突发情况，无尽的会议。如果没有 buffer，这个压力强度就太高了。</p><p></p><p>或者让团队成员去列下粗估的构成，让其他人都看看是否合理，但是考核什么就会得到什么，这种检验不信任已经造成了不信任，不仅无法揪出不合理，而且会造成士气低下。</p><p></p><p>也可能以概率替代全局，比如某个任务原来需要 20 天，我们做了某种改进，然后再执行相似任务只花了 4 天。然后把这个收益摆上去要投资。完全不谈命中，这让人信服吗？任何的改进都有概率会命中失败，比如某个端能力缺失，开发这个端能力需要 8 天，那优化收益就变成 12 天。仅把最佳情况列上去是有问题的。更何况，有的情况是，我们做了改进，一年都用不上。</p><p></p><p>在第五部分维护控制阶段，我再谈谈我们有限解法。</p><p></p><p></p><h3>团队成熟度</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/4e/4ece5cf1de0dba297c01820b668a5ea2.png\" /></p><p></p><p>在团队成熟度方面，以我这几年在多个团队的经历和变迁。我发现，一开始新业务会处在原型阶段，可能会有很多需求迭代，这时通过继承也好，或者拷贝也好，怎么快怎么做。</p><p></p><p>在后面的阶段，业务会发生扩张，遍地都是“黄金”，大家就开始做一些通用化的建设，但这个时候在一个比较大的范围内，还是没有人管的，还没有非常好的治理手段，导致大家会有重复造轮子的现象，或者说核心的部分，大家都不想让别的团队来掺和，于是处于一种野蛮的生长状态，大家都会去争抢业务边界。</p><p></p><p>再后面大家可能会意识到内耗，去搞这么多框架这么多组件来占用人力维护是一笔不小的成本，而且从上而下，可能架构师会去做一些合并去重的事情，这时候的节奏就是争抢标准，争抢输出，比如说我输出多少个组件，你输出了多少到哪，这样我的组件或者框架可能变得安全一些（不会被合并），这时候大家的想法是你造一个汽车，我就造一个航母，我这个能力更强，各方面会更好。此时此刻，对 ROI 尚且宽容。</p><p></p><p>到最后就会进入到一个萎缩阶段，因为我们可能从一个业务线，或者说一个进攻的重点，迁移到另外一个重点，原来那个重点上只会处在维护的阶段，这时候各方面都已经成熟落地了，再做一点点改进的时候都要考虑 ROI，当真的有较好收益时才会被允许去做一些重构或者升级。</p><p></p><h3>业务复杂度</h3><p></p><p></p><p>我们团队也经历了从 MVC 这种小作坊的模式到后面能驾驭更大复杂度设计的转变。我们一直在说复杂度，什么是业务复杂度？</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/72/72788b31cccd4c97aa5970fce8c28f79.png\" /></p><p></p><p>比如说我们在做一个转换器的插件，将 RGBA 的颜色数组转换成 YV12 格式，可能技术很复杂，可能会用汇编，可能会用 C++，可能会用 Erlang 运作多处理器，或者是通过 OpenCL 充分利用 GPU 的能力，但它的业务复杂性却很低，因为我们很明确知道它就是要做这个单一的事情。可以类比问题域的复杂度很低，但解决方案空间的复杂度很高（为了追求某种质量属性，这里是性能）。</p><p></p><p>再比如我们在有些情况下做一个简单的弹窗，这种弹窗只是调用系统 API 就可以了，技术复杂度很低，工作也就是拼接一个字符串，也非常简单，但由于要考虑上百种不同的情况，或者不同情况组合之间有一些互斥，在有些协调和相互作用的情况下，文案都不一样，这种情况下业务复杂度会变得很高。也就是说我们分支很多，熵会很大。</p><p></p><p>很多业务在经过深入迭代以后，要实现一点微小的数据的提升都要做很多实验，很多微小路径的改变都会导致整个业务复杂度增加，它的分支会越来越多，这难以避免。我们称这为“业务雪球”。</p><p></p><p>再比如，文件写入也可能有很多异常要处理，但文件处理本身是你要专注的业务吗？如果我们本身是写一个文件处理软件，那可能就是，如果对于这个产品来说，你告诉我是否成功就可以了，至于有多少种错误码我不关心，我只 try catch 一下就可以了，也就是说，它是不是你的核心业务是一方面。</p><p></p><h3>团队成熟度和业务复杂度</h3><p></p><p></p><p>说到团队成熟度和业务复杂度，如果我们用平面切割思维，它可以组合成很多方式：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/54/5459ac1fffb7aa418aa380da341d7e37.png\" /></p><p></p><p>比如说是简单的业务，或者说复杂的业务。当然这里的边界不做量化的定义。度量衡交给您。就我们基础体验小组，大家都能认可刷新业务是复杂的，首先出现问题影响极大，所以开发者强度高，压力大，而且没有单测覆盖，也不会轻易去做改动，业务逻辑分支，几屏幕的思维导图放不下。没有人能不看源码枚举出所有 case。</p><p></p><p>横轴是我列的三种人设，管理学上有经济人、社会人、复杂人假设。你可能会想，这人怎么这样，带有色眼镜看别人，是不是心理太阴暗？这倒不是说对某个具体的人做出假设或影射。而是想简化架构服务人群，进而挑选更合适的质量属性和选型决策。而且一个人在不同的阶段，面对不同的项目，可能表现为某种人设成分多一些，即一个真实的人是复杂的，可能同时映射到多种假设。事实上两边的人设都是理想态极值。你可以类比星座。我们稍微展开下。</p><p></p><p>第一种是自由人，有一些人不太服从团队的指挥，他们非常愿意去钻研，或者说实践一些新的东西，也可能就是单纯喜欢自由的空气，他们普遍非常聪明，但他们普遍也看不上工程化的价值，觉得是束缚，对于大部分的设计，他们认为是华而不实，花里胡哨，也可能不会让别人污染侵犯自己的代码“领地”。在我工作的这十多年，不同范围内的不同团队里，总能看到这一类人，这种情况下，如果是简单业务就放任他，能有个人做就不错了，而且你要相信，这类中的大部分的人 bug 率一直都是很低的。如果是复杂业务，这种人多了很容易失败，我们很多局部的架构已经因为这种情况而失败过了。表现为离开他，很难有人接起来，除非重写。</p><p></p><p>第二种是工具人，工具人基本上就是处于服从的状态，你让我怎么搞就怎么搞，我们有一套规则，我就按照这个规则来做就好了，我不管它复杂还是不复杂，繁琐不繁琐，这种情况下，如果是简单业务，我们给他打造一块样板间就可以。如果是比较复杂的业务，最好是前期时做一些稍微的、适当的过度设计，但这个度还是要把握好，不是做太大的过度设计，不然维护成本会激增，但肯定要稍微过度设计一下，因为他只会拷贝你的代码或思路来叠加他们的逻辑。</p><p></p><p>上百号人的团队，有时候很多东西真的是管不过来的，哪怕培养了一批中间力量来承上启下。有很多的 CR 情况没办法感知到，当真正感知到的时候已经晚了。比如说我们原来的 Feed 流它有一些卡片，这些卡片有一百多张，当时解析数据的 Model 用的是安卓的一个框架，发现这个框架可能有一些问题，即便是有一些问题，但没有人去关心，很多人就开始迭代这些代码，到最后出现问题，你会发现根本就改不过来了，现在的话，由于 ROI 不高也不会去改它，但是每个新人入职看到这个都会嗤之以鼻一下。</p><p></p><p>最后一种是敏捷人，这是一个比较理想的状态，敏捷人和自由人有什么相同点？我觉得他们的特点都是不去遵守规则，而是坚持他们认为正确的原则和设计理念。比如我们原来的规矩是每个人 cr 数都要达到多少多少。你知道的，古德哈特定律，考核什么就会得到什么。对于这两种人，他们都会反对盲目的 cr 数考核，但是自由人的原则往往 cr 没有用，阻碍他们写代码。而敏捷人更能认识到“有 cr 比没有 cr 好，没有 cr 比有 cr 好”的这种观点，进而聚焦到“提升质量”这件事本身。这意味着敏捷人不止于打破规则，而且要进行推广并影响更多的人，使新的实践成为新的规则。而自由人让你看到的是多套不同的凌乱的东西。</p><p></p><p>我们针对简单业务做简单设计，简单设计是 Kent Beck 提出来的，就要遵守四个原则，即通过测试、消除重复，最小元素表达和更少代码元素，这样就会得到一个相对可以的设计，因为我们大多数人不是设计大师，不是搞设计艺术的人，能得到一个平庸的，大家都认可的，可以量化的设计即可。</p><p></p><p>如果是复杂业务，我们更多的还是看看能不能建立领域模型，Martin Fowler 的企业应用架构模式里提到了像事务脚本、领域模型、表驱动等概念，因为我们某些领域比较复杂，在这种情况下需要知道如何梳理我们的领域，领域模型可能是一个前进的方向，它会对整个业务的梳理起到一些作用。</p><p></p><h3>什么应该是模型</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/50/500b2ca8bb5eed5a3a20a159a4f61922.png\" /></p><p></p><p>那什么是领域模型？什么是业务模型？业务模型一般认为是状态（包括场景或环境、数据表示）、策略（包括错误处理）和操作的应激集合。</p><p></p><p>我先说下模型，对于一个简单的 MVC 架构，那 M 就是一个模型，我工作的这十多年里，我发现大多数人会把 Server 下发的数据完全当成成一个模型。</p><p></p><p>我举个例子，比如说 is_vip 这个字段，is_vip 下发了 1，就会有对应的一个字段是 is_vip 为 1 这样的字段，但这种在我们看来只是一个 DTO，即一个数据传输对象。</p><p></p><p>还有另外一种是把数据库里面的字段作为一个真正的模型的一部分，比如说安卓经常推广一些框架，比如 Room 框架，你如果用 Room 框架会发现，框架会让类里面每一列是一个字段，在这样的情况下，很多时候列名和业务模型就不一致性了，比方说我们现在这个 case 里边只存了两列，第二列是一个 Json，我们要在这个字段里面定义一个 String 这样一个字段吗？可能不是。也有可能会把这个展现模型作为一个模型，如果是 VIP，就要标个红色，如果不是就标黑色，红和黑可能会是一种展现特有的特点，把这个也会作为一个模型，但这些可能都不是业务模型。</p><p></p><p>我们希望的业务模型是能够和 PM 沟通的时候，能够作为一个概念去说的，比如我们希望如果是 VIP 就要做解锁，做刷新，这种情况下，这几个东西 PM 能听的懂，业务逻辑里也能够写明，我们把这个规则表达好，具体这个规则是怎么实现的，就不是那么重要了。我们只需要知道要存一个数据，具体是怎么存的，不是业务需要关注的东西，“我们要去存它”这件事本身以及“什么时机”可能更重要。</p><p></p><p>我们设想一个简单业务，随着它变得复杂，关于模型边界这块的问题，我们在做什么：</p><p></p><p>首先，我们在协调存储模型和业务模型不一致的矛盾。比如当对一个列表进行增删改成时，不太容易直观将这些反映到存储设施上，除非全删全存。再比如当对性能有较高要求时，数据库的列和模型的字段往往对应不上，因为可能需要预读。</p><p></p><p>其次，我们在协调下发模型和业务模型不一致的矛盾。比如 server 下发了三批数据，但是 server 可能是无状态的，不太容易知道给某个设备下发了这三批数据，并根据展现上报情况做展现去重，即便知道可能也有延迟，但是端有此上下文。再比如业务模型需要一个布尔概念，但是 server 下发了数值或字符串概念。</p><p></p><p>再次，我们在协调展现模型和业务模型不一致的矛盾。比如业务模型可能表现为多个布尔求值，但是展现可能归结合并为某个控件的显隐或者字体粗细。</p><p></p><p>比如可复用视图的控件（RecyclerView）可能要求滑动窗口模型（去适配它的 Adapter）。再比如展现模型是按照窗口页面的粒度组织，但是业务模型可能要求连贯的跨越这种粒度。</p><p></p><p>然后呢，我们也可能会去协调对内业务模型和对外业务模型不一致的矛盾。</p><p></p><p>比如对外提供了一套 API 和能力集，需求变化导致内部已经使用了新方案，但仍需要兼容使旧方案工作。比如非完整复用带来一定的扩展定制诉求，要求在你的业务模型上做一些埋点和钩子供外部定制，以匹配外部方的业务模型，而这些埋点和钩子不存在于你的真实业务流程。</p><p></p><p>我们也可能会去协调不同业务模型间需要转换翻译的矛盾。比如 SDK 基于自己的模型提供了几个必要通知，但是你的模型对此无明显感知，需要做同样的处理。</p><p></p><p>再比如不同的领域团队间的代码基可能是松散耦合的、并行开发的，关注点也不同，使用的数据结构也可能不同。</p><p></p><p>最后，我们极可能也在协调技术模型和业务模型的矛盾。这体现在协调性能要求对业务模型泄露的影响。比如业务模型设计为以页面为上下文，即页面创建时生成数据，销毁时丢弃数据。但性能原因可能在冷起阶段进行提前处理、预处理部分逻辑，这要求页面创建前生成数据。这也体现在人的理解和计算机的矛盾。比如你的意图是交换两个值，但是你需要定义第三个变量来存储临时值。</p><p></p><p>Martin Fowler 将业务模型设计拆解为概念模型、契约模型、实现模型。你的意图，即交换两个值，这是概念模型，是领域语言，可以与其他角色共享；然后你设计了一个表明意图接口层 API 叫作交换，这是契约模型了，因为此时可以与模型的其他组成部分产生关联，与多个模型产生协调，这里已经很好的隐藏了技术信息；最后我们通过临时变量存储的方案完成了交换功能，这属于实现模型。</p><p></p><p>在这类问题上，我们倾向于在模型驱动开发。假设我们做一个弹窗，可能有很多不同的规则，可能有的是几天弹一次，有的是每次冷起弹一次，对于很多端上同学，将采用 UI 驱动开发的方式，这势必在 UI 里或者从 UI 导到控制器里边去做 if-else 判断。但是如果说模型驱动，那么首先它会去写个类来描述这个规则，弹窗可以简单的用 show 接口方法代替，弹什么此时不重要，把这个 UI 细节往后推，推到最后才去考虑这个事情。如果是这样驱动，那么 TDD 测试驱动开发是可能的，容易的。让一个程序员把所有的逻辑跑通再事后去写单测是乏味的，因为他知道结果是啥，所以写单测也是草草找个场景敷衍。</p><p></p><p>另一个是这个东西其实依赖于程序员的开发习惯，他们需要简单的业务去产生慢慢改变自己，如果总是去支援一个特别着急的需求，它可能迫于时间压力倾向于采用他所熟悉的开发方式，那其实根本就不可能达到这种效果。</p><p></p><h3>KMM 的启示</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/47/47e2344be0cede543686e905e6d1ab8e.png\" /></p><p></p><p>我们再看下 KMM，KMM 是 Kotlin 推出的一个跨平台的东西，它最推荐你共享的是业务逻辑，像平台访问、前端交互它都希望你遵守原来平台的规范，或者说 UI 展示之类相关的不推荐共享，如果我们的业务逻辑是最大的，我们的 UI 是薄的，或者说我们客户端访问数据存储是薄的，它可以比较快速地实现复用，我们得出了业务逻辑不要去依赖基础设施的结论。</p><p></p><p>和上面我们要打磨业务模型的结论也是一致的。</p><p></p><p></p><h3>前端状态管理方案的启示</h3><p></p><p></p><p>然后把视角拉向前端状态管理方案，我们研究了大部分的前端框架，一个很有意思的地方吸引力我们，就是除 Vue 等几个 MVVM 模式的框架外，出现了一些单向数据流的设计理念，Redux 就是这样一个例子，它可能是因为要配合 React 使用，而 React 是一个 UI 框架，这个 UI 框架是以不可变为导向的，前端 JS 借鉴了很多函数式编程的优点，可能更推荐不可变，当然可能是为了整体 UI 更新的时候更可靠的做一个 Diff 算法，才设计的不可变。</p><p></p><p>总之前端会在倾向于声明式 UI 的情况下，更多地去选择不可变的思路来做 Diff 刷新，这时候我们可能会有一些状态管理的方案出现，除了 Redux，比如说像 Flutter 有 BLoC 这个东西，像 Vue 有 VueX，都有一些类似的状态管理方案。</p><p></p><p>我们从这里大概了解到 UI 是被动的渲染，它不能更改状态，它只是传递了要做什么的意图，剩下的事情都不在 UI 层里操作。很显然，UI 变成了谦卑对象，这非常有助于写单测。从第四部分可以知道，我们的架构从 Redux 中汲取了一些经验。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f0/f0ee9547095b9c90a2e6feaa9b96ee73.png\" /></p><p></p><p></p><h3>后端前沿架构的启示</h3><p></p><p></p><p>后端的架构情况方面，可以发现无论是 6 角形架构，还是 Clean 架构，或者是领域驱动设计的其他相关模式，都是以领域为核心，领域层里有一些比如实体类、值对象等，根据建模方式的不同而不同，比如可能用的是四色原型，或者说可能用的是 DCI，也或者其它简单的一些像 ECB 这种架构模式来建设、划分领域层的一些对象，但一定是以领域为核心的，领域里的类不会再去依赖外边的类，外边的类可以去依赖领域内的类，但可能并不会实线依赖。可以发现图中这个是六角形加上 DDD 的架构，从这里边可以看到有一个端口和适配的概念，领域层有一个端口，可以认为是一个接口，我们有进行适配，这里适配的就是真正的技术实现相关的东西，然后去实现领域里边的接口，使得依赖方向反转，这样的好处是我们整个领域模型边界清晰，完整干净，第二个就是我们整个领域模型是完全可测的。基础设施变更了，对我们来说也可以非常好的平滑过度。这些都在我们的架构中有所体现。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/9d/9dea66905169ab65f003d7f0e96c0b15.png\" /></p><p></p><p></p><h3>快速开发的思考</h3><p></p><p></p><p>我们再从快速开发的角度看一个问题，比如我们现在有几十上百号人，如果我们的 Feed 里有好几个团队，不是每个团队在当前都有任务要做的，这时候我们就希望能够把这些人都用起来，支援其它团队的开发，这时候就会涉及到快速支援的问题，比如说我们当时分析了一下这个模型，新入职的同学以及外部的同学跟 Feed 内部的同学到底有什么差异，对于特别核心的业务，有很大历史包袱的业务，真的只有 Feed 内部的人才能去做，但是其它支援的同学可以做一些更普适的工作，如果这些工作做得好，也能非常好的发挥相应的价值，最后的结论就是希望能让中间这部分可独立扩展，可动态裁减，让独立的模块变大变多、标准化，这样能让边界清晰，开发起来也比较方便，不需要太深入业务认知。这也要求我们打造一个微小的内核，大的可扩展边界，将更多的时机以标准化的接口方式暴露出去。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/dd/dd6a072ae58dbb01bd6d63daebec11dc.png\" /></p><p></p><p></p><h3>组件化</h3><p></p><p></p><p>从公司和整个 APP 层面我们也在做组件化的工作，聚焦在物理组件化层面。但是这里对于组件的边界，抽象程度，依赖形式，我们走过比较多的路。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/0f/0fd18f36a5a174fd40324d8ca4d520be.png\" /></p><p></p><p>比如说我们有一个壳工程，存在一些业务组件和基础组件，我们最开始的时候对业务组件的认知是，假如有 A 组件和 B 组件，如果二者之间不想交互，我们就再搞一个 C 组件，让 A 和 B 都去依赖这个 C，就是所谓的“下沉”。</p><p></p><p>后来我们采用的是另外一种方式，把每个组件分成了两部分，一部分是有一个接口层的模块，另部分有一个实现层的模块，接口层之间可以互相依赖，实现层之间不再互相依赖，是通过其他的接口层 IoC 方式进行间接依赖。这样可以去解决一些类似循环依赖的问题。</p><p></p><p>这里拓展一下，比如组件 A 如果想扩展，比如第三方的一个业务想插进一个时机做点事情，我们需要给它增强一个能力，一个配置口子。会有这么几种情况，</p><p></p><p>第一种是直接作为组件的一部分去用，比如在组件 A 里还有扩展层，因为扩展出的能力也是通用的。第二个是我们把扩展层独立地打包和发布，扩展是独立的，这样能保持组件的动态组合性，但给别人输出的时候也可能会被遗漏。第三个是我们过去都在用安卓 XML 写布局文件，这种情况下我们需要布局文件里有一个 View 的实体（真身），XML 布局是天然反接口设计的，它是面向实现的。为了能使用这个实现，必须要依赖实现层的模块。</p><p></p><p>并且过去的时候，安卓推荐 public 字段，不要使用枚举等一系列为性能反设计的内容，，直到现在官方也不太推荐抽象化的技术，但这就导致我们很多数据类都已经做成公开的了，这些繁多的退化类暴露着数据字段，没办法通过接口化的方式包装后透出去，所以不得不又把整个把实现模块暴露出去。</p><p></p><p>现在我们希望改变这些做法，它们不利于组件化也不利于大型组织，所以我们选择用声明式的 UI ，去 XML 化，并且去减少贫血模型，用接口化的方式去做一些改进。</p><p></p><p>下图中，左边这个图是整个 APP 当时做组件化的时候划分的架构层次，这个层次的划分依据是按照变化的维度去划分，比如越是与业务相关，那就越容易变化，所以组装层 /App 工厂在最上层，业务在上层，越往下越通用，越是业务无关。比如说网络库，可能没有必要依赖任何东西，它就是一个很底层的模块。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/12/12b779046f0d1d0c6202fe18be955fba.png\" /></p><p></p><p>当我们按照前面说的后端六边形架构，DDD 架构，上下之间不能是直接依赖的关系，而是一个反向依赖的关系，比如说网络库可能不需要依赖业务，但业务也不应该直接依赖网络库，中间我们有适配层模块，我们依赖这个适配层的 Port，即接口层，适配的接口实现包装了网络库，从而实现依赖反转，这种做法和思路至少覆盖主要的，核心的，复杂的，需要测试保证的模块。</p><p></p><p>组件我们可以根据集成方式进行划分，最常见的组件形式是提供某种服务，你需要调用它来获得这种能力，比如工具类的组件，图片库之类的。但也有很多组件是已约束的方式做了某些事，并在很多时机给你留了很多模板方法或者配置参数，希望你通过泛化的方式来扩展和使用，比如框架类组件、提供最小集的中台类组件经常提供基类。最后像 UI 组件和数据类的这种裸奔的组件，很可能需要去包含它，比如你的业务 View 类里包含好些个 TextView，比如我们的卡片里包含一个关注按钮。</p><p></p><p>然后我们再加上业务相关性这个维度。可以发现，最右侧的业务组件，几乎不被复用。另一个是注意服务化程度代表接口层提取的容易程度，越偏向使用 / 调用关系的，越容易提取，侵入性也越小。这有助于我们甄别所依赖的组件中某种集成方式的占比是否健康。</p><p></p><p>提到健康，也需要知道怎样判断组件能力是否完善？对此我们列有一个组件能力模型。组件既有物理组件也有逻辑组件，当然这个约束的主要是逻辑组件。</p><p></p><p>第一层级，逻辑组件明确对外依赖以及自己提供的服务；第二层级，不仅仅停留在明确，逻辑组件以最小的依赖代价提供相应合理的服务；第三层级，则是在第二级的基础上，承诺自己的依赖和服务不会轻易发生变更，并在升级后仍较长时间向下兼容这些明确部分。我们可以看下有多少组件到达了哪个层级，还有组件管理上，身份、生命周期、通信机制是否健全、灵活。这些都可以采用评分的方式，最终纳入健康度雷达和组件评优平台。</p><p></p><h3>边界问题</h3><p></p><p></p><p>组件这块，有个共建边界问题，我想分享一个 case，这个 case 也是我们之前遇到过的场景，App 都有 Push 的能力，比方说手机百度 App 里有内容推送过来，点击这个推送以后，它直接会进到视频落地页中，不会进入到首页当中，为了快速启动跳过了首页逻辑，这种情况下，我们进入到第二个视频落地页，我们有个需求是当返回的时候要创建这个首页，同时要把刚才访问的视频落地页的相关条目插入到首页里面去，比方说插到第三楼去。我们的想法是它的数据结构和列表的数据结构不一样，我们需要单独通过 Server 的其他接口把落地页内容条目的 ID 传上去，拿回匹配首页列表 UI 能解析的这套数据下来，因为数据的使用者是首页，落地页去请求不合理，而如果返回的时候再请求已经晚了，因为返回的时候就需要使用数据了，还不知道这个东西是什么，如果再单独去请求肯定会延迟，延迟会导致一开始插不上这个第三楼，所以我们必须得在每进入一个落地页就去做请求并缓存到首页列表能 cover 的范围内。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5d/5dcfb4c098a43b8cef6897dd33c31ea2.png\" /></p><p></p><p>这个需求涉及到首页模块，也涉及到视频落地页模块，首页会说我提供了一个通用的能力告诉你怎么插入，只要按照规则去插就好。视频落地会说每进到一个视频落地页我会按我的通用格式周知，前提是你得先注册。这个注册的时机在首页不好找，需要在 application 启动时做。这时基础平台会说在 application 加一个只有两个业务方需要的“定制连接”，会影响 TTI，不会同意。而因为一些打点的问题，需要区分条目来源于推送还是原始数据请求。</p><p></p><p>这时候你会发现这个工作没人愿意去做，第一个原则肯定是好的，每个组件都是独立的，都会提供一些通用的能力，互不依赖，所以应用第二个原则，谁受益谁去做这个事，谁的 PM 去提的需求，谁来做这个脏活，做这个适配。首页的 PM 提的，首页的人单独搞一个模块去解析视频落地页的通知格式，然后拼装去请求 server。即我们建立了一个胶水组件来做这些不太通用的事情。</p><p></p><p>刚才这个例子里面也有另外一个问题，拿视频通知格式来说，比如这次是首页提的，那首页去做胶水，后面是电商提的，然后电商去做胶水，它们两个都会去解析同样的数据，做类似的事情，这是一种重复逻辑的扩散。所以视频落地页也做了个胶水层组件，把这部分有重复隐患的代码收敛起来，便利大家。</p><p></p><p>这样你会发现，最后的解决方案可能都是会偏向于我们既有组件，也会有一个类似胶水的组件互相穿插连接。</p><p></p><h3>多产品线方案选型</h3><p></p><p></p><p>还有多产品线的一些方案，比如我们采用的方案是分支的方案，当时的考虑是两个团队的发版节奏不一样，如果想搞通用的组件，去做真实的复用，当几个团队之一要做扩展的时候就需要原来做组件的维护者去做一个接口或建设一种能力，一起合作共建。但版本如果匹配不上，这种支援会经常得不到回应，导致这个需求产生 Delay，所以采用了这种分支方案，也就是对于矩阵内的产品、一个新孵化出的创新 App，可能会直接修改分支去做定制化。只要做好组件化，其实大部分组件都是无需修改就能复用的，只有一部分是有差异的，而有差异的部分我们也有自动化 merge 工具来降低工作量，所以这种方案是可以接受的，尤其在效率上，虽然有一定的概率导致组件的通用性不足。这有点像 DDD 里 Context Map 中的跟随者和独立自主的模式。</p><p></p><p>当然，插件的方式来实现组件设计的真实复用才是理想态，但现在看条条大路通罗马，遗留代码基太大，没必要换这种方案，收益不高。</p><p></p><p>最右边是构建方案（DDD 里 Context Map 中的共享内核的模式），这种可以基于 android productFlavor 实现，事实上 KMM、JNI 的外观上都很类似于这种映射方案。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/55/558a9cb2533e8e16dedbdaafbec72509.png\" /></p><p></p><p>最后的一个关注点，就是怎么升级。</p><p></p><p></p><h3>架构升级假设</h3><p></p><p></p><p>我们有一个假设，当时想做升级的时候，因为升级动作比较大，所以考虑什么样的升级方式能够更好的应对不一样的变化，当时的想法是我们整个业务中有不同的功能单元和能力单元，其复杂度是不一样的，后面的变化和迭代情况也不一样的，我们想实现一些细粒度的定制和升级动作，比如说修改其中的一个能力单元进行架构升级时，其它模块不会有太大的改动，这样比较平滑，最小化架构升级和业务迭代并行导致多套并存的混乱程度。另外一种思路是做一个大一统的标准化架构，并且推行这个架构。但这种架构对很多不常迭代的业务来说比较复杂，犹如大炮打蚊子。所以最后我们还是决定用细粒度的方式做升级，去做组件化和架构模式的应用。只要保留在想升级更重量级架构时能够升级这个可选项。这样下来，整个工程上，有不同量级的可升级的架构，很像一个梯田。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f1/f1466e3ca0c3f5321dd074a433b38a49.png\" /></p><p></p><p></p><h3>迁移和升级准备</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b0/b0ff841b1f1d3909d321f766ed354367.png\" /></p><p></p><p>我们之前做中台化的时候也做过一个升级的动作，但最后失败了，原因是我们有一个非常复杂的列表，其中有很多各种刷新，各种实践，各种分支逻辑，比如锚点逻辑，搜索和插入，等非常复杂的逻辑在里面，但我们当时做中台的时候希望中台是通用的，不需要那么复杂，所以当时就另起炉灶去搞一个干净无包袱的组件，设想了三层输出，就是最小可以有什么，通用级可以有什么，业务饱和级列表可以有什么，业务饱和就是带上 Server 的协议和策略。然后在应用这个中台组件时，比如说我们当时在做付费项目时，发现完全是另外一套策略，业务饱和级成了累赘，通用级为了通用，非常的薄，我们需要填补很大的空白逻辑。另外，由于它是独立出来开发的，很难再反哺到一开始所说的真正复杂的列表中去，导致升级中断。</p><p></p><p>这次升级，不仅注意到这些，而且我们针对架构升级影响到的那些团队做了很多培训和推广，来应对架构升级中的一些设计问题。</p><p></p><p>有一些人会觉得引进新的时髦的东西就是好的，比如 Android 规范推了这个，又推了那个，他会不亦乐乎的追随和集成。再比如这次 Android 的架构导向偏 MVVM，但是，他发现 Redux 不错，所以在 MVVM 里再攒一个类似 Redux 的设计模式。我们觉得这不太合理，而且大家对这些会有一些自己的理解，会产生歧义。再比如说 MVC 就非常普适，但我发现前端、Android、iOS，不同工龄背景的人，没有多少能达成一致的见解。</p><p></p><p>所以，这次，如刚刚介绍的思考和原则，又是前端，又是后端，虽然我们也是引入，但重新定义出了一套独有的概念，并予以规范化的解释，使之出处一致，避免扯皮这些。比如我们有个 Processor 的概念，有点像 Redux 的 Producer，但是不直接引用这个名字，因为有差异。</p><p></p><h2>若干场景的架构示例</h2><p></p><p></p><p>上一 part 我们集中描述了思考，具体落地只是顺理成章的事，现在举几个场景来做下示例。如下图，这里我采用了 C2 描述语言去描述，不采用 C4 或者 4+1。</p><p></p><p>我们的组件里 Processor 承担业务处理的逻辑单元，Ability 作为基础设施能力的抽象单元来参与 Processor 里的业务逻辑，比如说我们的 UI 控件，或者几个 UI 控件被包装成 Ability 使用。</p><p></p><p>再说说 Extension 概念，比如一个处理加载相关逻辑的 Processor，在加载失败时，可能不同频道有不同的微调处理，那么这个加载失败可以定义为扩展点，由不同的频道注入 Extension 来解决。是的，我们的 Processor 基本上所有的方法都是私有的，也就是虽然可以泛化，但是以 Extension 组合的方式来表达扩展。注意，这里的扩展点是面向实现的。也就是说强依赖刚刚说的 Processor。如果是面向接口协议的，一些通用的时机，我们的选择是发 Action，我们马上介绍。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/10/104114d6493e170e651f1e971d269c39.png\" /></p><p></p><p>上面说的组件，需要通过连接件组合组装起来，连接件也要作为容器处理组件间，父子容器间的交互诉求。比如我们的展示页面，用 Page 接口抽象，Page 组合管理很多 Ability 。ProcessContext 作为 Processor 的容器会去处理很多 Processor 间的交互逻辑，也会把父 ProcessContext 的 Action 转派给 Processor， 比如通过 Action 的方式去发消息给 Processor，Processor 也可以使用另一个 Processor 的能力，但需要以 Assistant 接口包装。一般来说，解决通信，提供消息机制、服务调用机制、共享内存机制三者中的一个就够了，所以最后一种我们没提供。</p><p></p><p>我们定义了很多约束原则，这些原则都是事先就规范化的。鉴于篇幅，不再叙述。</p><p></p><p>说到 Action，我们不得不再提下 Redux。只是这次以子系统视角。下图这是列表子系统，Feed 还有视频落地页子系统、图文落地页子系统等。每个子系统都是独立的，我们不希望这个系统被污染，我们是按照系统思考的方式去做，拿这个例子来说，我们的系统是 Action 应激，没有其他的方式使用这个系统。而且我们摆脱安卓原来的低级事件，比方说安卓点击这个东西，弹什么东西，我们把点击这种低级事件已经转化成了一种高级事件，虽然名字可能叫 Click 事件。这样我们可以基于 Action 的录制和回放来实现自动化测试。尤其在应对复杂的业务时，实现逻辑的自动化校验会很有帮助。Redux 有很多的优势，但我们最看重的是事件溯源，CQRS+ 单向数据流的好处。另外这些也有助于非脆弱性单测的编写。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d0/d030c5aa7b0487ce1ea7f1dd46062aab.png\" /></p><p></p><p>架构升级的过程中，我们把机制作为框架下沉，包括编排引擎、插件打包。见下图</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/1d/1de1c93f5efcb868816acfb219714c5d.png\" /></p><p></p><p>我们复杂的业务不是很多，但也有一些，比如刷新，图文落地页，对于这种复杂的业务，我们倾向于引入 DDD 战术来改造，比如把真正的实现从外部注入进来，注入进来以后我们会走到一个比较干净的应用层和领域层里边去，这个应用层的目的是去接收外部的 Action，比如搜索（和 Feed 平行，未使用这套架构组件）过来一个事件通知，会通过 event bus 发过来，在应用层会被转成 Action 再进来，我们会在概念上维护 PM 提需时的用例，这些用例会去配置策略参数，然后进一步传递领域层进行更改，比如说我们的显示列表层就是一个领域层聚合，它以数据的方式完全代表最终的显示状态。我们可能还有一些还原历史的诉求，历史是单独的一个概念，也是 PM 和各方面都能认可的通用领域语言概念，这是领域层的一些实例。数据处理这块我们采用 Repository，不是 Android 的 Repository，而是 DDD 里的概念，Repository 和 DAO 最大的不同技术，Repository 是以集合的方式而不是以数据库语言或者网络协议请求方式来维护聚合，Repository 的接口层在领域层，实现在基础设施层，基于前面说的端口和适配器的概念，实现依赖反转。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/0e/0e5b3db9966d78cfe2b5ce7980759443.png\" /></p><p></p><p></p><h4>展示层我们应用了三种模式：</h4><p></p><p></p><p>第一种模式是应用了逻辑图层概念，这不仅仅是 Z 轴，而且体现在两个无真实 UI 视图的层，比如手势层，谁在上谁先消费或过滤，这对于事件消费的管理有帮助，另外某些 UI 控件想同显同隐，可以放在一个层上来简化管理。第二种模式是将页面分区分成命名卡片槽位的方式，这种方式可以应对局部的组件化，比如说我们这个运营槽位可以作为独立的一个组件使用，供别的频道更细粒度的进行复用。第三种模式是 UI 技术实现，比如我们说列表过去依赖了 ListView，现在依赖 RecyclerView 这个特定控件，未来我们使用了 Jetpack Compose 来实现列表，他们局限于某种技术细节和开发方式，我们把这层实现和要提供的接口能力隔离开来，接口可以使用 Ability 架构组件，真正的实现在业务组装配置的工厂里注入进来。这里的 UI Ability 不同于把页面分区，也不同于一个 UI 控件包装成一个 Ability。比如都是用 RecyclerView 作为实现载体，但是我们的 Adapter Ability， Footer Ability 和 Update Ability 都需要它。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/75/752435b115b4198f21fb513036c5c612.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/55/5520df75cb0d85602d9a7845d6542776.png\" /></p><p></p><p>最后，这三种模式可以进行组合嵌套，你中有我，我中有你。比如我们先用逻辑图层，然后它的某一层，可能嵌套使用分区命名卡片槽位，槽位里边也可以嵌套配置图层，或者将某个槽位组件做成 Ability 或 Ability 的容器 Page。也可能是反过来，比如整个 Page 里很多的 Ability，其中的某个 Ability 的载体是列表控件，列表条目是卡片槽位，某个槽位进行了图层化处理。</p><p></p><p>当然这需要 Ability 设计时考虑它的复用方式，比如是否支持槽位，如果可以支持，就将槽位管理器引入进来，然后由工厂注入时配置开关。</p><p></p><p></p><h2>架构维护控制</h2><p></p><p></p><p>在架构维护控制方面，我当时看了《演进式架构》，很受启发，演进式架构的一个道理是想利用适用度函数尽可能管理和降低架构裂化程度，我们也定义了一揽子适用度函数。比方说像 McCable 圈复杂度，稳定性度量等。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/8c/8cf5578f4c3ebb28b1b9a2db11cdd2dc.png\" /></p><p></p><p>有一次我们去参加 ATAM 的培训，它是一种架构权衡的分析方法，类似以评审会的方式对质量属性进行评价，进而对架构进行评价。也讨论了哪种方式可以作为长期的适用度函数，但总体上这种方式开展的不频繁，和团队对冲突管理的好坏有关系。有一段时间，我们也研究了 Google 提供的 GSM 这种方式，了解到除了定量还可以通过观察开发者是不是产生了某种行为来衡量收益和结果。这种方式的实施仍和管理者理想中对于目标的掌控方式有很大关系。之前也提过，如果管理者的想法是让每个人都忙起来，工作饱和起来，被管理者可能对提效这件事不再敏感，因为无事可做，仍要假装很忙到 11-12 点，那还不如慢慢做。我听过一个故事，说老板希望员工很忙，后来他做到了，以至于有顾客进店都没人去理他，因为大家真的忙起来了。</p><p></p><p>除此之外，不同的团队，比如不同阶段，不同环境和文化，不同规模，不同业务形态，在架构的选型上，以上的架构实践方式是否适合，需要自己权衡。</p><p></p><p>可以做一个架构能力评估模型来评估下，自己当时的架构是什么水平的，可以做成什么水平，平台支撑是不是足够好。比方服务端能不能做微服务？并不是每一个团队都适合做微服务。比如我们当时非常关心的一点是，是不是有一个最佳的决策路径，我们的一线开发者遇到问题时，可以助力设计决策。其他部分详见下图。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/6e/6ec867a2e6725a69ed4f5c47b294ea66.png\" /></p><p></p><p>另外我们需要做好防劣化，这块有几点印象比较深刻，比如说像 Emacs 编辑器可以煮咖啡吗？也许能，也许不能，我对此的感受是，程序员希望做一件事时，没有其他的干扰，比如编码时，他不希望又从浏览器收藏夹的某个链接进入网站进行编辑搜索文档。最好不要离开 IDE，不要离开开发者手边的东西，离它越近的东西越有价值，比如我们定义一个编码规范，在 IDE 里直接提示应该怎样做，开发者可能懒的去找规范，而不是提交完了，再气冲冲的去改问题。</p><p></p><p>第二点就是我们会在很多地方做埋点去监控东西，比如说静态内部类是单例是最好的写法吗？不是，最好的写法是，你只要去标一个注解说这是单例，不管里边怎么实现的，是不是真的单例都没关系，就可以在团队级别起作用，大家得以自觉的不再去创造新的实例了，怎么能让这些契约成为武器，那就让他们尽可能在埋点的地方，进行自动生成。</p><p></p><p>第三点，我们的钩子里也有助于我们知道有哪些单例，有哪些架构组件，有哪些卡片等等，这些数据统计会对做架构决策有帮助。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e8/e876baed8cceced1522cfa344dfa55bf.png\" /></p><p></p><p>下面这是我们的几个示例，这几个东西都是 IDE 上的，都是基于开源框架去改的，它有各种衡量，比如像复杂度的衡量和抽样度的衡量，架构决策上是引导，lint 检查。我们自己在做 IDE 插件，我们的模板卡片怎么统计，它到底是什么卡片，什么类型，它的数据结构是什么样的，大概长的什么样子，能不能复用，这些东西都可以在 IDE 的工具里找到。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c5/c5768746f68fdc33a34e3cb40ece2460.png\" /></p><p></p><p>还有就是平台，我们基础平台团队在 DevOps 平台帮我们检查很多指标，像组件接口的依赖化的程度是不是合适的。后面这部分我们还在整合，不方便展示，包括健康度雷达，组件的健康度指标等。</p><p></p><p>作为一个业务开发团队，要体现业务价值，所以我们的业务目标是业务数据，比如 DAU、时长、留存、转化率，因业务形态、App 形态而异。这是必须直面的部分。</p><p></p><p>但这些业务数据往往不是一个业务开发团队能左右的，且不说里面有天时地利，而且需要 PM，策略，开发，市场等一众团队合力解决的。</p><p></p><p>所以另一个间接目标可能会是这个业务开发团队的口碑，一种公司内的“品牌”。这意味着虽然数据指标仍不如意，但我们已经尽最大的努力做到做好，比如我们做的需求数同比环比提高了一个量级，或者比公司其他的相似团队有质的提升。因为后者对开发团队本身更可控些。</p><p></p><p>有了这种用研发效率间接体现业务价值的思路，我们可以从需求数量（多）和需求质量（好）上着手继续拆解。</p><p></p><p>需求数量，可以用一个版本需求吞吐量衡量。那为什么需求可以突然做得多？可以大体拆成需求，人，效率三因素来看：</p><p></p><p>也许是 1）需求拆的小或者需求简单；</p><p></p><p>也许是 2）大家加班肝出来或者人员给力水平卓越；</p><p></p><p>也许是 3）效率提升，命中了之前做的改进措施；</p><p></p><p>那相反，为什么做得慢，需求复杂或者人员躺平或者没命中改进措施。很显然，需求拆小可能是“考核什么就会得到什么”的古德哈特定律对团队的反噬。也可能不是，我们可以把需求类型拆解为：</p><p></p><p>一期攻坚需求；要求快，投入人力往往较多，需求复杂。这种对复用性和协作分工性提出较高要求；后期迭代需求；这种需求偏小，但迭代频。会对不同团队成员的接力，进而对可读性提出要求；UE 需求；这种需求频率小，复杂度低，但波及范围广。会对组件的规范性提出要求；研发技术需求；这种我们不展开。</p><p></p><p>从这里也可以看出，提炼质量属性以及多维度指标是可行且可刻画需求本身（因为下面说的命中和此有关）。</p><p></p><p>看起来效率提升是可持续发展的正确思路。但拿技术手段来说，这里都有命中和没命中之说。比如改进措施：</p><p></p><p>1）架构边界清晰、可协作分工，设计通用、机制健全、可高度复用（用质量属性度量）。&nbsp; &nbsp; &nbsp; 因为我们不是在白纸上工作，都是在一个大的遗留代码中进行改进，没个几年不可能翻新一 &nbsp; &nbsp; &nbsp;遍代码，也无法保证翻新的收益以及翻新过程中间新出现的负收益。所以那些只谈从 20 天变成 5 天的，不谈命中概率的，我是持怀疑态度。</p><p></p><p>技术上的改进措施还可能是：</p><p></p><p>2）采用了自动化或者低代码技术（自动化率衡量）</p><p></p><p>3）动态化技术使双端需求变成了单端需求，比如用了 H5、RN、KMM 等技术（随版转非随率，人力投入比衡量）。</p><p></p><p>后面两者（2、3）依然存在命中概率，所以做得省、做得快不代表需求做得多，因为可能把人投资在了建设和维护这些如低代码平台，动态化能力完善上，改善架构和设计上。尽管如此，相比非技术手段的改进措施，如流程得到优化；梯队合理、培养了 backup，导致不需要有人从旁指导，接手速度快；等等吧，技术手段还是更研发可控些。</p><p></p><p>需求质量，那肯定业务数据提升代表需求质量好，数据提升的前提是：</p><p></p><p>1）体验好；2）线上稳故障少；3）我们的数据指标统计准。</p><p></p><p>虽然后者无法覆盖前者，但在一定程度上能间接刻画。而这些间接指标我们有些是定性，比如说团队成员有了数据驱动意识，有些可以拆解到研发可控的质量属性上：</p><p></p><p>1）性能；2）可维护性、可用性（鲁棒性）；3）可维护性，可预测性（平台监控、工具检查、测试覆盖等）。</p><p></p><p>说了这么多，就是想说我们可以通过建设健康度雷达来刻画质量属性，从而可以间接量化架构优化和重构升级的收益，这是一种不够严谨但研发可控的方式。但量化的收益是需要考虑命中率的。可以使用工具来识别迭代热点等来提高命中率，虽然如股票一样，这些指标仍代表的是过去，但对趋势研判是有助力的。另外就是架构、基建、机制这种往往是每块业务都避不开的，天然能命中。健康度雷达的另一个好处，我之前有看过，说这些质量属性上的提升，也会提升开发者的安全感和幸福感。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c0/c0bc7f37f2295bbac5fefcc31f3ae7fe.png\" /></p><p></p><p>回顾架构过程，我们做架构升级需求分析的时候，并行开发快速支持其它业务、业务动态下发、尽可能免测来提高研发效率、提高质量是我们的需求。我们甄别了几个除性能之外的质量属性，我把可观测性加在里边去了，我们很多东西是为了它去做设计的，然后我们进行了架构风格的选择，我们可以从内部自下而上进行改造，但是我们也想尽量和行业接轨，推行了很多风格的模型去做选择和借鉴。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/cf/cf7a00f46a4b3b030b5f795d474d0798.png\" /></p><p></p><p>最后就是维护的几个指标和平台建设的情况，我们整体获得了一些收益，比方说像输出复用的收益，还有并行开发、动态化这方面得到的一些改善，测试体系也得到了一些保障。很多时候在真实的复用场景中，如果复用的东西出现问题，影响面会非常广，我们希望有一个测试的体系来保障这些是可以改的，如果没有，有的时候确实还不如拷贝的方式，因为不希望影响到别的业务，所以想要真实复用，我们必须要建设测试体系。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3c/3c4342b5c1439bf6f669f616a7042623.png\" /></p><p></p><p>开发效率的提升来自于免测的情况，还有一个是非单点依赖，我们原来的业务很复杂，非常依赖某几个人，现在有了测试可以很好地应对这个问题，通过测试来知道改动对某些 case 是否有影响，这样我们就有信心去重构。</p><p></p><p>在决策自由度的改善上，比如从业务维度进行隔离后，各个业务参更好地根据自己的特点进行决策，因为它的粒度更细了，无论怎么说，细粒度化和积木化确实是大型 APP 的走向。</p><p></p><h5>相关阅读：</h5><p></p><p><a href=\"https://xie.infoq.cn/article/7c02a2af010b7ac97710edb9f\">百度 APP iOS 端内存优化实践 - 内存管控方案</a>\"</p><p><a href=\"https://xie.infoq.cn/article/e645ef771162067dc08002b0a\">百度 Android 直播秒开体验优化</a>\"</p><p><a href=\"https://xie.infoq.cn/article/18c01d16db60b3332fceaf631\">IDC MarketScape ：百度安全位居 NESaaS 市场领导者位置</a>\"</p>",
    "publish_time": "2022-12-08 17:09:31",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何平衡全球标准化和本土差异化｜第五期完整版（上）",
    "url": "https://www.infoq.cn/article/jryGQGYWDXcEhozouGmc",
    "summary": "<p>《行知数字中国》第五期，InfoQ邀请到麦当劳中国首席信息官，对外界深入分享他眼中的“数字化金拱门”。在他看来，企业进行数字化的过程很重要的一点是：转换思考问题的角度。</p>\n<p>本视频为第五期完整版的（上）集。精剪版可进入《行知数字中国》视频栏目专辑查看。</p>",
    "publish_time": "2022-12-08 18:16:41",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]