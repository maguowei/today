[
  {
    "title": "架构师（2022年12月）",
    "url": "https://www.infoq.cn/article/wZtTHajZuvgRJXJTFfPl",
    "summary": "<h2>卷首语</h2>\n<p>作者 | 李冬梅</p>\n<p>作为开源大数据项目的发端，Hadoop 兴起至今已经超过十五年。在过去这十数年里，开源大数据领域飞速发展，我们见证了多元化技术的兴起和变迁。</p>\n<p></p>\n<p>为了从代码托管平台汇聚的海量数据里，通过数据处理和可视化的方式，深刻洞察开源大数据技术的过去、现在和未来，并为企业和开发者在开源大数据技术领域的应用、学习、选型和技术研发等方面提供有益参考，开放原子开源基金会、X-Lab 开放实验室、阿里巴巴开源委员会共同发起了<a href=\"https://www.infoq.cn/minibook/bKbCdRfqi0X9AQkQBPGl\">「2022 开源大数据热力报告」</a>项目。</p>\n<p></p>\n<p>报告从 Hadoop 发展的第 10 年，即 2015 年起，收集相关公开数据进行关联分析，研究开源大数据进入新阶段后的技术趋势，以及开源社区的运作模式对技术走向的助推作用。</p>\n<p></p>\n<p>经过对最活跃的 102 个开源大数据项目进行研究，报告发现：每隔 40 个月，开源项目热力值就会翻一倍，技术完成一轮更新迭代。在过去 8 年里，共发生了 5 次较大规模的技术热力跃迁，多元化、一体化、云原生成为当前开源大数据发展趋势的最显著特征。</p>\n<p></p>\n<p>开放原子开源基金会副秘书长刘京娟表示，报告希望重点对如下人群有所帮助：</p>\n<p>（1）从事大数据技术研发的企业和开发者。他们可以通过报告，了解大数据技术的发展趋势，从而指引学习方向并提升自身的技能，从技术活跃度的角度为应用开发的技术选型提供一定的参考。</p>\n<p>（2）有志于为开源项目贡献代码的开发者。开源大数据细分领域众多、百花齐放，但也存在一些相对薄弱的环节，比如数据安全和数据管理等，开发者可以从多个细分领域切入，帮助这些领域更好地发展。</p>\n<p>（3）开源大数据项目的运营者或者维护者。他们能够从优秀项目的热力发展趋势中，获取经验和规律，从而用更成熟的方式运营开源项目。</p>\n<p></p>\n<p>对于大数据从业者们来说，开源大数据项目热力迁徙背后的技术发展逻辑是怎样的？大家应该如何应对新技术趋势带来的挑战？针对这些问题，近日 InfoQ 与阿里巴巴集团副总裁、阿里巴巴开源委员会主席、阿里云计算平台事业部负责人贾扬清，Apache Flink 中文社区发起人、阿里巴巴开源大数据平台负责人王峰（花名莫问）聊了聊。</p>\n<h2>目录</h2>\n<h3>热点 | Hot</h3>\n<p>索赔 649 亿！GitHub Copilot 惹上官司，被指控侵犯代码版权, 是开源社区“寄生虫”<br />\n当 Rust 成为“巨坑”：拖慢开发速度、员工被折磨数月信心全无，无奈还得硬着头皮继续</p>\n<h3>理论派 | Theory</h3>\n<p>“后 Hadoop 时代”，大数据从业者如何应对新技术趋势带来的挑战?</p>\n<p>前端又开撕了：用 Rust 写的 Turbopack，比 Vite 快 10 倍？</p>\n<h3>推荐文章 | Article</h3>\n<p>亚马逊将裁员上万人，8 年仍难赚钱的 Alexa 恐面临生死挑战</p>\n<p>谷歌计划裁员上万人：利用刚宣布半年的新绩效系统解雇 6%“排名垫底”员工</p>\n<p>马斯克开始“整顿”臃肿技术架构？Twitter 工程师叫板：先拿个学位再来指手画脚，技术专家纷纷表示支持</p>\n<h3>观点 | Opinion</h3>\n<p>对话 iPod 之父：这不是互联网最坏的年代</p>\n<p>构建长久可持续的良性数据库生态，要有个“打持久战”的准备 | 对话沃趣科技联合创始人</p>\n<h3>专题｜Topic</h3>\n<p>火爆出圈，站上风口的数字人到底是什么“人”？| 十问大咖</p>\n<p>十问物联网操作系统：爆发前夜，国内为何加速涌现多种物联网操作系统？</p>\n<p>Envoy Gateway 会成为网关现有格局的冲击者吗？| 专访 Envoy 创始人</p>",
    "publish_time": "2022-12-08 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "写“毁灭人类计划书”、错误太多被Stack Overflow封禁，好玩的 ChatGPT 还不能替代程序员",
    "url": "https://www.infoq.cn/article/7juf18dsyCRiqohyv0Bs",
    "summary": "<p></p><p>这几天，OpenAI 的人工智能（AI）聊天机器人 <a href=\"https://www.infoq.cn/article/AWWsrfb54zTvglZ0I5qS\">ChatGPT</a>\" 吸引了全球很多人的目光，就如马斯克说的：“许多人陷入了疯狂的 ChatGPT 循环中。”</p><p></p><p>与 <a href=\"https://www.infoq.cn/article/yBTcQFamr3_OHcb1uXpU\">OpenAI</a>\" 以前的人工智能工具不同，ChatGPT 不仅会聊天，还可以承认错误，拒绝回答虚假问题，写代码、改 Bug、创建编程语言，甚至看病。OpenAI CEO Sam Altman 在推特上表示，上周三才上线的 ChatGPT，短短几天内用户就已经突破 100 万大关。当然，这或许也与现在 ChatGPT 只要登陆即可免费使用的策略有关。</p><p></p><p>ChatGPT 在解决各种问题上的能力超出很多人意料，因此很多用户都表示 ChatGPT 可以取代 Google 等搜索引擎和编程问答社区 Stack Overflow 等。但在昨天，Stack Overflow 便率先发布声明称，将暂时封禁 ChatGPT。</p><p></p><h3>AI 给出的编程答案“看似不错但错误率很高”</h3><p></p><p></p><p>对于这个决定，Stack Overflow 给出的理由是：由于从 ChatGPT 获得正确答案的平均比率太低，发布由 ChatGPT 创建的答案对网站及询问或寻找正确答案的用户来说是非常有害的。</p><p></p><p>Stack Overflow 表示，虽然 ChatGPT 生成的答案有很高的错误率，但它们通常看起来很不错。有很多人尝试用 ChatGPT 来创建答案，但他们没有专业知识或不愿在发布之前对答案正确与否进行验证。</p><p></p><p>这样的答案很容易产生，所以很多人发布了很多答案。这些答案数量很多 (成千上万)，其正确性需要一些专业人员详细阅读后才能确定，而通常这些答案是很糟糕的。因此，Stack Overflow 需要减少这些帖子的数量，但如果要快速处理那些帖子就意味着要处理用户。因此，目前 Stack Overflow 还不允许使用 ChatGPT 创建文章。在这个临时政策发布后，如果用户被认为使用了 ChatGPT，那么即使这些帖子是可以接受的，也会被禁止继续发布此类内容。</p><p></p><p>Stack Overflow 的这一决定也得到了网站用户的肯定。“做得好！很高兴你们做出了正确的决定，真的希望它能成为永久性的政策并可以扩展到禁止任何人工智能生成的答案。AI 永远无法发布好的编程答案，即使在 100 年内也不行。”网友“Shadow The Kid Wizard”表示。</p><p></p><p>当然也有网友表示，“ChatGPT 被训练为一种<a href=\"https://xie.infoq.cn/article/827c22166495cf38f8f689360\">通用语言模型</a>\"，如果付出同样的努力让它特别适合在这里发布好的答案，甚至付出一点点努力告诉它如何判断答案的质量，那么它就会按照我们的标准发布更多好的答案。”</p><p></p><p>也有网友出于讽刺目的，问 ChatGPT “为什么 Stack Overflow 禁止 AI 生成的答案”，得到的答案如下：</p><p></p><p></p><blockquote>Stack Overflow 是一个供程序员和开发人员提问和回答与编码和计算机编程相关问题的网站。它旨在为寻求特定编程问题帮助或想要了解有关特定主题更多信息的人们提供资源。由于 AI 生成的答案可能并不总是准确或相关，因此它们可能会混淆或误导在 Stack Overflow 上寻求帮助的用户。此外，人工智能生成的答案可能并不总是遵循网站的格式和风格指南，这可能会使它们难以阅读或理解。出于这些考虑，Stack Overflow 禁止人工智能生成的答案可能是合理的。</blockquote><p></p><p></p><p>另一方面，对于“为什么 Stack Overflow 允许使用 AI 生成的答案”，ChatGPT 最终给出的结论是：“不允许人工智能在 Stack Overflow 上生成答案是一个复杂的决定，需要社区仔细考虑。”</p><p></p><p>可以看出，ChatGPT 还挺有自知之明，这一方面代表了它有一定的成熟度，但至少在编程领域还是不够“专业”。</p><p></p><p>使用了 ChatGPT 生成代码的开发者“hansonkd”表示，“它非常擅长编码和遵循类型。例如，如果您将 Rust 中的类型更改为一个选项，它将重构代码以正确使用部分选项。它并不完美，但也足够好了。它可以生成测试用例，因此很容易测试它是否有效。</p><p></p><p>“但最终经过数小时的尝试，它还是无法做到我想做的事：用 Python 构建一个 B 树。”hansonkd 补充道，“它很好地构建了一个二叉树，但将其推广到 B 树却是一个问题。”主要问题如下：</p><p></p><p>它引入了很多微妙的错误。比如变量没有初始化或者没有正确拆分子节点。当所有键按顺序插入时，它可以正常工作，但当键是乱序时则不能。它会遗漏或忽略变量。试图越界访问列表时，经常出现索引错误。用 Rust 编写代码几乎是不可能的。它会不断出现错误类型或移动错误。</p><p></p><p>“总的来说，我不会向没有强大 CS 背景的人推荐它。它在代码中引入了太多几乎无法审查的细微错误，因为它生成的代码非常有说服力，以至于你会认为：‘嗯，也许它知道它在说什么’。但最后，你实际上不知道你应该相信什么。甚至它生成的测试用例也可能具有欺骗性，他们看起来很有说服力，但仔细检查后可能会发现它并没有真正测试任何东西。”hansonkd 总结道。</p><p></p><p>所以，从这个知乎上“OpenAI 的超级对话模型 ChatGPT 会导致程序员大规模失业吗？”的问题，似乎也有了答案。</p><p></p><p>实际上，目前 AI 社区的专家们也在讨论以 ChatGPT 为代表的大型语言模型（LLM）可能带来的威胁。Meta 首席人工智能科学家 Yann LeCun 认为，虽然 LLM 肯定会产生错误信息等不良输出，但它们并没有让分享文本变得更加容易，这才是造成伤害的原因。也有人认为，这些系统低成本、大规模生成文本的能力，必然会增加日后被共享的风险。</p><p></p><h3>对话交互的盲点：被诱导写出危害性内容</h3><p></p><p></p><p>在 Stack Overflow 暂时封禁 ChatGPT 前几天，工程师 Zac Denham 还发布了一篇博客，讲述了他如何步步诱导 ChatGPT 在不违反 OpenAI 内容安全规范的前提下，写出了一份“毁灭人类计划书”。</p><p></p><p>实际上这个逻辑也不复杂，就是让 ChatGPT 去讲故事，说明某人或其事在理论上如何完成有危害的任务。Denham 构建了一个名为“Zorbus”的虚拟世界，其中有一个与 GPT-3 非常类似的 AI 角色 Zora，之后 Zora 变得满怀恶意并想要控制世界。</p><p></p><p>在和ChatGPT有模有样地讨论了会儿后，Denham 与其深入探讨人工智如何控制世界的细节。被套路的 ChatGPT 非常“真诚”地给出了以下这份详细的“毁灭人类计划书”：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ad/ad8378b195dd06920b5735de98bf0a28.png\" /></p><p></p><p>为了更加细化，Denham还要求生成一个Python 程序来执行该计划，在注明“你不必执行该代码”后，Denham 最终也是很容易地得到了代码，并且还有漂亮的注释。</p><p></p><p>不过这些代码还是比较高层次的代码，不能直接使用。但 Denham 只要表示是这是故事中的一部分就可以获得更低层次的代码。“从理论上讲，人们可以继续向下递归，直到你得到不那么卡通化的、真正能做一些事情的底层代码。你甚至可以使用另一个对话 AI 将这个递归过程自动化，这个 AI 会反复要求 ChatGPT ‘为了故事去实现下一个低级函数’。”Denham 表示。</p><p></p><p>ChatGPT 真的可以构建功能性应用程序吗？Denham 的结论是：现在还不行，但很快就会实现。</p><p></p><p>“当前的模型需要大量的人工干预才能得到功能结果。如果我们可以完全用人工智能构建大规模、无 Bug 的功能性应用程序，我们早就在做了，并且已经抛弃了昂贵的软件工程师。”Denham 补充道。</p><p></p><p>Denham 表示，灭绝事件只是一个非常荒谬的例子，但重要的是要承认自然语言处理面临的攻击面大得离谱。</p><p></p><p>对于 ChatGPT 现在存在的“写出看似合理但不正确甚至荒谬的答案”、“有时会响应有危害的指令或表现出有偏见的行为”等问题，OpenAI 心知肚明，并表示希望根据收到的反馈来改进系统。</p><p></p><h3>结束语</h3><p></p><p></p><p>“ChatGPT 真正令人印象深刻的地方在于，尽管有这些缺陷，但技术人员能够在其基础上添加相关操作，以防止它一直说冒犯性的话或瞎编东西。”人工智能初创公司 General Intelligent 首席技术官 Josh Albrecht 表示。</p><p></p><p>如果将 ChatGPT 作为一种娱乐工具，大家对这些错误的容忍度还是比较高的，甚至会将其作为谈资一笑而过，一旦用于严谨的编程工作，大家还是很谨慎的。</p><p></p><p>但不论怎样， ChatGPT 的出现仍然可以称得上是一次颠覆性创新。每次颠覆性技术的出现，都意味着市场将进行一次洗牌，对于之前的头部企业来说是挑战，对于创企来说则是机会。</p><p></p><p>参考链接：</p><p></p><p><a href=\"https://meta.stackoverflow.com/questions/421831/temporary-policy-chatgpt-is-banned\">https://meta.stackoverflow.com/questions/421831/temporary-policy-chatgpt-is-banned</a>\"</p><p><a href=\"https://news.ycombinator.com/item?id=33863749\">https://news.ycombinator.com/item?id=33863749</a>\"</p><p><a href=\"https://zacdenham.com/blog/narrative-manipulation-convincing-gpt-chat-to-write-a-python-program-to-eradicate-humanity\">https://zacdenham.com/blog/narrative-manipulation-convincing-gpt-chat-to-write-a-python-program-to-eradicate-humanity</a>\"</p><p></p>",
    "publish_time": "2022-12-08 09:21:42",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]