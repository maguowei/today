[
  {
    "title": "容器编排器生态：Swarm、Kubernetes、Nomad 并非仅有产品，但是最有生命力三个",
    "url": "https://www.infoq.cn/article/MeAAslt9z7vHWhNy4YyS",
    "summary": "<p></p><blockquote>尽管复杂，Kubernetes仍然是目前最流行的编排器，但 HashiCorp 在 Nomad 上的成功也表明，Kubernetes的替代方案还有发展空间。&nbsp;有些用户仍然热衷于Docker Swarm的简单性，但它的未来存在不确定性，其他替代方案看上去已经基本被放弃了。现在的生态似乎主要围绕着Swarm、Kubernetes 和 Nomad 这三个玩家，但容器编排仍然是一个相对不那么成熟的领域。十年前，这种技术几乎还不存在，现在仍在快速发展。容器编排领域可能还会出现许多令人兴奋的新想法和新发展。</blockquote><p></p><p>&nbsp;</p><p>本文最初发布于LWN.net。</p><p>&nbsp;</p><p><a href=\"https://lwn.net/Articles/902049/\">Docker及其他容器引擎</a>\"可以从许多方面简化服务端应用程序的部署，但许多应用程序不只包含一个容器。随着部署的应用程序和服务增加，管理一组容器的难度越来越大，一类名为容器编排器的工具由此发展了起来，截至目前最著名的是<a href=\"https://kubernetes.io/\">Kubernetes</a>\"，容器编排的历史以它为界也分成了前后两段。</p><p>&nbsp;</p><p>在享受容器带来的便利的同时，我们也要做好一些权衡取舍。如果一个人严格遵守Docker“<a href=\"https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#decouple-applications\">每个服务都应有自己的容器</a>\"”的理念，那么最终他将运行海量的容器。即使是一个访问数据库的简单Web界面也可能需要为数据库服务器和应用程序运行单独的容器，它可能还包括一个单独的Web服务器容器用于提供静态文件服务、一个单独的代理服务器容器用于终止SSL/TLS连接、一个键/值存储容器充当缓存，或者一个辅助应用程序容器用于处理后台作业及计划任务。</p><p>&nbsp;</p><p>一位管理员如果负责了数个这样的系统，很快就会发现需要一个工具来简化自己的工作，这就是容器编排器的用途所在了。</p><p>&nbsp;</p><p>容器编排器是一个工具，它可以将一组容器当成一个单元来管理。编排器让你可以将多台服务器合并成一个集群，并自动在集群节点之间分配容器工作负载，而不是单独在一台服务器操作。</p><p></p><p></p><h2>Docker Compose 和 Swarm</h2><p></p><p>&nbsp;</p><p><a href=\"https://github.com/docker/compose\">Docker Compose</a>\" 称不上是一个不完全的编排器，但这是Docker第一次尝试创建一个工具来简化多容器应用程序的管理。Compose读取一个YAML文件，通常命名为docker-compose.yml，并使用 Docker API创建文件中声明的资源；Compose还会为所有资源添加标签，以便在创建完成后把它们当成一个组来管理。实际上，它是Docker命令行接口（CLI，可操作容器组）的一个替代方案。Compose文件可以定义三类资源：</p><p>&nbsp;</p><p>服务（services)：声明要启动的容器，其中每一条都相当于一个docker&nbsp;run命令。网络（networks）：声明可以附加到容器（Compose文件中定义的）的网络，其中每一条相当于一个docker&nbsp;network&nbsp;create命令。卷（volumes）：&nbsp;定义可以附加到容器的命名卷。在Docker术语中，卷是可以挂在到容器的持久存储。命名卷由Docker daemon管理。其中每一条相当于一个docker&nbsp;volume&nbsp;create命令。</p><p>&nbsp;</p><p>网络和卷可以直接连接到Docker所在主机的网络和文件系统，也可以通过<a href=\"https://docs.docker.com/engine/extend/legacy_plugins/\">插件</a>\"提供。网络插件可以帮我们实现像将容器连接到VPN这样的事情；卷插件可以帮我们将卷存储在一台NFS服务器或一个对象存储服务上。</p><p>&nbsp;</p><p>在管理多容器应用程序方面，Compose提供了一种方便许多的方式，但在最初的版本中，它只能工作在单台主机上，创建的所有容器也运行在相同的机器上。为了让它能够覆盖多台主机，Docker在2016年推出了Swarm mode。实际上，这是Docker第二个带有“Swarm”字样的产品——2014年的一款产品实现了一种完全不同的、跨多台主机运行容器的方式，但Docker已经不再维护，它被 SwarmKit 所取代，后者是Docker Swarm当前版本的基础。</p><p>&nbsp;</p><p>Swarm mode包含在Docker中，无需安装其他软件。创建集群很简单，只需在初始节点上运行docker swarm init，然后在每个要添加的节点上运行docker swarm join。Swarm集群包含两种类型的节点。管理节点提供了一个API，用于启动集群中的容器，并使用基于<a href=\"https://raft.github.io/\">Raft一致性算法</a>\"的协议互相通信，在所有管理节点间同步集群状态。工作节点完成运行容器的具体工作。这些集群可以到多大我们并不是很确定，Docker的文档说一个集群的管理节点不应超过7个，但并没有说明工作节点的数量限制。跨节点桥接容器网络功能是自带的，但跨节点共享存储不是，需要借助第三方卷插件来提供跨节点的共享持久存储。</p><p>&nbsp;</p><p>服务使用Compose文件部署到Swarm上。Swarm扩展了Compose模式，为每个服务添加了一个deploy键，用于指定该服务应该运行多少实例以及应该在哪些节点上运行。遗憾的是，这导致了Compose和Swarm的分化，进而导致了一些混乱，因为对于像CPU和内存配额这样的选项，它们提供了不同的指定方式。</p><p>&nbsp;</p><p>在这段时期内，为了避免歧义，用于Swarm的文件被称作“栈文件”，而不是Compose文件；所幸，在Swarm和Compose的当前版本中，这些差异似乎已经被抹平。如果引用的栈文件和Compose文件截然不同，那多半是从网上搜来的。现在，Compose格式已经有了一个开放的规范，并且它自己的GitHub社区也提供了参考实现。</p><p>&nbsp;</p><p>Swarm的未来还存在一定的不确定性。它曾是Docker Cloud服务的基础，但<a href=\"https://web.archive.org/web/20200611102535/http://success.docker.com/article/cloud-migration\">该服务2018年突然关闭了</a>\"；它也曾被认为是Docker企业版的关键特性，但那个产品自此卖给了另外一家公司，它现在的名称为Mirantis&nbsp;Kubernetes&nbsp;Engine。与此同时，Compose的最新版本已经具备向亚马逊和微软托管服务部署容器的能力。一直没有弃用声明，但记忆中也没有任何其他类型的公告。在Docker的网站上搜索“Swarm”这个词，也只能够搜到过去一些曾提及它的信息。</p><p>&nbsp;</p><p></p><h2>Kubernetes</h2><p></p><p>&nbsp;</p><p>Kubernetes （有时候称为k8s）项目的灵感来自谷歌内部的一个工具<a href=\"https://kubernetes.io/blog/2015/04/borg-predecessor-to-kubernetes/\">Borg</a>\"。Kubernetes可以在多达数千个节点的集群上管理资源并协调工作负载的运行；它在容器编排领域的统治地位就像谷歌在搜索领域的地位一样。2014年，谷歌希望与Docker合作开发Kubernetes，但Docker决定走自己的路，继续开发Swarm。然而，Kubernetes在<a href=\"https://www.cncf.io/certification\">云原生计算基金会</a>\"（CNCF）的主持下发展壮大。截至2017年，Kubernetes已经变得如此流行，以至于Docker也宣布将其集成到自己的产品中。</p><p>&nbsp;</p><p>除了受欢迎之外，Kubernetes主要以其复杂性而闻名。手动配置一个新集群是一项非常复杂的任务，除了Kubernetes之外，管理员还需要选择并配置多个第三方组件。和Linux内核需要结合额外的软件形成完整的操作系统一样，Kubernetes只是一个编排器，它需要结合其他的软件才能组成一个完整的集群。它需要一个容器引擎来运行容器；它还需要网络插件以及持久卷插件。</p><p>&nbsp;</p><p><a href=\"https://containerjournal.com/topics/container-ecosystems/kubernetes-distribution-what-it-is-and-what-it-isnt/\">Kubernetes发行版</a>\"的存在填补了这一空白。和Linux发行版一样，Kubernetes发行版也将Kubernetes与安装程序以及精心挑选的第三方组件捆绑在一起。不同发行版的存在是为了满足不同的细分市场；似乎每个具有一定规模的公司都有自己的发行版和/或托管服务，以迎合企业的需求。minikube项目让开发人员可以轻松地在本地搭建一个试验环境。和Linux发行版不同，Kubernetes发行版经过了CNCF的一致性认证；为了得到认证，每个发行版都必须实现基本的功能，这样它们才能使用“Certified Kubernetes”标识。</p><p>&nbsp;</p><p>一个Kubernetes集群包含多个软件组件。集群中的每个节点都运行着一个名为kubelet的代理，用于维护集群的成员关系并从它接收工作。它还运行着一个容器引擎和kube-proxy，后者负责与在其他节点上运行的容器进行网络通信。</p><p>&nbsp;</p><p>维护集群状态的组件以及决定资源分配的组件合称为控制平面——这包括一个名为<a href=\"https://etcd.io/\">etcd</a>\"的分布式键值存储，一个给集群节点分配工作的调度器，一个或多个响应集群状态变化的控制器进程，负责触发所需的操作，使集群的状态符合预期。用户和集群节点通过Kubernetes&nbsp;API Server与控制平面交互。要实现修改，用户会通过API Server设定期望的集群状态，而kubelet会向控制器进程报告每个集群节点的实际状态。</p><p>&nbsp;</p><p>Kubernetes在一个名为pod的抽象中运行容器，其中可以包含一个或多个容器，不过，并不建议在一个pod中运行多个服务的容器。相反，一个pod通常只有一个提供服务的主容器，可能会有一个或多个“边”容器负责从运行服务的主容器中收集指标或日志。一个pod中的所有容器都将调度到同一台机器上，共享同一个网络命名空间——在同一pod中运行的容器可以通过loopback接口相互通信。每个pod在集群中都有自己独一无二的IP地址。运行在不同pod中的容器可以使用它们的集群IP地址相互通信。</p><p>&nbsp;</p><p>Pod指定一组要运行的容器，但pod的定义并没有说明在哪里运行这些容器，或者是运行多长时间——没有这些信息，Kubernetes就会在集群上的随便什么地方启动容器，但不会在它们退出时重启，而且，如果控制平面判断其他工作负载需要它们占用的资源，Kubernetes可能会终止它们。为此，pod很少单独使用；取而代之，pod的定义通常是封装在用于定义持久服务的Deployment对象中。和Compose及Swarm一样，由Kubernetes管理的对象是在YAML中声明的；对于Kubernetes，YAML声明是通过 kubectl 工具提交到集群的。</p><p>&nbsp;</p><p>除了pod和Deployment之外，Kubernetes还可以管理许多其他类型的对象，如负载均衡器和授权策略。它支持的API清单还在不断增长，根据Kubernetes的版本以及集群运行的哪个发行版会有所不同。<a href=\"https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/\">自定义资源</a>\"可以用于向集群添加API，用于管理额外的对象类型。例如，<a href=\"https://kubevirt.io/\">KubeVirt</a>\"添加的API使Kubernetes可以运行虚拟机。可以通过<a href=\"https://jamesdefabia.github.io/docs/user-guide/kubectl/kubectl_api-versions/\">kubectl&nbsp;api-versions</a>\"命令查看特定集群支持的完整API清单。</p><p>&nbsp;</p><p>和Compose不同，这些对象中的每一种都是在单独的YAML文档中声明的，虽然多个YAML文档可以内联到一个文件中，并用“---”隔开（参加<a href=\"https://kubernetes.io/docs/concepts/cluster-administration/manage-deployment/#organizing-resource-configurations\">Kubernetes文档</a>\"）。一个复杂的应用程序可能包含许多对象，它们的定义分散在多个文件中；在维护这样一个应用程序时，保持所有这些定义彼此同步会非常繁琐。为了简化这项工作，有些Kubernetes管理员转而采用像<a href=\"https://jsonnet.org/articles/kubernetes.html\">Jsonnet</a>\"这样的模板工具。</p><p>&nbsp;</p><p><a href=\"https://helm.sh/\">Helm</a>\"让模板工具更上一层楼。和Kubernetes类似，Helm也是在CNCF的主持下开发的；它号称是“Kubernetes包管理器”。Helm从一套名为chart的模板和变量声明生成Kubernetes的YAML配置。它使用的模板语言不同于Ansible使用的<a href=\"https://jinja.palletsprojects.com/en/3.1.x/\">Jinja</a>\"模板，但看上去非常相似；熟悉<a href=\"https://docs.ansible.com/ansible/latest/user_guide/playbooks_reuse_roles.html\">Ansible Roles</a>\"的人看到Helm Charts也会感觉很熟悉。</p><p>&nbsp;</p><p>Helm Charts集可以发布到<a href=\"https://helm.sh/docs/topics/chart_repository/\">Helm存储库</a>\"；<a href=\"https://artifacthub.io/\">Artifact Hub</a>\"提供了一个很大的公共Helm存储库目录。管理员可以将这些存储库添加到他们的Helm配置中，使用已经编制好的Heml chart将流行应用的预打包版本部署到集群上。Helm的最新版本还支持向容器注册中心推送或从注册中心拉取chart，为管理员提供了一个选型，让他们可以将chart和容器镜像存储在一起。</p><p>&nbsp;</p><p>Kubernetes的增长势头还没有任何减缓的趋势。按照设计，它可以管理任何类型的资源；这种灵活性（已为KubeVirt虚拟机控制器所证明）使得，即使容器化工作负载最终不再流行，Kubernetes仍然有继续存在的价值。开发有序进行，新的主版本定期发布。版本支持周期为1年；似乎没有长期支持版本。集群可以升级，但有人喜欢新建一个集群，并将服务迁移过去。</p><p>&nbsp;</p><p></p><h2>Nomad</h2><p></p><p>&nbsp;</p><p><a href=\"https://www.hashicorp.com/products/nomad\">Nomad</a>\"是HashiCorp推出的一个编排器，号称是一个比Kubernetes更简单的替代方案。和Docker及Kubernetes类似，Nomad是一个开源项目。它包含一个名为nomad的二进制文件，可以用于启动一个名为代理的守护进程。它还提供了一个CLI，用于和代理通信。根据配置方式不同，代理进程可以在两种模式下运行。在服务器模式下运行的代理可以接受作业，并为它们分配集群资源。在客户端模式下运行的代理会接收作业，运行它们，并将作业状态报告给服务器。代理还可以在开发模式下运行，同时承担客户端和服务器的角色，成为一个用于测试目的的单节点集群。</p><p>&nbsp;</p><p>创建Nomad集群相当简单。在Nomad最基本的操作模式中，必须启动初始服务器代理，然后使用nomad&nbsp;server&nbsp;join命令向集群添加额外的节点。HashiCorp还提供了Consul，这是一个通用的服务网格和发现工具。虽然Nomad可以单独使用，但最好是和Consul搭配使用。Nomad代理可以使用Consul自动发现并加入一个集群，它还可以执行健康检查，提供DNS记录，并为集群上运行的服务提供HTTPS代理。</p><p>&nbsp;</p><p>Nomad支持复杂的集群拓扑。每个集群被划分成一个或多个“数据中心”。和Swarm类似，同一数据中心中的服务器代理使用一种基于Raft的协议相互通信；这种协议有严格的延迟要求，但多个数据中心可以用gossip协议连接起来，从而使信息可以在集群中传播，而又不需要每个服务器与其他服务器保持直接连接。从用户的角度来看，以这种方式连接起来的数据中心就和一个集群一样。这种架构让Nomad在扩展到大量集群时颇有优势。按照官方说法，Kubernetes最多支持5000个节点和3万个容器，而Nomad的文档中提到了一个有1万多节点的集群示例和一个有20万容器的集群示例。</p><p>&nbsp;</p><p>和Kubernetes类似，Nomad并没有包含一个容器引擎或运行时，它使用任务驱动器来运行作业。它包含使用Docker和Podman来运行容器的任务驱动器；社区提供了面向其他容器引擎的驱动器。Nomad的野心也不限于容器，这点也和Kubernetes类似。它还提供了面向其他工作负载类型的任务驱动器，包括在主机上运行命令的fork/exec驱动器，运行虚拟机的QEMU驱动器，启动Java应用程序的Java驱动器。社区支持的任务驱动器可以将Nomad连接到其他类型的工作负载。</p><p>&nbsp;</p><p>与Docker或Kubernetes不同，Nomad不使用YAML，而是使用<a href=\"https://github.com/hashicorp/hcl\">HashiCorp配置语言</a>\"（HCL）。HCL最初是为HashiCorp的另一个项目创建的，用于配置名为<a href=\"https://www.terraform.io/\">Terraform</a>\"的云资源。虽然在其他地方的应用有限，但HashiCorp的整个产品线都在使用HCL。用HCL编写的文档很容易转换成JSON，但它的目标是提供一种比JSON更便捷、比YAML更不容易出错的语法。</p><p>&nbsp;</p><p>HashiCorp提供的相当于Helm的产品是Nomad Pack。和Helm类似，Nomad Pack会处理一个满是模板和变量声明的目录，生成作业配置。Nomad还有一个预打包应用程序的社区注册中心，但其选择空间比Helm的Artifact Hub要小很多。</p><p>&nbsp;</p><p>Nomad不像Kubernetes那么受欢迎。和Swarm一样，它的开发似乎主要是由其创建者推动的；尽管有许多大公司部署了HashiCorp，但HashiCorp仍然是Nomad相关社区的中心。目前看来，该项目似乎不太可能获得足够的发展势头，进而从母公司独立出来。对用户来说，与Docker在Swarm上做的工作相比，HashiCorp对Nomad的开发和推广或许更有保证。</p><p></p><h2>小结</h2><p></p><p>&nbsp;</p><p>Swarm、Kubernetes和Nomad并不是仅有的容器编排器，但它们是其中最有生命力的三个。<a href=\"https://mesos.apache.org/\">Apache Mesos</a>\"也可以用来运行容器，但它在2021年就几乎被封存了；<a href=\"https://dcos.io/\">DC/OS</a>\"基于Mesos，但很像Docker企业版，支持其开发的公司现在也专注于Kubernetes。其他大多数容器编排项目，如OpenShift和Rancher，实际上只是增强（和认证）的Kubernetes发行版，即使它们的名字中没有 Kubernetes。</p><p>&nbsp;</p><p>尽管 Kubernetes 非常复杂，它仍然是目前最流行的编排器，但HashiCorp在Nomad上的成功表明，替代方案也还有它的发展空间。有些用户仍然热衷于Docker Swarm的简单性，但它的未来存在不确定性。至此，其他替代方案看上去已经基本被放弃了。现在的生态似乎主要围绕着这三个玩家，但容器编排仍然是一个相对不那么成熟的领域。十年前，这种技术几乎还不存在，而它现在仍在快速发展。容器编排领域可能还会出现许多令人兴奋的新想法和新发展。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://lwn.net/SubscriberLink/905164/e1f4d4c1ce35f8b9/\">The container orchestrator landscape</a>\"</p>",
    "publish_time": "2022-11-18 07:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Tensorflow新一轮迭代路线图：更好的XLA编译和分布式计算",
    "url": "https://www.infoq.cn/article/0LoWyKuYdXlCdWkNEyPV",
    "summary": "<p>谷歌<a href=\"https://blog.tensorflow.org/2022/10/building-the-future-of-tensorflow.html\">宣布</a>\"TensorFlow开发的下一轮迭代。TensorFlow是由谷歌开发并在七年前<a href=\"https://github.com/tensorflow\">开源</a>\"的机器学习平台，现在是GitHub上star数量最多的项目之一。另外一个方案是<a href=\"https://pytorch.org/\">Pytorch</a>\"，它是由Facebook开发和开源的ML平台。未来几个<a href=\"https://www.infoq.cn/topic/TensorFlow\">TensorFlow</a>\"发布版本的开发路线图将基于四个支柱，分别是快捷与扩展性、机器学习应用、部署就绪和简单性。</p><p></p><p>对于快捷和可扩展的支柱来说，开发工作将主要关注XLA编译，因为谷歌认为XLA将成为深度学习编译器的行业标准。其目标是使模型训练和推理工作流程在CPU和GPU上更快地执行。开发也将关注分布式计算方面：借助<a href=\"https://www.tensorflow.org/guide/dtensor_overview\">DTensor</a>\"，模型将能够在多个设备上进行训练，以解锁未来超大型模型的训练和部署。此外，性能也很重要，所以谷歌将对算法性能的优化进行投资，如<a href=\"https://en.wikipedia.org/wiki/Mixed-precision_arithmetic\">mixed-precision</a>\"和<a href=\"https://www.rambus.com/blogs/reduced-precision-computation-for-neural-network-training/\">reduced-precision</a>\"计算，以提高在GPU和TPU上的速度。</p><p></p><p>对于机器学习应用支柱，谷歌将投资<a href=\"https://github.com/keras-team/keras-cv\">KerasCV</a>\"和<a href=\"https://github.com/keras-team/keras-nlp\">KerasNLP</a>\"包，这些包是为应用CV和NLP使用场景设计的，包括大量的预训练模型。该支柱也将以开发者资源为基础：对于流行的和可应用的机器学习场景添加更多的代码样例、指南和文档，以降低机器学习的进入门槛。</p><p></p><p>对于部署就绪支柱，努力的方向主要在于更便利地将模型导出到移动端、边缘端、服务后端以及JavaScript中。尤其是，将模型导出到<a href=\"https://www.tensorflow.org/lite\">TFLite</a>\"和<a href=\"https://www.tensorflow.org/js\">TF.js</a>\"将会更易于调用。C++原生API正处于开发阶段，它会更易于部署使用<a href=\"https://github.com/google/jax\">JAX</a>\"和TensorFlow Serving开发的模型，并使用TFlite和TF.js部署到移动端和web中。</p><p></p><p><a href=\"https://numpy.org/\">NumPy</a>\"&nbsp;API和更便利的调试体验将是第四个支柱的核心特征，即简单性。Tensorflow将采用NumPy API的数值标准，以使其更加一致和易于理解。Tensorflow还会实现更好的调试器功能，以最大限度地减少开发人员解决问题的时间。</p><p></p><p>谷歌承诺，新的Tensorflow版本将100%向后兼容，这样，工程师可以立即采用最新的版本，而不用担心现有的代码库会出现问题。</p><p></p><p>Tensorflow新功能的预览版计划在2023年第二季度推出，生产版本计划在同一年推出。关于路线图和相关更新的更多信息可以参阅<a href=\"https://blog.tensorflow.org/\">官方博客</a>\"。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/10/google-tensorflow-roadmap/\">Google’s Tensorflow Roadmap Includes Better XLA Compilation and Distributed Computing</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/8OADODV0EZZ72TMrDvTz\">使用&nbsp;TensorFlow.NET 构建神经网络</a>\"</p>",
    "publish_time": "2022-11-18 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AI 算法在智能搜索领域的经验分享",
    "url": "https://www.infoq.cn/article/vALgJcNQM9ue2IQN7l5H",
    "summary": "<h2>听众受益</h2>\n<ul>\n<li>了解搜索和推荐的根本区别</li>\n<li>了解搜索功能实现的基本流程和功能模块以及各模块的关键技术点</li>\n<li>了解搜索功能召回和精排部分的建模方法和基于场景的思考</li>\n</ul>",
    "publish_time": "2022-11-18 08:51:02",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "社交网络分析方法在恶性舆论事件分析中的应用",
    "url": "https://www.infoq.cn/article/yiqJ3WXw0LoCV8qRpxzK",
    "summary": "<h2>议题概要</h2>\n<p>近年来域外社交平台涌现污名化中国的舆论事件，事件背后的组织与个人对事件的发酵与传播起着推波助澜的作用。本议题以域外抵制2022年北京冬奥会为例，以百分点数据科学基础平台为实现工具，介绍如何利用社交网络分析与机器学习分类算法，分析挖掘参与话题用户的角色作用，并识别异常机器人用户，实现恶意话题中的用户类型精准定位。</p>\n<p>暗流涌动的污名化舆论中，“看不见的手”究竟是谁？谁在张扬推动？谁在暗中勾连？本次分享将为大家揭秘，社交网络分析如何对舆论事件层层拆解，定位关键。</p>\n<h2>听众受益</h2>\n<p>•了解社交网络分析基本原理<br />\n•了解如何识别社媒用户在社群中的角色作用<br />\n•了解如何使用百分点数据科学基础平台实现社交网络分析与可视化过程</p>",
    "publish_time": "2022-11-18 08:58:44",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "马斯克称Twitter将专注“硬核软件工程”：要么加班，要么走人",
    "url": "https://www.infoq.cn/article/J8E4r5V4UBAFmmzFvV9f",
    "summary": "<p>据<a href=\"https://www.washingtonpost.com/technology/2022/11/16/musk-twitter-email-ultimatum-termination/\">外媒报道</a>\"，马斯克在当地时间周三凌晨向 Twitter 员工发送一封电子邮件，要求员工在周四下午 5 点之前做出选择——要么接受“极其硬核”的 Twitter 2.0 计划，接受长时间、高强度的工作；要么拿着三个月薪资的遣散费走人。</p><p></p><p>在这封名为“岔路口”的邮件中，马斯克写道：</p><p></p><p></p><blockquote>展望未来，要想建立一个突破性的 Twitter 2.0，并在竞争日益激烈的世界中取得成功，我们需要“极其硬核”。这也意味着，需要长时间、高强度的工作，只有优异的表现才算及格。Twitter 将更加以工程为导向。设计和产品管理仍将非常重要，并向我汇报，但那些编写出色代码的人将构成我们团队的大多数，并具有最大的影响力。从本质上来讲，Twitter 是一家软件和服务器公司，所以我认为这是有道理的。如果你确定你想成为新的 Twitter 的一员，请点击这个链接。在美国东部时间明天(周四)下午 5 点前，任何没有这样做的人都将获得 3 个月的遣散费。无论你做出什么决定，都要感谢你为 Twitter 成功所做的努力。</blockquote><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dd/dd7c75cb2d0995907f740a980250a182.jpeg\" /></p><p></p><p>对于这封邮件，网友 Jez Wyke 批评道：马斯克需要具备更好的管理和领导能力，任何需要做的事情，都要给足够的时间和资源，毕竟员工不是你的个人财产。</p><p></p><h2>马斯克的“硬核软件工程”愿景</h2><p></p><p></p><p>这并不是马斯克第一次强调“硬核”。早在今年 5 月份，他就曾在 Twitter 上表示，一旦他成功收购 Twitter，公司就将超级专注于“硬核软件工程”、设计、信息安全和服务器硬件。当时“UML 之父”Grady Booch 还曾质问马斯克，“硬核软件工程”究竟是什么意思。Grady Booch 是 IBM Rational 的首席科学家，其在软件架构、软件工程和软件建模方面有杰出贡献，并在国际上享有盛名。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/db/db8a0af1acedcaf9e0d995b9b088cdff.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6c/6c8fd6c231c54520a7e8a5ca1117e851.png\" /></p><p></p><p>在讨论马斯克的“硬核软件工程”之前，或许应该先聊聊什么是软件工程。</p><p></p><p>现在的软件开发早已告别了单兵作战的时代，一些中大型软件都是团队的集体智慧产出。而软件工程则是团队协作的基石，区别于传统的项目管理，软件工程是一项复杂的知识工程。比如现代软件开发都建立在 Apache 和 Linux 基金会的众多开源项目之上，成千上万的软件工程师通过集体协作，编写了上亿行代码，最终才诞生了这些伟大的项目。大批程序员通过精细化分工协作，达到高效的工作和高质量产出。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/72/722eaaf5960b997cef7511f7474bda12.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d4/d40f33708c0ac0f1a295951936de2bc4.png\" /></p><p></p><p>作为软件工程实践最成功的公司之一，谷歌内部曾有声音认为“软件工程是随着时间的推移而集成的编程”。不过，时间对程序的影响是一个没有固定答案的问题，代码的预期寿命无论是几分钟，还是数十年，都能找到合理的解释。对于一个假定只有 1 小时寿命的程序来说，开发者不太可能需要适应新版本的底层库、操作系统、硬件或语言版本。因此，这个短寿的程序实际上只是一个编程问题。如果开发者想延长程序的寿命，就需要对程序做出改变。在十年或更长的时间里，大多数程序的依赖关系，无论是隐式的还是显式的，都可能会发生变化。就需要做出的决策的复杂性及其风险而言，软件工程与编程不同，进一步来说，编程只是软件工程的重要组成部分。</p><p></p><p>正如 Jorge Luis Borges 所说：没有什么是建立在石头上的。一切都建立在沙子上，但我们必须把沙子当作石头来建造。</p><p></p><p>在现代软件工程的基础上，马斯克加了“硬核”二字，让一切都变了味儿。</p><p></p><p>从马斯克的各种言论里，可以推测他所认为的“硬核软件工程”，在某种程度上等同于长时间、高强度的工作。毕竟在接手 Twitter 后，马斯克不止一次强调工时问题。</p><p></p><p>据 CNBC 11 月初报道，在没有明确加班费的情况下，马斯克要求 Twitter 的部分员工“997”，即每周工作 7 天，每天工作 12 小时。11 月 9 日，马斯克又向全体 Twitter 员工发送电子邮件，要求员工停止远程办公，每周在岗时间至少 40 小时。</p><p></p><p>马斯克曾在一条推文回复中强调，他对员工职业道德的期望是极端的，但相比对自己的要求来说，还是低了很多。他在前几天举行的第 29 届年度巴伦投资大会上称，收购 Twitter 后，自己的工作时长从每周 70-80 小时增加到 120 小时（平均每天 17 个小时以上）。他在另一场采访中更是强调，“我尽我所能工作——从早到晚，一周 7 天。”</p><p></p><p>一位程序员网友对此评论说：“我从事过高压项目，如果要从所有这些项目中吸取一个教训，那就是在编码方面，更长的工作时间会导致负生产力，因为你必须在后面进行更多测试、修复更多（最初未检测到的）错误。在我看来，管理层也有责任确保你的员工保持理智和健康——显然马斯克不这么认为。”</p><p></p><h2>Twitter 的软件是不断迭代出来的</h2><p></p><p></p><p>从 2006 年建立到现在，Twitter 历经多轮<a href=\"https://www.infoq.cn/article/twitter-architecture-evolution\">技术迭代</a>\"，解决过无数类似“失败之鲸”的故障，从而让系统变得庞大而稳固，在此同时，软件工程的复杂性也在不断增加。</p><p></p><p>在创办初期，Twitter的架构非常简单，当时创始人 Jack Dorsey 考虑过用 Python、C 和 OCaml 编写软件。不过机缘巧合，他找到了 Ruby on Rails 的核心贡献者 Florian Weber，所以 Twitter 选择了用 RoR 实现。</p><p><img src=\"https://static001.infoq.cn/resource/image/72/99/729bb950c1a43d2d96ee7cd9eaf47f99.png\" /></p><p>随着 Twitter 用户规模不断增长，其 Ruby on Rails 部署规模已经是世界第一，最多时机器达到 3000 台。但所有逻辑都在 Monorail 中，当时有超过 200 名工程师往里面 check in 代码，导致系统效率低下，延迟长，难以加入新功能。</p><p></p><p>随后，Twitter 开始对系统进行拆分，并用 Scala 重写了服务器。经过进一步分解，Monorail 逐渐被分离出来，整个系统从 Ruby 平台迁移到 JVM 上。单机 QPS 处理能力从 200~300 提高到 10000~20000，延迟减小到 1/3；减少了 90% 资源使用。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/d8/da/d8569ccc559aa77fbac0ee345cc8d0da.png\" /></p><p></p><p>在经历了多轮系统拆分后，2015 年，Twitter 已经搭建起完整的工程生态，软件工程的复杂度跟十年前已经不可同日而语。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b6/b6bdb0015d203c36b5ce3bd2697f85a8.png\" /></p><p></p><p>像 Twitter 这样的规模少有其他公司能够达到。在达到这样的规模之前，必然经历过艰辛的拓荒之路，背后更是无数“技术天才”不断地钻研和付出。</p><p></p><p>知名开发者 Dan Luu 发帖称，Twitter在基础设施方面，做了非常多的“硬核”工作，而在较为年轻的企业中，这些工作大多会以“云”或开源项目的形式被外包出去。他举例称，很多人可能不知道，Twitter 公司也有自己的内核团队，在设计低功耗服务器时，Twitter的团队能让服务器达到让英特尔都惊讶的功率范围；在 gRPC 出现之前，Twitter 就开始研究RPC了，所以他们构建了 Finagle；Twitter 的内部数据库 Manhattan 的延迟非常低，导致 Twitter 尝试迁移到云并切换到某些云数据库时还曾因此出现问题....</p><p></p><p>在马斯克接手后，Twitter 的软件工程重心或将再次进行转移，毕竟他理解的软件工程，貌似和大家理解的不是一回事儿。而这些人才也不被珍惜地“清理”了出去。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/13/1334486c250124cd43bfea4d6f3689cd.png\" /></p><p></p><p>本周早些时候，马斯克还质疑 Twitter App 在渲染主页时间线时，会执行 1000 多个性能低下的<a href=\"https://www.infoq.cn/article/Gw50bZHLrreF9GAVJJDc\">批量 RPC</a>\"，导致运行速度过慢。对于这个说法，Twitter 软件工程师 Eric Frohnhoefer 站了出来，押上自己的职业生涯跟马斯克正面对决：“我参与 Android 版 Twitter 的开发有大概 6 年了，我敢说这种论断是错的。”很快，Eric Frohnhoefer 就遭到了解雇，一些站队 Eric Frohnhoefer 的工程师如首席软件工程师 Yao Yue、软件工程师 Sasha Solomon 和后端工程师 Nick Morgan 也纷纷被解雇。</p><p></p><p>对于这些因意见不合而被解雇的工程师们，马斯克还阴阳怪气道：“我为解雇这些天才而道歉。他们的巨大才能无疑将在其他地方发挥巨大作用。”</p>",
    "publish_time": "2022-11-18 10:23:32",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "面向基础软件领域，ReScript编程语言中文文档正式上线",
    "url": "https://www.infoq.cn/article/yL6WxAPUzoZDL42dMgFb",
    "summary": "<p></p><h2>ReScript是什么？</h2><p></p><p><a href=\"https://rescript-lang.org/\">ReScript</a>\"是由&nbsp;IDEA讲席科学家<a href=\"https://www.infoq.cn/article/z7Fo6dZC408iguGJiDzN\">张宏波</a>\"于2015年设计的一门静态函数式语言，由国人主导设计研发，且目前已成为了在国际上有一定影响力的通用程序语言。</p><p>&nbsp;</p><p>ReScript起源于OCaml，能被编译成高质量、可读性强的JavaScript代码，其性能在同类型语言中<a href=\"https://unsafeperform.io/blog/2022-07-02-a_small_benchmark_for_functional_languages_targeting_web_browsers/\">遥遥领先</a>\"，ReScript本身也被用于<a href=\"https://ocaml.org/\">OCaml官方网站</a>\"的搭建。</p><p>&nbsp;</p><p>ReScript语言有着相对活跃的国际化<a href=\"https://forum.rescript-lang.org/\">社区</a>\"。这门程序语言曾被多个业界巨头使用，如Meta用于<a href=\"https://www.messenger.com/\">Messenger</a>\" 和Chats，Google用于<a href=\"https://github.com/WebAssembly/spec\">WebAssembly spec</a>\"；此外，ReScript在全球范围也具有一定的影响力，曾被欧洲、澳洲、北美、亚洲甚至中东的数百家公司采用，如欧洲的Wolt、 澳洲的TinyMCE、韩国的GreenLabs、印度的Porter以色列的AT&amp;T等等。截止目前，ReScript全球累计下载量近3百万，每周平均下载量约1.5万次。</p><p>&nbsp;</p><p>ReScript社区在线下也有过比较积极的交流，在疫情前曾分别在维也纳，芝加哥共召开过三次ReScript全球开发者大会。此外，ReScript编译器本身的贡献也非常多元化，除了原作者张宏波本人以外，有来自世界各地近300名的贡献者，目前累计约1.4万多次提交。其核心开发人员中也不乏业界权威如<a href=\"https://github.com/cristianoc\">Cristiano</a>\"、著名的静态分析软件<a href=\"https://fbinfer.com/\">Infer</a>\"的作者。 ReScript作者在加入IDEA之前，因其在社区的特殊贡献成为Meta在中国大陆的唯一一名特聘软件工程师。</p><p>&nbsp;</p><p>ReScript社区还具有多元化的特点，目前社区已经贡献了英文官方文档并被翻译成韩语、葡萄牙语等多国语言。ReScript作者离开Meta后致力于中文社区的推广，开设了国内首门以ReScript语言来实现的程序语言理论和实践公开课程。同时，为了让国内开发者更方便地学习和入门这门语言，在社区众多志愿者的帮助下，完成了中文文档的首次发布。</p><p>&nbsp;</p><p>本次 ReScript 中文文档上线，不仅能够降低该语言对于国内开发者的学习门槛，还能为之后中文社区的建设夯实基础。欢迎广大开发者使用 ReScript 做出更多技术性尝试，一起为我国的基础软件领域发展添砖加瓦。</p><p>&nbsp;</p><p>文档主页：<a href=\"https://link.zhihu.com/?target=https%3A//rescript-idea.github.io/\">https://rescript-idea.github.io/</a>\"</p><p>ReScript语言中文手册：<a href=\"https://link.zhihu.com/?target=https%3A//rescript-idea.github.io/docs-cn/manual/latest/introduction\">https://rescript-idea.github.io/docs-cn/manual/latest/introduction</a>\"</p><p></p><h2>为什么选择ReScript？</h2><p></p><p>&nbsp;</p><p>开发者所使用的<a href=\"https://www.infoq.cn/article/Bz4RgtSyra8c94CY2HCg\">编程语言</a>\"除了会影响日常所写的代码，还会塑造这门语言的使用者在编写程序时的思维方式，甚至也会影响到其在开发软件以及设计架构时的思维方式。</p><p>&nbsp;</p><p>另外一方面，软件开发所选择的程序语言会影响代码的可靠性、安全性和性能，从长远来看也影响开发者阅读代码的流畅度，以及对现有代码进行重构和扩展的复杂度。</p><p>&nbsp;</p><p>ReScript采用了过去几十年业界和学术界一些关键语言特性的优雅组合，使其具备了效率、表达能力和实用性的良好平衡。</p><p>&nbsp;</p><p>ReScript具有两大亮点，一是类型系统：在程序执行之前，编译器会检查数据的类型和对其进行的计算是否相匹配。对于出现类型不匹配情况的程序，类型系统会进行报错，而不会在执行程序的过程中出现未定义行为或者程序崩溃的情况。这有助于帮助语言的使用者及时排查出程序中可能存在的bug，从而提升程序的可靠性和稳定性。</p><p>&nbsp;</p><p>另一大亮点是ReScript可以沿用当前<a href=\"https://www.infoq.cn/article/CSRgKxyZK0XNK9ZARYEp\">JavaScript</a>\"的生态，ML语系很多方言设计的很优雅，但是当需要做工业应用的时候往往因为缺乏完善的第三方库而让人望而却步。ReScript得益于和JavaScript共用运行时，使得业界可以快捷方便地拿来作为主要工具语言开发工业级应用，而不会产生大量的额外负担。</p><p>&nbsp;</p><p>ReScript曾被著名程序员Paul Biggar（连续创业者: CircleCI、Darklang的创始人，程序语言专业博士）认为是可能是JS平台上最好的编程语言。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/45/4545556c76c6bd08956d09cac09f5009.png\" /></p><p></p><p>&nbsp;</p><p>虽然同赛道的<a href=\"https://www.infoq.cn/article/ds994KySqo868U3e8s4N\"> TypeScript</a>\" 搭配孪生项目 VsCode已经占据了绝大部分市场份额，但由于设计思路上更具远见，在未来，ReScript 仍然有机会可以成为国产基础软件的一个突破。</p><p></p><h2>未来ReScript将如何发展？</h2><p></p><p></p><p>ReScript是由国人主导设计的一门编程语言，未来它的发展将立足中国，拥抱世界，努力培养一个开放，多元化的社区。</p><p>&nbsp;</p><p>在语言本身发展方面，ReScript将加速和TypeScript的整合，提高和TypeScript的互操作。同时，由于ReScript的类型系统的可靠性，ReScript也将聚焦去实现一些TypeScript不能做到的事情，如将更多的类型信息用于代码优化，对多后端如WebAssembly的探索。</p><p></p><h2>首个以ReScript语言实现的程序语言理论与实践公开课上线</h2><p></p><p>&nbsp;</p><p>程序语言与编译器的<a href=\"https://qcon.infoq.cn/2022/shanghai/track/1435\">设计与实现</a>\"体现了计算机科学中的最核心的思想和技术，并且和业界新兴的技术领域，如人工智能加速芯片、云计算、物联网等都有着非常重要的联系。但目前在国内一直存在缺少优质教学资源、入门难、领域人才稀缺的问题。</p><p>&nbsp;</p><p>最近，IDEA基础软件中心在bilibili平台推出由张宏波亲自讲授的《程序语言理论与实践公开课》，这是首个以Rescript语言进行教授的编程语言课程。</p><p>&nbsp;</p><p>这门公开课的制作团队曾深度参与过哈佛、耶鲁、宾大相关课程的制作。课程以理论与实践相结合的方式讲授编程语言最核心内容填补了国内该教学领域的空白，意在培养更多学生及业界同行对基础软件相关领域的兴趣，为国内基础软件行业贡献一份力量。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://idea.edu.cn/dii.html\">https://idea.edu.cn/dii.html</a>\"</p><p><a href=\"https://bobzhang.github.io/courses/\">https://bobzhang.github.io/courses/</a>\"</p><p><a href=\"https://space.bilibili.com/1453436642/video\">https://space.bilibili.com/1453436642/video</a>\"</p><p><a href=\"https://www.zhihu.com/column/c_96822072\">https://www.zhihu.com/column/c_96822072</a>\"</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2022-11-18 10:23:56",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "我们这群90后，正在字节跳动“死磕”Linux内核 | 卓越技术团队访谈录",
    "url": "https://www.infoq.cn/article/INOPK8KybcAGOePKeYga",
    "summary": "<p>嘉宾 | 张宇、段熊春、宋牧春、谢永吉、邓良</p><p>作者 | 凌敏</p><p></p><p></p><blockquote>随着互联网的快速更迭，许多明星产品在时代的光环下熠熠生辉；但在喧闹的背后，有这样的一个群体，默默的守护着互联网世界的平稳，今天我们就来介绍这样一群幕后守护者。</blockquote><p></p><p></p><p>2012 - 2022，是字节跳动产品线快速延伸的十年，也是基础设施规模快速增长的十年。在这背后，有这样一支团队默默为字节上层业务的稳定保驾护航，他们就是字节系统部 STE 团队。</p><p></p><p>早在 2015 年，<a href=\"https://www.infoq.cn/article/UWL0pC4CfkSsBoaDxLkw\">STE 团队</a>\"就初具雏形，当时主要是问题驱动，为字节内部基础设施及软件系统提供技术支持。随着 2017 年抖音等热门产品用户量级大爆发、成为现象级 APP，字节内部的服务器规模愈发庞大，对系统的维护工作也成为重中之重。</p><p></p><p>2018 年，团队被正式命名为 STE（全称：System Technologies &amp; Engineering，系统技术与工程）。如今，STE 团队已从最初的 20 人扩大至数百人规模，在英国、美国等多地设有研发中心。技术维度也从操作系统内核扩展到服务器固件、编译器技术、系统虚拟化、主机网络、系统智能运维等基础技术，并将基础软件工程能力赋能业务。</p><p></p><p>在本期访谈中，InfoQ 有幸采访到了 STE 内核方向的多位核心成员，了解他们在 Linux 内核优化上的技术实践与经验，以及这些工作为业务带来的价值，同时一窥这支专注于底层基础设施建设、在“看不见的地方”用技术构筑城墙的团队的精神和文化。</p><p></p><h2>专注 Linux 内核的 90 后团队</h2><p></p><p></p><p>据了解，STE 内核团队是字节系统部面向公司内部所有业务提供 Linux 内核服务的团队，主要负责内核管理、进程调度、虚拟化和网络等几个方面的工作。据 STE 内核团队负责人段熊春介绍，在 2015 年 STE 团队初具雏形的时候，就有研发人员负责内核相关的工作。2018 年，STE 团队正式成立，内核方向也作为其下属团队之一，逐步扩建成有专职研发人员负责解决 Linux 内核存在的问题，并增加和维护新特性。</p><p></p><p>我们注意到，这是一支非常年轻的团队，内核维护者以 90 后居多，这其实并不常见。毕竟 “Linux 之父”Linus Torvalds 曾感慨，“目前的维护者多是 50、60 后，社区面临代际更新问题。”Linus Torvalds 甚至担心，在他们这批 Linux 内核维护者老去之后，很难再找到新的继任者，因为很多年轻开发者认为“Linux 内核项目并不那么有趣”。</p><p></p><p>STE 团队的负责人张宇深耕于系统技术领域多年，对此他也表示，“现在专注在底层基础软件、操作系统内核上的人才越来越匮乏，甚至出现了两种极端：一种是开发者的计算机基础非常扎实，底子好，但对内核研发并不感兴趣；一种是对内核非常感兴趣，但底子薄，需要补功课。同时具备这两方面优势的人才非常少。对于我们内核团队而言，年轻是我们的优势，正是这种对内核技术的痴迷和热爱，才让我们走到了一起。”</p><p></p><p>向团队中注入新鲜的血液并不难，难的是如何让这些年轻人在 Linux 内核方向愈战愈勇、愈走愈远。对此，张宇提到了两个字：激发。给年轻人平台，激发其兴趣；给年轻人机会，激发其斗志。“我们也有很多资深的开发者，但他们更倾向于把好的机会留给年轻人。这种‘传帮带’的传统，能够让年轻开发者有机会站到台前，越做越有信心。否则，如果年轻人持续得不到鼓励、不被激发，在这条艰辛的道路上就很难做出成绩、走得长远。”张宇提到。</p><p></p><p>正是在这种文化氛围的熏陶下，STE 内核团队依托于 Linux 内核，在虚拟化、云原生、eBPF 等技术方向都有非常硬核的输出。比如，2020 年 9 月，团队向 Linux 内核社区贡献了 HVO 方案，该方案能够解决 Linux 内核内存管理冗余这一难题。</p><p></p><h2>困扰业内数十年的 Linux 内核内存管理冗余，有了解法</h2><p></p><p></p><p>从 Linus Torvalds 在 1991 年发布第一版开始，<a href=\"https://www.infoq.cn/article/KYsy5BQysK7vtlPtgd0Y\">Linux 内核</a>\"迄今已发展了 30 余年。据称，第一版的 Linux 内核只有 10250 行代码，占用 65 KB，而如今，Linux 内核代码行数早已超过 2700 万。</p><p></p><p>Linux 内核每年新增 / 删除的代码多达百万行，也加入了越来越多优秀的特性。这样一个复杂且臃肿的工程，在不同的业务场景下，势必会面临各式各样的挑战。</p><p></p><p>支撑字节全量服务器运转的正是 Linux 操作系统。STE 内核团队发现，一些云计算的场景会带来额外的内存管理开销，随着服务器规模越来越大，这种损耗也会成倍放大。</p><p></p><p>“Linux 内核以页（一般 4 KB）为单位管理物理内存。每个 4 KB 页对应一个 struct page 结构体。使用一个 struct page 管理一个页，这本身没什么问题。但是当使用的页的大小是 2 MB 甚至 1 GB 时，Linux 依然以 4 KB 为单位分配 struct page，这显然是个内存浪费的行为。我的目的就是尽可能减少这部分冗余的内存管理开销。”说这话的是 STE 工程师宋牧春。2019 年 7 月，宋牧春加入字节 STE 内核团队，三年时间，宋牧春随团队一同成长，也完成了从 Linux 内核开发者到 Linux 内核维护者的转变，并成为 Linux 内核社区 HugeTLB 和 Memory Cgroup 两个核心子模块的 maintainer。</p><p></p><p>实际上，Linux 内核内存管理冗余并不是一个新问题，它在业内已存在十年之久。过去不少公司都做过研究，但始终没有找到解法。即便如此，STE 内核团队依然想做一些尝试。在不断地讨论、验证各种方案的可行性后，团队发现这个问题是有可能被解决的。</p><p></p><p>“某些场景会使用到大页，每个大页需要 8 个页的 struct page 去管理，即 8X4K 的内存，我们希望最终只占用一个页的物理内存（4KB）。对此，我们想的方案是复用，把后面 7 个虚拟地址映射到唯一的物理页，如果方案能成功落地，则意味着 1T 的服务器，最大能节省接近 16GB 的内存。即使优化 1%，整体给公司带来的收益也会非常大。”宋牧春说道。</p><p></p><p>这套方案被称作 <a href=\"https://www.kernel.org/doc/html/latest/mm/vmemmap_dedup.html\">HVO</a>\" (HugeTLB Vmemmap Optimization)。方案有了，下一步就是做代码调研。</p><p></p><p>Linux 内核管理是非常复杂且核心的一个模块，它和各个模块交织在一起，它的稳定性也必然会影响整个 Linux 内核的稳定性。因此，STE 内核团队需要尽可能地减少该方案代码涉及的范围，并确保不会影响系统里的其他功能。为此，从 2020 年 4 月到 2021 年 6 月，团队开始了长达一年时间的代码调研、开发、测试和重构。</p><p></p><p>用一年的时间，解决一个技术难题，值得吗？段熊春给出了肯定的回答。</p><p></p><p>“我们会衡量这件事情的价值，显然我们也面临着很多压力，但真正难的事情是需要投入更多时间去看的，我们也需要这样做。基于对技术的狂热，我们周末也经常聚在一起讨论和思考，再把这些想法带到实际场景中，更好的打磨和优化。这是一个长期的过程，而这些突破也能为公司和业界带来巨大的收入，这就是有价值的。”</p><p></p><p>同时，HVO 也得到了业界的广泛认可：华为、Google、AWS、甲骨文都准备将这个方案投入使用，还有公司向团队发来感谢信。“但这不是终点，我们会持续优化 HVO 方案。”段熊春说道。</p><p></p><h2>Linux 内核云原生技术新探索</h2><p></p><p></p><p>设备虚拟化技术作为云计算领域最重要的基础技术之一，多年来一直在稳步向前演进。其中，virtio 和 VFIO 在过去一直是最主流的设备虚拟化技术，并分别于 2008 年、2012 年被合入 Linux 内核主线。为了将 virtio 和 VFIO 的优势结合，2020 年，vDPA（Virtio Data Path Acceleration）技术框架被合入 Linux 内核主线。</p><p></p><p>与此同时，字节内部的云原生化进程也在进行着。</p><p></p><p>据了解，字节最早于 2016 年开始在内部推进云原生化进程，对业务进行大规模容器化改造。到 2021 年年末，字节已经有超过 95% 的应用实现了云原生化。在这个过程中，STE 内核团队发现，容器在一些 I/O 相关的解决方案中，与传统的虚拟化方案相比比较受限。“我们当时希望能够在 Linux 内核中提供一套框架，开发者可以基于这个框架去模拟各种各样的设备，并且能够直接供容器接入使用。这样，就进一步弥补了基于容器的云原生方案在 I/O 方面的短板，甚至还能够和相对成熟的虚拟化方案实现一定程度上的技术复用。”STE 工程师谢永吉对 InfoQ 说道。</p><p></p><p>于是，<a href=\"https://www.kernel.org/doc/html/latest/userspace-api/vduse.html\">VDUSE</a>\" 框架应运而生。通过 VDUSE，开发者可以在一个用户进程中实现一个软件定义的 vDPA 设备，并可以通过 vDPA 框架接入 virtio 或者 vhost 子系统，供容器或者虚机使用。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/29/2998c1fb9406b01960e56e18748c01db.png\" /></p><p></p><p>根据介绍，具体的实现原理上，VDUSE 设备是由 /dev/vduse/control 的ioctl(VDUSE_CREATE_DEV)创建的，通过这个 ioctl，用户空间可以为这个模拟设备指定一些基本配置，如设备名称（唯一标识 VDUSE设备）、virtio特性、virtio配置空间、virtqueues数量等等。然后，一个字符设备接口（/dev/vduse/$NAME）会被导出到用户空间用于设备模拟。用户空间可以在 /dev/vduse/$NAME 上使用 VDUSE_VQ_SETUP ioctl 来初始化每个 virtqueue 的配置，如 virtqueue 的最大长度等。</p><p></p><p>在初始化之后，VDUSE 设备可以通过 VDPA_CMD_DEV_NEW 这条 netlink 消息绑定到 vDPA 总线。之后，用户空间可以在 /dev/vduse/$NAME 上通过 read()/write() 来接收并回复来自 VDUSE 内核模块的一些控制请求，同时还可以通过 mmap() 映射一段共享内存，与内核相应的 virtio 驱动进行数据通信。</p><p></p><p>2020 年 10 月，STE 内核团队向 Linux 内核社区正式开源 VDUSE。经过一年时间，VDUSE 在 Linux 5.15 版本被正式合入。</p><p></p><p>“在计算存储分离的架构下，我们可以在计算节点通过 VDUSE 框架模拟各类存储设备供容器或虚机使用，这类存储设备的后端往往是远端的存储节点。现在，这套解决方案在字节的云原生场景已经开始大规模部署。后续，我们也将继续探索在云原生高性能网络场景上的应用可行性。”谢永吉说道。</p><p></p><p>Linux 内核始终在向前演进，在 STE 工程师邓良看来，“随着云原生应用场景不断扩大、硬件朝着高密度应用异构的机型上发展，对 Linux 内核提出了新的要求。内核是连接底层硬件和上层云原生应用的一个桥梁，我们也在思考，当前这种单一的宏内核是否合适，并且我们也在做一些探索。”</p><p></p><h2>拥抱社区，让技术产出更大的收益和价值</h2><p></p><p></p><p>如果说攻克技术难关靠的是技术硬实力，那么向社区推广并使其合入我们的代码，则要依靠足够多的耐心去沟通和布道。</p><p></p><p>在与社区沟通上，STE 内核团队也积累了自己的经验。</p><p></p><p>2020 年 9 月，当 HVO 第一个版本发到社区后，团队收到很多质疑的声音。“社区起初对我们的方案产生怀疑，我们需要先向社区证明这个方案没有问题。同时，社区也会提出一些针对性的问题，甚至有很多都是我们之前没有考虑过的场景。根据这些问题，我们再对方案进行迭代和维护。像 HVO，我们迭代了 20 多个版本，需要不断地向社区证明这个方案在不同场景的有效性，这个过程持续了很长的时间。”回忆 HVO 的社区之路，宋牧春觉得特别漫长。在他看来，社区需要考虑维护成本是否大于收益，这无可厚非，作为开发者和社区贡献者，要做的就是解释清楚技术方案能够产生的价值，让社区看到它带来的收益，并证明这个方案的可行性和稳定性。</p><p></p><p>在企业内部，一套技术方案从开发到应用，这个链路并不复杂。但面向社区，开发人员需要考虑的问题就会更多。“很多时候，我们要突破自有场景，去看社区里的其他场景和痛点，而这些很可能是我们从来没有遇到过的。”显然，拥抱社区的沟通成本会很高，但在段熊春看来，为社区贡献代码能够实现双赢，这都是值得的。</p><p></p><p>“现在我们的工作环境基本是模拟社区环境，工作模式也跟社区保持一致。这种标准化的作业模式能有效降低代码的维护成本，同时社区思维的开阔性，也为我们思考问题提供了更多的思路，进而为技术创造价值提供了更多的可能性。”</p><p></p><h2>走进“无人区”</h2><p></p><p></p><p>对于 STE 内核团队的愿景和目标，张宇用了三个“贴近”来描述：贴近业务，去了解业务的痛点；贴近社区，去了解社区的方向；贴近新硬件技术，在软硬协同设计上发挥内核更大价值。内核本身无法直接创造价值，更多是通过服务业务来创造价值。所以团队在做研发时，一定要想清楚对业务的收益是什么，它能否真正的解决业务痛点，进而创造业务价值。</p><p></p><p>STE 内核团队多年来一直深入社区。基于开源 Linux 操作系统，团队做了一些优化以满足企业内部的需求，反之，团队也会把这些好的特性回馈给社区，像前文提到的 HVO 和 VDUSE 都已被合入 Linux 内核主线。在张宇看来，STE 内核团队并不是要做一个标新立异的操作系统，更多的是源自技术初心，希望能够把自身的力量贡献给社区，交给 Linux，再不断引进。</p><p></p><p>张宇表示，STE 团队非常重视“务实”，这也是字节的核心价值观之一。“我们在做的事情都是围绕基础设施展开的，提高它的稳定性、优化性能等等，与公司内其他能直接创造收益的明星产品相比，我们是一个做减法的部门，通过技术手段降低基础设施成本，在业务链路里属于非常靠后的位置，就像足球场上的后卫一样，要能守住系统稳定性 / 可靠性的基本盘不出问题，又要能够往前场助攻进球。回到团队的愿景来看，我的想法比较简单务实，希望团队先满足业务的需求，再高于业务需求、先于业务需求，做一些引领业界的技术。就像一开始，我们是跟着社区，跟着业界领先者的路径去走，但随着我们技术能力不断提升以满足业务场景多样性的需求，再往前走，必将进入‘无人区’。”</p><p></p><p>进入“无人区”后，没有方向的指引，也没有参照物，这才是最考验团队能力和韧性的时候。“我希望团队有开拓精神，辨识出合理的方向并坚定的走下去，也许在过程中会有微调，但最后顶多画出来的路线是波浪线，而不是一条完全没有目标的曲线。”张宇说道。</p><p></p><h2>写在最后</h2><p></p><p></p><p>直到今天，团队对 HVO 的优化还在继续。2022 年 3 月，团队优化了 HVO 在 2 MB HugeTLB 的表现，与此前相比，它进一步将 2 MB HugeTLB 的 struct page 开销减少了 12.5%；2022 年 4 月，HVO 支持 ARM 64 架构；2022 年 5 月，HVO 支持运行时开关，不再束缚于 cmdline 的方式使能。</p><p></p><p>依托 Linux 内核，团队在虚拟化、云原生、eBPF 等技术方向上也在继续探索着。</p><p></p><p>“现在我们关注的比较多的场景，一个是云原生，这也是大家都在关注的方向，但当前并没有一个特别好的解决方案，甚至在云游戏的一些基础设施场景下，业界还没有形成一个标准；另一个就是软硬协同，用软件的方式定义硬件，用硬件的方式来定义软件。目前我们也围绕这些方向在做一些研究。”张宇认为，“如果团队一直在做一些重复的事情，是没有激情与战斗力的，对团队的期待还是要在满足业务需求之上，去做一些引领业界的事情。”</p><p></p><p>在张宇看来，做操作系统这类基础软件不是一时热情，是需要长期投入的。大浪淘沙沙去尽，沙尽之时见真金。“目前国内外大厂也都在围绕自己的业务场景做软硬一体的事情，涉及基础系统软件、芯片板卡服务器之类的硬件研发。在做的同时也要上升到社会责任感的层面上来看，能贡献多少力量。这些都是需要持续思考的。”</p><p></p><h4>嘉宾介绍：</h4><p></p><p></p><p>张宇，字节跳动 STE 团队负责人</p><p>段熊春，字节跳动 STE 内核团队负责人</p><p>宋牧春，字节跳动 STE 工程师、Linux 内核社区 HugeTLB 和 Memory Cgroup 两个核心子模块的 maintainer</p><p>谢永吉，字节跳动 STE 工程师</p><p>邓良，字节跳动 STE 工程师</p><p></p>",
    "publish_time": "2022-11-18 10:53:18",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Alphabet股东呼吁谷歌“砍掉”数千人，称支付给员工的薪水过高",
    "url": "https://www.infoq.cn/article/r8CLWdrPO9uFWNWz7kiq",
    "summary": "<p>当地时间11月17日，维权投资者TCI基金管理公司呼吁 Alphabet 裁员数千人，并减少长期投资支出。这家公司还表示，谷歌母公司支付给员工的薪酬过高。</p><p>&nbsp;</p><p>TCI 表示，“随着收入增长放缓，现在需要成本控制。”</p><p>&nbsp;</p><p>这家投资机构还声称，它曾与 <a href=\"https://mp.weixin.qq.com/s?__biz=MzIzNjUxMzk2NQ==&amp;mid=2247517674&amp;idx=1&amp;sn=98edafdf5dd6ec04a0db9e0437478768&amp;chksm=e8d47a28dfa3f33ec6dfd7a63169b04a2198e988577b09e9907055840ad834eb3209bbda2525&amp;scene=27#wechat_redirect\">Alphabet </a>\"的前高管交谈过，他们建议：“谷歌的业务可以用更少的员工更有效地运营。”</p><p>&nbsp;</p><p>今年9 月，<a href=\"https://www.infoq.cn/article/76gYqPA2YU0YXCDHFvIE\">谷歌</a>\"和 Alphabet 首席执行官桑达尔·皮查伊（Sundar Pichai）表示，他希望让公司提效20%，为了达到这一目标，他可能会进行裁员，但更多的还是让公司减少官僚作风，更加灵活。</p><p>&nbsp;</p><p>TCI 认为皮查伊的这些评论纯粹指的是裁员，并补充说“我们完全同意”。TCI指出了Meta、亚马逊、微软、Salesforce、Stripe 和Twitter都经历了大幅度裁员。</p><p>&nbsp;</p><p>TCI 还指出，“Alphabet 支付的薪水在硅谷名列前茅”，高于微软和 20 家最大的上市科技公司。</p><p>&nbsp;</p><p>TCI 建议大幅削减的另一个领域是谷歌的“其他投资”部门，该部门涵盖非核心业务和登月业务。在经历了 200 亿美元的运营亏损和 30 亿美元的收入后，TCI 表示其他投资的资金应该“至少削减 50%”。</p><p>&nbsp;</p><p>特别是，TCI 还挑出了<a href=\"https://www.infoq.cn/article/WBXif1YYls8QmjCZ3fCw\"> Waymo</a>\"这个“天坑”。“不幸的是，自动驾驶汽车的热情已经崩溃，竞争对手已经退出市场......如果Waymo不再继续挣扎，那么损失应该可以大幅减少。”</p><p>&nbsp;</p><p>TCI 只是顺便提及了谷歌云部门的亏损，称该部门尚未盈利。</p><p>&nbsp;</p><p>上个季度，谷歌云报告的收入为 68.6 亿美元，高于 2021 年的 49.9 亿美元。但其亏损略有扩大，从 6.44 亿美元增至 6.99 亿美元。</p><p>&nbsp;</p>",
    "publish_time": "2022-11-18 11:04:39",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "华为云官网 Web3D 和动效技术的应用与探索",
    "url": "https://www.infoq.cn/article/qDTC0goYFc17UAoRoNTZ",
    "summary": "<p>演讲嘉宾 | 杨鹏军</p><p></p><p>整理 | 王玉玉</p><p></p><p>编辑 | 蔡芳芳</p><p></p><p>华为云官网是华为云的门户页面，对于页面的视觉与交互体验有较高的要求，结合华为云官网动态、强拟物、3D 影像等主流设计风格，我们在 Web 页面上使用了包含 js 动效、<a href=\"https://xie.infoq.cn/article/511aa64f69530ed3061829351\">WebGL</a>\"、WebGPU 等多种 Web 动效技术，极大地提升了门户页面的视觉与交互体验效果。</p><p></p><p>本文整理自华为云前端工程师杨鹏军在<a href=\"https://qcon.infoq.cn/2022/guangzhou/\"> QCon 2022 广州站</a>\"的演讲分享，主题为“<a href=\"https://qcon.infoq.cn/2022/guangzhou/presentation/4836\">华为云官网 Web3D 和动效技术的应用与探索</a>\"\"。</p><p></p><p>这次分享主要分四个部分，分别是背景介绍、动效平台的构建和 Web3D 技术的应用实践、总结展望。</p><p></p><h3>背景介绍</h3><p></p><p></p><p>我们希望能实现目前比较流行的一些概念，比如大家在苹果官网产品页看到的炫酷动效，商超的裸眼 3D 屏幕，再比如一些厂家做的数字孪生能力，以及经常冒出头的 VR、AR 的概念。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a9/a99a9a60578209ff196479deb0d5aa16.png\" /></p><p></p><p>在华为云内部，我们最近几年也需要实现一些真实的 3D 场景光影，符合物理运动规律的动效，以及符合用户直觉的交互方式。华为云的官网是面向 Web 用户的，更倾向于构建一些体验上的能力。从开发角度来说，前端动效，在整个前端技术里面属于比较小的分支，大家开发的时候并不是非常重视，我们没有实现统一的动效能力。随着近期设计的要求量增多，我们逐渐开始意识到，前端需要去构建<a href=\"https://xie.infoq.cn/article/a01bed4ce97239c238dc94190\"> Web3D</a>\" 的能力，要做一些技术沉淀。我们需要 3D 能力来展示华为云内部的监控页面、展示看板，以及看板上的复杂数据交互等内容。受限于二维层面无法清晰呈现数据节点间的复杂关系，我们需要再加一个层级，拓宽到三维的空间，提高呈现效果。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e4/e492b094e982135b467dc2efa628c241.png\" /></p><p></p><h3>动效应用</h3><p></p><p></p><h4>前端动效基本概念</h4><p></p><p></p><p>基于这个背景，华为云前端开发团队做了动态能力的构建。为了方便后续理解，我先简述几个基本概念。前端开发人员应该都比较清楚，动效基本上分为四种，CSS 动效、JS 动效、多媒体、SVG 动效。从我的角度来说，最简单的就是 CSS 动效，可以通过 Transition、Transform 或者 Animation 属性去做一些过渡效果，或者一些帧动画。JS 动效用得比较多，像华为官网的一些场景用的 scroll，就是监听用户的 scroll 事件，然后更新页面上的 Dom，也有围绕 requestAnimationFrame 全局函数去做的一些实现。多媒体用得也比较多，但它缺乏交互性，主要就是视频、gif。为了性能考虑，可以把 gif 换成 apng，或者 Webp 这种性能更高、体验效果更好的图片格式。这些和开发关系不大，开发考虑的是做一些视频、图片上的性能优化问题。最后是 SVG 动效。我认为 SVG 动效主要是做一些单独的动画，跟我们官网契合度不高。华为用的主要是 CSS 动效和 JS 动效，所以对这两个能力做了一些封装。</p><p></p><h3>通用前端动效插件封装</h3><p></p><p></p><p>CSS 动效和我们平常开发组件差不多，封装一些底层的 less 或 Mixin，在定义这些变量的基础上做动效封装。比如在一些渐变、旋转平移等场景，以及更上层的动效，例如如下图所示的华为线，各种元素悬浮的微动效，以及背景放缩等。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ef/efc00a8a02e586b7ed3aed204e0d6ade.png\" /></p><p></p><p>接下来介绍 JS 通用动效的封装。JS 通用动效的封装是围绕 requestAnimationFrame 建立最基本的底层能力。因为 requestAnimationFrame 它的调用方式跟 setTimeout 与 setInterval 不太一致，setInstance 和 setTimeout 是让用户去指定间隔的时间，跟屏幕的刷新率不太匹配。而 requestAnimationFrame 函数是在每次页面刷新的时候去调用传进去回调函数。我们是基于 requestAnimationFrame 传进来的默认参数（时间戳），计算两个时间戳之间的 costTime，再去做整个进度里面的时间占比，更新动画实例的状态。我们之前需要做很多额外工作才能实现这个简单的机制。比如要做的动画实例、动画对象不是简单的 Dom，有的时候还要去更新页面上的标签，更新 3D 物体 material 属性中的 Color，或者 position 属性里面的坐标，而这些对于底层插件来说都是不同的输入，需要做解析函数。前面提到，设计要求动效符合运动规律，就需要定义一些动效曲线。比如 ease-in 、ease-out 等不同类型的运动规律曲线。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/6a/6a2ad9488b4a90e028e35a545f260903.png\" /></p><p></p><p>完成上述两种动效封装后我们已经可以实现很多种动效方式了。一般动效可以设置动画指令的初始值，再设置它的结束时间。你还可以指定延时、动效曲线的变换方式。这个通用的动效应用能够做一些常用的数字动画、导航，锚点定位，以及帧动画。</p><p></p><p>我们内部之前都是各自独立开发各自的功效的。这个动画组件发布后内部开发就可以直接接入使用了。我们基于这两个底层能力，还做了一些更复杂的封装。比如下图的这个模拟的 3D 鼠标跟随效果，其实不是用 3D 做的，而是用底层的帧动画去做的。监听鼠标运动在屏幕区域位置去对整个图形做上下定位，中间再加一个过渡效果，就可以实现模拟 3D 空间的鼠标跟随效果。这个动画组件还可以呈现苹果官网上常见的视差动画，就是大家去滚动页面的时候，各种不同的 Dom 去做视差平移，实现错位的效果。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/13/13e9a5396822337bed7e7bb76f949b5f.png\" /></p><p></p><p>我们做这个组件的目的是统一内部的动效能力。之前大家开发的时候会去使用各种不同的动效插件。把这个底层能力封装后，实现各自的动效会节省很多工作量。基于这个底层封装，大家还可以再在上层封装自己的动效应用。这有两种实现方式，一个在动效平台上做个表单，让大家手动去填。另一种是接入到内部的 Devops 平台，在发布的结点上注册一个钩子函数，钩子函数在发布时会调这个组件，把它内部的 Readme.md，或是 package.json 里的配置信息通过接口传到动画平台的数据库里面，平台会把组件信息展示出来。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/52/52c8b8d79d8a4d8dfbbc368c35a2bb04.png\" /></p><p></p><p>有了这个平台后，我们用它建立了大概 30~40 个基础 / 上层的动效应用，官网目前有 200 多万个页面用到了这个动效组件通用能力，大概占到一半以上了。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/68/68f6d091fa95f837a5c336dd645d014e.png\" /></p><p></p><h3>Web3D 技术的探索与应用</h3><p></p><p></p><p>Web3D 应用与动效组件的关联性不大，但 Web3D 里的动效使用了一些动效平台的通用插件。</p><p></p><p>在背景介绍里我们说了业务上的痛点，对于 Web 来说，全球的云服务布局，对外展示的一些解决方案的展厅，用 3D 的效果实现体验会更好。内部的接口调用链、全球性能监控，以及整个组网里面各种网云的可用性监控，定单的数据流走向，也可以用 3D 数据可视化提升使用体验。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/bb/bb5b54d45357817f0c248a73518ecf01.png\" /></p><p></p><p>需求确认之后，接下来就是技术选型。我们查了市面上大家用得比较多的一些 3D 能力库，第一个 High &nbsp;topo。High &nbsp;topo 相对来说功能比较强大，比 three.js 封装做得好，它把一些效果，比如文字标签、后期粒子光效等都已经封装好了，不需要自己再做；但是它不好的地方就是不开源，社区太封闭了，想要做一些更上层的封装就比较难。ECharts 也比较简单易用，但灵活性扩展性比较差，而我们需要做一些自己定制化的东西。three.js 上手难度稍微高一点，但是社区非常活跃，可以找到很多不同的效果，遇到问题，去网站搜一搜，大部分都能解决。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/1b/1b68b5d2406b2d98730cfeadfde8aca1.png\" /></p><p></p><p>我们研发工作流很简单，设计和产品去画原形图，提供给我们面板的设计稿，如果有复杂的模型，就输出 GLTF 格式的模型，或者是 obj 格式的模型。模型导入后需要对材质信息调优、完成底层 3D 场景，元素构建。效果做完之后就是数据通用配置化工作。之后借助内部的平台把 3D 数据图表的通用插件发布出来，让各个业务去对接。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e1/e1faff5e055e8d123445b9a0984c6815.png\" /></p><p></p><p>这里重点介绍开发的工作。如图所示，three.js 提供一些底层的场景。最基础的点、线、面元素一定要有，还有就是辅助元素。接下来是交互方法的封装。最上层实现一些动效、特效，提高视觉体验。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/95/9526f41855cbda30275e2478debc2c42.png\" /></p><p></p><p>基本元素点、线、面的开发占用了我们大量时间。它不像写前端代码，做一些标签就行。节点（node）的展示形式非常多，除了通过 three.js 提供的 API 去画一些基本的 3D 元素外，还需要根据自己的展示做一些组合，或者通过 group 统一控制。node 有时候会比较复杂，自己画图形很难实现，这部分需要去跟设计师沟通，请设计师输出各种不同格式的 Model。如果不强求节点在页面的三维空间属性，为了性能也可以用 HTML DOM 去做。edge 就是根据图里是否带流量，或者根据粗细做不同的实现。如果没有粗细限制，就直接调 three.js 的 Line 函数实现。根据它是实线还是虚线，使用 material shader 自定义样式。如果是有粗细要求，就用管道去做。面的实现方式很简单，目前识别的有网格、平面和球面。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/8d/8d9bd191e149cc28a6baaa35fa32bf34.png\" /></p><p></p><p>辅助元素开发也很花时间，主要是标签文字。我们不建议用 TextGeometry 实现标签文字，因为国内需要展示的一般都是中文文字，中文转换成 3D 几何体在页面上渲染，会有非常多的网格和面片。中文我们要么通过 Canvas 模拟，要么直接用 HTML DOM。一般只有在比较大的面板上，需要显示有质感的英文标签时，才会用 TextGeometry。Canvas 是把文字作为纹理贴图，画到 3D 元素属性上面。我们基于文字的一些基本属性做了一些封装，把文字背景色、边框、颜色、字体大小，统一封装到 planeText、SpriteText 类里面。辅助面板是整个 3D 界面里底部的操作提示。点击某个节点会显示一些辅助说明文字，基本上用 HTML 就能解决，这里不再赘述。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b7/b7b8d70014b747a2a49bfa3fc9af7205.png\" /></p><p></p><p>接下来讲交互。交互的原理是监听 camera 和鼠标放在屏幕上面的位置，中间发出一条射线，Raycaster 监听射线和 3D 场景里 Object 的交点，把焦点里面的物体全部存储起来，之后可以为 Object 绑定各种不同的事件。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3b/3b79324ca91e87702aa3752d103fc6eb.png\" /></p><p></p><p>接下来讲特效和动效的封装。动效主要是摄像机动画和元素动画。摄像机动画我们用了 GitHub 上比较常用的插件 CameraControl，它比 three.js 的 OrbitControl 提供的动画效果更好，可以呈现阻尼变化效果，在视角切换的时候也更加顺滑。元素动画总结起来就是一些贴图动画，用 canvas 可以实现动态纹理，更新 Mesh 属性也能实现一些动画。有一些效果我们会使用自定义的 Material 去做，定义它的顶点着色器和片段着色器，通过修改 JS 里的 Time 属性，跟顶点位置绑定做着色渲染。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/25/25900e0a0aa94e48d769e8b75de32d9d.png\" /></p><p></p><p>下面分享我们的两个实践。第一个就是全球布局。一开始它就是个 Table，设计师要求用三维空间的球体去展示它。归结到底层其实就是点、线、面的能力。如下面 2 张图所示。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7a/7ac4a58129b11febc30221956af5b429.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e9/e90205ab78d416272ed25de9c65e8330.png\" /></p><p></p><p>页面的功能主要包括标签点定位、2G、3G 切换和视角聚焦。这里的技术重点是球体表面的标签定位，还有 HTML DOM 显示和隐藏的处理。定位的问题就是，因为运营人员给到的是城市的经纬度信息，无法提供出球体上面三维空间里的 position。这需要我们去建立经纬度辅助器，把经纬度转换成三维空间上面的 position，然后再通过矩阵变换器定位到三维空间里。这里还涉及文字选型的问题。之前也说到，文字样式比较复杂，需要呈现悬浮动效。内容变更用三维方式去写会比较麻烦，所以我们就把它做成 HTML Dom。但是 HTML Dom 就带来一个问题，标签元素如何隐藏。我们需要把标签的 Z 轴坐标映射成 HTML 里的 CSS z-index 值，Z 轴坐标越靠近前面它的 z-index 值就越高。标签在球体上面转动时，要确定它是否被球体盖住。因为球体是三维的，但是 HTML 是二维的，两边本质上来说是互不影响的，如果不去做处理，球体转到后面，HTML 标签是能够被看到的。看下面的示意图，我们监听 dom 和球体中心的边以及 dom 和摄像机的边的夹角，如果小于 90 度就隐藏 dom。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/86/86b0c6b9c69a2ee6f1206371fc473dd7.png\" /></p><p></p><p>这个实践还用在了官网和其他一些内部页面。因为这个 3D 地球在华为内部应用很广，很多页面都有用到，所以我们就做了通用性封装。比如通过不同贴图去表示一些主题，并且做了多端的兼容，还为标签单独做了配置化。</p><p></p><p>另一个实践应用是内部数据流监控。这个监控原来是用数据流图表示的。如果只是几个节点还好，但是应用到具体的业务里面，数据流的节点非常多，可能有几百个节点。每个节点里面是一个实例，下面还有一些子节点。在主流程上面点击子节点，子节点再跳到子流程，这样体验上就会有割裂感。于是我们对这个图表进行了 3D 化改造。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/de/de55216e184658e2c60ca5c985771788.png\" /></p><p></p><p>如下图所示，左边是整体布局的监控图，右边是每个云服务内部的一些具体流程。运维人员在看主流程的监控时，如果碰到某个云服务故障，就在界面上通过光学效果或数据流走向标注出来。点击节点可以进入下一个层级。子流程可以通过点击收起或展开。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/de/de55216e184658e2c60ca5c985771788.png\" /></p><p></p><p>数据流监控比 3D 地球用的模型要多，因为设计和产品要求这个 3D 的模型需要一些流化处理，所以我们还做了效果调优，包括通过 canvas 的动态纹理实现玻璃、辉光和能量球等高质量的 3D 材质效果。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/50/50bb4d661f8aab1ca11979bb0ea9bbf9.png\" /></p><p></p><p>材质主要是实现金属效果和玻璃效果。之前教导版本的 three.js 没有开放 MeshPhysicalMaterial 的 transmission 属性，要通过构建 shader 去实现。新版本的 three.js 提供了修改玻璃属性的函数后，就可以调整 transmission、thickness 属性设置透光度、反射度。金属材质可以通过调整表面的粗糙度，加上光照的环境贴图来实现更加逼真的效果。</p><p></p><h4>性能优化</h4><p></p><p></p><p>我们在性能优化的过程中也做了很多工作。如下图所示，图里有很多类似的云服务的节点，需要做一些网格的组合和 Mesh 克隆。我们建议尽量少去加载 obj 或 fbx 文件模型文件，推荐统一都用 GLTF 格式模型载入。实际的场景区分文字实现，其中部分面板文字用了 TextGeometry，其他大部分文字是用 HTML Dom 和 SpriteText 做的。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d5/d568cee1f88a03f8dceb4f66606b245e.png\" /></p><p></p><p>接下来具体讲讲大数据量对象渲染的优化。优化是一个渐进的过程。一开始，我们把网格用 Group 组合在一起，但每个 Group 都是单独渲染的。节点数量变多的时候，整体帧数就降低了，节点一多就变得非常卡。后面我们采用了网格组合方式，虽然性能提升了，但也有问题，因为它不是分片渲染的，所以材质都是一样的。我们的 3D 物体需要一些点缀性的装饰物，有不同的颜色等。虽然材质没办法改变，但是可以通过顶点转换的方式设置颜色，用 position 设置对应的颜色属性。</p><p></p><p>下面介绍关于资源的释放问题。在 3D 物体里面，包括几何体、纹理、材质都可以通过 dispose 方法把资源释放出去。我们不能每次想要释放资源的时候，都手动去 dispose，所以就做了资源跟踪类 ResourceTracker，类里封装了一些方法。在声明 three.js 对象时，把它用类提供的方法包一层，把资源注册到追踪器里。在需要释放整个场景时，统一调用追踪器的 dispose 方法。它做了两个方法，一个是把资源从场景中移除，另一个是一次性释放所有资源。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5a/5ae2103700a91a7f76fe613faeac35b6.png\" /></p><p></p><h3>总结</h3><p></p><p></p><p>最后是总结展望。第一点是技术沉淀和平台的重要性。我们一开始做能力构建时，并没有做那么多底层的东西，只是完成一些单一的设计要求。做得多了之后发现很多东西是可以去复用的，包括动效的一些能力。我们的 3D 图表就是点、线、面，对应一些贴图动效的结合。需求来了后，先根据业务去实现它，然后再去做技术去封装。除了这个之外，我们在 AR、VR，还有 WebGPU 上面也做了一些简单的探索。但目前业务应用的还不是特别广泛。</p><p></p><p>AR 在内部做了简单的探索，能够扫描地板，检测出地板的平面，完后在手机的屏幕上添加一些 3D 的模型。和华为云业务结合起来的场景是在大促活动里面，让用户去扫描一些能够识别的物体，完后领取促销品等。我们的 VR 从能力上来说不能算真实的 VR，它是基于第一人称视角用 VR 场景模拟了战机看板，也只是内部的一些实验性探索，用在了我们内部的一些看板的登录界面上面。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ba/ba9224c755d4c05e4ddc83667ab73b11.png\" /></p><p></p><p>WebGPU 是我们下一代要用来渲染浏览器 3D 场景的一个 API，比 WebGL 的性能好很多，目前在浏览器的某些实验版本上可以用。我们下载了一个 Google &nbsp;Chrome 的 Canaries 版本（金丝雀版本），它的某个实验标签可以开启 WebGPU。开启后就可以跑 three.js，three.js 已经封装了一些 WebGPU 能力，可以通过 three.js 实现 WebGPU 场景。根据谷歌开发者文档所述，这个功能可能在 2023 年或 2025 年才会开放出来，技术会持续更迭，我们要紧跟潮流。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d0/d0836755ff48e21eb028a8995fe6a8cf.png\" /></p><p></p><p>以上就是分享的全部内容。</p><p></p><p>演讲嘉宾介绍</p><p></p><p>杨鹏军，华为云官网前端工程师，毕业于东南大学，2018 年加入华为云，负责华为云官网首页及公共组件等的开发，多次主导华为云官网整体设计改版的开发工作，提升官网整体视觉与交互体验，对前端动效、Web3D 及前端性能优化有较深入的研究。</p>",
    "publish_time": "2022-11-18 12:35:40",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "微软低代码技术介绍及实战分享",
    "url": "https://www.infoq.cn/article/3C81NDRjPAF5rlZf3xwv",
    "summary": "<h2>直播介绍</h2>\n<p>低代码是近几年一直都很火的数字化管理模式之一，但我大多数的企业、开发者以及业务人员，对于如何应用低代码还比较陌生。</p>\n<p>如果你想要了解低代码产品到底如何用？它到底能在实际的应用场景中解决什么问题？本次直播邀请到了微软MVP讲师，北京金帆树人科技有限公司技术总监李琪老师，给大家分享低代码有关的内容。</p>",
    "publish_time": "2022-11-18 12:38:03",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]