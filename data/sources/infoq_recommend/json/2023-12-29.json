[
  {
    "title": "英伟达发布中国特供版RTX 4090D：砍掉部分核心功能后，速度降低11%，性能只差5%",
    "url": "https://www.infoq.cn/article/c7WgP4xIsU9YNAlM7U66",
    "summary": "<p></p><blockquote>受美国今年 10 月份颁布的最新限令影响，一夜之间，英伟达顶级旗舰显卡 RTX 4090 全面下架。如今，事情似乎有了转机。</blockquote><p></p><p></p><h2>英伟达发布中国特供版RTX 4090D</h2><p></p><p>&nbsp;</p><p>12 月 28 日，英伟达中文网站上线了一款名为 RTX 4090D 的显卡，这是英伟达顶级旗舰显卡 RTX 4090 的低性能版本，可以在不违背美国最新出口管制规定的前提下，出口中国。据悉，字母“D”意为 Dragon，代表 2024 年农历龙年。该显卡将于明年 1 月正式上市。</p><p>&nbsp;</p><p>与&nbsp;RTX 4090 相比，RTX 4090D 性能降低约 10.94%，具体差异为核心数量较少、共 14592 个 CUDA 核心，低于中国境外销售的 16384 核心版本。</p><p>&nbsp;</p><p>英伟达日前在采访中表示，4090D 这张 GPU 的张量核心数也有类似幅度的削减，从 512 个减少至 456 个。除此之外，其他设计基本没有变化，峰值时钟速率仍为 2.52 GHz、内存为 24 GB GDDR6x，内存总线也继续保持 384 位。</p><p>&nbsp;</p><p>尽管有所“阉割”，英伟达坚称这款显卡的性能并没有受到太大影响。</p><p>&nbsp;</p><p>英伟达公司一位发言人在邮件采访中表示，“在启用光线追踪和深度学习超采样（DLSS）的 4K 分辨率游戏当中，GeForce RTX 4090D 的性能只比 GeFOrce RTX 4090 低 5% 左右，而且运行方式与全系 GeForce GPU 没有区别，所以最终用户仍可进行超频。”</p><p>&nbsp;</p><p>这已经不是英伟达第一次为了遵守美国出口管制条例而主动削弱显卡性能。2022 年底，在限制对中国 AI 加速器销售风波之后，这家美国芯片巨头就降低了广受欢迎的 A100&nbsp;GPU 的互连速度，由此衍生出的新版本被命名为 A800。下一代 H100 也有同样的低性能版本，预计将定名为 H800。</p><p>&nbsp;</p><p>英伟达的举动也很快引起了美国商务部长 Gina Raimondo 的注意，她警告各芯片制造商不要触碰禁令的底线。“我可以告诉大家，如果你们沿着划定的边界重新设计芯片、让这些产品用于 AI 场景，那我第二天就会收紧控制。”</p><p>&nbsp;</p><p>Raimondo 随后向路透社解释称，美国商务部正在与英伟达密切合作，确保不会把可能对美国国家安全构成威胁的 GPU 和 AI 加速器出售给中国。当然，这家芯片大厂可以、也应该获准在中国开展正常业务。</p><p></p><h2>受“新限令”影响，RTX 4090 曾全面下架</h2><p></p><p>&nbsp;</p><p>此前，出口到中国的GPU 和 AI 加速器的主要性能上限，体现在互连带宽之上——也就是处理器之间相互通信的速度。2022 年 10 月，美国商务部工业和安全局（BIS）公布对中国出口管制新规，主要针对先进芯片和芯片制造设备领域，限制了双向互连带宽为 600 GB/秒芯片的出口，规格在此之下的 GPU 无需额外申请许可。</p><p>&nbsp;</p><p>作为回应，英伟达和英特尔都调整了自家最新 GPU，主动下调互连速度以回避美国商务部的限制。比如 H800 就是典型的特供版本。</p><p>&nbsp;</p><p>2023 年 10 月 17 日，拜登政府更进一步，对性能密度采取了新一轮管控政策。据悉，<a href=\"https://www.infoq.cn/article/QJ73po4wuwTvLKcpK1Fw?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">新的政策</a>\"将限制 Nvidia A800 和 H800 芯片的出口，此外，新规将豁免笔记本电脑、智能手机和游戏设备中使用的大多数消费级芯片，但其中部分芯片仍须受到美国官员的批准和专项管控。相关规定将在未来 30 天内生效。</p><p>&nbsp;</p><p>根据商务部工业和安全局（BIS）提交的文件，新规则第一条、也是其中最重要的条款，限制了以下产品的对中出口：</p><p>&nbsp;</p><p>“拥有一个或多个数字处理单元，且具备以下任一特征的集成电路产品：（1）「总处理性能」（TPP）为 4800 或者以上；或者（2）「总处理性能」为 1600 或更高，且「性能密度」为 5.92 或以上。”</p><p>&nbsp;</p><p>其实 GPU 和加速器的总处理性能（TPP）分数计算非常简单。只需要将设备的每秒密集万亿次运算（浮点或整数）的最大数字加倍，再乘以运算的位长度。对于涉及不同精度的多项性能指标（例如 INT4、FP8、FP16 和 FP32 等），则使用最高 TPP 得分。</p><p>&nbsp;</p><p>受这一新规影响，<a href=\"https://www.infoq.cn/article/0AbAmTSduzAuVFFu29Nq?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">RTX 4090</a>\" 成为唯一一款被禁止在中国销售的消费级显卡产品。</p><p>&nbsp;</p><p>据悉，RTX 4090 的总处理性能（TPP）超过了 4800，略高于规定的消费级显卡性能上限。所谓 4800，是指先将 GPU 每秒所能运行的最大万亿次运算数字（浮点或整数运算）加倍，再乘以运算的位长度。</p><p>&nbsp;</p><p>初版 4090 的 TPP 性能为 5285，也就是说英伟达必须获得美国政府颁发的许可证才能在中国合法销售这款高人气游戏显卡。需要注意的是，消费级显卡不受性能密度指标的限制，这项指标主要用于约束英伟达 L4 等性能较弱的数据中心用显卡的销售活动。</p><p>&nbsp;</p><p>一时间，在京东搜索 “RTX 4090 显卡”只有少数第三方售卖，但需要预约等待到货。 同样，在淘宝搜索也是如此，标注价格基本 2 万起步，最高甚至接近 4 万元。而在二手平台咸鱼上，RTX4090 售价基本 1.2 万起步。华硕、微星、影驰等英伟达合作商也同样纷纷下架该型号的非公显卡，官方旗舰店均已显示无货状态。</p><p>&nbsp;</p><p>对于“新限令”，英伟达方面曾回应称：“我们遵守所有适用的法规，同时努力提供支持不同行业的数千种应用产品。鉴于全球对我们产品的需求，我们预计（新规）短期内不会对我们的财务业绩产生实质性的影响。”</p><p></p><h2>受影响的不只有英伟达</h2><p></p><p>&nbsp;</p><p>虽然作为 AI 芯片市场上份额占比最高的巨头，英伟达肯定会首当其冲受到此项新规的影响，但英特尔和 AMD 的情况恐怕也好不到哪里去。</p><p>&nbsp;</p><p>虽然 AMD 当前的最高规格 GPU MI250X 已经受到去年出口政策的限制，但 MI210 从技术角度讲其实低于 600 GB/秒的带宽限制。不过根据估算，该卡的 TPP 得分为 5792、功率密度为 8，所以随着新规的出台生效，MI210 恐怕也将告别中国市场。不过，AMD 曾公开表示他们正在开发一款类似于英伟达 A800 和 H800 的特殊加速器，专门面向中国销售。</p><p>&nbsp;</p><p>来自 TrendForce 的行业观察师们表示，这些规定可能会抑制中国市场对英伟达高端 AI 服务器的需求，导致其全球需求份额从目前的 5% 到 6% 降低至 3% 到 4%。此外，TrendForce 预计字节跳动、百度、阿里巴巴和腾讯等大型 Web 和云服务商将在新规生效之前积极储备 GPU 资源。TrendForce 在一份研究报告中表示，“英伟达可能也会努力将当前稀缺的资源（例如 H800）优先交付给中国客户。”</p><p>&nbsp;</p><p>从长远来看，TrendForce 预计中国企业将加快芯片自主研发力度，目前阿里巴巴打造的平头哥 ASIC 和华为投资的昇腾计算平台就是典型案例。与此同时，分析师们认为中国企业还可能调整 AI 开发思路，转而租用服务商提供的资源。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.theregister.com/2023/12/28/nvidia_4090_returns_to_china/\">https://www.theregister.com/2023/12/28/nvidia_4090_returns_to_china/</a>\"</p><p><a href=\"https://www.infoq.cn/article/QJ73po4wuwTvLKcpK1Fw?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">https://www.infoq.cn/article/QJ73po4wuwTvLKcpK1Fw?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search</a>\"</p><p><a href=\"https://www.infoq.cn/article/0AbAmTSduzAuVFFu29Nq?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">https://www.infoq.cn/article/0AbAmTSduzAuVFFu29Nq?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search</a>\"</p><p>&nbsp;</p>",
    "publish_time": "2023-12-29 15:14:11",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "打造数字化核心引擎，中国移动磐维数据库 2.0 重磅发布",
    "url": "https://www.infoq.cn/article/hg5meweaWrM7rBsgXUFE",
    "summary": "<p>12 月 28 日，在 openGauss Summit 2023 大会上，中国移动磐维数据库 2.0 版本重磅发布。中国移动信息技术中心副总经理陈国在大会主论坛发表题为《依托磐维数据基石，共谋自主创新之路》的演讲，全面介绍了磐维数据库领先的产品特性、专业的服务体系和完善的产品生态。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fd/fd0924d57de771368a1e0088d47169cb.png\" /></p><p></p><p>据陈国介绍，磐维数据库 2.0 是中国移动基于国内开源数据库 openGauss 打造的面向 ICT 基础设施的自研数据库产品，具有高性能、高可靠、高安全、高兼容等特点，能够为集中式、分布式、云原生、一体机等多种应用场景提供强大支撑。通过融合 AI 能力智能运维，磐维数据库 2.0 的效能显著提升，部分能力已达到业界领先水平。</p><p></p><p>在产品特性方面，磐维数据库 2.0 版本结合了 AI 智能强化学习与循环神经网络，在性能上较上一版本提升 30%，存储空间的预测准确率提升至 90% 以上；通过结合线程并发控制算法关键技术，每分钟在线事务处理数突破 170 万个。</p><p></p><p>在服务体系方面，磐维数据库在部署交付过程中提供自动化、流程化的解决方案，实现一键式数据迁移，数据迁移速率达到 300M/S，校验速率超过 150M/S，达到业界领先水平。</p><p></p><p>在配套生态方面，磐维数据库引入专属的图形化数据迁移平台和运维管理平台，采用自动巡检与告警策略，提前识别风险，进一步增强数据库的易用性和可观测性，有效解决客户业务迁移困难、运维效率低、硬件资源浪费等痛点。</p><p></p><p>目前，磐维数据库已部署应用到中国移动 20 个省（区、市）公司及专业公司，覆盖 125 个业务系统，累计完成超过 1000 个节点的交付。</p><p></p><p>未来，磐维数据库计划在云原生、Serverless、智能运维、生态兼容等方面持续做强深度自主研发，进一步打造面向全行业的数据管理解决方案。</p>",
    "publish_time": "2023-12-29 16:15:30",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "一个不会画画的我遇到AI绘画的时代",
    "url": "https://www.infoq.cn/article/b93d248d8bc3e267a746ea2ac",
    "summary": "<p></p><h2>AI 绘画的时代</h2><p></p><p>大家好，我是小包。</p><p></p><p>我是没有艺术细胞的，这点我从很小就切实的感受到了，我不会画画，不会唱歌，我便是艺术的荒漠。童年是那么的梦幻，那么的值得渴望，谁不想亲自用自己的画笔来描绘记忆中的过去那？没错，我也曾想成为一个画家。</p><p></p><p>今年是很值得庆幸的一年，AI 绘画在 2023 年泉涌般发展，给予了我马良的神笔，使用它我可以绘画出无限的可能，本文就分享了今年我在 AI 绘画中的一系列尝试，本文整理了整年学习和体验 AI 绘画的总结以及一些对于 AI 绘画的看法，我尽量通过浅显易懂的方式讲述 AI 绘画的基本使用，文章很长，其中包含大量案例和小窍门，建议收藏慢慢品味，如果能对大家的 AI 绘画之路有微乎其微的帮助，那真的是我的荣光。</p><p></p><p>让我们举起 AI 绘画的神笔，一起绘制出梦想中的世界。</p><p></p><h2>一、基础原理</h2><p></p><p></p><h3>Diffusion</h3><p></p><p>在 AI 绘画之前，我有必要简短给大家介绍一下 AI 绘画的基本原理。</p><p></p><p>我们先来想一个问题，你认为 AI 是怎么进行绘画的？是一笔一笔地勾勒轮廓，然后再上色精修，然后得到一副完美的画作吗？</p><p></p><p>No No No。</p><p></p><p>它采取了一种非常独特的思路——扩散 Diffusion，这个词比较难以理解，我想了一个通俗的案例，那就是我们经常使用的马赛克。</p><p></p><p>日常中，发朋友圈或者其他方式分享时，有张图片很喜欢，但是其中有一些部分涉及一些隐秘，不想让别人看，我们就会打上马赛克，这些部分就由此变得模糊不清。</p><p></p><p>如果有一张模糊不清的图片，我们给予一些提示，正如一千个读者就有一千个哈姆雷特，那每个人对这个模糊区域的想象是不同的，如果把每个人的想象复现为真实图像，就会得到与原图不同表现的千万张图片。</p><p></p><p>Diffusion 就是这样的工作原理，在图像的生成过程中，不断地迭代加入噪声或一些随机性信息，也就是进行马赛克，同时每一次噪声的迭代只与上一次的状态相关联，也就是说形成一段随机的加噪链条。</p><p></p><p>然后迭代去噪，在这个过程中，AI 就是万千的我们，根据关键词和它们所学习的知识，不断地进行联想，进行去噪，图像变得越来越清晰和逼真。</p><p></p><p>以后再想起 AI 绘画，你就可以简单地理解为马赛克的加密和解密过程，至于细节如何实现，有兴趣可以去深究一下，没兴趣，了解这么多就够了。</p><p></p><h3>模型是什么</h3><p></p><p>学到这里，我不由就产生了新的问题，最基础的文生图，我输入的都是文字啊，何来图像之说，那有何来马赛克之说？</p><p></p><p>好问题，AI 怎么知道你描述的是什么，又是如何转化为图像的那？</p><p></p><p>模型，AI 绘画的底层本质是一个图像模型，摸不着头脑，嘛玩意。</p><p></p><p>要是想彻底说清楚它，我估计三天三夜都不一定够。</p><p></p><p>还是再举一个例子吧，神经网络大家我想都不陌生，CNN，RNN，Transformer 等多了去了，它们其实就是一个结构，那它们是怎么具备人工智能的那？</p><p></p><p>练它，练它，它们也需要学习，这个学习过程叫做训练，图像模型就是这样一种模式，假设我是它的训练师，大致就是这样的一个训练过程。</p><p></p><p>来来来，图像模型你坐好，上课了，严肃点我拿出一个狗的照片，跟我念，这是狗我再拿出一个猫的照片，这是猫图像模型若有所思，眼神中全是清澈的愚蠢我再次拿出另一张狗的图片，图像啊，你说这是啥？图像回答是狗，我松一口气，没白教，这个算学会了猫，你说这是猫，我气晕了，回炉真得回炉，这是狗，记住，好好记住就在我和图像模型的反复拉扯中，它就会逐渐建立起猫、狗和对应图像的联系，然后它还具备对猫、狗的判断能力这就是所谓的图像模型</p><p></p><p>图像模型经过的无数类别的对应训练，它就构建了一张庞大的文本到图像的对应关系。当我输入狗时，它脑海中就会出现无数狗的印象，这是一个很笼统的狗，这也就是最初的马赛克图像。</p><p></p><h3>Stable Diffusion</h3><p></p><p>原理其实并不难，但将这个原理付诸于现实，推广使用，就是一个非常艰难的论题，Stable Diffusion 完整的实现了这个流程，并将其开源，由此我们便迎来了 AI 绘画的元年，我只能说配享太庙。</p><p></p><h2>二、基本使用</h2><p></p><p>了解完基础原理后，我相信你已经成功构建起 AI 绘画的基本概念，那么估计已经迫不及待的开始 AI 绘画之旅了。</p><p></p><p>开源的魅力就在于它的无限可能，<a href=\"https://github.com/AUTOMATIC1111/stable-diffusion-webui\">AUTOMATIC1111</a>\"大佬为 Stable Diffusion 开发了一套 Webui 页面，通过简单的网页交互操作，就可以轻松实现 AI 绘画。Webui 大幅度降低了使用门槛，这也是今年 AI 绘画的爆发的有力推动者之一。</p><p></p><h3>环境配置</h3><p></p><p>环境配置这里我就不详细讲解了，目前社区内已经有广泛的配置细节，这里我讲一些比较省事省力的方法</p><p></p><p>AI 绘画对于设备的要求还是蛮高的，嗯，挺高的，很多朋友的电脑其实未必能吃得住 AI 绘画，因此就需要一个在线的 AI 绘画平台，对于这种情况，就有两种解决方案，我最推荐下面的几类方案</p><p></p><p>方案一：自己搭建colab 搭建方法，这是借助 Google Colab 平台搭建，不需要花钱，但是空间容量很小，只能进行一些比较简单的体验，具体<a href=\"https://juejin.cn/post/7217750296171233339\">搭建教程</a>\"。方案二：免部署<a href=\"https://www.liblib.art/\">liblib</a>\" 免费的，支持在线生图，也非常繁荣，模型和 lora 都很多，用起来特别方便。缺点就是每天只有 300 能量值，一般情况是用不完的，因为需要排队，火的模型排队有点小长。此外就是它不支持额外插件扩展，只能用官方提供的默认。<a href=\"https://cloud.megaease.cn/megacloud/app/main/ease-middleware/manage/app\">megaEage</a>\"，一个付费的在线免部署平台，平台内部集成了环境，一键式部署，价格也相对比较便宜，Webui 一小时 5 毛左右，可以比较自由的扩展，缺点就是花钱。</p><p></p><p>如果电脑的性能足够的话，可以在本地配置环境，那样的话我强烈推荐<a href=\"https://www.bilibili.com/video/BV1iM4y1y7oA/?vd_source=9c8655c372d505efbf535185968313cd\">秋叶佛祖</a>\"的整合包，一键式安装，摒弃复杂的环境配置流程。</p><p></p><h3>基本页面介绍</h3><p></p><p></p><p></p><p>webui 启动后，就类似于上图，由于我已经安装了很多扩展插件，可能与你的存在一些差异，但是整体模块是类似的。</p><p><img src=\"https://static001.geekbang.org/infoq/3e/3ebc3295f1f3dcf8f892c6ce431d3f78.jpeg\" /></p><p></p><p>Stable Diffusion 模型: 生图所使用的图像模型Vae: 影响画面的色彩和质感，可以理解为一个调色滤镜，理解为拍照时用的那个滤镜功能栏：文生图、图生图或者一些其他扩展Prompt: 提示词，分为 Positive 和 Negative，通俗理解就是你想要 AI 画的和不想让它画的Params: 控制参数，生成图像中所需的一些参数Steps 迭代步数，也就是打马赛克的轮数Sampler Methods 采样方法，这个后面我会详细的带大家体验一番...</p><p></p><h2>三、绘画核心三要素</h2><p></p><p>了解到基本页面后，我们就可以开始第一张 AI 的绘画了。经过我一阶段的 AI 马良之旅，AI 绘画在我看来有三大核心要素：模型+提示词+参数。另外额外的一些扩展，可以算是核心外的锦上添花，把握住核心，就能完成一些不错的绘图。</p><p></p><h3>模型</h3><p></p><p>Stable Diffusion 模型其实官方提供了几款基本模型，但是在日常的绘画中，我很少使用。很简单的道理，Stable Diffusion 就像一个世界语言词典，囊括世界上所有的词汇，咱们汉语是母语，遇到不会的，世界语言词典肯定能查到，但是怎么能比的过使用汉语词典去查，来得简单和精确那。</p><p></p><p>Stable Diffusion 官方提供的模型就是类似的原理，它们足够包容，全面，但是它们的专精性不够强，例如我就像画猫狗，我便倾向于侧重于猫狗的图像模型；我画人像，我便倾向于人像。于是，开源的小伙伴们，就在 Stable Diffusion 官方的基础模型(也可以称作底模)上进行了无数微调，私炉训练，由此产生了现在模型万花筒般的盛况。</p><p></p><p>那么问题来了，我们该如何获取模型那？</p><p></p><p>下面我先推荐几个不错的模型社区，然后分享几款我特别喜欢的模型。</p><p></p><p><a href=\"https://civitai.com/\">civital</a>\"<a href=\"https://huggingface.co/\">huggingface</a>\"<a href=\"https://www.liblib.art/\">liblib</a>\"</p><p></p><p>上面三款应该足以满足大多数 AI 炼丹师的需求了，尤其是 C 站，那真的是繁荣，各类资源丰富，就是需要科学上网，如果综合考虑，我还是推荐 liblib，下载速度和模型数量都足够抗打，而且更偏向于国人的审美。</p><p></p><p>在推荐模型之前，有句话希望大家可以有个概念，别被繁杂的模型弄晕了：模型本质没有优劣之分，只不过有些模型好评度比较高。</p><p></p><p>二次元类<a href=\"https://www.liblib.art/modelinfo/e5b2a904207448b47c2e49abd2875e70\">anything V5(*)</a>\"<a href=\"https://www.liblib.art/modelinfo/1004b01e19714137a593e30007f3c737\">ReVAnimated_v122(*)</a>\"<a href=\"https://www.liblib.art/modelinfo/36b74574a3d3185a1caf28ab84d2c80b\">counterfeit V2.5</a>\"<a href=\"https://www.liblib.art/modelinfo/81c9082dc98ad9f3f60e8d733d95fbb3\">dreamlike diffusion</a>\"写实类<a href=\"https://www.liblib.art/modelinfo/bced6d7ec1460ac7b923fc5bc95c4540\">majicMIX realistic(*)</a>\"DeliberateLEOSAM HelloWorld 新世界 | SDXL 真实感大模型Realistic Vision<a href=\"https://www.liblib.art/modelinfo/2e889beaae284cb5868e417676316e59\">dreamshaper_8(*)</a>\"2.5D 类Never Ending DreamProtogen<a href=\"https://www.liblib.art/modelinfo/d920d0d81d388f3feff3933e588cc0d3\">国风 3</a>\"3D 可爱化<a href=\"https://www.liblib.art/modelinfo/2beae39bf23edd20675436f88cbf0942\">IP DESIGN</a>\"<a href=\"https://www.liblib.art/modelinfo/dc96b4ed7c1d43afafa21a59812f1825\">三维 IP 效果模型</a>\"</p><p></p><p>模型如海一般，每天又在频繁的制造 ing，大家选用自己喜欢的即可，我就不详细的写模型的推荐理由了，只标记了几款我最常用的，通过链接点进去，都会有模型的详细介绍和返图区，风格、画风比较容易判断。</p><p></p><h3>prompt 如何写</h3><p></p><p>关键词是门学问，还记得 ChatGpt 刚出现时，网络上出现一种 prompt develop 的岗位，专门来帮助设计 prompt，当时还有些不屑一顾，后来开始 AI 绘画时，才发现 prompt 刚上来是真有些摸不着头脑。</p><p></p><p>此外经过一段时间的学习，我总结了一些 prompt 的使用经验，我称为三大法宝：</p><p></p><h4>法宝一：分类 prompt</h4><p></p><p>标准化提示词，这些通常是固定的，画质建议每次都写上，画风则根据风格发生相应变化画质提示词高画质: best quality,masterpiece.hires,8k,ultra-detailed高分辨率: extremely detailed CG, unity 8k wallpaper, unreal engine rendered画风提示词插画风格: painting, illustration, paintbrush写实风格: relistic, photorelistic二次元: anime, comic辅助提示词: 辅助提示词来界定绘制的场景信息场景特征室内、室外 indoor/outdoor场景的类型 forest、city、street小的细节 tree、cloud、flower环境、光照时段: morning、sunset、day/night光线: sunlight、bright天空: blue sky画幅视角 - 距离 close-up、distant - 人物比例 full body、upper body - 观察视角 from above，view of back - 镜头类型 wide angle、Sony A7 III内容提示词: 内容型提示词是每次需要核心绘制的内容，这个就没有明确的划分，想绘制什么内容就写什么</p><p></p><p>因此我推荐在写 prompt 时，按照分类顺序来写，这样编写的 prompt 逻辑更好，修改起来也更不容易混淆。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/59/5902d2c7d40c55691c5d410e85d09c58.png\" /></p><p></p><p></p><h4>法宝二: prompt 插件</h4><p></p><p>关于 prompt 方面，有三个插件我是特别大力强烈推荐的，分别是</p><p></p><p><a href=\"https://github.com/DominikDoom/a1111-sd-webui-tagcomplete\">sd-webui-tagcomplete</a>\" 可以实现自动补全，默认支持英文，中文需要添加相对应词库</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/86/86be2d86aea5335f208497a1cdfe1c53.jpeg\" /></p><p></p><p></p><p><a href=\"https://github.com/Physton/sd-webui-prompt-all-in-one\">prompt-all-in-one</a>\" 支持自动中文转英文、一键转英文、将 prompt 中的所有提示词按照 tag 展开，可以实现快速修改权重、收藏常用提示词等。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4b/4b76674b090cfb436983e81a5c2f3914.jpeg\" /></p><p></p><p><a href=\"https://github.com/thisjam/sd-webui-oldsix-prompt\">oldsix-prompt</a>\" 懒人福音，上面的插件只是降低了 prompt 的编写难度，而这个插件直接集成了多个分类的上千个提示词，而且还是中文的，只需要点击选择就可以实现 prompt 编写了。tql。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/25/25e337f80f3dff972c6d258d4b6ee69e.jpeg\" /></p><p></p><p></p><p></p><blockquote>对于每个插件，都有一些更细节，更高级的配置，这里我就不详细解释，网上都有非常多的教程。</blockquote><p></p><p></p><h4>法宝三: 拿来主义</h4><p></p><p>C 站、liblib 每个模型都有返图区，返图区的某些图像会带有相对应的生成参数，我们可以直接借鉴。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b9/b958411311640c5bb2300321238cd577.jpeg\" /></p><p></p><p>除此之外，再给大家提供几个我常用的抄作业网站，生成好看绘图前，保证让你挑花眼。</p><p></p><p><a href=\"https://openart.ai/\">OpenArt</a>\"<a href=\"https://arthub.ai/\">ArtHubAi</a>\"</p><p></p><h4>其他注意</h4><p></p><p>除了提示词写法外，还有两点需要补充</p><p></p><p>提示词权重：提示词是存在权重的，可以通过增加或者降低提示词权重来控制生成细节，具体写法是 (prompt:weight)，如果不写 weight，默认一层括号为 1.1 权重，写了以 weight 为主负面提示词：负面提示词相较于没有那么关键，可以一套用到黑，这里就附上我常用的一套，每次生图对应填写到 negative prompt 即可。</p><p></p><p><code lang=\"javascript\">NSFW, (worst quality:2), (low quality:2), (normal quality:2), lowres, normal quality, ((monochrome)),((grayscale)), skin spots, acnes, skin blemishes, age spot, (ugly:1.331), (duplicate:1.331), (morbid:1.21), (mutilated:1.21), (tranny:1.331), mutated hands, (poorly drawn hands:1.5), blurry, (bad anatomy:1.21), (bad proportions:1.331), extra limbs, (disfigured:1.331), (missing arms:1.331), (extra legs:1.331), (fused fingers:1.5), (too many fingers:1.5), (unclear eyes:1.331), lowers, bad hands, missing fingers, extra digit,bad hands, missing fingers, (((extra arms and legs))),\n</code></p><p></p><h3>参数</h3><p></p><p>提示词相关性（CFG）：这个很好理解，就是书写的 prompt 对绘图中内容的影响程度，一般不会修改，默认 7 就可以。如果你感觉生成图像像没有很好的反映提示词，可以修改 prompt 或者适当增大 CFG。Seed: 种子是稳定扩散产生噪声的数字。计算机中的随机都是伪随机，大家应该都听过这句话，Stable Diffusion 中的噪声生成也并非随机，每次它都是源于一个随机种子，即 seed，也就说，只要 seed 不改变，对应的生成噪声的方式也不会改变。固定了 seed，就相当于固定了整个生图过程，从而可以实现图像的复现。Sampler Method: 在 sd 中，采样方法有一大堆，但其实我们只会使用其中的几种，这里总结一下它们的常用场景。快速生成质量不错的图: 建议选择 DPM++ 2M Karras(写实风格我也比较推荐它)高质量的图: DPM++ SDE Karras 、DDIM简单的图: 建议选择 Euler a极速生图: LCM，此种情况下，迭代步数建议 3~5Sampling Step: 推荐 20~40 之间，正常来说，越大，细节越丰富，但消耗时间会相应增加，文生图我一般推荐 20~30，图生图推荐 30~40。此外，Step 也受相对应的采样方法影响。高分辨率修复(文生图)，可以放大图像， 本质上相当于进行了将文生图的结果一次图生图Denoising 重绘幅度(图生图)，类似于 CFG，图像被修改的幅度，推荐 0.3~0.7。</p><p></p><p>后续不同参数的效果会在后面做案例比较，大家这里先有一个概念。</p><p></p><h2>四、文生图</h2><p></p><p>掌握核心三要素后，就可以开启文生图的旅程了，后续的案例我都将按照下面的模式来注明所用的指标。</p><p></p><p></p><blockquote>如果你想复现我的图，一定要铭记\"模型+提示词+参数\"全部相同，其中 seed 最为关键，没特别声明的为默认值。</blockquote><p></p><p></p><p><code lang=\"javascript\">Model: Anything V5/V3\n\nPositive: masterpiece,best quality,4k,realistic,1girl,solo,long hair,looking at viewer,bangs,white hair,parted lips,upper body,simple background,dress,from side,(blue eyes:1.2),\n\nNegative: (worst quality, low quality:1.4),negative_hand Negative Embedding,verybadimagenegative_v1.3,2girls,nsfw:1.4,bad anatomy,bad hands,cropped,missing fingers,too many fingers,missing arms,long neck,Humpbacked,deformed,disfigured,poorly drawn face,distorted face,mutation,mutated,extra limb,ugly,poorly drawn hands,missing limb,floating limbs,disconnected limbs,malformed hands,out of focus,long body,missing toes,too many toes,monochrome,symbol,text,logo,door frame,window frame,mirror frame,\n\nSampler Method: Euler a\nSampling Steps: 20\nSeed: 520684962\nwidth*height: 512*768\n</code></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/eb/ebec2f00e5f30c70ea91a63c98ec0751.jpeg\" /></p><p></p><p></p><p>如果你按照我的步骤来了一遍，那么你应该得到的是下面这个小姐姐，是不是挺简单的，不知不觉，你已经成功地完成第一张绘制了。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8e/8eb93e30535119cdc3ec7d234f4419db.png\" /></p><p></p><p>文生图就是这么简单，朴素无华，只要写好提示词，就可以绘制出大千世界的任何景色。</p><p></p><p>但这远不是文生图的真正强大，它的魅力还远远不止这些。例如我为此添加一个 lora: <a href=\"https://www.liblib.art/modelinfo/d53b929309f04ce69b0ab2b1c658b829\">扁平像素风</a>\"，设置权重 0.8，小姐姐风格瞬间就被改变了，是不是很神奇，AI 绘画的世界大着那，Lora 是什么，具体先不用深入理解，后续咱们一步一步来。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9d/9d03e4d2f63016a6364a6d6e15bf6aa2.png\" /></p><p></p><p>但是此时如果取消传入的 Seed，再点击生成，你会就发现，每次生成，得到的绘图是天差地别的，AI 画师也形象把这个过程比作抽卡。那么问题就来了，抽卡通常就意味着低效，大家应该都被抽卡概率荼毒过，学到这里你可能会怀疑 AI 商业的可能性？别急，等我慢慢道来。</p><p></p><h2>五、图生图</h2><p></p><p>图生图说到底也并不复杂，相较于文生图枯燥的文字提示，它只是添加了更为直接的提示——图片信息，也就是所谓的垫图，其余都是一样的。</p><p></p><h3>真人漫画风</h3><p></p><p>文生图我们不是生成一张扁平肖像风小姐姐吗？这里咱们把这个汉服小姐姐扁平像素风一番，这也就是真人动漫风的一种。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7a/7ae49fa69673af821d777c5bd5fa5271.png\" /></p><p></p><p></p><p>我们把文生图所用的参数都同步到图生图中，注意修改一下生成图像的尺寸，图生图会以传入的图像作为基准，上面小姐姐像素为 1200*2048，如果不修改尺寸，依旧按照 512*768，生成图像就会被压缩。</p><p></p><p>1200*2048 这个分辨率有些过大，太考验显卡性能，咱们等比缩放一下，使用600*1024，重绘幅度，保持默认。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4e/4e59d6c3749a2f7d95a81550ece882cb.png\" /></p><p></p><p>使用了文生图的提示词，汉服小姐姐的很多行为被修改了</p><p></p><p>头发颜色使用黑色服装想用汉服头发扎的方式-盘发注视屏幕-侧着身子</p><p></p><p>对应修改一下 positive prompt，如下:</p><p></p><p><code lang=\"javascript\">masterpiece, best quality, 4k, realistic,\n1girl, solo,  bangs,  parted lips, upper body, simple background,\nWearing Hanfu, from side, (blue eyes:1.2), updo, Side by side\n</code></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0e/0ebc44b5a21be067b22a95770e135850.png\" /></p><p></p><p>绘制的图像是不是更接近我们的想法了，如果依旧感觉不足，可以继续调整提示词。</p><p></p><p>比如我想要东方传统青花瓷风格的衣服，那就可以再添加一个 Lora:<a href=\"https://www.liblib.art/modelinfo/1b210067e4714d73851b627f33de9346\">东方魅力系列-青花瓷风</a>\"，权重依旧设置为 0.8</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bc/bc34777f56c669798bf674c2f527eda9.png\" /></p><p></p><p>青花瓷的感觉已经上来了，但是它也带来了负面作用，那就是发色、整体画风受到了非常大的影响，权重有些大，降至 0.4。整体就有比较清晰的回调，当然，你也可以继续调整，辅助于其他的 Lora 和 prompt。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/31/31fd1985a0d1cbc10467e92da2201113.png\" /></p><p></p><p></p><p></p><h3>重绘幅度</h3><p></p><p>依照上面这个案例，我们来测试一下重绘幅度的影响，加深对此的认识。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7d/7d9e54222de4deb64a4e82a1b77bf8be.png\" /></p><p></p><p>重绘幅度位于 0.1~0.3 之间，图像的改变其实并不是特别大(画风的改变是 Lora 影响的)，而 0.8~0.9 背景已经没有，原图也变动很大，因此我比较推荐 0.3~0.8，在这个区间，一方面尽可能保留了原图特征，还给了 AI 足够的发挥空间。</p><p></p><p>但小的重绘幅度也有妙用，比如你想做一个赛博 Coser，既然是 Coser，你总不想出来的效果完全不像你吧。</p><p></p><h3>赛博 Coser</h3><p></p><p>赛博 Coser 是今年上半年，一个 B 站 Up 主制作了一组以自己为原型的赛博 Coser，上传到 B 站时，被官方分类到了 Coser 类，官方都没审核出来，可见这组绘图的质感。此事一出，在国内外的 Coser 圈和设计圈引起了轩然大波，人们由此开始重新思考 AI 绘画的魅力。</p><p></p><p><code lang=\"javascript\">model: majicMIX realistic 麦橘写实_v7\npositive prompt:\n    (cybermech bodysuit:1.2),((Cyberpunk)),full armor,city skyline,(fluttering cloak:1.3),(white armor, gold trim, paladin), mechanical parts, (robot joints), single mechanical arm,(hair flying:1.2),mechanical prosthetics, (intricate mechanical bodysuit),(cyborg, mecha:1.2)\n    masterpiece,best quality,full details,Super clear details\n    futuristic, technological, science fiction, liquid metal, metal texture,\n    cinematic lighting, weird lighting, rim light, natural light, slight film grain, Bright cinematic lighting, Global lighting, clear shadows, Bright cinematic lighting,\nnegative positive: ng_deepnegative_v1_75t,badhandv4,(worst quality:2),(low quality:2),(normal quality:2),lowres,bad anatomy,bad hands,normal quality,((monochrome)),((grayscale))\nSampler Method: DPM++ 2M Karras\nSampling Steps: 30\nImageSize: 512*1024\nCFG Scale: 10\nDenoising: 0.60\nseed: 4019293404 | 3515564825\n</code></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5f/5f837a14748692087be6458c9bb032b9.jpeg\" /></p><p></p><p>如果有兴趣也可以读一下我写的 prompt，主要就是写了一些赛博朋克风格、科幻风格的背景和衣服。</p><p></p><p>另外有一个比较值得注意的点，除了降低重绘幅度外，我还拉高了 CFG 的大小，这是为了更大程度上模拟赛博朋克风格，同时尽可能保持脸部和身形的还原度。最后的结果大约就是下面这样。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/10/10f7ade486314a71e35f123bfb3b7399.jpeg\" /></p><p></p><p>如果感觉赛博朋克的风格不够显著，也可以加入相对应的 Lora，例如<a href=\"https://www.liblib.art/modelinfo/03b461c8fb484227909bddd15981c7ec\">赛博朋克风格 V2.0</a>\"，风格类权重不要设置太大，0.4~0.6 就好，这里咱们设置 0.4。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b8/b8365b7d7d408677385c3fb5d9c277f4.png\" /></p><p></p><p>图生图的案例还有很多，记住其生成核心即可：利用图片提供更多的信息，相当于垫图。但你是否发现一个问题，我们已经提供了图片信息，还是要写一大堆 prompt，而且还不能保证生成效果，这有点让人难受。</p><p></p><p>那有没有解决方案呢？有，还有两种，一种便是 Lora，另一种是前段时间刚推出的 ip-adapter，后面我都会慢慢介绍。</p><p></p><h2>六、Lora</h2><p></p><p></p><h3>基础知识</h3><p></p><p>上文中反复使用了多种 Lora，但是我并没有告诉你它是什么？现在咱们来揭开它的面纱。</p><p></p><p>训练图像模型的时候，我举过让他辨别猫狗的案例，那么现在问题来了，我现在要求提升了，我现在要求画一只柯基。</p><p></p><p>它认识柯基吗？它不认识，不信咱们试试。不应该这么武断，应该说它的认识不够精确。</p><p></p><p><code lang=\"javascript\">model: majicMIX realistic7\n\npositive prompt: (masterpiece:1.2), best quality, realistic,\nA corgi dog, humorous, beautiful colorful background,\n\nnegative prompt: easynegative,(((pubic))), ((((pubic_hair)))),sketch, duplicate, ugly, huge eyes, text, logo, monochrome, worst face, (bad and mutated hands:1.3), (worst quality:2.0), (low quality:2.0), (blurry:2.0), horror, geometry, (bad hands), (missing fingers), multiple limbs, bad anatomy, (interlocked fingers:1.2), Ugly Fingers, (extra digit and hands and fingers and legs and arms:1.4), crown braid, ((2girl)), (deformed fingers:1.2), (long fingers:1.2),succubus wings,horn,succubus horn,succubus hairstyle,girl,\nSampler method: DDIM\nSampling Steps: 30\n</code></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e7/e7b2694b6346d3b41333a4c248db2246.png\" /></p><p></p><p></p><p>距离咱们日常中的柯基是不是相差甚远，这是因为 AI 在训练时，虽然可能接收了部分柯基图片，但是通常只会占据一小部分，它们没法建立起特别精确的对应关系。</p><p></p><p>这时候就产生了两种解决方案:</p><p></p><p>更精准的描绘柯基，帮助 AI 进一步筛选，这个调试过程可能会很麻烦使用 Lora，你不用按照定义去理解它，它就是针对特定场景的一种特训方案，例如<a href=\"https://www.liblib.art/modelinfo/0d96314f74c7eb6107c945922ac68ba6\">动物模型丨柯基 MG_CORGI</a>\"它就是使用柯基训练的，SD 模型拿到它，就可以清晰的捕捉到柯基的对应图像。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/16/16ec3828f3ad9f3baaaffe9e6e9a98e1.png\" /></p><p></p><p></p><p>柯基的感觉是不是直接溢出屏幕了，没有添加任何的提示词，加入一个Lora就可以实现柯基效果。</p><p></p><p>模型是对 SD 底模的微调，Lora 则是针对特定场景的特训，不管谁来了，你就这么理解，就是相当于查字典，本来你使用提示词，需要告诉字典第几章第几部分第几个，Lora 就相当于书签，直接定位到所查单词。</p><p></p><h3>Lora 使用</h3><p></p><p>Lora 使用有三种，我比较推荐我介绍的这种，在 Webui 界面中，有一个工具栏，点击 Lora 选项，就可以罗列出所有的 Lora。如果没有这个工具栏，在生成按钮下面，会有一个小按钮，叫隐藏/显示扩展模型，点击一下，就可以出现。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0d/0d58ddf54d06cc95473cf13ae0e00b41.jpeg\" /></p><p></p><p></p><p>进入 Lora 工具栏后，点击的 Lora 会默认填写到 Positive Prompt 中，格式为，默认权重默认为 1。</p><p></p><h3>Lora 分类</h3><p></p><p>Lora 相较于模型，它更容易训练，体积更小，能完成我们心中的特定场景、人物中，我时常称其为 AI 绘画中的明珠，如何能用好它呐，我认为需要在心中对 Lora 有一个大致的分类，不同的分类权重设置有所不同。</p><p></p><p>人物/动物 Lora，推荐权重 0.6~0.8画风 Lora，推荐权重 0.2~0.4，画风对于画面的影响非常大，所以一般使用比较小的参数。概念 Lora，这些 Lora 通常形容一个概念，或一个场景，也不宜太大。例如原神中抽卡，既有人物，也有复杂背景这种。服饰类 Lora，视情况而定，0.6~0.8特定元素 Lora，头盔、项链等一些装饰品</p><p></p><p>Lora 可以同时使用多个，但注意有些 Lora 可能会存在冲突，这个生图的时候需要注意一下。下面推荐一个案例，使用了画风和概念 Lora，大家有兴趣可以去尝试一番</p><p></p><p><code lang=\"javascript\">model: XXMix_9realistic_v4.0 v4.0,\npositive prompt: masterpiece, best quality, 8k, cinematic light, ultra high res, (full body:1.2), 1girl, look up, full body, Black hair, blue eyes, full body, chibi, snow,\nNegative prompt: EasyNegative, badhandv4, (worst quality, low quality:1.3), logo, watermark, signature, text\nSteps: 25,\nSize: 512x1024,\nSeed: 1389480785,\nLora1: 3D渲染风格 | 3D Render Style v1.0,\nLora2: Q版角色-- niji风格卡哇伊 v1.0,\nSampler: DPM++ 2M Karras,\nCFG scale: 7\n</code></p><p></p><p>大约是这种效果：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/24/241c484e52f7601aae4696f60e2ad6a0.jpeg\" /></p><p></p><p></p><h2>七、ControlNet</h2><p></p><p>上面的案例，为了保证你生成的效果与我保持一致，我推荐固定 seed。但是在日常我们的绘画过程中，需要大批量的生图，最后再挑出一张心仪的，作为绘制成果。</p><p></p><p>在这个大批量绘制的过程中，你会发生，牛鬼蛇神，各种姿态，各种布置都会出现，这是由于 AI 绘图是基于扩散模型，生成过程充满了随机性，难以控制。</p><p></p><p>随机也就意味着低效，那我就需要重新评估它的商业价值了。</p><p></p><p>ControlNet 就是针对于这些场景而出现的，中文叫控制网，本质是对大模型做微调的额外网络，根据一些额外信息控制扩散生成走向。</p><p></p><p>ControlNet 提供了很多提取额外信息的方式，例如 openpose 提取姿势信息，canny 提取边缘信息，在后续中，我不会详细的讲解每个到底是怎么使用的，下面主要围绕案例展开。</p><p></p><p>Controlnet 位于参数的下面，框起来的是核心部分，支持多种 ControlNet 同时使用，推荐开启完美像素模式，如果设备显卡有限，可以开启低显存模式。</p><p></p><p>控制权重类似于 CFG、Deoising，代表提取的控制信息对生图的影响比例，后面的介入时机和终止时机表示这些控制信息什么时候参与到噪声生成。举个好理解的例子，例如 Step 为 20 步，0.2 就可以理解为从第 4 步参与。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/72/72f318d7488c5ed377d028cb9b9cff58.jpeg\" /></p><p></p><p></p><h3>模特换装|背景</h3><p></p><p>模特换装|背景这是电商中非常热门的应用之一，它的核心便是借助于图生图的蒙版重绘。</p><p></p><p>蒙版的设计可以借助 PS，但如果不会 PS，也没关系，webui 中存有<a href=\"https://github.com/AUTOMATIC1111/stable-diffusion-webui-rembg\">webui-rembg</a>\"插件，安装该插件后，在顶部菜单栏的后期处理中，就会有生成蒙版的功能。按照下面截图操作，点击生成，就可以获得蒙版。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/16/16fb038546c91a2a65e4250824bbe16b.jpeg\" /></p><p></p><p></p><p>然后传入到图生图的蒙版绘制，蒙版默认重绘白色区域，但可以选择重绘蒙版内容，实现倒置。</p><p></p><p>其余的参数，建议按照我所使用的</p><p></p><p>蒙版内容区域建议选择 原版，如果生成后的图像蒙版接壤处有些模糊，也可以使用填充重绘区域建议选择 整张图片，否则可能会出现非常奇怪的东西，但其实约束了也会出现特别奇怪的。。。</p><p></p><p>下面来看一个例子，首先把背景换成圣诞风格，我随便写了一组比较简单的关键词。</p><p></p><p><code lang=\"javascript\">model: dreamshaper 8\npositive prompt: christmas background,(christmas_tree:1.1),christmas light,beautiful lighting,christmas present,fireworks,(no human:1.5),christmas scene,realistic,(no hand:1.1),\nnegative prompt: ng_deepnegative_v1_75t,badhandv4,(worst quality:2),(low quality:2),(normal quality:2),lowres,bad anatomy,bad hands,normal quality,((monochrome)),((grayscale)),\nStep: 30\nSampler Method: DPM++ 2S karras\n蒙版区域填充/原版都可以\n蒙版边缘模糊度 2\n重绘区域整张图片\n</code></p><p></p><p>然后你就有可能会看到惊悚的一幕，生成的图像中多出了两只手，即使我在 prompt 中进行了约束((no human:1.5),(no hand:1.1))，但是依旧还是出现多余肢体的问题。</p><p></p><p>网上很多教程并没有提出对此的解决方案，这其实算是蒙版重绘目前存在的弊端，确实不好解决。其一它还不够智能，我们使用的蒙版，右手被身体遮盖了，它就会尝试去补全；其二咱们制作的蒙版边缘应该存在一些空隙，可能会好一些。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b2/b21ee1899b955348d69a5546bb15c71a.jpeg\" /></p><p></p><p></p><p>那该怎么解决那？我经过一系列的尝试，Controlnet 可以有效地解决这一问题。</p><p></p><p>openpose 可以提取图片中人物的姿态，支持身体、手指以及面部等各部位，下面展示的是最完善的所有部分提取，即 openpose-full。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/44/44e74a9cc9a18461202fcb086928e455.jpeg\" /></p><p></p><p></p><p>提取越多信息，openpose 所用时长越久，这里咱们不需要面部表情，因此选用 openpose-hand 就可以，有了它，我们就可以控制小姐姐的身体和手指的整体姿态。但是光有它是不够的，姿态只能提供平面信息，无法提供深度位置信息，小姐姐的右手是被遮挡住了，因此我们需要添加额外的 Controlnet。</p><p></p><p>depth</p><p></p><p>在人像的生成中，depth 通常可以用来提供深度信息的辅助，因此其权重通常设置比较小，0.2~0.4 左右，同时引导时机也要相应调整，否则生成的人像会非常突兀。depth 推荐使用 depth leres++预处理器，下面是我使用的参数和深度图，深度图中颜色的深浅便是其中部分距离我们的远近，也就是距离深度信息。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/0197077521da3744d6145b665f7427c1.jpeg\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f5/f5fb9fb14cbf2e7e8d31a9fd4aed29ed.png\" /></p><p></p><p>depth 可以提供深度信息，其实它最大的发挥空间是建筑、布局等诸多领域。</p><p></p><p>多生成几次，你就可以发现，在 openpose + depth 的双重控制下，多余肢体出现的情形就会非常少。openpose 和 depth 是一组常用的控制网搭配，在人像绘制中可以起到很好的互补作用。</p><p></p><p>这个案例因为是一个长图，可供渲染的背景区比较少，更换背景的效果没有那么明显，主要目的是为了记录在蒙版重绘过程中遇到的问题和解决方案，如果想要更明显的背景切换感，可以换成横屏图或者缩小人像的占比。</p><p></p><p>下面我们来尝试进行模特换装，从背景中提取人像，我们用 webui 插件实现了，衣服的提取也可以用 webui 插件实现，是不是感觉好强，打倒 PS 就在今日。</p><p></p><p>这个插件叫<a href=\"https://github.com/Uminosachi/sd-webui-inpaint-anything\">inpaint-anything</a>\"，安装之后，会在顶部菜单栏多一个 Inpaint Anything 标签页。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/26/26cba899a1ede69089f5a6d54ddd6f4f.jpeg\" /></p><p></p><p></p><p>截图中提供了使用的大致步骤，模型推荐使用 sam_vit_l_0b3195.pth，这个生成会有些慢，需要等一会，然后再右边就可以得到场景中每一个部分的切片，想要那部分蒙版，用画笔在上面勾勒一下，就可以获取对应蒙版，这个插件可以允许你提取图像中的任何部分，而且效果还是特别不错的。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f4/f460837c5e80bbfbe874e109f52828f2.png\" /></p><p></p><p>得到蒙版后，更换衣服的方法与更换背景类似，这里就不做赘述。</p><p></p><h3>文字风暴</h3><p></p><p>基于扩散的机制，虽说可以产生无限的可能，但是在某些情形下，它也有很多的不足，例如早期 AI 画手，就是因为扩散的机制，导致出来的手千奇百怪。除了手，另外一个最典型的就是文字，AI 写出的文字也和早期的手一般，歪曲，乱七八糟。</p><p></p><p>如果想绘制不变形的文字，或者在文字的基础上在做一番尝试，也需要借助 Controlnet 来做。这是我随手在 Word 中写的两个字——冬至，我想以此为基准，创建一个带有冬至的海报。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/73/730d5a260d5ad36ab87bfa92b3c3d85e.jpeg\" /></p><p></p><p>给它一组参数，扔了图生图里面去。</p><p></p><p><code lang=\"javascript\">model: revAnimated_v122\npositive prompt: in winter,snowfield,snow,ice,(snowflakes:0.9),landscape,waterpark,\n\nnegative prompt: EasyNegative,fog,nsfw,nude,(badhandv4:1.2),(Style-Japan:1.2),(easynegative),verybadimagenegative_v1.3,deformation),Paintings,sketches,(worst quality, low quality, normal quality:1.7),lowres,blurry,text,logo,((monochrome)),((grayscale)),skin spots,acnes,skin blemishes,age spot,strabismus,wrong finger,lowres,bad anatomy,bad hands,text,error,missing fingers,extra digit,fewer digits,cropped,wort quality,low quality,normal quality,jpeg artifacts,signature,watermark,username,blurry,bad feet,(worst quality, low quality:1.4),nsfw,\nSampler Method: DPM++ 2M Karras\nSteps: 30\n</code></p><p></p><p>结果我就不展示了，因为你会得到一些奇奇怪怪的展示。如果我再给 AI 些提示，例如加上poster style,the \"冬至\" is written in the middle,，额，结果怎么说那，又臭又硬。</p><p></p><p>Controlnet 出手，对于这种需要比较精准的提取轮廓信息，Controlnet 中有很多种，例如 canny 边缘监测、softedge 柔性边缘、Scribble 涂鸦都是可以的，canny 最较真一些，后面两者相对更柔和一些，对于信息的把控没有那么严格，如果你想要 AI 更天马行空一些，可以使用后面；如果更多的精度，canny 最合适。下面就是分别对冬至两个字的 controlnet 预览效果，可以看到，从 canny -&gt; softedge -&gt; scribble，对边缘的提取越来越柔和，AI 的发挥空间越来越大</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/91/91cd15be55381ebaa7ca7c37e3e085ed.jpeg\" /></p><p></p><p></p><p>下面两图分别使用 scribble 和 canny 生成的，我没有使用太复杂的提示词，加上了几个 Lora，效果就挺不错的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/69/69013e5c1530815f5af1709937b92f10.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/75/75ff7ff975334e929502e909bd35c5d5.png\" /></p><p></p><p></p><p></p><h3>艺术二维码</h3><p></p><p>艺术二维码也算是在抖音盛极一时，那时候我记得抖音总会推相应的广告或者视频，甚至现在咸鱼上还有好多售卖艺术二维码的，我不信这个邪，让我来看看怎么个事。二维码其实是通过定位点和黑白之间的明暗关系来识别的。因此我们只需要尽可能地还原二维码中的关键定位点，同时增加明暗关系，然后借助文生图的方式，是不是就可以实现艺术二维码。</p><p></p><p>当然这种方式不是我发明的，是神通广大的网友发明的，我只是其中的实践者。</p><p></p><p>那我们就按照上面的思路来：</p><p></p><p>抓住关键定位点和轮廓信息，这点 <a href=\"https://huggingface.co/monster-labs/control_v1p_sd15_qrcode_monster\">qrcode_monster</a>\" 可以解决提升信息间明暗度，这点 <a href=\"https://huggingface.co/ioclab/control_v1p_sd15_brightness\">brighness</a>\" 可以解决</p><p></p><p>边边角角的融合度通常是较难的，经过我反复体验，AI 更喜欢圆滑的曲线，因此咱们首先使用 <a href=\"https://github.com/antfu/sd-webui-qrcode-toolkit\">QR Toolkit</a>\" 插件进行二维码改造，改造的模式建议使用我下面的方案，经过测试，融合度最好。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a3/a3d344b353c31bdb05d2c43589f28376.jpeg\" /></p><p></p><p></p><p>改造完二维码后，一定要用手机扫一下，如果不成功，修改一下 seed，但是别指望长按识别，等会你会见证奇迹。</p><p></p><p>qrcode 权重关乎到二维码的还原度，通常在 1~1.2 以上，但是据我经验，最好开始不要拉太大，1 即可，后续慢慢调整。brightness 是提供明暗辅助信息，因此权重要小，0.3~0.5 之间就好，引导时机也要拉小，0.3~0.8 之间，最开始我都设置 0.65~0.8。</p><p></p><p>然后写上提示词，就可以进行艺术二维码的创作了。</p><p></p><p><code lang=\"javascript\">model: RevAnimated\npositive: ((Masterpiece, best quality, edge quality)),edgie,landscape,fairies,There is a coconut tree on an isolated island,and a group of fairies live on it,drawn in edgFae style,wearing edge,cloud,the sky,sea mew,\nseed: 2702996596\n\nnegative prompt: (worst quality, low quality:1.4),negative_hand Negative Embedding,verybadimagenegative_v1.3,2girls,nsfw:1.4,bad anatomy,bad hands,cropped,missing fingers,too many fingers,missing arms,long neck,Humpbacked,deformed,disfigured,poorly drawn face,distorted face,mutation,mutated,extra limb,ugly,poorly drawn hands,missing limb,floating limbs,disconnected limbs,malformed hands,out of focus,long body,missing toes,too many toes,monochrome,symbol,text,logo,door frame,window frame,mirror frame\n\nqrcode 1.0 0~1\ncontrolnet brightness 0.35 0.65~0.83\n</code></p><p></p><p>下面就是我随手创建的一张，既可以扫描，也可以长按识别。当然你也可以继续丰富提示词，让画面更加的精美。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/58/58a4df96fc04b50417eaa6875a30e682.png\" /></p><p></p><p></p><p>艺术二维码的生成难度主要在于调试上，一般有两种情形</p><p></p><p>生成图像直接扫不出来，那建议拉大 qrcode 权重，或者更换种子生成图像能扫出来，却没法长按识别，建议拉大引导时机，如果还不行，建议换种子</p><p></p><p>把握住这两点，慢慢的你就可以调控出属于自己的 AI 艺术二维码。</p><p></p><h3>海报绘制</h3><p></p><p>Canny 的效果其实可以做很有意思的操作，前段时间，我在 B 站看到一个海报的生成模式。它是这样一种生产方式，我认为还是挺科学的。</p><p></p><p>首先在 PS 中搭建一个基础场景，然后传入文生图，使用 canny 进行控制。canny 的阈值根据自己所需来设置，由于我想要丰满草地细节，因此选择了默认。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0d/0d33544623f1e5acad39e7b8d63e0913.jpeg\" /></p><p></p><p>提示词参数</p><p></p><p><code lang=\"javascript\">model: RevAnimated\npositive prompt: a bottle of milk,preventing smashing on the grass,put it on the grass,green grassland,how many cows are there on the grass,cow,there is a stream in front of the grassland,clear river water,hills,sky,sunlight,available light,nature,landscape,highres,\nnagetive prompt: NSFW,text,blurry,low quality,bad anatomy,lowres,monochrome,worstquality,watermark,bad proportions,out of focus,\nSampler Steps: 30\nSampler Method: DPM++ 2M Karras(偏写实)\nControlnet: canny 100~200\n540*960\nseed: 3493080894\n</code></p><p></p><p>加入<a href=\"https://www.liblib.art/modelinfo/5f5a284674544dbaa75c34ae503187d3\">草场 Lora</a>\"，别设置太高的权重，使草场更生动使用 ControlNet Tile + 脚本进行放大，得到高清图像最后再去 PS 精修，替换掉中间经过生成变动很大的牛奶</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/36/3635bc5c3712d195c2d3369484d33263.jpeg\" /></p><p></p><p>以 AI 绘制掌控整体的大背景，然后再借助 PS 修改小细节，这样的融合度和画面的呈现都都会好特别多，一种不错的海报制作方式，记录一下。</p><p></p><h3>Ip-Adapter</h3><p></p><p>Ip-Adapter 是今年刚出的一个 ControlNet，它的效果让我惊喜，也让我恐惧，AI 进化的速度超乎我的想象。</p><p></p><p>Ip-Adapter 你不用知道它的原理，你就知道它能非常完善的提取图像的画风，提出的还原度超级高。</p><p></p><p>例如下面的案例，我甚至都不用写 prompt，只需要配置上 Ip-Adapter 和 canny，前者提供风格，后者提供内容，一键复刻，内容就和风格完美统一。</p><p></p><p><code lang=\"js\">Model: majicmixRealistic_v7\nSteps: 20\nSampler: DPM++ 2M Karras\nCFG scale: 7\nSeed: 745903371\nSize: 640x1136\nControlNet 0: ip-adapter, Weight: 1, Guidance Start: 0.2, Guidance End: 0.8\nControlNet 1: canny, Weight: 0.75,  Guidance Start: 0, Guidance End: 1,\nControlNet 2: depth_midas, Weight: 0.3, Guidance Start: 0.3, Guidance End: 0.65\n</code></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/00/00640df18e53dff6d2ab1ede18417827.jpeg\" /></p><p></p><p>除了人像风格的融合，在建筑设计领域，我感受到了 ip-adapter 深深的潜力，一套线稿，我可以随便拿风格来套，这不就是云装修吗？</p><p></p><p></p><blockquote>当然也可以书写提示词，能帮助 AI 绘图更好的划定重点。</blockquote><p></p><p></p><h2>AI 绘画总结与预测</h2><p></p><p>经过半年多对 AI 绘画的体验，有了好多感想，也有了几丝惧怕，AI 的时代就这样一步一步地靠近我们，不日必将石破天惊。同时也让我想到了闲鱼上很多售卖 AI 绘画的商家，其实大多都是特别简单的原理，如果你不了解，很容易被唬住，AI 没有那么难，而且它会越来越便利，因此，学起来吧，扬帆起航，美好的就在不远处。不会画画的你，也可以成为马良。</p><p></p><p>以最近比较重大的更新入手，来预测 24 年 AI 绘画走向。</p><p></p><p>LCM 采样方法的提出，出图速度飙升，五步成图；无独有偶，前段时间 TensorRT 发布，出图快 3-4 倍。Ip-Adapter ControlNet 的推行，画风轻松移植，甚至无需 Prompt 和多余 LoraAnimateDiffV3 发布，更优质的 AI 视频体验，效果更优SD XL 发布，Prompt 更简单，生成效果更好</p><p></p><p>AI 绘画在飞速发展的 2023 年，展现出两大特点：</p><p></p><p>更高的效率，提高模型运转的效率，降低对算力需求更简单的操作，对参数的依赖越来越少，操作越来越简单的</p><p></p><p>在 2024 年，我认为有几大趋势：</p><p></p><p>模型的进一步压缩，减少模型的参数数量来降低计算和内存需求；算法进一步提升，1s 出图不是梦AI 绘画过程进一步简化，不在局限于复杂的 Prompt，更具个性化创作comfyui 流程简化，正式成为生图或者视频的极佳工具AI 生成视频不断进步，一火冲天AI 与虚拟现实和增强现实，3D 可视化等技术进一步融合</p><p></p><p>如果是 2023 是绘画元年，2024 我相信会是视频元年，全民绘画元年。拥抱 AI，就是在拥抱未来的机会。</p>",
    "publish_time": "2023-12-29 09:33:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "一文搞懂Go GC演进史，讲的太细致了！",
    "url": "https://www.infoq.cn/article/f56b419e9de2e8ca3d44ee0ce",
    "summary": "<p>最近在和 <a href=\"https://mp.weixin.qq.com/s/ibD4u4WSJqcgzXObZ9MOJA\">Go就业训练营</a>\" 的朋友讨论Go GC的问题，发现了刘丹冰老师总结的内容，写的太好了，和大家分享一下。</p><p></p><p>我们的讨论和思考也整理到这篇文章中了，希望对你有启发。</p><p></p><p></p><blockquote>垃圾回收(Garbage Collection，简称GC)是编程语言中提供的自动的内存管理机制，自动释放不需要的内存对象，让出存储器资源。GC过程中无需程序员手动执行。GC机制在现代很多编程语言都支持，GC能力的性能与优劣也是不同语言之间对比度指标之一。</blockquote><p></p><p></p><p>Golang在GC的演进过程中也经历了很多次变革，Go V1.3之前的标记-清除(mark and sweep)算法。Go V1.3之前的标记-清扫(mark and sweep)的缺点。</p><p></p><p>大家可以重点关注以下版本的变化：</p><p></p><p>Go V1.5的三色并发标记法Go V1.5的三色标记为什么需要STWGo V1.5的三色标记为什么需要屏障机制(“强-弱” 三色不变式、插入屏障、删除屏障 )Go V1.8混合写屏障机制Go V1.8混合写屏障机制的全场景分析</p><p></p><h3>一、Go V1.3之前的标记-清除(mark and sweep)算法</h3><p></p><p>接下来我们来看一下在Golang1.3之前的时候主要用的普通的标记-清除算法，此算法主要有两个主要的步骤：</p><p></p><p>标记(Mark phase)清除(Sweep phase)</p><p></p><h4>1 标记清除算法的具体步骤</h4><p></p><p>第一步，暂停程序业务逻辑, 分类出可达和不可达的对象，然后做上标记。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d7/d78be6fd9c53894c6cc27b7fbf363a9a.png\" /></p><p></p><p>图中表示是程序与对象的可达关系，目前程序的可达对象有对象1-2-3，对象4-7等五个对象。</p><p></p><p>第二步, 开始标记，程序找出它所有可达的对象，并做上标记。如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e3/e3a317b9c1311191543a66de23187c60.png\" /></p><p></p><p>所以对象1-2-3、对象4-7等五个对象被做上标记。</p><p></p><p>第三步, &nbsp;标记完了之后，然后开始清除未标记的对象. 结果如下。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/87/879e329928ccfdbcbf3932cadfd886a9.png\" /></p><p></p><p>操作非常简单，但是有一点需要额外注意：mark and sweep算法在执行的时候，需要程序暂停！即 STW(stop the world)，STW的过程中，CPU不执行用户代码，全部用于垃圾回收，这个过程的影响很大，所以STW也是一些回收机制最大的难题和希望优化的点。所以在执行第三步的这段时间，程序会暂定停止任何工作，卡在那等待回收执行完毕。</p><p></p><p>第四步, 停止暂停，让程序继续跑。然后循环重复这个过程，直到process程序生命周期结束。</p><p></p><p>以上便是标记-清除（mark and sweep）回收的算法。</p><p></p><h4>2 标记-清除(mark and sweep)的缺点</h4><p></p><p>标记清除算法明了，过程鲜明干脆，但是也有非常严重的问题。</p><p></p><p>STW，stop the world；让程序暂停，程序出现卡顿 (重要问题) ；标记需要扫描整个heap；清除数据会产生heap碎片。</p><p></p><p>Go V1.3版本之前就是以上来实施的, &nbsp;在执行GC的基本流程就是首先启动STW暂停，然后执行标记，再执行数据回收，最后停止STW，如图所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fd/fdd7862757320f10baa8ada9ad409cb2.png\" /></p><p></p><p>从上图来看，全部的GC时间都是包裹在STW范围之内的，这样貌似程序暂停的时间过长，影响程序的运行性能。所以Go V1.3 做了简单的优化,将STW的步骤提前, 减少STW暂停的时间范围。如下所示</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c2/c2a5bdc3703cb85420da28eca8905167.png\" /></p><p></p><p>上图主要是将STW的步骤提前了一步，因为在Sweep清除的时候，可以不需要STW停止，因为这些对象已经是不可达对象了，不会出现回收写冲突等问题。</p><p></p><p>但是无论怎么优化，Go V1.3都面临这个一个重要问题，就是mark-and-sweep 算法会暂停整个程序 。</p><p></p><p>Go是如何面对并这个问题的呢？接下来G V1.5版本 就用三色并发标记法来优化这个问题.</p><p></p><h3>三、Go V1.5的三色并发标记法</h3><p></p><p>Golang中的垃圾回收主要应用三色标记法，GC过程和其他用户goroutine可并发运行，但需要一定时间的STW(stop the world) ，所谓三色标记法实际上就是通过三个阶段的标记来确定清楚的对象都有哪些？我们来看一下具体的过程。</p><p></p><p>第一步 , 每次新创建的对象，默认的颜色都是标记为“白色”，如图所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/61/61be2a51722d13b06991b645c49facbd.png\" /></p><p></p><p>上图所示，我们的程序可抵达的内存对象关系如左图所示，右边的标记表，是用来记录目前每个对象的标记颜色分类。这里面需要注意的是，所谓“程序”，则是一些对象的根节点集合。所以我们如果将“程序”展开，会得到类似如下的表现形式，如图所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/41/41df89703347ad03ee255e0feefaf833.png\" /></p><p></p><p>第二步, 每次GC回收开始, 会从根节点开始遍历所有对象，把遍历到的对象从白色集合放入“灰色”集合如图所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cc/cc316cc57abca1c4358d473d5dc2f01e.png\" /></p><p></p><p>这里 要注意的是，本次遍历是一次遍历，非递归形式，是从程序抽次可抵达的对象遍历一层，如上图所示，当前可抵达的对象是对象1和对象4，那么自然本轮遍历结束，对象1和对象4就会被标记为灰色，灰色标记表就会多出这两个对象。</p><p></p><p>第三步, 遍历灰色集合，将灰色对象引用的对象从白色集合放入灰色集合，之后将此灰色对象放入黑色集合，如图所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/44/44dd0a34f8c37f30cd26ed2ba7f54990.png\" /></p><p></p><p>这一次遍历是只扫描灰色对象，将灰色对象的第一层遍历可抵达的对象由白色变为灰色，如：对象2、对象7. 而之前的灰色对象1和对象4则会被标记为黑色，同时由灰色标记表移动到黑色标记表中。</p><p></p><p>第四步, 重复第三步, 直到灰色中无任何对象，如图所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b0/b0cb5cdac2251b610dc6da92ae60ce47.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8e/8e86151feaf9de2eef80ff757877c4e2.png\" /></p><p></p><p>当我们全部的可达对象都遍历完后，灰色标记表将不再存在灰色对象，目前全部内存的数据只有两种颜色，黑色和白色。那么黑色对象就是我们程序逻辑可达（需要的）对象，这些数据是目前支撑程序正常业务运行的，是合法的有用数据，不可删除，白色的对象是全部不可达对象，目前程序逻辑并不依赖他们，那么白色对象就是内存中目前的垃圾数据，需要被清除。</p><p></p><p>第五步: 回收所有的白色标记表的对象. 也就是回收垃圾，如图所示。</p><p></p><p>以上我们将全部的白色对象进行删除回收，剩下的就是全部依赖的黑色对象。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f4/f444233c6e8c58d42364e8b05186af6e.png\" /></p><p></p><p>以上便是三色并发标记法，不难看出，我们上面已经清楚的体现三色的特性。但是这里面可能会有很多并发流程均会被扫描，执行并发流程的内存可能相互依赖，为了在GC过程中保证数据的安全，我们在开始三色标记之前就会加上STW，在扫描确定黑白对象之后再放开STW。但是很明显这样的GC扫描的性能实在是太低了。</p><p></p><p>那么Go是如何解决标记-清除(mark and sweep)算法中的卡顿(stw，stop the world)问题的呢？</p><p></p><h3>四、没有STW的三色标记法</h3><p></p><p>先抛砖引玉，我们加入如果没有STW，那么也就不会再存在性能上的问题，那么接下来我们假设如果三色标记法不加入STW会发生什么事情？</p><p></p><p>我们还是基于上述的三色并发标记法来说, 他是一定要依赖STW的. 因为如果不暂停程序, 程序的逻辑改变对象引用关系, 这种动作如果在标记阶段做了修改，会影响标记结果的正确性，我们来看看一个场景，如果三色标记法, 标记过程不使用STW将会发生什么事情?</p><p></p><p>我们把初始状态设置为已经经历了第一轮扫描，目前黑色的有对象1和对象4， 灰色的有对象2和对象7，其他的为白色对象，且对象2是通过指针p指向对象3的，如图所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5f/5f24629dd056e8f915312245b34bb6c0.png\" /></p><p></p><p>现在如何三色标记过程不启动STW，那么在GC扫描过程中，任意的对象均可能发生读写操作，如图所示，在还没有扫描到对象2的时候，已经标记为黑色的对象4，此时创建指针q，并且指向白色的对象3。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2f/2fd5d9b0abc029b91d69637bdbca40cb.png\" /></p><p></p><p>与此同时灰色的对象2将指针p移除，那么白色的对象3实则就是被挂在了已经扫描完成的黑色的对象4下，如图所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4a/4ab73232f1bba20e21eeb22f87f0ccc2.png\" /></p><p></p><p>然后我们正常指向三色标记的算法逻辑，将所有灰色的对象标记为黑色，那么对象2和对象7就被标记成了黑色，如图所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2a/2a26545db75997839c0dd62e4d032050.png\" /></p><p></p><p>那么就执行了三色标记的最后一步，将所有白色对象当做垃圾进行回收，如图所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/83/83f339e7ca79feceae4927f5e0b6e48c.png\" /></p><p></p><p>但是最后我们才发现，本来是对象4合法引用的对象3，却被GC给“误杀”回收掉了。</p><p></p><p>可以看出，有两种情况，在三色标记法中，是不希望被发生的。</p><p></p><p>条件1: 一个白色对象被黑色对象引用 (白色被挂在黑色下)条件2: 灰色对象与它之间的可达关系的白色对象遭到破坏 (灰色同时丢了该白色)如果当以上两个条件同时满足时，就会出现对象丢失现象!</p><p></p><p>并且，如图所示的场景中，如果示例中的白色对象3还有很多下游对象的话, 也会一并都清理掉。</p><p></p><p>为了防止这种现象的发生，最简单的方式就是STW，直接禁止掉其他用户程序对对象引用关系的干扰，但是STW的过程有明显的资源浪费，对所有的用户程序都有很大影响。那么是否可以在保证对象不丢失的情况下合理的尽可能的提高GC效率，减少STW时间呢？答案是可以的，我们只要使用一种机制，尝试去破坏上面的两个必要条件就可以了。</p><p></p><h3>五、屏障机制</h3><p></p><p>我们让GC回收器，满足下面两种情况之一时，即可保对象不丢失。 &nbsp;这两种方式就是“强三色不变式”和“弱三色不变式”。</p><p></p><h4>(1) “强-弱” 三色不变式</h4><p></p><p>强三色不变式</p><p></p><p>不存在黑色对象引用到白色对象的指针。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/18/18cacdf678cf497c0f8c79f43251cd35.png\" /></p><p></p><p>强三色不变色实际上是强制性的不允许黑色对象引用白色对象，这样就不会出现有白色对象被误删的情况。</p><p></p><p>弱三色不变式</p><p></p><p>所有被黑色对象引用的白色对象都处于灰色保护状态。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b0/b03771905fed5af393af72473d222eee.png\" /></p><p></p><p>弱三色不变式强调，黑色对象可以引用白色对象，但是这个白色对象必须存在其他灰色对象对它的引用，或者可达它的链路上游存在灰色对象。 这样实则是黑色对象引用白色对象，白色对象处于一个危险被删除的状态，但是上游灰色对象的引用，可以保护该白色对象，使其安全。</p><p></p><p>为了遵循上述的两个方式，GC算法演进到两种屏障方式，他们“插入屏障”, “删除屏障”。</p><p></p><h4>(2) &nbsp;插入屏障</h4><p></p><p>具体操作: 在A对象引用B对象的时候，B对象被标记为灰色。(将B挂在A下游，B必须被标记为灰色)</p><p></p><p>满足: 强三色不变式. (不存在黑色对象引用白色对象的情况了， 因为白色会强制变成灰色)</p><p></p><p>伪码如下:</p><p></p><p><code lang=\"text\">添加下游对象(当前下游对象slot, 新下游对象ptr) {   \n  //1\n  标记灰色(新下游对象ptr)   \n  \n  //2\n  当前下游对象slot = 新下游对象ptr            \n}\n</code></p><p></p><p>场景：</p><p></p><p><code lang=\"text\">A.添加下游对象(nil, B)   //A 之前没有下游， 新添加一个下游对象B， B被标记为灰色\nA.添加下游对象(C, B)     //A 将下游对象C 更换为B，  B被标记为灰色\n</code></p><p></p><p>这段伪码逻辑就是写屏障,. 我们知道,黑色对象的内存槽有两种位置, 栈和堆. 栈空间的特点是容量小,但是要求相应速度快,因为函数调用弹出频繁使用, 所以“插入屏障”机制,在栈空间的对象操作中不使用. 而仅仅使用在堆空间对象的操作中.</p><p></p><p>接下来，我们用几张图，来模拟整个一个详细的过程， 希望您能够更可观的看清晰整体流程。</p><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4d/4d65d60a920e04ba07a422500ff4e413.png\" /></p><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/46/46b6e05f8015c097f0d48206afd1e31b.png\" /></p><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ae/ae6a133267175b2fb79d332a52de5f45.png\" /></p><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b1/b15bcfb8e7798b5c8117f8a365d98f1b.png\" /></p><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fc/fcb1fe6cc35c3a413eceeca16a061cc3.png\" /></p><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1e/1eaebcb80e23459f878c522b2e4927d7.png\" /></p><p></p><p>但是如果栈不添加,当全部三色标记扫描之后,栈上有可能依然存在白色对象被引用的情况(如上图的对象9). &nbsp;所以要对栈重新进行三色标记扫描, 但这次为了对象不丢失, 要对本次标记扫描启动STW暂停. 直到栈空间的三色标记结束.</p><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d5/d5b4d0ec8574ea0411c753a8e65c6d51.png\" /></p><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/db/db11ab5527ef1dfe03ce927f304f6f03.png\" /></p><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bd/bd1acf7ebdab2c7e811122a92b63c095.png\" /></p><p></p><p></p><p></p><p>最后将栈和堆空间 扫描剩余的全部 白色节点清除. &nbsp;这次STW大约的时间在10~100ms间.</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e2/e2a9554860b6544a2b65791cd8bf66a3.png\" /></p><p></p><p></p><p></p><h4>(3) &nbsp;删除屏障</h4><p></p><p>具体操作: 被删除的对象，如果自身为灰色或者白色，那么被标记为灰色。</p><p></p><p>满足: 弱三色不变式. (保护灰色对象到白色对象的路径不会断)</p><p></p><p>伪代码：</p><p></p><p><code lang=\"text\">添加下游对象(当前下游对象slot， 新下游对象ptr) {\n  //1\n  if (当前下游对象slot是灰色 || 当前下游对象slot是白色) {\n      标记灰色(当前下游对象slot)     //slot为被删除对象， 标记为灰色\n  }\n  \n  //2\n  当前下游对象slot = 新下游对象ptr\n}\n</code></p><p></p><p>场景：</p><p></p><p><code lang=\"text\">A.添加下游对象(B, nil)   //A对象，删除B对象的引用。  B被A删除，被标记为灰(如果B之前为白)\nA.添加下游对象(B, C)     //A对象，更换下游B变成C。   B被A删除，被标记为灰(如果B之前为白)\n</code></p><p></p><p>接下来，我们用几张图，来模拟整个一个详细的过程， 希望您能够更可观的看清晰整体流程。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/be/beec3726a02a2447772bc03d945b4e4c.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/46/46d4b5e2cf9134caba93d5b5049c788d.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a2/a228aca80de9186b57a9960335ff4a1f.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c7/c77bce4c2ae19bc7dd6186f3641f4ca5.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b8/b86ef08f918e09d4fedf53846bfb6016.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f8/f820515eb6289211150751fb0f3e529c.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4f/4f21348b58da462983ac456798f12976.png\" /></p><p></p><p>这种方式的回收精度低，一个对象即使被删除了最后一个指向它的指针也依旧可以活过这一轮，在下一轮GC中被清理掉。</p><p></p><h3>六、Go V1.8的混合写屏障(hybrid write barrier)机制</h3><p></p><p>插入写屏障和删除写屏障的短板：</p><p></p><p>插入写屏障：结束时需要STW来重新扫描栈，标记栈上引用的白色对象的存活；删除写屏障：回收精度低，GC开始时STW扫描堆栈来记录初始快照，这个过程会保护开始时刻的所有存活对象。</p><p></p><p>Go V1.8版本引入了混合写屏障机制（hybrid write barrier），避免了对栈re-scan的过程，极大的减少了STW的时间。结合了两者的优点。</p><p></p><p></p><p></p><h4>(1) 混合写屏障规则</h4><p></p><p>具体操作:</p><p></p><p>1、GC开始将栈上的对象全部扫描，并将全部可达对象标记为黑色(之后不再进行第二次重复扫描，无需STW)，</p><p></p><p>2、GC期间，任何在栈上创建的新对象，均为黑色。</p><p></p><p>3、被删除的对象标记为灰色。</p><p></p><p>4、被添加的对象标记为灰色。</p><p></p><p>满足: 变形的弱三色不变式.</p><p></p><p>伪代码：</p><p></p><p><code lang=\"text\">添加下游对象(当前下游对象slot, 新下游对象ptr) {\n    //1 \n    标记灰色(当前下游对象slot)    //只要当前下游对象被移走，就标记灰色\n    \n    //2 \n    标记灰色(新下游对象ptr)\n      \n    //3\n    当前下游对象slot = 新下游对象ptr\n}\n</code></p><p></p><p>这里我们注意， 屏障技术是不在栈上应用的，因为要保证栈的运行效率。</p><p></p><h4>(2) 混合写屏障的具体场景分析</h4><p></p><p>接下来，我们用几张图，来模拟整个一个详细的过程， 希望您能够更可观的看清晰整体流程。</p><p></p><p>注意混合写屏障是Gc的一种屏障机制，所以只是当程序执行GC的时候，才会触发这种机制。</p><p></p><h5>GC开始：扫描栈区，将可达对象全部标记为黑</h5><p></p><p><img src=\"https://static001.geekbang.org/infoq/fc/fcd25baa186071fed498a3f354136df3.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/df/dfd3701c019976805deb733108d570be.png\" /></p><p></p><p></p><p></p><h5>场景一： 对象被一个堆对象删除引用，成为栈对象的下游</h5><p></p><p>伪代码</p><p></p><p><code lang=\"text\">//前提：堆对象4-&gt;对象7 = 对象7；  //对象7 被 对象4引用\n栈对象1-&gt;对象7 = 堆对象7；  //将堆对象7 挂在 栈对象1 下游\n堆对象4-&gt;对象7 = null；    //对象4 删除引用 对象7\n</code></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5e/5ec3afdb1259d673f2b56e5b0fddeae2.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/93/93f85047554c7a348112f66b27a6706b.png\" /></p><p></p><h5>场景二： 对象被一个栈对象删除引用，成为另一个栈对象的下游</h5><p></p><p>伪代码</p><p></p><p><code lang=\"text\">new 栈对象9；\n对象8-&gt;对象3 = 对象3；      //将栈对象3 挂在 栈对象9 下游\n对象2-&gt;对象3 = null；      //对象2 删除引用 对象3\n</code></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e6/e69eb071412e9b5c5583af785a6cdd16.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c5/c5725832d938a4b31a28cd6c42cb1724.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/51/5161f063b7115f8825cf6f92b307b1f0.png\" /></p><p></p><p>延伸一下：提出我们的疑问</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a3/a36a8504bae3e9af5a7a66a34945f84d.png\" /></p><p></p><p>如上图所示：如果对象9引用对象5，栈上没有屏障，对象5最终还是白色的 这样不会造成误删除吗？混合写屏障是对堆使用的，对栈不使用，如果栈中黑色对象引用一个白色对象，没有写屏障，最后白色的要被回收的，我们对此造成了困扰。</p><p></p><p>经过调研以及和刘丹冰老师请教之后得出结论：</p><p></p><p>不会出现这种情况，对象9是看不见对象5的，是不可达的，如果对象5是可达对象就不会变成白色了。</p><p></p><p>白色表示已经断链了，是引用不到的，否则在STW遍历期间，就不会被标记为白色了。</p><p></p><p>再思考一下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/51/5161f063b7115f8825cf6f92b307b1f0.png\" /></p><p></p><p>假如对象2删掉对对象3的引用，且没有新的对象重新引用3，对象3在这一轮GC中是否会被回收？</p><p></p><p>屏障机制不会应用在栈上，那么在这一轮中就不会被回收，要下次扫描才会被标记为白色。</p><p></p><h5>场景三：对象被一个堆对象删除引用，成为另一个堆对象的下游</h5><p></p><p>伪代码</p><p></p><p><code lang=\"text\">堆对象10-&gt;对象7 = 堆对象7；       //将堆对象7 挂在 堆对象10 下游\n堆对象4-&gt;对象7 = null；         //对象4 删除引用 对象7\n</code></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0c/0c284b2e1812ce67ae78cc896d86c7e6.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/36/3658fa84fc95851f6ee6d8b0d4ce849a.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0b/0b8f0a004ff8c6bc6972a0ca7717e8cd.png\" /></p><p></p><h5>场景四：对象从一个栈对象删除引用，成为另一个堆对象的下游</h5><p></p><p>伪代码</p><p></p><p><code lang=\"text\">堆对象10-&gt;对象7 = 堆对象7；       //将堆对象7 挂在 堆对象10 下游\n堆对象4-&gt;对象7 = null；         //对象4 删除引用 对象7\n</code></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cf/cf47fc37281491d8710681bf3e248a91.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0f/0fcac0a74c07c6c55661cea95bc6a800.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f3/f33daa0d3afe4efa0f3906a5690c0ff0.png\" /></p><p></p><p>Golang中的混合写屏障满足弱三色不变式，结合了删除写屏障和插入写屏障的优点，只需要在开始时并发扫描各个goroutine的栈，使其变黑并一直保持，这个过程不需要STW，而标记结束后，因为栈在扫描后始终是黑色的，也无需再进行re-scan操作了，减少了STW的时间。</p><p></p><h3>七、总结</h3><p></p><p>以上便是Golang的GC全部的标记-清除逻辑及场景演示全过程。</p><p></p><p>GoV1.3- 普通标记清除法，整体过程需要启动STW，效率极低。</p><p></p><p>GoV1.5- 三色标记法， 堆空间启动写屏障，栈空间不启动，全部扫描之后，需要重新扫描一次栈(需要STW)，效率普通</p><p></p><p>GoV1.8-三色标记法，混合写屏障机制， 栈空间不启动，堆空间启动。整个过程几乎不需要STW，效率较高。</p><p></p><h3>版权说明</h3><p></p><p>本文内容经作者授权转载</p><p></p><p>原文链接：https://www.yuque.com/aceld/golang/zhzanb</p><p></p><h3>一起学习</h3><p></p><p>我的文章会首发在同名公众号，欢迎关注：<a href=\"https://mp.weixin.qq.com/s/ibD4u4WSJqcgzXObZ9MOJA\">王中阳Go</a>\"</p>",
    "publish_time": "2023-12-29 09:58:50",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "深入探究音视频开源库WebRTC中NetEQ音频抗网络延时与抗丢包的实现机制 | 主赛道",
    "url": "https://www.infoq.cn/article/e7c02c015cd06cae82c6054f0",
    "summary": "<p></p><p></p><p>音视频软件随着应用场景和使用环境的变化，对音频的质量要求越来越高，要实现高质量的音频效果，可以借鉴音视频领域一些成熟的解决方案。WebRTC正是目前解决话音质量最先进的语音引擎之一，其中NetEQ网络均衡器模块很好地解决了音频数据在低带宽下出现的延迟、抖动与丢包问题。本文将详细分析WebRTC中NetEQ网络均衡器的实现原理、处理流程以及丢包补偿处理机制。</p><p></p><p>1、引言</p><p></p><p>由于IP网络主要用于数据传输业务，与传统的电话占用独立的逻辑或物理线路不同，因此没有服务质量（Qos）保证，存在包乱序到达、延迟、丢包和抖动等问题。对于丢包，业务上可以采用重传或者多倍发送机制，但音视频软件都是实时业务，对带宽、时延和抖动有严格的要求，所以必须有一定的Qos保证。</p><p></p><p>音视频软件中影响音频质量主要有两个因素：时延抖动和丢包处理。一般通过抖动缓冲区来消除网络传输所带来的不良影响，抖动缓冲区技术直接影响丢包处理。接收缓冲区可以用来消除时延抖动，但如果发生丢包，会卡顿或者填静音或者插值补偿，但在时延大、抖动大、丢包严重的网络中，效果都不理想。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7a/7a077f3a9dfa7c24f5d4380511c9136c.png\" /></p><p></p><p></p><p>如何借用WebRTC中的NetEQ网络均衡器的技术来提高软件的音频质量，首先需要分析分解NetEQ的原理和处理流程，其次是了解丢包补偿算法的原理和使用场景，然后就是将之有效到应用到软件产品的设计中去。</p><p></p><p>2、WebRTC简介</p><p></p><p>在详细介绍WebRTC中的NetEQ网络均衡器之前，我们先来大概地了解以下WebRTC。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5d/5dd3158b7e80b245b0a77d2cae124f0f.png\" /></p><p></p><p></p><p>WebRTC（Web Real-Time Communication）是一个由Google发起的实时音视频通讯C++开源库，其提供了音视频采集、编码、网络传输，解码显示等一整套音视频解决方案，我们可以通过该开源库快速地构建出一个音视频通讯应用。</p><p></p><p>一个实时音视频应用软件一般都会包括这样几个环节：音视频采集、音视频编码（压缩）、前后处理（美颜、滤镜、回声消除、噪声抑制等）、网络传输、解码渲染（音视频播放）等。其中每一个细分环节，还有更细分的技术模块。</p><p></p><p>虽然其名为WebRTC，但是实际上它不光支持Web之间的音视频通讯，还支持Windows、Android以及iOS等移动平台。WebRTC底层是用C/C++开发的，具有良好的跨平台性能。</p><p></p><p>l&nbsp;WebRTC主要使用C++开发实现，代码中大量使用了C++11及以上的新特性，在阅读源码之前需要大概地了解C++的这些新特性。</p><p></p><p>l&nbsp;学习C++11新特性很有必要，不仅在C++开源代码中会频繁地使用到新特性，在跳槽时的笔试面试时也会经常被问到。</p><p></p><p>l&nbsp;推荐大家仔细研读一下新版的、免费公开的《Google 开源项目风格指南（zh-google-styleguide） 》，它不仅仅是Googe的编码规范，它不仅告诉你编码时要怎么做，还告诉你为什么要这么做！对于学习C++11及以上的新特性也很有好处！这本项目风格指南，我们项目大组去年系统地研读过，收获很大，很有参考价值！</p><p></p><p>WebRTC因为其较好的音视频效果及良好的网络适应性，目前已被广泛的应用到视频会议、实时音视频直播等领域中。在视频会议领域，腾讯会议、华为WeLink、字节飞书、阿里钉钉、小鱼易连、厦门亿联等国产厂商均提供了基于WebRTC方案的视频会议。</p><p></p><p>大家熟知的音视频专业服务商声网（Agora），更是基于开源WebRTC库，提供了社交直播、教育、游戏电竞、IoT、AR/VR、金融、保险、医疗、企业协作等多个行业的音视频互动解决方案。使用声网服务的企业包括小米、陌陌、斗鱼、哔哩哔哩、新东方、小红书、HTC VIVE 、The Meet Group、Bunch、Yalla等遍布全球的巨头、独角兽及创业企业。除了头部公司声网之外，也陆续有多家公司基于开源的WebRTC，开发出了多个音视频应用，提供了多个领域的音视频通信解决方案。</p><p></p><p>3、什么是NetEQ？</p><p></p><p>NetEQ 本质上就是一个音频的 JitterBuffer（抖动缓冲器），全称是 Network Equalizer（网络均衡器）。</p><p></p><p>GIPS 语音引擎的两大核心技术之一就是包含丢包隐藏算法的高级自适应抖动缓冲器技术，称作 NetEQ。2010 年谷歌公司以6820万美元收购Global IP Solutions公司而获得的这项技术，另一个核心技术就是3A算法。随后，谷歌在2011年将其集成到 WebRTC 中对外开源发布。</p><p></p><p>NetEQ 集成了自适应抖动控制算法和语音丢包隐藏算法，并且与解码器进行集成，所以 NetEQ 能够在较高的丢包环境下始终能够保持较好的语音质量。</p><p></p><p>4、NetEQ技术详解</p><p></p><p>4.1、NetEQ概述</p><p></p><p>NetEQ处理中包括了自适应抖动控制算法和语音丢包补偿算法。自适应抖动算法能够快速适应不断变化的网络环境，而语音丢包补偿算法能够保证一定的音质和清晰度且缓冲延迟最小，另外对NetEQ算法的模拟测试有助于评估音质效果和如何与现有软件设计的有机结合。</p><p></p><p>NetEQ处理中包括了自适应抖动控制算法和语音丢包补偿算法。自适应抖动算法能够快速适应不断变化的网络环境，而语音丢包补偿算法能够保证一定的音质和清晰度且缓冲延迟最小，另外对NetEQ算法的模拟测试有助于评估音质效果和如何与现有软件设计的有机结合。</p><p></p><p>NetEQ的模块概要图如下所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ff/ff5a538be63f2056cd4fa70206ce8be3.png\" /></p><p></p><p></p><p>从上图可以看出，NetEQ分为4部分：自适应缓冲（Adaptive packet buffer）、语音解码器（Speech decoder）、抖动控制和丢包补偿（Jitter control and error concealment）和播放（Play out）。其中抖动控制和丢包补偿模块是NetEQ的核心算法，既控制着自适应缓冲，又控制着解码器和丢包补偿算法，并且将最终的计算结果交给声卡去播放。</p><p></p><p>首先，NetEQ是目前最为完善的抖动消除技术。与固定抖动缓冲和传统的自适应抖动缓冲相比，NetEQ能够快速适应不断变化的网络环境，因此保证了更小的延迟和更少的丢包。NetEQ自适应抖动算法性能比较如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f1/f12e7961e027c6a94b9386f377a532db.png\" /></p><p></p><p></p><p>其次，抖动控制和和丢包补偿模块由三大操作所组成，即Expansion、Normal和Accelerate：</p><p></p><p>Expansion：扩展操作，即对语音时长的拉伸，其中包括expand和preemptive_expand两种模式。前者为NetEQ的丢包补偿处理，其作用是等待延迟包并补偿丢包；后者为优先扩展，即在原有数据的基础上拉伸语音时长，其作用是实现减速播放。</p><p></p><p>Normal：正常播放操作，即网络环境正常且相对平稳时的操作。</p><p></p><p>Accelerate：加速操作，即实现快速播放。</p><p></p><p>综上所述，本文主要讨论NetEQ的抖动消除和丢包补偿技术，并结合模拟测试和产品设计分析来进一步提高视频会议产品的通话音质。NetEQ性能列表如下所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ec/ece6d291b072e92d9acb451b157f1480.png\" /></p><p></p><p></p><p>4.2、抖动消除技术</p><p></p><p>有两种抖动的定义：</p><p></p><p>l&nbsp;抖动定义1：指由于各种延迟的变化导致网络中的数据分组到达速率的变化。具体地说，可将抖动定义为数据流在发送端发送间隔与接收端接收间隔之差，适用于可变码率场景。</p><p></p><p>l&nbsp;抖动定义2：接收端某个数据包到达间隔与平均数据包达到间隔之差定义为该数据包的延时抖动，使用于恒定码率场景。</p><p></p><p>抖动是一个零均值的随机序列，是由排队IP包的延迟时间差构成的。数据包堆积时意味着数据包提前到达，虽然保证了语音的完整性，但是容易造成接收端缓存溢出并且会增大端到端延迟。数据包超时时意味着数据包经过网络传输后，一段时间后仍未到达接收端，说明数据包可能会延迟到达或者丢包。由于溢出和超时均可导致丢包，会增加端到端的丢包概率。因此，必须对抖动进行有效的控制，以减少由此引起的丢包。</p><p></p><p>抖动通常采用抖动缓冲技术来消除，即在接收方建立一个缓冲区，语音包到达接收端时首先进入缓冲区暂存，随后系统再以平稳的速率将语音包从缓冲区提取出来，经解压后从音频端口播放。抖动消除的理想状态为：每个数据包在网络传输中的延迟与缓冲区中的所有缓冲数据的延迟应该相等，而缓冲区的大小应该与每个数据包提前到达的抖动加上缓冲数据的延迟之和相等。</p><p></p><p>抖动缓冲控制算法包括静态抖动缓冲和自适应缓冲抖动控制算法两类：</p><p></p><p>l&nbsp;静态抖动控制算法：缓冲区的延时和大小在语音通话建立后一直到通话结束，均为固定值，对于超时和抖动超出缓冲区大小的数据将会被丢弃。该算法模型简单，易于实现；但网络延时大、抖动大时，丢包率较高，而网络延时和抖动小时，语音延迟较大，不能根据网络状况动态改变缓冲区的延时和大小，而且初始值限定了适用的网络状况。</p><p></p><p>l&nbsp;自适应抖动控制算法：缓冲区的延时和大小随着实际网络的抖动情况而变化。接收端将当前收到的数据包的延迟与算法中保存的延迟信息相比较，得到当前网络的最大抖动，从而选择恰当的缓冲区延时和大小。该算法的优点是：网络抖动大时丢包率小，网络抖动小时延时小；缺点是算法多样且相对复杂。</p><p></p><p>考虑到当前网络的复杂多变，一般采用自适应抖动算法，NetEQ的抖动消除也属于这类算法。</p><p></p><p>4.3、丢包补偿技术</p><p></p><p>丢包补偿又称为丢包隐藏，即Packet Loss Concealment，简称为PLC，可以分为两类：基于发送端补偿和基于接收端补偿。丢包补偿技术构成如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/013b9916f175725a3baa74f84c45c0c8.png\" /></p><p></p><p></p><p>基于发送端的补偿也称为丢包恢复，即Packet Loss Recovery。一般来说，基于发送端的补偿要比基于接收端的补偿效果要好，但会增加网络带宽和时延。</p><p></p><p>FEC（Forward Error Correction，前向纠错技术）是目前最看好的一种改善VoIP语音质量的冗余编码技术，目的在于提高语音数据传输时的可靠性。为此FEC不仅要传输原始数据，同时还要根据相关性，传输一些冗余数据，以便使解码端根据数据之间的相关性重构丢失的数据包。在VoIP中最简单是奇偶校验码。这种方法是每个n-1个数据包就传输一个包含前面n个数据包的异或操作的校验码，当网络每n个数据包只丢失一个包时，可从别的n-1个数据包重构丢失的数据包。基于奇偶校验包的FEC如下所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1a/1a61bbe4efd9c9ac8d8de02d06bdbb05.png\" /></p><p></p><p></p><p>当发生连续丢包时，FEC等各种补偿技术的效果都不理想。为了抵抗大段的突发连续语音丢失，可采用交织（interleaving）技术。交织技术不是真正的丢包恢复技术，因为它不能恢复已经丢失的数据包，但是这种技术能够减少丢包带来的损失。交织技术是通过把原始数据分成若干个比IP包小的单元，在发送前，重新排序这些单元的顺序，使得每个IP包中的数据来自不同的语音帧，当发生丢帧时，只是每一帧的一部分数据丢失，不会出现一帧数据全部丢失现象，在接收端这些单元再重新排序。交织技术利用了人脑能够利用听觉感知自动恢复丢失的一部分数据的功能。当每帧数据只丢失少量数据时，对人耳听觉的影响较小，从而提高音质。由于没有输出额外的信息，所以不会增加带宽，但是由于需要在接收端重新排序，所以会增加时延，达到一定程度也会让人无法忍受。GSM系统就采用了交织技术。</p><p></p><p>交织技术如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b0/b02b1b38649044632e21f7bc3b43d80e.png\" /></p><p></p><p></p><p>低比特率冗余编码（Low-rate Redundant Coding）是一种冗余技术，每个数据包除了包含自身的数据外，还包含前一帧数据经过压缩后的复制，该复制质量低，占用比特数少。当接收端丢包后，可从后面的数据包利用这个复制快速重构丢失包。不像FEC增加的比特数与前后帧具有相关性，它只是简单的在后续包中一份复制，所以也会增加带宽和时延，但是在网络拥塞时与FEC一样，对于连续丢包不适用，会导致丢包更严重。G.729A就采用了冗余编码技术。冗余编码恢复丢包示意图如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e6/e683aabe0df4d9ee3373337e9becdf28.png\" /></p><p></p><p></p><p>接收端丢包补偿技术的基本原理是产生一个与丢失的语音包相似的替代语音，这种技术的可行性是基于语音的短时相似性和人耳的掩蔽效应，可以处理较小的丢包率（&lt;15%）和较小的语音包（4~40ms）。接收端的丢包补偿无法替代发送端的补偿，因为不能精确恢复丢失数据。因此网络丢包率较大的时候需要依赖发送端补偿技术，但是丢包率过大的时候只能优化网络。</p><p></p><p>基于插入的方法是指在丢包处插入一个简单的波形隐藏丢包的方法，这个波形通常与丢失的波形没有相关性，包括静音、白噪声和复制等。</p><p></p><p>静音替代使用范围非常有限，在丢包率低于2%且语音帧小于4ms时效果较好。白噪声或者舒适噪声利用了人脑下意识用正确语音修复丢失波形的能力，比静音效果好。</p><p></p><p>复制是GSM系统采用的方法，在发生连续丢包时，补偿的波形用上一帧数据通过逐渐衰减来生成，由于没有考虑语音的前后帧相关性，效果也不是很理想。插值技术是指在丢包时用相似的波形来补偿，这种技术相对复杂，利用丢包前后的数据对丢失数据进行估计，然后用最相似的波形替代丢失波形，所以效果比插入技术更好。</p><p></p><p>帧间插值技术是一种传统的误码隐藏技术。对于变换编码或线性预测编码的语音编码器，解码器可以基于语音信号的短时平稳性和相邻帧间参数的相关性，根据上一帧的参数进行插值来补偿。G.723.1就采用了参数插值技术，对LSP系数和激励信号分别进行帧间插值来补偿丢失帧；G.729也是利用上一帧的参数进行插值来隐藏错误帧的，利用上一帧的线性预测系数（LPC）和增益衰减系数来补偿丢失帧。</p><p></p><p>基于重构的补偿技术是通过丢包前后的解码信息来重构产生一个补偿包，计算量最大，效果最好。在接收端完成，不需要发送端的参与和额外的比特流，所以能够满足实时传输的要求，在现代网络传输中更具有有效性和实用性。</p><p></p><p>基于基音检测的波形替代技术是通过计算基音周期，然后根据基音周期对该帧进行清浊音判断，如果是清音，则用丢包前最近的波形替代，否则用丢包之前长度为基音周期的一段合适的波形来替代，再结合短时能量和过零率来恢复丢失语音，效果由于插入技术，但相对复杂。</p><p></p><p>数字语音信号处理的基本单位是基音，基音指物体振动时所发出的频率最低的音，其余为泛音。也就是发声体振动时，携带语音中的大部分能量，这种声带振动的频率称为基频，相应的周期为基音周期。基音周期的估计称为基音检测，其目的是得出和声带振动频率完全一致的基音周期长度。</p><p></p><p>采用波形编码的G.711编码器中没有使用丢包补偿技术，但为了提高语音质量，G.711协议附录中增加了基于基音检测的波形替代技术来补偿丢帧，它利用解码的上一帧数据来估计当前语音信号的基音周期，将最近的一个基音周期和它之前的1/4基音周期的数据用于补偿丢失数据。其中前1/4基音周期的数据用于与丢帧前的语音信号进行重叠相加，保证原始信号和补偿信号之间平滑过渡。若下一帧数据没有丢失，为了保证平滑过渡，则再拓展1/4基音周期数据与正常解码数据进行重叠相加。若下一帧仍然丢失，则多提取一个基音周期的数据用于补偿，最多可提取3个基音周期。丢帧越多，补偿语音与实际语音相差越大。因此，除第一帧外，连续丢帧补偿时，要以20%的速度逐帧衰减。由于语音信号是准平稳的时间序列，尤其是浊音信号，具有一定的周期性，因此采用丢帧前的语音数据重构丢帧数据效果更好。</p><p></p><p>时域修正技术采用缺口两侧的波形向切口方向延展来填充缺口，在缺口的任一侧找到基音周期的交叠矢量，偏移它们来覆盖缺口，交叠部分求均值。这种方式避免了缺口边界相位不连续的现象，在丢包结合处听不到爆破音，主观效果优于基音检测的波形替代。</p><p></p><p>WebRTC中NetEQ的丢包补偿技术是采用融合了iLBC算法的丢包补偿技术。iLBC全称为Internet Low Bit rate Codec，是GIPS开发的一种专为包交换网络通信设计的编解码算法，采样率为8khz，有20ms和30ms两种编码时长，码率分别为15.2kbps和13.3kbps，在丢包时具有强大健壮性。iLBC的丢包补偿只在解码端进行处理，采用基于模型恢复法产生补偿包，其具体步骤为：</p><p></p><p>l&nbsp;重建线性预测系数（LPC） ，即采用最后一帧的LPC系统来重建。因为无论空间上还是时间上，最后一帧都与当前丢失帧的LPC具有最相关性，但是这种简单的复制在处理连续丢帧时，显然会引入更大的失真。</p><p></p><p>l&nbsp;重建残差信号。残差信号通常可以分为两部分：准周期成分和类噪声成分。其中准周期成分可以根据上一帧的基音周期来近似得到，而类噪声成分则可以通过产生随机噪声得到，二者的能量比例也可以借鉴上一帧的比例关系。因此，首先要对上一帧进行基音检测，然后以基音同步的方式重建丢失帧的话音信号，接着利用相关性得到类噪声增益，最后进行混合以重建整个残差信号。</p><p></p><p>l&nbsp;在连续丢帧的情况下，PLC所补偿的各个语音帧具有相同的频谱特性（相同的LPC）和基音频率，为了减少各个补偿帧之间的相关性，会将能量进行逐帧递减。</p><p></p><p>OPUS的丢包补偿分为两种模式：CELT和SILK。OPUS编解码器是由互联网工程任务组（IETF）设计用于互联网的交互式语音和音频输出的，融合了Skype的SILK（与Skype现有SILK算法不兼容）和Xiph.Org的CELT技术。其中CELT模式的丢包补偿与iLBC的类似。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1e/1e5f8772e16e0cf11ee65e55948f27d4.png\" /></p><p></p><p></p><p>SILK编码器模块框架如下所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4b/4b80daf9ecb648508bcbe6fea82f2614.png\" /></p><p></p><p></p><p>4.4、NetEQ概要设计</p><p></p><p>NetEQ模块主要包括MCU和DSP两大处理单元，其中MCU（Micro Control Unit）模块是抖动缓冲区的控制单元，由于抖动缓冲区的作用是暂存接收数据，所以MCU主要作用是负责数据包的插入和控制数据包的输出。抖动消除技术包含在MCU控制模块中。</p><p></p><p>NetEQ概要设计如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6a/6a5795d4fd1cd76f69e5578719780714.png\" /></p><p></p><p></p><p>抖动缓冲区中设置240个插槽，每个从网络中传输过来的原始数据包都会在抖动缓冲区中选择一个合适的插槽进行放置，主要存储数据包的时间戳、序列号、数据类型等信息，而真正的数据载体存放于一个内存缓冲区中。当有新的数据包到达后，才在内存缓冲区中分配空间存放其载体，从而实现抖动消除。</p><p></p><p>DSP模块主要负责对从MCU中读取的数据包进行算法处理，包括解码、信号处理、数据输出等，丢包补偿技术包含在DSP模块中。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/83/83d69a181c0118a9ae3ad02f579ef431.png\" /></p><p></p><p></p><p>语音缓冲区中存储的是经过解码及信号处理的待播放数据，可以存储565个样本，curPosition表示待播放数据的起点，sampleLefe为待播放样本数。</p><p></p><p>共享内存、解码缓冲区和算法缓冲区都是临时数据缓冲区，其中共享内存用于暂存从抖动缓冲区中读取的待解码数据，并且存储样本丢失数量及MCU控制命令；解码缓冲区暂存解码后的数据；NetEQ算法缓冲区暂存DSP算法处理后的数据，用于补充语音缓冲区的新数据；播放缓冲区是播放驱动的数据缓冲区，用于从语音缓冲区中读取数据并播放。</p><p></p><p>4.5、NetEQ的命令机制</p><p></p><p>NetEQ的处理流程由各种命令来进行控制，根据接收数据包的状况，来决定采用什么命令：</p><p></p><p>l&nbsp;上一帧和当前帧都正常接收：这时数据包进入正常的处理流程，并将解码后的数据按照是否有抖动消除的需要来选择Normal、Accelerate或者Preemptive Expand。</p><p></p><p>l&nbsp;仅当前帧丢包或超时：如果当前帧丢包或超时，那么进入PLC处理重建LPC和残差信号，即Expand操作。NetEQ最多会为超时、丢包帧等待100ms，超过该时间则直接提取播放下一帧。</p><p></p><p>l&nbsp;连续多帧超时或丢包：如果连续多帧丢包，那么就需要多次进行PLC操作，这时越靠后的数据越难以准确重建补偿包，所以对连续丢包的补偿能量增益采取逐帧减少的方式，以避免引入更大的失真。</p><p></p><p>l&nbsp;上一帧丢失，当前帧正常：上一帧丢失，那么播放的上一帧数据是PLC补偿的。为了使经过PLC补偿的帧与正常解码的帧保持语音连续，需要根据前后帧的相关性进行平滑，这时选择Normal或者Merge。</p><p></p><p>此外，当NetEQ第一次接收到数据包或者整个NetEQ重置之后，会重置解码器。另一方面，当NetEQ接收超过延迟超过3.75s的数据包时，不会将其视为超时包丢弃，而是将其插入抖动缓冲区，并重置缓冲区状态。</p><p></p><p>4.6、NetEQ的播放机制</p><p></p><p>WebRTC的语音引擎运行时启动两个线程：一个线程接收数据包并插入抖动缓冲区；另一个线程每隔10ms从语音缓冲区中读取10ms数据进行播放。</p><p></p><p>NetEQ会结合语音缓冲区中的数据存量和抖动缓冲区中的数据存量来决定是否从抖动缓冲区中读取数据：</p><p></p><p>l&nbsp;控制命令为Normal、Expand、解码器重置或者packet buffer状态重置，且SampleLeft大于等于10ms时，则不从抖动缓冲区读取数据，DSP进行Normal操作。</p><p></p><p>l&nbsp;控制命令为Normal、解码器重置或者packet buffer状态重置，且SampleLeft小于10ms时，从抖动缓冲区读取数据后，DSP进行Normal操作。</p><p></p><p>l&nbsp;控制命令为Expand且SampleLeft小于10ms时，则不从抖动缓冲区读取数据，DSP进行Expand操作。</p><p></p><p>l&nbsp;控制命令为Merge时，从抖动缓冲区读取数据后，DSP进行Merge操作。</p><p></p><p>l&nbsp;控制命令为Accelerate时，当SampleLeft大于等于30ms，不从抖动缓冲区读取数据，DSP进行Accelerate操作；当SampleLeft大于等于10ms且小于30ms时，不同抖动缓冲区读取数据，DSP进行Normal操作；当SampleLeft小于10ms时，从抖动缓冲区读取数据后，DSP进行Accelerate操作。</p><p></p><p>l&nbsp;控制命令为Preemptive Expand时，当SampleLeft大于等于10ms时，不从抖动缓冲区读取数据，DSP进行Preemptive Expand操作；当SampleLeft小于10ms时，从抖动缓冲读取数据后，DSP进行Preemptive Expand操作。</p><p></p><p>上面的命令处理中，由于考虑到防止在语音缓冲区中增加额外的通话延迟，因此SampleLeft大于等于10ms时不需要从抖动缓冲区读取数据，只有在其小于等于10ms时才会读取数据，保持语音缓冲区中适量的数据；当控制命令为Merge时，任何时候都需要从抖动缓冲区读取数据，这是为了保证前后数据的连贯性；当控制命令为Expand时，丢包补偿会产生一定量的数据，因此任何都是都不需要从抖动缓冲区读取数据，但SampleLeft大于等于10ms时也不进行Expand操作，因为语音缓冲区中有足够的数据用于播放，只进行Normal操作。</p><p></p><p>4.7、MCU的控制机制</p><p></p><p>NetEQ的抖动算法中用Blo（optBufferLevel）基于遗忘因子算法来计算预测网络的抖动，用BLc（bufferLevelFit）基于自适应平均算法来计算预测抖动缓冲区的抖动。MCU的控制机制根据已播放数据的时间戳（playedOutTS，记为TSplay）、待读取数据包的时间戳（availableTS，记为TSavail）、Blo和Blc的关系来选择操作命令。TSplay和TSavail的关系来判断网络数据是否正常。</p><p></p><p>Blo和Blc的比较如下所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5e/5e25f78952cfff2e76e573316ca3db83.png\" /></p><p></p><p></p><p>上图中Blo和Blc的关系来判断选择Accelerate、Preemptive Expand、Expand和Merge操作。</p><p></p><p>简而言之，NetEQ中抖动消除主要由网络延迟和抖动缓冲区延迟的关系发送不同的命令通知DSP执行对应的操作来完成。</p><p></p><p>4.8、DSP的算法处理</p><p></p><p>DSP模块是NetEQ中的语音信号处理模块，其操作命令受MCU控制。WebRTC中采用自相关函数法，由于语音信号是非平稳信号，所以对信号的处理都使用短时自相关函数。短时自相关函数法的基因检测主要是利用短时自相关函数在信号周期处最大的特点，通过比较原始信号和它位移后的信号之间的相似性来确定基音周期，如果位移距离等于基音周期，那么两个信号便具有最大相似性。经典的短时自相关函数进行基音检测时，使用一个窗函数，窗不动，语音信号移动。窗长度至少要大于基音周期的两倍，窗长度越长，得出的基音周期越准确，但计算量也会相应的增加。</p><p></p><p>WebRTC中加速和减速操作基于WSOLA算法来实现语音时长的调整，就是要在不改变语音的音调并保证良好音质的前提下，使语音在时间轴上被压缩或者拉伸，即通常所说的变速不变调。语音时长调整算法分为时域和频率两类，时域以重叠区波形相似性（WSOLA）算法为代表，对于语音信号来说可以获得较高的语音质量，且相对频率算法运算量较小。而对于频率变化剧烈的音频，如音乐信号，时域算法则通常难以获得较高的语音质量，此时通常采用计算量较大的频率算法，如子带WSOLA算法。由于GIPS针对VoIP业务设计的NetEQ，所以数据以语音信号为主，频域变化较小，因此采用时域算法WSOLA。</p><p></p><p>DSP处理是实现抖动消除、丢包补偿并使得播放的语音实现低时延和较好音质的关键，下面分别介绍DSP的各个操作：</p><p></p><p>1）加速：将一个语音包的样本数减少，减少的数据是根据语音样本的相关性所得到的基音周期。将两个样本周期的语音数据经过平滑处理，转变为一个基音周期的数据。加速操作以30ms为一帧，只有相关性非常强（&gt;0.9）或者为信号能量很低时才会加速，算法与减速处理类似。如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9c/9c56910f87aaab248b267f49c3162d07.png\" /></p><p></p><p></p><p>2）减速：将一个语音包的样本数增加，增加的数据是根据语音样本的相关性所得到的基音周期。将两个样本周期的语音数据经过平滑处理，插入两个样本周期之间。减速操作以30ms为一帧，且待播放数据至少有0.625ms，否则重复播放上一帧；当解码后数据缓存不足30ms时，直接拷贝至播放缓存。基音周期的范围为2.5ms至15ms，所以最多延长15ms。如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c1/c14e188a1c6553a1f46e0d040be43cae.png\" /></p><p></p><p></p><p>3）插帧：采用iLBC的丢包补偿算法，即重建线性预测系统、重建残差信号和将补偿帧能量逐帧递减。插帧操作时待播放缓存要小于播放读取时长（10ms）。如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/63/63b705c266ceead13a7dd54ef03dc0cc.png\" /></p><p></p><p></p><p>4）融合：上一帧丢包之后会进行插帧操作，当新的数据解码后，为了提高语音数据的连贯，对新的解码数据和插帧数据进行平滑处理，能量渐强。融合操作生成的数据中间数据较大，需要预留最大空间。如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/54/542fc52fd39f0c74f6b8c141ab338a1f.png\" /></p><p></p><p></p><p>5）正常：这时新的解码数据正常输出播放，但如果上一帧数据是插帧数据，需要先插帧再平滑。</p><p></p><p>4.9、DSP算法的模拟测试</p><p></p><p>针对以上DSP算法操作，本文分别对间断的语音信号（Test1）、连续的语音信号（Test2）和音乐信号（Test3）在不同丢包率下进行了模拟测试，并采用ITU-T P563客观测量标准进行MOS值估计，LostData为丢包时填补静音，Expand为丢包时插帧，Expand+Merge为丢包时先插帧再融合。</p><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/60/6052ef027de8a1218cb9e66fcfe46048.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fa/fa4a6fd73f9d2b265db9a8084d131c56.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c5/c5c69aee14dea3943a929e1f4d539781.png\" /></p><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/df/df99dc4bbda1f2aeac9eeae5b55077d2.png\" /></p><p></p><p></p><p>间断话音信号对丢包率的变化不是很敏感，因为丢包的时候没有丢失太多语音时MOS值就会比较好，丢包时产生的爆破音在丢包补偿之后都有明显改善，主观感受良好。</p><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b4/b40007da215a58b968790d7b05fb45fa.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/88/8829eef0eb84e2d31d6a7c54afd505b2.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d1/d12ea60170bbae6c30d1e934de29b339.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5d/5dbdc2ccf0defecb2e32c5c4047f19e0.png\" /></p><p></p><p></p><p></p><p>连续话音信号跟随丢包率呈现出逐渐下降的趋势，丢包补偿的效果与Test1相近，爆破音明显改善，主观感受良好。</p><p><img src=\"https://static001.geekbang.org/infoq/78/7849c33501986dea9f1fd86b58be100d.png\" /></p><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8e/8e16f577da42327ffbdc018f49012c08.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c0/c02015e0ccdb359e7234ae8dba408d4a.png\" /></p><p></p><p></p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dc/dcd42fbf9e62de335249d1c3da0ff108.png\" /></p><p></p><p></p><p>音乐信号选取的是久石让的《天空之城》，整个频谱变化较大，丢包率较小时补偿效果不错，丢包率越大补偿的主观效果越差。</p><p></p><p>加速、减速和正常操作就不一一对比了，其中加速和减速操作在不丢包时对消除抖动的音质效果非常好，保持语音信号的完整性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/93/938b6ed4c895d6641142b64d523ecb6b.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/53/53d75b29fbae3d57e48e98470d6778af.png\" /></p><p></p><p></p><p>上图中动态模拟的初始值为37个样本，即初始时待播放样本为37个。Expand之后Merge得到的MOS值下降，有两个可能的原因：1、Expand前待播放字节数较少，导致插帧数据音质不高；2、Merge前Expand补偿的数据较多影响Merge后的音质，理想情况应该是Expand和Merge一一对应。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6e/6ead73d73729aafba32fe0dfdf00ff88.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6d/6d6c776b4a47aea197b04ed4f6ccf8ed.png\" /></p><p></p><p></p><p>上图中固定模拟的固定值为500个样本，即待播放样本保持为500个。这时Expand得到的MOS值有较大提升，之后每次都进行Merge操作，帮助提高MOS值。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/41/41f586b424eef79576a311e3d57a0684.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/30/30539beb660e445932bc99e4cefc446c.png\" /></p><p></p><p></p><p>上图中动态模拟的初始值为0，即初始时待播放样本为0个。这时Expand之前待播放样本减少导致Expand插帧数据的MOS值降低，之后虽然不是Expand和Merge一一对应，但是每次Merge之前待播放数据较少，所以需要平滑的数据就会更少，帮助提高MOS值。</p><p></p><p>P563标准的几个重要参数为：信噪比（SNR）、静音间隔和平均基音周期等，没有参考相位变化，但是相位变化对听觉的主观影响很大，比如在插帧数据之后相位不连续的波形有可能会产生爆音，这时会影响音质，所以插帧与融合虽然采用P563的MOS值估计有时相差无几，但是融合的主观感受要明显好于插帧。</p><p></p><p>5、参考文档</p><p></p><p>《GIPS NetEQ》，Global IP Solutions</p><p></p><p>《WebRTC语音引擎中NetEQ技术的研究》，吴江锐</p><p></p><p>《WebRTC语音引擎中分组缓存技术研究》，肖洪亮</p><p></p><p>《VoIP丢包处理技术的研究发展》，李如玮，鲍长春</p><p></p><p>《ITU-T P.563 Single-ended method for objective speech quality assessment in narrow-band telephony application》，国际电联ITU（International Telecommunication Union）</p>",
    "publish_time": "2023-12-29 16:21:03",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何打造适用金融行业的智能网关？",
    "url": "https://www.infoq.cn/article/LgdRRwz8EXhlbifotAFa",
    "summary": "<p>随着我们逐渐步入数字化时代，金融行业对于网络安全与效率的需求日益迫切。在这种背景下，智能网关显现出其在解决相关问题上的巨大潜力。本文将深入探索如何构建一个适配金融行业需求的智能网关。</p><p></p><h2>明确需求和目标</h2><p></p><p></p><p>在构建智能网关的初步阶段，关键是明确其面临的挑战。由于金融行业需频繁处理大量敏感数据，数据的安全性和隐私保护显得尤为重要。同时，考虑到金融交易的实时性和高频率，系统的可用性和性能也是核心的考量因素。因此，我们打造的智能网关应具备包括但不限于以下能力：安全防护、连接优化、流量管理及服务降级等。具体来看，我们需要考虑：</p><p></p><p>面对用户网络出现的各种问题，我们需要考虑如何提供可靠的备选连接方式，确保用户始终能够访问并进行操作。当面临异常流量时，我们需要设计出能有效感知并合理调度流量的策略，以保障系统功能的稳定运行。在突发事件发生时，我们必须有预案来保证核心功能的无缝运行。</p><p></p><h2>系统设计</h2><p></p><p></p><p>在明确需求后，我们将聚焦于智能网关的架构设计，这涉及到以下几个关键问题：如何管理并路由客户端发来的请求、如何监控当前的流量状态、如何处理服务降级和熔断等问题。同时，我们还需考虑如何实现服务的发布、上线、以及回滚等基础运维功能。</p><p></p><h4>框架设计：</h4><p></p><p></p><p>首先，让我们一起来看看好分期智能网关服务的整体框架设计。这个服务框架主要由四个核心模块构成，包括基础组件（Basic Components）、控制器（Controller）、服务（Service）以及数据（Model）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1e/1e1b7e931c9bb459ebce40ea8df14711.png\" /></p><p></p><p>基础组件（Basic Components）：这个模块为服务提供了一系列基本功能，如信息采集、用户验证、请求限流以及降级等。这些功能是构建稳健服务的基石，帮助我们追踪问题、保障安全、管理流量并在必要时启动备用系统进行降级。开发人员在开发接口时，可以根据实际需求灵活地开启或关闭这些功能。控制器（Controller）：控制器是服务的出入口，它定义了服务对外公开的接口。控制器负责接收用户的请求，并将请求路由到相应的Service进行处理。同时，根据每个接口的特定功能，控制器实现了与基础组件的绑定，这使得我们可以根据每个接口的特性和需求，选择适当的基础组件进行使用。服务（Service）：服务模块是业务逻辑的核心，它负责实现接口的内部逻辑。好分期网关服务会根据客户端的需求，向相应的后端接口请求数据，然后对获取的数据进行必要的加工处理，最终将数据以客户端所需的格式返回。这使得我们的服务能够灵活地适应各种业务需求，并根据终端类型提供定制化的数据。数据（Model）：数据模块负责处理与其他服务的交互逻辑。当下游服务出现问题时，数据模块能够实施高可用性策略，例如熔断和降级，这可以确保我们的服务在面对异常时，仍然能够维持其稳定性和可用性。</p><p></p><h4>信息采集：</h4><p></p><p></p><p>接下来，我们再具体介绍一下基础组件中的信息采集功能。在系统的日常运行中，我们构建了一个全方位的信息采集框架，它覆盖了运行环境、接口请求、以及系统出现异常等关键环节。所有的信息都会按照统一的日志格式进行整理和输出。通过这些日志信息，我们能够实时掌握系统运行状况，及时发现并解决问题。而且，它为后续的分析和优化提供了丰富的数据支撑，使我们能够基于数据深入理解系统，从而制定出更加科学和有效的优化策略。</p><p><img src=\"https://static001.geekbang.org/infoq/7e/7ee659dbd6e859fb2399211b47d09bb1.png\" /></p><p></p><p>性能监控信息： 记录了运行容器的各项性能指标，以便我们深入理解系统的运行状态和性能表现。</p><p></p><p>CPU 使用率（CPU Used）：这一指标反映了 CPU 的使用情况，为我们提供了关于系统负载状态的重要信息。这有助于我们在系统负载过高时及时进行负载均衡或扩容操作。CPU 限制次数&amp;时间（CPU Throttle Count &amp; Time）：这一指标显示了 CPU 被限制的次数和累计时间。这有助于我们分析系统是否在处理 CPU 密集型任务，并进行相应的优化。内存使用率（Memory Used）：这一指标揭示了内存的使用情况。这有助于我们分析并查找程序运行过程中可能存在的内存泄漏问题，从而提高系统的运行效率。</p><p></p><p>请求记录：记录了所有通过服务的请求日志，以便我们可以准确地追踪和分析系统的行为。</p><p></p><p>接口访问日志：这部分日志详细记录了每个接口的基本信息，如请求结果和请求耗时等。这有助于我们分析接口的性能，并找出可能的性能瓶颈。接口内部逻辑执行的分段耗时：这部分日志深入记录了每个接口内部 Service 方法的执行时间。这有助于我们分析和优化代码的执行效率。跨服务请求的访问日志：这部分日志记录了每个接口调用下游服务的基本信息，如请求结果和请求耗时等。这有助于我们监控和优化服务间的通信效率。</p><p></p><p>异常记录： 记录了服务中出现的所有异常，以便我们可以及时响应并修复问题。</p><p></p><p>逻辑异常：这类异常一般发生在 Service 内部逻辑执行出错的情况下，例如解密数据出错、JSON 解析出错等。这有助于我们找出代码中的错误并进行修复。结果异常：这类异常一般发生在调用下游服务成功，但服务返回了错误的结果的情况下。这有助于我们调试和定位问题。访问失败：这类异常一般发生在调用下游服务失败的情况下，即无法正常访问到下游服务。这有助于我们监控服务的可用性，并及时处理服务间的通信问题。</p><p></p><h2>具体解决方案</h2><p></p><p></p><p>在详细描述了系统的基础设计之后，接下来我们将深入探讨好分期智能网关是如何有效应对之前提及的挑战的。</p><p></p><h4>挑战一：如何选择最佳的连接方式</h4><p></p><p></p><p>每次客户端启动时，都会向好分期的网关服务发送一次访问信息（Ping），以验证服务的连通性和可用性。通常，服务会成功返回响应数据并记录一条含有客户端访问地区的日志。但在某些情况下，尽管我们的系统仍在运行，但客户端可能由于网络限制、防火墙设置等原因无法正常与网关服务建立连接，从而导致Ping请求失败。</p><p></p><p>当客户端的Ping请求失败时，客户端会立即向特定接口发送请求以获取备用的服务配置。这个备用配置包含了多个不同接入点的信息，每个接入点都代表了一个可能的服务路径。获取备用配置后，客户端会根据当前网络状况和地理位置（省份、城市）精选出一个最佳的备用策略，可能包括选择最佳接入点或调整连接参数等，总之，目的就是尝试与服务进行连接，优先保证用户的使用体验。</p><p><img src=\"https://static001.geekbang.org/infoq/54/54a66d681c66c6b5ab2eb06591990eff.png\" /></p><p></p><p>这种自动化的故障应对机制，使得我们的服务在面临可能的网络故障时，仍能保持其稳定性和可靠性。此外，这种访问监控机制也提供了大量的实时数据，这对于我们来说是非常宝贵的。我们可以通过这些数据，深入理解我们的服务在各种情况下的表现，找出可能的瓶颈和问题，然后优化我们的服务以提供更好的用户体验。</p><p></p><h4>挑战二：如何应对异常流量</h4><p></p><p></p><p>在传统的限流策略中，为了让系统在任何情况下都能正常运行，我们通常会设定一个相对保守的阈值。然而，通过对系统运行数据的实时监控和分析发现，这种策略并非在所有情况下都是最优选择。举例来说，有些时候，即使并发量超过阈值触发限流，系统的负载率仍然不高；反过来，即使没有触发限流，系统在执行复杂运算逻辑时的负载率却可能非常高，导致系统响应速度下降。为了解决这个问题，我们需要设计一个新的方案，能够根据系统的实际负载情况动态调整限流阈值。</p><p><img src=\"https://static001.geekbang.org/infoq/81/817a961ce0740399d33be474a3d8ac32.png\" /></p><p></p><p>在这个新的方案中，我们利用已经采集到的系统运行数据，包括CPU使用率、CPU限制次数及时间，以及内存使用率。通过详细分析这些关键指标，我们能够确定系统效率下降的临界点。然后，我们将基于这个临界点，动态地更新限流阈值，确保系统在达到阈值时，其运行状态能够接近这个临界点。这种方式既能最大化系统的使用效率，也能同时保证系统的稳定性。</p><p><img src=\"https://static001.geekbang.org/infoq/2f/2f14c851e9e6e5f00d7f2a990cb28b0d.png\" /></p><p></p><p>为了实现这个目标，我们先后尝试了多种计算方法，包括比例计算、累积误差计算，以及在工业领域广泛应用的PID控制算法。经过对比，我们发现PID控制算法在调节流量阈值方面表现优秀。PID控制算法采用比例控制、积分控制和微分控制来适应性地调整流量阈值：</p><p></p><p>比例控制：该参数决定了系统对负载误差的响应速度。值越大，系统对负载误差的响应越迅速。积分控制：该参数决定了系统对持续负载误差的反应强度。值越大，系统对持续负载误差（如长时间的CPU过载）的反应越强烈。微分控制：该参数决定了系统对负载误差变化的响应速度。值越大，系统对负载误差的变化（如CPU使用率的突然增加）反应越快。</p><p></p><h4>挑战三：如何保障核心功能</h4><p></p><p></p><p>划分业务优先级：</p><p></p><p>首先，我们需要对业务进行优先级划分。这通常涉及到将业务分为核心业务和非核心业务。核心业务是那些对公司运营至关重要的业务，如还款、借款、进件等操作。非核心业务可能包括一些附加功能，如推荐系统、广告系统等。</p><p><img src=\"https://static001.geekbang.org/infoq/79/797e1c27a37150d6bf921acab10973ea.png\" /></p><p></p><p>通过划分业务优先级，我们可以在系统资源有限的情况下，优先保障核心业务的正常运行。</p><p></p><p>评估核心流程规模：</p><p></p><p>在明确了业务优先级之后，我们需要根据这些优先级来评估核心流程的具体规模。这一步骤要求我们深入研究并预测核心流程在面临极限压力时，可能需要处理的最大负载。这通常涉及到以下几个关键因素：</p><p></p><p>请求峰值： 这一指标涉及到系统在特定时间（例如还款高峰期）可能需要处理的最大请求量。对请求峰值的了解可以帮助我们预测最大的工作负载，并据此做好充分的准备，以保证系统可以顺利处理这些请求。数据规模： 这涉及评估每个请求的平均数据量以及在高峰期间可能需要处理的总数据量。对数据规模的了解和预测可以帮助我们预防和处理可能出现的IO瓶颈，保证数据流畅地在系统中流动。系统资源使用情况： 我们需要评估处理这些请求时，每个服务可能需要的最大CPU、内存和磁盘资源。通过这种方式，我们可以更有效地管理和分配系统资源，确保每个核心业务流程都能获得足够的资源。</p><p></p><p>限流策略的精细化调整：</p><p></p><p>一旦确定了核心流程的业务规模，我们就可以以此为基础，精细调整限流策略，以更有效地保护核心功能。</p><p></p><p>对于核心业务，设定一个较高的限流阈值是必要的。这样做不仅在大流量下保证了服务的连续性，而且防止了核心业务在关键时刻因资源不足而受限。另一方面，对于非核心业务，我们可以设定一个较低的阈值，以防止在资源紧张的情况下，这些业务消耗过多的资源，从而对核心业务的运行产生影响。</p><p><img src=\"https://static001.geekbang.org/infoq/60/60c46cedc2dacf254421f6557052d74f.png\" /></p><p></p><p>同时，我们还可以根据实际访问量动态调整非核心业务的限流阈值。例如，在访问量较低的时段，我们可以适当提高非核心业务的阈值，以充分利用可用资源；而在访问量较高的时段，我们可以适当降低非核心业务的阈值，以确保核心业务能够优先获取到足够的资源，保证其稳定运行。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/68/68cf691acbcd96da57e064c93a611eee.png\" /></p><p></p><p>极端情况下的降级方案：</p><p></p><p>在遭遇网络波动或硬件故障等极端情况时，我们必须有备选的降级策略来进行应对。这些策略通常包括降低服务质量和简化部分复杂操作。</p><p></p><p>降低服务质量：对于那些耗费大量资源但并非必须的服务，我们可以选择降低其服务质量。例如，降低实时数据的更新频率，减少非必要的数据同步等。此外，我们也可以选择暂停一些非核心业务，如获客、营销、消息中心等系统，从而迅速减轻系统负载，确保核心业务的正常运行。简化操作过程：当系统资源紧张时，复杂的操作流程也可能会加重系统负担。因此，我们可以选择简化一些操作，例如缩短用户操作流程，简化页面展示等，以有效地降低系统负载。启动备用系统：对于关键业务，我们应提前准备好备用系统。一旦主系统出现问题，我们可以立即切换到备用系统，以保障关键业务的连续性。</p><p></p><p>这些降级策略将帮助我们在极端情况下维持系统运行，并确保核心功能的提供。通过预先规划和准备这些降级策略，我们可以在突发事件发生时，迅速且准确地做出响应，尽最大可能保护核心业务的正常运行。</p><p></p><h2>总结</h2><p></p><p></p><p>打造适用于金融行业的智能网关是一个持续进化和优化的过程，它需要我们深入洞察业务需求，不断探索新的策略，反思和调整我们的方法，以持续提升和完善我们的方案。这一过程的核心目标是提高系统的安全性和稳定性，并为用户提供出色的体验，以满足金融行业对实时性、高频率和高可靠性的严格要求。</p><p></p><p>作者介绍：</p><p></p><p>张欣元，微财数科 Android开发高级工程师</p><p>李萌萌，微财数科 大前端资深开发工程师</p><p>李军，微财数科 技术负责人</p><p>吴迪，微财数科 副总裁</p>",
    "publish_time": "2023-12-29 16:52:20",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]