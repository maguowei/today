[
  {
    "title": "Java迎来增强功能字符串模板，代码简化，安全性提升",
    "url": "https://www.infoq.cn/article/bKWjLjEoFVTr0GFVTmWm",
    "summary": "<p>面向JDK 21的JEP 430（<a href=\"https://openjdk.org/jeps/430\">字符串模板预览</a>\"）已经从Proposed to Target状态提升到Targeted状态。该JEP提议用字符串模板来增强Java编程语言。字符串模板类似于字符串字面量，但包含嵌入式表达式，这些表达式会在运行时合并到字符串模板中。</p><p>&nbsp;</p><p>现在，Java开发人员可以使用字符串模板增强该语言的字符串字面量和文本块。字符串模板将字面量文本与嵌入式表达式及处理器相结合，用于生成特定的结果。这一新特性的目的是简化Java程序的编写，提高文本和表达式混合代码的可读性，增强Java程序从用户提供的值组成字符串时的安全性。</p><p>&nbsp;</p><p>该JEP引入了一种新的表达式，名为模板表达式，让开发人员可以安全有效地执行字符串插值及组合字符串。模板表达式是可编程的，其功能并不限于组合字符串。它们可以根据特定于领域的规则将结构化文本转换为任何类型的对象。在模板表达式中，模板处理器在运行时将模板中的字面量文本与嵌入表达式的值组合在一起生成所需的结果。请看下面的例子：</p><p><code lang=\"java\">String name = \"Joan\";\n\n\nString info = STR.\"My name is \\{name}\";\nassert info.equals(\"My name is Joan\");   // true</code></p><p>&nbsp;</p><p>模板表达式的语法与字符串字面量类似，但有一个前缀。上述代码的第二行包含一个模板表达式。</p><p>&nbsp;</p><p>相比之下，字符串插值通常允许程序员将字符串字面量和表达式组合成单个字符串，就像许多编程语言所做的那样，与传统的字符串连接相比，这样更方便也更清晰。但是，它会生成可能被其他系统误解的危险字符串，特别是在处理SQL语句、HTML/XML文档、JSON片段、shell脚本和自然语言文本时。为了防止安全漏洞，Java要求开发人员使用转义或验证方法对带有嵌入式表达式的字符串进行验证和消毒。</p><p>&nbsp;</p><p>更安全、更有效的解决方案是引入一种基于模板的一等字符串组合机制，该机制会自动将特定于模板的规则应用于字符串，为SQL语句添加转义引号，让HTML文档没有非法实体，以及实现无模板的消息本地化。这种方法使开发人员不用再手动对每个嵌入式表达式进行转义，并验证整个字符串。这正是Java模板表达式所做的，与其他流行的编程语言所使用的字符串插值完全不同。</p><p>&nbsp;</p><p>在模板表达式的设计中，包含嵌入式表达式的字符串字面量或文本块是不可能直接转换为插入了表达式值的字符串的。这是为了防止危险的错误字符串在程序中传播。取而代之，模板处理器（如STR、FMT或RAW）会处理字符串字面量，验证结果，并插入嵌入式表达式的值。</p><p>&nbsp;</p><p>下面是一些模板表达式的例子，它们使用多行来描述HTML文本、JSON文本和一个区域表格：</p><p><code lang=\"java\">String title = \"My Web Page\";\nString text  = \"Hello, world\";\nString html = STR.\"\"\"\n        \n          \n            \\{title}\n          \n          \n            </code></p><p><code lang=\"java\">\\{text}</code></p><code lang=\"java\">\n          \n        \n        \"\"\";</code><p></p><p>&nbsp;</p><p>它生成以下输出：</p><p><code lang=\"java\">| \"\"\"\n| \n|   \n|     My Web Page\n|   \n|   \n|     </code></p><p><code lang=\"java\">Hello, world</code></p><code lang=\"java\">\n|   \n| \n| \"\"\"</code><p></p><p>&nbsp;</p><p>下面是另一个例子：</p><p><code lang=\"java\">String name    = \"Joan Smith\";\nString phone   = \"555-123-4567\";\nString address = \"1 Maple Drive, Anytown\";\nString json = STR.\"\"\"\n    {\n        \"name\":    \"\\{name}\",\n        \"phone\":   \"\\{phone}\",\n        \"address\": \"\\{address}\"\n    }\n    \"\"\";</code></p><p>&nbsp;</p><p>类似地，它生成以下输出：</p><p><code lang=\"java\">| \"\"\"\n| {\n|     \"name\":    \"Joan Smith\",\n|     \"phone\":   \"555-123-4567\",\n|     \"address\": \"1 Maple Drive, Anytown\"\n| }\n| \"\"\"</code></p><p>&nbsp;</p><p>另一个例子：</p><p><code lang=\"java\">record Rectangle(String name, double width, double height) {\n    double area() {\n        return width * height;\n    }\n}\n\n\nRectangle[] zone = new Rectangle[] {\n        new Rectangle(\"Alfa\", 17.8, 31.4),\n        new Rectangle(\"Bravo\", 9.6, 12.4),\n        new Rectangle(\"Charlie\", 7.1, 11.23),\n    };\n\n\nString form = FMT.\"\"\"\n        Description     Width    Height     Area\n        %-12s\\{zone[0].name}  %7.2f\\{zone[0].width}  %7.2f\\{zone[0].height}     %7.2f\\{zone[0].area()}\n        %-12s\\{zone[1].name}  %7.2f\\{zone[1].width}  %7.2f\\{zone[1].height}     %7.2f\\{zone[1].area()}\n        %-12s\\{zone[2].name}  %7.2f\\{zone[2].width}  %7.2f\\{zone[2].height}     %7.2f\\{zone[2].area()}\n        \\{\" \".repeat(28)} Total %7.2f\\{zone[0].area() + zone[1].area() + zone[2].area()}\n          \"\"\";</code></p><p>&nbsp;</p><p>上述代码生成以下输出：</p><p><code lang=\"java\">| \"\"\"\n| Description     Width    Height     Area\n| Alfa            17.80    31.40      558.92\n| Bravo            9.60    12.40      119.04\n| Charlie          7.10    11.23       79.73\n|                              Total  757.69\n| \"</code></p><p>&nbsp;</p><p>Java提供了两个模板处理器来执行字符串插值：STR和FMT。STR用它（字符串化）的值替换模板中的每个嵌入式表达式，而FMT会解释出现在嵌入式表达式左侧的格式说明符。格式说明符与java.util.Formatter中定义的格式说明符相同。如果需要未经处理的原始模板，则可以使用标准的RAW模板处理器。这个处理器只是简单地返回原始模板，不做任何插值或处理。</p><p>&nbsp;</p><p>此外，开发人员还可以创建自己的模板处理器，用于模板表达式的处理。模板处理器是一个提供ValidatingProcessor功能接口的对象，它的类实现了ValidatingProcessor的单一抽象方法。该方法接受StringTemplate并返回一个对象。自定义模板处理器让开发人员可以在运行时执行验证并返回任何类型的对象，而不仅仅是字符串。</p><p>&nbsp;</p><p>总之，Java模板表达式使开发人员可以轻松、安全地进行字符串插值和字符串组合。</p><p></p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/04/java-gets-a-boost-with-string/\">https://www.infoq.com/news/2023/04/java-gets-a-boost-with-string/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/eazviIX3Dutuh3lKwd1F\">Java 近期新闻：Java 28 岁、Payara、Micronaut 4.0-M5、Spring 更新</a>\"</p><p><a href=\"https://www.infoq.cn/article/R8sh9XHuojBsX9DpGYvJ\">快速实现不打折扣的云原生 Java 应用</a>\"</p><p><a href=\"https://www.infoq.cn/article/0ZTAForQs79EseZhPRXU\">Record 模式提升了 Java，能实现更具表现力的编码</a>\"</p><p></p>",
    "publish_time": "2023-06-10 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "访谈实录！张宏江对话OpenAI Altman：10年内，我们或将迎来超强AI系统",
    "url": "https://www.infoq.cn/article/zsPuUKHbYFHiRxsRSqdr",
    "summary": "<p>最近几年，人工智能来迎来了重大进展，在机器学习、自然语言处理和计算机视觉方面取得了技术突破。在数字化转型进入深水区后，人工智能已经可以成熟应用于各行各业中，包括医疗、保险、金融和交通运输等，人工智能彻底改变了我们的生活和工作方式。</p><p>&nbsp;</p><p></p><blockquote>2023 年 6 月 9 日，由<a href=\"https://www.baai.ac.cn/\">北京智源人工智能研究院</a>\"主办的<a href=\"https://2023.baai.ac.cn/\">2023 北京智源大会</a>\"在中关村国家自主创新示范区会议中心开幕，会期两天。智源大会是北京创建全球人工智能学术和创新最优生态的标志性学术活动，本文为 InfoQ 记者带来的现场报道。</blockquote><p></p><p>&nbsp;</p><p>以下内容根据OpenAI创始人Sam Altman演讲速记进行整理，未经本人确认。</p><p>&nbsp;</p><p>OpenAI创始人Sam Altman：我最近在做全球巡回的访问，期间穿越五大洲近20个国家，接触了诸多的学生、开发者，这趟出行令人振奋，我们见证了全球各地的人们利用OpenAI的新技术来改变生活方式，我们也获得了非常宝贵的意见，以便于让我们的工具优化得更好。此外，我也有机会拜访了多位外国领导人，讨论确保越来越强大的人工智能系统安全部署所需的各种基础工作。</p><p>&nbsp;</p><p>坦白说，世界的注意力主要集中在解决当今的人工智能问题上，很多问题的解决非常迫切，我们还有很多工作要做，不过鉴于我们已经取得的进展，我相信我们会实现目标。</p><p>&nbsp;</p><p>今天，我想谈谈未来。具体来说，我们正在看到人工智能能力的迅速增长，现在需要做的是负责任地将其应用到世界中去。科学的历史告诉我们，技术进步遵循指数曲线。这在农业、工业和计算革命中得到了验证。现在，我们亲眼目睹人工智能变革，不仅因为我们正在见证它，而且因为它带来的变革速度。</p><p>&nbsp;</p><p>它正在迅速拓展人类的想象力。想象一下，在未来十年，人工通用智能系统（常称为AGI）将会超过90年代初，人类所具备的专业水平，这些系统最终可能超过人类最大体量公司的总体生产力，这里的潜在收益是巨大的。</p><p>&nbsp;</p><p>人工智能革命将带来可共享的财富，使改善人类互动标准成为可能，但我们必须管理好风险，并共同努力来实现预期目标。我时常感觉一些人放弃他们应有的权益来实现人类共同的目标，在今天很多领域仍然如此——大国之间经常通过合作的方式来实现共同目标，这种形式的合作对关键的医学和科学进展都会带来好处，比如根除小儿麻痹症和天花等疾病，以及全球减少气候变化风险的努力。</p><p>&nbsp;</p><p>随着越来越强大的人工智能系统的出现，全球合作的利益变得前所未有地重要。如果我们不做好规划，一个设计用于改善公共卫生结果的未对齐的AI系统，可能会通过提供不平衡的建议来破坏整个集体系统。同样，一个旨在优化农业实践的人工智能系统可能会无意中损害经济和资源的消耗，缺乏对长期可持续性的考虑，从而影响食物生产和环境平衡。我希望我们都能认同，推进AGI安全是我们寻找共同立场的最重要领域之一，我希望把时间都集中在我们已经开始的领域。</p><p>&nbsp;</p><p>其中一个领域是AGI治理。AGI的力量可以从根本上改变我们的文明，这突显了有意义的国际合作、协调的必要性，每个人都会从积极的治理方法中受益。如果我们将这个核心的最先进政策网络化，AGI系统可以为全球经济创造无与伦比的经济丰富，解决共同的挑战，如气候变化、全球健康安全，并在无数其他方面提升社会福祉。我深信这也是未来，我们深处同一个星球，需要明确投资AGI的安全性的意义。</p><p>&nbsp;</p><p>我们必须为鲁莽的开发和部署可能引发的问题负起责任，其中最重要的两个领域是：首先，我们需要建立起包容的国际准则和标准，并在所有国家对AGI的使用中建立平等、统一的防护措施。其次，我们需要国际合作，以可验证的方式在全球范围内建立对越来越强大的AGI系统安全开发的信任，我知道这并不容易。</p><p>&nbsp;</p><p>作为国际社会，我们需要对安全进行长期的关注和投入，以确保我们做得正确。《道德经》提醒我们，“千里之行，始于足下”，最有建设性的第一步是与国际科技界展开合作，推动增加AGI安全技术进展的透明度和知识的机制，发现紧急问题的研究人员应该与更多人共享研究成果。</p><p>我们需要更加深入地思考如何在鼓励推动国际合作的同时尊重和保护知识产权。如果我们做得好，这将为我们打开深化合作的新大门。更广泛地说，我们应该推动并引导与安全研究一致的投资。</p><p>&nbsp;</p><p>当前，我们关注的是如何使AI系统成为一个有益和安全的助手，这对应的是如何训练模型，使其在没有安全威胁的前提下发挥积极作用，不过，随着AGI时代的接近，其带来的潜在影响、问题将呈指数级增长，所以，我们需要通过主动应对AGI带来的潜在挑战，将未来灾难性后果的风险降至最低。</p><p>&nbsp;</p><p>从GPT-4完成预训练到部署，我们花了八个月的时间来研究这个如何前置预判风险并给出对策的问题，我们认为我们走在了正确的道路上，GPT-4的对齐程度超过当前所有的代码。不过，对于更高级的系统，对齐仍然是一个尚未解决的问题，我们认为需要新的技术方法以及加强治理监督，毕竟未来的AGI，可能是一个十万行二进制代码的系统。</p><p>&nbsp;</p><p>人类监督者很难判断如此规模的模型是否在做一些损害的事情。因此，我们正在投资于几个新的，并且希望能取得成果的方向，其中之一是可扩展的监督，尝试使用AI系统来协助人类监督其他AI系统。例如，我们可以训练一个模型来帮助人类监督员找出其他模型代码中的缺陷。</p><p>&nbsp;</p><p>第二个方向是可解释性。我们希望更好地理解模型内部发生的事情，我们最近发表了一篇论文，使用GPT-4来解释计算机的复杂状态。虽然还有很长的路要走，但我们相信先进的机器学习技术可以进一步提高我们解释的能力。</p><p>&nbsp;</p><p>最终，我们的目标是训练AI系统具备更好地优化自身的能力，这种方法的一个有前景的方面在于——它可以与AI的发展速度相适应。随着未来的模型变得越来越智能和强大，作为助手，我们将找到更好的学习技术，在充分发挥AI的非凡好处的同时降低风险。</p><p>&nbsp;</p><p>我们认为，美国、中国乃至世界各地的研究人员，在应对AI领域的技术挑战上的合作，存在巨大潜力，想象人类可以利用AI来解决世界上最重要的问题，大幅改善生存条件和质量。</p><p>&nbsp;</p><p>演讲过后，Altman以视频连线的方式对话了智源研究院理事长张宏江，以下内容为现场对话访谈：</p><p>&nbsp;</p><p></p><blockquote>张宏江：您提到了正在和欧盟以及其他AI领域沟通全球治理，现在进展如何？我们距离AGI时代还有多远，有没有什么可以证明距离这一天还很遥远？假设我们发现了安全的人工智能，是否意味着也找到了不安全的人工智能？</blockquote><p></p><p>&nbsp;</p><p>Sam Altman：这很难预测，仍然需要不断地研究才能提供结论，并且这条路不会一帆风顺，但AGI可能很快就会发生，但在未来的10年内，我们可能会拥超强的AI系统。</p><p>&nbsp;</p><p>在那种情况下，全球监管就非常的紧迫，而且历史上也出现过很多新技术改变世界的相关的案例，现在这种改变速度正变得更快，考虑到这种紧迫性，我认为准备好迎接这一切并就安全问题作出正确回答非常重要。</p><p>&nbsp;</p><p></p><blockquote>张宏江：所以，您觉得这（正确回答安全相关的问题）是我们的优先事项？</blockquote><p></p><p>&nbsp;</p><p>Sam Altman：我想强调的是，我们并不确切知道（未来可能会如何），尤其是现在对人工智能的定义存在差异，但我认为在10年内，我们应该为一个拥有超强AI系统的世界做好准备。</p><p>&nbsp;</p><p></p><blockquote>张宏江：您提到，OpenAI是一个致力于全球合作的机构，你们正在推动的全球合作有哪些，获得了哪些回应，有什么感受？</blockquote><p></p><p>&nbsp;</p><p>Sam Altman：我认为人们非常重视AGI的风险和机遇。在过去的六个月里，相关讨论已经发生了很大变化。人们似乎真心致力于找到一种机制，既能让我们享受这些好处，又能在全球范围内共同努力减轻风险，我认为我们在这方面做的不错。</p><p>&nbsp;</p><p>全球合作始终是困难的，但我认为这种机遇和威胁确实能够让世界走到一起，我们可以为这些系统制定一个框架和安全标准，这非常有帮助。</p><p>&nbsp;</p><p></p><blockquote>张宏江：在之前有没有的成功的案例，您能举个例子吗？</blockquote><p></p><p>&nbsp;</p><p>Sam Altman：我们已经消除了一些全球合作的障碍。我们已经解决了技术上的困难，例如真实世界交易的问题。有很多例子可以说明我们已经有所突破。</p><p>&nbsp;</p><p></p><blockquote>张宏江：您提到了先进AI系统的对齐问题，我也注意到在过去几年中，许多AI系统都付出了很多努力来优化其对齐性能，我们可以在近些年里完成对AI安全的研究吗？</blockquote><p></p><p>&nbsp;</p><p>Sam Altman：我认为“对齐”这个词在不同的方式中被使用。我认为我们需要解决整个挑战，即能够安全地访问系统意味着什么。从传统意义上讲，让模型按照用户意图进行沟通的对齐是其中的一部分。还会有其他问题，例如我们如何验证系统正在按照我们的意愿行事，以及我们将系统与哪些价值观对齐。我认为重要的是全面考虑如何获得安全的AI。</p><p>&nbsp;</p><p>我认为对齐工作还在不断演变中。我们将纳入市场上已有的工作模式。很多这些技术仍处于纸面之上，但是我们需要超越技术的其他因素。这是一个复杂的问题。AI安全是最新的技术。因此，技术方面的创新是我们需要考虑的因素之一。我们需要思考关键的AI安全问题。我们如何应对这些挑战？就像我们大多数人都是科学家一样去思考。我们为什么要做这个？这是一个非常复杂的问题。我认为，为了确保我们解决了技术方面的安全问题，需要投入大量精力。</p><p>&nbsp;</p><p>正如我之前提到的，确定我们要与之保持一致的价值观并不是一个技术问题。我们确实需要技术的参与，但这更是一个值得全社会深入讨论的问题。我们必须设计出公平的、有代表性和包容性的系统。正如您所指出的，我们不仅需要考虑AI模型本身的安全性，还需要考虑整个系统的安全性。因此，我们需要构建安全的分类器和检测器，以监测符合用户政策的情况。这一点很重要。</p><p>此外，我认为很难预测和预先解决任何技术可能出现的问题。因此，通过从实际使用中学习并快速部署数据，观察在一个国家中会发生什么，并给人们提供时间来学习、更新和思考这些模型将如何影响他们的生活，这也非常重要。</p><p>&nbsp;</p><p></p><blockquote>张宏江：中国、美国和欧洲是推动人工智能和创新的三个主要力量。您认为国际合作解决人工智能需求和决策方面的优势有哪些？这些优势如何结合起来产生影响？</blockquote><p></p><p>&nbsp;</p><p>Sam Altman：我认为在人工智能安全性方面，普遍存在着需要许多不同观点的情况。我们还没有所有的答案，解决这个问题非常困难且重要。正如我提到的，这不仅仅是一个技术问题。使人工智能变得安全这件事受益于了解不同国家和不同背景下用户的偏好。因此，我们需要许多不同的观念来实现这一目标。中国拥有世界上一些最优秀的AI系统，从根本上讲，我认为这使研究人员在解决许多不同的AI系统的问题上面临困难。中国是世界上最好的地方，我真诚希望中国和美国的研究人员能对此做出巨大贡献。</p><p>&nbsp;</p><p></p><blockquote>张宏江：您能分享一些在这方面取得的成就吗？在这项工作中，您的计划或想法是什么？</blockquote><p></p><p>&nbsp;</p><p>Sam Altman：我认为一个重要的进展是人们开始对如何安全开发先进AI系统的国际标准感到兴奋了。我们希望在训练广泛模型并在其部署之前，思考应该进行什么样的测试。我们还就构建反映人们目标、价值观和实践的数据库进行了新的讨论，人们可以利用这些数据库来使他们的系统与之对齐，并探讨了开展共享AI安全性研究的形式问题。所以，这些可能是目前出现的三个最具体的事情。</p><p>&nbsp;</p><p></p><blockquote>张宏江：我在这里有一个很棒的问题，来自观众——您是否打算重新开放GPT的源代码，就像在3.0之前一样？</blockquote><p></p><p>&nbsp;</p><p>Sam Altman：关于源代码，我不太清楚，但可以确认一下。我们开源了一些模型，而其他模型则不开源，但随着时间的推移，我认为我们可以期望开源的模型会更多，我没有具体的模型或时间表，但这是我们正在努力的事情我不确定您是否听说过，但是我主持了一个开源机构，我们在开放源代码方面付出了很多努力，包括模型。</p><p>&nbsp;</p><p>我将采用一种算法来开发模型，并引入新的Python模型和A-15模型。我们相信需要倾听并理解听众的反馈。所以，如果您明天对此有类似的见解，是否有什么可以去讨论以回应两位现在正在谈论的同事之间的担忧？是的，我的意思是，开源确实起着重要的作用。</p><p>&nbsp;</p><p>开源模型的发展已经相当多了。我认为A-15模型也起着重要的作用，它为我们提供了额外的安全控制。您可以阻止某些用户，可以阻止某些类型的微调。这是一个重要的回归点。就目前模型的规模而言，我对此并不太担心，但随着模型变得越来越大，确保正确性可能会变得昂贵。我认为开源一切可能不是最优的路径，尽管这确实是正确的路径。我认为我们只需小心地朝着这些节点前进。</p><p>&nbsp;</p><p></p><blockquote>张宏江：是的，我认为开源模型确实有优势。总结一下我所说的，无论是GPT-4还是开源的模型及简化性AI，我们有没有可能需要改变整个基础设施或者模型的架构，使其像GPT-2一样简单？对此您有何想法？从能力和安全性的角度来看，我们可能确实需要一些非常不同的架构。</blockquote><p></p><p>&nbsp;</p><p>Sam Altman：我认为我们将在这个能力上取得一些良好的进展，但在当前的模型类型中他们展现的效果更好，这是一个原因。但是，如果在10年后出现另一个巨大的飞跃，我也不会感到惊讶。我不记得很多年间有什么东西真正改变了的架构。另外，作为一名研究人员，我相信在座的许多人都会有这种好奇心，就是关于大模型和大容量模型的人工智能用户体验方面的下一步发展方向。我们是否会很快落后于增长曲线，或者下一个前沿是具有体现能力的模型，或者自主机器人是人工智能所关注的下一个前沿？我也非常好奇接下来会发生什么。我最喜欢做这项工作的事情就是能够处在研究的前沿，这是令人兴奋和惊喜的，我们还没有答案。因此，我们正在探索许多关于接下来可能出现什么、可能的新领域的想法。</p><p>&nbsp;</p><p>当然，并不是说我们现在就能在序列中找到新的抗衰老模型，而是不用过于担心具体的时间点。我们在刚开始的时候就做过机器人方面的工作，并且我们对此非常兴奋，也经历了困难。我希望有一天我们能够回到这个话题。</p><p>&nbsp;</p><p></p><blockquote>张宏江：&nbsp;您还提到您正在研究如何制作更安全的模型，特别是使用CT4数据，在CT6的神经元有这个数据。这个工作在这个方向上是否有效？您是否能够在未来（用这种方法）推进人工智能领域？我们将继续在这方面努力。所以，如果我认为我们会考虑到这一点，它是否具有可扩展性？因为我在向一群生物学科学家提问，他们专注于人类的学习。他们想借鉴这些思想并从中学习，以研究人类在工作中的表现。观察人工神经元比观察生物神经元更容易。</blockquote><p></p><p>&nbsp;</p><p>Sam Altman：我认为这对人工神经网络是可行的。我认为使用更强大的模型或使用类似其他（生物）模型的模型的方法是可行的。但我不太确定如何将其应用于人脑。另外，我们正在讨论人工智能安全和API控制的话题。我们刚才在辩论，如果我们只有三个模型，那么我们会更安全。这就像一个核计划。您不希望（每个人）拥有核武器。因此，当我在控制模型数量时，如果控制不了接触模型和数据的人数的话是不安全的。</p><p>&nbsp;</p><p>那么，我们是要控制模型的数量吗？从人类的角度来看，无论是拥有少量模型还是大量模型，都不能让我们更安全。更重要的是，我们是否有一种机制，确保任何柯林斯模型都需要经过足够的安全测试。我们是否有一个框架，让那些创建了完备柯林斯模型的人具备足够的资源和责任心，确保他们创造的东西是安全可靠的？来自麻省理工学院的教授Max是莱布尼兹研究所的一位教师，他提到了一种方法，但他认为这个方法不够具体。</p><p>&nbsp;</p><p>从一个角度来看，我们可以研究如何控制隐私的泄露。如果您丢失了一封电子邮件，您仍然可以获取一份副本。在这个过程中您无法证明它是怎么获取到的。如果那家公司可以借用您的资料，那这将产生重大影响。我认为有一些行业正在发展不同的许可框架，将新技术引入市场，我认为我们应该借鉴它们。但我认为从根本上说，我们有着很好的购买数据的历史。</p><p></p><blockquote>&nbsp;张宏江：&nbsp;最后一个问题，您对人工智能社区的设想是什么，以及在这个方向上可能具有很大推动力的因素是什么？</blockquote><p></p><p>&nbsp;</p><p>Sam Altman：在过去我说过：是什么推动您如此高度地激励去从事人工智能安全性工作？对我而言，没有比安全性工作更令人兴奋、活力四溢、充实且重要的事情了。我坚信，如果您个人对一项重要的倡议非常认可，您将会有无穷的力量去解决它。这对我们团队来说确实如此。当我们刚开始的时侯，我觉得成功的概率会非常低。但如果我们能够找出如何构建人工智能，那它肯定会产生巨大变革。我们必须进行安全方面的工作对吧？这就是其中的一部分。但您不能阻止AI的发展。</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-06-10 18:01:14",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "2023北京智源大会开幕，“悟道3.0”大模型系列发布，院长黄铁军：大模型技术不应该被垄断，而是要共建",
    "url": "https://www.infoq.cn/article/4M7Ldc6fc1gufQ7XT5MQ",
    "summary": "<p>2023北京智源大会开幕，“悟道3.0”大模型系列发布，人工智能顶级专家共话通用人工智能机遇与挑战</p><p>&nbsp;</p><p>6月9日，为期两天的“北京智源大会”在中关村国家自主创新示范区会议中心成功开幕。科技部副部长吴朝晖和北京市副市长于英杰出席开幕式并致辞。</p><p>&nbsp;</p><p>北京智源大会是智源研究院主办的年度国际性人工智能高端专业交流活动，定位于“AI内行顶级盛会”，以“国际视野、技术前沿、思想激荡、洞见未来”为特色，已连续举办5届。今年，大会邀请到了图灵奖得主Geoffrey Hinton、Yann LeCun、Joseph Sifakis和姚期智，张钹、郑南宁、谢晓亮、张宏江、张亚勤等院士，加州大学伯克利分校人工智能系统中心创始人Stuart Russell，麻省理工学院未来生命研究所创始人Max Tegmark，OpenAI首席执行官Sam Altman等200余位人工智能顶尖专家参会，嘉宾将以国际视角探讨通用人工智能发展面临的机遇与挑战。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/30/3006650c368b3371900e4889a96437be.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/52/5240c0035007ea8cccbe720198b0869d.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5f/5f3dcd8e90eb06876117a43227b85885.jpeg\" /></p><p></p><p>开幕式由智源研究院理事长张宏江主持。</p><p>&nbsp;&nbsp;</p><p>智源研究院院长黄铁军发布《2023智源研究院进展报告》，并发布了全面开源的“悟道3.0”系列大模型及算法，报告了在高精度生命模拟和有机大分子建模方面的最新进展。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/7c/7cf11b5a72a862aed779af2938d9624c.jpeg\" /></p><p></p><p>成果发布方面，继2021年悟道大模型项目连创“中国首个+世界最大”纪录之后，智源 “悟道3.0 ”进入全面开源新阶段，带来一系列领先成果：“悟道·天鹰”（Aquila）语言大模型系列、天秤（FlagEval）开源大模型评测体系与开放平台，“悟道 · 视界”视觉大模型系列，以及一系列多模态模型成果。</p><p>&nbsp;</p><p></p><h2>智源大模型系列全面开源，发布语言、视觉、多模态等先进成果</h2><p></p><p>&nbsp;</p><p>智源研究院是国内最早进行大模型研究的科研机构之一，自2020年10月就启动了大模型研发工作。</p><p>&nbsp;</p><p>据黄铁军介绍，在2021年3月，悟道1.0发布会上，智源研判人工智能已经从“大炼模型”转变为“炼大模型”的新阶段，从此，“大模型”这个概念进入公众视野。</p><p>&nbsp;</p><p>至于何为大模型？他认为需要具备三个条件：一是规模要大，参数达百亿规模以上；二是涌现性，能够产生预料之外的新能力；三是通用性，不限于专门问题或领域，能够处理多种不同的任务。</p><p>&nbsp;</p><p>悟道系列模型已发展到“悟道3.0”版本，涵盖语言、视觉、多模态等基础大模型，现在已全面开源。</p><p>&nbsp;</p><p>“悟道·视界”视觉大模型系列，实现六项技术突破，点亮通用视觉曙光。</p><p>&nbsp;</p><p>“悟道·视界”系统化解决了当前计算机视觉领域的一系列瓶颈问题，包括任务统一、模型规模化以及数据效率等，包括：</p><p>在多模态序列中补全一切的多模态大模型 Emu十亿级视觉基础模型 EVA一通百通、分割一切的视界通用分割模型首创上下文图像学习技术路径的通用视觉模型Painter性能最强开源CLIP模型 EVA-CLIP简单prompt（提示）即可视频编辑的 vid2vid-zero 零样本视频编辑技术</p><p>&nbsp;</p><p>多模态大模型 Emu接受多模态输入、产生多模态输出。通过学习图文、交错图文、交错视频文本等海量多模态序列，实现在图像、文本和视频等不同模态间的理解、推理和生成。训练完成后，Emu 能在多模态序列的上下文中补全一切，实现多轮图文对话、视频理解、精准图像认知、文图生成、多模态上下文学习、视频问答和图图生成等多模态能力。</p><p>&nbsp;</p><p>EVA为当前十亿级视觉基础模型，通过将语义学习和几何结构学习这两大解决视觉问题的关键点进行结合，让视觉模型的通用性更强，目前EVA在ImageNet分类、COCO检测分割、Kinetics视频分类等广泛的视觉感知任务中取得当时最强性能。</p><p>&nbsp;</p><p>多模态图文预训练大模型EVA-CLIP是当前性能最强的开源CLIP模型。EVA-CLIP基于视觉基础模型EVA研发，去年发布的EVA-CLIP 1B 版本，今年才被Meta在5月份刚发布的DINOv2模型追平。在今年年初发布的EVA-CLIP 5B版本创造了零样本学习性能新高度，超越此前最强的OpenCLIP模型，在ImageNet 1K数据集上零样本达到最高82%的准确率。</p><p>&nbsp;</p><p>Painter通用视觉模型首创「上下文图像学习」技术路径，图像理解图像、图像解释图像，图像输出图像：将自然语言处理中的上下文学习概念引入视觉模型，首创“上下文图像学习”技术路径，将“以视觉为中心”作为建模核心思想。目前Painter模型可完成7种主流视觉任务，性能相比国际同类模型具有11%-25%的性能提升。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/f8/f8c21774e9aec434fcba7dd3fd510b72.png\" /></p><p></p><p>一通百通，分割一切的视界通用分割模型，是首个利用视觉提示（prompt）完成任意分割任务的通用视觉模型，一通百通、分割一切。从影像中分割出各种各样的对象，是视觉智能的关键里程碑。今年年初，智源视界分割模型与Meta 的 SAM 模型同时发布，点亮通用视觉曙光。</p><p>&nbsp;</p><p>简单prompt（提示）即可视频编辑的 vid2vid-zero 零样本视频编辑技术，首次在无需额外视频训练的情况下，利用注意力机制动态运算的特点，结合现有图像扩散模型，实现可指定属性的视频编辑。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/d9/d9589606739c503f8e4db40554f8f540.jpeg\" /></p><p></p><p>为推动大模型在产业落地和技术创新，智源研究院发布“开源商用许可语言大模型系列+开放评测平台” 2 大重磅成果，打造“大模型进化流水线”，持续迭代、持续开源开放。</p><p>&nbsp;</p><p>悟道·天鹰Aquila 语言大模型是首个具备中英双语知识、支持商用许可协议、国内数据合规需求的开源语言大模型。</p><p>&nbsp;</p><p>悟道·天鹰Aquila 语言大模型是在中英文高质量语料基础上从 0 开始训练，通过数据质量的控制、多种训练的优化方法，实现在更小的数据集、更短的训练时间，获得比其它开源模型更优的性能。</p><p>&nbsp;</p><p>“悟道·天鹰”的开源属于一系列套餐，包括Aquila·基础模型、AquilaChat对话模型与AquilaCode（文本-代码）生成模型。</p><p>&nbsp;</p><p>开源地址：</p><p><a href=\"https://github.com/FlagAI-Open/FlagAI/tree/master/examples/Aquila\">https://github.com/FlagAI-Open/FlagAI/tree/master/examples/Aquila</a>\"</p><p>&nbsp;</p><p>Aquila基础模型（7B、33B）在技术上继承了 GPT-3、LLaMA 等的架构设计优点，替换了一批更高效的底层算子实现、重新设计实现了中英双语的 tokenizer，升级了 BMTrain 并行训练方法，在Aquila的训练过程中实现了比 Magtron+DeepSpeed ZeRO-2 将近８倍的训练效率。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/f3/f3869aeb9bca5afec9cbe54010ea84c4.jpeg\" /></p><p>&nbsp;</p><p>AquilaChat对话模型（7B、33B）支持流畅的文本对话及多种语言类生成任务；通过定义可扩展的特殊指令规范，实现AquilaChat对其它模型和工具的调用，且易于扩展。例如，调用智源开源的 AltDiffusion 多语言文图生成模型，实现了流畅的文图生成能力。配合智源 InstructFace 多步可控文生图模型，它还可以轻松实现对人脸图像的多步可控编辑。</p><p>&nbsp;</p><p>AquilaCode-7B “文本-代码”生成模型基于Aquila-7B强大的基础模型能力，以小数据集、小参数量，实现高性能，是目前支持中英双语的、性能最好的开源代码模型，经过高质量过滤，使用有合规开源许可的训练代码数据进行训练。</p><p>&nbsp;</p><p>此外，AquilaCode-7B 分别在英伟达和国产芯片上完成了代码模型的训练，并通过对多种架构的代码+模型开源，推动芯片创新和百花齐放。</p><p>&nbsp;</p><p>天秤（FlagEval）大模型评测体系及开放平台，旨在建立科学、公正、开放的评测基准、方法、工具集，协助研究人员全方位评估基础模型及训练算法的性能，同时探索利用AI方法实现对主观评测的辅助，大幅提升评测的效率和客观性。</p><p><img src=\"https://static001.geekbang.org/infoq/9a/9a29b9c6688cf771095894093fb91846.jpeg\" /></p><p></p><p>&nbsp;目前已推出语言大模型评测、多国语言文图大模型评测及文图生成评测等工具，并对各种语言基础模型、跨模态基础模型实现评测。后续将全面覆盖基础模型、预训练算法、微调算法等三大评测对象，包括自然语言处理（NLP）、计算机视觉（CV）、音频（Audio）及多模态（Multimodal）等四大评测场景和丰富的下游任务。</p><p>&nbsp;</p><p>首期推出的天秤（FlagEval） 大语言模型评测体系，创新构建了“能力-任务-指标”三维评测框架，细粒度刻画基础模型的认知能力边界，可视化呈现评测结果，总计 600+ 评测维度，包括 22个评测数据集，84,433道题目。</p><p>&nbsp;</p><p>天秤（FlagEval）开放评测平台现已开放申请（flageval.baai.ac.cn），打造自动化评测与自适应评测机制，可辅助模型研发团队利用评测结果指导模型训练，同时支持英伟达、昇腾（鹏城云脑）、寒武纪、昆仑芯等多种芯片架构及 PyTorch、MindSpore 等多种深度学习框架。</p><p>&nbsp;</p><p>天秤（FlagEval）评测体系是科技部2030旗舰项目重要课题，正与北京大学、北京航空航天大学、北京师范大学、北京邮电大学、闽江学院、南开大学、中国电子技术标准化研究院、中国科学院自动化研究所等合作单位共建（按首字母排序），定期发布权威评测榜单</p><p>&nbsp;</p><p>黄铁军院长提到，大模型不是任何一家机构或者一家公司垄断的技术，大模型技术体系是大家共建共享。我们要共建一个智力社会所需要的一套基础的算法体系。因此，智源研究院在打造开源生态方面做了许多努力。</p><p>&nbsp;</p><p>今年年初发布的FlagOpen大模型技术开源体系，经过一段时间的发展，又有了一系列发展。为大模型发展夯实底层技术栈，提供切实加速度。</p><p>&nbsp;</p><p>FlagOpen平台是智源建设的大模型技术开源体系。旨在打造全面支撑大模型技术发展的开源算法体系和一站式基础软件平台，支持协同创新和开放竞争，共建共享大模型时代的“新Linux”开源开放生态。</p><p>&nbsp;</p><p>数据集方面，智源已开源首个大规模、可商用的中文指令数据集COIG。COIG一期已开放总计19.1万条指令数据，COIG二期正在建设最大规模、持续更新的中文多任务指令数据集，整合了1800多个海量开源数据集，人工改写了3.9亿条指令数据，并提供了完善的数据筛选、版本控制工具，方便大家使用。</p><p></p><h2>大模型、生命智能、AI4Science，三大路线通向AGI</h2><p></p><p>&nbsp;</p><p>在攻关大模型的同时，智源一直关注“具身智能”技术路线，探索强化学习在多模态交互模型方面的潜力。近期，智源研究院提出了在无专家数据情况下高效解决《我的世界》任务的方法Plan4MC，可完成大量复杂多样任务，为当前强化学习路径下最优表现，成功率相比所有基线方法有大幅提升。我们的下一个目标是让智能体在开放世界中持续学习并进一步具备创造力。&nbsp;</p><p>&nbsp;</p><p>智源在AI for Science领域的探索，致力于人工智能与基础科学深度融合的崭新科研范式，延展不同科学领域的探索边界，造福人类与社会。在相关研究中，智源团队在生命演化和蛋白质结构预测方向作出了重磅成果。OpenComplex 是智源健康计算研究中心打造的面向生物大分子的开源人工智能算法平台，目前已开源蛋白质、RNA 以及复合物的高精度结构预测训练和评测代码。平台还建立了将「蛋白质结构预测」「RNA 结构预测」和「蛋白质-RNA 复合物结构预测」三类任务统一的端到端生物大分子三维结构预测深度学习框架。最近一年，智源 OpenComplex 团队在蛋⽩质结构预测权威竞赛 CAMEO中取得稳定领先成绩，连续在最近月度、季度、半年度和年度评测周期中排名第一。</p><p>&nbsp;</p><p>去年智源大会发布了最高精度的仿真线虫。现在，智源开放仿真线虫研究所使用的“天演“平台，提供在线服务。天演是超大规模精细神经元网络仿真平台，具有四项显著特点：当今效率最高的精细神经元网络仿真的平台；支持超大规模的神经网络仿真；提供一站式在线建模与仿真工具集；高质量可视化交互，支持实时仿真可视协同运行。</p><p>&nbsp;</p><p>基于天演平台，实现对生物智能进行高精度仿真，探索智能的本质，推动由生物启发的通用人工智能。为进一步推动神经系统仿真规模与性能，天演团队将天演接入我国新一代百亿亿次超级计算机-天河新一代超级计算机。通过“天演-天河”的成功部署运行，实现鼠脑V1视皮层精细网络等模型仿真，计算能耗均能降低约10倍以上，计算速度实现10倍以上提升，达到全球范围内最极致的精细神经元网络仿真的性能，为实现全人脑精细模拟打下坚实基础。</p><p></p><h2>智源大会：人工智能顶级专家共话通用人工智能发展机遇与挑战</h2><p></p><p>&nbsp;</p><p>随着ChatGPT等大模型的发布，全球人工智能掀起了新一轮发展热潮，国内外大模型技术研究与产业发展日新月异，通用人工智能进入全新发展时期。</p><p>&nbsp;</p><p>本次大会围绕当前大模型等通用人工智能技术发展的热点问题，汇聚顶尖专家，搭建国际交流合作平台，将为人工智能技术可持续发展注入强劲动力。</p><p>&nbsp;</p><p>在本届大会安排上，重点围绕以下三方面展开：</p><p>&nbsp;</p><p>1、通用人工智能发展现状与未来趋势：</p><p>&nbsp;</p><p>虽然大模型生成的内容质量持续在提升，但是仍有专家对大模型路径存疑。图灵奖得主Yan LeCun认为基于自监督的语言模型无法获得关于真实世界的知识，这些模型在本质上是不可控的，并提出了“世界模型（World Model）”的概念。</p><p>&nbsp;</p><p>本次大会重点围绕通用人工智能主要三条路径的前沿研究现状及未来趋势进行深入研讨。</p><p>深度学习大模型路径设置了基础模型前沿技术、视觉与多模态大模型、生成模型等论坛，具身方向设置了具身智能与强化学习论坛，类脑智能方向设置了基于认知神经科学的大模型、</p><p>类脑计算、AI生命科学等论坛，另外，还有智能的物质基础等更为前沿的研究方向。</p><p>&nbsp;</p><p>作为首位开场嘉宾，图灵奖得主Yann LeCun带来了题为“Towards Machines that can Learn, Reason, and Plan”的主题演讲，表达了他对通用人工智能发展路径的系统思考。</p><p>&nbsp;</p><p>图灵奖得主Joseph Sifakis、郑南宁院士和Graphcore联合创始人Simon Knowles等嘉宾还带来了精彩的线上特邀报告。同时，基础模型前沿技术、视觉与多模态大模型、具身智能与强化学习、类脑计算、大模型新基建与智力运营等专题论坛也陆续开启。</p><p>&nbsp;</p><p>2、安全伦理问题和风险防范：</p><p>&nbsp;</p><p>今年人工智能的发展出现了很大的变化，大模型出来了“涌现”能力，尽管还远没到“超人”的风险，但是，随着人工智能技术进步而来的是对安全风险问题关注的陡然提升。</p><p>本次大会，我们也邀请到了关于人工智能安全伦理问题方面的代表性人物进行思辨。</p><p>&nbsp;</p><p>大会开幕式上，未来生命研究所创始人Max Tegmark介绍受控下的AI发展， 分享了“Keeping AI under control”的报告，并与清华大学张亚勤院士进行了对话，共同探讨AI伦理安全和风险防范问题。</p><p>&nbsp;</p><p>6月10日全天的“AI安全与对齐”论坛，OpenAI联合创始人Sam Altman进行了开场主题演讲，围绕模型的可解释性、可扩展性和可泛化性给出了见解。随后，Sam Altman和智源研究院理事长张宏江开展了尖峰问答，主要探讨在当前的AI大模型时代，如何深化国际合作，如何开展更安全的AI研究，以及如何应对AI的未来风险。</p><p>&nbsp;</p><p>本次论坛众星云集，加州伯克利分校教授Stuart Russell、 图灵奖得主，中国科学院院士姚期智、Anthropic联合创始人Christopher Olah等等AI专家，也在论坛中给出了自己对当前AI可持续发展的洞见。</p><p>&nbsp;</p><p>3、开源开放创新生态建设</p><p>&nbsp;</p><p>当前，以大模型为核心的人工智能生态体系正在形成，大模型向下带动AI基础软硬件、AI系统、算力设施，向上支撑赋智经济社会各类应用。本次大会围绕底层基础设置大模型新基建与智力运营、AI系统等论坛，围绕应用设置自动驾驶论坛。</p><p>&nbsp;</p><p>开源开放是人工智生态建设的必然选择，本次大会专门设置了AI开源论坛，同时邀请了国际开源社区LAION的创始人，Linux基金会负责人共同探讨开源社区、开源生态的建设与运营，推动开源开放创新生态建设。</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-06-10 18:30:05",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "卷积神经网络之父的强人工智能路线图：自监督，推理，规划",
    "url": "https://www.infoq.cn/article/tc5foBg4sgLiIRTgNWAs",
    "summary": "<p></p><blockquote>2023 年 6 月 9 日，智源大会第一天。在这场众星云集的盛会中。目前「深度学习三驾马车」中最活跃的 Yann LeCun 教授带来了重磅演讲「朝向能学习， 思考和计划的机器进发（ Towards Machines that can Learn, Reason, and Plan）」。在此次演讲中，LeCun 对自己近年来倡导的自监督学习进行了梳理，从认知科学出发对人工智能领域未来 10 年的研究目标展开了更为宏大的畅想，提出了基于自监督学习、世界模型、推理、规划的强人工智能实现路线图。&nbsp;</blockquote><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/86/862051794dc64f8e3f09dab566b9cd7b.jpeg\" /></p><p></p><p>Yann LeCun是FAIR 首席AI科学家，Facebook人工智能实验室负责人，曾获得“神经网络先驱奖”。同时是美国国家科学学院、美国国家工程学院和法学院国家科学院的院士。2018年图灵奖得主。出版图书《科学之路：人，机器与未来》。</p><p></p><p>以下内容根据演讲速记进行整理，未经本人确认。</p><p></p><p>在这里，我们将谈一谈人工智能的未来。</p><p></p><p>从根本上来说，我们要弥平观察到的人类/动物的能力与当下的工智能之间的差距。</p><p></p><p>当下的 AI 系统不仅缺少学习的能力，还缺乏推理和规划的能力。在本次演讲中，我们将讨论人工智能下一个十年将走向何方，我将给出一些初步的研究结果，但还没有形成完整的系统。</p><p></p><p>与人类和动物相比，机器学习还有很大的不足。数十年来，我们广泛使用监督学习技术，而这需要太多的标签。强化学习效果很好，但学习任何东西都需要大量的尝试。近年来，自监督学习蓬勃发展。但这些系统针对专门的领域开发，且十分脆弱，它们会犯一些愚蠢的错误。尽管它们反映迅速，但既没有真正的推理也没有规划。当我们与动物和人类进行比较时，动物和人类可以非常快速地执行新任务，了解世界是如何运作的，可以进行推理和规划。人和动物有一定程度的常识，这是机器所没有的。这一问题在人工智能社区由来已久。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/96eb14e3b886d42d6b91769f2b46ce0c.png\" /></p><p>从一定程度上说，这是由于当前的机器学习系统在输入和输出之间有恒定数量的计算步骤，以致于它们真的不能像人类和动物那样推理和规划。</p><p></p><p>那么，如何让机器了解世界是如何运作的，并像人类一样预测行为的后果，如何执行无限步推理链，或者如何通过将复杂任务分解为子任务序列来进行规划？</p><p></p><p>在深入讨论之前，我们先谈谈近年来机器学习社区火热的自监督学习。今天，机器学习的许多成就都归功于自监督学习（特别是在自然语言处理和文本理解与生成领域）。</p><p></p><h2>自监督学习</h2><p></p><p></p><p>自监督学习旨在学到到输入中的依赖关系，而非简单构建输入到输出的映射。我们只是得到了一个意见。通常，我们遮盖输入的一部分，并将其输入给机器学习系统，让系统重建确实的输入部分，训练系统来学到可见部分和被遮盖部分之间的依赖关系。有时，这一过程通过预测缺失的部分来完成，有时也不完全是预测。</p><p></p><p>这在几分钟内得到了很好的解释。本质上，我们使用监督学习的方法，但我们将它们应用于输入本身，而不是与人类提供的单独输出相匹配。这种方法在自然语言处理领域了惊人的成功，是最近成功的大语言模型的基础。</p><p><img src=\"https://static001.geekbang.org/infoq/c0/c0dbd82f50d302268176c017e8400057.png\" /></p><p>通过自监督学习，神经网络学习了一个很好的内部表征，可以用于许多后续的监督任务。此类方法在翻译、文本分类等任务上取得了成功。同样，自监督学习也曾为了一些图像、视频或文本的生成式人工智能系统的基石。</p><p><img src=\"https://static001.geekbang.org/infoq/6f/6f77510bc2e1cbf8aedb29b6b8e07ef9.png\" /></p><p>一些用于文本处理的自监督学习系统是自回归的。他们不是通过预测随机缺失的词例（Token）来训练自监督系统，而是循环预测最后一个 token。一旦系统接受了大量数据的训练，就可以进行自回归预测，即不断预测下一个 token，然后把这个 token 移到输入中，如此循环往复。</p><p></p><p>这就是近年来一些流行的大模型的工作原理：其中一些来自 Meta 的同事，包括开源的 BlenderBot、Galactica、LLaMA、Stanford 的 Alpaca（Lama 基于 LLaMA 的微调版）、Google 的 LaMDA 、Bard、DeepMind 的 Chinchilla，当然还有 OpenAI 的 ChatGPT 和 GPT-4。</p><p></p><p>如果使用一万亿个 Token 或两万亿个 Token 的数据训练模型，它们将获得惊人的性能。但实际上，它们也会犯很愚蠢的错误（事实错误、逻辑错误、不一致性等），它们的推理能力有限，会产生有害内容。</p><p>大量研究表明，这些系统缺乏底层的现实知识，因为它们纯粹是通过文本来训练的，无法完全理解人类知识，无法真正规划答案。然而，这些系统在编写辅助工具、生成代码以及帮助程序员编程方面都非常出色。</p><p><img src=\"https://static001.geekbang.org/infoq/aa/aaa19d3b7b750cee2530ce8fd091aca3.png\" /></p><p>你可以让他们做各种事情：用各种语言写代码、生成文本，而且效果很好。但同样，他们会虚构一些故事。如果你想获知真实的信息，我们不如使用信息检索系统、搜索引擎。</p><p></p><p>所以，这些系统对于写作辅助、初稿生成、统计出版都很有帮助（尤其对于写作语言非母语者）。但此类系统不擅长给出真实、一致的答案。对于一些数据集中存在的行为，它们可以做得很好。然而，对于推理，计划，做算术之类的问题，他们要用搜索引擎计算器数据库查询之类的工具来解决。它们还需要得到进一步的训练。</p><p></p><p>目前研究的一个热门话题是，如何让这些系统调用上述工具。这被称为扩展语言模型。我和 FAIR 的同事讨论了为扩展语言模型提出的各种技术。我们很容易被目前的 AI 系统流畅的性能所欺骗，以为他们很聪明，但实际上并非如此。这些系统非常擅长「提取记忆」。但是，他们并不理解世界的运行原理。这种基于自回归的生成存在一个主要的缺陷。</p><p></p><p>不妨想象所有可能答案的集合（token 序列）是一个树。在这个巨大的树中，有一个小的子树对应于给出提示的正确答案。如果我们想象任何 token 在树外的平均概率为 E，产生的错误之间是相互独立的。那么，得到正确答案的概率是 1-e 的 n 次方。</p><p></p><p>对于自回归预测而言，得到正确答案的树有一个指数发散的过程。除了让 e 越小越好。所以我们必须重新设计这个系统。事实上，学者，们已经指出了一些系统的局限性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bf/bffa380d3c345fef83547379254b89ba.png\" /></p><p>许多认知科学研究证明，这些系统没有关于物理世界的经验，这使得它们的能力非常有限。一些非机器学习的经典人工智能论文试图分析这些系统的规划能力：这些系统不能真正地进行规划，至少不能以与搜索和规划中使用经典人工智能类似的方式进行规划。</p><p></p><h2>如何快速学习？人和动物的启发</h2><p></p><p>那么，人类和动物如何得以快速学习?</p><p><img src=\"https://static001.geekbang.org/infoq/6f/6ffdcbfa3b939e9b23b0f66623b6522a.png\" /></p><p>婴儿在生命的最初几个月里学习了大量关于世界运作的背景知识，这是一些非常基本的概念（例如，物体的恒久性，世界是三维的，有生命的和无生命的物体之间的区别，稳定性的概念，重力）。如上图所示，婴儿在 9 个月大的时候就学会了重力的概念。</p><p></p><p>如果您向 5 个月大的婴儿展示下面左下角的场景：小车在平台上，将小汽车从平台上推下来，它似乎漂浮在空中，5 个月大的女婴不会感到惊讶。但是 10 个月大的婴儿会非常惊讶，因为经过这 5 个月的学习期间，婴儿已经知道了物体不应该停留在空中，它们应该在重力下下落。这些基本概念是通过观察世界和体验世界来习得的。我们应该用机器复制这种通过观察世界、体验世界来学习世界如何运作的能力。</p><p><img src=\"https://static001.geekbang.org/infoq/7e/7ea9179c844ed6b77034d3a938300b3e.png\" /></p><p>显然，我们在设计 AI 时遗漏了一些重要的东西。任何一个青少年都可以在20个小时的练习中学会开车，而我们仍然未能拥有完全可靠的 L5 级。为什么我们有流利的对话系统，可以通过法律考试或医学考试，但我们没有可以清理餐桌的家用机器人?这是任何一个 10 岁的孩子都能在几分钟内学会的东西。目前的人工智能系统，远没有达到人类的智力水平。</p><p></p><h3>人工智能发展路线图：表征、推理、规划</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/40/400a8e8a23e233599a864d5fff573bea.png\" /></p><p>那么，我们要怎么做呢?</p><p></p><p>事实上，我认为，人工智能研究面临三大挑战：</p><p>（1）通过自监督学习习得表征并预测世界模型。当下的自监督和强化学习需要大量的样本和试验。我们要通过自监督学习，以一种任务无关的方式表征世界。学习用于规划和控制的预测模型。</p><p>（2）学会推理：犹如 Daniel Kahenman 提出的「系统 1 &amp; 系统 2」的理论。系统 1 是一种与潜意识计算相对应的人类行为或行为，你不需要思考就能做的事情。系统 2 是有意识地用你的大脑的全部力量进行推理。当下的人工智能系统大多停留在系统 1 的阶段。</p><p>（3）学习规划复杂的动作序列。通过将复杂的任务分解成简单的任务来分层次地计划复杂的动作序列。</p><p>在论文「A Path Towards Autonomous Machine Intelligence」中，我提出了一些对未来 10 年人工智能研究方向的建议。</p><p></p><h3>世界模型</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/52/5224be7fd997b324e5d81d672bc33b88.png\" /></p><p>我们可以将各种模块组织成一个所谓的认知架构，该系统通过世界模型想象一个场景，想象会发生什么，即行为的结果。整个系统的目的是根据它自己的预测，用世界模型规划出一系列行动，使代价最小化。这些模块在大脑中都有相应的子系统：代价模块是我们脑中的「世界模型｜——前额皮质；短时记忆对应海马体；效应器对应前运动区；感知系统位于大脑后部，所有传感受器的感知分析都是在这里进行的。</p><p></p><p>这个系统的会结合之前可能存储在记忆中的世界的想法处理世界的状态。然后，用世界模型来预测如果世界变化了会发生什么或者智能体采取行动会带来什么结果会发生什么。</p><p></p><p>如上图所示，在这个黄色的效应模块里，智能体提出了一系列操作。世界模型模拟世界，并计算出这些行为的后果，计算出代价。接下来，系统会优化动作序列，使世界模型代价最小化。</p><p></p><p>上图中，每个箭头对应一个反向的梯度。所以我假设所有这些模块都是可微的我们可以通过反向传播梯度来推断动作序列从而最小化代价。这不是关于参数的最小化，这是在推理时为了做出动作而对潜在变量的最小化。&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/19/19d1882792d8c5ea867be9268524d49e.png\" /></p><p>实际上，有两种方法来使用该系统：</p><p></p><p>（1）反应性策略：观察世界的状态，通过一个感知编码器运行它，生成世界状态，然后直接通过一个策略网络运行，而效应器直接产生一个行动。&nbsp;</p><p></p><p>（2）在 0 时刻，观察世界并提取世界状态的表征。然后，系统想象出从 a[0] 到一个很长T（时间）的一系列行动。这些预测的状态输入给一个代价函数，系统旨在找出行动的序列，根据预测使成本最小。因此，这里的世界模型在每个时间步骤中被复用，根据时间 T 的世界表征中预测出时间 T+1 的世界状态，并想象出要完成的行动。这个想法与优化控制领域的「模型预测优化」十分类似。</p><p><img src=\"https://static001.geekbang.org/infoq/44/4491008aa854ca75e05fc6b57fa70501.png\" /></p><p>我们还希望做一个更复杂的版本：一个层次化的系统。该系统通过一系列编码器提取越来越多的世界状态的抽象表示，并使用不同层次的世界模型预测器，来预测世界的不同状态，并在不同的时间尺度上做出预测。</p><p></p><p>例如，如果我想从纽约去北京，要做的第一件事就是去机场，然后乘飞机去北京。最终的代价函数可以表示我到北京的距离。然后第一个动作是:去机场。第二个动作是，赶飞机去北京。那么，我该怎么去机场？你可以把这个任务分解到毫秒级，通过毫秒级的控制来完成这个大小。</p><p></p><p>所以，所有复杂的任务都是通过这种方式分层完成的，我们不知道如何用今天的机器学习来解决这一问题。层次化规划这是一个很大的挑战。</p><p></p><p>代价函数可以由两组成本模块组成：</p><p>（1）固有成本。固有的成本是固定不变的。这些成本函数将确保系统正常运行，</p><p>（2）可训练成本。用来模拟完成任务的满意度，假设所有这些模块都是可微的。</p><p></p><h3>构建&amp;训练世界模型</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/6e/6e137bf7fc3e2e4f37e90f04575f6c10.png\" /></p><p>假设我们要捕获上图视频中的依赖关系，根据现在或过去的视频进一步预测视频的未来片段。如果你训练一个 2016 年的神经网络来预测视频，会得到非常模糊的预测。因为系统不能提前预测视频中会发生什么，所以它预测的是所有结果的平均值。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7a/7a0b772c0bffbdbc88ee9ac8903ee11d.png\" /></p><p>在这里，我们提出「联合嵌入预测架构」，从而处理多模态问题。加入我们有生成式架构，比如VAE、MAE。自动编码器，或者我之前说过的大型迁移模型。有一个观测变量 X、编码器、预测器/解码器，产生一个预测变量预测 Y，然后测量某种散度。该系统存在缺陷：要预测 Y 的每一个细节。。当 Y 是离散变量时，这相对容易；但当 Y。是连续变量时，比如一组视频帧，预测视频帧中的所有细节基本上是不可能的，而且大部分细节都无法捕捉。因此，我提出了右边的「联合嵌入预测架构」。</p><p><img src=\"https://static001.geekbang.org/infoq/ed/edaee8bec1bb921678b40780b04dc55e.png\" /></p><p>在该架构下，X 和 Y 都是通过编码器输入的，预测发生在表征空间而非输入空间。预测网络试图根据 X 的表征预测 Y 的表征。这种联合嵌入架构的一个简单形式是我在很多年前的90年代初提出的「孪生网络」，在过去的几年里，这种架构在图像自监督学习中逐渐流行起来。</p><p></p><p>此外，除了 MAE 及其变体，没有其它生成式架构可以很好地学习视觉特征。但从某种意义上说，它产生的特征不是很好。你需要对系统进行微调以获得好的结果。</p><p></p><p>所以，如果你想要在不进行微调的情况下得到好的特征。你需要使用联合嵌入架构（例如，MoCo、 SimCLR），它们在自监督学习方面做得很好，并产生了非常好的特征。</p><p></p><p>这里没有列出的另一种方法是 Dino，这是一个稍微复杂一点的联合嵌入版本，包括一个预测器，它试图根据 x 的表示预测 y 的表示，而不是仅仅试图使它们相等。但这将是一个确定性的预测。右边是这个系统的一个版本。在这个系统中，预测器将一个潜在变量作为输入，这个潜在变量可以用来参数化一系列可能的预测，基本上是做出非确定性的预测。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bd/bd5211f173656da8ce7cb3c3143fe5c5.png\" /></p><p>在 JEPA 系统中，世界模型的预测器会有两个变量，一组潜在变量 z 代表所有未观察到的变量代表世界的状态，让你预测接下来会发生什么；另一组变量 a 代表你可能采取的行动。</p><p></p><p>所以从对世界X状态的观察中，你提取出它的一个表征，然后给它一个动作，通过对一组潜在变量的采样，你可以通过编码器对 Y 状态的表征做出一个预测。</p><p></p><p>接下来，我们如何训练这个系统？</p><p></p><p>这个系统可能包括其他在右上方表示的标准，比如C (S)它可能表示我们希望系统满足的约束条件；或代价函数，它表示我们希望系统学习提取的信息类型。</p><p></p><h3>训练：基于能量的模型</h3><p></p><p></p><p>我们不能通过传统的概率建模方法来理解这些系统，需要用到基于能量的模型。一个能量函数，捕获了两变量 x 和 y 之间的依赖关系，通过一个标量输出来表示。当标量输出很小的时候，x 和 y 相互兼容的时候。当 y 与 x 不兼容时，它会取更大的值。如上图右侧所示，x 和 y 是标量变量，数据点集就是那些黑点。</p><p></p><p>能量函数将神经网络参数化并训练。我们希望能量函数在数据点周围取低值，然后在数据点外取高值。你可以把它看作是一个隐函数，它表示 x 和 y 之间的依赖关系。通过学习训练这个能量函数很容易，训练后的数据点提供低能量。</p><p><img src=\"https://static001.geekbang.org/infoq/74/74814e919ea960217dbacce43641888d.png\" /></p><p>然而，很难弄确保在训练样本之外的能量更高。有两类方法可以做到这一点。一种叫做对比方法，它包括产生对比点，这些绿色的闪烁点，在数据的集合之外，然后把它们的能量推高。</p><p></p><p>我们同时把现有的数据点的能量降低，然后产生对比的数据点，把它们的能量提高。通过在正确的位置上下推，能量面就会呈现出正确的形状。我更倾向于正则化的方法，在能量函数上施加一个正则化器，这样低能量的空间体积就被限制或最小化了。所以当你压低某个区域的能量时，其他区域就会上升因为只有有限的体积可以吸收低能量。</p><p><img src=\"https://static001.geekbang.org/infoq/28/28a22b440685059f1737a790138a2e89.png\" /></p><p>我认为，对比方法有一个主要的限制，那就是随着 y 的空间维度的增加，需要生成的能量函数形状正确的对比点的数量，随着维度呈指数增长。正则化方法往往更有效，因为它基本上最小化了可以消耗低能量的空间体积。</p><p><img src=\"https://static001.geekbang.org/infoq/05/05fed1ae570f98ab65819ce9d81e2df6.png\" /></p><p>我认为我们应该做到以下四点：</p><p></p><p>（1）放弃生成模型。现在生成模型很流行。我想说的是，如果你想要一个可以学习世界模型的系统，仅仅通过生成是不行的，因为在高维连续空间中进行预测太复杂了。所以我们必须使用联合嵌入架构，这意味着我们必须放弃使用生成模型的想法。</p><p>（2）放弃使用概率模型。而使用那些基于能量的框架。原因是，如果你要通过编码器对 y 编码，你不能反转这个编码器函数来产生 y 在给定 x 时的条件概率p。必须放弃对分布建模的想法。你只需要计算这个能量函数，它是一个更简单的只能提，就像一个分布。</p><p>（3）放弃对比i方法，选择正则化方法。</p><p>（4）放弃强化学习。首选规划方法，只有在我们别无选择的情况下才使用强化学习。</p><p></p><h3>联合嵌入的正则化方法</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/f6/f6c966e8de3d10bcbaee257e028d2603.png\" /></p><p>这是这次演讲的核心。如果我们只是训练一个联合嵌入预测架构(JEPA)来最小化预测误差，也就是根据 x 的表示预测 y 的表示所产生的误差，系统基本上会崩溃，因为它会忽略 x 和 y 产生的向量 Sx和 Sy，导致预测误差为零。这个模型不会捕捉到 x 和 y 之间的依赖关系，因为它会为任何东西赋予零能量。你会成功地使训练样本的能量很低，但能量在任何地方都是零。你必须防止这种崩溃的发生。</p><p></p><p>在这里，我们提出的技术本质上是对 Sx 的信息内容和 Sy 的信息内容进行一些度量，并将它们最大化。</p><p>所以找到一种最大化 Sx 和 Sy 的信息含量的方法，这将防止这种崩溃。事实上，它具有正则化效果，尽量减少占用你能量的空间。</p><p></p><p>如果你有一个潜在变量作为预测器，你还需要正则化这个潜在变量的信息内容，并将其最小化。如果你有一个信息量太大的变量，也会让它崩溃。</p><p></p><p>如何使 Sx、Sy 的信息量最大化?使这些系统崩溃的一个简单方法是使 Sx 和 Sy 为常数。你可以通过一个运行时的代价函数来防止这种情况的发生，它保证了 Sx 的所有组成部分的标准差高于某个阈值。如上图所示，Hinge 损失使得 S 的每个分量的标准差都大于1。所以系统只能输出常数。这是在一批样本上计算的，对 Sx 和 Sy 做同样的处理。这叫做方差正则化。</p><p><img src=\"https://static001.geekbang.org/infoq/4d/4de4fc17a792ac7816317b820adf2b0d.png\" /></p><p>这还不足以防止系统崩溃，因为系统可以选择使 Sx 的所有分量相等或非常相关。所以你要做的就是最小化前一个矩阵 Sx 的非对角线项。取一对坐标，测量它们的协方差对于两个不同的坐标，试着最小化协方差项。代价函数是每一对变量的协方差项的平方。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/26/26f46e5b646e82ad9d2830ec40f564c4.png\" /></p><p>VICReg（方差不变性协方差正则化）让 Sx 通过扩展模块，得到一个更大的向量 Vx。然后对这个较大的向量 Vx 应用方差协方差准则。这将会使 Sx 的分量更加相互独立，至少是成对独立。我们可以用相互扭曲的图像对来训练一种联合嵌入架构。可以将这些特征应用到其他任务中，这些任务是对图像的扭曲版本进行预训练的。</p><p><img src=\"https://static001.geekbang.org/infoq/9e/9e484663b93a495e7c4dd2857d6a662f.png\" /></p><p>这将是局部的VICReg，这对于分割来说非常有效。这个系统产生了非常棒的分割功能。Dino V2也产生了很好的分割特征。在很多方面都很相似，防止崩溃的方法不同，其表征是量化的，但在很多方面，这是一个非常相似的想法。</p><p><img src=\"https://static001.geekbang.org/infoq/4c/4c91aecdd06f26b077b0b045bca79acf.png\" /></p><p>Image-JEPA 是一种联合嵌入预测架构，它们完全基于 mask。这并不是在做数据增强。取一个图像，将其输入一个编码器，产生一个表示。在这种情况下，编码器是一个Transformer。我们通过Transformer得到图像的完整表示。然后我们通过相同的Transformer处理部分masking版本的图像。所以这两个有相同的权重。这就产生了较弱的局部特征。然后，我们训练了一个预测器来预测从完整图像产生的表示，从部分图像获得的表示。它产生了非常好的特性，运行非常快，且不需要任何数据增强。</p><p></p><h3>将层次化 JEPA 用于层次化规划</h3><p></p><p></p><p>我们可以使用JEPA架构来提取输入的低级表示，并在短期内使用大量细节进行预测。</p><p></p><p>或者我们可以做的是运行另一个编码器，它将提取一个更高层次的抽象，在相反的地方做出更长期的预测。较低的层次可能涉及现实世界中的实际行动，较高的层次将涉及潜在变量，这些变量可能表示与实际行动不对应的高级行动。</p><p><img src=\"https://static001.geekbang.org/infoq/41/41b13bb99cbcc54f26826c0b81ead472.png\" /></p><p>我们为视频预测构建了一些这种层次架构。该架构并不完美，但我们似乎可以从视频中学到很好的特征。它从视频中取两帧，送入编码器，并有一些预测器试图层次化地从第一帧的表示中预测架构的表示，使用相同的编码器从图像中进行训练。</p><p></p><p>预测器有一个特殊的结构，迫使表示遵循某种几何变换，变形向量场是自顶向下预测的。这个系统会自发地，通过自监督学习学到视频中两个连续帧之间的扭曲，并学习提取代表所有信息的表示。如果你用一种全局图像识别标准同时训练它，你最终得到的系统可以估计光流。但我们也可以提取表征，可以用于对象识别和分割。</p><p></p><h2>结语</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/17/179c5d3f88f0f0f154d40e0d5a21e059.png\" /></p><p>如果我们成功地制造了这种层次化的系统，它是完全通用的，我们能够将它们整合到一个系统中。这个系统可以预测由于行动或潜在变量的结果会发生什么，然后用这个系统来做规划。在某种程度上，通过能量最小化进行规划可以看作是一个非常普遍的推理框架。推理总是可以用最小化某个能量函数的形式来表述，所以这比自回归生成更强大。</p><p><img src=\"https://static001.geekbang.org/infoq/fd/fd7e08920f26d51ca2cc0215b2811bd7.png\" /></p><p>因此，走向强人工智能系统的步骤包括：使用SSL从观察中学习世界模型，使用JEPA架构和框架处理预测中的不确定性，通过使用相对于动作变量的能量最小化来推理和规划。</p><p></p><p>这是一种不涉及任何符号或逻辑的推理，只是向量的连续优化。这种架构也许可能将我们引向人类水平的智能。还有待探究。</p><p><img src=\"https://static001.geekbang.org/infoq/5f/5ffbea0cf195692c04878eccaeba2375.png\" /></p><p>所恐惧是由对潜在负面结果的预期引起的，而兴奋是由对非常积极的结果的预测产生的。这样的目标驱动的系统，被称之为目标驱动的人工智能，它会有情感，它会有动力，它会是可控的，因为我们可以通过这些代价函数为它们设定目标。比自回归模型更可控。通过适当地设计这些成本函数，我们可以确保这些系统不会想要接管世界。相反，服从人类并且安全。</p><p></p><p>演讲过后，杨立昆以视频连线的方式对话了朱军教授，以下内容为现场对话访谈：</p><p></p><p></p><blockquote>朱军：生成模型会输出多种选择。另外，当我们应用生成模型的多样性时，创造性是一个理想的属性。所以我们经常乐见用模型来输出多样化的结果。这是否意味着实际上像事实错误或不合逻辑的错误，不一致的地方，对于这样的模型来说是不可避免的？因为在很多情况下，即使你有数据，数据也可能包含了矛盾的事实。你也提到了预测的不确定性。</blockquote><p></p><p></p><p>杨立昆：没错。所以我不认为自回归预测模型、生成模型的问题是可以通过保留自回归生成来解决的。我认为这些系统本质上是不可控的。因此，我认为它们必须被我提出的那种架构所取代，即在推理中包含时间，有一个系统去最优化成本和某些标准。这是使它们可控、可引导、可计划的唯一方法，即系统将能够计划出它们的答案。</p><p></p><p>你知道当你在做一个像我刚才那样的演讲时，你会计划演讲的过程，对吗？你从一个点讲到另一个点，你解释每个点。当你设计演讲时，你在脑子里会计划这些，而并不是（像大语言模型一样）一个字接一个字地即兴演讲。也许在较低的（行为）水平上，你是即兴创作，但在较高的（行为）水平上，你是在计划。</p><p>所以，计划的必要性真的很明显。而人类和许多动物有能力进行规划的事实，我认为这是智力的一个内在属性。所以我的预测是，在相对较短的几年内--当然是在5年内--没有正常人会接着用自回归大预言模型。这些系统将很快被抛弃。因为它们是无法被修复的。</p><p></p><p></p><blockquote>朱军：我在你的设计和框架中，一个关键部分是内在成本模块，对吗？所以它的设计基本上是为了决定智能体行为的性质。看了你的工作文件中的开放性观点后，我和网上的一个评论有共同的担忧。这个评论说，主要是这个模块没有按照规定工作。</blockquote><p></p><p></p><p>杨立昆：保证系统安全的成本模块不会是一个微不足道的任务，但我认为这将是一个相当明确的任务。它需要大量仔细的工程和微调，其中一些成本可能要通过训练获得，而非仅仅通过设计。这与强化学习中的策略评估（Actor-Crtic结构中的Ctric，对作为语言模型的行为者产出的结果进行评估）或LLM背景下的所谓奖励模型是非常相同的，是一个会整体考量系统的内部状态到成本全程的事情。</p><p></p><p>你可以训练一个神经网络来预测成本，你可以通过让它接触大量的——让它产生大量的输出，然后让某人或某物对这些输出进行评价来训练它。这给了你一个成本函数的目标。你可以对它进行训练，让它计算出一个小的成本，然后在得到成本之后通过它进行反向传播，以保证这个成本函数得到满足。</p><p></p><p>所以，我认为设计成本这事儿，我认为我们将不得不从设计架构和设计LLM的成本转向设计成本函数。因为这些成本函数将推动系统的性质和行为。与我的一些对未来比较悲观同事相反，我认为设计与人类的价值观相一致的成本（函数）是非常可行的。这不是说如果你做错一次，就会出现人工智能系统逃脱控制和接管世界的情况。而且我们在部署这些东西之前，会有很多方法把它们设计得很好。</p><p></p><p></p><blockquote>朱军：你通过分层的JEPA设计来模型，这其中几乎所有的模块都是可微的？也许你可以用反向传播的方法来训练。但是你知道还有另外一个领域，比如说符号逻辑，它代表着不可微的部分，也许在内在成本模块中能以某种形式制定我们喜欢的约束条件，那么，你是否有一些特别的考虑来连接这两个领域，或者干脆就忽略符号逻辑的领域？</blockquote><p></p><p></p><p>杨立昆：对。所以我认为是的，现实中是有一个神经+符号架构的子领域，试图将可训练的神经网络与符号操作或类似的东西结合在一起。我对这些方法非常怀疑，因为事实上符号操作是不可微的。所以它基本上与深度学习和基于梯度的学习不兼容，当然也与我所描述的那种基于梯度的推理不兼容。</p><p></p><p>我们应该尽一切努力在任何地方使用可微分的模块，包括成本函数。现在可能有一定数量的情况下，我们可以实现的成本（函数）是不可微的。对于这一点，执行推理的优化程序可能必须使用组合型的优化，而不是基于梯度的优化。但我认为这应该是最后的手段，因为零阶无梯度优化比基于梯度的优化要少很多。</p><p>因此，如果你能对你的成本函数进行可微调的近似，你应该尽可能地使用它。在某种程度上，我们已经这样做了。当我们训练一个分类器时，我们想要最小化的成本函数并不完全准确。但这是不可微分的，所以我们使用的是一个可微分的成本代理。是系统输出的成本熵与所需的输出分布，或像e平方或铰链损失的东西。这些基本上都是不可微分的二进制法则的上界，我们对它不能轻易优化。因此还是用老办法，我们必须使用成本函数，它是我们实际想要最小化的成本的可微调近似值。</p><p></p><p></p><blockquote>朱军：我们听说你将参加一场关于AGI的现状和未来的辩论。由于我们大多数人可能无法参加，你能否分享一些关键点给我们一些启发？我们想听到一些关于这方面的见解。</blockquote><p></p><p></p><p>杨立昆：好的，这将是一场有四位参与者的辩论。辩论将围绕一个问题展开，即人工智能系统是否会对人类造成生存风险。因此，马克斯和约书亚本吉奥将站在 \"是的，强大的人工智能系统有可能对人类构成生存风险 \"的一方。然后站在 \"不\"的一方的将是我和来自圣菲研究所的梅兰妮-米切尔。</p><p></p><p>而我们的论点不会是AI没有风险。我们的论点是，这些风险虽然存在，但通过仔细的工程设计，很容易减轻或抑制。我对此的论点是，你知道在今天问人们，我们是否能保证超级智能系统对人类而言是安全，这是个无法回答的问题。因为我们没有对超级智能系统的设计。因此，在你有基本的设计之前，你不能使一件东西安全。这就像你在1930年问航空工程师，你能使涡轮喷气机安全和可靠吗？而工程师会说，\"什么是涡轮喷气机？\" 因为涡轮喷气机在1930年还没有被发明出来。所以我们有点处于同样的情况。声称我们不能使这些系统安全，因为我们还没有发明它们，这有点为时过早。一旦我们发明了它们--也许它们会与我提出的蓝图相似，那么就值得讨论。</p><p></p><p>\"我们如何使它们安全？\"，在我看来，这将是通过设计那些使推理时间最小化的目标。这就是使系统安全的方法。显然，如果你想象未来的超级智能人工智能系统将是自回归的LLM，那么我们当然应该害怕，因为这些系统是不可控制的。他们可能会逃脱我们的控制，胡言乱语。但我所描述的那种类型的系统，我认为是可以做到安全的。而且我非常肯定它们会。这将需要仔细的工程设计。这并不容易，就像在过去七十年里，使涡轮喷气机变得可靠并不容易一样。涡轮喷气机现在令人难以置信的可靠。你可以用双引擎飞机跨越大洋，而且基本上具有这难以置信的安全性。因此，这需要谨慎的工程。而且这真的很困难。我们大多数人都不知道涡轮喷气机是如何设计成安全的。</p><p></p><p>因此，想象一下这事情这并不疯狂。弄清楚如何使一个超级智能的人工智能系统安全，也是很难想象的。&nbsp;</p>",
    "publish_time": "2023-06-10 18:47:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "可观测性也“卷”起来了！过去十年，我们在阿里云如何建设可观测体系？ | 卓越技术团队访谈录",
    "url": "https://www.infoq.cn/article/jgzBEmozGmBsUKeWFf6J",
    "summary": "<p>IT 系统的运维监控最早出现在上世纪 90 年代。彼时，分布式架构正向传统的单体架构发出挑战，其带来显著优势的同时，也为系统开发和运维带来了新的难题。在这一背景下，IT 人员开始引入监控技术，观测主机上的应用运行情况，及时定位问题。</p><p></p><p>随着分布式系统、微服务、云计算技术兴起，IT 系统发生多轮演进，复杂的运维环境对监控提出了更高的要求。2018 年，CNCF 将可观测性引入 IT 领域，取代监控。可观测性也一跃成为云原生技术领域最热门的话题之一。</p><p></p><p>5 年后的今天，可观测性技术早已从早期的运维排查问题工具，逐渐进化成业务生产过程中的生产力工具。Gartner 更是将应用可观测性列为“2023 年十大战略技术趋势”，并表示“如果能够在战略中予以规划并成功执行，可观测性应用将成为数据驱动型决策的最强大来源”。</p><p></p><p>作为阿里巴巴集团最早的监控 &amp; 可观测团队，云原生可观测团队早年打造了 EagleEye（鹰眼）作为分布式调用跟踪系统应用于阿里内部各业务线，随后将该工具进行产品化，结合云上客户的广泛需求，打造出了阿里云应用实时监控服务 ARMS。</p><p></p><p>那么，阿里云云原生可观测体系的建设背景与历程是什么样的？可观测体系建设的重难点是什么？如何从内部自研走向产品化？2023 年，企业和开发者应该如何理解可观测性？在本期访谈中，InfoQ 有幸采访到了阿里云云原生可观测团队的多位核心成员，以期找到上述问题的答案。</p><p></p><h2>阿里云云原生可观测体系建设历程</h2><p></p><p></p><p>2010 年 4 月，Benjamin H. Sigelman 等人在 Google Technical Report 上发表了一篇名为《Dapper, a Large-Scale Distributed Systems Tracing Infrastructure》的论文，介绍了 Google 生产环境中大规模分布式系统下的跟踪系统 Dapper 的构建和部署经验。这篇论文正式揭开了分布式链路追踪的技术大幕，也为后来涌现出的包括 EagleEye 在内的分布式调用系统提供了灵感源泉。</p><p></p><h3>分布式链路追踪 EagleEye 的设计与实现</h3><p></p><p></p><p>2012 年，阿里的淘宝电商业务正处于高速增长期，为满足业务快速迭代的需求，支撑不断提高的交易量，阿里采用微服务架构对整个业务逻辑做了一次重构。微服务架构在性能、可维护性和可用性上带来优势的同时，也带来了四大难题：</p><p></p><p>故障定位难：一个简单的下单购买操作背后是由十几个甚至数十个微服务共同完成的，这些微服务又由不同的团队负责，微服务的过度协同带来的结果就是，一旦出现问题，需要十几个团队一起来解决；容量预估难：在大促场景下，过去只需按照预估的流量与当前系统的单机压测容量做对比，再将所有的系统按比例去扩容即可，但在微服务架构下，每个系统在核心链路中的参与度、重要性都不同，无法进行等比例的扩容；资源浪费多：这也是容量预估不准造成的后果，同时，资源浪费多也会引发性能优化难的问题；链路梳理难：复杂的微服务体系，让各个微服务系统的负责人很难梳理清楚每种业务的上下游细节逻辑对自身系统的影响。</p><p></p><p>“我印象比较深刻的是，当时淘宝已经迭代出了上百个应用，但却没有一个业务架构师能够讲清楚整个业务的系统架构是什么样子的。正是在这个时候，我们遇到了 Google 的《Dapper, a Large-Scale Distributed Systems Tracing Infrastructure》这篇论文，我们参考了 Google 的主要思想，在阿里内部做了落地实践。”阿里云可观测技术负责人司徒放回忆道。</p><p></p><p>正是在这一背景下，EagleEye 应运而生。EagleEye 是一个以链路追踪技术为核心的监控系统，通过收集、存储、分析分布式系统中的调用事件数据，协助开发和运维人员进行故障诊断、容量预估、性能瓶颈定位以及调用链路梳理。2012 年，EagleEye 第一次发版，EagleEye 1.0 能够构建链路跟踪核心体系，提供调用链与离线报表服务。</p><p></p><p>当时虽未出现可观测性一词，但业界已将其分解为三个更具体的方向展开研究：Metrics（指标）、Tracing（链路追踪）以及 Logging（日志）。这三大方向也是此后 OpenTelemetry 协议定义的可观测性三大支柱。</p><p></p><p>最开始，EagleEye 主要关注 Tracing 领域，这也是业界比较早期的大规模 Tracing 实践。“EagleEye 解决了阿里当时微服务架构下的分析和诊断挑战，有很多阿里内部研发人员在应用它。”司徒放说道。</p><p></p><p>2013 年上半年，EagleEye 打通了淘系所有常见中间件的调用数据，应用负责人能看到自己的系统在整个链路上的执行情况，为大促和单元化的容量规划、依赖分析提供了数据支撑，并具备了快速定位分布式系统故障的能力。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/de/de3418d5b45b8cc9fbbb7a898c676d0b.png\" /></p><p></p><p>EagleEye 的第一个重要发展契机是淘宝的双十一大促，这是 EagleEye 的首次大规模应用。也是在这时，EagleEye 上线了实时链路大盘，为全链路压测提供压测透传和链路来源流量分析。</p><p></p><p>当时，为了提前做好系统容量的准备，阿里对线上系统进行了全链路压测，而全链路压测的底层其实是与 EagleEye 的 Tracing 能力紧密相关的。于是，EagleEye 从 Tracing 领域切入到 Metrics 和 Logging 领域，通过 Traces 去做流量级别的、精准的 Metrics 数据统计，用来分析上下游应用的依赖关系，提供一个全局流量拓扑。同时抽象了一个通用的实时日志处理系统，用来做通用的日志采集、计算、存储方案，进一步提升问题排查效率。</p><p></p><p>EagleEye 1.0 之后，团队陆续发布了 2.0、3.0、4.0 版本，围绕链路跟踪的核心能力， EagleEye 逐步构建了集监控、诊断、优化于一体的综合性服务平台：提供多维查询与实时报表以及数据分析能力；基于内存统计，提供精准实时报表与系统监控服务；基于链路追踪，提供单机诊断与业务定制化服务。</p><p></p><p>脱胎于 EagleEye，2017 年，云原生可观测团队打造出了应用实时监控服务 ARMS，并于 2022 年 6 月推出阿里云云原生可观测套件（Alibaba Cloud Observability Suite），打造云原生时代完整可观测数据生态与产品套件。</p><p></p><h3>从内部自研工具到产品化</h3><p></p><p></p><p>EagleEye 从最初的内部自研工具走向产品化，是一个自然而然的过程。</p><p></p><p>在自研体系下，EagleEye 的出现为阿里内部降低了成本和风险，提高协作效率。同时，在云原生变革的大趋势下，云原生可观测团队也越来越深刻地意识到，PaaS 类产品一定得是开放的，是基于标准和开源的。结合云上客户的广泛需求，云原生可观测团队将 EagleEye 进行产品化，打造出了阿里云应用实时监控服务 ARMS。</p><p></p><p>“阿里内部的技术栈是比较统一的，在内部业务场景中，我们采用完全自研的形态去支撑业务没有任何问题。但外部客户的技术栈百花齐放，要求所有人学习和使用我们的技术体系并不现实。于是，我们的整个可观测体系从自研转向了开源的 Prometheus。”司徒放提到。</p><p></p><p>Prometheus 最初是由前 Google 工程师在 SoundCloud 上构建的开源系统监视和警报工具包，自 2012 年创建以来，许多公司和组织都采用其作为监控告警工具。2016 年，Prometheus 加入 CNCF，成为继 Kubernetes 之后的第二个 CNCF 托管项目。</p><p></p><p>如今，Prometheus 已经成为云原生时代的可观测事实标准。根据 CNCF《Cloud Native Observability MicroSurvey》调查，84% 受访者在可观测技术栈中使用 Prometheus。</p><p></p><p>司徒放表示，转向 Prometheus 架构后，再去审视移动端、应用、中间件、云服务的基础设施监控等子领域，我们发现采用开放的体系可以让整个数据模型得到统一，整个实体关联也更加简单。“这和当时秦始皇统一六国后实行的书同文、车同轨、度同制道理是一样的。我们的整个可观测体系统一后，打通了很多数据孤岛。”</p><p></p><p>在转变的过程中，云原生可观测团队也面临着来自技术与思维的双重压力。</p><p></p><p>技术上，过去团队支撑内部业务应用，可观测工具能够保证运行稳定、快速响应业务需求即可。但可观测云产品的市场需求多元，对易用性、可扩展性，以及应用集成的能力要求较高，并需要满足数据安全标准。思维上，过去团队着重关注技术，但现在也需要考虑如何做好商业化产品，需要设计产品的差异化能力，以及盈利模式、用户增长。</p><p></p><p>“这些对于我们团队来说，都是过去没有经历过的问题，我认为这个过程也是一个很好的机会。能够把自己擅长的技术打造成一个可能会被全球各个企业广泛使用的产品，并与其他世界一流的产品展开竞争，对于程序员来说，这应该是最大的荣耀和梦想。”司徒放说道。</p><p></p><p>在 Gartner 发布的《2022 Gartner 应用性能监控与可观测魔力象限》中，Gartner 将阿里云定义为此魔力象限中的细分领域者，并给予了高度评价。</p><p></p><p>当前，阿里云可观测产品由核心产品应用实时监控服务ARMS、可观测监控 Prometheus版、可观测可视化 Grafana 版、可观测链路 OpenTelemetry 版联合云监控 CMS、日志服务 SLS 共同组成，以公共云 SaaS 服务、混合云不同产品形态为不同规模、不同业务需求的企业提供开箱即用的可观测服务。其中，阿里核心容器调度（千万核规模）以及超过 50 款云产品，全面基于 Prometheus 构建可观测体系。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/fe/fea0aef880d5d036375c40bd61a1be72.png\" /></p><p></p><p>在提到与同类型产品的差异化时，阿里云可观测高级技术专家徐彤表示，阿里云可观测产品及解决方案的显著优势是上下游产品生态的支持，结合阿里云整个原生生态，用户可以在一个统一的平台上实现对云计算应用的全方位可观测，效率与便捷性大幅提升。过去，EagleEye 在阿里内部积累了大量运维场景经验，脱胎于 EagleEye，ARMS 也积累了丰富的行业应用与运维经验。</p><p></p><p>此外，阿里云可观测产品形态丰富，可观测监控 Prometheus 版托作为完全兼容开源 Prometheus 的全托管监控服务，提供开箱即用的 Grafana、智能告警等组件，并预置常见场景模板。用户无需关注系统搭建与日常维护，有效提升运维监控效率。在开源开放方面，阿里云可观测产品兼容业界通用的 OpenTelemetry 标准，支持多语言协议及 SkyWalking、Jaeger 平滑迁移。</p><p></p><p>“开放与集成是我们很重要的能力，我们坚持将开源标准和产品集成到平台，方便用户在现有产品的基础上进行拓展和优化。同时我们也在积极贡献开源社区，与业界共同推动云原生可观测生态发展。”徐彤介绍道。</p><p></p><p>下一阶段，阿里可观测产品体系的重点是数据的集中管理和关联，整个系统端到端的分析将更加全面、完整、统一，同时结合可观测下游服务与人工智能技术，从监管控一体化走向智能化运维。</p><p></p><h2>云原生可观测团队：从“幕后”走到“台前”</h2><p></p><p></p><p>从打造 EagleEye 应用于阿里内部各业务线，到打造阿里云应用实时监控服务 ARMS 服务更多企业，云原生可观测团队基于可观测行业趋势，将开源项目与商业产品相结合，帮助越来越多的企业获得完整的可观测能力，节省运维成本。</p><p></p><p>徐彤表示，随着当前千行百业以及云产品对可观测的重视度与日俱增，可观测在云原生体系中所扮演的角色也发生了变化，很多团队会主动找过来，一起建设自己的可观测能力。“在过去，我经常说我们团队是幕后无名配角，但现在，我们也会开玩笑说，自己已经慢慢地走到了台前男二号的角色。大家更重视我们，我们也会提供更多、更重要的能力，二者结合，越走越远。”</p><p></p><p>而 EagleEye 既是阿里云云原生可观测团队打造的第一个产品，也是云原生可观测团队最初的名字，其诞生背后的逻辑其实是客户需求和行业趋势决定的。</p><p></p><p>据司徒放介绍，企业做云原生数字化转型会先选择做容器化、微服务架构的改造，这也导致整个开发、运维体系以及协作模式发生翻天覆地的变化。在这一背景下，云原生团队开始进一步孵化出可观测团队。目前，云原生可观测团队主要由包括应用监控、前端监控、链路跟踪、告警管理、Prometheus、Grafana在内的技术团队，以及运营、解决方案等团队构成。“在整个云原生大团队中，可观测团队的定位就是为我们的客户提供一套统一、高效、易用的原生可观测解决方案。在日常工作中，云原生可观测团队与容器、存储和网络、安全、解决方案等多个团队密切协作。”</p><p></p><p>作为可观测产研团队的重要组成部分，运营团队也在其中扮演着重要作用。</p><p></p><p>“云上产品和服务越来越走向 PLG （Product Lead Growth）模式，运营也变得更加重要，作为足球比赛中‘中场’的角色，即衔接用户需求与产品服务。”阿里云可观测高级运营专家王希正认为，在市场侧，从应用性能监控领域到可观测，市场发生了很大变化，运营团队需要构建全新的技术内容，协助开发者快速找到解决自身问题所匹配的技术方案，并配套开发者体验场景及优秀的文档能力，让开发者能够自体验自生产自服务。在服务侧，可观测产品作为数据汇聚地，如何呈现数据从而辅助决策至关重要。运营团队需要提供丰富的模板，帮助开发者自助享受云上可观测能力，真正用起来、用得好。</p><p></p><p>作为“中场”，运营团队还需要拥有出色的数据洞察能力，发现不同业务场景下的主流用户需求及体验问题，驱动产品研发为用户提供更好的服务。“未来，B 端产品尤其是以 SaaS 交付方式提供的产品，产品驱动增长的 PLG 模式将成为主流。运营同学除了做好增长外，更多需要深入到自身产品的使用体验中，基于市场的洞察推动产品改进到一个领先的位置。这也会是整个团队的一大助力。”王希正总结道。</p><p></p><h2>可观测力即生产力</h2><p></p><p></p><p>2018 年，CNCF 将可观测性引入 IT 领域。5 年后的今天，可观测再次获得了广泛关注，并被 Gartner 认定为“2023 年十大战略技术趋势”。Gartner 表示，可观测性使企业、机构能够利用数据来获得更加明显的竞争优势，在最恰当的场景挖掘出数据背后的战略价值，以便规划与决策战略方向而不是盲目的快速行动。因此，可观测性应用作为一种强大的工具，如果能够在战略规划过程中充分使用，这将成为数据驱动型决策最强大的支持。</p><p></p><p>阿里云可观测高级产品专家曹剑认为，与 5 年前相比，当前可观测市场正迈入一个全新的阶段——数据为王。</p><p></p><p>随着千行百业进行云原生架构转型升级，可观测数据量得到了指数级增长，数据之间的关联分析以及传输也带来了可观测数据模型的标准化，标准化也会反过来促进数据的上下游协作，并进一步催生出多个细分市场。比如，有些厂商专门做可观测数据的采集，有些厂商专门做可观测数据的编排，等等。而在安全、软件质量等场景下，新的可观测产品也瞄向了新的客群。“现在不单是运维同学在应用可观测产品，运营、市场以及管理者，都开始使用可观测工具。在这样一个数据为王的时代，谁能够把可观测的数据价值挖掘出来，谁就能够给用户提供更好的可观测服务。”</p><p></p><p>与此同时，随着国内云服务越来越成熟，开发者用云深度增加，可观测作为具有代表性的云服务，已经从早期的运维排查问题工具逐渐变成了业务生产过程中的生产力工具。</p><p></p><p>王希正表示，从近些年国内外可观测的发展来看，有一个很明显的趋势是，企业的可观测力即生产力：</p><p></p><p>从云产品视角看，当前云计算不再只提供资源服务，越来越多的云产品能够帮助企业更 + 高效、更易用、更安全的创建云原生应用，使业务研发模式发生深刻的变革，各个云的组件本身都需要提供开箱即用的可观测力。以 MQ 为例，它其实代表了企业业务数据的流向，云上的 MQ 通过 Prometheus+Grafana 提供的可观测能力可以快速对线上消息消费问题进行排查和定位，还能通过分析消息流量变化趋势、流量分布特点或消息体量，帮助客户更好的进行业务规划，这也驱动了可观测的发展。</p><p></p><p>从开发者及企业视角看，构建可观测力不止是运维或者 SRE 部门的事情，越来越成为企业业务决策的一个方向。对于产品业务部门来说，可观测能够将业务数据与 IT 性能与指标关联，是 PLG 产品的必备条件；对企业管理者来说，可观测产品有助于构建高效的 Issue to resolve 流程，为 IT 和业务提效。</p><p></p><p>“整体来说，驱动可观测增长的重要动因实际是当前越来越激烈的市场竞争以及高效的研发模式，从过去的月度发版到很多业务的周迭代，势必要引入可观测能力去主动发现流程与过程问题，而不是在问题出现后才去解决。”王希正总结道。</p><p></p><h2>写在最后</h2><p></p><p></p><p>2023 年，可观测性技术还将持续地发展与演进。</p><p></p><p>未来，AI 驱动的可观测将得到更多应用，并对数据进行了更加高效的整合，故障预测、异常检测、自动化业务都会逐步变得智能化，可以更好地降低成本。同时，随着低代码的应用更加广泛，企业运维门槛降低，可观测性技术也需做好迎接这一趋势的准备。此外，用户对安全隐私保护重视度与日俱增，未来的可观测产品设计中，也需要更加注重合规性与安全性，充分保护数据。而在实时性方面，随着应用程序以及基础设施建设完善，可观测系统本质上等同于大型数据处理系统，如何更快、更稳定地处理数据也是从业者需要思考的课题。</p><p></p><p>徐彤表示，下一步，云原生可观测团队会重点关注几个方向：</p><p></p><p>可观测性技术演进：持续关注可观测领域的技术动态，并与开源项目以及行业标准相结合，优化现有产品。同时探索 AI 技术在可观测领域的应用，帮助用户实现更加智能的自动化运维。可观测性体系化建设：当前的可观测产品主要聚焦在运维监控阶段，在整个软件生命周期的管理中位置偏后，需要结合其他技术继续往前走。解决方案：每个行业在不同阶段都有自己的可观测解决方案诉求，需要深入了解各个行业的痛点以及诉求，为用户提供一站式的可观测能力。持续运营：加强运营动作，帮助用户更好地理解和应用可观测性技术。全球化：关注全球化的可观测性诉求。</p><p></p><h4>嘉宾介绍：</h4><p></p><p></p><p>司徒放，阿里云可观测技术负责人，资深技术专家。</p><p>徐彤，阿里云可观测高级技术专家。</p><p>曹剑，阿里云可观测高级产品专家。</p><p>王希正，阿里云可观测高级运营专家。</p>",
    "publish_time": "2023-06-10 19:36:59",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]