[
  {
    "title": "小红书的降本增效之路",
    "url": "https://www.infoq.cn/article/OVsMQqTOZjfy7tGhQqio",
    "summary": "<p></p><blockquote>本文由 InfoQ 整理自小红书基础技术部后端开发 孙晓飞 在 QCon 全球软件开发大会（北京站）2022 上的演讲《小红书的降本增效之路》。</blockquote><p></p><p>&nbsp;</p><p>大家好，我是孙晓飞，目前就职于小红书容器架构组，负责团队内调度系统整体工作，拥有 6 年云原生相关开发设计经验，是 Kubernetes 和 Volcano member。本文将分享过去一年中，容器架构团队为小红书和整体容器服务在降本增效方面所采用的方案措施。</p><p>&nbsp;</p><p></p><h2>小红书与云原生</h2><p></p><p>小红书早在2013年成立之初便坚定了云原生的方向，主要原因也是出于成本方面的考量，对小型厂商而言，将服务全部上云意味着无需自行搭建 IDC 机房、构建运维体系，便于成本节约。依托云厂商所提供的云服务，小红书可以将主要精力投入到业务研发，快速地迭代升级。经过九年多的发展，小红书的容器化率已经达到80%有余。</p><p>&nbsp;</p><p>然而，云厂商所提供的便捷云交付方式是一把双刃剑。短短几分钟便可完成的 Kubernetes 集群构建和交付也带来了不少问题：</p><p>集群碎片化。早期小红书对集群申请方面缺乏相对专业的评估，内部业务线轻松申请到的小规模集群数量众多，导致了资源的滥用。版本碎片化。集群申请后缺乏专业团队维护导致版本停滞不前，而 Kubernetes 在过去九年间已有大规模版本迭代，内部集群跨越1.8~1.22版本，特性差异极大。资源碎片化。为处理不同业务场景（如 Redis 的 I/O 问题），容器团队会申请8核16G之类小型机型作为 node 节点，其机型过小导致后续资源优化难度极大。</p><p></p><p></p><h2>容器架构</h2><p></p><p>容器团队的主要工作可按架构分为不同层级，如下图所示：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ee/ee785ebd06214c586aecd7e73d964aa9.png\" /></p><p></p><p>&nbsp;</p><p>在小红书内部，许多业务最初都是由工程师在集群中提交 YAML 任务申请才能实现服务搭建，为降低业务成本，我们内部构建了容器云平台便于常规业务构建使用。其他平台还包括存储平台（Redis 等）、搜推平台和训练平台。为便于管控，我们搭建了统一的 API 层用于对接所有平台。</p><p>&nbsp;</p><p>在架构下层，我们构建了发布引擎以控制业务的灰度升级、多集群调度模块以筛选出适合业务的集群、服务画像以处理分析历史数据中业务特性、常规 HPA 和 VPA 以处理服务弹性。其次，因为机器涉及多个集群，存在许多机器长期闲置的情况，因此采用巡检模块以便于精细管理；CA（Cluster Autoscaler）模块用于集群自动扩缩节点；定制 workload 面向分片服务；有状态服务定制的 operator；联通小集群的 virtual kubelet。</p><p>&nbsp;</p><p>最后，我们还构建了用于闲置机器治理的 descheduler，其中 descheduler 模块的默认周期性轮巡无法满足部分业务需求，因此我们也通过事件触发的方式对其进行了重构改造；自定义 kube scheduler 集群调度器用于抢占云厂商的默认锁；用于离线训练服务的批调度 Volcano；用于安全防护的 webhook；主要用于混部和故障检测的 node agent。</p><p></p><p></p><h3>容器云平台</h3><p></p><p>早期小红书内部业务均是通过 YAML 模式进行部署，这对许多研发而言门槛非常高；新服务往往需要查询许多文档才能完成搭建。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/62/626329c33f1603483d9851ad9397b144.png\" /></p><p></p><p>&nbsp;</p><p>对此，我们希望能将容器云平台的设计尽量简化，让用户只需提供镜像、灰度部署步长、目标实例数等配置，即可实现完整的发布。容器扩缩容也可以通过简单指定实例数实现。当然，我们也提供根据具体业务自定制的高级特性。除了效率的提升，容器云平台的构建还屏蔽了多云多版本的差异，通过封禁发版的行为规范用户行为，以平台侧规范注入的方式，降低了先前业务通过 YAML 模式进行的资源申请的治理成本。</p><p>&nbsp;</p><p></p><h3>多集群调度</h3><p></p><p>涉及多个集群的业务在发布过程中，无从得知集群资源情况，此时就需要多集群调度模块将具体集群资源情况返回业务服务，之后再通过规则发布引擎将其下发至具体集群进行管控。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/db/db80633e3b3ca03b91877d2da64e9ad6.png\" /></p><p></p><p>&nbsp;</p><p>多集群调度模块会同时监听多个集群，其中 Cache 负责缓存 node、pod 等相关资源信息。PlugIn 模块则类似于定制化的 Kube Scheduler 插件，主要负责节点过滤；配置插件启用的 Profile 模块则是负责同步集群中调度策略，不同调度策略都有可能影响集群最终的调度。</p><p>&nbsp;</p><p>在接收到业务请求后，我们首先会筛选出满足业务所需集群特性的 Zone 下的集群列表，根据业务对 pod 等相关信息的请求，计算集群可创建资源，并最终根据其策略筛选出合适集群。如选择剩余资源最多的集群，或根据服务容灾情况返回按一定比例分布的多个集群。</p><p>&nbsp;</p><p>我们在集群调度模块中，主要实现了以下几个方面：</p><p>资源分配。根据集群剩余资源情况进行资源最优分配，保障实例调度完成后不出现 pending 情况。服务迁移。在调度器层屏蔽底层集群场景，做到业务新旧集群迁移时的无感知。集群容灾。单个集群故障不影响其余集群正常运行。资源水位。通过 metrics 监听所有集群剩余资源情况，根据资源水位管控结果腾挪资源或机器退机。资源解释。调度器涉及插件策略众多，为简化排查机器不可调度原因，我们在多集群调度中新增了对应接口，用户只需提供实例和机器信息便能查到节点调度失败原因，如内存不足、PVC 或 Label Selector 亲和性等问题。</p><p>&nbsp;</p><p></p><h2>容器侧的降本增效改造</h2><p></p><p></p><h3>分片管理</h3><p></p><p>分片管理的特性主要面对搜索、数据库等有状态服务，主要用于将无法被服务独立承载业务请求拆分，最终将每个分片单独计算的结果汇总返回用户。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/db/dbd415ecd75aabe4343b73ee2144f2a4.png\" /></p><p></p><p>&nbsp;</p><p>在分片管理中，每组分片是一组独立的有状态服务，由一个分片组 workerload 控制所有分片，用于控制分片扩缩容，确保每一组分片都可同步进行扩缩容和灰度发布。此外，在调度器侧，我们也将分片的多个副本强制打散，确保其不会出现在同一台机器之上。业务侧的安全运维工作则是由相关 operator 实现，如创建 NFS、cluster-svc、PDB 等主要用于防止有状态服务的业务误操作情况发生。</p><p>&nbsp;</p><p></p><h3>Webhook 扩展</h3><p></p><p>我们也在 Webhook 层进行了扩展，其中包含 PVC 动态 bind、动态超售、删除保护、资源转换、变量注入、规范校验，以下进行展开：</p><p>&nbsp;</p><p></p><h4>PVC 动态绑定</h4><p></p><p>Kubernetes Deployment 之类无状态服务因为其随机的命名方式，导致无法动态创建 PVC，为此，我们在 Webhook 层进行了相应注入。业务只需在 pod annotation 中添加指定字段，便能在 Webhook 层自动创建 PVC，并将其更新至 pod 的 YAML 模板中。该功能只能在 Webhook 层实现，因为提交至集群的 pod YAML 模板将无法变更。</p><p>&nbsp;</p><p></p><h4>动态超售</h4><p></p><p>许多业务套餐申请不合理，而容器平台无法单独为业务进行变更，因此我们通过服务画像获取监控数据，计算 node 节点当前利用率信息，从而得出超售系数。如下图所示，我们在 Webhook 层拦截 Kubelet 上报的 node allocatable 信息请求（64核256G），如果我们通过计算得出其超售系数为2，则会将该 node 的节点资源信息视作128核256G。通过这种方式，我们可以在集群中部署更多服务，而超售系数的动态调整也允许我们根据资源超发或节点利用率提升等情况，进行热点驱逐。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/65/65cb40469bd70bcd3b0b29b6fab9ce85.png\" /></p><p></p><p>小红书大部分服务在前期仍使用1：2机型，在这种情况下单纯的 CPU 超售无法解决节点不可用的问题，为此我们通过将其置换为1：4大机型，充分利用超售资源，从而实现了整体退机4万余核、单节点利用率提升5%~15%的目标。</p><p></p><h4>删除保护</h4><p></p><p>这一功能与小红书先前遭遇的几起故障相关。通过在 Webhook 层拦截请求，限制 Ingress Service 等对象的随意删除，仅允许添加特定 Label 的请求才允许进行全部服务对象的删除操作。</p><p>&nbsp;</p><p></p><h4>资源转换</h4><p></p><p>Webhook 层的资源转换功能主要为实现独立扩展资源（如离线资源）的业务无感知。</p><p>&nbsp;</p><p></p><h4>变量注入</h4><p></p><p>环境变量如 Region、Zone 等业务相关信息，以及 Sidecar 等变量注入均在 Webhook 层实现。</p><p>&nbsp;</p><p></p><h4>规范校验</h4><p></p><p>业务必须遵守小红书内部制定的规范，如业务套餐 Request 大小限制，出于内部机型限制问题，过大的 Request 会导致服务调度失败。</p><p></p><p></p><h3>资源弹性</h3><p></p><p>云厂商提供资源的一大优势是资源弹性，我们可以按需申请机器。直接从云厂商处获取的机器可能会因为资源不足或者网络限制导致失败，需要人工介入。从云厂商开新机器大约耗时五分钟，一些高优服务扩容是无法容忍这个开机时间。</p><p>&nbsp;</p><p>我们在集群部署了 CA（Cluster Autoscaler）在集群内维护的一定 Buffer 池，提前储备部分机器，减少业务扩容等待时间。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f8/f8bfbf20e7bc6a799f311f86161c9737.png\" /></p><p></p><p>&nbsp;</p><p>CA 会在检测到业务扩容失败时，直接从 Buffer 池中添加机器至业务池，但如果 Buffer 池资源不足我们也会直接从云厂商库存中获取机器。缩容同理，在业务池进行缩容时，CA 会对机器进行碎片整理，将大机器清理完成后放入 Buffer 池中，如果 Buffer 池中机器存在超过 24 小时则会自动退回云厂商库存，从而实现资源的弹性管理。</p><p>&nbsp;</p><p>因为小红书中部分业务对 daemonset 部署的基础组件有强依赖，只能通过 CA 管控常规机器的方式进行扩缩容。至于其他对公司内部基础组件没有依赖度的业务，则可直接使用云厂商的 EKS 或 ECI。对弹性服务而言，白天高峰期短暂使用（低于 16 小时）EKS 或 ECI 资源往往会比常规机器价格便宜，但这也取决于各家的不同报价折扣。</p><p></p><h3>服务弹性</h3><p></p><p>我们的服务弹性功能是基于常规 HPA&amp;VPA 进行了定制开发的改造。小红书内部 Kubernetes 集群版本碎片化严重，各个集群的 HPA&amp;VPA 行为不一致，很难为其提供行为保障。因此，我们在集群之上开发了统一 HPA&amp;VPA 功能，通过采集服务画像和 Prometheus 信息，从而实现了定时扩缩容、按利用率扩缩容，以及业务自定义指标扩缩容能力。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/da/dac542f6783af1baa6646d1338e4d2a5.png\" /></p><p></p><p>&nbsp;</p><p>此外，我们也新增了按资源余量扩缩容的能力，主要面向转码等离线资源使用。我们希望能让转码等离线服务充分利用夜间时段的空闲资源，夜间资源扩容较多可能导致正常在线业务扩容失败，而夜间扩容较少则可能导致资源浪费，按资源余量扩缩容可以更充分地利用资源。</p><p>&nbsp;</p><p>以转码服务为例，我们在根据服务画像获取到业务平均利用率的推荐值后，首先对其进行定时扩缩容的改造，后续再根据业务指标进行改造，在我们所提供的推荐 CPU 利用率下，整体的业务资源使用量减少20%左右，服务利用率则从40%提升至60%。</p><p></p><p></p><h3>统一 Kube-scheduler</h3><p></p><p>小红书 Kubernetes 集群版本众多，集群版本横跨1.12至1.20。为了统一集群调度行为满足未来调度需求，我们选择基于目前较为稳定且版本最新的1.22进行改造开发。</p><p>&nbsp;</p><p>由于 Kubernetes 集群均是托管至云厂商，master 组件对我们而言并不可见，我们首先修改了1.22版本 Kube-scheduler 调度器抢锁逻辑，将我们自己调度器的锁优先级调整至最高，云厂商调度器变为 standby 模式，从而接管整体集群的调度。</p><p>&nbsp;</p><p>1.18~1.20版本：Kubernetes 集群没有太多变化，主要为 PVC、volume 相关版本从 alpha 升级 至 GA 等等，故而版本兼容只需简单通过 feature-gates=CSIStorageCapacity=false,PodDisruptionBudget=false 命令关闭没用到的 CSI、PDB 等功能。</p><p>&nbsp;</p><p>1.14~1.16版：将 NodeVolumeLimits、VolumeBinding 关闭，前者是为限制每个 node 中 PVC 数量，其中插件多半为国外云厂商所提供，故而我们进行了单独的改造。VolumeBinding 延迟挂载在我们大部分场景，尤其是低版本，因此我们也将该插件注销。</p><p>&nbsp;</p><p>1.12-1.13版本：因为1.22版本默认抢锁模式是通过 Lease 实现，因此我们只需在部署时抢锁模式指定为 endpoint。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a4/a416f3fbffd6ab17f3b95fcae5da09f9.png\" /></p><p></p><p>&nbsp;</p><p>通过调度器版本统一，我们可以统一所有集群的所有调度器行为。此外，我们也开发了插件定制化，其中包括：</p><p>负载调度。如图中右上所示，开启负载调度后内存利用率基本趋于均衡。L3cache 绑核。小红书所使用的主要为相对较为廉价的 AMD 机器，其架构主要为 Zen，使用 CCX 的 CPU 堆叠模式，即 AMD 每四个物理核（即八个逻辑核）共享一个 L3cache。因此我们在进行调度时需要尽量将8核或16核机器绑定至同一个 L3cache 上，从而提高 cache 命中率，进而提升服务利用率。如右下所示，部分服务在开启 L3cache 后利用率有显著下降。服务打散策略。默认调度器的服务打散仅针对 deployment、statefulSet 等原生 workload，因此我们需要针对定制 CRD 进行扩展，使其具备打散能力。此外，我们也定义了强制打散、尽量打散等策略。抢占。根据服务特性，我们对抢占功能进行定制开发。</p><p>&nbsp;</p><p></p><h3>Volcano 调度与抢占</h3><p></p><p>我们在训练集群的服务主要用 Volcano 调度器。小红书的训练服务高峰期主要在夜间，为应对夜间资源量不够的情况，我们将部分峰值流量卸载至云厂商的 EKS，从而减少机器成本。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6c/6c4687dcf2e1b79102697e87ea0ef03b.png\" /></p><p></p><p>&nbsp;</p><p>由于很多在线集群的服务开启了HPA，在线集群在夜间时段也有很多剩余资源。我们通过 virtual kubelet 打通在线集群与训练集群，让夜间的部分训练任务能够在在线集群中运行。</p><p>&nbsp;</p><p>我们的训练任务使用的是 Kubeflow 计算框架 ，TFjob 训练任务套餐大、数量多，再加上按照 queue、资源池划分机器资源，整体集群资源碎片较多。为此我们会用部分低优先级、可随时中断的离线任务填充资源碎片空间。此外，因为 TFjob 往往根据业务触发时间提交，时间不固定所带来的碎片时间也可以用低优先级的离线任务填充。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/40/40179f819fa449ed828e5de832a8b58f.png\" /></p><p></p><p>&nbsp;</p><p>我们增强了 volcano 的抢占功能，批调度的抢占和普通的抢占不同，因为训练集群大部分时间有大量 pending 的训练任务在等待调度，不能以 pod 维度进行抢占，必须以 podgroup 批调度维度进行抢占。volcano 在抢占之前，会进行预调度，在预调度阶段计算出驱逐哪些离线转码服务，能让整个训练任务整体可以运行，才会执行抢占动作。</p><p>&nbsp;</p><p>训练集群只损失了30s+的启动时间（需要等待离线转码服务30s退出），但整个训练集群的利用率提升了约10%。</p><p>&nbsp;</p><p></p><h3>闲置资源</h3><p></p><p>我们通过巡检模块，从服务画像中获取机器过去三天的资源使用情况，再结合机器当前资源信息生成报表，从而发现业务闲置机器。机器闲置原因有很多，可能是业务在申请后遗忘了机器，业务在先扩后缩，灰度发布时所申请的 buffer 资源，为防止业务紧急扩容而提前储备的 buffer 机器等等。</p><p>&nbsp;</p><p>我们会根据巡检模块生成的闲置机器报表，如果是业务遗忘的机器，会进入退机流程；其他情况则会将机器添加指定 label，加入到闲置池中，这一过程主要是通过 Descheduler 二次调度器实现。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/46/4617a621d5862a0c12d08bc9c725fefe.png\" /></p><p>Descheduler 会定期检测 node 节点的闲置情况，连续超过10分钟的闲置机器会被标记为 VK Buffer，并放入 VK Buffer 池中。如果在线业务在扩容时因为资源被占用而调度失败，我们会通过 Descheduler watch 到调度失败信息，并将 VK Buffer 池中机器上的离线服务驱逐，将机器并归还给业务。</p><p>&nbsp;</p><p>对业务而言，日常更新升级不受影响，只是服务扩容时间略有增加，但整体集群的资源利用率得到有效提升。</p><p>&nbsp;</p><p></p><h3>混部资源</h3><p></p><p>混部资源的主要组成部分是业务申请与实际使用的差，再加上集群的碎片化资源，整体架构有参考阿里的 Koordinator。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/69/69eafbd4813f4d9b29ee224c453835ff.png\" /></p><p></p><p>&nbsp;</p><p>架构上层的 SLO manager 主要负责全局计算，综合计算 node 节点资源使用、剩余情况，如网络带宽等方面，从而得出机器节点可用资源情况。</p><p>&nbsp;</p><p>Agent 侧的 QoS 保障模块总管离线服务，根据离线抑制策略和资源使用情况判断是否需要执行驱逐。该模块同时也负责干扰检测，将干扰在线业务的离线服务进行驱逐。其余模块还包括指标采集、接口模块。</p><p>&nbsp;</p><p></p><h3>闲置资源治理</h3><p></p><p>由于小红书集群多且比较分散，每个集群闲置机器或者混部资源并不多，我们通过 VK 将各个小块资源聚合起来，统一接入到元数据集群，进行统一调度分配。</p><p>&nbsp;</p><p>VK 下层则接入了在线集群、训练集群，以及混部集群资源：</p><p>在线集群：通过 descheduler 巡检找出闲置机器训练任务：volcano通过抢占提供的碎片资源混部集群：混部资源</p><p>&nbsp;</p><p>我们将离线服务大致分为近线和离线两类：</p><p>&nbsp;</p><p>近线服务 pod 可以被驱逐，资源供给可以有几分钟的延迟。这类业务优先使用常规 node、闲置资源、混部资源，高峰时段还可以使用 EKS 资源。</p><p>&nbsp;</p><p>离线服务则可以容忍长时间 pending，对于这类服务，会使用近线资源剩余的部分，不会用 EKS 资源。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f7/f71a4ce5da52167d2d0c772f3113d985.png\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>通过闲置资源治理，在线闲置池能为我们提供约五万核算力，训练集群能提供约一万核算力、在线集群混部资源则也有五万核算力，整体为我们带来了11万核的算力。</p><p></p><h2>成果</h2><p></p><p>总体来说，我们的成果如下：</p><p>通过超售及机型置换，实现了退机四万核的目标闲置池资源治理，提供了五万核算力资源混部，提供了五万核算力整体集群利用率提升了约7%</p><p></p><h2>探索</h2><p></p><p>因为集群划分较为分线，因此我们借助 VK 将 kubeflow、airflow、flink、存储等独立集群相连接。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/45/451fea9fdb38df3f1aa038b174e49d37.png\" /></p><p></p><p>&nbsp;</p><p>由于 VK 本身架构设计模式所限，部分问题无法得到解决，其中就包括：</p><p>VK 社区的不稳定性，其中存在许多潜在问题，我们是在使用一年左右才基本达到稳定。VK 无法准确测量资源情况。调度至 VK 的服务可能存在不同套餐，这些套餐都会影响对资源的计算，套餐的随意变化则会影响服务对底层实际集群的调度，导致 pending 情况出现。为此，我们通过提高 VK 的预留从而避免这类情况发生。PVC 无法进行跨集群迁移。这种问题主要针对 pod 共享的 PVC 上有相关业务数据的场景。但如果只是动态 PVC，那么为减少对机器 I/O 的限制，先前提到的 Webhook 注入也可以用于管理这类 PVC。</p><p>&nbsp;</p><p>我们后期的主要目标，是将小集群集中放置到统一集群中，以基于 kube-scheduler 的方式进行统一调度，希望能减少先前在 volcano 中遇到的诸多问题。</p><p>主要改造方向基本可以分为三点：&nbsp;</p><p>在离线统一调度。增强批调度能力，加强离线服务目前所匮乏的资源管控能力。推动混部业务大规模上量。让混部业务不再受限于集群和机器规模、特殊有状态服务等情况，实现大规模上量。训练任务的弹性伸缩。TFjob 对失败容忍度很低，单独 worker 失败即会造成整体训练精度降低，三个 worker 训练失败则会导致任务失败。我们需要通过夜间弹性方式，将在线业务的夜间时段空闲资源供给离线业务使用，同时也要增强 TFjob 对 worker 调度失败的容忍。</p><p></p><p></p><h2>作者简介</h2><p></p><p>孙晓飞，小红书基础技术部后端开发，毕业于北京邮电大学，曾在美团、快手负责 Kubernetes 系统和多集群调度相关工作，目前就职于小红书容器架构组，负责团队内调度系统整体工作。拥有 6 年云原生相关开发设计经验，是 Kubernetes 和 Volcano member。</p><p></p><p>相关阅读：</p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MzI5ODQ2MzI3NQ==&amp;mid=2247508255&amp;idx=1&amp;sn=6eee57733ace605a4ebf0c28408c2323&amp;chksm=eca7985bdbd0114dc9fce8c7a6d466986db4acc23dd05762eb9da9449562a8b3eea084304b9d&amp;scene=27#wechat_redirect\">小红书微服务框架及治理等云原生业务架构演进案例</a>\"</p><p><a href=\"https://xie.infoq.cn/article/b31cbe87ad98618d0a827b4cb\">小红书自研 KV 存储架构如何实现万亿量级存储与跨云多活</a>\"</p>",
    "publish_time": "2023-05-02 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Java近期新闻：JEP for JDK 21、MicroStream成为Eclipse项目、Helidon、Piranha、Gradle 8.1",
    "url": "https://www.infoq.cn/article/OoCiOPX0mArJd8ozFbWW",
    "summary": "<p></p><h4>OpenJDK</h4><p></p><p></p><p>在评审结束后，针对JDK21的JEP 444（<a href=\"https://openjdk.org/jeps/444\">虚拟线程</a>\"）已经从Proposed to Target状态<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-April/007599.html\">提升</a>\"到Targeted状态。本JEP建议根据前两轮预览的反馈最终确定该特性：JEP 436，<a href=\"https://openjdk.org/jeps/436\">虚拟线程第二次预览</a>\"，在JDK 20中发布；JEP 425，<a href=\"https://openjdk.org/jeps/425\">虚拟线程预览</a>\"，在JDK 19中发布。该特性为Java平台提供了虚拟线程。这种轻量级线程可以显著减少编写、维护和观察高吞吐量并发应用程序的工作量。JEP 436最重要的变化是，虚拟线程现在完全支持<a href=\"https://openjdk.org/jeps/8303683#Thread-local-variables\">线程本地变量</a>\"，并取消了不使用这些变量的选项。要了解关于JEP 425的更多细节，可以阅读<a href=\"https://www.infoq.com/news/2022/05/virtual-threads-for-jdk19/\">InfoQ的这篇报道</a>\"，以及观看Oracle Java平台组Java开发大使<a href=\"https://www.linkedin.com/in/jos%C3%A9-paumard-2458ba5/\">José Paumard</a>\"提供的<a href=\"https://inside.java/2022/06/08/jepcafe11/\">截屏视频</a>\"。</p><p>&nbsp;</p><p>类似地，针对JDK 21的JEP 430（<a href=\"https://openjdk.org/jeps/430\">字符串模板预览</a>\"）已经从Proposed to Target状态<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-April/007628.html\">提升</a>\"到Targeted状态。在<a href=\"https://openjdk.java.net/projects/amber/\">Amber项目</a>\"的支持下，这个<a href=\"https://openjdk.org/jeps/12\">JEP预览</a>\"提议用字符串模板来增强Java编程语言。字符串字面量包含嵌入表达式，在运行时进行解释，即在运行时对嵌入表达式进行求值和验证。</p><p>&nbsp;</p><p>针对JDK 21的JEP 442（<a href=\"https://openjdk.org/jeps/442\">外部函数和内存API第三次预览</a>\"）已经从Candidate状态提升到Proposed to Target状态。该JEP包含基于前期反馈的改进，提供了第三次预览：JEP 434，<a href=\"https://openjdk.org/jeps/434\">外部函数和内存API第二次预览</a>\"，在JDK 20中发布；JEP 424，<a href=\"https://openjdk.org/jeps/424\">外部函数和内存API预览</a>\"，在JDK 19中发布，以及相关的正在孵化中的JEP 419，<a href=\"https://openjdk.org/jeps/419\">外部函数和内存API第二轮孵化</a>\"，在JDK 18中发布；JEP 412，<a href=\"https://openjdk.org/jeps/412\">外部函数和内存API第一轮孵化</a>\"，在JDK 17中发布。该特性为Java应用程序提供了一个API，通过它可以有效地调用外部函数，安全地访问不受JVM管理的外部内存，从而与Java运行时之外的代码和数据进行互操作。JEP 434的更新包括：在Arena 接口中集中管理本地段的生命周期；增强布局路径，使用一个新元素来解引用地址布局；移除VaList类。评审预计将于2023年4月21日结束。</p><p>&nbsp;</p><p>JEP 445（<a href=\"https://openjdk.org/jeps/445\">灵活主方法和匿名主类预览</a>\"）已经从JEP Draft 8302326状态<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-April/007600.html\">提升</a>\"到Candidate状态。该JEP原名为隐式类和增强主方法（预览版）。它提议“改进Java语言，让学生可以不必理解这门为大型程序而设计的语言的特性，就可以编写他们的第一个程序。”该JEP延续了Oracle Java语言架构师<a href=\"https://www.linkedin.com/in/briangoetz/\">Brian Goetz</a>\"在2022年9月发表的博文“降低学习门槛（<a href=\"https://openjdk.org/projects/amber/design-notes/on-ramp\">Paving the on-ramp</a>\"）”。</p><p>&nbsp;</p><p>Oracle Java架构师<a href=\"https://www.linkedin.com/in/paul-sandoz-4704562/\">Paul Sandoz</a>\"<a href=\"https://mail.openjdk.org/pipermail/panama-dev/2023-April/018958.html\">提交</a>\"了JEP Draft 8305868，<a href=\"https://openjdk.org/jeps/8305868\">Vector API第六轮孵化</a>\"。在<a href=\"https://openjdk.org/projects/panama/\">Panama项目</a>\"的支持下，该JEP包含了针对前五轮孵化反馈所做的增强：JEP 438，<a href=\"https://openjdk.org/jeps/438\">Vector API第五轮孵化</a>\"，在JDK 20中发布；JEP 426，<a href=\"https://openjdk.org/jeps/426\">Vector API第四轮孵化</a>\"，在JDK 19中发布；JEP 417，<a href=\"https://openjdk.java.net/jeps/417\">Vector API第三轮孵化</a>\"，在JDK 18中发布；JEP 414，<a href=\"https://openjdk.java.net/jeps/414\">Vector API第二轮孵化</a>\"，在JDK 17中发布；JEP 338，<a href=\"https://openjdk.java.net/jeps/338\">Vector API第一轮孵化</a>\"，在JDK 16中作为<a href=\"https://openjdk.java.net/jeps/11\">孵化器模块</a>\"交付。该JEP建议增强Vector API，以便从JEP 424（<a href=\"https://openjdk.java.net/jeps/424\">外部函数和内存API预览</a>\"）定义的MemorySegment中加载向量及向它存储向量。</p><p>&nbsp;</p><p></p><h4>JDK 21</h4><p></p><p></p><p>JDK 21<a href=\"https://jdk.java.net/21/\">早期访问构建</a>\"<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-21%2B18\">Build 18</a>\"在上周发布，其中包括<a href=\"https://github.com/openjdk/jdk/compare/jdk-21%2B17...jdk-21%2B18\">Build 17的更新</a>\"，主要是修复了各种<a href=\"https://bugs.openjdk.org/issues/?jql=project%20%3D%20JDK%20AND%20fixversion%20%3D%2021%20and%20%22resolved%20in%20build%22%20%3D%20b18%20order%20by%20component%2C%20subcomponent\">问题</a>\"。要了解关于这个版本的更多细节，请查看<a href=\"https://jdk.java.net/21/release-notes\">发布说明</a>\"。</p><p>&nbsp;</p><p>对于<a href=\"https://openjdk.java.net/projects/jdk/21/\">JDK 21</a>\"，我们鼓励开发人员通过<a href=\"https://bugreport.java.com/bugreport/\">Java Bug数据库</a>\"报告Bug。</p><p>&nbsp;</p><p></p><h4>Spring Framework</h4><p></p><p></p><p><a href=\"https://spring.io/projects/spring-framework\">Spring Framework</a>\" 6.0.8、5.3.27和5.2.24.RELEASE版本<a href=\"https://spring.io/blog/2023/04/13/spring-framework-6-0-8-5-3-27-and-5-2-24-release-fix-cve-2023-20863\">发布</a>\"，主要是解决了CVE-2023-20863 <a href=\"https://spring.io/security/cve-2023-20863\">Spring Expression DoS漏洞</a>\"。利用该漏洞，攻击者可以通过提供专门编写的Spring Expression Language表达式发起拒绝服务（DoS）攻击。其他新特性包括：在StringUtils类中定义了一个新的重载方法truncate()，作为一种集中一致的字符串截断方式；在ObjectUtils类中定义了一个新方法nullSafeConciseToString()，为各种对象生成更“简洁”的空安全toString()表示，不包括完整的对象图；将Collections类中定义的unmodiableelist()方法替换为List接口中定义的copyOf()方法，提高Spring应用程序代码的可读性，防止意外Bug，提升可维护性。要了解关于这些版本的更多细节，请查看<a href=\"https://github.com/spring-projects/spring-framework/releases/tag/v6.0.8\">6.0.8</a>\"、<a href=\"https://github.com/spring-projects/spring-framework/releases/tag/v5.3.27\">5.3.27</a>\"和<a href=\"https://github.com/spring-projects/spring-framework/releases/tag/v5.2.24.RELEASE\">5.2.24.RELEASE</a>\"版本的发布说明。</p><p>&nbsp;</p><p><a href=\"https://spring.io/projects/spring-data\">Spring Data</a>\"&nbsp;2023.0-RC1、2022.0.5和2021.2.11在上周<a href=\"https://spring.io/blog/2023/04/14/spring-data-2023-0-rc1-and-service-releases-2022-0-5-and-2021-2-11-released\">发布</a>\"。2023.0-RC1版本的特性包括：恢复MariaDB对<a href=\"https://spring.io/projects/spring-data-r2dbc\">Spring Data R2DBC</a>\"的支持；在<a href=\"https://spring.io/projects/spring-data-mongodb\">Spring Data MongoDB</a>\"中新增了一个@Hint注解，支持响应式批处理操作；许多针对<a href=\"https://spring.io/projects/spring-data-jpa\">Spring Data JPA</a>\" Hibernate和JPQL解析器的增强，对@Query注解查询在别名和其他方面的查询解析提供了更好的支持。2022.0.5和2021.2.11版本是服务版本，带来了改进，修复了回归Bug。这两个版本可能会分别与即将发布的<a href=\"https://spring.io/projects/spring-boot\">Spring Boot</a>\" 3.0.6和2.7.11一起使用。</p><p>&nbsp;</p><p></p><h4>GraalVM Native Build Tools</h4><p></p><p></p><p>在迈向1.0版本的道路上，<a href=\"https://labs.oracle.com/\">Oracle实验室</a>\"发布了<a href=\"https://github.com/graalvm/native-build-tools/blob/master/README.md\">Native Build Tools</a>\"的<a href=\"https://github.com/graalvm/native-build-tools/releases/tag/0.9.21\">0.9.21版本</a>\"。这是一个GraalVM项目，包含与GraalVM原生镜像互操作的插件。这个最新版本有一些值得注意的变化，比如：修复了与Gradle配置缓存的兼容性问题；弃用requiredVersion属性，转而使用版本字符串；新增Maven目标write-args-file，它会生成一个参数文件，供生命周期下游的其他插件使用。要了解关于这个版本的更多细节，请查看<a href=\"https://graalvm.github.io/native-build-tools/latest/index.html#changelog\">变更日志</a>\"。</p><p>&nbsp;</p><p></p><h4>MicroStream</h4><p></p><p></p><p>MicroStream<a href=\"https://microstream.one/blog/article/microstream-becomes-an-eclipse-project/\">宣布</a>\"，他们的Java原生持久化层将成为一个Eclipse项目。<a href=\"https://microstream.one/products/serializer/\">MicroStream Serializer</a>\"产品将重命名为Eclipse Serializer，<a href=\"https://microstream.one/products/microstream-for-java/\">MicroStream Persistence</a>\"产品将重命名为EclipseStore。MicroStream还计划启动一个EclipseStore工作组，制定Jakarta Persistence规范标准。其中，EclipseStore将成为一个兼容实现。</p><p>&nbsp;</p><p></p><h4>Micronaut</h4><p></p><p></p><p>Micronaut基金会<a href=\"https://micronaut.io/2023/04/13/micronaut-framework-3-8-9-released/\">发布</a>\"了Micronaut Framework 3.8.9，修复了Bug，支持JDK 20的注解处理器，并升级了模块<a href=\"https://micronaut-projects.github.io/micronaut-aws/snapshot/guide/\">Micronaut AWS</a>\"和<a href=\"https://micronaut-projects.github.io/micronaut-kafka/snapshot/guide/\">Micronaut Kafka</a>\"。还有一个依赖项升级到<a href=\"https://netty.io/news/2023/04/03/4-1-91-Final.html\">Netty 4.1.91</a>\"。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/micronaut-projects/micronaut-core/releases/tag/v3.8.9\">发布说明</a>\"。</p><p>&nbsp;</p><p>Micronaut 4.0.0的<a href=\"https://github.com/micronaut-projects/micronaut-core/releases/tag/v4.0.0-M2\">第四个里程碑版本</a>\"也于上周发布，它支持：基于注解的CORS配置；注解编译时间表达式；禁用流式HTTP请求处理的能力；条件路由。</p><p>&nbsp;</p><p></p><h4>Helidon</h4><p></p><p></p><p>Helidon 4.0.0的<a href=\"https://twitter.com/helidon_project/status/1646809142030417920?cxt=HHwWgIC2uZCM0totAAAA\">第六个Alpha版本</a>\"带来了一些显著的变化，比如：支持JDK 20；完成WebServer和WebClient组件中所有HTTP方法的快捷方法；将receive()方法重命名为onMessage()，以便与WebSocket组件中的其他方法保持一致。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/helidon-io/helidon/releases/tag/4.0.0-ALPHA6\">发布说明</a>\"。</p><p>&nbsp;</p><p></p><h4>Hibernate</h4><p></p><p></p><p>HibernateORM 6.2.1.Final<a href=\"https://in.relation.to/2023/04/14/hibernate-orm-621-final/\">发布</a>\"，提供了一些值得注意的修复，比如：改进了使用别名和左连接的子查询；启用脏检查和字节码增强时忽略泛型关联的问题；复合主键@IdClass的一部分查询时不返回；内部nullness标记和检查。</p><p>&nbsp;</p><p></p><h4>Micrometer</h4><p></p><p></p><p>Micrometer Metrics <a href=\"https://github.com/micrometer-metrics/micrometer/releases/tag/v1.11.0-RC1\">1.11.0-RC1</a>\"、<a href=\"https://github.com/micrometer-metrics/micrometer/releases/tag/v1.10.6\">1.10.6</a>\"和<a href=\"https://github.com/micrometer-metrics/micrometer/releases/tag/v1.9.10\">1.9.10</a>\"版本发布。1.11.0-RC1版本的新特性包括：为Observation接口内部类Context的方法getOrDefault()增加一个新的Supplier 变量；Netty分配器和事件执行器指标支持；提升AbstractTimeWindowHistogram类中定义的takeCountSnapshot()方法累积计数的计算效率。1.10.6和1.9.10版本主要是提供Bug修复和依赖项升级。</p><p>&nbsp;</p><p>同样，Micrometer Tracing的<a href=\"https://github.com/micrometer-metrics/tracing/releases/tag/v1.1.0-RC1\">1.1.0-RC1</a>\"和<a href=\"https://github.com/micrometer-metrics/tracing/releases/tag/v1.0.4\">1.0.4</a>\"版本也是提供了Bug修复，并分别将依赖项升级到Micrometer 1.11.0-RC1和1.10.6。它们还带来了一些新特性：允许通过ThreadLocalAccessor接口传播span；与Micrometer中的注解变化保持一致；支持创建带有链接的span。</p><p>&nbsp;</p><p></p><h4>Piranha</h4><p></p><p></p><p>Piranha 23.4.0<a href=\"https://github.com/piranhacloud/piranha/releases/tag/v23.4.0\">发布</a>\"。这个新版本被称为2023年4月的“升级组件”版本，包括：将Jakarta EE组件的各种兼容实现更新到最新版本；更新在发布工作流中运行的自动化测试，以便使用JDK 19；基本代码清理。要了解关于这个版本的更多细节，请查看<a href=\"https://javadoc.io/doc/cloud.piranha/project/latest/index.html\">官方文档</a>\"和<a href=\"https://github.com/piranhacloud/piranha/issues?q=is%3Aissue+-label%3Awontfix+milestone%3A23.4.0+is%3Aclosed\">问题跟踪系统</a>\"。</p><p>&nbsp;</p><p></p><h4>Reactor</h4><p></p><p></p><p><a href=\"https://github.com/reactor/reactor/blob/main/README.md\">Reactor</a>\" 2022.0.6是<a href=\"https://github.com/reactor/reactor/releases/tag/2022.0.6\">第六个维护版本</a>\"，依赖项升级到reactor-core 3.5.5、reactor-addons3.5.1、reactor-netty 1.1.6、reactor-kafka 1.3.17和reactor-kotlin-extensions 1.2.2。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/reactor/reactor/compare/2022.0.5...2022.0.6\">变更日志</a>\"。</p><p>&nbsp;</p><p></p><h4>Gradle</h4><p></p><p></p><p>Gradle 8.1<a href=\"https://github.com/gradle/gradle/releases/tag/v8.1.0\">发布</a>\"，新特性包括：稳定版本的<a href=\"https://docs.gradle.org/8.1-rc-2/userguide/configuration_cache.html\">配置缓存</a>\"；支持<a href=\"https://docs.gradle.org/8.1-rc-2/userguide/dependency_verification.html\">依赖验证</a>\"；改进Groovy闭包错误报告；支持Java lambdas；改进内存管理；支持使用JDK 20构建项目。要了解关于这个版本的更多细节，请查看<a href=\"https://docs.gradle.org/8.1/release-notes.html\">发布说明</a>\"。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/04/java-news-roundup-apr10-2023/\">https://www.infoq.com/news/2023/04/java-news-roundup-apr10-2023/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/gB3ToN16f0iPC3tvdpDZ\">Java 近期新闻：字符串模板、Quarkus、Open Liberty、PrimeFaces、JobRunr、Devnexus 2023</a>\"</p>",
    "publish_time": "2023-05-02 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "PyTorch 2.0编译器提高了模型训练速度",
    "url": "https://www.infoq.cn/article/l9UJDcD4E1DbGuvOs15T",
    "summary": "<p><a href=\"https://pytorch.org/\">PyTorch基金会</a>\"最近发布了<a href=\"https://pytorch.org/blog/pytorch-2.0-release/\">PyTorch 2.0版本</a>\"，这是一个100%向后兼容的更新。该版本的主要API贡献是为深度学习模型提供了一个编译函数，可以加快训练速度。163个开源人工智能项目的内部基准测试显示，在训练期间，这些模型平均运行速度提高了43%。</p><p>&nbsp;</p><p>PyTorch 2.0的发布计划于2022年12月在<a href=\"https://www.youtube.com/watch?v=vbtGZL7IrAw\">PyTorch大会</a>\"上宣布。除了新的编译特性外，该版本还包括通过<a href=\"https://pytorch.org/blog/accelerated-diffusers-pt-20/\">缩放点积注意力（SDPA）</a>\"的新实现来提高Transformer-based模型（如大语言模型和扩散模型）的性能。通过改进的<a href=\"https://pytorch.org/docs/stable/notes/mps.html\">Metal Performance Shaders（MPS）</a>\"加快了在Apple Silicon上的训练，目前在MPS中实施了300项操作。除了核心版本外，包括TorchAudio、TorchVision和TorchText在内的<a href=\"https://pytorch.org/blog/new-library-updates-in-pytorch-2.0/\">域库</a>\"也更新了新的测试版功能。总体而言，自1.13.1版本发布以来，2.0版本包含了来自428名开发人员的4500多次提交。PyTorch基金会的博客上写到：</p><p>&nbsp;</p><p></p><blockquote>能宣布PyTorch®2.0的发布，我们很激动，我们在2022年12月2日的PyTorch大会上强调了这一点！PyTorch 2.0提供了相同的动态图模式（eager-mode）开发和用户体验，同时从根本上改变并加强了PyTorch在编译器级别的操作方式，提供了更快的性能和对动态形状和分布式的支持。</blockquote><p></p><p>&nbsp;</p><p>在2022年PyTorch大会的主题演讲中，PyTorch联合创始人<a href=\"https://soumith.ch/about/\">Soumith Chintala</a>\"指出，由于GPU计算能力的增加，许多现有的PyTorch工作负载受到了内存带宽或PyTorch框架开销的限制。此前，PyTorch团队通过用C++编写一些核心组件来解决性能问题；Chintala将PyTorch描述为“基本上是一个C++代码库”，并表示他“讨厌”为C++组件做出贡献。</p><p>&nbsp;</p><p>新的编译特性基于四个用Python编写的底层组件：</p><p>&nbsp;</p><p>TorchDynamo——通过将表示深度学习模型的Python代码重写为计算图块来执行图的获取AOTAutograd ——为后退步骤执行“提前”自动微分PrimTorch——将超过2k个PyTorch操作符规范化为固定的约250个原始操作符TorchInductor——为加速器生成特定于硬件的快速后端代码</p><p>&nbsp;</p><p>为了演示编译函数的性能改进和易用性，PyTorch团队确定了163个开源深度学习项目进行基准测试。其中包括各种任务的实现，包括计算机视觉、自然语言处理和强化学习。除了对编译函数的单行调用外，该团队没有对代码进行任何更改。这一单一改动在93%的项目中有效，在<a href=\"https://www.nvidia.com/en-us/data-center/a100/\">NVIDIA A100</a>\" GPU上训练时，编译后的模型的运行速度提高了43%。</p><p>&nbsp;</p><p>在黑客新闻（Hacker News）关于此次发布的讨论中，<a href=\"https://news.ycombinator.com/item?id=33832511\">一位用户指出</a>\"：</p><p>&nbsp;</p><p></p><blockquote>通过与其他框架相比，我从PyTorch中学到的一条重要教训是，生产力胜过增量的性能改进。Caffe和MXNet都以速度快为卖点的，但显然在此处或这里的速度都快了一些，但这并不重要。另一方面，一旦我们让一个系统运行并流行起来，社区将会以比竞争对手预期更快地缩小性能差距。另一个教训可能是老生常谈的但同样值得重复：对开源项目的投资和专业打磨很重要。</blockquote><p></p><p>&nbsp;</p><p><a href=\"https://github.com/pytorch/pytorch\">PyTorch的代码</a>\"和<a href=\"https://github.com/pytorch/pytorch/releases/tag/v2.0.0\">2.0版本的发布说明</a>\"可在GitHub上获得。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/03/pytorch-release-compile/\">https://www.infoq.com/news/2023/03/pytorch-release-compile/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/OYS7T01SgBBZvCqNT04E\">里程碑！PyTorch 正式加入 Linux 基金会，社区治理这一核心将不会改变</a>\"</p><p><a href=\"https://www.infoq.cn/article/7Azz9NMpjuI4zmV4S4oC\">深度学习为什么要选择&nbsp;PyTorch</a>\"</p>",
    "publish_time": "2023-05-02 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "平台工程的失败模式及如何避免，来自一线的宝贵经验",
    "url": "https://www.infoq.cn/article/oAygLlEZHJGmJf7l6vIr",
    "summary": "<p>平台工程给整个企业带来的价值是不容置疑的。Gartner不仅将平台工程列为<a href=\"https://www.gartner.com/en/articles/gartner-top-10-strategic-technology-trends-for-2023\">2023年十大技术趋势之一</a>\"，还将其纳入其<a href=\"https://humanitec.com/blog/gartner-internal-developer-platforms-platform-engineering\">技术成熟度曲线</a>\"，这为公司如何通过构建内部开发者平台(IDP)来改善开发者体验提供了强有力的指引。</p><p>&nbsp;</p><p>更重要的是，平台工程社区正在迅速发展。从这也可以看出，这不仅仅是某个公司做出的决定。使用内部开发人员平台的开发人员获得了无可争议的优势，比如开发人员生产力的提升、更好的产品成果、更好的开发体验和更低的成本。</p><p>&nbsp;</p><p>现在，人人都在云上开展工作，员工们也十分期望使用这样的工具平台，<a href=\"https://internaldeveloperplatform.org/what-is-an-internal-developer-platform/\">IDP</a>\"已经成为一种保持竞争力的必需品，这极大地提高了开发者的生活质量。</p><p>&nbsp;</p><p>不过，这也意味着人们的期望值变的极高。除非发明一款新的Heroku(当然没有它的任何限制)，否则任何其它事情都可能被视为失败。</p><p>&nbsp;</p><p>我认为至关重要的是，要加倍努力提高开发人员的生产力。但在开始之前，应该了解什么是不该做的：了解陷阱的所在，可以更容易地避开它们。我目睹了无数努力付之东流，也见证了平台工程的发展，以下是我在为Salesforce和其他公司创建IDP过程中得到的一些收获。</p><p>&nbsp;</p><p></p><h1>失败的平台工程模式</h1><p></p><p></p><p>导致平台工程项目失败的情况有很多种，有一些会使项目还没成熟就陷入瘫痪。在创建IDP时，请注意下面这些错误的模式：</p><p>&nbsp;</p><p></p><h2>先把平台建好，他们一定会用的</h2><p></p><p></p><p>这是一个很大的逻辑错误。你知道你在做什么吗？人们会因为你建了平台就一定使用它？你这是在给自己挖坑。</p><p>&nbsp;</p><p>当然，新平台可能比问题百出的旧系统更好，但这并不意味着新系统是完美的，比如它可能浪费更多时间或者根本没法满足开发人员的某些需求。</p><p>&nbsp;</p><p>在这种情况下，结果只会助长不满情绪。用户会抱怨你给他们带来的新问题，而不是抱怨旧问题。这不是一个好的预期效果。</p><p>&nbsp;</p><p>更糟糕的是，这会造成一个“恶意遵从”的环境。人们会使用平台，因为他们被告知要这么做。但每当平台产出不了他们预期的结果时，他们便会责怪平台以及平台团队。平台成了很好的甩锅对象 。</p><p>&nbsp;</p><p>这不仅会损害你的职业发展，还会让团队以后不愿接受新要求，也会给企业文化带来负面影响。</p><p>&nbsp;</p><p>不过也不用过分担心，这有一个简单的解决方案：做一个好的、专业的产品经理，与客户拉近距离。不过，最好你在开始做这件事情之前就这样做。</p><p>&nbsp;</p><p>在产品需求上，我们把精力放在我们认为的，而不是询问用户真正需要的功能上，将使我们陷入无法挽回的困境中。换句话说，提前了解各类典型用户的需求将使我们摆脱窘境。</p><p>&nbsp;</p><p>记住，改善开发人员的体验是一个至关重要的目标。定期征求反馈意见，以便了解真实需求变化及改进建议。我们通过采用以用户为中心的产品管理方法，解决重要问题，进而提高产品使用率。</p><p>&nbsp;</p><p></p><h2>这是唯一正确的路径</h2><p></p><p></p><p>构建IDP意味着为开发者构建黄金路径。但问题在于，一些潜在的黄金之路并不太经得起推敲。开发软件不存在“唯一正确的路径”， 如果你的IDP迫使人们接受不可行的做法，它就不会成功。</p><p>&nbsp;</p><p>在某种程度上，对于“过度自信”的工具，开发人员都会拿一些你没有预料到的情况进行证伪——作为优秀的开发者，他们会非常认真的寻找解决方案，然后告诉你：“看吧，这个工具支撑不了我的工作。”</p><p>&nbsp;</p><p>你的黄金路径需要考虑到人们偏离正轨的倾向——并有足够的适应性来匹配。例如，在不使用像Kafka这样的队列技术或像Hadoop这样开箱即用的分布式计算框架的情况下，IDP仍然可以支撑。IDP的架构应该允许多种集成方式，这样也方便以后进行扩展。平台的架构必须考虑到，开发人员会想自助加入你甚至没有听说过的未来技术。</p><p>&nbsp;</p><p></p><h2>讨人喜欢的平台</h2><p></p><p></p><p>虽然“唯一正确路径”反模式会导致一定的失败，但反过来做，也可能导致失败——构建一个“讨人喜欢”的平台。毕竟，你永远不可能让每个人都满意，尝试这么做可能会让事情变得更糟。</p><p>&nbsp;</p><p>并非每个功能需求都具有相同的权重。比如，你的一个团队想要使用一些尖端的实验技术。集成上述工具可能会让他们满意，但也可能导致平台的不稳定——这不是一个理想的平台特性。</p><p>&nbsp;</p><p>在一些其他情况下，你过度吹嘘自己的能力，结果只能不可避免地让人失望。例如，你可能有许多使用不同技术栈的团队。如果你说“放心吧，你们所有的需求我都能够满足，不会有问题的。”这样你便把自己拖进了无限的痛苦折磨中。</p><p>&nbsp;</p><p>记住，你的能力是有限的。更重要的是，要明白，你的团队精力越分散，产出的工作质量就会越受到影响。即使你有大量的资金和资源，你也无法支持所有可能的技术组合，更不用说做得让所有人都满意了！</p><p>&nbsp;</p><p>与其试图取悦整个组织，不如从MVP开始，与愿意接受早期不成熟产品并持续提供反馈的灯塔团队紧密合作。通过帮助你指导改进和提高生产效率，你的灯塔项目能够在需求出现时及时完成开发。当然，你仍然需要在迭代过程中合理地划分优先级，在没有大量需求积压的情况下，这是很容易做到的。一旦产品稳定性达到一定程度，你便可以考虑向更多团队推广，最终推广到整个组织。</p><p>&nbsp;</p><p></p><h2>搭积木式的架构方式</h2><p></p><p></p><p>你希望通过创建一个平台，帮助公司达到新的高度，但一定不能通过搭积木的方式，让平台充满不稳定技术。当你试图能为给公司带来蓬勃发展的产品和服务打下基础时，这样创建平台的方式是非常糟糕的。</p><p>&nbsp;</p><p>为什么会有这样的事情发生？毕竟，没有哪个平台团队想制造混乱。但我确实已经无数次见到过这种情况了。</p><p>&nbsp;</p><p>问题关键点往往在于，团队是如何构建平台的。许多团队试图将一系列尚处于生命周期早期的不成熟技术焊接在一起。即便你能跟上其中部分组件的迭代更新速度，但众多这样的组件聚合在一起的维护成本将呈指数级增长，最终让你无能为力。</p><p>&nbsp;</p><p>尽早调整自己的策略，避免出现“搭积木”式的反模式。不要去做华而不实的事情，要勇于处理那些艰难的、基础的架构问题——从基本要素开始，才能提高你成功的几率。</p><p>&nbsp;</p><p>我们在建造房子时，需要按照特定的顺序做事。首先，你要浇筑地基，然后建造框架和墙，最后添加门、窗和装饰。我在以前写的文章中也提到过，我们在考虑构建漂亮的UI或服务之前，首先要设计IDP的架构。</p><p>&nbsp;</p><p>当然，我承认，这种策略可能不是最能打动人的，但按正确的顺序打好基础，未来会获得巨大回报。除了提高IDP的稳定性之外，构建一个坚实的基础还可以进一步满足其它任务需求，比如集成那些酷炫的技术。</p><p>&nbsp;</p><p></p><h2>“瑞士奶酪”平台</h2><p></p><p></p><p>瑞士奶酪有很多优点。例如，它非常符合空气动力学，重量轻，而且非常美味。然而，就像积木架构一样，我们也要避免IDP中的“瑞士奶酪”问题。（译者注：瑞士奶酪理论提到，如果把很多片奶酪重叠放置在一起，在自然光线下，因为每片奶酪的孔洞位置不一，光线无法透过奶酪；而在极端情况下，孔洞刚好连成一条线，光便会透过去。此处作者想表达的是，平台每个层面都可能有漏洞，不安全因素就是光源，可能穿透平台。）</p><p>&nbsp;</p><p>主要的原因在于，你并不总能找到漏洞的位置，有些漏洞比其他漏洞更致命。虽然你可能能够解决可用性等方面的缺陷，但安全性是完全不同的情况。</p><p>&nbsp;</p><p>记住，只需要一个漏洞就能造成严重破坏。如果你的平台漏洞百出，就会大大增加泄露数据、暴露敏感客户信息的可能性，并将你的公司从行业领导者的位置拉下。</p><p>&nbsp;</p><p>打造人人都满意的平台是一项崇高的追求。然而，如果你以牺牲安全为代价，那么一旦事情搞砸了，你最大的粉丝就会变成你最恶毒的诋毁者。</p><p>&nbsp;</p><p>这里的解决方案很简单：从项目的第一天起，甚至在你开始第一天的编码之前，就把安全性作为优先事项考虑。</p><p>&nbsp;</p><p>“瑞士奶酪”在系统工程中唯一有效的作用是，当你谈论<a href=\"https://www.engineeringforhumans.com/systems-engineering/the-swiss-cheese-model-designing-to-reduce-catastrophic-losses/\">风险分析和事故原因</a>\"时，你需要在所有阶段都把安全放在首位。</p><p>&nbsp;</p><p></p><h2>致命的成本旋涡</h2><p></p><p></p><p>这是一个大问题。许多团队创建的平台缺乏内在的成本控制机制，比如AWS配置配额。这种“全速前进，不用关心预算”的观念是行不通的。</p><p>&nbsp;</p><p>这种反模式的缺点应该是显而易见的，但是很容易忽略它们的范围。每个平台工程师都知道超出他们的项目预算是不好的。但很少有人意识到成本超支可能对公司单位经济指标产生更广泛的影响。许多计算密集型公司在云计算上的花费比他们在办公室和工资上的花费加起来还要多。对于一家科技公司来说，糟糕的单位经济状况实际上会决定其是否能达到盈利预期。</p><p>&nbsp;</p><p>不幸的是，这种思想上的忽视似乎是根深蒂固的。我曾在一些公司工作，在没有CFO批准的情况下，你不能为开发团队订购披萨，但任何一个员工都可以调用一个每天会启动数十万个实例的API节点!</p><p>&nbsp;</p><p>让组织中的每个人都参与到有成本意识的DevOps中可能是一件不大可能的事。然而，作为一名平台架构师，你需要引导这项工作。</p><p>&nbsp;</p><p>咨询你的FinOps联络人，让你的DevOps工作与公司的财务架构紧密结合。如果你不能控制底线，你的平台就注定要失败——不管你在早期获得了多少投资!</p><p>&nbsp;</p><p></p><h1>智能平台工程的关键要点</h1><p></p><p></p><p>那么，成功的平台工程行为与失败的行为区别有哪些呢？回顾一下，你需要：</p><p>从产品经理的角度审视平台。推销你的平台，但不要过度吹嘘。将你的平台视为产品，并确定你的主要客户和利益相关方。接受你不能重新创造Heroku或AWS的事实，除非你有数亿美元可以花。了解并迭代MVP，它将帮助您赢得下一轮投资。</p><p>&nbsp;</p><p>当然，到目前为止列出的失败模式只是常见的一些情况。其他还有一些也会导致失败，如设计IDP时为了满足团队中声音最大的那部分需求而牺牲了一些边缘需求，以及仅仅为了抽象而牺牲了对底层技术的关键支撑，等等。然而，无论这些风险中哪一种被证明与你的情况最相关，在早期计划阶段获得对风险更广泛的认识都是朝着正确方向迈出的一步。</p><p>&nbsp;</p><p>知道要避免什么，但也要知道要专注于什么。专注于那些让你的平台工程团队更有效率的事情。这样做将使成功和构建能够带来持久价值的东西变得更加容易。</p><p>&nbsp;</p><p>&nbsp;</p><p>作者介绍：</p><p>Aaron Erickson 是Orgspace的联合创始人兼首席执行官。在Orgspace之前，他在领导岗位上工作了30年，最近一次是在New Relic担任工程副总裁。在整个职业生涯中，他一直倡导构建更好的软件。他在ThoughtWorks工作了十年，在那里他通过快速和持续地交付应用推动了数字化转型。Aaron现在旧金山生活和工作。</p><p>&nbsp;</p><p>原文链接：</p><p> <a href=\"https://www.infoq.com/articles/platform-engineering-lessons-learned/\">https://www.infoq.com/articles/platform-engineering-lessons-learned/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/TbxS2My9fOIL1GMpHjKD\">平台工程应知应会</a>\"</p><p><a href=\"https://www.infoq.cn/article/5JuuFYFFNH0WT2aDJgA3\">平台工程的 2023：助力云原生重构研发组织文化与组织架构</a>\"</p><p><a href=\"https://www.infoq.cn/article/q6JwiNRJIZ8C0h1WCHVQ\">Puppet 2023 DevOps 现状报告：平台工程有助于提升开发效率</a>\"</p>",
    "publish_time": "2023-05-02 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "2023年，Rust能干掉JavaScript吗？",
    "url": "https://www.infoq.cn/article/5WfwOlQ5WDIDtEEW61zl",
    "summary": "<p>如果大家已经拥有一定的Rust Web开发经验，应该听说过在前端Web开发上用Rust（通过WASM）还是用JavaScript这个充满争议性的话题。不少人旗帜鲜明表示反对，认为Rust“不适合生产”，而且速率“比JavaScript还慢”。</p><p></p><p>这种说法也有道理：从历史上看，因为WASM无法访问DOM，所以从JavaScript调用WASM确实会产生额外开销。但目前这方面的影响已经很小，基准数据显示，像Leptos和Dioxus这样的Rust WASM框架（底层使用Sledgehammer，属于速度前三甲级别的JavaScript框架）在性能上已经优于React和Vue等大部分JS框架。感兴趣的朋友可以参考<a href=\"https://krausest.github.io/js-framework-benchmark/current.html\">原始基准测试</a>\"。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/04/045ef212fc5d32bfd8ead22b35eeb2ae.png\" /></p><p></p><p>如图片所见，各框架按性能排序分别为原始Javascript、Sledgehammer（Dioxus的底层引擎）、wasm-bindgen（允许 WASM 模块和&nbsp;Javascript&nbsp;实现互操作的库）、Solid.js ，Vue&nbsp;和&nbsp;RxJS，之后是&nbsp;Leptos、Dioxus、LitJS，接下来是 Sycamore……排在最末的才是Vue和React（还有Yew）。很明显，其中一些Rust前端框架甚至比最流行的JavaScript框架性能还好。千万别抬杠说也可以不用框架，直接编写纯JavaScript代码——确实可以，但这明显偏离本文讨论的主题了。</p><p></p><p>TechEmpower发布的后端性能基准测试：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ca/cad93405dae057c00d867a45e6c27a44.png\" /></p><p></p><p>在前10大后端框架中，有5个是用Rust编写的。很明显，Rust在后端框架领域占据着突出的优势，甚至能与<a href=\"https://www.infoq.cn/article/Y9KJX5zaEXov90wK68JP\">C++</a>\"正面较量。有人可能会说Rust用作后端服务有点太过了——但它确实能带来更高性能，占用的内存更小、服务的运行稳定性更好、引发崩溃的可能性也更低。这些都是不容低估的重要因素，毕竟从企业的角度来看，尽可能节约成本永远都是高优先级事项。</p><p></p><p>但也必须承认，在选择新框架时，速度和常规性能往往并不足以构成综合决策的充分因素。开发者体验如何、错误处理功能是否强大、怎样解决SSR问题等也都非常重要。要想做出明智的最终选择，必须先为这些问题找到合理答案。幸运的是，Rust同样是有备而来。</p><p></p><h2>开发者体验</h2><p></p><p>不管大家主观判断如何，在Web开发方面，Rust有着相对宽松的使用要求。其中很多代码的样式上跟React等Web框架中的<a href=\"https://www.infoq.cn/article/CBb3RhvCHflT42ppOLkR\">JavaScript</a>\"组件非常相似——比如Leptos（一款Rust Web框架）中的组件代码：</p><p></p><p><code lang=\"plain\">use leptos::*;\n \n#[component]\npub fn SimpleCounter(cx: Scope, initial_value: i32) -&gt; impl IntoView {\n    // create a reactive signal with the initial value\n    let (value, set_value) = create_signal(cx, initial_value);\n \n    // create event handlers for our buttons\n    // note that `value` and `set_value` are `Copy`, so it's super easy to move them into closures\n// (for reference: closures are like anonymous/arrow functions in Javascript)\n    let clear = move |_| set_value(0);\n    let decrement = move |_| set_value.update(|value| *value -= 1);\n    let increment = move |_| set_value.update(|value| *value += 1);\n \n    // create user interfaces with the declarative `view!` macro\n    view! {\n        cx,\n        </code></p><div><code lang=\"plain\">\n            <button>\"Clear\"</button>\n            <button>\"-1\"</button>\n            <span>\"Value: \" {value} \"!\"</span>\n            <button>\"+1\"</button>\n        </code></div><code lang=\"plain\">\n    }\n}\n \n// Easy to use with Trunk (trunkrs.dev) or with a simple wasm-bindgen setup\npub fn main() {\n    mount_to_body(|cx| view! { cx,   })\n}\n</code><p></p><p></p><p>可以看到，这些代码其实跟JSX区别不大，最大的不同就是该组件不返回任何内容，而是用Rust宏来渲染HTML。其main函数类似于React、Vue乃至其他JS框架当中作用于root文件的index.js脚本。再来看另一个来自Dioxus的例子：</p><p></p><p><code lang=\"plain\">// An example of a navbar\nfn navbar(cx: Scope) -&gt; Element {\n    cx.render(rsx! {\n        ul {\n            // NEW\n            Link { to: \"/\", \"Home\"}\n            br {}\n            Link { to: \"/blog\", \"Blog\"}\n        }\n    })\n}\n \n// An example of using URL parameters\nfn get_blog_post(id: &amp;str) -&gt; String {\n    match id {\n        \"foo\" =&gt; \"Welcome to the foo blog post!\".to_string(),\n        \"bar\" =&gt; \"This is the bar blog post!\".to_string(),\n        id =&gt; format!(\"Blog post '{id}' does not exist!\")\n    }\n</code></p><p></p><p>可以看到，RSX（相当于Dioxus中的React JSX）的编写非常简单，甚至可能比使用Leptos还简单一些。而且很明显，React的组件设计理念已经超越了特定编程语言，在Rust这边也已经有所体现。大家甚至可以把这些函数跟单元结构体（unit structs）结合起来，为各种函数提供命名空间，这样就能实现对API调用之类的捆绑了，例如：</p><p></p><p><code lang=\"plain\">// this is a unit struct\npub struct APICalls;\n \n// we can implement the unit struct to bundle functions under it\n// like so:\nImpl APICalls {\n         pub async fn get_dog_api_data() -&gt; Json {\n... some code here\n// this should probably return some json data\n}\n         pub async fn get_cat_api_data() -&gt; Json {\n... some code here\n// this should probably return some json data\n}\n}\n \nfn navbar (cx: Scope) -&gt; Element {\n// now we can call the data like this, or something similar\n    let dogs = APICalls::get_dog_api_data().await;\n}\n</code></p><p></p><p>如大家所见，哪怕只是稍稍触及Rust的浅表层次，也已经能够获得相当不错的开发效果。而且真正让人眼前一亮的，还要数Rust的错误处理机制，这也是其优于JavaScript甚至是TypeScript的关键亮点之一。通常，如果使用TypeScript进行编码，我们只有两个选择：类型检查和try-catch块。但对于拥有一定开发经验的朋友们来说，不断把代友打包到try-catch块中仍然有其隐患。毕竟TypeScript仍可被编译为JavaScript，所以一旦不小心就会引发跟JS相关的问题（CJS和ECMAscript兼容问题，运行时内随时可能出现的随机错误等）。</p><p></p><p>下面来看看Rust的基本错误处理机制：</p><p></p><p><code lang=\"plain\">async fn foo() -&gt; Result{\nlet bar = String::from(\"foobar!\");\n// return is implicit, no need to write \"return\"\nmatch bar.trim() {\n    \"foobar!\" =&gt; Ok(bar),\n      _ =&gt; Err(\"Was not foobar!\".to_string())\n             }\n   }\n \n#[tokio::main]\nfn main() -&gt; Result {\nlet Ok(res) = foo().await else {\n   return Err(\"Was not foobar :(\".to_string());\n}\n \nprintln!(\"The string was: {res}!\");\n}\n</code></p><p></p><p>这里展示了两个示例：我们可以使用基础模式匹配来确定字符串是什么，如果结果匹配则返回OK；如果属于其他内容（会加注下划线），则只返回一个具有String类型的错误（也会提示std::error::Error&nbsp;-，我们可以将其作为错误类型来处理）。我们还可以声明一个变量，要求该变量必须是实际的Result类型，否则执行其他操作（在示例中为提前返回）。之后，我们就可以使用res本体了，因为它将被声明为Result中包含的值。</p><p></p><h2>生态系统</h2><p></p><p>虽然JavaScript的生态系统（Node/npm）要比Rust庞大得多，但Rust阵营也完全能够满足大多数项目的需求。Rust目前对数据库、Redis和Web应用程序中所需的各种服务都提供良好支持，不管用哪种编程语言都能使用。</p><p></p><p>如果您打算构建SaaS，Rust正好准备了几乎包罗万象的工具箱：用于SMTP的lettre、用于Stripe支付的async-stripe，用于处理社交网络账户登录的OAuth回调oauth2，用于数据库（甚至是airtable）的SQLx（如果倾向于对象关系映射，还有Diesel或SeaORM可以选择）。当然，还有用于GPT-3的openai_api。在SaaS投入运行之后，Rust甚至支持用于RabbitMQ的lapin和用于Kafka的rs-rdkafka。由此看来，如果大家想开发一项坚如磐石的高性能服务，Rust的表现完全可以跟JavaScript正面抗衡。</p><p></p><p>根据个人经验，我发现cargo在对接各种工具时表现突出。以clippy为例，这是一款无需初始化就能使用的出色工具程序，只要输入cargo clippy&nbsp;即可启用，它能检测出不必要的借用等部分、帮助我们快速优化代码。更重要的是，如果需要把一个项目中的配置迁移至另一项目，也可以直接在根目录下创建一个clippy.toml文件并随意加以配置。</p><p></p><p>由于Rust本身并不是普及度最高的Web编程语言，所以生态系统中各厂商对它的支持态度可能没那么积极，比如开放相应服务API。但因为大多数服务API采取的都是HTTP REST Web服务的形式，所以Rust也能用得起来，大家还可以使用reqwest等工具检索自己需要的数据。</p><p></p><h2>部署</h2><p></p><p>在部署方面，Shuttle是迄今为止最简单的Rust部署方法。后端部署确实要麻烦一点，要么需要鼓捣配置文件、要么通过网站上的GUI添加环境变量来接入需要使用的服务，或者是提供相应的静态文件。</p><p></p><p>Shuttle的另一个优点就是采取基础设施即代码的实现理念，可以通过代码注释快速上手。只需简单通过Rust宏在main函数中声明，大家就能避免亲自动手鼓捣配置文件。我们可以借此交付数据库并支持静态文件，从能够编译为静态资产的Next.js、React等JS框架处添加编译前端，例如：</p><p></p><p><code lang=\"plain\">// main.rs\n#[shuttle_runtime::main]\npub async fn axum (\n#[shuttle_shared_db::Postgres] postgres: PgPool,\n#[shuttle_secrets::Secrets] secrets: SecretStore,\n#[shuttle_static_folder] static: PathBuf\n) -&gt; shuttle_axum::ShuttleAxum {\n// carry out database migrations (this assumes migrations are idempotent)\n    sqlx::migrate!().run(&amp;postgres).await.expect(\"Migrations failed :(\");\n \n    let hello_world = secrets.get(\"MY_VARIABLE\")\n   .expect(\"Is MY_VARIABLE set in Secrets.toml?\");\n \n// Make a router serving API routes that require a DB connection\n    let api_router = create_api_router(postgres);\n \n// Add a compiled frontend (like e.g. from Next.js, React, Vue etc) to the router\n    let router = Router::new()\n        .nest(\"/api\", api_router)\n        .nest_service(\"/\", get_service(ServeDir::new(static)\n        .handle_error(handle_error));\n \n// Rust returns implicitly so writing \"return\" is not required\nOk(router.into())\n}\n</code></p><p></p><h2>总结</h2><p></p><p>综上所述，Rust无疑是一款值得用于Web开发的优秀语言。凭借着内存占用小、性能水平高、正常运行时间长和运维成本低等优势，Rust将帮助您在前端领域节约下宝贵的时间和金钱。</p><p></p><p>原文链接：</p><p></p><p><a href=\"https://joshuamo876.bearblog.dev/can-rust-beat-javascript-in-2023/\">https://joshuamo876.bearblog.dev/can-rust-beat-javascript-in-2023/</a>\"</p>",
    "publish_time": "2023-05-02 14:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]