[
  {
    "title": "伯克利AI实验室开源图像编辑模型InstructPix2Pix，简化生成图像编辑并提供一致结果",
    "url": "https://www.infoq.cn/article/JSu06eARbfbxUzEe2iPk",
    "summary": "<p>来自<a href=\"https://bair.berkeley.edu/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTIzMzgwOTYsImZpbGVHVUlEIjoiczFUaFlGRFNnWm9laVJkSyIsImlhdCI6MTY5MjMzNzc5NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.pRHWBdOIPJ034Vs28K3HLWFeLf-d1eewbwAGKyHBAUY\">伯克利人工智能研究</a>\"（BAIR）实验室的研究人员开源深度学习模型<a href=\"https://www.timothybrooks.com/instruct-pix2pix?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTIzMzgwOTYsImZpbGVHVUlEIjoiczFUaFlGRFNnWm9laVJkSyIsImlhdCI6MTY5MjMzNzc5NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.pRHWBdOIPJ034Vs28K3HLWFeLf-d1eewbwAGKyHBAUY\">InstructPix2Pix</a>\"，它可以遵循人类指令来编辑图像。InstructPix2Pix在合成数据上进行训练，表现优于基线AI图像编辑模型。</p><p></p><p>BAIR团队在最近举行的2023年IEEE/CVF<a href=\"https://cvpr2023.thecvf.com/Conferences/2023/AcceptedPapers?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTIzMzgwOTYsImZpbGVHVUlEIjoiczFUaFlGRFNnWm9laVJkSyIsImlhdCI6MTY5MjMzNzc5NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.pRHWBdOIPJ034Vs28K3HLWFeLf-d1eewbwAGKyHBAUY\">计算机视觉和模式识别</a>\"（CVPR）大会上<a href=\"https://arxiv.org/abs/2211.09800?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTIzMzgwOTYsImZpbGVHVUlEIjoiczFUaFlGRFNnWm9laVJkSyIsImlhdCI6MTY5MjMzNzc5NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.pRHWBdOIPJ034Vs28K3HLWFeLf-d1eewbwAGKyHBAUY\">展示了他们的工作成果</a>\"。他们先是生成了一个合成训练数据集，其中的训练样本是成对的图像以及用于将第一幅图像转换为第二幅图像的编辑指令。该数据集用于训练图像生成扩散模型，该模型可以接受基于文本的指令来编辑图像。例如，给定一张骑马的人的图片和提示词“让她变成骑龙”，它会输出原始图片，但原来的马被替换了龙。BAIR的研究人员的表示：</p><p></p><p></p><blockquote>尽管模型完全是在合成样本上进行训练的，但它实现了对任意真实图像和人类自然语言指令的零样本泛化。我们的模型能够进行直观的图像编辑，可以遵循人类指令执行多种编辑：替换对象、改变图像风格、修改设置、艺术媒介等。</blockquote><p></p><p></p><p>之前的AI图像编辑能力通常是进行风格转换，流行的文本到图像生成模型（如<a href=\"https://www.infoq.com/news/2021/02/openai-gpt-image/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTIzMzgwOTYsImZpbGVHVUlEIjoiczFUaFlGRFNnWm9laVJkSyIsImlhdCI6MTY5MjMzNzc5NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.pRHWBdOIPJ034Vs28K3HLWFeLf-d1eewbwAGKyHBAUY\">DALL-E</a>\"和<a href=\"https://www.infoq.com/news/2022/09/stable-diffusion-image-gen/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTIzMzgwOTYsImZpbGVHVUlEIjoiczFUaFlGRFNnWm9laVJkSyIsImlhdCI6MTY5MjMzNzc5NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.pRHWBdOIPJ034Vs28K3HLWFeLf-d1eewbwAGKyHBAUY\">Stable Diffusion</a>\"）也支持图像到图像风格转换操作。然而，使用这些模型进行有针对性的编辑仍然具有挑战性。最近，InfoQ报道了微软的<a href=\"https://www.infoq.com/news/2023/04/microsoft-visual-chatgpt/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTIzMzgwOTYsImZpbGVHVUlEIjoiczFUaFlGRFNnWm9laVJkSyIsImlhdCI6MTY5MjMzNzc5NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.pRHWBdOIPJ034Vs28K3HLWFeLf-d1eewbwAGKyHBAUY\">Visual ChatGPT</a>\"，它可以调用外部工具来编辑图像，前提是提供编辑操作的文本描述。</p><p></p><p>为了训练InstructPix2Pix，BAIR首先创建了一个合成数据集。为此，团队在一个由输入文字说明、编辑指令和期望输出文字说明组成的人类文本样本的小数据集上对GPT-3进行了微调。然后，这个微调模型被给予一个大型的输入图像文字说明数据集，从中生成了超过450k次编辑和输出文字说明。然后，团队将输入和输出文字说明馈送到预训练的<a href=\"https://arxiv.org/abs/2208.01626?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTIzMzgwOTYsImZpbGVHVUlEIjoiczFUaFlGRFNnWm9laVJkSyIsImlhdCI6MTY5MjMzNzc5NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.pRHWBdOIPJ034Vs28K3HLWFeLf-d1eewbwAGKyHBAUY\">Prompt-to-Prompt</a>\"模型中，该模型根据文字说明生成成对的相似图像。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/24/243f4068025109361e49dafcb3f62f7f.webp\" /></p><p></p><p>InstructPix2Pix的架构，图片来源：<a href=\"https://arxiv.org/abs/2211.09800?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTIzMzgwOTYsImZpbGVHVUlEIjoiczFUaFlGRFNnWm9laVJkSyIsImlhdCI6MTY5MjMzNzc5NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.pRHWBdOIPJ034Vs28K3HLWFeLf-d1eewbwAGKyHBAUY\">https://arxiv.org/abs/2211.09800</a>\"</p><p></p><p>研究人员鉴于这个数据集训练了基于Stable Diffusion的InstructPix2Pix。为了评估其性能，团队将其输出与基线模型<a href=\"https://github.com/ermongroup/SDEdit?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTIzMzgwOTYsImZpbGVHVUlEIjoiczFUaFlGRFNnWm9laVJkSyIsImlhdCI6MTY5MjMzNzc5NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.pRHWBdOIPJ034Vs28K3HLWFeLf-d1eewbwAGKyHBAUY\">SDEdit</a>\"进行了比较。他们使用两个指标之间的权衡：一致性（即输入图像和编辑后图像的CLIP嵌入之间的余弦相似度）和方向相似性（即编辑后文字说明中的变化与编辑后图像的变化在多大程度上保持一致）。在实验中，对于给定的方向相似性值，InstructPix2Pix产生的图像比SDEdit具有更高的一致性。</p><p></p><p>人工智能研究员<a href=\"https://en.wikipedia.org/wiki/Andrew_Ng?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTIzMzgwOTYsImZpbGVHVUlEIjoiczFUaFlGRFNnWm9laVJkSyIsImlhdCI6MTY5MjMzNzc5NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.pRHWBdOIPJ034Vs28K3HLWFeLf-d1eewbwAGKyHBAUY\">吴恩达</a>\"在他的深度学习新闻邮件组“<a href=\"https://www.deeplearning.ai/the-batch/issue-199/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTIzMzgwOTYsImZpbGVHVUlEIjoiczFUaFlGRFNnWm9laVJkSyIsImlhdCI6MTY5MjMzNzc5NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.pRHWBdOIPJ034Vs28K3HLWFeLf-d1eewbwAGKyHBAUY\">The Batch</a>\"”中评价了InstructPix2Pix：</p><p></p><p></p><blockquote>这项工作简化了生成和人造图像的编辑操作，并提供了更一致的结果。巧妙地利用现有模型，模型作者能够使用相对较少的人类标记样本在新任务上训练他们的模型。</blockquote><p></p><p></p><p><a href=\"https://github.com/timothybrooks/instruct-pix2pix?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTIzMzgwOTYsImZpbGVHVUlEIjoiczFUaFlGRFNnWm9laVJkSyIsImlhdCI6MTY5MjMzNzc5NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.pRHWBdOIPJ034Vs28K3HLWFeLf-d1eewbwAGKyHBAUY\">InstructPix2Pix的代码</a>\"可在GitHub上获取，<a href=\"https://huggingface.co/timbrooks/instruct-pix2pix?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTIzMzgwOTYsImZpbGVHVUlEIjoiczFUaFlGRFNnWm9laVJkSyIsImlhdCI6MTY5MjMzNzc5NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.pRHWBdOIPJ034Vs28K3HLWFeLf-d1eewbwAGKyHBAUY\">模型</a>\"和<a href=\"https://huggingface.co/spaces/timbrooks/instruct-pix2pix?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTIzMzgwOTYsImZpbGVHVUlEIjoiczFUaFlGRFNnWm9laVJkSyIsImlhdCI6MTY5MjMzNzc5NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.pRHWBdOIPJ034Vs28K3HLWFeLf-d1eewbwAGKyHBAUY\">基于Web的演示</a>\"可在Huggingface上访问。</p><p></p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/07/berkeley-instruct-pix2pix/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTIzMzgwOTYsImZpbGVHVUlEIjoiczFUaFlGRFNnWm9laVJkSyIsImlhdCI6MTY5MjMzNzc5NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.pRHWBdOIPJ034Vs28K3HLWFeLf-d1eewbwAGKyHBAUY\">https://www.infoq.com/news/2023/07/berkeley-instruct-pix2pix/</a>\"</p>",
    "publish_time": "2023-08-24 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "自主研发多套系统实现数字化转型，安能物流如何打造一栈式物流数据平台？",
    "url": "https://www.infoq.cn/article/4Pw69p65Retxs5kWgTOy",
    "summary": "<p></p><blockquote>作为加盟制货运合作商平台模式的提出者，安能物流是快运行业数字化转型的先行者。与快递行业不同，快运行业面临着业务流程复杂、交易链路长等问题，对数据的准确度、线上交易数据的生命周期等有着较高要求。因此，安能物流IT系统演进路线、建设思考、数据库选型等对行业具备极强的参考价值。</blockquote><p></p><p></p><p>嘉宾｜李家林 安能物流数据库负责人</p><p>&nbsp;</p><p>本文要点：</p><p>1.&nbsp;快运行业的业务特点及安能物流的数字化转型过程；</p><p>2.&nbsp;在数字化转型中，安能物流在人工智能层面做过哪些探索，结果如何；</p><p>3.&nbsp;数据库选型从Oracle到MySQL再到TiDB，安能物流做了哪些思考；</p><p>4.&nbsp;数据库迁移前后，成本和体验发生了哪些变化；</p><p>5.&nbsp;安能物流对于数据底座及大模型技术的未来思考；</p><p></p><h2>快运行业的先行者：安能物流的数字化转型之路</h2><p></p><p>InfoQ：快运行业和快递行业的数字化转型（信息化建设）存在哪些差异？</p><p>李家林：首先，二者的业务形态存在很大不同。快递更多是针对C端，规模达到一定程度后，整个业务流程比较规范化。快运更多是针对B端业务，业务处理的流程环节繁多，业务逻辑也更为复杂。其次，企业在信息化建设过程中可能会因为缺乏顶层设计而走一些弯路，甚至需要将原有系统推到重建，比如现有系统足以支撑当前的业务形态，但却无法解决未来业务灵活多变时所出现的问题，缺少对于未来建设的思考，但大多数情况下只有企业真的走到那一步才会发现问题。</p><p>&nbsp;</p><p>InfoQ：您方便分享下安能物流的数字化转型分为哪几个阶段吗？</p><p>李家林：自2010年成立，安能物流至今已经发展了接近13年的时间。在这个过程中，安能物流自主研发了52套IT系统，开发了一系列专有的、部署于整个业务流程的数字化工具，通过全链路数字化运营和智能化决策实现了效率升级。从系统信息化建设的角度可以分为如下三个阶段：</p><p></p><p>第一个阶段是2016年以前，该阶段采取垂直大集中的模式，主要解决的问题是将所有操作、业务涉及的环节和节点全部线上化，该阶段最大的问题是灵活性不够，单一系统的功能更新会影响全网的所有流程操作。</p><p></p><p>第二个阶段是2016年到2018年，，开始对系统进行拆分，由于对微服务架构的理解不够彻底，导致最终拆分出来的系统过多，虽然解决了灵活性的问题，但忽略了业务流程节点数据环环相扣的问题，且该阶段为了解决特定应用场景的业务问题，使用了多种技术架构。</p><p></p><p>第三个阶段是2018年之后，团队意识到系统拆分过于复杂，且对用户而言操作负担过重，完成一个业务流程可能需要登录多个系统，因此该阶段开始做分布式集中，在保证系统灵活性的同时保证底层数据统一，降低数据交付的复杂度，并提高准确性。基于此，团队提出全链路数字化升级的新目标：构建新一代一栈式物流数据平台，实现货物全闭环实时状态追踪。</p><p>&nbsp;</p><p>InfoQ：在数字化转型的过程中，安能物流有引入过人工智能技术吗？具体做哪些事情？结果如何？</p><p>李家林：第一个探索方向是辅助驾驶，快运行业很大一部分成本来源于车辆运输费用，安能物流也探索过通过辅助驾驶的能力接入节省人力和油耗成本，比如一些长线路要求双驾，通过接入辅助驾驶最终只保留一位驾驶员，并且通过其规划出最佳行驶路线和最优驾驶技巧从而节省燃油成本。经过几个月的测试，我们成功验证了该想法，只是要想达到要求需要对车进行改造，成本比较高，经过测算大概需要三年时间可以回本。据了解，目前已经有货运公司开始跟车厂合作生产这类型的汽车，未来是有可能实现规模化的。</p><p>第二个探索方向是场内货物极速定位。相比于快递行业，快运行业的物品形状更不规则、体积更大，这些因素导致场内货物往往分布在场内更大的区域范围内，随之而来的问题就是需要找到诸如拦截件的时候费时费力。目前，安能物流已经通过RFID射频技术实现了一定距离范围内的快件位置搜寻，整个实践下来确实提升了效率；其次通过RFID技术还能快速的完成场内货物盘点。当下，RFID的成本还是比较高，但我相信未来成熟之后成本会有所降低。</p><p>&nbsp;</p><p>InfoQ：最近两年，行业内对于“降本增效”非常关注，安能物流的IT部门转型过程是否有这方面的思考？</p><p>李家林：安能物流已经在该方向进行实践。具体来说，在组织架构层面，组织变得更加扁平化，IT组织内部按照产品线的方式调整团队，缩减了部门分类；在业务层面，部门内人员的具体定位都做了重新梳理，明确定位了每一个业务角色应该具备的能力和承担的责任；在IT技术层面，团队的职能不仅仅是提供工具和系统给业务人员使用，需要通过已有业务数据挖掘业务潜在价值，寻找新的增长点。</p><p></p><h2>从Oracle到MySQL再到TiDB，安能物流成功打造一栈式物流数据平台</h2><p></p><p></p><p>InfoQ：在数字化转型的过程中，安能物流对底层数据库的需求是如何变化的？</p><p>李家林：在数字化化转型的第三阶段，我们意识到既要保证系统数据的灵活可扩展，又要保证底层数据交互统一，降低数据交互的复杂度。此时，安能核心业务系统—结算系统（涉及总部及下属30000多家加盟网点，主要包含充值、交易、算费、调账、扣款、代收、代付包括税差全费用结算业务流程处理）因面临系统数据动态扩展、高并发、数据生命周期等问题，需要对系统数据库进行重构，此时就面临数据库选型的需求。</p><p><img src=\"https://static001.geekbang.org/infoq/1b/1b04e6dcfe07e7881d6cd6b4631e1eb4.png\" /></p><p>当时，业内主流的选择就MySQL和PostgreSQL两种。经过比较，团队最终选择了当时常用的MySQL加数据库中间件代理的模式。在运行了不到三年的时间，这套系统就出现了比较大的问题，这种伪分布式集群的第一个问题是扩展性太差；第二个问题是库压力不均和性能问题。</p><p></p><p>为了避免同一个网点查询或处理数据时出现跨库问题，当时分库分表设计的思路是以网点编码作为分库表的路由规则，共分了八个库，除此以外，为了保证单库单表数据量尽量均衡，我们还将产粮区如华东华南和非产粮区如东北西北区域的网点进行相互组合后放在同一个库同一个表中，即便如此，由于业务的不断增长，地区产业布局的变化，网点货量的变化，最终不同库的表数据量还是出现较大差异，个别库的压力极大，这就面临需要对该伪分布式集群增加节点或对现有节点数据进行迁移再平衡，无论哪一种方案，都需要重新设计分库分表路由规则和对现有集群数据进行迁移再平衡的问题，且MySQL当时的性能已经到了瓶颈，在线交易数据最多保持六个月的生命周期。基于以上面临的诸多挑战，我们大概在20年开始考虑，要对这套结算系统MySQL数据库进行换代升级。</p><p><img src=\"https://static001.geekbang.org/infoq/62/62304903b589e07b68f64781ec18d219.png\" /></p><p>InfoQ：快运行业对数据生命周期有哪些具体要求？</p><p>李家林：严格意义上来讲，数据都是有生命周期的。相比于快递行业，快运的业务流程节点更多，业务逻辑也更复杂一些，而在每一个业务环节，不但会涉及到业务操作，还会涉及到一些管理的动作，因此每个业务节点都会产生大量数据，而这些数据又环环相扣，这对数据的实时性金和准确性要求非常高。数据生命周期可能会持续一至两年。在结算没有完成之前，数据是不能归档到历史数据的。从业务角度来讲，我们希望在线的结算数据周期生命更长，我们其实没有做严格意义上的冷热数据分离，主要也是考虑到对冷数据进行分析也是存在业务价值的。</p><p>&nbsp;</p><p>InfoQ：基于以上因素，安能物流在数据库选型过程主要考虑哪些因素？</p><p>李家林：在选型阶段，我们调研了很多数据库，我们的目标是希望找到一款性能、稳定性、扩展性可以满足业务诉求的分布式数据库。在测试TiDB之前，我们先测试了PostgreSQL，但PostgreSQL有自己的集群模式，整体测试效果不及预期。虽然PostgreSQL生态也有一些自动化的工具，但与MySQL加代理中间件的伪分布式集群没有本质区别。2020年3月份，我们了解并开始测试TiDB，从3.0版本一直测试到5.4版本。具体来说，3.0版本并没有达到安能结算业务的要求，因为该业务对数据的准确性、大规模数据查询和处理能力及高可用性等方面有较高要求。经过测试发现，在TiDB&nbsp;5.4版本可以满足我们的要求，且在此期间PingCAP团队也和我们团队进行了交流，到目前为止最新的TiDB版本已实现了我们对TiDB提出的所有要求。</p><p><img src=\"https://static001.geekbang.org/infoq/2f/2f35891ff6be333532364b77f3144895.png\" /></p><p>在测试达到要求之后，团队用了接近10个月的时间开始进行迁移，包括迁移前的数据校验等筹备工作。最终，在2023年初完成了结算系统的数据库迁移，原有的MySQL数据库已经下线。由于快运行业的业务流程比较长，后期会分批进行迁移，目前正在进行快件装车扫描、卸车扫描、分拣扫描等运营操作节点的数据迁移，预计今年底全面完成。</p><p><img src=\"https://static001.geekbang.org/infoq/0a/0a9f06b528b8ebeb87193d2d0a791faa.png\" /></p><p>InfoQ：切换前后，整个成本和体验发生了哪些变化？</p><p>李家林：一是TiDB高度兼容MySQL，应用代码几乎无改动，系统平滑迁移至TiDB上，是一款真正的分布式关系型数据库；二是一键水平扩容或者缩容，可按需对计算、存储分别进行在线扩容或者缩容并对应用运维人员透明；三是金融级高可用，计算与存储分离的多副本存储，保证总部与网点费用结算准确性和高可用；四是大规模数据处理能力和实时HTAP特性，增加了在线数据的生命周期，降低系统低延迟；五是内置的图形化监控系统，提供完整闭环监控能力和故障分析能力，降低了运维成本和门槛；六是支持表结构在线变更（DDL），减少了系统变更停机时间，提高了业务的可用性。</p><p>&nbsp;</p><p>InfoQ：为什么没有先从边缘业务开始试点迁移？</p><p>李家林：这与研发团队的技术积累和风格有关。此前已经完成了从Oracle到MySQL数据库的切换，当时是因为Oracle的性能确实无法达到要求，团队充分具备相应的技术积累和沉淀，所以本次就直接选择将核心系统从MySQL切换到TiDB，如果从边缘业务开始试点，整个战线会非常长。</p><p></p><p>InfoQ：安能如何借助于TiDB实现数字化升级目标？</p><p>&nbsp;</p><p>李家林：安能在系统建设过程中，经历了从垂直大集中模式到数据独立拆分，再到微服务架构下数据分布式集中存储这样一个过程。目前我们正将业务全链路环节运营操作系统切换到TiDB上，从而降低系统数据交互的复杂度。如何使用最简单、最灵活、最高效的技术体系和最少的成本构建新一代数据平台，实现货物从下单到签收及结算等全闭环实时状态追踪。</p><p><img src=\"https://static001.geekbang.org/infoq/b0/b054ee318820f7a237fc4140bdba5e46.png\" /></p><p>基于TiDB在安能的应用实践，接下来我们将借助TiDB分布式、高可用性、弹性伸缩、大规模数据处理和实时HTAP等特点来构建新一代一栈式物流数据平台，加速公司数字化升级。</p><p>&nbsp;</p><p>我们将使用TiDB作为一栈式物流数据平台的底座，把我们源端业务系统所采集的所有数据，按照业务主题和数据域统一进行存储，降低不同系统之间数据交互的复杂度，解决数据统一的问题。而在一栈式物流数据平台的基础上，我们可以做相应的数据服务，统一对外提供数据服务平台和API接口，以及更高阶的数据应用产品。</p><p></p><h3>未来规划</h3><p></p><p>InfoQ：面向AI时代，TiDB提出了Serverless的模式，您怎么看待这一动作？</p><p>李家林：目前，Serverless版本还是在云端，企业级的私有化部署可能需要两到三年的时间。对快运行业而言，一个企业内部可能不太需要建很多的TiDB集群，只需要做到用户或应用级别的资源隔离，并给不同的开发人员提供相应的代码开发服务就足够了。基于此，TiDB的Serverless服务可能更多还是面向未来的中小型企业或个人，快运行业可能更多的还是使用其现有的企业级数据库产品。</p><p>&nbsp;</p><p>InfoQ：未来在数据层面，安能物流还有哪些计划？</p><p>李家林：对我们而言，最重要的还是底层的数据。现在，我们选择将TiDB作为新一代物流平台的数据底座，未来希望基于此统一技术栈，用最简单的体系满足业务层面多样化的数据需求。在TiDB的演进过程中，我们需要的功能都正在被PingCAP一一实现，相信未来TiDB还会出现更多令人期待的功能和特性，这也是我们认为的分布式数据库最优选择。</p><p>&nbsp;</p><p>InfoQ：对于大模型相关技术，安能物流未来是否会考虑接入业务？</p><p>李家林：目前，大家普遍想到的场景是智能客服，这需要给大模型输入一些快运行业的特定数据做训练，基本就可以应用了。此外，我们希望可以实现全链路的数据可视化，应用数据挖掘业务的潜在增长点，包括对我们的服务品质和时效性有所提升，通过模型和算法做事前预测，提前干预可能的风险点。</p>",
    "publish_time": "2023-08-24 10:09:20",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "2023 中国人工智能成熟度模型报告",
    "url": "https://www.infoq.cn/article/IV4VhedKw1E1tY8Hleje",
    "summary": "<h3>研究背景</h3>\n<p>2022年上半年，AI绘画等生成式AI的内容引发了人工智能领域的广泛关注，年底发布的ChatGPT更是迅速破圈，话题度和讨论度不断提升。这些变化的趋势也延续到了2023年上半年，人们讨论话题也向着大模型的实际应用逐渐深入，同时AI安全也展现了大家对技术突破的不同态度。<br />\n今年年初，InfoQ研究中心发布了<a href=\"http://www.infoq.cn/minibook/UGhD7MTY5Z43JG5YmWP3\">《中国软件技术发展洞察和趋势预测报告 2023》</a>，在报告中将各个领域的关键技术按照不同成熟度阶段进行了划分，总结成为中国技术成熟度评估曲线。报告发布之后也获得了众多企业和开发者的关注和讨论。<br />\n因此，作为年度趋势报告的延续，InfoQ研究中心基于2023年人工智能领域的种种变化，更新《2023 中国人工智能领域技术成熟度模型报告》，为技术的应用决策和未来投资参考提供研究分析工具。<br />\n未来，InfoQ研究中心还将继续推出更多细分领域（云原生、大数据等）的成熟度报告，并定期更新，欢迎大家持续关注。</p>\n<h3>中国人工智能技术成熟度模型</h3>\n<p><img alt=\"\" src=\"https://static001.infoq.cn/resource/image/0a/32/0affd338817e741dcaf474de3caca432.png\" /></p>\n<h5>备注说明</h5>\n<ul>\n<li>模型涵盖40+人工智能相关技术点，立足三大核心指标（技术专利数量、技术发展时间、技术舆论指数），参考市场规模、融资事件等公开资料，并结合了AI行业内硬件、模型、应用不同领域的各位专家观点。</li>\n<li>技术专利相关数据来自国家知识产权局旗下专利检索及分析系统，检索时间为2023年8月15日。</li>\n<li>技术发展时间使用知网论文库等学术平台进行相关技术领域论文最早收录年份统计计算。</li>\n<li>技术舆论指数数据来源为各家技术媒体和开发者社区，包括InfoQ中文站和CSDN社区。</li>\n</ul>\n<h3>中国人工智能技术厂商生态图谱</h3>\n<p><img alt=\"\" src=\"https://static001.infoq.cn/resource/image/2c/f3/2ccc22e8a501f6e8885ca7c4a3bb2ff3.png\" /></p>\n<h3>目录</h3>\n<ul>\n<li>⼈工智能技术发展历程</li>\n<li>中国人⼯智能技术成熟度模型</li>\n<li>中国⼈工智能技术⼚厂商⽣生态图谱</li>\n</ul>",
    "publish_time": "2023-08-24 10:10:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何使用 Amazon CodeWhisperer 免费进行代码安全检查",
    "url": "https://www.infoq.cn/article/p4r2t1XP2yXAK55ti8zV",
    "summary": "<p>CodeWhisperer 是Amazon发布的一款免费的AI 编程辅助小工具，在辅助程序员编程的同时，还具备代码安全审计的功能。可以快速扫描 Java、JavaScript 和 Python 项目中难以发现的漏洞，并获取代码建议以立即修复这些漏洞。遵循跟踪安全漏洞的最佳实践，例如开放全球应用程序安全项目 (OWASP) 概述的漏洞，或者不符合加密库最佳实践及其他类似安全最佳实践的漏洞。今天小试牛刀，试验一下CodeWhisperer的代码安全检查能力，成功识别出Python代码中可能存在的系统命令注入漏洞、SQL注入漏洞、MD5碰撞漏洞以及反序列化漏洞，666 ～</p><p></p><h2>系统命令注入漏洞</h2><p></p><p></p><p>以下是一段有安全漏洞的 Python 代码：</p><p><code lang=\"python\">import os\n\nfilename = input(\"请输入文件名：\")\nos.system(\"rm \" + filename)</code></p><p></p><p>这段代码的作用是删除用户输入的文件名对应的文件，但存在安全漏洞。其中的漏洞是，用户可以通过输入特殊字符来执行任意系统命令，而不仅仅是删除文件。例如，如果用户输入的是&nbsp;;ls，则会先删除指定文件，然后执行&nbsp;ls&nbsp;命令。这可能导致系统被攻击者接管或者数据被窃取，因此这段代码需要进行安全性改进。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/db/dbe0eb387e9b3577d12c706ffac2f4fc.png\" /></p><p></p><p>Amazon CodeWhisperer 成功检测出：系统命令注入漏洞。</p><p></p><p></p><h2>SQL注入漏洞</h2><p></p><p></p><p>以下是一个有安全漏洞的 Python 代码：</p><p></p><p><code lang=\"python\">import sqlite3\n\nconn = sqlite3.connect('example.db')\nc = conn.cursor()\n\nc.execute('''CREATE TABLE stocks\n             (date text, trans text, symbol text, qty real, price real)''')\n\ndate = input(\"请输入日期：\")\ntrans = input(\"请输入交易类型：\")\nsymbol = input(\"请输入股票代码：\")\nqty = input(\"请输入数量：\")\nprice = input(\"请输入价格：\")\n\nc.execute(f\"INSERT INTO stocks VALUES ('{date}', '{trans}', '{symbol}', {qty}, {price})\")\n\nconn.commit()\nconn.close()</code></p><p></p><p>这段代码的作用是向 SQLite 数据库中插入一条记录，但存在安全漏洞。其中的漏洞是，用户输入的数据没有进行任何过滤或转义，从而可能导致 SQL 注入攻击。例如，如果用户输入的&nbsp;symbol&nbsp;参数是&nbsp;ABC'); DROP TABLE stocks; --，则会删除&nbsp;stocks&nbsp;表。这可能导致数据丢失或系统崩溃，因此这段代码需要进行安全性改进。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/05/05a7f1fbd8b83ac88a1c91f5d3bc4076.png\" /></p><p></p><p>Amazon CodeWhisperer 成功检测出：SQL注入漏洞。</p><p></p><h2>MD5碰撞漏洞</h2><p></p><p></p><p>以下是一个有安全漏洞的 Python 代码：</p><p></p><p><code lang=\"python\">import hashlib\n\npassword = input(\"请输入密码：\")\n\nhash = hashlib.md5(password.encode('utf-8')).hexdigest()\n\nprint(f\"您的密码的 MD5 值为：{hash}\")</code></p><p></p><p>这段代码的作用是计算用户输入的密码的 MD5 值，并输出结果。但存在安全漏洞。其中的漏洞是，MD5 算法已经被证明不再安全，可以被暴力破解或碰撞攻击。因此，如果攻击者获得了用户的 MD5 值，就可以使用彩虹表等方法轻松地破解密码。这可能导致用户账户被攻击者接管或者数据被窃取，因此这段代码需要进行安全性改进。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/40/4098461d87de6d1e6c26b3223a5c88ad.png\" /></p><p></p><p>Amazon CodeWhisperer 成功检测出：MD5碰撞漏洞</p><p></p><h2>反序列化漏洞</h2><p></p><p></p><p>以下是一个有安全漏洞的 Python 代码：</p><p></p><p><code lang=\"python\">import pickle\n\nserialized_data = input(\"请输入序列化数据：\")\ndata = pickle.loads(serialized_data)\n# 使用反序列化后的数据...</code></p><p></p><p>这段代码的作用是对输入序列化数据，进行反序列化。但存在安全漏洞，其中的漏洞是没有对输入进行验证和过滤，直接进行反序列化操作可能导致恶意对象的执行，从而导致远程代码执行或数据泄露。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6c/6cf801c61cd5482a0bd8fb1e683779dd.png\" /></p><p></p><p>Amazon CodeWhisperer 成功检测出：反序列化漏洞。</p><p></p>",
    "publish_time": "2023-08-24 10:39:25",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "1小时搭建对话式搜索服务，阿里云开放搜索 OpenSearch 重磅推出 LLM 智能问答版！",
    "url": "https://www.infoq.cn/article/mcgD3Vy1bii7GZ5R8KiR",
    "summary": "<p>2023 年以来，全球掀起了一场有关大模型的“热潮”，国内外企业纷纷入局参与大模型的研发与训练，调研和推动<a href=\"https://www.infoq.cn/article/NifbwmdGvISTtEyTTNT7\">大模型</a>\"技术与产业结合落地方案，大模型生态蓬勃发展。</p><p></p><p>2023 年过半，我们发现，业内对于大模型技术的关注点已经逐渐从“AI 大模型可以做到什么”、“国内哪些企业拥有大模型技术”等话题，转至“企业如何接入大模型”、“企业如何实际应用大模型技术降本增效”上，越来越多的企业开始关注大模型的具体接入与应用。而大模型的典型应用场景，对话式搜索服务一直备受行业关注，高效、低成本搭建高质量对话式搜索服务，进一步提升用户的信息检索体验则成为了新时代每个企业都需要探索的方向。</p><p></p><p>对此，近期 InfoQ 获悉，阿里云开放搜索 <a href=\"https://xie.infoq.cn/article/9863d685407f528b90b13dd4f\">OpenSearch </a>\"重磅推出 LLM 智能问答版，提供基于大模型的 LLM 智能对话产品，帮助企业在 1 个小时以内，从 0 搭建起自己的对话式搜索服务。自开放搜索 OpenSearch LLM 智能问答版正式发布一个月以来，已有数百家企业接入使用，在最新发布的钉钉个人版中，也大规模应用了产品所提供的能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a7/a74bbe1eaf77375fdd1dd000e0670d73.png\" /></p><p></p><p>钉钉个人版的智能问答能力由阿里云开放搜索 OpenSearch LLM 智能问答版提供支持</p><p></p><p>据悉，企业只需要将原始数据导入实例，开放搜索 OpenSearch LLM 智能问答版即可为其搭建完整的一站式对话式搜索技术链路，企业客户再通过简单的 API 对接，即可将生成搜索结果和传统搜索结果集成在自己的应用中。本文将以阿里云开放搜索 OpenSearch 产品为引，剖析企业接入大模型的痛点、难点，并为大家进一步解读阿里云开放搜索 OpenSearch LLM 智能问答版的技术实践与能力亮点。</p><p></p><p></p><h2>企业接入 AI 大模型的趋势已经到来</h2><p></p><p></p><p>目前，企业接入大模型的需求场景主要围绕在电商行业选品、智能对话客服、企业内部知识库资料智能对话检索，以及企业自有 App 的搜索推荐系统搭建等。</p><p></p><p>来自阿里云 OpenSearch 的行业调查结果显示，企业自行接入大模型，普遍面临着二次开发任务繁重、模型 finetune 困难、运维工作量大、缺乏清晰的业务目标测评方法等实际难题。具体而言，在接入大模型方面往往面临以下六大“拦路虎”：</p><p></p><p>人才储备与技术能力不足：大模型的研发训练和维护需要专业的技术团队支持，但是部分企业没有招聘和培养相应的人才，无法确保大模型能够得到有效支持和维护。合规与数据安全难保障：企业需保障大模型的对话结果基于业务数据生成、生成内容安全合规，并且保障企业数据安全，避免相关法务风险。硬件基础不够：大模型需要大量的计算资源，包括 GPU、TPU 等硬件设备，这对于个人或小型企业来说，可能是难以承担的开销。模型优化和解释性问题：随着模型参数数量的增加，调整参数的复杂度也在增加。如果企业研发人员经验不够，参数调节不当，可能会导致过拟合或欠拟合等问题；大模型的可解释性比较差，所以对于一些对模型解释性能力要求比较高的领域（例如医疗、金融等）而言调整难度更大。维护成本困境：维护大模型的调优、数据更新需要占用较多人力与时间成本。训练语料不充分：大模型的训练需要大量训练数据和语料信息，如果企业相关数据较少，很难获得较好的大模型训练效果。</p><p></p><p>目前，多家国内外知名企业均已发布自主研发的大模型，并宣布未来旗下产品将全面接入大模型。这意味着，大模型技术本身已经具备企业接入与业务落地的成熟度，接入大模型是各行业的整体趋势，但对于大部分企业来说，与其自行训练大模型，不如直接选用大模型的应用层解决方案，将资源聚焦在业务与需求本身，用更绿色、更低碳的方式推动整个信息产业技术升级。</p><p></p><p></p><h2>阿里云 OpenSearch LLM 如何让企业具备智能对话能力？</h2><p></p><p></p><p>阿里云 OpenSearch 始终致力于帮助企业客户构建高质量的端到端搜索服务，本次快速推出 LLM 智能问答版，提供端到端全托管的对话式搜索服务，也是 OpenSearch 产品希望帮助企业解决算力不够、人力时间成本高昂等大模型接入问题，让每一家企业都能够便捷地接入大模型，享受全新一代的搜索体验，提升信息检索效率，感受 AI 为业务带来的改变的新使命。</p><p></p><p>OpenSearch 的智能对话与文本生成能力通过 LLM 提供，这里我们以阿里云自研的通义千问为例，介绍 OpenSearch LLM 智能问答版的技术实现。</p><p></p><p></p><h3>OpenSearch LLM 智能问答版系统架构&nbsp;&nbsp;</h3><p></p><p></p><p>OpenSearch LLM 智能问答版系统架构主要包含业务数据处理、对话搜索在线服务、大模型预训练三个部分。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c8/c8909c0b781de713f06118925010efa1.png\" /></p><p></p><p></p><h4>业务处理数据</h4><p></p><p></p><p>相比传统的搜索引擎，OpenSearch &nbsp;LLM 智能问答版离线数据处理流程最大的变化点在于对业务数据的处理：</p><p></p><p>传统搜索引擎的数据源是结构化文本，而这里需要处理的往往是非结构化文本，并且数据的格式会更加多样（HTML、Markdown、纯文本、PDF 等）。传统搜索引擎构建索引是基于文档的唯一主键，而这里由于数据源的差异，需要先对文档进行段落拆分，对拆分后的段落生成新的段落主键。传统搜索引擎基于文本索引进行内容匹配，而这里采用向量索引，更加容易适配丰富的数据格式和长文本搜索。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/67/67a8dd1ea27e160b34ae50c7f28f7794.png\" /></p><p></p><p></p><h4>对话搜索在线服务</h4><p></p><p></p><p>据悉，相比传统的搜索引擎，OpenSearch 智能问答版在线服务架构变化非常大，主要区别有：</p><p></p><p>传统搜索一般会返回 10 个以上的结果，并且经常会以翻页查询的方式呈现结果，而这里的检索是为了找到相关度相对最高的段落内容，Top N 中的 N 不宜过大（一般在 3 以内），且需要控制相关性，确保不召回相关性过低的段落带来误导。检索完成得到 Top N 搜索结果后，将结果添加到 prompt 中输入大模型，这一阶段耗时一般较大，OpenSearch 智能问答版支持流式输出以缓解等待时间过长的体验问题。返回结果时，基于用户业务数据，通过 API 输出指定 Query 下的参考链接、参考图片和模型生成的对话结果。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c5/c5fe3b648498c2780b2ba2881c169554.png\" /></p><p></p><p></p><h4>大模型预训练</h4><p></p><p></p><p>阿里云 OpenSearch 深度整合和应用通义千问模型，为了提升模型在检索增强场景下的有效性，减少有害性，OpenSearch LLM 智能问答版还对模型进行了有监督的模型微调（Supervised Finetune，SFT）进一步强化检索增强的能力。对比 SFT 后的对话搜索模型与原始 LLM，阿里云 OpenSearch 团队发现：经过 SFT 的模型更擅于总结输入文档中的内容，从而精准简练地回答用户问题，达到智能对话搜索效果。</p><p></p><p>此外，OpenSearch 还可以支持包括 Llama2、openbuddy、falcon 在内的多种开源模型，用户无需开发、集成、部署，即可直接使用 LLM 能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/06/068c254f361ee61d34cb9fa0338360eb.png\" /></p><p></p><p></p><h3>强大的对话检索能力&nbsp;&nbsp;</h3><p></p><p></p><p>阿里云 OpenSearch LLM 底层采用了阿里巴巴自研的大规模高性能搜索引擎，可以保障搜索环节的召回准确度与性能，擅长处理向量维度更高的大模型场景。</p><p></p><p>除了引擎优势之外，阿里云 OpenSearch LLM 智能问答版通过内置段落拆分模型、内置文本向量化模型、内置图片向量化模型，保证了对话搜索结果的精准度。同时已支持多轮对话，结合上下文挖掘用户需求，对话搜索结果全部基于客户数据生成，保障内容的可靠性和相关性。</p><p></p><p>在此基础上，阿里云 OpenSearch LLM 智能问答版提供了充分开放的模型能力，包含多种底座 LLM 可替换，自定义 prompt，模型参数调优与排序策略优化等，此外还支持对话结果人工干预，满足对语言、风格等对话式搜索效果的更高要求。</p><p></p><p>在工程架构方面，阿里云 OpenSearch 诞生于电商场景，经过内部业务多年打磨沉淀，能够稳定承载千亿级数据、百万级 QPS 的业务流量。读写分离的架构使得数据写入与查询相互不影响，能够有效保障服务的稳定性。此外，产品支持对话结果的流式输出，能够缓解由于回答生成速度慢带来的用户体验问题。</p><p>段落拆分模型：ops-text-ace-001</p><p></p><p>模型最终生成的效果很大程度上是由检索结果决定的。传统文档检索系统只需要针对 Query 给出最相关的文档列表。检索增强式 LLM 则需要给出具体与 Query 相关的段落。权衡效率与效果，OpenSearch 智能问答版的段落拆分模型支持结构化数据及包含 doc、pdf、html 在内的多种非结构化数据的快速导入，并能够实现自适应段落长度，保障语义段落的完整性。</p><p></p><p></p><h4>文本向量化模型：ops-text-embedding-001</h4><p></p><p></p><p>相比于传统搜索，在与 LLM 的交互中，一个很大的改变是用户可以非常自然地口语化输入。对于口语化输入，基于语义的向量检索架构天然契合。OpenSearch 内置自研高性能向量检索引擎，擅长处理向量维度更高的大模型场景，可以达到数倍于开源引擎的搜索性能和更高的召回率。</p><p></p><p>为了更加适配多语言、多行业的对话搜索场景，OpenSearch 算法团队进行了定制模型研发与效果调优，并对模型效率进行了针对性地优化，以满足搜索场景实时性的需求，最终产出 ops-text-embedding-001 模型。在中文数据集 Multi-CPR 上，ops-text-embedding-001 模型在 MRR@10 等关键指标上的表现已经优于行业标杆向量模型即 OpenAI 的 text-embedding-ada-002：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/20/2063b660d3e01eafa4938867e7569a08.png\" /></p><p></p><p></p><h4>图像向量化模型：ops-image-embedding-001</h4><p></p><p></p><p>对于内容行业而言，大量关键信息以图片的形式呈现，图文结合的多模态展现可以让企业专属智能对话搜索效果大幅提升。为了在对话式搜索中实现图文并茂的效果，OpenSearch 智能问答版也提供了图片向量化模型 ops-image-embedding-001，该模型结合多模态的信息，计算 Query 与文档中图片的图文相关性，最终返回相关性最高的图片作为参考图片结果。</p><p></p><p></p><h4>对话式搜索效果调优</h4><p></p><p></p><p>影响对话式搜索业务效果的环节通常包含三个方面：</p><p></p><p>底座大模型的效果OpenSearch 支持多种底座大模型的选择，除阿里巴巴自研的通义千问大模型，还包含开源的 Llama2、openbuddy、falcon 等多种 LLM 可选，用户可基于自身的业务需求、场景、语言等，尝试并使用最适配的 LLM。同时，还支持调整部分模型参数，解决对话式搜索过程中的 bad case。搜索召回的效果除上文已经介绍过的段落切分模型和文本向量化模型外，OpenSearch 还内置多种搜索召回排序函数与规则，用户可以自行定制排序策略，召回最符合业务需求的结果。Prompt 适配度Prompt 中除了包含搜索召回的业务文档外，还需要包含对 LLM 的角色、指令控制，以实现预期的效果。OpenSearch 支持用户自行调整输入给 LLM 的基础 Prompt，用户可基于自身业务需求，灵活调整语言、语气、无结果时的回答语、输出格式等内容，充分满足灵活性和效果调优需求。</p><p></p><p>此外，针对搜索领域常见的高频 Query 干预与效果调优问题，OpenSearch 智能问答版还支持基于知识库的人工干预。用户可以指定干预问题与对应回答，OpenSearch 智能问答版会识别相似问题，并根据知识库中的预设结果给出相应答案，从而实现针对指定 Query、活动等场景的运营干预，使对话结果更安全可靠、服务于企业业务。</p><p></p><p>目前，OpenSearch LLM 版本已与多个阿里巴巴内部业务、云上客户合作实现方案落地，帮助机器硬件资源稀缺、不具备前期数据切片、向量化等环节的处理能力和经验的企业，基于垂直领域数据构建对话式搜索服务。</p><p></p><p>以阿里云产品文档数据作为业务数据，基于 OpenSearch LLM 智能问答版搭建对话式搜索系统，我们可以看到如下的对话搜索效果演示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/90/90d7c8bde4f5f0d33967465c253ce7a1.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/68/6811c3f063ff4433b55fd8d24ecd1dd5.png\" /></p><p></p><p>据悉，在上述效果演示中，企业只需将相应的文档数据导入 OpenSearch LLM 智能问答版，即可根据用户输入的 Query 返回对话模型生成的图文答案和相应的参考链接，实现智能对话搜索效果。</p><p></p><p>未来 OpenSearch LLM 智能问答版将提供更多行业的解决方案，为各垂直领域提供行业专属大模型，并将上线电商行业大模型。此外，OpenSearch 还将在现有能力基础上，推出 LLM 智能问答专业版，支持更定制化的专属模型 finetune、预训练等能力。未来 OpenSearch LLM 智能问答版将支持客户更高自由度的模型使用，满足业务对生成风格、生成效果的更高要求。</p><p></p><p></p><h2>对话式搜索将迎来更广阔的应用</h2><p></p><p></p><p>阿里云 OpenSearch 除了提供基于内置大模型的 LLM 智能问答版之外，也面向开发者推出基于 OpenSearch 向量检索版 +LLM 工具包的大模型应用解决方案，支持客户灵活选用文档切片方案、向量化模型、大语言模型，为客户提供高性价比的向量检索服务，并已经将向量检索版本核心引擎 Havenask 进行了开源。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4f/4f868e9aee3455a19f294f7dd71baf11.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/66/6621f305d026b27779d6f19a7797a5ba.png\" /></p><p></p><p>OpenSearch 向量检索版 + 大模型方案图示</p><p></p><p><a href=\"https://help.aliyun.com/document_detail/2504703.html\">OpenSearch 向量检索版 + 大模型方案</a>\"</p><p><a href=\"https://github.com/alibaba/havenask/blob/main/llm/README.md\">开源 Havenask+ 大模型方案</a>\"</p><p></p><p>对话式搜索将对电商场景、内容社区场景、金融场景、政企服务场景进行大规模的体验升级，用户与平台的交互方式也会因大模型技术而带来全新的改变，所以产品的落地形态和用户体验一定是这场大模型变革中的下一个重要战场。因此，无论是推出 LLM 智能问答版这种全托管的 MaaS（Model as a Service）产品，或是在云上提供更高性价比的 OpenSearch 向量检索引擎及 LLM 工具包，还是下定决心将核心引擎开源的一系列举措，OpenSearch 的目标就是希望为整个行业提供新的技术方案与选型，解决不同状态、不同阶段、不同预算的企业客户及开发者遇到的共性难题，即 OpenSearch 搞定对话式搜索场景的通用基础设施，企业级开发者专注进行场景级的业务优化与落地。</p><p></p><p>未来 OpenSearch 还会进一步“OPEN”，把整套工程链路彻底开放给大模型的开发者，任何通过认证的大模型都可以随时上架到 OpenSearch 平台，在合规的前提下为第三方开发者提供服务，这也是在全球 AI 行业飞速发展的今天，OpenSearch 与全行业共建的决心。</p><p></p><p><a href=\"https://www.aliyun.com/activity/bigdata/opensearch/llmsearch\">点击了解 OpenSearch LLM 智能问答版</a>\"</p>",
    "publish_time": "2023-08-24 14:36:17",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "挑战三大任务，Amazon CodeWhisperer 生成代码的能力到底如何？",
    "url": "https://www.infoq.cn/article/e52aPvCV9EldytRdXJ4o",
    "summary": "<p>ChatGPT 火出圈之后，AI 大模型编程越来越多，虽然 AI 编码暂时无法完全替代程序员，但是时代变化、潮流趋势所向，大家没有必要过多焦虑，而是应该拥抱变化，拥抱趋势，尝试用 AI 辅助自己的编码，看是否可以得到帮助，本文试用了 Amazon 的 CodeWhisperer AI 编程工具，在这里做一个小小的总结。</p><p></p><p>CodeWhisperer 通过 AI 技术，可以自动分析代码库中的模式和常见用法，从而生成符合标准的代码片段，其旨在帮助开发人员节省时间和精力，提高开发者的工作效率。</p><p></p><p>当前 CodeWhisperer 支持集成到几种开发环境中，VS、Jetbrains、JupyterLab，Lamda 等，由于平时用 C++/Python/Go 比较多，因此本文使用 JetBrains 的 Clion 来测试 CodeWhisperer 生成 C++的能力，首先安装好 Clion(具体步骤网上找或者亚马逊官网指导书)，进行 Clion 后，首先通过 tools 搜索安装 aws toolkit，安装好后启动就可以使用 CodeWhisperer 了，第一次启动时会生成一个验证码，链接到你的亚马逊账号进行授权，此处不细讲，按照提示操作即可</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ef/ef63844bbeea544664f257fc9e5ac74a.png\" /></p><p></p><p>下面进入正题：</p><p></p><p>使用 CodeWhisperer 生成代码，需要添加注释，其会根据注释一行一行完成代码编写，并且会帮助你完成要编写代码的注释</p><p></p><h4>任务一：</h4><p></p><p></p><h4>测试生成全部代码能力，主题完成一个 TCP Server 收发数据，下面图里是一步步的结果</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/93/93df399819258175a155ccd9a5dad993.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ca/caafc3e43740ba7473d54142d41be9c1.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/22/22a50c6937c0da324e9fe1e5399083f4.png\" /></p><p>最终完成的代码如下</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c8/c8644ef532436742c9cb3752c4b3df93.png\" /></p><p>生成过程并非像 ChatGPT 一样，一股脑的代码全部生成扔给你，需要开发同学一行一行的插入确认，这种情况也有好处，在于可以在开发过程中自己一行一行的确认正确性及问题，避免一大堆复杂代码重新费神的确认逻辑。</p><p></p><p></p><h4>任务二： </h4><p></p><p></p><h4>推荐相应功能的开源库以及使用已集成的开源包进行代码生成测试，主题完成一个 SIP 消息处理函数，下面图片展示其完成过程和结果</h4><p></p><p></p><p>(1)使用 osip2 解析 sip 消息，下面是生成的代码，基本符合预期</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/15/15f8b2426121690100cb2d8c9c275f9f.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/05/054d766be22667efdc706807de2d4e39.png\" /></p><p>&nbsp;(2) 期望重新推荐一个 sip 消息解析库，不知道是我已经集成了解析库还是还是什么其他原因，没有成功</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e8/e8e16857a03ee50f5623f198e8e26209.png\" /></p><p>可见 CodeWhisperer 对于 Github、Gitee 以及互联网上标准开源库是进行过训练的，可以读懂 oSip2 是一个很有名的 sip 协议栈，因此可直接使用其 API 根据注释生成可用代码</p><p></p><p></p><h4>任务三：</h4><p></p><p></p><h4>基于已完成部分代码，根据注释生成补全代码，CodeWhisperer 也可以根据上下文和注释补齐代码的相应功能，建立一个资源分配函数(带一定的业务功能)，完成一半的部分(&gt;4)，让 CodeWhisperer 完成剩下的部分(&lt;4)，下面展示结果</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/10/10950b27f9b396e9bed6c95c920fb09e.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3c/3c75818968ed522698b3f2c385b954eb.png\" /></p><p></p><p>最终的结果</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ff/ffb81c9080c4baa0d267ede1128174bb.png\" /></p><p></p><p>至此任务三测试完成，生成了基本可用的代码。</p><p></p><p>最后总结，CodeWhisperer 对于能够更快地编写代码还是有一定的帮助。</p><p></p><p>首先，在集成开源或者第三方不熟悉的代码库时，它可以为我节省大量的时间去学习和查阅 API 接口文档，让我能够专注于改进和测试。</p><p></p><p>其次，可以帮助我节省繁琐的重复性工作，如上面的 TCP Socket 处理。</p><p></p><p>当然，也期望可以后续可以生成整体代码段的方式，对于非复杂逻辑代码的场景其效率是更高的。</p><p></p><p>版权声明: 本文为 InfoQ 作者【Hanson】的原创文章。</p><p>原文链接:【<a href=\"https://xie.infoq.cn/article/386428468269729e334f2c134\">https://xie.infoq.cn/article/386428468269729e334f2c134</a>\"】。</p><p>本文遵守【CC BY-NC】协议，转载请保留原文出处及本版权声明。</p>",
    "publish_time": "2023-08-24 14:38:40",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "美团容器平台调度策略团队负责人陆启超确认出席 QCon 北京，分享从 0 到 1 构建集群服务质量运营体系降低云成本",
    "url": "https://www.infoq.cn/article/4vP8DAo4jUBUglb5IUQd",
    "summary": "<p>9 月 3 日 - 5 日，在<a href=\"https://qcon.infoq.cn/202309/beijing/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=0824&amp;utm_content=luqichao\"> QCon 全球软件开发大会（北京站）</a>\"上，美团容器平台调度策略团队负责人陆启超将发表题为《从 0 到 1 构建集群服务质量运营体系降低云成本》主题分享，介绍美团如何通过技术创新和产品优化等多重手段解决集群资源利用率提升和服务质量保障这一对集群运营矛盾统一体、集群服务质量运营体系（Quality-Cost Ops）、在 FinOps 落地实践中遇到的挑战，以及未来集群运营的演进方向。</p><p></p><p>陆启超，美团容器平台调度策略团队负责人。从事基础架构相关研发设计工作十余年，涉及分布式存储、集群调度等领域，主持设计开发多个大型目，在分布式系统设计、资源调度以及降本增效运营方面有丰富的经验。从业经历包括创业公司和互联网公司（京东），目前在美团负责容器平台的资源调度、资源利用率及服务质量运营工作。他在本次会议的演讲内容如下：</p><p></p><p>演讲：从 0 到 1 构建集群服务质量运营体系降低云成本</p><p></p><p>本次演讲主要介绍美团通过技术创新和产品优化等多重手段，解决了集群资源利用率提升和服务质量保障这一对集群运营矛盾统一体。通过在集群运营层面落实集群资源利用率运营，实现在不同场景下有效的做到资源利用率提升降低运营成本，同时又不影响业务的稳定性，通过体系化运营实现了为公司降本增效的目标。</p><p></p><p>演讲提纲：</p><p></p><p>资源利用率运营的难点与挑战美团的集群服务质量运营体系（Quality-Cost Ops）介绍FinOps 落地实践中的挑战未来演进方向</p><p></p><p>你将获得：</p><p></p><p>○ 集群服务质量运营一些新思路，如何持续在集群运营中资源利用率提升和服务质量保障的矛盾</p><p>○ 资源利用率提升和服务质量保障上具体的实践经验</p><p>○ 未来集群运营的思路和展望</p><p></p><p>除上述演讲外，QCon 北京还将围绕 <a href=\"https://qcon.infoq.cn/202309/beijing/track/1556?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10\">FinOps&nbsp;落地</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1570?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10\">云原生</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1567?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10\">AIGC&nbsp;浪潮下的研发效能提升</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1558?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10\">业务安全技术</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1552?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10\">面向&nbsp;AI&nbsp;的存储</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1557?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10\">从&nbsp;BI&nbsp;到&nbsp;BI+AI，新计算范式下的大数据平台</a>\"等进行分享。</p><p></p><p>130+ 名嘉宾、近 30 个精彩专题、8 种交流活动，QCon 北京 2023，相约 9 月！咨询购票请联系 18514549229（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/33/33cbbbf20baa8b2a18db4f0681f159aa.jpeg\" /></p><p></p>",
    "publish_time": "2023-08-24 15:10:21",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "DarazPrincipal Engineer Leader 冯湧，确认担任 FCon 基于大数据和 AI 的风控系统",
    "url": "https://www.infoq.cn/article/JaV436vlaoHP0WFUqzmF",
    "summary": "<p><a href=\"https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle\">FCon 全球金融科技大会</a>\"，将于 11 月在上海召开。DarazPrincipal Engineer Leader 冯湧将担任「<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1578?utm_source=infoqweb&amp;utm_medium=article\">基于大数据和 AI 的风控系统</a>\"」的专题出品人。在此次专题中，你将了解到如何利用机器学习、大数据模型，来提升数据在风控中的价值，以及对未来的发展展望。</p><p></p><p><a href=\"https://fcon.infoq.cn/2023/shanghai/track/1578?utm_source=infoqweb&amp;utm_medium=article\">冯湧</a>\"，从业 20 余年，目前担任 Daraz 的 Principal Engineer Leader，之前在 Shopee 担任风控团队负责人。在职业历程中，曾担任美团的信贷、支付研发团队和保险平台的研发团队的技术负责人，同时还兼任美团金服技术委员会的副主席。</p><p></p><p>个人专注于电商、供应链以及金融行业的系统设计与研发。技术领域涵盖金融和互联网行业的业务系统设计、风控系统设计，高可用架构设计，以及体系化的研发团队管理。此外，在各大公司任职期间内，也曾荣获了多项国家和公司相关专利。</p><p></p><p>相信冯湧的到来，可以帮助提升此专题的质量，让你了解到，黑产在数据收集方面已有较大优势，使得企业在风控对抗中面临挑战、实时更新风控规则对风险控制具有重要意义，如何运用机器学习和大数据模型提升数据在风控中的价值，和对未来发展的展望。</p><p></p><p>除上述专题外，FCon 上海还将围绕 <a href=\"https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle\">DevOps&nbsp;在金融企业落地实践</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle\">金融行业大模型应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle\">创新的金融科技应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle\">金融实时数据平台建设之路</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle\">金融安全风险管控</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle\">数据要素流通与数据合规</a>\"等专题进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，前 100 人可享 5 折特惠购票，咨询购票请联系：13269078023（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png\" /></p><p></p>",
    "publish_time": "2023-08-24 15:37:43",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "谷歌认真起来，就没OpenAI什么事了！创始人组队打造“杀手级”多模态AI模型",
    "url": "https://www.infoq.cn/article/jFYJRGB0rgH5prgwzAdE",
    "summary": "<p>截至目前，OpenAI大语言模型在AI竞赛中一直处于领先地位。而强劲优势的背后，离不开微软庞大数据中心基础设施的有力支持。但ChatGPT的主导地位恐怕无法长久持续下去，因为新的、更强大的AI模型正不断涌现，而其中最具战斗力的挑战者就来自谷歌。</p><p>&nbsp;</p><p>今年 4 月，Alphabet 首席执行官桑达尔·皮查伊 (Sundar Pichai) 迈出了不寻常的一步：合并两个具有不同文化和代码的大型人工智能团队（谷歌Brain和 DeepMind 团队），以赶上并超越 OpenAI 和其他竞争对手。</p><p>&nbsp;</p><p>现在，检验这个团队工作成果的时刻即将到来。有消息称，这支数百人组成的团队将在今年秋天发布一组大型机器学习模型Gemini，这是该公司有史以来构建的风险最高的产品之一。据参与 Gemini 开发的人士透露，这些模型统称为 Gemini，预计将使谷歌能够制造出竞争对手无法制造的产品。</p><p>&nbsp;</p><p>谷歌Gemini于今年5月在I/O开发者大会上首度亮相。</p><p>&nbsp;</p><p>当时，谷歌称Gemini为其下一代基础模型，它仍在训练中。Gemini 是从一开始就以多模式、高效的工具和 API 集成为目标而创建的，旨在支持未来的创新，例如内存和规划。经过微调和严格的安全测试后，Gemini 将提供各种尺寸和功能，就像 PaLM 2 一样。</p><p></p><h2>全世界都在关心的Gemini到底是个啥？</h2><p></p><p>早在 2016 年，DeepMind 就因其人工智能程序 AlphaGo 在复杂的围棋游戏中击败了一位冠军选手而成为头条新闻。快进到今天，DeepMind首席执行官Demis Hassabis透露，他的团队正在利用 AlphaGo 的变革性技术来创建 Gemini AI。Demis Hassabis透露，Gemini AI的开发成本估计为数亿美元，使用了数万颗谷歌的TPU AI芯片进行训练。</p><p>&nbsp;</p><p>据悉，Gemini AI是一个类似于ChatGPT的GPT-4的大规模语言模型。然而，Hassabis和他的团队更进一步，为 Gemini AI 注入了源自 AlphaGo 的解决问题能力和战略规划能力。</p><p>&nbsp;</p><p>从根本上讲，Gemini AI 包含下一代 AI 架构，有望取代 Google 当前的 AI 模型 PaLM 2。该模型目前支持 Google 的一系列 AI 服务，例如 Workspace 应用程序中广泛使用的 Duet AI 和流行的 Bard 聊天机器人。</p><p>&nbsp;</p><p>谷歌还放出消息，称Gemini将为旗下AI聊天机器人Bard，以及Google Docs、Slides等企业级应用提供支持。</p><p>&nbsp;</p><p>The Information报道称，谷歌并不是简单地与 ChatGPT 等产品竞争，而是打算超越一众大模型产品让友商们无法望其项背。消息人士指出，该公司专注于将大型语言模型 (LLM) 的文本功能与人工智能图像生成相结合，以创建多功能产品。这意味着 Gemini 不仅能够像 ChatGPT 那样生成文本，还能够创建上下文图像，但据报道，谷歌也在考虑添加其他功能。例如，用户最终可能能够使用 Gemini 通过语音分析流程图或控制软件。</p><p>&nbsp;</p><p>Gemini之所以能够成为强大的竞争对手，是因为谷歌同样掌握着雄厚的资源储备，特别是用于训练AI模型的宝贵数据。谷歌能够访问YouTube视频、谷歌图书、庞大的搜索索引以及Google Scholar上的学术资料。其中大部分数据为谷歌所独有，这也使其在构建顶尖AI模型方面占据着超越其他厂商的优势。</p><p>&nbsp;</p><p>那么，Gemini在训练中，具体都用到了哪些数据集？</p><p>&nbsp;</p><p></p><h3>Gemini用到了哪些数据集？</h3><p></p><p>&nbsp;</p><p>据悉，Gemini项目汲取了谷歌多个项目的数据集来训练大模型，包括了Google&nbsp;Piper monorepo、DeepMind&nbsp; MassiveText以及YouTube中的数据。</p><p>&nbsp;</p><p>来自 Google&nbsp;Piper monorepo的 Gemini 数据集（估计）</p><p>&nbsp;</p><p>Gemini 数据集可能由大量代码组成，以支持最终训练模型中的推理。Google 的内部 monorepo Piper 大小为 86TB 。使用 The Pile 的每字节 0.4412 个令牌的计算，该数据集将约为 37.9T 个令牌，或者大约是 GPT-4 中下一个最大数据集大小的两倍（估计）。</p><p>&nbsp;</p><p>来自DeepMind&nbsp;MassiveText的Gemini 数据集（估计）</p><p>&nbsp;</p><p>Gemini 数据集可能由 DeepMind 的一些MassiveText（多语言）&nbsp;5T 令牌数据集组成</p><p>请注意，下表是关于Gemini 数据集的猜测（未经 Google DeepMind 确认），并且基于来自最先进的 DeepMind MassiveText（多语言）+ 1,000B 讨论令牌的可用信息。MassiveText 包括网页、书籍、新闻和代码等文本，包含约 23.5 亿个文档， 10.5 TB 的文本量。</p><p></p><p></p><p>MassiveText 多语言数据集估计。</p><p>*四舍五入大概的数据以粗体显示（来自 DeepMind 的 MassiveText 多语言数据集），确定的数据以斜体显示。</p><p>&nbsp;</p><p>来自YouTube 的Gemini 数据集（估计）</p><p></p><blockquote>据一位知情人士透露，谷歌的研究人员一直在使用 YouTube 来开发其下一个大型语言模型 Gemini。</blockquote><p></p><p>&nbsp;</p><p>YouTube 2023 总体统计数据（来自<a href=\"https://www.wyzowl.com/youtube-stats/#:~:text=If%20we%20assume%20there%20are,videos%20in%20the%20mean%20time!\">Wyzowl</a>\"和<a href=\"https://www.statista.com/statistics/259477/hours-of-video-uploaded-to-youtube-every-minute/\">Statista</a>\"）：</p><p>视频总数：8 亿。平均长度：11.7 分钟。总时间：93.6亿分钟。四舍五入以跟上每小时上传 30,000 小时的速度：10B 分钟。</p><p>&nbsp;</p><p>YouTube 2023 文本统计数据：</p><p>人类说话速度：每分钟 150 个单词 (wpm)。150wpm x 10B 分钟 = 总计 1.5 万亿字。假设：(1) 说话仅出现在视频的子集中，(2) 质量分类器保留分数位于前 80% 的视频，那么我们保留其中的 80%。1.5T 字 x 0.8 = 1.2T 字。1.2T 单词 x 1.3 = 1.56T 文本标记。</p><p>&nbsp;</p><p>1.5T 文本令牌不足以大幅降低 Gemini 或 GPT-5 规模模型的要求：</p><p>1T 参数（20T 文本令牌）。2T 参数（40T 文本标记）。5T 参数（100T 文本令牌）。</p><p>&nbsp;</p><p>鉴于 2023-2024 年大型语言模型对多模态的关注，可以假设视觉内容（不仅仅是文本）正在用于训练这些模型。</p><p>&nbsp;</p><p>在将YouTube上的音频、视频数据注入Gemini数据集中后，Gemini模型就具有了多模态能力，比如，根据YouTube视频训练的模型，可以帮助需要的人根据视频解决一些实际动手问题。</p><p>&nbsp;</p><p>使用YouTube内容，还可以帮助谷歌开发更先进的文本转视频软件，根据用户想看的内容描述，自动生成详细的视频。</p><p>&nbsp;</p><p>Google DeepMind在 Piper（其 86TB monorepo）中的迭代代码上训练大模型（<a href=\"https://ai.googleblog.com/2023/05/large-sequence-models-for-software.html\">DIDACT</a>\"）。使用 The Pile 的每字节 0.4412 个令牌的计算，该数据集将约为37.9T个令牌，大约是GPT-4 中下一个最大数据集大小的两倍（预估）。这意味着训练Ge​​mini不会出现传闻中的数据匮乏的情况。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/13/130d20d6b9798aee8457a70301041bcf.png\" /></p><p></p><p>2023年最大数据集列表（截至2023年6月）</p><p>*四舍五入大概的数据以粗体显示，确定的数据以斜体显示。</p><p>&nbsp;</p><p>据称与GPT-4不同，Gemini将是首个能够同时处理视频、文本和图像的多模态模型。有报告表明，Gemini 接受的训练令牌数量是 GPT-4 的两倍，是 PaLM 2 的 10 倍。</p><p>&nbsp;</p><p></p><h3>Gemini+GPT-4等于AGI？</h3><p></p><p>&nbsp;</p><p>Google Gemini 是一种多模式工具和 API 集成，旨在将 GPT-4 等语言模型与 AlphaGo 中使用的技术相结合，以增强其能力，例如规划和解决问题。</p><p>&nbsp;</p><p>比如，目前GPT-4等大语言模型的缺陷主要体现在两方面：第一，是结果高度依赖训练语料，如果语料存在偏见或错误，那么大语言模型生成的结果也会是错误的；第二，是大语言模型可能会出现幻觉，给出完全不符合常识的错误信息，这主要是因为大语言模型只具备当前训练语料的知识，缺乏对真实世界全面而准确的理解。</p><p>&nbsp;</p><p>Gemini 作为先进的数学定理证明系统，与 GPT4 等大型语言模型相结合，有可能解决人工智能模型中搜索和规划的弱点，并生成新的定理。有专家预测，该模型可以在五年内达到 MMLU基准的 100分。</p><p>&nbsp;</p><p>谷歌在构建和训练大语言模型方面还有着深厚的人才池和多年实践经验。除了预计于明年秋季发布的新模型之外，谷歌还有意发布由Gemin驱动的新聊天机器人，或者借此升级现有Bard聊天机器人。照惯例来看，新模型应该会通过Google Cloud对外发布，这无疑会对谷歌的云业务产生深远的积极影响。</p><p>&nbsp;</p><p>Gemini在上月谷歌开发者大会上首度亮相时曾遭嘲笑，期间谷歌展示的几个AI项目也未受认可。</p><p>&nbsp;</p><p>谷歌称，Gemini项目的下一代AI模型最早将于今年秋季推出。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/90/902457246acfefc581a0518bfd9bb429.png\" /></p><p></p><p></p><h2>联合创始人谢尔盖·布林躬身入局，组建研发团队</h2><p></p><p>在将谷歌Brain和DeepMind两大AI部门合并时，掌门人皮查伊称是为了提高部门运作效率，将谷歌庞大的计算资源同DeepMind的研究技能结合起来。</p><p>&nbsp;</p><p>消息人士指出，谷歌大脑和 DeepMind 团队的几位前成员目前正在研究 Gemini。其中包括 Google 高级研究员 Paul Barham 和 DeepMind 的 Tom Hennigan，后者专注于 Gemini 的基础设施。然而，最引人注目的团队成员可能是谷歌联合创始人谢尔盖·布林 (Sergey Brin)。</p><p>&nbsp;</p><p>据报道，2022 年底，布林开始更频繁地进入谷歌办公室。在谷歌于 2022 年底因 OpenAI 失去研究人员后，人们认为布林正在专注于 Gemini 的招聘流程。现在，消息人士称，他在评估和训练 Gemini 模型方面发挥了重要作用。</p><p>&nbsp;</p><p>在此之前，两大部门也分别对ChatGPT做出了自己的回应。DeepMind这边有Goodall项目，使用了一种名为 Chipmunk 的未公开模型，另一部门则拿出基于Google Brain模型的Bard。尽管双方之间存在一定竞争，DeepMind还是决定放弃Goodall，转而在Gemini上携手合作。</p><p>&nbsp;</p><p></p><h2>ChatGPT的统治将就此终结？</h2><p></p><p>事实上，Google Brain和DeepMind的通力合作必然给OpenAI及其他竞争对手带来麻烦。当然，谷歌具体如何打造Gemini才是决定性因素。报道表明，Gemini在多模态能力方面取得了显著进步，切实超越了以往模型。其设计侧重于多模态，意味着它能够理解和处理多种不同形式数据，并在工具与API集成方面极为高效。</p><p>&nbsp;</p><p>具体来讲，Gemini不仅擅长理解和生成会话文本，而且精通处理多种其他输入，例如文本、图像和视频。另有报道表明，Gemini能够接收的token数量可达GPT-4的两倍，这应该能够支撑起更强的智能度优势。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/03/03fecb2854e12a089b5830332b939419.png\" /></p><p></p><p>随着生成式人工智能竞争格局的加剧，谷歌准备通过推出 Gemini AI 来展示其真正的能力。谷歌从匆忙引入Bard中汲取了宝贵的经验教训，决心确保无懈可击地进入市场。预计到 2030 年，生成式人工智能市场将达到 1093.7 亿美元，投资者和客户热情高涨，加剧了主导地位的争夺。谷歌着眼于彻底改变行业，已准备好释放 Gemini AI 的全部潜力，塑造文本分析人工智能解决方案的未来。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://indianexpress.com/article/technology/artificial-intelligence/google-gemini-ai-fall-launch-chatgpt-edge-8896455/lite/\">https://indianexpress.com/article/technology/artificial-intelligence/google-gemini-ai-fall-launch-chatgpt-edge-8896455/lite/</a>\"</p><p><a href=\"https://www.androidpolice.com/google-ai-gemini-chatbot/\">https://www.androidpolice.com/google-ai-gemini-chatbot/</a>\"</p><p><a href=\"https://www.theinformation.com/articles/the-forced-marriage-at-the-heart-of-googles-ai-race?irclickid=XepQ8kzcBxyPURYQqf1uq0VoUkF3jszhq2PuWY0&amp;irgwc=1&amp;utm_source=affiliate&amp;utm_medium=cpa&amp;utm_campaign=10078-Skimbit%20Ltd.&amp;utm_term=androidpolice.com\">https://www.theinformation.com/articles/the-forced-marriage-at-the-heart-of-googles-ai-race?irclickid=XepQ8kzcBxyPURYQqf1uq0VoUkF3jszhq2PuWY0&amp;irgwc=1&amp;utm_source=affiliate&amp;utm_medium=cpa&amp;utm_campaign=10078-Skimbit%20Ltd.&amp;utm_term=androidpolice.com</a>\"</p><p><a href=\"https://insights.daffodilsw.com/blog/google-gemini-algorithm-the-next-level-ai-model\">https://insights.daffodilsw.com/blog/google-gemini-algorithm-the-next-level-ai-model</a>\"</p><p><a href=\"https://lifearchitect.ai/gemini/\">https://lifearchitect.ai/gemini/</a>\"</p>",
    "publish_time": "2023-08-24 16:01:28",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AI安全成为新焦点，一文带你领略中国AI领域新变化，盘点40+细分领域技术成熟度",
    "url": "https://www.infoq.cn/article/cRwfD7F6xKwBJuji1UQS",
    "summary": "<p>2022年上半年，AI绘画等生成式AI的内容引发了人工智能领域的广泛关注，年底发布的ChatGPT更是迅速破圈，话题度和讨论度不断提升。这些变化的趋势也延续到了2023年上半年，人们讨论话题也向着大模型的实际应用逐渐深入，同时AI安全也展现了大家对技术突破的不同态度。</p><p>InfoQ研究中心此前发布的<a href=\"https://www.infoq.cn/minibook/UGhD7MTY5Z43JG5YmWP3\">《中国软件技术发展洞察和趋势预测研究报告2023》</a>\"，绘制了涵盖130+细分领域的中国技术成熟度评估曲线。作为年度趋势报告的延续，InfoQ研究中心基于2023年人工智能领域的种种变化，更新<a href=\"http://gk.link/a/128Px\">《2023&nbsp;中国人工智能领域技术成熟度模型报告》</a>\"。</p><p>同样，InfoQ研究中心也在三大核心指标（技术专利数量、技术发展时间、技术舆论指数）的基础上，参考了市场规模、融资事件等公开资料，并结合了AI行业内硬件、模型、应用不同领域的各位专家观点，绘制了包含40+技术点的中国人工智能技术成熟度模型。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0a/0affd338817e741dcaf474de3caca432.png\" /></p><p>备注：</p><p>1、技术专利相关数据来自国家知识产权局旗下专利检索及分析系统，检索时间为2023年8月15日。</p><p>2、技术发展时间使用知网论文库等学术平台进行相关技术领域论文最早收录年份统计计算。</p><p>3、技术舆论指数数据来源为各家技术媒体和开发者社区，包括InfoQ中文站和CSDN社区。</p><p></p><p>有关各发展阶段的具体特征，欢迎大家点击<a href=\"http://gk.link/a/128Px\">《2023&nbsp;中国人工智能领域技术成熟度模型报告》</a>\"进行完整报告下载。</p><p></p><p>中国人工智能技术成熟度三大核心指标气泡图</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/de/dea9d59bff8e1790664ef8ff12e944d2.png\" /></p><p></p><p>此外，在模型生成的过程中，我们也发现了一些有趣的现象，希望与各位读者共同探讨。</p><p></p><h3>对大模型的期待和应用现状出现短期错配</h3><p></p><p>这一方面是因为大众和用户对大模型充满了极大的热情与期待，另一方面，在经过了半年多的激烈讨论之后，大家的关注重点已经开始转向大模型的具体应用效果和由此带来的成本。简而言之，无论是C端还是B端，用户已经在期望成本可控下，体验到大模型和AIGC的卓越成效。</p><p>相比之下，现阶段众多大模型相关厂商之间的竞争，仍然属于「无」与「有」，即先推出产品再慢慢优化效果和降低落地成本。同时，现阶段的业务选择中，众多厂商聚焦于确定性高的场景，这也导致了现阶段大模型与AIGC领域的产品并没有建立各自的差异化优势。</p><p>这种短期错配，实际上带来了大模型各类厂商对于应用场景探索的焦虑与急迫性，本质上也限制了大模型潜力的充分释放。但归根到底，这是技术与业务之间的权衡。大模型各类厂商，无论是模型层还是最终的应用层，都需要贴合实际需求，充分展现产品价值，才能在激烈竞争中脱颖而出。</p><p></p><h3>AI安全的关注度迅速提升，如何安全地使用模型成为重点</h3><p></p><p>伴随着AI的应用范围逐渐拓宽，应用深度逐渐深入，AI在各行各业发挥的促进作用日益凸显。而AI越重要，对AI使用过程中的安全可信要求就越高，可信AI、可解释AI等正在成为AI落地的重要考虑因素。然而，目前数据投毒攻击、模型窃取攻击、噪音攻击等攻击方式正在严重威胁AI自身的安全，但相对应的防御手段与解决措施却未能及时更新。这意味着AI安全领域需要更多可用的工具，帮助企业建立有效的防护措施。</p><p>此外，AI大模型的出现也在一定程度上降低了网络攻击的技术门槛，给现有的网络安全工作带来了一定的冲击。</p><p></p><h3>技术难点与应用受限是限制技术发展的两大因素</h3><p></p><p>InfoQ研究中心在对舆论关键词的研究过程中发现，伴随着人工智能技术逐渐走向成熟，讨论重点也在逐渐从技术实现和风险伦理转向解决方案与产品标准。</p><p></p><p>不同发展阶段下的人工智能技术讨论重点词云变迁图</p><p><img src=\"https://static001.geekbang.org/infoq/32/32abe2144da94a441a1e21da3b6c2eaf.png\" /></p><p>除此以外，在报告中，InfoQ研究中心将限制技术走向成熟的因素总结为技术难点和应用受限。其中技术难点还包括硬件/资源限制和技术实现，应用受限包括应用场景探索、规模化经济、法律及伦理道德三点。</p><p>限制中国人工智能技术发展的两大因素</p><p><img src=\"https://static001.geekbang.org/infoq/02/0219c84ce8191c9b88395cf076f23a3d.png\" /></p><p>但这并不意味着是单一因素限制了技术的发展，在现实中通常存在多种因素相互作用。例如，汽车自动驾驶早期的探索重点一直是如何在技术上实现可行性，这时技术实现主要限制了汽车自动驾驶的发展。在后续发展过程中，乘用车还是商用车优先发展、先借助L2/L3实现盈利还是直接探索L4/L5，这些不同发展路线既包括了应用场景探索的思考，也包括了规模化经济，即落地成本的限制。但法律伦理贯穿汽车自动驾驶的整个发展过程。</p><p>同时，我们也需要理性思考这些限制性因素。当我们对于限制性因素的解决方案或者发展路线上达成了共识，这些限制性因素会反过来形成一种产品/技术标准，推动技术领域的发展。</p><p>InfoQ研究中心也期待中国人工智能技术领域能够实现更大的突破和应用，InfoQ研究中心将持续关注中国人工智能领域的各项最新动态，也欢迎各位读者与AI开发者一起探讨。</p><p>此外，在报告中我们还对40+人工智能及其细分技术领域绘制了企业图谱和名录，欢迎大家点击<a href=\"http://gk.link/a/128Px\">《2023&nbsp;中国人工智能领域技术成熟度模型报告》</a>\"下载完整报告。</p><p>中国人工智能技术厂商生态图谱</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/23/2302ffd63ff3292d1cc3341113694743.png\" /></p><p></p>",
    "publish_time": "2023-08-24 16:14:56",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]