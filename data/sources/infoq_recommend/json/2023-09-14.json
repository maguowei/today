[
  {
    "title": "Java 21：最新进展一览",
    "url": "https://www.infoq.cn/article/QB87kOkWjf6jXxODkd9T",
    "summary": "<p>Oracle Java平台组首席架构师<a href=\"https://www.linkedin.com/in/markreinhold\">Mark Reinhold</a>\"<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-August/008059.html\">宣布</a>\"<a href=\"https://openjdk.java.net/projects/jdk/20/\">JDK 21</a>\"（继<a href=\"https://www.infoq.com/news/2021/09/java17-released/\">JDK 17</a>\"之后的下一个长期支持(LTS)版本）已经进入初始发布候选阶段。主线源码库（在2023年6月初（Rampdown Phase One）fork到JDK<a href=\"https://github.com/openjdk/jdk21\">稳定代码库</a>\"） 定义了JDK 21的特新集合。一些关键错误，如回归或严重的功能问题，可能得到了修复，但这些修复必须通过<a href=\"https://openjdk.java.net/jeps/3#Fix-Request-Process\">Fix-Request</a>\"流程审批。根据<a href=\"https://openjdk.org/projects/jdk/21/#Schedule\">发布时间表</a>\"， JDK 21将于2023年9月19日正式发布。</p><p>&nbsp;</p><p>最终确定的15个新特新按照<a href=\"https://openjdk.java.net/jeps/0\">JEP</a>\"的形式分为四类：核心Java库，Java语言规范，HotSpot和安全库。</p><p>&nbsp;</p><p>被归入为核心Java库的6个新特新：</p><p>&nbsp;</p><p>JEP 431：<a href=\"https://openjdk.org/jeps/431\">序列集合</a>\"JEP 442：<a href=\"https://openjdk.org/jeps/442\">外部函数和内存API(第三次预览)</a>\"JEP 444：<a href=\"https://openjdk.org/jeps/444\">虚拟线程</a>\"JEP 446：<a href=\"https://openjdk.org/jeps/446\">作用域值(预览)</a>\"JEP 448：<a href=\"https://openjdk.org/jeps/448\">Vector API(第六次孵化器)</a>\"JEP 453：<a href=\"https://openjdk.org/jeps/453\">结构化并发(预览)</a>\"</p><p>&nbsp;</p><p>被归入Java语言规范的5个新特性：</p><p>&nbsp;</p><p>JEP 430：<a href=\"https://openjdk.org/jeps/430\">字符串模板(预览)</a>\"JEP 440：<a href=\"https://openjdk.org/jeps/440\">记录模式</a>\"JEP 441：<a href=\"https://openjdk.org/jeps/441\">switch模式匹配</a>\"JEP 443：<a href=\"https://openjdk.org/jeps/443\">未命名模式和变量(预览)</a>\"JEP 445：<a href=\"https://openjdk.org/jeps/445\">未命名类和实例主方法(预览)</a>\"</p><p>&nbsp;</p><p>被归入HotSpot的3个新特性：</p><p>&nbsp;</p><p>JEP 439：<a href=\"https://openjdk.org/jeps/439\">分代ZGC</a>\"JEP 449：<a href=\"https://openjdk.org/jeps/449\">弃用Windows 32位x86移植</a>\"JEP 451：<a href=\"https://openjdk.org/jeps/451\">准备禁止动态加载代理</a>\"</p><p>&nbsp;</p><p>最后，归入安全库的1个新特性：</p><p>&nbsp;</p><p>JEP 452：<a href=\"https://openjdk.org/jeps/452\">密钥封装机制API</a>\"</p><p>&nbsp;</p><p>值得注意的是，JEP 404（<a href=\"https://openjdk.org/jeps/404\">分代Shenandoah(实验特性)</a>\"），最初是针对JDK 21的）已正式从JDK 21的最终特性集中<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-June/007959.html\">移除</a>\"。这是由于“在审查过程中发现了确定性的风险，并且没有足够的时间来进行针对大量代码改动所需的评审。”Shenandoah团队决定“尽他们所能提供最好的分代Shenandoah”，并将JDK 22作为发布目标。</p><p>&nbsp;</p><p>我们研究了其中的一些新特性，以及它们所属的4个主要Java项目——<a href=\"https://openjdk.java.net/projects/amber/\">Amber</a>\"、<a href=\"https://wiki.openjdk.java.net/display/loom\">Loom</a>\"、<a href=\"https://openjdk.java.net/projects/panama/\">Panama</a>\"和<a href=\"https://openjdk.java.net/projects/valhalla/\">Valhalla</a>\"——这些项目旨在孵化一系列组件，并最终包含在JDK中。</p><p>&nbsp;</p><p></p><h4>Project Amber</h4><p></p><p>&nbsp;</p><p>JEP 445（<a href=\"https://openjdk.org/jeps/445\">未命名类和实例主方法(预览版)</a>\"），也就是之前的_灵活的主方法和匿名主类(预览)_和_隐式类和增强的主方法(预览)_，提议“让新手可以很容易地编写他们的第一个Java程序，而无需知道那些为大型程序而设计的语言特性。”Oracle Java语言架构师<a href=\"https://www.linkedin.com/in/briangoetz/\">Brian Goetz</a>\"在2022年9月撰写了博文<a href=\"https://openjdk.org/projects/amber/design-notes/on-ramp\">Paving the on-ramp</a>\"进一步推进了这一JEP。Oracle技术咨询委员会成员<a href=\"https://www.linkedin.com/in/gavin-bierman-a0173075/\">Gavin Bierman</a>\"已<a href=\"https://mail.openjdk.org/pipermail/amber-dev/2023-May/008065.html\">发布</a>\"<a href=\"https://cr.openjdk.org/~gbierman/jep445/jep445-20230502/specs/unnamed-classes-instance-main-methods-jls.html\">规范文档</a>\"初稿，供Java社区评审。关于JEP 445的更多细节可以在InfoQ的<a href=\"https://www.infoq.com/news/2023/05/beginner-friendly-java/\">报道</a>\"中找到。</p><p>&nbsp;</p><p>JEP 440（<a href=\"https://openjdk.org/jeps/440\">记录模式</a>\"）最终确定，并根据前两轮的<a href=\"https://openjdk.java.net/jeps/12\">预览</a>\"反馈进行了改进：在JDK 20中发布的JEP 432（<a href=\"https://openjdk.org/jeps/432\">记录模式(第二次预览)</a>\"）和在JDK 19中发布的EP 405（<a href=\"https://openjdk.org/jeps/405\">记录模式(预览)</a>\"）。这个特性通过_记录模式_来解构记录值。记录模式可以与_类型模式_结合使用，实现“强大的、声明式和可组合的数据导航和处理形式”。类型模式在switch中得到了进一步采用：在JDK 18中发布的JEP 420（<a href=\"https://openjdk.java.net/jeps/420\">switch模式匹配(第二次预览)</a>\"）和在JDK 17中发布的JEP 406（<a href=\"https://openjdk.java.net/jeps/406\">switch模式匹配(预览)</a>\"）。JEP 432最重要的变化是删除了对出现在增强的for语句头中的记录模式的支持。关于JEP 440的更多细节可以在InfoQ的<a href=\"https://www.infoq.com/news/2023/05/java-gets-boost-with-record/\">报道</a>\"中找到。</p><p>&nbsp;</p><p>JEP 430（<a href=\"https://openjdk.org/jeps/430\">字符串模板(预览)</a>\"）提出了用_字符串模版_（包含嵌入表达式的字符串字面量）来增强Java编程语言，这些表达式将在运行时进行验证和求值。关于JEP 430的更多细节可以在InfoQ的<a href=\"https://www.infoq.com/news/2023/04/java-gets-a-boost-with-string/\">报道</a>\"中找到。</p><p>&nbsp;</p><p></p><h4>Project Loom</h4><p></p><p>&nbsp;</p><p>JEP 453（<a href=\"https://openjdk.org/jeps/453\">结构化并发(预览)</a>\"）结合针对前两轮孵化的反馈：在JDK 19中发布的JEP 428（<a href=\"https://openjdk.org/jeps/428\">结构化并发(孵化器)</a>\"）和在JDK 20中发布的JEP 437（<a href=\"https://openjdk.org/jeps/437\">结构化并发(第二轮孵化器)</a>\"）。最新的重大变化包括：TaskHandle接口被重命名为<a href=\"https://cr.openjdk.org/~alanb/sc/api/java.base/java/util/concurrent/StructuredTaskScope.Subtask.html\">`Subtask`</a>\"；修复了handleccomplete()方法的通用签名；修改了取消子任务时的状态和行为；在<a href=\"https://cr.openjdk.org/~alanb/sc/api/jdk.management/com/sun/management/Threads.html\">`Threads`</a>\"类中定义了一个新的currentThreadEnclosingScopes()方法，该方法返回一个包含当前结构化上下文描述的字符串；<a href=\"https://download.java.net/java/early_access/loom/docs/api/jdk.incubator.concurrent/jdk/incubator/concurrent/StructuredTaskScope.html\">`StructuredTaskScope`</a>\"类的fork()方法返回一个Subtask（之前前的TaskHandle）实例而不是<a href=\"https://docs.oracle.com/en/java/javase/20/docs/api/java.base/java/util/concurrent/Future.html\">`Future`</a>\"，因为老的TaskHandle接口的get()方法被重构为行为与Future接口的resultNow()方法相同。关于JEP 453的更多细节可以在InfoQ的<a href=\"https://www.infoq.com/news/2023/06/structured-concurrency-jdk-21/\">报道</a>\"中找到。</p><p>&nbsp;</p><p>JEP 446（<a href=\"https://openjdk.org/jeps/446\">作用域值(预览)</a>\"），也就是之前的_扩展局部变量（孵化器）_，现在是JEP 429（<a href=\"https://openjdk.org/jeps/429\">作用域值(孵化器)</a>\"，在JDK 20中发布）之后的一个<a href=\"https://openjdk.org/jeps/12\">预览</a>\"特性。这个JEP建议在线程内部和线程之间共享不可变数据。这比线程局部变量更可取，特别是在使用大量虚拟线程时。</p><p>&nbsp;</p><p>JEP 444（<a href=\"https://openjdk.org/jeps/444\">虚拟线程</a>\"）根据前两轮的预览进行特新的确定：在JDK 20中发布的JEP 436（<a href=\"https://openjdk.org/jeps/436\">虚拟线程(第二次预览)</a>\"）和在JDK 19中发布的JEP 425（<a href=\"https://openjdk.org/jeps/425\">虚拟线程(预览)</a>\"）。该特性为Java平台提供虚拟线程，可以显著减少编写、维护、观察高吞吐量并发应用程序的工作量。来自JEP 436的最重要的变化是虚拟线程现在完全支持<a href=\"https://openjdk.org/jeps/8303683#Thread-local-variables\">线程局部变量</a>\"，取消了不使用这些变量的选项。关于JEP 444的更多细节可以在InfoQ的<a href=\"https://www.infoq.com/news/2023/04/virtual-threads-arrives-jdk21/\">报道</a>\"和Oracle Java平台组Java开发者布道师<a href=\"https://www.linkedin.com/in/jos%C3%A9-paumard-2458ba5/\">José Paumard</a>\"的<a href=\"https://inside.java/2022/06/08/jepcafe11/\">JEP Café</a>\"中找到。</p><p>&nbsp;</p><p></p><h4>Project Panama</h4><p></p><p>&nbsp;</p><p>JEP 448（<a href=\"https://openjdk.org/jeps/448\">Vector API(第六次孵化器)</a>\"）结合了对前五轮孵化反馈的增强：在JDK 20中发布的JEP 438（<a href=\"https://openjdk.org/jeps/438\">Vector API(第五次孵化器)</a>\"）、在JDK 19中发布的JEP 426（<a href=\"https://openjdk.org/jeps/426\">Vector API (第四次孵化器)</a>\"）、在JDK 18中发布的JEP 417（<a href=\"https://openjdk.java.net/jeps/417\">Vector API (第三次孵化器)</a>\"）、在JDK 17中发布的JEP 414（<a href=\"https://openjdk.java.net/jeps/414\">Vector API (第二次孵化器)</a>\"）、在JDK 16中作为<a href=\"https://openjdk.java.net/jeps/11\">孵化器模块</a>\"发布的JEP 338（<a href=\"https://openjdk.java.net/jeps/338\">Vector API (孵化器)</a>\"）。此功能建议增强Vector API，以便可以从外部函数和内存API定义的<a href=\"https://docs.oracle.com/en/java/javase/14/docs/api/jdk.incubator.foreign/jdk/incubator/foreign/MemorySegment.html\">`MemorySegment`</a>\"中加载和存储Vector。</p><p>&nbsp;</p><p>JEP 442（<a href=\"https://openjdk.org/jeps/442\">外部函数和内存API(第三次预览)</a>\"）基于之前的反馈进行了改进，并提供第三次预览：在JDK 20中发布的JEP 434（<a href=\"https://openjdk.org/jeps/434\">外部函数和内存API(第二次预览)</a>\"）、在JDK 19中发布的JEP 424（<a href=\"https://openjdk.org/jeps/424\">外部函数和内存API(预览)</a>\"），以及相关的孵化——在JDK 18中发布的JEP 419（<a href=\"https://openjdk.org/jeps/419\">外部函数和内存API(第二孵化器)</a>\"）和在JDK 17中发布的JEP 412（<a href=\"https://openjdk.org/jeps/412\">外部函数和内存API(孵化器)</a>\"）。这个特性为Java应用程序提供了一个API，可以通过有效地调用外部函数和安全地访问不受JVM管理的外部内存与Java运行时之外的代码和数据进行互操作。来自JEP 434的更新包括：在Arena接口中集中管理本地段的生命周期、增强的布局路径，使用新元素来解引用地址布局、移除VaList类。</p><p>&nbsp;</p><p>开发人员可能会有兴趣了解外部函数和内存API所带来的性能提升，这个API预计将成为JDK 22的最终特性。Oracle技术咨询委员会成员<a href=\"https://www.linkedin.com/in/minborg/\">Per-Åke Minborg</a>\"发表了一篇<a href=\"http://minborgsjavapot.blogspot.com/2023/08/java-22-panama-ffm-provides-massive.html\">博文</a>\"，他在文章中提供了一个关于字符串转换的基准测试，他使用这个API在JDK 21（JEP 442）和JDK 22（JEP Draft 8310626）中与旧的Java本地接口(JNI)调用进行了比较。</p><p>&nbsp;</p><p></p><h4>HotSpot</h4><p></p><p>&nbsp;</p><p>JEP 439（<a href=\"https://openjdk.org/jeps/439\">分代ZGC</a>\"）“通过扩展Z Garbage Collector(ZGC)来为年轻代和老年代象维护单独的代来提高应用程序性能”。这将使ZGC能够更频繁地回收早就成为垃圾的年轻代对象。”关于JEP 439的更多细节可以在InfoQ的<a href=\"https://www.infoq.com/news/2023/07/java-enhance-zgc/\">报道</a>\"中找到。</p><p>&nbsp;</p><p></p><h4>JDK 22</h4><p></p><p>&nbsp;</p><p>目前还没有针对计划于2024年3月发布的<a href=\"https://jdk.java.net/20/\">JDK 22</a>\"的JEP。然而，根据一些JEP候选和草案，特别是那些已经提交的，我们可以推测出哪些额外的JEP有可能包含在JDK 22中。</p><p>&nbsp;</p><p><a href=\"https://openjdk.org/projects/amber/\">Project Amber</a>\"的JEP 447（<a href=\"https://openjdk.org/jeps/447\">super()前置语句</a>\"）提议：允许构造函数中不引用正在创建的实例的语句出现在this()或super()调用之前，并保留现有的安全性和初始化保证。Oracle技术咨询委员会成员<a href=\"https://www.linkedin.com/in/gavin-bierman-a0173075/\">Gavin Bierman</a>\"提供了该JEP的<a href=\"https://cr.openjdk.org/~gbierman/jep447/jep447-20230420/specs/statements-before-super-jls.html\">初始规范</a>\"，供Java社区评审和反馈。</p><p>&nbsp;</p><p>JEP 435（<a href=\"https://openjdk.org/jeps/435\">异步堆栈跟踪虚拟机API</a>\"），一个特性JEP，提议定义一个有效的API，用于从包含Java和本地帧信息的信号处理程序获取异步调用跟踪信息。</p><p>&nbsp;</p><p>JEP 401（<a href=\"https://openjdk.org/jeps/401\">Null-Restricted值对象存储(预览)</a>\"，之前的_原始类(预览)_，属于Project Valhalla），引入了开发人员声明的原始类（Primitive Classes）——由值对象API定义的特殊类型的值类——它们定义了新的原始类型。</p><p>&nbsp;</p><p>JEP草案8307341（<a href=\"https://openjdk.org/jeps/8307341\">为限制JNI使用做准备</a>\"），提议限制使用不安全的Java本地接口(JNI)，并在外部函数和内存(FFM)API中使用受限制的方法，<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-August/008061.html\">这预计将成为JDK 22的最终特新</a>\"。从JDK 22开始，Java运行时将会显示关于使用JNI的警告，除非FFM用户通过命令行启用不安全的本地访问。预计在JDK 22之后的版本中，使用JNI将抛出异常而不是警告。</p><p>&nbsp;</p><p>JEP草案8310626（<a href=\"https://openjdk.org/jeps/8310626\">外部函数和内存API</a>\"），建议经过两轮孵化和三轮预览之后成为最终特新：在JDK 17中发布的JEP 412（<a href=\"https://openjdk.org/jeps/412\">外部函数和内存API(孵化器)</a>\"）、在JDK 18中发布的JEP 419（<a href=\"https://openjdk.org/jeps/419\">外部函数和内存API(第二孵化器)</a>\"）、在JDK 19中发布的EP 424（<a href=\"https://openjdk.org/jeps/424\">外部函数和内存API(预览)</a>\"）、在JDK 20中发布的JEP 434（<a href=\"https://openjdk.org/jeps/434\">外部函数和内存API(第二次预览)</a>\"），以及即将在JDK 21中发布的JEP 442（<a href=\"https://openjdk.org/jeps/442\">外部函数和内存API(第三预览版)</a>\"）。自上一个版本以来的改进包括：一个新的Enable-Native-Access MANIFEST属性，允许可执行JAR包中的代码调用受限制的方法，不需要使用——Enable-Native-Access标志；允许客户端以编程方式构建C函数描述符，避免使用特定于平台的常量；改进对本地内存可变长度数组的支持；本机字符串多字符集支持。</p><p>&nbsp;</p><p>JEP草案8288476（<a href=\"https://openjdk.org/jeps/8288476\">模式、instanceof和switch中的原始类型(预览)</a>\"），提议“允许在所有模式上下文中使用原始类型模式，将原始类型模式的语义与instanceof对齐，并允许将原始常量作为switch的case标签。”</p><p>&nbsp;</p><p>JEP草案8277163（<a href=\"https://openjdk.java.net/jeps/8277163\">值对象(预览)</a>\"），Project Valhalla的一个特性JEP，提议提供值对象——可以指定其实例行为的无标识值类。该草案与仍处于候选状态的JEP 401（<a href=\"https://openjdk.java.net/jeps/401\">原始类(预览)</a>\"）相关。</p><p>&nbsp;</p><p>JEP草案8313278（<a href=\"https://openjdk.org/jeps/8313278\">Java虚拟机的提前编译</a>\"），提议“让Java虚拟机加载编译成本地代码的Java应用程序和库，以实现更快的启动和基线执行。”</p><p>&nbsp;</p><p>JEP草案8312611（<a href=\"https://openjdk.org/jeps/8312611\">计算常量</a>\"），引入了_计算常量_的概念，持有不可变值，最多可被初始化一次。它具备final字段的性能和安全优势，同时在初始化时间方面提供了更大的灵活性。该特新将作为<a href=\"https://openjdk.org/jeps/12\">预览</a>\" API首次亮相。</p><p>&nbsp;</p><p>JEP草案8283227（<a href=\"https://openjdk.org/jeps/8283227\">JDK源代码结构</a>\"），一个信息类JEP，用于描述JDK源代码和JDK代码库中相关文件的总体布局和结构。该JEP建议帮助开发人员适应JEP 201（<a href=\"https://openjdk.java.net/jeps/201\">模块源代码</a>\"，在JDK 9中发布）所描述的源代码结构。</p><p>&nbsp;</p><p>JEP草案8280389（<a href=\"https://openjdk.org/jeps/8280389\">ClassFile API</a>\"），提议提供一个用于解析、生成和转换Java类文件的API。这个JEP最初将作为<a href=\"https://asm.ow2.io/\">ASM</a>\"（Java字节码操作和分析框架）的内部替代方案，并计划将其作为公共API开放出来。Java语言架构师<a href=\"https://www.linkedin.com/in/briangoetz\">Brian Goetz</a>\"称ASM为“带有大量遗留包袱的旧代码库”，并提供了关于该草案将如何演进并最终取代ASM的相关信息。</p><p>&nbsp;</p><p>JEP草案8278252（<a href=\"https://openjdk.org/jeps/8278252\">JDK打包和安装指南</a>\"，一个信息类JEP，提议为构建macOS、 Linux和Windows的JDK安装程序提供指南，以降低在安装不同JDK供应商提供的JDK时出现冲突的风险。其目的是通过形式化安装目录名称、包名称和可能导致冲突的其他元素，为安装JDK更新版本提供更好的体验。</p><p>&nbsp;</p><p>我们预计Oracle很快就会提供JDK 22将包含的JEP。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/09/java-21-so-far/\">https://www.infoq.com/news/2023/09/java-21-so-far/</a>\"</p>",
    "publish_time": "2023-09-14 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "支持几十种业务场景，字节跳动大规模 Sidecar 运维管理实践",
    "url": "https://www.infoq.cn/article/DZEY87Ntr7zNEfHhL8US",
    "summary": "<p>作者 &nbsp;| 字节跳动基础架构 / 服务框架团队研发工程师 - 刘立伟</p><p></p><p></p><blockquote>本文主要介绍了字节跳动 Sidecar 应用场景，以及进行 Sidecar 大规模版本升级的实践和总结。</blockquote><p></p><p></p><p></p><h2>字节 Sidecar 场景介绍</h2><p></p><p></p><p>Sidecar 是一种用于扩展应用程序功能的架构模式。在 Sidecar 架构中，应用程序主进程和一个或多个 Sidecar 进程运行在同一个计算节点中，例如 Pod、物理机等，Sidecar 进程与主进程保持相同的生命周期，为应用程序提供额外的功能支持，例如网络、安全、日志、监控等相关功能。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c6/c6c45ae79bf3d7758ced1e00efaf1339.png\" /></p><p></p><p>目前，在字节跳动的微服务架构下，有丰富的 Sidecar 应用场景，包括 Service Mesh、网关、风控、流量录制、业务安全等几十种业务场景 Sidecar，支持了抖音、飞书、基础架构等多个业务线 / 部门。</p><p></p><p>以下，对几个典型 Sidecar 应用场景进行介绍。</p><p></p><h3>Service Mesh</h3><p></p><p></p><p>在微服务体系下，RPC 框架是微服务之间通信的核心组件，RPC 框架支持了服务发现、流量调度、负载均衡、访问控制等复杂的服务治理功能。随着微服务规模变大，RPC 框架暴露出一些问题：</p><p></p><p>多语言成本高：服务使用的开发语言分散，包含 Go、Python、C++ 等多种语言，各语言 RPC 框架都要实现完备的服务治理功能，开发、维护成本很高；升级成本高：治理功能更新后，需要升级框架版本，但是推动业务升级成本很高，如果版本有 Bug 也难以收敛；</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/96/96bb8875f23d555ede187f4f3c0d40af.png\" /></p><p></p><p>Service Mesh 解决了上述问题，作为服务通信的基础设施，它实现了一个高性能多协议的数据面代理和一个灵活可扩展的控制面服务，RPC 框架复杂的治理功能下沉到了数据面，数据面以 Sidecar 的形式部署在服务实例中。</p><p></p><p>相比于传统的 RPC 框架，Service Mesh 优势如下：</p><p></p><p>多语言成本低：治理功能收敛到了数据面，各语言 RPC 框架轻量化，维护成本降低；升级成本低：治理功能更新后，只需要升级数据面 Sidecar，Sidecar 与业务代码不耦合，可以单独升级；</p><p></p><h3>分布式 API 网关</h3><p></p><p></p><p>API 网关（APIGateway）以 API 为核心，提供流量调度、稳定性策略、服务治理等全套解决方案。</p><p></p><p>API 网关最初的架构是中心化网关，一个网关集群为多个服务进行分流，存在一些痛点问题：</p><p></p><p>网关变更风险大：网关的逻辑变更发布一旦有问题，将会影响所有业务；业务故障隔离差：多个服务共用同一个网关集群，单服务出现问题可能影响其他服务；大促容量评估难：每年双 11、新春红包活动，上万 API 接口的 QPS 很难评估，不同 API 的 延时、QPS、BodySize 对于网关性能的影响都是不同的，为了网关入口的稳定性，只能大量的扩容；</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/cc/cc02edb67af8ab2fa518fe189a67cc2d.png\" /></p><p></p><p>API 网关团队将网关改造成 Sidecar 部署到服务实例中，实现了分布式网关，并通过 Sidecar 运维平台对分布式网关进行管理。</p><p></p><p>通过分布式网关方案，解决了上述痛点问题：</p><p></p><p>网关变更风险小：网关的更新操作，只影响被变更的服务，粒度可控；业务故障隔离强：不同服务相互隔离，出问题不会互相影响；无容量评估问题：网关部署在服务 Pod 内，服务自行承担成本，自行扩容；</p><p></p><p>除了上述优化，也有其他收益：</p><p></p><p>由于网关和 Service 通信由 RPC 改为了 IPC，延时收益明显，性能得到了提升。</p><p></p><h3>风控 Sidecar</h3><p></p><p></p><p>风控团队为业务提供 API 反爬取、反作弊支持，可以降低业务接口风险，加强 API 安全防护。</p><p></p><p>风控最初提供 SDK 接入方式，用户接入时，需要在业务代码中主动集成风控 SDK，存在以下痛点问题：</p><p></p><p>用户接入成本高：API 防护是基本的安全能力，有大量的 API 服务需接入，但是业务接入仍需修改代码，有一定的接入成本；多语言 SDK 维护成本高：API 服务使用的语言不一致，不同语言均需要实现 SDK，SDK 更新迭代成本高；升级迭代困难：SDK 和业务代码耦合在一起，SDK 升级时需要业务配合升级，版本迭代、问题收敛效率低；</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d4/d431b1712fddd9d024e70e1f2da1c53c.png\" /></p><p></p><p>为解决以上问题，风控团队和 Service Mesh 团队合作，借助 Sidecar 方案和 Service Mesh 的能力，设计开发了风控 Sidecar：</p><p></p><p>Mesh Proxy 与风控 Sidecar 通信进行 http 请求 / 应答的风控判断处理，Service 不感知风控逻辑；如果风控 Sidecar 拦截 http 请求，请求直接返回，Service 不会处理请求；</p><p></p><p>对比风控 SDK，通过风控 Sidecar 的方案，解决了上述痛点问题：</p><p></p><p>用户接入成本低：通过 Sidecar 运维平台动态注入 Sidecar，业务无感接入，接入成本低；无需维护多语言 SDK：风控逻辑收敛到 Sidecar，只需要迭代 Sidecar；升级迭代简单：风控逻辑更新，仅需升级 Sidecar，不用推动业务升级，升级节奏可控。</p><p></p><h3>MQ Sidecar</h3><p></p><p></p><p>消息队列 MQ 团队提供了 RocketMQ/BMQ 两种消息队列来处理在线、离线场景。为了满足业务接入，目前每种消息队列提供了多个语言的 SDK，存在一些问题：</p><p></p><p>多语言 SDK 维护成本高：功能很难对齐，MQ &nbsp;SDK 需要拓展流量治理、动态配置等能力，完善统一 Log、Metrics 逻辑，支持成本高；SDK 更新迭代速度慢：SDK 版本更新后，需要随业务代码发版，由于使用 MQ 的业务很多，业务发版速度很慢；</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/76/76eb239fa12620946292078184cf3919.png\" /></p><p></p><p>因此，MQ 团队引入 Sidecar 架构方案，实现了 MQ Sidecar：</p><p></p><p>MQ Sidecar 负责对接 MQ，流量治理等复杂逻辑收敛在 MQ Sidecar；保留 MQ SDK，SDK 只有基本 Produce/Consume 逻辑，接口保持一致，业务无需感知 Sidecar；</p><p></p><p>对比 MQ SDK，通过 MQ Sidecar 的方案，解决了上述痛点问题：</p><p></p><p>多语言 SDK 维护成本低：MQ SDK 只保留基本逻辑，更新频率低，减少维护成本；更新迭代速度快：MQ SDK 更新频率低，MQ Sidecar 更新频率高，但是 Sidecar 升级不受业务限制，升级速度快。</p><p></p><h2>Sidecar 架构的优势和挑战</h2><p></p><p></p><h3>优势</h3><p></p><p></p><p>综合对几个典型 Sidecar 应用场景的介绍，可以总结出 Sidecar 架构核心优势如下：</p><p></p><p>多语言维护成本低：业务逻辑收敛到 Sidecar，降低维护多语言 SDK 的成本；用户接入成本低：业务能力以 Sidecar 形式提供，用户可以无感接入，或者低成本接入；版本升级灵活可控：Sidecar 版本更新后，可以单独升级，支持有效的版本收敛、缺陷版本召回。</p><p></p><h3>挑战 - 升级运维</h3><p></p><p></p><p>从上述分析可以看出，Sidecar 架构的关键是 Sidecar 进程可以独立运行、单独升级，因此，只有支持 Sidecar 的升级运维能力，才能使 Sidecar 架构真正发挥出优势。然而，Sidecar 的升级运维面临严峻的挑战。</p><p></p><p>不同于传统的微服务升级，Sidecar &nbsp;升级场景更加复杂：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5e/5e6dd535e089cc1f2083a86a3378ca3f.png\" /></p><p></p><p>其中最关键的特点，Sidecar 升级面向的服务规模很大，以 Service Mesh Sidecar 举例，生产环境接入情况如下：</p><p></p><p>微服务数量超过 4W实例数量超过 400W</p><p></p><p>在如此大规模的场景下，在进行版本升级的时候，一些问题会被放大：</p><p></p><p>事故风险：不同于升级单个 / 少量服务，升级的服务覆盖面过广时，如果版本有缺陷且扩散到很多服务，可能导致严重的业务受损，甚至出现挂站风险；时间成本：由于服务数量过多，运维人员在进行升级时，需要进行灰度验证、灰度观察、全区域发布等操作，如果发现问题还要操作回滚、修复，这将耗费大量时间，可能影响迭代速度，也耗费大量人力；</p><p></p><h4>事故案例介绍</h4><p></p><p></p><p>以下是一个真实的事故案例，展示了一次 Service Mesh 升级导致业务故障的处理全过程：</p><p></p><p>开始：Mesh 团队操作升级，类型为热升级，升级了一批服务的小流量；业务报警：升级完成后，很快出现多个业务报警，包括 API 5xx、CPU 异常、MEM 异常报警；业务排查：业务开始排查，发现报错的都是小流量实例，怀疑是 Paas 平台异常或者流量调度问题，因此拉了 Paas 和 Mesh Oncall 进行排查；定位：Mesh 团队很快定位到是新版本问题，初步定位是新 feature 引入的 Bug 导致的 CPU 升高；处理：Mesh 团队操作热升级回滚，并对一些回滚失败的实例进行迁移解决；恢复：Mesh 版本回滚后，业务恢复正常；改进：Mesh 团队确认问题并修复，对后续发版流程进行了优化，完善了升级过程监控，加强了灰度验证流程。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7a/7aaaf2321599babe30d6eafb552f08fc.png\" /></p><p></p><p></p><h4>核心问题：稳定性 &amp; 效率</h4><p></p><p></p><p>在进行大规模 Sidecar 升级时，最核心的两个问题是稳定性和效率。</p><p></p><p>对于稳定性，主要关注业务故障风险：</p><p></p><p>新版本缺陷：新版本可能引入缺陷，比如逻辑 Bug、SDK 兼容问题等，导致业务发生故障；灰度验证有效性：升级新版本时，需要进行灰度验证，但是灰度验证不充分，导致没有发现问题；故障感知与处理：问题发生时，Sidecar 运维人员缺少报警没有及时感知到，并在继续升级的过程中，异常版本大范围扩散，导致回滚、止损成本高。</p><p></p><p></p><blockquote>历史上，Service Mesh 升级导致过 P0 事故，导致业务受损</blockquote><p></p><p></p><p>对于效率，主要关注时间、人力成本：</p><p></p><p>发布周期长：一个版本的发布周期可能很长，发布过程中，会出现多种情况影响发布速度，比如新 feature 随意插入、紧急 feature、缺陷修复等；耗费人力：发布过程中，会有多种原因导致人力耗费严重，比如发布周期长，自动化程度低导致灰度、升级、版本召回繁琐等。</p><p></p><p></p><blockquote>历史上，Service Mesh 进行 1 次大版本升级，历时 5 个月，期间多次 feature 插入、问题修复，共发了 25 个小版本才最终完成升级</blockquote><p></p><p></p><h2>Sidecar 大规模升级 - 思考</h2><p></p><p></p><p>如何设计一套可靠的 Sidecar 大规模升级方案？为应对稳定性和效率两个挑战，主要从变更安全和变更效率两个角度展开思考：</p><p></p><p>变更安全：确保升级过程是安全的，不会对业务造成稳定性影响；变更效率：尽可能缩短升级的时间，减少手工操作，降低人力成本。</p><p></p><h3>变更安全</h3><p></p><p></p><p>要保障升级过程的安全，必须树立对风险的正确意识：问题一定存在！</p><p></p><p>只不过，对于问题，存在已知问题和未知问题，对两种问题有不同的应对措施：</p><p></p><p>杜绝已知问题：对于已知问题，要有严密的机制防止其发生，比如：维护缺陷版本，拦截缺陷版本的升级，拒绝不该升级的服务；谨慎验证未知问题：保证版本验证流程的合理性，尽早的将问题暴露出来，防止扩散。</p><p></p><p>当然，总有问题不可避免的发生，此时需要积极应对已发生问题：</p><p></p><p>主动发现问题：要有主动检测、发现问题的手段，主动、尽早发现问题，缩短影响时间；阻断问题扩散：问题出现，要及时阻断，防止问题扩散面积过大；快速修复：要对问题快速修复，及时止损，比如快速回滚、修复版本快速覆盖等。</p><p></p><h3>变更效率</h3><p></p><p></p><p>为提升变更效率，首先，要完善变更规范：</p><p></p><p>加强准入限制：杜绝随意的 feature 插入，并保证合入的 feature 经过严格测试，防止出现 Bug 影响发布速度；</p><p></p><p>其次，通过技术手段，尽量加快升级速度：</p><p></p><p>自动化：提升灰度验证、逐步扩量、版本召回等流程的自动化水平，减少人的参与，减少人为导致问题的风险；安全加速：在有安全保证的前提下，合理的进行发布加速，提升速度。</p><p></p><h3>总结</h3><p></p><p></p><p>综上，对 Sidecar 大规模升级的思路进行总结：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/92/92c9221eb52d880fafb751f4493a3d0b.png\" /></p><p></p><p>在不同的升级阶段，综合多种策略保障变更安全和变更效率：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d4/d45d274200faf236267cf947e65dc4cf.png\" /></p><p></p><p>同时，最关键的，要将版本升级流程平台化，将上述策略固化在平台上。</p><p></p><h2>Sidecar 大规模升级 - 方案解析</h2><p></p><p></p><p>我们构建了一套 Sidecar 运维管理系统，在系统上落地了 Sidecar 大规模升级方案，本节对如何进行安全、高效的 Sidecar 大规模升级进行详细解析。</p><p></p><h3>运维管理系统</h3><p></p><p></p><p>Sidecar 运维管理系统提供了一套 Sidecar 应用运维管理解决方案，支持多种云环境下 Sidecar 标准化接入、安全运行、观测运维、版本治理等能力。</p><p></p><p>系统包含以下核心组件：</p><p></p><p>SidecarAgent：与业务进程部署在同一个实例中，负责管理 Sidecar 进程的生命周期，包括启动、升级、退出、异常处理等；SidecarManager：负责存储 Service 启用的 Sidecar 列表及版本信息，并下发给 SidecarAgent；Sidecar 运维平台：负责 Sidecar 运维管理，支持 Sidecar 元信息管理、启 / 停用、升级等运维能力，平台的升级计划功能支持 Sidecar 大规模升级。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d8/d86a161e69c5ccefc25eac2ca126a65f.png\" /></p><p></p><h3>方案总览</h3><p></p><p></p><p>以下为完整的升级方案总览：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/cc/cce3eb3c61223225342446fb95637fcc.png\" /></p><p></p><p>方案从升级的各个阶段入手，通过引入多项措施控制变更质量，保障变更安全，并在安全的基础上加速升级，提升变更效率。</p><p></p><p>在升级前，严格控制准入，包括：变更准入、版本准入、服务准入等策略。</p><p></p><p>在升级中，平台构建了灰度验证、逐步全量的自动化发布流程，可以谨慎的对版本进行验证，并且谨慎的将版本逐步全量。</p><p></p><p>在问题发生时，平台支持通过快速回滚、修复覆盖的流程，支持快速恢复，快速止损。</p><p></p><p>在升级后，支持版本治理，包括对长尾版本的收敛，以及在版本发现异常后，对版本进行快速的召回。</p><p></p><p>另外，在发布的整个流程中：</p><p></p><p>加强变更管控：平台对齐公司变更管控、封禁策略，杜绝在非可变更窗口进行升级，降低变更风险；主动检测异常：构建了异常检测机制，支持在升级中，对服务进行异常检测，在发现异常后，及时阻断升级。</p><p></p><p>以下，对升级流程中灰度验证、逐步全量和异常检测进行介绍，详细介绍如何将上述策略落地。</p><p></p><h3>升级流程</h3><p></p><p></p><h4>灰度验证</h4><p></p><p></p><p>灰度是逐步将新版本验证稳定、可靠的过程，要在灰度阶段尽可能的验证出问题，不要到全量阶段才暴露出问题，不然会导致更大面积的影响。</p><p></p><p>谨慎验证</p><p></p><p>首先，关于灰度覆盖面，要确保灰度验证的有效性，需要保证足够的覆盖面，这样才能验证到足够多的场景。</p><p></p><p>但是，如何保证足够的覆盖面，对于 Sidecar 新版本可能影响的服务，分为两类：</p><p></p><p>预期内受影响的服务：新版本的逻辑改动，对于预期内会受影响的服务，在升级时会明确关注；</p><p></p><p></p><blockquote>比如：新版本变更了负载均衡算法，升级时会明确关注服务的流量负载情况</blockquote><p></p><p></p><p>预期外受影响的服务：新版本的逻辑改动，意外的影响到了某些服务，这些服务不会被关注到。</p><p></p><p></p><blockquote>比如：一些历史逻辑受影响，或者有用户使用了非公开的特性</blockquote><p></p><p></p><p>但是，「预期外受影响的服务」是很难知道的，如果灰度覆盖不到这些服务，就无法保证灰度的有效性。为了简单起见，我们选择了大力出奇迹的做法，选择对所有服务进行灰度，这样就尽量保证了覆盖面。</p><p></p><p>其次，关于单服务灰度范围，字节的服务部署区分小流量、单机房、全流量的部署阶段，小流量阶段一般只部署少量的实例，业务升级服务时使用该阶段进行新版本验证，因此 Sidecar 也使用小流量阶段进行灰度验证。</p><p></p><p>另外，关于升级方式，要保证灰度版本快速生效，这样有问题才能尽快暴露出来，因此，我们选择使用热升级的方式，热升级后，服务使用的 Sidecar 版本可以立即更新。</p><p></p><p>最后，还构建了特征服务机制，Sidecar 的升级，可能会对特定服务产生影响，比如特定语言、框架、通信协议，或者使用了特殊配置的服务，因此，我们构建了特征集合，并对每种特征选取有代表性的服务集合，灰度验证时，首先对这些服务进行验证，并充分观察服务是否异常。</p><p></p><p></p><blockquote>比如：Service Mesh HTTP 压缩算法调整，影响到了配置特殊 HTTP 压缩算法的服务</blockquote><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/bd/bdbb5ef2ec256a0ce0a087daa93955b0.png\" /></p><p></p><p>防扩散</p><p></p><p>在灰度阶段，要将问题尽早的暴露出来，并防止问题扩散，其中有两个关键点：</p><p></p><p>防扩散到全量阶段：在灰度阶段，将问题验证出来，并及时阻断后续升级流程；防扩散到过大灰度范围：因为要灰度覆盖所有服务，即便是在灰度阶段，出现问题后，也要避免影响过多服务，将业务影响降到最低。</p><p></p><p>为达成防扩散的目标，设计实现了以下方案：</p><p></p><p>首先，控制升级顺序，保障：</p><p></p><p>服务敏感 / 重要程度：不敏感 / 不重要 -&gt; 敏感 / 重要升级后观察充分程度：观察充分 -&gt; 观察不充分</p><p></p><p>具体顺序如下：</p><p></p><p>服务等级：P2 -&gt; P1 -&gt; P0部署区域：线下 -&gt; 线上各区域部署环境：预览环境 -&gt; 生产环境服务分类：特征服务 -&gt; 全量服务</p><p></p><p>基于上述升级顺序，对全量服务进行顺序编排，然后逐步对服务进行灰度升级。</p><p></p><p>其次，控制升级节奏，要防止一次变更影响过多服务，控制好爆炸半径：</p><p></p><p>分批发布：对服务进行合理的批次划分，确定合适的分批间隔，逐个批次进行升级，目前平台支持指数分批、线性分批策略；</p><p></p><p>限制变更数量上限：限制好每批的变更数量上限，也限制好每天的变更数量上限。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/45/4502ba41fd0b500febea2d9775368d08.png\" /></p><p></p><p>分批发布 - 指数分批</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3e/3e9a46681d39ab80ad9921b58cd649dc.png\" /></p><p></p><p>分批发布 - 线性分批</p><p></p><p>最后，支持异常检测、异常阻断：</p><p></p><p>异常检测：在升级时，创建异常检测任务，对服务异常进行检测；异常阻断：如果检测到异常后，及时阻断升级，并通知用户，进行异常问题确认。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ae/aecbc74260b774dabfd1060bbe469c16.png\" /></p><p></p><p>检测到异常后的工单详情页面</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b8/b87f2855bd085ac4415e9b4d7dc4072b.png\" /></p><p></p><p>异常检测详情页面</p><p></p><p></p><h4>逐步全量</h4><p></p><p></p><p>灰度验证完成后，说明新版本已经基本稳定，可以开始全量的发布，但是，仍不排除有特殊问题没有暴露出来，因此，在全量的过程中，也要防范问题的发生。</p><p></p><p>全量阶段，主要目的是进行安全的铺量，在保证安全的前提下，将新版本逐步的升级到全量服务。</p><p></p><p>主要采用了以下策略：</p><p></p><p>安全升级</p><p></p><p>不同于灰度阶段使用热升级的方式，使用安全升级进行全量，安全升级不会让版本立即生效，而是配置好目标版本，跟随业务升级生效。使用安全升级，可以避免热升级可能导致的业务流量受损，并且服务在升级时，有服务负责人进行充分的稳定性观察，相比热升级安全很多。</p><p></p><p>控制顺序</p><p></p><p>和灰度验证类似，安全铺量阶段，也采用相同的升级顺序控制，确保先升级不敏感 / 不重要的服务，保障敏感 / 重要的服务。</p><p></p><p>控制节奏</p><p></p><p>和灰度验证类似，安全铺量阶段，也采用相同的升级节奏控制，进行分批升级，限制变更数量上限，控制好爆炸半径。</p><p></p><p>并行加速</p><p></p><p>由于升级的区域很多，为加速升级速度，对不同的区域进行合理的并行推进，加快推进速度。</p><p></p><h4>流程总结</h4><p></p><p></p><p>对升级流程进行总结，以下为一个升级流程的全貌，包括灰度阶段、全量阶段，以及，升级完成后的版本收敛阶段。</p><p></p><p>平台将这些流程、策略都固化下来，支持了大规模升级流水线，可以支持自动化的版本升级，保障变更安全，提升变更效率。</p><p></p><p></p><blockquote>以 Service Mesh 升级为例，各阶段大概耗时如下：灰度阶段 - 线下：5 个工作日灰度阶段 - 线上各区域：12 个工作日‍全量升级（线下 &amp; 线上）：11 个工作日</blockquote><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/2f/2f7f1e8eef591d10c3fcfac8e6f6504b.png\" /></p><p></p><h3>异常检测</h3><p></p><p></p><p>在 Sidecar 升级过程中，平台支持主动检测、主动发现异常，在出现问题后，平台可以及时的阻断异常，降低故障影响时间，减少业务损失。</p><p></p><p>Sidecar 升级过程中，如果新版本有问题，一般会导致 Sidecar 自身或者业务出现异常问题，比如：</p><p></p><p>Sidecar 异常：Sidecar 异常退出，Sidecar CPU、MEM 出现异常增长；服务异常：服务接口错误率升高、延时升高，调用下游错误率升高，实例 CPU、MEM 出现异常增长，甚至服务出现告警等。</p><p></p><p>这些问题一般能从指标、日志等方面检测出来，也可以从服务告警反映出异常。因此，我们可以对这些指标、日志、服务告警等进行检测，检测是否有异常发生。</p><p></p><p>我们和字节内部上线检测平台（Niffler）合作，构建了 Sidecar 检测模型，在升级过程中对服务、Sidecar 的异常进行检测，检测模型包含以下三类检测指标：</p><p></p><p>基座服务指标：检测服务是否出现进程退出 /Panic，CPU、MEM 占用上涨，接口成功率下降、延时上涨，错误日志增多，出现服务告警等；Sidecar 通用指标：检测 Sidecar 是否发生进程退出 /Panic，CPU、MEM &nbsp;占用上涨等；Sidecar 自定义指标：Sidecar 开发者可以配置自定义指标，检测这些指标是否出现异常。</p><p></p><h2>落地效果</h2><p></p><p></p><p>以 Service Mesh 为例，该大规模升级方案上线后，升级稳定性和效率都有明显收益：</p><p></p><p>在稳定性方面，很多问题在灰度验证时被及时发现，异常检测机制也检测、发现到很多异常，版本升级导致的事故数量、等级明显降低。</p><p></p><p>在升级效率方面，Service Mesh 发布一次大版本，小版本数量和发布耗时都明显下降：</p><p></p><p></p><blockquote>Service Mesh 在一个大版本的升级过程中，会发布小版本进行灰度、全量的全流程，如果小版本成功全量到所有服务，则完成大版本的升级。但是，在小版本发布过程中，如果有紧急 feature、问题修复，则需要重新发布新的小版本，一般要发布多个小版本，才能完成大版本升级。</blockquote><p></p><p></p><p>平均小版本数量：从 10+ 个降低到 8.6 个</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/87/8704f01912d14c64359433a37d60199e.png\" /></p><p></p><p>一次大版本发布，平均耗时：从 4+ 个月降低到 2.1 个月</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5e/5e2e8c821c6c4d7a18f17b495f7fb2f9.png\" /></p><p></p><h2>下一步计划</h2><p></p><p></p><p>1. 继续提升效率</p><p></p><p>目前，虽然大规模升级效率已经有了明显提升，但是由于字节跳动业务覆盖区域很多，平台缺乏多区域串联能力，目前操作所有区域的升级仍是一件繁琐的事情。因此，我们计划会进一步增强多区域升级的能力，降低多区域操作成本。</p><p></p><p>另外，为了解决升级过程中，如果发现版本缺陷，进行修复并重新升级，对升级速度影响过大的问题，我们也在探索更高效的小版本自动验证机制，进一步加快问题发现能力，加快升级速度。</p><p></p><p>2. 完善异常检测</p><p></p><p>目前，虽然支持了异常检测能力，但是当前的检测模型还比较简单，检测准确率有待提升，存在较多的误报、漏报。因此，我们后续会对检测模型进行进一步调优，提升准确率，以发挥异常检测的更多价值。</p><p></p><p>3. 加强版本收敛</p><p></p><p>目前，虽然设计了版本收敛阶段，但是平台对于版本收敛的功能支持并不好。有些 Sidecar 仍旧会存在比较多的长尾版本，并且如果出现缺陷版本，召回流程也比较繁琐。因此，我们后续会进一步加强版本收敛能力，支持更有效的长尾版本收敛、缺陷版本召回功能。</p><p></p>",
    "publish_time": "2023-09-14 10:27:54",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "实时双向同步：朴朴 Elasticsearch 双活自研实践与思考",
    "url": "https://www.infoq.cn/article/SS5ajVIjWGy1WWlXtkXT",
    "summary": "<p></p><h2>背景</h2><p></p><p></p><p>随着朴朴业务的快速增长，业务中断给公司的品牌、经济以及客户带来影响越来越大，因此业务对容灾的需求越来越迫切，要求在发生灾难时，业务能够快速恢复。显然当前公司采用的数据冷备的方式无法满足这个需求。出于公司长远规划考虑，核心业务需要具备地域级灾难的故障逃逸能力，确保在地域灾难发生时能够在分钟级内快速恢复业务，因此朴朴的双活建设被提上了议程。</p><p></p><p>双活建设包含应用双活建设和数据双活建设。数据双活是指两个数据中心都有完整数据，并且同时承担读写业务。这两个数据中心互为备份且实时同步数据，确保一个数据中心故障后，另一个数据中心可以快速接管业务。目前朴朴需要实现双活的业务数据散布在 MySql、Elasticsearch、Redis、Kafka 等等，要实现双活就要求两个数据中心中的各类数据都能够实时双向同步。不同数据双向同步的实现原理相近，本文主要以 Elasticsearch（之后简称 ES） 双向同步为例进行介绍。</p><p></p><h2>方案调研</h2><p></p><p></p><p>当前业内实现 ES 数据同步的方案主要有两种：</p><p></p><p>通过 ES 官方提供的铂金会员功能 CCR 进行同步;通过双写的方式确保两个数据中心的数据一致。</p><p></p><p>对于 ES 官方提供的 CCR 能够实现单个索引的单向同步，但不能实现单个索引的双向同步，因为其无法解决数据回环以及数据冲突的问题，并且 CCR 是铂金会员才能享有的，是需要收费的。</p><p></p><p>双写是目前比较通用的数据同步方式，双写可以是业务同步双写，也可以是通过 MQ 实现异步双写。业务同步双写是指业务写 ES 时需要同时往两个 ES 集群写入数据，两者都成功了才算写入成功。这种实现方式对业务的侵入性比较高，而且无法保障数据一致性。通过 MQ 实现异步双写的方式是业务不将数据写入 ES，而是将数据直接写入 MQ，然后由 MQ 消费者实现 ES 数据的写入。这种方案能够保障数据一致性，但是引入了 MQ 增加了系统复杂度，并且数据的延时变高。</p><p></p><p>通过以上分析可以看出常规方案都有明显的缺陷，不能满足预期的能够实现双向同步、业务侵入小且实时性又高的要求。那 ES 是否存在像 MySql 的 binlog 那般通过订阅就能够实时拉取到变更日志，然后在另一边进行回放从而达到数据同步效果的机制呢？</p><p></p><p>这当然也是有的，ES 有 translog 能够记录下变更信息，理论上通过监听消费 translog 的变更就能够实现数据同步。这个方案强依赖于 translog，translog 是会被删除的，如果某些数据还未被同步而 translog 文件已被删除，这就会造成数据丢失，从而导致两个集群数据不一致。在 ES 中，当 flush 操作执行完成之后， translog 就会被直接删除，而这个 flush 操作触发的影响因素较多，是不可控的，这意味着 translog 随时都可能被清除，如果用这种方案两个集群的数据一致性就没法保证，因此 translog 的方案也不太合适。</p><p></p><p>除了 translog，ES 从 6.7 版本开始，还提供了软删除机制（应该说是 Lucene 提供，为便于理解之后统一用 ES 描述）。软删除使得更新和删除操作在 merge 时不会被清除，它支持将 ES 的操作记录日志（operation）按照顺序排放，并以递增的 SeqNo 标记每个操作记录日志所处的位置。另一个集群只要监听并实时拉取该操作记录后再回放就能够实现数据实时同步了，同时通过记录 SeqNo 的点位，确保故障后能够断点续传，避免数据丢失。这些更新和删除操作会占用额外的存储空间，如果都不删除会导致资源浪费。这可以通过软删除 + 租约的方式，实现主动控制历史操作记录存放的时间，保障数据同步的同时也能及时清理已同步的历史记录，避免资源浪费。该方式虽然需要进行较大的源码改造，但是整体效果是能够满足预期的实时性高、业务侵入小并且能够实现双向同步的要求。</p><p></p><h2>方案设计</h2><p></p><p></p><h3>实现思路</h3><p></p><p></p><p>由于在数据双活建设过程中有多种数据类型需要实现双向同步，因此在设计之初就计划实现一个通用的数据传输服务，该服务通过实时拉取源的操作变更记录，然后到目标上进行回放从而实现数据同步，以 ES 数据同步为例，其流程如下图所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0d/0d862c5b6d4e0254f563ab87c4574762.png\" /></p><p></p><p>数据传输服务利用 ES 的软删除 + 租约的机制，定期从源集群中拉取操作变更记录。但 ES 的软删除机制是从 6.7 版本开始提供的，在 ES 6.x 版本软删除是默认关闭的，另外获取操作变更记录的接口在开源版本中也是没有的，这些都需要通过改动 ES 源码进行开放。</p><p></p><p>软删除开启后，每个索引的每个分片的操作变更记录（包含更新和删除）都会被按顺序保存下来，并且通过一个递增的 SeqNo 来标记各个变更记录对应的点位。如下图所示，数据传输服务中任务 1 负责拉取 index1 的 分片 1 数据然后再另一个集群进行回放。当前已经拉取到 SeqNo 为 13 的位置，也就是说数据传输服务上已经有 SeqNo 小于 14 的操作记录，只要将这些数据写到集群 2 进行回放就实现数据同步了。同理再起一个任务负责拉取集群 2 中该分片的操作变更记录，然后同步到集群 1 进行回放，这样就实现了分片的双向同步。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f3/f3a7ed08accbf223999732c378672f3a.png\" /></p><p></p><h3>整体框架</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5a/5ae66c03ca81c40c16c71124857c32cf.png\" /></p><p></p><p>上图是数据同步平台的系统框架图，主要分为管控层、通用层、数据仓库层以及存储层。其中管控层和通用层主要是负责配置、监控以及任务调度等。数据仓库层主要负责变更数据的抓取、转换、过滤和写入，也就是 ETL 流程，它整个数据同步的核心流程。数据同步平台的具体实现见下图，从图中可以看出数据同步平台在实现时主要分为两个部分：管控服务以及数据传输服务。管控服务实现管控层和通用层的功能，主要服务对象是管理员，为其提供操作以及查看相关的功能。而数据传输服务实现数据仓库层的功能，负责具体的数据同步操作。</p><p></p><p>前文也提到过不同数据源的同步原理基本都是一样的，都是拉取变更日志然后再另一端回放，只不过是具体的通信协议以及报文格式等有差异而已。所以数据传输服务采用的是微内核 + 插件化的架构，核心流程是共用的，要实现不同数据源的同步只需要实现对应插件即可。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d6/d63b5a25775278227efc3b99054ae396.png\" /></p><p></p><h3>核心设计点</h3><p></p><p></p><h4>数据完整性</h4><p></p><p></p><p>数据完整性主要指在故障恢复后不会丢数据，也不需要重新进行全量同步。这要求在设计过程中要考虑故障后的断点续传功能。ES 的数据同步主要是拉取历史操作记录然后进行回放来实现，历史操作记录是包含 SeqNo 的，这是一个递增的游标。为了保证数据完整性，数据传输服务在回放成功之后会及时将 SeqNo 记录到 MQ 中。当出现故障导致数据传输服务器意外退出时，数据传输服务器在启动后会自动从 MQ 中读取上次记录的最新点位，然后继续往后消费，从而保证故障后数据不丢失。</p><p></p><h4>数据冲突</h4><p></p><p></p><p>在进行双向同步时，由于两边数据源都可能对同一份数据进行改动，如果这个改动在同一时刻发生，就出现数据冲突。这里同一时刻的定义并非要求真正意义上时间点一致，而是指在 A 集群修改数据后在同步到 B 集群之前的这段时间内，B 集群如果也有对这条数据做改动，那么就算同一时刻。</p><p></p><p>数据冲突有可能会导致两边数据不一致，因为在数据冲突的时候，无法确定到底应该以哪条记录为准。目前处理数据数据冲突的方案有以下几种，可以根据场景选择某一种或者组合：</p><p></p><p>增加更新时间，以时间较新的数据覆盖旧数据（与时间字段精度和时间准度有关）；数据增加版本号，新版本覆盖旧版本；选取信任源，在出现冲突的时候，总是以信任源的数据为准；做字段同步而非记录同步，减少冲突发生（需要知道变更的字段）；将冲突的数据记录下来，锁定这条数据不让使用，并告警，需要人为介入。其它数据照常消费。</p><p></p><p>方案 1 中采用的是 Last write wins 的方式，通过这种方式，同一条记录的两个 update 语句不论执行顺序如何变化、不论执行多少次，他们执行后的结果是固定的，这个是满足 CRDT 语义的，能够保障数据最终一致性。但是方案 1 强依赖于更新时间，要求不同机器实例时间一致，并且每个同步的索引都需要具备更新时间字段，要求业务在更新数据时也同步更新该时间字段，这会加大业务的改造工作量。</p><p></p><p>方案 2 也能保障数据最终一致性，它是依赖于版本号，需要业务维护版本号，并且保证在分布式场景下这个版本号是递增的。这样增加了业务改造开发工作量以及增加业务复杂度，代价非常大。而方案 3 到 方案 5 虽然实现上比较简单，但是都有可能造成数据较大面积的错误或者是业务阻塞，数据的一致性无法保证。</p><p></p><p>通过以上方案对比，方案 3 、4、5 存在的问题对业务影响大，不予考虑。方案 1 和 方案 2 都能保证数据最终一致性，但相比于方案 2 ，方案 1 的实现难度更低，所以我们选用的方案 1 来解决数据冲突。针对方案 1 强依赖于更新时间的问题，通过 NTP 可以确保机器实例之间的时间误差在一定精度范围内。另外为了避免业务接入过程都需要改造，更新时间字段通过修改 ES 源码将时间字段内置并且主动更新，且该字段对业务无感，这样既能满足方案要求，也不影响业务。</p><p></p><p>数据回环</p><p></p><p>数据回环是指业务将数据写入到 DB1 之后会产生操作记录日志，数据传输服务通过拉取该操作记录日志将数据同步到 DB2。而数据被写入到 DB2 之后也会产生操作记录日志，该日志同样会被数据通过服务拉取并同步到 DB1，如此就形成回环，如下图所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f0/f0a41bdc558d7c2526f84bea98bf508a.png\" /></p><p></p><p>避免数据回环的方案就是要找到能够打断回环的点。如下图所示（图中 DTS 就是数据传输服务），我们采用的方案是数据传输服务在同步时为每条操作记录日志打上来源标识，数据传输服务在同步数据时通过判断该标识是否与目标数据源一致，如果一致就表示该记录是回环数据，应该直接丢弃，这样就避免回环问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fd/fd16bb5f7c1ec13faf648e0c04d121b2.png\" /></p><p></p><p>由数据回环示意图可以看出这个避免回环的来源标识需要落到 DB2 进行存储，这样数据传输服务才能从操作日志记录中拉取到该标识的信息。对于 ES 而已，这个打标可以考虑在索引的 _source 上增加回环标识字段，这样标识就跟着数据走了。但是删除操作时是没有 _source 字段的，因此删除操作需要独立处理，比如利用 ES 现有的元字段信息进行携带或者直接增加元字段。</p><p></p><h4>一致性校验</h4><p></p><p></p><p>尽管已经有对数据冲突进行处理，最终还是可能出现两个数据源的数据不一致的问题。因此还需要有额外的手段进行数据校验，当发现有数据不一致时，给出告警，然后人为介入处理。常用的数据校验方式可以有以下几种，可根据实际情况选择合适的方式进行实现：</p><p></p><p>全量检测。对于正在运行中的数据库实例，采用如截止到指定时间的所有历史数据对比。这种方式准确性高，但代价大；定期抽样检测。每次定期选取一小段时间同时计算两个数据源的数据量是否一致。这种方式代价小，但准确性不高；指定某个索引或者是指定时间段内的全量数据校验。这种方式准确性较高并且代价也相对较小，属于折中方案。</p><p></p><h2>上线问题与处理</h2><p></p><p></p><h3>ES 源集群 CPU 大幅上升</h3><p></p><p></p><p>ES 数据同步功能上线后，某个业务集群开启数据同步时，发现源集群的 CPU 有大幅提升。下面两张图分别是未开启数据同步的 CPU 使用率，以及开启数据同步的 CPU 使用率， 从图中可以看出 CPU 从 25% 直接被提升到 50%。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/20/20cea89b99ba91fbc12799d18d047460.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/00/00c1719c875e8335c5da5c41a8c47bef.png\" /></p><p></p><p>CPU 升高的主要原因是在每次拉取增量数据时，ES 都要将增量数据打成快照并同步给数据传输服务，这个过程是比较耗 cpu 的，高频度数据拉取会造成源集群 cpu 大幅上升。解决方案是通过限流降低拉取频率，同时增加每次拉取的数据量，虽然延迟上有毫秒级的升高，但 cpu 能够大幅降低，CPU 上升幅度控制在 10% 以内。</p><p></p><h3>大批量更新的场景下会出现更新阻塞</h3><p></p><p></p><p>线上某个业务集群在升级了 ES 版本为自研版本时，部分更新操作出现超时，从 prometheus 指标上看，索引写入时长出现突刺，最高写入延迟达到了 20s，指标如下图所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/80/80206c2db597a543e4f93b2e6f27aeb8.png\" /></p><p></p><p>通过查看指标发现该索引的 refresh 时间也出现大幅上升，如下图所示，并且 write 队列堆积比较严重。另外将版本降回开源版本后并继续以此压力写入，不会出现写入延迟问题，所以这个是自研版本中引入的变更引起的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8d/8d0c095ca6faf3e17766070a49049755.png\" /></p><p></p><p>当前我们使用的 ES 版本是 6.7，在开源版本中默认是不开启软删除的，而在自研版本中软删除被默认开启。我们怀疑是软删除引起写入延迟，便将自研版本的软删除关闭，发现问题确实就不出现了，表现与开源版本无异。之后在社区中也看到软删除开启后，在高频的 update 场景下会导致 refresh 耗时变长的问题。refresh 慢会导致 indexing buffer 的内存来不及 refresh 到磁盘中，当 indexWriter 大于 index_buffer_size 配置的阈值，Elasticsearch 会降低分片的写入速度。</p><p></p><p>这个问题应该算是 lucene 的 bug，lucene 在 8.5 版本中对其做了优化，并且其后的版本中也在持续优化。在不升级 ES 版本的情况下，通过合并 lucene 的优化改造能够缓解这个问题。</p><p></p><h2>总结与展望</h2><p></p><p></p><p>目前 ES 的双向同步建设已经取得了阶段性的进展，并且在部分业务的双活场景上成功落地。但是当前双向同步还只实现了增量同步，业务接入过程还需要 DBA 配合处理存量数据同步，接入双活的流程不够顺滑。因此接下来首先要实现存量数据同步，此外还会在接入流程以及配套辅助工具的建设上投入较大精力，从而降低业务接入和运维成本，助力朴朴双活建设顺利推进。</p>",
    "publish_time": "2023-09-14 10:47:08",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "平安科技数据智能部负责人及总工程师张茜，确认担任 FCon 金融数据治理专题出品人",
    "url": "https://www.infoq.cn/article/BIYAc62z90RiR7HNk1HI",
    "summary": "<p><a href=\"https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle\">FCon 全球金融科技大会</a>\"，将于 11 月在上海召开。平安科技数据智能部负责人及总工程师张茜将担任「<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1590?utm_source=infoqweb&amp;utm_medium=article\">金融数据治理</a>\"」的专题出品人。在此次专题中，你将了解到数据是企业的战略资产，数据治理能力强弱直接影响数据价值的释放，并学习到金融企业在数据治理方面的实践与经验。</p><p></p><p><a href=\"https://fcon.infoq.cn/2023/shanghai/track/1590?utm_source=infoqweb&amp;utm_medium=article\">张茜</a>\"，平安科技数据智能部负责人及总工程师，毕业于纽约大学，曾任美国高盛集团技术架构部 VP，美国私募对冲基金 Point72 市场数据智能部 VP。拥有近 15 年（包括 8 年海外）金融机构大数据领域的专业技术及团队管理经验，专注于大数据在金融领域的赋能和应用，尤其在企业数字化转型、数据驱动赋能业务增长、另类数据投研挖掘分析、流式计算及湖仓一体平台建设等方面有丰富的经验。</p><p></p><p>在平安科技任职期间，成功通过数据建设驱动和加速平安寿险及平安普惠等专业公司的数字化转型，通过构建统一指标体系、画像标签体系、客群挖掘分析及相关数据产品等，支撑业务的全面数字化经营、管理及运营。任职期间，获得 30 余项专利。</p><p></p><p>相信张茜的到来，可以帮助提升此专题的质量，让你了解到，数据治理是一个涉及企业战略、组织架构、数据标准、管理规范、执行落地、技术工具的综合体，同时也是企业数字化转型成功的前提与基石。</p><p></p><p>除上述专题外，FCon 上海还将围绕&nbsp;<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle\">DevOps&nbsp;在金融企业落地实践</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle\">金融行业大模型应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle\">创新的金融科技应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle\">金融实时数据平台建设之路</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle\">金融安全风险管控</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle\">数据要素流通与数据合规</a>\"等专题进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，前 100 人可享 5 折特惠购票，咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png\" /></p><p></p>",
    "publish_time": "2023-09-14 11:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "基于 ECS 倚天实例的大数据加速最佳实践",
    "url": "https://www.infoq.cn/article/5jthE49vdMOuuWohyLsl",
    "summary": "<p><img alt=\"\" src=\"https://static001.infoq.cn/resource/image/3b/a0/3b4511b7f8d02aed6d87f27a4f7b3ba0.png\" /></p>",
    "publish_time": "2023-09-14 14:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "《英特尔®️至强®️实战课》科学计算平台优化策略与产品技术分享",
    "url": "https://www.infoq.cn/article/JmbB4tQmQlBlmcwLyuC2",
    "summary": "<p>英特尔与领先技术媒体共同打造《英特尔®&nbsp;至强®&nbsp;实战课》系列课程，本次课程为重视基础科学研究并希望在科学计算平台上提升创新效率的高校和科研机构，分享具有启发性、易于复制和借鉴的英特尔®&nbsp;至强® CPU Max系列调优策略与方法，并展示包括英特尔® oneAPI中用于支持科学计算的软件工具在内的英特尔数据中心产品组合，为该领域的建设者和应用者输出前沿技术干货内容。</p><p>&nbsp;</p><p>在科学计算的高速发展和普及应用中，人们逐渐意识到其在基础科学研究中具有重要意义，可显著加速科研项目的研究速度，甚至颠覆传统科研范式。因此各大高校，尤其是研究型大学和科研机构纷纷加入到科学计算平台的建设与应用当中。但即便在相同的基础设施条件下，因应用优化程度不同，其在性能表现上也会产生较大波动，进一步影响前沿科技领域的研究效率。在这种情况下，高校和科研机构该如何升级和优化科学计算平台，以充分释放其在教学和科研中的应用潜力，并将之转化为创新潜能？</p><p>&nbsp;</p><p>《英特尔®&nbsp;至强®&nbsp;实战课》新一期课程惊喜上线！本期课程专家阵容强大，内容充实，特邀英特尔中国AI与基础设施技术专家陈江、英特尔中国GPU产品经理刘樱蕾、英特尔中国技术咨询工程师黄鹏，以“科学计算平台优化策略与产品技术分享”为主题展开交流与对话。届时，三位嘉宾将结合自身研究及项目实战经验，详细介绍英特尔®&nbsp;至强® GPU Max系列和包括英特尔® oneAPI在内的英特尔产品与技术组合对科学计算带来的诸多优势。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7f/7fdb76a5aad6baf2795fb044ce4c3c2a.jpeg\" /></p><p></p><p>精彩亮点：</p><p>英特尔®&nbsp;至强® CPU Max系列产品在实际应用中表现如何，调优后性能显著提升的原理是什么？英特尔® oneAPI中用于支持科学计算的软件工具都有哪些，可以如何应用它们？英特尔在科学计算领域提供了哪些产品组合，未来的发展路线是什么样的？</p><p>&nbsp;</p><p>如果您对本次课程涉及的英特尔产品感兴趣，<a href=\"https://www.intel.cn/content/www/cn/zh/high-performance-computing/overview.html#introtext_1439144442\">欢迎立即前往了解更多！</a>\"</p><p>&nbsp;</p><p>上线时间</p><p>上线时间：2023年9月20日&nbsp;14:00-15:40</p><p>&nbsp;</p><p>课程内容</p><p>课程分享：英特尔®&nbsp;至强® CPU Max系列产品简介及优化策略、方法和经验分享</p><p>陈江&nbsp;英特尔中国AI与基础设施技术专家</p><p>课程分享：英特尔计算产品组合的持续演进</p><p>刘樱蕾&nbsp;英特尔中国GPU产品经理</p><p>课程分享：oneAPI Industry Initiative &amp; Intel®&nbsp;oneAPI Tools</p><p>黄鹏&nbsp;英特尔中国技术咨询工程师</p><p>&nbsp;</p><p>点击观看完整视频<a href=\"https://s2.uao.so/bff6e619\">https://s2.uao.so/bff6e619</a>\"</p>",
    "publish_time": "2023-09-14 14:33:23",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "《英特尔®️至强®️实战课》英特尔平台上的行业AI实战与大模型优化",
    "url": "https://www.infoq.cn/article/0lxfNlbKZ8PjeRNIYa5k",
    "summary": "<p>英特尔与领先技术媒体共同打造《英特尔®&nbsp;至强®&nbsp;实战课》系列课程，旨在为物流和交通、医药、金融、制造和互联网等行业分享基于第四代英特尔®&nbsp;至强®&nbsp;可扩展处理器，以及英特尔Habana®️ Gaudi®️ 2等产品的AI实战用例、优化经验及方法，并期待这些技术干货内容能帮助各行各业的IT决策者、架构师和相关从业者加速推进自身的AI实践。</p><p>&nbsp;</p><p>伴随技术层面的快速变革与演进，人工智能（AI）的应用领域呈现出一浪叠一浪的态势。一方面，此前已成熟的AI应用开始步入真正的行业落地期，如何利用既有的、得到大规模部署和应用的英特尔®&nbsp;至强®&nbsp;平台来实现这些AI应用的加速，尤其是推理加速，成为它们部署和应用速度能否再上一层楼的关键。另一方面，新近崛起的大语言模型也引起了行业领先客户争先尝鲜的兴趣，它们又能否在英特尔® CPU平台实现优化，抑或在英特尔Habana®️ Gaudi®️2的深度学习特定加速能力支持下兼顾性能强大、成本更优，且易于使用的表现？</p><p>&nbsp;</p><p>《英特尔®&nbsp;至强®&nbsp;实战课》新一期课程将带来这些问题的答案！本期课程锁定“英特尔平台上的行业AI实战与大模型优化”主题，邀请英特尔交通行业高级技术顾问姚煜，英特尔人工智能架构师俞巍，与英特尔人工智能架构师杨威，深入探讨交通物流行业与医药行业的AI应用落地与优化实战；并特邀英特尔首席工程师、人工智能首席架构师夏磊，讲述经典的大语言模型如何在英特尔®&nbsp;平台上释放应用潜力并强化应用与数据的安全。这些专家还将结合相关核心场景中的实战用例、优化经验及方法，全面展示英特尔®&nbsp;至强®&nbsp;可扩展平台、英特尔®&nbsp;数据中心GPU及Habana®️ Gaudi®️ 2等英特尔AI产品技术组合的强大优势。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/00/0e/0033ecf80ff1fe4f648476950fe5760e.png\" /></p><p></p><p>精彩亮点：</p><p>至强® CPU、数据中心GPU及软件工具如何助智慧物流、智慧交通节支增效？至强®&nbsp;平台能为AI for Science“明星”——AlphaFold2带来哪些增益？至强® CPU与Gaudi®️2能为大语言模型的部署与性能加速带来哪些支持？英特尔®&nbsp;架构上有哪些易用且好用的大语言模型优化工具？又能如何强化其安全？</p><p>&nbsp;</p><p>如果您对本次课程涉及的英特尔产品感兴趣，<a href=\"https://www.intel.cn/content/www/cn/zh/artificial-intelligence/overview.html#introtext_ce0f_copy__1074325497\">欢迎立即前往了解更多！</a>\"</p><p>&nbsp;</p><p>上线时间</p><p>上线时间：2023年9月22日&nbsp;14:00-15:20</p><p>&nbsp;</p><p>课程内容</p><p>课程分享：英特尔中国物流与交通AI实战手册-趋势篇</p><p>姚煜 英特尔交通行业高级技术顾问</p><p>课程分享：英特尔中国物流与交通AI实战手册-实战篇</p><p>俞巍 英特尔人工智能架构师</p><p>课程分享：基于第四代至强®&nbsp;可扩展平台实现AlphaFold2端到端优化</p><p>杨威&nbsp;英特尔人工智能架构师</p><p>课程分享：在英特尔®&nbsp;平台上释放大语言模型应用潜力</p><p>夏磊 英特尔首席工程师、人工智能首席架构师</p><p>&nbsp;</p><p>点击观看完整视频<a href=\"https://s2.uao.so/d2ec320a\">https://s2.uao.so/d2ec320a</a>\"</p>",
    "publish_time": "2023-09-14 14:34:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "强制向开发者提AI建议再引公愤，GitHub：我知道你们很不满，但我不改",
    "url": "https://www.infoq.cn/article/peXzTWatkmx1lK8fXXi6",
    "summary": "<p>一周前，<a href=\"https://github.blog/changelog/\">GitHub 决定</a>\"将主页提要与算法建议整合在一起，此举很快激怒了这家微软放下代码托管平台的不少用户。</p><p>&nbsp;</p><p>本周二，GitHub对大家的愤怒做出了回应，称受到质疑的问题实际上是由bug造成，且目前已经修复完成。但其基本思路仍然不变，还是要把原本各自独立的“Following”和“For You”两类提要合并起来。</p><p>&nbsp;</p><p>其中，“Following”提要展示的是“您所关注的用户和代码仓库中的活动”。这部分内容由用户自行选定，代表大家真正感兴趣的代码和贡献者。而“For You”提要则是“基于您GitHub人脉网络的活动和建议”，也就是GitHub社交算法依据用户行为数据得出的推荐结果。</p><p></p><h2>执着变成“社交媒体算法”</h2><p></p><p>&nbsp;</p><p>根据官方声明，GitHub决定将二者合并一处是为了减轻服务器负担。该公司在帖子中解释道，“在我们于2023年9月6日发布最新版本的摘要功能时，我们对其底层技术进行了变更，旨在提高平台的整体性能。”</p><p>&nbsp;</p><p>“为此，我们移除了‘用户订阅代码仓库的push事件’功能。我们一直对功能调整抱以审慎态度，但随着GitHub社区的持续发展和体量增长，我们必须优先考虑平台的可用性、用户体验和性能。”除此之外，GitHub没有更多解释该调整会对平台性能带来怎样的影响。</p><p>&nbsp;</p><p>对于那些希望自定义的用户，GitHub表示增强了过滤控件，仅显示对用户最重要的事件类型，过滤项目包括：公告、版本、赞助商、星星、存储库、存储库活动、关注和推荐等类别。</p><p>&nbsp;</p><p>GitHub展示了新版本摘要功能，声称“新鲜且视觉上吸引人”，但网友并不买账：“这是一个非常糟糕的界面，而且没有用处。”有网友表示，页面上最有用的部分是“最近活动”，大约占屏幕显示的 10%，80% 的屏幕完全无用：这需要提要、最新更改和探索存储库。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/11/111319425fdb9db7e79c6f8d5080bf71.png\" /></p><p></p><p>GitHub新版本页面截屏</p><p>&nbsp;</p><p>相信关注Twitter的朋友对GitHub的这项操作不会陌生——马斯克接手之后，这家社交网络也改变了其“Home”时间线的默认算法设置，取消了按时间顺序排列的“Latest Tweets”最新推文选项。各位观望Twitter的吃瓜群众们，这下大棒也挥到自己头上了。</p><p>&nbsp;</p><p>有用户反馈称，GitHub删除了之前的提要，从而犯了一个错误。“在当前的 feed 中，无论你添加了多少个过滤器，我都找不到我感兴趣的信息。”</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/05/05e6bb3f0d8f101c234c8ceb79112640.png\" /></p><p></p><p>&nbsp;</p><p>这位用户向 GitHub 呼吁道，请停止接触那些不是非常必要的东西！帖子下面有大量开发者跟帖表示赞同。</p><p>&nbsp;</p><p>开发者“mjpitz”表示，“我的 GitHub 已经用了十多年了，我收到了我多年前注星标的项目/存储库的无用更新，我今天对它们不感兴趣。我知道我可以取消星标，但这需要做很多工作。由于这种转变，我真正关心的事情正在消失在这些‘噪音’中。”</p><p>&nbsp;</p><p>实际上，<a href=\"https://www.infoq.cn/article/gb4xb811mmyxkocgrjxo\">去年 GitHub</a>\" 刚上线“For you”功能时就遭到了开发者抗议。GitHub 声称，上线该功能的目的是为了让开发人员接触更广泛的受众并建立社区属性。但是开发者们担心这些推荐会把 GitHub 变成一个社交媒体平台。同时，这些开发者还提到，大家喜欢开源工具来增加数据隐私和透明度，算法推荐可能会导致数据收集和隐私的丢失，这与开源社区是不相符的。</p><p>&nbsp;</p><p>当时，就有不少开发者直言道，“我不需要看到推荐，也不需要看到我不关注的人的活动，GitHub 正在试图推出社交功能，但我们在这里是为了工作”、“请不要把 GitHub 变成 Facebook”、“请给我一个选项来完全禁用算法提要”。</p><p></p><h2>GitHub对问题避而不谈</h2><p></p><p>&nbsp;</p><p>大量用户要求GitHub恢复到原来的设置。但一年多过去了，GitHub看起来似乎并不在乎用户多么讨厌这套新的算法推荐系统和单方面设计变更：用户反对的理由没有变，GitHub的变更也一直在进行。</p><p>&nbsp;</p><p>在近200条直接评论中（此外相关讨论线程中也有声音），哥伦比亚开发平台BeeSoft Labs的创始人Bram Borggreve对此番未经预告的提要变更给出了有理有据的反对意见：</p><p>&nbsp;</p><p></p><blockquote>GitHub，请你倾听用户的反馈，保留按时间顺序排列的选项。就在昨天，这个选项还好好地摆在那里。&nbsp;大约10个月前你们曾做过类似的尝试，但实验失败了，可昨天你们又搞了一次。&nbsp;按时间顺序排列提要对很多用户来说意义重大，这能帮助我们发现新的代码仓库和需要关注的开发者，有助于顺利开发工作，因为用户可以看到谁给自己的代码仓库打了星。更重要的是，因为内容会按时间顺序排列，所以我们知道该从哪里开始浏览、哪些内容之前已经看过。&nbsp;新增算法推荐选项不是不好，甚至更符合某些用户的实际需求。但是拜托，别在更新的同时把好东西撤掉，按时间排序已经存在多年、而且实践也证明这是个效果很好的选项。&nbsp;我们没必要把一切都搞得像Twitter、Facebook或者Instagram那样。我们来GitHub是为了完成工作，而不是关注算法认为我们可能感兴趣的内容。</blockquote><p></p><p>&nbsp;</p><p>来自某IT基础设施管理软件开发商的一位工程师表示，“GitHub之前就做过类似的尝试，但被用户们抵制了。他们正在取消有用的功能，取而代之的则是垃圾般的社交媒体算法。GitHub似乎忘了人们来这里是为了做实际工作，而不是没完没了地浏览问题、pull请求和新的JavaScript框架。”</p><p>&nbsp;</p><p>但GitHub拒绝就此事发表评论，只是承认也许有些用户对新功能不太满意，并再次重申了新功能的发布说明。</p><p>&nbsp;</p><p>该公司指出，“我们理解，不少用户对最近的提要调整感到不满。我们应当更好地表述最近上线的变更、决策思路，以及我们与平台服务目标之间的关系。我们将不断发展并继续努力提供一流的开发者体验，帮助每位用户快乐高效地完成工作。您的持续反馈非常宝贵，也将引导我们的后续工作。”</p><p>&nbsp;</p><p>外媒The Register还向GitHub寻求相关数据，想要了解其关于旧版提要格式会影响平台性能的说法有无依据，但估计获得正面回应的可能性不大。</p><p>&nbsp;</p><p>目前，喜欢旧提要版本的开发者可以安装相应的user-script（<a href=\"https://github.com/Gerrit0/old-github-feed\">https://github.com/Gerrit0/old-github-feed</a>\"）或访问仍提供旧格式的GitHub页面（<a href=\"https://github.com/dashboard-feed\">https://github.com/dashboard-feed</a>\"）。当然，如果对GitHub的“倒行逆施”实在不满，也可以考虑转向其他代码托管平台。</p><p>&nbsp;</p><p>&nbsp;</p><p>相关链接：</p><p><a href=\"https://github.com/orgs/community/discussions/65343\">https://github.</a>\"<a href=\"https://github.com/orgs/community/discussions/65343\">c</a>\"<a href=\"https://github.com/orgs/community/discussions/65343\">o</a>\"<a href=\"https://github.com/orgs/community/discussions/65343\">m</a>\"<a href=\"https://github.com/orgs/community/discussions/65343\">/o</a>\"<a href=\"https://github.com/orgs/community/discussions/65343\">r</a>\"<a href=\"https://github.com/orgs/community/discussions/65343\">gs</a>\"<a href=\"https://github.com/orgs/community/discussions/65343\">/c</a>\"<a href=\"https://github.com/orgs/community/discussions/65343\">o</a>\"<a href=\"https://github.com/orgs/community/discussions/65343\">mm</a>\"<a href=\"https://github.com/orgs/community/discussions/65343\">u</a>\"<a href=\"https://github.com/orgs/community/discussions/65343\">n</a>\"<a href=\"https://github.com/orgs/community/discussions/65343\">it</a>\"<a href=\"https://github.com/orgs/community/discussions/65343\">y/</a>\"<a href=\"https://github.com/orgs/community/discussions/65343\">d</a>\"<a href=\"https://github.com/orgs/community/discussions/65343\">iscussions</a>\"<a href=\"https://github.com/orgs/community/discussions/65343\">/</a>\"<a href=\"https://github.com/orgs/community/discussions/65343\">65343</a>\"</p><p><a href=\"https://github.com/orgs/community/discussions/66244\">https://github.com/orgs/community/discussions/66244</a>\"</p><p><a href=\"https://www.theregister.com/2023/09/13/github_alienates_customers_by_force/\">https://www.theregister.com/2023/09/13/github_alienates_customers_by_force/</a>\"</p><p>&nbsp;</p>",
    "publish_time": "2023-09-14 14:39:45",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "天翼云存储资源盘活系统 HBlock，全面释放企业数据价值",
    "url": "https://www.infoq.cn/article/HOTjbXqI4WmFSuhVjUDa",
    "summary": "<p>近日，天翼云联合权威科技媒体 InfoQ 举办了以“存储难题新解法，揭秘极致易用的 HBlock”为主题的线上技术分享会”。天翼云国际业务事业部研发专家武志民与存储产品线总监魏玮参与了第二期分享，以“天翼云存储资源盘活系统 HBlock，深挖独创技术亮点与实战演练”为主题，讲解了 HBlock 在安装部署、数据可靠性和安全性保障、混沌测试与性能分析等方面的内容，本文将对其观点进行详细阐述。</p><p></p><h2>安装部署超易用，打造企业数据存储底座</h2><p></p><p></p><p>随着数字经济的蓬勃发展，数据作为核心生产要素，已成为数字经济发展的重要基石。与此同时，数据规模持续爆炸性增长，数据类型不断丰富，企业对数据处理与分析速度要求越来越高，带来了一系列存储的新挑战。</p><p></p><p>尽管市场上的分布式存储产品和解决方案层出不穷，但如何提高企业存储资源利用率，同时满足安全可靠、高性能、方便易用、降本增效等需求，是一件非常不容易的事情。在天翼云最新发布的存储资源盘活系统 HBlock 中，我们看到了分布式存储的全新“解题思路”。</p><p></p><p>作为天翼云自主研发的业内第一款全用户态的软件定义存储产品，HBlock 采用极简设计模式，相比于传统存储存在建设周期长、安装部署复杂、扩容难等问题，HBlock 安装包只有 170MB 左右，可安装在任何主流 Linux 操作系统上，不依赖于 NTP 服务器，3 个命令行完成安装部署，3 分钟即可建立数据中心级别集群，大幅降低安装部署门槛，同时可以按需扩容，为用户带来极佳的使用体验。</p><p></p><p>与传统存储软硬一体的模式不同，HBlock 对底层基础设施完全解耦，可以完美适配存量异构服务器环境，解决了硬件兼容性问题，可将 X86、ARM、龙芯等不同架构服务器上的存储资源进行统一管理，转换成高性能的虚拟存储阵列，通过标准 iSCSI 协议提供分布式块存储服务。</p><p></p><h2>高可用技术架构，保障企业数据安全</h2><p></p><p></p><p>通常，人们都认为传统集中式存储的软硬件结合模式才具有极高的可用性，HBlock 用出色的技术架构在纯软件上实现了令人刮目相看的高可用性。HBlock 基于 MPIO 的“一主多备”方案，故障场景下支持数据链路自动切换，集群中所有服务都采用冗余模式部署，数据处理过程不依赖任何时钟服务器，使用天翼云自研的分布式租约和心跳机制进行主备切换，从发生故障到故障发现，再到完成服务接管，整个过程几秒内就能完成。在切换过程中，分布式多控制器保证了两个缓存之间的数据是强一致的，确保数据不丢失。</p><p></p><p>针对不同容量、不同性能表现、不同负载的节点及磁盘组成的集群，数据应当如何分布，由 HBlock 的多因子权重算法来决定：针对空间总量、使用量、使用率的空间因子；针对读写并发数、内存、磁盘负载的负载因子；针对时延、带宽的网络因子。三种因子通过综合计算得出总体权重，用来确定数据存放的节点或磁盘，充分发挥各个部件的性能，同时可避免性能差、负载高的节点及磁盘成为性能瓶颈。</p><p></p><p>HBlock 还通过灵活的 QoS（Quality of Service，服务质量）特性来保障读写的服务质量。在空间和内存紧张时，会触发一个平滑的降速，同时在管理侧通过告警、系统事件、发邮件等方式通知管理员人为干预，这样可以避免存储资源耗尽导致业务突然中断的问题。HBlock 具有读写分离控制的机制，对于不同的资源，降速的请求是不一样的，空间紧张时降低写速度，内存紧张时同时降低读写速度。扩容后，由多因子权重算法决策平衡方案，负载向新节点倾斜，可灵活配置业务优先或数据恢复优先策略，满足不同需求场景。</p><p></p><p>HBlock 可以设置节点或磁盘级别的故障域，每个存储卷都可以选择纠删码或副本等不同的冗余方式。可以检测数据静默错误，保障数据完整性。另外，HBlock 是面向混沌环境的设计的，在各种弱电（电源不稳定、时钟抖动、CPU 降速）、弱盘（老化降速、读写失败）、弱网（网卡降速、丢包、错包）等情况下，通过分布式租约、实时感知故障、多因子空间分配、坏盘后快速重构等技术手段确保数据不丢。</p><p></p><h2>高性能实战表现，激活企业数据潜力</h2><p></p><p></p><p>HBlock 的存储性能表现优异，单卷 IOPS 可达 15 万次、读写延迟 200 微秒的性能表现完全能够胜任多种业务场景的性能需求，HBlock 支持 1024 节点弹性扩展和 PB 级存储资源池。HBlock 之所有具有如此出色的性能，要归功于领先的分布式多控制器架构和智能调度算法，通过多模式写缓存与读缓存的设计来实现高性能。</p><p></p><p>HBlock 具有 WriteBack、WriteThrough、WriteAround 三种写缓存模式，可以根据不同场景的读写需求来动态调整；同时，HBlock 会根据网络距离和节点负载选择最合适的节点，将数据放在缓存中，避免对磁盘频繁的小 IO 操作，更好地发挥存储介质的性能。</p><p></p><p>通过与开源 Ceph 的对比测试发现，在 1MB 大 IO、三副本读写的场景下，HBlock 读带宽 300 多 MB，写带宽 350 多 MB，是 Ceph 的 2 倍以上。随机读、随机写的带宽也是 Ceph 的 1 倍以上。用 4K 小 IO 进行读写，HBlock 性能表现有更突出的优势，单线程读写场景下 HBlock 的读、写、随机写性能均为是 Ceph 的 3-5 倍。即使是在 32 个并发的场景下，HBlock 的性能也是 Ceph 的 1-2 倍。而 EC 更是 HBlock 的优势领域，用 EC2+1 模式代替三副本模式，HBlock 的性能可以达到 Ceph 的 5 倍以上，在空间使用率方面，得盘率由 33.3% 翻倍，达到 66.7%，可在提升性能的同时显著降低存储成本。</p><p></p><h2>福利来了！HBlock 尝鲜活动震撼发布！</h2><p></p><p></p><p>为帮助更多政企客户高效、低成本搭建软件定义存储平台，天翼云推出了 HBlock 尝鲜活动，尝鲜期内用户将有机会免费使用 HBlock。活动规则如下：</p><p></p><p>报名时间：2023.8.21-2023.10.31</p><p>用户特权：尝鲜期报名且激活授权的用户，将获得上限 1PB、1024 节点的永久免费 License，欢迎企业客户、集成商伙伴踊跃报名！</p><p>特别说明：免费尝鲜版本为 HBlock 3.4，HBlock 支持 PB 级部署，用户需自行准备硬件设备，天翼云提供 HBlock 重大缺陷修复、邮件和电话咨询服务，但不提供产品新增功能，尝鲜期内报名未激活授权或尝鲜期后报名需正常付费。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/83/83b4606b961a73a4e06290bce6d015ad.png\" /></p><p></p><p></p>",
    "publish_time": "2023-09-14 14:45:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "云计算未来发展的“变”与“不变” | C位面对面",
    "url": "https://www.infoq.cn/article/L80Mkw2PcCuKs8cvw0xp",
    "summary": "<p>&nbsp;</p><p>9月3日，在<a href=\"https://qcon.infoq.cn/202309/beijing\">QCon全球软件开发大会</a>\"主会场，极客邦科技与阿里云认证正式宣发携手认证合作，举办了授牌仪式，共同致力于未来技术人才的发展。同时，阿里云CIO &amp; aliyun.com负责人蒋林泉与极客邦科技创始人&amp; CEO霍太稳也进行一次深入对话，讨论了影响企业数字化转型的人才问题，以及在AIGC浪潮下的云计算未来发展。</p><p>&nbsp;</p><p>本次谈话的主要亮点如下：</p><p>&nbsp;</p><p>云计算已经成为整个IT产业中不可或缺的一部分，成为基础设施的存在。云计算的发展趋势应该回归到其基本逻辑，即降低硬件和基础软件的使用门槛。AIGC本质上就像移动互联网和产业互联网，所有行业都值得使用新的技术栈来重新塑造自己。每次产业浪潮来临时的核心问题在于，谁做好了准备、谁没有准备好，那些没有做好准备的往往会被淘汰出局。真正稀缺的是那些能够理解现实业务问题、将其建模并选择最高效工具和语言来实现的人才。具备开放性和好奇心可以使开发者在技术领域走得更远。</p><p>&nbsp;</p><p>以下为对话内容，为了便于读者阅读，我们在不影响原意基础上做了调整和删减。</p><p>&nbsp;</p><p>Kevin：在QCon大会上，我和蒋总一起宣布了极客邦科技和阿里云重要合作的消息，这也标志着极客邦科技正式进入了认证业务领域。从您的角度看，认证的价值和好处是什么？对整个行业和云计算人才培养有影响吗？</p><p>&nbsp;</p><p>蒋林泉：云计算实际上是随着移动互联网的发展兴起的，像QCon大会也是紧随互联网发展创建的，这个浪潮已经持续了15年。互联网浪潮在发展到第七、八年的时候，产业互联网浪潮开始兴起，传统企业和行业开始意识到互联网的重要性。在国家政府的支持和鼓励下，大家积极配合，采纳了云计算等新技术实现数字化转型。</p><p>&nbsp;</p><p>实际上，我俩早先也讨论过一个问题：为什么我们以前没有展开认证合作？因为我们主要关注的是互联网行业。互联网行业是技术密集型的，自身技术能力较强，具备数字化转型的能力，因此相对不那么重视认证。</p><p>&nbsp;</p><p>但像金融和政企这些行业对安全合规和认证合规就有更多、更严格的要求。这一现象与行业特性及人才需求密切相关。信息技术不是这些行业的主要业务，因此他们在数字化转型时更依赖第三方公司，需要像极客邦科技和阿里云这样具有强大IT数字化产业能力的公司提供支持。</p><p>&nbsp;</p><p>在数字化转型过程中，人才培养和甄别筛选变得至关重要。在互联网产业兴起之前，微软认证、思科认证、Oracle认证等的出现是为了筛选出具备在大型企业内部进行关键管控工作所需的人才。现在，云计算技术能够提升更多领域企业的数字化转型能力。因此，这个阶段需要建立云计算的认证体系，来帮助广大企业完成类似的数字化转型过程。</p><p>&nbsp;</p><p>Kevin：我之前没有过多关注认证领域的原因是我们一直致力于服务企业业务，帮助传统企业进行数字化转型，但随着时间的推移，传统企业经常向我们询问是否有相关的认证标准。因此，我们决定为云计算和大数据等领域的人才开设认证课程。</p><p>&nbsp;</p><p>事实上，许多企业通常从学校直接招聘IT人才，并且进行大规模的招聘，如何有效地培养和评估人才是一个挑战，仅仅依赖项目经验来评估他们的能力并不高效。因此，认证对这些企业来说是必不可少的。我们现在已经正式成为阿里云认证的合作伙伴，大家也关注极客时间阿里云认证课程产品，探索感兴趣的ACP或ACE认证。</p><p></p><h3>云计算不变的发展逻辑</h3><p></p><p>&nbsp;</p><p>Kevin：阿里云在每个关键时刻都能够把握住行业的发展方向，你们设定技术战略时背后的逻辑和方法是什么？</p><p>&nbsp;</p><p>蒋林泉：我从业差不多20年了，时间回到2009年，当年发生了几件重要的事情。第一件是，中国的QCon大会首次举办，那是当时中国IT行业的重要事件。2009年QCon上，时任IBM中国CTO的毛新生与Rod Johnson进行了对话，Rod Johnson也进行了有关Java开源的演讲，还有一场VMware虚拟化支持云计算平台的演讲。</p><p>&nbsp;</p><p>我特别关注这个是因为我在做开源和企业软件领域的工作。我觉得2009年是一个分水岭，QCon里面大量出现云计算、开源、spring这些话题。那时，我在研发IBM的核心中间件WebSphere，有人认为它太庞大、太重、不够敏捷，但也有一堆人认为评价不够公允。回想这些评论，我认为2009年的时候，尽管大家已经看到了一些技术趋势，但开发者看的视角仍然受到了上个时代存留痕迹的影响。</p><p>&nbsp;</p><p>2009年另外一个重要事件是阿里云的成立。在第一年的员工大会上，王坚博士断言道，互联网已经成为一种基础设施，IDC将成为一台超级计算机，我们将为外部应用开发提供计算资源，使计算成为一种公共服务。</p><p>&nbsp;</p><p>在2009年，人们对云计算和虚拟化的评价不高。回过头看，我还是比较震撼的，因为整个云计算领域的核心逻辑就是阿里云的基因。但是在2009年QCon大会上，没有阿里云相关的话题。</p><p>&nbsp;</p><p>我认为，云计算的底层逻辑从第一天开始至今就没有发生变化，就是整个互联网改变了整个产业，即软件正在重新定义整个世界。本质上，它是通过互联网化的方式、通过PC和移动互联网来吞噬整个世界。但王坚博士的断言是，IDC将成为一台超级计算机，计算会成为一种公共服务。本质上，这一直是阿里云关注的核心问题，无论是基础IT支持还是中间件支持，它们都是支撑性的，应该像水和电一样易于获取。</p><p>&nbsp;</p><p>今年的QCon大会上，几乎50%以上的话题与AIGC有关。AIGC实质上就像移动互联网和产业互联网一样，所有行业都值得使用新的技术栈来重新塑造自己。这里唯一不变的是，IDC仍然是一台超级计算机，我们的目标是将支持AIGC的技术栈变成一种基础服务。云计算在今天已经成为整个IT产业中不可或缺的一部分，成为了基础设施的存在。</p><p>&nbsp;</p><p>Kevin：我们看到，国内外云计算厂商飞速增长的时代已经过去了，近期财报显示大家的收入增速都有所下降。云计算行业目前面临着什么样的挑战和阻力？大模型能否给云计算带来一些新的机会？</p><p>&nbsp;</p><p>蒋林泉：云计算本身是IT产业的基础设施，是服务性的底座，为企业的数字化创新提供工具。我们刚才讨论了前两轮推动云计算发展的因素，一是移动互联网，二是产业数字化。实际上，移动互联网和数字化改造仍在进行中，只不过现在的红利相对较小，覆盖范围较窄，这是我们面临的现状。</p><p>&nbsp;</p><p>但是企业数字化仍然是一件必须要做的事情，无论是那些已经进行数字化的行业，还是那些尚未数字化的行业。也就是说，现在很多行业仍然需要云计算来进行数字化。一方面，已经在进行数字化的行业需要新的技术来进一步推动数字化创新；另一方面，云计算的目标是降低数字化门槛，让那些原本没有能力进行数字化创新的企业也能够参与到数字化体系建设中。这实际上也是云计算的核心理念，即降低数字化的门槛。从这个角度看，如果云计算能够提高数字化的效率，帮助更多原本无法进行数字化创新的公司和企业，那么它就仍然是一种先进的生产力工具。</p><p>&nbsp;</p><p>目前，前两个浪潮的增长红利略有减缓，但新的AIGC浪潮让每个领域都有机会再次进行数字化创新。我认为，这仍然是整个行业，包括云计算在内的IT产业的最大机会。我对云计算的发展前景还是非常乐观的。</p><p>&nbsp;</p><p>Kevin：在阿里云北京峰会上你们发布了一个<a href=\"https://www.infoq.cn/article/1g335mw8VbQX2ioG3b8B\">免费试用计划</a>\"，5个月过去了，这个计划的进展如何？另外，最近国内云计算厂商似乎开始价格战，从你的角度来看，如何使这个行业更有序、更健康地发展？</p><p>&nbsp;</p><p>蒋林泉：其实免费试用计划和认证有些相似，可以看作是认证的前奏。我们的目标是让开发者在进行云计算认证之前，能够以非常低的门槛轻松获得云计算学习和使用的机会。我自己曾经加入开源社区进行开源软件开发，我意识到在开发者培养方面，社区是非常重要的，其中的一个关键点就是让开发者以极低的成本入门。从现有数据来看，我们已经达到了最初的预期目标。当初发布时有50多款云服务，现在已经超过100款了。</p><p>&nbsp;</p><p>当前阶段的挑战在于云计算厂商之间的价格战，价格不断下降。在我看来，IT产业的基本主旋律是摩尔定律，硬件成本和计算能力的成本就应该不断下降。如果云计算厂商不能持续降低价格来适应这一趋势，那么云计算就很难被视为先进的生产力工具。</p><p>&nbsp;</p><p>Kevin：实际上，我了解到像AWS从刚开始到现在已经降低了数百次价格，还在不断降价。</p><p>&nbsp;</p><p>蒋林泉：这背后包含了两个方面的红利。首先是我们依赖的整个硬件体系的红利，这个红利需要持续释放；其次是云计算体系规模效应以及后续的技术红利，包括资源调度、利用率优化等方面的红利，也可以释放出来。我们希望持续提高先进生产力的同时，确保成本低于其他方面，否则我们很难相信云计算是需要进行长期坚持的领域。</p><p>&nbsp;</p><p>Kevin：有人认为AI大模型可能会引发云计算行业的一场大洗牌，您对此有何看法？您认为未来五年云计算的发展趋势会是什么样的？</p><p>&nbsp;</p><p>蒋林泉：实际上，每次产业浪潮来临时，核心问题在于谁做好了准备、谁没有准备好，那些没有做好准备的往往会被淘汰出局。这次大家达成共识的速度是历史上最快的，带来了一次全面重写的机会，也是行业创新的机遇。因此，面对这个迅速到来的浪潮，准备充分就显得越来越重要。我坚信，那些没有准备好的云计算公司将会受到巨大挑战，而那些做好准备的公司将迎来机遇。</p><p>&nbsp;</p><p>谈到未来五年的云计算发展趋势，我认为需要回到云计算的基本逻辑。阿里是要活102年的公司，云计算我认为它有望在未来50年内持续发展。这是因为它一直在提高生产力，帮助社会降低运营成本、提高创新效率。</p><p>&nbsp;</p><p>从这个角度来看，云计算的发展趋势应该回归到其基本逻辑，即降低硬件和基础软件的门槛，不断推动创新。只要行业不断变化，我们就需要持续创新，这将有助于云计算的长期存在。与其说它有五年的趋势，不如说它是一个范式，会根据行业的潮流和需求不断进行调整。</p><p></p><h3>内部实测：大模型如何让开发者回归业务</h3><p></p><p>&nbsp;</p><p>Kevin：我听说公司把您CIO的工作比作在负责阿里云“内部经营管理操作系统”，这个比喻挺有意思的。那作为CIO，你在内部具体推动哪些工作？</p><p>&nbsp;</p><p>蒋林泉：CIO的工作之所以被称为第二个内部操作系统，是因为我们在阿里云已经有第一个操作系统，即飞天云计算操作系统，“飞天”系统主要是面向外部的。而第二个操作系统则是面向内部的，它是阿里云内部的一种组织和业务设计。我的任务是通过系统化的方式将这个组织设计与业务设计关联起来，以便更好地运作。</p><p>&nbsp;</p><p>阿里云与其他互联网公司不同之处在于，它既服务开发者和互联网领域，又服务大型企业，还要管理自有的IDC等硬件资产。这使得阿里云的业务更加复杂，需要处理更长的价值链，包括产、销、服、供等多个环节。因此，阿里云需要创建一个“内部操作系统”，确保各个领域之间的协同工作。这是一项非常有趣的挑战。</p><p>&nbsp;</p><p>互联网企业在数字化转型和创新方面通常表现出色，阿里云的各个分支和团队内部的数字化转型都很成功。但由于它们各自的能力强大，当整体需要协同合作时，它们往往比整体发展得更快。因此，我们需要重新协调和补充一些原本不够适应业务需求的系统，以确保整体运作顺畅。</p><p>&nbsp;</p><p>Kevin：我记得原来你说过，“云计算的故事就是云计算永远能让开发者回归到业务本身”，能不能解释一下这句话背后的含义。</p><p>&nbsp;</p><p>蒋林泉：我最近对这个问题的认知更加深刻。正如大家谈到的，大模型已经成为整个行业的共识，我们也不例外。</p><p>&nbsp;</p><p>我们在几个领域里做了些AIGC方面的创新工作。首先，我们关注内部效率的提升，比如如何更高效地处理文档和设计。此外，我们还着手提升阿里云的服务，包括开发一个aliyun.com的聊天机器人（chatbot），让客户通过聊天的方式高效地获取知识和问题的答案。</p><p>&nbsp;</p><p>后来，我发现不止我们一个部门在进行这项工作，几乎每个团队都有两三名成员参与探索。我提出，我们可以选择在合适的时机分别发布一个相对出色的版本，以便形成协同作用。然而令我惊讶的是，这几位同事竟然推出了三四个版本，而且每个版本看起来都很出色。</p><p>&nbsp;</p><p>这几位同事都在使用我们的云产品，包括矢量数据库、OpenSearch和分析数据库中的矢量版本。我们拥有一套强大的训练和线上部署方法，包括数据清洗和SFT等。在此基础上，这几位同事的工作都非常出色，差距几乎可以忽略不计。</p><p>&nbsp;</p><p>那么，他们竞争的关键点是什么呢？首先是对业务内容数据的清洗能力是否出色；其次是对外提供服务的深入理解；最后是他们对这些内容的后续运营体系做得是否出色。比如，to B业务方面，我不能允许它生成虚假的知识，否则将导致严重问题，因此重点是在理解知识和做知识摘要方面。</p><p>&nbsp;</p><p>在这个领域，大家明显的差异在于认知，这种认知不是对工具的认知，而是对业务的认知。有些问题需要经过SFT的训练才能将QA列表喂入模型中，我们有一个团队就积累了大量为客户提供服务的问题与答案（QA）。团队对业务越了解，就会越擅长准备QA。</p><p>&nbsp;</p><p>总的来说，这一轮内部竞赛，成本相对较低、时间也很短，各团队在内容运营和业务理解方面迅速达成了共识。</p><p>&nbsp;</p><p>这告诉我们一个重要事实：工具和云计算达到一定水平时，就能够促进业务的创新，使企业人力资源都集中在业务创新上。反之，如果没有云计算体系支持，当完成所有这些工作时，其他人可能早已上线运营了。</p><p>&nbsp;</p><p>Kevin：可以把原来花在技术方面的精力用来思考业务上怎么和技术相结合。</p><p>&nbsp;</p><p>蒋林泉：AIGC本质其实就是一个完整的产业链。从底层的硬件如英伟达芯片、到服务器，再到上层的软件，最终目标都是进行模型训练、推理以及与业务结合。云计算真正解决了底层上的重要问题，从而为上层进行业务创新提供了时间和机会。</p><p>&nbsp;</p><p>Kevin：在成为CIO之前，您一直负责阿里云弹性计算产品、业务运营、平台技术研发。您参与的哪个项目或者产品是您觉得最满意的？为什么？</p><p>&nbsp;</p><p>蒋林泉：事实上，我在阿里云做了许多不同岗位和项目，很难挑出一个最满意的项目，因为印象深刻的项目有很多，难以界定哪一个最令我满意。</p><p>&nbsp;</p><p>Kevin：那来说说您印象最深刻或者最不满意的项目吧。</p><p>&nbsp;</p><p>蒋林泉：说下我印象比较深刻的事儿吧。在我加入阿里云的第二年，大约是在2015年，由于一系列机缘巧合，我被安排担任阿里云国际化和单元化架构师，负责阿里云专有云技术体系从0到1的架构构建。那是我第一次负责中间件和PaaS的研发，跳出垂直领域，成为一个跨公司体系架构的负责人。这个职位需要与所有业务团队、云产品研发团队进行深入沟通，并根据业务目标制定整个架构方案，同时还需要获得业务和技术团队的支持。当时，我几乎没有团队可以依赖。</p><p>&nbsp;</p><p>这是一项需要大量协作的工作。如果方案不够好，别人也不会支持，如果沟通不够好，别人也不会支持。对我来说，那段时间是我职场上遇到的最大挑战之一，但也是最令我满意的项目之一。我从一个垂直领域扩展到了一个更大的横向领域，对整个云计算业务体系、架构体系以及阿里云内各个业务团队和核心技术产品团队有了更好的理解。那段痛苦的经历之后，后续的工作虽然也有挑战，但相对来说没有那么困难了。</p><p></p><h3>真正稀缺的人才是什么样的</h3><p></p><p>&nbsp;</p><p>Kevin：我记得两年前有份报告指出，云计算领域的人才缺口已经达到150万。现在云计算领域的人才供需情况是否发生了变化？为什么人们总是在谈论人才短缺的问题？</p><p>&nbsp;</p><p>蒋林泉：随着数字化转型的深入，许多原本没有涉足云计算领域的企业进入了这一行，这导致了人才供给不足的问题。云计算领域的人才供需问题不仅涉及互联网企业，还包括以前没有互联网技术背景的中小型企业。这一背景下，人才供给明显无法满足需求。</p><p>&nbsp;</p><p>不过，我们也看到国内从业者的规模和能力都有了显著提升。现在，不论是在开源软件领域还是云计算领域，开发者和用户的数量都在迅速增加。然而，从根本上来看，供给并没有跟上需求的增长速度，这才是导致云计算人才短缺的主要原因。</p><p>&nbsp;</p><p>Kevin：实际上，如果单独看IT领域，会发现有很多人才供给，同样单独看某业务领域的话也有相应的人才。问题是，当两者结合起来后，企业就需要一个具备业务和技术双重背景的综合型人才，而这类人才实际上是非常稀缺的。</p><p>&nbsp;</p><p>蒋林泉：我记得我们上次也谈到过AIGC推出后是否会导致程序员失业的问题。我一直坚信程序员永远不会失业。因为真正稀缺的是那些能够理解现实业务问题、将其建模并选择最高效工具和语言来实现的人才。企业转型真正需要的是懂业务的人才。</p><p>&nbsp;</p><p>这像是一个倒置的金字塔，金字塔底部是科学家或者天才，他们专注于做基础的事情，其成果将服务于所有人。如果底层平台越来越容易、越来越高效，那么上层管理者的门槛将降低，也将为数字化创新提供更多的程序员人才。这是一个很有趣的现象，比如等到LLaMA2成了金字塔底部的一部分时，人们会很快向上发展，每一轮浪潮都是如此。</p><p>&nbsp;</p><p>Kevin：国内许多程序员似乎对与他人交流感到不安，您认为这背后的原因有哪些？您能否提供一些关于克服交流障碍的建议？</p><p>&nbsp;</p><p>蒋林泉：国外文化相比较更鼓励个人表现。然而，如果你希望扩展自己的影响力，就需要克服与他人交流的恐惧以及根深蒂固的文化影响。这其中两个关键的方面：克服恐惧和积极分享。</p><p>&nbsp;</p><p>首先，你不必感到自卑，因为中国文化注重谦逊是合理的。其次，我们经常强调，如果你无法进行公开演讲，那么你的学习将受到限制。这是费曼学习法中的一项原则，也叫做“教学相长”，意味着你不仅要理解知识，还要能够将其传达给他人。当你能够清晰地表达并让他人理解时，你就会成为这个领域的专家。在克服恐惧的过程中，不仅提高了自己的表达能力，还掌握了通往专家之路的关键技能。</p><p>&nbsp;</p><p>Kevin：阿里云一直在积极推动云计算领域的人才培养和认证，这个举措对于整个人才生态的推动产生了怎样的价值？</p><p>&nbsp;</p><p>蒋林泉：阿里云一直坚定不移地投入认证领域。我们的目标是以业界领先的云服务提供商的身份，从产业的角度推动认证标准的制定，这些标准能够综合评估人才在技术和云计算综合应用方面的能力。这一标准不仅适用于整个云计算生态伙伴，还适用于那些正在进行数字化转型的企业，帮助他们精确筛选和培养人才。</p><p>&nbsp;</p><p>通过推动阿里云认证的发展，我们希望促进云计算人才的大规模成长，建立起能够供应大量高质量人才的体系。这将有助于云计算行业以及数字化转型企业，共同构建人才培养的良性循环，使得开发者和企业能够共同健康发展。</p><p>&nbsp;</p><p>Kevin：阿里的培训体系在整个行业里面也是非常知名的，您能不能给技术人的成长和发展提出一些建议。</p><p>&nbsp;</p><p>蒋林泉：第一个方面，关于“技术的触觉”。我们聊到了2009年第一场QCon，话题其实都是后面几年的预言，这一刻你的认知有可能是有历史延续性的。事实上，业界领军人物在谈的话题往往都是对后面几年发展的预言。所以，大家一定要关注技术前沿性，关注整个技术社区真正在发生的事情。大家首先要知道你想要从事什么样的职业，比如说你想去创建金字塔底层的基础平台，那就需要高度专业化，并且要知道这个领域很难、最终成功的人很少，你必须要谨慎选择这条道路。</p><p>&nbsp;</p><p>另外，更加长期有生命力的能力是贴近业务。我们之前说到，业务与技术的结合在这个领域是最具生命力的，因为掌握业务和技术的交汇点就可以运用技能来提高业务价值。</p><p>&nbsp;</p><p>此外，我更注重两个方面的软技能，一个是开放性，一个是好奇心。“开放性”意味着在整个过程中，你必须对一些机会或挑战持开放态度。如果不愿走出舒适区，那你肯定不会成长。而想要了解未曾涉足的领域，就必须要保持“好奇心”。好奇心是克服乏味学习和未知恐惧的最重要动力。因此，从长远来看，具备开放性和好奇心可以使你在技术领域走得更远。</p><p>&nbsp;</p><p>Kevin：你认为，未来云计算领域的从业者需要采取哪些措施应对变化？</p><p>&nbsp;</p><p>蒋林泉：在构建云计算基础设施的过程中，必须确保基础层的稳定和可靠。然而长期来看，云计算领域也会经历马太效应，即越来越多的资源集中在少数核心企业手中。真正的机会在于业务创新，通过有效地将业务创新与底层工具和低门槛的创新支持能力相结合，你就有可能在这一波浪潮中脱颖而出。</p>",
    "publish_time": "2023-09-14 15:13:04",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何用机器学习模型打击虚拟货币犯罪？",
    "url": "https://www.infoq.cn/article/OdL3dMC44dKGM989m1wC",
    "summary": "<p>历经十五年的发展，区块链技术以完整的技术生态系统重塑千行百业，其广泛应用也为金融、医疗、物流等多个领域带来巨大变革。但凡事皆有两面性，技术向善，也能为恶。</p><p>&nbsp;</p><p>区块链技术在普及应用的同时，也滋生了一系列的安全风险，尤以涉虚拟货币犯罪为重。此类新型科技犯罪形式，不仅对人民及社会的安全造成了严重威胁，也对现有法律和执法提出了全新挑战。本文主要讲述了我们如何用机器学习模型来打击虚拟货币违法犯罪行为。</p><p><img src=\"https://static001.infoq.cn/resource/image/03/ee/0307a9f68c18b79yyefd0c8904cf69ee.png\" /></p><p>图1：数据显示，涉币犯罪愈演愈烈</p><p>&nbsp;</p><p></p><h2>区块链：“黑暗森林”的形成</h2><p></p><p></p><p>区块链技术的核心特点是去中心化、匿名性，参与区块链交易的真实主体难以追踪，犯罪分子在链上自由交易，不必担心执法小队的追踪猎杀。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/38/55/38023bde302b74b10e573d9aeb6cf755.png\" /></p><p></p><p>图2：区块链技术：去中心化、安全透明、可追溯的分布式账本技术</p><p>&nbsp;</p><p>虚拟货币具有去中心化、无法监管、无国界、跨境限制、交易无限制和交易低成本的特征。不仅如此区块链技术还为犯罪分子提供了丰富的手段来隐匿踪迹、抵挡追踪。“混币器、隐私币”等的出现，进一步增强了其匿名性，为犯罪分子创造了毁灭追踪路径的“迷雾地带”。违法犯罪活动多以稳定币USDT（泰达币）为主要犯罪媒介，此外也常见于通过BTC(比特币)、ETH(以太坊)、XRP(瑞波币)、XMR(门罗币）等虚拟货币作为载体的犯罪行为。</p><p>&nbsp;</p><p>尽管区块链技术为不法分子实施犯罪带来诸多便利，但链上交易数据完全公开透明的特性，也为涉币案件的分析研判提供了海量数据。很多安全专家试图将分析传统法币犯罪案件的实战经验，应用在链上交易数据分析。但鉴于区块链技术的独特性，这些传统方法仍需与时俱进优化。</p><p>&nbsp;</p><p>涉币案件的侦破流程耗时很长，一个案件从获取线索到结案，通常会超过半年。为了提升结案成果率，案件的线索阶段就需广撒网、多线跟踪，这对于办案人员的分析产出质量与时效要求甚高。办案人员不仅需要具备深厚的区块链技术知识，也要深刻了解犯罪分子的行为模式与作案策略，门槛较高。目前，业内优秀的办案人员实属稀缺。为更高效精准打击涉币犯罪，执法领域在招募并培养复合型涉币案件办案人员的同时，要不断引进相关创新技术进行赋能，进一步提升侦破能力。</p><p>&nbsp;</p><p>利用大数据和机器学习技术来分析海量链上数据，帮助发现人力难以识别的线索，从而找到犯罪分子的踪迹”，已成为当前打击涉虚货币犯罪领域创新探索与方法研究的重要而前沿的方向，并在业内释放了巨大的应用价值与潜能。</p><p>&nbsp;</p><p></p><h2>机器学习如何用于涉币犯罪分析</h2><p></p><p></p><p>机器学习新技术已在合规领域尤其是金融犯罪风险防控方面，如金融风险评估、反洗钱等场景有了较为广泛的应用。近年来，业内不断布局探索图计算技术的动作，旨在进一步提升模型表现。</p><p>&nbsp;</p><p>相较基于人工经验主观判断的风险评估系统，机器学习模型的优势在于：</p><p>&nbsp;</p><p>最大限度利用获取的信息，发现人力难以找到的规律。如在反洗钱领域，机器学习技术这一优势得到充分发挥。洗钱活动往往涉及复杂的交易链和隐蔽的资金流向，机器学习模型通过对大量交易数据进行分析，可自动识别出可疑的交易模式与行为，从而帮助金融机构及时发现和阻止洗钱犯罪；判断更加精准高效，摆脱人工经验的主观性。如在金融风险评估中，传统方法十分依赖人工经验主观判断，效率低下，且仅能针对划分出的人群进行粗略判断；机器学习技术可以自动为每位客户甚至每笔交易进行分析推断，生成风险评分，并且确保这些评分均基于完整和准确的信息客观计算产出，精准度和可靠性极大提升；数据资源是人工智能发展的驱动力之一。随着数据量的快速增长和技术的飞速进步，机器学习模型可不断进行迭代优化，从而确保其表现始终处于最佳状态。</p><p>&nbsp;</p><p>上述机器学习模型，在传统金融安全领域发挥的优势，同样也可在涉币案件侦查中发挥巨大作用。我们基于区块链交易特征进行迭代完善，形成了图计算机器学习模型，并将其应用于涉币案件侦查平台的实战后，证实卓有成效。</p><p>&nbsp;</p><p></p><h2>图计算模型：判断涉案地址关联度</h2><p></p><p>&nbsp;</p><p>在涉虚拟币新型网络犯罪案件中，起始线索地址往往是犯罪活动的初始资金归集地址。以涉币网络赌博案件为例，该地址可能是用于归集赌客充值兑换筹码资金的地址，以此线索地址作为追踪犯罪团伙，开展侦查工作的实战开端，但从起始线索地址追踪到犯罪团伙的各个核心职能地址，中间分析过程可能涉及数十万个相关联的地址。如何在这些大量地址中，准确又快速找到相关性最强的可疑地址，是侦查工作突破的关键。</p><p>&nbsp;</p><p>传统的人工侦查方法存在以下痛点：</p><p>&nbsp;</p><p>主要依赖人工操作，侦查效率低下，且容易出错。由于人本身的能力有限，即使投入大量人力成本，去追踪覆盖数十万个地址的可能性也微乎其微；展开链上节点数量、层级有限。由于技术与资源的限制，传统侦查方法往往只能展开有限的节点数量和层级（最多3层），这样的实战节奏可以窥见，追踪到犯罪团队的核心地址并不明朗。人力能够并行处理的特征数量少。依靠人工经验，往往只能综合考虑有限的主要特征（5-10个），无法同时考虑更多维度特征。人为主观因素影响巨大。优秀的涉币案件分析师人才十分稀缺，已从业人员专业水平参差不齐，业内也并没有形成公认的标准侦查方法并培训普及，每个办案人员的方法与历史实战经验均不相同，便会导致结果因人而异；即使拥有培训经历，分析师也只能综合考虑5-10个标准化的主要特征，且每个人基于自身经验赋予各特征的权重也不一样，也会造成结果因人而异。</p><p>&nbsp;</p><p>所有机器学习产品功能的成功落地应用，皆是一个公司“业务、算法和工程”三方实力的综合体现，三者相辅相成。图计算模型的成功开发落地，首先根植于案件分析师团队依托大量案例实践沉淀的业务理解。在近一年多的时间里，分析师们通过借鉴大量传统法币案件的侦破经验，并结合虚拟币交易的特征，针对几十起具体涉币案件的情况深入分析研判，积累了极具价值的“特征判定规则”。这些规则可以帮助分析师更加准确地判断虚拟货币交易是否涉及犯罪行为，以及发现和追踪可疑交易。人力发掘出案件中的可疑涉案地址后，通过警方向交易所调取涉案地址的身份与交易信息，进一步确认了结果的准确性，并根据结果来修正“特征判定规则”。</p><p>&nbsp;</p><p>涉案团伙分工明确，资金归集、洗钱、收益发放、资金沉淀和兑换等各类职能划分清晰，此类多层级的组织结构和交易行为模式形成了复杂的网络关系。应用风险管理领域最前沿的图计算模型，可以将涉案团伙的成员、职能以及交易活动等数据信息整合成“点和边”的形式呈现，从而构建出复杂的不限层级的全币种全链路的网状图，并自动学习其中包含信息；此外，网图的拓扑结构也释放了高价值信息，可以深入揭示出团伙内部的组织关系、资金流动路径以及犯罪收益的分配情况等关键线索与证据。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/21/26/21187cb7f634209a96d5a630296ec126.png\" /></p><p></p><p>图3：涉币网络赌博案件的资金流转脉络</p><p></p><h3>模型实现步骤</h3><p></p><p>&nbsp;</p><p>图计算模型实现的步骤如下：</p><p>&nbsp;</p><p>搜索提取全量交易数据。首先获取一个起始线索地址，通常是一个案件初始资金的归集地址。从数据库中搜索并提取从该地址出发的所有下游交易，可根据案件类型灵活设置向后搜索的层级。随着搜索层级的增加，对计算资源要求也呈指数加大，但并不会发现更多高价值的涉案地址，增量价值递减；根据交易数据构建网图（Graph）。网图的“节点”是交易对手方的地址，“边”是两个地址之间的交易关系，链路则是一个起始地址到一个终点地址之间的交易通路。起始线索地址与任意一个终点地址之间，可能存在多条不同长度的链路。这将构建一个包含数十万节点与边的复杂网络。提取特征。生成网图后，按照链路维度，从链路中每个地址和每笔交易中提取关键特征。这里，我们主要用到了5大类，共计超过100个特征，包括：</p><p>地址资金余额相关特征：比如平均账户余额、账户余额的标准差、最新余额等；交易模式相关特征：比如平均交易频率、交易频率的标准差、交易总次数、交易间隔等；交易金额相关特征：比如除了均值、中位数、标准差等，还有异常大额交易等；交易时间特征：比如时间戳分布（是否有特定的交易活动时间段），交易时间重合度等；社交网络相关特征：用户的连接度（用户连接的其他用户数量），用户的社交网络位置（中心性），用户所属社群的数量等。</p><p>模型训练。搭建基于特征的规则模型，并用机器学习方法不断迭代规则阈值和注意力权重。规则模型为特征进行打分，最后加权求和，得出各链路分数，再根据链路数量、各链路分数，综合计算出起始线索地址与某个终点地址之间的“关联度”。结果产出。计算从起始线索地址到所有终点地址的“关联度”并进行排序，关联度最高的终点地址，就是高度可疑的涉案地址，用户可以针对这些涉案地址进行下一步的分析侦查，比如发函向其所在的交易所要求调取证据。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/1d/70/1d41c78f3493ddf8de02946ef8648470.png\" /></p><p></p><p>图4：多特征图计算模型</p><p>&nbsp;</p><p>能快速实现上述大规模计算，主要依赖区块链大数据积累。区块链AI安全厂商中科链源自建了三大区块链（以太坊、币安智能链和波场链）的全节点，并实时将交易数据解析处理，以确保数据的及时性和准确性，同时，为提高数据的安全性与可靠性，将数据存储到实时和离线两套数据库中，便于后续的数据分析和挖掘，这样就拥有了从链的创世区块到最新的所有完整交易数据的优势；并且根据模型特征计算需求，在数仓中建立了按天更新的业务中间表，以确保数据的新鲜度和准确性，同时提高计算效率，在接到用户发出的计算任务后，调用中间表，在30分钟内完成计算并产出结果。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/f1/a7/f16a8b73948324a4ea9ae7ba151988a7.png\" /></p><p></p><p>图5：用户使用去向关联分析功能，体验多特征图计算模型服务</p><p>&nbsp;</p><p>模型结果计算完毕后，中科链源自研的SAFEIS安士区块链AI信息作战系统会为用户呈现计算结果。作战系统的核心组件是以区块链交易资金流向形成的网状分析视图，在这里，用户可以点击任意地址，对其有交易关联的相关地址进行展开，从而形成巨大的网状图，便于追踪分析。该组件的使用场景与图计算模型的功能高度匹配，所以模型功能便深度融合到此数智执法产品的核心组件中。用户通过右键菜单，可以对任意地址调用模型，来计算其资金关联高的涉案地址，并将结果也展示在网状图上，直观揭示出犯罪行为的动态演变过程，方便进一步研判分析。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/e5/yf/e5282f9cd644e209f5c1034822537yyf.png\" /></p><p></p><p>图6：调用模型功能计算资金关联高的涉案地址</p><p></p><h2>机器学习模型在涉币资金分析中的优势和效果</h2><p></p><p>&nbsp;</p><p>机器学习模型可以自动快速处理和分析海量链上数据，减少人工参与的需求，极大提高效率。模型可以突破人类能够处理的信息极限，分析范围可覆盖到数十万的下游节点，并自动从数据中提取有用的特征，同时综合考虑多种特征进行分析，如统计特征、图特征等，进而提供相较于单纯依赖人工分析更为全面和准确的分析结果。最后，模型的决策基于数据和算法，如此避免了人工由于能力、经验参差不齐或主观判断等因素造成的结果不稳定。</p><p>&nbsp;</p><p>功能上线后，我们与几位资深分析师合作，将模型投入到新案件的实战中验证效果。针对每个起始线索地址，我们用模型计算出Top30的可疑涉案地址，相关度从高到低排列。同时由分析师自行通过人工分析，再对比双方结果。</p><p>&nbsp;</p><p>侦查案件对准确性与时效性的要求很高，关键在于快速找到一定数量的高质量线索进行突破，而无需费时找齐所有涉案线索，因此我们在评估中重点关注准确率，忽略了召回率。由于网络复杂，人工也难以穷尽所有节点，评估召回率则异常困难。</p><p>&nbsp;</p><p>从准确率来看，模型计算的Top3中，有60%左右的地址与人工分析的结果匹配，准确率符合预期；此外，另有15%的地址，没有通过人工找到，但经验证后发现相关度很高，这部分是模型的增量价值，可以发现人力难以察觉的信息。</p><p>&nbsp;</p><p></p><h2>模型功能开发难点攻坚</h2><p></p><p></p><p>在模型的开发过程中，我们遇到以下主要难点：</p><p>&nbsp;</p><p>1.&nbsp;源数据查询性能压力。</p><p>&nbsp;</p><p>随着模型搜索分析覆盖的范围增加（深入到5层就有几十万个地址节点、千万级别的交易数据），导致查询性能压力剧增，对性能优化和分析策略提出较高要求。</p><p>对此，我们优化了SQL查询逻辑，首先基于对案件特点的理解，合理设置了数据查询的限制条件，尽可能在数据源头提前筛除信息价值不高的数据。此外，我们还建立了精简高效的临时表，从根本上改进了查询性能。</p><p>&nbsp;</p><p>2.&nbsp;特征计算压力。</p><p>&nbsp;</p><p>在获取了几十万个地址节点、千万级别的交易数据后，需要构建出网状图，并且需根据这些数据计算出上百个特征，包括统计特征和图特征，这使得数据处理和分析计算量巨大。</p><p>对此，我们引入了Numpy矩阵计算库和Networkx图特征计算库。通过此类高效的计算库，我们实现了高达10倍的计算速度提升。</p><p>&nbsp;</p><p>3.&nbsp;不断挖掘新特征，提升模型效果。</p><p>&nbsp;</p><p>仅使用传统的交易数据的统计特征，已很难达到理想效果，需要根据案件特征，来发掘更多的高质量特征，以提高模型的推断能力。</p><p>&nbsp;</p><p>对此，我们引入了图特征，通过将网络拓扑结构与数据融合，为模型提供了更多的高价值信息。此外，根据资深分析师的经验，地址之间gas fee的流通也是其潜在关系的重要特征，在增加这一关键特征后，模型效果也得到了较大提升。</p><p>&nbsp;</p><p></p><h2>未来：模型迭代方向</h2><p></p><p>&nbsp;</p><p>目前，我们仍在积极与资深分析师团队展开密切合作，试图将该模型更多用于实战，并在实践中探索改进点。未来，我们探索的主要方向是挖掘寻找更多特征，提高模型的准确性和泛化能力，同时形成更完整的规则进行判断，以帮助构建更强大的模型。</p><p>&nbsp;</p><p>模型产品优化后，鉴于更多用户的持续使用，并给模型结果进行评分，我们进而可以拿到更多有价值的标注数据，用来优化特征计算，优化机器学习方法，进一步迭代模型，提高模型性能与质量，赋能数智执法产品，从而为用户提供更好的需求服务。</p><p>&nbsp;</p><p></p>",
    "publish_time": "2023-09-14 15:34:15",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "小开发者的生存之战：“Unity 希望获得我们全部收入的 108%！”",
    "url": "https://www.infoq.cn/article/LXGodZ1vZlYGt9o6AI6M",
    "summary": "<p>&nbsp;</p><p></p><blockquote>如今，流行游戏引擎的劣化程度愈发夸张，部分开发者表示已经在寻求开源替代方案。</blockquote><p></p><p>&nbsp;</p><p>Unity日前公布了新的收费规定。条款要求每次有人安装游戏时，游戏开发者都应支付相应费用。新规一出，立即遭到众多游戏开发者的普遍抵制。他们表示Unity的行为不仅打击了自己多年以来的努力，甚至可能直接导致其入不敷出。</p><p>&nbsp;</p><p>Unity曾被誉为游戏产业的救世主，它相对容易使用，成为很多游戏的引擎和框架。在商业游戏引擎普及之前，每个游戏都是定制构建的，这虽然有一定的优势，但需要很多时间，移植也很繁琐。Unity带来的最伟大的东西之一是相对简单的主机发布流程，如果要进行移植，更多的是关于平台特殊性而不需要进行完全重写。</p><p>&nbsp;</p><p>针对这一收费消息，一位游戏开发总监<a href=\"https://insertcredit.com/opinion/unity/\">建议大家</a>\"，如果你将要启动一个新的游戏项目，请不要使用Unity。如果你的项目是在4个月前启动的，可以考虑换成其他引擎。</p><p>&nbsp;</p><p></p><h2>根据游戏安装量对开发者进行收费</h2><p></p><p>&nbsp;</p><p>Unity在其官方网站的文章中宣布了这项新计划。公告写道，Unity 引擎自 2024 年 1 月 1 日起将根据游戏的安装量引入新的 Unity Runtime 费用 (runtime fee)。</p><p>&nbsp;</p><p>Unity 引擎主要由两个重要的软件部分组成：Unity 编辑器 和 Unity Runtime。Unity Runtime 是在玩家设备上执行的代码，每月的下载量达数十亿次。此次引入的 Unity Runtime 费用，是基于游戏被终端用户下载的次数而定。官方称选择这种计费方式是因为每次游戏被下载时，Unity Runtime 也会被安装。此外，他们认为基于初始安装的收费模式可以让创作者在与玩家互动的过程中持续盈利，这是与收入分成模式不同的地方。</p><p>&nbsp;</p><p>开发者之前就需要承担软件的使用年费，而且分为2000美元到5000美元等几个不同等级，而新费用又独立于这笔年费之外。</p><p>&nbsp;</p><p>新费用按月向游戏开发者收取，每位用户安装游戏将产生0.01至0.20美元间的费用，具体取决于实际售出的游戏数量、所在地区（新兴市场的收费标准较低）以及开发者已经选择的年费级别。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c5/c55f0c68b0b5e74160c3f3c11e70fbe3.png\" /></p><p></p><p>截图来自Unity中国社区</p><p>&nbsp;</p><p>Unity Technologies (Unity 技术公司) 中国公司也刊发了官方博客，宣布跟进收费变更。中国市场算是Unity的新兴市场，去年Unity刚联合本地团队设立了合资公司，并于今年8月宣布了Unity 引擎中国版 “团结引擎”（还处于内测阶段）。</p><p>&nbsp;</p><p>利用Unity 制作的游戏众多，其中包括《原神》、《炉石传说》、《Pokémon GO》、《Among Us》、《Cult of the Lamb》等等。对于头部公司来说，它们大多用的是Unity Enterprise，如果按照0.005美元（约人民币0.0364元）每次安装的收费标准，一款一亿下载量的游戏，Unity将从中额外获取约364万元的运行费用收益。这对一些有平台支撑的爆款游戏来说，还不算太多。显然，相对头部企业，Unity的新收费措施给一些工作室和独立开发者带来的冲击更大。</p><p>&nbsp;</p><p>Unity 论坛上已经有了数千条消息，其中大部分是开发者抗议这些变化，并讨论转向 Unreal 或开源 Godot 等竞争对手引擎。</p><p>&nbsp;</p><p>其中一篇帖子称：“我们有 2 名开发者，下载量超过 100 万，年收入超过 100 万。 ” “按照目前每天的安装量，我们每天必须向 Unity 支付 2000 美元。但我们基本上无法用剩下的钱来支付自己的工资……我们必须在 2024 年 1 月 1 日将游戏从商店下架，对我们来说，我们梦想中的工作就结束了。不幸的是，我们在短时间内不可能将我们的游戏移植到另一个引擎。”</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f9/f9ac84a6ec3321f56052459f068519a9.jpeg\" /></p><p></p><p>&nbsp;</p><p>另一名开发者也发表了题为“Unity 希望获得我们总收入的 108%”的评论：“我们的工作室专注于儿童手机游戏。我们不会向孩子们展示广告（而且我们也不想这样做），我们通过这些游戏获利的唯一方法是通过应用内购买。根据我们去年的数据，到 2024 年，我们将欠 Unity 约109% 的收入（100 万收入对应 1.09 的 Unity 运行时费用），这意味着比我们实际赚取的还要多。 当然，这还没有考虑工资、税收、运营成本和营销成本。”</p><p>&nbsp;</p><p></p><h2>反复修改的收费细则</h2><p></p><p>&nbsp;</p><p>这个消息对独立游戏开发者造成的打击极为沉重，毕竟对于这部分开发者来说，Unity一直作为经济实惠、简单易用的游戏引擎选项。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/de/de4a6962426671a4f5b859da65aa68f5.jpeg\" /></p><p></p><p></p><blockquote>“一名据称是 Unity 的员工发帖称，Unity 已经意识到开发者每次安装的费用可能会超过其收入，甚至达到破产的程度。但他们表示会与客户一起解决这个问题，以免让他们破产。”</blockquote><p></p><p>&nbsp;</p><p>游戏开发商Half Mermaid旗下作品《传世不朽》（&nbsp;Immortality）的编剧兼总监Sam Barlow在评价Unity当前的行径时使用了“劣化”这一术语。这里的劣化，是指企业先开发出优质产品，之后再对被锁定的用户提高收费、降低服务质量的行为。</p><p>&nbsp;</p><p>在Barlow看来，“对于独立游戏开发者来说，此番调整无疑就是真正的劣化时刻&nbsp;。Unity的思路非常明确，就是希望把业务转化为游戏即服务，同时最大程度提升每次安装的收益贡献。但这绝对不是我们希望看到的理想状况——理想条件下，优质独立游戏应该通过订阅来实现收支平衡，而游戏安装量与实际收入之间并不一定具有强关联。”</p><p>&nbsp;</p><p>南非游戏开发商QCF Design的Danny Day也指出，“自2010年的Unity 2.6以来，我就一直是Unity的付费用户。此次他们发布的是一项极具破坏性、而且缺乏慎密考量的政策，肯定会引发一系列问题。如果Unity继续一意孤行，必然会对众多开发人员产生负面影响。其中受伤最深的，就是那些最近几年才开始在Unity中开发项目的用户。因为他们绝对想不到Unity方面会突然要求收取新的费用，这可能导致其工作成果丧失经济效益。”</p><p>&nbsp;</p><p>此番争议的核心，在于Unity所说的“Unity运行时费用”。即当游戏开发者的收入和安装量达到一定阈值后，每当有新用户安装他们的游戏，这套方案就会向游戏开发者额外收取费用。具体来讲，当游戏开发者在过去12个月内赚到20万美元、且游戏在全生命周期内的安装量至少达到20万次时，Unity就会根据Unity Personal和Unity Plus计划向游戏开发者额外收费。而选择Unity Pro和Unity Enterprise计划的游戏开发者则可以在12个月内赚到100万美元、全生命周期安装量达到100万次后才开始缴纳额外费用。</p><p>&nbsp;</p><p>另一方面，Unity方面通过电子邮件对此事做出了澄清，表示“Unity运行时费用将于2024年1月1日起开始计算，且新政策不追溯以往、也并非持续性收费。我们只对新安装用户收取一次费用，不会像收入分成那样设置永久许可使用费。”目前的不少批评源自用户对于回溯性计费的担心，害怕自己突然收到一张覆盖以往多年的账单，而Unity表示事实绝非如此。然而，这种按安装量计费的模式仍会对游戏开发者造成冲击，迫使他们采取当初发布游戏时从未考虑过的其他商业模式。Unity承认从2024年起，之前及之后发布的所有游戏都须承受这笔本不存在的成本负担。</p><p>&nbsp;</p><p>更糟糕的是，Unity随后又做出澄清，称如果同一用户多次进行安装，他们也会向开发者重复收费。这就给开发者带来了噩梦般的场景——心怀不满的玩家完全可以多次安装、删除和重新安装游戏，这样就能给自己不喜欢的开发商造成经济损失。这无疑会让本就不平静的游戏行业面临又一轮“血雨腥风”，毕竟之前就曾经有极端玩家给游戏开发者发来死亡威胁。</p><p>&nbsp;</p><p>因为激起群愤，Unity随后撤销了重新安装将重复计费的决定。本周三早上，Unity在邮件中表示他们不会向开发者收取重新安装费用。</p><p>&nbsp;</p><p>Unity在其常见问答部分，也没有明确解释要如何跟踪用户安装Unity游戏的行为。而在“使用Unity开发的软件只要运行起来，就一定会通知Unity，即使是企业许可证也不例外吗？”问题之下，Unity表示“我们使用一套综合模型来计算运行时安装，该模型会从多个来源处收集数据。Unity运行时费用将使用符合GDPR和CCPA要求的数据，所请求的数据将被汇总且仅用于计费目的。”</p><p>&nbsp;</p><p>Meta公司游戏开发人员Andre Infante认为，“从某种角度来看，这项新规比虚幻引擎提出的收入分成协议更加糟糕。下载量跟收入并不一定严格挂钩，而二者之间的差异很可能给开发者带来严峻的风险。”Infante同时强调，他只代表个人发言，立场与Meta公司无关。“如此一来，盗版传播就有可能产生安装费用，而玩家也可能为了惩罚自己不喜欢的开发者而一遍遍在虚拟机上安装游戏。”</p><p>&nbsp;</p><p>Unity并未回应这套系统是否可能被滥用的问题，但Axios公司的Stephen Totilo表示得到了Unity的解释，后者计划使用欺诈检测工具并允许开发者上报潜在的欺诈状况。</p><p>&nbsp;</p><p></p><h2>老用户很迷茫</h2><p></p><p>&nbsp;</p><p>专门负责游戏维护和Linux版本移植工作的开发者Ethan Lee表示，“我已经在游戏开发领域工作了很多年，但我实在无法想象这条新规会造成怎样的影响。Unity等于是抱着对中间件业务的巨大误解就匆匆上马了这项政策。”</p><p>&nbsp;</p><p>Infante还发推文表示“很遗憾，我恐怕只能去学习新的引擎了。在过去十年间，我积累下非常丰富的Unity开发经验。这些技能大多可以转移，但肯定会有新的难关需要克服。”</p><p>&nbsp;</p><p>部分开发者还想知道，Unity会不会要求他们自行上报实际收入，毕竟游戏引擎本身并不清楚他们到底赚了多少钱。Unity公司的解释则是，“我们会使用自己的专有数据模型，所以这里无法解释太多，但我们相信它能准确计算出运行时在给定项目中的分发次数。”</p><p>&nbsp;</p><p>纽约大学媒体教授、《Apple II 时代：计算机如何变得个性化》一书作者Laine Nooney认为，“至少在游戏领域，我实在想不出任何类似的案例能够像Unity新规这样产生深远的影响。这种货币化策略就是平台资本主义最赤裸裸的呈现——像Unity这样的软件可以利用联网计算带来的监控能力，以之前无法实现的方式为自己持续谋取利益。”</p><p>&nbsp;</p><p>即使Unity的专有模型准确可靠，而游戏开发者也不会因重复安装而蒙受损失，新的定价模式在开发者眼中仍然代表着令人震惊且不安的变化趋势。其中最核心的问题在于，有些Unity开发者是在免费发布游戏，之后通过游戏内购项目赚钱。在这种情况下，只有极少部分游戏安装用户会真正付费。再有，不少独立游戏都会进行捆绑销售，即软件的价格只是实际售价中的一小部分、甚至完全免费。在这类情况下，游戏本体的安装量会大幅增加，但赚取的收益甚至不足以抵偿新规要求的费用。</p><p>&nbsp;</p><p>Barlow认为，“捆绑、打折等传统促销手段与订阅模式结合之后，可能意味着开发者在作品大获成功的同时，反而承受巨大的经济损失。”</p><p>&nbsp;</p><p>Day也提到，“这项新政似乎完全没有意识到游戏市场的实际结构，因此会对捆绑销售、订阅服务、随赠形式、免费游戏甚至是盗版产生巨大影响。当盗版用户安装我的游戏时，我作为开发者要不要向Unity付费？而考虑到其不断收集用户信息的行为，需要承担信息安全与隐私义务的平台也会将Unity项目视为潜在风险……总之，这就是场灾难。”</p><p>&nbsp;</p><p>也有不少开发者表示，他们已经开始考虑其他游戏引擎，比如虚幻引擎。另一种新的替代方案则是Godot开源游戏引擎，这明显是对Unity疯狂追求利润的抗议回应。四位接受采访的游戏开发者表示，面对Unity公布的新规，他们希望在未来转战Godot。另外两位则表示，他们正在研究虚幻游戏引擎。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dc/dc142f4be18c401012bfb5ebac79f253.jpeg\" /></p><p></p><p>Pokémon GO 表示将考虑 Ingress</p><p>&nbsp;</p><p>但这一切都需要时间。在准备就绪之前，游戏开发者得先承受一段时间的Unity最新定价方案，导致其已经发布的游戏受到影响。不少正在进行的项目也将因进展已深而无法切换至其他游戏引擎。</p><p>&nbsp;</p><p>Unity开发工具专家、YouTube游戏开发频道主播Freya Holmér指出，“我认为最大的问题在于，Unity的新条款也同样适用于已经发布的游戏和旧版本Unity。对于已经发布的项目，大家当然希望能维持之前的Unity商业模式不变。所以这种‘反攻倒算’式的政策会大大影响Unity在用户群体中的信任度。”</p><p>&nbsp;</p><p>此次公布的新规，已经让那些从Unity入行、对其拥有美好回忆的游戏开发者们伤透了心。</p><p>Spoiled Cat公司的Andreia“shana”Gaita表示，“Unity最初的使命就是‘推动游戏开发大众化’。Unity用更低的上手难度和友好的使用成本为每个人开启了通往游戏开发的大门。正因为如此，大多数手机游戏才都是用Unity开发而成，同时也奠定了Unity项目的独特气质——人员少、预算低、项目成功、人们可以靠游戏赚钱。但如今的Unity已经彻底失去了这一切。”</p><p>&nbsp;</p><p>Barlow解释称，“如果这代表着Unity的未来方向，那实在令人既不安又困惑。可残酷的现实就是如此，他们把新政回溯到每一款Unity游戏的行为既扇了开发者耳光、又在背后捅了一刀。我自己的独立职业生涯就是从Unity开始的，它变成这个样子实在让我既迷茫又心痛。”</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://insertcredit.com/opinion/unity/\">https://insertcredit.com/opinion/unity/</a>\"</p><p><a href=\"https://developer.unity.cn/projects/650025a7edbc2ad788ccc1ea\">https://developer.unity.cn/projects/650025a7edbc2ad788ccc1ea</a>\"</p><p><a href=\"https://forum.unity.com/threads/unity-plan-pricing-and-packaging-updates.1482750/page-55#post-9299384\">https://forum.unity.com/threads/unity-plan-pricing-and-packaging-updates.1482750/page-55#post-9299384</a>\"</p><p><a href=\"https://mastodon.gamedev.place/@runevision/111057752854385107\">https://mastodon.gamedev.place/@runevision/111057752854385107</a>\"</p><p><a href=\"https://old.reddit.com/r/Unity3D/comments/16hgmqm/unity_wants_108_of_our_gross_revenue/\">https://old.reddit.com/r/Unity3D/comments/16hgmqm/unity_wants_108_of_our_gross_revenue/</a>\"</p><p><a href=\"https://devclass.com/2023/09/13/unity-disunity-community-up-in-arms-after-announcement-of-runtime-fee-from-january-2024/\">https://devclass.com/2023/09/13/unity-disunity-community-up-in-arms-after-announcement-of-runtime-fee-from-january-2024/</a>\"</p><p><a href=\"https://www.404media.co/unity-new-fees-prices/\">https://www.404media.co/unity-new-fees-prices/</a>\"</p><p><a href=\"https://pokemongohub.net/post/news/unity-to-start-charging-niantic-per-game-install/\">https://pokemongohub.net/post/news/unity-to-start-charging-niantic-per-game-install/</a>\"</p>",
    "publish_time": "2023-09-14 16:54:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "合纵连横 降本增效——QQ 音乐敏捷项目管理实践",
    "url": "https://www.infoq.cn/article/sg6MrGM1qAuex4R4dsOo",
    "summary": "<p>近两年互联网行业的发展逐步放缓，降本增效成为了各大企业的核心主题，作为互联网研发项目管理负责人，如何从客观实际出发，在确保质量的前提下，降低沟通协作成本，减少常规操作耗时，将人力聚焦在更核心的专业工作上成为了需要持续优化的方向之一。</p>\n<h2>演讲大纲</h2>\n<ul>\n<li>QQ 音乐项目管理模式的发展简介</li>\n<li>项目管理优化思路及实践详解</li>\n<li>Before&amp;After：提升效果一览</li>\n<li>基于 QQ 音乐项目管理模式升级的总结与建议</li>\n</ul>\n<h2>听众收益</h2>\n<ul>\n<li>了解 QQ 音乐在项目管理过程中结合 TAPD 的管理实践经验</li>\n<li>针对不同时期的产品发展阶段和客观实际，活学活用各种管理工具，以达到不同的管理目标</li>\n</ul>",
    "publish_time": "2023-09-14 17:49:09",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "卡拉彼丘：游戏研发团队基于 TAPD 的敏捷探索与实践",
    "url": "https://www.infoq.cn/article/BAOvq45J3UcrcZ66sllw",
    "summary": "<p>复杂的游戏开发进程中必然会面临项目管理的困难，卡拉彼丘游戏团队将敏捷开发结合 TAPD 落地，有效提升了项目开发效率。</p>",
    "publish_time": "2023-09-14 17:55:32",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "提质增效·虎牙项目管理探索与实践",
    "url": "https://www.infoq.cn/article/1hWWWNoib6TK2fW65a0Y",
    "summary": "<p>在项目管理过程中，PM 在频繁的数据收集、人工催进度等重复事项上占用较多精力。虎牙综合考虑 TAPD 的优势和特点，选定它作为统一的项目管理工具。采用 TAPD 后，项目过程中信息沟通和同步的效率得到极大地提升，同时衍生出一系列基于 TAPD 的流程改进、流程自动化，并反向推动了项目效率和质量的提升。</p>",
    "publish_time": "2023-09-14 17:55:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]