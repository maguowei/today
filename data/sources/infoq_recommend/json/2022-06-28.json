[
  {
    "title": "通过Java来学习Apache Beam",
    "url": "https://www.infoq.cn/article/DNHzwEIkQyJgShdGHz6L",
    "summary": "<p>在本文中，我们将介绍Apache Beam，这是一个强大的批处理和流式处理<a href=\"https://github.com/apache/beam\">开源项目</a>\"，eBay等大公司用它来集成流式处理管道，Mozilla用它来在系统之间安全地移动数据。</p><p></p><h2>概览</h2><p></p><p>Apache Beam是一种处理数据的编程模型，支持批处理和流式处理。</p><p></p><p>你可以使用它提供的Java、Python和Go SDK开发管道，然后选择运行管道的后端。</p><p></p><h2>Apache Beam的优势</h2><p></p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/apache-beam-intro/en/resources/5pasted%20image%200-1654188064991.jpeg\" /></p><p>Beam的编程模型</p><p></p><p>内置的IO连接器Apache Beam连接器可用于从几种类型的存储中轻松提取和加载数据。主要连接器类型有：基于文件的（例如Apache Parquet、Apache Thrift）；文件系统（例如Hadoop、谷歌云存储、Amazon S3）；消息传递（例如Apache Kafka、Google Pub/Sub、Amazon SQS）；数据库（例如Apache Cassandra、Elastic Search、MongoDB）。作为一个OSS项目，对新连接器的支持在不断增长（例如InfluxDB、Neo4J）。可移植性：Beam提供了几个运行管道的Runner，你可以根据自己的场景选择最合适的，并避免供应商锁定。分布式处理后端，如Apache Flink、Apache Spark或Google Cloud Dataflow可以作为Runner。分布式并行处理：默认情况下，数据集的每一项都是独立处理的，因此可以通过并行运行实现优化。开发人员不需要手动分配负载，因为Beam为它提供了一个抽象。</p><p></p><h2>Beam的编程模型</h2><p></p><p>Beam编程模型的关键概念：</p><p></p><p>PCollection：表示数据的集合，如从文本中提取的数字或单词数组。PTransform：一个转换函数，接收并返回一个PCollection，例如所有数字的和。管道：管理PTransform和PCollection之间的交互。PipelineRunner：指定管道应该在哪里以及如何执行。</p><p></p><h2>快速入门</h2><p></p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/apache-beam-intro/en/resources/1figure-4-1654188238779.jpeg\" /></p><p>一个基本的管道操作包括3个步骤：读取、处理和写入转换结果。这里的每一个步骤都是用Beam提供的SDK进行编程式定义的。</p><p></p><p>在本节中，我们将使用Java SDK创建管道。你可以创建一个本地应用程序（使用Gradle或Maven构建），也可以使用<a href=\"https://frontend-beta-dot-apache-beam-testing.appspot.com/\">在线沙盒</a>\"。示例将使用本地Runner，因为这样使用JUnit断言验证结果会更容易些。</p><p></p><h4>Java本地依赖</h4><p></p><p>beam-sdk-java-core：包含所有的Beam模型类。beam-runners-direct-java：默认情况下Beam SDK将直接使用本地Runner，也就是说管道将在本地机器上运行。</p><p></p><h4>乘2操作</h4><p></p><p>在第一个例子中，管道将接收到一个数字数组，并将每个元素乘以2。</p><p></p><p>第一步是创建管道实例，它将接收输入数组并执行转换函数。因为我们使用JUnit运行Beam，所以可以很容易地创建TestPipeline并将其作为测试类的一个字段。如果你更喜欢通过main方法来运行，需要设置<a href=\"https://beam.apache.org/documentation/programming-guide/#creating-a-pipeline\">管道配置参数</a>\"。</p><p></p><p><code lang=\"java\">@Rule\npublic final transient TestPipeline pipeline = TestPipeline.create();\n</code></p><p></p><p>现在，我们可以创建作为管道输入的PCollection。它是一个直接在内存中实例化的数组，但它也可以从支持Beam的任何地方读取。</p><p></p><p><code lang=\"java\">PCollection numbers =\n                pipeline.apply(Create.of(1, 2, 3, 4, 5));\n</code></p><p></p><p>然后我们应用我们的转换函数，将每个元素乘以2。</p><p></p><p><code lang=\"java\">PCollection output = numbers.apply(\n                MapElements.into(TypeDescriptors.integers())\n                      .via((Integer number) -&gt; number * 2)\n      );\n</code></p><p></p><p>为了验证结果，我们可以写一个断言。</p><p></p><p><code lang=\"java\">PAssert.that(output)\n                .containsInAnyOrder(2, 4, 6, 8, 10);\n</code></p><p></p><p>注意，结果不排序，因为Beam将每一个元素作为独立的项进行并行处理。</p><p></p><p>测试到这里就完成了，我们通过调用下面的方法运行管道：</p><p></p><p><code lang=\"java\">pipeline.run();\n</code></p><p></p><h4>Reduce操作</h4><p></p><p>Reduce操作将多个输入元素进行聚合，产生一个较小的集合，通常只包含一个元素。</p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/apache-beam-intro/en/resources/1pasted%20image%200-2-1654188064991.jpeg\" /></p><p>MapReduce</p><p></p><p>现在我们来扩展上面的示例，将所有项乘以2后求和，产生一个MapReduce转换操作。</p><p></p><p>每一个PCollection转换都会产生一个新的PCollection实例，这意味着我们可以使用apply方法将转换链接起来。对于这个示例，将在每个元素乘以2后使用Sum操作：</p><p></p><p><code lang=\"java\">PCollection numbers =\n            pipeline.apply(Create.of(1, 2, 3, 4, 5));\n\nPCollection output = numbers\n            .apply(\n                   MapElements.into(TypeDescriptors.integers())\n                       .via((Integer number) -&gt; number * 2))\n            .apply(Sum.integersGlobally());\n\nPAssert.that(output)\n             .containsInAnyOrder(30);\n\npipeline.run();\n</code></p><p></p><h4>FlatMap操作</h4><p></p><p>FlatMap先对每个输入元素应用映射，返回一个新集合，从而产生一个集合的集合。然后再应用Flat操作将所有嵌套的集合合并，最终生成一个集合。</p><p></p><p>下一个示例将把字符串数组转换成包含唯一性单词的数组。</p><p></p><p>首先，我们声明将作为管道输入的单词列表：</p><p></p><p><code lang=\"java\">final String[] WORDS_ARRAY = new String[] {\n          \"hi bob\", \"hello alice\", \"hi sue\"};\n\nfinal List WORDS = Arrays.asList(WORDS_ARRAY);\n</code></p><p></p><p>然后，我们使用上面的列表创建输入PCollection：</p><p></p><p><code lang=\"plain\">PCollection input = pipeline.apply(Create.of(WORDS));\n</code></p><p></p><p>现在，我们进行FlatMap转换，它将拆分每个嵌套数组中的单词，并将结果合并成一个列表：</p><p></p><p><code lang=\"java\">PCollection output = input.apply(\n      FlatMapElements.into(TypeDescriptors.strings())\n            .via((String line) -&gt; Arrays.asList(line.split(\" \")))\n);\n\nPAssert.that(output)\n      .containsInAnyOrder(\"hi\", \"bob\", \"hello\", \"alice\", \"hi\", \"sue\");\n\npipeline.run();\n</code></p><p></p><h4>Group操作</h4><p></p><p>数据处理的一个常见的任务是根据特定的键进行聚合或计数。我们将计算上一个例子中每个单词出现的次数。</p><p></p><p>在有了扁平的字符串数组之后，我们可以链接另一个PTransform：</p><p></p><p><code lang=\"java\">PCollection&gt; output = input\n            .apply(\n                  FlatMapElements.into(TypeDescriptors.strings())\n                      .via((String line) -&gt; Arrays.asList(line.split(\" \")))\n            )\n            .apply(Count.perElement());\n</code></p><p></p><h4>产生结果：</h4><p></p><p><code lang=\"java\">PAssert.that(output)\n.containsInAnyOrder(\n       KV.of(\"hi\", 2L),\n       KV.of(\"hello\", 1L),\n       KV.of(\"alice\", 1L),\n       KV.of(\"sue\", 1L),\n       KV.of(\"bob\", 1L));\n</code></p><p></p><h4>从文件中读取</h4><p></p><p>Beam的一个原则是可以从任何地方读取数据，所以我们来看看在实际当中如何使用文本文件作为数据源。</p><p></p><p>下面的示例将读取包含“An advanced unified programming model”文本的文件“words.txt”。然后转换函数将返回一个包含每一个单词的PCollection。</p><p></p><p><code lang=\"java\">PCollection input =\n      pipeline.apply(TextIO.read().from(\"./src/main/resources/words.txt\"));\n\nPCollection output = input.apply(\n      FlatMapElements.into(TypeDescriptors.strings())\n      .via((String line) -&gt; Arrays.asList(line.split(\" \")))\n);\n\nPAssert.that(output)\n      .containsInAnyOrder(\"An\", \"advanced\", \"unified\", \"programming\", \"model\");\n\npipeline.run();\n</code></p><p></p><h4>将结果写入文件</h4><p></p><p>从前面的输入示例可以看到，Beam提供了多个内置的输出连接器。在下面的例子中，我们将计算文本文件“words.txt”（只包含一个句子“An advanced unified programming model\"）中出现的每个单词的数量，输出结果将写入一个文本文件。</p><p></p><p><code lang=\"java\">PCollection input =\n      pipeline.apply(TextIO.read().from(\"./src/main/resources/words.txt\"));\n\nPCollection&gt; output = input\n      .apply(\n            FlatMapElements.into(TypeDescriptors.strings())\n                 .via((String line) -&gt; Arrays.asList(line.split(\" \")))\n            )\n            .apply(Count.perElement());;\n\n       PAssert.that(output)\n             .containsInAnyOrder(\n                 KV.of(\"An\", 1L),\n                 KV.of(\"advanced\", 1L),\n                 KV.of(\"unified\", 1L),\n                 KV.of(\"programming\", 1L),\n                 KV.of(\"model\", 1L)\n            );\n\n      output\n             .apply(\n                   MapElements.into(TypeDescriptors.strings())\n                         .via((KV kv) -&gt; kv.getKey() + \" \" + kv.getValue()))\n             .apply(TextIO.write().to(\"./src/main/resources/wordscount\"));\n\n      pipeline.run();\n</code></p><p></p><p>默认情况下，文件写入也针对并行性进行了优化，这意味着Beam将决定保存结果的最佳分片（文件）数量。这些文件位于src/main/resources文件夹中，文件名包含了前缀“wordcount”、碎片序号和碎片总数。</p><p></p><p>在我的笔记本电脑上运行它生成了4个分片：</p><p></p><p>第一个分片（文件名：wordscount-00001-of-00003）：</p><p></p><p><code lang=\"java\">An 1\nadvanced 1\n</code></p><p></p><p>第二个分片（文件名：wordscount-00002-of-00003）：</p><p></p><p><code lang=\"java\">unified 1\nmodel 1\n</code></p><p></p><p>第三个分片（文件名：wordscount-00003-of-00003）：</p><p></p><p><code lang=\"java\">programming 1\n</code></p><p></p><p>最后一个分片是空的，因为所有的单词都已经被处理完了。</p><p></p><h4>扩展Beam</h4><p></p><p>我们可以通过编写自定义转换函数来扩展Beam。自定义转换器将提高代码的可维护性，并消除重复工作。</p><p></p><p>基本上，我们需要创建一个PTransform的子类，将输入和输出的类型声明为Java泛型。然后重写expand方法，加入我们的逻辑，它将接受单个字符串并返回包含每个单词的PCollection。</p><p></p><p><code lang=\"java\">public class WordsFileParser extends PTransform, PCollection&gt; {\n\n     @Override\n     public PCollection expand(PCollection input) {\n       return input\n                .apply(FlatMapElements.into(TypeDescriptors.strings())\n                  .via((String line) -&gt; Arrays.asList(line.split(\" \")))\n                );\n     }   \n}\n</code></p><p></p><p>用WordsFileParser来重构测试场景就变成了：</p><p></p><p><code lang=\"java\">public class FileIOTest {\n\n    @Rule\n    public final transient TestPipeline pipeline = TestPipeline.create();\n\n    @Test\n    public void testReadInputFromFile() {\n          PCollection input =\n                          pipeline.apply(TextIO.read().from(\"./src/main/resources/words.txt\"));\n\n          PCollection output = input.apply(\n                      new WordsFileParser()\n          );\n\n          PAssert.that(output)\n                      .containsInAnyOrder(\"An\", \"advanced\", \"unified\", \"programming\", \"model\");\n\n          pipeline.run();\n    }\n\n    @Test\n    public void testWriteOutputToFile() {\n          PCollection input =\n             pipeline.apply(TextIO.read().from(\"./src/main/resources/words.txt\"));\n\n          PCollection&gt; output = input\n                      .apply(new WordsFileParser())\n                      .apply(Count.perElement());\n\n          PAssert.that(output)\n                      .containsInAnyOrder(\n                            KV.of(\"An\", 1L),\n                            KV.of(\"advanced\", 1L),\n                            KV.of(\"unified\", 1L),\n                            KV.of(\"programming\", 1L),\n                            KV.of(\"model\", 1L)\n                      );\n\n           output\n                      .apply(\n                            MapElements.into(TypeDescriptors.strings())\n                            .via((KV kv) -&gt; kv.getKey() + \" \" + kv.getValue()))\n                      .apply(TextIO.write().to (\"./src/main/resources/wordscount\"));\n\n       pipeline.run();\n  }\n}\n</code></p><p></p><p>结果变成了更清晰和更模块化的管道。</p><p></p><h4>时间窗口</h4><p></p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/apache-beam-intro/en/resources/1pasted%20image%200-3-1654188064991.jpeg\" /></p><p>Beam的时间窗口</p><p></p><p>流式处理中一个常见的问题是将传入的数据按照一定的时间间隔进行分组，特别是在处理大量数据时。在这种情况下，分析每小时或每天的聚合数据比分析数据集的每个元素更有用。</p><p></p><p>在下面的例子中，我们将假设我们身处金融科技领域，我们正在接收包含金额和交易时间的事件，我们希望获取每天的交易总额。</p><p></p><p>Beam提供了一种用时间戳来装饰每个PCollection元素的方法。我们可以通过这种方式创建一个代表5笔交易的PCollection：</p><p></p><p>金额10和20是在2022年02月01日转账的；金额30、40和50是在2022年02月05日转账的。</p><p></p><p><code lang=\"java\">PCollection transactions =\n      pipeline.apply(\n            Create.timestamped(\n                  TimestampedValue.of(10, Instant.parse(\"2022-02-01T00:00:00+00:00\")),\n                  TimestampedValue.of(20, Instant.parse(\"2022-02-01T00:00:00+00:00\")),\n                  TimestampedValue.of(30, Instant.parse(\"2022-02-05T00:00:00+00:00\")),\n                  TimestampedValue.of(40, Instant.parse(\"2022-02-05T00:00:00+00:00\")),\n                  TimestampedValue.of(50, Instant.parse(\"2022-02-05T00:00:00+00:00\"))\n               )\n       );\n</code></p><p></p><p>接下来，我们将应用两个转换函数：</p><p></p><p>使用一天的时间窗口对交易进行分组；把每组的数量加起来。</p><p></p><p><code lang=\"java\">PCollection output =\n      Transactions\n             .apply(Window.into(FixedWindows.of(Duration.standardDays(1))))\n             .apply(Combine.globally(Sum.ofIntegers()).withoutDefaults());\n</code></p><p></p><p>在第一个时间窗口（2022-02-01）中，预计总金额为30（10+20），而在第二个窗口（2022-02-05）中，我们应该看到总金额为120（30+40+50）。</p><p></p><p><code lang=\"java\">PAssert.that(output)\n                   .inWindow(new IntervalWindow(\n                       Instant.parse(\"2022-02-01T00:00:00+00:00\"),\n                       Instant.parse(\"2022-02-02T00:00:00+00:00\")))\n                 .containsInAnyOrder(30);\n\nPAssert.that(output)\n                 .inWindow(new IntervalWindow(\n                        Instant.parse(\"2022-02-05T00:00:00+00:00\"),\n                        Instant.parse(\"2022-02-06T00:00:00+00:00\")))\n                 .containsInAnyOrder(120);\n</code></p><p></p><p>每个IntervalWindow实例需要匹配所选时间段的确切开始和结束时间戳，因此所选时间必须是“00:00:00”。</p><p></p><h2>总结</h2><p></p><p>Beam是一个强大的经过实战检验的数据框架，支持批处理和流式处理。我们使用Java SDK进行了Map、Reduce、Group和时间窗口等操作。</p><p></p><p>Beam非常适合那些执行并行任务的开发人员，可以简化大规模数据处理的机制。</p><p></p><p>它的连接器、SDK和对各种Runner的支持为我们带来了灵活性，你只要选择一个原生Runner，如Google Cloud Dataflow，就可以实现计算资源的自动化管理。</p><p></p><p>作者简介</p><p></p><p>Fabio Hiroki是一位在Mollie公司从事金融服务的软件工程师。</p><p></p><p>原文链接：</p><p></p><p><a href=\"https://www.infoq.com/articles/apache-beam-intro/\">Introduction to Apache Beam Using Java</a>\"</p>",
    "publish_time": "2022-06-28 09:01:24",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "规避代码被“投毒”，开源软件供应链安全面面观 | InfoQ《极客有约》",
    "url": "https://www.infoq.cn/article/EgmPvTu4Ik9xeFJ8qToL",
    "summary": "<p>开源软件供应链当前面临的主要是两大风险：一是安全风险，一是许可证、版权、专利和出口管制等方面的法律合规风险。当然针对使用开源软件的企业来说，还有供应链风险及运维风险。这些风险如何更好地规避？开源协议、开源组织都做了哪些事情？企业如何自查内部开源项目的安全性？本期《极客有约》，我们邀请到了Zilliz合伙人，首席布道师顾钧，上海安势信息技术有限公司资深解决方案架构师朱贤曼共同解答上述问题。</p>\n<p><strong>直播大纲：</strong></p>\n<p>1.开源软件供应链解读；<br />\n2.常见的针对开源软件 - 供应链的攻击类型；<br />\n3.企业如何自查安全性；</p>\n<p><strong>讲师介绍：</strong></p>\n<p>顾钧，Zilliz 合伙人、首席布道师，LF AI&amp;Data 基金会 TAC 成员，开放原子基金会开源导师。北大毕业 16 年以来专注于数据库、大数据技术，尤其对 OLTP 平台与场景有着丰富的经验，先后任职于工商银行、IBM、摩根士丹利、华为等企业。</p>\n<p>朱贤曼，上海安势信息技术有限公司资深解决方案架构师，十余年软件开发经验，先后从事出口管制合规、合规相关系统设计和实施、开源软件合规等工作。</p>",
    "publish_time": "2022-06-28 09:13:47",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "亚马逊云科技发布架构决策记录指南",
    "url": "https://www.infoq.cn/article/6aLhRfRH7BPfGL3del9I",
    "summary": "<p>亚马逊云科技发布了<a href=\"https://docs.aws.amazon.com/prescriptive-guidance/latest/architectural-decision-records/welcome.html\">使用架构决策记录（architecture decision record，ADR）的指南</a>\"。他们推荐了一个在软件工程团队中采用和审查ADR的过程，这个过程的结果是包含已批准、已拒绝和已废弃的ADR集合的决策记录。</p><p></p><p>亚马逊云科技提出该ADR过程的目的是改善架构决策，避免对相同主题的重复性讨论，并有效地对决策进行沟通。</p><p></p><p>ADR是一个简短的文档，描述了会影响软件架构的团队决策。它不仅包含决策，还包含了相关的背景和影响。一组ADR组成了一个决策日志，它提供了关于项目或产品的更广泛的背景、设计信息和实现细节。</p><p></p><p>ADR过程中，最常见的输入是需要在架构方面进行重大决策的功能性或非功能性需求。发现了这种决策的任何团队成员都应该创建一个ADR。使用<a href=\"https://docs.aws.amazon.com/prescriptive-guidance/latest/architectural-decision-records/appendix.html\">模板</a>\"可以简化ADR的创建，并且能够确保它会捕获所有相关的信息。</p><p></p><p>按照亚马逊云科技的指南，创建ADR的团队成员也是该ADR的所有者，要负责维护和交流它的内容。在初始阶段，ADR所有者会提供一个“proposed”状态的ADR，这意味着它可以进行审查了。随后，ADR所有者要安排一个团队会议，以审查并决定该ADR要被批准、返工还是拒绝。</p><p></p><p>如果团队发现该ADR需要改进的话，它会依然保持“proposed”状态，所有者和其他团队成员会对其进行优化。否则的话，ADR的状态将会变为“accepted”或“rejected”，ADR就不可改变了。如果团队需要更新这个决策的话，那应该提出一个新的ADR，当该ADR被批准后，会取代之前的ADR。</p><p></p><p>下图展示了ADR的创建、所有权和采用的过程。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/news/2022/06/aws-adr-guide/en/resources/1adr-creation-1654293535205.png\" /></p><p></p><p>图片来源：<a href=\"https://docs.aws.amazon.com/prescriptive-guidance/latest/architectural-decision-records/adr-process.html\">https://docs.aws.amazon.com/prescriptive-guidance/latest/architectural-decision-records/adr-process.html</a>\"</p><p></p><p>亚马逊云科技建议，ADR应该有一个变更历史。一旦ADR被批准或拒绝，它就应该被认为是不可改变的。如果团队批准了一个新的ADR，并且该ADR取代或更新了以前的决策，ADR的所有者应该将旧ADR的状态变更为“superseded”。如果新的ADR 被拒绝了，则不需要对旧的ADR进行任何改变。</p><p></p><p>下图显示了ADR的更新过程。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/news/2022/06/aws-adr-guide/en/resources/1adr-inspection-1654293535205.png\" /></p><p></p><p>图片来源: <a href=\"https://docs.aws.amazon.com/prescriptive-guidance/latest/architectural-decision-records/adr-process.html\">https://docs.aws.amazon.com/prescriptive-guidance/latest/architectural-decision-records/adr-process.html</a>\"</p><p></p><p>决策日志会随着时间的推移而增长，它会提供团队所做出的所有决策的历史。例如，在代码或架构审查期间，团队可以使用决策日志作为参考，以验证变更是否符合商定的决策，或者是否需要创建一个新的ADR。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/06/aws-adr-guide/\">AWS Publishes Guide to Architecture Decision Records</a>\"</p>",
    "publish_time": "2022-06-28 09:27:05",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "作业帮直播间性能优化实践",
    "url": "https://www.infoq.cn/article/LusTLR314yoOMVFvaYI4",
    "summary": "<p></p><h3>直播间结构</h3><p></p><p></p><p>在线教育场景下的直播间不同于泛娱乐类直播 App，其业务的复杂度更高，同时用户的设备分布更分散，有很多低端机及性能差的设备，并且用户的上课时长通常在 1.5 小时左右，长时间的停留让设备发热及耗电明显，最终导致直播间的性能问题成为了根本的瓶颈。</p><p></p><p>要解决直播间的性能问题，首先要先从直播间的整体构成入手，具体如下图：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/f5/9c/f53da191f022dc9976796f3236d4009c.png\" /></p><p></p><p>从整体 UI 的结构上看整个直播间是横屏，由课件区、主讲的拉流区、用户自己的推流区、同组学员区、聊天区组成，这几个区域都是常驻，从进入直播间开始就存在，其中的课件区是 Webview，上课过程中还会通过 Webview 展示互动题以及画板。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/7e/8e/7e6a027e2yyyy495c4694ed2172f038e.png\" /></p><p></p><p>其中课件区承载的是 H5 课件，最上层是常驻透明的笔迹画板，同样是 Webview 承载，具体是由 H5 的 canvas 绘制，课件的复杂度在于有很多转场动画和交互，画板会频繁绘制笔迹，从 Webview 角度看这些高复杂的场景都会导致资源消耗较大且不可控。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/d6/7e/d62de17784da9e4bc57ecceba300497e.png\" /></p><p>内容区分层图</p><p></p><p>不可见的还有直播的推拉流、编解码、图像的渲染。信令通道，信令的解析、分发、排重、补偿等等，这些逻辑虽不可见，但依然是性能消耗的大户，特别是流媒体相关，一定程度上是性能的黑洞。</p><p></p><h3>性能衡量（APM）</h3><p></p><p></p><p>搞清楚了直播间的结构后，接下来我们要定量分析出性能具体如何？衡量直播间的性能，从 App 角度衡量性能有现成的概念 APM。通过 APM 来收集、上报、分析数据，产出对应的报表，来衡量性能，再根据业务场景直播间来输出结论。再进一步可以整合问题定位系统，进行问题的定位及排查，这样就完成了诊断 -&gt;定位 -&gt;优化的闭环。这部分的设计不展开讲，后续可以单独开一篇文章讲一下问题诊断、定位、优化及 APM 的设计。</p><p></p><p>APM 的核心是监控 CPU、内存、FPS 这些指标，并按照一定的频率及采样率上报分析，最终分析出性能的整体表现。在我们的业务中分析的结果是，从进入直播间开始，运行内存 200MB 的占用，随时间的变化升到 800MB 甚至更高，低端机 CPU 持续占用 80%~90% 左右，帧率方面低端机上低帧率（低于 10）的场景特别频繁。</p><p></p><p>客服和技术支持系统可以监控到用户的反馈情况，数据包含舆情、客服反馈渠道、用户社群等，可以分析出用户视角的问题。</p><p></p><p>最后，综合业务、客服、技术支持、用户体验等，最终确定按照如下指标衡量直播间性能：</p><p></p><p>用户问题反馈率：图像（卡顿或画面问题）、声音、互动，结合业务目标是千分位以下；性能指标：CPU、内存、FPS，目标是平稳且及时释放；业务指标：视频卡顿率、信令（到达、接收、展示）、互动成功率，目标是 99.9%。</p><p></p><h3>明确问题</h3><p></p><p></p><p>通过业务逻辑、用户视角的现象结合技术监控，进行分析、诊断，最终定位出如下核心问题：</p><p></p><p>卡顿：由于性能消耗较大且持续濒临性能崩溃的边缘，造成卡顿、卡死、crash 等，最经典的案例是有些低端机运行内存剩余不足 10MB，CPU几乎在 100%，GPU内存暴掉出现 OOM；课件性能：表现是课件区内容展示不全或不连续、卡在某一页、笔迹花屏等等；黑白屏：如上面的内容区分层图所示，课件、互动题、画板三层均为 Webview，移动端的 Webview 是由系统底 WebGL ES 进行渲染，渲染过程中如果出现 GPU 的 OOM，在 iOS 表现为白屏（WKWebview 进程触发了 Terminate 回调），Android平台表现为黑屏或部分黑屏；互动失败：互动题是由信令通道的信令来驱动，信令如果出现延迟到达、丢失、乱序等就会造成互动失败；</p><p></p><h3>优化方案</h3><p></p><p></p><p>从业务上的表现及技术上的分析最终确定问题核心是 CPU、运行内存、GPU 这些资源在调度或使用过程中出现资源不足导致，资源上的消耗、占用、竞争是问题的根本，同时资源的释放不及时也会导致问题加剧，所以从资源角度解决问题需要先从各方面进行资源的释放及管控。</p><p></p><h4>独立进程</h4><p></p><p></p><p>从平台特性角度首先想到的方案是 Android 系统的独立进程，因为独立进程有自己独立的资源调度及使用控制，在需要的时候申请相对独立的资源，在不需要的时候释放可以更彻底的回收资源。这种资源的管控恰恰适合直播间的场景，用户在进入直播间时创建独立进程，在退出时彻底销毁释放资源，过程中如果资源告警或超过阈值还可以进行销毁重建。</p><p></p><p>具体的实现是 App 主进程作为核心载体及宿主，将直播间加入到独立的进程中，直播间的进程与主进程建立 AIDL 通信通道，完成进程间的功能调用。使用 MMKV 在进程间共享数据，需要特别注意数据一致性（使用文件锁）。过程中由统一的调度器 (Service Manager) 管理所有的 binder 服务，包括系统服务和应用自定义的服务，具体参考下图：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/58/3b/5824yyfae35209e696b6883de99da63b.jpg\" /></p><p>独立进程架构图</p><p></p><p>当然由于系统及平台的限制独立进程在 iOS 是实现不了的，iOS 平台需要其他方式，下面就来讲讲适用全平台的优化方案！</p><p></p><h4>容器化</h4><p></p><p></p><p>关于资源的管控有很多现成的模式可以参考，容器化是最为直接的方式，以容器为组织单位进行生命周期的管理，可有效的管控资源。譬如将 Webview 看成是一个容器，其生命周期可分为创建、加载、更新、重置、关闭、销毁的整个过程，每个过程都有其存在的价值和互相之间的关系。</p><p></p><p>创建&nbsp;负责生成容器对象及基本的资源申请，使容器处于初始化的状态；加载&nbsp;负责将内容 load 到容器，渲染展示内容；更新&nbsp;与加载对应，负责将老的内容刷新至新的状态，并重新渲染展示内容；重置&nbsp;可以将原有的资源释放，使容器重新恢复到初始化状态；关闭&nbsp;将容器从可见状态转换为非可见状态，但此时容器的对象依然存在；销毁&nbsp;彻底将容器的对象释放，并将其占用的所有资源释放。</p><p></p><p>其整个生命周期的管理基于平台提供的 API 进行封装，中间使用对应的桥接层进行对接，最上层使用统一调度层将核心的能力提供给上层业务进行整合和调度，具体如下图：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/00/a3/00ef04a17a80c003f83c4e41743b16a3.png\" /></p><p>容器化架构图</p><p></p><h4>信令通道</h4><p></p><p></p><p>容器是承载内容的载体，而直播场景的内容是有一定连续性的，类似视频播放器，一个完整的视频是由一系列连续的帧图构成，通过时间的纬度将一系列帧图组织在一起，一帧帧播放出来，再配合上音频就构成了视频。容器也类似，使用信令将容器驱动起来，将一页页内容展示出来，譬如主讲老师的课件、笔迹、互动题等，课件的翻页、笔迹的书写、互动题的发起结束都是一系列的信令进行驱动的。</p><p></p><p>其中信令的通道选择尤为重要，最初信令的通道设计是由直播流的 SEI 通道进行承载，通过时间戳的对齐向上层业务抛信令，这样的设计最初目的是为了保证更实时的传输，但事与愿违，由于直播流的技术采用了 WebRTC，它的网络层实现使用的是 UDP 协议，UDP 本身不保证时序及可靠性，所以会有大量的乱序及丢包存在，导致信令的错乱和丢失，可靠性大打折扣。</p><p></p><p>使用 SEI 通道的另外一个问题是完全耦合到直播拉流的逻辑中，假如想切换拉流方式需要同时切换信令通道，带来了更多的额外成本。</p><p></p><p>所以最理想的信令通道应该是独立通道且保证可靠性的方式，业界也有成熟方案——长连接，其实在直播课的业务中，rtmp 拉流方式下已经使用过长连接，可以保证技术可靠性的同时也是相对独立的服务及通道。所以我们最终使用长连接通道，将信令从直播拉流中解耦出来。</p><p></p><h4>渲染优化</h4><p></p><p></p><p>解决了内容的承载、驱动，接下来要解决渲染的问题，业务上所有可视化的内容都涉及渲染，主要包括了 Navtive UI 渲染、流媒体渲染、Webview 内容渲染，下面展开讲一下其中的原理及方案：</p><p></p><h5>Native UI</h5><p></p><p></p><p>Native 的 UI 渲染由系统提供，对资源的使用相对合理，只要编码上保证没有内存泄漏一般不会出现问题。</p><p></p><h5>流媒体</h5><p></p><p></p><p>直播场景占核心地位的渲染来自流媒体，即视频流的渲染，直播视频解码与渲染的 Pipline 流程是视频解码 -&gt; 视频前后处理 -&gt; 视频的渲染，而核心的渲染流程是：</p><p></p><p>CPU 计算需要显示的内容，通过数据总线传给 GPU；GPU 拿到数据，开始渲染数据并保存在帧缓存区中；视频控制器会按照 VSync 信号逐行读取帧缓冲区的数据，经过数模转换传递给显示器显示。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/51/bd/515e93a068756bcc2a6493b60c381ebd.png\" /></p><p>视频渲染图</p><p></p><p>当前主流的视频渲染技术有 OpenGL、Metal、Vulkan 等，这些技术更多的是依托平台，最常见的是 OpenGL，其最大优势是跨平台。Metal 是苹果公司推出的，具有更好的性能。Vulkan 在安卓平台，与 Metal 类似 Vulkan 可以更详细的向显卡描述你的应用程序打算做什么，从而可以获得更好的性能和更小的驱动开销。</p><p></p><p>视频渲染的过程其重要的性能消耗在于频繁的计算、拷贝内容，最直接的方案是减少计算及拷贝，在解码上使用硬解将计算逻辑由 CPU 分散 GPU 进行计算，同时使用平台更优的 Metal 或 Vulkan 方式进行渲染。但这这种方式不适用于部分低端机（GPU 相对差的机型），安卓机成为突出，针对部分机型需要单独的适配，成本会比较高。但带来的收益也很明显，硬解更加省电，适合长时间的移动端视频播放器和直播，手机电池有限的情况下，使用硬件解码会更加好。减少 CPU 的占用，可以把 CPU 让给别的线程使用，有利于手机的流畅度。</p><p></p><p>低端机的渲染最有效的方案是进行降级，目前直播间所采用的是减少不必要的推拉流、减少动画、降低业务复杂度，保证核心体验等。</p><p></p><h5>Webview</h5><p></p><p></p><p>Webview 的渲染主要消耗在于图片展示、GIF 播放、DOM 计算等，从资源角度入手减少资源的占用，同时让 CPU、运行内存、GPU 资源能及时释放。在课件及互动场景下更多的采用 cocos runtime 容器平替方案，效果比较明显。具体有相关的<a href=\"https://www.infoq.cn/article/Rr7U1xRZ3OvpC7Mtz9Yu\">专项文章</a>\"可以参考。</p><p></p><h5>线程优化</h5><p></p><p></p><p>除上面比较明显的资源消耗大部头之外，从 CPU 角度关注其核心消耗最直接有效的方式莫过于使用调试工具进行摸排。Android 的可以使用 adb 或 AndroidStudio 提供的工具进行调试，iOS 使用 Instruments 进行调试。重点关注占用 CPU 时间片较长的线程或常驻线程，这部分在直播间场景发现比较重的是大量的常驻 log 线程，通过统一的 log 系统将其收敛管控即可。其他沉重的线程也可以使用统一的线程池管控的方案进行优化。</p><p></p><h4>效果</h4><p></p><p></p><h5>内存</h5><p></p><p></p><p>运行内存的优化收益明显，从是从原来的平均 800MB 降至平均 200MB 左右，并且从之前的进入直播间之后一直上升的趋势转为过程会不断回收释放，维持在相对平稳的状态。</p><p></p><p>其中独立进程对于 Android 机型的优化最为明显，平均可释放 300MB 内存。容器化对于课件和笔迹等常驻类直播间的场景优化相对更有效，内存上的表现是回收及时。</p><p></p><h5>CPU 和 FPS</h5><p></p><p></p><p>低端设备上表现最为突出，从 CPU 和 FPS 的表现上观测到，低帧率的现象明显变少。同时从舆情数据上看，卡顿反馈率降低了 80% 左右，其中渲染优化、线程优化、业务降级最为有效，其他用户反馈率也达到了千分位的目标。</p><p></p><h5>黑白屏</h5><p></p><p></p><p>Webview 容器的黑白屏率初期降低了 83% 左右，经过后续的升级迭代最终趋近于 0；Cocos Runtime 容器黑白屏率 0；所有方案对此均有效果，整体资源使用的更优会让黑白屏率变得极低甚至趋近于 0。</p><p></p><h4>总结</h4><p></p><p></p><p>上述就是我们对直播间性能优化所做的一些实践和积累，性能优化是一个长期的工程，需要结合自身的业务特性不断进行打磨，力求极至。</p><p></p><p>除了优化方案，良好的性能监控系及开发规范也很重要，是防止劣化的重要方式，否则性能优化方案取得的收益抵不过业务快速迭代带来的性能黑洞，结合 APM 及相关监控指标可以不断的升级优化措施及规范，不断的落地实践。</p><p></p><p>未来在我们可能还会在资源竞争、CPU 线程调度、GPU 渲染、技术手段简化业务等方面继续深入探究性能优化，后面也会将其中的某些优化方案整理成文章继续分享，也希望各位前辈同行多多指教、探讨！</p><p></p><p>嘉宾介绍</p><p></p><p>于晓鹏</p><p>作业帮直播移动端负责人，在移动端架构设计、性能优化、网络优化、直播等领域有一定探索和实践，致力打造高性能的移动端体验。</p>",
    "publish_time": "2022-06-28 10:43:43",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]