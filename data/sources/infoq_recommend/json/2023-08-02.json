[
  {
    "title": "复杂业务开发之数据存储 ：SQL、数据库组件",
    "url": "https://www.infoq.cn/article/1UOSrFtkpdLSYGWwSYfV",
    "summary": "<p>在现代企业开发中，初级开发者难以掌握开发企业级 Java 应用，中高级开发者则被繁琐任务所占据。为了让大家能快速上手可以解决这个难题的“SoFlu 软件机器人”，前蚂蚁金服技术专家杨彪设计了《2 小时学会 10 个组件“取代”传统 Java 开发》课程，本节为该系列课程的第三讲。</p>\n<p>本节将主要针对 SoFlu 提供的常用组件——SQL及数据库组件展开讲解，同时解决“如何减轻开发者负担，避免数据操作异常？”的问题。要知道，数据存储是每个业务系统中必不可少的部分，也是开发者日常最多的工作，所以这是每位Java开发者的必听课。</p>\n<p>大家在课后可以登录 Gitee 下载 SoFlu 软件机器人客户端进行实践：<a href=\"http://suo.im/8wROo\">点击下载</a></p>\n<p>大家可以扫码添加小助手，进学习群与专家一对一交流：<br />\n<img alt=\"\" src=\"https://static001.infoq.cn/resource/image/e8/c9/e8833a01ba0bc705acab14a572b57cc9.png\" /></p>",
    "publish_time": "2023-08-02 09:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "搜索与分析型数据库论坛｜2023可信数据库发展大会",
    "url": "https://www.infoq.cn/article/9QeZ2pR1mHtFbElOWReC",
    "summary": "<p>近年来，随着非结构化数据成为各类组织数据的增长主力，搜索与分析型数据库发展迅速，关键技术陆续突破，应用场景日益增多，数据规模逐年上升，已成为企业必不可少的核心基础设施。在国产化建设需求持续升级的当下，如何搭建更稳定、安全、高效、智能的搜索与分析型数据库？在数据价值愈发凸显的未来，如何革新技术以更快更好地赋能百行百业？2023年7月5日，搜索与分析型数据库分论坛将邀请业内专家、学者及优秀厂商代表，与业界同仁深入探讨，为行业持续释放、挖掘数据价值注入新动力。</p>",
    "publish_time": "2023-08-02 09:25:58",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "时序时空与图数据库论坛｜2023可信数据库发展大会",
    "url": "https://www.infoq.cn/article/KECYPfa1bgM5YNclFNxl",
    "summary": "<p>从蛰伏、追随到自主创新，时空数据库在短短十几年里取得了里程碑式的飞跃。随着移动互联网、物联网、5G的迅猛发展，时空数据被广泛应用于能源管理、医疗保健等行业，高歌迈入属于它的黄金时代，爆发出惊人的增长姿态。与此同时，时空数据也迎来了不同业务场景下的重重难题。2023年7月5日，时序时空与图数据库分论坛将邀请本领域的专家亲临现场，溯源时序数据库的历史脉络，厘清发展途中面临的技术挑战，勾勒未来创新研发的趋势路径。</p>",
    "publish_time": "2023-08-02 09:26:01",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "互联网行业数据库创新应用论坛｜2023可信数据库发展大会",
    "url": "https://www.infoq.cn/article/lJeYTLuiZlKHevNdelOx",
    "summary": "<p>在大数据与云计算狂飙发展的时代，繁杂巨量的数据信息与快速迭代的新兴业务，引发了互联网企业对数据库技术的持续重构与升级。数据库在企业数字化转型的过程中，究竟发挥着怎样的作用？数据库在架构演进、自研内核优化方面有何实践经验？作为AI时代的新基建，数据库又将迎来怎样的挑战与发展？2023年7月5日，互联网行业数据库创新应用分论坛邀请数位互联网领域的知名技术专家，与数据库从业者共同探讨数据库自研、变革、创新之路。</p>",
    "publish_time": "2023-08-02 09:26:04",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "谷歌语音人工智能AudioPaLM，语音传输瞬间翻译",
    "url": "https://www.infoq.cn/article/6xrUw7llCxkeoebxHek7",
    "summary": "<p><a href=\"https://research.google/\">谷歌</a>\"的研究人员发布了<a href=\"https://arxiv.org/abs/2306.12925\">AudioPaLM</a>\"，这是一个大语言模型（LLM），可以通过语音传输执行文本转语音（TTS）、自动语音识别（ASR）和语音到语音翻译（S2ST）。AudioPaLM是基于<a href=\"https://www.infoq.com/news/2023/06/google-palm2-bard/\">PaLM-2 LLM</a>\"的，在翻译基准测试上优于<a href=\"https://www.infoq.com/news/2022/10/openai-whisper-speech/\">OpenAI的Whisper</a>\"。</p><p></p><p>AudioPaLM是一个基于Transformer的纯解码器模型，它将文本和音频输入组合成单个嵌入表示。与使用离散ASR、机器翻译（MT）和TTS模型等级联的传统S2ST模型不同，AudioPaLM可以保留声学特征，例如说话者的声音。AudioPaLM在S2ST和ASR基准测试中取得了最先进的成绩，并且还展示了零样本能力，对训练数据中不存在的输入和目标组合执行ASR。在<a href=\"https://paperswithcode.com/dataset/fleurs\">FLEURS数据集</a>\"上进行评估时，AudioPaLM在ASR任务上“显著”优于OpenAI的Whisper。</p><p></p><p>InfoQ最近报道了其他几个多语言人工智能语音模型。2022年，<a href=\"https://www.infoq.com/news/2022/10/openai-whisper-speech/\">OpenAI发布了Whisper</a>\"，这是一个基于Transformer的编码器/解码器ASR模型，可以转录和翻译97种不同语言的语音音频。今年早些时候，<a href=\"https://www.infoq.com/news/2023/06/meta-mms-speech-ai/\">Meta发布了MMS</a>\"，这是一个基于wav2vec的模型，可以用1100多种语言进行ASR和TTS。</p><p></p><p>与这些相比，AudioPaLM是一个基于Transformer的纯解码器模型。它是基于预训练的PaLM-2的。然后，将模型的标记字典扩展为包括声学标记，声学标记表示音频波形的短片段。它们被映射到与原始模型中文本标记相同的嵌入空间中。然后，模型的输入可以包括音频和文本。文本输入包括任务的简短描述，例如“[ASR意大利语]”。当模型的输出被解码时，可以使用<a href=\"https://ai.googleblog.com/2022/10/audiolm-language-modeling-approach-to.html\">AudioLM模型</a>\"将声学标记转换回音频波形。</p><p></p><p><img src=\"https://imgopt.infoq.com/news/2023/07/google-audiopalm/en/resources/1audiopalm-architecture-1688226252526.png\" /></p><p></p><p>AudioPaLM的架构图。图片来源：<a href=\"https://google-research.github.io/seanet/audiopalm/examples/\">https://google-research.github.io/seanet/audiopalm/examples/</a>\"</p><p></p><p>AudioPaLM接受了来自100多种语言的数千小时的音频数据训练。它在多个基准上进行了评估，包括<a href=\"https://github.com/facebookresearch/covost\">CoVoST2</a>\"（AST）、<a href=\"https://research.google/resources/datasets/speech-to-speech-translation-corpus/\">CVSS</a>\"（S2ST）和<a href=\"https://github.com/facebookresearch/voxpopuli\">VoxPopuli</a>\"（ASR）。它在AST和S2ST上的表现优于基线模型，在ASR上具有“竞争力”。在使用<a href=\"https://paperswithcode.com/dataset/fleurs\">FLEURS</a>\"基准的零样本AST中，AudioPaLM“显著”优于Whisper。它在ASR任务上也优于Whisper，Whisper接受过ASR任务所涉及的语言的训练，而AudioPaLM没有。</p><p></p><p>研究人员还评估了AudioPaLM的音频生成质量，特别是在S2ST期间保留原始说话者的声音方面。他们结合“客观指标和主观评估研究”将其性能与基线模型进行比较，发现它“显著”优于基线。在他们的论文中，谷歌团队指出，需要更好的基准来衡量音频生成的质量：</p><p></p><p></p><blockquote>与文本相比，生成文本/音频任务的既定基准集的丰富性还不够成熟。这项工作主要集中在语音识别和语音翻译，它们的基准比较成熟。为生成音频任务建立更多的基准和指标将有助于进一步加快该研究。</blockquote><p></p><p></p><p>一些用户在Hacker News的帖子中<a href=\"https://news.ycombinator.com/item?id=36443676\">讨论了AudioPaLM</a>\"。在回答关于LLM翻译准确性的问题时，鉴于其会“产生幻觉”的倾向，一位用户表示，对于像AudioPaLM这样最先进的模型，幻觉“几乎不存在”。关于AudioPaLM的翻译，另一位用户观察到：</p><p></p><p></p><blockquote>令人印象深刻的是，它将“Morgenstund hat Gold imMund”（早晨口中含金子）翻译成了相应的英语表达“早起的鸟儿有虫吃”，而不是直译。</blockquote><p></p><p></p><p><a href=\"https://google-research.github.io/seanet/audiopalm/examples/\">AudioPaLM输出的若干示例</a>\"可以在网上找到。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/07/google-audiopalm/\">https://www.infoq.com/news/2023/07/google-audiopalm/</a>\"</p><p></p>",
    "publish_time": "2023-08-02 10:36:51",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "超越GPT-4！加州大学伯克利分校与微软研究院合作开源大型语言模型Gorilla",
    "url": "https://www.infoq.cn/article/gPRaLM4Edvq8ZtEN7Ar6",
    "summary": "<p>来自<a href=\"https://cs.berkeley.edu/\">加州大学伯克利分校</a>\"和<a href=\"https://www.microsoft.com/en-us/research/\">微软研究院</a>\"的研究人员开源了<a href=\"https://gorilla.cs.berkeley.edu/\">Gorilla</a>\"，这是一个可以编写API调用代码的大型语言模型（LLM）。在度量代码生成准确性的实验中，Gorilla优于包括GPT-4在内的几个基线模型。</p><p>&nbsp;</p><p>Gorilla被描述为“LLM的API应用商店”。它基于开源大型语言模型<a href=\"https://www.infoq.com/news/2023/03/meta-ai-large-language-model/\">LLaMA</a>\"。这个LLM在APIBench上做了调优。APIBench是一个新的ML模型API描述数据集，托管在<a href=\"https://huggingface.co/docs/hub/index\">HuggingFace</a>\"、<a href=\"https://pytorch.org/hub/\">TorchHub</a>\"和<a href=\"https://www.tensorflow.org/hub\">TensorHub</a>\"上。Gorilla还可以调用API定义的外部文档数据库，让它在访问新的API时无需重新训练。借助Gorilla，开发人员可以创建问题的自然语言描述，例如“调用图像分类模型，参数个数不多于10M，但ImageNet准确性至少要达到70%。”然后，Gorilla将输出Python代码，调用具有适当选项的ML模型。按照作者的说法：</p><p></p><p></p><blockquote>在各个领域，LLM正迅速普及。我们重点关注的是那些可以提高LLM在特定任务中API识别准确性的技术——这是这项技术发展中一个重要但经常被忽视的方面。作为一种通用语言，API函数能够实现各种系统间的有效通信。正确使用API可以提高LLM与更广阔世界中的工具进行交互的能力。</blockquote><p></p><p>&nbsp;</p><p>像<a href=\"https://www.infoq.com/news/2023/04/openai-gpt4/\">GPT-4</a>\"这样的LLM在包括生成代码在内的各种任务上都有出色的表现。然而，它们的API知识在训练时被“固定”了，因此，无法生成代码来调用更新的API。此外，它们经常会产生幻觉——在代码生成时，它们输出的代码可能会调用不存在的API。InfoQ之前报道过人们近来为解决这些问题所做的努力，例如，<a href=\"https://www.infoq.com/news/2023/04/meta-toolformer/\">Meta的Toolformer</a>\"可以调用外部服务API，<a href=\"https://www.infoq.com/news/2023/05/chatgpt-retrieval-plugin/\">ChatGPT的插件系统</a>\"可以利用外部资源来增强LLM。</p><p>&nbsp;</p><p>不过，伯克利团队指出，那些方法是利用API调用的例子来提示LLM。相比之下，Gorilla的方法侧重于“系统化地评估并构建一个可供未来使用的管道”。首先，研究人员构建了APIBench数据集。他们从HuggingFace模型中心、PyTorch中心和TensorFlow中心收集了所有的模型卡。经过过滤之后，获得了一个包含1645个API调用的集合。对于其中的每一个调用，研究人员使用GPT-4生成了一个指令-API对数据集，用于对Gorilla进行调优。</p><p>&nbsp;</p><p>在对Gorilla的输出进行评价时，一个主要的挑战是识别幻觉。首先，团队将幻觉定义为模型输出调用了在API定义外部数据库中不存在的API。这与错误不同，错误是指模型输出错误地调用了“真实存在”的API。团队使用所生成代码的抽象语法树（AST）来匹配数据库中的API和用于评估的测试集。在零样本任务中使用AST准确性度量，Gorilla比GPT-4高了20.43%。</p><p>&nbsp;</p><p>Gorilla的主要作者<a href=\"https://news.ycombinator.com/item?id=36333290\">Shishir Patil参加了黑客新闻关于这项工作的讨论</a>\"，并回答了几个问题。当被问及该模型的许可是否允许商业使用时，Patil指出，Gorilla有三个版本，基于LLaMA的版本没有商业应用许可，但基于MPT-7 base和Falcon-7B的版本可以。还有一位用户问，Gorilla与<a href=\"https://docs.langchain.com/docs/\">LangChain</a>\"相比怎么样。Patil回答说：</p><p></p><p></p><blockquote>Langchain是一个很棒的项目，它试图教代理如何利用提示来使用工具。我们对此的看法是，如果你想在数以千计的API之间做出选择，那么提示不具有可扩展性。而Gorilla作为一个LLM，可以帮你挑选API并编写语义、语法正确的API调用！它可以方便地替代Langchain！</blockquote><p></p><p>&nbsp;</p><p>Gorilla的<a href=\"https://github.com/ShishirPatil/gorilla\">代码和模型文件</a>\"托管在GitHub上。<a href=\"https://colab.research.google.com/drive/1DEBPsccVLF_aUnmD0FwPeHFrtdC0QIUP?usp=sharing\">这里</a>\"还有一个在谷歌Colab笔记本中的模型演示。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/07/microsoft-gorilla/\">https://www.infoq.com/news/2023/07/microsoft-gorilla/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/IQrajVXjyLTw1QjFxHV5\">比Bing更早将LLM集成到搜索引擎中，这家由谷歌前高管创立的公司为什么还是失败了？</a>\"</p><p><a href=\"https://www.infoq.cn/article/H2ZgktSAypUhC2I3zP2B\">马斯克等人热捧：高薪缺人，但要懂全栈懂LLM，一个全新职业正在兴起！</a>\"</p>",
    "publish_time": "2023-08-02 10:52:20",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AIGC 应用与风险控制，你们先探索，我们紧随其后 ｜ArchSummit闭门会",
    "url": "https://www.infoq.cn/article/XzDAFw05DSkvCkfvkoj9",
    "summary": "<p>随着ChatGPT的火爆，大模型逐渐走入企业的视野，但在实际应用中存在着各种挑战与困难。在&nbsp;7&nbsp;月&nbsp;21&nbsp;日&nbsp;<a href=\"https://archsummit.infoq.cn/202307/shenzhen/\">ArchSummit全球架构师峰会（深圳站）</a>\"上，我们就&nbsp;AIGC&nbsp;在各行业的应用与风险控制展开了深入的讨论。以下为脱敏版本的分享纪要，希望对您有所启发。</p><p></p><h4>精彩分享1</h4><p></p><p>我们正在研发类似数字人的虚拟主播，以用于金融领域，如财报智能解读等。我们当前的方案是利用ChatGPT语言模型，并配合GRM来实现目标。我们选择在本地部署ChatGLM-6B模型，配合使用Stable&nbsp;Diffusion处理图片。</p><p></p><p>在常规情况下，我们会先根据上下文生成评论，然后进行PDF解析和添加图片，最后生成一分钟以内的播报。</p><p></p><p>另一个项目是关于垂直领域的场景，我们正在探索如何结合风控原有数据，利用Chatgpt进行解读。其中包括使用上下文或langchain等方式。</p><p></p><p>目前，这方面的效果还在验证阶段，不过它的效果将依赖于我们系统中台的能力。我们正在努力将中台的所有功能和服务能力转变为函数和服务接口，并通过GPT的提问方式调用这些接口，进而生成文本。</p><p></p><p>最后，我们团队正在认真考虑 AI 相关的风险问题。但是我们选择保守一些，让其他竞争者先探索，我们主要关注一些较浅层次的应用。</p><p></p><h4>精彩分享2</h4><p></p><p></p><p>在产品探索上，我们已经应用了两个小点。首先是，我们公司的市场品牌宣传，图文问题已经解决，以至于原来做这个事情的同事已经可以去别的部门了。</p><p></p><p>原来可能要花三天打磨一个80分的文章，现在一天可以产出5~10&nbsp;篇70~75分的文章。我们产出的这些文章主要用在SEO上，例如敏捷迭代、瀑布管理、DEBOR等概念的介绍。这些内容并不需要质量非常高，只需要达到一定的程度。现在来看，这类型的内容可以由&nbsp;AI&nbsp;生成的。</p><p></p><p>另外是第二个应用——生成单元测试的用例。这个过程是建立在需求描述清楚，特别是函数的注释清楚的情况下，以前我们都会根据函数的参数类型和注释生成测试用例，现在这个过程更进一步，变得更方便了。</p><p></p><p>现在大约有60-70%的单元测试就是这样生成出来的。但至于这个提效有多少，说实话，还不一定。我们用Copilot辅助写代码，感觉上很好，但很难量化它最终的产出效果。不像写营销文，我可以用1/4的成本，提升3~5倍的效率。目前来说我们内部的形容，大模型是一个更好用的补全工具。</p><p></p><h4>精彩分享3</h4><p></p><p></p><p>在我们内部沟通时，我注意到一个重要问题。当培训员工时，我会告诉他们何时可以使用某种功能，何时不可以使用。这对于掌握这项技术非常关键，因为编辑这个功能的开启时机非常重要。</p><p></p><p>我曾经亲自尝试过，唯一能够真正快速掌握并充分利用这项技术的方法是，将需求拆分成函数级别，确保函数的通用性。这样，我就可以解决问题并生成相应的代码段。</p><p></p><p>然而，如果函数与业务过于相关，复制粘贴可能会解决当前问题，但长远来看是行不通的，因为系统接口并不会理解你的需求。因此，在内部应用中，我们需要确保代码的通用性，以确保我们的系统能够高效运作。</p><p></p><h4>精彩分享4</h4><p></p><p></p><p>我想分享两方面&nbsp;Security&nbsp;for&nbsp;AI&nbsp;&amp;&nbsp;&nbsp;AI&nbsp;for&nbsp;Security。首先是&nbsp;Security&nbsp;for&nbsp;AI，对于千片卡以上的大型模型，很可能需要使用公有云来运行。尽管我们可以通过专线接入云服务，但是我们也意识到这样做可能存在较大的风险。</p><p></p><p>目前我们正在思考如何规避这些风险。例如，将大型模型运行在云上需要对接机器学习管理平台，这些平台提供模型算法和基础能力，并能直接调用底层资源配置。</p><p></p><p>在这个过程中，权限管理是一个头疼的问题。普通用户的权限管理相对简单，每类用户的权限基本上没有太多管控，他们都可以直接连接到平台进行操作、调参和模型调优。然而，一旦员工离职，可能花费了数月时间训练出的模型就可能被直接拷走。</p><p></p><p>为了保障数据的安全共享，我们目前正在内部采用TEE（可信执行环境）技术，用于不同部门间的数据共享。这样至少能确保数据是可信的，不会被窃取。但由于TEE技术受限于卡片性能，我们正在考虑如何提升性能。</p><p></p><p>目前，据说H800每百次可以支持一次计算性能的优化，然而目前性能上仍然相对较差。因此，我们正在研究是否有组合方案，例如将CPU的能力与A100和A800卡的性能结合，以实现隐私计算。</p><p></p><p>其次是AI&nbsp;for&nbsp;Security，安全领域一直面临着一个难解决的问题，即安全运维。无论是国外还是国内，数据安全需求不断增加，因为需要同时记录流量日志、事件和报警等信息，这对于每家企业来说数据量都非常庞大。</p><p></p><p>例如，当攻击流量涌现时，如何分析哪些数据是攻击的，AI&nbsp;在这方面能够提供很大的帮助。国外的一些公司，比如微软，已经将内部的安全运维交给了\"Copilot\"，通过对话形式，安全运维人员可以直接了解每天关注的事件及其解决方案。</p><p></p><p>而国内主要是在已有的数据上进行自动化统计，真正智能化生成的内容还相对较少。不过，这个方向对于安全领域来说是一个值得探索的方向。</p><p></p><h4>精彩分享5</h4><p></p><p></p><p>AI大型模型具有几个优势。首先，它拥有广泛的知识库，尽管随着链路的加深，有时知识会有些模糊，但它所知道的比单个人类要丰富；其次，它具备强大的推理能力，特别在复杂的领域如理赔案件判定和保险条件评估方面，可以代替人力进行基础性的决策，从而节省了理赔保全等事务处理所需的人工劳动力，保留了一些专家级别的人力资源，提升了效率。然而，在生产关系上，生产力的提升带来的是效率的提升，而岗位本身并不会消失。人工审核在某些领域仍然是必要的。</p><p></p><p>而大型模型不是简单的0和1的准确判断，而是通过自回归推断来完成，在某种程度上是一种更大概率的预测。在To&nbsp;B领域追求精准的情况下，很难完全取代某些工种，AI大型模型更多地作为副驾驶的存在，用于提高效率和生产力，但无法改变生产关系的基本需求，产品的需求仍然存在。</p><p></p><p>另一个方面是在风控场景中的应用。公司尝试使用智能助手辅助代理人使用复杂产品的APP。最后，大型模型在内容生成领域有着广泛的应用，如文本、音频和视频生成。结合数字人技术，可以用于培训行业或保险产品推荐。例如，保险计划书，未来可能由代理人的数字分身来向客户解释，</p><p></p><h4>精彩分享6</h4><p></p><p></p><p>我们的客户中有很多拥有大量文档，数量达到几千万份，这些文档的探索过程中发现了一些有意思的情况。在产品设计初期，由于搜索能力尚未完善，这些文档的潜在价值无法充分发挥，交互体验也不尽如人意。然而，随着搜索能力的提升，我们发现许多交互问题得到了解决。</p><p></p><p>然而，我们又发现搜索能力主要服务于普通员工，但存在一个场景尚未涵盖，即大部分政府单位，领导通常有秘书协助。他们需要整理相关文档内容。在政务领域等特定应用中，领导和局长需要查看与今年及前几年相关联的数据，秘书需要将这些相关内容整理并提供给领导。</p><p></p><p>这也是一个非常有市场需求的产品，目前，我们已经在开发阶段，通过模型来理解文档背后的逻辑，并将相关内容组织整理，模拟秘书的工作，然后将所需信息整理打包供查看和调阅。</p><p></p><h4>精彩分享7</h4><p></p><p></p><p>为了保证核电站的安全，我们需要投入大约500亿的资金，其中有2/3用于预防措施。核电发电成本本身非常低，但由于安全要求高，大部分投资都用于设备的维护和人员的配备与培训。核电站面临的主要问题是如何防止人员和设备出现错误。</p><p></p><p>关于设备出错，目前的解决方案效率较低，我们需要定期对设备进行检查和维修，通过设备运行的历史数据，我们可以判断出何时需要维修，然而，这项任务对人员来说并不容易实现。因此，我们将这项任务交由AI来执行，</p><p></p><p>全世界核电厂的数据都是公开透明的。每个核电站的设备信息、运行情况、维修经验等都在全球范围内共享，我们建立了一个经验反馈系统。我们利用大模型进行核电厂的经验反馈数据分析。通过将全球所有核电厂的数据输入给这个系统，它可以根据我们的设备信息来判断可能存在的风险和后果。通过这种方式，我们能够更好地保障核电站的安全和运行效率。</p><p></p><p>针对人员减少出错的问题，培训是一个非常重要的措施。然而，培训成本高昂且效率较低。在需求分析、过程实施、效果评估以及人员的孪生建模等方面，我们现在主要依赖人力来完成，通过AI，我们可以实现更精准的培训，它可以自动判断学员需要什么样的培训。</p><p></p><p>我自己是核电领域的第一个数字人，我用它来讲解核物理中的反应堆。不过我们希望进一步实现问答式的知识库。通过AI分析，我们可以直接提供学员所需的多模态教学内容，包括语音和视频教学。学员可以边学习边进行交互式评估。</p><p></p><p>我们正在开发一个名为\"数字教室\"的系统，将其作为教室的机器人，放置在教室中。通过这个系统，教员可以假装成学员，有意制造错误让机器人来分析是否需要相应的知识点。如果机器人能够说服教员，我们就可以投入使用。在人才培养领域，我们利用数字人技术代替了辅导员。</p><p></p><h4>精彩分享8</h4><p></p><p></p><p>风险控制这块，可以考虑让内部员工签署保密协议，以确保他们不会泄露关键信息。另一个方法是通过控制IDE上传的大小来限制代码的传递。这样可以确保大规模的代码不会全部上传，只传递输入和结果等关键部分。敏感词扫描也是一个有效的措施，可以检测和阻止包含敏感信息的内容上传。</p><p></p><p>例如，像清华大模型等大型模型可以限制上传的大小，只允许传递部分关键信息，这样可以降低泄露的风险。虽然你可以询问大规模的问题，但是返回结果可能会受到限制，以保护核心技术和数据。</p><p></p><p>另外，设置一层网关并进行关键词拦截是一个有效的措施。通过在网关上设置关键词拦截功能，可以阻止包含敏感信息或公司核心技术的数据传递到外部。</p>",
    "publish_time": "2023-08-02 11:44:43",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]