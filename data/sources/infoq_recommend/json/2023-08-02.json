[
  {
    "title": "复杂业务开发之数据存储 ：SQL、数据库组件",
    "url": "https://www.infoq.cn/article/1UOSrFtkpdLSYGWwSYfV",
    "summary": "<p>在现代企业开发中，初级开发者难以掌握开发企业级 Java 应用，中高级开发者则被繁琐任务所占据。为了让大家能快速上手可以解决这个难题的“SoFlu 软件机器人”，前蚂蚁金服技术专家杨彪设计了《2 小时学会 10 个组件“取代”传统 Java 开发》课程，本节为该系列课程的第三讲。</p>\n<p>本节将主要针对 SoFlu 提供的常用组件——SQL及数据库组件展开讲解，同时解决“如何减轻开发者负担，避免数据操作异常？”的问题。要知道，数据存储是每个业务系统中必不可少的部分，也是开发者日常最多的工作，所以这是每位Java开发者的必听课。</p>\n<p>大家在课后可以登录 Gitee 下载 SoFlu 软件机器人客户端进行实践：<a href=\"http://suo.im/8wROo\">点击下载</a></p>\n<p>大家可以扫码添加小助手，进学习群与专家一对一交流：<br />\n<img alt=\"\" src=\"https://static001.infoq.cn/resource/image/e8/c9/e8833a01ba0bc705acab14a572b57cc9.png\" /></p>",
    "publish_time": "2023-08-02 09:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "搜索与分析型数据库论坛｜2023可信数据库发展大会",
    "url": "https://www.infoq.cn/article/9QeZ2pR1mHtFbElOWReC",
    "summary": "<p>近年来，随着非结构化数据成为各类组织数据的增长主力，搜索与分析型数据库发展迅速，关键技术陆续突破，应用场景日益增多，数据规模逐年上升，已成为企业必不可少的核心基础设施。在国产化建设需求持续升级的当下，如何搭建更稳定、安全、高效、智能的搜索与分析型数据库？在数据价值愈发凸显的未来，如何革新技术以更快更好地赋能百行百业？2023年7月5日，搜索与分析型数据库分论坛将邀请业内专家、学者及优秀厂商代表，与业界同仁深入探讨，为行业持续释放、挖掘数据价值注入新动力。</p>",
    "publish_time": "2023-08-02 09:25:58",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "时序时空与图数据库论坛｜2023可信数据库发展大会",
    "url": "https://www.infoq.cn/article/KECYPfa1bgM5YNclFNxl",
    "summary": "<p>从蛰伏、追随到自主创新，时空数据库在短短十几年里取得了里程碑式的飞跃。随着移动互联网、物联网、5G的迅猛发展，时空数据被广泛应用于能源管理、医疗保健等行业，高歌迈入属于它的黄金时代，爆发出惊人的增长姿态。与此同时，时空数据也迎来了不同业务场景下的重重难题。2023年7月5日，时序时空与图数据库分论坛将邀请本领域的专家亲临现场，溯源时序数据库的历史脉络，厘清发展途中面临的技术挑战，勾勒未来创新研发的趋势路径。</p>",
    "publish_time": "2023-08-02 09:26:01",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "互联网行业数据库创新应用论坛｜2023可信数据库发展大会",
    "url": "https://www.infoq.cn/article/lJeYTLuiZlKHevNdelOx",
    "summary": "<p>在大数据与云计算狂飙发展的时代，繁杂巨量的数据信息与快速迭代的新兴业务，引发了互联网企业对数据库技术的持续重构与升级。数据库在企业数字化转型的过程中，究竟发挥着怎样的作用？数据库在架构演进、自研内核优化方面有何实践经验？作为AI时代的新基建，数据库又将迎来怎样的挑战与发展？2023年7月5日，互联网行业数据库创新应用分论坛邀请数位互联网领域的知名技术专家，与数据库从业者共同探讨数据库自研、变革、创新之路。</p>",
    "publish_time": "2023-08-02 09:26:04",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "谷歌语音人工智能AudioPaLM，语音传输瞬间翻译",
    "url": "https://www.infoq.cn/article/6xrUw7llCxkeoebxHek7",
    "summary": "<p><a href=\"https://research.google/\">谷歌</a>\"的研究人员发布了<a href=\"https://arxiv.org/abs/2306.12925\">AudioPaLM</a>\"，这是一个大语言模型（LLM），可以通过语音传输执行文本转语音（TTS）、自动语音识别（ASR）和语音到语音翻译（S2ST）。AudioPaLM是基于<a href=\"https://www.infoq.com/news/2023/06/google-palm2-bard/\">PaLM-2 LLM</a>\"的，在翻译基准测试上优于<a href=\"https://www.infoq.com/news/2022/10/openai-whisper-speech/\">OpenAI的Whisper</a>\"。</p><p></p><p>AudioPaLM是一个基于Transformer的纯解码器模型，它将文本和音频输入组合成单个嵌入表示。与使用离散ASR、机器翻译（MT）和TTS模型等级联的传统S2ST模型不同，AudioPaLM可以保留声学特征，例如说话者的声音。AudioPaLM在S2ST和ASR基准测试中取得了最先进的成绩，并且还展示了零样本能力，对训练数据中不存在的输入和目标组合执行ASR。在<a href=\"https://paperswithcode.com/dataset/fleurs\">FLEURS数据集</a>\"上进行评估时，AudioPaLM在ASR任务上“显著”优于OpenAI的Whisper。</p><p></p><p>InfoQ最近报道了其他几个多语言人工智能语音模型。2022年，<a href=\"https://www.infoq.com/news/2022/10/openai-whisper-speech/\">OpenAI发布了Whisper</a>\"，这是一个基于Transformer的编码器/解码器ASR模型，可以转录和翻译97种不同语言的语音音频。今年早些时候，<a href=\"https://www.infoq.com/news/2023/06/meta-mms-speech-ai/\">Meta发布了MMS</a>\"，这是一个基于wav2vec的模型，可以用1100多种语言进行ASR和TTS。</p><p></p><p>与这些相比，AudioPaLM是一个基于Transformer的纯解码器模型。它是基于预训练的PaLM-2的。然后，将模型的标记字典扩展为包括声学标记，声学标记表示音频波形的短片段。它们被映射到与原始模型中文本标记相同的嵌入空间中。然后，模型的输入可以包括音频和文本。文本输入包括任务的简短描述，例如“[ASR意大利语]”。当模型的输出被解码时，可以使用<a href=\"https://ai.googleblog.com/2022/10/audiolm-language-modeling-approach-to.html\">AudioLM模型</a>\"将声学标记转换回音频波形。</p><p></p><p><img src=\"https://imgopt.infoq.com/news/2023/07/google-audiopalm/en/resources/1audiopalm-architecture-1688226252526.png\" /></p><p></p><p>AudioPaLM的架构图。图片来源：<a href=\"https://google-research.github.io/seanet/audiopalm/examples/\">https://google-research.github.io/seanet/audiopalm/examples/</a>\"</p><p></p><p>AudioPaLM接受了来自100多种语言的数千小时的音频数据训练。它在多个基准上进行了评估，包括<a href=\"https://github.com/facebookresearch/covost\">CoVoST2</a>\"（AST）、<a href=\"https://research.google/resources/datasets/speech-to-speech-translation-corpus/\">CVSS</a>\"（S2ST）和<a href=\"https://github.com/facebookresearch/voxpopuli\">VoxPopuli</a>\"（ASR）。它在AST和S2ST上的表现优于基线模型，在ASR上具有“竞争力”。在使用<a href=\"https://paperswithcode.com/dataset/fleurs\">FLEURS</a>\"基准的零样本AST中，AudioPaLM“显著”优于Whisper。它在ASR任务上也优于Whisper，Whisper接受过ASR任务所涉及的语言的训练，而AudioPaLM没有。</p><p></p><p>研究人员还评估了AudioPaLM的音频生成质量，特别是在S2ST期间保留原始说话者的声音方面。他们结合“客观指标和主观评估研究”将其性能与基线模型进行比较，发现它“显著”优于基线。在他们的论文中，谷歌团队指出，需要更好的基准来衡量音频生成的质量：</p><p></p><p></p><blockquote>与文本相比，生成文本/音频任务的既定基准集的丰富性还不够成熟。这项工作主要集中在语音识别和语音翻译，它们的基准比较成熟。为生成音频任务建立更多的基准和指标将有助于进一步加快该研究。</blockquote><p></p><p></p><p>一些用户在Hacker News的帖子中<a href=\"https://news.ycombinator.com/item?id=36443676\">讨论了AudioPaLM</a>\"。在回答关于LLM翻译准确性的问题时，鉴于其会“产生幻觉”的倾向，一位用户表示，对于像AudioPaLM这样最先进的模型，幻觉“几乎不存在”。关于AudioPaLM的翻译，另一位用户观察到：</p><p></p><p></p><blockquote>令人印象深刻的是，它将“Morgenstund hat Gold imMund”（早晨口中含金子）翻译成了相应的英语表达“早起的鸟儿有虫吃”，而不是直译。</blockquote><p></p><p></p><p><a href=\"https://google-research.github.io/seanet/audiopalm/examples/\">AudioPaLM输出的若干示例</a>\"可以在网上找到。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/07/google-audiopalm/\">https://www.infoq.com/news/2023/07/google-audiopalm/</a>\"</p><p></p>",
    "publish_time": "2023-08-02 10:36:51",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "超越GPT-4！加州大学伯克利分校与微软研究院合作开源大型语言模型Gorilla",
    "url": "https://www.infoq.cn/article/gPRaLM4Edvq8ZtEN7Ar6",
    "summary": "<p>来自<a href=\"https://cs.berkeley.edu/\">加州大学伯克利分校</a>\"和<a href=\"https://www.microsoft.com/en-us/research/\">微软研究院</a>\"的研究人员开源了<a href=\"https://gorilla.cs.berkeley.edu/\">Gorilla</a>\"，这是一个可以编写API调用代码的大型语言模型（LLM）。在度量代码生成准确性的实验中，Gorilla优于包括GPT-4在内的几个基线模型。</p><p>&nbsp;</p><p>Gorilla被描述为“LLM的API应用商店”。它基于开源大型语言模型<a href=\"https://www.infoq.com/news/2023/03/meta-ai-large-language-model/\">LLaMA</a>\"。这个LLM在APIBench上做了调优。APIBench是一个新的ML模型API描述数据集，托管在<a href=\"https://huggingface.co/docs/hub/index\">HuggingFace</a>\"、<a href=\"https://pytorch.org/hub/\">TorchHub</a>\"和<a href=\"https://www.tensorflow.org/hub\">TensorHub</a>\"上。Gorilla还可以调用API定义的外部文档数据库，让它在访问新的API时无需重新训练。借助Gorilla，开发人员可以创建问题的自然语言描述，例如“调用图像分类模型，参数个数不多于10M，但ImageNet准确性至少要达到70%。”然后，Gorilla将输出Python代码，调用具有适当选项的ML模型。按照作者的说法：</p><p></p><p></p><blockquote>在各个领域，LLM正迅速普及。我们重点关注的是那些可以提高LLM在特定任务中API识别准确性的技术——这是这项技术发展中一个重要但经常被忽视的方面。作为一种通用语言，API函数能够实现各种系统间的有效通信。正确使用API可以提高LLM与更广阔世界中的工具进行交互的能力。</blockquote><p></p><p>&nbsp;</p><p>像<a href=\"https://www.infoq.com/news/2023/04/openai-gpt4/\">GPT-4</a>\"这样的LLM在包括生成代码在内的各种任务上都有出色的表现。然而，它们的API知识在训练时被“固定”了，因此，无法生成代码来调用更新的API。此外，它们经常会产生幻觉——在代码生成时，它们输出的代码可能会调用不存在的API。InfoQ之前报道过人们近来为解决这些问题所做的努力，例如，<a href=\"https://www.infoq.com/news/2023/04/meta-toolformer/\">Meta的Toolformer</a>\"可以调用外部服务API，<a href=\"https://www.infoq.com/news/2023/05/chatgpt-retrieval-plugin/\">ChatGPT的插件系统</a>\"可以利用外部资源来增强LLM。</p><p>&nbsp;</p><p>不过，伯克利团队指出，那些方法是利用API调用的例子来提示LLM。相比之下，Gorilla的方法侧重于“系统化地评估并构建一个可供未来使用的管道”。首先，研究人员构建了APIBench数据集。他们从HuggingFace模型中心、PyTorch中心和TensorFlow中心收集了所有的模型卡。经过过滤之后，获得了一个包含1645个API调用的集合。对于其中的每一个调用，研究人员使用GPT-4生成了一个指令-API对数据集，用于对Gorilla进行调优。</p><p>&nbsp;</p><p>在对Gorilla的输出进行评价时，一个主要的挑战是识别幻觉。首先，团队将幻觉定义为模型输出调用了在API定义外部数据库中不存在的API。这与错误不同，错误是指模型输出错误地调用了“真实存在”的API。团队使用所生成代码的抽象语法树（AST）来匹配数据库中的API和用于评估的测试集。在零样本任务中使用AST准确性度量，Gorilla比GPT-4高了20.43%。</p><p>&nbsp;</p><p>Gorilla的主要作者<a href=\"https://news.ycombinator.com/item?id=36333290\">Shishir Patil参加了黑客新闻关于这项工作的讨论</a>\"，并回答了几个问题。当被问及该模型的许可是否允许商业使用时，Patil指出，Gorilla有三个版本，基于LLaMA的版本没有商业应用许可，但基于MPT-7 base和Falcon-7B的版本可以。还有一位用户问，Gorilla与<a href=\"https://docs.langchain.com/docs/\">LangChain</a>\"相比怎么样。Patil回答说：</p><p></p><p></p><blockquote>Langchain是一个很棒的项目，它试图教代理如何利用提示来使用工具。我们对此的看法是，如果你想在数以千计的API之间做出选择，那么提示不具有可扩展性。而Gorilla作为一个LLM，可以帮你挑选API并编写语义、语法正确的API调用！它可以方便地替代Langchain！</blockquote><p></p><p>&nbsp;</p><p>Gorilla的<a href=\"https://github.com/ShishirPatil/gorilla\">代码和模型文件</a>\"托管在GitHub上。<a href=\"https://colab.research.google.com/drive/1DEBPsccVLF_aUnmD0FwPeHFrtdC0QIUP?usp=sharing\">这里</a>\"还有一个在谷歌Colab笔记本中的模型演示。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/07/microsoft-gorilla/\">https://www.infoq.com/news/2023/07/microsoft-gorilla/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/IQrajVXjyLTw1QjFxHV5\">比Bing更早将LLM集成到搜索引擎中，这家由谷歌前高管创立的公司为什么还是失败了？</a>\"</p><p><a href=\"https://www.infoq.cn/article/H2ZgktSAypUhC2I3zP2B\">马斯克等人热捧：高薪缺人，但要懂全栈懂LLM，一个全新职业正在兴起！</a>\"</p>",
    "publish_time": "2023-08-02 10:52:20",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AIGC 应用与风险控制，你们先探索，我们紧随其后 ｜ArchSummit闭门会",
    "url": "https://www.infoq.cn/article/XzDAFw05DSkvCkfvkoj9",
    "summary": "<p>随着ChatGPT的火爆，大模型逐渐走入企业的视野，但在实际应用中存在着各种挑战与困难。在&nbsp;7&nbsp;月&nbsp;21&nbsp;日&nbsp;<a href=\"https://archsummit.infoq.cn/202307/shenzhen/\">ArchSummit全球架构师峰会（深圳站）</a>\"上，我们就&nbsp;AIGC&nbsp;在各行业的应用与风险控制展开了深入的讨论。以下为脱敏版本的分享纪要，希望对您有所启发。</p><p></p><h4>精彩分享1</h4><p></p><p>我们正在研发类似数字人的虚拟主播，以用于金融领域，如财报智能解读等。我们当前的方案是利用ChatGPT语言模型，并配合GRM来实现目标。我们选择在本地部署ChatGLM-6B模型，配合使用Stable&nbsp;Diffusion处理图片。</p><p></p><p>在常规情况下，我们会先根据上下文生成评论，然后进行PDF解析和添加图片，最后生成一分钟以内的播报。</p><p></p><p>另一个项目是关于垂直领域的场景，我们正在探索如何结合风控原有数据，利用Chatgpt进行解读。其中包括使用上下文或langchain等方式。</p><p></p><p>目前，这方面的效果还在验证阶段，不过它的效果将依赖于我们系统中台的能力。我们正在努力将中台的所有功能和服务能力转变为函数和服务接口，并通过GPT的提问方式调用这些接口，进而生成文本。</p><p></p><p>最后，我们团队正在认真考虑 AI 相关的风险问题。但是我们选择保守一些，让其他竞争者先探索，我们主要关注一些较浅层次的应用。</p><p></p><h4>精彩分享2</h4><p></p><p></p><p>在产品探索上，我们已经应用了两个小点。首先是，我们公司的市场品牌宣传，图文问题已经解决，以至于原来做这个事情的同事已经可以去别的部门了。</p><p></p><p>原来可能要花三天打磨一个80分的文章，现在一天可以产出5~10&nbsp;篇70~75分的文章。我们产出的这些文章主要用在SEO上，例如敏捷迭代、瀑布管理、DEBOR等概念的介绍。这些内容并不需要质量非常高，只需要达到一定的程度。现在来看，这类型的内容可以由&nbsp;AI&nbsp;生成的。</p><p></p><p>另外是第二个应用——生成单元测试的用例。这个过程是建立在需求描述清楚，特别是函数的注释清楚的情况下，以前我们都会根据函数的参数类型和注释生成测试用例，现在这个过程更进一步，变得更方便了。</p><p></p><p>现在大约有60-70%的单元测试就是这样生成出来的。但至于这个提效有多少，说实话，还不一定。我们用Copilot辅助写代码，感觉上很好，但很难量化它最终的产出效果。不像写营销文，我可以用1/4的成本，提升3~5倍的效率。目前来说我们内部的形容，大模型是一个更好用的补全工具。</p><p></p><h4>精彩分享3</h4><p></p><p></p><p>在我们内部沟通时，我注意到一个重要问题。当培训员工时，我会告诉他们何时可以使用某种功能，何时不可以使用。这对于掌握这项技术非常关键，因为编辑这个功能的开启时机非常重要。</p><p></p><p>我曾经亲自尝试过，唯一能够真正快速掌握并充分利用这项技术的方法是，将需求拆分成函数级别，确保函数的通用性。这样，我就可以解决问题并生成相应的代码段。</p><p></p><p>然而，如果函数与业务过于相关，复制粘贴可能会解决当前问题，但长远来看是行不通的，因为系统接口并不会理解你的需求。因此，在内部应用中，我们需要确保代码的通用性，以确保我们的系统能够高效运作。</p><p></p><h4>精彩分享4</h4><p></p><p></p><p>我想分享两方面&nbsp;Security&nbsp;for&nbsp;AI&nbsp;&amp;&nbsp;&nbsp;AI&nbsp;for&nbsp;Security。首先是&nbsp;Security&nbsp;for&nbsp;AI，对于千片卡以上的大型模型，很可能需要使用公有云来运行。尽管我们可以通过专线接入云服务，但是我们也意识到这样做可能存在较大的风险。</p><p></p><p>目前我们正在思考如何规避这些风险。例如，将大型模型运行在云上需要对接机器学习管理平台，这些平台提供模型算法和基础能力，并能直接调用底层资源配置。</p><p></p><p>在这个过程中，权限管理是一个头疼的问题。普通用户的权限管理相对简单，每类用户的权限基本上没有太多管控，他们都可以直接连接到平台进行操作、调参和模型调优。然而，一旦员工离职，可能花费了数月时间训练出的模型就可能被直接拷走。</p><p></p><p>为了保障数据的安全共享，我们目前正在内部采用TEE（可信执行环境）技术，用于不同部门间的数据共享。这样至少能确保数据是可信的，不会被窃取。但由于TEE技术受限于卡片性能，我们正在考虑如何提升性能。</p><p></p><p>目前，据说H800每百次可以支持一次计算性能的优化，然而目前性能上仍然相对较差。因此，我们正在研究是否有组合方案，例如将CPU的能力与A100和A800卡的性能结合，以实现隐私计算。</p><p></p><p>其次是AI&nbsp;for&nbsp;Security，安全领域一直面临着一个难解决的问题，即安全运维。无论是国外还是国内，数据安全需求不断增加，因为需要同时记录流量日志、事件和报警等信息，这对于每家企业来说数据量都非常庞大。</p><p></p><p>例如，当攻击流量涌现时，如何分析哪些数据是攻击的，AI&nbsp;在这方面能够提供很大的帮助。国外的一些公司，比如微软，已经将内部的安全运维交给了\"Copilot\"，通过对话形式，安全运维人员可以直接了解每天关注的事件及其解决方案。</p><p></p><p>而国内主要是在已有的数据上进行自动化统计，真正智能化生成的内容还相对较少。不过，这个方向对于安全领域来说是一个值得探索的方向。</p><p></p><h4>精彩分享5</h4><p></p><p></p><p>AI大型模型具有几个优势。首先，它拥有广泛的知识库，尽管随着链路的加深，有时知识会有些模糊，但它所知道的比单个人类要丰富；其次，它具备强大的推理能力，特别在复杂的领域如理赔案件判定和保险条件评估方面，可以代替人力进行基础性的决策，从而节省了理赔保全等事务处理所需的人工劳动力，保留了一些专家级别的人力资源，提升了效率。然而，在生产关系上，生产力的提升带来的是效率的提升，而岗位本身并不会消失。人工审核在某些领域仍然是必要的。</p><p></p><p>而大型模型不是简单的0和1的准确判断，而是通过自回归推断来完成，在某种程度上是一种更大概率的预测。在To&nbsp;B领域追求精准的情况下，很难完全取代某些工种，AI大型模型更多地作为副驾驶的存在，用于提高效率和生产力，但无法改变生产关系的基本需求，产品的需求仍然存在。</p><p></p><p>另一个方面是在风控场景中的应用。公司尝试使用智能助手辅助代理人使用复杂产品的APP。最后，大型模型在内容生成领域有着广泛的应用，如文本、音频和视频生成。结合数字人技术，可以用于培训行业或保险产品推荐。例如，保险计划书，未来可能由代理人的数字分身来向客户解释，</p><p></p><h4>精彩分享6</h4><p></p><p></p><p>我们的客户中有很多拥有大量文档，数量达到几千万份，这些文档的探索过程中发现了一些有意思的情况。在产品设计初期，由于搜索能力尚未完善，这些文档的潜在价值无法充分发挥，交互体验也不尽如人意。然而，随着搜索能力的提升，我们发现许多交互问题得到了解决。</p><p></p><p>然而，我们又发现搜索能力主要服务于普通员工，但存在一个场景尚未涵盖，即大部分政府单位，领导通常有秘书协助。他们需要整理相关文档内容。在政务领域等特定应用中，领导和局长需要查看与今年及前几年相关联的数据，秘书需要将这些相关内容整理并提供给领导。</p><p></p><p>这也是一个非常有市场需求的产品，目前，我们已经在开发阶段，通过模型来理解文档背后的逻辑，并将相关内容组织整理，模拟秘书的工作，然后将所需信息整理打包供查看和调阅。</p><p></p><h4>精彩分享7</h4><p></p><p></p><p>为了保证核电站的安全，我们需要投入大约500亿的资金，其中有2/3用于预防措施。核电发电成本本身非常低，但由于安全要求高，大部分投资都用于设备的维护和人员的配备与培训。核电站面临的主要问题是如何防止人员和设备出现错误。</p><p></p><p>关于设备出错，目前的解决方案效率较低，我们需要定期对设备进行检查和维修，通过设备运行的历史数据，我们可以判断出何时需要维修，然而，这项任务对人员来说并不容易实现。因此，我们将这项任务交由AI来执行，</p><p></p><p>全世界核电厂的数据都是公开透明的。每个核电站的设备信息、运行情况、维修经验等都在全球范围内共享，我们建立了一个经验反馈系统。我们利用大模型进行核电厂的经验反馈数据分析。通过将全球所有核电厂的数据输入给这个系统，它可以根据我们的设备信息来判断可能存在的风险和后果。通过这种方式，我们能够更好地保障核电站的安全和运行效率。</p><p></p><p>针对人员减少出错的问题，培训是一个非常重要的措施。然而，培训成本高昂且效率较低。在需求分析、过程实施、效果评估以及人员的孪生建模等方面，我们现在主要依赖人力来完成，通过AI，我们可以实现更精准的培训，它可以自动判断学员需要什么样的培训。</p><p></p><p>我自己是核电领域的第一个数字人，我用它来讲解核物理中的反应堆。不过我们希望进一步实现问答式的知识库。通过AI分析，我们可以直接提供学员所需的多模态教学内容，包括语音和视频教学。学员可以边学习边进行交互式评估。</p><p></p><p>我们正在开发一个名为\"数字教室\"的系统，将其作为教室的机器人，放置在教室中。通过这个系统，教员可以假装成学员，有意制造错误让机器人来分析是否需要相应的知识点。如果机器人能够说服教员，我们就可以投入使用。在人才培养领域，我们利用数字人技术代替了辅导员。</p><p></p><h4>精彩分享8</h4><p></p><p></p><p>风险控制这块，可以考虑让内部员工签署保密协议，以确保他们不会泄露关键信息。另一个方法是通过控制IDE上传的大小来限制代码的传递。这样可以确保大规模的代码不会全部上传，只传递输入和结果等关键部分。敏感词扫描也是一个有效的措施，可以检测和阻止包含敏感信息的内容上传。</p><p></p><p>例如，像清华大模型等大型模型可以限制上传的大小，只允许传递部分关键信息，这样可以降低泄露的风险。虽然你可以询问大规模的问题，但是返回结果可能会受到限制，以保护核心技术和数据。</p><p></p><p>另外，设置一层网关并进行关键词拦截是一个有效的措施。通过在网关上设置关键词拦截功能，可以阻止包含敏感信息或公司核心技术的数据传递到外部。</p>",
    "publish_time": "2023-08-02 11:44:43",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "大模型竞争突然升级！亚马逊CEO亲自监督、组建新的核心技术团队，集中优势资源打造“最具野心”的大语言模型",
    "url": "https://www.infoq.cn/article/3utpk9247A6CtoyztLTB",
    "summary": "<p></p><blockquote>亚马逊“最具野心”的大语言模型，将会是什么样？</blockquote><p></p><p></p><h2>亚马逊被曝组建新团队研发大语言模型</h2><p></p><p>&nbsp;</p><p>据外媒 Insider 近日报道，亚马逊 CEO Andy Jassy 目前正直接领导一支新团队，负责开发该公司最具野心的 AI 项目。</p><p>&nbsp;</p><p>Jassy 告知亚马逊的 S-team（由 20 多名高管组成的亚马逊最高决策团队），他将提拔 Alexa 首席科学家兼高级副总裁 Rohit Prasad 作为自己的直接下属，向他直接汇报。目前 Jassy 共有 16 名直接下属，包括&nbsp;Devices and Services 高级副总裁 Dave Limp、零售业务负责人 Doug Herrington、云计算 CEO Adam Selipsky 以及 CFO Brian Olsavsky 等。</p><p>&nbsp;</p><p>根据 Insider 获得的一封内部邮件，Prasad 将在新位置上组织建立新的技术小组，致力于为亚马逊打造“最具野心”的大语言模型。</p><p>&nbsp;</p><p>大语言模型是 AI 工具中的底层技术，能够从巨大的训练数据集中学会生成与人类相似的响应结果。OpenAI、谷歌和 Meta 等企业都已建立起规模庞大、功能强劲的大语言模型，并在全球范围起掀起热潮。亚马逊之前也有相关布局，成果包括 Alexa Techer Model 和 Titan。</p><p>&nbsp;</p><p>在 6 月末发出的这封邮件中，Jassy 称 Prasad 将领导一支“中央小组”，负责构建亚马逊“最具泛用性”的大语言模型。</p><p>&nbsp;</p><p></p><blockquote>“简单说一下，Prasad 将调任新岗位，负责领导一支中央小组并构建我们最具泛用性的大语言模型。虽然我们已经在公司内部构建起多个大语言模型，还有另外几个项目也在推进，但这次我们将集中优势资源打造最具野心的大语言模型，并由 Prasad 领导这支队伍。在新岗位上，Prasad 将向我直接报告。”</blockquote><p></p><p>&nbsp;</p><p>资料显示，Prasad 统领 Alexa 团队已经超过十年，同时他也是 Dave Limp 领导的亚马逊 Devices and Services 团队中的一员，并将继续承担这方面工作。</p><p>&nbsp;</p><p>根据 Insider 看到的另一封邮件，就在 Jassy 于 6 月宣布上述决定后不久，Limp 在团队内部发出通告，称 Prasad 仍将是“Alexa 的关键合作伙伴与支持者，并将在我们的未来业务中发挥重要作用。”这封邮件称，亚马逊 Devices 副总裁 Daniel Rausch 将接掌 Alexa 产品与业务组织，包括各娱乐、合作伙伴参与及跨国团队。</p><p>&nbsp;</p><p>Limp 在邮件中强调，“我们在 Alexa 的使命和愿景上没有动摇，对于我们向客户交付新发明、新成果的能力，我也比以往任何时候都更加乐观。”有消息显示，亚马逊最近还启动另一个新项目，希望利用类似 ChatGPT 的技术让 Alexa 变得更智能、更富个性化。</p><p>&nbsp;</p><p>目前关于 Prasad 领导的新团队并未有更多消息流出，但可以看到，亚马逊在这场大模型竞赛中已经准备好了，至于未来能带来什么样的惊喜，还需要交给时间。</p><p></p><h2>亚马逊入局“大模型之战”</h2><p></p><p>&nbsp;</p><p>根据 Insider 之前的报道，亚马逊正急于应对生成式 AI 的迅速崛起。尽管亚马逊过去数十年间一直致力于 AI 技术研究，但微软、OpenAI 和谷歌等竞争对手明显取得了一定优势，Meta 最新的Llama 2 模型也在整个科技行业内掀起了波澜。为此，亚马逊决定在新计划中立足亚马逊云科技事业部组建新团队，专注于帮助客户使用生成式 AI 产品。</p><p></p><h3>亚马逊的 AI 产品布局</h3><p></p><p>&nbsp;</p><p>在这场大模型竞赛中，亚马逊云科技已经交出过不少答卷。今年 4 月，亚马逊推出了 Amazon Bedrock 服务、Amazon Titan 大语言模型，以及 AI 编码助手 Amazon CodeWhisperer。</p><p>&nbsp;</p><p>其中，Amazon Bedrock 既提供自研的大语言基础模型—— Amazon Titan Text 、Amazon Titan Embeddings，也与 AI21 Labs、Anthropic、Stability AI 等基础模型提供商广泛合作，助力企业轻松灵活构建生成式 AI 应用，降低所有开发者的使用门槛。</p><p>&nbsp;</p><p>Andy Jassy 在此前接受 CNBC 采访时表示，“大多数企业都想要用上大语言模型，但顶尖 AI 模型需要几十亿美元和长达数年的训练成本和周期，用户肯定不想亲自动手。因此，他们希望能在规模够大、性能更好的基础模型之上工作，再根据自身需求对其做出定制。而这，就是 Bedrock 的基本定位。”</p><p>&nbsp;</p><p>Amazon Titan 基础模型可以识别和删除客户提交给定制模型的数据中的有害内容，拒绝用户输入不当内容，过滤模型中不当内容的输出结果。Titan 系列模型分为两种，一种是用于内容生成的文本模型，另一种是可创建矢量嵌入的嵌入模型，用于创建高效搜索功能等。</p><p>&nbsp;</p><p>AI 模型经常会出现“一本正经地胡说八道”现象，尽管输出内容看似有理有据、令人信服，但实际上并没有相关训练数据可以支撑。针对 AI “幻觉”问题，亚马逊云科技副总裁 Bratin Saha 此前在接受外媒采访时表示，亚马逊非常关心准确性，并努力确保 Titan 模型能够生成高质量的响应结果。</p><p>&nbsp;</p><p>据外媒报道，十几年前起就一直在亚马逊工作的 Sivasubramanian 表示，亚马逊在 AI 领域已经持续投入二十多年，亚马逊云科技目前拥有超过 10 万家 AI 相关客户。他同时补充称，亚马逊也一直在使用 Titan 的微调版本交付主页上的搜索结果。</p><p>&nbsp;</p><p>Amazon CodeWhisperer 则是一款面向个人开发者免费使用的辅助代码编写工具，是一种人工智能代码生成扩展，目标是提高软件开发者的工作效率。CodeWhisperer 可以更快地完成更多工作，避免软件开发人员花费大量时间编写非常简单且无差别的代码，CodeWhisperer 作为 AI 编码伴侣，它能根据开发人员的自然语言评论和集成开发环境 ( IDE ) 中的先前代码实时生成代码建议，从根本上提高开发人员的工作效率。</p><p></p><h3>“大型语言模型和生成式AI对亚马逊意义重大”</h3><p></p><p>&nbsp;</p><p>在发布上述&nbsp;AI 服务/产品的同一天，亚马逊还发布了 2022 年度股东信，Jassy 在信中提到，公司正大力投资大型语言模型和生成式 AI。</p><p>&nbsp;</p><p>Jassy 表示，LLM 和生成式 AI 是能让“亚马逊未来几十年可以在每个业务领域都进行创新的核心”，将显著加速亚马逊已经深耕了 25 年的机器学习的应用，他称生成式 AI 具有变革性，对客户、股东和亚马逊来说都意义重大：</p><p>&nbsp;</p><p></p><blockquote>“亚马逊研发自己的 LLM 已有一段时间了，相信它将改变并改善几乎每一种客户体验，并将继续在所有我们的消费者、卖家、品牌和创作者体验中大量投资这些模型。&nbsp;与多年来亚马逊云科技的发展路径一样，我们正在推动各种规模的公司都可以利用生成式人工智能。亚马逊云科技提供了最具性价比的机器学习芯片Trainium和Inferentia，使得小型和大型公司都可以负担得起在生产中训练和运行他们的 LLMs。&nbsp;亚马逊的商业客户可以从各种LLMs中进行选择，并使用客户喜好的所有AWS安全、隐私和其他功能构建应用程序。此外，我们正在提供像AWS CodeWhisperer这样的应用程序，它通过实时生成代码建议来革命性地提高开发者的生产力。”</blockquote><p></p><p>&nbsp;</p><p>Jassy 最后提到，他本可以用生成式人工智能写一整封信，但他要把这封信留到未来。大型语言模型和生成式人工智能对客户、股东和亚马逊来说都将是一件大事。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.businessinsider.com/amazon-ceo-andy-jassy-oversees-group-most-ambitious-ai-models-2023-7\">https://www.businessinsider.com/amazon-ceo-andy-jassy-oversees-group-most-ambitious-ai-models-2023-7</a>\"</p><p><a href=\"https://www.infoq.cn/article/j3qbSPiG9Hmapal2exir\">https://www.infoq.cn/article/j3qbSPiG9Hmapal2exir</a>\"</p><p><a href=\"https://www.cnbc.com/2023/04/13/aws-launches-bedrock-generative-ai-service-titan-llms.html\">https://www.cnbc.com/2023/04/13/aws-launches-bedrock-generative-ai-service-titan-llms.html</a>\"</p>",
    "publish_time": "2023-08-02 15:05:17",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "打造中国版“Snowflake”，经济低迷时期技术创业型公司如何乘风破浪？",
    "url": "https://www.infoq.cn/article/1dwmueV39HfaatqC7MXq",
    "summary": "<p>在当下科技创业热潮中，多云及一体化数据平台提供商云器科技备受瞩目。成立于 2021 年的<a href=\"https://www.infoq.cn/article/uVkQaLTDVKLLOJwqNDhz\">云器科技</a>\"，在近期宣布完成连续两轮总计数亿元人民币的融资，并举办<a href=\"https://www.infoq.cn/video/22GhZyjOkqJEzbHD9o3I\">新产品发布会</a>\"的消息获得了广泛的关注。</p><p></p><p>这家初创公司选择在如此低迷的经济环境中乘风破浪，其背后秘诀何在？他们又是如何看待技术创新与商业成功的关系？在全球竞争激烈的市场上，云器科技如何保持核心竞争力？<a href=\"https://www.infoq.cn/article/Re4O8YyDbACbrsOh3R7l\">一体化趋势下</a>\"，云器自创的 Single-Engine 理念有何独特之处？近期，<a href=\"https://www.infoq.cn/video/AN33kAfP4y35xBeb6M22\">InfoQ【C 位面对面】</a>\"栏目特别邀请到云器科技联合创始人 &amp; CTO 关涛，来分享云器科技的创业之路、技术创新策略以及对中国数据平台发展的独到见解，</p><p></p><p>探讨主题如下：</p><p></p><p>中国版的 Snowflake 在哪里？在低迷的经济环境中，技术创业型公司如何乘风破浪？一体化趋势下，技术创新有哪些关键点？</p><p></p><p></p><h2>中国版的 Snowflake 在哪里？</h2><p></p><p></p><p>关涛：相比海外，中国的原创数据平台技术公司和产品还是太少。我们希望在技术侧推出自有的新技术理念，也希望构建中国的云上国之重器，打造中国原创的数据平台技术。</p><p></p><p>InfoQ：云器科技成立于 2021 年，彼时国内的数据平台正处于发展期向普惠期过渡的阶段。为什么选择这样一个时机创立云器科技？创立云器科技的初心是什么？</p><p></p><p>关涛：从整体发展的视角看，国内的数据平台市场有很大的空间和潜力。我个人来讲，我们希望在技术侧能推出有自己理念的新东西。我们之所以取名叫云器，也是希望构建中国的云上国之重器，打造中国原创的数据平台技术。</p><p></p><p>InfoQ：当时，国外市场上 Snowflake、Databricks 这样的产品已经经历了 8-10 年的发展，一直保持高速增长。云器是否考虑过复制他们的成功模式？云器科技设定的发展路线 / 策略是怎样的？</p><p></p><p>关涛：从商业模式来看 Snowflake 有几个特点。首先它是多云的商业模式，基础设施在云上，我们希望按这个模式来做。其次它是 SaaS 模式，用户无需关心技术细节，上手简单，我们也是一样的定位。所以我们与 Snowflake 的商业模式、产品理念基本一致，我们希望填补中国在这方面的空白，满足愿意用 SaaS 化的多云平台的企业需求。</p><p></p><p>云器与 Snowflake 的不同在于技术侧。多年前 Snowflake 凭借 shared-data 架构与云原生模式取得成功，但那时的先进技术现在已经成熟了。我们的技术理念有所不同，我们推出了自己的增量计算模式与 Single-Engine 一体化设计。</p><p></p><p>InfoQ：在数据平台领域，中美是否有差异？中国企业有哪些本土技术创新的机会？</p><p></p><p>关涛：从市场的差别看，首先美国绝大多数的企业都在云上，选择自建云平台的很少。而中国还有 30% 左右的企业在线下做自己的数据中心，云化和数字化还有潜力。第二点，美国绝大多数企业不自建数据平台，而是选择 Snowflake 等产品，而国内基于开源自建很普遍，这是市场侧的差异。技术视角的差异没那么大，但美国前五的数据平台都是原创技术，而国内企业更多是拿来主义，原创偏少。更多中国企业选择了自己修改开源方案，同质化明显。国内还没有 Snowflake 这样有规模和影响力的公司和产品，这也给国内注重原创技术的企业创造了很大的市场机会，这样的企业如果做得比较好就会有很大的回报。</p><p></p><p>InfoQ：最近网上热门的讨论主题在说“中国不需要 SaaS”，国内的大环境下 SaaS 企业很难生存，认为中国应该走印度 InfoSys（外包管理公司）这样的技术路线，不需要 SaaS，您怎么看待？</p><p></p><p>关涛：从我们自身情况看，云器从创业到现在，从云底座管控平台到 HR 系统、绩效系统、文档系统和周边的很多系统，几乎都选择了 SaaS 化服务。从这个层面上讲，我认为 SaaS 已经潜移默化地改变了非常多国内企业的形态。所以 SaaS 在中国已经发展起来了，并不是伪需求。</p><p></p><p>而很多企业之所以需要的是解决方案而非平台，是因为国内 IT 人员数量总体少、企业技术水平不高，没有足够的人基于 SaaS 做业务开发，需要其他公司来做整体的解决方案。所以国内的 SaaS 就要做得更加简单易用，而不是单纯抱怨市场。服务好客户仍然是国内 SaaS 的成功关键。</p><p></p><p>另外，国内企业更愿意选择 SaaS 加服务的模式。针对技术水平较高的企业可以提供标准化产品，同时针对技术薄弱的环节要提供定制化的服务做补充。</p><p></p><p>InfoQ：打造中国版的 Snowflake 是很多厂商的愿景，那么为什么在中国至今仍然没有出现 Snowflake 这样的巨头公司？如何看待多云数据平台与云厂商的竞争格局？</p><p></p><p>关涛：我们把 Snowflake 定义成多云独立、SaaS 化且有一定影响力和营收规模的平台，那么国内为什么没有这样的巨头？首先中国原创的数据技术还是太少了，而基础设施需要长周期、大投入，要有很多经验积累。而国内这一领域相对年轻，积累总体少。另一方面国内企业的付费意愿也不够高，SaaS 化的商业环境不够友好。但未来随着越来越多的企业意识到自建数据平台并非自己的核心竞争力，不应该在这方面投入重资产，国内迟早会有 Snowflake 这样的企业成长起来。</p><p></p><p>其实云器和国内云厂商的关系可以类比 Snowflake 和亚马逊云科技的关系。Snowflake 没有替代亚马逊云科技，云器也不会替代其他国内云厂商。云器 Lakehouse 平台是构建在云上，与其他厂商之间以合作关系为主。</p><p></p><p></p><h2>在低迷的经济环境中，技术创业型公司如何乘风破浪？</h2><p></p><p></p><p>关涛：经济低迷的环境中，有着深厚积累的技术平台企业有更多机遇。云器专注于细分领域，只要能做到最快、最简单、最低成本，就能在数据平台这样成熟的技术领域获得市场成功。</p><p></p><p>InfoQ：近日，云器科技宣布已完成连续两轮总计数亿元人民币的融资，且刚刚举办了新产品发布会。作为一家初创公司，在经济依旧低迷的当下，云器快速成长的秘诀是什么？</p><p></p><p>关涛：第一，最近一年半我们一直专注技术和产品本身，最近才开始正式接触客户，所以经济环境对我们影响不是很大。在经济低迷期，我们刚好做积累来构建产品。第二，经济低迷的环境让我们和客户都更容易想清楚定位。客户经过测试发现云器确实更简单，也能给他们降低成本。所以这样的经济环境对于平台技术企业并不完全是坏事。我们希望在这样的经济条件下提供给客户多一个选择，让轻资产的客户也可以有高性能、低成本的数据平台。</p><p></p><p>轻资产 / 重资产 IT 投入，数据平台是否自建，这些问题一直有争论。但我们认为，最终效率会成为判断的“黄金指标”。我们会更专注于细分领域，效率会是我们的核心价值。</p><p></p><p>InfoQ：您认为该如何判断一项技术是否能够在商业上取得成功？</p><p></p><p>关涛：我的理解，创业大概有两种模式。第一种创业模式叫 Searching，是说我有一套新技术、一套新想法，但不知道这套想法能不能最终转化成商业成就，不知道就去做 search ，类似在森林里找路的模式，找到金矿就赢，找不到就输。例如 LLM 大模型当前总体还属于这样的模式，大家都在寻找合适的商业化路径。还有一种叫 Mountain Climbing，也就是爬山模式。这种模式下商业场景是清楚的，大家是沿着不同路径向山顶爬，看谁爬得快爬得好，谁就能赢得市场。</p><p></p><p>数据平台领域其实是后者，数据平台的价值、应用场景都非常清楚，最后谁的技术最好、最简单、最低成本，谁就赢。</p><p></p><p>InfoQ：云器科技如何看待开源领域的发展？在竞争激烈的市场中保持核心竞争力的关键是什么？</p><p></p><p>关涛：云器还没有开源，短期开源战略也不是我们重点。我认为在一个技术领域的发展初期，开源会极大推动这个领域的发展。那时行业的头部企业和研发人员有着很好的技术水平，他们开源后回馈社区，形成技术迭代，推动行业快速成长。但随着技术发展逐渐成熟，很多传统行业的用户进入市场，他们就不那么看重开源，而只是想要简单、便宜、好用的产品，甚至不想知道内部的技术细节。我们认为现在数据平台已经发展到了这个阶段，这也是我们没有选择开源的一个原因。</p><p></p><p>另外，开源体系更像组装式的架构，每个开源的领域都很小，大家拼到一起形成一个大生态。但对于很多用户而言，比如 Snowflake 的客户，他希望你把所有细节都封装起来，展现给用户的是一个简单的接口，闭源模式更适合这个领域现在的状态。</p><p></p><p>InfoQ：在前不久的发布会上，云器科技发布了新一代数据平台云器 Lakehouse。能否聊聊云器 Lakehouse 的研发历程，在整个过程中团队遇到过哪些困难挑战，又是如何克服的？</p><p></p><p>关涛：我们创业两年来，目标一直是做下一代的数据平台，技术路线一开始就确定了，包括不开源、SaaS 模式、湖仓一体架构，Single-Engine 一体化这些大方向都没有变动过。执行阶段整体还是非常聚焦。原创数据平台技术门槛和投入高，我们产品 MVP 版本开发大约用了 1 年。之后是 PMF，经过多次迭代，听取客户反馈意见，不断加入新的需求，完善产品体验，最后有了现在的产品。但在细节上我们还是做了很多尝试，例如 AI for Data 这个方向我们就有很多尝试和调整。</p><p></p><p>技术架构选型上，就说一个细节，相比数仓来说，湖仓架构能兼顾数据的开放性、引擎的多样性，同时又兼具数仓的高性能。它是面向未来企业需求设计的架构。云器 Lakehouse 就是湖仓一体的架构，也是现在的主流设计。</p><p></p><p>InfoQ：有用户会担心，既然云器不开源，那么企业选择云器后如何避免被绑定呢？</p><p></p><p>关涛：这是好问题，我们在设计上也特别关注这个方面。首先，云器的多云架构保证了企业调整基础设施的灵活性，用户去哪个云都可以用这个平台；其次，我们在开放性上做了额外的工作，计算不锁定，存储开放。用户存储的数据可以开放成开源的标准格式，用户也有权限访问这些数据，用户的其它引擎都可以直接来读这些数据，所以并不会有绑定。</p><p></p><p></p><h2>一体化趋势下，技术创新的关键是什么？</h2><p></p><p></p><p>关涛：我们认为流、批和交互这三个计算范式都不能替代对方，需要一个更新的计算范式去覆盖，所以我们提出了第四种计算范式叫做增量计算。同时，我们选择了 Shared-Everything 系统架构替代 shared-data，我们认为这样的一套技术可以实现一体化的基础目标。</p><p></p><p>InfoQ：现如今，一体化或者 Converged infrastructure 成为业界的共同趋势。您如何理解“一体化”的概念？理想状态的“一体化”应该是怎样的？</p><p></p><p>关涛：我们谈一体化主要是从数据平台和数据分析的视角上来谈的。数据分析平台可以分成批处理、流处理和交互分析这三类场景，分别对应大批量数据计算、数据新鲜度较高的流计算和非常高性能的交互分析。对此国内主流解决方案是组装式的，用三个引擎分别满足这三个不同场景的需求。这样的好处是每个引擎都可以在特定场景上做到极致，但带来的挑战也有很多。比如三个引擎的接口不统一，有的引擎是带存储的，有的引擎带元数据，导致数据和存储都不统一，分散在三个引擎的不同位置，导致数据管理非常复杂。数据要在多个引擎间同步，数据版本都很难对齐。这种组装式的架构叫 Lambda 架构，</p><p>这个架构的问题和挑战，也业界也都清楚。业界为了解决 Lambda 架构的问题做了很多尝试，流批一体就是一个尝试。整体来说，技术是向着一体化的方向不断发展。云器的 Single-Engine 就实现了离线、实时、交互、分析的统一，希望尽可能同时覆盖三大场景，让用户轻松使用。</p><p></p><p>InfoQ：Single-Engine 方案的独特之处是什么？</p><p></p><p>关涛：Single-Engine 背后实际是增量计算的计算范式。之前我们经过分析，认为流、批和交互这三个计算范式都不能替代对方，需要一个更新的计算范式去覆盖，所以我们提出了第四种计算范式叫做增量计算。基于这个范式打造出来的引擎就叫做 Single-Engine。计算侧，我们是用增量计算的计算范式实现的；存储侧是增量的湖仓存储。整体的系统架构上我们选择了 Shared-Everything 架构，比 shared-data 又进一步。我们认为这样的一套技术可以实现一体化的技术目标。</p><p></p><p>InfoQ：在将产品推向市场的过程中，云器收到过哪些来自客户对于产品的反馈？</p><p></p><p>关涛：我们的技术理念和方向，还是得到普遍的认可。比如一家国内知名的汽车厂商，在他们的流水线中我们真正做到了低成本的全能增量化。客户原来只有 10% 的场景是实时化的，我们把他所有的场景都做到实时化，还帮他降了 50% 的成本，真正解决了客户的问题。</p><p></p><p>另外就是，客户试用、盲测，他们的第一印象就是我们的性能表现很不错。</p><p></p><p>客户 Onboard 是一个比较复杂的过程，因为涉及基础架构升级。第一阶段是客户的试用、盲测需求，他们的第一印象就是我们的性能表现很不错。经过初始的展示环节，客户会走 POC 的流程，选他自己的场景来做测试。之后如果觉得不错，会挑选多个业务场景中的一个来试用。比如说我们有一个客户选了实时化的线路，第一阶段是先把实时化的部分业务迁移上来，离线部分和 AI 的部分排在后面，这种渐进式的替代过程是比较典型的。</p><p></p><p>InfoQ：面向未来，您觉得数据领域的重要趋势是什么？云器科技未来有怎样的规划？</p><p></p><p>关涛：从技术视角看，在数据分析领域，一体化是大趋势。从客户视角看，只要能更好地解决客户问题、提升效率、降低成本就能赢得市场。一体化是提升效率、降低成本的一个好手段。</p><p></p><p>另外数据和 AI 的一体化也是一个趋势。AI 如何与数据平台结合还有很多值得探索的方向。未来 AI 一定很重要，但它的具体形态现在还不能完全确定。未来有更多物料数据进入湖仓平台，云器这样的平台可以通过 AI 能力提供扩展性，支持更丰富的数据类型。</p><p></p><p>我们今天身处很好的时代，这是一个技术加速迭代的时代。我们期待和国内的平台从业者、客户一起，共同推动中国的原创数据技术向前发展。我们一起在全球打出中国数据平台的技术品牌知名度和影响力，这需要客户的支持，也需要更多同业者的互相扶持。</p>",
    "publish_time": "2023-08-02 15:08:40",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "字节跳动系统部项目管理负责人申建，确认担任QCon北京卓越项目管理专题出品人",
    "url": "https://www.infoq.cn/article/NwC3ACdG5jo374Mf14SX",
    "summary": "<p>9 月 3 日 - 5 日，在 <a href=\"https://qcon.infoq.cn/202309/beijing?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=0802&amp;utm_content=shenjian\">QCon 全球软件开发大会（北京站）</a>\"，字节跳动系统部项目管理负责人申建将担任「卓越项目管理」的专题出品人。在此次专题中，你将了解到卓越的项目管理是实现成功项目的关键，以及它能给团队、客户、企业带来的益处。</p><p></p><p>申建，字节跳动系统部项目管理负责人、火山引擎边缘云项目管理负责人、中国软件行业协会项目管理专委会专家；MBA（博士在读）、PMP、PgMP。他担任多家互联网企业 PMO 友情咨询顾问，拥有二十年互联网产品研发和项目管理经验；曾在阿里和字节内部多 BU 组建和管理 PMO 组织，推行原生项目管理框架下多方法体系解决方案，不断探索适合互联网 / 云计算行业下项目经理和 PMO 组织的公认价值模型。</p><p></p><p>相信申建的到来，可以帮助提升此专题的质量，让你了解到卓越的项目管理能够使项目管理效率更高、项目成本更低，实现预算内完成更多项目的目标，进而提高团队和客户的满意度，并帮助企业保持竞争优势，在企业的良好发展中发挥着不可或缺的作用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ff/ff5317f4690587861f128f7a1888dd27.jpeg\" /></p><p></p><p>除上述专题外，QCon 北京还将围绕<a href=\"https://qcon.infoq.cn/202309/beijing/track/1553?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">异构计算</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1554?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">向量数据库</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1556?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">FinOps&nbsp;落地</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1558?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">业务安全技术</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1557?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">从&nbsp;BI&nbsp;到&nbsp;BI+AI，新计算范式下的大数据平台</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1559?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">从&nbsp;MLOps&nbsp;到&nbsp;LLMOps</a>\" 等进行分享。</p><p></p><p>近 100 名讲师、近 30 个精彩专题、8 种交流活动，QCon 北京 2023，相约 9 月！现在购票，享 9 折特惠，立省 ¥880！咨询购票请联系 18514549229（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/33/33cbbbf20baa8b2a18db4f0681f159aa.jpeg\" /></p><p></p>",
    "publish_time": "2023-08-02 15:13:01",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "中台之上：业务架构设计",
    "url": "https://www.infoq.cn/article/1yc8IjNAFAOBy8Tw6xjk",
    "summary": "<p></p><h2>作者序</h2><p></p><p>有人说，将来的企业都是科技公司，虽然就目前来讲，这句话还为时尚早，但是，很多传统行业已经被科技大大改变了。大家都知道 BATJ 是科技公司，其实星巴克也已经是科技公司了，在美国的星巴克门店，有将近 16%的收入来自手机客户端；星巴克自己的 App 有将近 1300 万的活跃用户，星巴克内部已经将网页、手机、社交媒体、网络营销、StarbucksCard 、电子商务、Wi-Fi、星巴克数字网络和新兴的店内消费技术等等，统一作为数字业务战略。今年在风口浪尖上的滴滴，2016 年时就已经日产生数据超过 50TB（相当于 5 万部电影），每天规划 90 亿次路径；2017 年据称全年累计提供出行服务 74.3 亿次。美团公司也是人工智能的玩家，只不过他们没搞个钢铁侠之类的，而是更接地气的、服务快递小哥的语音助手，支持骑手全程通过语音和系统进行沟通、确认，避免了手动操作，提高了效率和安全性。以派单为例，语音系统会说：“派单，从哪里到哪里，收到回复”，骑手只需要说：“收到”，系统就可以确认派单。到了用户家附近的时候，骑手亦可以通过语音关键词回复，直接拨打电话，从而避免了掏出手机这个动作。在电量过低的时候，系统会提醒骑手，骑行速度过快的时候也会提醒骑手放慢速度，到达顾客附近时，自动提示顾客的地址。这个语音助手不仅方便了小哥，也让快递过程更加安全，减少事故发生。</p><p></p><p>倒退回 15 年前，恐怕没有多少人真的相信零售、餐饮、出租车、外卖这些行业会跟科技如此紧密相关，甚至直接成为了科技企业，而他们用的技术已经是大多数普通业务人员无法理解的，这不仅仅指技术原理无法理解，连应用方式都无法理解，这是一个真实的“数字鸿沟”。其实技术人员也被这道鸿沟困扰，成天喊着找场景、找场景，说到底，没场景要么是这项技术无用，要么就是没法让业务人员真正理解，导致无法与业务结合。</p><p></p><p>大家都清楚地认识到了科技的力量，心里都明白要应对技术推动的跨界竞争，但是，要怎么做呢？高薪聘请一些技术人员？买买大厂的科技产品？这些也是需要的，但正如交给你一把狙击步枪，不代表你已经成为了一名合格的狙击手，你还需要自身的转变。这种转变才是最终促成数字化转型的关键。</p><p></p><p>转变当然不是要大家都去学技术，都当技术小能手，而是转变思维方式，架起一道跨越“数字鸿沟”的桥梁，我认为，这就是业务架构的核心作用。业务架构可以帮助业务人员整体化、结构化、模块化地思考问题，从业务和系统的整体视角，附带一些对技术的基础了解，如分层理念去认识业务和技术；也能够帮助技术人员理解、归纳业务人员的想法和目标，从而让业务和技术能够在同一个语境下，使用同一种“语言”工作。过去那种业务不用管技术怎么实现、技术听懂需求就够了的时代已经过去，以后是深度融合的时代，深度融合就代表互相深入理解，而这种理解需要首先从思维方式的转变开始，通过建立业务架构，让双方都向对方迈出一步，当然，这一步对业务人员的挑战更大，但科技是这个时代的特征，在一个信息化的时代，就得具备这个时代的思维方式，这是任何人也无法回避的问题。在构建业务架构的过程中，业务人员需要技术人员的大力协助来共同掌握这个工具，这就不仅是一个通向理解的过程，更是一个达成信任的过程。此外，我们也无法忽视一点，如果业务本身不能被很好的结构化、模块化，我们也很难做出一个具有良好架构的系统来，就算你是中台的拥趸、“死粉”，也无法解决这个问题。所以，培养业务人员的逻辑思维、架构意识，对于系统开发而言，只有好处，没有坏处。</p><p></p><p>可能有些技术人员还会觉得应该让业务人员只专注业务就好，但是，不妨想一想，业务人员和技术人员在现实中的比例，你会发现要是业务人员也能对技术的思维方式有所了解，那将会对技术的合理应用乃至创新产生多大的推动力。打个不恰当的比方，技术人员就好比茶商，你可能想象不到，有多少现代人的喝茶习惯、茶叶知识都是拜茶商所赐，客户对茶叶了解的越多反而兴趣越浓，更愿意尝试不同的茶叶、茶具、技法，很多消费者最终在知识上远超越一般的茶商，这就是大家常说的培养客户、与客户共同成长吧。</p><p></p><h3>目录</h3><p></p><p>为什么业务架构存在 20 多年，技术人员还觉得它有点虚？</p><p></p><p>战略和组织结构，业务架构设计中不应被忽视的关键因素</p><p></p><p>面对复杂的流程和数据，我们总结出了一个分析套路</p><p></p><p>业务架构和中台的难点，都是需要反复锤炼出标准模型</p><p></p><p>如何为一个商业银行设计业务架构？</p><p></p><p>不神秘但很麻烦的业务架构落地过程</p><p></p><p>企业级业务架构的实现需要不断沟通和调整</p><p></p><p>业务架构设计“笨重”，它能跟敏捷沾边吗？</p><p></p><p>企业级业务架构设计的“五难”</p><p><img src=\"https://static001.geekbang.org/infoq/df/df109e0480d7f404a70d96df1a9e6a33.png\" /></p><p>扫/码/下/载</p>",
    "publish_time": "2023-08-02 15:33:08",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]