[
  {
    "title": "银行核心业务系统数据库主机下移架构与实践 | DBTalk 技术公开课第2期",
    "url": "https://www.infoq.cn/article/BHMyzwGhzlE6aiK4lxCb",
    "summary": "<p>**信创背景下，银行核心业务系统数据库主机下移如何做？基于业务场景，需要重点关注数据库的哪些关键点和特性？数据库高可用架构如何设计，是否需要分库分表？满足业务场景需求的同时如何保证系统高可用和高效运行？</p>\n<p>本次分享，将逐一给出答案并分享实践案例。**</p>",
    "publish_time": "2022-08-18 00:25:47",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何从 0 到 1 实现智能化运维？| DBTalk 技术公开课第2期",
    "url": "https://www.infoq.cn/article/8gqi6lKfYEPQvoqdS0xS",
    "summary": "<p>**随着数字化、互联网的快速发展，金融行业正在加快推进全面改革转型。业务创新与技术架构演进的同时，对底层基础软件平台的支撑能力也提出了更高的要求。而数据库运维逐步向标准化、自动化、集中化、智能化演进则成为行业未来发展的必然趋势。</p>\n<p>本次议题，将聚焦金融行业，分享数据库运维能力演进及落地经验。**</p>",
    "publish_time": "2022-08-18 00:27:09",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "用AI打败AI：向Deepfakes“宣战”",
    "url": "https://www.infoq.cn/article/Rg7oFVSj0LoF9AUblWiV",
    "summary": "<p></p><p></p><blockquote>如今，由计算机生成的逼真人脸已经随处可见。我们到底该如何分辨个中真伪？</blockquote><p></p><p></p><p>大概十年之前，当时在蒙特利尔大学攻读博士学位的Ian Goodfellow和朋友们在一家酒吧小酌时，突然萌生了一个“永远改变整个机器学习与信息伪造领域”的念头。</p><p></p><p>Goodfellow之前在播客上打趣道，“我不是说非要喝酒才能萌生出科研灵感。但当时情况确实是这么个情况，我觉得少喝两杯能帮自己打开思路。”总之，他回家后马上开始着手尝试。</p><p></p><p>Goodfellow隐隐觉得，如果让两个计算机系统相互对抗（即生成对抗网络，简称GAN），应该可以产生比当时的深度学习技术更真实的输出结果。那时候的深度学习算法只能产出模糊的人物图像，而且严重缺乏面部特征。他的早期模型只能生成类似于手写数字、有那么点意思的虚构人脸，以及类似于像素化风格的莫奈式动物图像。但随着技术的发展，用更少的图像创造出高度逼真的伪造画面已经成为可能。</p><p></p><p>GAN中使用两种相互竞争的算法，会在同样的数据集上自我训练。其中的生成器会根据原始数据集创建新图像；而另一边的鉴别器则负责识别出伪造图像。最初双方都很弱，生成能力与鉴别能力堪称“菜鸡互啄”。</p><p></p><p>但随着时间推移，算法在零和博弈中相互对抗——如果生成器骗过了鉴别器，则生成器得一分；如果鉴别器检测出了伪造内容，则鉴别器得一分。如此反复，生成的图像变得越来越真实可信。</p><p></p><p>感兴趣的朋友可以访问This-person-does-not-exist.com网站，亲自感受一下由GAN快速生成的大量虚构人物头像。如果说机器学习的目标在于赋予计算机模仿人类智能行为的能力，那么Goodfellow就相当于给计算机插上了想象力的翅膀。</p><p></p><p>虽然GAN开创了机器学习的新时代，在医学影像、面部衰老预测和视觉艺术创造等方面获得了广泛应用，但同时也成为恶意黑客和网络谣言传播者手中的利器。有了这项技术，他们可以随意伪造证据、展示攻击对象种种并不存在的不当行为。例如在政界令人头痛不已的“假新闻”难题，如今deepfakes搞出来的照片和视频正引发轩然大波，亟需一种可靠的伪造鉴别方法。这可绝不是危言耸听，今年就出现过一段deepfakes视频，其中乌克兰总统泽连斯基要求他的部队放下武器、向俄军投降。</p><p></p><p>其他案例也所在多有。</p><p></p><p>2021年，挪威摄影师Jonas Bendiksen就在法国Visa pour l'image&nbsp;新闻摄影节上公布了自己的《Book of Veles》作品集。照片描绘的是2016年美国总统大选期间，他在北马其顿小镇的生活点滴。唯一的异样，就是所有图像均系伪造，一切人和动物全部由计算机生成。问题是根本没人能发现……如果连那些把一生献给摄影艺术的专家都识别不了Bendiksen的花招，那我们普通人就更加难以分辨了。</p><p></p><p>随着AI工具变得越来越复杂，以deepfakes为代表的伪造媒体信息已经愈发难以检测。根据世界经济论坛2021年发布的报告，deepfakes视频数量每年增加约九倍，而且像Bendiksen这样的外行人只要看看YouTube上的制作教程就能学会。</p><p></p><p>为了化解这场虚假信息引发的危机，研究人员只能积极寻求新的鉴别方法。</p><p></p><p>为此，Facebook（现更名为Meta）决定在2019到2020年间的三个月中举办一场Deepfake检测挑战赛，要求参赛者想办法自动识别某张照片是否为AI伪造。挑战赛共吸引到2114名参赛者，开发出最强识别算法的选手拿到了100万美元奖金。但尽管云集了AI领域最睿智的头脑，比赛中的优胜程序也只能实现65%的deepfakes识别成功率。</p><p></p><p>目前，大部分基于AI的检测程序会将注意力集中在“视觉伪影”上，也就是通过光照冲突、错误的阴影位置和几何图形矛盾等线索确定伪造图像。但随着AI技术的不断发展，deepfakes程序能够快速学会抹除矛盾。</p><p></p><p>2018年奥尔巴尼大学的一项研究曾经发现，deepfakes视频中的眨眼频率往往明显高于或低于真人。但短短一年之后，韩国研究人员就发现deepfakes正发展出更逼真的眨眼模式。眼镜和牙齿部分也获得了类似的升级，快速消除了这两部分在此前AI生成照片中不够自然的问题。事实上，专家们披露出的这些错误，其实在不经意间已经给deepfakes创作者指明了生成更强伪造图像的方向。</p><p></p><p>Deepfakes目前还无法生成完美无瑕的全合成人类图像，所以检测工具暂时有效。但Adobe内容真实性计划高级主管Andy Parsons表示，这种有效性不知道还能维持多长时间。“如果时间再推进五年或者十年，结果又会如何？我觉得伪造一方很可能会最终胜出。再不找到更好的识别方法，防线就要崩溃了。”</p><p></p><p>虽然deepfakes已经成为日益严峻的现实威胁，但负责编撰《媒体操纵案例手册》的Jane Lytvynenko表示更令人担心的其实是“廉价伪造”，即不涉及AI的伪造照片和视频。</p><p></p><p>在加入哈佛大学肯尼迪学院新闻政治中心的技术与社会变革项目之前，Lytvynenko就已经凭借在BuzzFeed News上报道错误及虚假信息而声名鹊起。</p><p></p><p>根据Lytvynenko的介绍，单纯通过剪切、粘贴、放慢音频和视频拼接，这种廉价伪造已经足以用成本极低的方式欺骗大众、操纵媒体。YouTube上有个专门宣扬右翼党派阴谋论的频道，在其中一段题为《她喝醉了吗？》的视频中，南希·佩洛西（Nancy Pelosi）在新闻发布会上口齿不清、似乎难以站稳。但这段视频其实是通过慢放来误导观众，给人一种佩洛西无法正常讲话的印象。</p><p></p><p>虽然这段视频后来被鉴定为假，却已经造成了相当广泛的传播效应。Lytvynenko表示，“其实用不着deepfakes，人们往往会被更简单的策略所误导，所以恶意传播者暂时还没必要采取那些更复杂的技术方法。”</p><p></p><p>面对充斥着错误信息的世界，名为内容来源的新型解决方案有望开辟出一条信息保障之道。该项目的灵感源自艺术创作界，希望建立一条来源链，记录图像在整个数字生命周期中发生的一切——包括由谁拍摄、何时拍摄、是否经过编辑等。软件不是回溯性检查图像的篡改痕迹，而是从图像创建之时起就始终保证内容的真实性。这些数据会被打包起来，在图像上线发布后显示在旁边的信息框内。</p><p></p><p>Adobe在2019年公布的《内容真实性倡议》中就已经开始推动此类验证。这项倡议目前已登陆Creative Cloud应用程序，希望为Twitter、《纽约时报》等重量级媒体提供照片内容与变更线索方面的跟踪能力，让受众以更透明的方式判断信息是否可信。</p><p></p><p>作为一款可选工具，内容真实性倡议没办法勘破deepfakes的花招，只是为社交媒体用户提供了一种查看未受操纵媒体可信度的方法。自项目公布以来，Adobe已经与多家数字平台和媒体组织建立合作伙伴关系，着手在他们的库存图像上添加内容真实性保障。</p><p></p><p>根据Parsons的介绍，deepfakes检测与内容来源是一对互补的验证工具——前者为被动检验，后者则是主动追踪。这不止能带来更高的线上内容透明度，同时也鼓励观众对自己看到的东西做出批判性思考。</p><p></p><p>Parsons解释道，“归根结底，照片和数学原理固然可信，但用户对媒体的信任其实是对组织、对人的信任。现在，我们对这些组织的信任比以往任何时候都更重要。我们既是内容消费者，也是事实核查者，应当查看内容来源并判断其是否受到了操纵或篡改。”</p><p></p><p>暂时来看，抗击deepfakes的任务需要由消费者和创作者共同承担，但未必会永远如此。短短八年，蒙特利尔一家酒吧里突如其来的念头就发展出了如此庞大的信息伪造产业，也许我们也能很快找到同样强大的检测方法、遏制住这股操纵媒体导向的歪风邪气。</p><p></p><p>原文链接：</p><p></p><p><a href=\"https://thewalrus.ca/fighting-ai-with-ai-the-battle-against-deepfakes/\">https://thewalrus.ca/fighting-ai-with-ai-the-battle-against-deepfakes/</a>\"</p><p></p>",
    "publish_time": "2022-08-18 13:35:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "OpenBMB x 清华NLP，如何玩转大模型？｜InfoQ《极客有约》",
    "url": "https://www.infoq.cn/article/2obhUaf98SE2j2uuyi8I",
    "summary": "<p>最近两年，超大规模预训练模型迎来了大爆发，国内外巨头和学术机构纷纷开启 AI 大模型研究热潮。然而大模型所需要的高性能计算能力与海量数据，让很多中小企业望而却步。如何推动大模型的落地和普及，让大模型真正飞入千家万户，是一个重要的课题。 InfoQ 和 OpenI 启智社区联合发起的《极客有约》第二季第一期直播，我们邀请到了清华大学计算机系的博士后韩旭，来给我们分享如何玩转大模型。</p>",
    "publish_time": "2022-08-18 13:51:56",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "云原生时代下的数智融合：让 AI 重新定义数据治理，让数据高效激发 AI 创新",
    "url": "https://www.infoq.cn/article/tXgNFT5odgXvBeMs76oX",
    "summary": "<p>在 VUCA 时代，市场变化加速，企业需要更加敏捷而准确的数智化决策，但众多企业面临着数据的困境，数据能力现状与需求之间存在差距，我们知道数据要素的价值，但却很难获得。而另一方面，数据分析和AI分析技术蓬勃发展，呈现出融合的趋势，让分析的广度和深度不断增强，让使用的门槛不断降低，越来越多的开发者开始关注数智融合的发展。</p><p>&nbsp;</p><p>8&nbsp;月 16日，华为云大咖说数智融合专场邀请到了艾瑞研究院总经理徐樊磊、华为云数据智能创新 Lab 高级技术专家季振峰、T3 出行大数据平台研发负责人杨华、顺丰科技大数据总监蔡适择四位来自不同领域的数据专家坐镇，以不同的视角解读“数智融合”这个话题。</p><p>&nbsp;</p><p>本期华为云大咖说线上分享会的主题为“数智融合，云上创新”，主持人为 InfoQ 主编赵钰莹，共分为专家分享与圆桌共话两大环节，以下为直播内容精编整理。</p><p>&nbsp;</p><p></p><h1>《2022 年中国数智融合发展洞察》研报解读</h1><p></p><p></p><h4>艾瑞研究院总经理徐樊磊</h4><p></p><p>&nbsp;</p><p>如今不管是技术层面还是应用层面，大数据智能化趋势都非常明显，不断加速着不同产业之间的融合创新，艾瑞咨询一直在关注数据+智能的整体发展，今年发布了一份《中国数智融合发展洞察》的报告，以下为艾瑞研究院的总经理徐樊磊的分享：</p><p>&nbsp;</p><p>首先，聊下数智融合的现状。提到数智融合，必然要聊下多元异构问题。一方面，我们要正视多元异构，在未来，它或许“更多元、更异构”。另一方面，多元异构意味着它必然是多元且分布式的状态，但使用时需要统一调度，所以这时就需要一个平台来屏蔽掉底层的差异，链接各个数据源，这样数据就能从“汇聚才可被用”到了“链接即可被用”。为了屏蔽底层的差异，像微服务等技术解决方案已经很成熟。所以，接下来数智融合技术的演进方向其实就是降低编写应用程序的难度，让技术更加贴近业务场景。</p><p>&nbsp;</p><p>从目前整个 IT 环境来看，IT 架构的明显特点是“去过程化”。自然状态下，数据往往都是“越来越乱”的，呈现出一个熵增的过程。如果想更好地使用数据，那需要采取一系列措施，比如抽象解耦、水平扩展的基础设施、高性能计算于网络、自动化与智能化等。</p><p>&nbsp;</p><p>其次，再来聊下数智融合技术的痛点及解决方案：</p><p>&nbsp;</p><p>1、数据量、存储成本和计算效率的“不可能三角”：存储成本、数据量、计算效率三者无法同时达到最优状态。想要平衡三者关系，那就需要“软硬结合”。现阶段的解决方案就是以内存为中心的计算，从一定程度上防止数据迁移，同时成本也可以达到可控状态。</p><p>&nbsp;</p><p>2、多元异构使数仓、数据湖、AI数据形成了新数据孤岛：数据出现多元异构后，我们肯定不能让数据散着，否则成本会越来越高，数据的不一致性也会越来越强。理想的解决方案是从底层调用数据，现阶段的解决方案大多是在应用中多加了一层（即三层结构），拿 Master 举例，它会有统一的元数据、目录、数据权限、事务的一致性多版本的管理。</p><p>&nbsp;</p><p>3、当下开源产品和方案很多，但在实际实施过程中人力成本和运维成本都很高：企业在使用开源产品过程中，遇见这个问题很正常，所以大家不用那么排斥商业商品，一味使用开源产品的话，也许后期投入成本远远高于购买一个成熟的商业产品。大家在购买商业产品时的顾虑可能在于担心它会不会倒闭或者未来会涨价、被深度捆绑后“难以转身”，所以在选择相应的商业产品时，要考虑厂商规模是否足够大，是否能够和开源完美结合，这样基本可以避免上述所有问题。</p><p>&nbsp;</p><p>4、数据产生的长链条使数据准备工作变复杂：对于数据治理人员来说，这个阶段会占用数智化过程中绝大部分时间。数据治理这件事如果完全靠人工去做，成本会很高，这也是当前企业要数字化转型的初衷。当下的解决方案是，低代码+人工智能，让数据治理这件事变简单，无论是技术人员还是业务人员都能够去处理这些数据。</p><p>&nbsp;</p><p>最后想说的是，像华为云这种厂商便能够解决以上痛点，在未来对于数字融合产品的搭建和输出上都有比较大的技术优势和服务优势。在软硬融合、行业实践和开源生态方面，华为一直做的都很不错，是一个不错的选择。</p><p>&nbsp;</p><p></p><h1>《数据治理的生产线，构建高效、安全的一站式数智融合治理平台》</h1><p></p><p></p><h4>华为云数据智能创新 Lab 高级技术专家季振峰</h4><p></p><p>&nbsp;</p><p>关于数智融合，华为云也有自己的观察和思考，华为云数据智能创新 Lab 高级技术专家季振峰解读了华为云数智融合的解决方案：</p><p>&nbsp;</p><p>当前企业想要进行数字化转型，主要面临三个挑战，即复杂的数据治理导致成就业务难、系统众多架构复杂和技术门槛高。为了解决这些难题、更好地释放数据价值，华为云面向数据治理提出了数据治理生产线 DataArts，像生产线一样把海量的、复杂的、无序的数据生产为高质量的、清洁的、透明的数据能源，输送给业务并帮助业务驱决策。</p><p>&nbsp;</p><p>DataArts 采用 AI 辅助数据治理，目的是实现全生命周期的自动化和智能化，当前已经支持实时的数据入湖和数据分析、自动的数据处理以及自动数据标准化和质量稽核、全面的安全链路管控能力保护用户隐私数据和合规审计，并且与华为的 AI 开发生产线 ModelArts 进行了贯通。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/86/53/86105e6cd405e6ed3cc7d74cdbeb2553.png\" /></p><p></p><p>DataArts 提供丰富的 OLTP 和 OLAP 数据服务，应对多样化的数据场景。同时，提供集中化的数据治理和管理，包括：</p><p>&nbsp;</p><p>1、从 DGC（数据湖治理中心）升级到 DataArts Studio，涵盖了从数据集成到数据开发、数据质量、数据服务的全流程，既支持大数据开发人员可以高效的进行数据的开发和生产，也支持不懂数据开发和数据分析的业务人员去处理和加工各种数据。</p><p>&nbsp;</p><p>2、集成了丰富的工具让企业不同系统不同类型的数据能方便快捷得入湖，使低代码的编排可以支持企业的异构数据源，通过很方便的编排方式就能将各种数据接入进来，同时在接入的过程中可以支持隐私数据的发现，以及选择是加密存储还是加密传输，同时也提供了端到端的链路监控能力。</p><p>&nbsp;</p><p>3、即将上市的 DataArts LakeFormation，可以支持湖内的数据湖、数据仓库、大数据及 AI 元数据统一管理，并且支持湖内元数据事务性的更新和修改、半结化数据的元数据自动提取，让数据不用在多个湖、仓、AI分析系统中来回移动，而导致的数据不一致问题，基于一份数据进行分析，让决策结果唯一可信。</p><p>&nbsp;</p><p>4、融合低代码和无代码的开发模式，支持低代码和无代码开发数据，准备数据加工，处理好数据作业，极大的提高了开发的效率。将数据开发从之前的天级提升到了小时级，甚至是分钟级，用户无需懂 SQL、Python，甚至 Java 代码，只需要在我们的低代码开发界面上通过拖拽的方式选择各种数据处理算子，就可以数据的加工和处理。</p><p>&nbsp;</p><p>5、企业级数据目录，帮助企业实现数据的资产化管理。企业的数据通常是异构的，零散的，在物理上可能分布在不同的地域，甚至可能在不同的云上面。从物理上很难把这些数据存储到一起，而从逻辑上又需要一个统一的数据目录，来对这些数据进行统一的管理，因此 DataArts 面向多云、多 Region，多级数据湖提供了统一的数据目录，可以自动的采集、分析和识别、存储企业里头各种数据的元数据信息，并且将基础元数据和业务元数据、管理元数据进行自动关联、补全，实现数据的资产化管理，让数据能够找得到、好理解、易使用，支持更好的查找数据，支持以自然语言搜索的方式去搜索到资产，可以自动的给出搜索建议和自然推荐，并且实现搜索的智能纠错，根据用户的搜索意图做好资产的排序。</p><p>&nbsp;</p><p>6、全链路的数据安全保护能力，让企业可以统一的配置企业的数据安全策略，达到数据的加工全链路都能受到数据安全管控的目的，从数据集成、数据架构、数据开发、数据目录到数据服务我们都提供了很全面的数据安全管控能力，这些能力包括数据访问权限管理、敏感数据发现、隐私数据保护、数据风险管理，以及数据的合规审计。</p><p>&nbsp;</p><p>7、面向生态开放，引入了 BI、主数据、数据建模、数据标签等数据管理行业 TOP 伙伴的 SaaS 产品，并与数据治理生产线 DataArts 云原生服务集成，为客户提供一致性的体验。</p><p>&nbsp;</p><p></p><h1>《“围湖而建”的智慧出行——T3 出行的Lakehouse 架构与实践》</h1><p></p><p></p><h4>T3 出行大数据平台研发负责人杨华</h4><p></p><p>&nbsp;</p><p>T3 出行作为华为云数智融合解决方案的使用方，在数智融合领域也有自己的一些思考，T3 出行大数据平台研发负责人杨华进行了分享：</p><p>&nbsp;</p><p>T3出行的Lakehouse采用了存算分离的架构，借助华为云 FusionInsight 整体托管能力，构建在华为云的 OBS 对象存储之上，在计算层，从 T3 出行的业务场景出发，面向 BI 和 AI 两个方向构建了自己的计算体系。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/e8/26/e8747e02169055048da890a231dfcf26.png\" /></p><p></p><p>解析 BI 类框架。T3 出行 Lakehouse 的对象存储和计算层中间引入了 Apache &nbsp;Hudi 框架，起到一个“承上启下”的作用，目前像华为云等国内主流云厂商都在围绕它封装一些开箱即用的能力。该框架的核心特性是能在 Hadoop 及云存储上提供 upserts、deletes、incrementals 能力，它能够支持 ACID 的事务语义层，支持做增量处理、增量计算，支持智能存储的布局管理以及 time &nbsp;travel 的查询。</p><p>&nbsp;</p><p>Apache Hudi 生态很丰富（见下图），左侧 Data Sources 能够支持多种多样的数据源，能够将数据摄取到 Hudi 表的数据存储中来。在右侧最底层还能够支持主流的这种开源的数据存储，像 HDFS 以及各大云厂商的兼容 HDFS 的对象存储，目前它现在已经能够支持主流的开源大数据的存储查询和计算引擎。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/e6/2d/e60a0e5847b433b0b370913b1198612d.png\" /></p><p></p><p>T3 出行应用 BI 类框架的三个典型实践：</p><p>&nbsp;</p><p>第一个实践便是“入湖”，即将业务的关键数据（尤其指变更数据）摄取到数据湖中。T3 出行采用 Spark 来将业务的存量数据摄取到 Hudi 表中，而处理主要来自业务的关系型数据库的变更数据，T3 出行借助的是基于 Binlog CDC 的能力，先将 Binlog 采集到 Kafka，然后通过 Flink 做一层轻粒度的汇聚。因为 T3 出行会有一些分布分表的数据，需要将它汇总成一个逻辑上的大表，通过 Spark 或者 Flink再将数据摄取到数据湖中。在杨华看来，“经常发生变更的数据需要持续增量地、以低延迟的方式同步到数据湖中。”</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/a1/3c/a1e3f209d91df2yy421dabda1ee1c13c.png\" /></p><p></p><p>第二个实践是 T3 出行在湖仓中的 ETL，此处的数据加工大概分了几个层次。首先存储层还是一些 Hudi 表，计算的主要引擎是 Spark SQL，使用了 Apache Kyuubi 框架来解决多租户隔离问题。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/a2/e0/a235cf6ac19fcbbe4a888ed4c11d6fe0.png\" /></p><p></p><p>第三个实践是关于 T3 出行数据 OLAP 以及 AD Hoc 的能力，拥有不同的 Client 以及不同的业务场景，除了能够对不同的场景做租户隔离以外，还能对相同的租户里面不同的用户去 share 上下文，除了 Spark &nbsp;SQL 外，在这里引擎还引入了像 Presto 等其他相关的一些引擎，全部都托管在 Kyuubi 的  Gateway 上。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/ae/35/ae80e6d19261c7520b97786fb78ceb35.png\" /></p><p></p><p>解析 AI 类框架。资源管理方面，T3 出行借助 Kuberentes 面向于不同的训练场景，抽象出了 CPU 集群、GPU 集群，T3 出行还借助微众开源的 Prophecis 的机器学习平台来做资源及机器学习环境的管理，内置了一些开箱即用的算法库及相关环境。最上层业务应用了像 Jupyter 这种集成开发环境进行业务开发。</p><p>&nbsp;</p><p>T3 出行基于机器学习的 Lakehouse 的实践，构建了一体化的数据管理体系，T3 出行利用数据管理体系对特征数据进行版本化管理。其中，特征工程阶段是开发过程中的关键阶段，T3 出行采用了 Feature Store 体系做 MLOps。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/33/91/3370d146a639a767c042a6d2ffb3f591.png\" /></p><p></p><p></p><h1>《DataOps 驱动数据中台云原生》</h1><p></p><p></p><h4>顺丰科技大数据总监蔡适择</h4><p></p><p>&nbsp;</p><p>关于数据融合，不同的企业、不同的开发者的理解均有差异，对于顺丰科技来说，他们将视野聚焦在了 DataOps 与云原生数据中台的关系上，顺丰科技大数据总监蔡适择对此进行了分享：</p><p>&nbsp;</p><p>在顺丰科技数据中台的全景图中，最核心的还是可持续发展的数据治理体系。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/de/f8/de21a25bc9586df28fd7eeb1298beff8.png\" /></p><p></p><p>为了支撑顺丰科技的数据开发用户，让他们能够更加便利简单的进行数据开发，顺丰科技在 DataOps 方面做了许多努力，从需求出发，到建模、接入、开发、管理、服务以及整个数据上架的全环节，相当于做到了端到端的打通、全链路的重新梳理以及自动化串接过程实现。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/97/e7/97233b9d3e6c5914dc77c1991773afe7.png\" /></p><p></p><p>当 DataOps 整个环节自助化后，顺丰科技发现因为有很多多人协作、运维紧急保障、高峰应对这样的诉求，所以这就要求中台具有极致的弹性能力来保障资源。此外，在数据安全方面，还要保障用户测试时线上数据不被污染，灰度上线要保证数据能支持多版本、可恢复的操作，整个数据共享也要有行级、列级全局管控等等。</p><p>&nbsp;</p><p>然而对于顺丰科技 DataOps 来说，并不能要求用户去了解这些底盘，包括测试环境、生态环境、研发环境，所以我们赋予了它云原生能力，这也是 DataOps 对数据中台底盘的基础诉求。</p><p>&nbsp;</p><p>顺丰科技为此就构建了弹性、融合、实时的全体系链条（见下图）。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/1a/73/1aa22010cea91ab34befc31779b68f73.png\" /></p><p></p><p>如上图所示，左边部分是统一 SQL 和统一元数据，相当于把数据分布到不同的地方、不同机房、不同引擎的情况对用户透明，建一套逻辑统一的数据湖，同时构建统一 SQL，达到让用户跨机房跨引擎使用的时候无感，跟使用普通 SQL 没有任何区别。</p><p>&nbsp;</p><p>为构建资源弹性能力，顺丰科技建立了以存算分离、分布式缓存、容器化为核心的大数据架构，在存储层面进行了对 HDFS、S3 的融合，相当于一个存储服务既可以支持 HDFS，也可以支持 S3，也可以支持他们混合使用。在计算方面，顺丰科技也做了容器化，就是把引擎（尤其是 Spark）做了纯粹的 Kuberentes 化，并以自建的非共享式缓存缓解存算分离后带来的性能损失，最终实现资源的按需弹性伸缩及跨云弹性融合的效果。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/af/4a/afd1d0ccafb53ccf8a714e6b21231f4a.png\" /></p><p></p><p>在数据组织优化方面，首先，用户想要做一个数据的复制或者对数据进行生产测试，因为要用到的数据就是生产数据，且测试数据还要跟原来的数据做对比，所以需要这个数据本身支持多版本，于是顺丰科技以 Hudi 作为数据底盘。Hudi 包括两部分，一部分是数据怎么快速接入进来，另一部分是用户如何通过简单的 SQL，把 Hudi 本身也有的一些能力整合进来，让用户在做数据开发的时候跟离线开发没有什么区别，直接用 SQL 即可用 Hudi 数据进行准实时数据开发。</p><p>&nbsp;</p><p>在测试的时候，也就是用户在线上测试运行阶段，平台自身会在后台做数据的克隆，并自动对比试运行结果，若没有问题的话即可自动上线，变成生产任务，让整个数据的加工、测试、上线做到比较准确的验证。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/df/31/df630be58a21a4993665db08ffbf2e31.png\" /></p><p></p><p>至于统一 SQL，则指的是把数据由汇聚才可以用，转到链接即可用的效果，相当于是一个逻辑统一的实时的数据湖，这里有三个重点，第一个是支持跨云、跨大数据分析引擎的融合分析，相当于一个简单的 SQL 能够直接跨 Hive、Presto，包括 Doris 进行实时关联和分析，这些都与数据资产打通，相当于只要是数据资产管理的数据，用户都可以通过简单的 SQL 进行融合的数据分析。第二个是无感优化用户大数据架构，支撑已有技术生态，实现向云上数仓的平滑过渡。第三个是，支持跨云、跨大数据引擎全局统一元数据管理，实现统一权限管控，并支持基于代价估算的全局解析执行引擎。</p><p>&nbsp;</p><p>总体来说，统一 SQL 相当于是顺丰用户对大数据使用的视窗，实现用户对数据的端到端透明化使用。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/0d/4c/0d2118483580b6367b0e9cd70b2d6b4c.png\" /></p><p></p><p></p><h1>圆桌畅谈：“数智时代，重塑数据价值需要几步？”</h1><p></p><p>&nbsp;</p><p>Q：如何定义未来的\"数据价值”？未来的\"数据价值”是怎样的？</p><p>&nbsp;</p><p>徐樊磊：在不同的时期，数据价值应该“匹配”不同的特点，比如说 PC 互联网时代，我们用谷歌、百度层搜索引擎，其实也做到了人和文本信息的匹配，但这种匹配相对来说是比较浅层次的。未来我们能看到的这种“匹配”将达到多维，比如实时、主动的、结构化的。所以说，定义未来的数据价值，其实就已有数据真的能“匹配”到你想要的。</p><p>&nbsp;</p><p>季振峰：数据现在已经成为数字经济时代的生产要素，作为生产要素，它可以流通和交易，这在某种程度上就体现了数据的价值。但数据真正的价值不在于交易和流通，而在于使用，即：描述现在、模拟变化、预测未来。从数据中获取知识和洞察，并驱动企业的业务决策是数据价值的真正体现。</p><p>&nbsp;</p><p>杨华：站在企业的角度来看，我认为不管什么时候数据的核心价值一直都是让数据变得更能够驱动业务的决策以及企业的管理或者变革，这是它的核心要素。就未来价值而言的话，我们需要继续提升我们数据的新鲜度，因为我认为越新鲜的数据它的价值其实是越高的，这也是现在像一些 Streaming 的 Database 变得越来越流行的一个原因。</p><p>&nbsp;</p><p>蔡适择：看数据，本质上来讲还是为了了解自己，了解企业自己的情况、了解客户，这些数据驱动企业做战略调整及规划，这是数据最基本的价值。从经济学角度来看，价值是客体对主体表现出来的意义和效用性，所以数据价值应该是由数据真正的使用者，即消费者来定义的，说白了应该是由市场需求来决定。但这也并不意味着那些未被使用的数据就没有价值，因为现在没有使用也不代表未来不适用。</p><p>&nbsp;</p><p>Q：低/零代码实现自动化，AI 是否真的可以反哺数据实现智能化？</p><p>&nbsp;</p><p>徐樊磊：这个问题可以简单翻译为低、零代码这种技术的背景之下，AI 在数据治理中是否可以发挥作用。答案是肯定的，之前，在图像的识别、语音识别等很多领域，AI 的能力已经超过人类，所以在数据治理领域，AI 的未来也是值得期待的。低、零代码这种相对低门槛，可以让大家便捷地进行数据处理，这直接可以说明，AI 促进了数据治理。</p><p>&nbsp;</p><p>季振峰：AI 反哺数据实现智能化主要有以下几个方面。首先，自动数据处理，自动数据特征识别、自动数据标准化和质量稽核等。其次，自动运维，数据开发作业的运维和调度是非常复杂的，AI 可以通过作业依赖关系和作业运行情况做到自动运维，并智能停止或重新执行作业。最后，AI 在一定程度上也能支持资源优化，包括计算资源优化、数据处理流程优化、查询优化等。</p><p>&nbsp;</p><p>杨华：AI 是可以去促进低代码或者零代码自动化的，但这是个未来趋势，现在应该还达不到理想状态。比如最大的开源托管代码服务提供商 GitHub 已经开发了代码的自动补全的一些工具，但是很多的自动补全其实仍然存在很大的漏洞。又比如说被引用的代码可能存在一些缺陷或者一些严重的安全漏洞，只有解决了安全性问题，才可以正式的谈“AI 是否真的可以反哺数据实现智能化”。</p><p>&nbsp;</p><p>蔡适择：业界在这一块也开展了不少的尝试，取得的效果还是不错的，包括顺丰自己在这方面也落了不少的成果，比如说数据安全的打标，像这种单场景多数据的情况下，通过规则及数据属性以AI的方式去识别数据的敏感度，并且依托数据血缘实现数据安全的全链路的自动标注，达到全面的数据安全梳理。</p><p>&nbsp;</p><p>Q：基于 AI 应用的数据治理面临着哪些难题？想要重塑数据价值，需要怎么做？</p><p>&nbsp;</p><p>徐樊磊：第一，做数据的准确和统一的原则，原先我们看到仓是仓，湖是湖，AI 是 AI，这种数据的不统一导致最后没有一份原始的、统一的、准确的数据可以进行调用，那“数据价值”就是空谈。第二，要重点关注规模，因为 AI 跟人工不太一样，AI 至少目前它需要投喂大量的数据。而且成本要足够低，因为成本高会导致用户舍不得保留这些数据。第三，解决端到端的统一，企业内的每个角色对于数据的操作方式都实现统一，每个人都能以最简单、最便捷的方式将自己的需求反馈到“链条”上的每个人。</p><p>&nbsp;</p><p>季振峰：要发挥数据的价值或者重塑数据价值，首先要通过数据治理把数据从异构的、离散的状态变成真正的数据资产。数据治理正在从人力密集型向集约化、自动化和智能化转变，因此华为云推出数据治理生产线 DataArts ——顾名思义，就像生产线一样，把海量的复杂的无序的数据，生产成为清洁透明高质量的数据能源，输送给业务。</p><p>&nbsp;</p><p>杨华：重点还是要关注数据治理的准确性。例如我们在治理得有些方面，比如说数据安全方面其实是不会允许给你一些犯错的机会的，因为在安全这一块，现在其实是非常的严格。</p><p>&nbsp;</p><p>至于重塑数据价值，我个人认为在允许犯错的地方，可以逐步利用算法或者自动化的规则来逐步地替换掉人力。像安全这类需要严格处理的方向还是得和自动化能力配合着来，当然 AI 和人工的配置比重也是随着AI技术的进步而发生变化的。</p><p>&nbsp;</p><p>蔡适择：数据价值重塑可分为三步，首先，构建端到端的数据生产的供应链；其次，全局统一数据治理体系，让数据分类清晰明了；最后，数据平台要建立自运营体系，以数据运营来驱动数据治理，使数据价值量化，让数据模型自动持续优化。只有数据被及时使用，才叫真正地产生了价值。</p><p>&nbsp;</p><p></p><h1>圆桌问诊：开发者比较关心的问题</h1><p></p><p>&nbsp;</p><p>Q1：数智融合时代，如何做好\"元数据管理？</p><p>&nbsp;</p><p>季振峰：元数据管理是数智融合的关键基础，数智融合需要无缝连接企业任何数据，构建企业级数据目录，实现数据的资产化管理。元数据管理的业务目标简单来讲就是让企业数据找得到、好理解、易使用：</p><p>找得到：构建主动元数据能力，主动查找、识别、采集、丰富和存储企业各种元数据信息；好理解：通过元数据智能，自动分析数据特征、识别关联关系、补全业务元数据、构建数据知识图谱等；易使用：构建企业级数据目录，提供企业统一的数据资产视图，支持数据智能搜索推荐、数据共享交换、数据价值评估等能力，支撑数据价值变现。</p><p>&nbsp;</p><p>杨华：我觉得元数据管理我们可以拆解为三步走的策略，首先是定目标，接着是出方案，然后是推落地。</p><p>&nbsp;</p><p>首先定目标要先确定元数据想干啥，想实现怎么样的价值。因为元数据从概念上来说还是比较宽泛的，我们常规会分为业务类的元数据，技术类的元数据，以及操作类型的元数据。元数据的应用场景其实也是比较多的，比如说典型的应用在数据治理或者提升作业的溯源能力，我们现在可能有一些更高的目标，比如说更好的促进布局一体化或者 AI 一体化的这些能力的融合。</p><p>&nbsp;</p><p>其次，出方案。就是为了实现这个目标我们需要怎么去做，因为这样的话我们就可以判断我们有哪些元数据可以采集，怎么存储？是不是需要用一些图数据库来存？怎么查询？怎么使用等等。考虑到融合，我们还会判断我们还需要哪些类型的元数据，我们可能会需要一些定制化的开发，我们可能需要构建一个从采集到存储，到提供访问服务的一体化平台，将整个元数据的能力释放出来，在此之上我们可能还会构建一个用于实现目标应用层的能力。</p><p>&nbsp;</p><p>最后，推落地是指有了我们的方案之后，接下来落地去实施的。在实施的过程中我觉得也不一定非得从零开始，比如说我们可以向利用现在一些云厂商，华为云已经提供的已有的开箱即用的能力。在业界也有一些开源的元数据平台或者相关的框架，例如 LinkedIn 之前也开源过一个叫 Datahub 的元数据平台，当然对于业务类的元数据其实可能还需要基于特定的业务场景来做相应的定制。</p><p>&nbsp;</p><p>当前其实在机器学习和 AI 方向的元数据建设业界应该主要处在比较初级的阶段，这部分可能需要整个行业花一些精力做一些探索。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;</p><p>&nbsp;Q2：如何利用 AI 技术从源头上建立完整、科学的数据治理体系？</p><p>&nbsp;</p><p>蔡适择：通过 AI 技术可以大幅便利这个进程，首先比如说在找数据方面，因为找数据不仅仅是数据消费者，也包括数据开发者自己要开发数据的时候也涉及到找数据，所以在找数据方面重点在于元数据的完善和管理，也就是刚刚畅谈环节里面也聊到，通过 AI 技术可以根据数据规则，利用聚类和知识图谱实现数据的自动分类、自动识别主数据，自动构建全链路的 ER 视图，补全注释、数据类型，包括敏感级别来进行全链路的跟踪，让数据清晰的摆放到相应的类目上，让用户能够快速定位其所需要的数据。</p><p>&nbsp;</p><p>再者，我们让用户搜到的数据能够快速被使用，除了打破数据孤岛，屏蔽底层技术，建立逻辑统一的数据中台，让用户透明使用之外，更为追求的是要数据的模型能覆盖面更全，关联更少，使用户得以通过简单的拖拽获得想要的数据，在这里AI技术就可以发挥非常大的作用。</p><p>&nbsp;</p><p>徐樊磊：利用 AI 技术从源头上建立完整科学的治理体系，主要需要关注三点。第一，面对这种重复的治理工作，需要搭建针对性体系解决的重复性的环节，将面向 AI 数据治理环节流程化、标准化，包括体系化，主要目的是降低数据的反复准备、特征筛选、模型调优迭代的成本，缩短 AI 模型开发建构全流程的周期，要提升 AI 应用规模化落地的效率。第二，从建设之初就要考虑多元异构数据的质量管理体系。第三，基于多元异构需要做标准体系的建设准备，为 AI 整个模型开发提供一致的数据语言，从而快速实现数据的重复共享，进一步进行数据的特征管理，将多元异构数据转化为机器能够理解的“结构化数据”。</p><p></p><p>华为云数智融合平台，通过 DataArts 和 ModelArts 融合的独家创新架构，打通了大数据和人工智能，兼顾成本与性能，实现统一管理、一数多用，同时实现敏捷用数，全流程自动化与智能化。</p><p>&nbsp;</p><p>同时，华为云数智融合平台的领先优势和价值，也在千行百业的实践应用中得到印证。尤其在互联网行业市场，依托数智融合平台，华为云已助力 T3 出行、梦饷集团、脉脉、兴盛优选等互联网企业提升数据利用效率，加速业务创新，实现降本增效提质。目前，已有 80% 的中国 Top50 互联网企业选择华为云，“H（华为云）+X”的多云部署模式也越来越受到企业客户的认可与选择。</p>",
    "publish_time": "2022-08-18 16:39:38",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "“今日头条”名字是AB测试定的？字节跳动用九年时间打造出了怎样的数据平台",
    "url": "https://www.infoq.cn/article/NePuifvKismCoTWecrLg",
    "summary": "<p></p><p></p><blockquote>8 月 18 日，在北京·富力万丽酒店举办的 <a href=\"https://archsummit.infoq.cn/2021/beijing/?utm_source=infoq&amp;utm_medium=footer\">ArchSummit 全球架构师峰会</a>\"上，字节跳动数据平台负责人罗旋老师，分享了字节跳动从 0 到 1 的数据平台建设过程。从最简单的数据处理方法，到国内最前沿的数据处理手段，字节数据平台经历了多阶段的发展过程，也有很多解决问题的思路值得技术人关注。以下是演讲整理，以飨读者。</blockquote><p></p><p></p><p></p><h2>数据平台发展路径：大而全？还是从业务问题出发？</h2><p></p><p></p><p>大家好，我是罗旋，来自字节跳动数据平台。今天我想跟大家分享的主题是《字节跳动数据平台的实践与演进》，主要会从我们数据平台的发展历程、为什么这么发展、每个阶段的挑战是什么，以及我们对挑战的解法等方面来介绍。</p><p></p><p>我们讲，字节跳动数据平台的演进脱离不了一个更大的背景，就是字节跳动业务的发展。抖音、头条等业务发展有什么特点？从这个图可以看出：快 + 多。</p><p></p><p>快：头条，12-14 年破千万；抖音上线 17 个月 DAU 破亿，5 年破六亿。多：除了图文信息流、短视频，还有电商和 ToB 等众多业务线。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/13/13f4b0f3587e14db3bc98c406dd1cef7.png\" /></p><p></p><p>接来下，我们来看看数据平台当前的业务架构形态。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/69/69e7e38134ca52d754aee17901a23754.jpeg\" /></p><p></p><p>从横向来看，最上面是我们服务的客户，下面则是我们的能力，分为“中台能力 + 解决方案”两层。从纵向来看，左边蓝色部分的服务对象是字节跳动内部的各个业务，右边绿色部分是字节跳动外部的企业客户。</p><p></p><p>字节跳动内部，我们的中台能力分为引擎层、建设层和应用层来建设，再通过数据 BP 团队对内部业务提供综合性解决方案，来驱动业务发展。而基于内部的这些能力和经验，我们又封装成供外部使用的中台底座和营销套件，以产品解决方案的形态，通过火山引擎来对外部客户提供服务。</p><p></p><p>如果只看这个图可能也没有太特别之处，但相信各位同行都知道，要把这么一套体系完备地搭建落地，并不是容易的事，有很大的工作量和挑战，有一段很长的路要走，很难一蹴而就。</p><p></p><p>那么，如果一个企业的决策者已经认识到数据驱动的重要性，决心要落地这样一套体系的话，接下来就马上面临一个问题：路径怎么选？怎么从零 / 初级阶段到达一个比较完备的阶段。这里，有两个选项：</p><p></p><p>选项 A ：要从一开始就有大而全的规划，非常明确的步骤，建设一个完善完备的系统架构，再来服务业务。选项 B ：先从实际业务问题出发，业务哪有问题先解哪，优先解决业务痛点问题，让业务价值来驱动，数据体系的建设。</p><p></p><p>不知道大家心里有没有答案。</p><p></p><p>字节选的是什么呢？路径 B：从业务出发。</p><p></p><p>我们除了主观上的思考，认为更应该先解决业务问题，验证业务价值外，也有客观的因素。比如，刚才介绍的字节业务发展，相信大家也可以感觉得出来。字节的业务发展得实在太快了，我们没有时间遵照大而全的规划一步步慢慢建设好。业务等不起！</p><p></p><p></p><h2>字节跳动数据平台发展历程</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/8b/8bef8644433515105b2e839db15f7915.png\" /></p><p></p><p>如果具体拆解一下，我们的发展路径可以分为这么四个阶段：</p><p></p><p>2014 年及以前，原始阶段</p><p></p><p>当时，只有 1 个 Hive 和最基础的几张报表，仅包括 DAU、时长等，报表仅以邮件形式来发送，是非常原始的一个状态。</p><p></p><p>不过很有意思的是，在这个时候，我们已经开始重度<a href=\"https://www.infoq.cn/article/T7HCVlTeUCSroDRhT1FF\">使用 A/B 测试</a>\"了，这是我们最早相对成熟的一个系统。相信这跟绝大多数公司的发展顺序都不同，因为在那个阶段，我们认为最重要的事，就是让业务能够量化、度量，并以非常快速试错的方式来迭代。</p><p></p><p>2015-2017 年，基础建设阶段</p><p></p><p>我们快速补齐业务发展所需要的各项数据基础能力，包括如何让业务更快获取数据的底层引擎、让业务可自主分析的一些应用型产品等。</p><p></p><p>2018-2019，平台阶段</p><p></p><p>但我们的业务发展实在是太快的，除了业务体量增大，业务线也越来越多元化、有差异性。对接了更多业务线后，光建设好基础能力也不能更好满足业务需求，需要更有效驱动业务发展的方式。所以，我们在 18 年开始探索数据 BP 模式，一方面平台能力持续升级，产品矩阵扩大，另外一方面，通过 BP 的模式深入业务，可以为业务提供更适合自身发展的数据解决方案。</p><p></p><p>2020 年之后，ToB 输出阶段</p><p></p><p>这时，我们开始思考在对内提供优质服务的基础上，能不能也帮助更多的外部企业，把这件事做好、产生更大的价值。所以，我们也开始也把这部分能力对外开放，封装成产品套件和解决方案，对外部其他企业服务。</p><p></p><p></p><h2>如何应对发展速度的挑战</h2><p></p><p></p><p>在不同的阶段中，我们遇到了非常多的挑战。今天，我会分享其中一些最典型的问题和解决方案，希望我们趟过的这些坑和经验能对各位同行有一定助益。</p><p></p><p>首先就是一开始，在一穷二白的情况下，我们面临最直接的挑战就是：业务随时迭代上线，我们要怎么快速帮助业务去做验证？</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d8/d88759965b8afa059e8a5fec3aff3dc1.png\" /></p><p></p><p>这是一张 14 年今日头条迭代发版的情况，仅仅用了 3 个月不到的时间，今日头条就发版 10 次，这个速度还是非常快的，而且大部分发版都有一些新的优化改进或者突破。这还仅仅是客户端的部分，实际在服务后端、个性化推荐等领域，迭代甚至更加频繁。</p><p></p><p>这些飞速迭代的背后依靠的是什么？一个新功能、新模型、新特征为啥要增加，增加了是不是就会更好？判断的依据是什么，怎么来保障正确性？</p><p></p><p>针对这些挑战，我们的解法是什么呢？刚刚其实也已经提到过，我们是一家重度使用 A/B 测试的公司。所以，基本每次迭代的背后，都有 A/B 测试的身影。可以说，A/B 测试是字节数据文化的最典型代表。</p><p></p><p>字节的 A/B 测试发展也经历了三个阶段：</p><p></p><p>A/B 测试是在 12 年字节跳动成立之初就开始应用了，今日头条的命名也是 A/B 测试的结果。当然，在原始阶段的 A/B 测试是很粗糙的，也不像现在有那么多功能和场景，从统计科学角度也有很多欠缺。一开始，我们对 A/B 测试的定位，只是一款快速拿到实验结果的验证工具。因为业务迭代很快，当时做一个 A/B 测试，我们有时需要几天，甚至一到两天就要出一个结果。当时业务各方面的提升空间都比较大，在这样的环境下，A/B 测试起到了关键的作用，但还是单纯工程师使用的工具。后来，随着需求的增多，功能也在不断丰富完善。同时，A/B 测试需要提升在业务上的易用性，工具形式无法满足。于是在 16 年，我们开始重构 A/B 测试，以产品的形式来提供更便捷优化和标准的服务。A/B 测试也从一个验证工具变成了一个产品，内部命名为 Libra，寓意为客观。这是我们数据平台的第一款自研产品。这个阶段，Libra 的能力也有了较大发展。与此同时，业务场景也更丰富，接入了广告、推送等场景，同时互娱、搜索业务全面接入。访问高涨，测试总数从之前 1w，直接飞升到了 10w。随着业务形态不断丰富，我们也需要提供更多场景化的支持和深入。除了基础产品功能之外，我们近两年更多追求的是效率和场景的覆盖，还提供更多场景化模板和解决方案，降低使用门槛。比如，我们现在也支持运营类的一些场景，让小白用户也能自助使用。</p><p></p><p>刚刚讲的是原始阶段，我们通过不断 A/B 测试，小成本快速奔跑快速试错的方式，来支撑业务快速迭代。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/1a/1add02c2c015dcb3d0f5b4a8dc380f45.png\" /></p><p></p><p>字节的业务发展非常快，而数据量的增长更快。16 年的时候，我们每天处理的数据量大概是 200TB。去年，我们日处理数据量已经达到 1500PB，数据平台日新增数据 40PB。</p><p></p><p>这是我们面临的另外一个非常大而艰巨的挑战。在之前数据量小的时候，业务看数据做分析，能够很快的产出，但大一万倍的时候呢？相信各位同行都知道，数据量每上升一个量级，对架构都有新的挑战，何况是好几个量级。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/08/080709aac8b684969dccb2db3eef7e6b.png\" /></p><p></p><p>为了解决数据量和分析效率的问题，我们在引擎层面做过很多探索，当然也有一些曲折的地方。比如在 OLAP 引擎上，我们尝试过 Kylin、Druid、Spark。</p><p></p><p>比如，一开始我们选了 Kylin，它的优点是响应速度毫秒级别，能解决查询响应慢的问题，但需要预聚合，存在维度组合爆炸带来的计算存储量浪费，同时存在需要提前定义、分析灵活度不足等问题。之后，我们又尝试通过 Spark 来解决，但查询速度又不够极致。</p><p></p><p>后来我们开始反思，现有的查询引擎是否能持续支撑后面的高速发展？我们有哪些根本性的需求，应该通过什么样的技术来满足？</p><p></p><p>结论是，我们有几个根本性需求：首先，能够处理海量数据，具有高度可扩展性。其次，要有超高性能，秒级响应。然后，分析模式具有高灵活自主性，能够基于明细数据来分析，而非聚合数据。在这些基础上，还要考虑二次开发、集成的便利性、可运维性、易用性等等。</p><p></p><p>最终，我们确认<a href=\"https://xie.infoq.cn/article/24bca839b30cd4de43f896ec6\"> ClickHouse </a>\"作为最终使用的 OLAP 查询引擎，它在满足我们最根本诉求时，还具有突出的优势。我们也在开源版本上不断迭代，弥补了它的一些不足，也进一步强化了优势。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c8/c84a513e2a13818626c3772b1bde5337.png\" /></p><p></p><p>在确定 ClickHouse 之后，我们也经历了三个阶段的迭代演进：</p><p></p><p>第一阶段，要在生产环境中大规模使用，首先解决的就是可用和稳定。我们在这个阶段，主要做了高可用引擎和稳定性优化，增强运维能力。此时，我们主要在广告和用户增长业务上提供服务。在可用性和稳定性达到 SLA 后，我们进行了数据分析架构统一，把之前零散异构的分析架构做了统一。这本质上是基础设施的复用，也是中台化理念的一种体现。所以，我们能在这技术栈上搭建各种面向场景化的应用，比如 CDP 等。再之后，我们把重点放在了提升资源利用率、降低运维成本和提升数据的实时性上。在这个阶段，我们发布了自己的云原生版本，叫做 ByteHouse，提供了存储计算独立扩缩容的能力，也面向实时数仓做了很多优化，运维的友好型大幅提升。</p><p></p><p>目前，ByteHouse 字节内部数据分析服务超过了 2.5 万个节点，单集群最大规模可以达到 2400 个节点左右，从业务上来看，在字节内部支撑了超过 80% 的业务分析应用。也正是因为经过了字节内部的磨炼，我们去年才有信心将 ByteHouse 对外部企业开放提供服务。</p><p></p><p>那么，<a href=\"https://www.infoq.cn/article/gz7yXwgCwNWeEs1M8kOP\">ByteHouse</a>\" 的核心能力有哪些呢？</p><p></p><p>第一，实时分析场景。在海量数据场景下，我们可以支持真正的实时数据分析。单集群层面，可以在复杂业务模型情况下，每秒钟数据实时写入的吞吐量可以达到千万级别，能够实现极致的 time-to insight 体验。第二，架构下面实现了存储和计算的分离，计算节点可以弹性伸缩，更灵活且有效地利用资源，从而降低使用成本。这样在做集群规划的时候可以把它们两个完成解耦开。第三，不同业务部门、不同业务用户可以针对性申请资源，做到多级资源隔离，以提升资源利用率。第四，实现 OLAPaaS，借助云上全托管服务，支持服务随时启停，即付即用。</p><p></p><p></p><h2>数据平台关键词：数据 BP、0987、分布式治理</h2><p></p><p></p><p>度过了前两个阶段之后，我们再来看看，到了平台阶段，我们又有什么样的困难和解法？</p><p></p><p>前面已经提到过，字节拥有非常多元迥异的业务线形态，它们带来了很异构的数据和不同的场景。作为数据平台，之前的经验还有没有用？要如何复用起来？这么多不同的业务，怎么更敏捷、更深入得支持好？数据质量要怎么保障？成本可以如何进一步优化？这个时候，我们面临的挑战，不能只是单纯依靠技术层面的优化创新来解决了。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/64/644c0fb9deda40c69be46a6e4dc0aeb3.png\" /></p><p></p><p>首先，为了解决更敏捷深入支持和驱动业务发展的问题，我们从 HRBP 里获取了灵感，建立了数据 BP，探索了“中台能力 + 数据 BP”的模式。</p><p></p><p>如何理解呢？我们可以用一个生活中的场景来类比——中央厨房和餐厅。中央厨房通过采摘或者购入食材，进行一系列复杂而标准化的加工，最终为各餐厅提供标准化的成品或者半成品的食物。而餐厅则可以根据自己的用户需要，通过煎炸烹煮各种方式将这些食物组合加工形成一道道的菜，直接供客户食用。这个中央厨房就相当于我们的中台，而这些餐厅则是我们的数据 BP，依据不同业务特点，将“中央厨房”提供的各种能力有机地形成对应的数据解决方案。</p><p></p><p>这样做有什么好处呢？具体有三点：</p><p></p><p>BP 作为数据平台与业务的桥梁，对业务直接输出平台已沉淀的能力，把业务场景方向输出回中台建设，实现能力的动态互哺。多元业务线的支撑可沉淀出不同业务类型，对不同业务阶段的方法论和经验进行更强大敏捷的泛化复用。以明确的目标为导向，可量化可扩展的服务标准。</p><p></p><p>举个例子，Pico 是 21 年下半年刚并入字节的一个 VR 业务产品，在并入后不久我们就开始着手对这条业务线的支持。对我们来说，这是一个全新的业务形态，该怎么做呢？</p><p></p><p>总的来说，分为几步走：首先，数据 BP 团队先去了解业务形态，梳理出目前的数据状况以及痛点诉求。整理技术方案，将基础数据快速接入，同时进行历史数据迁移；基础数据接入之后，业务就能直接在字节数据平台的体系中使用各种数据建设和数据分析应用产品。</p><p></p><p>有了 BP 机制和之前沉淀的中台能力，我们在 3 周内就完成了数据接入工作。数据中台的这些产品体系，从 Pico 业务方的感知来说，就是「即插即用」，可以直接在字节数据中台产品上做数据开发、数据管理、行为分析以及搭建业务数据报表等。</p><p></p><p>在这之前，Pico 有专职同学进行报表开发，3 周之后，这个工作已经完全可以通过产品实现，也把对应同学从繁重的报表开发中解放出来。整体看，这个效率还是非常高的。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/1f/1f5ae3a65d6bcf49b5f372be94918026.png\" /></p><p></p><p>除了敏捷之外，数据 BP 也提出了非常严苛的一套服务衡量标准。相信很多做数据的同行都认可数据价值很大，但数据研发的工作价值和能力水平要怎么体现出来？这是困扰大家的一个问题。对于字节来说，我们还是一家数据驱动的公司，也是最大程度上追求量化客观。</p><p></p><p>所以，我们还是总结了一套服务评估体系，我们称之为“0987”：</p><p></p><p>0 代表稳定性，即产生数据是否稳定。通常，SLA 破线的故障数要清零。9 代表需求满足程度。我们要满足 90% 的业务数据需求。8 代表数仓构建情况，即数仓完善度。我们要看是否可以满足分析师查询覆盖率达到 80%，就是分析师查询日常数据都可以找到数据。（需求满足程度和数仓完善度都不追求 100%，因为灵活发展的业务中总有特别长尾、临时的一次性分析查询需求。）7 代表用户满意度。通过 NPS 看服务是否满意，我们的目标是 70%，对于 NPS 熟悉的同学知道这在业内是比较高的指标。</p><p></p><p>整体看，这四个指标的标准都足够高，也刻画了不同的侧面。如果达到，我们就认为对业务提供了高水准的数据服务。</p><p></p><p>刚刚说，业务多元发展后，我们是通过数据 BP+ 中台能力的模式，来更敏捷、更深入地支持业务。但是所有做数据的人都会遇到的一个问题：数据治理。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/20/20fac78078742035d64ff769235f0493.png\" /></p><p></p><p>关于数据治理，业内有很多定义，在不同业务阶段的实施优先级也与路径不同。从我们的实践经验出发，有这么几个要点：坚持业务第一、优先稳定性建设、保障数据质量、强调数据安全、重视成本优化。</p><p></p><p>我们的数据治理过程，也经历了从运动式到分布式的迭代。</p><p></p><p>运动式，相信大家都能理解，就是以项目的形式成立治理委员会，自顶向下的形式来解决数据治理问题。这个模式在前期非常有效，能够很好地打造标杆案例，总结出实践经验，但成本比较高。</p><p></p><p>字节有大量的业务，委员会很难集中统一治理每个业务，同时每个业务的发展不一样，也需要具备一定灵活性。因此，我们提出了“分布式自治”的概念，也就是说，各个业务可以按照自己的情况进行治理，通过循环迭代，随着业务增长把数据治理提升到一个高水位，而不是上来之后强制按统一模式去做。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5c/5ce538ffaf2f18f4f1353245938b5572.png\" /></p><p></p><p>那么，分布式治理的核心是什么呢？</p><p></p><p>首先，一定有组织问题。组织需要构建一个更高效的治理模式，这体现在治理委员上，不应该是中心制的什么都管理，而是要核心解决各种规格和规范问题、多团队协作且无法达成共识时做决策。当大家有问题的时候，这个治理委员会就会发挥作用。我们也希望业务能发挥主观能动性，将治理工作日常化。</p><p></p><p>其次，就像刚才讲的，治理首先要坚持业务第一，明确是为什么而治理。治理一定要为业务服务、对业务造成最小的打扰，而不是治理同学不考虑业务情况，强制让业务按自己的要求来治理，造成业务的过度抵触。减小对业务节奏打扰的核心在于，让业务自己去发现问题，并且愿意去做治理的事情。我们可以通过产品能力，给业务更全景的视图 &amp; 线索来做到这一点。</p><p></p><p>此外，在产品设计上，治理能力要分拆出来。不同阶段的业务，可以根据实际情况自由选择最核心需要治理的部分，并去解决问题。</p><p></p><p>最后，通过产品工具提供最高效的执行效率。如何提供最高效的执行效率呢？治理里面有两个关键点：专家经验、系统智能。系统智能比较好理解，比如元数据自动分析，专家经验是指各个团队沉淀下来的治理相关经验。成熟团队可以沉淀很多专家经验到产品上，还不成熟的团队就可以借鉴参考，进而构建自己的方案。</p><p></p><p>通过这些方式，可以把治理问题从高度依赖中心化组织决策，变成一个全集团各个业务能够分头治理的事情。从而，我们也跟业务达成一个比较好的协作关系。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/68/684543d2e13ff603da3fac330e3cc03e.png\" /></p><p></p><p>以稳定性 SLA 为例，看看我们是如何解决最核心的链路稳定问题的。</p><p></p><p>举个例子，我们有一个治理产品提供的是 SLA 治理能力，也就是提供“稳定性保障”，比如说任务是否每天 6 点产出了，如果没有就是一个故障。</p><p></p><p>这个问题的核心是解决全链路稳定性问题。对于特别小的公司来说，这个事情很好解决，大家拉个群说下就可以了。但对于体量大、业务复杂的公司来说，这就没有那么容易了。字节拉过最长的链路，一个要 6 点产出的任务，上游涉及到几十个团队，你拉几十个人的群去协商的过程是极其费力的，而且协商之后也不一定能完全确保稳定。所以，我们通过产品构建整个全链路 SLA 保障，对整个闭环进行控制，核心有以下两点：</p><p></p><p>业务可以按需在系统里面进行申报。当业务表示我这个东西很重要，那就先申报，系统会协助完成申报后的对齐工作。例如，申报 6 点，链路上所有人都要对齐。产品可以帮助「找到人」「找对人」「提供建议」「提供催办 / 预警 / 监督」。更具体地，如果以前历史记录证明你完全可以做到这个事情，就会自动签署。通过一系列类似机制，之前可能需要几天、几周，甚至更长的对齐过程，变成一天之内可以解决的过程。全部签署之后，剩下的问题全部交给系统。系统会自动调整优先级、做资源倾斜，确保签署任务可以及时完。出现故障后也可以很方便地 review 相关的全链路流程。这样一段时间的不断迭代，我们就可以实现整个业务需要的 SLA 的保障。</p><p></p><p>实践过程中，我们仅仅用了一年的时间就完成了字节内所有业务的 SLA 全链路保障，这比调研过的其他企业要快上一些。</p><p></p><p>前面这些，基本上涵盖了我们从最初比较贫瘠、被各种问题追着跑，到逐步解决问题，并发展成现在数据平台的阶段。</p><p></p><p>换个角度看，如果把字节的各个业务线看成一个个公司，我们实际已经对很多不同类型的公司提供过高水准的数据解决方案和服务。所以我们也开始考虑，这些能力是否可以面向更多外部企业提供。</p><p></p><p>在通过火山引擎对外部企业提供服务时，我们会遇到很多此前没有遇到的问题。我列了一些比较尖锐而直接挑战，比如：</p><p></p><p>我没有那么大体量的数据，你们 ByteHouse 再快再稳，我用不上这么高规格的产品技术。你们产品听起来很强大，但你们人才密度要比我们公司大，万一产品我们不会用怎么办？我们的业务就是很单一，我为什么需要中台？产品有点贵，算一算我不如直接招几个程序员来管理更方便字节的这些经验，我们要怎么用？</p><p></p><p>事实上，这些问题都有一定的道理，但也有一定的片面性和局限性。</p><p></p><p>比如没有大体量数据的问题，我们相信，如果业务要持续发展且需要促进业务不断增长，那么企业对数据的要求只会越来越高，数据量也会越来越大，正如我们所经历过的一样。其次，数据量只是其中一个维度，字节近年来孵化的很多新业务一开始的量也不大，但都在初期就享受到了这些高水准的数据产品和服务能力，对业务发展有很大的助力。由于支持过不同体量的业务，我们也有能力提供非常高的适配性，例如 ByteHouse 的弹性伸缩能让大家在选择时更灵活，兼顾不同的数据体量。</p><p></p><p>那针对我们如何更适配企业自身，我们也在做一些努力：</p><p></p><p>统一化——我们坚持内外部统一用同一套产品技术体系。简单来说，抖音能用到什么样的数据产品技术，外部的企业就可以用到相同的技术。平民化——即数据平民化、降低使用门槛，让更多人不需要太高的能力和条件也能自助使用这套产品技术。场景化——也就是更契合业务实际场景，提供更具有价值的解决方案。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/04/04f827080bb7fb18774ffc66fdaa0b5d.png\" /></p><p></p><p>举个例子，一开始提到的 A/B 测试，我们在对外的时候发现，很多企业并没有像字节这么多的专业分析同学来设计实验、分析实验结果。所以我们在对外的产品设计中，就会把这部分做得更易上手。同时，我们也会提供场景化模板，比如广告营销的一些场景，包括素材投放对比、DMP 投放等等。</p><p></p><p>再比如，可视化实验支持直接在页面上修改站点的元素，比如文案、图片、元素的颜色比、字体字号、布局位置，甚至我想新增或者是删除一个元素，不需要跟设计和研发反复沟通确认排期，非常适合 Web 或者是 H5 这样的推广活动页做 UI 的调整。还可以做个性化推送实验，与部分推送平台打通后，针对推送时机、推送通道、标题、内容文案、提醒方式都可以做实验。</p><p></p><p>通过提供这样的场景化模板，很多实验都能在不需要研发介入的情况下快速开启和分析。这对用户非常友好，没有太强专业背景的人也可以做很多数据驱动的实验和判断。</p><p></p><p>以上就是字节数据平台过去九年的一些实践经验和演进思路。</p><p></p><p></p><h2>数据平台未来会更开放、更智能</h2><p></p><p></p><p>未来，我们除了继续秉持业务发展驱动演进之外，也会有两个投入方向：一是开放，二是智能。</p><p></p><p>过去，我们基本上是按照使用“开源→基于开源二次开发→自研”这个路径发展，最开始追求解决业务问题，开源提供了很多不错的基础方案。</p><p></p><p>在使用过程中，随着业务复杂度的增加，我们在可扩展性，易用性，垂直定制优化等方向遇到瓶颈，所以就会有基于开源做二次开发，并将一些具体的改动反馈给开源社区。</p><p></p><p>如果有一些系统，开源社区也没有好的选择，我们就会做自研。我们的技术构建受益于开源，所以目前也已经考虑把一些比较成熟的自研系统开源出来，回馈更广泛的开发者和社区。数据平台内部在积极的推进中，大家可以期待一下。</p><p></p><p></p><p></p><p></p>",
    "publish_time": "2022-08-18 18:25:24",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]