[
  {
    "title": "银行核心业务系统数据库主机下移架构与实践 | DBTalk 技术公开课第2期",
    "url": "https://www.infoq.cn/article/BHMyzwGhzlE6aiK4lxCb",
    "summary": "<p>**信创背景下，银行核心业务系统数据库主机下移如何做？基于业务场景，需要重点关注数据库的哪些关键点和特性？数据库高可用架构如何设计，是否需要分库分表？满足业务场景需求的同时如何保证系统高可用和高效运行？</p>\n<p>本次分享，将逐一给出答案并分享实践案例。**</p>",
    "publish_time": "2022-08-18 00:25:47",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何从 0 到 1 实现智能化运维？| DBTalk 技术公开课第2期",
    "url": "https://www.infoq.cn/article/8gqi6lKfYEPQvoqdS0xS",
    "summary": "<p>**随着数字化、互联网的快速发展，金融行业正在加快推进全面改革转型。业务创新与技术架构演进的同时，对底层基础软件平台的支撑能力也提出了更高的要求。而数据库运维逐步向标准化、自动化、集中化、智能化演进则成为行业未来发展的必然趋势。</p>\n<p>本次议题，将聚焦金融行业，分享数据库运维能力演进及落地经验。**</p>",
    "publish_time": "2022-08-18 00:27:09",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "用AI打败AI：向Deepfakes“宣战”",
    "url": "https://www.infoq.cn/article/Rg7oFVSj0LoF9AUblWiV",
    "summary": "<p></p><p></p><blockquote>如今，由计算机生成的逼真人脸已经随处可见。我们到底该如何分辨个中真伪？</blockquote><p></p><p></p><p>大概十年之前，当时在蒙特利尔大学攻读博士学位的Ian Goodfellow和朋友们在一家酒吧小酌时，突然萌生了一个“永远改变整个机器学习与信息伪造领域”的念头。</p><p></p><p>Goodfellow之前在播客上打趣道，“我不是说非要喝酒才能萌生出科研灵感。但当时情况确实是这么个情况，我觉得少喝两杯能帮自己打开思路。”总之，他回家后马上开始着手尝试。</p><p></p><p>Goodfellow隐隐觉得，如果让两个计算机系统相互对抗（即生成对抗网络，简称GAN），应该可以产生比当时的深度学习技术更真实的输出结果。那时候的深度学习算法只能产出模糊的人物图像，而且严重缺乏面部特征。他的早期模型只能生成类似于手写数字、有那么点意思的虚构人脸，以及类似于像素化风格的莫奈式动物图像。但随着技术的发展，用更少的图像创造出高度逼真的伪造画面已经成为可能。</p><p></p><p>GAN中使用两种相互竞争的算法，会在同样的数据集上自我训练。其中的生成器会根据原始数据集创建新图像；而另一边的鉴别器则负责识别出伪造图像。最初双方都很弱，生成能力与鉴别能力堪称“菜鸡互啄”。</p><p></p><p>但随着时间推移，算法在零和博弈中相互对抗——如果生成器骗过了鉴别器，则生成器得一分；如果鉴别器检测出了伪造内容，则鉴别器得一分。如此反复，生成的图像变得越来越真实可信。</p><p></p><p>感兴趣的朋友可以访问This-person-does-not-exist.com网站，亲自感受一下由GAN快速生成的大量虚构人物头像。如果说机器学习的目标在于赋予计算机模仿人类智能行为的能力，那么Goodfellow就相当于给计算机插上了想象力的翅膀。</p><p></p><p>虽然GAN开创了机器学习的新时代，在医学影像、面部衰老预测和视觉艺术创造等方面获得了广泛应用，但同时也成为恶意黑客和网络谣言传播者手中的利器。有了这项技术，他们可以随意伪造证据、展示攻击对象种种并不存在的不当行为。例如在政界令人头痛不已的“假新闻”难题，如今deepfakes搞出来的照片和视频正引发轩然大波，亟需一种可靠的伪造鉴别方法。这可绝不是危言耸听，今年就出现过一段deepfakes视频，其中乌克兰总统泽连斯基要求他的部队放下武器、向俄军投降。</p><p></p><p>其他案例也所在多有。</p><p></p><p>2021年，挪威摄影师Jonas Bendiksen就在法国Visa pour l'image&nbsp;新闻摄影节上公布了自己的《Book of Veles》作品集。照片描绘的是2016年美国总统大选期间，他在北马其顿小镇的生活点滴。唯一的异样，就是所有图像均系伪造，一切人和动物全部由计算机生成。问题是根本没人能发现……如果连那些把一生献给摄影艺术的专家都识别不了Bendiksen的花招，那我们普通人就更加难以分辨了。</p><p></p><p>随着AI工具变得越来越复杂，以deepfakes为代表的伪造媒体信息已经愈发难以检测。根据世界经济论坛2021年发布的报告，deepfakes视频数量每年增加约九倍，而且像Bendiksen这样的外行人只要看看YouTube上的制作教程就能学会。</p><p></p><p>为了化解这场虚假信息引发的危机，研究人员只能积极寻求新的鉴别方法。</p><p></p><p>为此，Facebook（现更名为Meta）决定在2019到2020年间的三个月中举办一场Deepfake检测挑战赛，要求参赛者想办法自动识别某张照片是否为AI伪造。挑战赛共吸引到2114名参赛者，开发出最强识别算法的选手拿到了100万美元奖金。但尽管云集了AI领域最睿智的头脑，比赛中的优胜程序也只能实现65%的deepfakes识别成功率。</p><p></p><p>目前，大部分基于AI的检测程序会将注意力集中在“视觉伪影”上，也就是通过光照冲突、错误的阴影位置和几何图形矛盾等线索确定伪造图像。但随着AI技术的不断发展，deepfakes程序能够快速学会抹除矛盾。</p><p></p><p>2018年奥尔巴尼大学的一项研究曾经发现，deepfakes视频中的眨眼频率往往明显高于或低于真人。但短短一年之后，韩国研究人员就发现deepfakes正发展出更逼真的眨眼模式。眼镜和牙齿部分也获得了类似的升级，快速消除了这两部分在此前AI生成照片中不够自然的问题。事实上，专家们披露出的这些错误，其实在不经意间已经给deepfakes创作者指明了生成更强伪造图像的方向。</p><p></p><p>Deepfakes目前还无法生成完美无瑕的全合成人类图像，所以检测工具暂时有效。但Adobe内容真实性计划高级主管Andy Parsons表示，这种有效性不知道还能维持多长时间。“如果时间再推进五年或者十年，结果又会如何？我觉得伪造一方很可能会最终胜出。再不找到更好的识别方法，防线就要崩溃了。”</p><p></p><p>虽然deepfakes已经成为日益严峻的现实威胁，但负责编撰《媒体操纵案例手册》的Jane Lytvynenko表示更令人担心的其实是“廉价伪造”，即不涉及AI的伪造照片和视频。</p><p></p><p>在加入哈佛大学肯尼迪学院新闻政治中心的技术与社会变革项目之前，Lytvynenko就已经凭借在BuzzFeed News上报道错误及虚假信息而声名鹊起。</p><p></p><p>根据Lytvynenko的介绍，单纯通过剪切、粘贴、放慢音频和视频拼接，这种廉价伪造已经足以用成本极低的方式欺骗大众、操纵媒体。YouTube上有个专门宣扬右翼党派阴谋论的频道，在其中一段题为《她喝醉了吗？》的视频中，南希·佩洛西（Nancy Pelosi）在新闻发布会上口齿不清、似乎难以站稳。但这段视频其实是通过慢放来误导观众，给人一种佩洛西无法正常讲话的印象。</p><p></p><p>虽然这段视频后来被鉴定为假，却已经造成了相当广泛的传播效应。Lytvynenko表示，“其实用不着deepfakes，人们往往会被更简单的策略所误导，所以恶意传播者暂时还没必要采取那些更复杂的技术方法。”</p><p></p><p>面对充斥着错误信息的世界，名为内容来源的新型解决方案有望开辟出一条信息保障之道。该项目的灵感源自艺术创作界，希望建立一条来源链，记录图像在整个数字生命周期中发生的一切——包括由谁拍摄、何时拍摄、是否经过编辑等。软件不是回溯性检查图像的篡改痕迹，而是从图像创建之时起就始终保证内容的真实性。这些数据会被打包起来，在图像上线发布后显示在旁边的信息框内。</p><p></p><p>Adobe在2019年公布的《内容真实性倡议》中就已经开始推动此类验证。这项倡议目前已登陆Creative Cloud应用程序，希望为Twitter、《纽约时报》等重量级媒体提供照片内容与变更线索方面的跟踪能力，让受众以更透明的方式判断信息是否可信。</p><p></p><p>作为一款可选工具，内容真实性倡议没办法勘破deepfakes的花招，只是为社交媒体用户提供了一种查看未受操纵媒体可信度的方法。自项目公布以来，Adobe已经与多家数字平台和媒体组织建立合作伙伴关系，着手在他们的库存图像上添加内容真实性保障。</p><p></p><p>根据Parsons的介绍，deepfakes检测与内容来源是一对互补的验证工具——前者为被动检验，后者则是主动追踪。这不止能带来更高的线上内容透明度，同时也鼓励观众对自己看到的东西做出批判性思考。</p><p></p><p>Parsons解释道，“归根结底，照片和数学原理固然可信，但用户对媒体的信任其实是对组织、对人的信任。现在，我们对这些组织的信任比以往任何时候都更重要。我们既是内容消费者，也是事实核查者，应当查看内容来源并判断其是否受到了操纵或篡改。”</p><p></p><p>暂时来看，抗击deepfakes的任务需要由消费者和创作者共同承担，但未必会永远如此。短短八年，蒙特利尔一家酒吧里突如其来的念头就发展出了如此庞大的信息伪造产业，也许我们也能很快找到同样强大的检测方法、遏制住这股操纵媒体导向的歪风邪气。</p><p></p><p>原文链接：</p><p></p><p><a href=\"https://thewalrus.ca/fighting-ai-with-ai-the-battle-against-deepfakes/\">https://thewalrus.ca/fighting-ai-with-ai-the-battle-against-deepfakes/</a>\"</p><p></p>",
    "publish_time": "2022-08-18 13:35:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "OpenBMB x 清华NLP，如何玩转大模型？｜InfoQ《极客有约》",
    "url": "https://www.infoq.cn/article/2obhUaf98SE2j2uuyi8I",
    "summary": "<p>最近两年，超大规模预训练模型迎来了大爆发，国内外巨头和学术机构纷纷开启 AI 大模型研究热潮。然而大模型所需要的高性能计算能力与海量数据，让很多中小企业望而却步。如何推动大模型的落地和普及，让大模型真正飞入千家万户，是一个重要的课题。 InfoQ 和 OpenI 启智社区联合发起的《极客有约》第二季第一期直播，我们邀请到了清华大学计算机系的博士后韩旭，来给我们分享如何玩转大模型。</p>",
    "publish_time": "2022-08-18 13:51:56",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]