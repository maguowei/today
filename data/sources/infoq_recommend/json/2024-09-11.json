[
  {
    "title": "AI 超算新时代：GMI Cloud 携手新加坡电信 打造亚太 AI 算力高速网络",
    "url": "https://www.infoq.cn/article/kiE2wEfrXVZxkLS4kXeb",
    "summary": "<p>2024 年 9 月 10 日，台湾首家荣获 NVIDIA 认证云服务合作伙伴（NCP）资格的 AI 原生 GPU 云服务平台 GMI Cloud 重磅宣布——“与亚洲领先的通讯科技集团新加坡电信 (Singtel) 达成策略合作。”该策略联盟强强联手，将结合双方的 GPU 资源和云计算部署能力，倾心打造灵活可扩展的高效能运算平台，大幅提升企业在获取运算资源时的效率与便捷程度。</p><p>&nbsp;</p><p>双方合作协议明确指出，Singtel 的客户将能够畅享 GMI Cloud 强大的 GPU 高效算力，在新开拓的市场中轻松处理密集型工作负载。这一举措将不仅极大地拓展了 Singtel 的服务覆盖范围，还为 GMI Cloud &nbsp;开辟了全新的市场机会。与此同时，GMI Cloud 将与 Singtel 的 Paragon 编排平台深度整合，全面发挥 Singtel 在新加坡的 NVIDIA H100 Tensor Core GPU 算力资源优势，为企业提供先进的 AI 模型训练与推理能力，助力企业从容应对大规模计算任务及 AI 应用挑战。</p><p>&nbsp;</p><p>就此，GMI Cloud 首席执行官 Alex Yeh 表示：“此次与 Singtel 的合作，是亚太地区 AI 基础设施发展的一项重要突破。GMI Cloud 在提供可扩展性和电信优化的 GPU 算力解决方案方面具备深厚专业，与 Singtel 领先的网络能力相得益彰。我们的灵活部署方式和处理高容量、低延迟工作负载的产业经验，将为电信行业的 AI 计划带来显著的性能提升和成本优化。这一合作将构建一个加速 AI 采用的生态系统，让电信提供商和企业能提升运算效率、优化服务，并推动区域性的技术创新。”</p><p>&nbsp;</p><p>同时，Singtel 数字基础设施公司和 Nxera 首席执行官 Bill Chang 也表示：“我们致力于构建下一代数字基础设施和合作伙伴生态，以满足各行业对可扩展、高效且具成本效益的解决方案日益增长的需求，尤其针对计算密集型工作负载。与 GMI Cloud 的合作扩展了我们在亚太地区的 GPUaaS 覆盖范围，增强了我们在该区域的算力部署能力。这将为企业提供所需的灵活性和扩展性，使其充分利用运算的强大能力，推动创新并加速发展。”</p><p>&nbsp;</p><p>此次合作进一步彰显了GMI Cloud 在 AI 基础设施市场中的领导地位。作为 NVIDIA 认证的云服务合作伙伴（NCP），GMI Cloud 不仅在技术研发方面具有显著优势，同时在供应链整合方面也有着卓越能力。目前，该公司已储备充足了的最新的 H200 GPU，全力确保可持续性地为客户提供高效能、低延迟的算力支持，以满足企业多样化的密集型工作负载需求。</p><p>&nbsp;</p><p>随着GMI Cloud 与Singtel此次合作的稳步推进，亚太地区的企业将能够加速 AI 应用的落地。借助 GMI Cloud 的先进技术和 Singtel 的广泛网络，企业将获得灵活且强大的 AI 算力，驱动自身业务创新与发展，全面提升区域竞争力。</p><p>&nbsp;</p><p></p><p></p><h5>关于GMI Cloud</h5><p></p><p></p><p>GMI Cloud 是一家领先的 AI 原生 GPU 云服务提供商，拥有遍布全球的数据中心网络，为 AI 和机器学习工作负载提供最新、最优化的 GPU 资源。公司由来自 GoogleX 的 AI 开发专家和硅谷精英人才创立，致力于为新创公司、研究机构以及大型企业提供安全、高效且具成本效益的 AI 基础架构解决方案。GMI Cloud 的技术能让客户更快速、更经济地进行 AI 创新，同时确保高度的数据安全和运算效能。作为推动通用人工智能（AGI）未来发展的重要力量，GMI Cloud 持续在 AI 基础设施领域引领创新。欲了解更多信息，请访问 <a href=\"https://www.gmicloud.ai/\">www.gmicloud.ai</a>\"</p><p>&nbsp;</p><p></p><h5>关于Singtel</h5><p></p><p></p><p>Singtel 是亚洲领先的通讯科技集团，经营下一代连接、数字基础设施和数字业务，包括区域数据中心分支 Nxera 和区域 IT 服务分支 NCS。该集团业务遍及亚洲、澳大利亚和非洲，为 21 个国家的超过 7.8 亿移动客户提供服务。对于消费者，Singtel 提供完整而整合的服务套餐，包括移动、宽带和电视服务。对于企业，Singtel 提供互补的劳动力流动性解决方案、数据托管、云计算、网络基础设施、分析和网络安全能力。Singtel 致力于持续创新，利用科技创造新颖令人兴奋的客户体验，支持企业数字转型，塑造更可持续的数字未来。欲了解更多信息，请访问<a href=\"https://www.singtel.com/\">www.singtel.com</a>\"</p>",
    "publish_time": "2024-09-11 11:39:06",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Gödel Scheduler 性能优化: 算法设计思想与数据结构应用",
    "url": "https://www.infoq.cn/article/FAGgYDQPmsB0Dmcth5GU",
    "summary": "<p>基于优异的调度性能，Gödel Scheduler 拥有在超大集群规模 (20k+ Nodes, 1000k+ Pods)、超高业务负载 (1k+ Incoming Pods/s)、超多复杂场景 (ML/批流/潮汐混部等) 下长期稳定运行的能力。</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=Mzk0NDMzNjkxNw==&amp;mid=2247486750&amp;idx=1&amp;sn=742cc8dfa0c2b92182d1c45dd7284008&amp;chksm=c3277464f450fd72d328053ee223164a384ffd31e5f6bdffac53cba06da8e27a1a6c2aa0ad03&amp;scene=21#wechat_redirect\">Gödel Scheduler</a>\"&nbsp;是字节跳动开源的在离线统一调度器，旨在使用同一套调度器来统一调度和管理在离线业务，实现资源并池，从而在提升资源利用率和资源弹性的同时，优化业务成本和体验，降低运维压力。</p><p></p><p>当前，Gödel Scheduler 的单分片调度吞吐可达 2500+ Pods/s (10x Kube Scheduler)，多分片调度吞吐可达 5000+ Pods/s，这离不开大量创造性的构思。</p><p></p><p>本文将以几个经典优化为例，阐述基于这些构思所衍生的算法设计思想与数据结构应用，说明其对提升 Gödel Scheduler 调度性能并最终解决实际问题所发挥的巨大作用。</p><p></p><p></p><h2>设计一：增量更新</h2><p></p><p></p><h3>前置介绍</h3><p></p><p></p><p>与 Kube Scheduler 相似，Gödel Scheduler 同样维护了 In Memory 的 Cache 与 Snapshot。</p><p></p><p>Cache:</p><p>维护各类 Resource Object 的组织关系，有助于快速获得汇聚信息 (如节点已被使用的资源总量)，提高调度算法的执行效率会伴随着 Event 触发实时变动，且数据维护需要对整个 Cache 加锁</p><p></p><p>Snapshot:</p><p>规避当前调度轮次期间 Event 带来的影响，保证调度过程中的数据一致性单个调度轮次期间数据只读，不需要加锁</p><p></p><p>每次调度流程的起始都需要将 Cache 的最新数据同步 Clone 到 Snapshot 中供串行的调度流程取用，因此数据同步的效率就格外关键。</p><p></p><p></p><h3>问题产生与解决</h3><p></p><p></p><p>相比于 Kube Scheduler，Gödel Scheduler 拥有更复杂的调度功能、需要承载更大规模的集群与应用，并由此带来了更多种类的缓存信息与更大量级的数据同步规模。此前，伴随着业务上量与集群规模自然增长，大量生产集群都频繁出现了各类缓存信息全量克隆所产生的性能问题，并严重拖垮了调度吞吐与调度时延。</p><p></p><p>❓ 思考：在前后两次调度的时间间隔中，并非 Cache 中所有的数据单元都发生了改动；实际上，我们只需要识别出发生了变动的部分，并将这部分以 “增量” 的形式覆盖到前一轮调度的 Snapshot 即可满足数据同步需求。</p><p></p><p>具体来说：</p><p></p><p>1. 假定前一轮调度时，Snapshot 已经完整的拷贝了 Cache 中的 Node 0, Node 1, ..., Node 5；当前调度轮次发起时，Cache 中的 Node 1 &amp; Node 3 发生了更新、Node 5 被删除、Node 6 被新增。Snapshot 应当如何感知？</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3b/3b922968428506e7ad3d690c98ccab42.png\" /></p><p></p><p>很显然，在不做特殊维护的情况下，除非遍历比对所有对象，否则 Snapshot 很难得知 Cache 基于某个时刻起发生了哪些变动。</p><p></p><p>2. 如果我们手动赋予每个对象特定时序，并按时序（如时序降序）维护对象列表，则一段连续时间内的 Cache 变动都能够被映射到一段连续时序内。以前一轮次调度所对应的全局时序值作为基准，当前大于该全局时序值的所有对象对于该基准来说都是 “增量”。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a5/a55de1781a2fe6365a093cf5f4116bd7.png\" /></p><p></p><p>按照时间发生顺序组织所有对象，并将前一轮次的全局时序值 (x+5) 记录在 Snapshot 中，则后续产生变动的对象的时序值都将大于该基准值，由此感知 “增量” 并做局部更新。</p><p></p><p>3. 将前述数据维护过程做进一步抽象：本质上 Cache 与 Snapshot 中需要向上层暴露的都是一个能够提供 Get &amp; Set 接口的存储 (GenerationStore)；区别在于，Cache ListStore 的存储内部需要能够维护时序，而 Snapshot RawStore 只关心存储对象本身。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/91/911b05855cdee61695c4de3698decb38.png\" /></p><p></p><p></p><p>通过逻辑抽象并将各类数据全面接入增量更新，大幅降低了缓存信息的数据同步损耗，显著提升了调度吞吐并优化调度时延。</p><p></p><p>如下图所示，整体 e2e 调度时延由分钟级下降至毫秒级并保持长期稳定，有 4 个数量级的优化。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d1/d1ed19649f30bbfde558bf917d206bd6.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/55/559d4f92af2727761924caf94fd8f3cc.jpeg\" /></p><p></p><p></p><h2>设计二：离散化节点列表</h2><p></p><p></p><h3>前置介绍</h3><p></p><p></p><p>出于调度效率的考量，单个 Pod 调度时不会遍历集群中的所有可行节点，而是只遍历特定数量或特定比例后立即停止，因而每一个 Pod 的调度都存在一定的空间局部性。</p><p></p><p>在这样的前提下，原始逻辑中为了尽力实现调度时的天然离散，Scheduler Cache 会按拓扑域维护一颗 Node Tree (二维数组)。Update Snapshot 时，会将 NodeTree 压缩为一维列表并存储于 Snapshot 中，并在每次调度时以取模轮转的形式取用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9f/9fea0e0183e1d4c5435ab3705c95564f.png\" /></p><p></p><p></p><h3>问题产生与解决</h3><p></p><p></p><p>容易看到，前述 NodeList 的生成过程存在明显的问题：通过压平 Node Tree 构建的 NodeList 在拓扑域层面并不真正离散，其只能保证每个 Zone 在靠前的部分均匀分布，而靠后的部分则会被某个数量较多的 Zone 节点完全占据，导致部分 Pod 错误地产生拓扑域倾向性。</p><p></p><p>更严重的问题在于：NodeList 会由于任意 Node 的 Add / Delete 等场景频繁触发整个列表的完全重建，而其重建过程涉及对整个节点存储的遍历和相应的内存分配与回收。在 20k+ Nodes、Incoming Workload 接近 1k Pods/s 的超大规模集群中，频繁重建 NodeList 的计算开销达到了整体进程开销的 50+%，严重影响调度效率。</p><p></p><p>❓ 思考：</p><p>1. 怎样实现真正的拓扑域离散？</p><p>等价于任何节点在 NodeList 的下标位置完全随机</p><p>2. 如何避免频繁重建的开销，低成本地维护 NodeList？</p><p>理想情况下，单个元素的增删应当能够在 O(1) 的时间复杂度内完成增加：直接追加到线性列表末尾删除：将待删除元素与列表末尾元素交换，随后移除末尾元素（此时需要结合 HashMap 以实现元素下标索引，用以支持元素交换）更新：删除 + 增加</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/38/38593bf046a3afbe661143c57d863d37.png\" /></p><p>由于整个集群所有节点发生 Add/Delete/Update 的随机性，容易得知 NodeList 中任意下标元素所对应的节点是完全随机的；更进一步地，任意长度的一段连续区间内每个下标所对应的节点都是随机的，则该连续区间内任意拓扑域出现比例的数学期望均与其全局统计比例一致，进而能够保证拓扑域的离散。</p><p></p><p>通过重新设计 NodeList 维护机制，我们解决了多个超大规模生产集群出现的性能问题，并以更低的开销获得了更好的节点离散效果。</p><p></p><p>如下图所示，2022-10-11 下午升级后，整体 e2e 调度时延的主要热力分布由分钟级下降至毫秒级。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e7/e7f0e21627325189ea7074a1ca04cd2e.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/74/748cdfadb8cd79bffbfeb78570ff597b.png\" /></p><p></p><p></p><h2>设计三：启发式剪枝算法</h2><p></p><p></p><h3>前置介绍</h3><p></p><p></p><p>Gödel Scheduler 中，单个 Unit 的调度被划分为 Scheduling + Preempting 两大阶段。正常 Scheduling Filter 机制下 Pod 无法被摆放到特定节点的情况下，将会通过 Preempting 触发抢占行为，并尝试通过驱逐部分 Pods 来实现调度摆放的目的。</p><p></p><p>抢占过程需要通过大量计算逻辑以得出 \"抢占哪个节点\"\"驱逐哪些 Pods\" 的决策，因而一直是部分调度场景下的 CPU 热点。抢占的本质其实是一颗搜索树，其主体流程如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e1/e1ff3743429643b154ff3e89ed5a65a0.png\" /></p><p></p><p></p><h3>问题产生与解决</h3><p></p><p></p><p>大规模生产环境中，在线业务负载有着明显的潮汐特征。我们会将高优的在线业务与低优的离线任务在同个资源池混部，并伴随在线业务的扩缩去动态调整离线运行的规模，进而保证全天候的资源利用率。</p><p></p><p>在高优在线业务返场时，由于整体资源水位较高，将不得不对此前占据了集群资源的低优任务发起抢占，短时间内即产生极高的抢占频率，严重拖垮性能、影响在线返场效率。</p><p></p><p>❓ 思考：假定计算逻辑无法改变，如何减少参与计算的数据规模？</p><p></p><p>1. 如何减少参与计算逻辑的 Pod 的规模？</p><p></p><p>考虑到 Pod Priority 是抢占的基本原则，可以提前对节点上的存量 Pods 进行分类和排序。则对于当前要调度的 Pod 来说，它最多能够抢占的 Pods 是确定的，需要考虑的 Pods 的数量得以大幅降低。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/42/4288ad1b4bdc6c11dd11095da8f0f127.png\" /></p><p></p><p>2. 如何减少参与计算逻辑的 Node 的规模？</p><p></p><p>💡 一个设想：能否在不进入复杂计算逻辑之前，就能对 \"能否成功抢占\" 做一个粗略的估算？</p><p></p><p>乐观地假设当前 Pod 可以抢占优先级较低的所有 Pod（实际上部分 Pod 可能由于 PDB 保护等规则无法被抢占），则其可释放的资源总量是明确的。如果有办法获取这部分可释放资源量并将其与节点剩余资源相加，则可以得到当前 Pod 在抢占情况下最多可以利用的资源总量，若该总量仍然不满足 Pod Request 那么当前节点的抢占行为必然失败（启发式剪枝）。</p><p></p><p>💡 更进一步：如何快速获取节点上对于要调度的当前 Pod 的可释放资源量？</p><p></p><p>基于节点上的 Pods 已经按照 Priority 排序的前提，如果能为每个位置记录其资源维度的前缀和，则对于要调度的当前 Pod 的特定的 Priority，只要找到最后一个小于该 Priority 的位置，该位置的前缀和即为所求。</p><p></p><p>🥊 挑战：节点上的 Pods 会以极高的频率动态添加和删除，如何低成本的维护有序结构与资源前缀和？</p><p></p><p>我们可以将其拆解为两个子问题：</p><p>维护有序性：Balanced Binary Search Tree维护资源前缀和：将【前缀和问题】抽象为【区间和问题】，进而将【线性的区间和】转化为【结构化的子树求和】。借助 Splay-Tree，能够在维护有序性的同时维护子树性质（资源维度求和），并通过 Splay 伸展操作动态调整树结构、通过子树和来得到所需前缀和</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ac/ac95a6738ce14eda42b720cbee9d8acb.png\" /></p><p></p><p>3. 最终效果：在搜索树上实现了高效的剪枝。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/88/88396d0910e6a2a44f897a9920ff3b32.png\" /></p><p></p><p>基于 Pod &amp; Nodes 的多维剪枝策略，我们使得抢占吞吐能够快速回升、抢占时延大幅降低，并能在 2ms 内快速过滤无法抢占的情况。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7f/7ffa954742526670e474c20cccdf6d45.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/69/69fd009976106926bff8d5ef36178451.png\" /></p><p></p><p></p><h3>成果与未来规划</h3><p></p><p></p><p>基于前述多项设计与优化，Gödel Scheduler 在通用场景下的调度吞吐取得了极大的突破。目前，单分片的 Gödel Scheduler 已经能够游刃有余地应对字节跳动绝大多数业务场景，多分片也能提供更长期稳定的业务负载处理能力。</p><p></p><p>除此之外，Gödel Scheduler 对集群资源高水位等多个细分场景也做了大量创造性的设计优化并取得了显著收益，我们将在未来逐步迁移这些优化至开源版本中。</p><p></p><p>Gödel 调度器目前已开源，真诚欢迎社区开发者和企业加入社区，与我们一起参与项目共建，项目地址：github.com/kubewharf/godel-scheduler</p><p></p><p>文章专题推荐：<a href=\"https://www.infoq.cn/theme/225\">字节跳动云原生创新实践与开源之路</a>\"</p>",
    "publish_time": "2024-09-11 14:19:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何应对企业架构中的复杂度问题？",
    "url": "https://www.infoq.cn/article/MRDjtXsuaj25Hr9E5Sjw",
    "summary": "<p>企业架构经常被抱怨的问题就是复杂度问题——太复杂，做不来。这方面只能说见仁见智，没法有一个统一的、令人满意的解释。毕竟，抽象讨论共性问题只是动动脑、动动嘴，笔者自己也常在一些聊天群里做这样的事情，但这不过是练练“口才”罢了。如果真要聊复杂度控制，那么脱离实际语境去讨论就属于有点“臆想”了。很多聊天，聊着聊着就没意思了，也是这个原因，抛出一个概念图来就要开始“大杀四方”，谁真知道这张图的背后到底是啥呢？</p><p></p><p>架构的复杂度很令人头疼，归结起来常见原因可能有以下几种：业务复杂、方法复杂、周期叠加、阳奉阴违。</p><p></p><h2>一、业务复杂</h2><p></p><p>这是架构复杂度最基本的来源，架构从业务开始设计，业务复杂架构自然就复杂。比如，一个大型集团的业务架构，哪怕业务相对单一，业务自身的复杂性也不会太低，因为组织的庞杂本身就带动了业务的复杂，结构梳理起来就不会太容易，而且对流程的确认、调整都很难简单取得共识，天天都在处理的事情，也一样有说不清道不明之感。最怕的是，有些企业经常会觉得自己的业务是清楚的，但真到要较真做开发时，却怎么也定不下来。组织最奇特之处就是，可以很模糊地前进，但却给人以清晰的错觉，这可能也是流程管理一直不容易让人充分认知自己价值的一个原因吧。</p><p></p><p>小企业就会很简单吗？未必，笔者自己就是“一人企业”，但企业就是企业，无关乎是不是“一人”，签约、交付、开票、报税、发薪、宣传、设计、学习、交流等等，没有一样可以少的，只不过没必要给“一人”建立明确的流程而已。在此基础上，人数放大到一定程度之后，没有流程就是很低效的了。</p><p></p><p>但是，从流程建立开始，显式的复杂度管理也就开始了，如果企业没有类似“马斯克五步工作法”或者以前提倡的丰田精益管理之类的工作思路、管理追求的话，流程会新账压旧账，越来越乱，事情一样能办，就是低效之处很多。这时候不照镜子还勉强，一照镜子可能把自己吓一跳，吓到了之后反倒说架构复杂。</p><p></p><p>按照笔者自己的经验，人数 1000 人左右的企业，人手一个流程不是什么难事儿，也就是大约有 1000 个左右大小不一的流程或者叫活动，这一点从 APQC 的参考流程中也能侧面验证下，这里我们先不讨论颗粒度问题。以此为界，人数再多了之后，如果管理得当，流程数量增加未必就是正相关的；人数比这少，如果不能有意控制，流程数量下降也未必很明显，但是人数降到了哪个数量级，流程数量会出现明显的下降，笔者没有了解过，读者可以自己调查下。至少作为“一人企业”，笔者要干的事情也能凑够一个完整的价值链。</p><p></p><p>如果以此类推，非严谨论证的情况下，可能一个行业中，中等规模或者中等偏上的企业，流程复杂度已经足够高了，所以，中等规模的企业并非不需要架构能力。企业即便成长到更大规模，流程数量仍然可以有一定的控制，只是随着管理层级增加，会导致流程拉长。组织大到一定程度一般会“分裂”，也就是类似“分形”的方式产生小的“裂变体”，部门化、条线化的管理就类似这种。</p><p></p><p>如果流程控制得当，理想状态下是会有大量重复性流程出现，而不是真的增加了流程，这是“分裂”的复制结果，流程除了纵向拉长外，也会表现出横向拉长。管理得当的情况下，真实流程的增长数量应该是有限的，而很多集团企业的流程复杂实际上是标准化程度依然不高的表现。</p><p></p><p>标准化程度也左右了架构梳理结果的复杂度，很多企业觉得企业架构复杂，其实复杂的不是架构。做的过程让人觉得麻烦，正是为了消除标准化程度低导致的“杂乱”，但消除一次并非就结束了，为了保持不那么复杂，还要继续在流程优化上精进，这是热力学第二定律决定的，与架构无关。</p><p></p><p>所以从这个角度来讲，不要轻易谈降低架构复杂度这个问题。复杂度有个下限，再降低就只是在整体中转移复杂度的位置，而不是真的降低了。一个企业就是有 1000 个流程，如果流程数量优化不下去，还能怎么降低复杂度呢？如果在实现上就是想拼命降低，那业务人员还会觉得你做的系统是给他用的吗？</p><p></p><h2>二、方法复杂</h2><p></p><p>这个是方法论自己的毛病，但准确地说，是企业或者架构师、咨询师在落地实施过程中，对方法论适配的毛病。企业架构方法论不止一家，但家家不小，单看方法论，就没有很轻的，如果说介绍资料看着轻的话，那只是做法写得没有展开而已，如果真是完整做了全套架构，基本就没有太轻的方法。</p><p></p><p>单是流程梳理这一项就没听说过哪个企业做得轻松加愉快的，道理很简单，以前都是散步的走法，如今标准化了，忽然让人踢正步，那一步该多长、腿该抬多高，都得合计合计，顺便有些想甩的锅、想抢的碗也都搅合进来，所以，单就流程这一项来讲，谁都很难轻。要不要承受其重，那就需要企业自己掂量了，好处毕竟不是那么立竿见影，一个企业可能一两年功夫就能通过流程管理有所改善，但真到了所谓的提升整体竞争力，甚至堪称为人师表的境界，那估计得十年八年了。</p><p></p><p>流程梳理倒也可以有轻有重，轻重主要体现在对细节的关注上，比如，对最细的业务步骤、业务规则的梳理，都是可以控制的，因为不控制好的话，工作量会增加数倍。这个还是要取决于目的了，如果只想要整体视图，那就不关注细节，牺牲细节就是牺牲准确度，不要太高的准确度就行了；如果想要与开发深度连接，要的就是准确度，不太准确，不能指导细粒度结构划分、组间边界争端的流程，开发上是会看看而已，提供的指导意义不大，开发上还是以跟业务人员沟通得到的具体业务细节为准进行设计。</p><p></p><p>流程是架构梳理方法中耗时、耗人最高的一块，如果要轻，就要考虑这块是不是能越过，越过不是因为它不重要，而是企业承受不起，做不起全套的复杂操作，只能做基本能用的，这时就要考虑通过逻辑数据模型进行简化的架构梳理。降低方法复杂度并不是把所有东西都做浅就算降低，而是根据做架构的目标保证架构梳理出来的东西依然可用，如果只剩下轻飘飘一层，干啥都干不深，那还不如不做。</p><p></p><p>逻辑数据模型如果集中在实体级，耗时、耗人最少，而从架构视角看，企业架构方法要同时保证业务和技术两个视角都具备。技术视角主要是应用架构，要是把这个“轻”了，那开发上可能根本就不理解到底为啥要做企业架构；但如果没有业务视角，应用上以前搞不清的事情，即便搞了架构之后也还是不清楚，因为视角不完整。逻辑数据模型就是在无力完整梳理流程的情况下，作为独自承担业务视角这个重任的可选部分了，也是可以轻的一种选择。</p><p></p><p>单纯讲方法的复杂和简单是没有意义的，要根据目标和企业环境去考虑怎么做选择，这不是坐而论道的问题，只能是走进每一个企业去回答的问题。</p><p></p><h2>三、周期叠加</h2><p></p><p>企业的发展都是在给正在飞着的飞机换发动机，停下来调整好了再走，这是很理想的状态，几乎没有企业真做得到。所以，很多企业搞企业架构会很挠头，也都是因为飞机不能落地，都是在天上修的，这倒不是企业架构方法造成的复杂度，因为只要企业决定了要去解决那些问题，用不用企业架构方法，都是会在天上修飞机的。比较省事的做法是继续“挺”下去，直到真觉得“挺”不住。</p><p></p><p>老的系统不能一步替换、业务流程不能一下子调整到位、数据不能一天治理好、技术不能一天学会、生产一天不能停顿等等，这些问题交织在一起，学习周期、实施周期、新旧并行周期、市场周期都混在一起，会让方法看起来比其本来的复杂程度还要复杂。上文讲，“挺”到真“挺”不住，那时对方法复杂度的畏惧也会下降，所以“降低”复杂度，有时也是可以通过提高“刚需”程度来反向解决的。</p><p></p><p>周期叠加导致的复杂度是很难消解的，其实这个时候更需要的恰恰是企业架构主张的全局视角，通过全局视角判断优先级。实话实说，出现太高的周期叠加导致的复杂度时，架构工作未见得是第一位的，搞架构，晴天修房子最理想，但不下雨企业又注意不到房子漏，天一晴了又去忙别的了，所以常在漏雨时有感觉，但这个时候往往搞不太好，比修房子重要的事情可能太多了。真要在这个时候搞，就不是降低复杂度了，这属于迎难而上，需要的是定力和智慧。</p><p></p><h2>四、阳奉阴违</h2><p></p><p>这个指的是隐式架构导致的复杂程度，业务层执行的实际流程与业务架构梳理的流程不保持一致、技术侧执行的开发与企业架构设计的分工不一致，两侧的隐式架构都力量强大，那等于处处不一致，自然就复杂度爆棚了。这个问题不是方法问题，是管理问题和价值认可度问题，解决之道也不在方法本身，就算降低复杂度也未必有效。</p><p></p><p>这个问题的普遍程度之高也是令人叹息的，架构方法分开看的话，业务、应用、数据、技术、安全架构，其中的每个部分都不比同类方法更复杂。比如，很多人讲梳理流程如果用 BPMN 对业务人员而言太复杂，这其实没啥道理，就好像只有让人随便画流程才是合理的。笔者自己接触过多种业务上实际采用的流程画法，而且做业务人员时参加 ISO 贯标就画过比较标准的流程，至少不认为 BPMN 会是其中对业务人员而言最难理解的。</p><p></p><p>架构自己略微复杂之处是追求各个架构之间的协调一致，而很多企业都没做或者没做到这个衔接，如果单论各个架构部分，就说企业架构太复杂，那只能说是比较的可能不太充分。</p><p></p><p>综上，复杂度本身不是问题的根源，对其的控制也不是一概而论的，就像喜欢名牌就不会嫌名牌贵，喜欢廉价也不会真抱怨质量问题，都是根据需要做出的决策，都不盲目，只有脱离具体目标和实际环境聊复杂度会显得有些盲目。</p><p></p><p></p><p></p><blockquote>本文源自<a href=\"https://www.infoq.cn/theme/239\">《InfoQ × 晓语未来》</a>\"专栏，该专栏由 InfoQ 与行业专家付晓岩联合打造，为您解读最新的数字化政策，分析企业业务架构的转型和实践，并提供对数字化热点议题的洞察和评论。通过专业的视角和丰富的案例，帮助读者在数字浪潮中领航未来。付晓岩，天润聚粮执行董事总经理，原国有大型商业银行资深业务架构师。《银行数字化转型》、《企业级业务架构设计：方法论与实践》和《聚合架构：面向数字生态的构件化企业架构》三书作者。中国计算机学会软件工程专委会委员、数字金融分会首批执行委员；国家工程实验室金融大数据应用与安全研究中心研究员；CIC 金融科技与数字经济发展专家委员会成员；信通院企业架构推进中心、组装式推进中心技术专家；中华全国数字化人才培育联盟专家委员会特聘专家；工信部中小企业发展促进中心产教融合产业实践教授；国家互联网数据中心产业技术创新战略联盟专家委员会副主任专家委员。</blockquote><p></p>",
    "publish_time": "2024-09-11 15:22:20",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "中小银行如何通过组织力建设与人才培养，构建转型组织保障体系",
    "url": "https://www.infoq.cn/article/60DUTuHAoPdaAKFo2xsg",
    "summary": "<p>数字化转型不仅关乎技术层面的革新，更涉及到组织结构和人才培养的深层次变革。</p><p></p><p>在 8 月举行的 <a href=\"https://fcon.infoq.cn/2024/shanghai/\">FCon 全球金融科技大会</a>\"上，新疆银行数字化发展部副总经理、资深银行数字化转型专家田清明发表了题为《中小银行如何通过组织力建设、人才培养构建数字化转型组织保障体系》的演讲。其认为，当我们谈及“数字化转型”时，不仅要关注技术本身，更需要深入理解其中的核心——组织力提升和人才发展如何助力这一进程。</p><p></p><p>本次分享还针对中小银行在数字化转型组织保障体系中组织和人才方面的不足和问题进行了逐一分析，并基于实践经验提出了解决建议和方案。</p><p></p><p>以下是演讲实录（经 InfoQ 进行不改变原意的编辑整理）：</p><p></p><p>今天我想讨论的主题是《中小银行如何通过组织力建设、人才培养构建数字化转型组织保障体系》，核心在于强调组织力和人才培养是数字化转型过程中至关重要的两个基础要素。首先我想与大家达成一个共识，这个共识对于理解整个话题至关重要：为什么我们要特别强调组织力提升和人才培养？它们与数字化转型之间为何存在如此紧密的联系？只有当我们在这些点上达成共识，我们才能更清晰地理解后续的内容。</p><p></p><h2>在“数字化转型”上需达成共识</h2><p></p><p></p><p>数字化转型不仅仅是技术驱动的变革，它本质上是一场全面的变革。我个人是从科技领域起步的，从编码干到了科技管理，现在转移到了业务领域。大约在十年前，我坚信科技是引领业务发展的关键。但随着时间的推移，尤其是在我自己身份由为银行提供技术服务的乙方变为银行甲方后，我的观点发生了根本性变化。下面就开始我的内容分享，分享内容仅代表我的个人观点。</p><p></p><p>首先，为迅速与大家对数字化转型的认识达成统一认知，我从大家都了解的客观事项开始说起。</p><p></p><p>2016 年，浙江省政府明确启动了数字化转型工作；到了 2021 年，浙江省政府在疫情期间的表现非常出色；同时，还有一个标志性的变化是，他们不再使用“数字化转型”这一术语，而是改为“数字化变革”。这说明什么？说明数字化转型就是一场变革！转型是一个更温和的词，不会在变革开始的时候让大家感到害怕，一旦转型工作开展起来了，变革也随之就发生了。</p><p></p><p>因此，我们第一个需要达成的共识是：数字化转型实际上是数字化加上转型。这里的重点是“转型”，而“数字化”只是一个修饰词，是一种方法、路径或手段。对于任何企业，无论是银行、制造业还是其他金融行业，发展过程中都会经历业务转型或组织转型等。在过去，尽管没有提到数字化，但企业并没有停止转型和发展。例如，过去可能称之为会计电算化或信息化。当我们今天讨论数字化转型时，我们必须理解它到底是什么。它不是一个全新的概念。如果我们将重点放在“转型”上，那么数字化转型的意义就变得清晰：企业在面临新的经济周期、新的市场变化时，提升组织力，实现业务转型，从而实现业务能力跃升的过程。数字化是加速这一转型过程的有效方式。</p><p></p><p>我们在第一个共识的基础上以管理学的认知去剖析“转型”后的延伸思考就能有第二个共识，那就是任何企业在进行变革时，都需要从战略、组织、人才、业务流程等方面进行重塑。以华为为例，自 2000 年以来的转型和跃升都是按照这种方式进行的。即使不依赖科技和数据，转型也是可能的，只是速度可能较慢。数字化转型中，科技是生产力，数据是新的生产要素，它们为转型提供了坚实的基础，并加速了变革的进程。</p><p></p><p>2022 年年初，原中国银保监会颁布的《中国银保监会关于银行业保险业数字化转型的指导意见》文件中明确提出了数字化转型应具备的框架，包括战略、组织、人才、业务流程以及数据科技和风险管理等方面。这份文件印证了我们之前的观点：数字化转型不仅仅是数字化，它是一个全面的企业变革，涉及包括战略、组织、人才、业务流程等多个企业转型的关键要素。</p><p></p><p>我们针对上述文件构建的转型框架展开讲一下其内在逻辑：在管理实践中，一旦企业确定了战略方向，接下来的首要任务通常是调整组织结构。这是因为战略确定了企业的发展目标，而现有的业务能力可能无法满足这些目标。组织结构的调整是为了重新定义职能边界，以便更好地支持战略。华为的做法是组织和流程同时调整，但大多数企业在战略确定后，首先调整的是组织，然后是人才或岗位。因为有了新的组织形态和定位，对人才的要求也会随之变化。业务流程的重塑需要经过组织和人才的调整才能完全承接和执行。如果只有业务流程的再造而没有组织、人才和岗位的重新设计，那么战略就无法有效落地。</p><p></p><p>因此，在讨论数字化转型时，需要关注组织保障与人才培养等组织力的提升，而不仅是科技和数据，这是有其内在逻辑的：尽管科技和数据在数字化转型中扮演着重要角色，相比之下，合理的组织保险机制和数字化人才梯队才是执行层面的关键要素。银行或任何企业在数字化转型中，应该根据业务发展周期、业务能力和管理能力来确定所需的数据和科技手段。这是一个自下而上的过程，而不是反过来。企业不能仅仅通过建立系统和对接数据来解决管理问题，这种做法是不切实际的。数据和科技的作用是加速转型过程，但它们并不是转型成功的唯一或决定性因素。如果企业没有通过组织管理和人员调配能力来识别和解决管理问题，而试图通过系统建设来解决问题，那转型注定会以失败告终。这种做法不仅无效，而且可能导致资源的浪费。组织和人才是数字化转型成功的关键，而科技和数据则是支持和加速这一过程的工具。</p><p></p><p>特别地，我们在讨论数字化转型的过程中，要认识到文化是一个非常重要的方面，这一点在《中国银保监会关于银行业保险业数字化转型的指导意见》中也有所体现。文件中提到了要注重数字文化的培育，这一点非常有意思。企业的数字文化是否建立起来，是衡量数字化转型成熟度的一个重要标志。当每个人都能够自然而然地按照新的工作方式，使用新的工具来完成工作时，这种文化就已经形成了。</p><p></p><p>根据我刚才所述，我们可以看到《指导意见》内容非常全面，而这种全面的视角有助于企业在数字化转型过程中，不仅仅关注技术层面的升级，而是更加明确了银行如何通过战略指引下，围绕组织、人才打好基础并建立数字文化，使得整个组织能够适应新的工作方式，从而实现真正的转型。</p><p></p><h2>组织力建设：转型牵头部门如何开展“业技融合”工作</h2><p></p><p></p><p>在前面所达成针对数字化转型的共识里，已经明确了组织力、人才两个关键词。接下来，我就围绕这两个关键词进行剖析，为大家呈现如何开展相关工作的思路与方法。</p><p></p><p>现在我们从组织力建设开始。</p><p></p><p>在讨论组织力建设时，从行业内数字化转型落地的最佳实践来看，我们需要特别关注转型牵头部门如何开展“业技融合”工作。这是因为转型本质上是一种变革，它要求业务通过组织重塑来适应新的业务形态，可能包括新业务的开发和传统业务的改造。数字化转型要求科技为业务赋能，这意味着原有的业务部门和科技部门的职能、协同方式以及赋能模式都将发生变化。</p><p></p><p>如果让传统的业务部门或科技部门来牵头数字化转型，可能会因为它们固有的局限性思维而无法有效执行。数字化转型是一个全面的过程，需要有战略支撑，而传统的部门结构可能无法很好地承接这种战略。因此，在银行领域，大家普遍认同需要一个新的部门来发挥桥梁作用，连接业务部门和科技部门，实现资源整合和业务重塑。所以，当我们讨论组织力建设时，我们实际上是在讨论转型牵头部门如何开展“业技融合”工作。</p><p></p><h3>三类数字化转型牵头部门的定位、优势和不足</h3><p></p><p></p><p>在银行机构中，过去几年普遍存在三种转型牵头部门的形态：数字化转型办公室、数字银行和数字金融部。下面分别解释这三种形态的特征、优势和不足。</p><p></p><h4>数字化转型办公室</h4><p></p><p></p><p>数字化转型办公室在许多企业中是一个常见的组织形式，通常以虚拟组织的形式存在。这种设置反映了企业在变革过程中的一种折中和妥协。由于企业的组织结构和人员往往较为固化，直接建立一个实体组织来连接业务部门和科技部门可能会遇到较大的反对意见。因此，企业可能会选择成立一个虚拟的数字化转型办公室，以温和的方式引入变革，避免直接冲击现有的组织结构和员工的惯性思维。</p><p></p><p>数字化转型办公室的特征是，它在现有的组织架构中作为一个虚拟组织存在，不改变原有的组织结构，而是在某个实体部门内部增加这一虚拟组织，承担特定的责任和义务。这种设置的优势在于它能够以一事一议的方式运作，对部门的日常工作冲击较小，业务部门也更愿意按照这种要求去执行任务。</p><p></p><p>这种温和的方式也带来了一些问题。首先，由于是虚拟组织，它可能难以吸引和保留综合能力强、有挑战性的人才。这些人才可能对虚拟组织的职业发展路径、绩效考核和工作未来感到不清晰。其次，业务部门可能仅以完成任务的心态参与，而不是真正投入到转型工作中。由于数字化转型办公室是虚拟组织，它难以对业务部门的工作进行有效约束。这些问题最终可能导致办公室的工作目标变得不明确，组织变得松散，甚至被边缘化，成为大家都不愿意参与的部门。</p><p></p><p>尽管如此，数字化转型办公室的存在仍然有其必要性。在许多传统企业中，主动变革的动力可能不足，但高层领导具有战略眼光，意识到了变革的重要性。因此，他们可能会选择先温和地调整，逐步暴露问题，然后再进行组织演进。</p><p></p><h4>数字银行部</h4><p></p><p></p><p>数字银行部是部分银行为推动数字化转型而设立的一个新部门，其职责非常明确，即集中全行所有与数据相关的资源、工作和人力，以期快速形成行内的数据资产并广泛服务于业务应用。这个部门通常负责数据监管、报送、分析、处理和应用等任务。理论上，这种集中化的资源管理看起来非常理想，但在实际操作中却面临不少挑战。</p><p></p><p>首先，银行中与数据相关的工作大部分（可能超过 60%）与监管报送相关。尽管这些人员和工作被转移到了数字银行部，但他们仍然需要完成与监管报数相关的任务。这导致数字银行部的成员无法完全专注于数据应用、分析和探索等新任务，因为他们的大部分时间和精力仍然被原有的工作占据。</p><p></p><p>其次，数据质量问题也是一个重要挑战。数据质量问题往往源于业务流程的不规范。例如，如果业务办理过程中没有正确记录联系地址或电话号码，就会产生数据问题。这些问题并非数据本身的问题，而是业务流程不规范导致的。由于业务流程不规范，导致数据采集和处理过程中数据质量偏低。即使存在数据标准和规则，但如果业务执行不规范，就无法保证数据的质量。</p><p></p><p>上述问题导致数字银行部在实际执行中难以达到预期目标。银行对数字银行部的期望很高，但实际成果往往不尽如人意。由于部门成员无法从原有工作中完全脱离出来，他们很难有效地进行数据探索和分析工作。此外，由于数据质量问题，即使部门拥有数据，也无法确保数据分析的准确性和有效性。</p><p></p><p>最终导致业务部门对数字银行部的质疑和不满。他们可能会认为，最优秀的人才被调走了，但数字银行部的成果并不明显。在这种情况下，数字银行部的工作定位和实际成果之间存在很大的差距，使得部门处于被动状态。有些银行可能会选择撤销数字银行部，将人员和职能重新分配回原来的部门，以缓解这种紧张局势。这种回退的做法可能会让所有人都感到满意，但从长远来看，它并没有解决数字化转型过程中面临的根本问题。</p><p></p><h4>数字金融部</h4><p></p><p></p><p>数字金融部在许多银行中是由原有的网络金融部或电子银行部转变而来的。在互联网金融兴起的时期，银行为了适应市场变化，开始区分线上产品和线下产品。银行希望通过创建新的产品线和服务线，与传统的产品线进行竞争，并通过数字化手段赋能，以期在与传统业务的竞争中取得优势。</p><p></p><p>数字金融部的成立初衷是利用数字化转型来改变思维方式和经营模式。如果银行的战略从专注于大型对公业务转向普惠金融，那么相应的经营方式和思维方式也需要发生显著变化。</p><p></p><p>数字金融部也面临着一些挑战和不足。首先，对于客户而言，他们不会区分线上或线下产品，他们只认银行的品牌。如果银行按照产品线而非客户体验来定义服务，可能会导致客户体验的割裂。此外，由于数字金融部与传统部门的服务对象可能重叠，可能会导致内部冲突，同一个客户可能会被不同部门重复打扰。其次，尽管数字金融部的名称和定位更新了，但其核心团队成员可能仍然是原班人马，只是换了个名字。这些成员可能难以适应新的思维方式和工作模式，限制了部门发挥其应有的作用。</p><p></p><p>总的来说，针对数字化转型牵头部门所面临的问题和不足，以下是一些解决建议：</p><p><img src=\"https://static001.geekbang.org/infoq/48/488c14bf5cb7cde65389f1cc2f39b3dc.png\" /></p><p></p><h3>具有“数字化转型办公室 + 数字金融部”职能的数字金融部</h3><p></p><p></p><p>为让大家对组织力如何去做提升有一个直观的认识，我将一个具体的组织力提升的案例进行剖析，以给大家抛砖引玉。</p><p></p><p>首先我们要明确在探讨数字化转型的不同组织形态时，没有绝对的好与坏，关键在于是否适合特定企业的需求。以某家银行为例，其数字金融部的职能既包括了数字化转型办公室的规划制定，也涵盖了数字金融部的产品孵化和业务架构管理，是一个综合性的部门。这样的数字金融部需要聚焦于产品孵化，同时做好业务与技术的融合，以及数字工具的赋能，以快速响应一线业务部门的需求。这种综合性的数字金融部也面临着一系列挑战。</p><p></p><p>缺乏可借鉴路径：由于这种组织形态在行业中较为罕见，没有现成的模式可以模仿。转型思路不统一：由于职能众多，不同部门可能对转型的目标和方法有不同的理解。线上产品刚起步：对于纯线上产品的开发，缺乏可以参考的经验，需要探索如何将线上与线下产品有效结合，避免给客户带来不良体验。数字化人才缺乏：面对广泛的职能范围，缺乏相应的专业人才。业绩融合弱：在执行多项任务时，缺乏有效的业绩融合和评估机制。</p><p></p><p>为了解决这些问题，该行采取以下策略。</p><p></p><p>高位推动：建立转型领导小组常态化议事机制，明确并授权数字化转型办公室、数字金融部以相关的职责，充分发挥其在转型过程中的组织作用；在将组织工作的重心放在近期工作任务计划的同时，要明确远期所要达成的结果指明转型方向。统一转型思路：持续开展对全行管理层、员工按统一认识的目标构建其对应岗位、层级建立不同的数字化转型知识培训体系，让上下逐步形成全行转型的统一认知，高效、高质量执行具体的转型任务建立产品管理体系：建立新产品孵化的管理体制，明确指定统筹牵头部门，以便统一调度资源，及时响应组织级工作协同需求，实现产品在创新过程中的安全性、完整性、灵活性与扩展性。引进和培养数字化人才：一是加大对专家型与高级数字化人才的引入，成为全行数字化转型工作重要的人才节点，带动全行重要转型任务的开展；二是打基础，抓员工数据、科技基础技能培训，并通过在实战中运用技能锻炼队伍，逐步形成数字化运营人才梯队。借助外力：在业务与技术融合能力较弱的情况下，可以考虑借助外部力量，如第三方服务提供商。但在寻求外部帮助之前，需要明确自身的痛点和需求，以便找到合适的合作伙伴。</p><p></p><h2>人才队伍建设：如何制定与执行可落地的数字化人才实施方案</h2><p></p><p></p><p>在组织力做好设计与运行后，我们必须考虑在新的组织体系下需要什么样的人来执行？人才队伍的建设就非常重要了。</p><p></p><p>我们从《指导意见》的要求来看，转型工作实际上与银行中的每个员工都紧密相关，因此关键在于如何让每位员工，尤其是核心团队成员，积极参与到转型中，并培养他们成为具备复合技能的人才。同时，银行需要建立一个全面的数字化人才体系，这不仅是技术能力的提升，也包括数据能力和建模能力的培养。</p><p></p><p>在培训过程中，我们常常发现员工在培训结束后感觉所学内容与实际工作难以结合。这暴露出我们在培训中过于注重技能性训练，而忽视了基础概念的理解和共识的建立。特别是在科技金融或金融科技领域，很多人对业务的基本概念和思维框架理解不足，导致技术和业务逻辑之间的脱节。</p><p><img src=\"https://static001.geekbang.org/infoq/62/62c0d8f514287c7a1fed4483b92ef6b3.png\" /></p><p></p><p>为了解决这一问题，我们需要明确培养目标，并根据这些目标定制能力框架。培养框架应该包括培训的目标、思路、框架、方法、课程体系和培训计划，这些要素缺一不可。最终需要形成一个完整的数字化人才培养方案和行动计划表，确保培训计划能够落地执行。同时这个方案应该明确每个阶段的目标、策略和执行步骤，以确保培训内容与实际工作紧密结合，从而有效地支持银行的数字化转型。</p><p></p><p>在数字化转型的过程中，领军型人才和复合型管理人才的培养至关重要。过去，我们的培养重点往往集中在业务和技术专家上，而忽视了管理人才和领军人才的重要性。实际上，这两种人才是构建人才梯队、推动转型成功的关键。</p><p></p><p>培养应当从高层领导或潜在领导开始，他们通常是人才培养计划中的重要对象。培养方式需要多样化，且培养周期要适中，既不能过短以致于无法深入学习，也不能过长以致于延误转型进程。</p><p></p><p>培养方案需特别强调管理能力的重要性，这不仅仅是传统的管理学知识，更重要的是转型战略和数据思维。这些能力是可以通过量化和课件学习的，从而让管理层明确在数字化转型背景下应该做什么。例如，可以为银行管理层设计一个完整的课程体系，从宏观环境、监管要求到具体的执行策略，再到文化建设和运营机制，形成一个完整的管理逻辑。</p><p></p><p>培养计划还需要具体落实到课程内容、培养对象和周期上。不同类型的人才需要明确自己的重点工作和培训内容，以便更好地与自己的工作结合。最终，需要形成一个详细的实施方案和执行计划表，包括所有必要的内容。这样，组织内的人才培养框架和重点行动计划就非常清晰了。</p><p></p><h2>“一行一策”，脚踏实地构建转型基座</h2><p></p><p></p><p>在总结数字化转型工作时，我们强调“一行一策”的重要性，意味着每个银行或企业都应根据自己的实际情况制定合适的转型策略。这项工作的基础性非常强，它不是一件可以推迟的任务，而是一项必须立即开始且持续进行的工作。只有从现在开始，打好基础，才能确保数据和科技的应用在未来能够真正发挥作用。如果没有坚实的基础，就无法有效使用工具，也无法确保组织能够充分利用这些工具。</p>",
    "publish_time": "2024-09-11 15:36:22",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Android全力押注Rust，Linux却在原地踏步？谷歌：用Rust重写固件太简单了！",
    "url": "https://www.infoq.cn/article/9z7OYVi315St03g6AJtt",
    "summary": "<p>谷歌最近使用Rust编程语言重写了Android虚拟化框架中受到保护的虚拟机固件，并且建议涉及固件处理项目的开发者也同样积极拥抱这种内存安全语言。</p><p>&nbsp;</p><p></p><h2>Rust在Linux上遇阻，但在Android上受宠</h2><p></p><p>&nbsp;</p><p>在谷歌发布的博客中，Android工程师Ivan Lozano和Dominik Maier深入研究了使用Rust替换旧版C和C++代码的技术细节。</p><p>&nbsp;</p><p>Lozano和Maier介绍称，“大家可以看到，使用Rust代码来提高安全性其实相当简单易行，我们甚至会演示Rust工具链如何应对特殊的裸机目标。”</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/69/6900b47957b8878b4a75da6f2a6c5021.jpeg\" /></p><p></p><p>&nbsp;</p><p>对于Rust这样一门以学习难度高而闻名的编程语言来说，“简单易行”的说法似乎有点超出普遍认知。</p><p>&nbsp;</p><p>另外，让C和C++开发人员尝试用Rust的视角观察世界同样困难重重。<a href=\"https://mp.weixin.qq.com/s/7xr8UH6gi71pheZYcHrbcw\">就在上周，Rust for Linux项目的一位维护者刚刚选择辞职</a>\"（此项目旨在将Rust代码纳入基于C的Linux内核），理由就是Linux内核开发人员对Rust的强烈抵制。</p><p>&nbsp;</p><p>在今年早些时候，一位Linux内核贡献者在某场技术会议的热烈讨论中明确表示，“不会吧，你们不会强迫我们所有人都学习Rust吧。”</p><p>&nbsp;</p><p>尽管受众态度并不积极，但谷歌还是对潜在支持者拿出了足够的耐心和鼓励。Lozano和Maier指出，以往的固件通常使用内存不安全语言（例如C和C++）编写而成，因此缺乏高级安全机制。而Rust提供了一种避免内存安全漏洞（包括缓冲区溢出和释放后使用）的方法，成功阻遏了这些在大规模代码库中占据多数的重大漏洞来源。</p><p>&nbsp;</p><p>他们强调称，“Rust提供了一种内存安全的C和C++替代方案，有着足以与之媲美的性能表现和代码体量。”此外，Rust还支持与C代码的互操作性，且不会带来任何额外开销。</p><p>&nbsp;</p><p><a href=\"https://mp.weixin.qq.com/s/vL5NSp3W-974Szn32uhvsA\">就连美国政府最近也一直在强调这个议题</a>\"，并在各领先科技企业及非营利项目的支持下，尝试用Rust语言重写关键开源项目及组件。去年，网络安全与基础设施安全局（CISA）就建议软件供应商“将有关法律并最终消除其产品线中的内存安全漏洞，作为公司的最高目标之一。”</p><p>&nbsp;</p><p>谷歌已经接受了这一观点，今年3月，谷歌得出结论称，其Rust开发人员的生产力已经达到C++工程师的两倍。</p><p>&nbsp;</p><p>谷歌Android编程语言工程总监兼Rust基金会董事会主席Lars Bergstrom也表态说，“我们意识到Rust在构建技术栈各个层面的安全可靠软件方面，正在发挥极其关键的作用。”</p><p>&nbsp;</p><p>&nbsp;“在谷歌，我们正推动在Android、Chromium等平台上使用Rust语言，借此减少内存安全漏洞。我们还致力于同Rust生态系统开展合作、推动语言落地，并为开发人员提供顺利迁移所必需的资源和培训支持。这波将Rust引入嵌入式及固件开发的尝试，解决了技术栈中又一关键安全难题。”</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/61/61eafc981ca563015f8a9ccb82497f2c.jpeg\" /></p><p></p><p>&nbsp;</p><p>有网友指出，Rust在Android上进展顺利的关键就在于Lars Bergstrom的态度：</p><p>&nbsp;</p><p>“我们来看一下这位的头衔：谷歌 Android 编程语言工程总监，同时也是 Rust 基金会董事会主席。我认为，将 Android 系统全面采用 Rust 语言的进程可能会比 Linux 内核更顺利推进，因为他是负责人，有权解雇那些不按要求进行 Rust 改造的人。”</p><p>&nbsp;</p><p>而在Linux圈子里，Alex Gaynor和Geoffrey Thomas在2019年Linux安全峰会上表示，大约三分之二的Linux内核漏洞源于内存安全问题。而Rust理论上可以通过其本质上更安全的应用程序接口（API）完全避免这些问题。</p><p>&nbsp;</p><p>Torvalds对这一切怎么看？早几年的时候，他属于“观望派”——“我对这个项目感兴趣，但我认为它是由对Rust非常热衷的人推动的，我想看看它在实际中会如何运作。”</p><p>&nbsp;</p><p>Torvalds还表示：“个人而言，我并不在‘推动’Rust的行列中，但考虑到它所承诺的优势和避免一些安全隐患的可能性，我对它持开放态度，不过我也清楚有时承诺未必能兑现。”</p><p>&nbsp;</p><p>去年底，在Linux基金会的日本开源峰会上，Linus Torvalds和Dirk Hohndel（Verizon开源部门负责人）讨论了Rust语言在Linux内核中的使用，Torvalds表示，“Rust的使用在不断增长，但目前我们还没有任何内核部分真正依赖Rust。对我来说，Rust是一个在技术上合理的东西，但对我个人而言，更重要的是，我们作为内核和开发者，不能停滞不前。”</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a6/a62fe3827d675e21968770e60306634f.jpeg\" /></p><p></p><p>&nbsp;</p><p>这个表达有人解读为“Linus个人对Rust不是那么赞赏，但Linux总需要尝试一些新的东西”。</p><p>&nbsp;</p><p>另一方面也有人反驳说，“如果 Linus 没有从根本上相信 Rust 是一种应该在内核中占有一席之地的语言，那么 Rust 也不会获得内核支持。”</p><p>&nbsp;</p><p>在今年的KubeCon上，Linus Torvalds和Dirk Hohndel再次谈到了如何将 Rust 语言引入 Linux。Torvalds 对 Rust 的应用速度未能如预期般加快感到失望，“我原本指望着更新速度会更多，但问题在于不少老一代内核开发人员更习惯于使用 C 语言，而不太熟悉 Rust。他们不太愿意学习一种在某些方面与老办法截然不同的新语言。因此，Rust 的普及受到了一些阻力。”</p><p>&nbsp;</p><p>除此之外，Torvalds 还评论道，“另一个原因在于，Rust 自身的基础也并不是十分牢靠。”可以说，相比Lars Bergstrom，实际上Torvalds对Rust的态度一直很审慎。</p><p>&nbsp;</p><p></p><h2>作为Android的新默认语言，Rust的推进一直很顺利</h2><p></p><p>&nbsp;</p><p>2021年，谷歌宣布将Rust选定为Android开源项目（AOSP）代码新贡献的默认语言。</p><p>&nbsp;</p><p>谷歌在Android项目中使用的其他内存安全语言还包括Java以及与Java兼容的Kotlin。C和C++仍然是AOSP中的主导语言，但Android 13是首个大部分新代码都由内存安全语言编写的版本。在谷歌于2021年4月首次将Rust用于AOSP之后，短短一年后，这种编程语言在新代码贡献量中就占比约21%。</p><p>&nbsp;</p><p>在 Android 的新代码中使用 Rust，是为了减少与内存相关的漏洞。2019年发布的Android 10版本存在223项内存安全漏洞，而Android 13的已知内在安全问题已经大幅减少至85个。</p><p>&nbsp;</p><p>Android安全软件工程师Jeffery Vander Stoep于2022年指出，内存安全漏洞占Android总漏洞的比例从76%下降到了35%。随着内存安全漏洞的减少，谷歌还发现关键及远程可利用漏洞的数量同样有所缩减。</p><p>&nbsp;</p><p>Vander Stoep补充说，这一变化并非源自代码贡献者的“灵光乍现”，只是人们开始使用更好的工具来完成工作。Android团队计划加强对Rust的使用，但这也并不意味着要在其系统编程中彻底淘汰C和C++。</p><p>&nbsp;</p><p>他在推文中解释道，“如果一定要为此番成就找个理由，那我个人的答案就是‘谦逊’。Android团队中的各个部门都一直在关注‘我们怎样才能做得更好’这个关键问题，同时也有毅力坚持到底并做出改变，包括系统层面的变革。”</p><p>&nbsp;</p><p>“谦逊本身也应该是双向的。Rust并不能解决所有问题，C/C++在某些领域仍将是开发实践中最实用的选择，至少在相当长的一段时间内依旧如此。这很正常。”</p><p>&nbsp;</p><p>&nbsp;“我们将随时间推移努力减少这种情况，同时继续扩大我们的Rust使用率，并不断投资和部署对C/C++代码的改进。”</p><p>&nbsp;</p><p>Vander Stoep还提到，相关性也并不等同于因果关系，但必须承认内存安全漏洞的百分比（即在高严重性漏洞中的比例）确实与新代码使用的语言类型有着很强的关联趋势。谷歌表示，模糊测试等安全工具也在打击内存安全漏洞方面贡献了重要力量。</p><p>&nbsp;</p><p>Vander Stoep表示，“我们将继续投资于工具开发以提高项目的C/C++安全性。在过去几个版本当中，我们在生产Android设备上引入了Scudo强化分配器、HWASAN、GWP-ASAN以及KFENCE。我们还在现有代码库当中扩大了模糊测试的覆盖范围。使用这些工具发现的漏洞既有助于预防新代码中出现类似的问题，也有助于在上述评估中及时揪出旧代码中存在的漏洞。这些重要工具对我们的C/C++代码至关重要。然而，单凭这些还不足以解释我们从安全漏洞中观察到的趋势性变化，其他同样部署了这些技术的项目也并未发生如此重大的结构性变化。因此我们认为，Android从内存不安全语言向着内存安全语言的持续转变才是改善其安全态势的一大核心因素。”</p><p>&nbsp;</p><p>他当时还指出，Android 13中共包含150万行Rust代码，约占所有代码新贡献的21%。而且谷歌也没有在Android的Rust代码中发现任何内存安全漏洞。但谷歌认为将Rust应用于新代码，而不是用Rust重写整个操作系统，是更为合理的选择。团队表示：“即使我们让Android团队的每一位软件工程师都投入这项工作，重写数千万行代码也是不可行的。”</p><p>&nbsp;</p><p>Vander Stoep指出，“这表明Rust语言正一步步实现其预期目标，即防止Android中最常见的漏洞来源。在Android的不少C/C++组件（包括媒体、蓝牙和NFC等）当中，过往内存漏洞的密度已经超过了1/kLOC（即每千行代码一个漏洞）。以这样的历史水平为基准，对Rust语言的使用很可能已经将数百个漏洞阻挡在了生产环境之外。”</p><p>&nbsp;</p><p>在Android项目之内，谷歌使用Rust建立用户空间硬件抽象层（HAL），并在越来越多的受信应用程序之内添加对Rust的支持。去年，谷歌还曾发布过公告，表示他们用Rust编程语言重新实现了Linux内核中的Android Binder代码，Binder负责进程间通信（IPC）等任务。与C版Binder相比，Rust Binder的IPC基准测试结果显示出良好的前景，但仍需在实际工作负载下进行进一步测试。至少在Binder吞吐量的基准测试中，Rust版本与C版本的性能差异约为±2%。</p><p>&nbsp;</p><p>如今谷歌进一步在现有固件代码库中部署了 Rust。</p><p>&nbsp;</p><p>根据谷歌软件工程师Ivan Lozano和Dominik Maier的文章，使用C和C++编写的旧固件代码库可以通过“直接替换为Rust”来受益，以保证操作系统底层敏感层的内存安全。</p><p>&nbsp;</p><p>“我们希望证明这种方法对于固件是可行的，能够以高效且有效的方式实现内存安全，”Android团队表示。</p><p>&nbsp;</p><p>“固件充当硬件和高级软件之间的接口。由于缺乏高级软件中标准的软件安全机制，固件代码中的漏洞可能会被恶意攻击者危险地利用，”谷歌警告说，并指出现有的固件由用内存不安全的语言（如C或C++）编写的庞大的传统代码库组成。</p><p>&nbsp;</p><p>“简单地用Rust编写任何新代码都可以减少新漏洞的数量，并随着时间的推移减少现有漏洞的数量，”Android软件工程师表示，建议开发人员通过编写一个薄的Rust shim来替换现有的C功能，该shim在现有Rust API和代码库期望的C API之间进行转换。</p><p>&nbsp;</p><p>“shim作为Rust库API的包装器，连接了现有的C API和Rust API。当用Rust替代重写或替换现有库时，这是一种常见的做法。”</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.theregister.com/2024/09/06/google_rust_c_code_language/\">https://www.theregister.com/2024/09/06/google_rust_c_code_language/</a>\"</p><p><a href=\"https://security.googleblog.com/2024/09/deploying-rust-in-existing-firmware.html\">https://security.googleblog.com/2024/09/deploying-rust-in-existing-firmware.html</a>\"</p><p><a href=\"https://www.zdnet.com/article/google-after-using-rust-we-slashed-android-memory-safety-vulnerabilities/\">https://www.zdnet.com/article/google-after-using-rust-we-slashed-android-memory-safety-vulnerabilities/</a>\"</p><p><a href=\"https://www.reddit.com/r/rust/comments/18e6qrl/linus_on_rust_in_the_linux_kernel_december_2023/\">https://www.reddit.com/r/rust/comments/18e6qrl/linus_on_rust_in_the_linux_kernel_december_2023/</a>\"</p><p><a href=\"https://www.phoronix.com/news/Google-Linux-Binder-In-Rust\">https://www.phoronix.com/news/Google-Linux-Binder-In-Rust</a>\"</p><p><a href=\"https://www.zdnet.com/article/rust-support-moves-into-android-underpinnings/\">https://www.zdnet.com/article/rust-support-moves-into-android-underpinnings/</a>\"</p>",
    "publish_time": "2024-09-11 15:38:07",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "面壁小钢炮 3.0 重磅发布！“无限”长文本，性能超 Kimi",
    "url": "https://www.infoq.cn/article/3bmauitUuaQ3d9vmlKrp",
    "summary": "<p></p><p>近日，面壁智能宣布，旗舰端侧模型面壁「小刚炮」系列进化为全新 MiniCPM 3.0 基座模型，再次以小博大，以 4B 参数，带来超越 GPT-3.5 的性能。</p><p></p><p>据介绍，MiniCPM 3.0 量化后仅 2GB 内存，端侧友好，主要特点包括：</p><p></p><p>无限长文本，榜单性能超越 Kimi，超长文本也不崩；性能比肩 GPT-4o 的端侧最强 Function Calling；超强 RAG 外挂三件套，中文检索第一、生成超 Llama3-8B。</p><p></p><p>MiniCPM 3.0 开源地址：</p><p></p><p>GitHub:</p><p>🔗 <a href=\"https://github.com/OpenBMB/MiniCPM\">https://github.com/OpenBMB/MiniCPM</a>\"</p><p>HuggingFace:</p><p>🔗 <a href=\"https://huggingface.co/openbmb/MiniCPM3-4B\">https://huggingface.co/openbmb/MiniCPM3-4B</a>\"</p><p></p><p>“提前近 4 个月，我们实现了初代面壁小钢炮发布时立下的 Flag：今年内让 GPT-3.5 水平的模型在端侧跑起来！”面壁智能团队表示。</p><p></p><p>据悉，MiniCPM 3.0 再次挖掘端侧模型的极致性能，仅 4B 参数，在包括自然语言理解、知识、代码、数学等多项能力上对 GPT-3.5 实现赶超，在 Qwen2-7B、 Phi-3.5、GLM4-9B、LLaMa3-8B 等一众中外知名模型脱颖而出。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/21/210ccd8f55beeacbbc332a0f9f61afb5.png\" /></p><p></p><p>历经数次调整，面壁团队构建了全新技术架构。围绕 Scaling Law 的核心，面壁将提升知识密度视为高效大模型的第一性原理（知识密度 = 模型能力 / 参与计算的模型参数），并且提出了大模型时代的“摩尔定律”：模型知识密度不断提升，平均每 8 个月提升一倍，内部称为“面壁定律”。</p><p></p><p>新一代小钢炮集长文本、Function Call 与 RAG 等大模型重要能力于一身，在这些呼声极高的模型功能上，MiniCPM 3.0 集结各家所长。</p><p></p><h4>面壁“无限”长文本，性能超 Kimi</h4><p></p><p></p><p>上下文长度是衡量大模型基础能力的一项重要指标，更长的上下文长度意味大模型拥有更大的“内存”和更长的“记忆”，不仅能提高大模型处理数据的能力上限，还能拓宽大模型应用的广度和深度。</p><p></p><p>面壁提出 LLMxMapReduce 长本文分帧处理技术 ，一举实现“无限”长文本。除了超越 GPT-4、KimiChat 等标杆模型的优异表现（ InfiniteBench 榜单成绩），面壁还表示，文本越长，4B 小钢炮凭借愈加稳定的表现，可以展现出越强的性能优势。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/90/90235cb40d89075f0b69d73908643553.png\" /></p><p></p><p>InfiniteBench 大模型长文本能力的权威评测集</p><p></p><p>检索、数学、代码、问答和摘要等多维度能力评估</p><p></p><p>① MiniCPM 3.0 表现超越 GPT-4、KimiChat、Qwen2-70B；</p><p>② 千亿模型 Qwen2-70B、Llama3-70b 结合 LLMxMapReduce 也取得更佳表现。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f8/f8ce69cce071e1d2b9ee40398a3cab26.png\" /></p><p></p><p>InfiniteBench Zh.QA 评测结果显示，4B 参数的面壁小钢炮整体性能优于 Kimi，在更长的文本上表现出相较更强的稳定性。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/69/69a8bc0a1c3a7fdef0a05e3f5737fc7a.png\" /></p><p></p><p>LLMxMapReduce 技术框架图</p><p></p><p></p><h4>GPT-4o 级 Function calling ，终端 Agent 应用蓄势待发</h4><p></p><p></p><p>智能体应用是端侧 AI 必争之地，其中一项至关重要的技术是 Function Calling（函数调用），它能够将用户模糊化的输入语义转换为机器可以精确理解执行的结构化指令，并让大模型连接外部工具和系统，例如通过语音在手机上调用日历、天气、邮件、浏览器等 APP 或相册、文件等本地数据库，从而打开终端设备 Agent 应用的无限可能，也让人机交互更加自然和方便。</p><p></p><p>据介绍，MiniCPM 3.0 拥有端侧最强 Function calling 性能 ，在权威评测榜单 Berkeley Function-Calling Leaderboard 上，其性能接近 GPT-4o，并超越 Llama 3.1-8B、Qwen-2-7B、GLM-4-9B 等众多模型。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/2d/2d92def44884bc6fd77b9f6afedacb1a.png\" /></p><p></p><p></p><h4>RAG 外挂三件套</h4><p></p><p></p><p>端侧模型也能“开外挂”，RAG（检索增强生成技术）让模型引用外部知识库，检索到最新、最可靠的专业知识，确保生成内容更加可信，大大减少大模型的幻觉问题。大模型 +RAG 在行业中极其实用，尤其是对法律、医疗等依赖专业知识库、对大模型幻觉容忍度极低的垂直行业。</p><p></p><p>这次，面壁一口气带来超强 RAG 外挂三件套：MiniCPM-Embedding（检索模型）、MiniCPM-Reranker（重排序模型）和面向 RAG 场景的 LoRA 插件（生成模型），款款优秀：</p><p></p><p>MiniCPM-Embedding（检索模型）中英跨语言检索取得 SOTA 性能，在评估模型文本嵌入能力的权威评测集 MTEB 的检索榜单上中文第一、英文第十三 ；MiniCPM-Reranker（重排序模型）在中文、英文、中英跨语言测试上取得 SOTA 性能 ；经过针对 RAG 场景的 LoRA 训练后，MiniCPM 3.0-RAG-LoRA 在开放域问答（NQ、TQA、MARCO）、多跳问答（HotpotQA）、对话（WoW）、事实核查（FEVER）和信息填充（T-REx）等多项任务上的性能表现，超越 Llama3-8B 和 Baichuan2-13B 等业内优秀模型。</p><p></p><p></p><p></p><p></p>",
    "publish_time": "2024-09-11 16:58:31",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "走近张大鹏教授：哈工大走出的中国第一位人工智能博士",
    "url": "https://www.infoq.cn/article/yMDtbBbGAEPSLhPZDttm",
    "summary": "<p></p><h3>写在最前</h3><p></p><p></p><p>张大鹏，加拿大皇家科学院院士，加拿大工程院院士，国际电气与电子工程师协会终身会士（IEEE Fellow），国际模式识别协会会士，亚太人工智能学会会士，香港中文大学（深圳）数据科学学院校长学勤讲座教授，深圳市人工智能与机器人研究院（AIRS）计算机视觉研究中心主任，香港中文大学（深圳）—联易融计算机视觉与人工智能联合实验室主任，以及香港理工大学荣誉教授。长期担任清华大学双聘教授，以及哈尔滨工业大学、北京大学、上海交通大学及加拿大滑铁卢大学的兼职教授。</p><p></p><p>张大鹏教授本科毕业于北京大学计算机专业，硕士毕业于哈尔滨工业大学，并先后两次博士毕业于哈尔滨工业大学和加拿大滑铁卢大学。他在哈尔滨工业大学读博期间师从中国计算机科学与工程奠基人之一陈光熙教授，张大鹏教授也是新中国培养的第一位工智能研究方的博士。</p><p></p><p>张大鹏教授从事生物特征识别、图像处理等人工智能方向的研究四十余年，是掌纹识别、中医四诊量化及人脸美学客观化等研究领域的开创者和领军人。多年来出版相关专著 20 多部，发表论文 500 余篇，持有六十多项美国、日本和中国的专利。在中医领域感知特征的标准化、量化研究，以及人体美学等生物特征的体系化研究中做出了重要贡献。</p><p></p><p>生物特征识别是人工智能领域的研究方向之一，这种技术可以通过计算机利用人体的生理特征（指纹、虹膜、面相、DNA 等）或行为特征 (步态、击键习惯等) 来进行个人身份鉴定。</p><p></p><p>从今年开始，当我走进深圳街头的 7-11 便利店时，会见到很多门店都已经开始支持微信的刷掌支付。在体验便利支付方式的同时，我时常想到掌纹识别研究方向的开创者张大鹏教授。早在学校读博的时候，在我们学院历史介绍中就经常都会看到关于张大鹏的介绍。因为他是哈工大计算机专业毕业的第一位博士。</p><p></p><p>今年 75 岁的张大鹏教授依然工作在科研第一线，2024 年 8 月，我在香港中文大学深圳校区见到了百忙之中的他，听他给我讲述了他在生物特征识别领域四十多年的研究历程。</p><p></p><p></p><h3>进取的下乡岁月</h3><p></p><p></p><p>张大鹏，1949 年出生于黑龙江省哈尔滨市。张大鹏从小学习成绩就特别好，并且有极强的上进心。初中时期，他就读于哈尔滨市第二中学，那时候他各科考试的总分在全学年 19 个班级中排名第一。</p><p></p><p>初中阶段，他的一篇作文《我和祖国一同成长》被中央广播电台中学生节目选中，在全国播放。同时，张大鹏的思想非常积极，同时担任校学生会的团支部书记和学习委员。</p><p></p><p>在上世纪六十年代，董加耕和邢燕子的事迹传遍全国。1961 年，董加耕毅然放弃了北京大学哲学系的保送机会，回乡务农。同样在那个年代，邢燕子在初中毕业后也没有回到家乡天津市，而选择了去当时的天津市宝坻县司家庄村进行劳动。</p><p></p><p>1965 年，16 岁的张大鹏到了该初中毕业的时候，本来父母希望他继续考高中。但是董加耕和邢燕子的事迹也深深感染着张大鹏，他决心响应号召，到更广阔的天地里去经历风雨，去见世面。</p><p></p><p>当时，哈尔滨市十几所中学的毕业生里共有 38 人报名了“上山下乡”，包括 5 名高中毕业生和 33 名初中毕业生。他们当时受到了哈尔滨市市领导的接见，他们坐着大卡车环游哈尔滨的主要街道，受到全市各个中小学师生的沿途欢送。这在当时对这些立志报国的热血年轻人来说是莫大的荣耀。</p><p></p><p>张大鹏下乡的地方是松花江地区呼兰县。他提出要到最艰苦的地方接受锻炼，于是便被分配到了呼兰县莲花公社井沿大队，这里是呼兰县、阿城县和巴彦县的三县交界，当地条件十分艰苦。</p><p></p><p>张大鹏在下乡期间表现非常出色，这期间他担任了生产队队长、亚麻厂厂长以及五七农场场长等职务。有一段时间还被调到呼兰县县委工作。同时，张大鹏文采很好，当时还是《光明日报》和《黑龙江日报》的通信记者。</p><p></p><p>1970 年，清华大学和北京大学在全国招收工农兵学员，一共在呼兰县招收 3 名学生，张大鹏前往北京大学计算机专业进行本科学习。</p><p></p><p></p><h3>补习基础知识的北大时光</h3><p></p><p></p><p>1970 年，北京大学计算机专业招收了50多名学生，那时候的计算机专业还处于绝密阶段，大部分生源都来自军队，以定向培养为主。</p><p></p><p>张大鹏非常珍惜在北京大学学习的时光，由于初中毕业就下乡劳动五年，没有高中的学习基础，在校期间张大鹏非常刻苦，那时候每周只休息一天，这一天的时间他总会整日泡在图书馆补习高中课程。</p><p></p><p>在大学期间，他跟其他同学合作，在学校期刊上发表了一篇论文《关于计算机存储器“下雨”检测周期的新认识》。</p><p></p><p>张大鹏身高一米八五，腿也长，学校就让他加入了田径队。有一段时间，他非常刻苦的训练，在学校的很多日子，张大鹏都会早起晨跑，他腿上绑着沙袋，在北大的校园里认真准备体育比赛。后来，在北京市高校学生的田径比赛中，张大鹏分别打破了男子 200 米和 400 米的短跑高校比赛记录。他还代表学校参加了北京市运动会，并担任旗手。</p><p></p><p>因为张大鹏的文笔一直很好，经常在学校写一些报道和诗歌。毕业的时候，他还写了一部小说并入选毕业生成果展览，当时在北大师生中引起了强烈反响。</p><p></p><p>1974 年，张大鹏就要大学毕业，本来他已经内定留校，不过张铁生高考交白卷的事件导致当时的氛围很紧张，张大鹏觉得还是回到家乡更踏实一些。于是他跟学校提出了调回黑龙江的申请，大学毕业后，张大鹏被分配到黑龙江大学，那时候的黑龙江大学还没有计算机专业，于是他成为了一名数学系的大学老师。</p><p></p><p></p><h3>组建黑龙江大学计算机系的前身</h3><p></p><p></p><p>张大鹏的专业是计算机，除了完成数学系的正常教学任务，他还在系里组建了计算机研发小组。作为小组的负责人，张大鹏牵头研发了可以用于工业计算的微型计算机，并且得到了实际应用，这个项目后来还在 1978 年的黑龙江科学大会上获奖。这个计算机研发小组也是后来黑龙江大学计算机系的前身。</p><p></p><p>在黑龙江大学期间，张大鹏一个偶然的机会认识了黑龙江省公安厅的刑事技术专家崔道植（崔道植先生是全国公安第一代刑事技术警察、中国首席枪弹痕迹鉴定专家，被誉为中国的“福尔摩斯”）。崔道植提出希望张大鹏研发的微型计算机可以用于指纹识别技术，这对刑事案件的侦破会非常有帮助。这引发了张大鹏对生物识别技术的思考，使他产生了多年科研之路的萌芽。</p><p></p><p>1977 年，改革开放的消息传来，国家在恢复高考制度的。1980 年 2 月，新中国颁布第一个学位条例，也开始了研究生入学考试。上进的张大鹏觉得只有继续深造才能进一步提高自己，于是他全力准备考研，跟着数学系的老师学习数学，跟着英语系的老师学习英语。</p><p></p><p>1980 年，作为学位法公布后的第一批研究生，张大鹏以优异的成绩考入哈尔滨工业大学计算机专业。</p><p></p><p></p><h3>哈工大，生物特征识别研究的起点</h3><p></p><p></p><p>张大鹏在哈尔滨工业大学的硕士导师是李仲荣教授，因为以前就接触过指纹识别，他硕士的研究方向就选择了指纹识别。</p><p></p><p>在读期间，他在非常简陋的条件下，他完成了包括软 / 硬件在内的完整的微机指纹识别系统。</p><p></p><p>他的研究还协助大庆市公安局破获了一起盗窃案，公安机关在作案现场采集到了犯罪嫌疑人的指纹，他的算法匹配到了三个指纹细节特征，从而确定了嫌疑人。张大鹏其实当时感到了一些疑惑，不明白为什么仅仅三个特征的匹配就可以破案。公安机关解释说，以大庆市的人口基数，三个特征的匹配足以锁定罪犯。这件事让张大鹏备受鼓舞。</p><p></p><p>随后，他多次去北京参加公安部牵头的三校联席（清华大学、北京大学、哈尔滨工业大学）指纹识别工作会议，与清华大学边肇祺、北京大学石青云等高校科研人员一起讨论指纹识别系统在全国的研发和应用。</p><p></p><p>1983 年，张大鹏硕士毕业，继续在哈工大攻读博士学位，导师是中国计算机科学与工程奠基人之一的陈光熙教授，副导师是李仲荣教授。</p><p></p><p>张大鹏的博士研究方向是遥感卫星数据的实时处理，这项研究起源于中国航天科技集团公司某机构的一个项目。卫星在围绕地球旋转的时候会不断采集地面图像数据，卫星每绕一圈采集的数据量都很大，所以就需要有高速的数据处理算法来实时处理这些信息。</p><p></p><p>1984 年，第七届国际模式识别会议 (International Conference on Pattern Recognition, ICPR) 在加拿大蒙特利尔召开，张大鹏的两篇论文《A Fingerprint Recognition System with Micro-Computer》和《To Detect the Defects in Welding Seam the Pattern Recognition》被会议录用。</p><p></p><p>就在这一年，哈尔滨工业大学焊接专业吴林教授找到张大鹏所在的研究组，吴林教授在日本看到了利用计算机视觉技术自动检测焊接质量的技术，他希望和计算机系合作开发这样的技术。这个任务被分配给了张大鹏，他们合作的论文《微型机焊接缺欠自动检测系统的研究》发表在学术期刊《信息与控制》上，这是在中国知网中可以查到张大鹏最早发表的中文论文。</p><p></p><p>1985 年，张大鹏跟随中国宇航代表团赴瑞典参加国际宇航大会（International Astronautical Congress，IAC）。他在会议上介绍了他遥感卫星图像处理的研究工作。</p><p></p><p>1986 年，张大鹏硕士阶段的研究《指纹识别系统》获得了国防科学技术工业委员会科技进步三等奖。</p><p></p><p>同年，他博士阶段的研究《卫星实时遥感图像识别》获得航空航天工业部科技进步一等奖。</p><p></p><p>也是在这一年，张大鹏博士毕业。那个年代的博士毕业答辩很受重视，他的博士论文送审收到了 50 多位国内顶级专家 / 学者的评审意见。</p><p></p><p>张大鹏的毕业答辩在北京举行，答辩委员会专家云集，答辩委员会的主任由中国科学院学部委员（院士）、清华大学教授常迵担任。由于研究成果突出，答辩顺利通过。</p><p></p><p>因为张大鹏读博的工作涉及到指纹识别和遥感卫星的图像处理等相关方向，所以他是中国和哈工大培养的第一位人工智能研究方向的博士。</p><p></p><p></p><h3>中国首批博士后研究员</h3><p></p><p></p><p>当时，张大鹏博士毕业后有三个选择。一是留校，时任哈工大校长的杨士勤教授亲自与张大鹏谈话，希望他能留在学校，并且可以直接给他副教授的职称。</p><p></p><p>第二个选择是去公安部工作，公安部特别重视张大鹏之前关于指纹识别的研究。公安部科技司司长专门找到哈工大，希望张大鹏可以服从组织分配到公安部工作，报效国家。</p><p></p><p>第三个选择是去清华大学，1983 年至 1984 年，诺贝尔奖获得者、华裔物理学家李政道先生两次致信邓小平，建议中国实行博士后制度。1985 年，国务院正式批准设立博士后工作站。</p><p></p><p>在北京博士答辩时，常迵院士告诉张大鹏他正准备招收第一批博士后，并希望张大鹏去清华大学做博士后。</p><p></p><p>虽然对母校很留恋，但是张大鹏还是希望能够继续深造，他选择了去清华大学自动化系做常迵院士的第一个博士后，也是新中国首批博士后。</p><p></p><p>在清华常院士的教研组，张大鹏博士主要跟着边肇祺教授继续指纹识别方面的研究，同时还在公安部刑侦二所兼职做一些咨询工作，协助公安部在生物识别方面的刑侦研究。</p><p></p><p>在常院士和边教授的指导下，他还在博士后期间写完了他的第一本编著《并行图像处理与模式识别的计算机系统设计》。</p><p></p><p>1988 年 4 月，张大鹏完成了清华大学的博士后研究工作。</p><p></p><p></p><h3>从第二个博士后到第二个博士学位</h3><p></p><p></p><p>张大鹏博士后出站时本来有机会留在清华大学，不过，常迵院士鼓励他出国继续深造，到更好的科研环境中学习。如果留在清华，出国的机会就需要排队等待，这在当时并不是容易的事情。</p><p></p><p>当时，常迵教授也是中国科学院自动化研究所的学术委员会主席。常教授建议张大鹏入职自动化所，这样能快一些出国深造。</p><p></p><p>就这样，1988 年，张大鹏博士后出站后被聘为中科院自动化所的副研究员。</p><p></p><p>当时，国家 863 计划刚刚起步，常迵院士让张大鹏参与了 863 项目的一些前期筹备工作。常院士认为，硬件技术的发展对于国家信息技术整体的发展至关重要。他希望张大鹏能够出国从事大规模集成电路方向（VLSI）的相关研究，这是国家最需要的技术。在中科院自动化所工作 5 个月后，1988 年 10 月，张大鹏开始前往加拿大温莎大学继续进行博士后研究，研究方向为大规模集成电路。</p><p></p><p>两年后，他的两篇学术论文在国际顶级期刊《IEEE Transaction on Circuts and Systems》和《IEEE Journal of Solid-State Circuts》上发表。</p><p></p><p>经过三年的研究工作，张大鹏发现博士后的身份让他很难真正接触到研究组的核心技术。于是，张大鹏决定在加拿大滑铁卢大学攻读他的第二个博士学位，导师为穆罕默德·艾尔马斯里 (Mohamed Elmasry) 教授，研究方向为 VLSI 芯片设计。</p><p></p><p>第二次攻读博士期间，他在相关学术期刊上陆续发表了 9 篇学术论文，并亲手设计及研发了乘法以及神经元等芯片。</p><p></p><p>1994 年，张大鹏在加拿大滑铁卢大学第二次博士毕业。他攻读了一个哈工大的人工智能博士学位和一个加拿大滑铁卢大学的芯片博士学位，这在现在看来也是相当不容易的事情，然而张大鹏在 30 年前就已经做到了。</p><p></p><p></p><h3>回到香港，开启掌纹识别研究</h3><p></p><p></p><p>在滑铁卢大学博士毕业后，张大鹏留校担任了一年的助理教授。但是张大鹏的初心还是回国发展。恰好在这个时候，香港的高校开始招人，香港科技大学、香港城市大学和香港理工大学对他都很感兴趣，但香港城市大学最先给张大鹏教授发了聘任 Offer。于是，1995 年 7 月 21 日，张大鹏优先选择入职香港城市大学担任副教授。</p><p></p><p>这一年开始，他与国内很多大学建立了密切合作。首先，他回到母校哈工大访问，受到了杨士勤校长和各学院院长的热烈欢迎。他也被母校哈尔滨工业大学聘任为兼职博士生导师。</p><p></p><p>一开始回到香港，由于当时国内还没有芯片相关的研发需求，张大鹏教授还是从事指纹识别方面的研究。一次在香港维多利亚港散步，他看到路边有看手相的算命先生，于是萌生了进行掌纹识别研究的想法。张大鹏教授认为，掌纹的特征足够复杂，这是可以作为防伪手段的保证。另外，掌纹的面积足够大，即使有一部分因为油渍、破损等原因无法识别，也不会影响整体识别效果。尤其是国内外最当时还没有相关研究，这是一个高精度、高防伪识别能力的新方向。</p><p></p><p>1997 年，张大鹏的团队正式开始掌纹识别的研究工作。1998 年，张大鹏团队发表了关于掌纹识别的第一篇论文《Palmprint Verification: An Implementation of Biometric Technology》在 ICPR 上发表。这也是国际上最早进行掌纹识别的研究团队。</p><p></p><p>从 1998 年至今，张大鹏教授的团队多年来发表掌纹识别相关论文 200 余篇，公开了多个掌纹数据集，同时也研发了包括 2D、3D、多光谱、接触式以及非接触式的多种掌纹识别系统并将其投入应用。</p><p></p><p></p><h3>四诊量化，人工智能与传统中医的结合</h3><p></p><p></p><p>1997 年，一个偶然的机会张大鹏教授认识了哈尔滨市第 211 医院普通外科主任李乃民医生，李医生是中西医结合的专家。两个人聊起中医中脉象、舌象等传统疾病诊断方法，张大鹏教授觉得这些传统中医中的“望闻问切”特征应该也可以用计算机量化。这次相遇是引发他之后中医四诊量化研究的契机。</p><p></p><p>张大鹏教授跟我讲解了四诊量化研究的具体方向和重要性。在传统的中医诊断当中，观察体表信息只能靠人的经验，这些体表信息包括人的舌象、脉象、气味、语音和步态等。中医四诊量化，就是要获取这些体表信息数据，再把这些体表信息转换成计算机可以存储、分析的标准数据。</p><p></p><p>体表信息存储的下一步是特征的标准化，曾经有一个经验丰富的中医跟张大鹏说，他肉眼看到的舌象与手机拍摄到的舌象看起来就是不一样的，这是由于光线、观察角度等因素导致的不一致。四诊量化工作就是要把这些体表数据标准化，使同一个设备在不同条件下采集的体表数据相同，这样同一设备在不同地点、条件下采集的数据就是兼容和通用的。最后将信息提供给中医师，作为他们诊断、治疗过程中的参考。</p><p></p><p>体表信息标准化的工作完成后，张大鹏教授的团队还实现了疾病的量化。他们采集大量患者的疾病数据和体表信息数据，尝试训练算法找出西医框架下的疾病（比如高血压、糖尿病等）与中医框架下体表信息（比如舌象、脉象等）的关联。并把这种关联提供给中医师进行参考。</p><p></p><p>张大鹏教授告诉我，他们团队将中医中经典的“望闻问切”映射成人体的四种感知信息，分别是：视觉感知、嗅觉感知、听觉感知、触觉感知。</p><p></p><p>2002 年，张大鹏教授关于舌象研究的第一篇论文《On Automated Tongue lmage Segmentation in Chinese Medicine》在 ICPR 会议上发表。</p><p></p><p>2006 年，张大鹏教授关于舌象研究的第一本专著《Tongue Diagnostics》（舌象诊断）在 Academy Press（美国学术出版社）出版。</p><p></p><p>这些年他们的研究过程就是采集患者数据、算法训练、分析结果和发表论文，然后再重新循环这些步骤，一步一个脚印地深入中医四诊量化的研究。拿舌象数据来说，他们的舌象信息获取分析设备已经研发到了第七代。</p><p></p><p>多年来，他的团队跟哈尔滨市 211 医院、北京武警医院、广东省中医院、北京大学深圳医院、深圳市龙岗区医院、深圳市精神卫生中心（深圳市康宁医院）以及深圳市中医院等医疗机构密切合作。其中，他们与广东省中医院杨志敏院长合作的研究获得了国家自然科学基金重点项目的资助。</p><p></p><p>他们团队已经发表了 100 余篇中医四诊量化方面的论文，不但对器质性疾病（比如高血压、糖尿病等）进行量化，还对一些功能性疾病（比如抑郁症等）进行了四诊分析。</p><p></p><p>张大鹏教授的团队还建立了世界上最大的中医感知数据库，数据库涵盖了几万名患者的体表信息，对于每个患者，数据库采集了视觉、嗅觉、听觉、触觉以及步态等 7 种模态的信息。</p><p></p><p></p><h3>建立人脸美学体系，探索美的客观化本质</h3><p></p><p></p><p>有一年，“香港小姐”选美结果揭晓，大众一片哗然，对于选美结果有很大的质疑。这时候组委会找到张大鹏，希望找到一种算法可以对候选人是否美丽进行初筛。</p><p></p><p>张大鹏教授告诉我，虽然每个人的审美观不一样，美的判断是主观的，但是有些美应该是大家公认的，比如三庭五眼、黄金规则这样的标准就长期广泛被大众接受。</p><p></p><p>张大鹏当时在调研中发现，其实美学相关的生物特征研究还很少，以色列有些学者在心理学领域进行美学探讨，也没能给出相应的量化标准。所以他决定尝试建立完善的人脸美学客观化分析体系。</p><p></p><p>2011 年，张大鹏教授人脸美学体系研究的第一篇论文《Quantitative analysis of human facial beauty using geometric features》在顶级国际期刊《Pattern Recognition》发表。</p><p></p><p>2016 年，张大鹏教授人脸美学体系研究的第一本专著《Computer Models for Facial Beauty Analysis》（人脸美学分析的计算机模型）在 Springer（施普林格出版社）出版</p><p></p><p>香港执教二十三年，</p><p></p><p>科研之路成绩斐然</p><p></p><p>1995 年 7 月从加拿大回到香港起，张大鹏教授一共在香港城市大学工作了三年。1998 年，张大鹏教授觉得香港城市大学的研究氛围更偏重底层理论，而香港理工大学相对更加重视应用研究，更适合自己的工科背景，于是便决定加入香港理工大学计算机系。从这时起，他在香港理工大学整整工作了二十年。</p><p></p><p>1998 年，张大鹏在香港理工大学创立国际上第一个生物识别研究中心。</p><p></p><p>1999 年，张大鹏晋升香港理工大学教授。</p><p></p><p>2001 年，张大鹏教授创立计算机视觉领域国际顶级期刊《国际图像和图形学报》（International Journal of Image and Graphics，IJIG）</p><p></p><p>2002 年，张大鹏教授创建 Springer 国际生物识别丛书（International Series on Biometrics，KISB）的创始人并担任主编。</p><p></p><p>2004 年，张大鹏获得香港特别行政区最高科技奖“裘槎科技工作者”。</p><p></p><p>2005 年，张大鹏担任香港理工大学讲座教授。</p><p></p><p>2014 年开始，张大鹏教授连续八年被 Clarivate Analytics(前身为汤森路透) 列为“高被引科学家”。</p><p></p><p>三十多年的时间，张大鹏为中国生物特征识别和模式识别领域培养了70余名博士、20余名硕士，他们中许多人已经成为了很优秀的学者。他们在各自的研究领域里发挥了重要作用。</p><p></p><p>2018 年，张大鹏教授从香港理工大学正式退休并继续担任荣誉教授。随后，张大鹏教授回到内地，担任香港中文大学（深圳）数据科学学院校长讲座教授。</p><p></p><p>2020 年，张大鹏教授当选加拿大科学院院士。</p><p></p><p>2021 年，张大鹏教授当选加拿大工程院院士。</p><p></p><p>同年，张大鹏教授开始担任香港中文大学（深圳）数据科学学院校长学勤讲座教授。</p><p></p><p>2022-2024 年，张大鹏连续三年获得 Research.com 评选的计算机领域 Leader Award。</p><p></p><p>现在，75 岁的张大鹏依然在香港中文大学以全职身份承担教学和科研工作，而且工作节奏非常忙碌。这次访谈我们约了好久才终于成行，采访进行的特别顺利，以至于有几个问题我还没有问，他就已经说出了答案。我丝毫感觉不出他的真实年龄，而只能感受到他对科学工作的热情，以及他对几十年研究工作积累成果的自豪和欣慰。</p><p></p><p>2015 年，中国中医科学院屠呦呦研究员获得诺贝尔生理奖，使中国的传统中医药更加被世界认可。</p><p></p><p>同样，近四十年的时间，从东半球的中国到西半球的加拿大。从中国的最北端哈尔滨到几乎是最南端的香港和深圳。张大鹏教授一直持之以恒地深耕自己的研究方向。从指纹、掌纹识别的身份鉴定工作到中医四诊量化的研究，作为中国第一位人工智能方向毕业的博士，张大鹏教授和他的团队将最先进的计算机技术和人工智能技术融入中国的传统医学，为中医的标准化和量化工作做出了重要贡献，也使中国传统医学可以走向国际，更广泛地被世界认可。</p><p></p><p>作者简介</p><p></p><p>秦海龙，香港科技大学社会科学部博士后研究员，中国中文信息学会社会媒体处理专业委会委员。主要研究方向为中国人工智能发展史和计算社会学。博士毕业于哈尔滨工业大学社会计算与信息检索研究中心，前自然语言处理研发工程师，曾就职于小米科技和三角兽科技。</p><p></p><p></p><p></p>",
    "publish_time": "2024-09-11 16:58:59",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "三个月建成“世界最大”Nvidia GPU 计算集群，马斯克：不够，还要再加10万个",
    "url": "https://www.infoq.cn/article/NmjtW9BeY7HaN8dHLPRM",
    "summary": "<p></p><p>9 月 2 日，马斯克发文称，其人工智能公司 xAI 的团队已经上线了一台被称为“Colossus”的训练集群，总共有 100000 个英伟达的 H100 GPU。</p><p></p><p>马斯克表示，他的团队花了 122 天才完成 Colossus 的上线过程。由于 xAI 在 6 月份才选定孟菲斯作为其所在地，因此 Colossus 的部署速度可以说是非常快的。马斯克表示，在接下来的几个月里，Colossus 的规模将扩大一倍，达到 200,000 个 GPU，其中 5 万个是更为先进的 H200。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/80/80cb4f3f8d3908a1bc357eb469b0136f.png\" /></p><p></p><p>一位 X 用户指出，这一发展的实际规模超过了迄今为止发布的每个主要模型。相比之下，OpenAI 最强大的模型才使用了 80000 个 GPU。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f7/f7799c1c99756c92a9c17ab67426f7f3.png\" /></p><p></p><p>Nvidia 的 H200 是市场上最抢手的芯片之一，尽管最近被该公司于 2024 年 3 月推出的最新 Blackwell 芯片超越。相比之下，H200 配备 141 GB 的 HBM3E 内存和 4.8 TB/s 的带宽，Blackwell 的最高容量比 H200 高出 36.2%，总带宽高出 66.7%。</p><p></p><p>Nvidia 在 Colossus 发布后向马斯克和 xAI 团队表示祝贺。它还强调，Colossus 将是性能最强大的产品，并且在能源效率方面将有“显著提升”。</p><p></p><p>风险投资公司 ARK Invest 的首席执行官 Cathie Wood 也对该团队取得的成就表示祝贺，称其“令人印象深刻”，并表示“未来还会有重大公告”。</p><p></p><p>2023 年 4 月，有广泛报道称马斯克正在购买大量 GPU，一些消息来源报道称他打算购买多达近 10,000 个 GPU，以推进他的 xAI 项目。</p><p></p><p>在当前的人工智能淘金热中，包括微软、谷歌、亚马逊在内的多家重量级科技公司正与马斯克一道竞相采购英伟达备受青睐的 Hopper 系列人工智能芯片。马斯克也是英伟达的重要客户，其承诺今年仅用于特斯拉的英伟达硬件就要投资 30 至 40 亿美元。</p><p></p><p>孟菲斯集群将主要用来训练马斯克的 Grok-3。他在 7 月份表示，“我们希望在 12 月之前发布 Grok-3，到那时 Grok-3 应该会成为世界上最强大的人工智能。”Grok-2 的早期测试版上个月刚刚向用户推出 。</p><p></p>",
    "publish_time": "2024-09-11 17:03:16",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "微软如何完成AI转型？微软中国CTO韦青亲述：我们需要的不是一个无所不知的模型",
    "url": "https://www.infoq.cn/article/68NmXXFxrZObFEvICIKd",
    "summary": "<p></p><p></p><blockquote>出品｜InfoQ 《大模型领航者》访谈主持｜霍太稳，极客邦科技创始人兼 CEO访谈嘉宾｜韦青，微软中国首席技术官作者｜褚杏娟</blockquote><p></p><p></p><p>“Satya 刚上任 CEO 时，就跟微软的员工说，‘在技术行业没有人尊重传统，只尊重创新。”微软中国首席技术官韦青说道。</p><p></p><p>船大难掉头，同样对于有着近 50 年历史、20 多万员工的微软来说，创新并不容易。但是，微软这次却无疑走在了全球 AIGC 转型之路的最前沿。</p><p></p><p>微软早早就将 GPT 系列模型全面集成到了自家的产品体系中：Github Copilot、Office 及 PC 端等，在 OpenAI 的几次重大发布对部分企业造成打击时，微软只需要专心搞应用。微软确实也取得了漂亮的财报表现，比如 GitHub 年收入已达 20 亿美元，其中 Copilot 占收入增长的 40 % 以上，这已经比当初收购整个 GitHub 的规模还要大。</p><p></p><p>正如韦青所说，“大家看到的只是冰山一角，实际上，背后是积攒了可能几十年带来的成果。”</p><p></p><p>OpenAI 与微软的合作可以追溯到 2016 年。2021 年 Build 大会上，Satya 表示将“世界上最强大的语言模型”GPT-3 引入到了 Power Platform 上。2022 年的 Build 大会上，Satya 直接提到了 OpenAI 的名字，并把 GPT、DALL-E、Codex 纳入微软 Models as Platforms 服务的一部分。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/46/464ce111342da1e8eb69963207a7ee35.jpeg\" /></p><p></p><p>Satya Nadella 2021 年、2022 年（从左到右）Build 大会的 keynote 演讲</p><p></p><p>但两者的合作只是微软 AIGC 转型的其中一面，对于普通开发者来说，更宝贵的应该是微软亲身实践的心得。在这次访谈里，韦青向我们介绍了一个更加务实、创新的微软。</p><p></p><p></p><h3>为什么是微软</h3><p></p><p></p><p></p><blockquote>“我们不再只是讨论大模型、算力和存储这些了，已经不是那个阶段了。”</blockquote><p></p><p></p><p>韦青加入微软至今已经 20 多年的时间，先后负责了移动产品、Windows 产品等。见证了互联网这么多年的变迁，他对这次 AIGC 转型的感想是：人的思想转型是最难的。</p><p></p><p>就拿微软的研发工程师来说，他们对 AIGC 的认识也是随着自己对各种应用的不断深入而持续刷新的。</p><p></p><p>具体地，比如微软 Fabric 工程师最开始的想法是“AI for Data”，可以理解为“AI +”，即将 AI 放入现有产品体系来改进数据处理。基于此，他们推出了第一版产品并获得了很大的成功。</p><p></p><p>但在开发第二版产品时，工程师们便意识到不能再继续沿用同样的方法。第二版产品的核心理念是“Data for AI”，对应地，可以理解为“AI*”。乘法与加法的思维方式有着本质的不同，乘法意味着内化，而不仅仅是增加，也就是说不仅仅要将 AI 应用到现有流程中，而是要为了新工具将现有流程进行重构。</p><p></p><p>虽然冲在了大模型应用的前头，但微软内部并没有神化大模型。Microsoft Azure 首席技术官 Mark Russinovich 评论大模型是“junior employee”，即学了很多知识、主观能动性很强、记忆力也超强，但是一个非常幼稚的员工。</p><p></p><p>要让这个员工知道怎么帮你干活，就需要“your data”来训练，否则它不知道你的喜好、边界。而用户能够使用的大模型就是用自己数据调整过的“小模型”。</p><p></p><p>微软的另一层考虑是，大模型的应用不应该被限制。“不存在只有谁能用谁不能用、大型机可以用边缘不能用等情况，函数调用要因人、因事、因地制宜。”因此，当概率模型不能起作用时候，工具就要通过调用软件、功能、函数等发挥作用。这也是为什么微软大力研发小模型的原因之一。</p><p></p><p>“当你不能用大模型或断网的时候，Phi 就是本地解决方式。Phi-3 作为一个边缘模型，在基座模型和 tool chain 之间，起到了非常重要的承前启后作用。”韦青说道。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e7/e7cd8d6178c5d64acb0444852b806902.png\" /></p><p></p><p>韦青习惯于用系统工程方式考虑问题，有前提条件约束地思考，看到“水桶的短板”。他否认所谓要么是大模型时代、要么就是小模型时代等各种绝对的说法。“模型并不是越大就越好。大模型之所以大，是因为它们有更多的人造神经元，能够记住更多的知识，但这也会带来所谓的‘知识的诅咒’。”</p><p></p><p>在他看来，人们需要的不是一个无所不知的模型，而是一个能够理解自己喜好，并提供个性化建议的模型，这样的模型能够告诉我们“下周应该做什么”就足够了。当人们偶尔会对某个特定话题感兴趣时，则可以利用大模型来获取信息。</p><p></p><p>因此，人们身边的小模型除了能够调度本地应用，还要在必要时能够调用云端大模型，云端某个大模型可能擅长回答人文问题，而另一个擅长回答科学问题，可以通过分工合作提供更加精准和个性化的服务。</p><p></p><p>“这才是未来大家想要的，而微软 Azure 架构就是在为这种方式做准备，即将所有模型集中在一起构成一个庞大的系统。”韦青介绍道。</p><p></p><p>要利用好各种工具，算力、存储和网络通信都是必要的。如果网络通信存在延迟，就需要中央模型和边缘模型结合，边缘模型需要相应的数据支持，而有了数据就可以开发出自己的 Copilot。</p><p></p><p>以 Azure 为支点，微软构建了从基础设施、数据、工具到应用程序的完整技术堆栈来支持 AI 用户。与此同时，微软还加大了投入，将大约一半资本支出用于建设和租赁数据中心，剩下的部分主要用于购买服务器，但其投入速度依然跟不上市场需求。</p><p></p><p>微软全球向世界各地用户提供了“AI 全家桶”，但这应该算是云厂商的基本操作。微软现在已经进入下一阶段：向计算要效率，比如在提供针对大模型的计算能力时，微软甚至会对生成 token 的计算方式进行优化。</p><p></p><p>“我们现在做的是最大化人工智能的计算效率。”韦青说道，“不仅仅是计算，所有针对 AI 特点的数据流动，包括 prompt、KVQ 等，还涉及不同精度的计算，比如浮点数、16 位整数、8 位整数或 4 位整数等，都是优化目标。”</p><p></p><p>如何最大化算力的利用效率，并以最节能的方式进行计算，关键在于找到最有效的计算方法，以及如何以最小的实验成本生成所需的结果。“这并不意味着精度越高越好，而是要找到最适合当前任务的精度水平。”韦青提醒道。</p><p></p><p></p><h4>超强工具的另一面</h4><p></p><p></p><p>“一阴一阳谓之道”，任何事物都包含着对立统一的规律。</p><p></p><p>某个特别强大的工具开始被普遍使用时，了解它的负面影响是必要的，这就是负责任的 AI（Responsible AI）的核心理念，因为太强的话一定有弱点，比如公平性、透明性和可追溯性。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c2/c2841a448e98fabc364c2b3f673a3938.png\" /></p><p></p><p>“世界上没有 100% 完美的事物，我们生活的是一个充满概率的世界。”在韦青看来，如果出了事故，责任在于人而非工具，人们要做的就是在充满概率性的波动中找到确定性。</p><p></p><p>“即使是现在，起码我认识的许多工程师在开发那些很厉害的工具时，他们都会秉持一个最基本的、第一性认知原则，即在开发一个特别强大的工具时，我必须知道它的弱点。”韦青补充道，“同样地，当听到有人说某事物非常糟糕时，我们也应该看到它积极的一面。只有看到了一个所谓不好事物的积极面，才能更有信心地作出评价。”</p><p></p><p>微软在 2019 年之前意识到这些工具变得越来越强大时，率先成立了 Responsible AI 团队。“有些公司可能会认为这是在浪费钱，但实际上，公司是社会的一部分。当公司开发出一款强大的工具时，如果不能确保其被负责任地使用，就可能遭到反噬。”韦青说道。</p><p></p><h3>大模型应用启示</h3><p></p><p></p><p></p><blockquote>“现在早已经过了还在分析、还在想、还在空谈的时候了，全世界大量的企业和个人都已经进入了实用态。”</blockquote><p></p><p></p><p>“模型不是你的产品，模型是你产品的一部分（model is not your product，model is part of your product）”Satya 在 2022 年 Build 大会上说道，这其实就蕴含了微软对大模型应用的理解。</p><p></p><p>韦青把大模型比作公有发电厂，它的任务就是发电。但只是发电的话，并不足以让大模型应用普及。</p><p></p><p>“人们并不能直接使用电子，电子需要被整合到电器中才能被使用。同理，这些 token 被整合到各种应用中，尤其是边缘计算领域，如 AIPC 等，大模型应用才会变得流行起来。”韦青解释道。这其实意味着，大模型要普及就得变成一种本地能力为个人使用。</p><p></p><p>如今，一些模型厂商开始卷入 token 的价格竞争。在韦青看来，大模型价格高低的问题就像问木材这种原材料的价格是贵还是便宜。木材可以按重量出售，但加工后的产品很难用同样的方式定价，木制工艺品、木家具等价格都不一样。</p><p></p><p>因此，价格竞争虽然有一定的意义，但问题在于大模型这种“电”还是没有直接产生价值。“当前的生成视频、图片和进行问答只是初级阶段，绝不是这些技术的最终目标。”韦青说道。</p><p></p><p>而要实现从 token 到应用的质变，意味着要做流程重构。</p><p></p><p>依然以电力应用为例，百年前的电烤面包机和电动洗衣机插头实际上是灯座，因为当时的人们没有意识到除了电灯之外，电力还可以做更多的应用，因此设计之初没有留有足够的插座，如果要将插座安装在墙内就需要修改设计图。</p><p></p><p>同样，大模型应用的普及也需要“修改设计图”，这对企业来说就意味着对现有流程进行重构。</p><p></p><p>但是，如果把各种流程拆开来看，这与 AI 既有关系，又没关系。</p><p></p><p>梳理现有流程、重构流程，确保每个节点都能进行数字化数据采集，这是第一步。这个阶段确保了企业能够不断产生数据来表征流程模型。</p><p></p><p>那么，接下来的问题就是：大多数公司都拥有大量数据，这些数据能否都被用来学习并提取知识？</p><p></p><p>数据要包含信息才有意义，而信息如果没被有效利用就没有价值，之后通过各种比对和分析，信息才会产生洞察力，进而形成知识。但事实上，大部分数据在收集时并不是为了机器学习，因此许多公司虽然拥有大量数据，但当要求 CTO、CIO 建立一个模型时却不知所措。</p><p></p><p>韦青对此给出的解答是，“他们需要重新考虑从数据到信息的转化过程，这取决于企业的目标是仅仅实现数字化和信息化，还是真正建立机器知识？而机器知识又是为了什么服务？”他解释称，对于数据、信息、知识和智慧的服务，如果要清晰地应用这一轮的 AI 模型，就需要有明确的目标，否则就会失去方向。</p><p></p><p>韦青提醒道，上述工作完成后，最重要的是通过 RLHF 给这些学习内容赋予人类的期望，在此基础上进行不断优化和微调。“使用这些模型后，人们会意识到，将数据转化为信息，再通过机器学习形成知识，是为了解决人类不想做、不能做、不爱做或做不好的事情。这些事情大多是重复性的，要求精确但不一定需要创意。”</p><p></p><p>此外，韦青从工程师角度提醒一个企业大模型纳入应用的前提。</p><p></p><p>首先，要对问题进行类似几何原理的定义和论证，然后将一个特别泛泛的问题拆分为若干个小问题。比如出版业是指受众获取、经营、内容制作，还是未来的发展方向？这些都是不同的问题，需要分别拆解和定义。</p><p></p><p>其次，要有公设。比如出版社是在中国、欧洲还是美国，数字出版还是纸质出版等。然后，要有公理、论证。只要结果，而不考虑前提的定义、公设和工程约束，是非常危险的。有了上述前提，我们然后才能进行推断，而这种推断遵循 DIKW 金字塔的结构。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/27/27a4bef87bf9fb4e29f23d1191fa9cd2.png\" /></p><p></p><p>上述步骤跟 AI 其实没关系，但只有上面的这些基础工作完成后，讨论 AI 在某个行业中的作用才有意义。</p><p></p><h3>对 AI 认知的极限，关键在人</h3><p></p><p></p><p></p><blockquote>“拥有了上面所有要素后，我们会意识到，技术是一方面，更重要的是人的问题。”</blockquote><p></p><p></p><p>大模型的快速发展，让人无比期待 OpenAI 能赶紧发布更先进的模型 GPT-5。韦青并没有给出大家想要的爆料，相反，他发出了自己的疑问：难道因为 5 比 4 大，就意味着 5 一定比 4 好吗？</p><p></p><p>“这实际上是一个没有意义的问题（大的不一定是好的）。关键在于社会民众对机器智能能力的需求达到了什么程度，届时一定会出现与这个需求相匹配的服务。”这是韦青的答案。</p><p></p><p>他结合自己的经验说道，“如果你真的在一个产品团队中工作，尤其是在那些全球顶级的产品团队，只要参与过产品开发你就会明白一个事实：没有人能确切地知道下一步会发生什么。”</p><p></p><p>韦青认为，对于我们所有人来说，接下来真正的挑战不仅仅是技术，真正限制在于我们的意识。他用了一句很哲学的话来总结：我们越接近真相的核心，就会发现我们离真相越远。</p><p></p><p>他举了两个例子。比如，2017 年人工智能战胜围棋选手，严重打击了顶尖选手：机器告诉我们，人类下了 2,000 年围棋，但连围棋的皮毛都没摸着。又比如，我们以为自己最远只能骑自行车到北京香山登上其最高峰香炉峰（又称鬼见愁），然后就认为自己登上了世界最高峰鬼见愁，但其实同时代已经有人用更先进的工具到了真正的最高峰珠穆朗玛峰。</p><p></p><p>“不能因为你到不了就认为不存在、认为人类无法达到。我们的寿命和思想经历是有限的。”韦青说道。</p><p></p><p>当前我们被限制的一个表现是：在产品开发中，人们又把自己当作机器来对待。</p><p></p><p>“很多时候，我们根本没有意识到我们不知道，结果机器刚刚把我们带到一个认知的边界，很多人就绝望了，认为机器将完全超越我们。我觉得不是这样。我们才到‘鬼见愁’，就争论机器要不要代替人类、人类有没有未来，这反映了人们已经被局限了。我们没有意识到，我们不应该将人视为机器。人天生不需要做机器做的事。”</p><p></p><p>在韦青看来，人类最大的特点在于擅长制定规则和“破坏”规则（这里的“破坏”是指创新和优化规则），而机器恰恰特别擅长于理解和严格执行规则。按照这个逻辑，人类本来就应该负责发号施令，让机器去做那些重复性和规则性强的工作，并在机器完成后不断改进，来保持人类的创新优势。</p><p></p><p>韦青眼中的人工智能边界是“极大、极小，极远、极近”的。极大就是宇宙，比如 AI for Science，只是生成图片和视频是不够，它会在生产力和科学上有巨大突破；极小是量子，比如把材料、药物分子等重新组合，带来更好的效果。极远是太空旅行，极近就是认识自己。</p><p></p><p></p><h4>给程序员的一些建议</h4><p></p><p></p><p>如今，韦青依然坚持自己动手去写代码，虽然无法编写大型软件，但仍然要保持手感。当我们把目光放到更细分的程序员群体，coding 出身的韦青也给出了自己判断和建议。</p><p></p><p>作为几十年的软件开发者，韦青经历了纯手工撸代码的时代，现在也开始尝试代码生成工具。</p><p></p><p>多年前，他想要自己手搓一个基础的多层神经元模型，以便深入了解更多神经元架构的细节，但因为工作繁忙而未能实现。几年后他便使用 Copilot 辅助编写，“没有进行任何优化，没有针对内存或数据位移做任何处理，只是用 C 语言直接实现了”：</p><p></p><p></p><blockquote>我们首先共同定义了数据结构，然后列出了 CNN 所需的所有函数定义，包括 ReLU、Sigmoid 等激活函数，以及矩阵乘法等。我们还列出了这些函数的导数和偏导数，然后一起实现。实现完成后，我们构建了一个测试用例，并运行了这个用例。整个过程大约花费了一个小时，写了大约 2000 行代码，而且每个函数都是正确的。虽然还需要进行一些调整，但效率非常高。</blockquote><p></p><p></p><p>“如果我们的程序员也能够这样工作，那该有多好。”韦青感叹道，“但是，如果程序员不了解网络结构的底层知识，仅仅依赖于 Tensorflow 或 PyTorch 等工具，那么也是无法有效完成任务的。”</p><p></p><p>要达到这样的水平，需要开发者对数学，特别是机器学习领域的知识有深入的了解。</p><p></p><p>韦青认为，未来的趋势就是，程序员要在两端都非常强大：既要有扎实的底层知识，也要对行业需求有清晰的认识。虽然中间的实现部分也很重要，但最关键的是要保持对基础数学建模能力和行业需求的深刻理解。</p><p></p><p>这意味着，对程序员来说，只擅长写代码已经不够了。</p><p></p><p>韦青回忆起多年前了解到的一家日本软件公司，高级软件工程师只写伪代码，其完成逻辑描述后，让所谓的“码农”去写将 UML（统一建模语言）。无论客户要求使用 C 语言、Java 还是 C#，“码农”都能根据伪代码转换成相应的代码，但他们并不能真正理解行业。</p><p></p><p>编写伪代码的人是那些既了解行业知识，又懂得基本逻辑描述的人，而真正编写 C、Python 等代码的工作其实可以交给机器完成。韦青说道，“我们应该从码农升级为程序员，程序员的水准是达到架构师的水平，即具备行业知识，并能够用逻辑方式表征这些知识。”</p><p></p><p></p><h3>结束语</h3><p></p><p></p><p>Satya 不建议微软称自己为 leader（领先者），而是用 Incumbent（现任者）。现任者把人从创新者窘境中拉出来，等着后面 challenger（挑战者）来超越。韦青将其解读为“胜不骄、败不馁”。</p><p></p><p>而对于未来，韦青借用 Ilya Sutskever 的话来总结：尽量能够比这个时代超前半步，但也别超前太多。“因为现在所有对技术的不足都是马后炮，但超前多一点点看，大部分问题都很快会被解决。”这是一种更加务实的态度。</p><p></p><p>如今，这场 AIGC 竞赛还没有结束，微软能否继续坚守自己 Incumbent 的位置，我们拭目以待。</p><p></p><p></p><p></p>",
    "publish_time": "2024-09-11 17:13:03",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AI 推理竞赛正在升温",
    "url": "https://www.infoq.cn/article/OBY1si0QCkbxXbblcBxl",
    "summary": "<p></p><p>虽然英伟达的 GPU 在 AI 训练领域的主导地位仍然难以撼动，但似乎有迹象表明，在 AI 推理方面，竞争对手正在迎头赶上这家科技巨头，尤其是在能效方面。然而，英伟达新推出的 Blackwell 芯片的卓越性能可能很难被超越。</p><p></p><p>最近，ML Commons 发布了最新的 AI 推理竞赛 ML Perf Inference v4.1 的成绩单。这一轮竞赛包括使用 AMD Instinct 加速器的团队、最新的谷歌 Trillium 加速器、来自多伦多初创公司 UntetherAI 的芯片以及英伟达最新发布的 Blackwell 芯片的首次试水。另外两家公司，Cerebras 和 FuriosaAI，也发布了最新的推理芯片，虽然没有提交给 MLPerf 进行评测。</p><p></p><p>就像奥林匹克运动会一样，MLPerf 也有许多类别和子类别。提交数量最多的是“封闭数据中心”类别。封闭类别（相对于开放类别）要求提交者在不进行重大软件修改的情况下按照原样运行推理任务。数据中心类别评估的是批量处理查询的能力，而边缘类别则侧重于降低延迟。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/0b/0ba10c0ee80fb26fa124cd1ba643fe9b.png\" /></p><p></p><p>每个类别有 9 个不同的基准测试，针对不同类型的 AI 任务，包括一些流行的应用场景，如图像生成（例如 Midjourney）和 LLM 问答（例如 ChatGPT），以及同样关键但可能不那么引人注目的任务，比如图像分类、目标识别和推荐引擎。</p><p></p><p>本轮竞赛新增了一个叫作 Mixture of Experts 的基准测试。这是 LLM 部署方面的一个日益流行的趋势：一个语言模型被分解为几个较小的、独立的模型，每个子模型都针对特定任务进行微调，如常规对话、解决数学问题和协助编码。模型能够将每个查询定向到适当的子模型（或者叫“专家”模型）。这种方法使得每个查询使用更少的资源，从而降低成本并提升吞吐量。</p><p></p><p>在备受瞩目的封闭数据中心基准测试中，获胜者仍然是基于英伟达 H200 GPU 和 GH200 超级芯片（封装了 GPU 和 CPU）的参赛者。然而，如果深入分析性能数据，我们会发现情况远比表面看起来的复杂。一些参赛者部署了大量加速器芯片，而另一些则只使用了一片。如果我们将每个参赛者每秒处理的查询数量按使用的加速器数量进行标准化，并仅考虑每种加速器类型的最佳性能，一些有趣的细节便会浮出水面。（需要注意的是，这种分析方法并未考虑 CPU 和互连对性能的影响。）</p><p></p><p>以单个加速器为前提，英伟达的 Blackwell 芯片在其参与的唯一基准测试——LLM 问答任务中，性能比所有之前的芯片高出 2.5 倍。Untether AI 的 speedAI240 预览芯片在它参与的唯一任务——图像识别中，性能几乎与 H200 持平。谷歌的 Trillium 在图像生成任务上的性能大约是 H100 和 H200 的一半，而 AMD 的 Instinct 在 LLM 问答任务上的性能与 H100 大致相当。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/2c/2c575fb50d1697d88c8d9dd23f723fa4.png\" /></p><p></p><p></p><h3>强大的 Blackwell</h3><p></p><p></p><p>英伟达 Blackwell 芯片取得成功的一个关键因素是它能够使用 4 位浮点精度运行 LLM。英伟达及其竞争对手一直在努力减少用于表示数据的位数，以此来提升计算速度。英伟达在 H100 中引入了 8 位数，而此次参赛在基准测试中首次展示了其 4 位数的运算能力。</p><p></p><p>英伟达产品营销总监 Dave Salvator 指出，使用低精度数字位的最大挑战在于保持模型的准确性。为了满足 MLPerf 评测所需的高精度标准，英伟达团队不得不在软件层面进行重大创新，他补充道。</p><p></p><p>Blackwell 芯片成功的另一个关键因素是其内存带宽的显著提升，达到了每秒 8 兆字节，几乎是 H200 芯片每秒 4.8 兆字节带宽的两倍。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/09/09474cdb0a6a2266526f1abfc01e1ba3.png\" /></p><p></p><p>英伟达 GB2800 Grace Blackwell 超级芯片</p><p></p><p>Blackwell 芯片虽然在竞赛中仅使用了单个芯片，但 Salvator 指出，该芯片是为了实现联网和伸缩性而设计的，在与英伟达的 NVLink 互连技术配合使用时将发挥最大效能。Blackwell GPU 支持多达 18 个 NVLink 连接，每个连接的速率为每秒 100 千兆字节，总带宽达到每秒 1.8 兆字节，大约是 H100 互连带宽的两倍。</p><p></p><p>Salvator 认为，随着大型语言模型的不断扩展，推理任务也将需要多 GPU 平台来满足日益增长的需求，而 Blackwell 芯片正是为了应对这一趋势而设计。Salvator 强调，“Blackwell 不仅仅是一个芯片，它还是一个平台”。</p><p></p><p>英伟达基于 Blackwell 芯片的基础系统参与了 MLPerf 的预览子类别，这表明该芯片尚未对外销售，但预计将在未来六个月内，即下一次 MLPerf 评测发布之前上市。</p><p></p><p></p><h3>Untether AI 在功耗和边缘计算方面表现出色</h3><p></p><p></p><p>对于 MLPerf 的每一项基准测试，都有相应的能源效率测试，以系统性地评估各系统在执行任务时的功耗。封闭数据中心能源类别只有 Nvidia 和 Untether AI 两家提交了测试结果。Nvidia 参与了所有基准测试，但 Untether AI 只参与图像识别环节。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/be/be59f72444df009420fdb2997b239d92.png\" /></p><p></p><p>Untether AI 通过所谓的“内存内计算”实现了卓越的能效。Untether AI 的芯片设计为由内存元素构成的网格，每个小处理器紧邻其旁。处理器采用并行处理方式，与邻近内存单元格中的数据同步工作，显著减少了模型数据在内存与计算核心间传输所需的时间和资源。</p><p></p><p>Untether AI 产品副总裁 Robert Beachler 表示：“我们发现，在 AI 工作负载中，大约 90% 的能耗仅用于将数据从 DRAM 传输到缓存，再传输到处理单元。因此，我们采取了相反的策略……不是将数据移至计算单元，而是将计算单元移到数据所在的地方。”</p><p></p><p>这种创新方法在 MLPerf 的“封闭边缘”子类别中取得了显著成效。这个类别专注于更贴近实际的应用场景，如工厂内的机器检查、引导视觉机器人和自动驾驶汽车等——Beachler 指出，在这些应用中，低能耗和快速处理至关重要。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/53/53e93b1d2c945a21c46053fd2f321b27.png\" /></p><p></p><p>在图像识别任务中，Untether AI 仍然是唯一提供评测结果的公司，它的 speedAI240 预览芯片在延迟性能方面是 NVIDIA L40S 的 2.8 倍，吞吐量（每秒处理的样本数）提升了 1.6 倍。这家初创公司还提交了功耗数据，但因为 Nvidia 没有提供相应的数据，因此很难进行直接比较。不过，Untether AI 的 speedAI240 预览芯片每个芯片的标称功耗为 150 瓦，而 Nvidia 的 L40s 为 350 瓦，这意味着在延迟性能提升的同时，功耗名义上降低了 2.3 倍。</p><p></p><p></p><h3>Cerebras、Furiosa 没有参与MLPerf 竞赛，但发布了新的芯片</h3><p></p><p></p><p>Furiosa 的新芯片采用了一种独特且高效的手段来实现 AI 推理中的基本数学运算——矩阵乘法。</p><p></p><p>在近期斯坦福大学举办的 IEEE Hot Chips 大会上，Cerebras 公司推出了自己的推理服务。这家位于加州 Sunnyvale 的公司专注于制造大型芯片，利用尽可能大的硅片来避免芯片间的互连问题，并显著提升设备的内存带宽。这些设备主要用于训练大型神经网络。现在，Cerebras 已经升级了其软件栈，用于其最新的计算机 CS3 执行推理任务。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/33/33b7a1dcdf5b1be102aba01e1ab46431.png\" /></p><p></p><p>Furiosa 的新芯片以一种不同的、更有效的方式实现了 AI 推理最基本的矩阵乘法。</p><p></p><p>尽管 Cerebras 尚未参与 MLPerf 的评测，但该公司宣称其平台在每秒生成的 Token 数量比 Nvidia 的 H100 高出 7 倍，比竞争对手 AI 初创公司 Groq 的芯片高出 2 倍。Cerebras 首席执行官兼联合创始人 Andrew Feldman 表示：“我们正处在通用人工智能的拨号上网时代。这是因为受到内存带宽的限制。无论是 Nvidia 的 H100、MI 300 还是 TPU，它们都使用相同的外部内存，从而受到相同的限制。我们已经突破了这一限制，这得益于我们的晶圆级技术。”</p><p></p><p>在 Hot Chips 大会上，来自首尔的 Furiosa 公司也发布了第二代芯片——RNGD。Furiosa 芯片的独特之处在于它所采用的张量收缩处理器（TCP）架构。在 AI 工作负载中，矩阵乘法是一项基础操作，通常在硬件中以原语的形式实现。然而，矩阵的规模和形状（即张量）可以有极大的变化。RNGD 实现了这种更为通用的乘法版本作为原语。Furiosa 创始人兼首席执行官 June Paik 在 Hot Chips 大会上解释说：“在推理过程中，批次大小差异显著，因此充分利用张量形状的固有并行性和数据重用至关重要。”</p><p></p><p>虽然 Furiosa 没有向 MLPerf 提交 RNGD 芯片的评测数据，但该公司已在内部将 RNGD 芯片在 MLPerf 的 LLM 摘要基准测试中的性能与 Nvidia 的边缘计算芯片 L40S 进行了比较。结果显示，在功耗仅为 185 瓦的情况下，RNGD 芯片的性能与功耗为 320 瓦的 L40S 相当。June Paik 表示，随着软件优化的进一步深入，芯片的性能有望得到进一步提升。</p><p></p><p>IBM 还发布了他们为满足企业生成式 AI 工作负载需求而设计的新款 Spyre 芯片，并计划于 2025 年第一季度推向市场。</p><p></p><p>至少，在可预见的未来，AI 推理芯片市场的买家们将不会感到乏味。</p><p></p><p>原文链接：</p><p></p><p><a href=\"https://spectrum.ieee.org/new-inference-chips\">https://spectrum.ieee.org/new-inference-chips</a>\"</p><p></p><p>声明：本文由 InfoQ 翻译，未经许可禁止转载。</p><p></p>",
    "publish_time": "2024-09-11 17:46:18",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "微软中国 CTO 韦青：关于微软 AI 转型的经验和思考 ｜InfoQ《大模型领航者》",
    "url": "https://www.infoq.cn/article/IsYusctiFD8MGarHY81Q",
    "summary": "<p>“在技术行业，没有人尊重传统，只尊重创新。”历经50多年，微软如何保持“年轻”心态，并抓住了AIGC机会实现AI转型？这个过程中，他们有哪些尝试和反思？本期《大模型领航者》，微软中国 CTO 韦青讲述微软的AI转型故事。</p>",
    "publish_time": "2024-09-11 17:53:14",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "MiniMax 视频生成模型首秀！闫俊杰：大模型的研发核心是“快”",
    "url": "https://www.infoq.cn/article/Hh9SEWrDlo7phePDw0I8",
    "summary": "<p></p><p></p><p></p><p>上面是 MiniMax 最新推出的视频模型 video-01 生成的效果。“这只是我们的第一版，很快还会有更新的版本。” MiniMax 创始人闫俊杰说道。</p><p></p><p>在 MiniMax 内部，多模态已经是一件非常确定的事情了。</p><p></p><p>“在人类社会，大模型的核心意义是做更好的信息处理，而大部分的信息体现在多模态内容里，而非文字上，文字很多时候只是其中精华的一小部分。”闫俊杰解释道。</p><p></p><p>“为了有非常高的用户覆盖度和使用深度，唯一的办法就是能够输出动态的内容，而非只输出单纯的文字内容，这是一个非常核心的判断。”用户的渗透率和使用深度是闫俊杰这次创业非常关注的事情。在他看来，这两点是达成“Intelligence with Everyone”的核心，也是 MiniMax 的差异化能力。</p><p></p><p>用户方面，MiniMax 已经有了不错的成绩。据统计，MiniMax 每日与全球用户进行超 30 亿次交互，处理超 3 万亿文本 token、2000 万张图片和 7 万小时语音，大模型日处理交互量排名国内 AI 公司首位。</p><p></p><p>但在视频生成赛道，MiniMax 的发布算不上早。闫俊杰对此的解释是，“我们在解决一个更难的技术问题：如何能够原生地训练算力比较高的东西。”</p><p></p><p>具体来说，首先，训练视频生成能力时也需要先把视频变成一些 token，视频变成的 token 非常长，越长复杂度就越高，MiniMax 团队要做的就是在算法上把复杂度降低、压缩率变得更高。</p><p></p><p>其次，视频还很大，比如 5 秒的视频有几兆，而 5 秒看到的文字可能不到 1K，这是千倍的存储差距。因此，之前基于文本模型的基础设施，对视频模型来说是不适用的，这意味着要对基础设施进行升级。</p><p></p><p>“一两周新的东西出来，并达到我们更加满意的状态后，可能会考虑商业化。”闫俊杰表示。</p><p></p><p></p><h3>“能带来数倍提升的技术才值得投入研发”</h3><p></p><p></p><p>视频生成模型的研发更让闫俊杰坚定了一件事：无论是视频、文本还是声音，核心都不是让一个算法带来 5%、10% 的提升，重要的是找到提升数倍的方式，如果能够提升数倍就一定要做出来，如果只提升 5% 就不太值得做。</p><p></p><p>“从读书、工作，到现在创业，我对技术的理解慢慢变得非常简单，就是第一性原理。技术，特别是有很大研发投入的技术，追求的不应该是 10% 的提升，如果一个技术的提升只有 10%，那这个技术就不应该做，原因是你不做也会有人做或有人开源出来，其实根本不需要自己研发。”闫俊杰对 InfoQ 表示。</p><p></p><p>“对创业来说，一块钱掰成几份来花是非常难的。像我们这样的创业公司，真正应该花钱做的研发是那种能够带来几倍变化的技术，这种东西很多时候如果我们自己不做，外面也没有，但对满足用户的需求又很重要，只能自己来做，这样的才是核心的东西。”闫俊杰说道。</p><p></p><p>那么，MiniMax 做大模型的核心是什么？</p><p></p><p>闫俊杰的答案是：快 = 好。</p><p></p><p>在率先判断出 MoE 技术路线后，MiniMax 又推出基于 MoE+ Linear Attention 的新一代模型技术。通过此新型线性模型架构，MiniMax 大模型能在单位时间内更加高效地训练海量数据，极大地提升了模型的实用性和响应速度。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/21/216ddd9f50c795c660c5daed2c7c041e.png\" /></p><p></p><p>MiniMax 与GPT-4o 同一代模型能力进行对比发现，新一代模型处理 10 万 token 时效率可提升 2-3 倍，并且随着长度越长，提升越明显。相比于通用 Transformer 架构，在 128K 的序列长度下，新架构成本减少 90% 以上。</p><p></p><p>“不管是做 MoE、Linear attention 还是其他的，本质上是让同样的效果模型变得更快，快才意味着同样的算力可以做得更好，这是我们最底层的研发思路。”闫俊杰说道。</p><p></p><p>“从实际应用上，就像我们肯定不希望星野的 NPC 只能记住最近 8000 字的内容，这对用户的体验损伤比较大，如果能 Scale 到 8 万字、80 万字、800 万肯定能做出更不一样的产品。” MiniMax 技术总监韩景涛补充道。</p><p></p><p></p><h3>“产品不赚钱是技术不够好”</h3><p></p><p></p><p>目前，MiniMax 在国内 C 端的主打产品是星野和海螺 AI。</p><p></p><p>“当一个产品没人用或者不赚钱的时候，肯定不能怪用户，大部分时候只能怪自己的技术做得不够好，或者产品做得不够好。”闫俊杰说道。</p><p></p><p>因此，在闫俊杰看来，像基于 GPT-4 的 GPT Store 跑不通的根本原因，不是因为 Agent 的框架写得不够好，是因为模型本身不够好。“当前的模型没有很长的记忆、理解不了特别复杂的指令就会这样。”</p><p></p><p>现在所有的模型错误率都是 20% 的量级，闫俊杰认为，真正发生变革的是有一个模型可以把错误率降低到个位数，这会让很多复杂的任务从“不可以”变得“可以”。</p><p></p><p>“当技术做得不好的时候，所有东西都是问题，当技术做好了，似乎所有问题都被掩盖了。技术是一家科技公司的最核心的要素，我觉得我花了两年才意识到这件事。”闫俊杰说道。</p><p></p><p>在闫俊杰看来，做技术是一件非常奢侈的事，这件事甚至只有创业的时候才会理解，因为做技术，可能会失败、投入也很大。当一个东西很奢侈时，很多时候就会想要不要走点捷径，比如不做技术，先把产品提升好等。</p><p></p><p>“实践经验证明，走捷径的时候会被打脸。”闫俊杰笑道。</p><p></p><p>目前，MiniMax 的商业化基本上分成两种模式：一是面向企业的开放平台，现在已经有两千多家的客户，包括互联网公司、传统企业等；二是在自有产品里设立广告机制进行变现。</p><p></p><p>“现阶段，最重要的还不是商业化，是真正地对技术到达广泛可用的程度。”闫俊杰表示。</p><p></p><p>对于国内市场，MiniMax 希望打造偏工具类的产品，比如会给海螺 AI 不断打磨出新的功能，直到产生了很强的用户粘性。“粘性构造起来后，我们才会考虑 ROI 和 Retention。这个飞轮转起来了，我们才会进行投放。”MiniMax 国际业务总经理盛静远表示。</p><p></p><p>盛静远认为，这个 ROI 会有转起来的一天，但不是今天的产品形态。“作为一个普通消费者，今天的产品形态没有任何的忠诚度可言。它一收费我就可以换到另外一个产品，这个模式是不成立的。”</p><p></p><p>但海外市场不太一样。海外企业更愿意付费，因此把技术做得细腻很重要。“对我们来讲现在技术完全到位了，更多是公司的精力和资源，以及怎么变现的问题。海外市场有一套自己的打法，会相对地比较 straightforward，变现也更快。”</p><p></p><p>实际上，MiniMax 海外产品 Talkie 名气可能比国内产品更高。在全球知名风投机构 a16z 最新发布的《Top100 消费级生成式 AI 应用》移动应用榜单中，Talkie 位列 22 位。</p><p></p><p>盛静远总结道，任何伟大的 2 C 产品都是基于人性的深入思考，另外则要考虑 AI 在高容错率的情况下可以做什么，并变成大众喜闻乐见的产品。</p><p></p><p></p><h3>结束语</h3><p></p><p></p><p>大模型领域的竞争依然在继续。闫俊杰表现得比较淡然，“这就是一个发展的客观规律，作为一家创业公司，如果我们在竞争中打不赢，那我们就应该被淘汰，其实也没有其他的选择。”</p><p></p><p>在与大厂的竞争中，闫俊杰认为，要赢就要更快地看清非常底层的东西，“大公司开始跟你竞争时，就会意识到有些东西是没用的，因为那些东西大厂能做得比你强千百倍。我们能做的就是无限放大能让我们变强的事情：一是提升技术；二是跟用户共创，这两点非常关键的判断是需要长期积累的。”</p><p></p><p>而对于国内的大模型价格战，闫俊杰认为确实非常大地提高了模型的调用量，本来认为大模型很贵的公司，包括很多传统的企业开始愿意使用大模型，因为成本低对出错的容忍度也会高一些。“正是激烈的竞争，推动了大家必须得把模型做好。一定阶段之后，大家会发现自己的模型在海外也有竞争力，比如东南亚等，至少目前已经在非英语国家的语种上跟 GPT 不相上下。”</p><p></p><p>“我们看到乐观的一面，国内大模型的使用量确实在显著地增长，并且中国的模型在海外确实越来越具有竞争力，我觉得这是两个积极的变化。”闫俊杰说道。</p><p></p><p></p><p></p>",
    "publish_time": "2024-09-11 18:34:07",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "又“刑”了！搞瘫公司三千多工作电脑，不给 500 万就删 IT 账户，网友：快乐的员工谁干这事儿啊",
    "url": "https://www.infoq.cn/article/QQHhGTK6VStzy2JDHu2U",
    "summary": "<p></p><p>美国一家全国性工业企业遭某心怀不满的 IT 员工报复。Daniel Rhyne 是这家企业的核心基础设施工程师，他曾试图向所在公司勒索价值 75 万美元（约530万人民币）的比特币。</p><p></p><p>2023 年 11 月 25 日，该公司的网络管理员收到通知，提示其域管理员账户以及数百个用户账户的密码遭到重置。此后不久，网络管理员发现其他域管理员账户均已被删除，导致各域管理员无法正常访问计算机网络。大约 44 分钟后，该公司的部分员工收到一封来自外部勒索电子邮件地址，标题为“你的网络已遭入侵”。</p><p></p><p>勒索软件向收件人发出警告称：该公司的所有“IT 管理员账户均已被锁定或删除”，因此公司计算机网络无法登录；公司的所有“备份均已被删除”；如果未在 2023 年 12 月 2 日之前将 70 万欧元的赎金以 20 比特币的形式汇入勒索邮件中指定的 BTC 地址，则每天将另外“随机关闭 40 台服务器，为期 10 天”。按 2023 年 11 月 25 日当天的价格计算，20 个比特币的价值约为 75 万美元。</p><p></p><p>执法部门根据调查，确认从 2023 年 11 月 8 日左右到 11 月 25 日左右，这家公司的计算机网络上确实发生了恶意活动。公司域控制器上存在了多项计划任务，具体包括：删除公司的 13 个域管理员账户、更改受害者共 301 个域用户账户的密码、更改受害者两个本地管理员账户的密码，具体影响到 254 台服务器；更改公司另外两个本地管理员账户的密码，影响到了 3284 台工作站；在 2023 年 12 月的数日之内，关闭了受害者多台服务器和工作站。</p><p></p><p>这些计划任务为统一设置，目的是阻止公司正常访问其系统和数据。</p><p></p><p>在 2023 年 11 月 25 日上午 7：48 左右，该公司管理员账户曾遭 7 次未授权访问，Rhyne 由远程桌面会话发起了该访问，从上午 7：48 持续至上午 9：45 左右。这期间，Rhyne 创建了自己的“计划任务”。</p><p></p><p>8：12 左右起，Rhyne 控制管理员账户开始在其域控制器上创建约 16 项未经授权的“计划任务”，其中 6 项“计划任务”配置为在 2023 年 11 月 25 日下午 4：00 这一特定时间点执行，其余计划任务则为从 2023 年 12 月 3 日开始的几天内，对受害者的数十台计算机服务器执行关停。如果这些计划任务实际执行，则受害者将无法访问其系统和数据，很可能导致其业务运营中断。</p><p></p><p>该远程桌面会话源自公司网络上某未经授权的卡片机（以下简称“隐藏虚拟机”）。从 2023 年 11 月 10 日到 2023 年 11 月 25 日左右，该隐藏虚拟机曾多次被用于访问受害者域控制器上的管理员账户。此外，该隐藏虚拟机也是该时段内唯一通过远程桌面会话访问受害者域控制器上管理员账户的系统。</p><p></p><p>据调查，该隐藏虚拟机于 2023 年 11 月 9 日创建完成，当时隐藏虚拟机的用户账户密码为“TheFr0zenCrew!”。此密码与受害者管理员账户以及 301 个域用户账户被重置后的密码内容相同。</p><p></p><p>在此时段，公司的安全摄像头和物理访问日志还记录到，Rhyne 曾亲自进入受害者总部。Rhyne 在抵达公司总部后，很快就使用 Rhyne 账户登录了 Rhyne 电脑，并曾多次使用该账户访问隐藏虚拟机。当 Rhyne 不在受害者总部时，Rhyne 电脑的使用者会通过分配给 Rhyne 位于新泽西州沃伦县住所的互联网协议（IP）地址远程访问受害者的计算机网络，包括隐藏虚拟机。</p><p></p><p>当局随后成功将勒索信息追溯到了 Rhyne 控制的电子邮件地址，并于 2024 年 8 月 27 日在密苏里州将其逮捕。Rhyne 被指控犯有一项设施勒索罪、一项故意损坏受保护计算机罪和一项电信欺诈罪，目前面临共计最高 35 年的监禁和 75 万美元的罚款。值得注意的是，Rhyne 今年已经 57 岁了。</p><p></p><p></p><h3>“快乐的员工可能不会做这种事”</h3><p></p><p></p><p>这件事在 Reddit 上被网友热议，核心在企业与员工上。</p><p></p><p>“感觉这类事情现在发生得越来越频繁了。我绝不是纵容这种行为，但不得不怀疑，这是否是公司对待员工的‘副产品’，让少数人在即将离职时充满了这种‘我不在乎’的心态。”有网友评价道。</p><p></p><p>事实上，前不久，39 岁在新加坡工作的印度人 Kandula Nagaraju 因被解雇而感到“困惑和沮丧”，因为他认为自己在工作期间表现良好，并为公司“做出了良好贡献”。于是，他进入前公司的计算机测试系统并删除了 180 台虚拟服务器，给公司造成损失约 678,000 美元。最后，他因一项未经授权访问计算机资料的指控被判处两年零八个月监禁，另一项指控正在量刑。</p><p></p><p>“在一家公司工作多年，与黑客和垃圾邮件发送者抗争，日夜工作。修补 100 台机器、升级和维护新用户等。然后，无缘无故被解雇。我完全可以理解在一家公司欺骗了你和你认识的在那里工作的每个人之后，你对这家公司的态度。”网友 Noct 表示。</p><p></p><p>有网友分享了自己的身边的真实案例。“在我工作的一家初创公司，也发生过类似的事情，只是规模比较小。我们有一个和蔼可亲但完全不称职的 IT 经理，他最终被解雇了。他离开后，我们发现他创建了一家与我们公司名称相似的假公司，并将供应商支票寄到了这个公司。他还创建了与供应商名称相似的假公司，因此他可以从两方榨取利润。他还负责我们的网站，并以自己的名义注册了网站，被解雇的那天，他又重定向到了我们最大的竞争对手。”</p><p></p><p>有网友认为，这在一定程度上反映了企业文化对人们思维的影响。“你不需要懂心理学就可以知道，更快乐的员工可能不会做出这种事情。”</p><p></p><p>当然，也有网友提出，有的员工即使没有那么多怨恨，也可能会做同样的事情，即使他们曾经受到良好的待遇，并且因为正当理由而被解雇。</p><p></p><p>还有网友对做出这种行为的人表示惋惜。“真是愚蠢！我知道你对工作、老板或生活不满意，但不要对别人那么粗鲁，优雅体面地处理你的问题，然后另谋出路。”“被解雇是一件很艰难、很有压力的事情，但为此无法再在自己的领域工作是不值得的。”</p><p></p><p></p><h3>“内鬼”安全该被关注？</h3><p></p><p></p><p>IT Governance 治理、风险与合规管理（GRC）主管 Damian Garcia 在接受媒体采访时表示，该事件应当成为企业实施强有力离职流程、以防止内部人士恶意攻击的典型案例。</p><p></p><p>“这家公司所经历的情况，正是那些缺乏强有力离职流程的企业所面临的典型威胁——当员工因违纪等理由被迫离开组织时，特别是包括系统管理员在内的拥有较强技术能力的员工，必须及时撤销其对系统的访问权限。”</p><p></p><p>Garcia 还提到，内部威胁对于组织来说已经构成严重风险。他指出，这类威胁常常遭到忽视，因为人们更倾向于抵御受到更多关注的外部威胁。</p><p></p><p>“内部威胁对于组织来说已经构成极其严重的风险。从历史上看，企业往往会忽视这一点，宁愿把精力集中在外部威胁行为者身上（比如那种身着连帽衫、把面部遮挡起来的刻板网络犯罪分子形象）。然而，企业应当意识到内部威胁已经成为更大的问题，同样是需要认真对待的风险因素。”他解释道。</p><p></p><p>“根据具体工作性质，我们需要保证员工能够访问系统以获取必要的信息，借此履行他们受雇承担的职责。也正是由于这种系统访问权限以及我们需要绝对信任员工这一事实，才导致组织面临严峻风险，毕竟没人能保证这些员工永远规规矩矩。”</p><p></p><p>Trustwave 在其针对金融行业的内部研究研究中发现，与前几年相比，如今 40% 的企业报告称内部威胁攻击频率有所增加，近半数（45%）的企业承认过去一年间曾经历五次以上的此类攻击。</p><p></p><p>Trustwave 计算出，内部威胁事件造成的平均损失为 500 万美元，凸显出此类攻击可能造成的重大财务影响。</p><p></p><p>当然，并非所有内部威胁都出于恶意，员工的疏忽大意也可能对所在组织造成风险。攻击面管理专业服务商 Armis 的研究表明，67% 的英国员工会在未经 IT 部门或者安全团队许可的情况下下载软件，进而对业务环境造成威胁。</p><p></p><p>为了最大限度减少企业承受的内部威胁风险（无论出于恶意还是无意），Garcia 都建议企业开展员工安全意识培训，借此改善整体安全文化，具体措施包括营造一种支持性的办公环境，让员工更坦然地上报自己可能犯下的任何错误。</p><p></p><p>“应对内部威胁最有效的方法，就是组织员工安全意识培训——缺少了这关键的一环，数据泄漏将不可避免。必须建立起一种安全意识文化，让每个人（而不仅仅是 IT 部门）了解到自己在安全领域扮演的角色和发挥的作用。员工应当可以更坦然地上报无心之失，比如意外点击了钓鱼链接，以确保问题能够快速得到响应。”Garcia 表示。</p><p></p><p>此外，Garcia 认为，组织也可以实施多种技术措施来缓解内部威胁，包括部署电子邮件过滤器和监控工具。“我们永远无法预测下一个威胁来自哪里，因此多重保护体系才是保障组织安全的关键所在。”</p><p></p><p>参考链接：</p><p></p><p><a href=\"https://www.justice.gov/usao-nj/media/1365476/dl?inline\">https://www.justice.gov/usao-nj/media/1365476/dl?inline</a>\"</p><p></p><p><a href=\"https://www.itpro.com/security/why-you-should-always-be-wary-of-insider-threats-a-disgruntled-employee-at-a-us-industrial-firm-deleted-backups-and-locked-it-admins-out-of-workstations-in-a-failed-data-extortion-attempt\">https://www.itpro.com/security/why-you-should-always-be-wary-of-insider-threats-a-disgruntled-employee-at-a-us-industrial-firm-deleted-backups-and-locked-it-admins-out-of-workstations-in-a-failed-data-extortion-attempt</a>\"</p><p></p><p><a href=\"https://www.channelnewsasia.com/singapore/former-employee-hack-ncs-delete-virtual-servers-quality-testing-4402141\">https://www.channelnewsasia.com/singapore/former-employee-hack-ncs-delete-virtual-servers-quality-testing-4402141</a>\"</p><p></p><p></p>",
    "publish_time": "2024-09-11 18:41:02",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]