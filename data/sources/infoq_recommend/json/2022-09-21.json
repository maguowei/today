[
  {
    "title": "刘少轩：工业和信息化重点领域数字化转型产业人才基地介绍 ｜ DTDS 8 月",
    "url": "https://www.infoq.cn/article/5W80s0K0mOzbbMoCo1Rb",
    "summary": "<p>在工业和信息化部人才交流中心和中国移动通信联合会教育与考试中心的大力支持与指导下，由极客时间企业版、培训杂志共同举办，甫瀚咨询联合举办的 DTDS 全球数字人才发展线上峰会于 8 月 9 日拉开帷幕。</p>\n<p>经过多年在企业数字人才发展领域的耕耘，极客时间于 2022 年发布了数字人才粮仓模型，深入定义了五层数字人才，收获了来自各行各业的企业客户的认可。我们也看到许多企业都在加大对数字人才的培养，并且希望向行业标杆学习，完善自己的数字人才培养体系，融入数字人才标准和生态。</p>\n<p>为此，DTDS 峰会汇聚了来自政府和产业的权威，以及金融、汽车、制造、ICT、零售、互联网、风控审计企业的数字化先锋人物，旨在建立数字人才培养“朋友圈”，让大家从多维视角了解企业数字化转型，人才发展，和组织变革的先进经验。</p>",
    "publish_time": "2022-09-21 00:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "SaaS初创公司如何选择合适的云基础设施",
    "url": "https://www.infoq.cn/article/HXgMpZwrxmhGU2DyWE9M",
    "summary": "<p>Gartner<a href=\"https://webtribunal.net/blog/cloud-adoption-statistics/#grefhttps://webtribunal.net/blog/cloud-adoption-statistics/\">预测</a>\"，到2022年，云应用方面的投入将达到4820亿美元，这是云计算向不同行业渗透的一个重要指标。但令人感到担忧的是云迁移的失败率。目前，各阶层企业的这一比例在44%到57%之间徘徊，这给预算紧张的初创企业带来了很大的压力。</p><p>&nbsp;</p><p>软件即服务（SaaS）初创企业也不例外。作为一名解决方案架构师，多年来我一直在设计SaaS应用程序，我看到了初创企业在努力地寻找合适的云基础设施，并改进他们的产品。</p><p>&nbsp;</p><p>这些经历促使我写了这篇文章，并将其作为一种工具帮助公司做出务实的基于事实和数据驱动的决策。</p><p>&nbsp;</p><p>在开始讨论云计算解决方案之前，我们需要了解每种解决方案提供的抽象级别，因为它直接影响了管理成本。更高级别的抽象提供更少的控制、更低的性能输出，并增加了成本，但涉及的工作量更少，利用率更高。</p><p>&nbsp;</p><p>如果你正在构建SaaS产品，首先需要购买和采购硬件。然后，你需要在硬件上安装操作系统，再安装JVM、v8和Python等运行时。之后，你需要安装所有的依赖项，最后再部署代码。</p><p></p><h2>云基础设施解决方案</h2><p></p><p>现如今，每一种可用的基础设施解决方案都至少抽象了一两项以下这些东西。</p><p>&nbsp;</p><p>云虚拟机（IaaS）——它们主要对硬件层进行了抽象，你不需要配置任何物理设备，但仍然需要构建其他层。这将为你提供最大程度的控制，但需要花费更多的时间来设置，如EC2、Azure VM、谷歌云平台（GCP）。</p><p>&nbsp;</p><p>平台即服务（PaaS）——它提供了位于硬件之上的另一层抽象，你不需要担心操作系统/容器、升级、安全等问题，如Azure PaaS、AWS Elastic Beanstalk和GCP PaaS。</p><p>&nbsp;</p><p>无服务器（函数即服务，FaaS）——这是抽象了运行时的PaaS。在这个抽象级别，你不需要操心运行时，如<a href=\"https://www.infoq.cn/profile/16442875E6261F/publish\">AWS</a>\" Lamda、<a href=\"https://www.infoq.cn/topic/Azure\">Azure</a>\" Function和<a href=\"https://gcp.infoq.cn/index.html\">Google Cloud</a>\" Functions。</p><p>&nbsp;</p><p>低代码——除了硬件、操作系统和运行时之外，你还可以获得依赖项管理的抽象，如Parse。你需要认真思考最佳实践。</p><p>&nbsp;</p><p>Kubernetes（容器编排）——如果你一开始选择了Kubernetes，或者在Kubernetes即服务（EKS）达到生产就绪状态时使用了它，那么你将以Pod的形式发布代码。从抽象的角度来看，它类似于无服务器，但仍然提供更大程度的控制。</p><p>&nbsp;</p><p>零代码——有一些平台和服务可以让你在不写任何代码的情况下创建应用程序。然而，这并不意味着你不需要开发人员。它们可用于交付快速原型、MVP和初始引导代码，如Zoho或Quick Base。我们不打算在本文中讨论零代码平台。</p><p>&nbsp;</p><p>现在让我们深入讨论一下影响结果的关键因素。</p><p></p><h2>影响SaaS应用程序基础设施的7个因素</h2><p></p><p></p><h4>因素1：管理开销</h4><p></p><p>首先需要考虑的是公司管理基础设施的能力，包括时间、日常管理是否需要人力，以及产品对未来变化的适应性。</p><p>&nbsp;</p><p>如果产品的主要用户是企业，并且需要定制，那么可能需要多次部署产品，这可能意味着基础设施管理员需要花费更多的精力和时间。部署可以自动化，但自动化过程要求产品稳定性。对于早期产品，ROI可能不会太好。在这种情况下，我的建议是使用托管服务，比如用于基础设施的PaaS、用于数据库/持久化的托管服务，以及用于计算的FaaS/无服务器架构。</p><p></p><h4>因素2：上市时间（TTM）</h4><p></p><p>实现快速TTM的关键是快速开发、测试和发布。快速开发到快速发布的关键是将更多的时间花在编码和测试上，而不是配置和部署上。低代码和无代码平台都是不错的选择。无服务器和FaaS被设计用来解决这些问题。如果你的系统涉及多个组件，那么自己构建服务器将会消耗太多的时间和精力。同样，使用Kubernetes也不会使它变得更快。</p><p>&nbsp;</p><p>PaaS仍然提供了比云虚拟机更好的选择，但你可能需要构建部署管道（CI/CD）来加速TTM。CI/CD管道在低代码平台中是隐式可用的。你可能还希望选择与云不可知的工具，便于在未来迁移到其他平台。在这方面，零代码和低代码平台存在很大的风险。</p><p></p><h4>因素3：敏捷性</h4><p></p><p>产品敏捷性是一个关键因素。你需要考虑定制量、主要变更、垂直转换、水平转换以及可能出现的新业务需求。假设你正在构建一个多租户系统，不同的租户有不同的定制需求。这些变更需求会不断地涌向你。从基础设施的角度来看，你需要一个不必为每个变更需求做出改变的系统。这个时候需要考虑云的无关性。</p><p>&nbsp;</p><p>对于数据，AWS Aurora或Azure Cosmos DB等无服务器数据服务是很好的选择。如果你正在构建工作流或处理数据，那么像函数这样的在线服务可能是最好的选择。对于应用程序，无服务器或FaaS是很好的选择。你还可以使用Kubernetes构建多租户系统，但这不是好的入手点，因为你可能需要维护多个版本的应用程序、数据和功能。无服务器架构可能是更好的选择。</p><p></p><h4>因素4：控制程度</h4><p></p><p>考虑对基础设施的控制程度。基于以下这些原因，你可能想要更多的控制。</p><p>&nbsp;</p><p>将会有大量的应用程序、数据库和服务。这是一个必须为客户提供硬件的系统（<a href=\"https://www.infoq.cn/topic/mongodb\">MongoDB</a>\" Atlas）。你需要为租户隔离数据或运行时，或两者都隔离。它是一种在线服务或API，你的USP是为客户节省许可、硬件和管理成本。</p><p>&nbsp;</p><p>你可以通过控制物理机器或机架获得最大程度的控制，但这些已经不再被使用了——因此，保持高程度控制的最佳方法是高端专用实例。无服务器、低代码和无代码平台提供的控制程度最低。</p><p>&nbsp;</p><p>Kubernetes将耗费大量的时间和精力，但从长远来看，这是一笔不错的交易。尽量避免使用在线服务，不要忘了你也在构建在线服务。</p><p></p><h4>因素5：成本</h4><p></p><p>成本是最重要的因素之一。早期的成本估算总是很困难的，不过我们来看一个例子。</p><p>&nbsp;</p><p>对于每天每小时一万个请求，无服务器基础设施比云虚拟机的成本更高。但是，如果负载是异构的，并且在某些随机时间是一万，而在其他时间是一千，那么使用云虚拟机实例的成本可能会更高，因为它们在大多数时间都没有得到充分利用，在空闲时没有产生任何价值。</p><p>&nbsp;</p><p>你从一开始就要尽量避免固定成本。但为了更好的利用率，你需要找出平衡点，并切换回较低的级别（从低代码到无服务器，或者从无服务器到容器）。避免过早优化，在一开始不要追求优化或平衡。选择最便宜的、现收现付的订阅方式，之后再选择更好的。</p><p></p><h4>因素6：迁移</h4><p></p><p>迁移与云不可知直接相关。更新、更便宜、更好的云服务会不断出现，所以你需要进行迁移。有时候迁移取决于你的客户希望与哪个云供应商合作。仅仅使用虚拟机并不意味着你的系统是不可知的。</p><p>&nbsp;</p><p>例如，如果你系统中有不同的组件访问了其他组件，而你的<a href=\"https://www.infoq.cn/topic/Devops\">DevOps</a>\"团队已经完全在IAM角色上设计了这种访问管理，那么从AWS迁移到GCP可能是一件棘手的事情。类似地，如果必须基于无服务器构建整个计算层，那么迁移到虚拟机可能并不容易。</p><p></p><h4>因素7：集成</h4><p></p><p>如果你正在构建一个聚合平台，那么你可能需要从第三方API收集数据，或者与其他API发生交互。这是一个集成问题，作为初创公司，你需要关心的是基础设施的速度、可靠性和一致性。</p><p>&nbsp;</p><p>在进行集成时，为应对节流和API速率限制，你可能会在短时间内生成多个Spot实例或多个无服务器实例，从其他API收集/提交数据。在这里，无服务器提供了很大的帮助。自动缩放Kubernetes节点也很好。如果你选择的是云虚拟机实例，那么你必须花一些时间和精力来自动化配置。</p><p>&nbsp;</p><p>基于上面定义的因素，我列出了一个决策矩阵，可以帮你做出决策。</p><p></p><h2>决策框架</h2><p></p><p>我提出了一个包含选项、因素和难度级别的框架。我在这里使用的评价等级带有主观性，因为它是基于我十多年来使用不同基础设施的经验，而不是基于测试基准。</p><p>&nbsp;</p><p>这个表格将让你了解使用特定类型的基础设施达到（构建和设置）某个因素级别的困难程度。</p><p>&nbsp;</p><p>容易：你可以做一些简单的配置就可以完成。只需要付出较少的努力和时间，你就可以达到所需的因素级别。中等：你可能需要进行更多的配置/调优才能达到特定的因素级别，这可能不是一种最直接的方法。困难：为了达到这个目标，你可能需要基于一个明确的策略投入很多时间和精力。你可能还需要具备一些专业知识。</p><p>&nbsp;</p><p></p><p></p><h2>结论</h2><p></p><p>对于SaaS初创公司，我已经意识到最好从Kubernetes（容器编排）开始，如果不选择Kubernetes，那么可以考虑云虚拟机。<a href=\"https://www.infoq.cn/topic/Kubernetes\">Kubernetes</a>\"只需要付出最小的努力就可以实现最大程度的控制，并可以确保成本优化以及未来的迁移和集成。</p><p>&nbsp;</p><p>你需要远离低代码/无代码平台，它们在一开始可能看起来很容易，但它们在未来是个雷区，它们无法你解决三个关键因素：基础设施成本、IT管理成本和许可成本。PaaS在某种程度上是可以接受的，但是如果涉及到操作系统级别的升级，它也会带来一些障碍。</p><p>&nbsp;</p><p>作者简介：</p><p>Ratnesh Singh Parihar是Talentica软件公司的首席架构师。他是苏拉特国立理工学院的校友，在超过15年的职业生涯中，曾与几家早期和成长期的初创公司合作。他在架构和设计、扩展和处理大型系统、解决复杂的工程问题以及现代化遗留应用程序方面积累了大量的专业知识。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/cloud-infrastructure-saas/\">Choosing the Right Cloud Infrastructure for Your SaaS Start-up</a>\"</p><p>&nbsp;</p>",
    "publish_time": "2022-09-21 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "中科驭数完成数亿元B轮融资，第二代DPU芯片预计近期回片",
    "url": "https://www.infoq.cn/article/DZh5RswKhFdGgjNX9Gow",
    "summary": "<p></p><blockquote>2020年，英伟达创始人黄仁勋将DPU与CPU、GPU并列称为“未来计算三大支柱”，此后，DPU逐渐成为芯片投资的热门赛道。</blockquote><p></p><p></p><p>9月20日消息，DPU芯片企业中科驭数宣布完成数亿元B轮融资，由金融街资本领投，建设银行旗下建信股权跟投，老股东灵均投资、光环资本、泉宗资本连续三轮追投。公司创始人兼CEO鄢贵海表示，本轮融资将用于加速驭数<a href=\"https://xie.infoq.cn/article/673ca43b426a48501d4bd3939\">DPU芯片</a>\"的研发迭代和产业布局。</p><p>&nbsp;</p><p>中科驭数成立于2018年，创始团队来自科研院所，公司聚焦专用数据处理器的研发设计，自主研发的DPU系列产品可广泛应用于超低延迟网络、大数据处理、5G边缘计算、高速存储等场景，助力算力成为数字时代的新生产力。</p><p>&nbsp;</p><p>过去一年多，<a href=\"https://xie.infoq.cn/article/34eedfd38369c7560f0ca0965\">中科驭数</a>\"已完成三轮大体量融资。2021年7月，中科驭数完成数亿元A轮融资；2021年12月，中科驭数完成数亿元A+轮融资；2022年9月，中科驭数完成数亿元B轮融资。</p><p>&nbsp;</p><p>在技术路线上，中科驭数2018年曾提出“软件定义加速器”技术路线(Software Defined Accelerator)，自主研发了面向领域专用计算(DSA)的芯片架构KPU(Kernel Processing Unit)和敏捷异构软件栈(HADOS)。据此打造了业界首颗融合高性能网络与数据库一体化加速功能的DPU芯片和标准加速卡系列产品，解决了专用处理器设计碎片化的问题，异构众核的技术架构具有软件定义可配置、设计周期短、性能更优、计算高效的优势，目前已经研发积累了百余类功能核。</p><p>&nbsp;</p><p>产品进展方面，中科驭数第二代DPU芯片K2今年初投片，预计于近期回片，这也是国内目前功能定义最完整的首颗DPU芯片。区别于大部分DPU厂商的FPGA加速卡方案，K2芯片具有成本更低、性能更优、功耗更小、自主可控性强的特点。此外，第三代DPU芯片研发迭代已经接近尾声。</p><p>&nbsp;</p><p>所谓DPU，指的是Data Processing Unit的缩写，直译为数据处理单元。</p><p>&nbsp;</p><p>鄢贵海在接受北京日报客户端记者采访时曾表示，如果把一台计算机或服务器比作一个团队，CPU相当于“大管家”，负责思考并处理业务；GPU是“美工”，专攻图像处理；DPU则相当于“前台”，负责打包、拆包“数据包”，提升整个团队的工作效率。</p><p>&nbsp;</p><p>据白皮书预测，DPU 的潜在市场非常巨大，预测到 2025 年仅中国市场就能达到每年 40 亿美元的规模，估计全球将超过 120 亿美元。</p><p>&nbsp;</p><p>有专家接受InfoQ采访时曾表示，DPU 的火热印证了芯片已经走上<a href=\"https://www.infoq.cn/article/QguHG8yPXkAe4SeiBDh5\">定制化路线</a>\"。“目前在业内，芯片厂商和操作系统厂商有的一个共识就是，今天的芯片已经走向了领域定制趋势。所谓领域定制，指的是芯片或系统，可以为一个场景去重新设计，以获得最佳用户体验。比如 DPU 是针对云计算、虚拟化的场景实现芯片创新，未来针对其他场景，可能也会出现越来越多的案例。”</p>",
    "publish_time": "2022-09-21 10:27:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "英伟达RTX 40系显卡重磅来袭！性能实现巨大飞跃，卡皇冲上12999元",
    "url": "https://www.infoq.cn/article/IA1W5Ab8FvzuiHus2oy7",
    "summary": "<p></p><p>北京时间 9 月 20 日晚间，英伟达 2022秋季GTC上，英伟达首席执行官黄仁勋在线上主题演讲中，介绍了自然语言理解、虚拟世界、游戏与AI技术方面等领域的一系列最新进展。</p><p></p><p>“计算技术正以令人难以置信的速度向前挺进，而推动这枚火箭的引擎正是加速计算，燃料则是AI”，黄仁勋表示。</p><p></p><p>黄仁勋在演讲中宣布，支持AI工作流的全新云服务与新一代GeForce RTX GPU发布，其中涉及一系列新的系统、芯片及软件成果。他认为，加速计算解开了长期困扰AI进步的枷锁，而AI又反过来影响到世界各地的诸多行业。</p><p></p><p>黄仁勋在演讲最后强调，此番公布的新技术、产品公告乃至用例宣讲，几十种不同元素的结合只为同一个目标 —— “今天，我们公布了新的芯片、平台进展，以及首次亮相的全新云服务。这些平台将推动AI技术的新突破、AI技术的新应用，也将掀起AI在科学和工业领域的新发展。”</p><p></p><h2>GeForce RTX 40 系列显卡，终于来了！</h2><p></p><p>千呼万唤始出来。英伟达第三代 RTX 显卡 —&nbsp;GeForce RTX 40终于来了！</p><p></p><h3>最新显卡性能强劲</h3><p></p><p>下一代GeForce RTX 40系列GPU由Ada架构提供支持。黄仁勋将其称为“量子飞跃”，号称能为决意模拟整个世界的创造者们铺平道路。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/bc/d5/bce413006918cf49f394d5396891c3d5.png\" /></p><p></p><p>黄仁勋发布下一代GeForce RTX 40系列GPU</p><p></p><p>Ada的提升包含一个新的流式多处理器、一个具有双倍光线三角相交吞吐量的新RT核心，外加一个带有Hopper FP8 Transformer引擎与1.4万亿次张量算力的新型张量核心。</p><p></p><p>Ada还引入了最新版本的英伟达DLSS 3技术，其使用AI将新帧与先前帧进行比较，据此生成更多新帧以体现场景变化情况。结果就是，与直接渲染相比，其游戏性能可提高4倍。</p><p></p><p>DLSS 3已经得到多家世界领先游戏开发商的支持，目前超过35款游戏和应用程序宣布引入这项新技术。黄仁勋提到，“DLSS 3是我们最伟大的神经渲染成果之一。”</p><p></p><p>与之前的RTX 3090 Ti相比，新的GeForce RTX 4090凭借上述创新带来了4倍的吞吐量处理能力。黄仁勋宣布，“这款新的旗舰级产品”起售为1599美元，计划于10月12日上市。</p><p></p><p>此外，新的GeForce RTX 4080将于11月推出，届时将提供两种配置选项。</p><p></p><p>其中GeForce RTX 4080 16GB起售价为1199美元，包含9728个CUDA核心与16 GB美光高速GDDR6X显存。在DLSS 3的支持下，其运行现有游戏的速度可达GeForce RTX 3080 Ti的两倍，甚至能够以更低的运行功耗带来超越GeForce RTX 3090 Ti的强劲表现。</p><p></p><p>GeForce RTX 4080 12GB包含7680个CUDA核心和12 GB美光GDDR6X显存，在DLSS 3的支持下速度同样高于上代旗舰GPU&nbsp;RTX 3090Ti。12GB版本的起售价为899美元。</p><p></p><h3>价格太贵了？</h3><p></p><p></p><p>不过，英伟达的 RTX 40系显卡在价格上却招来了不少吐槽。</p><p></p><p>不少人认为，在RTX 30系列推出2年多后，英伟达为下一代 GPU收取了巨额溢价，而且采用了具有“欺骗性的命名，” 这令许多 PC 爱好者并不满意。</p><p></p><p>“到底发生了什么?4080， 12G是899（美元），那哪个是4070?4080 16G 1200（美元），比上一代xx80贵500美元。这些价格太疯狂了。”<a href=\"https://old.reddit.com/r/hardware/comments/xjbobv/geforce_rtx_4090_revealed_releasing_in_october/ip7dx9h/\">一位 Redditor 感叹道</a>\"。</p><p></p><p>一位评论者回顾了2018年的GeForce 20系列的售价，对比之下，新一代显卡的价格确实显得</p><p></p><p>高昂。“最后两代已经失控了，即使在建议零售价上也是如此。多年来，x70的价格是329美元，x80是499美元，x80 Ti是700美元，而专业一级(Titan、x90等)的价格是1199美元。现在，他们把所有的价格都提高了一个级别”。</p><p></p><p>事实上，2018年，英伟达就曾因RTX 20系列卡的定价比之前的10系列卡的价格高了整整一个“级别”而招致批评。例如，RTX 2070的价格几乎与之前的高端GTX 1080一样多，尽管它不是旗舰卡。</p><p></p><p>现在来看，类似的价格层级跳现象仍在继续。</p><p></p><p>10GB RTX 3080的建议零售价是699美元。如今英伟达发布的16GB的RTX 4080，许多观察家认为它是最接近真正的3080的“继任者”，其价格高达1199美元，比上一代高出500美元。</p><p></p><p>而至于售价 899 美元的 12GB RTX 4080 ，一位网友评论说，“他们试图以900美元的价格卖给你一辆改头换面的4070。”</p><p></p><p>有网友认为，12GB 的RTX 4080 看起来只是名义上的“4080”，对于这款产品来说，“RTX 4070”会是一个更“诚实”的名称。因为，这款产品的性能明显较低，而且与16GB的RTX 4080相比，本质上，本质上是一张完全不同的卡。参考硬件规格，我们会发现12 GB版本RTX 4080所使用的芯片（「AD104」，只包含7680个着色器核心）与16 GB版本RTX 4080（「AD103」，包含9728个核心）并不相同。</p><p></p><p>但在价格上，12GB 的RTX 4080的建议零售价仍为 899 美元，比 RTX 3070 的原始建议零售价 499 美元高出 400 美元。</p><p></p><p>而关于定价的考量，英伟达的一位发言人是这样回应的：</p><p></p><p>RTX 4090 的起价为 1599 美元。 相比之下，被RTX 4090取代的RTX 3090 Ti的上市价格为1999美元。RTX 4080 16GB 的性能是 RTX 3080 Ti 在下一代内容上的 3 倍，例如具有 RT Overdrive 模式的 Cyber​​punk 或 Racer RTX，价格相同，为 1199 美元。RTX 4080 12GB 售价 899 美元，是 RTX 3080 12GB 性能的 3 倍，价格便宜 100 美元。</p><p></p><h2>最强自动驾驶汽车芯片Thor亮相</h2><p></p><p></p><h3>新一代自动驾驶计算芯片</h3><p></p><p>在如今的汽车上，主动安全、驻车、驾驶员监控、智能后视镜、仪表盘和车载信息娱乐系统各自由不同的计算机驱动。黄仁勋认为，未来的发展方向应该由集中计算机统一运行，并随软件交付而持续改进。</p><p></p><p>为了达成这个目标，黄仁勋公布了DRIVE Thor，一款将Hopper transformer引擎、Ada GPU与Grace CPU相结合的强大解决方案。</p><p></p><p>新的Thor超级芯片可提供2000万亿次浮点运算性能，将取代DRIVE路线图中的Atlan，并支持从当前DRIVE Orin（性能为每秒254万亿次浮点运算）无缝过渡。</p><p></p><p>黄仁勋介绍称，Thor将主要面向机器人、医疗器械、工业自动化和边缘AI系统等用例。</p><p></p><h3>首发中国客户</h3><p></p><p>英伟达汽车业务负责人 Danny Shapiro 表示，DRIVE Thor 将能够更换汽车中的大量芯片和电缆，并降低整体系统成本，但他没有给出具体的降本数字。“你可以想象在成本、减少布线、减轻重量、降低整体能耗方面节省了巨大的成本。”</p><p></p><p>英伟达为 DRIVE Thor 宣布的第一个客户是中国吉利旗下 (GEELY.UL) 的 ZEEKR。Shapiro 表示，DRIVE Orin计算机系统将用于中国汽车公司XPeng的新智能SUV和中国自动驾驶初创公司QCraft。</p><p></p><p>值得注意的是，近期由于美国禁止向中国出口英伟达两款用于数据中心的顶级计算芯片，人们担心中国客户能否继续使用英伟达的技术。</p><p></p><p>对此，Shapiro 回应称:“有很多公司做着伟大的工作，做着造福人类的事情，我们想支持他们。”“在我们为数据中心提供的产品受到出口限制的情况下，我们会与这些中国客户合作，提出一种合适的替代产品。”</p><p></p><h2>助力大型语言模型发展</h2><p></p><p></p><h3>H100 GPU已全面投产，为超大模型提供强大算力</h3><p></p><p>黄仁勋在演讲中再次将系统和软件同广泛的技术发展趋势联系起来，并提到大型语言模型（LLM）和推荐系统已经成为当前最重要的两大AI应用场景。</p><p></p><p>推荐系统“主导整个数字经济”，为电子商务、娱乐以及广告等行业提供动力。可以说，推荐系统“是社交媒体、数字广告、电子商务和搜索业务背后的助推引擎”。</p><p></p><p>而基于2017年亮相的Transformer深度学习模型的各类大型语言模型，同样成为当前AI研究中最具活力的领域之一。它们已经能够在无监督或标注数据集的前提下，尝试理解人类语言。</p><p></p><p>黄仁勋指出，“单一预训练语言模型已经可以执行多种任务，例如问答、文档摘要、文本生成、翻译甚至软件编程。”</p><p></p><p>黄仁勋表示，配备Hopper的下一代Transformer引擎，英伟达H100张量核心GPU将为这些超大体量模型提供必要算力。这款新产品现已全面投入生产，预计未来几周内就将开始出货。“Hopper现已全面投产，很快就会为世界上的各AI项目提供动力。”</p><p></p><p>H100的系统构建合作伙伴包括Atos、思科、戴尔科技、富士通、技嘉、HPE、联想和Supermicro。从明年开始，亚马逊云科技、谷歌云、微软Azure和甲骨文云基础设施也将率先在云端部署基于H100的实例。</p><p></p><p>而Grace Hopper，是将英伟达的Arm架构Grace数据中心CPU与Hooper GPU相结合，把高速内存容量增加到7倍，将给推荐系统带来“巨大飞跃”。搭载Grace Hopper的系统将于2023年上半年推出。</p><p></p><h3>推出大型语言模型云服务，推进 AI 和数字生物学发展</h3><p></p><p>大型语言模型（LLM）“是目前最重要的AI模型。”以Transformer架构为基础，这些大体量模型能够在无监督或标注数据集的前提下理解语言内容及含义，从而迸发出难以想象的能量。</p><p></p><p>为了让研究人员轻松将这种技术应用到自己的工作成果中，黄仁勋公布了LLM&nbsp;Nemo服务。这是一项由英伟达托管的云服务，可用于调整预训练LLM以执行特定任务。</p><p></p><p>为了加快药物和生物科学研究人员的工作进度，黄仁勋还公布了BioNeMo LLM。这是一项LLM创建服务，生成的大型语言模型能够理解化学物质、蛋白质、DNA及RNA序列。</p><p></p><p>黄仁勋宣布英伟达正与全球最大的人类基因组信息提供商The Broad Institute合作，在后者的Terra Cloud平台上提供英伟达Clara库，其中包含英伟达Parabricks、基因组分析工具包以及BioNemo等服务选项。</p><p></p><h2>打造元宇宙新方案</h2><p></p><p></p><h3>L40数据中心GPU与元宇宙全面交融</h3><p></p><p>互联网的下一波浪潮正是元宇宙，按照黄仁勋的解释，这波浪潮的核心就是3D化扩展。Omniverse正是英伟达用于构建和运行元宇宙应用的基础平台。</p><p></p><p>黄仁勋还解释道，连接和模拟一个个元宇宙世界，必然需要更强大、更灵活的新型计算机。英伟达OVX服务器就是专门为横向扩展的元宇宙应用程序而生。</p><p></p><p>英伟达的第二代OVX系统将采用Ada Lovelace L40数据中心GPU，目前这款GPU也已全面投产。</p><p></p><h3>构建和运行工业元宇宙应用的Omniverse Cloud服务</h3><p></p><p>黄仁勋还详尽介绍了英伟达Omniverse Cloud，这是一种能够对接云端、本地或设备上Omniverse应用程序的基础设施即服务。</p><p></p><p>黄仁勋也带来了新的Omniverswe容器选项，在其支持下，用于合成数据生成的Replicator、用于扩展渲染农场的Farm、以及用于构建/训练AI机器人的Isaac Sim现在都可部署在云端。</p><p></p><p>Omniverse已经得到广泛采用，黄仁勋在演讲中分享了几个客户案例及演示：</p><p></p><p>拥有近2000家零售店的劳氏正使用Omniverse设计、构建并运营其实体门店的数字孪生副本；市值500亿美元的电信运营商Charter，正与交互式数据分析供应商HeavyAi共同使用Omniverse为Charter 4G/5G网络创建数字孪生；通用汽车正在Omniverse为其密歇根设计工作室创建数字孪生，设计师、工程师和营销人员可以在这里开展协同。</p><p></p><p></p><h3>计算机图形和AI特效技术新进展、新工具</h3><p></p><p>目前全球大部分互联网流量均为视频，而用户生成的视频流也越来越多地得到了AI特效及计算机图形技术的增强。“数字化身将在云端实时接受计算机视觉、语音AI、语言理解和计算机图形等技术的处理。”黄仁勋表示。</p><p></p><p>为了在实时图形、AI和通信的交叉点上有所创新，他公布了英伟达构建的一系列加速库成果，包括CV-CUDA、作为云运行时引擎的UCF统一计算框架、Omniverse ACE Avatar云引擎，以及Tokkio客户服务化身应用。</p><p></p><h2>发布微型机器人计算机Jetson Orin Nano</h2><p></p><p>从虚拟世界转向现实世界，机器人计算机可以说是“最新类型的计算机形态”。而此次发布的第二代机器人处理器Orin，则被黄仁勋形容为这类技术的一记本垒打。</p><p></p><p>为了将Orin推向更多市场，英伟达发布了Jetson Orin Nano。这款微型机器人计算机比之前大获好评的Jetson Nano快80倍。</p><p></p><p>Jetson Orin Nano运行有英伟达Isaac机器人堆栈并搭载ROS 2 GPU加速框架，同时配备可在云端使用的英伟达Isaac Sim机器人模拟平台。</p><p></p><p>对于使用AWS RoboMaker的机器人开发者用户，黄仁勋也公布了登陆AWS市场的英伟达Isaac机器人开发平台容器。</p><p></p><h2>350万开发者，3000个加速用例</h2><p></p><p>黄仁勋宣布要把英伟达的系统/芯片以及加速计算优势，推广到全球各行各业。这是一个涵盖350万开发人员的软件生态系统，他们使用英伟达提供的500款软件开发套件（SDK）及AI模型，创建出约3000个加速用例。</p><p></p><p>参考链接：</p><p></p><p><a href=\"https://blogs.nvidia.com/blog/2022/09/20/keynote-gtc-nvidia-ceo/\">https://blogs.nvidia.com/blog/2022/09/20/keynote-gtc-nvidia-ceo/</a>\"</p><p></p><p><a href=\"https://kotaku.com/pc-nvidia-rtx-4090-4080-gpu-card-prices-crypto-scalping-1849560018\">https://kotaku.com/pc-nvidia-rtx-4090-4080-gpu-card-prices-crypto-scalping-1849560018</a>\"</p><p></p>",
    "publish_time": "2022-09-21 14:05:03",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Wasmtime 1.0 发布，官方曾透露高性能的秘密",
    "url": "https://www.infoq.cn/article/6yG3MdA25Mhe0fbELvaf",
    "summary": "<p>美东时间 9 月 20 日，Bytecode Alliance <a href=\"https://bytecodealliance.org/articles/wasmtime-1-0-fast-safe-and-production-ready\">宣布</a>\"经过三年开发，正式迎来 Wasmtime 1.0 版本。<a href=\"https://docs.wasmtime.dev/\">Wasmtime</a>\" 是创建在编译器 Cranelift 之上的 WebAssembly Runtime。Wasmtime 利用 Rust 编程语言，完全开源并符合 WASI。Wasmtime 还支持与 C/C++、Python、.NET、Go 等语言集成，同时运行在 Windows/Linux/macOS 等平台上。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/01/00/01cf5e6a118868331546517144b33300.png\" /></p><p></p><p><a href=\"https://bytecodealliance.org/\">Bytecode Alliance</a>\"是一个推动 <a href=\"https://www.infoq.cn/article/5QcN1eJ0A8xUVhNifDjK\">WebAssembly</a>\" 标准化的组织，该组织正在推动标准化的 WASI（WebAssembly System Interface），使 WebAssembly 能够安全地访问文件、网络和内存等系统资源。</p><p>&nbsp;</p><p>Wasmtime 1.0 被 Bytecode Alliance 总结为“快速、安全和生产就绪”，v1.0 公告中指出：</p><p>&nbsp;</p><p></p><blockquote>事实上，我们在一年多以前就可以称 Wasmtime 为生产就绪。但我们并不想只发布任何WebAssembly 引擎。我们希望有一个超级快速和超级安全的 WebAssembly 引擎。我们希望当我们推荐人们选择 Wasmtime 时，能够感到非常有信心。&nbsp;因此，为了确保它为你们所有人做好生产准备，我们字节码联盟的一些人在过去一年里一直在生产中运行Wasmtime。而Wasmtime在这些生产环境中表现出色，提供了一个稳定的平台，同时也给我们带来了安全和速度上的胜利。</blockquote><p></p><p>&nbsp;</p><p>目前，Shopify、Fastly、微软等公司已经在生产环境中使用了 Wasmtime 半年多到一年多的时间不等。其中，Wasmtime 为 Shopify 带来了约 50% 的性能提升；Fastly 从一个 WebAssembly 引擎切换到 Wasmtime 后，每秒钟的请求数也增加了 163% ，且其他几个公司在使用 Wasmtime 时也同样看到了可观的收益。</p><p>&nbsp;</p><p></p><h4>高性能的秘密</h4><p></p><p>&nbsp;</p><p>在正式公告发布前，Bytecode Alliance 就曾发布文章，介绍 Wasmtime 1.0 所应用的加速技术。具体来看，Bytecode Alliance 通过加速编译器和 Runtime 的各项工作，大幅增加了 Wasmtime 的整体执行速度。</p><p>&nbsp;</p><p>其中实例化 Wasm 模块的速度，则是加速的关键之一。官方提到，他们在过去一年间，针对这项工作进行了大量的优化，将模块实例化从毫秒等级加速至微秒等级，在实际的SpiderMonkey.wasm 案例中，实例化时间从原本的 2 毫秒缩减成 5 微秒，快了 400 倍。</p><p>&nbsp;</p><p>同时，官方针对 Cranelift 也进行了性能改进，最重要的工作是大幅改造托管器分配器regalloc2。Regalloc2 应用了更高端的算法，来决定托管器分配值的方法，提升了程序性能。在导入 regalloc2 后，SpiderMonkey.wasm 的执行时性能提升约 5%。</p><p>&nbsp;</p><p>Bytecode Alliance 表示，如果 <a href=\"https://www.infoq.cn/article/7JLCSEfriy7gy97XRF4A\">WebAssembly</a>\" 想要成功，就需要加速执行的工具，这样它才能够与原生程序进行竞争。“我们将继续朝着这个目标努力。”</p><p>&nbsp;</p><p>&nbsp;</p><p>GitHub 地址：</p><p></p><p><a href=\"https://github.com/bytecodealliance/wasmtime/releases/tag/v1.0.0\">https://github.com/bytecodealliance/wasmtime/releases/tag/v1.0.0</a>\"</p><p>&nbsp;</p><p>参考链接：</p><p>&nbsp;</p><p><a href=\"https://www.phoronix.com/news/Wasmtime-1.0-Released\">https://www.phoronix.com/news/Wasmtime-1.0-Released</a>\"</p><p></p><p><a href=\"https://www.ithome.com.tw/news/152999\">https://www.ithome.com.tw/news/152999</a>\"</p>",
    "publish_time": "2022-09-21 14:45:33",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Azure CTO呼吁不要使用 C/C++ 创建新项目，C++之父回应：你们这些高管就爱喜新厌旧",
    "url": "https://www.infoq.cn/article/CxumGNubD8mzyo1RCcwI",
    "summary": "<p></p><blockquote>微软Azure CTO 向旧语言猛烈开炮，C++之父对此进行了辩护。</blockquote><p></p><p>&nbsp;</p><p>微软Azure CTO Mark Russinovich呼吁放弃C和C++这两门久经时间考验，被广泛应用于高性能本机应用程序开发的编程语言。C++之父Bjarne Stroustrup回应称企业高管就是喜欢新事物，且一些人总爱发表非常片面的言论。</p><p>&nbsp;</p><p>本周一，Russinovich敦促科技行业放弃C/C++。他强调，“说到编程语言的选择，是时候停止用C/C++创建新项目了。Rust才是无垃圾回收语言中的最佳选项。出于安全性和可靠性的考量，整个软件行业都该弃用这两种陈旧的语言。”</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/13/1395ca7b365df777206d136a72f20d0b.png\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>从C++专家到“Rust 传播者”</h2><p></p><p>&nbsp;</p><p>Mark Russinovich 本人是著名的黑客和逆向工程大师，2005年，曾运用逆向工程在索尼DRM产品中发现 <a href=\"https://www.csoonline.com/article/2998952/sony-bmg-rootkit-scandal-10-years-later.html\">rootkit</a>\"&nbsp;复制保护有害程序。该曝光事件在当时极其有名，因为 rootkit 性质恶劣，它通过修改操作系统，阻止计算复刻CD 副本，并无法卸载，甚至无法被反病毒和反间谍程序检测到，为其他恶意软件打开了渗透Windows PC 的大门。另外，他还曾利用闲暇时间写过三本安全相关的小说（堪称摸鱼大师）。</p><p>&nbsp;</p><p>在Reddit上，他被人誉为“地球上最有才华的 C/C++ 程序员之一”。在加入微软之前，Russinovich 编写并发布了数十个流行的 Windows 管理和诊断实用程序。 2006 年，微软收购了他一手创办起来的企业Winternals Software，Russinovich 也因此加入微软，成为微软技术研究员——这是它可以授予的最高荣誉之一，随后职位变更为微软 Azure 主架构师以及CTO。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bc/bc6c5ffc7e1461b0e078eb5b0cd8eeb5.png\" /></p><p></p><p>&nbsp;</p><p>截图来源：<a href=\"https://www.linkedin.com/in/markrussinovich/\">https://www.linkedin.com/in/markrussinovich/</a>\"</p><p>&nbsp;</p><p>因其微软Azure CTO的身份，Mark Russinovich 的评论值得注意，因为微软的核心产品，如 Windows、Office 和 SQL Server，主要是用 C 和 C++ 编写的。而在Azure 云平台上得到广泛应用的Linux也是如此，主要语言为&nbsp;C 和 C++。根据报道，Linux缔造者Linus Torvalds已经证实，除非出现不可预见的特殊状况，否则Linux 6.1版内核将使用Rust代码。作为向来以C语言编写，同时包含少量汇编及胶水脚本的传世项目，Linux对Rust的接纳堪称里程碑式事件。</p><p>&nbsp;</p><p>Rust是Graydon Hoare出于个人爱好设计的编程语言，于2006年在Mozilla初步成型，并在2010年正式亮相。随着2015年Rust 1.0的发布，它也逐渐以C/C++替代选项的姿态得到人们的广泛关注。</p><p>&nbsp;</p><p>自那时起，Rust连续七年成为Stack Overflow年度调查中最受欢迎的编程语言。尽管学习难度不低，但它还是被各大科技巨头先后纳入自家项目当中。</p><p>&nbsp;</p><p>苹果、亚马逊、谷歌、Meta乃至<a href=\"https://www.infoq.cn/article/SVuuVZgX7DYY3xt1fYyw\">微软</a>\"等等，都已经在功能开发和实际生产中使用Rust。<a href=\"https://mp.weixin.qq.com/s/Dq37UGTOZ3zYbbw7UdiYFA\">Cloudflare最近大肆宣传的全新HTTP代理Pingora</a>\"也是用Rust编写而成，据称在提高性能的同时削减了CPU与内存用量。</p><p>&nbsp;</p><p>Rust的最大优势在于出现内存损坏bug的几率更低，也就让软件变得更加安全。至少自2019年以来，微软就一直在讨论放弃C/C++、转用Rust的可能性。微软还在开发自己的云内存安全编程语言，即Verona项目。所以，Russinovich这次提出放弃C/C++的主张，可以说是早有先例。</p><p>&nbsp;</p><p>另外，这也不是微软第一次公开支持 Rust。三年前，<a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651017880&amp;idx=4&amp;sn=c024f9398fafeb33909904322e9217e3&amp;chksm=bdbeaacb8ac923dd18158c18aaab78603c08a5cb53c0fbb95a6bcbff2e9747ff3220ccb7b6d2&amp;scene=27#wechat_redirect\">微软安全响应中心</a>\"(MSRC)曾在博客上发表文章表示“ Rust 是目前 C 和 C++ 的最佳替代品”。 MSRC 团队还表示，“大多数修复的漏洞和分配的 CVE 都是由开发人员无意中将内存损坏错误插入到其 C 和 C++ 的代码中造成的。自2006年以来，微软修复的CVE中约有70%跟内存安全问题相关。这意味着，如果该软件是用 Rust 编写的，那么这些安全问题很可能会被消除。”</p><p>&nbsp;</p><p>外媒The Register询问了Russinovich的建议是否会在全公司内部推行，但微软方面拒绝置评。</p><p>当然，单靠Rust本身并不足以保障软件安全。它虽然提供针对内存安全漏洞的防御，但却无法消除其他威胁元素。</p><p>&nbsp;</p><p>正如Rust说明文档所言，“Rust是种既安全、又不那么安全的语言。”开发者有可能在某些任务中编写出不安全的Rust代码，这是无法单靠语言自身解决的问题。另外，Rust也解决不了健全软件设计范畴之外的攻击向量（例如社会工程）。但必须承认，Rust的品质相当过硬，在自己的领地内足以支撑起更强的安全信心。</p><p>&nbsp;</p><p>Rust基金会执行董事兼CEO Rebecca Rumbul在采访中表示，“我们希望各方的支持和肯定能推动针对Rust基础设施和技术社区的持续投入，确保Rust能够在未来的发展道路上延续安全、可靠和可持续等优势。”</p><p>&nbsp;</p><p></p><h2>C++之父：ISO C++已经实现了可靠的内存安全</h2><p></p><p>&nbsp;</p><p>对此，外媒请C++缔造者Bjarne Stroustrup发表了评论。在回复中，Stroustrup站在C++的立场做了一番辩护。</p><p>&nbsp;</p><p>“人们总是迷恋那些看似能让生活更轻松的新事物，这一点在企业高管身上体现得尤其明显。”</p><p>&nbsp;</p><p>“另外，选择新事物也能激起人们的兴奋之情；相比之下，解决旧有知名工具中的已知问题就显得没那么‘酷’。很遗憾，新语言往往需要多年历练和完善，才能在广泛的应用领域中获得与成熟语言相比肩的水平。但大多数人看不到一点，而且总爱发表一些非常片面的评论。”</p><p>&nbsp;</p><p>Stroustrup表示，“当然，安全性在大多数开发场景下都至关重要，所以多年来我一直致力于提高C++的安全性。”</p><p>&nbsp;</p><p>“我们现在已经在ISO C++中实现了可靠的完美类型与内存安全。也就是说，每个对象都会根据它的定义类型进行使用。具体而言，我们消除了空指针问题、能够捕捉范围错误，并消除了数据争用。请注意，包括Rust在内，任何一种号称‘安全’的语言都无法彻底避免风险代码。”</p><p>&nbsp;</p><p>Stroustrup还以参与编写的C++ Core指南为例，提出“这份指南的基本思路，就是定义一组必须遵循的安全规则，而后通过静态分析强制执行这些规则。之所以需要这些规则，是因为任意C或C++代码本身无法自证安全。”</p><p>&nbsp;</p><p>“这就是符合ISO标准的C++代码，可以强制要求开发者通过分析器保障代码安全和更新。目前，微软Visual Studio、Clang Tidy等都提供类似的分析器实现选项。”</p><p>&nbsp;</p><p>“C++正在积极进步，而且已经在实际应用当中发挥出良好的灵活性和性能表现。当前，各类项目中部署的C++代码多达数十亿行。”</p><p>&nbsp;</p><p>“所以无论是直接替换掉这些C++代码，还是所谓让它们更加‘安全’，都会是一项艰巨的任务。如果没有分期分批、持之以恒的努力，大量不安全的C代码和陈旧C++代码将‘永远’存在。纵观历史，在颠覆性革命出现惨烈失败之后，更温和的演进方式往往能够最终取得成功。”</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.theregister.com/2022/09/20/rust_microsoft_c/\">https://www.theregister.com/2022/09/20/rust_microsoft_c/</a>\"</p><p><a href=\"https://devclass.com/2022/09/20/microsoft-azure-cto-on-c-c/\">https://devclass.com/2022/09/20/microsoft-azure-cto-on-c-c/</a>\"</p><p><a href=\"https://www.csoonline.com/article/2998952/sony-bmg-rootkit-scandal-10-years-later.html\">https://www.csoonline.com/article/2998952/sony-bmg-rootkit-scandal-10-years-later.html</a>\"</p><p><a href=\"https://news.ycombinator.com/item?id=32905885\">https://news.ycombinator.com/item?id=32905885</a>\"</p><p><a href=\"https://www.reddit.com/r/programming/comments/xj3muf/mark_russinovich_azure_cto_its_time_to_halt/\">https://www.reddit.com/r/programming/comments/xj3muf/mark_russinovich_azure_cto_its_time_to_halt/</a>\"</p>",
    "publish_time": "2022-09-21 14:51:11",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "甲骨文出现可访问客户数据的云隔离漏洞，现已修复",
    "url": "https://www.infoq.cn/article/LXapis10RZeLMLDK2hsx",
    "summary": "<p>当地时间9月20日，<a href=\"https://www.wiz.io/blog/attachme-oracle-cloud-vulnerability-allows-unauthorized-cross-tenant-volume-access\">Wiz 安全研究人员</a>\"称，甲骨文云基础设施 (OCI) 出现了一个云隔离漏洞，在修补之前，所有 OCI 客户都可能成为攻击者的目标。只要攻击者拥有其 Oracle Cloud Identifier (OCID)，就可以读写任何未附加的存储卷或允许多重附加的附加存储卷，从而导致敏感数据被窃取或通过可执行文件操作发起更具破坏性的攻击。</p><p>&nbsp;</p><p>幸运的是，Wiz 的 Elad Gabay 表示，在向甲骨文披露漏洞后，这家 IT 巨头“在 24 小时内”修补了安全漏洞，而且修复过程中不需要客户采取任何行动。</p><p>&nbsp;</p><p>据悉，这个漏洞被称为 AttachMe，是报告过的最严重的云漏洞之一，因为它可能会影响所有 OCI 客户。根据 Wiz 的说法，利用 AttachMe 的详细要求是：&nbsp;</p><p>&nbsp;</p><p>攻击者必须知道目标卷的 OCID——虽然 OCID 通常是私有的，但它们不被视为机密，因此这个要求很容易实现。攻击者的计算实例必须与目标卷在同一个可用域 (AD) 中——这个条件很容易满足，因为可用区的数量相对较少（某些区域最多三个），因此可以通过枚举法找出。目标卷必须是分离的或附加为可共享的——分离的卷相对常见，因为默认情况下与终止的计算实例关联的引导卷不会被删除。此外，备份数据卷通常不附加到正在运行的计算实例。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cf/cffd16db51ca5dae6040f1beb53edb62.png\" /></p><p>&nbsp;</p><p>据悉，Wiz 工程师是在夏天为自己的技术堆栈构建 OCI 连接器时发现的这个漏洞。他们在这个过程中发现，他们可以将任何人的可用虚拟磁盘附加到自己的虚拟机实例上。Wiz 研究负责人 Shir Tamari 在一系列关于该漏洞的<a href=\"https://twitter.com/shirtamari/status/1572223325719646211\">推文</a>\"中指出，根本原因是 AttachVolume API 中缺乏权限验证。他指出，这也是 Wiz 研究人员第一次在云服务提供商的基础设施 (IaaS) 中发现此类跨租户漏洞。</p><p>&nbsp;</p><p>今年早些时候，Wiz 研究人员还发现了一个<a href=\"https://www.theregister.com/2022/04/28/microsoft_azure_postgresql/\">类似的云隔离漏洞</a>\"，该漏洞影响了 Azure 中的特定云服务。微软修复的这些缺陷存在于 Azure Database for PostgreSQL 灵活服务器的身份验证过程中，一旦被利用，任何 Postgres 管理员可以获得超级用户权限并访问其他客户的数据库。就在上个月，相同类型的 PostgreSQL 漏洞也影响了谷歌云服务。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.wiz.io/blog/attachme-oracle-cloud-vulnerability-allows-unauthorized-cross-tenant-volume-access\">https://www.wiz.io/blog/attachme-oracle-cloud-vulnerability-allows-unauthorized-cross-tenant-volume-access</a>\"</p><p><a href=\"https://www.theregister.com/2022/09/21/oracle_fixes_critical_cloud_vuln/\">https://www.theregister.com/2022/09/21/oracle_fixes_critical_cloud_vuln/</a>\"</p>",
    "publish_time": "2022-09-21 15:42:06",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "满心欢喜入职 Gitpod 一年后失望离开：垃圾邮件当OKR、天天造势但就不兑现承诺",
    "url": "https://www.infoq.cn/article/4Q0j77VWKMRCsck9NWZc",
    "summary": "<p>&nbsp;</p><p></p><blockquote>去年，选择了房车露营生活的 Geoffrey Huntley 受邀请加入了 Gitpod，远程办公、充满才华横溢的人、开源等因素都让他选择加入Gitpod。Gitpod 是一个开源的开发者平台，可以自动配置现成代码的开发者环境。Gitpod 公司则是在2020年成立，目前重点放在了云上的自动化开发环境。&nbsp;当时的 Huntley 在<a href=\"https://ghuntley.com/a-new-chapter/\">文章中</a>\"称赞道：过去几年，Gitpod 一直是我工具包中一个有意义且关键的软件，因为 Gitpod 让我能够在任何地方在任何设备上进行开发。“我可以连续几个小时谈论 Gitpod 所做的工作多么有意义，以及它如何让开源维护者更容易为自己的项目吸引新的贡献者。”&nbsp;不过在Gitpod任职一年多后，Huntley 便选择了离职，并写了博文来讲述自己离开的原因。他表示自己离开的原因很复杂，但促使其下定决心的是那封“让人恶心”的内部邮件，“它打碎了我的归属感，让我迫不及待想要逃离……”&nbsp;我们对 Huntley 叙述的内容进行了整理，也希望借此机会一窥 Gitpod 现在面临的内外部挑战。</blockquote><p></p><p>&nbsp;</p><p></p><h2>Gitpod 内部问题</h2><p></p><p></p><h4>两年过去，管理面板仍直接向网络开放</h4><p></p><p>&nbsp;</p><p>在刚刚加入公司的时候，我不安地发现<a href=\"https://gitpod.io/admin\">https://gitpod.io/admin</a>\"&nbsp;就那么直接地向网络开放，并在内部员工间传来传去。而差不多两年过去，全体员工仍然可以通过个人GitHub账户下载客户的源代码和环境变量。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/1b/1b096e32567243ba87b9c8df95ce94fe.png\" /></p><p></p><p>&nbsp;“可真「刑」：Gitpod可以直接下载用户工作区的数据压缩包”</p><p>&nbsp;</p><p>早在2021年3月，曾经发生过一起安全事件。当时公司在生产环境中部署了管理面板访问通道，而且默认完全开放、不经任何身份验证，也从未对客户发出过提醒。事件之后，Gitpod已经筹集到3600万美元风险投资，所以至少该请位安全工程师了吧……但是并没有。</p><p>&nbsp;</p><p></p><h4>客户们怨声载道</h4><p></p><p>&nbsp;</p><p>Gitpod 嘴上把服务客户喊得山响，但实际行动却始终跟不上。</p><p>&nbsp;</p><p></p><blockquote>别用@gitpod——他们礼拜五宕机，导致我三天做不了开发，还有一整天的代码彻底丢失。他们的客户支持啥帮也忙不上，连帮我查找邮件地址都做不到……&nbsp;— Ryan George (@RyanGGeorge)&nbsp;<a href=\"https://twitter.com/RyanGGeorge/status/1571877537155878912?ref_src=twsrc%5Etfw\">2022年9月19日</a>\"</blockquote><p></p><p>&nbsp;</p><p>当产品质量和服务可用性的大问题得不到解决时，拼命吸引客户有意义吗？没有，只会招来更多骂声。</p><p>&nbsp;</p><p></p><h4>天天为DevX造势，但迟迟无法兑现</h4><p></p><p>&nbsp;</p><p>Gitpod把大量精力花在了宣传“开发者体验至上”的理念上。但纵观整个工作经历，我发现公司连内部开发员工的体验都不关心。</p><p>&nbsp;</p><p>根据最新统计，Gitpod有11名员工全职从事软件开发。大家顶着300毫秒的延迟用亚太及日本（JAPAC）的Gitpod服务操作欧洲或北美的集群。于是问题来了：</p><p>&nbsp;</p><p></p><blockquote>“当这帮员工每天受到糟糕开发体验的折磨，同时看到公司随时强调DevX开发体验的重要性时，内心会作何感想？”</blockquote><p></p><p>&nbsp;</p><p>已关闭、未解决的问题包括：</p><p>&nbsp;</p><p>GItpod新加坡区，问题#5534：<a href=\"https://github.com/gitpod-io/gitpod/issues/5534\">https://github.com/gitpod-io/gitpod/issues/5534</a>\"</p><p>Gitpod孟买区，问题#6139：<a href=\"https://github.com/gitpod-io/gitpod/issues/6139\">https://github.com/gitpod-io/gitpod/issues/6139</a>\"&nbsp;</p><p>亚太数据中心，问题#4526：<a href=\"https://github.com/gitpod-io/gitpod/issues/4526\">https://github.com/gitpod-io/gitpod/issues/4526</a>\"</p><p>&nbsp;</p><p></p><h4>用垃圾邮件当OKR推动增长策略</h4><p></p><p>&nbsp;</p><p>这里先向大家“科普”一个新词儿，Gitpod化。所谓Gitpod化，就是往流行的开源repo中发送垃圾邮件，把相应的PR设计成广告展示。</p><p>&nbsp;</p><p>公司甚至专门定了OKR，要求员工宣传Gitpod的优点。因为种种行为太过火，很多项目的维护者甚至在自述文件里专门强调，不会接收/合并.gitpod.yml和“在Gitpod中打开”选项。</p><p>&nbsp;</p><p>有开发者在<a href=\"https://twitter.com/joasahacker/status/1563443194183892993/\">推特</a>\"上讽刺道：笑死<a href=\"https://t.co/UvWckrXX0y\">http://github.com/gitpod-for-os</a>\"看起来还是在人工发小广告，“有幸”成为第一个收到小广告的人。</p><p>&nbsp;</p><p>情况已经显而易见。我曾多次向领导层建言，提醒他们在开源项目里发垃圾邮件的营销策略实在是败人缘。但结果嘛……“问题已关闭，未解决”。</p><p></p><h4>垃圾领导</h4><p></p><p>&nbsp;</p><p>如果大家身为新晋领导，看着身边的老员工一个个离开，你会怎么想？反正咱们这位老大想得很开：都是别人的错。</p><p>&nbsp;</p><p></p><blockquote>你们这些资深老员工离职的时候，真的应该好好做一番自我反省。— Mike Nikles (@mikenikles)&nbsp;<a href=\"https://twitter.com/mikenikles/status/1562413358787223552?ref_src=twsrc%5Etfw\">2022年8月24日</a>\"</blockquote><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ee/ee9b513c24cecb87598ae9989b6a41c5.png\" /></p><p></p><p>说了半天都是白说，谁离职谁错就完事了……</p><p></p><h2>面临的外部挑战&nbsp;</h2><p></p><p></p><h4>微软正在战略性驱逐Gitpod</h4><p></p><p>&nbsp;</p><p>自由竞争的破坏者微软又出手了，这次的战场是在Visual Studio Code生态系统之内。面向全体VSCode用户，微软先后推出了GitHub Codespaces和Visual Studio Codespaces两款与Gitpod 高度重合的服务。更要命的是，人家的产品没有讨厌的弹窗广告。</p><p>&nbsp;</p><p>其实微软的作法也不能说有多过分，毕竟从事语言工具开发的工程师身份不菲。根据粗略计算，Gitpod 每年至少要再额外砸下 900 万美元的薪酬成本才能跟GitHub Visual Studio Codespaces 正面竞争。另外有博文披露，后续 Gitpod 将不能合法使用微软维护的 VSCode 语言服务器。</p><p>&nbsp;</p><p>跟微软竞争向来不是什么好主意。微软最擅长的就是把自家方案设置成默认值，Octopus Deploy公司创始人兼CEO Paul Stovell在2016年就亲身经历过这家软件巨头的“毒打”。</p><p>&nbsp;</p><p></p><blockquote>一夜之间，微软的产品就成了设置选项。我们在Build 2016大会上展示了自己的方案，但总有人跑到我们展台问：微软也有同类产品，我们为什么要用你们家的？问题是“微软同类产品”才刚刚公布，我们哪里知道呢……</blockquote><p></p><p>&nbsp;</p><p></p><h4>可重现开发者环境是一波浪潮，而非特定产品功能</h4><p></p><p>&nbsp;</p><p>可重现的开发者环境长期不受重视，直到最近才开始逐渐普及。也许再过几年，这类环境将成为开发流程中的标配。但我觉得整个行业正走向跟Gitpod（即.&nbsp;workspace-images&nbsp;和&nbsp;.gitpod.yml）不同的方向。</p><p>&nbsp;</p><p>workspace-images&nbsp;的问题在于，除非 Gitpod 员工能在每一个 Docker 镜像中单独更新，否则客户根本得不到安全修复。</p><p>&nbsp;</p><p>至于.gitpod.yml，它的问题是规定了一种特定的开发者环境重现方式，这种方式会造成供应商锁定，而与之竞争的&nbsp;devcontainer.json开放标准则是微软VSCode和GitHubVisual Studio Codespaces中的默认选项。</p><p>&nbsp;</p><p>如果问我从业这40年来总结出的核心经验是什么，那就是无论微软把什么东西当成默认选项发布，最终都能赢得市场。</p><p>&nbsp;</p><p>但无论是 Gitpod 还是微软，我觉得他们都忽略了行业正在超越Docker、转向Nix（或Guix）等新兴工具的整体趋势。这些工具不仅能提供可重现的开发者环境，同时也包含更加灵活自主的软件供应链工具（可通过源代码/二进制文件替换）和软件物料清单。</p><p>&nbsp;</p><p></p><blockquote>Nix唯一的缺点就是让人们迅速与现实脱节。如果各位已经忘了依赖项版本维护起来有多痛苦，请马上使用Nix。&nbsp;— Mitchell Hashimoto (@mitchellh)&nbsp;<a href=\"https://twitter.com/mitchellh/status/1491102567296040961?ref_src=twsrc%5Etfw\">2022年2月8日</a>\"</blockquote><p></p><p>&nbsp;</p><p>我可以大方承认，我自己就是Nix的铁粉。四年之前，这款由学术界酝酿出的构建工具占据了我的心，并迅速发展为市场主流。通过Cachix和nix这类工具，用户能够以独立于供应商之外的姿态获得与Gitpod相同的预构建+可重现环境功能集。</p><p>&nbsp;</p><p>这当然很好，只不过面对糟糕的经济环境，大家的心态都变得更加保守持重，所以我觉得没有哪款产品（包括nix）能够在短时间内成为可重现开发环境的客观标准。</p><p>&nbsp;</p><p>所以，谁能更好地融入企业的现有工作方式，最大限度减少相应的人员/流程变更，谁就能降低产品普及的成本风险，从而真正在市场上获得认可。</p><p>&nbsp;</p><p>也正因为如此，我很难相信人们会愿意在自己的每个git repo中添加&nbsp;.gitpod.yml。在Gitpod工作时，我也多次在内部讨论中提到过这个问题，毕竟开源维护者一直强烈反对“再加个yml”的作法。</p><p></p><h4>Gitpod 工作流很快就将不再独特</h4><p></p><p>&nbsp;</p><p>看看下面的内容，我的意思不言而喻了。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/59/59095a3e04d80b6223154eeb6c1b36d7.png\" /></p><p></p><p></p><h4>Kubernetes不是那个正确的抽象层</h4><p></p><p>&nbsp;</p><p>Gitpod的开发环境立足于Kubernetres pod。虽然后者非常简洁，但经过认真考量，我觉得Kubernetes并不是适合Gitpod的正确抽象层。原因有以下几点：</p><p>&nbsp;</p><p>围绕Kubernetes进行产品设计，会把受众群体限制在使用容器的开发者之内。在糟糕的整体经济环境下，企业需要一款能够面向所有软件开发场景的统一工具——包括Windows桌面开发、macOS移动开发和数据科学（能够访问强大的GPU）。Kubernetes太复杂了。企业在Kubernetes方面本身就缺乏丰富的经验，因此以本地产品的形式推广/销售/支持Gitpod将极为困难，而且需要辅以相应的文化转型。</p><p>&nbsp;</p><p></p><h4>一线老员工的真实想法</h4><p></p><p>&nbsp;</p><p>我认为对于远程代码执行即服务这类业务（即运行不受信的公共工作负载）来说，容器的环境隔离技术还不够安全。Gitpod确实利用Linux命名空间实现了不少酷炫的功能，但这样既不够安全，也要承担相应的代价。</p><p>&nbsp;</p><p>由于上述原因，之前两年我们一直无法在Gitpod上原生运行Kubernetes。客户之所以愿意把开发环境从本地许配电脑转移至云端，最关键的动机之一就是想要运行云原生工作流和应用程序。但Gitpod做不到这一点，那还折腾什么劲。</p><p></p><h2>结束语</h2><p></p><p>&nbsp;</p><p>Huntley 表示自己很珍惜在Gitpod工作的时光，同事们既亲切又聪明。但他认为，要让产品真正发光发热，Gitpod 还需要解决结构、战略和领导等层面的诸多问题。“我是等不到那天了，所以就此别过吧。”</p><p>&nbsp;</p><p>离开 Gitpod 后，Huntley 目前投身到了<a href=\"https://technews.tw/2021/12/01/nft-the-pirate-bay/\">NFT 行业</a>\"，创建了 <a href=\"https://thenftbay.org/\">thenftbay.org</a>\"。Huntley 称自己将以太链和 SOL 链上所有NFT 文件打包成一个17.76TB 的压缩文件，并将 BT 种子放在该网站上供任何人下载。</p><p>&nbsp;</p><p>在该网站上可以找到很多热门NFT，但无论点击哪个NFT，都会指向那个巨大的压缩包，无法单独下载。Geoffrey Huntley 表示，他想用盗版让人们意识到自己买的 NFT 究竟是什么，真正关注 NFT 的价值，进而不会被卖家当成韭菜。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://ghuntley.com/tea/\">https://ghuntley.com/tea/</a>\"</p><p><a href=\"https://technews.tw/2021/12/01/nft-the-pirate-bay/\">https://technews.tw/2021/12/01/nft-the-pirate-bay/</a>\"</p>",
    "publish_time": "2022-09-21 15:47:08",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从 Hadoop 到云原生， 大数据平台如何做存算分离",
    "url": "https://www.infoq.cn/article/4U8V7NRh31OTQYbkegIW",
    "summary": "<p>Hadoop 的诞生改变了企业对数据的存储、处理和分析的过程，加速了大数据的发展，受到广泛的应用，给整个行业带来了变革意义的改变；随着云计算时代的到来， 存算分离的架构受到青睐，企业开开始对 Hadoop 的架构进行改造。</p><p></p><p>今天与大家一起简单回顾 Hadoop 架构以及目前市面上不同的存算分离的架构方案，他们的利弊各有哪些，希望可以给正在存算分离架构改造的企业一些参考和启发。</p><p></p><h2>01 - Hadoop 存算耦合架构回顾</h2><p></p><p>2006 年 Hadoop 刚发布，这是一个 all-in-one 的套装，最早有三个核心的组件：MapReduce 负责计算，YARN 负责资源调度，HDFS 分布式文件系统，负责存数据。</p><p><img src=\"https://static001.geekbang.org/infoq/88/883906ab2d27078902c11edda796699e.png\" /></p><p>在这三个组件中，发展最迅速和多元的是计算组件这一层，最早只有一个 MapReduce，但业界很快在计算层上面各显神通，造出了一大堆的轮子，包括有 MapReduce，Tez，Spark 这样的计算框架，Hive 这类数据仓库，还有 Presto、Impala 查询引擎，各种各样的组件。配合这些组件的，还有像 scoop 这样的数据流转采集的组件也很丰富，一共有几十款。</p><p><img src=\"https://static001.geekbang.org/infoq/08/08047f04f2034b810611ca2e02eed26d.png\" /></p><p>底层存储经过了大概 10 年左右的时间，一直是 HDFS 一枝独秀，带来的一个结果就是它会成为所有计算组件默认的设计选择。上面提到的这些大数据生态里发展出来的各种组件，都是面向HDFS API 去做设计的。有些组件也会非常深入的利用 HDFS 的一些能力，比如深入看 Hbase，在写 WAL log 的时候就直接利用了HDFS 的一些很内核的能力，才能达到一个低时延的写入；比如说像最早的 MapReduce 和 Spark 也提供了数据亲和性（Data Locality）的能力，这些都是HDFS 提供的一些特殊的 API。</p><p></p><p>这些大数据组件面向 HDFS API 设计的做法， 为后续数据平台上云带来了潜在的挑战。</p><p></p><p>下面是一个简化的局部的架构图，通过这张图快速理解 Hadoop 存算耦合架构。在这张图有三个节点，每个节点里面它都承载了 HDFS DataNode 的存数据的角色，但同时 YARN 也会在这里布一个 Node Manager的进程。有了 Node Manager 之后，YARN 就会认为 HDFS DataNode 的节点，在其管理范围之内，当需要计算任务可以分发到这个节点上来完成。存储任务和数据就在同一个机器里了，计算的时候就可以直接读到磁盘上的数据。</p><p><img src=\"https://static001.geekbang.org/infoq/de/de86681774017cd912e6240148f24db5.png\" /></p><p></p><p>为什么 Hadoop 在设计之初是一个存储计算耦合的架构？</p><p></p><p>一个不能忽略的重要的原因是，网络通讯和硬件的局限。2006年，当时云计算几乎还没有发展，亚马逊才发布第一个服务而已。</p><p></p><p>在机房里面，当时我们面对的最大的问题就是网卡，主流的还是百兆网卡，刚开始用千兆网卡。这个时候，大数据使用的磁盘，吞吐大概是 50MB/s，对网络带宽来说要乘以 8，也就是 400M bps；如果一个节点里放 8 块盘，吞吐都跑起来，就需要几千兆带宽传输了，但是网卡最高也就1Gb。这就意味着每一个节点网络带宽根本不够，无法让这个节点里面的所有的磁盘的能力都发挥出来。所以如果计算任务在网络的一端，数据在数据节点在网络的另一端，计算任务需要说通过网络传输来进行，网络带宽是一个最明显的瓶颈。</p><p></p><h2>02 - 存算分离的需求出现</h2><p></p><p>首先从，企业的需求看，从 2006 年发展到 2016 年左右，这十年我们看到了一些新的变化，第一企业数据增长很快，但是算力的需求其实长得没那么快。这些任务靠人开发，不会发生一天一倍的去涨的情况，但是产生的数据的速度是是非常快的，有可能是指数型的；而且有些数据产生出来，也不一定马上知道怎么用，但未来会用，所以企业都会先把数据尽可能全量的去存起来，再去挖掘它的价值。</p><p></p><p>在这个背景下，存算耦合的硬件的拓扑的架构就给扩容带来了一个影响，当存储不够，就要去加机器。但是不能只加机器，不能只有硬盘，因为在存算耦合的架构上，数据的节点还需要负责计算，所以 CPU 和内存也不能太差。因此配置的机器都是计算与存储配置非常平衡的机器，在提供足够存储容量的同时，也提供了等量的算力。但实际场景中算力的需求没涨。这样扩出来的算力对企业来说造成了更大的浪费，整个集群在存储和 I/O 上的资源利用率可能是非常不平衡的，当集群越大，这种不平衡就越严重。而且另外买机器也挺难的，购买的机器必须是计算与存储平衡的。</p><p></p><p>而且，数据调度亲和性的策略在实际的业务中未必能发挥作用，因为数据有可能会有很明显的倾斜，可能会有很局部的热点，需要非常多的算力。大数据平台的任务可能调度到有限节点上，I/O 仍然有可能成为瓶颈。</p><p></p><p>在这个过程中硬件也有变化，给存算分离架构带来了可行性。首先，10Gb万兆网卡普及了，今天机房里或者包括云上也开始有更多的 20Gb、40Gb，甚至 50Gb，有些 AI 的场景甚至有100Gb的网卡，网络的带宽其实加大了比以前提升了100倍之多。</p><p><img src=\"https://static001.geekbang.org/infoq/e1/e1be9e4e82194bc4aaa5e832deb6fc03.png\" /></p><p></p><p>存储方面，在今天大的数据集群里面，许多企业还是使用磁盘来存储，磁盘的吞吐提升了一倍，从 50MB/s 每秒提升到 100MB/s。一个配置了万兆的网卡的实例，可以支持差不多 12 块磁盘的峰值吞吐，对于大部分企业来说已经够用了，以前网络传输的瓶颈就基本不存在了。</p><p></p><p>不仅网卡，磁盘也在变化，软件也在变化。最早的时候，我们可能用 csv 或者打一个 zip 包，现在有了更高效的压缩算法，比如说有 snappy、lz4、zstandard 这些。而且有了 Avro、Parquet、Orc 这些列存格式。</p><p></p><p>这些变化加在一起，都进一步减小了需要传输的数据量。同时， 网卡在提升，再加上硬硬盘本身的吞吐没增加多少，企业以前曾经要面对的 I/O 的瓶颈就逐渐的在弱化甚至消除，保证了存算分离的可行性。</p><p></p><h2>03- 如何实现存算分离？</h2><p></p><p></p><h3>最初的尝试：在云上独立部署 HDFS</h3><p></p><p>从2013、2014年，行业内开始看到一些存算分离架构的尝试。最初的方案比较简单，就是独立部署 HDFS，不再和负责计算 worker 去混合部署。这个方案在 Hadoop 生态里，没有引入任何的新组件。</p><p>从下面的示意图可以看到， DataNode 节点上不再部署 Node Manager，意味着不再把计算任务发送到 DataNode 节点上。存储成为一个独立集群，计算需要用到的数据都会通过网络来传输，端到端的万兆网卡去支持，网络传输线没有在下图标出。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/46/4615240814b6c7c32738d62e4bf19744.png\" /></p><p></p><p></p><p>在这个改变里，尽管 HDFS 最巧妙的数据本地性这个设计被舍弃了，但由于网络通讯速度的提高， 给集群的配置带来更大的便利。Juicedata 创始人 Davies，2013 年在 Facebook 工作期间，团队就做了这样的实验， 发现这样的一个存算分离的改造，对整个平台性能的影响是仅仅是几个百分点，但是给集群的配置管理带来了一个还很大的便利，可以独立的部署和管理计算节点了。</p><p></p><p>但是这个尝试没有得到进一步发展，是什么原因呢？最大的一个原因，当在机房做这样的改造是可行的，但当我们去使用云上资源的时候，这个方案的弊端就显露了。</p><p></p><p>首先，源自 HDFS 的多副本机制在云上会增加企业的成本。过去，企业在机房使用裸硬盘去搭建一套 HDFS，为了解决裸硬损坏的风险， HDFS 设计了多副本的机制，来保证数据安全性；同时多副本还承载着保证数据可用性的作用。除了磁盘损坏，当某一个 DataNode 的节点临时宕机了，这个节点上的数据访问不到了？多副本机制在可靠性和可用性上都发挥作用。当数据被迁移到云上时，云提供给用户的是经过多副本机制存储的云盘，不再是裸硬盘了，企业用这块云盘去搭一个HDFS，又要做3副本，企业数据在云上要存 9 副本，成本立马飙升了好几倍。</p><p></p><p>后来，云也会提供一些有裸硬盘的机型，但是这类机型往往都非常少，比如说云上有 100 款虚拟机，云盘可以任意配置，但是有裸盘的机型只有 5~10 款，选择余地比较少，这些型号不一定能匹配企业的集群需要。</p><p></p><p>第二个原因， 这个方案不能让企业得到云上的独特价值，比如开箱即用，弹性伸缩，以及按量付费这些云上最大的优势。在云上部署 HDFS， 需要自己创建机器，手动部署和维护，自己监控和运维，而且还不能方便地扩缩容。这种情况下，HDFS 上云实现存算分离，仍然有其痛点。</p><p></p><p>第三个原因，HDFS 本身的局限。首先是，NameNode，只能垂直扩展，并不能分布式扩展说扩出更多的 NameNode 节点，限制了 HDFS 单集群去管理的文件数量。</p><p></p><p>当 NameNode 的资源占用比较多，负载又高的时候就有可能会触发 FullGC（Garbage Collection) 。一旦触发这个问题之后，它会影响到整个 HDFS 集群可用性。系统存储可能宕机，不能读，又无法干预 GC的过程，系统卡多久无法确定。这个也是 HDFS 高负载集群一直以来的痛点。</p><p></p><p>根据实际运维经验，一般在 3 亿文件以内，运维 HDFS 还是比较轻松的，3 亿文件之后运维的复杂度就会明显提升，峰值可能就在 5 亿文件左右，就达到单机群的天花板了。文件量更多，需要引入 HDFS的 Federation 联邦的机制，但是它就增加了很多的运维和管理的成本。</p><p></p><h3>公有云+ 对象存储</h3><p></p><p>随着云计算技术的成熟，企业存储又多了一个选项，对象存储。不同的云厂商有不同的英文缩写名，例如阿里云的对象存储服务叫做 OSS，华为云 OBS，腾讯云 COS，七牛 Kodo；对象存储适用于大规模存储非结构化数据的数据存储架构，其设计的初衷是想满足非常简单的上传下载数据，企业存储系统拥有超级强大的弹性伸缩的能力，还能保证低成本的存储。</p><p></p><p>最早从 AWS 开始，后来所有的云厂商其实都在往这个方向发展，开始推动用对象存储去替代 HDFS。这些方案首先带来了两个 HDFS 无法实现的最明显的好处：</p><p>第一，对象存储是服务化的，开箱即用，不用做任何的部署监控运维这些工作，特别省事儿。第二，弹性伸缩，企业可以按量付费，不用考虑任何的容量规划，开一个对象存储的 bucket ，有多少数据写多少数据，不用担心写满。</p><p></p><p>这些方案相比在云上独立部署 HDFS ， 运维方面是有了很大的简化。但当对象存储被用来去支持复杂的 Hadoop 这样的数据系统，就会发现如下的一些问题。</p><p>1. 文件 Listing 的性能比较弱。Listing 是文件系统中最基础的一个操作。我们在文件系统中 List 目录，包括 HDFS 里面 List 目录，都是非常轻量快的操作。它的性能是源于在文件系统中，数据是一个树形结构。</p><p>对象存储没有树形结构的，它的整个存储结构是扁平的。当用户需要存储成千上万，甚至数亿个对象，对象存储需要做的是用 Key 去建立一份索引，Key 可以理解为文件名是该对象唯一标识符。如果用户要执行 Listing，只能在这个索引里面去搜索，搜索的性能相比树形结构的查找弱很多。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/67/672585c6bbdd4a71aacdbbd472da60d9.png\" /></p><p>文件系统的结构：树状，适用于按目录组织数据进行计算处理</p><p>对象存储的结构：扁平，适用于数据存储和直接访问&nbsp;</p><p></p><p>2. 对象存储没有原子 Rename， 影响任务的稳定性和性能。在 ETL 的计算模型中，每个子任务完成会将结果写入临时目录，等到整个任务完成后，把临时目录改名为正式目录名即可。</p><p>这样的改名操作在 HDFS 和其他文件系统中是原子的，速度快，而且有事务性保证。但由于对象存储没有原生目录结构，处理 rename 操作是一个模拟过程，会包含大量系统内部的数据拷贝，会耗时很多，而且没有事务保证。</p><p></p><p>用户在使用对象存储时，常用文件系统中的路径写法作为对象的 Key，比如 “/order/2-22/8/10/detail”。改名操作时，需要搜索出所有 Key 中包含目录名的对象，用新的目录名作为 Key 复制所有的对象，此时会发生数据拷贝，性能会比文件系统差很多，可能慢一两个数量级，而且这个过程因为没有事务保证，所以过程中有失败的风险，造成数据不正确。这样看起来很细节的差异对整个任务 pipeline 的性能和稳定性都会有影响。</p><p></p><p>对象存储数据最终一致性的机制，会降低计算过程的稳定性和正确性。举个例子，比如多个客户端在一个路径下并发创建文件，这是调用 List API 得到的文件列表可能并不能包含所有创建好的文件列表，而是要等一段时间让对象存储的内部系统完成数据一致性同步。这样的访问模式在 ETL 数据处理中经常用到，最终一致性可能会影响到数据的正确性和任务的稳定性。</p><p></p><p>为了解决对象存储存在无法保持强数据一致性的问题。AWS 发布过一个名为 EMRFS 的产品。AWS EMRFS 的做法是，因为知道 Listing 结果可能不对，所以另外准备一个 DynamoDB 数据库， 比如 Spark 在写文件的时候，同时也写一份文件列表到 DynameDB 里，再建立一个机制，不断调用对象存储的 List API，和数据库里面存下来的结果做比较，直到相等了再返回。但这个机制的稳定性不好，它会受对象存储所在的区域的负载高低影响忽快忽慢，不是一个理想的解决方式。</p><p></p><p>除了上述由于文件系统和对象存储本身差异带来的问题外，在对象存储上使用 Hadoop 的另一大问题，就是对象存储对于 Hadoop 组件的兼容性相对弱。在文章开头 Hadoop 架构介绍中提到了 HDFS 是 Hadoop 生态早期几乎唯一的存储选择，上层各种各样的组件都是面向 HDFS API 开发的。而到了对象存储上，数据存储的结构变了， API 也变了。</p><p></p><p>云厂商为了能够与现有的这些 Hadoop 组件适配，一方面需要去改造组件和云对象存储之间的 connector，另一方面还需要给上层的组件去打 patch ，对于每一个组件都一一的去验证兼容性，这对公有云厂商来说意味着巨大的工作量。所以，目前公有云它提供的大数据组件里面能包含的计算组件是有是有限的，一般只能包含 Spark、 Hive、 Presto 三个常用组件，而且还只能包含少数几个版本。这样就会给将大数据平台迁移上云，或者有需要使用自己的发行版和组件需求的用户带来了挑战。</p><p>企业如何能够享受到对象存储的强大性能，同时又兼顾文件系统的准确性？</p><p></p><h3>对象存储 + JuiceFS</h3><p></p><p>当用户想在对象存储上去进行复杂的数据计算、分析训练这些场景的时候，对象存储确实无法满足企业的需求；这也是我们去做 JuiceFS 的一个出发点，希望能够站在对象存储之上去补充他不擅长的部分，与对象存储一起以比较低廉的价格服务好密集性的数据计算、分析、训练这些场景。</p><p></p><p>JuiceFS + 对象存储是如何工作的呢？通过下图 JuiceFS 在 Hadoop 集群中的部署方式，简单介绍原理。</p><p></p><p>从下面这个简单的示意图看到， YARN 管理的这些执行节点上，都带一个 JuiceFS Hadoop SDK， 这个 SDK 可以保证完整兼容 HDFS。图片下方可以看到， SDK 它需要访问两个部分，左侧是 JuiceFS Meta Engine，右侧是 S3 bucket。Metadata engine 就相当于 HDFS里的 NameNode，整个文件系统的元数据信息会存储在这里，元数据信息包括目录数、文件名，权限时间戳这些信息，并且相应的解决掉了 HDFS NameNode 扩展性 、GC 这些的痛点。</p><p><img src=\"https://static001.geekbang.org/infoq/ed/ed3d02c7b43fd04307c4b601b5971286.png\" /></p><p>另外一边，数据存在 S3 bucket 里面，这里的 S3 bucket 等同于HDFS 中的 DataNode，可以将它看成一大堆海量的磁盘来用，它会管理好的数据存储和副本的相关任务。JuiceFS 就是三个组件组成，JuiceFS Hadoop SDK， Metadata Engine 和 S3 Bucket。</p><p></p><p>相较于直接使用对象存储， JuiceFS 还有哪些优势呢？</p><p>HDFS 100% 完整兼容。这得益于我们最初完整兼容 POSIX 的这个设计。POSIX API 的覆盖程度以及复杂程度是大于 HDFS的，HDFS 在设计的时候就是去简化了 POSIX，因为最先去实现复杂的 API 集，再去简化它就变得非常容易了，所以这也是 JuiceFS 能实现 100%实现 HDFS 完整兼容性的一个原因。同时， 用户可以和 HDFS 一起使用，无需完全替换 HDFS。这也得益于 Hadoop 系统的设计，在一个 Hadoop 集群里，可以配置多个文件系统，JuiceFS 和 HDFS 可以同时使用，并不是互相替代的关系，而是可以互相合作。这样的架构给我们我们现有的集群带来的好处是用户不用完整替代现有的 HDFS 集群，完整替代的工作量和风险上都太大了。用户可以结合着业务，结合着集群的情况，分步分批的去做融合。元数据性能强大，JuiceFS 将元数据引擎独立出来不再依赖于 S3 里面的原数据性能，保证了元数据的性能。使用 JuiceFS 的时候，对底层对象存储的调用简化到只是 get、 put、delete 这三个最基础的操作，像 listing, update 等命令都用不到，在这样的架构下，用户就避开了对象存储元数据性能弱的问题，最终一致性这些问题也都不再存在了。原子 rename, 因为有独立的原数据引擎，JuiceFS 也可以支持原子 rename。缓存，有效提升热数据的访问性能，提供了 data locality 特性。缓存可以让热数据缓存到执行器 worker 节点本地的一些磁盘空间上。有了缓存后，会反复访问的热数据，不需要每次都通过网络去对象存储里面读数据。而且 JuiceFS 特意实现了HDFS 特有的数据本地性的 API，让所有支持数据本地性的上层组件都能重新获得数据亲和性的感知，这会让 YARN 把自己的任务优先调度到已经建立缓存的节点上面，综合的性能可以和存储计算耦合的 HDFS 相当的。兼容 POSIX， 与机器学习、AI 相关的任务应用结合方便。JuiceFS 还兼容 POSIX，可以和机器学习， AI相关的这些业务更便捷地融合。</p><p></p><h2>&nbsp;小结&nbsp;</h2><p></p><p>伴随着企业需求的更迭、基础技术的发展，存储和计算的架构在变，从最初的耦合到分离；实现存算分离方式多样，各有利弊，从直接将 HDFS 部署到云上，到使用公有云提供兼容 Hadoop的方案，再到公有云 + JuiceFS 这样的适合在云上进行复杂大数据计算和存储的方案。对于企业来说，没有银弹，结合自身需求做架构选型才是关键。&nbsp;</p><p></p><p>但无论选什么，保持简单都不会错。</p><p></p><p>作者简介：</p><p>苏锐，Juicedata 合伙人， JuiceFS 的1号成员，一直深度参与在开源社区中支持开发者使用 JuiceFS。历任互联网 O2O 汽车服务品牌功夫洗车创始人 &amp; CEO，豆瓣电影 PM &amp; Tech Lead。在工作期间，经历了早期由 Hadoop 技术栈主导的大数据平台，到云原生时代存算分离的架构变迁。</p>",
    "publish_time": "2022-09-21 16:10:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]