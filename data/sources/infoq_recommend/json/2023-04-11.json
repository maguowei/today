[
  {
    "title": "ThoughtWorks CTO：2025年之前，我们会看到架构的演进，但不会看到革命",
    "url": "https://www.infoq.cn/article/XYlKxH5f3GjBflH31z9h",
    "summary": "<p>在<a href=\"https://qconlondon.com/\">QCon伦敦会议</a>\"的第二天，ThoughtWorks的CTO<a href=\"https://www.linkedin.com/in/rebecca-parsons-871491/\">Rebecca Parsons</a>\"重新审视了<a href=\"https://qconlondon.com/presentation/mar2023/how-will-evolutionary-architecture-evolve\">演进式架构（evolutionary architecture）的理念并设想了在2025年前它将会出现的变化</a>\"。她从演进式架构的定义开始，回顾了每项“能力”和属性，预测了在下一个阶段将会发生的变化。她的结论是，我们会看到演进，但不会看到革命。</p><p></p><p></p><blockquote><a href=\"https://www.thoughtworks.com/en-gb/insights/books/building-evolutionary-architectures\">演进式架构</a>\"支持在多个维度上有指导性的、渐进式的变化。</blockquote><p></p><p></p><p>Parsons解释了为何采用演进这个词而不是敏捷或涌现。在与“演进式架构”一书的合著者Neil Ford进行了一次建设性、强有力的对话后，这个名字被确定了下来。最初，Ford将这种做法称为“涌现式（emergent）”架构。虽然在代码方面，“好”与“坏”相对比较容易达成一致，但在架构方面就并非如此了。定义的指南部分指出了好的架构要有哪些部分组成。</p><p></p><p></p><blockquote>这就是我们引入<a href=\"https://en.wikipedia.org/wiki/Fitness_function#%3a~%3atext=A%20fitness%20function%20is%20a,to%20achieving%20the%20set%20aims.\">适应度函数（fitness function）</a>\"的原因。适应度函数是一个特定的系统在多大程度上反映所需的行为特征的客观描述。</blockquote><p></p><p></p><p>随后，Parsons着重强调了可执行的重要性：在通往生产化的道路上，如何渐进式地增加新的特性并提供可行的机制？</p><p></p><p></p><blockquote>演进式架构的重要实践和推动力之一就是与<a href=\"https://en.wikipedia.org/wiki/Continuous_delivery\">持续交付</a>\"和最终的<a href=\"https://en.wikipedia.org/wiki/Continuous_deployment\">持续部署</a>\"一同实现严谨性和自动化。</blockquote><p></p><p></p><p>这些适应度函数应该被纳入到部署流水线中。</p><p></p><p>定义的最后一部分强调的是多维度方面。她使用一张幻灯片展示了几年前维基百科上的“能力（-ilities）”列表。这个列表后来有了一些变化，例如，更加注重可观测性。列表中的一个谬误是，我们无法最大化所有的能力，因为其中有些能力是互斥的：“有些系统是一次性的，不关心可演进性”。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/news/2023/03/evolutionary-architecture-2025/en/resources/1ilities-1680043256351.jpg\" /></p><p></p><p>接下来，Parsons谈到了如今演进式架构的原则，并预测了它们在未来两年的发展。</p><p></p><p></p><blockquote>个人认为，我们第一次尝试SOA的失败原因之一就是我们在系统周围画了边界。比我们围绕概念画出的边界更多。</blockquote><p></p><p></p><p>最后的责任时刻：为了尽可能多地掌握系统的信息，我们想把决定推迟到最后的责任时刻（responsible moment）。需要做的权衡转换成了“能力”和适应度函数。</p><p></p><p>为可演进性而设计和开发：如果可演进性对你的系统很重要，那么它不仅对你如何编写代码很重要，而且对你如何结构化代码也很重要。</p><p></p><p></p><blockquote>可读性是关键，这就是优质软件指标的作用所在。[...]这就是我们谈论边界、耦合和内聚的时候。</blockquote><p></p><p></p><p>Postel定律：对收到的东西要慷慨，对发送的东西要谨慎。</p><p></p><p></p><blockquote>如果你只需要一个邮政编码，就不要验证收到的地址。这样，如果我决定把它分成两行，你就不需要在意它了。</blockquote><p></p><p></p><p>可测试性架构：测试某项功能的能力以及某项功能的可测试性如何，很好地说明了你的边界划分是否合理。如果你专注于测试金字塔的所有层次，你就会有更好的系统架构。</p><p></p><p>康威定律：可怕的人的问题。任何系统都会反映出所有组织的沟通情况。</p><p></p><p></p><blockquote>如果你想要一个三阶段的流水线，你必定有三个小组。</blockquote><p></p><p></p><p>最后，她谈到了这些原则在未来两年内会受到怎样的影响。根据Parsons的说法，“最后的责任时刻”和Postel定律都不会受到影响。</p><p></p><p>即使这些原则保持不变，但会有更多的创新，从而能够建立起更强大、更具“免疫性”的系统。不仅仅物联网、增强或虚拟现实等系统的复杂性中会融入创新，更多的创新将发生在机器学习模型的测试方式上。人工智能辅助开发会促进不同类型的开发技术的发展，如测试优先开发（Test First Development），即开发人员编写测试，人工智能生成代码，或其他方式。</p><p></p><p>所有这些都将通过增强持续部署流水线、增加对生产中测试的依赖以及扩大适应度函数和方法套件来实现。</p><p></p><p>她在演讲结束时这样总结说：</p><p></p><p></p><blockquote>这些原则自始至终都是不变的，目前还没有迹象表明我们遗漏了什么原则。实践会不断发展，但不会有根本性的改变[......]即使创新会改变工具，但原则是不变的。演进式架构会继续发展，但不太可能会迎来一场革命。</blockquote><p></p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/03/evolutionary-architecture-2025/\">Rebecca Parsons - ThoughtWorks CTO: By 2025 We'll See Evolution in Architecture, But Not Revolution</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/minibook/sihSN688wdNINfNNTWKu\">架构师（2023 年 4 月）</a>\"</p><p><a href=\"https://www.infoq.cn/article/J3ulcioRIXNfR0HDtZjr\">浅析三款大规模分布式文件系统架构设计</a>\"</p><p></p>",
    "publish_time": "2023-04-11 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "JetCache 缓存开源组件设计精要",
    "url": "https://www.infoq.cn/article/cac316dcf2db8cc3d029c1065",
    "summary": "<p>​作者：张隆   阿里电影演出技术中心团队</p><p></p><p></p><blockquote>本文将为大家介绍JetCache缓存开源组件的前世今生，并剖析了JetCache的工作原理及设计优势。</blockquote><p></p><p></p><p></p><h1>一、JetCache的前世今生</h1><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/51/51d67b04e7a02a293a8ff176cb28bb1e.png\" /></p><p></p><p></p><h2>1.1&nbsp;诞生-阿里彩票JetCache的伊甸园</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4b/4b67292d29f86ec94748747116f928b2.png\" /></p><p></p><p>2013年，JetCache诞生于 [ 阿里彩票 ]，作者是 [ huangli ] 凭借得天独厚的Tair支持和丰富的Spring生态注解支持，赢得了大家的喜爱。2015年，随着SpringBoot的大热和集团内PandoraBoot的彻底铺开，JetCache以Starter的形式实现了扩展，优化了配置项，在架构设计和性能上更上一层楼。2015年同年，JetCache开源至Github，作为alibaba的开源缓存框架，其易用性和设计先进性吸引了大批国内外用户，截止当前在github上累计3.7k star，870 fork。2018年JetCache最大版本更新，对整体的设计进行了调整，修改了默认的序列化方式，集成支持了SpringData，RedisLettuce，Redisson等更加高效以及功能更加灵活且高级的三方SDK。</p><p></p><p></p><h2>1.2 整合-开源界大放异彩</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ed/edd39a3181b49725df174d90cf791fc3.png\" /></p><p></p><p>JetCache原生支持的远程缓存是Tair，但是Tair在集团外并不可用。JetCache为了拥抱开源，实现了时下主流的GuavaCache, CaffeineCache, &nbsp;Redis，MemCache基本覆盖了国内的主流缓存中间件。在功能性方面，JetCache满足了用户一行注解解决Method缓存的刚需，同时也能通过叠加注解的方式非常高效的处理缓存穿透，缓存击穿，缓存雪崩，缓存失效等经典分布式缓存的问题，这让用户充分体验到了缓存框架的效率优势和设计先进性。在扩展性方面，JetCache满足了用户一行注解解决Method缓存的刚需，也提供了优秀的扩展能力。想要实现一个新的Cache类型，只需要实现AbstractEmbeddedCache或者AbstractExternalCache就可以以非常低廉的成本实现一个新的缓存框架。</p><p></p><p></p><h2>1.3 挑战-SpringCache江湖地位</h2><p></p><p></p><p>在2015年最火的框架是SpringBoot，SpringBoot提供了非常丰富的组件支持以及模块化的组件管理，其中就包括基于JSR-107--JCacheAPI实现的SpringCache框架。﻿SpringCache框架很好的实现了JCacheAPI，在当时占据了非常有力的位置，几乎所有的SpringBoot初创项目，都选择了使用SpringCache来作为他们的第一个缓存框架。但随着软件工程的规模越来越大，分布式场景的经典问题也接踵而至，显然SpringCache在应对分布式环境的经典问题时显得太过于稚嫩。&nbsp;对于分布式场景，缓存穿透，缓存击穿，缓存雪崩 等经典问题，缺少足够成熟的方案。高级特性上，如 分布式锁，多级缓存滑动窗口，缓存序列化，异步API支持等实际工作场景经常会需要用到的核心能力，要么没有，要么不够用。对于扩展性上，设计的不够开放和正交，很难低成本的完成一些高级功能的扩展。JetCache在这方面做的就不错，并且在迁移缓存方面基本上可以做到换注解平替，所以一旦工程规模达到一定量级，很多架构师会选择从SpringCache的方式切换到JetCache上。</p><p></p><p></p><p></p><h1>二、JetCache是如何工作的</h1><p></p><p></p><p>完整的组件串联文档：</p><p>https://app.heptabase.com/w/db02907915c401c6e33ddcc47e4d67a589047a846be16f30de1644501d939787</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/55/55106b5cdfa3e91ef3a4ec0df4f15473.png\" /></p><p></p><p></p><h2>2.1&nbsp;JSR-107--缓存JCache标准抽象实现</h2><p></p><p></p><p>Java在2012的JSR-107协议中新增了关于缓存的抽象设计标准--JCache。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c5/c5c9ddc5be8aa34ecdc1090d93287d4e.png\" /></p><p></p><p></p><h2>2.2&nbsp;丰富注解-无侵入抽象设计</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2a/2ac829e25b3fc7141f7a6c4ecfbf1582.png\" /></p><p></p><p></p><h2>2.3&nbsp;启动器和配置-Bean方式</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/aa/aa813a823e11845e43a042b07daf8b30.png\" /></p><p></p><p><code lang=\"null\">@Configuration\n@EnableMethodCache(basePackages = \"com.taobao.film.tfmind\")\n@EnableCreateCacheAnnotation\npublic class JetCacheConfig {\n    \n@Bean\npublic GlobalCacheConfig config(\n  @Qualifier(\"ldbTairManager\") TairManager tairLdbManager,\n  @Qualifier(\"mdbTairManager\") TairManager tairMdbManager,\n  @Qualifier(\"rdb3CacheCompose\") Rdb3CacheCompose rdb3CacheCompose) {\n  Map localBuilders = new HashMap&lt;&gt;();\n  Map remoteBuilders = new HashMap&lt;&gt;();\n​\n​\n  // 本地缓存 CaffeineCache\n  EmbeddedCacheBuilder<!--?--> localBuilder = CaffeineCacheBuilder\n    .createCaffeineCacheBuilder()\n    .keyConvertor(FastjsonKeyConvertor.INSTANCE);\n  localBuilders.put(CacheConsts.DEFAULT_AREA, localBuilder);\n​\n​\n  // 远程缓存 LDB\n  TairCacheBuilder<!--?--> ldbCacheBuilder = TairCacheBuilder.createTairCacheBuilder()\n    .keyConvertor(FastjsonKeyConvertor.INSTANCE)\n    .valueEncoder(KryoValueEncoder.INSTANCE)\n    .valueDecoder(KryoValueDecoder.INSTANCE)\n    .tairManager(tairLdbManager)\n    .namespace(SysConstants.NEW_TAIR_AREA)\n    .cacheNullValue(true);\n  remoteBuilders.put(CacheConsts.DEFAULT_AREA, ldbCacheBuilder);\n​\n  // 远程缓存 MDB\n  TairCacheBuilder<!--?--> ldbCacheBuilder = TairCacheBuilder.createTairCacheBuilder()\n    .keyConvertor(FastjsonKeyConvertor.INSTANCE)\n    .valueEncoder(KryoValueEncoder.INSTANCE)\n    .valueDecoder(KryoValueDecoder.INSTANCE)\n    .tairManager(tairLdbManager)\n    .namespace(SysConstants.NEW_TAIR_AREA)\n    .cacheNullValue(true);\n  remoteBuilders.put(\"MDB\", mdbCacheBuilder);\n​\n  // 远程缓存 RDB\n  TairRdb3CacheBuilder<!--?--> rdb3CacheBuilder = TairRdb3CacheBuilder.createRedisCacheBuilder()\n    .keyConvertor(FastjsonKeyConvertor.INSTANCE)\n    .valueEncoder(KryoValueEncoder.INSTANCE)\n    .valueDecoder(KryoValueDecoder.INSTANCE)\n    .jedisPool(rdb3CacheCompose.getJedisPool())\n    .cacheNullValue(true);\n  remoteBuilders.put(\"RDB3\", rdb3CacheBuilder);\n​\n  // 构建全局缓存配置\n  GlobalCacheConfig globalCacheConfig = new GlobalCacheConfig();\n  globalCacheConfig.setConfigProvider(springConfigProvider());\n  globalCacheConfig.setLocalCacheBuilders(localBuilders);\n  globalCacheConfig.setRemoteCacheBuilders(remoteBuilders);\n  globalCacheConfig.setStatIntervalMinutes(5);\n  globalCacheConfig.setAreaInCacheName(false);\n​\n  return globalCacheConfig;\n}\n}</code></p><p></p><p></p><h2>2.4&nbsp;注解模式-AOP-缓存</h2><p></p><p></p><p>基于AOP的方法级缓存，最常用最直观的CacheAside模式。</p><p><code lang=\"null\">  public interface UserService {\n      @Cached(expire = 3600, cacheType = CacheType.REMOTE)\n      User getUserById(long userId);\n  }</code></p><p></p><p></p><h2>2.5&nbsp;注解模式-Cache-API 缓存</h2><p></p><p></p><p>基于CacheAPI的缓存形式，复杂场景下最灵活的模式。</p><p><code lang=\"null\">  @CreateCache(expire = 3600, cacheType = CacheType.REMOTE)\n  private Cache userCache;</code></p><p></p><p></p><h2>2.6&nbsp;高级API模式-手动创建CacheAPI</h2><p></p><p></p><p><code lang=\"null\">  @Autowired\n  private CacheManager cacheManager;\n  private Cache userCache;\n  \n  public UserDO getTestCacheValue() {\n    if(userCache == null) {\n      QuickConfig qc = QuickConfig.newBuilder(\"userCache\")\n          .expire(Duration.ofSeconds(100))\n          .cacheType(CacheType.BOTH)\n          .syncLocal(true) // invalidate local cache in all jvm process after update\n          .build();\n      userCache = cacheManager.getOrCreateCache(qc);\n    }\n    return userCache.get(\"TestCacheKey\")\n  }</code></p><p></p><p></p><h2>2.7&nbsp;Cache基础缓存操作</h2><p></p><p></p><p><code lang=\"null\">  // 数据存储\n  void put(K key, V value); // 数据录入\n  void putAll(Map<!--? extends K,? extends V--> map); // 批量数据录入\n  boolean putIfAbsent(K key, V value); // 卫语句的数据存储\n  \n  // 数据读取\n  V get(K key); // 数据读取\n  Map getAll(Set<!--? extends K--> keys); // 批量数据读取\n  \n  // 数据删除\n  void remove(K key);\n  void removeAll(Set<!--? extends K--> keys);\n  \n  // 异步高级缓存API\n  V computeIfAbsent(K key, Function loader);\n  V computeIfAbsent(K key, Function loader, boolean cacheNullWhenLoaderReturnNull);\n  V computeIfAbsent(K key, Function loader, boolean cacheNullWhenLoaderReturnNull, long expire, TimeUnit timeUnit);\n  \n  // 分布式锁\n  AutoReleaseLock tryLock(K key, long expire, TimeUnit timeUnit);\n  boolean tryLockAndRun(K key, long expire, TimeUnit timeUnit, Runnable action);\n  \n  // 原始缓存API （一般不用）\n  CacheGetResult GET(K key);\n  MultiGetResult GET_ALL(Set<!--? extends K--> keys);\n  CacheResult PUT(K key, V value);\n  CacheResult PUT(K key, V value, long expireAfterWrite, TimeUnit timeUnit);\n  CacheResult PUT_ALL(Map<!--? extends K, ? extends V--> map);\n  CacheResult PUT_ALL(Map<!--? extends K, ? extends V--> map, long expireAfterWrite, TimeUnit timeUnit);\n  CacheResult REMOVE(K key);\n  CacheResult REMOVE_ALL(Set<!--? extends K--> keys);\n  CacheResult PUT_IF_ABSENT(K key, V value, long expireAfterWrite, TimeUnit timeUnit);</code></p><p></p><p></p><h2>2.8&nbsp;分布式-缓存穿透</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/42/429d3e4b31e1d5e3ee5090c209e62fab.png\" /></p><p></p><p>分布式场景下的热点数据通常都保存在缓存当中，以减少数据库的压力，提升服务的性能。缓存击穿是指，攻击者利用随机访问的方式短时间大量的访问不存在的数据，由于数据不存在，所以缓存中查不到，请求越过缓存层直达数据库，造成数据库的压力激增。通常的解法有：[空值缓存] 及 [布隆过滤器]JetCache使用了较为轻量级的 [空值缓存] 方式，来解决这个问题。</p><p>@Cached(cacheNullValue=true)、@CreateCache(cacheNullValue=true)</p><p></p><p><code lang=\"null\">// AbstractCache.class\n​\nstatic  V computeIfAbsentImpl(K key, Function loader, boolean cacheNullWhenLoaderReturnNull,\n                                               long expireAfterWrite, TimeUnit timeUnit, Cache cache) {\n  .......\n    Consumer cacheUpdater = (loadedValue) -&gt; {\n    if(needUpdate(loadedValue, cacheNullWhenLoaderReturnNull, newLoader)) {\n        if (timeUnit != null) {\n          cache.PUT(key, loadedValue, expireAfterWrite, timeUnit).waitForResult();\n        } else {\n          cache.PUT(key, loadedValue).waitForResult();\n        }\n     }\n  };\n  ......\n  }</code></p><p></p><p></p><h2>2.9&nbsp;分布式-缓存击穿</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e3/e3578cdf3eb1bdf93108ce3f92751863.png\" /></p><p></p><p>CacheAside模式的缓存由于本身有淘汰策略，在数据失效后，缓存组件会直接访问数据库尝试重建缓存。在大规模分布式热点的情况下，一旦热点数据失效，会有大量的请求同时尝试重建缓存，这不但会导致资源浪费，更加危险的是会造成数据库瞬时极大的压力。JetCache通过注解@CachePenetrationProtect实现了JVM内存锁级的击穿保护，使并发重建的请求限制到可控范围。( 如果数据利用率高还可以使用@CacheRefresh的方式来实现基于分布式锁的缓存重建能力 )</p><p></p><p><code lang=\"null\">// AbstractCache.class\n​\nstatic  V computeIfAbsentImpl(K key, Function loader, boolean cacheNullWhenLoaderReturnNull,\n                                               long expireAfterWrite, TimeUnit timeUnit, Cache cache) {\n  ....\n    if (cache.config().isCachePenetrationProtect()) {\n      loadedValue = synchronizedLoad(cache.config(), abstractCache, key, newLoader, cacheUpdater);\n    } else {\n      loadedValue = newLoader.apply(key);\n      cacheUpdater.accept(loadedValue);\n    }\n  ....\n}</code></p><p></p><p></p><h2>2.10&nbsp;分布式-缓存雪崩</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dc/dc386b8aa263ceb111e5ede6e935673b.png\" /></p><p></p><p>缓存雪崩与缓存击穿类似，但是情况更为危机后果更为严重，有可能导致整个集群服务瘫痪。当大量热点缓存同时失效的时候，大量的缓存重建请求会直达数据库，造成服务节点瘫痪形成服务雪崩。缓存雪崩的处理方式较为复杂，但简单来说：&nbsp;可以建立多级缓存，通过设置不同的过期时间，形成重叠数据滑动窗口。通过服务主动维护异步任务的形式，维护一块永固缓存，防止热点失效。JetCache 可以通过多级缓存来避免这种情况。JetCache 还提供了@CacheRefresh和CacheLoader的方式，使服务有能力创建内建的时间块任务，来达到维护分布式环境下永固缓存的目的。</p><p></p><p><code lang=\"null\">// RefreshCache.class\n​\npublic void run() {\n  try {\n    if (config.getRefreshPolicy() == null || (loader == null &amp;&amp; !hasLoader())) {\n      cancel();\n      return;\n    }\n    long now = System.currentTimeMillis();\n    long stopRefreshAfterLastAccessMillis = config.getRefreshPolicy().getStopRefreshAfterLastAccessMillis();\n    if (stopRefreshAfterLastAccessMillis &gt; 0) {\n      if (lastAccessTime + stopRefreshAfterLastAccessMillis &lt; now) {\n        logger.debug(\"cancel refresh: {}\", key);\n        cancel();\n        return;\n      }\n    }\n    logger.debug(\"refresh key: {}\", key);\n    Cache concreteCache = concreteCache();\n    if (concreteCache instanceof AbstractExternalCache) {\n      externalLoad(concreteCache, now);\n    } else {\n      load();\n    }\n  } catch (Throwable e) {\n    logger.error(\"refresh error: key=\" + key, e);\n  }\n}</code></p><p></p><p></p><h2>2.11&nbsp;分布式-缓存失效/更新</h2><p></p><p></p><p>缓存数据也需要维护，尤其是缓存和实际数据不一致的情况下。例如用户数据，就非常需要缓存失效和缓存更新的能力，及时的在用户做了数据操作之后更新公共缓存的数据。JetCache通过@CacheInvalid和@CacheUpdate提供了这种能力，极大程度的避免了缓存数据不一致的情况，同时也增强了缓存操作的灵活性。</p><p></p><p><code lang=\"null\">public interface UserService {\n    @Cached(name=\"userCache.\", key=\"#userId\", expire = 3600)\n    User getUserById(long userId);\n​\n    @CacheUpdate(name=\"userCache.\", key=\"#user.userId\", value=\"#user\")\n    void updateUser(User user);\n​\n    @CacheInvalidate(name=\"userCache.\", key=\"#userId\")\n    void deleteUser(long userId);\n}</code></p><p></p><p></p><h1>三、JetCache框架设计剖析优势有哪些？</h1><p></p><p></p><p></p><h2>3.1&nbsp;支持多种KV序列化方式</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/86/86e7c7036afe505f77ec91058078eeaf.png\" /></p><p></p><p>CacheKey Convertor ：用来进行缓存Key的加工处理&nbsp;环境隔离：&nbsp;CacheKey在影演使用最广泛方式，抽象实现环境前缀Convertor就可以当前环境进行缓存前缀的拼接，从而达到数据隔离的目的。长短缓存：&nbsp;长短缓存通常使用对象缓存作为Key，为了容灾短缓存和长缓存通常使用了不同的缓存Key。通过实现长短缓存Convertor可以实现相同对象，可以控制长、短缓存的Key使用对象中的不同属性构造，从而达到短缓存提升性能，长缓存降级的目的。﻿ValueEncode、ValueDecode：用来提升缓存性能的绝佳方式高性能序列化：选择JavaSerialize、kyro、Kyro5的序列化方式可以极大程度的提升我们系统对性能的要求，很适合应对高并发环境的大流量压力。兼容性序列化：选择JSON（FastJson、FastJson2、Jackson）的方式，可以为缓存提供良好的兼容性。在架构设计的初期，完全可以采用这种方式来实现平稳迭代。加密序列化：当我们使用外部数据库的时候，我们可以自己实现ValueEncode和ValueDecode来保障我们数据的安全。</p><p></p><p></p><h2>3.2&nbsp;支持多种本地，远程缓存</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/97/977f298fd979ed84787f9306cef1a496.png\" /></p><p></p><p></p><h2>3.3&nbsp;多级缓存-乐高积木</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7e/7e0b003d6a7492b815ea726820aa02cf.png\" /></p><p></p><p>长短缓存：通过多级缓存加上KeyConvertor可以快速构建成本最低效率最高的长短缓存组件。用户缓存：互动用户数据很多，配合用户路由，可以结合 LocalCache + LDB 的方式既保证数据的可靠性，又能将性能从10ms -&gt; 1ms 级。自定义多级“缓存”：由于JetCache缓存的实现相当方便，我们甚至可以实现 Mysql，Opensearch 的Cache实现，并且把它组转到多级缓存之中，形成一种结构稳固的数据读写组件。</p><p></p><p></p><h2>3.4&nbsp;高级特性-加载器</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5a/5aab360dd88c86c4fa33e8d0d66e1ea4.png\" /></p><p></p><p><code lang=\"null\">// AOP 缓存 Example\n@Cached(expireTime= 5 * 60)\npublic Long loadOrderSumFromDatabase(String orderType);</code></p><p></p><p><code lang=\"null\">@CreateCache(expireTime= 5 * 60)\nprivate Cache orderSumCache;\n​\n// 每分钟拉取订单总数，形成持久缓存\n@PostConstruct\npublic void init(){\n  RefreshPolicy policy = RefreshPolicy.newPolicy(1, TimeUnit.MINUTES)\n    .stopRefreshAfterLastAccess(30, TimeUnit.MINUTES);\n  orderSumCache.config().setLoader(this::loadOrderSumFromDatabase);\n  orderSumCache.config().setRefreshPolicy(policy);\n}</code></p><p></p><p></p><h2>3.5&nbsp;高级特性-监听器</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9b/9b5ec9ab9fb644da1d28a88f807746da.png\" /></p><p></p><p>官方实现-数据报告</p><p><code lang=\"null\">// 数据报告Monitor的代码实现\npublic class DefaultCacheMonitor implements CacheMonitor {\n    public synchronized void afterOperation(CacheEvent event) {\n        if (event instanceof CacheGetEvent) {\n            CacheGetEvent e = (CacheGetEvent) event;\n            afterGet(e.getMillis(), e.getKey(), e.getResult());\n        } else if (event instanceof CachePutEvent) {\n            CachePutEvent e = (CachePutEvent) event;\n            afterPut(e.getMillis(), e.getKey(), e.getValue(), e.getResult());\n        } else if (event instanceof CacheRemoveEvent) {\n            CacheRemoveEvent e = (CacheRemoveEvent) event;\n            afterRemove(e.getMillis(), e.getKey(), e.getResult());\n        } else if (event instanceof CacheLoadEvent) {\n            CacheLoadEvent e = (CacheLoadEvent) event;\n            afterLoad(e.getMillis(), e.getKey(), e.getLoadedValue(), e.isSuccess());\n        } else if (event instanceof CacheGetAllEvent) {\n            CacheGetAllEvent e = (CacheGetAllEvent) event;\n            afterGetAll(e.getMillis(), e.getKeys(), e.getResult());\n        } else if (event instanceof CacheLoadAllEvent) {\n            CacheLoadAllEvent e = (CacheLoadAllEvent) event;\n            afterLoadAll(e.getMillis(), e.getKeys(), e.getLoadedValue(), e.isSuccess());\n        } else if (event instanceof CachePutAllEvent) {\n            CachePutAllEvent e = (CachePutAllEvent) event;\n            afterPutAll(e.getMillis(), e.getMap(), e.getResult());\n        } else if (event instanceof CacheRemoveAllEvent) {\n            CacheRemoveAllEvent e = (CacheRemoveAllEvent) event;\n            afterRemoveAll(e.getMillis(), e.getKeys(), e.getResult());\n        }\n    }\n}</code></p><p></p><p><code lang=\"null\">// 数据报告Monitor 的注册\npublic void addMonitors(CacheManager cacheManager, Cache cache, QuickConfig quickConfig) {\n    if (metricsManager == null) {\n        return;\n    }\n    DefaultCacheMonitor monitor = new DefaultCacheMonitor(quickConfig.getName());\n    cache.config().getMonitors().add(monitor);\n}</code></p><p></p><p>效果：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/18/18a2fe38d19a4d0c2d189237f16d7072.png\" /></p><p></p><p></p><p></p><h1>四、影演之路：影演如何发展了JetCache</h1><p></p><p></p><p>Jetcache在开源界如此火，离不开它遵循了JSR107标准，遵从于原则的设计和对原则的扩充使得它在学习效率上非常高效，代码结构上也非常优秀，并且它也在开放性和扩展性下足了功夫，真正实现了架构上的 ”正交“。</p><p></p><p>在电影演出BU内部，由于要应对业务的复杂性，所以需要针对Jetcache做一些比较定制化的扩展，其中有关于核心底层tair的支持，也有关于分布式场景管理的诉求，更有对业务瓶颈挑战的通用设计。</p><p></p><p>通过这些新的场景设计，我们极大的丰富了Jetcache的应用场景以及让它重新再集团中间件的环境之下，长出了新的分支，非常好的支撑的业务发展。</p><p></p><p></p><h2>4.1&nbsp;通用高并发三级缓存熔断组件</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fd/fda3c4dd33c9288b50411d36e344716f.png\" /></p><p></p><p></p><h2>4.2&nbsp;缓存后置写（Cache Write-Back）</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/18/180bc678e060dce54b373edd383fa46c.png\" /></p><p></p><p>缓存后置写是一种 Cache Write-Back 模式的实现：</p><p>1）缓存后置写由JetCache的Monitor来实现活跃事件的监控以及记录，每当有事件产生，后置写监控器就会被触发。</p><p>2）将需要缓存后置写的Cache实例通过Config.Monitor的方式添加好默认后置写监控器。</p><p>3）活跃Event 将会被不同的 缓存后置写实现捕获，并会将CacheKey缓存在一个唯一分布式队列中，等待调度。</p><p>4）我们通过了 ScheduleX 实现了分布式调度器，每分钟都会进行触发（当然每个后置写实现可能会有不同的触发频率）</p><p></p><p>目前影演使用缓存后置写实现了非常多的实用应用，包括：&nbsp;</p><p>影演评分数据准实时合并入库，同步至淘票票，大麦三方业务库。（ 准实时并发写方案，数据同步方案）线上、预发缓存准实时同步。 (环境数据一致性)数据变更对比，趋势数据记录。 ( 数据对账，数据趋势图 )本地缓存广播器。（ 本地缓存一致性，避免数据波动）</p><p></p><p></p><h2>4.3&nbsp;本地缓存广播器（LocalCache Distribute）</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8b/8bdb782b419d7786c382577679eec4c2.png\" /></p><p></p><p></p><h2>4.4&nbsp;稀疏列表缓存实现（MultiListCache）</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/40/4009f7b7278a9405cbc9c5b6c94bd17c.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/07/07e0af428c600b2bfb934848003dbf40.png\" /></p><p></p><p></p><h1>五、面向未来：JetCache还有哪些不足</h1><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/29/29b9a6f1041d7812e0c1aa769b71eb14.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/96b029c4292f23f8288af6b1f4b743c4.png\" /></p><p></p>",
    "publish_time": "2023-04-11 10:10:41",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "张勇：阿里巴巴所有产品未来将接入大模型全面改造",
    "url": "https://www.infoq.cn/article/7tuErOzX9lV5G8ffxfDE",
    "summary": "<p>4 月 11 日，<a href=\"https://www.infoq.cn/video/q6qgde5XiKFIxtmr84ju\">阿里巴巴</a>\"集团董事会主席兼 CEO、阿里云智能集团 CEO 张勇在云峰会上表示，阿里巴巴所有产品未来将接入<a href=\"https://www.infoq.cn/article/MBhLRG3KXdBw3QSJL2gR\">“通义千问”大模型</a>\"，进行全面改造。他认为，面向 AI 时代，所有产品都值得用大模型重新升级。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a1/a107ebc88c80134a2de204ecfbcbd9bc.png\" /></p><p></p><p>张勇表示，AI 大模型的出现是一个划时代的里程碑，人类将进入到一个全新的智能化时代，就像工业革命一样，大模型将会被各行各业广泛应用，带来生产力的巨大提升，并深刻改变我们的生活方式。</p><p>&nbsp;</p><p>自 2019 年起，阿里即开始进行大模型研究，并在近期推出阶段性的研究成果：通义千问大模型。张勇介绍，钉钉、天猫精灵等产品在接入通义千问测试后，变得聪明了很多，像天猫精灵，不仅能回答家里小朋友的各种刁钻问题，还多了一份情感连接，成为更温暖更人性化的智能助手。</p><p>&nbsp;</p><p>钉钉接入通义千问测试之后，可以自动生成工作方案，也可以在会议纪要后自动生成总结和待办事项，还能拍一张功能草图自动生成小程序。</p><p>&nbsp;</p><p>阿里巴巴决定未来将所有产品接入通义千问，进行全面改造。张勇表示，面向 AI 时代，所有产品都值得用大模型重做一次，基于这一信念，阿里云希望帮助更多企业用上大模型，让每家企业都能基于“通义千问”，拥有具备自己行业能力的专属大模型。</p><p>&nbsp;</p><p>他同时指出，大模型是一场“ AI+云计算”的全方位竞争，超万亿参数的大模型研发，并不仅仅是算法问题，而是囊括了底层庞大算力、网络、大数据、机器学习等诸多领域的复杂系统性工程，需要有超大规模<a href=\"https://www.infoq.cn/article/lj4SMzSjJxNMYrGf5lob\"> AI 基础设施</a>\"的支撑。</p><p>&nbsp;</p><p>张勇表示，面对全新的 AI 时代，阿里云已经做好了准备。十多年来，阿里云已经累积了从飞天云操作系统、芯片到智算平台的“AI+云计算”的全栈技术实力，今天，阿里云将把这些AI基础设施和大模型能力向所有企业开放，共同推动 AI 产业的发展。</p><p>&nbsp;</p><p>“一家企业的想象力终归是有限的，释放 AI 潜力要靠无数人探索。”张勇说。</p>",
    "publish_time": "2023-04-11 10:39:45",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]