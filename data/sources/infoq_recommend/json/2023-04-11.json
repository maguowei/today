[
  {
    "title": "ThoughtWorks CTO：2025年之前，我们会看到架构的演进，但不会看到革命",
    "url": "https://www.infoq.cn/article/XYlKxH5f3GjBflH31z9h",
    "summary": "<p>在<a href=\"https://qconlondon.com/\">QCon伦敦会议</a>\"的第二天，ThoughtWorks的CTO<a href=\"https://www.linkedin.com/in/rebecca-parsons-871491/\">Rebecca Parsons</a>\"重新审视了<a href=\"https://qconlondon.com/presentation/mar2023/how-will-evolutionary-architecture-evolve\">演进式架构（evolutionary architecture）的理念并设想了在2025年前它将会出现的变化</a>\"。她从演进式架构的定义开始，回顾了每项“能力”和属性，预测了在下一个阶段将会发生的变化。她的结论是，我们会看到演进，但不会看到革命。</p><p></p><p></p><blockquote><a href=\"https://www.thoughtworks.com/en-gb/insights/books/building-evolutionary-architectures\">演进式架构</a>\"支持在多个维度上有指导性的、渐进式的变化。</blockquote><p></p><p></p><p>Parsons解释了为何采用演进这个词而不是敏捷或涌现。在与“演进式架构”一书的合著者Neil Ford进行了一次建设性、强有力的对话后，这个名字被确定了下来。最初，Ford将这种做法称为“涌现式（emergent）”架构。虽然在代码方面，“好”与“坏”相对比较容易达成一致，但在架构方面就并非如此了。定义的指南部分指出了好的架构要有哪些部分组成。</p><p></p><p></p><blockquote>这就是我们引入<a href=\"https://en.wikipedia.org/wiki/Fitness_function#%3a~%3atext=A%20fitness%20function%20is%20a,to%20achieving%20the%20set%20aims.\">适应度函数（fitness function）</a>\"的原因。适应度函数是一个特定的系统在多大程度上反映所需的行为特征的客观描述。</blockquote><p></p><p></p><p>随后，Parsons着重强调了可执行的重要性：在通往生产化的道路上，如何渐进式地增加新的特性并提供可行的机制？</p><p></p><p></p><blockquote>演进式架构的重要实践和推动力之一就是与<a href=\"https://en.wikipedia.org/wiki/Continuous_delivery\">持续交付</a>\"和最终的<a href=\"https://en.wikipedia.org/wiki/Continuous_deployment\">持续部署</a>\"一同实现严谨性和自动化。</blockquote><p></p><p></p><p>这些适应度函数应该被纳入到部署流水线中。</p><p></p><p>定义的最后一部分强调的是多维度方面。她使用一张幻灯片展示了几年前维基百科上的“能力（-ilities）”列表。这个列表后来有了一些变化，例如，更加注重可观测性。列表中的一个谬误是，我们无法最大化所有的能力，因为其中有些能力是互斥的：“有些系统是一次性的，不关心可演进性”。</p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/news/2023/03/evolutionary-architecture-2025/en/resources/1ilities-1680043256351.jpg\" /></p><p></p><p>接下来，Parsons谈到了如今演进式架构的原则，并预测了它们在未来两年的发展。</p><p></p><p></p><blockquote>个人认为，我们第一次尝试SOA的失败原因之一就是我们在系统周围画了边界。比我们围绕概念画出的边界更多。</blockquote><p></p><p></p><p>最后的责任时刻：为了尽可能多地掌握系统的信息，我们想把决定推迟到最后的责任时刻（responsible moment）。需要做的权衡转换成了“能力”和适应度函数。</p><p></p><p>为可演进性而设计和开发：如果可演进性对你的系统很重要，那么它不仅对你如何编写代码很重要，而且对你如何结构化代码也很重要。</p><p></p><p></p><blockquote>可读性是关键，这就是优质软件指标的作用所在。[...]这就是我们谈论边界、耦合和内聚的时候。</blockquote><p></p><p></p><p>Postel定律：对收到的东西要慷慨，对发送的东西要谨慎。</p><p></p><p></p><blockquote>如果你只需要一个邮政编码，就不要验证收到的地址。这样，如果我决定把它分成两行，你就不需要在意它了。</blockquote><p></p><p></p><p>可测试性架构：测试某项功能的能力以及某项功能的可测试性如何，很好地说明了你的边界划分是否合理。如果你专注于测试金字塔的所有层次，你就会有更好的系统架构。</p><p></p><p>康威定律：可怕的人的问题。任何系统都会反映出所有组织的沟通情况。</p><p></p><p></p><blockquote>如果你想要一个三阶段的流水线，你必定有三个小组。</blockquote><p></p><p></p><p>最后，她谈到了这些原则在未来两年内会受到怎样的影响。根据Parsons的说法，“最后的责任时刻”和Postel定律都不会受到影响。</p><p></p><p>即使这些原则保持不变，但会有更多的创新，从而能够建立起更强大、更具“免疫性”的系统。不仅仅物联网、增强或虚拟现实等系统的复杂性中会融入创新，更多的创新将发生在机器学习模型的测试方式上。人工智能辅助开发会促进不同类型的开发技术的发展，如测试优先开发（Test First Development），即开发人员编写测试，人工智能生成代码，或其他方式。</p><p></p><p>所有这些都将通过增强持续部署流水线、增加对生产中测试的依赖以及扩大适应度函数和方法套件来实现。</p><p></p><p>她在演讲结束时这样总结说：</p><p></p><p></p><blockquote>这些原则自始至终都是不变的，目前还没有迹象表明我们遗漏了什么原则。实践会不断发展，但不会有根本性的改变[......]即使创新会改变工具，但原则是不变的。演进式架构会继续发展，但不太可能会迎来一场革命。</blockquote><p></p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/03/evolutionary-architecture-2025/\">Rebecca Parsons - ThoughtWorks CTO: By 2025 We'll See Evolution in Architecture, But Not Revolution</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/minibook/sihSN688wdNINfNNTWKu\">架构师（2023 年 4 月）</a>\"</p><p><a href=\"https://www.infoq.cn/article/J3ulcioRIXNfR0HDtZjr\">浅析三款大规模分布式文件系统架构设计</a>\"</p><p></p>",
    "publish_time": "2023-04-11 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "JetCache 缓存开源组件设计精要",
    "url": "https://www.infoq.cn/article/cac316dcf2db8cc3d029c1065",
    "summary": "<p>​作者：张隆   阿里电影演出技术中心团队</p><p></p><p></p><blockquote>本文将为大家介绍JetCache缓存开源组件的前世今生，并剖析了JetCache的工作原理及设计优势。</blockquote><p></p><p></p><p></p><h1>一、JetCache的前世今生</h1><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/51/51d67b04e7a02a293a8ff176cb28bb1e.png\" /></p><p></p><p></p><h2>1.1&nbsp;诞生-阿里彩票JetCache的伊甸园</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4b/4b67292d29f86ec94748747116f928b2.png\" /></p><p></p><p>2013年，JetCache诞生于 [ 阿里彩票 ]，作者是 [ huangli ] 凭借得天独厚的Tair支持和丰富的Spring生态注解支持，赢得了大家的喜爱。2015年，随着SpringBoot的大热和集团内PandoraBoot的彻底铺开，JetCache以Starter的形式实现了扩展，优化了配置项，在架构设计和性能上更上一层楼。2015年同年，JetCache开源至Github，作为alibaba的开源缓存框架，其易用性和设计先进性吸引了大批国内外用户，截止当前在github上累计3.7k star，870 fork。2018年JetCache最大版本更新，对整体的设计进行了调整，修改了默认的序列化方式，集成支持了SpringData，RedisLettuce，Redisson等更加高效以及功能更加灵活且高级的三方SDK。</p><p></p><p></p><h2>1.2 整合-开源界大放异彩</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ed/edd39a3181b49725df174d90cf791fc3.png\" /></p><p></p><p>JetCache原生支持的远程缓存是Tair，但是Tair在集团外并不可用。JetCache为了拥抱开源，实现了时下主流的GuavaCache, CaffeineCache, &nbsp;Redis，MemCache基本覆盖了国内的主流缓存中间件。在功能性方面，JetCache满足了用户一行注解解决Method缓存的刚需，同时也能通过叠加注解的方式非常高效的处理缓存穿透，缓存击穿，缓存雪崩，缓存失效等经典分布式缓存的问题，这让用户充分体验到了缓存框架的效率优势和设计先进性。在扩展性方面，JetCache满足了用户一行注解解决Method缓存的刚需，也提供了优秀的扩展能力。想要实现一个新的Cache类型，只需要实现AbstractEmbeddedCache或者AbstractExternalCache就可以以非常低廉的成本实现一个新的缓存框架。</p><p></p><p></p><h2>1.3 挑战-SpringCache江湖地位</h2><p></p><p></p><p>在2015年最火的框架是SpringBoot，SpringBoot提供了非常丰富的组件支持以及模块化的组件管理，其中就包括基于JSR-107--JCacheAPI实现的SpringCache框架。﻿SpringCache框架很好的实现了JCacheAPI，在当时占据了非常有力的位置，几乎所有的SpringBoot初创项目，都选择了使用SpringCache来作为他们的第一个缓存框架。但随着软件工程的规模越来越大，分布式场景的经典问题也接踵而至，显然SpringCache在应对分布式环境的经典问题时显得太过于稚嫩。&nbsp;对于分布式场景，缓存穿透，缓存击穿，缓存雪崩 等经典问题，缺少足够成熟的方案。高级特性上，如 分布式锁，多级缓存滑动窗口，缓存序列化，异步API支持等实际工作场景经常会需要用到的核心能力，要么没有，要么不够用。对于扩展性上，设计的不够开放和正交，很难低成本的完成一些高级功能的扩展。JetCache在这方面做的就不错，并且在迁移缓存方面基本上可以做到换注解平替，所以一旦工程规模达到一定量级，很多架构师会选择从SpringCache的方式切换到JetCache上。</p><p></p><p></p><p></p><h1>二、JetCache是如何工作的</h1><p></p><p></p><p>完整的组件串联文档：</p><p>https://app.heptabase.com/w/db02907915c401c6e33ddcc47e4d67a589047a846be16f30de1644501d939787</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/55/55106b5cdfa3e91ef3a4ec0df4f15473.png\" /></p><p></p><p></p><h2>2.1&nbsp;JSR-107--缓存JCache标准抽象实现</h2><p></p><p></p><p>Java在2012的JSR-107协议中新增了关于缓存的抽象设计标准--JCache。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c5/c5c9ddc5be8aa34ecdc1090d93287d4e.png\" /></p><p></p><p></p><h2>2.2&nbsp;丰富注解-无侵入抽象设计</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2a/2ac829e25b3fc7141f7a6c4ecfbf1582.png\" /></p><p></p><p></p><h2>2.3&nbsp;启动器和配置-Bean方式</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/aa/aa813a823e11845e43a042b07daf8b30.png\" /></p><p></p><p><code lang=\"null\">@Configuration\n@EnableMethodCache(basePackages = \"com.taobao.film.tfmind\")\n@EnableCreateCacheAnnotation\npublic class JetCacheConfig {\n    \n@Bean\npublic GlobalCacheConfig config(\n  @Qualifier(\"ldbTairManager\") TairManager tairLdbManager,\n  @Qualifier(\"mdbTairManager\") TairManager tairMdbManager,\n  @Qualifier(\"rdb3CacheCompose\") Rdb3CacheCompose rdb3CacheCompose) {\n  Map localBuilders = new HashMap&lt;&gt;();\n  Map remoteBuilders = new HashMap&lt;&gt;();\n​\n​\n  // 本地缓存 CaffeineCache\n  EmbeddedCacheBuilder<!--?--> localBuilder = CaffeineCacheBuilder\n    .createCaffeineCacheBuilder()\n    .keyConvertor(FastjsonKeyConvertor.INSTANCE);\n  localBuilders.put(CacheConsts.DEFAULT_AREA, localBuilder);\n​\n​\n  // 远程缓存 LDB\n  TairCacheBuilder<!--?--> ldbCacheBuilder = TairCacheBuilder.createTairCacheBuilder()\n    .keyConvertor(FastjsonKeyConvertor.INSTANCE)\n    .valueEncoder(KryoValueEncoder.INSTANCE)\n    .valueDecoder(KryoValueDecoder.INSTANCE)\n    .tairManager(tairLdbManager)\n    .namespace(SysConstants.NEW_TAIR_AREA)\n    .cacheNullValue(true);\n  remoteBuilders.put(CacheConsts.DEFAULT_AREA, ldbCacheBuilder);\n​\n  // 远程缓存 MDB\n  TairCacheBuilder<!--?--> ldbCacheBuilder = TairCacheBuilder.createTairCacheBuilder()\n    .keyConvertor(FastjsonKeyConvertor.INSTANCE)\n    .valueEncoder(KryoValueEncoder.INSTANCE)\n    .valueDecoder(KryoValueDecoder.INSTANCE)\n    .tairManager(tairLdbManager)\n    .namespace(SysConstants.NEW_TAIR_AREA)\n    .cacheNullValue(true);\n  remoteBuilders.put(\"MDB\", mdbCacheBuilder);\n​\n  // 远程缓存 RDB\n  TairRdb3CacheBuilder<!--?--> rdb3CacheBuilder = TairRdb3CacheBuilder.createRedisCacheBuilder()\n    .keyConvertor(FastjsonKeyConvertor.INSTANCE)\n    .valueEncoder(KryoValueEncoder.INSTANCE)\n    .valueDecoder(KryoValueDecoder.INSTANCE)\n    .jedisPool(rdb3CacheCompose.getJedisPool())\n    .cacheNullValue(true);\n  remoteBuilders.put(\"RDB3\", rdb3CacheBuilder);\n​\n  // 构建全局缓存配置\n  GlobalCacheConfig globalCacheConfig = new GlobalCacheConfig();\n  globalCacheConfig.setConfigProvider(springConfigProvider());\n  globalCacheConfig.setLocalCacheBuilders(localBuilders);\n  globalCacheConfig.setRemoteCacheBuilders(remoteBuilders);\n  globalCacheConfig.setStatIntervalMinutes(5);\n  globalCacheConfig.setAreaInCacheName(false);\n​\n  return globalCacheConfig;\n}\n}</code></p><p></p><p></p><h2>2.4&nbsp;注解模式-AOP-缓存</h2><p></p><p></p><p>基于AOP的方法级缓存，最常用最直观的CacheAside模式。</p><p><code lang=\"null\">  public interface UserService {\n      @Cached(expire = 3600, cacheType = CacheType.REMOTE)\n      User getUserById(long userId);\n  }</code></p><p></p><p></p><h2>2.5&nbsp;注解模式-Cache-API 缓存</h2><p></p><p></p><p>基于CacheAPI的缓存形式，复杂场景下最灵活的模式。</p><p><code lang=\"null\">  @CreateCache(expire = 3600, cacheType = CacheType.REMOTE)\n  private Cache userCache;</code></p><p></p><p></p><h2>2.6&nbsp;高级API模式-手动创建CacheAPI</h2><p></p><p></p><p><code lang=\"null\">  @Autowired\n  private CacheManager cacheManager;\n  private Cache userCache;\n  \n  public UserDO getTestCacheValue() {\n    if(userCache == null) {\n      QuickConfig qc = QuickConfig.newBuilder(\"userCache\")\n          .expire(Duration.ofSeconds(100))\n          .cacheType(CacheType.BOTH)\n          .syncLocal(true) // invalidate local cache in all jvm process after update\n          .build();\n      userCache = cacheManager.getOrCreateCache(qc);\n    }\n    return userCache.get(\"TestCacheKey\")\n  }</code></p><p></p><p></p><h2>2.7&nbsp;Cache基础缓存操作</h2><p></p><p></p><p><code lang=\"null\">  // 数据存储\n  void put(K key, V value); // 数据录入\n  void putAll(Map<!--? extends K,? extends V--> map); // 批量数据录入\n  boolean putIfAbsent(K key, V value); // 卫语句的数据存储\n  \n  // 数据读取\n  V get(K key); // 数据读取\n  Map getAll(Set<!--? extends K--> keys); // 批量数据读取\n  \n  // 数据删除\n  void remove(K key);\n  void removeAll(Set<!--? extends K--> keys);\n  \n  // 异步高级缓存API\n  V computeIfAbsent(K key, Function loader);\n  V computeIfAbsent(K key, Function loader, boolean cacheNullWhenLoaderReturnNull);\n  V computeIfAbsent(K key, Function loader, boolean cacheNullWhenLoaderReturnNull, long expire, TimeUnit timeUnit);\n  \n  // 分布式锁\n  AutoReleaseLock tryLock(K key, long expire, TimeUnit timeUnit);\n  boolean tryLockAndRun(K key, long expire, TimeUnit timeUnit, Runnable action);\n  \n  // 原始缓存API （一般不用）\n  CacheGetResult GET(K key);\n  MultiGetResult GET_ALL(Set<!--? extends K--> keys);\n  CacheResult PUT(K key, V value);\n  CacheResult PUT(K key, V value, long expireAfterWrite, TimeUnit timeUnit);\n  CacheResult PUT_ALL(Map<!--? extends K, ? extends V--> map);\n  CacheResult PUT_ALL(Map<!--? extends K, ? extends V--> map, long expireAfterWrite, TimeUnit timeUnit);\n  CacheResult REMOVE(K key);\n  CacheResult REMOVE_ALL(Set<!--? extends K--> keys);\n  CacheResult PUT_IF_ABSENT(K key, V value, long expireAfterWrite, TimeUnit timeUnit);</code></p><p></p><p></p><h2>2.8&nbsp;分布式-缓存穿透</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/42/429d3e4b31e1d5e3ee5090c209e62fab.png\" /></p><p></p><p>分布式场景下的热点数据通常都保存在缓存当中，以减少数据库的压力，提升服务的性能。缓存击穿是指，攻击者利用随机访问的方式短时间大量的访问不存在的数据，由于数据不存在，所以缓存中查不到，请求越过缓存层直达数据库，造成数据库的压力激增。通常的解法有：[空值缓存] 及 [布隆过滤器]JetCache使用了较为轻量级的 [空值缓存] 方式，来解决这个问题。</p><p>@Cached(cacheNullValue=true)、@CreateCache(cacheNullValue=true)</p><p></p><p><code lang=\"null\">// AbstractCache.class\n​\nstatic  V computeIfAbsentImpl(K key, Function loader, boolean cacheNullWhenLoaderReturnNull,\n                                               long expireAfterWrite, TimeUnit timeUnit, Cache cache) {\n  .......\n    Consumer cacheUpdater = (loadedValue) -&gt; {\n    if(needUpdate(loadedValue, cacheNullWhenLoaderReturnNull, newLoader)) {\n        if (timeUnit != null) {\n          cache.PUT(key, loadedValue, expireAfterWrite, timeUnit).waitForResult();\n        } else {\n          cache.PUT(key, loadedValue).waitForResult();\n        }\n     }\n  };\n  ......\n  }</code></p><p></p><p></p><h2>2.9&nbsp;分布式-缓存击穿</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e3/e3578cdf3eb1bdf93108ce3f92751863.png\" /></p><p></p><p>CacheAside模式的缓存由于本身有淘汰策略，在数据失效后，缓存组件会直接访问数据库尝试重建缓存。在大规模分布式热点的情况下，一旦热点数据失效，会有大量的请求同时尝试重建缓存，这不但会导致资源浪费，更加危险的是会造成数据库瞬时极大的压力。JetCache通过注解@CachePenetrationProtect实现了JVM内存锁级的击穿保护，使并发重建的请求限制到可控范围。( 如果数据利用率高还可以使用@CacheRefresh的方式来实现基于分布式锁的缓存重建能力 )</p><p></p><p><code lang=\"null\">// AbstractCache.class\n​\nstatic  V computeIfAbsentImpl(K key, Function loader, boolean cacheNullWhenLoaderReturnNull,\n                                               long expireAfterWrite, TimeUnit timeUnit, Cache cache) {\n  ....\n    if (cache.config().isCachePenetrationProtect()) {\n      loadedValue = synchronizedLoad(cache.config(), abstractCache, key, newLoader, cacheUpdater);\n    } else {\n      loadedValue = newLoader.apply(key);\n      cacheUpdater.accept(loadedValue);\n    }\n  ....\n}</code></p><p></p><p></p><h2>2.10&nbsp;分布式-缓存雪崩</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dc/dc386b8aa263ceb111e5ede6e935673b.png\" /></p><p></p><p>缓存雪崩与缓存击穿类似，但是情况更为危机后果更为严重，有可能导致整个集群服务瘫痪。当大量热点缓存同时失效的时候，大量的缓存重建请求会直达数据库，造成服务节点瘫痪形成服务雪崩。缓存雪崩的处理方式较为复杂，但简单来说：&nbsp;可以建立多级缓存，通过设置不同的过期时间，形成重叠数据滑动窗口。通过服务主动维护异步任务的形式，维护一块永固缓存，防止热点失效。JetCache 可以通过多级缓存来避免这种情况。JetCache 还提供了@CacheRefresh和CacheLoader的方式，使服务有能力创建内建的时间块任务，来达到维护分布式环境下永固缓存的目的。</p><p></p><p><code lang=\"null\">// RefreshCache.class\n​\npublic void run() {\n  try {\n    if (config.getRefreshPolicy() == null || (loader == null &amp;&amp; !hasLoader())) {\n      cancel();\n      return;\n    }\n    long now = System.currentTimeMillis();\n    long stopRefreshAfterLastAccessMillis = config.getRefreshPolicy().getStopRefreshAfterLastAccessMillis();\n    if (stopRefreshAfterLastAccessMillis &gt; 0) {\n      if (lastAccessTime + stopRefreshAfterLastAccessMillis &lt; now) {\n        logger.debug(\"cancel refresh: {}\", key);\n        cancel();\n        return;\n      }\n    }\n    logger.debug(\"refresh key: {}\", key);\n    Cache concreteCache = concreteCache();\n    if (concreteCache instanceof AbstractExternalCache) {\n      externalLoad(concreteCache, now);\n    } else {\n      load();\n    }\n  } catch (Throwable e) {\n    logger.error(\"refresh error: key=\" + key, e);\n  }\n}</code></p><p></p><p></p><h2>2.11&nbsp;分布式-缓存失效/更新</h2><p></p><p></p><p>缓存数据也需要维护，尤其是缓存和实际数据不一致的情况下。例如用户数据，就非常需要缓存失效和缓存更新的能力，及时的在用户做了数据操作之后更新公共缓存的数据。JetCache通过@CacheInvalid和@CacheUpdate提供了这种能力，极大程度的避免了缓存数据不一致的情况，同时也增强了缓存操作的灵活性。</p><p></p><p><code lang=\"null\">public interface UserService {\n    @Cached(name=\"userCache.\", key=\"#userId\", expire = 3600)\n    User getUserById(long userId);\n​\n    @CacheUpdate(name=\"userCache.\", key=\"#user.userId\", value=\"#user\")\n    void updateUser(User user);\n​\n    @CacheInvalidate(name=\"userCache.\", key=\"#userId\")\n    void deleteUser(long userId);\n}</code></p><p></p><p></p><h1>三、JetCache框架设计剖析优势有哪些？</h1><p></p><p></p><p></p><h2>3.1&nbsp;支持多种KV序列化方式</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/86/86e7c7036afe505f77ec91058078eeaf.png\" /></p><p></p><p>CacheKey Convertor ：用来进行缓存Key的加工处理&nbsp;环境隔离：&nbsp;CacheKey在影演使用最广泛方式，抽象实现环境前缀Convertor就可以当前环境进行缓存前缀的拼接，从而达到数据隔离的目的。长短缓存：&nbsp;长短缓存通常使用对象缓存作为Key，为了容灾短缓存和长缓存通常使用了不同的缓存Key。通过实现长短缓存Convertor可以实现相同对象，可以控制长、短缓存的Key使用对象中的不同属性构造，从而达到短缓存提升性能，长缓存降级的目的。﻿ValueEncode、ValueDecode：用来提升缓存性能的绝佳方式高性能序列化：选择JavaSerialize、kyro、Kyro5的序列化方式可以极大程度的提升我们系统对性能的要求，很适合应对高并发环境的大流量压力。兼容性序列化：选择JSON（FastJson、FastJson2、Jackson）的方式，可以为缓存提供良好的兼容性。在架构设计的初期，完全可以采用这种方式来实现平稳迭代。加密序列化：当我们使用外部数据库的时候，我们可以自己实现ValueEncode和ValueDecode来保障我们数据的安全。</p><p></p><p></p><h2>3.2&nbsp;支持多种本地，远程缓存</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/97/977f298fd979ed84787f9306cef1a496.png\" /></p><p></p><p></p><h2>3.3&nbsp;多级缓存-乐高积木</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7e/7e0b003d6a7492b815ea726820aa02cf.png\" /></p><p></p><p>长短缓存：通过多级缓存加上KeyConvertor可以快速构建成本最低效率最高的长短缓存组件。用户缓存：互动用户数据很多，配合用户路由，可以结合 LocalCache + LDB 的方式既保证数据的可靠性，又能将性能从10ms -&gt; 1ms 级。自定义多级“缓存”：由于JetCache缓存的实现相当方便，我们甚至可以实现 Mysql，Opensearch 的Cache实现，并且把它组转到多级缓存之中，形成一种结构稳固的数据读写组件。</p><p></p><p></p><h2>3.4&nbsp;高级特性-加载器</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5a/5aab360dd88c86c4fa33e8d0d66e1ea4.png\" /></p><p></p><p><code lang=\"null\">// AOP 缓存 Example\n@Cached(expireTime= 5 * 60)\npublic Long loadOrderSumFromDatabase(String orderType);</code></p><p></p><p><code lang=\"null\">@CreateCache(expireTime= 5 * 60)\nprivate Cache orderSumCache;\n​\n// 每分钟拉取订单总数，形成持久缓存\n@PostConstruct\npublic void init(){\n  RefreshPolicy policy = RefreshPolicy.newPolicy(1, TimeUnit.MINUTES)\n    .stopRefreshAfterLastAccess(30, TimeUnit.MINUTES);\n  orderSumCache.config().setLoader(this::loadOrderSumFromDatabase);\n  orderSumCache.config().setRefreshPolicy(policy);\n}</code></p><p></p><p></p><h2>3.5&nbsp;高级特性-监听器</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9b/9b5ec9ab9fb644da1d28a88f807746da.png\" /></p><p></p><p>官方实现-数据报告</p><p><code lang=\"null\">// 数据报告Monitor的代码实现\npublic class DefaultCacheMonitor implements CacheMonitor {\n    public synchronized void afterOperation(CacheEvent event) {\n        if (event instanceof CacheGetEvent) {\n            CacheGetEvent e = (CacheGetEvent) event;\n            afterGet(e.getMillis(), e.getKey(), e.getResult());\n        } else if (event instanceof CachePutEvent) {\n            CachePutEvent e = (CachePutEvent) event;\n            afterPut(e.getMillis(), e.getKey(), e.getValue(), e.getResult());\n        } else if (event instanceof CacheRemoveEvent) {\n            CacheRemoveEvent e = (CacheRemoveEvent) event;\n            afterRemove(e.getMillis(), e.getKey(), e.getResult());\n        } else if (event instanceof CacheLoadEvent) {\n            CacheLoadEvent e = (CacheLoadEvent) event;\n            afterLoad(e.getMillis(), e.getKey(), e.getLoadedValue(), e.isSuccess());\n        } else if (event instanceof CacheGetAllEvent) {\n            CacheGetAllEvent e = (CacheGetAllEvent) event;\n            afterGetAll(e.getMillis(), e.getKeys(), e.getResult());\n        } else if (event instanceof CacheLoadAllEvent) {\n            CacheLoadAllEvent e = (CacheLoadAllEvent) event;\n            afterLoadAll(e.getMillis(), e.getKeys(), e.getLoadedValue(), e.isSuccess());\n        } else if (event instanceof CachePutAllEvent) {\n            CachePutAllEvent e = (CachePutAllEvent) event;\n            afterPutAll(e.getMillis(), e.getMap(), e.getResult());\n        } else if (event instanceof CacheRemoveAllEvent) {\n            CacheRemoveAllEvent e = (CacheRemoveAllEvent) event;\n            afterRemoveAll(e.getMillis(), e.getKeys(), e.getResult());\n        }\n    }\n}</code></p><p></p><p><code lang=\"null\">// 数据报告Monitor 的注册\npublic void addMonitors(CacheManager cacheManager, Cache cache, QuickConfig quickConfig) {\n    if (metricsManager == null) {\n        return;\n    }\n    DefaultCacheMonitor monitor = new DefaultCacheMonitor(quickConfig.getName());\n    cache.config().getMonitors().add(monitor);\n}</code></p><p></p><p>效果：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/18/18a2fe38d19a4d0c2d189237f16d7072.png\" /></p><p></p><p></p><p></p><h1>四、影演之路：影演如何发展了JetCache</h1><p></p><p></p><p>Jetcache在开源界如此火，离不开它遵循了JSR107标准，遵从于原则的设计和对原则的扩充使得它在学习效率上非常高效，代码结构上也非常优秀，并且它也在开放性和扩展性下足了功夫，真正实现了架构上的 ”正交“。</p><p></p><p>在电影演出BU内部，由于要应对业务的复杂性，所以需要针对Jetcache做一些比较定制化的扩展，其中有关于核心底层tair的支持，也有关于分布式场景管理的诉求，更有对业务瓶颈挑战的通用设计。</p><p></p><p>通过这些新的场景设计，我们极大的丰富了Jetcache的应用场景以及让它重新再集团中间件的环境之下，长出了新的分支，非常好的支撑的业务发展。</p><p></p><p></p><h2>4.1&nbsp;通用高并发三级缓存熔断组件</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fd/fda3c4dd33c9288b50411d36e344716f.png\" /></p><p></p><p></p><h2>4.2&nbsp;缓存后置写（Cache Write-Back）</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/18/180bc678e060dce54b373edd383fa46c.png\" /></p><p></p><p>缓存后置写是一种 Cache Write-Back 模式的实现：</p><p>1）缓存后置写由JetCache的Monitor来实现活跃事件的监控以及记录，每当有事件产生，后置写监控器就会被触发。</p><p>2）将需要缓存后置写的Cache实例通过Config.Monitor的方式添加好默认后置写监控器。</p><p>3）活跃Event 将会被不同的 缓存后置写实现捕获，并会将CacheKey缓存在一个唯一分布式队列中，等待调度。</p><p>4）我们通过了 ScheduleX 实现了分布式调度器，每分钟都会进行触发（当然每个后置写实现可能会有不同的触发频率）</p><p></p><p>目前影演使用缓存后置写实现了非常多的实用应用，包括：&nbsp;</p><p>影演评分数据准实时合并入库，同步至淘票票，大麦三方业务库。（ 准实时并发写方案，数据同步方案）线上、预发缓存准实时同步。 (环境数据一致性)数据变更对比，趋势数据记录。 ( 数据对账，数据趋势图 )本地缓存广播器。（ 本地缓存一致性，避免数据波动）</p><p></p><p></p><h2>4.3&nbsp;本地缓存广播器（LocalCache Distribute）</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8b/8bdb782b419d7786c382577679eec4c2.png\" /></p><p></p><p></p><h2>4.4&nbsp;稀疏列表缓存实现（MultiListCache）</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/40/4009f7b7278a9405cbc9c5b6c94bd17c.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/07/07e0af428c600b2bfb934848003dbf40.png\" /></p><p></p><p></p><h1>五、面向未来：JetCache还有哪些不足</h1><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/29/29b9a6f1041d7812e0c1aa769b71eb14.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/96b029c4292f23f8288af6b1f4b743c4.png\" /></p><p></p>",
    "publish_time": "2023-04-11 10:10:41",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "张勇：阿里巴巴所有产品未来将接入大模型全面改造",
    "url": "https://www.infoq.cn/article/7tuErOzX9lV5G8ffxfDE",
    "summary": "<p>4 月 11 日，<a href=\"https://www.infoq.cn/video/q6qgde5XiKFIxtmr84ju\">阿里巴巴</a>\"集团董事会主席兼 CEO、阿里云智能集团 CEO 张勇在云峰会上表示，阿里巴巴所有产品未来将接入<a href=\"https://www.infoq.cn/article/MBhLRG3KXdBw3QSJL2gR\">“通义千问”大模型</a>\"，进行全面改造。他认为，面向 AI 时代，所有产品都值得用大模型重新升级。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a1/a107ebc88c80134a2de204ecfbcbd9bc.png\" /></p><p></p><p>张勇表示，AI 大模型的出现是一个划时代的里程碑，人类将进入到一个全新的智能化时代，就像工业革命一样，大模型将会被各行各业广泛应用，带来生产力的巨大提升，并深刻改变我们的生活方式。</p><p>&nbsp;</p><p>自 2019 年起，阿里即开始进行大模型研究，并在近期推出阶段性的研究成果：通义千问大模型。张勇介绍，钉钉、天猫精灵等产品在接入通义千问测试后，变得聪明了很多，像天猫精灵，不仅能回答家里小朋友的各种刁钻问题，还多了一份情感连接，成为更温暖更人性化的智能助手。</p><p>&nbsp;</p><p>钉钉接入通义千问测试之后，可以自动生成工作方案，也可以在会议纪要后自动生成总结和待办事项，还能拍一张功能草图自动生成小程序。</p><p>&nbsp;</p><p>阿里巴巴决定未来将所有产品接入通义千问，进行全面改造。张勇表示，面向 AI 时代，所有产品都值得用大模型重做一次，基于这一信念，阿里云希望帮助更多企业用上大模型，让每家企业都能基于“通义千问”，拥有具备自己行业能力的专属大模型。</p><p>&nbsp;</p><p>他同时指出，大模型是一场“ AI+云计算”的全方位竞争，超万亿参数的大模型研发，并不仅仅是算法问题，而是囊括了底层庞大算力、网络、大数据、机器学习等诸多领域的复杂系统性工程，需要有超大规模<a href=\"https://www.infoq.cn/article/lj4SMzSjJxNMYrGf5lob\"> AI 基础设施</a>\"的支撑。</p><p>&nbsp;</p><p>张勇表示，面对全新的 AI 时代，阿里云已经做好了准备。十多年来，阿里云已经累积了从飞天云操作系统、芯片到智算平台的“AI+云计算”的全栈技术实力，今天，阿里云将把这些AI基础设施和大模型能力向所有企业开放，共同推动 AI 产业的发展。</p><p>&nbsp;</p><p>“一家企业的想象力终归是有限的，释放 AI 潜力要靠无数人探索。”张勇说。</p>",
    "publish_time": "2023-04-11 10:39:45",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "信创基础软件赛道提速升级，云轴科技ZStack获数亿元C轮融资",
    "url": "https://www.infoq.cn/article/yiD9hlHxBWADzsWI6eq0",
    "summary": "<p>InfoQ获悉，近日，云计算基础软件企业<a href=\"https://www.infoq.cn/article/OEJlBw6abL2XkWu3oKUN\">云轴科技ZStack</a>\"宣布获数亿元C轮融资。本轮融资由国鑫创投、君联资本领投，国方创新、接力资本、七海资本跟投，腾达资本担任融资顾问。本轮融资将用于加大云计算基础软件关键技术的研发投入，扩大政府、通信、金融等重点领域与区域市场覆盖，加强合作伙伴生态系统建设等三大方向。</p><p>&nbsp;</p><p>ZStack创始人兼CEO张鑫表示：“数字中国建设正在推动中国信息技术产业链加速形成，基础软件行业在信创趋势下面临巨大机遇和挑战。ZStack一直致力于云计算基础软件产品化，为3000多家企业级用户提供自主创新的软件基础设施。通过此轮融资，我们将继续坚持产品化道路，加速基础软件关键技术创新进程，与合作伙伴一道助推数字中国建设发展。”&nbsp;</p><p>&nbsp;</p><p>据悉，ZStack成立于2015年，创始团队由国内虚拟化、云计算领域的“黄金一代”组成，以产品化理念切入云计算基础软件市场，先后获阿里云、中国电信战略投资，是国家级“专精特新”小巨人企业。作为云计算基础软件企业，ZStack坚持自主创新，自研架构，具备完全自主知识产权，产品矩阵可全面替代VMware核心产品线，涵盖云平台/虚拟化、分布式存储、容器云平台、多云管理平台、超融合一体机、边缘一体机等。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e1/e14fa7023ca21a5755e38c65a43b4b84.png\" /></p><p></p><p>信创是数字中国建设的重要组成部分，也是数字经济发展的关键推动力量。基础软件是信创产业的重要底座，也是各行业用户业务运行的关键载体，中国各行业用户将以信创和云化并行的方式进行新一轮数字化升级。</p><p>&nbsp;</p><p>随着近几年我国云计算产业日益发展，云计算已经进入到千行百业中。而在全面上云的大趋势下，信创产业也开启了“上云”旅程。“十四五”规划更是对行业数字化转型有了明确的指示和方向指引。在这一背景下，可以预见的是，信创产业将加速上云，而信创云也将迎来新的发展机遇。</p><p>&nbsp;</p><p>云轴科技 ZStack 信创产品部总经理许佳珺此前在接受 InfoQ 采访时表示，信创即信息技术应用创新，最大的特点是要基于国内一些行业的特征及需求，做功能和方案上的创新，而不是简单地做技术套用，并且要做到国产化，自主开发。此外，从产品形态和部署方式上来讲，有各种各样的云，如果把信创和云的需求结合起来会发现，目前信创云的整体发展还达不到其他信创基础软件技术的发展水平，甚至很多时候还是基于国外的一套基础方案再去做，比较落后。</p><p>&nbsp;</p><p>基于这些特点，许佳珺认为，信创云的建设一定是基于一些特定业务、场景，做的带有一定探索和验证性质的建设部署，并且更多是从中小规模开始试点。“简单来说，我理解的信创云就是国产化、自主开发的，同时可以针对于国内信创行业的场景和特点有所创新，能够迭代快速部署的一个云平台软件。”</p><p>&nbsp;</p><p>据悉，2017年，ZStack就打造了ARM国产云平台，成为能同时支持x86和ARM架构服务器的云基础软件企业，并在2018年云上贵州电子政务、精准扶贫等项目当中投入实际应用；2019年，ZStack正式推出信创云平台，在2020年实现产品级“一云六芯”，全面奠定了与主流信创软硬件企业的合作基础，并获首届全国信创大赛特等奖；2021年，ZStack联合麒麟、鲲鹏获云计算性能测试国际标准SPEC Cloud测评全球第一名。</p><p>&nbsp;</p><p>目前，ZStack 已经落地超过400朵信创云，为上海市闵行区政务云、天津市滨海新区政务云、安徽电信、中国出口信用保险、齐鲁银行、甘肃农信、东海证券、申银万国期货、上海金融信创联合攻关基地等关键客户构建信创云底座，还携手600家合作伙伴助力新疆气象局、黑龙江交警、旭阳集团、华中电力、四川高速、郑州市第一人民医院、南京大学、紫金山实验室、徐工集团等超过3000家企业级用户数字化转型，覆盖党政、金融、石油、电力、电信、交通、航空航天、医疗、教育、制造等行业领域。</p>",
    "publish_time": "2023-04-11 12:13:03",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "疯狂烧钱、管理混乱、竞争激烈，Stable Diffusion 背后的明星企业濒临倒闭",
    "url": "https://www.infoq.cn/article/dF8gUGECaxBzgMr3oaEH",
    "summary": "<p>Stability AI是开源图像生成器Stable Diffusion背后的初创公司。最近<a href=\"https://futurism.com/the-byte/stable-diffusion-stability-ai-risk-going-under\">有媒体报道称</a>\"，该公司正在以惊人的速度烧钱，但却没有明确的盈利途径。此外，Stability AI还面临来自一众初创企业和科技巨头的竞争。目前，该公司现在正在寻找新的高管人才，希望他能在对手环伺的条件下帮助销售并给公司带来收入，以解决当前“疯狂烧钱、营收可怜”的窘况。</p><p>&nbsp;</p><p></p><h2>疯狂烧钱</h2><p></p><p>&nbsp;</p><p>Stability AI成立于 2019 年，是生成式 AI 行业中最知名的公司之一。</p><p>&nbsp;</p><p>与 ChatGPT、DALL-E 和 Midjourney 等项目不同，Stable Diffusion 是开源的，这意味着任何人都可以查看或下载代码，配置一张家用中高端显卡，就能在本地训练和部署AI模型。从开源角度来说，Stable Diffusion更像是回到了OpenAI的初衷。</p><p>&nbsp;</p><p>去年底，Stability AI宣布<a href=\"https://www.infoq.cn/article/V24vD7kvHyuT3byVVObJ\">融资 1.01 亿美元</a>\"，并宣称Stable Diffusion已被全球超过200,000名开发者下载和授权，成为当前可用性最高的开源模型。而据《福布斯》报道，每天有 1000 万人使用 <a href=\"https://www.infoq.cn/article/p1DHKrHQjEsQvDcr9jlM\">Stable Diffusion</a>\"——比使用 OpenAI 的 DALL-E 2 的人数还要多。同时，Stability AI 提供面向消费者的产品DreamStudio， 该产品目前拥有来自 50 多个国家/地区的 100 万注册用户，总共创建了超过 1.7 亿张图像。&nbsp;</p><p>&nbsp;</p><p>目前，<a href=\"https://www.infoq.cn/article/MYYhWiSNPaAQIGfZywa0\">Stability AI</a>\"还在探索商业模式，但公司实现的营收，完全覆盖不了巨额的服务器和人才招募的费用。</p><p>&nbsp;</p><p>关于训练模型所需的计算资源和成本，Stability AI的CEO Emad Mostaque曾在Twitter上回复一位用户时说：“实际上，我们为这个模型使用了 256 个 A100 显卡，总共 15 万小时，所以按市场价格计算为 60 万美元。”</p><p>&nbsp;</p><p>可对比GPT-3的单次训练成本的460万美元，总而言之，模型训练是一个相当烧钱的事情。据透漏，公司去年融到的1亿美元至今已经“烧”掉大半。另外，在上个月，Stability AI 还斥资收购了<a href=\"https://www.prnewswire.com/news-releases/stability-ai-acquires-init-ml-makers-of-clipdrop-application-301764600.html\">成像工具 Init ML</a>\"。&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/03/03b16a8c473f73a1c5c1cf95c8b7c10e.jpeg\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>而且在过去的几年里，为形成自己的生态，Stability AI一直在资助几个人工智能研究社区，社区人数从一千到五万不等。其中很多是来自不同领域的 3D 游戏开发人员、图形工程师或博士生，也有一些是业余爱好者。根据<a href=\"https://innovationorigins.com/en/ai-software-from-stability-ai-is-genuinely-open-source-anyone-can-join-in-discussions/\">之前采访</a>\"的说法，Stability AI对他们提供经济支持和计算能力，“我们的首席执行官Mostaque与这些社群取得了联系，并为每个社区的两三名主要研究人员提供资金和计算能力。”</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/da/da278cd9526462735b88df91a91a935c.jpeg\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7c/7c1e796f1a29f42aad5a554a66211ef7.jpeg\" /></p><p>截图来自：https://news.ycombinator.com/item?id=35487364</p><p>&nbsp;</p><p>彭博社报道称 Stability AI 正在谋求新一轮融资，希望能将公司的估值翻4番至40亿美元。不过也有不具名VC表示，并不太认可这个估值，两位不愿透露姓名的风险投资者正在重新考虑是否参与新一轮的融资。</p><p>&nbsp;</p><p></p><h2>管理混乱</h2><p></p><p>&nbsp;</p><p>另外，部分 Stability AI 的雇员也对 Mostaque 的领导风格“失去信心”。Mostaque 今年 39 岁，此前主要的职业生涯是对冲基金分析师，虽然他有计算机科学的学位，但并没有科研经验，更不用说AI研究了。但Mostaque倾向于给AI研究人员非常大的自由度，例如在没有监管的情况下不限时地随意使用昂贵的云服务。</p><p>&nbsp;</p><p>一位前雇员表示，Mostaque有时也会突然介入接管一个项目。知情人士透露，伊马德将会继续担任CEO，他倾向于引入一名专门帮助公司实现扭亏为盈的专家啊，类似于Facebook时期的首席运营官雪莉·桑德伯格。</p><p>&nbsp;</p><p>另外，Stability AI也有别于竞争对手，首先OpenAI背后有微软，Midjourney选择与谷歌合作，面对微软和谷歌这样的“钞能力”玩家，Stability AI并没有深不见底的金钱口袋，也没有金主承担训练模型的巨额费用。</p><p>&nbsp;</p><p>更为关键的是，Stable Diffusion并不是公司完全独立开发出来的商品。Stable Diffusion 结合了两种形式的人工智能，可将文本提示转换为图像，由众多合作者创建，合作者包括德国慕尼黑大学的研究人员以及一众商业公司。数年前，这些研究人员已经开始研究如何将自然语言描述绘制成图片，Stability AI找到并资助他们搞AI开源大模型等其他研究。</p><p>&nbsp;</p><p>据知情人士透露，对冲基金经理出身的Mostaque还自掏腰包，亲自资助了构建稳定扩散模型所需的昂贵计算能力，为公司购买AWS的算力提供价值7500万美元的担保。这些人说，当 AWS 的巨额账单到期时，Stability 在 10 月份刚刚结束其风险投资回合。</p><p>&nbsp;</p><p></p><h2>竞争加剧，但商业模式还不够清晰</h2><p></p><p>&nbsp;</p><p>虽然Stable Diffusion在去年8月发布后获得了不错的反响。但短短几个月后，差不多同期登场的Midjourney已经能击败 OpenAI 的 DALL-E，在文字生成图像的赛道上处于领跑位置。举例而言，近些日子非常火的“特朗普被捕照”就是作者使用这款产品生成的。</p><p>&nbsp;</p><p>今年2月，<a href=\"https://www.businessinsider.com/stability-ai-ceo-employees-going-die-openai-google-meta-report-2023-2\">据报道</a>\"，作为OpenAI 的竞争对手，这位 Stability AI 的首席执行官警告员工，随着竞争的加剧，他们“都将在 2023 年死去”。</p><p>&nbsp;</p><p>为了应对竞争，Mostaque招募了该领域的一些顶尖研究人员，包括 Andreas Blattmann、Dominik Lorenz 和 Robin Rombach。据悉，除了为Stable Diffusion开发升级服务外，也在开发自营大模型，以与 ChatGPT 竞争，不过该产品已被推迟，并不清楚何时能看到成品。</p><p>&nbsp;</p><p>据曾在该公司工作的人士和了解该公司计划的投资者称，他还追求一种非正统的商业模式和公司结构。</p><p>&nbsp;</p><p>为了获得营收，Mostaque想出了两个思路，一个是向那些有意整合AI工具的公司提供咨询服务，另一个是通过向主权财富基金的所在国设立卫星办公室，换取他们的投资承诺。不过短期内看上去Stability 似乎已经放弃了主权财富基金的战略。</p><p>&nbsp;</p><p></p><h2>写在最后</h2><p></p><p>&nbsp;</p><p>据了解Mostaque并与他共事过的人说，尽管他的领导方式混乱，但Mostaque深受大部分员工和人工智能行业人士的喜爱。也有很多人希望Mostaque能取得成功。</p><p>&nbsp;</p><p>如果 Stability 现在不是一团糟，可能更会令人惊讶。毕竟许多新兴的科技公司都很混乱，Mostaque也从未创立过科技公司，不是该行业的资深人士。他没有遵循任何熟悉的硅谷模板，但他的公司发展速度与任何热门初创公司一样快。</p><p>&nbsp;</p><p>这并不是说Stability注定会失败，它具有知名度和看上去算是成功的产品。如果它能够度过这个成长阶段，还是极有可能变得更强大。而且作为开源AI模型，Stability AI 将从中受益。</p><p>&nbsp;</p><p>有一种观点认为，开源人工智能模型是大公司和政府机构唯一可以真正信任的模型。开源将允许他们定制模型并在自己的计算机系统上运行，因此能有效管理潜在敏感数据。</p><p>&nbsp;</p><p>正如 Mostaque 4 月 5 日发送的<a href=\"https://twitter.com/EMostaque/status/1643650796930596865?s=20\">推文中所说</a>\"：“算法和数据集的透明度，实际上开放的 AI(.com) 将对我们的发展至关重要。”“大型黑匣子系统并不适合社会关键系统等任务。”</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/da/da37a113d40604365cec71cf72c4915d.jpeg\" /></p><p></p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.semafor.com/article/04/07/2023/stability-ai-is-on-shaky-ground-as-it-burns-through-cash\">https://www.semafor.com/article/04/07/2023/stability-ai-is-on-shaky-ground-as-it-burns-through-cash</a>\"</p><p><a href=\"https://www.businessinsider.com/stability-ai-ceo-employees-going-die-openai-google-meta-report-2023-2\">https://www.businessinsider.com/stability-ai-ceo-employees-going-die-openai-google-meta-report-2023-2</a>\"</p><p><a href=\"https://innovationorigins.com/en/ai-software-from-stability-ai-is-genuinely-open-source-anyone-can-join-in-discussions/\">https://innovationorigins.com/en/ai-software-from-stability-ai-is-genuinely-open-source-anyone-can-join-in-discussions/</a>\"</p><p><a href=\"https://www.prnewswire.com/news-releases/stability-ai-acquires-init-ml-makers-of-clipdrop-application-301764600.html\">https://www.prnewswire.com/news-releases/stability-ai-acquires-init-ml-makers-of-clipdrop-application-301764600.html</a>\"</p><p><a href=\"https://venturebeat.com/ai/stable-diffusion-creator-stability-ai-raises-101m-funding-to-accelerate-open-source-ai/\">https://venturebeat.com/ai/stable-diffusion-creator-stability-ai-raises-101m-funding-to-accelerate-open-source-ai/</a>\"</p>",
    "publish_time": "2023-04-11 13:57:30",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "热点聚焦|金融科技新闻速览（4.8-4.11）",
    "url": "https://www.infoq.cn/article/28ZmXcrRWC90ibRpzgTB",
    "summary": "<p>微众银行依托数字科技将区块链技术应用产业数字化；北京银行首次介绍“数字京行”战略体系；邮储银行打造个人金融业务“双子星”；兴业银行上线人民币跨境支付系统债券通直通服务；……一文速览金融科技领域新动向！</p><p>&nbsp;</p><p></p><h4>微众银行依托数字科技，将区块链技术应用产业数字化</h4><p></p><p></p><p><a href=\"https://www.infoq.cn/article/OJaT*6JGmhfqp2ipBYm2\">微众银行</a>\"是国内首家数字银行，坚持科技创新驱动核心业务发展，依托金融科技探索金融机构服务实体经济的新方向。微众银行将区块链作为金融科技的核心技术之一，助力产业数字化发展，助力经济稳定发展。据悉，微众银行构建了面向金融和新基建的全栈区块链技术体系，发布了 12 个主要开源项目，160 余个代码仓库，有效助力国家推进关键技术安全可控战略的落地，微众银行牵头金链盟开源工作组完成的开源国产<a href=\"https://www.infoq.cn/article/TVocv80lDp1Y9BOkDY8H\">区块链底层平台 </a>\"FISCO BCOS 已成功支持政务、金融、农业、公益、文娱、供应链、物联网等领域的数百个区块链应用场景落地。</p><p>&nbsp;</p><p></p><h4>北京银行形成“数字京行”战略体系，设立金融科技委员会</h4><p></p><p></p><p>近日，北京银行首次介绍了其“数字京行”战略体系。具体来看，北京银行树立“一个银行（One Bank）、一体数据（One Data）、一体平台（One Platform）”的理念，贯穿总行为分行服务、分行为支行服务、全行为一线服务的思想，运用清单化管理、项目化推进、责任化落实、矩阵式管控的工作方法，以数字化转型统领发展模式、业务结构、客户结构、营运能力和管理方式“五大转型”。基于“数字京行”的战略布局，在组织配合上，北京银行成立数字化转型战略委员会、金融科技委员会、北京市首家金融企业科学技术协会。底层技术上，北京银行建设统一数据底座，打通数据竖井；建设统一金融操作系统，打通系统竖井。据悉，北京银行按照“五高两低一智能”（高并发、高穿透、高协同、高一致、高体验；低代码、低耦合；智能化）的方向，积极推进统一金融操作系统建设，将于 2023 年 6 月底实现系统上线。</p><p>&nbsp;</p><p></p><h4>重庆农村商业银行推进转型变革，持续创新发展手机银行</h4><p></p><p></p><p>重庆农村商业银行加快融合科技与业务，通过数字化授信、线上支用、贷后智能管理等有效提升业务效率。据悉，全行日均智能决策 85 万笔、同比增长 1.2 倍，上线机器人流程自动化场景 34 个、处理效率平均提升 12 倍。推出 AI 融合的仿真数字员工“小渝”，应用 RPA 自动化流程 40 余个，传统劳动密集型业务不断由数字劳动力替代。技术对业务的支撑能力不断提高，企业网银 4.0、手机银行 7.0 及助农乡村版成功发布，电子交易替代率达 97%。科技系统建设加快优化升级，业务中台、管理中台、智能中台系列项目逐步实施，运营效率持续提升。</p><p>&nbsp;</p><p></p><h4>邮储银行：手机银行 APP+邮储银用卡 APP ——打造个人金融业务“双子星”</h4><p></p><p></p><p>近日，<a href=\"https://www.infoq.cn/article/Pdc9ycGOY44NLmHFS1Pr\">邮储银行</a>\"推出手机银行 8.0，主要突出五个新特征：一是“新”面貌。聚焦不同客群差异化需求，推出六大版本，十余款主题皮肤，实现了“千人千面”的极致体验。二是“新”生态。基于精确的地理定位能力、丰富的场景开放能力和强大的数智驱动能力，支持产品及服务的个性化推送，打造个人服务数字生态。三是“新”智慧。依托强大的数据储存和处理能力，支持查询长达 8 年的交易明细。四是“新”交互。采用生物识别、大数据风控等技术，重塑业务流程，推动主动授信产品；升级远程交互方式大幅提升语音识别效果，全流程提升交互体验。五是“新”保障。运用智能风控、人脸识别、客户画像等技术，依托强大完善的反欺诈系统，实现风险交易实时阻断，大幅提升手机银行转账限额，简化低风险账户间的转账操作。此外，邮储银行全新推出“邮储信用卡” APP4.0 版本。基于邮储银行个人金融业务 APP“双子星”战略，秉承以客户为中心的理念，新增大字版、服务大厅、商户扫码分期等便捷功能，进一步提升客户体验。</p><p>&nbsp;</p><p></p><h4>兴业银行上线人民币跨境支付系统债券通直通服务</h4><p></p><p></p><p>近日，在跨境清算公司的支持下，兴业银行携手国泰君安证券股份有限公司成功上线中国人民币跨境支付系统（CIPS）债券通直通服务，完成国内首笔债券通结算银行和债券通参与者间线上债券通资金结算业务。据了解，本笔业务通过全流程线上化形式实现资金结算、国际申报的直通化处理，大幅简化传统方式债券通结算银行与债券通参与者（“北向通”做市商和“南向通”投资者）线下人工交互流程，有效打通了债券通业务项下跨境人民币结算的“最后一公里”，助力债券通参与者实现流动性管理更可控、结算时效性更强、数据申报更便利。</p>",
    "publish_time": "2023-04-11 15:30:05",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "一文速览汽车技术领域新动向！（4.8-4.11）",
    "url": "https://www.infoq.cn/article/6LOguiSo3Zhbdf0cLGw5",
    "summary": "<p>大疆车载将配套比亚迪提供高级辅助驾驶技术；AITO 问界 M5 智驾版将于 4 月 17 日发布；黑芝麻智能发布武当系列智能汽车跨域计算平台及其首款芯片 C1200；比亚迪云辇智能车身控制系统正式发布……一周过去，汽车界又发生了哪些新鲜事？我们来看看！</p><p>&nbsp;</p><p></p><h4>大疆车载将配套比亚迪，提供高级辅助驾驶技术</h4><p></p><p></p><p>据悉，大疆车载已经获得比亚迪的项目定点，将为比亚迪提供高级别辅助驾驶技术方案。消息人士透露，合作方案中包括不依赖高精地图的城市 NOA（Navigate on Autopilot，即城市领航辅助驾驶）。据大疆车载介绍，其入门版的城市 NOA 方案可采用纯视觉路线，依靠 9 个摄像头、80TOPS（运算能力单位）就能摆脱<a href=\"https://www.infoq.cn/video/umHON6SPmuZxht6VSkvB\">高精地图</a>\"依赖，实现泊车辅助、记忆泊车、记忆行车、高速领航驾驶，城区领航驾驶等功能。大疆车载表示，目前产品已处于可用状态，正在积极推进量产进程。</p><p>&nbsp;</p><p></p><h4>AITO 问界 M5 系列华为高阶智驾版官宣 4 月 17 日发布：突遇变道，灵活绕行</h4><p></p><p></p><p>4 月 10 日消息，AITO 汽车官方宣布，AITO 问界 M5 智驾版将于 4 月 17 日发布。据了解，AITO 问界 M5/M5 EV 高阶智能驾驶版造型有所变化，主要是加强辅助驾驶功能，配备位于车顶凸出的激光雷达，同时还增加了一颗后视镜雷达和全视角 ADAS 摄像头，计算单元也将更换为华为自研的 MDC。动力方面，高阶智能驾驶版将继续提供增程版与纯电版以供消费者选择。</p><p>&nbsp;</p><p></p><h4>华为智能座舱为极狐阿尔法 S・HI 版车型推送新 OTA 升级</h4><p></p><p></p><p>4 月 8 日消息，<a href=\"https://www.infoq.cn/article/J8cbCCtGIa3BCz39cWb9\">华为智能</a>\"汽车解决方案官方微博宣布，将为极狐阿尔法 S・HI 版车型的华为智能座舱推送新 OTA 升级。从华为智能汽车解决方案官方微博处获悉，此次 OTA 升级主要包括以下内容：车机日程与手机更同步；个人账号登入更便捷；语音识别更准确；音频策略更智能（重点音效优先提醒）；座椅记忆交互逻辑优化；中控屏幕优化。</p><p>&nbsp;</p><p></p><h4>黑芝麻智能武当系列智能汽车跨域计算平台发布：首款芯片 C1200 采用 7nm 工艺</h4><p></p><p></p><p>近日，黑芝麻智能今天宣布公司定位升级，从“自动驾驶计算芯片的引领者”升级为“智能汽车计算芯片的引领者”，发布全新产品线——武当系列智能汽车跨域计算平台及其首款芯片 C1200。据了解，黑芝麻智能武当系列 C1200 基于 7nm 制程，使用支持锁步的车规级高性能 CPU 核 A78AE，和车规级高性能 GPU 核 G78AE，提供强大通用计算和通用渲染算力；自研 DynamAI NN 车规级低功耗神经网络加速引擎，支持 NOA 场景；内置成熟高性能 Audio DSP 模块和每秒在线处理 1.5G 像素的新一代自研 NeuralIQ ISP 模块；提供 32KDIPMS 的 MCU 算力；能同时处理大于 12 路高清摄像头的输入，支持高速率的 MIPI。同时，C1200 内置支持 ASIL-D 等级的 Safety Island 和国密二级和 EVITA full 的 Security 模块，满足车规安全等级最高的可靠性要求。此外，C1200 能够灵活支持行业现在和未来的各种架构组合，单颗芯片满足包括 CMS 系统、行泊一体、整车计算、信息娱乐系统、智能大灯、舱内感知系统等跨域计算场景。</p><p>&nbsp;</p><p></p><h4>比亚迪云辇智能车身控制系统正式发布</h4><p></p><p></p><p>4 月 10 日，比亚迪云辇智能车身控制系统正式发布。在活动现场，比亚迪董事长兼总裁王传福表示，云辇是行业内首个新能源专属智能车身控制系统，不仅填补了国内在这方面的技术空白，实现从 0 到 1 的突破，更超越了国外技术水平，实现了从 1 到 2 的提升。据悉，云辇将搭载在比亚迪王朝海洋旗舰车型、腾势、仰望以及比亚迪专业个性化品牌的车型上。</p><p>&nbsp;</p><p></p><h4>东风汽车发布全新电动化平台“量子”</h4><p></p><p></p><p>4 月 10 日，东风汽车发布全新电动化平台“量子”。据悉，新平台续航里程可以达到 1200 公里以上，将配备 800V 高压快充技术，并支持共享换电。按照东风汽车的产品规划，未来新平台年产量预计将达 100 万辆。</p><p>&nbsp;</p><p></p><h4>阿维塔 11 汽车在“8D 山城”重庆开启城区 NCA 智驾导航辅助试驾体验</h4><p></p><p></p><p>4 月 10 日消息，阿维塔宣布，即日起在重庆正式开放阿维塔 11 城区 NCA 智驾导航辅助功能的用户试驾体验。阿维塔成为首个在 8D 山城落地城区 NCA 智驾导航辅助的品牌。与此同时，AVP 代客泊车辅助功能也完成了首次亮相，展示出多楼层停车场环境建模、智能导航至车位并无缝衔接自动泊入的实力。阿维塔 11 城区 NCA 智驾导航辅助和 AVP 代客泊车辅助在内的智驾服务均基于 HI 华为全栈智能汽车解决方案。</p><p>&nbsp;</p><p></p><h4>2023 滴滴自动驾驶开放日活动官宣 4 月 13 日举行</h4><p></p><p></p><p>4 月 10 日消息，滴滴出行官方宣布，<a href=\"https://www.infoq.cn/article/fUlKk6ge9T2AKaiF52PZ\">滴滴自动驾驶</a>\"开放日活动官宣 4 月 13 日 15:30 举行。据悉，滴滴自动驾驶旗下搭载双子星自动驾驶平台的 XC90 车型于今年 1 月通过安全技术检测和审核，入选广州智能网联汽车车型目录，意味着车辆具备示范运营的能力和条件。这批自动驾驶车能实现多方位的安全冗余，为乘客提供多重安全保障。对广州的多样化路况，滴滴自动驾驶也进行了针对性测试、打磨、提升。运营首日，滴滴自动驾驶车辆在雨中环境始终表现稳定。</p>",
    "publish_time": "2023-04-11 15:30:10",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]