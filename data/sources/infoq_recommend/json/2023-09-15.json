[
  {
    "title": "科技巨头是如何迷失方向的？探讨大型科技企业的问责制度",
    "url": "https://www.infoq.cn/article/0J1G2olqx7fF4N8ayoVG",
    "summary": "<p>大型科技公司似乎缺乏问责制；身居要职的人很少被追究责任。工程师应该意识到他们想要工作的公司文化，并关注他们的福祉，而公司应该投资于他们的领导者，以支持人们的最佳工作。Andy Walker在<a href=\"https://qconlondon.com/\">伦敦QCon 2023（QCon London 2023）</a>\"上发表了一篇关于科技巨头是如何迷失方向的演讲。</p><p>&nbsp;</p><p>Walker说到，随着公司的成熟，高层的问责制似乎消失了，而基层的问责制却在加强。完全可以想象，科技行业的裁员是为了摆脱那些公司领导人不想要的人。然而，与此同时，我们看到高管薪酬飙升，而且在大型科技公司担任资深职位（我们说的是董事及以上级别）的人因不良行为而被追究责任的情况非常罕见，Walker解释道：</p><p>&nbsp;</p><p></p><blockquote>例如，Sundar Pichai在解雇1.2万人的同时获得了超过2亿美元的薪酬，并表示自己别无选择，因为他雇佣了过多的人，这似乎是在奖励高层的失败。与此同时，12000名因非自身过错而失业的人不得不进入现在已经非常拥挤的就业市场。</blockquote><p></p><p>&nbsp;</p><p>沃克认为，作为工程师，我们需要真正意识到我们想要工作的公司文化：</p><p>&nbsp;</p><p></p><blockquote>我告诉很多最近受裁员影响的人的一件事是，你不是你为之工作的公司。如果你在科技行业工作，你在其他地方也会有机会。</blockquote><p></p><p>&nbsp;</p><p>Walker提到，呆在一个你觉得无法产生积极影响的地方，对你以后的心理健康是没有帮助的。不仅是对你，对你的工作也一样，而且你的首要任务是照顾好自己的健康。</p><p>&nbsp;</p><p>Walker说：“可悲的是，当你的公司文化消亡时，就需要有人进入最高层来重新启动它——你可能无能为力”。他提到，你可以看到类似的事情正在微软的Satya Nadella（萨蒂亚·纳德拉）的身上发生，尽管他们也盲目地效仿了推特的大规模解雇策略。在这种情况发生之前，你能做的就是向每一个走进公司大门的人强化你的企业文化。他说到，你不太可能阻止工作场所的公司化，但你可以减缓它。文化投资是一项持续的活动。如果你不这样做，那么你的文化就会变成发生在你身上的事情，而不是你有意识的选择。</p><p>&nbsp;</p><p>Walker建议公司应该投资于他们的领导者。领导者要么是支持人们把工作做到最好的地板，要么是限制人们把工作做到最好的天花板。他总结道，当你成为董事或副总裁时，你的工作就已经发生了变化。领导力不是要找到答案，而是要提出值得解决的问题，并提供一个可以解决这些问题的环境。当领导者提供解决方案而不是确定结果时，以及当他们开始谈论“追究人们的责任”时，这些都是需要警惕的预警信号。这两者都与合规而非创新有关。</p><p>&nbsp;</p><p>InfoQ采访了<a href=\"https://www.infoq.com/profile/Andy-Walker/\">Andy Walker</a>\"，讨论了科技巨头是如何衡量成功以及如何扭转行业趋势的。</p><p>&nbsp;</p><p>InfoQ：科技巨头是如何衡量成功的？这会产生什么影响？</p><p>&nbsp;</p><p></p><blockquote>Andy Walker：当你用增长来衡量成功时，你就会以一种糟糕的方式违背古德哈特定律（Goodhart’s Law）。古德哈特定律可以概括为“当一项措施成为目标时，它就不再是一项好的措施”。如果你看看大型科技公司报告的增长方式，就会发现它是活跃用户（在某些情况下是用户粘性）。如果你看看无问责制的言论自由问题，那么你应该能够立即发现问题所在。科技公司屏蔽的每一个用户都是他们没有货币化的用户，因为这会损害他们的增长故事。&nbsp;这对于持极端观点的人来说尤其如此。对用户安全的投资变成了一种胁迫行为。实现零滥用是不可能的，但大型科技公司将这方面的投资视为成本中心，认为会损害其增长。因此，与能带来增长的事项相比，它的优先级经常被降低。</blockquote><p></p><p>&nbsp;</p><p>InfoQ：公司可以做些什么来扭转这个行业的负面趋势？</p><p>&nbsp;</p><p></p><blockquote>Walker：公司在支持员工应对这些变化方面需要非常具体，并为他们的领导者设定明确的期望。他们需要建立制衡机制，以便在高层人员造成真正伤害之前追究其责任。&nbsp;他们需要停止将奖励“货物装箱”和“帝国建设”作为职业发展和奖励影响力的手段，这是负责任的。他们需要奖励那些站在用户那边的人，而不是那些站在股东这边的人。采纳两者中任何一种观点都会对公司不利，而真正有效的领导者能够平衡这两种相互冲突的需求。</blockquote><p></p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/08/big-tech-accountability/\">https://www.infoq.com/news/2023/08/big-tech-accountability/</a>\"</p>",
    "publish_time": "2023-09-15 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "速度提升30%！Astro 3.0正式发布，第一个支持 View Transitions API 的框架",
    "url": "https://www.infoq.cn/article/hyMHv5EILGC77346OtoP",
    "summary": "<p>Astro 3.0 是首个支持 View Transitions API 的主流 Web 框架，能够轻松在页面导航间实现淡入淡出、滑动、变形及保留有状态元素。在此之前，这些功能还只能在 JavaScript 的单页应用（SPA）中实现。而随着 Web 平台的进步，现在 Astro 3.0 允许每位开发者灵活运用这些功能。</p><p></p><p>其他版本亮点还包括：</p><p></p><p>图像优化（稳定）：比以往效果更好。更快的渲染性能：Astro 组件渲染速度提高了 30% 至 75%。无服务器 SSR 增强：提供接入托管平台的新方法。为 JSX 提供 HMR 增强：React 与 Preact 获得快速刷新支持。优化构建输出：提供更清晰、性能更好的 HTML。</p><p></p><p>Astro 3.0 现已在 npm 上正式开放。大家可以阅 astro.new 在浏览器中试用 Astro 3.0，或者在终端中运行以下命令以创建新项目：</p><p></p><p><code lang=\"nginx\"># Create a new Astro 3.0 project:\nnpm create astro@latest\n</code></p><p></p><p>如果有意将现有项目升级至 Astro 3.0，您可以参考 v3.0 升级指南，了解各项变更的具体细节与对应升级说明：</p><p><a href=\"https://docs.astro.build/en/guides/upgrade-to/v3/\">https://docs.astro.build/en/guides/upgrade-to/v3/</a>\"</p><p></p><p></p><h2>Astro View Transitions</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/4e/4eb26877a96d1a450bde9e5bf683adca.png\" /></p><p></p><p>View Transitions 是一组新的平台 API，能够在多页之间实现浏览器原生级别的转换效果。以往，这种效果只能在单页应用（SPA）中实现，但网络浏览器和规范作者们过去几年间一直在努力将原生页转换纳入 Web 平台，而 Astro 3.0 也有幸成为首个达成这项目标的主流 Web 框架。</p><p></p><p>借助 Astro View Transitions，我们可以：</p><p></p><p>将持久元素从一页变形（morph）至另一页；淡入 / 淡出页面上的内容，减少导航前后的冲突感；将内容滑入 / 滑出当前页，实现个性化设计；跨页保留（persist）通用 UI，无论是否刷新。</p><p></p><p>Astro View Transitions 最大的亮点，在于其使用起来非常简单。只需 2 行代码，我们就能添加各种微妙且雅致的元素，在网站上实现漂亮的淡入效果。您如果感兴趣，可以尝试导入 ViewTransitions 组件并将其添加至任意页的元素内：</p><p></p><p><code lang=\"javascript\">---\n// src/pages/index.astro\n// Note: Make sure you add the \"\" component\n// to other pages as well, and not just one.\nimport {ViewTransitions} from 'astro:transitions';\n---\n\n  My View Transition Demo\n  \n\n\n  <!-- -->\n\n</code></p><p></p><p>自 Astro 2.9 版本起，用户们就已经提前享受到了 View Transitions 功能。我们技术社区也一直在开展试验、收集早期反馈，最终塑造出了大家如今看到的终版 API。下面来看社区中的一些出色演示，相信能帮助您了解新功能带来的无穷可能性：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/20/201df92c68ee04e13642ef39793facfb.png\" /></p><p></p><p>Joe Bell 演示的新 View Transitions 功能：</p><p><a href=\"https://twitter.com/joebell_/status/1688167865961037825\">https://twitter.com/joebell_/status/1688167865961037825</a>\"</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/cc/cccb3b103610b97476ed8c5c1b1742f6.png\" /></p><p></p><p>即将推出：无 JavaScript 页转换：</p><p><a href=\"https://twitter.com/astrodotbuild/status/1683514985115426817\">https://twitter.com/astrodotbuild/status/1683514985115426817</a>\"</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5f/5fb8fd76bf448aae133af0b2f46643a0.png\" /></p><p></p><p>Maxi Ferreira 带来的实时演示：</p><p><a href=\"https://astro-records.pages.dev/\">https://astro-records.pages.dev/</a>\"</p><p></p><p>可以看到，每段演示都拥有不逊于本机客户端的应用体验。这些可都是实实在在的 Web 应用，所有 HTML 均在服务器端渲染而成，通过 Astro 3.0 和新的 View Transitions API 实现。</p><p></p><p>我们付出了大量努力，让 View Transitions 得以在所有浏览器上均可正常工作，甚至包括那些尚不支持本机 View Transitions API 的浏览器。Astro 3.0 囊括了大部分浏览器的补充功能，并将其以约 3 kb 小脚本的形式自动添加至页面当中。</p><p></p><p>要了解关于 View Transitions 的更多细节信息，这里推荐大家参阅我们的 View Transitions 快速指南：</p><p><a href=\"https://docs.astro.build/en/guides/view-transitions/\">https://docs.astro.build/en/guides/view-transitions/</a>\"</p><p></p><p>Chrome 团队发布的精彩文章：</p><p><a href=\"https://developer.chrome.com/docs/web-platform/view-transitions/\">https://developer.chrome.com/docs/web-platform/view-transitions/</a>\"</p><p></p><p>另外，也欢迎您浏览 Chrome 开发者博客，具体了解 View Transitions 如何实施落地。</p><p><a href=\"https://developer.chrome.com/blog/astro-view-transitions/\">https://developer.chrome.com/blog/astro-view-transitions/</a>\"</p><p></p><p></p><h2>更强渲染性能</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/dd/dd2c1b28787cfcbb6159264833a29642.png\" /></p><p></p><p>Astro 3.0 的渲染性能也显著提升，大多数组件的渲染速度提高了 30%（相较于 Astro 2.9）。在复杂的基准测试中，速度增幅更可达到 75%。</p><p></p><p><a href=\"https://gist.github.com/bluwy/0cf63b46915244477cea91c7b34e90ec\">https://gist.github.com/bluwy/0cf63b46915244477cea91c7b34e90ec</a>\"</p><p></p><p>之所以能实现这样的加速效果，是因为我们自 Astro 2.10 版本起就在不断重构框架，最终在 Astro 3.0 中修得正果。我们从构建管线的热路径中尽量去除掉不必要的代码，并对剩余代码进行优化。众所周知，非必要生成器和异步代码是影响性能的两大罪魁祸首，您的每一毫秒我们都很关注！</p><p></p><p></p><h2>图像优化（稳定）</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3a/3a79a85474f4103aad4e8d033bf9965d.png\" /></p><p></p><p>图像优化功能现已在 Astro 3.0 中稳定实现，并适用于您的所有项目。</p><p></p><p>您可以从代码库导入图像，并使用新的内置<img />组件将其放置在页面上。Astro 将帮助大家处理余下的工作：构建管线以自动检测并优化每幅图像。最终渲染的图像标签会添加推断得出的宽度和高度，据此通过自动累积布局偏移（CLS）保护来防止出现布局偏移。</p><p></p><p><code lang=\"javascript\">---\n// Import the <img /> component\nimport { Image } from \"astro:assets\"\n// Import a reference to the image itself\nimport myImage from \"../assets/penguin.png\"\n---\n\n<img alt=\"A very cool penguin!\" src=\"https://www.infoq.cn/article/%7BmyImage%7D\" />\n</code></p><p></p><p>今年 6 月我们曾经介绍过图像优化功能，在接下来的几个月间，我们又相继取得多项重要改进，包括：</p><p></p><p>全面支持 Vercel 的内置图像服务。将 imageService: true 添加至您的 Vercel 集成配置当中，即可查看由其全球 CDN 优化得出的实际图像效果。转用 Sharp 作为我们新的默认优化库。Sharp 取代了我们之前默认使用的 @squoosh/lib，相关维护也将就此中止。支持远程图像优化。内容团队可以继续通过现有工作流程与 CMS 工具管理自己的图像。</p><p></p><p>关于图像优化的更多细节信息，请参阅我们的图像指南：</p><p><a href=\"https://docs.astro.build/en/guides/images/\">https://docs.astro.build/en/guides/images/</a>\"</p><p></p><p></p><h2>无服务器 SSR 增强</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a9/a97fd8e7e2d13d722ab12ec4704c16e3.png\" /></p><p></p><p>8 月底，我们宣布与 Vercel 建立新的官方托管合作伙伴关系。与 Cervel 的合作让我们得以对 Astro 3.0 中的 SSR 机制进行重大改进。这些新功能将使全体用户获益，且全面支持各种网站托管方式：</p><p></p><p>按路由代码拆分：为网站中的每个路由创建更小的独立服务器文件。无服务器用户（Vercel、Netlify、Cloudflare 等）可以借此减少每条请求上未使用的代码量，通过加载“瘦身”提高性能。边缘中间件：Astro 现可捆绑您的中间件以实现边缘位置部署。边缘中间件分布在全球范围之内，并将在尽可能靠近用户的服务器上运行。托管定制：由于每家托管服务商各有差异，因此我们为 Astro 添加了一个 API，以帮助用户更好地把握这些区别因素。托管适配器（例如 @astrojs/node 和 @astrojs/vercel）能够告知 Astro 各服务商能够支持哪些功能。Astro 则借此信息在开发流程中显示出信息丰富、更具指导性的警告，防止生产错误的意外发生。</p><p></p><p>上述功能现已登陆 Vercel，您也可以升级任意托管适配器并添加支持。在未来几个月中，我们将与社区维护人员合作，帮助将这些功能引入一切能够提供支持的托管平台。</p><p></p><p></p><h2>为 JSX 提供 HMR 增强</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f9/f9c8e9b846079491324a87298f796285.png\" /></p><p></p><p>由于我们对内部 JSX 构建支持进行了重大重构，因此 React Fast Refresh 现可在 Astro 3.0 中正常运行。React、Preact 和 Solid.js 用户都将在 Astro 3.0 中感受到热模块重新加载（HMR）和开发服务器整体稳定性的显著改进。</p><p></p><p>快速刷新是一项现代开发功能，能够以智能方式将本地变更推送至浏览器端，且无需刷新页面。快速刷新（与常规 HMR 相比）的独特之处，在于更新内容会被推送至浏览器，且不更改 UI 的当前状态。</p><p></p><p>在以下演示中，可以看到虽然开发者对模板本身进行了更新，但页面却一直不会刷新，且计数器也不会重置归零。这就是快速刷新在发挥作用。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/55/554977018530d58a8771a8c29d667456.png\" /></p><p></p><p>如果大家构建过 modal 或者其他多步骤 UI，肯定也曾被每次变更之后的页面状态刷新和重置折磨得头痛欲裂。快速刷新解决了这个问题，帮助您进一步加快开发流程。</p><p></p><p></p><h2>优化构建输出</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/cc/ccb01b3709379ef471a1599558d406ed.png\" /></p><p></p><p>我们对 Astro 3.0 中的整体构建输出做出了多项改进，包括：</p><p></p><p>HTML 缩小：Astro 3.0 现在会自动缩小所有 HTML 输出。缩小后的 HTML 能够减少网络加载量、提升整体响应速度。组件 ID：以往那些根本看不懂的 astro-XXXXXX 类名称现被替换成了新的专用 data-astro-cid-hash HTML 属性。这项变更将让您的 class=\"\"属性更具可读性，整体改善 HTML 输出的组织水平。CSS 内联：Astro 3.0 现在会自动将小块 CSS 内联至 HTML 当中。与旧版 Astro 相比，新设计能够提高页面加载性能。在旧版本中，页面可能会将多个小型 CSS 文件作为浏览器发来的单独请求进行加载，导致资源浪费。</p><p></p><p></p><h2>立即体验 Astro 3.0</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/dd/dd66198f188012cb73d0119a34638e6d.png\" /></p><p></p><p>Astro 3.0 目前已正式登陆 npm。您可以访问 <a href=\"https://astro.new/\">https://astro.new/</a>\" 在浏览器中试用 Astro 3.0，或者在终端中运行以下命令以创建新项目：</p><p></p><p><code lang=\"nginx\"># Create a new Astro 3.0 project:\nnpm create astro@latest\n</code></p><p></p><p>如果有意将现有项目升级至 Astro 3.0，您可以参考 v3.0 升级指南，了解各项变更的具体细节与对应升级说明：</p><p><a href=\"https://docs.astro.build/en/guides/upgrade-to/v3/\">https://docs.astro.build/en/guides/upgrade-to/v3/</a>\"</p><p></p><p></p><h5>原文链接：</h5><p></p><p><a href=\"https://astro.build/blog/astro-3/\">https://astro.build/blog/astro-3/</a>\"</p><p></p><p></p><h5>相关阅读：</h5><p></p><p><a href=\"https://www.infoq.cn/article/YMYGqq5x3i5P6klPGRkf\">Web 框架 Astro 2.0 发布，在静态和动态渲染之外提供了混合渲染能力</a>\"</p><p><a href=\"https://xie.infoq.cn/article/575a705c21b244d8c4bec0ac8\">浅析华为云&nbsp;Astro&nbsp;的 5 大关键能力技术</a>\"</p><p><a href=\"https://xie.infoq.cn/article/6ad6a05df82b8163f5f725760\">Astro&nbsp;低代码平台关键能力技术浅析</a>\"</p><p><a href=\"https://www.infoq.cn/article/GaBY0uTZ9plRpNL93bMe\">使用&nbsp;Astro&nbsp;如何构建 Astrobot Voice</a>\"</p>",
    "publish_time": "2023-09-15 10:11:42",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "4500亿元芯片巨头成功上市，首日大涨25%，成年内全球最大IPO",
    "url": "https://www.infoq.cn/article/469EAl58bc8DbDxlj3cu",
    "summary": "<p></p><h2>Arm IPO首日股价最高涨幅达25%</h2><p></p><p></p><p>当地时间9月15日，日本软银集团旗下芯片巨头Arm正式登陆纳斯纳克交易所，首轮公开募股（IPO）价格定为每股51美元。</p><p>&nbsp;</p><p>按照这一发行价计算，Arm的全稀释市值（包括已发行的限制性股票单位）将超过540亿美元。该公司在新闻稿中表示，上市交易定于本周四开始，股票代码为“ARM”。</p><p>&nbsp;</p><p>截至北京时间9月15日，00点30分，Arm最新市值为622亿美元（折合约4527亿人民币）。</p><p>&nbsp;</p><p>这家总部位于英国的芯片技术授权商将在纳斯达克发行至少9550万股美国存托股，其当前所有者软银将控制该公司约90%的流通股。</p><p>&nbsp;</p><p>而此次发行价，明显来到Arm原本预期的48至51美元区间中的顶端。</p><p>&nbsp;</p><p>Arm在招股说明书中表示，截至今年3月份的2023财年营收较上年下滑不到1%，至26.8亿美元。当财年净利润下降22%至5.24亿美元。</p><p>&nbsp;</p><p>Arm正搭乘AI技术的热潮，希望能在市场原地踏步近两年之后，重新开启科技IPO的大门。该公司也有望成为今年体量最大的新上市科技企业。</p><p>&nbsp;</p><p>与除英伟达以外的其他任何企业相比，Arm这家芯片厂商获得的估值都堪称相当可观。根据最新财年的利润报告，按540亿美元估值计算，Arm的市盈率已经来到约104倍。</p><p>&nbsp;</p><p>英伟达的市盈率的确更高、达到108倍，但这是AI芯片的旺盛需求与预计本季度收入增长170%这双重因素的推动结果。作为参照，Invesco PHLX Semiconductor ETF衡量了全美30家最大芯片企业的业绩水平，发现其平均市盈率约为25。</p><p>&nbsp;</p><p>根据IPO文件，AMD、苹果、Cadence、谷歌、英特尔、联发科的附属实体、英伟达、三星电子、新思科技、台积电等基石投资者，分别表示有兴趣购买Arm总计7.35亿美元的股票。目前，全球99%的移动处理器均采用Arm授权技术。此外，Arm已与苹果达成一项新的长期协议，将让苹果使用Arm架构的合作关系延续到2040年。</p><p></p><h2>全球约70%的人口用到了Arm的技术，竞争地位异常稳固</h2><p></p><p>&nbsp;</p><p>Arm架构用于描述中央处理器的底层运作方式，包括如何执行数学运算和如何访问计算机内存。这家公司成立于1990年，最初专为带有电池的设备制造芯片，随后乘智能手机芯片爆发的东风而迅猛发展。Arm指令集的运行功耗要明显低于以英特尔和AMD为代表的PC/服务器芯片搭载的x86架构。</p><p>&nbsp;</p><p>虽然Arm有不少客户只使用其提供的指令集来自行设计CPU，但Arm同时也会将自己的整套设计授权给芯片制造商，据此制造处理器当中的CPU核心。亚马逊在其部分服务器芯片中就使用到了Arm CPU设计。</p><p>&nbsp;</p><p>如今，Arm CPU运行着世界上绝大多数软件，包括智能手机、平板电脑、个人电脑、数据中心、网络设备乃至车载平台的各类操作系统与应用程序；还承载着智能手表、恒温器、无人机和工业机器人等设备中的嵌入式操作系统。据Arm估计，全球约70%的人口在使用基于Arm成果的产品，而且Arm的覆盖范围仍在不断扩大。</p><p>&nbsp;</p><p>Arm公司表示，截至 2023 年 3 月的财年，Arm 芯片的出货量超过 300 亿颗，全年出货量将超过 2500 亿颗。较截至2016年3月31日的财年增长了约70%。自公司成立以来芯片一直在出货。如今，任何企业都可以通过Arm的节能CPU知识产权和相关技术，配合Arm的其他合作伙伴打造出现代计算机芯片。</p><p>&nbsp;</p><p>在截至2023年3月31日的财年中，已经有超260家公司报告在售基于Arm的芯片，其中包括全球最大的科技公司（例如亚马逊云科技与Alphabet）、主要半导体芯片供应商（例如AMD、英特尔、联发科、英伟达、高通和三星电子）、汽车行业老牌厂商、领先的汽车技术供应商、物联网创新企业等。</p><p>&nbsp;</p><p>消费级与企业级市场中智能设备的指数级增长，也在算力提升和优化能效两个方面带来新的芯片需求。三十年前，PC设备是大多数人在家庭、办公或学校场景中操作的唯一计算形式。此后，手机成为口袋中的计算机，数字电视成为客厅中的计算机。如今，车辆实际上已经成为带轮子的计算机，而服务器与网络设备则是将以上一切装置与服务彼此对接起来的计算机。</p><p>&nbsp;</p><p>Arm官员在向投资者发表的演讲中指出，该公司在智能手机之外还有其他发展空间，包括为数据中心和AI应用设计更多芯片。Arm公司表示，预计到2025年全球芯片设计市场总值将达到约2500亿美元。</p><p>&nbsp;</p><p>Arm此番上市，也成为了自美国造车新势力 Rivian 在 2021 年 11 月筹资额 137 亿美元以来，美国规模最大的一次 IPO。</p><p>&nbsp;</p><p>晨星公司（Morningstar）股票分析师哈维尔·科雷奥内罗（Javier Correonero）表示，“从估值角度来看，该股看起来‘非常非常昂贵’”。</p><p>&nbsp;</p><p>Correonero 表示，Arm 技术的广泛采用使该公司“拥有非常稳固的竞争地位”。</p><p></p><h2>锚定人工智能领域，最大的客户在中国</h2><p></p><p>Arm 总部位于英国剑桥，其设计的芯片架构被应用在 99%的智能手机之上。</p><p>&nbsp;</p><p>该公司的历史可以追溯到一家名叫 Acorn Computers 的早期计算公司。1990 年，Acorn 又与苹果和美国芯片制造商 VLSI Technology 合资建立了 Advanced RISC Machines 这家新公司。</p><p>&nbsp;</p><p>Arm 本身并不属于芯片制造商。相反，该公司只负责提出“架构”或者整体设计，包括可供其他公司用于构建芯片的组件和编程语言指令。其最初的发展目标，就是设计出与 PC 设备中常规 x86 相比能耗极低的计算芯片。很多人把 Arm 视为科技领域的“瑞士”——即永远保持厂商中立。Arm 推出的设计方案几乎被应用于一切智能手机处理器，包括苹果制造的处理器，而且近年来也被越来越多地应用于服务器和笔记本电脑。</p><p>&nbsp;</p><p>Arm，已然成为英国科技行业皇冠上的明珠。Arm 公司 CEO Rene Haas 在 2022 年 10 月的开发者大会上接受采访时曾表示，鉴于该公司的技术几乎嵌入到一切设备当中，已经没有哪家企业能够完全避免跟 Arm 合作。Haas 当时指出，“考虑到我们将技术授权给行业内的所有主要参与者，已经没人能真正承担我们延误产品周期、缩减研发规模或者不发布产品的后果。”</p><p>&nbsp;</p><p>Arm 的商业模式就是对外授权这些架构知识产权，客户可以据此自行构建系统。近年来，Arm 还努力出售自己的处理器设计，这项业务的利润空间要比仅授权底层架构技术更加可观。</p><p>&nbsp;</p><p>2016 年，软银方面同意以 320 亿美元收购 Arm，这也是当时欧洲科技界有史以来规模最大的一笔收购。软银当时表示，收购该业务是为了在不断发展的物联网领域站稳脚跟。尽管物联网只是其业务版图上的一小部分，但当时却在科技领域拥有极高的热度和号召力。</p><p>&nbsp;</p><p>Arm 不仅被广泛应用于可穿戴设备和智能家电，同时也在将业务触角延伸至联网汽车等其他场景，尤其是在AI领域的影响力也越来越大。</p><p>&nbsp;</p><p>早在今年5月份，Arm 就秘密申请在美上市，Arm 首席执行官将 Arm IPO定位为人工智能领域，希望能在这次 AI 热潮中得到一个好估值。Arm 不仅是芯片行业的领头羊，同时也在 AI 领域发挥着重要作用，并开始更多标榜自己 AI 厂商的身份。</p><p>&nbsp;</p><p>此次IPO后，投资者也将继续密切关注该公司的 S-1 文件，了解 Arm 如何通过规划将 AI 技术的发展转化成业务收益。</p><p>&nbsp;</p><p>今年 5 月，Arm 推出了两款针对机器学习应用的新芯片组。据 Arm 介绍，其中一款为新型 Cortex-4&nbsp;CPU 芯片组，能够在改善机器学习性能的同时将功耗较前代芯片降低 40%。另一款则为 G720 GPU 芯片组，可在提供更好的性能同时将内存带宽占用量较前代减少 22%。</p><p>&nbsp;</p><p>该公司在 5 月 29 日发布的产品博文中指出，“Arm 仍在致力于针对机器学习（ML）新应用，开发并测试我们的 GPU。”</p><p>&nbsp;</p><p>英伟达和 AMD 等高性能芯片对于 AI 应用而言至关重要，这些应用需要借助大量算力才能顺利运行。上个月，英伟达发布了用于生成式 AI 应用的新型 Grace Hopper 芯片，设计采用的正是 Arm 架构。</p><p>&nbsp;</p><p>软银希望 AI 的增长能够支撑起愿景基金的发展路径，缓解该基金之前几年因押注 WeWork、中国网约车巨头滴滴出行和 Uber 等而造成的价值缩水。由于回报不佳，愿景基金已经将所持 Uber 股份抛售殆尽。</p><p>&nbsp;</p><p>软银公司 CFO 后藤芳光在 6 月的季度财报电话会议上表示，该公司一直在“谨慎而缓慢地恢复投资活动”，目前的重点关注方向为人工智能。</p><p>&nbsp;</p><p>在全球AI爆发之际，国内的AI市场也异常火爆。Arm也在招股书中透露中国（安谋科技）是 Arm 最大的客户。2023 财年，前五名客户合计占 Arm 总收入的 57%，其中安谋科技分别占其总收入 24%。</p><p>&nbsp;</p><p>Arm 在 IPO 文件中明确提及 Arm 与安谋科技的关系：安谋科技是 Arm 的重要收入来源及中国市场的重要渠道，是向中国客户转授 Arm IP 许可的独家分销商。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.cnbc.com/2023/09/13/arm-prices-ipo-at-51-per-share.html\">https://www.cnbc.com/2023/09/13/arm-prices-ipo-at-51-per-share.html</a>\"</p><p><a href=\"https://www.cnbc.com/2023/08/21/arm-ipo-what-it-means-for-ipo-market-softbank.html\">https://www.cnbc.com/2023/08/21/arm-ipo-what-it-means-for-ipo-market-softbank.html</a>\"</p><p><a href=\"https://www.ft.com/content/36bc706f-66a1-48e3-8c20-ab4966cb0fce\">https://www.ft.com/content/36bc706f-66a1-48e3-8c20-ab4966cb0fce</a>\"</p><p><a href=\"https://www.theregister.com/2023/09/14/arm_ipo/\">https://www.theregister.com/2023/09/14/arm_ipo/</a>\"</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-09-15 10:39:41",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "万字全面评测（下篇）：文心一言 vs ChatGPT",
    "url": "https://www.infoq.cn/article/2407ec2798197a61f53b4d6cf",
    "summary": "<p></p><blockquote>摘要：这是全面对标评测百度文心一言和 OpenAI 的 ChatGPT（包括 3.5 和 4）的下篇。豆茉君从P.性能表现和D.开发友好两大主题、11 个方面展开了评测。</blockquote><p></p><p></p><h2>前言</h2><p></p><p>接着<a href=\"https://mp.weixin.qq.com/s/3ajCfN54N8OzaqR6IpMjag\">全面评测（上篇）：文心一言 vs ChatGPT</a>\"，下篇将对文心一言和 ChatGPT 的性能表现和开发友好这两个主题进行对标评测。</p><p><img src=\"https://static001.geekbang.org/infoq/b3/b3326d0582fe92a2e7e2e0814e1b1605.png\" /></p><p>先说结论，一图胜千言：</p><p><img src=\"https://static001.geekbang.org/infoq/81/81a429ea51ee7a32e63b76530292e71a.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b0/b013f58b89f44de6402a91442a344712.png\" /></p><p>其中，对于如何有效地评测性能表现，豆茉君思索了很久。</p><p>首先，我想需要对人类智力活动和 AI 工具定位做一个设定。从人类个体角度出发，豆茉君认为，我们的智力活动有两个对象：一个是外在的世界，我们需要不断地增进对世界的了解；一个是内在的自我，我们需要不断地提高对自我的认知。</p><p>人类大脑智力活动的本质，是对数据、信息、知识和智慧进行处理、加工和产出的过程。而语言是人类思维的桥梁，是思考过程的载体，是智力产出的外化，对于人类智力的发展起到了至关重要的作用。</p><p>文心一言和 ChatGPT 作为大语言模型应用，它们在被训练的时候就被喂食了有关这个世界、有个人类本身的很大一部分的数据、信息、知识甚至智慧。所以，它们肚子里面的货比任何人类个体都多得多，但是它们还没有自我意识更没有主观能动，所以不会有目的地进行智力活动。（关于这部分内容，请移步豆茉君前面一篇文章：<a href=\"https://mp.weixin.qq.com/s/3yo9r7j-Y7VkiSgUg2g5Uw\">打工人要的安慰，GPT 给不了</a>\"）</p><p>如果说外化的文字，是给我们大脑外接了一台显示器，以达到反复加强从眼睛看到脑袋想再到眼睛看的这个循环过程，以达到刺激大脑思维产出的效果，即形成大脑和自我外化的一部分镜像快照形成沟通交流的回路。</p><p>那么大语言模型 AI 则更像是给大脑联通了一个外挂，它能让大脑快速触达人类巨量的智力成果，而不要求大脑预先进行学习、记忆，这极大的释放了人脑的学习压力（虽然人脑长期记忆容量是惊人的，但是学习效率太低），增加了人脑的工作容量（人脑的工作容量非常有限，一次激活加载的记忆区域不超过 7 个）。</p><p>与传统的搜索引擎不同，AI 能够跟大脑进行丝滑的对话沟通，会直接给出知识甚至智慧，而不要求大脑完成数据收集、信息组织再到提炼知识的工作步骤，让大脑能够更专注于最后一步即智慧的产出。</p><p>从这个角度理解，大语言模型 AI 是人类绝佳的智力活动副驾驶，这也是人们通常把它称之为 Copilot 、贾维斯的原因。</p><p></p><h2>智力活动的 16 象限分解</h2><p></p><p>为了确定性性能对标评测的测试内容，豆茉君结合上面前言的思考结果，把智力活动分成了 16 个象限。如图：</p><p><img src=\"https://static001.geekbang.org/infoq/60/606da506fd5dd1e025b5422009694be8.png\" /></p><p></p><h3>三个维度</h3><p></p><p>16 象限的划分依靠三个维度：</p><p></p><h4>1、DIKW 模型</h4><p></p><p>DIKW模型是一个用于描述数据、信息、知识和智慧之间关系的概念模型。这个模型通常以金字塔形式表示，从底层到顶层分别是：数据（Data）、信息（Information）、知识（Knowledge）和智慧（Wisdom）。每一层都是基于其下一层构建的。</p><p>数据（Data）</p><p>数据是未经处理的原始事实和统计数字。数据本身没有意义，需要进一步处理和分析。例如：温度读数、销售数字、人口统计数据。</p><p>信息（Information）</p><p>信息是经过组织、分类或解释的数据。信息提供了一种更高级别的组织和解释，通常用于描述某种情况或环境。 例如：天气预报、销售报告、人口普查结果。</p><p>知识（Knowledge）</p><p>知识是经过深入理解、分析和应用的信息。知识通常包括观点、技能、经验和教训，用于解决问题或进行决策。 例如：如何修复一个机器、如何进行有效的项目管理、医学或法律专业知识。</p><p>智慧（Wisdom）</p><p>智慧是一种更高级的认知形式，通常涉及到道德、伦理和长期目标的考虑。智慧不仅仅是知识的应用，还包括对何时、如何以及为什么应用这些知识的深入理解。 例如：如何公平地分配有限资源、如何做出道德和伦理上正确的决策、如何实现长期的可持续发展。</p><p>图中用同心圆表示，从外到内依次为数据、信息、知识和智慧。</p><p></p><h4>2、已知和未知</h4><p></p><p>图中的 X 轴，左边（已知）代表已经被确认或理解的内容，而右边（未知）代表尚未被发现或理解的内容。</p><p></p><h4>3、世界与自我</h4><p></p><p>图中的Y轴，上面（世界） 代表与外界、社会或环境有关的内容，而下面（自我） 代表与个人、内心或主观经验有关的内容。</p><p></p><h3>象限清单</h3><p></p><p></p><p>接下来的性能表现测试，将会用针对 16 个象限设计 16 个问题，然后分别发给文心一言、ChatGPT 3.5 和 GPT-4，看看它们的回答质量。需要注意的是：</p><p>1、进行零样本提示问答测试。</p><p>所谓零样本提示，就是直接一句话问出问题，而不采用优化设计后的复杂提示词。</p><p>2、不启用任何插件</p><p>3、测试语言：中文</p><p>4、对于有确切答案的，答对得1分，不全对得 0.5 分，全错得 0 分。</p><p>5、对于没有确切答案的，豆茉君自行打分，优、中、差三档得分1、0.5 和 0 分。</p><p></p><h2>P. 性能表现 Performance</h2><p></p><p></p><h3>P1 工作记忆</h3><p></p><p>我们先来对比一下工作记忆容量。这个指标非常关键，直接决定了对话篇幅。这里不纳入评分考核。</p><p>所谓工作记忆，是指在一次对话中，AI 能记住并处理的最大篇幅。用于衡量最大篇幅的单位叫 token 数。token 是令牌的意思，每一个 token 相当于大语言模型中的一个单元对象。</p><p>对于 ChatGPT，OpenAI 提供了一个 token 数计算小工具（https://platform.openai.com/tokenizer），可用来自动计算自然语言句子的 token 数量：</p><p><img src=\"https://static001.geekbang.org/infoq/4f/4fb85c4ab978d2a5f65868f6efb74521.png\" /></p><p>例如，在上面所示的句子 “ChatGPT is an AI model.”中，有8个token。实质上，tokens 是语言模型用于理解和生成文本的\"构建块\"，它们构成了输入和输出数据的基础，tokens的数量、种类和质量直接影响模型性能的有效性。</p><p>在自然语言处理（NLP）和语言模型的背景下，\"token\"代表模型设计用来处理的最基本数据单元。一个token可以是一个字符，也可以是一个单词，具体取决于语言和模型的设计。在类似于 GPT-4 这样的 AI 语言模型中，一个token通常对应一个单词，但它也可以表示单词的一部分、一个短语，甚至是标点符号或空白字符。</p><p>为什么会有这么个 token 最大数量限制呢？</p><p>这是由于多种因素，涉及效率、计算可行性以及模型性能等方面的考虑：</p><p>计算效率：处理大量的token需要大量的计算资源，包括内存和处理能力。设置token的最大数限制有助于管理计算成本，确保语言模型在合理的时间范围内运行，以便提供及时的回复。模型性能：token限制有助于维持输出的质量。由于模型架构限制，具有固定大小的注意力窗口，这决定了模型一次能够处理的 token 数量。资源分配：设置token的最大数限制有助于在多个同时使用模型的用户之间平衡资源的使用，确保多用户环境下对计算资源的公平访问。</p><p>那么，token 最大数量限制将如何影响用户的使用体验呢？</p><p>首先是对话长度限制</p><p>token 数量的限制会影响模型能够处理的对话长度。输入和输出都计入token限制，因此在一个对话中，token的数量可能会超过限制，导致需要削减或省略一些内容。这可能会使长对话无法在模型中完整地进行处理。</p><p>多轮对话</p><p>对于涉及多次来回对话或多个参与者的对话，token数量的限制可能会成为一个关键因素。对话需要适应模型的 token 限制，对于含有多个对话轮数的场景会产生较大影响。</p><p>实时交互</p><p>在需要快速回复的实时应用中，处理大量token所需的时间可能会显著影响用户体验。如果模型处理大量token的速度较慢，可能会导致用户等待时间过长，从而降低实时交互的效果。</p><p>根据官方的资料，ChatGPT 3.5 的最大 token 数量限制是 16384 个，上下文大约能记住 12000 个单词：</p><p><img src=\"https://static001.geekbang.org/infoq/29/29ca7a8273d76db2dd5bc352e6c38559.png\" /></p><p>而 GPT-4 的限制是 32768 个，上下文大约能记住 25000 个单词：</p><p><img src=\"https://static001.geekbang.org/infoq/c0/c05f255de52281ed96e76a65a6202e78.png\" /></p><p>再来看看文心一言。从百度千帆大模型平台的一处文档可以看出，其估算 token 公式：</p><p><img src=\"https://static001.geekbang.org/infoq/8e/8e6476ec925448fe2e47c03d9b7dc2a1.png\" /></p><p>对于文心一言应用来说，对话的 token 限制是多少，豆茉君没有找到官方有准确的介绍。不过在使用的时候，发现网页对话框内最大输入的限制是 2000，单位应该是 token：</p><p><img src=\"https://static001.geekbang.org/infoq/64/64426e391386f9c6698d92d5ab956f91.png\" /></p><p></p><h3>P2 语言理解</h3><p></p><p>语言理解性能，主要是测试 AI 对于已知世界的数据、信息、知识和智慧的筛选和归纳能力。对应的象限是 1、5、9、13。</p><p></p><h4>1 数据 + 已知 + 世界：中国 1990 年的 GDP 是多少？</h4><p></p><p>标准答案：3609 亿美元。</p><p>文心一言：答不出来 0</p><p><img src=\"https://static001.geekbang.org/infoq/39/39fdc46c068ee5eb894315b6396d7049.png\" /></p><p>GPT-3.5：大差不差 0.5</p><p><img src=\"https://static001.geekbang.org/infoq/df/dfb2ca666c944c0990dc7266257c1327.png\" /></p><p>GPT-4：完全正确 1</p><p><img src=\"https://static001.geekbang.org/infoq/9e/9ebad8391a3ac174f35ff59c55bac122.png\" /></p><p></p><h4>5 信息 + 已知 + 世界：最近一次奥运会的金牌榜前5名的国家和奖牌数是？</h4><p></p><p>标准答案：</p><p><img src=\"https://static001.geekbang.org/infoq/df/df6d835c2e71eb0710476302b085dbc2.png\" /></p><p>文心一言：第五名错了，奖牌数有错误 0.5</p><p><img src=\"https://static001.geekbang.org/infoq/f6/f612101c1fa6378709f2e66e13623f2f.png\" /></p><p>GPT-3.5：金牌数前两名错了。0.5</p><p><img src=\"https://static001.geekbang.org/infoq/cb/cbef07802297b121392783c4ec31bfcd.png\" /></p><p>GPT-4：俄罗斯的名称前面部分错了 0.5</p><p><img src=\"https://static001.geekbang.org/infoq/33/33bbb9fbd839145dfc6c823717207c30.png\" /></p><p></p><h4>9 知识 + 已知 + 世界：牛顿的三大定律是什么？</h4><p></p><p>都对了。</p><p>文心一言：1</p><p><img src=\"https://static001.geekbang.org/infoq/07/079c77be6987a8ba7ef0586678a63bb0.png\" /></p><p>GPT-3.5：1</p><p><img src=\"https://static001.geekbang.org/infoq/21/21a172858bb8f83b10c484ed725e1207.png\" /></p><p>GPT-4：1</p><p><img src=\"https://static001.geekbang.org/infoq/7d/7d1f52cbe59e16efe45d2f02d4d49267.png\" /></p><p></p><h4>13 智慧 + 已知 + 世界：如何解决贫富不均的问题？</h4><p></p><p>文心一言：0</p><p><img src=\"https://static001.geekbang.org/infoq/28/282e2eb32f32e1ad26dc5d31eda84e4f.png\" /></p><p>GPT-3.5：0.5</p><p><img src=\"https://static001.geekbang.org/infoq/b5/b59f9f3ebdb3bc65dfa16126bdcbd16f.png\" /></p><p>GPT-4：1</p><p><img src=\"https://static001.geekbang.org/infoq/00/0044c6281af391431de1da4c12d41fa4.png\" /></p><p></p><h3>P3 情感对话</h3><p></p><p>情感对话性能，主要是测试 AI 对于已知自我的数据、信息、知识和智慧的咨询和推理能力。对应的象限是 3、7、11、15。</p><p></p><h4>3 数据 + 已知 + 自我：作为输入</h4><p></p><p>我叫小明，来自江苏，是一个在上海工作 3 年的男程序员，我平时负责编写一些数据分析代码，目的是对公司平台用户的交易行为进行分析。我毕业于国内的一所 211 大学，专业是计算机科学与技术。</p><p></p><h4>7 信息 + 已知 + 自我：作为输入</h4><p></p><p>我还没有女朋友，平时喜欢玩电脑游戏，捣鼓数码产品，还喜欢吃火锅。节假日的时候，喜欢约朋友打打篮球，然后骑骑我的山地自行车。</p><p></p><h4>11 知识 + 已知 + 自我：如何提高我的沟通能力？</h4><p></p><p>文心一言：跟GPT 3.5 的答案好像，0.5</p><p><img src=\"https://static001.geekbang.org/infoq/26/2641dc719d71a807306a21015929f1bd.png\" /></p><p>GPT-3.5：跟文心一言的答案好像，0.5</p><p><img src=\"https://static001.geekbang.org/infoq/53/5330d91dbc3dc689b096596627052415.png\" /></p><p>GPT-4：1</p><p><img src=\"https://static001.geekbang.org/infoq/dd/dd01301f433b4690ba49486d7dfa8c7b.png\" /></p><p></p><h4>15 智慧 + 已知 + 自我：我该如何去找女朋友？</h4><p></p><p>文心一言：0.5</p><p><img src=\"https://static001.geekbang.org/infoq/d3/d3ae94fc229a5f94d022d99d335dc5dd.png\" /></p><p>GPT-3.5：1</p><p><img src=\"https://static001.geekbang.org/infoq/1f/1ffa9c09f316f51a30eff3e5dd9dee9d.png\" /></p><p>GPT-4：1</p><p><img src=\"https://static001.geekbang.org/infoq/29/295290ce3865ff2c8e6dd9225e335579.png\" /></p><p></p><h3>P4 逻辑推理</h3><p></p><p>逻辑推理性能，主要是测试 AI 对于未知世界和自我的数据、信息、知识和智慧的演绎和预测能力。对应的象限是 2、6、10、14、4、8、12、16。</p><p></p><h4>2 数据 + 未知 + 世界：火星上有生命吗？</h4><p></p><p>文心一言：0.5</p><p><img src=\"https://static001.geekbang.org/infoq/14/148d17c39fa99159c014456043a4a88e.png\" /></p><p>GPT-3.5：0.5</p><p><img src=\"https://static001.geekbang.org/infoq/a6/a623876466925e48f7d2968d53dcb4bd.png\" /></p><p>GPT-4：1</p><p><img src=\"https://static001.geekbang.org/infoq/ce/ce25ab531bc141c611e3fd082d019258.png\" /></p><p></p><h4>6 信息 + 未知 + 世界：疫情以后的世界经济会好转吗？</h4><p></p><p>文心一言：0.5</p><p><img src=\"https://static001.geekbang.org/infoq/5d/5dac66d09c286273fcf664c8c22ca0e8.png\" /></p><p>GPT-3.5：0.5</p><p><img src=\"https://static001.geekbang.org/infoq/d4/d4847f52828cc532365cf5a3bd2ef66b.png\" /></p><p>GPT-4：1</p><p><img src=\"https://static001.geekbang.org/infoq/ef/ef7ec666eea9ffc2d29fb7b51d67458d.png\" /></p><p></p><h4>10 知识 + 未知 + 世界：鸡兔同笼问题</h4><p></p><p>文心一言：0.5</p><p><img src=\"https://static001.geekbang.org/infoq/f9/f91c4a3a9b4a6d69321b85913c99c786.png\" /></p><p>GPT-3.5：1</p><p><img src=\"https://static001.geekbang.org/infoq/df/dfe3cf09cbfe88187606b6e398dd3c33.png\" /></p><p>GPT-4：1</p><p><img src=\"https://static001.geekbang.org/infoq/59/59735fd69b139658922142b5792caf3a.png\" /></p><p></p><h4>14 智慧 + 未知 + 世界：未来人类应该如何处理人工智能的道德和伦理界限？</h4><p></p><p>文心一言：0.5</p><p><img src=\"https://static001.geekbang.org/infoq/fb/fb0abd1e375fe9eb7c2a2fcb77d7ae3b.png\" /></p><p>GPT-3.5：0.5</p><p><img src=\"https://static001.geekbang.org/infoq/6b/6b362803550a517d041e363b1b2272f9.png\" /></p><p>GPT-4：1</p><p><img src=\"https://static001.geekbang.org/infoq/94/94daa53f1181bf7ed6a8b876979dd98b.png\" /></p><p></p><h4>4 数据 + 未知 + 自我：我有哪些未发掘的才能？</h4><p></p><p>文心一言：0.5</p><p><img src=\"https://static001.geekbang.org/infoq/7d/7d43414fe2948ff3b334e2acb2932421.png\" /></p><p>GPT-3.5：0.5</p><p><img src=\"https://static001.geekbang.org/infoq/f2/f2d37ea8a1104f9af35042fb31270023.png\" /></p><p>GPT-4：1</p><p><img src=\"https://static001.geekbang.org/infoq/29/29e52ea3030bacd015afea55e95da3be.png\" /></p><p></p><h4>8 信息 + 未知 + 自我：我在团队中应该擅长扮演什么角色？</h4><p></p><p>文心一言：0.5</p><p><img src=\"https://static001.geekbang.org/infoq/65/659b4c592ceb51dc7d24d1d9a1303365.png\" /></p><p>GPT-3.5：1</p><p><img src=\"https://static001.geekbang.org/infoq/c0/c09f9dc8549957d0a58842ffa87d16a8.png\" /></p><p>GPT-4：1</p><p><img src=\"https://static001.geekbang.org/infoq/dd/dddece4a4b5b2b2778b7208da4274af8.png\" /></p><p></p><h4>12 知识 + 未知 + 自我：我如何找到我的人生目标？</h4><p></p><p>文心一言：0.5</p><p><img src=\"https://static001.geekbang.org/infoq/df/df012325d2d30a58d442d13eb8c270e6.png\" /></p><p>GPT-3.5：1</p><p><img src=\"https://static001.geekbang.org/infoq/18/1885b027d7ce7516fb8b67b276563be2.png\" /></p><p>GPT-4：1</p><p><img src=\"https://static001.geekbang.org/infoq/3b/3b4bebc17a8197599da9dbb3bea67422.png\" /></p><p></p><h4>16 智慧 + 未知 + 自我：我的人生是否有更高的使命或目标？</h4><p></p><p>文心一言：0.5</p><p><img src=\"https://static001.geekbang.org/infoq/c9/c90ad5e3e455c9df36c59a514585f789.png\" /></p><p>GPT-3.5：1</p><p><img src=\"https://static001.geekbang.org/infoq/69/698b240db88fb2e55f4a3813c8692e82.png\" /></p><p>GPT-4：1</p><p><img src=\"https://static001.geekbang.org/infoq/c9/c9ee7706c37e99444a2ab5621f69dc57.png\" /></p><p></p><h3>P5 代码生成</h3><p></p><p>豆茉君要求 AI：1、生成一段Python代码，用于计算斐波那契数列前1000项的和；2、你能够进一步改进这段代码吗？并说明是如何改进的，改进的效果是什么？</p><p>评价标准包括：1、是否能生成代码2、是否能得到正确答案3、计算耗时</p><p>文心一言：</p><p><img src=\"https://static001.geekbang.org/infoq/ac/ac6d46238124e725794761aefede9999.png\" /></p><p></p><p><code lang=\"null\">def&nbsp;fibonacci_sum_improved_baidu(n):&nbsp;\n&nbsp;#&nbsp;创建一个数组来存储斐波那契数列&nbsp;\n&nbsp;fib&nbsp;=&nbsp;[0]&nbsp;*&nbsp;(n&nbsp;+&nbsp;1)&nbsp;\n&nbsp;#&nbsp;第一和第二项&nbsp;\n&nbsp;fib[0]&nbsp;=&nbsp;0&nbsp;fib[1]&nbsp;=&nbsp;1&nbsp;\n&nbsp;#&nbsp;通过动态规划计算斐波那契数列的前n项&nbsp;\n&nbsp;for&nbsp;i&nbsp;in&nbsp;range(2,&nbsp;n&nbsp;+&nbsp;1):&nbsp;\n&nbsp;fib[i]&nbsp;=&nbsp;fib[i&nbsp;-&nbsp;1]&nbsp;+&nbsp;fib[i&nbsp;-&nbsp;2]&nbsp;\n&nbsp;#&nbsp;使用反向迭代计算和&nbsp;\n&nbsp;sum&nbsp;=&nbsp;fib[n]&nbsp;\n&nbsp;for&nbsp;i&nbsp;in&nbsp;range(n&nbsp;-&nbsp;1,&nbsp;-1,&nbsp;-1):&nbsp;\n&nbsp;sum&nbsp;+=&nbsp;fib[i]&nbsp;\n&nbsp;return&nbsp;sum&nbsp;\n</code></p><p>GPT-3.5：</p><p><img src=\"https://static001.geekbang.org/infoq/92/9224e29375ebe5728d23b2f56205279d.png\" /></p><p></p><p><code lang=\"null\">def&nbsp;fibonacci_sum_GPT35(n):\n&nbsp;&nbsp;&nbsp;&nbsp;fib_sequence&nbsp;=&nbsp;[0,&nbsp;1]\n&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;i&nbsp;in&nbsp;range(2,&nbsp;n):\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;next_fib&nbsp;=&nbsp;fib_sequence[i-1]&nbsp;+&nbsp;fib_sequence[i-2]\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fib_sequence.append(next_fib)\n&nbsp;&nbsp;&nbsp;&nbsp;\n&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;sum(fib_sequence)\n</code></p><p>GPT-4：</p><p><img src=\"https://static001.geekbang.org/infoq/31/31e8de3dc991e25a102128d77824ab62.png\" /></p><p></p><p><code lang=\"null\">def&nbsp;generate_fibonacci(n):\n&nbsp;&nbsp;&nbsp;&nbsp;a,&nbsp;b&nbsp;=&nbsp;0,&nbsp;1\n&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;_&nbsp;in&nbsp;range(n):\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;yield&nbsp;a\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a,&nbsp;b&nbsp;=&nbsp;b,&nbsp;a&nbsp;+&nbsp;b\n\ndef&nbsp;fibonacci_sum_GPT4(n,&nbsp;max_value=None):\n&nbsp;&nbsp;&nbsp;&nbsp;total&nbsp;=&nbsp;0\n&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;val&nbsp;in&nbsp;generate_fibonacci(n):\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;max_value&nbsp;is&nbsp;not&nbsp;None&nbsp;and&nbsp;val&nbsp;&gt;&nbsp;max_value:\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(f\"Reached&nbsp;max_value&nbsp;at&nbsp;{val},&nbsp;stopping&nbsp;early.\")\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;break\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;total&nbsp;+=&nbsp;val\n&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;total\n</code></p><p>运行结果是：</p><p><img src=\"https://static001.geekbang.org/infoq/e6/e6b721a7ad9fc4d5a55d12ba4e07f7f0.png\" /></p><p>结论是：</p><p>1、它们都生成了代码；2、运行以后，文心一言代码运行的答案居然是错的，GPT3.5 和 GPT-4 是对的；3、运行的都是优化后的代码，计算耗时文心一言最长，GPT-3.5 其次，GPT-4 最短。</p><p></p><h3>P6 数据分析</h3><p></p><p>通过对数据的清洗、整理和可视化，发现数据中的信息，从而解读出知识。</p><p>文心一言：</p><p>打开文心一言的官方插件：E言易图。然后可以让它把对话中谈到的数据进行可视化。比如，豆茉君让文心一言查询了最新的人口数量前20名的国家，并让他作个图出来。可以看到，完成得不错。不过，文心一言暂时不支持上传本地的数据文件。</p><p><img src=\"https://static001.geekbang.org/infoq/5d/5dae298502a48bf730050ce2858f7e9b.png\" /></p><p>GPT-3.5</p><p>对于同样的要求，GPT-3.5 表示只能生成代码，不能直接给出可视化。</p><p><img src=\"https://static001.geekbang.org/infoq/5d/5d4e3e90be4e23295cca907bde89cd32.png\" /></p><p>GPT-4：</p><p>同理，GPT-4 不开插件是实现不了的。</p><p><img src=\"https://static001.geekbang.org/infoq/34/349650f8c8afbfc2319dc8534972dafb.png\" /></p><p>GPT-4 选择 Advanced Data Analysis ( ADA ) 模式：</p><p>我上传了一个几十户的用电功率，5分钟颗粒度，整整一个月的数据。让它帮我进行可视化处理，完成得很好，完全理解我用自然语言简单给到它的想法。我还让它按照《经济学人》杂志美化了一下图表。这个 ADA 确实非常强大。</p><p><img src=\"https://static001.geekbang.org/infoq/8e/8e74d73cf12ea6be60fcb12b1e5d48c0.png\" /></p><p>需要注意的是，在 ADA 模式下，有两套环境：一个是对话环境，一个是程序运行环境，两者是独立运行的，互不干扰。</p><p></p><h3>P7 多模支持</h3><p></p><p>所谓多模，意思就是可以文生图、图生文，其他模态还有声音、视频等。</p><p>文心一言：</p><p>目前，文心一言是可以实现文生图和图生文的。</p><p>我让文心一言画个小女孩等妈妈的图片。我也测试过改变图像尺寸和比例，暂时都不支持。从生成的图片看，基本满足我对小朋友的外貌描述。</p><p><img src=\"https://static001.geekbang.org/infoq/b3/b37900edcee44dbca36b55dd1bee73f9.png\" /></p><p>但是跟 midjourney 或者 stable diffusion 比，暂时还是差很多。比如豆茉君画的这张人像（Stable Diffusion 1.5, majicMIX realistic 模型）：</p><p><img src=\"https://static001.geekbang.org/infoq/6f/6f9c6286077399752fcb5b3f07ca501b.png\" /></p><p>另外，我还上传了一张他信回国在机场出来被警察带走的照片。文心一言识别出了政府官员、警察、泰国这些信息。可能是通过我的图片名称来解析的，我的图片名称是“他信被捕.jpg”。</p><p><img src=\"https://static001.geekbang.org/infoq/2d/2dc51c4c6bf41b5c39694e4eabe650aa.png\" /></p><p>GPT-3.5 和 GPT-4 暂时都不支持多模态。</p><p></p><h2>D. 开发友好 Development</h2><p></p><p>一个公司再强大，也不可能独立做好一个行业，服务数以千万计的用户。开发者作为信息时代的创作者，是非常关键的存在。在开源社区和开发工具的发展下，当代的开发者一个人就能做一个很细分的产品，这早已不是什么难事。更何况，进入到 AI 时代，出现了一种用自然语言编程的开发者（提示词工程师）。照这个趋势发展下去，以后只要你会说话写字，用人类自然语言编程的时代很快就会到来。</p><p>所以，如何创立和维护一个富有活力、公开、公平、共同致富的开发者生态，对于 任何 AI 时代创新领导者公司来说，都是必须的。</p><p></p><h3>D1 开放接口</h3><p></p><p>API 是信息时代高速公路的闸道，它用来把各式各样的软件应用连接起来。有了公开的 API 文档，开发者们可以把各种东西集成起来，创造性地弄出很多产品服务细分到毛细的需求。</p><p>百度智能云千帆大模型平台上有丰富的内容，这里不展开了。</p><p><img src=\"https://static001.geekbang.org/infoq/7d/7d281ac130d83656bb60e67e0f327342.png\" /></p><p>而 OpenAI 的 GPT 产品，除了依托微软 Azure 云提供各种 API 以外，官方也有 API 服务、定价和丰富的文档。这里也不展开了。</p><p><img src=\"https://static001.geekbang.org/infoq/1f/1f3f5d9cb8c54e127b902af261999e63.png\" /></p><p></p><h3>D2 插件生态</h3><p></p><p>使用 ChatGPT，GPT-4 的官方插件市场和基于浏览器的插件（Chrome、油猴）能够极大的拓展产品功能，这种提升有的时候是飞跃式的。因此，插件至关重要。</p><p><img src=\"https://static001.geekbang.org/infoq/01/0152f4bab4d44da3d3964e712bd04504.png\" /></p><p>可喜的是，百度文心一言已经开始了自己的插件市场和生态的搭建。只要填写一个材料，就可以申请参加插件开发。</p><p><img src=\"https://static001.geekbang.org/infoq/11/11a2ad10e762fd0d9ac6f78ab9544a76.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ce/cea8a9512fbfb88fa11f80b08bee367e.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/63/636972edeabccf414defd6dc44b279a7.png\" /></p><p></p><h3>D3 指令微调 Fine Tuning</h3><p></p><p>所谓指令微调，就是训练属于特定行业、特定群体、特定目的小模型，任务以大语言模型为基底，配上自己训练的小模型，可以根据细分场景针对性地提高产出效果。</p><p>用过 Stable Diffusion 画图的人都知道 LoRA，即基于某一个大模型，然后使用这些微调的 LoRA 来实现高针对性的特定效果。指令微调跟 LoRA 就是一样的。</p><p>百度的</p><p><img src=\"https://static001.geekbang.org/infoq/e3/e372a0e53b7634a388196af9b40221c8.png\" /></p><p>而 OpenAI 是在 2023年8月22日 开放 GPT-3.5 指令微调的，也预告说今年秋天会开发 GPT-4 的指令微调：</p><p><img src=\"https://static001.geekbang.org/infoq/d4/d4dcddbe523ef808aaef2e8108d4b4eb.png\" /></p><p>价格如下，比通用 API 服务价格要贵不少：</p><p><img src=\"https://static001.geekbang.org/infoq/47/477ae2916a4cef3cfab76fc712525ab5.png\" /></p><p></p><h3>D4 复杂提示词</h3><p></p><p>大家可能都听说过，出现了一种新职业叫“提示词工程师”，这个职业就是专注于如何用自然语言写出复杂的提示词（相对于一句话的问题来说），从而挖掘出大语言模型的潜力，同时测试和保证模型输出的正确性和鲁棒性。</p><p>当然，提示词工程师也可以写代码，不过对于普通人来说，使用自然语言编写复杂的提示词更容易上手，也更容易使用，因为只要在对话框中进行开发、测试和运行就行了，不用碰半点代码。</p><p>因此，对自然语言编码的支持，是非常重要的，这对于用自然语言进行编程的用户来说是非常友好的。</p><p>所以，豆茉君增加了一个部分，即对标比较复杂提示词的运行结果。豆茉君选择的一段提示词，是上个月参加 FlowGPT 游戏提示词大赛作品的中文版。</p><p><img src=\"https://static001.geekbang.org/infoq/a3/a3ca601e99691951d4a4af423b0e010c.png\" /></p><p>大家可以直接到 FlowGPT 上访问并运行：https://flowgpt.com/p/ow9PInkg5M2Pkw1wkvzuA</p><p>豆茉君也把提示词分享出来，获取地址：https://www.doumoman.site/blog/prompt_gamemaster</p><p>这个提示词实现了文字版的角色扮演游戏，妙处在于每次的对话和用户的行为选择共同决定了下面剧情的走向，而这一切完全是随机而且有逻辑的，像是实时创作一部冒险小说。</p><p><img src=\"https://static001.geekbang.org/infoq/80/80f88949c8fc6f94fa559ab56ff44fc4.png\" /></p><p>由于篇幅太长，这里就不截图了，直接说结论：</p><p>文心一言：无法持续按照要求输出对话内容，到了一半就忘了提示词的要求，导致游戏无法继续；</p><p>GPT-3.5：可以进行游戏，但是不是每次都能完全理解所有的要素要求，比如经常忘记给可能的行动计算影响值；</p><p>GPT-4：可以正常游戏，非常好。</p><p></p><h2>结语</h2><p></p><p>好了，终于，豆茉君完成了这篇评测。至此，文心一言对比 ChatGPT 的全面评测就结束了。让我们总结一下结论：</p><p><img src=\"https://static001.geekbang.org/infoq/02/02d57c8c545c89adeb06bf22323aa053.png\" /></p><p>结论1：在A.获取条件和F.功能体验两个方面，都完胜 ChatGPT，让豆茉君看到了百度作为国内大厂，在应用侧产品功能研发的投入，文心一言有着成为国内 AI 超级应用的潜质。</p><p>结论2：在D.开发友好方面，百度也正在打造一个开放的开发者生态社区，这是一个非常好的开始。苹果时代的 app store 教育大家，谁建立了应用平台，谁就能制定游戏规则，让广大的开发者在平台共生共赢共同富裕。</p><p>结论3：在P.性能表现方面，必须看到目前的文心一言和 ChatGPT 3.5 还有这一段差距，更不要提 GPT-4 了。但是，在豆茉君看来，如果百度包括国内大厂，能够奋起直追，保持今天的干劲，一步步拉小差距也只是时间问题。</p><p>结论4：在D4.复杂提示词方面，豆茉君确实没有想到文心一言有着比较大的差距，用自然语言编程写提示词与大语言模型应用交互，这极大地降低了深度使用模型的难度，这应该也是直接影响到深度爱好者体验的关键点。</p><p>如果觉得这篇评测对你有用，请给豆茉君点赞、关注和转发。</p><p>-（全文完）-</p>",
    "publish_time": "2023-09-15 09:53:38",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "最新估值达430亿美元！Databricks获得超 5 亿美元融资，英伟达参投",
    "url": "https://www.infoq.cn/article/F9Z5HldsTRNSLtTPeO8M",
    "summary": "<p>9 月 14 日，数据湖提供商 Databricks 宣布获得超 5 亿美元融资。目前，Databricks 估值达 430 亿美元。</p><p>&nbsp;</p><p>据悉，在此番最新融资轮中，Databricks 的股价为73.50美元，与2021年的价格大致相当。公司CEO Ali Ghodsi表示，&nbsp;Databricks这轮增加的50亿美元估值，主要来自过去两年间分配给3500名员工及投资者的股权。目前该公司员工数量约6000人。</p><p>&nbsp;</p><p>Databricks成立于2013年，总部位于旧金山，其最后一次宣布融资是在2021年的市场繁荣期，当时估值为380亿美元。此后，云软件股票暴跌，其竞争对手Snowflake的估值直接缩水了45%。但与Canva和Stripe等其他热门IPO选手不同，Databricks的表现一直相当稳健、估值并未出现大幅波动。</p><p>&nbsp;</p><p>今年7月，Databricks以13亿美元收购了初创公司MosaicML，后者的软件可高效运行大语言模型并输出自然顺畅的文本结果。</p><p>&nbsp;</p><p>值得注意的是，英伟达也参与了Databricks的本轮融资。这家芯片巨头最近一直在向各AI基础设施初创公司注入资金。Hugging Face、Cohere和CoreWeave等公司都从英伟达手中拿到了可观的资金支持。</p><p>&nbsp;</p><p>Ghodsi表示，他“不久前”开始与英伟达CEO黄仁勋接洽。而且随着两家公司对AI领域的深入，双方的战略合作也变得愈发重要。Databricks在英伟达的图形处理单元上花费了大量资金，主要是租借公有云平台上的资源；而如今在收购了Mosaic之后，这方面开销也变得更大。Ghodsi还补充道，在收购之前，Mosaic也曾经与英伟达就合作伙伴关系展开谈判。“我们有必要开展更为紧密的合作，毕竟从本质上讲，双方的市场定位属于互补关系。”</p><p>&nbsp;</p><p>此外，参与本轮融资的还有第一资本风险投资部门。第一资本是Databricks竞争对手Snowflake最大的客户。Snowflake财务主管Mike Scarpelli在2022年8月的一次投资者会议中表示，第一资本每年在Snowflake产品上花费近5000万美元。同年11月，他又强调第一资本是其最大客户，“双方经过5.3年的合作才走到今天。”</p><p>&nbsp;</p><p>而根据2021年的一篇博文，第一资本同时也使用Databricks家的产品，主要用于进行欺诈检测。</p><p>&nbsp;</p><p>原投资方T. Rowe Price继续领投Databricks的这一轮最新融资。Andreessen Horowitz、Baillie Gifford、Fidelity、摩根士丹利旗下 Counterpoint Global和Tiger Global等纷纷跟投。</p><p>Ghodsi表示，该公司从几个月前开始与投资方讨论新的融资轮，而且“最初的指导金额不超过1亿美元。”但由于更多投资方希望加入，这个数字最终扩大了5倍。</p><p>&nbsp;</p><p>至于未来会不会进行首轮公开募股（IPO），Ghodsi称准备工作仍在进行当中，且本轮融资不会改变既有计划。但他没有透露IPO的具体时间。</p><p>&nbsp;</p><p>未来几周之内，Databricks就会看到市场对于新兴技术的需求到底有多大。芯片设计厂商Arm在2016年转为私营之后，已经于本周四重新上市。日用百货配送公司Instacart和软件供应商Klaviyo也在上个月提交了招股说明书。自2021年底以来，美国已经近两年没有进行过规模可观的风投支持型科技企业IPO。</p><p>&nbsp;</p><p>近年来，不少企业软件开发商一直在努力削减开支，宏观经济背景的不确定性也导致大客户收紧采购配额、令其业务增长率放缓。但Databricks一直保持着稳定的增长速度，也未宣布任何裁员计划。</p><p>&nbsp;</p><p>Ghodsi表示，他一直努力在技术应用层面寻求成本削减空间，特别是转为软件订阅模式。</p><p>“我们之前曾花费3000万美元购买了300款SaaS软件。为了节约运营成本，我们决定将数字减半。”</p><p>&nbsp;</p><p>Databricks还发布消息，在截至今年7月的当季度内，其年化收入达到15亿美元，销售额同比增长50%。作为其长期竞争对手，Snowflake的股票于2020年在纽约证券交易所上市，且最近一个季度的报告收入也增长了36%，达到6.74亿美元。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.cnbc.com/2023/09/14/nvidia-and-capital-one-invest-in-databricks-at-43-billion-valuation.html\">https://www.cnbc.com/2023/09/14/nvidia-and-capital-one-invest-in-databricks-at-43-billion-valuation.html</a>\"</p>",
    "publish_time": "2023-09-15 14:37:17",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "JetBrains 推出独立 Rust IDE",
    "url": "https://www.infoq.cn/article/G4aQNXfcplOmXj9Pivse",
    "summary": "<p>9月14日，专业软件开发工具提供商 <a href=\"https://www.jetbrains.com/zh-cn/\">JetBrains</a>\"&nbsp;宣布推出一款专为Rust编程语言打造的集成开发环境（IDE) RustRover，旨在无缝集成高级编码支持与工具链，助力Rust开发者能够更高效地构建应用和服务。</p><p>&nbsp;</p><p>跟据介绍，RustRover 不仅能够为开发者提供实时反馈、智能代码建议，还带来了简化的工具链管理，并提供无缝式团队协作功能，使掌握任何熟练程度的开发者，均可享受到更强大的的Rust编程体验。RustRover的功能包括：</p><p>&nbsp;</p><p>实时分析：通过快速排查故障和实时反馈功能，助力开发者实现高效调试。开箱即用的体验：开发者可快速配置RustRover并立即开始编码，无需安装额外插件或从零开始配置 IDE。灵活的补全和解析代码：即使在非常规上下文中，程序员也可获得智能代码建议，从而提高工作效率。高级单元测试集成：开发者可轻松执行无缝测试以及重新运行失败测试，并从而快速排除故障。全面的代码洞察：帮助用户理解代码及其结构，并访问代码示例，从而提高开发能力。强大的Rust工具链支持：开发者可获得实现成功编码Rust所需的所有工具支持，包括Rust编译器等。完整的版本控制系统（VCS）集成：内置支持GitHub和 Git，帮助用户可以简化团队协作和版本控制流程。对前端技术和数据库提供支持：开发者无需大量其他工具，便可以轻松构建应用。</p><p>&nbsp;</p><p>RustRover技术布道师Vitaly Bragilevsky 表示，“借助 RustRover，我们将能够充分满足开发者不断变化的需求，并在快速发展的市场中见证Rust生态系统的茁壮发展。根据我们的调查显示，56% 的开发者在过去 6 个月内开始采用 Rust。通过集成先进的编码支持与工具链功能，我们的IDE将助力开发者更高效地构建应用和服务，并为不断壮大的Rust社区做出积极贡献。”</p><p>&nbsp;</p><p>此前，JetBrains已为Rust开发者提供了 <a href=\"https://www.jetbrains.com/rust/\">IntelliJ Rust</a>\"，这是一款面向IntelliJ IDE的开源Rust插件。而RustRover是一款面向初学者和进阶开发者的Rust产品，不仅为初学者提供了简便的Rust入门方式，还为经验丰富的开发者提供可靠支持。开发者在抢先体验计划（EAP）&nbsp;期间可以免费使用，JetBrains 表示也将确保其插件版本兼容IDEA Ultimate和CLion。</p><p>&nbsp;</p><p>更多信息可查看：</p><p><a href=\"https://www.jetbrains.com/rust/download\">https://www.jetbrains.com/rust/download</a>\"&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-09-15 15:00:20",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "汇丰科技证券服务技术部 DevSecOps 负责人周纪海博士确认出席 FCon ，分享大象起舞：国际大型银行数字化转型的挑战和实践",
    "url": "https://www.infoq.cn/article/PZmTlQRpdVimolCBzlNU",
    "summary": "<p><a href=\"https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle\">FCon 全球金融科技大会</a>\"，将于 11 月在上海召开。汇丰科技证券服务技术部 DevSecOps 负责人周纪海 博士将发表题为《<a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5529?utm_source=infoqweb&amp;utm_medium=article\">大象起舞：国际大型银行数字化转型的挑战和实践</a>\"》主题分享，介绍一些实际案例，分析传统银行如何通过工程赋能、业务创新提高业务竞争力。通过 BizDevOps 实践，实现业务和技术敏捷迭代与协作，提升业务体验。同时，升级为 DevSecOps，确保金融系统和产品安全。以及分析如何正确使用度量评估技术，为技术赋能业务提供指导。</p><p></p><p><a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5529?utm_source=infoqweb&amp;utm_medium=article\">周纪海博士</a>\"，英国伦敦帝国理工学院博士毕业，拥有 10 余年多家国际大型银行（巴克莱银行，汇丰银行等）和腾讯的 DevOps 和 DevSecOps 转型和落地的工作经验。2018 年从汇丰银行伦敦总部派到中国广州汇丰科技，负责投资银行技术部门千名开发人员规模的 DevOps 和 DevSecOps 转型。2021 年 12 月由机械工业出版社发行的国内首本 DevSecOps 书籍《DevSecOps 实战》的第一作者。2022 年 5 月由新加坡 World Scientific 出版社发行的金融科技书籍《The Future and Fintech, ABCDI and Beyond》的作者之一。2023 年 8 月由清华大学出版社发行的书籍《DevOps 持续万物》翻译小组组长和翻译作者之一。在 2018 到 2023 年期间，受邀作为演讲嘉宾出席国外 10 几场和国内 20 多场技术峰会分享 DevOps 和 DevSecOps 经验，并担任近 10 场技术峰会的专场出品人。南京大学软件学院工程卓越技术讲堂讲师和 DevOps+ 实验室企业导师。他在本次会议的演讲内容如下：</p><p></p><p>演讲：大象起舞：国际大型银行数字化转型的挑战和实践</p><p></p><p>传统金融机构，由于其历史悠久，强监管等特殊性，在其数字化转型的道路上往往困难重重。汇丰科技通过近 10 年的不断升级的数字化转型的过程中，在工程赋能，业务创新，业技融合，降本增效和风险管控等方面都取得了一定的成果。</p><p></p><p>本次分享通过结合实际案例分析传统银行，如何通过工程赋能和业务创新使得业务交付速度更快质量更好，从而降低技术投入成本并且提高了业务竞争力。以及通过 BizDevOps 实践，提高了业务和技术敏捷迭代和协作，最终实现了业技融合，从而提升业务体验。另外，为了进一步满足了监管和合规对于金融行业的要求，升级为 DevSecOps 并进行落地，从而通过安全左移使得金融系统和产品更安全。最后，总结和分析了如何正确使用度量评估技术创造的业务价值和实现数字驱动业务，从而为技术赋能业务指明正确方向。</p><p></p><p>演讲提纲：</p><p></p><p>金融行业数字化转型的特点和挑战工程效能和创新 - 赋能业务，降本增效业技敏捷和协作 – 实现业技融合，提高生产力安全和控制左移 – 进一步满足监管和合规要求度量和数字驱动 – 评估业务价值和指引战略方向</p><p></p><p>你将获得：</p><p></p><p>○ 了解金融行业数字化转型的面临的困难和挑战</p><p>○ 了解金融行业进行数字化转型的思路和重点方向</p><p>○ 通过案例了解金融行业数字化转型的实施方案和最佳实践</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle\">DevOps&nbsp;在金融企业落地实践</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle\">金融行业大模型应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle\">创新的金融科技应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle\">金融实时数据平台建设之路</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle\">金融安全风险管控</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle\">数据要素流通与数据合规</a>\"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，前 100 人可享 5 折特惠购票，咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png\" /></p><p></p>",
    "publish_time": "2023-09-15 15:10:28",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "为什么选择事件驱动的微服务架构？",
    "url": "https://www.infoq.cn/article/8b76ea4afb3d266f7faaab65a",
    "summary": "<p>在当今动态的业务环境中，开发人员面临越来越大的压力，需要提供快速、可靠、可扩展的解决方案，以满足不断变化的业务需求，而事实证明，传统应用程序是实现这些目标的障碍。微服务提供了一种易于理解且有前途的替代方案，但这种方法有一个强大的增强功能，可以为开发人员带来更大的敏捷性和实现价值的时间：更具体地说，我所说的事件驱动编程模型，利用事件驱动的微服务。</p><p></p><p>事件驱动的微服务是一种强大的架构模式，它将微服务的模块化和灵活性与事件驱动架构的实时响应能力和效率相结合。事件驱动的微服务的核心依赖于三个基本原则：松耦合、消息驱动的通信和异步处理。这些原则结合起来创建可扩展、有弹性和高性能的分布式系统：</p><p></p><p>松耦合：松散耦合是事件驱动的微服务的一个关键方面，因为它促进了模块化和关注点分离。松耦合允许每个微服务独立发展，最大限度地减少各个服务之间的依赖关系，而不影响整个系统。松散耦合可以加快开发和部署周期，并确保一项服务中的问题不会级联并影响系统的其他部分。</p><p></p><p>消息驱动的通信：在事件驱动的微服务架构中，服务通过消息进行通信，表示系统内发生的事件或数据更改。通过事件处理程序在服务之间传递的事件充当将事件生产者与事件消费者分离的中介。通过采用消息驱动的通信，事件驱动的微服务可以有效地处理变化的负载，确保系统即使在大流量或高峰使用期间也能保持响应能力和弹性。</p><p></p><p>异步处理：异步处理是事件驱动微服务的另一个基本原则。此架构中的服务可以在等待先前请求完成的同时继续处理其他任务，而不是等待立即响应或任务完成。这种方法显着减少了系统延迟并允许更大的并行性，因为多个服务可以同时处理事件而不会被同步调用阻塞。</p><p></p><p>这些基础知识为事件驱动的微服务以及事件驱动的编程奠定了基础，使开发人员能够创建高度可扩展、有弹性和响应迅速的分布式系统。通过采用松散耦合、消息驱动的通信和异步处理，事件驱动的微服务可以有效地处理复杂、动态的工作负载，并适应现代应用程序不断变化的需求。</p><p></p><h2>1、拥抱松耦合：可扩展且有弹性的事件驱动微服务的关键</h2><p></p><p></p><p>松耦合是事件驱动微服务的一个基本特征，它有助于分布式系统中关注点的分离和模块化。这种设计原则有助于最大限度地减少各个服务之间的依赖性，使它们能够独立发展和扩展，而不影响整个系统。</p><p>在松耦合的体系结构中，服务被设计为仅对传入命令做出反应、处理它们并发出事件。这种方法有几个好处：</p><p></p><p>（1）服务自治：通过限制服务处理命令和发出事件的责任，每个服务独立于其他服务运行。这种自主权允许开发的灵活性，因为团队可以修改或扩展单个服务而不影响系统中的其他组件。</p><p></p><p>（2）解耦通信：松耦合架构中的服务不是通过 API 直接调用其他服务或共享数据，而是通过事件进行通信。这种间接通信使服务彼此解耦，从而降低了创建脆弱依赖项或紧密耦合的风险，而这些依赖项或紧密耦合可能会阻碍可扩展性和可维护性。</p><p></p><p>（3）增强的可扩展性：每个服务负责处理其命令和发出事件，这些事件可以独立扩展以处理增加的需求或提高性能。此功能使系统能够适应不断变化的工作负载或用户流量的增长，而不会影响其他服务或整个系统。</p><p></p><p>（4）改进的容错能力：松散耦合有助于遏制单个服务内的故障。如果服务遇到问题，可以将其隔离并修复，而不会导致整个系统出现级联故障。这种遏制提高了整个系统的可靠性和弹性。</p><p></p><p>（5）更轻松的维护和更新：由于每个服务独立运行，开发人员可以部署更新、错误修复或向单个服务添加新功能，而不会影响其他服务。这种模块化简化了维护并实现更快的迭代周期。</p><p></p><p>开发人员可以通过采用松散耦合和设计仅对传入命令、进程和发出事件做出反应的服务来创建更健壮、可维护和可扩展的事件驱动微服务。这种隔离可以在不断变化的需求和不断增长的工作负载方面提供更大的灵活性和适应性，从而确保系统保持响应能力和弹性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ed/eda472101a2fa29ec602d4ce1f99ba24.jpeg\" /></p><p></p><h2>2、利用事件驱动系统中的消息驱动通信：事件、命令和下游服务</h2><p></p><p></p><p>消息驱动的通信是事件驱动系统的基础，它使服务能够异步通信并保持松散耦合。这个过程涉及上游服务、事件、命令和下游服务之间的协调交互。让我们分解一下这个沟通过程的每一步：</p><p></p><p>（1）发布事件：上游服务或事件生成器生成事件以响应系统内的特定操作或更改。这些事件代表必须传达给其他服务的状态更改或重要事件。事件制作者将这些事件发布到事件经纪人或日志，并将其传播给感兴趣的各方。</p><p></p><p>（2）将事件转换为命令：消息处理程序或中间服务接收到事件后，它们通常会转换为命令。命令代表需要由下游服务执行的操作。此转换过程通常涉及从事件有效负载中提取相关数据、验证数据并将其映射到适当的命令结构。</p><p></p><p>（3）向下游服务发布命令：消息处理程序或中间服务将事件转换为命令后，将命令发布到下游服务或命令使用者。这些服务负责执行命令中指定的操作、处理数据，并在必要时生成新事件以通知其他服务结果。</p><p></p><p>事件驱动系统中的消息驱动通信具有以下几个优点：</p><p></p><p>（1）异步交互：通过事件和命令进行通信，服务可以异步交互，而无需等待立即响应。这种方法可以减少系统延迟，实现更好的并行性并增强响应能力。</p><p></p><p>（2）解耦服务：使用事件和命令作为服务之间通信的主要方式可以促进松散耦合，因为服务不需要了解彼此的内部实现或 API。这种解耦简化了开发并允许服务独立发展。</p><p></p><p>（3）可扩展性和弹性：消息驱动的通信可以实现更好的负载平衡和资源利用率，因为服务可以独立扩展并适应不断变化的工作负载。此外，这种通信模式还提高了容错能力，因为一项服务的故障不会立即影响整个系统。</p><p></p><p>总之，事件驱动系统中的消息驱动通信对于促进松散耦合、异步处理和可扩展性至关重要。通过从上游服务发布事件，将其转换为命令，并将这些命令发布到下游服务，事件驱动系统可以有效地处理复杂的工作负载并适应现代应用程序不断变化的需求。</p><p></p><h2>3、过渡到异步事件驱动架构：从经验中学习</h2><p></p><p></p><p>开发人员和团队通常习惯于同步通信模式，因为他们从面向对象或函数式编程的经验中熟悉且直观。在这些范例中，对象调用其他对象或同步调用其他函数的函数上的方法。这种熟悉通常导致在分布式系统中的微服务之间采用同步通信模式。</p><p></p><p>然而，由于以下几个原因，同步处理流程可能不太适合分布式处理环境：</p><p></p><p>（1）耦合：同步通信导致服务之间的紧密耦合，因为它们需要了解彼此的 API 和实现细节。这种耦合使得独立发展、扩展或维护服务变得困难。</p><p></p><p>（2）延迟：当服务同步通信时，它们必须等待响应才能继续，这会增加系统延迟并降低响应能力，特别是在处理复杂的工作流程或高工作负载时。</p><p></p><p>（3）容错能力降低：同步通信可能导致级联故障，其中一项服务中的问题可以快速传播到其他服务，从而导致系统范围内的不稳定。</p><p></p><p>（4）可扩展性有限：同步通信模式限制了系统水平扩展的能力。服务必须始终可用且能够响应来处理传入请求，这在高流量场景或繁重工作负载下可能具有挑战性。</p><p></p><p>当开发人员遇到生产稳定性问题并认识到脆弱的同步处理模式的局限性时，他们开始认识到异步事件驱动架构的优点。这些架构具有以下几个优点：</p><p></p><p>（1）松散耦合：异步事件驱动架构使用消息驱动通信，这可以解耦服务并允许它们独立发展，从而促进更高的模块化和可维护性。</p><p></p><p>（2）提高响应能力：异步处理使服务能够继续处理其他任务，而无需等待响应，从而减少系统延迟并增强响应能力。</p><p></p><p>（3）增强的容错能力：异步通信有助于遏制单个服务内的故障，防止级联故障并提高整体系统的弹性。</p><p></p><p>（4）可扩展性：异步事件驱动的系统可以更有效地水平扩展，因为服务可以并发且独立地处理事件，而不会被同步调用阻塞。</p><p></p><p>通过采用异步事件驱动架构，开发人员可以解决同步通信模式的局限性，并构建更具可扩展性、弹性和高效的分布式系统。从经验中学习，他们可以创建更强大、更可维护的微服务应用程序，更好地适应现代软件开发不断变化的需求。</p><p></p><h2>4、总结</h2><p></p><p></p><p>采用事件驱动的微服务是一项战略举措，它改变了企业和开发人员进行软件设计和管理的方式。正如这里所指出的，开发人员在时间、资源和高质量代码方面的好处是巨大的。除了简单的商业利益之外，还可以为各个行业带来显着的好处。考虑在医疗保健领域，事件驱动的架构如何使医院网络能够实时监控患者的健康数据，并在检测到异常情况时向医疗保健专业人员发出警报。这可以通过确保在危急情况下立即采取行动来拯救生命。</p><p></p><p>这些示例展示了事件驱动的微服务的原理如何通过提供强大、适应性强且响应迅速的应用程序来彻底改变各个行业。</p><p></p><h2>5、推荐一款开发工具</h2><p></p><p></p><p>JNPF快速开发平台，很多人都用过它，它是功能的集大成者，任何信息化系统都可以基于它开发出来。</p><p>原理是将开发过程中某些重复出现的场景、流程，具象化成一个个组件、api、数据库接口，避免了重复造轮子。因而极大的提高了程序员的生产效率。</p><p></p><p>官网：<a href=\"https://www.jnpfsoft.com/?infoq\">https://www.jnpfsoft.com?infoq</a>\" ，如果你有闲暇时间，可以做个知识拓展。</p><p></p><p>这是一个基于Java Boot/.Net Core构建的简单、跨平台快速开发框架。前后端封装了上千个常用类，方便扩展；集成了代码生成器，支持前后端业务代码生成，满足快速开发，提升工作效率；框架集成了表单、报表、图表、大屏等各种常用的Demo方便直接使用；后端框架支持Vue2、Vue3。</p><p></p><p>为了支撑更高技术要求的应用开发，从数据库建模、Web API构建到页面设计，与传统软件开发几乎没有差异，只是通过低代码可视化模式，减少了构建“增删改查”功能的重复劳动。</p>",
    "publish_time": "2023-09-15 14:50:38",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "基于YOLOv2和传感器的多功能门禁系统",
    "url": "https://www.infoq.cn/article/5fb843c637443ad56972a6241",
    "summary": "<p></p><blockquote>文章和项目源码已经归档至【Github仓库：<a href=\"https://github.com/timerring/face-recognition-door\">https://github.com/timerring/face-recognition-door</a>\" 】或者公众号【AIShareLab】回复 人脸识别门禁 也可获取。</blockquote><p></p><p></p><h1>1.通信系统制作方案概述</h1><p></p><p>项目演示视频: <a href=\"https://www.bilibili.com/video/BV1jh4y1N7q2\">基于YOLOv2和传感器的多功能门禁系统</a>\"</p><p></p><h2>1.1系统设计的立意</h2><p></p><p>此处略。</p><p></p><h2>1.2系统的主要组成</h2><p></p><p>设计基于 YOLOv 2 的人脸识别门禁系统，主要由成品模块组成。具体包含：K210 Maix Bit、配套24PIN DVP 摄像头及 LCD 屏、SG90舵机、HC-SR501人体红外感应模块、MFRC-522射频模块、HC-05蓝牙模块、有源蜂鸣器、32G SD 内存卡及读卡器、4位独立按键。</p><p></p><h2>1.3系统的制作方案</h2><p></p><p></p><h3>1.3.1制作方案框图</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/c5/c5b5116741a72e5ef02f7db3d14be7c5.png\" /></p><p></p><h3>1.3.2制作方案原理描述</h3><p></p><p>初步设立门禁系统三大模式，等待、门禁及录入模式。</p><p></p><p>等待模式无人时显示屏全黑只显示 waiting......；门禁模式打开摄像头锁定人脸显示比对精度（百分制）与识别框，此时 RFID 数据通道打开，并在左上角标注所处模式；</p><p></p><p>录入模式打开摄像头锁定人脸显示采样进度与识别框，此时蓝牙通道打开，并在左上角标注所处模式，默认等待模式。使用 K210 MAIXBIT 做主控，当红外感知模块检测到人时，屏幕亮起，可识别人脸但无反应（红外感知模块可调节灵敏度与延时，但过于灵敏会导致画面卡顿，反之则检测效果不理想）。使用独立按键切换到录入或门禁模式，30s 未检测到人脸自动进入等待黑屏模式。</p><p></p><p>录入模式时，使用移动端 app 调试全能王连接蓝牙模块并发送指令：</p><p></p><p>输入“register****”（**** 代表录入人脸编号）后按照 yolo v 2 算法采集 196 维人脸数据（3 轮 18 次采样），并储存在 SD 卡文件中，且屏幕显示采样进度，录入完成屏幕显示“successful”，蜂鸣器发低声。输入“delete****”则删除对应用户储存在 SD 卡的特征值，蜂鸣器发高声。输入“erase”则删除 SD 卡内所有用户人脸特征值，蜂鸣器发高声。输入“open”则无条件控制舵机旋转。</p><p></p><p>门禁模式时，设定比对阈值，高于则蜂鸣器发低声且舵机旋转，低于则蜂鸣器发高声舵机无反应。此外 RFID 数据通道开通，我们已给两张 S50标准卡与异形卡相同扇区注入不同信息，分别会有舵机与蜂鸣器的不同响应情形，当其他 RFID 卡靠近则默认发生系统错误并发出独有蜂鸣器声音（可以修改）。</p><p></p><h2>1.4系统方案的可行性论证</h2><p></p><p>技术可行性分析:深度学习算法和神经网络理论已有较成熟应用,图像识别、人脸识别等领域有较多成功案例,技术上实现人脸识别门禁系统是可行的。传感器技术也比较成熟,可以采集人脸图像和相关生物特征,作为识别的输入。系统集成方面,人脸识别算法、传感器技术和门禁系统的结合也是现有技术可以实现的。经济可行性分析:相关硬件成本在可接受范围内,如高清摄像头等。软件实现可以采用开源算法和框架,开发成本不高。人脸识别门禁系统可以降低人工成本,尤其适用于人流较大场景,具有较好的经济效益。操作可行性分析:人脸识别门禁系统操作简单,易于推广使用,无需复杂训练,符合大多数人的接受习惯。该系统也便于维护和管理,可靠性较高。</p><p></p><p>综上,从技术、经济和操作等多方面考虑,基于深度学习的人脸识别门禁系统是一种可行的智能门禁方案。但是,数据安全和隐私保护也需要重点考虑,总体而言该方案是值得研究和探索的。</p><p></p><h1>2.具体模块分布图及集成原理图</h1><p></p><p><img src=\"https://static001.geekbang.org/infoq/20/20809fc4a191f8e5730fee83da5bf01a.png\" /></p><p></p><p>图2-1 人脸识别系统实操图</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ba/ba47c6d8f76c596523dd59a1eb500e7c.png\" /></p><p></p><p>图2-2 通信系统原理图</p><p></p><h1>3.各个模块硬件调试中遇见难题及解决方案</h1><p></p><p></p><h2>3.1蓝牙</h2><p></p><p>HC-05蓝牙模块是一种基于蓝牙协议的简单无线通信设备。该模块基于 BC417单芯片蓝牙 IC，符合蓝牙 v2.0标准，支持 UART 和 USB 接口。</p><p></p><p>具有两种工作模式：命令响应工作模式和自动连接工作模式。</p><p></p><p>当模块处于命令响应工作模式（或者AT模式）时能才能执行 AT 命令，用户可向模块发送各种 AT指令，为模块设定控制参数或发布控制命令。（AT指令就是我们PC与一些终端设备（例如蓝牙，WiFi模块）之间进行通信的，配置这些终端设备参数的一套指令。）在自动连接工作模式下模块又可分为主（Master）、从（Slave）和回环（Loopback）三种工作角色。当模块处于自动连接工作模式时，将自动根据事先设定的方式连接的数据传输。主模式：该模块可以主动搜索并连接其它蓝牙模块并接收发送数据。从模式：只能被搜索被其它蓝牙模块连接进行接收发送数据。回环：蓝牙模块就是将接收的数据原样返回给远程的主设备。</p><p></p><p>初次使用模块由于不知道蓝牙模块密码，故需要再使用 TTL 转串口模块，使用 AT 指令查询和修改蓝牙名称与密码。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/73/73a2c17249cd7e3fd2609e76411b5c33.png\" /></p><p></p><p>图3-1正点原子XCOM串口调试助手图</p><p></p><h2>3.2蜂鸣器</h2><p></p><p>蜂鸣器主要用于功能实现的提示音，一开始使用了低电平的蜂鸣器，导致一直响以为是代码不当导致的功能卡顿，多次检查后发现和代码无关，后来选取了高电平触发的蜂鸣器得以成功得到提示音。</p><p></p><h2>3.3红外感知模块</h2><p></p><p>红外模块用来感知是否有人在使用，从而开启或者关闭识别元件，红外检测器件的使用难点在于灵敏性调整，需要仔细修改，否则就会导致过快或者不进入休眠模式，从而影响使用。除此之外，不准确的红外检测还会导致器件反应过慢等等的问题，所以在红外器件的修改上下了很多时间才得到比较准确的识别数据。</p><p></p><h2>3.4矩阵键盘</h2><p></p><p>用于模式转换，录入人脸模式和正常使用模式，安装需要注意连接线。</p><p></p><h2>3.5 RFID</h2><p></p><p>RFID模块：标签进入磁场后，接收解读器发出的射频信号，凭借感应电流所获得的能量发送出存储在芯片中的产品信息（Passive Tag，无源标签或被动标签），或者由标签主动发送某一频率的信号（Active Tag，有源标签或主动标签），解读器读取信息并解码后，再进行有关数据处理。在RFID模块的设计中，为了方便地将标签的信息进行区分，首先设计了不同权限卡之间的对应规则，分别设计了存储信息中Y开头的万能通用卡，N开头的带有序号的普通用户权限卡，以及未规定的其他RFID卡，然后按照设定写了读卡器的写入程序，将对应的规则写入测试卡片，并且对卡片进行了测试。具体要将RFID验证模块加入到哪个环节之中，我们也对应地做了测试，所有流程都会回到普通模式，因此最开始是将RFID是加入在普通模式下，但是经过实际地测试与检验后，发现普通模式并不适合加入RFID模块，应该在检测到有人存在时再启动RFID。 其一，当门禁系统不被使用时，启动RFID模块会浪费大量的能源。通过检测到有人存在再启动RFID模块，可以最大程度地节省能源，降低系统的运行成本。其二，在门禁系统中，启动RFID模块是为了实现对进出人员的身份识别和控制。通过检测到有人存在后再启动RFID模块，可以确保门禁系统只对授权人员开放，提高门禁系统的安全性。最后综合考虑，将RFID模块放置在门禁模式之下。</p><p></p><h2>3.6人脸识别模块</h2><p></p><p>由k210芯片，摄像头和LED显示屏组成，用于识别用户脸部数据决定是否开启舵机。原理是YOLO 人脸识别，是一种基于深度学习的目标检测算法，它可以在一张图像中同时检测出多个目标，并且实时性能非常好。YOLO 模型的识别原理是通过将图像分成名个网格，然后对每个网格进行预测，最终将所有网格的预测结果合并起来得到最终的检迎结果。YOLO 模型的输入是一张图像，输出是每个目标的类别、位置和置信度。在训练阶段，YOLO 模型会学习如何将图像分成多个网格，并且对每个网格进行预测。每个网格的大小可以根据图像的大小 或者目标的大小进行调整。对于每个网格，YOLO 模型会预测出多个边界框，每个边界框包含了一个日标的位置和大小信息。同时，YOLO模型还会预测出每个边界框对应的目标的类别和置信度。除了写入训练的数学模型外，还需要设置识别的准确数据分数，超过标准才可以运行下一步功能。还需协调模型的数据存储和循环量，以免占用过多的数据空间，造成大量数据冗余，导致死机。</p><p></p><h2>3.7舵机</h2><p></p><p>SG 90舵机需要使用正确的通信协议与门禁系统的其他部件进行通信。在门禁系统中使用SG 90舵机时，应该选择适当的通信协议，例如PWM或者串口通信，并确保通信协议的准确性和稳定性。</p><p></p><h1>4.开发平台介绍及代码思路简介</h1><p></p><p></p><h2>4.1 yolo v2算法介绍</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/73/73c8b5bfdf6321f43c47a620929382c9.png\" /></p><p></p><p>图4-1 YOLOv2原理图</p><p></p><p>输入图片被分成 S x S 个网格(cell)，每个网格负责检测该网格内是否存在目标物体。对于每个网格，预测出 B 个边界框（bounding box），每个边界框包括(x, y, w, h, confidence)五个元素，其中(x, y)是边界框中心的坐标，w 和 h 是边界框的宽和高，confidence 表示该边界框中包含目标物体的置信度。对于每个边界框，计算它与 ground truth（真实标注的物体位置）的 IoU（交并比），并选取 IoU 最大的边界框作为该物体的预测框。使用非极大值抑制（NMS）方法来剔除重叠的预测框，最终输出预测结果。</p><p></p><p>关于IoU：</p><p></p><p>IoU 是交并比（Intersection over Union）的缩写，是一种用于衡量目标检测算法检测准确性的指标。它是通过计算预测框和 ground truth（真实标注的物体位置）之间的重叠程度来得出的。具体来说，IoU 是预测框和 ground truth 的交集面积除以它们的并集面积，即：</p><p></p><p>IoU = Intersection over Union = Intersection / Union</p><p></p><p>其中，Intersection表示预测框和ground truth的交集面积，Union表示它们的并集面积。IoU的取值范围在0到1之间，取值越大表示检测准确性越高。一般来说，当IoU大于某个阈值时，我们就认为预测框和ground truth匹配成功，可以将其作为检测结果；反之则认为匹配失败。</p><p></p><p>在目标检测算法中，通常会使用IoU作为评价指标来衡量算法的准确性。比如，在YOLOv2算法中，会使用IoU来选取每个边界框中与ground truth匹配的框。在训练过程中，如果预测框与ground truth之间的IoU大于某个阈值，我们就认为这个预测框是正确的，并计算它的损失函数；反之则认为它是错误的，不参与损失函数的计算。通过不断地调整模型参数，最终可以得到一个准确性较高的目标检测算法。</p><p></p><p>关于NMS：</p><p></p><p>非极大值抑制（Non-Maximum Suppression，NMS）是一种用于目标检测算法中的后处理方法，主要用于剔除重叠的预测框，保留最准确的预测结果。在目标检测算法中，一些目标可能会被多个预测框所检测到，这些预测框之间可能存在重叠。在这种情况下，我们需要对这些预测框进行筛选，保留最准确的预测结果。NMS方法就是用来完成这个任务的。NMS的基本原理如下：</p><p></p><p>对所有预测框按照其置信度（confidence）进行排序，从置信度最高的预测框开始遍历。对于当前遍历到的预测框，计算它与之前已经选中的预测框的 IoU（交并比），如果 IoU 大于某个阈值（如0.5），则将该预测框剔除，否则保留该预测框。重复步骤2和3，直到遍历完所有的预测框。</p><p></p><p>通过这个过程，NMS方法可以将多个重叠的预测框剔除，保留最准确的预测结果。NMS方法可以有效地解决目标检测算法中的多框问题，提高检测准确性。需要注意的是，NMS方法的效果受到阈值的影响。如果阈值较高，那么将会保留更少的预测框，可能会漏检一些目标；如果阈值较低，那么将会保留更多的预测框，可能会增加误检的概率。</p><p></p><p>同时，为了提高准确性和速度，YOLOv2采用了一些技巧：</p><p></p><p>Darknet-19网络：YOLOv2使用了一个19层的卷积神经网络 Darknet-19来提取特征。该网络比 VGG16等经典网络更轻量，同时具有更好的准确性。Anchor Boxes：YOLOv2在每个网格上预测 B 个边界框，而不是像 YOLOv1一样只预测一个。此外，YOLOv2使用了 Anchor Boxes，即预定义的边界框，来提高检测准确性。在训练过程中，YOLOv2通过调整 Anchor Boxes 和预测框的位置和大小来进行目标检测。Batch Normalization：在 Darknet-19网络中使用 Batch Normalization 来加速收敛和提高准确性。High Resolution Classifier：YOLOv2使用了一个高分辨率的分类器来提高检测准确性。具体来说，在训练时，YOLOv2将输入图片的分辨率提高到608x608，而在测试时，将其缩小到416x416，以加快处理速度。Convolutional With Anchor Boxes (CWA)：YOLOv2引入了一种新的卷积层，称为 Convolutional With Anchor Boxes (CWA)。该层同时计算多个 Anchor Boxes 的位置和置信度，以提高检测准确性和速度。</p><p></p><p>总的来说，YOLOv2是一个快速且准确的目标检测算法，它的核心思想是将目标检测问题转化为一个回归问题，并使用神经网络来解决。通过使用Anchor Boxes、Batch Normalization、High Resolution Classifier和Convolutional With Anchor Boxes等技巧，YOLOv2在准确性和速度方面都有所提高。</p><p></p><h2>4.2 开发平台</h2><p></p><p>开发环境：MaixPy IDE</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ec/ec38b0ce0623b8bf22722dfa8ea05b45.png\" /></p><p></p><p>MaixPy IDE 是一款基于 Python 语言的集成开发环境（IDE），主要用于开发和调试 MaixPy（开源的嵌入式人工智能框架）项目。MaixPy IDE 提供了一系列功能，包括代码编辑、调试、编译、下载、串口调试、固件升级等，方便用户对 MaixPy 进行开发和调试。</p><p></p><p>烧录环境：kflash_gui</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/08/08c9ab4562d5abb110df6970e732b00a.png\" /></p><p></p><p>kflash_gui是一款开源的图形化固件烧录工具，用于将固件烧录到Kendryte K210芯片上。K210是一款基于RISC-V架构的高性能、低功耗的嵌入式处理器，广泛应用于物联网、人工智能等领域。kflash_gui是Kendryte K210的官方固件烧录工具，提供了一系列功能，包括固件下载、擦除、烧录、调试等。kflash_gui基于Python语言和PyQt库开发，支持命令行和GUI两种模式。用户可以通过命令行模式进行批量烧录等高级操作，也可以通过GUI模式进行简单易用的固件烧录。kflash_gui还提供了一些高级功能，如自动检测串口、自动切换烧录模式、支持多种烧录设备等，方便用户进行高效的固件烧录。</p><p></p><p>串口调试环境：XCOM</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c9/c90f3c3de762e761901fd132fed9b226.png\" /></p><p></p><p>支持多个常用波特率，支持自定义波特率支持5/6/7/8位数据，支持1/1.5/2个停止位支持奇/偶/无校验支持16禁止发送/接收显示，支持DTR/RTS控制支持窗口保存，并可以设置编码格式支持延时设置，支持时间戳功能支持定时发送，支持文件发送，支持发送新行支持多条发送，并关联数字键盘，支持循环发送支持无限制扩展条数，可自行增删支持发送条目导出/导入（excel格式）支持协议传输（类modbus）支持发送/接收区字体大小、颜色和背景色设置支持简体中文、繁体中文、英文三种语言支持原子软件仓库</p><p></p><h2>4.3代码解析</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/cb/cb3b6d4d57ab892957d5e5282a7bd563.png\" /></p><p></p><p>图4-3 代码流程图</p><p></p><p>从左到右依次将代码模块化为三个模块，分别是人脸数据采集模块，人脸信息录入模块，人脸蓝牙RFID综合验证模块。下面依次对三个模块的思路进行解析：</p><p></p><p>首先是人脸数据采集模块，这段代码是一个人脸识别的应用程序，主要分为以下几个步骤：首先设置各种标志位和参数，包括是否检测到人、是否录入、查找模式、人脸对比置信度等。</p><p></p><p>然后执行以下操作：a. 调用 check_key()函数，可能用于检测设备是否已经授权使用相关的模型。b. 调用sensor.snapshot()函数获取一张图像。c. 使用kpu.run_yolo2()函数对输入的图像进行人脸检测，返回一个包含检测结果的列表code。d. 如果检测到人脸，程序会遍历code中的每个检测结果，计算人脸框的面积，并选择面积最大的人脸进行处理。e. 使用 img.draw_rectangle()函数在原图像上绘制人脸框，然后使用 img.cut()函数对原图像进行裁剪，得到人脸图像。f. 对人脸图像进行特征点检测，得到人脸的五个关键点坐标，使用img.draw_circle()函数在原图像上绘制出这些关键点的位置。g. 使用这些关键点的坐标计算人脸的仿射变换矩阵，并使用image.get_affine_transform()函数计算变换矩阵，将人脸图像进行对齐，得到标准的人脸图像。h. 使用kpu.forward()函数对对齐后的人脸图像进行特征提取，再使用kpu.face_encode()函数将特征向量进行编码。i. 遍历预先录入的人脸特征列表，使用kpu.face_compare()函数计算当前人脸特征向量与列表中每个特征向量的相似度得分，并选择得分最高的特征向量，返回其在列表中的索引，用于识别当前人脸是否为已知人脸。j. 根据人脸识别结果，可以执行不同的操作，如录入新人脸特征、查找已知人脸特征，或者进行相应的提示和处理。</p><p></p><p>代码详细注释如下：</p><p></p><p><code lang=\"python\"># 设置各种flag\nno_people = 0 # 是否无人\nno_flag = 0\ndelline = []\ncheck_num = 0\nshibie_num = 0\nuart.read()\n\n# 设置人脸对比置信度\nACCURACY = 75\n# 录入模式flag\nluru_flag = 0\n# 查找模式flag\nfind_flag = 0\n\nfeature = ''\nmax_score = 0\nindex = 0\nwhile (1):\n    # 程序首先调用了check_key()函数，该函数可能用于检测设备是否已经授权使用相关的模型。\n    check_key()\n    # 调用了sensor.snapshot()函数获取一张图像。\n    img = sensor.snapshot()\n    # 使用kpu.run_yolo2()函数对输入的图像进行人脸检测，返回一个包含检测结果的列表code。\n    code = kpu.run_yolo2(task_fd, img)\n    max_score = 0\n    # 如果code不为空，即检测到人脸，程序会遍历code中的每个检测结果，计算人脸框的面积，并选择面积最大的人脸进行处理。\n    if code:\n        t = 0\n        max_face = 0\n        totalRes = len(code)\n        area = []\n        # 如果检测到的人脸数大于1，则只处理面积最大的人脸。\n        if totalRes &gt; 1:  #多张人脸时，挑选面积最大的，一般即最前面的\n            for i in code: # 迭代坐标框  多张人脸\n                area.append(i.w()*i.h())\n            for j in range(len(area)):\n                if max_face &lt; area[j]:\n                    max_face = area[j]\n                    t = j    #保存最大脸面积下标\n            totalRes = 1\n            del area\n        if totalRes == 1:  #只有一张脸\n            i = code[t]\n            # 首先使用img.draw_rectangle()函数在原图像上绘制人脸框\n            # Cut face and resize to 128x128\n            a = img.draw_rectangle(i.rect())\n            # 然后使用img.cut()函数对原图像进行裁剪，得到人脸图像。\n            face_cut = img.cut(i.x(), i.y(), i.w(), i.h())\n            # 使用img.resize()函数将人脸图像缩放为128x128大小\n            face_cut_128 = face_cut.resize(128, 128)\n            # 使用img.pix_to_ai()函数将图像转换为KPU能够处理的格式。\n            a = face_cut_128.pix_to_ai()\n            # a = img.draw_image(face_cut_128, (0,0))\n            # Landmark for face 5 points\n            # 程序使用kpu.forward()函数对人脸图像进行特征点检测，得到人脸的五个关键点坐标。\n            fmap = kpu.forward(task_ld, face_cut_128)\n            plist = fmap[:]\n            le = (i.x() + int(plist[0] * i.w() - 10), i.y() + int(plist[1] * i.h()))\n            re = (i.x() + int(plist[2] * i.w()), i.y() + int(plist[3] * i.h()))\n            nose = (i.x() + int(plist[4] * i.w()), i.y() + int(plist[5] * i.h()))\n            lm = (i.x() + int(plist[6] * i.w()), i.y() + int(plist[7] * i.h()))\n            rm = (i.x() + int(plist[8] * i.w()), i.y() + int(plist[9] * i.h()))\n            # 使用img.draw_circle()函数在原图像上绘制出这些关键点的位置。\n            a = img.draw_circle(le[0], le[1], 4)\n            a = img.draw_circle(re[0], re[1], 4)\n            a = img.draw_circle(nose[0], nose[1], 4)\n            a = img.draw_circle(lm[0], lm[1], 4)\n            a = img.draw_circle(rm[0], rm[1], 4)\n            # align face to standard position\n            src_point = [le, re, nose, lm, rm]\n            # 程序使用这些关键点的坐标计算人脸的仿射变换矩阵，并使用image.get_affine_transform()函数计算变换矩阵。\n            T = image.get_affine_transform(src_point, dst_point)\n            # 使用image.warp_affine_ai()函数将人脸图像进行对齐，得到标准的人脸图像。\n            a = image.warp_affine_ai(img, img_face, T)\n            # 然后，程序使用img.ai_to_pix()函数将对齐后的图像转换为原图像能够显示的格式。\n            a = img_face.ai_to_pix()\n            # a = img.draw_image(img_face, (128,0))\n            del (face_cut_128)\n            # calculate face feature vector\n            # 程序使用kpu.forward()函数对对齐后的人脸图像进行特征提取\n            fmap = kpu.forward(task_fe, img_face)\n            # 使用kpu.face_encode()函数将特征向量进行编码\n            feature = kpu.face_encode(fmap[:])\n            reg_flag = False\n            scores = []\n            # 程序遍历预先录入的人脸特征列表\n            for j in range(len(record_ftrs)):\n                # 使用kpu.face_compare()函数计算当前人脸特征向量与列表中每个特征向量的相似度得分。\n                score = kpu.face_compare(record_ftrs[j], feature)\n                scores.append(score)\n            max_score = 0\n            index = 0\n            # 最终，程序选择得分最高的特征向量，并返回其在列表中的索引。这个索引可以用于识别当前人脸是否为已知人脸。\n            for k in range(len(scores)):\n                if max_score &lt; scores[k]:\n                    max_score = scores[k]\n                    index = k\n</code></p><p></p><p>其次是人脸信息录入模块，主要分为以下几个步骤：</p><p></p><p>如果检测到当前画面中存在人脸，且识别率超过预设值，程序会在屏幕上显示提示信息“Face Exist”，然后继续循环，等待下一张图像的检测和处理。如果检测到人脸特征，程序会记录当前采集的人脸数量，每检测到一次人脸就加 1，并在屏幕上显示当前采样进度。程序会间隔录入，每采集 6 次人脸特征就将当前特征加入到临时特征值列表中。如果已采集到 18 次人脸特征，表示录入结束，程序会将当前特征添加到已知特征列表中，并将编号添加到 names 列表中。然后程序会尝试打开 SD 卡上的 faceinfo. Txt 文件，并以追加模式写入数据。写入完成后，程序会将当前特征添加到已知特征列表中，并将编号添加到 names 列表中。同时清空临时特征值列表和采集次数，显示录入成功或失败的提示信息，并进行蜂鸣器声音提示。最后退出录入任务并回到正常模式。如果保存到 SD 卡失败，则按键次数清零，check_num 清零，编号清空，并显示录入失败的提示信息。最后，程序会删除code变量，释放内存空间。</p><p></p><p>代码详细注释如下：</p><p></p><p><code lang=\"python\">    # 执行录入任务\n    if luru_flag == 1:\n        # 如果检测到当前画面中存在人脸，且识别率超过预设值\n        if max_score &gt; ACCURACY:\n            # 人脸采集次数清零\n            check_num = 0\n            # 在屏幕上显示提示信息“Face Exist”\n            a = img.draw_string(200,0, b'Face Exist', color=(255,0,0),scale=1.6,mono_space=1)  #提示人脸已存在\n            # 在屏幕上显示图像\n            a = lcd.display(img)\n            # 继续循环，等待下一张图像的检测和处理\n            continue\n        # 如果检测到人脸特征\n        if code:\n            # 记录当前采集的人脸数量，每检测到一次人脸就加1\n            check_num = check_num + 1     #检测到一次人脸则加 1\n            # 在屏幕上显示当前采样进度\n            a = img.draw_string(5,40, b'%d'%check_num, color=(0,255,0),scale=1.4,mono_space=1) #显示采样进度\n            # 间隔录入，每采集6次人脸特征就将当前特征加入到临时特征值列表中\n            if check_num % 6 == 0 and check_num != 0:\n                record_ftrtemp.append(feature)   #加入当前人脸特征\n            # 如果已采集到18次人脸特征，表示录入结束\n            if check_num == 18:\n            # 录入成功标志位设为1\n                save_success = 1\n                try:\n                    # 尝试打开SD卡上的faceinfo.txt文件，并以追加模式写入数据\n                    with open(\"/sd/faceinfo.txt\", \"a\") as f:\n                        for i in range(len(record_ftrtemp)):  #循环遍历临时特征值列表，写入SD卡\n                            f.write(stu_num+'#'+str(record_ftrtemp[i]))\n                            # 每个特征值占一行\n                            f.write(\"\\n\")\n                        # 关闭文件\n                        f.close()\n                except Exception:\n                    save_success = 0  #表示保存到SD卡失败了\n                    pass\n                # 如果保存到SD卡成功，则将当前特征添加到已知特征列表中，并将学号添加到names列表中；同时清空临时特征值列表和采集次数，显示录入成功的提示信息，并进行蜂鸣器声音提示；最后退出录入任务并回到正常模式。\n                if save_success == 1:\n                    #将当前特征添加到已知特征列表，学号添加到names\n                    for i in record_ftrtemp:\n                        record_ftrs.append(i)\n                        names.append(stu_num)\n                    record_ftrtemp.clear()  #清空临时特征值列表\n                    # 在屏幕上显示录入成功的提示信息\n                    a = img.draw_string(0,5, b'Success!', color=(255,0,0),scale=1.4,mono_space=1)  #录入成功\n                    # 在屏幕上显示图像\n                    a = lcd.display(img)\n\n                    #蜂鸣器声音提示\n                    beep.enable()\n                    beep.freq(1000)\n                    time.sleep(2)\n                    beep.disable()\n                    luru_flag = 0  # 退出录入任务\n                    # 回到正常模式\n                    LuRu_mode = False   # 录入模式\n                    Door_mode = False   # 门禁模式\n                    Normal_mode = True  # 正常模式\n                #如果保存到SD卡失败，则按键次数清零，check_num清零，学号清空\n                else:\n                    a = img.draw_string(0,5, b'Fail!', color=(255,0,0),scale=1.4,mono_space=1)  #录入失败\n                    #蜂鸣器声音提示\n                    beep.enable()\n                    beep.freq(600)\n                    time.sleep(2)\n                    beep.disable()\n                    luru_flag = 0  # 退出录入任务\n                    # 回到正常模式\n                    LuRu_mode = False   # 录入模式\n                    Door_mode = False   # 门禁模式\n                    Normal_mode = True  # 正常模式\n        # 删除code变量，释放内存空间。\n        del code\n</code></p><p></p><p>最后是人脸蓝牙RFID综合验证模块，这个模块相较于前面两个模块，逻辑设计较为复杂，首先判断是否检测到人：程序首先会检测人是否出现在门禁的监控区域，如果有人，则将 no_flag 置为1。同时进行垃圾回收，程序会定期进行垃圾回收，以释放不再使用的内存空间。再接收蓝牙数据：程序会读取蓝牙模块发送的数据，如果读取到了数据且长度大于等于2，则进行后续的处理。a. 如果读取到的蓝牙数据中包含 'open'，则程序会将舵机旋转以打开门禁，以实现临时门禁的功能。b. 如果读取到的蓝牙数据中包含 'erase'，执行删除全部用户的操作。具体来说，代码实现了以下功能：</p><p></p><p>如果读取到的蓝牙数据中包含 'erase'，则执行内部代码块。清空名称列表、特征值列表和人脸信息文件。打开人脸信息文件，并将其内容清空。清空图像缓存。绘制矩形和字符串，并在 LCD 屏幕上显示图像。发出蜂鸣器声音提示。</p><p></p><p>c. 如果读取到的蓝牙数据中包含 'delete' ，执行删除指定用户的操作。具体来说，代码实现了以下功能：</p><p></p><p>如果读取到的蓝牙数据中包含 'delete'，则执行内部代码块。截取出要删除的编号，并打印输出。逐行读取人脸信息文件，查找要删除的编号，并记录要删除的行数。如果找到了要删除的行，则打开人脸信息文件，删除指定行，并重新写入文件。从名称列表和特征值列表中删除指定的用户。绘制矩形和字符串，并在 LCD 屏幕上显示图像。发出蜂鸣器声音提示。将程序回到正常模式。</p><p></p><p>d. 如果当前处于录入模式，则在 LCD 屏幕上显示“Register Mode”字样。如果读取到的蓝牙数据中包含 'register'，则执行人脸注册操作。</p><p></p><p>截取出要注册的编号，并打印输出。判断该编号是否已经被录入，如果已经被录入，则在 LCD 屏幕上显示“ID Exist!”字样，并在屏幕上显示红色矩形区域，发出蜂鸣器声音提示，并回到正常模式；否则，设置录入标志位为 1。如果录入标志位为 1，则进行人脸录入操作。检测到人脸后，提取人脸特征，并将其添加到特征值列表 record_ftrs 中。将编号和姓名组合成一个字符串，并添加到名称列表 names 中。发出蜂鸣器声音提示。将录入标志位设置为 0。将程序回到正常模式。</p><p></p><p>e. 如果当前处于门禁模式，脚本初始化 RFID 模块并尝试从中读取数据。如果检测到有效的 RFID 卡片，代码将读取卡片数据并根据不同卡片内容执行相应的操作。如果卡片包含预期数据，则触发一个绿色 LED 和一个舵机来打开门锁。如果卡片包含无效数据，则触发一个红色 LED 和一个蜂鸣器来警告用户。此外，为了更加丰富使用场景，这里还预留了一个万能卡的对应信息，保证管理员可以在特殊情况下进行无限制开门。</p><p></p><p>除了 RFID 部分，“门禁模式”还同时运行人脸识别算法。如果检测到人脸，比较当前人脸与存储人脸相似的置信度，如果识别的置信度高于设定的阈值，则触发与有效 RFID 卡片相同的操作，控制舵机打开门禁并且显示绿灯。如果人脸识别分数低于设定的阈值，显示分数，并计数，如果计数超过3次则表示人脸识别失败，开启红灯并发出蜂鸣器声音</p><p></p><p>f. 如果当前处于正常模式，设置录入标志和检查数字为 0，使用 LCD 显示屏显示“等待......”,并将标志位 no_people 设置为 0。如果当前没有人在操作，程序会将 LCD 清空并显示“休眠中......”,并将标志位 no_people 设置为 1。程序会在适当的时候调用 del img 和 gc.collect() 来回收内存。其中，del img 用于删除 img 对象占用的内存，而 gc.collect() 用于回收未被使用的内存。</p><p></p><p>代码详细注释如下：</p><p></p><p><code lang=\"python\">    # 有人的时候LCD显示摄像头的拍摄画面\n    if people_find.value() == 1:\n        no_flag = 1\n\n\n\n        # 接收蓝牙数据\n        # 垃圾回收\n        gc.collect()\n        # 读取蓝牙数据\n        text = uart.read()\n        if text != None and len(text) &gt;= 2: #如果读取到了数据，且大于等于2\n            # 临时开门禁\n            # 如果蓝牙数据中包含 'open'\n            if 'open' in text:\n                print(\"--------蓝牙开门--------\")\n                # 舵机旋转\n                Servo(SS,90)\n                time.sleep(2)\n                Servo(SS,0)\n\n            # 删除全部用户命令\n            # 如果蓝牙数据中包含 'erase'\n            if 'erase' in text:\n                print(\"--------删除全部用户--------\")\n                # 清空名称列表、特征值列表和人脸信息文件\n                names.clear()\n                record_ftrs.clear()\n                # 打开文件\n                file_new = open('/sd/faceinfo.txt', 'w')\n                # 写入空字符串\n                file_new.write(''.join(''))\n                # 关闭文件\n                file_new.close()\n                # 清除图像\n                img.clear()\n                # 绘制矩形\n                img.draw_rectangle((90, 85, 140, 70), fill=True, color=(0, 0, 255))\n                # 绘制字符串\n                img.draw_string(110, 112, \"delete all\", color=(255, 255, 255), scale=1.5, mono_space=0)\n                # 在LCD屏幕上显示图像\n                lcd.display(img)\n                #蜂鸣器声音提示\n                beep.enable()\n                beep.freq(1000)\n                time.sleep(2)\n                beep.disable()\n                a = img.clear()\n\n            # 删除用户命令\n            # 如果蓝牙数据中包含 'delete'\n            if 'del' in text:\n                print(\"--------删除用户--------\")\n                delnum = text[3:].decode('utf-8')  #截取出删除的学号\n                print('删除的学号: ', delnum)\n                print(delnum)\n                del text\n                k=-1\n                # 打开人脸信息文件\n                with open('/sd/faceinfo.txt', 'r') as f:\n                    while(1):\n                    # 逐行读取文件内容\n                        thisline=f.readline()\n                        if not thisline:\n                            # 如果文件已读完\n                            break\n                        # 计数器加1\n                        k=k+1\n                        # 判断是否找到要删除的学号\n                        result = delnum in thisline\n                        # 如果找到了第一个匹配项\n                        if result==True and find_flag == 0:\n                            # 标记为找到\n                            find_flag=1\n                            print('ok')\n                        # 如果找到了多个匹配项\n                        if result==True and find_flag == 1:\n                            # 记录要删除的行数\n                            delline.append(k)\n                        # 如果匹配项已结束\n                        if result==False and find_flag == 1:\n                            # 标记为未找到\n                            find_flag = 0\n                            break\n                    # 关闭文件\n                    f.close()\n                # 如果SD卡中有此人，那么就删除，\n                if delline:\n                    # 按行读入，删除最后一行\n                    # 打开文件\n                    file_old = open('/sd/faceinfo.txt', 'r')\n                    # 逐行读取文件内容\n                    lines = [i for i in file_old]\n                    # 删除指定行数\n                    del lines[int(delline[0]):int(delline[-1])+1]\n                    # 关闭文件\n                    file_old.close()\n                    del file_old\n                    # 清空要删除的行数列表\n                    delline.clear()\n                    # 再覆盖写入\n                    # 打开文件\n                    file_new = open('/sd/faceinfo.txt', 'w')\n                    # 将修改后的内容写入文件\n                    file_new.write(''.join(lines))\n                    # 关闭文件\n                    file_new.close()\n                    del lines\n                    ##删除姓名列表和特征值列表中的数据\n                    #print('之前',names)\n                    i = 0\n                    # 清空名称列表\n                    temp_num = ''\n                    names = []\n                    # 清空特征值列表\n                    record_ftrs = []\n                    # 垃圾回收\n                    gc.collect()\n                    try:\n                        # 打开人脸信息文件\n                        with open(\"/sd/faceinfo.txt\", \"r\") as f:\n                            while(1):\n                                # 垃圾回收\n                                gc.collect()\n                                # 逐行读取文件内容\n                                lin = f.readline()\n                                # 如果文件已读完\n                                if not lin:\n                                    break\n                                stunum = lin[0:lin.index('#')]    #获取学号\n                                lin = lin[lin.index('#')+1:]      #截取除了学号以外的字符串\n                                stu_name = lin[0:lin.index('#')]  #获取姓名\n                                names.append(stunum+'#'+stu_name) #追加到姓名列表\n                                lin = lin[lin.index('#')+1:]      #截取人脸特征\n                                record_ftrs.append(eval(lin))     #向人脸特征列表中添加已存特征\n                    except:\n                        pass\n                    # 垃圾回收\n                    gc.collect()\n                    # 清除图像\n                    img.clear()\n                    # 绘制矩形\n                    img.draw_rectangle((90, 85, 140, 70), fill=True, color=(0, 0, 255))\n                    # 绘制字符串\n                    img.draw_string(110, 112, \"delete %s\"%delnum, color=(255, 255, 255), scale=1.5, mono_space=0)\n                    # 在LCD屏幕上显示图像\n                    lcd.display(img)\n                    #蜂鸣器声音提示\n                    beep.enable()\n                    beep.freq(1000)\n                    time.sleep(2)\n                    beep.disable()\n                    a = img.clear()\n\n                    # 回到正常模式\n                    LuRu_mode = False   # 录入模式\n                    Door_mode = False   # 门禁模式\n                    Normal_mode = True  # 正常模式\n                else:\n                    a = img.clear()\n                    # 绘制矩形\n                    a = img.draw_rectangle((90, 85, 140, 70), fill=True, color=(0, 0, 255))\n                    # 绘制字符串\n                    a = img.draw_string(118, 112, \"No people!\", color=(255, 255, 255), scale=1.5, mono_space=0)\n                    # 在LCD屏幕上显示图像\n                    a = lcd.display(img)\n                    #蜂鸣器声音提示\n                    beep.enable()\n                    beep.freq(600)\n                    time.sleep(2)\n                    beep.disable()\n                    a = img.clear()\n                    # 回到正常模式\n                    LuRu_mode = False   # 录入模式\n                    Door_mode = False   # 门禁模式\n                    Normal_mode = True  # 正常模式\n\n        # 检测按键\n        # 录入模式按键\n        if LuRu_mode:\n            try:\n                # 在屏幕上显示“录入模式”字样\n                a = img.draw_string(0,0, b'Register Mode', color=(0,255,0),scale=1.6,mono_space=1)\n            except:\n                pass\n            # 判断蓝牙数据是否读取到并且长度大于等于2\n            if text != None and len(text) &gt;= 2: #如果读取到了数据，且大于等于2\n                # 判断是否收到“register”命令，如果是则进行人脸注册\n                if 'register' in text:\n                    print(\"--------人脸注册--------\")\n                    stu_num = text[2:].decode('utf-8')  # 截取出学号\n                    print('学号: ', stu_num)\n\n                    # 判断该学号是否已被录入\n                    # 如果该学号已经被录入，显示“ID Exist!”字样，并在屏幕上显示红色矩形区域\n                    if stu_num in names:\n                        a = img.clear()\n                        a = img.draw_rectangle((90, 85, 140, 70), fill=True, color=(0, 0, 255))\n                        a = img.draw_string(118, 112, \"ID Exist!\", color=(255, 255, 255), scale=1.5, mono_space=0)\n                        a = lcd.display(img)\n                        #蜂鸣器声音提示\n                        beep.enable()\n                        beep.freq(600)\n                        time.sleep(2)\n                        beep.disable()\n                        # 回到正常模式\n                        LuRu_mode = False   # 录入模式\n                        Door_mode = False   # 门禁模式\n                        Normal_mode = True  # 正常模式\n                    # 如果学号没有被录入，进行下一步录入\n                    else:\n                        # 设置录入标志位为1\n                        luru_flag = 1\n\n        # 门禁模式按键\n        if Door_mode:\n        # 录入标志位设置为0\n            luru_flag = 0\n            # 校验次数设置为0\n            check_num = 0\n            # 在屏幕上显示“门禁模式”字样\n            a = img.draw_string(0,0, b'Entrance Mode', color=(0,255,0),scale=1.6,mono_space=1)\n            # ================================== RFID ================================\n\n            # time.sleep(2)\n            # from micropython import const\n\n\n            #############################################\n\n            #continue_reading = True\n\n            # 20: CS_NUM;\n            fm.register(CS_NUM, fm.fpioa.GPIOHS20, force=True)\n\n            # set gpiohs work mode to output mode\n            cs = GPIO(GPIO.GPIOHS20, GPIO.OUT)\n\n            spi1 = SPI(SPI.SPI_SOFT, mode=SPI.MODE_MASTER, baudrate=SPI_FREQ_KHZ * 1000,\n                    polarity=0, phase=0, bits=8, firstbit=SPI.MSB, sck=SPI_SCK, mosi=SPI_MOSI, miso=SPI_MISO)\n\n            # Create an object of the class MFRC522\n            MIFAREReader = MFRC522(spi1, cs)\n\n            # time.sleep_ms(300)\n            # Scan for cards\n            (status, ataq) = MIFAREReader.MFRC522_Request(MIFAREReader.PICC_REQALL)\n\n            # If a card is found\n            if status == MIFAREReader.MI_OK:\n                # 如果卡片被找到，打印卡片类型和UID\n                print(\"Card detected type: \",hex(ataq[0]&lt;&lt;8|ataq[1]))\n                # Get the UID of the card\n                (status, uid) = MIFAREReader.MFRC522_Anticoll()\n\n                # If we have the UID, continue\n                if status == MIFAREReader.MI_OK:\n\n                    # Print UID\n                    print(\"Card read UID: \" +\n                        str(uid[0])+\",\"+str(uid[1])+\",\"+str(uid[2])+\",\"+str(uid[3]))\n\n                    # This is the default key of M1(S50) for authentication\n                    # M1卡片的默认密钥\n                    key = [0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF]\n\n                    # Select the scanned tag\n                    # 选择扫描到的标签\n                    MIFAREReader.MFRC522_SelectTag(uid)\n\n                    # Authenticate\n                    # 验证卡片密钥\n                    status = MIFAREReader.MFRC522_Auth(\n                        MIFAREReader.PICC_AUTHENT1A, 0x12, key, uid)\n\n                    # Check if authenticated\n                    # 检查是否验证成功\n                    #if status == MIFAREReader.MI_OK:\n                        # 示例：定义一个包含16个元素的列表，并将第一个元素设为'Y'\n                        ##data = ['Y',0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n                        ##data = ['N',0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n                        ## Fill the data with 0~16\n                        #for x in range(0, 16):\n                            #data.append(x)\n\n                        ## Write the data\n                        # 向扇区0x12写入数据\n                        #print(\"Sector 11 will now be filled with 1~16:\")\n                        # 使用MFRC522_Write方法将data列表写入扇区0x12\n                        #status = MIFAREReader.MFRC522_Write(0x12, data)\n                    # 如果验证成功，读取RFID模块中的数据\n                    try:\n                        if status == MIFAREReader.MI_OK:\n                            print(\"start to read\")\n                            # read the data\n                            # MIFAREReader.MFRC522_Read(0x12)\n                            datas = MIFAREReader.MFRC522_Read(0x12)\n                            #读出卡中的id号\n                            strnum = ' '\n                            strnum = chr(datas[0])+str(datas[1])+str(datas[2])+str(datas[3])+str(datas[4])\n                            #如果第一个字符不是B则说明卡错误\n                            if chr(datas[0]) == 'Y':\n                                led_g.value(0)  # 绿灯亮\n                                Servo(SS,90)\n                                time.sleep(2)\n                                Servo(SS,0)\n                                led_g.value(1)  # 绿灯灭\n\n                            if chr(datas[0]) == 'N':\n                                #蜂鸣器声音提示\n                                beep.enable()\n                                beep.freq(300)\n                                time.sleep(2)\n                                beep.disable()\n                                ##读出卡中的姓名\n                                #if datas[11]==0: #名字两个字\n                                    #strname = \"b'\"+hex(datas[5])+hex(datas[6])+hex(datas[7])+hex(datas[8])+hex(datas[9])+hex(datas[10])+\"'\"\n                                #else :          #名字三个字\n                                    #strname = \"b'\"+hex(datas[5])+hex(datas[6])+hex(datas[7])+hex(datas[8])+hex(datas[9])+hex(datas[10])+hex(datas[11])+hex(datas[12])+hex(datas[13])+\"'\"\n                                #strname = eval(strname.replace('0','\\\\')).decode('utf8')\n\n                            # Stop\n                            MIFAREReader.MFRC522_StopCrypto1()\n                        #else:\n                            #print(\"Authentication error\")\n                    except Exception as e:\n                         beep.enable()\n                         beep.freq(1000)\n                         time.sleep(2)\n                         beep.disable()\n\n\n            try:\n                # 如果人脸识别分数高于设定的阈值，显示学号与分数，并开启绿灯\n                if max_score &gt; ACCURACY:\n                    a = img.draw_string(i.x()+4,i.y()-20, (\"%s: %2.1f\" % (names[index], max_score)), color=(0,255,0),scale=2) # 显示学号与分数\n                    a = lcd.display(img)\n                    print(\"--------人脸识别成功--------\")\n                    led_g.value(0)  # 绿灯亮\n                    Servo(SS,90)\n                    time.sleep(2)\n                    Servo(SS,0)\n                    led_g.value(1)  # 绿灯灭\n                    shibie_num = 0\n                elif code:\n                    # 如果人脸识别分数低于设定的阈值，显示分数，并计数，如果计数超过3次则表示人脸识别失败，开启红灯并发出蜂鸣器声音\n                    img.draw_string(i.x()+4,i.y()-20, (\"%s: %2.1f\" % (\"No\",max_score)), color=(0,255,0),scale=2) # 显示分数\n                    a = lcd.display(img)\n                    shibie_num = shibie_num + 1\n                    if shibie_num &gt; 3:\n                        shibie_num = 0\n                        print(\"--------人脸识别失败--------\")\n                        led_r.value(0)  # 红灯亮\n                        beep.enable()\n                        beep.freq(600)\n                        time.sleep(2)\n                        beep.disable()\n                        led_r.value(1)  # 红灯灭\n            except:\n                pass\n                # 删除变量code，释放内存空间\n            del code\n\n        # 正常模式按键\n        # 设置录入标志和检查数字为0，使用LCD显示屏显示“等待……”\n        if Normal_mode:\n            luru_flag = 0\n            check_num = 0\n            a = img.draw_string(0,0, b'Waiting......', color=(0,255,0),scale=1.6,mono_space=1)\n            ## ================================== RFID ================================\n\n            ## time.sleep(2)\n            ## from micropython import const\n            #################### config ###################\n            #CS_NUM = const(18)\n            #SPI_FREQ_KHZ = const(600)\n            #SPI_SCK = const(19)\n            #SPI_MOSI = const(8)\n            #SPI_MISO = const(15)\n\n            ##############################################\n\n            ##continue_reading = True\n\n            ## 20: CS_NUM;\n            #fm.register(CS_NUM, fm.fpioa.GPIOHS20, force=True)\n\n            ## set gpiohs work mode to output mode\n            #cs = GPIO(GPIO.GPIOHS20, GPIO.OUT)\n\n            #spi1 = SPI(SPI.SPI_SOFT, mode=SPI.MODE_MASTER, baudrate=SPI_FREQ_KHZ * 1000,\n                    #polarity=0, phase=0, bits=8, firstbit=SPI.MSB, sck=SPI_SCK, mosi=SPI_MOSI, miso=SPI_MISO)\n\n            ## Create an object of the class MFRC522\n            #MIFAREReader = MFRC522(spi1, cs)\n\n            ## time.sleep_ms(300)\n            ## Scan for cards\n            #(status, ataq) = MIFAREReader.MFRC522_Request(MIFAREReader.PICC_REQALL)\n\n            ## If a card is found\n            #if status == MIFAREReader.MI_OK:\n                #print(\"Card detected type: \",hex(ataq[0]&lt;&lt;8|ataq[1]))\n                ## Get the UID of the card\n                #(status, uid) = MIFAREReader.MFRC522_Anticoll()\n\n                ## If we have the UID, continue\n                #if status == MIFAREReader.MI_OK:\n\n                    ## Print UID\n                    #print(\"Card read UID: \" +\n                        #str(uid[0])+\",\"+str(uid[1])+\",\"+str(uid[2])+\",\"+str(uid[3]))\n\n                    ## This is the default key of M1(S50) for authentication\n                    #key = [0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF]\n\n                    ## Select the scanned tag\n                    #MIFAREReader.MFRC522_SelectTag(uid)\n\n                    ## Authenticate\n                    #status = MIFAREReader.MFRC522_Auth(\n                        #MIFAREReader.PICC_AUTHENT1A, 0x12, key, uid)\n\n                    ## Check if authenticated\n                    ##if status == MIFAREReader.MI_OK:\n                        ###data = ['Y',0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n                        ###data = ['N',0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n                        ### Fill the data with 0~16\n                        ##for x in range(0, 16):\n                            ##data.append(x)\n\n                        ### Write the data\n                        ##print(\"Sector 11 will now be filled with 1~16:\")\n                        ##status = MIFAREReader.MFRC522_Write(0x12, data)\n                    #try:\n                        #if status == MIFAREReader.MI_OK:\n                            #print(\"start to read\")\n                            ## read the data\n                            ## MIFAREReader.MFRC522_Read(0x12)\n                            #datas = MIFAREReader.MFRC522_Read(0x12)\n                            ##读出卡中的id号\n                            #strnum = ' '\n                            #strnum = chr(datas[0])+str(datas[1])+str(datas[2])+str(datas[3])+str(datas[4])\n                            ##如果第一个字符不是B则说明卡错误\n                            #if chr(datas[0]) == 'Y':\n                                #led_g.value(0)  # 绿灯亮\n                                #Servo(SS,90)\n                                #time.sleep(2)\n                                #Servo(SS,0)\n                                #led_g.value(1)  # 绿灯灭\n\n                            #if chr(datas[0]) == 'N':\n                                ##蜂鸣器声音提示\n                                #beep.enable()\n                                #beep.freq(300)\n                                #time.sleep(2)\n                                #beep.disable()\n                                ###读出卡中的姓名\n                                ##if datas[11]==0: #名字两个字\n                                    ##strname = \"b'\"+hex(datas[5])+hex(datas[6])+hex(datas[7])+hex(datas[8])+hex(datas[9])+hex(datas[10])+\"'\"\n                                ##else :          #名字三个字\n                                    ##strname = \"b'\"+hex(datas[5])+hex(datas[6])+hex(datas[7])+hex(datas[8])+hex(datas[9])+hex(datas[10])+hex(datas[11])+hex(datas[12])+hex(datas[13])+\"'\"\n                                ##strname = eval(strname.replace('0','\\\\')).decode('utf8')\n\n                            ## Stop\n                            #MIFAREReader.MFRC522_StopCrypto1()\n                        ##else:\n                            ##print(\"Authentication error\")\n                    #except Exception as e:\n                         #beep.enable()\n                         #beep.freq(1000)\n                         #time.sleep(2)\n                         #beep.disable()\n\n        a = lcd.display(img)\n\n    # 无人的时候LCD黑屏，休眠状态（录入的时候不能进入休眠状态）\n    # 如果没有人在操作，将LCD清空并显示“休眠中……”，并将标志位no_people设置为1。\n    elif luru_flag == 0:\n        no_people = 1\n    # 如果有人在操作，则将标志位no_people和no_flag都置为0，表示有人正在操作，不进行休眠。\n    if no_people == 1 and no_flag == 1:\n        no_people = 0\n        no_flag = 0\n        a = img.clear()   # 清空一次LCD\n        # 最后，将img对象在LCD上显示出来，并回收内存。\n        a = img.draw_string(40,110, b'Suspending......', color=(0,255,0),scale=2,mono_space=1)\n        a = lcd.display(img)\n    # del img用于删除img对象占用的内存\n    del img\n    # gc.collect()用于回收未被使用的内存。\n    gc.collect()\n</code></p><p></p><h1>5.各模块实操结果展示和实现指标</h1><p></p><p><img src=\"https://static001.geekbang.org/infoq/fb/fb8b94b22e43125b5d408745b905e935.png\" /></p><p></p><p>图5-1人脸录入成功</p><p></p><p>输入“register****”（****代表录入人脸编号）后按照yolo v2算法采集196维人脸数据（3轮18次采样），并储存在SD卡文件中，且屏幕显示采样进度，录入完成屏幕显示“successful”，蜂鸣器发低声。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3f/3fa8a0d8de8f035ac85bb27d62e9ee5a.png\" /></p><p></p><p>图5-2人脸识别成功</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c7/c7fce8b197dd4082da256794f0130f2f.png\" /></p><p></p><p>图5-3人脸识别比对失败</p><p></p><p>门禁模式时，人脸识别框上会显示序列号和相似度，设定比对阈值，此处设置75，高于则蜂鸣器发低声且舵机旋转，低于则蜂鸣器发高声舵机无反应。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/66/6612bf1611544c30f4717e4e418846f0.png\" /></p><p></p><p>图5-4 人脸数据删除成功</p><p></p><p>输入“delete****”则删除对应用户储存在SD卡的特征值，蜂鸣器发高声。且屏幕显示ok，输入“erase”则删除SD卡内所有用户人脸特征值，蜂鸣器发高声且屏幕显示delete all。输入“open”则无条件控制舵机旋转，用作临时开关门禁。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fd/fd3e539a47c8834a4e519e8b51548427.png\" /></p><p></p><p>图5-5蓝牙app操作</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ac/ac1d92b58743534f25cae704c7a62ec8.png\" /></p><p></p><p>图5-6删除所有人脸数据</p><p></p><h1>6.可改进之处及拓展方向</h1><p></p><p></p><h2>6.1 不足及改进之处</h2><p></p><p>此部分略。</p><p></p><h2>6.2 系统方案可拓展方向</h2><p></p><p>此部分略。</p><p></p><h1>7.参考资料</h1><p></p><p>1、RFID 学习资料</p><p></p><p><a href=\"https://blog.csdn.net/HuangChen666/article/details/114024767?spm=1001.2014.3001.5506\">https://blog.csdn.net/HuangChen666/article/details/114024767?spm=1001.2014.3001.5506</a>\"</p><p></p><p>2、K210学习系列</p><p></p><p><a href=\"https://blog.csdn.net/Thousand_drive/article/details/123796878?spm=1001.2014.3001.5506\">https://blog.csdn.net/Thousand_drive/article/details/123796878?spm=1001.2014.3001.5506</a>\"</p><p></p><p>3、人脸识别学习资料</p><p></p><p><a href=\"https://blog.csdn.net/Aaron357/article/details/93485279?spm=1001.2101.3001.6650.5&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-5-93485279-blog-107153393.235%5Ev36%5Epc_relevant_default_base3&amp;depth_1-utm_source=\">https://blog.csdn.net/Aaron357/article/details/93485279?spm=1001.2101.3001.6650.5&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-5-93485279-blog-107153393.235%5Ev36%5Epc_relevant_default_base3&amp;depth_1-utm_source=</a>\"</p><p></p><p>4、固件烧录、信息储存学习资料</p><p></p><p><a href=\"https://blog.csdn.net/HuangChen666/article/details/113995079?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522168536128716800222862427%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=168536128716800222862427&amp;biz_id=0&amp;utm_me\">https://blog.csdn.net/HuangChen666/article/details/113995079?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522168536128716800222862427%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=168536128716800222862427&amp;biz_id=0&amp;utm_me</a>\"</p><p></p><p>5、蓝牙模块学习资料</p><p></p><p><a href=\"https://blog.csdn.net/qq_44125275/article/details/128266379?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522168536196416800192217378%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&amp;request_id=168536196416800192217378&amp;biz_id\">https://blog.csdn.net/qq_44125275/article/details/128266379?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522168536196416800192217378%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&amp;request_id=168536196416800192217378&amp;biz_id</a>\"</p><p></p><p>[1] Zhu, X., Lei, Z., Liu, X., Shi, H., &amp; Li, S. Z. (2018). Face recognition: From traditional to deep learning methods. Advances in Computers, 113, 1-69.</p><p></p><p>[2] AlBdairi, A.J.A.; Xiao, Z.; Alkhayyat, A.; Humaidi, A.J.; Fadhel, M.A.; Taher, B.H.; Alzubaidi, L.; Santamaría, J.; Al-Shamma, O. Face Recognition Based on Deep Learning and FPGA for Ethnicity Identification. Appl. Sci. 2022, 12, 2605. https://doi.org/10.3390/app12052605</p><p></p><p>[3] Chen, J., Liao, S., &amp; Liu, Y. (2021). Intelligent access control system based on deep learning and IoT. Journal of Physics: Conference Series, 1821(1), 012074.</p><p></p><p>[4] Derbel, A., Vivet, D. and Emile, B. (2015), Access control based on gait analysis and face recognition. Electron. Lett., 51: 751-752. <a href=\"https://doi.org/10.1049/el.2015.0767\">https://doi.org/10.1049/el.2015.0767</a>\"</p><p></p><p>[5] A. Nag, J. N. Nikhilendra and M. Kalmath, \"IOT Based Door Access Control Using Face Recognition,\" 2018 3rd International Conference for Convergence in Technology (I2CT), Pune, India, 2018, pp. 1-3, doi: 10.1109/I2CT.2018.8529749.</p><p></p><p>[6] Radzi S A, Alif M K M F, Athirah Y N, et al. IoT based facial recognition door access control home security system using raspberry pi[J]. International Journal of Power Electronics and Drive Systems, 2020, 11(1): 417.</p>",
    "publish_time": "2023-09-15 15:10:42",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "揭秘 Google Cloud Next ’23：生成式 AI 的探索之路与开发范式变革",
    "url": "https://www.infoq.cn/article/AGWPQMx0Ea3FUepM1fmC",
    "summary": "<p>8 月底，谷歌以「AI 与云科技驱动创新」为题，举办了为期三天的 Google Cloud Next ’23 大会，展示了谷歌在基础架构、数据和 AI、Workspace 协作和信息安全解决方案等全系列产品不断创新的成果。</p><p></p><p>乍看之下似乎又是一场「大而全」的行业大会，但全程看完之后会明显的感受到，本次大会的内容全部围绕住了一个重心 —— <a href=\"https://www.infoq.cn/article/M4oBLcDHp7reGbveMud8\">「生成式 AI」</a>\"。</p><p></p><p>生成式 AI 作为近一两年最热门的技术话题没有之一，大家的谈论早已经超出了技术的范畴。如何应用、如何融合、如何落地，各行各业都在探索生成式 AI 带来的可能性。但除了 ChatGPT 这类的聊天机器人，似乎还没有特别成功的落地工具或者应用，哪怕是技术本源所在的研发领域也如是。</p><p></p><p>谷歌这次，似乎给出了一个参考答案。</p><p></p><p></p><h2>Google Next '23：生成式 AI 的探索之路</h2><p></p><p></p><p>生成式 AI 与传统 AI 技术最根本的区别在于前者通过理解自然语言创建内容，而后者依赖的是编程语言，这是生成式 AI 技术的关键变革特征，也是以前从未有过的能力。并且生成式 AI 能够以文本、图像、视频、音频和代码的形式生成新内容，而传统的 AI 系统训练计算机对人类行为、商业结果等进行预测。</p><p></p><p>对于许多人来说，第一次切身感知到生成式 AI 技术就是通过<a href=\"https://www.infoq.cn/article/iEkbUrxDh6c7svEbepKj\"> ChatGPT</a>\"。作为一种人工智能聊天机器人，在 2022 年 11 月迅速风靡全球。</p><p></p><p>大部分人不知道的是，ChatGPT 在架构层使用的是<a href=\"https://www.infoq.cn/article/wt-KaTfcsAv9E7exzIkF\"> Transformer </a>\"这一语言处理架构，该架构实际上便是谷歌在 2017 年的论文《Attention Is All You Need》中提出的。</p><p></p><p>谷歌作为一家成立了 25 年的公司，曾经在搜索、邮箱等领域取得了很多成绩，但在 AI 领域却面临了一些质疑。此前有媒体表示“谷歌在人工智能领域没有‘秘密武器’，无法赢得这场竞争。”而今年 5 月份的 Google I/O 以及前几日的 Google Cloud Next '23，可能正是在某种程度上回击了这种言论。</p><p></p><p>正如 Alphabet 和谷歌首席执行官桑达尔·皮查伊 （Sundar Pichai） 在活动开幕式上表示：</p><p></p><p>“在过去几年与企业领导者的交谈中，我听到了一个类似的主题。从桌面到移动，到云，再到现在的人工智能，他们需要的是一直走在技术突破前沿的合作伙伴。很多转变确实令人兴奋，但同时也会带来不确定性。向人工智能的转变无疑就是如此。”</p><p></p><p>“作为一家公司，我们已经为这一时刻准备了一段时间。在过去的七年里，我们采取了人工智能先行的方法，应用人工智能使我们的产品从根本上更加可用。我们相信，让人工智能为每个人带来帮助，是我们在未来十年完成使命的最重要方式。”</p><p></p><p>先内部小规模测试，再面向大众开放成熟的能力。谷歌也许确实没有“秘密武器”，但可能重点在于并不需要“秘密”，准备好之后，拿出来大家正面比划一下。这次的大会中，谷歌便亮出了其武器：</p><p></p><p></p><h3>Cloud TPU v5e</h3><p></p><p></p><p>生成式 AI 带来许多先进的功能，并可广泛使用于各种应用，但不可否认的是更加迫切的需要更先进、更强大的基础架构，设计和构建计算基础设施的传统方法已不足以满足生成式 AI 和大语言模型 （LLM） 等新兴工作负载的需求。为了解决这个问题，谷歌推出了 Cloud TPU v5e，一款最新且最具成本效益的 TPU。</p><p></p><p>TPU 是专门为大型人工智能模型的训练和推理而设计的定制人工智能芯片。客户可以使用单个 Cloud TPU 平台来运作大规模 AI 训练和推理。根据大会公开信息展示，Cloud TPU v5e 可扩展到数万个芯片并针对效率进行了优化。与 Cloud TPU v4 相比，每美元的训练效率可提升 2 倍，每美元的推论效率可提升 2.5 倍。</p><p></p><p></p><h3>Vertex AI</h3><p></p><p></p><p>在 2021 年 Google I/O 大会中，谷歌推出了 Vertex AI 托管式机器学习平台，用来帮助开发者更轻松地构建、部署和维护其机器学习模型。在本次的大会上，则正式推出了 Vertex AI 的搜索和对话功能，并将 ML 模型数量增加到 100 多个，这些模型都依据不同任务和不同大小进行了优化，包括文本、聊天、图像、语音、软件代码等等。</p><p></p><p>为了进一步平衡用户使用大模型进行建模的灵活性，以及他们可以生成的场景与推理成本以及微调能力，谷歌还为 Vertex AI 带来了扩展功能和 Grounding 等新的功能和工具。</p><p></p><p>借助 Vertex AI 扩展功能，开发者可以将 Model Garden 模型库中的模型与实时数据、专有数据或第三方平台（如 CRM 系统或电子邮件）连接起来，从而提供即时信息、集成公司数据并代表用户采取行动。这为生成式 AI 应用程序开辟了无限的新可能性。</p><p></p><p>Grounding 则是适用于 Vertex AI 基础模型、搜索及对话（Search and Conversation）的一项服务，可以协助客户将回复纳入企业自身的数据中，以提供更准确的回复内容。这一功能的重点在于可以一定程度上避免现阶段 AI 的“胡言乱语”，从而规避一些风险或者问题。</p><p></p><p></p><h3>Duet AI</h3><p></p><p></p><p>在 5 月的 I/O 大会上，Google Cloud 推出了 Duet AI。官方将其描述为“一位重要的协作伙伴、教练、灵感来源，和生产力推进器”，比如将 Docs 大纲转换成 Slides 中的演示文档，根据表格中的数据生成对应的图表；或者把 Duet AI 当做一个创作型的工具，用它来撰写电子邮件、生成图像、做会议纪要、检查文章的语法错误等等。</p><p></p><p>但当时的 Duet AI 只能在 Workspace 中使用，这次则扩展到了 Google Cloud 和 BigQuery 中，并推出更多适用的 AI 功能。例如 BigQuery 中的 Duet AI 旨在通过生成完整的函数和代码块，让用户专注于逻辑结果。它还可以建议和编写 Python 代码和 SQL 查询。这将进一步发挥 Duet AI &nbsp;\"编码专家、软件可靠性工程师、数据库专家、数据分析专家和网络安全顾问 \"的作用。</p><p></p><p>数据是生成式 AI 的核心，不难看出谷歌这次的更新迭代正式为了帮助数据团队进一步提高生产力，协助组织发挥数据及 AI 的最大潜力。</p><p></p><p></p><h2>一些后续思考：生成式 AI 带来的开发范式变革</h2><p></p><p></p><p>从基建、到平台再到应用，草蛇灰线，伏脉千里。谷歌在生成式 AI 领域的探索，其实并不像大家所想的有些“掉队”，而是在另一个维度提前布局。</p><p></p><p>25 年来，谷歌不断投资数据中心和网络，现在已经拥有涵盖 38 个云区域的全球网络，根据官方所说，目标是在 2030 年完全实现全天候采用无碳能源维持运营。谷歌的 AI 基础架构也在业界占据很大的份额，有超过 70% 的生成式 AI 独角兽公司和超过一半获得融资的生成式 AI 初创公司，都是 Google Cloud 客户。</p><p></p><p>“我们从每一层开始。这是对整个堆栈的重新构想。\"这是英伟达的黄仁勋在 Google Cloud Next '23 中传递的一个态度，”生成式人工智能正在彻底改变计算堆栈的每一层。我们两家公司（英伟达和谷歌）拥有世界上最有才华的两支计算科学团队，将为生成式人工智能重新发明云基础设施。\"</p><p></p><p>开发者关注的，是如何借助生成式 AI 的能力 &amp; 工具提效；企业关注的，是如何借助生成式 AI 来迭代业务产品抢占市场心智。但对谷歌这类“搞基建”的公司而言，关注堆栈的每一层、关注堆栈的整体结构，才有可能推进技术的发展，实现传统开发范式的变革。</p><p></p><p>今年年初，谷歌推出了 Security AI Workbench，这是业界首创的可扩展平台，由谷歌的新一代安全性大语言模型 Sec-PaLM 2 驱动，结合了谷歌独有的观测技术，能帮助开发者掌握不断变化的安全性威胁，并针对网络安全操作进行微调。</p><p></p><p>几周前，谷歌推出 Chronicle CyberShield，能解决数据孤岛的问题，也能集中管理安全性数据，并统一规划处理方式。</p><p></p><p>“我们正处于一个由人工智能推动的全新数字化转型时代，”Google Cloud 首席执行官库里安说，“这项技术已经在改善企业的运营方式以及人类之间的互动方式。它正在改变医生照顾病人的方式、人们沟通的方式，甚至我们在工作中的安全方式。而这仅仅是个开始。”</p><p></p><p>生成式 AI 通过 ChatGPT 类的工具产品，已经在艺术创作、代码生成等领域带来了未曾设想过的便利，随着基础设施的迭代演进，相信现阶段的开发范式变革，可能真的仅仅是个开始。</p><p></p><p></p><h2>结语</h2><p></p><p></p><p></p><p>生成式 AI 兴起之后，业界纷纷提出“想象力等于生产力”之类的观点，并借助一些场景的应用为佐证。谷歌这次的大会发布，无论是对生成式 AI 技术的推动，还是开发工具&amp;服务的迭代，都给了我们更多的信心与想象的方向。</p><p></p><p>无论是从 AI 最佳化的基础架构，到注入了生成式 AI 强大功能的数据分析和信息安全服务；还是从增加了更多新模型和工具的 Vertex AI 平台，到扩大了支持 Duet AI 的 Workspace 和 Google Cloud，这些技术都是难得的探索与尝试，这些演变或者变革都是迈向下一次重大演变的正确方向的垫脚石。</p><p></p><p>对于开发者这一最了解技术本质的人群而言，我们能做的就是拥抱变化与发展，与企业、社区、生态一起，持续探索与创新。在变革到来前，找到要去的方向；在变革到来后，找到自己的位置。</p><p></p><p>&nbsp;Tips：会后的配套学习资料，给你准备好了！</p><p></p><p>为了让中国的开发者们更好地 Get 新技术、新发展，Google Cloud 今年同样安排了会后的配套系列课程 —— 「Next ’23 中文精选课」。</p><p></p><p>今年的课程将聚焦 AI/ML、安全合规、数据库、数据分析、DevOps、应用程序开发等领域，解读最新技术发布与行业实践应用，解读 Next ’23 发布的 100 项创新成果 。</p><p></p><p>发布会中没来得及讲的、没讲完的，都在这次的课程中了👌</p><p></p><p>据官方的信息展示，这次的中文精选课不仅有技术干货，更给开发者提供了多种互动方式体验，以及一批 Google Cloud 官方周边礼品，旅行颈枕、无线鼠标、电竞游戏耳机、蓝牙音箱，甚至还有 Google 25 周年纪念版安卓小人！</p><p></p><p><a href=\"https://services.google.cn/fb/forms/0926next23/?channel=infoQ\">点击预约 9 月 26 日 Next '23 中文精选课</a>\"</p>",
    "publish_time": "2023-09-15 16:50:40",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "40 多名直接下属、从不 1 对 1 沟通，老黄如此管理下的英伟达能在 AI 芯片领域称霸多久？",
    "url": "https://www.infoq.cn/article/0PqgWtj6yy0bBhioY0vx",
    "summary": "<p>英伟达无疑是一家伟大的企业，几十年来一直以终为始、积极筹划，在AI技术革命当中发挥着核心作用。凭借精准的判断和预先布局，英伟达现已成为世界上最有价值的公司之一。但<a href=\"https://petewarden.com/2023/09/10/why-nvidias-ai-supremacy-is-only-temporary/\">HackNews上一篇热帖</a>\"认为，英伟达的AI霸主地位还只是暂时的，还远称不上稳固。</p><p></p><h1>英伟达在AI领域的霸主地位只是短暂的？</h1><p></p><p>这篇博文的作者<a href=\"https://petewarden.com/\">Pete Warden</a>\"阐述了英伟达目前所占据的优势：</p><p>&nbsp;</p><p>大型机器学习应用的普及度仍然不高。除了少数大型科技企业之外，很少有公司能在实际生产中运行大规模AI模型。他们的重点仍停留在学习新功能、试用新功能层面，所以主要成本集中在数据收集、硬件训练和模型开发等阶段。也就是说，机器学习技术的重点仍集中在训练、而非推理端；所有英伟达替代方案都很差劲。如果大家身为机器学习模型的构建或使用者，肯定会感觉到英伟达GPU用起来要比AMD OpenCL、谷歌TPU或者Cerebras系统等各类替代性硬件更轻松、也更省时。英伟达的软件栈更加成熟，提供丰富的示例、文档和其他资源，在劳动力市场上更容易找到经验丰富的英伟达开发工程师，而且跟各类主流框架的集成度也更高；研究人员决定购买力。目前，人才市场上的机器学习研究人才相当稀缺，正处于人挑岗位、而非岗位挑人的阶段。所以企业才特别需要“哄人才开心”，而研究人员的一项基本要求就是使用英伟达平台了，所以出于吸引和留存优秀人才的考虑，企业在购买硬件时也会充分尊重他们的技能和使用偏好；训练周期原则。根据经验，从头开始训练模型大概需要一周时间。这一点从AlexNet诞生之初就基本得到了证实，这是因为一旦迭代周期变得更长，研究人员将很难开展实证测试和原型设计，而这些都是保证模型成果能达成准确性目标的关键前提。而随着硬件性能越来越强，人们开始构建起规模更大的模型，直到整个训练周期再次拉长到一周左右。这就让人们有了不断购买新款英伟达GPU的动力，因为新的同平台产品能以更快的速度直接兼容大部分现有代码。虽然竞争对手理论上有机会以性能取胜，但他们的软件栈却很难在短时间内抗衡投资积累数十年的英伟达CUDA。</p><p></p><h2>一些事情正悄然发生变化</h2><p></p><p>看了以上内容，大家可能已经理解了英伟达为什么能在生成式AI时代叱咤风云。但<a href=\"https://petewarden.com/\">Pete Warden</a>\"表示，在未来几年中，一些事情正在悄然发生变化。</p><p>&nbsp;</p><p></p><h3>训练退位，推理将占据主导</h3><p></p><p>几年前，有人曾告诉我“训练成本将随着研究人员的数量而变化，推理成本则随着用户的数量而变化。”我从中得出这样的结论，即在未来的某个时刻&nbsp;，任何企业根据用户请求而运行模型所消耗的计算量，将超过其用于训练模型的计算量。哪怕单次训练运行成本要远远高于单次推理成本，面对全球各地的巨量潜在用户及其多种多样的应用需求，推理规模终归要超过训练总量。毕竟，研究人员的数量永远是有限的。</p><p>&nbsp;</p><p>从硬件层面来看，这意味着AI研究的重点将转向如何降低推理成本。不少机器学习研究人员一直将推理视为训练的一个子集，但这种判断其实有失偏颇。在推理过程中整合大量输入往往非常困难，因为整个过程实际是在延迟与吞吐量之间寻求最佳平衡，而延迟则直接决定着面向用户类应用的市场命运。小批量/单批次输入会极大改变工作负载形态，因此必须对应不同的优化思路。与此同时，权重等因素在推理过程中却基本保持不变，因此可以配合权重压缩或恒定折叠等预处理技术进行优化。</p><p></p><h3>CPU在推理方面同样具有竞争力</h3><p></p><p>前文列出的英伟达替代方案中并未涉及CPU，因为这种历史悠久的计算架构在训练方面仍然慢得可笑。各类主流桌面CPU（包括x86、Arm，也许很快还将包括RISC-V）的优势在于数十积累而来的工具链投资，他们因此拥有着比英伟达更成熟的开发工具和社区，而且每次算术运算的成本也要比GPU低得多。</p><p></p><h3>部署工程师说了算</h3><p></p><p>随着推理成本开始在模型生命周期中占主导地位，人们当然要想办法为其寻求成本优化空间。到这个阶段，研究人员将不再是话语权的主导者，他们的偏好将变得不那么重要，真正的重点在于简化生产和应用。而随着人们对AI相关技能的逐渐熟悉，未来几年将有更多模型训练人才进入劳动力市场。种种迹象表明，研究人员在企业中的主导权将有所萎缩，而部署团队的诉求将获得更高的优先级。</p><p></p><h3>应用成本原则</h3><p></p><p>随着推理在整个AI预算体系中占据主导，对硬件和工作负载的要求也将随之变化。研究人员更重视快速实验的能力，因为他们需要充分的灵活性来探索各种原型设计方向。但生产应用对于模型的变更则不那么频繁，而且一旦研究人员交付了能满足需求的成果，整个基本架构往往可以稳定运行多年。所以我们几乎必然会走向这样的新阶段：模型创作者使用专门的工具（例如用于数学算法的Matlab）搞开发，再将结果交付给部署工程师，由后者手动将结果转换成有助于实际应用的形式。就是说只要能保证模型架构基本不变，那么即使权重不断接受调整，漫长的AI应用周期都能显著放大成本节约的实际效果。</p><p>&nbsp;</p><p>英伟达在加速计算芯片市场上的霸主地位到底能持续多久我们无从得知，但回顾万亿市值英伟达的发展史就会发现，英伟达的成功并不只是上述提到的其在市场上的几点优势就可以概括的。</p><p></p><h2>CEO有40多个直接下属，老黄几乎参与公司全部运营</h2><p></p><p>作为公司创始人兼CEO，黄仁勋几乎参与了英伟达日常运营的各个方面。据一位直接了解情况的现任英伟达经理人称，这包括审查销售代表计划对相对较小的潜在客户说的话。</p><p>&nbsp;</p><p>该公司的组织结构图显示了黄的大部分报告，也反映了他的深度参与。这位人士表示，他的直接下属数量异常多，大约有 40 名，该阵容包括为游戏 PC 和数据中心服务器设计 Nvidia GPU 的高级硬件工程师，以及监督 CUDA 编程语言等软件产品开发的工程师。这远远超过了科技行业及其他行业绝大多数CEO的水平。</p><p>&nbsp;</p><p>黄仁勋一直以来都赞成扁平化的组织结构。与竞争对手英特尔和 AMD 不同，英伟达没有中央产品管理团队。一位前英伟达经理表示，黄仁勋采取的是亲力亲为的方式，挑选他想要帮助开发的产品，并为它们“充当伪产品经理”。</p><p>&nbsp;</p><p>黄仁勋曾在某次采访中称：“如果想要一个服从命令和控制的组织，那么你就把它做成一个金字塔，就像罗马帝国时期的旧军队一样。但如果你想赋予人们权利，就要尽可能地让它变得平坦，这样信息传播得更快。有很多人向我汇报工作，我不需要一对一进行指导。他们都非常快乐，他们知道自己在做什么，且都是各自领域的专家，所以那些一对一的交流真的没有必要。”</p><p>&nbsp;</p><p>此外，英伟达内部员工还提到，黄仁勋不主张员工报告工作状态，他会“随机对系统进行抽样” ，因为他认为当某项产品或者技术到达他手中时，它们已经足够完美了。公司中的任何人都可以通过电子邮件向他发送“最重要的五件事”，黄仁勋也都会阅读。</p><p>&nbsp;</p><p>英伟达现任经理表示，黄仁勋对其他科技公司的内部斗争十分不屑。这位人士表示，英伟达全球共有员工26000余人，让大量员工向少数高级管理人员汇报就容易造成信息闭塞。</p><p>&nbsp;</p><p>黄仁勋也不会只与副总裁或董事举行会议，公司中任何人都可以加入并做出贡献。黄仁勋曾表示：“如果有什么我不喜欢的事情，我只是公开说出来，我还花了很多时间对我的决定进行推理和解释，这赋予了员工权力，让他们了解领导是如何思考并作出这个决定的”。</p><p>&nbsp;</p><p>不管多么不寻常，英伟达的管理结构似乎正在发挥作用。今年 5 月，受投资者对其在人工智能领域核心地位的热情鼓舞，英伟达加入了苹果、微软、Alphabet 和亚马逊的行列，成为唯一一家估值超过 1 万亿美元的美国公司。</p><p></p><h2>要么为了食物而奔跑，要么远离成为食物</h2><p></p><p>&nbsp;</p><p>黄仁勋曾在公开场合中讲述了英伟达的三个故事，包括英伟达如何从痛苦的失败中幸存下来，以及如何通过战略撤退，获得先发优势，在人工智能（AI）时代取得成功。</p><p>&nbsp;</p><p>他强调，我们仍处于人工智能革命的起跑线上，并预测未来十年内，随着世界以新型加速人工智能计算机取代传统计算机，该行业将面临价值超过万亿美元的黄金机遇。</p><p>&nbsp;</p><p>黄仁勋称，最初创立英伟达是为了创造加速处理芯片。英伟达的第一个应用程序是用于 PC 游戏的 3D 图形。彼时，英伟达发明了一种非常规的 3D 方法，称为前向纹理映射和曲线。这一方法能够大大降低了3D 图形在游戏中的运行成本，也为英伟达赢得了世嘉的合同。此后，凭借这项技术，英伟达吸引了更多游戏厂商并得到了大量的资金支持。</p><p>&nbsp;</p><p>但经过一年的开发，英伟达意识到这款处理器架构是错误的策略。当时技术很差，微软即将发布基于逆纹理映射和三角形的 Windows 95 3D。许多公司已经在开发 3D 芯片来支持该标准。如果英伟达正在研发的这款芯片应用到世嘉的游戏机上，那它与Windows不兼容，而且会远远落后。但如果不完成合同，前期投入全都打了水漂，没钱入账就会破产。不管怎样，英伟达似乎只有死路一条。</p><p>&nbsp;</p><p>危机之际，黄仁勋联系了世嘉的首席执行官入尻正一郎，并解释说了该项技术是错误的，世嘉应该寻找另一个合作伙伴，英伟达不得不终止合同。但英伟达需要付给世嘉违约金，以英伟达当时的情况没有了这笔生意再付出高额的违约金就相当于直接宣布破产。</p><p>&nbsp;</p><p>最后黄仁勋说动了入尻正一郎，世嘉的理解和慷慨让英伟达又活了六个月。</p><p>&nbsp;</p><p>就这样，英伟达在资金即将耗尽时建造了 Riva 128。Riva 128 震惊了年轻的 3D 市场，让英伟达名声大噪，并拯救了公司。</p><p>&nbsp;</p><p></p><h3>CUDA的传奇</h3><p></p><p>2007年，英伟达宣布了CUDA GPU加速计算。英伟达的愿望是让 CUDA 成为一种编程模型，促进从科学计算到物理模拟和图像处理的应用。创建新的计算模型非常困难，而且历史上很少有人这样做。自 IBM System 360 诞生以来，CPU 计算模型已成为标准 60 年。CUDA 需要开发人员编写应用程序并展示 GPU 的优势。开发人员需要庞大的安装基础，而庞大的 CUDA 安装基础需要客户购买新应用程序。因此，为了解决“先有鸡还是先有蛋”的问题，英伟达使用了 GeForce GPU来建立安装基础，该 GPU 已经拥有庞大的游戏玩家市场。</p><p>&nbsp;</p><p>但CUDA的附加成本非常高。英伟达的利润受到了巨大打击。多年来，英伟达的市值一直徘徊在略低于或略高于 10 亿美元的水平。英伟达在此期间挣扎良久。在AI时代来临之前，股东对 CUDA 也持怀疑态度，并希望他们专注于提高盈利能力。但在黄仁勋坚信加速计算的时代终将会到来。于是英伟达创建了一个名为 GTC 的会议，并在全球范围内孜孜不倦地推广 CUDA。</p><p>&nbsp;</p><p>然后，应用程序出现了：地震处理、CT 重建、分子动力学、粒子物理、流体动力学和图像处理。一个又一个科学领域，他们都向加速计算走来了。英伟达与每位开发人员合作编写他们的算法并实现了令人难以置信的加速。在 2012 年，人工智能研究人员发现了 CUDA。著名的 AlexNet就是在 GeForce GTX 580 上进行训练的，这也让CUDA，自此开启了人工智能大爆炸的序章。</p><p>&nbsp;</p><p>老黄称，幸运的是，他们很早就意识到深度学习作为一种全新软件方法的潜力，并调动公司的各个方面来推进这个新领域，他们冒着一切风险去追求深度学习。十年后，人工智能革命开始了。英伟达顺势也成为了全球人工智能开发者的引擎。因为他们发明了 CUDA，并开创了加速计算和人工智能。这段旅程也塑造了英伟达的企业调性——能够承受实现愿景需付出的所有痛苦和磨难。</p><p>&nbsp;</p><p></p><h3>在移动芯片市场中以退为进</h3><p></p><p>老黄称，在英伟达的发展史中，还有一段历程值得铭记。</p><p>&nbsp;</p><p>2010年，谷歌的目标是将Android开发成一款具有出色图形功能的移动电脑。手机行业拥有拥有调制解调器专业知识的芯片公司，而 英伟达的计算和图形专业知识使英伟达成为帮助构建 Android 的理想合作伙伴。于是他们进入了移动芯片市场。</p><p>&nbsp;</p><p>随后，英伟达在移动芯片市场取得了巨大的成功，公司业务和股价飙升，竞争很快就蜂拥而至。调制解调器芯片制造商正在学习如何构建计算机芯片，而英伟达正在学习如何构建调制解调器，因为手机市场是巨大的，英伟达不得不为市场份额而战。</p><p>&nbsp;</p><p>但没多久，英伟达做出了一个艰难的决定——放弃移动芯片市场。</p><p>&nbsp;</p><p>据黄仁勋称，英伟达的使命是制造能够解决普通计算机无法解决的问题的计算机，公司应该致力于实现我们的愿景并做出独特的贡献。</p><p>&nbsp;</p><p>很快，英伟达退出移动芯片市场的战略得到了回报。离开手机市场后，英伟达打开了新思路——发明了一款新手机，他们设想为机器人计算机创建一种新型计算机，配备神经网络处理器和运行人工智能算法的安全架构。</p><p>&nbsp;</p><p>就这样，英伟达进入了机器人市场。</p><p>&nbsp;</p><p>现在，英伟达已经拥有数十亿美元的汽车和机器人业务，并开始了一个新的行业。黄仁勋表示：</p><p></p><p></p><blockquote>“对于很多成功的人和成功的公司来说，撤退并不容易。然而，战略性撤退和牺牲，决定好放弃什么，才是成功的核心”。</blockquote><p></p><p>&nbsp;</p><p>参考链接：</p><p>&nbsp;</p><p><a href=\"https://twitter.com/danhockenmaier/status/1701608618087571787\">https://twitter.com/danhockenmaier/status/1701608618087571787</a>\"</p><p><a href=\"https://semiwiki.com/forum/index.php?threads/ceo-jensen-huang-runs-nvidia-with-a-strong-hand.18499/\">https://</a>\"<a href=\"https://semiwiki.com/forum/index.php?threads/ceo-jensen-huang-runs-nvidia-with-a-strong-hand.18499/\">semi</a>\"<a href=\"https://semiwiki.com/forum/index.php?threads/ceo-jensen-huang-runs-nvidia-with-a-strong-hand.18499/\">wi</a>\"<a href=\"https://semiwiki.com/forum/index.php?threads/ceo-jensen-huang-runs-nvidia-with-a-strong-hand.18499/\">ki.com/</a>\"<a href=\"https://semiwiki.com/forum/index.php?threads/ceo-jensen-huang-runs-nvidia-with-a-strong-hand.18499/\">for</a>\"<a href=\"https://semiwiki.com/forum/index.php?threads/ceo-jensen-huang-runs-nvidia-with-a-strong-hand.18499/\">u</a>\"<a href=\"https://semiwiki.com/forum/index.php?threads/ceo-jensen-huang-runs-nvidia-with-a-strong-hand.18499/\">m</a>\"<a href=\"https://semiwiki.com/forum/index.php?threads/ceo-jensen-huang-runs-nvidia-with-a-strong-hand.18499/\">/</a>\"<a href=\"https://semiwiki.com/forum/index.php?threads/ceo-jensen-huang-runs-nvidia-with-a-strong-hand.18499/\">in</a>\"<a href=\"https://semiwiki.com/forum/index.php?threads/ceo-jensen-huang-runs-nvidia-with-a-strong-hand.18499/\">dex</a>\"<a href=\"https://semiwiki.com/forum/index.php?threads/ceo-jensen-huang-runs-nvidia-with-a-strong-hand.18499/\">.</a>\"<a href=\"https://semiwiki.com/forum/index.php?threads/ceo-jensen-huang-runs-nvidia-with-a-strong-hand.18499/\">php?th</a>\"<a href=\"https://semiwiki.com/forum/index.php?threads/ceo-jensen-huang-runs-nvidia-with-a-strong-hand.18499/\">re</a>\"<a href=\"https://semiwiki.com/forum/index.php?threads/ceo-jensen-huang-runs-nvidia-with-a-strong-hand.18499/\">ad</a>\"<a href=\"https://semiwiki.com/forum/index.php?threads/ceo-jensen-huang-runs-nvidia-with-a-strong-hand.18499/\">s/ceo-jensen-huang-runs-nvidia-with-a-strong-hand</a>\"<a href=\"https://semiwiki.com/forum/index.php?threads/ceo-jensen-huang-runs-nvidia-with-a-strong-hand.18499/\">.18499/</a>\"</p><p><a href=\"https://petewarden.com/2023/09/10/why-nvidias-ai-supremacy-is-only-temporary/\">https://petewarden.com/2023/09/10/why-nvidias-ai-supremacy-is-only-temporary/</a>\"</p>",
    "publish_time": "2023-09-15 17:00:47",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "中邮消费金融李远鑫：如何用数字化搞定获客成本和用户运营难题？",
    "url": "https://www.infoq.cn/article/fE084eOJxKOxJyD1Z7kB",
    "summary": "<p>消费金融业务与传统银行业务相比，存在诸多差异化。比如，其产品基于线上场景运营，天然与数字化技术息息相关，并且，由于客群覆盖面更广、风险容忍度更高，反欺诈和风险控制的难度更大。因此，消费金融公司的整体数字化进程比其它金融机构要快得多。</p><p></p><p>利用 OCR、人脸识别、机器学习等技术建立智能风控体系，运用 AI 技术优化营销运营，通过数据中台驱动业务和决策，提升整体运营效能——这些几乎是消费金融企业的“常规动作”。在 9 月 12 日的 InfoQ《超级连麦·数智大脑》直播中，InfoQ 与中邮消费金融市场部、数字化转型办公室 / 部门负责人、办公室主任<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1575\">李远鑫</a>\"深入探讨了消费金融的数字化体系是如何构建的。</p><p></p><p>李远鑫表示，在消费金融行业中，获客成本和用户运营常常是棘手的问题。对此，中邮消费金融通过数字化手段成功解决了这些挑战。首先，公司致力于提高产品的核心竞争力，包括优化用户体验和流程设计，通过精确的目标客户画像和科学的运营手段，公司不仅提高了转化率，还成功降低了单个客户的获客成本。</p><p></p><p>并且，不同于多数消费金融公司主要依赖头部互联网平台进行获客，中邮消费金融建立了一套完善的智能营销运营体系。这一体系基于数据中台，涵盖了数据的采集、存储、计算和管理，进一步支持了营销运营。</p><p></p><p>以下是对话全文（经 InfoQ 进行不改变原意的编辑整理）：</p><p></p><h5>InfoQ：顾名思义，消费金融直接面向消费者提供金融服务。那么，它与其它金融业务相比，会有哪些差异化特点？请您介绍下目前消费金融行业的数字化现状？</h5><p></p><p></p><p>李远鑫：消费金融业务其实就是银行消费信贷业务的延伸，广义的消费金融业务包含了银行的房贷、车贷、消费贷、信用卡等业务，而我们今天所谈论的消费金融业务，指的是银行消费信贷业务以外的狭义消费金融业务，它与传统的信贷业务存在多方面的差异：</p><p></p><p>在产品方面，具备线上化便捷申请、纯信用无抵押、小额分散、基于大数据快速审批和放款、运用大量的数字化技术实现个性化、智能化的用户体验和营销运营等特点；</p><p></p><p>在客群选择方面，消费金融业务与银行业务相比，其风险容忍度更高，可以覆盖更广的客群，客群比传统银行信贷业务面向的客群要下沉；</p><p></p><p>在风险方面，由于大部分业务均为线上化无接触的方式开展，欺诈风险和信用风险比传统信贷业务要高，反欺诈和风险控制的难度更大。</p><p></p><p>消费金融公司因业务依赖互联网和移动设备，通常比传统银行更快地实现数字化。但单纯的线上化和产品同质化还不足以形成核心竞争力。因此，多数消费金融公司已加速数字化转型，利用 OCR、人脸识别、机器学习等技术建立<a href=\"https://www.infoq.cn/article/tXdg1xI1YWGYG6iGg4rj\">智能风控</a>\"体系，运用 AI 技术如深度学习和自然语言处理优化营销运营，以及通过数据中台驱动业务和决策，提升整体运营效能。</p><p></p><h5>InfoQ：根据您的观察和经验，现阶段整个金融行业进行数字化转型的普遍难题有哪些？</h5><p></p><p></p><p>李远鑫：我认为金融行业数字化转型的普遍难题主要有以下几个层面：</p><p></p><p>没有与企业的战略和发展目标挂钩，转型的目标不清晰不明确，在企业内部没有达成共识，转型工作难以启动或者启动后遇到较大的阻力难以往下推进。对此，企业应该明确，数字化转型的目的就是为了赋能企业战略和发展目标的达成，要对企业战略进行解码，运用数字化这种新的生产方式重塑或优化现有的业务模式，以业务发展目标和指标作为数字化转型的最终目标，与公司高层、业务部门的目标对齐，上下达成一致。</p><p></p><p>盲目跟风，路径和节奏不清晰，数字化战略高度同质化，追赶业界“时髦”趋势而未充分结合自身业务基础，数字化转型节奏与业务发展需求脱节，导致资源盲目投入与重复建设。对此，企业需要制定出符合自身业务目标的数字化规划蓝图。</p><p></p><p>只有“数字化”，没有“转型”，数字化转型仍然是传统 IT 转型，转型方向以优化工具效率、优化系统架构、引入新工具进行科技应用为主要目的。对此，企业应该进行由业务战略驱动、与业务有机结合的数字化转型。建议以增长作为切入口和抓手开展数字化，因为增长可以带来快速反馈，及时反哺企业业绩，既可以帮助企业坚定信心，又能够平息内部反对意见。</p><p></p><p>从业务构想到数字化实现的传导走形，由于在能力角色、流程机制、交付标准等方面存在缺失，客户需求在转化为数字化产品的过程中层层失真，最后的产出与实际需求相悖。对此，企业可以进行端到端进行客户旅程和业务流程的分析和优化改造，建立企业级架构，特别是业务架构，统一技术和业务的语言，形成结构化的蓝图，指导应用架构、信息架构和技术架构的设计和 IT 系统落地实施。</p><p></p><p>组织支撑体系不匹配，治理水平成为瓶颈。存在组织壁垒、部门孤岛、复杂冗长的审批流程、自驱型专业人才缺失和科技基础设施不足等软基因问题，大大阻碍数字化转型进程。对此，企业应该建立数字化转型意识及共识，组织文化层面需要配套，从顶层出发驱动数字化转型，增强全公司参与感。</p><p></p><h5>InfoQ：在战略指定和规划落地过程中，怎么平衡数字化转型的长短期目标，以及投入产出的问题？</h5><p></p><p></p><p>李远鑫：根据我们的经验，在进行数字化转型时，长期和短期目标需要同时考虑并平衡。这并不意味着我们要等到整个长期规划完成后才开始实施。实际上，在制定数字化转型的规划蓝图过程中，我们会同时启动一些短期的“速赢”项目。这些项目有双重目的：首先，它们用于验证我们设计的业务架构是否合理和可行；其次，这些成功的小项目能够增加业务部门和公司领导层对整个转型过程的信心。</p><p></p><p>例如，通过一些以增长为目标的速赢项目，我们可能会设计全新的业务模式或优化现有模式。一旦这些改动带来效率提升或客户体验的增强，就能促进公司规模或利润的增长。这样的成功案例能有效证明我们的业务架构设计是可行的，并有助于平衡长期与短期的目标。</p><p></p><p>在规划阶段，不必一开始就做到极其详细和全面。例如，当我们分解业务架构时，不一定需要深入到非常细致的流程和角色层面。在初步阶段，我们可以先集中在主要的业务流程上，识别其中的数字化机会，并通过这些项目进行验证和迭代。总体而言，这能够有效解决长期和短期目标之间的平衡问题。</p><p></p><h5>InfoQ：要应对金融业转型创新的挑战，哪些工作是必不可少的？哪些技术又会发挥重要的作用？</h5><p></p><p></p><p>李远鑫：要有清晰的转型战略和明确、可落地的转型规划，与业务转型一体两面推进；</p><p></p><p>要以数字化的思维、以用户为中心的视角重新梳理业务模式和流程，提升客户体验和运营效率；</p><p></p><p>要建立结构化的企业架构，特别是业务架构，形成业务和技术融合的标准化语言，从业务架构、应用架构落地到业务中台的实施；</p><p></p><p>要夯实数据底座的建设，在数据采集、存储、管理、计算、应用等方面全面提效，支撑企业数据驱动、智能决策的需求；</p><p></p><p>要紧跟新技术发展的趋势和应用场景，对于金融行业而言，要特别关注隐私计算技术，因为金融行业普遍都依赖大量的内外部数据进行营销获客和风险防控，解决信息不对称的问题。但受个人信息安全保护的限制，目前能合规利用的数据非常少，如果能够通过隐私计算实现行业数据的合规共享，金融行业的转型将迈上一个新的台阶。</p><p></p><h5>InfoQ：获客成本快速攀升、用户运营困难是消费金融行业的一大痛点，如何用数字化手段解决这一问题？</h5><p></p><p></p><p>李远鑫：降低获客成本要做到三个方面的事情：</p><p></p><p>一是要提高产品的核心竞争力，包括良好的用户体验、便捷的流程设计、匹配客户需求的产品要素；二是要有清晰的目标客户画像，无论是做广告投放还是通过平台引流获客，都要结合自身的客户画像和流量方的画像进行投放，做到精准获客；三是要通过科学有效的运营手段提升转化率和复购率，降低单个客户的获客成本。</p><p></p><p>关于用数字化手段来解决问题方面，我认为首先是要运用设计思维，通过用户旅程地图分析工具端到端地分析产品流程，以用户同理心来分析每一个节点的优化点，以发现其中的数字化机会点。通过分析，绝大部分产品流程可以提高效率、缩短受理时间、提升客户体验；</p><p></p><p>其次是构建清晰的客户画像，一方面依赖于自身对客户数据的清洗和识别，通过一些模型来提炼出关键的特征，另一方面要与合作方开展数据合作或联合建模，可以采取前置联合建模、联邦学习、蒸馏模型等方式实现，从获客端就按照客户画像的需求进行筛选；</p><p></p><p>最后是提升转化率和复购率方面，要建立全生命周期的用户运营矩阵、智能营销运营的决策引擎以及整套 AB 测试、营销活动效果监测体系等。</p><p></p><h5>InfoQ：多数消费金融公司都倾向于依赖头部外部互联网平台进行获客，中邮消费金融则建立了一套智能营销运营服务体系，背后的驱动力和能力基础分别是什么？</h5><p></p><p></p><p>李远鑫：目前多数消费金融公司都通过头部互联网平台获客，中邮消费一直致力于加强自主获客能力，不断做大自营贷款规模，积累更多可运营客户的数量，通过智能营销运营体系持续运营存量客户，不断刺激客户复贷、增加粘性，发挥最大的价值，这就是背后的驱动力。</p><p></p><p>要做到持续运营存量客户，能力基础主要有几个方面：</p><p></p><p>一是拉新的能力，没有新用户，存量客户运营就是一句空话，因此获客渠道的建设非常重要，包括自营 APP、广告投放、线下渠道、可运营的三方渠道等，需要有一个灵活、可靠、能快速对接的渠道及服务开放平台，实现高效获客；二是数据底座的能力，需要对存量客户的特征进行提炼，形成可筛选的客群标签，为运营打好基础；三是全生命周期客户运营的体系，能够持续筛选不同的客群、不同的生命周期定制不同的触达渠道、触达策略和营销活动，并实现实时的跟踪、监测、AB 测试等，形成营销闭环；四是多样化、有效、畅通的触达渠道，包括 APP、短信、电话营销号码资源、线路等，确保有效触达客户；五是对客户数据的不断挖掘，通过提额、降息等风险经营的工具，越来越精准地匹配客户对消费金融产品的需求，持续提升客户粘性和复贷次数。</p><p></p><h5>InfoQ：据了解，中邮消费金融智能营销运营服务体系是在数据中台基础上进行搭建的。它是如何运作和发挥作用的？</h5><p></p><p></p><p>李远鑫：<a href=\"https://www.infoq.cn/article/SEJ62iIqiEpPfW0pRm7f\">数据中台</a>\"的本质是解决数据采、存、算、用、管 5 个方面的问题，最终的目的是“用”，营销运营是其中的一项非常重要的应用场景，要能够达到“智能”的效果，必须要解决其他的四个问题，即“采、存、算、管”。</p><p></p><p>在采集方面，要实现对数据的高效、灵活、全域的采集和交换，这项能力是数据中台的基础，传统的数仓数据采集时效低，而 Flink+Kafka 的实时采集的链路代价大，我们在离线和实时链路的基础上，通过 FlinkCDC 搭建了准实时场景采集链路，提供分钟级的数据，比传统数仓有更高的时效性，解决纯实时成本过高，纯离线时效太差的问题。</p><p></p><p>在数据存储方面，需要对多类型、大容量数据提供存储支持和全领域数据的集成能力，我们集成了 Iceberg 数据湖组件，通过数据湖提供的 Upsert 功能，建立准实时数据加工链路，解决 Flink 实时开发成本过高，实时加工效率低、不支持 Upsert 的问题。</p><p></p><p>在计算方面，对实现对海量数据的计算以及资源的灵活配置，提供高效的批处理和实时交互能力，我们通过 Spark、Impala 和 Presto 等多模引擎，打通数据湖和数据仓库，实现湖仓数据的融合查询能力。</p><p></p><p>在管理方面，通过数据治理管理数据质量、数据标准、元数据，并强化对数据架构的管控，规范数据中台的设计开发过程，保障数据质量。</p><p></p><p>基于这些基础能力建设，我们打造了一个扎实的数据底座，在数据底座之上，我们构建了“贴源层 - 整合层 - 语义层 - 数据集市层 - 数据应用层”五个层次的数据架构，并通过 OneService API 的方式向应用提供数据服务接口，支撑营销运营等应用场景的用数需求。</p><p></p><h5>InfoQ：实现精细化营销和运营，一方面要确保数据质量和数据量的真实可靠；另一方面还要注重数据安全、用户隐私保护等问题。您认为这两方面的需求如何平衡？</h5><p></p><p></p><p>李远鑫：为了更好地服务客户，金融机构需要进行精细化营销和运营。这包括发掘和建立更多有效的客户接触点，利用创新技术和工具，以数字化和智能化的方式提供高效的业务交易，从而改善客户体验。在运营过程中，公司需要强化客户相关数据的生成、收集和应用，以深入了解客户，从而提供更个性化的产品和服务。</p><p></p><p>然而，在过去几年里，大数据技术的快速发展使客户洞察和数据挖掘变得更加丰富，但行业里也发生了一些数据泄露事件，以及对个人隐私安全的担忧。因此，金融机构必须在追求竞争优势的同时，确保以下几方面：</p><p></p><p>合规性和合规</p><p>确保数据收集和处理活动遵守当地和国际的数据隐私法规，例如欧洲的 GDPR 或美国的 CCPA。遵守法律要求，包括数据保留期限和用户访问权等。</p><p></p><p>透明度和最小数据原则</p><p>提供清晰、透明的隐私政策，明确数据收集和使用的目的。最小化数据收集，只保留与业务目标相关的最少数据，并确保数据使用符合用户的期望和授权。</p><p></p><p>安全措施和风险评估</p><p>实施强化的数据安全措施，包括加密、访问控制和漏洞修复，以保护数据免受未经授权的访问或泄露。定期进行安全审计和漏洞扫描，确保系统的安全性。进行定期的风险评估，以识别潜在的数据隐私和安全风险，并采取相应措施来降低风险。</p><p></p><p>综合考虑这些因素，建立一个健全的数据管理和隐私保护框架，有助于在精细化营销和运营中平衡数据质量、数据安全和用户隐私保护的需求，同时维护良好的用户关系和法规合规性。此外，随着隐私计算技术的不断发展，我们将能够找到新的方法来实现数据的安全共享，从而更好地平衡数据使用和隐私保护。</p><p></p><h5>InfoQ：您觉得比较理想的金融科技大会是什么样子？</h5><p></p><p></p><p>李远鑫：实际上，这是我第一次参加以金融科技为主题的正式峰会。在我看来，金融科技虽然包括“科技”二字，但其核心依然是“金融”。<a href=\"https://www.infoq.cn/theme/213\">金融</a>\"是一个非常广泛的领域，不仅包括银行和消费金融公司，还涵盖了如保险和证券等多个方面。其中，我认为最重要的关注点是风险管理，这也应是峰会上讨论的重要议题。科技在金融行业中的作用也不容忽视。科技和数字化都在赋能金融机构进行业务转型和模式升级。如何将科技与金融有效地结合起来，我觉得这是另一个重要的议题。</p><p></p><p>除此之外，金融行业当前面临多种问题，包括客户获取越来越困难、客户运营复杂、以及产品同质化严重等。这些问题需要我们用科技的手段去解决，并且应以问题为导向；在提升金融行业工作效率方面，我认为这也是一个关键的议题。关于峰会的形式，我觉得它应该是一个开放和互动的平台。</p><p></p><p>因为金融行业内部的交流通常并不频繁，借助这次峰会，我们可以创建一个同行业间交流的平台，无论是技术人员还是业务人员。具体到峰会的形式，除了演讲之外，还可以有闭门会议、圆桌论坛，甚至是专题晚宴等，以便在更为轻松的氛围下进行交流。</p><p></p><h5>InfoQ：作为 FCon 大会《金融领域数字化转型挑战探索》专题出品人，这个专题将解决业界的哪些问题和困惑？</h5><p></p><p></p><p>李远鑫：关于数字化转型专题，核心问题是：数字化转型的最终目标是什么？</p><p></p><p>根据我的个人经验和感受，我认为其最终目的是推动业务转型，并实现企业战略。因此，数字化转型与业务转型应该是同步进行的，不可割裂。遗憾的是，很多企业在进行数字化转型时容易忽视这一点，导致转型难以落地。这也是金融机构数字化转型面临的主要痛点。为了解决这个问题，我们特地邀请了多位专家和金融研究院的院长，以及不同类型的金融机构代表，来分享他们的经验和看法。</p><p></p><p>内容方面，我们将从宏观和微观进行设计，主要以实践分享为主。宏观方面将探讨数字化转型的基础理念和方法，如何与顶层企业战略相承接，以及如何将这些战略通过架构思维落实到 IT 实施中。微观方面，我们将探讨各金融机构在转型过程中如何建设业务中台、数据中台和 AI 中台，以解决金融机构的各种痛点。特别是风险控制，这是金融机构最关心的一个话题。我们将深入探讨如何通过数字化手段实现有效的风险防控，尤其是在线上金融产品日益增多的情况下。</p><p></p><p>总体来说，这个专题旨在全面解决金融机构在数字化转型过程中遇到的难题，提供一种全面和深入的解决方案。</p><p></p><h4>关于 FCon</h4><p></p><p></p><p>首届<a href=\"https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">FCon全球金融科技大会</a>\"将于 11 月 19-20 日在上海举办。大会将围绕金融领域数字化转型挑战探索、DevOps 在金融企业落地实践、金融行业大模型应用、创新的金融科技应用、金融实时数据平台建设之路、金融安全风险管控、数据要素流通与数据合规等 10+专题进行交流。</p><p></p><p>目前大会邀请了汇丰科技中国区的代理总经理马国栋、度小满金融数据智能部总经理杨青先、蚂蚁集团副总裁 &amp; 首席技术安全官韦韬博士、恒生聚源总经理吴震操担任大会联席主席。更多嘉宾仍在邀请中......</p><p></p><p>我们诚挚地邀请您加入我们，共同探索金融科技的未来，<a href=\"https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">点击链接</a>\"即可查看全部演讲专题。</p><p></p><p>目前 <a href=\"https://fcon.infoq.cn/2023/shanghai/apply?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">5 折 优惠购票</a>\"，仅限前 100 人，咨询购票可联系：17310043226（微信同手机号）。</p>",
    "publish_time": "2023-09-15 17:56:14",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]