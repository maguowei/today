[
  {
    "title": "Java 19新特性一览",
    "url": "https://www.infoq.cn/article/Zf6wLOe3l8elAjPlKiVz",
    "summary": "<p>Oracle<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2022-September/006933.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjQyNDcwMjcsImZpbGVHVUlEIjoia1ZJNXdhVUZMOTQ0Mk1pSCIsImlhdCI6MTY2NDI0NjcyNywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.6nEXDfklFT9wb-xCOB1PKgeV_pQVkXD20uU5xKolE3M\">发布</a>\"了Java 19及虚拟机。这个最终的特性集中包含了如下7个JEP。</p><p></p><p>JEP 405：记录模式（预览）；JEP 422：Linux/RISC-V移植；JEP 424：外部函数和内存API（预览）；JEP 425：虚拟线程（预览）；JEP 426：Vector API（第四轮孵化器）；JEP 427：switch的模式匹配（第三次预览）；JEP 428：结构化并发（孵化器）。</p><p></p><p>Java 19的新特性发布节奏与JDK 18的9个新特性差不多，但少于JDK 17的14个新特性、JDK16的17个新特性、JDK 15的14个新特性和JDK 14的16个新特性。</p><p></p><p>这个版本包含了来自Amber、Loom和Panama项目的JEP，以及将JDK移植到Linux/RISC-V指令集的新特性。我们在这里介绍其中的一些新特性。值得注意的是，在JDK 19中没有代表Valhalla项目的JEP。</p><p></p><h2>Panama项目</h2><p></p><p></p><p>JEP 424和JEP 426属于Panama项目，这个项目旨在改进和丰富JVM与“外来”（即非java）API之间的互操作性，这些API极有可能包含C语言库中常用的接口。</p><p></p><p>JEP 424，即外部函数和内存API（预览），为Java应用程序引入一个API，通过高效调用外部函数和安全访问不受JVM管理的外部内存来实现与Java运行时之外的代码和数据的互操作。这个JEP演化自JEP 419（即外部函数和内存API（第二轮孵化器），在JDK 18中交付）和JEP 412（即外部函数和内存API（孵化器），在JDK 17中交付），并针对Java社区的反馈进行了增强。</p><p></p><p>JEP 426，即Vector API（第四轮孵化器），根据前三轮孵化的反馈进行了改进——JEP 417（即Vector API（第三轮孵化器），在JDK 18中交付）、JEP 414（即Vector API（第二轮孵化器），在JDK 17中交付），以及JEP 338（即Vector API（孵化器），在JDK 16中作为孵化器模块交付）。JEP 426提议对Vector API进行增强，从MemorySegment（JEP 424，即外部函数和内存API（预览））加载或存储Vector。</p><p></p><p>关于如何实现外部函数和内存API的示例应用程序，可以在这个<a href=\"https://github.com/carldea/panama4newbies?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjQyNDcwMjcsImZpbGVHVUlEIjoia1ZJNXdhVUZMOTQ0Mk1pSCIsImlhdCI6MTY2NDI0NjcyNywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.6nEXDfklFT9wb-xCOB1PKgeV_pQVkXD20uU5xKolE3M\">GitHub代码库</a>\"中找到，由Azul的高级开发布道师Carl Dea提供。</p><p></p><h2>Loom项目</h2><p></p><p></p><p>JEP 425和JEP 428属于Loom项目，这个项目旨在探索、孵化和交付Java VM特性和API，其目的是支持易于使用、高吞吐量的轻量级并发和新的编程模型，可以通过虚拟线程、定界续体（Delimited Continuation）和尾部调用来实现。</p><p></p><p>JEP 425，即虚拟线程（预览），向Java平台引入了虚拟线程。这是一种轻量级线程，极大地减少了编写、维护和观察高吞吐量并发应用程序的工作量。</p><p></p><p>JEP 428，即结构化并发（孵化器），提议通过引入一个新的库来简化多线程编程，这个库将运行在不同线程中的多个任务视为单个工作单元。这可以简化错误处理和取消操作，提高可靠性，并增强可观察性。</p><p></p><p>关于如何实现虚拟线程和结构化并发API的示例应用程序可以在这些代码库中找到：由Oracle的Java开发布道师Nicolai Parlog提供的<a href=\"https://github.com/nipafx/loom-lab?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjQyNDcwMjcsImZpbGVHVUlEIjoia1ZJNXdhVUZMOTQ0Mk1pSCIsImlhdCI6MTY2NDI0NjcyNywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.6nEXDfklFT9wb-xCOB1PKgeV_pQVkXD20uU5xKolE3M\">GitHub代码库</a>\"和由Contrast Security公司高级软件工程师Bazlur Rahman提供的<a href=\"https://github.com/rokon12/project-loom-slides-and-demo-code?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjQyNDcwMjcsImZpbGVHVUlEIjoia1ZJNXdhVUZMOTQ0Mk1pSCIsImlhdCI6MTY2NDI0NjcyNywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.6nEXDfklFT9wb-xCOB1PKgeV_pQVkXD20uU5xKolE3M\">GitHub代码库</a>\"。</p><p></p><h2>Amber项目</h2><p></p><p></p><p>JEP 405和JEP 427属于Amber项目，这个项目旨在探索和培养较小的用于提升生产力的Java语言特性。</p><p></p><p>JEP 405，即记录模式（预览），提议用记录模式来解构记录值。记录模式可以与类型模式一起使用，“支持强大的、声明式的和可组合的数据浏览和处理形式”。类型模式最近已通过JEP 406（即switch的模式匹配（预览），在JDK 17中交付）和JEP 420（即switch的模式匹配（第二次预览），在JDK 18中交付）被用在switch的case子句中。</p><p></p><p>JEP 427，即switch的模式匹配（第三次预览），针对前两轮预览反馈进行了增强——JEP 406（即switch的模式匹配（预览），在JDK 17中交付）和JEP 420（即switch的模式匹配（第二次预览），在JDK 18中交付）。JEP 420以来的变更包括——保护模式被替换为switch块中的when子句；当选择器表达式的值为空时，模式switch的运行时语义与遗留switch的语义更为接近。</p><p></p><p>关于如何实现switch的记录模式和模式匹配的示例应用程序可以在这个<a href=\"https://github.com/wesleyegberto/java-new-features?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjQyNDcwMjcsImZpbGVHVUlEIjoia1ZJNXdhVUZMOTQ0Mk1pSCIsImlhdCI6MTY2NDI0NjcyNywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.6nEXDfklFT9wb-xCOB1PKgeV_pQVkXD20uU5xKolE3M\">GitHub代码库</a>\"的java-19目录中找到，作者是Global Points的Java技术主管Wesley Egberto。</p><p></p><h2>JDK 20</h2><p></p><p></p><p>目前还没有针对或者集成到JDK 20的JEP。但是，根据最近提交的JEP草案和JEP候选版本，我们在这篇<a href=\"https://www.infoq.com/news/2022/09/java-19-so-far/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjQyNDcwMjcsImZpbGVHVUlEIjoia1ZJNXdhVUZMOTQ0Mk1pSCIsImlhdCI6MTY2NDI0NjcyNywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.6nEXDfklFT9wb-xCOB1PKgeV_pQVkXD20uU5xKolE3M\">新闻报道</a>\"中猜测了哪些JEP有可能被包含在JDK 20中。</p><p></p><p>JDK 20的正式发布日期还没有公布，但按照6个月的发布节奏，它预计在2023年3月中旬发布，并在2022年12月中旬进行功能冻结。</p><p></p><p>JDK 19现在可以从<a href=\"https://jdk.java.net/19?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjQyNDcwMjcsImZpbGVHVUlEIjoia1ZJNXdhVUZMOTQ0Mk1pSCIsImlhdCI6MTY2NDI0NjcyNywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.6nEXDfklFT9wb-xCOB1PKgeV_pQVkXD20uU5xKolE3M\">Oracle网站</a>\"下载，其他二进制文件预计将在未来几天内可用。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/09/java19-released/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjQyNDcwMjcsImZpbGVHVUlEIjoia1ZJNXdhVUZMOTQ0Mk1pSCIsImlhdCI6MTY2NDI0NjcyNywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.6nEXDfklFT9wb-xCOB1PKgeV_pQVkXD20uU5xKolE3M\">Java 19 Delivers Features for Projects Loom, Panama and Amber</a>\"</p>",
    "publish_time": "2022-09-28 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "一文读懂网络框架Netty",
    "url": "https://www.infoq.cn/article/398qN2sicBSWUdTuSM5c",
    "summary": "<p></p><blockquote>作为稍微有点经验的 Java 开发者，应该多少都听过 Netty 的大名，但如果你要问 Netty 是什么，它的特色有哪些，实现机制如何，适用于什么场景并解决什么问题，能完整回答出来的人并不多。本文试着基于上述维度对 Netty 进行深入介绍，帮助读者对 Netty 知其然并知其所以然。</blockquote><p></p><p></p><h1>基础篇</h1><p></p><p></p><h2>Netty 是什么？</h2><p></p><p></p><p>首先我们来看 Netty 是什么，关于这个问题，其<a href=\"https://xie.infoq.cn/link?target=https%3A%2F%2Fnetty.io%2F\">官网</a>\"有一段阐述：</p><p></p><p></p><blockquote>Netty is a NIO client server framework which enables quick and easy development of network applications such as protocol servers and clients.</blockquote><p></p><p></p><p>这段翻译过来意思就是：</p><p></p><p></p><blockquote>Netty 是一个基于 NIO 的异步网络编程框架，基于 Netty 能快速的搭建高性能易扩展的网络应用（包括客户端与服务端）。</blockquote><p></p><p></p><p>具体来说，Netty 就是对于 Java NIO 的封装，NIO 又是什么呢？NIO 是 Java 1.4 后引入的基于事件模型的非阻塞 IO 框架，在 NIO 之前，对于数据的处理都是基于 BIO(blocking IO)，从名字上就知道 BIO 是以阻塞的形式对数据进行处理，这种处理形式比较简单，但是既然阻塞的，那么就不可避免会涉及到线程的操作。熟悉并发的小伙伴应该都知道，线程是一种昂贵的资源，无论是创建、销毁，还是切换，这就导致 BIO 在面对一些特定场景如高并发等束手无策，而这些场景在互联网应用中却又很常见。</p><p></p><p>对应的，NIO 能较好的应对这些场景。遗憾的是，Java 在刚推出 NIO 时，由于各种原因，致使其使用复杂，且经常会出现 Bug。结果就是：广大开发者有需求，但解决需求的工具就是不好用这样尴尬的局面，怎么办呢？ -- 自己动手，丰衣食足！大不了再造个\"轮子\"，所以就出现了一系列解决 NIO 问题的框架，而 Netty 就是其中最著名的那一个（当然 Java 发展到现在，其 NIO 库原本的很多问题都得到了解决，不过很多解决方案借鉴的也是 Netty 的思想）。</p><p></p><p>另外，Netty 并不止于解决 NIO 的问题，它更进一步，还提供了一系列特色功能。</p><p></p><h2>Netty 的特色</h2><p></p><p></p><p>下面是 Netty 官网对于 Netty 特色的说明：</p><p></p><p></p><blockquote>It greatly simplifies and streamlines network programming such as TCP and UDP socket server'Quick and easy' doesn't mean that a resulting application will suffer from a maintainability or a performance issue. Netty has been designed carefully with the experiences earned from the implementation of a lot of protocols such as FTP, SMTP, HTTP, and various binary and text-based legacy protocols. As a result, Netty has succeeded to find a way to achieve ease of development, performance, stability, and flexibility without a compromise</blockquote><p></p><p></p><p>这段话大概的意思就是：</p><p></p><p></p><blockquote>首先，Netty 能极大的简化你的网络编程；并且，简单好用还不需要以复杂的管理和低效的性能为代价，Netty 通过优秀的设计，在易部署，高性能，稳定性，扩展性之间找到了一个较好的平衡点</blockquote><p></p><p></p><p>我们把这句话提炼出来，大概就可以得到 Netty 的几大特色：</p><p></p><p>针对基本的需求提供了简单易用的接口，直接上手！针对复杂的场景提供了很强的扩展性，轻松应对业务发展！在上面两点的基础上，性能不打折！</p><p></p><p>而如果对这些特点进行细化，则可以得出：</p><p></p><p>基于事件机制（Pipeline - Handler）达成关注点分离（消息编解码，协议编解码，业务处理）可定制的线程处理模型，单线程，多线程池等屏蔽 NIO 本身的 bug性能上的优化相较于 NIO 接口功能更丰富对外提供统一的接口，底层支持 BIO 与 NIO 两种方式自由切换</p><p></p><p>这些特性将在本文第二部分「实现篇」里做详细分析；既然 Netty 的本质还是一个基于 NIO 的网络框架，那么想要掌握 <a href=\"https://xie.infoq.cn/article/f6dcd60b1ac50a2fa907201ee\">Netty </a>\"的精髓，对于 NIO 的了解就不可或缺。</p><p></p><h2>NIO 处理模型介绍</h2><p></p><p></p><p>在介绍 NIO 之前，最好了解一下 BIO，还没有学习过的小伙伴可以阅读我另外一篇介绍 BIO 的文章：<a href=\"https://xie.infoq.cn/link?target=https%3A%2F%2Fwww.jianshu.com%2Fp%2F83d5020f2734\">Java IO使用入门 -- IO其实很简单</a>\"。</p><p></p><p><a href=\"https://xie.infoq.cn/article/37e5691df67c0ee43b7db3d6d\">NIO</a>\" 是 Java 1.4 引入的一种同步非阻塞的 I/O 模型，也是 I/O 多路复用的基础；相对于 Java BIO(OIO)提供的基于面向流的阻塞式编程模型，NIO 提供的是面向缓冲区的响应式事件编程模型。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b6/b6f3b8debc05701f1a9dc40488867824.png\" /></p><p></p><p>读到这里可能有些人会觉得迷糊，什么阻塞？非阻塞？基于流？基于缓冲区？这里有必要介绍一下 Linux 下的 5 中 IO 模型：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/24/2457141ecb58108d49bd181be34255d9.png\" /></p><p></p><p>阻塞 I/O 模型：最常用的 I/O 模型就是阻塞 I/O 模型，当用户进程调用了 recvfrom 这个系统调用，kernel 就开始了 IO 的第一个阶段：准备数据（对于网络 IO 来说，很多时候数据在一开始还没有到达。比如，还没有收到一个完整的 UDP 包。这个时候 kernel 就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。而在用户进程这边，整个进程会被阻塞。当 kernel 一直等到数据准备好了，它就会将数据从 kernel 中拷贝到用户内存，然后 kernel 返回结果，用户进程才解除 block 的状态，重新运行起来。所以，blocking IO 的特点就是在 IO 执行的两个阶段都被 block 了。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/24/24a31990df21a97a9828fb83e151ea6a.png\" /></p><p>非阻塞 IO 模型：linux 下，可以通过设置 socket 使其变为 non-blocking。当对一个 non-blocking socket 执行读操作时，流程是这个样子：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/71/711cdc0b70977b6795db5a29c76b5e52.png\" /></p><p></p><p>当用户进程发出 read 操作时，如果 kernel 中的数据还没有准备好，那么它并不会 block 用户进程，而是立刻返回一个 error。从用户进程角度讲 ，它发起一个 read 操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个 error 时，它就知道数据还没有准备好，于是它可以再次发送 read 操作。一旦 kernel 中的数据准备好了，并且又再次收到了用户进程的 system call，那么它马上就将数据拷贝到了用户内存，然后返回；所以，nonblocking IO 的特点是用户进程需要不断的主动询问 kernel 数据好了没有。IO 复用模型：IO multiplexing 就是我们说的 select，poll，epoll，有些地方也称这种 IO 方式为 event driven IO。select/epoll 的好处就在于单个 process 就可以同时处理多个网络连接的 IO。它的基本原理就是 select，poll，epoll 这个 function 会不断的轮询所负责的所有 socket，当某个 socket 有数据到达了，就通知用户进程。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/74/749b2c5bea1e0a8cfbec2930342bb3c0.png\" /></p><p>当用户进程调用了 select，那么整个进程会被 block，而同时，kernel 会监视所有 select 负责的 socket，当任何一个 socket 中的数据准备好了，select 就会返回。这个时候用户进程再调用 read 操作，内核负责将数据从 kernel 拷贝到用户进程；所以，I/O 多路复用的特点是通过一种机制使得一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select()函数就可以返回，所以说它最大的优势是系统开销小，系统不需要创建或维护新的进程/线程。另外，从上面比较 IO 复用流程图和阻塞 IO 的图可以发现，多路复用本身也是阻塞的，事实上，其效率可能还更差一些。因为这里需要使用两个 system call (select 和 recvfrom)，而阻塞 IO 只调用了一个 system call (recvfrom)。但是，用 select 的优势在于它可以同时处理多个 connection。所以，如果处理的连接数不是很高的话，使用 select/epoll 的 web server 不一定比使用阻塞 IO 的 web server 性能更好，可能延迟还更大。select/epoll 的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。）在 IO 复用模型中，对于每一个 socket，一般都设置成为 non-blocking，但是，如上图所示，整个用户的 process 其实是一直被 block 的。只不过 process 是被 select 这个函数 block，而不是被 socket IO 给 block。信号驱动 IO 模型：首先开启套接口信号驱动 I/O 功能,并通过系统调用 sigaction 执行一个信号处理函数（此系统调用立即返回，进程继续工作，它是非阻塞的）。当数据准备就绪时，就为该进程生成一个 SIGIO 信号。随即可以在信号处理程序中调用 recvfrom 来读数据，井通知主循环函数处理数据；一般用的较少。异步 IO：在异步 IO 模型下，用户进程发起 read 操作之后，立刻就可以开始去做其它的事。而另一方面，从 kernel 的角度，当它收到一个 asynchronous read 之后，首先它会立刻返回，所以不会对用户进程产生任何 block。然后，kernel 会等待数据准备完成，然后依然由它将数据拷贝到用户内存，当这一切都完成之后，kernel 会给用户进程发送一个 signal，告诉它 read 操作完成了。</p><p><img src=\"https://static001.geekbang.org/infoq/38/38b9ed584d29a3f42d2f89db469c8228.png\" /></p><p>介绍完这 5 种 IO 模型后，我们回到 NIO，NIO 基于的是 IO 复用模型（就是上面的第三种 IO 模型），正如在介绍 IO 复用模型时已提到，而在 linux 下，有三种针对该模型的实现，分别为：select，poll，epoll；select 和 poll 的实现机制类似，主要区别在于描述 fd 集合的方式不同，poll 使用 pollfd 结构而不是 select 的 fd_set 结构；epoll 是 linux 2.6 后才有的，它主要是对 select 和 poll 的缺陷做了一些改进。</p><p></p><p>这两种实现方式有几个比较大的缺点：1) 每次调用 select，都需要把 fd 集合从用户态拷贝到内核态，这个开销在 fd 很多时会很大 2) 每次调用 select 都需要在内核遍历传递进来的所有 fd，这个开销在 fd 很多时也很大 3) select 支持的文件描述符数量太小了，默认是 1024（当然可以手动改，但改大了不一定效果好，以为前面的 1,2 两点）对于第一个缺点，epoll 在每次注册新的事件到 epoll 句柄中时，会把所有的 fd 拷贝进内核，而不是在 epoll_wait 的时候重复拷贝。这样就保证了每个 fd 在整个过程中只会拷贝一次。</p><p></p><p>对于第二个缺点，epoll 的解决思路是每当一个 fd 准备就绪，就调用对应的回调函数将其加入一个就绪链表，然后只需要遍历这个就绪链表即可，不需要遍历所有 fd。</p><p></p><p>对于第三个缺点，epoll 没有这个限制，它所支持的 fd 上限是最大可以打开文件的数目，这个数字一般远大于 1024,举个例子,在 1GB 内存的机器上大约是 10 万左右，具体数目可以 cat /proc/sys/fs/file-max 察看，一般来说这个数目和系统内存关系很大。</p><p></p><p>另外顺便提一下 Windows 下的异步 IO 实现机制：I/O Completion Ports，或简称 IOCP，个人觉得它的设计比较好，极大的减少线程切换对性能的影响，同时又能保证 CPU 保持在较高的利用率，有兴趣可以阅读：<a href=\"https://xie.infoq.cn/link?target=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fwindows%2Fwin32%2Ffileio%2Fi-o-completion-ports\">https://learn.microsoft.com/en-us/windows/win32/fileio/i-o-completion-ports</a>\"。</p><p></p><h1>实现篇</h1><p></p><p></p><h2>Netty 总体结构</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/c2/c2df8d4b47fca9ac082d61d67bfa5923.png\" /></p><p></p><p>这张图摘自 Netty 官网，其展示的是 Netty 的模块结构，总体来说，Netty 分为两大模块：</p><p></p><p>核心模块核心模块主要提供的是 Netty 的一些基础类和底层接口，主要包含三部分：</p><p>用以提升性能，减少资源占用的 Zero-Copy-Capable Rich Byte Buffer，即「零拷贝」缓冲区，Netty 里的「零拷贝」与操作系统语境下的「零拷贝」不是同一个概念，具体会在后续章节做阐述。统一的 API，这是 Netty 对外宣传的简单易用 API 的一部分，什么意思呢？就是 Netty 为同步和异步 IO 提供统一的编程接口，举个例子，如果在前期希望使用 BIO，后续随着业务变动，希望改用 NIO，只需要改动几个简单的初始化参数，而不需要变动主体流程；相反，如果一开始不是基于 Netty，而是直接基于 BIO 书写处理流程，后期想改成 NIO，其变动是很大的，毕竟是两个不同的接口模块。易扩展的事件模型，这里的重点在于易扩展，因为 NIO 本身就是基于事件的 IO 模型，而扩展性很好理解，如果一个框架无法扩展，那么也就意味着无法应对业务的变化。</p><p></p><p>服务模块既然 Netty 的核心是 IO，那么其服务模块基本也就和 IO 操作分不开了，主要有：</p><p>网络接口数据处理相关服务，如报文的粘包，拆包处理，数据的加密，解密等各网络层协议实现服务，主要包括传输层和应用层相关网络协议的实现文件处理相关服务</p><p></p><h2>Netty 处理架构</h2><p></p><p></p><p>介绍完 Netty 的模块结构，我们再来看一下它的处理架构：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/46/46fbcfbd63870d028fdb3a4019a94be9.png\" /></p><p></p><p>Netty 的架构也很清晰，就三层：</p><p></p><p>底层 IO 复用层，负责实现多路复用。通用数据处理层，主要对传输层的数据在进和出两个方向进行拦截处理，如编/解码，粘包处理等。应用实现层，开发者在使用 Netty 的时候基本就在这一层上折腾，同时 Netty 本身已经在这一层提供了一些常用的实现，如 HTTP 协议，FTP 协议等。</p><p></p><p>一般来说，数据从网络传递给 IO 复用层，IO 复用层收到数据后会将数据传递给上层进行处理，这一层会通过一系列的处理 Handler 以及应用服务对数据进行处理，然后返回给 IO 复用层，通过它再传回网络</p><p></p><h2>基于 Reactor 模式的 IO 复用</h2><p></p><p></p><p>在 Netty 处理架构图中，可以看到在 IO 复用层上标注了一个「Reactor」：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a0/a03a4e31a2dfe2a52c3f7a03dbc656c5.png\" /></p><p></p><p>这个「Reactor」代表的就是其 IO 复用层具体的实现模式 -- Reactor 模式</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/24/249cfcb81ca31445c5fcb900d7070400.png\" /></p><p></p><p>这张图是从大名鼎鼎的<a href=\"https://xie.infoq.cn/link?target=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FDoug_Lea\">Doug Lea</a>\"的一份演讲稿中截取下来的，通过这张图示，就可以大致明白什么是 Reactor 模式了。在 Reactor 模式中，分为主反应组（MainReactor）和子反应组（subReactor）以及 ThreadPool，主反应组（MainReactor）负责处理连接，连接建立完成以后由主线程对应的 acceptor 将后续的数据处理（read/write）分发给子反应组（subReactor）进行处理，而 Threadpool 对应的是业务处理线程池；对应代码为：</p><p><code lang=\"undefined\">EventLoopGroup bossGroup = new NioEventLoopGroup(1);\nEventLoopGroup workerGroup = new NioEventLoopGroup(1);\n\nServerBootstrap b = new ServerBootstrap();\n            b.group(bossGroup, workerGroup)\n            ...</code></p><p></p><p>在这段代码中 bossGroup 对应的就是主反应组（MainReactor），workerGroup 对应的是子反应组（subReactor），而NioEventLoopGroup其实就是一个实现了 Java ExecutorService的线程池，其中的线程数可定制，若不设置线程数参数，则该参数值默认为2 * CPU核数量，在ServerBootstrap的初始化过程中，会为其添加一个实现了acceptor机制的Handler</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/da/da3f9452b473bc141a451b215b10db27.png\" /></p><p></p><p>而通过ServerBootstrapAcceptor，会在 Channel 建立后触发channelRead()方法，并在channelRead()内将此 Channel 绑定至子反应组对应的处理线程，后续的数据处理就交于它进行处理</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ae/ae1faabcdffe4f93778db72076b8449b.png\" /></p><p></p><p>在阅读这部分源码的时候需要注意一个点，按理来说，连接的建立应该是ACCEPT事件，怎么会触发channelRead()呢 ？其实 netty 内部将READ和ACCEPT状态一并作为 read 的触发条件。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/88/885289d18f5ddb0d4b155931b157bc41.png\" /></p><p></p><p>介绍完了 Netty 关于 IO 复用层的实现，继续看其「易扩展」和「关注点分离」的核心：Pipeline。</p><p></p><h2>基于责任链模式的 Channel-Pipeline</h2><p></p><p></p><p>同样回过头去再看 Netty 处理架构图中的中间层 -- Pipeline。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b8/b8b77f7378b7a1ba5f1fb2230a1e22e9.png\" /></p><p></p><p>其字面意思为「管道」，顾名思义，管道的作用就在于传输，而对于 Netty 来说，它的管道传输的当然就是数据了，在本位「基础篇」关于 Netty 基础的介绍里，提到它有一个很重要的特色就在于：基于事件机制（Pipeline - Handler）达成关注点分离（消息编解码，协议编解码，业务处理），而Pipeline就是实现这一特色的核心所在，我们下面来看 Netty 是如何实现所谓的「易扩展」和「关注点分离」的。</p><p></p><p>首先，Netty 的Pipeline从数据传输的方向上来看分为进和出，这个和 BIO 相同；其次，最重要的在于 Netty 在Pipeline上通过责任链模式插入一系列的「Handler」，这一结构是它能实现「易扩展」和「关注点分离」的关键。想想看，所谓 IO，不就是数据的「进」和「出」吗？而进来干啥呢？当然就是需要应用逻辑对其处理，那处理完了呢？还需要送回给请求方以示响应，而在进的过程中需要哪些处理逻辑，这些处理逻辑的先后顺序如何，处理完后出去的过程中需要哪些处理逻辑，这些处理逻辑的顺序又是如何，如果这些都可以方便的配置调整，是不是就达到了 Netty 宣称的「易扩展」和「关注点分离」（只需关注业务相关的 Handler，网络协议相关的 Handler 直接调用即可，IO 复用更无须关注）呢？</p><p></p><p>在 Netty 里，这一实现机制的核心类叫做ChannelPipeline：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/af/afc49bff9b0315600300a1782c70712c.png\" /></p><p></p><p>其中Channel负责数据通信，Handler负责逻辑处理，而ChannelPipeline就相当于一个由Handler串起来的处理链条，在 Neety 源码里有一个关于ChannelPipeline的比较形象的图形化描述：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2c/2c2e401dc926373cb7e80d7d25159fe5.png\" /></p><p></p><p>看到没有，其实很简单，就是一个针对不同方向数据流的责任链，其中Inbound对应的是输入流，Outbound对应的是输出流（在这里再多提一句，责任链模式在很多框架里都有使用，比如 Spring MVC 里看到的各种 Handler，也是基于责任链的封装）。</p><p></p><h2>强大的 ByteBuf</h2><p></p><p></p><p>既然是对 Netty 进行分析，就必然绕不过 Netty 自己封装的数据缓冲区：ByteBuf，它是 Netty 对外宣称的高性能的重要支撑，另外有必要提一下，在 Netty 里其核心缓冲区类叫「ByteBuf」，以便与 NIO 本身的缓冲区类「ByteBuffer」做区分，ByteBuf 有如下特点：</p><p></p><p>功能丰富的接口，Java NIO 本身的缓冲区接口比较简单支持零拷贝，提升性能，减少资源占用支持动态扩展缓冲区初始块大小动态控制读写切换不需要手动调用 clear()，flip()；使用过 Java NIO 的小伙伴应该知道，其在进行读写切换时需要不停的通过 clear()和 flip()进行模式切换，很麻烦池化，提升性能，减少资源占用</p><p></p><p>下面将对上面提到的几个 ByteBuf 的重要特性进行实现分析，首先来看下 ByteBuf 是如何避免 NIO 中那繁琐的读写切换的。我们知道，对于 Java NIO 的 Buffer，其有几个重要的属性：position，limit，capacity，其中position代表的是下一个读或写的位置，limit是可被读或写的最高位，而capacity就是 Buffer 的容量了，之所以要在读和写切换的时候进行手动操作（clear()，flip()），主要是因为在 NIO 中，position和limit在读的时候代表的是下一个需读的位和可读的最高位，但是在写的时候又代表下一个需写的位和可写的最高位（其实就是capacity），换句话说这两个变量在不同的操作场景下有不同的含义，对应值也不同，所以需要在读写切换的时候进行手动操作。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/44/44b484cf605c1c8283efcab92780dd34.png\" /></p><p></p><p>而 Netty 的 ByteBuf 则对这一点做了改进，其针对读写操作分别增加上了readerIndex，writerIndex，使用的时候不需要考虑读写转换。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/24/24d819b315c3cd5aa34068577ec90324.png\" /></p><p></p><p>读的时候就变动readerIndex的值，而此时可读的最高位（对应 NIO 中的 limit）其实就是writerIndex，同理写的时候就变动writerIndex，此时可写的最高位（对应 NIO 中的 limit）就是capacity，说白了就是两个变量分别管理读和写的操作位，互不冲突，也就不存在读写切换的时候手动操作了；其实看到这里我们可以发现，NIO 在接口设计的时候确实没有考虑周到，毕竟 Netty 的这种优化并不是有多难！</p><p></p><h4>零拷贝 Buf</h4><p></p><p></p><p>在分析 ByteBuf 的「零拷贝」特性之前，先说说什么是「零拷贝」，所谓「零拷贝」, 通常指的是在 OS 层面上为了避免在用户态(User-space) 与 内核态(Kernel-space) 之间进行数据拷贝而采取的性能优化措施；例如 Linux 提供的 mmap 系统调用，它可以将一段用户空间内存映射到内核空间，当映射成功后，用户对这段内存区域的修改可以直接反映到内核空间；同样地，内核空间对这段区域的修改也直接反映用户空间。正因为有这样的映射关系，我们就不需要在用户态(User-space) 与内核态(Kernel-space) 之间拷贝数据，从而提高了数据传输的效率；对于 Java 的网络操作来说，网络接口在收到数据的时候需要先将数据复制到内核内存，然后在从内核内存复制到用户内存，同理往网络接口发数据也是先将数据从用户内存复制到内核内存，再从内核内存中将数据传给网络接口，所以如果是直接操纵内核内存，无疑处理的性能会更好。</p><p></p><p>回到 Netty，Netty 中的 「零拷贝」与上面我们所提到到 OS 层面上的 「零拷贝」其实不太一样，Netty 的 「零拷贝」 完全是在用户态里的，或者说更多的是偏向于减少 JVM 内的数据操作，具体体现在如下几个方面：</p><p></p><p>通过 CompositeByteBuf类，将多个ByteBuf合并为一个逻辑上的ByteBuf，避免了各个ByteBuf之间的拷贝通过wrap操作，将byte[]数组、ByteBuf、ByteBuffer等多个数据容器合并成一个ByteBuf对象，进而避免了拷贝操作通过slice操作，将ByteBuf分解为多个共享同一个存储区域的ByteBuf，避免了内存的拷贝通过FileRegion包装的FileChannel.tranferTo实现文件传输，将文件缓冲区的数据发送到目标Channel，避免了传统通过循环write方式导致的内存拷贝问题</p><p></p><p>这些操作之所以能避免不必要的拷贝操作，其实就在于内部对数据进行的是逻辑操作而非物理操作，操作完成后根据各逻辑引用的数据信息（大小，位置等）重新计算ByteBuf内部的控制属性（limit，capacity，readerIndex，writerIndex），如通过CompositeByteBuf将原本两个分别表示 head 和 body 的 buffer 组装成一个 buffer：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a7/a7a14c39c67a2dfd6cd430068d8f56d4.png\" /></p><p></p><p>虽然看起来CompositeByteBuf是由两个ByteBuf组合而成的，不过在CompositeByteBuf内部，这两个ByteBuf都是单独存在的（指针引用），CompositeByteBuf只是逻辑上是一个整体；这样在数据操作的时候不需要对数据进行物理挪动，只需要操作数据引用并计算关键因子即可，这种方式不但能提升性能，还可以减少内存占用，值得借鉴。</p><p></p><h4>Buf 池化</h4><p></p><p></p><p>在 Netty 中，ByteBuf 用来作为数据的容器，是一种会被频繁创建和销毁的对象，ByteBuf 需要的内存空间，可以在 JVM Heap 中申请分配，也可以在 Direct Memory（堆外内存）中申请，其中在 Direct Memory 中分配的 ByteBuf，其创建和销毁的代价比在 JVM Heap 中的更高，但抛开哪个代价高哪个代价低不说，光是频繁创建和频繁销毁这一点，就已奠定了效率不高的基调。Netty 为了解决这个问题，引入了池化技术，池化技术的思想不复杂，和线程池思想类似，说白了就是对一些可重用的对象用完不回收，后面需要再次使用，以减少创建和销毁对象带来的资源损耗，下面结合 Netty 源码对其池化技术做剖析。</p><p></p><p>首先看ByteBuf，它实现了ReferenceCounted接口，表明该类是一个引用计数管理对象</p><p></p><p><code lang=\"undefined\">public abstract class ByteBuf implements ReferenceCounted, Comparable</code></p><p></p><p>而引用计数就是实现池化的关键技术点（不过并非只有池化的 ByteBuf 才有引用计数，非池化的也会有引用），继续看ReferenceCounted接口，它定义了这几个方法：</p><p></p><p><code lang=\"python\">public interface ReferenceCounted {\n    int refCnt();\n\n    ReferenceCounted retain();\n\n    ReferenceCounted retain(int increment);\n\n    boolean release();\n\n    boolean release(int decrement);\n}</code></p><p></p><p>每一个引用计数对象，都维护了一个自身的引用计数，当第一次被创建时，引用计数为 1，通过refCnt()方法可以得到当前的引用计数，retain()和retain(int increment)增加自身的引用计数值，而release()和release(int increment)则减少当前的引用计数值，如果引用计数值为 0，并且当前的 ByteBuf 被释放成功，那这两个方法的返回值就为true。而具体如何释放，各种不同类型的 ByteBuf 自己决定，如果是池化的 ByteBuf，那么就会重新进池子，以待重用；如果是非池化的，则销毁底层的字节数组引用或者释放对应的堆外内存。具体的逻辑在AbstractReferenceCountedByteBuf类中可以看到：</p><p></p><p><code lang=\"text\">@Override\npublic final boolean release() {\n    for (;;) {\n        int refCnt = this.refCnt;\n        if (refCnt == 0) {\n            throw new IllegalReferenceCountException(0, -1);\n        }\n\n        if (refCntUpdater.compareAndSet(this, refCnt, refCnt - 1)) {\n            if (refCnt == 1) {\n                deallocate();\n                return true;\n            }\n            return false;\n        }\n    }\n}</code></p><p></p><p>释放对象的方法定义在 deallocate() 方法里，它是个抽象方法，既然是抽象的，那么就需要子类自行实现，对于非池化的 HeapByteBuf 来说，释放对象实际上就是释放底层字节数组的引用：</p><p></p><p><code lang=\"text\">@Override\nprotected void deallocate() {\n    array = null;\n}</code></p><p></p><p>对于非池化的DirectByteBuf来说，释放对象实际上就是释放堆外内存：</p><p></p><p><code lang=\"text\">@Override\nprotected void deallocate() {\n    ByteBuffer buffer = this.buffer;\n    if (buffer == null) {\n        return;\n    }\n\n    this.buffer = null;\n\n    if (!doNotFree) {\n        PlatformDependent.freeDirectBuffer(buffer);\n    }\n\n    if (leak != null) {\n        leak.close();\n    }\n}</code></p><p></p><p>对于池化的 ByteBuf 来说，就是把自己归还到对象池里：</p><p></p><p><code lang=\"text\">@Override\nprotected final void deallocate() {\n    if (handle &gt;= 0) {\n        final long handle = this.handle;\n        this.handle = -1;\n        memory = null;\n        chunk.arena.free(chunk, handle);\n        if (leak != null) {\n            leak.close();\n        } else {\n            recycle();\n        }\n    }\n}</code></p><p></p><p>熟悉 JVM GC 的同学应该对这个引用计数的机制不会感到陌生，因为 JVM 在判断一个 Java 对象是否存活时有一种方式使用的就是计数法；另外 Netty 的池化缓存在实现上借鉴了<a href=\"https://xie.infoq.cn/link?target=https%3A%2F%2Fwww.geeksforgeeks.org%2Foperating-system-allocating-kernel-memory-buddy-system-slab-system%2F\">buddy allocation和slab allocation</a>\"的思想并进行了比较复杂的设计（buddy allocation 是基于一定规则对内存进行分割，回收时进行合并，尽可能保证系统有足够的连续内存；而 slab allocation 是把内存分割为大小不等的内存块，请求内存是分配最贴近请求 size 的内存块，避免内存浪费），可以减少对象的创建与销毁对性能的影响，因为缓冲区对象的创建与销毁会占用内存带宽以及 GC 资源，另外由于池化缓存本身比较复杂，如线程私有池与全局共有池，其声明与释放都需要手动处理（比如本地池内的缓冲区对象如果不是在同一个线程内释放就会导致内存泄漏，这也是为什么 JVM GC 的时候需要有 Stop The World），Netty 提供了内存泄漏监控工具<a href=\"https://xie.infoq.cn/link?target=https%3A%2F%2Fnetty.io%2F4.0%2Fapi%2Fio%2Fnetty%2Futil%2FResourceLeakDetector.html\">ResourceLeakDetector</a>\"，如果发生了内存泄漏，它会通过日志记录并提醒，这个工具主要是防止对象被 GC 的时候其占用的资源没有被释放（如内存），或者没有执行release方法</p><p></p><p>也许有人会说，既然池化缓存实现复杂，用起来还得防止内存泄漏，那么它到底能给性能带来多大提升呢？我们可以看下 Twitter 对 Netty 池化缓存做的性能测试结果：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fa/fa2bbe6fb9182263251aed9b8db049e2.png\" /></p><p></p><p>这张图的 Y 轴显示的是创建对象花费的时间，而 X 轴代表的是所创建对象的大小，同时在实验中，使用了四种不同的对象，分别是非池化堆内存对象（Unpooled Heap），池化堆内存对象（Pooled Heap），非池化直接内存对象（Unpooled Direct），池化直接内存对象（Pooled Direct）。结果现实，随着被创建对象大小的增加，池化技术的优势愈加明显，当然当对象很小时，池化反而不如 JVM 本身的对象创建性能（可以结合 ByteBuf 的实现原理，想想为什么？）</p><p></p><p>除了对象创建的性能，Twitter 还测试了使用池化技术时 GC 相关的表现，实验模拟了在 16000 个连接下，对 256byte 大小的数据包进行循环传输：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2b/2b6e9ca89115a398afc0334bb42588e2.png\" /></p><p></p><p>结果表明，相对于非池化，池化的 GC 停顿减少了近 4 倍，而垃圾的增长也慢了 4 倍。所以说，Netty 对 ByteBuf 进行的复杂的重写还是值得的。</p><p></p><h2>NIO epoll 死循环问题及 Netty 解决方案</h2><p></p><p></p><p>最后说说 Netty 是如何解决著名的「NIO epoll 死循环」问题的。什么是「NIO epoll 死循环」呢？在 Linux 系统中，当某个 socket 的连接突然中断后，会重设事件集 eventSet，而 eventSet 的重设就会导致 Selector 被唤醒（但其实这个时候是没有任何事件需要处理的，select()方法应该还是处于阻塞状态），虽然被唤醒了，但其实是没有事件需要处理的，所以就又返回select()方法之前（正常情况下是处理完事件重新回去被select()阻塞），此时select()方法还是会直接返回，如此反复便造成死循环：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/37/3771360151fbd277fce96c5d234e00a0.png\" /></p><p></p><p>这个问题的原因本质上就是 NIO 的 Selector 实现有问题，Netty 解决的方式其实比较简单粗暴，它会记录一段时间内空轮询的次数，如果超过一定阈值，就认为这个 bug 出现了，此时会重新生成一个新的 selector 取代旧的 selector，避免死循环，具体的处理代码在NioEventLoop中：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7d/7d355379c564f488986dbcde7ab59236.png\" /></p><p></p><h2>Netty 主要类关系图</h2><p></p><p></p><p>这里贴一张 Netty 主要实现类的关系图，对需要阅读 Netty 源码的小伙伴可能有一个参考作用</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6a/6a7363fb2a9a1abcda8da7fe13a2b62d.png\" /></p><p></p><h1>总结篇</h1><p></p><p></p><h2>Netty 适用场景</h2><p></p><p></p><p>Netty 只是一套网络框架，它不可能适用于所有场景，所以选用 Netty 前最好能想清楚它是否能很好的应对自己的需求。想要知道 Netty 的适用场景最好的方式就是从 Netty 本身的特性出发进行思考，具体可参考本文「基础篇」中「Netty 的特色」章节，基于此，如果你的需求属于下列场景，则 Netty 会比较适合你，包括：</p><p></p><p>高并发，实时处理，如：游戏服务器，聊天服务器，SOA 调用框架，RPC 框架等。对网络协议（传输层与应用层）有一定的定制需求。一套代码可能需要同时支持 BIO 和 NIO。</p><p></p><p>而其他情况，Netty 并一不定适合，如：</p><p></p><p>需求较简单的网络应用，则不必使用 Netty，毕竟在能满足需求的基础上，越简单越好。单次请求处理耗时较长的应用，这种情况下 NIO 没有优势，此时使用 BIO 的方式可能效果会更好。</p><p></p><h2>Netty 支持的协议</h2><p></p><p></p><p>Netty 框架本身已经对常用的协议进行了实现，包括：</p><p></p><p>应用层：HTTP，WebSocket，HTTP2，Redis，SMTP，DNS，MQTT，SSL，STARTTLS ，RTSP。传输层：TCP，UDP，SCTP，UDT 等。其他：Protobuf，gzip。</p><p></p><p>可以说，一般的应用使用 Netty 本身的支持就能满足大部分需求，剩下的关注自己的业务即可</p><p></p><h2>Netty &amp; MINA &amp; Jetty</h2><p></p><p></p><p>Netty 和 MINA 经常会放在一起比较，主要是因为两个框架有很多相似的地方，或者说它们本身就是一对兄弟 -- 都是基于 Java NIO 封装的一个网络框架。其实更深入的了解会发现，Netty 的作者<a href=\"https://xie.infoq.cn/link?target=https%3A%2F%2Fgithub.com%2Ftrustin\">Trustin Lee</a>\"也是 MINA 的作者（当然已经不继续参与了），据说他是对 MINA 的代码不满意，才重新写了 Netty，所以看 Netty 的代码经常能看到 MINA 的影子，但就现在来说 Netty 的社区远比 MINA 要活跃，迭代频率也更高，大部分的特性也优于 MINA。</p><p></p><p>至于 Jetty 之所以会拿来比较，主要是因为和 Netty 名字类似，但其实这两者并没有很大的可比性，因为 Jetty 是一个轻量级的 servlet 容器，而 Netty 是一个基于 NIO 的异步网络编程框架，基于 Netty 可以实现自己的 servlet 容器或者其它网络应用。</p><p></p><h2>相关项目</h2><p></p><p></p><p>很多项目内部都使用 Netty 作为其网络处理模块，包括：</p><p><a href=\"https://xie.infoq.cn/link?target=https%3A%2F%2Fgithub.com%2Fapache%2Fincubator-dubbo\">Dubbo</a>\"<a href=\"https://xie.infoq.cn/link?target=https%3A%2F%2Fgithub.com%2Fapache%2Fspark\">Spark</a>\"<a href=\"https://xie.infoq.cn/link?target=https%3A%2F%2Fgithub.com%2Fplayframework%2Fplayframework\">Play framework</a>\"<a href=\"https://xie.infoq.cn/link?target=https%3A%2F%2Fgithub.com%2Felastic%2Felasticsearch\">Elastic search</a>\"</p><p></p><p>Netty 本身是一个优秀的框架，其源码的层次和结构也很清晰，值得一读；平常很多人说熟悉网络，但是大部分人也仅仅只是知道一些皮毛（也包括我自己）。其实，想要写一个健壮易用的网络框架并不容易，如果需要同时支持高并发，那更是难上加难，而 Netty 在这一点就做得很出色，不仅体现在其本身优秀的代码组织，更多的还是把一些已有的功能和思想进行合适的组装和适当的优化。</p><p></p><p>另外，结合当今另一个炙手可热的高性能服务器 Nginx 会发现，这两者的思想有很多相通之处，如都是基于事件机制，都分为主工作组与子工作组，都是在 PipeLine 上设置一系列的 Handler 进行数据处理，都有通过逻辑映射增强内存效率的设计等等，很有意思，感兴趣的小伙伴可以找寻相关资料进行延展阅读。</p><p></p><h4>作者介绍</h4><p></p><p></p><p>蔡昱星，飞书深诺首席架构师；主要专注于基于云原生的互联网架构设计与落地，当前重点关注企业系统架构领域，特别是如何更好的应对业务复杂度。</p>",
    "publish_time": "2022-09-28 10:48:07",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "SaaS时代，凭什么说数据分析的未来是指标中台",
    "url": "https://www.infoq.cn/article/4t6E7u2EOOlO4VNCNqRA",
    "summary": "<p>当前，数字化转型已成为很多企业的必修课。而面对如今的经济形势，企业为数字化转型迈出的每一步都至关重要。过去，不少企业为充分发挥数据价值，已经做了很多相关努力，从以 Hadoop 为核心的数据湖，到 Snowflake、Databricks 等云上数据仓库，再到<a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651090633&amp;idx=2&amp;sn=9041d6d7b134230132adeeb098b8d386&amp;chksm=bdb9969a8ace1f8c79cb06fe0b5d65619e053834f0d8ab2078923ca2e1e58958ba3135649f14&amp;scene=27#wechat_redirect\">湖仓一体化</a>\"...... 这些举措真的解决了与日俱增的数据问题吗？未必。今年 Gartner 发布的《分析查询加速的市场引导报告》就曾指出，企业在享受数据湖带来灵活性的同时，也承受着因数据使用和管理混乱带来的不利影响。</p><p></p><p></p><h2>传统BI 已经无法满足需求？</h2><p></p><p></p><p>事实上，不管是数据仓库、数据湖、还是湖仓一体，都是典型的中心化模式。随着云时代的到来，中心化的模式已不再适用。整个行业、架构、信息显现出新的趋势，去中心化的分析模式将是未来。</p><p></p><p>传统 BI 主要是依托于数据仓库作为支撑。传统数据集成系统位于本地的数据中心，而类似 Snowflake 这样的产品的出现颠覆了企业级数据仓库（EDW），在云和数据仓库之间找到了平衡。与传统数据仓库解决方案相比，云数据仓库安全灵活，且能够提供更多即时性、自主性和控制性。然而，想要用好云数据仓库却并不容易。首先，云数据仓库的核心功能并不是为多并发用户在大型数据集上提供交互式查询，其查询优化都是在其内部完成，因此，查询性能较差，且用户的发挥空间有限。其次，采用云数据仓库一旦超出标准，比如数据量过大或者希望获得更高的可用性及更快的获得结果，用户就需要负担超额的成本。</p><p></p><p>数据仓库的位置介于可视化报表和底层业务系统数据源之间。即便云数据仓库努力拥抱变化，但仍不能解决企业数据分析面临的难题，BI 项目解决方案的应用依托云数据仓库，也因此受到限制。</p><p></p><p>从业务维度，消费数据的人群也发生了变化。过去分析工具只提供给数据分析师这样专业的人员使用，而现在，更多的数据需要提供给一线业务人员使用。在这样的情况下，传统 BI 已无法满足需求。传统 BI 的确是非常专业的工具，但恰恰是因为过于专业，一线业务人员很难承担复杂知识背后的学习成本。根据 IBM 的统计数据，实施传统 BI 的项目失败率达到近 70%，大量的 BI 系统并没有得到有效的使用。究其原因是⽤⼾⽤不起来、不会⽤数据分析⼯具把业务和数据进⾏转换。</p><p></p><p>此外，采用传统 BI 工具必然会牵扯到团队间的协作，除了学习成本，还会带来巨大的沟通成本，导致数据无法及时、快速地反馈到数据使用者的手中。</p><p></p><p>一方面，数据分析项目从提出需求到最终交付，是一个漫长而繁琐的过程，需要进行数据源整合、指标定义、模型开发、数仓任务开发及运维、报表开发等一系列流程。更可怕的是，业务场景并非一成不变，一旦指标逻辑变更，数仓就要重新开发刷数。</p><p></p><p>另一方面，在实际使用过程中，传统 BI 很容易变成报表的游戏。传统 BI 的架构思维是数据通过 ETL 流向数据湖或数据仓库，并通过报表实现可视化。报表的需求与业务的需求和个人习惯有关。一旦业务需求或者人员发生变动，就需要重新进行报表开发，即使以往有类似的需求，报表也很难复用，这就造成严重的报表堆叠。</p><p></p><p>近年来，大量互联网公司都在不断使用更多的 SaaS 服务，而这些 SaaS 服务背后所产生的数据割裂在不同的云和 SaaS 产品之间。在这样的情况下，已无法使用以往的方式把数据汇集起来，进行建模，再制成报表给到业务人员，而需要更加敏捷的方式，为业务人员提供数据分析和决策的能力。</p><p></p><p>数据的基础架构、数据的使用对象、数据的消费方式都发生了变化。InfoQ 也于近日采访 Kyligence，一起聊了聊行业中的最新洞察与实践。在采访中，公司联合创始人兼 CEO 韩卿认为，当今已进入 SaaS 时代，面对 SaaS 时代带来的数据割裂及传统数据分析方式难以适用等诸多问题，就需要用 SaaS 的方式去解决。</p><p></p><p></p><h2>一站式云端指标中台的技术架构</h2><p></p><p></p><p>现代管理学之⽗彼得·德鲁克有⼀句⾮常经典的话：“What gets measured gets done”，意思是只有⼀个事情能被量化，才能够被解决。数据分析的目标就是找到能够量化业务的关键指标，从中进行洞察，并做出决策。</p><p></p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651110890&amp;idx=3&amp;sn=23b5863d76f0da1700ebf2826e46a87f&amp;chksm=bdb945b98aceccaf4dc207fb9071475b5d670eaa9ae652b5df355a19f200372e4f701fdfb4d5&amp;scene=27#wechat_redirect\">指标中台</a>\"的出现正是为了达成这一目标。</p><p></p><p>对于指标中台，来自领先的市场研究和咨询机构 Ventana Research 的 David Menninger 给出定义，指标中台是一个指标的仓库，存储了我们之前提到的各项规则，定义了如何进行计算以及对齐了与指标相关的各项目标。</p><p></p><p>在指标中台里，“指标”成为数据和业务交互的主体，通过对“指标”的标准化，进而实现数据开发和管理的标准化，有效衡量业务经营和发展情况。通过指标中台降低数据使用门槛，有效推动数据赋能一线业务，从而推进企业的数字化经营。</p><p></p><p>指标中台产品陆续面世，产品均以实现 OLAP 下的数据治理，减少计算逻辑和数据逻辑的重复为目标，但最终将走向何方，还需要进一步探索与实践。Kyligence 也于近日宣布推出了一站式云端指标中台 Kyligence Zen。据了解，Kyligence Zen 是处于数据层和应用层之间的指标中台，可以统一管理所有业务指标，自动完成数据加工、指标计算等过程，企业可以在不同应用中实现指标的复用，形成以指标为核心的共同语言，提高协同管理的效率。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3b/3b48967a2cfa4d6f14d9d0d1750fb5d2.jpeg\" /></p><p></p><p>Kyligence Zen 的本质其实是一款基于 Kyligence OLAP 能力打造的 SaaS 产品。用韩卿的话来说，SaaS 时代就需要⽤ SaaS 的⽅式解决数据分析面临的挑战。作为一款 SaaS 产品，Kyligence Zen 致力于把数据指标化，把指标智能化。相比于 BI 来说，Kyligence Zen 指标中台以更简单的方式，使业务人员能够更加个性化、自动化的使用好指标，并通过提供合适的指标模版，快速建立自己的指标体系。</p><p></p><p>随着云时代的到来，大量测试、开发、应用全都部署在了云上。据 Flexera 2020 State of the Cloud Report 统计，应用部署到云上之后将近 30%-35% 的资源被浪费。初创公司 Milkie Way 在对 Firebase 和 Cloud Run 进行内部测试期间，一不小心在几个小时里就在云上烧掉了 72,000 美元，差点导致这家公司破产。如果没有一个好的云端的费用的管控，成本方面就会形成一个巨大的黑洞。</p><p></p><p>通过 Kyligence Zen 可以帮助企业从事前规划、事中监控、事后评估三个阶段实现云成本管控。事前基于用途进行云资源规划，事中对所有云资源的使用情况进行持续监控，事后基于云账单建立指标体系，定期对指标进行管理和分析，帮助合理管控云成本。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c8/c80ef9493cb0e9e309dd7bc3ce9a7fb1.png\" /></p><p></p><p>Zoom 公司在 2021 年一季度的财报中称，其毛利率从前一季度的 69.4% 上升至 73.9%，这主要是由于其在公共云资源的优化上下了很大功夫。Spotify 自研了追踪云计算开支的工具，同时鼓励工程师们掌握云计算支出的所有权，使其每年节省了几百万美元的云计算开支。在企业全面上云的浪潮之中，Kyligence Zen 指标中台很好地解决云成本管控场景中的挑战，帮助企业内部建立可观测的管理系统，对齐所有团队的运营过程。</p><p></p><p></p><h2>全球视角下看指标中台</h2><p></p><p></p><p>在海外，近年来有关<a href=\"https://www.infoq.cn/article/Kw3xSXDPMQOVrZAJMKpF\">现代化数据堆栈</a>\"的谈论持续掀起热浪。从更广阔的视角来看，指标中台其实就是现代化数据堆栈中一个非常重要的组成部分，在 Gartner 最新发布的 《指标中台创新洞察报告》(Innovation Insight: Metrics Stores) 中也证实了这一点，同时该报告将 Kyligence 列为指标中台的代表厂商。&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6f/6f91c7efd11fd427f7f71db64eec2672.jpeg\" /></p><p></p><p>现代数据堆栈技术是基于云原生数据平台的技术集合，用于降低运行传统数据平台的复杂性。在现代数据堆栈中，为什么需要指标中台呢？核心原因是现代的企业使用数据的场景加更多元，数据驱动已经涉及到了企业运用的各个方面，如果没有统一的指标中台，就会造成每个使用数据的下游都有自己的指标技术逻辑，利用数据进行决策时数据的不统一。</p><p></p><p>从现代化数据堆栈的维度，Kyligence Zen 指标中台更多地关注到了业务和管理，而非技术本身，更多关注到服务业务的用户，而不是服务 IT 或者底层的工程师。据韩卿介绍，Kyligence 指标中台曾帮助某股份制银行管理了超过 1.4 万多指标，成为他们非常核心的运营决策体系。他说：“我们希望 Kyligence Zen 能够成为数字化转型的重要平台，帮助客户构建整个数字化智慧体系。一个公司，没有度量就没有管理，而度量的核心就是指标，因此，Kyligence Zen 目标管理会更加偏重管理性的能力。”</p><p></p><p>从产品角度来看，韩卿表示，Kyligence Zen 未来将朝着更简化、更智能、成本更优化的方面不断改进。随着 AI 增强技术的演进，Kyligence 将通过更多 AI 能力的融合，给用户更多的智能的推荐，从而降低人力成本，帮助用户从数据中发现更多未知且有价值的洞察。</p><p></p><p>从行业趋势与价值来看，随着数字化转型的深入，业务人员将需要更加主动、自主的使用数据，管理指标。SaaS 产品本身方便、易用的特点适应时代的需求，而指标中台所提供的数据分析和决策能力，为企业管理、经营，更好的数字化转型提供新的方式和可能，有望引领数智时代新一轮数据分析的浪潮。</p>",
    "publish_time": "2022-09-28 10:53:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]