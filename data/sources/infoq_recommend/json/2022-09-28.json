[
  {
    "title": "Java 19新特性一览",
    "url": "https://www.infoq.cn/article/Zf6wLOe3l8elAjPlKiVz",
    "summary": "<p>Oracle<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2022-September/006933.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjQyNDcwMjcsImZpbGVHVUlEIjoia1ZJNXdhVUZMOTQ0Mk1pSCIsImlhdCI6MTY2NDI0NjcyNywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.6nEXDfklFT9wb-xCOB1PKgeV_pQVkXD20uU5xKolE3M\">发布</a>\"了Java 19及虚拟机。这个最终的特性集中包含了如下7个JEP。</p><p></p><p>JEP 405：记录模式（预览）；JEP 422：Linux/RISC-V移植；JEP 424：外部函数和内存API（预览）；JEP 425：虚拟线程（预览）；JEP 426：Vector API（第四轮孵化器）；JEP 427：switch的模式匹配（第三次预览）；JEP 428：结构化并发（孵化器）。</p><p></p><p>Java 19的新特性发布节奏与JDK 18的9个新特性差不多，但少于JDK 17的14个新特性、JDK16的17个新特性、JDK 15的14个新特性和JDK 14的16个新特性。</p><p></p><p>这个版本包含了来自Amber、Loom和Panama项目的JEP，以及将JDK移植到Linux/RISC-V指令集的新特性。我们在这里介绍其中的一些新特性。值得注意的是，在JDK 19中没有代表Valhalla项目的JEP。</p><p></p><h2>Panama项目</h2><p></p><p></p><p>JEP 424和JEP 426属于Panama项目，这个项目旨在改进和丰富JVM与“外来”（即非java）API之间的互操作性，这些API极有可能包含C语言库中常用的接口。</p><p></p><p>JEP 424，即外部函数和内存API（预览），为Java应用程序引入一个API，通过高效调用外部函数和安全访问不受JVM管理的外部内存来实现与Java运行时之外的代码和数据的互操作。这个JEP演化自JEP 419（即外部函数和内存API（第二轮孵化器），在JDK 18中交付）和JEP 412（即外部函数和内存API（孵化器），在JDK 17中交付），并针对Java社区的反馈进行了增强。</p><p></p><p>JEP 426，即Vector API（第四轮孵化器），根据前三轮孵化的反馈进行了改进——JEP 417（即Vector API（第三轮孵化器），在JDK 18中交付）、JEP 414（即Vector API（第二轮孵化器），在JDK 17中交付），以及JEP 338（即Vector API（孵化器），在JDK 16中作为孵化器模块交付）。JEP 426提议对Vector API进行增强，从MemorySegment（JEP 424，即外部函数和内存API（预览））加载或存储Vector。</p><p></p><p>关于如何实现外部函数和内存API的示例应用程序，可以在这个<a href=\"https://github.com/carldea/panama4newbies?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjQyNDcwMjcsImZpbGVHVUlEIjoia1ZJNXdhVUZMOTQ0Mk1pSCIsImlhdCI6MTY2NDI0NjcyNywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.6nEXDfklFT9wb-xCOB1PKgeV_pQVkXD20uU5xKolE3M\">GitHub代码库</a>\"中找到，由Azul的高级开发布道师Carl Dea提供。</p><p></p><h2>Loom项目</h2><p></p><p></p><p>JEP 425和JEP 428属于Loom项目，这个项目旨在探索、孵化和交付Java VM特性和API，其目的是支持易于使用、高吞吐量的轻量级并发和新的编程模型，可以通过虚拟线程、定界续体（Delimited Continuation）和尾部调用来实现。</p><p></p><p>JEP 425，即虚拟线程（预览），向Java平台引入了虚拟线程。这是一种轻量级线程，极大地减少了编写、维护和观察高吞吐量并发应用程序的工作量。</p><p></p><p>JEP 428，即结构化并发（孵化器），提议通过引入一个新的库来简化多线程编程，这个库将运行在不同线程中的多个任务视为单个工作单元。这可以简化错误处理和取消操作，提高可靠性，并增强可观察性。</p><p></p><p>关于如何实现虚拟线程和结构化并发API的示例应用程序可以在这些代码库中找到：由Oracle的Java开发布道师Nicolai Parlog提供的<a href=\"https://github.com/nipafx/loom-lab?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjQyNDcwMjcsImZpbGVHVUlEIjoia1ZJNXdhVUZMOTQ0Mk1pSCIsImlhdCI6MTY2NDI0NjcyNywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.6nEXDfklFT9wb-xCOB1PKgeV_pQVkXD20uU5xKolE3M\">GitHub代码库</a>\"和由Contrast Security公司高级软件工程师Bazlur Rahman提供的<a href=\"https://github.com/rokon12/project-loom-slides-and-demo-code?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjQyNDcwMjcsImZpbGVHVUlEIjoia1ZJNXdhVUZMOTQ0Mk1pSCIsImlhdCI6MTY2NDI0NjcyNywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.6nEXDfklFT9wb-xCOB1PKgeV_pQVkXD20uU5xKolE3M\">GitHub代码库</a>\"。</p><p></p><h2>Amber项目</h2><p></p><p></p><p>JEP 405和JEP 427属于Amber项目，这个项目旨在探索和培养较小的用于提升生产力的Java语言特性。</p><p></p><p>JEP 405，即记录模式（预览），提议用记录模式来解构记录值。记录模式可以与类型模式一起使用，“支持强大的、声明式的和可组合的数据浏览和处理形式”。类型模式最近已通过JEP 406（即switch的模式匹配（预览），在JDK 17中交付）和JEP 420（即switch的模式匹配（第二次预览），在JDK 18中交付）被用在switch的case子句中。</p><p></p><p>JEP 427，即switch的模式匹配（第三次预览），针对前两轮预览反馈进行了增强——JEP 406（即switch的模式匹配（预览），在JDK 17中交付）和JEP 420（即switch的模式匹配（第二次预览），在JDK 18中交付）。JEP 420以来的变更包括——保护模式被替换为switch块中的when子句；当选择器表达式的值为空时，模式switch的运行时语义与遗留switch的语义更为接近。</p><p></p><p>关于如何实现switch的记录模式和模式匹配的示例应用程序可以在这个<a href=\"https://github.com/wesleyegberto/java-new-features?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjQyNDcwMjcsImZpbGVHVUlEIjoia1ZJNXdhVUZMOTQ0Mk1pSCIsImlhdCI6MTY2NDI0NjcyNywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.6nEXDfklFT9wb-xCOB1PKgeV_pQVkXD20uU5xKolE3M\">GitHub代码库</a>\"的java-19目录中找到，作者是Global Points的Java技术主管Wesley Egberto。</p><p></p><h2>JDK 20</h2><p></p><p></p><p>目前还没有针对或者集成到JDK 20的JEP。但是，根据最近提交的JEP草案和JEP候选版本，我们在这篇<a href=\"https://www.infoq.com/news/2022/09/java-19-so-far/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjQyNDcwMjcsImZpbGVHVUlEIjoia1ZJNXdhVUZMOTQ0Mk1pSCIsImlhdCI6MTY2NDI0NjcyNywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.6nEXDfklFT9wb-xCOB1PKgeV_pQVkXD20uU5xKolE3M\">新闻报道</a>\"中猜测了哪些JEP有可能被包含在JDK 20中。</p><p></p><p>JDK 20的正式发布日期还没有公布，但按照6个月的发布节奏，它预计在2023年3月中旬发布，并在2022年12月中旬进行功能冻结。</p><p></p><p>JDK 19现在可以从<a href=\"https://jdk.java.net/19?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjQyNDcwMjcsImZpbGVHVUlEIjoia1ZJNXdhVUZMOTQ0Mk1pSCIsImlhdCI6MTY2NDI0NjcyNywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.6nEXDfklFT9wb-xCOB1PKgeV_pQVkXD20uU5xKolE3M\">Oracle网站</a>\"下载，其他二进制文件预计将在未来几天内可用。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/09/java19-released/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2NjQyNDcwMjcsImZpbGVHVUlEIjoia1ZJNXdhVUZMOTQ0Mk1pSCIsImlhdCI6MTY2NDI0NjcyNywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.6nEXDfklFT9wb-xCOB1PKgeV_pQVkXD20uU5xKolE3M\">Java 19 Delivers Features for Projects Loom, Panama and Amber</a>\"</p>",
    "publish_time": "2022-09-28 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "一文读懂网络框架Netty",
    "url": "https://www.infoq.cn/article/398qN2sicBSWUdTuSM5c",
    "summary": "<p></p><blockquote>作为稍微有点经验的 Java 开发者，应该多少都听过 Netty 的大名，但如果你要问 Netty 是什么，它的特色有哪些，实现机制如何，适用于什么场景并解决什么问题，能完整回答出来的人并不多。本文试着基于上述维度对 Netty 进行深入介绍，帮助读者对 Netty 知其然并知其所以然。</blockquote><p></p><p></p><h1>基础篇</h1><p></p><p></p><h2>Netty 是什么？</h2><p></p><p></p><p>首先我们来看 Netty 是什么，关于这个问题，其<a href=\"https://xie.infoq.cn/link?target=https%3A%2F%2Fnetty.io%2F\">官网</a>\"有一段阐述：</p><p></p><p></p><blockquote>Netty is a NIO client server framework which enables quick and easy development of network applications such as protocol servers and clients.</blockquote><p></p><p></p><p>这段翻译过来意思就是：</p><p></p><p></p><blockquote>Netty 是一个基于 NIO 的异步网络编程框架，基于 Netty 能快速的搭建高性能易扩展的网络应用（包括客户端与服务端）。</blockquote><p></p><p></p><p>具体来说，Netty 就是对于 Java NIO 的封装，NIO 又是什么呢？NIO 是 Java 1.4 后引入的基于事件模型的非阻塞 IO 框架，在 NIO 之前，对于数据的处理都是基于 BIO(blocking IO)，从名字上就知道 BIO 是以阻塞的形式对数据进行处理，这种处理形式比较简单，但是既然阻塞的，那么就不可避免会涉及到线程的操作。熟悉并发的小伙伴应该都知道，线程是一种昂贵的资源，无论是创建、销毁，还是切换，这就导致 BIO 在面对一些特定场景如高并发等束手无策，而这些场景在互联网应用中却又很常见。</p><p></p><p>对应的，NIO 能较好的应对这些场景。遗憾的是，Java 在刚推出 NIO 时，由于各种原因，致使其使用复杂，且经常会出现 Bug。结果就是：广大开发者有需求，但解决需求的工具就是不好用这样尴尬的局面，怎么办呢？ -- 自己动手，丰衣食足！大不了再造个\"轮子\"，所以就出现了一系列解决 NIO 问题的框架，而 Netty 就是其中最著名的那一个（当然 Java 发展到现在，其 NIO 库原本的很多问题都得到了解决，不过很多解决方案借鉴的也是 Netty 的思想）。</p><p></p><p>另外，Netty 并不止于解决 NIO 的问题，它更进一步，还提供了一系列特色功能。</p><p></p><h2>Netty 的特色</h2><p></p><p></p><p>下面是 Netty 官网对于 Netty 特色的说明：</p><p></p><p></p><blockquote>It greatly simplifies and streamlines network programming such as TCP and UDP socket server'Quick and easy' doesn't mean that a resulting application will suffer from a maintainability or a performance issue. Netty has been designed carefully with the experiences earned from the implementation of a lot of protocols such as FTP, SMTP, HTTP, and various binary and text-based legacy protocols. As a result, Netty has succeeded to find a way to achieve ease of development, performance, stability, and flexibility without a compromise</blockquote><p></p><p></p><p>这段话大概的意思就是：</p><p></p><p></p><blockquote>首先，Netty 能极大的简化你的网络编程；并且，简单好用还不需要以复杂的管理和低效的性能为代价，Netty 通过优秀的设计，在易部署，高性能，稳定性，扩展性之间找到了一个较好的平衡点</blockquote><p></p><p></p><p>我们把这句话提炼出来，大概就可以得到 Netty 的几大特色：</p><p></p><p>针对基本的需求提供了简单易用的接口，直接上手！针对复杂的场景提供了很强的扩展性，轻松应对业务发展！在上面两点的基础上，性能不打折！</p><p></p><p>而如果对这些特点进行细化，则可以得出：</p><p></p><p>基于事件机制（Pipeline - Handler）达成关注点分离（消息编解码，协议编解码，业务处理）可定制的线程处理模型，单线程，多线程池等屏蔽 NIO 本身的 bug性能上的优化相较于 NIO 接口功能更丰富对外提供统一的接口，底层支持 BIO 与 NIO 两种方式自由切换</p><p></p><p>这些特性将在本文第二部分「实现篇」里做详细分析；既然 Netty 的本质还是一个基于 NIO 的网络框架，那么想要掌握 <a href=\"https://xie.infoq.cn/article/f6dcd60b1ac50a2fa907201ee\">Netty </a>\"的精髓，对于 NIO 的了解就不可或缺。</p><p></p><h2>NIO 处理模型介绍</h2><p></p><p></p><p>在介绍 NIO 之前，最好了解一下 BIO，还没有学习过的小伙伴可以阅读我另外一篇介绍 BIO 的文章：<a href=\"https://xie.infoq.cn/link?target=https%3A%2F%2Fwww.jianshu.com%2Fp%2F83d5020f2734\">Java IO使用入门 -- IO其实很简单</a>\"。</p><p></p><p><a href=\"https://xie.infoq.cn/article/37e5691df67c0ee43b7db3d6d\">NIO</a>\" 是 Java 1.4 引入的一种同步非阻塞的 I/O 模型，也是 I/O 多路复用的基础；相对于 Java BIO(OIO)提供的基于面向流的阻塞式编程模型，NIO 提供的是面向缓冲区的响应式事件编程模型。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b6/b6f3b8debc05701f1a9dc40488867824.png\" /></p><p></p><p>读到这里可能有些人会觉得迷糊，什么阻塞？非阻塞？基于流？基于缓冲区？这里有必要介绍一下 Linux 下的 5 中 IO 模型：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/24/2457141ecb58108d49bd181be34255d9.png\" /></p><p></p><p>阻塞 I/O 模型：最常用的 I/O 模型就是阻塞 I/O 模型，当用户进程调用了 recvfrom 这个系统调用，kernel 就开始了 IO 的第一个阶段：准备数据（对于网络 IO 来说，很多时候数据在一开始还没有到达。比如，还没有收到一个完整的 UDP 包。这个时候 kernel 就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。而在用户进程这边，整个进程会被阻塞。当 kernel 一直等到数据准备好了，它就会将数据从 kernel 中拷贝到用户内存，然后 kernel 返回结果，用户进程才解除 block 的状态，重新运行起来。所以，blocking IO 的特点就是在 IO 执行的两个阶段都被 block 了。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/24/24a31990df21a97a9828fb83e151ea6a.png\" /></p><p>非阻塞 IO 模型：linux 下，可以通过设置 socket 使其变为 non-blocking。当对一个 non-blocking socket 执行读操作时，流程是这个样子：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/71/711cdc0b70977b6795db5a29c76b5e52.png\" /></p><p></p><p>当用户进程发出 read 操作时，如果 kernel 中的数据还没有准备好，那么它并不会 block 用户进程，而是立刻返回一个 error。从用户进程角度讲 ，它发起一个 read 操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个 error 时，它就知道数据还没有准备好，于是它可以再次发送 read 操作。一旦 kernel 中的数据准备好了，并且又再次收到了用户进程的 system call，那么它马上就将数据拷贝到了用户内存，然后返回；所以，nonblocking IO 的特点是用户进程需要不断的主动询问 kernel 数据好了没有。IO 复用模型：IO multiplexing 就是我们说的 select，poll，epoll，有些地方也称这种 IO 方式为 event driven IO。select/epoll 的好处就在于单个 process 就可以同时处理多个网络连接的 IO。它的基本原理就是 select，poll，epoll 这个 function 会不断的轮询所负责的所有 socket，当某个 socket 有数据到达了，就通知用户进程。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/74/749b2c5bea1e0a8cfbec2930342bb3c0.png\" /></p><p>当用户进程调用了 select，那么整个进程会被 block，而同时，kernel 会监视所有 select 负责的 socket，当任何一个 socket 中的数据准备好了，select 就会返回。这个时候用户进程再调用 read 操作，内核负责将数据从 kernel 拷贝到用户进程；所以，I/O 多路复用的特点是通过一种机制使得一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select()函数就可以返回，所以说它最大的优势是系统开销小，系统不需要创建或维护新的进程/线程。另外，从上面比较 IO 复用流程图和阻塞 IO 的图可以发现，多路复用本身也是阻塞的，事实上，其效率可能还更差一些。因为这里需要使用两个 system call (select 和 recvfrom)，而阻塞 IO 只调用了一个 system call (recvfrom)。但是，用 select 的优势在于它可以同时处理多个 connection。所以，如果处理的连接数不是很高的话，使用 select/epoll 的 web server 不一定比使用阻塞 IO 的 web server 性能更好，可能延迟还更大。select/epoll 的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。）在 IO 复用模型中，对于每一个 socket，一般都设置成为 non-blocking，但是，如上图所示，整个用户的 process 其实是一直被 block 的。只不过 process 是被 select 这个函数 block，而不是被 socket IO 给 block。信号驱动 IO 模型：首先开启套接口信号驱动 I/O 功能,并通过系统调用 sigaction 执行一个信号处理函数（此系统调用立即返回，进程继续工作，它是非阻塞的）。当数据准备就绪时，就为该进程生成一个 SIGIO 信号。随即可以在信号处理程序中调用 recvfrom 来读数据，井通知主循环函数处理数据；一般用的较少。异步 IO：在异步 IO 模型下，用户进程发起 read 操作之后，立刻就可以开始去做其它的事。而另一方面，从 kernel 的角度，当它收到一个 asynchronous read 之后，首先它会立刻返回，所以不会对用户进程产生任何 block。然后，kernel 会等待数据准备完成，然后依然由它将数据拷贝到用户内存，当这一切都完成之后，kernel 会给用户进程发送一个 signal，告诉它 read 操作完成了。</p><p><img src=\"https://static001.geekbang.org/infoq/38/38b9ed584d29a3f42d2f89db469c8228.png\" /></p><p>介绍完这 5 种 IO 模型后，我们回到 NIO，NIO 基于的是 IO 复用模型（就是上面的第三种 IO 模型），正如在介绍 IO 复用模型时已提到，而在 linux 下，有三种针对该模型的实现，分别为：select，poll，epoll；select 和 poll 的实现机制类似，主要区别在于描述 fd 集合的方式不同，poll 使用 pollfd 结构而不是 select 的 fd_set 结构；epoll 是 linux 2.6 后才有的，它主要是对 select 和 poll 的缺陷做了一些改进。</p><p></p><p>这两种实现方式有几个比较大的缺点：1) 每次调用 select，都需要把 fd 集合从用户态拷贝到内核态，这个开销在 fd 很多时会很大 2) 每次调用 select 都需要在内核遍历传递进来的所有 fd，这个开销在 fd 很多时也很大 3) select 支持的文件描述符数量太小了，默认是 1024（当然可以手动改，但改大了不一定效果好，以为前面的 1,2 两点）对于第一个缺点，epoll 在每次注册新的事件到 epoll 句柄中时，会把所有的 fd 拷贝进内核，而不是在 epoll_wait 的时候重复拷贝。这样就保证了每个 fd 在整个过程中只会拷贝一次。</p><p></p><p>对于第二个缺点，epoll 的解决思路是每当一个 fd 准备就绪，就调用对应的回调函数将其加入一个就绪链表，然后只需要遍历这个就绪链表即可，不需要遍历所有 fd。</p><p></p><p>对于第三个缺点，epoll 没有这个限制，它所支持的 fd 上限是最大可以打开文件的数目，这个数字一般远大于 1024,举个例子,在 1GB 内存的机器上大约是 10 万左右，具体数目可以 cat /proc/sys/fs/file-max 察看，一般来说这个数目和系统内存关系很大。</p><p></p><p>另外顺便提一下 Windows 下的异步 IO 实现机制：I/O Completion Ports，或简称 IOCP，个人觉得它的设计比较好，极大的减少线程切换对性能的影响，同时又能保证 CPU 保持在较高的利用率，有兴趣可以阅读：<a href=\"https://xie.infoq.cn/link?target=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fwindows%2Fwin32%2Ffileio%2Fi-o-completion-ports\">https://learn.microsoft.com/en-us/windows/win32/fileio/i-o-completion-ports</a>\"。</p><p></p><h1>实现篇</h1><p></p><p></p><h2>Netty 总体结构</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/c2/c2df8d4b47fca9ac082d61d67bfa5923.png\" /></p><p></p><p>这张图摘自 Netty 官网，其展示的是 Netty 的模块结构，总体来说，Netty 分为两大模块：</p><p></p><p>核心模块核心模块主要提供的是 Netty 的一些基础类和底层接口，主要包含三部分：</p><p>用以提升性能，减少资源占用的 Zero-Copy-Capable Rich Byte Buffer，即「零拷贝」缓冲区，Netty 里的「零拷贝」与操作系统语境下的「零拷贝」不是同一个概念，具体会在后续章节做阐述。统一的 API，这是 Netty 对外宣传的简单易用 API 的一部分，什么意思呢？就是 Netty 为同步和异步 IO 提供统一的编程接口，举个例子，如果在前期希望使用 BIO，后续随着业务变动，希望改用 NIO，只需要改动几个简单的初始化参数，而不需要变动主体流程；相反，如果一开始不是基于 Netty，而是直接基于 BIO 书写处理流程，后期想改成 NIO，其变动是很大的，毕竟是两个不同的接口模块。易扩展的事件模型，这里的重点在于易扩展，因为 NIO 本身就是基于事件的 IO 模型，而扩展性很好理解，如果一个框架无法扩展，那么也就意味着无法应对业务的变化。</p><p></p><p>服务模块既然 Netty 的核心是 IO，那么其服务模块基本也就和 IO 操作分不开了，主要有：</p><p>网络接口数据处理相关服务，如报文的粘包，拆包处理，数据的加密，解密等各网络层协议实现服务，主要包括传输层和应用层相关网络协议的实现文件处理相关服务</p><p></p><h2>Netty 处理架构</h2><p></p><p></p><p>介绍完 Netty 的模块结构，我们再来看一下它的处理架构：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/46/46fbcfbd63870d028fdb3a4019a94be9.png\" /></p><p></p><p>Netty 的架构也很清晰，就三层：</p><p></p><p>底层 IO 复用层，负责实现多路复用。通用数据处理层，主要对传输层的数据在进和出两个方向进行拦截处理，如编/解码，粘包处理等。应用实现层，开发者在使用 Netty 的时候基本就在这一层上折腾，同时 Netty 本身已经在这一层提供了一些常用的实现，如 HTTP 协议，FTP 协议等。</p><p></p><p>一般来说，数据从网络传递给 IO 复用层，IO 复用层收到数据后会将数据传递给上层进行处理，这一层会通过一系列的处理 Handler 以及应用服务对数据进行处理，然后返回给 IO 复用层，通过它再传回网络</p><p></p><h2>基于 Reactor 模式的 IO 复用</h2><p></p><p></p><p>在 Netty 处理架构图中，可以看到在 IO 复用层上标注了一个「Reactor」：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a0/a03a4e31a2dfe2a52c3f7a03dbc656c5.png\" /></p><p></p><p>这个「Reactor」代表的就是其 IO 复用层具体的实现模式 -- Reactor 模式</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/24/249cfcb81ca31445c5fcb900d7070400.png\" /></p><p></p><p>这张图是从大名鼎鼎的<a href=\"https://xie.infoq.cn/link?target=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FDoug_Lea\">Doug Lea</a>\"的一份演讲稿中截取下来的，通过这张图示，就可以大致明白什么是 Reactor 模式了。在 Reactor 模式中，分为主反应组（MainReactor）和子反应组（subReactor）以及 ThreadPool，主反应组（MainReactor）负责处理连接，连接建立完成以后由主线程对应的 acceptor 将后续的数据处理（read/write）分发给子反应组（subReactor）进行处理，而 Threadpool 对应的是业务处理线程池；对应代码为：</p><p><code lang=\"undefined\">EventLoopGroup bossGroup = new NioEventLoopGroup(1);\nEventLoopGroup workerGroup = new NioEventLoopGroup(1);\n\nServerBootstrap b = new ServerBootstrap();\n            b.group(bossGroup, workerGroup)\n            ...</code></p><p></p><p>在这段代码中 bossGroup 对应的就是主反应组（MainReactor），workerGroup 对应的是子反应组（subReactor），而NioEventLoopGroup其实就是一个实现了 Java ExecutorService的线程池，其中的线程数可定制，若不设置线程数参数，则该参数值默认为2 * CPU核数量，在ServerBootstrap的初始化过程中，会为其添加一个实现了acceptor机制的Handler</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/da/da3f9452b473bc141a451b215b10db27.png\" /></p><p></p><p>而通过ServerBootstrapAcceptor，会在 Channel 建立后触发channelRead()方法，并在channelRead()内将此 Channel 绑定至子反应组对应的处理线程，后续的数据处理就交于它进行处理</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ae/ae1faabcdffe4f93778db72076b8449b.png\" /></p><p></p><p>在阅读这部分源码的时候需要注意一个点，按理来说，连接的建立应该是ACCEPT事件，怎么会触发channelRead()呢 ？其实 netty 内部将READ和ACCEPT状态一并作为 read 的触发条件。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/88/885289d18f5ddb0d4b155931b157bc41.png\" /></p><p></p><p>介绍完了 Netty 关于 IO 复用层的实现，继续看其「易扩展」和「关注点分离」的核心：Pipeline。</p><p></p><h2>基于责任链模式的 Channel-Pipeline</h2><p></p><p></p><p>同样回过头去再看 Netty 处理架构图中的中间层 -- Pipeline。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b8/b8b77f7378b7a1ba5f1fb2230a1e22e9.png\" /></p><p></p><p>其字面意思为「管道」，顾名思义，管道的作用就在于传输，而对于 Netty 来说，它的管道传输的当然就是数据了，在本位「基础篇」关于 Netty 基础的介绍里，提到它有一个很重要的特色就在于：基于事件机制（Pipeline - Handler）达成关注点分离（消息编解码，协议编解码，业务处理），而Pipeline就是实现这一特色的核心所在，我们下面来看 Netty 是如何实现所谓的「易扩展」和「关注点分离」的。</p><p></p><p>首先，Netty 的Pipeline从数据传输的方向上来看分为进和出，这个和 BIO 相同；其次，最重要的在于 Netty 在Pipeline上通过责任链模式插入一系列的「Handler」，这一结构是它能实现「易扩展」和「关注点分离」的关键。想想看，所谓 IO，不就是数据的「进」和「出」吗？而进来干啥呢？当然就是需要应用逻辑对其处理，那处理完了呢？还需要送回给请求方以示响应，而在进的过程中需要哪些处理逻辑，这些处理逻辑的先后顺序如何，处理完后出去的过程中需要哪些处理逻辑，这些处理逻辑的顺序又是如何，如果这些都可以方便的配置调整，是不是就达到了 Netty 宣称的「易扩展」和「关注点分离」（只需关注业务相关的 Handler，网络协议相关的 Handler 直接调用即可，IO 复用更无须关注）呢？</p><p></p><p>在 Netty 里，这一实现机制的核心类叫做ChannelPipeline：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/af/afc49bff9b0315600300a1782c70712c.png\" /></p><p></p><p>其中Channel负责数据通信，Handler负责逻辑处理，而ChannelPipeline就相当于一个由Handler串起来的处理链条，在 Neety 源码里有一个关于ChannelPipeline的比较形象的图形化描述：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2c/2c2e401dc926373cb7e80d7d25159fe5.png\" /></p><p></p><p>看到没有，其实很简单，就是一个针对不同方向数据流的责任链，其中Inbound对应的是输入流，Outbound对应的是输出流（在这里再多提一句，责任链模式在很多框架里都有使用，比如 Spring MVC 里看到的各种 Handler，也是基于责任链的封装）。</p><p></p><h2>强大的 ByteBuf</h2><p></p><p></p><p>既然是对 Netty 进行分析，就必然绕不过 Netty 自己封装的数据缓冲区：ByteBuf，它是 Netty 对外宣称的高性能的重要支撑，另外有必要提一下，在 Netty 里其核心缓冲区类叫「ByteBuf」，以便与 NIO 本身的缓冲区类「ByteBuffer」做区分，ByteBuf 有如下特点：</p><p></p><p>功能丰富的接口，Java NIO 本身的缓冲区接口比较简单支持零拷贝，提升性能，减少资源占用支持动态扩展缓冲区初始块大小动态控制读写切换不需要手动调用 clear()，flip()；使用过 Java NIO 的小伙伴应该知道，其在进行读写切换时需要不停的通过 clear()和 flip()进行模式切换，很麻烦池化，提升性能，减少资源占用</p><p></p><p>下面将对上面提到的几个 ByteBuf 的重要特性进行实现分析，首先来看下 ByteBuf 是如何避免 NIO 中那繁琐的读写切换的。我们知道，对于 Java NIO 的 Buffer，其有几个重要的属性：position，limit，capacity，其中position代表的是下一个读或写的位置，limit是可被读或写的最高位，而capacity就是 Buffer 的容量了，之所以要在读和写切换的时候进行手动操作（clear()，flip()），主要是因为在 NIO 中，position和limit在读的时候代表的是下一个需读的位和可读的最高位，但是在写的时候又代表下一个需写的位和可写的最高位（其实就是capacity），换句话说这两个变量在不同的操作场景下有不同的含义，对应值也不同，所以需要在读写切换的时候进行手动操作。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/44/44b484cf605c1c8283efcab92780dd34.png\" /></p><p></p><p>而 Netty 的 ByteBuf 则对这一点做了改进，其针对读写操作分别增加上了readerIndex，writerIndex，使用的时候不需要考虑读写转换。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/24/24d819b315c3cd5aa34068577ec90324.png\" /></p><p></p><p>读的时候就变动readerIndex的值，而此时可读的最高位（对应 NIO 中的 limit）其实就是writerIndex，同理写的时候就变动writerIndex，此时可写的最高位（对应 NIO 中的 limit）就是capacity，说白了就是两个变量分别管理读和写的操作位，互不冲突，也就不存在读写切换的时候手动操作了；其实看到这里我们可以发现，NIO 在接口设计的时候确实没有考虑周到，毕竟 Netty 的这种优化并不是有多难！</p><p></p><h4>零拷贝 Buf</h4><p></p><p></p><p>在分析 ByteBuf 的「零拷贝」特性之前，先说说什么是「零拷贝」，所谓「零拷贝」, 通常指的是在 OS 层面上为了避免在用户态(User-space) 与 内核态(Kernel-space) 之间进行数据拷贝而采取的性能优化措施；例如 Linux 提供的 mmap 系统调用，它可以将一段用户空间内存映射到内核空间，当映射成功后，用户对这段内存区域的修改可以直接反映到内核空间；同样地，内核空间对这段区域的修改也直接反映用户空间。正因为有这样的映射关系，我们就不需要在用户态(User-space) 与内核态(Kernel-space) 之间拷贝数据，从而提高了数据传输的效率；对于 Java 的网络操作来说，网络接口在收到数据的时候需要先将数据复制到内核内存，然后在从内核内存复制到用户内存，同理往网络接口发数据也是先将数据从用户内存复制到内核内存，再从内核内存中将数据传给网络接口，所以如果是直接操纵内核内存，无疑处理的性能会更好。</p><p></p><p>回到 Netty，Netty 中的 「零拷贝」与上面我们所提到到 OS 层面上的 「零拷贝」其实不太一样，Netty 的 「零拷贝」 完全是在用户态里的，或者说更多的是偏向于减少 JVM 内的数据操作，具体体现在如下几个方面：</p><p></p><p>通过 CompositeByteBuf类，将多个ByteBuf合并为一个逻辑上的ByteBuf，避免了各个ByteBuf之间的拷贝通过wrap操作，将byte[]数组、ByteBuf、ByteBuffer等多个数据容器合并成一个ByteBuf对象，进而避免了拷贝操作通过slice操作，将ByteBuf分解为多个共享同一个存储区域的ByteBuf，避免了内存的拷贝通过FileRegion包装的FileChannel.tranferTo实现文件传输，将文件缓冲区的数据发送到目标Channel，避免了传统通过循环write方式导致的内存拷贝问题</p><p></p><p>这些操作之所以能避免不必要的拷贝操作，其实就在于内部对数据进行的是逻辑操作而非物理操作，操作完成后根据各逻辑引用的数据信息（大小，位置等）重新计算ByteBuf内部的控制属性（limit，capacity，readerIndex，writerIndex），如通过CompositeByteBuf将原本两个分别表示 head 和 body 的 buffer 组装成一个 buffer：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a7/a7a14c39c67a2dfd6cd430068d8f56d4.png\" /></p><p></p><p>虽然看起来CompositeByteBuf是由两个ByteBuf组合而成的，不过在CompositeByteBuf内部，这两个ByteBuf都是单独存在的（指针引用），CompositeByteBuf只是逻辑上是一个整体；这样在数据操作的时候不需要对数据进行物理挪动，只需要操作数据引用并计算关键因子即可，这种方式不但能提升性能，还可以减少内存占用，值得借鉴。</p><p></p><h4>Buf 池化</h4><p></p><p></p><p>在 Netty 中，ByteBuf 用来作为数据的容器，是一种会被频繁创建和销毁的对象，ByteBuf 需要的内存空间，可以在 JVM Heap 中申请分配，也可以在 Direct Memory（堆外内存）中申请，其中在 Direct Memory 中分配的 ByteBuf，其创建和销毁的代价比在 JVM Heap 中的更高，但抛开哪个代价高哪个代价低不说，光是频繁创建和频繁销毁这一点，就已奠定了效率不高的基调。Netty 为了解决这个问题，引入了池化技术，池化技术的思想不复杂，和线程池思想类似，说白了就是对一些可重用的对象用完不回收，后面需要再次使用，以减少创建和销毁对象带来的资源损耗，下面结合 Netty 源码对其池化技术做剖析。</p><p></p><p>首先看ByteBuf，它实现了ReferenceCounted接口，表明该类是一个引用计数管理对象</p><p></p><p><code lang=\"undefined\">public abstract class ByteBuf implements ReferenceCounted, Comparable</code></p><p></p><p>而引用计数就是实现池化的关键技术点（不过并非只有池化的 ByteBuf 才有引用计数，非池化的也会有引用），继续看ReferenceCounted接口，它定义了这几个方法：</p><p></p><p><code lang=\"python\">public interface ReferenceCounted {\n    int refCnt();\n\n    ReferenceCounted retain();\n\n    ReferenceCounted retain(int increment);\n\n    boolean release();\n\n    boolean release(int decrement);\n}</code></p><p></p><p>每一个引用计数对象，都维护了一个自身的引用计数，当第一次被创建时，引用计数为 1，通过refCnt()方法可以得到当前的引用计数，retain()和retain(int increment)增加自身的引用计数值，而release()和release(int increment)则减少当前的引用计数值，如果引用计数值为 0，并且当前的 ByteBuf 被释放成功，那这两个方法的返回值就为true。而具体如何释放，各种不同类型的 ByteBuf 自己决定，如果是池化的 ByteBuf，那么就会重新进池子，以待重用；如果是非池化的，则销毁底层的字节数组引用或者释放对应的堆外内存。具体的逻辑在AbstractReferenceCountedByteBuf类中可以看到：</p><p></p><p><code lang=\"text\">@Override\npublic final boolean release() {\n    for (;;) {\n        int refCnt = this.refCnt;\n        if (refCnt == 0) {\n            throw new IllegalReferenceCountException(0, -1);\n        }\n\n        if (refCntUpdater.compareAndSet(this, refCnt, refCnt - 1)) {\n            if (refCnt == 1) {\n                deallocate();\n                return true;\n            }\n            return false;\n        }\n    }\n}</code></p><p></p><p>释放对象的方法定义在 deallocate() 方法里，它是个抽象方法，既然是抽象的，那么就需要子类自行实现，对于非池化的 HeapByteBuf 来说，释放对象实际上就是释放底层字节数组的引用：</p><p></p><p><code lang=\"text\">@Override\nprotected void deallocate() {\n    array = null;\n}</code></p><p></p><p>对于非池化的DirectByteBuf来说，释放对象实际上就是释放堆外内存：</p><p></p><p><code lang=\"text\">@Override\nprotected void deallocate() {\n    ByteBuffer buffer = this.buffer;\n    if (buffer == null) {\n        return;\n    }\n\n    this.buffer = null;\n\n    if (!doNotFree) {\n        PlatformDependent.freeDirectBuffer(buffer);\n    }\n\n    if (leak != null) {\n        leak.close();\n    }\n}</code></p><p></p><p>对于池化的 ByteBuf 来说，就是把自己归还到对象池里：</p><p></p><p><code lang=\"text\">@Override\nprotected final void deallocate() {\n    if (handle &gt;= 0) {\n        final long handle = this.handle;\n        this.handle = -1;\n        memory = null;\n        chunk.arena.free(chunk, handle);\n        if (leak != null) {\n            leak.close();\n        } else {\n            recycle();\n        }\n    }\n}</code></p><p></p><p>熟悉 JVM GC 的同学应该对这个引用计数的机制不会感到陌生，因为 JVM 在判断一个 Java 对象是否存活时有一种方式使用的就是计数法；另外 Netty 的池化缓存在实现上借鉴了<a href=\"https://xie.infoq.cn/link?target=https%3A%2F%2Fwww.geeksforgeeks.org%2Foperating-system-allocating-kernel-memory-buddy-system-slab-system%2F\">buddy allocation和slab allocation</a>\"的思想并进行了比较复杂的设计（buddy allocation 是基于一定规则对内存进行分割，回收时进行合并，尽可能保证系统有足够的连续内存；而 slab allocation 是把内存分割为大小不等的内存块，请求内存是分配最贴近请求 size 的内存块，避免内存浪费），可以减少对象的创建与销毁对性能的影响，因为缓冲区对象的创建与销毁会占用内存带宽以及 GC 资源，另外由于池化缓存本身比较复杂，如线程私有池与全局共有池，其声明与释放都需要手动处理（比如本地池内的缓冲区对象如果不是在同一个线程内释放就会导致内存泄漏，这也是为什么 JVM GC 的时候需要有 Stop The World），Netty 提供了内存泄漏监控工具<a href=\"https://xie.infoq.cn/link?target=https%3A%2F%2Fnetty.io%2F4.0%2Fapi%2Fio%2Fnetty%2Futil%2FResourceLeakDetector.html\">ResourceLeakDetector</a>\"，如果发生了内存泄漏，它会通过日志记录并提醒，这个工具主要是防止对象被 GC 的时候其占用的资源没有被释放（如内存），或者没有执行release方法</p><p></p><p>也许有人会说，既然池化缓存实现复杂，用起来还得防止内存泄漏，那么它到底能给性能带来多大提升呢？我们可以看下 Twitter 对 Netty 池化缓存做的性能测试结果：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fa/fa2bbe6fb9182263251aed9b8db049e2.png\" /></p><p></p><p>这张图的 Y 轴显示的是创建对象花费的时间，而 X 轴代表的是所创建对象的大小，同时在实验中，使用了四种不同的对象，分别是非池化堆内存对象（Unpooled Heap），池化堆内存对象（Pooled Heap），非池化直接内存对象（Unpooled Direct），池化直接内存对象（Pooled Direct）。结果现实，随着被创建对象大小的增加，池化技术的优势愈加明显，当然当对象很小时，池化反而不如 JVM 本身的对象创建性能（可以结合 ByteBuf 的实现原理，想想为什么？）</p><p></p><p>除了对象创建的性能，Twitter 还测试了使用池化技术时 GC 相关的表现，实验模拟了在 16000 个连接下，对 256byte 大小的数据包进行循环传输：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2b/2b6e9ca89115a398afc0334bb42588e2.png\" /></p><p></p><p>结果表明，相对于非池化，池化的 GC 停顿减少了近 4 倍，而垃圾的增长也慢了 4 倍。所以说，Netty 对 ByteBuf 进行的复杂的重写还是值得的。</p><p></p><h2>NIO epoll 死循环问题及 Netty 解决方案</h2><p></p><p></p><p>最后说说 Netty 是如何解决著名的「NIO epoll 死循环」问题的。什么是「NIO epoll 死循环」呢？在 Linux 系统中，当某个 socket 的连接突然中断后，会重设事件集 eventSet，而 eventSet 的重设就会导致 Selector 被唤醒（但其实这个时候是没有任何事件需要处理的，select()方法应该还是处于阻塞状态），虽然被唤醒了，但其实是没有事件需要处理的，所以就又返回select()方法之前（正常情况下是处理完事件重新回去被select()阻塞），此时select()方法还是会直接返回，如此反复便造成死循环：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/37/3771360151fbd277fce96c5d234e00a0.png\" /></p><p></p><p>这个问题的原因本质上就是 NIO 的 Selector 实现有问题，Netty 解决的方式其实比较简单粗暴，它会记录一段时间内空轮询的次数，如果超过一定阈值，就认为这个 bug 出现了，此时会重新生成一个新的 selector 取代旧的 selector，避免死循环，具体的处理代码在NioEventLoop中：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7d/7d355379c564f488986dbcde7ab59236.png\" /></p><p></p><h2>Netty 主要类关系图</h2><p></p><p></p><p>这里贴一张 Netty 主要实现类的关系图，对需要阅读 Netty 源码的小伙伴可能有一个参考作用</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6a/6a7363fb2a9a1abcda8da7fe13a2b62d.png\" /></p><p></p><h1>总结篇</h1><p></p><p></p><h2>Netty 适用场景</h2><p></p><p></p><p>Netty 只是一套网络框架，它不可能适用于所有场景，所以选用 Netty 前最好能想清楚它是否能很好的应对自己的需求。想要知道 Netty 的适用场景最好的方式就是从 Netty 本身的特性出发进行思考，具体可参考本文「基础篇」中「Netty 的特色」章节，基于此，如果你的需求属于下列场景，则 Netty 会比较适合你，包括：</p><p></p><p>高并发，实时处理，如：游戏服务器，聊天服务器，SOA 调用框架，RPC 框架等。对网络协议（传输层与应用层）有一定的定制需求。一套代码可能需要同时支持 BIO 和 NIO。</p><p></p><p>而其他情况，Netty 并一不定适合，如：</p><p></p><p>需求较简单的网络应用，则不必使用 Netty，毕竟在能满足需求的基础上，越简单越好。单次请求处理耗时较长的应用，这种情况下 NIO 没有优势，此时使用 BIO 的方式可能效果会更好。</p><p></p><h2>Netty 支持的协议</h2><p></p><p></p><p>Netty 框架本身已经对常用的协议进行了实现，包括：</p><p></p><p>应用层：HTTP，WebSocket，HTTP2，Redis，SMTP，DNS，MQTT，SSL，STARTTLS ，RTSP。传输层：TCP，UDP，SCTP，UDT 等。其他：Protobuf，gzip。</p><p></p><p>可以说，一般的应用使用 Netty 本身的支持就能满足大部分需求，剩下的关注自己的业务即可</p><p></p><h2>Netty &amp; MINA &amp; Jetty</h2><p></p><p></p><p>Netty 和 MINA 经常会放在一起比较，主要是因为两个框架有很多相似的地方，或者说它们本身就是一对兄弟 -- 都是基于 Java NIO 封装的一个网络框架。其实更深入的了解会发现，Netty 的作者<a href=\"https://xie.infoq.cn/link?target=https%3A%2F%2Fgithub.com%2Ftrustin\">Trustin Lee</a>\"也是 MINA 的作者（当然已经不继续参与了），据说他是对 MINA 的代码不满意，才重新写了 Netty，所以看 Netty 的代码经常能看到 MINA 的影子，但就现在来说 Netty 的社区远比 MINA 要活跃，迭代频率也更高，大部分的特性也优于 MINA。</p><p></p><p>至于 Jetty 之所以会拿来比较，主要是因为和 Netty 名字类似，但其实这两者并没有很大的可比性，因为 Jetty 是一个轻量级的 servlet 容器，而 Netty 是一个基于 NIO 的异步网络编程框架，基于 Netty 可以实现自己的 servlet 容器或者其它网络应用。</p><p></p><h2>相关项目</h2><p></p><p></p><p>很多项目内部都使用 Netty 作为其网络处理模块，包括：</p><p><a href=\"https://xie.infoq.cn/link?target=https%3A%2F%2Fgithub.com%2Fapache%2Fincubator-dubbo\">Dubbo</a>\"<a href=\"https://xie.infoq.cn/link?target=https%3A%2F%2Fgithub.com%2Fapache%2Fspark\">Spark</a>\"<a href=\"https://xie.infoq.cn/link?target=https%3A%2F%2Fgithub.com%2Fplayframework%2Fplayframework\">Play framework</a>\"<a href=\"https://xie.infoq.cn/link?target=https%3A%2F%2Fgithub.com%2Felastic%2Felasticsearch\">Elastic search</a>\"</p><p></p><p>Netty 本身是一个优秀的框架，其源码的层次和结构也很清晰，值得一读；平常很多人说熟悉网络，但是大部分人也仅仅只是知道一些皮毛（也包括我自己）。其实，想要写一个健壮易用的网络框架并不容易，如果需要同时支持高并发，那更是难上加难，而 Netty 在这一点就做得很出色，不仅体现在其本身优秀的代码组织，更多的还是把一些已有的功能和思想进行合适的组装和适当的优化。</p><p></p><p>另外，结合当今另一个炙手可热的高性能服务器 Nginx 会发现，这两者的思想有很多相通之处，如都是基于事件机制，都分为主工作组与子工作组，都是在 PipeLine 上设置一系列的 Handler 进行数据处理，都有通过逻辑映射增强内存效率的设计等等，很有意思，感兴趣的小伙伴可以找寻相关资料进行延展阅读。</p><p></p><h4>作者介绍</h4><p></p><p></p><p>蔡昱星，飞书深诺首席架构师；主要专注于基于云原生的互联网架构设计与落地，当前重点关注企业系统架构领域，特别是如何更好的应对业务复杂度。</p>",
    "publish_time": "2022-09-28 10:48:07",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "SaaS时代，凭什么说数据分析的未来是指标中台",
    "url": "https://www.infoq.cn/article/4t6E7u2EOOlO4VNCNqRA",
    "summary": "<p>当前，数字化转型已成为很多企业的必修课。而面对如今的经济形势，企业为数字化转型迈出的每一步都至关重要。过去，不少企业为充分发挥数据价值，已经做了很多相关努力，从以 Hadoop 为核心的数据湖，到 Snowflake、Databricks 等云上数据仓库，再到<a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651090633&amp;idx=2&amp;sn=9041d6d7b134230132adeeb098b8d386&amp;chksm=bdb9969a8ace1f8c79cb06fe0b5d65619e053834f0d8ab2078923ca2e1e58958ba3135649f14&amp;scene=27#wechat_redirect\">湖仓一体化</a>\"...... 这些举措真的解决了与日俱增的数据问题吗？未必。今年 Gartner 发布的《分析查询加速的市场引导报告》就曾指出，企业在享受数据湖带来灵活性的同时，也承受着因数据使用和管理混乱带来的不利影响。</p><p></p><p></p><h2>传统BI 已经无法满足需求？</h2><p></p><p></p><p>事实上，不管是数据仓库、数据湖、还是湖仓一体，都是典型的中心化模式。随着云时代的到来，中心化的模式已不再适用。整个行业、架构、信息显现出新的趋势，去中心化的分析模式将是未来。</p><p></p><p>传统 BI 主要是依托于数据仓库作为支撑。传统数据集成系统位于本地的数据中心，而类似 Snowflake 这样的产品的出现颠覆了企业级数据仓库（EDW），在云和数据仓库之间找到了平衡。与传统数据仓库解决方案相比，云数据仓库安全灵活，且能够提供更多即时性、自主性和控制性。然而，想要用好云数据仓库却并不容易。首先，云数据仓库的核心功能并不是为多并发用户在大型数据集上提供交互式查询，其查询优化都是在其内部完成，因此，查询性能较差，且用户的发挥空间有限。其次，采用云数据仓库一旦超出标准，比如数据量过大或者希望获得更高的可用性及更快的获得结果，用户就需要负担超额的成本。</p><p></p><p>数据仓库的位置介于可视化报表和底层业务系统数据源之间。即便云数据仓库努力拥抱变化，但仍不能解决企业数据分析面临的难题，BI 项目解决方案的应用依托云数据仓库，也因此受到限制。</p><p></p><p>从业务维度，消费数据的人群也发生了变化。过去分析工具只提供给数据分析师这样专业的人员使用，而现在，更多的数据需要提供给一线业务人员使用。在这样的情况下，传统 BI 已无法满足需求。传统 BI 的确是非常专业的工具，但恰恰是因为过于专业，一线业务人员很难承担复杂知识背后的学习成本。根据 IBM 的统计数据，实施传统 BI 的项目失败率达到近 70%，大量的 BI 系统并没有得到有效的使用。究其原因是⽤⼾⽤不起来、不会⽤数据分析⼯具把业务和数据进⾏转换。</p><p></p><p>此外，采用传统 BI 工具必然会牵扯到团队间的协作，除了学习成本，还会带来巨大的沟通成本，导致数据无法及时、快速地反馈到数据使用者的手中。</p><p></p><p>一方面，数据分析项目从提出需求到最终交付，是一个漫长而繁琐的过程，需要进行数据源整合、指标定义、模型开发、数仓任务开发及运维、报表开发等一系列流程。更可怕的是，业务场景并非一成不变，一旦指标逻辑变更，数仓就要重新开发刷数。</p><p></p><p>另一方面，在实际使用过程中，传统 BI 很容易变成报表的游戏。传统 BI 的架构思维是数据通过 ETL 流向数据湖或数据仓库，并通过报表实现可视化。报表的需求与业务的需求和个人习惯有关。一旦业务需求或者人员发生变动，就需要重新进行报表开发，即使以往有类似的需求，报表也很难复用，这就造成严重的报表堆叠。</p><p></p><p>近年来，大量互联网公司都在不断使用更多的 SaaS 服务，而这些 SaaS 服务背后所产生的数据割裂在不同的云和 SaaS 产品之间。在这样的情况下，已无法使用以往的方式把数据汇集起来，进行建模，再制成报表给到业务人员，而需要更加敏捷的方式，为业务人员提供数据分析和决策的能力。</p><p></p><p>数据的基础架构、数据的使用对象、数据的消费方式都发生了变化。InfoQ 也于近日采访 Kyligence，一起聊了聊行业中的最新洞察与实践。在采访中，公司联合创始人兼 CEO 韩卿认为，当今已进入 SaaS 时代，面对 SaaS 时代带来的数据割裂及传统数据分析方式难以适用等诸多问题，就需要用 SaaS 的方式去解决。</p><p></p><p></p><h2>一站式云端指标中台的技术架构</h2><p></p><p></p><p>现代管理学之⽗彼得·德鲁克有⼀句⾮常经典的话：“What gets measured gets done”，意思是只有⼀个事情能被量化，才能够被解决。数据分析的目标就是找到能够量化业务的关键指标，从中进行洞察，并做出决策。</p><p></p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651110890&amp;idx=3&amp;sn=23b5863d76f0da1700ebf2826e46a87f&amp;chksm=bdb945b98aceccaf4dc207fb9071475b5d670eaa9ae652b5df355a19f200372e4f701fdfb4d5&amp;scene=27#wechat_redirect\">指标中台</a>\"的出现正是为了达成这一目标。</p><p></p><p>对于指标中台，来自领先的市场研究和咨询机构 Ventana Research 的 David Menninger 给出定义，指标中台是一个指标的仓库，存储了我们之前提到的各项规则，定义了如何进行计算以及对齐了与指标相关的各项目标。</p><p></p><p>在指标中台里，“指标”成为数据和业务交互的主体，通过对“指标”的标准化，进而实现数据开发和管理的标准化，有效衡量业务经营和发展情况。通过指标中台降低数据使用门槛，有效推动数据赋能一线业务，从而推进企业的数字化经营。</p><p></p><p>指标中台产品陆续面世，产品均以实现 OLAP 下的数据治理，减少计算逻辑和数据逻辑的重复为目标，但最终将走向何方，还需要进一步探索与实践。Kyligence 也于近日宣布推出了一站式云端指标中台 Kyligence Zen。据了解，Kyligence Zen 是处于数据层和应用层之间的指标中台，可以统一管理所有业务指标，自动完成数据加工、指标计算等过程，企业可以在不同应用中实现指标的复用，形成以指标为核心的共同语言，提高协同管理的效率。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3b/3b48967a2cfa4d6f14d9d0d1750fb5d2.jpeg\" /></p><p></p><p>Kyligence Zen 的本质其实是一款基于 Kyligence OLAP 能力打造的 SaaS 产品。用韩卿的话来说，SaaS 时代就需要⽤ SaaS 的⽅式解决数据分析面临的挑战。作为一款 SaaS 产品，Kyligence Zen 致力于把数据指标化，把指标智能化。相比于 BI 来说，Kyligence Zen 指标中台以更简单的方式，使业务人员能够更加个性化、自动化的使用好指标，并通过提供合适的指标模版，快速建立自己的指标体系。</p><p></p><p>随着云时代的到来，大量测试、开发、应用全都部署在了云上。据 Flexera 2020 State of the Cloud Report 统计，应用部署到云上之后将近 30%-35% 的资源被浪费。初创公司 Milkie Way 在对 Firebase 和 Cloud Run 进行内部测试期间，一不小心在几个小时里就在云上烧掉了 72,000 美元，差点导致这家公司破产。如果没有一个好的云端的费用的管控，成本方面就会形成一个巨大的黑洞。</p><p></p><p>通过 Kyligence Zen 可以帮助企业从事前规划、事中监控、事后评估三个阶段实现云成本管控。事前基于用途进行云资源规划，事中对所有云资源的使用情况进行持续监控，事后基于云账单建立指标体系，定期对指标进行管理和分析，帮助合理管控云成本。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c8/c80ef9493cb0e9e309dd7bc3ce9a7fb1.png\" /></p><p></p><p>Zoom 公司在 2021 年一季度的财报中称，其毛利率从前一季度的 69.4% 上升至 73.9%，这主要是由于其在公共云资源的优化上下了很大功夫。Spotify 自研了追踪云计算开支的工具，同时鼓励工程师们掌握云计算支出的所有权，使其每年节省了几百万美元的云计算开支。在企业全面上云的浪潮之中，Kyligence Zen 指标中台很好地解决云成本管控场景中的挑战，帮助企业内部建立可观测的管理系统，对齐所有团队的运营过程。</p><p></p><p></p><h2>全球视角下看指标中台</h2><p></p><p></p><p>在海外，近年来有关<a href=\"https://www.infoq.cn/article/Kw3xSXDPMQOVrZAJMKpF\">现代化数据堆栈</a>\"的谈论持续掀起热浪。从更广阔的视角来看，指标中台其实就是现代化数据堆栈中一个非常重要的组成部分，在 Gartner 最新发布的 《指标中台创新洞察报告》(Innovation Insight: Metrics Stores) 中也证实了这一点，同时该报告将 Kyligence 列为指标中台的代表厂商。&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6f/6f91c7efd11fd427f7f71db64eec2672.jpeg\" /></p><p></p><p>现代数据堆栈技术是基于云原生数据平台的技术集合，用于降低运行传统数据平台的复杂性。在现代数据堆栈中，为什么需要指标中台呢？核心原因是现代的企业使用数据的场景加更多元，数据驱动已经涉及到了企业运用的各个方面，如果没有统一的指标中台，就会造成每个使用数据的下游都有自己的指标技术逻辑，利用数据进行决策时数据的不统一。</p><p></p><p>从现代化数据堆栈的维度，Kyligence Zen 指标中台更多地关注到了业务和管理，而非技术本身，更多关注到服务业务的用户，而不是服务 IT 或者底层的工程师。据韩卿介绍，Kyligence 指标中台曾帮助某股份制银行管理了超过 1.4 万多指标，成为他们非常核心的运营决策体系。他说：“我们希望 Kyligence Zen 能够成为数字化转型的重要平台，帮助客户构建整个数字化智慧体系。一个公司，没有度量就没有管理，而度量的核心就是指标，因此，Kyligence Zen 目标管理会更加偏重管理性的能力。”</p><p></p><p>从产品角度来看，韩卿表示，Kyligence Zen 未来将朝着更简化、更智能、成本更优化的方面不断改进。随着 AI 增强技术的演进，Kyligence 将通过更多 AI 能力的融合，给用户更多的智能的推荐，从而降低人力成本，帮助用户从数据中发现更多未知且有价值的洞察。</p><p></p><p>从行业趋势与价值来看，随着数字化转型的深入，业务人员将需要更加主动、自主的使用数据，管理指标。SaaS 产品本身方便、易用的特点适应时代的需求，而指标中台所提供的数据分析和决策能力，为企业管理、经营，更好的数字化转型提供新的方式和可能，有望引领数智时代新一轮数据分析的浪潮。</p>",
    "publish_time": "2022-09-28 10:53:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "瓜分 28 万现金大奖，Tapdata 数据源 Connector 大赛等你来战！",
    "url": "https://www.infoq.cn/article/8a4f148a2c9f51e6c78b48008",
    "summary": "<p>“让数据使用像打开水龙头使用自来水一样简单”——秉承 Data on Tap 的远大愿景，<a href=\"https://tapdata.net/\">Tapdata</a>\" 深知一个人、一个公司的力量是有限的，在通往目标的路上，有大量挑战在等待着我们。我们需要社区的声音、用户的鞭策、开发者的参与等多方的力量，一同将产品打磨得更强。这是 Tapdata 的开源基因与初衷。</p><p></p><p>值得高兴的是，从踏出开源第一步起，Tapdata 积累了越来越多开发者的关注。随着更多新鲜力量涌入社区，面对大家的期待，我们也在不断探索助力 Tapdata 开源项目加速成长的更多可能。一方面为了吸引更多优秀的开发者参与共建，同时也为了活跃社区，回馈项目贡献者，Tapdata 数据源 Connector 挑战赛（第一届）于今日正式开幕！积累开发经验，瓜分28万现金大奖，我们在这里，等一个热爱技术的你！</p><p></p><h2>【大赛介绍】</h2><p></p><p></p><p>Tapdata 数据源 Connector 挑战赛是由 <a href=\"https://tapdata.net/\">Tapdata Inc.</a>\"「深圳钛铂数据有限公司」主办的面向全体开发者的开源项目贡献回馈活动。以赛制简单、普惠设奖为特色，本次挑战赛围绕「如何使用 Tapdata 完成数据源接入任务？」这一赛题展开，教程清晰，文档完整，旨在与开发者携手共创，点亮更多数据源，开发成果共享，让更多数据源与目标的互通成为可能，共同打造一个具备更广泛连接性的数据平台。欢迎每一位想要尝试或“练手”的开发者。</p><p></p><p>*精彩预告：后续伴随大赛进入第二期，我们的赛制模式也会逐步迈向新的阶段，为达到为开发成果付费的目的，我们将开启收益共享计划，让参与进来的项目贡献者真正享受到成果上线的持续收益。</p><p></p><h3>一、活动亮点</h3><p></p><p></p><p>① 参与完成即可领奖：任务奖+邀请奖，惊喜好礼等你来赢取！</p><p>② 简单容易上手：提供开发指南，小白也能轻松上手！</p><p>③ 数据技能提升：积累数据开发经验，简化数据链路的开发流程，又好又快地完成数据源和目标端的开发工作。</p><p>④ 技术资源共享：获得异构数据实时同步和 Fluent ETL 的能力。</p><p></p><h3>二、奖项设置</h3><p></p><p></p><p>本次活动设置了丰厚的贡献者奖励，经 Tapdata 产研协同审核，基于对提交的新数据源的完成质量综合评估，将对审核通过的任务所属开发者予以奖品激励：</p><p></p><p>奖项一：参与并完成任务，赢现金大奖</p><p><img src=\"https://static001.geekbang.org/infoq/57/57f6a0a01b9beff64f865191183a9524.png\" /></p><p></p><p>奖项二：邀请参赛者，赢 Tapdata 定制礼品</p><p></p><p>无论是参赛者还是未参赛者，都可以将挑战赛分享给好友并邀请好友参赛，达标后你将获得 Tapdata 双肩包、T恤、多功能无线充电套装、技术图书等丰厚礼品。</p><p><img src=\"https://static001.geekbang.org/infoq/b7/b7cbad086ac0015e3989a9e7dbc24e08.jpeg\" /></p><p>奖品发放时间：</p><p></p><p>每月15日中午12:00前完成数据源开发任务并通过审核的，会在25日发放对应现金奖励。每月30日中午12:00前完成数据源开发任务并通过审核的，会在次月10日发放对应现金奖励。邀请奖，在达标后可自助通过 Tapdata 积分商城进行礼品兑换。</p><p></p><p>*官方联络人：Tapdata 开源小助手（Tapdata2022），将会即时为大家报送参赛结果及奖品发放情况。</p><p></p><h3>三、赛制玩法</h3><p></p><p></p><h4>① 活动时间</h4><p></p><p></p><p>即日起-11月30日，在活动截止时间之前提交结果，即视为参与活动成功。请各位开发者注意提交时间。</p><p></p><h4>② 如何参与</h4><p></p><p></p><p>1. 任务领取：</p><p></p><p>Fork <a href=\"https://github.com/tapdata/tapdata.github.io/blob/main/plugin-contributor-program/plugin-contributor-program.md\">项目页面</a>\"，在数据源列表（数据源任务列表预览见文末）中相应数据源的贡献者栏中，写上自己的 GitHub Username 并提交 PR。经管理人员审核并合并 PR 即视为任务认领成功，可以进入开发阶段。</p><p></p><p></p><blockquote>活动详情页：<a href=\"https://github.com/tapdata/tapdata.github.io/blob/main/plugin-contributor-program/plugin-contributor-program.md\">https://github.com/tapdata/tapdata.github.io/blob/main/plugin-contributor-program/plugin-contributor-program.md</a>\"</blockquote><p></p><p></p><p>2. 结果提交：</p><p></p><p>完成开发后，可将结果以 issue/PR 的形式提交至认领任务的评论列表中，交由管理人员审核。</p><p></p><p>*更多开发指南及项目详情，可点击<a href=\"https://github.com/tapdata/tapdata.github.io/blob/main/plugin-contributor-program/plugin-contributor-program.md\">此处</a>\"查看。</p><p></p><p></p><blockquote>参赛小贴士：各位参与活动的开发者在领取任务时需要特别注意，避免重复认领，合理分配任务时间，尽可能让大家机会相对均等地参与到各个任务中来，不浪费任务名额。每位开发者至少认领1个任务，同一位开发者可领取多个任务；认领任务后，如果该认领者超过3周未提交对应的数据源结果，则该数据源任务自动释放，除认领者以外的开发者可重新认领。</blockquote><p></p><p></p><h3>四、立即参赛</h3><p></p><p></p><p>如果你也想从早期开始参与一个很潜力无限的开源项目，共同为社区作贡献；如果你也想和众多同样热爱技术的开发者一起，共创一个优秀的实时数据平台，欢迎点击<a href=\"https://github.com/tapdata/tapdata.github.io/blob/main/plugin-contributor-program/plugin-contributor-program.md\">这里</a>\"，即刻评论认领任务！</p><p></p><h4>【附数据连接器任务列表】</h4><p></p><p><img src=\"https://static001.geekbang.org/infoq/20/204b9546084516ab328cd7f940adadd3.png\" /></p><p></p><h4>官方通知第一接收阵地</h4><p></p><p></p><p>无论是技术交流还是测试问题反馈，欢迎扫描下方二维码，添加 Tapdata 开源小助手并回复关键词【挑战赛报名】，加入官方讨论群进行沟通！</p><p><img src=\"https://static001.geekbang.org/infoq/76/760eb5f1ecdf8aad31f731db6599bac9.jpeg\" /></p><p></p>",
    "publish_time": "2022-09-28 11:23:23",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "「非结构化数据峰会」精彩速递丨Zilliz Cloud 首发、Milvus 技术演进、生态实践全揭秘",
    "url": "https://www.infoq.cn/article/21W2hWlxTurCWpfr8qp9",
    "summary": "<p></p><p>2022 年 9 月 24-25 日，首届非结构化数据峰会（2022 Unstructured Data Summit）在线上举行。本次峰会由 Zilliz 主办，主题为「矩阵革命，向量连接世界」，峰会设置了一系列 Keynote 和分论坛演讲，围绕人工智能在非结构化搜索领域的顶尖技术、热门话题、前沿观察展开分享和探讨，共同探索行业发展的新风向。</p><p>&nbsp;</p><p>对于主办方 Zilliz，如果近期有关注科技圈投融资动态的话，应该对它不陌生。不久前，向量数据库公司 Zilliz 宣布完成 6000 万美元的新一笔融资，通过这轮融资 Zilliz 成功将其&nbsp;B 轮融资规模进一步扩大至 1.03 亿美元。</p><p>&nbsp;</p><p>这家刚满 5 岁的数据库公司正在做什么？这次的非结构化数据峰会又给行业带来了哪些新风向？</p><p>&nbsp;</p><p></p><h2>Zilliz 全新产品发布，非结构化数据 ETL 流水线详解</h2><p></p><p>&nbsp;</p><p></p><h3>Zilliz Cloud 首发并公布架构图</h3><p></p><p>&nbsp;</p><p>互联网快速发展至今天，全球仍然有 80% 的数据都以非结构化的形态存在，它们很难被有效利用，释放数据原本的价值。在过去的几十年中，虽然计算机已经能够高效处理普通的数值和文本类结构化数据，但对于图片、音视频、行为画像、化合物三维结构，以及基因序列等这些广泛存在的非结构化数据依旧不知所措，业界缺乏有效的非结构化数据处理手段。</p><p>&nbsp;</p><p>在首届「非结构化数据峰会」上，Zilliz 创始人兼 CEO 星爵表示，非结构化数据因其自身的特点，天然难以被洞悉和管理，如何做好非结构化数据的处理，将会是广大企业面临的巨大挑战；作为较早研究非结构化数据的公司，Zilliz 已经取得了一定的成果，包括早前发布的 Towhee、Milvus、Attu、Feder 等项目，能够实现端到端的向量提取与转化、向量存储与分析、数据库图形化管理、算法处理过程可视化等。</p><p>&nbsp;</p><p>此次峰会上，Zilliz 又有一款新产品发布，即全托管 <a href=\"https://www.infoq.cn/article/ioBQo5TUMyf5yE8w0dg1\">Milvus</a>\" 服务 Zilliz Cloud，定位为一个非结构化数据处理的云服务。</p><p>&nbsp;</p><p>Zilliz Cloud 是 Milvus 开源社区原班人马基于全球最流行的开源向量数据库 Milvus 打造的全托管向量检索服务，在具备高可用、高可拓展、安全合规的基础上，提供了更加丰富的生态能力和开箱即用的高性能向量检索方案。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1d/1d8a0139ee1ceda3213f7e83385a1497.jpeg\" /></p><p></p><p>Zilliz 合伙人兼技术总监栾小凡向 InfoQ 表示：“Zilliz Cloud 最大的优势在于背靠 Milvus 开源社区。首先 Zilliz Cloud 的开发团队是 Milvus 的原班人马，我们可能是最了解非结构化数据和向量检索的那一拨人；另外这些年来通过在社区跟开源用户不断地交流、探讨，我们深知这个领域用户的需求和应用场景；除此之外，我们团队的工程师都非常有经验，几乎都构建过大规模、高可用的一些解决方案，同时也知道怎么去最大化利用 Milvus 的能力，我们更清楚 Milvus 这个系统应该用什么样的参数去跑，出了问题以后怎么样去解决。”</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h3>Towhee：非结构化数据 ETL 流水线详解</h3><p></p><p></p><p>数据库托管后，又该如何进行非结构化数据的处理，如何通过最低成本来构建 AI 应用，实现模型在业务落地呢？</p><p>&nbsp;</p><p>Zilliz 合伙人和产品总监郭人通博士，在其主题分享《Towhee：非结构化数据 ETL 流水线》中指出，在非结构化数据中提取/嵌入向量、数据标签和属性等信息，是构建 AI 应用，实现数据分析、检索的关键。为此，Zilliz 技术团队打造了 <a href=\"https://xie.infoq.cn/article/a12a0aee573f7b4f59fb2fa96\">Towhee</a>\" 这个专注于非结构化数据 ETL 的框架，它能帮助各行各业把各种不同的非结构化数据更加简便地转变成向量。</p><p>&nbsp;</p><p>通过使用 Towhee，任何用户都能够基于 Python 代码一键构建面向生产的高性能非结构化数据处理流水线。Towhee 提供了一套优雅的函数式 Python 编程接口，以及一组覆盖日常工作所需要的工具集，只需要几行代码，就能够自动解决以下问题：将推理流水线内出现的代码（模型、算法、数据处理过程等）转换成对应的高性能实现，组织端到端的推理服务代码，一键生成 Docker 镜像等。</p><p>&nbsp;</p><p>对于 Towhee 的研发历程，郭人通向 InfoQ 表示：“去年六七月份，我们受到一个社区诉求的启发，产生了研发一款非结构化数据 ETL 流水线的想法，10 月份 Towhee 0.1 版本诞生，之后进入了持续的模型验证阶段，直到今年 6 月份，我们推出了一个基于 Python 的、易用的、流水线定义的编程接口，开始做大量的面向性能和场景执行效率相关的工作，这个月底我们还将发布 Towhee 0.9 版本，新版本在一些大的视频、音频这类流式数据的处理效果上，会有比较大的提升。”</p><p>&nbsp;</p><p>未来，Towhee 将在现有的 pipeline 定义接口上提供一个类似于 Spark、 Flink 的流水线定义接口；同时将更加深入地集成英伟达的技术生态，进一步提升整个流水线面向生产的一个执行效率；最后 Towhee 也会应社区很多用户的需求，去解决关于中文模型缺口的问题等。</p><p>&nbsp;</p><p>在 Zilliz 的定义里，尽管 Towhee 是一个年轻的项目，但是它作为非结构性数据快速转换为向量的框架，实际上是使用 Milvus 系统的前一站。</p><p>&nbsp;</p><p>作为 Zilliz 的核心产品， Milvus 又是如何一步步成长为现在的样子的呢？</p><p>&nbsp;</p><p></p><p></p><h2>从开源中来：Milvus 开源数据库的演进之路</h2><p></p><p>&nbsp;</p><p>峰会上，Linux Foundation AI &amp; Data 基金会执行董事 Ibrahim Haddad 带来了《加速中的开源人工智能创新与合作》主题分享，他分享了开源项目 Milvus 是如何为 Linux 基金会书写了一段成功的故事，以及基金会在 AI &amp; Data 领域如何帮助初创项目进行孵化、互惠共赢。</p><p>&nbsp;</p><p>LF AI &amp; Data 是 Linux 基金会的一个伞形基金会，支持人工智能、机器学习、深度学习和数据的开源创新。创建 LF AI &amp; Data 是为了支持开源 AI、ML、DL 和数据，并创建一个可持续的开源 AI 生态系统，让使用开源技术创建 AI 和数据产品和服务变得容易。LF AI &amp; Data 鼓励在中立的环境下以开放的治理进行协作，以支持开放源码技术项目的协调和加速。&nbsp;</p><p>&nbsp;</p><p>星爵向 InfoQ 表示，2019 年 Zilliz 将 Milvus 项目正式开源，2020 年初便捐献给了 Linux Foundation AI &amp; Data 基金会，随后的几年 Milvus 发展成全球最流行的向量数据库系统之一；凑巧的是就在峰会前夕， Milvus 项目超越了 ONNX 以及 Horovod 项目，成为了基金会里 star 数量最多的开源项目。</p><p>&nbsp;</p><p>Ibrahim Haddad 指出，Milvus 项目于 2020 年 1 月加入 Linux Foundation AI &amp; Data 基金会，只用了一年半时间便成功毕业，目前已经有超过 1600 名贡献者参与到这个项目，其中超过一半为持续活跃的贡献者；最令他感到惊讶的是，过去两年项目的提交增长了 270%，而项目的拉取请求周期只有 2.23 天，这意味着 Zilliz 团队花了非常多的时间在社区维护上。</p><p>&nbsp;</p><p>从最初的想法萌生到 Milvus 开源，只用了一年的时间，随后便发布了 Milvus 1.0 版本；但是伴随非结构化数据的爆发式增长，1.0 版本下的数据孤岛、架构耦合、缺乏弹性、迭代慢等问题开始变得严重，如何让 Milvus 支撑千亿级向量动态扩展以及云原生等能力成为了横亘在眼前不得不解决的问题。为了解决以上问题，Milvus 团队下定决心去开发一个新的版本——Milvus 2.0。</p><p>&nbsp;</p><p>在经过了一系列的测试之后，Milvus 2.0 于今年 2 月份正式发布，Milvus 2.0 是完全基于云原生架构进行开发的一个全新版本。随后经历了持续半年多的用户反馈、生产环境的经验积累，Milvus 2.0 更进一步迭代，性能更优、生态更完善、适配场景更丰富的 Milvus 2.1 于 7 月份发布。</p><p>&nbsp;</p><p>相比于 2.0 版本， Milvus 2.1 支持内存多副本、查询高可用，能够解决读写分离及高并发等问题，另外还支持了 String 类型，系统性能也得到了大幅提升，比如支持了 ANN 索引，加入了全新的智能调度引擎，实现了 3.2倍的性能提升，延迟低至 5ms 等。</p><p>&nbsp;</p><p>值得一提的是，Zilliz 团队计划在 9 月底/10 月初推出更新的 Milvus 2.2 版本，新版本将重点改进运维友好性、可观测性和稳定性。</p><p>&nbsp;</p><p>Zilliz 首席工程师焦恩伟表示，在 Milvus 2.2 版本中最重磅的功能便是增加了磁盘索引（DiskANN）这一选项，相比于传统的纯内存索引方案，<a href=\"https://xie.infoq.cn/article/7299b3f5c7e39634a4fe9eab1\">DiskANN</a>\" 可以把用户的本地磁盘作为存储索引，牺牲少量的查询性能，但能换来大幅成本降低，用户可以使用更低成本的具备 SSD 且内存更小的机器进行数据库部署。同时新版本还将增加数据批量导入、RBAC 权限控制、查询 Pagination、限流与反压等功能。</p><p>&nbsp;</p><p>Zilliz 向 InfoQ 表示，下一代的 Milvus 将重点围绕 AI 中台 / AI 业务两大用户群、高性能向量库 / 海量向量分析两大场景的需求继续进行迭代升级。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>到实践中去：Milvus 向量数据库的技术挑战与场景实践</h2><p></p><p>&nbsp;</p><p>随着 AI 技术的快速发展和非结构化数据的爆炸式增长，基于向量的数据分析技术开始被普遍应用。然而，由于向量数据天然的高维特性，对其分析时的算力和存储需求远高于传统标量数据。如何快速高效地对分析向量数据，是近年来在学术界和工业界都备受关注的一个问题。</p><p>&nbsp;</p><p>Zilliz 研究团队负责人和高级研究员易小萌博士将 Milvus 向量数据库面临的挑战总结为三点：向量数据处理的维度灾难、多路折衷的问题、复杂的查询语义挑战，并从数学的角度对这三个挑战进行了阐释。</p><p>&nbsp;</p><p>针对 Milvus 向量检索的实际应用，易小萌举了一个商品搜索的例子：用户给出一个商品图片，除了想要搜索出跟这个图片上的商品一样或近似的商品外，很可能还希望看到它的价格。这种情况下，向量检索不仅仅要找到相似的向量，还需要找到该向量所携带的一些属性、条件等。从数学上的定义就是每一个 item 具备一个向量和一个属性的标签。Milvus 需要在给定一个向量查询需求的同时也给到一个属性的过滤条件，最后在符合属性过滤条件的向量里找到 K 个最相似的向量，然后进行合并分析，从而得出最接近用户需求的答案。</p><p>&nbsp;</p><p>事实上，Milvus 向量数据库系统及相关技术早已在很多行业进行了场景验证。比如金融支付场景下，翼支付利用 Milvus 构建了更加智能的金融风控体系；视频直播场景，Milvus 帮助虎牙团队快速进行敏感区域特征识别与检索，提高视频内容安全审查效率；社交场景，Milvus 助力陌陌进行垃圾信息甄别、假照识别等；深度学习场景，Milvus 语义索引库帮助百度<a href=\"https://www.infoq.cn/article/X7FT1HAdybceki0EWix4\">飞桨</a>\" PaddleNLP 提高语义检索的精准性等。</p><p>&nbsp;</p><p>当然，目前非结构化数据和向量搜索依然是一个非常新的领域，除了需要更多的场景落地验证外，还需要更多的开发者与企业加入进来，共同构筑行业新生态。</p><p>&nbsp;</p><p></p><h2>向量连接世界：非结构化数据搜索的技术生态与未来</h2><p></p><p>&nbsp;</p><p>当前围绕非结构化数据检索的开源技术生态处于快速发展和变革期，领域内的开源技术生态成熟度将直接影响上层应用的规模与成本，做出正确的技术决策，选择开放、活跃的生态社区，将是企业实现降本增效的最核心的手段之一。</p><p>&nbsp;</p><p>Zilliz 合伙人和产品总监郭人通博士在其主题分享《非结构化数据搜索的工具链与技术生态》中提到，在应用生态层面，非结构化数据搜索在图搜、视频搜索、文本语义搜索、跨通道搜索、推荐/问答系统、版权保护、欺诈检测、数据查重、网络安全、药物发掘、异常检测等场景有着良好的应用前景；在行业生态层面，当前非结构化数据生态的基础软件和工具远远少于结构化数据生态，未来有着非常广阔的增长空间。</p><p>&nbsp;</p><p>但是，不得不承认的是当前非结构化数据检索在可用性、安全性、性能、可靠性、可扩展性等方面依然面临较多的用户痛点。由于缺乏基础组件工具，各个关键技术点很难被串联起来，最终可能陷入“重复造轮子”的窘境，无法向客户输出系统性解决方案。</p><p>&nbsp;</p><p>面对这些问题，Zilliz 开发了一系列的工具去解决一些关键应用环节的问题。在部署阶段，Zilliz 提供了 Milvus Sizing Tool 工具，能够自动生成部署脚本，帮助用户快速布置一个分布式的、大规模的向量数据库软件；在运维阶段，Zilliz 提供了开源工具 Attu，能够帮助用户管理硬件资源、负载状态等等；在业务提效方面，Zilliz 提供了一个向量召回工具 Feder，面向不同索引、不同层面，可视化地告诉用户召回过程中发生了什么，以及数据之间的关系是怎样。另外，Zilliz 还将上述工具进行整合，开发出了一个全托管的向量数据库 SaaS 云平台，也就是刚刚发布的 Zilliz Cloud。</p><p>&nbsp;</p><p>除了内部三件套工具的集成外，在外部生态方面，Milvus 携手百度飞桨社区共建 AI 基础设施开源生态；Towhee 与上海人工智能实验室 OpenDataLab 社区开展了开放数据集领域的生态合作，打通 AI 落地的最后一公里；模型层面，Milvus 已经完成了与 Huggingface、TIMM、TorchVision 等软件的生态对接；数据处理层面，集成了 Numpy、OpenCV、FFmpeg 等开源软件；服务层面，也已经与 Docker、Triton、ONNX、TensorRT 等进行了连通等。目前 Milvus 和 Towhee 也在积极寻求生态合作，希望与合作伙伴们共同完善非结构化数据搜索的技术生态。</p><p>&nbsp;</p><p>最后，借用 Zilliz 创始人兼 CEO 星爵的话来说，“十年后回头看现在，非结构化数据的价值几乎是完完全全没被挖掘出来的。”非结构化数据领域是一个全新的赛道，未来十年，一定会有更多的创新应用、场景涌现，而在生态建设的过程中，需要更多的开发者、产业链伙伴、创业公司加入进来，一起去探索、去共建非结构化数据的未来。</p>",
    "publish_time": "2022-09-28 13:50:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "英特尔CEO基辛格：摩尔定律仍然有效！ 希望2030 年一个芯片可封装 1 万亿个晶体管",
    "url": "https://www.infoq.cn/article/07JFquThmH4DbC9iMqIx",
    "summary": "<p></p><p>InfoQ获悉，北京时间9月28日凌晨1点，英特尔On技术创新峰会开幕，英特尔CEO帕特・基辛格在开幕主题演讲中带来了多款重磅发布，并分享了他对芯片制造、摩尔定律失效、开发者面临的挑战等方面的观点。</p><p></p><h2>五大超级技术力量</h2><p></p><p></p><p>“我们正处于一个新时代，技术在人类生存的方方面面越来越重要”。</p><p></p><p>帕特・基辛格认为，未来十年，一切都将继续数字化。计算、连接、基础设施、人工智能，以及传感和感知这五大基础的超级技术力量将深刻地塑造我们体验世界的方式。 随着这五大基础的超级技术力量越来越普及，它们相互结合、互相加强，将释放出全新的可能性。</p><p></p><p>此前，帕特・基辛格一直在提“四大超级技术力量”，最近在与客户、同行和媒体的交流中，他觉得应该将“传感和感知”加入其中。万物数字化不只是计算和连接，也在进一步“看到”一切，甚至还有我们“看不到”的，比如，识别目标，辨别位置，甚至机器也有了听觉、味觉和嗅觉。</p><p></p><h2>摩尔定律“死”了吗？</h2><p></p><p></p><h3>帕特・基辛格：摩尔定律仍然有效，还将一往无前</h3><p></p><p>摩尔定律是英特尔联合创始人戈登·摩尔对半导体行业创新的预测，芯片中集成的晶体管数量大约每24个月翻一番，同时价格下降为之前的一半。后来，这个周期缩短到18个月。</p><p></p><p>近年来，行业关于摩尔定律失效的讨论甚嚣尘上。主题演讲中，帕特·基辛格分享了自己对摩尔定律失效的看法。</p><p></p><p>帕特・基辛格认为，人们长期以来一直怀疑摩尔定律的“寿命”，但“摩尔定律还将继续向前发展。“摩尔定律很有效，至少在未来的十年里依然有效”。</p><p></p><p>他表示，英特尔还将一往无前，挖掘元素周期表中的无限可能，持续释放硅的神奇力量。</p><p></p><p>英特尔已经制定了在4年内交付5个节点的大胆计划。Intel 18A 制程 PDK 0.3 版本现在已经被早期设计客户采用，测试芯片正在设计中，将于年底流片。凭借 RibbonFET、PowerVia 两大突破性技术， High-NA 光刻机等先进技术，英特尔希望到 2030 年在一个芯片封装上可以有 1 万亿个晶体管。</p><p></p><p>“英特尔和英特尔代工服务将开创系统级代工的时代”，这一模式由四个主要部分组成：晶圆制造、封装、软件和开放的芯粒生态系统。“曾经被认为不可能实现的创新已经为芯片制造带来了全新可能”，帕特·基辛格表示。</p><p></p><h3>黄仁勋：摩尔定律已经死亡</h3><p></p><p>有趣的是，在上周英伟达GTC2022 秋季发布会后的媒体采访中，英伟达创始人兼CEO黄仁勋也发表了对摩尔定律的看法。不过，他持有相反的观点，他认为“摩尔定律结束了。”</p><p></p><p>英伟达在GTC2022上发布的40系显卡因价格过高而备受争议。RTX4090的官网售价提升为12999元，较RTX3090上涨了8%。</p><p></p><p>黄仁勋解释，价格大幅上涨的其中一个原因是，与上一代RTX 3000相比，其最新的RTX 4090提供了更高的性能，RTX4090性能提升了2到4倍，而不仅仅是摩尔定律的双倍性能。为了实现这种性能的飞跃，不仅仅是硬件，英伟达已经在整个堆栈上进行了大量投资。 “未来是关于加速全栈的，你必须想出新的架构，想出尽可能好的芯片设计。”</p><p></p><p>黄仁勋表示，鉴于RTX4090性能的大幅提升，摩尔定律已经死亡。他还表示，消费者将无法再拿一半的价钱买到相同的性能。以类似成本实现两倍业绩预期对于该行业来说“已成为过去”。</p><p></p><p>“今天12英寸的晶圆要贵得多，不是贵了一点点，是贵了非常非常多。”黄仁勋说，“现在技术越来越贵，所以我们必须使用更多办法，像RTX、DLSS、SCR、Tensor Cores这样的发明，使我们能够继续克服成本的增加。”</p><p></p><h2>意外惊喜：Linux 之父压轴出场</h2><p></p><p>主题演讲的最后，Linux 之父 Linus Torvalds 作为惊喜嘉宾压轴出场。</p><p></p><p>现场，帕特还亲自给Linux 之父颁发了第一个英特尔创新奖，以表彰他的技术成就。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/6e/3a/6e741f568901cbcba3bdb69101483e3a.png\" /></p><p></p><p></p><p></p><p>帕特・基辛格说，“当我们实现开放、选择和信任时，我们的集体潜力就会得到释放，Linux 之父 Linus 是几十年来我一直钦佩的人，没有比‘开源教父’和 Linux 的创造者更支持开放、协作系统的了”。</p><p></p><p>Linus现场谈了对开源的看法，“我喜欢开源，喜欢在社区工作，这是为了让事情一起完成，我不是一个人（在做事）。但与此同时，社区也确实激励了我”。</p><p></p><h2>重磅发布</h2><p></p><p>主题演讲中，帕特·基辛格列举了开发者所面临的一系列挑战，例如供应商锁定（vendor lock-in）、新型硬件的获取、生产力、上市时间和安全问题，并介绍了英特尔帮助开发者应对这些挑战的众多解决方案，介绍了英特尔产品组合的最新进展。</p><p></p><h3>台式机处理器性能的新标准：第13代英特尔®酷睿™处理器</h3><p></p><p>会上，英特尔发布了第13代英特尔®&nbsp;酷睿™&nbsp;处理器产品家族，第13代英特尔®&nbsp;酷睿™&nbsp;i9-13900K处理器是该系列中的旗舰产品。全新的产品家族包括六款未锁频的台式机处理器，拥有最多高达24核心和32线程，睿频频率最高高达5.8GHz，提供超凡的游戏、直播和录制体验。</p><p></p><p>与上一代处理器相比，实现了15%的单线程性能提升1和41%的多线程性能提升，帮助用户更好地畅享游戏、进行内容创作和高效工作。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/6d/06/6d2766ce44a44bb2803283b4yy43ff06.png\" /></p><p></p><p>以英特尔酷睿K系列处理器为首，第13代英特尔酷睿台式机家族将包含22款处理器和超过125款合作伙伴的机型设计，为用户提供强大应用性能和平台兼容性。凭借现有的英特尔®&nbsp;600或全新英特尔®&nbsp;700芯片组主板，发烧友用户可以畅享第13代英特尔酷睿处理器的出众性能。产品支持最新的DDR5和既有的DDR4内存，用户在享受第13代酷睿所带来的性能优势的同时，也可以根据自己的功能需求和预算组装机器。</p><p></p><p>英特尔执行副总裁Michelle Johnston Holthaus表示，全新第13代英特尔酷睿旗舰级处理器再次提升了PC性能的标杆。第13代英特尔酷睿家族是体现英特尔在所有PC细分市场带来令人震撼体验的又一例证。</p><p></p><p>采用成熟的Intel 7制程工艺和x86高性能混合架构，第13代英特尔酷睿台式机处理器实现了超越以往的出众系统性能，即使是要求苛刻的多任务工作负载也不在话下。其单线程性能和多线程性能分别最多提高了15%2和41%。</p><p></p><p>在最新产品家族中，英特尔的高性能混合架构整合了英特尔迄今为止最快速的性能核和最高多达两倍的能效核，提升了单线程和多线程性能。为用户带来多项体验提升：</p><p></p><p>提升游戏体验。全新酷睿i9-13900K拥有多达24核心（8性能核，16能效核）和32线程，带来超凡的游戏、直播和录制体验。最多高达5.8 GHz的睿频频率和最多提升15%的单线程性能，让这款处理器推高了游戏帧率，为畅玩游戏大作带来震撼体验3。持续提升内容创作性能：第13代英特尔酷睿处理器增加了能效核（E-Cores）数量，并在运行多个计算密集型工作负载时将多线程性能最多提升高达41%，让用户保持才思泉涌，在创作工作流中轻松施展才华。超频体验：用户可以看到性能核（P-Cores）、能效核（E-Cores）和DDR5内存都达到更高的平均超频速度。为支持第13代酷睿处理器，英特尔还更新了极具便捷性的一键超频功能Intel®&nbsp;Speed Optimizer，以帮助用户轻松地超频。Intel®&nbsp;Extreme Memory Profile（XMP）3.0生态系统提供了多种超频模块选择。与Intel®&nbsp;Dynamic Memory Boost搭配使用时，此功能可以轻松实现DDR4和DDR5内存的超频。通过多项全新和改进的特性，第13代英特尔酷睿台式机处理器在游戏、内容创建和办公等方面向用户提供卓越性能和体验，包括：Intel®&nbsp;Adaptive Boost Technology 和 Thermal Velocity Boost——在运行特定工作负载时，根据功率和热余量适时地提升处理器睿频。两项技术适用于未锁频的酷睿i9处理器中发挥作用。通过增加更多能效核，酷睿i5、i7、i9处理器实现了多线程性能的飞跃，为用户提供更好的多任务及大型任务的应用体验。支持PCIe Gen 5.0，处理器上总共有多达16条。增加了对DDR5-5600和DDR5-5200的支持，同时继续兼容DDR4。L2缓存大小增加一倍并增加L3缓存大小。伴随着第13代英特尔酷睿台式机处理器的发布，英特尔还将推出全新英特尔700系列芯片组，配备提升可靠性和性能的先进功能。基于PCIe Gen 3.0通道和8条额外的PCIe Gen 4.0通道，全新的英特尔700系列芯片组总通道达到28条，通过更多USB 3.2 Gen 2x2（20 Gbps）端口提高了USB连接速度，而DMI Gen 4.0可增加芯片组到CPU的吞吐量，帮助快速访问外设和网络。此外，英特尔带来了向前和向后兼容性。使用英特尔600芯片组的主板，也可以畅享第13代英特尔酷睿处理器的出众性能。</p><p></p><p>第13代英特尔酷睿K系列台式机处理器和英特尔Z790芯片组将于10月20日开始发售，包括盒装处理器、主板和台式机系统。</p><p></p><h3>英特尔Geti计算机视觉平台</h3><p></p><p>全新协作式英特尔®&nbsp;Geti™计算机视觉平台（此前代号为Sonoma Creek）能够助力各种行业从业者——从数据科学家到各领域的专家快速、轻松地开发有效AI模型。通过用于数据上传、标注、模型训练和再训练的单一接口，</p><p></p><p>英特尔Geti计算机视觉平台可助力开发团队减少模型开发所需时间，并降低AI开发技术门槛及开发成本。借助内置的针对OpenVINO的优化功能，开发团队还可以在其企业中部署高质量计算机视觉AI解决方案，以推动创新和自动化发展，并提高生产力。</p><p></p><h3>英特尔开发者云平台</h3><p></p><p>推进开放的生态系统是英特尔转型的核心，对英特尔的成功而言，开发者社区也起着至关重要的作用。</p><p></p><p>英特尔开发者云平台融合了丰富的开发者工具和资源，包括英特尔®&nbsp;oneAPI工具包和英特尔Geti平台等，有助于加快基于英特尔平台的解决方案的上市时间。</p><p></p><p>据介绍，英特尔开发者云平台（Intel Developer Cloud）即将扩展支持全新技术。英特尔开发者云平台正在启动小范围的尝试，让开发者和合作伙伴能够更早、更高效地获得英特尔技术，早至产品上市前几个月乃至一整年。</p><p></p><p>参与测试的客户和开发者可以在未来几周内测试和验证英特尔的多种最新平台，包括第四代英特尔®至强®可扩展处理器（Sapphire Rapids）、内置高带宽内存（HBM）的第四代英特尔®至强®处理器、英特尔®至强®D处理器、Habana®&nbsp;Gaudi®&nbsp;2深度学习加速器、英特尔®数据中心GPU（代号为Ponte Vecchio）和英特尔®数据中心GPU Flex系列。</p><p></p><h3>更多GPU新品</h3><p></p><p>GPU是英特尔的一个增长引擎。帕特·基辛格还分享了英特尔不同领域GPU的进展，</p><p></p><p>内置代号为Ponte Vecchio的英特尔数据中心GPU的刀片式服务器，现已出货给阿贡国家实验室，将为极光超级计算机提供驱动力。</p><p></p><p>8月发布的英特尔数据中心GPU Flex系列，为客户提供了基于单一GPU来满足广泛智能视觉云工作负载需求的解决方案。它还将支持时下热门的行业AI和深度学习框架，包括OpenVINO、TensorFlow和PyTorch。</p><p></p><p>英特尔发布了面向游戏玩家的锐炫GPU，锐炫™&nbsp;A770将于10月12日以329美元的起售价和多种产品设计登陆零售市场，提供出色的内容创作和1440p游戏性能。</p><p></p><p>此外，英特尔的XeSS超级采样技术，能够在英特尔独立显卡和集成显卡上为游戏性能提供加速，现有许多游戏将陆续推出更新补丁开启支持，预计今年内会有超过20款游戏支持XeSS技术。XeSS SDK现已在GitHub上线。</p><p></p><p>英特尔多设备协同技术（Intel®&nbsp;Unison™）是全新的软件解决方案，在手机（Android和iOS）和电脑之间提供了无缝的连接，包括文件传输、短信、电话和手机通知等功能。今年晚些时候开始将应用于新的笔记本电脑。</p><p></p><p>在数据中心方面的最新进展是，第四代英特尔至强可扩展处理器内置一系列加速器，主要用于人工智能、数据分析、网络、存储和其他高需求的工作负载。通过全新的英特尔®按需激活模式，用户可以在原始SKU的基本配置之外，开启额外的加速器组合，在业务有需求时获得更大的灵活性和更多的选择。</p>",
    "publish_time": "2022-09-28 13:53:11",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "传统大数据平台如何进行云原生化改造",
    "url": "https://www.infoq.cn/article/bzIkh26ufTd4X41jGJ7y",
    "summary": "<p></p><p>以<a href=\"https://xie.infoq.cn/article/2e99710bb06d38840aa69d5d6\"> Hadoop</a>\" 为中心的大数据生态系统从 2006 年开源以来，一直是大部分公司构建大数据平台的选择，但这种传统选择随着人们的深入使用，出现的问题也越来越多，比如：数据开发迭代速度不够快、集群资源利用效率过低、新的开发工具集成非常复杂等。这些问题已经成为困扰企业数字化转型加速迭代和升级的主要障碍。</p><p></p><p>而传统大数据平台通常是以 Hadoop 为中心的大数据生态技术。一个 Hadoop 集群包含 HDFS 分布式文件系统和以 Yarn 为调度系统的 MapReduce 计算框架。围绕 Hadoop，有一系列的软件来帮助人们进行大数据的存储和计算，比如数据仓库 Hive、计算框架 Spark、实时消息队列 Kafka 等。</p><p></p><p>在大数据发展的初期，这样的大数据生态技术框架是能基本满足人们建设大数据平台的需要的。随着时代的发展，大数据技术使用逐步地深入，大数据开发需求变得越来越旺盛，人们对多租户环境下大数据开发的效率、大数据集群资源利用率、新（计算和存储）技术的集成速度提出了越来越高的要求，而传统大数据平台在面对这些需求时则显得有点束手无策，出现了无法克服的困难。</p><p></p><p>从 2014 年开始，以 <a href=\"https://xie.infoq.cn/article/3e29493405be713146641fbec\">Docker </a>\"和 Kubernetes（K8s）为代表的云原生技术蓬勃发展，云原生的社区和机构迅速壮大。现在，Kubernetes 已经成为企业搭建容器云平台的标配。</p><p></p><p>那么，高速发展的云原生技术能不能解决传统大数据平台的问题呢？答案是肯定的。本文将从大数据平台产品云原生化的实践过程，阐述一下传统大数据平台迁移到 Kubernetes 上所要经过的技术改造过程。</p><p></p><h3>传统大数据平台遭遇四大窘迫问题</h3><p></p><p></p><p>我们先仔细分析看下传统大数据平台的弊端。传统大数据平台的技术架构决定了依靠它本身的发展是无法克服以下这些困难：</p><p></p><p>传统大数据平台难以实现资源的隔离。多租户环境下的数据开发效率提升，需要以资源隔离的方式来保证租户之间的计算作业互相不影响，特别是不能出现某一个或几个租户独占集群资源的情况。但 Hadoop 系统本身的出发点就不是为了多租户环境而设计的，其目前的资源隔离实现也不完善。在最近的 Hadoop 版本中，在一定程度上实现了内存资源和文件资源的隔离，但是不够完整，而磁盘 I/O 和网络 I/O 的隔离还在社区讨论的过程中，短期内看不到解决的希望。传统大数据平台难以集成新的计算和存储技术。Hadoop 系统在部署其他组件的时候，对这些组件与 HDFS 和 Yarn 的版本适配是有严格要求的。很多新的大数据组件是不适配老版本的 Hadoop 的，而升级 Hadoop 又会造成其他组件的失效。另外，部署新的组件还要考虑到 Linux 不同操作系统的兼容性所带来的额外复杂度。所以引入一个新的计算和存储组件的难度是非常高的，往往需要几天甚至是几周的时候。Hadoop 存算合一的耦合架构决定了它的资源利用率无法提高。在一个 Hadoop 集群中，一个节点既是存储节点（datanode），也是计算节点。当存储资源不够的时候，增加节点可以进行存储扩容，但会造成计算资源的利用率下降；同样，当计算资源不够而进行扩容的时候，存储资源利用率就会下降。同时，因为对于 Yarn 的依赖，不使用 Yarn 调度的其它组件很难集成到 Hadoop 的计算框架中。所以 Hadoop 的这种耦合架构决定了它的资源利用率不可能很高。Hadoop 集群资源无法做到快速的弹性扩容和缩容。弹性的扩容和缩容是提高集群资源利用率的有效方法。很遗憾，Hadoop 的节点扩容和缩容流程，导致这个动作无法在很快的时间内完成，尤其是缩容过程，只有当一个 datanode 的所有数据块都在其他节点完成了备份以后，该节点才能被移出集群，而由于数据备份是以较小的传输率运行在后台，往往要持续几个小时以上。</p><p></p><p>总而言之，传统大数据平台因为其结构性的缺陷导致了多租户环境下数据开发效率低、集群资源利用率不高、以及集成新技术很复杂等问题，依靠 Hadoop 生态技术框架本身的发展是不可能解决这些问题的。</p><p></p><p></p><h3>大数据平台的云原生化趋势</h3><p></p><p></p><p>既然不能够依靠 Hadoop 生态技术本身的发展来解决传统大数据平台带来的难题，那么我们就应该把注意力放到当前最新的技术发展趋势之上，也就是以容器和 Kubernetes 为代表的云原生技术。</p><p></p><p>云原生技术在 2013 年容器项目以及 2014 年 Kubernetes 项目正式发布以后，发展非常迅猛。现在，各大公有云厂商都支持 K8s，还有上百家技术公司在持续投入 K8s 的迭代和更新工作。成立于 2015 年的云原生计算基金会（CNCF），将 K8s 作为其托管的第一个项目，到目前该基金会已经托管了 123 个项目，近 200 个国家的 16 万开发者在为这些项目开发代码。更令人兴奋的是，CNCF 的生态全景图目前包含了 1000 多个云原生技术产品，覆盖了数据库、消息级流处理、调度和任务编排、存储系统等 10 多个技术领域。</p><p></p><p>对于大数据来说，2021 年应该是<a href=\"https://www.infoq.cn/article/H6zC2DAM0momQ9wpqQi5\">云原生大数据技术</a>\"发展的里程碑。在这一年，有两个重大的技术进展被公布。一个是 2021 年 3 月，Apache 宣布 Spark 3.1 正式支持了 kubernetes，另外是在 2021 年 5 月，Apache Kafka 背后的商业公司 Confluent 也发布了 Confluent on Kuberneters，一个能私有发布的在 K8s 之上运行的 Kafka 生产集群系统。</p><p></p><p>这两个重要事件表明，大数据平台的云原生化已是大势所趋。按照这个趋势，Hadoop 也会逐渐迁移到 K8s 上。从技术角度来分析，常说的 Hadoop 三架马车中，计算框架 MapReduce 会被更高效的 Spark 所取代，资源调度组件 Yarn 正在被 K8s 取代，最坚挺的 HDFS 也有了云原生的对标方案。这意味着直接在 K8s 上运行所有现在的大数据工作负载已经成为了可能。</p><p></p><p>同时，从企业业务需求来看，传统大数据平台所缺乏的难以集成新组件、难以实现资源隔离、难以提供资源利用率，特别是缺乏云原生的弹性扩展能力大大阻碍了企业业务系统的发展，由于缺乏弹性扩展能力而导致的业务系统崩溃想象时有发生，而云原生大数据平台恰恰是解决这些问题的良药，简单的讲，就是云原生赋予了大数据平台原来没有的多种云化能力。</p><p></p><p>因此，无论从技术趋势还是从企业业务需求来看，大数据平台的云原生化都是一个必然的趋势。</p><p></p><h3>传统平台云原生化需要解决的 8 项技术难题</h3><p></p><p></p><p>虽然大数据平台的云原生化已经是大势所趋，但在落地实践的过程中还是有一些技术难题需求攻克。就拿 Spark 来说，虽然 Apache Spark 3.1 已经支持了 K8s，但是有几个问题还没有解决，比如 Hive SQL 作业如何以 Spark 的方式在 K8s 运行？JupyterLab 运行的 PySpark 和 Spark 程序怎么运行在 K8s 上？接下来，我们介绍下<a href=\"https://www.infoq.cn/article/Jx18F2HPWBlh4XBtMp1F\">智领云</a>\"是如何解决传统大数据平台云原生化的技术难题。</p><p></p><h5>Hive SQL 程序在 K8s 上运行</h5><p></p><p></p><p>在传统大数据平台中，Hive 被广泛用来进行数据仓库的建设。大数据平台的云原生化一个很重要的工作就是要保留对 Hive SQL 的支持，否则原有的大量的 Hive SQL 程序需要进行迁移，风险和成本都难以把控。从语法上看，Hive SQL 和 Spark SQL 还是有很大差异的，所以我们不能简单地用 Spark SQL 来取代 Hive SQL。另一个技术选择就是修改 Hive 的底层执行引擎，让 Hive SQL 程序以 Spark 作业的方式运行在 K8s 上。这个选择看上去不错，但也面临一些技术挑战。</p><p></p><p>首先，Spark 对 K8s 的支持是 2021 年达到 GA 状态，不同的 Hive 版本、Spark 版本、K8s 版本、以及很多相关大数据组件（比如说授权组件 Apache Ranger）之间的适配还没有成熟。因此，我们经过生产集群的验证，确定了基于以下大数据组件版本的 Hive 执行引擎切换到 Spark 的解决方案。</p><p></p><p>对于 Spark，我们推荐使用最新的版本，因为新版本的 Spark 能增强对 K8s 的支持。而 Hive 从 4.0.0 版本开始，重构了 spark-client 模块的代码结构，增加了 SparkClient 抽象类，通过对该抽象类的代码扩展，我们可以实现对 K8s 的支持。但是在 Hive 代码进行扩展的过程中，要注意避免 Hive 和 Spark 针对 Kryo 库的版本冲突。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ba/bab27d7193467117d36bbee9eb84c5bd.png\" /></p><p></p><p>我们对 Hive 代码的改造主要是增加了抽象类 SparkClient 的一个 K8s 实现，KubernetesSubmitSparkClient 类。这个类通过创建一个 SparkSubmit 实例向 K8s 提交 Spark 任务的各种参数。如下图所示，Hive SQL 代码的执行经过了下面一系列的流程。</p><p></p><p>Hive SQL 程序是通过 Beeline 来连接 HiveServer2，而 Hive 查询工具 Hue 则是通过 JDBC 来连接 HiveServer2；Hive SQL 语句提交到 HiveServer2 后，被解析生成一系列的 SQL 执行计划，并生成 SQL 任务；SQL 任务会启动一个 RPC server，然后 KubernetesSubmitSparkClient 会带上 RPC server 参数，通过 K8s 的 API server 提交一个 Spark 作业；K8s 的 scheduler 这时会启动一个 Spark Driver Pod 来和 HiveServer2 的 RPC server 进行通信，这个 Spark Driver Pod 的主要功能就是接收 RPC server 发送过来的 Hive SQL 作业进行计算，计算完成后，将结果返回给 RPC server；Spark Driver Pod 在启动完成后，会发送启动 Spark Executor Pod 请求给 K8s APIServer, K8s 再启动若干 Spark Executor Pod，然后 Spark Driver 和 Spark Executor 建立连接，完成 Hive SQL 作业的计算。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/72/72b8dad4488f1070f28e9d15ace36f51.png\" /></p><p></p><p></p><h5>Spark 程序在 K8s 上运行</h5><p></p><p></p><p>对于 Spark 程序和 PySpark 代码的执行，我们采用的解决方案是基于 Google 开源的 Spark on K8s Operator 项目。这个开源项目更好地利用了 K8s 的一些特性，来增强在 K8s 上使用 Spark 计算引擎的易用性、灵活性、以及性能提升。</p><p></p><p>但该项目有一个缺陷，就是用户需要通过配置一个复杂的 Yaml 文件来运 Spark 作业，该 Yaml 文件需要声明 Spark 作业的所有信息，包括 Driver/Executor 的资源配置、Spark 的容器镜像版本、以及调度算法等。对于一般用户而言，这些配置信息显得过于繁琐和复杂。</p><p></p><p>为了简化 Spark 程序在 K8s 上运行的复杂配置流程，我们模仿 Apache Livy 的 API 开发了一个 Spark Job Manager Server。该服务负责管理 Spark On K8s Operator 的作业，提供作业的创建、更新、删除、查询状态、日志获取等接口。提交 Spark 程序的时候，用户不需要配置任何 Yaml 文件，只需要配置少量 Spark 作业参数，跟用 spark-submit 脚本提交方式没有区别。Spark Job Manager Server 服务会根据用户提交的参数完成 Spark 作业的 Yaml 文件渲染，将作业提交到 K8s 集群。这一操作方式极大地简化用户在 K8s 上运行 Spark 程序的复杂度。Spark 程序在 K8s 上运行的架构图可以参考下图：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/42/428b7f1218b4d7a57804409754cd3f18.png\" /></p><p></p><p>需要注意的是，第 1、2、3 步都是发生在 Spark Job Manager Server，第 4 步是将 Spark 作业以 Yaml 文件的方式提交给 K8s API Server，之后的 Spark 作业执行就交给 Spark on K8s Operator 去执行了。在第 11 步，Spark Job Manager Server 会通过 API Server 获取 Spark Driver 的状态信息，从而与 Spark Driver 进行通讯以获取 Spark 作业的执行结果。</p><p></p><p></p><h5>JupyterLab 代码在 K8s 上运行</h5><p></p><p></p><p>在传统大数据平台，JupyterLab 一直是数据科学家首选的交互式编程工具，广泛应用在数据的探索分析以及人工智能机器学习算法的开发上。因此，在 K8s 平台上支持 JupyterLab 交互式的 Spark 程序运行是必须要解决的问题。</p><p></p><p>目前，JupyterLab 是利用开源项目 SparkMagic Kernel 通过 Apache Livy 服务来和 Spark 集群进行通讯，实现 Spark 程序的交互式运行。但是，Apache Livy 目前的版本并不支持 K8s。针对这个问题，我们采用了 Hive 模式类似的方式，对 Apache Livy 代码进行了扩展，在 Livy 服务端创建了一个 RPC Server，然后通过 SparkSubmit 提交 Spark 任务。运行在 K8s 集群的 Spark Driver Pod 会和 RPC Server 通信，来完成 SQL 任务的交互执行。下图展示了整个流程的架构图：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/58/58209fc2507cdd0f6a04e53369b4680a.png\" /></p><p></p><p></p><h5>Kafka 集群在 K8s 上运行</h5><p></p><p></p><p>Kafka on K8s 有不少开源的方案，我们选择了 Strimzi 开源的 Kafka Operator。这个项目通过 CRD 抽象描述各种 Kafka 组件的配置，以 Operator 控制协调的原理去管理 Kafka 集群组件，相对完整地实现了 Kafka 集群在 K8s 上的部署。</p><p></p><p>我们对 Strimzi Kafka Operator 的改造主要是支持安全认证和权限管理，将 Schema Registry 组件集成到 Kafka Operator，然后对开源的 Kafka 运维管理工具 AKHQ 进行改造，将其也集成到 Kafka Operator。下图展示了 Kafka 在 K8s 运行的架构图：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e5/e59d390011ff03178403d10594581d47.png\" /></p><p></p><p></p><h5>HDFS 在 K8s 上运行</h5><p></p><p></p><p>目前开源社区有不少成熟的项目都支持 HDFS 集群在 K8s 上发布，但是对多租户和数据安全的支持却不是很完善。我们对 HDFS on K8s 项目进行了扩展，首先是将 Hadoop 的版本升级到最新版本，并与最新的 K8s 版本进行适配。同时，我们集成了对 Https 访问、Kerberos 安全认证和 Apache Ranger 权限授权等功能的支持。</p><p></p><p></p><h5>利用 KubeVela 简化大数据组件在 K8s 上的发布</h5><p></p><p></p><p>在 K8s 这样的平台上发布应用并不是一件容易的事情，应用开发者要了解 K8s 复杂的应用资源配置，比如 API 版本、资源类型、命名空间、标签、容器参数、存储参数、网络参数、重启配置等等一长串的配置。应用开发者为了掌握 K8s 基于 Yaml 文件的应用配置方式需要大量时间去学习和实践。在实践过程中，有不少开发者反映，他们 90% 的时间都在编写重复的应用配置，整个流程过于复杂。</p><p></p><p>为了解决这一问题，我们采用了 KubeVela 框架来简化 K8s 上应用发布和交付的复杂性。KubeVela 作为 K8s 的一个插件，它利用 Open Application Model 模型和 K8s 的可扩展性，通过构建应用发布的一个抽象层，来解决在 K8s 上发布应用存在的一些复杂问题，比如 Pod、端口暴露、权限、资源声明和管理、CRD 等概念，都被抽象成了以应用为视角的配置 SDK。我们通过 KubeVela 框架，将应用发布的通用定义、监控告警定义、监控面板定义、日志采集定义、以及对外端口定义等都抽象成了一个个组件，极大地简化了应用发布的复杂性，也统一了数据应用集成开发平台的应用发布规范。</p><p></p><p></p><h5>大数据组件可观测性在 K8s 上的实现</h5><p></p><p></p><p>大数据组件的运行需要有统一的监控、报警、日志系统来高效地进行运行状态及性能的监控、失效报警、和故障跟踪等大数据运维工作，以保证大数据生产系统的平稳运行。</p><p></p><p>在可观测性方面，我们采用了开源的 Prometheus 来进行监控指标的采集，集成了 Grafana 来配置各组件的监控面板，利用轻量级的云原生日志系统 Loki 来收集各组件的日志，并自主研发了 LogViewer 服务来快速地搜索和获取日志。下图展示了 Kafka 集群的监控面板及日志检索大屏：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3f/3faa48e30f77d8a00724e31d641ca4f3.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/af/aff9a2c0c51e53947d0d7ba1f9857352.png\" /></p><p></p><p></p><h5>数据安全和资源隔离在 K8s 上的实现</h5><p></p><p></p><p>通常一个大数据平台要服务多个部门、业务人员、数据开发人员，是一个典型的多租户环境。在这样的多租户环境下，我们首先要实现所有大数据（可视化）组件的单点登录，这样既能避免维护多套用户登录系统的麻烦，也能保证我们能在大数据计算和存储层能实现统一的安全认证和权限授权机制，而安全认证和权限授权机制也必须是所有计算和存储引擎共用同一套机制。</p><p></p><p>传统大数据平台在多租户环境下的一个难点就是资源隔离，它很难避免一个或少数几个租户独占资源的情况。在云原生架构下，这一问题就迎刃而解。那么，我们具体看看是怎么实现上述功能点的。</p><p></p><p>单点登录：我们基于 OpenID Connect 协议以及开源认证授权管理平台 Keycloak，对主要的大数据可视化工具（Hue、Superset、JupyterLab 等）的登录代码做了修改或扩展，实现了所有可视化工具的单点登录。数据安全：对于数据安全，我们采用了 Kerberos 协议来实现安全认证，并基于开源授权框架的 Apache Ranger 实现了统一的大数据资源（HDFS、Hive 和 Kafka）的授权管理。对于 Spark，我们扩展了 Spark Authorizer 开源插件的代码以支持最新版本的 Spark。对于 Hive，我们修改了大量的 Apache Ranger 的代码以完成对 Hive 4.0.0 的支持。而对于 Kafka，开源的 Strimzi KafkaOperator 是不支持 Kerberos 安全认证和 Apache Ranger 的授权机制的，我们对 Strimzi Kafka Operator 的代码和配置进行了扩展，实现了 Kafka 集群的数据安全。资源隔离：我们充分了利用了 K8s 的命名空间来实现多租户的资源管理，对于每一个机构，我们在 K8s 上分配了一个独立的命名空间，并对该命名空间进行了资源配额的管理，以确保每个机构都不会使用超过其分配份额的集群资源。</p><p></p><p>数据应用开发平台的数据安全架构如下图所示。目前，每个用户在每台虚机上都创建了一个相同的账号，并且保存了一份该用户的 Kerberos keytab，这样每个运行中 K8s 上的容器和大数据组件都可以使用这个用户 ID 和 keytab 进行安全认证。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/41/41deb36f912e5fd202a4a00edef98e8d.png\" /></p><p></p><p>目前，我们已经将云原生大数据平台的基本版作为一个项目开放了出来，与开发者共享 HDFS、Hive、Spark operator、和 Kafka Operator 等大数据组件的部署方式。开发者可以基于这个项目部署一个实验的大数据集群，来体验云原生大数据平台。</p><p></p><p>Github 地址：</p><p></p><p><a href=\"https://github.com/linktimecloud/big-data-on-k8s\">https://github.com/linktimecloud/big-data-on-k8s</a>\"</p><p></p><p>Gitee 地址：</p><p></p><p><a href=\"https://gitee.com/linktimecloud/big-data-on-k8s\">https://gitee.com/linktimecloud/big-data-on-k8s</a>\"</p><p></p><p>需要注意的是，本项目只能作为一个实验系统来运行，因为它不支持高可用、Kerberos 安全认证、以及基于 Apache Ranger 的鉴权机制。</p><p></p><h3>结束语</h3><p></p><p></p><p>这两年以来，我们在大数据平台云原生化这个方向做了大量尝试，实现了大数据组件在 K8s 的稳定运行以及统一的数据安全机制，使数据应用开发平台实现了完整的云原生化。接下来，我们将在以下几个方向继续探索，推动大数据平台更高效更稳定地运行在 K8s 之上。</p><p></p><p>取代 HDFS：HDFS 的主要问题是文件块元数据都在内存中，造成 NameNode 经常消耗大量的内存而且容易出现内存故障，同时对小文件的不友好，运维也比较复杂。我们计划在未来采用开源的云原生分布式文件存储系统 MinIO 来取代 HDFS。统一 Spark 程序的运行方式：目前我们运行 Hive SQL 和 Spark SQL 采用了不同的模式，未来我们希望能用统一的 Spark On K8s Operator 模式来执行 Hive SQL 和 Spark SQL 的计算，使得 Spark 运行更稳定，也使 Spark 计算引擎的监控和运维更加高效。Flink 等其他大数据组件的云原生化：未来我们将持续不断地将其他主要的大数据计算和存储引擎集成到 K8s 集群上，进一步提升数据应用开发平台的大数据开发体验。Spark 访问数据的局部性问题（也称为 Data Locality 问题）：当 Spark 程序和 HDFS 都运行在 K8s 之上的时候，我们需要保证 Spark executor 在读取 HDFS 文件的时候是从同一个节点上的 datanode 去读数据，而不是到其他节点的 datanode 上去读取数据。在其他节点上去读取数据有网络上的延迟，会造成计算作业大约 10% 的性能损耗。解决这个问题可能会需要引入新的 Spark 作业调度机制，或者对 Spark Driver 的源码进行修改。</p><p></p><p>作者简介：</p><p></p><p>宋文欣，智领云科技联合创始人兼 CTO，美国纽约州立石溪大学计算机博士，武汉大学计算机系本科及硕士。具有二十多年软件开发，大数据及云计算经验，前 Electronic Arts 高级工程经理，ask.com Analytics 技术带头人。</p><p></p>",
    "publish_time": "2022-09-28 14:03:28",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "走向现代化数据分析架构：趋势与挑战",
    "url": "https://www.infoq.cn/article/zNNlJywCZIJgX0qHFHIK",
    "summary": "<p>我是汪源，来自网易杭州研究院，网易有不同的事业单元，包括说媒体、教育、音乐、严选、游戏等，我们团队给所有的事业单元提供技术支撑。同时这几年我们也通过网易数帆品牌为300家以上中大型的客户提供技术服务。今天来<a href=\"https://archsummit.infoq.cn/202212/beijing/\">ArchSummit全球架构师峰会</a>\"上，主要分享我们长期以来对数据分析技术相关的趋势的观察和思考。</p><p></p><p>首先介绍一下自己。我可以说是干了一辈子数据相关的技术研发，我在网易杭州研究院也会管理基础设施、云原生、IT等相关的团队，从我个人来说最关注的还是数据相关的领域，因为我在2003年作为核心开发人员参与神舟OSCAR国产数据库的建设，现在叫做神通数据库，最近他们也在科创板提交了招股书。2006年，我在网易研究院成立的第一天加入了研究院，第一个项目做的是分布式数据库DDB，也是国内最早的一批分布式数据库的产品。到后面持续在数据分析的链路上，2014年我们做了网易猛犸，底层的以Hadoop基础的平台。今天我还作为网易数帆负责人，旗下有一个产品线叫网易有数，提供所有面向数据分析的技术栈，最底层是以Hadoop为基础的NDH的发行版，中间提供了数据研发的平台和数据治理的平台和数据中台的解决方案，最上层也提供了BI的产品。</p><p></p><p>因为我的工作，我在日常中非常关注数据分析领域相关的技术趋势和发展，我之前在个人公众号“冷技术热思考”上也分享过一些观察和思考，涉及到数据中台、数据基础设施创新的方向、数据湖之类的，有时候也会出来解释一下我们为什么要去做网易数帆有数大数据基础平台NDH这个产品。</p><p></p><p>当前在数据分析领域新的名词和新的方向是非常多的，所以有很多的客户比较困惑：有这么多的新方法、新趋势，我看得眼花缭乱，怎么办？我提炼出我认为最主要的三条主线，这些主线都是在发展过程中，当前并没有非常高的成熟度，但是我觉得是最值得关注的。</p><p></p><h4>数据分析领域的发展与新概念</h4><p></p><p></p><p>数据分析领域的方法论层出不穷，最核心的是上个世纪90年代形成的一系列分析方法，直到今天还是我们使用的最主要的方法。比如1993年由图灵奖获得者Edgar Frank Codd在一篇文章所提出的OLAP与多维分析的概念，由Bill Inmon和Ralph Kimball两位大师级人物提出的“数据仓库”的整套比较规范的建设方法。BI的概念也在90年代开始盛行开来。另外还有数据治理、主数据管理、数据挖掘等概念。</p><p></p><p>最近20年，方法论的创新不是特别多，但是技术体系的进步非常大。有一个技术底座上很大的进步，就是大数据或者说数据湖的一套体系，分为几个主要模块，在最底层是低成本的分布式存储技术，包括在私有环境下部署的HDFS文件系统，在云端主要是对象存储。在计算层发展了MapReduce框架，包括Spark也还是在MapReduce框架之内，在调度层有YARN和K8s。非常核心的一点是这个行业形成了一个标准并且开放的数据格式，最典型的代表就是Parquet，它既可以表达结构化的数据，也可以有效表达半结构化的数据，比如JSON这种嵌套式的结构，也可以转化成Parquet格式。所有的上层应用都会和Parquet格式衔接，所以在这之上又形成了像Hive MetaStore（HMS）这样的体系规范Catalog，还有优秀的SQL引擎，像Impala、SparkSQL、Presto。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/ea/68/ea8d62e065e6ca1ec507646e98b84668.png\" /></p><p></p><p>这个体系完全基于开放的技术和标准，这些标准并非由某个单位制定，而是事实上的标准。如果Hadoop相应的技术体系要用传统的商业化产品如Oracle、Teradata等去满足，成本会特别高。这个体系可能是过去20年在基础侧所产生的最大成就。</p><p></p><p>过去20年我们在流计算也形成了非常成熟的基础产品。比如说传输方面有Kafka和Pulsar，在计算方面有Flink，当然早期还有Storm，现在已经基本被淘汰。最近20年在应用场景上盛行各类机器学习相关的应用，我们有个性化推荐、搜索、精准广告、风控、量化交易等，这在20年前是比较少的，虽然与机器学习相关的数据挖掘在30年前被提出来了，但是机器学习真正盛行起来是在这20年。</p><p></p><p>现在数据分析领域相关的概念，有很多而且很杂，经过30年的发展，可能又进入到一个比较混乱的状态。比如说我日常最关注的一些概念，Lakehouse（湖仓一体），刚刚看到它在InfoQ技术采用生命周期已经进入晚期大众阶段。Data Fabric、Data Mesh被列在最左边的早期采用者阶。有一些厂商死活跟一个词过不去，叫ELT，并且产生了一系列的跟它相关的词。有的说我们不做ETL了，要做ELT；有的说我做AutoETL，甚至有的宣传我可以NoETL；还有反向ETL，就是把数仓里面分析的结果又灌到业务系统里面去。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/01/48/01b404a884eb77a1d0fde5yy9bb4bd48.png\" /></p><p></p><p>还有很多词在刚才的曲线中还没有出现过，欧美讨论比较多。其中一个是Semantic Layer（语义层）。大概是在1991年，Business Objects(BO)在还没有被SAP收购的时候，就提出了Semantic Layer的概念。后来这个词不温不火，最近两三年突然又火起来了，不少创业公司都宣称自己是在做一个Semantic Layer产品。有些叫得朴实一点，说做的是Metric Layer（指标层）。还有一些把自己定位成HeadlessBI，没有头的BI，它不带展示和交互层，但是可以做语义的建模，可以定义好规范的管理。另外，我们国内最近五年一直在讨论的是数据中台、DataOps、数据虚拟化。</p><p></p><p>这些词都是当下数据分析领域经常看到的，这些词应该怎么梳理和整合呢？接下来就是我的核心观点：现代化数据分析领域主要发展趋势是三大主题，这三大主题我都用“统一”这个词来描述，我认为大家追求的是怎么样做一个统一的基础设施，怎么样做一个统一的中间层，怎么样做统一的数据资产。我也希望整个行业能够往这些方向去聚焦，不要产生太多的相互割裂的概念。</p><p></p><h4>统一的基础设施</h4><p></p><p></p><p>第一个是统一的基础设施。比较理想的统一的基础设施，是一个流式湖仓的基础设施——湖仓和流批都一体之后，我们把它称为流式湖仓——它的实现现在开始出现了非常扎实的基础，你不能说它是非常的完善，但是至少是可用的成熟度。这里面除了最底层的对象存储是各个云厂商提供的，其他的都是开源的技术。我们整个文化一直围绕开源的技术，这里面有一些项目就是由我们自己研发之后开源共享出来的。</p><p></p><p>我认为整个统一的基础设施已经形成了六层架构，如果加上元数据就是七个模块的架构。最底层还是存储层，然后是Parquet文件格式层，中间加了缓存加速层，用来弥补上层需求和底层对象存储之间的性能差距，现在出现的有Alluxio、JuiceFS、CurveFS，其中CurveFS是我们开源出来的一个平台，它能够做同样的工作。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/77/3f/77df84abfccfd8f302f2ba845dbfd23f.png\" /></p><p></p><p>最核心的是在最近两三年我们整个行业中出现了两个新的层次，一个是表格式（table format），一个是表服务（table service），这两个层次能够解决底层大数据体系怎样做到满足湖仓一体、实时更新、版本一致性、ACID等等，之前的大数据没有这样的功能，所以它无法做一些实时的分析服务，只能做T+1的分析。这两个层次可以看到有Iceberg、Arctic、Hudi等。最上层是分析引擎层。</p><p></p><p>Iceberg是Netflix团队开源出来的，我认为它是现在社区里面最有希望成为table format标准的项目。跟它竞争的还有Hudi(Hadoop Upsert anD Incremental)，Hudi最近迫于竞争压力，也把它的table format开放出来的。原来的数据湖三剑客，Delta Lake、Iceberg和Hudi里面，Hudi是一个相对封闭的体系，它的table format是不开放的。</p><p></p><p>Iceberg从数据层面提供了ACID的能力，并且可以读到任何时间点的数据；第二个从元数据层面解决了HMS性能瓶颈，把原来集中式的元数据变成了分布式的元数据，并且相当于给数据构建了一个多级的索引，能够支持高级过滤，这能解决很多问题。很多时候在大数据的体系中，一个query所需要touch的文件数字非常多，可能是几千万、几亿，甚至更多的文件。那么这个query在准备的时候需要去读取哪些文件？我们在自己的场景中之前用Hive技术，一个query启动要花20分钟——它还没有开始跑，只是为了分析清楚到底哪些数据是需要读取的。Iceberg可以把这个性能直线降低至不到一分钟，这是一个非常夸张的进步。</p><p></p><p>第二个比较核心的项目是Arctic，这是我们在8月份的时候开源的一个项目，但这个项目在网易数帆内部研发已经将近三年的时间了。Arctic主要用来帮助Iceberg把整体的技术体系构建完整，因为Iceberg只是一种格式，但是怎样利用这种格式把它组织成面向分析性能最优化的状态，它是不管的，所以我们在Arctic中主要提供了自优化的能力。我们提供了一个基于Iceberg的自优化的机制，并且我们提供了upsert的功能，也就是说支持高效的数据更新。</p><p></p><p>另外我们做到流批一体，一张流表和一张批表的定义是一致的，可以复用。最后为了让这个技术快速落地，我们是可以兼容Hive和Iceberg，一张Hive的表，你不需要做任何动作可以无缝升级成Arctic表，不需要做数据迁移。</p><p></p><p>我认为Iceberg+Arctic在新的技术栈里面处于核心的位置。在老的技术栈中，Parquet是一个开放的文件格式，HMS是大家公认的元数据的服务。在这Parquet和HMS下面有不同的存储体系，还有不同的计算体系，它们两个是唯一的标准，基本上没有别的选择。到今天由Iceberg和Arctic共同构建的这一层会成为一个新的事实的标准，在它下面有很多不同的存储，在它上面有不同的计算体系。这个中间基本上胜出的只有一家，不可能有多家，否则这个技术栈就混乱了。我们目前看好的是Iceberg+Arctic这条路，其实之前我们非常看好Iceberg的发展，所以就做了一个跟它配套的项目Arctic。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/6c/05/6c78620f9ef664265b6a49ee39e1f605.png\" /></p><p></p><p>小结一下，统一的基础设施解决的四大问题，第一是湖仓一体，第二是流批一体，第三是标准格式，不仅是文件格式，还包括表格式，最后是实现存算分离。</p><p></p><h4>统一的中间层</h4><p></p><p></p><p>第二个话题是统一的中间层。一提到中间层我们就想到ETL，现在很多人想灭掉它。这张图来自从蚂蚁金服出来创业的Aloudata团队，原来大家设想数据从数据源经过ETL进入到数仓再到BI，但实际上如同这张图所画，ETL环节是无所不在的。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/d0/0c/d02c7ec877e081bdbede92506337550c.png\" /></p><p></p><p>为什么会有ETL呢？所谓的ETL就是一个把原始数据转化成分析所需要的好用的数据的过程。理想的状态下，很多理论大师们给我们规划了一条路线，在数据仓库里面做好了所有的数据转化，每一个团队用很好的BI工具，应该只做数据的展现和交互，所有的计算逻辑应该都在数仓里面完成，或者说最多再加一个数据集市——数据集市其实也可以认为是数据仓库大体系的一部分。但实际上大家会发现每一个团队都会在自己的BI里面又去做了很多的计算逻辑，因为数据仓库的计算逻辑不够用，导致一个很大的问题就是分散的计算逻辑。大家在不同的BI产品中看到的数据口径是不一样的，结果也是不一样的，就是由分散的计算逻辑带来的。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/82/b6/82efc147cfe84cfa1c6bc567cfef01b6.png\" /></p><p></p><p>怎么样解决这个问题呢？有很多的方案，我把它们分为中国方案、国际方案和我们的方案。中国方案就是数据中台，要做到OneData、OneService、OneID，解决指标口径不一致的问题，所有的口径定义、计算逻辑都应该在中台里面做好。</p><p></p><p>数据中台大致有这么几个模块，包括了数据仓库（我认为典型的数据中台是包括了数据仓库这一层）。在数据仓库定义了一套规范的指标层，包括原始指标、派生指标、复合指标，派生应该是原始指标加上时间周期加上修饰词等等。上面是数据服务层，对外提供所有对外的数据。同时又引入了数据治理的概念来保证中台输出的数据是高质量的，是符合安全要求的。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/3c/50/3c2b246b76c6d64b8babaf1f8208a350.png\" /></p><p></p><p>国际方案没有这么复杂，只有三个核心的概念：Semantic Layer、HeadlessBI和Metric Layer。它们其实是近义词，不同的公司有不同的叫法。有一些公司年头比较长了，比如GoodData，最近宣传自己是Semantic Layer公司。Kyvos宣称给印度政府建了全球最大的数据平台，之后做了很多相关的产品。</p><p></p><p>国际方案里面最贴切的描述是HeadlessBI，我引用了其中一个产品叫Cube，下图来自Cube官网，数据输入来自左边的各种数仓，它在HeadlessBI这一层要做的是数据建模、安全相关的访问控制、性能加速，最后以API的方式提供给右边的下游消费者，主要是BI工具，以及一些数据产品中内嵌的展示，也就是嵌入式的分析。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/c3/a3/c3b9fbabcc9f2fbb199f1885ddcb13a3.png\" /></p><p></p><p>我们在这个方向也做了一点贡献，思路和大家不太一样。我们强调的是开发和治理一体化，让指标、模型等等持续保持高质量。大致的产品设计逻辑，是我们在建数仓、建指标这些开发活动的过程中，同步把数据治理的活动也做掉了。这是因为我们发现有很多客户，先找开发的厂商来做开发，做完之后发现数据质量不太行，又去找数据治理的厂商来做数据治理的项目。我们认为可以把开发和治理做到一体化，在开发环节同时把开发治理做好了，就不会有后遗症了。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/6b/32/6be22b7437201c0db367ce7b430fb832.png\" /></p><p></p><p>最终，我们希望会产生这样一个统一的中间层，包括数据仓库和HeadlessBI两层，后者能做建模，包括指标，做权限、加速和服务，同时把开发和治理一体化了，没有单独的数据开发和数据治理相关的模块。所以它的目标就是通过统一的模型指标计算逻辑和口径，实现事前事中事后的持续治理。这个时候BI层才可以真正的聚焦在展现和交付上，这一层BI我命名为NecklessBI，底下的HeadlessBI是无头BI，上面是只有头没有脖子的BI。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/a4/14/a41465d4b73a0ff4c1f912db0bb6b214.png\" /></p><p></p><p>最后再说一下ETL。我认为ETL不会被消除的，它只能被转移或隐藏，因为从数据源到分析所需要的数据一定是有很多不匹配的，数据源在设计的时候不会考虑到为了分析需求设计的，所以说ETL是一定会有的。但是比较现实的是做ETL的自动化，比较低调一点叫AutoETL，高调的NoETL其实也是AutoETL。HTAP这个场景的应用可能有限，大量的分析工作要做多源数据的整合，HTAP在这个过程中发挥不了太多的作用。</p><p></p><h4>统一的数据资产</h4><p></p><p></p><p>最后是统一的数据资产。我们企业做数据分析的时候面临很多的问题，不是有强大的算力就可以了，有很多资产管理不到位带来的问题，比如说数据找不到，找到了看不懂，看了之后信不过、不敢用，因为不知道数据质量；最后从企业管理层的角度，他觉得这么多的数据管不牢。这都是在数据资产相关领域面临的很大的问题，之前建数据中台也是希望解决类似的问题，但我认为这主要还是数据资产管理的问题。</p><p></p><p>我看到了一个比较可行的思路就是Data Fabric，它的目的是实现数据的整合利用，它是一个架构思想或者设计理念，并不绑定一个特定的技术实现。Data Fabric强调元数据要集中管理，但是从数据本身可以兼容各种风格数据的处理手段，我们可以用ETL的方式来做Data Fabric，也可以用虚拟化的方式来做。当然我个人认为如果用ETL和数据仓库的方式来做Data Fabric，那么Data Fabric的优势就发挥得就没有那么明显。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/2b/e8/2bb1918115632a904cba330ca62c5ee8.png\" /></p><p></p><p>其他几个做数据整合利用的方式的区别，第一个是数据仓库或者数据中台，比较强调数据的集中，同时也强调数据比较深度的预加工，数据仓库就是要对数据进行深度的预加工。第二个是数据湖，强调数据的集中，但是它强调数据不要做太多的预加工，应该按照原始的数据格式都存在湖里面，需要的时候再把它拿出来处理。Data Fabric是强调元数据的集中。</p><p></p><p>Data Fabric的实际落地需要构建四个方面的核心能力：</p><p></p><p>一是连接数据源，连接各种各样的数据源。比如一些产品更新以后，数据暴露的方式变了，我们再连接花了不少的时间。所以连接数据源是一个非常复杂和非常关键的能力，很多产品目前在这方面做得还不是特别好。</p><p><img src=\"https://static001.infoq.cn/resource/image/9b/2d/9ba36d9fc274cdfe117b9b13ae7a042d.png\" /></p><p></p><p>二是元数据的管理，要做到主动元数据（active metadata）。因为最传统的元数据是要靠手工登记注册的，这种情况下要管理企业的数据资产，工作量是非常大的，而且也很容易导致阶段性做元数据管理，而不是项目验收的时候元数据注册很好，结果项目验收完了，手动注册的元数据就跟不上变化。主动元数据可以主动地扫描这些数据源的数据变化，通过智能化的识别、知识图谱相关的技术帮助我们理解元数据和数据之间的关系。</p><p></p><p>三是数据虚拟化，我认为数据虚拟化能最大程度发挥Data Fabric的能力，因为它能够在数据没有完成集中之前就能够做一定程度的利用，当然它的天花板可能也不是太高，你不能假设所有的数据分析都可以基于数据虚拟化来做。</p><p></p><p>四是我们做的逻辑数据湖，也是Data Fabric的一种实现。逻辑数据湖从逻辑上看是一个湖，但是从物理实现上数据位置还是分散的，还是存在Hadoop、Oracle、MySQL里面。详见之前的回顾 | <a href=\"https://xie.infoq.cn/article/462d6585a6f3c5463af36808d\">Data Fabric：逻辑统一、物理分散</a>\"</p><p></p><h4>总结</h4><p></p><p></p><p>最后简要总结，现代数据分析技术的三大主题，第一个是构建一个统一的基础设施，这个基础设施能够支撑数据的实时的更新和消费，它本身又是一个开放的、低成本的体系，我们命名为流式湖仓。</p><p></p><p>第二个是统一的中间层，要做到统一的模型、指标、计算逻辑和口径，另外要做到事前事中事后持续的数据治理，它的组成部分包括了数据仓库和HeadlessBI这两个层次。</p><p></p><p>第三个是统一的数据资产，它的目的是要做企业全域数据资产的高效的发现、整合和管理，它在实现上能够兼容各种风格的数据处理技术，核心的概念有很多分析机构提倡的Data Fabric，我们也提供了称为逻辑数据湖的Data Fabric实现。</p><p></p><h4>【活动推荐】</h4><p></p><p></p><p>在12月2-3日，ArchSummit架构师峰会，将在北京举办，这次会议重点讲述架构演进，以及在架构层面的落地细节，同时也会分享在当前形势下，国内可替代的软件方案。更多细节可以查看会议官网 https://archsummit.infoq.cn/202212/beijing/track</p>",
    "publish_time": "2022-09-28 14:09:26",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Java 19发布，Loom 怎么解决 Java 的并发模型缺陷？",
    "url": "https://www.infoq.cn/article/Wg5qYbla1pS222lArJ3y",
    "summary": "<p>本文最初发表于<a href=\"https://developer.okta.com/blog/2022/08/26/state-of-java-project-loom\">okta网站</a>\"，经原作者<a href=\"https://www.linkedin.com/in/deepu05/\">Deepu K Sasidharan</a>\"授权由InfoQ中文站翻译分享。</p><p></p><p></p><blockquote><a href=\"https://www.infoq.cn/article/Zf6wLOe3l8elAjPlKiVz\">Java 19</a>\"已经于日前发布，其中最引人注目的特性就要数虚拟线程了，本文介绍了Loom项目中虚拟线程和结构化编程的基础知识，并将其与操作系统线程进行了对比分析。</blockquote><p></p><p></p><p>Java 在其发展早期就具有良好的多线程和并发能力，能够高效地利用多线程和多核CPU。Java开发工具包（Java Development Kit，JDK）1.1对平台线程（或操作系统（OS）线程）提供了基本的支持，JDK 1.5提供了更多的实用工具和更新，以改善并发和多线程。JDK 8带来了异步编程支持和更多的并发改善。虽然在多个不同的版本中都进行了改进，但在过去三十多年中，除了基于操作系统的并发和多线程支持之外，Java并没有任何突破性的进展。</p><p></p><p>尽管Java中的并发模型非常强大和灵活，但它并不是最易于使用的，而且开发人员的体验也不是很好。这主要是因为它默认使用的共享状态并发模型。我们必须借助同步线程来避免数据竞争（data race）和线程阻塞这样的问题。我曾经在一篇名为“<a href=\"https://deepu.tech/concurrency-in-modern-languages-java/\">现代编程语言中的并发：Java</a>\"”的博客文章中讨论过Java并发问题。</p><p></p><h2>Loom项目是什么？</h2><p></p><p></p><p></p><blockquote>Loom项目致力于大幅减少编写、维护和观察高吞吐量并发应用相关的工作，以最佳的方式利用现有的硬件。——Ron Pressler（Loom项目的技术负责人）</blockquote><p></p><p></p><p>操作系统线程是Java并发模型的核心，围绕它们有一个非常成熟的生态系统，但是它们也有一些缺点，如计算方式很昂贵。我们来看一下并发的两个最常见使用场景，以及当前的Java并发模型在这些场景下的缺点。</p><p></p><p>最常见的并发使用场景之一就是借助服务器在网络上为请求提供服务。在这样的场景中，首选的方法是“每个请求一个线程（thread-per-request）”模型，即由一个单独的线程处理每个请求。这种系统的吞吐量可以用<a href=\"https://en.wikipedia.org/wiki/Little%27s_law\">Little定律</a>\"来计算，该定律指出，在一个稳定的系统中，平均并发量（服务器并发处理的请求数）L等于吞吐量（请求的平均速率）λ乘以延迟（处理每个请求的平均时间）W。基于此，我们可以得出，吞吐量等于平均并发除以延迟（λ = L/W）。</p><p></p><p>因此，在“每个请求一个线程”模型中，吞吐量将受到操作系统线程数量的限制，这取决于硬件上可用的物理核心/线程数。为了解决这个问题，我们必须使用共享线程池或异步并发，这两种方法各有缺点。线程池有很多限制，如线程泄漏、死锁、资源激增等。异步并发意味着必须要适应更复杂的编程风格，并谨慎处理数据竞争。它们还有可能出现内存泄漏、线程锁定等问题。</p><p></p><p>另一个常见的使用场景是并行处理或多线程，我们可能会把一个任务分成跨多个线程的子任务。此时，我们必须编写避免数据损坏和数据竞争的解决方案。在有些情况下，当执行分布在多个线程上的并行任务时，还必须要确保线程同步。这种实现会非常脆弱，并且将大量的责任推给了开发人员，以确保没有像线程泄露和取消延迟这样的问题。</p><p></p><p>Loom项目旨在通过引入两个新特性来解决当前并发模型中的这些问题，即虚拟线程（virtual thread）和结构化并发（structured concurrency）。</p><p></p><h2>虚拟线程</h2><p></p><p></p><p></p><blockquote>Java 19已经于2022年9月20日发布，虚拟线程是其中的一项预览功能。</blockquote><p></p><p></p><p><a href=\"https://openjdk.org/jeps/425\">虚拟线程</a>\"是轻量级的线程，它们不与操作系统线程绑定，而是由JVM来管理。它们适用于“每个请求一个线程”的编程风格，同时没有操作系统线程的限制。我们能够创建数以百万计的虚拟线程而不会影响吞吐。这与Go编程语言（Golang）的协程（如<a href=\"https://go.dev/tour/concurrency/1\">goroutines</a>\"）非常相似。</p><p></p><p>Java 19中的虚拟线程新特性很易于使用。在这里，我将其与Golang的goroutines以及Kotlin的coroutines进行了对比。</p><p></p><p>虚拟线程</p><p></p><p><code lang=\"text\">Thread.startVirtualThread(() -&gt; {\n    System.out.println(\"Hello, Project Loom!\");\n});\n</code></p><p></p><p>Goroutine</p><p></p><p><code lang=\"text\">go func() {\n    println(\"Hello, Goroutines!\")\n}()\n</code></p><p></p><p>Kotlin coroutine</p><p></p><p><code lang=\"text\">runBlocking {\n    launch {\n        println(\"Hello, Kotlin coroutines!\")\n    }\n}\n</code></p><p></p><p>冷知识：在JDK 1.1之前，Java曾经支持过绿色线程（又称虚拟线程），但该功能在JDK 1.1中移除了，因为当时该实现并没有比平台线程更好。</p><p></p><p>虚拟线程的新实现是在JVM中完成的，它将多个虚拟线程映射为一个或多个操作系统线程，开发人员可以按需使用虚拟线程或平台线程。这种虚拟线程实现还有如下几个注意事项：</p><p></p><p>在代码、运行时、调试器和剖析器（profiler）中，它是一个Thread。它是一个Java实体，并不是对原生线程的封装。创建和阻塞它们是代价低廉的操作。它们不应该放到池中。虚拟线程使用了一个基于任务窃取（work-stealing）的ForkJoinPool调度器。可以将可插拔的调度器用于异步编程中。虚拟线程会有自己的栈内存。虚拟线程的API与平台线程非常相似，因此更容易使用或移植。</p><p></p><p>我们看几个展示虚拟线程威力的样例。</p><p></p><p></p><h3>线程的总数量</h3><p></p><p></p><p>首先，我们看一下在一台机器上可以创建多少个平台线程和虚拟线程。我的机器是英特尔酷睿i9-11900H处理器，8个核心、16个线程、64GB内存，运行的操作系统是Fedora 36。</p><p></p><p>平台线程</p><p></p><p><code lang=\"text\">var counter = new AtomicInteger();\nwhile (true) {\n    new Thread(() -&gt; {\n        int count = counter.incrementAndGet();\n        System.out.println(\"Thread count = \" + count);\n        LockSupport.park();\n    }).start();\n}\n</code></p><p></p><p>在我的机器上，在创建32,539个平台线程后代码就崩溃了。</p><p></p><p>虚拟线程</p><p></p><p><code lang=\"text\">var counter = new AtomicInteger();\nwhile (true) {\n    Thread.startVirtualThread(() -&gt; {\n        int count = counter.incrementAndGet();\n        System.out.println(\"Thread count = \" + count);\n        LockSupport.park();\n    });\n}\n</code></p><p></p><p>在我的机器上，进程在创建14,625,956个虚拟线程后被挂起，但没有崩溃，随着内存逐渐可用，它一直在缓慢进行。你可能想知道为什么会出现这种情况。这是因为被park的虚拟线程会被垃圾回收，JVM能够创建更多的虚拟线程并将其分配给底层的平台线程。</p><p></p><p></p><h3>任务吞吐量</h3><p></p><p></p><p>我们尝试使用平台线程来运行100,000个任务。</p><p></p><p><code lang=\"text\">try (var executor = Executors.newThreadPerTaskExecutor(Executors.defaultThreadFactory())) {\n    IntStream.range(0, 100_000).forEach(i -&gt; executor.submit(() -&gt; {\n        Thread.sleep(Duration.ofSeconds(1));\n        System.out.println(i);\n        return i;\n    }));\n}\n</code></p><p></p><p>在这里，我们使用了带有默认线程工厂的newThreadPerTaskExecutor方法，因此使用了一个线程组。运行这段代码并计时，我得到了如下的结果。当使用Executors.newCachedThreadPool()线程池时，我得到了更好的性能。</p><p></p><p><code lang=\"text\"># 'newThreadPerTaskExecutor' with 'defaultThreadFactory'\n0:18.77 real,   18.15 s user,   7.19 s sys,     135% 3891pu,    0 amem,         743584 mmem\n# 'newCachedThreadPool' with 'defaultThreadFactory'\n0:11.52 real,   13.21 s user,   4.91 s sys,     157% 6019pu,    0 amem,         2215972 mmem\n</code></p><p></p><p>看着还不错。现在，让我们用虚拟线程完成相同的任务。</p><p></p><p><code lang=\"text\">try (var executor = Executors.newVirtualThreadPerTaskExecutor()) {\n    IntStream.range(0, 100_000).forEach(i -&gt; executor.submit(() -&gt; {\n        Thread.sleep(Duration.ofSeconds(1));\n        System.out.println(i);\n        return i;\n    }));\n}\n</code></p><p></p><p>运行这段代码并计时，我得到了如下结果：</p><p></p><p><code lang=\"text\">0:02.62 real,   6.83 s user,    1.46 s sys,     316% 14840pu,   0 amem,         350268 mmem\n</code></p><p></p><p>这比基于平台线程的线程池要好得多。当然，这些都是很简单的使用场景，线程池和虚拟线程的实现都可以进一步优化以获得更好的性能，但这不是这篇文章的重点。</p><p></p><p>用同样的代码运行Java Microbenchmark Harness（JMH），得到的结果如下。可以看到，虚拟线程的性能比平台线程要好很多。</p><p></p><p><code lang=\"text\"># Throughput\nBenchmark                             Mode  Cnt  Score   Error  Units\nLoomBenchmark.platformThreadPerTask  thrpt    5  0.362 ± 0.079  ops/s\nLoomBenchmark.platformThreadPool     thrpt    5  0.528 ± 0.067  ops/s\nLoomBenchmark.virtualThreadPerTask   thrpt    5  1.843 ± 0.093  ops/s\n\n# Average time\nBenchmark                             Mode  Cnt  Score   Error  Units\nLoomBenchmark.platformThreadPerTask   avgt    5  5.600 ± 0.768   s/op\nLoomBenchmark.platformThreadPool      avgt    5  3.887 ± 0.717   s/op\nLoomBenchmark.virtualThreadPerTask    avgt    5  1.098 ± 0.020   s/op\n</code></p><p></p><p>你可以在GitHub上找到<a href=\"https://github.com/deepu105/java-loom-benchmarks\">该基准测试的源代码</a>\"。如下是其他几个有价值的虚拟线程基准测试：</p><p></p><p>在<a href=\"https://github.com/ebarlas/project-loom-comparison\">GitHub</a>\"上，<a href=\"https://twitter.com/ElliotBarlas\">Elliot Barlas</a>\"使用ApacheBench做的一个有趣的基准测试。<a href=\"https://medium.com/@zakgof\">Alexander Zakusylo</a>\"在<a href=\"https://medium.com/@zakgof/a-simple-benchmark-for-jdk-project-looms-virtual-threads-4f43ef8aeb1\">Medium</a>\"上使用Akka actors的基准测试。在<a href=\"https://github.com/colincachia/loom-benchmark\">GitHub</a>\"上，<a href=\"https://twitter.com/colincachia\">Colin Cachia</a>\"做的I/O和非I/O任务的JMH基准测试。</p><p></p><p></p><h2>结构化并发</h2><p></p><p></p><p></p><blockquote>结构化并发是Java 19中的一个孵化功能。</blockquote><p></p><p></p><p><a href=\"https://openjdk.org/jeps/428\">结构化并发</a>\"的目的是简化多线程和并行编程。它将在不同线程中运行的多个任务视为一个工作单元，简化了错误处理和任务取消，同时提高了可靠性和可观测性。这有助于避免线程泄漏和取消延迟等问题。作为一个孵化功能，在稳定过程中可能会经历进一步的变更。</p><p></p><p>我们考虑如下这个使用java.util.concurrent.ExecutorService的样例。</p><p></p><p><code lang=\"text\">void handleOrder() throws ExecutionException, InterruptedException {\n    try (var esvc = new ScheduledThreadPoolExecutor(8)) {\n        Future inventory = esvc.submit(() -&gt; updateInventory());\n        Future order = esvc.submit(() -&gt; updateOrder());\n\n        int theInventory = inventory.get();   // Join updateInventory\n        int theOrder = order.get();           // Join updateOrder\n\n        System.out.println(\"Inventory \" + theInventory + \" updated for order \" + theOrder);\n    }\n}\n</code></p><p></p><p>我们希望updateInventory()和updateOrder()这两个子任务能够并发执行。每一个任务都可以独立地成功或失败。理想情况下，如果任何一个子任务失败，handleOrder()方法都应该失败。然而，如果某个子任务发生失败的话，事情就会变得难以预料。</p><p></p><p>设想一下，updateInventory()失败并抛出了一个异常。那么，handleOrder()方法在调用invent.get()时将会抛出异常。到目前为止，还没有什么大问题，但updateOrder()呢？因为它在自己的线程上运行，所以它可能会成功完成。但是现在我们就有了一个库存和订单不匹配的问题。假设updateOrder()是一个代价高昂的操作。在这种情况下，我们白白浪费了资源，不得不编写某种防护逻辑来撤销对订单所做的更新，因为我们的整体操作已经失败。假设updateInventory()是一个代价高昂的长时间运行操作，而updateOrder()抛出一个错误。即便updateOrder()抛出了错误，handleOrder()任务依然会在inventory.get()方法上阻塞。理想情况下，我们希望handleOrder()任务在updateOrder()发生故障时取消updateInventory()，这样就不会浪费时间了。如果执行handleOrder()的线程被中断，那么中断不会被传播到子任务中。在这种情况下，updateInventory()和updateOrder()会泄露并继续在后台运行。</p><p></p><p>对于这些场景，我们必须小心翼翼地编写变通方案和故障防护措施，把所有的职责推到了开发人员身上。</p><p></p><p>我们可以使用下面的代码，用结构化并发实现同样的功能。</p><p></p><p><code lang=\"text\">void handleOrder() throws ExecutionException, InterruptedException {\n    try (var scope = new StructuredTaskScope.ShutdownOnFailure()) {\n        Future inventory = scope.fork(() -&gt; updateInventory());\n        Future order = scope.fork(() -&gt; updateOrder());\n\n        scope.join();           // Join both forks\n        scope.throwIfFailed();  // ... and propagate errors\n\n        // Here, both forks have succeeded, so compose their results\n        System.out.println(\"Inventory \" + inventory.resultNow() + \" updated for order \" + order.resultNow());\n    }\n}\n</code></p><p></p><p>与之前使用ExecutorService的样例不同，我们现在使用StructuredTaskScope来实现同样的结果，并将子任务的生命周期限制在词法的作用域内，在本例中，也就是try-with-resources语句体内。这段代码更易读，而且意图也很清楚。StructuredTaskScope还自动确保以下行为：</p><p></p><p>基于短路的错误处理：如果updateInventory()或updateOrder()失败，另一个将被取消，除非它已经完成。这是由ShutdownOnFailure()实现的取消策略来管理的，我们还可以使用其他策略。取消传播：如果运行handleOrder()的线程在调用join()之前或调用过程中被中断的话，当该线程退出作用域时，两个分支（fork）都会被自动取消。可观察性：线程转储文件将清楚地显示任务层次，运行updateInventory()和updateOrder()的线程被显示为作用域的子线程。</p><p></p><p></p><h2>Loom项目状况</h2><p></p><p></p><p>Loom项目开始于2017年，经历了许多变化和提议。虚拟线程最初被称为fibers，但后来为了避免混淆而重新进行了命名。如今随着Java 19的发布，该项目已经交付了上文讨论的两个功能。其中一个是预览状态，另一个是孵化状态。因此，这些特性的稳定化之路应该会更加清晰。</p><p></p><p></p><h2>这对普通的Java开发人员意味着什么？</h2><p></p><p></p><p>当这些特性生产环境就绪时，应该不会对普通的Java开发人员产生太大的影响，因为这些开发人员可能正在使用某些库来处理并发的场景。但是，在一些比较罕见的场景中，比如你可能进行了大量的多线程操作但是没有使用库，那么这些特性就是很有价值的了。虚拟线程可以毫不费力地替代你现在使用的线程池。根据现有的基准测试，在大多数情况下它们都能提高性能和可扩展性。结构化并发有助于简化多线程或并行处理，使其能加健壮，更易于维护。</p><p></p><p></p><h2>这对Java库开发人员意味着什么？</h2><p></p><p></p><p>当这些特性生产环境就绪时，对于使用线程或并行的库和框架来说，将是一件大事。库作者能够实现巨大的性能和可扩展性提升，同时简化代码库，使其更易维护。大多数使用线程池和平台线程的Java项目都能够从切换至虚拟线程的过程中受益，候选项目包括Tomcat、Undertow和Netty这样的Java服务器软件，以及Spring和Micronaut这样的Web框架。我预计大多数Java web技术都将从线程池迁移到虚拟线程。Java web技术和新兴的反应式编程库，如RxJava和Akka，也可以有效地使用结构化并发。但这并不意味着虚拟线程将成为所有问题的解决方案，异步和反应式编程仍然有其适用场景和收益。</p><p></p><p></p><p>了解更多关于Java、多线程和Loom项目的信息：</p><p></p><p><a href=\"https://inside.java/2020/08/07/loom-performance/\">On the Performance of User-Mode Threads and Coroutines</a>\"<a href=\"http://cr.openjdk.java.net/~rpressler/loom/loom/sol1_part1.html\">State of Loom</a>\"<a href=\"https://www.youtube.com/watch?v=EO9oMiL1fFo\">Project Loom: Modern Scalable Concurrency for the Java Platform</a>\"<a href=\"https://foojay.io/today/thinking-about-massive-throughput-meet-virtual-threads/\">Thinking About Massive Throughput? Meet Virtual Threads!</a>\"<a href=\"https://developer.okta.com/blog/2022/04/08/state-of-ffi-java\">Does Java 18 finally have a better alternative to JNI?</a>\"<a href=\"https://developer.okta.com/blog/2022/06/16/oauth-java\">OAuth for Java Developers</a>\"<a href=\"https://developer.okta.com/blog/2022/06/09/cloud-native-java-microservices-with-istio\">Cloud Native Java Microservices with JHipster and Istio</a>\"</p><p></p>",
    "publish_time": "2022-09-28 14:46:48",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "龙蜥社区迎来麒麟软件、浪潮信息、曙光、新华三等重磅理事单位",
    "url": "https://www.infoq.cn/article/OEoWJQox0k6O720klvAD",
    "summary": "<p>9月28日消息，<a href=\"https://www.infoq.cn/profile/28E9DA5F69CE2F/publish\">龙蜥社区</a>\"理事会对外宣布，国产操作系统龙头企业麒麟软件和服务器头部厂商浪潮信息、中科曙光、新华三加入社区并成为理事单位和技术委员会成员。未来，这些公司将把龙蜥社区作为技术发源地，积极在技术研发、生态建设、市场拓展等方面贡献力量。</p><p></p><p>麒麟软件是国产操作系统龙头企业，加入龙蜥社区后，双方会共同拓展<a href=\"https://s.geekbang.org/search/c=0/k=Linux/t=\">Linux</a>\"操作系统生态，构建国内操作系统行业自主创新高地。服务器头部厂商浪潮信息、中科曙光、新华三的加入，意味着龙蜥社区实现了主流服务器厂商的覆盖。至此，龙蜥社区实现了从服务器到操作系统的开放产业生态。据悉，浪潮信息、中科曙光、新华三都将参与社区技术合作和发展路线的讨论；推动服务器、板卡和龙蜥的适配；发挥整机厂商的优势，推广龙蜥标准，助力龙蜥繁荣生态建设。</p><p></p><p>“这是龙蜥社区发展的重要里程碑。”龙蜥社区理事长马涛表示，“麒麟软件、浪潮信息、中科曙光、新华三的加入，意味着他们对龙蜥的未来充满信心。成为理事单位，更代表了他们全力投入的决心。这必将促进社区健康发展，让龙蜥走得更远。”</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/1c/1d/1c5626887cf088c77cd89ae6e2002a1d.png\" /></p><p></p><p>2020年9月，阿里云、统信软件、三大运营商等共同发起龙蜥社区，在多家企业及开发者的技术沉淀、积极贡献和努力下，仅成立两年的龙蜥社区如今已经成长为一个成熟的开源社区，在产业、技术、生态等方面具备了领先的实力和影响力。</p><p></p><p>截至目前，龙蜥操作系统下载量已超百万，整体装机量达150多万，龙蜥社区理事单位达21家，生态伙伴近250家。50余款企业产品完成与龙蜥操作系统的适配，多家企业基于龙蜥操作系统发行了商业版，在政务、金融、交通、通信等领域累计服务用户超过30万。浙江移动、政采云、国网信通产业集团等都基于<a href=\"https://www.infoq.cn/article/15ZhicNUoFx2bXzgy3AZ?utm_source=related_read_bottom&amp;utm_medium=article\">龙蜥操作系统</a>\"完成了CentOS替换。</p><p></p><p>与此同时，龙蜥社区正在打造下一代操作系统（Anolis OS 23），它将集成更多核心自研组件，引领操作系统的未来。龙蜥的目标是成为业界共建共享的软件基础设施。</p>",
    "publish_time": "2022-09-28 16:04:41",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "腾讯首次全面解读全真互联，其与元宇宙大不同，这五大技术体系值得关注",
    "url": "https://www.infoq.cn/article/Wvo3SEOyc5MsvbqCVLgl",
    "summary": "<p></p><p></p><blockquote>汤道生表示，腾讯已经为全真互联做好了技术储备。</blockquote><p></p><p></p><p>9月26日，腾讯联合埃森哲发布了《全真互联白皮书》，全面呈现这一面向未来的技术体系和应用场景。</p><p></p><p>这是腾讯公司董事会主席兼首席执行官马化腾提出全真互联后，腾讯首次对其进行详细解读。</p><p></p><h2>何谓「全真互联」？</h2><p></p><p></p><p>白皮书介绍，全真互联是通过多种终端和形式，实现对真实世界全面感知、连接、交互的一系列技术集合与数实融合创新模式。对个人，全真互联能随时随地提供身临其境的体验；对企业和组织，全真互联让服务变得更可度量，质量更可优化，推动组织效能提升；对社会，全真互联让资源利用效率提升，为产业发展模式带来创新，提高政府治理效能，促进社会可持续发展。</p><p></p><p>全真互联的概念是由腾讯集团董事会主席兼首席执行官马化腾在年度特刊《三观》前言中首次提出。</p><p></p><p>他在《三观》前言中表示，“现在，一个令人兴奋的机会正在到来，移动互联网十年发展，即将迎来下一波升级，我们称之为全真互联网；从实时通信到音视频等一系列基础技术已经准备好，计算能力快速提升，推动信息接触、人机交互的模式发生更丰富的变化”。</p><p></p><p>“这是一个从量变到质变的过程，它意味着线上线下的一体化，实体和电子方式的融合；虚拟世界和真实世界的大门已经打开，无论是从虚到实，还是由实入虚，都在致力于帮助用户实现更真实的体验；从消费互联网到产业互联网，应用场景也已打开；通信、社交在视频化，视频会议、直播崛起，游戏也在云化”。马化腾认为，“随着 VR 等新技术、新的硬件和软件在各种不同场景的推动，我相信又一场大洗牌即将开始；就像移动互联网转型一样，上不了船的人将逐渐落伍”。</p><p></p><p>全真互联将产生融合数字与实体、跨越时间和空间的全新连接方式，能够为用户、产业和社会价值创造，提供新的解决方案，带来新的应用场景，孕育新的产业生态，塑造新的生活方式。</p><p></p><h2>全真互联和元宇宙，并不一样</h2><p></p><p></p><p>元宇宙是近两年的顶流概念。一种说法认为，腾讯所提的全真互联是对元宇宙的另一种表述，但这两个概念，其实并不一样。</p><p></p><p>此前，马化腾曾在腾讯2021年度第四季度及全年财报的电话会议中，谈到了这两个概念的区别，</p><p></p><p>他表示，对现在比较热的元宇宙概念，腾讯更多的是从“数实融合”的角度来看，而不是纯虚拟的，比较关注全真互联的概念。</p><p></p><p>**汤道生认为，**通过多种终端与技术，实现全面沉浸式的感知，是全真互联的主要特征。相比元宇宙里的VR/AR等要素，全真互联的端会更多，更丰富。此外，不仅仅是连接，通过双向交互实现可操作、可执行，是全真互联的核心价值。在这个过程中，“互”的重要性得到提升，更强调通过交互对真实世界的目标产生影响和优化。服务真实场景、解决实际问题，让真实世界更美好，是全真互联的最终目标。元宇宙的概念并不统一，各家有各家的定义和理解，但更多是在娱乐、消费或者虚拟领域，全真互联则强调是服务于真实场景，解决实际问题，具有很明确的应用场景，主战场在产业互联网。</p><p></p><h2>汤道生：全真互联落地需要五大技术体系不断演进</h2><p></p><p></p><p>全真互联以全真体验、无限连接、自由协同、数实融合为主要发展特征。人们能够对真实世界沉浸式感知和体验，产生无限连接的可能性，突破物理时间和空间限制自由协作，数字技术和实体经济也将充分融合发展。</p><p></p><p>“全真互联能够实现沉浸体验、实时孪生的基础上，通过双向交互，对真实世界实现可操作、可执行。”腾讯高级执行副总裁、云与智慧产业事业群CEO汤道生认为，全真互联的落地需要五大技术体系不断演进。其中，孪生/视频、远程交互是核心，泛在智能、可信协议、无限算力则是支撑。</p><p></p><p>具体而言：</p><p></p><p>孪生/视频将包括音视频、数字孪生、3D引擎及空间计算等技术体系，能够全细节还原或超写实呈现真实世界，让数字世界和真实世界相互连接、映射与耦合。比如，城市管理者可以通过数字孪生系统实时掌握城市现状、趋势，发现变化过程中的关系、规律，支撑管理决策。</p><p></p><p>远程交互则在物联网、RTC、XR、多感官交互、多模态融合感知技术的引领下，让数实之间从“连接”升级为双向交互，实现可操作、可执行。未来，随着技术发展，远程交互还有望实现全感官体验、全场景无缝切换、加载零等待的升级。比如港口操作员可以利用音视频技术叠加多角度摄像头，实现对集装箱的远程精准操作，提升作业效率。</p><p></p><p>白皮书认为，音视频、物联网、人工智能、数字孪生、区块链、XR等技术已经相对成熟或高速发展中。预计2040年，量子计算、全息投影、折叠光路、脑机接口等前沿技术有望迎来进一步突破，支撑全真互联全面应用。</p><p></p><p>汤道生表示，腾讯目前在音视频、数字孪生、3D引擎、实时渲染、边缘计算、安全、区块链等领域已经做好了技术储备，并建立了核心优势。以音视频为例，腾讯音视频技术经过20多年的打磨和积累已经做到了业界甚至国际领先水平。</p><p></p><h2>解决实际问题是最终目的，数实融合是主战场</h2><p></p><p>在汤道生看来，基于沉浸式的“全真”体验与可操作的“互联”交互，全真互联的最终目的是要解决真实场景中的实际问题。“数实融合将成为全真互联的主战场。”</p><p></p><p>全真互联不仅可以支撑人和组织的能力边界延伸，也能帮助产业发展进化到全域全真的数实融合新模式。白皮书认为，全真互联在沟通协同、研发生产、运营管理、营销服务等产业全链条中都有巨大的应用潜力。</p><p></p><p>在沟通协同方面，全真互联能够降低跨时空沟通成本，提升作业效率。在研发生产方面，全真互联能够加速复杂产品研发，支撑跨地域无阻作业。在运营管理方面，全真互联能够助力空间智慧化管理和企业高质量运营。在营销服务方面，全真互联能够扩大营销半径，提升服务温度。</p><p></p><p>汤道生表示，面对数实融合的时代命题和行业趋势，全真互联也是腾讯产业互联网推进数实融合的重要战略和路径。腾讯将与合作伙伴携手，让全真互联成为企业价值提升和降本增效的利器，释放产业价值。</p><p></p><p>目前，腾讯已经打造了一批全真互联成功案例。</p><p></p><p>比如凭借腾讯20多年积累的音视频通讯能力，腾讯会议用户数超过3亿，服务覆盖全球超过220个国家和地区，是当前中国广泛使用的云视频会议产品。同时腾讯会议开放API和SDK接口，致力于构建一个连接人与人、人与会议室，会议室与会议室的视频会议开放生态。</p><p></p><p>腾讯与宝钢股份合作，利用分布式云、AIoT、实时渲染等技术，探索打造全真全景还原的全息3D裸眼效果“数字工厂”，帮助专家、工程师在数字世界更好地管理实际产线和设备，推动产线管理实现故障回溯、实时监控、工艺改进。</p><p></p><p>在金融行业，越来越多的银行通过腾讯音视频、AI、大数据等技术，打造全真金融服务场景，过往必须到线下排队办理的业务在线就能办好，极大便利了偏远山区居民、外出务工人员以及行动不便群体。</p>",
    "publish_time": "2022-09-28 17:52:10",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "雪花啤酒数字化转型从规划到落地，基本没有空口白话｜行知数字中国 × 郭华",
    "url": "https://www.infoq.cn/article/pF9AomjyXJyx3XKFchYr",
    "summary": "<p>无论是做规划还是做项目，一定不要吝啬在前期花时间。</p>\n<p>《行知数字中国》第四期，InfoQ邀请到华润雪花啤酒数字化负责人郭华，首次对外界深入分享雪花啤酒数字化转型背后的战略部署和相关思考。</p>\n<p>雪花啤酒做数字化，在前期筹备阶段，仅顶层设计、战略规划就花了 9 个月时间，此后也在不断复盘和迭代。在本期视频中，郭华将详述雪花数字化转型框架的意义和其制定过程，希望能对业界有所启发。</p>",
    "publish_time": "2022-09-28 18:16:03",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]