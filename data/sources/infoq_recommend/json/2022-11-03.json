[
  {
    "title": "大师级教程：构建高保真流处理数据管道",
    "url": "https://www.infoq.cn/article/VrdUNI3GRzSsyOptx3ZU",
    "summary": "<p>在去年11月的<a href=\"https://plus-archive.qconferences.com/recap/plus2021/nov\">QCon Plus 2021</a>\"上，Datazoom 的首席架构师暨<a href=\"https://airflow.apache.org/\">Apache Airflow</a>\"的PMC成员<a href=\"https://twitter.com/r39132\">Sid Anand</a>\"做出了<a href=\"https://www.infoq.com/presentations/building-high-fidelity-data-streams/\">在精益团队中构建高保真、近数据流处理为服务</a>\"的演讲，在演讲中，Sid给出了一个从底层构建高保真数据流处理的大师级教程。</p><p></p><h2>介绍</h2><p></p><p>在当今世界中，机械的智能化和个性化不断推进着用户的线上体验。无论是你最爱的搜索引擎的智能优化排序系统、音乐或视频推荐、“你可能感兴趣的人”，还是任何社交平台上根据喜好排序内容的系统，各种各样的数据不断被整合，并借此做出预测让人们保持参与感。虽然有些看起来很神奇的SQL的确可以做到数据整合，但随着现实中数据量的不断增长，将全部数据都存储在同一个数据库变得非常不切实际了。在十年之前我们还会用一个单体数据库来保存数据，但如今下面这张图或许更能代表我们所见到的现代数据架构：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/aa/aab4160643ef5ab4fb57fc9d7ceaeed5.png\" /></p><p></p><p>&nbsp;</p><p>图中所示的是由一或多个数据流动的基础设施服务打包在一起的、针对性解决方案集合，其重点在于数据的流动，而公司对数据复杂性管理通常有两种形式：批量处理或流处理。</p><p></p><h2>是什么阻碍了流处理？</h2><p></p><p>在前面我们所展示的图中，有很多可移动部分，而其宽广的表面积也意味着更高的出错概率。在流处理架构中，任何非功能性需求间的差距都是致命的。数据工程师们但凡是在构建系统时没有将“可X性”作为头等大事的，事后都要花费大把的时间在救急和系统维持上；这里的“可X性”指的是非功能性需求，如<a href=\"https://en.wikipedia.org/wiki/Scalability\">可扩展性</a>\"、<a href=\"https://en.wikipedia.org/wiki/Reliability_engineering\">可靠性</a>\"、<a href=\"https://en.wikipedia.org/wiki/Observability\">可观察性</a>\"、<a href=\"https://en.wikipedia.org/wiki/Operability\">可操作性</a>\"等等。更具体地讲，如果团队不以“可X性”为数据系统构建首要考量，那么数据管道的运维将会饱受中断和干扰的困扰，并通常会因此导致客户不满、团队成员焦头烂额并最终离开团队。</p><p></p><p>让我们深入研究，构建一个流处理系统吧。</p><p></p><h2>从简单的开始做起</h2><p></p><p>这是一段充满野心的征途，而就和任何大型项目或努力一样，我喜欢从简单的开始，比如定义一个目标：</p><p>&nbsp;</p><p>我们想要建立一个系统，将信息从源头S传递到目标D。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/b9/b9e553402cce337f522bfa75b6b99a1a.png\" /></p><p></p><p>&nbsp;</p><p>第一步是通过在S和D之间加一个消息中介来解耦，这一步骤很常见也很传统，是全球范围内通用的。这个消息中介系统可以是任何技术，我在这里选择的是<a href=\"https://kafka.apache.org/\">Kafka</a>\"。在系统之中创建一个Topic（主题）E，代表流经这个主题的事件。S和D通过事件主题E解耦，也就是说，如果D失败了，那么S可以继续向E发布消息；如果S失败了，D也可以继续从E消费消息。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/58/58e97ba7899b300ed3b20d375920c471.png\" /></p><p></p><p>下一步是确定系统的具体实施部分。假设系统在云平台上运行，多数人第一反应是AWS或GCP等公开可用的云平台，但其实Kubernetes也可以，甚至两者混合也没问题。另外，作为项目一开始，我们可以从小规模入手，在主题E的一个分区中运行Kafka的同时，在三个<a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regions_az/\">可用区域</a>\"分别运行一个代理以确保稳定性，将RF或复制因子设为3。此外，S和D需要在一个独立的<a href=\"https://aws.amazon.com/ec2/\">EC2实例</a>\"运行以提升系统可用性。</p><p></p><p>将流处理以服务的形式提供，意味着我们可以在流程S所托管的API端点接收输入消息，并在处理后发送向事件主题E。流程D将会消费主题E中的消息，将其发布到互联网上的第三方端点上。</p><p></p><h2>可靠性</h2><p></p><p>我要问的第一个问题是，“这个系统可靠吗？”让我们重新编辑一下目标：</p><p></p><p>我们想要建立一个系统，将信息从源头S可靠地传递到目标D。</p><p></p><p>更确切地说，应该加上这句话：</p><p></p><p>我想要零信息损失。</p><p></p><p>我们的设计需要根据这个需求变动什么吗？我们需要确保在流程S确认到远程发送来的消息后，流程D必须将该消息传递回发送者。那要如何建立系统可靠性？让我们先将系统一般化，假设我们有三个流程，而不是笼统的S和D，这三个流程都通过Kafka主题线性链接。</p><p></p><p>同所有链式连接一样，这种连接的强度取决于最薄弱处；如果链中每一个流程或环节都是事务性的，那么这个链条本身就会是事务性的。我对“事务性”的定义是：<a href=\"https://doc.akka.io/docs/alpakka-kafka/current/atleastonce.html\">至少有一次交付</a>\"，这也是现在Kafka最常见的使用方式。那要如何让链中每一个环节都是事务性的呢？可以先将链中的处理环节分解出来，流程A是摄取节点；流程B是内部节点，负责从Kafka中读取并写入信息数据；流程C是输出或驱逐节点，负责从Kafka中读取信息并将其发送至互联网。</p><p></p><p>如何让流程A可靠？流程A会通过REST端点接收到一个处理消息m1的请求，在将数据以Kafka事件的形式可靠地发送至Kafka后，再给服务调用者发送一个HTTP响应。至于要如何可靠地将数据传输至Kafka，A需要调用kProducer.send，入参有两个：主题和信息。之后立刻调用刷新（flush），清空Kafka内部的缓存并强制将m1发送向所有三个代理。因为配置了acks=all，A需要等三个代理都发回成功确认，才能响应服务的调用者。</p><p></p><p>那流程C要怎么才能变得可靠呢？流程C是用于读取数据的，通常是从Kafka中批量读取数据，一番处理之后再可靠地发送出去。在我们的示例中，可靠性意味着要接收到外部服务的200 OK响应代码。在流程C接收到200响应后会向下一个Kafka检查点驱动，一旦出现问题，流程C会负向ACK（如NACK）Kafka，强制流程B重新读取数据。</p><p></p><p>最后，流程B要如何可靠？流程B是流程A和C的组合体，流程B需要同流程A一样充当可靠的Kafka生产者，同时也需要像流程C一样充当一个可靠的Kafka消费者。</p><p></p><p>现在我们系统的可靠性是什么情况？万一进程崩溃，会发生什么？如果流程A崩溃，那么系统的摄取将完全中断，无法接收任何新消息。如果流程C崩溃，服务将停止向外部消费者传递消息，但从流程A中传来的消息仍会保存在Kafka中，流程B也可以继续处理，但直到流程C恢复之前，这些消息都不会被交付。</p><p>这类问题的常见解决方案是将所有服务都分别打包在一个大小为T的自动扩展组（autoscaling group）中，每个组都可以处理（T-1）个并发故障。自动扩展组这个词最初由亚马逊提出，但目前任何云平台，包括Kubernetes中都能适用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/21/21be14f0a49acd3d46da2a84e62827ae.png\" /></p><p></p><p></p><h2>滞后</h2><p></p><p>就目前而言，我们的数据流处理系统似乎非常可靠了，但这种可靠性要如何衡量呢？根据可观察性。流处理系统有两个重要的关键质量指标：滞后和损失。如果你对流很熟悉，那么这两个指标应该都不陌生，但如果你是流处理方面的新手，那么请容我介绍下。</p><p></p><p>首先从滞后开始。</p><p></p><p>滞后只是对系统中信息延迟的一种衡量。</p><p></p><p>信息在系统之中的传输时间越长，其滞后性就越大，对企业的影响也就约打，依赖低滞后性见解的企业更会深受其害。我们的目标是尽量缩减滞后，以更快地提供见解。滞后性要如何计算？我们需要一个“事件时间”的概念，也就是一个事件或消息的创建时间。事件时间通常会存放在消息文件中，并随消息一同在系统中传递。对系统中任何节点N的任何消息m1，都可以用以下公式计算滞后性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f2/f22508acdb7ce2e2aaeb31e2e85d7c93.png\" /></p><p></p><p>那么在实际情况中会怎么样？</p><p><img src=\"https://static001.geekbang.org/infoq/f0/f0b6617cdeabcc504bd79ecd87494d5e.png\" /></p><p></p><p>假设我们有一条在中午（T0）创建的消息，消息到达系统中节点A的时间是下午12.01（T1）。节点A处理信息后传递到节点B。消息到达节点B的时间是下午12.04（T3）.节点B处理后传递到节点C，到达时间为下午12.10（T5）。最后，节点C在处理信息后会将其发送到外部。</p><p></p><p>根据前面的公式，我们可以计算出消息m1和节点C之间的滞后时间是10分钟。但实际情况中，系统的滞后时间往往是以毫秒为单位，而不是例子中的分钟级。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/07/070ebac9988beda67cd588822974858e.png\" /></p><p></p><p>&nbsp;</p><p>我们在计算时不断提到的信息到达节点时间也被称作是到达滞后或滞后（lag-in）。另外需要注意，滞后是会累积的。在节点C计算出的滞后时间包含了其上游节点A和B上的滞后；在节点B计算出的滞后时间会包含其上游节点A的滞后。</p><p></p><p>处理到达滞后外，还有一种滞后叫离开滞后。离开滞后是从信息离开节点开始计算，计算方式同到达滞后的类似。参照下图，我们在A、B、C三个节点分别计算了离开滞后时间T2、T4和T6。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f7/f7117a8ec3905ff6a81aee48d6713291.png\" /></p><p></p><p>&nbsp;</p><p>在所有流处理系统中最为重要的滞后指标是端到端滞后（又称E2E滞后）。E2E滞后是指消息在系统中的全部时间，直接计算系统最后一个节点的离开滞后时间，也就是我们系统中节点C的10ms。</p><p></p><p>虽然计算出了某条消息（m1）的滞后时间非常有意思，但在我们要处理数十亿，甚至数万亿的消息量时，这个计算结果就没什么用了。因此，我们需要用统计数据来收集群体行为。我个人偏好用第95或第99个百分数（又称<a href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Statistics-definitions.html\">P95</a>\"、P99），但别人更偏好P99或MAX。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/94/94674972fe6fb3ade243400c38b4fec5.png\" /></p><p></p><p>我们可以构建的统计数据有很多，可以计算在P95时整体的端到端滞后，或者任何节点上的到达滞后或离开滞后。另外还可以计算带有到达滞后和离开滞后的流程持续时间，也就是信息在链上任何节点内的时间。但这组数据有什么用呢？</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/92/92bdca68251ca24fb7a04ba648cb124d.png\" /></p><p></p><p>让我们考虑一个更实际的例子。假设在一个上图中的线性结构里，有一条消息一路从红色、绿色、蓝色节点一路流转，最终到达橙色节点。这个结构其实是我们在生产环境运行的系统，上图是从我们在生产上的服务<a href=\"https://aws.amazon.com/cloudwatch/\">CloudWatch</a>\"中截取的。如你所见，我们计算了每个节点的流程持续时间，并以饼状图展示。这让我们对系统中滞后性的分布情况有了大致的概念。这个系统非常完善，每个节点的滞后时间大致相同，没有特别突出的。把饼状图按时间摊开会得到右侧的图，可以看出性能在某段时间内基本相同。因此，我们会认为这个系统是很合适的，性能表现在任何时间范围内都保持一致。</p><p></p><h2>损失</h2><p></p><p>在分析完滞后后，我们再来看看损失。损失是一种衡量信息在通过系统时损耗的计量方式。导致信息损失的原因有很多，其中大多数都是可避免的。数据损失得越多，数据质量就越差。因此，我们需要尽量降低数据损耗，以提供更高质量的见解。那么要怎么计算流处理系统的损失呢？损失可以看作是系统中任意两点间的信息集差。还是以先前的线性结构为例，不过在系统其中流转的是十条信息而非一条。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/88/885cb66aa0b95aa644fb0e56c77a2fa2.png\" /></p><p></p><p>我们可以通过损失表格来计算损失。表格中的每一行都代表一条信息，列则代表链中的节点。消息一成功通过系统，因此在每一列都是“1”；消息二同理。但消息三在成功通过红色节点后没能到达绿色节点，蓝色和橙色也没能接收到消息三。在表格最底部计算了系统每个节点中的损失情况，右下角则是计算了系统整体的端到端损失。在我们的例子中是50%。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/da/da9b609d658dcaa7bb46ca4e98f041e3.png\" /></p><p></p><p>在流数据系统中，消息会不断流动。那我们该从哪里计算呢？我们需要利用消息事件时间，将消息分配到一分钟长度的时间桶内。比如在某天的12.34时，我们计算所有落入12.34这一分钟事件时间的损失表格，这个方案也可以应用到一天中的任何时间。</p><p></p><p>假设现在是下午12.40，系统中的消息通常会延迟到达。我们现在可以看到下面这四张表都有统计数据更新。然而，到下午12.35表格中数据便不再变化，因此我们可以断定能到达的消息均已到达，并可以开始计算损失。时间早于这个时间点的损失表格都可以弃之不用，这样也可以裁剪掉不需要再计算的表格来缩小损失计算规模。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1d/1de3d3db0ba8ae87e766af94081defcc.png\" /></p><p></p><p>&nbsp;</p><p>总的来说，我们等待几分钟的信息传输时间后再计算损失，如果损失超过阈值（如1%），就触发损失警告。</p><p></p><p>在梳理清楚滞后和损失的定义后，我们就可以衡量系统的可靠性和滞后性了。</p><p></p><h2>性能</h2><p></p><p>那么我们系统的性能已经调整完毕了吗？让我们再回顾下目标。我们想要建立一个系统，将信息从源头S可靠且低延迟地传递到目标D。要想更好地了解流处理系统的性能，我们需要先认识端到端延迟的组成部分。首先是摄取时间，这是指从接收请求的第一个字节开始，到发送响应的最后一个字节。这个时间段包含了所有我们在可靠地将消息发送至Kafka时产生的任何开销。在管道尽头还有“驱逐时间（expel time）”和“排放时间（egest time）”，这是指在D段处理和整合消息所需要时间，其余时间被统称为传输时间（transit time）。这三者共同构成了端到端的滞后时间</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/07/076be76ee198f03b5b22ea50755480bf.png\" /></p><p></p><p></p><h2>性能惩罚</h2><p></p><p>在讨论性能时，我们也不能忽视为建造无损耗系统所牺牲的性能，我们需要用滞后换取可靠性。其中部分性能惩罚项如下。</p><p></p><p>首先是摄取惩罚（ingest penalty）。为了保障可靠性，S需要对每个接入的请求调用kProducer.flush，等待Kafka传来三个ACK才会发送API响应给客户端。虽然我们并不能干掉这些摄取惩罚，但却可以利用批处理来平摊成本。也就是说，我们可以通过支持推广批处理API，在API调用滞后时间不变的情况下最大限度地提高吞吐量，在每个网络请求中获取多个消息。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5e/5e9c7b099341e0a38b0a96e5bb98286a.png\" /></p><p></p><p>同样，还有驱逐惩罚（expel penalty）。有一个需要注意的点是，Kafka的速度很快，远比公共互联网上常见HTTP的往返时间（RTTs）还要快很多个数量级。事实上，大部分的驱逐时间就是HTTP的往返时间。同理，这里我们也采用分摊开销的方法：在每个D节点中，都增加批处理和并行性。我们从Kafka中读取批量数据后重新批处理为更小的批次，然后通过并行线程将这些批处理发送到各自的目的地。这样，我们就可以最大限度地提高吞吐量，减少单个消息的驱逐成本或惩罚</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/08/08a5c171da7e0a7a2fc84f382149acfa.png\" /></p><p></p><p>最后但同样重要的是重试惩罚（retry penalty）。为保证管道数据的零损失，我们需要在D端不断重试消息，只要次数够多就会成功。我们对D端调用的远程端点没有任何控制，这些端点可能会遭受瞬时故障，或者时不时对D进行限制，以及其他我们无法控制的事情都有可能发生，我们必须通过不断重试才能确保成功。这些情况被称作是可恢复故障，但仍有一些故障时不可恢复的。例如，4开头的HTTP响应代码，除了常见的节流响应代码429之外，我们都不应该继续重试，因为即使重试也是不会成功的。</p><p></p><p>也就是说，为了处理重试惩罚，我们必须以滞后性为代价，并慎重考虑需要重试的内容。这一点前文已经提过了，我们不应该重试任何不可恢复故障，并巧妙采用重试的方式。</p><p></p><h2>性能-分级重试</h2><p></p><p>我有一个叫做“分层重试”的想法，可以参考下面的架构图：我们将架构分为两层，本地重试层和全局重试层。在本地层中，我们尝试低频在D端发送一个可配置次数的消息，这一层是为尝试在远程目标短暂或瞬时中断期间重试消息传递。</p><p></p><p>如果耗尽本地重试次数，D端会将消息转移到全局重试服务（gr）中，全局重试层会在长时间内不断重试，以期望能超过目标的中断时长并成功传递消息。通过将消息重试任务转移到全局层，D服务可以将资源用于传递正常消息。但需要注意的是，D服务可能会需要向不同的远程服务或端点发送消息，也就是说，如果其中之一的远程目标中断，而其他目标完全正常。流处理系统中全局重试和服务D都会由Kafka主题分隔为RI（Retry_In）和RO（Retry_Out）。</p><p></p><p>这种方式的好处在于，实践中我们所遇到的全局重试概率远低于1%，甚至常常连0.1%都不到。因此，即使这些重试会需要更长时间，它们也不会影响我们的P95端到端延迟。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2a/2a4ff77fc536e43e2e03cc0552518b51.png\" /></p><p></p><p></p><h2>可扩展性</h2><p></p><p>目前为止，我们已经有了一个小规模的、运行良好的系统。那么这个系统要如何随流量的增加而扩容呢？</p><p>首先是辟谣，可以处理无限制规模的系统并不存在。很多人会以为，通过转移AWS或其他托管平台可以实现无限制规模系统，但现实情况是，每个账户都会有限制，因此流量和吞吐量都是有上限的。从根本来说，每个系统都有自己的流量等级，无论这个系统是在哪里运行，流量等级都是通过对系统的负载测试来衡量的。我们只有通过迭代运行负载测试并移除瓶颈才能到达更高的规模。</p><p></p><p>在对数据流自动扩缩容时，我们一般会有两个目标。目标一是自动扩容以保持低延迟（如减少端到端滞后性），目标二是缩容以减少成本。我们在此先关注目标一。在自动扩容时，有不少是需要考虑在内的，首先，什么可以自动扩容？至少在过去十年间，亚马逊已经可以做到计算的自动扩容了，所有的计算节点都是可自动扩容的。那Kafka呢？Kafka目前还不支持自动扩容，但未来或许可以。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b3/b366b7e62e893bbfef42ac99454e5f81.png\" /></p><p></p><p>&nbsp;如何正确挑选合适的指标来触发自动扩缩容操作是非常关键的。我们所选择的指标必须要有低延迟，要能够随流量的增加而增加，随微服务的扩容而下降。根据我的经验，平均CPU是很好的衡量标准。但还有一点需要注意，如果你的代码中有锁、代码同步，或者IO等待，那么你可能会没办法触发系统CPU的过饱和。随着流量的增加，CPU用量也会到达高峰并导致自动扩缩容操作停止，系统延迟增加。如果你看到系统中出现这种情况是，最简单的解决方法是将阈值降低到CPU峰值之下。</p><p></p><h2>结论</h2><p></p><p>现在，我们的系统拥有了期望中的所有非功能性需求。虽然这篇文章中覆盖了很多关键要素，但还有很多没有提及的：隔离、容器的多级自动扩展、流处理操作者，以及缓存的架构。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/high-fidelity-data-streams/\">Building &amp; Operating High-Fidelity Data Streams</a>\"</p>",
    "publish_time": "2022-11-03 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何把技术“卖”给业务，从 IT 视角看麦当劳中国数字化",
    "url": "https://www.infoq.cn/article/MQ0BZcA5TUaNbT7hIEm2",
    "summary": "<p></p><p>出品 | InfoQ ·《行知数字中国》</p><p>采访人｜霍太稳，极客邦科技创始人兼 CEO</p><p>采访嘉宾｜陈世宏，麦当劳中国首席信息官</p><p>编辑｜罗燕珊</p><p></p><p>目前，麦当劳中国已经发展到近 5000 家餐厅，员工数量超过 18 万。作为餐饮行业数字化的标杆案例，麦当劳中国被誉为全球数字化程度最高的麦当劳。《行知数字中国》<a href=\"https://www.infoq.cn/video/sVz55QCL2muze0GQtZA2?utm_source=home_video&amp;utm_medium=article\">第五期</a>\"，InfoQ 邀请到麦当劳中国首席信息官陈世宏，跟着他的视角去了解他眼中的“数字化金拱门”。</p><p></p><p>在陈世宏看来，企业进行数字化的过程很重要的一点是：转换思考问题的角度。尤其传统企业容易形成思维定势，作为 IT 侧人员，需要从技术的角度切入，并尝试用新的思路把传统业务重新思考一遍，再带着新想法去影响原来既定规则的制定者，一同找出改进的机会点。</p><p></p><h2>数字化转型逻辑</h2><p></p><p></p><h4>消费者是客户，员工也是客户</h4><p></p><p>服务业往往提倡客户至上，服务第一。即使进入数字化时代，对于餐饮企业而言，以“客户为中心”的出发点还是没变，本质还是离不开如何提升客户体验。</p><p></p><p>一方面，移动互联网让线上购物成为消费者日常，如何在线上提供不亚于线下的、更便利和流畅的消费体验，是餐饮业典型的数字化改造需求。</p><p></p><p>另一方面，在麦当劳中国看来，所谓客户，不仅指前来消费的顾客和消费者，员工也是他们的客户，因为企业经营过程中的效能的提升，也是数字化的核心目标。那么在这个场景下，近5000家餐厅里的员工都是客户，他们既包括在炸薯条做汉堡的员工，也包括每天凌晨2点多钟在做盘点的员工。</p><p></p><p>“如何站在一个合适的位置上，去构思更合理的数字化产品方案，让员工的工作变得更高效，让员工感到更满意，这是我们提供数字化解决方案的其中一个根本的出发点。”陈世宏说道。</p><p></p><h4>避免把数字化投资当成一次性项目</h4><p></p><p>除了“以客户为中心”，把数字化建设当成持续累积数据资产的过程也是很关键的一点。</p><p></p><p>为了提升效能，数字化建设中可能会出现“今天采购一个ERP，明天采购另一个系统”的缺乏统筹的情况，但如果盲目买系统，系统和系统之间没有产生关联，结果就会形成一座座数据孤岛，数据不能整合，也就无法把数据的价值发挥出来，系统们最终都会“腐化掉”。</p><p></p><p>因此，为避免把数字化投资当成一次性项目，陈世宏认为，首先要勾勒出数字化框架，当中要明确究竟要建设哪些对象领域模型、公司要建设哪些该有的数字化资产，然后再围绕这个目标去坚定做建设和投入，而不是频繁建设短期项目或把项目推倒重建。若没有产生累积效应，那么公司对 IT 领域的投资也会逐渐失去信心，并且对企业的数字化会带来很大的损伤，也就谈不上创造经营洞察和使能商业决策了。</p><p></p><h2>难题和挑战</h2><p></p><p>回到麦当劳中国本身，在数字化践行方面，其算得上是先行者。它是<a href=\"https://www.yicai.com/news/100285340.html\">最早试点微信功能</a>\"的快餐企业，从 2015 年起，就先后接入微信支付、推出小程序点餐、接入微信会员卡等等。</p><p></p><p>不过，在最初推行之时，麦当劳中国的小程序和App在体验上存在较多问题，比如“有多个小程序、用户需要在小程序之间反复横跳”、“小程序和App之间的数据没打通”等现象时常被消费者诟病。</p><p></p><p>而在过去这两三年间，麦当劳中国对消费者的线上体验做了大幅改进，一个显性的成果体现在应用程序口碑的挽回：麦当劳App在应用商店的评分经历了从2分到接近5分的提升。</p><p></p><p>这份成绩单的背后，陈世宏提到数个关键因素：解决全球化产品移植到中国的水土不服；用户体验旅程的梳理，品牌理念的理解和再设计，做有温度的产品；将持续改进的能力融入到C端产品的数字化血液里；跨渠道的一致性和流畅性；持续微创新；与麦当劳总部的衔接等等......</p><p></p><h4>全球标准化与市场差异化的平衡</h4><p></p><p>标准化被深深写在麦当劳的基因里，如此一来，在瞬息万变的移动互联网时代，麦当劳中国区业务的发展就会受到极大的限制，有翅难展。</p><p></p><p>甚至连自建App都是一件非常“麻烦”的事情，<a href=\"https://www.huxiu.com/article/240420.html\">最初</a>\"中国区的App不仅需要在麦当劳全球的框架里面开发，用户体验逻辑也来自于全球统一的标准流程（如邮箱注册账号），最终整个App在麦当劳的体系内花了近五年的时间才弄完。与敏捷开发、快速迭代的模式相背而驰的结果是，App的开发跟不上用户需求，据悉当时向总部说服做小程序也要耗费不少功夫。</p><p></p><p>2017年，这种约束的关系开始有了更多松弛空间，中信股份、中信资本和凯雷投资集团与麦当劳签署了中国区业务的收购协议，新公司“金拱门”成为麦当劳在中国的唯一特许经营商。金拱门也向麦当劳全球争取更多自主性，来推出自己的App。</p><p></p><p>尽管如此，直到今天，“标准化之下的差异化”依然是中国区团队在工作过程中需要持续攻克的难题，陈世宏指出，怎么克服“标准化的快速复制、扩张”与“贴近消费者诉求的市场化的本土需求”之间的矛盾，还需要投入非常多的技巧和耐性。</p><p></p><p>“大家都非常重视中国市场，而这个市场所伴生的一些非常独特的需求也是很有魅力的，这些需求往往能够反哺全球、被构筑进麦当劳的全球化市场里。”</p><p></p><h4>调整观念</h4><p></p><p>除了平衡全球化和本土化市场的差异，麦当劳中国的数字化转型同样要面临着传统生意和技术融合的普遍挑战。</p><p></p><p>当陈世宏以互联网技术人的身份进入到这样一家相对传统、有一定历史沉淀的企业里，他才深切体会到互联网与实体经营企业对数字化、对 IT 的认知有很大的区别。</p><p></p><p>比如现在在互联网或技术公司里，很少会提“打通”这个词，但加入麦当劳中国后，他发现“打通”成了一个非常痛的痛点。</p><p></p><p>再比如他发现传统企业更多的是以“我今天买个笔记本电脑，明天要去买其他工具”的短期项目制方式去看待数字化改造，而没有意识到通盘规划、系统性长期运作的重要性。</p><p></p><p>于陈世宏团队而言，如何把“技术”推销给业务团队也是日常工作中的一大挑战。</p><p></p><p>传统企业里提到产品经理，往往是指研发线下消费品的角色，比如在麦当劳里研发汉堡等食品的产品经理。而陈世宏团队里产品经理的职责则是研发数字化解决方案，方案出来之后，如何把它推销给业务团队，用以优化业务流程或者让业务团队的工作变得更高效，也是一个颇具挑战性的任务。</p><p></p><p>“今天我们再看技术和传统企业的融合，不能简简单单地把技术看成一个工具，它已经变成产品的一部分了。（解决方案）跟汉堡一样是产品，只是一个是有形的、拿在手上的产品，一个是在背后买走的服务。”</p><p></p><h4>快速学习带来的消化能力挑战</h4><p></p><p>技术人从互联网企业进入到传统公司后，往往会经历比较漫长的适应过程。对于陈世宏而言，进入麦当劳中国之后，他也经历了重新学习和对自己原有知识体系再造的过程。</p><p></p><p>其认为，一线技术人员进入到传统业务领域里去做垂直化改造，一定要识别出自己的位置。一方面要理解业务是什么、运转的逻辑是什么、消费者是谁、客户是谁；另一方面，理解业务逻辑之后，要思考自己能给业务提供的价值是什么，结合客户的诉求、以及自己所具备的能力，把这些信息都匹配起来，便有助于梳理出自身定位以及应该做什么样的事情。</p><p></p><p>据介绍，在麦当劳中国，无论职级高低，入职之后一定会有一周的时间在餐厅里面做一名员工。</p><p></p><p>“我曾经有一周的时间就待在餐厅里，每个岗位我都做了一遍，从打桌、帮用户点餐，到后厨，比如帮用户做一杯薯条，做一个汉堡，以及打烊之后，做盘点工作，了解清洁工作究竟有哪些工序，开铺的时候应该做哪些事情，我们每一个人都要去经历一遍。”</p><p></p><p>当所有的技术人员都经历过这样一个过程之后，在后续的开发工作中就很容易产生画面感，能够设身处地地想象如何通过技术的方式改造业务流程。虽然一周的时间并不足以让一位员工对业务产生非常深入的了解，但陈世宏表示，该方式能让员工跟餐厅产生连接，后续大家遇到任何问题都是可以随时再到餐厅去做了解。</p><p></p><p>此外，陈世宏还特地提到团队在技术方面遇到的高并发挑战，“基本上每天中午就是一次‘秒杀’”，在数千家餐厅的体量下，饭点时刻提供查询或下单服务的并发量巨大，这类因生意模式带来的技术难题，也是陈世宏团队需要去克服的长期挑战。</p><p></p><h2>数字化人才建设</h2><p></p><p>如今，麦当劳中国一线员工也可以通过一些数字化平台和载体，更实时地了解企业经营的现状，特别是其所在餐厅的经营情况。这背后和一个叫做 Data Citizen （数据公民）的项目有关，它鼓励员工通过工具去了解数据。</p><p></p><p>以往，解读数据似乎是技术部门的特权，业务团队要了解经营现状，常常需要以需求的形式去做申请，“比如跟 IT 部门或者某个技术部门说，‘我需要去看一个什么样的数据，你帮我做个什么样的解读。’”</p><p></p><p>但随着技术的进步，数据分析的门槛变得越来越低，因此陈世宏团队希望把数据分析能力植入到业务团队，让业务团队能够以相对轻松、短链路的方式落地需求，于是他们提供了相关的工具给业务团队并输出培训，教业务团队运用数据平台沉淀的数据资产。</p><p></p><p>“甚至我们发现很多业务团队的同事，可以直接写SQL去读一些数据，这样意味着他去获取数据的时候，他的维度会更加灵活，看到的东西可以更加接近于脑海里的原生的想法，”陈世宏进一步介绍称，还有一些业务团队会跟他们一起共建算法引擎，一块构筑智能化平台，比如对于外卖配送商圈的定义，基本是由业务团队来完成，技术团队仅提供平台载体，“这就是我们把数字化思考的方式植入到系统里面去的一个路径。”</p><p></p><p>整体来看，陈世宏认为包括麦当劳中国在内的很多传统企业，目前比较缺乏的数字化人才是企业级架构师，偏向复合型人才，该架构师既需要对业务有非常透彻的理解，又能够勾勒出和搭建数字化长期发展路径，能用不同的视角去思考解决方案。</p><p></p><p>行业繁荣之时，许多问题容易被高速增长的表象掩盖掉。如今增长放缓，如何提升效率、效能成了迫在眉睫的行业挑战。迈入数字化转型时代，陈世宏认为IT 从业人员面临着很多机遇，产业转型升级的发展空间巨大，而“金拱门”只是其中众多产业分支里的一间公司，其呼吁更多技术人员能够加入到数字化转型的建设当中，以更积极的心态去看待这个时代。</p><p></p><p>对本期内容感兴趣的读者，欢迎关注<a href=\"https://www.infoq.cn/album/79\">《行知数字中国》视频合辑</a>\"，我们将在近日更新本期完整版内容。</p><p></p><p>采访嘉宾介绍：</p><p></p><p>陈世宏，麦当劳中国首席信息官，负责 IT 战略、技术实现规划、数字产品路线图、技术基础设施、新技术创新和 IT 团队结构。世宏带领 IT 团队实现数字化转型，从提升消费者端体验到重新设计企业业务流程。</p><p></p><p>世宏于2020年4月加入麦当劳中国。为了加速麦当劳在中国的数字化能力和业务渗透，他制定了三层技术架构和团队结构的蓝图，通过可组合的“中间平台”实现全渠道体验。在不到一年的时间里，世宏凭借其领导力和技术敏锐度，带领团队实现了麦当劳消费端数字体验的进化和飞跃。</p><p></p><p>世宏还将本土洞察与麦当劳全球技术标准相结合，坚持技术实用主义的理念。他领导了近 5000 家餐厅的下一代网络的部署，提供了符合全球标准的高速和稳定的基础设施，同时也实现了与中国本土相关的创新。</p>",
    "publish_time": "2022-11-03 10:19:38",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "阿里云张建锋：云计算变革被严重低估了",
    "url": "https://www.infoq.cn/article/Ju5weRM9b7eXmCpYSUHM",
    "summary": "<p>InfoQ现场报道，11月3日，在2022云栖大会上，阿里云智能总裁张建锋发表了主题演讲。</p><p></p><p>张建锋认为历经十多年的发展，云计算带来的变革依然被严重低估，它正在重构整个IT软硬件和终端世界，形成一个全新的计算体系。新一轮的科技变革正在深入发展，阿里云将坚持技术长征，面向下一代体系去构建第二技术曲线，抓住未来技术的定义权。</p><p></p><p>张建锋认为，以云计算为核心的新型计算体系，正在带来三大变革：首先，云重构了整个IT硬件体系，数据中心、芯片、服务器等产业链发生深刻变化；其次，软件研发范式发生深刻变革，Serverless、低代码、AI大模型开源等趋势，大幅提升软件生产效率；最后，云和端加速融合，算力从端转移上云，未来万物皆是计算机。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0e/0e0dbb1bda78893b6297240d691cd69d.png\" /></p><p></p><h2>重构整个IT硬件体系</h2><p></p><p>&nbsp;</p><p>张建锋回顾了云计算演进历程，过去十多年，云的创新主要集中在软件领域，首先出现了分布式虚拟化，而后实现了资源池化，形成了广泛的应用规模。现在，云计算已经从软件创新，走向软硬件协同创新，用云来定义整个IT硬件体系。</p><p>&nbsp;</p><p>今年，阿里云发布了一款云数据中心专用处理器CIPU，替代CPU来管理和加速计算、存储和网络资源。这是一种全新的架构方式，代表着云计算深入到数据中心内部做体系化创新。CIPU实现了全面专用硬件加速的高性能，包括高带宽、高吞吐和弹性RDMA的能力。“飞天+CIPU”的组合性能表现普遍优于业内同类产品，性能可提升20%以上。</p><p>&nbsp;</p><p>在此基础上，阿里云基础设施已经广泛基于CIPU架构进行建设，并且构建了全栈自研的基础设施，例如自研CPU芯片倚天710、磐久服务器、EIC高性能网卡、磐久交换机、磐久液冷一体机、磐久液冷集装箱等自研硬件。</p><p>&nbsp;</p><p>去年，阿里巴巴发布了首款“为云而生”的芯片倚天710。目前，倚天710云实例已在多家互联网科技公司大规模应用，算力性价比提升超30%，单位算力功耗降低60%，这是中国首个云上大规模应用的自研CPU。</p><p></p><p>在2021年双11期间，天猫双11核心交易系统平滑迁移至倚天710实例。中国一些知名的科学计算、智能手机行业和互联网等领域的企业在迁移至倚天710实例后，性价比均得到了显著提升。</p><p>&nbsp;</p><p>张建锋表示，未来阿里云还将继续扩大自研CPU的部署规模，预计未来两年内20%新增算力将使用自研CPU芯片倚天710。</p><p>&nbsp;</p><p>他认为，过去十多年，飞天为阿里云打下了扎实的技术基础，让云实现了第一次飞跃。自研CPU芯片倚天710、下一代云计算体系架构CIPU将为阿里云构建第二技术曲线，是云面向下一代技术构建的核心竞争力。</p><p>&nbsp;</p><p></p><h2>软件研发范式发生深刻变革</h2><p></p><p>&nbsp;</p><p>计算体系的变革不仅将发生在IT硬件世界，软件研发范式也将发生颠覆性变化。</p><p></p><p>张建锋认为，软件研发范式的变革有三个层次，第一是新兴的软件开发方式崛起，软件架构全面Serverless化；第二是软件开发不再是程序员的专利，低代码让未来80%应用能够由业务人员直接开发；第三是未来所有软件都是AI化的，大模型开源将加速AI真正普及。</p><p>&nbsp;</p><p>其中，Serverless将让云计算从一种资源真正变成一种能力。张建锋表示，过去云计算用云服务器替代了物理服务器，但客户依旧按“几核几G服务器”的模式来购买云资源，未来云计算将全面Serverless化，更加接近“电网”模式，按计算的调用次数付费。</p><p>&nbsp;</p><p>这将带来软件开发方式的深刻变化，软件架构从原来的主机架构迁移到Serverless架构，客户只需要开发业务逻辑，不再需要关心运维问题。此外，Serverless架构可以降低软件开发门槛，提供更多的预制模块，大幅提高软件生产效率。</p><p>&nbsp;</p><p>例如，一家烟草公司只需要两个开发人员就可以做出整套物流系统。对互联网新兴应用而言，Serverless架构让应用轻松抗住流量高峰。以南瓜电影为例，Serverless架构让这个视频APP无人值守就能应对百万级流量，并且总成本较此前下降40%。</p><p>&nbsp;</p><p>其次，低代码将进一步降低应用开发门槛，张建锋认为，未来80%的应用将由业务人员开发，不懂低代码就和20年前不会用word一样。数据显示，钉钉上，两年新增了500多万个低代码应用，聚集了380余万低代码开发者。</p><p>&nbsp;</p><p>最后，越来越多的软件将AI化，大模型开源将推动AI真正普及。张建锋表示，开源是软件进步的核心推动力量，过去开源推动了软件架构的进步，未来开源还将推动AI应用的进步和普及。目前，达摩院在中文AI模型社区模搭ModelScope上，开源了超过300个优质模型，可以帮助开发者利用基础模型快速开发AI应用。</p><p>&nbsp;</p><p></p><h2>云端加速融合，万物皆是计算机</h2><p></p><p>&nbsp;</p><p>今天，云计算正在创造越来越多的终端形态。几十年前，手机只能用来打电话，现在手机是一个手里的计算机。过去，汽车从只讲究“马力”，现在汽车需要比拼“算力”，成为一个“四轮计算机”。</p><p>&nbsp;</p><p>张建锋认为，云端加速融合，算力正在不断从终端转移上云，这让终端突破了物理限制，不仅手机、电脑、汽车、音箱会变成计算机，未来万物皆是计算机。</p><p>&nbsp;</p><p>例如，Rokid在推出的AR眼镜中接入阿里云无影架构，利用云上算力，用户打开仅有85克重量的眼镜，就能在眼前的虚拟现实画面中，与人聊天、办公，并且还能做3D渲染、大数据编程等复杂工作。</p><p>&nbsp;</p><p>在PC电脑端，未来阿里云继续将RISC-V芯片和无影架构结合，让创新终端具有更高性能、更低能耗，并实现全栈自研。目前，阿里巴巴已经成为全球RISC-V技术与生态发展的引领者，并且已经完成了和云操作系统的适配，迈出了端边云一体的重要一步。</p>",
    "publish_time": "2022-11-03 10:59:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "阿里云宣布算力攻坚重要突破！倚天710已大规模应用，性价比提升超30%",
    "url": "https://www.infoq.cn/article/fWqoFNWr5SCpFd0r41tJ",
    "summary": "<p>11月3日，InfoQ 2022云栖大会现场报道，<a href=\"https://www.infoq.cn/article/Ju5weRM9b7eXmCpYSUHM\">阿里云智能总裁张建锋</a>\"宣布，<a href=\"https://www.infoq.cn/article/KKAJ6VM0S2X9HWq0T9mq\">阿里云自研CPU倚天710</a>\"已大规模应用，阿里云未来两年20%的新增算力将使用自研CPU，这是阿里算力攻坚的重要突破。</p><p>&nbsp;</p><p>目前，倚天710已在<a href=\"https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247574829&amp;idx=1&amp;sn=d234fe4fed2759a34e697a5a679203d8&amp;chksm=fbeb1ce2cc9c95f46321925247c91aa4b4e857f12b100de8b1ae4443f0d9e270a5b5b591dc10&amp;scene=27#wechat_redirect\">阿里云数据</a>\"中心大规模部署，并以云的形式服务阿里巴巴和多家互联网科技公司，算力性价比提升超30%，单位算力功耗降低60%，这是中国首个云上大规模应用的自研CPU。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/81/c2/81e3029c21660bd299271bef5634ffc2.png\" /></p><p>&nbsp;</p><p>2021年云栖大会，<a href=\"https://www.infoq.cn/article/kxN6zLPLbEyyvIVUbeav\">阿里平头哥</a>\"发布首颗CPU芯片倚天710，该芯片针对云场景研发，同时兼顾了性能与易用性。经过一年的业务验证，倚天710已大规模部署并提供云上服务。倚天710云实例与飞天操作系统及CIPU融合，在数据库、大数据、视频编解码、AI推理等核心场景中的性价比提升超30%；阿里云提供丰富的生态工具，支持全应用生态适配，0代码修改即可完成主流业务迁移。</p><p>&nbsp;</p><p>目前，倚天710云实例已应用于阿里巴巴集团核心业务，并服务科学研究、智能手机行业和多家知名互联网公司。2021年双11期间，天猫双11核心交易系统平滑迁移至倚天710云实例，算力性价比提升30%；汇量科技广告推理业务使用倚天710云实例，性能和网络带宽双双提升，性价比提升40%以上。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/2d/07/2df6edc04ecb4a9670962d8f06da6f07.png\" /></p><p></p><p><a href=\"https://www.infoq.cn/article/mNaShfSiXdRqXSV4DsaY\">汇量科技首席人工智能官朱小强</a>\"表示：“随着在线推理模型不断升级，我们对CPU性能和内网带宽要求更高，倚天710云实例满足了我们业务升级的需求，实现了降本与增效。”</p><p>&nbsp;</p><p>“<a href=\"https://www.infoq.cn/article/Ju5weRM9b7eXmCpYSUHM\">云计算</a>\"的发展进入了全新的阶段，未来十年，软硬件一体化的自研计算体系是云服务商的立身之本，只有在核心技术和产品的研发上持续创新才能抢占定义权。”阿里云智能总裁张建锋表示。</p>",
    "publish_time": "2022-11-03 11:04:58",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "“赋能制造 因你而耀”第六届全国工业互联网数据创新应用大赛赏金百万正式启航",
    "url": "https://www.infoq.cn/article/FqX4zbJCa6xjrA0XGLFM",
    "summary": "<p>盼望已久的<a href=\"https://www.industrial-bigdata.com/Home\">第六届全国工业互联网数据创新应用大赛</a>\"（以下简称“大赛”）装箱百万赏金正式扬帆启航了。</p><p></p><p>为了鼓励企业落地工业互联网创新数据应用，2017 年起，中国信息通信研究院在工业和信息化部指导下，举办工业大数据创新竞赛。这是首个由政府主管部门指导的工业大数据领域最具权威的全国性创新竞赛，为工业大数据人才培育、产业创新、生态打造提供支持。2021 年，“工业大数据创新竞赛”全面升级为“全国工业互联网数据创新应用大赛”，将进一步为加快我国工业互联网数据创新应用贡献力量。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/30/6d/30c8022c6dcb14f4b44ab93a307d196d.jpg\" /></p><p></p><p></p><h1>“耀”出精彩</h1><p></p><p></p><p>为了进一步壮大以应用实践为导向的大数据算法人才队伍，挖掘更多工业互联网数据创新应用共性需求场景落地，大赛设置了工业大数据算法和创新应用两条赛道，优胜者将分享百万奖金，更有机会与深圳市宝安区签署落户协议，作为优秀的工业大数据解决方案创业团队在宝安区落户！</p><p></p><h1>“耀”真好玩</h1><p></p><p></p><p>此刻，算法赛道火热报名中！</p><p></p><p>算法赛道赛题基于“碳达峰”、<a href=\"http://www.gov.cn/xinwen/2021-12/22/content_5664043.htm\">“碳中和”</a>\"国家战略背景设置。赛题挑战来自氢能产业龙头企业<a href=\"https://www.dongfang.com/\">中国东方电气集团</a>\"的真实课题和真实数据。让选手在比拼大数据算法能力的同时，亲身参与到绿色氢能前沿领域的专业课题。赛题为“氢燃料电池系统性能均值预测”，要求参赛团队通过分析各变量与系统性能均值之间的动态变化，构建以系统性能均值为核心的算法模型。大赛成果模型可为氢燃料电池系统的性能分析、设计优化和运营改进提供数字孪生模拟手段，为氢燃料电池的设计、制造、运行及维护全生命周期提供助力。</p><p></p><h3>报名方式</h3><p></p><p>即日起至 12 月 3 日 0:00，高等院校、科研单位、互联网企业等人员均可通过大赛官方报名通道（请在 PC 上访问 <a href=\"https://www.industrial-bigdata.com/Challenge/dynamic?competitionId=8UHAP1L3SYO8ROXQAJSE8EDHTRDAVC2S\">https://www.industrial-bigdata.com/Challenge/2022ii</a>\"）报名参赛。</p><p>联系人：赵先生 13825233551</p>",
    "publish_time": "2022-11-03 11:50:25",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]