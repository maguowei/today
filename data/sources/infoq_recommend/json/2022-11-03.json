[
  {
    "title": "大师级教程：构建高保真流处理数据管道",
    "url": "https://www.infoq.cn/article/VrdUNI3GRzSsyOptx3ZU",
    "summary": "<p>在去年11月的<a href=\"https://plus-archive.qconferences.com/recap/plus2021/nov\">QCon Plus 2021</a>\"上，Datazoom 的首席架构师暨<a href=\"https://airflow.apache.org/\">Apache Airflow</a>\"的PMC成员<a href=\"https://twitter.com/r39132\">Sid Anand</a>\"做出了<a href=\"https://www.infoq.com/presentations/building-high-fidelity-data-streams/\">在精益团队中构建高保真、近数据流处理为服务</a>\"的演讲，在演讲中，Sid给出了一个从底层构建高保真数据流处理的大师级教程。</p><p></p><h2>介绍</h2><p></p><p>在当今世界中，机械的智能化和个性化不断推进着用户的线上体验。无论是你最爱的搜索引擎的智能优化排序系统、音乐或视频推荐、“你可能感兴趣的人”，还是任何社交平台上根据喜好排序内容的系统，各种各样的数据不断被整合，并借此做出预测让人们保持参与感。虽然有些看起来很神奇的SQL的确可以做到数据整合，但随着现实中数据量的不断增长，将全部数据都存储在同一个数据库变得非常不切实际了。在十年之前我们还会用一个单体数据库来保存数据，但如今下面这张图或许更能代表我们所见到的现代数据架构：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/aa/aab4160643ef5ab4fb57fc9d7ceaeed5.png\" /></p><p></p><p>&nbsp;</p><p>图中所示的是由一或多个数据流动的基础设施服务打包在一起的、针对性解决方案集合，其重点在于数据的流动，而公司对数据复杂性管理通常有两种形式：批量处理或流处理。</p><p></p><h2>是什么阻碍了流处理？</h2><p></p><p>在前面我们所展示的图中，有很多可移动部分，而其宽广的表面积也意味着更高的出错概率。在流处理架构中，任何非功能性需求间的差距都是致命的。数据工程师们但凡是在构建系统时没有将“可X性”作为头等大事的，事后都要花费大把的时间在救急和系统维持上；这里的“可X性”指的是非功能性需求，如<a href=\"https://en.wikipedia.org/wiki/Scalability\">可扩展性</a>\"、<a href=\"https://en.wikipedia.org/wiki/Reliability_engineering\">可靠性</a>\"、<a href=\"https://en.wikipedia.org/wiki/Observability\">可观察性</a>\"、<a href=\"https://en.wikipedia.org/wiki/Operability\">可操作性</a>\"等等。更具体地讲，如果团队不以“可X性”为数据系统构建首要考量，那么数据管道的运维将会饱受中断和干扰的困扰，并通常会因此导致客户不满、团队成员焦头烂额并最终离开团队。</p><p></p><p>让我们深入研究，构建一个流处理系统吧。</p><p></p><h2>从简单的开始做起</h2><p></p><p>这是一段充满野心的征途，而就和任何大型项目或努力一样，我喜欢从简单的开始，比如定义一个目标：</p><p>&nbsp;</p><p>我们想要建立一个系统，将信息从源头S传递到目标D。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/b9/b9e553402cce337f522bfa75b6b99a1a.png\" /></p><p></p><p>&nbsp;</p><p>第一步是通过在S和D之间加一个消息中介来解耦，这一步骤很常见也很传统，是全球范围内通用的。这个消息中介系统可以是任何技术，我在这里选择的是<a href=\"https://kafka.apache.org/\">Kafka</a>\"。在系统之中创建一个Topic（主题）E，代表流经这个主题的事件。S和D通过事件主题E解耦，也就是说，如果D失败了，那么S可以继续向E发布消息；如果S失败了，D也可以继续从E消费消息。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/58/58e97ba7899b300ed3b20d375920c471.png\" /></p><p></p><p>下一步是确定系统的具体实施部分。假设系统在云平台上运行，多数人第一反应是AWS或GCP等公开可用的云平台，但其实Kubernetes也可以，甚至两者混合也没问题。另外，作为项目一开始，我们可以从小规模入手，在主题E的一个分区中运行Kafka的同时，在三个<a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regions_az/\">可用区域</a>\"分别运行一个代理以确保稳定性，将RF或复制因子设为3。此外，S和D需要在一个独立的<a href=\"https://aws.amazon.com/ec2/\">EC2实例</a>\"运行以提升系统可用性。</p><p></p><p>将流处理以服务的形式提供，意味着我们可以在流程S所托管的API端点接收输入消息，并在处理后发送向事件主题E。流程D将会消费主题E中的消息，将其发布到互联网上的第三方端点上。</p><p></p><h2>可靠性</h2><p></p><p>我要问的第一个问题是，“这个系统可靠吗？”让我们重新编辑一下目标：</p><p></p><p>我们想要建立一个系统，将信息从源头S可靠地传递到目标D。</p><p></p><p>更确切地说，应该加上这句话：</p><p></p><p>我想要零信息损失。</p><p></p><p>我们的设计需要根据这个需求变动什么吗？我们需要确保在流程S确认到远程发送来的消息后，流程D必须将该消息传递回发送者。那要如何建立系统可靠性？让我们先将系统一般化，假设我们有三个流程，而不是笼统的S和D，这三个流程都通过Kafka主题线性链接。</p><p></p><p>同所有链式连接一样，这种连接的强度取决于最薄弱处；如果链中每一个流程或环节都是事务性的，那么这个链条本身就会是事务性的。我对“事务性”的定义是：<a href=\"https://doc.akka.io/docs/alpakka-kafka/current/atleastonce.html\">至少有一次交付</a>\"，这也是现在Kafka最常见的使用方式。那要如何让链中每一个环节都是事务性的呢？可以先将链中的处理环节分解出来，流程A是摄取节点；流程B是内部节点，负责从Kafka中读取并写入信息数据；流程C是输出或驱逐节点，负责从Kafka中读取信息并将其发送至互联网。</p><p></p><p>如何让流程A可靠？流程A会通过REST端点接收到一个处理消息m1的请求，在将数据以Kafka事件的形式可靠地发送至Kafka后，再给服务调用者发送一个HTTP响应。至于要如何可靠地将数据传输至Kafka，A需要调用kProducer.send，入参有两个：主题和信息。之后立刻调用刷新（flush），清空Kafka内部的缓存并强制将m1发送向所有三个代理。因为配置了acks=all，A需要等三个代理都发回成功确认，才能响应服务的调用者。</p><p></p><p>那流程C要怎么才能变得可靠呢？流程C是用于读取数据的，通常是从Kafka中批量读取数据，一番处理之后再可靠地发送出去。在我们的示例中，可靠性意味着要接收到外部服务的200 OK响应代码。在流程C接收到200响应后会向下一个Kafka检查点驱动，一旦出现问题，流程C会负向ACK（如NACK）Kafka，强制流程B重新读取数据。</p><p></p><p>最后，流程B要如何可靠？流程B是流程A和C的组合体，流程B需要同流程A一样充当可靠的Kafka生产者，同时也需要像流程C一样充当一个可靠的Kafka消费者。</p><p></p><p>现在我们系统的可靠性是什么情况？万一进程崩溃，会发生什么？如果流程A崩溃，那么系统的摄取将完全中断，无法接收任何新消息。如果流程C崩溃，服务将停止向外部消费者传递消息，但从流程A中传来的消息仍会保存在Kafka中，流程B也可以继续处理，但直到流程C恢复之前，这些消息都不会被交付。</p><p>这类问题的常见解决方案是将所有服务都分别打包在一个大小为T的自动扩展组（autoscaling group）中，每个组都可以处理（T-1）个并发故障。自动扩展组这个词最初由亚马逊提出，但目前任何云平台，包括Kubernetes中都能适用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/21/21be14f0a49acd3d46da2a84e62827ae.png\" /></p><p></p><p></p><h2>滞后</h2><p></p><p>就目前而言，我们的数据流处理系统似乎非常可靠了，但这种可靠性要如何衡量呢？根据可观察性。流处理系统有两个重要的关键质量指标：滞后和损失。如果你对流很熟悉，那么这两个指标应该都不陌生，但如果你是流处理方面的新手，那么请容我介绍下。</p><p></p><p>首先从滞后开始。</p><p></p><p>滞后只是对系统中信息延迟的一种衡量。</p><p></p><p>信息在系统之中的传输时间越长，其滞后性就越大，对企业的影响也就约打，依赖低滞后性见解的企业更会深受其害。我们的目标是尽量缩减滞后，以更快地提供见解。滞后性要如何计算？我们需要一个“事件时间”的概念，也就是一个事件或消息的创建时间。事件时间通常会存放在消息文件中，并随消息一同在系统中传递。对系统中任何节点N的任何消息m1，都可以用以下公式计算滞后性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f2/f22508acdb7ce2e2aaeb31e2e85d7c93.png\" /></p><p></p><p>那么在实际情况中会怎么样？</p><p><img src=\"https://static001.geekbang.org/infoq/f0/f0b6617cdeabcc504bd79ecd87494d5e.png\" /></p><p></p><p>假设我们有一条在中午（T0）创建的消息，消息到达系统中节点A的时间是下午12.01（T1）。节点A处理信息后传递到节点B。消息到达节点B的时间是下午12.04（T3）.节点B处理后传递到节点C，到达时间为下午12.10（T5）。最后，节点C在处理信息后会将其发送到外部。</p><p></p><p>根据前面的公式，我们可以计算出消息m1和节点C之间的滞后时间是10分钟。但实际情况中，系统的滞后时间往往是以毫秒为单位，而不是例子中的分钟级。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/07/070ebac9988beda67cd588822974858e.png\" /></p><p></p><p>&nbsp;</p><p>我们在计算时不断提到的信息到达节点时间也被称作是到达滞后或滞后（lag-in）。另外需要注意，滞后是会累积的。在节点C计算出的滞后时间包含了其上游节点A和B上的滞后；在节点B计算出的滞后时间会包含其上游节点A的滞后。</p><p></p><p>处理到达滞后外，还有一种滞后叫离开滞后。离开滞后是从信息离开节点开始计算，计算方式同到达滞后的类似。参照下图，我们在A、B、C三个节点分别计算了离开滞后时间T2、T4和T6。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f7/f7117a8ec3905ff6a81aee48d6713291.png\" /></p><p></p><p>&nbsp;</p><p>在所有流处理系统中最为重要的滞后指标是端到端滞后（又称E2E滞后）。E2E滞后是指消息在系统中的全部时间，直接计算系统最后一个节点的离开滞后时间，也就是我们系统中节点C的10ms。</p><p></p><p>虽然计算出了某条消息（m1）的滞后时间非常有意思，但在我们要处理数十亿，甚至数万亿的消息量时，这个计算结果就没什么用了。因此，我们需要用统计数据来收集群体行为。我个人偏好用第95或第99个百分数（又称<a href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Statistics-definitions.html\">P95</a>\"、P99），但别人更偏好P99或MAX。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/94/94674972fe6fb3ade243400c38b4fec5.png\" /></p><p></p><p>我们可以构建的统计数据有很多，可以计算在P95时整体的端到端滞后，或者任何节点上的到达滞后或离开滞后。另外还可以计算带有到达滞后和离开滞后的流程持续时间，也就是信息在链上任何节点内的时间。但这组数据有什么用呢？</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/92/92bdca68251ca24fb7a04ba648cb124d.png\" /></p><p></p><p>让我们考虑一个更实际的例子。假设在一个上图中的线性结构里，有一条消息一路从红色、绿色、蓝色节点一路流转，最终到达橙色节点。这个结构其实是我们在生产环境运行的系统，上图是从我们在生产上的服务<a href=\"https://aws.amazon.com/cloudwatch/\">CloudWatch</a>\"中截取的。如你所见，我们计算了每个节点的流程持续时间，并以饼状图展示。这让我们对系统中滞后性的分布情况有了大致的概念。这个系统非常完善，每个节点的滞后时间大致相同，没有特别突出的。把饼状图按时间摊开会得到右侧的图，可以看出性能在某段时间内基本相同。因此，我们会认为这个系统是很合适的，性能表现在任何时间范围内都保持一致。</p><p></p><h2>损失</h2><p></p><p>在分析完滞后后，我们再来看看损失。损失是一种衡量信息在通过系统时损耗的计量方式。导致信息损失的原因有很多，其中大多数都是可避免的。数据损失得越多，数据质量就越差。因此，我们需要尽量降低数据损耗，以提供更高质量的见解。那么要怎么计算流处理系统的损失呢？损失可以看作是系统中任意两点间的信息集差。还是以先前的线性结构为例，不过在系统其中流转的是十条信息而非一条。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/88/885cb66aa0b95aa644fb0e56c77a2fa2.png\" /></p><p></p><p>我们可以通过损失表格来计算损失。表格中的每一行都代表一条信息，列则代表链中的节点。消息一成功通过系统，因此在每一列都是“1”；消息二同理。但消息三在成功通过红色节点后没能到达绿色节点，蓝色和橙色也没能接收到消息三。在表格最底部计算了系统每个节点中的损失情况，右下角则是计算了系统整体的端到端损失。在我们的例子中是50%。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/da/da9b609d658dcaa7bb46ca4e98f041e3.png\" /></p><p></p><p>在流数据系统中，消息会不断流动。那我们该从哪里计算呢？我们需要利用消息事件时间，将消息分配到一分钟长度的时间桶内。比如在某天的12.34时，我们计算所有落入12.34这一分钟事件时间的损失表格，这个方案也可以应用到一天中的任何时间。</p><p></p><p>假设现在是下午12.40，系统中的消息通常会延迟到达。我们现在可以看到下面这四张表都有统计数据更新。然而，到下午12.35表格中数据便不再变化，因此我们可以断定能到达的消息均已到达，并可以开始计算损失。时间早于这个时间点的损失表格都可以弃之不用，这样也可以裁剪掉不需要再计算的表格来缩小损失计算规模。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1d/1de3d3db0ba8ae87e766af94081defcc.png\" /></p><p></p><p>&nbsp;</p><p>总的来说，我们等待几分钟的信息传输时间后再计算损失，如果损失超过阈值（如1%），就触发损失警告。</p><p></p><p>在梳理清楚滞后和损失的定义后，我们就可以衡量系统的可靠性和滞后性了。</p><p></p><h2>性能</h2><p></p><p>那么我们系统的性能已经调整完毕了吗？让我们再回顾下目标。我们想要建立一个系统，将信息从源头S可靠且低延迟地传递到目标D。要想更好地了解流处理系统的性能，我们需要先认识端到端延迟的组成部分。首先是摄取时间，这是指从接收请求的第一个字节开始，到发送响应的最后一个字节。这个时间段包含了所有我们在可靠地将消息发送至Kafka时产生的任何开销。在管道尽头还有“驱逐时间（expel time）”和“排放时间（egest time）”，这是指在D段处理和整合消息所需要时间，其余时间被统称为传输时间（transit time）。这三者共同构成了端到端的滞后时间</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/07/076be76ee198f03b5b22ea50755480bf.png\" /></p><p></p><p></p><h2>性能惩罚</h2><p></p><p>在讨论性能时，我们也不能忽视为建造无损耗系统所牺牲的性能，我们需要用滞后换取可靠性。其中部分性能惩罚项如下。</p><p></p><p>首先是摄取惩罚（ingest penalty）。为了保障可靠性，S需要对每个接入的请求调用kProducer.flush，等待Kafka传来三个ACK才会发送API响应给客户端。虽然我们并不能干掉这些摄取惩罚，但却可以利用批处理来平摊成本。也就是说，我们可以通过支持推广批处理API，在API调用滞后时间不变的情况下最大限度地提高吞吐量，在每个网络请求中获取多个消息。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5e/5e9c7b099341e0a38b0a96e5bb98286a.png\" /></p><p></p><p>同样，还有驱逐惩罚（expel penalty）。有一个需要注意的点是，Kafka的速度很快，远比公共互联网上常见HTTP的往返时间（RTTs）还要快很多个数量级。事实上，大部分的驱逐时间就是HTTP的往返时间。同理，这里我们也采用分摊开销的方法：在每个D节点中，都增加批处理和并行性。我们从Kafka中读取批量数据后重新批处理为更小的批次，然后通过并行线程将这些批处理发送到各自的目的地。这样，我们就可以最大限度地提高吞吐量，减少单个消息的驱逐成本或惩罚</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/08/08a5c171da7e0a7a2fc84f382149acfa.png\" /></p><p></p><p>最后但同样重要的是重试惩罚（retry penalty）。为保证管道数据的零损失，我们需要在D端不断重试消息，只要次数够多就会成功。我们对D端调用的远程端点没有任何控制，这些端点可能会遭受瞬时故障，或者时不时对D进行限制，以及其他我们无法控制的事情都有可能发生，我们必须通过不断重试才能确保成功。这些情况被称作是可恢复故障，但仍有一些故障时不可恢复的。例如，4开头的HTTP响应代码，除了常见的节流响应代码429之外，我们都不应该继续重试，因为即使重试也是不会成功的。</p><p></p><p>也就是说，为了处理重试惩罚，我们必须以滞后性为代价，并慎重考虑需要重试的内容。这一点前文已经提过了，我们不应该重试任何不可恢复故障，并巧妙采用重试的方式。</p><p></p><h2>性能-分级重试</h2><p></p><p>我有一个叫做“分层重试”的想法，可以参考下面的架构图：我们将架构分为两层，本地重试层和全局重试层。在本地层中，我们尝试低频在D端发送一个可配置次数的消息，这一层是为尝试在远程目标短暂或瞬时中断期间重试消息传递。</p><p></p><p>如果耗尽本地重试次数，D端会将消息转移到全局重试服务（gr）中，全局重试层会在长时间内不断重试，以期望能超过目标的中断时长并成功传递消息。通过将消息重试任务转移到全局层，D服务可以将资源用于传递正常消息。但需要注意的是，D服务可能会需要向不同的远程服务或端点发送消息，也就是说，如果其中之一的远程目标中断，而其他目标完全正常。流处理系统中全局重试和服务D都会由Kafka主题分隔为RI（Retry_In）和RO（Retry_Out）。</p><p></p><p>这种方式的好处在于，实践中我们所遇到的全局重试概率远低于1%，甚至常常连0.1%都不到。因此，即使这些重试会需要更长时间，它们也不会影响我们的P95端到端延迟。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2a/2a4ff77fc536e43e2e03cc0552518b51.png\" /></p><p></p><p></p><h2>可扩展性</h2><p></p><p>目前为止，我们已经有了一个小规模的、运行良好的系统。那么这个系统要如何随流量的增加而扩容呢？</p><p>首先是辟谣，可以处理无限制规模的系统并不存在。很多人会以为，通过转移AWS或其他托管平台可以实现无限制规模系统，但现实情况是，每个账户都会有限制，因此流量和吞吐量都是有上限的。从根本来说，每个系统都有自己的流量等级，无论这个系统是在哪里运行，流量等级都是通过对系统的负载测试来衡量的。我们只有通过迭代运行负载测试并移除瓶颈才能到达更高的规模。</p><p></p><p>在对数据流自动扩缩容时，我们一般会有两个目标。目标一是自动扩容以保持低延迟（如减少端到端滞后性），目标二是缩容以减少成本。我们在此先关注目标一。在自动扩容时，有不少是需要考虑在内的，首先，什么可以自动扩容？至少在过去十年间，亚马逊已经可以做到计算的自动扩容了，所有的计算节点都是可自动扩容的。那Kafka呢？Kafka目前还不支持自动扩容，但未来或许可以。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b3/b366b7e62e893bbfef42ac99454e5f81.png\" /></p><p></p><p>&nbsp;如何正确挑选合适的指标来触发自动扩缩容操作是非常关键的。我们所选择的指标必须要有低延迟，要能够随流量的增加而增加，随微服务的扩容而下降。根据我的经验，平均CPU是很好的衡量标准。但还有一点需要注意，如果你的代码中有锁、代码同步，或者IO等待，那么你可能会没办法触发系统CPU的过饱和。随着流量的增加，CPU用量也会到达高峰并导致自动扩缩容操作停止，系统延迟增加。如果你看到系统中出现这种情况是，最简单的解决方法是将阈值降低到CPU峰值之下。</p><p></p><h2>结论</h2><p></p><p>现在，我们的系统拥有了期望中的所有非功能性需求。虽然这篇文章中覆盖了很多关键要素，但还有很多没有提及的：隔离、容器的多级自动扩展、流处理操作者，以及缓存的架构。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/high-fidelity-data-streams/\">Building &amp; Operating High-Fidelity Data Streams</a>\"</p>",
    "publish_time": "2022-11-03 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何把技术“卖”给业务，从 IT 视角看麦当劳中国数字化",
    "url": "https://www.infoq.cn/article/MQ0BZcA5TUaNbT7hIEm2",
    "summary": "<p></p><p>出品 | InfoQ ·《行知数字中国》</p><p>采访人｜霍太稳，极客邦科技创始人兼 CEO</p><p>采访嘉宾｜陈世宏，麦当劳中国首席信息官</p><p>编辑｜罗燕珊</p><p></p><p>目前，麦当劳中国已经发展到近 5000 家餐厅，员工数量超过 18 万。作为餐饮行业数字化的标杆案例，麦当劳中国被誉为全球数字化程度最高的麦当劳。《行知数字中国》<a href=\"https://www.infoq.cn/video/sVz55QCL2muze0GQtZA2?utm_source=home_video&amp;utm_medium=article\">第五期</a>\"，InfoQ 邀请到麦当劳中国首席信息官陈世宏，跟着他的视角去了解他眼中的“数字化金拱门”。</p><p></p><p>在陈世宏看来，企业进行数字化的过程很重要的一点是：转换思考问题的角度。尤其传统企业容易形成思维定势，作为 IT 侧人员，需要从技术的角度切入，并尝试用新的思路把传统业务重新思考一遍，再带着新想法去影响原来既定规则的制定者，一同找出改进的机会点。</p><p></p><h2>数字化转型逻辑</h2><p></p><p></p><h4>消费者是客户，员工也是客户</h4><p></p><p>服务业往往提倡客户至上，服务第一。即使进入数字化时代，对于餐饮企业而言，以“客户为中心”的出发点还是没变，本质还是离不开如何提升客户体验。</p><p></p><p>一方面，移动互联网让线上购物成为消费者日常，如何在线上提供不亚于线下的、更便利和流畅的消费体验，是餐饮业典型的数字化改造需求。</p><p></p><p>另一方面，在麦当劳中国看来，所谓客户，不仅指前来消费的顾客和消费者，员工也是他们的客户，因为企业经营过程中的效能的提升，也是数字化的核心目标。那么在这个场景下，近5000家餐厅里的员工都是客户，他们既包括在炸薯条做汉堡的员工，也包括每天凌晨2点多钟在做盘点的员工。</p><p></p><p>“如何站在一个合适的位置上，去构思更合理的数字化产品方案，让员工的工作变得更高效，让员工感到更满意，这是我们提供数字化解决方案的其中一个根本的出发点。”陈世宏说道。</p><p></p><h4>避免把数字化投资当成一次性项目</h4><p></p><p>除了“以客户为中心”，把数字化建设当成持续累积数据资产的过程也是很关键的一点。</p><p></p><p>为了提升效能，数字化建设中可能会出现“今天采购一个ERP，明天采购另一个系统”的缺乏统筹的情况，但如果盲目买系统，系统和系统之间没有产生关联，结果就会形成一座座数据孤岛，数据不能整合，也就无法把数据的价值发挥出来，系统们最终都会“腐化掉”。</p><p></p><p>因此，为避免把数字化投资当成一次性项目，陈世宏认为，首先要勾勒出数字化框架，当中要明确究竟要建设哪些对象领域模型、公司要建设哪些该有的数字化资产，然后再围绕这个目标去坚定做建设和投入，而不是频繁建设短期项目或把项目推倒重建。若没有产生累积效应，那么公司对 IT 领域的投资也会逐渐失去信心，并且对企业的数字化会带来很大的损伤，也就谈不上创造经营洞察和使能商业决策了。</p><p></p><h2>难题和挑战</h2><p></p><p>回到麦当劳中国本身，在数字化践行方面，其算得上是先行者。它是<a href=\"https://www.yicai.com/news/100285340.html\">最早试点微信功能</a>\"的快餐企业，从 2015 年起，就先后接入微信支付、推出小程序点餐、接入微信会员卡等等。</p><p></p><p>不过，在最初推行之时，麦当劳中国的小程序和App在体验上存在较多问题，比如“有多个小程序、用户需要在小程序之间反复横跳”、“小程序和App之间的数据没打通”等现象时常被消费者诟病。</p><p></p><p>而在过去这两三年间，麦当劳中国对消费者的线上体验做了大幅改进，一个显性的成果体现在应用程序口碑的挽回：麦当劳App在应用商店的评分经历了从2分到接近5分的提升。</p><p></p><p>这份成绩单的背后，陈世宏提到数个关键因素：解决全球化产品移植到中国的水土不服；用户体验旅程的梳理，品牌理念的理解和再设计，做有温度的产品；将持续改进的能力融入到C端产品的数字化血液里；跨渠道的一致性和流畅性；持续微创新；与麦当劳总部的衔接等等......</p><p></p><h4>全球标准化与市场差异化的平衡</h4><p></p><p>标准化被深深写在麦当劳的基因里，如此一来，在瞬息万变的移动互联网时代，麦当劳中国区业务的发展就会受到极大的限制，有翅难展。</p><p></p><p>甚至连自建App都是一件非常“麻烦”的事情，<a href=\"https://www.huxiu.com/article/240420.html\">最初</a>\"中国区的App不仅需要在麦当劳全球的框架里面开发，用户体验逻辑也来自于全球统一的标准流程（如邮箱注册账号），最终整个App在麦当劳的体系内花了近五年的时间才弄完。与敏捷开发、快速迭代的模式相背而驰的结果是，App的开发跟不上用户需求，据悉当时向总部说服做小程序也要耗费不少功夫。</p><p></p><p>2017年，这种约束的关系开始有了更多松弛空间，中信股份、中信资本和凯雷投资集团与麦当劳签署了中国区业务的收购协议，新公司“金拱门”成为麦当劳在中国的唯一特许经营商。金拱门也向麦当劳全球争取更多自主性，来推出自己的App。</p><p></p><p>尽管如此，直到今天，“标准化之下的差异化”依然是中国区团队在工作过程中需要持续攻克的难题，陈世宏指出，怎么克服“标准化的快速复制、扩张”与“贴近消费者诉求的市场化的本土需求”之间的矛盾，还需要投入非常多的技巧和耐性。</p><p></p><p>“大家都非常重视中国市场，而这个市场所伴生的一些非常独特的需求也是很有魅力的，这些需求往往能够反哺全球、被构筑进麦当劳的全球化市场里。”</p><p></p><h4>调整观念</h4><p></p><p>除了平衡全球化和本土化市场的差异，麦当劳中国的数字化转型同样要面临着传统生意和技术融合的普遍挑战。</p><p></p><p>当陈世宏以互联网技术人的身份进入到这样一家相对传统、有一定历史沉淀的企业里，他才深切体会到互联网与实体经营企业对数字化、对 IT 的认知有很大的区别。</p><p></p><p>比如现在在互联网或技术公司里，很少会提“打通”这个词，但加入麦当劳中国后，他发现“打通”成了一个非常痛的痛点。</p><p></p><p>再比如他发现传统企业更多的是以“我今天买个笔记本电脑，明天要去买其他工具”的短期项目制方式去看待数字化改造，而没有意识到通盘规划、系统性长期运作的重要性。</p><p></p><p>于陈世宏团队而言，如何把“技术”推销给业务团队也是日常工作中的一大挑战。</p><p></p><p>传统企业里提到产品经理，往往是指研发线下消费品的角色，比如在麦当劳里研发汉堡等食品的产品经理。而陈世宏团队里产品经理的职责则是研发数字化解决方案，方案出来之后，如何把它推销给业务团队，用以优化业务流程或者让业务团队的工作变得更高效，也是一个颇具挑战性的任务。</p><p></p><p>“今天我们再看技术和传统企业的融合，不能简简单单地把技术看成一个工具，它已经变成产品的一部分了。（解决方案）跟汉堡一样是产品，只是一个是有形的、拿在手上的产品，一个是在背后买走的服务。”</p><p></p><h4>快速学习带来的消化能力挑战</h4><p></p><p>技术人从互联网企业进入到传统公司后，往往会经历比较漫长的适应过程。对于陈世宏而言，进入麦当劳中国之后，他也经历了重新学习和对自己原有知识体系再造的过程。</p><p></p><p>其认为，一线技术人员进入到传统业务领域里去做垂直化改造，一定要识别出自己的位置。一方面要理解业务是什么、运转的逻辑是什么、消费者是谁、客户是谁；另一方面，理解业务逻辑之后，要思考自己能给业务提供的价值是什么，结合客户的诉求、以及自己所具备的能力，把这些信息都匹配起来，便有助于梳理出自身定位以及应该做什么样的事情。</p><p></p><p>据介绍，在麦当劳中国，无论职级高低，入职之后一定会有一周的时间在餐厅里面做一名员工。</p><p></p><p>“我曾经有一周的时间就待在餐厅里，每个岗位我都做了一遍，从打桌、帮用户点餐，到后厨，比如帮用户做一杯薯条，做一个汉堡，以及打烊之后，做盘点工作，了解清洁工作究竟有哪些工序，开铺的时候应该做哪些事情，我们每一个人都要去经历一遍。”</p><p></p><p>当所有的技术人员都经历过这样一个过程之后，在后续的开发工作中就很容易产生画面感，能够设身处地地想象如何通过技术的方式改造业务流程。虽然一周的时间并不足以让一位员工对业务产生非常深入的了解，但陈世宏表示，该方式能让员工跟餐厅产生连接，后续大家遇到任何问题都是可以随时再到餐厅去做了解。</p><p></p><p>此外，陈世宏还特地提到团队在技术方面遇到的高并发挑战，“基本上每天中午就是一次‘秒杀’”，在数千家餐厅的体量下，饭点时刻提供查询或下单服务的并发量巨大，这类因生意模式带来的技术难题，也是陈世宏团队需要去克服的长期挑战。</p><p></p><h2>数字化人才建设</h2><p></p><p>如今，麦当劳中国一线员工也可以通过一些数字化平台和载体，更实时地了解企业经营的现状，特别是其所在餐厅的经营情况。这背后和一个叫做 Data Citizen （数据公民）的项目有关，它鼓励员工通过工具去了解数据。</p><p></p><p>以往，解读数据似乎是技术部门的特权，业务团队要了解经营现状，常常需要以需求的形式去做申请，“比如跟 IT 部门或者某个技术部门说，‘我需要去看一个什么样的数据，你帮我做个什么样的解读。’”</p><p></p><p>但随着技术的进步，数据分析的门槛变得越来越低，因此陈世宏团队希望把数据分析能力植入到业务团队，让业务团队能够以相对轻松、短链路的方式落地需求，于是他们提供了相关的工具给业务团队并输出培训，教业务团队运用数据平台沉淀的数据资产。</p><p></p><p>“甚至我们发现很多业务团队的同事，可以直接写SQL去读一些数据，这样意味着他去获取数据的时候，他的维度会更加灵活，看到的东西可以更加接近于脑海里的原生的想法，”陈世宏进一步介绍称，还有一些业务团队会跟他们一起共建算法引擎，一块构筑智能化平台，比如对于外卖配送商圈的定义，基本是由业务团队来完成，技术团队仅提供平台载体，“这就是我们把数字化思考的方式植入到系统里面去的一个路径。”</p><p></p><p>整体来看，陈世宏认为包括麦当劳中国在内的很多传统企业，目前比较缺乏的数字化人才是企业级架构师，偏向复合型人才，该架构师既需要对业务有非常透彻的理解，又能够勾勒出和搭建数字化长期发展路径，能用不同的视角去思考解决方案。</p><p></p><p>行业繁荣之时，许多问题容易被高速增长的表象掩盖掉。如今增长放缓，如何提升效率、效能成了迫在眉睫的行业挑战。迈入数字化转型时代，陈世宏认为IT 从业人员面临着很多机遇，产业转型升级的发展空间巨大，而“金拱门”只是其中众多产业分支里的一间公司，其呼吁更多技术人员能够加入到数字化转型的建设当中，以更积极的心态去看待这个时代。</p><p></p><p>对本期内容感兴趣的读者，欢迎关注<a href=\"https://www.infoq.cn/album/79\">《行知数字中国》视频合辑</a>\"，我们将在近日更新本期完整版内容。</p><p></p><p>采访嘉宾介绍：</p><p></p><p>陈世宏，麦当劳中国首席信息官，负责 IT 战略、技术实现规划、数字产品路线图、技术基础设施、新技术创新和 IT 团队结构。世宏带领 IT 团队实现数字化转型，从提升消费者端体验到重新设计企业业务流程。</p><p></p><p>世宏于2020年4月加入麦当劳中国。为了加速麦当劳在中国的数字化能力和业务渗透，他制定了三层技术架构和团队结构的蓝图，通过可组合的“中间平台”实现全渠道体验。在不到一年的时间里，世宏凭借其领导力和技术敏锐度，带领团队实现了麦当劳消费端数字体验的进化和飞跃。</p><p></p><p>世宏还将本土洞察与麦当劳全球技术标准相结合，坚持技术实用主义的理念。他领导了近 5000 家餐厅的下一代网络的部署，提供了符合全球标准的高速和稳定的基础设施，同时也实现了与中国本土相关的创新。</p>",
    "publish_time": "2022-11-03 10:19:38",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "阿里云张建锋：云计算变革被严重低估了",
    "url": "https://www.infoq.cn/article/Ju5weRM9b7eXmCpYSUHM",
    "summary": "<p>InfoQ现场报道，11月3日，在2022云栖大会上，阿里云智能总裁张建锋发表了主题演讲。</p><p></p><p>张建锋认为历经十多年的发展，云计算带来的变革依然被严重低估，它正在重构整个IT软硬件和终端世界，形成一个全新的计算体系。新一轮的科技变革正在深入发展，阿里云将坚持技术长征，面向下一代体系去构建第二技术曲线，抓住未来技术的定义权。</p><p></p><p>张建锋认为，以云计算为核心的新型计算体系，正在带来三大变革：首先，云重构了整个IT硬件体系，数据中心、芯片、服务器等产业链发生深刻变化；其次，软件研发范式发生深刻变革，Serverless、低代码、AI大模型开源等趋势，大幅提升软件生产效率；最后，云和端加速融合，算力从端转移上云，未来万物皆是计算机。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0e/0e0dbb1bda78893b6297240d691cd69d.png\" /></p><p></p><h2>重构整个IT硬件体系</h2><p></p><p>&nbsp;</p><p>张建锋回顾了云计算演进历程，过去十多年，云的创新主要集中在软件领域，首先出现了分布式虚拟化，而后实现了资源池化，形成了广泛的应用规模。现在，云计算已经从软件创新，走向软硬件协同创新，用云来定义整个IT硬件体系。</p><p>&nbsp;</p><p>今年，阿里云发布了一款云数据中心专用处理器CIPU，替代CPU来管理和加速计算、存储和网络资源。这是一种全新的架构方式，代表着云计算深入到数据中心内部做体系化创新。CIPU实现了全面专用硬件加速的高性能，包括高带宽、高吞吐和弹性RDMA的能力。“飞天+CIPU”的组合性能表现普遍优于业内同类产品，性能可提升20%以上。</p><p>&nbsp;</p><p>在此基础上，阿里云基础设施已经广泛基于CIPU架构进行建设，并且构建了全栈自研的基础设施，例如自研CPU芯片倚天710、磐久服务器、EIC高性能网卡、磐久交换机、磐久液冷一体机、磐久液冷集装箱等自研硬件。</p><p>&nbsp;</p><p>去年，阿里巴巴发布了首款“为云而生”的芯片倚天710。目前，倚天710云实例已在多家互联网科技公司大规模应用，算力性价比提升超30%，单位算力功耗降低60%，这是中国首个云上大规模应用的自研CPU。</p><p></p><p>在2021年双11期间，天猫双11核心交易系统平滑迁移至倚天710实例。中国一些知名的科学计算、智能手机行业和互联网等领域的企业在迁移至倚天710实例后，性价比均得到了显著提升。</p><p>&nbsp;</p><p>张建锋表示，未来阿里云还将继续扩大自研CPU的部署规模，预计未来两年内20%新增算力将使用自研CPU芯片倚天710。</p><p>&nbsp;</p><p>他认为，过去十多年，飞天为阿里云打下了扎实的技术基础，让云实现了第一次飞跃。自研CPU芯片倚天710、下一代云计算体系架构CIPU将为阿里云构建第二技术曲线，是云面向下一代技术构建的核心竞争力。</p><p>&nbsp;</p><p></p><h2>软件研发范式发生深刻变革</h2><p></p><p>&nbsp;</p><p>计算体系的变革不仅将发生在IT硬件世界，软件研发范式也将发生颠覆性变化。</p><p></p><p>张建锋认为，软件研发范式的变革有三个层次，第一是新兴的软件开发方式崛起，软件架构全面Serverless化；第二是软件开发不再是程序员的专利，低代码让未来80%应用能够由业务人员直接开发；第三是未来所有软件都是AI化的，大模型开源将加速AI真正普及。</p><p>&nbsp;</p><p>其中，Serverless将让云计算从一种资源真正变成一种能力。张建锋表示，过去云计算用云服务器替代了物理服务器，但客户依旧按“几核几G服务器”的模式来购买云资源，未来云计算将全面Serverless化，更加接近“电网”模式，按计算的调用次数付费。</p><p>&nbsp;</p><p>这将带来软件开发方式的深刻变化，软件架构从原来的主机架构迁移到Serverless架构，客户只需要开发业务逻辑，不再需要关心运维问题。此外，Serverless架构可以降低软件开发门槛，提供更多的预制模块，大幅提高软件生产效率。</p><p>&nbsp;</p><p>例如，一家烟草公司只需要两个开发人员就可以做出整套物流系统。对互联网新兴应用而言，Serverless架构让应用轻松抗住流量高峰。以南瓜电影为例，Serverless架构让这个视频APP无人值守就能应对百万级流量，并且总成本较此前下降40%。</p><p>&nbsp;</p><p>其次，低代码将进一步降低应用开发门槛，张建锋认为，未来80%的应用将由业务人员开发，不懂低代码就和20年前不会用word一样。数据显示，钉钉上，两年新增了500多万个低代码应用，聚集了380余万低代码开发者。</p><p>&nbsp;</p><p>最后，越来越多的软件将AI化，大模型开源将推动AI真正普及。张建锋表示，开源是软件进步的核心推动力量，过去开源推动了软件架构的进步，未来开源还将推动AI应用的进步和普及。目前，达摩院在中文AI模型社区模搭ModelScope上，开源了超过300个优质模型，可以帮助开发者利用基础模型快速开发AI应用。</p><p>&nbsp;</p><p></p><h2>云端加速融合，万物皆是计算机</h2><p></p><p>&nbsp;</p><p>今天，云计算正在创造越来越多的终端形态。几十年前，手机只能用来打电话，现在手机是一个手里的计算机。过去，汽车从只讲究“马力”，现在汽车需要比拼“算力”，成为一个“四轮计算机”。</p><p>&nbsp;</p><p>张建锋认为，云端加速融合，算力正在不断从终端转移上云，这让终端突破了物理限制，不仅手机、电脑、汽车、音箱会变成计算机，未来万物皆是计算机。</p><p>&nbsp;</p><p>例如，Rokid在推出的AR眼镜中接入阿里云无影架构，利用云上算力，用户打开仅有85克重量的眼镜，就能在眼前的虚拟现实画面中，与人聊天、办公，并且还能做3D渲染、大数据编程等复杂工作。</p><p>&nbsp;</p><p>在PC电脑端，未来阿里云继续将RISC-V芯片和无影架构结合，让创新终端具有更高性能、更低能耗，并实现全栈自研。目前，阿里巴巴已经成为全球RISC-V技术与生态发展的引领者，并且已经完成了和云操作系统的适配，迈出了端边云一体的重要一步。</p>",
    "publish_time": "2022-11-03 10:59:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "阿里云宣布算力攻坚重要突破！倚天710已大规模应用，性价比提升超30%",
    "url": "https://www.infoq.cn/article/fWqoFNWr5SCpFd0r41tJ",
    "summary": "<p>11月3日，InfoQ 2022云栖大会现场报道，<a href=\"https://www.infoq.cn/article/Ju5weRM9b7eXmCpYSUHM\">阿里云智能总裁张建锋</a>\"宣布，<a href=\"https://www.infoq.cn/article/KKAJ6VM0S2X9HWq0T9mq\">阿里云自研CPU倚天710</a>\"已大规模应用，阿里云未来两年20%的新增算力将使用自研CPU，这是阿里算力攻坚的重要突破。</p><p>&nbsp;</p><p>目前，倚天710已在<a href=\"https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247574829&amp;idx=1&amp;sn=d234fe4fed2759a34e697a5a679203d8&amp;chksm=fbeb1ce2cc9c95f46321925247c91aa4b4e857f12b100de8b1ae4443f0d9e270a5b5b591dc10&amp;scene=27#wechat_redirect\">阿里云数据</a>\"中心大规模部署，并以云的形式服务阿里巴巴和多家互联网科技公司，算力性价比提升超30%，单位算力功耗降低60%，这是中国首个云上大规模应用的自研CPU。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/81/c2/81e3029c21660bd299271bef5634ffc2.png\" /></p><p>&nbsp;</p><p>2021年云栖大会，<a href=\"https://www.infoq.cn/article/kxN6zLPLbEyyvIVUbeav\">阿里平头哥</a>\"发布首颗CPU芯片倚天710，该芯片针对云场景研发，同时兼顾了性能与易用性。经过一年的业务验证，倚天710已大规模部署并提供云上服务。倚天710云实例与飞天操作系统及CIPU融合，在数据库、大数据、视频编解码、AI推理等核心场景中的性价比提升超30%；阿里云提供丰富的生态工具，支持全应用生态适配，0代码修改即可完成主流业务迁移。</p><p>&nbsp;</p><p>目前，倚天710云实例已应用于阿里巴巴集团核心业务，并服务科学研究、智能手机行业和多家知名互联网公司。2021年双11期间，天猫双11核心交易系统平滑迁移至倚天710云实例，算力性价比提升30%；汇量科技广告推理业务使用倚天710云实例，性能和网络带宽双双提升，性价比提升40%以上。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/2d/07/2df6edc04ecb4a9670962d8f06da6f07.png\" /></p><p></p><p><a href=\"https://www.infoq.cn/article/mNaShfSiXdRqXSV4DsaY\">汇量科技首席人工智能官朱小强</a>\"表示：“随着在线推理模型不断升级，我们对CPU性能和内网带宽要求更高，倚天710云实例满足了我们业务升级的需求，实现了降本与增效。”</p><p>&nbsp;</p><p>“<a href=\"https://www.infoq.cn/article/Ju5weRM9b7eXmCpYSUHM\">云计算</a>\"的发展进入了全新的阶段，未来十年，软硬件一体化的自研计算体系是云服务商的立身之本，只有在核心技术和产品的研发上持续创新才能抢占定义权。”阿里云智能总裁张建锋表示。</p>",
    "publish_time": "2022-11-03 11:04:58",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "“赋能制造 因你而耀”第六届全国工业互联网数据创新应用大赛赏金百万正式启航",
    "url": "https://www.infoq.cn/article/FqX4zbJCa6xjrA0XGLFM",
    "summary": "<p>盼望已久的<a href=\"https://www.industrial-bigdata.com/Home\">第六届全国工业互联网数据创新应用大赛</a>\"（以下简称“大赛”）装箱百万赏金正式扬帆启航了。</p><p></p><p>为了鼓励企业落地工业互联网创新数据应用，2017 年起，中国信息通信研究院在工业和信息化部指导下，举办工业大数据创新竞赛。这是首个由政府主管部门指导的工业大数据领域最具权威的全国性创新竞赛，为工业大数据人才培育、产业创新、生态打造提供支持。2021 年，“工业大数据创新竞赛”全面升级为“全国工业互联网数据创新应用大赛”，将进一步为加快我国工业互联网数据创新应用贡献力量。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/30/6d/30c8022c6dcb14f4b44ab93a307d196d.jpg\" /></p><p></p><p></p><h1>“耀”出精彩</h1><p></p><p></p><p>为了进一步壮大以应用实践为导向的大数据算法人才队伍，挖掘更多工业互联网数据创新应用共性需求场景落地，大赛设置了工业大数据算法和创新应用两条赛道，优胜者将分享百万奖金，更有机会与深圳市宝安区签署落户协议，作为优秀的工业大数据解决方案创业团队在宝安区落户！</p><p></p><h1>“耀”真好玩</h1><p></p><p></p><p>此刻，算法赛道火热报名中！</p><p></p><p>算法赛道赛题基于“碳达峰”、<a href=\"http://www.gov.cn/xinwen/2021-12/22/content_5664043.htm\">“碳中和”</a>\"国家战略背景设置。赛题挑战来自氢能产业龙头企业<a href=\"https://www.dongfang.com/\">中国东方电气集团</a>\"的真实课题和真实数据。让选手在比拼大数据算法能力的同时，亲身参与到绿色氢能前沿领域的专业课题。赛题为“氢燃料电池系统性能均值预测”，要求参赛团队通过分析各变量与系统性能均值之间的动态变化，构建以系统性能均值为核心的算法模型。大赛成果模型可为氢燃料电池系统的性能分析、设计优化和运营改进提供数字孪生模拟手段，为氢燃料电池的设计、制造、运行及维护全生命周期提供助力。</p><p></p><h3>报名方式</h3><p></p><p>即日起至 12 月 3 日 0:00，高等院校、科研单位、互联网企业等人员均可通过大赛官方报名通道（请在 PC 上访问 <a href=\"https://www.industrial-bigdata.com/Challenge/dynamic?competitionId=8UHAP1L3SYO8ROXQAJSE8EDHTRDAVC2S\">https://www.industrial-bigdata.com/Challenge/2022ii</a>\"）报名参赛。</p><p>联系人：赵先生 13825233551</p>",
    "publish_time": "2022-11-03 11:50:25",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Shopify 收购开源 Web 框架 Remix",
    "url": "https://www.infoq.cn/article/rlQqsVMLw2AleJ8wceEv",
    "summary": "<p>Remix是一家开发<a href=\"https://www.infoq.cn/article/4j1bzl08kpo0m0p6yko3\">类似于Next.js</a>\" 的开源 Web 框架的初创公司，日前宣布已被 Shopify 收购。目前并未披露具体交易金额，在一篇<a href=\"https://remix.run/blog/remixing-shopify\">博客文章</a>\"中，Remix 公司联合创始人兼CEO Michael Jackson表示，在 Shopify 的管理下，Remix 得到了知名商业领导者的长期支持和助力，这次合作能够让Remix 更快地发展并更加关注性能和可扩展性。</p><p></p><p>Remix 由前 Twitter 工程师 Jackson 和 Ryan Florence 于 2020 年共同创建。在决定推出同名的 Remix 框架之前，两人多年来一直围绕 Reac 创建开源工具。</p><p></p><p>Jackson 和 Florence 最有名的项目之一是 React Router，这是一个 React 库，已被下载近 10 亿次。并非巧合的是，Shopify最初使用React Router来构建Hydrogen，这是该公司用于构建自定义 Shopify 店面的前端 Web 开发框架。</p><p></p><p>至于 Remix，它是一个全栈网络框架，旨在利用分布式系统和本地浏览器功能，同时抽象出后端服务器任务。Remix兼容公共云环境，包括AWS、谷歌云、Netlify、Vercel和Cloudflare Workers，其主要功能之一是预取--该框架可以在用户点击链接之前并行预取网页的元素，包括按钮和表单，以尽量减少页面加载。</p><p></p><p>Shopify 工程副总裁 Dion Almaer <a href=\"https://shopify.engineering/remix-joins-shopify\">表示</a>\"，收购 Remix 将使得 Shopify 开发人员和商家都受益 。</p><p></p><p>“Remix 将依然是一个独立的开源框架，”Almaer 说。“Remix 将解决在 Hydrogen 上构建的开发人员在数据加载、路由和错误处理方面遇到的挑战……Shopify 将在许多有意义的项目中使用 Remix，随着时间的推移，大家可以期待看到更多我们的开发人员平台提供一流的 Remix 支持。”</p>",
    "publish_time": "2022-11-03 12:10:45",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Envoy Gateway会成为网关现有格局的冲击者吗？| 专访Envoy创始人",
    "url": "https://www.infoq.cn/article/aulwXCUFJctf5FK5zYzu",
    "summary": "<p></p><blockquote>新开源的Envoy Gateway项目，能让Envoy变得更平易近人吗？</blockquote><p></p><p>&nbsp;</p><p>2022年5月份，<a href=\"https://medium.com/envoyproxy/introducing-envoy-gateway-ad385cc59532\">新项目Envoy Gateway</a>\"正式开源。这是 Envoy 家族的一项新计划，背后汇集了一组基于 Envoy 的流行 Ingress 提供商，包括 VMware（由 <a href=\"https://github.com/projectcontour/contour\">Contour</a>\" 维护者代表）、<a href=\"https://www.tetrate.io/open-source-contributions/\">Tetrate</a>\"（领先的 Istio 贡献者）和<a href=\"https://www.getambassador.io/\">Ambassador</a>\"（<a href=\"https://github.com/emissary-ingress/emissary\">Emissary</a>\" 的维护者），共同构建Kubernetes 网关 API 参考实现。Envoy Gateway旨在通过开发一个统一的、规范的实现来修复基于 Envoy 的 Ingress 控制器的碎片化问题，该实现将托管在<a href=\"https://github.com/envoyproxy\">Project Envoy</a>\"下。</p><p>&nbsp;</p><p>Envoy Gateway希望给Envoy生态带来什么变化？Envoy上手难度高的问题有解吗？Envoy未来更长远的目标是什么？带着这些问题，InfoQ采访了Envoy创始人Matt Klein，我们也围绕Envoy的核心设计理念和运作模式做了一些探讨。</p><p>&nbsp;</p><p>Envoy项目有一点不同于大部分开源项目，它没有常规意义上的发展路线图、完全由社区驱动，不属于任何单个商业实体，也不存在任何对应的商业版本。这一点吸引了大量寻求技术中立性的潜在用户，但同时也难免让人心生疑问，这会不会导致Envoy项目发展缺少强有力的引导或不够稳定？虽然据Matt介绍，Envoy生态已经相当繁荣，但我们也看到，目前采用Envoy的主要还是大型企业，在打造网关的实践中选型Envoy的国内企业仍属于小众。</p><p>&nbsp;</p><p>本文出自InfoQ特别策划的专题《Envoy当道？云原生时代的下一代网关选型和实践》，希望能帮助你更好地理解Envoy和Envoy Gateway。</p><p>&nbsp;</p><p></p><p></p><p></p><h2>Envoy的目标不是打造最易用的解决方案</h2><p></p><p>&nbsp;</p><p>从技术角度来看，Envoy社区长久以来想做的就是开发一款工具，让它作为不同类型架构和系统的构建基础。在Matt看来，Envoy的核心技术理念实际上是围绕可扩展性展开的。社区所做的一切都是为了让系统更具可扩展性，比如尽可能提供健壮且定义明确的API、清晰的说明文档等。开源项目本身提供大量开箱即用的功能，同时也会保留扩展能力以支持部分用户满足他们的特定使用场景需求，即使大部分人可能用不上。这样一来，人们可以根据自己的需求，通过不同方式对Envoy做出扩展，很多扩展场景都超出了社区的意料，也让Envoy取得了超出预期的成功。</p><p>&nbsp;</p><p>Envoy的目标并不是打造一套最易用的解决方案，而是想为人们提供可以构成不同解决方案的构建单元，借此对接服务网格、边缘负载均衡、内部负载均衡等各类使用场景。</p><p>&nbsp;</p><p>实际上，Envoy从来不是一个很容易上手的软件。Matt坦言，很多人会觉得Envoy很复杂、很难理解、配置太多，这些说法都没错，但他更认为，纵观整个行业，没有哪种无需配置的简单工具能够同时满足多种不同使用场景的需求。Envoy的目标是帮助他人解决自己的问题，而不是让所有人都满意。</p><p>&nbsp;</p><p>在Matt看来，Envoy不可能适用于所有场景，也不可能适合每一位开发者。因此社区才会围绕Envoy建立起丰富的产品组合和初创项目生态系统，并把这一切都分层置于顶部。就如同瑞士军刀式工具，人们可以在它之上构建起更多不同解决方案。</p><p>&nbsp;</p><p>新开源的Envoy Gateway项目，已经代表着社区的明确态度：大家正在想办法解决Envoy上手难的问题。但这个解法不是改变Envoy，而是以Envoy为基础再做一些分层，用这种方式降低使用门槛，让人们能够轻松上手。</p><p>&nbsp;</p><p>Envoy Gateway项目的真正意义就在于，可以在Envoy之上构建起简化层，用以满足某些更简单的使用场景需求，比如降低在API Gateway（又称“南北向网关”）场景使用 Envoy的门槛。Envoy Gateway为此提供了一个更简易的入门解决方案，能够让用户更快速、更轻松地用上Envoy。在用户用上Envoy Gateway之后，可能就不需要其他东西了；但也有一种可能是未来用户的需求发生变化，而Envoy Gateway无法满足他们更进一步的需求，这时候用户可能需要更复杂的Envoy功能集，而整个Envoy项目生态系统都将能为他们所用，用户可以回过头去尝试使用原始的Envoy、去使用更加强大的XDS API。而这才是Envoy社区实现进一步推广项目、扩大受众这一目标的思路。</p><p>&nbsp;</p><p></p><h2>完全由社区驱动、没有明确的Roadmap</h2><p></p><p>&nbsp;</p><p>遵循着将Envoy打造成“构建单元”的核心理念，自2016年开源以来，Envoy社区一直在不断产出新功能。刚开源时Envoy的核心功能，如今只是所有功能集中的一小部分。不过在Matt看来，Envoy项目的关键里程碑主要体现在社区整体的发展成熟和项目的广泛延伸，而不会落在特定某项功能上。</p><p>&nbsp;</p><p>如今Envoy已经七岁了，不再属于初创项目，甚至可以说已经“步入中年”，就像成熟产品一样，Envoy项目的发展脚步也开始放慢。现在Envoy已经积累起太多用户，不能变得太快、不能颠覆得太快，否则大家会不高兴的。</p><p>&nbsp;</p><p>对于Envoy未来的发展，Matt表示很难明确定义出一份发展路线图（Roadmap），核心还是坚持为云原生架构提供构件单元。他倒是很想拿出一份神奇的功能清单，但确实没有。这一点也是Envoy区别于其他大部分开源项目的特殊之处。</p><p>&nbsp;</p><p>Envoy没有一套常规意义上的发展路线图，它是一个真正由社区驱动的开源项目，背后没有一家公司在推动、没有需要达成的产品目标，也没有产品经理和路线图的引导。Envoy项目由所有参与者共同推动，唯一的目标就是让它能够满足最终用户——那些在Envoy之上构建产品的公司们的需求。Envoy所实现的功能，一定是那些公司所关心的功能。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c7/c7180b74fb329e4795edaf8631c99153.jpeg\" /></p><p></p><p><a href=\"https://www.envoyproxy.io/community\">Envoy官网</a>\"上展示的基于Envoy的开源项目和商业化产品</p><p>&nbsp;</p><p>Envoy 社区完全开放，不存在对应的商业版本，所以用户不用担心部分高级功能会被锁死在商业版当中。同时，Envoy 不属于任何单个商业实体，虽然 Envoy 最初诞生于 Lyft，但 Lyft 并不直接靠 Envoy 赚钱，并将Envoy捐赠给了CNCF。</p><p>&nbsp;</p><p>早在2017年，也就是Envoy刚刚开源一年的时候，Matt就<a href=\"https://medium.com/@mattklein123/optimizing-impact-why-i-will-not-start-an-envoy-platform-company-8904286658cb\">发文公开表示</a>\"，自己不会创办Envoy平台公司，并对原因做了非常详细的解释。其中比较核心的一点是，在Matt看来，与 Docker、Kubernetes、Mesos、NGINX 等类似，“服务网格”Envoy不容易转化为 SaaS 产品。如果要提供即开即用的“服务网格”Envoy 解决方案，本质上相当于要提供完整的 PaaS产品，包括编排和部署的支持，而这等同于直接与主要云提供商竞争。如果不提供完整的 PaaS 产品，那最终业务可能是围绕现有的 PaaS 解决方案提供服务和支持（打包、工具、可观测性等）。无论哪种方式，都不会是一条好走的路，并且这些业务模式也并非Matt兴趣所在。</p><p>&nbsp;</p><p>事实上，Envoy 背后没有商业实体这一事实对许多潜在用户来说极具吸引力（尽管肯定不是全部），因为这让Envoy社区能做出不受企业利益影响的技术优先决策。</p><p>&nbsp;</p><p>Envoy Gateway项目的开源也是社区自发推动、顺理成章的结果。正如Matt在推特上分享的，“它的诞生并非自上而下的设计，而是自下而上的推动。”</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b6/b6148b259d3cdd97400def596829f0bc.png\" /></p><p></p><p>&nbsp;</p><p>由于Envoy的使用确实需要一定的技术积累，直到现在依然有不少用户在选择Kubernetes Ingress或者其他类型Ingress时，还会寻求其他技术。大家要么被迫寻找一家供应商来提供解决方案，要么就得投入大量时间精力深入学习Envoy。正因为如此，市面上出现了一些相互竞争的Ingress解决方案。比如说Emissary Ambassador，比如说Contour，还有很多独立的Ingress选项。但Matt认为，这些项目的开发者之间其实达成了一种共识，就是只要能够以Envoy之名把Ingress解决方案统一起来，就能真正吸引到人们的支持和使用。</p><p>&nbsp;</p><p>这更多是一个水到渠成的结果，只要能让更多人选择使用Envoy，供应商自然就会加入进来，然后建立起更高层级的增值解决方案。于是社区积极出动，与不同供应商广泛讨论，大家逐渐意识到参与进来的好处，最终有了Envoy Gateway的诞生。</p><p>&nbsp;</p><p>Envoy Gateway开源后在国内也引起了很多开发者的关注，其中有一个问题是大家关注的焦点：为什么Envoy Gateway不首选Istio而是新建控制面？以后是否会支持Istio一键迁移？</p><p>&nbsp;</p><p>对此，Matt回应称目前相关讨论和工作还在进行当中，暂时无法给出明确的答案。他本人其实并不反对使用Istio作为控制平面，但Istio是一款非常复杂的软件，Istio社区可能也在想办法做简化。“有一点是可以肯定的，我们没法让每个人都开心，有些人用过Istio后还想继续用，但有些人试过之后就再也不想碰了。总之，大家都会做尝试，看看到底是不是那个自己需要的正确答案。”</p><p>&nbsp;</p><p></p><h2>Envoy的未来：像Linux一样无处不在</h2><p></p><p>&nbsp;</p><p>Envoy自开源以来取得了惊人的成功，远超出Matt当初的想象，他之前从来没想过Envoy会像现在这么成功、这么普及。在最初决定开源Envoy的时候，Matt的梦想其实很简单，就是能再吸引到一家愿意使用它的公司，只要这样就知足了，因为这意味着他创造出了其他人愿意实际使用的东西。如今，Matt觉得自己当初的想法有些“好笑”：“问题已经不再是有没有人用Envoy，而是还有谁不用Envoy”。</p><p>&nbsp;</p><p>不过Matt坦言，Envoy的普及之路还很漫长。目前采用Envoy的主要还是大型企业，已经没多少大型企业能拒绝Envoy了，但Envoy在长尾分布的那条尾巴上还没什么动静。很多公司还在使用Nginx proxy之类的解决方案，但Matt认为这也正是Envoy的机遇所在。</p><p>&nbsp;</p><p>虽然Nginx proxy等解决方案也都是很出色的软件，但Matt认为“它们在市场上的寿命只剩10到15年了。”Envoy和Nginx的诞生相差了10-15年，在这期间，基础设施发生了非常多变化。Nginx和Nginx proxy诞生时的基础设施更趋于静态，因此它长期保持一种更为传统的配置方式，即在磁盘上保存一个配置文件，在需要的时候重新加载。而Envoy从创建之初就考虑到在动态环境下灵活运行，其获取和配置的机制更能适应越来越动态化的现代基础设施。Matt认为这是两者之间最大的区别。</p><p>&nbsp;</p><p>在他看来，如今Envoy已经开始引导Nginx和Nginx proxy的发展方向了。虽然目前Nginx确实还有不少用户和实际使用案例，但未来它们肯定会被逐渐替代掉，当然还需要花一些时间。</p><p>&nbsp;</p><p>此外，Matt认为，随着时间推移，在未来10到15年里，人们会更多关注服务器列表和函数式平台。相比之下，无论是Kubernetes还是Envoy，最终都会慢慢不再是大家关注的焦点，尤其对于普通开发者来说更是如此。</p><p>&nbsp;</p><p>Matt表示：“正常来讲，像Envoy和Kubernetes这样的项目在进入第十个年头之后，都会慢慢失去存在感。到时候人们应该更多转向函数式代码部署平台了。当然，我始终认为未来Envoy很有可能变得更加无处不在，但无处不在其实有两层含义，一是技术被广泛使用，另一层则是人们压根意识不到他们正在使用这个技术。（正是这种存在感的消失，让技术真正变得无处不在。）就像整个世界都运行在Linux之上，但大多数人都感受不到Linux。我觉得未来Kubernetes和Envoy也会走上类似的道路。”</p><p>&nbsp;</p><p></p><h2>写在最后</h2><p></p><p>&nbsp;</p><p>在这次对话中，我们能切实感受到Matt对于Envoy未来发展的信心十足。但对于如何选择网关方案，Matt不止一次强调：他绝不会按头安利，宣扬什么每个人都应该选择Envoy。</p><p>&nbsp;</p><p>在他看来，每个人应该选择能满足需求的最简单的技术，只要原本的解决方案仍然可行，就没必要做任何改变。如果一家公司正在使用Nginx而且效果不错，那最好别做任何改变。除非他们遇到了某个特定的、Nginx没办法解决的问题，比如可观测性问题、比如开源Nginx无法提供某些功能，那Envoy也许会是个不错的选项。首先还是要搞清楚自己需要解决的问题是什么。</p><p>&nbsp;</p><p>“不妨先从单体式架构开始，从最简单的云服务开始，从AWS Lambda开始，从小处入手。随着项目的发展，情况会变得更复杂。总之，别追赶潮流，只追赶问题。核心只有一个：明确要解决什么问题，然后找到最简单的解决办法。”</p>",
    "publish_time": "2022-11-03 13:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "河北首家城商行传统核心业务国产化，TDSQL突破三“最”为秦皇岛银行保驾护航",
    "url": "https://www.infoq.cn/article/047cff33f7b7f48587a4ad5e4",
    "summary": "<p>11 月 1 日，秦皇岛银行新一代分布式核心系统成功投产并稳定安全运行超过三个月，标志着秦皇岛银行数字化转型应用和服务水平登上了一个新台阶。</p><p></p><p>这是秦皇岛银行有史以来规模最大、范围最广、难度最高的一次系统升级，同时也是河北省首家在传统核心业务场景下使用国产数据库的城商行。</p><p></p><p>近年来，随着国际金融局势和疫情变化，银行业发展即要满足科技创新要求，又要保持稳定基础的关键技术自主可控的路线。</p><p></p><p>基于此，秦皇岛银行于2021年4月启动分布式核心系统建设，历时15个月，完成了1个核心系统和63个外围系统更新换代，实现了运营基础、服务能力、产品工具、风险防控、创新引擎等多领域支撑能力的提升。</p><p></p><p>新一代分布式核心系统新增一户通账户管理、集团现金管理、VIP同号换卡、客户自选卡号、统一回单打印、线上承兑、线上贴现等多元化功能，同时强化个人信息安全保护和识别能力，有效保障了客户信息安全和资金交易安全。</p><p></p><p>新一代分布式核心系统依托国产数据库TDSQL的分布式处理机制，实现了日间交易7×24小时不间断处理，提高了日终批处理的并发处理性能,满足了突发事件下的数据零丢失和快速自动恢复，全方位提升了银行监管机构要求的业务连续性水平。</p><p></p><p>新一代分布式核心系统采用“两地三中心”架构，同城主中心和灾备中心部署一套生产集群，依托分布式国产数据库TDSQL的数据同步机制保证中心级的高可用，异地灾备中心部署一套容灾集群，利用分布式国产数据库TDSQL的异步备份技术，实现跨中心的高可用。</p><p></p><p>在构建分布式核心系统的过程中，秦皇岛银行面临着诸多挑战——如何实现传统数据库海量数据向国产数据库的无损迁移是此次系统建设的难点所在。</p><p></p><p>借助国产数据库的数据迁移工具DBbridge，秦皇岛银行轻松实现了异构数据库之间数据的迁移和同步，成功将传统数据库中的数据平滑、安全地迁移到国产数据库，为银行存量业务的连续性和扩展性提供了强有力的保障。</p><p></p><p>秦皇岛银行新一代分布式核心系统积极响应国家对金融核心领域技术自主可控的要求，实现了金融服务的流程更优、速度更快、效果更好，极大提升了客户的满意度、获得感和安全感。</p><p></p><p>在金融领域，企业级分布式数据库TDSQL已服务近半国内TOP 20银行，TOP10银行中服务比例高达60%。未来五年还将助力1000家金融机构实现核心系统数据库国产化。更多案例可在菜单栏内获取哦～</p><p></p><p>方式1：点击【技术干货】进入【客户案例】</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/39/39f50981fac3ac7979f82acf047774d9.gif\" /></p><p></p><p></p><p>方式2：后台回复【客户案例】</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ca/ca2f20904eac787ed0b3f501eea0bcb7.gif\" /></p><p></p>",
    "publish_time": "2022-11-03 10:01:59",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "卷起来了！Meta AI用2周时间预测超6亿种蛋白质结构，速度比AlphaFold快60倍",
    "url": "https://www.infoq.cn/article/GJlzGDccxDtgiRDVdRue",
    "summary": "<p></p><blockquote>蛋白质结构预测领域又有新发现了。</blockquote><p></p><p>&nbsp;</p><p>2022 年 7 月 28 日，DeepMind 的 <a href=\"https://www.infoq.cn/article/IR7FH9Ub18rLOsTtkER2\">AlphaFold</a>\" 工具成功预测出超过 100 万个物种的 2.14 亿个蛋白质结构，几乎涵盖了地球上所有已知的蛋白质。近日，Meta 在这一方向又有新突破：通过 AI 技术成功预测了来自细菌、病毒和其他尚未分类的微生物中，超 6 亿种蛋白质的结构。</p><p>&nbsp;</p><p>Meta AI 蛋白质团队的研究负责人 Alexander Rives 表示：“这些结构来自于我们了解最少的那一部分蛋白质，这些蛋白质太神秘了。我认为这些预测结果能够为生物学的深入研究提供潜力。”</p><p></p><h2>为什么了解和预测蛋白质折叠结构很重要？</h2><p></p><p>&nbsp;</p><p>蛋白质作为一切生命活动的基础物质，其重要性不言而喻。</p><p>&nbsp;</p><p>事实上，蛋白质是一种复杂的“生物机器”。每一种蛋白质都有其独特的功能：有的负责在机体内运输代谢物质，比如血红蛋白；有的负责加速生物化学反应，比如淀粉酶；有的负责调节新陈代谢，比如胰岛素；有的则直接构成生物机体组织，比如胶原蛋白等。蛋白质之所以能够承担多种多样的功能，很大程度上是因为它们具有丰富而复杂的空间结构。</p><p>&nbsp;</p><p>虽然功能多种多样，但其实所有已知的蛋白质的结构都是由 21 种已知的氨基酸构成的。这些氨基酸当中也只包含碳、氢、氧、氮、硫和硒这六种元素。但是，这些氨基酸在链条上的排列组合、链条的折叠方式，以及最终折叠的结构，决定了蛋白质的最终功能。而蛋白质的 3D 形状或结构决定了它在细胞中的功能。</p><p>&nbsp;</p><p>因此，准确了解蛋白质的结构对于生命科学、环境科学等人类目前面对的重要课题都十分关键。</p><p>&nbsp;</p><p>但在 <a href=\"https://www.infoq.cn/article/OEcfh1vwtqEjJtNUGzSR\">DeepMind</a>\" 的 AlphaFold 工具出现以前，人类对地球上的某些蛋白质结构仍知之甚少。而随着 Meta AI 又有新发现，人类对于蛋白质结构乃至生物学，也将有了全新的理解。</p><p>&nbsp;</p><p></p><h2>基于 150 亿参数语言模型，Meta AI 成功预测超 6 亿种蛋白质结构</h2><p></p><p>&nbsp;</p><p>据了解，Meta 本次用于预测蛋白质结构的语言模型拥有 150 亿参数，这也是迄今为止最大的蛋白质语言模型。</p><p>&nbsp;</p><p>通常来说，语言模型是基于大量文本来做训练的。为了将这种模型应用于蛋白质预测领域，<a href=\"https://www.nature.com/articles/d41586-022-03539-1\">Meta AI </a>\"蛋白质团队的研究负责人 Alexander Rives 和他的同事们为模型输入了已知蛋白质的序列。这些蛋白质可以用由 20 种不同氨基酸组成的链条来表达，每一种氨基酸都用一个字母来表示。然后这个网络就学会了“自动完成”，给它输入一部分氨基酸结构被遮蔽的蛋白质分子，它就能预测出剩余的结构。</p><p>&nbsp;</p><p>Rives 表示，这种训练过程让网络对蛋白质序列有了直观的了解——这些蛋白质序列保存了有关其结构的信息。第二步工作受到了 DeepMind 的 AlphaFold 工具的启发，就是将这些见解与已知蛋白质结构和序列之间关系的信息相结合，从蛋白质序列中生成预测结构。</p><p>&nbsp;</p><p>Meta 将这个网络命名为 ESMFold。据其介绍，ESMFold 虽然预测准确性不如 AlphaFold，但在预测速度上，比 AlphaFold 快了大约 60 倍。</p><p>&nbsp;</p><p>因此，Meta 将结构预测工作扩展到更大的数据库范围内。比如，他们将 ESMFold 应用于来自环境来源（包括土壤、海水、人类肠道、皮肤和其他微生物栖息地）的批量测序“宏基因组”DNA 数据库。这个数据库中，绝大多数编码潜在蛋白质的 DNA 条目来自从未被人工培育过，科学上知之甚少的生物体。</p><p>&nbsp;</p><p>最终，ESMFold 预测了 6.17 亿种蛋白质结构，并且只用了 2 周时间，而 AlphaFold 可能需要几分钟才能生成一个预测。</p><p>&nbsp;</p><p>值得一提的是，这套模型的底层代码是免费开放的，任何人都可以免费使用这些预测结果。</p><p>&nbsp;</p><p>据介绍，在 ESMFold 预测的 6.17 亿种蛋白质结构中，有超过三分之一的结果是高质量的，也就是说，研究人员可以确信整体的蛋白质结构是正确的，并且在某些情况下可以辨别出更精细的原子级细节。</p><p>&nbsp;</p><p>此外，这些结构中有几百万个结果是全新的，与通过实验确定的蛋白质结构数据库，或通过已知生物体预测的 AlphaFold 数据库中的所有内容都不一样。</p><p>&nbsp;</p><p>首尔国立大学的计算生物学家 Martin Steinegger 表示，AlphaFold 数据库的很大一部分蛋白质由几乎相同的结构组成，而“宏基因组”数据库应该包含了很多未知的蛋白质结构。“现在我们有了一个很好的机会来探索更多未知的奥秘。”</p><p>&nbsp;</p><p>不过，也有人对 ESMFold 的预测结果表示质疑。</p><p>&nbsp;</p><p>马萨诸塞州剑桥市哈佛大学的进化生物学家 Sergey Ovchinnikov 认为，有些预测结果可能缺乏明确的参考；而另一些预测结果可能是非编码 DNA，只不过被误认为是蛋白质编码材料了。他表示：“看起来仍有一半以上的蛋白质是我们一无所知的。”</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2022-11-03 14:07:13",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "才华横溢的C++人才正在“枯竭”",
    "url": "https://www.infoq.cn/article/ry9vBTW3k67o6Ui4QMr2",
    "summary": "<p>日前海外金融猎头公司 eFinancialCareers 发文称，如今软件公司有一个问题——没有足够的可以编写 C++的人。</p><p></p><p>据悉，这是加密交易工具开发商 ProfitView 在关于使用C++的高频交易的网络研讨会上的共识。曾在花旗银行和Citadel担任量化分析师的Anthony Peacock表示：“很难找到真正拥有高水平 C++ 技能的人，而这正是每家交易公司都想要的。”</p><p></p><p>“这不仅是英国或美国的问题，也不是高频交易特有的问题。自 2008 年以来一直担任专业 C++ 培训师的 Rainer Grimm 认为德国的 C++ 教育同样糟糕，并补充说‘不仅在这个领域，而且汽车行业对 C++ 的需求也很大’。”文中写道。</p><p></p><p>不知从何时开始，C++ 似乎成了一个“老古董”的存在。科技界有些大佬也渐渐对 C++ 嗤之以鼻，<a href=\"https://www.infoq.cn/article/cxumgnubd8mzyo1rccwi\">比如微软 Azure CTO Mark Russinovich 呼吁</a>\"人们为了安全和可靠性，应弃用 C 和 C++ 这两门语言。而他本人曾经也是最优秀的 C++ 专家。</p><p></p><p>那么 C++ 开发人员都去哪了？2022 年 Stack Overflow 调查报告称，过去一年使用 C++ 的受访者几乎下降​​了近两个百分点（从 24.3% 下降到 22.5%），尽管使用它的专业开发人员的百分比有所上升。但另一个好消息是，正在学习编程的受访者群体中，有34.7%的人选择 C++，使其成为该统计类别中的前 6 种编程语言。与此同时，C++ 还是常年出现在 TIOBE 指数的前 4 名中。</p><p></p><p>总的来说，关于 <a href=\"https://www.infoq.cn/article/eG4ify4PeuCtJ1yoP7tD\">“C++ 死亡”的报道</a>\"还为时过早。现实情况是，金融领域有很多需要 C++ 的岗位，而与其他语言相比，填补这些工作的人相对较少。</p><p></p><p>C++ 既不简单也不算受欢迎，这门语言比较难，它是否值得程序员们学习和选择，则是见仁见智了。在 Stack Overflow 调查的“最受喜爱”类别中，<a href=\"https://www.infoq.cn/article/dgKDBiPl7KID0dyaE7Wl\">Rust</a>\" 获得了 87% 的支持率。</p><p></p><p>“我做了 25 年的 C++ 程序员。过去 3 年，我在日常工作和所有爱好项目中都使用 Rust 语言。我不会再回到 C++ 工作。没有钱可以让我改变我的决定。如今，编程对我来说又是一种纯粹的乐趣。”在<a href=\"https://news.ycombinator.com/item?id=33436268\">HackerNews论坛</a>\"上，有读者如是说。</p><p></p><p>参考链接：</p><p><a href=\"https://www.efinancialcareers.com/news/2022/11/why-is-there-a-drought-in-the-talent-pool-for-c-developers\">https://www.efinancialcareers.com/news/2022/11/why-is-there-a-drought-in-the-talent-pool-for-c-developers</a>\"</p>",
    "publish_time": "2022-11-03 15:44:22",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何更好地干掉微服务架构复杂性？| InfoQ《极客有约》",
    "url": "https://www.infoq.cn/article/rl9ZoMw2WHlw1KCWzgBg",
    "summary": "<p>分而治之是面对复杂问题时的惯用方法，微服务架构在分和治两个方面都给出了很好的理论指导和最佳实践，但随着微服务化的进程加深，我们发现了很多新的复杂度，甚至贯穿设计、开发、测试和发布等各个方面，我们又看到很多解决方案冒出来了，比如用DDD的思想解决问题，将微服务治理能力进一步下沉等。</p>\n<p>那么折腾了一大圈，微服务架构的复杂性问题怎么能被干掉呢？本期《极客有约》，我们希望邀请您一同探讨云原生时代，微服务架构治理之道。</p>\n<p><strong>直播话题 </strong></p>\n<p>1.见过或者听过哪些并不适合用微服务架构却用了的案例，可以分享下吗？</p>\n<p>2.微服务架构的复杂性体现在哪几个关键层面？贵司有在实践过程踩过哪些坑吗？</p>\n<p>3.针对上述几个关键层面的问题，有哪些解决思路可以分享？</p>\n<p>4.针对遗留系统做改造，在服务选择、服务改造、业务验证等层面有哪些建议可以分享？</p>\n<p>5.对于当前并不确定是否搭建微服务架构的企业，您可以从技术层面、业务场景、团队实力等多个维度分享下建议吗？</p>\n<p>6.sidecar的模式是否继续适用？</p>\n<p><strong>参与嘉宾</strong></p>\n<p>嘉宾1： 快手微服务中间件技术负责人 魏诗白<br />\n嘉宾2：去哪儿旅行技术总监、技术委员会委员 郑吉敏<br />\n嘉宾3：网易数帆云原生技术专家、架构师 裴斐</p>",
    "publish_time": "2022-11-03 16:05:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "RISC-V在高能效计算上持续演进！阿里平头哥发布RISC-V高能效处理器玄铁C908",
    "url": "https://www.infoq.cn/article/AMHObrpVe29vbUpQoky3",
    "summary": "<p>11月3日，InfoQ2022云栖大会现场报道，阿里平头哥发布了全新RISC-V高能效处理器玄铁C908。</p><p></p><p>玄铁C908计算能效全球领先，较业界同性能处理器能效提升超20%，更能满足低碳时代的算力需求，可广泛用于智能交互、多媒体终端、AR/VR、无线通讯等场景。</p><p>&nbsp;</p><p>“阿里巴巴不断深耕RISC-V 技术和生态，玄铁RISC-V处理器持续演进，端云一体的丰富生态也正在形成。”阿里云智能总裁张建锋说。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/5c/03/5cd9818976709a552cbbff5b147e8d03.png\" /></p><p></p><p>&nbsp;2022云栖大会，阿里云智能总裁张建锋介绍RISC-V进展</p><p>&nbsp;</p><p>从1 GHz跨入2 GHz商用，平头哥不断引领RISC-V新架构的性能提升，推动RISC-V进入新领域。随着碳达峰、碳中和的可持续发展需求日益增强，RISC-V如何在高性能和低功耗之间实现能效最大化，成为业界尤为关注的技术攻坚难题。</p><p>&nbsp;</p><p>最新发布的玄铁C908处理器实现了RISC-V架构的能效突破。玄铁C908支持多核多簇架构，采用高效9级双发按序流水线，主频2 GHz，通过创新的微体系结构和指令融合等技术，实现能效的大幅提升。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/92/e9/926fbd2533be826307147180ff7824e9.png\" /></p><p></p><p>2022云栖大会，平头哥副总裁孟建熠发布最新RISC-V处理器玄铁C908</p><p>&nbsp;</p><p>为进一步提升AI算力及能效，玄铁C908升级了微架构，首次采用RISC-V Vector 1.0标准，并基于标准新增DOT指令；推出INT4数据类型；全面优化AI算子及算法库，典型神经网络计算的性能比前一代产品提升50%以上。玄铁C908也因此超越此前在国际权威AI测试MLPerf Tiny V0.7中夺冠的玄铁C906，在图像分类任务中性能再提升3.5倍。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/39/d3/398b7e3e0c1c178673e33e04638ccbd3.png\" /></p><p></p><p>平头哥玄铁RISC-V产品家族</p><p>&nbsp;</p><p>“玄铁C908打开了RISC-V高能效应用的一片蓝海领域。从低功耗，到高性能，再到高能效，平头哥大幅提升软硬一体的全栈能力，打造出丰富的玄铁RISC-V处理器家族。”平头哥副总裁孟建熠在2022云栖大会上说，“我们还将不断拓展RISC-V技术、应用和生态的边界，挖掘RISC-V在更广阔的端云一体生态中的新价值。”</p><p>&nbsp;</p><p>今年，基于高性能SoC原型“曳影1520”，平头哥完成龙蜥操作系统的适配，成为RISC-V架构兼容云上操作系统的全球首个里程碑，迈出了端云一体的重要一步。2022云栖大会上，平头哥宣布完成RISC-V与统信操作系统社区版本的首度适配，成功运行桌面环境及多款办公、开发类软件，探索RISC-V在桌面端的潜力。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/be/ec/be9e5ddee9d1b07a97f15c6a5454b4ec.png\" /></p><p>玄铁RISC-V处理器上成功运行统信操作系统及多款软件</p><p>&nbsp;</p><p>在端侧，平头哥引领RISC-V架构首次进入安卓开源生态体系，推动RISC-V正式与全球主流移动操作系统生态接轨。从端到云，平头哥已完成RISC-V与RTOS、Yocto Linux、Android、龙蜥、统信等国际主流和国产操作系统的深度适配。</p><p>&nbsp;</p><p>中国工程院院士倪光南在2022云栖大会上表示：“开源模式已从软件领域走向硬件领域，RISC-V为我国掌握芯片产业发展主动权提供了机遇。中国要在全球开源领域中发挥应有的作用，为打破技术垄断和推动世界协同创新，贡献中国智慧、中国方案和中国力量。”</p><p>&nbsp;</p><p>据悉，平头哥是RISC-V国际基金会董事会成员，领导基金会中的数据中心、存储管理、安卓、安全等11个技术方向。平头哥正推进RISC-V国际标准制定，推动全球RISC-V技术与生态发展。</p><p></p>",
    "publish_time": "2022-11-03 16:12:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "微软首席工程师Nick Cameron：Rust要想取得更大的成功，需要解决这十大挑战",
    "url": "https://www.infoq.cn/article/RgA0yves4Q1FHI9dJlry",
    "summary": "<p></p><blockquote>日前，微软首席工程师 Nick Cameron 发文称，Rust 正面临十大挑战。</blockquote><p></p><p></p><p>本文最初发布于Nick Cameron的个人博客。</p><p></p><p><a href=\"https://www.infoq.cn/article/o2QRFPElEpOgvLPe5qzI\">Rust</a>\" 正处于非常有利的位置，它正变得越来越流行，贡献者也越来越多，而且被用在了一些相当重要的地方。然而，这是一个不断变化的时代，从一个研究项目变为一门快速变化的新语言，再成为一个发展势头良好的流行项目，这个过程是非常困难的。</p><p></p><p>在本文中，我想从个人角度介绍下Rust目前及今后几年面临的10个最大的挑战。对于解决之道，我有一些想法，但那都是些又大又难的问题，想找出答案并不容易。所以，真正的解决方案需要迭代，并为此付出精力、发挥创造力。</p><p></p><h2>治理挑战</h2><p></p><p></p><h4>1、如何掌握开发方向而又保持Rust的开放性？</h4><p></p><p></p><p>在开源工作中，对于项目来说什么是最好的，和贡献者想要做什么之间往往关系紧张。如果你足够幸运的话，两者能够保持一致，那自然没什么问题，但通常情况并非如此。有许多方法可以缓解这种紧张关系：给大家发放酬劳，有令人信服的愿景和良好的说服技巧，制定严格的PR接受策略，将事情游戏化，用宣传、感谢、授权或最终的工作机会等作为奖励来激励某些工作的参与者，等等。</p><p></p><p>随着Rust社区不断发展，以及Mozilla直接支持的结束，对Rust来说，这种关系似乎变得更为紧张了。虽然有很多人在做必要的维护工作，但往往还是人手不足，有一些重要的领域缺乏资源，也缺少一些战略性工作，贡献导向力显得不足。</p><p></p><p>在某种程度上，采用一种自上而下的方法可能更简单。不过，那将使Rust丧失作为<a href=\"https://www.infoq.cn/article/uup3gzeGpAtd7KIS8pzf\">开源项目</a>\"的优势。这里有一个很大的挑战是，要确保那些重要但没有吸引力的工作有人做，同时又不会失去那些让它成为优秀项目的特质。</p><p></p><p>我认为，我们当前应该着力完成以下几项具体的事情：</p><p></p><p>先把一些已经开始的工作做完，而不是开始新的工作；按照工具、库、非技术性工作、语言与编译器这样的优先级顺序开展工作；优先考虑影响范围较小、成本较低、但完成后总体影响较大的工作（而不是大而迷人的工作）。与此相关的是，在开发过程中保持Rust项目的本色。特别是，项目如何发展并接受新的贡献者和领导者（以及由此而引发的不可避免的变化），而又不会忽视Rust的中心任务？随着观察员（和评论员）数量的增加，我们如何在讨论和决策过程中保持开放和透明？</p><p></p><h4>2、多元化与包容性</h4><p></p><p></p><p>尽管Rust以其热情友好的社区而闻名，但它的多样性数据却很糟糕，甚至比整个科技行业还糟糕。虽然在包容性方面，我们还算是一个做得比较好的项目，但事实是，还是有很多贡献者因为负面原因离开了项目，这表明我们应该做得更好（是的，避免倦怠也是包容性的一部分）。</p><p></p><p>包容性的一个重要方面是能够协调各种观点。如果我们只有在大家意见一致时才能和平共处，那么我们就不是多元化或包容性的。虽然在某些领域，对协商一致的偏好给我们带来了一些好处，但那也造成了一些问题。我们的文化更倾向于避免冲突而不是解决冲突，那是不健康的，会导致治理功能的失调。</p><p></p><p>要解决这些问题真的很难！但是，我们必须优先解决它们，即使很难，即使有时伴有阵痛。</p><p></p><h4>3、避免僵化的低效流程</h4><p></p><p></p><p>过去这些年，Rust取得了难以置信的发展，但我们的流程和组织结构却未能跟上发展的步伐。任何与治理或流程相关的变革都很保守。即使现有流程存在着巨大的损耗，除了微调之外似乎也不可能做其他任何事情。我们积累的组织债务已经如此之多，需要进行根本性的变革，但这会非常困难。</p><p></p><p>我认为，问题的核心是项目不愿意把“管理（management）”（人员管理、项目管理、产品管理）作为项目领导层的一个重要组成部分。这些事情可以独立于技术领导层，但需要真正的权力下放（而不仅仅是工作下放）。</p><p></p><p>项目面临的挑战是愿意授权，支持这些活动，并引入新的流程，为项目提供更好的支持。</p><p></p><h2>生态系统挑战</h2><p></p><p></p><h4>4、浏览crate生态系统</h4><p></p><p></p><p>Rust在最小标准库和“batteries included”之间取得了很好的平衡，这得益于蓬勃发展的生态系统和简单易用的包管理器。然而，浏览crate生态系统一直很费劲。crate有很多，要找出一个适合的需要做大量的工作，或是非常积极地参与社区活动。随着不积极参与社区活动的用户越来越多，以及crate数量的增长，这个问题会越来越严重。</p><p></p><h4>5、异步生态系统</h4><p></p><p></p><p><a href=\"https://xie.infoq.cn/article/aaafc6d8f03b629200de5b4a3\">异步编程</a>\"对于Rust的许多应用领域来说都很重要，而且与Rust的编程模型非常契合。然而，这个生态系统在不同的运行时之间存在着一定程度的分裂，我们在这方面的改进工作一直很缓慢。我们在努力，但进展缓慢，最终能否成功也还是个变数。风险在于，我们最终把这些东西引入了标准库，而社区又不是很接受，最终导致这个生态系统比开始时还糟糕。</p><p></p><h2>技术挑战</h2><p></p><p></p><h4>6、如何让这门语言在不失去核心特性的情况下拥有更广泛的吸引力？</h4><p></p><p></p><p>Rust在其细分市场已经非常成功，而且我认为还有很大的发展空间。不过，Rust可能远不止于此。如今，有很多软件都是用具有托管运行时的语言编写的，这些运行时对性能都非常敏感，而Rust注重安全性、人体工程学和性能，可以开发出更好的产品，提高生产率。然而，与GC语言相比，Rust目前的学习难度还很大，需要付出很高的认知成本。让Rust更易于学习和使用可能会提升Rust的影响力。</p><p></p><p>我认为，支持GC、提供针对Rc&gt;类型的语法糖或是添加各种语法糖并不是这个问题的解决之道。我们要简化一些东西，但又不能使Rust丧失其作为系统编程语言的优势。减少显式生命周期的使用，增强借用检查器，避免trait系统过于复杂，关注用户体验，避免成为一门庞大的语言，这些都会有所帮助。也许我们会发现新的抽象，显著简化所有权和生命周期？</p><p></p><h4>7、内存模型和不安全代码</h4><p></p><p></p><p>安全性是Rust的主要特性之一，也是许多人使用它的原因。遗憾的是，在安全的边界上是不安全代码，从安全到不安全没有一个平稳的过渡，只是一个不安全的悬崖，冰冷、可怕。我们需要提供更多的支持和更好的体验，让程序员完成不安全的工作。为此，我们需要更清晰地理解Rust的内存模型，然后再开发语言特性、库和工具。</p><p></p><p>所幸，这个领域很活跃，有学术研究、社区的出色工作、MIRI、不安全代码指南，等等。遗憾的是，这是一个非常复杂和困难的领域，许多来自外围的声音减缓了进展速度，增加了参与者的工作难度。一些真正有影响力的变更可能因为政治和技术原因而变得太大（参见上文的流程僵化挑战和下文的编译器的重大修改挑战）。</p><p></p><h4>8、标准库演进</h4><p></p><p></p><p>Rust有一种严格而强大的方法来保持稳定性，包括针对向后兼容性定义了明确的保障措施。对于语言，一个版本可以有一些向后不兼容的演进而不会造成什么破坏。对于生态系统中的库，Cargo和Semver文化亦使得演进成为可能。然而，对于标准库，除了单调发展之外没有其他任何方法（有些东西可以弃用，但永远不能删除，还有一些东西不允许修改）。</p><p></p><p>就其本身而言，这将导致标准库越来越大，越来越混乱。除此之外，还有一个次级效应：我们在稳定性方面必须非常保守，除了“永远稳定”和“只在Nightly版本可用并且完全可以更改”之外，API再没有其他可能的状态（相比之下，对于crate，pre-1.0版本可能可以与稳定版的编译器一起使用，而post-1.0版本也可能要有选择地使用）。</p><p></p><p>与此相关，标准库是一笔全有或全无的买卖（技术上也有liballoc）。有一个更细粒度的版本管理方案，让我们可以更细粒度地使用标准库，而不是要么核心库，要么全部，那将是非常有好处的。</p><p></p><h4>9、编译器的重大修改</h4><p></p><p></p><p>Rustc 现在是一个相当庞大的软件，有很多内在的复杂性（Rust是一种复杂的语言，在保证快速编译的同时给出良好的错误消息非常困难），有很多大型软件常见的问题，还有很多技术债务。这里有一些很大的挑战，特别是在编译时（其中，增量编译和并行编译是两种正在研发中的方法），并且都是些很难实现的工作。</p><p></p><p>像Chalk和Pelonius这样的工作是特别大的项目（要好几个人做好几年才能完成）。将来，做出重大修改只会越来越难。幸运的是，编译器团队有能力、有精力，而且资源丰富。但是，对Rustc 进行影响重大的修改仍然很有挑战性。</p><p></p><h4>10、宏</h4><p></p><p></p><p>宏有许多不完善的地方，也是该语言最不完善的部分之一。声明式宏引入了一种全新的子语言。过程宏很笨重，需要大量的依赖，并且很难掌握。所有宏在编译器（编译时间、增量编译、错误消息）和工具（IDE、rustdoc等的各种问题）中的表现都很差。</p><p></p><p>我认为，这之所以成为一项巨大的挑战（不仅仅是又一个可以有针对性进行研究的语言特性）是因为这些问题涉及面广而且难度大。（可能）没有什么银弹，而只有大量的工程和设计工作。许多问题（如宏卫生性）需要的专业知识在社区中并不存在。宏的优先级不够高（毕竟，从根本上讲，它们还是有效的），对于贡献者来说也不够有吸引力。</p><p></p><h2>未来展望</h2><p></p><p></p><p>像这样列出10个问题，并把它们都说成是“大”问题，可能会让人感觉有点消极。但我认为，这些都是现实存在的挑战。好消息是（我觉得是），所有这些问题对于从事项目研发的各类人员来说都是已知的，而且，对于其中的许多问题，人们正在积极地寻求解决之道。尽管任何解决方案的难度都不会小，但我认为，所有这些挑战都有切实可行的解决方案。</p><p></p><p>如果我们能够专注于解决这些问题（当然还有其他一些日常的挑战），那么我认为，Rust将可以继续发展并取得更大的成功。</p><p></p><p>原文链接：<a href=\"https://www.ncameron.org/blog/ten-challenges-for-rust/\">https://www.ncameron.org/blog/ten-challenges-for-rust/</a>\"</p>",
    "publish_time": "2022-11-03 16:20:33",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "小马智行发布第三代自动驾驶卡车软硬件集成系统，软件算法、传感器方案再次升级",
    "url": "https://www.infoq.cn/article/6CKT512SXPfvcyfXRsrX",
    "summary": "<p>InfoQ 获悉，11月1日，<a href=\"https://www.infoq.cn/article/MsuYlIYEqpxTLeXEYAWa\">小马智行</a>\"正式发布第三代自动驾驶卡车软硬件集成系统。该系统方案面向干线物流业务需求设计，目前已应用于小马智行与三一重卡合作打造的<a href=\"https://www.infoq.cn/article/Xoxc53AKw0ChZH1flrMQ\">首款自动驾驶重卡产品</a>\"。</p><p>&nbsp;</p><p>据介绍，小马智行对第三代自动驾驶卡车软硬件集成系统的软件算法、传感器方案、造型设计、车辆线控底盘等方面都进行了全方位革新，重点提升自动驾驶车重卡产品在复杂工况下的稳定性与兼容性，满足后续大规模量产需求，以实现干线物流效益最大化。</p><p>&nbsp;</p><p>第三代自动驾驶卡车软硬件集成系统的传感器方案沿用多传感器深度融合技术，传感器整体数量20个，主要采用车规级传感器件，在实现自动驾驶超远距感知、360°全景无盲区、长尾场景处理等领域均取得突破。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b9/b9d38e7db17c35235a6c1376e30be710.png\" /></p><p></p><p>具体而言，在高速行驶和高载重的业务要求下，该传感器方案通过1个超长距摄像头、2个长距摄像头、1个量产车规级长距激光雷达、1个远距毫米波雷达构成强大的超远距感知模组，可覆盖前向200米至1000米障碍物探测。以卡车90公里/小时的行驶速度计算，超远距感知模组可让自动驾驶卡车提前30秒精准识别出前方故障车辆，做到从容避障。</p><p>&nbsp;</p><p>同时，为了确保车身周围200米内障碍物的安全召回，尤其是对倒地的锥桶、路面坑洞或抛洒物的识别，该方案包含有一个360°全景感知模组，由2个360°激光雷达、3个补盲激光雷达、3个摄像头、2个毫米波雷达组成，分布在车辆前后及两侧，解决了卡车近身盲区的行业痛点。</p><p>&nbsp;</p><p>软件开发方面，第三代自动驾驶卡车软硬件集成系统采用全新传感器方案和算法设计，从而灵活兼容多种类型货运挂箱；此外，算法系统可根据货物类型和运输要求，精准调节车辆横纵向控制灵敏度，保障玻璃、瓷砖等易碎品的安全平稳运输。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/54/549fd70f145929fc7970876f64b96080.png\" /></p><p></p><p>在硬件设计方面，新一代传感器套件采用一体式弧形设计（Sensor Arc），提高关键器件集成度，降低卡车安装和维护的难度。此外，小马智行还为<a href=\"https://www.infoq.cn/article/A6C1RExKsJtTFMbj7BqG\">卡车系统</a>\"新增传感器清洁系统（Sensor Cleaning System），并将空气动力学原理融入传感器接触面的工业设计中，有效降低脏污存留，减少了干线运输常见的雨雾、沙尘、冰雪、污泥等对传感器灵敏度的影响，可适用于各类工况。</p>",
    "publish_time": "2022-11-03 17:17:47",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "阿里达摩院一口气开源了300+AI模型，还推出了AI模型社区“魔搭”，直击AI应用难题",
    "url": "https://www.infoq.cn/article/mpyyVG2hM3LWRLg5u9H6",
    "summary": "<p></p><p>11月3日，InfoQ2022云栖大会杭州现场报道，阿里达摩院联手CCF开源发展委员会共同推出AI模型社区“魔搭”ModelScope，旨在降低AI的应用门槛。</p><p>&nbsp;</p><p>达摩院率先向魔搭社区贡献300多个经过验证的优质AI模型，超过1/3为中文模型，全面开源开放，并且把模型变为直接可用的服务。</p><p>&nbsp;</p><p>“近十年来，AI的研究发展迅猛，但AI的应用始终是一大难题，使用门槛过高限制了AI的潜能。”阿里巴巴集团资深副总裁、达摩院副院长周靖人表示，AI模型较为复杂，尤其是要应用于行业场景，往往需要重新训练，这使得AI只掌握在少数算法人员手中，难以走向大众化。而新推出的魔搭社区ModelScope，践行模型即服务的新理念（Model&nbsp;as&nbsp;a&nbsp;Service），提供众多预训练基础模型，只需针对具体场景再稍作调优，就能快速投入使用。</p><p>&nbsp;</p><p>据悉，魔搭社区首批合作机构包括澜舟科技、深势科技、智谱AI、哈工大讯飞联合实验室、中国科学技术大学等，社区首批开源模型超过300个，包括视觉、语音、自然语言处理、多模态等AI主要方向，并向AI&nbsp;for&nbsp;Science等新领域积极探索，覆盖的主流任务超过60个。模型均经过专家筛选和效果验证，包括150多个SOTA（业界领先）模型和10多个大模型，全面开源且开放使用。</p><p>&nbsp;</p><p>魔搭社区地址：<a href=\"http://www.modelscope.cn/\">modelscope.cn</a>\"</p><p>中文作画AI体验入口：<a href=\"https://decoder.modelscope.cn/\">https://decoder.modelscope.cn/</a>\"</p><p>&nbsp;</p><p>社区鼓励中文AI模型的开发和使用，希望实现中文AI模型的丰富供给，更好满足本土需求。目前已上架的中文模型超过100个，占比超过1/3，包括了一批探索人工智能前沿的中文大模型，如阿里通义大模型系列、澜舟科技的孟子系列模型、智谱AI的中英双语千亿大模型等。</p><p>&nbsp;</p><p>魔搭社区重点提供了易用的模型使用平台，让AI模型跑起来不再困难，从代码下载到安装部署再到效果验证，以前往往需要数天，现在只要几个小时甚至几分钟。通过全新开发的调用接口和统一的配置文件，平台提供模型探索、环境安装、推理验证、训练调优等一站式服务，在线0代码就可体验模型效果，1行代码实现模型推理，10行代码实现模型调优和定制。平台还提供了在线开发功能和算力支持，无需任何安装部署，打开网页就可以开发AI模型。</p><p>&nbsp;</p><p>据介绍，魔搭社区坚持中立开放原则，其模型兼容多种主流AI框架，支持多种训练与服务部署方式，用户均可自主选择。社区面向所有开发者开放，将实行理事会管理，旨在推动AI大规模应用，不以盈利为目标。</p><p>&nbsp;</p><p>中国科学院院士、中国计算机学会（CCF）开源发展委员会主任王怀民表示，开源是AI发展的重要驱动力，魔搭社区作为新型的AI开源社区，不仅将有力推动AI迈向广泛的落地应用，还将助力中国从开源世界的参与者逐步成长为引领者。中国计算机学会副理事长、澜舟科技创始人兼CEO周明博士表示，随着预训练模型的兴起，魔搭这样的模型社区有望成为AI时代的基础设施，能将AI模型以较低门槛提供给广大开发者，让AI惠及全社会。</p><p></p>",
    "publish_time": "2022-11-03 17:32:32",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]