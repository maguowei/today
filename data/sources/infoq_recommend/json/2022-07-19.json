[
  {
    "title": "微服务架构搭好了，可观测方案怎么整？",
    "url": "https://www.infoq.cn/article/7FgqsQVNa1a2BbHyjZf2",
    "summary": "<p>差不多在五年前，分布式系统也已成熟，微服务架构尚未普及，可观测问题就已经在桎梏技术团队的工作效率。一个To C的软件使用问题可能由客服发起，整条支撑链路的所有技术部门，都要逐一排查接口和日志，流程非常原始，也非常低效。如果业务到达一个量级，支撑系统变多，两名研发查上两三个星期也是常事。</p><p>&nbsp;</p><p>微服务架构普及后，问题变得更加严峻。一个服务被拆分成数个黑盒的、虚拟的微服务，故障排除彻底成为一种折磨。这一切都使业务的可观测性成为2022年技术人必须关注的话题。本期<a href=\"https://www.infoq.cn/video/5cJEWsLZdjGRSDR3WXMZ\">《极客有约》</a>\"，我们邀请到博睿数据创始人兼CTO孟曦东和某头部证劵公司SVP的周洪一起聊聊可观测技术究竟是什么？</p><p></p><p></p><p></p><p></p><p>InfoQ：微服务架构的普及对可观测带来了一些挑战，这些挑战又让运维领域发生了怎样的变化？</p><p>&nbsp;</p><p>孟曦东：可观测不是一个新名词。2018年，CNCF将其正式引入IT世界，该理论的出现则可以追溯至2014年前后，主要来自于控制学，希望通过外部输出推断内部的状态变化。如今，技术栈发生了巨大变化，微服务可能构建在容器之上，容器又构建在虚拟机上，虚拟机则在物理机上，包括更复杂的网络支持，这让定位排障遇到了前所未有的困难。CNCF之所以将可观测性带到微服务领域也是希望能有更好的能力控制系统的运行状态。</p><p>&nbsp;</p><p>与传统的监控相比，可观测性的核心点还是有所区别的。监控可能更多在看现实状态的变化，很直接，但并没有表现出问题的核心点在哪。我们认为可观测性是对现今技术架构非常好的适应，可以用另外一种模型来判断风险所在位置，能更好地预防故障发生而不是简单地降级、限流。</p><p>&nbsp;</p><p>InfoQ：在实际应用当中，企业对可观测性的实际感受是什么样的？</p><p>&nbsp;</p><p>周洪：我们面临着线上问题的排查困难，包括一些链路追踪的困难。特别是证券业务对高可用有非常高的要求，某一个业务出现问题可能无法通过降级和限流来解决，对客户来讲还可能面临着经济上的损失，我们对链路的观测，对链路问题的追踪，对链路服务质量有非常高的要求。在技术架构的升级和演进过程中，我们面临着两类比较难以解决的问题，分别是全链路故障定位及解决和缺少相对全局的视角。</p><p>&nbsp;</p><p>InfoQ：如今，大部分企业还停留在粗暴的降级阶段，还是有意识做全局可监控？</p><p>&nbsp;</p><p>孟曦东：可以分成两类，一类是发展靠前的企业，在业务体验或者用户感知能力上面要求较高，内部对此有很多KPI，比如出现问题需要一分钟内发现，十分钟内解决等；另一类是农林牧副渔等领域的传统企业，目前手段还比较初级，只做到了单体的简单监控，整个上层的应用体系还没有完整建立起来。</p><p>&nbsp;</p><p>InfoQ：具体到技术层面，可观测问题可以分为四类，分布式链路追踪、APM、NPM、RUM，方便介绍下这四者的核心思想吗？</p><p>&nbsp;</p><p>孟曦东：从可观测性的建设体系来看，需要有三种类型的数据。RUM可能更多关心的是用户侧，比如用户到底在使用浏览器、APP还是小程序，使用体验如何或者整个运行过程中的数据能力是如何表现出来的；NPM可能更多在描述链路层面，因为这是必备通道，是建立从前端到后台连接的必备过程，在描述整个数据流向的时候，流量数据又是什么样的表现；APM把物理设备层面的能力提升到了以应用代码级为主，可以看最详细的代码状态，或者依赖的中间件以及JVM状态变化。整个链路追踪分段做数据采集，数据来源可能不同，但模型的核心是构建出一套完整的数据链条来帮助我们更好地判断业务受损到底是由哪个环节产生的问题。</p><p>&nbsp;</p><p>InfoQ：APM做到代码级别之后，还有进一步的改进空间吗？</p><p>&nbsp;</p><p>孟曦东：改进空间肯定还是有的。第一，全链路可观测性需要了解代码的整体逻辑，这样才能更好地知道版本迭代时前后接口的变化；第二，我们也需要知道彼此之间的依赖项是什么，从技术内部来看，链路是非常多样化的，尤其是引用了容器云之后，随着Pod的增加和减少，链路变得错综复杂并且更加动态，我们需要有更完整的信息数据来支撑我们做故障定位。</p><p>&nbsp;</p><p>InfoQ：国内外目前在可观测领域的技术发展现状大概是什么样的？</p><p>&nbsp;</p><p>孟曦东：相对于国外来说，国内起步稍晚，我们可以看到国外有很多优秀的友商，在可观测能力的构建上已经非常成熟，他们还与DevOps做融合，加强安全方面的能力等。我认为国内在可观测性领域属于起步阶段，以博睿数据为例，我们今年才真正构建所谓的一体化全栈解决方案。</p><p>&nbsp;</p><p>InfoQ：贵司目前的监控体系大概是如何组建的？</p><p>&nbsp;</p><p>周洪：我们处于典型的起步阶段，基本采用采购加自研的方式，采购是针对一些比较成熟的产品，可以提供标准化的监测，包括流量、耗时、错误等。同时，我们会自己做一些定制化研发，包括从NPM拿数据，从支持拿数据，自己再做串联。这种方式的弊端可能是要投入相当一部分人力。当然效果还是比较明显的，在关键业务上，我们已经可以实现所谓的全链路监测。但是还有一些相对非核心的业务，边缘化的业务，由于企业自身的自研能力再加上资源投入的不足，可能还有进一步的改善空间。</p><p>&nbsp;</p><p>InfoQ：如何快速低成本地构建业务系统的可观测性？</p><p>&nbsp;</p><p>孟曦东：构建一个所谓的可观测性系统有三个要素，一是要有数据；二是背后有一个强大的异构能力的数据引擎；三是需要有高效的查询。最直接经济的方案是看现在的情况是什么样的，哪些需要采购商业化的产品，哪些选择开源项目或者自研，最终对整体进行拼凑，这种方式会高效一些。</p><p>&nbsp;</p><p>InfoQ：能否聊一下目前建设可观测体系通常的路径，比如说什么类型，或者什么规模的企业？</p><p>&nbsp;</p><p>孟曦东：大体分为三类，第一类是自研的，比如头部的互联网公司，自己的研发实力或者研发资源非常多，在公司的发展过程中沉淀了很多有价值的东西；第二类是基于开源做二次构建，比如腰部的公司，打磨出一个可能适合自己或者组织规模的模型，或许APM就可以，不一定是可观测的解决方案；第三类是全部采买三方软件，通过这种方式构建可观测的能力平台。</p><p>&nbsp;</p><p>InfoQ：有什么流程体系去评估是否应通过外采的方式？</p><p>&nbsp;</p><p>周洪：我们有三大衡量标准。一是市场的标准化程度是否足够高，监控本身的效率及系统稳定性；二是全链路监控而非单点监控，是否具备全业务场景的组合能力，是否可以配置化的形式完成组合业务监控；三是是否具备一些更高级的功能，比如业务异常检测、报警规则、自动发现等措施的智能化程度。</p><p>&nbsp;</p><p>InfoQ：目前市场上提供这种可观测的商用产品是不是也不多？</p><p>&nbsp;</p><p>孟曦东：国外的产品不少，因为今年Gartner的APM领域调研报告也增加了可观测性象限，其中列出了一些新型公司。谈到可观测性需要解决的核心问题，也就是数据来源、对数据的理解以及分析利用，国内市场能完整覆盖的方案少之又少，国外在该领域的纯商业化公司更多一些。</p><p>&nbsp;</p><p>InfoQ：大家比较熟知的项目SkyWalking是否适合微服务的架构？</p><p>&nbsp;</p><p>孟曦东：SkyWalking本身应该定义在APM领域更合适。如果是微服务，对探针端的能力是有要求的，据我们现在看到的，SkyWalking还没有真正做到类似商业公司的探针技术，还做不到全智能的基于K8s的直接部署，动态探针以及自动命名。</p><p>&nbsp;</p><p>InfoQ：可观测性技术在解决数据孤岛方面的作用是什么？</p><p>&nbsp;</p><p>孟曦东：大多数用户的监控系统还是比较多的，可能有几套到十几套不等，因为监控系统也有可能是由于不同的组织内部不同的部门构建的，这样就势必会造成一个问题，因为没有从上层做统筹安排，把这些系统真正有机地组成在一起，供所有业务方去真正消费，孤岛问题就比较严重。我们希望能把数据从相互割裂的体系里面抽取出来，做一个统一的描述的模型，然后供不同的业务方去消费。不管是报警场景，还是运维场景，都可以落地到实际的业务场景里面，这样才能真正拉通。我们有一个很重要的特性就是三方数据的开放性或者兼容性，可以把现有的标准集成到一个平台里面，做统一的标准化，统一的模型建设，统一的落盘，然后再抛掉上层做不同场景的消费能力的支持。</p><p>&nbsp;</p><p>InfoQ：AI在监控领域的作用？</p><p>&nbsp;</p><p>孟曦东：AI赋能到监控领域分为几大方面的作用：第一也是最重要的是根因分析的能力，基础是建立一体化的数据平台；第二是希望可以做自动化的框架，不管是第三方的还是商业化的，通过我们的判断触发一些信息让业务做更有价值的动作，让人力可以得到释放。</p><p>&nbsp;</p><p>InfoQ：如何看待国内可观测厂商SaaS发展的一个前景？</p><p>&nbsp;</p><p>孟曦东：很多人都提出国内的SaaS发展与北美差异较大，我个人认为有几个要素：一是国内的市场环境或者技术栈还未到一定程度，北美也是从基础监控、做日志、做APM慢慢累积到现在这个程度的，美国云计算的发展领先中国五六年的时间，所以北美很多业务应用更习惯于放在几大云上；第二，国内存在一些行业政策的监管要求，比如金融领域可能有一些数据方面的安全要求，这也就限制了公有云标准化SaaS能力的交付；第三，产品能力，这个问题不该回避，国内的可观测能力确实还在起步阶段，在整个能力构建图谱上还有差距，如果产品没有打磨好或者没有特别好的能力价值输出，就会影响客户的买单意愿。</p><p>&nbsp;</p><p>InfoQ：OpenTelemetry&nbsp;项目目前在可观测领域比较受欢迎，这是为什么？</p><p>&nbsp;</p><p>孟曦东：首先，OpenTelemetry&nbsp;将原来部分定义的标准真正体系化了。我们很早就有了OpenTracing&nbsp;，但那只是定义了追踪数据的标准格式。任何企业或组织的技术人员，都希望能把某些能力标准化，这样不管是兼容第三方，还是自我迭代都会有一致性或者维护成本方面的好处。其次，该项目提供了非常丰富的SDK和API能力，可以让开发者和企业快速使用。最后，该项目基于CNCF基金会，其中有很多优秀的人物制订了标准。</p><p>&nbsp;</p><p>InfoQ：在生产环境当中，如何选出靠谱的工具去解决可观测性的问题？</p><p>&nbsp;</p><p>孟曦东：在生产中，环境是多样的，我们首先要找到能与当前业务发展情况较好匹配的工具，毕竟每一款工具或者平台都不是万能的，企业会有很多个性化的要求。对于企业级服务，是不是真的有一些标准或者制度可以约束出来，提供给IT人员做问题定位。在整个工作流里面，QA测试完以后是否能覆盖到所有场景。我们认为，对任何企业或者IT组织来讲，APM工具都是必备的，因为可以把不同角色的人用同一种话术连接在一起。我们做运维、研发，或者业务Owner，需要一个平台把这些标准融合在一起，避免大家产生不必要的纠纷。在APM之外，用户肯定还会再构建更完整的能力平台，因为不能只看到内部，还要看到除了数据中心以外的人的反应。因为这部分可能还会需要依托互联网，依托前端业务应用场景定位可能产生的问题，我认为这是一个有机的组合，根据不同的阶段以及人群使用场景构建出一套自己的体系。</p><p>&nbsp;</p><p>InfoQ：对于同样想构建可观测能力的企业有没有什么比较好的建议？</p><p>&nbsp;</p><p>周洪：第一，无论是监测系统还是业务系统，我们关注的是系统本身的稳定性，监测系统的目的是监测本身的应用系统，通过监测发现应用系统的问题，这对我们来讲至关重要，否则一旦出现生产问题，不知道是怀疑监测系统出了问题，还是怀疑业务系统出了问题，这对甲方来说会带来灾难性的后果。</p><p>&nbsp;</p><p>第二，希望能做到更加体系化甚至全家桶方案，作为应用性的企业，我们还是希望把更多的精力放到业务上，提高业务实战水平，通过解藕的方式把监测体系搭建起来，如果本身对应用系统的入侵很大，甚至说影响到业务系统的信赖，就有点得不偿失了。</p><p>&nbsp;</p><p>InfoQ：博睿数据前段时间也在可观测这部分做了一些事情，发布了一体化智能可观测平台ONE，我们怎么理解这里面的“一体化和智能可观测”？</p><p>&nbsp;</p><p>孟曦东：一体化，我们认为就是要全面，数据能力要能覆盖到整个系统的云管边端的全数据链条。第一步是用三方能力接入或者博睿数据提供自己的数据采集能力把它构建起来。第二步体系化或者标准化的过程，真实构建一个立体的组织模型，否则会导致治理或者定义指标能力时出现混乱。第三步，我们认为一体化也是为AI提供一个底座，我们认为未来AI的价值不可或缺，在主动巡检、过程中的异常监测以及后面的根因分析，AI技术在其中发挥了很大的价值。</p><p>&nbsp;</p><p>InfoQ：国内目前可观测市场的未来发展技术方向是什么？博睿数据后续有什么规划？</p><p>&nbsp;</p><p>孟曦东：如果我们认为IT运维是为了业务做服务或者做支撑，不是成本中心，IT本身就会离业务越来越近，这肯定是一个必不可少的发展路径。反过来想，希望IT输出的价值可能也会发生改变，所以我们认为可观测性本身的核心定义就是Google谈的定位问题。如果业务是敏捷的，某个时间点的弹性或者高可靠无法代表全局。随着业务规模的逐渐膨胀，可观测性需要真正把冲突从根上解决，因为最终还是要定位问题，通过定位到的问题做好事前的风险防范、事中的问题排障以及事后的反思。我认为可观测性肯定是未来，不管是由于云计算还是其他技术的发展。</p><p>&nbsp;</p><p>博睿数据今年希望先把一体化做扎实，再在其上构建其他的能力模块。现在因为测试左移越来越流行，我们准备将安全与DevOps结合在一起，同时在知识库和其他一些ITSM工具的整合上面下功夫，希望能帮助到客户做成一个有机的定位平台。</p><p>&nbsp;</p><p>InfoQ：贵司后期在可观测领域会做哪些层面的事情？</p><p>&nbsp;</p><p>周洪：因为我们是应用方，对我们而言，监测本身不是我们的目的，我们的目的是通过监测间接提升整个服务质量和服务水平。我觉得我也代表广大用户给博睿数据等厂商在千亿级别的发展道路上提一些需求：一是希望把监测做得更加精细化；二是注重场景化诉求，我们已经建立了几千个黄金指标、业务指标，如何快速通过编排或者商业结合准确反应到真正的业务监测链路上，而不需要每次根据业务做一些定制化的开发；三是再进一步做到智能化。</p><p>&nbsp;</p><p>讲师介绍：</p><p>&nbsp;</p><p>孟曦东，博睿数据创始人兼CTO。1998年8月至2000年3月，任中国航空第303研究所软件工程师；2000年3月至2008年1月，任北京千龙新闻网络传播有限责任公司技术总监；2008年2月至2016年2月，任博睿数据首席技术官；自2016年2月至今，任博睿数据董事、副总经理。</p><p>&nbsp;</p><p>周洪，某头部证劵公司SVP</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2022-07-19 08:12:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "金融场景下，分布式数据库如何精准选型、快速落地？",
    "url": "https://www.infoq.cn/article/WJxYG0oi5GvyioGeKmpU",
    "summary": "<p>随着万物互联的到来，数据的应用场景呈现多元化趋势。其中，金融行业作为国民经济的命脉和枢纽，对底层数据库的能力要求也在提高。具有高性能、可扩展、高可用等特性的分布式数据库正在成为金融行业数字化转型的重要支撑。</p><p></p><p>分布式数据库在金融场景落地中，亟需解决金融业务面临的数据规模增长、数据结构多样化等难点。作为金融企业或金融行业从业者，如何在不同的应用场景下，做好分布式数据库的选型和落地？</p><p></p><p>7 月 26 日 19:00-21:30，我们邀请了 4 位嘉宾，带来 4 场精彩的线上主题分享，解答大家关于金融行业分布式数据库选型、落地实践等实际问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ac/acb2604fdf811a942530e4c565a59468.jpeg\" /></p><p></p><h3>议题介绍</h3><p></p><p></p><h5>19:00-19:35《金融业数据库选型之路》</h5><p></p><p>分享嘉宾：韩锋</p><p>议题简介：分布式数据库能够满足金融行业对数据基础设施的高要求，应对高性能、大数据量等多种业务场景。随着近些年来分布式数据库的成熟，金融行业中已有成功案例投入生产系统使用。本次议题聚焦于数据库选型，分享实战中积累的金融行业数据库选型的思考及经验。</p><p></p><h5>19:35-20:10《国产金融级分布式数据库在金融核心场景的探索实践》</h5><p></p><p>分享嘉宾：贾瓅园</p><p>议题简介：从金融级场景到传统金融核心系统场景，在云化的技术浪潮下，国产分布式数据库得以应用在对数据库最高要求的金融行业实现应用。本次分享，将围绕“国产金融级分布式数据库在金融核心场景的探索实践”，与行业探讨当中的经验方案，并展望未来前沿实践方向。</p><p></p><h5>20:10-20:45《金融应用对接分布式数据库》</h5><p></p><p>分享嘉宾：孙亮</p><p>议题简介：金融系统在使用分布式数据库时，可能会遇到哪些问题？会面临哪些改造？会对数据库有哪些要求？本议题将基于实施经验，进行一次探讨与分享。</p><p></p><h5>20:45-21:20《分布式数据库在金融场景下的实战》</h5><p></p><p>分享嘉宾：南云鹏</p><p>议题简介：本次分享将从银行业务场景出发，探讨易用性、可迁移性等要求下，数据库选型的依据及应用实战。</p><p></p><h3>预约报名</h3><p></p><p></p><p>本次公开课，除嘉宾分享外，直播间的小伙伴们还可以通过评论区就分享主题向嘉宾提问互动，现在扫码，即可预约直播！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/36/36095c356338ff7177b6e271698740b3.jpeg\" /></p><p></p><p></p>",
    "publish_time": "2022-07-19 08:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "亚马逊推出基于机器学习的代码助手CodeWhisperer",
    "url": "https://www.infoq.cn/article/8DIQfw2oIiF7qV8ogpI2",
    "summary": "<p>最近，亚马逊云科技推出了基于机器学习的编码助手<a href=\"http://aws.amazon.com/codewhisperer/\">CodeWhisperer</a>\"，它基于开发者使用自然语言编写的注释和集成开发环境（IDE）中的代码提供代码建议。机器学习驱动的服务提高了开发者的生产力。</p><p>&nbsp;</p><p>CodeWhisperer基于各种上下文线索提供建议，包括光标在源代码中的位置、位于光标前面的代码、注释，以及来自同一项目中其他文件的代码。开发者可以完全照搬这些建议，也可以根据需要进行改进和修改。CodeWhisperer使用来自论坛、亚马逊内部代码库、开源代码库和API文档的数十亿行代码进行机器学习训练。</p><p>&nbsp;</p><p>根据亚马逊的说法，开发者可以使用CodeWhisperer来加速开发过程，只需要在IDE中的代码中添加一条注释。编程语言、框架、软件库和云服务必须保持最新。有了CodeWhisperer，开发者可以通过自动代码推荐来加速前端和后端的开发，节省用于构建和训练ML模型的时间和精力，通过对亚马逊云科技服务（包括AWS EC2、AWS Lambda和AWS S3）API的代码推荐来加快开发过程，并减轻编写重复的单元测试代码的负担。</p><p>&nbsp;</p><p>CodeWhisperer还非常重视安全问题，它提供了Python和Java代码扫描，帮助程序员找到他们代码中的漏洞。此外，它还提供了一个引用跟踪器，可以知道代码推荐是否与一组特定的训练数据相似。开发者可以很快找到代码示例，并选择是否在项目中使用它们。</p><p>&nbsp;</p><p>亚马逊表示，推出CodeWhisperer并不是为了提供Copilot的替代方案。亚马逊早在几年前就推出了CodeGuru和DevOpsGuru等服务。</p><p>&nbsp;</p><p>目前，CodeWhisperer兼容Python、Java和JavaScript，支持各种IDE，包括JetBrains、Visual Studio Code、AWS Cloud9和AWS Lambda控制台。</p><p>&nbsp;</p><p>想要体验亚马逊这款最新的代码完成工具的开发者可以提交请求表单进行<a href=\"https://pages.awscloud.com/codewhisperer-sign-up-form.html\">注册</a>\"，并进入等待队列。开发者可以安装<a href=\"https://aws.amazon.com/tools/\">AWS IDE工具包</a>\"，激活CodeWhisperer功能，并在收到预览访问代码后开始使用该工具。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/07/aws-codewhisperer-coding/\">Amazon Unveils ML-Powered Coding Assistant CodeWhisperer</a>\"</p>",
    "publish_time": "2022-07-19 09:01:13",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "使用GraphQL和Ballerina操作多个数据源",
    "url": "https://www.infoq.cn/article/kBD5PhPV2eJQdGIYshxH",
    "summary": "<p>在当今的数字转型时代，应用程序和Web服务之间的相互对话是不可避免的，我们需要通过API来实现这些应用程序之间的通信。各种协议和规范定义了消息通过网络传递的语义和语法，最终形成了一种API架构。</p><p>&nbsp;</p><p>在本文中，我们将探讨如何使用GraphQL和Ballerina将MySQL数据库中的数据作为API公开出来。GraphQL是一种抽象了底层数据源的规范，借助GraphQL，开发人员能够灵活地使用他们喜欢的编程语言处理数据源，如数据库或REST API。</p><p>&nbsp;</p><p></p><h2>GraphQL是什么</h2><p></p><p>&nbsp;</p><p>GraphQL是一种应用层服务器端技术，由Facebook于2012年开始开发，并于2015年公开发布，用于优化REST API调用。GraphQL既可以被视为一种API查询语言，也可以被视为一种服务器端运行时，用于执行由用户定义的查询。</p><p>&nbsp;</p><p>GraphQL的操作类型如下：</p><p>&nbsp;</p><p>查询（读取）；突变（写入/更新）；订阅（连续读取）。</p><p>&nbsp;</p><p>这些操作都只是一个字符串，需要根据GraphQL查询语言规范进行构造。GraphQL对网络层或消息体的格式没有特别要求，不过最常用的一般是HTTP和JSON。</p><p>&nbsp;</p><p></p><h2>GraphQL是更好的REST</h2><p></p><p>&nbsp;</p><p>在过去的十年中，REST已经成为一种流行的API设计架构。REST和GraphQL可以被认为是解决同一问题（通过Web服务访问数据）的两种不同的方法。但是，随着客户端对API的访问需求发生了快速变化，REST API已经变得太不灵活了。推出GraphQL的目的是为了支持更灵活、更高效的数据访问行为。下面列出了选择GraphQL而不是REST的一些关键原因。</p><p>&nbsp;</p><p></p><h4>避免过度获取或获取不足</h4><p></p><p>&nbsp;</p><p>过度获取意味着获取的信息超过了你的需要。这在使用REST时非常常见，因为它总是从给定的端点返回固定的数据集，而客户端实际上具有特定的数据需求。获取不足意味着特定端点没有提供足够的所需信息，客户端不得不发出额外的请求来获取所需的数据。但在使用GraphQL时，你可以使用查询语法定义所需信息的结构，然后通过单个API请求就可以获取所需的信息。</p><p>&nbsp;</p><p></p><h4>客户端可以快速进行产品迭代</h4><p></p><p>&nbsp;</p><p>通常，REST API需要根据客户端应用程序需要的视图来提供端点。如果客户端应用程序发生了变化，它需要的数据可能比以前多也可能比以前少。因此，为了满足新的需求，需要调整REST API。如果使用的是GraphQL，由于客户端可以指定准确的数据需求，所以只需要在客户端做出更改，服务器端不需要做任何额外的工作。</p><p>&nbsp;</p><p></p><h4>支持基于模式和类型系统的开发方式</h4><p></p><p>&nbsp;</p><p>GraphQL有一个强大的类型系统，可用于定义通过API公开出来的数据，所有这些类型都可以使用GraphQL模式定义语言（SDL）写到模式中。模式成了客户端和服务器端之间的契约，不同的团队可以基于定义好的模式分别处理前端和后端的代码逻辑。</p><p>&nbsp;</p><p></p><h2>为什么选择Ballerina</h2><p></p><p>&nbsp;</p><p>你可以使用任何流行的编程语言来构建GraphQL应用程序，如Go、Java、Node.js等。我们选择<a href=\"https://ballerina.io/\">Ballerina</a>\"是因为它提供了很多附加价值：</p><p>&nbsp;</p><p>Ballerina是一种开源的云编程语言，它让网络服务的调用、组合和创建变得更加容易。它是一种现代的、工业级的、用于集成和开发网络服务和应用程序的通用语言。由于具有网络感知类型系统、对网络服务和资源的一流支持、对各种技术（包括GraphQL）的内置支持以及序列图语法等特性，使得开发者体验更加直观。</p><p>&nbsp;</p><p>有两种设计GraphQL端点的方法：</p><p>&nbsp;</p><p>模式优先方法：需要使用GraphQL模式来创建GraphQL服务。代码优先方法：模式是不必需的，可以直接使用代码编写端点，然后生成模式。</p><p>&nbsp;</p><p>Ballerina使用代码优先的方法来设计GraphQL端点。Ballerina的GraphQL实现使用HTTP作为底层协议。在下一节中，我们将探讨这些特性如何帮助你开发GraphQL应用程序。</p><p>&nbsp;</p><p></p><h2>一个书店示例</h2><p></p><p>&nbsp;</p><p>GraphQL服务器的数据源可以是任何东西，如数据库、另一个API或提供数据的服务等。此外，GraphQL可以与任意的数据源组合发生交互。这个示例演示了如何使用Ballerina实现GraphQL服务器，将MySQL数据库中的数据以及通过另一个API调用获取的数据公开出来。</p><p>&nbsp;</p><p>MySQL数据库中保存了与书店相关的数据，包括书籍和作者的信息。与书籍相关的其他信息通过<a href=\"https://developers.google.com/books\">Google Books API</a>\"获得。书店的客户端可以通过GraphQL API完成以下这些操作：</p><p>&nbsp;</p><p>获取所有书籍的详细信息；通过提供书名获取书籍的详细信息；向数据库中添加新书。</p><p>&nbsp;</p><p>上述操作的信息来源如下：</p><p>&nbsp;</p><p>书名、出版年份、ISBN、作者姓名、作者国籍——从数据库获取；平均评分和评分计数——通过ISBN查询Google Books API。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dc/dc041df2882d9d69753e3a26e5e68f50.png\" /></p><p></p><p>这个示例使用MySQL数据库和Google Books API作为数据源</p><p>&nbsp;</p><p>这个示例的所有<a href=\"https://github.com/anupama-pathirage/ballerina-scenarios/tree/main/ballerina-graphql-with-multiple-datasources\">源代码</a>\"都可以在Github上找到。</p><p>&nbsp;</p><p></p><h4>用示例数据填充数据库</h4><p></p><p>&nbsp;</p><p>首先用示例数据填充MySQL数据库。Bookstore数据库有两张表，“Book”和“Author”，包含以下这些字段。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/da/da55d28786b70f170ef2f3f203d143a3.png\" /></p><p></p><p>Bookstore的数据库模式</p><p>&nbsp;</p><p>可以在data.sql文件中找到创建数据库、表和填充数据的SQL语句。如果将这些语句保存到一个文件中，请在数据库中执行以下命令。</p><p>&nbsp;</p><p><code lang=\"javascript\">mysql -uroot -p &lt; /path/to/file/data.sql</code></p><p>&nbsp;</p><p></p><h2>使用Ballerina实现GraphQL服务</h2><p></p><p>&nbsp;</p><p></p><h4>创建Ballerina项目</h4><p></p><p>&nbsp;</p><p>通过执行下面的命令创建一个Ballerina项目。有关Ballerina项目结构的更多细节，请参考“<a href=\"https://ballerina.io/learn/organize-ballerina-code/\">Organize Ballerina code</a>\"”。</p><p>&nbsp;</p><p><code lang=\"javascript\">bal new bookstore\nCreated new package 'bookstore' at bookstore.</code></p><p>&nbsp;</p><p><code lang=\"javascript\">└── bookstore\n├── Ballerina.toml\n└── main.bal</code></p><p>&nbsp;</p><p>1个目录，2个文件。</p><p>&nbsp;</p><p>因为这是一个服务，不需要main.bal文件，所以可以把它删除。</p><p>&nbsp;</p><p></p><h4>创建记录类型</h4><p></p><p>&nbsp;</p><p>添加一个叫作“<a href=\"https://github.com/anupama-pathirage/ballerina-scenarios/blob/main/ballerina-graphql-with-multiple-datasources/bookstore/bookservice.bal\">bookservice.bal</a>\"”的Ballerina文件，用于实现GraphQL服务逻辑。第一步先定义用于表示书籍和作者数据的记录类型。在Ballerina中，记录是特定类型字段的集合。其中有命名的键，并定义了字段的类型。{|和|}分隔符表示这个记录类型只包含所描述的字段。</p><p>&nbsp;</p><p>下面的“BookDetails”记录表示从数据库中获取到的书籍的详细信息。</p><p>&nbsp;</p><p><code lang=\"typescript\">type BookDetails record {|\n   string title;\n   int published_year;\n   string isbn;\n   string name;\n   string country;\n|};</code></p><p>&nbsp;</p><p>接下来创建用于表示从Google Books API获取到的数据的记录类型。在创建所需的记录之前，需要分析一下根据指定ISBN从Google Books API获取的的JSON响应消息的格式。它返回一个JSON对象，其中包含了一个“items”的数组。它还有另一个叫作“volumeInfo”的对象，这个对象包含了与书籍评论相关的信息，字段名分别为“averageRating”和“ratingsCount”。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/80/80a3a4cc5e7011747bd3e3338d2b7a25.png\" /></p><p></p><p>&nbsp;</p><p>在Ballerina中有两种处理JSON的方式。你可以直接使用内置的“<a href=\"https://ballerina.io/learn/by-example/json-type.html\">json</a>\"”类型，或者将JSON转换成用户定义的“anydata”子类型。下面的示例使用了第二种方法，直接将响应消息映射成记录，因为Ballerina的HTTP客户端数据绑定为此提供了很好的支持。因为你只对与书籍评级相关的字段感兴趣，所以可以只用这些字段来创建记录。另外，你用不到字段名为“items”的中间对象，所以这里可以使用匿名记录，因为你不需要通过名称引用这个记录类型。</p><p>&nbsp;</p><p><code lang=\"typescript\">type BookReviews record {\n   record {\n       VolumeInfo volumeInfo;\n   }[] items;//通过内联的方式定义匿名记录类型\n};\n \ntype VolumeInfo record {\n   int averageRating?;\n   int ratingsCount?;\n};</code></p><p>&nbsp;</p><p></p><h4>创建服务对象</h4><p></p><p>&nbsp;</p><p>Ballerina记录类型和服务类型都可以作为GraphQL的对象类型。记录的字段被映射到GraphQL对象的字段，记录字段的类型被映射到GraphQL对应字段的类型。</p><p>&nbsp;</p><p>服务类型中的每一个资源方法表示GraphQL对象的一个字段，资源方法可以有输入参数，这些输入参数被映射到相应字段的参数。</p><p>&nbsp;</p><p>使用记录类型作为对象有局限性，因此，在这个示例中，我们使用服务类型来表示“Book”对象。</p><p>&nbsp;</p><p>在这个服务中，“BookDetails”是一个final的只读字段，在初始化后不能被赋值。</p><p>&nbsp;</p><p>Ballerina GraphQL服务中的资源可以有层级资源路径。如果出现了层级路径，例如下面的author/…，就会为每一个同名的中间路径段创建一个对象类型。路径段下的每一个子路径都将作为所创建类型的一个字段。</p><p>&nbsp;</p><p><code lang=\"typescript\">service class Book {\n   private final readonly &amp; BookDetails bookDetails;\n \n   function init(BookDetails bookDetails) {\n       self.bookDetails = bookDetails.cloneReadOnly();\n   }\n   resource function get title() returns string {\n       return self.bookDetails.title;\n   }\n   resource function get published_year() returns int {\n       return self.bookDetails.published_year;\n   }\n   resource function get isbn() returns string {\n       return self.bookDetails.isbn;\n   }\n   resource function get author/name() returns string {\n       return self.bookDetails.name;\n   }\n   resource function get author/country() returns string {\n       return self.bookDetails.country;\n   }\n   resource function get reviews() returns VolumeInfo|error {\n       string isbn = self.bookDetails.isbn;\n       return getBookReviews(isbn);\n   }\n}</code></p><p>&nbsp;</p><p></p><h4>创建GraphQL服务</h4><p></p><p>&nbsp;</p><p>现在开始编写GraphQL服务。Ballerina对基于网络的交互提供了一流的支持，因此编写服务就变得很简单。服务对象支持通过远程方法和资源方法进行网络交互。监听器提供了网络和服务对象之间的接口。</p><p>&nbsp;</p><p>首先，你需要导入ballerina/graphql模块。然后，你通过指定要监听的端口来创建GraphQL监听器对象，并将其附加到服务上。</p><p>&nbsp;</p><p>资源方法以REST的方式公开服务，而远程方法则以过程方式公开服务。Ballerina服务可以有资源方法和远程方法，资源方法用于表示GraphQL查询类型，远程方法用于表示可变类型。</p><p>&nbsp;</p><p>下一步是加入远程函数或资源函数。allBooks和bookByName是通过GraphQL查询获取书籍数据的资源函数，因此，它们返回“Book”数组。要将新书添加到数据库中，可以调用“addBook”远程方法。它将书籍的信息作为输入参数，并返回一个int值，这个值表示已插入的书籍的索引，如果发生错误就返回-1。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3f/3f69a0973501675a3d2f9e0064322006.png\" /></p><p></p><p>Ballerina GraphQL服务</p><p>&nbsp;</p><p>下一步是实现数据访问逻辑，也就是实现远程方法和资源方法。</p><p>&nbsp;</p><p>完整的代码在<a href=\"https://github.com/anupama-pathirage/ballerina-scenarios/blob/main/ballerina-graphql-with-multiple-datasources/bookstore/bookservice.bal\">bookservice.bal</a>\"中。服务的代码如下所示。与DB交互和API调用相关的getBooks、addBookData和getBookReviews函数的更多细节请参阅下一小节。</p><p>&nbsp;</p><p><code lang=\"typescript\">service /bookstore on new graphql:Listener(4000) {\n   resource function get bookByName(string title) returns Book[] {\n       return getBooks(title);\n   }\n   resource function get allBooks() returns Book[] {\n       return getBooks(());\n   }\n   remote function addBook(string authorName, string authorCountry, string title,\n                                               int published_year, string isbn) returns int {\n       int|error ret = addBookData(authorName, authorCountry, title, published_year, isbn);\n       return ret is error ? -1 : ret;\n   }\n}</code></p><p>&nbsp;</p><p></p><h2>实现数据访问逻辑</h2><p></p><p>&nbsp;</p><p>由于本例使用MySQL数据库作为后端数据存储，因此需要提供查询数据库和添加新记录的功能。Ballerina为DB交互提供了一流的支持。</p><p>&nbsp;</p><p>现在，在项目中添加另一个名为<a href=\"https://github.com/anupama-pathirage/ballerina-scenarios/blob/main/ballerina-graphql-with-multiple-datasources/bookstore/bookdatastore.bal\">bookdatastore.bal</a>\"的文件，用于DB交互和API调用相关的实现。首先，你需要创建一个MySQL数据库客户端，并导入<a href=\"https://central.ballerina.io/ballerinax/mysql\">ballerinax/mysql</a>\"、<a href=\"https://central.ballerina.io/ballerina/sql\">ballerina/sql</a>\"和<a href=\"https://central.ballerina.io/ballerinax/mysql.driver\">ballerinax/mysql.driver</a>\"模块。</p><p>&nbsp;</p><p>你可以在初始化客户端时提供配置信息，不过本例使用了<a href=\"https://ballerina.io/learn/configure-ballerina-programs/configure-a-sample-ballerina-service/\">Ballerina的配置功能</a>\"来提供配置信息。用户可以根据不同的环境通过外部输入来改变系统行为，而且敏感数据（如密码）不会通过代码暴露出来。在定义了配置数据库所需的<a href=\"https://github.com/anupama-pathirage/ballerina-scenarios/blob/main/ballerina-graphql-with-multiple-datasources/bookstore/bookdatastore.bal#L6:L14\">可配置记录</a>\"之后，就可以按照如下方式创建DB客户端。</p><p><code lang=\"typescript\">final mysql:Client dbClient = check new (database.host, database.username, database.password, database.name, database.port);</code></p><p>&nbsp;</p><p>然后可以通过项目中的<a href=\"https://github.com/anupama-pathirage/ballerina-scenarios/blob/main/ballerina-graphql-with-multiple-datasources/bookstore/Config.toml\">Config.toml</a>\"文件来提供配置信息。</p><p>&nbsp;</p><p>现在添加一个HTTP客户端，用于从Google Books API获取所需的数据。你需要导入<a href=\"https://central.ballerina.io/ballerina/http\">ballerina/http</a>\"模块，并按照如下方式创建客户端。</p><p><code lang=\"typescript\">final http:Client bookEp = check new (\"https://www.googleapis.com/books/v1\");</code></p><p>&nbsp;</p><p>这样，你就完成了这个场景的实现。完整的访问数据库的代码可以在<a href=\"https://github.com/anupama-pathirage/ballerina-scenarios/blob/main/ballerina-graphql-with-multiple-datasources/bookstore/bookdatastore.bal\">bookdatastore.bal</a>\"中找到。</p><p>&nbsp;</p><p></p><h2>使用生成的图表</h2><p></p><p>&nbsp;</p><p>因为存在多个实体之间的交互，所以集成用例就变得很复杂。因此，理解整个流程和顺序对于维护、改进和解释场景来说至关重要。Ballerina内置了图表功能，可以基于已编写的代码生成完整的序列图。图表可以作为代码的文档，相比直接阅读源代码，这种方式更易于理解程序。你可以使用<a href=\"https://marketplace.visualstudio.com/items?itemName=WSO2.Ballerina\">Ballerina VSCode插件</a>\"查看和编辑这些图表。</p><p>&nbsp;</p><p>下面是getBooks方法对应的图表。其他方法也有类似的图标，你可以使用VSCode插件查看和编辑它们。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d6/d6330b4bec9bd4694a3e29090592ae60.png\" /></p><p></p><p>基于源代码生成的Ballerina图表</p><p>&nbsp;</p><p>运行Bookstore服务</p><p>&nbsp;</p><p>现在，让我们运行并测试GraphQL服务。要运行这个服务，需要在bookstore项目的根目录下执行下面的命令：</p><p><code lang=\"typescript\">bal run</code></p><p>&nbsp;</p><p>如果你使用GraphQL客户端工具连接到这个服务，它将显示下面这个的模式：</p><p>&nbsp;</p><p><code lang=\"typescript\">type Query {\n allBooks: [Book!]!\n bookByName(title: String!): [Book!]!\n}\n \ntype author {\n country: String!\n name: String!\n}\n \ntype VolumeInfo {\n averageRating: Int\n ratingsCount: Int\n}\n \ntype Book {\n reviews: VolumeInfo!\n published_year: Int!\n author: author\n isbn: String!\n title: String!\n}\n \ntype Mutation {\n addBook(\n   authorName: String!\n   authorCountry: String!\n   title: String!\n   published_year: Int!\n   isbn: String!\n ): Int!\n}</code></p><p>&nbsp;</p><p></p><h2>测试Bookstore服务</h2><p></p><p>&nbsp;</p><p>要调用GraphQL服务器，需要使用客户端。你可以在命令行中使用curl向端点发送HTTP POST请求，并将GraphQL查询作为JSON传递给它。另外，你也可以使用<a href=\"https://ballerina.io/learn/graphql-client-tool/\">Ballerina GraphQL客户端工具</a>\"为给定的GraphQL模式（SDL）和GraphQL查询生成Ballerina客户端。如果你喜欢使用图形用户界面，可以使用<a href=\"https://github.com/graphql/graphiql\">GraphiQL</a>\"或<a href=\"https://altair.sirmuel.design/#download\">Altair</a>\"等。</p><p>&nbsp;</p><p>所有请求的端点都是<a href=\"http://localhost:4000/bookstore\">http://localhost:4000/bookstore</a>\"。</p><p>&nbsp;</p><p></p><h4>示例请求1：获取所有书籍的书名</h4><p></p><p>&nbsp;</p><p>GraphQL查询：</p><p><code lang=\"typescript\">{allBooks {title}}</code></p><p>&nbsp;</p><p>响应：</p><p><code lang=\"typescript\">{\n \"data\": {\n   \"allBooks\": [\n     { \"title\": \"Pride and Prejudice\" },\n     { \"title\": \"Sense and Sensibility\" },\n     { \"title\": \"Emma\" },\n     { \"title\": \"War and Peace\" },\n     { \"title\": \"Anna Karenina\" }\n   ]\n }\n}</code></p><p>&nbsp;</p><p>使用curl命令发送相同的请求：</p><p><code lang=\"typescript\">curl -X POST -H \"Content-type: application/json\" -d '{ \"query\": \"{allBooks {title}}\" }' 'http://localhost:4000/bookstore'</code></p><p>&nbsp;</p><p></p><h4>示例请求2：获取所有书籍更多的信息</h4><p></p><p>&nbsp;</p><p>这就是GraphQL真正强大的地方。用户可以按照自己需要的格式请求所需的信息，无需指定不同的端点，只需修改查询即可。你可以看到这里的一些评级是“null”，因为Google Books API调用返回的一些JSON响应没有包含这些信息。</p><p>&nbsp;</p><p>GraphQL查询：</p><p><code lang=\"typescript\">{allBooks {title, author{name}, reviews{ratingsCount, averageRating}}}</code></p><p>&nbsp;</p><p>响应：</p><p><code lang=\"typescript\">{\n \"data\": {\n   \"allBooks\": [\n     {\n       \"title\": \"Pride and Prejudice\",\n       \"author\": {\n         \"name\": \"Jane Austen\"\n       },\n       \"reviews\": {\n         \"ratingsCount\": 1,\n         \"averageRating\": 5\n       }\n     },\n     {\n       \"title\": \"Sense and Sensibility\",\n       \"author\": {\n         \"name\": \"Jane Austen\"\n       },\n       \"reviews\": {\n         \"ratingsCount\": 3,\n         \"averageRating\": 4\n       }\n     },\n     {\n       \"title\": \"Emma\",\n       \"author\": {\n         \"name\": \"Jane Austen\"\n       },\n       \"reviews\": {\n         \"ratingsCount\": null,\n         \"averageRating\": null\n       }\n     },\n     {\n       \"title\": \"War and Peace\",\n       \"author\": {\n         \"name\": \"Leo Tolstoy\"\n       },\n       \"reviews\": {\n         \"ratingsCount\": 5,\n         \"averageRating\": 4\n       }\n     },\n     {\n       \"title\": \"Anna Karenina\",\n       \"author\": {\n         \"name\": \"Leo Tolstoy\"\n       },\n       \"reviews\": {\n         \"ratingsCount\": 1,\n         \"averageRating\": 4\n       }\n     }\n   ]\n }\n}</code></p><p>&nbsp;</p><p>使用curl命令发送相同的请求：</p><p><code lang=\"typescript\">curl -X POST -H \"Content-type: application/json\" -d '{ \"query\": \"{allBooks {title, author{name}, reviews{ratingsCount, averageRating}}}\" }' 'http://localhost:4000/bookstore'</code></p><p>&nbsp;</p><p></p><h4>示例请求3：指定输入参数获取书籍的详细信息</h4><p></p><p>&nbsp;</p><p>GraphQL查询：</p><p><code lang=\"typescript\">{bookByName(title: \"Emma\") {title, published_year}}</code></p><p>&nbsp;</p><p>响应：</p><p><code lang=\"typescript\">{ \"data\": { \"bookByName\": [{ \"title\": \"Emma\", \"published_year\": 1815 }] } }</code></p><p>&nbsp;</p><p>使用curl命令发送相同的请求：</p><p><code lang=\"typescript\">curl -X POST -H \"Content-type: application/json\" -d '{ \"query\": \"{bookByName(title: \\\"Emma\\\") {title, published_year}}\" }' 'http://localhost:4000/bookstore'</code></p><p>&nbsp;</p><p></p><h4>示例请求4：将数据插入数据库</h4><p></p><p>&nbsp;</p><p>GraphQL查询：</p><p><code lang=\"typescript\">mutation {addBook(authorName: \"J. K. Rowling\", authorCountry: \"United Kingdom\", title: \"Harry Potter\", published_year: 2007, isbn: \"9781683836223\")}</code></p><p>&nbsp;</p><p>响应：</p><p><code lang=\"typescript\">{\n \"data\": {\n   \"addBook\": 6\n }\n}</code></p><p>&nbsp;</p><p>使用curl命令发送相同的请求：</p><p><code lang=\"typescript\">curl -X POST -H \"Content-type: application/json\" -d '{ \"query\": \"mutation {addBook(authorName: \\\"J. K. Rowling\\\", authorCountry: \\\"United Kingdom\\\", title: \\\"Harry Potter\\\", published_year: 2007, isbn: \\\"9781683836223\\\")}\" }' 'http://localhost:4000/bookstore'</code></p><p>&nbsp;</p><p></p><h2>总结</h2><p></p><p>&nbsp;</p><p>在现代应用程序开发中，GraphQL可能是比REST更好的选择。Ballerina为网络抽象提供了的一流的支持，可以通过简单而强大的方式开发GraphQL服务。在我们的示例中，我们实现了一个书店的GraphQL应用场景，结合了多个后端数据源，包括MySQL数据库和Google Books API。</p><p>&nbsp;</p><p>你可以访问<a href=\"https://ballerina.io/\">ballerina.io</a>\"来了解更多关于Ballerina的信息。</p><p>&nbsp;</p><p>你可以通过<a href=\"https://github.com/ballerina-platform/ballerina-standard-library/issues?q=is%3Aopen+is%3Aissue+label%3Amodule%2Fgraphql\">检查问题</a>\"来参与Ballerina GraphQL的模块开发。</p><p>&nbsp;</p><p>示例项目的完整源代码可以在<a href=\"https://github.com/anupama-pathirage/ballerina-scenarios/tree/main/ballerina-graphql-with-multiple-datasources\">这里</a>\"找到。</p><p>&nbsp;</p><p></p><h2>更多信息</h2><p></p><p>&nbsp;</p><p>可以参考以下资源了解更多关于Ballerina GraphQL的信息：</p><p>&nbsp;</p><p><a href=\"https://lib.ballerina.io/ballerina/graphql/latest\">Ballerina GraphQL API文档</a>\"</p><p><a href=\"https://github.com/ballerina-platform/module-ballerina-graphql/blob/master/docs/spec/spec.md\">Ballerina GraphQL规范</a>\"</p><p><a href=\"https://github.com/ballerina-platform/module-ballerina-graphql/tree/master/examples\">Ballerina GraphQL示例</a>\"</p><p><a href=\"https://central.ballerina.io/ballerina/graphql\">Ballerina GraphQL模块</a>\"</p><p>&nbsp;</p><p>作者简介：</p><p>&nbsp;</p><p>Anupama Pathirage是WSO2的工程总监、工程经理和Ballerina语言的开发者。她为Ballerina的各个方面（如编译器、运行时、事务、表、数据库客户端和数据处理等）做出了贡献。Anupama拥有软件架构硕士学位和斯里兰卡莫拉图瓦大学计算机科学与工程系一等荣誉学士学位。Anupama在DZone、InfoQ和Medium上发表文章，并定期在国际技术大会上发表演讲。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/graphql-ballerina/\">Using GraphQL and Ballerina with Multiple Data Sources</a>\"</p>",
    "publish_time": "2022-07-19 09:13:22",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "知乎：如何在大规模集群下使用istio升级微服务架构",
    "url": "https://www.infoq.cn/article/SslDEik5WJa6U5GweKfp",
    "summary": "<p>&nbsp;</p><p></p><blockquote>为进一步加强技术交流，推进云原生生态共建，6月28日下午，首届云原生实践者大会在线上线下同步举办。来自作业帮、知乎、转转、58、同程等多家科技企业的数十名研发人员，以及中国信通院云大所的专家共同参与了此次技术研讨沙龙。&nbsp;研讨会上，知乎核心架构平台开发工程师谢楚瑜讲述了“知乎的istio之旅”，与参会者分享了知乎如何在大规模集群下使用istio升级微服务架构，具体包括如何使istio管理的服务和现存服务之间可以互相通信、知乎的istio迁移都遇到和解决过哪些问题、Service Mesh如何为业务提供了帮助，以及知乎如何在大规模集群中优化性能指标等。&nbsp;以下，是谢楚瑜的分享。</blockquote><p></p><p>&nbsp;</p><p>大家好，我是谢楚瑜，这次主要是和大家分享下知乎是如何进行Service Mesh改造的、在改造期间有遇到了哪些问题，以及随着规模地不断扩大，我们又解决了哪些新的问题。</p><p>&nbsp;</p><p></p><h2>现状</h2><p></p><p>&nbsp;</p><p>先看一下 Service Mesh 在知乎目前的情况。</p><p>&nbsp;</p><p>目前，我们的核心业务以及数百个周边业务都已经完成迁移。在每天的高峰期，Service Mesh中的流量可以达到百万级别的rps。在指标维度也已经达到了百万级别。我们服务治理的各种功能，如压测、鉴权、限流和断路等也通过 Service Mesh 完成了兼容和重构。</p><p>&nbsp;</p><p>然后说下迁移的兼容方案。知乎在早期的时候就已经完成了容器化改造。那时候，我们其实还没有用上K8s，是自己做了一套基于负载均衡以及服务发现的服务通信发现。因此，在迁移Service Mesh时，我们必须首先提供一套方案即可以兼容以前的服务通信，又兼容旧方案的服务治理功能，同时迁移过程对业务无感知，如果有大规模故障还可以快速回滚到旧方案。</p><p>&nbsp;</p><p>为了满足上述需求，我们首先做的就是梳理现有的服务调用流程。</p><p>&nbsp;</p><p>以前，客户端会直接通过注册中心目标服务的负载均衡地址进行访问。但在云原生环境的做法应该是通过coreDNS查询它的一个ServiceIP，通过这个ServiceIP进行服务间通信。如果是在Service Mesh里的话，访问serviceIP 时会直接通过 Envoy 发现一个合适的服务端实例，直接从客户端打到服务端。</p><p>&nbsp;</p><p>考虑到对旧方案的兼容，我们决定对服务发现组件进行改造，增加一个服务发现的代理。如果是上了Mesh的服务访问没上Mesh的服务，那么它其实和以前是一样的，仍然通过旧的负载均衡方案去调用。而对于客户端、服务端都是在Mesh环境下服务调用，这个代理将会返回ServiceIP，这样一来就不需要做SDK层面的修改，可以直接兼容旧的负载均衡方案和新的Service Mesh调用了。这样有一个好处，如果我们需要切换到旧方案，比如紧急回滚的情况，只需要把这个代理上面的配置修改下就可以直接切回过往的一套流量方式。</p><p>&nbsp;</p><p>除此之外，关于鉴权和限流这些功能，我们通过一些Controller实现了一套同步方案，然后通过ServiceMesh的能力实现了兼容。然后关于从零上Mesh其实还有很多改造的点，比如限流。我们上一次IstioCon的分享有比较详细的描述，这次暂时不赘述了。</p><p>&nbsp;</p><p>在迁移期间，我们有遇到过很多的问题。就像我前面提到的，我们当时有一种集中式的代理方案，在切换到Mesh以后，Mesh其实会给每个业务容器实例后加上一个Sidecar，这样相当于说，它的连接方式从以前一种集中式的代理访问，变成一种点对点的模式。</p><p>&nbsp;</p><p>这会直接导致服务端收到并发数发生很明显的变化，很多性能比较敏感的服务也会发生改变。关于这个问题，我们通过一些指标去做连接池的适配，对于延时变化非常敏感的服务，我们会做一些人工处理。</p><p>&nbsp;</p><p>然后是连接管理带来的一些差异。比如我们以前那一套负载均衡方案，会在客户端断开连接以后，仍然保持跟服务端的连接。然而在Istio中，如果客户端连接断开，那么它和服务端连接也就断了，这导致我们的业务会在监控上看到一些不一样的错误，如Golang服务会看到更多的Context Cancel 这类错误。对于这种情况，我们是通过 SDK 对异常的采集做适配来解决。</p><p>&nbsp;</p><p>还有一个比较核心的点。在Istio中，每次读取指标文件都可能在内存里面同时写两份完整的指标配置。当一个实例的指标文件达到上百兆的时候，对Sidecar的性能影响是非常大的。我在后面会具体提到指标这块我们是怎么解决的。</p><p>&nbsp;</p><p></p><h2>业务应用</h2><p></p><p>&nbsp;</p><p>在做好了基础的兼容和适配以后，剩下就是考虑怎么样让业务应用起来。</p><p>&nbsp;</p><p>考虑到Istio对象的复杂度非常高，一上来如果直接看VS、DR，还有Authpolice、Service Entry这些东西的话，很难直接用起来。另外，每一个配置都可能会因为需求的复杂而进行重复配置，比如一个vs的配置里面有时可能会加一个故障注入改一下，然后又加一个重试规则又改一下。</p><p>&nbsp;</p><p>基于这个问题，我们实现了一个类似于Envoyfilter一样的Crd、Istiofilter。通过这个crd，我们可以对Istio应用一种overlay形式配置。这样我们可以通过配置多个Istiofilter 同时管理同一个 vs配置。如果中间某些配置不要了，比如不要流量镜像了，就只需要删掉对应的IstioFilter，随后 vs上面就只会减少这一个mirror的配置，其他配置仍然可以正常使用。目前这一套Istiofilter也是有开源版本的，可以直接在GitHub上找到。</p><p>&nbsp;</p><p>除此之外，我们Mesh的所有能力目前都是直接面向业务研发开放使用的。目前大部分功能都是基于接口这一种粒度进行配置。他们可以通过指标或者自己手动在接口配置界面上配置他们的一些接口定义，在完善接口配置以后就可以在上面使用一些故障注入和限流功能。</p><p>&nbsp;</p><p>考虑到自身业务的特殊性，我们并没有全面使用Istio原生提供的功能。比如，我们自己实现了流量镜像功能，它其实可以支持超过100%这种比例的配置，这样就可以拿线上的流量进行压测，也可以将压力都集中在需要测试的服务端实例上，避免影响其他的客户端应用。</p><p>&nbsp;</p><p>前面提到我们大概有百万级的Rps，同时也已经有10万+的实例运行在上面，这样就会有一些新的问题。比如像Ipvs上如果Service数量太多，一些采集工作会导致它在机器上面软中断时间变长，进而从业务角度观察会有一些网络延迟。最终我们是通过<a href=\"https://gist.github.com/cocotyty/4f5bc48362b9e957c32ced496862aac1\">livepatch</a>\"关闭了特性来解决的这个问题。</p><p>&nbsp;</p><p>然后是做了DNS优化。前面提到，我们当时是用了自己的一套服务发现体系，没有用coreDNS。然后我们在切到Mesh的时候发现，当时的coreDNS 比较难以支撑我们的性能需求。于是我们自己搭建了一套 local Dns，每个K8s节点放一个DNS实例，同时结合这一个Istio的smartdns，减少了由于服务域名没有填写完整而重复查询DNS的次数，这样尽量优化DNS在服务调用中的时间开销。</p><p>&nbsp;</p><p>关于Istio的参数配置，首先由于集群规模较大、服务更新频繁，对于一些服务来说可能配置推送会非常频繁，推送内容也非常比较大，这样的话推送配置非常容易超时。所以，我们根据集群规模调了配置，包括减少了配置推送的量，只针对某个位去推送所需的配置。我们做了一个自动的服务配置范围（sidecar crd）的适配，这样确保每个服务都按需加载配置。</p><p>&nbsp;</p><p>除此之外，我们还使用了Istio 的DiscoverySelector 减少istio采集集群信息的范围。因为我们的集群中除了常规的业务容器外，还有很多永远不会参与服务间通信的容器。但是DiscoverySelector有个问题：它里面的接口可能和我们集群的K8s接口不兼容，Istio 版本如果低于1.13的话，可能会因为panic导致istiod偶发重启。更多细节我们以前也在<a href=\"https://zhuanlan.zhihu.com/p/436796453\">知乎专栏</a>\"上做过很详细的分享。</p><p>&nbsp;</p><p>&nbsp;</p><p>指标方面，前面提到我们指标的维度已经比较大，总维度在百万以上，这对我们的指标系统确实存在一个挑战。我们以前其实只有一个victoriametrics集群，随着指标规模扩大，我们将指标集群分成了两个：一个是短期存储，只存大概一个星期左右的全量指标；另一个是长期存储，它会把短期存储指标里面的pod信息去掉，然后把剩下聚合过的指标存三个月。这样，我们可以做到在大部分情况都能较快地查询到监控数据。</p><p>&nbsp;</p><p>还有一个维度的问题，比如最常见的istio&nbsp;request&nbsp;total 指标，会把某一个客户端的版本信息，以及服务的版本信息全部都带上。但这会遇到一个问题，比如某一个服务端一直不更新、客户端一直更新的情况，会导致服务端有特别多不会增长的指标堆积在里面。可惜Envoy也不支持指标过期的功能，导致每一次拉取指标时我们会多拉很多冗余的指标。</p><p>&nbsp;</p><p>最终，我们决定在服务端去除客户端的版本信息、客户端的指标中去除掉服务端的版本信息，通过这种方式优化指标维度。这样做了之后，我们的指标系统压力有了很大程度的下降，个别服务的duration指标维度甚至下降了20万。通过这些操作，我们集群的监控指标维度基本趋于稳定。</p><p>&nbsp;</p><p>在知乎的Mesh化过程中，Mesh 一方面带来了很多新的问题，比如性能上、运营上的问题。但是另一方面，我们利用Mesh节约了很多过往需要在sdk层面反复实现的功能，也利用Mesh弥补了我们在监控与测试链路方面的许多缺失。Service Mesh是一项充满魅力的技术，而知乎的Mesh之路也将继续下去。</p>",
    "publish_time": "2022-07-19 09:51:45",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "详解“洋葱架构”",
    "url": "https://www.infoq.cn/article/zOlhF7uu455xOVvQwWv3",
    "summary": "<p></p><blockquote>领域驱动设计（Domain-driven design，DDD）是一种为复杂需求开发软件的方法，它将软件的实现与不断发展的核心业务概念模型紧密地结合在一起。</blockquote><p></p><p>&nbsp;</p><p>领域是一个知识的范畴。它指的是我们的软件所要模拟的业务知识。领域驱动设计的中心是领域模型，它对一个领域的流程和规则有着深刻的理解。洋葱架构实现了这一概念，并极大地改善了代码的品质，降低了复杂性，并且支持不断发展的企业系统。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/93/7a/938781120debcffaa9aca8180fb9e67a.png\" /></p><p></p><h2>为什么要用洋葱架构？</h2><p></p><p>&nbsp;</p><p>领域实体是核心和中心部分。洋葱架构是建立在一个领域模型上的，其中各层是通过接口连接的。其背后的思想是，在领域实体和业务规则构成架构的核心部分时，尽可能将外部依赖性保持在外。</p><p>&nbsp;</p><p>它提供了灵活、可持续和可移植的架构。各层之间没有紧密的耦合，并且有关注点的分离。由于所有的代码都依赖于更深的层或者中心，所以提供了更好的可维护性。提高了整体代码的可测试性，因为单元测试可以为单独的层创建，而不会影响到其他的模块。框架/技术可以很容易地改变而不影响核心领域。例如，RabbitMQ 可以被 ActiveMQ 取代，SQL 可以被 MongoDB 取代。</p><p>&nbsp;</p><p></p><h2>原则</h2><p></p><p>&nbsp;</p><p>洋葱架构是由多个同心层构成，它们相互连接，并朝向代表领域的核心。它是基于控制反转（Inversion of Control，IoC）的原则。该架构并不关注底层技术或框架，而是关注实际的领域模型。它是基于以下原则：</p><p>&nbsp;</p><p></p><h3>依赖性</h3><p></p><p>&nbsp;</p><p>圆圈代表不同的责任层。一般来说，我们潜入得越深，就越接近于领域和业务规则。外圈代表机制，内圈代表核心领域逻辑。外层依赖于内层，而内层则对外圈一无所知。通常情况下，属于外圈的类、方法、变量和源代码依赖于内圈，但是反过来也一样。</p><p>&nbsp;</p><p>数据格式/结构可能因层而异。外层的数据格式不应该被内层使用。例如，API 中使用的数据格式可以与 DB 中用于持久化的数据格式不同。数据流可以使用数据传输对象。每当数据跨层/跨界时，它应该以方便该层的形式出现。例如，API 可以有 DTO，DB 层可以有 Entity Objects，这取决于存储在数据库中的对象与领域模型的不同。</p><p>&nbsp;</p><p></p><h3>数据封装</h3><p></p><p>&nbsp;</p><p>每个层/圈封装或隐藏内部的实现细节，并向外层公开接口。所有的层也需要提供便于内层消费的信息。其目的是最小化层与层之间的耦合，最大化跨层垂直切面内的耦合。我们在较深的层定义抽象接口，并在最外层提供其具体实现。这样可以确保我们专注于领域模型，而不必过多地担心实现细节。我们还可以使用依赖性注入框架，比如 Spring，在运行时将接口与实现连接起来。例如，领域中使用的存储库和应用服务中使用的外部服务在基础设施层实现。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/e3/43/e3311c03a2632a88929ae41d29110d43.png\" /></p><p>洋葱架构中的数据封装</p><p></p><h3>关注点的分离</h3><p></p><p>&nbsp;</p><p>应用被分为若干层，每一层都有一组职责，并解决不同的关注点。每一层都作为应用中的模块/包/命名空间。</p><p>&nbsp;</p><p></p><h3>耦合性</h3><p></p><p>&nbsp;</p><p>低耦合性，可以使一个模块与另一个模块交互，而不需要关注另一个模块的内部。所有的内部层都不需要关注外部层的内部实现。</p><p>&nbsp;</p><p></p><h2>洋葱架构层</h2><p></p><p>&nbsp;</p><p>让我们通过一个创建订单的用例来了解架构的不同层和它们的职责。当收到一个创建订单的请求时，我们会对这个订单进行验证，将这个订单保存在数据库中，更新所有订单项目的库存，借记订单金额，最后向客户发送订单完成的通知。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/41/21/418729f9fd237cf1060b916a40960121.png\" /></p><p></p><p>说明各层之间的依赖关系的包图</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/29/b1/297ee78e2cb9aac2dcb1yyd4cd4e11b1.png\" /></p><p></p><h3>领域模型/实体</h3><p></p><p>&nbsp;</p><p>领域实体是领域驱动设计的基本构件，它们被用来在代码中为通用语言的概念建模。实体是在问题域中具有唯一身份的领域概念。领域实体封装了属性和实体行为。它应该是独立于数据库或网络 API 等特定技术的。例如，在订单领域，订单是一个实体，并具有像 OrderId、Address、UserInfo、OrderItems、PricingInfo 这样的属性以及像 AddOrderItems、GetPricingInfo、ValidateOrder 这样的行为。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/8f/2b/8fe54e4533e1cc195d9a8bdcc675812b.png\" /></p><p>订单实体类</p><p></p><h3>领域服务</h3><p></p><p>&nbsp;</p><p>领域服务负责保持领域逻辑和业务规则。所有的业务逻辑应该作为领域服务的一部分来实现。领域服务由应用服务协调，以服务于业务用例。它们不是典型的 CRUD 服务，通常是独立的服务。领域服务负责复杂的业务规则，如在处理订单时计算价格和税收信息，保存和更新订单的订单库接口，更新购买物品信息的库存接口等。</p><p>&nbsp;</p><p>它包含了对其目标非常关键的算法，并且将用例作为应用的核心来实现。</p><p>&nbsp;</p><p></p><h3>应用服务</h3><p></p><p>&nbsp;</p><p>应用服务也被称为“用例”，是只负责协调请求步骤的服务，不应该有任何业务逻辑。应用服务与其他服务交互，以满足客户的请求。让我们考虑一下用例，用一个物品清单创建一个订单。我们首先需要计算价格，包括税收计算/折扣等，保存订单项目并向客户发送订单确认通知。定价计算应该是领域服务的一部分，但涉及定价计算、检查可用性、保存订单和通知用户的协调工作应该是应用服务的一部分。应用服务只能由基础设施服务调用。</p><p>&nbsp;</p><p></p><h3>基础设施服务</h3><p></p><p>&nbsp;</p><p>基础设施服务也被称为基础设施适配器，是洋葱架构的最外层。这些服务负责与外部世界交互，不解决任何领域的问题。这些服务只是与外部资源通信，没有任何逻辑。例如：外部通知服务、GRPC 服务器端点、Kafka 事件流适配器、数据库适配器。</p><p>&nbsp;</p><p></p><h3>可观察性服务</h3><p></p><p>&nbsp;</p><p>可观察性服务负责监控应用。这些服务有助于执行以下任务：</p><p>&nbsp;</p><p>数据收集（指标、日志、痕迹）：主要使用库/侧线来收集代码执行期间的各种数据。数据存储：使用能够集中存储所收集的数据的工具（分类、索引等）。可视化：使用允许你对收集的数据进行可视化的工具。</p><p>&nbsp;</p><p>一些例子包括 Splunk、ELK、Grafana、Graphite、Datadog。</p><p>&nbsp;</p><p></p><h2>测试策略</h2><p></p><p>&nbsp;</p><p>洋葱架构的不同层有不同的职责，相应地也有不同的测试策略。测试金字塔是一个很好的框架，它规定了不同类型的测试。属于领域模型、领域服务和应用服务的业务规则应通过单元测试进行测试。当我们移动到外层时，在基础设施服务中进行集成测试更有意义。对于我们的应用，端到端测试和 BDD 是最合适的测试策略。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/4f/31/4fe71yyeb7b0a9b046yy92e95caaf631.png\" /></p><p>针对不同层的测试策略</p><p></p><h2>微服务</h2><p></p><p>&nbsp;</p><p>当孤立地看待每个微服务时，洋葱架构也适用于微服务。每个微服务都有自己的模型、自己的用例，并定义了自己的外部接口，用于检索或修改数据。这些接口可以用一个适配器来实现，该适配器通过公开 HTTP Rest、GRPC、Thrift Endpoints 等连接到另一个微服务。它很适合微服务，在微服务中，数据访问层不仅包括数据库，还包括例如一个 http 客户端，以从另一个微服务，甚至从外部系统获取数据。</p><p>&nbsp;</p><p></p><h2>应用结构和层数</h2><p></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/88/fc/88f6eee663410b24aefbb4089e2c4cfc.png\" /></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/69/01/690317ef04f34ebe39ee77d0dcf7ff01.png\" /></p><p>应用结构和层，包括层如何映射到模块以及它们之间的依赖关系。它还描述了对不同层使用什么样的测试策略</p><p>&nbsp;</p><p></p><h2>模块化与打包</h2><p></p><p>&nbsp;</p><p>有两种方法来组织应用的源代码：</p><p>&nbsp;</p><p>要么，我们可以将所有的包放在一个模块/项目中，要么将应用分为不同的模块/项目，每个模块/项目负责洋葱架构中的一个层。</p><p>&nbsp;</p><p>这在很大程度上取决于应用的复杂性和项目的规模，将源代码分为多个模块。在微服务架构中，模块化可能有意义，也可能没有意义，这取决于复杂性和用例。</p><p>&nbsp;</p><p></p><h2>框架、客户端和驱动</h2><p></p><p>&nbsp;</p><p>基础设施层由网络或服务器的框架、数据库的客户端、队列或外部服务组成。它负责配置和缝合所有的外部服务和框架。洋葱架构提供了解耦功能，因此在任何时候交换技术都会变得更容易。</p><p>&nbsp;</p><p></p><h2>我们需要每个层吗？</h2><p></p><p>&nbsp;</p><p>将我们的应用分层组织有助于实现关注点的分离。但我们需要所有的层吗？也许需要，也许不需要。这取决于用例和应用的复杂性。根据应用的需要，也可以创建更多的抽象层。例如，对于没有很多业务逻辑的小型应用，拥有领域服务可能没有意义。无论哪一层，依赖关系都应该是从外层到内层。</p><p>&nbsp;</p><p></p><h2>总结</h2><p></p><p>&nbsp;</p><p>洋葱架构在开始时可能似乎有些困难，但是<a href=\"https://jeffreypalermo.com/2013/08/onion-architecture-part-4-after-four-years/\">在业界已经得到了普遍的认可</a>\"。这是一种让软件易于演进的强有力架构。通过把应用划分为几层，可以使系统更加易于测试、维护和移植。它有助于在旧框架过时时轻松采用新框架/技术。与其他架构风格类似，如六边形、分层、简洁的架构等，它为常见问题提供了一个解决方案。</p><p>&nbsp;</p><p>作者简介：</p><p>&nbsp;</p><p>Ritesh Kapoor，软件工程师，热衷于研究算法、架构设计、敏捷方法。</p><p>&nbsp;</p><p>原文链接：</p><p>&nbsp;</p><p>https://medium.com/expedia-group-tech/onion-architecture-deed8a554423</p>",
    "publish_time": "2022-07-19 10:14:53",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "谷歌大量删除 Android 开源项目中 Fuchsia 相关代码",
    "url": "https://www.infoq.cn/article/vEJDHwEKQceAoT8KuJNL",
    "summary": "<p>本周，谷歌在 Android 开源项目 (AOSP) 中删除了大量关于 Fuchsia 的代码，但 Android 和 Fuchsia 目前依然联系紧密。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/b4/2f/b441675b6e860126735e5c2fb494d82f.png\" /></p><p></p><p>Fuchsia OS 是谷歌在 Android 和 chromeOS 之外的又一个操作系统，基于 Zircon，而非 Linux。Fuchsia 目前仅支持该公司的两款智能显示器<a href=\"https://9to5google.com/2021/06/11/google-nest-hub-fuchsia-video-comparison/\">Nest Hub</a>\"和<a href=\"https://9to5google.com/2022/06/23/google-fuchsia-nest-hub-max/\">Nest Hub Max</a>\"，但谷歌一直希望 Fuchsia 设备能够运行安卓和 Linux 等操作系统的 App。为此，谷歌做了很多尝试。</p><p>&nbsp;</p><p>早期，谷歌尝试在虚拟机中运行 Android 操作系统的完整实例，得益于此，Chrome OS 和 PC 版谷歌 Play Games 可以支持 Android 应用，但这种方案也存在潜在的性能缺陷。</p><p>&nbsp;</p><p>谷歌还想了一种办法就是在 Fuchsia 与 Android Runtime 之间建立直接联系。在 2019 年有媒体发现谷歌在 AOSP 代码中创建了一个专为 Fuchsia 设备设计 Android Runtime 进程的项目。</p><p>&nbsp;</p><p>不过，这个被称为“device/google/fuchsia”的Android 项目在 2021 年 2 月后便一直停滞不前，没有公开信息来表明项目进展。而在本周，“device/google/fuchsia”的所有代码都<a href=\"https://android-review.googlesource.com/c/device/google/fuchsia/+/2151868\">从 Android 中删除</a>\"，正式标志着该探索方式的终结。</p><p>&nbsp;</p><p>代码删除之后，该项目只留下简单的“TODO”信息，这表明谷歌可能正在寻求新的方式来代替它。资料显示，负责更改的开发人员主要从事 Fuchsia 的“Starnix”项目。</p><p>&nbsp;</p><p>据悉，Starnix 项目的目标就是让 Fuchsia 能够“原生”运行 Linux 或 Android 构建的应用和库，该项目最早是在 2021 年被曝光。为了实现目标，Starnix 还把底层内核指令从 Linux 转换成了 Fuchsia 的 Zircon 内核。</p><p>&nbsp;</p><p>Starnix 提案被接受并开始进行已经一年多的时间。在此期间，Fuchsia 团队在使 Linux 程序能够在 Fuchsia 设备上运行方面取得了重大进展。</p><p>&nbsp;</p><p>事实上，一个专门的 Starnix shell 曾<a href=\"https://fuchsia-review.googlesource.com/c/fuchsia/+/574541\">短暂地</a>\"用于测试 Fuchsia 的“工作站”。这个 shell 不仅仅是 Linux，实际上是“包含在系统中的小型 Android 发行版”。最近，这一功能被替换为<a href=\"https://fuchsia.googlesource.com/fuchsia/+/e8d93ddd2ebbad70ff5d1e8a8e22fb2a0acfa4b7/src/proc/bin/starnix/README.md#running-the-adb-relay\">通过adb命令</a>\"访问 Fuchsia 和 Starnix 的 Android 功能，就像访问任何其他 Android 设备一样简单。</p><p>&nbsp;</p><p>根据外媒推测，Fuchsia 的 Starnix 团队可能将专注在操作系统与 Android 及其应用程序兼容和稳定方面。</p><p></p><p>参考链接：</p><p></p><p>https://9to5google.com/2022/07/15/android-removes-fuchsia-code-starnix/</p>",
    "publish_time": "2022-07-19 12:05:27",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "互联网上下50年，万字长文推演Web1.0到Web5.0",
    "url": "https://www.infoq.cn/article/kJiii51Dg5p5OA6PLTPV",
    "summary": "<p>如果说2021年科技圈最火的概念是“元宇宙”，那么2022年最火的一定是Web3.0了。目前看来，较早定义Web3.0概念的，是区块链研究员Eshita。</p><p></p><p>Web1.0：可读 Read</p><p>Web2.0：可读+可写 Read+Write</p><p>Web3.0：可读+可写+拥有 Read+Write+Own</p><p></p><p>不过，从直观感觉上来讲，这个划分可能不太准确。毕竟在2004年之前就有大量的BBS、社区和论坛，还有QQ这样的社交软件，可以做到信息的读和写，读和写应该并不是Web1.0和Web2.0的本质区别。今天的头条新闻和当年的门户网站看起来都是信息分发，但它们无论是从技术还是业务逻辑上都有本质的区别。</p><p></p><p>Web3.0的“Own”不代表价值。资产，从定义上来讲，就是透过交易或非交易事项，能以货币衡量，能够为个人或企业带来收益的东西。如果不能变现，不能流通，不能带来现金流，所有权也没有价值，一栋坐落于衰退地区的每年需要缴纳大额房产税的房产可能是个负资产。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/de/c8/de9b37d98185035d1ebfbf0060cce7c8.png\" /></p><p></p><p>前段日子在朋友圈看到关于Web1.0到Web3.0的一个调侃，觉得还有点意思，于是结合自己过去的一些经历，再开了一下脑洞，补充了一下对Web4.0和Web5.0的想象。之后有不少朋友对这个段子感兴趣，于是花时间写下这篇文章，使得段子变得有逻辑，这样也能让自己信服未来是美好的，值得努力再奋斗几十年。</p><p></p><p>我这个调侃也结合了我自身的经历，我学过自动化和模式识别，研究过1年的脑机接口项目，然后从事了十多年的信息化、数字化和数据技术相关工作，折腾过一年的区块链和量子应用，在工作之余也对经济理论比较关注。</p><p></p><p>不卖关子，先给大家看一下Web1.0到Web5.0的推演过程，然后再详细展开每个阶段的故事。</p><p></p><p></p><h3>从Web1.0到Web5.0——关键时刻的预测</h3><p></p><p></p><p>Web1.0</p><p></p><p>1993~2004年，信息的共享和交互</p><p></p><p>标志性启动事件：Mosaic浏览器的出现，是点燃因特网浪潮的火种之一。</p><p></p><p>变革原因和对Web2.0的影响：互联网产生了大量的数据，但是因为技术瓶颈无法盈利。</p><p></p><p>Web2.0</p><p></p><p>从2004年开始，数据价值深度挖掘，产生互联网巨头</p><p></p><p>标志性启动事件：谷歌在2003年后陆续发表关于GFS、MapReduce 和 BigTable的论文。</p><p></p><p>变革原因和对Web3.0的影响：智能数据的价值深度挖掘，互联网巨头开始盈利，并形成垄断，在智能手机带来APP数据隔阂，用户需要更开放和公平的互联网。互联网平台已经深度数字化，孵化了各种大数据和云计算的技术底座。</p><p></p><p>Web3.0</p><p></p><p>从2018年开始，数字化的普及和对等价值交换</p><p></p><p>标志性启动事件：《通用数据保护条例》（GDPR）的发布。</p><p></p><p>变革原因和对Web4.0的影响：数据平权和对等价值交换，打破APP的隔阂和互联网平台的垄断，个人和组织的深度数字化，积累可以孵化AI的完备数据画像，量变引起质变。</p><p></p><p>Web4.0</p><p></p><p>预计从2030年开始，意识的交互</p><p></p><p>标志性启动事件：面向个人的完备AI助理，通过熟人的“图灵测试”。</p><p></p><p>变革原因和对Web5.0的影响：对人类大脑和行为的深度模拟，完成Web5.0需要的智能基础，人机融合可以进一步解放生产力。</p><p></p><p>Web5.0</p><p></p><p>预计从2045年开始，意识的互联，人机融合</p><p></p><p>预测标志性启动事件：人机融合的图灵测试。</p><p></p><p></p><h3>Web1.0：信息共享的时代</h3><p></p><p></p><p>在Web1.0时代，诞生了门户网站、聊天软件、BBS、电商购物网站等互联网应用。这个时代最大的特点是联网和在线，任何线下的场景搬到线上就可以获得火热的关注。Web1.0的兴起很重要的两个原因是个人计算机的普及和因特网的大众化。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/d0/de/d05004f524c9522c24d2106762021bde.png\" /></p><p></p><p>由于互联网用户增多，产生了巨量的内容和数据，服务器的硬件成本和技术团队的人工成本急剧上升，互联网企业压力巨大。门户网站的盈利方式主要靠广告，但是一个网页的页面布局空间有限，容纳太多广告的话会影响用户的体验。如果不能产生个性化的广告和精准的推送，从多个客户赚取广告费用，那么互联网公司的营收就无法支撑庞大的基础架构和技术成本。Web1.0时代的社交软件也很难把客户的各种数据保存在服务器端，因为数据的存储和处理成本过高。</p><p></p><p>在Web1.0里，大多数互联网应用只能做到信息的发布、共享和交互，很少能做到更深层的价值挖掘。第一代互联网在盈利模式上始终是个难题，这个问题导致了第一次互联网泡沫的破裂。1994~2004年，是第一个互联网浪潮兴起、泡沫和衰退的完整周期。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/98/d1/981433b705288ac3481a036960e45ed1.png\" /></p><p></p><p>在Web1.0时代，虽然名头响的是互联网企业，但是在市值和盈利能力上还是那些企业信息化的IT巨头们更胜一筹，例如微软、思科、英特尔、IBM等。互联网给数据技术带来的最大挑战就是数据量极大，但是单位数据的价值不高。企业的应用和业务流程数据往往是抽象和精炼的数据，如果把那些IT巨头面向的企业级信息化的数据和系统比作工厂在矿山里炼金，那么互联网的数据处理就像是在河里淘金，这两个场景需要的技术体系完全不同。互联网企业需要以极低的成本来收集、存储和处理数据，然后通过精准的广告体系来变现。&nbsp;</p><p></p><p>延展思考</p><p></p><p>在Web1.0时代，你每天花多少时间上网和线上社交？</p><p></p><p></p><h3>Web2.0：数据的大浪淘沙时代，诞生互联网巨头</h3><p></p><p></p><p>Web2.0诞生的标志性事件应该就是谷歌在2003年后陆续发表了关于GFS、MapReduce和BigTable的论文，解决了数据存储、计算和处理的成本问题。谷歌通过内部自研，攻克了互联网领域的这三座大山。谷歌通过大数据的成本优势，很早就实现了盈利，并于2004年公开上市。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/d2/e8/d2f03d00ba53e53b2ac0e3bf72851be8.png\" /></p><p></p><p>其他的互联网公司，有些用游戏、短信、甚至一些擦边球的业务利润继续补贴互联网业务，熬过了没有大数据技术的艰难时光。后来各互联网公司通过开源和合作的方式逐渐把谷歌的理论工程化，形成了后来的大数据技术和生态体系，成为互联网业务的基石。</p><p></p><p>Web2.0时代是数据、计算和产品的工业化时代，互联网平台处理数据的成本越低、效率越高，其垄断地位就会逐渐形成。过去十几年里，在搜索、社交、地理服务和信息发布等各个领域，出现了各种各样的互联网平台，这些巨头利用自身在数据上的技术和规模优势，不仅仅通过精准广告实现了数据的价值，也通过数据、流量和场景的结合对传统行业造成了巨大的挑战。一些传统行业公司甚至畏惧与互联网公司合作，因为担心自己积累了几十年的宝贵行业经验建立的护城河，被互联网企业通过数据和流量轻松攻破。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/0d/5f/0d261eb23a569b863a4eb32e2fedfa5f.png\" /></p><p></p><p>有了精准的数据，就可以形成巨大的流量；有了流量，就等于把控了线上的营销渠道。那些对制造、供应链、物流和渠道依赖性不高的产品，在垄断性的流量前基本没有还手之力。通过大数据和千人千面的精准建模，互联网巨头也开始渗透金融领域，通过金融的杠杆不断放大业务规模。</p><p></p><p>海量的个人隐私数据让一些互联网平台得以引导用户购买特定产品，使得用户对投放的内容和产品上瘾。它们利用大数据杀熟，同样的商品和服务，多次查看价格会出现变化，老客户的价格比新客户更高。它们只推荐能带来潜在商业利益的产品甚至假冒伪劣产品，而不是对用户最适合、最恰当的商品。</p><p></p><p>一些平台甚至可以利用数据，对个人的欲望、情绪乃至意识形态加以操控，指引用户阅读特定文章，为特定人投票或对特定群体产生特定的偏见。它们甚至可以成为特定政治势力的代理工具，影响国家大选。即使是大国总统，也可能被互联网平台禁言而失去自己的舆论阵地。</p><p></p><p>在Web2.0，因为智能手机的兴起，从网页时代进入了APP时代，各种弊端表现得尤其明显。</p><p></p><p>Web2.0时代一个不公平的现象，是广大用户贡献了互联网平台需要的数据，但是双方的地位并不对等。用户贡献了账户和数据，但是Web2.0的架构是站在互联网应用的视角来建设的。对于个人来说，其数据是存在一个个APP的服务器里。当互联网应用关闭的情况下，用户的博客、文章、好友列表和关系、聊天记录都将从互联网上消失，并且很难被个人用户在本地长期保存下来。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/4f/ca/4f110cee3b2135663daa2fc67fe1dbca.png\" /></p><p></p><p>在基于PC网页浏览器的互联网时代，各个网站之间还能相互跳转，相互引用，互联网用户还能够方便地订阅不同平台的信息。在APP时代，一些平台美名其曰ALL IN移动端，大幅砍掉纯Web的内容和服务，不登录不让看商品目录，不下载APP就不让看全文。用户成了数据运营和流量转化的工具人，成了各个APP的笼中之物，却没有享受到互联网带来的开放透明。</p><p></p><p>在数据安全上，在“不登录不让使用”“不同意收集数据不让使用”等条款下，个人数据被过度采集。互联网平台在管理用户数据的时候，其管理政策和技术过程的披露不够公开透明，也发生过对内监管不严数据被过度使用、对外数据泄露的安全事故。</p><p></p><p>一些互联网平台被用户贴上了垄断、霸道、乱用算法的标签。凡此种种，都违背了互联网发展的初衷，互联网用户期待未来能有一些改变。</p><p></p><p>延展思考</p><p></p><p>在Web2.0时代，你清楚自己的数据被怎样使用么？&nbsp;</p><p></p><p></p><h3>Web3.0：数字化的普及和对等价值交换</h3><p></p><p></p><p>为了规范管理互联网平台的扩张和对数据的使用，欧洲颁布了《通用数据保护条例》（GDPR），中国也制定了数据安全法。GDPR规定数据主体享有的七项数据权利分别是：访问权、更正权、删除权（“被遗忘权”）、限制处理权、可携带权、反对权，以及不受制于自动化决策的权利。</p><p></p><p>与此同时，在区块链的分布式和去中心化的哲学思潮的影响下，科技圈也希望用更透明、更公平、更开放、更去中心化和价值连接的方式实现一个全新的互联网。个体用户不仅仅在乎数据的权力，也在乎怎样在新的互联网架构体系下分享到价值，这就是Web3.0概念的产生。火爆的ICO、加密货币、Defi、GameFi、NFT等概念层出不穷，使得Web3.0的概念在媒体、投资圈、技术圈讨论火热。很多人认为Web3.0是下一代颠覆性的互联网架构，也有很多人认为Web3.0只是一个理念的炒作，很难真正落地，最终只会是一地鸡毛。</p><p></p><p>如果说，Web2.0给用户带来的困扰是垄断、算法不透明和数据滥用，那么Web3.0就需要在分布式、隐私、开源、信任和连接上做到更好，让互联网用户能够真正分享到Web3.0的好处。在Web2.0时代，即使作品版权归用户，但由于流量完全控制在互联网平台，用户很难将自己的作品或者数据变现。所以对Web3.0的定义，信息对等的价值交换取代了“Own”的概念，如果资源不能带来预期的收益，用户的所有权无法体现价值。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/43/46/43fe5497121107950e95ed1db3ebe146.png\" /></p><p></p><p>与互联网巨头谈对等价值交换，除了法律保障，还得有实力和资源。这里有两种实现对等关系的途径。</p><p></p><p>第一个途径是把以前的互联网平台完全排除在外，通过对等的个体或者是通过限制个体的规模，建立一个独立的Web3.0的生态体系。类似比特币那样的区块链架构是非常完备的体系，对大多数个体也有公平清晰的规则，但是用这样的架构无法支撑Web3.0的海量用户和应用场景。</p><p></p><p>比特币的架构体系完美得让人感觉冷血，这个游戏好像是为机器人设计的。在比特币里最关键的两个因素是能源和算力，二者构成了机器世界的生存基本元素。想象一下，在一个完全是机器人的世界里，机器人依靠能源产生比特币，也可以用比特币来交换能源，获得更多能源和更优算力的机器人，可以轻松淘汰其他机器人。也许区块链大放异彩的时刻，要等到Web5.0时代吧。</p><p></p><p>如果不使用闭环的区块链架构，很多项目披着Web3.0的外衣，带有很强的迷惑性，使得大众难以辨别是非。关于一些乱象，可以参考这篇文章：<a href=\"http://mp.weixin.qq.com/s?__biz=MzU0NjkxMzkwMQ==&amp;mid=2247484105&amp;idx=1&amp;sn=06e2a0a8a24046530d24cab69bf621dc&amp;chksm=fb5729cbcc20a0dd6225004713144ffc6f248b42ff9b202f49174e20ab2a57197105d0f21293&amp;scene=21#wechat_redirect\">《Web3.0里的各种乱象：谈谈StepN和NFT</a>\"》。</p><p></p><p>第二个途径是加强普通企业和个人的数据管理、技术和价值交换的能力，参与原先的体系，与互联网平台共舞。借用区块链的哲学思想和技术体系，充分利用现有的技术和法律的保障来构建Web3.0可能更实际一些。到目前为止，GDPR也只是一系列的法规，还没有具体的技术和产品跟法规一一对应，整个Web3.0的发展和落地应该会比大家想象的要更漫长。如果Web3.0的核心是数据平等和对等价值交换，数据平等是为了更好的和规模化的对等价值交换，那么可以围绕这两点来展开各种探索。</p><p></p><p>Web3.0对个人的影响</p><p></p><p>大多数企业都已经完成了基础的数字化建设，通过各种系统很容易追溯到过往的记录。企业即使是用SaaS应用软件或者公有云，也会将数据留存在自己的管控范围内。但是对于个人来讲，大多数人除了照片、文档和各种笔记外，其他的数据都在哪里呢？个人的数字化，并不是一堆照片和文档的堆积，就像企业级的ERP应用也不只是一堆文件和数据的堆积。</p><p></p><p>例如个人用户的手机里有各种银行和理财的APP，却很少有一个值得信赖的总账管家，来帮助自己管理各个账户里的交易和数据。虽然个人手机里有几十个APP，有的APP记录了自己的跑步数据，有的APP记录了自己的睡眠数据，有的APP记录了自己的体重数据，但是当你想把这些数据汇总在一起做一个归因分析的时候，对于非技术人员来讲几乎不可能。</p><p></p><p>因业务调整，跑步软件NRC APP从2022年7月8日起停止中国大陆地区服务。虽然用户可以从NRC APP里导出自己需要的数据，但是裸数据对用户来讲并没有太大的价值，原始的经纬度的记录也需要应用才能被用户理解。当你换一个新的健身APP的时候，是否还能用以前的数据和记录？</p><p></p><p>HTTP协议发明者蒂姆·伯纳斯-李（Tim Berners-Lee）在1998年提出一个语义网（Semantic Web）概念，它的核心是：通过给互联网上的文档（如: HTML文档）添加能够被计算机理解的语义（元数据），从而使整个互联网成为一个通用的信息交换介质。但是在进入APP时代后，互联网平台并没有沿着这个开放的方向发展。</p><p></p><p>因为不满互联网平台对数据的垄断，Tim Lee又做过一次尝试，在2018年发布了Solid的去中心化平台，这并不是一个区块链平台，https://solid.mit.edu/。Solid的设计思路是每个人都可以拥有一个数据POD，这个POD可以架设在自家的服务器上，也可以由第三方网站托管。当用户访问互联网应用的时候，数据留在个人的Solid的数据POD上，把互联网应用、平台数据和个人数据分开。Solid只是第一步，个人数据保存在POD上，也还需要维持数据的一致性和整合。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/3f/85/3f61b1a715d967058afa64b85613yy85.png\" /></p><p></p><p>当一个用户想把自己在互联网平台的文章迁移出去，可能会使用beepress或者wxsync这样的插件工具把文章同步到自己部署的开源Wordpress系统上。当用户想收藏整理自己在各种APP里阅读的内容，可能会用到Cubox这样的工具。Web2.0时代APP造成的数据墙，使得个人数字化的难度加大了很多，在Web1.0时代很简单的浏览器收藏夹所实现的功能，现在却需要很多专业的工具才能完成。在Web3.0时代，应该会有更好的工具来帮助个人实现更深层次的数字化，这或许是个不错的机会点。</p><p></p><p>大多数成熟的企业都已经建立了数据平台。在Web3.0时代，个人也需要一个属于自己的数据管家，用来管理自己所有的数据存储、分析和交互方式。当APP需要调用数据的时候，由管家来决定哪些数据可以被调用，是否需APP来支付数据调用的成本；当APP产生数据的时候，需要把属于个人的数据也保存在个人数据管家里；当APP停止运营的时候，需要把个人的数据以方便读取的方式交给个人数据管家，用另一个开源或者免费的应用来接管这些数据；个人数据管家还可以对多个APP产生的数据进行关联分析；个人创作的作品，例如文章、视频等，也是第一时间保存在个人数据管家中，然后通过接口与各个内容分发的平台进行数据和价值的交换。随着时间的推移，各种关于个人的数据都将长期保管在个人数据管家之中，形成个人的虚拟印象，最终产生足够智能的AI数字人，数据积累对AI的孵化，是Web4.0发展的一个重要基础。</p><p></p><p>个人数据想要得到价值，必须通过服务或者产品来体现，在Web3.0时代，个人也需要将自己的能力打造成标准的产品，这样可以更好地进行对等交易。过去几年，无论是自媒体、公众号还是短视频，都有非常多的专家在将自己的价值产品化，逐渐形成清晰的个人画像。这点上，微信公众号的Slogan倒是挺符合Web3.0的价值观。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/0b/72/0bede1e3c67045f8f493453ed7217272.png\" /></p><p></p><p>个人数字化的难点在于：个体的需求具体而清晰，但是每个人的个性和隐私需求可能不同，会不会出现好的工具体系来加速将每一个人数字化呢？</p><p></p><p>实现Web3.0需要打破APP之间的数据墙</p><p></p><p>打破互联网平台对数据的垄断也离不开手机厂商对个人隐私的保护。苹果公司首席执行官蒂姆·库克在接受《时代》杂志记者采访时称：关于我们所有人的信息比十年前或五年前更多，它无处不在，你正在到处留下数字足迹。</p><p></p><p>假设网络的速度足够快、延时足够低，也许云手机的生态可以加速个人数据管家的诞生。云手机方案可行的话，手机可以只留下电池、屏幕、摄像头、通信和加密解密的功能，计算、存储和应用都在云手机上。如果需要硬件升级，可以在后台实现一键升级扩容；如果APP需要升级，可以在虚拟的硬件环境里升级，而不用与复杂的硬件进行兼容测试。</p><p></p><p>现在的互联网架构中，有大量应用要用手机号码注册，而手机号码又直接对应个人最隐私的数据——身份证号码，一旦暴露，将给个人带来极大影响。而通过云手机里个人数字管家生成的虚拟身份与各种APP对接，可以在真实身份上加一层防护，实现数据更高级别的安全防护，避免隐私的泄露。</p><p></p><p>云手机也许还可以避免高端手机芯片的封锁，以弯道超车的方式实现一种新的架构体系。如果云手机的方案能落地，运营商就能从现在数据通道的地位翻身，转型为未来的数字化主战场了。由于云手机的技术对带宽和延时的要求很高，运营商的通信基站和边缘数据中心能够形成更好的组合，更能主宰云手机的市场。在运营商主导的云手机体系里，云手机之间的个人数字管家可以实现受监管的自组网，共享分布式数据和应用体系，用来对抗垄断的互联网平台。</p><p></p><p>Web3.0的网络链接价值</p><p></p><p>对Web3.0来讲，参与其中的个体和企业是对等的关系，在价值交换时需要经过复杂的网络链接，而不仅仅是通过单一的互联网平台。</p><p></p><p>例如，一个企业在做招聘的时候，可以通过带明确激励条件的小程序做传播，每个点击、传播和报名的用户都会通过信息加密记录下来。经过多次链路传播后，企业可以核对最终录取者的信息，并把激励发放给链路中间所有的贡献者。这样的小程序，虽然不是完备的区块链架构，但是如果企业能够长期保持其在激励上的信用，应该是可以替代传统的网站招聘方式，毕竟企业招聘和帮朋友介绍机会是个双赢的事情。这样的方式可以做到精准的信息匹配，在一定程度上也能很好地保护链路上用户的隐私。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/27/37/27c32614db98388c7ea0f893f5808837.png\" /></p><p></p><p>由于行政区划与地理远近并非一致，信息传递不能只依行政区划来安排优先级。比如河南信阳跟湖北武汉一样爱吃热干面，它离武汉比离河南省会郑州更近。如果一个武汉的公司去河南高校招聘，招聘信息传递到河南信阳的同乡群里，得到的反馈可能会比传递到普通的毕业班级群里要多得多。但是这样精准的信息传递，需要把信息和价值通过网络传播、反馈和验证，最终才能得到最佳匹配路径，降低成本，使得企业和个人都受益。</p><p></p><p>Web3.0时代，并不是要倒退到互联网的前夜，做事都得靠关系，靠线下的走动；而是要让这种线下的信息和价值，实现数字化、网络化并且可传递。深网信息挖掘的技术变得更重要，可能强化版的图数据库会成为时代的主宰，各种中小型信息数据站点又能够繁荣发展。</p><p></p><p>Web3.0对非互联网企业的影响</p><p></p><p>在没有计算机的年代，货币就是最好的“数字化”工具，人们用货币来衡量社会活动参与个体和企业的经济价值。</p><p></p><p>在过去研究的案例中，贝壳是一个把极其传统的行业和低频业务做了成功的数字化改造的公司。贝壳数字化成功的很重要的原因，是定义和计算一个业务内的不同组织和环节的价值，边界清晰，分工专业，实现企业内外协同的市场化和货币化，最终实现了业务规模化扩张和平台生态化。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/d8/62/d869b4f8cb3dce954de3c65f61653162.png\" /></p><p></p><p>在数字货币的技术和规则成熟后，数字货币不仅仅可以用于企业对外的业务结算，也适用于企业内部的价值结算，未来每个大型企业都有属于自身的数字货币体系。尽早建立一个企业内部的业务、组织和流程的价值体系，并且不断与外部的供应商和服务体系进行对比，可以增加外界对企业的各类资源价值的认知确定性。</p><p></p><p>价值和数字化的结合，打破了企业传统部门和公司的边界，清晰的规则，可以帮助企业实现规模的扩张和实现健康的平台生态。企业可以尝试用Web3.0的理念，打造行业联盟或者供应链上下游的合作体系，互相开放数据，将跨企业之间的业务数字化，将数字化的普及和对等价值交换的理念做实做深做透，在合作竞争中探索Web3.0的最佳实践。契约经济和数字化，不一定非得依靠区块链，用电子合同也可以实现大部分的需求。</p><p></p><p>企业对数据的管理体系比较成熟。在一些高频和标准的应用场景中，例如客服等体系，可以引入AI助理，不断迭代成为企业的虚拟员工。对于低频和复杂的场景，有些企业已经在部门聊天群里引入AI机器人，不断学习员工问与答产生的数据，学习企业或者部门的一些特有业务术语和业务逻辑。对于一些商业软件或者互联网平台造成的数据隔阂，也可以使用带有AI能力的RPA工具将企业的业务流程智能化。</p><p></p><p>并非每个企业都能拥有互联网企业那样的海量数据，在营销端的数据和流量被互联网平台把持的情况下，普通企业可以聚焦在自己的优势领域，例如生产制造、供应链体系、经销商管理，在供给端做深做透，在每个环节研究数字和价值的深层关系，不用过于焦虑。一味地脱实向虚并不可取，企业不可能靠裸数据来换取价值，数据积累的目的是为了更低成本更高效率的规模交易，交易离不开为实体赋能的产品和服务。社会生产制造消费中有很多智慧和经验，有的已经迭代成为最佳实践和第一性原理，其公式对业务的指导有效性，会超过数据的方法论。如果Web3.0真的能实现，在营销端和流量上，非互联网企业将不再处于劣势，那时候比拼的就是供给端的实力了。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/4d/c0/4dac58cd555aeb1df1ea10675d37acc0.png\" /></p><p></p><p>企业与员工之间的关系也可以做Web3.0的探索。大多数情况下，企业相对员工都是处于优势的地位，因为企业掌握了更多的信息和数据。分布式自治组织（DAO）的概念最早由美国作家奥里·布莱福曼（Ori Brafman）在一本名为《海星和蜘蛛》的书中提出。他在书中将中心化组织比喻为蜘蛛，将分布式组织比喻为海星。</p><p></p><p>中心化组织在未来也不会消失，有复杂链路的业务很难通过去中心化的方式去开展工作。组织是人类社会的最有力的武器之一，有了组织，才能建立庞大复杂的工业体系，才能有登月这样的伟大创举。大型企业不太可能完全用分布式自组织的方式进行复杂的生产，但是对于一些新业务，企业可以用阿米巴敏捷小组模式，用DAO的理念进行探索。企业可以用对等价值交换的理念，评估创新业务中员工和企业资源在每个环节中的贡献，据此不断孵化出新的业务和组织形态。</p><p></p><p>在不涉及到企业敏感数据的时候，企业也可以探索在数据治理上企业与员工的关系。企业可能是一个员工消耗时间最多的场所，哪些数据应该归员工所有？员工在回顾过去经历的时候是否有完整的画像？没有工作中的数据，个人的虚拟印象是不完整的。</p><p></p><p>企业数字化的难点在于：组织的需求是抽象并且变化的，组织需要长期探索和打磨才能形成适合自己的方法论和体系。</p><p></p><p>Web2.0时代的共享平台跟Web3.0的区别</p><p></p><p>在Web2.0时代，也有很多平台与生态一起共享收益。例如很多电商平台除了自营业务，也有各类中小卖家；每个司机也是共享打车平台独立的“合伙人”，在各个平台之间进退自如；在内容创作平台上，创作者也可以获得平台的奖励。是不是这样的平台其实已经属于Web3.0时代了？</p><p></p><p>这些平台在价值分享上做到了一定的开放，但是大部分平台对分润的模式和算法并不公开透明；另外平台也没有考虑参与者的视角，创作者切换平台有很高的成本。在这点上，开源开放可以使得共享平台真正走向Web3.0时代。</p><p></p><p>一些激进的企业，也许可以通过完全开源的方式，比如开源代码、开放业务模式、开放财务数据、开放非敏感的业务数据，达到透明的信息披露，获得客户、员工和投资方更高的信任。例如开源公司Gitlab就把自己的员工手册和管理方式也开放在互联网上，这样全球远程协同的员工可以更好地融合。</p><p></p><p>个人非常期待能看到有开源社区能以Web3.0的方式组织起来，开源社区的运作和数据本身就比较公开透明，如果能把平台、代码贡献者、社区参与者和早期用户的贡献价值体现在项目中，不断地平衡过去、现在和未来参与者的贡献价值，最终将收益返还给所有贡献者。也许Web3.0的一个标志性事件，就是通过这样的方式打造成功的项目，并能在传统交易所上市，获得公众的认可。</p><p></p><p>Web3.0会是一个技术上的倒退么？</p><p></p><p>1980年代，只有巨头们拥有大型计算机，但是个人和普通企业很难消费得起。从大型计算机到PC时代，很多人认为是技术上的一个倒退。从各种各样的性能指标上来讲，当年的大型机和小型机都比个人电脑强大很多倍。但是如果时代还停留在大型机时代，那么互联网的兴起就变成不可能的事情。Web1.0时代也是到了后期，通过分布式的集群，云计算的算力才超过传统的大型机。</p><p></p><p>40年后的今天，只有大型互联网平台才有大量的数据，个人和普通企业只是数据的提供者，而无法充分利用数据时代的红利。今天大家都能轻松地购买电脑和手机，但是硬件不等于软件，软件不等于数据，数据不等于信息，信息不等于价值。很多个人和普通企业的数字化水平，还停留在封闭和碎片化的状态。</p><p></p><p>类似GDPR的法规，必然会对互联网平台在技术架构体系上产生各种约束，数据的收集、处理、应用和归档难度也大幅增加。Web3.0需要的分布式体系，在起步阶段的效率，可能不如集中式的Web2.0互联网平台。并且Web3.0时代需要的分布式体系，不仅仅是个分布式计算体系，不仅仅是上万个计算节点组成的云，不仅仅是一个大的分布式数据库，而是一个由很多个体和组织联合起来的，分布式、隐私、开源、信任和价值连接的复杂体系。</p><p></p><p>除了区块链的技术体系外，数字货币、电子合同、隐私计算、联邦身份管理账户体系、深网信息挖掘、个人数字管家、AI助理、应用平民化、全员的数字思维、联盟和上下游共生思维等，都是建立Web3.0体系的重要技术和文化基础。</p><p></p><p>也许在一段时间内，Web3.0体现出的技术水平没法超越Web2.0时代。不过通过Web3.0的建设，个体得以深度数字化，为Web4.0的到来提供了全面的数据基础。如果没有数据平等和对等价值交换的基础，到了Web4.0和Web5.0时代，还是互联网平台垄断一切，其副作用将不可想象。</p><p></p><p>延展思考</p><p></p><p>在Web3.0时代，怎样不被各种概念忽悠？&nbsp;</p><p></p><p></p><h3>Web4.0：AI+脑机接口，意识的交互</h3><p></p><p></p><p>AI的发展从量变到质变</p><p></p><p>世界上第一台通用计算机“ENIAC”于1946年在美国宾夕法尼亚大学诞生，在计算机诞生后不久，AI与人脑的较量就开始了。计算机科学和密码学的先驱阿兰·麦席森·图灵于1950年写了一篇论文《计算机器与智能》，文中预言了创造出具有智能的机器的可能性，提出了著名的图灵测试：如果一台机器能够与人类展开对话而不能被辨别出其机器身份，那么称这台机器具有智能。图灵测试是人工智能哲学方面第一个严肃的讨论。</p><p></p><p>在2006年之前学习AI的同学可能会感受到，无论用什么算法都很难满足通用场景。哪怕是现在看起来挺简单的车牌识别和人脸识别，当时都靠算法工程师调参的手艺，可能在一个特定的场景下可以工作，但是切换到另一个相似的场景就不能满足要求了。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/20/6a/20301a5c9a789efc3db103496dc5b36a.png\" /></p><p></p><p>在2006年加拿大多伦多大学教授Hinton提出深度学习的新思路后，人工智能的发展才开始进入快车道。随着互联网的发展提供了丰富的大数据资源以及GPU的硬件性能提升，AI的发展终于在2016年迎来了质变。2016年3月，Google旗下的AlphaGo在韩国首尔以总比分4比1的成绩战胜了围棋世界冠军、职业九段选手李世石。2017年5月，进化后的AlphaGo在“人机大战2.0”中，以3:0战胜世界排名第一的中国选手柯洁。</p><p></p><p>今天大家觉得AI还比较弱智，无论是家里的智能音箱，还是跟电商的AI客服对话，大家发现AI并不是真的懂自己，无法理解和回答你的很多个性化问题。</p><p></p><p>这背后的深层原因是现在的大数据积累都是从互联网平台视角出发的，而不是从个人用户视角出发的。</p><p></p><p>即使互联网平台拥有大量的数据，但其在个人的维度上是碎片化和不完整的。由于数据隐私问题，个人也不可能把自己的完整数据交给互联网平台。但是可以想象一下，如果个人的数字管家，拥有一个人一生的数字化的记录，比如收集记录一个人一生的视频，每个刺激、反馈和动作，每个阅读的内容和笔记，每一段对话和思考，那这样的数据足以训练AI读懂一个人。</p><p></p><p>如果Web3.0真的可以实现，可以想象，个人数字化水平会有飞跃的发展。随着技术的发展和进步，“个人数字化”的门槛会大幅降低，越来越多的个人数字画像会被完整记录，虚拟数字人也会越来越懂个人的需求。</p><p></p><p>大脑和AI的运作机理类似</p><p></p><p>科学家和工程师提升计算机的AI水平时，另外一条研究路线也取得了巨大进步，那就是对大脑运作机理的研究。最近读了一篇非常有意思的文章：<a href=\"https://mp.weixin.qq.com/s?__biz=MzI0MjI1NTgxNQ==&amp;mid=2651464591&amp;idx=1&amp;sn=866f8b7909aab8f62afe77c7a5423b87&amp;chksm=f2819127c5f618310402b58ef3101095d6143c71065ca41e306ccf864c3be833c3996727ccf7&amp;mpshare=1&amp;scene=21&amp;srcid=0704tynWJILAAWQAQ34qHeIb&amp;sharer_sharetime=1657071813866&amp;sharer_shareid=2eac5226898093eb5453fdbb71a89275&amp;version=4.0.8.6027&amp;platform=win#wechat_redirect\">《大脑中的熵、自由能、对称性和动力学》</a>\"。</p><p></p><p>人类的大脑在一定程度上是一个贝叶斯模型，生成内部的模型不断地预测和判断未来，然后将预测与感官输入不断对比，并通过反馈来校验更新内部的模型。从这个角度来看，现在的AI训练模式和大脑做的事情非常类似。以德州扑克为例，人类通过观察自己的起手牌、公共牌、对手的出牌行为和对手的过往历史记录，并结合当时对手的表情动作，来做出自己的下注及判断对手的下一步动作。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/ce/4e/cebda6392e8d4c3ayy00c5d722a78a4e.png\" /></p><p></p><p>德州扑克一直是人工智能领域最难攻克的问题之一，因为扑克对局涉及“隐藏信息”。你不知道对手的牌是什么，也不知道对手对你手牌Range的判断，要想在牌局中获胜，需要成功运用bluff 和其他多种策略。这些策略跟国际象棋、围棋等透明的对局不同，相比较而言，德州扑克面临的问题更像是真实人类社会生活工作中的真实场景，这使得德州扑克成为AI科学家们最感兴趣的领域之一。</p><p></p><p>在2015年就有德州扑克Solver的概念。与围棋领域的Alpha Go/Alpha Zero全自动AI算法相比，Solver更像是一个辅助的场外计算器，估算对方手牌的Range以及对方猜测你的手牌的Range。有了这个辅助计算器，人类可以降低计算的复杂度，而把更多的能量放在最终决策上。不过专业的Solver，因为计算量太大，很难在手机里完成实时的计算。</p><p></p><p>而类似Alpha Go的全自动德州扑克AI算法也取得了很大的成绩。Libratus在双人对决的比赛里获得了非常好的成绩，而Pluribus算法在六人游戏中表现出众，使用了深度学习算法的Deepstack和Poker CNN也取得了不错的成绩。</p><p></p><p>德州扑克游戏有一定的特殊性，牌局里有很多隐藏信息，参与的玩家也会受到情绪和体力的影响，牌局的走势有相当大的随机干扰。在德州扑克领域靠算法不能保证100%的胜率，AI可能不能完全战胜人类中最优秀的选手。但是如果一个AI能够记录一个人类选手历史上的所有数据，包括各类身体表情的数据，通过大量的训练，AI最终应该也能模拟出这个人类选手的出牌风格。在这种情况下训练出的AI虽然不一定每次都能跟模仿对象出一样的牌，但是从多轮牌局的统计维度上来看，应该能保持非常好的一致性。</p><p></p><p>另外人类大脑处理信息大概是在100ms以内完成的，如果AI也能在便携的计算设备里以相同或者更少的时间做出反馈，那么可以认为AI能够很好地模拟大脑的工作机制。人类的大脑毕竟不是个无限的信息容器，AI模拟人类在打德州扑克时的风格，应该很快能实现。</p><p></p><p>AI通过脑机接口读取人类意识</p><p></p><p>对大脑的研究除了通过输入和反馈，也需要对大脑的实体进行深度研究。其中脑机接口就是一项非常实用的技术。目前，大部分的脑机接口就只是对大脑进行读取信息的操作。</p><p></p><p>早在1857年，英国青年生理科学工作者卡通（R.Caton）就在猴脑上记录到了脑电活动，并发表了论文《脑灰质电现象的研究》。1924年，德国的精神病学家贝格尔（H.Berger）真正地记录到了人脑的脑电波，人的脑电图从此诞生了。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/49/c6/4971656bc2aebbd60c4ca3b08b0fd9c6.png\" /></p><p></p><p>20年前我做脑机接口研究的时候，脑电采集设备还不是很灵敏，为了提高灵敏度，实验人员甚至可能要剃光头并涂上导电胶体。常见的实验场景是，实验人员戴上脑电采集的电极帽，通过脑电信号和算法，控制屏幕上的鼠标达到指定的区域。在当年大多数公开的记录中，准确率只能达到75%，在这种情况下，要完成一个字符的输入可能要花上1分钟。</p><p></p><p>最近10年，脑机接口领域的发展突飞猛进。</p><p></p><p>2021年4月，脑机接口公司Neuralink发布了《Monkey MindPong》的Demo视频。一只猴子正在靠“意念”轻松地玩电脑游戏。在这个系统里，先是通过正常连接的摇杆来校准系统，然后用脑电的信号输出和算法来精准模拟有线摇杆的信号；系统校准后，即使是断开摇杆的连线，猴子也可以靠着脑电的信号输出来完成游戏。下面的Demo显示摇杆跟显示屏之间的连线已经断开了。不过Neuralink的脑机接口是一种侵入式的系统，需要通过手术将芯片植入到猴子的大脑中，然后通过USB－C接口读取大脑信号。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/e7/c7/e73ca784301621865bec30ce05f39ec7.png\" /></p><p></p><p>2021年5月，斯坦福大学、霍华德・休斯医学研究所（HHMI）和布朗大学等团队用脑机接口技术实现了瘫痪患者将脑中的“笔迹”转化成屏幕字句，并在Nature杂志发表论文《High-performance brain-to-text communication via handwriting》。他们将AI软件与脑机接口设备结合，利用大脑运动皮层的神经活动解码“手写”笔迹，并使用循环神经网络（RNN）解码方法，将笔迹实时翻译成文本，快速将患者对手写的想法转换为电脑屏幕上的文本。实验人员每分钟可以输入90个字符，接近正常人在智能手机上的打字速度，这个性能已经非常接近实用场景了，实现了AI读懂人类大脑中的表达。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/86/48/86yy56yy6f4c889644a9e844eb5ec448.png\" /></p><p></p><p>大脑中不断闪现想法，不一定每个想法都有语言的表达和身体的动作反馈，例如选手在德州牌局正式下注前的挣扎和思考，这些在隐藏层的意识活动对AI的训练也非常有价值。毕竟人类受到社会和环境的约束，很多想法是无法实现的，尤其是一些重大事件的决策，不是每件事都能下决心和落地的，人的一生做不了太多次重大决策。如果只是把最终表达出的语言和实际落地的行动作为AI训练的来源，样本量就会过少，就会遗漏掉那些人性最重要的部分，使得AI无法模拟人类在关键时刻的决策。</p><p></p><p>AI实现对大脑的模拟的3个方向</p><p></p><p>1.AI对抽象但是简单的概念进行识别，例如对图像、声音等的识别来模拟大脑的功能。</p><p></p><p>2.通过预测—反馈的不断测试和复杂的博弈场景，利用全面的个人数据，用AI来拟合人类对各种输入的反馈。</p><p></p><p>3.通过对脑机接口的研究，一方面深度挖掘大脑隐藏的工作机制和那些没能表达出来的想法，塑造更完整的AI；另一方面提供一个很好的人机交互方式，人类可以通过简单的方式表达自己的意识。</p><p></p><p>未来，也许人们会随身戴上便携式的脑电设备，用以训练属于自己的AI助理。无论是游戏还是汽车驾驶，都是非常适合迭代优化个人AI助理的场景。当AI助理足够了解你的时候，人们就可以复制多份AI助理，用来处理不同的工作，大家就应该可以把更多的时间放在家庭和休闲上了，这时候的AI助理应该称得上合格吧。</p><p></p><p>在Web4.0时代，可以实现意识的复制，意识在虚拟空间的交互，还有计算机对大脑意识的读取。</p><p></p><p>延展思考</p><p></p><p>在Web4.0时代，怎样保护自己的意识被合法使用？&nbsp;</p><p></p><p></p><h3>Web5.0：人机融合的时代</h3><p></p><p></p><p>也许大家觉得Web5.0的提法有些过于超前，不过很多Web5.0时代的技术，现在都已经在萌芽了。人机融合的定义，借用图灵测试的标准，就是无论是在网络的交流中，还是实际的交往中，已经分辨不出是机器还是人了。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/a7/bc/a75a9d967b06778bdeea41083352c8bc.png\" /></p><p></p><p>首先，我们从仿人机器人开始说起。</p><p></p><p>在人形机器人领域受关注度最高的玩家要属波士顿动力公司。2009年，波士顿动力的双足机器人Petman原型机亮相，此时它需要拖着电缆在履带上晃晃悠悠地行走。2013年，初具人类外形的Atlas原型机亮相，这时的Atlas已经能够在碎石堆上行走，还会“金鸡独立”，以及承受大摆球的撞击。这段视频发布两个月后，波士顿动力被谷歌母公司Alphabet收购。2017年，波士顿动力被日本软银集团收入囊中。易主并未影响到Atlas的快速成长，它的动作更加流畅，并且能够上台阶、后空翻等。随后几年里，Atlas学会了跑步、体操、翻滚、倒立、跳舞等技能。2021年6月，现代汽车集团与软银集团宣布，前者完成了对波士顿动力公司80%股权的收购。</p><p></p><p>另外一家是特斯拉。继2021年8月宣布特斯拉人形机器人（Tesla Bot）计划后，今年6月，马斯克在推特上表示，将在今年9月30日的特斯拉AI Day推出Tesla Bot原型机。特斯拉人形机器人被命名为Optimus（擎天柱），高1.72米，重56.6千克，与人类相仿，身体由特殊材料制成，内置特斯拉FSD（完全自动驾驶）芯片，并共用AI系统。根据特斯拉的计划，Optimus最早将于2023年开始生产。在马斯克看来，从传感器和执行器的角度来看，制造一个人形机器人是有可能的，目前所缺少的要素有两点——足够的智能和扩大的生产规模。</p><p></p><p>Web4.0的发展和积累刚好可以给机器人带来足够的智慧。如果AI机器人对外界的每一个刺激都能做出跟人类一样的动作和反应，那么在模拟人的方面就算是成功的。</p><p></p><p>但是机器人的结构与人类肯定会有天壤之别，以机械或者其他材料打造的机器人是无法模拟人类的血肉之躯的，也无法提供人类交流时需要获得的真实感受。也许听觉是第一个被AI机器人模拟成功的，然后视觉可以模拟一部分，但是像触觉、嗅觉、味觉等就很难模拟。正是因为这些难点的存在，所以AI机器人不能在打德州扑克时有爽朗的大笑，和Bluff后紧张的微表情。这些信息和感受对身边的人类来说同样重要。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/ea/4c/ea0d7cb5dcf6c2de8419ecd6c8de624c.png\" /></p><p></p><p>Web4.0阶段的脑机接口只是实现从大脑读取意识，但是在Web5.0阶段，脑机接口还需要实现给大脑写意识的功能，这样才能真正实现意识的互联互通。人类的大脑本身就是一个非常好的计算和仿真系统，是一个效率极高的元宇宙体系，私密而又有无穷的可能。在梦境里，人类可以把以前真实见过的、听说过的、想象过的各类场景和人物重新组合，模拟出全新的场景。这些组合也许符合现实的规律，也许可以超越现实的约束。只需要少量的输入刺激和引导信号，就可以让人类的大脑模拟出丰富的场景，类似“盗梦空间”的情景可能就不再是科幻了。</p><p></p><p>像触觉、嗅觉、味觉这些机器人很难模拟出来的反馈，也可以通过脑机接口输入的方式在人类大脑中产生类似的刺激。如果人类无法分辨这个刺激的来源是人类还是互联的机器AI，那么人机融合的“图灵测试”应该就可以被认为通过了吧。</p><p></p><p>延展思考</p><p></p><p>在Web5.0时代，肉身会被替代么？&nbsp;</p><p></p><p></p><h3>后Web5.0时代</h3><p></p><p></p><p>也许，“冷血”的区块链体系在人机融合的时代里可以大放异彩，能源和算力成了时代的硬通货。人类能进入Web3.0，打破互联网巨头的垄断么？人类在Web5.0时代，能与机器共存么？技术进步得越来越快，但是，人类的意识何去何从？人类的肉身何去何从？</p>",
    "publish_time": "2022-07-19 12:48:04",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "离开谷歌的副作用：外面很难找到这么好用的开发工具",
    "url": "https://www.infoq.cn/article/N67eM6HgLrDEqrp7tUlV",
    "summary": "<p></p><blockquote>离开谷歌之后，很难再享受到这些称手的开发工具了。</blockquote><p></p><p></p><p>博主 Beyang Liu 在多年以前曾在谷歌短暂任职，尽管时间不长，但谷歌内部工具还是给他留下了深刻的印象。在他看来，谷歌的内部开发工具在很多方面都堪称全球最强水平。谷歌不仅善于扩展自有软件系统，在探索如何高效大规模构建软件方面也一直号令群雄。谷歌以绝大部分其他公司无法企及的复杂程度，处理着海量代码库、代码可发现性、组织知识共享及多服务部署等现实难题。</p><p></p><p>但从另一方面来看，谷歌的内部工具其实数量不多，而且几乎都与谷歌内部环境紧密耦合。所以离开谷歌之后，很难再享受到这些称手的开发工具了。此外，在谷歌工作期间，大家已经习惯了谷歌内部的工作方式，离职后会有人感觉编程难度陡然提升，其实这也与大家失去了自己熟悉的工具有关。</p><p></p><p>Beyang Liu 结合自己和其他前谷歌员工的经验，总结出数个关于开发工具的使用心得，并编写出了这份谷歌以外的实用主义开发工具指南，帮助开发者设计开发工具常规路径，最终为自己和新团队探索出尽可能高效的工具。</p><p></p><h2>软件开发生命周期</h2><p></p><p></p><p>离开谷歌加入其他公司多少会让人有些沮丧，因为没有多少企业能在工作效率上跟谷歌相提并论。但具体区别到底体现在哪里？首先，我们应该考虑自己每天在做什么，然后确定这种沮丧情绪的来源。</p><p></p><p>有一点可以确定的是，无论是否在谷歌工作，软件开发生命周期的一般形式都差不多：</p><p></p><p>想到一个想要构建的功能，或者一个需要修复的bug。读了一大堆代码、设计文档，并向同事提问。通过这种方式，我们建立起对问题的理解，并明确了解决方案该如何大致适应现有系统。开始编写代码。开发的第一要务就是让编写出来的东西能跑。在此期间，我们可能会多次查找文档或者参阅更多原有代码。能运行的成果已经出来了，但还不能直接使用。代码成果通不过某些测试，所以需要先行修复。经过更多测试、完成了代码重构，再降低代码设计的理解门槛，接下来就可以把成果发布到分支上了。到这里，我们就可以等待CI运行了，还可以引入一些额外的修复和小改动。提交补丁以供审核。同事们当然会发表评论，我们再据此做出调整。在变更真正获批之前，这样的过程可能会反复几次。合并补丁并实际部署。现有监控系统将确定新补丁是否会引发生产问题。如果我们的补丁引发中断，我们自然有责任进行修复。在整个流程的各个阶段中，通常都会有一款工具来锚定开发者的实际体验。具体工具会塑造我们的工作周期，并对生产力产生巨大影响。</p><p></p><p></p><p></p><p>为了提高生产力，最好能在各个步骤中找到更好的工具。这里向大家推荐一个实用的GitHub repo，能够识别谷歌内部几乎每款工具所对应的最相似外部工具：<a href=\"https://github.com/jhuangtw/xg2xg\">https://github.com/jhuangtw/xg2xg</a>\"。</p><p></p><p>这份列表非常全面，但内容也确实太多了。那我们该从哪里入手呢？</p><p></p><h2>第一个月：别急着引入新工具，先熟悉现有工具</h2><p></p><p></p><p>离开谷歌之后，在新公司入职的第一个月，先别急着做出改变，多听、多学习。</p><p></p><p>作为团队的新成员，大家还没有足够的影响力或者权限来变更团队使用的各种工具。另外，我们也缺乏实践知识，比如不清楚新团队如何工作、为何选择这种工作方式、为什么要使用当前工具集。</p><p></p><p>如果你简单地把谷歌内部工具复制过来，并不一定就能在新团队中实现良好效果。因此，你需要先摸索一下哪些工具适合新团队使用，哪些并不适用。</p><p></p><h4>从代码搜索起步</h4><p></p><p></p><p>大家可以先从代码搜索起步。事实上，当一个程序员离开谷歌之后，他最怀念的往往就是代码搜索工具。</p><p></p><p>你可以自己尝试不同的代码搜索引擎，验证它们究竟效果如何，并在确定有效后再向同事推荐。千万别急着把自己都不熟悉的工具推荐给同事，或者提交给决策者进行审查。</p><p></p><p>同时，你也不必改变他人的原有工作习惯，毕竟新团队往往还没有用上代码搜索工具。即使已经在用，也就是分两种情况：比较差的情况是，他们选的工具效果一般、使用频率不高；比较好的情况是，他们选的工具已经非常出色，不用再费心。</p><p></p><p>如果你所在的新公司旗下拥有多支开发团队，那么需要处理的代码可能更多，作为新员工当然有必要去理解这些代码。而即使是在小而精的初创公司，也有可能通过依赖项的方式引入了大量开源代码。只有深入研究了这些代码，我们才能进行后面的新功能构建或关键bug跟踪等工作。</p><p></p><p>如今，几乎每位开发者都必须面对庞大的代码规模，所以如果代码搜索工具跟不上，绝对会大大降低你的开发速度。</p><p></p><p>在评估代码搜索引擎时，我们需要考虑以下几个重点：</p><p></p><p>查询语言：正则表达式是关键。我们需要保证代码搜索查询语言既富有表现力，又简单易用。字面搜索应该更直观，而且提供更高级的模式匹配功能。规模：确保代码搜索引擎的规模适应性能够匹配你的代码库大小。如果你的代码库超过数GB，那么代码搜索引擎是否支持三元组索引（<a href=\"https://swtch.com/~rsc/regexp/regexp4.html\">https://swtch.com/~rsc/regexp/regexp4.html</a>\"）就非常重要了，这也是我们以常规方式在大型代码库上实现表达式匹配的唯一方法。代码浏览：作为谷歌代码搜索（Code Search）的用户，大家都知道搜索本身只是故事的一半。单击结果之后，我们当然希望能够继续点击、跳转至相应定义并找到引用部分，整个过程应该像签出代码并在IDE中设置开发环境一样轻松。如果没有出色的代码浏览体验作基础，我们就得经常在编辑器和代码搜索引擎之间来回切换。权限：如果你所在的公司强制推行代码库权限，那就应该考虑代码搜索引擎是否支持这些权限。总体成本：需要同时考虑代码搜索引擎的价格，与保持工具运行的维护开销。以下是我们平时常见的代码搜索引擎：<a href=\"https://oracle.github.io/opengrok/\">OpenGrok</a>\": 一款相当古老、但仍具生命力的代码搜索引擎，现由甲骨文负责维护。<a href=\"https://github.com/hound-search/hound\">Hound</a>\": 一款由Etsy工程师创建并开源的代码搜索引擎。<a href=\"https://livegrep.com/search/linux\">Livegrep</a>\": 一款由Stripe公司Nelson Elhage创建的代码搜索引擎。当然，还有我们自己开发的Sourcegraph。</p><p></p><h4>那些好用的监控工具</h4><p></p><p></p><p>另一个重要的早期目标，就是监控。每位工程师在特定情况下都需要处理生产问题。请注意，生产环境跟开发环境完全是两码事，我们不可能在生产环境下设置断点或添加printf，并指望在几秒内就看到结果。另外，生产环境的更新对应着极高成本：计算资源、开发者时间，还有可能给客户带来的糟糕体验。</p><p></p><p>过去5到10年来，部署思路发生了很大变化。微服务、Kubernetes、云迁移等一系列新生事物，都标志着企业软件部署方式上的重大转变。不少企业开始采用这些新的范式和技术，但并没有更新自己的监控基础设施，所以很难在新型生产环境下开展调试。</p><p></p><p>幸运的是，近年来涌现出一些伟大的开源工具和厂商，他们用努力极大改善了谷歌之外的监控与可观察性工具选项。</p><p></p><p><a href=\"https://prometheus.io/\">Prometheus</a>\"&nbsp;是一款类似于Borgmon的时间序列指标跟踪器兼可视化器。它能帮助大家检测自己的应用程序，随时间推移持续跟踪CPU利用率、错误率及90百分位延迟等指标。<a href=\"https://grafana.com/\">Grafana</a>\"是一款类似于Viceroy的仪表板工具。大家经常会将Grafana与Prometheus匹配起来，由此构建起包含一系列关键指标的单页视图，根据这些指标了解应用程序的整体健康状况。谷歌率先使用了Dapper这一面向多服务架构的重要分布式跟踪工具。Dapper的缔造者之一Ben Sigelman随后又打造出Lightstep。分布式跟踪现已成为众多监控系统中的一项功能，包括Honeycomb&nbsp;和&nbsp;<a href=\"https://sentry.io/\">Sentry</a>\"这类付费产品，以及由Uber工程师开发的Jaeger等开源项目。监控要比代码搜索更复杂一些，因为其必须要集成到生产环境当中。这往往涉及更改部署环境，所以必须要跟负责控制部署环境的团队协调并配合。另外，其中还可能涉及添加检测代码，也就是向持有被检测代码的各团队提交补丁。</p><p></p><p>但总体来讲，引入新工具并不需要改变其他同事的原有工作习惯，所以难度不算太高。人们可以自由选择使用或不使用新工具，所以前期推广压力不会太大。</p><p></p><h2>首战告捷之后：代码审查</h2><p></p><p></p><p>代码搜索和监控的引入，并不会影响到任何团队成员的现有工作流程。但代码审查工具却不一样，它会实实在在影响到同事们的工作方式。</p><p></p><p>如果大家在谷歌工作过一段时间，那么离开谷歌后可能会觉得外面的代码审查方式有点奇怪。GitHub PR就是最常见的代码审查工具，但谷歌员工还是能从中发现不少问题：</p><p></p><p>不太容易查看自上一轮审查之后出现的变更，有时候甚至根本查看不到。简单的路径只允许我们查看尚未完成部分的差异。不支持堆叠CR。变更页面是把所有文件中的全部差异都集中在一起，很难弄清我们面对的到底是哪个具体部分。GitHub PR并没有设计出明确的审查路径。如果不添加额外的第三方集成，整个审查流程会显得非常松散。而即使有了第三方集成，其中仍然缺乏细粒度的审查与签署政策。对于某些语言，GitHub PR对模糊跳转至某定义或查找引用的支持效果很差，完全不能跟谷歌内部的Critique相提并论。在谷歌之外，我们能找到的跟Critique最接近的工具当数Gerrit了。Gerrit最初属于Rietveld的一个分支，而Rietveld本身又是谷歌原始代码审查工具Mondrian的一个开源分支。因此，正是这种血脉传承让人们在Gerrit身上感受到了谷歌眼中的代码审查思路。</p><p></p><p>Phabricator也是一款不错的代码审查工具，反正对前谷歌员工来说要比GitHub PR强不少。Phabricator最初是Facebook的内部代码审查工具，随后被开源了出来。它的背后由Phacility公司负责运营，为其提供托管实例和支持，能为那些不愿自行维护实例的客户分担压力。</p><p></p><p>另一款值得关注的工具，则是由前谷歌员工Piotr Kaminski开发的Reviewable。与Gerrit或者Phabriactor不同，Reviewable只支持云环境，但换来的则是最接近于谷歌内部的代码审查体验。</p><p></p><p>在向团队其他成员介绍Gerrit、Phabricator或者Reviewable的优点时，请务必关注大家对于原有代码审查工具的感受。从GitHub PR等转向Gerrit之类的工具，可以有效解决以下几大常见痛点：</p><p></p><p>Gerrit能够明确的签署机制，让审查流程的结构化水平更上一层楼。如果团队规模正在不断扩大，而且希望在组织内实施更严格的审查政策，那Gerrit绝对物有所值。Gerrit能够简化大规模差异的审查难度，允许我们逐一文件查看、查看自上轮审查以来的变更以及堆叠CR，最终实现更快、更彻底的审查效果。Gerrit、Phabricator和Reviewable都能让大家朝着谷歌内部的常规审查流程更进一步，但仍然缺失重要一环：代码智能。Sourcegraph浏览器的扩展能够在代码审查期间提供工具提示、跳转至定义和交叉引用等，它适用于GitHub PR、GitLab MR、Phabricator以及Bitbucket Server，对Gerrit的支持也正在开发当中。</p><p></p><h2>是时候迈出最终一步了</h2><p></p><p></p><p>软件开发生命周期当中，最棘手的部分往往就是CI和build系统。这是因为要想理解整个build，就必须以非常具体的方式观察整个代码库的每一部分。随着时间推移，大家都希望加快构建速度，所以build代码也就积累了越来越多的调整和优化部分，导致投入大量人手也未必能实现无痛更新。</p><p></p><p>简而言之，build系统就是最后的守关Boss，所以在完成前面的“打怪升级”积累之前，千万不要轻易尝试。但它又时刻在诱惑在我们，毕竟跟现有工具相比，Blaze实在是太强大了。谷歌甚至以Bazel的名号对Blaze进行了开源。但Bazel毕竟不是Blaze，它缺少大规模分布式build集群，而且毕竟不是运行在谷歌内部。</p><p></p><p>所以先要承认，Bazel绝不是什么万金油。当初刚刚发布时，Go社区中就有很多开源项目转用它来支持标准Go build工具。但不到一年，由于使用太过复杂、Go社区内很多成员对它不够熟悉，以及Bazel的构建速度似乎更慢等现实，大家又纷纷选择放弃。从那时起，Bazel对Go语言的支持虽然实现了重大改进，但还是建议大家在使用之前认真做一番评估。</p><p></p><p>为了开展这项严格评估，我们先得把其他开发工具落实到位：包括出色的代码搜索，确保真正深入到代码库中各部分的build脚本当中，理解它们的作用和依赖关系。大家还需要出色的代码审查工具，确保build系统的变更能够在不同工程团队之间获得支持和协同。</p><p></p><p>在做好准备之后，还要明确一点。除Bazel之外，还有很多其他build工具能够在大型代码库中实现可扩展构建。具体包括：</p><p></p><p><a href=\"https://buck.build/\">Buck</a>\", 来自Facebook。<a href=\"https://gradle.org/\">Gradle</a>\", 在Java世界中很受欢迎。<a href=\"https://www.pantsbuild.org/\">Pants</a>\", 由前谷歌员工为Twitter和Foursquare所设计。<a href=\"https://please.build/\">Please</a>\",&nbsp;一款新型build工具，由前谷歌员工受Blaze启发创建而成。还有&nbsp;YourBase，它虽然不属于build工具，而是由前谷歌员工Yves Junqueira开发的CI服务，但确实能够提供超快且可扩展的构建体验，而且完全独立于实际底层build工具之外。谷歌拥有着不同于大多数其他公司的企业文化，包括优先考虑开发者体验的强大工具储备。谷歌前员工们曾经感受过这些最先进的开发工具，所以永远忘不掉这段能够充分发挥自身天赋和能力的经历。</p><p></p><p>在离开谷歌之后，大家的一大竞争优势，就是利用这些经历将出色的开发体验融入新的组织，借此提高自己和其他团队成员的工作效率。配合上述大规模软件开发最佳实践，各位完全可以将谷歌那极高的工程组织协同能力转化为新公司的底层实力。</p><p></p><p>大规模软件的构建过程相当复杂。有经验的朋友都知道，单靠堆人手是无法获得更好的软件的，我们还需要更好的工具。正如优秀的软件会成为最终用户的生产力放大器，出色的开发工具也是软件开发者的生产力放大器。因此，如果大家愿意作新公司的主人翁，不妨利用自己前谷歌员工的专业知识，将世界一流的开发者工具引入这片全新的天地。</p><p></p><p>原文链接：</p><p></p><p><a href=\"https://about.sourcegraph.com/blog/ex-googler-guide-dev-tools\">https://about.sourcegraph.com/blog/ex-googler-guide-dev-tools</a>\"</p>",
    "publish_time": "2022-07-19 14:56:09",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "旷视逐梦AIoT",
    "url": "https://www.infoq.cn/article/JNufVBHQ2hHBVrjrePSy",
    "summary": "<p></p><p></p><blockquote>成立11年来，AIoT一直是旷视核心的战略关键词。</blockquote><p></p><p></p><h2>AIoT战略与“2+1”的核心技术科研体系</h2><p></p><p></p><p>7月15日，在2022旷视技术开放日（MegTech 2022）上，旷视联合创始人、CEO印奇阐述了旷视的AIoT战略及“2+1”的核心技术科研体系。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/6c/4a/6cc9366484c401d8bd6d5ae1ecbce14a.png\" /></p><p></p><p>印奇表示，AIoT是旷视过去11年里最核心的主旋律。</p><p></p><p>旷视将AIoT定义为，“AIoT=AI+IoT+空间”。其中，“AI”和“IoT”是两个相辅相成的核心关键词。AI是不断演进的算法能力，如今越来越多的AI算法正在各行各业发挥核心价值；IoT是软硬结合的设备载体，只有在特定的载体中，AI才能最大限度地释放其价值。</p><p></p><p>在此基础上，旷视还强调“空间”这一关键词，提出空间是应用场景的闭环。在过去二三十年，互联网、5G、AR、VR等技术的不断演进，给虚拟世界带来了翻天覆地的变化。但与此同时，技术对于物理世界的改造并没有发生根本性的变化。印奇认为，AIoT从业者要更好地改变物理世界。</p><p></p><p>为了支撑AIoT这一长期发展战略，旷视构建了“2+1”的AIoT核心技术科研体系，即以“基础算法科研”和“规模算法量产”为两大核心的AI技术体系，和以“计算摄影学”为核心的“算法定义硬件”IoT技术体系（包括AI传感器和AI机器人）。</p><p></p><p>印奇表示，AI为“本”，是旷视一直坚持的核心能力，它包括两个核心要素 —&nbsp;基础算法科研和规模算法量产，因为从基础的科研创新到把AI推向规模化的市场，要用算法量产，用系统化的方式来解决AI算法的生产问题；IoT为“器”，其是实现AI规模化落地的硬件载体，算法定义硬件是IoT的核心要素。</p><p></p><p>这一整套科研战略体系，涵盖了从基础研究、算法生产到软硬一体化产品的AI落地全链路。印奇认为，“2+1”的AIoT科研战略体系，是支撑旷视未来不断走向AIoT商业化成功的重要基石，这也将会是旷视未来十年、二十年会不断坚持的科研方向。</p><p></p><p>印奇最后强调，“科研实力和竞争力，最终都将回归到人。‘技术信仰、价值务实’是旷视的科研人才观，技术创新需要大量试错，需要长期坐冷板凳，这要求技术人一定要有技术信仰，才能长期坚持下去。“价值务实”是指，要做真正可以“Work”的科研，本质上希望通过产品让科研成果创造价值。</p><p></p><h2>旷视的核心技术能力如何支撑AIoT战略？</h2><p></p><p></p><p>AIoT是旷视相对长期的业务战略方向和商业战略方向。那么，旷视的核心技术能力如何支撑AIoT战略？本次MegTech分别从基础科研、算法量产、算法定义传感器等三个方面作了详细阐述。</p><p></p><h3>视觉AI基础研究的新趋势：走向“大”和“统一”</h3><p></p><p></p><p>基础模型科研是AI创新突破的根基。</p><p></p><p>在2012年AlexNet被提出之后，基于深度学习的神经网络成为AI视觉发展的主要原动力之一。神经网络根据用途、构建方式的不同，大致可以分为CNN、Transformer、基于自动化神经网络架构搜索的模型以及轻量化模型等。这些模型极大地推动了AI发展的历史进程。</p><p></p><p>当时间来到2022年，旷视认为，“大”和“统一”已经成为视觉AI基础研究的最新趋势。</p><p></p><p>其中，“大”主要是指AI大模型，即利用大数据、大算力和大参数量，提高模型的表达能力，使得AI模型能够适用于多种任务、多种数据和多种应用场景。</p><p></p><p>旷视研究院基础科研负责人张祥雨认为，“大”是提高AI系统性能的重要捷径之一。但是**，大并不意味好，片面地追求大参数量、大计算量和大数据量，并不一定能够实现更强大的模型，反而会产生更大的计算开销，令整体收益非常有限。**</p><p></p><p>基于这一行业洞察，旷视将其关于“大”的研究进行了更加精细的划分。首先在大模型方面，旷视的研究不仅着眼于如何实现“大”，而是将会聚焦于如何充分发挥大模型背后的威力；其次在大算法方面，如果利用创新的算法将大模型的作用最大化，也将会是旷视未来重点关注的；最后在大应用方面，将重点解决大模型生成后如何进行合力的应用，提升AI模型性能。</p><p></p><p>同时，AI视觉的研究领域众多，包括CNNs、VL&nbsp;Models、 Transformers等基础模型研发，物体检测、分割等视觉基础应用，优化、自监督、半监督等AI算法演化等。每个研究路径，都会衍生出一系列算法。</p><p></p><p>旷视通过研究发现，这些算法在底层正在走向统一。通过统一的算法、模型来表示和建模各种数据、任务，将产生更加简单、强大且通用的系统。 旷视借助特定的优化算法，通过在训练过程中增加先验的方式，使得CNNs、VL Models、 Transformers都取得相似的性能，为旷视“统一”AI系统设计打下基础。</p><p></p><p>围绕“统一”的趋势，旷视在“基础模型架构”、“算法”和“认知”，进行了全面布局。旷视基础科研的“统一”，集中体现在统一各种基础模型架构，从纷繁的AI算法中提炼其本质特性，使其能支持各种任务、数据和平台，并最终构建统一的、高性能的视觉AI系统。</p><p></p><p>围绕“大”和“统一”的研究趋势，旷视基础模型科研聚焦于通用图像大模型、视频理解大模型、计算摄影大模型和自动驾驶感知大模型四个方向，并取得了多项科研成果。比如，在通用大模型方面，旷视提出了一种基于大Kernel的CNN和MLP设计范式。在自动驾驶感知大模型方面，旷视新提出了BEVDepth；去年，旷视提出了简单通用的目标检测框架YOLOX。</p><p></p><p>张祥雨强调，基础模型科研需要坚持长期主义，旷视将以原创、实用和本质作为基础科研的指导原则，解决人工智能最本质的难题。</p><p></p><h3>发布自研算法生产平台AIS，算法量产是实现AI落地的有效途径</h3><p></p><p></p><p>旷视研究院算法量产负责人周而进总结了过去十多年在算法生产和应用落地过程中的实践经验。旷视认为，在推动算法在各行各业的实际场景落地的过程中，落地实用是算法价值的最终检验标准。</p><p></p><p>算法生产的过程并不是模型训练这么简单的一个环节，为了让模型算法能够解决实际问题，它包含了需求分析，数据处理，模型训练，上线部署，到最后的应用落地。同时，在这个环节中可能需要反复多轮的算法打磨。这整个过程才真正是一个完整的算法生产的过程。</p><p></p><p>基于多年实践经验，周而进认为算法生产的主要困难集中在整个生产环节的复杂性上。具体来说，可以分为三个方面：第一，数据生产的复杂性。第二，算法模型本身的不确定性。第三，算法落地的AIoT硬件平台多样性也带来了整个生产过程的复杂和高成本。</p><p></p><p>面对如此复杂的挑战，他认为“算法生产过程的标准化，是解决复杂的、碎片化的算法生产的有效手段”。这个标准化过程，包括了数据生产的标准化、算法模型的标准化和推理框架的标准化。</p><p></p><p>为此，旷视在本次技术开放日上发布了自研的算法生产平台AIS（AI&nbsp;Service）。AIS基于旷视Brain++体系，构建了一套覆盖数据处理、模型训练、性能分析调优、推理部署测试等算法生产全链路的零代码、自动化的生产力工具平台。AIS承载着旷视实现“算法量产”的小目标。</p><p></p><p>周而进以生产安全场景的火焰检测算法生产为例，介绍了旷视AIS平台的工作全流程。通过标准化的数据处理，自动完成去重去花屏，用基于机器学习的人机交互数据标注系统，提升超过30倍的标注效率。此外，基于旷视10余年一线算法落地中积累的海量模型储备，自动化地适配合适的模型并自动化完成模型的训练和诊断，实现标准化的模型生产。最后，通过解耦的工具链自动完成硬件部署，有效化解算法在生产中的复杂性，大大降低算法的生产门槛。</p><p></p><p>据介绍，旷视 AIS 算法生产平台提供多种功能支持算法快速生产部署，可大幅降低算法生产的门槛，提升算法生产效率。目前，AIS平台已经能够支持100多种业务模型训练，最快2小时即可完成，且模型产出精度指标远高于业界平均水平。经验证，算法研发人员使用Brain++和AIS平台，可以实现智能标注平均加速30倍，自动学习训练加速4至20倍。</p><p></p><p>周而进表示，AIS的理念很简单，就是希望用越来越多的算法来代替人工的分析，用更多的算力和搜索来代替人工的规则，用机器的生成来代替人工的生产。</p><p></p><p>随着AI算法在越来越多的行业领域里逐步深化，行业对于AI算法的需求也呈现出碎片化、个性化特征。面向广阔又碎片化的产业场景，算法量产是实现AI落地的有效途径。</p><p></p><p>周而进强调，算法量产不是单一的产品，而是对AI生产模式的理念革新和生产力进化。 旷视希望通过AI算法生产的标准化以及AI生产力平台的构建，极大地降低算法生产的成本和门槛，让更多人可以参与进来，促进算法在更多行业的落地。</p><p></p><h3>AI传感器是“算法定义硬件”的核心单元</h3><p></p><p></p><p>市场数据显示，AIoT行业中AI渗透率仅为4%，还有约96%的场景没有被AI渗透（2021年数据），这是源于AIoT行业具有大量的碎片化场景，而这些海量的碎片化场景存在数据采集难、算法复用度低的问题，导致企业很难针对每一个场景进行硬件和算法的定制适配。</p><p></p><p>同时，算法本身也对于硬件应该提供怎样的信息和输入提出了要求，甚至从根本上改造了硬件的形态与样式。</p><p></p><p>在此情况下，“算法定义硬件”通过海量算法+一定数量的通用型/标准硬件，成为AIoT市场的解决之道。</p><p></p><p>旷视研究院计算摄影负责人范浩强以AI传感器为例，分享了旷视在“算法定义硬件”方面的最新思考与进展。</p><p></p><p>他认为，随着AI、视觉算法等领域的发展，传感器将不再单独的、直接地提供应用价值，传感器和应用之间需要算法来作为承上启下的桥梁。从技术角度讲，这两者最显著的结合点就是计算摄影。</p><p></p><p>范浩强以手机拍照在灯光、月光、星光等不同环境下成像能力的提升为例，介绍了在AI算法和传感器的协同工作下，手机拍照画质如何发生了显著变化。旷视已参与手机影像的能力提升中，目前旷视的4K级别的硬件方案已实现量产，并正在推动8K“AI画质”硬件方案的研发与产品化。此外，在非成像的屏下光学指纹方面，算法也在牵引传感技术向前发展。</p><p></p><p>范浩强认为，“应用-算法-传感器”的全链路整合能力，是“算法定义硬件”的核心。</p><p></p><p>这具体来说，在传感器上需要有光学、模组、电子学的设计能力；在算法上，需要搞定深度学习，对传感器的物理建模、模型优化具有专业能力；更重要的是在应用层上，需要懂需求、能够完成产品定义和功能交付。旷视目前已实现将传感器的光学、模组、电子学的设计能力，传感器的物理建模和算法能力，以及传感器的应用能力融为一体。该能力已在非成像的屏下光学指纹领域获得验证。</p><p></p><h3>发布20个技术Demo</h3><p></p><p></p><p>在今年的旷视技术开放日上，旷视发布了20个技术Demo，VR裸手交互、自然语言生成3D人物、手绘人物转动画、基于神经网络的3D重建、3D建模仿真检测等。这些技术Demo反映了旷视在前沿技术探索、软硬件协同设计、算法量产应用，以及商业化产品落地方面的最新成果。</p>",
    "publish_time": "2022-07-19 16:35:41",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "下一代负载均衡的思考与实践",
    "url": "https://www.infoq.cn/article/45lSR8NaqzAVBOlKlrTV",
    "summary": "<p>当下，Web 3.0大火，各种炒币、非同质化代币、元宇宙等应用模式纷纷粉墨登场。这些场景有一个共同的点就是——上”链”（这里所说都是指公链。我个人认为联盟链都是假的，巨头的跑马圈地，最多就是 Web 2.0重来一遍。只有公链才是真的，所有场景都值得重塑一遍）。上”链”有一点难度的，一是因为应用场景可能受政治因素影响，另外一个是技术也是影响场景落地的一个关键要素。</p><p></p><p>我认为技术关键点可能有三个，计算、存储和网络。这其中，又以网络因素影响最大。为什么呢？无限计算和存储的基础是通过网络连接构成一个”超级计算机”，使其拥有海量算力和存储。所以如何提高网络”力量”是根本，如何无”墙”连接？如何提速？如何合理流量调度？都是需要我们解决的问题。今天，咱们来一起聊下网络的流量调度，这时候就不得不提网络流量大闸——负载均衡。</p><p></p><h3>一. 背景与现状</h3><p></p><p></p><p>主流的负载均衡器有很多，大致分为两类，商业和开源。商业负载均衡代表产品有F5和A10，它们的典型特征是运行稳定，功能齐全，但价格偏高，性能有限。例如F5中端产品 配置4core CPU-32G mem-1G net bandwidth的，应对如今的互联网的海量数据转发场景，根本无法应对。价格又偏高，低端BIG-IP I2000系列是25万+，中端BGP-IP i4000系列是45万+。性价比极低。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4f/4fa446d46216f24f115e8782f98419eb.png\" /></p><p></p><p>开源负载均衡又可以分为两类，一类是成熟的开源负载均衡，例如Nginx、Haproxy等。典型特征是功能基本满足，灵活，但缺少vip管理，热加载功能会造成业务抖动，配置数据基于文件存储，管理困难，对于企业级应用，不成熟。另一类是新兴开源负载均衡，例如iqiyi dpvs、openELB和metaLB等，特点是要么架构复杂，依赖特别多，dpvs是典型代表。或者，社区不活跃，维护比较困难，有问题基本靠自己解决，难上加难。</p><p></p><p>综述，我们是否能有一个负载均衡器？它是一种全新设计模式的，分布式的，性能强的，云原生的，它是为未来海量流量调度而生的。它能充分解决上述问题，设计简单，成本低又易用？——是的，是有的，那就是负载均衡器-合页（Parasaus）。&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/85/853a44281f45f509f6fa8ee78eed9dd5.png\" /></p><p></p><h3>二. 原理：设计架构与实现特性</h3><p></p><p></p><p>合页（Parasaus）按照数据面和控制面分离的架构而设计，数据面只负责数据转发，控制面负责watch条目的变化、管理员的增删改查及节点探活，架构简单清晰。</p><p>数据面的流量转发节点无状态，支持横向扩展，最多支持254个节点。流量转发基于lvs实现，流量转发在内核态完成，性能优异，非常高效。整个负载均衡维护一个ip地址池和端口池，容量有35000个地址。可以为每个服务都创建一个连接地址。控制面比较轻量，功能简洁，circle-watch模块观察到条目变化，触发一个hook，在circle-healthcheck添加探活条目，用以及时监测到服务是否可用。circle-healthcheck探测到有不可用服务条目或服务恢复条目时，触发一个hook，在数据面对转发流量进行调整，使流量能全部转发到所有服务健康节点上。服务健康检查方式支持三种，分别是L7 http、L4 tcp、mysql。支持容器部署，产生的元数据存储到etcd中，易于管理，并保证高可用。数据面的实现借鉴了Kubernetes Service的架构，支持多种负载均衡策略，例如RR、LC、WLC、WRR、Source Hash等。配置的增删改均支持热加载，即使是业务高峰期，对业务也是零影响。硬件均采用普通x86服务器，无需任何特殊配置（例如dpvs的dpdk驱动）或硬件，成本极低。自主可控，支持信创。管理接口支持多种方式，例如接口、Yaml文件和Dashboard界面，简单易操作。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/68/68fc9aaf9bf363b1cc64a0fd7930753b.png\" /></p><p></p><h3>三. 应用场景：为云原生而生</h3><p></p><p></p><p>场景1：完全云原生，是Cloud-Native，更是Kubernetes-Native的，可大幅缩短通讯链路，有效降低延迟。举例：在传统场景中，K8S中pod应用对外部服务的访问必须流出容器集群虚拟网络而进入数据中心物理网络，每次进出其他子网和经过转发节点（例如DNS、负载均衡等），都会耗费时间，且增加故障域，如下：&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/62/62226c569b91c84eb11c527ef73e249b.png\" /></p><p></p><p>在新场景中，借助合页（(Parasaus）的强大功能，可实现流量转发操作全部在一个区域内完成。针对以上案例，负载均衡和探活功能由合页完成，且是在容器集群内全部完成，大大缩短链路和减少故障域。&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c8/c8c9868ad83485112b732b2af89db84a.png\" /></p><p></p><p>场景2：在数据中心内进行流量调度，用作于基础设施底层的一环，将流量在南-北向和东-西向进行合理分配。&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/15/155ac3c12bc0b2cf27affd4cb5cbd580.png\" /></p><p></p><h3>四. 优势表现</h3><p></p><p></p><p>性能：</p><p>我们针对当前比较主流的负载均衡开源产品进行了比较和测试，相较于Nginx、Haproxy，合页(Parasaus)性能表现更好。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e5/e5b0bb7b0ad439d15d2ebacd513dc3b0.png\" /></p><p>&nbsp;</p><p>2. 稳定性：</p><p>因为合页((Parasaus)负载均衡是完全分布式的，网络流量是从交换机上通过等价路由完全均匀转发的。发生故障时，可以在10秒内完成故障转移，所以SLA是非常有保证的。</p><p>3. 成本：</p><p>在合页((Parasaus)作为云原生负载均衡的场景中，合页是作为一个应用运行在云中（1-3个pod），基本等同于免费。毋庸置疑，肯定比云上的任何一个负载均衡成本都低。hw负载均衡 &gt;0.32元/小时，tencent 负载均衡 &gt;0.788元/小时，ali 负载均衡 &gt;0.1+0.02*GB 元/小时（计算价格像是双11的网购，需要有奥数的本领）。</p><p>另外一个场景，合页(Parasaus)作为一台标准负载均衡，只需要三台服务器，估计10w左右，便可获得拥有海量数据转发的能力。比任何一种商业负载均衡价格都低。</p><p></p><h3>五. 使用方式</h3><p></p><p></p><p>目前合页(Parasaus)负载均衡支持三种方式，分别是Dashboard ﻿页面、Yaml文件和API接口方式，使用方便，对开发人员和运维人员都很友好。举例：</p><p>Dashboard ﻿页面方式：&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a5/a5512d7d965b461a2ea44752f55aadc2.png\" /></p><p></p><p>Yaml文件方式：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ca/ca53fb6fe263ec0a2468f129e74ceff0.png\" /></p><p></p><h3>六. 关于合页﻿（Parasaus）</h3><p></p><p>合页（Parasaus）是 NextArch 基金会孵化的首个面向企业级生产就绪的下一代云原生分布式负载均衡开源项目。旨在为企业级用户提供多元、复杂化的使用场景，如数据中心、边缘、虚拟化/容器等场景，具有高安全性和稳定性、易部署和易运维可扩展等优点。</p><p></p><p>最后，希望有兴趣的同学关注和使用合页﻿（Parasaus）G﻿i﻿t﻿h﻿u﻿b﻿加入社区，共同成长。</p><p></p><p>G﻿i﻿t﻿h﻿u﻿b﻿地址：https://github.com/Dinosaur-Park/heyelb</p>",
    "publish_time": "2022-07-19 18:13:08",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "2022开放原子全球开源峰会即将在京举办",
    "url": "https://www.infoq.cn/article/1pR0HTQBQPe3Z95CKRum",
    "summary": "<p>7月19日，2022开放原子全球开源峰会新闻通气会在北京经开区国家信创园会议中心举行，宣布本届峰会于7月25-29日在北京举办。北京市经济和信息化局信息化与软件服务业处处长尤靖、北京经济技术开发区管委会副主任刘力、开放原子开源基金会秘书长孙文龙等共同出席，介绍大会背景、内容设置、特色亮点、筹备进展等情况并答记者问。</p><p></p><p>2022 开放原子全球开源峰会由开放原子开源基金会、北京市经济和信息化局、北京经济技术开发区管理委员会联合承办。以“软件定义世界，开源共筑未来”为主题，设置了开幕式及主论坛、十余个分论坛及活动，精心筹备“源博荟”开源长廊、基金会捐赠人授牌仪式、年度开源贡献之星揭晓仪式等活动，以立足中国、面向世界的姿态，推动全球开源事业的交流合作。</p><p></p><h2>构建数字技术创新生态，打造国际开源社区</h2><p></p><p></p><p>北京市经济和信息化局信息化与软件服务业处处长尤靖在通气会上指出，党中央、国务院高度重视数字经济发展。进入数字经济时代，开源模式的重要价值日渐凸显，已经成为数字经济的基础设施与底座。北京市积极推动开源产业发展，国内半数以上的开源原生企业诞生于北京，覆盖数据库、操作系统、大数据、人工智能等基础前沿领域。国内唯一的开源基金会——开放原子开源基金会也于2020年落户北京。蔡奇书记在调研企业过程中指出，要坚持以开放引领创新，加速构建以北京为核心的国际化开源社区，打造开源软件基地。北京市将充分发挥基金会在开源生态体系的引领作用，多措并举，将北京打造成中国开源产业高地。</p><p></p><p></p><h2>携手共建国际开源社区，加速开源科技发展</h2><p></p><p></p><p>北京经济技术开发区管委会副主任刘力表示，作为此次峰会的承办区，经开区推动开放原子开源基金会 “两中心、一基地、一研究院”项目落地，推进建设中国国际开源社区，促进中国企业深度参与全球开源治理，孵化运营优秀开源项目引领全球开发者参与共建，以开源模式加速推进产业进步和科技发展。</p><p></p><p></p><h2>共同打造国际开源盛宴，重点突出“四大亮点”</h2><p></p><p></p><p>作为具有全球影响力的开源盛会，开放原子开源基金会秘书长孙文龙表示可关注以下突出特色：</p><p></p><p>一是打造汇聚全产业链开源力量的行业盛会。本届峰会邀请国内外头部科技企业，聚集开源开发者及政、产、学、研、用等各界有识之士，为切实推进开源发展的可实践性落地，围绕国家“十四五”规划制定的重点发展领域与方向，探索如何使开源更好地赋能实体经济、推动社会发展。</p><p></p><p>二是提高开放原子开源基金会作为开源核心组织的链接能力。以本届峰会为契机，打造开源领域常态化沟通交流和展示平台，践行开放原子开源基金会“以开发者为本、共享开源价值”的价值观，倡导开放共享、共建共治的开源理念及原则；通过开源项目孵化成果及生态活力的展示，提供卓有成效的运营与治理路径参考。</p><p></p><p>三是提供服务于开源开发者的分享交流平台。通过峰会的高峰论坛与开源合规分论坛、OpenHarmony分论坛、openEuler分论坛、开源技术应用与治理分论坛、数据库分论坛、教育分论坛、云原生分论坛等多个与开源开发者紧密相关的分论坛及专题活动，共同探讨开源发展模式，分析开源现状、问题及趋势，共商开源开放的创新实践。</p><p></p><p>四是拓展开源国际交流与合作空间。本届峰会邀请了国际知名开源基金会负责人、国内外开源专家等做主题发言，共同探讨开源发展理念、共商全球开源生态共建模式，并通过峰会传播我国开源生态建设取得的成果，吸引海内开源开发者及产业上下游的生态伙伴关注并参与我国的开源项目。</p><p>2022开放原子全球开源峰会即将于7月25-29日在北京亦创国际会展中心拉开帷幕，期待大家的参与和关注！</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2022-07-19 19:25:02",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何让算力像自来水一样“一点接入，随取随用”？",
    "url": "https://www.infoq.cn/article/6stRiPtpJD4fYeT4L8vy",
    "summary": "<p></p><p>7月19日，<a href=\"https://carrier.huawei.com/cn/events/winwin-innovation-week\">Win-Win·华为创新周</a>\"期间，华为光产品线总裁靳玉志正式发布华为全光品质运力网络产品解决方案，并提出“构筑算力时代的确定性运力”。据介绍，目前国内有超过10个省和直辖市布局全光品质运力网络。</p><p></p><p>靳玉志表示：“<a href=\"https://www.infoq.cn/news/mYlW0DzLlKwxKAzTeIOU\">迈向F5.5G</a>\"，以无处不在的光联接，无站不达的光传送为愿景。面向算力时代，华为发布全光品质运力网络，提供确定性运力，让算力像自来水一样‘一点接入，随取随用’。”</p><p></p><p>其指出，面对行业多样化的算力应用需求，只有确定性的运力和算力进行深度的融合，才能应对未来的算力需求。比如，线上云VR教育在完成云上渲染后，需要将数据20毫秒内传送到用户侧，才能有效避免眩晕；地方气象局每天会有几百T的数据，需要快速上传到云上进行计算处理；智慧工厂在工业云上自动化精密操控，需要7*24小时0业务中断超高可靠性。</p><p></p><p>经过对1400多家企业的调研，华为发现企业数字化转型对网络的带宽、时延、可靠性的确定性要求不断提高。因此，在算力时代，F5.5G通过瞄准超大带宽、超低时延、超高可靠性来打造确定性运力，支持算力网络发展。</p><p></p><p>此次发布会，华为基于F5.5G发布全光品质运力网络，其中包括5大创新解决方案：全光锚点、全光终端、全光调度、全光网关以及运力地图，实现向下联接企业和家庭，向上联接算力和云。</p><p></p><p>全光锚点：向上联接到算力节点，实现超低时延，1毫秒入算；向下加强OTN覆盖，实现100米联接企业；以端到端的OSU硬管道能力，带宽从2M到100G无损可调，实现泛在的10Gbps万兆联接，满足海量用户的入云入算需求；全光终端：通过OTN下沉到OLT站点，覆盖全场景接入需求，提供OTN点对点、OTN点对多点、FTTR-B、FTTR-H四种算力接入方式，满足大中小微企业及家庭的联接需求，实现算力触手可及；全光调度：通过400G和Super C+Super L技术，打造用户到算力节点以及算力节点间的超高速互联，以OXC、OTN全光调度，实现用户接入到城市算力中心1毫秒，用户接入到省算力中心5毫秒，用户接入到枢纽算力中心20毫秒；全光网关：作为全光品质运力网络和算力之间的“关口”，关联算力集群中的不同算力资源，配合全光锚点创建端到端的OSU管道，通过算网大脑，实现用户到云、算力节点端到端的灵活联接；运力地图：将带宽、时延、可靠性、能耗、利用率等运力资源全面数字化，并通过多因子均衡算法，根据用户配置偏好和业务SLA要求，比如最低时延、最大利用率、最高可靠性等，为用户匹配最合适的算力节点，并在用户和云、算力之间推荐最优的运力路径。算力，即设备的计算能力。随着国家大力发展数字基础设施，算力的提升和普惠变得越来越重要，如同《中国移动算力网络白皮书》中提到的，水力发展离不开水网，电力发展离不开电网，算力发展离不开“算力网络”。</p><p></p><p>会上，华为公司副总裁、计算产品线总裁邓泰华还呼吁共建算力网络，为数字经济注入新动能，当中关键主要有三：第一，运营商将成为算力网络建设的主力军。第二，AI算力将成为主要增量，算力网络AI先行。第三，产业协同、生态构建是关键。“华为作为运营商长期战略合作伙伴，坚持‘联接+计算’战略，全力帮助运营商构建新型信息基础设施，加速算力网络的发展与建设。”</p>",
    "publish_time": "2022-07-19 19:30:26",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]