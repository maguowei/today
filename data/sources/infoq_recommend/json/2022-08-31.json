[
  {
    "title": "谷歌宣布扩展3个新的亚太云区域",
    "url": "https://www.infoq.cn/article/9hbdPFw3xLLJdtu4Agw9",
    "summary": "<p><a href=\"https://gcp.infoq.cn/index.html\">谷歌云</a>\"在全球拥有34个地区和103个可用区域，为全球200多个国家和地区的客户提供云服务。最近，谷歌宣布将把业务扩展到马来西亚、泰国和新西兰这3个新的云区域。此前宣布的其他6个区域分别是柏林、达曼、多哈、墨西哥、特拉维夫和都灵。</p><p>&nbsp;</p><p>谷歌云亚太区副总裁Karan Bajwa在谷歌云博客上发表的一篇<a href=\"https://cloud.google.com/blog/products/infrastructure/announcing-new-google-cloud-regions-in-asia-pacific\">文章</a>\"中表示，谷歌的云计算扩张是基于IDC的一项预测数据，到2025年，亚太地区（不包括日本）的云服务总支出将达到2820亿美元。此外，文章中引用的另一份<a href=\"https://www.businesswire.com/news/home/20211110006478/en/Asia-Pacific-Sourcing-Market-Driven-by-Cloud-Services-in-Q3\">研究报告</a>\"来自Information Services Group于2021年做出的一项调查。调查指出，2021年第三季度，云服务占亚太地区IT和商业服务支出的84%以上，是所有地区中比例最高的。</p><p>&nbsp;</p><p>Bajwa还在博文中解释说，随着数字服务需求的增长，新的云区域出现了。在这些市场的各个行业，尤其是电信、制造业、金融服务和零售领域，云应用正在不断增长。</p><p>&nbsp;</p><p>谷歌云区域是客户可以在云计算环境中部署云资源的地理位置。至少，所有的谷歌云区域都提供诸如计算引擎、谷歌Kubernetes引擎、云存储、持久磁盘、CloudSQL、虚拟私有云、密钥管理系统、云身份和秘密管理器等服务。其他产品通常在新地区启动后的6个月内推出。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8f/8f0d83ef6fa2b36bebf2d84dab0d00c2.png\" /></p><p>谷歌目前落后于其他公共云供应商亚马逊云科技和微软<a href=\"https://www.infoq.cn/topic/Azure\">Azure</a>\"。根据<a href=\"https://www.srgresearch.com/articles/huge-cloud-market-is-still-growing-at-34-per-year-amazon-microsoft-and-google-now-account-for-65-of-all-cloud-revenues\">IT市场调查机构Synergy Research Group</a>\"的数据，亚马逊云科技以34%的全球市场份额领先，其次是微软（21%）和谷歌（10%）。在建设新的数据中心方面，这三家公共云供应商加起来也是最主要的投资支出方。例如，仅在2022年，谷歌就打算在数据中心和美国办公室投资95亿美元。</p><p>&nbsp;</p><p>Trade Me的DevOps/云工程师Simon Merrick在推特上表示欢迎云供应商在新西兰推出服务。</p><p>&nbsp;</p><p></p><blockquote>现在来了。@GoogleCloud_ANZ加入@awscloud和@Azure在新西兰开设数据中心。</blockquote><p></p><p>&nbsp;</p><p>最后，<a href=\"https://www.infoq.cn/topic/google\">谷歌云</a>\"预计到今年年底将在整个亚太地区拥有14个云区域，而亚马逊云科技的云区域只有13个，其中3个计划设在印度、澳大利亚和新西兰。此外，<a href=\"https://www.infoq.cn/topic/alibaba\">阿里巴巴</a>\"目前有21个云区域，今年没有宣布新的区域。在亚太地区，甲骨文、微软和IBM预计将分别拥有9个、17个和7个云区域。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/08/google-cloud-regions-apac/\">Google Announces Three New Regions in Asia Pacific</a>\"</p>",
    "publish_time": "2022-08-31 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "《架构师成长计划》联邦学习的研究与应用实践",
    "url": "https://www.infoq.cn/article/bvZD9ZQtN7wlD9888RBm",
    "summary": "<p>国际学术期刊Science/AAAS和英特尔在全球首次联袂推出第一季《架构师成长计划》以来，吸引了无数架构师踊跃参与，获得业内广泛赞誉。为持续助力架构师把握数智机遇，构建未来，第二季《架构师成长计划》全新升级，强势归来！业内顶尖架构师大咖齐聚，为架构师群体量身打造系统成长课程，带来涵盖云游戏、云原生、联邦学习、生信大数据、算力网络、云网融合等多个热门话题的前沿技术及案例实践。</p>\n<p>当前云计算、移动互联、人工智能、大数据、物联网等技术在重塑生活生产并带来诸多便利的同时，也加剧了人们对隐私泄露、数据安全的担忧。5G网络的普及，使得大量终端设备接入互联网或物联网，持续产生海量数据，造成了数据的爆炸式增长，而数据的交互、共享或流通却因对安全和隐私的担忧而困难重重，让以数据为养料的人工智能的发展受到严重限制。在此背景下，联邦学习应运而生，它是打通数据孤岛、避免隐私泄漏，在更高效地共享数据价值的同时还能更好地保护数据隐私的关键技术。</p>\n<p>大咖荟萃、权威解读，英特尔《架构师成长计划》第三讲精彩继续！特邀中国人工智能开源软件发展联盟副理事长王健宗、英特尔软件和高级技术系统部首席技术架构办公室产品安全部门高级总监郭伟，以及中国信息通信研究院云计算与大数据研究所、大数据与区块链部副主任闫树。他们将从概念原理、应用场景、实践用例、技术解析等多个方面，由浅入深地讲解联邦学习的应用优势和价值，并会对英特尔® SGX技术进行全方位的介绍和解析，包括其如何凭借更强的可信性和隔离机制，来兼顾联邦学习的数据防护需求与数据处理效率，以及在加速相关应用落地实践方面的重要作用。除了干货满满，第二季还设置有“互动有礼”活动，参与即有机会获取精美礼品。点击链接观看完整课程：<a href=\"https://bizwebcast.intel.cn/eventstart.aspx?eid=315&amp;tc=4nn5lm9ouy&amp;frm=InfoQ_2\">https://bizwebcast.intel.cn/eventstart.aspx?eid=315&amp;tc=4nn5lm9ouy&amp;frm=InfoQ_2</a></p>\n<p><strong>精彩亮点</strong></p>\n<p>为什么说联邦学习是加速数据要素化市场建设和AI应用普及的关键技术？</p>\n<p>什么是联邦学习？它适用于哪些场景？相比传统隐私保护手段优势和价值何在？</p>\n<p>如何构建更安全的多方计算平台，并实现各方数据高效且安全的协同及利用？</p>\n<p>英特尔®SGX为何能在强化数据安全防护的同时，优化和提升其处理效率？</p>\n<p><strong>议程</strong></p>\n<p>圆桌讨论：基于可信执行环境的联邦学习</p>\n<p>王健宗 中国人工智能开源软件发展联盟副理事长</p>\n<p>郭伟 英特尔软件和高级技术系统部首席技术架构办公室产品安全部门高级总监</p>\n<p>闫树 中国信息通信研究院云计算与大数据研究所大数据与区块链部副主任</p>\n<p>课程分享：联邦学习的研究与应用实践</p>\n<p>王健宗 中国人工智能开源软件发展联盟副理事长</p>\n<p>课程分享：英特尔®SGX助力的机密计算</p>\n<p>郭伟 英特尔软件和高级技术系统部首席技术架构办公室产品安全部门高级总监</p>",
    "publish_time": "2022-08-31 10:06:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "凯捷中国万学凡：IT 团队的数字化转型实践",
    "url": "https://www.infoq.cn/article/RuOHmW9rMy9oBC7EIu9Y",
    "summary": "<p>数字化转型的思考框架是什么？</p><p></p><p>大家好，首先特别感谢各位能够出席 DTDS 全球数字人才发展峰会，我是万学凡。</p><p></p><p>我今天分享的主题是 IT 团队的数字化转型实践，希望就大型 IT 团队在数字化转型过程中如何发展、建设分享一些我的经验。在切入正题之前，我有两个问题和大家探讨。</p><p></p><p>这两个问题来自于我三个月前在 InfoQ 组织的 TGO 鲲鹏说上分享的《大型研发团队的数字化魔方》，主题思想是：在数字化转型时代，随着研发团队越来越大，组织该如何思考研发团队的建设？</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1e/1ec9aa9f4228e36ce1c4169937641d07.png\" /></p><p></p><p></p><p></p><p>有两个主题方向，一个是 IT 团队的核心价值是什么？在思考这个问题的过程中，我从两个角度来分析。</p><p></p><p>第一个角度是规划视角，即如何和竞争对手在战略上形成差异，以及为目标顾客创造什么样的价值。如果将它深入解读，即如何在战略上形成差异化的竞争力：</p><p>我们的研发团队核心价值是什么？如何真正地以客户为中心，为客户创造什么样的价值？</p><p></p><p>第二个是能力视角，即如何做组织设计：</p><p>如何真正地围绕企业战略目标和业务目标有效分配资源，以此来提升组织能力，更好地支撑数字化转型的落地？</p><p></p><p>这是我思考这个问题的两个基本逻辑，围绕这两个大的逻辑，我们从规划战略入手，形成业务框架，进而形成技术框架，再到我们的组织架构、运营模型，以此来支撑整体的数字化转型。这是我与大家分享的第一个框架。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e8/e8c3a55c883f934ec312e757268d2064.png\" /></p><p></p><p></p><p>第二个主题，是企业在规划 IT 团队数字化转型的过程中，什么样的工作矩阵是行之有效的？我认为有三层：</p><p></p><p>第一层是战略与组织，这里要考虑两件事情：第一个是围绕着战略的投资组合如何做？哪些方向上要加大投资，哪些方向会延缓投资，哪些方向维持投资，这是 IT 团队 Leader 需要思考的问题；第二个是组织架构如何搭建和治理？这是战略与组织层面的内容，很多时候要和 HR 一起思考。</p><p></p><p>第二层有很多细节，这里只聊五大块。第一是产品管理，很多组织里也叫需求管理；第二个是技术架构；第三个是现在很火的研发效能；第四个是项目治理；第五个是运维演进。其实这 5 大块可以层层展开，总体说我把它归纳为产品与研发。</p><p></p><p>第三层叫运营平台，一支 IT 团队需要关注什么？关注财务指标，关注人才的选用育留，以及相应的能力建设和绩效评估体系。</p><p></p><p>切入正题之前，快速介绍一下我自己，我叫万学凡，是凯捷中国VP、数字化团队的负责人，也是凯捷咨询的首席顾问。</p><p></p><p>在行业摸爬滚打多年，我正在组建着越来越大的数字化研发团队，现在团队有超过 1200&nbsp;名专业顾问，我们组织本身也经历着数字化转型。我常常思考我的团队如何变得越来越高效，如何去搭建更好的工程师文化并建立人才观。</p><p></p><p>在服务众多客户的同时，我有幸参与到他们的数字化转型实践之中，了解到这些企业的 IT 团队如何从组建走向成熟。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bb/bbb6df1b89f83c24c178929d1184753d.png\" /></p><p></p><p></p><p>今天的分享将围绕黄金圆环展开，什么是黄金圆环？最里层的是 WHY，中间层是 HOW，最外层是 WHAT。很多人思考问题的方式是从外向内的，先看外面的表象是什么，再看如何做，最后思考问题本身。在过往 10&nbsp;余年的工作中，我认为这是一个比较好的框架，思考问题、构建问题、构建问题解决方案的方式应该是由内向外的，即先谈 WHY，再谈 HOW，最后谈 WHAT。这也是我今天分享的主线。</p><p></p><p></p><h3>数字化团队应具备的能力</h3><p></p><p></p><p>首先，IT 团队应该具备的数字化能力是什么，先讲 WHY，应该是什么样子；然后讲HOW，主要分享两个方面：一个是组织设计，另外一个是工程师文化；最后讲 WHAT，以此做一个总结，即 IT团队的组织能力构建应该是什么样子。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4a/4a54aa979feb2c245a8c7964322168bc.png\" /></p><p></p><p></p><p>IT 团队应该如何构建、具备哪些数字化能力？这是我过去一年在搭建上千人的数字化研发团队中总结的三个点。</p><p></p><p>第一点是业务思维，或者叫商业思维，就是如何以客户为中心。在很多大型的数字化 IT 团队中，有的把精力放在技术本身，有的放在业务解决方案上，却往往忽略了商业思维。我经常与团队探讨，我们既要“埋头拉车”，又要“抬头看路”，真正地围绕“以客户为中心”，构建商业思维。</p><p></p><p>第二个是解决方案思维。很多 IT 团队在数字化转型的过程中，思考解决方案思维的时候都会比较狭隘，微服务架构，领域驱动设计，DevOps，BDD，TDD……这都很好，但是我认为脱离了业务谈技术是空谈，所以解决方案思维一定是解决某个场景的具体业务问题，基于此提出业务和技术相融合的解决方案。</p><p></p><p>第三个是团队思维。IT 团队在不断地发展过程中，需要培养一群真正的技术领导者，技术领导者能带领团队朝目标更好地前进。我们今天看到很多 IT 工程师聚焦在技术本身，力争写出更好的代码。真正好的技术领导者要不要写出很好的代码呢？要，但同样也需要有很好的团队思维：需要能够培养团队、发展团队、建设团队，这样才能真正地让整个团队具备好的数字化能力。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/38/38aca6ce55e931620ac95eb717f757c0.png\" /></p><p></p><p></p><p>以赋能为核心的组织架构设计</p><p></p><p>HOW，就是该如何做。第一，做组织设计的时候，要搭建以能力为核心的平台型组织架构，这个非常重要。什么叫“以能力为核心”？我认为在未来的 IT 团队数字化转型过程中，能力发展、能力建设是最重要的话题，所以我在搭建自己团队的组织架构的时候，也是通过这个维度来思考的。</p><p></p><p>最上层的是战略与规划，包括业务架构设计，技术架构治理；中间一层围绕着各个 Account（你可以认为是各个产品线）的产品与研发。但是各个产品线之间往往会形成竖井，这是很难避免的，如何打破组织间的竖井？通过最上一层的战略与规划，通过业务架构设计，技术架构治理，能够横向地把能力打通；第三层，通过运营平台的人才培养、赋能体系、绩效评估，能够进行横向能力建设。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3b/3bf1de81a1c61f2f6911abeeb4f2732b.png\" /></p><p></p><p></p><p></p><p>在 IT 团队数字化转型过程中，“以资产为核心的解决方案管理”是其中的一个核心要素，很多企业都在谈如何能够提升 IT 团队的能效，建议从三个方面入手：资产、技术和胜任力。</p><p></p><p>很多IT团队在谈及组织能效提升的过程中，首次谈到的是研发效能，研发效能就是以技术为核心，提升 IT 团队的效率。但也要思考另外两个因素，一个是人的因素，人的因素如何考量？这里我提到的叫胜任力。</p><p></p><p>第二个是如何形成好的资产？很多组织里面建设平台型组织架构的时候，往往忽略了这一点，或者大家觉得这一点很难在组织中落地实行。对于产品型公司，可能相对来说较容易落地，可以在不断地打磨组织的业务资产和技术资产中形成一套产品，但是对于非产品型公司则会困难一些。</p><p></p><p>今天先谈两点：一是以资产为核心，该怎么做？第二点是以胜任力为核心，该怎么看？</p><p></p><p>以资产为核心，解决方案的孵化特别重要，包括四个方面：第一，标准化解决方案。一定要形成不一样的解决方案，解决客户不同的问题，但是在这些不一样的解决方案层面，有一些共性的东西可以抽象和提炼出来，这就是标准化的解决方案。</p><p></p><p>比如研产供销服，供应链等等，一定要有可以沉淀的标准化的解决方案，通过标准化解决方案来打破产品和产品之间、部门和部门之间的“部门墙”，横向拉通整个部门的能力。</p><p></p><p>第二，标准化文档。很多的企业推行敏捷，在践行敏捷的过程中，一定要有标准化的文档构建组织能力。</p><p></p><p>第三，可以执行的代码。无论是产品进公司还是非产品进公司，构建组织级平台的时候，一定有通用的组件或者API，可以包装、固化下来的，就叫做可执行的代码。</p><p></p><p>第四，相应的人与组织、以及核心团队。以上就是以资产为核心的解决方案管理。</p><p></p><p>胜任力模型是 HR 行业里面通用的一套框架，每个企业规划胜任力模型都不太一样，比如技术团队的胜任力如何看？如何为一个好的 IT 技术人员？可以从以下三个方面进行评价：</p><p></p><p>第一，他应该充分意识到自己专业技术领域的最新发展和最佳实践，比如一个非常好的Java后台工程师，应该具备理解 Java 的行业发展趋势是什么，最佳实践是什么。</p><p></p><p>第二，他不仅能和相关的 IT 工程师讲清楚某个技术的好处和限制，还能和不懂技术的人讲清楚。</p><p></p><p>举个例子：我在一个行业领域讲，什么是数字化转型？数字化转型对于一个企业意味着什么？工程师文化又是什么？这并不难，但是要给我 70 多岁的父亲母亲讲清楚什么是数字化转型？什么是工程师文化？这就很困难。但是如果能用他们的语言讲清楚，那么我对数字化转型的理解就又上升了一个台阶。</p><p></p><p>第三，如果我们精通一个工具，一门技术，在去完成一项工作的时候，紧迫感会更强，效率会更高。每个人都有自己擅长的技术，需求分析师擅长需求分析，咨询顾问擅长咨询方法论，程序员知道如何写好代码、如何搭建好的体系架构、如何践行DDD，无论是什么样的人物画像，都有自己的技术专长。</p><p></p><p>衡量一个人的技术专长好或者不好，都有一套胜任力模型的框架，以此来指导一个团队或个体，在其发展过程中应该如何去演进发展。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ec/eca257e99b2baed55912645d73f084cd.png\" /></p><p></p><p></p><p></p><p>再举个例子，我的团队如何用胜任力模型去评估一个人的通用胜任力和专业胜任力？大家可以看到如上这个图，有CI/CD的能力、架构能力、英语能力等等，根据每个人的情况打出相应的分数——从 0 分到 5 分做出评估。这样就知道他在不同维度中的评分，以此来指导这个员工在组织中的晋升和发展方向。</p><p></p><p></p><h3>为团队成长投资</h3><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6f/6fe75e3a8c703488ec9f5701011c9680.png\" /></p><p></p><p></p><p>第二个 HOW，是工程师文化。凯捷沈阳刚刚装修设计了一个新的办公室。关于敏捷团队的办公室设计，我在公众号中写过三篇文章，最近的一篇就是关于这次沈阳办公室的装修设计：<a href=\"https://mp.weixin.qq.com/s?__biz=MzU3NzY0Nzk1NA==&amp;mid=2247484823&amp;idx=1&amp;sn=abc6c783fe16fff6ed7ceec35bc20857&amp;scene=21#wechat_redirect\">面向未来的办公室：敏捷团队的办公室设计</a>\"</p><p></p><p>我认为工程师文化建设，能够让一个 IT 团队在数字化转型过程中变得更加高效，这里需要关注三件事情：</p><p></p><p>第一，需要有更加敏捷的工作环境。关于更加敏捷的工作环境，我思考了两个方面：第一作为社会锚点，专为人情来设计。好的工程师文化的工作场景是，大家在一起不仅是为了工作，也包含了很多“人情”，所以在这个工作的场所里面，可以创造很多偶遇的机会，可以进行除了工作之外的交流。第二，专为分享而设计。一个好的 IT 团队，一定有很多学习和分享的活动发生，我也鼓励在 IT 团队中专门设置读书角，鼓励团队成员更多地阅读。</p><p></p><p>第二，有公共开放区，大家可以在开放区进行主动的学习分享活动，这是作为学习分享空间而做的设计。</p><p></p><p>第三，作为合作枢纽，专为协作而设计，在办公空间中要有很多的白板和小会议室，大家可以在会议室里展开充分的讨论，也可以随时停下来，在白板上展开互动和协作。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/51/51faf71c4acb552da30f76cca6fb073e.png\" /></p><p></p><p></p><p></p><p>讲到学习和分享的氛围，向大家推荐一个工具叫技术雷达。什么叫技术雷达？我们主张每个大的 IT 团队都有自己的技术雷达，这个技术雷达会分享未来的 6-12个月，哪些技术是要采用的，哪些技术是要探索的，哪些技术是要停下来缓一缓的，把这个技术雷达张贴在办公室公共区域，让所有人都能去理解和学习。</p><p></p><p>每个团队也会看到他们要采取的新技术栈是什么，要尝试哪些不一样的技术方向，理解行业最新发展的趋势。技术雷达能够帮助我们打造学习和分享的氛围，构建工程师文化。</p><p></p><p>这里面我总结为两个点：</p><p></p><p>第一，通过技术能力组建，来加速整个 IT 项目的开发与交付，这个与资产相关。</p><p></p><p>第二，以人为本，通过学习和分享的氛围、技术雷达，让团队中的工程师都能找到属于自己的技术信仰。同样，我认为很多 HR 同学，以及技术领导者需要注意一个点，为团队的成长投资。</p><p></p><p>为此，我专门成立了一个叫数字化研修院的团队，就是把团队的能力做整合，从业务解决方案到软件架构，到开发运维、通用能力、业务建模、测试等等整合起来，形成一个大的能力建设图谱，赋能团队。</p><p></p><p>再深入讲一下，如何在团队里面形成很好的学习和分享氛围？有个比较好的实践，大家看到课程体系图谱里面的所有课程，包括业务、技术、运维、测试，所有的课程都来自于团队。</p><p></p><p>我们团队里有一个很好的学习和分享文化，就是我们鼓励团队能够主动开发、设计一些好的培训课程。开发和设计完成之后，面向整个大团队，做培训和分享，这是一个方面。</p><p></p><p>同样我们也鼓励团队能够举起手来说，我想去获取什么样的知识——一方面有人说，我愿意主动地去分享这些知识，一方面有人说我想去获取这样的培训，这样就在我们就形成了一个有效的学习和分享的闭环。</p><p></p><p>同样作为一个团队的 HR，作为一个团队的 Leader，要形成非常好的 OKR或者 KPI 的体系，来鼓励团队做更多的学习和分享，为团队的成长投资。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b5/b546572a79b260e55c65ab74f5fced79.png\" /></p><p></p><p></p><p>HOW 就是如何去搭建更具包容性的IT团队？这里分享一个话题，叫做要消除隐性偏见。</p><p></p><p>在 IT 团队里，很多时候会有一些隐性偏见，比如说认为女性 IT 工作者不如男性程序员，其实这是完全不对的。现在在我的团队中，IT 女性的比例超过了40%，我们希望要让消除隐性偏见能够弥漫在公司的氛围中，能够形成 IT 团队的文化和价值观，构建更具包容性的 IT 团队。如果一个团队的包容性好，它会提升团队的集体智力，进而提升整个团队的生产力。</p><p></p><p>所以说另外一个 HOW，就是在招聘过程中就要消除隐性偏见，不断地构建更加包容性的 IT 团队，来提升整个团队的集体智慧。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/de/de8aa16797c8eadf89a8d2c193d56f30.png\" /></p><p></p><p></p><p>推荐一本书，《卓有成效的工程师》，今天很多内容也来自于这本书。我认为卓有成效是一种超凡的境界，全书描绘了一种迅捷、高效、积极、友善的工作方式，在这个不断内卷的数字化时代，很多人都习惯于把血汗和泪水当做勋章，我本人并不赞同，我认为一定有一种更加从容的解决之道，让我们在工作中提高效率，在生活中更加自如。</p><p></p><p></p><p>最后总结，我认为在数字化转型中 IT 团队组织能力的构建，包括三个大的方面：</p><p></p><p>员工思维：需要具备三大思维，第一，商业思维，以客户为中心；第二，解决方案思维，如何去形成好的解决方案，包括核心团队、标准化的代码、标准化的解决方案等等；第三，团队思维，我提倡大家要有团队意识，成为技术领导者。员工能力：以能力为中心的组织设计，有三层：第一层，战略与组织的架构设计；第二层，产品与研发；第三层是运营平台。搭建以能力为核心的组织架构需要通过解决方案、胜任力、研发效能，横向地打通不同产品线、不同部门，建立以能力为核心的平台型组织。员工治理：重点分享的是团队胜任力，包括如何用胜任力模型指导员工和团队的发展。我们谈的不仅是敏捷研发，而是整个组织的敏捷性。</p>",
    "publish_time": "2022-08-31 10:17:31",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "字节跳动开源Volo：国内首个基于Rust语言的RPC框架",
    "url": "https://www.infoq.cn/article/NR3Rd5YlUkarAhKyrZUe",
    "summary": "<p>8 月 30 日，字节跳动基础架构的开源项目 <a href=\"https://www.infoq.cn/article/9iXLu4KjAPg3ufHYmM3J\">CloudWeGo</a>\" 正式发布 Rust RPC 开源框架 Volo。Volo 是一个轻量级、高性能、可扩展性强、易用性好的 Rust RPC 框架，使用了 Rust 最新的 GAT 和 TAIT 特性。</p><p></p><p>GitHub地址：https://github.com/cloudwego</p><p>官网：www.cloudwego.io</p><p></p><p>在字节内部，Volo 已经落地多个业务和基础组件，并且取得了超预期的性能收益（与 Go 版本对比，不那么公平）。</p><p></p><p>Volo 与其它 CloudWeGo 开源项目一样，坚持内外维护一套代码，为开源使用提供了强有力的保障。同时，我们观察到 Rust 开源社区在 RPC 框架这块还比较薄弱，Volo 的开源希望能为社区的完善贡献一份力量，同时也能完善 CloudWeGo 生态矩阵，为追求性能、安全性和最新技术的开发者、企业以及 Rustaceans 开发 RPC 微服务、搭建云原生分布式系统提供强有力的支持。</p><p></p><p>本文会为大家简单介绍 Volo 及其相关生态，并为大家提供一个简单的 Rust 与 Go 的选型建议。</p><p></p><h2>项目缘起</h2><p></p><p></p><p>其实 Volo 的创始成员来自于 Kitex 团队（CloudWeGo 开源的 Go RPC 框架），当时我们在 Go 上做了非常深度的性能优化，也因此深刻感受到了在 Go 上做性能优化所面临的阻碍。因此，我们选择了 Rust，期望能够给需求极致性能、安全和指令级掌控能力的业务一个合适的选择。而 RPC 框架是分布式系统中重要的组成部分，Volo 就这么诞生了。</p><p></p><h2>特性</h2><p></p><p></p><h4>高性能</h4><p></p><p></p><p>Rust 以高性能和安全著称，我们在设计和实现过程中也时刻以高性能作为我们的目标，尽可能降低每一处的开销，提升每一处实现的性能。</p><p></p><p>首先要说明，和 Go 的框架对比性能是极不公平的，因此我们不会着重比较 Volo 和 Kitex 的性能，并且我们给出的数据仅能作为参考，希望大家能够客观看待。同时，由于在开源社区并没有找到另一款成熟的 Rust 语言的 Async 版本 Thrift RPC 框架，而且性能对比总是容易引战，因此我们希望尽可能弱化性能数据的对比，仅会公布我们自己极限 QPS 的数据。</p><p></p><p>在和 Kitex 相同的测试条件（限制 4C）下，Volo 极限 QPS 为 35W。同时，我们内部正在验证基于 Monoio（CloudWeGo 开源的 Rust Async Runtime）的版本，极限 QPS 可以达到 44W。</p><p></p><p>从我们线上业务的火焰图来看，得益于 Rust 的静态分发和优秀的编译优化，框架部分的开销基本可以忽略不计（不包含 syscall 开销）。</p><p></p><h4>基于 GAT 设计</h4><p></p><p></p><p>我们热爱并追随最新的技术，Volo 的核心抽象使用了 Rust 最新的 GAT 特性，在这个过程中我们也借鉴了&nbsp;Tower&nbsp;的设计。Tower 是一个非常优秀的抽象层设计，适用于非 GAT 的情况下。在此我们非常感谢 Tower 团队。</p><p></p><p>Tower：https://github.com/tower-rs/tower</p><p></p><p>通过 GAT，我们可以避免很多不必要的&nbsp;Box&nbsp;内存分配，以及提升易用性，给用户提供更友好的编程接口和更符合人体工程学的编程范式。</p><p></p><p>我们的核心抽象如下：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/f6/c5/f6ea2639969c9d180dc630d3f0307ac5.png\" /></p><p></p><p>由于使用了 Rust 的 GAT 特性，因此我们可以解决返回异步 Future 带来的生命周期问题。同时，如果配合&nbsp;type_alias_impl_trait&nbsp;使用，效果更佳，比如实现 Timeout 可以使用如下方式：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/4d/9a/4d9d46245c65254a43d6fa178096d19a.png\" /></p><p></p><h4>易用性好</h4><p></p><p></p><p>Rust 以难学难用而闻名，我们希望尽可能降低用户使用 Volo 框架以及使用 Rust 语言编写微服务的难度，提供最符合人体工程学和直觉的编码体验。因此，我们把易用性作为我们重要的目标之一。</p><p></p><p>比如，我们提供了 Volo 命令行工具，用于初始化项目以及管理 IDL。同时，我们将 Thrift 及 gRPC 拆分为两个独立（但共用一些组件）的框架，以提供最符合不同协议语义的编程范式及接口。</p><p>我们还提供了&nbsp;#[service]&nbsp;宏（可以理解为不需要&nbsp;Box&nbsp;的&nbsp;async_trait）来使得用户可以无心理负担地使用异步来编写&nbsp;Service&nbsp;中间件。</p><p></p><p>通过这个宏，我们编写&nbsp;Service&nbsp;中间件可以简化到如下图：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/70/cd/70f13be6743d8bd420b3237f902e00cd.png\" /></p><p></p><h4>扩展性强</h4><p></p><p></p><p>受益于 Rust 强大的表达和抽象能力，通过灵活的中间件 Service 抽象，开发者可以以非常统一的形式，对 RPC 元信息、请求和响应做处理。</p><p></p><p>比如，服务发现、负载均衡等服务治理功能，都可以以 Service 形式进行实现，而不需要独立实现 Trait。相关的扩展，我们会放在&nbsp;github.com/volo-rs&nbsp;组织下，也欢迎大家贡献自己的扩展到&nbsp;volo-rs。</p><p></p><h2>生态系统</h2><p></p><p></p><p>Volo 是 RPC 框架的名字，随着 Volo 一起开源的有以下几个项目：</p><p></p><p>1. Volo-rs：Volo 的相关生态。</p><p>2. Pilota：Volo 使用的 Thrift 与 Protobuf 编译器及编解码的纯 Rust 实现（不依赖 protoc）。</p><p>3. Motore：Volo 参考 Tower 设计的、使用了 GAT 和 TAIT 的 middleware 抽象层。</p><p>4. Metainfo：Volo 用于进行元信息透传的组件，期望定义一套元信息透传的标准。</p><p></p><h2>选型建议</h2><p></p><p></p><p>“什么情况下应该用 Rust、什么情况下应该用 Go？”这是一个非常经典的问题。在 Volo 团队看来，Rust 和 Go 并不是对立关系，而是合作关系，取长补短。</p><p></p><p>对于性能不敏感的应用、重 IO 的应用以及需要快速开发快速迭代胜过稳定性的应用，推荐使用 Go，这种应用使用 Rust 并不会带来明显的收益。</p><p></p><p>对于需要极致性能，重计算的应用，以及需要稳定性并能接受一定开发速度损失的应用，推荐使用 Rust，Rust 在极致性能优化和安全性上的优势可以在这类应用中得以发挥。</p><p></p><p>当然，还有一个很重要的考虑因素，是团队现有的技术栈，即技术储备和人才储备。</p><p></p><h2>总结</h2><p></p><p></p><p>希望本文能让大家对于 Volo 及相关生态有一个基本的了解。同时，Volo 还处于早期阶段，欢迎各位感兴趣的同学一起加入，共同建设 CloudWeGo 及 Rust 开源社区，向 Volo 提交 Issue 和 PR 共建 Volo。我们诚心期待更多的开发者加入，也期待 Volo 助力越来越多的企业快速构建云原生架构。如果企业客户想内部试用，我们可以排期提供专项技术支持和交流。</p><p></p><p>参考资料</p><p></p><p>Volo 概览：https://github.com/cloudwego/volo</p><p>Volo Tutorial：https://www.cloudwego.io/zh/docs/volo/</p><p>Volo 文档：https://docs.rs/volo</p><p>Volo-rs 组织：https://github.com/volo-rs</p>",
    "publish_time": "2022-08-31 11:55:12",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "YOLOX-PAI:加速YOLOX,比YOLOV6更快更强",
    "url": "https://www.infoq.cn/article/GitPuxirzKxtpAh2Gizs",
    "summary": "<p></p><h3>导言</h3><p></p><p></p><p>近日，<a href=\"https://www.aliyun.com/?utm_content=se_1008364713\">阿里云</a>\"<a href=\"https://xie.infoq.cn/article/462125fa016e696d638206688\">机器学习平台团队PAI</a>\"通过自研的PAI-EasyCV框架复现YOLOX算法，并结合了PAI自研的PAI-Blade推理加速框架优化模型性能，使得加速过后的YOLOX-PAI在速度和精度上都比现阶段的轻量级目标检测的SOTA算法YOLOV6&nbsp;提速约20%，同时，<a href=\"https://xie.infoq.cn/article/380f99bbd0bf7f28a937071b2\">PAI-EasyCV</a>\"提供高效简洁的模型部署和端到端推理接口，供社区快速体验使用YOLOX-PAI的功能。</p><p></p><p>目前，EasyCV和Blade项目已在<a href=\"https://www.baidu.com/link?url=aPfgPN6pfnVBYOJ6KX7_ugYUl-Gpj9xjTljtR7OSB7i&amp;wd=&amp;eqid=a434d4c90000e74d00000003630ee39a\">GitHub</a>\"上开源：</p><p></p><p>https://github.com/alibaba/EasyCV</p><p></p><p>https://github.com/alibaba/BladeDISC</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6f/6fc4aa5f417fa30b7703b40a34fc4032.jpeg\" /></p><p></p><p></p><h3>实现方案</h3><p></p><p></p><p>1.提供了一套Apache&nbsp;License&nbsp;训练/优化/推理的代码库以及镜像，可以实现当前社区40+mAP&nbsp;量级最快（相比&nbsp;YOLOV6&nbsp;mAP提升0.4/加速13~20%）的目标检测模型。</p><p></p><p>2.调研了YOLOX相关的改进技术和消融实验，总结了其中一些相对有帮助的改进，并以配置的方式提供出来。</p><p></p><p>3.对目标检测的端到端推理进行灵活封装及速度优化，在V100上的端到端推理为3.9ms，相对原版YOLOX的9.8ms，加速250%，供用户快速完成目标检测推理任务。</p><p></p><p>本文，我们将重点介绍如何基于PAI-EasyCV使用PAI-Blade优化模型推理过程，及如何使用PAI-EasyCV进行模型训练、验证、部署和端到端推理。欢迎大家关注和使用PAI-EasyCV和PAI-Blade，进行简单高效的视觉算法开发及部署任务。</p><p></p><p></p><h3>YOLOX-PAI&nbsp;精益求精的算法改进</h3><p></p><p></p><p>YOLOX-PAI是阿里云机器学习平台PAI&nbsp;的开源计算机视觉代码库EasyCV中集成的&nbsp;YOLOX&nbsp;算法。通过对YOLOX&nbsp;算法的分析，结合检测技术的调研，从以下4个方向对原版的YOLOX进行优化，</p><p></p><p>Backbone&nbsp;:&nbsp;repvgg[1]&nbsp;backboneNeck&nbsp;:&nbsp;gsconv&nbsp;[2]&nbsp;/&nbsp;asff&nbsp;[3]Head&nbsp;:&nbsp;toods[4]&nbsp;/&nbsp;rtoodsLoss&nbsp;:&nbsp;siou&nbsp;[5]&nbsp;/&nbsp;giou</p><p></p><p>在算法改进的基础上，利用PAI-Blade对改进后的的模型进行推理优化，开发了如下的PAI-YOLOX模型。具体改进的消融实验可以参考我们的[arxiv]，筛选有效改进与现有主流算法的对比结果如下：</p><p></p><p>（&nbsp;-ASFF&nbsp;代表使用了&nbsp;NeckASFF，&nbsp;-TOODN代表使用N个中间层的TOODHead取代原有的YOLOXHead）</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/30/3030a355d2b702fe61d04b6bad25c684.png\" /></p><p></p><p>从结果中可以看到，相比目前同水平(1ms以内)SOTA的YOLOV6模型，融合上述改进的YOLOX-PAI在同等精度/速度的条件下有一定的速度/精度优势。(PS：上表精度测量和速度测量上与YOLOV6对齐，不包含NMS和后处理，测试精度也分图片大小等于672/640两种。)</p><p></p><p></p><h3>YOLOX-PAI&nbsp;简单的端到端预测</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c5/c57752e2f03ebf69408240dcebc23575.png\" /></p><p></p><p>针对使用PAI-EasyCV训练的YoloX-PAI&nbsp;模型，用户可以使用PAI-EasyCV自带的导出功能得到优化后的模型，并使用&nbsp;EasyCV&nbsp;提供的TorchYoloXPredictor&nbsp;进行端到端的推理。&nbsp;该导出功能对检测模型进行了如下优化：</p><p></p><p>使用PAI-Blade优化模型推理速度，简化对模型的推理加速（TensorRT/编译优化）开发流程。</p><p></p><p>支持EasyCV配置TorchScript/PAI-Blade对图像前处理、模型推理、图像后处理分别优化，供用户灵活使用。</p><p></p><p>支持python环境下的Predictor结构端到端的模型推理优化，简化图片预测过程。</p><p></p><p>也可以参考[EasyCV detector.py]&nbsp;自行组织相应的图像前处理/后处理过程，或直接使用我们导出好的模型和接口，这里提供一个已经导出好的检测模型，用户下载三个模型文件到本地</p><p>&nbsp;[preprocess,&nbsp;model,&nbsp;meta]</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1d/1d503b3e0e23b2b9be3da8dc971831e0.png\" /></p><p></p><p>用户可以直接使用PAI-EasyCV提供的Predictor接口，通过如下简单的API调用，</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c1/c1a4a1b43123a0da71fac1ccf480acd5.png\" /></p><p></p><p>高效的进行图像的检测任务：</p><p></p><p></p><h3>YOLOX-PAI&nbsp;极致性能的推理优化</h3><p></p><p></p><p>下图，我们展示了YOLOX-PAI在集成PAI-Blade/torchscript优化后和原版YOLOX的不同尺寸（s/m/l/x）模型的推理耗时对比，&nbsp;在开启预处理优化和模型的PAI-Blade优化后：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a4/a4c1b4d5364231902200f7a101ae01be.jpeg\" /></p><p></p><p>可以看到PAI-EasyCV导出的模型，极大程度的优化了原模型的端到端推理速度，达到了接近250%。</p><p></p><p>PAI-Blade&nbsp;推理优化</p><p></p><p>PAI-Blade是由<a href=\"https://www.infoq.cn/article/3rBcBW7v2z46Wv6LVoX6\">阿里云机器学习平台</a>\"PAI开发的深度学习模型优化工具，可以针对不同的设备不同模型进行推理加速优化。PAI-Blade遵循易用性，鲁棒性和高性能为原则，将模型的部署优化进行高度封装，设计了统一简单的API，在完成Blade环境安装后，用户可以在不了解ONNX、TensorRT、编译优化等技术细节的条件下，通过简单的代码调用方便的实现对模型的高性能部署。更多PAI-Blade相关技术介绍可以参考&nbsp;[PAI-Blade介绍]。</p><p></p><p>PAI-EasyCV中对PAI-Blade进行了支持，用户可以通过PAI-EasyCV的训练config&nbsp;中配置相关的导出（export）参数，调用PAI-Blade用于优化导出模型，结合EasyCV&nbsp;Predictor完成图片的端到端的图像检测任务。</p><p></p><p></p><h3>写在最后</h3><p></p><p></p><p>YOLOX-PAI&nbsp;是PAI-EasyCV团队基于旷视YOLOX&nbsp;复现并优化的在V100BS32的1000fps量级下的SOTA检测模型。整体工作上集成和对比了很多社区已有的工作：替换基于RepVGG的高性能Backbone，&nbsp;在Neck中添加基于特征图融合的ASFF/GSConv增强，在检测头中加入了任务相关的注意力机制TOOD结构。结合PAI-Blade编译优化技术，同等精度下比YOLOV6&nbsp;加速13~20%。EasyCV提供配套了一系列算法/训练/推理优化代码和环境，目前，YOLOX-PAI已广泛的应用在阿里集团内外的互联网，智能零售，自动驾驶等客户场景中。</p><p></p><p>PAI-EasyCV（https://github.com/alibaba/EasyCV）是阿里云机器学习平台PAI研发的计算机视觉算法框架，已在集团内外多个业务场景取得相关业务落地成果，未来将聚焦在自监督学习/VisionTransformer等前沿视觉领域，并结合PAI-Blade等自研技术不断优化。欢迎大家参与进来一同进步。</p><p></p><p></p><h3>相关文献</h3><p></p><p></p><p>[1]&nbsp;Ge&nbsp;Z,&nbsp;Liu&nbsp;S,&nbsp;Wang&nbsp;F,&nbsp;et&nbsp;al.&nbsp;Yolox:&nbsp;Exceeding&nbsp;yolo&nbsp;series&nbsp;in&nbsp;2021[J].&nbsp;arXiv&nbsp;preprint&nbsp;arXiv:2107.08430,&nbsp;2021.</p><p></p><p>[2]&nbsp;YOLOv6,&nbsp;https://github.com/meituan/YOLOv6.</p><p></p><p>[3]&nbsp;Xu&nbsp;S,&nbsp;Wang&nbsp;X,&nbsp;Lv&nbsp;W,&nbsp;et&nbsp;al.&nbsp;PP-</p><p>YOLOE:&nbsp;An&nbsp;evolved&nbsp;version&nbsp;of&nbsp;YOLO[J].&nbsp;arXiv&nbsp;preprint&nbsp;arXiv:2203.16250,&nbsp;2022.</p><p></p><p>[4]&nbsp;Wang&nbsp;C&nbsp;Y,&nbsp;Liao&nbsp;H&nbsp;Y&nbsp;M,&nbsp;Wu&nbsp;Y&nbsp;H,&nbsp;et&nbsp;al.&nbsp;CSPNet:&nbsp;A&nbsp;new&nbsp;backbone&nbsp;that&nbsp;can&nbsp;enhance&nbsp;learning&nbsp;capability&nbsp;of&nbsp;CNN[C]//Proceedings&nbsp;of&nbsp;the&nbsp;IEEE/CVF&nbsp;conference&nbsp;on&nbsp;computer&nbsp;vision&nbsp;and&nbsp;pattern&nbsp;recognition&nbsp;workshops.&nbsp;2020:&nbsp;390-391.</p><p></p><p>[5]&nbsp;Ding&nbsp;X,&nbsp;Zhang&nbsp;X,&nbsp;Ma&nbsp;N,&nbsp;et&nbsp;al.&nbsp;Repvgg:&nbsp;Making&nbsp;vgg-style&nbsp;convnets&nbsp;great&nbsp;again[C]//Proceedings&nbsp;of&nbsp;the&nbsp;IEEE/CVF&nbsp;Conference&nbsp;on&nbsp;Computer&nbsp;Vision&nbsp;and&nbsp;Pattern&nbsp;Recognition.&nbsp;2021:&nbsp;13733-13742.</p><p></p><p>[6]&nbsp;Liu&nbsp;S,&nbsp;Huang&nbsp;D,&nbsp;Wang&nbsp;Y.&nbsp;Learning&nbsp;spatial&nbsp;fusion&nbsp;for&nbsp;single-shot&nbsp;object&nbsp;detection[J].&nbsp;arXiv&nbsp;preprint&nbsp;arXiv:1911.09516,&nbsp;2019.</p><p></p><p>[7]&nbsp;YOLOv5,&nbsp;https://github.com/ultralytics/yolov5.</p><p></p><p>[8]&nbsp;Li&nbsp;H,&nbsp;Li&nbsp;J,&nbsp;Wei&nbsp;H,&nbsp;et&nbsp;al.&nbsp;Slim-neck&nbsp;by&nbsp;GSConv:&nbsp;A&nbsp;better&nbsp;design&nbsp;paradigm&nbsp;of&nbsp;detector&nbsp;architectures&nbsp;for&nbsp;autonomous&nbsp;vehicles[J].&nbsp;arXiv&nbsp;preprint&nbsp;arXiv:2206.02424,&nbsp;2022.</p><p></p><p>[9]&nbsp;Feng&nbsp;C,&nbsp;Zhong&nbsp;Y,&nbsp;Gao&nbsp;Y,&nbsp;et&nbsp;al.&nbsp;Tood:&nbsp;Task-aligned&nbsp;one-stage&nbsp;object&nbsp;detection[C]//2021&nbsp;IEEE/CVF&nbsp;International&nbsp;Conference&nbsp;on&nbsp;Computer&nbsp;Vision&nbsp;(ICCV).&nbsp;IEEE&nbsp;Computer&nbsp;Society,&nbsp;2021:&nbsp;3490-3499.</p><p></p><p>[10]&nbsp;Gevorgyan&nbsp;Z.&nbsp;SIoU&nbsp;Loss:&nbsp;More&nbsp;Powerful&nbsp;Learning&nbsp;for&nbsp;Bounding&nbsp;Box&nbsp;Regression[J].&nbsp;arXiv&nbsp;preprint&nbsp;arXiv:2205.12740,&nbsp;2022.</p><p></p><p>[11]&nbsp;Rezatofighi&nbsp;H,&nbsp;Tsoi&nbsp;N,&nbsp;Gwak&nbsp;J&nbsp;Y,&nbsp;et&nbsp;al.&nbsp;Generalized&nbsp;intersection&nbsp;over&nbsp;union:&nbsp;A&nbsp;metric&nbsp;and&nbsp;a&nbsp;loss&nbsp;for&nbsp;bounding&nbsp;box&nbsp;regression[C]//Proceedings&nbsp;of&nbsp;the&nbsp;IEEE/CVF&nbsp;conference&nbsp;on&nbsp;computer&nbsp;vision&nbsp;and&nbsp;pattern&nbsp;recognition.&nbsp;2019:&nbsp;658-666.</p>",
    "publish_time": "2022-08-31 12:47:27",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "《架构师成长计划》用架构思维为云原生做减法",
    "url": "https://www.infoq.cn/article/itoqVs4yeH0zHi3FEr4j",
    "summary": "<p>国际学术期刊Science/AAAS和英特尔在全球首次联袂推出第一季《架构师成长计划》以来，吸引了无数架构师踊跃参与，获得业内广泛赞誉。为持续助力架构师把握数智机遇，构建未来，第二季《架构师成长计划》全新升级，强势归来！业内顶尖架构师大咖齐聚，为架构师群体量身打造系统成长课程，带来涵盖云游戏、云原生、联邦学习、生信大数据、算力网络、云网融合等多个热门话题的前沿技术及案例实践。</p>\n<p>数字化转型的深化发展，带来规模化的业务升级，愈来愈多的企业开始意识到现有IT基础设施已经不能满足当前业务需求，也难以应对多方挑战，数字化转型价值无法充分实现。如何高效管理多种基础设施？如何降低运维开发成本，实现更加敏捷的业务迭代？面对变幻莫测的市场竞争，企业亟需革新传统IT架构。而随着云原生技术的持续发展，构建云原生架构正在成为大中小企业驱动数字化转型、引领业务变革的制胜法宝。</p>\n<p>轻松拥抱云原生，充分发挥云效能，英特尔《架构师成长计划》第四期精彩纷呈！特邀青云科技容器产品负责人于爽、英特尔云基础设施软件研发总监王庆、CSDN创始人、总裁蒋涛，三位业界专家代表共话云原生。他们将全面剖析云原生的技术优势及前瞻发展趋势，为您解密云原生落地最佳实践方案，不走弯路！同时，还会深度解构英特尔丰富的云原生解决方案，涵盖混合云、容器基础设施、计算加速、存储优化等，全面赋能云原生架构，助您迎战产业数字化浪潮！点击链接观看完整课程https://bizwebcast.intel.cn/eventstart.aspx?eid=316&amp;tc=tghv9wfxlu&amp;frm=InfoQ</p>\n<p><strong>精彩亮点</strong></p>\n<p>云原生的优势是什么？企业该如何落地云原生？</p>\n<p>K8s解决了哪些问题？如何升级改造更适合企业的容器管理？</p>\n<p>混合云容器化有哪些实现路径，英特尔在促进多云融合方面有哪些成功经验？</p>\n<p>如何软硬兼施提升云原生应用的运行效率？规避容器的安全风险，又该如何技术布局？</p>\n<p><strong>议程</strong></p>\n<p>圆桌讨论：如何看待云原生的技术优势和发展趋势？</p>\n<p>于爽 青云科技容器产品负责人</p>\n<p>王庆 英特尔云基础设施软件研发总监</p>\n<p>蒋涛 CSDN创始人、总裁</p>\n<p>课程分享：用架构思维为云原生做减法</p>\n<p>于爽 青云科技容器产品负责人</p>\n<p>课程分享：英特尔在云原生里的技术发展和展望</p>\n<p>王庆 英特尔云基础设施软件研发总监</p>",
    "publish_time": "2022-08-31 15:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "中国卓越技术团队访谈录（2022 年第三季）",
    "url": "https://www.infoq.cn/article/EQzDrPI1dT9G8V6alV1I",
    "summary": "<p><strong>封面故事</strong></p>\n<ul>\n<li>在阿里达摩院搞了四年数据库，我来聊聊实际情况</li>\n</ul>\n<p>全密态数据库在学术界有多种不同方向的探索，但并不是每一种路线都能够在商业场景落地，全球目前仅有极少数具备全密态数据库管理能力的厂商，阿里达摩院数据库存储与创新实验室做到了。</p>\n<p><strong>重磅访谈</strong></p>\n<ul>\n<li>不到3年覆盖25个行业，华润集团系统上云比例超过99%</li>\n</ul>\n<p>除了不照搬敏捷开发模式，华润云也不推崇大量采用分布式、微服务等前沿技术架构。</p>\n<ul>\n<li>突围电商大促场景，得物在高可用上的探索与实践</li>\n</ul>\n<p>大型电商系统并非一开始就具有完整设计的高可用特性，而是随着用户的不断增加与业务的快速增长逐步演进与完善的。</p>\n<ul>\n<li>用三年替换掉二十年老系统，民生保险数字化转型秘籍</li>\n</ul>\n<p>对民生保险来说，项目的实施需要很多懂技术，又有很多有大型项目经验的人员去推动。而且项目实施之后，技术怎么去沉淀，怎么去传承，怎么去保证确保所有的技术迭代和稳定的运转，这都是需要想办法解决的问题。这也是大多数转型中的中小企业需要面对的问题：作为一个甲方企业，不能无限制的在技术上去投入。</p>\n<ul>\n<li>从基础架构到用户体验，字节跳动是如何打造移动端架构团队的？</li>\n</ul>\n<p>“务实是我们团队非常重要的一个业务视角，也是我们反复强调的一点。”</p>\n<ul>\n<li>一年 100% 云原生化，众安保险架构演进的探索与实践</li>\n</ul>\n<p>众安认为，云原生技术能够为金融行业、尤其是互联网金融行业带来巨大的红利，为众安构建新一代的数字化基础设施，以及帮助企业数字化转型带来强大的推力。</p>",
    "publish_time": "2022-08-31 15:05:28",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "PaaS的祖先Heroku，连相当值钱的“免费套餐”遗产都丢掉了",
    "url": "https://www.infoq.cn/article/lDpmKirqFiUXrqKh8lKA",
    "summary": "<p>8月25日，Heroku发布通告，表示为了防止欺诈和滥用，将从 2022 年 11 月 28 日开始停止提供免费产品计划，并关闭免费的dynos和数据服务，以后将重点关注核心客户。</p><p>&nbsp;</p><p>Heroku的免费计划，曾为众多想进入科技行业的人打开了一扇门。</p><p>&nbsp;</p><p>Heroku 是一种平台即服务(PaaS)，是 2007 年创建的第一批云平台之一，可让开发者将 git 存储库推送到云端，然后神奇地获取在某处运行的应用程序的 URL。一位开发者说，这种魔法对他的职业生涯起到了很大的催化作用，“当年作为学生，没有信用卡，也穷，Heroku的免费计划帮助我打开了真正了解网站如何工作的大门。如果没有Heroku，我永远无法达到今天的水平，以至于现在我真的无法说清它对我的职业生涯曾经有多么重要！”</p><p>&nbsp;</p><p>像他这样通过Heroku学习编程的，不是少数。在今年StackOverflow 2022年度开发者调查报告中，有一个关于“云平台”调查问题，以了解开发者在过去一年中主要在哪些云平台中进行开发工作。在针对“Learning to Code”群体中，Heroku以35.24%的比例位列第一，超过了Google、AWS和Microsoft&nbsp;。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/eb/ebcf2300ffbecdcd8c47ebb70d9b920a.png\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>实际上，这个革命性的产品，从技术上讲已经停滞不前，其产品也名存实亡，一位Heroku前员工在 HN 上写道：“你必须追溯到 Heroku Changelog 才能找到任何不是语言版本升级或特性删除的内容：<a href=\"https://devcenter.heroku.com/changelog\">https://devcenter.heroku.com/changelog</a>\"。我认为特性冻结是发生在 2018 年。”</p><p>&nbsp;</p><p>今年4 月，Heroku还曾发生一起严重的安全事故，社区反应激烈，当时一名攻击者获取了 Heroku 的主数据库（在我们那个时代称为 core-db）的访问权，并泄露了它的内容，包括哈希密码和用于 GitHub 集成的机密。</p><p>&nbsp;</p><p>现在，短短几个月过去，Heroku再次让社区感到悲伤，它关闭了免费计划。</p><p>&nbsp;</p><p>对此，一位开发者说，“Heroku 对我来说已经死了，我看到一扇又一扇进入科技的门被牢牢地关闭和锁定。”</p><p>&nbsp;</p><p>“我只是希望下一个时代能给每个人带来公平的技术。希望资本有点耐心，在它发光之前不要杀死它。”</p><p>&nbsp;</p><p>虽然Heroku在走向衰落，但它也给如今的软件行业留下了很多遗产。</p><p>&nbsp;</p><p></p><h2>Heroku有哪些遗产</h2><p></p><p>&nbsp;</p><p>Heroku 由三位 Ruby 开发人员（James Lindenbaum、Adam Wiggins 和 Orion Henry）于 2007 年建立，仅仅三年后就被收购，SaaS 巨头 Salesforce 最终击败 VMware，以 2.12 亿美元的价格将 Heroku 收到囊下，当时该公司只有 30 名员工。</p><p>&nbsp;</p><p>2011 年，Heroku 的联合创始人 Adam Wiggins 根据针对上百万应用托管和运维的经验，发布了著名的“十二要素应用宣言（The Twelve-Factor App）” 。他们那时候绝对不会料到这份宣言会在之后数年时间里，成为 SaaS 应用开发的启蒙书。同时这也奠定了 Heroku 在 PaaS 领域的地位，成为了云上应用开发规范化的基石。</p><p>&nbsp;</p><p>Heroku 的工程负责人 Jason Warner 说：“我相信 Heroku 是在 2014 年到 2017 年之间最具革命性的产品，对 Web 开发产业的推动作用非常大。它也是同时代最受争议的项目之一，因为它实在太超前了。当时它看起来就像魔法一般，人们都被它深深震撼了。”</p><p>&nbsp;</p><p>Heroku 的人气一直都归功于其简洁、优雅和可用性的优势，它率先将重心放在了开发人员的体验上，致力于让部署像开发流程那样无缝流畅。</p><p>&nbsp;</p><p>Heroku 是最早喊出“以应用为中心”，大规模帮助应用上云的产品。正是围绕“以应用为中心”这样先进的理念，使得 Heroku 从一开始便拥有了至今看来都非常诱人的功能：用户无需关心应用背后的基础设施是什么，Heroku 负责维护背后的一切。</p><p>&nbsp;</p><p>这句看似简单的话背后隐藏了巨大的复杂性，试想下某个软件或系统爆出安全漏洞后给你带来的窘境，又或者你想使用一个数据库服务时却不得不维护一个数据库实例。而在 Heroku， 这一切麻烦你都无需关心。用户可以直接从开发语言出发，选择对应的技术栈，通过 heroku create 这样简单的命令，将应用托管到云上。主流的开发语言，均能在 Heroku 中找到对应的选择。从代码的变动自动触发软件的部署交付，清晰的工作流、多样的发布策略，直到后来的很多年都是 DevOps 们梦寐以求的功能。</p><p>&nbsp;</p><p>Heroku 的联合创始人，如今是初创企业加速器 Heavybit 的合伙人 Linden baum 说：“震撼人心的是 Git 推送部署，这也是人们从 Heroku 学到的核心思想，大家原本以为必然要做的很多事情都用不着操心了。我们的愿景不是给猪涂口红，而是重新思考怎样彻底解决这个问题。”</p><p>&nbsp;</p><p></p><h3>卖给Salesforce算是一种成功吗？</h3><p></p><p>&nbsp;</p><p>之前有人在 <a href=\"https://twitter.com/craigkerstiens/status/1519483444861935616\">Twitter</a>\" 上提出了一个不那么简单的问题：“Heroku 是成功还是失败？”</p><p>&nbsp;</p><p>对此问题，答案分成了两派，正反双方都有很多人参与。一部分人认为Heroku 已经失败了，但是另一部分人恰恰相反——他们认为Heroku 是一个不折不扣的成功。</p><p>&nbsp;</p><p>从成功的角度来讲，以 2.12 亿美元卖给 Salesforce 是一个明显的胜利。但从产品寿命或持久的行业技术方面来说，它又是失败的。</p><p>&nbsp;</p><p>以 2.12 亿美元卖给 Salesforce ，最显而易见的是，在如此规模的收购中，有些人发了财，也给一些新员工享受着高科技薪酬和优厚待遇的条件。</p><p>&nbsp;</p><p>Heroku 的粘附力出乎意料。鉴于这一产品已经多年基本未变，加上市场中的新成员众多，也接受了更大范围的云计算竞争，但是直到今天，Heroku 依然可以成为可信的平台。很多开发者很了解这个产品，并且它的厂商锁定是最低的，让开发者不需要在企业的非核心服务的运营/基础设施上动手。各大云计算提供商都推出了新的业务，这些业务都是为了满足 PaaS 层（像亚马逊云科技那样，也不只是一家），但是直到现在，几乎没有什么公司可以与 Heroku 的简化工作流程和简单操作相媲美。</p><p>&nbsp;</p><p>除此之外，这家公司还做了许多了不起的工作。</p><p>&nbsp;</p><p>外包运维：长期以来，很难在互联网上部署软件。后来，PHP 问世，它的语法简练，部署过程简单，赢得了整个世界，但是也存在许多缺陷。部署一个通用的栈非常困难，那时候，Rails 需要安装一个负载均衡器，为每个服务器提供反向代理，CGI 进程，并且可以随时监控和执行所有必要的操作。Heroku 使这一问题得到了极大的简化，它使开发者集中精力在构建软件上，而非在配置和运行基础设施上。在当今世界，这显然是一种有利条件，但在那时并非如此。Postgres：Postgres 在过去的十年里的发展得益于很多方面的原因，其中包括其卓越的核心进展以及其竞争对手的相对衰退，但是通过使其成为平台提供的核心部分并高调宣传，Heroku 成了平台的重要组成部分。容器：很少有人记得它，但 Heroku 在容器还不流行的时候就已经开始运行了，使用 <a href=\"https://linuxcontainers.org/\">LXC</a>\" 作为其 Cedar 栈的核心技术。CLI：和 Git 本身一样，Heroku 的 CLI 也是该产品中很关键的一环。Unix 命令行工具已有数十年之久，但是一家公司推出一种专用 CLI 还是很有创意的，并且很快就得到了推广。DX 和 CLI：CLI 以及一个广泛的面向开发者的产品，播下了最终发展成 DX 的种子，现在 DX 已经成为科技行业的一个专门分支。Buildpack：Buildpack 是如何部署用特定语言编写的应用的通用公式，是 Dockerfile 的前身，也可以说是一种更合适的抽象层。在 Cedar 栈的初期，自定义 Buildpack 就已经为用户提供了支持。目前，Heroku 之外的其他几个云计算提供商也支持这些技术，比如 <a href=\"https://docs.digitalocean.com/products/app-platform/concepts/buildpack/\">Digital Ocean</a>\" 和 <a href=\"https://cloud.google.com/blog/products/containers-kubernetes/google-cloud-now-supports-buildpacks\">GCP</a>\"。</p><p>&nbsp;</p><p>这是一份相当令人印象深刻的清单——即便是其中的一两个，也会比大多数科技公司在世界上留下的印记更多。</p><p>&nbsp;</p><p>但是，这些项目也有一个共同的潜在趋势——尽管它们的创意很伟大，并且在未来的服务部署方式中会留下持久的印象，但它们都并没有为 Heroku 产品本身带来持久的剩余价值——其他平台抓住了这些概念并获得了收益，即使撇开商业方面，也没有具体的技术会被归于 Heroku。尽管 Docker 作为一家公司可能注定以失败告终，但它将作为基于容器的部署的始祖而被记住几十年。未来关于 2010 年代的历史将谈论 Docker 到 OCI 的演变，但是 Heroku 充其量只能算是一个注脚。</p><p>&nbsp;</p><p>Heroku 是云计算的终极创意工厂——比如 “十二要素应用宣言（The Twelve-Factor App）” 、抗侵蚀和 DX，这些概念将会经得起时间的检验，但是在它们的受益者中，很少有人会认识到它们与 Heroku 的关系。</p><p>&nbsp;</p><p></p><h2>想象力与现实</h2><p></p><p>&nbsp;</p><p>没有多少持久的产品或技术影响是硬币的一面，而另一面，则是对一个拥有无限潜能却从来没有实现过的宏伟愿景感到失望。</p><p>&nbsp;</p><p>Cedar 栈确实是一个真正的天才之作。之前的 Aspen 和 Bamboo 栈都有很大的限制，仅能支持特定栈的特定版本，并且有很多特殊的条件。Cedar 让 Heroku 成为可以运行一切的平台——用户可以通过 Buildpack 和 Procfile 带来自己的栈，它复杂的内部状态机和路由层使得运行在其上的应用变得非常强大。</p><p>&nbsp;</p><p>2012 年，Cedar 的交付势头非常好，虽然取得了巨大的成功，但是它仅仅被认为是一个更加雄心勃勃的项目的第一步。很快，它就会被推广到可以处理不同形状和大小的软件，而现在 512MB 的容器仅仅是附带的第一选项。即使是最大的数据处理应用也可以部署在 10GB 或 100GB 内存的容器上，一直到最小的一次性云 grep 运行只需要几兆字节。如此快速和简单，以至于不在 Heroku 上运行简直就是疯了。</p><p>&nbsp;</p><p>它已经成为模块化。对于大多数用途来说，共享路由器是一个足够的选择，但是大用户可能希望实现自己的路由，从而避开其他企业的云计算，或者提供他们自己高度定制的路由配置。甚至在 Heroku 的“内核”中，你也可以进行交换，因此你仍然可以使用 Heroku 来构建、编排和监控你的应用，但是它们会在你自己的专用单租户服务器上运行。</p><p>&nbsp;</p><p></p><h2>自托管的奇点</h2><p></p><p>&nbsp;</p><p>Heroku 云将变得如此可扩展，如此健壮，就像一个自引导的语言编译器一样，它能够自托管。像平台 API、动态状态机和路由器这样的核心组件，都将作为 Heroku 应用运行，并获得所有 DX 的人体工程学和健壮性。这种充满乐观和雄心勃勃的愿景被称为“自托管的奇点”。</p><p>&nbsp;</p><p>它将是反亚马逊云科技的。亚马逊云科技在新用户首次登录时，就向他们展示了成千上万个错综复杂、相互交叉的原始概念，而 Heroku 公司的愿景就是不让新用户看到。他们从基本的 git push heroku master 和单一的 dyno 应用起步，但是当他们的软件不断发展，他们的要求也越来越复杂，当他们需要的时候，新的原语就会逐渐显露出来，比如带有入口/出口规则的 VPC、带有备选基本镜像或架构的可配置主机。SSH 访问、静态 IP 等等。就像洋葱一样，可以一层一层地剥开。</p><p>&nbsp;</p><p>还有一些其他的东西。“十二要素应用宣言（The Twelve-Factor App）”中的“支持服务”描述了诸如数据库等持久性服务的“额外资源”，它作为孤立的资源存在，能够被任意地附加和分离到更短暂的应用中。Heroku用了好几年的时间来开发这一特性，尽管他们成功了，但是 Heroku 在产品领导力方面的黄金时代已经结束，而且他们也没有取得什么进展来说服别人相信它是个好点子。</p><p>&nbsp;</p><p>定价又是一头难以捉摸的野兽。从免费层跳到付费应用的成本是一个巨大的飞跃，从产品推出的第一天起，用户就抱怨过这个问题。最终，一个新的定价模式确实推出了，但是并没有帮助人们消除最初的忧虑。</p><p>&nbsp;</p><p></p><h2>检查失败</h2><p></p><p>&nbsp;</p><p>那么，到底发生了什么呢？一切成功的基石都已经就位，因此无法实现其雄心勃勃的愿景并非必然。</p><p>&nbsp;</p><p>运营陷入困境：Cedar 进入后，由于一些不能控制的因素（us-east-1 在那段时期尤其糟糕），以及内部因素（有一段时间，Heroku似乎每隔一天就会有一个糟糕的部署），导致了产品的频繁故障，已经升级到了成为生存责任的地步。产品的工作被取消，取而代之的是对运营的支持——设置指标、警报、安全部署流程，并且广泛地建立运营能力。产品周期：尤其是初期，没有制度上的框架来交付新特性。这是有可能的，但是经常需要你自己发出拉取请求或者给某个人发送一个请求来帮助你修改。即使有推动新特性的强烈动机，它也常常会从组织/服务的边界中消失殆尽。Heroku也存在着令人不齿的退化情形，比如将组织功能构建在核心 API 之上，变成了一个单独的微服务，这是由于没有任何使其更加集成的机制。Docker 视野狭隘：Docker 的第一个版本引起了如此大的轰动和广泛的兴趣，以至于Heroku之中的很多人对它产生了一种不健康的痴迷。Heroku的前员工说道：“我们内化了一种失败主义的态度，认为 Docker 容器是未来，而我们所做的是过去的事。”从某些方面来说，这是对的，但是Dockerfile 仍然是非常低的抽象层次，低到有些不可取。我们现在所见，容器技术已经成为许多部署栈的基石，但更多的是作为一种原始技术，其中有许多技术可以提高其工作效率。在很多方面，Buildpack 对应用开发者来说，是一个更好的抽象层，他们不必为任何事情编写 Dockerfile，只要用 Gemfile、Cargo.toml 或 go.mod 等栈中常用的工具，然后让构建过程找出如何将其“烘焙”成一个可部署的镜像。从那以后，如果说基础层需要更新，或者某种编程语言的次要级别/补丁级别需要更新，都可以广泛地进行，而不必调整每个项目的 Dockerfile。下一个栈的固定性：Heroku 的栈是以树命名的。Aspen、Bamboo、Cedar。Cedar 比 Bamboo 有了质的飞跃，虽然Heroku的下一个目标是建立一个比 Cedar 更好的栈，就像 Cedar 比 Bamboo 好一样，但在这种情况下，员工会把 Cedar 作为一个过去的种子埋在他们的脑海里，从而阻碍了他们对它的大量投资。回顾过去，从目前可用技术的融合情况来看，可能并没有一种栈能比 Cedar 好得多，就像 Cedar 对 Bamboo 那样。最好还是把精力集中在逐步改善 Cedar 上，而不要在地平线上找什么“灵丹妙药”。构思者/运营者的分歧：作为一家大公司内部资金雄厚的小公司，曾经有过一段时期，我们有一个相当独特的情况，就是雇佣了一批员工，他们花费大量的时间进行实验、原型设计和创意，就好像在公司内部开着一个小型的贝尔实验室或者施乐 PARC。隔着篱笆，就是那些顽固的服务工程师，他们经常忙于解决运营问题，很少露面。构思者们没有能力把所有的事情都投入到生产中，同时，运营人员也没有足够的时间和精力去进行实质性的产品改善。这导致了很酷炫的内部演示，但是可以预料的是，他们不会有所动作。</p><p>&nbsp;</p><p>总而言之，特别是考虑到之前发生的安全问题，Heroku 作为一个自维持的产品是一个失败。作为一个多产的思想创造者，以及无数当前和未来工具和平台的直接祖先，Heroku 取得了巨大的成功。</p><p>&nbsp;</p><p>参考资料：</p><p>Heroku的下一章：<a href=\"https://blog.heroku.com/next-chapter\">https://blog.heroku.com/next-chapter</a>\"</p><p><a href=\"https://xeiaso.net/blog/rip-heroku\">https://xeiaso.net/blog/rip-heroku</a>\"</p><p>如何理解Heroku提出的12要素应用？<a href=\"https://mp.weixin.qq.com/s/EUPo12ZPpBp_P1b7wouYtw\">https://mp.weixin.qq.com/s/EUPo12ZPpBp_P1b7wouYtw</a>\"</p><p>Heroku 的衰落：<a href=\"https://www.infoq.cn/article/gvcgP6XitdHjy169oAk5\">https://www.infoq.cn/article/gvcgP6XitdHjy169oAk5</a>\"</p><p><a href=\"https://brandur.org/nanoglyphs/033-heroku\">https://brandur.org/nanoglyphs/033-heroku</a>\"</p>",
    "publish_time": "2022-08-31 15:32:53",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "资深Web开发的经验之谈：为什么你开发的网页不应该大于14KB？",
    "url": "https://www.infoq.cn/article/r1BGRqibOqE5exgoPMqi",
    "summary": "<p></p><blockquote>虽然我们生活在一个宽带无处不在、4/5G 几乎全覆盖的时代，但网站加载缓慢还是常态，就算我们打开一个以文本为中心的新闻网站，都可能需要至少30秒才能开始阅读。毕竟在内容膨胀时代，一张照片就能轻易超过1MB大小，许多网站为了显示几段文本，还会单独加载至少 10MB 的 JS 和自定义字体。&nbsp;对此，对优化和极简主义充满热情的资深Web开发Nathaniel告诉我们，你应该让你的网页尽力控制在14KB以内，而且即使对于以富媒体为中心的网站，这条 14KB 的规则可能仍然值得遵循。如果 14KB 不足以用于最终布局，则需要优先考虑“首屏”字节，可以用发送给访问者的前14KB数据来渲染一些有用的东西，减少用户还没有开始阅读就流失掉的机会。</blockquote><p></p><p>&nbsp;</p><p>网页越小，加载速度就越快——这一点都不奇怪。</p><p>&nbsp;</p><p>但令人感到惊讶的是，14KB网页的加载速度比15KB要快得多——可能快612毫秒——而15KB和16KB网页之间的加载速度差异微乎其微。</p><p>&nbsp;</p><p>这是TCP慢启动算法导致的。本文将介绍这个算法、它的原理以及为什么你应该关注它。但首先我们需要快速过一遍一些基础知识。</p><p>&nbsp;</p><p></p><h2>TCP是什么</h2><p></p><p>&nbsp;</p><p>传输控制协议（Transmission Control Protocol，TCP）是一种使用IP协议可靠地发送数据包的方法——有时被称为TCP/IP。</p><p>&nbsp;</p><p>当浏览器向你的网站（或图像或样式表）发出请求时，它会使用HTTP请求。HTTP建立在TCP之上，一个HTTP请求通常由许多TCP数据包组成。IP只是一个将数据包从互联网上的一个位置发送到另一个位置的系统。IP没有检查数据包是否成功到达目的地的方法。</p><p>&nbsp;</p><p>对于网站来说，确保所有的数据到达请求端是非常关键的，否则我们可能会因为丢失数据包无法获得完整的网页。但在网络的其他应用场景中，这一点并不那么重要——比如流媒体直播视频。</p><p>&nbsp;</p><p>TCP是IP的扩展，浏览器和网站服务器通过它告诉对方哪些数据包已经成功到达。</p><p>&nbsp;</p><p>服务器发送一些数据包，然后等待浏览器已经收到数据包的响应（这叫确认或ACK），然后它继续发送更多的数据包——或者如果它没有收到ACK，将再次发送相同的数据包。</p><p>&nbsp;</p><p></p><h2>什么是TCP慢启动</h2><p></p><p>&nbsp;</p><p>TCP慢启动是一种算法，服务器用它来确定一次可以发送多少数据包。</p><p>&nbsp;</p><p>当浏览器第一次连接到服务器时，服务器无法知道它们之间的带宽是多少。带宽是指在单位时间内网络可以传输的数据量。通常以比特/秒（b/s）为单位。我们可以用管道来作类比——把带宽想象成每秒从管道流出多少水。</p><p>&nbsp;</p><p>服务器不知道网络连接可以处理多少数据——所以它先发送少量且安全的数据——通常是10个TCP数据包。如果这些数据包成功地到达网站访问者，他们的计算机返回确认（ACK），表示数据包已经被收到了。然后，服务器发送更多的数据包，但这一次它将数据包的数量增加了一倍。</p><p>&nbsp;</p><p>这个过程会不断重复，直到数据包丢失，服务器没有收到ACK。（此时，服务器会继续发送数据包，但速度较慢）。</p><p>&nbsp;</p><p>这就是TCP慢启动的要点——在现实当中，虽然算法各不相同，但这是它的基本原理。</p><p>&nbsp;</p><p></p><h2>那么14KB这个数字是怎么来的</h2><p></p><p>&nbsp;</p><p>大多数Web服务器的TCP慢启动算法都是从发送10个TCP数据包开始的。</p><p>&nbsp;</p><p>TCP数据包最大长度为1500字节。这个最大值不是由TCP规范设置的，它来自于以太网标准。</p><p>&nbsp;</p><p>每个TCP数据包的标头占了40个字节，其中16个字节用于IP，另外24个字节用于TCP。</p><p>&nbsp;</p><p>这样每个TCP数据包还剩下1460个字节。10 x 1460 = 14600字节，或大约14KB！</p><p>&nbsp;</p><p>因此，如果你能把网站的网页——或网页的关键部分——压缩到14KB，就可以为访问者节省大量的时间——他们和网站服务器之间的往返时间。</p><p>&nbsp;</p><p>一个数据往返能有多糟糕？但人们非常没有耐心——一个数据往返可能会出奇地长，具体多长取决于延迟……延迟是指数据包从源传输到目的地所花费的时间。如果带宽是每秒钟可以通过管道的水的数量，那么延迟就是一滴水进入管道后从另一端流出所花费的时间。</p><p>&nbsp;</p><p>下面是一个关于延迟有多糟糕的例子。</p><p>&nbsp;</p><p></p><h4>卫星网络</h4><p></p><p>&nbsp;</p><p>卫星网络是由环绕地球轨道的卫星提供的，在人烟稀少的地区、石油钻井平台、游轮以及飞机上，人们可以使用这种网络。</p><p>&nbsp;</p><p>为了说明这种糟糕的延迟，我们想象一群在石油钻井平台工作的兄弟把骰子忘在了家里，他们需要通过missingdice.com（少于14KB）来玩《龙与地下城》游戏。</p><p>&nbsp;</p><p>首先，他们中的一个用手机发出一个网页请求……</p><p>&nbsp;</p><p>手机将请求发送到钻井平台的WiFi路由器，路由器将数据发送给平台上的卫星天线，我们假设这可能需要1毫秒时间。</p><p>&nbsp;</p><p>然后，卫星天线将数据发送到地球轨道上方的卫星。</p><p>&nbsp;</p><p>通常，这是通过在地球表面上方35786公里处运行的轨道卫星实现的。光速为299792458米/秒，所以信息从地球发送到卫星需要120毫秒。然后，卫星将信息传回地面接收站，这又需要120毫秒。</p><p>&nbsp;</p><p>然后，地面站必须将请求发送到位于地球任意位置的服务器（当光通过光纤电缆传输时，速度会降至每秒200000000米）。如果地面站和服务器之间的距离等于纽约到伦敦之间的距离，那么大约需要28毫秒，如果地面站和服务器之间的距离等于纽约到悉尼之间的距离，则需要80毫秒——所以我们姑且定一个60毫秒的数字（这个数字便于计算）。</p><p>&nbsp;</p><p>然后，服务器需要处理请求，这可能需要10毫秒，然后服务器再次将它发送出去。</p><p>&nbsp;</p><p>回到地面站，进入太空，回到卫星天线，然后回到无线路由器，再到手机上。</p><p>&nbsp;</p><p></p><blockquote>手机 -&gt; WiFi路由器 -&gt;卫星天线 -&gt;卫星 -&gt; 地面站 -&gt; 服务器 -&gt; 地面站 -&gt; 卫星 -&gt; 卫星天线 -&gt;&nbsp;WiFi路由器 -&gt; 手机</blockquote><p></p><p>&nbsp;</p><p>如果我们算一下，就是10 + ( 1 + 120 + 120 + 60 ) x 2 = 612毫秒。</p><p>&nbsp;</p><p>这是每次往返额外的612毫秒——也许这看起来不是很长时间，但你的网站可能只是为了获取第一个资源就需要许多个往返。</p><p>&nbsp;</p><p>另外，HTTPS在完成第一个往返之前需要额外的两次往返——这使延迟达到了1836毫秒！</p><p>&nbsp;</p><p></p><h4>对于生活在陆地上的人，延迟又是怎样的</h4><p></p><p>&nbsp;</p><p>卫星网络似乎是一个极端的例子——我选择它作为例子是因为它能够充分说明了网络延迟这个问题——但对于生活在陆地上的人来说，延迟可能比这更糟糕，原因有很多。</p><p>&nbsp;</p><p>2G网络的延迟通常在300毫秒到1000毫秒之间；3G网络的延迟可以在100毫秒到500毫秒之间；嘈杂的移动网络——比如在一个异常拥挤的地方，比如音乐节；处理大流量的服务器；其他一些不好的东西。</p><p>&nbsp;</p><p>不稳定的网络连接也会导致数据包丢失——导致需要另一个往返来获取丢失的数据包。</p><p>&nbsp;</p><p>了解了14KB法则，接下来可以做些什么</p><p>&nbsp;</p><p>当然，你应该让你的网页尽可能的小——你爱你的访客，你希望他们开心。将每个页面的大小控制在14KB以内是一个不错的主意。</p><p>&nbsp;</p><p>这14KB可以是压缩数据——所以实际上可以对应大约50KB的未压缩数据——这已经非常慷慨了。要知道，阿波罗11的制导计算机只有72KB内存。</p><p>&nbsp;</p><p>去掉自动播放的视频、弹出窗口、Cookie、Cookie横幅、社交网络按钮、跟踪脚本、JavaScript和CSS框架，以及所有其他人们不喜欢的垃圾——你可能就能实现14KB法则。</p><p>&nbsp;</p><p>假设你已经尽力将所有内容控制在14KB以内，但仍然做不到——但14KB法则仍然很有用。</p><p>&nbsp;</p><p>你可以用发送给访问者的前14KB数据来渲染一些有用的东西——例如一些关键的CSS、JS和解释如何使用你的应用程序的前几段文本。</p><p>&nbsp;</p><p>需要注意的是，14KB法则包含了HTTP标头——这些是未压缩的（即使是HTTP/2的第一个响应），也包含图片，所以你应该只加载在页面上方的内容，并保持它们最小，或者使用占位符，让访问者知道他们在等待一些更好的内容。</p><p>&nbsp;</p><p></p><h4>关于这个法则的一些注意事项</h4><p></p><p>&nbsp;</p><p>14KB法则更像是一种经验之谈，而不是计算的基本法则。</p><p>&nbsp;</p><p>一些服务器已经将TCP慢启动初始窗口从10个数据包增加到30个；有时服务器知道它可以从更大数量的数据包开始传输，因为它使用TLS握手来建立一个更大的窗口；服务器可以缓存路由可管理的数据包数量，并在下一次连接时发送更多的数据包；还有其他需要注意的地方——这里有一篇文章更深入地探讨关于为什么14KB法则并不总是这么回事（<a href=\"https://www.tunetheweb.com/blog/critical-resources-and-the-first-14kb/\">https://www.tunetheweb.com/blog/critical-resources-and-the-first-14kb/</a>\"）。</p><p>&nbsp;</p><p></p><h4>HTTP/2和14KB法则</h4><p></p><p>&nbsp;</p><p>有一种观点认为，在使用HTTP/2时，14KB法则不再适用。我已经读了所有我能读到的关于这个问题的东西，但我还没有看到任何证据表明使用HTTP/2的服务器已经停止使用TCP慢启动（从10个数据包开始）。</p><p>&nbsp;</p><p></p><h4>HTTP/3和QUIC</h4><p></p><p>&nbsp;</p><p>与HTTP/2类似，有一种观点认为HTTP/3和QUIC将废除14KB法则——事实并非如此。实际上，QUIC仍然建议使用14KB法则。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://endtimes.dev/why-your-website-should-be-under-14kb-in-size/\">https://endtimes.dev/why-your-website-should-be-under-14kb-in-size/</a>\"</p>",
    "publish_time": "2022-08-31 15:44:39",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从纯软件转发到软硬一体化可编程，腾讯云网关技术演进之路",
    "url": "https://www.infoq.cn/article/kCGa64yBCdv1AOdiXic8",
    "summary": "<p></p><p></p><p>近十年来，国内的云计算业务取得了长足的进步，越来越多的企业认识到云的价值，将业务部署在云上，云也为客户提供了存储、计算、数据库、安全、大数据等丰富的服务。云服务规模的爆发式增长，对网络提出了巨大的挑战，传统网络方式已无法满足大规模云应用阶段网络的诉求，主要有以下几个方面。</p><p></p><p>网络规模巨大，短视频、直播等业务应用快速发展，导致单一客户动辄要求 10T 级别带宽，10 万级别路由，数以万计的客户叠加情况下对网络系统规格挑战巨大；网络弹性要求高，客户业务发展变化快，并且存在秒杀、大促、公共突发事件、热点事件等正常业务活动，仅靠堆料式运营方式成本难以为继，网络需要具备极强的弹性能力；业务特性繁多，不同场景需求各不相同，有状态的、无状态的、加密的、非加密的、安全的、加速的等等，没有任何一个单一网络应用能解决所有问题；精细化调度要求高，不同客户对网络质量、网络成本要求各不相同，在越来越多的场景存在基于业务的精细化调度诉求；大象流、微突发等问题频发，业务吞吐的飙升、高性能网络应用的普及，导致网络面临大量的大象流、微突发问题，对转发性能、数据面定位能力等要求极高；</p><p></p><p>针对这些挑战，我们通过多年不断的尝试和技术革新，由早期的纯软件转发平台，演进到基于可编程硬件的转发平台，再到软硬一体化的可编程网络平台，提高了云网络的弹性能力，降低了网络运营成本，为各类云服务的大规模应用铺平了道路。</p><p></p><p></p><h2>腾讯可编程网络技术演进</h2><p></p><p></p><p>腾讯探索可编程网络相关技术，主要目的是降低网络运营成本、提升网络质量。早期也曾使用过专用硬件方式，例如使用 tilera 众核芯片的专用服务器等，随着开源社区 DPDK 的成熟，逐步迁移到了基于通用 x86 CPU 的 DPDK 平台，形成了可编程网关平台 1.0。可编程网关平台 1.0 主要基于 DPDK 的 PMD 能力，通过内存零拷贝、大页、无锁队列等方式极大的提高了网络处理性能，早期支持了 10G 级处理能力，后来随着硬件网卡和 CPU 能力的提升，逐步演进到 100G 级处理能力。由于底层基于通用的 x86 CPU 实现，可编程网关平台 1.0 最大的优势就是可编程能力极强，可以实现任意行为的网络处理能力，例如 L3 转发、VPN、LB、NAT、DPI、IDS 等等。同时，由于本身基于通用服务器实现，天然能够和虚拟化技术结合，支持基于业务需求的弹性扩展能力，实现了资源复用，提高了资源的利用率。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/36/367eaefd9e20e0d3e543c5d8e64470a4.png\" /></p><p></p><p>图 1 可编程网关平台演进</p><p></p><p>可编程网关平台 1.0 在网络应用的发展过程中起到了非常重要的作用，实现了很多网络业务从无到有的突破。但随着业务的持续演进和现网的大规模运营，数据面平台 1.0 逐渐碰到一些问题。首先，随着 4G/5G 基础设施的快速完善，以及以短视频、直播为主的视频类业务的快速发展，网络带宽需求在爆炸式增长，但基于服务器的网络处理能力，仍然停留在百 G 级别，无法跟上业务的增长。导致需要使用大量的服务器资源来扛住业务流量，以一个 6.4T 业务集群为例，需要 128 台服务器资源才能扛住所有的业务流量，运营成本极高。</p><p></p><p>其次，在硬件升级和技术演进的助力下，云上业务的处理性能同步得到大幅提升，导致频繁出现大象流、微突发等网络问题。这类问题由于出现时间短、难以复现，通常很难定位，但出现这类问题时通常会伴随网络丢包和业务抖动，并且会出现多租户之间互相串扰，严重影响客户体验，因而对基于服务器构建的网络系统产生了巨大的挑战。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/70/70f7069d0dca6cd38da730c07cdc3bc6.png\" /></p><p></p><p>图 2 网络带宽与服务器硬件演变趋势</p><p></p><p>基于服务器处理网络业务可行的最主要原因，是充分利用了服务器的多核并行处理能力，实现了性能的大幅度提升，满足了网络传输的高性能转发诉求。而产生上述这些挑战的根本原因，也是在于服务器的系统架构在处理更大规模网络流量方面并不擅长。网络流量流经服务器的典型路径是由网卡收发报文，再通过 PCIe 总线将数据 DMA 到内存，再由 CPU 来处理内存中的数据，整个处理过程非常漫长，需要经历至少 4 种不同的物理器件，导致成本很难降低，并且任意器件的性能问题都会导致整体性能变差。以 CPU 为例，最近十年间，由于 CPU 制程工艺逐渐接近物理极限，摩尔定律放缓成为事实，依靠 CPU 制程提升来提升处理性能的方法已不可持续。在此背景下，单核性能基本趋近于极限，大多数 CPU 厂商采用多核架构来提升性能。这种趋势的问题在于微突发问题严重依赖单核处理性能，同时共享数据的存在使得网络处理性能无法随核数线性扩展。其他硬件单元，如网卡、PCIe 总线、内存等，也存在类似的问题。从图 2 可以看到网络带宽在近十年取得了爆发式的增长，CPU 制程、PCIe 传输率等影响硬件处理性能的关键指标增长却越来越平缓。在这种背景下，可编程硬件为解决这些问题提供了一种全新的思路。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d0/d0ee90d73823f60555ffd851d2bb09b0.png\" /></p><p></p><p>图 3 可编程网关平台 2.0 软件架构</p><p></p><p>可编程网关平台 2.0 基于可编程硬件构建，实现了 Tbps 级别数据转发能力，相比 1.0 提升了一个数量级，同时成本也得到大幅度优化。在可编程网关平台 2.0 中，数据面流量不再需要经过复杂的物理器件路径，仅在一颗 ASIC 芯片上就可以完成所有的处理逻辑，处理过程十分高效。同时，通过 P4 语言实现了对数据面流水线的灵活编程，以满足业务灵活的可编程诉求。在 2.0 阶段，由于所有业务逻辑基于可编程芯片实现，受限于芯片 SRAM/TCAM 等表项资源限制，业务规格无法做到太大。虽然通过流水线折叠方可以一定程度缓解这类问题，但在某些要求超大规格的网络场景就无法适用。针对这种情况，我们推出了可编程网关平台 3.0，通过软硬件一体化方式，充分发挥异构硬件的优势，通过软硬协同实现超大规模 Tbps 级数据面处理能力。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7e/7e0f0ad5d7ced4ae545ead85800fd741.png\" /></p><p></p><p>图 4 可编程网关平台 3.0 硬件架构</p><p></p><p>可编程网关平台 3.0 将可编程 ASIC、FPGA、高性能 CPU 一体化，并且通过模块化的硬件设计，实现针对不同场景的灵活定制，满足全业务场景的高性能可编程诉求。在一些业务规格要求不高的场景，可以通过低配 CPU+ 可编程 ASIC 退化为类似 2.0 的方式应用，尽可能减少成本，提高资源利用率。在一些业务规格要求较高的场景，可以通过 FPGA 扩展的方式实现大规格表项，满足业务大规格诉求。在一些特殊应用场景中，还可以将高性能 CPU 作为数据面慢路径，可编程 ASIC 作为快路径，通过软硬协同方式满足特殊场景需求。</p><p></p><p>可编程网关平台已经在腾讯网络中大规模部署应用，以下内容将就可编程网关平台的典型应用场景进行介绍。</p><p></p><p></p><h2>企业专线接入</h2><p></p><p></p><p>许多企业客户基于既有资源利用、数据安全、合规要求等原因，会采用混合云的方式来利用云上的各种服务。如何将企业云上资源与自有资源打通是一个重要问题，企业专线接入是解决这种问题最常用的手段之一。腾讯企业专线接入服务的主要特点是能够提供大带宽、低时延、高性能、高可靠的专线接入能力，可编程网关平台是提供这些能力的基础。目前基于可编程网关平台，腾讯企业专线接入服务已支持 10Tbps 级别带宽接入，2us 转发时延，单机支持 Tbps 级转发能力，在可靠性方面支持多线接入、跨 AZ 容灾、单节点 NSR 等能力，为企业客户业务上云提供了坚实可靠的底层能力。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3d/3de1895b5af2b130857016ba7749e0cb.png\" /></p><p></p><p>图 5 企业专线接入</p><p></p><p>数据面可编程能力在企业专线接入场景有多方面的应用。在基础互联互通能力方面，为保护客户私有数据的安全性，腾讯云采用了定制 GRE 的方式来实现 Overlay 隔离，基于可编程网关平台可以便捷的实现这种定制转发行为，实现租户之间的安全隔离。同时，企业专线服务需要具备软件能力迭代、故障处理、跨 AZ 容灾等能力，这些能力要求数据面能够高效响应业务变化，并且在变化过程中业务无感知，可编程网关平台通过 RPC 方式与云上各类业务系统联动，支持快速故障感知、秒级业务迁移。另外，作为网关类型业务，企业专线业务要屏蔽云上网络细节，因此专线网关上需要支持大规模路由表项的维护，大型企业客户甚至达到 10 万级别的路由量，可编程网关平台通过流水线折叠扩展了业务表项，满足了大规格业务需求。</p><p></p><p></p><h2>运营商公网接入</h2><p></p><p></p><p>云上客户存在一个普遍诉求就是通过云上资源触达用户，运营商公网接入主要承载此类业务。早期腾讯运营商公网接入主要依赖商业设备来实现，但传统网络解决方案主要基于路由相关策略进行业务支持，无法精细化感知业务细节。通过可编程网关平台可以基于业务应用进行差异化调度，提升公网服务能力。以精品网业务为例，云上众多客户对网络质量要求各不相同，有些要求时延低，有的要求带宽高，有些要求成本低。而公网资源十分宝贵，如果对每个客户都采用相同的策略提供公网服务，将无法满足客户个性化需求，也无法收回成本。将质量敏感成本不敏感的业务走质量较好的链路，成本敏感但质量容忍度高的业务走带宽较大的链路，通过这种方式将网络流量分而治之，为不同客户提供差异化服务。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/62/6261e1530a72671fa924b461910ce2d0.png\" /></p><p></p><p>图 6 BGP 精品网服务</p><p></p><p>通过可编程网关，可以将不同的客户不同的业务区分开来，达到差异化服务的目的。可编程能力在公网服务中应用较多。在基础业务特性上，通过基于源 IP 选路的方式实现业务感知，公网服务通常是基于 IP 来提供服务的，通过源 IP 进行路径选择，可以较好的基于业务诉求来调整网络路径，实现差异化服务。另外，公网服务本身为公域流量提供服务，难以避免的存在网络攻击等安全问题，通过可编程网关可以在公网入口将流量调度到腾讯安全清洗中心，保证正常业务的安全。公网业务可编程应用较多，这里不再赘述，可编程网关平台丰富了公网业务的武器库，为公网业务的进一步演进提供了可能性。</p><p></p><p></p><h2>边缘互联网络</h2><p></p><p></p><p>随着分布式云的出现，大量客户选择根据业务的特点将云计算资源分布式地部署在中心云、边缘云，甚至是客户机房以取得性能和成本的折中。趋势之一是越来越多的云资源被部署在靠近数据和业务发生的网络边缘，以满足高带宽、低时延、数据不出局等需求。分布式云的典型场景包括在线课堂、自动驾驶、云游戏、AR/VR 等对带宽和时延有着严苛要求的新兴应用。</p><p></p><p>分布式云的快速生长引入了大量的边缘云节点，将原本只连接中心云的骨干网络（DCI/vDCI）通过互联网向外扩张，形成了复杂、异构的边缘互联网络。传统的骨干网通常由稳定的大容量专线提供业务承载，边缘互联网络则由互联网承载，如何在不安全、欠稳定的互联网之上构建高可靠、高性能的边云、边边互联是我们发展分布式云遇到的全新课题；边缘云节点规模小，通常只能容纳数百台服务器，如果照搬中心云的设计，用于部署机房间加密互通、VPC 互通、虚实互通、NAT 等功能的网关服务器将占据 15%~30% 的机架空间，大大增加了边缘云节点的成本。如何通过软硬一体化设计融合网关功能降低网关成本是我们遇到的另一关键问题。此外，边缘互联网络发展过程中还涌现出了其他新的问题，包括但不限于智能化的管控、灵活的选路、路径优化等等。为此我们基于可编程网关平台 3.0 研发了新一代超融合边缘网关 HyperSGW, 以满足边缘互联网络在新功能、低成本、高集成度方面的诸多需求。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c1/c1bc432cd90d743e20c0bb0534501027.png\" /></p><p></p><p>图 7 边缘网关系统架构</p><p></p><p>通过 HyperSGW 我们实现了多种适用于边缘场景的特性。</p><p></p><p>首先，实现了多链路优选，实时调度，支持边云、边边加速。腾讯中心 - 边缘一体化网络是由成百上千个 HyperSGW 构成的 full mesh 网络，任意两个边缘节点的 HyperSGW 之间存在多条不同运营商提供的直连（边边互联）和非直连（边 - 云 - 边）链路。不同运营商的链路在成本和质量上存在一定的差异性，而同一链路的质量（时延、带宽、丢包率）随网络负载的波动呈时变特性，使得租户的链路优选变成了一个含时间参数的动态规划问题。结合 HyperSGW 的高精度立体探测机制，控制器系统实时采集网络拓扑和节点流量，周期性地更新优化问题的约束条件，求取最优解并下发转发面，实现租户的全局路径优化和边云、边边加速。</p><p></p><p>另外，实现了基于成本、时延、质量的意图转发，满足云租户的个性化网络需求。利用 HyperSGW 的可编程能力，支持业务自定义调度标识，帮助客户按照不同的业务类型进行差异化调度选择。通过与底层物理网络在控制面和转发面的联动提供灵活的多级调度，客户可以在多个网络路径中，按需选择时延最低、成本最低或质量最优的线路。我们通过自研的多目标多约束调度算法，实现了客户可自定义的、多维度组合的调度策略，比如“在满足指定的时延范围内，选择成本最低的线路”，“在满足指定可用率范围内，选择时延最小的线路”等等，以尽可能满足云租户个性化的网络需求。</p><p></p><p></p><h2>结&nbsp; &nbsp;语</h2><p></p><p></p><p>互联网建立至今的数十年时间里，网络一直在不断演进，实现了人、信息、商品、服务等各种元素的丰富连接。在这个过程中，网络的承载技术也在不断演进，从早期的窄带宽带，到移动互联网，到现在的云网络时代。可编程网络为大规模云上服务而生，是云上服务与企业客户、终端用户之间的桥梁。在可编程网关平台的助力下，云网络将为不同的客户不同的应用提供更加灵活、高效、安全的连接服务。</p><p></p><p>作者简介：</p><p></p><p>郑胜利，腾讯网络平台部网关团队负责人，致力于网络领域产品研发，先后负责腾讯公网传输系统、对等连接、专线接入网关、公网接入网关等产品研发，熟悉高性能包处理、可编程硬件、高可靠 BGP 等网络技术。</p><p></p>",
    "publish_time": "2022-08-31 16:08:28",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]