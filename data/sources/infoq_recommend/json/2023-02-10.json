[
  {
    "title": "第二届湾区金融科技高校分论坛暨 2022 深圳国际金融科技大赛——西丽湖金融科技大学生挑战赛颁奖典礼",
    "url": "https://www.infoq.cn/article/JiD6qU8GNwgKA4lhg98e",
    "summary": "<p>2 月 4 日，由深圳市地方金融监督管理局、深圳市福田区人民政府、深圳市南山区人民政府担任战略指导单位，并由深大微众金融科技学院、微众银行、深圳香蜜湖国际金融科技研究院、深圳大学大数据经济与金融研究中心主办第二届湾区金融科技高校分论坛暨“2022 深圳国际金融科技大赛——西丽湖金融科技大学生挑战赛”颁奖典礼于深圳五洲宾馆隆重举行并圆满落幕。</p>\n<p>本次活动主要分为“2022 深圳国际金融科技大赛——西丽湖金融科技大学生挑战赛”颁奖仪式、产学研多方金融科技合作项目揭牌仪式、金融科技人才培育相关主题演讲、雨燕基金课题报告分享及第二届雨燕基金发布仪式四大部分。深圳大学党委书记李清泉、深圳市地方金融监督管理局党组成员、副局长王新东、微众银行首席人工智能官杨强教授和来自深圳大学、浙江财经大学、对外经济贸易大学等高校以及微众银行、江南银行等企业的多位领导专家出席了本次活动，共同打造了一场集产学研多元视角、绝对前沿视野、开放创新的顶级金融科技交流盛宴，吸引了近百名金融科技教育者、从业者来到现场。</p>\n<p>湾区金融科技高校论坛迄今已连续成功举办两届，是由产学研多方联袂打造的年度行业级论坛事件，今年紧扣深圳市首届金融科技节主题的同时，希望将每年的高校论坛活动打造成学术教育圈的标杆型金融科技活动，助力大湾区高水平金融科技人才高地建设，为深圳市抢抓金融科技发展机遇、加快金融科技产业升级注入一股强势力量。</p>",
    "publish_time": "2023-02-10 05:35:45",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "PyTorch-Nightly受到供应链攻击，导致数据和文件泄露",
    "url": "https://www.infoq.cn/article/Y6mQzGwyHoNMeyZsWIuE",
    "summary": "<p>&nbsp;<a href=\"https://pytorch.org/blog/compromised-nightly-dependency/\">PyTorch维护者</a>\"表示，建议在2022年12月25日至12月30日期间安装了PyTorch夜间构建的开发人员卸载它并清除pip缓存，以摆脱恶意包。新的攻击凸显了最近的一个趋势。</p><p>&nbsp;</p><p>供应链攻击源自一个恶意依赖项。该依赖项被推送到了PyPi，它与PyTorch夜间构建附带的依赖项同名。</p><p>&nbsp;</p><p></p><blockquote>由于PyPI是索引优先的，所以安装的是这个恶意包，而不是官方存储库中的版本。这种设计允许用户注册与第三方索引中存在重名的包，pip将默认安装他们的版本。</blockquote><p></p><p>&nbsp;</p><p>该恶意包名为torchtriton，包含一个二进制文件，除了窃取主机名、DNS配置、用户名、shell环境等系统信息外，还会将/etc/hosts、/etc/passwords、~/.gitconfig、~ /.ssh /*的内容，以及在用户主目录中找到的前1000个文件上传到外部服务器。不过，只有当用户显式地将triton包导入到他们的程序中时，信息才会被泄露，这降低了此次攻击的影响。</p><p>&nbsp;</p><p>这种被称为依赖混淆的供应链攻击方案并不新颖。在接受InfoQ采访时，Endor Labs安全研究员Henrik Plate解释说，这种攻击“与我们在过去两年中看到的次世代攻击类型一致”，攻击者的重点是操纵维护者和用户，而不是设法利用漏洞。</p><p>&nbsp;</p><p>在官方披露后，torchtriton的所谓维护者在他们的网站上宣称，这个包不是恶意的。对此，Ax Sharma首先在Twitter上做了<a href=\"https://twitter.com/Ax_Sharma/status/1609586774204116994?s=20\">报道</a>\"。不过，在<a href=\"https://www.bleepingcomputer.com/news/security/pytorch-discloses-malicious-dependency-chain-compromise-over-holidays/\">分析</a>\"Bleeping Computer的攻击时，Sharma还透露，torchtriton使用了反虚拟机技术以及混淆来逃避检测。</p><p>&nbsp;</p><p></p><blockquote>这也不是第一次有黑客声称他们的行为应算是伦理研究，就像他们被抓到窃取机密一样。</blockquote><p></p><p>&nbsp;</p><p>根据Plate的说法，依赖项混淆攻击可以使用私有存储库来托管内部包和镜像外部包来解决。Python生态系统有一个这样的解决方案是<a href=\"https://github.com/devpi/devpi\">devpi</a>\"，但它并不简单。</p><p>&nbsp;</p><p></p><blockquote>通常，这样的解决方案允许对依赖项解析和包下载过程进行更多的控制。但是，它们的设置和操作需要付出不小的努力，并且只有在开发人员本地客户端配置正确时，它们才有效。</blockquote><p></p><p>&nbsp;</p><p>PyTorch维护者立即采取行动，删除作为依赖项的torchtriton，替换为<a href=\"https://github.com/pytorch/pytorch/pull/91539\">pytorch-triton</a>\"，并在PyPi上注册了一个假包，以确保这种情况不会再发生。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/01/pytorch-supply-chain-attack/\">https://www.infoq.com/news/2023/01/pytorch-supply-chain-attack/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/OYS7T01SgBBZvCqNT04E\">里程碑！PyTorch 正式加入 Linux 基金会，社区治理这一核心将不会改变</a>\"</p><p><a href=\"https://www.infoq.cn/article/7Azz9NMpjuI4zmV4S4oC\">深度学习为什么要选择 PyTorch</a>\"</p><p><a href=\"https://xie.infoq.cn/article/579fa337d715f17aef15e4c6e\">进击的 PyTorch，和它背后的开源领袖</a>\"</p>",
    "publish_time": "2023-02-10 10:16:05",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "2023年软件测试、人工智能和机器学习趋势",
    "url": "https://www.infoq.cn/article/gGEedWvlMcRU8FS2tBAz",
    "summary": "<p></p><blockquote>本文要点2023年和未来几年将发生重大的变化，这些变化将在大大小小的方面影响软件测试行业，因此，你应该开始研究如何使用人工智能（AI）和机器学习（ML）来改进测试流程，利用基于人工智能的安全工具，并实施基于风险的测试，如可以利用大数据洞察的基于风险的测试。软件测试趋势——在疫情期间，需要快速重塑商业模式或添加新功能来处理远程工作/生活。开发人员的需求旺盛，供不应求，导致了对更多编程专业知识进行测试的矛盾需求，以及对这些编程技能更多的竞争。机器学习改变软件测试——软件应用程序不断变化，因为用户希望不断更新其他功能或业务流程；然而，这些更改通常会导致自动化测试不再能正常工作。我们在测试中使用机器学习的第一种方式是使当前的自动化测试更具弹性，更不那么脆弱。人工智能如何改变安全测试——人工智能有望以多种方式来改变网络安全行业，我们现在看到，人工智能首次被用于定位和探测系统，以主动发现薄弱点和漏洞。新的角色和职业——随着人工智能变得越来越主流，很可能会出现尚未被我们发明出来的全新的职业领域。</blockquote><p></p><p>&nbsp;</p><p>从很多方面来看，2022年都是软件的分水岭；随着疫情最严重肆虐破坏的过去，我们可以看到暂时的变化，以及哪些变化已经成为结构性的了。因此，那些利用软件建立可持续长期业务的公司得以蓬勃发展，打破了疫情前的现状。然而，与此同时，那些仅仅是技术潮流的产品将被扔进历史的垃圾桶。</p><p>&nbsp;</p><p>随着工作实践以及软件和IT对世界生存的重要程度的变化，软件测试行业也发生了类似的转变，转向质量工程实践和自动化程度的提高。与此同时，我们看到机器学习、人工智能以及使之成为可能的大型神经网络取得了重大的进展。这些新技术将以前所未有的方式改变软件的开发和测试方式。在本文中，我将讨论未来几年我们可能会看到的趋势。</p><p>&nbsp;</p><p></p><h2>软件测试趋势</h2><p></p><p></p><p>即使是在疫情之前，软件测试就已经通过提高测试过程中各个级别的自动化程度而发生了转变。然而，由于需要在疫情期期间快速重塑商业模式或添加新的功能来处理远程工作/生活，开发人员的需求旺盛，供不应求。这导致了对更多编程专业知识进行测试的矛盾需求，以及对这些编程技能的更多竞争。</p><p>&nbsp;</p><p>结果之一是转向了用“低代码”或“无代码”工具、平台和框架来构建和测试应用程序。在测试方面，这意味着Selenium或Cypress等代码繁重的测试框架面临着来自业务用户可以使用的低代码替代方案的竞争。此外，对于某些ERP和CRM平台，例如Salesforce、Dynamics、Oracle和SAP等，这意味着测试工具本身需要对被测试的应用程序有更多的智能和理解。</p><p>&nbsp;</p><p></p><h2>机器学习改变软件测试</h2><p></p><p></p><p>我们看到机器学习（ML）用于测试的第一种方式是使当前的自动化测试更具弹性，更不那么脆弱。软件测试的一个致命弱点是维护，主要体现在测试整个应用程序和用户界面而不是独立模块（称为单元测试）时。软件应用程序会不断变化，因为用户希望不断更新其他功能或业务流程；然而，这些更改将会导致自动测试不再能正常工作。</p><p>&nbsp;</p><p>例如，如果登录按钮更改了它的坐标、形状或位置，则可能会中断先前记录的测试。即使是像页面加载速度这样的简单更改也可能导致自动测试的失败。具有讽刺意味的是，人类比计算机更直观，也更擅长测试，因为我们可以查看应用程序，并立即看到哪个按钮放在了错误的位置、哪些内容没有被正确显示。当然，这是因为大多数应用程序都是为人类使用而构建的。那些为其他计算机使用而构建的软件系统（称为API）使用自动化测试要容易得多！</p><p>&nbsp;</p><p>为了克服这些限制，较新的低代码软件测试工具正在使用机器学习让这些工具以多种方式并多次迭代扫描正在测试的应用程序，以便它们能够了解哪些结果是“正确”的，哪些结果是“不正确”的。这意味着当系统的更改与最初记录的内容略有偏差时，它将能够自动确定该偏差是预期内的（测试通过）还是预期外的（测试失败）。当然，我们仍然处于这些工具的早期阶段，而且它们的炒作多于实质。尽管如此，随着我们步入2023年，我们将会看到机器学习在软件测试中的实际用例，特别是针对复杂的业务应用程序和快速变化的云原生应用程序的。</p><p>&nbsp;</p><p>机器学习技术的另一个广泛应用将是在质量工程的分析和报告方面。例如，软件测试中的一个长期存在的挑战是要知道将测试资源和工作集中在哪里。“基于风险的测试”这一新兴学科旨在将软件测试活动集中在包含最大风险的系统区域上。如果你可以使用测试来减少总体风险敞口，那么你就有了一种分配资源的量化方式。衡量风险的方法之一是查看特定事件的概率和影响，然后使用先前的数据来了解这些值对于系统每个部分的重要性。然后，你可以针对这些区域进行测试。对于机器学习来说，这是一个近乎完美的用例。这些模型可以分析之前的开发、测试和发布活动，以了解发现缺陷、更改代码的位置以及历史上发生过的问题。</p><p>&nbsp;</p><p></p><h2>人工智能如何改变安全测试</h2><p></p><p></p><p>如果说机器学习正在改变软件测试行业，那么人工智能（AI）将以多种方式改变网络安全行业。例如，已经有传言称，许多防病毒和入侵的检测系统正在使用人工智能来寻找可能表明网络攻击的异常模式和行为。然而，我们现在才看到人工智能首次被用于定位和探测系统，以主动发现薄弱点和漏洞。</p><p>&nbsp;</p><p>例如，流行的OpenAI ChatGPT聊天机器人被要求创建用于访问系统的软件代码，并生成假冒但真实的钓鱼文本，以发送给使用该系统的用户。鱼叉式网络钓鱼最常见的方法之一是使用某种社会工程和模拟，这是网络安全的新前沿。聊天机器人能够根据从受害者那里实时收到的响应，同时创建工作代码和逼真的自然语言，以使人工智能能够创建动态的实时攻击能力。</p><p>&nbsp;</p><p>如果你不相信自己会上当受骗，这里有一个测试——本文中有一个段落是由ChatGPT编写的，并且我们将它原封不动地粘贴到了本文中。你能猜出是哪一段吗？</p><p>&nbsp;</p><p></p><h2>我们如何测试或检查人工智能或机器学习系统？</h2><p></p><p></p><p>当我们部署基于人工智能（AI）和机器学习（ML）的系统和应用程序时，面临的另一个挑战是：我们如何测试它们？对于传统的软件系统，人类编写需求，开发系统，然后让其他人（在计算机的辅助下）对其进行测试，以确保结果匹配。对于AI/ML开发的系统，通常没有离散的需求，取而代之的是大数据集、模型和反馈机制。</p><p>&nbsp;</p><p>在许多情况下，我们不知道系统是如何得出具体答案的，只知道答案是与所提供的数据集中的证据相符。这使得AI/ML系统能够创建人类以前不知道的新方法，并找到独特的关联和突破。然而，这些新的见解是未经证实的，可能只与它们所基于的有限数据集一样好。风险在于，你开始将这些模型用于生产系统时，它们会以意想不到且不可预测的方式运行。</p><p>&nbsp;</p><p>因此，测试人员和系统所有者必须确保他们清楚地掌握了业务需求、用例和边界条件（或约束）。例如，定义所用数据集的限制和训练模型的特定用例将能确保模型仅用于支持其原始数据集所代表的活动。此外，让人类独自检查模型预测的结果也是至关重要的。</p><p>&nbsp;</p><p></p><h2>人工智能如何改变计算机硬件？</h2><p></p><p></p><p>人工智能开发人员面临的物理挑战之一是当代硬件的局限性。一些正在使用的数据集的规模达到了PB级，这对于根本没有足够RAM容量来运行这些模型的数据中心来说是一个挑战。取而代之的是，它们必须使用500多个通用处理单元（GPU）来处理整个数据集，每个GPU都有数百GB的RAM。在处理方面，问题也类似，当前的电子CPU和GPU会产生大量的热量，消耗大量的电力，并行处理的速度会受到电阻的限制。解决这些限制的一个可能方案是使用光计算（Optical Computing）。</p><p>&nbsp;</p><p>光计算是一种利用激光和光电探测器等基于光的技术来执行计算并处理信息的计算类型。虽然已经有了将光计算用于人工智能（AI）应用的研究，但它尚未被广泛用于这一目的。将光计算用于人工智能存在一些挑战，其中包括许多人工智能算法需要高精度的数值计算，而使用光技术很难执行这些计算。</p><p>&nbsp;</p><p>话虽如此，但将光计算用于人工智能仍有一些潜在的优势。例如，光计算系统可能会以非常高的速度运行，这对于某些需要实时处理大量数据的人工智能应用来说非常有用。一些研究人员也在探索使用光子学（光学的一个子领域）来实现人工神经网络，这是许多人工智能系统的关键组成部分。</p><p>&nbsp;</p><p></p><h2>我们将会有哪些新的角色和职业？</h2><p></p><p></p><p>随着人工智能变得越来越主流，可能会出现一些还没有被我们发明出来的全新职业领域。例如，如果你曾经尝试过使用ChatGBT这样的聊天机器人，你会发现它可以写出大量看似合理但却完全不准确的信息。除了简单地雇佣人类事实核查人员和人工软件测试人员团队之外，道德规范在软件测试中可能会扮演一个新的角色。</p><p>&nbsp;</p><p>一些众所周知的技术已经从输入的数据中学习到了偏见或开发了歧视算法。例如，Compass法庭判决系统将对有色人种或面部识别技术在某些种族上比其他种族更有效的人判处更长的刑期。软件测试人员的角色包括理解这些模型中的偏差，并能够在系统投入生产之前对其进行评估。</p><p>&nbsp;</p><p>另一个吸引人的职业领域与此相反，即试图影响人工智能的学习。例如，在数字营销领域，聊天机器人可能会部分取代搜索引擎的使用。当聊天机器人可以在一段话中为你提供（潜在的）正确答案或将答案读给你听时，你为什么还要点击链接页面来查找答案呢？在这种情况下，搜索引擎优化（SEO）领域可能会被新的聊天机器人优化（CBO）领域所取代。网站和其他信息资源的所有者会希望让他们的内容更容易被聊天机器人消化，就像今天网站开发人员试图让网站更容易被搜索引擎索引一样。</p><p>&nbsp;</p><p>ChatGBT写的是哪一段？</p><p>&nbsp;</p><p>你猜到了吗？那就是“人工智能如何改变计算机硬件？”这一节的最后一段。</p><p>&nbsp;</p><p></p><h2>总结</h2><p></p><p></p><p>总之，2023年和未来几年将会发生重大的变化，这些变化将在大大小小的方面影响软件测试行业。因此，你应该开始研究如何使用人工智能（AI）和机器学习（ML）来改进你的测试流程，利用基于人工智能的安全工具，并实施基于风险的测试，例如可以利用大数据洞察力的基于风险的测试。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/software-testing-ai-ml-2023/\">https://www.infoq.com/articles/software-testing-ai-ml-2023/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/rggHjzaBfCVPV5hxTF7H\">取代搜索，“干掉”艺术家？顶流「AIGC」的疯狂与争议 | 解读 AIGC 的 2022</a>\"</p><p><a href=\"https://www.infoq.cn/article/KDhdcyKx639AQIfYGQSA\">ChatGPT 带火大模型！深度解读人工智能大模型在产业中的服务新态势</a>\"</p>",
    "publish_time": "2023-02-10 10:23:31",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "GitHub宣布裁员10%，所有员工远程办公，CEO称未来将重点关注AI",
    "url": "https://www.infoq.cn/article/4i3YZ65Eedg0h9218Whl",
    "summary": "<p>近年来，受疫情影响，各公司业务发展缓慢，导致裁员动作频出。GitHub的母公司微软此前宣布将在2023年1月中旬裁减1万名员工。其他大型科技公司，如Google、<a href=\"https://www.infoq.cn/article/6gqyyO1jGOhCKsWEiKBS\">Zoom</a>\"、戴尔、PayPal、Spotify、亚马逊和Meta，在过去几个月也都启动了自己的裁员计划。</p><p></p><h2>GitHub宣布裁员10%，关闭所有实体办公室</h2><p></p><p></p><p>当地时间2月9日，<a href=\"https://www.infoq.cn/article/FJhulyO6mpox7bqqZIg4\">微软</a>\"旗下的 GitHub 宣布，将在公司财年结束前裁员 10%。在这一消息被曝出之前，GitHub 拥有大约 3000 名员工，这意味着其中300人现在正在寻找其他工作机会。该公司还将在租约结束时关闭所有实体办公室，剩下的员工从现在起将进行远程工作。至于关闭办公室的原因，GitHub公司发言人称一部分部分原因是它们的利用率低，并转向远程优先文化。</p><p></p><p>此外，GitHub将继续其在1月份首次宣布的招聘冻结计划，并进行其他一些内部调整，以“保护其业务的短期健康”。</p><p></p><p>“我们宣布了一些困难但必要的决定和预算调整，以在短期内保护我们业务的健康发展，并使我们有能力投资于能使我们向前发展的长期战略。”公司发言人在接受媒体采访时如是说。</p><p></p><p>为了进一步节省成本，<a href=\"https://www.infoq.cn/article/1s4tJwDHpM5zTbeScaRI\">GitHub</a>\"还告知员工要从视频聊天程序Slack转向Microsoft Teams以满足其视频会议需求。此外，公司还将员工的笔记本电脑硬件的更新或升级周期从三年增加到四年。</p><p></p><p>“尽管我们整个领导团队都仔细考虑了这一步骤并达成一致，但作为CEO，这样艰难的决定还是要由我来做。我知道这对你们所有人来说都很困难，我们将怀着对 Hubbers 的崇高敬意来迎接这一时期，”GitHub 首席执行官 Thomas Dohmke 在今天给公司员工的一封电子邮件中写道。</p><p></p><p>被解雇的员工将获得过渡补偿和职业服务援助，但将转移到 COBRA（失业后的健康保险），这是一项联邦保险福利，被解僱的员工可以获取和解雇前相等的团体保健福利，但该员工要向雇主支付保费。</p><p></p><p>Dohmke指出，他希望公司成为“面向未来世界的开发者至上的<a href=\"https://qcon.infoq.cn/2023/beijing/track/1299\">工程团队</a>\"”，重点关注<a href=\"https://qcon.infoq.cn/2023/beijing/track/1308\">人工智能</a>\"。鉴于 GitHub 最近对其 Copilot 的关注以及微软向 AI-everything 的整体转变，这也许并不出人意料。</p><p></p><h2>GitHub CEO：未来我们将重点关注AI</h2><p></p><p></p><p>在一封发给整个公司的内部邮件中，GitHub首席执行官Thomas Dohmke表示，该公司未来将大力关注人工智能，他希望GitHub成为“未来世界的开发者至上的工程团队\"。</p><p></p><p>这是 Dohmke 昨天发送给公司的完整电子邮件：</p><p></p><p></p><blockquote>今天，我们宣布了一些艰难的决定，包括告别一些Hubbers和制定新的预算调整，旨在保护我们业务的短期健康，同时也让我们有能力投资于我们的长期战略。怀着对 Hubbers 的崇高敬意，我首先想让大家了解清楚我们为什么要做出这些决定，以及这对 GitHub 的未来意味着什么。持续增长对每个企业都很重要。对于 GitHub 而言，这意味着我们将继续在全球范围内支持更高效的开发人员，并随着我们帮助客户的机会发生变化而迅速采取行动。今天，我们是 1 亿名开发者的家园，我们必须成为面向未来世界的开发人员至上的工程团队。<a href=\"https://qcon.infoq.cn/2023/beijing/track/1315\">AI 时代</a>\"已经开始，我们一直在通过 GitHub Copilot 引领这一变革，这是我们迄今为止最成功的产品发布。我们有一个巨大的机会来紧急构建一个集成的、人工智能驱动的 GitHub。我们必须继续帮助我们的客户通过 GitHub 成长和繁荣，加快和简化他们的云采用之旅，同时每天为他们提供支持。对于有限的资源，将它们投放在哪、以什么样的方式进行投资我们必须高度重视起来。首先，我们的工作必须紧贴目标和我们的客户需求。但不幸的是，这将包括导致 GitHub 的员工在 2023 财年末最多减少 10%。许多 Hubbers 将在今天收到解聘通知，因为我们将在 23 财年末重新调整业务。我在1月18日宣布的暂停招聘这一动作仍将继续。尽管我们整个领导团队都仔细考虑了这一步骤并达成一致，但作为CEO，这样艰难的决定还是要由我来做。我知道这对你们所有人来说都很困难，我们将怀着对 Hubbers 的崇高敬意来迎接这一时期。我们将与受影响的 Hubbers 交谈，以便他们了解将提供的过渡补偿和 COBRA/COBRA 等价物（美国以外）。还将提供职业过渡服务援助福利。此外，我们一直致力于提高我们的运营效率和业务规模。我们的决定之一是转向完全远程的 GitHub。我们发现，我们在世界各地的办公室的利用率都非常低，这一决定证明了我们长期存在的远程优先文化的成功。我们不会立即腾出办公室，但会在租约结束或在运营能力允许时关闭所有办公室。在有了最终确定结果时，我们将与您分享更多工作场所细节和过渡计划。我们正在考虑进一步降低运营成本。我们将在未来几个月与您分享详细信息和过渡计划，但我想与您分享两个决定：1、我们将笔记本电脑的更新周期从三年改为四年，立即生效；2、 我们将从原来的视频会议软件转向 Microsoft Teams，从而节省大量成本并简化跨公司和客户的对话。这一举措将于 2023 年 9 月 1 日完成。我们将继续使用 Slack 作为我们的日常协作工具。最后，我想对每一位 Hubber表示最深切的感谢，感谢他们帮助 GitHub 取得了今天的成就。你所做的每一次承诺和每一天的工作都帮助 GitHub 成为最大和最重要的软件开发平台。感谢您为全球数百万软件开发人员提供支持的奉献精神、坚持和热情。</blockquote><p></p><p></p><p>参考链接：</p><p></p><p>https://techcrunch.com/2023/02/09/github-lays-off-10-and-goes-fully-remote/</p>",
    "publish_time": "2023-02-10 11:55:13",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "虚拟线程：大规模Java应用的新基石",
    "url": "https://www.infoq.cn/article/YaBqqD7fd6kX97GbhkGm",
    "summary": "<p>Java 19为Java平台带来了第一轮<a href=\"https://openjdk.java.net/jeps/12\">预览</a>\"的<a href=\"https://openjdk.java.net/jeps/425\">虚拟线程</a>\"，它是OpenJDK&nbsp;<a href=\"https://wiki.openjdk.org/display/loom/Main\">Loom项目</a>\"项目的主要成果。长期以来，这是Java的最大变化之一，同时它也是一个几乎难以觉察的变更。虚拟线程从根本上改变了Java运行时与底层操作系统的交互方式，消除了可扩展性的巨大障碍，但是它对我们如何构建和维护并发程序的改动相对较小。从表面上看，几乎没有什么新的API，虚拟线程的行为几乎与我们已知的线程完全一样。事实上，要高效利用线程，需要做的更多是忘却（unlearning）而不是学习。</p><p></p><h2>线程</h2><p></p><p></p><p>线程是Java的基石。当我们运行Java程序时，它的主方法是作为“main”线程的第一个调用帧（call frame）而调用的，该线程是由Java启动器（launcher）创建的。当某个方法调用另外一个方法时，被调用者和调用者在相同的线程上运行，而返回位置则记录在线程栈中。当方法使用局部变量时，它们会被存储在线程栈上该方法所对应的调用帧中。如果出现错误，我们可以通过遍阅当前的线程栈来重建遇到错误的上下文，也就是所谓的栈跟踪。线程提供了很多我们习以为常的特性，比如顺序控制流、局部变量、异常处理、单步调试以及运行期剖析（profiling）。线程也是Java程序中调度的基本单元，当一个线程阻塞等待存储设备、网络连接或锁的时候，该线程将会取消调度，以便于另外的线程能够在CPU上运行。Java是第一个集成基于线程进行并发操作的主流语言，它包括了跨平台的线程模型。线程是Java并发模型的基础。</p><p></p><p>尽管如此，线程的名声并不太好，因为大多数开发者在使用线程时，都是在实现或调试共享状态的并发。事实上，共享状态的并发（通常称为“使用线程和锁进行编程”）可能会非常困难。与Java平台上其他方面的编程不同，并非所有的答案都能在语言规范或API文档中找到。编写安全、高性能的并发代码来管理共享的可变状态时，需要理解很多微妙的概念（如内存可见性）并掌握大量的编程原则。（如果很容易的话，作者自己的“<a href=\"https://jcip.net/\">Java并发编程实战（Java Concurrency in Practice）</a>\"”一书也不会有近400页的篇幅。）</p><p></p><p>尽管开发人员在接触并发时有合理的担忧，但是我们很容易就能将其抛之脑后，在其他99%的时间里，线程在默默地、可靠地使我们的生活变得更加轻松，它为我们提供了带有栈信息的异常处理、能够让我们观察每个线程正在做什么的服务性工具、远程调试以及能够让我们的代码更易于分析的顺序性执行错觉。</p><p></p><h3>平台线程</h3><p></p><p></p><p>Java在语言和API层面为线程提供了完整且可移植的抽象、进程间的协调机制，而且它的内存模型为线程在内存中的行为提供了可预测的语义，借此Java实现了“一次编写，到处运行”的并发程序，这可以有效映射到众多不同的底层实现中。</p><p></p><p>如今，大多数JVM都将Java线程作为操作系统线程的简单封装，我们将这些重量级、操作系统管理的线程叫做平台线程。实际上，并非必须如此，Java线程本身要早于操作系统对线程的广泛支持，但是因为现代操作系统现在对线程有很好的支持（在今天的大多数操作系统中，线程都是基本的调度单元），所以有充分理由依赖底层的平台线程。但是，对操作系统的这种依赖有一个很大的缺点：由于大多数操作系统实现线程的方式所限，线程的创建相对代价高昂，而且是资源密集型操作。这对可创建线程的数量形成了一个隐形的实际限制，而它反过来又影响了我们在程序中使用线程的方式。</p><p></p><p>在线程创建的时候，操作系统通常会将线程栈分配为整块的内存，以后无法调整它的大小。这意味着线程会携带MB级别的内存块来管理本地和Java调用栈。栈的大小可以通过命令行开关和Thread构造器进行调整，但是在这两个方面进行调整都是有风险的。如果线程被分配了过多资源，我们将会使用更多的内存，如果分配资源不足的话，假设在错误的时间调用错误的代码时，我们将会面临遇到StackOverflowException的风险。我们通常倾向于为线程栈配置更多的资源，似乎这样后果没有那么严重，但是其结果就是在给定数量的内存中，我们只能创建较少数量的并发线程。</p><p></p><p>限制我们可以创建多少个线程的做法是有问题的，因为构建服务器应用的最简单方式就是“每个任务一个线程”的方式，也就是在任务的生命周期内，为每个传入的请求分配一个线程。以这种方式将应用中的并发单元（任务）与平台（线程）进行对齐，能够最大限度地提升开发、调试和维护的便利性，这依赖于线程无形中为我们带来的所有收益，尤其是最重要的其顺序执行的错觉。它通常并不需要我们注意到并发（除了为请求处理器配置线程池）的存在，因为大多数请求是相互独立的。不幸的是，随着程序的扩展，这种方式与平台线程的内存特征产生了冲突。对于中等规模的应用来说，每个任务一个线程的方式非常好，我们可以很容易地服务于1000个并发请求，但是使用相同的技术，即便硬件有足够的CPU容量和IO带宽，我们也无法服务于100万个并发请求。</p><p></p><p>到目前为止，Java开发人员如果想要服务于大量的并发请求，那么只有几个很糟糕的可选方案：限制代码的编写方式，使其能够使用更小的栈（这通常意味着放弃大多数第三方库），针对该问题投入更多的硬件，或者切换到“异步”或“反应式”编程风格。尽管“异步”模式最近变得流行了起来，但是它意味着要采取一种高度受限的风格来进行编程，要求我们放弃线程带来的很多收益，比如易读的栈跟踪、调试和可观测性。由于大多数异步库所采用的设计模式，它也意味着放弃了Java语言带给我们的许多收益，因为异步库本质上会成为僵化的领域特定语言，它想要管理整个计算过程。这就牺牲了许多让Java编程卓有成效的特性。</p><p></p><h2>虚拟线程</h2><p></p><p></p><p>虚拟线程是java.lang.Thread的另一种实现，它们将栈帧存储在了Java垃圾收集堆上，而不是由操作系统分配的整块内存中。我们不必猜测一个线程可能需要多少栈帧，或者试图做一个“放之四海而皆准”的预估，一个虚拟线程初始的内存占用只有几百个字节，并且会随着调用栈的扩展和收缩而自动放大和缩小。</p><p></p><p>操作系统只知道平台线程，它们依然是调度单元。为了在虚拟线程中运行代码，Java运行时通过将其挂载在某个平台线程（叫做载体线程（carrier））上来安排它的运行。挂载一个虚拟线程意味着将所需的栈帧暂时从堆复制到载体线程的栈中，并在挂载时借用载体线程的栈。</p><p></p><p>当在虚拟线程中运行的代码因为IO、锁或者其他资源的可用性而阻塞时，它可以从载体线程上卸载，变更过的栈帧会被复制回堆中，将载体线程释放出来做其他的事情（比如运行另外的虚拟线程）。JDK几乎调整了所有的阻塞点，以便在虚拟线程遇到阻塞操作时，将虚拟线程从载体线程上卸载下来，而避免造成阻塞。</p><p></p><p>在载体线程上挂载和卸载虚拟线程是一个实现细节，对Java代码来说是完全不可见的。Java代码无法观察到当前载体线程的标识（调用Thread::currentThread始终会返回虚拟线程）；载体线程的ThreadLocal值对于被挂载的虚拟线程是不可见的；载体线程的栈帧不会出现在虚拟线程的异常或线程转储中。在虚拟线程的生命周期中，它可能会运行在不同的载体线程中，但是依赖于线程身份标识的内容，比如锁，都会看到一致的线程执行情况。</p><p></p><p>虚拟线程之所以得名，是因为它与虚拟内存有共同的特点。通过虚拟内存，应用会有一种错觉，那就是它在访问整个内存地址空间，而不仅局限于物理内存。硬件在实现这种错觉的时候，通常会在需要时将充裕的虚拟内存映射到稀缺的物理内存上，当其他虚拟页需要物理内存时，旧的内容会先被分页到磁盘。与之类似，虚拟线程也是廉价而充裕的，并根据需要分享稀缺而珍贵的平台线程，不活跃的虚拟线程栈会被“分页”到堆中。</p><p></p><p>虚拟线程的新API相对较少。有多种创建虚拟线程的新方法（比如，<a href=\"https://docs.oracle.com/en/java/javase/19/docs/api/java.base/java/lang/Thread.html#ofVirtual%28%29\">Thread::ofVirtual</a>\"），但是在创建之后，它们就是普通的Thread对象，其行为与我们已知的线程是一样的。现有的API，如Thread::currentThread、ThreadLocal、终端、栈跟踪等，在虚拟线程上的行为与在平台线程上完全相同。这意味着我们可以放心地在虚拟线程上运行现有的代码。</p><p></p><p>如下的样例阐述了如何使用虚拟线程并发获取两个URL，作为请求处理的一部分，会将它们的结果进行汇总。它创建了一个<a href=\"https://docs.oracle.com/en/java/javase/19/docs/api/java.base/java/util/concurrent/ExecutorService.html\">ExecutorService</a>\"，在一个新的虚拟线程中运行每个任务，向其提交任务并等待结果。ExecutorService已经进行了改造，实现了AutoCloseable接口，因此可以与try-with-resources协作使用，close方法会关闭执行器并等待任务完成。</p><p></p><p><code lang=\"text\">void handle(Request request, Response response) {\n    var url1 = ...\n    var url2 = ...\n    \n    try (var executor = Executors.newVirtualThreadPerTaskExecutor()) {\n        var future1 = executor.submit(() -&gt; fetchURL(url1));\n        var future2 = executor.submit(() -&gt; fetchURL(url2));\n        response.send(future1.get() + future2.get());\n    } catch (ExecutionException | InterruptedException e) {\n        response.fail(e);\n    }\n}\n\nString fetchURL(URL url) throws IOException {\n    try (var in = url.openStream()) {\n        return new String(in.readAllBytes(), StandardCharsets.UTF_8);\n    }\n}</code></p><p></p><p>在阅读这段代码时，我们最初可能会担心，为如此短暂的活动创建线程或者为如此少的任务创建线程池是一种资源浪费，但这就是我们要忘却的，上述代码对虚拟线程的使用是完全没有问题的。</p><p></p><h3>这不就是“绿色线程”吗？</h3><p></p><p></p><p>Java开发人员可能还记得，在Java 1.0时代，有些JVM使用<a href=\"https://docs.oracle.com/cd/E19455-01/806-3461/ch2mt-41/index.html\">用户模式</a>\"实现了线程，或者叫做“绿色”线程。虚拟线程与绿色线程在表面上有相似之处，它们都是由JVM，而不是由操作系统来管理的，但它们之间的相似之处仅此而已。90年代的绿色线程依然有庞大的、整块的栈。在很大程度上来讲，它们是那个时代的产物，当时系统是单核的，操作系统根本就没有线程支持。虚拟线程与其他语言中的用户模式线程有很大的相似之处，例如<a href=\"https://go.dev/tour/welcome/1\">Go</a>\"中的<a href=\"https://go.dev/tour/concurrency/1\">goroutines</a>\"或者<a href=\"https://www.erlang.org/\">Erlang</a>\"中的<a href=\"https://www.erlang.org/doc/reference_manual/processes.html\">processes</a>\"，但虚拟线程的优势在于，它们与已有的线程在语义上是一致的。</p><p></p><h3>一切为了可扩展性</h3><p></p><p></p><p>尽管创建的成本不同，但是虚拟线程并不会比平台线程更快，我们无法在一秒钟的时间内使用虚拟线程执行比平台线程更多的计算。我们也无法调度比平台线程更多的活跃运行的虚拟线程，它们均受限于可用CPU的核心数量。那么，这到底能带来什么好处呢？因为它们是轻量级的，所以我们可以拥有比平台线程更多的非活跃虚拟线程。乍听上去，这可能根本就没有什么太大的收益。但“大量非活跃的线程”实际上描述了大多数服务器应用的状态。服务器应用中的请求花在网络、文件或数据库I/O方面的时间要远远多于计算。所以，如果我们在自己的线程中运行每个任务，大部分时间该线程都会因为I/O或其他资源的可用性而处于阻塞状态。虚拟线程通过消除最常见的扩展瓶颈，即线程的最大数量，使“每任务一个线程”的IO密集型应用能够更好地进行扩展，这反过来又会使硬件得到更充分的利用。虚拟线程能够让我们获得两全其美的效果：一种与平台和谐相处的编程风格，而不是与之对立，同时能够实现最佳的硬件利用率。</p><p></p><p>对于CPU密集型的工作负载，我们已经有了获取最佳CPU利用率的工具，比如<a href=\"https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/concurrent/ForkJoinPool.html\">fork-join</a>\"框架和<a href=\"https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/stream/package-summary.html\">并行流</a>\"。虚拟线程为这些工具提供了补充收益。并行流使得CPU密集型的工作负载更易于扩展，但是对IO密集型的工作负载来说，它们所提供的收益很有限，虚拟线程为IO密集型的工作负载提供了可扩展性方面的收益，但是对CPU密集型的工作负载作用有限。</p><p></p><h3>利特尔法则</h3><p></p><p></p><p>一个稳定系统的可扩展性受到<a href=\"https://en.wikipedia.org/wiki/Little%27s_law\">利特尔法则（Littles Law）</a>\"的约束，它与延迟、并发性和吞吐量有关。如果每个请求的持续时间（或延迟）为d，并且我们可以并发执行N个任务，那么吞吐量T可以通过如下公式计算得出：</p><p></p><p><code lang=\"null\">T = N / d</code></p><p></p><p>利特尔法则并不关心时间是用到了“工作”还是“等待”上，也不关心并发单元是线程、CPU、ATM机，还是银行的出纳员。它只是表明，为了提高吞吐量，我们要么按比例降低延迟，要么提高并发处理的请求数量。当达到并发线程的限制时，“每个任务一个线程”模型的吞吐量就会受到利特尔法则的限制。虚拟线程通过为我们提供更多的并发线程，而不是要求我们改变编程模型，以一种优雅的方式解决了我们的问题。</p><p></p><h3>虚拟线程实战</h3><p></p><p></p><p>虚拟线程并不会取代平台线程，它们是互补的。然而，很多的服务器应用会选择虚拟线程（通常会通过框架的配置）以实现更高的可扩展性。</p><p></p><p>如下的样例创建了100,000个虚拟线程，通过睡眠一秒钟来模拟IO密集型的操作。它创建了“每个任务一个虚拟线程”的执行器并以lambda的形式来提交任务。</p><p></p><p><code lang=\"text\">try (var executor = Executors.newVirtualThreadPerTaskExecutor()) {\n    IntStream.range(0, 100_000).forEach(i -&gt; {\n        executor.submit(() -&gt; {\n            Thread.sleep(Duration.ofSeconds(1));\n            return i;\n        });\n    });\n}  // 隐式调用close()</code></p><p></p><p>在没有特殊配置的普通台式机上，运行该程序在冷启动时大约需要1.6秒，在预热后大约需要1.1秒。如果我们尝试使用缓存的线程池来运行该程序的话，根据可用内存的大小，该程序很可能在所有任务提交之前就因为OutOfMemoryError而崩溃。如果我们使用有1000线程的固定线程池来运行该程序的话，它不会崩溃，但是利特尔法则准确预测它将需要100秒才能完成。</p><p></p><h2>要忘却的事情</h2><p></p><p></p><p>因为虚拟线程就是线程，它们本身并没有什么API，所以为了使用虚拟线程，要学习的东西相对很少。但是，为了高效使用它们，我们需要忘却一些以前的做法。</p><p></p><h3>避免使用线程池</h3><p></p><p></p><p>我们首先需要忘却的就是线程的创建方式。Java 5引入了java.util.concurrent包，其中包括ExecutorService框架，Java开发人员已经学习到（这是正确的），在一般情况下，让ExecutorService以策略驱动的方式管理和池化线程要比直接创建它们好得多。但是，当涉及到虚拟线程时，使用池就是一种反模式了。（我们不必放弃使用ExecutorService或它所提供的策略封装，我们可以使用新的工厂方法<a href=\"https://docs.oracle.com/en/java/javase/19/docs/api/java.base/java/util/concurrent/Executors.html#newVirtualThreadPerTaskExecutor%28%29\">Executors::newVirtualThreadPerTaskExecutor</a>\"来获取一个ExecutorService，它会为每个任务创建一个虚拟线程。）</p><p></p><p>因为虚拟线程初始占用的资源非常少，所以创建虚拟线程在时间和内存方面都比创建平台线程成本低廉得多，以至于我们需要重新审视关于创建线程的直觉。对于平台线程，我们习惯于将它们进行池化管理，这样是为了限制资源的使用（否则的话，很容易耗尽内存），并且能够在多个请求中分摊创建线程的成本。而虚拟线程的创建成本非常低，以至于将它们进行池化管理是一个糟糕的主意。在限制内存使用方面，我们的收益并不大，因为虚拟线程占用的内存太少了，即便是1G的内存，我们也能使用数百万个虚拟线程。在分摊创建成本方面，我们的收益也很小，因为它们的创建成本太低了。我们经常会忘记一点，那就是在历史上，池是一个被迫无奈的选择，但它也带来了自己的问题，比如ThreadLocal污染（在长期存活的线程中，ThreadLocal的值被遗留并长期积累下来，造成内存泄露。）</p><p></p><p>如果有必要限制并发，以约束除线程之外的其他资源的消耗，比如数据库连接池，那么我们可以使用Semaphore，让每个需要稀缺资源的虚拟线程均要获取一个许可。</p><p></p><p>虚拟线程是如此轻量级，以至于即便为短暂的任务创建一个虚拟线程也是完全可以的，而试图重复使用或回收它们则会产生副作用。事实上，虚拟线程在设计时就考虑到了这种短暂的任务，比如HTTP请求或JDBC查询。</p><p></p><h3>ThreadLocal的滥用</h3><p></p><p></p><p>库可能还需要根据虚拟线程来调整它们对ThreadLocal的使用。ThreadLocal的一种使用方式就是缓存那些分配起来代价高昂、非线程安全的资源（有人说这是一种滥用），或者只是为了避免重复分配通用的对象（比如，ASM使用ThreadLocal为每个线程维护了一个char[]缓冲，用来进行格式化操作）。当系统有数百个线程时，这种模式的资源占用通常并不会太多，而且可能会比每次需要时重新进行分配代价要低廉一些。但是，如果有几百万个线程，而每个线程只执行一个任务，那么计算结果就会发生很大的变化，因为可能会分配更多的实例，而且每个实例被重用的机会也小得多。使用ThreadLocal在同一个线程中执行的多个任务间分摊昂贵资源的创建成本实际上是一种临时的池化形式，如果这些东西需要池化的话，它们应该显式地进行池化。</p><p></p><h2>那么，反应式编程呢？</h2><p></p><p></p><p>一些所谓的“异步”或“反应式”框架提供了一条实现更充分资源利用的途径，它们要求开发者以异步IO、回调和线程共享的方式来替换“每个请求一个线程”的风格。在这种模型中，当活动需要执行IO操作时，它会在IO操作完成时，触发一个回调。框架会在某个线程上触发回调，但不一定是初始化该操作的线程。这意味着开发人员必须将他们的逻辑拆分成交替的IO和计算步骤，这些步骤被缝合到一个连续的工作流中。因为请求只有在进行实际的计算时才会使用线程，所以并发请求的数量并不会受到线程数量的限制，所以线程数量的限制不太可能成为应用吞吐量的限制因素。</p><p></p><p>但是，这种可扩展性是有很大代价的，我们往往不得不放弃平台和生态系统的一些基本特性。在“每个任务一个线程”模型中，如果我们想要两件事情顺序执行的话，我们只需要按顺序编写即可。如果想要使用循环、条件或try-catch代码块来构造工作流的话，都可以毫无顾忌地这样做。但是在异步风格中，我们往往无法使用语言提供的顺序组合、迭代或其他特性来构造工作流，这些必须要通过API调用来完成，这些API在异步框架中模拟了这些构造。用于模拟循环和条件的API永远不会像语言中内置的构造那样灵活和为人熟知。如果使用了执行阻塞操作的库，而它们可能并没有适应异步风格的运行方式，那么我们将无法使用它们。因此，我们会从这种模型中获取可扩展性，但是为此必须要放弃使用部分语言和生态系统的特性。</p><p></p><p>这些框架还让我们放弃了一些使Java开发更便利的运行时特性。因为请求的每个阶段可能会在不同的线程中执行，而且服务线程可能会交替执行不同请求的计算，所以当出现错误时，我们经常使用的工具（如栈跟踪、调试器和profiler）所能提供的帮助都要比“每个任务一个线程”模型小得多。这种编程风格与Java平台并不一致，因为框架的并发单位（即异步流水线的一个阶段）与平台的并发单位并不一致。而虚拟线程允许我们在不放弃关键语言和运行时特性的情况下获得同样的吞吐量收益。</p><p></p><h3>那么，async/await呢？</h3><p></p><p></p><p>有些语言采用了async方法（一种无栈的coroutines形式），用来作为管理阻塞操作的方式，它可以被其他的async方法调用，也可以通过await语句被普通方法调用。实际上，有很多人呼吁将async/await添加到Java中，就像<a href=\"https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/concepts/async/\">C#</a>\"和<a href=\"https://kotlinlang.org/docs/async-programming.html\">Kotlin</a>\"那样。</p><p></p><p>虚拟线程提供了async/await无法具备的明显优势。虚拟线程并不只是异步框架的语法糖，而是对JDK库的全面改造，使其更具“阻塞意识”。如果没有这一点的话，在异步任务中对同步阻塞方法的错误调用依然会在调用过程中占用一个平台线程。如果仅仅在语法层面使异步操作的管理更容易，并不会带来任何可扩展性方面的收益，除非我们找出系统中的每一个阻塞操作，并将其转换为async方法。</p><p></p><p>async/await更严重的问题在于所谓的<a href=\"https://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/\">“函数颜色”</a>\"，即方法会被分为两种，即一种是为线程设计的，另一种是为async方法设计的，这两种方式并不能完美地交互。这是一个繁琐的编程模型，通常会有大量的重复，并且需要将新的构造引入到库、框架和工具的每一层中，以达到无缝的效果。我们为什么要实现另外一个并发单元（它仅仅是一个语法深度单元），而且它还与我们已有的编程模型不一致？在别的语言中，这种方式可能很有吸引力，因为它们无法做到语言-运行时的共同演进，但幸运的是，在Java中我们不必进行这样的抉择。</p><p></p><h2>API和平台变更</h2><p></p><p></p><p>虚拟线程及相关的API是一个<a href=\"https://openjdk.java.net/jeps/12\">预览特性</a>\"。这意味着要使用--enable-preview标记才能启用对虚拟线程的支持。</p><p></p><p>虚拟线程是java.lang.Thread的实现，所以没有新的VirtualThread基础类型。但是，Thread&nbsp;API中扩展了一些新的API，用于创建和探查线程。有一些新的工厂方法，包括Thread::ofVirtual和<a href=\"https://docs.oracle.com/en/java/javase/19/docs/api/java.base/java/lang/Thread.html#ofPlatform%28%29\">Thread::ofPlatform</a>\"、新的<a href=\"https://docs.oracle.com/en/java/javase/19/docs/api/java.base/java/lang/Thread.Builder.html\">Thread.Builder</a>\"类，以及用来在虚拟线程上创建一次性任务的Thread::startVirtualThread。现有的线程构造器运行方式和以前一样，但只用于创建平台线程。</p><p></p><p>虚拟线程和平台线程在行为上有一些差异。虚拟线程始终是守护线程，Thread::setDaemon方法对它们没有作用。虚拟线程的优先级始终是Thread.NORM_PRIORITY，这种优先级不能改变。虚拟线程不支持某些（有缺陷的）遗留机制，比如ThreadGroup和Thread的stop、suspend与remove方法。Thread::isVirtual会返回某个线程是不是虚拟线程。</p><p></p><p>与平台线程栈不同，如果没有操作让线程处于活跃状态，虚拟线程可以被垃圾收集器回收。这意味着，如果虚拟线程被阻塞了，比如阻塞在BlockingQueue::take上，但该虚拟线程和队列均无法被任何平台线程访问到，那么这个线程和它的栈可以被垃圾回收。（这是安全的，因为这种情况下，虚拟线程永远不会被中断或解除阻塞。）</p><p></p><p>最初，虚拟线程的载体是<a href=\"https://docs.oracle.com/en/java/javase/19/docs/api/java.base/java/util/concurrent/ForkJoinPool.html\">ForkJoinPool</a>\"中的线程，并以FIFO模式运行。该池的默认大小是可用处理器的数量。未来，可能会有更多的方案来创建自定义的调度器。</p><p></p><h3>JDK的准备工作</h3><p></p><p></p><p>尽管虚拟线程主要是Loom项目的成果，但是JDK在幕后也有很多改进，以确保应用在使用虚拟线程时能有良好的体验：</p><p></p><p>新的socket实现。<a href=\"https://openjdk.java.net/jeps/353\">JEP 353</a>\"（重新实现遗留的Socket API）和<a href=\"https://openjdk.java.net/jeps/373\">JEP 373</a>\"（重新实现遗留的DatagramSocket API）替换了Socket、ServerSocket和DatagramSocket，以更好地支持虚拟线程（包括使虚拟线程中的阻塞方法可中断）。虚拟线程感知。JDK中几乎所有的阻塞点均能意识到虚拟线程，并且会卸载虚拟线程，而不是阻塞它。重新审视对ThreadLocal的使用。考虑到线程使用模式的变化，JDK中ThreadLocal的许多用法都已被修改。重新审视锁。因为目前获取内部锁（即synchronized）将会导致虚拟线程锚定（pin）到它的载体上，所以内部锁已被ReentrantLock所取代，ReentrantLock不会导致这样的行为。（虚拟线程和内部锁之间的交互未来很可能会得到改善。）改进线程转储。提供了对线程转储的更大控制，例如jcmd产生的转储，以过滤虚拟线程，将相关的虚拟线程进行分组，或者以机器可读的格式产生转储，以获得更好的可观测性。</p><p></p><h3>相关工作</h3><p></p><p></p><p>虽然虚拟线程是Loom项目的主要课题，但还有其他几个Loom子项目进一步增强了虚拟线程。其中包含一个简单的<a href=\"https://openjdk.org/jeps/428\">结构化并发</a>\"框架，它提供了协调和管理虚拟线程组协作的强大功能。另一个是范围内的局部变量（extent local variable），它类似于线程局部变量，但更适合（并且性能更优）在虚拟线程中使用。这些将是未来文章的主题。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/java-virtual-threads/\">Virtual Threads: New Foundations for High-Scale Java Applications</a>\"</p><p></p><h5>相关阅读：</h5><p></p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MzI3NzE0NjcwMg==&amp;mid=2650190181&amp;idx=1&amp;sn=b77c4289f096befa59636edd121a2554&amp;chksm=f368ac44c41f2552a221828bf53eb9c9ce6c792ef56e25f6a0b60860ab1a68ff0cccc13a5383&amp;scene=27#wechat_redirect\">科技与狠活？JDK19中的虚拟线程到底什么鬼？</a>\"</p><p><a href=\"https://xie.infoq.cn/article/fc4b6b8fa5810c9567e7358ed\">你知道这个提高 Java 单元测试效率的 IDEA 插件吗</a>\"</p><p><a href=\"https://xie.infoq.cn/article/e4f7423f9c106157437864113\">Java 19 中新推出的虚拟线程到底是怎么回事儿？</a>\"</p><p><a href=\"https://xie.infoq.cn/article/f2eddb54e2d3e2b8bb08d637d\">API 网关策略二三事</a>\"</p>",
    "publish_time": "2023-02-10 13:47:16",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "在Angular中实现自定义独立API的模式",
    "url": "https://www.infoq.cn/article/5N4SGOcYc9yiEqGc01fS",
    "summary": "<p>与独立组件（Standalone Component）一起，Angular 团队引入了独立 API（Standalone API）。它支持以一种更加轻量级的方式实现库。目前，提供独立 API 的样例是HttpClient和Router。另外，NGRX 也是该理念的早期采用者。</p><p></p><p>在本文中，我会介绍几种编写自定义独立 API 的模式，这些模式的灵感来源于上述的几个库。对于每个模式，我都会讨论如下话题：模式背后的意图、描述、实现样例、在上述库中出现的样例场景以及实现细节的变种。</p><p></p><p>大多数模式对库作者会特别有用。对库的消费者来说，它们有助于改善 DX。但是，对于应用来说，这就有点大材小用了。</p><p></p><p>本文的源码请参考该地址：<a href=\"https://github.com/manfredsteyer/standalone-example-cli.git%E3%80%82\">https://github.com/manfredsteyer/standalone-example-cli.git。</a>\"</p><p></p><p></p><h2>样例</h2><p></p><p></p><p>为了阐述这些推断出来的模式，我会使用一个简单的 Logger 库。这个库尽可能简单，但又足以阐述这些模式。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b5/b5ad7a2177e0b306fc6daf0be1845981.png\" /></p><p></p><p>每条日志消息都有一个LogLevel，它是由枚举定义的：</p><p></p><p><code lang=\"text\">export enum LogLevel {\n  DEBUG = 0,\n  INFO = 1,\n  ERROR = 2,\n}</code></p><p></p><p>为了简单起见，我们将 Logger 库限制为只有三个日志级别。</p><p></p><p>我们会使用一个抽象LoggerConfig来定义可能的配置选项：</p><p></p><p><code lang=\"text\">export abstract class LoggerConfig {\n  abstract level: LogLevel;\n  abstract formatter: Type;\n  abstract appenders: Type[];\n}</code></p><p></p><p>我们有意将其定义为抽象类，因为接口无法作为 DI 的令牌（token）。该类的一个常量定义了配置选项的默认值：</p><p></p><p><code lang=\"text\">export const defaultConfig: LoggerConfig = {\n  level: LogLevel.DEBUG,\n  formatter: DefaultLogFormatter,\n  appenders: [DefaultLogAppender],\n};</code></p><p></p><p>LogFormatter用于在通过LogAppender发布日志消息之前对其进行格式化：</p><p></p><p><code lang=\"text\">export abstract class LogFormatter {\n  abstract format(level: LogLevel, category: string, msg: string): string;\n}</code></p><p></p><p>与LoggerConfiguration类似，LogFormatter是一个抽象类，可以用作令牌。Logger 库的消费者可以通过提供自己的实现来调整格式，也可以使用库提供的默认实现：</p><p></p><p><code lang=\"text\">@Injectable()\nexport class DefaultLogFormatter implements LogFormatter {\n  format(level: LogLevel, category: string, msg: string): string {\n    const levelString = LogLevel[level].padEnd(5);\n    return `[${levelString}] ${category.toUpperCase()} ${msg}`;\n  }\n}</code></p><p></p><p>LogAppender是另一个可替换的概念，它会负责将日志消息追加到日志中：</p><p></p><p><code lang=\"text\">export abstract class LogAppender {\n  abstract append(level: LogLevel, category: string, msg: string): void;\n}</code></p><p></p><p>默认实现会将日志消息打印至控制台。</p><p></p><p><code lang=\"text\">@Injectable()\nexport class DefaultLogAppender implements LogAppender {\n  append(level: LogLevel, category: string, msg: string): void {\n    console.log(category + ' ' + msg);\n  }\n}</code></p><p></p><p>尽管我们只能有一个LogFormatter，但是这个库支持多个LogAppender。例如，第一个LogAppender可以将消息写到控制台，而第二个可以将消息发送至服务器。</p><p></p><p>为了实现这一点，各个LogAppender是通过多个提供者（provider）注册的。所以，Injector 在一个数组中将它们全部返回。因为数组无法作为 DI 令牌，所以样例使用了一个InjectionToken来代替：</p><p></p><p><code lang=\"null\">export const LOG_APPENDERS = new InjectionToken(\"LOG_APPENDERS\");</code></p><p></p><p>LoggserService本身会通过 DI 来接收LoggerConfig、LogFormatter和包含LogAppender的数组，并允许为多个LogLevel记录日志信息：</p><p></p><p><code lang=\"text\">@Injectable()\nexport class LoggerService {\n  private config = inject(LoggerConfig);\n  private formatter = inject(LogFormatter);\n  private appenders = inject(LOG_APPENDERS);\n\n  log(level: LogLevel, category: string, msg: string): void {\n    if (level &lt; this.config.level) {\n      return;\n    }\n    const formatted = this.formatter.format(level, category, msg);\n    for (const a of this.appenders) {\n      a.append(level, category, formatted);\n    }\n  }\n  error(category: string, msg: string): void {\n    this.log(LogLevel.ERROR, category, msg);\n  }\n\n  info(category: string, msg: string): void {\n    this.log(LogLevel.INFO, category, msg);\n  }\n\n  debug(category: string, msg: string): void {\n    this.log(LogLevel.DEBUG, category, msg);\n  }\n}</code></p><p></p><p></p><h2>黄金法则</h2><p></p><p></p><p>在开始介绍推断出的模式之前，我想强调一下提供服务的黄金法则：</p><p></p><p></p><blockquote>只要有可能，就使用 @Injectable({providedIn: ‘root’})</blockquote><p></p><p></p><p>在库中有些场景也应该使用这种方式，它提供了一些我们想要的特征：简单、支持摇树（tree-shakable），并且能够与懒加载协作。最后一项特征与其说是 Angular 的优点，不如说是底层打包器的优点：在懒加载包（bundle）中需要的所有内容都会放在这里。</p><p></p><p></p><h2>模式：提供者工厂（Provider Factory）</h2><p></p><p></p><p></p><h3>意图</h3><p></p><p></p><p>为可重用库提供服务配置可重用库替换预定义的实现细节</p><p></p><h3>描述</h3><p></p><p></p><p>提供者工厂是一个函数，它会为给定的库返回一个包含提供者的数组。这个数组会被转换为 Angular 的EnvironmentProviders类型，以确保提供者只能在环境作用域内使用，具体来讲就是根作用域以及懒路由配置引入的作用域。</p><p></p><p>Angular 和 NGRX 将这些函数放在provider.ts文件中。</p><p></p><p></p><h3>样例</h3><p></p><p></p><p>如下的提供者函数（Provider Function）provideLogger会接收一个LoggerConfiguration，并使用它来创建一些提供者：</p><p></p><p><code lang=\"text\">export function provideLogger(\n  config: Partial\n): EnvironmentProviders {\n  // using default values for missing properties\n  const merged = { ...defaultConfig, ...config };\n\n  return makeEnvironmentProviders([\n    {\n      provide: LoggerConfig,\n      useValue: merged,\n    },\n    {\n      provide: LogFormatter,\n      useClass: merged.formatter,\n    },\n    merged.appenders.map((a) =&gt; ({\n      provide: LOG_APPENDERS,\n      useClass: a,\n      multi: true,\n    })),\n  ]);\n}</code></p><p></p><p>缺失的配置会使用默认配置的值。Angular 的makeEnvironmentProviders会将Provider数组包装到一个EnvironmentProviders实例中。</p><p></p><p>这个函数允许消费库的应用在引导过程中像使用其他库（如HttpClient或Router）那样设置 logger：</p><p></p><p><code lang=\"text\">bootstrapApplication(AppComponent, {\n  providers: [\n\n    provideHttpClient(),\n\n    provideRouter(APP_ROUTES),\n\n    [...]\n\n    // Setting up the Logger:\n    provideLogger(loggerConfig),\n  ]\n}</code></p><p></p><p></p><h3>使用场景和变种</h3><p></p><p></p><p>在所有经过验证的库中，这是一个常用的模式。Router和HttpClient的提供者工厂有第二个可选参数，以提供额外的特性（参见下文的特性模式）。NGRX 支持为 reducer 提供令牌或具体的对象，而不是传入具体的服务实现（如LogFormatter）。HttpClient能够通过with函数（参见下文的特性模式）获取函数化拦截器的数组。这些函数也会被注册为服务。</p><p></p><h2>模式：特性（Feature）</h2><p></p><p></p><p></p><h3>意图</h3><p></p><p></p><p>激活或配置可选的特性使这些特性支持摇树通过当前环境作用域提供底层服务</p><p></p><h3>描述</h3><p></p><p></p><p>提供者工厂会接收一个包含特性对象的可选数组。每个特性对象都有一个叫做kind的标识符和一个providers数组。kind属性允许校验传入特性的组合。比如，可能会存在互斥的特性，如为HttpClient同时提供配置 XSRF 令牌处理和禁用 XSRF 令牌处理的特性。</p><p></p><p></p><h3>样例</h3><p></p><p></p><p>我们的样例使用了一个着色的特性，为不同的LoggerLevel显示不同的颜色：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/19/19594b11895996c649b3280e14b30681.png\" /></p><p></p><p>为了对特性进行分类，我们使用了一个枚举：</p><p></p><p><code lang=\"text\">export enum LoggerFeatureKind {\n    COLOR,\n    OTHER_FEATURE,\n    ADDITIONAL_FEATURE\n}</code></p><p></p><p>每个特性都使用LoggerFeature对象来表示：</p><p></p><p><code lang=\"text\">export interface LoggerFeature {\n  kind: LoggerFeatureKind;\n  providers: Provider[];\n}</code></p><p></p><p>为了提供着色特性，引入了遵循with Feature命名模式的工厂函数：</p><p></p><p><code lang=\"text\">export function withColor(config?: Partial): LoggerFeature {\n  const internal = { ...defaultColorConfig, ...config };\n\n  return {\n    kind: LoggerFeatureKind.COLOR,\n    providers: [\n      {\n        provide: ColorConfig,\n        useValue: internal,\n      },\n      {\n        provide: ColorService,\n        useClass: DefaultColorService,\n      },\n    ],\n  };\n}</code></p><p></p><p>提供者工厂通过可选的第二个参数接收多个特性，它们定义为rest数组：</p><p></p><p><code lang=\"text\">export function provideLogger(\n  config: Partial,\n  ...features: LoggerFeature[]\n): EnvironmentProviders {\n  const merged = { ...defaultConfig, ...config };\n\n  // Inspecting passed features\n  const colorFeatures =\n    features?.filter((f) =&gt; f.kind === LoggerFeatureKind.COLOR)?.length ?? 0;\n\n  // Validating passed features\n  if (colorFeatures &gt; 1) {\n    throw new Error(\"Only one color feature allowed for logger!\");\n  }\n\n  return makeEnvironmentProviders([\n    {\n      provide: LoggerConfig,\n      useValue: merged,\n    },\n    {\n      provide: LogFormatter,\n      useClass: merged.formatter,\n    },\n    merged.appenders.map((a) =&gt; ({\n      provide: LOG_APPENDERS,\n      useClass: a,\n      multi: true,\n    })),\n\n    // Providing services for the features\n    features?.map((f) =&gt; f.providers),\n  ]);\n}</code></p><p></p><p>特性中kind属性用来检查和验证传入的特性。如果一切正常的话，特性中发现的提供者会被放到返回的EnvironmentProviders对象中。</p><p></p><p>DefaultLogAppender能够通过依赖注入获取着色特性提供的ColorService：</p><p></p><p><code lang=\"text\">export class DefaultLogAppender implements LogAppender {\n  colorService = inject(ColorService, { optional: true });\n\n  append(level: LogLevel, category: string, msg: string): void {\n    if (this.colorService) {\n      msg = this.colorService.apply(level, msg);\n    }\n    console.log(msg);\n  }\n}</code></p><p></p><p>由于特性是可选的，DefaultLogAppender将optional: true传入到了inject中。如果特性不可用的话会遇到异常。除此之外，DefaultLogAppender还需要对null值进行检查。</p><p></p><p></p><h3>使用场景和变种</h3><p></p><p></p><p>Router使用了它，比如用来配置预加载或激活调试跟踪。HttpClient使用了它，比如提供拦截器、配置 JSONP 和配置 / 禁用 XSRF 令牌的处理。Router和HttpClient都将可能的特性组合成了一个联合类型（如export type AllowedFeatures = ThisFeature | ThatFeature）。这能够帮助 IDE 提示内置特性。有些实现注入到了当前Injector，并使用它来查找配置了哪些特性。这是对使用optional: true的一种命令式替换。Angular 的特性实现在kind和providers属性上添加了ɵ前缀，因此将它们声明成了内部属性。</p><p></p><p></p><h2>模式：配置提供者工厂（Configuration Provider Factory）</h2><p></p><p></p><p>配置现存的服务。提供额外的服务并将它们与现存的服务注册到一起。在嵌套环境作用域中扩展服务的行为。</p><p></p><h2>描述</h2><p></p><p></p><p>配置提供者工厂能够扩展现存服务的行为。它们可以提供额外的服务，并使用ENVIRONMENT_INITIALIZER来获取所提供的服务以及要扩展的现存服务的实例。</p><p></p><p></p><h2>样例</h2><p></p><p></p><p>我们假设有个扩展版本的LoggerService，可以为每个日志类别定义一个额外的LogAppender：</p><p></p><p><code lang=\"text\">@Injectable()\nexport class LoggerService {\n\n    private appenders = inject(LOG_APPENDERS);\n    private formatter = inject(LogFormatter);\n    private config = inject(LoggerConfig);\n    [...]\n\n    // Additional LogAppender per log category\n    readonly categories: Record = {};\n\n    log(level: LogLevel, category: string, msg: string): void {\n\n        if (level &lt; this.config.level) {\n            return;\n        }\n\n        const formatted = this.formatter.format(level, category, msg);\n\n        // Lookup appender for this very category and use\n        // it, if there is one:\n        const catAppender = this.categories[category];\n\n        if (catAppender) {\n            catAppender.append(level, category, formatted);\n        }\n\n        // Also, use default appenders:\n        for (const a of this.appenders) {\n            a.append(level, category, formatted);\n        }\n\n    }\n\n    [...]\n}</code></p><p></p><p>为了给某个类别配置LogAppender，可以引入另外一个提供者工厂：</p><p></p><p><code lang=\"text\">export function provideCategory(\n  category: string,\n  appender: Type\n): EnvironmentProviders {\n  // Internal/ Local token for registering the service\n  // and retrieving the resolved service instance\n  // immediately after.\n  const appenderToken = new InjectionToken(\"APPENDER_\" + category);\n\n  return makeEnvironmentProviders([\n    {\n      provide: appenderToken,\n      useClass: appender,\n    },\n    {\n      provide: ENVIRONMENT_INITIALIZER,\n      multi: true,\n      useValue: () =&gt; {\n        const appender = inject(appenderToken);\n        const logger = inject(LoggerService);\n\n        logger.categories[category] = appender;\n      },\n    },\n  ]);\n}</code></p><p></p><p>这个工厂为LogAppender类创建了一个提供者。但是，我们并不需要这个类，而是需要它的一个实例。同时，我们还需要Injector解析该示例的依赖。这两者均需要在通过注入检索LogAppender时提供。</p><p></p><p>确切地讲，这是通过ENVIRONMENT_INITIALIZER实现的，它是绑定到ENVIRONMENT_INITIALIZER令牌并指向某个函数的多个提供者。它能够获取注入的LogAppender和LoggerService。然后，LogAppender会被注册到 logger 上。</p><p></p><p>这样，就能扩展甚至来自父作用域的现有LoggerService。例如，如下的样例假设LoggerService在根作用域中，而额外的日志级别是在懒加载路由中设置的：</p><p></p><p><code lang=\"text\">export const FLIGHT_BOOKING_ROUTES: Routes = [\n  {\n    path: '',\n    component: FlightBookingComponent,\n\n    // Providers for this route and child routes\n    // Using the providers array sets up a new\n    // environment injector for this part of the\n    // application.\n    providers: [\n      // Setting up an NGRX feature slice\n      provideState(bookingFeature),\n      provideEffects([BookingEffects]),\n\n      // Provide LogAppender for logger category\n      provideCategory('booking', DefaultLogAppender),\n    ],\n    children: [\n      {\n        path: 'flight-search',\n        component: FlightSearchComponent,\n      },\n      [...]\n    ],\n  },\n];\n</code></p><p></p><p></p><h3>使用场景和变种</h3><p></p><p></p><p>@ngrx/store使用该模式来注册特性切片（slice）。@ngrx/effects使用该模式来装配特性提供的效果。withDebugTracing特性使用该模式订阅Router的events Observable。</p><p></p><h2>模式：NgModule 桥</h2><p></p><p></p><p></p><h3>意图</h3><p></p><p></p><p>当切换到独立 API 时，不能破坏使用NgModules的现有代码。支持上述类型的应用通过来自提供者工厂的EnvironmentProviders设置应用的部分功能。</p><p></p><h3>描述</h3><p></p><p></p><p>NgModule 桥是一个通过提供者工厂衍生的 NgModule。为了让调用者对服务有更多的控制权，可以使用像forRoot这样的静态方法。这些方法也可以接收一个配置对象。</p><p></p><p></p><h3>样例</h3><p></p><p></p><p>如下的NgModules以传统的方式设置 Logger。</p><p></p><p><code lang=\"text\">@NgModule({\n  imports: [/* your imports here */],\n  exports: [/* your exports here */],\n  declarations: [/* your delarations here */],\n  providers: [/* providers, you _always_ want to get, here */],\n})\nexport class LoggerModule {\n  static forRoot(config = defaultConfig): ModuleWithProviders {\n    return {\n      ngModule: LoggerModule,\n      providers: [\n        provideLogger(config)\n      ],\n    };\n  }\n\n  static forCategory(\n    category: string,\n    appender: Type\n  ): ModuleWithProviders {\n    return {\n      ngModule: LoggerModule,\n      providers: [\n        provideCategory(category, appender)\n      ],\n    };\n  }\n}</code></p><p></p><p>当使用 NgModules 时，这种方式是很常用的，所以消费者可以利用现有的知识和惯例。</p><p></p><p></p><h3>使用场景和变种</h3><p></p><p></p><p>我们检查过的库均使用这种模式以保持向后兼容性。</p><p></p><h2>模式：服务链</h2><p></p><p></p><p></p><h3>意图</h3><p></p><p></p><p>使服务能够委托给父作用域中的另一个实例。</p><p></p><h3>描述</h3><p></p><p></p><p>当同一个服务被放在多个嵌套的环境 injector 中时，我们通常只能得到当前作用域的服务实例。因此，在嵌套作用域中，对服务的调用无法反映到父作用域中。为了解决这个问题，服务可以在父作用域中查找自己的实例并将调用委托给它。</p><p></p><p></p><h3>样例</h3><p></p><p></p><p>假设为一个懒加载的路由再次提供了日志库：</p><p></p><p><code lang=\"text\">export const FLIGHT_BOOKING_ROUTES: Routes = [\n  {\n    path: '',\n    component: FlightBookingComponent,\n    canActivate: [() =&gt; inject(AuthService).isAuthenticated()],\n    providers: [\n      // NGRX\n      provideState(bookingFeature),\n      provideEffects([BookingEffects]),\n\n      // Providing **another** logger for this part of the app:\n      provideLogger(\n        {\n          level: LogLevel.DEBUG,\n          chaining: true,\n          appenders: [DefaultLogAppender],\n        },\n        withColor({\n          debug: 42,\n          error: 43,\n          info: 46,\n        })\n      ),\n\n    ],\n    children: [\n      {\n        path: 'flight-search',\n        component: FlightSearchComponent,\n      },\n      [...]\n    ],\n  },\n];</code></p><p></p><p>在这里，我们在懒加载路由及其子路由中的环境 injector 中设置了另外一套 Logger 的服务。该服务会屏蔽掉父作用域中对应的服务。因此，当懒加载作用域中的组件调用LoggerService时，父作用域中的服务不会被触发。</p><p></p><p>为了防止这种情况，可以从父作用域中获取LoggerService。更准确地说，这不一定是父作用域，而是提供LoggerService的“最近的祖先作用域”。随后，该服务可以委托给它的父服务。这样，服务就被链结起来了。</p><p></p><p><code lang=\"text\">@Injectable()\nexport class LoggerService {\n  private appenders = inject(LOG_APPENDERS);\n  private formatter = inject(LogFormatter);\n  private config = inject(LoggerConfig);\n\n  private parentLogger = inject(LoggerService, {\n    optional: true,\n    skipSelf: true,\n  });\n  [...]\n\n  log(level: LogLevel, category: string, msg: string): void {\n\n    // 1. Do own stuff here\n    [...]\n\n    // 2. Delegate to parent\n    if (this.config.chaining &amp;&amp; this.parentLogger) {\n        this.parentLogger.log(level, category, msg);\n    }\n  }\n  [...]\n}</code></p><p></p><p>当使用inject来获取父 LoggerService 时，我们需要传递optional: true，避免祖先作用域在没有提供LoggerService时出现异常。传递skipSelf: true能够确保只有祖先作用域会被搜索。否则，Angular 会从当前作用域开始进行搜索，因此会返回调用服务本身。</p><p></p><p>另外，上述的样例允许通过LoggerConfiguration中的新标记chaining启用或停用这种行为。</p><p></p><p></p><h3>使用场景和变种</h3><p></p><p></p><p>HttpClient使用这种模式可以在父作用域中触发HttpInterceptor。关于链式HttpInterceptor的更多细节，可以参阅 该文。在这里，链式行为可以通过一个单独的特性来激活。从技术上讲，这个特性注册了另一个拦截器，将调用委托给了父作用域中的服务。</p><p></p><h2>模式：函数式服务</h2><p></p><p></p><p></p><h3>意图</h3><p></p><p></p><p>通过使用函数即服务，使库的使用更加轻量级。通过使用临时函数来减少间接影响。</p><p></p><h3>描述</h3><p></p><p></p><p>库能够避免强迫消费者按照给定的接口实现基于类的服务，而是允许使用函数。在内部，它们可以使用useValue注册服务。</p><p></p><p></p><h3>样例</h3><p></p><p></p><p>在本例中，消费者可以直接传入一个函数，作为LogFormatter传递给provideLogger：</p><p></p><p><code lang=\"text\">bootstrapApplication(AppComponent, {\n  providers: [\n    provideLogger(\n      {\n        level: LogLevel.DEBUG,\n        appenders: [DefaultLogAppender],\n\n        // Functional CSV-Formatter\n        formatter: (level, cat, msg) =&gt; [level, cat, msg].join(\";\"),\n      },\n      withColor({\n        debug: 3,\n      })\n    ),\n  ],\n});</code></p><p></p><p>为了允许这样做，Logger 需要使用LogFormatFn类型来定义函数的签名：</p><p></p><p><code lang=\"text\">export type LogFormatFn = (\n  level: LogLevel,\n  category: string,\n  msg: string\n) =&gt;</code></p><p></p><p>同时，因为函数不能用作令牌，所以需要引入InjectionToken：</p><p></p><p><code lang=\"text\">export const LOG_FORMATTER = new InjectionToken(\n  \"LOG_FORMATTER\"\n);</code></p><p></p><p>这个InjectionToken既支持基于类的LogFormatter，也支持函数式的LogFormatter。</p><p></p><p>这可以防止破坏现有的代码。为了支持这两种情况，providerLogger需要以稍微不同的方式处理这两种情况：</p><p></p><p><code lang=\"text\">export function provideLogger(config: Partial, ...features: LoggerFeature[]): EnvironmentProviders {\n\n    const merged = { ...defaultConfig, ...config};\n\n    [...]\n\n    return makeEnvironmentProviders([\n        LoggerService,\n        {\n            provide: LoggerConfig,\n            useValue: merged\n        },\n\n        // Register LogFormatter\n        //  - Functional LogFormatter:  useValue\n        //  - Class-based LogFormatters: useClass\n        (typeof merged.formatter === 'function' ) ? {\n            provide: LOG_FORMATTER,\n            useValue: merged.formatter\n        } : {\n            provide: LOG_FORMATTER,\n            useClass: merged.formatter\n        },\n\n        merged.appenders.map(a =&gt; ({\n            provide: LOG_APPENDERS,\n            useClass: a,\n            multi: true\n        })),\n        [...]\n    ]);\n}</code></p><p></p><p>基于类的服务是用useClass注册的，而对于函数式服务，则需要使用useValue。</p><p></p><p>此外，LogFormatter的消费者需要为函数式和基于类的方式进行调整：</p><p></p><p><code lang=\"text\">@Injectable()\nexport class LoggerService {\n  private appenders = inject(LOG_APPENDERS);\n  private formatter = inject(LOG_FORMATTER);\n  private config = inject(LoggerConfig);\n\n  [...]\n\n  private format(level: LogLevel, category: string, msg: string): string {\n    if (typeof this.formatter === 'function') {\n        return this.formatter(level, category, msg);\n    }\n    else {\n        return this.formatter.format(level, category, msg);\n    }\n  }\n\n  log(level: LogLevel, category: string, msg: string): void {\n    if (level &lt; this.config.level) {\n      return;\n    }\n\n    const formatted = this.format(level, category, msg);\n\n    [...]\n  }\n  [...]\n}</code></p><p></p><p></p><h3>使用场景和变种</h3><p></p><p></p><p>HttpClient允许使用函数式拦截器。它们是通过一个特性注册的（参见特性模式）。Router允许使用函数来实现守卫和解析器。</p><p></p><p></p><h5>原文链接：</h5><p></p><p></p><p><a href=\"https://www.angulararchitects.io/en/aktuelles/patterns-for-custom-standalone-apis-in-angular\">https://www.angulararchitects.io/en/aktuelles/patterns-for-custom-standalone-apis-in-angular</a>\"</p><p></p><h5>相关阅读：</h5><p></p><p><a href=\"https://xie.infoq.cn/article/7baec545b8202471064494a69\">2023 重学 Angular</a>\"</p><p><a href=\"https://www.infoq.cn/article/oONc5r5opJF64kBCtzIv\">Angular v15 发布：可以脱离 NgModules 构建组件了</a>\"</p><p><a href=\"https://xie.infoq.cn/article/fd637cabb33b1ab82d5742dee\">AngularJS 进阶 (二十五)requirejs + angular + angular-route 浅谈 HTML5 单页面架</a>\"</p><p><a href=\"https://xie.infoq.cn/article/61e968dd45368e77c03fcbe10\">谈谈企业级前端 Angular 应用的定制化二次开发话题</a>\"</p>",
    "publish_time": "2023-02-10 13:50:44",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "马斯克开会当场解雇Twitter首席工程师：我有1亿多粉丝，他却说公众对我失去兴趣",
    "url": "https://www.infoq.cn/article/qhgHLsmYuUuAZC9J4S2Q",
    "summary": "<p></p><p></p><blockquote>自马斯克入主&nbsp;Twitter&nbsp;以来，Twitter&nbsp;员工的大部分时间都被耗在三件事上：灭火，执行不可能完成的任务，再就是在缺少明确指导和预期结果的情况下「提高效率」。</blockquote><p></p><p></p><p></p><h2>马斯克质问自己在&nbsp;Twitter&nbsp;的影响力下降&nbsp;&nbsp;</h2><p></p><p></p><p><a href=\"https://www.infoq.cn/article/uNeOAuw1HXjKFBHjwRjk\">Twitter 2.0 </a>\"时代的内乱仍在继续，员工们整天沉浸在难以捉摸的企业破产和岗位裁撤恐惧当中，甚至会担心自己被联邦贸易委员会突然拉去问话。</p><p></p><p>最近几个礼拜，伊隆·马斯克最关注的问题就是……有多少人在看他的推文。</p><p></p><p>上周，这位 Twitter CEO 尝试把自己的账户设置成了私有，想看看这样能不能增加粉丝。而在此之前，马斯克刚刚听到几个著名右翼账户的抱怨，说是 Twitter 最近的调整削弱了他们的社会影响力。</p><p></p><p>周二，马斯克突然把一帮工程师和顾问召集到房间里，质问他们自己的交互数量为什么变少了。</p><p></p><p>了解会议情况的多位消息人士证实，马斯克当场发飙称“这太荒谬了 ——&nbsp;“我有超过 1 亿粉丝，但得到的观看数就只有几万个。”</p><p></p><p>公司仅存的两名首席工程师之一，对于马斯克社会影响力下降的问题给出了可能的解释：在这位特斯拉 CEO 宣布要以 440 亿美元收购 Twitter 之后，公众对于他的过格举动逐渐失去了兴趣。</p><p></p><p></p><h2>“你被炒了，你被炒了”&nbsp;&nbsp;</h2><p></p><p></p><p>员工向马斯克展示了其账户参与度的内部数据和谷歌趋势图。</p><p></p><p>从结果来看，马斯克在去年 4 月时处于搜索排名中人气“最高”的第一梯队，得分为“100”。但现在，他的得分只有 9 分。工程师此前曾调查过马斯克的社交活动是否受到人为限制，但没有发现任何证据表明当前算法对其存在偏见。</p><p></p><p>但马斯克根本不吃这一套。</p><p></p><p>马斯克直接告诉这位工程师，“你被炒了，你被炒了。”（考虑到马斯克有骚扰 Twitter 前员工的前科，这里隐去该工程师的姓名。）</p><p></p><p>据一位现任员工透露，<a href=\"https://www.infoq.cn/article/5LYIHLWuPVU8btDrfBut\">马斯克</a>\"对该工程师一直以来的工作并不满意，并要求员工持续跟踪他每条推文获得的赞数。</p><p></p><p>近两个月前，Twitter 开始为每条推文添加已观看次数这一指标。当时马斯克承诺，这个功能是为了让全世界更好地了解 Twitter 平台的社交活力。</p><p></p><p>他在推文中写道，“这证明 Twitter 的真实活力比人们印象中更强，因为超过 90% 的 Twitter 用户只看内容，却并不喜欢发推、回复或点赞这类公开操作。”</p><p></p><p>可从现在的结果看，开放查看次数反而产生了负面效果。与庞大的关注者列表相比，大部分帖子的观看数简直少得可怜。与此同时，最近一项研究表明，自马斯克上任以来，Twitter 在美国的使用率下降了近 9%。</p><p></p><p>据 Twitter 方面的消息人士称，观看次数功能本身也可能导致参与度下降，并进一步拉低观看量。因为为了适应新的视图布局，现在的点赞和转发按钮都变得更小，所以用户越来越懒得专门去操作。</p><p></p><p></p><h2>内部一片混乱&nbsp;&nbsp;</h2><p></p><p></p><p>“这里现在一片混乱，而我们正在传播这份混乱。”</p><p></p><p>参与度下降的另一个明显原因，在于 Twitter 产品的故障越来越多 —— 无故消失的 @、不断变化的算法优先级还有随机显示的未关注账户推文，种种问题让用户感到困惑。本周三，Twitter 公司遭遇了马斯克接手以来最严重的中断事故之一。用户莫名其妙收到通知，称“您已超过每日推文发送上限。”</p><p></p><p>事实证明，一名员工无意间删除了某项内部服务的数据，而该服务的作用正是限制 Twitter 的使用频率。以往专门负责该服务的团队已经在去年 11 月被裁掉。</p><p></p><p>一位现任员工表示，“大家都听过康威定律，「你呈现出来的就是组织内部的沟通方式」。这里现在一片混乱，而我们正在传播这份混乱。”</p><p></p><p>通过对 Twitter 员工的采访，可以看到这家公司如今正弥漫着深陷泥潭却无力挣脱的绝望气氛。马斯克正以突发奇想式的产品管理思路让员工快速发布新功能，即使引发核心服务崩溃也在所不惜。但越是这样折腾，马斯克就越难收回他收购 Twitter 所花出去的 440 亿美元，甚至可能加速这家社交企业的破产。</p><p></p><p>一名员工坦言，“我们没收到多少有说服力的长期战略。我们的大部分时间都被耗在三件事上：灭火（主要是因为把重要的员工解雇掉了，所以到处都在爆发意外问题），执行不可能完成的任务，再就是在缺少明确指导和预期结果的情况下「提高效率」。从我的角度来看，我们面对的就是一处四下起火的‘垃圾场’，救完这里还有那里。”</p><p></p><p>马斯克还总是把产品反馈写在推文里，这也让员工们倍感头痛。</p><p></p><p>“他经常会在半夜醒来，然后写一段毫无意义的推文。他会突然跑过来，说「某人说无法在当前平台上实现这个功能」，然后我们就得四处奔波解决这个孤立的用例。这完全没有任何意义。”</p><p></p><p>旧金山总部这边，业主已经在起诉 Twitter 拖欠租金，压抑的气氛也笼罩在员工们头顶。当人们在大厅里简单寒暄时，问的都是“你最近参加什么面试了？”和“拿到录取通知没有？”总部 8 层设有休息床位，员工需要提前预定才能使用。</p><p></p><p>另一位在座员工表示，“工作日晚间，这些床位大多都被预订满了。”</p><p></p><p>在马斯克入驻之前，Twitter 曾经凭借丰富的福利待遇成为无数人求职的目标，但如今种种风光已不再。零食饮料？“糟透了，这可能是过去日子过得太舒服。而且我必须得抱怨一句，他们选的应该是世界上最差的咖啡供应商。”</p><p></p><p></p><h2>Slack 变成“鬼城”&nbsp;&nbsp;</h2><p></p><p></p><p>而 Twitter 曾经的开放文化中心、员工意见交流平台<a href=\"https://www.infoq.cn/article/2rbINfiqx4rf7ELesSXM\"> Slack</a>\"，现在也彻底陷入沉寂。一名现任员工直接将其形容为“鬼城”。</p><p></p><p>“人们甚至不在这里讨论工作方面的事情。如今的情况令人心碎。跟 Slack 相比，我自己倒经常在 Signal 和 WhatsApp 上跟同事对话。在易主之前，团队频道经常会有大家周末娱乐安排的消息，但现在都没了。”</p><p></p><p>而且面对马斯克狂躁的质问，员工们往往不知道自己该给出正确的答案、还是安全的答案。</p><p></p><p>一位员工解释道，“面对提出的问题，我会在脑袋里盘算一下，想想最平和，最不容易犯错的答案应该是哪个。”</p><p></p><p>当然，也不是人人如此。“少数家伙明显就是钻营拍马的高手，他们特别善于利用这段明显的真空期。”</p><p></p><p></p><h2>并非一无是处 ——“Twitter 2.0”在某些方面确有改进&nbsp;&nbsp;</h2><p></p><p></p><p>尽管出现了动荡，但剩下的员工承认，所谓“Twitter 2.0”至少在某些方面确有改进。</p><p></p><p>有员工指出，“以往，Twitter 里充斥着各种无所事事的运营委员会。现在这种雷厉风行的行事节奏是有好处的，能让有改善意愿的员工快速获得行动许可。但这也是把双刃剑，行动太快可能会造成意想不到的后果。”</p><p></p><p>这位员工提到了 Twitter Blue“蓝 V”认证的灾难性重启。由于管控不力，大量知名品牌被冒名顶替，数十家顶级广告商决定逃离 Twitter 平台。</p><p></p><p>“如果伊隆能学会在某些重大决策前多加思考，避免草率行事，可能结果会好得多。他需要学习自己不了解的东西，让真正懂行的人接手。”</p><p></p><p>可问题是，“他完全不愿相信有哪些技术是自己不懂的，这确实令人沮丧。你不可能永远是那个最聪明、最懂行的人，不可能的。”</p><p></p><p>“他的立场很简单，「一切监管，统统滚蛋。」”</p><p></p><p>随着马斯克在冲动之下疯狂裁撤员工，一个个团队就此解体消失，他们的工作则被移交给情绪焦虑、而且不太熟悉这些工作内容的其他团队。</p><p></p><p>“这是在逼着人去当代码考古学家，追溯过去并努力理解当时发生了什么。”</p><p></p><p>与此同时，近期科技行业的整体裁员浪潮也让留在 Twitter 的人们不敢轻举妄动。</p><p></p><p>有员工表示，“我觉得大多数人之所以选择留下，就是因为最近科技行业整体环境不好，人们害怕找不到工作岗位。其实我知道，团队里的大多数人都在认真准备面试，一有机会就会离开 Twitter。”</p><p></p><p>至于监管机构对近期变化的审查压力，同样让人们感到不安。作为与联邦贸易委员会（FTC）达成的一项协议，Twitter 承诺在发布变更之前遵循一系列步骤，例如建立项目方案并开展安全与隐私性审查。</p><p></p><p>但员工们表示，自从马斯克接管公司以来，这些步骤已经被抛诸脑后。“他的立场很简单，「一切监管，统统滚蛋。」”</p><p></p><p>据说贸易委员会本季度将对 Twitter 公司开展审计，而员工们普遍怀疑 Twitter 根本就没有通过检查所需的必要文件。“FTC 合规性审计真的让人担心。”</p><p></p><p>去年，就在马斯克正式接手之前，联邦贸易委员会曾以违反协议为由对 Twitter 处以 1.5 亿美元罚款。再次违规不光会继续造成巨额损失，同时也会让 Twitter 成为头条新闻里的众矢之的 — 但到那个时候，马斯克在 Twitter 上的人气肯定又能大涨一波。按他的评判标准来看，这应该是个好消息吧……</p><p></p><p>参考链接：</p><p></p><p>https://www.theverge.com/2023/2/9/23593099/elon-musk-twitter-fires-engineer-declining-reach-ftc-concerns</p><p></p><p>https://www.shacknews.com/article/134120/elon-musk-fires-twitter-engineer</p>",
    "publish_time": "2023-02-10 14:04:01",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "在输掉ChatGPT首战前，谷歌的AIGC战略是什么？",
    "url": "https://www.infoq.cn/article/6bDGZW6yciiAOk3xVAYt",
    "summary": "<p>2022 年是<a href=\"https://www.infoq.cn/article/rggHjzaBfCVPV5hxTF7H\">生成式人工智能</a>\"的重要一年。大型语言模型在生成文本和软件代码方面继续取得进展。与此同时，随着 DALL-E 2、<a href=\"https://www.infoq.cn/article/SwDArsl8afPV6baZRyE0\">Imagen</a>\" 和 Stable Diffusion 等模型的引入，我们已经看到了文本到图像生成器的巨大进步。</p><p></p><p>这一年还标志着生成式人工智能模型的产品化进程加快。生成式模型的科学和技术正在成熟到能够解决实际问题的程度。现在，像微软和谷歌这样的公司正在寻找方法，在一个可能改变创造力未来的新形成的市场中占据领先地位。</p><p></p><p>此前，在 AI@ '22 会议上，谷歌展示了其在产品中利用生成模式的路线图。该公司的战略可能预示着该领域的发展方向，以及未来竞争格局可能发生的变化。</p><p></p><h2>谷歌的生成式模型</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ad/ad3dad12699bf5f01ebfe2d92eb73dcc.webp\" /></p><p></p><p>在 AI@ '22 上，谷歌研究院的首席科学家 Douglas Eck 列出了谷歌目前在四个领域对生成式模型的研究：文本、源代码、音频、图像和视频。</p><p></p><p>谷歌目前正在所有这些领域开展测试项目，着眼于在未来创造产品。Wordcraft Writers Workshop 是一个帮助作家从大型语言模型中获得写作帮助的项目。谷歌开发了 Wordcraft，这是一款使用语言模型 <a href=\"https://www.infoq.cn/article/76gYqPA2YU0YXCDHFvIE\">LaMDA</a>\" 的工具，根据用户提供的提示生成写作。该工具被设计为在一个迭代的过程中使用该模型，在这个过程中，人类作家和 LLM 互动，共同创造故事。</p><p></p><p>“使用 LaMDA 来编写完整的故事是一条死胡同。当它被用来添加情趣，添加到一个特定的角色或加强故事的一个方面时，它是一个更有效的工具，”Eck 说。“用户界面也必须正确。Wordcraft 工具从一开始就被设计为使作家能够与生成模型进行互动。”</p><p></p><p>学习代码是一个使用 LLM 为开发人员生成代码建议的项目。谷歌目前正在内部测试该工具，其中包括单行和多行代码完成建议。</p><p></p><p>AudioLM 使用语言模型来生成音频。该模型将一个音频样本作为输入并继续进行。它可以用来生成音乐和语音。</p><p></p><p>也许 Eck 在 AI@ '22 上展示的最先进的模型是文本到图像模型 Imagen 和 Parti。Imagen 的工作方式类似于 OpenAI 的 DALL-E 2，使用扩散模型将语言嵌入到图像中。Parti 使用 Transformer 架构，从文本标记中生成图像。DreamBooth 是一个模型，可以调整像 Imagen 这样的文本到图像生成器，在不同的背景下显示一个主题。而 DreamFusion 将扩散模型的力量与神经辐射场（neural radiance fields，NeRF）相结合，这是一种深度学习架构，可以从 2D 图像中创建 3D 模型。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/da/da0e59931d4a5779f89384fe1831814b.webp\" /></p><p></p><p>Eck 还展示了谷歌在视频生成方面的研究预览，包括 Imagen Video 和 Phenaki。ImageVideo 使用扩散模型来创建一系列高分辨率图像，这些图像可以缝合在一起来创建视频。Phenaki 基于 Transformer 架构，将一系列文本提示转换为一系列图像。Eck 还展示了如何将 Imagen Video 和 Phenaki 结合起来，从提示序列中创建高分辨率视频。</p><p></p><h2>谷歌的生成式模型的战略</h2><p></p><p></p><p>Eck 在整个演讲中明确表示，生成式模型并不是意味着自动化或取代人类的创造力。</p><p></p><p>“这不再是创造一幅真实画面的生成式模型，这是关于制作你自己创造的东西，”Eck 说，“技术应该服务于我们的需要，即对我们所做的事情拥有代理权和创造性的控制。”</p><p></p><p>他在讨论谷歌的“负责任的人工智能”战略时，进一步强调了这一点，并在演讲结束时说：“创造力是使我们所有人成为人类的一个重要部分。我认为，当我们开发这些人工智能系统时，必须牢记这一点。”</p><p></p><p>除了这种言论的公关方面，即旨在缓解公众对生成式人工智能模型取代人类创造力的担忧（这在很大程度上被夸大了），对控制的强调还具有引导该领域走向以人为本的人工智能的积极影响。人工智能系统的设计方式应该提供透明度和控制，以增强人类的能力。如果没有人类的控制和监督，像生成式模型这样的人工智能系统将表现不佳，因为它们不像我们人类那样掌握基本概念。</p><p></p><h2>谷歌能在生成式人工智能领域展开竞争吗？</h2><p></p><p></p><p>人工智能研究和产品化之间的差距可能非常难以弥补。当然，谷歌的 LLM 和文本到图像模型的质量并不比 OpenAI 的 GPT-3 和 DALL-E 2 差。但问题是，谷歌能否基于这些模型推出一款成功的产品？</p><p></p><p>在考虑将一项技术产品化时，有几个方面需要考虑。该技术是否会成为一个新产品的基础？如果不是，它是否会被整合到现有产品中？它解决的是什么问题，目前存在的替代解决方案是什么？该产品是否提供了足够的附加值来说服用户转换？它能否帮助巩固公司在现有市场的地位？</p><p></p><p>自然地，公司会试图达到容易实现的目标，也就是把技术带到他们已经擅长的市场。在写作领域，微软已经领先于谷歌。Office 365 比 G Suite 拥有更大的市场份额，微软在将 LLMs 集成到其产品中方面已经领先一步。</p><p></p><p>微软在编码方面也有领先优势，其 GitHub Copilot 和 Codex 已经处于生产模式，而谷歌的内部代码生成工具还没有进入生产模式。谷歌最受欢迎的开发工具是 Colab 和 Android Studio，这将为其提供一个测试的场所，让谷歌在准备就绪时测试并推出自己的代码人工智能。但这些 IDE 的市场份额无法与微软的 Visual Studio Code 和 GitHub Codespaces（也归微软所有）相提并论。</p><p></p><p>在图像、视频和音频领域，我认为 Adobe 将是生成式人工智能的赢家。Adobe 已经拥有最大的市场份额和成熟的工具，这些工具正在定期更新人工智能功能。而且，Adobe 已经在其工具套件中尝试使用生成式人工智能工具。</p><p></p><p>然而，这并不意味着现任者一定会在生成式人工智能领域占据主导地位。目前，我们正从我们今天使用的工具的角度来看待生成式模型，如文字处理器、IDE 和图像编辑应用程序。基本上，我们正在研究生成式模型如何能够自动化或改进我们已经在做的任务（完成我们的句子，编写代码块，编辑或生成照片，等等）。当我们创造新的工具系统和工作流程时，人工智能的真正潜力将得到充分发挥，这些系统可以充分利用生成模型日益增长的能力和人工智能的其他进步，以完全不同的方式做事（我有一些想法，我将在未来详细阐述）。</p><p></p><p>正如谷歌重塑了信息发现，亚马逊随着网络的普及重塑了购物模式一样，那些发现并拥抱人工智能新机遇的公司，必将改造现有市场或创造新的市场。</p><p></p><p>作者简介：</p><p>Ben Dickson，软件工程师，也是TechTalks 创始人，撰写关于科技、商业和政治的文章。</p><p></p><p>原文链接：</p><p>https://bdtechtalks.com/2022/11/07/google-generative-ai-strategy/</p>",
    "publish_time": "2023-02-10 14:48:18",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "微软、快手、荣耀技术专家，与你分享从技术到业务落地经验",
    "url": "https://www.infoq.cn/article/JPOpROxxEj2ePOdUKw9k",
    "summary": "<p></p><blockquote>有了技术不等于有了产品，有了产品不等于有了好的业务。产品是实现技术价值的管道，业务是实现产品价值的管道。</blockquote><p></p><p>&nbsp;</p><p>技术、产品、运营是业务发展的三方。如何做好三方协作，更好地实现业务发展？是许多伙伴关注的话题。</p><p>&nbsp;</p><p>在 <a href=\"https://archsummit.infoq.cn/202303/beijing/schedule\">ArchSummit 全球架构师峰会（北京站</a>\"）我们设置了【技术-产品-业务】专题，我们邀请快手高级算法专家谢淼博士担任专题出品人，负责整体的内容质量与品控。在此专题下，我们一共设置了三个Topic，下面是议题详细介绍：</p><p>&nbsp;</p><p>首先，我们邀请了专题出品人谢淼博士来分享第一个话题——《在线优化技术在快手联盟上的实践和产品化》，通过他的分享，你可以了解到 MAB 算法落地难点及解决方案、学习如何将 MAB 技术与在线大规模机器学习预估模型有机融合；</p><p>&nbsp;</p><p>其次，我们邀请了微软 STAC资深工程师姜燕，她将分享《Office JS 插件的落地实践与产品化探索》，通过她的分享，你可以了解如何在大型项目系统中安全快捷的结合新的前沿技术和功能；</p><p>&nbsp;</p><p>最后，我们邀请了荣耀 MagicOS 首席隐私安全规划专家殷高生，他将分享《双 TEE 隔离系统在手机数据安全的实践和产品化》，通过他的分享，你可以学习独特技术到场景的转化经验。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6a/6a992b1c014127901827a317baea60a1.png\" /></p><p></p><p></p><p>&nbsp;</p><p>通过这三个议题，期待为你提供更多的借鉴思路。欢迎大家来到ArchSummit全球架构师峰会北京站的现场，和大咖进行面对面的交流。除上述议题外，本次大会我们策划了还【数字化转型下的业务架构】【高并发架构实践】【可观测技术落地】以及【<a href=\"https://archsummit.infoq.cn/202303/beijing/track/1482\">云原生大数据专题</a>\"】等专题，点击阅读原文查看大会日程。</p><p>&nbsp;</p><p>直播推荐：</p><p>&nbsp;</p><p>伴随短视频行业的飞速发展和快手商业化的加速繁荣，2022 年快手联盟增长迅猛，作为移动开发者短视频商业生态联盟，快手联盟正在成为各行业撬动短视频、直播商业红利的新杠杆。</p><p>&nbsp;</p><p>InfoQ 邀请了快手的专家进行一场圆桌讨论，从业务，产品和算法技术角度，与大家聊聊快手联盟近年来在产研合作上的探索与创新。本次出席圆桌的嘉宾有：快手联盟运营中心负责人白晓航、快手联盟产品中心负责人晁杨以及快手高级算法专家<a href=\"https://archsummit.infoq.cn/202303/beijing/track/1453\">谢淼</a>\"博士。</p><p>&nbsp;</p><p>直播时间：2月15日 20:00-21:30</p><p>直播平台：InfoQ视频号、InfoQ Pro视频号、<a href=\"https://time.geekbang.org/\">极客时间</a>\"App、磁力引擎视频号、快手中学快手号、磁力学堂视频号</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/da/dae8ac656ffb48b1df0d5f07ec2852e2.jpeg\" /></p><p></p>",
    "publish_time": "2023-02-10 16:48:56",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "金融分布式多活架构在落地之时，都有哪些值得关注的点？",
    "url": "https://www.infoq.cn/article/72DVwj3RzWWdPFpQXuKm",
    "summary": "<p></p><blockquote>在2月8日晚，InfoQ 连麦了网易数帆云原生资深技术架构师 <a href=\"https://archsummit.infoq.cn/202303/beijing/presentation/5053\">翁扬</a>\"老师，为大家分享了金融分布式多活架构在落地时，都有哪些值得关注的点？本文为直播整理~</blockquote><p></p><p>&nbsp;</p><p></p><p></p><p>InfoQ：翁老师，您和大家打个招呼，能够介绍下您所在的团队以及您的工作内容？</p><p>翁扬：大家好，我是来自网易数帆轻舟云原生技术团队的翁扬，目前主要从事于云原生技术的学习研究，以及相关技术的落地工作。其实我日常所参与的工作内容和我所在的团队的目标有密切关系，网易数帆是网易集团旗下 To B 企业服务品牌，依托网易多年互联网技术积累，打造了云原生、大数据、人工智能、低代码等主要产品线，我们期望通过全链路产品、成熟解决方案、 优质原厂服务、大量实践经验、方法论指导，为企业量身打造领先、稳定、可控、创新 的云原生软件生产力平台、全链路数据生产力平台、企业智慧生产力平台。</p><p></p><p>所以我当前主要从事的工作基本都和云原生这块相关，我自己有十多年的软件开发经验，对于微服务和云原生等领域也持续在关注，比如早些年的微服务架构比较火，对spring cloud、Dubbo还有gRPC等一些微服务架构设计可能用到的技术选型有过比较深入的学习和实践，那段时间基本上有时候天天都专研在各种框架源码上，也是做了不少的技术积累。</p><p></p><p>这几年除了持续在技术领域的学习和探索之外，更多的是把精力花在了我们云原生产品包括后续会介绍到的分布式平台等的持续打磨，以及用户侧的技术落地工作，比如分布式平台建设、服务网格、应用多活等项目的设计和交付。因为作为一个产品，始终都是要面临商业化的问题，作为技术产品或者B端的产品，有时候最担心的就是出现闭门造成的情况，虽然我们很多都是基于内部集团的一些支撑经验总结和沉淀出来，但是问题就在于不同的行业，不同的领域，不同的用户的组织架构，对于一个产品的设计要求的影响也是非常大的。尤其这几年也是一直投身并参与金融行业的架构落地，发现金融行业相比其它行业有着更高的设计要求，同时在整个落地过程中也存在着很大的困难，那这也是我们团队以及我们的产品期望帮助用户解决的问题。</p><p></p><p>InfoQ：看介绍，您参与过一些金融级分布式技术平台建设项目，落地过程中也遇到了不少问题，能否简单介绍下，都遇到了什么样的问题？以及你们是怎么解决的？</p><p>翁扬：其实这几年在金融行业的一些分布式技术平台建设项目过程中，我觉得遇到的问题以及难度要远远超过我们之前所预想的，特别是真正在参与落地项目之前。一个产品在设计开发过程中的时候，大部分技术工程师，尤其技术架构师或者产品经理，可能都会有这种体验。那就是在产品化的开发过程中，前期“自我感觉非常良好”，你会觉得我当前设计的产品形态一定是用户迫切需要的，这个设计一定是业界最领先的，能够帮助用户去解决痛点，而实际的结果往往会让你大失所望，所以这是在做商业化过程中遇到的第一个比较大的问题。</p><p></p><p>这是面向产品设计驱动和面向解决问题驱动的两种方式本质的区别，并不是说我们的产品功能层面设计得天花乱坠不切实际，更多的是想说明产品在实际落地过程中，应该更多关注和聚焦在用户的实际使用场景和解决的问题，而不是一味的基于技术能够实现什么，然后去堆砌功能点，这只会让产品变得越来越臃肿，用户在使用上也会容易陷入一种迷茫状态，我究竟应该用哪个功能，怎么用这个功能。相反，反而一些业务团队他们自己也有一些技术平台或者工具，虽然界面比较简陋，功能比较简单，但解决的一个特定场景的问题，似乎从需求的角度方面匹配度更高一些，所以这是我们在落地过程中遇到的一个关于产品匹配度的问题。这个是做平台型产品经常容易陷入的一个误区，就是拿着锤子找钉子，觉得有这些功能，从技术实现出发去做设计，往往会导致很多功能用户可能并不一定用得到。</p><p></p><p>举个金融场景的例子，我们在做金融级的服务治理之前，有两个治理功能，叫做熔断和限流，大家都知道当出现突发状况的时候，一般的设计思路是要么是触发限流规则，返回419状态码之类的，要不就触发熔断规则来保护服务可用性。这个设计本身没什么问题，但是在金融系统里，就没有这么简单了，及时是已经触发了治理规则，但实际上已经返回了错误，或者即将会发生大量的错误返回，会导致整个连路上的错误率有明显的上升，这种情况是不太能接受的。所以在熔断和限流的基础上，还要结合一些指标监控，负载均衡算法等，尽可能多的把流量转移到一些处理能力更强的节点上，俗称“能力越大，责任也越大”就是这个意思，因为银行里一般对于某个业务团队的整体的请求响应的成功率是有要求的，所以有时候在设计的时候，就需要进一步去思考，从一些问题的本质出发去解决问题。而且，服务治理这个点，在银行的很多业务里也是基于类似于交易码或者服务码的概念的，和传统企业基于服务粒度或者接口粒度也是有所不太一样，这就是典型的产品匹配度的问题，金融行业有着比较特定的业务场景，是需要结合对于场景的深入理解才能做成一个更好用的产品，那这也是我们这些年来不断经验积累和沉淀到产品的一个方面。</p><p></p><p>那第二个我觉得遇到比较大的问题，应该是产品的落地兼容性方面，这个其实比较容易理解，也算是我们踩过的一些坑吧。金融行业相较于传统企业有着更高的监管要求，因为交付上线的哪怕一个小的功能都有可能会真实影响到我们的日常金融系统，业务一不小心某个bug可能会导致转账失败了，可能突然间又爆出一个安全漏洞，会让整个金融系统陷入了风险之中。所以金融行业在整个软件交付过程中，要做很多相关的安全扫描，包括不限于开源漏洞扫描、内存泄漏扫描、代码静态检查等等，做过这块的同学应该不太陌生，也深知这里面的痛苦，大家印象最深刻的我相信莫过于去年的log4j2的漏洞升级，当时被爆出来有漏洞之后，我记得那个时候刚好是周五，我们可以说是周末连夜紧急修复，最终把这个漏洞给堵上了。</p><p></p><p>其实一些安全修复最大的难处不在于说要紧急修复，而是有时候当你一个在用的框架被扫描出来说有风险要升级的时候，你需要充分评估升级的兼容性，以及升级后的相关影响，简单的话可能知识改个包依赖重新上线即可，有些推荐包的升级跨度太大，比如Spring boot要从1.x升级到2.x这种，可以算是非常大的挑战了，兼容性方面存在巨大的挑战，这个修改可能还需要进行大量的功能测试回归验证，投入的精力也是比较大的。好在我们在这些年的磨炼之后，一方面把现有发现的已知问题都已经修复了，另外是我们在内部也建设了相应的工具和体系来确保我们交付的产品是足够安全的，除此之外，为了更好的与一些银行内部的系统对接，我们在整个系统上也是采用了插件化设计，可以方便的对接不同银行或者企业内部的一些用户系统等，这也是我们在交付了多个项目之后打磨出来的一些灵活的对接特性，所以这是第二个问题，基本上都是在讲产品在落地过程中的一些“水土不服”的问题。</p><p>&nbsp;</p><p>InfoQ： 之前您谈过金融 IT 系统业务连续性的挑战，这里都包含哪些内容？</p><p>翁扬：简单来说，金融IT业务系统的连续性挑战主要是在业务连续性的技术挑战之上，又叠加了金融行业的一些特色的要求。主要呢可能有这么几个方面：</p><p></p><p>首先，是最本质的问题，如何有效的保障业务的连续性。保障的方式或者手段其实有很多，最核心的一个思想就是永远不要让核心业务有可能处在单点故障风险中，所以你看从技术架构的演进历程中，为了解决服务的单点故障，我们一般采用至少双副本高可用部署，并且尽可能分散在不同的服务器上。为了解决机房的故障，我们提出了同城双活的架构方案。那城市如果出现问题了怎么办，于是又提出了异地多活的架构方案。所以这是层层递进的，本质上都是为了解决不同级别的单点故障，主要我两个服务或者两个以上服务同时在线，那一旦其中一个出现问题的时候，就能随时提供服务，从而保障了业务的连续性。但这里说起来简单，实际上在这个设计过程中还是面临很多的技术问题，在软件开发领域，大家都知道，我们在引进一项新的技术或者一项新的架构的同时，往往会引入一些额外的问题，所以比如以多活来说，实际上他并不是说只是在多个城市部署多个机房同时部署业务这么简单，它还需要解决数据分片，数据一致性，跨区访问，业务改造等等问题，这里面的每个问题都是需要有很多技术和经验积累的，不是说随便找几个人就能随便做出来的。</p><p></p><p>其次，我们始终绕不开的一个问题，那就是成本问题。这里的成本不光光是说这个工具或者平台的开发的线性成本，我认为这些成本是相对于比较好理解和评估的。这个成本还包括一些隐性的潜在成本，比如业务的改造、接入成本，应用多活或者单元化的改造会比传统的比如微服务改造都要难和复杂，一定程度上说他是在微服务的基础上做的进一步的设计，比如应用多活中一项比较重要的能力是流量调拨，那流量调拨的基础首先得有一个统一的管理平台，并且能够通过对流量进行识别然后进行按照设定规则的转发，这个本来就是微服务框架所涉及的范畴之类的，所以想要做异地多活的业务改造，中间的成本其实不低，如何降低成本是我们在设计时要考虑的。</p><p></p><p>另外关于成本方面的一个考量是整个项目的投入产出比，前面介绍到，不同层级的容灾设计，提供的故障应对能力是不一样的，比如异地多活的架构能解决城市级别的故障，但是它的整体建设投入成本会比较高，那作为项目的负责人或者技术架构师。不得不需要思考，这个技术投资是否真的有必要。开玩笑的说，夸张一点，即使异地多活解决了城市级别的故障，那万一地球被三体攻击了，我们还需要考虑地球级别的容灾吗？答案严谨一点说应该是暂时不用，确实没有必要。所以想说，所有的技术都有它的适用性，没有一项技术是能一刀切解决所有问题的，多活也一样，在建设的时候也要评估好成本。</p><p>有一次在一个技术大会上，一个券商的技术负责人说了一句话，说真的出现城市级别的故障的时候，能做到保全好数据的完整性其实就已经很不错了，仔细想想确实也是这么一个道理，有时候最适合当前业务的需求的实现，往往是性价比最高的。</p><p></p><p>第三个点，我认为挑战可能在于如何在设计一个连续性保障系统时候，如何降低整体的系统复杂度和运维难度。比如我们在做一些容灾系统的设计，以多活为例，这里面会牵涉到很多的技术概念，同时也会横向交叉着一些流量治理的设计，用户在学习和理解这个系统的成本其实是比较高的，我们认为用户真正能够用好一个技术产品，是需要用户对于这个产品的设计有深入的理解，而降低用户的学习和理解成本，又反而成为了我们首要需要思考的方式，既要保证在设计上能有一些通用性，去适应不同的业务团队，业务场景，又要考虑在实现上不太过于抽象，导致用户在使用的时候不知所措，这是一个在系统设计复杂度方面考虑如何去优化的挑战。另外是运维方面，其实运维是一个长期的过程，系统上线之后，大部分可能都要转交到一些运维团队做日常的巡检、演练和配置等，有一些企业的多活容灾系统，与其说是系统，不如说是一个工具合集，一些常用的功能经常需要在不同的平台之间来回切换，可能数据指标在负责监控的团队开发提供，流量配置在负责服务治理的团队中提供，这样子的运维成本很高，并且往往由于数据分散，很多时候没有办法形成一些统一的操作视图，用户使用运维起来也是相当心累。所以这是第三个关于在产品设计易用性方面的一个挑战，这往往会和团队的建设经验有关，有过多个类似的项目支撑，在这方面的设计往往会更好一些，可以避免走很多弯路。</p><p></p><p>最后一个点是想说的是，在金融行业特有的合规性方面的挑战。其实国家针对金融信息系统的容灾设计要求方面一直都有监管要求，早在08年就提出了类似《银行业信息系统灾难恢复管理规范》等面向银行的规范，而在21年的时候，也颁布了《金融信息系统多活技术规范》，文件里明确提出了针对金融业务连续性保障中要求的一些设计，要求，首先是架构分层，要求多活系统应当分为业务接入层、业务处理层和数据存储层这三层，其次是针对这三个层次，规范中都有详细的定义了设计要求和参考方法，此外还针对业务多活接入、监控、流量分配等方面进行要求；</p><p></p><p>规范中还给出了多活的关键评估指标，分别是多活业务集中度，多活接管容量能力、多活同城业务集中度，多活业务接管时间、多活数据恢复点目标，最后两个对应的通常缩写是RTO和RPO，所以对于金融行业，我们在连续性的系统设计时，它并不是可以完全按照自己的想法去开发的，是需要按照规范中的设计要求去做实现的，这是金融行业相对比较有特色的一个要求，也是一项比较大的挑战。</p><p>&nbsp;</p><p>InfoQ：面对这些问题，对于金融企业来说，在多活容灾的设计过程中，和普通企业的多活技术设计思路和落地形态上有哪些区别？</p><p>翁扬：先说设计思路方面，普通的企业，相比一些金融企业，在多活容灾方面的建设时间可能也更早一些，因为互联网出现过一个爆炸式的增长，需要对业务的容灾有更好的保障。在容灾技术设计方面，几年前我们就已经听到了各大互联网企业有一些关于异地多活和单元化的落地实践，尤其是当业务增长到一定的规模的时候，机房建设都会从单一城市扩展到了多个城市，甚至是全球各地，在这种机房的部署形态下，为了更充分的利用好资源，就会有了多活的架构设计。包括我们支撑过的网易在内的云音乐、严选等，也是结合自身的业务需求做了多活和单元化的设计。所以，总体感觉下来就是在容灾多活这个技术领域，早年大家各自为战，其实没有一个统一的标准，都是从解决各自的业务问题出发，不管白猫黑猫，反正能抓到老鼠的就是好猫，尽管技术设计上存在不少差异，但好在整个架构的顶层设计思想上基本上还是一致的，做多活为了解决业务的水平扩展和连续性保障问题，有一些单元化或者类似单元化之类的关键设计点。</p><p></p><p>而前面最后一点提到了，作为金融企业的IT团队，在做多活容灾的系统的设计时候，就不能完全按照自己想法来了，现在已经是有规范作为参考指引的。不管从架构的分层也好，从系统的关键设计指标也好，都是有一些相对比较明确的要求。</p><p></p><p>换个角度说，如果金融企业现在需要新做一套多活容灾系统的话，已经有一个顶层的架构设计参考建议或者标准，一定程度上也是能够有效避免走一些弯路的，所以这是围绕整个设计思路上的区别，我们在设计多活的时候，也是参考了《金融信息系统多活技术规范》的要求，目的也是为了更好的帮助金融用户能够大大减少建设成本，避免重复或者二次开发。</p><p></p><p>再来谈一下落地形态，首先是围绕上面的设计思路方面，会有一些业务架构分层的设计差异，在普通企业，其实整体上也绕不开这些分层设计，但是可能不叫这个名字或者表现的不明显，比如规范中提到的业务接入层，业务在普通的企业中是通过一些全局接入网关或者微服务网关做的，没有什么接入层这个概念，但实际上是有这个能力的。在金融多活的系统中，这个划分和界定也许会更加清晰，在使用上用户也更加能够达成一致的认知，所以这是围绕整个设计规范在落地上的差异，我觉得这个可能大家都比较好理解。</p><p></p><p>除此之外呢，我想重点介绍一下我们在金融行业的多年支撑过程中积累和理解的一些其它可能存在的落地差异，如果前面因为多活容灾建设时间不一样我们把它叫做时机的话，还有个比较大的差异就是动机。</p><p></p><p>随着这几年分布式技术的发展日趋成熟，很多银行在内的金融企业在做的一个事情就是传统的集中式架构往分布式架构的升级改造，也就是我们经常听到的“主机下移”，分布式架构的转型过程中，对于银行现有的业务来说，是一次巨大的冲击，不管是从架构形态上还是技术栈的实现，同时它也是一个非常时间窗口，允许金融业务趁着架构转型完成整个业务技术形态的升级，所以相比传统企业只是为了解决特定的问题而提出多活的方案，在金融场景下，这可能是一个大的技术升级浪潮的一个重要组成拼图，它是围绕整个分布式架构的体系去做设计和建设的，可能也会参考一些行业的技术标准，例如《金融分布式架构设计参考规范》之类的。</p><p></p><p>此外，在多年的金融项目支撑中我们发现，金融企业对于整个技术实现的要求往往更高，而且在落地实施过程中也更加保守。普通的企业，尤其是在互联网公司，讲的一般是快速迭代，快速试错，有一些功能设计经过一定的测试和验证没有问题之后，就可以考虑尝试接入线上流量去做灰度验证。但是在金融行业，任何一个哪怕比较小的功能或者技术点，都是需要经过前期非常充分的讨论，以及方案验证的，而且从设计上也会提出更高的要求，举个例子，比如流量切换这个点，很多时候能实现一些机房的切换就能满足大部分的应用场景了，在金融场景下，可能会要求按照特定规则流量、单元、机房甚至是地区不同的级别都能实现流量切换的能力，并且要求切换的过程是秒级无感知的，这个实现起来就比较困难了。在实施过程中，也是需要长期的线下稳定性测试之后，及时到了线上，也可能也是通过旁路的一些方式先做并行验证，等经过长时间的验证确保业务都正常稳定之后，才会可能执行相关的上线，所以这是在落地过程中金融行业的一些高要求的区别。</p><p></p><p>然后还有一点差异的是，可能大家并不陌生都听过，这两年提到的也比较多，那就是信创国产化，在金融行业，作为国家的重要支撑产业，我们的很多核心技术是需要自主掌控的，所以在技术的一些选型和落地方面，也是做了大量的信创适配和验证等方面的工作，比如适配了国产操作系统，国产数据库，开源治理等相关工作，这些在非金融的行业，目前是不需要考虑这些问题的。</p><p></p><p>InfoQ：能否大致介绍下分布式多活架构的技术实现，可以为在场的听众提供一些设计参考？</p><p>翁扬：涉及到整个分布式多活的架构实现，会比较复杂，也很难通过三言两句描述清楚，我就大概讲一下我们在多活产品设计的一些思路和理念，再结合几个比较关键的技术来做介绍，希望能给大家抛砖引玉，有一些启发。</p><p></p><p>那首先从设计理念上，前面其实有提到，我们整个分布式多活的架构是参考了金融行业的设计标准，也结合了多年我们金融行业的支撑经验和内部互联网的技术积累设计的，因为作为一个面向商业化的产品团队，我们一方面需要考虑前面说的产品匹配度的问题，我们希望设计出来的产品对于用户而言是能够开箱即用的，所以相较于一些分散式的产品组合形态，我们提供的是一站式的平台产品，在一个控制台系统内我们把网关、微服务、监控、中间件等多个产品能力通过多活容灾集中进行管理，用户可以比较方便的进行操作使用。</p><p></p><p>另外再说下一些技术实现部分，大家知道，技术是会一直往前发展的，这几年其实爆发了很多新的好用的技术。包括这几天热点很高的chatGPT，一项新的技术有时候突然就诞生了，并且被大家所熟悉和认可。技术的选型也和电子产品一样往往是“买新不买旧”，在开发新的产品，也会先调研当前业界的主流选型，选用一些当下最合适的实现方案。</p><p></p><p>作为金融行业，在新技术的探索和追求方面，也从未停止过。一方面是一些陈旧的技术实现随着时间的推移会变成一些历史包袱，成了新业务发展和新技术落地的阻碍。另外一方面是新技术的“诱惑”让金融行业的IT从业者们对一些新的设计理念、实现方案蠢蠢欲动。</p><p></p><p>那我们数帆轻舟云原生团队因为长期都在云原生领域里面摸爬打滚，算是在这方面积累了大量的经验，所以我们默认采用的整个技术实现也是偏云原生化的，比如整个平台架构是基于K8s部署的，在网关实现上基于云原生的代理Envoy做了很多优化和增强，而微服务也是基于微服务框架和Isito服务网格等多种技术引擎实现，满足客户的不同的架构设计需求，当然我们也在Proxyless方面做探索，包括像<a href=\"https://xie.infoq.cn/article/5ad16453bb7253dca4a4aab21\">Proxyless Agent</a>\"和 Ambient Mesh我们也做了一些探索和落地。为了解决一些用户的改造接入成本，我们在多活上的实现上，也基于我们的无侵入式的agent做了增强，在部分的业务场景下，用户可以不用修改业务代码也能完成一些多活的业务改造，这是关于技术实现侧的一些介绍。</p><p></p><p>不过可能听众也许会有疑问，很多银行目前部署都还是基于虚机甚至是物理机，云原生的这种架构和这些技术形态是不是真的能比较低成本的落地。确实如此，基于云原生的整个形态使我们的标准形态，在落地过程中其实还是会面临刚才我们讲的一些“水土不服”的问题，有时候确实也是需要去考虑做一些兼容和适配的，所以我们整个产品在设计上也把灵活性和扩展性作为一个比较重要的目标，允许在不同的环境都能做到快速适配，也能快速对接不同的现有系统，比如在多活的产品设计上，除了在Envoy上支持多活的流量切换外，考虑到不少银行也是基于Spring Cloud Gateway作为网关的，所以我们也是提供了相对应的实现模块，可以比较灵活帮助用户现有系统改造升级。</p><p></p><p>尽管在实现上，我们的云原生平台会考虑针对不同的客户实际落地情况去做适配，但我们也看到好的方面是，越来越多的客户也逐渐更加接受并实践一些云原生化的技术，比如部署从虚机开始逐渐转到容器，并且用上了K8s，服务治理也开始使用了服务网格这样子的云原生的治理系统，云原生是一种技术趋势，有时候你不得不承认，不知不觉其实大家都已经在这艘船上了。</p><p></p><p>InfoQ：多数据中心架构下，多活应用的架构有没有落地的最佳实践或者实施路径建议？</p><p>翁扬：前面基本上已经大致介绍过一些技术选型上我们的方案，就不再赘述了。关于落地最佳实践方面我想稍微补充一些关于整个系统在组织结构方面的最佳实践，在之前的一些项目支撑过程中，经常会被一些业务团队问到一个问题是，比如多活是一个相对比较庞大复杂的系统，在整个架构的落地过程中，究竟应该是以业务作为出发点去设计呢，还是从平台的角度去设计，这也是一个关乎与架构落地最佳实践的问题。</p><p></p><p>按照我们的经验是在一个企业内部，平台化的统一架构设计思路更佳，有这么几个原因。</p><p></p><p>第一，还是绕不开的成本问题，我们已经知道了多活容灾系统的建设成本其实并不低，如果只是聚焦于业务去做多活的设计，后期如果有另外一个业务团队也需要建设多活能力的话，会面临技术重复建设的质疑，为了避免重复造轮子，所以在一个企业内部尽可能应该是一套通用平台来应对不同的业务部门的容灾需求；</p><p></p><p>第二，建设难度偏高，业务团队首要的业绩目标应该是聚焦于业务方面，所以日常对于业务方面会更加精通。而类似于多活这样子的技术平台，建设所需要的技术和人才储备是巨大的，不是随便找几个人搞个几个月就能折腾出来应用的，一般而言，有个企业内部会有专门的基础架构团队来承接做这样子的基础设施的建设，他们在技术方面有着更多的经验和积累，也更加能够通过协调一些横向资源，比如数据库团队、运维团队等；</p><p></p><p>第三，不利于企业内部的规范统一，我们看到很多银行这几年在推行内部规范的统一，尤其是早些年金融业务的快速发展，甚至有些是总分行的组织架构，各个团队各自为战，内部的技术实现、开发规范等等都是按照各自的标准定的，那随着业务的日趋庞大，发现不同的实现愈到后面愈难管理，中间还伴随着一些人员的变动，可能有些老的代码在经历几次交接之后，现在都没人敢去动它。这就是规范不统一带来的弊端，因此不少企业内部从开发规范、开发流程、开发工具，包括技术平台等基建方面开始去做统一这个事情，在这个背景下，如果还是按照业务维度去做多活的落地，与统一规范的理念是有点背道而驰的。</p><p></p><p>所以从整个实施路径上，我们更加倾向和建议的是平台化的落地设计思路。在一个企业内部，应当建设一套标准的，统一的分布式平台或者多活容灾平台来支撑不同的业务团队。这样子在后续的演进过程中也能有更加专业的人员去支撑，提供技术的演进和维护，所以有时候对于平台的设计也是一个考验，需要做的比较灵活，从而能满足不同的一些业务场景诉求，例如多活的流量分片规则引擎实现，它不应该是几个固定写死的规则，而是用户可以自由灵活配置，并且动态能够生效的这么一项能力。这里面实现上可以通过一些自定义插件等方式去做，具体细节方面就不展开介绍了。</p><p>&nbsp;</p><p>InfoQ：如何确保设计的多活架构，容灾架构能在面对实际重大生产故障的时候能发挥作用？</p><p>翁扬：如果这个问题是想问说如何确保多活架构能够一定应对业的故障，确保业务是能够一直连续的话。我想说这非常难，甚至基本可以说是做不到。时至今日，我们还能偶尔听到一些云厂商的业务出现服务不可用的新闻，连谷歌和亚马逊都不能幸免于难。</p><p></p><p>容灾的建设它不单单是一个技术问题，我更认为他是一个体系化建设的事情。因为要保障业务的连续性，不出现故障，中间牵涉的原因可能点有很多，而每一次出问题的点，往往是哪些容易被忽略的不经意的地方，它并不是说技术架构上存在设计缺陷，更多的是一些在实施和管理中的疏忽，因为有人的地方，总是避免不了会出错。</p><p></p><p>所以从保障容灾的这个大的目标上来说，首先在技术架构方面，肯定要基于实际的容灾要求和目标去做相应的建设，并且配合一些有效的指标监控和告警手段来及时，提前反馈出一些风险，这也是我们设计容灾监控大盘的目的之一，希望通过直观的数据展示来有效的反馈出系统当前的健康状况。</p><p></p><p>那回过来说，如果这个问题是想问说有没有手段可以帮助来检查当前的架构是否能够真的来应对一些故障场景的话，那答案是有的。最重要的应该属常态化的故障演练，通过结合一些故障注入工具，来模拟真实线上环境可能会出现的一些故障，来达到演练的效果。这种方法，对于检验一些容灾能力的有效性方面，还是有很大的帮助的。有的时候，为了提高对于故障有效性和真实性，也会引入一些工具比如混沌工程，通过一些随机化的故障，让故障变得更加“捉摸不透”，及时是这样子，还是很难有效保障在系统某个环节出现故障时仍然是可以对外正常提供服务的。</p><p></p><p>当然为什么说是体系性的建设，作为多活或者容灾的建设，除了故障发生时的一些应对处理机制，在故障没有发生的时候，提前做好一些应急预案的制定，一旦真的出现问题，也能帮助我们能够快速的恢复业务，从而可以减少一些损失，所以有些地方会按照事前、事中和事后这样一些维度来做这个容灾体系的建设，这也是另外一种建设思路。</p><p></p><p>InfoQ：金融分布式多活架构在落地过程中有没有一些坑，或者大家容易存在的误区？</p><p>翁扬：其实关于技术上的一些所谓的坑，大多数都是由于当时在做这个事情的时候的认知水平不够导致的，只要在问题发生之后，能够彻底弄清楚问题的根本产生原因，解决掉它之后，也就不存在所谓的坑，学习的过程本身可以说就是踩坑积累经验的过程。</p><p></p><p>这里我想可以稍微讲几个新人在学习过程中可能容易存在的一些误区，也许能更好帮助大家理解一些多活的设计。</p><p></p><p>首先第一个点，我们今天讲的主体是多活，我们提到异地多活呢往往一般会结合单元化设计去做落地，并不是说单元化的设计解决了业务的连续性保障问题，而是异地多活的架构下，通过单元化的设计可以更好的把资源利用合理，它解决的是跨区数据访问性能瓶颈和系统水平扩展问题。而这种异地多活的架构恰好又能较好的保障好业务的连续性，支持地域级别的故障切换，但是它引入的其它的问题也是需要我们去解决的，比如数据一致性等，所以这里面的逻辑关系需要厘清。但这里重点想说的，异地多活架构不一定必须做单元化，同城多活也不一定不可以做单元化，这两者没有直接关联关系，这是一种设计最佳实践。单元化设计它不是万能的。所以我们在做架构设计的时候，还是要基于实际的业务场景，选用最符合当前诉求的容灾架构。</p><p></p><p>另外一个点是即使是业务已经发展到了异地多活，并且必须要要上单元化的设计之后，并不是所有业务都需要做单元化改造的，允许存在一些全局、或者局部的“中心化”业务，全局业务比较好理解，所谓的局部中心化“业务”在我们这里也叫区域信息系统，一般来说是针对一些不可拆分或者不需要拆分为多子信息系统，并且访问频率不高的业务，可以根据性能需求在每个地域部署并提供可读能力。而全局信息系统则是针对一些访问频率低，数据仅有一份，数据一致性要求非常高的业务。所以，第二个容易存在的误区是很多人往往会以为一旦业务要上单元化之后，那我所有的业务以及流量都得考虑要做拆分，这个思路是不对的。并且即使是针对同一个业务，在整个后续的灰度上线过程中，也会存在一些新旧业务的兼容形态的，为了确保整个上线过程是平滑的。</p><p></p><p>最后再讲一个吧，针对同一个业务系统，单元化的规则它也不是唯一的或者是一成不变的，比如有的业务可以根据用户的id取模分片进行单元化的划分，但有的就可以根据一些特定的标识，比如地域信息，甚至业务属性等进行单元切片划分，不同规则是允许同时存在一个系统内运行的。另外，单元化的规则也是只是动态的调整，从而可以用于满足一些例如扩容或者缩容这样子的业务需求场景。所以这对于平台的这种灵活性设计要求还是比较高的。</p><p></p><p>InfoQ：分布式架构在金融领域不是新技术，您认为接下来金融领域的架构会往哪个方向演进？</p><p>翁扬：确实分布式架构不是一项新技术，但是这几年在金融行业被经常提起，我认为主要的一个背景是前面提到的传统银行的技术架构从集中式架构往分布式架构转型的过程中，需要依赖于很多分布式技术作为承载，这是去IOE过程中非常重要且不可或缺的一环。</p><p></p><p>但是分布式架构涉及的范围其实又非常广，从最简单的RPC调用，到服务注册发现，再到服务治理和监控等等，都是分布式架构中会面对的一些常见问题。好在目前在技术领域很多东西是开放的，大家可以相互学习和借鉴，甚至都不需要任何操作，就可以直接引用别人提供的一个比较完善的框架，这是技术时代我们享受到的红利。</p><p></p><p>技术的快速发展、更迭，有时候就好比宇宙大爆炸一样，出现各种各样的开发语言、技术框架、技术组件等，导致有时候用户在选择和使用技术的时候，不得不陷入一些思考，我究竟应该用哪个技术选型，如果用这个会不会有什么问题，试用起来难度会不会很大，后续在业务的长期演进中会不会有问题之类的烦恼。</p><p></p><p>所以我们通过一种平台化的设计理念，通过分布式技术平台，设计了一些通用能力，提供一些更加云原生和标准化的开发最佳实践，来帮助用户更好的去业务开发，从而提高整个生产效率。</p><p></p><p>而金融领域的架构，我我们看到的，或者可以预见的是，也是朝着一个云原生和标准化的方向去做演进。前面其实有提到，有不少银行客户，在一些内部的业务系统上已经改造成容器化的方式运行，通过K8S有效的提升了管理和运维效率。也有一些客户，已经在一些关键的业务上落地了服务网格等云原生的微服务架构形态，也正在探索多运行时等一些新的设计理念，金融架构的发展，本质上是做金融架构技术的这部分技术工程师们主导的，那云原生基本上是业界和社区发展所认可的，这是逐渐“标准化”的过程。</p><p></p><p>而另外一个标准化，我想说的是金融架构无论从内到往外都随着业务发展演进朝着一个更加统一好管理的方式演进，所谓由内，就好比一些金融企业，内部开始由一些架构团队制定一个统一的开发规范，来约定大家的开发模式和开发行为，本质上为了更低成本的去做提高生产力的事情，这和我们的动机出发点是一样的，只不过我们通过的是平台和工具，他们通过的是流程规范。而外部，从整个金融行业的行业标准、监管规范等方面，都提出了一些架构设计标准，包括对于信创国产化，技术自主可控等方面的要求，也促使金融架构越来越趋于标准化。</p><p></p><p>所以，云原生和标准化，两者是有一定交集的。云原生的部分设计理念是通过一些标准的技术抽象来统一不同的技术实现，但这个标准化不是说给用户限定了一种选型，反而是让用户以更加标准、开放的方式来解决软件开发的生产力问题，所以这也是我认为金融领域架构会发展的方向，当然金融架构在稳定性、安全性、合规性方面有着更高的要求，这个是始终不会变的。</p><p></p><p>活动推荐：</p><p>翁扬讲师即将在<a href=\"https://archsummit.infoq.cn/202303/beijing/\">ArchSummit全球架构师峰会</a>\"北京站，在本次峰会，我们们策划了【数字化转型下的业务架构】【国产软件优化迭代之路】【可观测技术落地】以及【云原生大数据专题】，详细内容可通过扫描下方二维码进行了解。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/2c/64/2c4c702fd9d50b0955869edf3f2c1064.jpg\" /></p><p></p>",
    "publish_time": "2023-02-10 20:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]