[
  {
    "title": "Spring Batch 5.0发布，使用JDK 17作为基线版本并支持原生Java",
    "url": "https://www.infoq.cn/article/5GyCp1rm0IyPIfRoDyjQ",
    "summary": "<p>VMware<a href=\"https://spring.io/blog/2022/11/24/spring-batch-5-0-goes-ga\">发布Spring Batch 5.0</a>\"。基于Java 17和最新的Spring Framework 6.0，Spring Batch现在支持GraalVM原生镜像、新的Observation API、Java Record以及由50多位贡献者实现的一系列功能增强和缺陷修复。</p><p></p><p>Spring Batch 5依赖Spring Framework 6、Spring Integration 6、Spring Data 3、Spring AMQP 3和Micrometer 1.10。此外，对Jakarta EE API的所有导入语句需要从javax.*迁移至jakarta.*命名空间，这是因为该版本已经迁移至Jakarta EE 9。Spring Batch现在使用Hibernate 6来读取游标和分页条目。</p><p></p><p>Spring Batch 5引入了一个新的类，<a href=\"https://docs.spring.io/spring-batch/docs/current/api/org/springframework/batch/core/configuration/support/DefaultBatchConfiguration.html\">DefaultBatchConfiguration</a>\"，作为<a href=\"https://docs.spring.io/spring-batch/docs/current/api/org/springframework/batch/core/configuration/annotation/EnableBatchProcessing.html\">@EnableBatchProcessing</a>\"注解的替代者。它会为所有基础设施提供默认配置，用户可以据此进行自定义。用户可以声明事务管理器并使用<a href=\"https://docs.spring.io/spring-batch/docs/current/api/org/springframework/batch/core/explore/JobExplorer.html\">JobExplorer</a>\"接口自定义其事务属性。最新版本还提供了增强功能，以更好地利用框架中的Record API，对Record API的支持是在Spring Batch 4中首次引入的。Spring Batch还扩展了对SAP HANA的支持和对MariaDB的完整支持。</p><p></p><p>@EnableBatchProcessing注解<a href=\"https://github.com/spring-projects/spring-batch/issues/816\">不会在</a>\"应用上下文中暴露事务管理器。这对用户定义的事务管理器来说是个好消息，因为能够避免以前版本无法控制的行为。用户必须在每个tasklet step定义中手动配置事务管理器，以避免XML和Java配置风格的<a href=\"https://github.com/spring-projects/spring-batch/issues/4130\">不一致性</a>\"。@EnableBatchProcessing注解还配置了一个基于JDBC的<a href=\"https://docs.spring.io/spring-batch/docs/current/api/org/springframework/batch/core/repository/JobRepository.html\">JobRepository</a>\"接口。VMware建议使用嵌入式数据库来与内存中的job仓库协作。</p><p></p><p><a href=\"https://github.com/micrometer-metrics/micrometer/blob/main/README.md\">Micrometer</a>\"升级到了1.10版本，允许用户获得Batch追踪和Batch度量指标。Spring Batch现在还为每个job和step创建一个跨度（span）。这些数据可以在<a href=\"https://zipkin.io/\">Zipkin</a>\"等分布式追踪工具中查看。</p><p></p><p>另一个值得关注的变化是使用<a href=\"https://docs.spring.io/spring-batch/docs/current/api/org/springframework/batch/core/JobParameter.htmltch/core/repository/JobRepository.html\">JobParameter</a>\"类来处理job参数。这样，用户不用像Spring Batch 4那样局限于long、double、string或date类型。这一变化对参数在数据库中的持久化会有<a href=\"https://github.com/spring-projects/spring-batch/wiki/Spring-Batch-5.0-Migration-Guide#column-change-in-batch_job_execution_params\">影响</a>\"。</p><p></p><p>Spring Batch 5还删除了对SQLFire、<a href=\"https://jcp.org/en/jsr/detail?id=352\">JSR-352</a>\"（Java平台的批处理应用）和GemFire的支持。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/12/spring-batch-5-released/\">Spring Batch 5.0 Delivers JDK 17 Baseline and Support for Native Java</a>\"</p>",
    "publish_time": "2023-01-11 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从游戏上云出发，底层技术迭代的复利正在被看见",
    "url": "https://www.infoq.cn/article/eZ2uQ7926ET3pAGsBb1M",
    "summary": "<p>近日，市场调研机构 Newzoo 发布了《<a href=\"https://newzoo.com/cn/trend-reports/newzoo-global-games-market-report-2022-free-version-cn\">2022 年全球游戏市场报告</a>\"》，报告内容显示，2022 年全球游戏玩家达到 32 亿，预计为游戏市场创造 1968 亿美元收入，同比增长 2.1%。其中，移动游戏是增长的主力。2022 年来自移动市场的收入预计达到 1035 亿美元，占全球游戏市场的 53%，同比增长 5.1%。</p><p></p><p>无论是手游还是端游，高交互、高画质的多人在线大型游戏越来越多。游戏厂商们渴望玩家活跃度和在线人数攀升，就要做好承接数据峰值的准备。2022 年 7 月，中科院研究团队首次定义了“<a href=\"https://www.jiemian.com/article/7792926.html\">游戏技术</a>\"”，并量化测算了游戏技术和芯片、5G、VR/AR 产业的关系，指出游戏技术在 2020 年对芯片产业的技术进步贡献率约为 14.9%。游戏行业底层技术或者说“游戏科技”在其他行业的应用，近年来也得到了广泛认同。</p><p></p><p>随着云计算技术、边缘计算、流媒体传输技术、GPU 虚拟技术、网络传输技术等关键技术的发展，以云计算为基础的云游戏也在不断发展，无论是游戏厂商还是上下游的云服务商、硬件厂商都需要做好扎实的技术储备。</p><p></p><h1>深受玩家喜爱的完美世界《幻塔》如何实现流畅的游戏体验？</h1><p></p><p></p><p>完美世界的轻科幻开放世界手游《幻塔》，以精美的画风、独特的设定、丰富多样的开放世界玩法，成为完美世界创新品类多元融合的自研代表作之一。</p><p></p><p>作为一款大型多人在线角色扮演类游戏，《幻塔》游戏的交互性很强，需要对客户端中玩家的操作、行为等进行及时地反馈并推送给共同游戏或对战的其他玩家，对网络质量更加敏感。同时，游戏需要保持会话状态，当玩家进行操作时，下次通信的数据会依赖之前的通信数据，对网络吞吐性能要求较高。另外，由于游戏需要高密度记录玩家的操作及结果，数据需要频繁写入，较强的 I/O 性能必不可少。为了保证游戏玩家的交互效果，对底层服务器的计算能力也有较高的要求。</p><p></p><p>为了向玩家提供低时延、流畅的游戏体验，使单服能够承载数千玩家，完美世界《幻塔》将每个游戏服部署在一台 1T 内存的超大规格云服务器上，而这对云服务器的性能提出了极高的要求：单个服务器需要提供足够的配置和性能承载数千名玩家，支持每个玩家的高资源需求；在使用大内存实例的情况下，需要提供超强稳定性以保障业务无间断、无损运行；峰值期间需要多个可用区提供数万核资源，新版本上线等节点会有周期性的高并发，游戏高峰期、低峰期、稳定期切换对算力的性能、稳定性、多地域分布，都有着较高要求；除了高性能、低时延之外，业务的可用性和稳定性也十分重要，尤其是面对黑客的 DDos 攻击 (分布式拒绝服务攻击) 时，需要保持游戏服务时刻不断线，最大程度保障玩家的服务。</p><p></p><p>为了满足上述核心需求并达到理想的效果，为用户带去稳定、流畅的游戏体验，阿里云基于英特尔硬件、软件及存储技术，为完美世界《幻塔》提供了针对性解决方案和全流程技术服务。</p><p></p><p>针对游戏服对处理器的高性能需求，阿里云为《幻塔》提供了搭载 2021 年发布的面向单路和双路的第三代英特尔® 至强® 可扩展处理器的第七代云服务器 ECS，其采用阿里云第三代神龙架构，计算、网络及存储能力大幅提升，同时叠加英特尔® SGX 可信计算与加密计算能力，可为云上业务提供可靠的安全可信环境，同时超高可用性架构、软硬协同的热升级和热迁移通道，也可让业务对底层硬件故障无感。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7e/7e2fb26eabea34c76f967c1f37932736.png\" /></p><p>（来源：“以至强为底，阿里云助力完美世界打造流畅云上游戏体验”白皮书）</p><p></p><p>英特尔® 至强® 可扩展处理器能够提供更低的时延、更高的吞吐量以及更可靠的性能。其针对 AI、安全等应用场景提供了特定的加速能力，为人工智能、大数据分析、云计算、科学计算等关键负载提供了高效、可靠和灵活的支持。</p><p></p><p>完美世界《幻塔》可以通过阿里云云上游戏解决方案，调用英特尔开源的英特尔® 智能存储加速库（Intel® Intelligent Storage Acceleration Library，英特尔® ISA-L）。最新的英特尔® ISA-L 使用英特尔® AVX-512 指令集来加速数据的压缩 / 解压，利用英特尔® AVX-512 加速完美世界日志文件的压缩和解压缩性能，解决了日志压缩和解压缩场景的性能瓶颈问题，<a href=\"https://www.intel.cn/content/www/cn/zh/customer-spotlight/cases/ali-cloud-perfect-world-smooth-gaming-experience.html?wapkw=%E5%AE%8C%E7%BE%8E%E4%B8%96%E7%95%8C\">优化后压缩性能达到优化前 9 倍，解压性能达到 2 倍</a>\"。</p><p></p><p>在生产环境中，由于 log rotation 的存在，日志文件大小是可以预测的，可以直接使用 GKL 对 GZIP 优化，或使用 igzip-java 基于流的接口来优化。英特尔® ISA-L 提供了压缩 / 解压功能，支持 RFC1951 标准，并且针对英特尔® 架构做了优化，在略微损失压缩率的情况下相对 zlib 具有非常好的性能，这非常适合像游戏这样的高吞吐量存储应用。通过使用英特尔® ISA-L 对日志压缩进行优化，借助其较好的性能和压缩率， GZIP 算法得到了有效优化，且高效完成了对日志文件的压缩。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/69/691a5689e90b154f16db6582b900b9b0.png\" /></p><p>（英特尔® ISA-L 架构图示，来源：“以至强为底，阿里云助力完美世界打造流畅云上游戏体验”白皮书）</p><p></p><h1>不止于《幻塔》，看的见的英特尔软硬件技术复利</h1><p></p><p></p><p>游戏需要的音视频技术底层能力是看得见的技术复利。游戏场景之外，视频点播、AR/VR、智能语音、影视制作等场景，英特尔通过一系列软硬件产品与技术方案，提供和优化算力、存储、网络以及软件能力，满足多元应用的独特需求。在硬件基础设施上，英特尔通过英特尔® 至强® 可扩展处理器、英特尔® FPGA 产品、英特尔® 傲腾™ 持久内存，以及英特尔® 以太网网络适配器、英特尔® 视觉云媒体分析加速卡等产品，为各类基于音视频能力的创新方案提供强劲的计算、存储和网络处理能力；在软件优化加速上，英特尔® oneAPI、英特尔® Media SDK、 SVT 等，在不同应用场景中以完整的软件栈来加速音视频能力的工作效能。</p><p></p><p>如今，英特尔至强处理器迎来了最新一代的第四代英特尔® 至强® 可扩展处理器，其内置一系列加速器，包括新的指令集架构和集成 IP，能够高效应对人工智能、数据分析、网络、存储和其他高需求的工作负载，可以在不断变化且要求日益增高的数据中心使用中提供可观的计算性能，并对工作负载进行优化。值得一提的是，第四代英特尔® 至强® 可扩展处理器内置了全新 AI 加速器——英特尔® 高级矩阵扩展（英特尔® AMX），能够帮助用户通过扩展通用至强® 服务器平台，覆盖包括训练和微调在内的更多深度学习使用场景。该 AI 引擎已经过优化，基于行业标准框架，可提供相较于上一代深度学习训练模型多倍的性能。</p><p></p><p>底层算力技术每一次进步带来的技术复利，正在被看见。从基础音视频应用 ，到发展迅猛的游戏场景，英特尔底层技术和软硬件产品，将有更多元、更创新的应用可能。英特尔希望持续与阿里云、完美世界等众多合作伙伴一起，以灵活可扩展的生态和各类成熟的解决方案，满足更多互联网应用对音视频能力的需求，共同推动互联网迈向动态、丰富、多维和可交互的新纪元。</p><p></p><p>了解更多公有云和互联网软硬件创新技术实践，点击【<a href=\"https://www.intel.cn/content/www/cn/zh/cloud-computing/china-best-practice-public-cloud-internet-industry.html?cid=soc&amp;source=Wechat&amp;article_id=4303\">此处</a>\"】获取白皮书。</p>",
    "publish_time": "2023-01-11 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "KaiwuDB 1.0 - 时序数据库系列产品正式发布",
    "url": "https://www.infoq.cn/article/4cc9eb935f70f4185c3851161",
    "summary": "<p></p><p><img src=\"https://static001.geekbang.org/infoq/94/941d267c2e771fc80221794c74448058.jpeg\" /></p><p></p><p></p><h2>发布会精彩回顾</h2><p></p><p></p><p>1月10日，KaiwuDB 1.0 系列产品发布会圆满落幕。全程线上直播，收获各大行业伙伴热切关注。</p><p></p><p>本次发布会 KaiwuDB 正式推出 1.0 时序数据库版本以及面向工业领域的一站式高速数据集成构建的工业实时分析解决方案 - KaiwuDB 数据服务平台 1.0。</p><p></p><p>KaiwuDB 1.0-时序数据库运用实时就地运算等核心专利技术；拥有海量时序数据高吞吐写入、高性能大批量复杂查询、集群部署等核心优势，专为工业物联网、数字能源、交通车联网、智慧产业等场景设计，真正实现了“好用易用”，为用户业务开展保驾护航。</p><p></p><p></p><h2>划重点！</h2><p></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6a/6a68a0e67512a3e9f1452d9546b25abf.jpeg\" /></p><p></p>",
    "publish_time": "2023-01-11 09:21:06",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "达摩院2023十大科技趋势发布，生成式AI将进入应用爆发期",
    "url": "https://www.infoq.cn/article/5e5157061b47f13bd33f33050",
    "summary": "<p>1月11日，达摩院2023十大科技趋势发布，生成式AI、Chiplet模块化设计封装、全新云计算体系架构等技术入选。达摩院认为，全球科技日趋显现出交叉融合发展的新态势，尤其在信息与通信技术（ICT）领域酝酿的新裂变，将为科技产业革新注入动力。</p><p></p><p>颠覆性的科技突破也许百年才得一遇，持续性的迭代创新则以日进一寸的累积改变着日常生活。进入2023年，达摩院预测，基于技术迭代与产业应用的融合创新，将驱动AI、云计算、芯片等领域实现阶段跃迁。</p><p></p><p>AI正在加速奔向通用人工智能。多模态预训练大模型将实现图像、文本、音频等的统一知识表示，成为人工智能基础设施；生成式AI将迎来应用大爆发，极大推动数字化内容的生产与创造。人工智能诞生数十年，人类对“通用AI”的想象从未如此具体。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0f/0fbb9c23fc449c631749242c80a13ea7.png\" /></p><p>（图说：多模态预训练大模型将实现图文音统一知识表示）</p><p></p><p>云计算始终是数字时代的技术创新中心：基于云定义的可预期网络技术，将从数据中心的局域应用走向全网推广；因云而生的云原生安全技术，则将推动平台化、智能化的新型安全体系的成形；云也在重新定义计算体系架构，从以CPU为中心的传统架构，向以囊括计算、存储、网络的CIPU为中心的体系演进。未来，由云定义的软硬一体化，将实现系统级的深度融合。</p><p></p><p>芯片领域在算力需求暴涨、摩尔定律放缓的夹击下寻求突围，达摩院预测，存算一体和Chiplet模块化设计封装将有长足进展：基于SRAM、NOR Flash等成熟存储器的存内计算有望在智能家居、可穿戴设备等场景规模化商用；Chiplet互联标准的逐渐统一将重构芯片研发流程。&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/55/5530655f44fe041aeb4227ee5e55ee10.jpeg\" /></p><p>（图说：Chiplet模块化设计封装有望重塑芯片产业格局）</p><p></p><p>基础技术的迭代演进必将催生新场景和新产业，今年最被达摩院看好的趋势有计算光学成像、数字孪生城市、双引擎智能决策等。</p><p></p><p>计算光学成像技术有望突破传统光学的物理极限，帮助人类发现“见所未见”的事物；智慧城市完成了精准映射、生成渲染、仿真推演等关键技术的全面突破，将从单一场景演进至大规模城市数字孪生，辅助人类更“全知”地认识和管理城市；智能决策系统实现了运筹优化和机器学习的联合驱动，将为人类在电网调度、港口吞吐管理、机场停机安排等实时变化的复杂难题上，提供更有价值的优化答案。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4a/4a6347d3dd1044e2f35886aa0a591f2a.png\" /></p><p>（图说：大规模城市数字孪生向立体化、无人化、全局化方向演进）</p><p></p><p>据悉，达摩院2023十大科技趋势采用“巴斯德象限”研究思路，基于论文和专利的大数据“定量发散”，并对产、学、研、用领域上百位专家深度访谈进行“定性收敛”，再从学术创新、技术突破、产业落地、市场需求等维度综合评估，力求“致广大而尽精微”，最后遴选出十大趋势。</p><p></p><p>中国工程院院士邬贺铨指出，技术前瞻性预测分析工作难度大，准确的技术预见既需要有工程实践经验的积累和感性认识，也需要有科学理论基础的支撑与理性思维。达摩院作为一所致力于基础科研和颠覆式技术创新研究的新型研发机构，其科技趋势报告为科技界和产业界贡献了有价值、有深度的预见。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bf/bf80d2698fdb2f484bb2d95e2ce66284.png\" /></p><p></p><p>➠ 获取<a href=\"https://files.alicdn.com/tpsservice/520892c6b94b5a52744ecc54c8650f73.pdf\">达摩院2023十大科技趋势</a>\"报告全文</p>",
    "publish_time": "2023-01-11 11:00:32",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "2023年最值得关注的十大科技趋势，这些技术将迎来爆发，把握住风口和掘金机会！",
    "url": "https://www.infoq.cn/article/3T9d2oMBgbBGRLVXsN8G",
    "summary": "<p></p><p>1 月 11 日，InfoQ获悉，<a href=\"https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247553145&amp;idx=1&amp;sn=b15ec56d90ae3884ddb8896caff322e0&amp;chksm=fbeaa9b6cc9d20a02898f58000c61e65afe19fd0a96e144796ccb139a9622396dea119b4cfb5&amp;scene=27#wechat_redirect\">达摩院</a>\" 2023 十大科技趋势发布，生成式 AI、Chiplet 模块化设计封装、全新云计算体系架构等技术入选。</p><p></p><h2>达摩院发布十大科技趋势</h2><p></p><p></p><p>达摩院认为，全球科技日趋显现出交叉融合发展的新态势，尤其在信息与通信技术（ICT）领域酝酿的新裂变，将为科技产业革新注入动力。</p><p></p><p>颠覆性的科技突破也许百年才得一遇，持续性的迭代创新则以日进一寸的累积改变着日常生活。进入 2023 年，达摩院预测，基于技术迭代与产业应用的融合创新，将驱动 AI、云计算、芯片等领域实现阶段跃迁。AI 正在加速奔向通用人工智能。多模态预训练大模型将实现图像、文本、音频等的统一知识表示，成为人工智能基础设施；<a href=\"https://www.infoq.cn/article/rggHjzaBfCVPV5hxTF7H\">生成式 AI </a>\"将迎来应用大爆发，极大推动数字化内容的生产与创造。人工智能诞生数十年，人类对“通用 AI”的想象从未如此具体。&nbsp;&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/95/95bd4eabf6a58518e89e671f3f8f2238.png\" /></p><p></p><p>多模态预训练大模型将实现图文音统一知识表示</p><p></p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247566934&amp;idx=1&amp;sn=ad3ac0f9104a8c19ccd036dd970734b5&amp;chksm=fbeb7f99cc9cf68f803d81eee2de0ee3badbe1fc4a7c555174d440e78ec2168b56bbd524728e&amp;scene=27#wechat_redirect\">云计算</a>\"始终是数字时代的技术创新中心：基于云定义的可预期网络技术，将从数据中心的局域应用走向全网推广；因云而生的云原生安全技术，则将推动平台化、智能化的新型安全体系的成形；云也在重新定义计算体系架构，从以CPU为中心的传统架构，向以云基础设施处理器 （CIPU）为中心的全新体系架构演进。</p><p></p><p>芯片领域在算力需求暴涨、摩尔定律放缓的夹击下寻求突围，达摩院预测，存算一体和 Chiplet 模块化设计封装将有长足进展：基于 SRAM、NORFlash 等成熟存储器的存内计算有望在智能家居、可穿戴设备等场景规模化商用；Chiplet 互联标准的逐渐统一将重构芯片研发流程。&nbsp;&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e0/e0a49ccb0e354cce6c69f8bdc1bdb1d3.jpeg\" /></p><p></p><p>Chiplet 模块化设计封装有望重塑芯片产业格局</p><p></p><p>基础技术的迭代演进必将催生新场景和新产业，今年最被达摩院看好的趋势有计算光学成像、数字孪生城市、双引擎智能决策等。</p><p></p><p>计算光学成像技术有望突破传统光学的物理极限，帮助人类发现“见所未见”的事物；智慧城市完成了精准映射、生成渲染、仿真推演等关键技术的全面突破，将从单一场景演进至大规模城市数字孪生，辅助人类更“全知”地认识和管理城市；智能决策系统实现了运筹优化和机器学习的联合驱动，将为人类在电网调度、港口吞吐管理、机场停机安排等实时变化的复杂难题上，提供更有价值的优化答案。&nbsp;&nbsp;</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0e/0ece256944881b40c3746e271fddb172.jpeg\" /></p><p></p><p>大规模城市数字孪生向立体化、无人化、全局化方向演进</p><p></p><p>据悉，达摩院 2023 十大科技趋势采用“巴斯德象限”研究思路，基于论文和专利的大数据“定量发散”，并对产、学、研、用领域近百位专家深度访谈进行“定性收敛”，再从学术创新、技术突破、产业落地、市场需求等维度综合评估，力求“致广大而尽精微”，最后遴选出十大趋势。</p><p></p><p>中国工程院院士邬贺铨指出，技术前瞻性预测分析工作难度大，准确的技术预见既需要有工程实践经验的积累和感性认识，也需要有科学理论基础的支撑与理性思维。</p><p></p><p>达摩院作为一所致力于基础科研和颠覆式技术创新研究的新型研发机构，其科技趋势报告为科技界和产业界贡献了有价值、有深度的预见。</p><p></p><p></p><h2>详解生成式AI</h2><p></p><p>&nbsp;</p><p>今年的AI领域，可能没什么比AIGC更热了。有预测数据显示，到2030年，AIGC的市场规模或将超过万亿人民币。</p><p></p><p>2022年，尤其是下半年，AIGC概念突然升温。有这么几个标志性的事件把AIGC推到了风口浪尖之上，其一是文生图模型Stable Diffusion的开源，其二是ChatGPT的爆火出圈。ChatGPT 展示出的强大的能力和无限可能，让人们看到，通过 ChatGPT 这样的技术方案解决很多任务的潜力。</p><p></p><p>不久前，达摩院基础视觉负责人赵德丽在接受InfoQ采访时表示，从信息检索的角度看，ChatGPT取得了很大突破。以前谷歌等搜索引擎做搜索和检索，只是找已经存在的信息，ChatGPT的应用，实现了从信息的搜索到信息的创造这样一个范式的转变，从算法能力上看，它取得了一个质的飞跃。短期来看，ChatGPT 有望成为或者辅助像谷歌这种传统信息检索的强有力的工具；长期来看，它有望发展成为AI系统级的服务。</p><p></p><p>赵德丽对ChatGPT抱有很大的期待。虽然还有各种瑕疵，但ChatGPT短时间内出现了各式各样的不同方向上解决问题的能力，展现了AI算法的巨大潜力。从技术发展和解决方案的角度看，它将来可能会成长为一个超级APP，就像是一个无所不知的虚拟体。“ChatGPT 这种应用的出现，从长远来看的影响力，其实不亚于阿尔法狗曾经在人工智能界带来的影响力，它将会是一个影响非常深远的技术和应用”。</p><p></p><p>GAN，是生成式 AI 的核心技术之一。2014年以来，以生成式对抗网络(Generative Adversarial Network,GAN)为代表的深度学习算法的提出和迭代更新，让AIGC进入了快速发展阶段，带动了AIGC的一波热潮。今年这波AIGC的热潮，被认为是由生成扩散模型带动起来的。例如，OpenAI 发布了文本生成图像模型 DALL·E 2；谷歌推出了Imagen；今年 8 月，初创公司 Stability.AI 发布了 Stable Diffusion...</p><p></p><p>赵德丽表示，在 Stable Diffusion这种扩散算法出现之前，从生成的效果上看，在计算机领域，GAN是效果最好的。发展到现阶段，GAN 生成的人脸图像已经到了真假难辨的程度。以StyleGAN为例，其生成的图片可以做到栩栩如生，光线和纹理都清晰可见，非专业人士几乎无法分辨出是由AI生成的虚假图。即便是现在的Diffusion model目前也做不到现在GAN在人脸生成上的结果。</p><p></p><p>但GAN有一个最大的缺点，它对于多类别、语义非常复杂的、一般场景下的图片生成的建模能力较弱。如果只是人脸，只是猫或者只是狗这类场景的数据，GAN的效果很好。但它在某种复杂数据的规模能力方面，在性能上受限较大，如果把狗、猫、花朵、桌子、椅子、电话等不同种类的数据放在一起，目前的情况下，GAN得不到一个较好的结果。</p><p></p><p>而Diffusion model在这方面取得了突破性的进展。Diffusion model解决了GAN不能解决的问题，因此大家立刻意识到了它的巨大潜力。今年是Diffusion model取得快速发展的第一年。而且，它的发展速度超过当年的GAN，当年的GAN已经足够火热了，但可以感受到，Diffusion model现在的受关注程度超过当年的GAN 。</p><p></p><p>赵德丽认为，现阶段，AIGC的生成效果已经非常惊艳了，它已经达到了广泛应用的基础性能，虽然在使用上还有较大门槛，但通过大模型的开源开放等，有助于将门槛降下来。</p><p></p><p>“AIGC技术走到了一个转折点，到了一个新阶段的起点”。赵德丽认为，此前，虽然AIGC技术在不断发展，但生成效果并没有得到广泛认可，还没达到大规模商业化的条件。但现在，不一样了。</p><p></p><p>今年，AIGC生成的效果，包括基于AIGC技术推出来的应用，大家看到，这项目技术已经具备了大规模应用和商业化的潜力和性能，具备了从只能在窄领域到更普遍场景下应用的可能性。AIGC技术到了大规模商业化应用的转折点。今年是一个起点，但还远远没有到成熟的程度。</p><p></p><p>AIGC具体在哪些领域能用好，发挥出商业化的价值，还需要不断打磨产品和技术。例如对于文本生成图，现在对problem的提示语要求很高，现在算法还做不到随便给个描述，就能生成栩栩如生的图片。什么样的problem合适，如何设计出合适的problem等，都有一定门槛。</p><p></p><p>&nbsp;此外，像ChatGPT虽然展示了强大的能力，但在很多场景下还是有瑕疵，出现问题和答案不匹配的情况还非常多。如果对其进行商业化应用，需要再针对具体的场景，不断打磨和优化。尽管它达到了大规模应用的基础，但并不是非常成熟，还达不到让大家自由应用的程度。</p><p></p><p>另一个值得注意的问题是，AIGC并不意味着取代人。赵德丽表示，AIGC本身是基于生成模型产生的能力，生成模型训练需要数据，这些数据都是人类活动产生，生成的提示词需要人来输入，人需要做场景的设计、提示词的设计、元素的设计等等。只不过在一些具体的场景上，对于一些固定的设计模式，比如设计成具体的图形如红包界面、商品素材等，可以实现完全的AIGC的方式。但整体而言，人还是AIGC中重要的因素。</p><p></p><p>延伸阅读：<a href=\"https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247584953&amp;idx=1&amp;sn=d5b412da9de55e8c59205850e5028cf6&amp;chksm=fbeb3576cc9cbc60327ec81c0c0eb1e64c895bd454513a4b2950fbf40cd8d1312d384ab8dd6c&amp;token=1429146590&amp;lang=zh_CN&amp;scene=21#wechat_redirect\">《火爆全球，下一个万亿级AI风口即将爆发》</a>\"</p><p></p><p></p><h3>附：达摩院 2023 十大科技趋势概览</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ab/ab3ae5f841430fabc1d804393933d7ca.png\" /></p><p></p><p>多模态预训练大模型：基于多模态的预训练大模型将实现图文音统一知识表示，成为人工智能基础设施。Chiplet 模块化设计封装：Chiplet 的互联标准将逐渐统一，重构芯片研发流程。存算一体：资本和产业双轮驱动，存算一体芯片将在垂直细分领域迎来规模化商用。云原生安全：安全技术与云紧密结合，打造平台化、智能化的新型安全体系。软硬融合云计算体系架构：云计算向以 CIPU 为中心的全新云计算体系架构深度演进，通过软件定义、硬件加速，在保持云上应用开发的高弹性和敏捷性的同时，带来云上应用的全面加速。端网融合的可预期网络：基于云定义的可预期网络技术，即将从数据中心的局域应用走向全网推广。双引擎智能决策：融合运筹优化和机器学习的双引擎智能决策，将推进全局动态资源配置优化。计算光学成像：计算光学成像突破传统光学成像极限，将带来更具创造力和想象力的应用。大规模城市数字孪生：城市数字孪生在大规模趋势基础上，继续向立体化、无人化、全局化方向演进。生成式 AI：生成式 AI 进入应用爆发期，将极大推动数字化内容生产与创造。</p><p></p>",
    "publish_time": "2023-01-11 11:23:45",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Clearview AI“偷”了我的脸，欧盟却对此无能为力",
    "url": "https://www.infoq.cn/article/f7EDMtpjfUukLE0cTNdR",
    "summary": "<p></p><blockquote>Matthias Marx说他的脸被偷了。这位德国维权人士的脸苍白而宽阔，顶着是一头凌乱的金发。到目前为止，已经有三家公司在未经他允许的情况下绘制了这些特征并将其货币化。就像发生在其他数十亿人们身上的一样，他的脸在未经他同意的情况下被变成了搜索词。</blockquote><p></p><p>&nbsp;</p><p>2020年，Marx读到了<a href=\"https://www.infoq.cn/article/JctRKUQrBjOraRxMkIwD\">Clearview AI</a>\"相关的报道，这家公司称，它已经从互联网上收集了数十亿张照片，创建了一个庞大的人脸数据库。通过上传单张照片，Clearview的客户（包括执法机构）可以使用该公司的人脸识别技术来挖掘其他具有相同面部特征的在线照片。</p><p>&nbsp;</p><p>Marx想知道该公司的数据库中是否有他的人脸照片，于是他向Clearview发电子邮件询问。一个月后，他收到了一封附有两张截图的回复。这两张照片都是十年前拍的，但照片上的Marx都穿着蓝色T恤，面容清爽，正在参加谷歌的工程师竞赛。Marx知道这些图片是存在的。但与Clearview不同的是，他并不知道有摄影师在未经他许可的情况下将这些照片在照片图库网站Alamy上出售了。</p><p></p><p>Marx说，Clearview的披露是一个警钟。“我不能控制人们对我的数据做了什么，”他说。对他来说，Clearview在他不知情或未经许可的情况下使用了他的面部或生物特征数据，显然违反了欧洲的隐私法GDPR。因此，他在2020年2月向汉堡（Hamburg）当地的隐私监管机构提交了投诉。该投诉是欧洲首次针对Clearview提起的<a href=\"https://www.infoq.cn/article/422lAN7NjQVkRYuZ8vcs\">投诉</a>\"，但目前尚不清楚该案件是否已经解决。</p><p></p><p>监管机构的一位发言人告诉WIRED，案件已经完结，但Marx表示，他还没有收到结果通知。“自从我投诉Clearview AI以来，已经快两年半了，但该案件依然悬而未决，”在IT安全公司Security Research Labs担任安全研究员的Marx说，“这太慢了，即使考虑到这是首例此类案例。”</p><p>&nbsp;</p><p>在整个欧洲，数百万人的脸出现在由Clearview等公司运营的搜索引擎中。该地区可能拥有世界上最严格的隐私法，但包括汉堡在内的欧洲监管机构正在努力执行这些法律。自从Marx提出申诉以来，欧洲各地的其他人和隐私团体也采取了同样的行动。</p><p></p><p>2022年10月，法国数据保护机构成为第三个由于Clearview违反欧洲隐私规则而对其处以2000万欧元（1900万美元）罚款的欧盟监管机构。然而，Clearview并没有将欧盟面孔从其平台中删除，意大利和希腊监管机构开出的类似罚单仍未支付。（法国方面表示，由于隐私规定，它无法透露有关付款的详细信息）。但随着欧洲监管机构努力让该公司听从对他们的谴责，该类问题正在如雨后春笋般出现。Clearview不再是唯一一家通过人脸获利的公司了。</p><p>&nbsp;</p><p>和其他隐私维权人士一样，Marx不相信Clearview会在技术上永久地删除一张人脸。他相信，Clearview的技术会不断地在互联网上搜索人脸，会重新找到它并将其分类。Clearview没有回复关于它是否能够从其数据库中永久删除人脸的评论请求。</p><p>&nbsp;</p><p>“如果我的脸出现在互联网上的某个地方，这种事还会发生。”Marx说。“它们（Clearview的算法）不会停止爬取。”该公司一直在告诉投资者，2022年其数据库中的照片数量有望达到1000亿张，地球上70亿人口中，平均每人就有14张左右。</p><p>&nbsp;</p><p>Clearview首席执行官Hoan Ton-That表示，Clearview的工作方式是发送机器人在互联网上搜索人脸，然后将其存储在数据库中，这使得其无法阻止欧盟的人脸出现在平台上。他将自己的产品与市场上的其他产品进行比较时表示：“单纯根据互联网上的公开照片无法确定一个人是否居住在欧盟，因此无法删除欧盟居民的数据。”。“Clearview AI只从互联网上收集公开可用的信息，就像谷歌、必应或DuckDuckGo等其他任何搜索引擎一样。”</p><p>&nbsp;</p><p>但隐私维权人士认为，用名字搜索和用人脸搜索之间的区别是至关重要的。“名字不是唯一的标识符。名字是你可以在公共场合隐藏的东西。”Privacy International的律师Lucie Audibert表示。“除非你头上套着袋子出门，否则你不可能在公共场合隐藏你的脸。”</p><p>&nbsp;</p><p>在欧洲，<a href=\"https://www.infoq.cn/article/l7FpGfdsolTlC5u3Er1Z\">人脸搜索引擎</a>\"可以公然无视监管机构要求其停止处理欧盟人脸的命令，继续运行，这让人们感到越来越沮丧。Ton-That认为Clearview不受GDPR的约束，因为它在欧盟没有客户或办公室——这是监管机构所争议的。Audibert表示：“如果一家美国公司不愿意合作，就很难执行欧洲对该公司的监管决定。”他希望欧盟监管机构在执法方面更加积极。“这真的是一个测试案例，看看GDPR有什么样的限制性权力。”她不认为全面的欧盟新科技规则会影响这场争端。</p><p>&nbsp;</p><p>针对Clearview的案件本应作为对其他公司的警告，这些公司的搜索引擎在欧盟也是非法的。“一旦有了一个案例，当局很容易将其作为先例。”NOYB的数据保护律师Felix Mikolasch表示，该隐私组织一直在支持Marx的案件，然而，情况却恰恰相反。Audibert说：“由于缺乏执法力度，很难说服公司停止这样做，因为他们知道自己可以逍遥法外。”</p><p>&nbsp;</p><p>自2020年以来，Marx发现他的人脸照片正在传播。当他在另一个名为Pimeyes的人脸识别平台上搜索他的脸时，该平台挖掘出的图片甚至比Clearview的还要多。讽刺的是，其中有一张照片显示他正在发表关于隐私的演讲。另一张是2014年的当地报纸剪报，照片中他为难民提供免费的Wi-Fi。另一张照片是他在一个政党主办的活动上，他说他正在讨论诸如自行车道等相关的地方问题.......</p><p>&nbsp;</p><p>隐私专家表示，Pimeyes在技术上与Clearview不同，因为它不会将人脸存储到数据库中，而是在用户上传图片时在互联网上搜索人脸。该平台也更加开放；任何人都可以免费搜索该网站，不过要想查看照片的链接，他们必须支付每月36美元起的费用。</p><p>&nbsp;</p><p>该公司的首席执行官Giorgi Gobronidze教授也强调，与Clearview不同，Pimeyes不会爬取诸Facebook、Twitter或VKontakte（VK）等社交媒体平台。“理论上我们可以爬行社交媒体的事实并不意味着我们应该这样做，”Gobronidze说道，他在去年年底买下了该平台。相反，Gobronidze表示，Pimeyes使互联网更加透明了。“有成千上万的人不知道他们的照片正在被不同的网络资源所使用，”他说。“实际上，他们有权知道。”</p><p>&nbsp;</p><p>对于那些不想知道的人，Gobronidze说从他的网站上删除他们的人脸很容易。“（人们）可以提交退出请求，或者他们可以在每个免费搜索结果下一键删除并阻止某张图片的进一步处理。”尽管Pimeyes的官方总部位于欧盟以外的伯利兹（Belize），但Marx表示，该公司一开始就不应该使用他的照片。“只有在得到我明确同意的情况下，这家公司才能使用我的生物特征数据。”</p><p>&nbsp;</p><p>Pimeyes之前曾引发过争议。在2020年一系列新闻文章批评其隐私政策后，其前所有者、企业家Łukasz Kowalczyk和Denis Tatina决定出售该公司。但这两个人并没有从这个行业中退出。相反，根据波兰的公司记录，他们以一个名为Public Mirror的全新人脸搜索引擎的所有者身份重新露面，该引擎是针对公关行业的。Pimeyes和Public Mirror有一个共同点，那就是它们都包含了Marx的人脸。</p><p>&nbsp;</p><p>2022年3月，Marx发现Public Mirror的档案中有四张他的人脸。和其他人脸搜索引擎一样，不仅图片本身揭示了Marx的信息，而且还有与之相伴的在线链接。Public Mirror的链接就像是一个媒体文章目录，这些文章都是关于Marx或他发表过演讲的会议的。</p><p>&nbsp;</p><p>这些平台都透露了大量的个人信息。“你可以知道我在哪里学习，我喜欢哪个政党。”Marx说。总之，这些公司收集到的关于他的照片指向了一个行业，该行业所披露的信息比任何社交媒体的个人资料都要多得多。</p><p>&nbsp;</p><p>当Marx在2020年开始关注这个话题时，他只想让一家公司停止收集他的人脸照片。现在，他呼吁监管机构全面禁止该行业收集欧洲人的照片。要做到这一点，监管机构必须对Clearview杀鸡儆猴。但问题是，他们能吗？</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.wired.co.uk/article/clearview-face-search-engine-gdpr\">https://www.wired.co.uk/article/clearview-face-search-engine-gdpr</a>\"</p>",
    "publish_time": "2023-01-11 11:57:30",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "大话“智能对话”",
    "url": "https://www.infoq.cn/article/JL4C1m4lb4AiCkLRy4DZ",
    "summary": "<p>近年来，随着人工智能的快速发展，智能对话技术趋成熟，逐渐成为大家关注的焦点。大环境催化下，全行业数字化应用也迎来了需求拐点，智能对话行业发展进入需求爆发期。如今智能硬件语音交互所搭载的算法将成为硬件智能化的基础标配，随着 5G 技术的发展，智能硬件市场的发展将驱动中国语音助手市场规模进入爆发阶段。</p><p>&nbsp;</p><p>于是 InfoQ 编辑对 OPPO 对话系统工程专家莫骁进行了采访，莫骁多年来一直专注后端工程架构，从 0 到 1 搭建<a href=\"https://www.infoq.cn/article/JZw9tHzimGleWBq65lN6\"> OPPO</a>\" 智能助手小布的对话系统后端系统，目前负责对话系统工程架构规划和研发工作，与他的对话，我们对 <a href=\"https://www.infoq.cn/article/YXCoqIWRvZhCDw1tU6Wf\">OPPO </a>\"及全行业智能对话技术的发展有了一个全面的了解。</p><p>&nbsp;</p><p>以下是视频采访的全部内容，为方便读者查看，视频下方也附上了文字内容。</p><p></p><p></p><p></p><p></p><h4>InfoQ：目前越来越多的人开始关注智能对话领域，现在智能对话技术的发展现状是怎样的？国内外相关技术的演进方向和发展速度是否有所差异？</h4><p></p><p>&nbsp;</p><p>莫骁：行业的技术发展可以分成两层，第一层是感知智能的技术，第二层是认知智能的技术，这两方面共同构成了产业目前需要的对话技术。在感知智能方面，整体趋势是从语音的单模态向多模态发展。认知智能则是从人工规则系统向预训练大模型的方向发展，这在产业界也有所体现。</p><p>&nbsp;</p><p>2013 年至 2015 年期间，深度学习技术实现了爆发式的成长。在亚马逊 Alexa 等智能音箱的领域及智能客服的领域都实现了产业落地。从目前的发展来看，Alexa 的智能音箱目前也是从语音交互形态往触屏到多模态的方向演进，这也对百度、阿里、小米等公司产生了较大的影响。在这一方面，国内外的差异不会太大，整体的发展趋势还是一致的。</p><p>&nbsp;</p><p></p><h4>InfoQ：关于对话系统的评估，这个是最难被定义的，也是最重要的，您认为到底什么是“好的”对话？</h4><p></p><p>&nbsp;</p><p>莫骁：我们可以从一个人的感知层面去定义一个对话的“好坏”，简单来说，一个好的对话首先是流畅的，其次是满意的，第三是可信的。</p><p>&nbsp;</p><p>从流畅度来说，对话要能够自然进行下去，不要有割裂感。</p><p>&nbsp;</p><p>从满意度来说，对话要能满足一定的意图，比如说在这次采访中，需要从专业的角度进行作答，即使是在平时的闲聊沟通中，对话也并非是毫无意图的，漫无目的的闲聊也会有情感的诉求，在这种情况下，也可以认为是满足了用户的某种意图。</p><p>&nbsp;</p><p>从可信度来说，我们希望人机要像朋友一样能够持续地交互下去，人机之间的信任关系非常重要，这包括了安全隐私方面的互信，内容的可信以及三观的可信，比如不能出现敏感的政治评论或是对用户进行人身攻击。</p><p>&nbsp;</p><p>这是从人三个感知层面对对话进行“好坏”的判断，它是非定量的，也相对模糊。学术界会用更加量化的指标来评价“对话”的好坏，比如参考机器翻译，用 BLEU 指标评价结果和人工标注之间的相关性。除此之外，对话的轮次，或者是任务的完成度，以及其它的近似任务完成度的指标定义也是评价对话“好坏”的指标。</p><p>&nbsp;</p><p>在 <a href=\"https://www.infoq.cn/article/58dW6BKuNZVUrJg4xmur\">OPPO </a>\"的实践中，我们会构建一个完整的数据质量的工程系统来辅助定义对话的“好坏”，目前主要是以人工评价为主、自动的指标评价为辅。在对话的完整链路当中，要能够听清你在说什么，理解你在说什么，并用一个合适的内容来满足你的意图。在整个过程的漏斗模型中，我们会通过数据的埋点、采集、上报、分析、评估形成闭环，打造对话系统“好坏”的人工和自动化相结合的评估体系。</p><p>&nbsp;</p><p></p><h4>InfoQ：目前智能对话领域最大的“技术挑战”是什么？行业里是如何应对这个挑战的？</h4><p></p><p>&nbsp;</p><p>莫骁：当前智能对话领域最大的“技术挑战”需要从两个方面来看，一个是智商的层面，一个是情商的层面，这两个因素共同决定了人机对话中机器的对象是否足够的聪明。在智商方面，行业里有一些公司背靠搜索及知识图谱技术，通过知识补充智商；在情商方面，也有公司从拟人化及情感化的角度赋予机器人格，赋予它人类的感知和情感，对情商做一个补充。</p><p>&nbsp;</p><p></p><h4>InfoQ：对于用户来说，“智能对话”产品的核心需求是什么？</h4><p></p><p>&nbsp;</p><p>莫骁：从用户需求层面看，主要分为三层。第一层需求是来源于效率型用户的需求，用户希望能够通过对话的方式控制一些设备，这种属于命令型的需求，比如我需要智能助手帮我打开 WI-FI。</p><p>&nbsp;</p><p>第二层需求是知识内容与日常服务，用户会对智能助手进行提问，比如在小孩的教育场景种所需要回答的内容，或者是满足用户叫外卖等需求。这种属于“进阶”的需求，用户需要的是更贴心的个性化服务，智能对话产品还会有一些主动行为，比如在识别到用户熬夜之后，通过一些推送服务提醒用户早睡。</p><p>&nbsp;</p><p>第三层需求会更加高阶一些，它是更上层的需求——情感诉求，通过分析用户与小布助手进行的多轮交互，我们会发现用户对智能助手具有大量的情感诉求。</p><p>&nbsp;</p><p>从技术层面看，也是分为三类需求。第一类是任务型的对话，在这种需求形态下，为了完成某些任务，对对话进行相应的组织，对应的是前面提到的第一层和第二层的用户需求。第二类是知识问答类型的对话，也就是 Q&amp;A ，一般会对应第二层的用户需求。第三类是开放域的闲聊对话，对应的是第三层用户需求。</p><p>&nbsp;</p><p></p><h4>InfoQ：小布助手对话系统主要是应用在什么样的场景里？分别解决了用户什么需求？有哪些技术亮点？</h4><p></p><p>&nbsp;</p><p>莫骁：截至去年 2 月，小布助手覆盖了逾 3 亿设备，月活跃用户数超过 1.4 亿。在如此庞大的用户规模下，它的用户群体也非常广泛，我们需要满足不同用户群体的不同需求。在上一个问题中，我们提及的三层用户需求以及三种不同技术需求都会有所覆盖。</p><p>&nbsp;</p><p>总的来说，小布助手的用户需求是非常长尾的需求，有点类似搜索系统，在长尾的用户需求之下，如何让这些用户的需求不断地被发现、被满足，这是需要持续探索的事情。基于此，小布技术团队以自学习的算法工程架构进行支撑，发现问题并主动根据用户需求进行产品升级与维护。</p><p>&nbsp;</p><p></p><h4>InfoQ：从前面的回答可以看到，在技术探索上，小布助手主要是在预训练大模型上有所投入，除此之外，在其他方向上是否也会有相应的探索呢？？</h4><p></p><p>&nbsp;&nbsp;&nbsp;&nbsp;</p><p>莫骁：小布助手是从 2018 年开始从 0 到 1 进行建设的，这一启动时间较晚于行业，如何面向数亿用户量快速完成技术的追赶，是我们当时面临的一大挑战。</p><p>&nbsp;</p><p>在此背景下，我们发现，小布助手的用户场景中可以归纳为“五多”，我们会面临多设备、多领域、多模式、多模态以及多上下文的挑战，因此需要一个非常灵活并且能够支撑业务快速迭代的工程架构往下发展，于是我们选择了分布式的组件化架构——Pipeline 架构来做支撑。</p><p>&nbsp;</p><p></p><h4>InfoQ：在学术界，对话系统主要有 Pipeline 和 E2E 两种架构，但据我们观察，Pipeline 在工业届应用较多，E2E 还处在探索阶段。您觉这两种架构分别有何优缺点呢？</h4><p></p><p>&nbsp;</p><p>莫骁：这是一个很好的问题，Pipeline 架构的主要优点也是它在工业界应用比较多的原因。Pipeline 的分治思想可以把一个大问题拆解成若干个小问题，每一个小问题用相应的模块来解决，这样可以得到一个比较可控的解决方案。它最大的优点在于可控、稳定。但 Pipeline 也有相应的缺点，因为每一个模块之间是一个级联的关系，所以错误会累积，优化效果的“天花板”比较受限，串联出来的问题解决起来也比较困难。</p><p>&nbsp;</p><p>E2E 架构在学术界应用得比较多。E2E 架构主要通过大模型解决端到端的问题，不再把一个大的问题拆解成若干个小问题。这种解决方案主要的优点在于可以联合地解决问题，整体的目标是统一的。它的缺点在于过程会相对不太可控，因为大模型的可解释性是相对比较弱的。</p><p>&nbsp;</p><p>在小布助手的实践中，整个对话系统是一个大的工程系统，采用 Pipeline 架构更符合当前的业务状态及业务诉求。</p><p>&nbsp;</p><p></p><h4>InfoQ：小布助手对话系统在 Pipeline 和 E2E 这两种架构方面分别做了哪些探索？</h4><p></p><p>&nbsp;</p><p>莫骁：小布助手对话系统在 E2E 上会进行相应的融合，比如用户情感诉求中的“闲聊”，在预训练技术红利下，基于 transformer 架构的大模型在小布助手也有得到应用，这是一个比较典型的 E2E 系统，我们也会把它集成进 Pipeline 的系统当中。在这种情况下，小布助手的对话轮次会明显增加；针对在安全方面不太受控的问题，我们会在合适的场景里进行限定。这相当于 E2E 在局部领域集成进 Pipeline 中。</p><p>&nbsp;</p><p></p><h4>InfoQ：从对话引擎层和数据层，小布助手对话系统分别又有哪些技术突破？有什么架构建设经验可以分享呢？</h4><p></p><p>&nbsp;</p><p>莫骁：前面已经提到，小布助手从 2018 年开始进行建设，建设过程可以分成三个阶段：第一个阶段是 2018 年启动建设，一年内在 2019 年 4 月份上线，这是起步阶段。第二个阶段是上线后，一年之内快速对齐竞品特性，这是快跑阶段。第三个阶段是深入进行体验优化以及业务创新，这是冲锋阶段。</p><p>&nbsp;</p><p>这三个不同的阶段，整体架构建设的原则是一致的，最终还是要为业务成功服务。因此，小布助手的架构建设主要遵循了康威定律——随着组织架构的变化，技术架构需要适应组织架构。</p><p>&nbsp;</p><p>在起步阶段，小布助手采用大单体的架构设计思路，比较适合小团队快速试错以及快速推进的业务目标。</p><p>&nbsp;</p><p>在快跑阶段，小布助手采用前面介绍的分布式组件化的 Pipeline 架构，支持团队的快速扩展，适应迭代速度的提升以及多人的协作，迭代效率较起步阶段提升了 4-5 倍。</p><p>&nbsp;</p><p>最后的冲锋阶段需要往更深入地优化体验并进行业务探索，对于质量及性能的诉求会更高。在这个阶段，我们会在组件化的 Pipeline 架构中，集成更完善的质量体系和观测体系。</p><p>&nbsp;</p><p></p><h4>InfoQ：数据安全问题一直是一个广受用户关注的问题，请问小布助手对此有何解决方案？您如何看待智能助手的数据治理技术现状呢？</h4><p></p><p>&nbsp;</p><p>莫骁：小布助手一直非常重视隐私安全的保护，隐私安全是我们的第一道红线，基于此，我们专门设计了安第斯安全大脑来看护。通过在 Pipeline 架构中加入安全考虑和设计，例如端侧数据运行架构、声纹等用户生物识别数据还有数据加密、去标识化、匿名化、分级访问控制等一系列技术，我们实现了对用户个人数据全生命周期安全保护。整套解决方案现已通过 ISO27001、ISO27701 等权威机构认证，能够有效保障用户的数据安全。在内容安全方面，小布助手的回复会相对谨慎，避免输出敏感内容；在风控安全方面，如积分等与资产相关的服务，小布助手会通过风控架构解决恶意黑灰产行为。</p><p>&nbsp;</p><p>站在行业视角来看，从国外的 Alexa 到 Siri ，再到国内众多的语音助手，都经历过一些有关“语音数据是否有安全保障”的质疑。小布助手从未忽略过这种威胁，也不断加强在这一方面的治理。随着端侧算力增强，端边云协同技术的成熟，未来部分必须云侧做的计算可能迁移到端侧和边侧，实现更强的隐私安全保障。</p><p>&nbsp;</p><p></p><h4>InfoQ：未来，您觉得智能对话在智能助手方面还将有哪些演进？您理想中的“智能对话”是怎样的？</h4><p></p><p>&nbsp;</p><p>莫骁：总的来说，智能对话在智能助手上会有三个演进方向，端边云协同、多模态和主动对话，这也是基于前面的技术探讨得出的结论。隐私安全驱动下的端边云协同，多样化设备和元宇宙虚实共生下的多模态，个性化有温度体验驱动下的主动对话。</p><p>&nbsp;</p><p>刚才讨论到，好的对话应该要流畅、满意、可信，技术上如何逼近？在我看来，一个好的对话首先是高智商的，目前很多智能助手的回答并不理解真实世界的知识，需要在这一层面做一些补充，要能理解用户所说的话，能够和真实世界的知识对应起来进行理解，同时需要一定程度的推理。第二是高情商的，一个好的对话需要能够用情商来让对话流畅进行，让人认为这个“人”是有人格的。第三是高度个性化的，需要像一个老朋友或者是一个真正的助理一样了解用户，不需要重复出现上下文，可以根据用户过往的行为和兴趣、画像更好地满足用户需求，在更少的对话轮次中猜中用户的意图。</p>",
    "publish_time": "2023-01-11 13:48:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "能与人类谈判、游戏水平媲美真人，Meta是如何构建新人工智能CICERO的？",
    "url": "https://www.infoq.cn/article/WTGeuldhgMYP96V9FHdN",
    "summary": "<p></p><blockquote>前段时间，Meta正式发布人工智能CICEROO——这是第一个在时下流行的战略游戏Diplomacy中表现达到人类水平的人工智能。在CICEROO的背后，有哪些技术实践？</blockquote><p></p><p></p><p>本文最初发布于Meta AI官方博客。</p><p></p><p>长期以来，游戏一直是人工智能最新进展的试验场——从深蓝战胜国际象棋大师Garry Kasparov，到<a href=\"https://www.infoq.cn/article/Lets-talk-about-deep-learning.\">AlphaGo</a>\"熟练掌握围棋，再到Pluribus在扑克游戏中战胜了人类高手。但真正有用的多功能代理不能局限于在棋盘上移动棋子。我们能否建立更有效、更灵活的代理，使用语言进行谈判、说服，并与人合作，像人那样实现战略目标？</p><p></p><p>日前，我们宣布了一项突破性进展，向着构建掌握这些技能的人工智能迈进了重要的一步。我们已经构建了一个代理CICERO——这是第一个在时下流行的战略游戏Diplomacy中表现达到人类水平的人工智能。CICERO在webDiplomacy.net（该游戏的在线版本）上证明了这一点，它的成绩是人类玩家平均分的两倍多，并且在玩过多个游戏的玩家中排名前10%。（观看<a href=\"https://ai.facebook.com/1319742961447503/videos/445937990947006/\">视频</a>\"）</p><p></p><p>几十年来，Diplomacy一直被视为人工智能领域近乎不可能的重大挑战，因为它要求玩家掌握了解他人动机和观点的艺术；制定复杂的计划并调整策略；然后用自然语言与他人达成协议，说服他们建立伙伴关系和联盟，等等。CICERO在使用自然语言与人进行外交谈判方面表现非得常出色，以至于玩家常常倾向于与CICERO而不是其他人类玩家合作。</p><p></p><p>与国际象棋和围棋等游戏不同，Diplomacy是一个关于人而不是棋子的游戏。如果代理无法辨别出某人可能在虚张声势，或者另一个玩家会认为某一举动具有攻击性，那么它很快就会输掉游戏。同样，如果它不能像真人那样说话——表现出同情心，建立关系，并对游戏有一定的了解——它就无法找到其他愿意与它合作的玩家。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/34/3482be69f178b3ff89df11374593ee03.png\" /></p><p></p><p>我们的主要成就是打通了两个完全不同的人工智能研究领域并开发了新技术：战略推理（如AlphaGo和Pluribus等代理中使用的技术）和自然语言处理（如<a href=\"https://www.infoq.cn/article/9cb21vxX8tfDP3Kk6yqw\">GPT-3</a>\"、BlenderBot 3、<a href=\"https://www.infoq.cn/article/76gYqPA2YU0YXCDHFvIE\">LaMDA</a>\"和OPT-175B等模型中使用的技术）。举个例子，CICERO可以推断出，在游戏后期，它会需要特定玩家的支持，然后精心设计一个策略来赢得这个人的青睐——甚至可以识别出这个玩家从自己特定的视角所看到的风险和机会。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ba/bab472f5e4ef56e2586391f65e66522f.png\" /></p><p></p><p>我们已经将代码开源，并<a href=\"https://l.facebook.com/l.php?u=https%3A%2F%2Fwww.science.org%2Fdoi%2F10.1126%2Fscience.ade9097&amp;h=AT1yETuFYyDIGWvDq6WyYLN_ofVAHd1adY_BTxT-r2D1HoB9lXR3vrNjxwrimMgWP2IeuMgilrYlf1LmChOaKb75uICJ0it8e9crgtl5UJ5FgxC3736BRz_GQIezwgVV26t65sLM6NxPEw3GaByZSQ\">发表了一篇论文</a>\"，希望可以为更广泛的人工智能社区带来帮助，让他们使用CICERO来推动人类与人工智能的合作进一步进展。如果你想了解更多关于这个项目的信息，或者试用这个代码，请移步<a href=\"https://ai.facebook.com/research/cicero/diplomacy/\">CICERO的官网</a>\"。感兴趣的研究人员可以向<a href=\"https://ai.facebook.com/research/request-for-proposal/towards-human-AI-cooperation/\">CICERO RFP</a>\"提交建议，获取数据使用权。</p><p></p><h2>我们是如何构建CICERO的？</h2><p></p><p></p><p>CICERO的核心是一个可控的Diplomacy对话模型，外加一个策略推理引擎。在游戏中的每个时刻，CICERO都会查看棋盘及其对话历史，并对其他玩家可能采取的行动建模。然后，它会用这个方案来控制一个可以生成自由对话的语言模型，告知其他玩家它的计划，为其他玩家提出合理的行动建议，与他们做好协调。</p><p></p><h3>可控的对话</h3><p></p><p></p><p>为了构建一个可控的对话模型，我们从一个有27亿参数的类似BART的语言模型开始，使用从互联网上收集的文本对它进行了预训练，然后使用webDiplomacy.net上超过4万个人类游戏对它进行了优化。我们开发了一些技术，将训练数据中的信息与游戏中相应的计划动作进行自动标注，这样，在推理时我们就可以控制对话的生成，讨论代理和其对话伙伴所期望的具体行动。</p><p></p><p>例如，如果我们的代理在扮演法国，在涉及英格兰支持法国进入勃艮第的计划时，对话模型可能会生成这样一条信息发送给英格兰，“嗨，英格兰！你愿意支持我进入勃艮第吗？”以这种方式控制对话生成，可以使CICERO将对话建立在一套计划之上，并随着时间的推移完善和改进，以更好地进行谈判。这有助于代理更有效地协调和说服其他玩家。</p><p></p><p>第1步：使用棋盘状态和当前对话，CICERO对每个人下一步会做什么做了一个初步预测。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f9/f9a2c736753612ddf8e50e3330f61b27.png\" /></p><p></p><p>第2步：CICERO利用规划反复完善该预测，然后利用这些预测为自己和合作伙伴形成一个意图。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/af/af1f50ac9d99b056405b69d2dfd1b85b.png\" /></p><p></p><p>第3步：根据棋盘状态、对话和意图，生成几条候选信息。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/75/750c3972222b93da963114bfd08df374.png\" /></p><p></p><p>第4步：对候选信息进行过滤，减少废话，使价值最大化，并确保其符合意图。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ab/ababf734c943f66bfed87a8613df2a53.png\" /></p><p></p><p>我们利用一些过滤机制——例如经过训练的分类器来区分人类和模型生成的文本——来进一步提高对话质量，确保生成的对话是切合实际的，与当前游戏状态和之前的信息相一致，并且战略上也合理。</p><p></p><h3>对话感知策略 &amp; 规划</h3><p></p><p></p><p>以前，在象棋、围棋和扑克等对抗性游戏中的超人代理是通过自我强化学习（RL）创建的——让代理与自身的其他副本进行数百万次对局来学习最佳策略。然而，涉及合作的游戏需要对人类在现实生活中的实际行为进行建模，而不是对完美的机器人副本应该做什么进行建模。特别是，我们希望CICERO制定的计划与它和其他玩家的对话一致。</p><p></p><p>人类建模的经典方法是监督学习，即用带标签的数据（如过去游戏中人类玩家的行动数据库）来训练代理。然而，纯粹依靠监督学习根据过去的对话结果来选择行动，会导致代理的能力相对较弱，而且很容易被利用。例如，一个玩家可以告诉代理，“很高兴我们能达成一致，你将把你的部队从巴黎撤出！”由于类似的信息只有在达成协议时才会出现在训练数据中，所以代理可能真的会将其部队调离巴黎，即使这样做是一个明显的战略失误。</p><p></p><p>为了解决这个问题，CICERO会运行一个迭代规划算法，平衡对话的一致性和合理性。首先，代理会根据它与其他玩家的对话预测每个人在当前回合的策略，同时也预测其他玩家会如何预测代理的策略。然后，它会运行我们开发的名为piKL的规划算法，根据其他玩家预测的策略选择具有更高期望值的新策略来迭代改进自己的预测，同时还会设法使新的预测接近于初始的策略预测。我们发现，与单纯的监督学习相比，piKL能更好地模拟人类游戏，帮代理选出更好的策略。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f6/f65029e46bc164e101806388eec80aa8.png\" /></p><p></p><h2>生成自然、有目的的对话</h2><p></p><p></p><p>在Diplomacy中，玩家与他人的交谈方式，甚至比他们移动棋子的方式更重要。在与其他玩家一起制定策略时，CICERO能够说出清晰而有说服力的话。例如，在一个演示游戏中，CICERO要求一个玩家立即在棋盘的某个部分提供支持，同时向另一个玩家施加压力，使其在后续的游戏中考虑结盟。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/22/22f6a507349f895835a3becbe0f93baa.png\" /></p><p></p><p>在这些交流中，CICERO试图通过向三个不同的玩家提供行动建议来执行其策略。在第二次对话中，代理能够告诉其他玩家为什么他们应该合作，以及合作如何对双方有利。在第三次对话中，CICERO既是在征集信息，也是在为未来的行动打基础。</p><p></p><h2>哪里还有改进空间？</h2><p></p><p></p><p>必须认识到，CICERO有时也会生成不一致的对话，妨碍目标的达成。在下面的例子中，CICERO扮演的是奥地利，它与自己的第一条信息（要求意大利移到威尼斯）前后矛盾了。虽然我们的过滤器套件就是用于检测这类错误，但它并不完美。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0b/0b3c8790b1763a7cac14a90b37dd2db0.png\" /></p><p></p><h2>将Diplomacy作为促进人类与人工智能互动的沙盒</h2><p></p><p></p><p>在竞合类游戏中，以目标为导向的对话系统的出现，对于协调AI与人类的意图和目标提出了重要的社交和技术挑战。Diplomacy为研究这一问题提供了一个特别有趣的环境，因为玩游戏需要在相互冲突的目标中艰难应对，并将这些复杂的目标翻译成自然语言。举个简单的例子，玩家可能会为了维持一个盟友关系而选择在短期利益上做出妥协，目的是希望这个盟友能够在下个回合中帮助他们取得更有利的地位。</p><p></p><p>虽然我们在这项工作中取得了重大的进展，但是，将语言模型与具体意图紧密结合的能力，以及确定这些意图的技术（和规范）挑战，仍然是有待解决的重要问题。通过开放CICERO的源代码，我们希望人工智能研究人员能够基于我们的工作以负责任的方式继续研究下去。通过使用我们的对话模型进行零样本分类，我们已经在这个新领域中围绕检测和删除有毒信息做了一些初步的工作。我们希望，Diplomacy可以作为一个安全的沙盒来推进人类与人工智能互动的研究。</p><p></p><h2>未来展望</h2><p></p><p></p><p>虽然CICERO只会玩Diplomacy这个游戏，但这项成果背后的技术涉及到现实世界的许多应用。比如，通过规划和RL控制自然语言生成，减少人类和人工智能驱动的代理之间的沟通障碍。再比如，如今的人工智能助手只擅长回答简单的问题，如告诉你天气，但如果他们能维持长时间的对话，并以教给你一个新技能为目标，那会怎样？另外，想象有一个视频游戏，其中的非玩家角色（NPC）可以像人一样计划和交谈——理解你的动机并相应地调整对话——以帮助你完成攻打城堡的任务。</p><p></p><p>我们非常看好这些领域未来的发展潜力，也希望可以看到其他人基于我们的研究开展进一步的工作。</p><p></p><p>原文链接：</p><p><a href=\"https://ai.facebook.com/blog/cicero-ai-negotiates-persuades-and-cooperates-with-people/?utm_source=twitter&amp;utm_medium=organic_social&amp;utm_campaign=cicero&amp;utm_content=video\">https://ai.facebook.com/blog/cicero-ai-negotiates-persuades-and-cooperates-with-people/?utm_source=twitter&amp;utm_medium=organic_social&amp;utm_campaign=cicero&amp;utm_content=video</a>\"</p>",
    "publish_time": "2023-01-11 14:29:03",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "火遍国内外，Web3的狂热与现实",
    "url": "https://www.infoq.cn/article/UfUdeqqaKHJaVuMdbHjP",
    "summary": "<p></p><p></p><blockquote>一文道尽 Web 3。</blockquote><p></p><p></p><p>最近两年来，“<a href=\"https://www.infoq.cn/theme/129\">Web 3</a>\"”这个概念在IT行业的热度迅速升高。在刚刚过去的2022年，Web 3可谓是站在了舆论的风口浪尖之上，实在火得不行。</p><p></p><p>但时至今日，很多人面对这个术语时仍然感到云里雾里，并不清楚它与现有的互联网技术有哪些异同。另一方面，Web 3.0的布道者认为该技术将成为下一代互联网的基础设施，很多企业也开始在相关领域进行前期研发投入。此外，大火的元宇宙概念与Web 3.0之间的关系也让人们感到好奇。</p><p></p><p>最近，InfoQ专访了凯云实验室CTO 杨威理 （Wiiliam Yang）。凯云实验室是一家初创企业，立志于构建面向Web 3的免信任数据库。杨威理在访谈中分享了他对Web 3这一技术的诸多看法，为我们描述了一幅基于Web 3的新一代互联网产业的蓝图。</p><p></p><h2>Web3热潮</h2><p></p><p></p><p></p><blockquote>InfoQ：请您用通俗易懂的语言解释一下什么是Web 3。目前而言，这项技术有没有被普遍接受的<a href=\"https://www.infoq.cn/article/jsf43rxkftgecP5aQCNG\">定义</a>\"？</blockquote><p></p><p></p><p>杨威理： 从技术角度讲，我们通常认为Web3是以去中心化技术为核心的新一代互联网生态系统。Web3是以区块链技术为核心，构建新一代的去中心化互联网组件，再基于它们来构建我们想要提供的服务、应用。以区块链技术构建这些网络组件，目的在于让用户能够真正拥有互联网，让互联网用户的身份和数据为我们自己所有，让我们成为数据的主人。我们能通过这个网络展示个人数据，能用它们来交易变现。</p><p></p><p>从另一个角度讲，Web1时代，我们只能读数据，通过浏览网页这种形式读取信息和资讯。Web2时代最大的变革就是，我们每个互联网用户成为了内容的创建者，我们都在不断向互联网输出内容。</p><p></p><p>在这个过程中，最早我们是在电脑上用浏览器操作，比如打开一个博客网页写文章。随着移动互联网的成熟，我们现在已经习惯于在手机上操作，大量移动应用随之兴起，互联网企业开始记录个人的内容、数据。</p><p></p><p>Web3带来的不同在于，我们可以对互联网做出自己的决定。比如微博是由新浪推给我们的一款产品，所有的数据信息都是中心化地在新浪的管理之下。而Web3是一个去中心化的网络，没有这种单点的控制或管理，网络中的这些资源该做什么事情，会有类似大众投票的机制来决定。我们也可以完全决定个人发布的数据该如何管理，决定哪些人有权访问我们的数据。同时Web3的资源也是永远可以访问的，不会出现某家厂商的服务器出故障就无法访问的问题。</p><p></p><p>Web3是一个以去中心化技术为核心的互联网生态系统。我们可以比对我们现在生活的地球生态，互联网上也同样会有必要的这些元素。我们现在在互联网上可能只能做很有限的一些事情，那么在新一代互联网生态系统中，它一方面能满足我们现在上网的这些传统需要，同时还会满足跟我们真实生活越来越接近的一些需求。比如元宇宙这样的概念就是说，互联网更像是一个虚拟的世界，带给我们越来越好的体验。</p><p></p><p></p><blockquote>InfoQ：从历史发展的角度来看，您觉得互联网已经进化到Web3的阶段了吗？</blockquote><p></p><p></p><p>杨威理：目前我们依然还处于第三次迭代的初期。首先一个共识就是，区块链技术是第三次迭代的核心，这个技术提出已经有很多年，有很多优秀的产品和项目推出。但是从终端互联网用户的角度来讲，这些产品作为Web3基础设施，目前还不足以匹配我们现在日常使用的互联网产品，从用户体验到性能，方方面面都跟Web2的产品还有差异。要让第三次迭代进入比较成熟的阶段，首先就是必须依赖于底层这些基础设施的进一步完善。比如说像非常重要的分布式存储技术，目前虽然我们看到了很多很有希望的产品，但和现有的这些存储服务相比，目前Web3的这些产品还需要更好的提升。</p><p></p><p>另外对于整个Web3，未来这些产品需要重新定义互联网的经济模型、用户行为。Web3认为用户的个人数据都是有价值的，例如，用户发的一篇微博文章或一个视频，它本身是有价值的。这个价值如何在Web3里体现出来？我们可以认为，阅读者是需要付费的，这听起来可能比较颠覆大家的使用习惯，但这有可能就是未来互联网的用户行为模式。这需要比较长的时间，让企业产品的研发方以及互联网用户不断实践，适应新的经济模型。</p><p></p><p></p><blockquote>InfoQ：Web3这个概念大概在最近一年开始火起来，但它其实不是一个特别新的概念。那么它最近一年突然热度飙升，您觉得主要是因为什么原因？</blockquote><p></p><p></p><p>杨威理： Web3的概念在最近一年特别火，我可以归结为两方面。一方面是因为元宇宙这个概念，另一方面就NFT。这两个概念火起来了以后，大家开始关注、探索，摸到了它背后的Web3这个概念。</p><p></p><p>NFT究竟是什么？为什么大家这么感兴趣？那是因为NFT让我们看到了所谓数字资产，也就是互联网上的个人数据，比如说文章、图片，在Web3里有了价值变现的渠道。它给了我们一种可能性。我们可能已经习惯于每天在互联网上使用各种应用来交流，发文章、图片、视频....但可能从来没想到NFT能让我们在网络上留存的内容数据变成价值。NFT标识的是用户资产的唯一性，比如说小明的书就是唯一的一本，是小明的，那么我以NFT的形式来定义这本书，记录在区块链之上，或许它有些特殊的价值，这样我们是能够通过NFT的渠道把它变现。</p><p></p><p>另外这几年疫情让我们的生活方式发生了非常大的变化，带火了元宇宙的概念。元宇宙给我们一种虚拟化办公、娱乐和生活的可能性，当大家去了解NFT、元宇宙，最终发现了它背后非常大的概念就是Web3，这也是Web3在这一年的时间内越来越火的原因。</p><p></p><h2>Web3.0基础设施建设</h2><p></p><p></p><p></p><blockquote>InfoQ：相比于Web2，Web3的区别和优势是什么？</blockquote><p></p><p></p><p>杨威理： Web3的最大优势在于，互联网用户有了数据的所有权。我们有很多个人数据都存在互联网企业的服务器上，这些企业完全拥有和控制了我们的用户数据。我们虽然免费使用这些应用，但企业总是需要盈利，它的钱从哪来？很大一部分就来自于基于用户数据做的市场营销和广告推广，通过这种方式来赚钱。在这种数据单一存储与企业侧的模式下，存在一些个人数据的隐私方面的问题，我们无法完全控制这些企业对个人数据的使用，也不知道他们是否对这些数据做了修改等等。</p><p></p><p>很重要的一点在于，在Web2时代，我们并不能够保证我们的个人数据随时都能访问，因为企业有可能由于某些原因切断一些资源的访问。比如我们上传一张图片，可能服务器关掉了，就再也无法访问了。在Web3的时代，数据并不为某一家企业所有，它安全地加密存储在网络之上。当某一方需要访问我们的数据，需要用户进行授权，这样用户可以安全管理个人数据。这中间会有一个密钥管理的概念。用户有自己的密钥，他可以决定这些数据是否能够被别的服务访问，这个所有权就给到了用户，这就是数据的所有权。</p><p></p><p>另一方面是用户身份机制的变化。随着Web3技术的发展，去中心化身份成为了可能。去中心化身份就是用户能够以去中心化的方式完全管理自己的身份和数据。因为区块链技术提供了不可删改和账本的功能，它是分布式的，因此用户可以通过可加密验证的数字身份去证明自己，这是一种很安全的证明方式，同时不泄露我们的个人信息。</p><p></p><p>还有一点非常重要的不同是组织治理的形式。Web3的组织形式会发生根本的变化。目前主流的组织形式是公司，公司需要注册，会有员工、不同的角色，管理层根据公司的制度和他们的决策为公司未来的发展负责。Web3里就是去中心化的自治组织，这种组织形式下不会有CEO，取而代之的是通证的持有者。组织会预先设定好它的架构和规则，以智能合约的形式来定义好，发布在网络之上，所有的规则都会严格执行。这就不会出现一小部分人的一些特权导致公司决策并不能以民主的形式来制订或实施，推动Web3的组织管理实现民主化。</p><p></p><p>最后，正因为在Web3里没有一个单一的主体实体，所有的架构都是去中心化的，因此在这样一个生态系统之上，数据和服务永远都可以访问，并且无法被阻断，交易数据也全部都存储在<a href=\"https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247576268&amp;idx=2&amp;sn=6df2fdd8a92fbda5dd3f5577ef69ffff&amp;chksm=fbeb1303cc9c9a15d7fb25ab8af336099ba5c936868dd770e6099a5f0a94524172f9575948f6&amp;token=1429146590&amp;lang=zh_CN#rd\">区块链</a>\"之上，无法被篡改。以上就是Web3和Web2最大的区别。</p><p></p><p></p><blockquote>InfoQ：Web3接下会与Web2共生，还是说到一个阶段之后，它就会完全取代后者？</blockquote><p></p><p></p><p>杨威理： 我认为这取决于我们如何去定义Web3和Web2。从技术角度讲，Web3和Web2都充分利用了人类在计算机科学和非计算机科学领域里的成果，它们只是为互联网用户展现了不同的用户体验，定义了用户不同的角色，来为用户服务。Web2中，我们可以认为用户只是在使用互联网给我们的一些功能，并不真正完全拥有互联网，个人数据也不完全为自己所用，不能把它交易变现，不能体现出它更多的价值。</p><p></p><p>当互联网发展到Web3，用户有了不同的角色，我们成了这些数据的主人，可以对它进行我们想要的一些操作，甚至可以把它卖掉。而从技术角度来讲，Web3并不是站在Web2的对立面的，因此并不是说有了Web3，Web2就被颠覆掉，就没有了。Web3到现在并没有颠覆性的新技术出现，更多还是使用一些现在互联网中比较成熟的技术和概念，进行了一定的创新重组，为互联网带来一种新的概念。Web3的社区也借鉴了非常多的Web2的技术成果。</p><p></p><p>在不远的未来，我们应该能够看到，Web3领域的创业者推出大量创新性产品。比如Web3当中的去中心化博客是永远可以访问的，即使网络中的一两台主机服务器被关闭，甚至永久离开这个网络，并不影响我们对这些文章的访问。从用户的角度来讲，我们会看到一些互联网应用产品被成功从2.0复制到了3.0，至于他们之间的博弈最终是否导致2.0的产品消亡，这需要时间来告诉我们。它们有非常大的概率还会共存，这完全取决于用户。如果我们用户能够适应不同的经济模型或者用户行为，这种模式是有可能会共存的。</p><p></p><p></p><blockquote>InfoQ：面对当前的热潮，Web2公司应该如何去布局Web3？</blockquote><p></p><p></p><p>杨威理： 目前已经有大量Web2公司开始关注这个新兴领域。要开始在这一领域布局，首先是要基于公司自身的商业模式做调研，至少应该了解探索Web3究竟是什么，能给公司的用户带来哪些不一样的体验。公司要再一次从用户角度出发去思考用户价值这个问题，帮助用户实现价值流转。同时毕竟Web2的公司给用户提供了服务、产品，是要赚取利润，那么我们要考虑在新的技术架构、商业模式下如何赚取同样的钱。在Web3时代，企业无法再掌控所有用户数据，那么广告是否还能做？这一种赚钱的渠道是否还存在，如果不能再以这种方式赚钱，该怎么赚钱？这就是Web2公司必须要考虑的非常重要的一点。</p><p></p><p>我们认为公司应该主动调研区块链技术在公司业务中的可行性，考虑如何去重构我们的商业模式。后续需要的一个转变就是通过区块链为用户的数据提供交易和变现的平台，赚取其中的服务费用。还是以博客系统为例，Web3的时代，博主发的文章本身可能已经有了价值，用户阅读他的文章天然就要付费，这样博主就能够赚取到利润。那么这个利润如何给这个企业？博客系统的发布方可以从这个交易中收取一定的手续费来获取利润。当然这个收入情况是否能够支撑公司的运营，保证公司赚到钱，这也是Web2公司需要去调研的。</p><p></p><p>另一方面，很多Web2公司本来就是做互联网基础设施的，这类公司去布局Web3就很有必要。因为Web3本来在去中心化存储和分布式存储上有一个非常大的目标，Web2公司可以利用现有的成熟的技术和经验快速切入Web3领域，在这个领域里，作为先行者赚到第一桶金，树立自己在这个领域的行业地位。</p><p></p><p></p><blockquote>InfoQ：去中心化被认为是Web3的核心特征，您能否详细给我们解释下Web 3.0究竟是如何让互联网实现去中心化的？</blockquote><p></p><p></p><p>杨威理： Web3的技术栈可以自下而上分成五层。首先是基础设施和网络层，提供了整个互联网的通信机制、接口、协议等，最著名的就是P2P这个点对点的网络协议。区块链技术也是基于P2P建立的，这就从最底层给Web3提供了去中心化的基础。在它之上有一层叫中间层，或者是链下层，然后是协议层，也可以称之为链上层。中间层的目的是解决协议层的扩展性和性能问题，将部分计算工作从区块链之上转到了链下来解决。在这三层之上就是API层和应用层，分别为开发人员和普通的互联网用户提供区块链的访问接口。这几层逐层为我们提供了去中心化的机制，从而实现了整个互联网的去中心化。</p><p></p><p></p><blockquote>InfoQ：区块链是Web3.0背后的关键技术，为什么区块链会成为这次互联网迭代（革命）的核心？</blockquote><p></p><p></p><p>杨威理： 当我们定义Web3的时候，是期望互联网再度出现变革，期望能够让用户真正拥有他们的数据，能够决定互联网的形态。我们发现去中心化能够为我们实现这个目标，而去中心化正好就是区块链技术带来的产物，因此区块链就成了Web3非常核心的基础设施。</p><p></p><p>区块链是分布式数据库的一种实现，数据一旦接入链上就无法修改，这样它也解决了不同网站之间的数据交换问题。用户数据就只有一份，存储在Web3的网络之上，在区块链上存储；不同的产品、不同的应用需要访问用户的个人数据，就需要用户授权。但数据就这么一份，只要能够经过授权，它都能够在用户授权之下使用其数据，这也就一定程度解决了网站或者应用之间的数据交换问题。</p><p></p><p></p><blockquote>InfoQ：实现Web3的技术支撑只有区块链吗？人工智能、机器学习、云等这些技术对Web3世界来说扮演着什么样的角色？现在，Web3的基础设施构建是否已经进入成熟阶段？</blockquote><p></p><p></p><p>杨威理： 区块链仅仅提供了去中心化分布式记账的手段，而Web3必要的核心组件包含了存储、计算、网络，那么区块链可以为我们解决一部分问题，比如说存储，也可能解决一些计算问题。目前而言，随着IPFS技术发展，去中心化存储逐渐成型，但还没有最终达到愿景中的那种级别，需要进一步发展。</p><p></p><p>接下来就是计算。智能合约给我们带来了计算能力，Web3应用的开发者可以基于智能合约来定义业务逻辑，智能合约帮助做具体的计算和实现，支撑Web3应用。人工智能、机器学习、云技术是相对更高一级的应用，也会应用Web3当中。例如人工智能可以更高效智能地进行数据分发，优化网络性能。云计算的背后本来就是分布式的技术架构，它和Web3在技术上没有特别大的差异。现在这些成熟的云厂商有大量的经验和技术积累，这对Web3的发展有很大的促进作用。同时现在这些云服务厂商非常有可能会在Web3领域扮演先行者的角色，他们有可能最早迎来产业变革。</p><p></p><p>在Web3的基础设施构建方面，从五层架构来看，每个领域都有明星产品。Web3现在还处于早期发展阶段，因此人工智能、云技术都可以被应用到Web3的领域当中。Web3领域里并没有颠覆性的新技术出现，它更多是对现在成熟技术和成果的整合，从而去解决互联网当中的一些痛点。</p><p></p><p></p><blockquote>InfoQ：现阶段Web3的应用程序开发是怎样的现状？</blockquote><p></p><p></p><p>杨威理： 目前的开发工作主要分为两大方面，一方面是基于去中心化技术的一些创新，这些创新一定程度上还在原型阶段，这方面大家去使用或尝试的相对会少一些。</p><p></p><p>另一个大方向就是将Web2的成熟产品搬到Web3之上，比如像Youtube、Facebook这些产品在Web3都有对标的竞品出现。因为Web3的社区生态很活跃，开发者也乐于将这些成熟产品和概念布置到Web3之上。这本身对Web3的基础设施发展就非常重要，因为用户的需求、产品的功能需求能够反映出基础设施的不足，从而推动基础设施进一步发展，这样对Web3本身就是非常好的促进。</p><p></p><p></p><blockquote>InfoQ：Web3领域的就业情况是怎样的？</blockquote><p></p><p></p><p>杨威理： 最近这一年时间，Web3的创业热潮是不断升温的，确实有大量Web2的工程师向Web3转型，这个趋势肯定是存在的。至于说多和少，这确实就是个相对概念，这个不太好衡量。</p><p></p><p>国内也是有很多团队在致力于Web3相关领域的技术研究和开发的，但国内目前还是没有Web3的一种成型的生态系统。另一方面，究竟怎样定义Web3的从业人员也是一个问题。我们不能说有人在研究区块链，他就是Web3的从业者，这种定义是没法明确的。</p><p></p><p></p><blockquote>InfoQ：如果说现在就有工程师想成为Web3的开发人员，他应该去学习哪些技能？</blockquote><p></p><p></p><p>杨威理： Web3领域，特别是区块链这块，整个社区比较偏向的编程语言，一个是Go，一个是Rust，这两个也是开发中的首选语言。Web3开发人员在这方面的编程技能挺重要。JavaScript也有不错的使用比例。当然作为开发人员，基础计算机科学知识是必备的，数据、结构、算法、网络都要熟悉。还要了解分布式系统、区块链技术、智能合约这些领域。</p><p></p><p></p><blockquote>InfoQ：对于现在的科技企业来说，既然Web3是未来的互联网形态，大家是不是从现在开始应该有意识，或多或少要开始为未来做一点准备？</blockquote><p></p><p></p><p>杨威理： 是的。科技企业应该从用户价值角度出发审视Web3的技术，看看它究竟能为用户带来什么样的用户体验，包括数据的融通、个人隐私数据保护、高度安全性等方面，区块链这些技术很重要，但并不是最高优先级。科技企业毕竟还是考虑企业盈利、商业模式，那就要思考区块链技术究竟在商业模式中能起到什么作用，Web3中的其他组件能够为科技公司的商业模式带来什么变革，在Web3里这家公司的产品将会是什么样的形态提供给用户。</p><p></p><p>另外就是市场营销的主题。目前市场营销还是非常重要的获取客户渠道，Web3就会有所不同。Web3世界中的重心就是构建消费者、客户社区，通过激励第一批的用户来带动新客户的到来。在Web3时代，所有企业都需要考虑这个问题。</p><p></p><h2>下一代互联网？</h2><p></p><p></p><p></p><blockquote>InfoQ：作为下一代互联网，Web3现在已经进入到了初级阶段。那么它的真正实现会有什么标志性的事物吗？</blockquote><p></p><p></p><p>杨威理： 应该很难有一个明确的标志、事件、时间点。我们在Web3上能达成的共识就在于互联网用户能够真正拥有个人数据，这是很不一样的互联网生态。那么随着我们在日常的互联网使用中越来越多感受到自己所拥有权限发生的变化，可能逐渐能够感觉到Web3的到来。</p><p></p><p>另外还有一点非常重要的在于用户的价值。Web2的时代，我们可能体会不到这个概念。我们现在使用互联网没有付钱，大多数应用都是免费使用的。很有可能在Web3的生态当中，我们使用互联网是要付费的，跟现在的使用习惯有非常大的不同，但这很有可能会是Web3生态中的现实。</p><p></p><p>那么用户怎样获得收入来支付这个费用？在Web3当中，很有可能每个人在互联网当中都是有价值的，我们能够在这个虚拟的世界当中创造价值，每个人的价值不仅体现在线下的工作中，还会体现在线上。我们如果具备写作技能可以把作品变现，我们擅长音乐可以将音乐作品变现，每个人在互联网当中不仅消费内容，同时具备将我们自己的价值变现的能力。具体到付费渠道，Web3当中也有数字钱包，数字钱包可以方便管理我们的数字资产、个人身份，现在看起来很麻烦的事情届时都会有很便捷的解决方案。</p><p></p><p></p><blockquote>InfoQ：Web3和元宇宙两个概念之间有哪些区别和联系呢？</blockquote><p></p><p></p><p>杨威理： Web3和元宇宙没有必然的联系。之所以大家经常将它们相提并论，是因为元宇宙和Web3在核心技术层面出现了很多交集。但元宇宙更强调于虚拟现实的概念，主要是要让用户之间进行虚拟化的交互。Web3并不局限于这个方向，它就是基于区块链技术的去中心化网络。元宇宙会用到Web3当中非常重要的一些技术和基础设施，所以我们可以一定程度上将元宇宙看成是Web3的一种表现形式。</p><p></p><p>另一方面，很多巨头都在投注元宇宙领域，那么他们推出的这些元宇宙产品或者概念有多大程度的去中心化？这是一个非常值得思考的问题。如果他们还是在做非常中心化的产品，同Web3就会有非常大的差异。从这个角度上看，我们也很难将互联网的未来定义为元宇宙。这些企业希望在Web3、元宇宙领域走什么路线，也是要遵从它们自身的调研和决策的。很难说未来它们就一定会向这个方向全力发展。</p><p></p><p></p><blockquote>InfoQ：凯云实验室为什么决定要在这个方向做布局？你们公司围绕着这个战略做了哪些方面的动作？</blockquote><p></p><p></p><p>杨威理：凯云实验室在过去的很长一段时间都在存储和计算方面做研究。我们也看好、认可去中心化分布式存储和计算领域，相信它们是Web3的两大基石。因为我们也看好Web3的未来，因此我们对这个领域做了长期调研，最终确定了去中心化存储这个主战场。</p><p></p><p>在这个领域当中我们也发现，去中心化存储还有很长的路要走，因此我们就投入大量研发资源，以开源解决方案的形式提高存储和检索的扩展性，再结合去中心化数据库和去中心化计算为整个存储提供计算能力，期望为去中心化网络提供数据处理能力，让数据真正具有使用价值。</p><p></p><p>我们目前正在重点打造的就是一款具有帐本功能的Web3数据库，旨在为Web3提供存储和计算解决方案。从目前的发展来看，因为整个Web3生态还是自下而上的分层架构，所以我们应该先是夯实底层，再逐渐向应用层发展。有了完善的基础设施才能够提供完善的用户体验接口。</p><p></p><h2>争议和未来</h2><p></p><p></p><p></p><blockquote>InfoQ：关于Web3概念也有一些反对的声音，很多文章说它就是一个骗局。您是怎么看待当下存在的一些质疑声音的？</blockquote><p></p><p></p><p>杨威理： 首先这个概念非常火，同时因为Web3是基于我们现在认可的一些技术逐渐在完善成熟过程当中，因此是会有少数人利用技术、监管的漏洞进行所谓的割韭菜行为。当然我认为这些骗局、问题的出现本身也是对大众的教育。Web3生态肯定不是一个诈骗游戏，而这些骗局或者问题的出现体现出了Web3当中目前存在的一些问题。市场的反馈可以帮助Web3不断成熟、发展，这种所谓割韭菜的行为也会越来越少。</p><p></p><p>具体来说，从Web3的经济模型来看，这个生态系统的游戏规则还不完善，正好被这些非法人士利用这些漏洞进行一些割韭菜行为。就像我们早期在做软件的过程当中，IT行业也会出现很多致命的缺陷和漏洞。正是通过市场、用户的反馈让我们发现这些漏洞，从而推动软件行业技术领域不断发展，进而弥补这些漏洞来提供更好的产品，我相信Web3也会经历同样的过程。</p><p></p><p>最后，在Web3的发展过程中还有很多领域需要探索。现在之所以互联网的主流是中心化技术，也是因为技术本身不足以让这些平台成为去中心化的。既然它目前还是中心化的，它就还有我们可以去探索的内容。Web3的从业人员可以思考如何将它变成去中心化的架构。目前全球，包括国内的行业、高校都有很多组织在积极探索、研究和尝试Web3领域的技术，也有很多创新成果出现。</p><p></p>",
    "publish_time": "2023-01-11 15:01:16",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Flag Boot：基于范畴论的新一代极简开源微服务框架",
    "url": "https://www.infoq.cn/article/YhajomC93FKrgbEGb5fy",
    "summary": "<p>2022年11月，智源北京人工智能研究院开源了<a href=\"https://www.infoq.cn/video/YoR074jiv0cOkezLUCxf\">Flag Boot</a>\"。Flag Boot是一个基于Scala开发的轻量级的高并发微服务框架，为类型安全、服务治理等常见问题，给出了简洁且可扩展性强的解决方案。同时，它使用了基于范畴论的Cats/Cats_Effect等框架，针对抽象代数运算有天然支持。</p><p></p><p>本期直播，InfoQ《<a href=\"https://www.infoq.cn/video/YoR074jiv0cOkezLUCxf\">极客有约》</a>\"邀请到了清华大学交叉信息研究院助理教授袁洋和博士生杨景钦来给我们分享Flag Boot开源的二三事。</p><p></p><p>以下为对话全文，经编辑。</p><p></p><p></p><blockquote>InfoQ： 首先有请两位嘉宾老师做一下自我介绍。</blockquote><p></p><p></p><p>袁洋： 我在清华交叉信息研究院主要研究的方向是智能医疗，关注的主要是人工智能的可解释性，同时也在做人工智能的理论研究。</p><p></p><p>杨景钦： 我是清华大学交叉信息研究院博士二年级学生。现在研究的方向和袁老师一样。</p><p></p><p></p><blockquote>InfoQ： 本期直播的主题围绕Flag Boot项目来进行，请两位老师详细介绍一下Flag Boot是一个什么样的项目？</blockquote><p></p><p></p><p>杨景钦： Flag Boot是一个基于<a href=\"https://www.infoq.cn/article/V6C4slKg2hCsA6ofJsts\">Scala</a>\"开发的轻量级、高并发的微服务框架，为类型安全、服务治理等问题，给出了一些简单、可扩展性非常强的方案，并且它使用了基于范畴论的框架，如Cats/Cats Effect等，针对抽象代数运算有着天然的支持。</p><p></p><p>袁洋： 最初我们的研究方向和做Flag Boot这样的开源框架没有太大的关系。我到清华半年左右的时候，和杨景钦就开始着手来做智慧医疗项目，这是一个很大的项目，我们较长远的目标是做人工智能辅助诊断系统。之前也有很多不同的团队探索过人工智能辅助诊断系统，比较有名的是IBM的沃森医生，但并没有获得最后的成功，所以我们当时也在想怎么才能把这个项目做好。</p><p></p><p>“工欲善其事，必先利其器”，我们认为一定要把基础的工具搭好。如果要把辅助诊断系统做好，就需要把医疗就诊全流程中的各个环节都打通，并描述清楚。我们最终选择并学习了Scala语言，以Scala语言作为底层支撑，来更好地描述整个过程。因为Scala语言虽然在国内了解的朋友不是很多，但它相对于Java或者其他语言而言，对程序员理论有更好的支持，所以它非常适合搭建一些很大型的系统。其实从它名字上也可以看出来，Scala其实是Scalable的简称。</p><p></p><p>做了两年多之后，我们积累了相当多的经验。之前我们主要用的是Akka，在Scala社区也是非常流行的。但后来我们发现这里面有一些问题。主要是，我们在做的是辅助诊断系统，需要把医疗诊断的全流程以一种较偏数学、偏理论的方式刻画出来，这就是为什么我们后来接触到范畴论，因为范畴论是做这件事的一个很好的工具。但是我们发现Akka整个生态体系来做范畴论不是很方便。</p><p></p><p>我和杨景钦最后发现Cats/Cats Effect之类的比较适合做这件事。Cat是Category的缩写，其实是一个双关语，既代表猫也代表范畴论。所以我们就想把这两个包拿过来做底层支撑，之后又发现虽然这两个包很好，但是并没有一个很好的框架能够和包有比较好的无缝贴合，相当于有工具，但还没有使用工具的环境。所以我们就想为Cats/Cats Effect做一个比较好的环境，既可以给我们的团队用，也可以给Scala的爱好者用。这就是我们想做Flag Boot的原因。</p><p></p><p></p><blockquote>InfoQ： Flag Boot项目大概有多少人参与，2022年这个项目的侧重点在哪些方面？</blockquote><p></p><p></p><p>袁洋： 我们的项目最初是清华里面的一个科研项目，主要是我组里的学生在参与。去年9月份我们开始和智源合作，有一些全职的工程师参与到里面。现在我们整个团队在智源大约有十几个人，包括前后端工程师、产品经理等，主要做辅助诊断系统这方面的具体实践之类的。后端做Flag Boot这方面代码的，加上我的学生一共是5个人。</p><p></p><p></p><blockquote>InfoQ： Flag Boot项目在研发过程中，发生过什么有意思的小故事可以分享下？</blockquote><p></p><p></p><p>杨景钦： 我说一个个人的事情。我是以写C++出身的，很早之前打过一些算法竞赛，拿过一些奖，在刚开始接触微服务架构的时候，就不可避免地需要用到Java和Scala。但是最初因为各种各样的原因，我认为这两个语言和C++很相似，并没有觉得里边有什么很值得我去细细看的一些内容，等遇到不会的再去查，看一下怎么把基于C++的想法翻译成Scala或者Java的代码就可以了。</p><p></p><p>后来发生一件事情，我们在早期做测试时，在代码里边会有一些对type的变量，我们发现当对一些type的变量进行改动之后，整个代码编译出来的结果可能不会有任何变化，因为它编译里面的东西可能和type根本没有关系。但仅从运行情况来看，它最后出的错看上去非常普通，就好像是我的代码在什么地方写错了一样，调了非常久都完全不知道错在了哪里。最后查了很多才发现这种type其实在Java里面叫类型擦除，它在打完包之后类型就没有了，相当于代码没有任何问题，只是在编译的时候，中间进行了一些奇怪的优化，才导致了这样的结果。</p><p></p><p>通过这件事我才真正感觉Java、Scala这种语言，和C++有着本质的区别。所以后来就花了更多的精力去研究这两种语言，它们在类型上面到底做了什么样的事情，最后才对类型安全有了一个更深的了解，并且可以去做一些设计。</p><p></p><p>袁洋： 我之前是做机器学习理论算法设计的，也做过竞赛，回国之后我决定要做智能医疗，即使用几年时间，也要把一个比较大的、复杂的系统搞出来，但我之前并没有太多搞复杂系统的经验。</p><p></p><p>后来在读博士以及博士后期间，除了发论文，有一段时间是用Scala来做一些系统、软件，但真正开始搭系统是最近这三年时间，期间我也是不断去摸索。因为我以前不是做system的，所以更多的是从理论角度来想事情，比如要实现某个功能，我会把它看作一个函数，它的输入是什么，输出是什么，函数作用是什么。基于这个角度，我想到了需要先把整个系统要处理的各类数据的类型先定义清楚，然后再定义每个数据从a到b应该经历哪些。</p><p></p><p>这个过程很漫长，在这个过程中我慢慢意识到了函数式编程和程序语言理论的重要性，之后整个团队也开始研究程序语言理论。过程中我发现程序语言理论好像是基于范畴论的，其实我以前根本没学过范畴论，但是在做系统时发现必须要了解范畴论的内容，有些事情才可以往前推。</p><p></p><p>但在这个过程中不断出现一些问题，我在解决时发现有些问题应该用范畴论的思想去解决，有些问题应该用程序语言的思想去解决。反过来，范畴论的很多想法又可以帮助我更好地去理解人工智能理论里面的一些问题。</p><p></p><p>Flag Boot相当于是我们这两年探索的一个小成果，虽然它比较简单，但是对我们来说其实是件很不错的事情。而且在暑假的时候，我在清华给姚班的同学开了一门前后端系统设计的课程，杨景钦是我们的课程助教。在这个过程中我发现同学们接受起来很快，于是让同学们从0-1，用三个礼拜做了一个功能很完备的健康宝。</p><p></p><p></p><blockquote>InfoQ： Flag Boot是什么时候开源的？</blockquote><p></p><p></p><p>袁洋： 在智源的 Flag生态系统里面，它大概是2022年11月初开源的，但我们没有宣传，所以大家可能并不知道。我们做了一些测试，有很多人问我们是不是要对标<a href=\"https://www.infoq.cn/article/5VMP2p3hLyEKpYIILxLr\">Spring Boot</a>\"，答案是Spring Boot的生态做得非常好，而且做了很多年，有很多Java程序员的支持，所以我们肯定无法和那么大的生态去比较。但如果你是Scala的爱好者或者初学者，想要用Scala来做一些比较有趣的应用，可能比较适合用我们这个框架。或者想要做一个稍微大一点的项目，想选一个好的架构，我认为Scala比Java要精简、优美很多，而且可扩展性很强。</p><p></p><p></p><blockquote>InfoQ： Flag Boot的整体架构，以及迭代更新的情况如何？</blockquote><p></p><p></p><p>杨景钦： 现在它是一个很轻量级的代码，在非常少的代码函数下，整体架构要做的事也就比较简单，比如每一个服务向外暴露了一些接口，我们对接口有一个统一的控制，统一去收发。之后内部对于多个同时接入的请求，有一个异步控制器，相当于只有一个API进来，然后我们在内部把它处理掉，在处理的时候可能需要用到服务治理以及和数据库进行一些比较方便的连接等之类的其他模块。</p><p></p><p>目前的框架迭代有三次比较大的更新。第一次，我们最初用的是Akka做了最早的一个版本，然后在袁老师的强烈建议下，引入了范畴，这是一次整体的重构。后来因为我们已经引入了范畴，就可以拥抱更近一点的框架，然后我们把Akka从里边拿掉了，这是第二次。最后一次是对接口的管理，以及服务治理等这种模块，做了一次比较大的优化。</p><p></p><p>袁洋： 从架构上来说，我们是一个很简单的架构，整个框架并不大，代码行数大概3000多行，可以从头到尾看清楚所有的东西是怎么做的。因为Scala比较简单，比如实现同一个功能，用Java写需要的代码行数可能是Scala的三倍。</p><p></p><p>另外，我们微服务框架的不同之处在于，里面用了很多范畴的概念，其中有一个叫Monad。简单来讲Monad是个盒子，里面可以装各种各样的东西，可以把它看成类似于薛定谔装猫的盒子一样。如果没有Monad，很多时候会不受控制，比如一个Spring Boot框架，或者其他微服务框架，当一个请求进来时，就需要处理这个请求，然后又会接二连三触发更多请求，不能完全受控制。</p><p></p><p>我们是这样处理的，我们整个框架用到范畴论，也用了基于Cats Effect里面的一个叫做Monix.Task的包，所谓的Task就是一个盒子，来了一个请求之后，我先不处理请求，而是先把请求装到盒子里。比如想知道user的名字是什么，来了一个API请求，我不会去看数据库，而是先把它装到盒子里，然后再看如果要处理这个请求，下一步应该做什么。比如应该去和数据库沟通，或者应该进行一些简单的预算，暂时也先不去做这些事，而是再用另外一个盒子把要做的事记下来，只有当盒子全部定义清楚之后，再返回去开始运行。</p><p></p><p>这样做的好处在于，可以有更好的调度策略，所有的事情都在控制之下，不至于来了API之后手忙脚乱。得益于这些优化，从效率上来看，我们比Spring Boot快很多。</p><p></p><p></p><blockquote>InfoQ： Flag Boot针对类型安全、服务治理存在的问题，提出了简洁且可扩展的解决方案。您能详细讲讲，以往在类型安全、服务治理等方面存在哪些问题呢？</blockquote><p></p><p></p><p>杨景钦： 并不是说原来的模式有很大的问题，服务治理还好，只是原来可能在微服务中要做类型安全会比较麻烦。类型安全的作用是，在编译的时候发现绝大部分的潜藏问题，做得越好在编译的时候就能够发现更多的可能会出现的bug，并且能够提前优化掉在上线之后才发现的bug。</p><p></p><p>另外，也并不是说类型安全有多麻烦或者说做不了，只是它现在做的东西不是特别简洁。举例来说，对于一个API，在调用的时候，正常情况下它需要返回的是某一个特定类型的返回值。当某一个服务的API的返回类型，出于一些原因比如没有设计好或者其他原因，发生变化的话，我们希望能够去提醒其他所有的服务，对它的处理就应该有变化，比如你把字符串当成double去处理肯定是不对的。我们的框架就能够比较方便地去做到这一点。</p><p></p><p>总结来说，我们的Type Safe在做的事情是，当某一个服务比如它的 API接口有变化，其他所有使用的 API服务在编译的时候就会发现这是有问题的，类型会有变化，然后在编译的时候会针对一些很危险的操作给出警告。</p><p></p><p>袁洋： 杨景钦主要说的是从实现上面，它很多东西可以更简洁、更方便，但是Java也是一个强类型的语言，所以Java也可以做，只是可能稍微复杂、麻烦一点。我从另外一个角度来给大家分享一下我们框架的好处。</p><p></p><p>我很早就接触了Scala，大概是在博士二年级，我2014、2015年去推特实习的时候，推特全用Scala，当时我觉得Scala并没有什么用处，用C++和Java就足矣。在去年的暑假我在上前后端类型安全系统实践课时，我迫使同学们必须要用Scala，告诉大家类型安全很重要，做任何东西都必须用类型安全方式来做，让同学们做一个很复杂的类型出来。后来发现虽然他们整个应用做得非常漂亮，该有的功能都有，但确实他们很少用到我觉得比较好的一个复杂类型，他们认为地址不用string表示，用address来表示，就叫类型安全。</p><p></p><p>后来我进行了反思，当在进行一些相对比较简单的应用时，有可能不会对类型安全给自己带来的帮助有非常深的感触。因为我们在做的辅助诊断系统是一个很复杂，相对比较大的系统，这个时候就会感受到类型安全的重要性，它能够给整个系统提供很好的支撑。</p><p></p><p>另外一个是范畴论。范畴论描述了Mathematical Structures，是来刻画一些数学的Object彼此之间的关系的。比如一个人生病了，其实这里面包含很多信息，例如病因是什么，进行了哪些治疗，有哪些地方不舒服，先后关系是什么以及历史记录等等。现在我们去看医生，大部分医生是用电脑写病历，虽然是电子化了，但并不是形式化。就算是形式化，部分医院的电子系统往往也只是把这些条目并排放在一起，并没有把这些信息以很好的结构化的方式连在一起。如果没有连在一起，让机器学习去学就很难把它学得非常好，很多数据或者信息就会被浪费掉。</p><p></p><p>而我们提的框架现在大家不一定能够马上看出来，因为可能还没有这样的需求，但是至少我们团队有这个需求，对于一个非常复杂的东西，内在有很复杂的结构时，也许用范畴论，用Scala、Cats/Cats Effect效果会比较好。</p><p></p><p></p><blockquote>InfoQ： Flag Boot对于其他语言爱好者怎么容易地去使用？</blockquote><p></p><p></p><p>杨景钦： 我们现在只提供了Scala的API，所以目前这个阶段如果需要使用，确实需要具备Scala最基本的语法知识才可以。当然有一个好处是我们的门槛比较低，只要知道Scala最基本的知识，能把Scala用到和C++差不多的程度，就可以用Flag Boot框架去做很多事情。我们后面也计划提供Java的API之类的，只不过可能还需要一段时间。</p><p></p><p>袁洋： 我们去年暑期上课的同学是刚刚升大二的本科生，他们有一半之前没有搞过竞赛，有的都没有写过代码，我是第一个礼拜给他们上三堂课，讲一下这个东西要怎么做，然后杨景钦给一个样例，让他们三个人组队，用三个礼拜写几千行到一两万行的代码，也都可以做出来，所以门槛没有想象得那么高。</p><p></p><p>我想说的是大家需要为自己未来20年去想，编程每10年可能就变得不一样了。我有个专门做程序语言理论研究的朋友，他说未来应该是让更少的、更优秀的程序员，用更少的代价来实现更强大的功能。还有个朋友在Amazon工作，他看Amazon的源代码，发现10年前程序员用同样时间实现的功能和10年之后相比要少很多，应该是因为10年之后有了更多、更强大的工具。所以我认为大家还是要不断地学习更强大的工具，而Scala有作为这种强大的工具的潜力。</p><p></p><p></p><blockquote>InfoQ： 对于正在学习或者使用Scala，以及对Scala这门语言有强烈爱好的人，能够用Flag Boot去做哪些事情？</blockquote><p></p><p></p><p>袁洋： 能做的事情和Spring Boot差不多，可以拿它做任何事情。经常有人会问想用Scala做一个东西，应该怎么开始，但其实没有一个初始化的脚手架让大家来开始。</p><p></p><p>大家基本上只能够看Scala的Tutorial做一个“Hello World”，再复杂的比如做一个网页的服务器，就会觉得很困难。之前有人用 Play Framework，但我们觉得它没有我们的工具精简和高效。杨景钦用了两个小时做了一个很高效的、高并发的健康宝查询功能之类的应用。</p><p></p><p></p><blockquote>InfoQ： Flag Boot 是一个轻量级的框架，代码量比较少，而且代码简洁，少有晦涩的代码，隐式代码等，要做一款代码简洁的应用并不容易，您有什么经验可以分享下吗？</blockquote><p></p><p></p><p>杨景钦： 我个人觉得最关键的是技术选型。一方面，如果技术选型选择好，开始写代码的时候就会非常舒服，很多事情框架会去做，自然而然写的代码就短了。比如选择了特别好的框架，所有东西就可以用框架里面的包，可能一行就可以写完一个功能。另一方面，如果最初技术选型没有选好，后面就会容易进行很多的重构，如果没有全身心从头到尾进行重构，会发现到中间时代码变得越来越多。重构一个框架其实是一个先变多再变少的过程，但是如果前面的坑太大，大家有可能会在变多的过程中走不出去。</p><p></p><p>另外，写代码的时候要多想，“Think twice，code once”。以前参加算法竞赛，比如一场考试5个小时，可能有3.5个小时在想，只有1个小时左右是在写代码，想清楚之后，代码的量就不会很大。当然也分情况，如果是以代码行数作为发工资的标准或者KPI，可能多凑一点行数也是好的。还有一点，即使刚开始很痛苦，也要保持一个重构的习惯，其实只要经常重构，代码会越来越好看。</p><p></p><p>袁洋： 杨景钦说得很有道理，简单来说就是“谋定而后动”。先想清楚到底要实现什么功能，这个功能有的时候不要从面向过程的角度去想，第一步要做什么，第二步要做什么，第三步要做什么，而是要把它想象成是一个什么到什么的映射，什么到什么的函数。</p><p></p><p>这其实都在类型系统里面，如果所有东西都没有类型是件很痛苦的事情。如果有类型系统，会发现比如把大象装进冰箱分三步，第一步打开冰箱，第二步把大象塞进去，第三步关上冰箱就真的很简单。但前提是要把什么是大象，什么是冰箱，什么是放进这些基本操作搞清楚，搞清楚之后代码自然而然就会非常清晰、简洁。</p><p></p><p>这其实是一个范畴的思想，范畴论是一个很优美的学科，它是数学里面一个虽小但是很核心的分支。如果把代数、几何、代数拓扑、分析等等各种学科，用范畴的语言来表达，会发现以前很复杂的、可能需要两三页的证明，在范畴里面可能就两三句话，因为你把很多东西都抽象掉了，只保留了它的结构。还会发现这两三句话不仅可以证明原来很复杂的一个定理，还可以同时证明很多定理。这件事情映射到程序员里面，就相当于一个很小的、只有三行的函数，可以同时来做很多不同的事情，做很好的代码复用。但前提是需要不停地重构，不断地锻炼，去想而不是去写。</p><p></p><p></p><blockquote>InfoQ： 从原理来看，为什么Flag Boot会更快？</blockquote><p></p><p></p><p>袁洋： 我举个例子，比如去火车站营业厅买票，以往是有10个窗口相当于10个线程，如果突然涌进来1000个人，整个厅里全是人，大家会不停地拥挤，办事速度会很慢。而用Monad会这么做，同样是1个大厅里有10个窗口，不同的是我会在大厅旁边再准备一个大厅供大家排队；然后有一个专门的负责运行管理的人来负责叫号，他会决定每个人该去哪个窗口。</p><p></p><p>但是我想说Monad比这个重要很多，它作为一个盒子的思想不仅可以用在线程调度上面，还可以用在很多别的地方。为了更好地理解Monad这个概念，我觉得最好的一个方法就是看范畴论或者程序语言理论里面的定义，顺着定义去理解可能会更好。</p><p></p><p>杨景钦： 对于怎么在线程上面进行调度，我用另外一个视角来看待这个问题。因为我们现在拿很多盒子去封，其实盒子不一定只是一个字条，字条上面还会有一些批注。盒子会有不同的类型，比如同一段代码，有的盒子上面写的是一个读操作，有的是一个写操作。比如分布式数据库的一些优化里，我们需要把读和写分开考虑，因为读和写对于资源的占用过程不一样。同理，我们原来的技术里边，把一段代码去异步地做，我们是在它外面套一个thread，然后直接喊它到一个别的地方去run一下，它就在异步上面去做，至于它怎么做并没有去管。</p><p></p><p>现在我们是对它做了范畴论的包装，然后在Cats Effect的框架里，在包装的过程当中会自动给这些盒子里的一些代码段，打上读、写或者其他等等一些标签，它自己内部在用 Fiber的概念对线程进行调度时，会参考这些标签上面的内容，并且以此来优化它的调度策略。当然具体的实践是Cats Effect的框架写的，我们只是在它外面又做了一层封装。</p><p></p><p>袁洋： 我们只是个搬运工或者粘贴工，把很多包以一个比较好的方式粘起来，让它比较好用，适合初学者。</p><p></p><p></p><blockquote>InfoQ： 在可扩展性方面，Flag Boot表现如何？</blockquote><p></p><p></p><p></p><blockquote>杨景钦： 其实严格上来说，我们并没有对用户使用的机器技术做任何限制，从理论上来说，几乎所有其他框架和Flag Boot都是兼容的。</blockquote><p></p><p></p><p>举一个对于用户使用的技术有比较强烈限制的例子，比如Akka公司最近推出一个基于Scala写的比较小众的微服务框架叫Lagom，从可扩展性上面来看，它基本上把用户使用的所有技术站都限制在了Akka支持的一些框架上，如果他们不支持这个框架就用不了。因为他们所有的优化都是从Actor这个模型出发的，要想用这个框架，首先要跟Actor兼容。然而众所周知，他们的Actor和Java的thread等是非常冲突的,只能是一个支持Actor模型的框架才能够在他们的框架里去用。</p><p></p><p>我们不存在这个问题，因为我们做的最本质的事情是对逻辑进行了一个范畴论的封装，并且交由一些框架去进行异步处理，我们并没有对要包装的代码有多大的限制。所以我们在Flag Boot里基本上可以用所有的其他框架，甚至可以用Spring Boot。</p><p></p><p>另一方面，我们虽然用的是Scala，这个语言听上去很怪异，可能它的生态环境没有很好，但是Scala兼容了Java的所有框架，Java所有框架都可以在Scala里边用，所以可扩展性还是挺强的。但是我们现在的问题是只提供了Scala的API，最后的开发是基于Scala开发的，等我们也提供了Java的API之后，这个事情就能变得更好。</p><p></p><p>袁洋： 我们的代码是比较显式的，所有实现的东西我们都是显式实现，并没有用宏，也没有像Spring Boot用注解。有相关计算机背景的同学，如果知道基本的一些程序开发方式，其实就可以拿过来直接用，而且能看明白我们到底在做什么。</p><p></p><p></p><blockquote>InfoQ： 针对人工智能辅助诊断系统，Flag Boot框架的应用效果如何？</blockquote><p></p><p></p><p>袁洋： 我们用的还行，效率和并发挺高，但是我们又没有对比。杨景钦之前做了一些简单的、高并发的实验，可以介绍一下。</p><p></p><p>杨景钦： 那个实验是我们搭一个服务，然后去疯狂地请求，做 HTTP的性能测试。我们做了几个测试，一个是模拟所有的请求都是非常快的，基本上请求完之后立刻返回，因为这个逻辑写起来很简单，在不同的框架上面没有任何区别。和Spring Boot比，我们比较快，大概有2-3倍吞吐量的优势，没有快很多。</p><p></p><p>另一个是我们去试了一下比较大的延迟的测试，比如每个请求过来，我们需要先让它在内部运行100毫秒，再返回。这种情况下发现，我们的框架在比较大的并发压力下，大概有5倍还要往上的一个吞吐量。</p><p></p><p>袁洋： 它主要框架是因为它是原生异步，不会有饥饿的情况，不会有一个东西一直卡着，然后调度出现问题，大家调度起来会非常方便。</p><p></p><p>有线上观众说这本质是一个智能的任务调度系统，我认为不是。今天主要在讲调度的事情，是因为可能观众比较感兴趣，问得比较多。调度其实只是这个框架的一个比较好的特点，因为它用了范畴论，用了Monad调度起来比较方便，但核心是，它是一个类型安全的支持复杂类型的系统。</p><p></p><p>现在看可能还不是很清晰，我个人认为再过10年我们来看这个事情，会觉得对一个大型的软件系统来说，一个强有力的类型安全的支持是非常重要的。很强的类型系统做很多事都很方便，可能看具体的代码会发现确实很方便，但是可能在交流的时候很难说清楚。</p><p></p><p></p><blockquote>InfoQ： 与Spring Boot框架相比，Flag Boot&nbsp;主要的不同是更快吗，还有什么其他优势？</blockquote><p></p><p></p><p>袁洋： 我举个不太合适的极端例子，大家都知道汇编，原则上所有东西都可以拿汇编做，但汇编和一个新的框架比如Spring Boot的区别是什么？可能关注更多的不是更快，也不是Spring Boot或者Flag Boot有什么功能是汇编实现不了，也不是汇编写起来更费劲，代码会更长等等，其实关注的是这个更加intuitive，有更强的可扩展性，它在这上面可以做更多很强大的事情，速度不一定是最关键的事情。我们在编程的时候，一定要先做对再做快，如果做得不对，做再快也无济于事。</p><p></p><p>杨景钦： 我们与Spring Boot相比，主要的是我们有更简洁的Type Safe，以及代码的可读性更强一点。对于Spring Boot比较熟悉的人来说，代码确实会好读一点，但是对于刚用不久的人来说，还是比较难以看懂，因为Spring Boot是利用注解去进行编程的，它里面有很多可能需要去查很多资料才能够弄懂的注解。而我们没有加注解，也基本上没有用到任何的红。我们做得所有处理，都在代码里面，大家可以直接看到。只要能看懂Scala，就能看懂其他人到底在做什么。除了Type Safe以及代码的可读性强之外，还有一些性能上的小优势，以及我们框架是原生异步的。</p><p></p><p></p><blockquote>InfoQ： Flag Boot这个项目在明年有什么规划？</blockquote><p></p><p></p><p>杨景钦： 第一，我们现在是基于Scala 2写的，Scala 2.13或者2.12，接下来要做的事情是把我们的框架向上迁移到Scala 3。第二，是Java的API。第三，是在分布式计算里边的一些支持，相当于是其他的功能。</p><p></p><p>袁洋： 我还希望这个框架在我们那个项目里面用的时候看看有什么反馈，有什么地方可以再改进。</p><p></p><p></p><blockquote>InfoQ： 请老师分享一下在马上过去的这一年里，微服务框架的发展情况如何？</blockquote><p></p><p></p><p>杨景钦： 我觉得微服务框架现在是一个百花齐放的状态，其实有很多的地方都开始做微服务框架，可能背后的原因有很多。另外，现在有很多搞AI的人，他们做出来一点成果，比如做出来可以让大家玩的东西，像之前的 AI作画者，去运用一些简单的类似于Flag Boot或者Spring Boot等等这种框架，快速去构建一个Web服务，然后交由用户去运行。这是一个背景，然后在这个基础上，我在2022年看到很多的框架，比如Spring Boot、Play，还有一些别的厂商自己在用的框架等等，大家做得东西还是挺多的。</p><p></p><p>大家关注的点以及要处理的问题也都有不一样的地方。比如Spring Boot考虑要加更多新功能，让大家用我们这一个框架可以做到所有的事情。还有一些框架可能想的是让用户在用这个框架时，能够养成一套非常良好的代码审美，更偏向于让最后写出来的代码非常好看。还有的可能希望要干掉微服务里边的分布式的一致性问题，要让多个服务去达成共识等等。整体来说，大家都在朝着各自的方向去做，处在一个百花齐放的状态。</p><p></p><p>袁洋： 我们团队在做辅助诊断系统的时候，除了做框架，还做了很多其他的技术选型。我在2012年读博士的时候，听说未来10年程序语言理论会发展得最迅速，当时我并不了解程序语言理论。今年这一年到底怎么样，可能我没有那么清楚，但是现在回过头来看这10年涌现了很多新的程序语言，虽然有的还没有来得及成为主流，但是新的程序语言基本上都是强类型的，支持很多基本的程序语言理论里面需要支持的东西。</p><p></p><p>所以我觉得一个总的趋势是语言新的框架，它们可能会有自己的各种特点，但是一定不变的是，它们越来越需要和程序语言理论聚合，因为根据过去十年或者十几年的经验，证明了程序语言理论是对的，是符合软件开发需要的经验。</p><p></p><p>直播嘉宾介绍：</p><p></p><p>袁洋，清华大学交叉信息研究院助理教授</p><p></p><p>杨景钦 清华大学交叉信息研究院博士  NOI CCPC ACM/ICPC金牌</p>",
    "publish_time": "2023-01-11 15:14:14",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "透视华为云云原生数据库的前世今生及未来演进，能给行业带来哪些启发？",
    "url": "https://www.infoq.cn/article/dJl3TSVe38mQARXruD0U",
    "summary": "<p>自云计算出现后，风云变幻十余载，硬件、软件行业都经历了重构变革所带来的机遇与激荡。企业 IT 基础设施逐渐云化，应用转向云端，系统架构也经历了从单体到微服务再到 Serverless 架构的演进。这些变化一方面为用户提供了更优秀的特性，另一方面也对云计算的组件提出更高要求。大势的裹挟之下，数据库作为云计算关键技术和最基础的服务之一，同样需要不断进化以适应日新月异的场景需求。自此，通过云服务形式提供数据库功能的云数据库应运而生，但这还仅仅是数据库变革的开端。</p><p></p><h2>云数据库进一步演进：云原生数据库诞生</h2><p></p><p></p><p>相比传统数据库，云数据库确有一定的进步，但是其本质上并非针对云场景或云环境来设计和构建的，只是用到了云的资源，因此存在一些局限，比如资源利用率低、维护成本高、可用性低等，从而限制了业务发展。随着云计算深入发展，云计算步入云原生时代。同时，越来越多企业加速数字化转型，业务对数据的诉求不断提升，倒逼着云数据库进一步演进，更加适应云特性的云原生数据库就此诞生。云原生数据库的目标主要是充分利用云基础设施的资源弹性调度实现数据库资源的极致弹性伸缩、数据就近访问、多模兼容，让用户专注在业务创新，而不用在数据库管理和运维层面耗费资源。云原生数据库的这些优势，受到越来越多企业的欢迎，而且热度不断攀升，已经成为数据库行业的重要发展趋势之一。</p><p></p><h2>云原生数据库缘何兴起</h2><p></p><p></p><p>为什么云原生数据库这么火？在华为云数据库软件总工程师彭立勋看来，第一，传统数据库的使用门槛相对较高。以前，数据库主要是本地部署（On-Premises），从采购机器、规划容量到部署软件，整个过程非常复杂。他说：“有了云计算，尤其是云原生数据库出现后，正好遇上企业数字化转型，对数据库的需求增加，而云原生数据库可以开箱即用，不用像以前那样做大量规划、采购和部署等。”</p><p></p><p>第二，云原生数据库能满足企业对数据库弹性伸缩的需求。而传统的做法是靠 DBA 规划，这很容易出现问题。对此，彭立勋深有感触，他以前做 DBA 时，要对容量做很精细的规划。如果规划没做对的话，要么浪费资源，要么性能不足，然后还要重新调整。</p><p></p><p>第三，云原生数据库可以从技术上解决传统数据库面临的资源、性能和扩展性受限等问题。传统上，这些问题要靠 DBA 不断提升自己的技术能力去解决。他表示，云原生数据库出现后，云服务商提供的相应产品本身就具备这样的能力，因此对企业来说，数据库的使用门槛大大降低。所以，在进行数字化转型时，很多企业倾向于选择云原生数据库。从传统数据库到云原生数据库，这是数据库自身的演进。更重要的是，数据库演进的背后折射出企业业务的变化。</p><p></p><p>据彭立勋介绍，首先，从以资源为中心到以应用为中心。从企业视角出发，它一定有一些自身需求，比如要求资源能弹性扩展。以前，缺乏这种技术时，企业主要是以资源为中心，有多少资源配多少数据库，然后再根据资源的表现和负载情况进行调整。云原生数据库出现后，从以资源为中心转变成以应用为中心，通过技术手段让用户使用更简单。企业只管用数据库，不用管背后到底需要多少资源。如果资源不够，系统自动帮你扩展，或者用户手动进行弹性扩展，速度更快、效率更高。并且，企业无需像以前那样预先规划资源，直接自动或手动调整资源即可。</p><p></p><p>其次，从以地域为中心到以流量为中心。以前，数据在哪，应用就要布置在哪，或者说应用在哪，数据也要同步到哪，这是以地域为中心。为了给用户提供最快访问，企业往往需要在各地设置数据中心，然后通过各种方法把数据同步到用户就近访问的地方。基于云原生数据库，企业只需要关注流量从哪里来，用户从哪里访问，数据库会将数据分布到不同的 Region，应用就近、随时随地访问数据。彭立勋表示：“应用在哪，数据库帮你把数据往哪同步。对用户来说，全球是一张网。”</p><p></p><p>最后，从以负载为中心到以数据为中心。传统上，不同的负载要放在不同的数据库里，比如报表、分析类的会放在一种数据库里，文档或键值类的放在另一种数据库。云原生数据库出现后，用户不同的负载由云服务商在后端适配不同的数据库实例，或者帮用户做同步，将数据放到适合做相应查询的数据库里。不管用户使用什么类型的负载和数据模型，都由云服务商帮用户判断。</p><p></p><p>“比如偏 OLAP 的，我们把它转到适合 OLAP 的数据查询的节点上。简单说，华为云云原生数据库改变了用户习惯，让用户对数据库的使用变得没有那么复杂。”他补充道。</p><p></p><p>此外是商业模式的改变。传统数据库是基于授权来获取商业收入，企业在使用数据库前要先购买 license。如果预估不准，企业采购的 license 就会存在浪费或不足的情况。而云原生数据库是以云服务的方式提供给用户，按需使用，用多少资源、使用多长时间，相应的为使用资源付费。</p><p></p><h2>云原生数据库命中企业痛点，最大挑战不在技术</h2><p></p><p></p><p>基于长期的行业观察，彭立勋总结出云原生数据库的价值。首先，云原生数据库开箱即用，使用简单，用户只要购买云原生数据库的服务，就可以直接使用。同时，按需使用，需要多少资源，用户就购买多少资源，一旦资源不够，还能快速扩容。这大大降低了企业使用数据库的门槛，减少企业在数据库部署等基础运维和管理上的人力投入。</p><p></p><p>其次，对数据库人员来说，不用关注最底层的运维问题，可以更靠近业务，关注数据处理等更有价值的问题。如此，不仅可以提升数据库人员的能力，而且能给企业带来更大的价值。</p><p></p><p>然后，云服务商将整个技术打包成服务，提供给所有用户，这让一些中小企业能像大企业一样使用相同的云原生数据库服务，享受技术带来的红利。此外，云原生数据库可以让企业应用系统更高效快捷地处理数据，充分发挥数据的价值。彭立勋解释道，“以前，中小企业可能没有那么多资源部署数据挖掘和分析。而现在采用 华为云云原生数据库后，它提供 HTAP 混合负载的能力。这样，中小企业也可以做一些轻量级的数据分析，挖掘数据中的价值，让企业更专注在业务创新上。”</p><p></p><p>目前，虽然云原生数据库很火，但是企业在采用过程中依然存在挑战。在彭立勋看来，很多企业从传统的商业数据库向云原生数据库迁移时，最大的挑战倒不是技术本身，而是很多的技术人员还是从传统数据库的角度出发，利用传统数据库的思维和积累的经验，来使用云原生数据库。</p><p></p><p>他强调，云原生数据库并非简单地把传统数据库搬到云上，它对数据库进行了全面重构，充分利用了云的能力，带来一些新优势。所以，如果还是按照传统数据库的使用习惯和思维模式，将无法发挥云原生数据库的优势，甚至可能会增加其使用成本。当然，对企业而言，是否采用云原生数据库，它需要根据具体业务进行判断。</p><p></p><p>从业务角度看，云原生数据库更适合偏互联网型的业务，诸如电商、社交、文娱、游戏、车联网等。偏互联网型的业务非常敏感，变化快，业务体量的弹性非常大。以游戏为例，一款游戏在突然火爆后，游戏公司需要在短时间内弹性扩展整个系统处理能力。而一款游戏进入收缩期后，需要快速收缩资源、节省成本。这类变化非常快的业务会对数据库的性能、弹性伸缩、快速部署等提出很高的要求，这恰恰是云原生数据库的优势所在。无论是什么样的企业，只要是偏这种类型的业务，都非常适合使用云原生数据库。</p><p></p><h2>云原生数据库未来将如何发展</h2><p></p><p></p><p>从星星之火到燎原之势，在数据库领域，云原生数据库蔚然成风，风起云涌之后的云原生数据库又将怎样演进、驶向何方？</p><p></p><p>在华为云看来，“以客户为中心，解决客户最关注的问题”是接下来云原生数据库发展演进的关键。基于此，华为云提出云原生数据库的三大发展方向：Serverless、Regionless 和 Modeless，这也成为 华为云云原生数据库 的发展指南。</p><p></p><p>彭立勋说：“客户最关注的几个问题，一是资源调度，二是数据访问，三是使用体验。现在，越来越多的客户希望聚焦业务，聚焦于挖掘数据的价值，而非聚焦做一个具体的技术，因为对大部分有这种业务的企业来说，它并非一家做 IT 技术的企业，它关注的是自己所在领域的业务。所以，针对这几个方面，我们提出 Serverless、Regionless 和 Modeless 三大发展方向。”</p><p></p><p>具体说来，Serverless 要解决资源调度问题，实现资源的极致弹性。在遭遇故障、规格变更时，整个资源弹性调度速度可以从分钟级缩短到秒级，这样对用户来说，真正的无感知；Regionless 是解决用户的数据访问，数据库全域可用，业务可以在任意地方进行接入和访问，同时带来跨地域的高可用，用户只需关注业务的数据流动而不用担心业务的跨地域部署和访问；Modeless 要解决的是使用体验，一个统一入口能智能地处理各种类型的负载，不管是交易型、分析型、 NoSQL模型、 MySQL 模型，我们以统一入口，提供给用户，提升用户的易用性和效率。</p><p></p><p>当然，Serverless、Regionless 和 Modeless 的落地应用还需要更具体的技术支撑。Serverless 方向，华为云云原生数据库在三个能力上重点投入，分别是 ALT、AST、ATC。首先是通过 ALT 应用无损透明倒换框架（Application Lossless and Transparent）实现应用层对底层调度倒换的无感知，当用户进行主备切换、小版本升级或者规格变更时，系统可以打包用户的会话上下文状态，在达到安全的事务边界后，确保会话上下文状态被完整重放至目标节点并与原会话一一关联保证业务持续性，不受各种操作的影响。</p><p></p><p>其次是通过 AST 应用弹性透明调度框架（Application Scaling Transparent）满足根据负载智能调度实例的需求，AST 融合了一些 AI 的能力，能够根据客户负载情况生成模型预测，从而以更精确的方式，提前扩缩资源。</p><p></p><p>最后是通过 ATC 应用透明集群（Application Transparent Cluster）实现读写能力的横向透明扩展。</p><p></p><p>Regionless 方向，华为云云原生数据库会重点聚焦于全域分层式引擎、全域数据总线（Global Dataflow Bus ）和全域一致性集群三个方面。彭立勋认为， Regionless 首先要实现的便是低成本跨越存储，不同的数据中心的存储成本是不一样的，从成本角度考虑，最合理的方式就是将客户不常用的或者对时间不敏感的资源，放到一些比较低成本的地域， 华为云云原生数据库的全域分层式引擎就是为了实现这个诉求；同时，要为所有的数据提供就近访问、跨域访问的数据分布，还需要有一个全域的数据总线（Global Dataflow Bus），它能让用户在不同的 Region 之间按需复制数据，接下来还将根据数据的访问频次更加智能地判断、精细化调度；此外，面向数据全球化的场景，华为云云原生数据库也在投入全域一致性集群方面的研发，利用类似全球转发的技术，去实现用户不管从全球哪里接入，所看到的数据都是一致的。</p><p></p><p>彭立勋称：“最终我们要达到的目的是通过 Regionless 实现全球数据多活、故障自动再倒换、本地数据就近访问、全域数据分层的低成本存储。”</p><p></p><p>Modeless 方向，一方面华为云云原生数据库充分利用软硬件结合的优势，去高效处理不同类型的查询，比如数据并行查询 NDPQ 技术；另一方面推出了 HTAP 混合负载查询能力，它能够为用户同时提供一个一致性的行存和列存，给用户提供两种数据模型，通过优化器的智能调度，就能判断用户到底是适合哪一种数据模型，然后再从相应的数据引擎中把数据抽出来，实现快速访问；除此之外，针对多种模型混合的业务，华为云云原生数据库正在规划多模一体化的模型处理与转换总线，最终实现一个接口满足所有模型。</p><p></p><h2>写在最后</h2><p></p><p></p><p>毫无疑问，云原生数据库逐渐成为数据库行业的“宠儿”。它的流行代表着云原生发展的深化，更反映出数字化转型背景下，企业对数据库的诉求和态度。技术的巨轮滚滚向前，条条大路的尽头，终归是用户的需求，核心都是帮助用户优先解决业务问题，从而走上业务发展的快车道。作为国内云原生数据库的代表之一，华为云云原生数据库的实践和探索正是基于华为云多年来对用户需求洞察的结果而展开的，如何真正做到以客户为中心，解决客户最关注的问题，是华为云数据库求索的方向，也是值得全行业去思考的话题，由此，将可能再一次迸发出改变世界的力量。</p>",
    "publish_time": "2023-01-11 15:21:25",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "服务网格 2022 ：Gateway API是最大惊喜，eBPF不会改变游戏规则",
    "url": "https://www.infoq.cn/article/WpWf9jqsVoM1wVZV9Jfw",
    "summary": "<p></p><p>本文最初发布于Linkerd官方博客。</p><p>&nbsp;</p><p>今年对于Linkerd是个好年景。尽管软件行业的大部分都在经济衰退中苦苦挣扎，但Linkerd的应用却一直在增长。事实上，日志指标显示，运行Linkerd的稳定Kubernetes集群数量在2022年翻了一番。Linkerd可能是唯一一个从CNCF毕业的服务网格，但它肯定不会因为毕业而放缓发展的脚步！</p><p>&nbsp;</p><p>这种增长从何而来？为什么是现在？基于2022年与新采用者的交流，我们认为情况是这样的：由于极端的炒作，再加上炒作最厉害的项目相对并不成熟且比较复杂，服务网格在早期的名声并不好。早期的采用者决定等到一切尘埃落定时再说。现在，他们回来了，他们看到了第一次的事儿，正渴望着有一种不会让他们背负众所周知的操作复杂性的选择。</p><p>&nbsp;</p><p>自然地，他们转向了Linkerd，因为简单，它成了服务网格领域一个独特的存在。Linkerd的主要优势在于它的数据平面。Linkerd是唯一一个避开了Envoy的服务网格，它把重点放在了专用的边车（sidecar）“微代理”上。在2018年，这是一个有争议的决定；在2022年，事实证明这种方法可以带来巨大的回报。当其他项目花费时间为其数据平面的复杂性和资源消耗构建变通方案时，Linkerd却专注于提供强大的功能，如<a href=\"https://linkerd.io/2022/03/09/announcing-automated-multi-cluster-failover-for-kubernetes/\">多集群故障转移</a>\"和<a href=\"https://buoyant.io/blog/announcing-linkerd-2-12\">基于Gateway API的完整L7授权策略</a>\"。</p><p>&nbsp;</p><p>但2022年，也并非完全像我们想象的那样。这一年里，即使是我们这些“头发花白”的老兵也得到了一些教训，同时也得到了一些真正的惊喜。以下是2022年让我们感到惊喜的几件事。</p><p></p><h2>惊喜1：Kubernetes的Gateway API非常适合服务网格</h2><p></p><p></p><p>到目前为止，Gateway API是我们2022年最大的惊喜，实际上，它还让我们中途更改了计划。年中，当时我们正在最终确定Linkerd的L7授权功，Gateway API在Kubernetes进入了Beta测试。当我们更深入地研究这个项目时，我们意识到了几件事：</p><p></p><p>它已经解决了我们正在Linkerd 2.12中处理的一个主要问题：如何以一种全面、可组合、kubernetes式的方式描述一类HTTP流量（例如，“所有以/foo/开头的东西”或“所有有这个报文头的东西”）。虽然已经计划在Linkerd中添加CRD，但我们并不情愿，而Gateway API资源已经是Kubernetes的一部分。它的设计很好。真的很好。虽然它最初是为处理Ingress配置而设计的，但核心原语足够灵活，而且可组合，因此，它实际上也适用于服务网格用例。</p><p>&nbsp;</p><p>因此，我们放弃了最初的计划，<a href=\"https://buoyant.io/blog/linkerd-and-the-gateway-api\">转而采用Gateway API作为Linkerd授权策略的核心配置机制</a>\"。尽管这会使2.12版本的发布推迟几个月，但我们知道，这是在为Linkerd的采用者做正确的事。</p><p>&nbsp;</p><p>这个决定已经有了回报。在即将发布的2.13版本中，我们将利用Gateway API资源类型来实现诸如基于头的路由和可配置的断路等功能。Linkerd还参与了<a href=\"https://gateway-api.sigs.k8s.io/contributing/gamma/\">GAMMA计划</a>\"，这是Gateway API中的一个项目，目的是更好地追踪服务网格用例。</p><p>&nbsp;</p><p>延伸阅读：<a href=\"https://buoyant.io/blog/linkerd-and-the-gateway-api\">Linkerd和Gateway API</a>\"。</p><p>&nbsp;</p><p></p><h2>惊喜2：eBPF是一项优化，而不是游戏规则改变者</h2><p></p><p></p><p>当围绕服务网格eBPF的讨论在2022年年初达到顶峰时，我们决定进行更深入的研究。我们发现，那并没有我们希望的那么引人注目。虽然eBPF可以简化一些基本的服务网格任务，如转发原始TCP连接，但如果没有用户空间组件，它根本就无法处理HTTP/2、mTLS或其他L7任务，这意味着它无法带来根本性的改变——即使使用eBPF，服务网格在集群上某个地方仍然会需要L7代理。</p><p>&nbsp;</p><p>尤其是被大肆吹捧的“无边车eBPF服务网格”模型，<a href=\"https://buoyant.io/blog/ebpf-sidecars-and-the-future-of-the-service-mesh\">感觉在可操作性和安全性方面是重大的倒退</a>\"。将那种逻辑移到针对每个主机的Envoy代理中，将网络问题和节点上所有东西的TLS密钥资料混合在一起，这彻底违背了我们将事物容器化的初衷。eBPF不是每个主机都需要的方式，营销资料中却将两者混为一谈，我们对此感到失望。</p><p>&nbsp;</p><p>未来，我们确实计划研究将eBPF作为一种简化Linkerd L4特性集的方法，不过，将关键代码转移到内核中的前景还是让我们感到担忧，因为在内核中调试、观察和推理都非常困难。(更不用说<a href=\"https://pentera.io/blog/the-good-bad-and-compromisable-aspects-of-linux-ebpf/\">eBPF引入的新的令人兴奋的攻击向量了</a>\"。)</p><p>&nbsp;</p><p>总的来说，我们对eBPF的调查并没有让我们真正相信eBPF。但是与以往任何时候相比，我们都更相信边车仍然是服务网格的最佳模型，无论是出于操作还是安全考虑。</p><p>&nbsp;</p><p>延伸阅读：<a href=\"https://buoyant.io/blog/ebpf-sidecars-and-the-future-of-the-service-mesh\">eBPF、边车和服务网格的未来</a>\"。</p><p>&nbsp;</p><p></p><h2>惊喜3：Ambient Mesh</h2><p></p><p></p><p>很快，Istio的无边车“Ambient Mesh”模式加入了无边车eBPF服务网格，该模式组合使用每主机和每服务代理。深入研究这种方法是我们的又一个学习经历。我们很高兴地看到，它的安全性更好，至少在这里是这样：例如，不同身份的TLS密钥资料在单独的进程中维护。</p><p>&nbsp;</p><p>然而，取消边车的代价非常大：需要大量的新机器，其结果有<a href=\"https://github.com/istio/istio/tree/experimental-ambient#limitations\">很大的局限性</a>\"，而且对性能有重大的影响。</p><p>&nbsp;</p><p>总的来说，我们得出的结论是，它在生命周期管理和资源消耗方面的改进对Linkerd的用例并没有助益。我们的感觉是，Ambient Mesh比其他任何东西都更能解决大规模运行Envoy的问题。</p><p>&nbsp;</p><p></p><h2>意料之中的事1：容器排序仍然是Kubernetes的弱点</h2><p></p><p></p><p>除了惊喜，2022年，我们还看到了一些意料之中的情况。与前几年一样，Linkerd的采用者继续与长期困扰Kubernetes的问题——缺少对容器排序的控制——做斗争。这体现在多个方面：</p><p></p><p>需要访问网络的Sidecar容器需要在linkd-init容器之后运行；终止的作业需要有一种方式可以向其代理组件发出终止信号；重新启动或添加到现有集群的节点需要一种方法来暂停Linkerd网络初始化，直到CNI层初始化完成；等等。</p><p>&nbsp;</p><p>在特定的情况下，这些问题都是可以解决的。但对于服务网格采用者来说，这类问题仍然是一个麻烦，并且严重地违反了我们的原则，即服务网格应该对应用程序透明。然而，随着臭名昭著的<a href=\"https://github.com/kubernetes/enhancements/issues/753\">边车KEP</a>\"走上了这条愚蠢的道路，我们可能还要忍受更长的时间。</p><p>&nbsp;</p><p>虽然，关于另一个KEP的谣言甚嚣尘上……</p><p></p><p></p><blockquote>就是这样，但经过多次讨论，我认为我们现在对如何做一种每个人都可以接受的形式有了很好的了解:)——蒂姆·霍金（thockin.yaml）（@thockin）<a href=\"https://twitter.com/thockin/status/1591198130049257473?ref_src=twsrc%5Etfw\">2022年11月11日</a>\"</blockquote><p></p><p>&nbsp;</p><p>延伸阅读：<a href=\"https://linkerd.io/2022/12/01/what-really-happens-at-startup-linkerd-init-containers-the-cni-and-more/\">在启动时到底发生了什么：Linkerd、初始化容器、CNI等等</a>\"。</p><p>&nbsp;</p><p></p><h2>意料之中的事2：安全性仍然是采用Linkerd的主要动力</h2><p></p><p></p><p>与前几年一样，采用Linkerd的主要动力仍然是安全性。Linkerd的<a href=\"https://linkerd.io/2.12/features/automatic-mtls/\">零配置Mutual TLS</a>\"一直是该项目的一个主要吸引力来源，2022年引入的<a href=\"https://buoyant.io/blog/announcing-linkerd-2-12\">L7授权策略</a>\"完善了Linkerd的零信任特性集。</p><p>&nbsp;</p><p>我们也很高兴地看到，市场显现出了日益成熟的迹象。几年前，“我们需要在传输过程中加密”是采用mTLS的主要理由。2022年，我们听到许多采用者说，“是的，我们需要在传输过程中加密，但也需要使用真实的工作负载标识进行身份验证，以及在每个Pod上实现零信任授权”。零信任正变得越来越受欢迎，这已经不是什么秘密了，<a href=\"https://buoyant.io/resources/zero-trust-in-kubernetes-with-linkerd\">基于边车的服务网格如果不直接实现零信任原则，就什么都不是</a>\"。边车模型再得一分！</p><p>&nbsp;</p><p>像往常一样，我们也尽量保持项目的整洁，Linkerd<a href=\"https://linkerd.io/2022/06/27/announcing-the-completion-of-linkerds-2022-security-audit/\">出色地完成了年度安全审计</a>\"。</p><p>&nbsp;</p><p></p><h3>2023年服务网格会带来什么？</h3><p></p><p></p><p>2023年有望成为Linkerd公司又一个辉煌的年份。我们已经有了一些令人兴奋不已的计划，从即将发布的2.13版本（包括基于头的路由和断路），到其他一些目前还保密的杀手级想法。一如既往，我们将专注于保持Linkerd简单、轻便和安全。</p><p>&nbsp;</p><p>想参与CNCF第一个也是唯一一个毕业的服务网络吗？现在就是加入的好时机。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://linkerd.io/2022/12/28/service-mesh-2022-recap-ebpf-gateway-api/index.html\">https://linkerd.io/2022/12/28/service-mesh-2022-recap-ebpf-gateway-api/index.html</a>\"</p>",
    "publish_time": "2023-01-11 15:57:04",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "《流程挖掘白皮书》",
    "url": "https://www.infoq.cn/article/b9v43T7bJim0xmTj6whs",
    "summary": "<p>从大环境看，国家大力推进加快数字化发展，企业的数字化转型迎来了积极的制度环境和明确的政策指引。运营管理的数字化发展是其中的重要课题，旨在以数字化方式谋求提升企业运营管理能力，加快塑造企业韧性，抵御不确定风险，实现企业中长期战略目标。</p>\n<p>从企业的自身发展诉求看，为了应对复杂的业务变化，企业不断加快其信息化、自动化的步伐，其IT系统逐渐变得厚重，业务流程也越发复杂。企业的领导者和管理者亟需清晰、透明的全局视角，洞悉隐藏增长点、高额隐形成本、潜在风险点等。</p>\n<p>望繁信科技已为国内逾100家各行业头部优秀企业提供了流程挖掘解决方案，并在陪伴客户完成企业运营管理提升与数字化转型过程中，观察、接触并总结了这些企业在面对管理痛点时的流程特征和典型困难，基于流程治理，也沉淀出了较为完整的解决思路和应对方案。因此，为了帮助更加广泛的企业充分运用流程挖掘技术来实现运营管理能力提升、推动业务发展和取得数字化转型成功，望繁信科技发布本白皮书，分享近年来在流程挖掘实战中的积累，为企业提供新的思路。</p>",
    "publish_time": "2023-01-11 16:38:49",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "日本软件业烂透了！谷歌日本高管揭秘回顾那些被遗忘的错误",
    "url": "https://www.infoq.cn/article/mT8H23b58ma76XOKVOBu",
    "summary": "<p></p><blockquote>如今，似乎人人都在吐槽日本的软件质量不行，但究竟出了什么问题？近日，Google for Startups Japan 负责人Tim Romero撰写了一篇文章，带大家一同回顾整个时代脉络，特别是日本迷失方向的特定时刻，并希望以此能让大家看清软件发展的规律和逻辑，理解万事万物此消彼长、不断变化的底层原因。也许这会给大家带来一种全新的、更具启发性的日本软件行业审视角度。没错，请做好准备，迎接这出涵盖迷失与清醒、重生与救赎的精彩大戏。</blockquote><p></p><p>&nbsp;</p><p></p><h2>烂摊子的起源</h2><p></p><p>&nbsp;</p><p><a href=\"https://www.infoq.cn/article/chinatechday-Japan-IT\">日本软件</a>\"确实有问题。按国际标准来判断，简直可以说<a href=\"https://www.infoq.cn/article/R55Axi5OLGTWG3AhV_4X\">是糟透了</a>\"。这事我们都知道。但有趣的是，状况恶化成这样却有其合理性……没错，很糟糕，但整个过程相当符合逻辑。</p><p>&nbsp;</p><p>其实决定<a href=\"https://www.infoq.cn/article/japan-agile-whats-happening\">日本软件</a>\"行业命运的时间节点，比大家想象中要更早。</p><p>&nbsp;</p><p>不仅是二战末期，我们得一路回溯到明治维新开启后的那几年，即1800年代末期。那个时候，整个日本的经济已经由财阀所主导。如今，“zaibatsu”这个词常被翻译成“大型企业集团”或者“家族控制的企业集团”。但更确切地讲，应该称之为“财阀”。在上世纪之交，存在住友、三井、三菱和安田四大财阀。日本战败后，财阀被重组成了另外一种不如原先强大，且更为现代人所熟知的形式，即经连会。从50年代到70年代，这些经连会团体创新、颠覆并主导着日本几乎所有行业——从汽车、相机、机械零件、钢铁、半导体、手表到家用电子产品。</p><p>&nbsp;</p><p>可那时候的经连会，在软件开发方面表现如何？其实，也相当不错。</p><p>&nbsp;</p><p>但这里有个前提，60年代和70年代的软件行业跟现在完全不同。软件开发流程本身倒是没多大变化，Fred Brooks撰写的不朽巨著《人月神话》就是当时的产物，他在那个年代总经的经验至今仍然指导着软件工程与项目管理思维。</p><p>&nbsp;</p><p>最大的区别，体现在软件的买卖方式上。在60到70年代，软件是专为极度昂贵的特定硬件所编写，软件需求属于整体采购合同中的一部分。因此软件本身并不是独立的产品，而更像是一种服务，类似于现在大家熟悉的集成、培训和持续性支持与维护。当时的软件大多按时间和开发成本计费，有时也会免费赠送的方式向客户让利。真正用来赚钱的是硬件。</p><p>&nbsp;</p><p>不光是日本，当时全世界的软件都以符合规范为第一要务。有没有创造性、创新性，易不易用或者优不优雅并不重要，但千万不能有违既定规范。事实上，在那个时代开发卓越软件的行为被视为一种资源浪费。毕竟产品都卖了、合同也签了，你玩命折腾软件是要干什么？跟如今的很多系统集成项目一样，当时软件开发的目标就是别出毛病、让客户能接受。</p><p>&nbsp;</p><p>这就塑造出了“好”软件的定义：符合客户既定规范的软件，就是好软件。</p><p>&nbsp;</p><p>日本的经连会在大型机时代表现不错。尽管富士通、NEC和日立在整个60和70年代仍不足以真正挑战IBM和Univac的全球霸权，但其微型计算机和大型办公系统的表现已经堪称可圈可点。</p><p>&nbsp;</p><p></p><h2>日本，对新兴产业说不</h2><p></p><p>但随着PC革命在80年代后期到来，整个日本工业猝不及防。而且个中缘由，可能跟大家的设想有很大出入。日本软件开发之所以在整个1980年代都停滞不前，绝不是因为缺少才华横溢的软件开发人员。相反，这是经连会存在所引发的必然结果。从商业要素来看，个人计算机代表是一块全新的市场。虽然其核心技术和硬件是上一个时代的直接延续，但市场本身的属性却完全不同。</p><p>&nbsp;</p><p>个人计算机市场源自少数标准化操作系统加多种硬件架构的联合。经连会在硬件这个层面做得不错，开发出了一系列令人印象深刻的机器，特别是笔记本电脑。但非标软件这东西超出了日本企业的惯有认知。做个软件得取悦客户？还得在对方没想明白自己要什么之前，就拿出符合他们需求的设计方案？种种新基准把这些经连会的企业一下子整不会了。</p><p>&nbsp;</p><p>历史的车轮滚滚向前，这时候的这些大企业站在非常有利的市场地位上，完全有机会从头开始重塑符合80年代特性的软件产业。但问题是，他们为什么要从头开始？日本的经济在80年代处于有史以来最繁荣的时期，经济学家甚至预测日本的GDP在十年内就将超越美国。有了一个利润丰厚且安全稳定的国内市场，企业们认为专注于赚这笔钱，可比在充满不确定性的新兴全球市场上冒险下押更有意义。</p><p>&nbsp;</p><p>每个经连会团体都有自己的技术企业，他们也在销售PC和软件。其中一部分面向消费者，但主要收益还是源自企业级市场，靠整合加定制业务就能给经连会带来超额收益。这就是最可悲的现实——作为“面子”的大型系统集成商一直在国际市场上奋力搏杀，但作为“里子”的日本软件公司从来没有亲自登台与全球对手一较高下。</p><p>&nbsp;</p><p></p><h2>创新枯竭的起点</h2><p></p><p>80年代到90年代的日本软件产业，仍然保持着大型机时代的特征。软件的意义还是够用、客户能接受就行，而且因为服务的主要是内部企业或兄弟企业，所以“能接受”的标准跟全球同行相比确实偏低了。即使存在一些“小小”的软件缺陷，下阶段再修复就行了。</p><p>&nbsp;</p><p>这时候的软件开发仍是表单上的一栏，打上勾、客户确认可以并签下合同，功能就算实现了。</p><p>&nbsp;</p><p>这不仅导致日本错过了全球软件产业，同时也标志着日本整个产业创新体系的崩溃起点。</p><p>&nbsp;</p><p>在接下来的30年间，软件成为创新和效率的关键驱动力。而日本这种将整个IT战略外包给单一集成商的做法，几乎必然导致各个行业的发展节奏都落后于技术前进曲线。时至今日，日本好像还是没能回过神来，大多数企业系统仍落后于全球竞争对手几十年。</p><p>&nbsp;</p><p>那么，80和90年代在日本当一名软件开发者是种什么感觉？</p><p>&nbsp;</p><p>感觉很差，因为人们普遍认为软件开发是种低技能工作。这类岗位报酬不高，甚至被归入文书工作的范畴。人们只是简单编写软件，确保销售在酒桌上跟客户谈好的合同能顺利签下来就行。</p><p>&nbsp;</p><p>很多文学、商学和法学出身的新员工都在软件开发岗上工作过，这是要让他们了解公司内不同部门的运作方式。软件开发本身没有真正的职业道路，虽然也有相应的项目管理或者销售岗，但如果一个人30岁了还在写代码，那肯定是哪里出了问题。</p><p>&nbsp;</p><p>当然，日本也有不少伟大的、极具前瞻性的软件开发者，我也认识好几位。他们真正想要让计算机获得突破性的能力，也意识到软件技术正在颠覆各个行业。</p><p>&nbsp;</p><p>如果你恰好是这样的优秀开发者，那整个80和90年代对你来说一定是段不堪回首的痛苦岁月。</p><p>&nbsp;</p><p>有趣的是，硬件工程师的感受截然不同。无论是过去还是现在，硬件工程师在日本都备受尊重。无论是丰田、三菱还是索尼，大家最看重的永远是这部分工程师。</p><p>&nbsp;</p><p>所以日本的硬件创新在80和90年代仍然如火如荼地推进。随身听和任天堂游戏机在全球取得成功，日本国内市场上的电子词本、电子词典等产品也远远领先于海外市场，这就有了“日本人总是把最好的留给自己”的说法。对了，还有i-mode。日本消费者在黑莓发布的几年之前就已经能在移动设备上发送邮件和浏览网页，比iPhone早了近十年。</p><p>&nbsp;</p><p></p><h2>大厦崩塌</h2><p></p><p>&nbsp;</p><p>但日本之外的整个世界都在疾步前行，从专用硬件配专用软件，转向在标准硬件上运行创新软件。Marc Andreessen对此做出了恰如其分的描述，“软件正在吞噬世界”。</p><p>&nbsp;</p><p>随着互联网泡沫的膨胀，日本终于意识到自己也需要有才华的软件开发人员。但因为各个行业都不重视这个群体，所以大企业也不知道哪里有合适的人选。最优秀的人才往往得不到认可，被困在组织结构的中低层次，未来的发展空间也不大。不受尊重加上待遇偏低，很少会有日本学生主动选择软件工程专业。</p><p>&nbsp;</p><p>尽管形势很差，但也有些人纯粹出于兴趣选择了这条道路。这就像学音乐和学绘画，他们只是在追寻自己的梦想。确实有可能成功，只是几率非常非常低。</p><p>&nbsp;</p><p>到上世纪90年代，当外国软件企业开始入驻日本时，国内的产业几乎无力抵抗。</p><p>&nbsp;</p><p>90年代后期的互联网繁荣得到了日本第一波风险投资的支持，这时候颠覆性的创新浪潮已经涌起，但日本的软件开发商仍然不具备广泛的国际知名度。</p><p>&nbsp;</p><p>当时愿意放手一搏的，往往是那些人脉广泛或者斗志旺盛的商人。但大家对软件开发者的成见还在，没人相信这些看起来呆呆的家伙有能力主导一家企业。</p><p>&nbsp;</p><p>我的第一次创业尝试就是从互联网泡沫时期开始的。有趣的是，我这样一位技术出身的家伙搞创业，在日本其实是比外国人搞创业更罕见的情况。</p><p>&nbsp;</p><p>必须承认，互联网泡沫时代的繁荣确实给了日本一次振兴软件产业的绝佳机遇。由于获得了前所未有的肯定和尊重，这时候召集优秀开发者、做出有意义贡献、增强代码质量和呼吁全社会学习软件技能的声音可谓振聋发聩。</p><p>&nbsp;</p><p></p><h2>日本软件开发者开始走向舞台中心</h2><p></p><p>上世纪90年代末常被称为日本“失去的十年”。经连会企业的力量被持续削弱，迫于成本压力，心高气傲的日本厂商也不得不将生产线从日本转移到劳动力更便宜的其他国家。到这一时期，日本最著名的终身雇佣制也走到了终点。</p><p>&nbsp;</p><p>此举震惊了整个日本。终身雇佣制在很长一段时间是维系基本社会秩序的基础——如果努力工作和绝对忠诚得不到回报，那为什么还要为企业奉献一生？于是令日本政客苦恼的情况出现了，很多日本年轻人根本就不打算加入企业。</p><p>&nbsp;</p><p>现在回头来看，软件行业增长放缓、被动变革令人痛苦，但这一切也是在为日本之前对软件开发者的忽视付出代价。</p><p>&nbsp;</p><p>我个人会将2010年视为日本软件开发者走上舞台中心的标志性元年。虽然之前趋势已现，但真正的转折还是在这一年才全面爆发。</p><p>&nbsp;</p><p>这背后有两个根本原因。首先是云计算的出现，其次是智能手机的推出。尽管这些都是技术发展的产物，但推动变化的却并不是技术本身。</p><p>&nbsp;</p><p>云计算大大拉低了创业所需要的资金和时间门槛。在十年前的互联网时代，创立一家互联网初创公司需要采购服务器机架，并向系统管理员付费以保持设备运行。但突然之间，每分钟只要支付几美分就能让公司获得配置完善、维护到位、安全可靠的服务。那还愣着干什么，赶紧创业啊！</p><p>&nbsp;</p><p>于是日本的软件开发者不再需要向风投解释自己要干什么、怎么盈利，他们可以直接把产品开发出来、交给受众使用，效果好的话再启动收费。大家也的确就是这么做的。</p><p>&nbsp;</p><p>另一个重要里程碑是2007年诞生的iPhone和一年后亮相的Android。不只是技术，智能手机的出现颠覆了软件的商业模式。</p><p>&nbsp;</p><p>日本的i-mode确实比整个西方领先多年，但想让应用程序登陆i-mode，开发商必须得跟电信公司进行长时间谈判。智能手机的生态则完全不同，任何能证明自己应用产品符合质量标准的开发者，都可以通过官方软件商店进行销售。不需要业务联系、不需要排他性谈判、也不需要签收入对赌协议。</p><p>&nbsp;</p><p>2010年，日本的软件开发者终于有了“基本人权”。随着有才华的开发人员意识到新时代下创业难度之低，他们开始开辟自己的道路，压根不会考虑大企业那种等级森严的老古董式职业方向。</p><p>&nbsp;</p><p>再加上互联网时代令硅谷传奇响彻寰宇，彻底重塑了日本软件开发者的思维和形象。如今，软件开发者群体受到重视和尊敬，日本的初创公司和大型企业都在全力招募和挽留出色的程序员。更值得庆幸的是，日本各行业也终于开始积极讨论代码质量问题。</p><p>&nbsp;</p><p>当然，这种态度的转化不仅限于开发人员。随着终身雇佣与定期晋升制度的消失，人们不再像过去那样害怕风险，开始以创新为载体有计划地拥抱风险。“自由职业者”不再是街溜子的代名词，这部分群体成了日本灵活创业的核心。另外，部分被经连会组织抛弃的家庭小作坊，也在重新探索可行的商业道路。</p><p>&nbsp;</p><p></p><h2>创新决定了软件的未来</h2><p></p><p>在基本被隔绝在PC和互联网两场革命外后，日本软件开发商一直在努力弥补错失的时间和创业空间。日本在某些领域已经发展出了具有效力的软件市场，但总体上还有很长的路要走。</p><p>&nbsp;</p><p>曾在日本占据主导的系统集成商也没那么有竞争力了，老客户们正在迅速流失。B2B SaaS软件初创公司的出现，令那些早就不想花高成本维护遗留系统的日本企业迅速接纳了现代IT系统。</p><p>&nbsp;</p><p>当然，系统集成商不会消失。市场需要优秀的系统集成商，而更具前瞻性的集成企业正在主动自我重塑。但必须承认，由系统集成商决定客户IT战略的日子已经一去不复返，不过这对日本软件业、日本初创企业来说未尝不是一件好事。</p><p>&nbsp;</p><p>由于初创企业被列为国家优先事项，日本对优质软件和软件初创企业的渴求空前高涨。这股风甚至吹进了哪怕最顽固的经连会组织。他们也希望通过并购和长期合作伙伴关系与软件初创公司携手，补充内部研发能力，并呼吁各成员企业大幅增加对初创公司的投入和合作力度。</p><p>&nbsp;</p><p>虽然日本软件还处于阴霾之下，但我认为如今涌现的创业公司、大企业和学界联合应该也会探索出一条新的道路。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.disruptingjapan.com/the-forgotten-mistake-that-killed-japans-software-industry/\">https://www.disruptingjapan.com/the-forgotten-mistake-that-killed-japans-software-industry/</a>\"</p><p><a href=\"https://news.ycombinator.com/item?id=34320669\">https://news.ycombinator.com/item?id=34320669</a>\"</p>",
    "publish_time": "2023-01-11 16:58:32",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "JSONQL 低代码数据模型引擎的设计与实现",
    "url": "https://www.infoq.cn/article/QQYdqK3yjzxrb8TbvgVC",
    "summary": "<p>在低代码产品中，后端最重要的功能是数据模型，它的能力决定了低代码平台可以开发应用的上限，之前在介绍<a href=\"https://zhuanlan.zhihu.com/p/451340998\">低代码实现原理</a>\"时列举过几种实现方式，其中只有第一个动态 ORM 方案支持对接已有数据库，这个方案比其它方案的灵活性和性能都更好，能制作的应用上限最高，因此<a href=\"https://link.zhihu.com/?target=https%3A//aisuda.baidu.com/\">爱速搭</a>\"里首先实现的就是这个方案。</p><p></p><p>本文将介绍爱速搭中数据模型的实现细节，以及其中最重要的 JSONQL 语言。</p><p></p><p>在介绍 JSONQL 前，先回顾一下在专业开发中如何进行数据查询，目前常见有三种方案：</p><p>裸写 SQL 方案，包括 MyBatis 这种映射方案，这个方案灵活性强，可以使用所有 SQL 功能，缺点是无法适配多种数据库，对于复杂的关联查询需要自己 JOIN 表，由于上手门槛低，是目前国内开发者主要使用的方案。Query Builder 方案，它将 SQL 做了一层封装，开发者可以通过代码来构造 SQL，比裸写 SQL 多了类型检查，开发时不容易写错，同时这个方案很适合既想支持多种数据库，又想接近 SQL 开发体验的开发者。ORM 方案，比如 JPA/Hibernate/ActiveRecord，主要特点是几乎屏蔽了 SQL，这也导致了上手成本高，初次接触需要学习大量概念，优点是上手后开发效率很高，关联查询写起来也简单，还能适配多种数据库，但这个方案的灵活性比 SQL 弱，有些特殊的数据库方言无法实现，而且屏蔽了 SQL 导致开发者不会怎么关注最终生成 SQL，很容易生成低效查询，比如查询所有列及 N+1 次查询问题。</p><p></p><p>有没有一种方案，可以同时有这些方案的优点，既能做到和 SQL 一样的灵活性，又能跨数据库，又能支持简易关联查询，又能解决查询无用字段及 N+1 问题呢？</p><p></p><p>这就是本文将介绍的新方案 JSONQL，它是爱速搭数据模型的前后端交互语言。</p><p></p><h2>爱速搭中的数据模型</h2><p></p><p></p><p>可能你还没用过爱速搭，所以在介绍 JSONQL 之前，先简单介绍一下爱速搭中数据模型的使用流程，主要分 3 步：</p><p>连接数据源导入表结构，建立关联关系设计前端界面</p><p></p><p>第 1 步是连接数据源，这个比较简单就是填入数据库地址和账号密码。</p><p></p><p>第 2 步是导入表结构，比如原始数据库里的表结构如下——</p><p></p><p>导入之后还能添加关联关系，这里添加了两个关系，一个是 user 下有多个 blog 的一对多关系，关系名是&nbsp;blogs，另一个是 blog 属于某个用户的多对一关系，关系名是&nbsp;user，最终效果如下图所示，也叫 ER 关系图。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/7e/a0/7eb80d3c7373750fbce24495084a62a0.png\" /></p><p>爱速搭模型设计</p><p></p><p>这里的关系并不依赖数据库外键，比如&nbsp;blog&nbsp;表里&nbsp;user_id&nbsp;可以不是外键。</p><p></p><p>第 3 步是设计前端界面，爱速搭提供了一个脚手架来快速生成 CRUD 界面，如下图所示</p><p><img src=\"https://static001.infoq.cn/resource/image/53/ec/53a629a5f20cb0ff56872af52df364ec.png\" /></p><p>爱速搭脚手架</p><p></p><p>勾选需要的功能和展示字段后，一个带增删改查的列表页面就生成出来了</p><p><img src=\"https://static001.infoq.cn/resource/image/ab/b8/ab3e9719d0b3d20a86f558b510cb44b8.png\" /></p><p></p><p>爱速搭页面编辑器</p><p></p><p>这个生成的界面是&nbsp;<a href=\"https://link.zhihu.com/?target=https%3A//aisuda.bce.baidu.com/amis/zh-CN/components/crud\">amis</a>\"&nbsp;CRUD 组件的配置，因此还可以进一步调整，比如修改列的展示类型，新增列等。</p><p></p><p>这样一个基于数据库的展示和编辑界面就做好了，全程无需写代码。</p><p></p><p>实现这个功能除了前端 UI 组件、后端 SQL 查询外，还有个重要部分是前后端如何交互？</p><p></p><p>爱速搭之前的做法是后端提供 RESTful 协议的接口，比如默认包含这些 HTTP api</p><p><code lang=\"null\">// 创建数据\nPOST /datamodel\n\n// 查询数据列表\nGET /datamodel\n\n// 查询加上过滤条件，下面的示例相当于 name = 'aisuda' AND age &lt; 10\nGET /datamodel?name=aisuda&amp;age[lt]=10\n\n// 查询某个数据详情，其中 1 是主键值\nGET /datamodel/1\n\n// 修改某个数据，修改内容在提交 payload 里\nPUT /datamodel/1\n\n// 删除某个数据\nDELETE /datamodel/1</code></p><p></p><p>这些接口可以用来实现简单应用，许多低代码平台也就是做到这个程度，但它有很多缺点：</p><p>无法控制返回字段，比如文章列表可能只想查询标题而无需返回内容，需要定制特殊参数。无法进行复杂组合查询，前面的过滤条件都是且（AND），如果要做负责的嵌套条件，比如&nbsp;name = aisuda OR age &lt; 10) AND deleted IS NOT NULL&nbsp;就无能为力了，需要定制特殊参数。无法支持聚合查询，要实现图表类的查询需要再定义新接口。</p><p></p><p>最开始提到过，数据模型决定了低代码平台能制作应用的上限，如果只有简单的 REST 接口，就只能做简单应用，比起专业开发在灵活性上有很大差距，因此为了让爱速搭能构建更为复杂的应用，我们开发了全新的前后端交互语言 JSONQL。</p><p></p><h2>JSONQL 介绍</h2><p></p><p></p><p>JSONQL 其实就是 JSON 格式的自定义 DSL，先来看一个 JSONQL 最简单实例</p><p><code lang=\"null\">{\n  \"statement\": \"select\",\n  \"select\": [\"name\"]\n  \"from\": \"user\"\n}</code></p><p></p><p>它的作用相当于下面这段 SQL</p><p><code lang=\"null\">SELECT name FROM user</code></p><p></p><p>JSONQL 有什么特点呢？</p><p>灵活性强易用性好支持多种数据库性能优安全性有保障</p><p></p><p>后面会分别介绍这些功能，从整个系统层面看，JSONQL 是爱速搭前后端交互的中心节点，前端可以通过 REST 接口、SQL、GraphQL 等方式连接后端，这些接口都会先转成 JSONQL，然后再通过 JSONQL 引擎连接各种后端数据。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/4e/84/4e2d9b8802101f4df62fd865bb395984.png\" /></p><p>JSONQL 作为中心节点连接前后端</p><p></p><h2>灵活性强</h2><p></p><p></p><p>JSONQL 的第一个特点是灵活性强，它的语法主要参考 SQL，相当于一种以 JSON 格式表达的 SQL，JSONQL 能表达绝大部分 SQL 语句，所以我们还实现了另一种模式，可以支持直接写 SQL，类似下面的写法</p><p><code lang=\"null\">{\n  \"sql\": \"select name from user\"\n}</code></p><p></p><p>它的原理是先进行 SQL 解析，再遍历解析后的 AST 树转成等价的 JSONQL，除了前面的简单例子，它还支持非常复杂的嵌套表达式及子查询，比如下面这段 SQL（来自 SQL for Data Analytics）也可以转换为等价 JSONQL，由于篇幅原因这里就不显示生成的 JSONQL 结构了，内容实在太长，只是为了说明 JSONQL 可以类似 SQL 那样无限嵌套</p><p><code lang=\"null\">SELECT sales_year,\n  womens_sales - mens_sales as womens_minus_mens,\n  mens_sales - womens_sales as mens_minus_womens\nFROM (\n    SELECT date_part('year', sales_month) as sales_year,\n      sum(\n        case\n          when kind_of_business = 'Women''s clothing stores' then sales\n        end\n      ) as womens_sales,\n      sum(\n        case\n          when kind_of_business = 'Men''s clothing stores' then sales\n        end\n      ) as mens_sales\n    FROM retail_sales\n    WHERE kind_of_business in (\n        'Men''s clothing stores',\n        'Women''s clothing stores'\n      )\n      and sales_month &lt;= '2019-12-01'\n    GROUP BY 1\n  ) a\nORDER BY 1;</code></p><p></p><p>除了查询还有更新和删除，比如类似下面的 SQL 写法</p><p><code lang=\"null\">UPDATE table1 SET column1 = column1 + 1</code></p><p></p><p>JSONQL 中可以表示为</p><p><code lang=\"null\">{\n  \"statement\": \"update\",\n  \"table\": \"table1\",\n  \"setExp\": {\n    \"column1\": {\n      \"binary\": \"+\",\n      \"left\": \"column1\",\n      \"right\": 1\n    }\n  }\n}</code></p><p></p><p>这时你可能会问为什么不直接用 SQL 呢？因为 SQL 是字符串，程序化生成时容易拼接出错，比如要拼接一个 WHERE 条件，你要注意字符串转义（字符串里本身就有引号的情况），生成复杂 WHERE 条件也挺麻烦，比如&nbsp;WHERE (a=1 or (b=2 and c = 3)) and d=4&nbsp;，要注意没有条件时这个 WHERE 字符串也不能输出，而用 JSON 可以方便前端编辑器生成。</p><p></p><p>接下来你可能会问直接将 SQL 暴露给前端岂不是太危险了？先别急，后面会详细介绍如何保证安全。</p><p></p><p>现在你对 JSONQL 有了初步认识，可以理解为一种用 JSON 结构化表示的 SQL，绝大部分 SQL 都能表示为 JSONQL 形式，考虑到读者对 SQL 更熟悉，因此后面文章会优先使用 SQL 来作为示例。</p><p></p><h2>易用性好</h2><p></p><p></p><p>前面介绍了 JSONQL 基本等于 SQL，所以灵活性强，但除了这点，JSONQL 还提供了许多功能来提升易用性。</p><p></p><h3>支持关联查询及 N+1 问题</h3><p></p><p></p><p>第一个是支持关联查询，这使得 JSONQL既能做到 SQL 的灵活性又能做到 ORM 的易用性。</p><p></p><p>还是拿前面那个简单的例子。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/4e/f5/4ee1092cb652fcf3fee7ce33f37dbcf5.png\" /></p><p></p><p></p><p>在 user 表里有个一对多关系字段 blogs，也就是一个用户写了多篇博客，查询用户及这个用户写的文章列表可以使用以下 JSONQL</p><p><code lang=\"null\">{\n  \"statement\": \"SELECT\",\n  \"select\": [\"name\", \"blogs\"]\n  \"from\": \"user\"\n}</code></p><p></p><p>查询输出给前端的结果类似如下示例，注意这里的&nbsp;blogs&nbsp;是深层结构，嵌入到每个用户对象里</p><p><code lang=\"null\">[{\n    \"id\": 1,\n    \"name\": \"user1\",\n    \"blogs\": [{\n        \"id\": 1,\n        \"title\": \"title1\",\n        \"user_id\": 1,\n        \"content\": \"content1\"\n    }, {\n        \"id\": 2,\n        \"title\": \"title2\",\n        \"user_id\": 1,\n        \"content\": \"content2\"\n    }]\n}, {\n    \"id\": 2,\n    \"name\": \"user2\",\n    \"blogs\": [{\n        \"id\": 3,\n        \"title\": \"title3\",\n        \"user_id\": 2,\n        \"content\": \"content3\"\n    }]\n}]</code></p><p></p><p>如何实现呢？有两种做法，一种是 ORM 里常见的 N+1 查询，也就是首先查询 user，然后再根据 user id 去查询 blog，类似如下伪代码</p><p><code lang=\"null\">const users = find(User);\nfor (const user of users) {\n  const blogs = find(Blog).byUserId(user.id);\n}\n</code></p><p></p><p>这种做法下，查到了 10 个用户，就要发起很 10 次 blog 查询，因此也叫 N+1 次查询，如果用户数量很多就会影响数据库性能。</p><p></p><p>如果要优化 N+1 查询，可以使用就是基于 JOIN 来一次查出，比如下面 SQL 语句</p><p><code lang=\"null\">SELECT\n  `user`.`id`,\n  `user`.`name`,\n  `blogs`.`id`,\n  `blogs`.`title`,\n  `blogs`.`user_id`,\n  `blogs`.`content`\nFROM\n  `user`\nLEFT JOIN `blog` `blogs` ON `user`.`id` = `blogs`.`user_id`</code></p><p></p><p>如果要获取所有数据，这个语句是能满足需求的，但大多数时候还有分页需求，比如只想一次性查询 10 个 user 的数据，这时就没法简单地加上 limit，比如</p><p><code lang=\"null\">SELECT\n  `user`.`id`,\n  `user`.`name`,\n  `blogs`.`id`,\n  `blogs`.`title`,\n  `blogs`.`user_id`,\n  `blogs`.`content`\nFROM\n  `user`\nLEFT JOIN `blog` `blogs` ON `user`.`id` = `blogs`.`user_id` \nLIMIT 10 # 这是错的</code></p><p></p><p>为什么这是错的？因为一个用户对应多个博客，合并到一张表里用户就会重复，比如变成如下数据输出</p><p></p><p></p><p>因此假设第一个用户 1 有 10 篇文章，加上 LIMIT 后就只能查出有这一个用户的文章列表了，而我们希望的是查 10 个用户的文章列表。</p><p></p><p>怎么办呢？有个高级办法是使用&nbsp;LATERAL&nbsp;语法，上面的语句可以改成 </p><p><code lang=\"null\">SELECT \"u\".\"id\", \"u\".\"name\"\nFROM (\n    SELECT *\n    FROM \"user\"\n    LIMIT 10\n  ) u\n  LEFT JOIN LATERAL (\n    SELECT \"blog\".\"id\", \"blog\".\"title\", \"blog\".\"content\"\n    FROM \"blog\"\n    WHERE \"u\".\"id\" = \"blog\".\"user_id\"\n  ) blogs on true</code></p><p></p><p>实际执行类似下面的伪代码</p><p><code lang=\"null\">for user in users:\n   for blog in blogs:\n     blog.user_id = user.id</code></p><p></p><p>比普通 SQL 查询多了一层嵌套循环，它会在查询完第一层结果后再查询，使得可以支持 LIMIT。</p><p></p><p>但它的缺点是只有少数几种数据库支持，Postgres 9.3、Oracle 12c 版本以上支持，SQL Server 需要改查&nbsp;<a href=\"https://link.zhihu.com/?target=https%3A//learn.microsoft.com/en-us/previous-versions/sql/sql-server-2008-r2/ms175156v%3Dsql.105\">APPLY</a>\"&nbsp;语法，支持最差的是 MySQL，要等到&nbsp;<a href=\"https://link.zhihu.com/?target=https%3A//dev.mysql.com/doc/refman/8.0/en/lateral-derived-tables.html\">8.0.14</a>\"&nbsp;版本才支持。</p><p></p><p>由于最流行的 MySQL 要高版本才支持，导致在国内实用性不高，因此 JSONQL 默认没有使用这个语法，而是使用了两次查询来解决，方法是：</p><p></p><p>第一次查询用户 id，使用如下语句 </p><p><code lang=\"null\">SELECT\n  DISTINCT `id`\nFROM\n  (SELECT\n      `user`.`id`,\n      `user`.`name`,\n      `blogs`.`id`,\n      `blogs`.`title`,\n      `blogs`.`user_id`,\n      `blogs`.`content`\n    FROM\n      `user`\n    LEFT JOIN `blog` `blogs` ON `user`.`id` = `blogs`.`user_id` ) AS `distinctAlias`\nLIMIT 10</code></p><p></p><p>接着再基于拿到的用户 id 去查询 blogs，生成类似如下的 SQL 语句</p><p><code lang=\"null\">SELECT\n  `user`.`id`,\n  `user`.`name`,\n  `blogs`.`id`,\n  `blogs`.`title`,\n  `blogs`.`user_id`,\n  `blogs`.`content`\nFROM\n  `user`\nLEFT JOIN `blog` `blogs` ON `user`.`id` = `blogs`.`user_id` \nWHERE\n  `user`.`id` IN (1, 2, 3, 4, 5, 6, 7, 8, 9, 10)</code></p><p></p><p>这样就只需要两个查询语句，也被称为批量查询方案。</p><p></p><p>然而这个方案并不完美，这里的第二次查询还是没法 LIMIT，如果 blogs 表的数据量很大，比如有的用户有几千篇文章，而只想显示最新一篇，也会导致大量 IO 及带宽浪费，这时使用 N+1 查询反而是个更好的方案。</p><p></p><p>因此在 JSONQL 中我们增加了一种名为二次查询的语法，使用下面的写法</p><p><code lang=\"null\">{\n  \"statement\": \"SELECT\",\n  \"select\": [\n    {\n      \"column\": \"name\"\n    }\n  ],\n  \"from\": \"user\",\n  \"limit\": 10,\n  \"secondQuery\": [\n    {\n      \"select\": [\n        {\n          \"column\": \"title\"\n        }\n      ],\n      \"limit\": 2,\n      \"where\": {\n        \"tag\": \"tag1\"\n      }\n      \"from\": \"blogs\"\n    }\n  ]\n}</code></p><p></p><p>在实现的时候，会先查询 user 表，然后再基于返回的 id 一个去查询 blog 表，并且加上 LIMIT 条件。</p><p>除了要发起 N 次查询，这个方案还有个缺陷是子表的过滤条件无法放到主表中，也就是无法查询「写过文章标题为 amis 的作者及文章列表」，因为主查询的过滤条件只能是用户字段里的字段。</p><p></p><p>由于 LATERAL 的巨大优势，JSONQL 后续版本打算进行优化，对于支持 LATERAL 的数据库优先使用它，这样就能完美支持两种场景，不需要区分两种写法了。</p><p></p><p>除了前面说到的多对一关系场景，JSONQL 还支持多对多、一对多、一对一关系、反向一对一关系，并且支持无限层级嵌套，比如下面的写法</p><p><code lang=\"null\">{\n  \"statement\": \"SELECT\",\n  \"select\": [\"books.author.address\"]\n  \"from\": \"bookshop\"\n}</code></p><p></p><p>这其实是四层关系，bookshop 和 books 是多对多，books 和 author 是多对一，author 和 adress 是一对一，生成 SQL 有四个 JOIN，输出结果也是个深层对象，类似</p><p><code lang=\"null\">[{\n    \"id\": 1,\n    \"name\": \"书店 1\",\n    \"books\": [{\n        \"title\": \"书籍 1\",\n        \"id\": 1,\n        \"author\": {\n            \"name\": \"作者 1\",\n            \"id\": 1,\n            \"address\": {\n                \"id\": 1,\n                \"location\": \"地址 1\"\n            }\n        }\n    }]\n}]</code></p><p></p><p>同时除了 select，在 where 里也能使用关系字段，比如根据书籍标题查找作者列表，查找同名的书都有谁写过</p><p><code lang=\"null\">{\n  \"statement\": \"select\",\n  \"where\": {\n    \"books.title\": \"书籍 1\"\n  }\n  \"from\": \"author\"\n}</code></p><p></p><p>如果用 SQL 需要自己 join，类似如下写法</p><p><code lang=\"null\">SELECT\n  \"author\".\"id\",\n  \"author\".\"name\"\nFROM\n  \"author\"\nLEFT JOIN \"book\" \"books\" ON \"author\".\"id\" = \"books\".\"author_id\" \nWHERE\n  \"books\".\"title\" = '书籍 1'</code></p><p></p><p>关联除了查询，还有增删改操作，比如新增一个用户的时候，还可以同时提供他的文章信息，类似下面的请求</p><p><code lang=\"null\">{\n  \"statement\": \"INSERT\",\n  \"table\": \"user\",\n  \"values\": {\n    \"name\": \"user1\",\n    \"books\": [\n      {\n        \"title\": \"book1\"\n      }\n    ]\n  }\n}</code></p><p></p><p>在实现的时候会首先写入 user 表，拿到主键的自增 id，然后再写入 book 表，自动将自增 id 填入&nbsp;author_id&nbsp;字段中，是不是比写 SQL 要简单很多？</p><p></p><h3>避免接口数量不断增长</h3><p></p><p></p><p>由于 JSONQL 的灵活性，它还可以避免前后端接口数量不断增长。</p><p></p><p>在专业开发中前后端通常使用 REST 协议进行交互，这时经常会遇到一个问题，那就是有些字段其实前端不需要，比如查询文章列表的接口，有时候我们只需要返回标题列表，有时候又想返回内容摘要，为了节省数据传输量，通常要用两个接口来实现，或者在接口上加个字段选择的功能，虽然项目发展，前后端接口会越来越多，甚至还出现了专门管理这些接口的 API 平台。</p><p></p><p>而在 JSONQL 方案下，数据查询的后端开发被彻底节省了，要查询什么信息前端自己构建 JSONQL 就行，不需要前后端接口约定，也不需要 API 接口文档及管理，前后端只需要一个接口。</p><p></p><p>这点和 GraphQL 要解决的问题是类似的，后面我们会单独介绍 GraphQL 和 JSONQL 的区别。</p><p></p><h3>简化分页查询</h3><p></p><p></p><p>常见的列表页除了查询数据，还需要返回页面总数，需要使用两个查询来实现</p><p><code lang=\"null\">SELECT * FROM table1 WHERE A = 1 ORDER BY name LIMIT 10 OFFSET 10\nSELECT COUNT(*) FROM table1 WHERE A = 1</code></p><p></p><p>JSONQL 简化了这个功能，只需要加上一个&nbsp;count配置就能实现类似功能</p><p><code lang=\"null\">{\n  \"statement\": \"SELECT\",\n  \"select\": [\"name\"],\n  \"from\": \"user\",\n  \"count\": true,\n  \"limit\": 10\n}</code></p><p></p><p>系统会自动去掉&nbsp;LIMIT/OFFSET&nbsp;及&nbsp;ORDER BY&nbsp;进行 COUNT 查询。</p><p></p><p>另外除了&nbsp;LIMIT/OFFSET&nbsp;及&nbsp;ORDER BY，如果有&nbsp;LEFT JOIN&nbsp;语句且对应的表是对一关系，这个&nbsp;LEFT JOIN&nbsp;对 COUNT结果不会有影响，也可以直接去掉。</p><p></p><h3>避免常见问题及更友好的错误提示</h3><p></p><p></p><p>不同数据库对 SQL 的支持不同，还会有奇怪问题，比如下面这个看起来毫无问题的 SQL</p><p><code lang=\"null\">SELECT id, date FROM table1;</code></p><p></p><p>在 Oracle 下会报两个错误：</p><p>ORA-00936: missing expressionORA-00933: SQL command not properly ended</p><p></p><p>你能看出是哪两个问题么？</p><p></p><p>这两个问题是：</p><p>date 是保留关键字必须加引号，不然就当成日期字面常量语法了date '2022-1-1'，这也是为什么报缺少表达式。结尾不能加分号，这是 Oracle 特有问题，不靠搜索引擎恐怕完全想不到。</p><p></p><p>在 JSONQL 中会自动解决，因为标识符会自动加引号，且在执行时自动去掉最后的分号。</p><p></p><p>另一方面是针对一些错误的写法，比如&nbsp;GROUP BY&nbsp;的字段不在 SELECT 中</p><p><code lang=\"null\">SELECT id FROM table1 GROUP BY type</code></p><p></p><p>JSONQL 内部解析的时候就会自动加上，变成</p><p><code lang=\"null\">SELECT id, type FROM table1 GROUP BY type</code></p><p></p><p>对于无法自动修复的场景会提供友好的报错信息，这样做的好处是报错信息是统一的，比起每个数据库千奇百怪的报错信息，JSONQL 给出的报错更易懂。</p><p></p><h3>同时支持 CRUD 及 BI 场景</h3><p></p><p></p><p>在绝大部分低代码平台中，CRUD 和 BI 往往是分开处理的，因为它们的前后端使用不同接口，毕竟 BI 查询的 SQL 往往特别复杂，很难使用 REST 形式表示。</p><p></p><p>但 JSONQL 可以完整支持大部分 SQL，因此在爱速搭里，CRUD 和 BI 的支持全都是用 JSONQL，避免了两次后端开发，简化了开发成本。</p><p></p><h3>支持多种数据库</h3><p></p><p></p><p>前面提到了 JSONQL 在易用性方面做的工作，接下来介绍在数据库支持方面的实现。</p><p></p><h3>关系数据库数据库方言</h3><p></p><p></p><p>虽然 SQL 有标准，但每个数据库的实现都不太一样，而且反而是国内最流行的 MySQL 其实最不符合标准，JSONQL 要支持大量数据库就得抹平这些方言差异，主要是这两个问题：</p><p>LIMIT/OFFSET 的写法不一致函数功能不一致</p><p></p><p>首先是 LIMIT/OFFSET 写法，这是最为突出的兼容性问题，一方面它非常重要，需要依赖它来做分页查询，另一方面它也是方言问题重灾区，许多数据库都发明了自己的写法，我知道的就有 15 种写法，有些数据库的写法特别繁琐，比如 SQL SERVER 2008。</p><p></p><blockquote>这个问题的根本原因是标准化太晚了，SQL 在 1974 年就有了，而 LIMIT/OFFSET 写法要等到 2011 年通过的 SQL:2008 规范才正式确定，这中间隔了 34 年，以至于标准的写法没几个数据库支持，反倒是 MySQL 简洁的 LIMIT OFFSET 写法最为流行。</blockquote><p></p><p></p><p>另一个差异点是函数支持，这里最为突出的是日期函数的支持，日期函数是 BI 查询的核心功能，比如想要按年聚合数据，查询每年的销售额，需要用到如下写法</p><p><code lang=\"null\">SELECT SUM(price), YEAR(date) from sales GROUP BY YEAR(date)</code></p><p></p><p>然而并不是所有数据库都支持 YEAR 函数，对应的替代函数可能有以下这些：</p><p>toYear(date)DATE_FORMAT_STR(date, 'YYYY')TIME_EXTRACT(date, 'year')to_number(to_char(date, 'yyyy'))CAST(strftime('%Y', date) AS INTEGER)DATEPART(year, date)</p><p></p><p>如果要输出更一致的效果，比如有些数据库输出月份前面不会补零，如果想保持输出结果一致，比如类似下面的提取年月的函数</p><p><code lang=\"null\">DATE_FORMAT(date, '%Y-%m')</code></p><p></p><p>需要转成</p><p><code lang=\"null\">CAST(DATEPART(year, date) as varchar) + '-' + CAST(RIGHT('0' + CAST(DATEPART(month, date) as varchar), 2) as varchar)</code></p><p></p><p>如果是要输出年月日时分秒的话。</p><p></p><p>要将所有不兼容函数都替换成方言版本是个非常费时的工作，需要查阅数据库官方文档里的 SQL 语法，而且同一个数据库的不同版本还不一样，为了保证结果正确，还得搭建这些数据库的测试环境来实际测试。我们另一款 BI 产品&nbsp;<a href=\"https://link.zhihu.com/?target=https%3A//cloud.baidu.com/product/sugar.html\">Sugar BI</a>\"&nbsp;也是花费了大量精力解决这个日期兼容性问题。</p><p></p><p>除了前面提到这两个，还有很多细节方言问题，比如字段类型、如何获取写入后的自增 id 等。</p><p></p><p>目前 JSONQL 底层引擎基于 JDBC 实现，可以连接市面上绝大部分数据库，目前已经支持 40+ 数据库，覆盖几乎所有国内开发者可能会使用的数据库，还包括大数据库相关的 Hive、Impala、Doris 等。</p><p></p><h3>对非关系型数据库的支持</h3><p></p><p></p><p>除了关系数据库，JSONQL 引擎还实现了对非关系型数据库的支持，使得 JSONQL 还可以对 MongoDB、Elasticsearch、Redis、HBase 及 OData 协议的数据库进行增删改查操作，这里分别介绍一下它们的实现原理。</p><p></p><h3>MongoDB</h3><p></p><p></p><p>MongoDB 的实现原理是转成了官方 Client 里的操作，比如&nbsp;select&nbsp;对应的是&nbsp;projection，where&nbsp;对应的是&nbsp;filter。</p><p></p><p>简单增删改查比较容易实现，最复杂的是聚合查询问题，比如&nbsp;group by，它的原理是转成&nbsp;<a href=\"https://link.zhihu.com/?target=https%3A//www.mongodb.com/docs/manual/core/aggregation-pipeline/\">Aggregation Pipeline</a>\"&nbsp;语句。</p><p></p><p>比如下面这个 SQL 语句</p><p><code lang=\"null\">SELECT SUM(transaction_count) AS sumResult\nFROM transactions\nGROUP BY account_id\nORDER BY sumResult DESC\nLIMIT 2</code></p><p></p><p>会转换先转成包含 pipeline 及 aggregate 的 json，然后再去执行 pipeline</p><p><code lang=\"null\">{\n  \"pipeline\": [{\n    \"$group\": {\n      \"sumResult\": {\n        \"$sum\": \"$transaction_count\"\n      },\n      \"_id\": {\n        \"account_id\": \"$account_id\"\n      }\n    }\n  }, {\n    \"$project\": {\n      \"sumResult\": \"$sumResult\",\n      \"_id\": 0\n    }\n  }, {\n    \"$sort\": {\n      \"sumResult\": -1\n    }\n  }, {\n    \"$limit\": 2\n  }],\n  \"aggregate\": \"transactions\"\n}</code></p><p></p><p>你可能知道MongoDB 官方有个&nbsp;<a href=\"https://link.zhihu.com/?target=https%3A//www.mongodb.com/docs/bi-connector/current/\">Connector for BI</a>\"&nbsp;工具可以实现类似功能，支持使用 SQL 查询 MongoDB，我们没有使用它，主要原因是：</p><p>Connector for BI 是属于企业版本 MongoDB 的一部分，开源版本只能试用。Connector for BI 不支持增删改操作，而我们需要完整支持 CUD 功能。</p><p></p><h3>Elasticsearch</h3><p></p><p></p><p>接下来是 Elasticsearch，它的原理是转成 REST 接口，比如查询转成&nbsp;_search&nbsp;接口，文档增删改转成&nbsp;_doc&nbsp;接口。</p><p></p><p>比如类似下面的 SQL 查询</p><p><code lang=\"null\">SELECT a FROM table1 WHERE b = 1 and c &gt; 2 ORDER BY d DESC LIMIT 3</code></p><p></p><p>会转成以下 JSON，然后调用&nbsp;/table1/_search&nbsp;进行查询</p><p><code lang=\"null\">{\n  \"query\": {\n    \"bool\": {\n      \"must\": [{\n        \"term\": {\n          \"b\": 1\n        }\n      }, {\n        \"range\": {\n          \"c\": {\n            \"gt\": 2\n          }\n        }\n      }]\n    }\n  },\n  \"sort\": [{\n    \"d\": {\n      \"order\": \"desc\"\n    }\n  }],\n  \"fields\": [{\n    \"field\": \"a\"\n  }],\n  \"size\": 3\n}</code></p><p></p><p>和 MongoDB 类似 Elasticsearch 官方也提供了 SQL 协议对接，我们没有使用它，主要原因是：</p><p>SQL 接口<a href=\"https://link.zhihu.com/?target=https%3A//github.com/elastic/elasticsearch/issues/30266\">不支持</a>\"查询&nbsp;_id&nbsp;字段，这对于实现增删改功能是必须的，不然就得要求数据里必须有个字段是唯一标识，导致了使用场景受限，比如在日志类场景下一般不会有唯一标识。SQL 接口是从 6.3 版本开始支持的，低版本无法使用，而 REST 接口可以支持到最早的 Elasticsearch 0.9 版本。</p><p></p><h3>Redis</h3><p></p><p></p><p>Redis 主要自由 kv 查询，所以支持它其实就是约定返回结果类型，比如下面的语句</p><p><code lang=\"null\">SELECT * FROM key1</code></p><p></p><p>对应的是&nbsp;GET key1&nbsp;命令，但根据值类型的不同会返回不同数据结构，比如简单字符串返回结果是</p><p></p><p>如果这个 key1 是个 list 结构，返回结果就将会是</p><p></p><p>同时 list 支持范围查询，类似如下的 SQL</p><p><code lang=\"null\">SELECT * FROM key1 WHERE range BETWEEN 0 AND 2</code></p><p></p><p>对应的就是&nbsp;LRANGE key 0 2&nbsp;命令。</p><p></p><p>其它还有 set、zset、hash 等类型也有特殊支持，就不展开了。</p><p></p><h3>OData</h3><p></p><p></p><p><a href=\"https://link.zhihu.com/?target=https%3A//www.odata.org/\">OData</a>\"&nbsp;是一种基于 REST 规范的数据查询协议，背后主要是微软在支持，国内还没见过有人用，它最大好处是提供了一种通用的数据对接方式，如果你自研了数据存储，就可以通过这个接口将数据查询功能暴露出来给其它服务使用。</p><p></p><p>因为本质是 REST 所以支持其实比较简单，就是转成了对应的 REST 接口，类似 Elasticsearch 的实现。</p><p></p><p>比如下面这个简单的查询</p><p><code lang=\"null\">SELECT FirstName, LastName\nFROM People\nWHERE FirstName = 'Vincent'\nORDER BY Concurrency DESC\nLIMIT 2 OFFSET 0</code></p><p></p><p>会转成以下 Query（这里为了方便查看进行了 URL 解码，实际发送是编码后的）</p><p><code lang=\"null\">/People?$skip=0&amp;$top=2\n&amp;$filter=FirstName eq 'Vincent'\n&amp;$orderby=Concurrency desc\n&amp;$select=FirstName, LastName</code></p><p></p><h2>性能优</h2><p></p><p></p><p>接下来介绍 JSONQL 里的性能优化，JSONQL 引擎针对许多慢查询场景提供了优化方案。</p><p></p><h3>大 offset 优化</h3><p></p><p></p><p>如果 offset 比较大会影响数据库性能，比如下面的 SQL</p><p><code lang=\"null\">SELECT film_id, description\nFROM film\nORDER BY title\nLIMIT 10 OFFSET 10000</code></p><p></p><p>数据库在执行的时候要首先读取一万条数据，然后再往后找 10 个，浪费了大量 IO 操作，因此 offset 越大性能越差。</p><p></p><p>针对 offset 较大的查询，JSONQL 引擎会进行 SQL 改写，改成如下写法</p><p><code lang=\"null\">SELECT film_id, description\nFROM film\n  INNER JOIN (\n    SELECT film_id\n    FROM film\n    ORDER BY title\n    LIMIT 10 OFFSET 10000\n  ) AS OFFSETOPT USING(film_id)</code></p><p></p><p>这个语句能实现同样功能，但它的性能更好，原因是在 OFFSET 查询的时候只选择了&nbsp;film_id&nbsp;字段，这是个主键字段，因此只需要遍历主键索引而无需读取数据，在获取了主键 id 后再去读取这些主键对应的数据，从而大幅减少了数据读取量。</p><p></p><h3>尽可能使用参数变量</h3><p></p><p></p><p>JSONQL 在执行的时候，会将变量都变成参数，比如类似如下语句</p><p><code lang=\"null\">SELECT * FROM table1 WHERE a = 'b' LIMIT 10 OFFSET 0</code></p><p></p><p>实际执行的时候会自动变成</p><p><code lang=\"null\">SELECT * FROM table1 WHERE a = ? LIMIT ? OFFSET ?</code></p><p></p><p>然后通过参数绑定的方式来执行，这样做的好处有两方面的好处：</p><p>避免 SQL 注入问题优化性能</p><p></p><p>为什么可以优化性能？因为上面的 3 个参数不管怎么变化都是同一条 SQL 语句，数据库在实现时就能直接复用这个解析及查询计划，无需再计算一次，在 Oracle、SQL Server 等数据库下会有更好性能。</p><p></p><p>不过参数变量的数量在有些数据库下有限制，比如 SQL Server 只支持&nbsp;<a href=\"https://link.zhihu.com/?target=https%3A//learn.microsoft.com/en-us/sql/sql-server/maximum-capacity-specifications-for-sql-server\">2100</a>\"&nbsp;个参数，超过之后就必须改成内嵌。</p><p></p><h3>高级缓存机制</h3><p></p><p></p><p>缓存是解决任何性能问题的终极办法，因此JSONQL 在语法上增加了缓存配置，可以控制过期时间。</p><p>除了过期时间，JSONQL 引擎还支持失效过期机制，在数据有变更的时候自动将相关缓存清空。</p><p></p><p>如何实现呢？最简单的是将相关表的所有缓存都删了，这是最简单的做法，也是 MySQL 之前&nbsp;<a href=\"https://link.zhihu.com/?target=https%3A//dev.mysql.com/doc/refman/5.7/en/query-cache.html\">Query Cache</a>\"&nbsp;的做法，但这种做法缓存命中率太低，所以在 MySQL 8 之后直接去掉了这个功能。</p><p></p><p>能不能更进一步优化呢？JSONQL 引擎由于有数据模型信息，知道主键是什么，因此对数据有更深入理解，可以实现更精确删除缓存，具体分两种情况：</p><p>增删改查场景BI 聚合查询场景</p><p></p><p>其中 BI 聚合查询场景比较复杂，想要精确知道某个数据修改是否会影响到缓存非常困难，因此无法实现。</p><p>增删改查场景就相对容易了，因为模型中有主键，所以查询到的数据后，引擎可以根据主键确认这个缓存都会设计那些行数据库，如果对应的数据有增删改操作，就能将对应行的缓存删除，避免了表级别粒度的命中率太低问题。</p><p></p><p>但这要求所有数据变更都用 JSONQL，如果有应用不使用 JSONQL 就无法感知了，只能通过自动分析 binlog 来感知数据库变更。</p><p></p><p>如果你觉得缓存有风险，JSONQL 还可以单独针对 count 加缓存。</p><p></p><p>对于一个常见的列表页，我们除了查询前十条记录，还需要查询总数，也就是类似如下的语句</p><p><code lang=\"null\">SELECT count(*) FROM table1</code></p><p></p><p>在 MySQL InnoDB 下，这个 count 查询的性能会随着表中数据量的变多越来越慢，几百万行数据后可能就变成秒级别了，因此这个语句对系统负担很重。</p><p></p><p>而有时候我们并不需要绝对准确的数据，毕竟一千万零一和一千万零二区别不大，因此可以单独针对 count 开启缓存，这样既能保证性能，又不担心数据缓存过期问题。</p><p></p><h3>乐观锁</h3><p></p><p></p><p>出于性能和安全考虑，JSONQL 下不提供排它锁支持，无法使用&nbsp;SELECT FOR UPDATE&nbsp;语句。</p><p></p><p>但提供了另一种被称为乐观锁的机制，可以设置模型的某个字段为版本号，更新的时候会将这个版本号加入条件，比如</p><p><code lang=\"null\">UPDATE user SET name = 'jsonql', version = version + 1 WHERE id = 1 and version = 1</code></p><p></p><h3>减少行锁冲突</h3><p></p><p></p><p>有时候我们可能需要频繁更新某个数据，比如</p><p><code lang=\"null\">UPDATE pageview set views = views + 1 where page_id = 1</code></p><p></p><p>在高并发场景下，比如某个页面的 QPS 很高会导致严重锁冲突，针对这个问题有个小技巧是增加一个随机字段，将一行锁变成多行锁，比如改成如下语句</p><p><code lang=\"null\">INSERT INTO pageview (page_id, random, views)\nVALUES (1, FLOOR(RAND() * 100), 1) ON DUPLICATE KEY\nUPDATE views = views + 1;</code></p><p>这样做就将锁冲突概率减小了 100 倍，但要实现这个功能比较麻烦，ON DUPLICATE KEY 语句 和 RAND 都有数据库方言问题，因此 JSONQL 引擎内置了这种特殊情况的支持，只要配置后就自动支持。</p><p></p><h3>支持分库分表</h3><p></p><p></p><p>当数据量增长到亿级别时，单个数据库将很难支持，这时除了切换为分布式数据库以外，还有许多公司使用分库分表来支持，但分库分表会影响查询，导致业务代码复杂。</p><p></p><p>JSONQL 底层引擎通过引入&nbsp;<a href=\"https://link.zhihu.com/?target=https%3A//shardingsphere.apache.org/\">ShardingSphere</a>\"&nbsp;项目支持了自动分表分库，在实际使用时可以当成一个表来使用。</p><p></p><h3>性能统计和控制</h3><p></p><p></p><p>JSONQL 引擎内置了性能统计功能，会统计语句执行性能，提供性能报告方便分析。</p><p></p><p>同时为了防止慢查询影响性能，还可以临时对某语句进行控制，比如</p><p>强制开启缓存，减低对数据库影响禁用这个语句</p><p></p><h3>金额类型特殊优化</h3><p></p><p></p><p>由于浮点数是不精确的，针对金额字段通常需要使用定点数，但定点数没有硬件加速支持，在数据库中都是软件实现的，效率不高。</p><p></p><p>JSONQL的增加了一种数据类型，就叫金额，它实际使用整数存储，读出来后自动转成小数，整数计算的性能远比定点数高，所以能提升性能。</p><p></p><p>但缺点是在除法运算时会丢失精度，因为有可能算出的结果小于分，比如定点数即便小数位是 2，在计算除法时输出结果还会变成 3 位，比如，比如&nbsp;0.01/2&nbsp;变成&nbsp;0.005，但如果是使用分作为单位，就变成&nbsp;0&nbsp;了，所以如果数据量不太还是更推荐用定点数。</p><p></p><h3>随机值返回的优化</h3><p></p><p></p><p>有时我们想随机从数据库里取个值</p><p><code lang=\"null\">SELECT * FROM table1 ORDER BY rand() LIMIT 1</code></p><p></p><p>这个语句在执行的时候需要将所有数据都进行一次排序，再取第一条，数据量较大的时候还会使用临时表或文件存储，对系统性能影响较大。</p><p></p><p>针对这种情况设计了个特殊语法，实现的时候先 count 总数，然后算个随机数 xxx，再通过下面语句来获取</p><p><code lang=\"null\">SELECT * FROM table1 LIMIT xxx, 1</code></p><p></p><p>但这个优化必须没有 WHERE 条件，限制比较大。</p><p></p><h2>安全性有保障</h2><p></p><p></p><p>前面介绍了 JSONQL 在灵活性、易用性及性能方面的功能，可以看到它拥有和 ORM 一样的易用性，同时又能做到和手写 SQL 一样的灵活性，因此 JSONQL 可以覆盖大部数据增删改查的后端开发工作，彻底降低这部分的研发成本。</p><p></p><p>但还有一个重要的问题没解决，那就是如何保证安全？JSONQL 相当于将 SQL 能力赋予了前端，但也意味着 SQL 注入及越权访问的风险，如果这个问题不解决，这个方案就彻底没法用，前面提到的所有功能都是浮云。</p><p></p><p>JSONQL 如何解决呢？主要有以下几点：</p><p>后台 JSONQL 模式数据模型控制支持数据验证禁止原始 SQL限制部分语句细粒度权限控制避免误更新或误删数据脱敏防止 DDOS</p><p></p><p>接下来分别介绍这些功能。</p><p></p><h3>后台 JSONQL 模式</h3><p></p><p></p><p>对于安全性要求较高的场景，JSONQL 可以不直接暴露给前端，而是只在后台使用，这就彻底杜绝了用户任意构造 JSONQL 进行查询的能力，因此安全性和专业开发是一样的。</p><p></p><p>这种模式叫后台 JSONQL 模式，JSONQL 不是前端动态生成，而是预先编写好的，比如在页面开发的时生成 JSONQL，实际查询的时前端只传递变量，比如在开发时存储了下面这段 JSONQL</p><p><code lang=\"null\">{\n  \"statement\": \"select\",\n  \"select\": [\"name\"],\n  \"from\": \"table1\",\n  \"where\": {\n    \"name\": \"${name}\"\n  }\n}</code></p><p></p><p>这段 JSONQL 等价于</p><p><code lang=\"null\">SELECT name FROM table1 WHERE name = ${name}</code></p><p></p><p>前端实际发起请求的时候是类似下面的 api 地址</p><p><code lang=\"null\">GET /api?name=amis</code></p><p></p><p>这和专业开发是一样的，前端只能传递部分变量，而后端 JSONQL 引擎会根据这个变量做替换，如果前端不传递这个变量，比如请求</p><p><code lang=\"null\">GET /api</code></p><p></p><p>引擎会自动去掉过滤条件，将查询变成</p><p><code lang=\"null\">SELECT name FROM table1</code></p><p></p><p>如果想支持默认值该怎么办呢？可以这样写</p><p><code lang=\"null\">{\n  \"statement\": \"select\",\n  \"select\": [\"name\"],\n  \"from\": \"table1\",\n  \"where\": {\n    \"name\": \"${name || 'amis'}\"\n  }\n}</code></p><p></p><p>其实&nbsp;${}&nbsp;里是个表达式引擎，这里是实现了和 amis 一样的表达式引擎，原理是基于 antlr4 实现的语法树遍历解释器，语法主要参考 JavaScript，可以支持四则运算、函数嵌套调用等功能，为什么不直接用 JavaScript 语法？因为嵌入 JavaScript 引擎性能较差且有安全性问题。</p><p></p><p>同时为了提升这个模式下的灵活性，在 JSONQL 语法中还增加了一种动态结构语法，比如下面的语句</p><p><code lang=\"null\">{\n  \"statement\": \"select\",\n  \"select\": [\n    {\n      \"if\": [\n        {\n          \"test\": \"a == 1\",\n          \"body\": {\n            \"column\": \"xx\",\n            \"func\": \"DATE_FORMAT\",\n            \"arg\": \"YYYY-MM\"\n          }\n        },\n        {\n          \"test\": \"a == 2\",\n          \"body\": {\n            \"column\": \"yy\"\n          }\n        }\n      ]\n    }\n  ],\n  \"from\": \"xxx\"\n}</code></p><p></p><p>当前端传递&nbsp;GET /api?a=1&nbsp;的时候，上面 JSONQL 会转成如下格式</p><p><code lang=\"null\">{\n  \"statement\": \"SELECT\",\n  \"select\": [\n    {\n      \"column\": \"xx\",\n      \"func\": \"DATE_FORMAT\",\n      \"arg\": \"YYYY-MM\"\n    }\n  ],\n  \"from\": \"xxx\"\n}</code></p><p></p><p>等价的 SQL 是</p><p><code lang=\"null\">SELECT DATE_FORMAT(xx, 'YYYY-MM') from xxx</code></p><p></p><p>如果前端传递&nbsp;GET /api?a=2，上面 JSONQL 就会变成</p><p><code lang=\"null\">{\n  \"statement\": \"select\",\n  \"select\": [{\n    \"column\": \"yy\"\n  }],\n  \"from\": \"xxx\"\n}</code></p><p></p><p>可以看到我们不仅能改变某个值，还能改变语句本身，从而实现复杂场景的支持。</p><p></p><p>除了&nbsp;if&nbsp;语句外，还有&nbsp;choose&nbsp;语句实现循环功能，熟悉 MyBatis 的读者可能会发现和 MyBatis 非常像，这里确实是参考了 MyBatis 的命名，也使得 JSONQL 拥有不亚于 MyBatis 的灵活性。</p><p></p><p>后台 JSONQL 模式在安全性上和专业开发一致，除此之外 JSONQL 引擎还提供了大量机制来保证安全性，使得可以让前端直接发起动态 JSONQL调用，下面会分别介绍这些机制。</p><p></p><h3>数据模型控制</h3><p></p><p></p><p>在前面的所有例子中，虽然看起来是查询某个表，但在 JSONQL 实际使用时，其实查询的是预先定义的数据模型，比如最开始举的例子。</p><p><img src=\"https://static001.infoq.cn/resource/image/4e/f5/4ee1092cb652fcf3fee7ce33f37dbcf5.png\" /></p><p></p><p>以其中的左侧模型&nbsp;user&nbsp;为例，它的模型定义类似如下 JSON 表示（省略了很多，比如关联关系定义）</p><p><code lang=\"null\">{\n  \"key\": \"user\",\n  \"name\": \"用户\",\n  \"fields\": [{\n    \"type\": \"int\",\n    \"key\": \"id\",\n    \"name\": \"id\",\n    \"isPrimaryKey\": true,\n    \"isGenerated\": true\n  }, {\n    \"type\": \"text\",\n    \"key\": \"name\",\n    \"name\": \"名称\"\n  }, {\n    \"type\": \"int\",\n    \"key\": \"age\",\n    \"name\": \"年龄\"\n  }]\n}</code></p><p></p><p>其中最顶层的 key 名相当于表名，而&nbsp;fields&nbsp;里的字段相当于列。</p><p></p><p>在进行 JSONQL 查询的时候，比如下面这个语句</p><p><code lang=\"null\">SELECT * FROM user</code></p><p></p><p>执行的时候会展开为</p><p><code lang=\"null\">SELECT id, name, age FROM user</code></p><p></p><p>即便原始数据库的 user 表有很多其它字段，只要这个字段没在模型定义里就没法查，如果遇到类似下面的 SQL 会直接报错，因为在模型定义里没有这个字段</p><p><code lang=\"null\">SELECT password FROM user</code></p><p></p><p>同样也没法查询没定义的模型，比如</p><p><code lang=\"null\">SELECT * FROM information_schema.tables</code></p><p></p><p>因为我们的模型定义里没有&nbsp;information_schema.tables这个模型，所以上面的查询会报模型不存在。</p><p></p><p>有了数据模型这一层限制，就可以有效避免查询任意表及字段，限制了查询范围。</p><p></p><h3>禁止原始 SQL</h3><p></p><p></p><p>JSONQL 可以表达大部分 SQL 语法，因此 JSONQL 无需支持原始 SQL形式，所有 SQL 都需要先转成 JSONQL 结构才能使用。</p><p></p><p>举个例子，SQL 语句在很多地方都支持表达式，比如在字段上使用，类似下面的语句中的第二行表达式</p><p><code lang=\"null\">SELECT customer_id\n    ,max(case when fruit = 'apple' and quantity &gt; 5 then 1 else 0 end) as loves_apples\nFROM order\nGROUP BY 1</code></p><p></p><p>要用结构化的代码构造第二行表达式写起来比较复杂，很多 ORM 框架及查询 DSL 会在这里支持写原始 SQL，框架不对这个字符串进行二次处理，在生成 SQL 的时候直接原样输出。</p><p></p><p>原始 SQL 的问题是对框架来说是个黑盒，完全不知道里面用到了什么函数，查询了哪些字段，而 JSONQL 中的实现是先转成结构化数据，前面的 SQL 可以用如下 JSONQL 表示</p><p><code lang=\"null\">{\n  \"select\": [{\n    \"column\": \"customer_id\"\n  }, {\n    \"exp\": \"max(case when fruit = 'apple' and quantity &gt; 5 then 1 else 0 end)\",\n    \"as\": \"loves_apples\"\n  }],\n  \"statement\": \"SELECT\",\n  \"from\": \"order\",\n  \"groupBy\": [{\n    \"val\": 1\n  }]\n}</code></p><p></p><p>看上去想使用了原始 SQL，但实际不是，引擎底层实现的时会先转换为如下 JSONQL</p><p><code lang=\"null\">{\n  \"select\": [{\n    \"column\": \"customer_id\"\n  }, {\n    \"args\": [{\n      \"cases\": [{\n        \"then\": 1,\n        \"when\": {\n          \"children\": [{\n            \"op\": \"=\",\n            \"left\": {\n              \"column\": \"fruit\"\n            },\n            \"right\": \"apple\"\n          }, {\n            \"op\": \"&gt;\",\n            \"left\": {\n              \"column\": \"quantity\"\n            },\n            \"right\": 5\n          }],\n          \"operator\": \"and\"\n        }\n      }],\n      \"else\": 0\n    }],\n    \"func\": \"max\",\n    \"as\": \"loves_apples\"\n  }],\n  \"statement\": \"SELECT\",\n  \"from\": \"order\",\n  \"groupBy\": [{\n    \"val\": 1\n  }]\n}\n</code></p><p></p><p>可以看到所有 SQL 都进行了结构化处理，这使得JSONQL 引擎可以准确分析出用到了那些语句、函数、查询了哪些字段，配合后面提到的权限控制机制，就能做到即便 JSONQL 完全暴露给前端使用，恶意用户无论怎么构造 JSONQL 也无法越过权限控制。</p><p></p><p>由于 SQL 的灵活性，实际实现时这里有很多细节问题需要处理，比如类似下面的写法</p><p><code lang=\"null\">SELECT u.id FROM table1 u</code></p><p></p><p>第一个&nbsp;u.id&nbsp;在 SQL 解析的时候时没法区分 u 到底是表名还是别名，因此需要在解析后二次处理，通过上下文确认实际表名是什么，类似情况还有在子查询、JOIN、WITH 语句里也能写别名。</p><p></p><p>你可能会说别名很少用，直接不支持就好了，但有些场景下必须用别名，比如 FROM 语句使用子查询时必须有别名，还有涉及到多个相同表进行 JOIN 的时候必须有别名来区分，比如有个&nbsp;staff&nbsp;员工表，其中有个字段是这个员工的上级leader_id，它指向另一行&nbsp;staff&nbsp;表里数据，如果要同时查询员工及其上级，就需要对这个&nbsp;staff表进行 JOIN，这时必须用别名来区分，比如</p><p><code lang=\"null\">SELECT staff.name, leader.name \nFROM staff \nJOIN staff leader ON staff.leader_id = leader.id</code></p><p></p><p>禁止 SQL 的主要缺点是导致 JSONQL 对数据库扩展语法支持不好，比如 Postgres 的列支持数组类型，可以使用下面语法查询二维数组里的值</p><p><code lang=\"null\">SELECT schedule[1:2][1:1] FROM sal_emp;</code></p><p></p><p>目前 JSONQL 还没有对应的结构表示导致无法使用，需要后续扩展，但扩展起来倒是比较容易。</p><p></p><h3>不支持部分语句</h3><p></p><p></p><p>虽然 JSONQL 支持大部分 SQL 语句转换，但有些功能不方便权限检查以及有严重安全问题，所以就直接不支持了，比如</p><p>DDL 相关的语句，这个没必要暴露给前端数据库管理语句，比如授权的 GRANT 语句等创建存储过程</p><p></p><p>另外就是针对表名和字段名都默认做了限制，比如不允许出现分号、引号等特殊字符，也避免了引擎内部实现遗漏时导致 SQL 注入问题。</p><p></p><h3>细粒度权限控制</h3><p></p><p></p><p>前面提到 JSONQL 中没有原始 SQL，使得底层引擎可以准确分析出查询了哪些字段，这使得 JSONQL 能够实现细粒度权限控制，目前支持以下 4 种粒度的权限控制：</p><p>表级别，如果没有某个表权限，那也没法 join，这种情况直接报错返回无权限。行级别权限，自动在对应的表上加行过滤条件 。列级别权限，在查询字段的时候自动删掉无权限的字段，如果这个字段是 join 所需的就只有 join on 上保留。表达式权限，比如对一个字段取&nbsp;MAX，同时设置GROUP BY&nbsp;的值，在这个权限设置下就只能查询这个字段的总数，无法查看明细，比如能查询公司总收入，但无法知道每个部门的收入分别是多少。</p><p></p><p>权限相关的配置采用类似如下格式</p><p><code lang=\"null\">{\n  //表名\n  \"table1\": {\n    // 表级别的写入权限\n    \"canInsert\": true,\n    // 列权限配置\n    \"field\": {\n      // 代表所有字段\n      \"*\": [\"select\", \"update\"],\n      // 针对某个字段\n      \"fild1\": [\"select\", \"update\"]\n    },\n    // 表达式权限，这里就只有读，因此是个数组\n    \"fieldSelectExp\": [\"SUM(fieldKey)\"],\n    // 行级别权限配置，针对查、改、删分别配置\n    \"filters\": {\n      \"select\": {},\n      \"update\": {},\n      \"delete\": {}\n    }\n  }\n}</code></p><p></p><p>列级别的配置使得你无法选择自己没权限的列，如果使用下面的 JSONQL 进行查询时</p><p><code lang=\"null\">{\n  \"statement\": \"SELECT\",\n  \"select\": [\"*\"]\n  \"from\": \"user\"\n}</code></p><p></p><p>最终生成 SQL 语句会数据模型配置及权限进行展开，变成</p><p><code lang=\"null\">SELECT name, age FROM user</code></p><p></p><p>也就是只选择模型中已经定义的列及自己有权限的列，如果主动查询没权限的字段会报权限不足。</p><p></p><p>这里还能做些有意思的扩展，比如下面的写法</p><p><code lang=\"null\">{\n  \"statement\": \"SELECT\",\n  \"select\": [\"*\", \"!content\"]\n  \"from\": \"blog\"\n}</code></p><p></p><p>意思是查询除了&nbsp;content&nbsp;之外的所有列，这样后续增加其它字段就自动支持了，这是 SQL 语句无法实现的功能。</p><p></p><p>不过也不是所有情况都能展开，如果 FROM 是子查询就不可以</p><p><code lang=\"null\">SELECT * FROM (SELECT name FROM user) u</code></p><p></p><p>行级别的权限配置是在&nbsp;filters&nbsp;下，这里针对查、改、删是独立的，常见的场景是我可以查询所有用户的信息，但我只能更新自己的信息，因此使用类似如下语句的 JSONQL 进行更新的时候</p><p><code lang=\"null\">UPDATE user set name = 'amis'</code></p><p></p><p>实际执行的 SQL 是</p><p><code lang=\"null\">UPDATE user set name = 'amis' WHERE user_id = xxx</code></p><p></p><p>行级别过滤条件是后添加的，用户无法控制，比如写了个</p><p><code lang=\"null\">UPDATE user set name = 'amis' WHERE 1=1 or 2=2</code></p><p></p><p>最终执行会变成</p><p><code lang=\"null\">UPDATE user set name = 'amis' WHERE (1=1 or 2=2) and user_id = xx</code></p><p></p><p>因此 JSONQL 引擎底层的权限控制彻底杜绝了水平越权问题，只要配置好权限，无论前端怎么构造 JSONQL 请求也无法绕过行列级别的控制，保证了 JSONQL 可以直接暴露给前端使用。</p><p></p><p>另外行级别权限控制还能用来支持另外两个重要功能：软删除和多租户，对软删除的支持就是在删除时只是更新删除时间字段而不是真删除，而在查询时加上时间不为 NULL，比如</p><p><code lang=\"null\">SELECT\n  \"author\".\"id\",\n  \"author\".\"name\"\nFROM\n  \"author\"\nWHERE\n  \"author\".\"deleted_at\" IS NULL</code></p><p></p><p>而多租户就是在查询时自动加上租户 ID。</p><p></p><h3>避免误批量更新或删除大量数据</h3><p></p><p></p><p>前面提到可以通过权限来避免更新和删除自己没权限的内容，如果无法阻止有权限用户的误删问题，比如管理员不小心执行了下面的语句</p><p><code lang=\"null\">DELETE FROM user</code></p><p></p><p>就直接将所有数据都删了，默认情况下 JSONQL 不允许不带 WHERE 的语句执行，上面的预计无法支持，但这个限制很容易绕过，比如随便加个肯定是真的条件</p><p><code lang=\"null\">DELETE FROM user WHERE id &gt; 0</code></p><p></p><p>为了解决这个问题，还可以配置 UPDATE 和 DELETE 里必须有主键等于的条件（id = xx），这时引擎会就不允许前面的语句执行，当然下面的语句也是不允许的，主键等于必须在最顶层且和其它条件是 AND 连接</p><p><code lang=\"null\">DELETE FROM user WHERE id = xx OR 1 = 1</code></p><p></p><p>通过这种模式可以避免误更新和删除大量数据。</p><p></p><p>但攻击者还是能通过写个循环来遍历所有id，因此还需要下面的功能。</p><p></p><h3>自动Hash id</h3><p></p><p></p><p>在设计表结构时，我们一般会使用自增id来当成主键，但这导致了两个问题：</p><p>暴露总数，因为新增一个就知道目前最大值是什么，通过id就知道你有多少注册用户数了。遍历攻击，如果有接口出现越权漏洞，攻击者就能写个简单的循环遍历所有数据。</p><p></p><p>有个解决办法是不使用自增id作为主键，比如使用UUID，这对基于 LSM 实现的 NewSQL 分布式数据库比较友好，但对于MySQL 这种单机数据库却会影响写入性能，因为MySQL InnoDB 是按主键的 B 树来组织数据的，UUID 的随机性导致经常要在已经写入的两个数据间插入新数据，造成随机读写。</p><p></p><p>另一个办法是使用<a href=\"https://link.zhihu.com/?target=https%3A//hashids.org/\">Hash id</a>\"，但这种做法对业务侵入性较强，因为所有使用到id的地方都得注意对id的编码和解码，开发起来麻烦还容易遗漏。</p><p></p><p>为了简化开发，JSONQL 引擎内置了对 Hash id 的支持，在模型设计的时可以对主键开启Hash id 功能，这时主键的输出结果会自动进行Hash id 编码，而进行查询的时候会进行 Hash id 解码。</p><p></p><p>但因为 SQL 的复杂性，有时候虽然能判断字段使用到了主键，也不知道输出结果是不是主键，比如</p><p><code lang=\"null\">SELECT (id * 0) + 1 FROM table1</code></p><p></p><p>虽然查询字段有主键，但实际上输出结果是 1，如果对这个结果也进行 Hash id 编码会有问题，因为攻击者可以通过遍历来构造，比如</p><p><code lang=\"null\">SELECT (id * 0) + 1 FROM table1\nSELECT (id * 0) + 2 FROM table1\n...\nSELECT (id * 0) + 100000 FROM table1</code></p><p></p><p>这样就能拿到10 万个 id 值对应的 Hash id，后续就能通过这些 Hash id 来反查真实 id，也被称为彩虹表攻击。</p><p></p><p>除了上面的例子还有很多其他可能情况，为了避免这个问题，JSONQL 引擎在开启 Hash id 时主键就只允许查询字段，不允许使用四则运算及函数调用等功能。</p><p></p><h3>数据脱敏</h3><p></p><p></p><p>和前面 Hash id 类似的功能是数据脱敏，可以针对某些字段设置脱敏，这些字段在输出的时候会进行脱敏处理，比如手机号自动隐藏中间内容。</p><p></p><p>另外就是有些字段只能写入不能查询，比如密码字段。</p><p></p><h3>性能白名单模式</h3><p></p><p></p><p>前面提到权限控制解决了安全性问题，但攻击者依然能够通过构造复杂的语句来拖慢系统性能（也被称为 CC 攻击），主要有以下几方面：</p><p>查询太多数据，比如不加 limit 导致变量全表，这个很好解决，可以配置强制最大 limit 数量，如果超过就不允许，同时 offset 过大也会影响性能，也可以配置最大数量。JOIN 太多表，这主要是关联查询导致的，关联查询依赖 JOIN，如果使用深层关联查询就需要 JOIN 许多表，比如一个多对多关系就要 JOIN 两张表。因此需要支持配置 JOIN 数量限制。使用某些语句导致无法使用索引，比如&nbsp;SELECT * from table WHERE MONTH(date) = 12&nbsp;，这个语句即便 date 字段加了索引也没法使用，因为实际查询是经过某个函数后的值，这和索引中的值并不匹配，因此这样的语句只能遍历全表，除非在创建索引时用的就是&nbsp;MONTH(date)。ORDER BY 的字段必须要能用上索引，包括字段顺序、排序方向的一致性。</p><p></p><p>对于数据量较大的表，为了避免性能风险，JSONQL 引擎支持高性能白名单模式，在这个模式下就只能进行最基本的增删改查操作，限制 LIMIT 及 JOIN 数量，所有 WHERE 条件及 ORDER 字段必须使用索引字段且无法使用函数，禁止 GROUB BY 语句，字段函数只支持几种常用的，如果再配合 Nginx 之类的反向代理基于 IP 限制 QPS，就能保证恶意用户无法通过构造复杂 JSONQL 来进行 CC攻击。</p><p></p><h3>支持数据验证</h3><p></p><p></p><p>后端写入和更新数据有时候需要对数据进行验证，JSONQL 支持数据校验，而且使用和&nbsp;<a href=\"https://link.zhihu.com/?target=https%3A//aisuda.bce.baidu.com/amis/zh-CN/components/form/formitem%23%25E6%25A0%25BC%25E5%25BC%258F%25E6%25A0%25A1%25E9%25AA%258C\">amis</a>\"&nbsp;一样的数据校验配置。</p><p></p><p>这样做的好处是同样的配置可以直接用于前后端，无需像专业开发那样前后端都分别进行配置。</p><p></p><p>具体配置就不展开了，可以参考 amis 文档，比如对数字的验证是如下配置</p><p><code lang=\"null\">{\n  \"validations\": {\n    \"isNumeric\": true,\n    \"minimum\": 10\n  },\n  \"validationErrors\": {\n    \"isNumeric\": \"请输入数字\"\n  }\n}</code></p><p></p><p>数据校验机制保证了用户无法通过构造请求的方式来绕过前端验证，保证了数据准确性。</p><p></p><h2>你可能想问的问题</h2><p></p><p></p><h3>和 GraphQL 的区别是什么？</h3><p></p><p></p><p>总结一下主要区别是：</p><p>GraphQL 的抽象程度更高，它设计理念就是从业务出发，不关心具体实现，JSONQL 相对来说更底层，使用者对 SQL 越了解用得越好，需要关注具体实现，比如针对 N+1 问题提供了两种语法来让用户选择。GraphQL 不自带实现，需要自己实现或使用第三方引擎，这些引擎的实现参差不齐，对数据库的支持不全，JSONQL 还包括了底层引擎实现，支持大量常见数据库。JSONQL 灵活性更强，很多地方可以使用复杂表达式，覆盖绝大部分 SQL 语句。GraphQL 依赖自定义的 DSL 语言，前后端都需要使用 SDK 才能方便生成，JSONQL 本身就是 JSON，无需 SDK。GraphQL 难以表示树形结构，JSONQL 原生支持。GraphQL 对底层数据存储没有要求，JSONQL 只能对接关系型数据库或 MongoDB 等底层引擎支持的数据存储，如果是自定义存储需要使用 OData 协议对接。</p><p></p><p>因为 JSONQL 的能力可以完全覆盖 GraphQL，所以还能将 GraphQL 转成 JSONQL，比如下面的 GraphQL 查询</p><p><code lang=\"null\">{\n  blog(id: \"1000\") {\n    title\n    user {\n      name\n    }\n  }\n}</code></p><p></p><p></p><p>可以转换成等价的 JSONQL 查询</p><p><code lang=\"null\">{\n  \"statement\": \"select\",\n  \"select\": [\"title\", \"user.name\"]\n  \"from\": \"blog\",\n  \"where\": {\n    \"id\": \"1000\"\n  }\n}</code></p><p></p><p>但对于复杂的过滤条件，由于 GraphQL 没有规定标准写法导致难以适配，比如想做字段大于的过滤，在 Hasura 里用的是类似 MongoDB 的语法</p><p><code lang=\"null\">query {\n  movies (where: {rating: {_gt: 4}}) {\n    id\n    name\n  }\n}</code></p><p></p><p>而 Prisma 用的是字段后面加&nbsp;_gt&nbsp;约定</p><p><code lang=\"null\">query {\n  movies (where: {rating_gt: 4}) {\n    id\n    name\n  }\n}</code></p><p></p><p>还有 limit、offset、orderBy 及聚合查询等功能都没有标准写法，导致了 GraphQL 很容易被实现绑定，不具备可移植性。</p><p></p><h3>和直接用 SQL 的区别是什么？</h3><p></p><p></p><p>主要有这几方面：</p><p>支持关联查询，尤其是多层级关联查询用 SQL 写起来很复杂，参考前面关联查询的介绍。JSONQL 有更严格的安全检查，参考前面的安全性保障，类似行列级别权限的控制都是自动的，无需自己在 SQL 里加条件判断。JSONQL 会改写 SQL 进行性能优化，比如前面提到的大 OFFSET、随机值等场景。JSONQL 是 JSON，前端生成比较容易，而拼接SQL 字符串容易出错。</p><p></p><h3>如何实现复杂业务逻辑？</h3><p></p><p></p><p>有时候不仅是数据查询，还需要一些特殊的业务逻辑处理，比如需要对数据进行二次加工后再输出，或者再调用另一个 API 获取其它数据再进行聚合，这时单纯使用 JSONQL 就不够了，我们的做法是有另一个服务编排的功能实现，它具备查询数据、发起 API 请求、循环、分支、自定义代码等功能，可以用来实现简单的业务逻辑。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/9f/b6/9ffc5277d7a44d6fbf1afc3c57df4cb6.png\" /></p><p>爱速搭里的服务编排功能</p><p></p><p>但如果是非常复杂的业务逻辑，比如涉及到复杂的算法，我更推荐写代码实现，这方面没有任何可视化工具能简化，我见过的所有方案屏幕利用率都极低，展现凌乱还不如代码看起来简洁。</p><p></p><h3>说了这么多优点，有缺点么？</h3><p></p><p></p><p>因为基本上是 SQL 子集，所以缺点是开发时没有强类型保护，只提供了JSON Schema 检查，没法做到 ORM 框架那样的强类型检查。</p><p></p><p>但相应的，不需要写代码使得无需编译，可以进行实时查询，特别适合低代码平台。</p><p></p><h2>总结</h2><p></p><p></p><p>最后总结一下，本文最开提到了现有方案无法同时满足易用性和灵活性问题，而 JSONQL 则同时做到了这两点：</p><p>在易用性方面 JSONQL 基于 JSON 格式，前端可以很方面生成，同时还支持 SQL 解析，使得只需要了解 SQL 就能使用，而且支持关联查询，可以轻松构建出复杂结构的查询。在灵活性方面 JSONQL 支持深层嵌套，可以覆盖绝大部分 SQL 场景，在灵活性方面等同于写 SQL ，因此能支撑复杂应用的开发。</p><p></p><p>同时 JSONQL 还能自动优化性能，并解决了安全问题，使得它甚至可以直接给前端使用，相当于将 SQL 能力赋能给了前端，意味着许多时候前端自己就能完成所有开发，避免了接口沟通成本，也节省了增删改查类场景的后端开发。</p><p></p><p>作者简介</p><p></p><p>吴多益，百度智能云爱速搭低代码平台架构师。</p><p></p><p>低代码到底是解决研发困局的银弹或是炒作起来的泡沫？2023年2月6-7日，<a href=\"https://gmtc.infoq.cn/202302/beijing/schedule?utm_source=infoq&amp;utm_medium=article&amp;utm_campaign=full&amp;utm_term=0111&amp;utm_content=wuduoyi\">GMTC全球大前端技术大会（北京站）</a>\"携手百度 FEX 前端团队资深成员、低代码方向技术专家<a href=\"https://gmtc.infoq.cn/202302/beijing/track/1355?utm_source=infoq&amp;utm_medium=article&amp;utm_campaign=full&amp;utm_term=0111&amp;utm_content=wuduoyi\">潘征</a>\"，邀请到在低代码方向有深度实践的分享者，为大家分享低代码方向的规划和实际落地经验，如基于<a href=\"https://gmtc.infoq.cn/202302/beijing/track/1355?utm_source=infoq&amp;utm_medium=article&amp;utm_campaign=full&amp;utm_term=0111&amp;utm_content=wuduoyi\"> LowCodeEngine 的阿里低代码组件体系的建设和实践、中国工商银行低代码可视化建设探索与实践、数字内容体验平台：不止低代码、零代码到低代码：百度多端小程序制作平台探索与实践</a>\"，希望能帮助大家在热潮中以更客观的立场找到适合自身的正确方向。</p><p></p>",
    "publish_time": "2023-01-11 17:14:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]