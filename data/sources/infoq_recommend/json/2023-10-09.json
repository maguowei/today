[
  {
    "title": "架构师（2023 年 10 月）",
    "url": "https://www.infoq.cn/article/iQmQtIBAaWc3w3BDhdqV",
    "summary": "<h2>卷首语：大模型重新定义软件开发，将带来哪些改变？</h2>\n<p><strong>作者 | 凌敏</strong></p>\n<p>去年以来，以 ChatGPT 为代表的 AI 大模型火爆出圈，并掀起了一场全领域的效率革命。软件开发亦在其中。</p>\n<p>在软件开发中，大模型的应用越来越广泛。凭借强大的表示能力和泛化性能，大模型正在催生软件工程的新范式，作为催化剂和创新引擎正在开启软件研发和创新效能的倍增，甚至带来指数级提升的可能。</p>\n<p>在自然语言处理领域，OpenAI 的 GPT 系列模型具有强大的语言生成和推理能力，被广泛应用于文本生成、对话系统、机器翻译等领域。在图像识别领域，Google 的 ViT 模型通过将图像分割为小块并使用 Transformer 进行处理，大大提高了图像识别的准确率。此外，大模型在推荐系统、智能客服、自动驾驶等许多其他领域也有着广泛应用。</p>\n<p>目前，越来越多的企业开始在实际的研发工作中，结合 AI 工具与 LLM 增强软件开发在设计、需求、测试、发布和运维等各个环节中的能力，提高质量和效率。</p>\n<p>在字节跳动，大模型生成单元测试已经在实际业务中落地。字节跳动智能服务团队通过任务微调、强化学习等技术提升语言模型的单元测试生成语法正确率和分支覆盖率。经过测试，他们的基于 Bloom 70 亿参数模型的生成效果不弱于通用版 ChatGPT 的水平，并且在低端显卡上的推理时延只有 ChatGPT 的 25%。且目前大模型单元测试生成分支覆盖率在实际项目中达到 56%，同时在抖音的 Android、iOS 双端落地，问题有效性达到 80%，修复率 65%。</p>\n<p>在微软，下一代跨平台软件测试基础设施 Hydra Lab 接入了 LLM（Azure OpenAI Service），以提高在测试结果分析、探索性测试和测试用例生成方面的能力。将智能化引入 Hydra Lab，可以看到一些自动化生成测试用例的模块、方案以及 prompt。工程化和智能化是 Hydra Lab 的关键词，而工程化是智能化赋能的基础。</p>\n<p>大模型技术的发展为软件开发范式带来了更多可能性，有受访专家对 InfoQ 表示，大模型将对研发的模式产生颠覆性的改变。但这一改变是一个持续渐进的过程，可能在三年、五年，甚至是十年后发生。随着大模型的不断发展和进化，对于研发工作流的影响程度会逐渐加深加强。对于身处其中的开发者而言，需要拥抱变化，并结合自身实际所需找到切入点，让大模型为己所用。此外，还需要多关注开源方案和数据集。同时也需要认识到大模型存在的潜在问题和限制，合理地使用它。</p>\n<h2>目录</h2>\n<p><strong>热点 | Hot</strong></p>\n<p>取代 Vue 和 React？25 年码龄程序员不满 Web 开发现状创建新框架 Nue JS，能减少 90% 代码量！</p>\n<p>JetBrains 推出独立 Rust IDE</p>\n<p>强制向开发者提 AI 建议再引公愤，GitHub：我知道你们很不满，但我不改</p>\n<p>华为云开源低代码引擎 TinyEngine 正式发布</p>\n<p><strong>访谈文章 | Interview</strong></p>\n<p>比 Spark 快 9 倍，超越 ClickHouse，在大语言模型时代构建全新数据平台</p>\n<p>OpenAI 当家产品 ChatGPT 都在用的 Redis，是如何从传统数据库升级为向量数据库的？</p>\n<p>美的集团：关于工业数字化的最新思考和实践</p>\n<p>当我想要构建一款 LLM 应用时：关于技术栈、省钱和游戏规则</p>\n<p>与 x86、ARM 三分天下，全球“开花”的 RISC-V 如何成为中国最受欢迎芯片架构？</p>\n<p><strong>案例研究 | Case Study</strong></p>\n<p>弃用 MySQL 后存储成本降低 85%，携程业务系统数据库升级技术实践</p>\n<p>实时双向同步：朴朴 Elasticsearch 双活自研实践与思考</p>\n<p>从 Kinesis 到 Timestream：探讨基于 AWS 的无服务器分析架构</p>\n<p>深入解析 Netflix 后端架构与云服务的系统设计</p>\n<p><strong>推荐文章 | Article</strong></p>\n<p>比 Python 快 68000 倍！Mojo 正式发布，网友：Python 生态系统最重要的升级来了</p>\n<p>用 Rust 拯救 60 岁老程序员：用 Ada 写了几十年的飞机程序，现在终于可以改用 Rust 了</p>\n<p>国外 20 家大型科技公司薪资揭秘</p>\n<p>ChatGPT 已成为 2023 年最大金矿，大家是怎么靠它挣到钱的？</p>\n<p><strong>特别专题｜AIGC 浪潮下的研发效能提升之道</strong></p>\n<p>如何利用 AIGC 自动化编程提高研发效率？</p>\n<p>大模型颠覆研发模式：字节跳动是如何在单元测试中落地大模型的?</p>\n<p>打造更聪明的猴子：开源云测框架 Hydra Lab 的智能化测试实战</p>\n<p><strong>特别专栏 | 视频推荐</strong></p>\n<p>欢迎阅读InfoQ架构师电子刊！每个月，我们都会为你带来行业同行关于新兴技术和模式的重要新闻及经验。</p>\n<p>本月，我们聚焦“AI 算力”这一话题。</p>",
    "publish_time": "2023-10-09 10:23:14",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "数字化供应链赋能产业链韧性协同发展（2023）",
    "url": "https://www.infoq.cn/article/eGOXSrAmwdgNSTWoL90q",
    "summary": "<p>为促进我国供应链数字化转型技术创新变革，推动数字技术赋能传统产业链转型升级并形成更具韧性、更加安全可靠的新型产业链业态，中国信通院云计算与大数据研究所联合产业各界，共同撰写《数字化供应链赋能产业链韧性协同发展（2023）》行业报告。</p>\n<p>《数字化供应链赋能产业链韧性协同发展（2023）》行业报告对我国供应链产业链发展新格局做出了全面论述，同时对供应链转型及产业链升级的必要性与意义、技术路径、应用场景、面临挑战以及发展趋势和建议提供了系统性的分析，观点清晰，案例翔实，在凝聚产业共识、引领企业创新、加速应用推广等方面具有重要意义，对于政府和产业界推动供应链转型及产业链升级发展提供了有益的参考。希望读者能够从报告中汲取经验、不断探索，共同推动我国供应链产业链安全稳定发展！</p>",
    "publish_time": "2023-10-09 10:25:12",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "华东政法大学教授高富平确认出席 FCon，分享以数据持有权，开启数据流通与利用新秩序",
    "url": "https://www.infoq.cn/article/QSHzbvKsH9V8WCrfWXeA",
    "summary": "<p><a href=\"https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle\">FCon 全球金融科技大会</a>\"，将于 11 月在上海召开。华东政法大学教授高富平将发表题为《<a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5561?utm_source=infoqweb&amp;utm_medium=atricle\">以数据持有权，开启数据流通与利用新秩序</a>\"》主题分享，介绍数据持有权的定义与意义，以及如何建立可信安全的数据流通规则。</p><p></p><p><a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5561?utm_source=infoqweb&amp;utm_medium=atricle\">高富平</a>\"，华东政法大学智能法学科带头人，任财产法研究院院长、互联网法治研究院院长、数据法律研究中心主任、电子商务法研究所所长，兼任互联网法治研究院（杭州）常务副院长。 高教授曾承担并完成了多项国家和省部级课题，出版著作 20 余本、发表论文 100 余篇。 高教授为“数据二十条”的起草者和解读者，获国家发改委感谢信，为国家医保局、上海数据交易所等大数据机构提供咨询服务，承担上海市经信委、市场监督管理局等大数据相关专项课题研究，并为上海市政府大数据政策制定提供咨询。他在本次会议的演讲内容如下：</p><p></p><p>演讲：以数据持有权，开启数据流通与利用新秩序</p><p></p><p>数据 20 条确立了以数据持有权为基础的数据流通制度，何谓数据持有权？为什么数据持有权是适合数据特征的，促进数据流通的基础制度？如何建立数据持有权为基础的可信安全的数据流通规则？</p><p></p><p>演讲提纲：</p><p></p><p>数据持有权的定义数据持有权的意义以数据持有权为基础，建立可信安全的数据流通规则</p><p></p><p>你将获得：</p><p></p><p>○ 了解数据持有权，以及如何建立可信安全的数据流通规则</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle\">DevOps&nbsp;在金融企业落地实践</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle\">金融行业大模型应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle\">创新的金融科技应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle\">金融实时数据平台建设之路</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle\">金融安全风险管控</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle\">数据要素流通与数据合规</a>\"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，前 100 人可享 5 折特惠购票，咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png\" /></p><p></p>",
    "publish_time": "2023-10-09 11:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "DeepMind全新AI项目曝光：可控制各类机器人，数据集有望开源",
    "url": "https://www.infoq.cn/article/Y2lof4tq2TOqiHcN8L2g",
    "summary": "<p></p><h2>DeepMind的新项目是什么？</h2><p></p><p>&nbsp;</p><p>开发机器人技术的一大挑战，就在于必须投入大量精力来为每台机器人、每项任务和每种环境训练机器学习模型。近日，谷歌DeepMind团队及其他33个研究机构正共同发起新项目，旨在创建一套通用AI系统来应对这个挑战。据称该系统能够与不同类型的物理机器人协同运作，成功执行多种任务。</p><p>&nbsp;</p><p>谷歌机器人部门高级软件工程师Pannag&nbsp;Sanketi在采访中表示，“我们观察到，机器人在专项领域表现极佳，但在通用领域却缺乏灵性。一般来讲，大家需要为每项任务、每台机器人和每种环境分别训练一套模型，从零开始调整每一个变量。”</p><p>&nbsp;</p><p>为了克服这个问题，让机器人的训练和部署变得更加轻松、快捷，谷歌DeepMind在名为Open X-Embodiment的大型共享数据库项目中引入了两大关键组件：一套包含了22种机器人类型数据的数据集，外加一系列能够跨多种任务进行技能迁移的模型 RT-1-X（这是一个源自RT-1的机器人变压器模型）。为了开发 Open X-Embodiment 数据集，研发人员在超过 100万个场景中展示了500多种技能和150,000项任务，因此，该数据集也是同类中最全面的机器人数据集。</p><p>&nbsp;</p><p>此外，研究人员还在机器人实验室和不同类型的物理装置之上对模型进行了测试，并发现与传统机器人训练方法相比，新方案确实能取得更好的成绩。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/78/782e8f89cce0fdce5401f39e87303470.png\" /></p><p></p><p>&nbsp;来自 Open X-Embodiment 数据集的样本展示了 500 多种技能和 150,000 项任务。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/45/45211e40b4438330727247df84fe16e8.png\" /></p><p></p><p>&nbsp;Open X-Embodiment 数据集结合了跨实施例、数据集和技能的数据。</p><p>&nbsp;</p><p></p><h2>结合机器人数据</h2><p></p><p>通常来讲，不同类型的机器人往往拥有独特的传感器和执行器，所以需要配合专门的软件模型。这就类似于不同生物体的大脑和神经系统需要专门进化，从而适应该生物的身体结构与所处环境。</p><p>&nbsp;</p><p>但Open X-Embodiment的诞生却出于这样一条先验性的假设：将来自不同机器人和任务的数据结合起来，就能创建一套优于专用模型的通用模型，足以驱动所有类型的机器人。这个概念在一定程度上受到大语言模型（LLM）的启发，即在使用大型通用数据集进行训练时，模型成果的匹配度甚至可以优于在特定数据集上训练的小型针对性模型。而研究人员惊喜地发现，此项原理果然也适用于机器人领域。</p><p>&nbsp;</p><p>为了创建Open X-Embodiment数据集，研究团队收集了来自不同国家20个机构的22台机器人具身的真实数据。该数据集包含超100万种情节（所谓情节，是指机器人每次尝试执行任务时所采取的一系列动作），其中具体涉及500多种技能和15万个任务示例。</p><p>&nbsp;</p><p>随附的各模型均基于Transformer，一套在大语言模型中也得以应用的深度学习架构。RT-1-X建立在Robotics Transformer 1（简称RT-1）之上，是一套适用于在真实环境下实现机器人技术规模化的多任务模型。RT-2-X则建立在RT-1后继者RT-2的基础之上——RT-2是一种视觉语言动作（VLA）模型，能够从机器人和网络数据中学习，并具备响应自然语言命令的能力。</p><p>&nbsp;</p><p>研究人员在五所不同研究实验室的五台常用机器人上测试了RT-1-X对各类任务的执行能力。与针对这些机器人开发的专用模型相比，RT-1-X在拾取和移动物体、以及开门等任务上的成功率高出50%。该模型还能将技能迁移至多种不同环境，这也是在特定视觉场景下训练出的专用模型所做不到的。由此可见，由不同示例集训练而成的模型在大多数任务中都优于专用模型。论文还提到，此模型适用于从机械手臂到四足动物在内的多种机器人。</p><p>&nbsp;</p><p>加州大学伯克利分校副教授、论文联合作者Sergey Levine写道，“对于任何曾有机器人研究经验的朋友来说，都能意识到这是多么了不起：这类模型「从来」就没能第一次就尝试成功，但这个模型却做到了。”</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/89/89fcd22e3582fb86c6284da0223f93f8.png\" /></p><p></p><p>&nbsp;值得注意的是，即使是规模较小的RT-1-X模型，也实现了对各实验室内部专用模型的超越！对于任何曾有机器人研究经验的朋友来说，都能意识到这是多么了不起：这类模型“从来”就没能第一次就尝试成功，但这个模型却做到了。</p><p>&nbsp;</p><p>在应急技能和处理训练数据集中未涉及的新任务方面，RT-2-X的成功率可达RT-2的3倍。具体来讲，RT-2-X在需要空间认知的任务上表现出更好的性能，例如理解“将苹果放到布旁边”和“将苹果放到布上”两种要求间的区别。</p><p>&nbsp;</p><p>研究人员在Open X和RT-X的发布博文中写道，“我们的结果表明，与其他平台的数据进行联合训练之后，RT-2-X获得了原始数据集中并不具备的额外技能，使其能够执行前所未见的新任务。”</p><p></p><h2>步步迈向机器人研究的新未来</h2><p></p><p>展望未来，科学家们正在考虑将这些进展与DeepMind开发的自我改进模型RoboCat的见解相结合，希望探索出新的研究方向。RoboCat能够学会在不同机械臂上执行各种任务，然后自动设计出新的训练数据以提高自身性能。</p><p>&nbsp;</p><p>Sanketi认为，另一个潜在的研究方向，也可能是进一步研究不同数据集间的混合会如何影响跨机器人具身的能力泛化与改进效果。</p><p>&nbsp;</p><p>该团队目前已经开源了Open X-Embodiment数据集和小型RT-1-X模型，但并未公开RT-2-X模型。</p><p>&nbsp;</p><p>Sanketi总结道，“我们相信，这些工具将改变机器人的训练方式，并加速该领域的研究进展。我们希望开源相关数据，并提供安全但受限的模型以减少障碍、加速研究。机器人技术的未来离不开机器人之间的相互学习，而这一切的前提，首先要求研究人员之间能够相互学习。”</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://venturebeat.com/ai/deepminds-remarkable-new-ai-controls-robots-of-all-kinds/\">https://venturebeat.com/ai/deepminds-remarkable-new-ai-controls-robots-of-all-kinds/</a>\"</p><p><a href=\"https://www.deepmind.com/blog/scaling-up-learning-across-many-different-robot-types\">https://www.deepmind.com/blog/scaling-up-learning-across-many-different-robot-types</a>\"</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-10-09 14:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "腾讯云曹骏：选择适合自身战略的架构是应对核心系统挑战的关键",
    "url": "https://www.infoq.cn/article/TJg7MXJ5WM1ayMsW8xtc",
    "summary": "<p>随着金融行业的不断发展和数字化转型的进行，银行核心系统的重要性日益凸显。然而，由于历史原因和技术限制，许多银行核心系统仍然依赖于国外厂商的技术和产品。为了提高银行核心系统的自主可控性和安全性，国内银行开始探索国产化替代的道路。但探索之路漫漫，在 9 月 22 日的 InfoQ《<a href=\"https://www.infoq.cn/theme/212\">超级连麦·数智大脑</a>\"》直播中，InfoQ 与<a href=\"https://www.infoq.cn/topic/tencent\">腾讯云</a>\"商业银行总经理曹骏探讨了银行核心系统的国产化进展与未来。</p><p></p><p>曹骏表示，在数字化与国产化趋势下，银行走向分布式是必然的方向，这一点在业界已经形成了共识。在核心系统替代方面，首先，选择适合自身战略的架构是应对核心系统挑战的关键；其次，我们需要在关键的技术组件和部署方式上作出选择，以应对可能出现的风险；最后，还需要防范系统在上线、调优、测试以及运营过程中可能出现的问题。</p><p></p><p>以下是对话全文（经 InfoQ 进行不改变原意的编辑整理）：</p><p></p><h5>InfoQ：金融行业经历了哪些决定性的发展阶段？在这些阶段中，金融机构对于技术的需求又有哪些相应的变化和调整？</h5><p></p><p></p><p>曹骏：金融机构在技术发展上经历了几个重要阶段。首先，金融机构在各自的赛道中有着不同的类型和规模，其中，银行在整个赛道中规模最大，技术投入也相对较高。</p><p></p><p>早期阶段：</p><p>我从1998年开始从业，最初是帮助一家区域性的银行建设核心系统。那时，所有的核心系统都是集中式的，不是分布式的。这个时期是中国银行科技系统建设的起步阶段。到了2000年左右，我们进入了被我们称为“大集中”的时代，国有银行开始采用IBM的主机承载银行核心系统，这种算力强大的服务器，一两台机器就可以支撑全国的交易业务。这是一个非常重要的里程碑，银行借助大集中的业务模式很容就能够在全国实现通存通兑。</p><p></p><p>IOE 技术阶段：</p><p>基于主机构建核心系统相当昂贵，随着时间的推移，小型机逐渐普及。很多银行开始使用IOE的技术，即IBM的小型机 + Oracle的数据库和EMC的存储来构建银行的业务系统。在这个时期，很多区域性的银行开始建立自己的核心系统，与大型主机上经常采用的胖核心架构不同，这个阶段大部分核心系统采用“瘦核心”架构。</p><p></p><p>分布式和国产化阶段：</p><p>目前，我们面临着数字化和国产化的双重挑战。我们需要对数据有更深更广的处理，对算力的要求也非常高。银行行业开始通过国产化的硬件和软件，以分布式的架构来支撑新的核心系统。在这个时代，大数据和AI技术得到了广泛应用，云原生的理念也得到了广泛应用。</p><p></p><h5>InfoQ：能否进一步追溯并探讨一下，银行在业务端遇到了哪些主要的挑战，从而触发了后端这一系列连锁反应和技术需求的变化？</h5><p></p><p></p><p>曹骏：在早期的单核心和集中式时代，银行系统的主要作用实际上是记账，确保如存取款、查询、转账等所有交易都能被准确记录。那时，系统的要求是以尽可能低的成本实现交易的准确性、一致性和稳定性。大集中的架构，采用一两台大型机，就能够提供非常强的算力和稳定性，能支持一家大型银行全国的账务处理。这种集中式处理方式效率较高，因为所有的账务都可以在一个地方集中完成，集中式的架构是最合适的。</p><p></p><p>但随着银行进入移动互联网时代，为了支持消费互联网和开放银行，例如线上支付、秒杀、千人千面的个性化、实时风控等，银行需要记录用户的访问行为，通过这些行为和客户端数据来提供更个性化的服务和风控措施。这就要求对数据有海量、高效率、高速的处理能力。如果完全采用集中式的处理方式，设备成本会非常高，至此分布式处理方式逐渐被接受。</p><p></p><p>一个典型的例子是<a href=\"https://www.infoq.cn/video/ClldtSRLIKa9U0mcPY7Q\">微众银行</a>\"，这家民营银行的收入和经营效率都非常出众，领先于行业。它通过分布式的方式，利用低成本的商用服务器和快速网络来提供业务支持，通过纯线上交易、线上风控和自动化的客户服务，提供给客户的服务的经营效率比一般的银行要高很多。这种分布式形式可以降低成本，提高市场响应效率，获得更多的发展空间。这也展现了新技术，如分布式、云原生、数字化等，能够有效提升业务处理能力。为了支持消费互联网和线上海量业务，性能和并发性要求非常高，越来越多的银行意识到需要通过分布式的方式来降低成本。加上国产服务器可能不像国外产的高端服务器那样能提供单体服务器的海量算力，国产化技术也在推动行业走向分布式方向。</p><p></p><p>除此之外，云计算和敏捷交付技术的发展也使得刚刚提到的分布式方式能够更加高效、灵活，能快速响应市场需求。 </p><p></p><h5>InfoQ：虽然分布式已经成为潮流趋势，但是集中式架构在单体性能等方面仍然具有优势，尤其对于国有银行这样有着高性能、高稳定性要求的行业来说，分布式真的是更好的选择吗？还是说在实施过程中存在一个平衡点？</h5><p></p><p></p><p>曹骏：在数字化与国产化趋势下，走向分布式是必然的方向，这一点在业界已经形成了共识。集中式处理在做账务处理时无疑有其优势，尤其是当单机算力足够强时。但这种单机的算力非常昂贵，例如，IBM的主机不是按台卖的，而是按MIPS来卖的，价格非常昂贵。而新的一些算力形式，如大数据处理，采用多机并行的处理方式，并不强调单个节点的处理能力。大数据处理可以通过几千台机器来并行处理，而即使采用最高端的服务器，单台机器提供与之媲美的计算能力。此外，现在关注度非常高的AI训练也是通过分布式的方式来实现的，集中式的算力处理不了这类负载。</p><p></p><p>集中式的另一个优势是在结构简单，且单机的稳定性高。但现在，通过分布式微服务等技术手段，新的设计可以达到与集中式相同的稳定度。例如，微众银行采用分布式，通过上千个节点来支撑业务运转，虽然单机可靠性可能并不高，但整体效果是一样的，可以提供非常高的服务水平。综合考虑稳定度和价格，我们判断未来的发展趋势肯定是走向分布式。</p><p></p><h5>InfoQ：在银行业中，各机构对于国产化系统的替代进展到什么程度了？</h5><p></p><p></p><p>曹骏：我们观察到，金融行业的国产化已经推动了三批试点机构，涉及超过150家银行机构。这150家银行基本上涵盖了我国的大中型银行。换句话说，国内主要的银行都开始推动国产化的工作。</p><p></p><p>从发展情况来看，主要的银行应用系统领域基本上都可以进行国产化替代。例如，最难替代的核心系统也在进行国产化。我们预计，在未来一两年的时间里，国产化会获得非常大的推广和推进。至今，无论是大型国有银行、股份制银行，还是地方金融机构，都有成功的国产化建设案例。一些先行者已经完成了国产化过程，未来处于全面推广和复制的阶段，技术上已经得到了验证。</p><p></p><h5>InfoQ：能否更详细地阐述一下，应该采取哪些关键措施来确保核心系统的稳定性和可靠性？</h5><p></p><p></p><p>曹骏：在金融机构中，核心系统的重要性极高。如果周边系统出现问题，可能只会影响局部，但如果核心系统出现问题，可能导致整个业务停摆。</p><p></p><p>因此，每个银行机构在进行核心相关的设计时，都会非常小心谨慎。在进行核心系统的重构时，通常会经过数年的时间逐渐完成。在此过程中，我们观察到几个重要的要点：首先，选择适合自身战略的架构是应对核心系统挑战的关键；其次，我们需要在关键的技术组件和部署方式上作出选择，这也是一个需要仔细考虑的环节，以应对可能出现的风险；最后，我们需要防范系统在上线、调优、测试以及运营过程中可能出现的问题。</p><p></p><p>传统的核心运营方式已经有几十年的历史，而新的技术架构可能只有数年的时间，其稳定性和配套机制可能都不如传统的技术。因此，我们必须留出足够的时间来进行试错和纠正。这也是我们需要面临并应对的风险。</p><p></p><p>总之，核心系统的复杂性和重要性要求我们在设计和实施过程中必须非常谨慎，选择合适的技术架构和部署方式，并预留足够的时间来应对可能出现的问题和风险。</p><p></p><h5>InfoQ：您提到了选择适合自身战略和业务需求的架构的重要性，您能否提供一些具体的例子？</h5><p></p><p></p><p>曹骏：当我们讨论适合自身战略和业务需求的架构时。首先，我们要明确银行的战略和规模是什么样的。例如，如果是一家具有国有大行或大型金融机构，那么它会拥有海量的客户。在这种情况下，我们需要有非常完备的分布式方案来应对业务挑战，因为处理节点的数量可能会达到几百甚至上千。在这种情况下，分布式的特性必须非常完备，以应对业务挑战。</p><p></p><p>其次，有一些银行可能一开始规模不大，但战略定位上会通过并购或者承接快速发展的线上业务而产生用户量的大幅增长，最终会拥有海量客户。这种银行从一开始可能只有几百万客户，但是会用户数会迅速增长，对系统的扩展性要求非常高。这类客户也需要针对用户快速增加的特点，进行针对性的设计。我们需要根据这样的业务战略去做相应的设计，确保在客户大幅增长的时候，技术架构可以平滑扩展。</p><p></p><p>然而，如果是一家地方性的金融机构，未来用户群可能相对稳定，业务量可能会稳中有增，但整体客户量没有多大的变化。在这种情况下，我们是否需要花费大量的精力实施复杂的架构，如采用大型银行通常会采用的单元化架构，就成了一个值得考虑的问题。如果选择了不合适的方向，可能会导致事倍功半。</p><p></p><h5>InfoQ：选择适合的技术组件的标准是什么？这个过程需要注意什么问题？</h5><p></p><p></p><p>曹骏：首先，选择一个可运维、且能够掌握的架构是至关重要的。如果这个架构过于复杂，以至于团队无法掌握，或者经过调整后无法融入现有体系，那即使这个架构再先进，我们也无法将其有效应用。</p><p></p><p>例如，我们与很多银行客户沟通时，他们表达了希望能像互联网公司一样，采用多地多中心、多活的架构，但实际上，对于多数金融机构来说，维持两地三中心的运维最佳实践是性价比最好的方式。这样的架构能很好地与我们现有的运维团队和开发体系结合，易于管理，能快速发挥价值。如果我们只是简单复制一些听起来很先进的多地多中心架构，可能由于我们缺乏足够的设计和运维能力，会出现如成本过高、运维困难等问题。</p><p></p><h5>InfoQ：上线、调优、测试以及运营过程中的风险具体有哪些？如何防范？</h5><p></p><p></p><p>曹骏：以系统设计为例，完成设计后，如何实施诸如银行所需的各项测试工作是一个大问题，因为通常测试工作的量可能会大于开发工作的量。在这个环节，如何深入测试，如何平滑实现上线，以及如何制定应对系统出现问题时的应急计划，都值得我们积极去考虑和解决。如果这些层面的配套设施不足，就有可能导致一个技术先进的平台，在实际落地时，无法发挥出良好的效果。</p><p></p><h5>InfoQ：核心系统国产化涉及架构侧和数据库应用侧等多个层面的改造，可以说牵一发而动全身，如果出现问题就会导致全行业务中断甚至瘫痪，根据您的经验，多个条线之间如何实现有序、稳定地规划、布局和实施？</h5><p></p><p></p><p>曹骏：针对这个问题，我认为主要可以从三个方面去考虑：</p><p></p><p>技术架构的明晰选择</p><p>对于技术架构和运营流程的明晰选择非常关键。需要选择适合于自己银行的策略和架构，例如标准的微服务架构可能更适合中小型银行。此外，在分布式体系下，如何实施运维监控，如何设计开发与运维的一体化，都需要全面设计和考虑。</p><p></p><p>紧密协同和合作</p><p>在实施核心系统时，需要行内相关团队、部门、核心系统供应商以及平台提供商等紧密协同和合作。这涉及到如何选择和定制核心厂商的产品，如何与平台提供商协同工作，以及如何在银行内部实现业务和技术部门之间的紧密合作。</p><p></p><p>专业项目管理</p><p>银行系统的升级或国产化周期长，组织协同复杂，因此通常会邀请有管理经验的专业项目管理机构（PMO）来帮助管理整个过程。他们凭借经验和专业工具，能够协助银行在每个环节更加明确地知道应该如何操作，能够有效降低风险，提升实施效果。</p><p></p><p>为了确保顺利实施，三个方面需要同步进行，这是一个需要全方位、多角度去考虑的问题，每个方面都需要深入探讨和精心实施，以确保最终可以达到预期的效果。</p><p></p><h5>InfoQ：国产系统和中间件在升级过程当中，如何平滑过渡，特别是数据库的替换？</h5><p></p><p></p><p>曹骏：现在，越来越多的银行选择使用国产化数据库，这已经成为一个比较普遍的趋势。事实上，不同规模的银行都在进行这样的转换。例如，腾讯已经协助四大行中的两家，从Oracle或主机平台迁移到<a href=\"https://www.infoq.cn/article/Au8A0GLJcHPNJQp3Vizx\">国产化</a>\"数据库。目前，主流系统基本已经完成了迁移工作。在股份制银行领域，也有多个成功的迁移案例。</p><p></p><p>从客户的需求来看，可以将其划分为两大类别：</p><p></p><p>第一类，选择在替换数据库的同时进行核心系统的重构。核心系统的迭代大部分时候是业务驱动的，银行希望更好地响应市场需求，提升数字化能力，大约每5到10年会重新建设一次核心系统。在国产化的要求下，很多银行会在核心系统数字化的同时，进行技术平台的国产化。对于这一类的需求，市场上的主流应用厂商都和主流数据库平台的提供商都有足够的应对经验。</p><p></p><p>第二类，某些银行的数据库或核心系统可能新近部署，但由于国产化的要求，他们需要进行近乎原地的数据库替换。这种情况下，技术层面会比较复杂，涉及到的流程包括评估、对核心代码进行改造、进行测试上线等。其中，可能涉及到的技术挑战如分布式的性能与集中式的差异、分布式的事务开销等，都需要进行性能优化。</p><p></p><p>总体上看，行业内主流选择的是第一种方式，因为大部分金融机构希望在替换数据库时，不仅实现技术上的替换，还能在业务上获得收益。具体的平滑替换过程现在已经形成了一套比较体系化的工作方法，如果需要可以后续展开细节的讨论。</p><p></p><h5>InfoQ：在分布式架构转型的过程，有哪些避坑经验可以分享？</h5><p></p><p></p><p>曹骏：首先，选择技术架构时，必须要与自己的业务发展规模和发展战略相匹配，不应一味追求先进技术。我们看到一些银行客户在实施过程中，可能会有偏离正确方向的倾向，但多数能够经过反复讨论后基本都会回归正轨，所以我们看到国内核心系统国产化和重构的过程中，很少有失败的案例 -- 大家在这个选择都表现得非常慎重。</p><p></p><p>第二点，我们需要结合业务的发展要求，面向业务价值来进行系统能力的建设。以微众银行为例，他们在核心系统集成过程中就非常注重业务发展价值。他们设计的核心系统架构完全是分布式的，能够快速适应客户数量的增加，且能够低成本、平滑地进行扩张，这与他们的客户发展策略完全吻合。而如果我们在系统建设中只考虑建设本身，而不与业务价值关联，可能会发现投入产出比并不理想。</p><p></p><p>第三点，在实施过程中，我们也要充分考虑到可能的困难。比如，分布式架构在建设和运维上与集中式有很大不同。在分布式环境中定位故障会比较困难，性能的优化也是一个需要重点考虑的问题。而在国产化的硬件性能方面，可能会与之前用到的服务器和芯片有所不同，需要一定时间去磨合。因此，建议大家要为这些困难和磨合预留相应的精力、资源和时间。</p><p></p><h5>InfoQ：银行核心系统替换的经验，是否可以复制到其他金融领域？</h5><p></p><p></p><p>曹骏：银行业发展与IT依赖度相对较高，并且其技术发展水平通常比较先进。因此，在其它金融赛道中复制和应用特别有帮助。</p><p></p><p>然而，在实际应用中，我们也观察到一些显著的差异：</p><p></p><p>a. 银行业的核心系统供应商多样，而像资管和保险行业的供应商集中度较高，可能大部分应用由同一家开发商提供，这意味着这家开发商的核心系统国产化准备程度非常关键。</p><p></p><p>b. 银行业的业务发展速度相对较快，并且核心系统经常重构。相比之下，其他金融子行业可能更倾向于稳定，他们可能只想更换数据库或进行小幅扩展，而不是全面重构。</p><p></p><p>c. 在核心故障化过程中，银行通常希望完成业务能力的全面升级，而其他行业可能希望以最低代价平滑地替换核心系统。</p><p></p><p>尽管存在差异，但通过银行的实践来验证技术的成熟度和稳定度是完全可行的。银行业已经验证了云原生、微服务等多项技术都可以应用到核心系统及周边系统中。这些经验将有助于其他金融行业的从业者更加明晰技术应用方向，并能够更有效地实现技术与业务的融合。</p><p></p><h4>关于 FCon</h4><p></p><p>首届<a href=\"https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">FCon全球金融科技大会</a>\"将于 11 月 19-20 日在上海举办。大会将围绕金融领域数字化转型挑战探索、DevOps 在金融企业落地实践、金融行业大模型应用、创新的金融科技应用、金融实时数据平台建设之路、金融安全风险管控、数据要素流通与数据合规等 10+专题进行交流。</p><p></p><p>目前大会邀请了汇丰科技中国区的代理总经理马国栋、度小满金融数据智能部总经理杨青先、蚂蚁集团副总裁 &amp; 首席技术安全官韦韬博士、恒生聚源总经理吴震操担任大会联席主席。更多嘉宾仍在邀请中......</p><p></p><p>我们诚挚地邀请您加入我们，共同探索金融科技的未来，<a href=\"https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">点击链接</a>\"即可查看全部演讲专题。</p><p></p><p>目前是 <a href=\"https://fcon.infoq.cn/2023/shanghai/apply?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">7 折特惠购票</a>\"，报名立减 ¥2040，咨询购票可联系：17310043226（微信同手机号）。</p>",
    "publish_time": "2023-10-09 14:06:06",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "两行代码解决大模型对话局限，港中文贾佳亚团队联合MIT发布超长文本扩展技术",
    "url": "https://www.infoq.cn/article/U5N1PsYQpVIpu3ThbIN6",
    "summary": "<p>近日，贾佳亚团队联合MIT发布了一项名为LongLoRA的新技术，只需两行代码、一台8卡A100机器，便可将7B模型的文本长度拓展到100k tokens、70B模型的文本长度拓展到32k tokens。同时，该研究团队还发布了首个拥有70B参数量的长文本对话大语言模型LongAlpaca。</p><p></p><h2>LongLoRA 如何解决大模型对话缺陷</h2><p></p><p>&nbsp;</p><p>“上下文越长大模型越笨”是典型的大语言模型对话缺陷。在长文本处理过程中，之前大语言模型计算量的主要开销集中在自注意力机制(self-attention)，其开销随着文本长度成平方次地增加。针对这个问题，研究团队提出LongLoRA技术，并用分组和偏移的方式来对全局自注意力机制进行模拟。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/70/70a810b92e075263b2e2a3281b062b01.png\" /></p><p></p><p>简单来说，就是将长文本对应的tokens拆分成不同的组，在每组内部做自注意力计算，而分组的方式在不同注意力头&nbsp;(attention head) 上有所偏移。这样的方式既可以大幅度节约计算量，又可以维持全局感受野的传递。而这个实现方法也非常简洁，仅两行代码即可完成。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6a/6aad8dba3c72ae4947e2aab04fe01c0e.png\" /></p><p></p><p>LongLoRA还探索了低秩训练的方式。原有的低秩训练方式，如LoRA [5]，无法在文本长度迁移上取得良好的效果。而LongLoRA在低秩训练的基础上，引入嵌入层&nbsp;(Embedding layer和 Normalization layers)&nbsp;进行微调，从而达到可以和全参数微调 (Full fine-tune) 逼近的效果。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f7/f7959f48537fc89bf6cb73e836ae3df0.png\" /></p><p></p><p>进行不同长度文本扩展和训练时，LongLoRA、LoRA和全参数微调不同技术的具体表现如下：</p><p>&nbsp;</p><p>在Perplexity-困惑度上，原有LoRA方法的性能在不断恶化，而LongLoRA和全参数微调都能在各种文本长度下维持很好的效果；在显存消耗上，相比于全参数微调，LongLoRA和原有LoRA都有大幅度的节省。例如，对于8k长度的模型训练，相比于全参数微调，LongLoRA将显存消耗从46.3GB降低到25.6GB；在训练时间上，对于64k长度的模型训练，相比于常规LoRA，LongLoRA将训练时间从90～100小时左右降低到52.4小时，而全参数微调超过1000小时。</p><p></p><p>目前，相关技术与模型已全部开源：</p><p>&nbsp;</p><p>代码和Demo地址：<a href=\"https://github.com/dvlab-research/LongLoRA\">https://github.com/dvlab-research/LongLoRA</a>\"</p><p>论文地址：<a href=\"https://arxiv.org/pdf/2309.12307.pdf\">https://arxiv.org/pdf/2309.12307.pdf</a>\"</p><p>&nbsp;</p><p></p><h2>长篇小说读后分析，LongAlpaca完胜Llama2</h2><p></p><p>&nbsp;</p><p>LongAlpaca大语言模型，利用LongLoRA技术解决了对话缺陷问题。但大语言模型处理长文本问题的一大难点还在于缺少公开的长文本对话数据。</p><p>&nbsp;</p><p>为此，研究团队特意收集了9k条长文本问答语料对，包含针对名著、论文、深度报道甚至财务报表的各类问答，此外还挑选了3k的短问答语料与9K的长问答语料混合训练，让长文本大模型同时具备短文本对话能力。这个完整的数据集被称为LongAlpaca-12k，目前已经开源。</p><p>&nbsp;</p><p>在LongAlpaca-12k数据集基础上，研究团队对不同参数大小7B、13B、70B进行了训练和评测，开源模型包括LongAlpaca-7B、LongAlpaca-13B和LongAlpaca-70B。下面是LongLoRA技术叠加12K问答语料的大模型LongAlpaca在论文方面表现：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/50/50194fb46842750d702e4f1a63c84faf.png\" /></p><p></p><p>&nbsp;</p><p></p><blockquote>让系统新读一篇论文，并根据ICLR的审查指南，对其提出修改意见，从而提升该论文的接收率。&nbsp;LongAlpaca的意见是：通过更精确地阐明新颖性，提供更严格和更有对比性的实验结果(包括具体的数据集和指标)、更广泛的应用和未来发展方向，重点呈现关键贡献和影响，论文被接受的机会将得到提高。</blockquote><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/29/299a67454b8e96bedbeefbbf655d7141.png\" /></p><p></p><p>&nbsp;</p><p></p><blockquote>让系统读两篇新的不同的论文，让LongAlpaca概括ICLR和CVPR两个会议之间的风格区别。&nbsp;LongAlpaca总结认为，CVPR论文倾向更具结构性和实验性的风格，专注于实用性和技术性。而ICLR的论文风格更加灵活，侧重关键的理论分析和数学推导，而非标准格式。&nbsp;可以看出，经过训练的LongAlpaca模型已经可以很轻松地接受新的长篇学术论文，在学术相关问题的回答上相当精准。</blockquote><p></p><p>&nbsp;</p><p>LongAlpaca在颇高阅读和理解门槛的经济领域的解读表现：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d2/d2b11b8e95cdefa727b358f4bef382c3.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f8/f805ddb1b64be78f4c8c25c0a77c7c48.png\" /></p><p></p><p></p><blockquote>根据国际货币基金组织从2012年到2023年的全球经济展望的概述合集，对经济形势进行逐年总结以及对未来经济趋势进行预测。&nbsp;LongAlpaca表示，2023年全球经济形势不明朗，跟2022年相比，增长预计放缓；未来几年，全球经济扩张速度偏温和并将低于预期，而地缘政治紧张、金融市场波动等大的挑战依然存在，需通过多边合作和结构性改革小心应对。</blockquote><p></p><p>&nbsp;</p><p>13B参数的LongAlpaca和Llama2在读完长篇小说后的内容分析对比：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/09/0931e6dfc10c170bffe91c8ce5c3d6bb.png\" /></p><p></p><p>&nbsp;</p><p></p><blockquote>名著《西游记》中，为什么孙悟空在大闹天宫时很厉害，但取经路上却屡屡受挫？&nbsp;LongAlpaca 给出了5点原因，大概可总结为： “孙悟空的不成熟、强大的对手、力量的限制、敌人的欺骗、最初缺少同伴等因素导致了他在旅途中的失败。但随着时间推移，他获得了智慧、经验和战友，使他最终战胜了最强大的敌人。”&nbsp;而 Llama2 的回答较为简单：“虽然他确实大闹天宫，但说他代表着不败的力量并不一定准确。事实上，他最终在西游记中被强大的唐三藏打败。”Llama2没有给出正确答案，并且还提出需要更多的内容信息。</blockquote><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/63/63852dbc48a17b22d9f25ad96a71289a.png\" /></p><p></p><p>&nbsp;</p><p></p><blockquote>让系统新读一次《三体》，然后问第一部中，叶文洁为什么要联系外星人，而后期又为什么后悔？&nbsp;LongAlpaca认为，叶文洁最初接触外星人是出于理想主义和复仇，但随着时间的推移，她对人类的看法发生了变化，意识到自己可能给全人类带来的危险，她的悔恨与日俱增。&nbsp;而Llama2的回答则是，“通过与外星人的互动，她希望能更深入地了解宇宙的本质，以及自己在宇宙中的位置。叶文洁逐渐意识到，外星人和他们的技术并不能解决她的问题。”</blockquote><p></p><p>&nbsp;</p><p>从模型给出的答案可看出，一些模型如Llama2，可能在预训练过程中见过相关小说，但如果在提问时进行仅根据小说题目进行短文本提问的话，回答并不理想。</p>",
    "publish_time": "2023-10-09 14:07:54",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "我，一个95后，从阿里辞职与贾扬清去硅谷创业",
    "url": "https://www.infoq.cn/article/8wWUiBa8eBWVLRMrxJaT",
    "summary": "<p>“在旧金山，随便进去一家咖啡馆，十分钟之内，你就会听到有人在谈论ChatGPT、AI。不管是不是有些天马行空，视线范围内的所有人都在尝试着融入和探索新的事物。”25岁决定与贾扬清一起在美国加利福尼亚州创业的鱼哲说道。</p><p>&nbsp;</p><p>鱼哲跟<a href=\"https://www.infoq.cn/article/Bg8*3spkPKCjCsw7MPR8\">贾扬清</a>\"的缘分始于阿里云。2020年，鱼哲本科毕业后入职阿里云，这是贾扬清进入阿里的第二年。当时，负责阿里云机器学习平台PAI产品线的鱼哲进入了贾扬清的团队，并与之共事了很久。2023年，贾扬清从阿里离职创业，鱼哲也选择加入这支队伍。</p><p>&nbsp;</p><p>“我非常认同扬清的创业方向，这个方向非常有趣。”鱼哲说道。在时代浪潮的推动下，每个人都在寻找自己的方向。鱼哲用这个中式的比喻来形容他们正在做的事情：我们不帮别人包饺子，而是为他们的厨师提供一个优秀的中央厨房，让厨师们可以轻而易举的获取所需的食材以便其能更好地准备自己的菜肴。</p><p>&nbsp;</p><p>那么，这个98年的“新秀”是如何一步步走向AI创业道路的？他们现在究竟在做什么样的事情？又是如何思考AI的现状和发展的呢？</p><p></p><h2>从高中开始就一直很“不正经”</h2><p></p><p>&nbsp;</p><p>2017年7月的一个周末，深圳的台风袭来，而几十位极客正在科技寺举办的黑客松上如火如荼地讨论各种项目，其中便有鱼哲的身影。</p><p>&nbsp;</p><p>在大二选择Gap Year时，鱼哲在编程猫担任算法工程师，业余时间利用图像识别和<a href=\"https://cloud.tencent.com/product/nlp?from_column=20065&amp;from=20065\">自然语言处理</a>\"技术，做了一个可以在对话中自动生成相应表情配合文字的程序，叫“表情包终结者（Meme Fighter）”，据说是因为他经常在微信群的表情包大战中惨败。</p><p>&nbsp;</p><p>两天内做出这样一个项目，对鱼哲来说并不是太难。</p><p>&nbsp;</p><p>当大多数人在为高考努力的时候，受素质教育影响的鱼哲被更愿意去探索不同的领域。那时的他对技术很感兴趣，除了一直关注最新的技术动态，他玩过单片机、也参与了一些机器人项目，算是积累了一些经验。后来在第一次接触JupyterLab时，遇到问题后的鱼哲会自己修复并提出bug报告，因此还被JupyterLab 创始人邀请参与到了项目中。</p><p>&nbsp;</p><p>举一反三也是鱼哲的强项。在编程猫工作时，他需要让模型能够应对大量业务流量。最开始无从下手，但当时听了“Instagram如何架构Python后端”的讲座后，鱼哲借鉴了其思路并实施到自己项目中，取得了不错效果。</p><p>&nbsp;</p><p>在鱼哲的成长过程中，实习工作是家常便饭，但也正是一次次的工作经历影响了他看待世界的方法，进而影响了他的职业选择。</p><p>&nbsp;</p><p>高中期间，鱼哲去了一家咨询公司做市场调研的工作。实际上，这份工作并不复杂：研究当时市场上的青少年科技夏令营主要做什么、定价情况、客户群体等，在收集到大量数据并进行分析后，推测当地人们的消费情况、对子女教育的投入等。</p><p>&nbsp;</p><p>“这种洞察力非常有趣，你可以通过一些有趣的数据看到其他人是如何生活的，就像有了上帝视角。”鱼哲说道。咨询公司对方法论和数据运用的重视也深刻影响了鱼哲，让鱼哲养成了“用数据看世界”的思维习惯。</p><p>&nbsp;</p><p>另外，这段实习经历也让鱼哲接触到了另一个跟技术无关的领域：商业运作。鱼哲开始思考将技术与商业结合起来。他认为，技术不能只停留在实验室中，只有真正落地并被大家接受和应用才能发挥更大的价值。</p><p>&nbsp;</p><p>于是，本科期间，鱼哲选择了去美国伦斯勒理工就读信息技术与网络科学专业（Information Technology and Web Science，ITWS），计算机学院和商学院各学两年，深入了解技术对商业变革的影响。根据规划，其最终的职业发展方向就是技术的落地及商业化。</p><p></p><h4>“阿里云最年轻的产品经理”</h4><p></p><p>&nbsp;</p><p>阿里云是鱼哲大学毕业后的第一份正式工作，22岁的他成了“阿里云史上最年轻的产品经理”。</p><p>&nbsp;</p><p>在阿里云，鱼哲更像是经历了一场“系统化训练”，用他的话就是，这次工作对他在“个人技术深度和广度方面的提升、个人职业规划的明朗，以及商业模式和市场的理解上，都产生了很大影响。”</p><p>&nbsp;</p><p>回忆起这段经历，鱼哲最先想到的是养成了“只要没干死，就往死里干”的态度。当时阿里云要研发很多新产品，刚入职的他心里憋着劲，将自己的工作节奏安排得非常紧：早上吃咖啡因含片，中午甚至只吃蛋白质代餐，一直工作到晚上九点或更晚。“年轻人总是会容易感动自己，以为这个世界离开了我就不行。”鱼哲笑着调侃当年的自己。</p><p>&nbsp;</p><p>鱼哲坦言自己经历了失败，“想要第一次尝试的事情也不总是正确的”，但周围阿里的同事给了他很大的包容，经过多次试错后最终可以找到正确的“打开方式”。这些努力也让他收获颇丰：经手业务一年里基本上都实现了二三十倍的增长。</p><p>&nbsp;</p><p>对鱼哲来说，“阿里云最年轻的产品经理”的标签，从某种程度上来说，代表着他年轻的特质。“年轻时，我们对许多东西都不懂，也不知道如何去应对，意识到‘自己不知道’很重要，更重要的是迎难而上的勇气和不断探索的精神”鱼哲解释道。</p><p></p><h2>选择创业，只能不停地学习</h2><p></p><p>&nbsp;</p><p>去年下半年，<a href=\"https://www.infoq.cn/article/iEkbUrxDh6c7svEbepKj\">ChatGPT</a>\"的爆火引发了AI狂潮，进而吸引了一批AI创业者，多年前就想创业的贾扬清这次终于下场。</p><p>&nbsp;</p><p>“在 AI 领域，模型的保鲜期基本上是一年左右。”贾扬清曾表示，因此他瞄准了需求更明确的方向：如何更好地部署模型，是否有更弹性的、更稳定的、更低成本的部署模式。不直接帮企业开发应用是因为许多情况下，用户比厂商更了解特定场景的实现细节，厂商无法深入解决专业领域的问题。</p><p>&nbsp;</p><p>已经在AI领域积累多年的鱼哲很认同贾扬清的观点，因此在阿里云工作三年的鱼哲加入了这个创业团队。“我的优势在于曾在甲方和乙方两方都工作过，对整体商业模式有较为深入的了解。我还有一段时间在海外工作、生活和学习，这些经历让我能更全面地看待问题。”鱼哲认真剖析了自己。</p><p>&nbsp;</p><p>如今，鱼哲在LeptonAI 担任产品负责人一职，他经常参加各种线下活动，通过与外界交流来了解市场和用户的需求，进而反推出自己应该做什么样的产品。</p><p>&nbsp;</p><p>对于鱼哲来说，大厂的很多工作相对来说都是可预测的，而现在的工作不确定性更强，但也更加让他兴奋。他如今需要更快速地学习，并充分利用自己之前的工作经验，来找到更好帮助用户实现自己AI落地的方法。</p><p>&nbsp;</p><p>没有固定的上下班时间、更注重结果，选择创业公司让他比之前更加忙碌。同时，像鱼哲这样的AI创业者，现在面临的最大挑战之一就是市场的不确定性：整个AI和机器学习领域变化迅速，每天都有新的机会和技术涌现，大家每天读论文的速度都跟不上发布速度，他们需要始终都要保持初学者的心态，不断学习和吸收新知识。</p><p>&nbsp;</p><p>“我也没有特别好的办法，只能尽力跟进最新进展，多与业内一些顶尖公司的专业人士交流，跟上这个快速发展的领域。”鱼哲说道。</p><p>&nbsp;</p><p></p><h2>“很难找出这样出色的团队”</h2><p></p><p>&nbsp;</p><p>作为一个创业公司，鱼哲所在的LeptonAI 现在主要将精力放在了三个方面：</p><p>&nbsp;</p><p>持续进行AI模型的前沿创新研究，涵盖训练、推理、编译等方面，不断提高模型从训练到生产环境等各个关键环节的竞争力；提升工程平台性能，确保整个工作流程更加高效；不断思考和调整商业模式，以确保公司在整体上保持竞争力。</p><p>&nbsp;</p><p><a href=\"https://www.lepton.ai/\">LeptonAI </a>\"的自信来自创始成员们此前资深的工作经验。创始人们在这些大厂多次带领团队实现技术和产品架构升级。比如贾扬清就曾在Meta将Pytorch打造为深受AI开发者们喜爱的框架的经历。这给 LeptonAI 的启示就是要与开发者“共鸣”：虽然Pytorch可能在性能方面不及静态图的TensorFlow，但它让开发者使用起来更方便。“我们对AI开发者的需求有很好的理解，知道他们在使用时可能遇到的问题。”</p><p>&nbsp;</p><p>除了“AI大神”贾扬清，团队很多成员之前都曾在阿里、Google、Meta和Uber等大厂工作，积累了在AI应用和AI框架方面的丰富经验。团队对云基础架构也有深入了解，能够充分利用各种云资源，包括完备的云服务商和基础的IDC。同时，新团队的成果，比如之前做的Llama 2 API 以及SDXL性能优化等，得到了开发者们认可和好评，这也让团队更加自信。</p><p>&nbsp;</p><p>“在业界，找出这样一支能够在这些方面都表现出色的团队是非常困难的。”鱼哲说道。</p><p>&nbsp;</p><p>至今为止，LeptonAI 仍然专注于开发面向应用和开发者的 AI 工具平台。不过，鱼哲也表示，顺势而为非常关键，“每个团队都需要建立自己的基本实力和核心竞争力，在此基础上，关键就看哪个团队能够更快地跟上技术热点的发展，并且能够充分利用已有的能力。”</p><p>&nbsp;</p><p>LeptonAI 不会制定过于详细的长期规划，而是倾向更灵活地应对局势，以月、周为周期来关注公司的目标和方向，不断调整和适应变化。</p><p>&nbsp;</p><p>比如，目前市场需求主要集中在大模型方面，公司则会在这方面相对投入更多资源。但这并不意味着LeptonAI 放弃了传统的深度学习或机器学习模型，因为很多企业实际上是混合模型的架构，这些传统模型并没有被舍弃。</p><p>&nbsp;</p><p></p><h2>怎么做好产品？</h2><p></p><p>&nbsp;</p><p>“我们不是过去传统意义上的服务提供者。”鱼哲强调，“我们是要将客户的行业专业知识转化为应用落地的加速器，而不是代替他们完成任务。”</p><p>&nbsp;</p><p>在对外交流过程中，鱼哲发现用户的需求多且细，比如企业很想使用一些机器学习和深度学习模型，但模型的复杂度是个阻碍；企业想在不将代码放在公共互联网上的情况下，利用代言模型来管理代码补全，但技术能力可能无法实现等。鱼哲团队要做的就是依靠工作经验找到其中确定性的东西，来解决用户真实存在的问题。</p><p>&nbsp;</p><p>当前，LeptonAI 的思路是：开发者用 Python 原生方式构建模型，无需学习容器或 Kubernetes；然后在本地调试和测试模型，再使用单个命令将它们部署到云端；之后，开发者可以通过简单、灵活的 API 在任何应用程序中使用模型。这个过程中，LeptonAI 还要帮开发者选择最适合应用程序的异构硬件，并做水平扩展来处理大量工作负载。</p><p>&nbsp;</p><p>为了方便开发者以更舒适的方式构建和打包AI应用，LeptonAI 提供了一个名为“光子（Photon）”的Python库，“光子无处不在，何时何地都能找到它，同时也象征着速度快的特性。”Photon最初是团队将机器学习模型、运行时环境以及工程代码有机结合的抽象概念。现在，Photon定义了一组处理程序和Python 依赖项，用户也可以根据情况构建自己的Photon。</p><p>&nbsp;</p><p>关于 Python作为AI服务框架的问题，业内目前存在一些争议，比如Python GIL是众所周知令人头疼的问题。为解决Python 带来的性能问题，大家的基本思路似乎是放弃Python：Hugging Face 用Rust 重写了一个 ML 框架、Modular 公司发布了名为 Mojo 的新编程语言。在鱼哲看来，Python 的应用取决于具体的使用场景。例如高频量化交易场景可能需要使用更低级别的语言来满足毫秒级延迟的要求，而在其他情况下，几十毫秒级别的延迟可能是可接受的。</p><p>&nbsp;</p><p>对于性能要求极高的场景，LeptonAI 会对原本在Python下进行的模型服务进行编译、推理、优化和加速等处理，进而保证其他方面的高效运行。比如部署在机器人或车辆上的应用，运行时资源非常有限，LeptonAI 会通过特殊的压缩手段来保持更高的性能，而用户端是无感的。</p><p>&nbsp;</p><p>LeptonAI 当前主要在公有云中提供全托管服务，但LeptonAI 给自己的定位和传统云厂商有些不同。“我们帮助客户制定自己的AI战略，这是很多厂商不提供的服务。我们能够提供很多云厂商无法提供的技术细节，我们比云厂商更深入了解AI。”鱼哲说道。</p><p>&nbsp;</p><p>目前LeptonAI 产品处于开放测试阶段，还在不断优化迭代和完善功能。比如团队推出了一个名为 <a href=\"https://www.infoq.cn/article/MPINGBSC8woTh558i7Fq\">TUNA </a>\"的功能，用户只需要上传语料，就能一键操作对模型进行微调。鱼哲总结自己产品的优势在开发者体验、价格成本和性能上。</p><p>&nbsp;</p><p>测试有时候也不仅仅针对产品，还有对开发团队心理的考验。“这个阶段，沮丧的事情有很多。”鱼哲说道，“当你抱着很高的期望尝试时，有时会发现某个基础组件并不稳定，或者是最初以为用户会非常喜欢的功能，实际做完后发现用户觉得很难用。”</p><p>&nbsp;</p><p>技术不断进步，总会有新的问题需要解决。在鱼哲看来，最重要的是保持冷静、坚定前行，因为很多事情并没有捷径可走。“这个道路上的坑也是多不胜数的，不要试图绕过，而是要努力填坑，并且越快越好。”</p><p></p><h4>承上启下的角色</h4><p></p><p>&nbsp;</p><p>现在，LeptonAI 的客户涵盖了金融、能源、自动驾驶以及信息互联网服务等领域。除了个别性能要求极高场景，LeptonAI 并不针对特定行业提供解决方案，更多是提供底层标准能力，方便用户快速应用。</p><p>&nbsp;</p><p>“我们处于一个承上启下的角色。因为在上游和下游的每个人，都有他们自己的客户（甲方）和供应商（乙方）。”鱼哲说道。</p><p>&nbsp;</p><p>LeptonAI 提供算力、模型和服务，服务方面包括通用流行模型的API服务、个性化模型的平台服务和对模型进行微调和部署的服务。这些能力背后需要计算、存储和网络三种资源支撑。LeptonAI 会从不同的供应商那里采购这些资源，包括传统云厂商和新兴云厂商。能够做好供应链整合、在价格上获得比竞争对手更大的优势，这也是LeptonAI 的核心竞争力之一。</p><p>&nbsp;</p><p>LeptonAI 的收费项主要有三部分：基于软件订阅的费用，私有模型部署的资源使用费用，和热门模型的使用费用。资源使用的定价逻辑是基于规格乘以使用时长的方式来计算。对于单位价格，LeptonAI 基于AWS、GCP、Azure等多个市场供应商来设定适当价格。</p><p>&nbsp;</p><p>鱼哲表示，LeptonAI 并不是基于各种成本来定价的，而是假设用户自己处理需要花费的成本，然后LeptonAI 在此基础上设定价格，目的是确保用户直接购买现成解决方案比自己做要更加划算。</p><p>&nbsp;</p><p>不过鱼哲强调，低成本并非是LeptonAI 的主打市场推广策略，同时还是要关注用户使用体验和产品性能。毕竟To B，从来就不是单个维度上的短跑，而是多个维度的长跑。</p><p>&nbsp;</p><p>此外，LeptonAI 也在积极融入整个行业发展中，以GitHub开源工具链SDK的方式来降低模型使用的门栏，让每一位AI开发者们通过一行命令即可拉起热门模型。</p><p>&nbsp;</p><p></p><h2>不能“拿着锤子找钉子”</h2><p></p><p>&nbsp;</p><p>关注AI多年，鱼哲这次感受到的一个显著变化是，人们不再是仅仅被炫酷的技术吸引后就不断投入资金进行尝试，反而会更加迅速地关注技术的实际应用和落地，更注重可行性和投资回报率（ROI）。人们变得更加理性，特别是在资本投入方面，也更加客观、认真地去思考技术如何落地。</p><p>&nbsp;</p><p>大模型因为聊天机器人被更多人熟知，但大模型不仅仅是聊天机器人。大模型的多模态特性可以将世界上的丰富多彩元素转化为机器可理解的格式。大模型的应用场景是非常广泛的。但对于大模型应用来说，最困难的不是训练模型，而是找到适合的应用场景和相应数据。</p><p>&nbsp;</p><p>鱼哲表示，开发大模型应用，行业经验和数据的质量是非常重要的因素：有足够的行业经验才能更好地理解目标受众的需求和应用场景；而数据的质量和多样性将直接影响模型的性能和效果。这两项确定后，拥有先发优势就非常关键，开发者一定要保持持一定的迭代速度。</p><p>&nbsp;</p><p>但在新技术落地上，找到场景也很难。“如果我现在只是拿着一个大模型去构建应用，那这就像拿着锤子找钉子。实际上，我们应该先有一个场景，然后再构建相应的应用。”鱼哲进一步说道，同时，大模型落地还需要企业里有既了解特定场景又熟悉相关技术、清楚什么能做什么不能做的人才，才能真正落地。</p><p>&nbsp;</p><p>本质上，大模型应用还处于非常早期的阶段，大多数应用仍停留在概念验证（POC）或短期上线能够使用的状态。就像Bing或者Google 搜索虽然落地了，但在特定领域的深度应用还在不断尝试中。</p><p>&nbsp;</p><p>“建议大家不要被大模型束缚住。实际落地时，除了大模型外，还可以充分利用许多已存在的深度学习模型或传统模型。例如在图像处理方面，卷积神经网络（CNN）实际上可能比大模型更适用。”鱼哲说道。</p><p>&nbsp;</p><p>如今，行业在大模型上基本形成了这样的共识：没必要一味追求大规模参数，开源会成为主流，通用大模型并不“通用”，垂直行业的大模型更被期待。鱼哲认为，下一步是努力消除基础能力和场景差距。这方面，AI Agent 被寄予厚望，人们希望借此解决单靠大模型无法解决的问题。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/73/731fcd2c495ee060a8019b81b687d7c1.png\" /></p><p></p><p>AI Agent 示意图</p><p>&nbsp;</p><p>简单说来，AI Agent希望达成的效果是：一个独立思考的实体具备了多种技能，这些技能可以组合起来应用到生产中，最终交付出一个成果。其中，大模型充当了代理的大脑，并由Memory、Tools、Planning、Action几个关键组件进行补充。</p><p>&nbsp;</p><p>鱼哲设想的一个Agents应用场景是交互式搜索，比如用户去某地方开会，智能助手可以除了导航还可以提示哪里可以停车等。鱼哲始终认为，技术否能够成功取决于它是否能与特定场景良好结合，停留在实验室内的技术不见天日更难有机会被打磨，因此更接近场景的人其实更有机会。</p><p></p><h2>结束语</h2><p></p><p>&nbsp;</p><p>“我无法设想 AI 不再流行的情景。”鱼哲说道，“AI 代表了一种信息处理的方式，而人类对于信息处理方式的投入只会越来越多，不会减少。”鱼哲预计，人工智能的进步和发展会越来越深入和持久，自己也会持续在这个行业深耕下去。</p><p>&nbsp;</p><p>鱼哲坦言，自己最擅长的领域仍然是人工智能。在这个领域工作久了，他逐渐意识到，技术落地的过程比想象的复杂得多，有些事很多时候更像是一场马拉松，而不是一次短跑。他现在的首要目标是和团队一起帮助LeptonAI 发展壮大，在这个前提下，继续秉持自己的兴趣前行。</p>",
    "publish_time": "2023-10-09 14:26:42",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]