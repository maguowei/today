[
  {
    "title": "优化容器工作负载：Kubernetes装箱的效益和挑战",
    "url": "https://www.infoq.cn/article/xW8oBGXBqDkhDMgOALDC",
    "summary": "<p>Kubernetes已经成为容器编排事实上的标准，因此企业不断寻求优化其集群资源利用的方法。其中一种技术是装箱（bin packing）：在集群中有效地分配资源，以最小化运行工作负载所需的节点数量。装箱使得企业能够通过减少支持应用程序所需的节点数量来降低成本。</p><p>&nbsp;</p><p>在Kubernetes中，装箱的概念涉及在节点内部战略性地放置容器或“箱子（bin）”，以最大化资源利用率和减少资源浪费。如果实施得当，可以实现对硬件资源更有效的利用，并降低基础设施成本。在云环境中，这尤为重要，因为基础设施支出占据IT开支的相当大部分。</p><p>&nbsp;</p><p>在本文中，我们将探讨在Kubernetes中进行装箱的复杂性，讨论与这种方法相关的挑战和权衡，并提供在企业中实现装箱的示例和最佳实践。</p><p>&nbsp;</p><p></p><h2>Kubernetes装箱挑战</h2><p></p><p>&nbsp;</p><p>尽管Kubernetes中的装箱在资源利用和成本节约方面提供了显著的好处，但也带来了一些需要解决的问题。</p><p>&nbsp;</p><p></p><h3>密度与工作负载隔离和分发</h3><p></p><p>&nbsp;</p><p>实现装箱的一个主要问题是在最大化资源密度和保持工作负载隔离性之间找到平衡，同时要确保工作负载分布在系统和可用区（AZ）中，以御硬件故障。将容器高密度地打包到节点上可以提高资源利用率，但也可能增加对共享资源（如CPU和内存）争用的风险。</p><p>&nbsp;</p><p>这可能导致性能下降，并可能影响整个集群的稳定性。此外，过度的装箱可能与分配的概念相矛盾，降低系统抵御硬件故障的能力。因此，我们有必要明智地并只在用例有意义的情况下应用装箱策略。</p><p>&nbsp;</p><p>为了更深入地理解这种权衡的含义，有必要考虑密度的增加对集群容错性所造成的影响。当容器被高密度地打包到较少的节点上时，单个节点的故障可能对应用程序的整体健康和可用性产生更大的影响。这带来了一个问题：在节省成本的同时，如何确保你的工作负载对潜在故障的弹性？</p><p>&nbsp;</p><p></p><h3>在节点上过度集中应用程序的风险</h3><p></p><p>&nbsp;</p><p>在节点中过度装箱应用程序的风险与保持分布式部署的“最佳实践”是两个对立面。把所有的鸡蛋放在一个篮子里，这是典型的风险管理错误。这是一种操作风险，如果某些节点宕机，整个部署的更大部分也将随之离线。因此，一方面，出于弹性的考虑，你希望尽可能偏向分布式。另一方面，你希望控制成本，而装箱是一个很好地解决方案。在这种平衡中找到最佳的点才是关键。</p><p>&nbsp;</p><p>当多个容器争用单个节点有限的资源（如内存或CPU）时，这些问题变得更加明显，从而导致资源匮乏和应用程序性能下降。此外，以非逐渐方式或突发方式扩展系统还可能导致不必要的故障，进一步加剧这些挑战。为了应对这些不一致性，可以尝试设置策略限制，确保向应用程序提供可靠的资源。</p><p>&nbsp;</p><p>在高密度装箱到节点时需要考虑的另一个问题是对维护和更新的潜在影响。随着在单个节点上运行更多的容器，对维护任务或软件更新的影响可能会被放大，导致更长时间的停机或降低应用程序性能。在进行装箱时，如何管理更新和维护而不对工作负载性能产生负面影响，是需要认真考虑的问题。</p><p>&nbsp;</p><p></p><h3>解决挑战的调度策略</h3><p></p><p>&nbsp;</p><p>Kubernetes提供了几种调度策略来帮助解决与装箱相关的问题：</p><p>&nbsp;</p><p><a href=\"https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\">资源请求和限制</a>\" 允许你配置Kubernetes调度程序在进行调度决策时考虑每个节点上的可用资源，这使你能够将容器放置在具有适当资源量的节点上。<a href=\"https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\">Pod亲和性和反亲和性规则</a>\" 允许你根据其他Pod的存在来指定Pod应该或不应该放置在哪些节点上，这有助于确保工作负载在整个集群中均匀分布，或者根据特定要求在某些节点上进行分组。例如，处理基本客户数据的数据关键系统需要尽可能偏向分布式，以增强可靠性和性能。这种方法可以降低单点故障风险，带来更好的整体系统弹性。<a href=\"https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/\">Pod拓扑传播约束</a>\" 使你能够考虑区域等因素，控制Pod在节点之间的分布方式。通过使用这些约束，你可以确保工作负载均匀分布，最大限度地减少单个节点过载的风险，并提高整体集群弹性。</p><p>&nbsp;</p><p>通过仔细考虑和实施这些调度策略，你可以有效地解决在Kubernetes中进行装箱所面临的挑战，同时保持最佳的资源利用率和性能。</p><p>&nbsp;</p><p></p><h2>Kubernetes装箱示例</h2><p></p><p>&nbsp;</p><p>关于在Kubernetes中如何有效地为不同类型的工作负载（从无状态的Web应用程序到数据库实例等）实施装箱，我们将在下面探讨其中一些示例。</p><p>&nbsp;</p><p></p><h3>无状态应用程序</h3><p></p><p>&nbsp;</p><p>Kubernetes可以将多个无状态应用程序实例打包到单个节点中，同时确保每个实例都具有足够的资源。通过使用资源请求和限制，你可以引导Kubernetes调度程序为每个实例分配适当数量的CPU和内存。只要这些实例有足够的资源，它们就会启动并运行，并确保无状态应用程序（如Web应用程序或面向客户的应用程序）具有高可用性。</p><p>&nbsp;</p><p></p><h3>数据库实例</h3><p></p><p>&nbsp;</p><p>在处理数据库时，Kubernetes可以有效地将不同有状态应用程序的单个实例打包到节点中，以最大化吞吐量和最小化延迟。通过利用Pod亲和性规则，你可以确保数据库实例放置在拥有必要的卷并与其他组件（如缓存服务器或应用程序服务器）接近的节点上。这有助于优化资源使用，同时保持数据库操作的高性能和低延迟。</p><p>&nbsp;</p><p></p><h3>批处理和机器学习工作负载</h3><p></p><p>&nbsp;</p><p>装箱也能给批处理和机器学习工作负载带来好处。Kubernetes可以使用Pod拓扑传播约束确保这些工作负载均匀分布在节点上，防止资源争用，保持性能处于最佳状态。</p><p>&nbsp;</p><p></p><h3>大型多节点集群</h3><p></p><p>&nbsp;</p><p>如果需要将服务分布到大量节点（例如2000个节点）中，资源优化仍然是一个重要的考虑因素。虽然将这些服务分散开对于容错能力来说是必不可少的，但仍然需要考虑对剩余的服务进行装箱，以提高节点的利用率。</p><p>&nbsp;</p><p>如果使用了特定的节点资源，Kubernetes可以通过拓扑传播配置（例如<a href=\"https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/\">PodTopologySpreadArgs</a>\"）来管理它们。集群管理员和云供应商应该要确保节点得到相应的配置，以平衡分散的服务和装箱的服务。</p><p>&nbsp;</p><p>通过理解和应用这些示例，你可以利用装箱来优化资源利用率，提高集群的整体效率。</p><p>&nbsp;</p><p></p><h2>Kubernetes装箱的成本效益</h2><p></p><p>&nbsp;</p><p>通过在集群内有效地分配资源并最小化支持工作负载所需的节点数量，装箱有助于降低基础设施成本。这是通过将多个容器合并到较少的节点上实现的，减少了对额外硬件或云资源的需求。因此，企业可以在硬件、能源和维护方面节省开支。</p><p>&nbsp;</p><p>在云环境中，基础设施成本占IT开支的很大一部分，因此通过装箱实现的成本节省可能非常显著。云提供商通常根据使用的节点数量和大小向客户收费，通过装箱优化资源利用率直接可以转化为减少云基础设施费用。</p><p>&nbsp;</p><p></p><h2>Kubernetes装箱最佳实践</h2><p></p><p>&nbsp;</p><p>要充分利用Kubernetes装箱所带来的好处，需要遵循一些最佳实践，确保在防止出现性能问题的同时实现最佳资源利用。以下是三个重要的最佳实践。</p><p>&nbsp;</p><p></p><h3>谨慎的规划和测试</h3><p></p><p>&nbsp;</p><p>在Kubernetes环境中实施装箱之前，需要仔细规划和测试容器在节点中的放置。这可能涉及分析工作负载的资源需求，确定适当的密度水平，并在不同场景下测试集群的性能和稳定性。此外，设置内存的硬限制至关重要，因为内存是不可压缩的资源，应谨慎分配，以避免影响其他的应用程序。还要考虑潜在的内存泄漏问题，确保一个节点的内存泄漏不会在整个系统中造成混乱。</p><p>&nbsp;</p><p>花一些时间进行规划和测试有助于避免与装箱相关的潜在问题，如资源争用和性能下降。</p><p>&nbsp;</p><p></p><h3>正确设置节点和容器大小</h3><p></p><p>&nbsp;</p><p>正确设置节点和容器大小是优化Kubernetes环境中资源利用的关键。为实现这一目标，首先需要评估应用程序的资源需求，如CPU、内存和存储。这些信息有助于确定最适合的节点大小和容器资源限制，以最大限度地减少浪费和提高效率。为工作负载设置适当的节点和容器大小至关重要，因为如果你的容器太大并占用了节点相当比例的资源，那么你将无法将其他容器放置到节点上。例如，如果你运行一个非常大的容器，占用了每个节点75%的资源，那么将导致25%的浪费，无论你设置了多少装箱规则。在优化Kubernetes环境时，容器分配的资源和机器提供的资源是需要考虑的关键因素。</p><p>&nbsp;</p><p></p><h3>随时监控和调整</h3><p></p><p>&nbsp;</p><p>在Kubernetes集群中保持最佳资源利用需要进行持续的监控和调整。随着工作负载和需求的演变，可能需要重新评估装箱策略，以确保其有效性。</p><p>&nbsp;</p><p>进行定期监控可以帮助你及早识别问题，如资源争用或未被充分利用的节点，让你能够在问题升级之前做出调整。</p><p>&nbsp;</p><p></p><h3>利用Kubernetes特性进行装箱</h3><p></p><p>&nbsp;</p><p>资源配额 允许你限制命名空间可以消耗的资源量，确保不存在单个工作负载垄断集群的可用资源。资源请求和限制 可以让你引导Kubernetes调度程序将容器放置在具有适当资源量的节点上，这有助于确保工作负载被高效分配，并最小化资源争用。</p><p>&nbsp;</p><p>另外需要考虑的一点是基础设施对环境的影响。通过装箱来优化资源利用，你可以潜在地减少企业的碳排放。运行较少的节点意味着消耗更少的能源并产生更少的热量，这有助于降低温室气体排放和降低对环境的影响。这带来了一个重要的问题：企业如何在追求成本效益和性能的同时，平衡其社会责任，以减少碳排放？</p><p>&nbsp;</p><p></p><h2>结论</h2><p></p><p>&nbsp;</p><p>在Kubernetes中进行装箱在优化资源利用和降低基础设施成本方面发挥着至关重要的作用，但同样重要的是如何在优化Kubernetes资源时正确找到效率和性能之间的平衡。</p><p>&nbsp;</p><p>通过在集群中战略性地分配资源，企业可以将运行工作负载所需的节点数量降到最低，实现更低的支出和更高效的基础设施管理。</p><p>&nbsp;</p><p>然而，正如讨论过的那样，企业需要面对与装箱相关的一些性能挑战和权衡以及在Kubernetes环境中有效使用装箱的最佳实践。通过理解和利用这些技术，企业可以最大限度地利用集群中的资源，节省基础设施成本，并提高总体效率。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p>https://www.infoq.com/articles/kubernetes-bin-packing/</p><p></p><p></p><h5>相关阅读：</h5><p></p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MzIzNjUxMzk2NQ%3D%3D&amp;chksm=e8d7e428dfa06d3ed76212b029784a7db555f1c09321a535ded950b30a7258bf3d84e30de519&amp;idx=1&amp;mid=2247490538&amp;scene=27&amp;sn=d9aab0a30357e4b1689e578144cf3957&amp;utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search#wechat_redirect\">50+ 顶级开源&nbsp;Kubernetes&nbsp;工具列表</a>\"</p><p><a href=\"https://www.infoq.cn/article/kubernetes-effect?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">Kubernetes&nbsp;效应</a>\"</p><p><a href=\"https://www.infoq.cn/article/8XZ4ZV59Yx9NHyqbaIlI?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">你该如何为&nbsp;Kubernetes&nbsp;定制特性</a>\"</p><p><a href=\"https://www.infoq.cn/article/u6D2XoVVVz1fpxxzBKzT?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search\">用了就会更好吗？小心&nbsp;Kubernetes&nbsp;陷阱</a>\"</p>",
    "publish_time": "2023-12-21 00:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Java新闻汇总：JDK 22、Spring CVE、Liberica JDK、JDKMon 21、Jupyter for Java和Gradle 8.5",
    "url": "https://www.infoq.cn/article/kHGCPfPcKtU7XBaxATRU",
    "summary": "<p></p><h4>OpenJDK</h4><p></p><p></p><p>在审查结束后，JEP 463，<a href=\"https://openjdk.org/jeps/463\">隐式声明类和实例主方法（Implicitly Declared Classes and Instance Main Methods，第二轮预览）</a>\"，已经在JDK 22中从Targeted状态<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-November/008469.html\">提升</a>\"到了Proposed to Target状态。它以前被称为未命名类和实例主方法（Unnamed Classes and Instance Main Methods，预览）、灵活主方法和匿名主类（Flexible Main Methods and Anonymous Main Classes，预览）和隐式类和增强的主方法（Implicit Classes and Enhanced Main Methods，预览），该JEP包含了对前一轮<a href=\"https://openjdk.java.net/jeps/12\">预览</a>\"反馈的增强，即JEP 445，<a href=\"https://openjdk.org/jeps/445\">未命名类和实例主方法（预览）</a>\"。这个JEP建议“演进Java语言，这样学生们就可以编写他们的第一个程序，而不需要理解为大型程序所设计的语言特性”。该JEP延续了甲骨文的Java语言架构师<a href=\"https://www.linkedin.com/in/briangoetz/\">Brian Goetz</a>\"在2022年9月发表的博客文章<a href=\"https://openjdk.org/projects/amber/design-notes/on-ramp\">Paving the on-ramp</a>\"。甲骨文的技术顾问<a href=\"https://www.linkedin.com/in/gavin-bierman-a0173075/\">Gavin Bierman</a>\"已经<a href=\"https://mail.openjdk.org/pipermail/amber-dev/2023-May/008065.html\">发布了</a>\"规范文档的<a href=\"https://cr.openjdk.org/~gbierman/jep445/jep445-20230502/specs/unnamed-classes-instance-main-methods-jls.html\">初稿</a>\"，供Java社区审查。关于JEP 445的更多细节可以在InfoQ的<a href=\"https://www.infoq.com/news/2023/05/beginner-friendly-java/\">新闻报道</a>\"中找到。</p><p>&nbsp;</p><p>在审查结束后，JEP 462，<a href=\"https://openjdk.org/jeps/462\">结构化并发（Structured Concurrency，第二次预览）</a>\"，已经从Proposed to Target状态<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-December/008493.html\">提升</a>\"到了Targeted状态。这个JEP提议在JDK 22中重新审查API，不做任何变更，以便于从上一轮预览中获取更多的反馈，即JDK 21交付的JEP 453，<a href=\"https://openjdk.org/jeps/453\">结构化并发（预览）</a>\"。这个特性通过引入结构化并发性来简化并发编程，“将在不同线程中运行的相关任务组视为单个工作单元，从而简化错误处理和取消，提高可靠性并增强可观测性。”</p><p>&nbsp;</p><p>在审查结束后，JEP 461,&nbsp;<a href=\"https://openjdk.org/jeps/461\">流收集器（Stream Gatherers，预览）</a>\"，已经在JDK 22中从Proposed to Target状态<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-November/008473.html\">提升</a>\"到了Targeted状态。该JEP建议增强流API以支持自定义的中间操作。“这将允许流管道以现有内置中间操作难以实现的方式转换数据。”关于此JEP的更多细节可以参考甲骨文Java平台组软件架构师<a href=\"https://www.linkedin.com/in/viktorklang/\">Viktor Klang</a>\"编写的原始<a href=\"https://cr.openjdk.org/~vklang/Gatherers.html\">设计文档</a>\"。</p><p>&nbsp;</p><p>在审查结束后，JEP 458，<a href=\"https://openjdk.org/jeps/458\">启动多文件源码程序（Launch Multi-File Source-Code Programs）</a>\"，已经在JDK 22的Proposed to Target状态<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-December/008494.html\">提升</a>\"到了Targeted状态。该JEP建议增强Java Launcher，以执行通过一个或多个Java源代码文件提供的应用程序。这可以通过推迟一个完整项目的搭建来实现从小型应用程序到大型应用程序的渐进过渡。</p><p>&nbsp;</p><p>在审查结束后，JEP 457，<a href=\"https://openjdk.org/jeps/457\">类文件API（Class-File API，预览）</a>\"，已经在JDK 22的Proposed to Target状态<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-November/008471.html\">提升</a>\"到了&nbsp;Targeted状态。该JEP建议提供一个API来解析、生成和转换Java类文件。它最初作为JDK中<a href=\"https://asm.ow2.io/\">ASM</a>\"的替代品，ASM是一个Java字节码操作和分析框架，并计划将其作为公开API对外开放。甲骨文的Java语言架构师<a href=\"https://www.linkedin.com/in/briangoetz\">Brian Goetz</a>\"将ASM描述为“带有大量遗留包袱的旧代码库”，并提供了关于该草案如何发展并最终取代ASM的<a href=\"https://mail.openjdk.org/pipermail/discuss/2022-June/006131.html\">背景信息</a>\"。</p><p>&nbsp;</p><p>在审查结束后，JEP 423，<a href=\"https://openjdk.org/jeps/423\">G1的区域锚定（Region Pinning for G1）</a>\"，已经在JDK 22的Proposed to Target<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-November/008470.html\">提升</a>\"到了&nbsp;Targeted状态。该JEP建议通过实现<a href=\"https://docs.oracle.com/en/java/javase/17/gctuning/garbage-first-g1-garbage-collector1.html#GUID-ED3AB6D3-FD9B-4447-9EDF-983ED2F7A573\">G1垃圾收集器</a>\"的区域锚定来减少GC延迟。这将扩展G1，以便在major和minor收集操作期间可以锚定任意区域，以便于实现<a href=\"https://shipilev.net/jvm/anatomy-quarks/9-jni-critical-gclocker/\">JNI关键区域</a>\"时避免禁用垃圾收集进程。</p><p>&nbsp;</p><p>JEP 464，<a href=\"https://openjdk.org/jeps/464\">作用域值（Scoped Values，第二次预览）</a>\"，已经从它的JEP Draft 8318898状态<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-November/008472.html\">提升</a>\"至Candidate状态，然后快速在JDK 22<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-November/008480.html\">提升</a>\"到了Proposed to Target状态。它以前被称为范围局部变量（Extent-Local Variables，孵化），这个JEP建议在JDK 22中重新预览API，不做任何更改，以便于从上一轮预览中获得额外的经验和反馈，即JDK 21交付的JEP 446,&nbsp;<a href=\"https://openjdk.org/jeps/446\">作用域值（预览）</a>\"和JDK 20交付的<a href=\"https://openjdk.org/jeps/429\">作用域值（孵化）</a>\"。该特性允许在线程内部和线程之间共享不可变数据。这种方式优于thread-local变量，特别是在使用大量虚拟线程的时候。该审查预计会在2023年12月7日结束。</p><p></p><h4>JDK 22</h4><p></p><p></p><p>JDK 22的早期访问构建版本的<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-22%2B26\">Build 26</a>\"发布，其中包括对Build 25的<a href=\"https://github.com/openjdk/jdk/compare/jdk-22%2B25...jdk-22%2B26\">更新</a>\"，其中包括对各种<a href=\"https://bugs.openjdk.org/issues/?jql=project%20%3D%20JDK%20AND%20fixversion%20%3D%2022%20and%20%22resolved%20in%20build%22%20%3D%20b26%20order%20by%20component%2C%20subcomponent\">问题</a>\"的修复。关于这个版本的更多细节可以在<a href=\"https://jdk.java.net/22/release-notes\">发行说明</a>\"中找到。</p><p>&nbsp;</p><p>对于<a href=\"https://openjdk.org/projects/jdk/22/\">JDK 22</a>\"，鼓励开发人员通过<a href=\"https://bugreport.java.com/bugreport/\">Java缺陷数据库</a>\"报告缺陷。</p><p></p><h4>Jakarta EE</h4><p></p><p></p><p><a href=\"https://jakarta.ee/specifications/data/\">Jakarta Data</a>\"&nbsp;1.0.0的第二个里程碑版本提供了如下特性：制品名称的重命名，例如，从jakarta-data-api改为jakarta.data-api，以便于同所有Jakarta EE规范保持一致；延迟静态元模型的实现，以进一步解决与反射和注解处理器相关的问题；对版权文档的优化，以便将值与占位符绑定。关于此版本的更多细节可以在<a href=\"https://github.com/jakartaee/data/releases/tag/1.0.0-M2\">发布说明</a>\"中找到。</p><p>&nbsp;</p><p><a href=\"https://www.jnosql.org/\">Eclipse JNoSQL</a>\"（<a href=\"https://jakarta.ee/specifications/nosql/\">Jakarta NoSQL</a>\"规范的兼容实现）的1.0.3版本发布，带来重要的数据库升级，比如，MongoDB驱动4.11.1、Hazelcast 5.3.6、Apache Solr 9.4.0、Couchbase Library 3.4.11和ArangoDB Library7.2.0。更新方法还实现了增强功能，以改进整个项目的功能。关于此版本的更多细节可以在<a href=\"https://github.com/eclipse/jnosql/releases/tag/1.0.3\">发布说明</a>\"中找到。</p><p></p><h4>BellSoft</h4><p></p><p></p><p>BellSoft<a href=\"https://bell-sw.com/blog/bellsoft-releases-liberica-jdk-lts-17-and-21-with-coordinated-restore-at-checkpoint-crac-for-fast-startup/\">发布</a>\"了<a href=\"https://bell-sw.com/libericajdk/\">Liberica JDK</a>\"的17和21版本，这是他们OpenJDK的下游发行版，具有检查点协调恢复(Coordinated Restore at Checkpoint，CRaC)功能，使开发人员能够构建运行中的应用程序快照，减少Java应用的启动和预热时间。这些新版本将适用于x86_64和AArch64 CPU架构以及Linux操作系统。</p><p></p><h4>Spring Framework</h4><p></p><p></p><p>VMware<a href=\"https://spring.io/blog/2023/11/27/cve-2023-34053-cve-2023-34055-spring-framework-and-spring-boot\">披露</a>\"了两个安全漏洞：CVE-2023-34053，<a href=\"https://spring.io/security/cve-2023-34053\">Spring框架服务器Web观测DoS漏洞（Spring Framework Server Web Observations DoS Vulnerability）</a>\"以及CVE-2023-34055，<a href=\"https://spring.io/security/cve-2023-34055\">Spring Boot服务器Web观测DoS漏洞（Spring Boot Server Web Observations DoS Vulnerability</a>\"，它们会影响<a href=\"https://spring.io/projects/spring-framework\">Spring Framework</a>\"6.0.0至6.0.13版本和<a href=\"https://spring.io/projects/spring-boot\">Spring Boot</a>\"3.1.0至3.1.5版本、3.0.0至3.0.12版本以及2.7.0至2.7.17版本。这两个漏洞都允许攻击者提供特制的HTTP请求，这些请求可能会在以下情况下导致拒绝服务：</p><p>应用程序使用了<a href=\"https://docs.spring.io/spring-framework/reference/web/webmvc.html\">Spring MVC</a>\"或<a href=\"https://docs.spring.io/spring-framework/reference/web/webflux.html\">Spring WebFlux</a>\"。io.micrometer:micrometer-core制品位于类路径中。在应用程序中配置了Micrometer&nbsp;ObservationRegistry接口的实现来记录观测结果。</p><p></p><p>因此，鼓励开发人员升级到Spring Framework 6.0.14以及Spring Boot 2.7.18、3.0.13和3.1.6。</p><p>&nbsp;</p><p><a href=\"https://spring.io/projects/spring-shell\">Spring Shell</a>\"的3.2.0-rc1、3.1.6、3.0.10和2.1.15版本<a href=\"https://spring.io/blog/2023/11/28/spring-shell-2-1-15-3-0-10-3-1-6-and-3-2-0-rc1-are-now-available\">发布</a>\"，分别进行了缺陷修复和对Spring Boot 3.2.0、3.1.6、3.0.13和2.7.18依赖升级。3.0和2.1版本系列已被宣布与它们对应的Spring Boot版本一起结束生命周期。3.2.0-RC1和3.1.6版本中的新特性包括：支持zsh补全和模态视图；对<a href=\"https://docs.spring.io/spring-shell/reference/tui/index.html\">Terminal UI</a>\"的小改动。关于此版本的更多细节可以在<a href=\"https://github.com/spring-projects/spring-shell/releases/tag/v3.2.0-RC1\">3.2.0-RC1版本</a>\"、<a href=\"https://github.com/spring-projects/spring-shell/releases/tag/v3.1.6\">3.1.6版本</a>\"、<a href=\"https://github.com/spring-projects/spring-shell/releases/tag/v3.0.10\">3.0.10版本</a>\"和<a href=\"https://github.com/spring-projects/spring-shell/releases/tag/v2.1.15\">2.1.15版本</a>\"的发行说明中找到。</p><p></p><h4>Quarkus</h4><p></p><p></p><p>Red Hat<a href=\"https://quarkus.io/blog/quarkus-3-6-0-released/\">发布</a>\"了<a href=\"https://quarkus.io/\">Quarkus</a>\"的3.6.0版本，其中有一些显著的变化，比如，支持OIDC bearer令牌的自定义授权模式；改进了服务器发送事件(SSE)，允许REST客户端返回整个SSE事件并对这些事件进行过滤；支持与Jakarta Annotations&nbsp;@RolesAllowed注解类似的@SecureField注解中的表达式。关于这个版本的更多细节可以在<a href=\"https://github.com/quarkusio/quarkus/releases/tag/3.6.0\">变更日志</a>\"中找到。</p><p>&nbsp;</p><p>Red Hat还<a href=\"https://quarkus.io/blog/java-17/\">宣布</a>\"JDK 17将是即将发布的Quarkus 3.7要求的最低版本，它计划于2024年1月底发布。InfoQ将会跟进更详细的新闻报道。</p><p></p><h4>Open Liberty</h4><p></p><p></p><p>IBM<a href=\"https://openliberty.io/blog/2023/11/28/23.0.0.12-beta.html\">发布</a>\"了<a href=\"https://openliberty.io/\">Open Liberty</a>\"的23.0.0.12-beta版，该版本支持<a href=\"https://jakarta.ee/specifications/data/\">Jakarta Data</a>\"&nbsp;1.0.0-M1，其中包括：用于基本存储库方法的新&nbsp;BasicRepository接口；在CrudRepository接口中添加insert()和update()方法；新的@Insert、@Update、@Delete和@Save注解。这个版本还提供了一个可配置的静默超时阶段，即当Liberty运行时的关闭时间超过默认的30秒时。这能够支持需要更多时间来完成处理请求的服务。</p><p></p><h4>Helidon</h4><p></p><p></p><p><a href=\"https://helidon.io/\">Helidon</a>\"&nbsp;4.0.1，即<a href=\"https://github.com/helidon-io/helidon/releases/tag/4.0.1\">第一个维护版本</a>\"，提供了值得关注的变更，比如，支持Helidon Web服务器组件的<a href=\"https://www.haproxy.com/blog/use-the-proxy-protocol-to-preserve-a-clients-ip-address\">代理协议</a>\"；&nbsp;WebServer接口的性能改进；在&nbsp;CrossOriginConfig.Builder类中定义的enabled()方法现在返回Optional而不是boolean以解决CORS问题。关于此版本的更多细节可以在<a href=\"https://github.com/helidon-io/helidon/blob/4.0.1/CHANGELOG.md\">变更日志</a>\"中找到。</p><p>&nbsp;</p><p>同样，Helidon 3.2.4的<a href=\"https://github.com/helidon-io/helidon/releases/tag/3.2.4\">发布</a>\"提供了依赖项升级和一些值得注意的变化，例如，用于延迟OCI Vault配置的新类的集合；将opentracing相关的类和接口迁移到Helidon Tracing API；正确处理请求URL的IPv6地址的解析。关于这个版本的更多细节可以在<a href=\"https://github.com/helidon-io/helidon/blob/3.2.4/CHANGELOG.md\">变更日志</a>\"中找到。</p><p></p><h4>Hibernate</h4><p></p><p></p><p><a href=\"https://hibernate.org/reactive/\">Hibernate Reactive</a>\"&nbsp;2.2.0.Final版本<a href=\"https://in.relation.to/2023/11/28/hibernate-reactive-2_2_Final/\">发布</a>\"，它兼容Hibernate ORM 6.4.0.Final and Vert.x SQL driver 4.5.0。Red Hat还提供了2.2.1.Final和2.0.7.Final版本，它们分别与<a href=\"https://hibernate.org/orm/\">Hibernate ORM</a>\"的6.3.2.Final and 6.2.13.Final版本兼容。关于此版本的更多细节可以在<a href=\"https://github.com/hibernate/hibernate-reactive/releases/tag/2.2.0\">发布说明</a>\"中找到。</p><p>&nbsp;</p><p>Hibernate Search 7.1.0的<a href=\"https://in.relation.to/2023/11/30/hibernate-search-7-1-0-Alpha1/\">第一个alpha版本</a>\"提供了一个孵化特性，即允许在<a href=\"https://lucene.apache.org/\">Apache Lucene</a>\"后端进行矢量搜索，并提供了搜索二进制或文本数据的工具。此外，在Spring boot 3.2中读取嵌套JAR时，Hibernate Search将不再启动失败。关于此版本的更多细节可以在<a href=\"https://hibernate.atlassian.net/browse/HSEARCH-5024?jql=project%3D10061%20AND%20fixVersion%3D32219\">发布说明</a>\"中找到。</p><p></p><h4>Grails基金会</h4><p></p><p></p><p>Grails 5.3.4发布，提供了依赖升级和一些值得注意的变化，比如，为所有主分支启用GitHub&nbsp;<a href=\"https://codeql.github.com/\">CodeQL</a>\"；添加了一个SnakeYAML物料清单（BOM）来覆盖SpringBoot BOM；对Javadoc的清理，包括在Javadoc中转义特殊字符、重构代码、定义显式类型和删除不必要的变量使用。关于此版本的更多细节可以在<a href=\"https://github.com/grails/grails-core/releases/tag/v5.3.4\">发布说明</a>\"中找到。</p><p></p><h4>Apache软件基金会</h4><p></p><p></p><p><a href=\"https://groovy-lang.org/\">Apache Groovy</a>\"&nbsp;5.0.0的<a href=\"https://www.mail-archive.com/announce@apache.org/msg08717.html\">第三个alpha版本</a>\"提供了缺陷修复、依赖升级和功能改进，例如，支持JDK 22；实现了在groovyc命令行中进行库编译器时缺失的特性；还有一个针对数组类型的新indexOf(element)扩展方法。关于此版本的更多细节可以在<a href=\"https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12318123&amp;version=12353636\">发布说明</a>\"中找到。</p><p>&nbsp;</p><p>同样，Apache Groovy 4.0.16的<a href=\"https://www.mail-archive.com/announce@apache.org/msg08716.html\">发布</a>\"也提供了缺陷修复、依赖升级和功能改进，例如，对JDK 22的支持；在DefaultGroovyStaticMethods类中定义一个新的allThreads()方法，以补充Java Thread类中定义的现有currentThread()方法。关于此版本的更多细节可以在<a href=\"https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12318123&amp;version=12353637\">发布说明</a>\"中找到。</p><p>&nbsp;</p><p>为了与Quarkus保持一致，Camel Quarkus 3.6.0版本<a href=\"https://camel.apache.org/blog/2023/11/camel-quarkus-release-3.6.0/\">发布</a>\"，解决了以下问题：在执行QuartzQuarkusSchedulerAutowiredWithSchedulerBeanTest类的时候，出现间歇性的AssertionFailedError；在使用容器的测试中，清除硬编码对主机的使用。关于此版本的更多细节可以在<a href=\"https://camel.apache.org/releases/q-3.6.0/\">发布说明</a>\"中找到。</p><p>&nbsp;</p><p><a href=\"https://maven.apache.org/\">Apache Maven</a>\"&nbsp;3.9.6版本提供了依赖项升级和排除插件验证的功能。关于此版本的更多细节可以在<a href=\"https://github.com/apache/maven/releases/tag/maven-3.9.6\">发布说明</a>\"中找到。</p><p></p><h4>JDKMon</h4><p></p><p></p><p>监视和更新已安装jdk的工具<a href=\"https://github.com/HanSolo/JDKMon\">JDKMon</a>\"发布了<a href=\"https://github.com/HanSolo/JDKMon/releases/tag/21.0.0\">21.0.0</a>\"版本。这个工具由Azul的首席工程师<a href=\"https://de.linkedin.com/in/gerritgrunwald\">Gerrit Grunwald</a>\"创建，这个新版本通过将所有依赖项移动到最新的LTS版本，完全支持JDK 21。</p><p></p><h4>PrimeFaces</h4><p></p><p></p><p>PrimeFaces的12.0.7、11.0.13、10.0.20和8.0.25版本发布，特性包括：升级<a href=\"https://github.com/stleary/JSON-java/blob/master/README.md\">JSON in Java</a>\"到20231013，以解决<a href=\"https://nvd.nist.gov/vuln/detail/CVE-2023-5072\">CVE-2023-5072</a>\"漏洞，该漏洞允许攻击者利用JSON解析器中的缺陷，例如，中等大小的字符串输入可能导致无限量的内存使用并导致拒绝服务。关于这些版本的更多细节可以在<a href=\"https://github.com/primefaces/primefaces/issues?q=is%3Aissue+label%3A12.0.7+is%3Aclosed\">12.0.7版本</a>\"、<a href=\"https://github.com/primefaces/primefaces/issues?q=is%3Aissue+label%3A11.0.13+is%3Aclosed\">11.0.13版本</a>\"、<a href=\"https://github.com/primefaces/primefaces/issues?q=is%3Aissue+is%3Aclosed+label%3A10.0.20\">10.0.20版本</a>\"和<a href=\"https://github.com/primefaces/primefaces/issues?q=is%3Aissue+is%3Aclosed+label%3A8.0.25\">8.0.25版本</a>\"的发布说明中找到。</p><p></p><h4>Jupyter for Java</h4><p></p><p></p><p><a href=\"https://github.com/jupyter-java\">Jupyter for Java</a>\"，这是一个新的GitHub组织，旨在帮助开发人员发现在Jupyter notebooks中使用Java的各种方法。该项目由Red Hat的杰出工程师<a href=\"https://www.linkedin.com/in/maxrydahlandersen/\">Max Rydahl Andersen</a>\"创建，目前包含五个提供资源和样例的仓库。</p><p></p><h4>Gradle</h4><p></p><p></p><p><a href=\"https://gradle.org/\">Gradle</a>\"&nbsp;8.5.0<a href=\"https://github.com/gradle/gradle/releases/tag/v8.5.0\">发布</a>\"，提供了以下新特性：完全支持在JDK 21上编译、测试和运行；<a href=\"https://docs.gradle.org/8.5-rc-1/userguide/kotlin_dsl.html\">Kotlin DSL</a>\"的改进，包括在预编译Kotlin脚本插件中<a href=\"https://docs.gradle.org/8.5-rc-1/release-notes.html#faster-first-use\">更快的首次使用</a>\"以及<a href=\"https://docs.gradle.org/8.5-rc-1/release-notes.html#catalog-precompiled\">对版本目录的支持</a>\"；改进了错误和告警的报告。关于此版本的更多细节可以在<a href=\"https://docs.gradle.org/8.5/release-notes.html\">发布说明</a>\"中找到。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/12/java-news-roundup-nov27-2023/\">Java News Roundup: JDK 22, Spring CVEs, Liberica JDK, JDKMon 21, Jupyter for Java, Gradle 8.5</a>\"</p>",
    "publish_time": "2023-12-21 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "软硬结合，共赴服务器操作系统的云智未来",
    "url": "https://www.infoq.cn/article/7fJZyhHOECjwFE33z6TJ",
    "summary": "<p>随着&nbsp;CentOS&nbsp;停服、信创产业蓬勃发展、生成式&nbsp;AI&nbsp;浪潮来袭等大事件接连发生，国产服务器操作系统正在迎来前所未有的崛起机遇。据信通院近期调查显示，国内大量服务器操作系统用户已经开始了国产替换的考量或计划，有意愿且已开始试点或制定计划的用户高达&nbsp;72%，意向用户占&nbsp;12%。与此同时，在多样性算力和智能计算快速发展的背景下，服务器操作系统产业正在步入&nbsp;2.0&nbsp;时代，新一代国产服务器操作系统开始全面围绕如何充分释放计算能力的核心问题，面向以云计算、智能计算为主的技术方向进化，这一变化进一步加快了主流用户向国产操作系统迁移的进度。</p><p>&nbsp;</p><p>在国产服务器操作系统百花齐放的局面中，龙蜥操作系统社区是发展水平较高、品牌市场基础较好的榜样之一。2023&nbsp;年&nbsp;12&nbsp;月&nbsp;17-18&nbsp;日，首届龙蜥操作系统大会在北京召开，以《云智融合&nbsp;共筑未来》为主题，宣告龙蜥社区到达了一个新的发展节点。大会筹备期间，InfoQ&nbsp;采访了龙蜥社区副理事长单位，英特尔公司软件与先进技术事业部研发总监杨继国，就英特尔公司与龙蜥战略合作、社区共建以及云智融合对服务器操作系统的影响等主题进行了深入探讨。</p><p>&nbsp;</p><p></p><h2>生态共建，英特尔与龙蜥社区携手同行</h2><p></p><p>&nbsp;</p><p>英特尔公司是在&nbsp;2020&nbsp;年首批加入龙蜥社区的&nbsp;14&nbsp;家理事单位之一，英特尔也同时加入了龙蜥社区的技术委员会、运营委员会，与其他伙伴共同推动社区的生态发展。在龙蜥社区，各项社区活动总体是以各个社区兴趣小组为基础展开的，英特尔也创建了名为&nbsp;Intel&nbsp;SIG&nbsp;的兴趣小组，并参与和促进了总共&nbsp;14&nbsp;个相关兴趣小组的发展。这些小组共同努力，使得龙蜥操作系统对各大主流芯片架构、平台技术的支持达到了业内领先水平，例如英特尔第四代、第五代至强可扩展处理器的&nbsp;AMX&nbsp;加速引擎、QAT&nbsp;网络加速、TDX&nbsp;安全虚拟机技术等创新特性就第一时间在龙蜥系统中得到了支持。此外，英特尔还向社区贡献了很多英特尔与龙蜥共同运用的技术最佳实践，并举办了多场线上、线下&nbsp;Meetup、Workshop，与社区共同撰写技术白皮书等，通过多种形式推动社区生态发展。</p><p>&nbsp;</p><p>在英特尔看来，龙蜥社区是国内领先的系统软件和开源生态社区，对国产软件生态有着很大的影响力和促进作用。英特尔与龙蜥社区的合作对双方的技术创新和生态拓展都有良好的推动力，一方面英特尔能够帮助社区在先进芯片技术支持方面维持领先地位，另一方面龙蜥社区也能帮助英特尔将很多最新的平台技术、软件特性高效传递给用户。例如，Intel&nbsp;SIG&nbsp;帮助龙蜥操作系统的很多发行版对英特尔至强平台提供了完善支持，还通过最佳实践教学用户将至强平台的新特性充分利用起来；阿里云等社区合作伙伴也在英特尔的帮助下，在自身产品中运用了英特尔平台的创新特性，等等。</p><p>&nbsp;</p><p>英特尔公司在龙蜥社区中的经历只是龙蜥开放生态的一个缩影。整体而言，龙蜥是多元化的开源技术生态社区，有来自各个行业的生态伙伴共同参与，丰富的多样性使这些生态伙伴能够将不同行业的经验和需求都带入社区广泛交流应对。由此以来，当社区协商龙蜥的技术发展路线、开发不同的发行版等工作时，就能充分考虑到不同垂直行业的需求、利用各类创新技术成果，使得龙蜥的技术发展紧跟行业大趋势，进而在关键节点上推动各行各业的数字化升级。</p><p>&nbsp;</p><p></p><h2>国产服务器操作系统崛起，云智融合成为行业方向</h2><p></p><p>&nbsp;</p><p>今天，服务器操作系统技术正在从传统的服务器硬件管理、支撑应用运行逐渐向覆盖云、边、端多场景，支持多样化算力的方向升级迭代，服务器操作系统的边界不断拓展，针对不同场景的深度定制化与对异构算力的优化成为技术突破重点。在这样的背景下，国产开源服务器操作系统近年来发展飞快，以龙蜥为代表的新一代国产操作系统从发展伊始就面向全新的行业趋势来开发设计，从而很快得到了行业的认可与应用。仅以龙蜥操作系统为例，目前其装机量超过&nbsp;600&nbsp;万，服务各个行业用户超过&nbsp;80&nbsp;万，在政务、金融、电信、互联网等领域有着较好的用户基础，竞争力持续提升。此外，龙蜥开启捐献到了开放原子开源基金会的流程，为开源产业的发展做出了贡献和表率。</p><p>&nbsp;</p><p>随着云计算和人工智能技术的飞跃式进步，行业也需要服务器操作系统进行对应的升级。2023&nbsp;年是生成式&nbsp;AI全面爆发的元年，硬件产业做了很多创新来为大模型等&nbsp;AI&nbsp;应用提供更加充沛的算力支持。英特尔就在第四代至强处理器上引入了&nbsp;AMX&nbsp;加速引擎、动态负载均衡加速器&nbsp;DLB、数据流加速器&nbsp;DIC&nbsp;和&nbsp;TDX&nbsp;安全虚拟技术，帮助云厂商以更低的&nbsp;TCO、更加安全可信赖的环境为用户提供更高算力的生成式&nbsp;AI&nbsp;服务。对此，英特尔与龙蜥社区共同规划合作，在&nbsp;2023&nbsp;年的主要版本更新中率先支持了第四代至强处理器的诸多特性，有力支持了云厂商的生成式&nbsp;AI&nbsp;服务升级。</p><p>&nbsp;</p><p>纵观全局，云计算与人工智能的发展是互相促进，相辅相成的。云计算能够为&nbsp;AI&nbsp;提供大规模、多样化的并行&nbsp;AI&nbsp;算力支持，大模型可以充分利用云端海量数据进行训练和推理，且云计算全球化部署的特性使得&nbsp;AI&nbsp;产品可以轻松为全球用户提供服务。反过来说，AI&nbsp;也能够为云计算提供更加智能的技术和运维支持，提升服务质量，实现智能服务调度和优化、智能算力预测等智算功能，帮助云厂商提升服务效率，降低&nbsp;TCO。云计算与人工智能结合，还让更多缺乏足够资源的中小企业可以轻松运用大模型等前沿技术进行业务创新，改善用户体验。</p><p>&nbsp;</p><p>服务器操作系统作为云计算基础设施的重要组成部分，在云智融合、携同发展的技术大势中肩负着重要任务。新一代服务器操作系统需要提供更好的解决方案，完美地融合各类开源工具链，帮助&nbsp;AI&nbsp;开发者和用户能够更轻松地构造、部署、管理和使用基于云计算的&nbsp;AI&nbsp;服务。另一大挑战来自安全性，AI&nbsp;服务的基础模型、算法和数据都需要更加完善的安全防护，预防窃取、篡改和滥用，这就要求操作系统建立更加安全、高效的响应机制。操作系统需要依托开源社区和专业安全机构，第一时间获取软件漏洞信息，同时通过迅捷的安全修复机制尽快修复漏洞，并及时响应已发生的安全攻击事件。最后，云智时代软硬件技术的频繁升级还会带来很多兼容性挑战，服务器硬件组件的持续升级需要软件层面优化适配，服务器操作系统的升级又可能对云智环境中的已有组件产生影响，极端情况下甚至可能需要组件重构代码以继续运行。这些兼容性问题需要操作系统和云服务厂商提前合理规划，实现平稳升级过渡，避免兼容性问题导致服务中断等事件。</p><p>&nbsp;</p><p>针对上述问题，龙蜥社区的开放和共建体系发挥出了很大优势。由于龙蜥社区非常注重技术创新进步，社区成员都很活跃，社区建立了能够吸纳创新技术、建立自身技术优势的机制。例如，英特尔的硬件团队在芯片设计阶段就会与软件团队紧密沟通，收集社区用户的反馈来调整设计，同时软件团队会提前开始新特性的优化适配工作。以上文提到的&nbsp;AMX&nbsp;加速引擎为例，龙蜥社区就很早引入了&nbsp;AMX&nbsp;指令来加速&nbsp;AI&nbsp;深度学习效率，获得两倍甚至更高的性能提升。又如英特尔&nbsp;TDX&nbsp;安全虚拟技术也在一两年前就开始在龙蜥社区引入，很早就完成了代码集成、测试等工作，提前集成到了龙蜥操作系统中。TDX&nbsp;技术使得云计算环境中，用户向云端上传的数据可以得到处理器硬件级的端到端加密保护，即便云厂商自身也无法解密获取，这样的设计极大提升了用户信心，为云端生成式&nbsp;AI&nbsp;等服务的普及打通了重要瓶颈。</p><p>&nbsp;</p><p>云智融合成为行业主要技术方向的当下，龙蜥社区的开放架构与创新机制使得更多厂商能够像英特尔一样，与社区内的其他产业伙伴共同加快创新技术的研发与应用过程。龙蜥社区的繁荣生态环境，也为国产服务器操作系统的崛起起到了引领作用，助力更多企业向国产操作系统迁移，并充分利用云计算与生成式&nbsp;AI&nbsp;等前沿技术的能力创造价值。</p><p>&nbsp;</p><p></p><h2>公平中立、开放活跃，龙蜥为开源社区治理作出表率</h2><p></p><p>&nbsp;</p><p>作为开源服务器操作系统社区，龙蜥在开源生态建设和治理方面的经验和成果也是可圈可点的。龙蜥社区有着典型的开源治理模式，所有社区角色和管理操作都是透明公开的，社区理事会的全部成员都有公平的机会表达观点，每一项社区角色都有理事会成员共同参与，社区对所有成员也是中立无偏向的。</p><p>&nbsp;</p><p>龙蜥社区从创立之初就积极鼓励创新、充满技术活力，并为来自各行业的技术人才提供了展示才华的机会，向他们提供了丰富的资源和工具，形成了活跃的开源人才生态圈。仅在&nbsp;2023&nbsp;年，社区开发者中就有超过&nbsp;15000&nbsp;人有代码贡献记录。活跃的开发者氛围为创新打下了坚实基础，龙蜥的每一个发行版都有众多创新特性，反过来也让社区竞争力持续提升。</p><p>&nbsp;</p><p>最后，龙蜥社区的理事成员涵盖了云厂商、芯片厂商、整机厂商、操作系统厂商、电信运营商、互联网服务商、独立软件开发商、系统解决方案提供商等诸多领域，社区成员来自各个行业与细分市场，有力保障了社区的多样与开放性。</p><p>&nbsp;</p><p>在社区的基础治理和协同研发方面，英特尔公司正在龙蜥社区内逐渐转向技术引领者的角色，参加了&nbsp;50&nbsp;余个&nbsp;SIG&nbsp;中的&nbsp;20&nbsp;多个，孵化了很多具有技术领先性和影响力的项目，是社区内影响力最大的厂商之一。2022-23&nbsp;年，英特尔公司在社区提交的代码约&nbsp;30&nbsp;万行，参与维护了四个代码仓库，也在龙蜥社区大会上获得了多个奖项。和英特尔公司一样，其他社区成员也在积极发挥自身优势，努力为社区贡献有价值的代码和项目，对社区事务发表观点，参加社区活动，推动龙蜥社区的技术进步。</p><p>&nbsp;</p><p>目前，龙蜥社区凭借活跃、丰富的开源生态，在国际开源社区中也取得了充足的话语权。社区围绕芯片、内核、编译器、安全、虚拟化及云原生等操作系统核心领域持续进行技术创新，进而推动建立国际范围的技术标准。随着龙蜥社区开源商业模式的不断成熟，越来越多的厂商依托龙蜥社区，&nbsp;不断推出国产服务器操作系统社区发行版及商业版，满足国产替代多样化需求。在此基础上，开源的参与方企业形成开源&nbsp;+&nbsp;服务的多种&nbsp;商业模式，加速开源项目的商业化落地，商业上的成功支撑龙蜥社区不断壮大，从而产生更多技术创新，龙蜥社区与商业模式也由此形成了良性循环。</p><p>&nbsp;</p><p>未来，英特尔等社区伙伴将进一步加强对龙蜥社区的技术发展与生态建设的投入，进一步在新技术使能、垂直软件栈集成、用户场景优化、社区最佳实践发布等方面持续发力，支持社区软硬件和应用生态繁荣局面。龙蜥社区正在紧抓国产替代与生成式&nbsp;AI&nbsp;浪潮等历史机遇，为中国开源社区基础建设和国产服务器操作系统生态发展作出表率，从而推动全产业数字化进程，帮助更多企业把握智算时代创新脉搏。</p>",
    "publish_time": "2023-12-21 11:04:04",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "搭起AI和DB之间“桥梁”！阿里云开源新技术：将AI算法“一键部署”进数据库",
    "url": "https://www.infoq.cn/article/htR9SxSgVDy9KhUUY4RX",
    "summary": "<p>12月20日，数据库国际顶会VLDB2024公布新一批论文，阿里云旨在实现将AI算法在数据库“一键部署”的PilotScope中间件相关论文成功入围。同日，阿里云宣布将PilotScope全部技术免费开源。</p><p>&nbsp;</p><p>开源地址：<a href=\"https://github.com/alibaba/pilotscope\">https://github.com/alibaba/pilotscope</a>\"</p><p></p><h2>在AI和DB之间“搭桥”</h2><p></p><p>&nbsp;</p><p>AI 和数据库的结合在业内已经探索了很长一段时间，其中AI for DB 是利用 AI 技术替换数据库里的某些功能，使其性能得到提升。</p><p>&nbsp;</p><p>这个方案需要依赖深度学习或者说大模型。但难点在于，AI开发和数据库开发基本是两拨人，数据库特别复杂，AI开发人员很难梳理清楚其中的结构，得到嵌入效果的同时还要保证数据库的稳定性。同时，AI方法非常多样，数据库底层架构也不尽相同，这导致嵌入的模式、交互需求、具体底层实现方式都各不相同，如果做定制化就会带来很大的时间成本，不利于大规模应用。</p><p>&nbsp;</p><p>“AI做了很多，DB做了很多，但中间的桥梁没有人干，这个桥是不通的。我们现在做的事情就是要把这个桥搭建起来。”PilotScope项目负责人朱鎔说道。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/965e270024da0ee69ed41bd0d20a5fd6.png\" /></p><p></p><p>根据朱鎔的介绍，PilotScope 屏蔽不同数据库异构的细节，提供了抽象的、可对AI调用的一整套接口。PilotScope把数据库交互需求及嵌入过程，抽象成了一个个的接口，将最难的底层细节开发部分屏蔽掉，用户可以直接使用，AI工程师不用关注数据库的细节。</p><p>&nbsp;</p><p>理论上，用户只要支持这个接口，同一个AI方法可以支持各种数据库，包括阿里云、微软、AWS以及PostgreSQL等数据库，开发者可以用一个方法、写一次代码就支持所有类型数据库在上面的运行。接口还可以不断扩展，支持不同AI方法的需求，同时通过开源的方式来增加支持AI算法的多样性。</p><p>&nbsp;</p><p>另外，PilotScope对AI算法的嵌入做了最小的扰动和侵入，不对系统的稳定性造成影响。用户不开启PilotScope时可以直接忽略它的存在，而使用PilotScope并把某些AI算法进行了相应运行后，PilotScope的检测机制会处理和限定模型的异常输出，对于不正常的结果会直接打断，让数据用原来的模块运行。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6e/6ec0d41a67e0b098d14ebfd13804e0cd.png\" /></p><p></p><p>&nbsp;据了解，当前PilotScope针对参数调优、索引推荐、基数估计、查询优化等数据库主流任务，预置了10多种AI算法，并完成PostgreSQL和Spark等两大主流开源数据库的适配打样。根据团队的实验数据，使用PilotScope将AI算法嵌入数据库，较传统“硬植入”方法，查询优化等任务提速1-2倍不等，并且PilotScope本身对部署产生的额外代价基本可忽略。</p><p></p><h2>十多人，用了两年做研发</h2><p></p><p>&nbsp;</p><p>PilotScope项目是一个深度交叉的领域：要有懂算法的研发人员明确算法具体需求，也要有懂系统的研发将需求真正抽象成系统化设计；除了要有懂AI的人，还要有懂数据库的人，了解数据库架构、嵌入模式、与数据库的交互等；在系统设计的人员抽象出系统模式后，还需要开发人员用实际的代码把构思实现出来；AI for DB是学界想做的算法探索研究，业界想做一些实际落地，两者的综合平衡对满足开源社区是比较重要的。</p><p>&nbsp;</p><p>从上可以看出，这样的研发难度是不小的。朱鎔表示，从有做PilotScope的想法开始到今天正式搞出来，十几个人的团队差不多用了两年时间才基本完成。</p><p>&nbsp;</p><p>做PilotScope的想法来源于阿里云团队在做AI for DB中遇到了测试、部署、落地等各种痛点问题。2021年夏季之前，团队是点对点地解决，然后发现通用性差、成本高，很难持续下去。之后，团队开始构思这样的一个中间件，在与业务部门沟通、研究了学界最新进展后，才将最终需求确认下来，包括要支持哪些主流方法、支持到什么程度等。</p><p>&nbsp;</p><p>整个2022年，团队一直在解决“两端解耦、让桥顺畅”的难题，到了9月份左右才开始做真正的系统研发。考虑到两个数据库的适配，团队要做很多细小的修改、打磨、迭代，陆陆续续到今年八九月份才算基本成熟。</p><p>&nbsp;</p><p>据悉，PilotScope目前已在阿里云内部展开试点应用。朱鎔表示，未来将做一些产业化部署，希望通过这个工具，把AI for DB的算法真正大规模的地应用到数据库系统里，提升数据库系统的效率和效果。</p>",
    "publish_time": "2023-12-21 11:16:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "矩阵起源产品总监邓楠确认出席 QCon 上海，分享云原生环境下的新型超融合数据架构",
    "url": "https://www.infoq.cn/article/gH7DVJrgOGszvC2143qX",
    "summary": "<p><a href=\"https://qcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=1221&amp;utm_content=dengnan\">QCon 全球软件开发大会</a>\"，将于 12 月在上海召开。矩阵起源产品总监邓楠将发表题为《<a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5693?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=1221&amp;utm_content=dengnan\">云原生环境下的新型超融合数据架构</a>\"》主题分享，探讨 MatrixOne 这套新型数据架构如何打破传统数据库资源使用率不高，运维管理相对碎片化的局面，彻底实现应用及数据一体化的 DevOps 实践。</p><p></p><p><a href=\"https://qcon.infoq.cn/2023/shanghai/presentation/5693?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=1221&amp;utm_content=dengnan\">邓楠</a>\"，矩阵起源产品总监，前腾讯云架构师，在云计算、大数据、AI 领域有十余年从业经验。他在本次会议的演讲内容如下：</p><p></p><p>演讲：云原生环境下的新型超融合数据架构</p><p></p><p>当前整个 IT 环境已经大规模走向 2.0 版本的云原生化时代，Kubernetes 已经基本等同于云原生技术栈上的 Linux。Kubernetes 管理无状态的应用层组件已经有很多成熟实践，然而对于有状态的数据层组件，在各个行业中并没有形成完善的思路。MatrixOne 作为一款新型的完全云原生化的超融合 HSTAP 数据库，将给行业带来一套完全 Kubernetes 及 S3 原生，完全容器化，线性扩展并且资源可动态调配的新型数据架构。</p><p></p><p>通过这套新型数据架构可以将大量独立的集中式数据库实例给合并到一套集群中，并且以多租户及资源池的管理模式来形成 Serverless 化的使用方式，动态调配各实例的使用资源，同时这套架构可以将 OLTP、OLAP 及流计算相关的负载都统一到一套集群中，极大的降低整个运维和管理的难度。MatrixOne 的新型架构将打破传统数据库资源使用率不高，运维管理相对碎片化的局面，彻底实现应用及数据一体化的 DevOps 实践。</p><p></p><p>演讲提纲：</p><p></p><p>云原生下的传统数据架构挑战。超融合数据库 MatrixOne 的架构介绍。MatrixOne 如何解决云原生环境下数据管理难题。MatrixOne 应用场景与落地案例。</p><p></p><p>听众收益：</p><p></p><p>○ 了解当前环境下的云原生数据库趋势</p><p>○ 了解超融合新型架构对行业的帮助，如何帮助开发和运维人员省时省力，降本增效</p><p></p><p>除上述演讲外，QCon 上海还将围绕&nbsp;<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart\">GenAI和通用大模型应用探索</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1596?utm_source=infoqweb&amp;utm_medium=teacherart\">AI&nbsp;Agent&nbsp;与行业融合应用的前景</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart\">LLM&nbsp;时代的性能优化</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart\">智能化信创软件&nbsp;IDE</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart\">面向人工智能时代的架构</a>\"、<a href=\"https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart\">性能工程：提升效率和创新的新方法</a>\"等专题进行交流。</p><p></p><p>12 月 28-29 日，QCon 全球软件开发大会即将落地上海，中国科学院外籍院士、国际数据库专家樊文飞院士，英特尔大数据技术全球 CTO 戴金权等大咖会亲临现场分享大数据、芯片、架构等方向的前沿洞见。</p><p></p><p>这次会议主要探讨大模型的全面技术架构的进化，不仅有跟大模型本身相关的推理加速、AI Agent、GenAI，还有架构的演进思路、性能优化，以及以智能代码助手为代表的研发效能提升等方向，感兴趣的朋友可以扫描下方二维码，查看大会详细日程。咨询购票可联系票务经理 18514549229。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/01/0113b3dfb187d5f9988b7eb16d2e0594.png\" /></p><p></p>",
    "publish_time": "2023-12-21 11:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "企业服务大模型能否成为智能化时代的“操作系统”？",
    "url": "https://www.infoq.cn/article/40hZdeAGQyD7AJGthtZy",
    "summary": "<p>大模型发展为企业应用创新打开巨大想象空间。在智能化时代，企业服务大模型可谓承担着企业应用“操作系统”的角色，让支撑企业应用的技术底座的智能化能力更加完整，推动智能应用从认知阶段升级为慧知阶段，助力企业实现智能化运营，让智能化真正为企业增收。</p><p></p><p></p><h3>企业服务大模型将成为企业级 AI&nbsp;应用的“操作系统”</h3><p></p><p></p><p>2023 年堪称生成式 AI 元年，对于积极谋求数智化转型的企业而言，生成式 AI 技术许诺的前景是非常诱人的：生成式 AI 工具可以大大简化低端重复工作的流程，大幅减少人力投入，激发内容创意，提出高水平业务洞察，辅助重要决策，预防风险；当生成式 AI 技术与企业已有的丰富数据资源充分结合，不仅能深度挖掘数据中潜藏的价值，还能让企业将有限的资源更多集中在业务和产品创新中，为竞争力持续提升奠定基础。</p><p></p><p>中国工程院院士戴琼海曾在公开发言中表示，拓宽数据边界、推动算法创新、打破算力瓶颈将是未来带来应用变革、引领人工智能基础突破的必由之路。基于大模型的生成式 AI 是人工智能技术和应用的最新发展潮流。戴琼海预测，大模型预计 5 年左右将成为人工智能应用中的关键基础性平台，类似 PC 时代的操作系统。</p><p></p><p>用友身为行业前列的企业数智化软件与服务提供商，在几年前就率先提出了“数智企业”的概念，定义了以数字和智能技术共同驱动的数智商业创新，数据驱动、智能运营的企业新范式。用友基于服务企业三十五年的经验积累，融合了企业各个领域专业知识和各类行业商业 KnowHow，经过领域、行业数据的预训练和精调，推出了业内首个企业服务大模型——YonGPT。YonGPT能够理解、解析各类企业数据，应用于各类业务场景，为企业提供智能化的人机协作、业务洞察、商业决策支持和智能运营服务。</p><p></p><p>YonGPT很好地诠释了企业智能化应用“操作系统”的角色。用友认为大模型作用的发挥，应该与企业现有数智化底座相互融合，这样可以对底座的各项能力与流程进行全方位的智能升级。对于企业而言，获得生成式 AI 能力并非目的，通过领先技术的融会贯通实现降本增效、加速创新才是最终目标。企业引入生成式 AI 的过程应该是“润物细无声”的，组织更偏好平滑流畅的转型过程，而非大张旗鼓的粗暴升级。</p><p></p><p>YonGPT通过大模型服务平台提供数据管理、大模型精调、大模型评估优化、大模型推理和插件服务等功能，为大模型的构建和服务提供稳定且有效的支撑。通过与用友BIP其它产品的有机集成，YonGPT还创新地将企业的私有化数据通过特定机制与企业服务大模型有效结合，不仅能够解决企业内部数据安全隐私问题，同时也充分利用大模型多领域、多行业的关联带来的涌现可重用专业能力，使得企业服务由流程驱动转变为基于大模型调度的语义驱动，为企业带来智能化的业务运营、自然化的人机交互、智慧化的知识生成、语义化的应用生成，成为企业智能化应用创新的能量源泉。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8a/8a4c2032f7a6395012c1c5238f0b7437.png\" /></p><p>YonGPT总体架构</p><p></p><p></p><h3>探究业内首个企业服务大模型的核心技术</h3><p></p><p></p><p>如今，推出一款单独的大模型产品已经需要企业具备相当程度的技术实力，而将大模型的能力融入已有的技术平台，对现有产品矩阵进行全面智能化升级更是需要深厚的能力积累。</p><p></p><p>YonGPT为企业智能化赋能的能力分为通用能力、应用能力两层。</p><p></p><p>用友的通用大模型底座通过优化技术架构和算法，为业界各种主流的通用大模型提供了强大的支持，比如百川智能、智谱 ChatGLM、百度文心一言等。这个通用大模型底座不仅提供了高效的计算和存储能力，还具备出色的可扩展性和灵活性，可以根据不同的需求进行定制化开发。为此，用友通用大模型底座还集成了丰富的工具和库，帮助开发者更加便捷地进行模型训练、部署和优化。通过与业界主流的通用大模型进行集成和优化，用友通用大模型底座为企业提供了更加智能、高效和可靠的大数据分析和应用服务，助力企业数字化转型和创新发展。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c8/c8b11dde1ef67103d4c85c85ad41a05b.png\" /></p><p>通用大模型基础上的YonGPT企业服务大模型</p><p></p><p>用友YonGPT通用能力层具备完备的语义理解能力，使其能够理解和生成自然语言文本，执行推理，识别实体，管理上下文，与知识库集成，并以有意义的方式与用户互动；YonGPT的内容生成能力，不仅可以用于生成文章、报告、新闻稿，还可以应用于自动化报告生成、翻译服务、自然语言生成的数据可视化以及虚拟助手和聊天机器人的开发；多轮对话能力，能够以自然、流畅的方式参与多轮对话，保持上下文的一致性，理解用户的需求，并生成有针对性的回应。这种能力为众多应用场景提供了巨大的潜力；知识问答能力，可以从广泛的知识源中提取信息并回答用户的问题。它具有广泛的知识覆盖，包含各种文本资料、百科全书、研究论文，以及大量的企业管理领域相关的知识体系，还能够处理多步骤的复杂问题；角色扮演能力使其能够模拟不同的虚拟角色，与用户进行逼真的对话和互动，创造出各种情境和情感表现。包括模拟架构师、咨询师、客服等不同的角色，以及日常办公、决策分析、客户支持等不同情境下的个性化角色扮演体验；逻辑推理能力，可以识别和应用各种逻辑规则，回答需要逻辑推理的问题，如数据分析、执行建议等问题，还可以用于解决复杂问题，验证假设和推断结论，有助于用户更深入地理解问题的本质；代码生成能力，可以生成程序代码，包括各种编程语言的代码段、脚本和算法。并且可以结合用友低代码开发平台YonBuilder的数字化建模能力生成符合YonBuilder框架逻辑的代码结果，对于降低研发人员的研发门槛有着非常大的价值。图像生成能力，可以生成多样性的图像，包括不同主题、风格和风格的图像。这使其非常灵活，可适应不同的创作需求。</p><p></p><p>企业服务场景下，很多业务场景非常地复杂，YonGPT提出了“决策 GPT”的解决方案，也就是将复杂任务分解为任务链并调度决策。在过去，传统 AI 技术更多是直接提供结果输出，大模型则为企业带来了在复杂业务决策流程中全程帮助推演最佳结果的能力。基于大模型的生成式 AI 技术可以为企业员工在内容创作、人机交互、产品设计等依赖创新输出的领域提供知识图谱、创意参考、决策修正等能力，升级企业的创新生产链条，使企业能够持续稳定输出创新成果，作出最佳决策。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cd/cd03c9ab69bdea5a1ed4eb6b90def4cc.png\" /></p><p>在应用能力层面，YonGPT首先解决了通用大模型在意图槽位识别上的不足。YonGPT意图槽位的模型训练，能够准确收集 30 种意图的近百个槽位，对于有大量候选项的意图槽位，采用分批次训练进模型 + 根据语义检索相关候选槽位词的方式进行识别，大大提升了企业应用场景的意图识别准确性。</p><p></p><p>在业务知识查询问答的场景上，用友YonGPT结合智能大搜相关的能力解决多模态数据的搜索查询、问答。比如，多数据类型快速索引、准确定位上下文、解决大模型生成问答幻觉。在专业领域大模型结合数智员工能力，可以训练专业方向的专家机器人，为员工提供专业服务，比如公文专家、法务专家机器人等。</p><p></p><p>YonGPT以强大的数据分析和预测能力、自然语言处理能力、知识整合能力以及应用生成能力，为企业实现数智化转型提供了强有力的支撑，为许多企业生产经营与运营管理的领域中发挥了重要作用。YonGPT已经在财务、人力、供应链、采购、制造、营销、研发、项目、资产、协同等业务领域形成全场景的大模型应用，通过大模型能够更好地理解业务需求、更准确地做出决策，并确保了模型的实用性和有效性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b8/b89bc4274624c8da790b955948d03442.png\" /></p><p>YonGPT大模型的全场景应用</p><p>例如，YonGPT可以基于市场变化及历史数据，智能感知企业产销存各领域数据的关联和归因，并模拟调整相关策略，多因子测算下个经营周期盈利数据；又如基于YonGPT的试用期评价，可以根据员工的工作表现、目标达成情况、日常协作、专项工作等行为数据，自动生成对该员工的试用期评价并提交审核；基于YonGPT的供应链协同可以实现供应网络优化。根据历史消耗和需求预测，动态计算不同仓库物料的安全库存，依据设定的服务水平，测算建议未来一定周期内的目标库存、预计订货量指标，在保证客户服务水平的前提下，降低优化库存成本等等。</p><p></p><p>值得一提的是，YonGPT非常注重企业隐私数据的安全保护，运用了多种安全组合架构来打消企业使用大模型时的后顾之忧。</p><p></p><h3>铸就牢固根基，数智底座推动创新技术在企业的全面应用</h3><p></p><p></p><p>YonGPT作为企业数智化底座用友iuap的一部分，它汲取了用友iuap领先的技术与平台能力，同时也为用友iuap的智能化升级添了一重砝码。</p><p></p><p>用友iuap助力企业提升数智化技术驾驭能力。基于技术平台、业务中台、数据中台、智能中台、低代码开发平台和连接集成平台，为企业提供了中台化构建能力、多云环境下的 混合云开放集成互联互通能力、技术普惠化下的低代码开发和数智能力自助等应用快速构建能力。</p><p></p><p>用友iuap经过二十几年持续创新，已发展成为更懂业务、技术领先、体系完整的企业数智化底座。其中，iuap智能中台承载着iuap的智能化能力，以大模型及服务平台，与 AI 算法、知识图谱相融合的智能技术为基础，提供了数智员工、智能大搜与智能服务三大类 AI 产品服务，进而作用于财务、人力、采购等领域云，为各行业的创新发展提供智慧赋能。在iuap智能中台的支持下，企业的研发、运营和业务全流程与每一位员工都能实现智慧升级，日常行为、关键决策与成果输出都有了数据与智能分析辅助的支撑，在此基础上的降本增效、风险防范、流程优化与决策创新也就顺理成章。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/30/30835d1205310d65e4365a851534b58f.png\" /></p><p></p><p>2023 年，用友iuap除了在企业服务大模型的突破之外，还在多个维度实现领先技术的提升和迭代。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5c/5ce977ac782f3b33bc011f96c7aef4f5.png\" /></p><p></p><p>YMC云监控中心：支持云上云下一体和远程智能会诊的健康管理专家</p><p></p><p>YMC云监控中心分为云上实时监测与本地端日常监测两大部分，提供大盘监控、远程会诊、专家分析、运维优化等能力。云监控中心可以面向多利益相关群体及时报告系统问题，并支持全链路、多场景、多环境根因高效分析。值得一提的是，云监控中心能够随时获取用友线上专家的帮助，对监控报告进行深度解析，与企业 IT 部门共同商讨对策，将问题消灭于萌芽之中。</p><p></p><p>租户领域分库：提供高弹性资源隔离模式，更高性能、更灵活部署、更低 TCO</p><p></p><p>数据库是企业数智化底座的关键组成部分，数据库用户分库方式直接影响数据库的使用效率。用友iuap平台提供 YMS 云中间件，创新实现了按领域分库的共享数据库架构。在这种分库方式中，技术中台、应用中台、业务中台与人力、财务等部门可以按照用途分库，共享数据库海量数据资源，中间件也支持按租户分库的独享模式。这种设计带来了更高性能、更低 TCO，可以满足更灵活的应用部署需求，使平台的微服务基础架构资源得到最大利用。</p><p></p><p>迁移家族：个性化、高可靠，加快应用上线与迭代升级速度</p><p></p><p>在企业应用开发流程中，应用通常需要在开发环境、测试环境与生产环境中来回迁移。用友iuap平台为此发展了一整套迁移技术栈，包含开发迁移、环境迁移、配置迁移和档案迁移四大组件，使开发人员可以平滑无缝地在不同环境中共享成果，在满足个性化与高可靠需求的情况下，大大加快了应用上线与迭代升级的速度。</p><p></p><p>此外，用友iuap首创云上云下一体的持续交付体系，让企业私有云平台体验到公有云的更新效率，让云下应用升级像 AppStore 一样简单；自研多维数据引擎（存算一体），实现 100% 自主安全可控，支持千亿级数据规模下的“多准则、多币种、主附表”快速合并，一键出表。这一技术已经在大型央企中进行了验证，实现了 1500 家分子公司规模的超大型企业报表的快速合并、一键出表；实现了安全可信的国产化信创适配，为企业客户提供稳固可信、自主可控的数智化平台服务。比如多维引擎数据库完成国产化芯片测试，实现千亿级数据量，万级并发检索，毫秒级响应。</p><p></p><p>技术是业务创新的源泉，用友iuap基于领先的技术，将技术、工具、平台、服务，以及深厚的知识积累和实践经验进行沉淀，以数智化底座的方式，来助力企业数智化成功落地。企业数智化底座为企业实现数据驱动，走向智能运营提供了稳固的平台支撑。同时，当 AI 进入普及应用，企业服务大模型或将成为新时代的“操作系统”，为数智底座注入智能化能量，为企业进行智能化应用创新带来更多可能，助力企业驾驭数智未来。</p>",
    "publish_time": "2023-12-21 14:36:13",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "选择哪种编程语言已经不重要了，只提倡程序员下班后“多看看书”提升竞争力是误人子弟｜独家专访亚马逊 CTO",
    "url": "https://www.infoq.cn/article/g8yRujmN4r0N5AJUXYRj",
    "summary": "<p>采访 ｜ Kevin</p><p>编辑 ｜ Tina、芳芳</p><p></p><p>1998 年，Werner Vogels 加入亚马逊时，这家公司只有一个美国网站，专注于书籍销售。他迎接了改变这种状况的挑战。“我希望您能理解，亚马逊首先是一家科技公司，”该公司的 CTO 在 2006 年的一次采访中强调。</p><p></p><p>Werner Vogels 一直坚持这一目标。亚马逊经历了从一家书店到云基础设施巨头的漫长进程，如今已拥有超过 145 万家企业客户。Werner 在将平台从普通在线商店转变为面向服务的架构方面发挥了举足轻重的作用。</p><p></p><p>过去的一年里，技术变革的速度迅速加快，云技术、机器学习以及生成人工智能已经深刻影响着各行各业。而作为全球最大科技巨头之一的首席技术官，Werner 这么多年一直以旁观者的独特视角审视科技发展的脉络。技术行业有着众多从业者，作为这个行业的关键角色，每年他都能提出一系列深刻的技术预测。而且过去几年，他的预测大部分都相当准确。预测未来对于 CTO 和 CIO 们抢先一步占得技术先机是至关重要的。</p><p></p><p>今年，很多人都对 AI 领域的动向和潜在成果抱有浓厚兴趣。Werner 就特地对 AI 技术的发展<a href=\"https://www.allthingsdistributed.com/2023/11/tech-predictions-for-2024-and-beyond.html\">进行了预测</a>\"，他认为生成式人工智能将成为技术发展的关键推动力之一。</p><p></p><p>在今年的 re:Invent 大会上，InfoQ 作为唯一一家参与 Werner 专访的中国媒体，进一步与 Werner 对话并结合他的预测进行了总结。以下内容经过不改变原意的编辑：</p><p></p><p></p><h2>人工智能来了，开发人员该如何保持自身竞争力？</h2><p></p><p></p><p>作为一名创造者和软件工程师，我对 AI 技术有着特定的理解，期待 AI 工具在日常工作中发挥更多作用。在过去两年中，我提到了 AI 工具在开发中的重要作用，特别是在分担开发者的一些繁琐工作方面。AI 技术的快速发展让我们进入了一个美好的时代，与 40 年前我学习编程时相比，如今有了更多能够实际帮助学习的工具。</p><p></p><p>AI 助手不仅仅是简单的工具，它们正在逐渐改变开发团队内不同角色之间的界限。产品经理、前端和后端工程师、DBA、UI/UX 设计师、DevOps 工程师和架构师之间的界限将变得模糊。AI 助手通过对整个系统的上下文理解，提供增强人类创造力的建议，例如将草图转换为代码、生成模板，或为任务推荐最佳基础设施。</p><p></p><p>在 2023 年的 Stack Overflow 开发者调查中，超过 70% 的受访者表示已经在使用或计划在开发过程中引入人工智能支持的工具。这印证了我在 2021 年的预测，即生成式人工智能将在软件编写中发挥关键作用。开发者们普遍认为，这些 AI 助手将增强他们的技能，使他们能够编写更安全、更可靠的代码。</p><p></p><p>现代软件开发中一些最乏味的任务，如编写单元测试、样板代码和调试错误，已经被 AI 助手消除。这些助手甚至能够重新搭建和迁移整个遗留应用程序，如从 Java 8 升级到 17，或从整体分解为微服务。这使得开发者能够专注于更有挑战性和创造性的工作，提高了整个团队的效率。</p><p></p><p>两年前，我就觉得 AI 工具主要是分担一些“铲屎”之类的杂活。作为开发者，当我们遇到解决不了的问题时，一般会上 Stack Overflow 寻找答案，或者问问社交网络上的其他同行。其他人会给出答案，我们挑选其中的高赞答案并粘贴到自己的代码中，或者是直接从亚马逊云云科技提供的示例代码中截取片段。但对于未来的 AI 工具，更多是在帮助开发者真正学习。如大家所见，AI 技术正在快速发展。短短一年之前，大语言模型还没什么热度，大多数人甚至根本没听说过。至少普通消费者肯定是没听说过这项技术。但这一切都在默默发展、快速迭代，随时准备给我们一个惊喜。</p><p></p><p>40 年前我刚开始学习编程时，当时只有两到三种主流的编程语言。现在，各种商业机构和教育平台都能帮我们快速掌握新的编程语言，所以到底选择哪种语言本身已经不那么重要了。如今我甚至可以雇用一位新手工程师来管理 Amazon S3，这可是几十万行代码构成的复杂服务。真要弄懂它是怎么实现的绝非易事，但好在根本没必要，会用就足够了。</p><p></p><p>另外，现在也有更多高级工程人才能指导编程新人。遗憾的是初级工程师们总在一遍又一遍提出同样的问题，搞得前辈们不胜其烦。但 AI 系统不会烦躁，愿意无数次回答相同的问题。它就像耐心极好的导师、助手和创造者，全心全意为培养优秀程序员而努力。在必要时，它甚至可以直接输出建议的代码。但从本质上看，它们仍然只是预测机器，真正的决策还是要由人类自己通过思考来完成。人类的价值也正在于此，擅长获取大量不同信息并做出推理、解决问题。</p><p></p><p>在此过程中，我们当然可以借助 AI 工具，并继续扮演最核心的角色。这就是人类与 AI 的共存之道。由于技术发展太过迅速，高等教育、大学课程根本就跟不上变化。问问那些刚刚走出校园的学生就知道了，他们对区块链、生成式 AI 等新技术的了解肯定不如我们这些从业者。而且随着技术的采用周期越来越短，产品的上市速度也会远超以往。也就是说，学校里传授的知识不再具有先进性。所以除了编程语言之外，我们在学校中的最大收获就是学习能力，这种学习能力决定我们能否成为技术专家、保持终身钻研。</p><p></p><p>我也不知道五年之后的技术会是什么样子。单是过去一年的变化就已经远超我们的想象，所以谁敢说自己能预测五年后的技术格局？我们做不到，大学当然也做不到，而且这种割裂会越来越严重。因此当大学毕业生找到工作之后，往往还需要一整年的适应才能成长为有价值的贡献者。为什么会这样？因为不同的企业有不同的需求，他们得花时间了解并融入这种差异。大家使用的技术各有区别，而我们在学校里最大的收获就是学习能力。</p><p></p><p>当然，企业也应该为员工们的终身学习铺平道路、提供帮助，而不只是善意提醒大家下班后多看书。那种空话没什么意思，一定要多给他们提供考证支持。 如果说之前大多数企业的员工培训都是种临时起意，那么现在越来越多的公司都开始参与进来、投资教育，并意识到持续进修是保持竞争力的必要前提。</p><p></p><p></p><h4>问题：生成式 AI 如何重塑开发流程和开发工具？</h4><p></p><p></p><p>生成式 AI 将如何重塑开发流程和开发工具，又会对开发者的概念产生哪些影响，这可以从两个方面来看。</p><p></p><p>它分别涉及开发本身和成为开发者的过程。我觉得这两部分是相辅相成的。</p><p></p><p>首先，我认为任何接受过良好基础教育的人都有能力掌握计算机技术，即便专业不同。</p><p></p><p>哪怕大家在学校里学的是艺术，还是不妨碍你成为一名计算机程序员。因为具体学了什么专业并不重要，重要的是教育经历让你掌握了学习能力、知道要如何设立更宏大的目标、如何汇总信息、记在脑子里、进行批判性思考，如此往复。我最近在德国伯林去过一所预备学校，那里收容了 200 万难民，而且大部分来自中东。他们需要在德国找到新的工作。实际上他们大多数都接受过良好教育，只是需要学习跟专业相关的德语。德国还有 80000 个空缺的开发岗位，相信他们完全可以胜任。</p><p></p><p>所以那所预备学校的任务，就是帮已经掌握一定英语知识的难民学习技术。如果连他们都能做到，那已经接受过大学教育的各位，在一年之内肯定也能做到。另外没必要太迷信高等教育，我无数次看到刚从学校走出来的年轻人至少要花一年时间才能真正适应工作岗位。当时的他们根本算不上程序员，要经过一年的历练才能理解整体目标、参与项目贡献。</p><p></p><p>是的，单凭大学里的计算机科学学位并不足以成就一位有价值的团队成员。他们并不知道要如何编写代码、如何为团队贡献价值、如何为他人服务。表现比较好的，通常是那些在学校里做过小项目的同学。所以我比较喜欢选择那些参与过开源项目的年轻人，因为他们已经理解了协作究竟是怎么一回事。</p><p></p><p>在实际工作中，我强调“协作”是日常工作的核心。特别是对于年轻开发者，了解项目的体量非常重要。项目不仅仅是一堆文件，更是一个完整的体系。AI 系统可以帮助我们整合这些知识，解决项目中不断变化的复杂性。</p><p></p><p>其实我们日常工作中的大部分内容，都可以概括为“协作”二字。特别是对于年轻的开发者来说，首先要对项目的体量拥有明确的认知。看到原本的项目有多大了吗，能感受到它的份量吗？摆在我们面前的不只是一个个文件，更是完整的体系。比如说我招聘一位年轻人管理亚马逊云科技的 S3 服务，那么其过去十几年间积累下的代码就高达数十万行。</p><p></p><p>最早开发项目的工程师可能已经离职了，所以我们该怎么了解项目？现在我们可以构建 AI 系统并把这些知识整合起来。更棒的是，有些高级开发人员可能缺乏耐心，经常问问题容易把他们惹毛。比如说连续把同样的问题问上五遍，对方可能就要骂人了。但 AI 不会这样，你可以一遍又一遍提出同样的问题，把它当成帮助自己学习的工具。</p><p></p><p>对于招聘，我更关心候选人是否具备在大学里培养的学习能力，而不仅仅是特定的语言或技术。</p><p></p><p>毕竟学校不会教你亚马逊云科技所使用的具体语言，但赋予你的能力会让你始终保持开放的心态、快速掌握新的语言。</p><p></p><p>再说说那些管理大型技术项目的 CIO 和工程师们，他们需要紧跟技术发展的脚步、需要保持终身学习。技术的变化一刻不停，永远别指望自己毕业之后头一年学到的东西够用一辈子。</p><p></p><p>现在是 2023 年，就跟过去一年比，如今的技术格局都已经截然不同。至少在去年的 re:Invent 上，还没人讨论大语言模型。我们知道大模型终将实现，但我们不知道它们具体什么时候实现，所以才会相对保守。毕竟实验性的成果可以早点展示给企业客户，但最好别轻松展示给普通消费者。</p><p></p><p>但保守并不代表守旧，研究人员还是在努力把成果整合起来，打造出能让消费者们眼前一亮的产品。就像那个有趣的比喻，如果你看到一只熊在跳舞，那最重要的就是它能跳舞，而不是它跳得好不好。希望大家能用类似的心态看待前沿技术，尽量宽容一点。现在大家在看到新兴技术时，下意识就会想到监管机构要如何介入，其实大不可不必如此紧张。</p><p></p><p>在开发者的定位上，AI 的发展带来了一些变化。举例来说，AI 可以接管一些繁琐的任务，这使得开发者可以更专注于他们真正擅长的工作，如获取和整合信息、做出决策和规划。</p><p></p><p>软件工程师中有很多人一直被迫在处理最愚蠢的事务。对，就是愚蠢，比如说从 Java 8 升级到 Java 17 这事毫无建设性，但工程师们还是得投入好几个月才能完成所有 Java 应用程序的升级工作。如果我们能够稳定可靠地把这事交给自动化处理，那该有多好。反正对于这类垃圾任务，我是愿意给 AI 个表现机会的。但大家接受起来肯定还需要段时间，未来也一定会有那种负责从 Java 8 升级到 Java 17 的专职工程师。但这活有意义吗？当然没有，没人会把这事写在简历上。</p><p></p><p>所以应该从现在开始，让工程师们做他们真正擅长的工作，也就是获取信息、获取数据、整合数据，发挥主观能动性将其组合起来并做出决策，最终制定出可操作的规划。当然，目前的 AI 模型还有很大的局限性，但我相信未来一定能突破这种局限。比如说，现在的大语言模型就不懂数学逻辑，虽然问它“2+5 是多少？”，它也能回答“7”，但它明显不懂 7 到底是怎么来的、不知道 2 和 5 相加是什么概念。毕竟它只是语言模型，而数理逻辑是超越自然语言的。我们的这种能力是由父母传授的，他们会教我们背乘法口诀。</p><p></p><p>但在我们学会这些基础技巧之后，具体的任务就可以交给计算器了。没错，加减乘除虽然重要，但我们需要跨过它们去解决更复杂的问题。至于这些相对简单又繁琐的部分，就交给工具吧。很多朋友小时候学过心算，我也学过，但现在都用不上了。而大语言模型缺少的就是这种能力。关于时间也一样，我们可以要求大模型帮我们设计晚间活动安排，比如想看某部电影、几点出发，那它就会告诉我们晚上 9：30 在某处影院准时开场。如果我晚上想吃日料，它就会给出具体的时间建议。</p><p></p><p>其实这些建议都挺靠谱的，但模型本身其实并没有对时间的概念。不过随着时间推移，未来我们肯定能解决时间推理、数学计算这些问题。</p><p></p><p>然而，我们需要明智地了解 AI 的局限性，理解 AI 只是辅助工具，而不是取代人的决策者。</p><p></p><p>了解 AI 模型的极限在哪里非常重要，只有这样我们才知道可以把哪些技术交付给大众。在亚马逊云科技，我们需要围绕明确的主题谨慎筛选技术要素。</p><p></p><p>但无论如何，现在的商业 AI 技术已经越来越强大，Meta 等公司的产品能帮大家解决越来越多的实际问题。已经有一些企业在用它建立新业务，不过我个人还是持谨慎态度，我觉得现在的生成式 AI 太容易产生幻觉。</p><p></p><p>比如说用 AI 来规划会议安排的时候，它就弄不明白这个人这个时段有空、那个人那个时段有空，到底该怎么协调。AI 最终给出的方案，相信大家看了都会眼前一黑。</p><p></p><p>总之，人需要肩负起监管的职责。请记住，AI 只是辅助、是帮助我们的工具。它们是在帮我们做预测，而不是替我们做预测，责任永远要由人来承担。</p><p></p><p>AI 模型经常产生幻觉，所以别轻信它输出的一切，因为那未必是事实和真相。我不是要吓唬大家，只是希望各位能明白在全面拥抱 AI 时代之前，一定要做好正确的心理准备。只有这样，大家才能理解 AI 该怎么用、它们的局限性在哪里。</p><p></p><p></p><h2>大模型与语言文化</h2><p></p><p></p><p>不同地区的人对同一事物可能有不同的理解方式，这就需要我们在生成式 AI 的训练中引入更多的文化元素，以促使这些模型更好地适应多元化的社会。我认为需要关注文化差异，因为不同文化对于相同议题的理解方式可能存在差异。这对于生成式 AI 工具的发展至关重要。</p><p></p><p>大语言模型在不同文化数据上的训练使其具备更细致的人类经验和社会挑战理解能力。这种文化意识的发展预示着未来全球用户将更容易使用生成式人工智能，因为模型能更好地适应各种文化背景。</p><p></p><p>我们已经训练了很多语言模型相关的工具，最知名的当数 Common Crawl。Common Crawl 语料库采集的主要是美国和西欧的数据，属于建立在这种文化之上的语言机器。当然，它具备的只是语言能力，而不是对事实的思维能力。它只能提供语言背景，帮助预测最可能出现的下一个单词是什么。尽管如此，它仍然反映出我们日常生活中蕴藏的文化知识。语言能力也是当前生成式 AI 最擅长、最容易理解的部分。正因为极具代表性，所以我就拿它来举例。</p><p></p><p>我相信通过这种方式，我们就能避免整个世界被少数几个纯英文大语言模型所主宰。</p><p></p><p>我们有必要关注那些包含多种不同语言、承载差异化文化的语言模型。</p><p></p><p>我觉得这就是关键所在。我本人对亚洲文化并不太精通，但如果向中国人、韩国人和日本人询问关于孔子的问题，那他们往往会给出截然不同的答案。这种差异不仅源自事实，更源自特定文化对于特定议题的理解方式。以伊莎贝尔·阿连德为例，她是一位著名的作家、写过很多书。她的伯父是智利前总统，所以她本人对于智利的制度革命有着非常深刻的理解。跟那种泛泛而谈的拉美介绍性资料相比，她在书中做出了非常具体且不同的解释。但她的书大多是在美国出版的，这也会对内容产生影响。另外，围绕 agent 智能体的讨论也在快速升温，我觉得这些要素需要互相学习才能带来更强大的 AI 成果。</p><p></p><p>另外我看到中国、韩国、日本和马来西亚都各自开发出了体量庞大的语言模型，这些模型自然也建立在各国的语言体系之上。而我们必须确保这些成果也能从其他文化中汲取营养，理解更全面的人类价值观。语言本身只是一方面，还要看文字质量和翻译效果。当然，现在的机器翻译已经很不错了，我可以对着手机说荷兰语，而对方能直接听到英语或者其他母语。总之，人类拥有自己的文化基因，但机器没有。</p><p></p><p>我相信我们已经来到了在技术中反映文化基因的临界点上。我们不应该只考虑美国或者少数特定国家，还应该关注世界其他地区，因为他们的文化和倾向也同样重要。</p><p></p><p>文化对于我们的生活方方面面都产生着深远的影响，而技术的设计、部署和消费方式也将受到文化的巨大影响。在未来，通过生成式人工智能，大语言模型将逐渐具备全球性的视角，从而更好地理解和回应不同文化下的复杂社会挑战。</p><p></p><p></p><h4>问题：在资源有限的情况下，如何构建更具包容性的模型？</h4><p></p><p></p><p>每种语言都承载着独特的文化属性。</p><p></p><p>构建包容性模型的关键并非要使 token 数量达到上百亿，而是要考虑实际需求。斯坦福大学的研究表明，体积较小的模型在生成能力方面与大模型相媲美。</p><p></p><p>而且从成本的角度讲，我们也没必要搞什么军备竞赛，把模型弄得越来越大、把训练周期弄得越来越长。 其实模型小一点也没什么不好，效果还是挺不错的，我觉得就是这样。另外，我觉得还应该参考具体需求，比如喀拉拉邦到底有多需要专属的大语言模型。虽然不同语言肯定有自己的特色，但翻译在很大程度上已经足以解决问题，而且现在的翻译几乎可以实时完成。在即时通话的过程中，内容就已经能被翻译成其他语言以供他人接收了。是的，任何语言几乎都可以实时翻译。所以真正需要处理的，就只有不同语言中的独特文化内涵。</p><p></p><p>现在，假设我手里有两套模型，二者的背景有一定交集，只是响应机制各有不同。这时候如果让它们相互对话，会有怎样的结果？很明显，我们根本不需要上百个拥有不同背景的大语言模型。当然，对于那些比较严肃的应用需求，确实可以考虑训练专门的印地语模型。但是马拉维语呢？对于那些应用范围的确不广的语言，真有必要设置专门的模型吗？</p><p></p><p>虽然不同地区之间确实存在文化差异，但我认为多 agent 讨论其实已经可以通过小模型达成不错的智能效果。它们不需要涵盖一切，而且可以通过相互对话来提升性能。有些小模型可能比其他模型更擅长某些任务，它们可以就这些问题进行讨论并达成共识。不只是两个模型，还可以是更多模型，比如 6 个、8 个、10 个或者 12 个，结合上下文共同讨论出最佳答案。</p><p></p><p>换句话说，我们真有必要让每段上下文都有 5000、甚至 50000 个 token 那么长吗？真有必要在每次输入时都提交一整本书那么多信息吗？当然不用。</p><p></p><p>所以我觉得其中是有很大的效率发掘空间的，总之先构建起来，再想办法逐步改进。</p><p></p><p>比如说我们可以先拿 1950 年之前的荷兰语历史数据进行模型训练，再随着时间推移不断改进这些模型。这样它就能理解重要的历史背景，而且这些历史背景已经不会再改变了。假设市面上一共有五种不同的荷兰语模型，但哪怕它们各自占据不同的文化或者宗教视角，对 1950 年之前的历史也基本会抱持相同的观点。这就是共通的基础，我们在此之外做具体的文化微调即可。</p><p></p><p>现在全世界也不过几十个国家，对应几十种文化。我甚至觉得很多文化基本是覆盖多个国家的，所以实际还没那么多。我们还是以语言为例，来自欧洲的阿拉伯人跟突尼斯的阿拉伯人连说再见的方式都不一样，但这并不影响他们拥有共通的思想内核。从外部视角看，总以为文化会有很大的差异。但并不一定，语言和文化的差异并没有想象中那么大。也许可以通过经常合作找到这种共通性的基础，同时尊重各自独特的要素。比如说伊拉克，那里有八大主要部落，各自拥有不同的语言和相应的家族发展史。</p><p></p><p>所以我觉得差异没有想象中那么大，不一定非要建立专属的大模型。我承认肯定会有独特的文化和元素，但这些应该是在建立了共通的上下文、找到求同存异的最佳答案之后再考虑的问题。</p><p></p><p></p><h4>&nbsp;问题：选择哪种语言训练的大模型更有竞争力？</h4><p></p><p></p><p>首先，我认为应该将语言和文化严格区分开来。</p><p></p><p>语言和文化之间当然存在关联。因此，我们可以使用英语训练大语言模型，然后将其翻译成其他语言，比如说韩语，这样就得到了韩语版本的模型，实际功能上并不受语言限制。然而，文化的差异确实存在，对于韩语内容，韩国人理解起来可能比美国人更容易。而这种差异不仅存在于美国和韩国之间，还广泛存在于消费受众和企业之间。以韩国为例，大多数亚洲国家都有自己独特而鲜明的商业文化，影响着交往方式、表达方式，甚至是专业人士之间的沟通方式。</p><p></p><p>比如，我曾在和亚洲的高级工程师们一起喝酒时发现，不能让酒杯离开视线，否则酒杯就会被再次填满。这是独特的文化属性，是无法仅通过阅读理解的。虽然这只是一个小例子，但却反映出背后深刻的文化差异。这些文化元素肯定会对在本地和国际之间进行分析产生影响。然而，如果能够添加一些附加元素，比如肢体语言，人们相互理解起来也就不那么困难。</p><p></p><p>总之，我相信本土元素在促进商业成功方面具有巨大的优势。</p><p></p><p>然而，真正的问题在于，并非每个国家和地区都有能力发挥自己的独特优势。例如，我多次访问过非洲，去过肯尼亚和安哥拉，他们可能没有足够的计算资源来展示自己的独特元素，或者至少还需要一些时间。但随着时机成熟，我相信他们将能够建立自己的本土比较优势。</p><p></p><p></p><h2>重视“实习”：传统的 IT 教育方式已经不满足需求了</h2><p></p><p></p><p>教育领域正在迅速适应技术创新，经历了一系列的变革。传统的高等教育不再是唯一的学习路径，行业主导的技能培训计划崭露头角，这种转变将使终身学习成为一种常态，个人和企业都将受益匪浅。</p><p></p><p>学位学徒制度的兴起进一步证明了这一趋势。雇主通过这种制度可以进行专门化的培训，而学徒在学习的同时能够赚取收入。越来越多的公司也开始大规模投资技能教育，将学习与实际工作相结合。</p><p></p><p>这种模式借鉴了技术工人的传统学徒模式，通过实际工作中的学习不断提升个体的技能水平。需要明确的是，这个概念并非没有先例：当你想到电工、焊工和木匠等技术工人时，他们的大部分技能都不是在课堂上获得的。他们从见习生到学徒，再到熟练工，甚至可能是熟练技工。在工作中学习是持续的，并且有明确的提升技能的途径。这种终身教育的方式——学习和好奇——对个人和企业来说都是好兆头。</p><p></p><p>教育的核心不再仅仅是所学专业，更重要的是教育经历是否培养了学习能力、设立宏大目标的能力、信息整合的能力以及批判性思维。 这些能力对于成功适应不断变化的工作环境至关重要。以德国为例，预备学校通过帮助接受过良好教育的难民学习技术，为他们更容易融入职场创造了机会。技术学习并不依赖于先前的职业背景，而是在于个体的学习意愿和能力。</p><p></p><p>未来，我们将目睹行业主导的教育机会崛起，逐渐超越传统的大学学位。这并非是对现有教育体系的取代，而是一种新的选择。在科技领域，学术学习仍然至关重要，但在其他行业，技术的快速发展将推动以行业为导向的培训和教育。</p><p></p><p></p><h2>区分性别的个性化医疗科技正在腾飞</h2><p></p><p></p><p>我关注这个话题是因为曾在医疗保健领域工作，文化、种族等差异都会影响人们的健康问题，而精准医疗的出现让我们能够更好地把握每个人身上的专有特质，标志着医疗保健行业迈向更高的层次。</p><p></p><p>近年来我看到女性保健在科技领域迎来了显著的发展。尽管女性每年在护理方面的支出超过 5000 亿美元，占人口的 50%，并负责 80% 的消费者医疗保健决策，但现代医学却基于对男性的默认假设。直到 1993 年 NIH 振兴法案颁布后，美国女性才被纳入临床研究。月经护理和更年期治疗等常见需求一直被视为禁忌，而女性在试验和研究之外的排除导致她们的治疗结果通常比男性更差。女性在很多疾病上的诊断时间普遍较晚，女性心脏病发作后被误诊的可能性高出 50%。处方药方面，女性报告不良副作用的比率明显高于男性。</p><p></p><p>然而，随着云技术和更多数据访问的帮助，女性医疗保健领域（也称为女性科技）的投资逐渐增加。亚马逊云科技与女性主导的初创企业密切合作，过去一年，FemTech 的资金增加了 197%。女性科技投资的激增，护理趋向混合化以及大量数据改善了诊断和患者治疗结果，将女性医疗保健带入了一个拐点。这种发展不仅将使女性受益，还将提升整个医疗保健系统。</p><p></p><p>现代社会对女性保健问题进行了更加开放的讨论，关注更年期等问题逐渐加强。同时，女性主导的初创公司崛起，吸引大量投资，标志着女性在医疗保健领域地位的提升。女性企业家的涌现将推动医疗保健行业更加注重个性化和全面性。在过去，女性在医疗研究中的参与曾受到限制，但近年来已逐渐有所改善，彰显了女性在医疗保健决策中的重要性。</p><p></p><p></p><h2>结语</h2><p></p><p></p><p>综上所述，2024 年将是技术发展的关键时期。人工智能助手和教育变革将在未来几年塑造我们的科技世界。我们期待着看到这些趋势推动技术的进步，为全球社会带来更多积极的变革。生成式人工智能的文化意识将为跨文化交流提供更深刻的理解。人工智能助手的崛起将提高开发人员的效率，缩短软件发布周期，教育的演进则将为个人和企业提供更灵活的学习机会。女性科技的崛起则将为医疗保健系统带来更全面、平等的服务。</p><p></p><p>在未来的技术发展中，我们期待看到更多创新的涌现，以满足不断变化的社会需求。通过对技术趋势的深入理解，我们可以更好地把握机遇，迎接挑战，共同创造一个更智能、更包容的未来。让我们共同努力，推动技术的发展，造福全人类。</p>",
    "publish_time": "2023-12-21 15:41:46",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Apache Doris 在奇富科技的统一 OLAP 场景探索实践",
    "url": "https://www.infoq.cn/article/ZDYOd0qX4V1vNh3o0xQI",
    "summary": "<p>作者｜奇富科技 中间件团队 &amp; SelectDB 技术团队</p><p></p><p>作为中国卓越的人工智能驱动的信贷科技服务平台，奇富科技（原 360 数科）致力于帮助金融机构提升智能化水平。经过多年金融领域实践，奇富科技以自身强大安全生态为依托，完成了在人工智能、大数据、云计算等技术方面的专业积累。目前，已与银行、消费金融公司、信托公司等建立广泛合作，针对不同类型金融机构的需求提供定制化解决方案，帮助客户完成数字化、智能化升级改造。</p><p></p><p>消费信贷对于促进消费起着越来越重要的作用，是助力消费恢复、激发潜在需求的重要手段之一。近年来，随着消费信贷规模快速增长，消费信贷的产品和服务也越来越丰富，个人信贷市场呈现的场景化、体验感强等特征。在此背景下，精准营销、精细化风险管理以及提升用户使用体验愈发重要。</p><p></p><p>为更贴合场景需求、提供精准运营数据支持，奇富科技自 22 年 3 月开始引入 <a href=\"https://doris.apache.org/\">Apache Doris</a>\"，希望通过 Apache Doris 融合用户多维价值数据，基于海量数据进行实时准确的数据分析，以提供个性化的营销方案及决策支持。截止目前 Apache Doris 已在奇富科技被多个业务线应用，每日线上运行数百同步工作流，日均新增及更新的数据规模达到数十亿，承载了上百万次的有效查询。Apache Doris 的应用不仅有效提高了数据处理与分析的速度，还降低了运维成本、确保了系统的稳定性，为奇富科技实现精细化运营和营销广告精准投放提供了强有力的数据支持。</p><p></p><h2>业务场景及应用现状</h2><p></p><p></p><p>奇富科技大数据平台提供一站式大数据管理、开发、分析服务，覆盖大数据资产管理、数据开发及任务调度、自助分析及可视化、统一指标管理等多个数据生命周期流程。其中，最典型的数据应用服务即在线报表分析和离线标签服务，离线标签服务又包含了用户标签点查、客群画像、触发式策略生成和人群圈选四大服务。为满足不同业务数据需求，早期架构将数据分散存储在 Clickhouse、Elasticsearch、MySQL 等多个组件中，带来了数据应用和系统运维的挑战：</p><p></p><p>部分 SLA 不达标：架构组件过多，原 OLAP 引擎的稳定性及可用性无法满足 SLA 要求。运维管理复杂：需同时管理多个组件，运维复杂度和难度均较高； ClickHouse 对其他组件依赖性高，扩容难度大；MySQL 单实例容量有限，需维护多个实例且不支持跨实例查询，增加了管理成本。数据治理难度高：整体数据关系复杂，数据治理难度较高，对于后续数据血缘和数据生命周期管理带来较高的成本。</p><p></p><p>除此之外，还存在一些性能及稳定性问题，具体表现为：</p><p></p><p>查询耗时高：MySQL / ClickHouse 在面对复杂查询时性能较差，存在关联查询失败率高、查询响应速度慢等问题，无法满足秒级查询响应需求。导入性能差：受限于 MySQL 可承载的数据规模（千万级），无法满足大规模数据导入的要求；且 ClickHouse 导入性能较差，容易出现导入不稳定的问题。</p><p></p><h2>技术选型</h2><p></p><p></p><p>为解决以上问题，奇富科技计划引入一款分析型数据库以满足大部分 OLAP 场景需求，该数据库应具备以下特性：</p><p></p><p>安全易治理：要求单一数据库即可满足大部分 OLAP 需求，简化数据管理流程，提高数据治理效率；要求具备完善的权限控制机制，以保证数据的安全性和隐私性。准确实时：支持数据实时导入及查询，确保数据导入不丢不重，实现 Exactly Once 语义。易用低成本：部署简单、可根据需求实现灵活扩缩容，支持 MySQL 语法、降低开发人员学习门槛，提高开发效率。</p><p></p><p>基于以上选型要求，奇富科技对 ClickHouse、Apache Doris 进行了调研。其中 Apache Doris 在导入、查询、运维等方面的性能符合选型要求，同时在社区规范性、活跃度、开放程度和可持续发展方向表现出色。因此，奇富科技选择 Apache Doris 作为整体 OLAP 场景统一的分析引擎。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/66/6649d90938263da3ebea18b609f8bbe2.png\" /></p><p></p><p>接下来将结合真实业务场景，介绍 Apache Doris 在奇富科技的深度应用和优化实践，更好了解 Apache Doris 如何助力奇富科技实现精准营销，提升业务收益。</p><p></p><h2>Apache Doris 在报表分析场景的应用</h2><p></p><p></p><p>在报表分析场景中，数据分析师通常会基于重要业务报告、图表、当前业务状况评估报告进行数据分析，旨在为业务策略决策提供重要依据。</p><p></p><p>早期架构在应对该场景时，会出现数据表同步时效 SLA 达标率（每日统计）波动较大的问题，经过深入分析是由数据同步过程所涉及组件繁多导致。不仅如此，组件繁多还增加了数据同步的复杂性，对数据源（MySQL、ClickHouse）和同步任务（如 DataX Job、Flink Job 等）的稳定性提出了挑战。</p><p></p><h3>报表引擎升级</h3><p></p><p></p><p>为了解决这些问题，我们使用 Apache Doris 替换了 ClickHouse 和 MySQL ，由 Doris 统一为报表提供服务，降低报表数据源的复杂度。从下图可知，Doris 架设于 Hive 数仓上层，可充分利用 Doris 强大的查询性能，为报表分析场景提供查询加速。同时 Apache Doris 支持原生 MySQL 协议，可与帆软、观远等 BI 工具无缝结合，提升了报表分析的灵活性与易用性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ab/abab74297d38b53fed8f47cf2383ebe8.png\" /></p><p></p><h3>导入任务优先级</h3><p></p><p></p><p>在原先的逻辑中，Doris 对于导入任务的处理没有优先级的概念。当有大量任务同时提交时，Doris 会按照先进先出的逻辑执行任务。因此，我们主导设计并向社区贡献了导入任务优先级功能。该功能可以根据用户设定的优先级来处理导入任务，从而可以保证部分高优任务的时效性。详细流程如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a1/a13783cb0d6ec52798ffbee9a771cb36.png\" /></p><p></p><p>通过优先级设置，即使在任务高峰期，依然可以保证高优任务的时效性，极大提升了数据表同步时效 SLA 达标率。为数据的传输及应用提供了更灵活、高效的支持。</p><p></p><h3>异地双机房高可用方案</h3><p></p><p></p><p>为保障 Doris 集群的可用性及稳定性、确保在机房故障时集群仍然可读，并在故障恢复后主集群的数据能够回写，为 Doris 集群配备双机房容灾能力势在必行。经过方案调研，决定通过自行开发 Replicator 主从同步插件来实现双机房容灾建设，以下为具体的架构设计：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e3/e3231f07d9876d8595f448764b5426f3.png\" /></p><p></p><p>在主集群安装 Replicator 插件，该插件可以拦截并解析主集群执行的全量 SQL，经过滤操作，可筛选涉及库、表结构变更和数据增、删、改相关的 SQL，并将相关 SQL（部分 SQL 需改写）发送到从集群进行回放。</p><p></p><p>更进一步的，为了应对主集群可能遭遇意外情况，奇富科技设计了一套灵活的 DNS 解析地址切换机制。当主集群不可用时，切换 DNS 解析地址到从集群，完成主从集群的切换。</p><p></p><p>除此之外，我们还在 Doris 控制台（内部自研的 Doris 集群维护管理服务）开发了 Validator 数据校验模块，可定时对 Doris 数据表主从集群一致性情况进行校验并上报，包括元信息、行数等。</p><p></p><h3>应用收益</h3><p></p><p></p><p>以表同步耗时为例，利用 Doris Broker Load 方式有效降低数据导入的复杂度，提高数据导入时效性，成功将报表数据同步时效 SLA 达标率提升至  99% 以上。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/51/51a2be92cbf6ef0b5248a8a8381f5806.jpeg\" /></p><p></p><p>以查询时效为例，下图为引入 Apache Doris 后报表分析集群的查询时效监控，平均耗时稳定在 10s 以内、P90 查询耗时稳定在 30 秒以内 ，相比旧架构平均耗时降低了 50% 以上。随着应用程度的加深和数据规模的增长，查询性能还得以进一步提升，获得更多内部业务线的认可。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8f/8f83aeae001f083ba26b690d64b4ba52.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/67/67ace14ad3ae2ed1534e7a5db748060b.jpeg\" /></p><p></p><h2>Apache Doris 在离线标签服务场景的应用</h2><p></p><p></p><p>在标签服务场景中，数据分析师会根据用户的多重维度信息，基于一定策略进行用户标签的打标，标签主要包括行为标签和属性标签。离线标签服务则以上述标签为基础，为下方四个场景提供服务：</p><p></p><p>用户标签点查服务：在风控流程中，特征平台将查询用户的标签信息，并基于标签信息构建用户特征变量。客群画像服务：基于用户标签信息进行客户画像描绘，为电销、营销等部门制定业务策略提供数据支撑。触发式策略生成服务：电销部门基于用户标签信息，通过触发式策略生成人群包，并对筛选出的客户群进行外呼。人群圈选服务：营销部门基于用户的标签信息，对生成的人群包进行个性化广告投放。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bb/bb923f4fc5f564f2562f62cfec1619e6.png\" /></p><p></p><p>由于离线标签服务需同时满足四个场景的需求，因此对数据导入时效性和可用性有较高要求，以确保服务持续稳定运行。同时，需要保证用户标签查询的点查性能，支持实时查询标签信息。在人群圈选方面，还需具备精准去重和集合交并集运算能力，保证营销活动和广告投放的精准性和有效性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6a/6a23c55f6b5cd1d1c5af4a5da7d79d10.png\" /></p><p></p><p>在原先的架构中（如上左图所示），导入的数据会逐步生成标签信息，并对标签信息进行加工、合并为 JSON 文件（合并操作是为了减少 Elasticsearch 的更新次数及负载），合并后的 JSON 文件导入到 Elasticsearch 中提供数据服务。然而，这种方式带来两个问题：</p><p></p><p>旧标签服务过度依赖于合并操作，如果某个标签服务的数据出现问题，那么整个标签的合并操作就无法完成，进而影响标签服务的正常运行。数据合并操作基于 Spark 和 MapReduce 进行，处理时效可能超过四个小时甚至更长，这样长时间的处理耗时会导致场景服务错过黄金营销时间，造成业务营收的损失。</p><p></p><p>为解决上述问题，我们基于 Apache Doris 对架构进行了改造，如上图右图所示，在标签数据加工过程中，利用 Apache Doris 进行标签宽表的存储和处理，当上游标签准备就绪时，可使用 Aggregate Key + replace_if_not_null 实现标签合并和部分列更新的效果。当所有标签均更新到标签宽表后，继续将其同步到 Duplicate Key 模型的标签明细宽表中，以提升查询性能。</p><p></p><p>这样的改造使得我们能更加及时地处理标签数据，标签数据的导入时效从 4 小时缩短至 1 小时以内。此外，借助 Doris 完善的 Bitmap 索引以及高并发查询性能，实现了秒级人群圈选。在点查询方面，QPS 达到 700+，确保了查询的快速响应。</p><p></p><h2>基于 Apache Doris 的湖仓查询加速实践</h2><p></p><p></p><p>为缩短业务决策周期、提升数据分析师的工作效率，对于离线湖仓查询加速的重要性日益凸显。因此自 22 年 9 月起，我们开始将 Apache  Doris 应用在离线查询加速场景中，彼时 Doris 仅支持以 Hive 外部表的形式进行查询，由于外部表需要配置映射关系，当 Hive 元数据发生变更时需要手动更新，人工维护成本较高，因此选择将 Hive 中数据导入进 Doris 中以实现查询加速。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d6/d662398356dfc4f4772acaffcaa87201.jpeg\" /></p><p></p><p>具体而言，会先根据查询频率对数据表优先级进行排序，通过 Doris Broker Load 将查询频率 Top 500 的数据表从 Hive 导入到 Doris。通过路由引擎定时调度收集数据表在 Doris 和 Hve 中表的元信息，包括表的字段、字类型以及数据规模。当收到查询语句时，路由器检测数据的是否在 Doris 中，如存在则会路由到 Doris 引擎，从而实现查询加速。</p><p></p><p>而该方案并不完美，依赖于对于 Hive 数据的导入。当面对大规模数据导入任务时，可能造成集群资源紧张导致查询和导入性能下降的问题，甚至可能引起集群不稳定，对业务使用产生负面影响。</p><p></p><p>为解决上述问题，我们对架构进行了进一步升级。在 Apache Doris 1.2 版本支持了 Multi-Catalog 多源数据目录，基于该能力简单配置即可将 Hive 集群的数据表完整同步到 Doris 中，解决了配置外表繁琐、元信息无法自动同步等问题。以下是数仓查询加速新方案：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/83/8330e31823f8d5fbb2c3f7041f03c48c.jpeg\" /></p><p></p><p>在新方案中，主要通过以下几个步骤完成数仓查询加速方案：</p><p></p><p>基于 Doris Multi-Catalog 能力，将 Doris 引擎加入到查询引擎路由策略中（Internal Catalog 和 Hive Catalog）；引入弹性计算节点并落地 Deploy on Yarn 方案，简化部署流程以支持灰度期间快速升级迭代、快速扩缩容支持；查询引擎实现自动路由，引擎选择对用户透明。</p><p></p><p>当用户提交查询语句后，路由引擎（即查询网关）会根据收集的数据元信息进行判断，为查询语句匹配最优查询路径。路由引擎还会分析查询涉及的分区数和表行数，来匹配最佳执行引擎（ Doris 、Presto、SparkSQL ），例如当查询语句所依赖数据表都存在于 Doris 内表中且元数据一致时，将直接路由至 Doris 内表进行查询，无法命中则将查询下压，由 Doris Hive Catalog 进行查询或者通过 Presto 进行查询。</p><p></p><p>通过这种策略，用户无需关心查询由哪个引擎执行，也无需关注查询引擎间的语法差异。查询总能以最高效的方式执行，实现查询加速，并能保障结果的准确性。使用上述方案也遭遇了一些问题，接下来分享应对策略及优化方案。</p><p></p><h3>Hive 元数据准实时同步</h3><p></p><p></p><p>使用上述查询加速方案时，如果 Hive 元信息更新后无法准实时同步至 Doris ，用户查询时会出现结果不一致问题。为避免该问题发生，可使用 Doris 元数据自动刷新特性（基于 HMS Event Listener 实现）实现元信息准实时同步。这种方式需要在 Hive 端开启 HMS Event Listener ，并在 Doris 端开启 HMS Event 消费开关。具体实现如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/55/557acfb0a6d1c9f185e3b5b974f22ff1.png\" /></p><p></p><p>对于 Hive 端，当开启 Listener 后，因 Hive 本身具有内置的 Listener 实现，会对 Hive 集群中 DDL 操作以及 Insert 操作进行拦截。在发起拦截操作后，生成对应的 HMS Event（事件），并写入 Hive 元信息数据库中。</p><p></p><p>对于 Doris 端，当开启消费 HMS Event 开关后，Doris 的 Master FE 节点会启动后台线程，调度式批量拉取 HMS  Event，通过消费 HMS Event 获取 Hive 端的元数据变化，并将该变化同步到 Doris 内部维护的 Hive 元信息中，实现数据的准实时同步。在实施过程中也遇到了一些新的问题，在此对优化方案进行分享：</p><p></p><p>优化方案 1：Hive DDL 长时间阻塞：</p><p></p><p>启动 Hive 端的 HMS Event Listener 后，Hive 处理新增表和分区时需要获取表、分区名和文件信息，生成相应的 HMS Event，而 Doris 回放 HMS Event 时并不需要文件信息。因此当 Hive 表、分区文件数过多或集群繁忙时，获取文件信息的操作会延长 HMS Event 生成时间，导致 Hive DDL 操作耗时增加。</p><p></p><p>基于此，我们重写了 Hive DbNotification  Listener，屏蔽对 Hive 表、表分区文件信息收集，有效减少不必要信息的拉取与采集，缩短了 Hive 端的执行效率。</p><p></p><p>优化方案 2：消费速率与事件产生速率不匹配：</p><p></p><p>Hive 集群繁忙时，DDL 或 Insert 事件频率高，且 Doris 采用单线程串行模式消费 HMS Event，可能会出现 Doris 消费速率与Hive 时间产生速率不匹配的问题。</p><p></p><p>为了提高 Doris 消费速度，我们在 Doris 端增加了预先事件合并（HMS Event Merge）步骤，过滤掉一部分 HMS Event，大幅降低了需要消费的 HMS Even 数量。预先事件合并的核心思想是判断批量 HMS Event 中是否存在可以抵消前面某个 HMS Event 产生的效果，如果是则跳过前面的 HMS Event。通过这样的方式，HMS Event 数量能够大幅度降低，进而提升了 Doris 处理 HMS Event 的消费速度。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0a/0a3e340a70846c69bf70a38a78a95dda.png\" /></p><p></p><p>预先事件合并原理如上图所示，第一个事件 DropPartitionEvent（db1.tbl1）和最后一个事件 DropTableEvent（db1.tbl1）针对同一张 Hive 表。DropPartitionEvent 发生在前，DropTableEvent 发生在后。在处理 DropPartitionEvent 时，Doris 会删除该 Hive 表的应分区缓存信息；在处理 DropTableEvent 时，Doris 会删除该 Hive 表的表缓存信息。由于后一个 HMS Event 产生的效果可以完全抵消前一个 HMS Event 产生的效果，因此可以跳过前面的 HMS Event。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9e/9ef71792d828a32fead5cf512db1eca8.png\" /></p><p></p><p>我们对集群 4 天内所处理 HMS Event 处理情况进行抽取，从上图可知，经 HMS Event Merge 操作后，Doris 消费事件数量时显著降低，较原来减少约 2-5 倍的数量。完成优化后，再未出现消费速率低于产生速率的问题。</p><p></p><p>优化方案 3：HMS Event 类型缺失，影响 FE 稳定性</p><p></p><p>针对 CDH 或者 HDP 集群 Hive 版本产生压缩格式的 Event ，新增了 GzipJSONMessageDeserializer 反序列化器进行处理。原因是 Slave FE 节点一般通过 Journal Log 方式消费 HMS Event ，如果消费失败会导致 FE 服务直接退出，通过新增 Fallback 策略可以提升消费逻辑的健壮性，尽量避免 FE 服务退出的问题。</p><p></p><h3>引入弹性计算节点，Deploy on Yarn 实现弹性扩缩容</h3><p></p><p></p><p>当需要处理大规模数据或进行高性能计算时，需要更多计算资源提供支持。若部署的 Doris BE 集群时有上百个节点，每一个节点需要多个 CPU，那么在运行过程中需要庞大的资源支撑，从而带来较大的资源成本和部署成本。为降低资源和部署成本，我们选择引入 Doris 的弹性计算节点（Elastic Compute Node），并选择将弹性计算节点与 Hadoop 集群的其他组件（如 DataNode 节点）混合部署，能够更好地管理和优化计算资源。</p><p></p><p>在此基础上，基于 Doris 计算节点的无状态特性，可通过 Skein 进一步简化 Doris 计算节点 Deploy on Yarn 的部署流程，实现节点弹性扩缩容。在实际运行过程中，我们依据用户的查询习惯，在夜间查询较少时缩容、在白天业务高峰时扩容，最大化利用集群资源、提高资源利用率。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a5/a51ed98aee67a34ecabb21ac8743d5bb.png\" /></p><p></p><p>如上图，在 Yaml 文件中定义 Doris 计算节点的数量和所需资源信息，并将安装包、配置文件、启动脚本统一打包至分布式文件系统。当需进行版本升级或集群启停时，只需一行命令即可在分钟内完成整个集群上百个计算节点的启停操作。</p><p></p><h3>Hive 视图查询优化</h3><p></p><p></p><p>在 Hive Catalog 查询运行过程中会有偶发的查询失败问题，因此我们对数百业务用户查询失败的原因进行了深度分析，发现 28% 是由查询视图引起，24% 是由于用户使用了 Doris 无法匹配的函数导致。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/39/39e1fdb6a86f193c4671f6117f77cb05.jpeg\" /></p><p></p><p>如下图所示，当用户发送查询请求后，在 Doris 内部将经历词法分析、语法分析、逻辑执行计划和分布式执行计划四个阶段。Hive 视图识别在第三阶段进行，即当逻辑执行计划阶段生成 Hive ScanNode 后，对其进行初始化时，Doris 会识别该表是否为 Hive 视图。如果是 Hive 视图，将直接抛出查询异常导致查询失败。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e7/e770632c96a47645e2398a0b1ae8fba5.png\" /></p><p></p><p>因此我们对 Hive 查询执行进行了优化，将 Hive 视图的识别提前至语法分析阶段（第二阶段）进行，如果识别为 Hive 视图，则通过 HMS Client 客户端获取该视图定义的 DDL ，并将 DDL 带入 Doris 解析视图依赖的 Hive 实体表。在逻辑执行计划生成阶段（第三阶段），将生成与 Hive 实体表相对应的 HiveScanNode，查询将继续进行。通过简单改造，Doris 即可通过 Hive Catalog 实现对 Hive 视图的查询支持。</p><p></p><h2>应用收益</h2><p></p><p></p><p>查询加速主要得益于 Apache Doris 的 Multi-Catalog 特性，相对于外部表，Multi-Catalog 无需创建表与表之间的映射关系，可以实现元数据层的对接，如上文所述只需简单的配置，实现将整个 Hive 集群的数据表完整地同步到 Doris 中，彻底解决了以往配置外表繁琐、不支持元信息自动同步等问题。</p><p></p><p>此外，借助 Doris Multi-Catalog 替代了早期架构中多个数据组件，统一了数据源入口和数据查询出口，降低架构的复杂度、缩短数据处理与查询的流程，大大提高数据查询的效率。</p><p></p><h2>结束语</h2><p></p><p></p><p>从 22 年引入 Doris 以来，凭借其优异的性能、较低的运维复杂度和较高稳定性，迅速在奇富科技内部多个业务场景得到大规模的应用。截止目前，生产环境共有近十套集群、上百 BE 节点、CPU Core 超过 1000+，总数据规模达到数十 TB ，每日有数百个同步工作流在运行，日新增数据或更新的规模达近百亿，每天支持业务方百万次的有效查询量。通过 Doris 的应用极大的降低了架构的复杂度，有效提高了数据处理与分析的速度，降低了运维成本，确保了系统的稳定性。</p><p></p><p>未来我们将继续深入使用 Apache Doris 、并引入 2.0 版本，为用户带来更加实时、统一的数据处理和分析体验。后续我们将重点关注存算分离架构、数据湖分析特性以及 Doris Manager 组件的应用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a0/a058b26ee8a6940862e4c2ad80ad53be.png\" /></p><p></p><p><a href=\"https://selectdb.com/blog/101\">存算分离架构</a>\"：通过存算分离架构实现集群融合，消除不同集群间 Doris 版本的差异，提供更加灵活的负载隔离策略和弹性部署支持，为用户带来更加稳定、可靠的数据处理环境，满足不同业务需求。<a href=\"https://selectdb.com/blog/48\">数据湖分析特性</a>\"：持续深入使用，通过统一查询引擎简化内外表数据流通过程，降低数据处理的复杂性。<a href=\"https://selectdb.com/blog/102\">Doris Manager 组件</a>\"：为了让用户更加轻松的进行数据库的运维和管理，飞轮科技开发了一站式数据库集群管理工具 Cluster Manager for Apache Doris（简称 Doris Manager）。该工具提供轻松部署和接管 Doris 集群的功能，支持物理机和虚拟机环境。借助直观的界面，为用户提供了简单易用的可视化运维体验。同时用户还可以快捷的对节点进行扩缩容和重启，设置监控告警等操作。这将极大地提升运维效率，减少错误和中断，提高服务质量和稳定性。</p>",
    "publish_time": "2023-12-21 16:20:04",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]