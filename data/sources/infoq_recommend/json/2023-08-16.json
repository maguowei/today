[
  {
    "title": "分布式PostgreSQL基准测试：Azure Cosmos DB、CockroachDB和YugabyteDB",
    "url": "https://www.infoq.cn/article/0HLeJbIogjXgqZ8bbCJj",
    "summary": "<p>最近，微软详细介绍了<a href=\"https://devblogs.microsoft.com/cosmosdb/distributed-postgresql-benchmarks-using-hammerdb-by-gigaom/\">分布式PostgreSQL基准测试的结果</a>\"，比较了Azure Cosmos DB for PostgreSQL、CockroachDB与Yugabyte的事务处理性能和价格。这几种数据库在实现时做了不同的权衡，测试结果显示，Azure Cosmos DB的吞吐量更高。同时，他还着重指出了针对分布式数据库进行基准测试所面临的挑战。</p><p>&nbsp;</p><p>根据<a href=\"https://research.gigaom.com/report/transaction-processing-price-performance-testing/\">GigaOm基准测试</a>\"，在事务性能和价格方面，采用Citus分布式表的<a href=\"https://learn.microsoft.com/en-us/azure/cosmos-db/postgresql/introduction\">Azure Cosmos DB for PostgreSQL</a>\"优于CockroachDB Dedicated和Yugabyte Managed这两种全托管分布式数据库。</p><p>&nbsp;</p><p>正如<a href=\"https://www.infoq.com/news/2021/10/cloud-spanner-postgresql/\">InfoQ之前的报道</a>\"，随着不同的供应商对PostgreSQL这个流行的开源关系型数据库进行扩展、重新实现或创建分叉，它正在成为云分布式数据库的新标准。这项由微软赞助的基准测试使用了<a href=\"https://github.com/TPC-Council/HammerDB/\">HammerDB</a>\"。这是一个用于对关系型数据进行基准测试的开源工具，由事务性能委员会（<a href=\"https://www.tpc.org/\">Transaction Performance Council</a>\"，缩写为TPC）负责管理。微软首席软件工程师<a href=\"https://www.linkedin.com/in/marcoslot/\">Marco Slot</a>\"写道：</p><p></p><p></p><blockquote>GigaOM使用HammerDB TPROC-C对Azure Cosmos DB for PostgreSQL和两个类似的托管服务产品（…）进行了基准测试。在最初的基准测试中，GigaOM使用了1000个仓库，产生了大约100GB的数据。然而，CockroachDB和Yugabyte的吞吐量之低令人惊讶。在不改变连接数的情况下，增加两者的仓库数量可以提升性能。</blockquote><p></p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2f/2f32249fbec97e91fcf1b2c95cc52e6f.png\" /></p><p></p><p>图片来源：<a href=\"https://devblogs.microsoft.com/cosmosdb/distributed-postgresql-benchmarks-using-hammerdb-by-gigaom/\">https://devblogs.microsoft.com/cosmosdb/distributed-postgresql-benchmarks-using-hammerdb-by-gigaom/</a>\"</p><p>&nbsp;</p><p>有一个非常重要但颇有争议的点是<a href=\"https://www.citusdata.com/product/citus-on-azure/\">Citus</a>\"的使用。Citus是PostgreSQL中一个用于分发表的开源扩展，它要求开发人员指定一个分发列，即分片键：</p><p></p><p></p><blockquote>Citus的核心理念一直是：分布式PostgreSQL是为大规模、高性能而生的，因为对于其他任何事情，PostgreSQL都已经足够好。</blockquote><p></p><p>&nbsp;</p><p>测试的其他分布式数据库不依赖于分布式列的定义。在Reddit上，Slot<a href=\"https://www.reddit.com/r/PostgreSQL/comments/14fbjgg/comment/jozf85t/?utm_source=share&amp;utm_medium=web2x&amp;context=3\">承认</a>\"了其中的区别：</p><p></p><p></p><blockquote>性能差异似乎有点尴尬。我想特别指出的是，使用Citus确实需要一些额外的步骤（例如create_distributed_table）来定义分布式列和协同定位（否则，你只能使用单个节点）。我们的经验是，如果不对相关数据做协同定位，那么传统的事务型PostgreSQL工作负载的性能将比单个服务器差许多。</blockquote><p></p><p>&nbsp;</p><p>YugabyteDB开发大使Franck Pachot在推特上谈到了这项基准测试，他<a href=\"https://twitter.com/FranckPachot/status/1672330208802635776\">提了一个问题</a>\"：</p><p></p><p></p><blockquote>这是比较Citus（通过两阶段提交协议在SQL数据库上实现的分片）与YugabyteDB及CockroachDB （通过全局ACID事务在分布式存储上实现的SQL）吗？弹性、全局一致性、灵活性、自动划分/再平衡都不在同一个层次上。它们针对的是不同的用例。</blockquote><p></p><p>&nbsp;</p><p>该报告承认，对于不同的部署，不同的分布式数据库可能在不同的特性上胜出，包括响应时间、并发性、容错性、功能、一致性或持久性。Slot总结道：</p><p></p><p></p><blockquote>分布式系统，尤其是分布式数据库，涉及多个层面的权衡。CockroachDB和Yugabyte做了不同的权衡，它们不需要分布式列（…）不管是扩展Postgres（如Citus所做的），还是创建Postgres分叉（如Yugabyte所做的），亦或是是重新实现Postgres（如CockroachDB所做的），每一种决定也都是一个权衡，都会对最终用户的体验产生重大的或好或坏的影响。</blockquote><p></p><p>&nbsp;</p><p>为了鼓励客户运行与其工作负载相匹配的基准测试，<a href=\"https://github.com/citusdata/citus-benchmark/tree/master/azure\">微软共享了辅助脚本</a>\"，以便他们可以在Azure Cosmos DB上运行HammerDB基准测试。微软高级软件工程师<a href=\"https://www.linkedin.com/in/jeltef/\">Jelte Fennema</a>\"<a href=\"https://victorious-mud-07c59021e-600.westus2.3.azurestaticapps.net/blog/2022/03/12/how-to-benchmark-performance-of-citus-and-postgres-with-hammerdb/\">展示</a>\"了如何自动运行基准测试，包括集群设置和销毁。</p><p>&nbsp;</p><p>按照GigaOm的说法，<a href=\"https://cloud.google.com/spanner/docs/postgresql-interface\">Google Spanner Postgres Interface</a>\"之所以不在比较范围，是因为该服务不提供运行基准测试所需的Postgres兼容性级别。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/07/distributed-postgresql-benchmark/\">https://www.infoq.com/news/2023/07/distributed-postgresql-benchmark/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/VVCTQbCV1rKcZoMD3TKR\">这将是一场灾难？37年历史的PostgreSQL数据库将进行重大架构变更</a>\"</p><p><a href=\"https://www.infoq.cn/article/4114G9FlqZFEyTzQ53mq\">微软发布Azure Cosmos DB for PostgreSQL</a>\"</p>",
    "publish_time": "2023-08-16 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "讯飞星火V2.0发布：突破代码能力 ，提升大模型智慧程度",
    "url": "https://www.infoq.cn/article/AYS8kOCDsu3VDfMdlrjQ",
    "summary": "<p>8月15日，讯飞星火认知大模型V2.0升级发布会如约而至，科大讯飞董事长刘庆峰、研究院院长刘聪重磅发布代码能力和多模态能力升级，同时发布并升级搭载讯飞星火认知大模型V2.0能力的多项应用和产品。刘庆峰表示，代码能力是支撑认知大模型智慧的关键维度，多模态能力则是实现通用人工智能的必经之路也是科大讯飞既定的人工智能技术长期战略，大模型赋能个体和行业的大未来正在到来。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/31/0e/3127387d101eec1d38329895d33f5f0e.png\" /></p><p></p><p>技术获得重大突破的同时，搭载讯飞星火认知大模型核心能力的应用和产品也越来越丰富：既有代码快速生成或者改Bug的智能编程助手iFlyCode1.0，能够进行视频创作的讯飞智作2.0，还有帮助教师设计教学活动、一键生成课件的星火教师助手，面向学生口语练习的星火语伴2.0，讯飞AI学习机也升级AI编程空间和AI创意画板。此外，科大讯飞还和华为联合发布讯飞星火一体机，为每一家企业提供专属的大模型，联合打造全国产化算力底座。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/f9/3b/f9dc8cdc0868f5afc1c10e6341f41a3b.png\" /></p><p></p><p>至今，讯飞星火已陆续在教育、办公、汽车、金融、工业、医疗等行业推进真实可见的应用落地，同时也和开发者一起持续构建通用人工智能新生态。</p><p></p><p>“关于未来，无论你觉得行还是不行，你终将都是对的”，科大讯飞董事长刘庆峰表示，要打造每个人的AI助手，释放每个人的无限可能。</p><p></p><h3>人人都是开发者！ 讯飞星火突破代码能力并发布智能编程助手 iFlyCode</h3><p></p><p></p><p>代码生成、自动纠错 ，讯飞星火代码能力升级</p><p></p><p>代码是大模型硬碰硬的能力，此次升级也是科大讯飞今年5月6日首发讯飞星火认知大模型时立下的里程碑。</p><p></p><p>“代码数据能提升认知大模型的‘智慧’，代码能力是认知大模型聪明程度的重要标志。”刘庆峰说，代码能力也是构建和链接数字世界的有效手段，可以大幅降低数字经济的创业门槛和成本，不用个个都是编程高手，只要发挥自己的想象力、基于对应用场景的认知，就可以提升开发效率、实现相关创业。</p><p></p><p>此次讯飞星火2.0对代码能力进行5个维度的升级，包括：代码生成、代码补齐、代码纠错、代码解释、单元测试生成。</p><p></p><p>现场演示中，使用Python画红色的心形线、画出马鞍面方程三维立体图并设置渐变色、用代码生成小游戏对讯飞星火都不在话下，“使用python处理视频星火.m4v，提取其中第2到10秒，把画面缩小一半，加速5倍，保存成gif图片。”就连利用小视频做表情包这种需求都可以迅速搞定。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/f0/93/f09dd2c380875e2d288058d032e9dd93.png\" /></p><p></p><p>刘庆峰介绍，根据OpenAI构建的代码能力公开测试集HumanEval，星火V1.5 Python语言的效果只有41分，V2.0已经到了61分、接近ChatGPT。根据认知智能国家重点实验室构建的代码的真实的场景使用的测试集，代码生成和补齐维度上已经超过了ChatGPT。根据计划，讯飞星火代码各维度的能力将在今年10月24日超越ChatGPT，明年上半年对标GPT-4。</p><p></p><p>讯飞星火智能编程助手 iFlyCode上线，编码效率提升30%</p><p></p><p>讯飞星火代码能力升级后如何让开发者们更方便使用？科大讯飞现场发布了讯飞星火的应用级产品——智能编程助手iFlyCode1.0。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/d0/cc/d062604cb6b77498f734030e985bb1cc.png\" /></p><p></p><p>去年科大讯飞全球1024开发者节期间，用两个手指捏合就能写字的“凌空手写”功能惊艳了不少人，对iFlyCode来讲，开发这个功能简直就是“小菜一碟”，刘聪现场简单几步Prompt完iFlyCode界面后，一行代码都不用写，“凌空手写”功能就已马上实现，而在以前，即便是有经验的工程师，也要半天到1天才能完成，现在只需要几分钟。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/f0/ab/f0d616160177f2d060a64a7bdce9d0ab.png\" /></p><p></p><p>根据讯飞内部研发效能平台对2000余名员工在1个月内测试使用iFlyCode1.0的成效数据统计，在一些典型场景中，代码采纳率达30%，编码效率提升30%，综合效率提升15%。</p><p></p><p>教育数字基座搭载讯飞星火2.0 “零代码”能力也能建设数字化校园</p><p></p><p>讯飞星火代码能力的升级，一方面是帮助专业的程序员提升效率、将自己从繁琐的事务性工作中抽离出来去发挥更大的创造力价值，另一方面则是帮助非专业的“小白”零门槛进入代码世界。</p><p></p><p>发布会上，科大讯飞发布了代码能力的行业应用案例：“零编程基础”的老师也能使用教育数字基座作为开发助手，满足学校管理数字化转型中的个性需求和定制开发。</p><p></p><p>“请帮我搭建一个离校管理应用，家长可以帮学生申请离校，申请信息需要经过班主任审批。”只需要简单指令便可在数字教育基座上完成应用搭建；家长请假语音输入后变成自动生成请假条，班主任在线审批，任课教师同步可在班牌上看到今天请教的同学名单；还可根据需求完成限定条件下的离校生统计。</p><p></p><p>“教育数字基座致力于构建‘数联、物联、智联’为一体的教育应用开发生态，是数字化校园发展的未来趋势。”根据上海、湖北等试点学校的应用成效，教育应用的开发周期和投资成本都大幅度降低。</p><p></p><p>刘庆峰表示，代码能力不仅应用于讯飞教育数字基座，还广泛应用于医院、大学、企业、政府等不同的机构，通过iFlyCode实现快速搭建和低成本迅速呈现，“这就是我们说的通用人工智能为什么会深刻改变今天以人力和时长为主要逻辑的商业模式，实现整个产业的彻底的颠覆和升级”。</p><p></p><h3>多模态能力再升级 ，讯飞智作2.0让视频生成更高效</h3><p></p><p></p><p>拍了美图想“秒速”发一个图文并茂的朋友圈？张嘴就想画出脑海里突发奇想的图画？只要输入一段文字，一键就想生成声情并茂的小视频？</p><p></p><p>这些功能，讯飞星火V2.0全部可以实现。发布会现场，刘庆峰对讯飞星火的多模态能力进行重磅发布，讯飞星火在图像描述、图像问答、识图创作、文图生成、虚拟人合成等方面全新升级。他表示，“讯飞星火的多模态能力在业界可测的大模型中明显领先。”</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/38/63/382024567b1d5887c0eb873ccb2dc863.png\" /></p><p></p><p>刘聪现场继续真机实测，让星火大模型现场“读图”，生成人物、风景等各类照片，生成班级手抄报，还能根据古诗词“作画”，“智商”在线。星火还能进行虚拟人短视频的生成，“创作一篇立秋抒情散文，并用一个短发民国风的女生形象生成视频”，他话音刚落，一个身穿民国风格的女生站在不断切换的秋天美景前娓娓道来。</p><p></p><p>对于升级多模态能力，刘庆峰重点介绍了两点。“多模态能力是赋能行业的刚需，也是实现通用人工智能的必经之路。”他强调，当前多模态能力已广泛应用在教育、医疗、工业、汽车、机器人等领域，它可以从真实世界获得越来越多的数据，在产品终端有学习、训练和提升，包括更柔性更自主的工业机器人、更好的自动驾驶、走入家庭的陪伴机器人等。</p><p></p><p>“多模态能力也是科大讯飞既定的人工智能技术长期战略。”最近3年，科大讯飞已在多模态领域获得了17个国际权威评测冠军，2022年初讯飞就已发布了包括多模感知、深度理解、多维表达、运动智能等核心能力的“讯飞超脑2030计划”，让懂知识、善学习、能进化的机器人走进每个家庭。“这其中最重要的一项技术就是多模态能力。”</p><p></p><p>多模态能力的升级也将为AIGC带来前所未有的产业机会，发布会上多模态能力升级后的产品——讯飞智作2.0也正式发布，无论是视频的后期处理还是创意视频生产，搭载了讯飞星火核心能力的讯飞智作2.0都能轻松搞定。</p><p></p><p>现场，刘聪使用讯飞智作进行虚拟人短视频生成、视频创作，“写一段黄山毛峰宣传文案，包括茶叶的产地、包装、色泽等特点”，刘聪又设定一位徽州古风女主播呈现，一个推介黄山毛峰的短视频就马上生成。</p><p></p><p>讯飞智作2.0可以进一步降低短视频制作的门槛，满足更多元的视频制作需求，推动AIGC产业的发展。</p><p></p><h3>发布教师助手、上线星火语伴2.0，星火打造每个人的AI助手</h3><p></p><p></p><p>“备考搭子”来了！星火语伴2.0上线口语模考沉浸式陪练</p><p></p><p>面向各学段学生、商务人士等广大英语学习爱好者的口语陪练老师，科大讯飞在6月9日发布了讯飞语伴APP。本次结合多模态能力，讯飞语伴2.0全新升级，除了能够进行主题对话、虚拟人对话，重点推出两大核心能力——口语模考和情景交流，可用AI实现真人式陪练。</p><p></p><p>刘聪现场和讯飞星火语伴2.0进行了一场代入感极强的口语模拟考试，他进入星火语伴的雅思考试入口，一位AI英语老师便跟他展开对话，对话结束后，系统马上给出准确度、流畅度、语法、词汇等维度的系统性评价，并推荐相关课程，通过及时反馈来强化学习结果。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/8a/3b/8a4ca245a8a6f6b7de7b3c3a77e40b3b.png\" /></p><p></p><p>据了解，目前口语模考功能已支持CET、雅思、托福等大型权威考试。</p><p></p><p>此外，8月15日，讯飞输入法“AI创作助手”正式开启内测。AI创作助手可在办公、学习、生活、社交等多个领域为用户提供场景化文案服务；还能对各类文案进行智能创作、润色，支持多种风格一键切换，提供更智能、便捷、有趣的输入体验。</p><p></p><p>设计教学活动、一键生成课件 ，星火要做教师好帮手</p><p></p><p>在“双减”前提下，全国的教育开始实现以核心素养的培养为重点的教育“三新”（即新课标、新教材、新高考）改革，这对老师提出了较大挑战，主要体现在单元教学的规划，教师的教育工具和个人的眼界知识面有限，教学活动过程中丰富资源也很难找到，需要6小时才能制作一个像样的单元课件，面对创新难、资源少、负担重的教学设计难题，如何应对“三新”改革带来的挑战？</p><p></p><p>科大讯飞全新发布的星火教师助手，支持教学设计的三大环节，创新规划单元教学设计、启发创设情境教学活动、一键生成互动教学课件，大大提升老师的备课效率。</p><p></p><p>刘聪现场演示了老师如何快速生成并修改教学设计，当他给出提示词“围绕‘时代品质、工匠精神’主题，生成高中语文必修（上）第二单元的教学设计”，一份逻辑清晰、细分成4个任务8个课时的教学设计马上生成，通过提示词就可以直接修改细节，还能一键生成参考课件PPT，为PPT配上风吹稻浪、小鸟鸣叫的背景音，并秒速总结输出思维导图，布置实践作业。</p><p></p><p>搭载了讯飞星火认知大模型的教师助手，通过数据驱动因材施教，用人工智能助力课堂创新，至今已服务全国超过2.5万所学校、超过1200万名师生。“星火教师助手帮助每个老师解放备课生产力，释放学生想象力”，刘庆峰说，星火教师助手带来的绝不仅仅是效率的提升，它可以帮助孩子获得超越老师自身知识面的素材库，帮助孩子释放想象力和带来更加丰富的课堂。</p><p></p><p>发布AI编程空间和AI创意画板 ，讯飞AI学习机再升级</p><p></p><p>讯飞星火发布以来，全面赋能C端硬件，今年“618”期间销售额同比增幅达125%。今年5月6日以来，讯飞AI学习机搭载星火发布的五大功能广受好评，包括TalkTalk口语对话、AI 作文助手、数学互动辅学、百科问答助手、亲子教育助手，讯飞AI学习机销量也实现同比增长180%。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/6d/86/6d4747dcb4d5ffc868c1d31dbb885a86.png\" /></p><p></p><p>在星火大模型2.0加持下，讯飞AI学习机此次也升级了两大功能，正式发布了AI编程空间和AI创意画板，更贴近新课标要求，全面赋能学科学习和素养拓展。</p><p></p><p>AI编程空间是学习机行业首款AI一对一智能编程助手，支持Python语言的学习、练习以及代码自动生成、修改、运行调试等功能。通过知识问答、练习题和代码诊断等步骤，在AI一对一互动的过程中，让孩子逐步爱上编程。</p><p></p><p>AI创意画板不仅可以看懂孩子画了什么，还能理解孩子想要表达的情感和意义，通过鼓励式探讨，不断提升孩子们的观察力、想象力、创造力和表达能力。</p><p></p><p>在星火大模型加持下，讯飞翻译机也为用户带来了全新的“AI口语”功能，使得用户能够在线体验中英口语对练功能。目前，“AI口语”支持73个不同场景的话题，包括出游、办公礼仪、自我介绍等等，覆盖绝大多数常用口语学习内容。</p><p></p><p>此外，今年星火大模型发布以来，在汽车、金融领域也取得丰富的成果，如在汽车场景推出了星火汽车助力和星火汽车APP，首款搭载星火的奇瑞汽车即将发布。下一步星火将赋能千行百业，助推产业升级。</p><p></p><h3>星火一体机重磅发布！科大讯飞牵手华为联合打造国产化算力底座</h3><p></p><p></p><p>今年7月6日，科大讯飞公布讯飞星火将与昇腾AI强强联合，打造基于中国自主创新的通用智能新底座。此次发布会，科大讯飞与华为强强联合发布星火一体机，让企业可以在国产自主创新的平台上，更方便、更自主、更安全可控地私有化部署大模型。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/be/dd/be59d63fe6cfb61cc1cb49f59b4e46dd.png\" /></p><p></p><p>刘庆峰说：“认知大模型深度赋能时代已经到来，健康发展急需构建安全可控保障。”他认为，认知大模型在行业深度应用有三方面的关键要素：</p><p></p><p>第一是安全可控，“通用人工智能改善民生、赋能社发展要根植在自主可控、算力安全平台上。”第二是场景驱动，“要能够在看得见摸得着的场景上，能够产生实实在在的应用价值，能够用统计数据来证明应用成效。”第三是专项训练，“构建私有化专属大模型，保护用户的专有数据和知识产权，并提升行业应用效果。”</p><p></p><p>在安全可控方面，刘庆峰介绍科大讯飞和华为已在联合攻关算力卡脖子的问题。科大讯飞拥有自研大模型训练平台，具备训练和数据闭环全流程设计、大模型训练和推理一体化设计、大规模异构算力兼容、支持混合云架构易拓展等优势，华为基于昇腾AI基础软硬件的高算力AI芯片、高性能算子库、多卡高速互联、分布式存储等优势，“我们正在跟华为一道打造面向超大规模大模型的训练国产算力的集群，形成集群化的优势。”</p><p></p><p>会上，讯飞星火和华为昇腾联合发布了星火一体机，该设备可提供对话开发、任务编排、插件执行、知识接入、提示工程等5种定制优化模式，以及办公、代码、客服、运维、营销、采购等10种以上即开即用的丰富场景包，支持3种模型尺寸供用户选择。刘庆峰表示，有了这些能力，就可以使得每一家企业、每一个行业、每一个学校、每个医院都有机会构建自己的专属大模型。目前，讯飞星火已完成的在金融、政务、汽车等领域的9个专属大模型的数据显示，在场景任务优化和私域知识增强等方面平均效果能够提升20%。</p><p></p><h3>进一步开放助手生态、插件市场、星火营，共建星火生态</h3><p></p><p></p><p>“中国人工智能的发展绝不是单个企业、单个科研院所使命，而是整个社会的机会，生态的发展决定了产业的繁荣。”刘庆峰发布会上表示，讯飞星火5月6日发布以来，100天间开发者数量同比增长282%，开发者行业分布中排名第一的是“企业服务”，“说明大模型真正开始赋能到刚需应用中。”</p><p></p><p>除了原有的能力开放、行业共建、双创赋能等举措，此次发布会上科大讯飞宣布将进一步开放助手生态、插件市场、星火营，与开发者团队一起构建通用人工智能新生态。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/c3/f9/c307ace507d146c0d43f31cc2dd8e9f9.png\" /></p><p></p><p>据悉，在讯飞星火中目前已有4109个助手开发者团队开发出7862款星火助手，“我们希望通过通用人工智能极大降低社会的创新创业门槛。”此外，讯飞星火营则将与高校联合培养通用人工智能领军人才，与开发者共建技术交流平台。</p><p></p><p>今年5月6日首次发布讯飞星火大模型时，科大讯飞便公布了今年的升级里程碑，随后如期在6月9日、8月15日分别发布的讯飞星火V1.5和V2.0，今年10月24日将全面对标ChatGPT，中文超越、英文相当，明年对标GPT-4。</p><p></p><p>为什么总能如约而至？刘庆峰说，这是科大讯飞过去24年创业过程中的技术积淀，星火的每一行代码、每一个算法模块都是自研的；还有成建制的团队，和华为这样的深度合作伙伴。“最重要的是一定要有不完成任务绝不服输的精神，要做就永争第一的坚持。”</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/18/69/18677c0e1316815a6c0e384b7a0ec269.png\" /></p><p></p><p>“关于未来，无论你觉得行还是不行，你终将都是对的！”刘庆峰说，要全力以赴、不遗余力、充满激情、充满斗志的去争取，“有‘最终一定行’的精神指引，借助这一波通用人工智能的机会，我们打造每个人的AI助手、释放每个人无限可能的梦想，就一定能够成为现实。”</p>",
    "publish_time": "2023-08-16 07:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "中国开源生态系列图谱——前端领域",
    "url": "https://www.infoq.cn/article/5ESYJ3VP3FrJoV8beRHN",
    "summary": "<p></p><h3>研究背景</h3><p></p><p>2022 年 8 月，InfoQ 研究中心推出《中国开源发展研究分析 2022》<a href=\"http://www.infoq.cn/minibook/DTAg4l8piWHrBGfU3der\"></a>\"。报告中对中国开源的宏观发展的背景、目前取得的成绩、整体发展的特征进行了分析。同时也推出了基于 InfoQ 研究中心研究成果的 InfoQ 开源项目指数。但是因为时间等因素，《中国开源发展研究分析 2022》<a href=\"http://www.infoq.cn/minibook/DTAg4l8piWHrBGfU3der\"></a>\"聚焦研究了中国 TOP30 开源项目。我们深知，中国开源发展百花齐放，仍有大量的项目深植于各技术领域中，并且取得了亮眼的成绩。另外，不同的技术领域开源也具有各自独特的特征。</p><p></p><p>所以，InfoQ 研究中心策划启动了《中国开源生态图谱系列研究》工作，技术领域涉及操作系统、数据库、云原生、大数据、前端、架构等。希望系列研究能够帮助关注中国开源世界的朋友绘制更为完整的开源全景图谱。通过对不同技术领域的研究分析，帮助读者获得更为具体的开源领域洞察。</p><p></p><p>此篇是《中国开源生态图谱系列研究》的第五篇，聚焦在前端领域，通过统计目前的前端开源项目，并进行分类，同时结合开源基金会、开源产业联盟等生态，完整构成中国前端开源的生态图谱。同时，洞察前端开源领域面临的三大挑战与三大发展趋势，供广大开发者和开源社区参考。随后，通过在《中国开源发展研究分析 2022》<a href=\"http://www.infoq.cn/minibook/DTAg4l8piWHrBGfU3der\"></a>\"中使用的 InfoQ 开源项目指数，分析和评价现有前端开源项目。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/c1/22/c127083a740bdbd09bb6ccc4070e3022.png\" /></p><p></p><p>截至目前，InfoQ 研究中心已经发布了 5 个领域的开源生态图谱，覆盖操作系统领域<a href=\"http://www.infoq.cn/minibook/ARa5HwDdOveaDKavLSc3\"></a>\"、数据库领域<a href=\"http://www.infoq.cn/minibook/pPz0K3aDcvO6pvtDBEq6\"></a>\"、人工智能领域<a href=\"http://www.infoq.cn/minibook/3ElKmiQIzsFC8ThhFfst\"></a>\"、云原生领域<a href=\"http://www.infoq.cn/minibook/zdDoaDUkCGiLmWcPBYIz\"></a>\"、前端领域，并且发布了涵盖 931 个中国开源项目的《中国开源生态图谱 2023》<a href=\"http://www.infoq.cn/minibook/9j4NSEEh2JGJAUVdQGGu\"></a>\"。欢迎下载和持续关注。</p><p></p><h3>目录</h3><p></p><p>生态图谱解读生态图谱项目洞察</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9b/9b56275152f561c6960a1ce02be4ec98.png\" /></p><p>扫/码/下/载</p>",
    "publish_time": "2023-08-16 11:23:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "探秘B站多媒体实验室：B站视频背后的AI黑科技是如何炼成的？",
    "url": "https://www.infoq.cn/article/EwMBkITYMgWM58jbZqBV",
    "summary": "<p>快速发展的AI技术正在为千行百业带来越来越多可能性，以多媒体领域为例，AI目前已经深层渗透到了内容生产、识别理解、处理增强、语音、检索、安全等诸多方面。在B站，不管你是看视频的用户还是发布作品的UP主，AI在你的使用过程中几乎可以说无处不在。比如，你在B站上刷视频推荐瀑布流的时候，视频推荐页卡片封面的高能看点GIF动画，可能就是由大语言模型生产出来的；比如，已经有很多UP主在使用开箱即用的AIGC工具辅助内容创作；再比如，在用户所看到的视频画面里，利用AI算法嵌入了不可见的数字水印信息，以便于后续平台对视频归属权进行快速鉴别，等等。</p><p>&nbsp;</p><p>而上述这些AI应用探索，都离不开B站多媒体实验室的工作。B站多媒体实验室是B站多媒体技术部的核心算法研发部门，除了立足于点直播转码核心算法的研发，也承担了一系列涉及视频内容生产、结构化、版权保护等环节的技术研究与落地，以及紧跟潮流的前沿热点追踪与预研工作。</p><p>&nbsp;</p><p>在9月3-5日即将召开的QCon 北京 2023上，B 站多媒体实验室算法负责人成超将带来以<a href=\"https://qcon.infoq.cn/202309/beijing/presentation/5415\">《B 站前沿多媒体技术保障用户体验与创作权益》</a>\"为主题的演讲分享。会前，InfoQ对成超老师进行了专访，提前揭秘B站多媒体实验室的重点工作方向，以及B站如何将LLM等前沿技术与多媒体业务相结合的落地探索。</p><p>&nbsp;</p><p>以下为访谈实录，经InfoQ编辑整理：</p><p>&nbsp;</p><p>InfoQ：很荣幸有机会采访您，能否请您先介绍一下您在计算机视觉及AI图像领域的从业经历？您是在什么时候、因为什么样的机缘加入B站多媒体实验室的？</p><p>&nbsp;</p><p>成超：在加入B站之前我一直在云厂商从事AI视频分析、处理、增强等方向的工作。2021年B站多媒体技术部成立了自己的算法研发部门，在紧贴业务一线的地方探索多媒体AI算法的更多可能性。在此契机下我加入了B站，同时也面临着toB到toC转变的挑战。</p><p>&nbsp;</p><p></p><h2>B站多媒体实验室的过去和现在</h2><p></p><p>&nbsp;</p><p>InfoQ：能否进一步介绍下B站多媒体实验室在公司内部的定位，以及它的发展历程？</p><p>&nbsp;</p><p>成超：B站多媒体实验室是B站多媒体技术部的核心算法研发部门，目前主要从事于编码器、多媒体算法，以及前沿技术在点直播体系下落地的研发。多媒体实验室的前身是编码器组与算法组，在部门早期阶段这两个组曾是独立运行的：编码器组主要负责B站转码架构中最核心的BILIAVC、BILIHEVC、BILIAV1，及当前重点投入的BILIVVC编码器的研发；算法组主要负责视频画质增强，如超分、超帧等处理算法的研发。</p><p>&nbsp;</p><p>随着多媒体技术部所负责的点直播转码架构的不断演进，我们发现AI处理+编码结合在一起能够取得更大的想象空间。例如通过AI算法对视频画面进行重构然后编码，能够比纯编码在取得相同画质结果的条件下节省10~15%的码率；又例如通过VQA等基于数据驱动的无参质量评价，能够一定程度替代PSNR等有参且不基于人眼感知的评价标准，为编码器的迭代指引更科学的优化方向。</p><p>&nbsp;</p><p>因此在2023年年初，我们从组织架构层面将这两个组合并成立了多媒体实验室，合并之后的多媒体实验室除了立足于点直播转码核心算法的研发之外，还需要承担一系列涉及视频内容生产、结构化、版权保护等环节的技术研究与落地，以及紧跟潮流的前沿热点追踪与预研。</p><p></p><p>InfoQ：根据您从业这几年的观察，AI技术在多媒体领域都有哪些应用、又带来了哪些重要变化？可否列举一些代表性案例进行说明。</p><p>&nbsp;</p><p>成超：这个问题比较宏大，AI目前已经深层渗透到了内容生产、识别理解、处理增强、语音、检索、安全等诸多领域，我想以内容生产为重点来谈谈目前AI所带来的显著变化与趋势。</p><p>&nbsp;</p><p>AI对内容生产的促进成果是非常令人兴奋的，我们很欣喜地看到，B站上很多UP主都已经在用开箱即用的AIGC工具辅助内容创作了。例如最近某个专注于神话志怪题材的UP主为了讲解封神榜的故事背景，采用当下流行的文生图平台制作了很多符合封神故事风格的人物、鬼怪设定图并应用在了视频中，这些图片质量很高，丝毫不亚于一些专业画师的创作水准。如果没有此类技术，观众大概只能凭借UP主的语音文字讲解来脑补那些奇幻角色造型，无疑提高了受众门槛，也降低了观看体验。</p><p>&nbsp;</p><p>再举一个作为平台方应用的例子，我们正在采用AI换脸制作个性化的直播虚拟礼物。对不同主播的高能用户我们会发送一些定制化礼物。传统的虚拟礼物生产流程是，首先创建一个虚拟人并生成一段统一的CG，然后对不同主播的人脸进行建模并替换掉虚拟人的面部，这样呈现到用户端的效果就是，他关注的主播在一个酷炫的场景里面做出一连串复杂的动作造型。而现在采用AI换脸，我们能够整体替换掉主播人脸建模这一生产环节，并且AI换脸所渲染出来的微表情、妆容甚至比建模还具有真实感。完整的个性化礼物制作周期与成本也被极大地压缩，在同样资源条件下，我们能够为用户提供更多更有意思的玩法和内容。</p><p>&nbsp;</p><p>InfoQ：我们知道B站一直有在积极探索新技术在多媒体领域的应用，比如2018年的<a href=\"https://www.infoq.cn/article/2018/08/bili-bili-mask-barrage\">蒙版弹幕</a>\"，那么当前B站多媒体实验室的主要研究方向包括哪些？为什么选择将这些方向作为重点？</p><p>&nbsp;</p><p>成超：B站多媒体实验室的主要研发线可以归纳为以下几个方向：</p><p>内容生产：包括端云协同玩法的云端算法服务部分、视频虚拟化玩法的探索；转码处理：包括点直播视频编解码（BILIAVC/BILIHEVC/BILIAV1/BILIVVC）、BiliVision画质矩阵、窄带高清智能转码；内容管理：包括视频结构化、BiliVQA质量评价体系、数字版权保护。</p><p></p><p>B站的视频数据从上传，到转码处理、分发、存储的完整生命周期，都是在多媒体技术部完成的，因而多媒体实验室的主要研发方向也都是基于点直播技术体系的基本算法需求制定的。核心出发点只有三个：体验、增长、成本。体验和成本自不必说，编码与画质是我们最核心的研发方向，也是B站作为一个视频平台所应当具备的硬实力。对于增长而言，我们相信视频数据在点直播技术体系中流转的过程也是能够为创作者和用户产生价值的，如通过为恰当的内容引入恰当的元素能够提升创作者收益、为观众带来更新颖的玩法；又例如保障创作者权益从而维护并激发创作热情，这都能为我们生态的建设与持续的增长带来新动能。</p><p></p><h2>B站多媒体前沿技术探索</h2><p></p><p>&nbsp;</p><p>InfoQ：您的演讲介绍中提到B站建立了一套覆盖云/边/端、点/直播的画质增强链路，能否展开解释一下这套链路是如何运作的，以及给用户体验带来的改进？</p><p>&nbsp;</p><p>成超：BiliVQA会通过无参质量评价以对视频画质进行评估，根据评估结果驱动BiliVision画质矩阵对视频进行增强处理。原始画质较低的内容以去噪增强为主、高播非4K内容以4K超分为主、动态收益较高的内容以超帧为主、优质高潜内容进行完整的超分+超帧+HDR处理等。结合无参质量评价与一套严密的运营逻辑，能够让任何一部片源进入它最适合的增强链路。</p><p>&nbsp;</p><p>我们在底层采用了一套名为BVT的推理框架完成这种可配置的、自定义的增强流程：它把每一个增强算法节点化，像搭积木一样把各种算法堆叠在一起。</p><p>&nbsp;</p><p>BiliVision从原子能力层面出发已覆盖了超分、超帧、增强、HDR/调色等主要AI画质增强手段；从业务层面出发已覆盖点、直播，满足大规模部署的性能需求；物理上充分利用多阶算力，点播增强主要基于云端GPU，直播增强放在了更靠近用户的边缘GPU，而在用户端我们也部署了更适合移动端/PC的轻量增强算法，以实时提升那些无法被云端增强覆盖到的片源的观看画质。高画质在当下的网络环境中已经是用户刚需，但创作端能力与基础设施的完善还需要时间，在这个gap中AI画质提升是最优解。</p><p>&nbsp;</p><p>InfoQ：用户对信息流的汲取效率，应该如何理解？传统的视频信息流推荐存在哪些问题和不足？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p><p>&nbsp;</p><p>成超：用户观看视频一般有两种模式，一是通过关注列表，二是通过推荐列表。用户刷推荐瀑布流的过程本质是一个对信息筛选甄别的过程，需要在短时间内仅仅依靠封面、标题、时长、点赞数/观看数等信息判断是否对某些视频感兴趣。如果用户通过推荐列表对某个视频产生兴趣，会形成一次点击的转化。进入视频详情页后，用户可能发现内容本身并不像封面那样有趣而跳出观看，从而影响视频的平均观看时长以及完播率，也浪费了用户的时间。所谓的信息流汲取效率就体现在这里，即用户对真正感兴趣内容（无论兴趣是发生在观看前还是观看后）的有效观看时间除以用户使用App的时间。</p><p>&nbsp;</p><p>传统模式有以下不足：</p><p>一是部分视频为了快速吸引流量，采用了大量劲爆性、诱导性的封面标题，并且可能伴随视频内容货不对板的标题党问题，导致用户点进去视频后会有一种上当受骗的感觉。传统模式无法提供更充分的信息让用户对潜在感兴趣的内容进行有效甄别，自然导致了信息汲取效率无法提升。二是B站现在全面将主要增长目标从视频播放数转向到视频观看时长，鼓励优质长视频的创作。但客观来讲基于封面+标题的推荐列表是不利于长视频的点击率转化的，其能传达的有限信息显然更适用于概括短视频内容。众所周知B站的特色在于广大UP主创作的UGC/PUGV长视频，这类视频仅仅依靠封面贴片很难传情达意。</p><p>&nbsp;</p><p>InfoQ：关于大语言模型在用户信息流汲取效率方面的应用，您能否分享一些具体的案例或者效果？</p><p>&nbsp;</p><p>成超：正如一部电影在上映前会发布预告片来吸引潜在观影者，预告片对整部电影中的精彩看点做了密集总结并简要梳理了剧情梗概，这样观众就能够通过预告片未看先知电影的大致内容。</p><p>&nbsp;</p><p>上一个问题提到，传统推荐页呈现的信息很难真实且精炼地反映一段长视频的精华。因此，B站在推荐页卡片中引入了动画封面的模式，即通过一段包含视频内高能看点的GIF动画展现视频精彩时刻。高能GIF起到的正是类似于电影预告片的作用，这种方式对于点击转化率的提升非常大。</p><p>&nbsp;</p><p>但它的问题也很明显：传统方式生产高能看点GIF需要人工打点，效率较低，并且较难处理一些需要结合画面精彩程度、专业性强内容、外文内容进行综合推荐的场景。这个时候大语言模型就具备用武之地了。大语言模型对于整体内容理解、抽象、概括的能力较强，并且涉猎的知识面也具备广度；同时结合多语言的ASR、OCR，及视觉层面的美学评估、动态评估等技术可以形成一套非常完整、高效的自动化高能看点提取方案。我们将大语言模型生产出来的高能看点GIF投入到线上发现，它对转化率的提升比人工打点方式还要高，并且效率较人工有巨大的规模量产优势。</p><p>&nbsp;</p><p>此外，大语言模型具备重构视频拆条技术体系的潜力，基于大语言模型能够更高效更高质量地完成例如视频切片、视频分章节等任务。只有真正理解了内容，才能帮助我们的用户更高效地接收信息。</p><p>&nbsp;</p><p>InfoQ：当前在视频创作者权益保障这方面，行业内存在哪些痛点和挑战？B站多媒体实验室采取了哪些新的策略或技术手段来解决上述问题？</p><p>&nbsp;</p><p>成超：国内视频行业对于UGC版权的保护机制非常薄弱，甚至缺失。盗链搬运、恶意剪辑、洗稿等行为难以避免，打击了创作者尤其是PUGV创作者的创作热情，并侵犯了他们的创作权益。行业内目前已经拥有一些版权保护方案，例如视频指纹和DRM。但这些方案也存在一些问题，视频指纹需要建立庞大的指纹库，每条视频进来后要进行指纹提取和撞库操作，成本较高，且随着内容数量的增长，视频指纹对原始稿件的召回概率也会变低；DRM虽然能够在源头防止视频内容被记录下来，却也在需要开放二创权限的情况下变成了限制。</p><p>&nbsp;</p><p>多媒体实验室目前采用数字水印的方法来克服以上问题，利用算法在视频画面中嵌入不可见的信息，这些信息包含了版权标识符、视频ID、时间戳等。通过对视频文件进行解码，如果其包含了水印信息则能被正确解码，通过这些信息我们能够对视频的归属权进行快速鉴别，并能够定位到它在视频平台中具体的源头、时间点位置。它不需要像视频指纹一样建库，且版权信息是跟着码流走的，能够抵抗二次转码、裁剪、贴图等二创过程引入的攻击类型。最重要的是，我们的方案具备大规模落地能力，这大大增强了数字水印系统能够覆盖到的稿件数量。</p><p>&nbsp;</p><p>InfoQ：关于B 站多媒体实验室前沿技术落地的经验和思考，您能不能选择其中一个关键点提前分享给大家？也可以作为您本次QCon大会演讲的一个小预告。</p><p>&nbsp;</p><p>成超：首先感谢大家的关注，前面我们其实已经提前透露了QCon 北京 2023上会分享的基于LLM的视频拆条方案，以及数字水印系统的部分内容。此外，我们还可以预告一个在为UP主尤其是中小UP主提升创作收益方向上，正在探索的一项有趣的技术，叫做VPP（Virtual Product Placement）虚拟广告植入。它能够在视频内容中无感的植入广告等元素，与传统贴片广告不同之处在于，它与视频内容本身是融为一体的，例如将视频中张贴在背景墙上的一张海报替换为平面广告。视觉效果既不违和，又增加了商业曝光，也不影响视频本身内容或者主旨表达的连贯性。期待能在大会上与同行专家们多多交流，谢谢大家。</p><p></p><h4>采访嘉宾介绍：</h4><p></p><p></p><p>成超，B 站 多媒体实验室算法负责人。毕业于清华大学电子系，从事计算机视觉及 AI 图像领域的研究与应用，是B站多媒体实验室算法负责人，面向视频质量体系、AI 智能化生产，及基于机器学习感知编码等业务方向。</p><p></p><p>QCon 北京 2023即将在9月3-5日在北京·富力万丽酒店召开，此次大会策划了大前端融合提效、大模型应用落地、面向 AI 的存储、AIGC 浪潮下的研发效能提升、LLMOps、异构算力、微服务架构治理、业务安全技术、构建未来软件的编程语言、FinOps 等近30个精彩专题。会上，成超老师将围绕<a href=\"https://qcon.infoq.cn/202309/beijing/presentation/5415\">《B 站前沿多媒体技术保障用户体验与创作权益》</a>\"主题做进一步分享，详述B站前沿技术探索和实践细节，为参会者带来一手实战经验与深层思考，敬请期待~</p><p>&nbsp;</p><p>现在购票即可享受 9 折优惠，立减 ¥880。咨询购票可联系票务经理 18514549229（微信同手机号）。点击<a href=\"https://qcon.infoq.cn/202309/beijing/track?utm_source=wechat&amp;utm_medium=infoqart2&amp;utm_campaign=9&amp;utm_content=chengchao\">链接</a>\"即可查看全部专题，期待与各位开发者现场交流。 &nbsp;</p>",
    "publish_time": "2023-08-16 14:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "升级国赛！第三届OceanBase数据库大赛启动报名",
    "url": "https://www.infoq.cn/article/YG9ycc9NVoKNPcJoU2ei",
    "summary": "<p>近日，第三届<a href=\"https://xie.infoq.cn/article/4c220d4c8f155efeddd84882c\">OceanBase数据库大赛</a>\"启动报名。本届大赛进一步升级为全国大学生计算机系统能力大赛，由系统能力培养研究专家组发起，全国高等学校计算机教育研究会、系统能力培养研究项目发起高校主办，OceanBase承办，旨在培养和发现计算机底层核心技术的后备人才。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/68/68720914654f445bfe34a9e0dd651997.png\" /></p><p></p><p><a href=\"https://xie.infoq.cn/article/8da6bf636faa6ffc606df313e\">OceanBase</a>\"是蚂蚁集团旗下的自研原生<a href=\"https://xie.infoq.cn/article/e29b62169027269118f763e4a\">分布式数据库</a>\"，曾在2019年、2021年接连打破世界纪录，并连续10年稳定支撑双11。从2021年起，OceanBase已连续举办两届数据库大赛，有近300所高校5千余名学生、数据库开发者参赛，大赛服务国家人才培养战略，以赛促学、以赛促教，开创了国内数据库内核开发人才培养的新模式。</p><p>&nbsp;</p><p>本届大赛分为初赛和决赛两个阶段。初赛阶段，参赛选手将基于具备基础功能的项目实战型数据库MiniOB系统进行开发，学习实现部分数据库功能。决赛阶段，参赛选手将在真实的企业级开源OceanBase内核上做更多数据库功能的探索，实现内核研发能力的进阶。此外，大赛提供40万奖金，冠亚季军队伍可获得实习绿色通道，前20强队伍都可以获得国家级竞赛证书。</p><p>&nbsp;</p><p>为保证大赛评审的公平公正，同时更好地指导学生，大赛评委团由多位学术界与工业界专家共同组成，包括中国人民大学明理书院院长杜小勇、北京航空航天大学计算机学院副院长高小鹏、Bilibili技术委员会主席毛剑、OceanBase CTO杨传辉等。</p><p>&nbsp;</p><p>全国大学生计算机系统能力大赛组委会专家、北京航空航天大学计算机学院副院长高小鹏教授表示，前两届大赛的参赛队伍思路开阔，能从各个角度深挖优化方案，证明了大赛的必要性与合理性，也证明了大赛是培育和发现数据库人才的平台，希望参赛选手能通过参赛以赛促学，系统学习理论知识、提升开发能力、积累企业级的工程经验，为未来打好基础。</p><p>&nbsp;</p><p>即日起，选手可通过全国大学生计算机系统能力大赛官网、<a href=\"https://open.oceanbase.com/competition\">OceanBase社区官网报名</a>\"，报名截止2023年10月25日。</p><p>&nbsp;</p><p>数据库，是基础软件“皇冠上的明珠”。数据库人才短缺是全球性问题，而国内比国外对这一问题的感触更深。越来越多企业联合高校搭建竞技平台，帮助产业培养人才，有望帮助年轻人树立信念、获得实践土壤，成为推动国产数据库发展的下一代。</p>",
    "publish_time": "2023-08-16 14:23:04",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "中国企业研发高效能白皮书（合集）",
    "url": "https://www.infoq.cn/article/DER7b8ez33OLpvahRSrG",
    "summary": "<p></p><h3>研究背景</h3><p></p><p>近年来，中国企业研发正在从粗放型走向精益型，研发工作的“高效能”成为几乎每个研发团队的共同追求。</p><p></p><p>中国软件服务产业也在近 5 到 10 年中得到了飞速发展，技术服务的边界不断拓展，赋能高效研发的产品层出不穷，适合中国研发环境的技术服务体系在不断完善。从结果上看，中国企业正在高效能研发的路径上快速前进。</p><p></p><p>本份报告以中国高效能研发企业为研究对象，尝试解读市场中具有代表性的高效能研发解决方案。本次报告由五个篇章组成，包括 CI/CD、ChatOps、企业级软件架构、Code Review、价值流管理与研发效能管理等五大主题。研究小组期待可以通过研究，帮助中国企业研发团队获得高效能研发新知。</p><p></p><h3>目录</h3><p></p><p></p><h4>CI/CD 篇</h4><p></p><p>CI/CD 概念和背景介绍CI/CD 行业发展概况极狐 GitLab CI/CD，带您开启研发高效能</p><p></p><h4>ChatOps 篇</h4><p></p><p>ChatOps 概念和背景介绍ChatOps 行业发展概况极狐 GitLab ChatOps</p><p></p><h4>企业级软件架构篇</h4><p></p><p>关于企业级软件架构常见的企业级软件架构方案极狐 GitLab 企业级软件架构极狐 GitLab 企业级软件架构最佳实践企业级软件架构市场发展趋势展望</p><p></p><h4>Code Review 篇</h4><p></p><p>Code Review 的定义与背景Code Review 发展现状Code Review 最佳实践</p><p></p><h4>从价值流管理到研发效能管理篇</h4><p></p><p>价值流管理定义与背景价值流管理行业发展现状极狐 GitLab 研发效能管理</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ac/acfb3de25ba325cec7a5531532dbcf21.png\" /></p><p>扫/码/下/载</p>",
    "publish_time": "2023-08-16 14:51:41",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从F5到通明智云，这位“探险家”如何突破应用交付创新边界？",
    "url": "https://www.infoq.cn/article/v3fU1OOujPUhhiSUQqjs",
    "summary": "<p>从深耕了22年且在应用交付领域全球领先的F5离开而选择加入一家成立不到2年的初创公司，这似乎是一个冒险的决定。然而冯勇就像一位“探险家”踏出了这一步并不断突破国内应用交付领域的创新边界。</p><p>&nbsp;</p><p>冯勇是应用交付和负载均衡行业公认的“大神”。这与他资深的行业背景密不可分，2001年，他加入了F5，并在同年与张毅强（F5中国区总经理）、吴静涛（时任F5中国区技术经理）、吴若松（时任F5北方区销售经理）等7人，组成了F5中国的七人初始团队。正式以厂商的身份把负载均衡市场引入到中国，在此后的22年里，他作为F5中国区首席架构师一直深耕在应用交付领域并主导了中国应用交付、负载均衡技术路线的演进。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/d1/36/d1e5a8346e443314byy29ed81d55b536.png\" /></p><p></p><p></p><h3>从F5到通明智云，为何做了这个看似”冒险“的决定？</h3><p></p><p>&nbsp;</p><p>老朋友的召唤和对应用交付领域的共同热爱，是冯勇加入通明智云的首要原因。在最初的7人团队中，吴若松和吴静涛如今是通明智云的总经理和COO。“我们深耕负载均衡市场超过20年，有着共同的热爱，如今老朋友再重聚，是契机也是意料之中。”冯勇说道。</p><p>&nbsp;</p><p>其次，大客户对通明智云的认可让冯勇有了下定决心的底气。在2018年之前，绝大多数国内厂商只能满足基本的负载均衡功能，需要3-5年才接近实现80%F5的功能。然而近几年国内企业追赶的步伐加快，通明智云就是其中之一。从2022年6月，工商银行开始针对通明湖产品进行功能性测试，仅仅一年时间就已经满足了客户所有的上线功能要求，逐一测试通过了60多项详细应用测试项目。这让工商银行对国内企业的技术发展和产品功能充满信心，也让冯勇心中增加了一份底气。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/54/32/54cda45510f8134eyy30d8716dafa832.png\" /></p><p>通明智云技术副总经理冯勇</p><p>&nbsp;</p><p>此外，近年来中国IT需求逐步引领全球。彼时担任F5架构师的冯勇深感中美技术路线的不一致，是否可以找到快速满足中国本地客户需求的方法？于是，F5与神州数码合作，打造了神州云科容翼系列产品，而通明湖系列则是完全自主研发的信创产品，真正为了满足中国客户需求而研发的，与客户一起推进现代应用发展。这是冯勇加入通明智云的第三个原因。</p><p>&nbsp;</p><p>从F5到通明智云，冯勇表示，“通明智云与F5的产品理念一脉相承。”&nbsp;</p><p></p><h3>双轨超高可用架构，保证核心应用的可持续性</h3><p></p><p>&nbsp;</p><p>信创背景下，各行业均加快应用的国产化。不过，伴随着信创发展的深入，也开始面临新的挑战。信创改造从办公网推进到核心区时，会遇到两个最大的问题：&nbsp;</p><p></p><p>第一，信创应用的稳定性、可靠性问题。面对核心应用99.999%的可用性要求和应用可持续性要求，很多客户缺乏信心。这就需要应用交付架构来帮助客户重构产品，包括实现故障的自动发现，在故障影响业务之前进行自动切换，并提供客户故障出逃计划，从而保证信创核心应用的超高可用性。&nbsp;</p><p></p><p>第二，当客户将核心应用从传统应用切换到信创区时，如何能够保证业务的平滑迁移？是否能将一些特定客户逐步迁移到信创区？目前很多信创核心业务都是整体切换，这就导致遇到问题不得不全部再回退。因为要保证业务的持续性，所以没有足够的时间、足够的测试以及实时手段来判断故障原因，给核心应用的信创改造带来巨大挑战。&nbsp;</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/29/01/29083718b7512887826a3440e293fb01.png\" /></p><p></p><p>双轨超高可用架构恰好能解决这些挑战。冯勇表示，“双轨超高可用架构能够提供统一的技术支持能力，通过统一的配置界面、统一的管理平台、统一的大数据采集分析，以及统一的服务平台等关键要素，来保证企业技术迭代创新过程中的应用可持续性和技术选型灵活性，尤其是实现核心信创的可靠过渡，满足信创应用可持续性的高要求。”</p><p>&nbsp;</p><p>双轨超高可用架构在双活数据中心的分区调度基础上，增加信创域和非信创域的分域调度，实行信创域与传统域应用全量部署，使双中心运营变为双中心四区域并行运行，互为多活，将“0到1”的单轨建设道路变为分区分域协同的多活双轨超高可用架构。帮助客户在新架构下，保障“信创”的同时解决性能瓶颈，提升稳定性，保证应用可持续性，最终实现信创区域和非信创区域的平滑过渡，完成国产化替代目标。</p><p>&nbsp;</p><p></p><h3>应用可持续性、应用可观测性、云原生应用引擎，是趋势也是目标</h3><p></p><p>&nbsp;</p><p>冯勇认为“就未来技术趋势来看，通明智云有三个大方向：应用可持续性、应用可观测性、云原生应用引擎”。</p><p>&nbsp;</p><p>Gartner 2023年十大技术趋势之一就是应用可持续性。应用可持续性关注的是应用的形态变化以及计算资源调度时能够保持应用服务的可持续性。从传统应用到自主信创平台，如何保持核心业务的可持续性是必须解决的问题。通明智云希望通过信创应用交付架构，实现应用从传统体系的国外平台到国产平台的平滑转换，帮助客户自动发现故障、屏蔽故障以提升国产应用的可用性。</p><p>&nbsp;</p><p>应用可观测性方面，要想真正保证应用的高可用性和可持续性，就必须要观测到每个应用的状态。这一点在中国尤其突出，我们在手机应用、物联网、车联网终端App的开发突飞猛进，尤其是游戏、短视频、社交、媒体App领先全球。基于此，在保证应用可持续性的基础上，通明智云希望能够帮助客户实现端到端的应用可观测性，确保能够真正掌握应用的运营状态。</p><p>&nbsp;</p><p>同时，通明智云正在致力于打造中国自主创新的现代应用引擎。云原生应用引擎OpenNJet项目正式成为开放原子开源基金会的孵化期项目，在Gitee、AtomGit代码托管平台建立了代码仓库。未来，OpenNJet将围绕五个方面展开工作，一是推广OpenNJet应用引擎，吸引开发者和企业用户共建和应用；二是深耕OpenNJet应用引擎技术研发和迭代；三是保障技术安全底线；四是积极谋划OpenNJet未来的产业发展；五是秉持开源开放的心态，积极回溯上游，推动云原生产业上下游生态共建。</p><p>&nbsp;</p><p>从应用可持续到应用可观测性进而发展成为云原生现代应用引擎，让客户真正掌握应用运营状态，这是通明智云一直在努力的方向。我们看到，通明智云在国内应用交付领域始终追求创新突破，致力于为企业创造更大价值。</p>",
    "publish_time": "2023-08-16 15:42:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "字节跳动算法专家张树波确认出席QCon北京，分享大模型助力智能单测生成",
    "url": "https://www.infoq.cn/article/NCSuki067wv7JxzmmYhe",
    "summary": "<p>9 月 3 日 - 5 日，在 <a href=\"https://qcon.infoq.cn/202309/beijing/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=0816&amp;utm_content=zhangshubo\">QCon 全球软件开发大会（北京站）</a>\"上，字节跳动算法专家张树波将发表题为《大模型助力智能单测生成》主题分享，介绍传统特智能单测生成，要依赖静态分析、动态分析等工具，对不同的语言需要重新适配。随着模型参数规模的提升，模型的代码理解、代码生成能力也大幅提升，使用模型端到端的生成单元测试，可以低成本地将单元测试覆盖到多种编程语言。</p><p></p><p><a href=\"https://qcon.infoq.cn/202309/beijing/presentation/5380?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=0816&amp;utm_content=zhangshubo\">张树波</a>\"，清华大学硕士毕业，先后就职于 vivo、字节跳动。从事 NLP 算法多年，在智能单测、智能客服、语音助手等业务场景有丰富的落地经验。</p><p></p><p>相信通过张树波的分享，你将了解到如何评估通用大模型的单测生成能力，如何提升大模型单测生成效果，大模型落地工程实践、应用落地介绍与未来展望。你会收获到大模型在单测生成领域存在的问题、如何缓解，以及大模型在单测生成领域的应用实践。</p><p></p><p>除上述专题外，QCon 北京还将围绕 <a href=\"https://qcon.infoq.cn/202309/beijing/track/1556?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">FinOps&nbsp;落地</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1570?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">云原生</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1567?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">AIGC&nbsp;浪潮下的研发效能提升</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1558?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">业务安全技术</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1552?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">面向&nbsp;AI&nbsp;的存储</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1557?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">从&nbsp;BI&nbsp;到&nbsp;BI+AI，新计算范式下的大数据平台</a>\"等进行分享。</p><p></p><p>近 100 名讲师、近 30 个精彩专题、8 种交流活动，QCon 北京 2023，相约 9 月！现在购票，享 9 折特惠，立省 ¥880！咨询购票请联系 18514549229（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/33/33cbbbf20baa8b2a18db4f0681f159aa.jpeg\" /></p><p></p>",
    "publish_time": "2023-08-16 16:20:15",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "腾讯云MaaS最新升级：上架20多个主流模型，支持开发者一键调用",
    "url": "https://www.infoq.cn/article/pL2hKmgWdkGN42puH0qw",
    "summary": "<p>&nbsp;如何快速、低成本将AI大模型技术应用到实际业务场景，是新一轮人工智能技术浪潮中，保持核心竞争力的关键，也是国内越来越多的企业关切、探索方向。</p><p>&nbsp;</p><p>8月16日，由工业和信息化部、广东省人民政府共同主办的“2023中国数字经济创新发展大会”在广东省汕头市开幕。腾讯集团高级执行副总裁、云与智慧产业事业群CEO汤道生在大会上宣布了腾讯云MaaS最新升级。腾讯云TI平台已经全面接入Llama 2、Falcon、Dolly、Vicuna、Bloom、Alpaca等20多个主流模型，且支持系列模型的直接部署调用、应用流程简单、可全程低代码操作，成为国内第一批上架和支持开源模型的大模型厂商。腾讯云对这些模型进行了推理测试验证，从市场反馈、推理测试效果等角度进行了综合评估，确保模型可用性、易用性，可覆盖智能对话、文本生成、写作等多个不同场景，为企业、开发者提供了多种模型选择。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e3/e3e8dc28534443739838c469ed0280a9.png\" /></p><p></p><p>&nbsp;为了帮助企业客户解决成本、数据、安全等大模型实际落地难题，今年6月，腾讯云正式发布了行业大模型解决方案，依托腾讯云TI平台打造行业大模型精选商店，为企业客户提供涵盖模型预训练、模型精调、智能应用开发等一站式行业大模型解决方案。</p><p>&nbsp;</p><p>在TI平台内置的高质量行业大模型基础上，企业加入自己的场景数据，就可以快速生成自己的专属模型；同时，也可根据自身业务场景需求，“量体裁衣、按需定制”不同参数、不同规格的模型服务。</p><p>&nbsp;</p><p>目前，腾讯云已经为金融、文旅、传媒、政务、教育等10大行业提供了超过50个大模型解决方案。在文旅场景，国内某头部在线旅游公司利用腾讯云自然语言模型实现了个性化的定制旅行服务。用户只需提供自己的偏好、预算和大致路线，即可生成详细的旅行方案，并提前安排好每天的行程。在金融场景，某头部银行利用腾讯云TI-OCR实现了95%以上准确率的文件智能识别和关键词提取，将文件数据转化为结构化数据,全面提升运营效率。</p><p>&nbsp;</p><p>大模型时代，算力、网络、数据构成了底层基础设施的“铁三角”。除了提供一站式MaaS服务之外，腾讯云还为客户提供了HCC高性能计算集群、星脉高性能计算网络以及向量数据库等基础设施服务。</p><p>&nbsp;</p><p>同时，腾讯云还积极参与、推动行业大模型标准建设。早在2020年，腾讯就被选举为全国信标委人工智能分委会委员兼副秘书长，国家在推进包括人工智能新基建的过程中，腾讯作为核心成员，承担了很多标准制定工作及技术引领作用。前不久，作为推动行业大模型的核心单位，腾讯云就与中国信通院共同启动了行业大模型标准联合推进计划，并联合信通院牵头开展国内首个金融行业大模型标准，为金融行业智能化的高质量规范化发展提供重要支撑。</p>",
    "publish_time": "2023-08-16 16:39:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "智研研究院FlagEval大模型评测平台更新8月榜单：新增通义千问、Llama2等多个模型评测，并评测基座模型代码生成能力",
    "url": "https://www.infoq.cn/article/XGymEQM1lowdUkAoNoaJ",
    "summary": "<p>为推动大模型在产业落地和技术创新，今年6月智源研究院发布了“开源商用许可语言大模型系列+开放评测平台” 两大重磅成果，打造“大模型进化流水线”。</p><p>&nbsp;</p><p>FlagEval（天秤）是北京智源人工智能研究院推出的大模型评测体系及开放平台，旨在建立科学、公正、开放的评测基准、方法、工具集，协助研究人员全方位评估基础模型及训练算法的性能。</p><p>&nbsp;</p><p>FlagEval 大语言模型评测体系当前包含 6 大评测任务，20+评测数据集，80k+评测题目。除了知名的公开数据集 HellaSwag、MMLU、C-Eval等，FlagEval 还集成了包括智源自建的主观评测数据集 Chinese Linguistics &amp; Cognition Challenge (CLCC) ，北京大学等单位共建的词汇级别语义关系判断、句子级别语义关系判断、多义词理解、修辞手法判断评测数据集，更多维度的评测数据集也在陆续集成中。</p><p>&nbsp;</p><p>自6月9日上线以来，FlagEval在短短一个月内就已收到200+模型评测申请，并更新了首期SFT模型排行榜和大模型2023高考排行榜。在FlagEval 8月榜单最新榜单中，新增了通义千问、Llama2等多个模型评测，也新增了基座模型代码生成能力评测。</p><p>&nbsp;</p><p></p><h2>新增多个明星开源模型评测：Llama2 / Qwen / InternLM / MPT / Falcon</h2><p></p><p>&nbsp;</p><p>基座模型（Base Model）榜单：</p><p>&nbsp;</p><p>Qwen-7B、InternLM-7B 超越 Llama2，分列第一、第二名。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/f9/f93d68fac8656573cdaf078bc1321d19.jpeg\" /></p><p></p><p>有监督微调模型（SFT Model）榜单：</p><p>&nbsp;</p><p>InternLM-chat-7B 夺魁，刷新中英客观评测记录，悟道·天鹰AquilaChat 排名第二；</p><p>&nbsp;</p><p>Qwen-chat-7B 中英文客观评测结果欠佳，远低于其基座模型的客观评测表现；但在中文主观评测上，Qwen-chat-7B 以 75.4% 准确率排名第一，与第二名 ChatGLM2-6B（62.1%）拉开较大差距。</p><p>&nbsp;</p><p>备受关注的 Llama2 基座模型 7B、13B&nbsp;综合评测结果相比于第一代提升了 10%、25%；Llama2-Chat 7B、13B 英文能力突出，中文存在明显短板，中文主观评测准确率仅为 18.3%、22%，在 SFT 模型榜单上排名第三，仅次于 InternLM 和悟道·天鹰 Aquila。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/e4/e4e18deee7047958d31e8e92aa638c7d.jpeg\" /></p><p></p><h2>新增针对基座模型 HumanEval代码生成能力评测</h2><p></p><p>&nbsp;</p><p>近期，“代码生成能力”新晋成为大语言模型领域的热门话题，开源基座模型如 Llama2 的技术报告特别强调了“代码生成能力”作为其关键特性。&nbsp;</p><p>&nbsp;</p><p>基座模型强大的代码生成能力为后续的代码语料微调提供了坚实基础。因此，本期榜单引入了针对基座模型的 HumanEval 评测：</p><p>&nbsp;</p><p>Pass@1 的评测结果显示，国产大模型 Qwen、InternLM 超越 Llama2-13B，分列第一、第二名。</p><p>&nbsp;</p><p>Pass@100 结果显示，悟道·天鹰 Aquila-7B的表现接近 Llama-13B，但与第二代 Llama2-13B 相比仍有一定差距。</p><p>&nbsp;</p><p></p><blockquote>HumanEval 是由 OpenAI 编写发布的代码生成评测数据集，包含 164 道人工编写的Python编程问题，模型针对每个单元测试问题生成k（k=1,10,100）个代码样本，如果有任何样本通过单元测试，则认为问题已解决，并报告问题解决的总比例，即 Pass@k 得分。</blockquote><p></p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/68/68eb0749139e4bfecac6b8198915d267.jpeg\" /></p><p></p><p>&nbsp;</p><p>Falcon-7b HumanEval 评测结果出自 Meta Llama2 官方论文 ：</p><p>&nbsp;</p><p><a href=\"https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/\">https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/</a>\"</p><p>&nbsp;</p><p></p><blockquote>评测说明：在评测时，FlagEval 根据数据集的不同规模进行了自动化采样。更多评测结果请登录官网查看：<a href=\"https://flageval.baai.ac.cn/\">https://flageval.baai.ac.cn/</a>\"</blockquote><p></p>",
    "publish_time": "2023-08-16 18:37:48",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]