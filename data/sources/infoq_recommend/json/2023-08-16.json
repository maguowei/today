[
  {
    "title": "分布式PostgreSQL基准测试：Azure Cosmos DB、CockroachDB和YugabyteDB",
    "url": "https://www.infoq.cn/article/0HLeJbIogjXgqZ8bbCJj",
    "summary": "<p>最近，微软详细介绍了<a href=\"https://devblogs.microsoft.com/cosmosdb/distributed-postgresql-benchmarks-using-hammerdb-by-gigaom/\">分布式PostgreSQL基准测试的结果</a>\"，比较了Azure Cosmos DB for PostgreSQL、CockroachDB与Yugabyte的事务处理性能和价格。这几种数据库在实现时做了不同的权衡，测试结果显示，Azure Cosmos DB的吞吐量更高。同时，他还着重指出了针对分布式数据库进行基准测试所面临的挑战。</p><p>&nbsp;</p><p>根据<a href=\"https://research.gigaom.com/report/transaction-processing-price-performance-testing/\">GigaOm基准测试</a>\"，在事务性能和价格方面，采用Citus分布式表的<a href=\"https://learn.microsoft.com/en-us/azure/cosmos-db/postgresql/introduction\">Azure Cosmos DB for PostgreSQL</a>\"优于CockroachDB Dedicated和Yugabyte Managed这两种全托管分布式数据库。</p><p>&nbsp;</p><p>正如<a href=\"https://www.infoq.com/news/2021/10/cloud-spanner-postgresql/\">InfoQ之前的报道</a>\"，随着不同的供应商对PostgreSQL这个流行的开源关系型数据库进行扩展、重新实现或创建分叉，它正在成为云分布式数据库的新标准。这项由微软赞助的基准测试使用了<a href=\"https://github.com/TPC-Council/HammerDB/\">HammerDB</a>\"。这是一个用于对关系型数据进行基准测试的开源工具，由事务性能委员会（<a href=\"https://www.tpc.org/\">Transaction Performance Council</a>\"，缩写为TPC）负责管理。微软首席软件工程师<a href=\"https://www.linkedin.com/in/marcoslot/\">Marco Slot</a>\"写道：</p><p></p><p></p><blockquote>GigaOM使用HammerDB TPROC-C对Azure Cosmos DB for PostgreSQL和两个类似的托管服务产品（…）进行了基准测试。在最初的基准测试中，GigaOM使用了1000个仓库，产生了大约100GB的数据。然而，CockroachDB和Yugabyte的吞吐量之低令人惊讶。在不改变连接数的情况下，增加两者的仓库数量可以提升性能。</blockquote><p></p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2f/2f32249fbec97e91fcf1b2c95cc52e6f.png\" /></p><p></p><p>图片来源：<a href=\"https://devblogs.microsoft.com/cosmosdb/distributed-postgresql-benchmarks-using-hammerdb-by-gigaom/\">https://devblogs.microsoft.com/cosmosdb/distributed-postgresql-benchmarks-using-hammerdb-by-gigaom/</a>\"</p><p>&nbsp;</p><p>有一个非常重要但颇有争议的点是<a href=\"https://www.citusdata.com/product/citus-on-azure/\">Citus</a>\"的使用。Citus是PostgreSQL中一个用于分发表的开源扩展，它要求开发人员指定一个分发列，即分片键：</p><p></p><p></p><blockquote>Citus的核心理念一直是：分布式PostgreSQL是为大规模、高性能而生的，因为对于其他任何事情，PostgreSQL都已经足够好。</blockquote><p></p><p>&nbsp;</p><p>测试的其他分布式数据库不依赖于分布式列的定义。在Reddit上，Slot<a href=\"https://www.reddit.com/r/PostgreSQL/comments/14fbjgg/comment/jozf85t/?utm_source=share&amp;utm_medium=web2x&amp;context=3\">承认</a>\"了其中的区别：</p><p></p><p></p><blockquote>性能差异似乎有点尴尬。我想特别指出的是，使用Citus确实需要一些额外的步骤（例如create_distributed_table）来定义分布式列和协同定位（否则，你只能使用单个节点）。我们的经验是，如果不对相关数据做协同定位，那么传统的事务型PostgreSQL工作负载的性能将比单个服务器差许多。</blockquote><p></p><p>&nbsp;</p><p>YugabyteDB开发大使Franck Pachot在推特上谈到了这项基准测试，他<a href=\"https://twitter.com/FranckPachot/status/1672330208802635776\">提了一个问题</a>\"：</p><p></p><p></p><blockquote>这是比较Citus（通过两阶段提交协议在SQL数据库上实现的分片）与YugabyteDB及CockroachDB （通过全局ACID事务在分布式存储上实现的SQL）吗？弹性、全局一致性、灵活性、自动划分/再平衡都不在同一个层次上。它们针对的是不同的用例。</blockquote><p></p><p>&nbsp;</p><p>该报告承认，对于不同的部署，不同的分布式数据库可能在不同的特性上胜出，包括响应时间、并发性、容错性、功能、一致性或持久性。Slot总结道：</p><p></p><p></p><blockquote>分布式系统，尤其是分布式数据库，涉及多个层面的权衡。CockroachDB和Yugabyte做了不同的权衡，它们不需要分布式列（…）不管是扩展Postgres（如Citus所做的），还是创建Postgres分叉（如Yugabyte所做的），亦或是是重新实现Postgres（如CockroachDB所做的），每一种决定也都是一个权衡，都会对最终用户的体验产生重大的或好或坏的影响。</blockquote><p></p><p>&nbsp;</p><p>为了鼓励客户运行与其工作负载相匹配的基准测试，<a href=\"https://github.com/citusdata/citus-benchmark/tree/master/azure\">微软共享了辅助脚本</a>\"，以便他们可以在Azure Cosmos DB上运行HammerDB基准测试。微软高级软件工程师<a href=\"https://www.linkedin.com/in/jeltef/\">Jelte Fennema</a>\"<a href=\"https://victorious-mud-07c59021e-600.westus2.3.azurestaticapps.net/blog/2022/03/12/how-to-benchmark-performance-of-citus-and-postgres-with-hammerdb/\">展示</a>\"了如何自动运行基准测试，包括集群设置和销毁。</p><p>&nbsp;</p><p>按照GigaOm的说法，<a href=\"https://cloud.google.com/spanner/docs/postgresql-interface\">Google Spanner Postgres Interface</a>\"之所以不在比较范围，是因为该服务不提供运行基准测试所需的Postgres兼容性级别。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/07/distributed-postgresql-benchmark/\">https://www.infoq.com/news/2023/07/distributed-postgresql-benchmark/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/VVCTQbCV1rKcZoMD3TKR\">这将是一场灾难？37年历史的PostgreSQL数据库将进行重大架构变更</a>\"</p><p><a href=\"https://www.infoq.cn/article/4114G9FlqZFEyTzQ53mq\">微软发布Azure Cosmos DB for PostgreSQL</a>\"</p>",
    "publish_time": "2023-08-16 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "讯飞星火V2.0发布：突破代码能力 ，提升大模型智慧程度",
    "url": "https://www.infoq.cn/article/AYS8kOCDsu3VDfMdlrjQ",
    "summary": "<p>8月15日，讯飞星火认知大模型V2.0升级发布会如约而至，科大讯飞董事长刘庆峰、研究院院长刘聪重磅发布代码能力和多模态能力升级，同时发布并升级搭载讯飞星火认知大模型V2.0能力的多项应用和产品。刘庆峰表示，代码能力是支撑认知大模型智慧的关键维度，多模态能力则是实现通用人工智能的必经之路也是科大讯飞既定的人工智能技术长期战略，大模型赋能个体和行业的大未来正在到来。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/31/0e/3127387d101eec1d38329895d33f5f0e.png\" /></p><p></p><p>技术获得重大突破的同时，搭载讯飞星火认知大模型核心能力的应用和产品也越来越丰富：既有代码快速生成或者改Bug的智能编程助手iFlyCode1.0，能够进行视频创作的讯飞智作2.0，还有帮助教师设计教学活动、一键生成课件的星火教师助手，面向学生口语练习的星火语伴2.0，讯飞AI学习机也升级AI编程空间和AI创意画板。此外，科大讯飞还和华为联合发布讯飞星火一体机，为每一家企业提供专属的大模型，联合打造全国产化算力底座。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/f9/3b/f9dc8cdc0868f5afc1c10e6341f41a3b.png\" /></p><p></p><p>至今，讯飞星火已陆续在教育、办公、汽车、金融、工业、医疗等行业推进真实可见的应用落地，同时也和开发者一起持续构建通用人工智能新生态。</p><p></p><p>“关于未来，无论你觉得行还是不行，你终将都是对的”，科大讯飞董事长刘庆峰表示，要打造每个人的AI助手，释放每个人的无限可能。</p><p></p><h3>人人都是开发者！ 讯飞星火突破代码能力并发布智能编程助手 iFlyCode</h3><p></p><p></p><p>代码生成、自动纠错 ，讯飞星火代码能力升级</p><p></p><p>代码是大模型硬碰硬的能力，此次升级也是科大讯飞今年5月6日首发讯飞星火认知大模型时立下的里程碑。</p><p></p><p>“代码数据能提升认知大模型的‘智慧’，代码能力是认知大模型聪明程度的重要标志。”刘庆峰说，代码能力也是构建和链接数字世界的有效手段，可以大幅降低数字经济的创业门槛和成本，不用个个都是编程高手，只要发挥自己的想象力、基于对应用场景的认知，就可以提升开发效率、实现相关创业。</p><p></p><p>此次讯飞星火2.0对代码能力进行5个维度的升级，包括：代码生成、代码补齐、代码纠错、代码解释、单元测试生成。</p><p></p><p>现场演示中，使用Python画红色的心形线、画出马鞍面方程三维立体图并设置渐变色、用代码生成小游戏对讯飞星火都不在话下，“使用python处理视频星火.m4v，提取其中第2到10秒，把画面缩小一半，加速5倍，保存成gif图片。”就连利用小视频做表情包这种需求都可以迅速搞定。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/f0/93/f09dd2c380875e2d288058d032e9dd93.png\" /></p><p></p><p>刘庆峰介绍，根据OpenAI构建的代码能力公开测试集HumanEval，星火V1.5 Python语言的效果只有41分，V2.0已经到了61分、接近ChatGPT。根据认知智能国家重点实验室构建的代码的真实的场景使用的测试集，代码生成和补齐维度上已经超过了ChatGPT。根据计划，讯飞星火代码各维度的能力将在今年10月24日超越ChatGPT，明年上半年对标GPT-4。</p><p></p><p>讯飞星火智能编程助手 iFlyCode上线，编码效率提升30%</p><p></p><p>讯飞星火代码能力升级后如何让开发者们更方便使用？科大讯飞现场发布了讯飞星火的应用级产品——智能编程助手iFlyCode1.0。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/d0/cc/d062604cb6b77498f734030e985bb1cc.png\" /></p><p></p><p>去年科大讯飞全球1024开发者节期间，用两个手指捏合就能写字的“凌空手写”功能惊艳了不少人，对iFlyCode来讲，开发这个功能简直就是“小菜一碟”，刘聪现场简单几步Prompt完iFlyCode界面后，一行代码都不用写，“凌空手写”功能就已马上实现，而在以前，即便是有经验的工程师，也要半天到1天才能完成，现在只需要几分钟。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/f0/ab/f0d616160177f2d060a64a7bdce9d0ab.png\" /></p><p></p><p>根据讯飞内部研发效能平台对2000余名员工在1个月内测试使用iFlyCode1.0的成效数据统计，在一些典型场景中，代码采纳率达30%，编码效率提升30%，综合效率提升15%。</p><p></p><p>教育数字基座搭载讯飞星火2.0 “零代码”能力也能建设数字化校园</p><p></p><p>讯飞星火代码能力的升级，一方面是帮助专业的程序员提升效率、将自己从繁琐的事务性工作中抽离出来去发挥更大的创造力价值，另一方面则是帮助非专业的“小白”零门槛进入代码世界。</p><p></p><p>发布会上，科大讯飞发布了代码能力的行业应用案例：“零编程基础”的老师也能使用教育数字基座作为开发助手，满足学校管理数字化转型中的个性需求和定制开发。</p><p></p><p>“请帮我搭建一个离校管理应用，家长可以帮学生申请离校，申请信息需要经过班主任审批。”只需要简单指令便可在数字教育基座上完成应用搭建；家长请假语音输入后变成自动生成请假条，班主任在线审批，任课教师同步可在班牌上看到今天请教的同学名单；还可根据需求完成限定条件下的离校生统计。</p><p></p><p>“教育数字基座致力于构建‘数联、物联、智联’为一体的教育应用开发生态，是数字化校园发展的未来趋势。”根据上海、湖北等试点学校的应用成效，教育应用的开发周期和投资成本都大幅度降低。</p><p></p><p>刘庆峰表示，代码能力不仅应用于讯飞教育数字基座，还广泛应用于医院、大学、企业、政府等不同的机构，通过iFlyCode实现快速搭建和低成本迅速呈现，“这就是我们说的通用人工智能为什么会深刻改变今天以人力和时长为主要逻辑的商业模式，实现整个产业的彻底的颠覆和升级”。</p><p></p><h3>多模态能力再升级 ，讯飞智作2.0让视频生成更高效</h3><p></p><p></p><p>拍了美图想“秒速”发一个图文并茂的朋友圈？张嘴就想画出脑海里突发奇想的图画？只要输入一段文字，一键就想生成声情并茂的小视频？</p><p></p><p>这些功能，讯飞星火V2.0全部可以实现。发布会现场，刘庆峰对讯飞星火的多模态能力进行重磅发布，讯飞星火在图像描述、图像问答、识图创作、文图生成、虚拟人合成等方面全新升级。他表示，“讯飞星火的多模态能力在业界可测的大模型中明显领先。”</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/38/63/382024567b1d5887c0eb873ccb2dc863.png\" /></p><p></p><p>刘聪现场继续真机实测，让星火大模型现场“读图”，生成人物、风景等各类照片，生成班级手抄报，还能根据古诗词“作画”，“智商”在线。星火还能进行虚拟人短视频的生成，“创作一篇立秋抒情散文，并用一个短发民国风的女生形象生成视频”，他话音刚落，一个身穿民国风格的女生站在不断切换的秋天美景前娓娓道来。</p><p></p><p>对于升级多模态能力，刘庆峰重点介绍了两点。“多模态能力是赋能行业的刚需，也是实现通用人工智能的必经之路。”他强调，当前多模态能力已广泛应用在教育、医疗、工业、汽车、机器人等领域，它可以从真实世界获得越来越多的数据，在产品终端有学习、训练和提升，包括更柔性更自主的工业机器人、更好的自动驾驶、走入家庭的陪伴机器人等。</p><p></p><p>“多模态能力也是科大讯飞既定的人工智能技术长期战略。”最近3年，科大讯飞已在多模态领域获得了17个国际权威评测冠军，2022年初讯飞就已发布了包括多模感知、深度理解、多维表达、运动智能等核心能力的“讯飞超脑2030计划”，让懂知识、善学习、能进化的机器人走进每个家庭。“这其中最重要的一项技术就是多模态能力。”</p><p></p><p>多模态能力的升级也将为AIGC带来前所未有的产业机会，发布会上多模态能力升级后的产品——讯飞智作2.0也正式发布，无论是视频的后期处理还是创意视频生产，搭载了讯飞星火核心能力的讯飞智作2.0都能轻松搞定。</p><p></p><p>现场，刘聪使用讯飞智作进行虚拟人短视频生成、视频创作，“写一段黄山毛峰宣传文案，包括茶叶的产地、包装、色泽等特点”，刘聪又设定一位徽州古风女主播呈现，一个推介黄山毛峰的短视频就马上生成。</p><p></p><p>讯飞智作2.0可以进一步降低短视频制作的门槛，满足更多元的视频制作需求，推动AIGC产业的发展。</p><p></p><h3>发布教师助手、上线星火语伴2.0，星火打造每个人的AI助手</h3><p></p><p></p><p>“备考搭子”来了！星火语伴2.0上线口语模考沉浸式陪练</p><p></p><p>面向各学段学生、商务人士等广大英语学习爱好者的口语陪练老师，科大讯飞在6月9日发布了讯飞语伴APP。本次结合多模态能力，讯飞语伴2.0全新升级，除了能够进行主题对话、虚拟人对话，重点推出两大核心能力——口语模考和情景交流，可用AI实现真人式陪练。</p><p></p><p>刘聪现场和讯飞星火语伴2.0进行了一场代入感极强的口语模拟考试，他进入星火语伴的雅思考试入口，一位AI英语老师便跟他展开对话，对话结束后，系统马上给出准确度、流畅度、语法、词汇等维度的系统性评价，并推荐相关课程，通过及时反馈来强化学习结果。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/8a/3b/8a4ca245a8a6f6b7de7b3c3a77e40b3b.png\" /></p><p></p><p>据了解，目前口语模考功能已支持CET、雅思、托福等大型权威考试。</p><p></p><p>此外，8月15日，讯飞输入法“AI创作助手”正式开启内测。AI创作助手可在办公、学习、生活、社交等多个领域为用户提供场景化文案服务；还能对各类文案进行智能创作、润色，支持多种风格一键切换，提供更智能、便捷、有趣的输入体验。</p><p></p><p>设计教学活动、一键生成课件 ，星火要做教师好帮手</p><p></p><p>在“双减”前提下，全国的教育开始实现以核心素养的培养为重点的教育“三新”（即新课标、新教材、新高考）改革，这对老师提出了较大挑战，主要体现在单元教学的规划，教师的教育工具和个人的眼界知识面有限，教学活动过程中丰富资源也很难找到，需要6小时才能制作一个像样的单元课件，面对创新难、资源少、负担重的教学设计难题，如何应对“三新”改革带来的挑战？</p><p></p><p>科大讯飞全新发布的星火教师助手，支持教学设计的三大环节，创新规划单元教学设计、启发创设情境教学活动、一键生成互动教学课件，大大提升老师的备课效率。</p><p></p><p>刘聪现场演示了老师如何快速生成并修改教学设计，当他给出提示词“围绕‘时代品质、工匠精神’主题，生成高中语文必修（上）第二单元的教学设计”，一份逻辑清晰、细分成4个任务8个课时的教学设计马上生成，通过提示词就可以直接修改细节，还能一键生成参考课件PPT，为PPT配上风吹稻浪、小鸟鸣叫的背景音，并秒速总结输出思维导图，布置实践作业。</p><p></p><p>搭载了讯飞星火认知大模型的教师助手，通过数据驱动因材施教，用人工智能助力课堂创新，至今已服务全国超过2.5万所学校、超过1200万名师生。“星火教师助手帮助每个老师解放备课生产力，释放学生想象力”，刘庆峰说，星火教师助手带来的绝不仅仅是效率的提升，它可以帮助孩子获得超越老师自身知识面的素材库，帮助孩子释放想象力和带来更加丰富的课堂。</p><p></p><p>发布AI编程空间和AI创意画板 ，讯飞AI学习机再升级</p><p></p><p>讯飞星火发布以来，全面赋能C端硬件，今年“618”期间销售额同比增幅达125%。今年5月6日以来，讯飞AI学习机搭载星火发布的五大功能广受好评，包括TalkTalk口语对话、AI 作文助手、数学互动辅学、百科问答助手、亲子教育助手，讯飞AI学习机销量也实现同比增长180%。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/6d/86/6d4747dcb4d5ffc868c1d31dbb885a86.png\" /></p><p></p><p>在星火大模型2.0加持下，讯飞AI学习机此次也升级了两大功能，正式发布了AI编程空间和AI创意画板，更贴近新课标要求，全面赋能学科学习和素养拓展。</p><p></p><p>AI编程空间是学习机行业首款AI一对一智能编程助手，支持Python语言的学习、练习以及代码自动生成、修改、运行调试等功能。通过知识问答、练习题和代码诊断等步骤，在AI一对一互动的过程中，让孩子逐步爱上编程。</p><p></p><p>AI创意画板不仅可以看懂孩子画了什么，还能理解孩子想要表达的情感和意义，通过鼓励式探讨，不断提升孩子们的观察力、想象力、创造力和表达能力。</p><p></p><p>在星火大模型加持下，讯飞翻译机也为用户带来了全新的“AI口语”功能，使得用户能够在线体验中英口语对练功能。目前，“AI口语”支持73个不同场景的话题，包括出游、办公礼仪、自我介绍等等，覆盖绝大多数常用口语学习内容。</p><p></p><p>此外，今年星火大模型发布以来，在汽车、金融领域也取得丰富的成果，如在汽车场景推出了星火汽车助力和星火汽车APP，首款搭载星火的奇瑞汽车即将发布。下一步星火将赋能千行百业，助推产业升级。</p><p></p><h3>星火一体机重磅发布！科大讯飞牵手华为联合打造国产化算力底座</h3><p></p><p></p><p>今年7月6日，科大讯飞公布讯飞星火将与昇腾AI强强联合，打造基于中国自主创新的通用智能新底座。此次发布会，科大讯飞与华为强强联合发布星火一体机，让企业可以在国产自主创新的平台上，更方便、更自主、更安全可控地私有化部署大模型。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/be/dd/be59d63fe6cfb61cc1cb49f59b4e46dd.png\" /></p><p></p><p>刘庆峰说：“认知大模型深度赋能时代已经到来，健康发展急需构建安全可控保障。”他认为，认知大模型在行业深度应用有三方面的关键要素：</p><p></p><p>第一是安全可控，“通用人工智能改善民生、赋能社发展要根植在自主可控、算力安全平台上。”第二是场景驱动，“要能够在看得见摸得着的场景上，能够产生实实在在的应用价值，能够用统计数据来证明应用成效。”第三是专项训练，“构建私有化专属大模型，保护用户的专有数据和知识产权，并提升行业应用效果。”</p><p></p><p>在安全可控方面，刘庆峰介绍科大讯飞和华为已在联合攻关算力卡脖子的问题。科大讯飞拥有自研大模型训练平台，具备训练和数据闭环全流程设计、大模型训练和推理一体化设计、大规模异构算力兼容、支持混合云架构易拓展等优势，华为基于昇腾AI基础软硬件的高算力AI芯片、高性能算子库、多卡高速互联、分布式存储等优势，“我们正在跟华为一道打造面向超大规模大模型的训练国产算力的集群，形成集群化的优势。”</p><p></p><p>会上，讯飞星火和华为昇腾联合发布了星火一体机，该设备可提供对话开发、任务编排、插件执行、知识接入、提示工程等5种定制优化模式，以及办公、代码、客服、运维、营销、采购等10种以上即开即用的丰富场景包，支持3种模型尺寸供用户选择。刘庆峰表示，有了这些能力，就可以使得每一家企业、每一个行业、每一个学校、每个医院都有机会构建自己的专属大模型。目前，讯飞星火已完成的在金融、政务、汽车等领域的9个专属大模型的数据显示，在场景任务优化和私域知识增强等方面平均效果能够提升20%。</p><p></p><h3>进一步开放助手生态、插件市场、星火营，共建星火生态</h3><p></p><p></p><p>“中国人工智能的发展绝不是单个企业、单个科研院所使命，而是整个社会的机会，生态的发展决定了产业的繁荣。”刘庆峰发布会上表示，讯飞星火5月6日发布以来，100天间开发者数量同比增长282%，开发者行业分布中排名第一的是“企业服务”，“说明大模型真正开始赋能到刚需应用中。”</p><p></p><p>除了原有的能力开放、行业共建、双创赋能等举措，此次发布会上科大讯飞宣布将进一步开放助手生态、插件市场、星火营，与开发者团队一起构建通用人工智能新生态。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/c3/f9/c307ace507d146c0d43f31cc2dd8e9f9.png\" /></p><p></p><p>据悉，在讯飞星火中目前已有4109个助手开发者团队开发出7862款星火助手，“我们希望通过通用人工智能极大降低社会的创新创业门槛。”此外，讯飞星火营则将与高校联合培养通用人工智能领军人才，与开发者共建技术交流平台。</p><p></p><p>今年5月6日首次发布讯飞星火大模型时，科大讯飞便公布了今年的升级里程碑，随后如期在6月9日、8月15日分别发布的讯飞星火V1.5和V2.0，今年10月24日将全面对标ChatGPT，中文超越、英文相当，明年对标GPT-4。</p><p></p><p>为什么总能如约而至？刘庆峰说，这是科大讯飞过去24年创业过程中的技术积淀，星火的每一行代码、每一个算法模块都是自研的；还有成建制的团队，和华为这样的深度合作伙伴。“最重要的是一定要有不完成任务绝不服输的精神，要做就永争第一的坚持。”</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/18/69/18677c0e1316815a6c0e384b7a0ec269.png\" /></p><p></p><p>“关于未来，无论你觉得行还是不行，你终将都是对的！”刘庆峰说，要全力以赴、不遗余力、充满激情、充满斗志的去争取，“有‘最终一定行’的精神指引，借助这一波通用人工智能的机会，我们打造每个人的AI助手、释放每个人无限可能的梦想，就一定能够成为现实。”</p>",
    "publish_time": "2023-08-16 07:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "中国开源生态系列图谱——前端领域",
    "url": "https://www.infoq.cn/article/5ESYJ3VP3FrJoV8beRHN",
    "summary": "<p></p><h3>研究背景</h3><p></p><p>2022 年 8 月，InfoQ 研究中心推出《中国开源发展研究分析 2022》<a href=\"http://www.infoq.cn/minibook/DTAg4l8piWHrBGfU3der\"></a>\"。报告中对中国开源的宏观发展的背景、目前取得的成绩、整体发展的特征进行了分析。同时也推出了基于 InfoQ 研究中心研究成果的 InfoQ 开源项目指数。但是因为时间等因素，《中国开源发展研究分析 2022》<a href=\"http://www.infoq.cn/minibook/DTAg4l8piWHrBGfU3der\"></a>\"聚焦研究了中国 TOP30 开源项目。我们深知，中国开源发展百花齐放，仍有大量的项目深植于各技术领域中，并且取得了亮眼的成绩。另外，不同的技术领域开源也具有各自独特的特征。</p><p></p><p>所以，InfoQ 研究中心策划启动了《中国开源生态图谱系列研究》工作，技术领域涉及操作系统、数据库、云原生、大数据、前端、架构等。希望系列研究能够帮助关注中国开源世界的朋友绘制更为完整的开源全景图谱。通过对不同技术领域的研究分析，帮助读者获得更为具体的开源领域洞察。</p><p></p><p>此篇是《中国开源生态图谱系列研究》的第五篇，聚焦在前端领域，通过统计目前的前端开源项目，并进行分类，同时结合开源基金会、开源产业联盟等生态，完整构成中国前端开源的生态图谱。同时，洞察前端开源领域面临的三大挑战与三大发展趋势，供广大开发者和开源社区参考。随后，通过在《中国开源发展研究分析 2022》<a href=\"http://www.infoq.cn/minibook/DTAg4l8piWHrBGfU3der\"></a>\"中使用的 InfoQ 开源项目指数，分析和评价现有前端开源项目。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/c1/22/c127083a740bdbd09bb6ccc4070e3022.png\" /></p><p></p><p>截至目前，InfoQ 研究中心已经发布了 5 个领域的开源生态图谱，覆盖操作系统领域<a href=\"http://www.infoq.cn/minibook/ARa5HwDdOveaDKavLSc3\"></a>\"、数据库领域<a href=\"http://www.infoq.cn/minibook/pPz0K3aDcvO6pvtDBEq6\"></a>\"、人工智能领域<a href=\"http://www.infoq.cn/minibook/3ElKmiQIzsFC8ThhFfst\"></a>\"、云原生领域<a href=\"http://www.infoq.cn/minibook/zdDoaDUkCGiLmWcPBYIz\"></a>\"、前端领域，并且发布了涵盖 931 个中国开源项目的《中国开源生态图谱 2023》<a href=\"http://www.infoq.cn/minibook/9j4NSEEh2JGJAUVdQGGu\"></a>\"。欢迎下载和持续关注。</p><p></p><h3>目录</h3><p></p><p>生态图谱解读生态图谱项目洞察</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9b/9b56275152f561c6960a1ce02be4ec98.png\" /></p><p>扫/码/下/载</p>",
    "publish_time": "2023-08-16 11:23:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "探秘B站多媒体实验室：B站视频背后的AI黑科技是如何炼成的？",
    "url": "https://www.infoq.cn/article/EwMBkITYMgWM58jbZqBV",
    "summary": "<p>快速发展的AI技术正在为千行百业带来越来越多可能性，以多媒体领域为例，AI目前已经深层渗透到了内容生产、识别理解、处理增强、语音、检索、安全等诸多方面。在B站，不管你是看视频的用户还是发布作品的UP主，AI在你的使用过程中几乎可以说无处不在。比如，你在B站上刷视频推荐瀑布流的时候，视频推荐页卡片封面的高能看点GIF动画，可能就是由大语言模型生产出来的；比如，已经有很多UP主在使用开箱即用的AIGC工具辅助内容创作；再比如，在用户所看到的视频画面里，利用AI算法嵌入了不可见的数字水印信息，以便于后续平台对视频归属权进行快速鉴别，等等。</p><p>&nbsp;</p><p>而上述这些AI应用探索，都离不开B站多媒体实验室的工作。B站多媒体实验室是B站多媒体技术部的核心算法研发部门，除了立足于点直播转码核心算法的研发，也承担了一系列涉及视频内容生产、结构化、版权保护等环节的技术研究与落地，以及紧跟潮流的前沿热点追踪与预研工作。</p><p>&nbsp;</p><p>在9月3-5日即将召开的QCon 北京 2023上，B 站多媒体实验室算法负责人成超将带来以<a href=\"https://qcon.infoq.cn/202309/beijing/presentation/5415\">《B 站前沿多媒体技术保障用户体验与创作权益》</a>\"为主题的演讲分享。会前，InfoQ对成超老师进行了专访，提前揭秘B站多媒体实验室的重点工作方向，以及B站如何将LLM等前沿技术与多媒体业务相结合的落地探索。</p><p>&nbsp;</p><p>以下为访谈实录，经InfoQ编辑整理：</p><p>&nbsp;</p><p>InfoQ：很荣幸有机会采访您，能否请您先介绍一下您在计算机视觉及AI图像领域的从业经历？您是在什么时候、因为什么样的机缘加入B站多媒体实验室的？</p><p>&nbsp;</p><p>成超：在加入B站之前我一直在云厂商从事AI视频分析、处理、增强等方向的工作。2021年B站多媒体技术部成立了自己的算法研发部门，在紧贴业务一线的地方探索多媒体AI算法的更多可能性。在此契机下我加入了B站，同时也面临着toB到toC转变的挑战。</p><p>&nbsp;</p><p></p><h2>B站多媒体实验室的过去和现在</h2><p></p><p>&nbsp;</p><p>InfoQ：能否进一步介绍下B站多媒体实验室在公司内部的定位，以及它的发展历程？</p><p>&nbsp;</p><p>成超：B站多媒体实验室是B站多媒体技术部的核心算法研发部门，目前主要从事于编码器、多媒体算法，以及前沿技术在点直播体系下落地的研发。多媒体实验室的前身是编码器组与算法组，在部门早期阶段这两个组曾是独立运行的：编码器组主要负责B站转码架构中最核心的BILIAVC、BILIHEVC、BILIAV1，及当前重点投入的BILIVVC编码器的研发；算法组主要负责视频画质增强，如超分、超帧等处理算法的研发。</p><p>&nbsp;</p><p>随着多媒体技术部所负责的点直播转码架构的不断演进，我们发现AI处理+编码结合在一起能够取得更大的想象空间。例如通过AI算法对视频画面进行重构然后编码，能够比纯编码在取得相同画质结果的条件下节省10~15%的码率；又例如通过VQA等基于数据驱动的无参质量评价，能够一定程度替代PSNR等有参且不基于人眼感知的评价标准，为编码器的迭代指引更科学的优化方向。</p><p>&nbsp;</p><p>因此在2023年年初，我们从组织架构层面将这两个组合并成立了多媒体实验室，合并之后的多媒体实验室除了立足于点直播转码核心算法的研发之外，还需要承担一系列涉及视频内容生产、结构化、版权保护等环节的技术研究与落地，以及紧跟潮流的前沿热点追踪与预研。</p><p></p><p>InfoQ：根据您从业这几年的观察，AI技术在多媒体领域都有哪些应用、又带来了哪些重要变化？可否列举一些代表性案例进行说明。</p><p>&nbsp;</p><p>成超：这个问题比较宏大，AI目前已经深层渗透到了内容生产、识别理解、处理增强、语音、检索、安全等诸多领域，我想以内容生产为重点来谈谈目前AI所带来的显著变化与趋势。</p><p>&nbsp;</p><p>AI对内容生产的促进成果是非常令人兴奋的，我们很欣喜地看到，B站上很多UP主都已经在用开箱即用的AIGC工具辅助内容创作了。例如最近某个专注于神话志怪题材的UP主为了讲解封神榜的故事背景，采用当下流行的文生图平台制作了很多符合封神故事风格的人物、鬼怪设定图并应用在了视频中，这些图片质量很高，丝毫不亚于一些专业画师的创作水准。如果没有此类技术，观众大概只能凭借UP主的语音文字讲解来脑补那些奇幻角色造型，无疑提高了受众门槛，也降低了观看体验。</p><p>&nbsp;</p><p>再举一个作为平台方应用的例子，我们正在采用AI换脸制作个性化的直播虚拟礼物。对不同主播的高能用户我们会发送一些定制化礼物。传统的虚拟礼物生产流程是，首先创建一个虚拟人并生成一段统一的CG，然后对不同主播的人脸进行建模并替换掉虚拟人的面部，这样呈现到用户端的效果就是，他关注的主播在一个酷炫的场景里面做出一连串复杂的动作造型。而现在采用AI换脸，我们能够整体替换掉主播人脸建模这一生产环节，并且AI换脸所渲染出来的微表情、妆容甚至比建模还具有真实感。完整的个性化礼物制作周期与成本也被极大地压缩，在同样资源条件下，我们能够为用户提供更多更有意思的玩法和内容。</p><p>&nbsp;</p><p>InfoQ：我们知道B站一直有在积极探索新技术在多媒体领域的应用，比如2018年的<a href=\"https://www.infoq.cn/article/2018/08/bili-bili-mask-barrage\">蒙版弹幕</a>\"，那么当前B站多媒体实验室的主要研究方向包括哪些？为什么选择将这些方向作为重点？</p><p>&nbsp;</p><p>成超：B站多媒体实验室的主要研发线可以归纳为以下几个方向：</p><p>内容生产：包括端云协同玩法的云端算法服务部分、视频虚拟化玩法的探索；转码处理：包括点直播视频编解码（BILIAVC/BILIHEVC/BILIAV1/BILIVVC）、BiliVision画质矩阵、窄带高清智能转码；内容管理：包括视频结构化、BiliVQA质量评价体系、数字版权保护。</p><p></p><p>B站的视频数据从上传，到转码处理、分发、存储的完整生命周期，都是在多媒体技术部完成的，因而多媒体实验室的主要研发方向也都是基于点直播技术体系的基本算法需求制定的。核心出发点只有三个：体验、增长、成本。体验和成本自不必说，编码与画质是我们最核心的研发方向，也是B站作为一个视频平台所应当具备的硬实力。对于增长而言，我们相信视频数据在点直播技术体系中流转的过程也是能够为创作者和用户产生价值的，如通过为恰当的内容引入恰当的元素能够提升创作者收益、为观众带来更新颖的玩法；又例如保障创作者权益从而维护并激发创作热情，这都能为我们生态的建设与持续的增长带来新动能。</p><p></p><h2>B站多媒体前沿技术探索</h2><p></p><p>&nbsp;</p><p>InfoQ：您的演讲介绍中提到B站建立了一套覆盖云/边/端、点/直播的画质增强链路，能否展开解释一下这套链路是如何运作的，以及给用户体验带来的改进？</p><p>&nbsp;</p><p>成超：BiliVQA会通过无参质量评价以对视频画质进行评估，根据评估结果驱动BiliVision画质矩阵对视频进行增强处理。原始画质较低的内容以去噪增强为主、高播非4K内容以4K超分为主、动态收益较高的内容以超帧为主、优质高潜内容进行完整的超分+超帧+HDR处理等。结合无参质量评价与一套严密的运营逻辑，能够让任何一部片源进入它最适合的增强链路。</p><p>&nbsp;</p><p>我们在底层采用了一套名为BVT的推理框架完成这种可配置的、自定义的增强流程：它把每一个增强算法节点化，像搭积木一样把各种算法堆叠在一起。</p><p>&nbsp;</p><p>BiliVision从原子能力层面出发已覆盖了超分、超帧、增强、HDR/调色等主要AI画质增强手段；从业务层面出发已覆盖点、直播，满足大规模部署的性能需求；物理上充分利用多阶算力，点播增强主要基于云端GPU，直播增强放在了更靠近用户的边缘GPU，而在用户端我们也部署了更适合移动端/PC的轻量增强算法，以实时提升那些无法被云端增强覆盖到的片源的观看画质。高画质在当下的网络环境中已经是用户刚需，但创作端能力与基础设施的完善还需要时间，在这个gap中AI画质提升是最优解。</p><p>&nbsp;</p><p>InfoQ：用户对信息流的汲取效率，应该如何理解？传统的视频信息流推荐存在哪些问题和不足？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p><p>&nbsp;</p><p>成超：用户观看视频一般有两种模式，一是通过关注列表，二是通过推荐列表。用户刷推荐瀑布流的过程本质是一个对信息筛选甄别的过程，需要在短时间内仅仅依靠封面、标题、时长、点赞数/观看数等信息判断是否对某些视频感兴趣。如果用户通过推荐列表对某个视频产生兴趣，会形成一次点击的转化。进入视频详情页后，用户可能发现内容本身并不像封面那样有趣而跳出观看，从而影响视频的平均观看时长以及完播率，也浪费了用户的时间。所谓的信息流汲取效率就体现在这里，即用户对真正感兴趣内容（无论兴趣是发生在观看前还是观看后）的有效观看时间除以用户使用App的时间。</p><p>&nbsp;</p><p>传统模式有以下不足：</p><p>一是部分视频为了快速吸引流量，采用了大量劲爆性、诱导性的封面标题，并且可能伴随视频内容货不对板的标题党问题，导致用户点进去视频后会有一种上当受骗的感觉。传统模式无法提供更充分的信息让用户对潜在感兴趣的内容进行有效甄别，自然导致了信息汲取效率无法提升。二是B站现在全面将主要增长目标从视频播放数转向到视频观看时长，鼓励优质长视频的创作。但客观来讲基于封面+标题的推荐列表是不利于长视频的点击率转化的，其能传达的有限信息显然更适用于概括短视频内容。众所周知B站的特色在于广大UP主创作的UGC/PUGV长视频，这类视频仅仅依靠封面贴片很难传情达意。</p><p>&nbsp;</p><p>InfoQ：关于大语言模型在用户信息流汲取效率方面的应用，您能否分享一些具体的案例或者效果？</p><p>&nbsp;</p><p>成超：正如一部电影在上映前会发布预告片来吸引潜在观影者，预告片对整部电影中的精彩看点做了密集总结并简要梳理了剧情梗概，这样观众就能够通过预告片未看先知电影的大致内容。</p><p>&nbsp;</p><p>上一个问题提到，传统推荐页呈现的信息很难真实且精炼地反映一段长视频的精华。因此，B站在推荐页卡片中引入了动画封面的模式，即通过一段包含视频内高能看点的GIF动画展现视频精彩时刻。高能GIF起到的正是类似于电影预告片的作用，这种方式对于点击转化率的提升非常大。</p><p>&nbsp;</p><p>但它的问题也很明显：传统方式生产高能看点GIF需要人工打点，效率较低，并且较难处理一些需要结合画面精彩程度、专业性强内容、外文内容进行综合推荐的场景。这个时候大语言模型就具备用武之地了。大语言模型对于整体内容理解、抽象、概括的能力较强，并且涉猎的知识面也具备广度；同时结合多语言的ASR、OCR，及视觉层面的美学评估、动态评估等技术可以形成一套非常完整、高效的自动化高能看点提取方案。我们将大语言模型生产出来的高能看点GIF投入到线上发现，它对转化率的提升比人工打点方式还要高，并且效率较人工有巨大的规模量产优势。</p><p>&nbsp;</p><p>此外，大语言模型具备重构视频拆条技术体系的潜力，基于大语言模型能够更高效更高质量地完成例如视频切片、视频分章节等任务。只有真正理解了内容，才能帮助我们的用户更高效地接收信息。</p><p>&nbsp;</p><p>InfoQ：当前在视频创作者权益保障这方面，行业内存在哪些痛点和挑战？B站多媒体实验室采取了哪些新的策略或技术手段来解决上述问题？</p><p>&nbsp;</p><p>成超：国内视频行业对于UGC版权的保护机制非常薄弱，甚至缺失。盗链搬运、恶意剪辑、洗稿等行为难以避免，打击了创作者尤其是PUGV创作者的创作热情，并侵犯了他们的创作权益。行业内目前已经拥有一些版权保护方案，例如视频指纹和DRM。但这些方案也存在一些问题，视频指纹需要建立庞大的指纹库，每条视频进来后要进行指纹提取和撞库操作，成本较高，且随着内容数量的增长，视频指纹对原始稿件的召回概率也会变低；DRM虽然能够在源头防止视频内容被记录下来，却也在需要开放二创权限的情况下变成了限制。</p><p>&nbsp;</p><p>多媒体实验室目前采用数字水印的方法来克服以上问题，利用算法在视频画面中嵌入不可见的信息，这些信息包含了版权标识符、视频ID、时间戳等。通过对视频文件进行解码，如果其包含了水印信息则能被正确解码，通过这些信息我们能够对视频的归属权进行快速鉴别，并能够定位到它在视频平台中具体的源头、时间点位置。它不需要像视频指纹一样建库，且版权信息是跟着码流走的，能够抵抗二次转码、裁剪、贴图等二创过程引入的攻击类型。最重要的是，我们的方案具备大规模落地能力，这大大增强了数字水印系统能够覆盖到的稿件数量。</p><p>&nbsp;</p><p>InfoQ：关于B 站多媒体实验室前沿技术落地的经验和思考，您能不能选择其中一个关键点提前分享给大家？也可以作为您本次QCon大会演讲的一个小预告。</p><p>&nbsp;</p><p>成超：首先感谢大家的关注，前面我们其实已经提前透露了QCon 北京 2023上会分享的基于LLM的视频拆条方案，以及数字水印系统的部分内容。此外，我们还可以预告一个在为UP主尤其是中小UP主提升创作收益方向上，正在探索的一项有趣的技术，叫做VPP（Virtual Product Placement）虚拟广告植入。它能够在视频内容中无感的植入广告等元素，与传统贴片广告不同之处在于，它与视频内容本身是融为一体的，例如将视频中张贴在背景墙上的一张海报替换为平面广告。视觉效果既不违和，又增加了商业曝光，也不影响视频本身内容或者主旨表达的连贯性。期待能在大会上与同行专家们多多交流，谢谢大家。</p><p></p><h4>采访嘉宾介绍：</h4><p></p><p></p><p>成超，B 站 多媒体实验室算法负责人。毕业于清华大学电子系，从事计算机视觉及 AI 图像领域的研究与应用，是B站多媒体实验室算法负责人，面向视频质量体系、AI 智能化生产，及基于机器学习感知编码等业务方向。</p><p></p><p>QCon 北京 2023即将在9月3-5日在北京·富力万丽酒店召开，此次大会策划了大前端融合提效、大模型应用落地、面向 AI 的存储、AIGC 浪潮下的研发效能提升、LLMOps、异构算力、微服务架构治理、业务安全技术、构建未来软件的编程语言、FinOps 等近30个精彩专题。会上，成超老师将围绕<a href=\"https://qcon.infoq.cn/202309/beijing/presentation/5415\">《B 站前沿多媒体技术保障用户体验与创作权益》</a>\"主题做进一步分享，详述B站前沿技术探索和实践细节，为参会者带来一手实战经验与深层思考，敬请期待~</p><p>&nbsp;</p><p>现在购票即可享受 9 折优惠，立减 ¥880。咨询购票可联系票务经理 18514549229（微信同手机号）。点击<a href=\"https://qcon.infoq.cn/202309/beijing/track?utm_source=wechat&amp;utm_medium=infoqart2&amp;utm_campaign=9&amp;utm_content=chengchao\">链接</a>\"即可查看全部专题，期待与各位开发者现场交流。 &nbsp;</p>",
    "publish_time": "2023-08-16 14:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "升级国赛！第三届OceanBase数据库大赛启动报名",
    "url": "https://www.infoq.cn/article/YG9ycc9NVoKNPcJoU2ei",
    "summary": "<p>近日，第三届<a href=\"https://xie.infoq.cn/article/4c220d4c8f155efeddd84882c\">OceanBase数据库大赛</a>\"启动报名。本届大赛进一步升级为全国大学生计算机系统能力大赛，由系统能力培养研究专家组发起，全国高等学校计算机教育研究会、系统能力培养研究项目发起高校主办，OceanBase承办，旨在培养和发现计算机底层核心技术的后备人才。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/68/68720914654f445bfe34a9e0dd651997.png\" /></p><p></p><p><a href=\"https://xie.infoq.cn/article/8da6bf636faa6ffc606df313e\">OceanBase</a>\"是蚂蚁集团旗下的自研原生<a href=\"https://xie.infoq.cn/article/e29b62169027269118f763e4a\">分布式数据库</a>\"，曾在2019年、2021年接连打破世界纪录，并连续10年稳定支撑双11。从2021年起，OceanBase已连续举办两届数据库大赛，有近300所高校5千余名学生、数据库开发者参赛，大赛服务国家人才培养战略，以赛促学、以赛促教，开创了国内数据库内核开发人才培养的新模式。</p><p>&nbsp;</p><p>本届大赛分为初赛和决赛两个阶段。初赛阶段，参赛选手将基于具备基础功能的项目实战型数据库MiniOB系统进行开发，学习实现部分数据库功能。决赛阶段，参赛选手将在真实的企业级开源OceanBase内核上做更多数据库功能的探索，实现内核研发能力的进阶。此外，大赛提供40万奖金，冠亚季军队伍可获得实习绿色通道，前20强队伍都可以获得国家级竞赛证书。</p><p>&nbsp;</p><p>为保证大赛评审的公平公正，同时更好地指导学生，大赛评委团由多位学术界与工业界专家共同组成，包括中国人民大学明理书院院长杜小勇、北京航空航天大学计算机学院副院长高小鹏、Bilibili技术委员会主席毛剑、OceanBase CTO杨传辉等。</p><p>&nbsp;</p><p>全国大学生计算机系统能力大赛组委会专家、北京航空航天大学计算机学院副院长高小鹏教授表示，前两届大赛的参赛队伍思路开阔，能从各个角度深挖优化方案，证明了大赛的必要性与合理性，也证明了大赛是培育和发现数据库人才的平台，希望参赛选手能通过参赛以赛促学，系统学习理论知识、提升开发能力、积累企业级的工程经验，为未来打好基础。</p><p>&nbsp;</p><p>即日起，选手可通过全国大学生计算机系统能力大赛官网、<a href=\"https://open.oceanbase.com/competition\">OceanBase社区官网报名</a>\"，报名截止2023年10月25日。</p><p>&nbsp;</p><p>数据库，是基础软件“皇冠上的明珠”。数据库人才短缺是全球性问题，而国内比国外对这一问题的感触更深。越来越多企业联合高校搭建竞技平台，帮助产业培养人才，有望帮助年轻人树立信念、获得实践土壤，成为推动国产数据库发展的下一代。</p>",
    "publish_time": "2023-08-16 14:23:04",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "中国企业研发高效能白皮书（合集）",
    "url": "https://www.infoq.cn/article/DER7b8ez33OLpvahRSrG",
    "summary": "<p></p><h3>研究背景</h3><p></p><p>近年来，中国企业研发正在从粗放型走向精益型，研发工作的“高效能”成为几乎每个研发团队的共同追求。</p><p></p><p>中国软件服务产业也在近 5 到 10 年中得到了飞速发展，技术服务的边界不断拓展，赋能高效研发的产品层出不穷，适合中国研发环境的技术服务体系在不断完善。从结果上看，中国企业正在高效能研发的路径上快速前进。</p><p></p><p>本份报告以中国高效能研发企业为研究对象，尝试解读市场中具有代表性的高效能研发解决方案。本次报告由五个篇章组成，包括 CI/CD、ChatOps、企业级软件架构、Code Review、价值流管理与研发效能管理等五大主题。研究小组期待可以通过研究，帮助中国企业研发团队获得高效能研发新知。</p><p></p><h3>目录</h3><p></p><p></p><h4>CI/CD 篇</h4><p></p><p>CI/CD 概念和背景介绍CI/CD 行业发展概况极狐 GitLab CI/CD，带您开启研发高效能</p><p></p><h4>ChatOps 篇</h4><p></p><p>ChatOps 概念和背景介绍ChatOps 行业发展概况极狐 GitLab ChatOps</p><p></p><h4>企业级软件架构篇</h4><p></p><p>关于企业级软件架构常见的企业级软件架构方案极狐 GitLab 企业级软件架构极狐 GitLab 企业级软件架构最佳实践企业级软件架构市场发展趋势展望</p><p></p><h4>Code Review 篇</h4><p></p><p>Code Review 的定义与背景Code Review 发展现状Code Review 最佳实践</p><p></p><h4>从价值流管理到研发效能管理篇</h4><p></p><p>价值流管理定义与背景价值流管理行业发展现状极狐 GitLab 研发效能管理</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ac/acfb3de25ba325cec7a5531532dbcf21.png\" /></p><p>扫/码/下/载</p>",
    "publish_time": "2023-08-16 14:51:41",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从F5到通明智云，这位“探险家”如何突破应用交付创新边界？",
    "url": "https://www.infoq.cn/article/v3fU1OOujPUhhiSUQqjs",
    "summary": "<p>从深耕了22年且在应用交付领域全球领先的F5离开而选择加入一家成立不到2年的初创公司，这似乎是一个冒险的决定。然而冯勇就像一位“探险家”踏出了这一步并不断突破国内应用交付领域的创新边界。</p><p>&nbsp;</p><p>冯勇是应用交付和负载均衡行业公认的“大神”。这与他资深的行业背景密不可分，2001年，他加入了F5，并在同年与张毅强（F5中国区总经理）、吴静涛（时任F5中国区技术经理）、吴若松（时任F5北方区销售经理）等7人，组成了F5中国的七人初始团队。正式以厂商的身份把负载均衡市场引入到中国，在此后的22年里，他作为F5中国区首席架构师一直深耕在应用交付领域并主导了中国应用交付、负载均衡技术路线的演进。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/d1/36/d1e5a8346e443314byy29ed81d55b536.png\" /></p><p></p><p></p><h3>从F5到通明智云，为何做了这个看似”冒险“的决定？</h3><p></p><p>&nbsp;</p><p>老朋友的召唤和对应用交付领域的共同热爱，是冯勇加入通明智云的首要原因。在最初的7人团队中，吴若松和吴静涛如今是通明智云的总经理和COO。“我们深耕负载均衡市场超过20年，有着共同的热爱，如今老朋友再重聚，是契机也是意料之中。”冯勇说道。</p><p>&nbsp;</p><p>其次，大客户对通明智云的认可让冯勇有了下定决心的底气。在2018年之前，绝大多数国内厂商只能满足基本的负载均衡功能，需要3-5年才接近实现80%F5的功能。然而近几年国内企业追赶的步伐加快，通明智云就是其中之一。从2022年6月，工商银行开始针对通明湖产品进行功能性测试，仅仅一年时间就已经满足了客户所有的上线功能要求，逐一测试通过了60多项详细应用测试项目。这让工商银行对国内企业的技术发展和产品功能充满信心，也让冯勇心中增加了一份底气。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/54/32/54cda45510f8134eyy30d8716dafa832.png\" /></p><p>通明智云技术副总经理冯勇</p><p>&nbsp;</p><p>此外，近年来中国IT需求逐步引领全球。彼时担任F5架构师的冯勇深感中美技术路线的不一致，是否可以找到快速满足中国本地客户需求的方法？于是，F5与神州数码合作，打造了神州云科容翼系列产品，而通明湖系列则是完全自主研发的信创产品，真正为了满足中国客户需求而研发的，与客户一起推进现代应用发展。这是冯勇加入通明智云的第三个原因。</p><p>&nbsp;</p><p>从F5到通明智云，冯勇表示，“通明智云与F5的产品理念一脉相承。”&nbsp;</p><p></p><h3>双轨超高可用架构，保证核心应用的可持续性</h3><p></p><p>&nbsp;</p><p>信创背景下，各行业均加快应用的国产化。不过，伴随着信创发展的深入，也开始面临新的挑战。信创改造从办公网推进到核心区时，会遇到两个最大的问题：&nbsp;</p><p></p><p>第一，信创应用的稳定性、可靠性问题。面对核心应用99.999%的可用性要求和应用可持续性要求，很多客户缺乏信心。这就需要应用交付架构来帮助客户重构产品，包括实现故障的自动发现，在故障影响业务之前进行自动切换，并提供客户故障出逃计划，从而保证信创核心应用的超高可用性。&nbsp;</p><p></p><p>第二，当客户将核心应用从传统应用切换到信创区时，如何能够保证业务的平滑迁移？是否能将一些特定客户逐步迁移到信创区？目前很多信创核心业务都是整体切换，这就导致遇到问题不得不全部再回退。因为要保证业务的持续性，所以没有足够的时间、足够的测试以及实时手段来判断故障原因，给核心应用的信创改造带来巨大挑战。&nbsp;</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/29/01/29083718b7512887826a3440e293fb01.png\" /></p><p></p><p>双轨超高可用架构恰好能解决这些挑战。冯勇表示，“双轨超高可用架构能够提供统一的技术支持能力，通过统一的配置界面、统一的管理平台、统一的大数据采集分析，以及统一的服务平台等关键要素，来保证企业技术迭代创新过程中的应用可持续性和技术选型灵活性，尤其是实现核心信创的可靠过渡，满足信创应用可持续性的高要求。”</p><p>&nbsp;</p><p>双轨超高可用架构在双活数据中心的分区调度基础上，增加信创域和非信创域的分域调度，实行信创域与传统域应用全量部署，使双中心运营变为双中心四区域并行运行，互为多活，将“0到1”的单轨建设道路变为分区分域协同的多活双轨超高可用架构。帮助客户在新架构下，保障“信创”的同时解决性能瓶颈，提升稳定性，保证应用可持续性，最终实现信创区域和非信创区域的平滑过渡，完成国产化替代目标。</p><p>&nbsp;</p><p></p><h3>应用可持续性、应用可观测性、云原生应用引擎，是趋势也是目标</h3><p></p><p>&nbsp;</p><p>冯勇认为“就未来技术趋势来看，通明智云有三个大方向：应用可持续性、应用可观测性、云原生应用引擎”。</p><p>&nbsp;</p><p>Gartner 2023年十大技术趋势之一就是应用可持续性。应用可持续性关注的是应用的形态变化以及计算资源调度时能够保持应用服务的可持续性。从传统应用到自主信创平台，如何保持核心业务的可持续性是必须解决的问题。通明智云希望通过信创应用交付架构，实现应用从传统体系的国外平台到国产平台的平滑转换，帮助客户自动发现故障、屏蔽故障以提升国产应用的可用性。</p><p>&nbsp;</p><p>应用可观测性方面，要想真正保证应用的高可用性和可持续性，就必须要观测到每个应用的状态。这一点在中国尤其突出，我们在手机应用、物联网、车联网终端App的开发突飞猛进，尤其是游戏、短视频、社交、媒体App领先全球。基于此，在保证应用可持续性的基础上，通明智云希望能够帮助客户实现端到端的应用可观测性，确保能够真正掌握应用的运营状态。</p><p>&nbsp;</p><p>同时，通明智云正在致力于打造中国自主创新的现代应用引擎。云原生应用引擎OpenNJet项目正式成为开放原子开源基金会的孵化期项目，在Gitee、AtomGit代码托管平台建立了代码仓库。未来，OpenNJet将围绕五个方面展开工作，一是推广OpenNJet应用引擎，吸引开发者和企业用户共建和应用；二是深耕OpenNJet应用引擎技术研发和迭代；三是保障技术安全底线；四是积极谋划OpenNJet未来的产业发展；五是秉持开源开放的心态，积极回溯上游，推动云原生产业上下游生态共建。</p><p>&nbsp;</p><p>从应用可持续到应用可观测性进而发展成为云原生现代应用引擎，让客户真正掌握应用运营状态，这是通明智云一直在努力的方向。我们看到，通明智云在国内应用交付领域始终追求创新突破，致力于为企业创造更大价值。</p>",
    "publish_time": "2023-08-16 15:42:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "字节跳动算法专家张树波确认出席QCon北京，分享大模型助力智能单测生成",
    "url": "https://www.infoq.cn/article/NCSuki067wv7JxzmmYhe",
    "summary": "<p>9 月 3 日 - 5 日，在 <a href=\"https://qcon.infoq.cn/202309/beijing/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=0816&amp;utm_content=zhangshubo\">QCon 全球软件开发大会（北京站）</a>\"上，字节跳动算法专家张树波将发表题为《大模型助力智能单测生成》主题分享，介绍传统特智能单测生成，要依赖静态分析、动态分析等工具，对不同的语言需要重新适配。随着模型参数规模的提升，模型的代码理解、代码生成能力也大幅提升，使用模型端到端的生成单元测试，可以低成本地将单元测试覆盖到多种编程语言。</p><p></p><p><a href=\"https://qcon.infoq.cn/202309/beijing/presentation/5380?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=0816&amp;utm_content=zhangshubo\">张树波</a>\"，清华大学硕士毕业，先后就职于 vivo、字节跳动。从事 NLP 算法多年，在智能单测、智能客服、语音助手等业务场景有丰富的落地经验。</p><p></p><p>相信通过张树波的分享，你将了解到如何评估通用大模型的单测生成能力，如何提升大模型单测生成效果，大模型落地工程实践、应用落地介绍与未来展望。你会收获到大模型在单测生成领域存在的问题、如何缓解，以及大模型在单测生成领域的应用实践。</p><p></p><p>除上述专题外，QCon 北京还将围绕 <a href=\"https://qcon.infoq.cn/202309/beijing/track/1556?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">FinOps&nbsp;落地</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1570?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">云原生</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1567?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">AIGC&nbsp;浪潮下的研发效能提升</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1558?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">业务安全技术</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1552?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">面向&nbsp;AI&nbsp;的存储</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1557?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">从&nbsp;BI&nbsp;到&nbsp;BI+AI，新计算范式下的大数据平台</a>\"等进行分享。</p><p></p><p>近 100 名讲师、近 30 个精彩专题、8 种交流活动，QCon 北京 2023，相约 9 月！现在购票，享 9 折特惠，立省 ¥880！咨询购票请联系 18514549229（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/33/33cbbbf20baa8b2a18db4f0681f159aa.jpeg\" /></p><p></p>",
    "publish_time": "2023-08-16 16:20:15",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "腾讯云MaaS最新升级：上架20多个主流模型，支持开发者一键调用",
    "url": "https://www.infoq.cn/article/pL2hKmgWdkGN42puH0qw",
    "summary": "<p>&nbsp;如何快速、低成本将AI大模型技术应用到实际业务场景，是新一轮人工智能技术浪潮中，保持核心竞争力的关键，也是国内越来越多的企业关切、探索方向。</p><p>&nbsp;</p><p>8月16日，由工业和信息化部、广东省人民政府共同主办的“2023中国数字经济创新发展大会”在广东省汕头市开幕。腾讯集团高级执行副总裁、云与智慧产业事业群CEO汤道生在大会上宣布了腾讯云MaaS最新升级。腾讯云TI平台已经全面接入Llama 2、Falcon、Dolly、Vicuna、Bloom、Alpaca等20多个主流模型，且支持系列模型的直接部署调用、应用流程简单、可全程低代码操作，成为国内第一批上架和支持开源模型的大模型厂商。腾讯云对这些模型进行了推理测试验证，从市场反馈、推理测试效果等角度进行了综合评估，确保模型可用性、易用性，可覆盖智能对话、文本生成、写作等多个不同场景，为企业、开发者提供了多种模型选择。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e3/e3e8dc28534443739838c469ed0280a9.png\" /></p><p></p><p>&nbsp;为了帮助企业客户解决成本、数据、安全等大模型实际落地难题，今年6月，腾讯云正式发布了行业大模型解决方案，依托腾讯云TI平台打造行业大模型精选商店，为企业客户提供涵盖模型预训练、模型精调、智能应用开发等一站式行业大模型解决方案。</p><p>&nbsp;</p><p>在TI平台内置的高质量行业大模型基础上，企业加入自己的场景数据，就可以快速生成自己的专属模型；同时，也可根据自身业务场景需求，“量体裁衣、按需定制”不同参数、不同规格的模型服务。</p><p>&nbsp;</p><p>目前，腾讯云已经为金融、文旅、传媒、政务、教育等10大行业提供了超过50个大模型解决方案。在文旅场景，国内某头部在线旅游公司利用腾讯云自然语言模型实现了个性化的定制旅行服务。用户只需提供自己的偏好、预算和大致路线，即可生成详细的旅行方案，并提前安排好每天的行程。在金融场景，某头部银行利用腾讯云TI-OCR实现了95%以上准确率的文件智能识别和关键词提取，将文件数据转化为结构化数据,全面提升运营效率。</p><p>&nbsp;</p><p>大模型时代，算力、网络、数据构成了底层基础设施的“铁三角”。除了提供一站式MaaS服务之外，腾讯云还为客户提供了HCC高性能计算集群、星脉高性能计算网络以及向量数据库等基础设施服务。</p><p>&nbsp;</p><p>同时，腾讯云还积极参与、推动行业大模型标准建设。早在2020年，腾讯就被选举为全国信标委人工智能分委会委员兼副秘书长，国家在推进包括人工智能新基建的过程中，腾讯作为核心成员，承担了很多标准制定工作及技术引领作用。前不久，作为推动行业大模型的核心单位，腾讯云就与中国信通院共同启动了行业大模型标准联合推进计划，并联合信通院牵头开展国内首个金融行业大模型标准，为金融行业智能化的高质量规范化发展提供重要支撑。</p>",
    "publish_time": "2023-08-16 16:39:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "智研研究院FlagEval大模型评测平台更新8月榜单：新增通义千问、Llama2等多个模型评测，并评测基座模型代码生成能力",
    "url": "https://www.infoq.cn/article/XGymEQM1lowdUkAoNoaJ",
    "summary": "<p>为推动大模型在产业落地和技术创新，今年6月智源研究院发布了“开源商用许可语言大模型系列+开放评测平台” 两大重磅成果，打造“大模型进化流水线”。</p><p>&nbsp;</p><p>FlagEval（天秤）是北京智源人工智能研究院推出的大模型评测体系及开放平台，旨在建立科学、公正、开放的评测基准、方法、工具集，协助研究人员全方位评估基础模型及训练算法的性能。</p><p>&nbsp;</p><p>FlagEval 大语言模型评测体系当前包含 6 大评测任务，20+评测数据集，80k+评测题目。除了知名的公开数据集 HellaSwag、MMLU、C-Eval等，FlagEval 还集成了包括智源自建的主观评测数据集 Chinese Linguistics &amp; Cognition Challenge (CLCC) ，北京大学等单位共建的词汇级别语义关系判断、句子级别语义关系判断、多义词理解、修辞手法判断评测数据集，更多维度的评测数据集也在陆续集成中。</p><p>&nbsp;</p><p>自6月9日上线以来，FlagEval在短短一个月内就已收到200+模型评测申请，并更新了首期SFT模型排行榜和大模型2023高考排行榜。在FlagEval 8月榜单最新榜单中，新增了通义千问、Llama2等多个模型评测，也新增了基座模型代码生成能力评测。</p><p>&nbsp;</p><p></p><h2>新增多个明星开源模型评测：Llama2 / Qwen / InternLM / MPT / Falcon</h2><p></p><p>&nbsp;</p><p>基座模型（Base Model）榜单：</p><p>&nbsp;</p><p>Qwen-7B、InternLM-7B 超越 Llama2，分列第一、第二名。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/f9/f93d68fac8656573cdaf078bc1321d19.jpeg\" /></p><p></p><p>有监督微调模型（SFT Model）榜单：</p><p>&nbsp;</p><p>InternLM-chat-7B 夺魁，刷新中英客观评测记录，悟道·天鹰AquilaChat 排名第二；</p><p>&nbsp;</p><p>Qwen-chat-7B 中英文客观评测结果欠佳，远低于其基座模型的客观评测表现；但在中文主观评测上，Qwen-chat-7B 以 75.4% 准确率排名第一，与第二名 ChatGLM2-6B（62.1%）拉开较大差距。</p><p>&nbsp;</p><p>备受关注的 Llama2 基座模型 7B、13B&nbsp;综合评测结果相比于第一代提升了 10%、25%；Llama2-Chat 7B、13B 英文能力突出，中文存在明显短板，中文主观评测准确率仅为 18.3%、22%，在 SFT 模型榜单上排名第三，仅次于 InternLM 和悟道·天鹰 Aquila。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/e4/e4e18deee7047958d31e8e92aa638c7d.jpeg\" /></p><p></p><h2>新增针对基座模型 HumanEval代码生成能力评测</h2><p></p><p>&nbsp;</p><p>近期，“代码生成能力”新晋成为大语言模型领域的热门话题，开源基座模型如 Llama2 的技术报告特别强调了“代码生成能力”作为其关键特性。&nbsp;</p><p>&nbsp;</p><p>基座模型强大的代码生成能力为后续的代码语料微调提供了坚实基础。因此，本期榜单引入了针对基座模型的 HumanEval 评测：</p><p>&nbsp;</p><p>Pass@1 的评测结果显示，国产大模型 Qwen、InternLM 超越 Llama2-13B，分列第一、第二名。</p><p>&nbsp;</p><p>Pass@100 结果显示，悟道·天鹰 Aquila-7B的表现接近 Llama-13B，但与第二代 Llama2-13B 相比仍有一定差距。</p><p>&nbsp;</p><p></p><blockquote>HumanEval 是由 OpenAI 编写发布的代码生成评测数据集，包含 164 道人工编写的Python编程问题，模型针对每个单元测试问题生成k（k=1,10,100）个代码样本，如果有任何样本通过单元测试，则认为问题已解决，并报告问题解决的总比例，即 Pass@k 得分。</blockquote><p></p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/68/68eb0749139e4bfecac6b8198915d267.jpeg\" /></p><p></p><p>&nbsp;</p><p>Falcon-7b HumanEval 评测结果出自 Meta Llama2 官方论文 ：</p><p>&nbsp;</p><p><a href=\"https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/\">https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/</a>\"</p><p>&nbsp;</p><p></p><blockquote>评测说明：在评测时，FlagEval 根据数据集的不同规模进行了自动化采样。更多评测结果请登录官网查看：<a href=\"https://flageval.baai.ac.cn/\">https://flageval.baai.ac.cn/</a>\"</blockquote><p></p>",
    "publish_time": "2023-08-16 18:37:48",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "吵翻了！到底该选 Rust 还是 Go，成2023年最大技术分歧",
    "url": "https://www.infoq.cn/article/UKdBmeZmr6ZCjmRVl7ce",
    "summary": "<p>2023年，我们有一千个学习Rust的理由。</p><p>&nbsp;</p><p>8 月 7 日，Rust基金会发布了 2022 年度 Rust <a href=\"https://blog.rust-lang.org/2023/08/07/Rust-Survey-2023-Results.html\">调查报告结果</a>\"，报告显示 Rust 采用率不断提高，超过90%的调查受访者表示自己是 Rust 用户；29.7% 的受访者表示，他们在工作中的大部分编码工作都使用 Rust，比上一年显着增加了 51.8%。</p><p>&nbsp;</p><p>毋庸置疑，Rust以其卓越的内存安全性和并发性能正日益成为开发者关注的焦点。然而，同样令人难以忽视的是Go，这门曾被评选为年度编程语言的相对比较“老牌”的选手。</p><p>&nbsp;</p><p>Go语言诞生于2009年，一开始就因其独特的并发模型和强大的性能优势而受到了极大关注。值得注意的是，跟Rust语言一样，<a href=\"https://www.youtube.com/watch?v=U2PpMZ7hWpg\">Go语言的创建者</a>\"也同样“讨厌”C++，并且Go同样也都是<a href=\"https://mp.weixin.qq.com/s/XOshX5yqxuBnynHsRgO2Ow\">云原生的主导语言</a>\"。</p><p>&nbsp;</p><p>而在Stack Overflow 2022开发者调查中，对于“让人爱恨交织的编程语言”这个问题，在7万份回复中，程序员们明显也更为偏爱Rust，86%的人表示喜欢Rust，而64%的人表示喜欢Go。面对Rust的火爆现状，一些开发者发出了灵魂提问：2023年，Go还值得学习吗？</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/40/4082dd12c4fa59c4050914a95c64a282.jpeg\" /></p><p></p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/58/58f4df4d37faa4122efb937deb61183a.jpeg\" /></p><p></p><p>&nbsp;</p><p>另外，这两天，到底是该选Rust还是选Go，也成为了Hacker News上的一个热门话题：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7d/7d078602d5b609d24dec46d543a4a15e.jpeg\" /></p><p></p><p>&nbsp;</p><p>一位挺Rust的网友说道：“我也为这个选择烦恼了很久。最终 Rust 胜出了。首先，我感觉Rust更接近于以前 Pascal 时代的东西，你可以控制一切；其次，如果 wasm 和相关技术大爆发，Rust将是一个更安全的选择；然后，我们已经有了 Python 用于快速开发，因此选择一些更极端的东西是有道理的，Go 在某种程度上处于中间地带。最后，Rust应用于内核且备受关注，所以不太可能会被淘汰。”</p><p>&nbsp;</p><p>另一位持反对意见的开发者则表示，“我从事 Go 开发已经快十年了，但最近我也尝试了下Rust。我认为目前有一些对 Rust 的强制性和误导性偏好，从我在各种初创公司的经验，包括我目前所在的公司来看，对于后端开发来说，Go是迄今为止最佳选择！注意，在性能、功能或其他方面……这两种语言非常非常相似！”</p><p>&nbsp;</p><p>不得不说的是，Go和Rust绝对都是优秀的编程语言。它们现代、强大、应用广泛，而且有着卓越的性能表现。但如果直接对比Go和Rust谁更好之类的，真的没啥意义，因为每种编程语言都代表着背后一系列深层次的权衡。不同的语言会针对不同的需求进行优化，因此我们在选择语言时，也应该考虑自己想要用它解决什么样的问题。所以我们将从Go和Rust语言的适用场景出发，探讨下Go与Rust的设计之“道”。</p><p>&nbsp;</p><p>虽然Rust和Go在语法和风格上差别很大，但它们都是构建软件的一流工具。下面咱们开始具体分析。</p><p>&nbsp;</p><p></p><h2>Go与Rust：相似性</h2><p></p><p>&nbsp;</p><p>Rust和Go有很多共同点，所以人们才经常把二者拿来相提并论。那它们有哪些共同目标？</p><p>&nbsp;</p><p></p><blockquote>Rust是一种低级静态类型的多范式编程语言，更多关注安全性和性能。—Gints Dreimanis</blockquote><p></p><p>&nbsp;</p><p>而：</p><p></p><blockquote>Go是一种开源编程语言，能够轻松构建起简单、可靠且高效的软件。—<a href=\"https://golang.org/\">golang.org</a>\"</blockquote><p></p><p>&nbsp;</p><p></p><h4>内存安全</h4><p></p><p>Go和Rust都属于重视内存安全的现代编程语言。在C和C++等旧语言发展的这几十年间，我们已经清楚地意识到，引发错误和bug的核心原因之一，就是对内存的不安全/不正确访问。</p><p>&nbsp;</p><p>于是Rust和Go各自给出了不同的解决思路，但二者的目标都是在内存管理方面更智能、更安全，帮助开发者编写出正确且性能极佳的程序。</p><p>&nbsp;</p><p></p><h4>快速、紧凑的可执行文件</h4><p></p><p>二者都属于编译语言，也就是说可以将程序直接翻译成可执行的机器代码，这样就能把程序部署成单一二进制文件。跟Python和Ruby等解释性语言不同，我们不需要随程序一同发布解释器和大量的库/依赖项。作为这个核心优势的直接体现，Rust和Go程序的运行速度往往比解释性语言更快。</p><p>&nbsp;</p><p></p><h4>通用型语言</h4><p></p><p>Rust和Go都属于功能强大且可扩展的通用编程语言，大家可以用它们开发出各种现代软件——从Web应用程序到分布式微服务，还包括嵌入式微控制器和移动应用等等。</p><p>&nbsp;</p><p>两者都拥有优秀的标准库和蓬勃发展的第三方生态系统，外加强大的商业支持与庞大的用户基础。二者已经存在多年，并将在未来几年继续保持旺盛的发展势头。如今，学习Go或者Rust将是非常合理的时间和精力投入方向。</p><p>&nbsp;</p><p></p><h4>务实的编程风格</h4><p></p><p>两者既不过多偏向函数式语言（例如Scala或Elixir），也不完全面向对象（例如Java和C#）。相反，虽然Go和Rust都具备函数式及面向对象编程的功能，但却始终强调务实取向——即以最合适的方式解决问题，而不是通过“意识形态”强迫大家用特定的方法做事。</p><p>&nbsp;</p><p>但如果您确实喜欢函数式编程风格，那Rust这边的相关工具选项更多，这也是Rust优于Go的一点。</p><p></p><blockquote>我们当然可以争论什么才是真正“面向对象”的语言。但公平地讲，C++、Java或者C#用户所期望的那种面向对象编程风格，在Go或者Rust中确实不存在。—Jack Mott</blockquote><p></p><p>&nbsp;</p><p></p><h4>大规模开发</h4><p></p><p>Rust和Go都为大规模编程提供不少有用功能，所以它们都能适应大开发团队作战和大体量代码库的现实需求。</p><p>&nbsp;</p><p>例如，C程序员多年来一直在争论应该把括号放在哪里，还有代码要不要用制表符或空格进行缩进；但Rust和Go早已使用标准格式化工具（Go有gofmt，Rust则是rustfmt）彻底解决了这些问题。它们会使用符合规范的风格自动重写你的代码。</p><p>&nbsp;</p><p>并不是说这种特定的格式有多精妙，而是Rust和Go程序员更加务实、宁愿选择统一的执行标准。</p><p></p><blockquote>gofmt的风格也许不是每个人的最爱，但gofmt却能帮到每一个人。—<a href=\"https://www.youtube.com/watch?v=PAAkCSZUG1c&amp;t=8m43s\">Rob Pike</a>\"</blockquote><p></p><p>&nbsp;</p><p>这两种语言的另一大优势，体现在构建管线上。二者都有优秀、内置且性能出色的标准构建与依赖项管理工具。就是说程序员不必跟复杂的第三方构建系统对抗，也用不着每隔几年就学习一种新系统。</p><p>&nbsp;</p><p></p><blockquote>我在职业生涯早期用的是Java和Ruby，所以编写Go和Rust代码一直让我有点畏惧、觉得自己掌握不了。但等到进入谷歌并看到用Go编写的服务时，我才真正松了口气，因为我发现它很容易构建和运行。Rust也是如此。虽然我只在小规模项目上进行过研究，但也看得出它的易用性。我希望那些能够无限配置的构建系统早点成为历史，现在的新语言都附带自己的专用构建工具而且能够开箱即用，这样不好吗？—<a href=\"https://samwho.dev/\">Sam Rose</a>\"</blockquote><p></p><p>&nbsp;</p><p></p><h2>到底选Rust还是Go？</h2><p></p><p>聊了这么多问题，再加上两种语言都设计得如此精良、功能如此强大，那这场比拼到底有没有结果？或者说，既然二者都是非常出色的选项，那为什么人们还会在社交媒体上出离愤怒，撰写长篇累牍的评论博文放出“白痴才用Rust”或者“Go根本不能算编程语言”之类的狠话？</p><p>&nbsp;</p><p>有些人当然只是为了宣泄情绪，但这显然无助于解决实际问题。至少在项目中该用哪种语言、或者该靠哪种语言闯荡编程世界这种事上，嗓门大显然无助于做出正确选择。</p><p>&nbsp;</p><p>下面咱们回到成年人的讨论，看看理性分析之下Rust和Go之间如何互有长短。</p><p>&nbsp;</p><p></p><h3>Go对Rust：性能</h3><p></p><p>之前已经提到，Go和Rust生成的程序运行速度都很快，因为它们会被编译成本机机器码，无需通过解释器或虚拟机这个步骤。</p><p>&nbsp;</p><p>但Rust的性能还是要更胜一筹，甚至能够与被称为业界性能标杆的C和C++相媲美。而且跟这些老牌语言不同的是，Rust还提供内存安全与并发安全机制，同时几乎不影响执行速度。Rust还允许开发者构建复杂抽象，又无需在运行时承受性能损失。</p><p>&nbsp;</p><p>相比之下，虽然Go程序的性能也不错，但其设计重心主要在于开发速度（包括编译）、而非执行程度。Go程序员更倾向于代码的清晰可读，所以运行速度要稍逊几分。</p><p>&nbsp;</p><p>Go编译器也不会花费太多时间来生成最高效的机器码，它更关心如何快速编译大量代码。所以在运行时基准测试中，往往是Rust程序要压Go程序一头。</p><p>&nbsp;</p><p>Rust的运行时性能还具有良好的一致性和可预测性，因为它没有使用垃圾收集。Go的垃圾收集器非常高效，而且做了优化以尽可能缩短暂停时长（随着Go新版本的发布，暂停时长也是越来越短）。但无论如何，垃圾收集总会给程序的行为方式带来一些不可预测性，而这对某些特定应用（比如嵌入式系统）而言可能很严重、甚至完全不可接受。</p><p>&nbsp;</p><p>因为Rust的目标是让程序员完全控制底层硬件，所以Rust程序都能深度优化以接近机器的最大理论性能。如此一来，Rust就在执行速度胜过其他一切的特定应用场景下成为最佳选项，此类用例包括游戏编程、操作系统内核、网络浏览器组件和实时控制系统等。</p><p>&nbsp;</p><p></p><h4>简单性</h4><p></p><p>如果一种编程语言过于难学、把大多数人都挡在了门外，那它的性能再强也没有意义。Go在设计上似乎就是刻意要跟C++等复杂度不断提升的语言区分开来：它语法极少，关键字也极少，就连功能都不多。</p><p>&nbsp;</p><p>这意味着Go语言很容易上手，稍微了解之后就能用它编写出各种程序。</p><p>&nbsp;</p><p></p><blockquote>Go确实非常容易学习。之前就经常听人提到这一点，但实际使用后我仍惊讶于它竟能快速提高工作效率。感谢Go语言、相关文档和工具，我只用了短短两天就编写出了有趣且可以提交的代码。—<a href=\"https://medium.com/better-programming/early-impressions-of-go-from-a-rust-programmer-f4fd1074c410\">Rust程序员对于Go语言的早期印象</a>\"</blockquote><p></p><p>&nbsp;</p><p>这里的重点就是“简单性”三个字。当然，简单并不代表容易。可一门小而简单的语言，学起来肯定要比大而复杂的语言要轻松。实现一种效果的方法并不多，所以高质量的Go代码看起来几乎都是一个样。这还带来另一个好处：我们可以快速理解某项自己不熟悉的服务到底在做什么。</p><p>&nbsp;</p><p><code lang=\"null\">fmt.Println(\"Gopher's Diner Breakfast Menu\")\nfor dish, price := range menu {\n    fmt.Println(dish, price)\n}</code></p><p></p><p>Go的核心本体虽然很小，但标准库却非常强大。也就是说，除了Go语法之外，我们的学习曲线还必须考虑到标准库这个部分。</p><p>&nbsp;</p><p>另一方面，把功能从语言转移到标准库，意味着大家只需要专注学习跟当前开发需求相关的库。</p><p>Go在设计上也充分考虑到大规模软件开发需求，能够有力支持大型代码库和开发团队。在这类场景下，新加入的开发者必须能够快速上手。为此，Go社区一直将程序的简单、明确、通用和直接放在首位。</p><p>&nbsp;</p><p></p><blockquote>使用Go，我们可以快速完成工作。Go是我用过的最高效的语言之一，它的座右铭就是：马上解决实际问题。—<a href=\"https://endler.dev/2017/go-vs-rust/\">Matthias Endler</a>\"</blockquote><p></p><p>&nbsp;</p><p></p><h4>功能</h4><p></p><p>&nbsp;</p><p></p><blockquote>Rust比其他几种编程语言支持更多复杂性，所以对应的实现范畴也更大些。—Devathon</blockquote><p></p><p>&nbsp;</p><p>Rust经过专门设计，包含多种强大且有用的功能，可以帮助程序员用最少的代码完成更多任务。例如，Rust的匹配功能就可快速编写出灵活且富有表达力的逻辑：</p><p><code lang=\"null\">fn is_prime(n: u64) -&gt; bool {\n    match n {\n        0...1 =&gt; false,\n        _ =&gt; !(2..n).any(|d| n % d == 0),\n    }\n}</code></p><p></p><p>但也因为Rust在设计上考虑得多，所以学起来也就更困难一点，特别是在起步阶段。但没关系，毕竟C++或者Java也有很多东西要学，甚至还无法提供内存安全之类的Rust高级功能。</p><p>所以批评Rust太过复杂的声音实在没啥道理：它在设计上就是在强调表达能力和丰富的功能，我们不可能在占了好处的同时又指望着它能那么简单纯粹。</p><p>&nbsp;</p><p>所以Rust当然有自己的学习曲线。但只要跨过了这道难关，后面就是一马平川了。</p><p>&nbsp;</p><p></p><blockquote>如果您已经准备好学习更复杂的语法和语义（以及更高的代码可读性门槛），并以此换取最高水平的性能表现，那Rust甚至足以跟C++和D分庭抗礼。—<a href=\"https://dave.cheney.net/2015/07/02/why-go-and-rust-are-not-competitors\">Dave Cheney</a>\"</blockquote><p></p><p>&nbsp;</p><p>Rust和Go之间虽然彼此借鉴了一些功能（比如说泛型），但公平地讲，Rust的功能还是更胜一筹，Go的功能相对要匮乏一点。</p><p>&nbsp;</p><p></p><h4>并发性</h4><p></p><p>大多数语言都为并发编程（即同时执行多项操作）提供某种形式的支持，但Go则是从头开始就为此而设计。Go不使用操作系统线程，而是提供一种轻量化的替代方案：goroutines。</p><p>每个goroutine都是个独立执行的Go函数，Go调度程序会将其映射至控制下的操作系统线程之一。也就是说，调度程序可以非常高效地管理大量并发goroutine，且只须使用有限数量的操作系统线程。</p><p>&nbsp;</p><p>因此，我们可以在单个程序中运行数百万个并发goroutine，又不必担心引发严重的性能问题。正因为如此，Go成为Web服务器和微服务等大规模并发应用场景下的完全解决方案。</p><p>&nbsp;</p><p>Go还为goroutines提供channels，这是一种快速、安全、高效实现数据通信和共享的方法。Go的并发设计水平确实很高，使用体验也相当轻松愉快。</p><p>&nbsp;</p><p>一般来说，并发程序的设计难度很大，在任何语言中构建起可靠且正确的并发程序都绝非易事。但由于在立项之初就考虑到这方面需求，所以Go中的并发编程机制已经做得尽可能简单且得到良好整合。</p><p>&nbsp;</p><p></p><blockquote>Go让我们能更轻松地构建起一个能精心解构的应用程序，这样的应用程序可以作为一组微服务进行部署，并充分发挥并发性优势。Rust也不是做不到，只是实现起来更难一些。从某种意义上讲，Rust更适合那些绝不允许因内存问题而引发安全漏洞的程序员；但相应的，他们在执行某些对其他语言（包括GO）来说较为简单的任务时，就得付出更多心力。—<a href=\"https://sdtimes.com/softwaredev/the-developers-dilemma-choosing-between-go-and-rust/\">Sonya Koptyev</a>\"</blockquote><p></p><p>&nbsp;</p><p>相比之下，Rust中的并发机制刚刚落地、还没有最终稳定，所以欢迎大家继续关注这个活跃的开发方向。这样也有好处，比如Rust的rayon库就提供一种非常优雅且轻量级的方法，能够将顺序计算转换为并行计算。</p><p>&nbsp;</p><p></p><blockquote>能有用于生成goroutine和使用channels的轻量级语法真的太棒了。这就是语法之力的直接体现，种种小细节也让Go的并发编程体验比其他语言好出一大截。—<a href=\"https://medium.com/better-programming/early-impressions-of-go-from-a-rust-programmer-f4fd1074c410\">Rust程序员对Go的早期印象</a>\"</blockquote><p></p><p>&nbsp;</p><p>虽然在Rust中实现并发程序可能不太容易，但仍然完全可行，而且这些程序还能获得Rust精心设计的内存安全保障。</p><p>&nbsp;</p><p>以标准库的Mutex类为例：在Go当中，我们可能会在访问某些内容前忘记获取互斥锁；但在Rust这边则完全不需要担心。</p><p>&nbsp;</p><p></p><blockquote>Go专注于把并发作为最核心的概念之一。这倒不是说我们就没法在Rust中实现跟Go类似的并发性效果，只是实现难度对于程序员多少是种考验。—<a href=\"https://dave.cheney.net/2015/07/02/why-go-and-rust-are-not-competitors\">Dave Cheney</a>\"</blockquote><p></p><p>&nbsp;</p><p></p><h4>安全性</h4><p></p><p>前文已经提到，Go和Rust都会以各自的方式防止各种常见的编程错误，特别是跟内存管理相关的问题。但Rust走得更远，可以说是不遗余力地保证大家不致搞出意料之外的安全纰漏。</p><p>&nbsp;</p><p></p><blockquote>Rust的编译器简直是严格到迂腐，它会检查我们使用的每个变量、引用的每个内存地址。它避免了潜在的数据竞争情况，还会通知你存在未定义行为。在Rust的世界中，并发和内存安全问题几乎不可能出现。—<a href=\"https://bitbucket.org/blog/why-rust\">为什么选择Rust?</a>\"</blockquote><p></p><p>&nbsp;</p><p>也就是说，Rust的编程体验跟几乎所有其他语言都有所不同，而且在刚刚接触时可能相当具有挑战。但在不少开发者看来，这份付出显然物有所值。</p><p>&nbsp;</p><p></p><blockquote>对我来说，Rust最大的优势就是编译器成了我的好助手，它不会放过任何检测得到的bug（说真的，有时候我感觉它就像会魔法）。—Grzegorz&nbsp;Nosek</blockquote><p></p><p>&nbsp;</p><p>包括Go在内，很多语言也提供帮助程序员避免错误的工具，但Rust把这种效果提升到了新的水平。很多不正确的程序甚至根本没办法编译。</p><p>&nbsp;</p><p></p><blockquote>在Rust中，各种库工具都能帮助程序员防止用户犯错。Rust允许我们指定一段数据，然后保证它不归属于任何其他事物、也不会被任何其他事物所篡改。我想不起以往还有哪种语言会提供这么多防止意外误用的工具，这种感觉堪称美妙。—<a href=\"https://samwho.dev/\">Sam Rose</a>\"</blockquote><p></p><p>&nbsp;</p><p>“与借用检查器作斗争”是Rust新人们必须要过的一关，但在大多数情况下，检查器并不是真正的敌人。它发现的问题确实是代码中的真实bug（或者至少是潜在bug）。它可能迫使我们从根本上重构自己的程序来避免此类问题——如果各位确实把正确性和可靠性当作首要任务，那这种严格要求显然是件好事。</p><p>&nbsp;</p><p>换个角度想，不改变编程方式的新语言，能叫新语言吗？而且在使用其他语言时，Rust教会我们的安全思维同样意义重大。</p><p>&nbsp;</p><p></p><blockquote>如果大家选择了Rust，往往是因为要使用它提供的保障性设计：关于空指针/数据竞争的安全性、可预测的运行时行为，还有对硬件的完全控制。如果这些对你来说毫无意义，那确实没必要非得使用Rust。毕竟这些好处背后是有代价的：上手很费劲。你得改掉坏习惯并掌握新概念。刚开始的时候，大家都会被借用检查器折磨得死去活来。—<a href=\"https://endler.dev/2017/go-vs-rust/\">Matthias Endler</a>\"</blockquote><p></p><p>&nbsp;</p><p>上手Rust编程模型的实际难度，可能取决于大家之前用过哪些其他语言。Python或者Ruby程序员可能觉得Rust限制太多，但其他人可能觉得这种清晰明确的约束也不错。</p><p>&nbsp;</p><p></p><blockquote>如果你是一名C或者C++程序员，曾经花几个礼拜在语言中查找内存安全bug，那你一定会爱上Rust。于是“跟借用检查器作斗争”就变成了“编译器还能这么用？爽！”—Grzegorz&nbsp;Nosek</blockquote><p></p><p>&nbsp;</p><p></p><h4>规模化</h4><p></p><p></p><blockquote>如今的服务器程序包含着数千万行代码，由成百上千名程序员编写而成，并且几乎每天都在更新。Go在设计和开发上，充分考虑到了此类环境下的工作效率提升需求。Go的设计考量因素包括严格的依赖项管理、软件架构随系统增长的适应性，还有跨组件边界的健壮性。—<a href=\"https://talks.golang.org/2012/splash.article\">Rob Pike</a>\"</blockquote><p></p><p>&nbsp;</p><p>当大家独自或者在小团队中解决问题时，要选简单的语言还是丰富的语言纯属个人喜好。但随着软件规模的扩大、复杂度的提升、团队的膨胀，两类语言之间的差异才开始真正显现出来。</p><p>&nbsp;</p><p>对于大型应用程序和分布式系统，代码执行速度的重要性往往低于开发速度：像Go这种刻意强调精简设计的语言能够缩短开发新手的适应时间，也让他们能更快参与到大型代码库的贡献当中。</p><p>&nbsp;</p><p></p><blockquote>使用GO语言，初级开发者往往更容易提高工作效率，但中级开发者则更难引入复杂的抽象并因此导致问题。正因为这种特性，在企业软件开发领域，Rust的吸引力往往不及Go。—<a href=\"https://kristoff.it/blog/why-go-and-not-rust\">Loris Cro</a>\"</blockquote><p></p><p>&nbsp;</p><p>在涉及大规模软件开发时，明确易读总是比精巧优雅更重要。Go的局限性实际使其比Rust等更复杂、更强大的语言，要更适应企业和大型组织的需求。</p><p>&nbsp;</p><p></p><h3>Rust与Go：差异之处</h3><p></p><p>虽然Rust和Go都是高人气且得到广泛应用的现代语言，但二者间并不是真正的竞争对手，因为它们所面向的用例可以说完全不同。</p><p>&nbsp;</p><p>Go的整个编程方法就跟Rust完全不同，这些特性一方面特别适合某些人，但另一方面也会彻底激怒某些人。这很正常，因为如果Rust和Go都在以基本相似的方式解决基本相同的问题，那我们干嘛还需要两种独立的语言？</p><p>&nbsp;</p><p>那么，我们能不能从Rust和Go采取的方法入手，解读它们各自的本质呢？下面就一起来试试。</p><p>&nbsp;</p><p></p><h4>垃圾收集</h4><p></p><p>“要垃圾收集，还是不要垃圾收集”永远是个没有正确答案的问题。一般来说，垃圾收集和自动内存管理能帮助我们快速、轻松地开发出可靠且高效的程序。所以对某些开发者来说，这些都是必不可少的功能。</p><p>&nbsp;</p><p>但也有人认为，垃圾收集和它带来的性能开销与全局暂停，会导致程序在运行时的行为变得不可预测，同时引入不可接受的延迟。这话当然也有道理。</p><p>&nbsp;</p><p></p><blockquote>Go跟Rust这两种语言可以说截然不同。尽管二者都可以被简单描述成系统语言或者C的替代品，但它们的目标和应用场景、语言设计风格与功能优先级确实差异巨大。垃圾收集就是一大核心差异因素。Go中的垃圾收集让语言变得更简单、更小巧也更易于理解。Rust不设垃圾收集则让它速度极快（这一点特别适合那些不仅要求高吞吐量、更要求低延迟的开发者），同时也实现了Go根本不可能做到的一系列功能与编程模式（至少是在不牺牲性能的前提下）。—PingCAP</blockquote><p></p><p>&nbsp;</p><p></p><h4>贴近硬件</h4><p></p><p>计算机编程的发展史，可以说是一段日益复杂的抽象发展历程。它让程序员们既能解决问题，又不用太多关注底层硬件的实际运行方式。</p><p>&nbsp;</p><p>这种设计让程序更易于编写、更具可移植性。但对于其他一些程序来说，访问硬件及精确控制程序的执行方式反而更加重要。</p><p>&nbsp;</p><p>Rust的目标就是让程序员能“贴近硬件”，夺回更多控制权；而Go则抽象掉了架构细节，让程序员更贴近问题。</p><p>&nbsp;</p><p></p><blockquote>两种语言各有不同的应用范围。Go擅长编写微服务和典型的“DevOps”任务，但它并不属于系统编程语言。Rust在强调并发性、安全性及/或性能的任务中更为强大，可学习曲线也确实比Go更陡峭。&nbsp;—<a href=\"https://endler.dev/2017/go-vs-rust/\">Matthias Endler</a>\"</blockquote><p></p><p>&nbsp;</p><p></p><h4>性能为先</h4><p></p><p>其实对大多数程序来说，性能的重要性是不及代码可读性的。但如果某些项目确实是以性能为先，那Rust中的很多设计权衡，将帮助大家把代码的执行速度一路推向极限。</p><p>&nbsp;</p><p>相比之下，Go更关心代码简单性，甚至愿意为此牺牲一些运行时性能。但Go的构建速度无与伦比，这对大规模代码项目来说往往更加重要。</p><p>&nbsp;</p><p></p><blockquote>Rust的执行速度优于Go。在基准测试中，Rust速度确实更快，某些情况下甚至能快出一个数量级。但在选择Rust语言之前，请先认清一点：Go在多数基准测试中也没有落后太多，而且也仍然保持对Java、C#、JavaScript和Python等语言的性能优势。如果你需要的是顶级性能，那么在这两种语言中任意选择都可以，速度表现绝不会令人失望。另外，如果你正在构建一款处理高强度负载的Web服务，而且要求能够纵向/横向灵活扩展，两款语言也都能满足需求。&nbsp;—<a href=\"https://codeburst.io/should-i-rust-or-should-i-go-59a298e00ea9\">Andrew Lader</a>\"</blockquote><p></p><p>&nbsp;</p><p></p><h4>正确性</h4><p></p><p>另一方面，如果不强求程序永不出错，那取舍以会不同。大多数代码都不会考虑到长期使用，但某些程序也确实在生产环境中多年运行。</p><p>&nbsp;</p><p>面对这些现实情况，也许我们有必要投入一点额外的时间，来开发并保证程序能够正确、可靠运行，且未来不致引发沉重的维护负担。</p><p>&nbsp;</p><p>Go和Rust都能帮助大家编写出正确的程序，只是具体方式各有不同：Go提供出色的内置测试框架，而Rust则专注通过借用检查器消除运行时bug。</p><p>&nbsp;</p><p></p><blockquote>我的看法是：对于明天就得发布的代码，用Go；如果是未来五年内必须能稳定运行的代码，那么选Rust。—Grzegorz&nbsp;Nosek</blockquote><p></p><p>&nbsp;</p><p>虽然Go和Rust都足以支撑起严肃的开发项目，但大家最好还是能充分了解它们的各种特性和优势。</p><p>&nbsp;</p><p>总之，别人的想法并不重要：只有你自己能决定哪种编程语言更适合你的团队及项目需求。</p><p>&nbsp;</p><p></p><blockquote>如果你想加快开发速度，比如说你有很多不同服务需要编写，或者开发团队本身规模庞大，那么Go语言肯定是正确答案。Go特别关注并发性设计，而且会敏锐地揪出不安全的内存访问行为（Rust也可以），但又不强迫你逐一管理每处细节。Go快速而强大，但它的核心亮点还是帮助开发人员摆脱困境、专注于简单性和统一性。在另一方面，如果你需要竭尽全力发挥每一丝性能空间，那Rust才是最理想的选择。—<a href=\"https://codeburst.io/should-i-rust-or-should-i-go-59a298e00ea9\">Andrew Lader</a>\"</blockquote><p></p><p>&nbsp;</p><p></p><h2>总结</h2><p></p><p>希望这篇文章能帮助大家理解Rust和Go的各自亮点。如果可能的话，各位最好能多少体验一下这两种语言，因为它们在任何技术道路上都非常有用，哪怕对业余编程爱好者也是如此。</p><p>&nbsp;</p><p>但如果您的时间只搞认真钻研一门语言，那请千万先把Go和Rust各自的专长和倾向性搞清楚，之后再做选择。</p><p>&nbsp;</p><p>当然，关于编程语言的知识只是成就一名成功软件工程师的很少一部分。除了编程之外，工程师们还得精通设计、工程、架构、沟通和协作。只要大家能把后面这几样做好，那无论你选择哪种编程语言，都将成为一名出色的软件工程大牛。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://bitfieldconsulting.com/golang/rust-vs-go\">https://bitfieldconsulting.com/golang/rust-vs-go</a>\"</p><p><a href=\"https://news.ycombinator.com/item?id=37107052\">https://news.ycombinator.com/item?id=37107052</a>\"</p><p><a href=\"https://thenewstack.io/developers-most-likely-to-learn-go-and-rust-in-2023-survey-says/\">https://thenewstack.io/developers-most-likely-to-learn-go-and-rust-in-2023-survey-says/</a>\"</p><p><a href=\"https://blog.rust-lang.org/2023/08/07/Rust-Survey-2023-Results.html\">https://blog.rust-lang.org/2023/08/07/Rust-Survey-2023-Results.html</a>\"</p>",
    "publish_time": "2023-08-16 21:44:09",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]