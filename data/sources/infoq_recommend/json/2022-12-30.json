[
  {
    "title": "亚马逊云科技为蓝绿及金丝雀策略引入CloudFront持续部署",
    "url": "https://www.infoq.cn/article/LW5JeoLR0Jcl1ktRNV0o",
    "summary": "<p>亚马逊云科技宣布CloudFront现已支持<a href=\"https://aws.amazon.com/about-aws/whats-new/2022/11/amazon-cloudfront-continuous-deployment-support/\">持续部署</a>\"，可用部分实时流量测试并验证配置变化。AWS内容交付网络的新功能简化了蓝绿及金丝雀部署策略。</p><p></p><p><a href=\"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Introduction.html\">CloudFront</a>\"的持续部署是为部署后验证、向后兼容，仅使用小部分请求验证新功能等场景而设计。AWS高级解决方案架构师<a href=\"https://www.linkedin.com/in/joe-v-3428806/\">Joe Viggiano</a>\"，首席解决方案架构师<a href=\"https://www.linkedin.com/in/johnsoncarlp/\">Carl Johnson</a>\"，以及首席产品经理Vishal Anand如此<a href=\"https://aws.amazon.com/blogs/networking-and-content-delivery/use-cloudfront-continuous-deployment-to-safely-validate-cdn-changes/\">解释</a>\"：</p><p></p><blockquote>当前行业上对于测试CDN配置变化已有的解决方案是需要在客户端注入自定义头信息、覆盖客户端DNS设置，或者实施单独的测试域。这一切都让大规模测试充满挑战。客户可能会不得不在应用程序中建立复杂的功能标志（……）这种方式缺乏可扩展性，且不能百分百引导生产流量，无法确保新引入的变化不会对工作负载产生负面影响。</blockquote><p></p><p>&nbsp;</p><p>借助CloudFront的持续部署，客户向主要分布中发送请求，CloudFront基于<a href=\"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/continuous-deployment.html\">持续部署策略</a>\"中的权重或头配置，将其中部分请求路由到暂存分布。基于权重的配置会将特定百分比（最高可至15%）的Viewer请求路由到暂存分布，而基于头的配置则会根据特定HTTP头将请求路由到暂存分布。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/78/7830cd8341e2182a6a59a1e28dc0bee9.png\" /></p><p></p><p>来源：<a href=\"https://aws.amazon.com/blogs/networking-and-content-delivery/use-cloudfront-continuous-deployment-to-safely-validate-cdn-changes/\">https://aws.amazon.com/blogs/networking-and-content-delivery/use-cloudfront-continuous-deployment-to-safely-validate-cdn-changes/</a>\"</p><p>&nbsp;</p><p>两种方式都可用于测试同一部署，以基于头的配置验证已知测试用户和设备的第一条变更，随后在借助基于权重的配置引入生产流量。这一功能通过将Viewer会话与环境绑定，让监控标准及实时日志变得可行，一旦变更对服务有影响，可即时回滚回先前的配置。Viggiano、Johnson及Anand写道：</p><p>&nbsp;</p><p></p><blockquote>在需要进行测试时，CloudFront现在允许创建一个与生产分布相关联的暂存分布 。可在暂存分布中修改原点、原点组、缓存行为、客户错误响应、默认根对象、日志和地理限制等设置，未来还会增加更多可更改的设置项。</blockquote><p></p><p>&nbsp;</p><p>开发者们对于AWS CDN上对蓝绿及金丝雀部署的支持期盼已久，无论是在<a href=\"https://www.reddit.com/r/aws/comments/ix8l52/what_is_the_status_on_doing_bluegreen_deployments/\">红迪</a>\"还是<a href=\"https://serverfault.com/questions/714742/blue-green-deployments-with-cloudfront\">Server Fault</a>\"上都有很多讨论串。云顾问及AWS无服务英雄<a href=\"https://www.linkedin.com/in/theburningmonk/\">Yan Cui</a>\"则对这个<a href=\"https://twitter.com/theburningmonk/status/1595054650629427206\">名称</a>\"发出来质疑：</p><p></p><blockquote>非常赞，但我不太理解为什么要叫CloudFront“持续部署”，而不是叫CloudFront金丝雀部署之类的名字。</blockquote><p></p><p>&nbsp;</p><p>主要分布和暂存分布不共享缓存。在资源使用高峰期，CloudFront可能会无视持续部署策略，将所有请求全部发送到主要分布。基于当前限制，CloudFront持续部署不支持<a href=\"https://www.infoq.com/news/2022/08/amazon-cloudfront-http3/\">启用了HTTP/3</a>\"的分布。</p><p>&nbsp;</p><p>该新功能可在所有AWS边缘，通过控制台、SDK、CLI或CloudFormation模板使用。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/11/aws-cloudfront-continuous/\">AWS Introduces CloudFront Continuous Deployment for Blue-Green and Canary Strategies by Renato Losio</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/IjopWm7HUlP8qftzbOB3\">AWS Lambda 现可支持 Node.js 18 运行时</a>\"</p><p><a href=\"https://www.infoq.cn/article/O9jijEFIBtaaeecQCe8K\">亚马逊云科技向 Well-Architected Framework 添加容器透镜</a>\"</p>",
    "publish_time": "2022-12-30 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "不管扎克伯格怎么想，虚拟世界都不需要 VR",
    "url": "https://www.infoq.cn/article/N6SrCwYGgA4rwSyW6VFE",
    "summary": "<p>扎克伯格的<a href=\"https://www.infoq.cn/article/j4AToos49jT09GQ5TCkr\">元宇宙梦</a>\"给投资者带来了噩梦。他每年在“具身化的互联网”（embodied internet）上押注 100 亿美元，之后 Meta 市值大幅下跌，季度营收首次出现下滑，增长前景黯淡。Meta公司推出的元宇宙平台Horizon Worlds是他在这个领域的首次尝试，这只能让人更加担心。由于采用范围不广、持续存在的错误和滑稽的虚拟形象，该社交平台常常遭到人们的嘲讽。</p><p></p><p>尽管批评声越来越大，扎克伯格仍然对让 Facebook 成为一家“元宇宙公司”持乐观态度。但是，英国独角兽企业 Improbable 的首席执行官 Herman Narula 认为，Meta 的愿景忽略了一个根本问题。“问题在于 VR（虚拟现实），”Narula 近日在斯坦福大学表示，“在硬件上的赌注太高了，与元宇宙的主要价值主张相去甚远，而且很难看出他们如何收回投资。”</p><p></p><h2>元宇宙需要“存在感”</h2><p></p><p></p><p>Narula 有自己的元宇宙项目。他的公司花了十年的时间来构建沉浸式的虚拟世界，从为美国陆军模拟战争游戏，到为 1450 名韩国流行音乐爱好者举办的互动派对。他还写了一部名为《虚拟社会》（Virtual Society）的著作，对元宇宙的理论体系进行了简要的阐述。在 Narula 的心目中，它包含了一个可以让人不用戴着头盔就能通过的数字体验网络。取而代之的是，只需通过一部手机或者一台电脑就能进入这些网络。</p><p></p><p>Narula 承认 VR 给人以强烈的沉浸感。但是，他认为，元宇宙还需要更重要的东西：存在感。</p><p></p><p>他将沉浸感描述为“世界是真实的感觉”。与之相对的是，存在感是“世界认为你是真实的感觉”。要想营造出这种感觉，用户的行为必须在整个虚拟世界中产生反应和涟漪。</p><p></p><p>Narula 断言，存在感不需要 VR。作为证据，他列举出了《Minecraft》《Roblox》和《Fortnite》这些“原始元宇宙”游戏，虽然这些游戏画面很粗糙，但是却能让人产生一种存在感，让这些游戏成为全球最流行的游戏之一。</p><p></p><p>根据 Narula 的说法，扎克伯格基于 VR 的元宇宙存在几个问题。其中之一是成本：新款 <a href=\"https://www.infoq.cn/article/KOcaWVjk3jdAmOFUYEpU\">Quest Pro VR 头盔</a>\"的售价高达 1500 美元。技术上的改进——包括眼球追踪和混合现实功能——带来了很大的提升，但由于价格的原因，它们对大多数客户来说无法企及。</p><p></p><p>扎克伯格已经承认了这个障碍。他形容这顶新的头盔是一种“专业消费者”设备，并计划在明年推出消费者级别的版本。调查显示，公众并不会一窝蜂地涌入购买。</p><p></p><p>Meta 公司也采取了初步措施来整合主流设备。该公司计划推出 Web 和移动版本的 Horizon Worlds，让用户无需戴 VR 头盔就能进入。然而，这有可能会导致一种双重体验。</p><p></p><h2>加速虚拟引擎</h2><p></p><p></p><p>自然，Narula 有他自己的计划来制造存在感。他认为 Improbable 是一个无与伦比的平台，它是元空间的一个重要组成部分：容量。为了支持这一观点，Narula 引用了一项名为每秒通信操作（OPS）的指标。</p><p></p><p></p><blockquote>这是元宇宙的马力。（译注：horsepower，俗称匹，是一个古老的功率单位。今日除了航空、造船与汽车工业提及内燃机的功率、空调的制冷性能以外，在其他领域较为少用马力这个单位，而会使用标准的国际功率单位瓦特。）</blockquote><p></p><p></p><p>每秒的操作数反映了在虚拟世界中可以同时发生多少不同的事情。 Improbable 的联合创始人 Rob Whitehead 形容这是“虚拟世界的‘马力’”。</p><p></p><p>Whitehead 将每秒操作的大致计算公式描述如下：</p><p></p><p>数学公式: </p><p></p><p>为了说明其工作原理，他引用了一款名为《反恐精英：全球攻势》（Counter-Strike: Global Offensive）的竞技射击游戏。如果游戏有 10 个玩家，那么他们都可以看到对方，而服务器每秒发送玩家更新 64 次，计算结果将是 数学公式:  每秒操作数。</p><p></p><p>随着玩家、密度和保真度的增加，这个数字会急剧上升。例如，EVE Online 的 8000 名玩家的对战中，如果每秒只发送 0.1 次玩家更新，每秒将产生 640 万次操作。</p><p></p><p>对比之下，Improbable 声称它现在每秒可以处理 20 亿次操作。</p><p></p><p>每秒的操作次数是比较虚拟世界的关键指标——你会听到我和 Narula、M² 经常使用这个指标。你可以将它想象成虚拟世界的“马力”——它所拥有的原始连接能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e0/e0d0ca0340131c952f54ff85a6641aa8.png\" /></p><p></p><p>为了解释虚拟世界的计算复杂性，Whitehead 提出了一个叫做“元宇宙狙击手问题”的难题。</p><p></p><p>“当你放大狙击步枪的瞄准镜时，你需要能够高保真地看到遥远的世界，才能获得精准的射击，”他说。</p><p></p><p>“对于 60~100 名玩家的传统游戏来说，这是很难做到的，因为架构的网络需求呈四次方扩展：200 名玩家的游戏的网络需求是 100 名玩家的 4 倍。因此，要让（成千上万的）玩家体验元宇宙，你需要从根本上改变技术。”</p><p></p><h2>相互连接的世界</h2><p></p><p></p><p>VR 的主导地位并不是 Narula 对 Meta 的唯一问题。和很多批评者一样，他也为该公司，或者其他任何一家公司掌控元宇宙感到担忧。为了避免出现这个可怕的前景，Narula 想将另外一种备受争议的技术整合起来：区块链。</p><p></p><p>基于区块链的<a href=\"https://www.infoq.cn/article/uKVmglLJtPzMtxUs4uEd\">元宇宙</a>\"的支持者指出了两个关键好处：去中心化和互操作性。前者来自在分布式账本上存储数据，不受任何一家公司控制。同时，互操作性是通过加密保护数据交换而实现的。例如，你的虚拟角色的衣服，可以在不同的虚拟世界之间安全地移植。</p><p></p><p></p><blockquote>这就是它不只是一个游戏的原因。</blockquote><p></p><p></p><p>区块链并不是提供这种可移植性的唯一手段。另外，公司可以就促进不同平台之间的数字传输的规则和系统达成一致。然而，Web3 的倡导者警告说，这样做会增强大型科技公司对我们的数据的掌控。</p><p></p><p>然而，这只是他们必须要赢得的一个论点。区块链的推动者还必须解决对该技术的可扩展性、环境影响以及对加密货币现金掠夺倾向的担忧。尽管如此，Narula 看起来很有信心，它的好处会比它的消极影响更大。</p><p></p><p>这位 34 岁的人设想，区块链能够实现世界之间的传输。公司将通过分享客户来建立元宇宙的业务，而用户将享受跨平台的有意义的体验。根据 Narula 的说法，VR 和 AR 与所有这些互动没有太大的联系。</p><p></p><p>“它们完全可以发挥作用，构建更具吸引力的体验，但它们并没有颠覆。”他说，“颠覆性的是——这些世界发生的事件可能会在一瞬间变得更加重要。这就是在我们和这些体验之间创造不同关系的原因。所以，它不只是一个游戏。”</p><p></p><p>作者简介：</p><p>Thomas Macaulay， TNW 媒体撰稿人。</p><p></p><p>原文链接：</p><p>https://thenextweb.com/news/metaverse-doesnt-need-vr-improbable-ceo-herman-narula-meta-zuckerberg</p>",
    "publish_time": "2022-12-30 09:51:43",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "马斯克关闭Twitter加州数据中心，员工还要自带卫生纸上班",
    "url": "https://www.infoq.cn/article/uuXOhcwzyFGzArMDdAsR",
    "summary": "<p>根据<a href=\"https://www.nytimes.com/2022/12/29/technology/twitter-elon-musk.html\">《纽约时报》</a>\"报道，埃隆·马斯克(Elon Musk)已经将Twitter成本缩减到维持基本运营的水平，员工们“零基础预算”，任何支出都要证明是合理的。</p><p>&nbsp;</p><p>据悉，在平安夜前夕，纳斯克飞往加利福尼亚州的萨克拉门托——Twitter三大主要计算存储设施之一的所在地——切断了维持该社交网络平稳运行的服务器。有知情人士表示，虽然有员工担心关闭这些服务器可能导致各种问题，但节省资金是首要任务。</p><p>&nbsp;</p><p>关闭数据中心是马斯克为稳定Twitter财务状况而采取的众多激进措施之一。过去几周，Twitter已经<a href=\"https://www.infoq.cn/article/NmgXYDUGCySPL8lqkik1\">停止支付数百万美元的办公室租金和服务费用</a>\"，马斯克要对这些协议进行重新谈判或者干脆终止。据悉，该公司已停止支付西雅图办公室的租金，这导致该公司面临被驱逐的局面。清洁和安全服务被削减，某些情况下，员工不得不自己带卫生纸到办公室。</p><p>&nbsp;</p><p>去年10月底，马斯克以440亿美元的价格收购了这家社交网络公司，这样让马斯克背上了巨额债务，他每年需要支付约10亿美元的利息。上周，马斯克将Twitter比作“一架引擎着火、控制失灵、高速冲向地面的飞机”。马斯克表示，到2023年，Twitter将面临大约30亿美元的“负现金流状况”，原因是广告环境低迷以及债务支付等成本增加。“这就是为什么我在过去五周疯狂削减成本。”</p><p>&nbsp;</p><p>但这些削减措施可能会产生一些后果。周三，世界各地的用户报告<a href=\"https://www.infoq.cn/article/SEMJIMViDzxqUQ4gebBT\">Twitter服务中断</a>\"。一些用户反馈 Twitter 出现很多奇怪的错误消息，比如看到空白页面、无法回复推文或关注热门话题，还有人被迫退出登陆。有熟悉Twitter基础设施的人士表示，如果萨克拉门托的设施仍在运行，它就可以在其他数据中心出现故障时提供备份计算能力，从而帮助缓解问题。现在，Twitter 将只剩下位于亚特兰大和俄勒冈州波特兰的数据中心。</p><p>&nbsp;</p><p>根据《纽约时报》得到的一份内部文件，自11月初以来，马斯克一直试图节省约5亿美元的非劳动力成本。收购完成后，他还裁掉或解雇了公司近75%的员工。</p><p>&nbsp;</p><p>成本削减一直由Steve Davis和Jared 负责，Davis是马斯克的隧道挖掘初创企业the Boring Company的负责人。</p><p></p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.nytimes.com/2022/12/29/technology/twitter-elon-musk.html\">https://www.nytimes.com/2022/12/29/technology/twitter-elon-musk.html</a>\"</p>",
    "publish_time": "2022-12-30 10:02:42",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "「AI推理」加速核心原理解析与工程实践 | 云原生 AI·技术公开课 第三期",
    "url": "https://www.infoq.cn/article/mPJzSMJ53meqBkFT2Nku",
    "summary": "<p>直播看点：<br />\n1、了解AI推理加速的核心原理、评估指标以及相应的优化方法<br />\n2、了解百度百舸平台的AI推理加速套件AIAK-Inference的工程实践效果</p>",
    "publish_time": "2022-12-30 12:54:18",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "「AI训练」加速原理解析与工程实践分享 | 云原生 AI·技术公开课 第二期",
    "url": "https://www.infoq.cn/article/tQqPUkoJ90bVbVPbW2Ee",
    "summary": "<p>直播看点：</p>\n<ol>\n<li>系统性了解各类 AI 模型训练方案下的 AI 训练瓶颈</li>\n<li>全面掌握 AI 加速训练的各种方法的原理</li>\n<li>了解百度百舸平台的 AI 训练加速套件 AIAK-Training 的工程实践效果</li>\n</ol>",
    "publish_time": "2022-12-30 12:54:21",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "云原生AI的资源调度和AI工作流引擎设计分享 | 云原生 AI·技术公开课 第一期",
    "url": "https://www.infoq.cn/article/Ga3SF30ulhwVsSc8Hbyh",
    "summary": "<p>直播看点：</p>\n<ul>\n<li>了解单机单卡、多机多卡、多机多卡等场景下云原生 AI 的资源调度方法。</li>\n<li>了解 AI 工作流引擎 PaddleFlow 打通底层资源和上层业务的架构和细节，提升 AI 工程效率。</li>\n</ul>",
    "publish_time": "2022-12-30 12:54:23",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "视觉大模型训练与推理优化 | 云原生 AI·技术公开课 第四期",
    "url": "https://www.infoq.cn/article/26yuRpJhQoP9INUveN4O",
    "summary": "<p>直播看点：<br />\n1、讲解如何结合profiling工具，发现训练与推理的性能瓶颈；<br />\n2、介绍结合GPU产品特点，利用算子融合、低精度等技术，以及Faster Transformer最佳实践，提升性能并加快吞吐。</p>",
    "publish_time": "2022-12-30 12:54:25",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "面向对象分析与设计的底层逻辑",
    "url": "https://www.infoq.cn/article/6e3c70d130a5769720178c79c",
    "summary": "<p>作者：高福来   阿里全球化业务平台团队</p><p></p><p></p><blockquote>在面向对象出现之前，已有面向过程的分析方法，那为什么面向对象被提出了呢？究其本质，人们发现面向过程并非按照人正常认识事物的方式去分析软件。面向过程是一种归纳的分析方法，由外到内的过程；面向对象是一种演绎的分析方法，由内到外的过程。本文将为大家分享面向对象分析与设计的底层逻辑。</blockquote><p></p><p></p><p></p><h1>一、面向对象是符合人认识事物的基本方法</h1><p></p><p></p><p></p><h2>1.1 人是怎么认识事物的</h2><p></p><p></p><p>在面向对象出现之前，已有面向过程的分析方法，为什么面向对象被提出了呢？究其本质原因，人们发现面向过程并不是按照人正常认识事物的方式去分析软件，那么人究竟是怎么认识事物的呢，Yourdon 在《面向对象的分析》一书中提到，人类认识事物是遵循分类学的原理，分类学主要包含三点：区分对象及其属性；区分整体对象及其组成部分；不同对象类的形成及区分。</p><p></p><p>我们现在可以回想下我们认识事物的过程，是不是和分类学所提到的 3 个要点很相似，看到一个事物，大概会感知到它的组成结构是怎样的，形状是怎样的，属于什么分类。所以，人认识事物是以对象的视角切入的，然后赋于对象具体的概念，比如苹果、梨子、汽车等等概念名称。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a0/a0ed19160e2da5b09749e545c05eff46.png\" /></p><p></p><p></p><h2>1.2 分类与分层的两种思维</h2><p></p><p></p><p>我们面对的现实世界是非常复杂的，应对复杂事物的有一个重要的方法即是抽象，抽象在实际应用过程中，又体现在两种方法上：分层和分类。分类即是将有差异的事物归类到不同的分组中，正如我们常听到的\"物以类聚、人以群分\"的道理一样，产生分类的原因有两点：一点是事物间的关联紧密程度，不需要将所有的事物都耦合在一起；另一点是人掌握事物是有局限的，只能掌握少量的要点，比如 5~7 个要点，超过了容易忘记。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/57/57b6975e1a3462aaaa6ae5436448476e.png\" /></p><p></p><p>分层是通过不同的视角看事物，每一层的关注点是不一样的，这种关注点不同是由自己的视角造成的，比如我们理解计算机，并不需要深入到二进制电信号去理解计算机。层次特性在软件设计中我们经常遇到，比如计算机体系结构、TCP 七层协议等，层次特性有一个特点：越往上越具体、越往下越抽象，越往上的内容越不稳定，也即是容易变化。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/78/784b7e3330f2d9a0d8fd54c79e9a8d6e.png\" /></p><p></p><p></p><h2>1.3 问题域到解空间的映射</h2><p></p><p></p><p>我们把需要解决的问题称之为问题域，或者问题空间，把解决方案称之为解空间。正向上一小节中提到的事物有层次特性，不同的人理解的事物是站在各自理解的视角，这样大家的理解、沟通并不一致的。如果我们看到的问题空间是表层的，那么基于浅层次理解设计出来的方案就会不稳定，可能下次有一个小变化导致方案需要重新设计。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/77/7787b6a36b2827f8f1588449429ae8d4.png\" /></p><p></p><p>我们可以把一个软件划分成三层：场景、功能和实体，场景层是经常会变的，比如发放优惠券场景就非常多，比如有天降红包领取优惠、分享有礼领取优惠券、新人注册领取优惠券等，这种场景的更迭随着业务的调整变化得非常快，因此场景层是不稳定的。功能支撑某一些的场景集合，对比场景，功能相对而言稳定些，就像前面提到的发放优惠券场景，本质就是给用户发放优惠券，只需要提供发放优惠券的功能即可，至于哪些场景来调用它并不关注，但功能还是基于场景的集合抽象出来的，如果场景场景类型变化了，功能也就随之变化，比如担保交易和预售交易就不一样。实体是稳定的，以担保交易和预售交易为例，它的订单模型大致是一样的，只是新增加了一些信息而已。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0e/0e3e1aa1850d247868d06d727fba2cd6.png\" /></p><p></p><p>因此，我们希望从问题空间到解空间，大家看到的、理解的是一致的，而且看到的是问题的本质而非表象，往往场景、功能是不稳定的，而面向过程又是以功能驱动的，所以在易变化的场景下，它面临的问题就比较多。比较稳定的是问题空间中的实体对象，所以面向对象分析是现实的需要。面向过程和面向对象是两个不同的视角的分析方法：面向过程是一种归纳的分析方法，由外到内的过程；面向对象是一种演绎的分析方法，由内到外的过程。</p><p></p><p></p><h2>1.4 三个一致性</h2><p></p><p></p><p>软件开发会经历需要分析、概要设计、详细设计、编码、测试、上线主要阶段，我们不希望每块是割裂的，比如分析做完之后，做设计阶段又要重新去做分析的工作，那么这里面就涉及到一致性的问题，即需求到分析的一致性、分析到设计的一致性、设计到编码的一致性。这样做的好处可以保证无信息失真，因此我们急需求一种分析设计方法能做到这一点，面向对象分析与设计就能做到，因此全流程是以对象作为分析与设计的目标，在最终编码中也都是对象。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/86/861eef47c4922e510fa84a25855f4c0f.png\" /></p><p></p><p></p><h2>1.5 面向对象的底层逻辑</h2><p></p><p></p><p>提到面向对象，有部分人会提到封装、继承、多态等特性，然后这些并不是面向对象的本质特性，比如封装，面向过程中也有封装，多态面向过程也有体现，这些特性算不上面向对象特有的特性。面向对象的底层逻辑是基于现实事物做的抽象映射：现实事物对应软件中的对象，我们讨论解空间能对应到问题空间中的对象，两者是一一直接映射的，其它的分析方法是问题空间到解空间的间接映射。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f0/f06bbc579cc38b4e05324e15c9dd2674.png\" /></p><p></p><p></p><h1>二、面向对象分析与设计的全景图</h1><p></p><p></p><p></p><h2>2.1 我们面临的问题是什么</h2><p></p><p></p><p>从顶层看，我们要完成需求到编码的工作，然而从需求到编码又会经过多个阶段，如需求分析、方案设计等，从大的层面讲，我们主要遇到三个问题：</p><p></p><p>1）做什么的问题</p><p></p><p>看似这是一个简单的问题，但在复杂的业务场景下，对做什么的理解太重要了，因为不同的人对需求的理解是不同的，比如最近做了一个项目，有一个业务判断规则是只针对跨境订单计税，最开始开发同学的理解是判断卖家类型是否是跨境卖家，然而到了测试阶段，发现大家对这个业务规则判断理解是不一致的，跨境订单跟卖家类型是没有关系的，真正的跨境订单计税场景是 shipTo（收货地址）和 shipFrom（发货地址）国家地址是不一样的。在大项项目中，涉及到多个团队之间的协同，这样的问题异常突出。而且从业务诉求到产品需求，再到技术方案，这其中是经过了 2 次变换，每次变换是不同的角色在里面，大家的认识也会不一样。</p><p></p><p>2）怎么做的问题</p><p></p><p>落实到事情具体要怎么做时，往往大家并不会出大的问题，怎么做偏具体执行阶段，程序员往往在逻辑严密性上没多大的问题，往往出问题是在第一个问题上，相当于方向弄错了，所做的工作也是无用的。</p><p></p><p>3）方法指导的问题</p><p></p><p>我们往往希望不劳而获得到一种万能的方法，能够应对所有的问题，同时又看不起低级的方法，比如大部分人对用例分析方法嗤之以鼻，想要能体现技术水平高大上的方法。其实自上世纪 70、80 年代，软件的分析设计方法并没有太大的变化，而且在我们大学期间都学过，只是大家并不认为它是一种高大上的方法而已。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/36/367962c3a51ebfd490e2cd7bdaf8e927.png\" /></p><p></p><p></p><h2>2.2 分析到设计的过程</h2><p></p><p></p><p>在本节中，我们推导软件分析到设计的过程，由粗到细，最终落实到我们接触到的 UML 知识上。从需求提出到编码实现，这中间有两个关键问题：一是界定目标，即是定义清楚要做什么的问题，相当于是我们做事的方向、目标；二是具体如何做的问题，即通过怎样具体的方案支撑需求目标实现。因此，我们需要一种方法能够帮助我们界定目标和表示具体方案，而且是大家互认的一种通用的方法。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3a/3aae5c3c98f95e84ca483451aa4c915b.png\" /></p><p></p><p>通过用例图可以帮我们界定目标，用例中有三个关键要素：用户、场景和目标。比如交易下单是一个用例，它的用户是买家，场景包含下单成功和下单失败两个场景，用例的目标是买家可以购买心仪的商品。当用例目标确定了，相当于界定了目标，知道需求要做什么，这个过程要反复和业务方确认好，至到最终大家对目标的理解是一致的，方向对了，具体怎么做就好办了。</p><p></p><p>具体怎么做用时序图表示，画时序图需要注意的一点是顶层的对象层次要一致，不能有的对象表示具体的实体对象，有的表示系统对象，即对象的层级是一致的，要么大家都是系统，比如导购系统调用交易系统，交易系统调用支付系统，要么大家都是对象，比如商品、订单等。通过时序图可以看到一个完整功能的执行步骤，它就包含具体执行的细节，如正常流程、异常流程。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/36/36cf81aad5088188f00caa608047314f.png\" /></p><p></p><p>其实在上面有一个问题，在画时序图时要确定好对象，那么这个对象是怎么来的呢？它是由健壮性图分析出来的，它里面有三个关键的对象：一个是边界对象，这个比较好理解，比如UI界面就是边界对象；另一个是控制对象，即是控制业务流程的对象，如下单服务就可以看作是控制对象；实体对象即是问题空间中的业务对象，比如订单。画健壮性图是有规则的，一般是边界对象调用控制对象，控制对象产生实体对象，比如用户下单界面是边界对象，下单服务是控制对象，订单就是实体对象。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/99/99908aafdfeb6c014168c5538224918c.png\" /></p><p></p><p></p><h1>三、寻找对象之路</h1><p></p><p></p><p></p><h2>3.1 对象从哪里来</h2><p></p><p></p><p>在本文第一部分第三小节中已经提到，问题空间到解空间是一一映射，我们讨论解空间中的对象时，其实它映射到问题空间中的对象，而问题空间中的对象主要来源于业务概念、业务规则、关键事件。大部分的对象是显现的，我们通过理解业务能发现，有的对象是隐性的，需要我们持续对业务有更深的理解才能发掘出来。好的对象模型是需要经过多次迭代打磨出来的，并非一次就能设计得十全十美。</p><p></p><p></p><h2>3.2 发现对象的方法</h2><p></p><p></p><p>在本文第二部分第二小节中已经提到寻找对象的方法，不过那还只是关键显现的对象，在本节中主要讲述完整对象发现的方法，主要方法分成四个步骤：</p><p></p><p>通过健壮性图找到关键的实体对象；通过结构分析方法找出更多的实体对象；将对象组成有机的对象模型；最后通过用例走查对象模型是否完备。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8e/8e7a90bd27ecd6af6e5da0c52a31dc96.png\" /></p><p></p><p>这里以一个案例来说明发现对象的过程，案例是用户在下单时，在订单上展示税的金额。首先画出健壮性图，这里的边界对象是下单界面，控制对象有两个，一个是下单服务，另一个是计税服务，实体对象也有两个，一个是计税单，一个是订单。有了计税单和订单这两个实体对象后，接下来通过结构分析方法，分析出更多的对象。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/99/9979be783f4412011d3944e3a4721261.png\" /></p><p></p><p>对象都是有结构的，只要我们掌握了对象的结构，基本上就能掌握对象的概貌，因此我们从对象的结构入手，去分析对象内部的结构、对象关联的结构，实质上是从两个维度出发：一是从自身的角度出发，看自己内部还包含了哪些对象，如主订单包含了子订单；另一个是从外部的角度出发，看自己还与哪些对象相关联，如计税单与订单是有关联的。这种找对象的方法我称之为结构分析方法，因为本身结构又是事物本质的一种表达方式，比如化学分子结构决定化学现象。</p><p></p><p>为了更好地表达出对象的结构，我的一个经验是给对象下好定义，下定义可以从不同的维度，比如功能性维度、价值性维度、目的性维度、结构性维度等，这里可以从结构性的维度去给对象下定义。以计税单为例，可以给它下一个定义：计税单是将订单金额信息转成若干个标的物计税的单据模型，从这个定义中，我们可以看到计税单是与订单有关联关系的，另一个是计税单是包含了若干个标的物，我们可以画出计税单的对象模型。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/964aca335d91ea9d39c262fac12771fb.png\" /></p><p></p><p>当对象模型画出来后，后续我们讨论业务基本上围绕这个对象模型去讨论业务问题的，比如商品标的物哪些金额要参与计税、计税金额的计算口径是怎样的，到这里，大家再体会下\"问题空间到解空间一一直接映射\"这句话，业务上的诉求也无非是哪些订单费用项要计税，计税的逻辑是怎样的，有可能在这个场景下要扣减金本位优惠，在另外一种场景下金本位优惠不需要扣减，基于对象模型与产品、测试同学讨论问题，大家都是处于同一个维度的视角看问题，沟通理解成本会少很多。</p><p></p><p>对象模型是一种可视化的表达，我们大部分的沟通问题是缺乏显性表达造成的，这句话可以这样理解，也可以那样理解，导致大家理解有偏差，现在用模型的形式沟通问题，很多偏差、歧义就消除了。</p><p></p><p></p><h2>3.3 组织对象结构</h2><p></p><p></p><p>当我们分析出一堆的对象后，还需要经过一定的组织，正如前面提到，人对事物理解是有局限的，不能一下子接受太多的事物，因此可以将它们分成一个个小的域，比如商品域、订单域、税务域等，这样当聚集一个问题时，可以只看某个子域里的对象模型即可。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c6/c6d3513f17382d1ac3c54913bda7aa26.png\" /></p><p></p><p></p><h1>四、如何分配职责</h1><p></p><p></p><p></p><h2>4.1 职责是怎么来的</h2><p></p><p></p><p>面向对象最难的点有两个：一个是找出对象；另一个是分配职责。UML 把职责定义为\"类元的契约或义务\"，因此职责的划分从本质来讲还是类元本身决定的，比如订单，它要提供订单渲染、订单创建、订单修改、订单查询的义务。</p><p></p><p>职责分为两类：一类是认知职责；另一类是行为职责。</p><p></p><p>认知职责包含：</p><p>对私有数据封装的认知；对相关对象的认知；对其能够导出或计算的事物的认识。</p><p></p><p>行为职责包含：</p><p>自己执行的行为，包括创建对象或计算；初始化其它对象的动作；控制或协调其它对象的活动。</p><p></p><p></p><h2>4.2 分配职责的逻辑</h2><p></p><p></p><p>上一小节中提到的职责有两类，认知职责是对象自身的认知范围，即它只能基于自身属性完成相应的职责，举一个例子，假如一主多子的订单，要计算总的订单金额，怎么分配职责呢？首先商品只能查到自身价格的信息，它的认识是基于商品 price 属性，一个子订单可以有多个商品，那么它也只能计算出子订单的金额信息，它的认知是基于 item 和 quantity两个属性，主订单包含所有子订单的信息，那么就可以计算出总的订单金额。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/33/335c5e6641c1a952e39db95313544a6d.png\" /></p><p></p><p>从上面的例子中我们可以看出，认知职责是基于对象属性的，正所谓\"不在其位、不谋其政\"，认知职责一定不会超过它的认识范围的。</p><p></p><p>行为职责是偏领域服务的，有的时候一个职责不属于某一个对象，比如转账，就是一个行为，让其它的职责承担并不合适，这类行为职责往往是一个显著的业务活动，比如订单渲染、订单创建就是行为职责而非认知职责。</p><p></p><p>分配职责一定要遵循\"信息专家\"模式，它的含义是将职责分配给具有完成该职责所需要信息的那个类，也即上面提到的认识产生职责。</p><p></p><p></p><h2>4.3 验证职责分配的合理性</h2><p></p><p></p><p>我们期望分配的职责满足\"高内聚、低耦合\"，怎么检验呢？我们再回过头来思考职责的定义：类元的契约或义务，换句话讲，职责是满足其它对象来调用的，这个就与我们画时序图的目的是一致的，每次发生一次调用，即意味着其它的对象要提供一个职责出来，因此我们可以在时序图中看对象间的调用频次，如果一个对象被调用得非常频繁，有可能这个对象承担了太多的职责，是不是可以对其拆分，把职责分配一部分出去。因此，对象职责分配并不是一蹴而就的，需要不断审视、检验。</p><p></p><p>分配职责是要遵循一定的原则，如创建者模式、信息专家模式、纯虚构模式等，这些原则会在下一篇中单独去讲。</p><p></p><p></p><h1>五、案例</h1><p></p><p></p><p></p><h2>5.1 案例背景</h2><p></p><p></p><p>这里举一个例子，说明面向过程和面向对象在分析、编写代码的差异性，计税需要判断是否满足计税规则，比如虚拟商品不计税（手机充值之类）、有些免税地址不计税、小 B 买家也不计税等，因此需要提供一个计税过滤判断逻辑。</p><p></p><p></p><h2>5.2 常规面向过程实现</h2><p></p><p></p><p>面向过程的思路很简单，提供一个过滤方法依次处理下面逻辑：过滤虚拟商品计税请求、过滤免税地址计税请求、过滤小 B 买家计税请求。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/09/09d03fde39cfb7433af34c7aa295c4b8.png\" /></p><p></p><p><code lang=\"text\">public void filter(List request){\n     \n     // 过滤虚拟商品计税请求\n     filterVirtualItem(request);\n\n     // 过滤免税地址计税请求(即外岛)\n     filterOuterIsland(request);\n\n     // 过滤小B买家计税请求\n     filterPurchaseType(reqeust);\n\n}</code></p><p></p><p></p><h2>5.3 面向对象实现</h2><p></p><p></p><p>面向过程是从过程视角或者是功能视角分析问题，而面向对象是从对象的视角分析问题，过滤计税请求是计税过滤器判断计税请求是否满足计税规则，这里就包含了两个对象：计税过滤器和计税规则，判断是否满足计税要求这个职责应该是在具体的计税规则处理器中，比如是否是小 B 买家等，因此我们可以画出对象模型。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e8/e84107ae2a8086495fcbdcbb9bfd8d1d.png\" /></p><p></p><p>关键代码如下：</p><p></p><p><code lang=\"text\">\npublic abstract class AbstractRuleHandler {\n\n    /**\n     * 抽象的业务规则处理\n     *\n     * @param request\n     */\n    public abstract void handler(TaxCalculateRequest request);\n\n    /**\n     * 构造函数里完成注册\n     */\n    public AbstractRuleHandler() {\n        TaxCaluclateFilter.register(this);\n    }\n}</code></p><p></p><p></p><h1>六、总结</h1><p></p><p></p><p>在文章中提到，面向对象的底层逻辑是基于现实事物做的抽象映射，重要的不是要面向对象具体技术的使用上，而是分析问题的思维上，这是最难的，它最大的好处是问题空间到解空间是一一直接映射的，请注意是一一直接映射，它意味着我们在讨论方案的时候，完全可以映射到问题空间，如果是间接映射，也就意味着设计的方案后面会面临重新设计的可能性，因为它是基于场景或功能做出的归纳设计，而且是表层的设计。真正掌握了面向对象分析和设计的方法，也体会到其中的益处，对理解业务、方案设计、编码开发都有好处。</p>",
    "publish_time": "2022-12-30 12:06:04",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "国外大学生用AI写论文，还次次拿到A",
    "url": "https://www.infoq.cn/article/K9uYlvh3u6q7ag1Z8hoD",
    "summary": "<p></p><blockquote>任何新技术都具有两面性，<a href=\"https://www.infoq.cn/article/k1EU1cHr1FflCxRuATtv\">生成式 AI </a>\"也是如此。</blockquote><p></p><p></p><h2>大学生用 AI 写论文，次次拿 A</h2><p></p><p></p><p>近日，国外大学生 Urdadgirl69 在 Reddit 上发帖称，自己利用 AI 写论文、完成电影和书的观后感作业，门门功课拿到了 A。Urdadgirl69 表示，一开始，自己还有点羞愧，但很快就适应了这种形式，甚至还开始帮同学用 AI 写作业，并从中赚取了 100 美元。如今，所有人都把自己当作天才来看待。最后，Urdadgirl69 表示，这篇帖子也是 AI 帮忙润色的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/97/97b9e5df0baf83d740baa8ab12aa2aee.png\" /></p><p></p><p>这篇帖子很快在 Twitter 上火了，大家发现，像 Urdadgirl69 这类用 AI 写论文、作业的大学生不在少数。</p><p></p><p>一个网名 innovate_rye 的大一学生称，自己用 AI 完成了生物化学专业的作业，成绩很好。“我用 AI 完成了一些简单的作业。比如说生物课上，我们要学习生物技术的知识。教授让我们写文章，回答关于生物技术的五个优点和缺点。我就把关键词输入给 AI，‘关于生物技术的五件好事和坏事是什么？’AI根据这句话生成一篇文章，让我拿到 A 的成绩。”innovate_rye 表示，自己以往写这种文章，至少要花 2 个小时，但有了 AI，他只需要 20 分钟就能搞定。</p><p></p><p>与人类相比，生成式 AI 没有拖延症，只需一点提示即可快速生成内容。学生群体可以说是生成式 AI 的完美受众：他们需要频繁地写作，而且普遍熟悉互联网。对于学生群体而言，生成式 AI 的确是个“不错的选择”。</p><p></p><p>目前，市面上充斥着各种 AI 创作产品，这些产品易于使用且价格低廉。不少商家甚至通过免费试用来吸引新用户，并承诺快速提升写作质量。</p><p></p><p>其中，最受欢迎的 Jasper 平台月度订阅费用为 40 美元，可生成 35000个 单词。而 Writesonic 和 Sudowrite 等其他选项可生成 30000 个单词，价格低至每月 10 美元。随着 <a href=\"https://www.infoq.cn/article/AWWsrfb54zTvglZ0I5qS\">ChatGPT 横空出世</a>\"，现在学生们又多了一个选择。</p><p></p><h2>AI 有其局限性</h2><p></p><p></p><p>尽管 AI 生成的文本可以拥有完美的语法和句法，但内容却很难超出几个段落。这意味着，内容越长，AI 的写作连续性越差，也没有清晰的逻辑思路作为主干。</p><p></p><p>同时，AI 无法正确理解事实，生成内容中的引用、日期和思路很可能是错的。学生必须认真检查结果并纠正错误，才能让写出的文章具有说服力。</p><p></p><p>得克萨斯大学奥斯汀分校修辞与写作副教授 Scott Graham 曾要求他的学生使用 AI 撰写一篇关于校内问题的 2200 字文章。学生们可以随意对作品稍做编辑和格式调整，唯一的规则就是论文的大部分内容必须由软件自动生成。</p><p></p><p>最终的效果显示，AI 辅助创作的论文并不好，质量最高的文章也只获得了 C 和 C- 水平的成绩。要想通过 AI 写作拿到 A，学生只能能用自己的话重新整理文章内容，或者设计出更狭义、更具体的提示来引导 AI 创作有用输出。实际上，这些工作也会花费不少时间和精力。</p><p></p><p>Graham 表示 AI 技术的确能帮助人们提高写作水平，但也有其局限性：</p><p></p><p></p><blockquote>“我认为如果学生能在 AI 的帮助下更好地完成写作，那其实跟他们自己从零开始写作并没什么区别。我教给大家和想要审查的写作技能，也主要体现在初稿形成之后。我认为作家们的真正才华其实也体现在这里，体现在修订和编辑的过程中。所以我对 AI 持乐观态度，因为我觉得它能为人们提供一套框架、更好地掌握修订和编辑的诀窍。有些学生在订制初稿方面遇到了很多麻烦。如果他们把所有精力都投入到初稿的撰写当中，那么到了截止日期，他们交上来的肯定也就是这份初稿了。没机会修改、没机会编辑、没机会完善。如果能使用这些AI系统加快初稿的撰写，那肯定是种有益的助力。”</blockquote><p></p><p></p><h2>AI 辅助写作需要制定相应的政策</h2><p></p><p></p><p>将 AI 作为辅助工具和利用 AI 作弊之间的界限其实非常模糊。一些教育人士在讨论这个问题时都表现得比较开明，并不抗拒学生使用 AI 软件。</p><p></p><p>匹兹堡大学英语副教授兼系主任 Annette Vee 认为：</p><p></p><p></p><blockquote>“对我们来说，最重要的其实是 AI 正给写作方式带来哪些改变，以及我们作为教师该如何在作业中做相应调整——包括主动设计与AI协作的元素。我们的责任就是在有 AI 辅助的同时，继续考查学生们是否掌握了写作学习的一贯目标。包括学生如何构思，怎样厘清逻辑，如何清晰并有创造性地设计沟通。我认为AI系统在这些环节中都将有所帮助，最终让写作呈现出不同于以往的形式。”Vee 强调，“从本质上讲，写作就是由技术塑造而来，自然不该拒绝新的技术元素。”</blockquote><p></p><p></p><p>但也有教育人士认为，<a href=\"https://www.infoq.cn/article/0tUIRWQUjaip2MtKgpYM\">AI 辅助写作</a>\"需要制定相应的政策，需要让学生和教师明确知道，什么是可接受的、什么不可接受。比如，用 AI 自动生成邮件回复是件很正常的事情，但如果用 AI 生成的内容违反学术诚信，则不可接受。</p><p></p><p>但想用学术政策解决 AI 辅助写作问题绝非易事。如今，对于使用机器生成的语句是否构成抄袭仍没有统一意见。另外，我们也很难准确检测哪些内容是由 AI 工具所生成。就连教师们自己都震惊于 AI 不断发展的技术能力，但也有些教育工作者觉得 AI 语言模型并没有坊间传闻的那么强大。</p><p></p><p>此外，考虑到语言模型会受训练数据中暗含偏见的影响，一些教育人士还担心 AI 会影响人们批判性的独立思考习惯。罗格斯大学英文与比较文学教授 Lauren Goodlad 彼时，假设学生们全盘接受 AI 的观点，那他们最终可能会简单粗暴地将穆斯林与恐怖主义联系起来，或者满脑子都是阴谋论。</p><p></p><p>无论未来高校可能采取怎样的政策，AI 都切实给学术界带来了改善教育成效的机会。如果教师们想要主导这波潮流就必须适应技术变化，同时鼓励学生无论是否使用 AI，都时刻保持自主学习和独立思考的习惯。</p>",
    "publish_time": "2022-12-30 13:40:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "市场增速超20%，国产操作系统“浴火重生” | 解读操作系统的 2022",
    "url": "https://www.infoq.cn/article/4lDxHRoqXbSw6zl29AEo",
    "summary": "<p></p><blockquote>本文是<a href=\"https://www.infoq.cn/theme/168\">“2022 InfoQ 年度技术盘点与展望”</a>\"系列文章之一，由 InfoQ 编辑部制作呈现，重点聚焦<a href=\"https://www.infoq.cn/theme/141\">操作系统</a>\"领域在 2022 年的重要进展、动态，希望能帮助你准确把握 2022 年操作系统领域的核心发展脉络，在行业内始终保持足够的技术敏锐度。“InfoQ 年度技术盘点与展望”是 InfoQ 全年最重要的内容选题之一，将涵盖操作系统、数据库、AI、大数据、云原生、架构、大前端、编程语言、开源安全、数字化十大方向，后续将聚合延展成专题、迷你书、直播周、合集页面，在 InfoQ 媒体矩阵陆续放出，欢迎大家持续关注。特此感谢郭振宇、江大勇、刘恺、马涛、任革林、张磊、张家驹（按姓名首字母排序）对本文的贡献，他们的真知灼见，是本文能与大家见面的关键。</blockquote><p></p><p></p><p>在整个软件生态中，操作系统起到重要的承上启下作用。经过数十年的持续迭代和演进，操作系统整体发展稳健。从技术角度来看，虽然近几年并未涌现突破性成果，但不少受访专家对 InfoQ 表示，巨变正在酝酿中。当前，全球数字经济进一步发展，企业数字化转型持续深入，以及摩尔定律的失效，都为软硬件带来新的挑战，而这也是操作系统变革的重要驱动力。</p><p></p><p>回顾操作系统的 2022 年，可以发现，有些改变正在悄然发生。随着“量变”的积累，操作系统必将迎来“质变”的飞跃。</p><p></p><h2>2022 年，值得关注的大事件</h2><p></p><p></p><p>2022 年，全球操作系统市场格局稳定。看国外主流操作系统，桌面操作系统方面并未带来太多惊喜。与去年重磅发布的 Windows 11、Windows 365 相比，Windows 今年仅带来了一些小范围的更新。</p><p></p><p>移动操作系统方面，Android 13 与 iOS 16 相继登场，但也都属于常规升级。2 月 11 日，谷歌发布了首个 Android 13 开发者预览版，8 月 16 日，谷歌向 Pixel 机型推送了 Android 13 正式版更新，并正式开源；6 月 7 日，苹果正式发布 iOS 16，并推送了首个开发者预览版，9 月 13 日，苹果正式推送 iOS 16 系统更新。</p><p></p><p>服务器操作系统方面，发展稳健。5 月，红帽正式发布 RHEL 9，其基于上游内核版本 5.14，并源自 CentOS Stream；10 月，SUSE 推出业界首个自适应 Linux 平台原型（Adaptable Linux Platform，简称 ALP），旨在让用户专注于工作负载，从硬件和应用层抽离出来。</p><p></p><p>看国内操作系统，2022 年迎来了多个版本升级。3 月，OpenHarmony 3.1 正式发布；4 月，欧拉首个数字基础设施全场景长周期版本 openEuler 22.03 LTS 正式发布；7 月，华为正式发布 HarmonyOS 3 以及搭载 HarmonyOS 3 的多款新产品；8 月，OpenCloudOS 开源操作系统社区正式发布首个 Linux 源社区（L1）内核版本 OCKS 2207，这也是 OpenCloudOS 源社区项目的核心组件；11 月，龙蜥社区正式发布面向云时代打造的下一代操作系统 Anolis OS 23 公测版……</p><p></p><p>2022 年，国产操作系统市场增速显著。根据亿欧智库测算，国产操作系统通用市场增速将超过 20%，在 2024 年将达到 34.1 亿元的规模。服务器操作系统方面，数据显示，2022 年上半年，中国服务器操作系统新增装机量是 195 万套，全年预计超过 400 万，过去两年，这个数字是 322 万和 350 万。这说明在产业数字化的背景下，操作系统依然是个巨大的增量市场。</p><p></p><p>总体而言，2022 年，国产操作系统在技术、社区和商业化方面均有快速发展：技术方面，更多企业及研究机构投入到自研系统项目中，原创组件和技术如雨后春笋般涌现；社区方面，头部社区蓬勃发展，新的社区不断出现；商业化方面，OSV 都有较为明显的业绩增长。</p><p></p><p>另一个显著变化是，中国开源力量迅速崛起，国内开发者正越来越深入地参与到开源操作系统的建设中。在一份对 Linux 内核提交数量的统计中，来自中国的开发者占比不断提高，有统计的来自中国的 patch 数，连续 7 年超过美国成为第一。</p><p></p><p>操作系统作为底层基础软件，其安全性至关重要，操作系统的安全也是网络系统信息安全的基础。2022 年，全球范围内都进一步重视开源软件供应链问题，可以说，开源安全在今年迈出了一大步。</p><p></p><p>2022 年 1 月 13 日，美国白宫召集了政府和 Apache 软件基金会、Linux 基金会、开源安全基金会、GitHub、微软、谷歌、甲骨文、红帽等企业或组织共同谈论开源软件安全问题。5 月 12 日，Linux 基金会和开源安全基金会提出了一项为期两年的近 1.5 亿美元的投资计划，并提出十个开源安全目标：安全教育、风险评估、数字签名、内存安全、事件响应、更好的扫描、代码审计、数据共享、软件物料清单（SBOM）以及改进的供应链。</p><p></p><p>国内方面，10 月 24 日，开放原子开源基金会联合 27 家单位共同发起开源安全委员会，开源安全委员会致力于制定开源项目的安全流程和规范、提供开源开发的安全工具和平台、发起开源安全依赖的关键项目、推动开源安全的国际合作与交流。</p><p></p><h3>如何评价国产操作系统的 2022？</h3><p></p><p></p><p>对于国产操作系统在 2022 年的整体发展，受访专家均给出了积极评价，关键词包括机遇、加速、合力等。</p><p></p><p>操作系统作为信息技术的核心底座，具有复杂度高、投入大、生态建设难、成功率低等特点。经过二十余年的探索与实践，中国有能力在技术上实现一个大型的操作系统。同时，近几年国内操作系统市场快速增长，人才储备量提升，政策投入力度巨大，操作系统产业正迎来新机遇。在这一背景下，国产操作系统的发展也驶入快车道，从无到有，从可用到好用，国内开发者用短时间迅速完成这一转变。此外，与其他软件不同，操作系统是一个强生态的产品，这也需要操作系统厂商与硬件厂商、高校、互联网等软件厂商等各个链条通力合作，共同促进操作系统生态建设。</p><p></p><p>对于服务器操作系统，则可以用“格局尽显，稳中有进”来形容这一年。</p><p></p><p>2022 年，主流云厂商、服务器厂商、芯片厂商以及传统操作系统厂商都加大了对操作系统研发和操作系统社区的投入。随着中国在操作系统领域研发力度的持续增加，国产开源操作系统社区和商业化操作系统的产品性能都已经大幅提升，生态建设也初具规模，开始具备规模化推广能力。</p><p></p><p>“当前国产操作系统正在逐渐走向成熟好用阶段。未来 5-10 年，可能是国产操作系统的黄金时代。”受访专家表示。</p><p></p><h2>重点趋势与变化解读</h2><p></p><p></p><p>2022 年，Linux 内核最大的一个变化是新增了对 Rust 语言的支持。此外，近两年涌现出的新技术在 2022 年继续带来新的变化，如 eBPF 技术、RISC-V 架构。</p><p></p><h3>Rust for Linux</h3><p></p><p></p><p>Rust 凭借其内存安全特性，近年来受到越来越多开发者的支持，并连续 7 年被 Stack Overflow 开发者调查评为“最受欢迎的编程语言”。2022 年的调查结果显示，有 87% 的开发者表示想要继续使用 Rust。</p><p></p><p>而 Linux 内核社区长期以来都是以性能、稳定性、安全作为发展的基本要求，这与 Rust 在安全方面的特性非常契合。因此，早在几年前就有开发者呼吁在 Linux 内核中增加 Rust 语言的支持。</p><p></p><p>在 2022 年 9 月举行的 Linux Plumbers Conference 上，有一场关于 Rust 是否会出现在 Linux 中的小型会议，会议讨论了将 Rust 作为一门系统编程语言集成到 Linux 内核主线的工作。彼时，Linux 的创建者 Linus Torvalds 在接受媒体采访时表示，“如果不出意外，Rust 将会出现在 Linux 6.1 版本中”。12 月 11 日，Linus Torvalds 发布了最新的 Linux 6.1 内核稳定版，正式引入对 Rust 的支持。</p><p></p><p><a href=\"https://www.infoq.cn/article/hRUNuCGVgGwda9jpwajc\">Rust for Linux</a>\" 带来的收益明显，安全性上的收益尤为突出。</p><p></p><p>在安全性上，Window 的一份数据可以作为参考。此前，一位微软工程师曾透露，微软产品每年通过安全更新解决的所有漏洞中，<a href=\"https://www.chromium.org/Home/chromium-security/memory-safety/\">大约 70% 是内存安全问题</a>\"。因为 Windows 主要是用 C/C++ 这两种“内存不安全”的编程语言编写的。</p><p></p><p>Linux 同样如此。随着 Linux 内核代码量愈发庞大，贡献者数量迅速增长，系统安全性问题也变得越来越突出。而 Rust 设计初衷就是为了解决内存安全问题，在功能保持不变的情况下，用 Rust 语言进行重写相当于将安全性提升三倍左右。此外，Linux 内核对代码执行效率要求较高，Rust 的执行效率和 C/C++ 近乎一致，这也是其能成为底层系统编程语言的原因之一。</p><p></p><p>当前，Rust for Linux 还处于早期阶段。长期以来，Linux 内核主线代码基本都由 C/C++ 语言编写，接受 Rust 需要社区补充和完善大量的周边工作。</p><p></p><p>同时，对于内核维护者来说，Rust 进入 Linux 内核也会带来一些问题。</p><p></p><p>首先，没有银弹。虽然 Rust 语言在设计上更多地考虑了内存安全、线程安全等，但代价是比较陡峭的学习曲线，以及使用者在实现某些功能时的便利性。此外，内核是贴近硬件、最底层的程序，某些在用户态司空见惯的语言特性，比如异常的处理方式，在内核里是不一样的。对于 Rust 而言，如何在内核里更好地工作，还有很大的探索空间。</p><p></p><p>其次，计算机语言和自然语言一样，都能反映出文化。C/C++ 语言反映出来的文化和 Rust 不同，对于那些已经非常熟悉并深度认同 C/C++ 语言文化的资深 Linux 内核维护者来说，接受 Rust 的难度较高。</p><p></p><p>对于 Rust for Linux 的未来发展，多数专家都给出了积极评价：“从长远看，会有越来越多新的代码用 Rust 来实现。”</p><p></p><h3>eBPF 时代来临</h3><p></p><p></p><p><a href=\"https://www.infoq.cn/article/jyrmBFJSUVk7a1fLtQR8\">eBPF</a>\" 的全称是“扩展型伯克利封包过滤器（Extended Berkeley Packet Filter）”，最早是从 BPF (Berkeley Packet Filter) 技术扩展而来，是一种无需更改 Linux 内核代码，便能让程序在内核中运行的技术。</p><p></p><p>2014 年，eBPF 首次出现在 Linux 内核中。经过社区不断迭代，目前，eBPF 技术已经非常成熟，技术应用呈现井喷现象。虽然在设计之初 eBPF 仅为 Linux 内核服务，但近年来已经诞生了一批基于 eBPF 的项目。2021 年 5 月，微软启动了新的开源项目 eBPF for Windows，该项目旨在让开发者在现有 Windows 版本之上使用熟悉的 eBPF 工具链和应用编程接口（API）。为了更好地推动 eBPF 的发展，2021 年 8 月 12 日，Linux 基金会旗下的非营利性组织 eBPF 基金会正式成立。</p><p></p><p>2022 年，eBPF 热度不减，仍是当下最火的技术之一。eBPF 技术带来的收益明显，一方面，包括 Linux、Windows 在内的主流操作系统内核是宏内核，可拓展性较差，而 eBPF 技术能够以非侵入式的方式对内核进行扩展；另一方面，eBPF 提供了比较好的安全性、扩展性和兼容性。</p><p></p><p>不少受访专家对 InfoQ 表示，eBPF 的发展前景广阔，属于 eBPF 的时代已经来临。</p><p></p><p>“eBPF 技术的发展已经超出了我的预期。操作系统内核在没有应用 eBPF 技术以前，整个内核是静态的，编写内核时实现了什么功能，运行时也只有这些功能，最多可以做一些参数的调整，但无法带来更复杂的功能变化。应用 eBPF 技术以后，可以在 Linux 内核中运行沙盒程序，编译成相关字节码加载到内核中，无需更改内核源代码或加载内核模块。”有受访专家表示，eBPF 技术为操作系统内核提供了一个新的可能性，为内核带来根本性的改变。</p><p></p><p>对于 eBPF 的未来，<a href=\"https://ebpf.io/summit-2022/\">eBPF summit 2022 </a>\"《The future of eBPF in the Linux Kernel》给出了几个演进方向：</p><p></p><p>更完备的编程能力：当前 eBPF 的编程能力存在一些局限性（比如不支持变量边界的循环，指令数量受限等），演进目标是提供图灵完备的编程能力；更强的安全性：支持类型安全，增强运行时 Verifier，演进目标是提供媲美 Rust 的安全编程能力；更广泛的移植能力：增强 CO-RE，加强 Helper 接口可移植能力，实现跨体系、平台的移植能力；更强的可编程能力：支持访问 / 修改内核任意参数、返回值，实现更强的内核编程能力。</p><p></p><h3>拥抱 RISC-V</h3><p></p><p></p><p>近几年，RISC-V 以其开放的指令集架构受到越来越多操作系统厂商和开发者的青睐，不少操作系统开始拥抱 RISC-V，并成为一种新兴趋势。Semico Research 预测，到 2025 年，RISC-V 市场规模将超 10 亿美元。</p><p></p><p>国外包括英特尔、苹果、Tenstorrent、瑞萨电子等多个厂商都在积极布局 RISC-V。2022 年 2 月，英特尔宣布加入 RISC-V International 基金会，正式成为该基金会第 19 个高级会员，并设立了 10 亿美元的 IFS 基金，用于帮助初创和成熟企业进行代工生态的创新，其中很大一部分用于 RISC-V；9 月，半导体产业分析机构 SemiAnalysis 称，苹果正在将其嵌入式内核将全面转移到 RISC-V 架构；同月，任职于 Tenstorrent 负责 RISC-V 架构的传奇芯片设计师 Jim Keller 喊出了“未来是属于 RISC-V 的”口号。</p><p></p><p>在 2022 RISC-V 国际峰会上，RISC-V 基金会首席执行官 Calista Redmond 表示，“我们 2022 年的愿景是让 RISC-V 无处不在，随着 RISC-V 在汽车、航空航天、数据中心以及消费设备等各个领域的采用和开发，这一愿景已经真正实现”。</p><p></p><p>目前，RISC-V 国际基金会在 70 个国家 / 地区拥有超过 3180 名会员，覆盖芯片厂商、芯片设计服务公司、软件提供商等软硬件公司，以及大学、科研机构和投资机构等。市场上有超过 100 亿个 RISC-V 核心，全球有数万名工程师致力于 RISC-V 计划。</p><p></p><p>国内方面，自 2018 年成立中国 RISC-V 产业联盟以来，四年间已有 150 多家会员单位。包括华为海思、阿里平头哥、紫光展锐、兆易创新在内的多家芯片厂商基于 RISC-V 架构开发产品，越来越多的操作系统厂商和社区开始拥抱 RISC-V。2020 年 4 月，中科院软件所牵头成立了 openEuler 社区 RISC-V SIG 组。</p><p></p><p>2022 年 8 月，阿里平头哥发布首个高性能 RISC-V 芯片平台“<a href=\"https://www.infoq.cn/article/0gsHOaDExDwuWgwxYfpm\">无剑 600</a>\"”及 SoC 原型“曳影 1520”；同月，阿里云、中科院软件所 PLCT 实验室、平头哥等在龙蜥社区成立 RISC-V 架构联合小组，全面兼容并促进 RISC-V 生态发展；同月，OpenCloudOS 社区推出 OCKS 2207.2 内核版本，增加对 RISC-V 64 架构的支持；11 月，deepin 社区宣布支持曳影 1520，deepin V23 已经启动与曳影 1520 平台的适配；12 月，中科院软件所基于 openEuler 打造的傲来操作系统宣布进入 2.0 阶段，最新发布的“傲来 2.0-RV”聚焦 RISC-V 指令集，提供模拟器、硬件板卡等多种运行环境，其中硬件板卡支持中科院香山、果壳系列，支持哪吒 D1 开发板、赛昉 VisionFive 单板机、SiFive 公司 Unmatched 系列，同时也集成了澎峰科技的并行计算库。移动操作系统方面，2022 年，OpenHarmony 新增了对 3 款 RISC-V 芯片的支持，包括 TLSR9518、HPM6750IVM1 以及 BK7235。</p><p></p><p>从生态繁荣程度上来看，RISC-V 生态正处于增长关键期。当前，RISC-V 的生态建设有很多基础性工作需要做，比如硬件需要更加成熟和规范，软件（主要是在内核层面）需要与硬件配合得更好，以及功能更加完善，这些都需要内核开发者们合作完成。“我们的经验就是 Upstream First，即任何工作都首先贡献到上游社区，与所有的生态合作伙伴一起，完善这个生态。”受访专家总结道。</p><p></p><h2>展望操作系统的 2023</h2><p></p><p></p><h3>值得关注的技术趋势 / 方向</h3><p></p><p></p><p>2023 年，操作系统领域值得关注的技术趋势 / 方向除了 Rust for Linux、eBPF、RISC-V 的发展，还有云原生、异构计算、安全以及 AI 等。</p><p></p><h4>移动</h4><p></p><p>&nbsp;</p><p>移动操作系统历经十余年发展，已经十分成熟。随着全球进入移动互联网时代，移动操作系统的市场份额稳定。数据显示，截至 2022 年 10 月，全球操作系统市场中 Android、iOS 的市场份额占比分别为 42.37%、17.60%。</p><p>&nbsp;</p><p>与此同时，国内以鸿蒙为代表的移动操作系统市场突飙猛进。2022 年，在 HarmonyOS 发布的第四个年头，其自研核心代码量已突破 2000 万行，搭载的设备量也正式达到 3.2 亿台，相比去年同期增长 113%。</p><p>&nbsp;</p><p>有受访专家表示，当前国产移动操作系统还处于准备期，离带动整个产业发展还有一定的距离，但“雪球正在越滚越大”，距离成熟期并不遥远。“到 2024 年，国产移动操作系统的市场规模远超百亿级”，受访专家预判道。</p><p></p><h4>云原生</h4><p></p><p></p><p>操作系统是连接应用和硬件的桥梁，它的发展和 IT 基础设施密切相关。当前，随着云的不断普及以及云原生的不断演化，云会逐渐成为企业 IT 形态的主流，企业数字基础设施将基于云来重建，并迎来跨越式发展。</p><p></p><p>与此同时，全面基于云、并面向云做设计研发的操作系统将成为主流。目前，国内外各大操作系统厂商和云厂商都在积极为这一跨越式发展做准备。2022 年，操作系统 + 云协同趋势越来越明显。微软借助其基于云计算的操作系统 Azure，不断增加公共云的市场份额；红帽除了企业 Linux（RHEL），也在云平台 OpenShift 上投入重兵；SUSE 也发布了专为边缘环境中的容器化工作负载量身打造的轻量级操作系统 SLE Micro 5.2。</p><p></p><p>有受访专家预判，“未来 IT 基础设施属于云，而未来的操作系统也属于云上操作系统”。</p><p></p><h4>异构计算</h4><p></p><p></p><p>异构计算是近年来计算机领域出现的热门方向之一，主要是指使用不同类型指令集和体系架构的计算单元组成系统的计算方式。与传统的通用计算芯片相比，异构架构具有高性能、低功耗等显著优点。</p><p></p><p>2021 年，以 DPU 以及各种各样 XPU 为代表的异构计算异军突起，英伟达、英特尔先后发布了 DPU、IPU。2022 年，英特尔披露了 XPU 概念的下一步规划——新架构 Falcon Shores，它能将 x86 CPU 和 Xe GPU 硬件合并到同一颗芯片中。据路线图所示，Falcon Shores 计划于 2024 年完成。2022 年，全球首台原生 RISC-V 笔记本电脑 ROMA 正式发布，并首次运行无剑 600 高性能异构芯片曳影 1520。</p><p></p><p>有受访专家表示：“在 2023 年，可能会涌现出更多的异构计算设备，操作系统要想更好地支持这些计算设备，需要解决很多技术难题，比如如何在不同的平台上运行软件。”</p><p></p><h4>安全</h4><p></p><p></p><p>随着操作系统代码数量逐渐增加，以及支持的硬件日益广泛，安全性问题不容忽视。一方面，操作系统向下支持硬件，硬件上的某些安全缺陷可能需要在软件层面进行修复；另一方面，操作系统本身具有海量的代码，一些新特性或新的执行机制出现，也会给安全带来一些新的挑战。</p><p></p><p>此外，开源安全也是 2023 年值得关注的方向之一（编者注：后续我们也将发布针对开源安全的盘点与展望文章，敬请期待）。随着越来越多的开源软件在千行百业中得到广泛应用，安全问题日益凸显，供应链安全攻击和容器安全威胁问题日益严峻。如何构建安全可信的操作系统，是每个参与者需要长期思考的问题。</p><p></p><h4>AI</h4><p></p><p></p><p>近几年，AI 技术在操作系统领域诞生了诸多应用。比如，openEuler 社区曾发布一款名为 A-Tune 的操作系统性能调优引擎，能够利用 AI 技术，对运行在操作系统上的业务建立精准模型，动态感知业务特征并推理出具体应用，根据业务负载情况动态调节并给出最佳的参数配置组合，从而使业务处于最佳运行状态。</p><p></p><p>除了调优工具，预计在 2023 年，操作系统领域结合 AI 技术还会带来更多惊喜，比如人机交互。</p><p></p><p>每一次人机交互方式的变化都会导致整个产业的跨越式发展或颠覆式发展。相应地，操作系统也需要做出改变，否则无法支撑新形态下的应用程序。在 2023 年，一旦 AR（增强现实）、VR（虚拟现实）、MR（混合现实）技术取得长足发展，那么，操作系统必然也会迎来跨越式的发展。</p><p></p><h3>如何做好操作系统生态建设？</h3><p></p><p></p><p>生态是操作系统发展的核心，也是其能否成功的关键。与国外主流操作系统相比，国产操作系统由于起步较晚，在生态建设方面仍面临一定的挑战。</p><p></p><p>随着开源发展理念逐渐成熟，越来越多的厂商开始发起成立操作系统开源社区，进一步加快操作系统生态建设。从 2019 年开始，国内先后成立了 openEuler、OpenAnolis、OpenCloudOS 等社区。2022 年，统信、麒麟分别成了桌面操作系统根社区深度（deepin）社区、openKylin 社区。</p><p></p><p>“现在是操作系统社区的春秋战国时代”，受访专家表示，随着操作系统赛道持续火热，越来越多的企业参与其中，建设自己的开源社区。在社区发展的早期阶段，一定会遇到各种各样的问题，但如果产品优秀，围绕这个产品可以吸引足够多的企业 / 开发者参与进来，并具备一定的创新能力，始终保持开放和中立的态度，经过时间的演化，最终会向成熟社区迈进。“做开源社区应该多做实事、少务虚”，受访专家总结道。</p><p></p><p>那么，2023 年，如何才能更好地打造操作系统开源社区？</p><p></p><p>首先，有情有利，方能长久。社区需要进一步鼓励合作伙伴在社区探索出更多的合作模式，聚焦在产品和商业合作本身，真正牵引企业在社区落地。开源不是公益，找准自身商业价值点才能有可持续发展，基于此，操作系统生态才能在开源社区的沃土上成气候。</p><p></p><p>其次，生态是圈，双向奔赴。操作系统是一项门槛比较高的技术，专业人才、技术储备、研发资源都比较有限。围绕客户业务场景，操作系统产业生态圈上的操作系统、芯片、整机、数据库、中间件、以及应用软件厂商需要互帮互助，双向奔赴，让有限资源充分流通，最终拉高国内操作系统产业天花板。</p><p></p><p>最后，放弃小我，成就大我。当前国内操作系统开源社区的局面需要百花齐放，要开展竞争、建立一个完全商业的竞争环境，大家可以在一个小生态里各自产生创新，但最终还是要汇聚在一处。如果没有一个统一的生态、社区或是标准去做，可能就会出现“七国八制”的现象，不仅浪费资源，还影响效率。</p><p></p><h2>写在最后</h2><p></p><p></p><p>有研究机构预测，到 2024 年，国产操作系统有 7 倍的增长空间，到达百亿级的市场规模。可以说，这是国产操作系统最好的时代，机遇远远大于挑战。</p><p></p><p>对于操作系统领域的开发者而言，除了要持续提升自身的研发能力，还要具备创新能力与安全意识，始终对技术保持好奇心，并积极拥抱开源。</p><p></p><p>采访嘉宾介绍（按姓名首字母排序）</p><p></p><p>郭振宇，OpenCloudOS 社区 TOC 主席；</p><p>江大勇，openEuler 委员会主席；</p><p>刘恺，SUSE Euler 负责人；</p><p>马涛，龙蜥社区理事长；</p><p>任革林，OpenHarmony 项目管理委员会首席架构专家；</p><p>张磊，统信软件高级副总经理、CTO；</p><p>张家驹，红帽首席架构师。</p><p></p><p>如果你对本文感兴趣，欢迎在文末留言，或加入 <a href=\"https://xie.infoq.cn/\">InfoQ 写作平台话题讨论</a>\"。后续，迷你书、专题将集合发布于 InfoQ 官网，登录<a href=\"https://www.infoq.cn/\">InfoQ 官网</a>\"注册并将 InfoQ 添加进收藏夹，精彩不错过。更多内容可<a href=\"https://www.infoq.cn/theme/168\">点击查看系列专题文章</a>\"。</p><p></p><p>同时，InfoQ 年度展望直播周将于 2023 年 1 月 3 日首场开播，并持续输出精彩内容，关注 InfoQ 视频号，与行业技术大牛连麦~</p>",
    "publish_time": "2022-12-30 14:18:18",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AI 推理加速原理解析与工程实践分享",
    "url": "https://www.infoq.cn/article/uoUvykdfrWfG3rgJFN7G",
    "summary": "<p>本文整理自同名线上分享，是 12 月份<a href=\"https://www.infoq.cn/video/mPJzSMJ53meqBkFT2Nku\">「百度百舸 - 云原生 AI」技术公开课的第三期</a>\"。</p><p></p><p>这次分享将端到端分析 AI 推理过程以及痛点，介绍业界典型的推理加速思路和具体方案，并介绍百度智能云在这方面的一些实践成果。</p><p></p><p>本次分享我们将介绍如何加速 AI 推理过程。内容主要包括四部分：</p><p>第一部分，端到端的分析 AI 推理的过程以及这个过程中的痛点；</p><p>第二部分，我们将介绍业界典型的推理加速思路及具体方案；</p><p>第三部分，介绍百度百舸平台的 AI 推理加速套件 AIAK-Inference 的加速方案；</p><p>最后一部分，我们则将通过 demo 的方式，演示 AIAK-Inference 的使用方式及加速效果。</p><p></p><h2>AI 推理的痛点</h2><p></p><p></p><p>AI 推理是将用户输入的数据，通过训练好的模型产生有价值信息的过程。具体的是将训练好的 AI 模型部署到提供算力的硬件上，并通过 HTTP/RPC 等接口对外提供服务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2e/2e3564d1ba7485b80b5f73780eb7d281.jpeg\" /></p><p></p><p>这个过程的参与者主要有 2 类人，一类是 AI 算法工程师，他们希望能将自己研发的模型高效的部署到线上，并为模型最终的效果负责。另外一类人则是基础架构工程师，他们负责管理异构算力集群，并为集群的资源利用效率负责。这两类人群的痛点分别如下：</p><p></p><p>对 AI 算法工程师来说，他们希望自己训练的复杂模型可以更快的提供服务。而对于基础架构工程师来说，他们则希望可以将价格昂贵的 GPU 资源发挥出最好的效能。这两类问题都需要解决。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d1/d102e1e9bc45ad63c0545db0af9fb2da.jpeg\" /></p><p></p><p>如果我们从端到端的视角再来分析下整个 AI 推理过程，会发现这两类用户的痛点目前没有得到很好的解决。</p><p></p><p>用户对 GPU 的使用初始于业务系统，用户根据业务需求搭建模型，并为最终模型的效果负责。</p><p></p><p>业务系统构建完成后，会从资源管理系统中申请资源，而资源管理器则会将 GPU 卡分配给业务系统，这个管理器只会为资源分配率负责，而不会关心资源分配后的业务使用效率。</p><p></p><p>用户在申请到资源后，会通过 AI 框架执行模型的计算过程。AI 框架更专注为用户提供易用的模型构建接口，而不会为业务的推理效率和资源利用率负责。</p><p></p><p>最后 AI 框架在使用异构硬件算力时，只能使用基础的加速包或工具，而不会专门结合业务特点进行优化。总的来看，整个过程中没有专门的工具为 GPU 算力的利用效率负责。</p><p></p><p>为此，我们需要 AI 推理加速，针对用户训练好的模型，进行针对性的加速，缩短业务推理时间，同时提升资源利用率。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/82/82b7d891ca8b047b7e73b79b4473ee39.jpeg\" /></p><p></p><h2>推理加速的业界解决方案</h2><p></p><p></p><p>为了系统性的分析和进行推理加速方案，我们首先需要能够定义推理加速的优化目标。为此我们先简单回顾下 GPU 的硬件架构和执行模式。</p><p></p><p>从硬件上看，GPU 的强大算力来源于多 SM 处理器，每个 SM 中包含多个 ALU 计算单元和专有的 Tensor Core 处理单元。对 GPU 来说，当所有 SM 上的所有计算单元都在进行计算时，我们认为其算力得到了充分的发挥。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c1/c13b140d71c7ed9742c60b212afb4c52.jpeg\" /></p><p></p><p>GPU 无法自己独立工作，其工作任务还是由 CPU 进行触发的。</p><p></p><p>整体的工作流程可以看做是 CPU 将需要执行的计算任务异步的交给 GPU，GPU 拿到任务后，会将 Kernel 调度到相应的 SM 上，而 SM 内部的线程则会按照任务的描述进行执行。当 CPU 不发起新的任务时，则 GPU 的处理单元就处在空闲状态。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f5/f57b02d07fb8571422cc650005c91147.jpeg\" /></p><p></p><p>通过这两个层面的分析，我们知道要想将 GPU 的算力充分发挥，其核心就是保持 GPU 上有任务，同时对单个 GPU 计算任务，使其可以尽量充分的用好 SM 处理器。</p><p></p><p>针对这两个层面的使用情况，NVIDIA 提供了相应的牵引指标 GPU 利用率和 SM 利用率：GPU 利用率被定义为在采样间隔内，GPU 上有任务在执行的时间。而 SM 利用率则被定义为在采样间隔内，每个 SM 有 warp 活跃时间的平均值。</p><p></p><p>我们可以通过 2 个 case 来比较下这两个指标的差异。在下图的 case 1 中，由于 CPU 异步发射任务到 GPU 上，GPU 很快就处理完了，于是就出现了等待下一个任务的空隙。在这种情况下，按照定义，GPU 利用率比较低，SM 利用率也相对较低。两个指标都能反应这种情况没有充分利用 GPU 资源。</p><p></p><p>针对下图的第二个 case，对于某一个 Kernel 来说，由于计算实现、参数配置等一系列问题，它只使用了 1 个 SM 处理器，而剩下的 3 个 SM 处理器（假设只有 4 个 SM 处理器）空闲。</p><p></p><p>对于这种情况，由于 GPU 上有 Kernel 在执行，在这个时间段内 GPU 利用率仍然是 100%，但 SM 利用率只有 25%。可以看到这种场景下，SM 利用率可以反应计算任务效率不高的问题，而 GPU 利用率则无法反应此类问题。</p><p></p><p>因此我们认为 SM 利用率可以更精细的反应 GPU 算力发挥情况。因此我们把 SM 利用率当做 AI 推理加速的牵引指标。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/75/7561288cfe0bd03d48bb450ce73859c4.jpeg\" /></p><p></p><p>有了牵引指标，结合模型执行的流程，我们就可以在逻辑上将优化方案分为三类：</p><p></p><p>第一类优化是模型精简类，即在模型真正执行之前就对模型的计算量进行精简，从而提升推理速度。这部分业界常见的优化方向包括量化、减枝、蒸馏和 NAS 等；</p><p></p><p>第二类和第三类则是当模型已经交由推理引擎在 GPU 上执行时，如何更好的提升 GPU 的利用效率。</p><p>我们由 SM 利用率公式做一个近似可以导出这两类优化方案，分别是尽可能让 GPU 上有计算任务和单个计算任务在 GPU 上执行效率更高。这两类优化方案常见的手段分别是算子融合和单算子优化。</p><p></p><p>接下来分别介绍这三类优化方案。</p><p></p><p>在模型精简上，通常大家会采用量化、减枝和蒸馏等手段。</p><p></p><p>简单来说，量化就是将模型中的计算类型进行压缩，从而降低计算量。常见的手段包括离线量化和量化训练两类。</p><p></p><p>离线量化是指在模型训练完成后，离线的对计算算子进行量化，这种方案通常易用性较好，对算法开发人员几乎透明，但对模型精度会有一定损失；量化训练则是在模型训练过程中就显示插入量化相关的操作，这样通常会有更好的精度，但需要算法开发同学准备相关数据。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/33/3351fa8bdc8afba51e5643efb934b9d7.jpeg\" /></p><p></p><p>而减枝则是通过将模型中对结果影响较小的一些计算进行移除，从而降低计算量。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5f/5fd192f95b134cae3ee96ce2d3118fa3.jpeg\" /></p><p></p><p>蒸馏则通常是将一个复杂的大模型通过降维的知识传递层，将大模型中的复杂计算，减少为效果相当的更小规模的计算，从而实现降低计算量，提升推理效率的效果。下图中是百度文心 3.0 大模型知识蒸馏的过程。</p><p></p><p>这些模型精简的方案，由于涉及到对精度的影响，通常需要算法工程师介入，协同优化。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/15/15aa8a72e330a33a96d82cda64f63bc0.jpeg\" /></p><p></p><p>第二类优化则是算子融合，算子融合顾名思义是指将多个计算算子合并成一个大算子的过程。</p><p></p><p>例如对于 BERT Base 这个模型，经过 PyTorch 原生 jit 编译生成的 TorchScript 图中有 800 多个小算子，这些小算子会带来 2 类问题：一是这些算子通常执行过程较短，因此会造成大量的 GPU 空闲时间；二是由于不同的任务之间还有数据的依赖，因此也会带来额外的访存开销。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/68/684f59258b615a0856c5d865c46c4ef8.jpeg\" /></p><p></p><p>目前针对算子融合，业界通常会采用手写或自动化生成的方式发现可融合的模式，并提供融合后的算子。例如针对 Transformer 结构，NVIDIA 开发了 FasterTransformer 这个库，其中包括针对多种 Transformer 类结构模型的具体融合算子。</p><p></p><p>例如下图中，针对 batch GEMM Q x K、Softmax、batch GEMM for QK x V 和长尾的 transpose 等操作，FasterTransformer 提供 Fused Multi-head Attention 等融合后算子。BERT Base 在经过 FasterTransformer 的算子融合优化后，数量可以降到 100 个左右。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f3/f3f0bf2db5cdc77879b84e4b84d5511a.jpeg\" /></p><p></p><p>第三类优化则是单算子优化。单算子优化是根据单个算子，结合计算模式和硬件架构特点，调整 GPU 核函数的实现方法，从而提升具体算子的执行效率。单算子优化中，最经典的例子就是对通用矩阵乘（GEMM）的优化。下图是 NVIDIA Cutlass 库对 GEMM 操作的抽象：</p><p></p><p>Cutlass 结合 GPU Global Memory、Shared Memory、Register File 这几层存储架构和 block、warp、thread 和 tensor core 这几层计算抽象，设计了一系列计算模板，并提供相关可优化参数（切分大小等），方便开发者开发高性能的 GEMM 实现。</p><p></p><p>以上就是业界常见的几类 AI 推理加速的方法和业界的一些解决方案。接下来我们重点介绍下 AIAK-Inference 是如何站在巨人的肩膀上，提供性能更好的推理加速方案。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/38/38c624892767ba412db1de07d782d324.jpeg\" /></p><p></p><h2>AIAK-Inference 推理加速套件简介</h2><p></p><p></p><p>AIAK-Inference 是百度智能云提出的 AI 推理加速套件，是百度百舸整体方案中的一部分。</p><p></p><p>AIAK-Inference 旨在优化在百度智能云上采购的 GPU 等异构算力的推理效率，降低推理延迟，提升推理吞吐。只要通过百度百舸方案提供的 GPU 算力，都可以使用 AIAK-Inference 进行推理加速。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e2/e25845f7229189132154286c9889cb73.jpeg\" /></p><p></p><p>AIAK-Inference 的整体架构如下图所示，整体分为 4 个层次，分别解决的问题如下：</p><p></p><p>图接入：解决多框架动态图 / 静态图捕获问题，将动态图转换为推理友好的静态图；后端抽象：支持将业界多种优化方案统一整合，通过计时的方式选择最优的加速后端；具体加速后端，支持业界多种开源加速后端，包括飞桨提供的 FastDeploy 等；此外还有一套自研加速后端，通过图优化、图转换和加速运行时三部分对模型进行整体的推理加速；算子库：除了使能业界最优的常见计算算子库，还针对具体场景的重点计算模式进行定制化开发，提供场景加速的算子库。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fb/fb232d40c8cf62492b5b20d6b1700180.jpeg\" /></p><p></p><p>与业界其他方案相比，AIAK-Inference 主要有 2 大特点，第一个是博采众长，支持多种优化后端的无缝接入，并通过计时选优的方法将效果最后的加速后端提供给用户；第二则是深入场景，针对重点场景的计算模式，通过 AIAK-OP 算子库进行专有加速。</p><p></p><p>AIAK-Inference 的加速原理也类似第二节讨论的业界常见方案，主要从图精简、算子融合、算子优化几个层面展开</p><p></p><p>在图精简上，AIAK-Inference 除了兼容社区常见的量化、减枝、蒸馏、NAS 等方案，还提供一些数学等价代换、死代码移除等精度无算的图精简操作；在算子融合上，AIAK-Inference 支持访存密集型算子融合、GEMM/Conv 长尾运算融合和背靠背 GEMM 融合等多种融合策略；而针对具体的单个算子，AIAK-Inference 则通过调度、访存、模板化优化等思路，实现了一系列高性能场景化算子。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f1/f1f62fbf33614bfe78ee94e67c886e22.jpeg\" /></p><p></p><p>具体举几个例子，对于单算子优化，我们通过 ncu 工具发现我们生成的 Conv 算子执行时有 20% 的访存指令浪费，通过将访存操作聚合，减少访存操作，最终模型端到端性能提升 3%。</p><p></p><p>算子融合上，我们针对 NLP、CV 场景开发了相应的重点融合算子（如 FMHA、YoloBox 等），并在通用场景针对卷积 + 长尾操作生成了一系列融合算子。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0d/0dd1f7c546f43ccc2e8ca87c4b8e57e1.jpeg\" /></p><p></p><p>除了这些之外，我们还紧跟社区生态，正在开发适配 PyTorch 2.0 编译生态的 Dynamo 编译 Backend；在算子生成方面，我们也开发了一套针对模板的自动化算子生成方案。</p><p></p><p>以上就是 AIAK-Inference 推理加速套件的整体介绍，我们接下来看看如何在百度智能云上使用推理加速套件。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c1/c1a8adf972d30a4cce1b33f5de1f6418.jpeg\" /></p><p></p><h2>使用 AIAK-Inference 推理加速套件</h2><p></p><p></p><p>首先整体介绍下 AIAK-Inference 推理加速套件在 AI 推理流程中的位置。</p><p></p><p>如下图所示，AIAK-Inference 是通过优化推理模型进行推理加速的。具体的说，算法工程师原来进行模型部署，是将 TorchScript/SavedModel 等训练好的模型通过 Inference Server 进行部署。</p><p></p><p>而 AIAK-Inference 则是在部署之前增加一个流程，通过开发一个核心只有 1 行代码的优化脚本，通过 aiak_inference.compile 优化接口，对 TorchScript/SavedModel 等模型进行优化，并返回优化后的模型。</p><p></p><p>用户可以将优化后的模型仍然部署到 Inference Server 上，部署无感的进行加速。总结下来就是优化代码离线化改造，业务部署零代码侵入。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/54/541035df006d3357da091af2b385dc9f.jpeg\" /></p><p></p><p>了解了整体使用方式后，我们来具体操作一下。首先为了使用 AIAK-Inference 推理加速套件，需要进行环境准备。AIAK-Inference 提供加速镜像和 wheel 包两种安装方法，无论哪种方案，用户只需要下载对应的镜像或安装 wheel 包，即可完成环境准备。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2c/2cdfe257b49d1bcbbc41aa80cd1930e5.jpeg\" /></p><p></p><p>环境准备完成后，只需要开发刚才演示的一个优化脚本，即可完成模型的优化。接下来以 ResNet50 模型为例，进行一个完整流程的演示。<a href=\"https://mp.weixin.qq.com/s?__biz=MzkxOTM4MTM3Ng==&amp;mid=2247485287&amp;idx=1&amp;sn=7d5590d3dbe8db42c04d69ba236c5130&amp;chksm=c1a3b388f6d43a9e91295cf56e341b25e9346cd776f8643a92895d0b968102e4a04f4e583d4c&amp;mpshare=1&amp;scene=21&amp;srcid=1227LMLwEyyIyQgiobNb2DbS&amp;sharer_sharetime=1672194336895&amp;sharer_shareid=8b44a188e33576dfd4362591e2688c4a&amp;key=eb16c4aa1548428c7e240c5eef4fdc7f9ac2c4b2b377f36a7f93a6f2f5ae31a0e3a088379c46c94235b1f3e7c1030e3a5d2225c53617220319fd61cdb93ab1bce0e1b06882e8be73d9864adab295bf2ba564e95f7568fc1cc9d33aa89c3954b051917966cd8f0257218348eec245db32b73530dd3007c9f6d42b182debf50967&amp;ascene=1&amp;uin=Mjg0MDUwODQxNA==&amp;devicetype=iMac%20MacBookAir10,1%20OSX%20OSX%2012.6%20build(21G115)&amp;version=13050510&amp;nettype=WIFI&amp;lang=zh_CN&amp;fontScale=100&amp;exportkey=n_ChQIAhIQZQdYJU2b/uzeFyJxcSu4JxKVAgIE97dBBAEAAAAAAKR4EDDq6S0AAAAOpnltbLcz9gKNyK89dVj0D7%20UeTQxq0whR3JtLNnXaa62gY0STDVLYC1g1ILzdP9TTmQ4YaLwF6228yU6qQJ1jhtK8s4oaYx4JXDS7qyJ1rsvm1q3fqHT3zmRYymkFqAl1vIABYjsXcz3a4QxaUumI5oDJfgYzd2ETCzmqrrBY0ObdjoYi6J3IaRd2lnic%20fJSeZbYXZY15WElqk8D64yq05F8Pb1KZzYDptVD4kp7097JrKBUfxR%20nOHj%20bivZbHNhAFiDow3nZLTT2h/DiB6Yyb3e5tdNblH2k1HMwBQmd4d8K8OuhMFdXldeu6SvkQBRw85e7aoaxMR3TF36c=&amp;acctmode=0&amp;pass_ticket=vevJ0S%20czrFsMV9nSKwAg1Z5rSGNvAwf/0lxaDJ52U6riVfEgqsZBReLBuCXuHdvwpMb4wB0ecywUSjb3T//8A==&amp;wx_header=0#wechat_redirect\">AIAK Inference 操作演示视频</a>\"</p><p></p><p>本次演示中使用了 2 个脚本，分别是 infer.py 和 optimize.py。其中 infer.py 是模拟用户部署的脚本，简单看下代码可以看到，这个脚本主要是加载模型，进行 100 次预热操作，然后执行 1000 次推理，并在 CPU 侧完成计时。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ca/ca2a9705ecfeb6f4311746218a614381.png\" /></p><p></p><p>简单执行这个脚本，可以看到 FP32 精度下，BS=1 的 ResNet50 在 T4 平台上，推理平均延迟是 6.73ms。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/03/033941f8e16fb2c746689e2e8105d467.png\" /></p><p></p><p>接下来使用 AIAK-Inference 对模型进行优化。这里我们使用 optimize.py 脚本，其代码如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5b/5bcaf9ee0845541c33ded21962262ad7.png\" /></p><p></p><p>整体代码非常简单，加载模型，调用 aiak_inference.optimize 接口进行优化，并将优化后的模型进行保存。这里为了演示我将优化后的模型保存成与优化前模型同名的模型。</p><p></p><p>有了优化后的模型，我们什么都不做改动，再次执行 infer.py（即模拟业务部署代码零改动），可以看到模型推理耗时大幅降低，只需要 3.54ms。</p><p></p><p>从而可以看出使用 AIAK-Inference 可以通过简单的脚本对模型进行透明优化，优化后的模型在推理效率上有大幅提升。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f5/f5b0e6263ec751b98490d8eff3198a3f.png\" /></p><p></p><p>除了刚才演示的单个模型，AIAK-Inference 还在多个模型上验证了效果。下表是 6 个典型 CV 类模型，可以看到推理延迟分别降低 40%~90%。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3a/3afc71d4472d02318a88459e7834daf0.jpeg\" /></p><p></p><p>以上就是今天分享的全部内容，谢谢大家。</p>",
    "publish_time": "2022-12-30 15:16:16",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Gartner 数据库魔力象限解读 | DBTalk 技术公开课第6期",
    "url": "https://www.infoq.cn/article/YS4byz52CheyAgfYSxy4",
    "summary": "<p>随着数字化进程的加快，数据越来越成为数字时代的基础性战略资源和革命性关键要素。作为数据存储与计算的基础软件，数据库对于筑牢数字经济底座至关重要。</p>\n<p>如今，数据库支撑着经济社会活动的关键核心业务，几乎所有的应用软件都需要基于数据库进行存储、管理和分析。近年来，随着国产自研数据库的不断创新，其在安全、稳定、高效性方面的优势持续凸显，市场占有率也在扩大。近日，腾讯云数据库进入Gartner数据库魔力象限，在 OLTP（TDSQL/TDSQL-C）及轻量级 TP 能力（KeeWiDB）得分均为国内第一。</p>\n<p>腾讯云数据库为何能够入选 Gartner 全球数据库魔力象限？多项数据库核心能力（critical capability）得分国内第一的秘密是什么？本次技术公开课，将回望腾讯云数据库自研之路的挑战和突破，挖掘自研数据库在存储、数据访问等方面的技术创新与实践。</p>",
    "publish_time": "2022-12-30 17:34:15",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "TDSQL 在 TP 领域的技术探索和实践 | DBTalk 技术公开课第6期",
    "url": "https://www.infoq.cn/article/idUjJYN3E5bj9pjByqRB",
    "summary": "<p>经过近 20 年的研发和应用实践，腾讯分布式数据库 TDSQL 已被越来越多客户所采用，<br />\n在分布式、高可用、稳定、性能等方面持续突破，支撑金融、政务、电信、游戏、互联网等各个领域进行数字化改造，尤其是在核心交易场景方面得到了非常广泛的应用。<br />\n本次分享重点介绍这 2 年 TDSQL 在 TP 领域的一些技术突破，以及如何通过这些技术帮助我们的客户顺利完成从传统集中式架构到分布式数据库的转型。</p>",
    "publish_time": "2022-12-30 17:34:18",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "KeeWiDB 轻 TP 技术实践 | DBTalk 技术公开课第6期",
    "url": "https://www.infoq.cn/article/DkqXdvIXScvkZwfG599y",
    "summary": "<p>KeewiDB 作为一个兼容 Redis 协议的 NOSQL 数据库，除了兼容社区 Redis 行为外，作为存储数据库，有必要实现 Redis 不具备的 TP 能力，从而更好的符合用户对存储数据库的诉求, 同时作为 Nosql 数据库还需要提供高性能的TP。本次分享介绍 KeewiDB 在 TP 实现的一些思考和实践。</p>",
    "publish_time": "2022-12-30 17:34:25",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "新一代云原生 TDSQL-C 关键技术突破 | DBTalk 技术公开课第6期",
    "url": "https://www.infoq.cn/article/HswNYNTZkJvBHSeSJ3l0",
    "summary": "<p>云应用程序的这些需求为云原生数据库提供了新的机会，而传统的企业内部数据库系统无法完全满足这些需求。腾讯云原生数据库经过多年的研发和打磨，所实现的计算、内存与存储资源的解耦的“日志即数据库”架构、HTAP、Serverless 等特性已是全球首创或业内领先的技术，同时其性能对比传统云数据库达到数倍的大幅度提升。</p>\n<p>本次分享将围绕着腾讯云原生数据库在架构演进、软硬结合探索、自研内核优化等方面的核心技术解析。结合海量数据存储、高频交易场景、流量洪峰/不可预估场景、开发测试等周期性峰值业务场景的行业案例，深入解析新一代云原生数据库 TDSQL-C 的产品特性、技术亮点以及未来的发展趋势。</p>",
    "publish_time": "2022-12-30 17:34:29",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "能源数字化是能源演进的趋势，华为发布站点能源十大趋势",
    "url": "https://www.infoq.cn/article/YNhgQ1sMgksqZAZQRqCG",
    "summary": "<p></p><p>当前，碳中和已是全人类的共同使命，各国家出台多种政策并采取行动，推动绿色发展。去年，我国提出“3060”双碳目标，“1+N”政策体系逐步落地，在全国，包括北京、上海、广东、深圳等在内已经有 31 个省市陆续制定了双碳目标。</p><p></p><p>华为认为，面向碳中和，低碳化和数字化是两个大的趋势。低碳化方面：能源结构加速走向发电侧清洁化、消费侧电气化；数字化方面：数字技术驱动人类进入数字文明时代，IT、CT融合，5G、AI、大数据等充分融入到各种产业场景包括能源场景，ICT成为各行业数字化的技术底座。</p><p></p><p>InfoQ不久前发布的<a href=\"https://www.infoq.cn/article/BXWSliYk7FK3EfGSbRtS\">2022年数字化盘点文章</a>\"中也提到，为落实可持续发展目标，如何利用数字化技术实现低碳、绿色、降低能耗，实现高质量的可持续发展，已成为企业数字化的重要议题。</p><p></p><p>那么，在2022年，随着技术的发展和环境的变化，在ICT耗电占据主导的通信站点的节能降碳，产生了什么新的变化，未来的趋势是怎么样的？针对该议题，12月29日，华为发布<a href=\"https://digitalpower.huawei.com/attachments/index/823f8f55a0b445fea5daf362a14413d2.pdf\">《站点能源十大趋势白皮书》</a>\"，这十大趋势关键词分别是：能源数字化，低碳网络，站点供电绿色化，站点极简化，站点高效化，全面智能化，通信站点社会化，多模架构，备电走向备储一体，安全可信。</p><p></p><p>华为站点能源领域总裁尧权表示，2022年是不平凡的一年，全球能源危机背景下，油价、电费持续上涨，运营商OPEX剧增，站点能源受到越来越多的关注。在此背景下，华为分享站点能源十大趋势，旨在与业界共同推进站点能源朝着极简化、绿色化、智能化方向升级变革，助力运营商加速实现网络碳中和。</p><p></p><p>以下是「白皮书」中提及的十大站点能源趋势：</p><p></p><h4>趋势一：能源数字化</h4><p></p><p>在通往碳中和的路上，ICT主要有两个核心任务，一是ICT自身的绿色低碳化，即Green ICT，二是ICT赋能千行百业降碳，即ICT for Green。对于这一切，数字技术与电力电子技术是根基。通过融合数字技术与电力电子技术、能量流与信息流，加速能源数字化，实现“比特管理瓦特”，进而推动能源行业及社会绿色低碳化转型。在可以预见的未来，无论对ICT还是对千行百业，能源的数字化都是势不可挡的趋势。</p><p></p><h4>趋势二：低碳网络</h4><p></p><p>ICT技术提升了社会运行效率，改变了人们的生活，但同时ICT网络演进也带来了功耗和碳排的增长。尤其是在能源危机及碳中和的背景下，各运营商都在积极行动，寻求建设一张从建网、供电再到运行的全生命周期绿色低碳网络。</p><p></p><p>在建网侧，站点走向房变柜、柜变杆，极简低碳建网。在供电侧，通过提升站点叠光比例，让绿电成为ICT站点的主要供能，减少市电消耗。在运行侧，通过站点数字化和运维智能化，减少人工上站运维，识别能耗及碳排异常站点，进一步降低站点运维成本和碳排放。</p><p></p><h4>趋势三：站点供电绿色化</h4><p></p><p>过去站点供电主要依靠市电或油机，绿电比例仅约1%。新能源技术的进步以及新商业模式的出现，太阳能、风、氢等清洁能源在站点供电中越来越重要，站点的供电呈现多样化清洁能源供电趋势。随着电价、油价上涨，同时清洁能源成本进一步降低，运营商将在PPA购买绿电的基础上加大自建绿电比例。</p><p></p><h4>趋势四：站点极简化</h4><p></p><p>传统建站多采用机房或者柜站，空调能耗高、效率低，成本高。在5G时代，站点数量剧增，建设成本飙升，传统模式不可持续。因此，站点形态需走向房变柜、柜变杆，实现极简部署，结构性降低能耗和碳排。</p><p></p><h4>趋势五：站点高效化</h4><p></p><p>站点从单一部件高效走向建站方式、供电全链路以及主设备协同全方位高效。</p><p></p><p>在形态高效方面：站点从房变柜，柜变杆，能效可以大幅度提高到97%，减少占地，极简部署。在供电高效方面：过去专注于整流模块效率的提升，随着新型半导体材料的加大商用以及数字技术使能功率智能化，站点供电朝向发、转、储、配、全链路高效的方向演进。在协同高效方面：电力电子技术与数字技术相融合，比特瓦特联动，能源设备与无线设备协同，实现精准能效管理和能耗优化。</p><p></p><h4>趋势六：全面智能化</h4><p></p><p>传统站点哑部件居多，管理粗放，站点的能耗、碳排不可视，节能降碳无从下手。另外，站点的维护也需要人工上站去运维，且无效下站多，导致运维成本高。通过站点数字化，站点将从简单管理走向全面智能化，实现运维自动驾驶、能效与碳排实时可视可优，进一步提升站点运行效率。</p><p></p><h4>趋势七：通信站点社会化</h4><p></p><p>海量通信站点蕴含巨大商机，但过去由于业务模式单一，站点资源未充分利用。未来，一方面通信站点将走向社会化，运营商从单一通信运营商走向综合运营商。另一方面，站点除了给通信设备供电外，还可以给民生、电力、油气等其他设备供备电，客户多样化。此外，站点业务模式多样化，比如虚拟电厂VPP、电随网进、以电换租等新业务给运营商带来开源增收，最大化释放通信站点价值。</p><p></p><h4>趋势八：多模架构</h4><p></p><p>随着站点供电从传统单一的市电或油机输入，转向市电、油机、风能、太阳能等多能源输入。同时站点社会化，将出现给不同行业、不同制式设备供备电，需要多制式输出。采用多模架构设计，能满足多能源接入、多制式输出的站点电源将越来越普及，成为部署主流。</p><p></p><h4>趋势九：备电走向备储一体</h4><p></p><p>传统通信站点储能往往只给通信设备备电，功能单一，资产闲置。随着峰谷电价等政策出现，越来越多的运营商开始探索错峰用电、虚拟电厂VPP等商业模式，将储能资产参与电网协同调度，站点储能从简单备电发展为备储一体化，走向循环型的应用。这对于运营商而言，可以激活闲置资产，增加收益，节省电费；对于电网而言，多了一份供电保障，提高了电网稳定性。</p><p></p><h4>趋势十：安全可信</h4><p></p><p>对于站点能源，安全可信至关重要，它包含两个方面，第一是网络安全，第二是硬件安全。在能源数字化大发展的趋势下，如何减少攻击风险与自身安全风险，已经成为各个国家和行业越来越重视的焦点，一系列包括网络安全及硬件自身安全在内的安全规范要求将持续出台。</p><p></p><p>延展阅读：</p><p></p><p><a href=\"https://www.infoq.cn/article/wK91ohatBuULkxsliMaa\">《在华 15 个“零碳工厂”，施耐德电气如何用技术实现“绿色”目标》</a>\"</p><p><a href=\"https://www.infoq.cn/article/vAYa8LWjQgHtestxjtWO\">《国环碳中和 CEO 张超：用新型能源互联网平台，推动“双碳”目标达成 | TGO 专访》</a>\"</p>",
    "publish_time": "2022-12-30 17:50:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "只用2年完成改造、兼备高稳定性和灵活性，作业帮多云实践",
    "url": "https://www.infoq.cn/article/9JAtZi9td8mrFddkcfqU",
    "summary": "<p></p><p>采访嘉宾 ｜ 董晓聪</p><p>编辑 ｜ Tina</p><p></p><p>云技术发展了十几年，但就算是到了今天，我们依然无法保证云服务不会发生宕机故障。另外对于成熟企业来说，数据是最宝贵的核心资产， 那么他们必然会担心会被某单一的技术提供商锁定，或担心公有云厂商进入自己的商业领域…</p><p></p><p>无论是用于平衡风险还是充分利用各种云平台的优势和用例，很多组织都会有意无意地让工作负载在多个云中运行。别把所有鸡蛋都放同一个篮子里，是放之四海皆准的思想。据统计，目前全球 81% 使用云服务的公司或组织正在使用多云，但不同的企业有不同的实践方法。</p><p></p><p>作业帮一开始就建立在公有云底座之上，享受着早期云计算释放的成本红利，也同样会面临云计算带来的这些挑战。因此作业帮从 2019 年开始，逐渐开始了多云转型。经过几年实践，作业帮形成了自己的多云架构，也应对过一些挑战，并有了一些非常有价值的思考。在组织“<a href=\"https://www.infoq.cn/theme/167\">多云专题</a>\"”的时候，我们采访了作业帮基础架构负责人董晓聪。</p><p></p><p></p><h2>多云的基本概念</h2><p></p><p></p><p>InfoQ：有人说多云的定义是开放的，那么在您们看来，我们该如何定义现在的多云？</p><p></p><p>董晓聪：多云是指企业使用两个或更多数量云服务供应商。之所以大家认为这个概念比较开放，是因为这个定义不是那么刚性。比如企业使用多个供应商的 SaaS 服务，这个能算多云吗，这个就和当下主流的理解是不一致。当下谈到多云，更多是讲的企业使用多家云厂商的 IaaS、PaaS 产品。</p><p></p><p>在多云这个范畴下，企业架构也有多种模式，如主备多云、弹性多云、业务切分多云、数据主权多云、多活多云等等。每一种架构下的特征也不尽相同，提炼其中的共性来看，多云应该具备如下特征：</p><p></p><p>具备选择权。多云给了企业选择的权限，可以选择成本更优、服务更好、功能更完备的云产品。这是对企业更有利的。对应用层屏蔽多云差异。除了给企业带来好的一面外，多云不可避免的带来了复杂性。对业务应用而言，需要有统一的 DevOps 管控面，屏蔽多云带来的部署差异、服务治理差异。网络互通。上面更多是讲的抽象的利弊特征，再来从具体的资源层和应用层看下。资源层这块多云最重要的是要把多个云厂商基础设施连接起来，不论是通过专线互通，还是通过 VPN 隧道，都要纳管到统一的网络平面。流量调度。只要在多个云上部署了应用服务，就涉及到流量的调度。其中既有用户侧的南北向调度，也有服务跨云的东西向调度。这些调度能力载体是 DNS、ingress、服务注册发现、Service Mesh 等。</p><p></p><p>InfoQ：多云解决的是什么问题？您们为什么需要它？</p><p></p><p>董晓聪：多云具有如下优势：</p><p></p><p>灾难恢复，当一家云供应商出现故障时，数据存储可以从另一家云供应商进行恢复。虽然云厂商有多地域，单地域也有多可用区，但还是存在中心化的依赖。这种依赖的故障就会导致整个云的故障。后面提到的故障主要指这种类型的故障。故障转移，当一家云供应商出现故障时，使用另一家云供应商承接服务，实现服务平稳不中断。成本优化，任意的采购只要有了两家及以上供应商，采购方就有了充分选择和议价的能力。避免供应商锁定，单一供应商，除了没有议价能力外，各种依赖也会使得变更极为困难。数据主权，企业提供服务，但产生的数据产权也是归属于服务对象。服务对象既有普通的用户（行权由国家主体代为进行），也有机构。他们对产权的需求，连带的导致企业的云基础设施选择也受其限制。特定服务访问，不同云有自己优势的服务，一般出现在 PaaS 层，如各式各样的数据库、大数据实时方案等。使用多云可以集各家之长。</p><p></p><p>InfoQ：现在主要有哪几种多云架构？性能是否有不同？部署是否有不同？</p><p></p><p>董晓聪：多云存在多种架构，对企业而言也是随着不同的发展阶段去选择适合自己的架构。每种架构没有绝对的优劣之分，更多的是看是否匹配业务。这个就像是服务架构从单体到微服务。微服务架构一定比单体更优吗，这个并不一定，对于业务初期或者交付类业务，单体的优势会更明显。</p><p></p><p>说回到多云架构，其主要有如下具体架构。</p><p></p><p>主备多云：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/20/2003454e3b9fedeaccda84df21bccf8d.png\" /></p><p></p><p>企业的应用服务还是在一家云厂商上，用户通过 DNS 解析过来，数据沿着网关、应用、数据存储这条链路流转。企业出于数据灾备的考虑，将数据存储同步到另一家云供应商上。亦或者企业有海量对象存储归档的需求，而另一家云在存储架构上有优势，如提供更具性价比的深度归档存储能力，或直接提供更具竞争力的价格。基于这些存储，企业还可能在备份云上开一些衍生的离线的计算，用来进行二次加工等。</p><p></p><p>弹性多云：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c2/c2c722eb6de4a0cba7cd7f4b7176f7af.png\" /></p><p></p><p>随着合作的更进一步，第二家云供应商抛出更优厚的条件，能提供更多的弹性计算能力。企业对这家云的使用变得更多，不再仅仅满足存储备份需求，开始把一些重要的应用服务进行部署，以应对一些突增流量的弹性需求。为了确保有突发流量时第二家云可以稳定承接，所以常态下就要承接一定流量，保证服务是双活的。当流量增加时，弹性云进行快速扩容，通过 DNS 或者网关将主云上无法承载的流量转移到弹性云上。</p><p></p><p>业务切分多云：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e9/e9fe780d395130ba5807afd1b1f4278f.png\" /></p><p></p><p>业务切分多云，这个也很好理解。公司有多个部门，或者直接是多个子公司，各自部署到钟意的云厂商上，就形成了这样切分的局面。这种多云模式往往也是最普遍的。用户访问不同业务使用不同的域名，不同域名根据 DNS 路由到不同云的不同服务上。两家云加起来才是公司完整的服务。因为业务线强势，中台无统一规划往往会出现这种情况。当然还有就是在线业务用一家云，离线业务用一家云等等。</p><p></p><p>数据主权多云：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b6/b64f238b6ef5374e3e46810e97d5e7e2.png\" /></p><p></p><p>不同用户群体，通过 DNS 路由到不同云上，在各自内部完成网关、应用、存储的数据链路，不同云之间不进行数据互通。每个云上都是完整的应用，但数据只有各自的用户数据。主要的场景有：</p><p></p><p>业务出海，很多国家都限定了数据不准离境，甚至规定了专属的云供应商。企业不得不一套代码，部署在多家云上。有些私有化交付项目也是类似，企业需要按照雇主的要求部署在指定的公有云或者私有云上。</p><p></p><p>多活多云：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/74/74c2f181589b7933412761bb894c46c3.png\" /></p><p></p><p>这种也是最复杂的一种，企业将服务等量部署在两家云供应商上，通过 DNS 进行流量分配。数据存储一般采用主从模式，随着分布式数据库的逐渐兴起，也有较多的选型，这里先简单按照主从来讲。多活多云是对稳定性和成本极致要求的产物。这种模式对多云互通的网络质量要求最高。</p><p></p><p>InfoQ：国外有 Snowflake 等多家多云企业，在您看来，国内外的多云技术、生态是否有所不同？</p><p></p><p>董晓聪：多云整体的理念是国外兴起的，有几个代表公司，如 HashiCorp、Snowflake。HashiCorp，是一家多云和基础设施管理公司，通过建立一系列开源工具，成为企业通往云的 “桥梁”，帮助企业实现云基础设施自动化、代码化。HashiCorp 关注重点在基础设施的多云。Snowflake 是一家基于云计算的数据管理软件公司，核心技术能力在于实现数据的跨云储存和计算，通过在云上扩展出一体化、一站式的数据处理和数据应用方案，令客户可以便利地挖掘数据价值。关注重点在 PaaS 的多云。国内类似的企业也有不少。</p><p></p><p>如果真要说国内外的生态差异，我感觉还是侧重面会有不同。多云在效率、成本、质量等方面均有收益，但国外的多云产品，尤其是基础设施层面的，会更侧重效率一些，如 HashiCorp 的创立原因就是创始人在工作花了绝大部分时间开发基础设施工具，配置云，创建开发工具等与公司核心业务相关性不高的工作。所以决定开发一款通用性产品，将工程师们从基础设施设计这件重复的杂活中解放出来，自动化这一过程。而国内多云管理的公司对外宣传会更侧重云成本的优化，这两年还在结合 FinOps 做宣传。为什么会出现这样的差异呢，国外人工成本高，产品化标准，产业分工完备，大家更倾向于专业的人做专业的事。所以企业会基于效率作出选择。而对于国内，定制化需求过多，这时候人的效率较难衡量，但云成本的财务账是显而易见的。</p><p></p><p>除了效率和成本外，还有一类公司是以质量为重。在国内是一些数十万核到数百万核的公司，这些公司自建 IDC，从人员和资源成本上看都不划算，上云还是最优解。但因其处于垂直领域的头部竞争或快速上升期，质量对其业务发展影响较大。对于此类企业多云建设的考量会更倾向于质量。由于企业基于不同的出发点选择多云架构，技术上也会呈现一定的差异，在前面的多云方案中也有提到。</p><p></p><p></p><h2>作业帮多云实践</h2><p></p><p></p><p>InfoQ：作业帮的多云规划是从什么时候开始的？当初选型时有考虑过哪些因素？</p><p></p><p>董晓聪：作业帮从 2019 年底还在虚机架构下时就要考虑核心业务多云多活的事情。这个是因为作业帮对稳定性和成本有着极致的追求。</p><p></p><p>我在加入作业帮之前，在传统互联网、工业互联网、金融互联网等行业有一定工作经历，作业帮对稳定性的要求是最高的。我认为主要是因为两点，一是之前在做传统的互联网的时候，用户离我们很远，在我们心目中的用户本质上是 UV、PV 这样的数字，但在线教育真的不一样，我们的主讲、辅导老师通过直播等形式和用户面对面在一起，更真切的感受用户。另一块是，我们用户的服务时间比较聚焦，几分钟的故障都可会影响学生整节课的学业，所以我们对稳定性的要求只能更高。单集群高可用，甚至单云多可用区高可用仍无法满足我们对稳定性的诉求。</p><p></p><p>这些问题很难一蹴而就的在虚机架构下得到很好的解决，所以作业帮选择了先进行云原生的改造，用基础设施接管业务当中大量非功能的逻辑，以此来实现弹性、可观测性、韧性、自动化、可持续等相关一些特性。再基于底层的容器技术和服务治理能力，构建起一套多云多活的架构。作业帮在线业务坚定的选择多活多云的策略，只有这样才能带来理想的稳定性和成本收益。</p><p></p><p>InfoQ：您们的多云解决方案的整体架构是怎样的？</p><p></p><p>董晓聪：作业帮多云多活架构详细如下图所示。</p><p></p><p>企业技术架构从大的层次来说，会分成两层，底下的一层资源层，包括计算、存储、网络等 IaaS 资源。应用这个层面，有底下的各种各样的 PaaS 组件，有数据存储的、有消息队列的、有安全的、有大数据的等等，然后再往就是具体的业务应用。</p><p></p><p>作业帮在实践中逐步摸索出一套多云组网 +CPE 管控的方案，实现在双云间甚至多云拓扑下的网络互通，以及诸多其他特性，如弹性 - 带宽快速扩缩、可观测性 - 跨云异常流量的分析、韧性 - 单节点单线路故障自动切换、可持续 - 新增云供应商的快速接入等。</p><p></p><p>虽然多云间网络上做了很多高可用的保证，但时延还是客观存在的，在微服务下会被成数量级放大。所以跨云的注册发现同步以及通信会有一系列问题，所以我们选择单云单集群，常态应用流量闭环在单个云机房内部的方案。如果需要跨云的话通过调度路由走边界网关进行通信。</p><p></p><p>数据存储方面，主要是用的还是经典的主从架构，不过根据业务对 CAP 不同的需求进行支持，有的业务以读取为主，数据的时效性要求不高，故障时可以牺牲一致性，要可用醒。而对于交易类型的业务，对数据一致性高度敏感，故障时宁可短时不提供服务，也不能使用不一致性的数据。除此之外，我们也在部分场景验证多主、MGR、单元化的方案。</p><p></p><p>InfoQ：多云需要使用多家云厂商服务，比如在使用腾讯、阿里或 AWS、Azure 和 Google 这些基础设施时，需要对调用的每个云厂商都具有高性能，并且有统一的 API，但实际上每家云厂商的 API 都不同、性能和成熟度也不同，这种情况下，您们的解决方案是什么？</p><p></p><p>董晓聪：每家云厂商提供的 IaaS、PaaS 能力看上去差异不大，计算无外乎是物理机、裸金属、虚拟机、Serverless。网络无外乎是 EIP、LB、NAT、VPC 等实体。PaaS 是各种持久化、内存型存储存储、大数据离线、实时计算产品。但深入到产品特性后，差异很大，管控面凹凸不齐。多云管控面要作为胶水层，对上游抹平这些差异。</p><p></p><p>我们做的时候要调研过一些开源产品和商业产品，但大家做的相对比较浅，只做了基础 API 的封装。真正麻烦的地方在逻辑的封装。如一家云厂商的某项资源管控比较宽松，仅用一个 API 即可实现功能。但另一家因为产品策略的收紧，需要结合多个产品才能实现类似功能。运维平台就需要将这些包成事务，对上层提供统一的能力。</p><p></p><p>InfoQ：作业帮在实践中，多云的运维和管理层面应用了哪些工具或流程？</p><p></p><p>董晓聪：作业帮在 2019 年底就开始探索多云架构，当时国内还没有成熟的多云管理产品，以及有一些个性化的需求，最终选择了自建的道路。我门对其的目标为，多云管理平台要纳管主流的云产品，对 SYS、SRE、RD 提供友好的操作界面。</p><p></p><p>在 IaaS 层，作业帮对计算、存储、网络都进行了封装。计算层面，如果无限度的开放云厂商的所有机型，SKU 过多，会给运维工作带来巨大负担。我们提炼总结了业务使用场景，定义了主力机型。这些机型再叠加上网络安全域、操作系统包装成一个个具化套餐，简化了使用流程，强化了资源管控。存储、网络等实体也进行了类似的平台建设。</p><p></p><p>容器在资源和应用中起承上启下的作用，北向接口的统一极大的便利了我们的工作。但不同云依然会有一定差异，如绑定的不同资源、不同的注解功能等。这块我们提炼共性做成统一模版，具体到单云配置实例化时再填充个性化变量。</p><p></p><p>CD 平台是业务研发使用最为频繁的系统，每一个云就对应一个 IDC，整体发布是分级的，较之前没有使用上的变化。感知体系中，日志、链路追踪、监控实现了数据的汇总，展现给研发的是统一的视角。除了统一面之外，监控还需要有分云分集群的展现，以便快速发现单云单集群级别的故障。</p><p></p><p>InfoQ：Kubernetes 和容器技术给多云带来了哪些改变？</p><p></p><p>董晓聪：以 Kubernetes 和 Docker 为代表的容器技术极大解决了服务部署和调度的问题。容器技术对应用层屏蔽了底层资源的差异，也包括云厂商的差异。使得我们在基础部署这个层面上更换机型、更换云厂商变得容易。以作业帮为例，更换一款主力机型可以在两周内完成。变更云厂商在解决冷启动后，两千多个服务可在一小时左右完成部署，且运行正常。</p><p></p><p>在更高一层的调度能力上，容器技术作为统一平台，进而展开调度器优化、在离线混部、HPA、Serverless 的应用。这里面的一部分技术我们是选择自研的，一部分选择应用云厂商的能力。基于容器技术的平台，可以较快在云之间迁移。</p><p></p><p>InfoQ：在成本管理上，您们有什么方法或经验？</p><p></p><p>董晓聪：作业帮通过 FinOps 理论和自身实践的结合，形成了一套完备的 FinOps，来指导技术成本的管理。</p><p></p><p>整个体系包括成本的核算、分析、预测、决策、计划和考核。包含的主体不仅包括云平台运维部门、业务研发部门、云厂商，还包括财务、业务线。云平台运维部门实际上担任了二级云服务提供商的角色，是公司进行云成本管控的一号位。需要和运厂商核对云服务的现金流账单，以及给业务研发部门出具云服务的用量账单。最后根据分摊比例，把最终的费用分摊到业务线上。</p><p></p><p>在多云架构下，云平台运维要建立 CMDB，记录所有云资产。再按照云厂商的计费模式，如包年包月、按使用计费等，再叠加上一定的商务策略，计算出最终的现金流账单，每月和云厂商账单核对。比对出现科目异常时再来比对明细。而对上层出具的用量账单要抹平不同云之间商务策略的不同，归一化到统一的成本视角。基础架构和业务研发部门基于用量成本的科目纬度和业务部门纬度进行成本优化，主要的手段有冗余资源的控制、服务性能优化、资源调度的优化、弹性资源的使用等。</p><p></p><p>通过这一套成本管控机制的建设，建立了清晰的台帐，让业务线的预算制定更科学，成本管控更有抓手，最终实现了整体优化 40% 的收益。</p><p></p><p></p><h2>多云实践中的挑战</h2><p></p><p></p><p>InfoQ：作业帮在构建多云实践的过程中，还克服了哪些挑战？是否存在在不同的云之间进行迁移的情况？</p><p></p><p>董晓聪：在明确技术方案后，作业帮多云就开始按照目标进行建设，过程中遇到了一些执行上的困难，以及突发的挑战。具体举几个典型的 case 吧。</p><p></p><p>一、如何将众多业务线从单云架构平稳过渡到多云多活架构？</p><p></p><p>对于数十万计算核心这个体量的公司，多云多活架构相对理想的方案是多云同构部署，即所有的应用在多个云厂商上都完整部署，常态下没有跨云的东西向流量，流量通过南北向进行调度。那么从单云架构该如何一步步过度过来呢，尤其是公司还有多种不同类型的业务，流量型、直播课课堂、电商、内部增效平台等等，不同业务线很难保持同一节奏。</p><p></p><p>我们是通过服务治理中跨云的灵活特性来解决此问题的，对于新建设的云，会将缺失服务默认路由到完备的云机房。这样就需要在业务迁移过程中反复变更注册发现了。除了同步流量外，异步 MQ 这块我们也是使用了类似的方案，通过开发 MQ-proxy，代理控制面，来屏蔽迁云过程中的复杂性。</p><p></p><p>二、上层应用完成多云多活架构后，如何防止裂化？</p><p></p><p>当绝大多数存量业务完成改造后，我们又面临一个问题，业务在不断发展迭代，会有新的服务出现，如新业务的应用服务、老业务技术重构的应用服务，如何让他们都遵守常态下东西向流量不跨云的规范。我们是这么来的做的：一方面，从 CD 上进行限制，新模块至少要在两个主力云机房部署。另一方面，从流量上进行限制。一开始我们想的是用纯粹的网络隔离来做，即禁止除中间件的跨云通信。但这样太刚性，不灵活。对于一些临时局部故障要进行东西向切流无法支持。所以探索了一套兼顾灵活和严格的方案。每个云划分为两种网络区域，互通区和受限区。互通区可以和所有区域通信，不同云的受限区不能通信。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/94/94aa356b16bcdbcdd3c1421abbd7166b.png\" /></p><p></p><p>这样将所有应用服务放置到受限区，即可以避免他们常态的跨云请求。互通区中放置跨云的网关代理、数据存储的 proxy。如果业务临时需要跨云请求，在跨云网关上进行规则配置，这样就在管控的前提下实现了灵活性。</p><p></p><p>三、如何精准调度多云的南北向流量？</p><p></p><p>传统 DNS 可以根据地域和运营商分配流量，但这两个维度无法做到调度的精准。这样就会导致容量和流量的不匹配，在多数业务中这个差异是可以忽略的。但在作业帮流量型产品和直播课课堂场景下，地域的差异较大，这就对我们南北向流量调度的精准性提出了较高的要求。</p><p></p><p>在之前，作业帮为了应对 local DNS 的缓存、劫持等问题，上线了 DoH 的能力，但之前只使用在通道场景，不对 DNS 解析结果进行变更。在新的要求下，我们增强了 DoH 能力，加入了自定义分配策略。如精准的百分比随机，经过我们的测算，误差可控制在 0.1% 以内，实现了容量和流量高度匹配。</p><p></p><p>InfoQ：现在的多云对开发者是否有提出新的技能要求？</p><p></p><p>董晓聪：多云对不同群体的开发者有新的要求。</p><p></p><p>对于业务研发更多是理念上的转变。云原生是要将非功能逻辑抽离到基础设施中，基于云原生的多云架构是要在底层屏蔽多云的差异，不让其蔓延到上层应用。在这个背景下应用服务的逻辑应该和云、IDC 无关，应用镜像、服务发现配置等在多云间也应该是同构的。只要达成这样的效果，在进行云迁移时，业务只需要关心服务运行状态，不需要修改逻辑。才可以真正做了底层基础设施对上层应用透明。</p><p></p><p>对于基础架构研发会有更高的技能要求，如何在容器、中间件、管控平台等设计实现过程中，践行对应用透明的理念。</p><p></p><p>除了上述的之外，开发者积极接触学习多云的开源技术也是好的，因为在成熟公司中有明确的职责划分，而在创业期的企业经常一个人身兼数职，这种情况下多云产品能大幅度提升工作效率。</p><p></p><p>今日好文推荐</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651152762&amp;idx=1&amp;sn=4ff7c53517d71a296cc5e8a2afcd9f87&amp;chksm=bdb899298acf103f27a9332a6661a422bc6885908a298b31a1f58721931881b3bbff9083283a&amp;scene=21#wechat_redirect\">市场增速超20%，国产操作系统“浴火重生” | 解读操作系统的 2022</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651152484&amp;idx=1&amp;sn=f3037dbb432c57da2b7873b7c1748955&amp;chksm=bdb898378acf1121a34664ba2343e93beb713d8b93d1460dbca4ac2205b4873600f9d1c4e05e&amp;scene=21#wechat_redirect\">直面成本“刺客”、拒绝繁杂技术花样，压力之下云厂商改变方向｜解读云原生的 2022</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651152236&amp;idx=1&amp;sn=429d414427f825ec6a6f8769b1b7587d&amp;chksm=bdb8a73f8acf2e29a8cab95527d723dbc687ae21151b491fcd7dd9043367d09ed54b36f674c4&amp;scene=21#wechat_redirect\">马化腾内部开炮：有些业务都活不下去了，周末还打球；阿里云香港服务器“史诗级”宕机；马斯克萌生退意 ｜ Q资讯</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651152234&amp;idx=1&amp;sn=f13ffd47c570280029ba8f76ddc953f3&amp;chksm=bdb8a7398acf2e2f5681186efd315961dd640c2289b8fc14f2362b3afb529297c4a6a6e30955&amp;scene=21#wechat_redirect\">奇点已来，推进All on Serverless有哪些困难、如何破局？｜ 解读Serverless的2022</a>\"</p><p></p><p></p><p></p>",
    "publish_time": "2022-12-30 17:56:20",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "取代搜索，“干掉”艺术家？顶流「AIGC」的疯狂与争议 | 解读AIGC的2022",
    "url": "https://www.infoq.cn/article/rggHjzaBfCVPV5hxTF7H",
    "summary": "<p></p><p>本文是&nbsp;<a href=\"https://www.infoq.cn/theme/168\">“2022&nbsp;InfoQ&nbsp;年度技术盘点与展望”&nbsp;</a>\"系列文章之一，由&nbsp;InfoQ&nbsp;编辑部制作呈现，重点聚焦AIGC领域在&nbsp;2022&nbsp;年的重要进展、动态，希望能帮助你准确把握&nbsp;2022&nbsp;年AIGC领域的核心发展脉络，在行业内始终保持足够的技术敏锐度。</p><p></p><p>“InfoQ&nbsp;年度技术盘点与展望”是&nbsp;InfoQ&nbsp;全年最重要的内容选题之一，将涵盖操作系统、数据库、AI、大数据、云原生、架构、大前端、编程语言、开源安全、数字化十大方向，后续将聚合延展成专题、迷你书、直播周、合集页面，在&nbsp;InfoQ&nbsp;媒体矩阵陆续放出，欢迎大家持续关注。</p><p></p><p>特此感谢百度ERNIE-ViLG团队、<a href=\"https://www.infoq.cn/article/6UmmSt3XGmIRuxJlkT4q\">黄民烈</a>\"、李笛、林咏华、赵德丽对本文的贡献，他们的真知灼见，是本文能与大家见面的关键。</p><p></p><p></p><blockquote>2022，浪潮凶猛的AIGC元年 。</blockquote><p></p><p></p><h2>风口上的AIGC</h2><p></p><p></p><p>今年的AI领域，可能没什么比AIGC更热了。</p><p></p><p>AIGC的全称是Artificial Intelligence Generated Content，人工智能生成内容。不过，AIGC目前还没有一个规范、统一的定义。</p><p></p><p>根据中国信通院与京东探索研究院发布的《人工智能生成内容（AIGC）白皮书》中给出的定义，AIGC既是从内容生产者视角进行分类的一类内容，又是一种内容生产方式，还是用于内容自动化生成的一类技术集合。</p><p></p><p>有预测数据显示，到2030年，AIGC的市场规模或将超过万亿人民币。</p><p></p><p>2022年，尤其是下半年，AIGC概念突然升温。有这么几个标志性的事件把AIGC推到了风口浪尖之上，其一是文生图模型Stable Diffusion的开源，其二是ChatGPT的爆火出圈。</p><p></p><h3>AI绘画神器Stable Diffusion横空出世</h3><p></p><p></p><p>有人将Stable Diffusion形容为AI界的“神笔马良”，这可能并不夸张。</p><p></p><p>Stable Diffusion 是一个文本至图像的模型，于今年8月22日公开发布，它能让数十亿人在几秒钟内创建出令人赞叹的艺术品。用户随意输入自己想要的文字描述，就能得到相应的图像结果。</p><p></p><p>两个月后，伴随着Stable Diffusion的开源，它所具备的潜力瞬间得到了极大释放。开源让 Stable Diffusion 将无过滤图像生成的门槛下放到历史最低，任何具备一点点技术知识的电脑用户都能轻松上手，可以说是一项老少咸宜的 AI 图像生成工具。</p><p></p><p>尽管此前，艺术创作AI已经历了一段时间的发展，但Stable Diffusion 的出现才真正让这项技术得到了腾飞式的发展。因为它可以免费使用、上手快捷，大大减少了用户生成内容的障碍。</p><p></p><p>Stable Diffusion 掀起了文生图模型的热潮。今年10月，百度发布了首个知识增强的 AI 作画大模型ERNIE-ViLG 2.0；11月初，阿里达摩院在魔搭社区ModelScope上开放了通义文生图大模型；11月底，智源研究院大模型研究团队开源最新双语 AltDiffusion 模型，中文世界有了专业级 AI 文图创作工具，其在视效上媲美 Stable Diffusion。</p><p></p><h3>ChatGPT 火爆出圈</h3><p></p><p></p><p>最近几周，OpenAI 最新的聊天机器人<a href=\"https://www.infoq.cn/article/AWWsrfb54zTvglZ0I5qS\">ChatGPT</a>\"火出天际，成为现象级应用。</p><p></p><p>问答、写小说、写代码、写论文、写区块链智能合约....ChatGPT的应用也频频出圈。ChatGPT 就像是一个无所不知的虚拟体，它能回答各种问题，而且总能给到让人满意，甚至超过预期的答案，因此引起了极高的关注度。</p><p></p><p>ChatGPT展示出的强大的能力和无限可能，让人们看到，通过ChatGPT这样的技术方案解决很多任务的潜力。大家感到惊奇的是，在一个模型里面就可以完成各种任务，而且是很难的任务。在过去一些看似比较困难的任务（比如问伦理道德方面），ChatGPT也能解决得很好。</p><p></p><p>清华大学教授黄民烈认为，ChatGPT的技术创新性主要在于两个方面：</p><p></p><p>强大的底座模型：过去几年 GPT-3 的能力得到了快速提升，OpenAI 建立了用户、数据和模型之间的飞轮。显然，开源模型的能力已远远落后平台公司所提供的 API 能力，因为开源模型没有持续的用户数据对模型进行改进。利用强化学习从人类反馈中学习：&nbsp;在真实调用数据上的精调模型，确保数据的质量和多样性，从人类反馈中学习。从“两两比较的数据”中学习，对强化学习而言意义很大。如果对单个生成结果进行打分，标注者主观性带来的偏差很大，无法给出精确的奖励值。在强化学习里，奖励值差一点，最后训练的策略就差很远。而对于多个结果进行排序和比较，相对就容易做很多。这种比较式的评估方法，在很多语言生成任务的评价上也被广泛采用。</p><p></p><p>黄民烈认为，ChatGPT 出现对AI界来说，有着十分重要的意义：“它宣示着无缝人机交互时代的来临。过去我们讲 conversation as a service （caas）还停留在纸面，但实际上今天，无论是开放域聊天，还是通用任务助理（ChatGPT）都在强烈地表明这一点”。</p><p></p><p>从信息检索的角度看，ChatGPT也取得了很大突破。达摩院基础视觉负责人赵德丽在接受InfoQ采访时表示，以前谷歌等搜索引擎做搜索和检索，只是找已经存在的信息，ChatGPT的应用，实现了从信息的搜索到信息的创造这样一个范式的转变，从算法能力上看，它取得了一个质的飞跃。短期来看，ChatGPT 有望成为或者辅助像谷歌这种传统信息检索的强有力的工具；长期来看，它有望发展成为AI系统级的服务。</p><p></p><p>但至于它最终会不会取代搜索引擎。黄民烈认为，ChatGPT 取代谷歌搜索还比较遥远，原因主要有，受限于训练数据，ChatGPT的信息实效性较弱，缺乏很多新的信息；在信息的可信度上，搜索引擎只“搬”东西，不创造内容。ChatGPT虽然会创造内容，但创造的东西多大程度上“有用、可信、无害”，还没有统一的定论；再就是成本问题，现在大模型的生成成本还是太高了，需要持续下降。</p><p></p><p>现阶段的ChatGPT并不完美。通俗地说，它还存在“一本正经地胡说八道”的问题，这本质上是对信息可信性的度量和评估。解决这一问题，技术上需要有信息验证的手段；从应用上来说，需要深入结合应用的场景和特点，针对性优化和解决。</p><p></p><p>但整体而言，ChatGPT还是让人非常惊喜。黄民烈非常看好ChatGPT接下来的发展方向。他认为这是一个正确的方向，现在还比较粗糙，但假以时日，一定会催生很多应用。</p><p></p><p>赵德丽同样对ChatGPT抱有大期待。虽然还有各种瑕疵，但ChatGPT短时间内出现了各式各样的不同方向上解决问题的能力，展现了AI算法的巨大潜力。从技术发展和解决方案的角度看，它将来可能会成长为一个超级APP，就像是一个无所不知的虚拟体。“ChatGPT 这种应用的出现，从长远来看的影响力，其实不亚于阿尔法狗曾经在人工智能界带来的影响力，它将会是一个影响非常深远的技术和应用”。</p><p></p><h2>AIGC为什么突然火了？</h2><p></p><p></p><p></p><p>AIGC并不是一个新概念。AIGC，通常还有另一种叫法 — AI Creation（人工智能创造），大致从2016年—2017年开始，其应用不断增加，尤其是在自然语言领域，广泛应用在生成文本、作诗句、写对联等方向，近几年，逐渐延伸到作画、作曲等领域。</p><p></p><h3>凭何而火？</h3><p></p><p></p><p>今年，AIGC突然在全球蹿红，成为人人口中的流行词。究其原因，主要由多项技术上的关键突破推动，总结来说：</p><p></p><p>一，算法上：从今年4月开始，在文生图视觉方向上，视觉效果生成的效果取得了突破性的进展，文生图的质量得到了很大改善。OpenAI的文本生成图像模型 DALL·E 2算法发布后，在算法效果上取得了和以往相比实质性的突破，成为一个现象级的算法，其在文本生成图像生成的效果、真实度表现上，让大家看到了大规模商用的前景。AI作画任务十分直观，给人的视觉冲击强烈，使得AIGC逐渐破圈，快速传播。</p><p></p><p>二，预训练大模型是AIGC的底座，没有大模型学到的丰富知识，就无法实现如此丰富的AI内容生成能力。AIGC最重要的是一种融会贯通的能力，要做领域的泛化，需要学习海量的数据，大模型的规模直接决定了AIGC创作力的广度。多模态大模型的应用，使得AIGC的质量得到了较为明显的进步。</p><p></p><p>三，扩散模型的发展。扩散生成的算法取得了突破，这个算法能够对图像做像素级别的建模，学习效率更高。<a href=\"https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247575915&amp;idx=3&amp;sn=bcc050ccf22f89e6973a68ab735c3274&amp;chksm=fbeb10a4cc9c99b253e83865d8b21fc5a2adff90b704683e50ec72090df45f16d23096e25063&amp;scene=27#wechat_redirect\">Stable Diffusion</a>\"是文本生成图像模型完全开源的第一个算法，它跑起来的效率相当高，其开源也带动了相关生态快速的发展，让人们看到，基于这种生成式基础模型，能够带来无限的创造和想象空间。特别是在一些国外社区里，基于Stable Diffusion做的各种创新式的应用发展快速，展现了商业化潜力。</p><p></p><p>四，算力降低。深度学习计算能力的快速发展。在大算力的基础上，AI作画能够实现在海量数据上进行大参数模型的训练。相比之前的AIGC算法，算力上有了很大降低。 要训练一个基础的预训练模型，需要很多算力。一些专注于基础的大模型的机构，将模型训练好后，可以供很多小企业使用，只需用消费级的网卡就可以做微调，也可以直接基于API调用。预训练大模型加上微调可以很好地进行文生图生成风格的改变，派生出了大量的二次开发者，屡屡破圈。</p><p></p><h3>从GAN 到 Diffusion</h3><p></p><p></p><p>GAN，是生成式 AI 的核心技术之一。2014年以来，以生成式对抗网络(Generative Adversarial Network,GAN)为代表的深度学习算法的提出和迭代更新，让AIGC进入了快速发展阶段，带动了AIGC的一波热潮。</p><p></p><p>赵德丽表示，在&nbsp;Stable Diffusion这种扩散算法出现之前，从生成的效果上看，在计算机领域，GAN是效果最好的。发展到现阶段，GAN 生成的人脸图像已经到了真假难辨的程度。以StyleGAN为例，其生成的图片可以做到栩栩如生，光线和纹理都清晰可见，非专业人士几乎无法分辨出是由AI生成的虚假图。即便是现在的Diffusion model目前也做不到现在GAN在人脸生成上的结果。</p><p></p><p>但GAN有一个最大的缺点，它对于多类别、语义非常复杂的、一般场景下的图片生成的建模能力较弱。如果只是人脸，只是猫或者只是狗这类场景的数据，GAN的效果很好。但它在某种复杂数据的规模能力方面，在性能上受限较大，如果把狗、猫、花朵、桌子、椅子、电话等不同种类的数据放在一起，目前的情况下，GAN得不到一个较好的结果。</p><p></p><p>而Diffusion&nbsp;model在这方面取得了突破性的进展。Diffusion&nbsp;model解决了GAN不能解决的问题，因此大家立刻意识到了它的巨大潜力。今年是Diffusion&nbsp;model取得快速发展的第一年。而且，它的发展速度超过当年的GAN，当年的GAN已经足够火热了，但可以感受到， Diffusion&nbsp;model现在的受关注程度超过当年的GAN 。</p><p></p><h3>Diffusion扩散化模型带动新一波AIGC的热潮</h3><p></p><p></p><p>今年这波AIGC的热潮，被认为是由生成扩散模型带动起来的。例如，OpenAI 发布了文本生成图像模型 DALL·E 2；谷歌推出了Imagen；今年 8 月，初创公司 Stability.AI 发布了&nbsp;Stable Diffusion...</p><p></p><p>百度ERNIE-ViLG团队向InfoQ介绍，扩散模型是受非平衡热力学的启发的一系列概率生成模型，通过逐渐增加噪声的方式对原始数据进行扰动，通过学习反向的恢复原始数据去噪过程得到用于生成数据的模型，典型的扩散模型如DDPM等。而扩散模型在生成过程中加入文本条件产生了诸如DALLE2、Imagen、ERNIE-ViLG 2.0等基于扩散的文本生成图像模型。传统生成对抗网络GAN存在训练不稳定和生成结果多样性差等缺点，而扩散模型显著提升了图像生成的效果和多样性，受到业界广泛关注。</p><p></p><p>生成扩散模型在多模态生成领域展现出很好的可扩展性。在训练数据时，把不同模态的训练数据混到一起，把文本、静态图片、视频、声音等各种各样不同类型的训练数据在一个语义空间里关联在一起。但因为训练数据规模大，大模型的参数特别多，用这种方式，它仍然只能得到一张分辨率很低的图片。然后不停地通过扩散模型算法，把很小的分辨率和图片不停地做超分辨率，不停地把一张很模糊的图片变得尺寸更大、更清晰，在这个过程里还会补上很多细节，最后得到一张相对较清晰的图。</p><p></p><p>现在很多人应用Diffusion model来生成视频，生成音乐，目前为止它最为可行的还是生成静态的视觉画面。</p><p></p><h3>AIGC相关技术逐步发展成熟</h3><p></p><p></p><p>AIGC包括多种内容形式，按照黄民烈的分类方法，分为感知智能和认知智能。</p><p></p><p>感知类：文生图、语音生成、音乐生成等认知类：续写、改错、小说故事创作、对话生成等从技术上看，写作相关和图像生成这两个方向表现比较成熟，对话最难。</p><p></p><p>其中在文本生成方面，例如在金融文本摘要生成领域，其技术早已成熟到可以落地的程度。ChatGPT在内容的创作能力、问答流畅度上表现不错，但要深究其真实性、正确性和时效性，还存在不少问题。如何保证内容的真实性、正确性和时效性，是现在AIGC尤其是文字类的生成需要重点考虑的问题。</p><p></p><p>图像生成方面，AI绘画格外火热。百度ERNIE-ViLG团队认为，今年以来，AI作画发展迅速，很大程度来自于技术的突破，使得效果有了质的飞跃，甚至有些AI图像作品十分惊艳。</p><p></p><p>不过，虽然AI绘画已经进入实用阶段，但依然有很大的优化空间。在技术角度，需要提高的主要是两个方面，包括生成的可控性和细节描述能力。</p><p></p><p>AI绘画的可控性有待提升，对于数量、逻辑、关系、多图关联等问题暂无有效的解决方案。比如说要求生成2个苹果，左边是红色，右边是绿色。虽然这里边的关系并不复杂，但模型很多时候，并不能稳定地生成正确的结果。细节描述能力有待提升，对于更加复杂的、有规律性的细节的描述能力有待提升。比如对于一栋居民楼的图片，窗户应该是有多种不同描绘，有开的、有关的、有晾衣服的，同时很多窗户应该对齐且规格统一。</p><p></p><p>小冰公司CEO李笛认为，整体来看，AI作画在生成质量上有了大幅提高，但仍然需要解决一些单点的问题，例如模型本身的迭代，一个人类设计师在和雇主的工作过程中，可以根据雇主的喜好，对设计初稿的某一局部做精细调整。但AI无法做到这一点，AI画作一旦生成，如果想让它修改，往往是用重画的方式来进行。而现有的技术 — 多模态大模型，注定有这类问题。它只能在一定程度上，提高作品与需求的相关性，但无法从根本上提高良品率。</p><p></p><p>AI生成视频，是AI生成图像的一种延伸。从技术本质上看，视频可以认为是多张“图片”，即视频帧构成的序列，且序列上各帧之间有画面、逻辑等层面的关联。因此，从生成质量上来说，AI生成视频相对更难。</p><p></p><p>当前文生图技术可以通过简单的技术组合，例如分步骤扩散生成等方式，将生成图像扩展到生成视频，但效果还不能令人满意。此外，受限于数据规模和质量，AI生成视频的生成效果和现在的文本生成图像的效果相比，有较大差距。</p><p></p><p>不过，相对图像，视频内容具有其独特属性。例如，在互联网视频内容消费场景中，经常会以“随便截一张图都是壁纸”作为对视频质量的极高赞誉。由此可见，相对于图片，视频对单个帧的质量要求相对较低，更强调传递信息等功能。因此，AI生成视频可以采用其他技术方案完成，在降低技术难度的同时，更符合特定应用场景的要求，例如基于图文输入生成视频、基于数据生成视频等。</p><p></p><p>总结来说，AI按照生成图像的方式生成视频，仍处于前沿探索阶段。</p><p></p><h2>商业想象力几何？</h2><p></p><p></p><p>赵德丽认为，现阶段，AIGC的生成效果已经非常惊艳了，它已经达到了广泛应用的基础性能，虽然在使用上还有较大门槛，但通过大模型的开源开放等，有助于将门槛降下来。</p><p></p><h3>商业模式在探索中</h3><p></p><p></p><p>而且可喜的是，现在，AIGC已经有不少可行的商业模式发生了。</p><p></p><p>例如在设计、艺术创作、电商、娱乐、金融等领域。具体在文本生成上，在一些商业非严肃性文书的辅助编写上已产生了不错的模式；在文生图方向，已经看到，面向设计师，面向教育行业的AI辅助画作生成等正在探索商业用途的路上。</p><p></p><p>最近几年，“数字人+AIGC”成为不少企业的探索方向。小冰从几年前就开始探索 AIGC。李笛表示，AIGC对于AI Being来说的作用在于，在和人交互的过程中，它不光要能从数字世界中获取知识内容和服务提供给人，它自己也应该相应地随机应变地去创造相应的内容提供给人。</p><p></p><p>在互联网应用之外，AIGC在实体经济领域，也蕴含着不少机会。</p><p></p><p>实体经济对内容生产的需求很大。“我们以前认为实体经济的瓶颈在于生产、产能，其实不是，实体经济的很多瓶颈在于设计，在于内容。” 李笛说。以小冰为例，小冰的AIGC内容很早就应用在纺织设计领域。小冰与中国纺织信息中心、国家纺织产品开发中心推出的AI图案设计平台，可按需定制100%原创的图案纹样，目前已有超过400家企业注册，并在生产中使用。</p><p></p><p>北京智源人工智能研究院总工程师林咏华向InfoQ谈到，工业生产、制造、仓储、物流等实体行业，近几年一直在探索如何用计算机视觉来进行智能化升级，但实际落地并不容易。原因在于，现有的模型质量还未能满足产业落地的质量要求。其中一个重要原因是，训练模型时所用的训练数据十分局限。因此，可以考虑通过AIGC的方式来产生这些场景里的训练数据。例如在仓储、物流或更多的工业场景，用AI来辅助产生一些少见的场景数据，作为训练数据的补充，提升整个模型的质量。但这需要更精准的图片生成的控制能力，比较起现有的AIGC模型能力，其可控性需要大大提升。</p><p></p><p>AIGC在自动驾驶场景下也有着不错的应用潜力。现在自动驾驶场景存在训练数据不足的问题，例如针对恶劣天气、事故等突发状况，视觉模型在真实场景中很难捕捉，也难以进行模拟，因此，目前业内在尝试用数字孪生和仿真的方式来模拟。也可以尝试用大模型的方式，通过给出描述，生成相应的精确场景，缓解某些场景下自动驾驶数据难获得的问题。</p><p></p><p>“整体来看，AIGC现在已经开始在探索向实体经济的应用发展，但目前还在一个比较早期的阶段” 林咏华判断。</p><p></p><h3>向B端收费还是C端？</h3><p></p><p></p><p>然而，AIGC的商业化落地，不得不面临的一个尴尬的问题是 —— 如何避免走向 “廉价”。</p><p></p><p>AI具有高并发性，注定了它的“廉价”。李笛认为，如果只对AI画作收费，它很可能会进入到廉价的成本经销模式。因为，人是有创造力的，从人类设计师那得到的画作，人可能愿意付一百块，从 AI 那得到的画作，且不论质量，人可能连一块都不愿意付，因为觉得它是廉价的。AI画的画可能很有价值，但人们认为它不值钱。因此如果卖的是内容，无论是卖给B端还是卖给C端它都不值钱。而如果卖调用服务给C端，也很难持续。API调用的模式是一种比较粗放的从技术源头开始的商业化包装方式。</p><p></p><p>内容产业有一个重要特点是，它是高附加值且有区分度的，不同内容的创作者定价不同，不完全取决于本身的作品质量。但用 AI 创作不同的绘画，定价是相同的，这样容易把一个高附加值的市场“打”成一个低附加值的市场。</p><p></p><p>对于AIGC可行的赚钱路径，李笛认为，如果to C ，是走内容平台模式，打造一个内容平台，通过广告收费。如果to B，是用AI Being和企业之间进行协同。一个AI Being创作者，能一定程度对标人类创作者，他有“唯一性”。通过与雇主的长期磨合，双方的审美、风格会越来越趋同。对雇主来说，他的作品质量会越来越稳定。“某种意义上讲，我们认为靠AIGC本身赚不到钱。我们不是在做‘画笔’，而是在做一个‘手拿画笔的人’，我们不是在做能画画的 AI，而是在做能画画的 AI Being。我们侧重把创作的能力，把生成的能力赋予 AI Being，让 AI Being 本身具有价值”。</p><p></p><h3>爆发前夜</h3><p></p><p></p><p>“AIGC技术走到了一个转折点，到了一个新阶段的起点”。赵德丽认为，此前，虽然AIGC技术在不断发展，但生成效果并没有得到广泛认可，还没达到大规模商业化的条件。但现在，不一样了。</p><p></p><p>今年，AIGC生成的效果，包括基于AIGC技术推出来的应用，大家看到，这项目技术已经具备了大规模应用和商业化的潜力和性能，具备了从只能在窄领域到更普遍场景下应用的可能性。AIGC技术到了大规模商业化应用的转折点。今年是一个起点，但还远远没有到成熟的程度。</p><p></p><p>AIGC具体在哪些领域能用好，发挥出商业化的价值，还需要不断打磨产品和技术。例如对于文本生成图，现在对problem的提示语要求很高，现在算法还做不到随便给个描述，就能生成栩栩如生的图片。什么样的problem合适，如何设计出合适的problem等，都有一定门槛。</p><p></p><p>此外，像ChatGPT虽然展示了强大的能力，但在很多场景下还是有瑕疵，出现问题和答案不匹配的情况还非常多。如果对其进行商业化应用，需要再针对具体的场景，不断打磨和优化。尽管它达到了大规模应用的基础，但并不是非常成熟，还达不到让大家自由应用的程度。</p><p></p><p>现阶段，AIGC已经有了一些称得上规模的应用，但在实际应用中，还存在一些问题。例如因为人设计的作品相对较贵，但人工智能的设计作品相对便宜，所以会有人利用这个漏洞，将人工智能系统里的大量作品改头换面，将它搬迁到或囤积到那些原本是人类设计者的定价体系的平台上去倾销，最终会造成人类创作作品的销量市场受到损害。AIGC应该避免形成这样的规模化。</p><p></p><h2>热度、争议与未来</h2><p></p><p></p><h3>如何提高良品率</h3><p></p><p></p><p>当前，AI写作、AI作画等AIGC内容在质量上还存在良莠不齐的问题，提高良品率尤为重要。</p><p></p><p>不过在大模型的生产模式下，提高良品率的方法并不多，某种意义上来讲，良品率目前主要依靠翻动过程，它能够在一定程度上降低瑕疵，但想要消除，不太可能，它不太可能是基于对大模型的修改而得到。接下来期待一个新的称之为台阶式的技术理念出来。</p><p></p><p>提高数据的质量是基础方法之一。林咏华表示，AIGC是针对训练数据的融会贯通和变换，所以数据的广泛性，数据的分布和数据的质量都很重要。在AI领域的研究人员越来越意识到，尤其在需要大量数据训练模型的大模型领域，数据起到的作用可能会比算法还大。如果希望生成的画作精良，那需要训练的图片的质量是精美的，但如果给的是小孩的画，那生成的画作可能还粗略停留在小孩阶段。</p><p></p><p>此外就是从算法侧改进算法，但改进算法本身如果针对通用场景，它可能在某些场景总是出现瑕疵或者出现瑕疵的概率比较高。很多团队在开发AIGC应用时，目标不是通用场景，比如针对的是生成二次元图像的产品，那需要对算法或模型进行二次开发。在这种情况下，完全有可能在二次开发的基础上把瑕疵去掉，提高良品率。一般通过二次开发，且在一些具体场景下的数据做模型二次微调，可以大大提高AIGC的良品率。</p><p></p><h3>“人工智能宣布放弃版权”</h3><p></p><p></p><p>AI作画的一个很大的争议点在于版权。例如，DALL-E和Stable Diffusion等图形生成类AI工具就被质疑在互联网上随意抓取数据，且完全没有考虑过任何许可或所有权限制。正是由于这种版权归属争议的存在，Shutterstock和Getty Images等公司禁止在其平台上使用AI生成图像。</p><p></p><p>谈到版权问题，李笛表示，小冰很早就提出，“人工智能宣布放弃版权”。</p><p></p><p>通常来说，版权界定需要几步：第一判定是不是侵权。人类作品判定侵权有明确的界定要求，比如一个作品多少比重的内容一致，就可以判定侵权。人工智能作为系统，它天生就有判定机制，当它输出作品的过程中，它自动就可以像知网一样进行查重。它生成的原始图像里，很可能存在着很多图像跟现有的作品，存在相似性，如果相似性较高，侵权了，只要不把作品输出就行。如果让人工智能确保它给到用户的每一个作品都是不侵权的，这件事很容易做。</p><p></p><p>第二步要有判定训练的过程，是基于什么样的训练数据训练的。但要注意的是，无论是人类作品还是AI生成作品，侵权的责任认定在于，这张作品是不是跟另一个作品产生了相似性，而并非在学习作画的过程中学习了别人的作品及作品思想等。如果这样，无论是人还是AI只要在画画，便会判定为侵权。从这个角度看，人工智能本身在训练过程不存在版权责任，尤其是大模型，因为人工智能在训练的时候，它使用的是公开的数据来进行训练。</p><p></p><p>另一个放弃版权的原因在于，人工智能保留知识产权没有意义。人工智能保留知识产权的一个先决条件是必须要经过确权的步骤。目前全球对于知识产权的确权方法主要是通过著作权登记，每登记一个作品，需要一笔著作权登记费用。而AI生成的内容规模十分庞大，这一规则对AIGC来说显然不现实。</p><p></p><h3>无法辨别真伪信息的世界</h3><p></p><p></p><p>很多人担忧，随着AIGC的不断普及，未来大家将生活在一个无法辨别真伪信息的世界里。</p><p></p><p>AIGC生成的内容越来越多，信息的真假会成为很大的负担。但这恐怕已经是无法避免的趋势，因为现在AI生成的图片早已经是海量规模，而且，这些AI生成的数据将会越来越多的出现在公共的资讯平台上，这样的时代正在快速到来。</p><p></p><p>对于用户来说，未来将面临判定真伪信息的挑战。目前还少有比较好的解决这一问题的方法。赵德丽提出了一种标记的方法。从算法角度来说，可以做一些隐性标记，标记出哪些图片是生成的，哪些是真实的图片。</p><p></p><h3>完全的AIGC可能不会出现</h3><p></p><p></p><p>不可否认的是，AIGC对内容创作的确产生了重大影响。一种观点认为，内容生成的四个阶段依次为“PGC、UGC、AI辅助生成和完全的AIGC”。按照这一走向，未来，AI的终级趋向会是取代人，最后内容产业将走向完全的AIGC。</p><p></p><p>李笛对此持有相反的观点，他认为，AI的终极应该是与人协同，应该先实现“规模化的AIGC”再到达“AI辅助生成”阶段，当AIGC集大成以后，再辅助人类生成内容。</p><p></p><p>此外，完全的AIGC可能不会实现。比如人看某个电影，是因为情节、演员、导演等多种因素。人类对作品的喜好，从来不仅仅是因为内容质量，即便未来完全的AIGC化了，可能也并不是人类想要的东西。李笛发出思考：“所以不存在AIGC颠覆人的可能性，能颠覆人的只有人类自己”。</p><p></p><p>赵德丽表示，AIGC本身是基于生成模型产生的能力，生成模型训练需要数据，这些数据都是人类活动产生，生成的提示词需要人来输入，人需要做场景的设计、提示词的设计、元素的设计等等。只不过在一些具体的场景上，对于一些固定的设计模式，比如设计成具体的图形如红包界面、商品素材等，可以实现完全的AIGC的方式。但整体而言，人还是AIGC中重要的因素。</p><p></p><p>再回到那个AI能不能让艺术家丢掉饭碗的老生常谈的话题 ——“让AI负责生成，让艺术家或设计师来负责审美，这两个并不矛盾，是一个相辅相成的关系。也不存在谁取代谁，有了AI绘画的辅助，艺术家会发挥出更大的能力，甚至说一些不是非常专业的艺术家，一些普通人借助AIGC，也有可能创造出非常惊艳的艺术品” 李笛表示。</p><p></p><p>采访嘉宾：（按拼音首字母排序）</p><p></p><p>百度ERNIE-ViLG团队</p><p></p><p>黄民烈，清华大学计算机科学与技术系长聘副教授、博导，聆心智能创始人。</p><p></p><p>李笛，小冰公司CEO</p><p></p><p>林咏华，北京智源人工智能研究院总工程师</p><p></p><p>赵德丽，阿里达摩院基础视觉负责人</p><p></p>",
    "publish_time": "2022-12-30 18:21:43",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "好分期热线客服系统的架构演进",
    "url": "https://www.infoq.cn/article/L3wtMIEMjtpCGHG5R5ue",
    "summary": "<p></p><p>客服是在用户服务体验不完美的时候，进一步提升用户体验及分析解决用户诉求的一种方式，是问题发生后的一种兜底方案，随着好分期业务的快速发展，强有力的客户服务越来越成为必不可少的一环，以下两点是系统核心设计原则：</p><p>技术层面在流量洪峰下如何保证系统的稳定业务层面中用户的首解率&amp;满意度</p><p>&nbsp;</p><p></p><h2>架构设计</h2><p></p><p></p><h3>业务架构</h3><p></p><p>进阶理解好分期用户一通电话是如何在和客服架构下流转的过程。主要分为三层（线路层、通讯组件、应用层）</p><p>名词概念：</p><p>线路：可以理解为支持并发的电话线路通讯组件：解析分发通话的服务应用层：一般性业务系统如客服系统、贷后系统、电销系统等</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/52/ce/52a2f85b1016039d198e4bc925fbf0ce.png\" /></p><p></p><p></p><h3>技术架构</h3><p></p><p>好分期业务发展过程中随着进线量的增加及业务的复杂度的提升，客服系统暴漏的部分问题如下</p><p>1.&nbsp;接入电话后数据内部流转缓慢、CTI操作无响应、业务数据监控数据不准确</p><p>2.&nbsp;缺失对流量的管控及洪峰的对应能力，如热线爆表而其他渠道波动较小如在线渠道等</p><p></p><p>针对如上问题客服系统从两个层面对系统进行设计分别为应用层(客服系统)、中间层(通讯组件)</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/5c/7d/5c36305ea8788e22e0d70f9d27f1527d.png\" /></p><p></p><p></p><h3>1.&nbsp;应用层客服系统设计</h3><p></p><p>对业务系统输出统一的话务数据，提供统一API接口提供可视化的流程引擎，或者通过API接口集成</p><p>主要目的是提供一个统一的管理平台，提供可视化的入口，主要有流程引擎及对外输出统一API接口。</p><p></p><p>以下通过两个核心设计来实现客服系统的高性能架构。</p><p>客服通讯组件实现外部电话的高效接入电话接入后内部快速流转催生孵化的流程引擎</p><p></p><h4>1.1 流程引擎的诞生</h4><p></p><p>用户的每一次进线到好分期都会一个或者多个诉求，当一线坐席不能够在当前会话中解决用户的诉求，就需要根据用户诉求创建对应的工单流转至微财下的责任部门进行处理，同时记录用户诉求及当前处理方案。微财下的责任部门根据一线坐席转交的工单进行下一步处理，直至解决用户问题结束工单流程。每个工单代表一个诉求，一个用户可以拥有多个工单，同时每个工单需要记录每一步处理人的操作内容及处理结果，可以及时反馈给用户当前处理结果，同时对于内部流转可以留痕溯源。</p><p></p><p>其实热线通话一开始是从工单侧发起，工单作为客服域最为重要的跟进用户问题的凭证，客服每天都在和各种各样的工单打交道，与用户的实时沟通需求显得尤为迫切，这就是热线业务的初诞生，这个时期的热线只是依附于工单的一个功能。</p><p></p><p>这个阶段主要是实现与话务系统打通，做到如何让用户和客服能通上话才是重点，用户拨打电话到客服接收到电话，这个阶段的服务架构如下：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/44/0c/44ab0e168ab99355583b8f5cdaf9330c.png\" /></p><p></p><p>&nbsp;</p><p>面对好分期业务的快速发展，很多为了提升用户首解率，降低投诉率的需求也都蜂拥而至，而在客服场景中很多场景都是有公共属性的例如：审批流程会应用到减免、余额提现、相关额度申请等，工单数据流转会在一线员工、主管、经理各个层级之间往复流转，流转规则穿插在业务中的各个环节中，很多的共通性带来了很多的重复开发，所以我们开始思考流程引擎的开发。好分期客服在处理用户问题痛点如下：</p><p>1.&nbsp;针对呼叫中心模式如何辅助一线坐席快速处理用户反馈问题</p><p>2.&nbsp;创建的工单如何准确的转交责任部门并快速响应处理</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如何应对业务变更中茫茫多的业务流程及研发的效率</p><p>3.&nbsp;提升24小时内用户首次来电有效解决用户问题的效率</p><p></p><p>针对如上三个个核心问题，需要一套贴合呼叫中心模式的可视化流程引擎，可视化的引擎配置，不仅要解决研发人员大多数业务流程的开发工作，同时运营侧亦可根据业务场景进行配置，也为实际流程运行时的运营工作提供了便捷的处理方式，可视化能将流程实际运行情况清晰的展示到界面上，使得运营人员能快速对线上问题进行定位。</p><p>提供可视化的引擎配置，能够留痕溯源以终端来电，计算用户轨迹，获取流程模板预设工单流程，定义节点根据业务策略，设定流转规则可针对处理时效，设置节点阈值并进行预警根据引擎规则，辅助一线坐席自动建单</p><p></p><p>始于终端用户的一通电话，通过计算用户IVR轨迹直接进入流程，完成智能自动建单，形成数据闭环。节省人工资源，减少工单流转率，提升首解率。</p><p></p><h4>1.2 流程引擎设计</h4><p></p><p>使用案例：如用户来电因为某种原因，希望进行减免操作，如下为引擎的建单过程</p><p>1.&nbsp;用户来电过程会通过语音机器人识别的用户意图并合并历史用户轨迹重新定位用户意图进行机器学习，命中减免规则模板</p><p>2.&nbsp;减免流程编排为开始节点-&gt;主干管审批节点-&gt;经理审批节点-&gt;部门负责人审批节点-结束节点</p><p>3.&nbsp;流转规则设置审批金额小于\"X\"元一级审批结束；小于等于\"Y\"元审批至经理审批节点结束；大于\"Z\"元审批至部门负责人审批结束</p><p>4.&nbsp;以主管审批节点为例，设置审批时效为派单起1小时，超时一级预警方式为消息提醒，二级预警方式为短信提醒，三级预警方式为电话提醒，当工单流转至主管审批时开始自动计时，按照超时级别对责任人进行提醒</p><p>5.&nbsp;直至流转至结束节点停止计时和预警，开始节点到结束节点期间全部按照流程配置进行流转和预警</p><p></p><p>如上案例如何通过引擎快速创建工单及流转的全部过程，从用户来电创建工单及工单整体流转过程的处理时效和预警有效的解决当前业务的问题</p><p>接通电话快速建单合理处理时效和有效的预警大大提升处理效率业务调整仅需调整流程配置无需开发时限内处理完成工单，有效提升首解率</p><p>&nbsp;</p><p>流程引擎架构图：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/c4/ae/c4f592b9af5a8a45784afa4f23d896ae.png\" /></p><p></p><p></p><h4>1.3 核心组件</h4><p></p><p>流程（Flow）： &nbsp;设置流程编号使用权限范围及流程基础信息流程任务（Todo）：具体执行流程树的最小的分支，具体到某个人员的代办事项流程节点（Node）：主流程中设置的阶段性节点，预设多种节点类型（建单、审批会签、审批或签、审批依次签、处理、回访、提醒、闭单）等等，无需开发。可按照节点类型自定义节点，节点可扩展性强，如特殊处理节点可自定义实现，配置节点类型即可使用流程处理人（People）：流程流转过程中的内置处理人，可指定多类型处理人（指定具体人、指定多级处理人、在线用户、指定组织机构、抄送人员）等等，指定任务分配方式内置（平均分配、轮询分配）等等。以及接收任务时的提醒方式内置（发起提醒、完成提醒）等方式，同时可通过动态参数方式指定任意处理人流转条件（Control）：流程编排中节点间的流转条件，可使用内置参数，也可以动态参数指定流程节点处理时限（SLA）：流程编排中每个节点的要求完成时长，流转至当前节点创建任务自动计算当前任务要求完成时长，创建任务后为当前处理人自动计时。通过节点预警设置的预警方式进行有效的提醒流程节点预警（Warning）：流程编排中节点设置处理时限超时后的预警方式，可设置多级预警级别适配不同预警方式，内置预警方式（企业微信消息提醒、短信提醒、邮件提醒、电话提醒）等方式。确保处理人在要求完成时间内处理当前工单&nbsp;</p><p></p><h4>1.4 流程引擎效果</h4><p></p><p>贴合呼叫中心模式，终端来电与与流程引擎无缝连接，通过用户IVR轨迹直接进入流程提供可视化页面，简洁美观，扩展性强大，极大的降低代码维护完全自定定义流程，可视化流程引擎配置，支持节点、流转规则自定义，丰富阈值预警支持多租户，数据分离，支持热部署标准简洁的API接口</p><p></p><p>引擎对比：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/ea/03/ea6e5b936b05d5a53cde6b30b5fbe403.png\" /></p><p></p><p>工单指标对比：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/60/86/60883b5c348af4c8b75b57c98aa39d86.png\" /></p><p></p><p></p><h3>2. &nbsp;通讯组件设计</h3><p></p><p>通讯组件以往是一个统一的大服务，处理用户电话到客服系统间数据交换的服务，主要职能包含电话的解析(agent数据、分机数据、技能组数据、间隔报表数据)等，各个渠道数据采集、CTI数据处理、标准化数据入库、数据实时推送等。由于不能根据当前流量控制资源使用情况，会出现数据延迟、CTI操作无响应、监控数据不准确等一系列问题。如下是针对以上问题设计的核心原则</p><p>通讯服务拆分及组件化，由一个服务按照数据流拆分多个组件，组件间进行互备增加Callcenter路由组件可插拔，计算当前流量分配可使用的资源主备话务服务改用路由（主备可同时使用），洪峰到来时可调用备用资源分摊压力流量管控，按照当前资源设置阈值，根据阈值级别分流到不同渠道（分流智能IVR、在线客服、按键IVR）服务降级，自动化三级降级策略，自动恢复、阈值决策、硬话机接听</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/72/32/72ce0c425b5b5dee2474fe482218c032.png\" /></p><p>&nbsp;</p><p>通讯组件拆分及其功能：&nbsp;&nbsp;&nbsp;</p><p>通讯服务按照使用渠道、流量压力及扩展性进行拆分，分别为数据采集、CTI平台、数据接收、数据汇总、数据推送及控制台。</p><p>数据采集组件：为了方便扩展，每一种类型的数据来源做成一个组件服务，获取到数据后通过统一接口推送到服务层负责对数据进行处理。定位于适配各大厂商的CTI为现场监控或者大屏监控系统提供统一的数据接口CTI组件：软电话服务用于业务行进行接打电话使用数据接收组件：接收数据获取采集组件获取到的数据及CTI相关数据，对数据进行分类处理数据汇总组件：接收各组各组件推送过来的数据进行计算及入库。并将数据推送给推送组件，数据包含标准话务数据（agent数据、分机数据、技能组数据、间隔报表数据）等等数据推送服务：对外提供接口，针对不同的接口进行数据推送分发控制台：负责通过当前流量计算可以是使用组件,以及是否需要引流等操作</p><p></p><p>通讯组件对外提供给业务端的数据获取接口，Web 接口，WebSocket接口，前端通过js接收数据。</p><p></p><p>报表系统通过Web接口来获取统计数据，实时监控系统通过WebSocket推送实时数据，通过Web接口获取历史明细数据。</p><p></p><h2>项目成果</h2><p></p><p>整体项目实施中，分为三个阶段</p><p>阶段一：单体架构，系统提供通话功能，首解率、系统SLA、用户满意度均停留在较低水平阶段二：多活架构，系统整合了多个金融服务，系统提供工单功能，首解率、系统SLA、用户满意度趋于行业平均水平阶段三：高可用架构，系统可进行弹屏辅助、动态压力感知，快速扩容，熔断降级的功能，首解率、系统SLA、用户满意度均高出行业平均水平</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/26/74/268fde846a04bd2311fd49b49122c574.png\" /></p><p></p><p></p><h3>未来规划</h3><p></p><p>现阶段热线客服整体架构已经趋于完善，但是整体架构还是和客服服务耦合严重，如果想要快速的迁移和扩展则需要较大成本，介于此话务中台顺势而生，下个阶段将会将整套的高可用架构进行封装为话务中台，微财下各个呼入呼出场景的业务均能快速集成并使用。</p><p></p><p>如下为话务中台核心设计原则：</p><p>汇总当前所有接入渠道，统一由话务中台接入，输出统一的接入SDK增强话务中台的延展性，提供统一的控制中心加强话务中台的核心价值及对业务系统的适配能力</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/90/c6/90d7bcdc371a46dbe6282dd0ec4e5bc6.png\" /></p><p></p><p></p><p>作者信息：</p><p>刘志敏，微财数科高级工程师&nbsp;</p><p>张兆强，微财数科资深工程师</p><p>李军，微财数科技术总监</p><p>吴迪，微财数科产品技术负责人</p>",
    "publish_time": "2022-12-30 18:38:23",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "打通研发管理任督二脉，驱动高科制造业提质增效",
    "url": "https://www.infoq.cn/article/x1UNFyRdi1pjYLYvyjA9",
    "summary": "<p>制造业是大国重器，也是实体经济的重要组成部分。2021年中国制造业增加值，在全球制造业增加值中占比接近30%，俨然成为世界第一制造大国。在政策、经济及技术的驱动下，制造企业纷纷将眼光投向“数字化转型”。这其中，高科制造企业也加紧了数字化的步伐，通过研发项目管理做好软硬协同、敏捷提效，是行业先行者们的共同探索。</p><p>&nbsp;</p><p>腾讯TAPD作为国内最早一批上线的敏捷协作研发平台，积累了腾讯10余年敏捷研发精髓，腾讯的每一款成功产品，如QQ、微信、企业微信、腾讯会议等背后，都离不开敏捷研发实践，都离不开TAPD的支撑。对外开放之来，腾讯TAPD为金融、游戏、社交文娱、电商零售、高科制造、企业服务等诸多行业客户量身打造了产品研发全生命周期解决方案，并帮助客户解决项目管理问题，提升研发效能。</p><p>&nbsp;</p><p>2022年12月21日，腾讯TAPD联合InfoQ、36Kr等平台举办了「TAPD 思享汇」线上分享课，「TAPD思享汇」希望为客户企业搭建沟通与交流的桥梁，助力客户企业在各自的赛道上成为行业翘楚。在第一期「 TAPD思享汇」上，腾讯TAPD邀请了创维VR研发总监张毅、元年科技研发流程总监周晓芳、鱼快创领项目管理专家唐骥三位行业专家，聚焦高科制造行业如何通过搭建软硬件一体化研发解决方案实现敏捷提效、如何开展量化质量管理快速交付业务价值等主题展开分享。本分享挖掘了腾讯TAPD的产品能力与在高科制造行业的实践经验，希望为高科制造行业从业者提供一定参考和启发。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/b4/db/b4ba5a6ee092cde38e478f7dbedb67db.png\" /></p><p></p><p></p><h2>一 高科制造业在软硬件研发协同上的难点</h2><p></p><p>&nbsp;</p><p>高科制造业由于需要软硬件协同，在项目研发时会遇到诸多困难：</p><p></p><h3>1 硬件开发周期长，软硬件协同复杂</h3><p></p><p>&nbsp;</p><p>相较于其他，软硬件一体的产品开发更为困难。因为硬件涉及到结构、ID、电路以及整个供应链生产体系，硬件研发过程中也分概念、计划、开发、验证等不同的阶段，软件也分为设计、开发、测试等不同迭代的过程，系统和组件间如何配合统筹很关键。在研发过程中，软硬件之间以及软件内部各团队的统筹协作是非常关键的，需要有比较成熟的协作平台来助力研发。</p><p>&nbsp;</p><p></p><h3>2 产品矩阵丰富，项目管理迎来挑战</h3><p></p><p>&nbsp;</p><p>高科制造业产品交付中既有硬件，也有软件，更有软硬件的交互，需要多种形式的组合管理，多条业务线的计划对齐，产品设计和研发同步推进。这些都对项目管理提出了巨大的挑战。</p><p>&nbsp;</p><p></p><h3>3 团队规模庞大，高效协同困难</h3><p></p><p>&nbsp;</p><p>高科制造企业发展势头迅猛，项目和需求高速增加，开发过程的提效增速愈加迫切。以创维VR需求开发为例，整个流程包括产品评审，美术评审，美术走查，用例评审，开发评审，需求确认多个环节，如何高效协同，是团队迫在眉睫需要解决的问题。很多项目都是综合的、复杂的、成体系的、需要软硬一体的解决方案和项目组合管理。</p><p>&nbsp;</p><p>针对这些问题，创维VR，元年科技，鱼快创领在研发过程中引入了腾讯TAPD敏捷化管理工具，采用敏捷思维，分而治之，从而实现快速迭代。</p><p>&nbsp;</p><p></p><h2>二 软硬件一体化研发解决方案</h2><p></p><p>&nbsp;</p><p></p><h3>1 聚焦产品价值，选择值得做的产品</h3><p></p><p>&nbsp;</p><p>高科制造业中，需要综合实现硬件产品、SaaS产品、平台产品、APP等等，需求纷繁复杂，是否要做某个需求，优先级如何考量？鱼快创领最终的答案是：产品聚焦价值，从价值的角度对产品（活拆分的需求）进行全流程把控。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/56/80/56bcac4a7c3e6a238b70abd7893de880.png\" /></p><p></p><p>鱼快创领建立了端到端的价值评估流程，在TAPD里创建需求洞察评审项目，专门管理经过评审的需求或者产品，需求提出方需要对背景、内容以及其他相关情况做简单且全面的说明。最终从3个维度来筛选产品是否要做：需不需要做、值不值得做，以及有没有能力做。</p><p>评审通过的需求或产品会进行拆解，录入到TAPD的各个项目中，定义需求流转的标准流程，囊括了产品、设计、开发、测试、运维、项目经理等多个角色。</p><p></p><h3>2自定义标准的需求流转流程，保障业务价值的快速流动</h3><p></p><p>&nbsp;</p><p>高科制造业研发项目最大的特点便是跨多业务线、涉及多项目团队，需要多角色协同工作，流程复杂。例如，在创维VR的需求开发中，需要：</p><p>&nbsp;</p><p>产品评审：与设计开发明确需求，评估需求工作量。</p><p>美术评审：与开发沟通和对齐UI/UE设计细节。</p><p>美术走查：开发完成初版后，先转美术确认UI/UE还原度。</p><p>用例评审：产品、开发、测试确认用例完备度。</p><p>开发评审：需求必须经自测试环节并经产品确认后才能转测试。</p><p>需求确认：转测试后产品同步确认需求完成度。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/2a/1e/2ae13ea107701c4272ce32b9ceb0be1e.png\" /></p><p></p><p>TAPD具备强大的敏捷项目管理能力，通过自定义标准化的需求流转工作流，保障业务价值的高效流动。此外通过自定义的项目模板可完成交付类项目管理，贯穿整个产品研发生命周期的研发项目管理方案，有力支持团队敏捷研发。整个流程都可以引入关键评审点来把控需求流转的质量，确保不会有人为疏忽或遗漏造成质量问题。</p><p>&nbsp;</p><p></p><h3>3 软硬一体化项目组合管理，保障项目如期高质量交付</h3><p></p><p>&nbsp;</p><p>很多高科制造业的开发，都需要综合的、成体系的解决方案，很难通过单独的项目团队去实现，需要软硬一体化的项目组合管理。基于现有的产品功能，在TAPD里可以创建多个独立的项目一起承接，由原先的 project management上升到portfolio management。</p><p>&nbsp;</p><p>l&nbsp; 父子项目层级+自定义项目模板，为软硬件一体化产品量体裁衣</p><p>&nbsp;</p><p>随着项目的数量和类型的增加，需要将项目进行分级分类，每一个具体类型都会以模板的形式固化下来，立项通过之后直接创建。TAPD具备父子项目的相关功能，通过在TAPD里面直接创建项目，既能拥有同类项目的共性和标准，又允许项目存在个性化。</p><p>&nbsp;</p><p>在软硬一体项目的组合管理中，由于牵涉的子项目比较多，相互的依赖关系复杂，管理者需要监控执行，查看进度并纠正偏移，仅仅靠站会或者庭审会是远远不够的。通过TAPD甘特图功能，管理者可以实时掌握组合内所有项目的执行情况，轻松监控全局。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/5b/77/5b3baf8db13c7c785802fdcd8ee49777.png\" /></p><p></p><p>&nbsp;</p><p>l&nbsp; 自定义多角色工作流，保证项目有序协作</p><p>&nbsp;</p><p>项目的执行依赖于各个角色成员，如产品拆解需求，研发承接需求，项目制定计划跟踪执行等。</p><p>&nbsp;</p><p>不管是项目组合还是单个的项目管理，在TAPD上都可以实现自定义项目模板、自定义不同角色的工作流。以测试为例，TAPD支持用例的导入，单个执行用例或者批量执行用例，针对未通过的用例也可以快速创建缺陷，同时在测试计划下查看该计划的执行情况，快速评估该阶段需求测试和目的验证的情况，最终还可以一键生成测试报告。此外我们通过测试计划的模板，自定义建立不同类型项目的测试管理流程规范，从而保障项目有序协作并高质量交付。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/15/de/15c2e7c07515d14d504485cc27f7b5de.png\" /></p><p></p><p></p><h3>4 集成企业微信，让协作与沟通无缝衔接</h3><p></p><p>&nbsp;</p><p>TAPD可以与企业微信深度集成，完成消息的触达和移动端协作。比如元年科技在企业微信上接收 TAPD 通知、定时报告，将放在TAPD的Wiki里的内容通过企业微信发送发版通知。也可以借助企业微信机器人进行事件自动提醒、需求智能创建、质量自动反馈等智能化研发实践，让研发协作，更加智能。</p><p>此外，当需求和BUG流转到某一个人，他会在TAPD工作台的待办任务里看到，做到第一时间应答。通过工时和甘特图等工具，实现了研发的资源管理，让项目的管理工作具体化，管理任务和成员任务更加明确。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/1c/ec/1cc1ffa777b805f824e83d72602243ec.png\" /></p><p></p><h2>三 量化质量管理快速交付客户价值</h2><p></p><p>&nbsp;</p><p>TAPD 项目中的报表应用提供了丰富的统计分析功能，帮助实现项目的量化管理。从全局角度,直观展现公司的项目进度、业务质量、工作饱和度等关键信息,满足研发负责人、项目经理、业务线负责人甚至管理层不同层级的管理诉求。比如可以统计出哪些地方bug特别多，监测到是谁负责，模块是否被卡住，是否需要协调资源来帮他完成。这样就保障了团队项目的顺利开发。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/f0/c6/f040feyycac3c185863cb9e9882a47c6.png\" /></p><p></p><p>在迭代开发中，TAPD对需求BUG迭代等进行研发项目管理，这些数据能通过API与Gitlab上的代码汇总，后续能计算分析数据，方便展示和后续改进。</p><p>&nbsp;</p><p>元年科技是如何通过TAPD是如何提升客户满意度的呢？通过收集意见，发现客户反馈最多的就是 bug响应时间较长，降低了客户体验感。于是，元年在TAPD上搜集了bug相应时间，分析之后发现：因为客户比较多，一个产品可能多家都在使用，如果这款产品有一个小bug或者缺陷，那这些客户都会发现。因为不同客户对bug的描述不一致，所以bug会分配给不同同事处理，导致bug被重复解决，造成了资源的极大浪费。</p><p>&nbsp;</p><p>看到这个问题后，在某个产品或者模块，元年设置了关键接口人。所有关于这个产品的bug都先交由接口人查看，接口人做汇总后统一处理bug，大大缩短了bug的响应时间和解决时间，从最初的43小时到后期的16小时，极大提升了客户满意度。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/53/70/53c19789aed98c35755b79697162cf70.png\" /></p><p></p><p></p><h2>结语</h2><p></p><p>&nbsp;</p><p>总体而言，TAPD满足了高科制造企业软硬件一体化产品研发项目管理的核心需求，包括日常的敏捷项目管理中的需求管理、缺陷管理、测试管理、发布管理等，同时支撑起组织内一部分的事务管理。</p><p></p><h3>1 敏捷研发提升企业生产力</h3><p></p><p>&nbsp;</p><p>TAPD为产品研发项目全生命周期与工作任务跟踪提供专业的解决方案，支持工作任务跟踪、敏捷需求规划、迭代计划跟踪、测试与质量保证、持续构建交付等全过程研发实践，协助产品和项目完成从0-1，从1-100的进化，提升了协作效率和研发效能。</p><p></p><h3>2 需求流转提升团队协作力</h3><p></p><p>&nbsp;</p><p>通过TAPD的需求定制和流程定制的功能，使项目工作流更智能化，解决了研发过程中需求沟通不畅，支持不充分等问题，提高了团队工作的灵活性和内部协同的工作效率。&nbsp;</p><p></p><h3>3 量化分析提升组织管理力</h3><p></p><p>&nbsp;</p><p>TAPD为管理员提供多维度、可视化研发数据度量，帮助管理员聚焦关键指标，提供决策依据。对内而言，多维度的统计报表、跨项目的聚合视图、按需订阅的个人仪表盘、灵活好用的甘特图，可以帮助团队度量研发过程，持续优化提升组织研发效能。对外而言，量化数据继而做对应的调整（如bug的响应时间），为提升客户体验提供了坚实的数字基础。内外共同驱动，提升了组织管理和团队效能。</p><p>&nbsp;</p><p>通过引进腾讯TAPD这样的高效协作的平台，使工作更加自动化和智能化。用工程化的方法来规范软件开发，从时间、范围、成本三个维度来控制，保障了项目按时完成，成本可控，质量有保证。正如鱼快创领-项目管理专家唐骥先生所说：TAPD就像一盏车灯，帮助企业驶向更远的前方、更光明的未来。</p><p>&nbsp;</p>",
    "publish_time": "2022-12-30 18:55:17",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]