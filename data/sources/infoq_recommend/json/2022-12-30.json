[
  {
    "title": "亚马逊云科技为蓝绿及金丝雀策略引入CloudFront持续部署",
    "url": "https://www.infoq.cn/article/LW5JeoLR0Jcl1ktRNV0o",
    "summary": "<p>亚马逊云科技宣布CloudFront现已支持<a href=\"https://aws.amazon.com/about-aws/whats-new/2022/11/amazon-cloudfront-continuous-deployment-support/\">持续部署</a>\"，可用部分实时流量测试并验证配置变化。AWS内容交付网络的新功能简化了蓝绿及金丝雀部署策略。</p><p></p><p><a href=\"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Introduction.html\">CloudFront</a>\"的持续部署是为部署后验证、向后兼容，仅使用小部分请求验证新功能等场景而设计。AWS高级解决方案架构师<a href=\"https://www.linkedin.com/in/joe-v-3428806/\">Joe Viggiano</a>\"，首席解决方案架构师<a href=\"https://www.linkedin.com/in/johnsoncarlp/\">Carl Johnson</a>\"，以及首席产品经理Vishal Anand如此<a href=\"https://aws.amazon.com/blogs/networking-and-content-delivery/use-cloudfront-continuous-deployment-to-safely-validate-cdn-changes/\">解释</a>\"：</p><p></p><blockquote>当前行业上对于测试CDN配置变化已有的解决方案是需要在客户端注入自定义头信息、覆盖客户端DNS设置，或者实施单独的测试域。这一切都让大规模测试充满挑战。客户可能会不得不在应用程序中建立复杂的功能标志（……）这种方式缺乏可扩展性，且不能百分百引导生产流量，无法确保新引入的变化不会对工作负载产生负面影响。</blockquote><p></p><p>&nbsp;</p><p>借助CloudFront的持续部署，客户向主要分布中发送请求，CloudFront基于<a href=\"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/continuous-deployment.html\">持续部署策略</a>\"中的权重或头配置，将其中部分请求路由到暂存分布。基于权重的配置会将特定百分比（最高可至15%）的Viewer请求路由到暂存分布，而基于头的配置则会根据特定HTTP头将请求路由到暂存分布。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/78/7830cd8341e2182a6a59a1e28dc0bee9.png\" /></p><p></p><p>来源：<a href=\"https://aws.amazon.com/blogs/networking-and-content-delivery/use-cloudfront-continuous-deployment-to-safely-validate-cdn-changes/\">https://aws.amazon.com/blogs/networking-and-content-delivery/use-cloudfront-continuous-deployment-to-safely-validate-cdn-changes/</a>\"</p><p>&nbsp;</p><p>两种方式都可用于测试同一部署，以基于头的配置验证已知测试用户和设备的第一条变更，随后在借助基于权重的配置引入生产流量。这一功能通过将Viewer会话与环境绑定，让监控标准及实时日志变得可行，一旦变更对服务有影响，可即时回滚回先前的配置。Viggiano、Johnson及Anand写道：</p><p>&nbsp;</p><p></p><blockquote>在需要进行测试时，CloudFront现在允许创建一个与生产分布相关联的暂存分布 。可在暂存分布中修改原点、原点组、缓存行为、客户错误响应、默认根对象、日志和地理限制等设置，未来还会增加更多可更改的设置项。</blockquote><p></p><p>&nbsp;</p><p>开发者们对于AWS CDN上对蓝绿及金丝雀部署的支持期盼已久，无论是在<a href=\"https://www.reddit.com/r/aws/comments/ix8l52/what_is_the_status_on_doing_bluegreen_deployments/\">红迪</a>\"还是<a href=\"https://serverfault.com/questions/714742/blue-green-deployments-with-cloudfront\">Server Fault</a>\"上都有很多讨论串。云顾问及AWS无服务英雄<a href=\"https://www.linkedin.com/in/theburningmonk/\">Yan Cui</a>\"则对这个<a href=\"https://twitter.com/theburningmonk/status/1595054650629427206\">名称</a>\"发出来质疑：</p><p></p><blockquote>非常赞，但我不太理解为什么要叫CloudFront“持续部署”，而不是叫CloudFront金丝雀部署之类的名字。</blockquote><p></p><p>&nbsp;</p><p>主要分布和暂存分布不共享缓存。在资源使用高峰期，CloudFront可能会无视持续部署策略，将所有请求全部发送到主要分布。基于当前限制，CloudFront持续部署不支持<a href=\"https://www.infoq.com/news/2022/08/amazon-cloudfront-http3/\">启用了HTTP/3</a>\"的分布。</p><p>&nbsp;</p><p>该新功能可在所有AWS边缘，通过控制台、SDK、CLI或CloudFormation模板使用。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/11/aws-cloudfront-continuous/\">AWS Introduces CloudFront Continuous Deployment for Blue-Green and Canary Strategies by Renato Losio</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/IjopWm7HUlP8qftzbOB3\">AWS Lambda 现可支持 Node.js 18 运行时</a>\"</p><p><a href=\"https://www.infoq.cn/article/O9jijEFIBtaaeecQCe8K\">亚马逊云科技向 Well-Architected Framework 添加容器透镜</a>\"</p>",
    "publish_time": "2022-12-30 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "不管扎克伯格怎么想，虚拟世界都不需要 VR",
    "url": "https://www.infoq.cn/article/N6SrCwYGgA4rwSyW6VFE",
    "summary": "<p>扎克伯格的<a href=\"https://www.infoq.cn/article/j4AToos49jT09GQ5TCkr\">元宇宙梦</a>\"给投资者带来了噩梦。他每年在“具身化的互联网”（embodied internet）上押注 100 亿美元，之后 Meta 市值大幅下跌，季度营收首次出现下滑，增长前景黯淡。Meta公司推出的元宇宙平台Horizon Worlds是他在这个领域的首次尝试，这只能让人更加担心。由于采用范围不广、持续存在的错误和滑稽的虚拟形象，该社交平台常常遭到人们的嘲讽。</p><p></p><p>尽管批评声越来越大，扎克伯格仍然对让 Facebook 成为一家“元宇宙公司”持乐观态度。但是，英国独角兽企业 Improbable 的首席执行官 Herman Narula 认为，Meta 的愿景忽略了一个根本问题。“问题在于 VR（虚拟现实），”Narula 近日在斯坦福大学表示，“在硬件上的赌注太高了，与元宇宙的主要价值主张相去甚远，而且很难看出他们如何收回投资。”</p><p></p><h2>元宇宙需要“存在感”</h2><p></p><p></p><p>Narula 有自己的元宇宙项目。他的公司花了十年的时间来构建沉浸式的虚拟世界，从为美国陆军模拟战争游戏，到为 1450 名韩国流行音乐爱好者举办的互动派对。他还写了一部名为《虚拟社会》（Virtual Society）的著作，对元宇宙的理论体系进行了简要的阐述。在 Narula 的心目中，它包含了一个可以让人不用戴着头盔就能通过的数字体验网络。取而代之的是，只需通过一部手机或者一台电脑就能进入这些网络。</p><p></p><p>Narula 承认 VR 给人以强烈的沉浸感。但是，他认为，元宇宙还需要更重要的东西：存在感。</p><p></p><p>他将沉浸感描述为“世界是真实的感觉”。与之相对的是，存在感是“世界认为你是真实的感觉”。要想营造出这种感觉，用户的行为必须在整个虚拟世界中产生反应和涟漪。</p><p></p><p>Narula 断言，存在感不需要 VR。作为证据，他列举出了《Minecraft》《Roblox》和《Fortnite》这些“原始元宇宙”游戏，虽然这些游戏画面很粗糙，但是却能让人产生一种存在感，让这些游戏成为全球最流行的游戏之一。</p><p></p><p>根据 Narula 的说法，扎克伯格基于 VR 的元宇宙存在几个问题。其中之一是成本：新款 <a href=\"https://www.infoq.cn/article/KOcaWVjk3jdAmOFUYEpU\">Quest Pro VR 头盔</a>\"的售价高达 1500 美元。技术上的改进——包括眼球追踪和混合现实功能——带来了很大的提升，但由于价格的原因，它们对大多数客户来说无法企及。</p><p></p><p>扎克伯格已经承认了这个障碍。他形容这顶新的头盔是一种“专业消费者”设备，并计划在明年推出消费者级别的版本。调查显示，公众并不会一窝蜂地涌入购买。</p><p></p><p>Meta 公司也采取了初步措施来整合主流设备。该公司计划推出 Web 和移动版本的 Horizon Worlds，让用户无需戴 VR 头盔就能进入。然而，这有可能会导致一种双重体验。</p><p></p><h2>加速虚拟引擎</h2><p></p><p></p><p>自然，Narula 有他自己的计划来制造存在感。他认为 Improbable 是一个无与伦比的平台，它是元空间的一个重要组成部分：容量。为了支持这一观点，Narula 引用了一项名为每秒通信操作（OPS）的指标。</p><p></p><p></p><blockquote>这是元宇宙的马力。（译注：horsepower，俗称匹，是一个古老的功率单位。今日除了航空、造船与汽车工业提及内燃机的功率、空调的制冷性能以外，在其他领域较为少用马力这个单位，而会使用标准的国际功率单位瓦特。）</blockquote><p></p><p></p><p>每秒的操作数反映了在虚拟世界中可以同时发生多少不同的事情。 Improbable 的联合创始人 Rob Whitehead 形容这是“虚拟世界的‘马力’”。</p><p></p><p>Whitehead 将每秒操作的大致计算公式描述如下：</p><p></p><p>数学公式: </p><p></p><p>为了说明其工作原理，他引用了一款名为《反恐精英：全球攻势》（Counter-Strike: Global Offensive）的竞技射击游戏。如果游戏有 10 个玩家，那么他们都可以看到对方，而服务器每秒发送玩家更新 64 次，计算结果将是 数学公式:  每秒操作数。</p><p></p><p>随着玩家、密度和保真度的增加，这个数字会急剧上升。例如，EVE Online 的 8000 名玩家的对战中，如果每秒只发送 0.1 次玩家更新，每秒将产生 640 万次操作。</p><p></p><p>对比之下，Improbable 声称它现在每秒可以处理 20 亿次操作。</p><p></p><p>每秒的操作次数是比较虚拟世界的关键指标——你会听到我和 Narula、M² 经常使用这个指标。你可以将它想象成虚拟世界的“马力”——它所拥有的原始连接能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e0/e0d0ca0340131c952f54ff85a6641aa8.png\" /></p><p></p><p>为了解释虚拟世界的计算复杂性，Whitehead 提出了一个叫做“元宇宙狙击手问题”的难题。</p><p></p><p>“当你放大狙击步枪的瞄准镜时，你需要能够高保真地看到遥远的世界，才能获得精准的射击，”他说。</p><p></p><p>“对于 60~100 名玩家的传统游戏来说，这是很难做到的，因为架构的网络需求呈四次方扩展：200 名玩家的游戏的网络需求是 100 名玩家的 4 倍。因此，要让（成千上万的）玩家体验元宇宙，你需要从根本上改变技术。”</p><p></p><h2>相互连接的世界</h2><p></p><p></p><p>VR 的主导地位并不是 Narula 对 Meta 的唯一问题。和很多批评者一样，他也为该公司，或者其他任何一家公司掌控元宇宙感到担忧。为了避免出现这个可怕的前景，Narula 想将另外一种备受争议的技术整合起来：区块链。</p><p></p><p>基于区块链的<a href=\"https://www.infoq.cn/article/uKVmglLJtPzMtxUs4uEd\">元宇宙</a>\"的支持者指出了两个关键好处：去中心化和互操作性。前者来自在分布式账本上存储数据，不受任何一家公司控制。同时，互操作性是通过加密保护数据交换而实现的。例如，你的虚拟角色的衣服，可以在不同的虚拟世界之间安全地移植。</p><p></p><p></p><blockquote>这就是它不只是一个游戏的原因。</blockquote><p></p><p></p><p>区块链并不是提供这种可移植性的唯一手段。另外，公司可以就促进不同平台之间的数字传输的规则和系统达成一致。然而，Web3 的倡导者警告说，这样做会增强大型科技公司对我们的数据的掌控。</p><p></p><p>然而，这只是他们必须要赢得的一个论点。区块链的推动者还必须解决对该技术的可扩展性、环境影响以及对加密货币现金掠夺倾向的担忧。尽管如此，Narula 看起来很有信心，它的好处会比它的消极影响更大。</p><p></p><p>这位 34 岁的人设想，区块链能够实现世界之间的传输。公司将通过分享客户来建立元宇宙的业务，而用户将享受跨平台的有意义的体验。根据 Narula 的说法，VR 和 AR 与所有这些互动没有太大的联系。</p><p></p><p>“它们完全可以发挥作用，构建更具吸引力的体验，但它们并没有颠覆。”他说，“颠覆性的是——这些世界发生的事件可能会在一瞬间变得更加重要。这就是在我们和这些体验之间创造不同关系的原因。所以，它不只是一个游戏。”</p><p></p><p>作者简介：</p><p>Thomas Macaulay， TNW 媒体撰稿人。</p><p></p><p>原文链接：</p><p>https://thenextweb.com/news/metaverse-doesnt-need-vr-improbable-ceo-herman-narula-meta-zuckerberg</p>",
    "publish_time": "2022-12-30 09:51:43",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "马斯克关闭Twitter加州数据中心，员工还要自带卫生纸上班",
    "url": "https://www.infoq.cn/article/uuXOhcwzyFGzArMDdAsR",
    "summary": "<p>根据<a href=\"https://www.nytimes.com/2022/12/29/technology/twitter-elon-musk.html\">《纽约时报》</a>\"报道，埃隆·马斯克(Elon Musk)已经将Twitter成本缩减到维持基本运营的水平，员工们“零基础预算”，任何支出都要证明是合理的。</p><p>&nbsp;</p><p>据悉，在平安夜前夕，纳斯克飞往加利福尼亚州的萨克拉门托——Twitter三大主要计算存储设施之一的所在地——切断了维持该社交网络平稳运行的服务器。有知情人士表示，虽然有员工担心关闭这些服务器可能导致各种问题，但节省资金是首要任务。</p><p>&nbsp;</p><p>关闭数据中心是马斯克为稳定Twitter财务状况而采取的众多激进措施之一。过去几周，Twitter已经<a href=\"https://www.infoq.cn/article/NmgXYDUGCySPL8lqkik1\">停止支付数百万美元的办公室租金和服务费用</a>\"，马斯克要对这些协议进行重新谈判或者干脆终止。据悉，该公司已停止支付西雅图办公室的租金，这导致该公司面临被驱逐的局面。清洁和安全服务被削减，某些情况下，员工不得不自己带卫生纸到办公室。</p><p>&nbsp;</p><p>去年10月底，马斯克以440亿美元的价格收购了这家社交网络公司，这样让马斯克背上了巨额债务，他每年需要支付约10亿美元的利息。上周，马斯克将Twitter比作“一架引擎着火、控制失灵、高速冲向地面的飞机”。马斯克表示，到2023年，Twitter将面临大约30亿美元的“负现金流状况”，原因是广告环境低迷以及债务支付等成本增加。“这就是为什么我在过去五周疯狂削减成本。”</p><p>&nbsp;</p><p>但这些削减措施可能会产生一些后果。周三，世界各地的用户报告<a href=\"https://www.infoq.cn/article/SEMJIMViDzxqUQ4gebBT\">Twitter服务中断</a>\"。一些用户反馈 Twitter 出现很多奇怪的错误消息，比如看到空白页面、无法回复推文或关注热门话题，还有人被迫退出登陆。有熟悉Twitter基础设施的人士表示，如果萨克拉门托的设施仍在运行，它就可以在其他数据中心出现故障时提供备份计算能力，从而帮助缓解问题。现在，Twitter 将只剩下位于亚特兰大和俄勒冈州波特兰的数据中心。</p><p>&nbsp;</p><p>根据《纽约时报》得到的一份内部文件，自11月初以来，马斯克一直试图节省约5亿美元的非劳动力成本。收购完成后，他还裁掉或解雇了公司近75%的员工。</p><p>&nbsp;</p><p>成本削减一直由Steve Davis和Jared 负责，Davis是马斯克的隧道挖掘初创企业the Boring Company的负责人。</p><p></p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.nytimes.com/2022/12/29/technology/twitter-elon-musk.html\">https://www.nytimes.com/2022/12/29/technology/twitter-elon-musk.html</a>\"</p>",
    "publish_time": "2022-12-30 10:02:42",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "「AI推理」加速核心原理解析与工程实践 | 云原生 AI·技术公开课 第三期",
    "url": "https://www.infoq.cn/article/mPJzSMJ53meqBkFT2Nku",
    "summary": "<p>直播看点：<br />\n1、了解AI推理加速的核心原理、评估指标以及相应的优化方法<br />\n2、了解百度百舸平台的AI推理加速套件AIAK-Inference的工程实践效果</p>",
    "publish_time": "2022-12-30 12:54:18",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "「AI训练」加速原理解析与工程实践分享 | 云原生 AI·技术公开课 第二期",
    "url": "https://www.infoq.cn/article/tQqPUkoJ90bVbVPbW2Ee",
    "summary": "<p>直播看点：</p>\n<ol>\n<li>系统性了解各类 AI 模型训练方案下的 AI 训练瓶颈</li>\n<li>全面掌握 AI 加速训练的各种方法的原理</li>\n<li>了解百度百舸平台的 AI 训练加速套件 AIAK-Training 的工程实践效果</li>\n</ol>",
    "publish_time": "2022-12-30 12:54:21",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "云原生AI的资源调度和AI工作流引擎设计分享 | 云原生 AI·技术公开课 第一期",
    "url": "https://www.infoq.cn/article/Ga3SF30ulhwVsSc8Hbyh",
    "summary": "<p>直播看点：</p>\n<ul>\n<li>了解单机单卡、多机多卡、多机多卡等场景下云原生 AI 的资源调度方法。</li>\n<li>了解 AI 工作流引擎 PaddleFlow 打通底层资源和上层业务的架构和细节，提升 AI 工程效率。</li>\n</ul>",
    "publish_time": "2022-12-30 12:54:23",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "视觉大模型训练与推理优化 | 云原生 AI·技术公开课 第四期",
    "url": "https://www.infoq.cn/article/26yuRpJhQoP9INUveN4O",
    "summary": "<p>直播看点：<br />\n1、讲解如何结合profiling工具，发现训练与推理的性能瓶颈；<br />\n2、介绍结合GPU产品特点，利用算子融合、低精度等技术，以及Faster Transformer最佳实践，提升性能并加快吞吐。</p>",
    "publish_time": "2022-12-30 12:54:25",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "面向对象分析与设计的底层逻辑",
    "url": "https://www.infoq.cn/article/6e3c70d130a5769720178c79c",
    "summary": "<p>作者：高福来   阿里全球化业务平台团队</p><p></p><p></p><blockquote>在面向对象出现之前，已有面向过程的分析方法，那为什么面向对象被提出了呢？究其本质，人们发现面向过程并非按照人正常认识事物的方式去分析软件。面向过程是一种归纳的分析方法，由外到内的过程；面向对象是一种演绎的分析方法，由内到外的过程。本文将为大家分享面向对象分析与设计的底层逻辑。</blockquote><p></p><p></p><p></p><h1>一、面向对象是符合人认识事物的基本方法</h1><p></p><p></p><p></p><h2>1.1 人是怎么认识事物的</h2><p></p><p></p><p>在面向对象出现之前，已有面向过程的分析方法，为什么面向对象被提出了呢？究其本质原因，人们发现面向过程并不是按照人正常认识事物的方式去分析软件，那么人究竟是怎么认识事物的呢，Yourdon 在《面向对象的分析》一书中提到，人类认识事物是遵循分类学的原理，分类学主要包含三点：区分对象及其属性；区分整体对象及其组成部分；不同对象类的形成及区分。</p><p></p><p>我们现在可以回想下我们认识事物的过程，是不是和分类学所提到的 3 个要点很相似，看到一个事物，大概会感知到它的组成结构是怎样的，形状是怎样的，属于什么分类。所以，人认识事物是以对象的视角切入的，然后赋于对象具体的概念，比如苹果、梨子、汽车等等概念名称。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a0/a0ed19160e2da5b09749e545c05eff46.png\" /></p><p></p><p></p><h2>1.2 分类与分层的两种思维</h2><p></p><p></p><p>我们面对的现实世界是非常复杂的，应对复杂事物的有一个重要的方法即是抽象，抽象在实际应用过程中，又体现在两种方法上：分层和分类。分类即是将有差异的事物归类到不同的分组中，正如我们常听到的\"物以类聚、人以群分\"的道理一样，产生分类的原因有两点：一点是事物间的关联紧密程度，不需要将所有的事物都耦合在一起；另一点是人掌握事物是有局限的，只能掌握少量的要点，比如 5~7 个要点，超过了容易忘记。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/57/57b6975e1a3462aaaa6ae5436448476e.png\" /></p><p></p><p>分层是通过不同的视角看事物，每一层的关注点是不一样的，这种关注点不同是由自己的视角造成的，比如我们理解计算机，并不需要深入到二进制电信号去理解计算机。层次特性在软件设计中我们经常遇到，比如计算机体系结构、TCP 七层协议等，层次特性有一个特点：越往上越具体、越往下越抽象，越往上的内容越不稳定，也即是容易变化。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/78/784b7e3330f2d9a0d8fd54c79e9a8d6e.png\" /></p><p></p><p></p><h2>1.3 问题域到解空间的映射</h2><p></p><p></p><p>我们把需要解决的问题称之为问题域，或者问题空间，把解决方案称之为解空间。正向上一小节中提到的事物有层次特性，不同的人理解的事物是站在各自理解的视角，这样大家的理解、沟通并不一致的。如果我们看到的问题空间是表层的，那么基于浅层次理解设计出来的方案就会不稳定，可能下次有一个小变化导致方案需要重新设计。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/77/7787b6a36b2827f8f1588449429ae8d4.png\" /></p><p></p><p>我们可以把一个软件划分成三层：场景、功能和实体，场景层是经常会变的，比如发放优惠券场景就非常多，比如有天降红包领取优惠、分享有礼领取优惠券、新人注册领取优惠券等，这种场景的更迭随着业务的调整变化得非常快，因此场景层是不稳定的。功能支撑某一些的场景集合，对比场景，功能相对而言稳定些，就像前面提到的发放优惠券场景，本质就是给用户发放优惠券，只需要提供发放优惠券的功能即可，至于哪些场景来调用它并不关注，但功能还是基于场景的集合抽象出来的，如果场景场景类型变化了，功能也就随之变化，比如担保交易和预售交易就不一样。实体是稳定的，以担保交易和预售交易为例，它的订单模型大致是一样的，只是新增加了一些信息而已。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0e/0e3e1aa1850d247868d06d727fba2cd6.png\" /></p><p></p><p>因此，我们希望从问题空间到解空间，大家看到的、理解的是一致的，而且看到的是问题的本质而非表象，往往场景、功能是不稳定的，而面向过程又是以功能驱动的，所以在易变化的场景下，它面临的问题就比较多。比较稳定的是问题空间中的实体对象，所以面向对象分析是现实的需要。面向过程和面向对象是两个不同的视角的分析方法：面向过程是一种归纳的分析方法，由外到内的过程；面向对象是一种演绎的分析方法，由内到外的过程。</p><p></p><p></p><h2>1.4 三个一致性</h2><p></p><p></p><p>软件开发会经历需要分析、概要设计、详细设计、编码、测试、上线主要阶段，我们不希望每块是割裂的，比如分析做完之后，做设计阶段又要重新去做分析的工作，那么这里面就涉及到一致性的问题，即需求到分析的一致性、分析到设计的一致性、设计到编码的一致性。这样做的好处可以保证无信息失真，因此我们急需求一种分析设计方法能做到这一点，面向对象分析与设计就能做到，因此全流程是以对象作为分析与设计的目标，在最终编码中也都是对象。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/86/861eef47c4922e510fa84a25855f4c0f.png\" /></p><p></p><p></p><h2>1.5 面向对象的底层逻辑</h2><p></p><p></p><p>提到面向对象，有部分人会提到封装、继承、多态等特性，然后这些并不是面向对象的本质特性，比如封装，面向过程中也有封装，多态面向过程也有体现，这些特性算不上面向对象特有的特性。面向对象的底层逻辑是基于现实事物做的抽象映射：现实事物对应软件中的对象，我们讨论解空间能对应到问题空间中的对象，两者是一一直接映射的，其它的分析方法是问题空间到解空间的间接映射。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f0/f06bbc579cc38b4e05324e15c9dd2674.png\" /></p><p></p><p></p><h1>二、面向对象分析与设计的全景图</h1><p></p><p></p><p></p><h2>2.1 我们面临的问题是什么</h2><p></p><p></p><p>从顶层看，我们要完成需求到编码的工作，然而从需求到编码又会经过多个阶段，如需求分析、方案设计等，从大的层面讲，我们主要遇到三个问题：</p><p></p><p>1）做什么的问题</p><p></p><p>看似这是一个简单的问题，但在复杂的业务场景下，对做什么的理解太重要了，因为不同的人对需求的理解是不同的，比如最近做了一个项目，有一个业务判断规则是只针对跨境订单计税，最开始开发同学的理解是判断卖家类型是否是跨境卖家，然而到了测试阶段，发现大家对这个业务规则判断理解是不一致的，跨境订单跟卖家类型是没有关系的，真正的跨境订单计税场景是 shipTo（收货地址）和 shipFrom（发货地址）国家地址是不一样的。在大项项目中，涉及到多个团队之间的协同，这样的问题异常突出。而且从业务诉求到产品需求，再到技术方案，这其中是经过了 2 次变换，每次变换是不同的角色在里面，大家的认识也会不一样。</p><p></p><p>2）怎么做的问题</p><p></p><p>落实到事情具体要怎么做时，往往大家并不会出大的问题，怎么做偏具体执行阶段，程序员往往在逻辑严密性上没多大的问题，往往出问题是在第一个问题上，相当于方向弄错了，所做的工作也是无用的。</p><p></p><p>3）方法指导的问题</p><p></p><p>我们往往希望不劳而获得到一种万能的方法，能够应对所有的问题，同时又看不起低级的方法，比如大部分人对用例分析方法嗤之以鼻，想要能体现技术水平高大上的方法。其实自上世纪 70、80 年代，软件的分析设计方法并没有太大的变化，而且在我们大学期间都学过，只是大家并不认为它是一种高大上的方法而已。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/36/367962c3a51ebfd490e2cd7bdaf8e927.png\" /></p><p></p><p></p><h2>2.2 分析到设计的过程</h2><p></p><p></p><p>在本节中，我们推导软件分析到设计的过程，由粗到细，最终落实到我们接触到的 UML 知识上。从需求提出到编码实现，这中间有两个关键问题：一是界定目标，即是定义清楚要做什么的问题，相当于是我们做事的方向、目标；二是具体如何做的问题，即通过怎样具体的方案支撑需求目标实现。因此，我们需要一种方法能够帮助我们界定目标和表示具体方案，而且是大家互认的一种通用的方法。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3a/3aae5c3c98f95e84ca483451aa4c915b.png\" /></p><p></p><p>通过用例图可以帮我们界定目标，用例中有三个关键要素：用户、场景和目标。比如交易下单是一个用例，它的用户是买家，场景包含下单成功和下单失败两个场景，用例的目标是买家可以购买心仪的商品。当用例目标确定了，相当于界定了目标，知道需求要做什么，这个过程要反复和业务方确认好，至到最终大家对目标的理解是一致的，方向对了，具体怎么做就好办了。</p><p></p><p>具体怎么做用时序图表示，画时序图需要注意的一点是顶层的对象层次要一致，不能有的对象表示具体的实体对象，有的表示系统对象，即对象的层级是一致的，要么大家都是系统，比如导购系统调用交易系统，交易系统调用支付系统，要么大家都是对象，比如商品、订单等。通过时序图可以看到一个完整功能的执行步骤，它就包含具体执行的细节，如正常流程、异常流程。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/36/36cf81aad5088188f00caa608047314f.png\" /></p><p></p><p>其实在上面有一个问题，在画时序图时要确定好对象，那么这个对象是怎么来的呢？它是由健壮性图分析出来的，它里面有三个关键的对象：一个是边界对象，这个比较好理解，比如UI界面就是边界对象；另一个是控制对象，即是控制业务流程的对象，如下单服务就可以看作是控制对象；实体对象即是问题空间中的业务对象，比如订单。画健壮性图是有规则的，一般是边界对象调用控制对象，控制对象产生实体对象，比如用户下单界面是边界对象，下单服务是控制对象，订单就是实体对象。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/99/99908aafdfeb6c014168c5538224918c.png\" /></p><p></p><p></p><h1>三、寻找对象之路</h1><p></p><p></p><p></p><h2>3.1 对象从哪里来</h2><p></p><p></p><p>在本文第一部分第三小节中已经提到，问题空间到解空间是一一映射，我们讨论解空间中的对象时，其实它映射到问题空间中的对象，而问题空间中的对象主要来源于业务概念、业务规则、关键事件。大部分的对象是显现的，我们通过理解业务能发现，有的对象是隐性的，需要我们持续对业务有更深的理解才能发掘出来。好的对象模型是需要经过多次迭代打磨出来的，并非一次就能设计得十全十美。</p><p></p><p></p><h2>3.2 发现对象的方法</h2><p></p><p></p><p>在本文第二部分第二小节中已经提到寻找对象的方法，不过那还只是关键显现的对象，在本节中主要讲述完整对象发现的方法，主要方法分成四个步骤：</p><p></p><p>通过健壮性图找到关键的实体对象；通过结构分析方法找出更多的实体对象；将对象组成有机的对象模型；最后通过用例走查对象模型是否完备。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8e/8e7a90bd27ecd6af6e5da0c52a31dc96.png\" /></p><p></p><p>这里以一个案例来说明发现对象的过程，案例是用户在下单时，在订单上展示税的金额。首先画出健壮性图，这里的边界对象是下单界面，控制对象有两个，一个是下单服务，另一个是计税服务，实体对象也有两个，一个是计税单，一个是订单。有了计税单和订单这两个实体对象后，接下来通过结构分析方法，分析出更多的对象。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/99/9979be783f4412011d3944e3a4721261.png\" /></p><p></p><p>对象都是有结构的，只要我们掌握了对象的结构，基本上就能掌握对象的概貌，因此我们从对象的结构入手，去分析对象内部的结构、对象关联的结构，实质上是从两个维度出发：一是从自身的角度出发，看自己内部还包含了哪些对象，如主订单包含了子订单；另一个是从外部的角度出发，看自己还与哪些对象相关联，如计税单与订单是有关联的。这种找对象的方法我称之为结构分析方法，因为本身结构又是事物本质的一种表达方式，比如化学分子结构决定化学现象。</p><p></p><p>为了更好地表达出对象的结构，我的一个经验是给对象下好定义，下定义可以从不同的维度，比如功能性维度、价值性维度、目的性维度、结构性维度等，这里可以从结构性的维度去给对象下定义。以计税单为例，可以给它下一个定义：计税单是将订单金额信息转成若干个标的物计税的单据模型，从这个定义中，我们可以看到计税单是与订单有关联关系的，另一个是计税单是包含了若干个标的物，我们可以画出计税单的对象模型。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/964aca335d91ea9d39c262fac12771fb.png\" /></p><p></p><p>当对象模型画出来后，后续我们讨论业务基本上围绕这个对象模型去讨论业务问题的，比如商品标的物哪些金额要参与计税、计税金额的计算口径是怎样的，到这里，大家再体会下\"问题空间到解空间一一直接映射\"这句话，业务上的诉求也无非是哪些订单费用项要计税，计税的逻辑是怎样的，有可能在这个场景下要扣减金本位优惠，在另外一种场景下金本位优惠不需要扣减，基于对象模型与产品、测试同学讨论问题，大家都是处于同一个维度的视角看问题，沟通理解成本会少很多。</p><p></p><p>对象模型是一种可视化的表达，我们大部分的沟通问题是缺乏显性表达造成的，这句话可以这样理解，也可以那样理解，导致大家理解有偏差，现在用模型的形式沟通问题，很多偏差、歧义就消除了。</p><p></p><p></p><h2>3.3 组织对象结构</h2><p></p><p></p><p>当我们分析出一堆的对象后，还需要经过一定的组织，正如前面提到，人对事物理解是有局限的，不能一下子接受太多的事物，因此可以将它们分成一个个小的域，比如商品域、订单域、税务域等，这样当聚集一个问题时，可以只看某个子域里的对象模型即可。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c6/c6d3513f17382d1ac3c54913bda7aa26.png\" /></p><p></p><p></p><h1>四、如何分配职责</h1><p></p><p></p><p></p><h2>4.1 职责是怎么来的</h2><p></p><p></p><p>面向对象最难的点有两个：一个是找出对象；另一个是分配职责。UML 把职责定义为\"类元的契约或义务\"，因此职责的划分从本质来讲还是类元本身决定的，比如订单，它要提供订单渲染、订单创建、订单修改、订单查询的义务。</p><p></p><p>职责分为两类：一类是认知职责；另一类是行为职责。</p><p></p><p>认知职责包含：</p><p>对私有数据封装的认知；对相关对象的认知；对其能够导出或计算的事物的认识。</p><p></p><p>行为职责包含：</p><p>自己执行的行为，包括创建对象或计算；初始化其它对象的动作；控制或协调其它对象的活动。</p><p></p><p></p><h2>4.2 分配职责的逻辑</h2><p></p><p></p><p>上一小节中提到的职责有两类，认知职责是对象自身的认知范围，即它只能基于自身属性完成相应的职责，举一个例子，假如一主多子的订单，要计算总的订单金额，怎么分配职责呢？首先商品只能查到自身价格的信息，它的认识是基于商品 price 属性，一个子订单可以有多个商品，那么它也只能计算出子订单的金额信息，它的认知是基于 item 和 quantity两个属性，主订单包含所有子订单的信息，那么就可以计算出总的订单金额。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/33/335c5e6641c1a952e39db95313544a6d.png\" /></p><p></p><p>从上面的例子中我们可以看出，认知职责是基于对象属性的，正所谓\"不在其位、不谋其政\"，认知职责一定不会超过它的认识范围的。</p><p></p><p>行为职责是偏领域服务的，有的时候一个职责不属于某一个对象，比如转账，就是一个行为，让其它的职责承担并不合适，这类行为职责往往是一个显著的业务活动，比如订单渲染、订单创建就是行为职责而非认知职责。</p><p></p><p>分配职责一定要遵循\"信息专家\"模式，它的含义是将职责分配给具有完成该职责所需要信息的那个类，也即上面提到的认识产生职责。</p><p></p><p></p><h2>4.3 验证职责分配的合理性</h2><p></p><p></p><p>我们期望分配的职责满足\"高内聚、低耦合\"，怎么检验呢？我们再回过头来思考职责的定义：类元的契约或义务，换句话讲，职责是满足其它对象来调用的，这个就与我们画时序图的目的是一致的，每次发生一次调用，即意味着其它的对象要提供一个职责出来，因此我们可以在时序图中看对象间的调用频次，如果一个对象被调用得非常频繁，有可能这个对象承担了太多的职责，是不是可以对其拆分，把职责分配一部分出去。因此，对象职责分配并不是一蹴而就的，需要不断审视、检验。</p><p></p><p>分配职责是要遵循一定的原则，如创建者模式、信息专家模式、纯虚构模式等，这些原则会在下一篇中单独去讲。</p><p></p><p></p><h1>五、案例</h1><p></p><p></p><p></p><h2>5.1 案例背景</h2><p></p><p></p><p>这里举一个例子，说明面向过程和面向对象在分析、编写代码的差异性，计税需要判断是否满足计税规则，比如虚拟商品不计税（手机充值之类）、有些免税地址不计税、小 B 买家也不计税等，因此需要提供一个计税过滤判断逻辑。</p><p></p><p></p><h2>5.2 常规面向过程实现</h2><p></p><p></p><p>面向过程的思路很简单，提供一个过滤方法依次处理下面逻辑：过滤虚拟商品计税请求、过滤免税地址计税请求、过滤小 B 买家计税请求。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/09/09d03fde39cfb7433af34c7aa295c4b8.png\" /></p><p></p><p><code lang=\"text\">public void filter(List request){\n     \n     // 过滤虚拟商品计税请求\n     filterVirtualItem(request);\n\n     // 过滤免税地址计税请求(即外岛)\n     filterOuterIsland(request);\n\n     // 过滤小B买家计税请求\n     filterPurchaseType(reqeust);\n\n}</code></p><p></p><p></p><h2>5.3 面向对象实现</h2><p></p><p></p><p>面向过程是从过程视角或者是功能视角分析问题，而面向对象是从对象的视角分析问题，过滤计税请求是计税过滤器判断计税请求是否满足计税规则，这里就包含了两个对象：计税过滤器和计税规则，判断是否满足计税要求这个职责应该是在具体的计税规则处理器中，比如是否是小 B 买家等，因此我们可以画出对象模型。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e8/e84107ae2a8086495fcbdcbb9bfd8d1d.png\" /></p><p></p><p>关键代码如下：</p><p></p><p><code lang=\"text\">\npublic abstract class AbstractRuleHandler {\n\n    /**\n     * 抽象的业务规则处理\n     *\n     * @param request\n     */\n    public abstract void handler(TaxCalculateRequest request);\n\n    /**\n     * 构造函数里完成注册\n     */\n    public AbstractRuleHandler() {\n        TaxCaluclateFilter.register(this);\n    }\n}</code></p><p></p><p></p><h1>六、总结</h1><p></p><p></p><p>在文章中提到，面向对象的底层逻辑是基于现实事物做的抽象映射，重要的不是要面向对象具体技术的使用上，而是分析问题的思维上，这是最难的，它最大的好处是问题空间到解空间是一一直接映射的，请注意是一一直接映射，它意味着我们在讨论方案的时候，完全可以映射到问题空间，如果是间接映射，也就意味着设计的方案后面会面临重新设计的可能性，因为它是基于场景或功能做出的归纳设计，而且是表层的设计。真正掌握了面向对象分析和设计的方法，也体会到其中的益处，对理解业务、方案设计、编码开发都有好处。</p>",
    "publish_time": "2022-12-30 12:06:04",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "国外大学生用AI写论文，还次次拿到A",
    "url": "https://www.infoq.cn/article/K9uYlvh3u6q7ag1Z8hoD",
    "summary": "<p></p><blockquote>任何新技术都具有两面性，<a href=\"https://www.infoq.cn/article/k1EU1cHr1FflCxRuATtv\">生成式 AI </a>\"也是如此。</blockquote><p></p><p></p><h2>大学生用 AI 写论文，次次拿 A</h2><p></p><p></p><p>近日，国外大学生 Urdadgirl69 在 Reddit 上发帖称，自己利用 AI 写论文、完成电影和书的观后感作业，门门功课拿到了 A。Urdadgirl69 表示，一开始，自己还有点羞愧，但很快就适应了这种形式，甚至还开始帮同学用 AI 写作业，并从中赚取了 100 美元。如今，所有人都把自己当作天才来看待。最后，Urdadgirl69 表示，这篇帖子也是 AI 帮忙润色的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/97/97b9e5df0baf83d740baa8ab12aa2aee.png\" /></p><p></p><p>这篇帖子很快在 Twitter 上火了，大家发现，像 Urdadgirl69 这类用 AI 写论文、作业的大学生不在少数。</p><p></p><p>一个网名 innovate_rye 的大一学生称，自己用 AI 完成了生物化学专业的作业，成绩很好。“我用 AI 完成了一些简单的作业。比如说生物课上，我们要学习生物技术的知识。教授让我们写文章，回答关于生物技术的五个优点和缺点。我就把关键词输入给 AI，‘关于生物技术的五件好事和坏事是什么？’AI根据这句话生成一篇文章，让我拿到 A 的成绩。”innovate_rye 表示，自己以往写这种文章，至少要花 2 个小时，但有了 AI，他只需要 20 分钟就能搞定。</p><p></p><p>与人类相比，生成式 AI 没有拖延症，只需一点提示即可快速生成内容。学生群体可以说是生成式 AI 的完美受众：他们需要频繁地写作，而且普遍熟悉互联网。对于学生群体而言，生成式 AI 的确是个“不错的选择”。</p><p></p><p>目前，市面上充斥着各种 AI 创作产品，这些产品易于使用且价格低廉。不少商家甚至通过免费试用来吸引新用户，并承诺快速提升写作质量。</p><p></p><p>其中，最受欢迎的 Jasper 平台月度订阅费用为 40 美元，可生成 35000个 单词。而 Writesonic 和 Sudowrite 等其他选项可生成 30000 个单词，价格低至每月 10 美元。随着 <a href=\"https://www.infoq.cn/article/AWWsrfb54zTvglZ0I5qS\">ChatGPT 横空出世</a>\"，现在学生们又多了一个选择。</p><p></p><h2>AI 有其局限性</h2><p></p><p></p><p>尽管 AI 生成的文本可以拥有完美的语法和句法，但内容却很难超出几个段落。这意味着，内容越长，AI 的写作连续性越差，也没有清晰的逻辑思路作为主干。</p><p></p><p>同时，AI 无法正确理解事实，生成内容中的引用、日期和思路很可能是错的。学生必须认真检查结果并纠正错误，才能让写出的文章具有说服力。</p><p></p><p>得克萨斯大学奥斯汀分校修辞与写作副教授 Scott Graham 曾要求他的学生使用 AI 撰写一篇关于校内问题的 2200 字文章。学生们可以随意对作品稍做编辑和格式调整，唯一的规则就是论文的大部分内容必须由软件自动生成。</p><p></p><p>最终的效果显示，AI 辅助创作的论文并不好，质量最高的文章也只获得了 C 和 C- 水平的成绩。要想通过 AI 写作拿到 A，学生只能能用自己的话重新整理文章内容，或者设计出更狭义、更具体的提示来引导 AI 创作有用输出。实际上，这些工作也会花费不少时间和精力。</p><p></p><p>Graham 表示 AI 技术的确能帮助人们提高写作水平，但也有其局限性：</p><p></p><p></p><blockquote>“我认为如果学生能在 AI 的帮助下更好地完成写作，那其实跟他们自己从零开始写作并没什么区别。我教给大家和想要审查的写作技能，也主要体现在初稿形成之后。我认为作家们的真正才华其实也体现在这里，体现在修订和编辑的过程中。所以我对 AI 持乐观态度，因为我觉得它能为人们提供一套框架、更好地掌握修订和编辑的诀窍。有些学生在订制初稿方面遇到了很多麻烦。如果他们把所有精力都投入到初稿的撰写当中，那么到了截止日期，他们交上来的肯定也就是这份初稿了。没机会修改、没机会编辑、没机会完善。如果能使用这些AI系统加快初稿的撰写，那肯定是种有益的助力。”</blockquote><p></p><p></p><h2>AI 辅助写作需要制定相应的政策</h2><p></p><p></p><p>将 AI 作为辅助工具和利用 AI 作弊之间的界限其实非常模糊。一些教育人士在讨论这个问题时都表现得比较开明，并不抗拒学生使用 AI 软件。</p><p></p><p>匹兹堡大学英语副教授兼系主任 Annette Vee 认为：</p><p></p><p></p><blockquote>“对我们来说，最重要的其实是 AI 正给写作方式带来哪些改变，以及我们作为教师该如何在作业中做相应调整——包括主动设计与AI协作的元素。我们的责任就是在有 AI 辅助的同时，继续考查学生们是否掌握了写作学习的一贯目标。包括学生如何构思，怎样厘清逻辑，如何清晰并有创造性地设计沟通。我认为AI系统在这些环节中都将有所帮助，最终让写作呈现出不同于以往的形式。”Vee 强调，“从本质上讲，写作就是由技术塑造而来，自然不该拒绝新的技术元素。”</blockquote><p></p><p></p><p>但也有教育人士认为，<a href=\"https://www.infoq.cn/article/0tUIRWQUjaip2MtKgpYM\">AI 辅助写作</a>\"需要制定相应的政策，需要让学生和教师明确知道，什么是可接受的、什么不可接受。比如，用 AI 自动生成邮件回复是件很正常的事情，但如果用 AI 生成的内容违反学术诚信，则不可接受。</p><p></p><p>但想用学术政策解决 AI 辅助写作问题绝非易事。如今，对于使用机器生成的语句是否构成抄袭仍没有统一意见。另外，我们也很难准确检测哪些内容是由 AI 工具所生成。就连教师们自己都震惊于 AI 不断发展的技术能力，但也有些教育工作者觉得 AI 语言模型并没有坊间传闻的那么强大。</p><p></p><p>此外，考虑到语言模型会受训练数据中暗含偏见的影响，一些教育人士还担心 AI 会影响人们批判性的独立思考习惯。罗格斯大学英文与比较文学教授 Lauren Goodlad 彼时，假设学生们全盘接受 AI 的观点，那他们最终可能会简单粗暴地将穆斯林与恐怖主义联系起来，或者满脑子都是阴谋论。</p><p></p><p>无论未来高校可能采取怎样的政策，AI 都切实给学术界带来了改善教育成效的机会。如果教师们想要主导这波潮流就必须适应技术变化，同时鼓励学生无论是否使用 AI，都时刻保持自主学习和独立思考的习惯。</p>",
    "publish_time": "2022-12-30 13:40:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "市场增速超20%，国产操作系统“浴火重生” | 解读操作系统的 2022",
    "url": "https://www.infoq.cn/article/4lDxHRoqXbSw6zl29AEo",
    "summary": "<p></p><blockquote>本文是<a href=\"https://www.infoq.cn/theme/168\">“2022 InfoQ 年度技术盘点与展望”</a>\"系列文章之一，由 InfoQ 编辑部制作呈现，重点聚焦<a href=\"https://www.infoq.cn/theme/141\">操作系统</a>\"领域在 2022 年的重要进展、动态，希望能帮助你准确把握 2022 年操作系统领域的核心发展脉络，在行业内始终保持足够的技术敏锐度。“InfoQ 年度技术盘点与展望”是 InfoQ 全年最重要的内容选题之一，将涵盖操作系统、数据库、AI、大数据、云原生、架构、大前端、编程语言、开源安全、数字化十大方向，后续将聚合延展成专题、迷你书、直播周、合集页面，在 InfoQ 媒体矩阵陆续放出，欢迎大家持续关注。特此感谢郭振宇、江大勇、刘恺、马涛、任革林、张磊、张家驹（按姓名首字母排序）对本文的贡献，他们的真知灼见，是本文能与大家见面的关键。</blockquote><p></p><p></p><p>在整个软件生态中，操作系统起到重要的承上启下作用。经过数十年的持续迭代和演进，操作系统整体发展稳健。从技术角度来看，虽然近几年并未涌现突破性成果，但不少受访专家对 InfoQ 表示，巨变正在酝酿中。当前，全球数字经济进一步发展，企业数字化转型持续深入，以及摩尔定律的失效，都为软硬件带来新的挑战，而这也是操作系统变革的重要驱动力。</p><p></p><p>回顾操作系统的 2022 年，可以发现，有些改变正在悄然发生。随着“量变”的积累，操作系统必将迎来“质变”的飞跃。</p><p></p><h2>2022 年，值得关注的大事件</h2><p></p><p></p><p>2022 年，全球操作系统市场格局稳定。看国外主流操作系统，桌面操作系统方面并未带来太多惊喜。与去年重磅发布的 Windows 11、Windows 365 相比，Windows 今年仅带来了一些小范围的更新。</p><p></p><p>移动操作系统方面，Android 13 与 iOS 16 相继登场，但也都属于常规升级。2 月 11 日，谷歌发布了首个 Android 13 开发者预览版，8 月 16 日，谷歌向 Pixel 机型推送了 Android 13 正式版更新，并正式开源；6 月 7 日，苹果正式发布 iOS 16，并推送了首个开发者预览版，9 月 13 日，苹果正式推送 iOS 16 系统更新。</p><p></p><p>服务器操作系统方面，发展稳健。5 月，红帽正式发布 RHEL 9，其基于上游内核版本 5.14，并源自 CentOS Stream；10 月，SUSE 推出业界首个自适应 Linux 平台原型（Adaptable Linux Platform，简称 ALP），旨在让用户专注于工作负载，从硬件和应用层抽离出来。</p><p></p><p>看国内操作系统，2022 年迎来了多个版本升级。3 月，OpenHarmony 3.1 正式发布；4 月，欧拉首个数字基础设施全场景长周期版本 openEuler 22.03 LTS 正式发布；7 月，华为正式发布 HarmonyOS 3 以及搭载 HarmonyOS 3 的多款新产品；8 月，OpenCloudOS 开源操作系统社区正式发布首个 Linux 源社区（L1）内核版本 OCKS 2207，这也是 OpenCloudOS 源社区项目的核心组件；11 月，龙蜥社区正式发布面向云时代打造的下一代操作系统 Anolis OS 23 公测版……</p><p></p><p>2022 年，国产操作系统市场增速显著。根据亿欧智库测算，国产操作系统通用市场增速将超过 20%，在 2024 年将达到 34.1 亿元的规模。服务器操作系统方面，数据显示，2022 年上半年，中国服务器操作系统新增装机量是 195 万套，全年预计超过 400 万，过去两年，这个数字是 322 万和 350 万。这说明在产业数字化的背景下，操作系统依然是个巨大的增量市场。</p><p></p><p>总体而言，2022 年，国产操作系统在技术、社区和商业化方面均有快速发展：技术方面，更多企业及研究机构投入到自研系统项目中，原创组件和技术如雨后春笋般涌现；社区方面，头部社区蓬勃发展，新的社区不断出现；商业化方面，OSV 都有较为明显的业绩增长。</p><p></p><p>另一个显著变化是，中国开源力量迅速崛起，国内开发者正越来越深入地参与到开源操作系统的建设中。在一份对 Linux 内核提交数量的统计中，来自中国的开发者占比不断提高，有统计的来自中国的 patch 数，连续 7 年超过美国成为第一。</p><p></p><p>操作系统作为底层基础软件，其安全性至关重要，操作系统的安全也是网络系统信息安全的基础。2022 年，全球范围内都进一步重视开源软件供应链问题，可以说，开源安全在今年迈出了一大步。</p><p></p><p>2022 年 1 月 13 日，美国白宫召集了政府和 Apache 软件基金会、Linux 基金会、开源安全基金会、GitHub、微软、谷歌、甲骨文、红帽等企业或组织共同谈论开源软件安全问题。5 月 12 日，Linux 基金会和开源安全基金会提出了一项为期两年的近 1.5 亿美元的投资计划，并提出十个开源安全目标：安全教育、风险评估、数字签名、内存安全、事件响应、更好的扫描、代码审计、数据共享、软件物料清单（SBOM）以及改进的供应链。</p><p></p><p>国内方面，10 月 24 日，开放原子开源基金会联合 27 家单位共同发起开源安全委员会，开源安全委员会致力于制定开源项目的安全流程和规范、提供开源开发的安全工具和平台、发起开源安全依赖的关键项目、推动开源安全的国际合作与交流。</p><p></p><h3>如何评价国产操作系统的 2022？</h3><p></p><p></p><p>对于国产操作系统在 2022 年的整体发展，受访专家均给出了积极评价，关键词包括机遇、加速、合力等。</p><p></p><p>操作系统作为信息技术的核心底座，具有复杂度高、投入大、生态建设难、成功率低等特点。经过二十余年的探索与实践，中国有能力在技术上实现一个大型的操作系统。同时，近几年国内操作系统市场快速增长，人才储备量提升，政策投入力度巨大，操作系统产业正迎来新机遇。在这一背景下，国产操作系统的发展也驶入快车道，从无到有，从可用到好用，国内开发者用短时间迅速完成这一转变。此外，与其他软件不同，操作系统是一个强生态的产品，这也需要操作系统厂商与硬件厂商、高校、互联网等软件厂商等各个链条通力合作，共同促进操作系统生态建设。</p><p></p><p>对于服务器操作系统，则可以用“格局尽显，稳中有进”来形容这一年。</p><p></p><p>2022 年，主流云厂商、服务器厂商、芯片厂商以及传统操作系统厂商都加大了对操作系统研发和操作系统社区的投入。随着中国在操作系统领域研发力度的持续增加，国产开源操作系统社区和商业化操作系统的产品性能都已经大幅提升，生态建设也初具规模，开始具备规模化推广能力。</p><p></p><p>“当前国产操作系统正在逐渐走向成熟好用阶段。未来 5-10 年，可能是国产操作系统的黄金时代。”受访专家表示。</p><p></p><h2>重点趋势与变化解读</h2><p></p><p></p><p>2022 年，Linux 内核最大的一个变化是新增了对 Rust 语言的支持。此外，近两年涌现出的新技术在 2022 年继续带来新的变化，如 eBPF 技术、RISC-V 架构。</p><p></p><h3>Rust for Linux</h3><p></p><p></p><p>Rust 凭借其内存安全特性，近年来受到越来越多开发者的支持，并连续 7 年被 Stack Overflow 开发者调查评为“最受欢迎的编程语言”。2022 年的调查结果显示，有 87% 的开发者表示想要继续使用 Rust。</p><p></p><p>而 Linux 内核社区长期以来都是以性能、稳定性、安全作为发展的基本要求，这与 Rust 在安全方面的特性非常契合。因此，早在几年前就有开发者呼吁在 Linux 内核中增加 Rust 语言的支持。</p><p></p><p>在 2022 年 9 月举行的 Linux Plumbers Conference 上，有一场关于 Rust 是否会出现在 Linux 中的小型会议，会议讨论了将 Rust 作为一门系统编程语言集成到 Linux 内核主线的工作。彼时，Linux 的创建者 Linus Torvalds 在接受媒体采访时表示，“如果不出意外，Rust 将会出现在 Linux 6.1 版本中”。12 月 11 日，Linus Torvalds 发布了最新的 Linux 6.1 内核稳定版，正式引入对 Rust 的支持。</p><p></p><p><a href=\"https://www.infoq.cn/article/hRUNuCGVgGwda9jpwajc\">Rust for Linux</a>\" 带来的收益明显，安全性上的收益尤为突出。</p><p></p><p>在安全性上，Window 的一份数据可以作为参考。此前，一位微软工程师曾透露，微软产品每年通过安全更新解决的所有漏洞中，<a href=\"https://www.chromium.org/Home/chromium-security/memory-safety/\">大约 70% 是内存安全问题</a>\"。因为 Windows 主要是用 C/C++ 这两种“内存不安全”的编程语言编写的。</p><p></p><p>Linux 同样如此。随着 Linux 内核代码量愈发庞大，贡献者数量迅速增长，系统安全性问题也变得越来越突出。而 Rust 设计初衷就是为了解决内存安全问题，在功能保持不变的情况下，用 Rust 语言进行重写相当于将安全性提升三倍左右。此外，Linux 内核对代码执行效率要求较高，Rust 的执行效率和 C/C++ 近乎一致，这也是其能成为底层系统编程语言的原因之一。</p><p></p><p>当前，Rust for Linux 还处于早期阶段。长期以来，Linux 内核主线代码基本都由 C/C++ 语言编写，接受 Rust 需要社区补充和完善大量的周边工作。</p><p></p><p>同时，对于内核维护者来说，Rust 进入 Linux 内核也会带来一些问题。</p><p></p><p>首先，没有银弹。虽然 Rust 语言在设计上更多地考虑了内存安全、线程安全等，但代价是比较陡峭的学习曲线，以及使用者在实现某些功能时的便利性。此外，内核是贴近硬件、最底层的程序，某些在用户态司空见惯的语言特性，比如异常的处理方式，在内核里是不一样的。对于 Rust 而言，如何在内核里更好地工作，还有很大的探索空间。</p><p></p><p>其次，计算机语言和自然语言一样，都能反映出文化。C/C++ 语言反映出来的文化和 Rust 不同，对于那些已经非常熟悉并深度认同 C/C++ 语言文化的资深 Linux 内核维护者来说，接受 Rust 的难度较高。</p><p></p><p>对于 Rust for Linux 的未来发展，多数专家都给出了积极评价：“从长远看，会有越来越多新的代码用 Rust 来实现。”</p><p></p><h3>eBPF 时代来临</h3><p></p><p></p><p><a href=\"https://www.infoq.cn/article/jyrmBFJSUVk7a1fLtQR8\">eBPF</a>\" 的全称是“扩展型伯克利封包过滤器（Extended Berkeley Packet Filter）”，最早是从 BPF (Berkeley Packet Filter) 技术扩展而来，是一种无需更改 Linux 内核代码，便能让程序在内核中运行的技术。</p><p></p><p>2014 年，eBPF 首次出现在 Linux 内核中。经过社区不断迭代，目前，eBPF 技术已经非常成熟，技术应用呈现井喷现象。虽然在设计之初 eBPF 仅为 Linux 内核服务，但近年来已经诞生了一批基于 eBPF 的项目。2021 年 5 月，微软启动了新的开源项目 eBPF for Windows，该项目旨在让开发者在现有 Windows 版本之上使用熟悉的 eBPF 工具链和应用编程接口（API）。为了更好地推动 eBPF 的发展，2021 年 8 月 12 日，Linux 基金会旗下的非营利性组织 eBPF 基金会正式成立。</p><p></p><p>2022 年，eBPF 热度不减，仍是当下最火的技术之一。eBPF 技术带来的收益明显，一方面，包括 Linux、Windows 在内的主流操作系统内核是宏内核，可拓展性较差，而 eBPF 技术能够以非侵入式的方式对内核进行扩展；另一方面，eBPF 提供了比较好的安全性、扩展性和兼容性。</p><p></p><p>不少受访专家对 InfoQ 表示，eBPF 的发展前景广阔，属于 eBPF 的时代已经来临。</p><p></p><p>“eBPF 技术的发展已经超出了我的预期。操作系统内核在没有应用 eBPF 技术以前，整个内核是静态的，编写内核时实现了什么功能，运行时也只有这些功能，最多可以做一些参数的调整，但无法带来更复杂的功能变化。应用 eBPF 技术以后，可以在 Linux 内核中运行沙盒程序，编译成相关字节码加载到内核中，无需更改内核源代码或加载内核模块。”有受访专家表示，eBPF 技术为操作系统内核提供了一个新的可能性，为内核带来根本性的改变。</p><p></p><p>对于 eBPF 的未来，<a href=\"https://ebpf.io/summit-2022/\">eBPF summit 2022 </a>\"《The future of eBPF in the Linux Kernel》给出了几个演进方向：</p><p></p><p>更完备的编程能力：当前 eBPF 的编程能力存在一些局限性（比如不支持变量边界的循环，指令数量受限等），演进目标是提供图灵完备的编程能力；更强的安全性：支持类型安全，增强运行时 Verifier，演进目标是提供媲美 Rust 的安全编程能力；更广泛的移植能力：增强 CO-RE，加强 Helper 接口可移植能力，实现跨体系、平台的移植能力；更强的可编程能力：支持访问 / 修改内核任意参数、返回值，实现更强的内核编程能力。</p><p></p><h3>拥抱 RISC-V</h3><p></p><p></p><p>近几年，RISC-V 以其开放的指令集架构受到越来越多操作系统厂商和开发者的青睐，不少操作系统开始拥抱 RISC-V，并成为一种新兴趋势。Semico Research 预测，到 2025 年，RISC-V 市场规模将超 10 亿美元。</p><p></p><p>国外包括英特尔、苹果、Tenstorrent、瑞萨电子等多个厂商都在积极布局 RISC-V。2022 年 2 月，英特尔宣布加入 RISC-V International 基金会，正式成为该基金会第 19 个高级会员，并设立了 10 亿美元的 IFS 基金，用于帮助初创和成熟企业进行代工生态的创新，其中很大一部分用于 RISC-V；9 月，半导体产业分析机构 SemiAnalysis 称，苹果正在将其嵌入式内核将全面转移到 RISC-V 架构；同月，任职于 Tenstorrent 负责 RISC-V 架构的传奇芯片设计师 Jim Keller 喊出了“未来是属于 RISC-V 的”口号。</p><p></p><p>在 2022 RISC-V 国际峰会上，RISC-V 基金会首席执行官 Calista Redmond 表示，“我们 2022 年的愿景是让 RISC-V 无处不在，随着 RISC-V 在汽车、航空航天、数据中心以及消费设备等各个领域的采用和开发，这一愿景已经真正实现”。</p><p></p><p>目前，RISC-V 国际基金会在 70 个国家 / 地区拥有超过 3180 名会员，覆盖芯片厂商、芯片设计服务公司、软件提供商等软硬件公司，以及大学、科研机构和投资机构等。市场上有超过 100 亿个 RISC-V 核心，全球有数万名工程师致力于 RISC-V 计划。</p><p></p><p>国内方面，自 2018 年成立中国 RISC-V 产业联盟以来，四年间已有 150 多家会员单位。包括华为海思、阿里平头哥、紫光展锐、兆易创新在内的多家芯片厂商基于 RISC-V 架构开发产品，越来越多的操作系统厂商和社区开始拥抱 RISC-V。2020 年 4 月，中科院软件所牵头成立了 openEuler 社区 RISC-V SIG 组。</p><p></p><p>2022 年 8 月，阿里平头哥发布首个高性能 RISC-V 芯片平台“<a href=\"https://www.infoq.cn/article/0gsHOaDExDwuWgwxYfpm\">无剑 600</a>\"”及 SoC 原型“曳影 1520”；同月，阿里云、中科院软件所 PLCT 实验室、平头哥等在龙蜥社区成立 RISC-V 架构联合小组，全面兼容并促进 RISC-V 生态发展；同月，OpenCloudOS 社区推出 OCKS 2207.2 内核版本，增加对 RISC-V 64 架构的支持；11 月，deepin 社区宣布支持曳影 1520，deepin V23 已经启动与曳影 1520 平台的适配；12 月，中科院软件所基于 openEuler 打造的傲来操作系统宣布进入 2.0 阶段，最新发布的“傲来 2.0-RV”聚焦 RISC-V 指令集，提供模拟器、硬件板卡等多种运行环境，其中硬件板卡支持中科院香山、果壳系列，支持哪吒 D1 开发板、赛昉 VisionFive 单板机、SiFive 公司 Unmatched 系列，同时也集成了澎峰科技的并行计算库。移动操作系统方面，2022 年，OpenHarmony 新增了对 3 款 RISC-V 芯片的支持，包括 TLSR9518、HPM6750IVM1 以及 BK7235。</p><p></p><p>从生态繁荣程度上来看，RISC-V 生态正处于增长关键期。当前，RISC-V 的生态建设有很多基础性工作需要做，比如硬件需要更加成熟和规范，软件（主要是在内核层面）需要与硬件配合得更好，以及功能更加完善，这些都需要内核开发者们合作完成。“我们的经验就是 Upstream First，即任何工作都首先贡献到上游社区，与所有的生态合作伙伴一起，完善这个生态。”受访专家总结道。</p><p></p><h2>展望操作系统的 2023</h2><p></p><p></p><h3>值得关注的技术趋势 / 方向</h3><p></p><p></p><p>2023 年，操作系统领域值得关注的技术趋势 / 方向除了 Rust for Linux、eBPF、RISC-V 的发展，还有云原生、异构计算、安全以及 AI 等。</p><p></p><h4>移动</h4><p></p><p>&nbsp;</p><p>移动操作系统历经十余年发展，已经十分成熟。随着全球进入移动互联网时代，移动操作系统的市场份额稳定。数据显示，截至 2022 年 10 月，全球操作系统市场中 Android、iOS 的市场份额占比分别为 42.37%、17.60%。</p><p>&nbsp;</p><p>与此同时，国内以鸿蒙为代表的移动操作系统市场突飙猛进。2022 年，在 HarmonyOS 发布的第四个年头，其自研核心代码量已突破 2000 万行，搭载的设备量也正式达到 3.2 亿台，相比去年同期增长 113%。</p><p>&nbsp;</p><p>有受访专家表示，当前国产移动操作系统还处于准备期，离带动整个产业发展还有一定的距离，但“雪球正在越滚越大”，距离成熟期并不遥远。“到 2024 年，国产移动操作系统的市场规模远超百亿级”，受访专家预判道。</p><p></p><h4>云原生</h4><p></p><p></p><p>操作系统是连接应用和硬件的桥梁，它的发展和 IT 基础设施密切相关。当前，随着云的不断普及以及云原生的不断演化，云会逐渐成为企业 IT 形态的主流，企业数字基础设施将基于云来重建，并迎来跨越式发展。</p><p></p><p>与此同时，全面基于云、并面向云做设计研发的操作系统将成为主流。目前，国内外各大操作系统厂商和云厂商都在积极为这一跨越式发展做准备。2022 年，操作系统 + 云协同趋势越来越明显。微软借助其基于云计算的操作系统 Azure，不断增加公共云的市场份额；红帽除了企业 Linux（RHEL），也在云平台 OpenShift 上投入重兵；SUSE 也发布了专为边缘环境中的容器化工作负载量身打造的轻量级操作系统 SLE Micro 5.2。</p><p></p><p>有受访专家预判，“未来 IT 基础设施属于云，而未来的操作系统也属于云上操作系统”。</p><p></p><h4>异构计算</h4><p></p><p></p><p>异构计算是近年来计算机领域出现的热门方向之一，主要是指使用不同类型指令集和体系架构的计算单元组成系统的计算方式。与传统的通用计算芯片相比，异构架构具有高性能、低功耗等显著优点。</p><p></p><p>2021 年，以 DPU 以及各种各样 XPU 为代表的异构计算异军突起，英伟达、英特尔先后发布了 DPU、IPU。2022 年，英特尔披露了 XPU 概念的下一步规划——新架构 Falcon Shores，它能将 x86 CPU 和 Xe GPU 硬件合并到同一颗芯片中。据路线图所示，Falcon Shores 计划于 2024 年完成。2022 年，全球首台原生 RISC-V 笔记本电脑 ROMA 正式发布，并首次运行无剑 600 高性能异构芯片曳影 1520。</p><p></p><p>有受访专家表示：“在 2023 年，可能会涌现出更多的异构计算设备，操作系统要想更好地支持这些计算设备，需要解决很多技术难题，比如如何在不同的平台上运行软件。”</p><p></p><h4>安全</h4><p></p><p></p><p>随着操作系统代码数量逐渐增加，以及支持的硬件日益广泛，安全性问题不容忽视。一方面，操作系统向下支持硬件，硬件上的某些安全缺陷可能需要在软件层面进行修复；另一方面，操作系统本身具有海量的代码，一些新特性或新的执行机制出现，也会给安全带来一些新的挑战。</p><p></p><p>此外，开源安全也是 2023 年值得关注的方向之一（编者注：后续我们也将发布针对开源安全的盘点与展望文章，敬请期待）。随着越来越多的开源软件在千行百业中得到广泛应用，安全问题日益凸显，供应链安全攻击和容器安全威胁问题日益严峻。如何构建安全可信的操作系统，是每个参与者需要长期思考的问题。</p><p></p><h4>AI</h4><p></p><p></p><p>近几年，AI 技术在操作系统领域诞生了诸多应用。比如，openEuler 社区曾发布一款名为 A-Tune 的操作系统性能调优引擎，能够利用 AI 技术，对运行在操作系统上的业务建立精准模型，动态感知业务特征并推理出具体应用，根据业务负载情况动态调节并给出最佳的参数配置组合，从而使业务处于最佳运行状态。</p><p></p><p>除了调优工具，预计在 2023 年，操作系统领域结合 AI 技术还会带来更多惊喜，比如人机交互。</p><p></p><p>每一次人机交互方式的变化都会导致整个产业的跨越式发展或颠覆式发展。相应地，操作系统也需要做出改变，否则无法支撑新形态下的应用程序。在 2023 年，一旦 AR（增强现实）、VR（虚拟现实）、MR（混合现实）技术取得长足发展，那么，操作系统必然也会迎来跨越式的发展。</p><p></p><h3>如何做好操作系统生态建设？</h3><p></p><p></p><p>生态是操作系统发展的核心，也是其能否成功的关键。与国外主流操作系统相比，国产操作系统由于起步较晚，在生态建设方面仍面临一定的挑战。</p><p></p><p>随着开源发展理念逐渐成熟，越来越多的厂商开始发起成立操作系统开源社区，进一步加快操作系统生态建设。从 2019 年开始，国内先后成立了 openEuler、OpenAnolis、OpenCloudOS 等社区。2022 年，统信、麒麟分别成了桌面操作系统根社区深度（deepin）社区、openKylin 社区。</p><p></p><p>“现在是操作系统社区的春秋战国时代”，受访专家表示，随着操作系统赛道持续火热，越来越多的企业参与其中，建设自己的开源社区。在社区发展的早期阶段，一定会遇到各种各样的问题，但如果产品优秀，围绕这个产品可以吸引足够多的企业 / 开发者参与进来，并具备一定的创新能力，始终保持开放和中立的态度，经过时间的演化，最终会向成熟社区迈进。“做开源社区应该多做实事、少务虚”，受访专家总结道。</p><p></p><p>那么，2023 年，如何才能更好地打造操作系统开源社区？</p><p></p><p>首先，有情有利，方能长久。社区需要进一步鼓励合作伙伴在社区探索出更多的合作模式，聚焦在产品和商业合作本身，真正牵引企业在社区落地。开源不是公益，找准自身商业价值点才能有可持续发展，基于此，操作系统生态才能在开源社区的沃土上成气候。</p><p></p><p>其次，生态是圈，双向奔赴。操作系统是一项门槛比较高的技术，专业人才、技术储备、研发资源都比较有限。围绕客户业务场景，操作系统产业生态圈上的操作系统、芯片、整机、数据库、中间件、以及应用软件厂商需要互帮互助，双向奔赴，让有限资源充分流通，最终拉高国内操作系统产业天花板。</p><p></p><p>最后，放弃小我，成就大我。当前国内操作系统开源社区的局面需要百花齐放，要开展竞争、建立一个完全商业的竞争环境，大家可以在一个小生态里各自产生创新，但最终还是要汇聚在一处。如果没有一个统一的生态、社区或是标准去做，可能就会出现“七国八制”的现象，不仅浪费资源，还影响效率。</p><p></p><h2>写在最后</h2><p></p><p></p><p>有研究机构预测，到 2024 年，国产操作系统有 7 倍的增长空间，到达百亿级的市场规模。可以说，这是国产操作系统最好的时代，机遇远远大于挑战。</p><p></p><p>对于操作系统领域的开发者而言，除了要持续提升自身的研发能力，还要具备创新能力与安全意识，始终对技术保持好奇心，并积极拥抱开源。</p><p></p><p>采访嘉宾介绍（按姓名首字母排序）</p><p></p><p>郭振宇，OpenCloudOS 社区 TOC 主席；</p><p>江大勇，openEuler 委员会主席；</p><p>刘恺，SUSE Euler 负责人；</p><p>马涛，龙蜥社区理事长；</p><p>任革林，OpenHarmony 项目管理委员会首席架构专家；</p><p>张磊，统信软件高级副总经理、CTO；</p><p>张家驹，红帽首席架构师。</p><p></p><p>如果你对本文感兴趣，欢迎在文末留言，或加入 <a href=\"https://xie.infoq.cn/\">InfoQ 写作平台话题讨论</a>\"。后续，迷你书、专题将集合发布于 InfoQ 官网，登录<a href=\"https://www.infoq.cn/\">InfoQ 官网</a>\"注册并将 InfoQ 添加进收藏夹，精彩不错过。更多内容可<a href=\"https://www.infoq.cn/theme/168\">点击查看系列专题文章</a>\"。</p><p></p><p>同时，InfoQ 年度展望直播周将于 2023 年 1 月 3 日首场开播，并持续输出精彩内容，关注 InfoQ 视频号，与行业技术大牛连麦~</p>",
    "publish_time": "2022-12-30 14:18:18",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AI 推理加速原理解析与工程实践分享",
    "url": "https://www.infoq.cn/article/uoUvykdfrWfG3rgJFN7G",
    "summary": "<p>本文整理自同名线上分享，是 12 月份<a href=\"https://www.infoq.cn/video/mPJzSMJ53meqBkFT2Nku\">「百度百舸 - 云原生 AI」技术公开课的第三期</a>\"。</p><p></p><p>这次分享将端到端分析 AI 推理过程以及痛点，介绍业界典型的推理加速思路和具体方案，并介绍百度智能云在这方面的一些实践成果。</p><p></p><p>本次分享我们将介绍如何加速 AI 推理过程。内容主要包括四部分：</p><p>第一部分，端到端的分析 AI 推理的过程以及这个过程中的痛点；</p><p>第二部分，我们将介绍业界典型的推理加速思路及具体方案；</p><p>第三部分，介绍百度百舸平台的 AI 推理加速套件 AIAK-Inference 的加速方案；</p><p>最后一部分，我们则将通过 demo 的方式，演示 AIAK-Inference 的使用方式及加速效果。</p><p></p><h2>AI 推理的痛点</h2><p></p><p></p><p>AI 推理是将用户输入的数据，通过训练好的模型产生有价值信息的过程。具体的是将训练好的 AI 模型部署到提供算力的硬件上，并通过 HTTP/RPC 等接口对外提供服务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2e/2e3564d1ba7485b80b5f73780eb7d281.jpeg\" /></p><p></p><p>这个过程的参与者主要有 2 类人，一类是 AI 算法工程师，他们希望能将自己研发的模型高效的部署到线上，并为模型最终的效果负责。另外一类人则是基础架构工程师，他们负责管理异构算力集群，并为集群的资源利用效率负责。这两类人群的痛点分别如下：</p><p></p><p>对 AI 算法工程师来说，他们希望自己训练的复杂模型可以更快的提供服务。而对于基础架构工程师来说，他们则希望可以将价格昂贵的 GPU 资源发挥出最好的效能。这两类问题都需要解决。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d1/d102e1e9bc45ad63c0545db0af9fb2da.jpeg\" /></p><p></p><p>如果我们从端到端的视角再来分析下整个 AI 推理过程，会发现这两类用户的痛点目前没有得到很好的解决。</p><p></p><p>用户对 GPU 的使用初始于业务系统，用户根据业务需求搭建模型，并为最终模型的效果负责。</p><p></p><p>业务系统构建完成后，会从资源管理系统中申请资源，而资源管理器则会将 GPU 卡分配给业务系统，这个管理器只会为资源分配率负责，而不会关心资源分配后的业务使用效率。</p><p></p><p>用户在申请到资源后，会通过 AI 框架执行模型的计算过程。AI 框架更专注为用户提供易用的模型构建接口，而不会为业务的推理效率和资源利用率负责。</p><p></p><p>最后 AI 框架在使用异构硬件算力时，只能使用基础的加速包或工具，而不会专门结合业务特点进行优化。总的来看，整个过程中没有专门的工具为 GPU 算力的利用效率负责。</p><p></p><p>为此，我们需要 AI 推理加速，针对用户训练好的模型，进行针对性的加速，缩短业务推理时间，同时提升资源利用率。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/82/82b7d891ca8b047b7e73b79b4473ee39.jpeg\" /></p><p></p><h2>推理加速的业界解决方案</h2><p></p><p></p><p>为了系统性的分析和进行推理加速方案，我们首先需要能够定义推理加速的优化目标。为此我们先简单回顾下 GPU 的硬件架构和执行模式。</p><p></p><p>从硬件上看，GPU 的强大算力来源于多 SM 处理器，每个 SM 中包含多个 ALU 计算单元和专有的 Tensor Core 处理单元。对 GPU 来说，当所有 SM 上的所有计算单元都在进行计算时，我们认为其算力得到了充分的发挥。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c1/c13b140d71c7ed9742c60b212afb4c52.jpeg\" /></p><p></p><p>GPU 无法自己独立工作，其工作任务还是由 CPU 进行触发的。</p><p></p><p>整体的工作流程可以看做是 CPU 将需要执行的计算任务异步的交给 GPU，GPU 拿到任务后，会将 Kernel 调度到相应的 SM 上，而 SM 内部的线程则会按照任务的描述进行执行。当 CPU 不发起新的任务时，则 GPU 的处理单元就处在空闲状态。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f5/f57b02d07fb8571422cc650005c91147.jpeg\" /></p><p></p><p>通过这两个层面的分析，我们知道要想将 GPU 的算力充分发挥，其核心就是保持 GPU 上有任务，同时对单个 GPU 计算任务，使其可以尽量充分的用好 SM 处理器。</p><p></p><p>针对这两个层面的使用情况，NVIDIA 提供了相应的牵引指标 GPU 利用率和 SM 利用率：GPU 利用率被定义为在采样间隔内，GPU 上有任务在执行的时间。而 SM 利用率则被定义为在采样间隔内，每个 SM 有 warp 活跃时间的平均值。</p><p></p><p>我们可以通过 2 个 case 来比较下这两个指标的差异。在下图的 case 1 中，由于 CPU 异步发射任务到 GPU 上，GPU 很快就处理完了，于是就出现了等待下一个任务的空隙。在这种情况下，按照定义，GPU 利用率比较低，SM 利用率也相对较低。两个指标都能反应这种情况没有充分利用 GPU 资源。</p><p></p><p>针对下图的第二个 case，对于某一个 Kernel 来说，由于计算实现、参数配置等一系列问题，它只使用了 1 个 SM 处理器，而剩下的 3 个 SM 处理器（假设只有 4 个 SM 处理器）空闲。</p><p></p><p>对于这种情况，由于 GPU 上有 Kernel 在执行，在这个时间段内 GPU 利用率仍然是 100%，但 SM 利用率只有 25%。可以看到这种场景下，SM 利用率可以反应计算任务效率不高的问题，而 GPU 利用率则无法反应此类问题。</p><p></p><p>因此我们认为 SM 利用率可以更精细的反应 GPU 算力发挥情况。因此我们把 SM 利用率当做 AI 推理加速的牵引指标。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/75/7561288cfe0bd03d48bb450ce73859c4.jpeg\" /></p><p></p><p>有了牵引指标，结合模型执行的流程，我们就可以在逻辑上将优化方案分为三类：</p><p></p><p>第一类优化是模型精简类，即在模型真正执行之前就对模型的计算量进行精简，从而提升推理速度。这部分业界常见的优化方向包括量化、减枝、蒸馏和 NAS 等；</p><p></p><p>第二类和第三类则是当模型已经交由推理引擎在 GPU 上执行时，如何更好的提升 GPU 的利用效率。</p><p>我们由 SM 利用率公式做一个近似可以导出这两类优化方案，分别是尽可能让 GPU 上有计算任务和单个计算任务在 GPU 上执行效率更高。这两类优化方案常见的手段分别是算子融合和单算子优化。</p><p></p><p>接下来分别介绍这三类优化方案。</p><p></p><p>在模型精简上，通常大家会采用量化、减枝和蒸馏等手段。</p><p></p><p>简单来说，量化就是将模型中的计算类型进行压缩，从而降低计算量。常见的手段包括离线量化和量化训练两类。</p><p></p><p>离线量化是指在模型训练完成后，离线的对计算算子进行量化，这种方案通常易用性较好，对算法开发人员几乎透明，但对模型精度会有一定损失；量化训练则是在模型训练过程中就显示插入量化相关的操作，这样通常会有更好的精度，但需要算法开发同学准备相关数据。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/33/3351fa8bdc8afba51e5643efb934b9d7.jpeg\" /></p><p></p><p>而减枝则是通过将模型中对结果影响较小的一些计算进行移除，从而降低计算量。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5f/5fd192f95b134cae3ee96ce2d3118fa3.jpeg\" /></p><p></p><p>蒸馏则通常是将一个复杂的大模型通过降维的知识传递层，将大模型中的复杂计算，减少为效果相当的更小规模的计算，从而实现降低计算量，提升推理效率的效果。下图中是百度文心 3.0 大模型知识蒸馏的过程。</p><p></p><p>这些模型精简的方案，由于涉及到对精度的影响，通常需要算法工程师介入，协同优化。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/15/15aa8a72e330a33a96d82cda64f63bc0.jpeg\" /></p><p></p><p>第二类优化则是算子融合，算子融合顾名思义是指将多个计算算子合并成一个大算子的过程。</p><p></p><p>例如对于 BERT Base 这个模型，经过 PyTorch 原生 jit 编译生成的 TorchScript 图中有 800 多个小算子，这些小算子会带来 2 类问题：一是这些算子通常执行过程较短，因此会造成大量的 GPU 空闲时间；二是由于不同的任务之间还有数据的依赖，因此也会带来额外的访存开销。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/68/684f59258b615a0856c5d865c46c4ef8.jpeg\" /></p><p></p><p>目前针对算子融合，业界通常会采用手写或自动化生成的方式发现可融合的模式，并提供融合后的算子。例如针对 Transformer 结构，NVIDIA 开发了 FasterTransformer 这个库，其中包括针对多种 Transformer 类结构模型的具体融合算子。</p><p></p><p>例如下图中，针对 batch GEMM Q x K、Softmax、batch GEMM for QK x V 和长尾的 transpose 等操作，FasterTransformer 提供 Fused Multi-head Attention 等融合后算子。BERT Base 在经过 FasterTransformer 的算子融合优化后，数量可以降到 100 个左右。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f3/f3f0bf2db5cdc77879b84e4b84d5511a.jpeg\" /></p><p></p><p>第三类优化则是单算子优化。单算子优化是根据单个算子，结合计算模式和硬件架构特点，调整 GPU 核函数的实现方法，从而提升具体算子的执行效率。单算子优化中，最经典的例子就是对通用矩阵乘（GEMM）的优化。下图是 NVIDIA Cutlass 库对 GEMM 操作的抽象：</p><p></p><p>Cutlass 结合 GPU Global Memory、Shared Memory、Register File 这几层存储架构和 block、warp、thread 和 tensor core 这几层计算抽象，设计了一系列计算模板，并提供相关可优化参数（切分大小等），方便开发者开发高性能的 GEMM 实现。</p><p></p><p>以上就是业界常见的几类 AI 推理加速的方法和业界的一些解决方案。接下来我们重点介绍下 AIAK-Inference 是如何站在巨人的肩膀上，提供性能更好的推理加速方案。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/38/38c624892767ba412db1de07d782d324.jpeg\" /></p><p></p><h2>AIAK-Inference 推理加速套件简介</h2><p></p><p></p><p>AIAK-Inference 是百度智能云提出的 AI 推理加速套件，是百度百舸整体方案中的一部分。</p><p></p><p>AIAK-Inference 旨在优化在百度智能云上采购的 GPU 等异构算力的推理效率，降低推理延迟，提升推理吞吐。只要通过百度百舸方案提供的 GPU 算力，都可以使用 AIAK-Inference 进行推理加速。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e2/e25845f7229189132154286c9889cb73.jpeg\" /></p><p></p><p>AIAK-Inference 的整体架构如下图所示，整体分为 4 个层次，分别解决的问题如下：</p><p></p><p>图接入：解决多框架动态图 / 静态图捕获问题，将动态图转换为推理友好的静态图；后端抽象：支持将业界多种优化方案统一整合，通过计时的方式选择最优的加速后端；具体加速后端，支持业界多种开源加速后端，包括飞桨提供的 FastDeploy 等；此外还有一套自研加速后端，通过图优化、图转换和加速运行时三部分对模型进行整体的推理加速；算子库：除了使能业界最优的常见计算算子库，还针对具体场景的重点计算模式进行定制化开发，提供场景加速的算子库。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fb/fb232d40c8cf62492b5b20d6b1700180.jpeg\" /></p><p></p><p>与业界其他方案相比，AIAK-Inference 主要有 2 大特点，第一个是博采众长，支持多种优化后端的无缝接入，并通过计时选优的方法将效果最后的加速后端提供给用户；第二则是深入场景，针对重点场景的计算模式，通过 AIAK-OP 算子库进行专有加速。</p><p></p><p>AIAK-Inference 的加速原理也类似第二节讨论的业界常见方案，主要从图精简、算子融合、算子优化几个层面展开</p><p></p><p>在图精简上，AIAK-Inference 除了兼容社区常见的量化、减枝、蒸馏、NAS 等方案，还提供一些数学等价代换、死代码移除等精度无算的图精简操作；在算子融合上，AIAK-Inference 支持访存密集型算子融合、GEMM/Conv 长尾运算融合和背靠背 GEMM 融合等多种融合策略；而针对具体的单个算子，AIAK-Inference 则通过调度、访存、模板化优化等思路，实现了一系列高性能场景化算子。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f1/f1f62fbf33614bfe78ee94e67c886e22.jpeg\" /></p><p></p><p>具体举几个例子，对于单算子优化，我们通过 ncu 工具发现我们生成的 Conv 算子执行时有 20% 的访存指令浪费，通过将访存操作聚合，减少访存操作，最终模型端到端性能提升 3%。</p><p></p><p>算子融合上，我们针对 NLP、CV 场景开发了相应的重点融合算子（如 FMHA、YoloBox 等），并在通用场景针对卷积 + 长尾操作生成了一系列融合算子。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0d/0dd1f7c546f43ccc2e8ca87c4b8e57e1.jpeg\" /></p><p></p><p>除了这些之外，我们还紧跟社区生态，正在开发适配 PyTorch 2.0 编译生态的 Dynamo 编译 Backend；在算子生成方面，我们也开发了一套针对模板的自动化算子生成方案。</p><p></p><p>以上就是 AIAK-Inference 推理加速套件的整体介绍，我们接下来看看如何在百度智能云上使用推理加速套件。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c1/c1a8adf972d30a4cce1b33f5de1f6418.jpeg\" /></p><p></p><h2>使用 AIAK-Inference 推理加速套件</h2><p></p><p></p><p>首先整体介绍下 AIAK-Inference 推理加速套件在 AI 推理流程中的位置。</p><p></p><p>如下图所示，AIAK-Inference 是通过优化推理模型进行推理加速的。具体的说，算法工程师原来进行模型部署，是将 TorchScript/SavedModel 等训练好的模型通过 Inference Server 进行部署。</p><p></p><p>而 AIAK-Inference 则是在部署之前增加一个流程，通过开发一个核心只有 1 行代码的优化脚本，通过 aiak_inference.compile 优化接口，对 TorchScript/SavedModel 等模型进行优化，并返回优化后的模型。</p><p></p><p>用户可以将优化后的模型仍然部署到 Inference Server 上，部署无感的进行加速。总结下来就是优化代码离线化改造，业务部署零代码侵入。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/54/541035df006d3357da091af2b385dc9f.jpeg\" /></p><p></p><p>了解了整体使用方式后，我们来具体操作一下。首先为了使用 AIAK-Inference 推理加速套件，需要进行环境准备。AIAK-Inference 提供加速镜像和 wheel 包两种安装方法，无论哪种方案，用户只需要下载对应的镜像或安装 wheel 包，即可完成环境准备。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2c/2cdfe257b49d1bcbbc41aa80cd1930e5.jpeg\" /></p><p></p><p>环境准备完成后，只需要开发刚才演示的一个优化脚本，即可完成模型的优化。接下来以 ResNet50 模型为例，进行一个完整流程的演示。<a href=\"https://mp.weixin.qq.com/s?__biz=MzkxOTM4MTM3Ng==&amp;mid=2247485287&amp;idx=1&amp;sn=7d5590d3dbe8db42c04d69ba236c5130&amp;chksm=c1a3b388f6d43a9e91295cf56e341b25e9346cd776f8643a92895d0b968102e4a04f4e583d4c&amp;mpshare=1&amp;scene=21&amp;srcid=1227LMLwEyyIyQgiobNb2DbS&amp;sharer_sharetime=1672194336895&amp;sharer_shareid=8b44a188e33576dfd4362591e2688c4a&amp;key=eb16c4aa1548428c7e240c5eef4fdc7f9ac2c4b2b377f36a7f93a6f2f5ae31a0e3a088379c46c94235b1f3e7c1030e3a5d2225c53617220319fd61cdb93ab1bce0e1b06882e8be73d9864adab295bf2ba564e95f7568fc1cc9d33aa89c3954b051917966cd8f0257218348eec245db32b73530dd3007c9f6d42b182debf50967&amp;ascene=1&amp;uin=Mjg0MDUwODQxNA==&amp;devicetype=iMac%20MacBookAir10,1%20OSX%20OSX%2012.6%20build(21G115)&amp;version=13050510&amp;nettype=WIFI&amp;lang=zh_CN&amp;fontScale=100&amp;exportkey=n_ChQIAhIQZQdYJU2b/uzeFyJxcSu4JxKVAgIE97dBBAEAAAAAAKR4EDDq6S0AAAAOpnltbLcz9gKNyK89dVj0D7%20UeTQxq0whR3JtLNnXaa62gY0STDVLYC1g1ILzdP9TTmQ4YaLwF6228yU6qQJ1jhtK8s4oaYx4JXDS7qyJ1rsvm1q3fqHT3zmRYymkFqAl1vIABYjsXcz3a4QxaUumI5oDJfgYzd2ETCzmqrrBY0ObdjoYi6J3IaRd2lnic%20fJSeZbYXZY15WElqk8D64yq05F8Pb1KZzYDptVD4kp7097JrKBUfxR%20nOHj%20bivZbHNhAFiDow3nZLTT2h/DiB6Yyb3e5tdNblH2k1HMwBQmd4d8K8OuhMFdXldeu6SvkQBRw85e7aoaxMR3TF36c=&amp;acctmode=0&amp;pass_ticket=vevJ0S%20czrFsMV9nSKwAg1Z5rSGNvAwf/0lxaDJ52U6riVfEgqsZBReLBuCXuHdvwpMb4wB0ecywUSjb3T//8A==&amp;wx_header=0#wechat_redirect\">AIAK Inference 操作演示视频</a>\"</p><p></p><p>本次演示中使用了 2 个脚本，分别是 infer.py 和 optimize.py。其中 infer.py 是模拟用户部署的脚本，简单看下代码可以看到，这个脚本主要是加载模型，进行 100 次预热操作，然后执行 1000 次推理，并在 CPU 侧完成计时。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ca/ca2a9705ecfeb6f4311746218a614381.png\" /></p><p></p><p>简单执行这个脚本，可以看到 FP32 精度下，BS=1 的 ResNet50 在 T4 平台上，推理平均延迟是 6.73ms。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/03/033941f8e16fb2c746689e2e8105d467.png\" /></p><p></p><p>接下来使用 AIAK-Inference 对模型进行优化。这里我们使用 optimize.py 脚本，其代码如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5b/5bcaf9ee0845541c33ded21962262ad7.png\" /></p><p></p><p>整体代码非常简单，加载模型，调用 aiak_inference.optimize 接口进行优化，并将优化后的模型进行保存。这里为了演示我将优化后的模型保存成与优化前模型同名的模型。</p><p></p><p>有了优化后的模型，我们什么都不做改动，再次执行 infer.py（即模拟业务部署代码零改动），可以看到模型推理耗时大幅降低，只需要 3.54ms。</p><p></p><p>从而可以看出使用 AIAK-Inference 可以通过简单的脚本对模型进行透明优化，优化后的模型在推理效率上有大幅提升。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f5/f5b0e6263ec751b98490d8eff3198a3f.png\" /></p><p></p><p>除了刚才演示的单个模型，AIAK-Inference 还在多个模型上验证了效果。下表是 6 个典型 CV 类模型，可以看到推理延迟分别降低 40%~90%。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3a/3afc71d4472d02318a88459e7834daf0.jpeg\" /></p><p></p><p>以上就是今天分享的全部内容，谢谢大家。</p>",
    "publish_time": "2022-12-30 15:16:16",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Gartner 数据库魔力象限解读 | DBTalk 技术公开课第6期",
    "url": "https://www.infoq.cn/article/YS4byz52CheyAgfYSxy4",
    "summary": "<p>随着数字化进程的加快，数据越来越成为数字时代的基础性战略资源和革命性关键要素。作为数据存储与计算的基础软件，数据库对于筑牢数字经济底座至关重要。</p>\n<p>如今，数据库支撑着经济社会活动的关键核心业务，几乎所有的应用软件都需要基于数据库进行存储、管理和分析。近年来，随着国产自研数据库的不断创新，其在安全、稳定、高效性方面的优势持续凸显，市场占有率也在扩大。近日，腾讯云数据库进入Gartner数据库魔力象限，在 OLTP（TDSQL/TDSQL-C）及轻量级 TP 能力（KeeWiDB）得分均为国内第一。</p>\n<p>腾讯云数据库为何能够入选 Gartner 全球数据库魔力象限？多项数据库核心能力（critical capability）得分国内第一的秘密是什么？本次技术公开课，将回望腾讯云数据库自研之路的挑战和突破，挖掘自研数据库在存储、数据访问等方面的技术创新与实践。</p>",
    "publish_time": "2022-12-30 17:34:15",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "TDSQL 在 TP 领域的技术探索和实践 | DBTalk 技术公开课第6期",
    "url": "https://www.infoq.cn/article/idUjJYN3E5bj9pjByqRB",
    "summary": "<p>经过近 20 年的研发和应用实践，腾讯分布式数据库 TDSQL 已被越来越多客户所采用，<br />\n在分布式、高可用、稳定、性能等方面持续突破，支撑金融、政务、电信、游戏、互联网等各个领域进行数字化改造，尤其是在核心交易场景方面得到了非常广泛的应用。<br />\n本次分享重点介绍这 2 年 TDSQL 在 TP 领域的一些技术突破，以及如何通过这些技术帮助我们的客户顺利完成从传统集中式架构到分布式数据库的转型。</p>",
    "publish_time": "2022-12-30 17:34:18",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "KeeWiDB 轻 TP 技术实践 | DBTalk 技术公开课第6期",
    "url": "https://www.infoq.cn/article/DkqXdvIXScvkZwfG599y",
    "summary": "<p>KeewiDB 作为一个兼容 Redis 协议的 NOSQL 数据库，除了兼容社区 Redis 行为外，作为存储数据库，有必要实现 Redis 不具备的 TP 能力，从而更好的符合用户对存储数据库的诉求, 同时作为 Nosql 数据库还需要提供高性能的TP。本次分享介绍 KeewiDB 在 TP 实现的一些思考和实践。</p>",
    "publish_time": "2022-12-30 17:34:25",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "新一代云原生 TDSQL-C 关键技术突破 | DBTalk 技术公开课第6期",
    "url": "https://www.infoq.cn/article/HswNYNTZkJvBHSeSJ3l0",
    "summary": "<p>云应用程序的这些需求为云原生数据库提供了新的机会，而传统的企业内部数据库系统无法完全满足这些需求。腾讯云原生数据库经过多年的研发和打磨，所实现的计算、内存与存储资源的解耦的“日志即数据库”架构、HTAP、Serverless 等特性已是全球首创或业内领先的技术，同时其性能对比传统云数据库达到数倍的大幅度提升。</p>\n<p>本次分享将围绕着腾讯云原生数据库在架构演进、软硬结合探索、自研内核优化等方面的核心技术解析。结合海量数据存储、高频交易场景、流量洪峰/不可预估场景、开发测试等周期性峰值业务场景的行业案例，深入解析新一代云原生数据库 TDSQL-C 的产品特性、技术亮点以及未来的发展趋势。</p>",
    "publish_time": "2022-12-30 17:34:29",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]