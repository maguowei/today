[
  {
    "title": "亚马逊云科技向Well-Architected Framework添加容器透镜",
    "url": "https://www.infoq.cn/article/O9jijEFIBtaaeecQCe8K",
    "summary": "<p>亚马逊云科技在其<a href=\"https://aws.amazon.com/architecture/well-architected\">Well-Architected框架</a>\"添加了一个<a href=\"https://aws.amazon.com/blogs/containers/introducing-the-container-build-lens-for-the-aws-well-architected-framework/\">新的容器透镜</a>\"。这份新的技术白皮书概述了来自社区、亚马逊云科技合作伙伴和其内部容器技术专家的最佳实践。这些最佳实践为运行高性能、可靠和安全的容器工作负载提供了指导。白皮书中还提供了一些常见用例的参考架构。</p><p>&nbsp;</p><p>AWS Well-Architected框架以六大支柱为基础——卓越的运营、安全性、可靠性、性能效率、成本优化和可持续性。它为AWS用户提供了特定的信息，帮助他们采用AWS的最佳构建实践。新的<a href=\"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/container-build-lens.html\">容器透镜</a>\"加入了其他特定于领域的透镜，如物联网、无服务器、AI、ML和SAP。</p><p>&nbsp;</p><p><a href=\"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/operational-excellence.html\">运营卓越支柱</a>\"专注于系统的运行和监控，交付业务价值，提供洞见，推动持续改进。容器透镜关注的是容器生命周期管理和可观察性。例如，在准备阶段的建议包括确保了解容器的基本镜像是由什么组成的。这与最近对<a href=\"https://www.infoq.com/news/2022/10/google-devops-2022\">供应链安全性</a>\"的关注和更好地了解应用程序中使用的组件是保持一致的。</p><p>&nbsp;</p><p>这一支柱的其他建议还包括建立父镜像或烘焙镜像，然后用于创建所有下游的镜像。这种方法可以更好地控制和治理被包含在基础镜像中的内容。他们建议在构建了下游镜像后，将其用在所有的环境中。随着通过每个阶段的验证，不断在各种环境中推广使用。</p><p>&nbsp;</p><p><a href=\"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/security-pillar.html\">安全性支柱</a>\"的建议包括关注容器应用程序的最小特权，实现所有构建基础设施的访问控制，以及最小化镜像的攻击表面。他们建议在没有shell或包管理器的情况下运行distroless镜像，防止不良行为者随意修改镜像。最近，谷歌<a href=\"https://www.infoq.com/news/2022/10/distroless-slsa-level-two/\">宣布</a>\"他们的distroless构建达到了<a href=\"https://slsa.dev/\">软件工件供应链级别</a>\"（Supply chain Levels for Software Artifacts，SLSA）2级。类似地，Chainguard发布了<a href=\"https://www.infoq.com/news/2022/09/wolfi-supply-chain/\">Wolfi</a>\"技术预览版，在设计上提供了最小化的攻击表面。</p><p>&nbsp;</p><p><a href=\"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/performance-efficiency-pillar.html\">性能效率支柱</a>\"的建议主要关注容器的构建时性能。他们指出，运行时性能超出了容器透镜的范畴，应该包含在<a href=\"https://docs.aws.amazon.com/wellarchitected/latest/performance-efficiency-pillar/welcome.html\">性能效率支柱白皮书</a>\"中。</p><p>&nbsp;</p><p><a href=\"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/reliability-pillar.html\">可靠性支柱</a>\"主要关注监控应用程序的运行状况、构建和测试镜像的自动化以及对父容器镜像的自动化更新。这个支柱以使用基础父镜像的建议为基础，建议使用分层的方式来管理容器镜像。这应该从通用共享的基础镜像开始，然后安装特定于应用程序的工件，并在最后一层安装应用程序所需的二进制文件。</p><p>&nbsp;</p><p>他们进一步建议，所有这些镜像都要在源码控制系统中进行维护和标记。他们建议使用“持续集成过程，在源码控制系统中的容器镜像和镜像标签之间创建直接关联”。根据白皮书的说法，这种方法有助于确定在不同的镜像发布之间发生了什么变化。</p><p>&nbsp;</p><p><a href=\"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/cost-optimization-pillar.html\">成本优化支柱</a>\"主要关注镜像的效率、自动伸缩和快速启动时间。这三个建议将有助于减少所需的容器数量和运行时间。<a href=\"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/sustainability-pillar.html\">可持续性支柱</a>\"提出的建议与成本优化支柱类似。</p><p>&nbsp;</p><p>最后，白皮书提供了许多用于解决常见用例的参考架构，例如，关于如何确保容器构建管道安全的架构。他们指出，这个架构应该与运行任意类型管道相关的安全实践一起实现。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2f/2f8330c5bb34729443eb86f53cfcd7b1.png\" /></p><p></p><p>安全容器化构建管道的参考架构（来源：<a href=\"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/securing-containerized-build-pipelines.html\">亚马逊云科技</a>\"）</p><p>&nbsp;</p><p><a href=\"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/container-build-lens.html\">容器透镜</a>\"现在可以在Well-Architected Framework文档中找到。Well-Architected Framework 的部分内容在<a href=\"https://aws.amazon.com/well-architected-tool/\">Well-Architected Tool</a>\"中可用，但容器透镜只提供了技术白皮书。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/11/container-well-architected/\">https://www.infoq.com/news/2022/11/container-well-architected/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/37KXc62o0QMozP8Y22Os\">亚马逊云科技开源Event Ruler</a>\"</p><p><a href=\"https://www.infoq.cn/article/69cDiK84CkeW7CEZXg9j\">Stack Overflow 2022报告：亚马逊云科技的软件开发“武器库”</a>\"</p>",
    "publish_time": "2022-11-09 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "开发人员必须知道的 Web3基本工具和技术",
    "url": "https://www.infoq.cn/article/AazZuDOCh0oSR27pbBNw",
    "summary": "<p>Web 3开发人员缺口很大，相对来说，目前只有一少部分开发人员成为该领域的专家。因此，如果一位成熟的Web 2工程师，想要进入Web 3行业，应该从哪里开始呢？要了解哪些基本概念、学习哪些工具和技术？</p><p>&nbsp;</p><p>本文将探讨Web 3，包括它的重要性以及与Web 2的区别。然后再来看看，有志于Web 3开发人员应该熟悉的技术栈。</p><p></p><h1>Web3 第一课</h1><p></p><p>在深入研究Web 3应用程序中使用的技术之前，让我们首先了解<a href=\"https://www.infoq.cn/video/9XgAQ2GxwUVgMKZBpi0j\">Web 3</a>\"是什么，以及它为什么重要。</p><p>&nbsp;</p><p>Web 3的五个关键特性是去中心化、区块链、安全性、可扩展性和隐私。在Web 3的去中心化世界中，区块链技术和其他协议从根本上改变了数据的存储、分发和访问方式，同时提供了一个本地事务层。当下流行的<a href=\"https://www.infoq.cn/article/a7ls8rH7EoAweEdLcNfO\">Web3应用案例</a>\"是去中心化金融（DeFi 和加密货币）、在称为“DAO”的去中心化治理模式中投票、以及作为所有权证明的不可伪造代币（NFT）。</p><p>&nbsp;</p><p>Web 3背后的许多动机，都是基于用户、公司和政府之间的信任受到侵蚀。看上去好像有点愤世嫉俗，但确是如此。</p><p>&nbsp;</p><p>在去中心化金融里，用户将资金存储在自己的私人钱包中，交易时无需与中心化机构互动或依赖国家的法定货币。</p><p>&nbsp;</p><p>建立在区块链上的投票应用程序，所有投票数据都是透明的，且任何人验证起来都很简便，因此不必再担心选举中发生徇私舞弊。这就是让 Web 3 “无需信人”的原因：该技术是透明的，并且通过密码学得到保护，因此不再是只能盲目信任某些机构。</p><p>&nbsp;</p><p>NFT 可用于证明任何数字资产（如音乐或艺术）的所有权，让你可以更直接地支持创作者。</p><p>&nbsp;</p><p>所有这些例子，其核心都牵涉到不再需要依赖中央机构或中介机构。</p><p>&nbsp;</p><p>需要注意的是，Web 3 并不是要取代 Web 2，就像 Web 2 没有取代 Web 1 一样。对于 Web 1 中出现的静态网站，在 Web 上仍然占有重要地位。即使 Web 3 越来越受欢迎和使用，Web 2 应用程序也将有一席之地。</p><p>&nbsp;</p><p></p><h1>去中心化的应用程序（Dapps）</h1><p></p><p>我们现在大致了解了<a href=\"https://www.infoq.cn/article/jsf43rxkftgecP5aQCNG\">什么是 Web 3</a>\"，以及为什么去中心化的概念很重要。那么Web3应用程序实际上是什么样子的呢？</p><p>&nbsp;</p><p>嗯……它们看起来很像 Web 2 应用程序！<a href=\"https://www.infoq.cn/article/6tiOQEV3UHCLAMGDXPXH\">去中心化的应用程序</a>\"，也称为“dapps”（或“dApps”），由一个前端 UI 组成，其与部署在区块链上的“智能合约”（一个小代码程序）交互。在交易或将数据写入区块链时，前端还可以与用户的钱包交互。与 Web 2 应用程序的主要区别在于，智能合约和区块链取代了由单个人或公司拥有和维护的经典的服务器和数据库。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bd/bdf139b8d62ec581970b55da99a0240d.png\" /></p><p></p><p>&nbsp;</p><p>去中心化应用架构</p><p>&nbsp;</p><p></p><h1>定义 Web 3 技术栈的技术</h1><p></p><p>&nbsp;</p><p>那么，如何真正构建一个去中心化的应用程序（dapp）？好消息是，可以从已有的编程技能和经验开始！我们已经知道 dapp 有一个前端，这意味着需要了解 HTML、CSS 和 <a href=\"https://www.infoq.cn/article/CSRgKxyZK0XNK9ZARYEp\">JavaScript</a>\"。可能还会使用Angular、React或Vue等框架或库，除非你喜欢用原生JavaScript。这对于已经精通这些技术的前端开发人员来说是个好消息。</p><p>&nbsp;</p><p>现在，让我们看看需要专门为Web3学习哪些语言、工具和框架：</p><p>&nbsp;</p><p><a href=\"https://soliditylang.org/\">Solidity</a>\"&nbsp;是一种编程语言，用于编写在以太坊区块链上运行的智能合约。它看起来像是 C++、Python和JavaScript的混合体。如果你现在已经学习了几种编程语言，那么你每次去学一门新语言都会变得更容易。由于大多数智能合约都涉及某种货币兑换，因此遵循<a href=\"https://docs.openzeppelin.com/\">适当的标准</a>\"和<a href=\"https://consensys.net/blog/developers/solidity-best-practices-for-smart-contract-security/\">在安全方面的最佳实践</a>\"至关重要。</p><p>&nbsp;</p><p>Solidity项目地址：https://soliditylang.org/</p><p>&nbsp;</p><p><a href=\"https://trufflesuite.com/docs/truffle/\">Truffle</a>\"是一个框架，可以用来编写、测试和部署智能合约。 其网站将其描述为“使用以太坊虚拟机 (EVM) 的区块链开发环境、测试框架和资产管道”。就像React 帮助你构建JavaScript应用程序一样，Truffle 帮助你构建智能合约。使用 Truffle 并不是绝对必要的，但是这个框架将极大地帮助你，因为它抽象了一些开发复杂性。对于 VS Code 用户，<a href=\"https://trufflesuite.com/blog/build-on-web3-with-truffle-vs-code-extension/\">Truffle for VS Code</a>\" 扩展会让开发周期更加容易。</p><p>&nbsp;</p><p><a href=\"https://trufflesuite.com/docs/truffle/\">Truffle</a>\"项目地址：https://trufflesuite.com/docs/truffle/</p><p>&nbsp;</p><p>Ganache是用于本地开发和测试智能合约的个人区块链。开发人员只需要通过几个简单的命令，就可以创建以太坊区块链的本地实例。Ganache 允许你在本地开发 Web 3应用，就像在本地或测试环境而非生产环境中开发 Web 2 应用程序一样。</p><p>&nbsp;</p><p><a href=\"https://trufflesuite.com/docs/ganache/\">Ganache</a>\"项目地址：https://trufflesuite.com/docs/ganache/</p><p>&nbsp;</p><p><a href=\"https://web3js.readthedocs.io/\">Web3.js</a>\" 是一个用于与以太坊交互的 JavaScript 库。你将在前端应用程序中使用 web3.js 来执行诸如连接到用户的钱包、授予对智能合约的访问权限以及调用智能合约上的函数等操作。智能合约可以通过命令行或UI访问，因此 web3.js 可以帮助你从 UI 使用智能合约。</p><p>&nbsp;</p><p>Web3.js 项目地址：https://web3js.readthedocs.io/en/v1.8.0/</p><p>&nbsp;</p><p>MetaMask 是一个 Web 3 钱包，你可以使用它的浏览器扩展程序或移动应用程序。我们之前提到过钱包，但还没有真正描述过钱包是什么。钱包为你的数字资产提供接口。你使用只有你自己知道的私钥保护钱包里的内容。 MetaMask 为用户提供了一种安全的方式，连接到基于区块链的应用程序，并与它们的钱包交互。对于开发人员来说，需要钱包来部署智能合约并与之交互。通常，私钥必须写在代码中才能交互，但 <a href=\"https://trufflesuite.com/blog/introducing-truffle-dashboard/\">Truffle Dashboard</a>\"能够将MetaMask钱包连接到项目而无需暴露密钥。</p><p>&nbsp;</p><p>MetaMask项目地址：<a href=\"https://metamask.io/\">https://metamask.io/</a>\"</p><p>&nbsp;</p><p><a href=\"https://infura.io/\">Infura</a>\"是连接以太坊和其他区块链以及去中心化存储网络（如 IPFS）的基础设施提供商。无需过多介绍，与区块链的任何交互都需要通过 JSON-RPC或WebSockets 访问节点。 Infura 提供了基础设施，因此你不必找机器来启动自己的节点。如果你实在想运行自己的节点，Infura 也可以作为备用。 Infura 还提供了一个开发套件和工具包，包括监控、指标、日志记录、事务管理和其他用于构建 dapp 的功能。这是对我们已谈论过的其他一些技术的进一步抽象，可以使 Web3 开发更加容易。</p><p>&nbsp;</p><p><a href=\"https://infura.io/\">Infura</a>\"项目地址：<a href=\"https://infura.io/zh\">https://infura.io/zh</a>\"</p><p></p><h1>结论</h1><p></p><p>Web 3 是支持下一代软件的下一代互联网。区块链是更透明的技术，不但消费者在采用，<a href=\"https://consensys.net/reports/web3-report-q3-2021/\">主要机构也在采用</a>\"，这让区块链成为了主流。</p><p>&nbsp;</p><p>了解Web 3 技术以及构建方法，将为你打入市场提供优势。</p><p>&nbsp;</p><p>对于已经拥有强大的Web 2基础，又有志于Web3的开发人员，我希望现在你对自己充满信心，因为你已掌握的知识就是良好的开端！花一些时间学学上面的技术，你可能会比你想象的更快做好准备，以迎接Web3的到来。</p><p>&nbsp;</p><p>原文链接：</p><p></p><p><a href=\"https://dzone.com/articles/the-essential-web3-tools-and-technologies-develope\">https://dzone.com/articles/the-essential-web3-tools-and-technologies-develope</a>\"</p>",
    "publish_time": "2022-11-09 11:43:10",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "高性能时序数据库引擎的技术实践 | DBTalk 技术公开课第4期",
    "url": "https://www.infoq.cn/article/uwaPEhX7fNM34wwmhUfd",
    "summary": "<p>随着万物互联时代的到来，时序数据处理成为释放数据价值，提升业务能力的关键。YMatrix 面向时序设计，同时兼顾分析速度。最近发布的 YMatrix 5.0 推出了全自研的时序存储引擎、向量化和全套的编码压缩，在性能方面得到了长足的进步。本次分享会全面解析性能优化技术。</p>",
    "publish_time": "2022-11-09 12:11:03",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "只有时代的 Oracle, 没有 Oracle 的时代 - 看国产数据库如何突出重围 | DBTalk 技术公开课第4期",
    "url": "https://www.infoq.cn/article/yjDlwOakrRVI9SuLkhCV",
    "summary": "<p>在国产化浪潮下，自主可控重要性凸显，去 IOE 已经逐步在政务、金融等垂直行业场景落地。其中，“去 O”也成为了众多企业及数据库从业者最关切的话题之一。</p>\n<p>腾讯云数据库 TDSQL 在过去多年里助力金融， 保险等多个行业上的核心系统成功去“O”。 本次的分享会将详解 TDSQL 如何在以内核兼容为基础，打造从驱动、迁移、内核三个层面的 Oracle 兼容能力， 帮助客户平滑迁移 Oracle 数据库。分享将涵盖 TDSQL 在内核、工具、接口等方面的全方位的兼容性工作。</p>",
    "publish_time": "2022-11-09 12:11:09",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "得物数据库中间件平台“彩虹桥”架构演进及落地实践 | DBTalk 技术公开课第4期",
    "url": "https://www.infoq.cn/article/vO8sd9j6Oslq9AA0amyz",
    "summary": "<p>ShardingSphere 是 Apache 社区一款优秀的开源分布式数据库生态项目，得物在 ShardingSphere 基础上，根据自身业务属性和特点，定制了一套数据库代理中间件“彩虹桥”。本次议题主要介绍“彩虹桥”的架构演进和落地实践。</p>",
    "publish_time": "2022-11-09 12:11:14",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何搭建技术人才岗位能力模型",
    "url": "https://www.infoq.cn/article/3TyHa7LfBwz6hqbJMHJU",
    "summary": "<p></p><blockquote>2022年&nbsp;10&nbsp;月&nbsp;26&nbsp;日，由极客时间企业版主办的“数字人才蓄能季高端论坛——夯实人才底座，掌控数字化未来机遇”成功举办。多位来自数字化领军企业的技术管理专家和人才发展专家进行了精彩的分享，在线交流了企业数字化战略下的组织发展和数字人才培养实践等相关话题，让参会观众收获颇丰。极客邦科技内容总监李佳带来《如何搭建技术人才岗位能力模型》的主题分享，以下为演讲实录：</blockquote><p></p><p></p><p>大家好，今天我为大家带来的主题分享是《如何搭建技术人才岗位能力模型》。在上一个环节中，我们的&nbsp;COO&nbsp;司巧蕾女士为大家介绍了极客时间企业版在数字人才培养路径的最佳实践之一，即“研、测、学、考、评”闭环式培养体系。接下来，我将主要聚焦在数字人才培养的第一步“研”的部分，与大家探讨岗位能力模型是什么？岗位能力模型有哪些应用？以技术人才为例，如何搭建岗位能力模型？等相关话题。</p><p></p><h1>岗位能力模型是什么？</h1><p></p><p></p><p>近些年，关于人才培养的方式有很多，按照大分类可以分为，人才培养、经验沉淀、培养路径三类内容。具体来说，在人才培养的分类下，包含岗位说明书、岗位人才画像、岗位能力模型、胜任力模型、岗位任职资格标准等，这些内容的本质是为企业人才招聘和发展提供指导；在经验沉淀的分类下，包含技能图谱、知识图谱、知识脑图、知识萃取、知识管理等，这些内容通常来源于业界专家、行业领先或企业团队内部的优秀标杆的经验积累，企业员工通过自发性的学习来获取解决问题的能力。最后是培养路径，包含学习地图、学习路径图、学习管理等，其本质是企业人才培养越来越趋于专业化，强调分层次、分阶段的培养方法。值得强调的是，学习路径要以岗位能力模型与技能图谱作为支撑才能更好地落地。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1a/1a5e0e4d20d882ef8e29f863d355dfef.png\" /></p><p>（岗位能力模型示意图）戳此领取<a href=\"https://app.jingsocial.com/microFrontend/leadGeneration/jsf-leads/list/contentMarketing/6iw9HawUN2U8qJfu8JGKMk/AowTuypHBoWL6soUsGJXZ8\">数字人才岗位能力模型</a>\"</p><p><img src=\"https://static001.infoq.cn/resource/image/7f/d3/7f79475e5a3724717yyf5e940be611d3.png\" /></p><p>（技能图谱示意图）戳此领取&gt;&gt;&gt;&nbsp;<a href=\"https://app.jingsocial.com/microFrontend/leadGeneration/jsf-leads/list/contentMarketing/bERJWeW9ub3Dx9ZTCMndSR/nMAdwwPh7ZKZJv7ZczdzkZ\">24张技术岗位技能图谱</a>\"</p><p><img src=\"https://static001.geekbang.org/infoq/67/675de5a147af12d7e245edf92ccf0605.png\" /></p><p>（学习路径示意图）</p><p></p><p></p><h1>企业设计岗位能力模型的底层逻辑</h1><p></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/89/a7/896f0b3a5fc53e041490488cb3e38ba7.png\" /></p><p></p><p>学习知识有两种形式，非功利性学习与目的性学习，对于企业人才培养往往是后者。所以回归到岗位能力模型设计这件事，一定是先从整个公司的战略开始的，这也是岗位能力模型设计的关键。比如当下数字化转型的需求或业务目标等，带着战略目标去思考设置什么样的组织能力或组织架构，进而匹配相应的岗位职责及岗位任务，从岗位任务中分析行为形成具体的行为项，再由此去寻找支撑行为项的知识体系。所以，当我们拿到一份技能图谱往往并不能直接使用，其原因就在于每个公司、团队或组织的战略目标是不一样的，岗位能力模型需要聚焦到关键目标上。</p><p></p><h1>岗位能力模型有哪些应用？</h1><p></p><p></p><p>岗位能力模型不仅应用于企业的人才培养，在“招、用、育、留”的各个环节都有着关键作用。</p><p></p><h2>一、招聘人才</h2><p></p><p>对于&nbsp;HR&nbsp;来说，如何在招聘平台发布既能符合公司业务目标，又能吸引候选人的岗位&nbsp;JD&nbsp;是一件痛苦的事情。通常情况下，我们会从公司过往发布的信息或者其他公司发布的岗位&nbsp;JD&nbsp;做修改，但是这样的岗位&nbsp;JD&nbsp;准确吗？事实上，随着业务发展目标的调整，同一个岗位对于职责、任务的要求与相应的能力模型也要发生动态变化。因此，我们发现当企业有一套完整的能力模型，在描述岗位&nbsp;JD&nbsp;时会更加敏捷、准确，同时能够非常精准匹配企业人才目标。</p><p></p><h2>二、识别、选拔人才</h2><p></p><p>岗位能力模型在识别、选拔人才方面的贡献也极其明显。当企业需要突破现有组织架构，快速组建敏捷团队时，岗位能力模型能够帮助企业准确定位合适的人员，快速跨越从&nbsp;A&nbsp;业务到&nbsp;B&nbsp;业务之间的鸿沟，助力实现业绩目标完成。</p><p></p><h2>三、晋升、绩效考核管理</h2><p></p><p>与传统绩效管理不同，应用岗位能力模型能够对管理能力、专业能力及通用能力进行全方位的评测，通过对员工能力的考核，引导员工培养企业发展所需的核心专长与技能，从而保证企业的长效发展。</p><p></p><h2>四、培养人才</h2><p></p><p>企业正值数字化转型、业务快速迭代的节点上，利用岗位能力模型可以实现三个培养方式：岗位驱动，即按照岗位能力模型对不同阶段的员工提供进阶分层式培训，提升岗位胜任力；问题驱动，又称项目驱动/场景驱动，强调岗位能力模型匹配公司业务战略动态调整，通过培养解决具体业务问题的能力，突破业务增长瓶颈；效率驱动，与&nbsp;1v1&nbsp;导师制不同，强调以岗位能力模型为指导，对同一能力要求内的人才进行统一培训，提升培训效率。</p><p></p><h1>以技术人才为例，如何构建岗位能力模型？</h1><p></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/1b/5d/1b939eba3c5e19e325e4ffda695fa05d.png\" /></p><p></p><p>在开始分享具体步骤前需要与大家强调的是，岗位能力模型需要与战略目标对齐，始终以赋能业务发展为目的形成结果闭环。</p><p></p><p>接下来，我以极客邦科技的架构师岗位为例，为大家拆解岗位能力模型构建流程：</p><p>第一步&nbsp;岗位梳理与分析：从战略目标出发，极客邦科技的愿景是成为全球卓越的数字人才发展平台，所以要求架构师的岗位职责包含有构建技术团队影响力，对外推广技术品牌的能力。对应其任务可以是以极客邦技术品牌为主题出品课程、书籍或演讲等不限形式的内容。</p><p>第二步&nbsp;任职资格标准设计：任务指导资格，比如，由极客邦架构师出品的新课《高并发项目实战》，主讲老师首先具备较为完整的架构师知识框架，其次熟练掌握高并发的单点技能；另外在制作课程中还需要完成调研、打磨、录制等行为。</p><p>第三步&nbsp;从知识表征到知识体系：用知识体系支撑行为，除了结构化的知识框架，课程定位理论与实战相结合，这就要求架构师还应在日常工作中积累实战案例。</p><p>第四步&nbsp;知识检验，形成图谱：知识检验的方法有很多，在架构师的例子中知识检验体现在项目复盘，比如是否将知识点形成视频、文章、演讲等多种形式的内容。</p><p></p><h1>如何为企业交付定制化的岗位能力模型？</h1><p></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/22/40/22bd312316b5865d31a33de01bde4d40.png\" /></p><p></p><p>资料收集阶段作为项目启动的第一步，会将企业信息（如企业3-5&nbsp;年的战略规划、岗位&nbsp;JD等&nbsp;）与外部专家资料结合进入调研，再根据调研结果构建能力词典。</p><p></p><p>在访谈/建模阶段会有两个关键步骤，一是确认访谈提纲是否围绕企业战略目标；二是确认访谈对象，是否以业务导向为抓手包含相关业务负责人。</p><p></p><p>在模型优化到定稿过程中，评审是极为重要的环节。一般来说评审分为技术团队评审、业务团队评审及外部专家评审。重视外部评审，也是提升看天花板的能力，通过外部视角的输入建立对标方向，提升岗位的弹性能力；此外还可以通过外部视角观察行业趋势，为未来发展作准备。</p><p></p><p>最后的交付阶段核心目标是通过可视化呈现让岗位能力模型更加高效的利用起来。事实上我们也沉淀了很多的最佳实践，一种是比较常见技能图谱，目前我们已经有&nbsp;24&nbsp;个技术岗位的通用技能图谱，欢迎大家可以下载领取&gt;&gt;&gt;&nbsp;<a href=\"https://app.jingsocial.com/microFrontend/leadGeneration/jsf-leads/list/contentMarketing/bERJWeW9ub3Dx9ZTCMndSR/nMAdwwPh7ZKZJv7ZczdzkZ\">24张技术岗位技能图谱</a>\"；另外在与企业交付过程中还有很多的创新实践，比如有些团队会把岗位能力模型或技能图谱做成一套桌游卡牌或者线上游戏，通过游戏运营的方式把这个内容传递下来；或者制作一些实用性较强的办公室用品，比如，笔记本，便签纸等等。总体上来说，岗位能力模型与技能图谱的传播与游戏化运营都是在内容的基础上上做加法，团队可以根据实际情况进行定制。</p><p></p><p>在服务企业客户的过程中，我们发现越来越多的企业能够通过岗位能力模型与“研、测、学、考、评”的融合，高效提升团队人员能力，最终回馈到业务目标形成培训闭环。</p><p></p><p></p><h1>总结</h1><p></p><p></p><p>企业人才培养本质上是处理“人与事”的关系，我们的公司、组织之所以存在一定是有使命、目标和场景，为了完成这个场景需要成员与组织不断地协同演化，从变化中找到突破，最终实现业务目标。</p><p></p><p>以上是本次分享的全部内容，谢谢大家。</p><p></p><p>扫码观看论坛完整视频</p><p><img src=\"https://static001.infoq.cn/resource/image/ac/63/ac64a05c4e1d5a681eb6cfcea907ca63.jpeg\" /></p><p></p>",
    "publish_time": "2022-11-09 14:07:16",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "全面发展数字生态的第一步：解决开发者的问题，共建数字生态",
    "url": "https://www.infoq.cn/article/absyH0TSbOjZGChkUz3w",
    "summary": "<p>近年来，云计算、大数据、人工智能等一系列前沿技术的飞跃式发展，加快了企业数字化转型的进程，目前企业数字化转型已进入深水区。然而，随着前沿技术与产业的融合，企业不断涌现出海量数据高并发等业务需求，企业开发低效、前沿技术开发门槛高、数据治理难等问题陆续显现，这也为企业实现降本增效的大目标提出了巨大挑战。所以，如果企业想要快速且成功地完成数字化转型，就必须要先解决技术开发能力的问题，这意味着企业要通过一切方式释放数字生产力，解决开发者的问题。</p><p></p><p>在 11 月 9 日召开的华为全联接大会 2022——“共建数智生态”主题演讲上，华为云全球生态部总裁康宁发表“共创新价值，一切皆服务”主题演讲。期间，华为云针对 AI 开发高门槛、数据治理难、开发亟需提效等问题发布的四大创新服务（ModelBox AI 开发套件、AutoETL 工具、智能编程助手 CodeArts Snap 和华为云 API 中心）的解决方案值得我们所有人参考。</p><p></p><p></p><h2>一、ModelArts 提供全新场景化 AI 资产，全方位降低 AI 开发门槛</h2><p></p><p></p><p>随着第四次工业革命的来临，人工智能已经从科幻逐步走入现实，如今，高效高精度仿真预测、构建数字孪生工厂、全息 3D 裸眼效果的数字工厂、永不塌房的品牌数字人……这些奇思妙想，都在借助人工智能技术实现。可以说，AI 应用正在使能千行百业，新一代人工智能正在成为推动科技跨越发展、产业优化升级、生产力整体跃升的驱动力量。</p><p></p><p>当我们究其根本，人工智能技术的快速发展离不开其核心算法的突破、计算能力的提高以及海量数据的支撑，而这背后，企业开发者都开始面临着相同的难题——人工智能技术开发复杂、成本高，想要追上该技术应用的发展，要源源不断地投入人力与物力，尤其对中小企业的长线业务发展来说，是一个很大的挑战。</p><p></p><p>于是，为了让 AI 开发变得简单，华为云推出了 AI 开发生产线 ModelArts，实现从数据标注、数据处理、模型训练到推理部署等环节的全流程自动化处理，大幅度提升开发效率。</p><p></p><p>有了 AI 开发平台的加持并不意味着开发者的编程工作可以一劳永逸。为了让 AI 落地更简单，华为云 ModelArts 深入到亟需 AI 赋能的各个行业，学习并集成行业智慧，发布 9 个行业 Usecase，包括出行调度、销量预测、生产排程、货架识别、工业质检、游戏 AI 等，覆盖生产、销售、服务、运营四大场景，推动项目的平均交付时间从月级降到天级。与此同时，华为云 ModelArts 提供了完善的模型资产平台，我们可以看到，如今的华为云 AI Gallery 上已沉淀了 5 万多个 AI 商业用例和资产，供开发者学习、分享和实践。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/07/2c/0788a1de8c79757dbabfd7ed1c95742c.png\" /></p><p>图：AI 货架识别</p><p></p><p>为了能够帮助开发者解决端云协同问题，ModelArts 的 ModelBox 框架屏蔽了底层软硬件的差异，实现了 AI 应用一次开发，全场景部署，将跨平台开发适配周期缩短 80%，推理性能提升 2-10 倍。</p><p></p><p>会上，华为云全球生态部总裁康宁介绍了 ModelArts 带给开发者的新装备——ModelBox AI 开发套件。其集成了硬件开发板、平台工具软件和最佳实践案例，让开发者快速掌握 AI 应用开发和部署流程。除了开发板，该开发套件还适配了 PC、边缘计算盒子等硬件平台，大大降低开发者上手门槛，缩短 AI 应用开发周期。</p><p></p><p></p><h2>二、AutoETL 工具通过零代码为数智融合添砖加瓦</h2><p></p><p></p><p>根据 Gartner 的报告， 约 90% 的企业战略将在 2022 年之前将信息视为一项关键的企业资产。这里的“信息”，指的其实就是数据。由此可见，“数据是新的石油”的概念不仅仅是一句空话。</p><p></p><p>数据虽然好用，但是企业的数据治理却不是一个简单问题。从数据到支撑业务的资产，传统数据库、数仓建模等技术无法满足企业全业务流程分析和决策需求，导致企业难以利用好这些异构数据，而治理好的数据也难以和应用有效融合，像数据湖、数据仓等的海量数据架构更是难以管理。</p><p></p><p>除此之外，当前企业传统的数据治理往往用时较长，中间环节较多。以业务变化为例, 首先要做业务需求变化确认，再进行代码开发，紧接着做开发后的联调，然后是功能测试、系统部署、停机发布，这一整套流程下来，时间周期长、执行效率也很低。而且对于很多企业来说，技术团队本身就缺乏大数据相关开发者，研发效率低，维护成本高。企业高成本数据治理问题亟待解决。</p><p></p><p>为了解决企业高效完成数据治理的矛盾点，华为云推出了数据治理生产线 DataArts，可以帮助企业的数据源进行数据接入、数据开发、数据治理、数据资产、数据服务、数据安全、数据共享，像生产线一样把海量复杂的无序数据转化成高质量的数据能源输送给业务，从而帮助业务侧高效决策。</p><p></p><p>目前<a href=\"https://www.infoq.cn/article/tXgNFT5odgXvBeMs76oX\">华为云</a>\"数据治理生产线 DataArts 主要包含 DataArts LakeFormation 与 DataArts Studio 两大部分。其中 DataArts LakeFormation 负责整合所有云原生数据湖的组建工作，统一管理一系列数据引擎的源数据，方便上层开发者使用。而 DataArts Studio 则是一个从数据集成到开发、治理、服务一站式端到端的平台，涵盖数据生产、处理、使用的全流程生命周期，帮助开发者高效系统地管理和使用数据。</p><p></p><p>从架构层面看，DataArts 不仅支持 OLAP 数据仓库及大数据分析平台，还支持 OLTP 事务性数据库。DataArts 具备丰富的集成工具，支持将结构化、半结构化、非结构化的数据，既可以实时数据同步入湖，也支持高效的批量数据集成。</p><p></p><p>康宁表示，今年 DataArts 在数据准备、数据质量和数据安全这三个方面都做了迭代升级，进一步提升自动化和智能化能力。比如在数据准备方面，华为云新推出的 AutoETL 工具，能通过无代码模式，简单的编排和拖拉拽就可以生成一个处理流水线，使数据湖开发任务节点数量降低 20%，数据作业开发效率由天级降到分钟级。</p><p></p><p>据了解，DataArts 还能够实现数据的自动化标准和质量稽核，同时拥有全链路安全管理能力，保护好用户隐私数据的同时还能对数据进行合规性审计，帮助企业沉淀数据资产，实现智能数据治理，从而释放数据价值。</p><p></p><p></p><h2>三、CodeArts Snap 智能编程助手和 API 中心帮助开发者大幅提效</h2><p></p><p></p><p>纵观所有企业技术开发团队的生产日常，重复造轮子是开发者最大的“痛”，也是企业在成本控制方面最头疼的问题。目前解决该矛盾，企业常用的方式譬如有低代码平台、一站式应用开发工具等。</p><p></p><p>然而市面上的这些平台龙鱼混杂，各有各的技术短板，比如使用门槛高、前端界面布局具有局限性、不能实现过于复杂化的应用逻辑、系统维护成本高及数据安全性问题等，无法彻底地解决掉企业生产力和开发者的问题，而这其中最大的问题是企业采买成本与平台成熟性之间的矛盾，所以选择一个合适的敏捷型开发工具是企业减少重复造轮子的第一步。</p><p></p><p>在帮助企业实现敏捷开发、降本增效方向，华为云持续投入、不断探索，其发布的华为云 CodeArts Snap 智能编程助手就是另外一件帮助开发者敏捷开发的利器，让每位开发者都能拥有一个“开发助理”。该工具能将自然语言转化为编程语言，高效提升开发者编码效率和质量。CodeArts Snap 不仅能根据中英文描述生成完整的函数级代码，而且可以替代重复且繁琐的单元测试代码编写过程，批量生成高可读性和高覆盖率的单元测试用例，还能提供代码的自动检查和修复，其检查准确率达到业界领先水平。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/1d/49/1d600e25ee76b12b5e7ccba4b0d29e49.gif\" /></p><p></p><p>除了 CodeArts Snap 智能编程助手，<a href=\"https://www.infoq.cn/article/FgogdjehRCRt9QjD4fMG\">华为云</a>\"丰富的 API 也是解决开发者重复造轮子得心应手的工具。本次会上，华为云全新发布华为云 API 中心，目前正在加速使能行业创新，其汇聚超过了 6 万个优质的 API，覆盖制造、政府、交通、物流、金融、零售、教育等多个行业。并引入华为内外部的 API 工具、低代码平台、集成工作台等相关服务，能够让开发者快速联接华为云云服务和 API 接口，帮助开发者快速实现应用的创新。</p><p></p><p>国家管网就基于华为云低代码平台实现软件应用创新，打造安全作业管理平台，从而深入推进了企业自身的数字化转型进程。</p><p></p><p></p><h2>四、围绕“释放数字生产力”做开发者生态扶持是基本盘</h2><p></p><p></p><p>如今许多厂商在构建了众多的基础能力后都会开始进行平台化、生态化的布局，将自身的底层能力作为基础设施开放出来，赋能更多的企业和开发者，而开发者是生态中的重要一部分。</p><p></p><p>开发者利用厂商提供的基础设施、开发工具、核心技术和商业生态创造出更多的商业价值，而反过来，厂商只有深刻了解开发者的需求，才能更好地运营好自己产品的开发者生态。无论是进行生态搭建与布道、技术赋能、商业孵化，还是通过产品使用体验提升等手段运营，都离不开开发者的核心需求——释放数字生产力。</p><p></p><p>我们从康宁的演讲中，可以清晰地看到华为云在释放数字生产力方面做出了许多举措。</p><p></p><p>在体验方面，华为云从“文档与教程”、“代码与工具”、“社区、技术支持”三个维度，打造“3C”开发者体验，帮助开发者快速解决在开发过程中遇到的具体问题，让开发者更聚焦于开发本身。像华为云学堂，对内，这是一个华为云员工、华为云伙伴及开发者自我提升的学习平台；对外，华为云则将华为人才培养经验沉淀为 aPaaS 服务，在教、学、练、考、评等教学阶段通过开放华为的课程生产线、认证体系、低代码实验做课平台等能力，为企业人才培养提质增效。</p><p></p><p>在多元生态协同方面，<a href=\"https://www.infoq.cn/news/uvF7Zg57t6RGoyRj9Dvu\">华为云</a>\"充分发挥华为产业组合优势，协同鲲鹏、昇腾、HMS/ 鸿蒙及 MDC 等生态，以云为底座打造丰富多元的生态能力，实现多种开发技术无缝协同，激发开发者的无限创新。</p><p></p><p>此外，今年“松山湖开发者村”正式揭牌，依托华为云、鸿蒙等技术，“松山湖开发者村”将联接企业，推动数字技术与东莞产业深度融合，打造成为一个聚天下英才的开发者基地。这也是华为在人才投入方面做出的又一大举措。</p><p></p><p>从开发者体验到多元生态协同，华为云做出了不少努力，“帮企业和开发者释放数字生产力，帮企业打造数字化坚实底座”不是说说而已，他们真的付出了许多时间去实践探索。正如华为云全球生态部总裁康宁在演讲中所说的，“万千开发者是华为云生态的中流砥柱，让开发者成为决定性力量是华为云生态的首要目标。华为云将持续创新，在技术、平台、体验、多元生态协同等方面全面赋能开发者。”</p><p></p><p>目前，华为云生态已聚合了全球超过 350 万的开发者，相比去年同期增长 1.3 倍；汇聚 41000 多家合作伙伴，相比去年增长 1.4 倍。相信在未来，将有越来越多的开发者和伙伴愿意选择加入华为云。</p><p></p><p></p><p>了解更多信息可以登录：https://developer.huaweicloud.com/tool.html</p>",
    "publish_time": "2022-11-09 14:53:50",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "查询性能显著提升，Apache Doris 向量化版本在小米A/B实验场景的调优实践",
    "url": "https://www.infoq.cn/article/xwijC1Afv3CN5zNj2sDi",
    "summary": "<p></p><blockquote>导读： 长期以来，Apache Doris在小米集团都有着广泛的应用。随着小米互联网业务的快速发展，用户对Apache Doris的查询性能提出了更高的要求，Doris 向量化版本在小米内部上线已经迫在眉睫。在 SelectDB 公司和 Apache Doris 社区的鼎力支持下，我们在小米 A/B实验场景对 Doris 1.1.2 向量化版本进行了一系列的调优操作，使得查询性能和稳定性有了显著地提升。</blockquote><p></p><p></p><p>作者｜魏祚、赵立伟</p><p></p><h2>背景</h2><p></p><p></p><p>2019 年 9 月，为了满足小米互联网增长分析业务中近实时、多维分析查询的需求，小米集团首次引入了Apache Doris。在过去的三年时间里，Apache Doris 已经在小米内部得到了广泛的应用，支持了集团数据看板、广告投放、广告BI、新零售、用户行为分析、A/B实验平台、天星数科、小米有品、用户画像、小米造车等小米内部数十个业务，并且在小米内部形成了一套以 Apache Doris 为核心的数据生态 。 小米集团作为 Apache Doris 最早期的用户之一，一直深度参与社区建设，参与 Apache Doris 的稳定性打磨。</p><p></p><p>为了保证线上服务的稳定性，小米内部基于 Apache Doris 社区的 0.13 版本进行迭代，为小米的业务提供稳定的报表分析和 BI看板服务，经过业务的长时间打磨，内部 Doris 0.13 版本已经非常稳定。但是，随着小米互联网业务的发展，用户对 Doris 的查询性能提出了更高的要求，Doris 0.13 版本在某些场景下逐渐难以满足业务需求了。与此同时，Apache Doris 社区在快速发展，社区发布的 1.1 版本已经在计算层和存储层全面支持了向量化，查询性能相比非向量化版本有了明显地提升，基于此，小米内部的 Apache Doris 集群进行向量化版本升级势在必行。</p><p></p><h2>场景介绍</h2><p></p><p></p><p>小米的 A/B实验平台对 Doris 查询性能的提升有着迫切的需求，因此我们选择优先在小米的 A/B实验平台上线 Apache Doris 向量化版本，也就是 1.1.2 版本。</p><p></p><p>小米的A/B实验平台是一款通过 A/B测试的方式，借助实验分组、流量拆分与科学评估等手段来辅助完成科学的业务决策，最终实现业务增长的一款运营工具产品。在实际业务中，为了验证一个新策略的效果，通常需要准备原策略A 和新策略B 两种方案。 随后在总体用户中取出一小部分，将这部分用户完全随机地分在两个组中，使两组用户在统计角度无差别。将原策略A和新策略B分别展示给不同的用户组，一段时间后，结合统计方法分析数据，得到两种策略生效后指标的变化结果，并以此来判断新策略B 是否符合预期。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/67/67abafb536d1059593bb985e67848caa.jpeg\" /></p><p></p><p>小米的A/B实验平台有几类典型的查询应用：用户去重、指标求和、实验协方差计算等，查询类型会涉及较多的 Count(distinct)、Bitmap计算、Like语句等。</p><p></p><h2>上线前验证</h2><p></p><p></p><p>我们基于 Doris 1.1.2 版本搭建了一个和小米线上 Doris 0.13 版本在机器配置和机器规模上完全相同的测试集群，用于向量化版本上线前的验证。验证测试分为两个方面：单 SQL 串行查询测试和批量 SQL 并发查询测试。在这两种测试中，我们在保证两个集群数据完全相同的条件下，分别在 Doris 1.1.2 测试集群和小米线上 Doris 0.13 集群执行相同的查询 SQL 来做性能对比。我们的目标是，Doris 1.1.2 版本在小米线上 Doris 0.13 版本的基础上有 1 倍的查询性能提升。</p><p></p><p>两个集群配置完全相同，具体配置信息如下：</p><p></p><p>集群规模：3 FE + 89 BEBE节点CPU: Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz 16核 32线程 × 2BE节点内存：256GBBE节点磁盘：7.3TB × 12 HDD</p><p></p><h3>单SQL串行查询测试</h3><p></p><p></p><p>在该测试场景中，我们选取了小米A/B 实验场景中 7 个典型的查询 Case，针对每一个查询 Case，我们将扫描的数据时间范围分别限制为 1 天、7 天和 20 天进行查询测试，其中单日分区数据量级大约为 31 亿（数据量大约 2 TB），测试结果如图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/de/deadb8076f5a13a0b2d726ce9752931a.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ba/badba9397fec1341dca51647d6373885.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7c/7c93c0aeb1875f8ccc7cdd1410dc8969.png\" /></p><p></p><p>根据以上小米A/B 实验场景下的单SQL串行查询测试结果所示，Doris 1.1.2 版本相比小米线上Doris 0.13版本至少有 3~5 倍的性能提升，效果显著，提升效果远高于预期。</p><p></p><h3>批量 SQL 并发查询测试</h3><p></p><p></p><p>在并发测试中，我们将小米A/B 实验场景的查询 SQL 按照正常的业务并发分别提交到 Doris 1.1.2 测试集群和小米线上 Doris 0.13 集群，对比观察两个集群的状态和查询延迟。测试结果为，在完全相同的机器规模、机器配置和查询场景下，Doris 1.1.2 版本的查询延迟相比线上 Doris 0.13 版本整体上升了 1 倍，查询性能下降非常明显，另外，Doris 1.1.2 版本稳定性方面也存在比较严重的问题，查询过程中会有大量的查询报错。Doris 1.1.2 版本在小米A/B 实验场景并发查询测试的结果与我们的预期差别较大。并发查询测试过程中，我们遇到了几个比较严重的问题：</p><p></p><p>CPU使用率上不去</p><p></p><p>查询下发到 Doris 1.1.2 版本所在的集群，CPU 使用率最多只能打到 50% 左右，但是完全相同的一批查询下发到线上 Doris 0.13 版本的集群，CPU使用率可以打到接近 100%。因此推测 Doris 1.1.2 版本在小米 A/B 实验场景中将机器的 CPU 利用不起来造成了查询性能大幅度降低。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e9/e9ab3c677f999b006d37264d5ef51e22.png\" /></p><p></p><p>查询持续报错</p><p></p><p>用户并发提交查询的时候会出现如下报错，后续的查询任务均无法执行，集群完全处于不可用的状态，只有重启 BE 节点才能恢复。</p><p></p><p><code lang=\"text\">RpcException, msg: timeout when waiting for send fragments RPC. Wait(sec): 5, host: 10.142.86.26</code></p><p></p><p>用户提交查询的时候也会频繁出现如下报错：</p><p></p><p><code lang=\"text\">detailMessage = failed to initialize storage reader. tablet=440712.1030396814.29476aaa20a4795e-b4dbf9ac52ee56be, res=-214, backend=10.118.49.24</code></p><p></p><p>Like 语句查询较慢</p><p></p><p>在小米 A/B实验场景有较多的使用 Like 语句进行字符串模糊匹配的查询，在并发测试过程中，该类查询普遍性能较低。</p><p></p><p>内存拷贝耗时较长</p><p></p><p>并发查询测试过程中，SQL 整体执行较慢，通过抓取查询过程中的 CPU 火焰图，发现读取字符串类型数据的时候内存拷贝会占用较多时间。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/46/46874c2b57826df4b8a47e0d50abdf2e.png\" /></p><p></p><h2>调优实践</h2><p></p><p></p><p>为了解决 Doris 1.1.2 版本在小米 A/B实验场景并发测试过程中暴露出的性能和稳定性问题，推动 Doris 向量化版本尽快在小米 A/B实验平台上线，我们和 SelectDB 公司以及 Apache Doris 社区一起对 Doris 1.1.2 版本进行了一系列的调优工作。</p><p></p><h3>提升 CPU 使用率</h3><p></p><p></p><p>针对并发查询时 CPU 使用率上不去的问题，我们截取了查询过程中BE进程的函数调用栈，通过分析发现，有较多的内存分配和释放操作在等锁，这可能会造成 CPU 使用率上不去。</p><p></p><p>函数调用栈</p><p></p><p><code lang=\"text\">#0  sys_futex (v3=0, a2=0x0, t=0x7f786c9e7a00, v=, o=128, a=0x560451827c48 ) at /root/doris/doris/be/src/gutil/linux_syscall_support.h:2419\n#1  SpinLockDelay (loop=1822369984, value=2, w=0x560451827c48 ) at /root/doris/doris/be/src/gutil/spinlock_linux-inl.h:80\n#2  base::internal::SpinLockDelay (w=w@entry=0x560451827c48 , value=2, loop=loop@entry=20) at /root/doris/doris/be/src/gutil/spinlock_linux-inl.h:68\n#3  0x000056044cfd825d in SpinLock::SlowLock (this=0x560451827c48 ) at src/base/spinlock.cc:118\n#4  0x000056044f013a25 in Lock (this=) at src/base/spinlock.h:69\n#5  SpinLockHolder (l=, this=0x7f786c9e7a90) at src/base/spinlock.h:124\n#6  (anonymous namespace)::do_malloc_pages(tcmalloc::ThreadCache*, unsigned long) () at src/tcmalloc.cc:1360\n...</code></p><p></p><p><code lang=\"text\">#0  sys_futex (v3=0, a2=0x0, t=0x7f7494858b20, v=, o=128, a=0x560451827c48 ) at /root/doris/doris/be/src/gutil/linux_syscall_support.h:2419\n#1  SpinLockDelay (loop=-1803179840, value=2, w=0x560451827c48 ) at /root/doris/doris/be/src/gutil/spinlock_linux-inl.h:80\n#2  base::internal::SpinLockDelay (w=w@entry=0x560451827c48 , value=2, loop=loop@entry=2) at /root/doris/doris/be/src/gutil/spinlock_linux-inl.h:68\n#3  0x000056044cfd825d in SpinLock::SlowLock (this=0x560451827c48 ) at src/base/spinlock.cc:118\n#4  0x000056044f01480d in Lock (this=) at src/base/spinlock.h:69\n#5  SpinLockHolder (l=, this=0x7f7494858bb0) at src/base/spinlock.h:124\n#6  (anonymous namespace)::do_free_pages(tcmalloc::Span*, void*) [clone .constprop.0] () at src/tcmalloc.cc:1435\n...</code></p><p></p><p>Doris 内存管理机制</p><p></p><p>Doris 中使用 TCMalloc 进行内存管理。根据所分配和释放内存的大小，TCMalloc 将内存分配策略分为小内存管理和大内存管理两类。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/28/289eb9e1adc2eac4083e0948b3bf7041.jpeg\" /></p><p></p><p>（1）小内存管理</p><p></p><p>TCMalloc 使用了 ThreadCache、CentralCache 和 PageHeap 三层缓存来管理小内存的分配和释放。</p><p></p><p>对于每个线程，TCMalloc 都为其单独维护了一个 ThreadCache，每个 ThreadCache 中包含了多个单独的 FreeList，每个 FreeList 中缓存了 N 个固定大小的可供分配的内存单元。进行小内存分配时，会直接从 ThreadCache 中进行内存分配，相应地，小内存的回收也是将空闲内存重新放回 ThreadCache 中对应的 FreeList 中。由于每个线程都有自己独立的 ThreadCache，因此从 ThreadCache 中分配或回收内存是不需要加锁的，可以提升内存管理效率。</p><p></p><p>内存分配时，如果 ThreadCache 中对应的 FreeList 为空，则需要从 CertralCache 中获取内存来补充自身的 FreeList。CentralCache 中维护了多个 CentralFreeList 链表来缓存不同大小的空闲内存，供各线程的 ThreadCache 取用。由于 CentralCache 是所有线程共用的，因此 ThreadCache 从 CentralCache 中取用或放回内存时是需要加锁的。为了减小锁操作的开销，ThreadCache 一般从 CentralCache 中一次性申请或放回多个空闲内存单元。</p><p></p><p>当 CentralCache 中对应的 CentralFreeList 为空时，CentralCache 会向 PageHeap 申请一块内存，并将其拆分成一系列小的内存单元，添加到对应的 CentralFreeList 中。PageHeap 用来处理向操作系统申请或释放内存相关的操作，并提供了一层缓存。PageHeap 中的缓存部分会以 Page 为单位、并将不同数量的 Page 组合成不同大小的 Span，分别存储在不同的 SpanList 中，过大的 Span 会存储在一个 SpanSet 中。CentralCache 从 PageHeap 中获取的内存可能来自 PageHeap 的缓存，也可能是来自 PageHeap 向系统申请的新内存。</p><p></p><p>（2）大内存管理</p><p></p><p>大内存的分配和释放直接通过 PageHeap 来实现，分配的内存可能来自 PageHeap 的缓存，也可能来自 PageHeap 向系统申请的新内存。PageHeap 向系统申请或释放内存时需要加锁。</p><p></p><p>TCMalloc 中的 aggressive_memory_decommit 参数用来配置是否会积极释放内存给操作系统。当设置为 true 时，PageHeap 会积极地将空闲内存释放给操作系统，节约系统内存；当该配置设置为 false 时，PageHeap 会更多地将空闲内存进行缓存，可以提升内存分配效率，不过会占用更多的系统内存；在 Doris 中该参数默认为 true。</p><p></p><p>通过分析查询过程中的调用栈发现，有比较多的线程卡在 PageHeap 向系统申请或释放内存的等锁阶段，因此，我们尝试将 aggressive_memory_decommit 参数设为false，让 PageHeap 对空闲内存进行更多的缓存。果然，调整完成之后，CPU 使用率可以打到几乎 100%。在 Doris 1.1.2 版本，数据在内存中采用列式存储，因此，会相比于 Doris 0.13 版本行存的方式有更大的内存管理开销。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/23/23c9b59201ad98454d63c4b807d69db4.png\" /></p><p></p><p>社区相关的PR：</p><p></p><p>https://github.com/apache/doris/pull/12427</p><p></p><h3>缓解 FE 下发 Fragment 超时的问题</h3><p></p><p></p><p>在 Doris 1.1.2 版本，如果一个查询任务的 Fragment 数量超过一个，查询计划就会采用两阶段执行(Two Phase Execution)策略。在第一阶段，FE 会下发所有的 Fragment 到 BE 节点，在 BE 上对 Fragment 执行相应的准备工作，确保 Fragment 已经准备好处理数据；当 Fragment 完成准备工作，线程就会进入休眠状态。在第二阶段，FE 会再次通过 RPC 向 BE 下发执行 Fragment 的指令，BE 收到执行 Fragment 的指令后，会唤醒正在休眠的的线程，正式执行查询计划。</p><p></p><p><code lang=\"text\">RpcException, msg: timeout when waiting for send fragments RPC. Wait(sec): 5, host: 10.142.86.26</code></p><p></p><p>在用户执行查询时，会持续有上面的报错，并导致任何查询无法执行。通过截取进程的调用栈，分析发现大量的线程均在休眠状态，均阻塞在 Fragment 完成准备工作并休眠等待被唤醒的状态。排查发现，查询计划的两阶段执行机制中存在 Bug，如果执行计划被FE取消，BE 上已经完成 Fragment 准备工作并休眠等待的线程就不会被唤醒，导致 BE 上的 Fragment 线程池被耗尽，后续所有查询任务的 Fragment 下发到 BE 节点之后，因为没有线程资源都会等待直到 RPC 超时。</p><p></p><p>为了解决这个问题，我们从社区引入了相关的修复 Patch，为休眠的线程增加了超时唤醒机制，如果线程被超时唤醒，Fragment 会被取消，进而释放线程资源，极大地缓解了 FE 下发执行计划时 RPC 超时的问题。</p><p></p><p>该问题还未完全解决，当查询并发很大时还会偶发地出现。另外，我们还引入了 Doris 社区相关的其他 Patch 来缓解该问题，比如：减小执行计划的 Thrift Size，以及使用池化的 RPC Stub 替换单一的 RPC Stub 。</p><p></p><p>社区相关的PR如下：</p><p></p><p>https://github.com/apache/doris/pull/12392</p><p></p><p>https://github.com/apache/doris/pull/12495</p><p></p><p>https://github.com/apache/doris/pull/12459</p><p></p><h3>修复 Tablet 元数据汇报的 Bug</h3><p></p><p></p><p>在 Doris 中，BE 会周期性地检查当前节点上所有 Tablet 是否存在版本缺失，并向 FE 汇报所有 Tablet 的状态和元信息，由 FE 对每一个 Tablet 的三副本进行对比，确认其中的异常副本，并下发 Clone 任务，通过 Clone 正常副本的数据文件来恢复异常副本缺失的版本。</p><p></p><p><code lang=\"text\">detailMessage = failed to initialize storage reader. tablet=440712.1030396814.29476aaa20a4795e-b4dbf9ac52ee56be, res=-214, backend=10.118.49.24</code></p><p></p><p>在该报错信息中，错误代码res=-214 （OLAP_ERR_VERSION_NOT_EXIST）表示查询计划执行过程中在 BE 上初始化 Rowset Reader 的时候出现异常，对应的数据版本不存在。在正常情况下，如果 Tablet 的某一个副本存在版本缺失，FE 生成执行计划的时候就不会让查询落在该副本上，然而，查询计划在 BE 上执行的过程中却发现版本不存在，则说明 FE 并没有检测到该副本存在版本缺失。</p><p></p><p>通过排查代码发现，BE 的 Tablet 汇报机制存在 Bug，当某一个副本存在版本缺失时，BE 并没有将这种情况正常汇报给 FE，导致这些存在版本缺失的异常副本并没有被 FE 检测到，因此不会下发副本修复任务，最终导致查询过程中会发生res=-214的报错。</p><p></p><p>社区相关的 PR 如下：</p><p></p><p>https://github.com/apache/doris/pull/12415</p><p></p><h3>优化 Like 语句性能</h3><p></p><p></p><p>在 Doris 1.1.2 版本中使用 Like 语句进行字符串模糊匹配查询时，Doris 底层其实是使用了标准库中的std::search()函数对存储层读出的数据进行逐行匹配，过滤掉不满足要求的数据行，完成 Like 语句的模糊匹配。通过调研和对比测试发现，GLIBC 库中的std::strstr()函数针对字符串匹配比std::search()函数有 1 倍以上的性能提升。最终我们使用std::strstr()函数作为 Doris 底层的字符串匹配算法，将 Doris 底层字符串匹配的性能可以提升 1 倍。</p><p></p><h3>优化内存拷贝</h3><p></p><p></p><p>在小米的场景中有很多字符串类型的查询字段，Doris 1.1.2 版本使用 ColumnString 对象来存储内存中的一列字符串数据，底层使用了 PODArray 结构来实际存储字符串。执行查询时，需要从存储层逐行读取字符串数据，在这个过程中需要多次对 PODArray 执行 Resize 操作来为列数据申请更大的存储空间，执行 Resize 操作会引起对已经读取的字符串数据执行内存拷贝，而查询过程中的内存拷贝非常耗时，对查询性能影响极大。</p><p></p><p>为了降低字符串查询过程中内存拷贝的开销，我们需要尽量减少对 PODArray 执行 Resize 操作的次数。鉴于小米 A/B实验场景中同一列不同行的字符串长度相对比较均匀，我们尝试预先为需要读取的字符串申请足够的内存来减少 Resize 的次数，进而降低内存拷贝的开销。在数据扫描时，每个 Batch 需要读取的数据行数是确定的（假设为 n），当字符串数据读取完指定的前 m（在小米的场景中，该值配置为100，m &lt; n）行时，我们根据前 m 行的 PODArray 大小预估所有 n 行字符串数据需要的 PODArray 大小，并为其提前申请内存，避免后面逐行读取时多次执行内存申请和内存拷贝。</p><p></p><p>内存预估公式为：</p><p></p><p>所需PODArray总大小 = （当前PODArray总大小 / m）* n</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3d/3d5714caf9f2759791293f37c79dc680.jpeg\" /></p><p></p><p>当然，该方法只是对所需的内存进行了预估，根据预估的大小提前申请了内存，减少了后面逐行读取字符串时大量的 Resize 操作，减少了内存申请和内存拷贝的次数，并不能完全消除字符串读取过程中的内存拷贝。该优化方案只对一列中字符串长度比较均匀的情况有效，内存的预估相对会比较接近实际内存。如果一列中字符串长度差别较大，该方法的效果可能不甚明显，甚至可能会造成内存浪费。</p><p></p><h2>调优测试结果</h2><p></p><p></p><p>我们基于小米的 A/B实验场景对 Doris 1.1.2 版本进行了一系列调优，并将调优后的 Doris 1.1.2 版本与小米线上 Doris 0.13 版本分别进行了并发查询测试。测试情况如下：</p><p></p><h3>测试1</h3><p></p><p></p><p>我们选择了 A/B 实验场景中一批典型的用户去重、指标求和以及协方差计算的查询 Case（SQL 总数量为 3245）对两个版本进行并发查询测试，测试表的单日分区数据大约为 31 亿（数据量大约 2 TB），查询的数据范围会覆盖最近一周的分区。测试结果如图所示，Doris 1.1.2 版本相比 Doris0.13版本，总体的平均延迟降低了大约 48%，P95 延迟降低了大约 49%。在该测试中，Doris 1.1.2 版本相比 Doris0.13 版本的查询性能提升了接近 1 倍。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bf/bfe2b6f15795c17a3879151b8955db25.png\" /></p><p></p><h3>测试2</h3><p></p><p></p><p>我们选择了 A/B实验场景下的 7 份 A/B 实验报告对两个版本进行测试，每份 A/B 实验报告对应小米 A/B实验平台页面的两个模块，每个模块对应数百或数千条查询 SQL。每一份实验报告都以相同的并发向两个版本所在的集群提交查询任务。测试结果如图所示，Doris 1.1.2 版本相比 Doris 0.13 版本，总体的平均延迟降低了大约 52%。在该测试中，Doris 1.1.2 版本相比 Doris 0.13 版本的查询性能提升了超过 1 倍。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2f/2f2176b3e63e7cdc987c97048d3fc429.png\" /></p><p></p><h3>测试3</h3><p></p><p></p><p>为了验证调优后的 Doris 1.1.2 版本在小米 A/B 实验场景之外的性能表现，我们选取了小米用户行为分析场景进行了 Doris 1.1.2 版本和 Doris 0.13 版本的并发查询性能测试。我们选取了 2022年10月24日、25日、26日和 27日这 4 天的小米线上真实的行为分析查询 Case 进行对比查询，测试结果如图所示，Doris 1.1.2 版本相比 Doris 0.13 版本，总体的平均延迟降低了大约7 7%，P95 延迟降低了大约 83%。在该测试中，Doris 1.1.2 版本相比 Doris 0.13 版本的查询性能有 4~6 倍的提升。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/53/53b4c33da85d88b386eb63ca175f966c.png\" /></p><p></p><h2>结束语</h2><p></p><p></p><p>经过一个多月的性能调优和测试，Apache Doris 1.1.2 版本在查询性能和稳定性方面已经达到了小米 A/B实验平台的上线要求，在某些场景下的查询性能甚至超过了我们的预期，希望本次分享可以给有需要的朋友一些可借鉴的经验参考。</p><p></p><p>最后，感谢 SelectDB 公司和 Apache Doris 社区对我们的鼎力支持，感谢衣国垒老师在我们版本调优和测试过程中的全程参与和陪伴。Apache Doris 目前已经在小米集团内部得到了广泛地应用，并且业务还再持续增长，未来一段时间我们将逐步推动小米内部其他的 Apache Doris 业务上线向量化版本。</p>",
    "publish_time": "2022-11-09 15:25:42",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "和Rust一样好，编程更安全？三年实践、员工态度反转，英伟达用 SPARK 换掉 C",
    "url": "https://www.infoq.cn/article/SlLsmcE3pW0qAZP6fTt9",
    "summary": "<p>&nbsp;</p><p>近日，知名编程语言 Ada 与 <a href=\"https://xie.infoq.cn/article/3aff3f16b49aa9b523c366031\">SPARK</a>\" 所属公司 AdaCore 表示，<a href=\"https://www.infoq.cn/article/7QaqOxHdropQbIKX7v3L\">英伟达</a>\"的产品运行着许多经过正式验证的 SPARK 代码。对于安全较为敏感的应用程序或组件，英伟达安全团队正在用 SPARK 语言取代 <a href=\"https://www.infoq.cn/article/PQi0LYV7HhmsgHkPzkJI\">C 语言</a>\"。</p><p>&nbsp;</p><p>在将 SPARK 模块与 C 中的等效模块进行了比较后，英伟达首席软件工程师 Cameron Buschardt 表示，SPARK 生成的程序集几乎与 C 代码中的程序集相同，“我根本没有看到任何性能差异。”</p><p></p><h2>为什么选择SPARK</h2><p></p><p>&nbsp;</p><p>英伟达虽以GPU闻名，但也参与嵌入式系统，并为GPU本身编写固件。这是安全关键代码。安全对英伟达至关重要，但当前的网络环境并不安全：针对固件和硬件的网络攻击呈上升趋势，但开发和验证生态系统没有跟上这些攻击的规模，同时全行业缺乏安全代码设计人员和软件安全从业人员。这些让英伟达面临着既要提供更安全的产品⼜不会⼤幅增加开发时间和成本的挑战。</p><p>&nbsp;</p><p>在全面审视自家软件开发方法后，英伟达思考哪些方面还需要改进，也因此英伟达开始注意到在开发关键嵌入式应用程序时，使用传统语言和工具集所带来的相应成本：</p><p>&nbsp;</p><p></p><blockquote>多年以来，嵌入式应用程序的开发仍然广泛使用C和C++。但这些语言已有数十年历史，语言自身相对陈旧、不少分析工具无法正常适用，C和C++的规范也有不少歧义。如果无法明确验证，开发者永远不知道特定代码模块何时算是测试通过。这不仅令安全保证无从谈起，更难以量化权衡项目进展。</blockquote><p></p><p>&nbsp;</p><p>英伟达软件安全副总裁 Daniel Rohre 坦言，“我们还是喜欢可量化的结果。”不过如何把这样一个难以量化、甚至不知道是否最终完成的问题，转化成能以数字衡量的明确答案，是摆在英伟达软件安全团队前面的一大难题。</p><p>&nbsp;</p><p>在查看了各种可实现量化的方法后，团队很快意识到不少方案需要依托于数学计算和形式证明，这类工具在过去十年间还发生了重大变化。</p><p>&nbsp;</p><p>“我们希望接下来的验证以可证明性作为起点，而不再满足于‘已经测试过了’。安全性是几乎无法测试验证的，因为根本就没有终极可靠的标准。”Rohrer表示，而形式证明则带来了强大的吸引力，能帮助英伟达确信其产品中不存在运行时错误和其他一些常见安全漏洞，且程序功能符合既定规范。</p><p>&nbsp;</p><p>“我们能不能调整基本方法？如果可以，具体要使用哪些工具？”这些问题，就成了软件安全团队接下来的工作重点。</p><p>&nbsp;</p><p>作为回应，安全团队给出的答案在 Rohrer 看来颇为“离经叛道”：如果我们不再用C语言，结果会如何？于是新的问题又冒了出来：还有哪些替代语言和工具，可以支持这些形式化方法？</p><p>&nbsp;</p><p>在追寻答案的过程中，英伟达发现了SPARK。</p><p>&nbsp;</p><p>SPARK是一种高级计算机编程语言，由定义明确的Ada子集组成。与之前的Ada一样，SPARK就是为开发高完整性软件而生，强调以可预测且高度可靠的状态运行。SPARK还提供一种名为“契约”（contract）的语言特性，能够为组件指定适用于静态验证的形式方法。</p><p>&nbsp;</p><p>英伟达首席软件工程师、首批SPARK用户之一Dhawal Kumar表示，“从编程语言功能的角度来看，这些范式跟C和C++非常相似。SPARK是一种命令式编程语言，可用于编写面向过程或面向对象的代码，也有不少大型编程工具可供选择。”</p><p>&nbsp;</p><p>归功于其独特设计，SPARK开发的代码中不会存在未定义的行为。该语言带有一组内置检查，能确保代码遵守所有规则，因此不会发生运行时错误（例如缓冲区溢出）。</p><p>&nbsp;</p><p>SPARK的另一个关键特性就是支持形式验证。换句话说，通过使用SPARK和形式方法求解器，即可在数学上证明我们的SPARK代码行为完全符合规范。这样的过程，就被称为形式验证。</p><p>&nbsp;</p><p>Dhawal Kumar解释道，“SPARK具备大多数其他编程语言所没有的功能，即在代码本体内指定程序要求、并使用相关工具集来确保这种合规性。简单来讲，这就是证明程序正确无误的能力。这一点非常重要。”</p><p>&nbsp;</p><p>总的来说，SPARK最能吸引英伟达的优势包括：</p><p>&nbsp;</p><p>SPARK具有确定性。也就是说，形式证明可以确切消除运行时错误、保障规范合规。SPARK代码能够与C链接。就是说英伟达不必一次性重新编码所有内容或非关键组件。SPARK组件能够被轻松集成至C/C++环境当中，这样英伟达就能灵活选择需要把哪些部分转化为能够形式验证的SPARK形式。SPARK拥有可靠的生态系统。SPARK的根源语言Ada本身就非常成熟，而且自1980年代以来经历过多次升级。开发者可以通过AdaCore（Ada和SPARK的全球权威机构）及其他组织轻松获得一流支持工具。此外，Ada和SPARK还拥有上游开源软件（OSS）。</p><p>&nbsp;</p><p></p><h2>概念验证：安全应用中比C/C++更优秀</h2><p></p><p>&nbsp;</p><p>2018年第四季度，英伟达开展了概念验证（POC）演习，希望深入研究SPARK语言、相关工具和可用的技术支持，借此确认其是否总体适用于英伟达的应用场景。</p><p>&nbsp;</p><p>在初始概念验证中，英伟达软件安全团队将SPARK引入了两款应用程序：其一是裸机应用程序，充当其他几块安全处理器上所运行代码的信任根；其二则是实时操作系统（RTOS）应用，负责处理保护区域的大小调整。</p><p>&nbsp;</p><p>概念验证团队在三个月内将两套代码库的几乎所有代码都由C转换成了SPARK。之后团队发现，两款应用程序的安全性和稳健性都有了重大改进。由于SPARK出色的稳健性，加上将程序属性表示为“契约”的设计，英伟达发现新程序能够大大减少安全介入需求。另外，开发团队实际上很容易适应这种新的语言和工具。</p><p>&nbsp;</p><p>与安全评估员一道完成结果审查之后，英伟达还发现SPARK完全可以在安全环境下与C代码混合使用。更重要的是，安全评估员认为SPARK不仅表现过关，而且只要开发者接受过充足的培训，其在安全关键型应用程序中的表现甚至比C/C++更优秀。</p><p>&nbsp;</p><p>概念验证团队还根据测试结果评估了投资回报率（ROI），得出的结论是由SPARK转换带来的工程成本（培训、实验、新工具获取等）可以被应用程序的安全性和验证效率提升所抵消，因此转向SPARK将大有可为。</p><p>&nbsp;</p><p>最后英伟达得出结论，SPARK的支持基础设施非常出色。</p><p>&nbsp;</p><p></p><h2>落地实践：受到工程师好评</h2><p></p><p>&nbsp;</p><p>概念验证完成之后，英伟达决定立刻将SPARK的成本节约与功能提升实践落地。从2019年开始，英伟达在其安全策略中为指定的固件使用SPARK。与此同时，英伟达还开始培训更多SPARK开发人员，并最终建立起内部培训计划。随着公司内部SPARK专业知识的积累，语言转换成本将逐渐被抵消。</p><p>&nbsp;</p><p>目前，多个英伟达团队正将SPARK引入众多应用程序，包括整体GPU固件镜像、BootROM和安全监控程序固件中的镜像身份验证与完整性检查，以及用于嵌入式操作系统的隔离内核中的形式验证组件等等。</p><p>&nbsp;</p><p>总体来看，目前的改造目标仍然是体量较小的代码，但这也是SPARK强类型、无运行时错误且在某些情况下可实现严格形式验证等优势的绝佳场景。</p><p>&nbsp;</p><p>另外在量化采用SPARK带来的好处方面，英伟达的工程经理们纷纷表示，SPARK提供的理论保证帮助他们增强了对产品质量的信心。</p><p>&nbsp;</p><p>英伟达公司GPU软件安全高级经理James Xu的团队的职责是，确保英伟达GPU中的软件和固件处于行业领先的安全水平。</p><p>&nbsp;</p><p>Xu 解释称，“我们之所以使用SPARK，主要原因就是它能提供严格保证。其中一大关键价值就是不存在运行时错误。要知道，能相信自己的代码可以直接回避掉大多数常见陷阱，这可是很有吸引力的。在使用SPARK编码时，我们往往更有信心，因为这种语言本身就能防止人们犯下C语言编程时一些常见的错误。”</p><p>&nbsp;</p><p>作为英伟达GPU固件安全团队负责人，Varun Kumar 的团队负责GPU组件的初始化和启动、安全引导、固件更新以及设备恢复证明等。如今 Kumar 带领着20名工程师按照NIST SP800-193平台固件弹性指南开发SPARK组件。他表示，Xu提到的这些特性对于他们这些客户安全保障人士也很有吸引力。</p><p>&nbsp;</p><p>与James Xu和Varun Kumar团队使用SPARK开发新组件不同，Cameron Buschardt 的主要工作是用 SPARK 编写出与 C 版本等效的模块。从结果来看，SPARK 版既未出现代码膨胀、也不存在性能降级。他表示，“由SPARK编写成的程序集几乎跟C语言版本完全相同。我没有发现任何性能差异，而且因为所有属性都得到了严格证明，所以我们压根不需要启用运行时检查。”</p><p>&nbsp;</p><p></p><h2>内部开发者：从怀疑到支持</h2><p></p><p>&nbsp;</p><p>虽然现在看着效果不错，但 SPARK 的推广工作起初并不顺利，不少开发者和工程经理对其多少是抵触的。James Xu认为这些都源自于对未知的担忧，工程技术和行政管理团队都有各自担忧的事情。</p><p>&nbsp;</p><p>“Ada和SPARK在某些领域缺乏知名度，所以人们会担心未来会不会影响工程资源的扩展能力、会不会影响到开发计划、会不会很难得到可靠的技术帮助等。虽然消除运行时错误这点听起来不错，但真能在实践中落地吗？对于逻辑错误，SPARK又有哪些优势？另外，考虑到对这种语言并不熟悉，人们天然会觉得从C到SPARK会严重拖慢开发进度。”</p><p>&nbsp;</p><p>英伟达用事实回应了大部分质疑。在培训方面，英伟达最初直接使用 AdaCore 提供的课程，不久之后便开发出了自己的内部培训计划。很快，参与学习的开发者数量就迅速增加。</p><p>&nbsp;</p><p>事实证明，语言转换带来的影响远不像想象中那么严重。</p><p>&nbsp;</p><p>James Xu当初曾猜测SPARK的开发周期可能是C语言的两倍。但后来他发现，只要保证只在隔离良好且规模较小（但更有价值）的范围内使用SPARK，那实际影响就可以“几乎忽略不计”。Xu还强调，“有些开发者还担心项目进度会大大减缓，甚至觉得预算可能会超支。但事实证明这都不是问题。</p><p>&nbsp;</p><p>在亲眼目睹了SPARK和形式化方法对工作和客户关系产生的积极影响之后，很多此前抱有怀疑态度的工程师迅速转变成了热情的支持者。</p><p>&nbsp;</p><p>“说实话，刚开始那会我也非常怀疑。我在SPARK中第一次尝试证明非平凡算法，结果简直糟透了。但在经历了初步学习之后，我又对SPARK那种严格的可证明性无比钦佩。”Cameron Buschardt 表示，“SPARK不仅允许我们构建一个组件，还承诺帮我们证明它的完备性。这是一场变革，是其他任何语言都无法带来的至高信任。”</p><p>&nbsp;</p><p>从怀疑到支持的英伟达工程师有很多。Rohrer表示，只要大家愿意直面挑战、亲身尝试，那么在克服了最初的思维惯性之后，他们就会意识到转向SPARK确实具有打破传统的变革性意义。</p><p>&nbsp;</p><p></p><h2>结束语</h2><p></p><p>&nbsp;</p><p>自最初部署以来，SPARK以及为其构建的形式化方法工具开始在英伟达内部快速传播和普及。</p><p>&nbsp;</p><p>在2018年底第一期概念验证结束时，英伟达里接受过SPARK培训的开发者只有5人。但到2022年第二季度，这个数字已经增长到50以上。在此期间，英伟达用SPARK实现了诸多组件，其中包括其GPU固件镜像中的各种组件、硬件引导ROM的组件，以及用于简化嵌入式操作系统内核证明的几个库。</p><p>&nbsp;</p><p>如今，许多英伟达产品都附带有SPARK组件，公司内部对这种语言的认识和兴趣也在持续增长。</p><p>&nbsp;</p><p>Buschardt表示，“我们最初用小规模概念验证证明自己，随后又用SPARK实现了规模更大的启动固件。这也向英伟达的其他团队证明，SPARK完全可以用来构建固件或者其他类似用例。它在架构讨论中出现得越来越频繁。还有客户经常讨论的关键安全属性，有了SPARK的支持，我们可以向客户证明这种安全保障不只是口头承诺、而是原理层面的严格证明。”</p><p>&nbsp;</p><p>同样消除了很多C 中易犯错误的 Rust，现在备受关注。人们难免会对这两种语言进行对比。众所周知 Rust 很难学习，SPARK 相对可能更容易些，特别是对于熟悉嵌入式编程的人。另外，Rust 专注于内存安全，而 SPARK 专注于经过验证的正确性。</p><p>&nbsp;</p><p>对于英伟达选择SPARK， AdaCore表示，“这是正确的”，并为未来选择使用SPARK的开发者铺平了道路。</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://devclass.com/2022/11/08/spark-as-good-as-rust-for-safer-coding-adacore-cites-nvidia-case-study/\">https://devclass.com/2022/11/08/spark-as-good-as-rust-for-safer-coding-adacore-cites-nvidia-case-study/</a>\"</p><p><a href=\"https://www.adacore.com/uploads/techPapers/222559-adacore-nvidia-case-study-v5.pdf\">https://www.adacore.com/uploads/techPapers/222559-adacore-nvidia-case-study-v5.pdf</a>\"</p>",
    "publish_time": "2022-11-09 15:53:06",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "李彦宏：过去一年，AI发生了方向性改变，要卷就“卷创新”",
    "url": "https://www.infoq.cn/article/ViLFIl9oiWbqLFsw7ZaW",
    "summary": "<p>11月9日，百度创始人、董事长兼首席执行官李彦宏在出席2022联想创新科技大会时表示，过去一年，无论是在技术层面还是在商业应用层面，人工智能都有了巨大的进展，有些甚至是方向性的改变。</p><p>&nbsp;</p><p>作为一家技术公司，百度过去十年累计研发投入超过1000亿元，李彦宏说“要卷就卷创新”，因为“发展的本质是增长，增长由创新驱动”。</p><p>&nbsp;</p><p>以下为李彦宏发言全文：</p><p></p><h2>过去一年，AI发生了方向性改变</h2><p></p><p>&nbsp;</p><p>大家都知道，百度是一家技术公司。让我们兴奋的东西往往和技术有关。过去一年，无论是在技术层面还是在商业应用层面，人工智能都有了巨大的进展，有些甚至是方向性的改变。</p><p>&nbsp;</p><p>我们先来看技术层面。</p><p></p><h3>AI作画取得技术突破</h3><p></p><p>&nbsp;</p><p>AI作画当下非常受关注，它就是技术突破的一个代表。这里的方向性改变是，AI从理解语言、理解文字、理解图片和视频，走向了生成内容。我们称之为AIGC，即人工智能自动生成内容。今天，你只需要在百度“文心一格”平台上，输入几个关键词，分分钟就可以生成风格独特的画作。</p><p>&nbsp;</p><p>AIGC是一种“人机共创”新模式。随着技术的突破，AI作画、AI创作视频、甚至构建虚拟世界，可能会变得像手机拍照一样简单。AIGC将创造出有独特价值和独立视角的内容，与此同时，成本大幅下降，效率大幅提升。</p><p>&nbsp;</p><p></p><h3>自动驾驶商业应用进展明显提速</h3><p></p><p>&nbsp;</p><p>人工智能在商业应用层面的进展，最明显的是自动驾驶。这里也涉及到方向性改变。过去大家认为，从L2-L5是一步一步来的。但其实L2之后，率先进入商用的很可能是L4，而不是L3。因为L2和L4的事故责任界定都是清楚的，L2出了事儿，责任在司机；L4没有司机了，运营商要为事故负责。L3则是司机在需要时进行接管，事故责任很难界定，因此L3的普及需要更长时间。</p><p>&nbsp;</p><p>百度L4级自动驾驶落地很快。到今年7月份，“萝卜快跑”累计订单已超过了100万单，运营范围遍及北上广深等10多个城市。在重庆和武汉，还开放了萝卜快跑的全无人商业化运营。我之前说，无人车就是汽车机器人。今天，这些汽车机器人在城市街头已经越来越常见，“人机共生”的愿景正在变成现实。</p><p>&nbsp;</p><p>刚才我谈到，AIGC带来“人机共创”新模式，自动驾驶正在实现“人机共生”的愿景，这都是人工智能技术的方向性改变。百度在人工智能领域，是为数不多的进行全栈布局的公司，从最底层高端芯片昆仑，到飞桨深度学习框架，再到文心预训练大模型，各个层面都有领先的自研技术。这使得我们一旦遇到大的应用时，能够进行端到端的优化，实现效率大幅提升。而端到端的优化，是因为我们能够从应用侧不断获得反馈，这就是“反馈驱动创新”。</p><p>&nbsp;</p><p>一段时间来，“卷”这个词特别火。我想说，要卷就“卷创新”吧。因为发展的本质是增长，增长由创新驱动。让我们把“最卷”的创新留给工程师，把“最爽”的体验留给用户，这才“卷”得有价值和意义。</p>",
    "publish_time": "2022-11-09 16:05:26",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AI时代，图神经网络将走向何方？",
    "url": "https://www.infoq.cn/article/PXDDY9kZpYwz819SqkGJ",
    "summary": "<p>事物存在即产生关联，网络无处不在。图作为描述网络的数学语言，能够很好地描绘万象的物理世界。关于图的研究，最早可以追溯到 18 世纪，在 20 世纪已经是一个很重要且热门的研究点。近年来，随着深度学习的兴起，神经网络表现出强大的数据拟合和刻画能力。“图+神经网络”强强联合的建模方式能够广泛适用于诸多场景中，因此也受到了越来越多的关注。</p><p>&nbsp;</p><p>本期“<a href=\"https://www.infoq.cn/video/YIv70yFzcgbidcZyoNI5\">InfoQ极客有约”与“OpenI启智社区</a>\"”联合推出的系列直播栏目邀请到了北京邮电大学教授、博士生导师、OpenI启智社区开源项目“图神经网络”负责人石川教授，听他来和我们聊一聊到底什么是图神经网络，为何近年来它如此“火热”？有哪些技术值得关注，经过多年技术演进，图神经网络将走向何方？</p><p></p><p></p><p></p><p>以下为直播内容整理：</p><p></p><p></p><blockquote>InfoQ：我了解到您从本科到博士后一直主修的是计算机相关的专业。您最初为什么会选择这个专业？这背后有什么故事吗？</blockquote><p></p><p></p><p>石川教授：我是97年上的大学，也没有什么太多的故事，计算机在当时还是很火热的，连装个电话都是比较先进的事情，所以当时通讯、计算机是挺火的方向。所以懵懵懂懂觉得这个方向未来机会比较多，就报考这个专业，一直读了下来。</p><p></p><p></p><blockquote>InfoQ：您本科毕业后，国内计算机行业环境是怎样的呢？</blockquote><p></p><p></p><p>石川教授：当时的环境和现在差不多，从长远来看也都是起起伏伏的。我是2001年本科毕业，那时候，计算机专业处于一个热得发烫的时候。我记得那年华为招人的时候，是整个班全部招进去，工资也都特别高。我们那时候本科毕业四五千块钱，现在看不高，可以说还比较低，但当时其他行业可能就是一两千块钱，计算机专业的工资比其他专业高个三四倍，属于很火热的状态。</p><p></p><p>但是那一年可能也是互联网泡沫消失的那一年。我们找工作时候机会还很多，但是过了半年，整个行业都不行了，立马就遇到了寒冬。前一年很多大公司还浩浩荡荡招人，第二年就开始了大规模裁员，很多学生可能刚参加工作半年就被裁掉了，所以说计算机行业有时候是虚火，有时候就会遇上寒冬，整体趋势起起落落，就像现在一样，我们本科毕业的时候也经历过一次。</p><p></p><p></p><blockquote>InfoQ：当时互联网泡沫破灭的起因是什么？有什么标志性事件吗？</blockquote><p></p><p></p><p>石川教授：我觉得这种泡沫一直都有的，就像计算机是一个发展很快速的行业，也被认为是朝阳行业，有大量的资本涌入，就催生了繁荣，当过度繁荣以后，那可能就会出现寒冬。我们那时候是经历了互联网的泡沫，就像现在，其实AI领域也存在泡沫。前两年各种因素使得AI、大数据特别火热，到今年也感觉到明显的寒冬，这既是技术发展的一个周期、一个规律，也是资本炒作各种因素造成的一种循环性现象。</p><p></p><p></p><blockquote>InfoQ：您是什么时候将研究教学作为自己的终身事业的？是在博士生毕业之后决定留校了？</blockquote><p></p><p></p><p>石川教授：博士毕业时候做的决定。当时也会纠结要去公司还是去高校，遇到一个十字路口。我还是比较想做研究，所以想去高校。但是当时也是有点犹豫，因为觉得自己不够聪明，可能做不好研究，进入高校后能不能做出成绩也是未知的，这是我的原因。最后深思考量后，还是选择了高校。</p><p></p><p></p><blockquote>InfoQ：我感觉您之前面临的纠结，现在即将毕业的学生同样会遇到此类问题，您认为什么样的人更适合进入高校，什么样的人适合进入企业？您能给那些在就业选择时感到迷茫的学生一些建议吗？</blockquote><p></p><p></p><p>石川教授：对于博士生来说，他们临近博士毕业的时候，或者更早一段时间都会有答案的。拿我自己来说，我会考虑自己到底喜不喜欢做研究、我研究做得够不够好、对自己走研究这条道路是否充满信心，这些自己心里会有一个基本的判断。如果想要时间上比较自由，想对社会未来做点贡献，有着想改变世界的雄心，而且做得也还不错，就可以考虑继续做研究。再一个，经济压力没那么大，就可以选择做研究、进高校。</p><p></p><p></p><blockquote>InfoQ：进高校以后，是什么样的契机和背景让您把数据挖掘和机器学习作为主要研究方向？</blockquote><p></p><p></p><p>石川教授：主要还是博士阶段工作的延续，且我自己也很喜欢这个方向。博士阶段我就主要做数据挖掘这个方向。那时候，<a href=\"https://qcon.infoq.cn/2022/shanghai/track/1437\">数据挖掘</a>\"、机器学习、人工智能，都是比较冷门的方向。我很看好这个方向，因为当数据体量庞大后，必然要从数据中发现知识，这是个发展的必然。因为喜欢，我才能够一直这么坚持做下来，一做就是十多年。</p><p></p><p></p><blockquote>InfoQ：2007年，您开始在北邮担任职务一直至今。提起北邮，大家脑海中的印象肯定是计算机界的顶尖学府一类的标签。您眼中对北邮的定位是怎样的？</blockquote><p></p><p></p><p>石川教授：北邮是一个特色很鲜明的学校，号称“信息黄埔”，搞计算机的应该都知道北邮，特别是搞计算机、互联网，北邮可算是一股中坚力量，北邮学校的学风是很好的。学生都比较踏实，做事认真，动手能力比较强，这是学校学生鲜明的一个特点。所以培养的学生在行业内深受信任，也成为行业的中坚力量。当然也存在一些缺点和不足，学生们研究创新的精神可能稍微弱一些，因为工程能力太强了，导致创新能力偏弱一些，这些不足现在也开始校正。我们希望北邮未来不仅是有优秀的工程师，还是有优秀的学者和知名的创业者。</p><p></p><p></p><blockquote>InfoQ：能分享下您在与学生沟通过程中令您印象深刻的几件趣事吗？</blockquote><p></p><p></p><p>石川教授：可以简单说下我读研、读博时碰到一些的老师和学生。读博确实是很漫长的一个事情，做研究也是个无止境的事情，但是这一路走过来，在不同阶段会经历不同的事，也很有趣。</p><p></p><p>我求学经历也是比较丰富。本科就读于吉林大学，研究生是在武汉大学读的，是跟着老先生做演化计算。从相对比较封闭纯朴的东北跑到开放的武汉，我觉得特别新奇，感觉整个人特别活跃。老先生是个比较纯粹的学者，领导我们做研究，激发了我对做研究的兴趣。读博时我想换个环境，就跑到北京来，到了中科院计算所读博。研究生阶段我过得很快乐，但是博士阶段就遇到一些挫折，甚至说差点退学。后来国内人工智能的先驱老先生，收留了我，我就跟着他读博。老先生做事是很严谨认真的，跟着他读博那三年也是相当辛苦的，也见识了国内顶尖的人工智能技术，在这种环境下我自己也更加勤奋，更加努力。</p><p></p><p>后来到了北邮工作两三年之后，有机会去了美国伊利诺伊大学芝加哥分校访问，跟着数据挖掘大师学习。于老师是数据挖掘领域的先驱，在华人计算机数据挖掘圈也是首屈一指的人物。我也很有幸跟着他成为他那边的第一个大陆访问学者。跟着他学习后，我学到了很多做研究的方法，特别是他就带我进入了国际数据挖掘圈，相当于在学术上又给我指了一条明路。后来在他的指引下，我在求学过程中碰到了很多老师，也是结交了很多朋友，跟这些最优秀的人、最聪明的人打交道合作，也使我更加努力，尽力做好每件事。这一路走过来，我感觉收获是挺大的。能够做研究，与最优秀的人为伍是一件很幸福的事情。</p><p></p><p></p><blockquote>InfoQ：您之前也在美国研究数据挖掘相关技术，在国外期间和在国内期间体验到的学术氛围有什么不同？</blockquote><p></p><p></p><p>石川教授：我是2010年去的美国，那时候我感觉国内外在学术界、工业界上的差别还是很大的。那时国内真正会做研究的人不多，虽然研究已经开始起步了，但是跟国外差距还是比较大的。我在美国那边也认识了那些顶尖的高校的主流的研究人员，了解了他们是怎么做研究，怎么培养学生的，这对我影响挺大的。</p><p></p><p>国外那边他们很强调学术界跟工业界合作，因为他们那边暑假是有三个月时间，挺长的，学生基本上都趁这三个月时间去企业里面实习，老师也很鼓励他们这么做，这样可以共同解决一些问题，既能发表高水平论文，也可以解决企业的实际问题，学生也可以赚一些钱，能够支持后面的学业，这是很好的模式。</p><p></p><p>在研究上，我也是学到了如何做研究，如何思考问题，学到了一些常用的主流的工具和方法。但是后来这十多年，我觉得国内进步是相当大的，年轻的老师基本上都受过正规的科研训练，很多也都是直接从国外回来的，把国外的一些先进的研究方法和思想都带回来了，国内的研究水平提升是很迅猛的。现在我感觉这些国内做得好的团队跟国外没有明显的区别，而且国内企业，特别是头部互联网企业进步也是相当大的。现在我们的学生也大量派到了企业里面跟他们合作做一些前沿的工作，这基本上跟国外的环境和模式差不多是齐平的。</p><p></p><p></p><blockquote>InfoQ：您在计算机行业已经从业二十多年了，能否结合您的经验为大家介绍下计算机行业的发展历程，以及我们能从这样的历程中得到哪些启示呢？</blockquote><p></p><p></p><p>石川教授：我是农村出身的，读大学的时候是97年，在那之前没接触过电脑，我在读的还是一个省重点高中，那时候好像有286、386那种台式机，但是都没接触过。读了大学之后，才开始接触DOS操作系统，应该是属于最早的那批微机。最早的微机人机交互的主要方式是命令行方式。后来586出现之后，从原来的DOS操作系统键盘这种命令行控制方式，到鼠标这种可视化视窗的控制方式，是个巨大的飞跃，也造成了计算机极大的普及。</p><p></p><p>再到近些年，智能手机触摸屏的出现，很大程度上推动了计算机、电脑产品的极大普及。这是我经历的交互系统的三次重大变革，也深入影响到我们的生活。随着交互系统的更加智能，像语音、脑电波，或者是眼球与电脑间的交互，这些新的交互模式正在发展中，未来有可能让计算机发生翻天覆地的变化。</p><p></p><p>现在全社会正在全面上云，<a href=\"https://qcon.infoq.cn/2022/shanghai/presentation/5024\">SaaS</a>\"、PaaS这些底层技术的革新，使得我们从软硬件系统到编程系统，到服务的方式，完全变了。这些模式的改变造成了行业的重大变革。国家提出的<a href=\"https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247556939&amp;idx=1&amp;sn=01e48bc3bb145d6dcb19181d33757bd3&amp;chksm=fbeaa684cc9d2f922a8b62e8d3c7b02235467e01b0818e7648909d760ad1df06df238d0c2c48&amp;scene=27#wechat_redirect\">东数西算</a>\"、算力网络等也将快速发展起来，可能未来计算也就像水和电一样，成为了基础设施。此外，有了AI和计算资源后，<a href=\"https://qcon.infoq.cn/2022/shanghai/track/1472\">智能算法</a>\"也需要融入到各行各业，未来各行各业都将发生重大变革。</p><p></p><p></p><blockquote>InfoQ：您现在主要研究数据挖掘与机器学习方向，这是数据科学与人工智能的交叉方向，您认为数据科学与人工智能领域的关系如何？有哪些共性的东西？</blockquote><p></p><p></p><p>石川教授：我研究数据挖掘、机器学习到现在已经20多年了，这些流行名词变化得很快，隔几年就有一个新名词，像网格计算、云计算、大数据、人工智能、区块链到元宇宙。但从学科发展的本质来说，一些研究方向相对来说是比较固定的，没有那么多花哨的东西。</p><p></p><p>数据科学是用科学的方法<a href=\"https://www.infoq.cn/article/ruW1ETT3VhEVvE6YKe24\">算法</a>\"以及系统从数据中提取价值的一个跨科学领域，它主要是从数据中提取价值，从数据中发现知识，这是数据科学要做得事情。这怎么做？数据挖掘是一个重要的核心方法，数据挖掘本身就从数据中挖掘知识，发现有用模式。所以，数据科学可以说是数据挖掘一个比较时髦，比较学术化的说法，其本质就是数据挖掘。</p><p></p><p>人工智能是研究开发，用于模拟延展人的智能的理论技术方法，这里面人工智能的核心技术就是机器学习，就是让这个机器能够从数据中提炼知识，像人一样从数据中分析数据、提炼出知识来，这是人工智能的一种重要技术手段，目前也成为一种核心的技术手段。深度学习又是属于机器学习里面的一类方法，现在它也是机器学习的主流方法，甚至成为人工智能的主流方法，但是人工智能方法也有其他一些机器方法。</p><p></p><p>人工智能实际上是数据科学的一个技术手段，我要做数据科学，要从数据中发现知识，用什么技术来挖掘？我们是用人工智能的这种技术来从数据中挖掘知识，所以说人工智能是数据科学的一种技术手段，当然我们也可以用其他的一些技术手段，<a href=\"https://www.infoq.cn/article/ayJaapeYP720G6gcx40K\">人工智能</a>\"是一种核心的技术手段，数据科学是人工智能的应用领域。人工智能用在哪里呢？它可以用在数据科学里面，也可以用在其他方面，这是他们之间的一个关系。</p><p></p><p></p><blockquote>InfoQ：随着数据科学、机器学习的兴起，图神经网络被提及得越来越频繁，您能给大家介绍下究竟什么是图神经网络，它为什么会这么“热”？</blockquote><p></p><p></p><p>石川教授：图神经网络通俗的说，是把神经网络技术用在图数据中，设计了一类模型，因此它就成为图神经网络，还有其他一些技术也用在分析处理图数据，目前我们分析图数据最主要的一种技术手段就是图神经网络。</p><p></p><p>图神经网络原本是用来分析图数据的，但是现在又不局限于图数据，它也可以用于其他类型的数据，现在也成为人工智能一个研究的热点，已经成为人工智能领域的一个核心主流方法。那么，为什么图神经网络这么火热？我分析有三点原因：</p><p></p><p>第一，它是图分析挖掘技术的一个必然，我们很早就开始研究怎么分析挖掘图数据，从以前做一些统计分析、概率模型，再到现在用图神经网络，这是技术发展的一个必然。这是它热起来的第一个原因；</p><p></p><p>第二，它也是神经网络发展的必然。<a href=\"https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247572442&amp;idx=3&amp;sn=0a638457392d40377f07aec72d22af89&amp;chksm=fbeb6215cc9ceb03cfad67a855329b3a4f81295b6a910def0c5ad6547a6492648a75ab5371d9&amp;scene=27#wechat_redirect\">神经网络</a>\"很早就出现了，近一些年，学者们发现它在图像识别领域很有效果，后来将其用在语音、视频等领域，效果也都挺好，再后来用到文本里面，也觉得很有效，神经网络的应用范围越来越广，最后就是到了图数据，发现在图数据里面也很有效，它是技术发展的一种必然；</p><p></p><p>第三，图神经网络它有很好的普适性和广泛的应用性。图数据是广泛存在的，万物互联，对象之间都是有关联关系的，这种关联关系是广泛存在的，我们能够挖掘利用这些关联关系，在很多问题中都会有好处。图神经网络技术刚好能够很好地利用这种学习结构关系，而且能够融合原来属性信息，这样就能很好地把原来机器学习主要分析的特性信息和它内部隐含的结构信息利用起来，而且在很多场景下都取得比较好的效果，这也使得它能够广泛的应用与研究。</p><p></p><p></p><blockquote>InfoQ：您能聊聊目前这些图神经网络的框架的现状吗？包括大家可能比较关心的是国内框架的水平如何，他们建完了以后到底能不能用？在您印象中这些框架发展现状是怎么样的？</blockquote><p></p><p></p><p>石川教授：我感觉国内外整体差别不大。具体来说，国内做图计算平台的企业和机构还是比较多的，但是更多的都是企业或机构内部使用。像阿里、蚂蚁、腾讯，他们都有自研的计算平台——图神经网络算法平台，国内也有一些做得比较有名的，像<a href=\"https://www.infoq.cn/article/IhiliY5-iSW4H60ushSl\">阿里达摩院做的Graph</a>\"、阿里妈妈做的Euler Graph，这些框架在他们企业内部能够真正地支持实际业务，像腾讯做得也挺不错，但这些一般都是在企业内部使用。</p><p></p><p>像开源的框架如PyTorch下面的PYG、DGL这两个是具有代表性的，在世界范围内广泛使用的，我们做研究编程大多都基于这些平台来做。</p><p></p><p>国内主要是百度基于深度学习平台做<a href=\"https://www.infoq.cn/article/8IfdDTb1YpasRCc394WV\">PaddlePaddle</a>\"。虽然有些应用是基于PaddlePaddle建立的，但它的用量比起DGL和PYG来说还是差一些。学术界也有不少做得不错的框架，那些框架在工业界也有比较大的影响力。在鹏城实验室的项目支持下面，我们做了OpenGNN，这是主要针对图神经网络做的开源平台，它主要是基于DGL，在DGL上面做的图神经网络算法库，DGL上面的抑制图神经网络算法库主要就是用的这个库，我们跟他们也是有深度合作。</p><p></p><p>另外我们也做了一个GAMMA GL，这个是图神经网络算法库，跟其他库的有一些区别，我们主要是基于一个通用的深度学习底层平台，不像前面的DGL和PYG是基于PyTorch或Tensorflow这些固定的深度学习平台建立的，我们GAMMA GL是基于一个通用的深度学习平台。下面底层的深度学习平台，像<a href=\"https://www.infoq.cn/article/Mq610CNq2BGDlIWQR9bm\">Tensorflow</a>\"、PyTorch、PaddlePaddle我们都支持。这个算法库目前有40多种算法。这两个算法库也都在启智社区上面做了开源，这两个库也支持了一些企业应用。</p><p></p><p></p><blockquote>InfoQ：我了解到您是启智社区 “图神经网络”负责人，您最初是如何与OpenI启智社区相识的？</blockquote><p></p><p></p><p>石川教授：我是因为一直在做图神经网络这方面的研究，在国内做得也还算不错，那么鹏城实验室做个开源的人工智能算法体系这么一个大型的开源库，就让我承担图神经网络这一块的工作，因为我们一直在做这方面的研究，有一定的基础。所以就是我就承担了这项工作，这些算法库也是需要做开源，启智社区在国内开源这一块是做得是很好的。我们也希望把我们的开源库放在启智社区上面，这一方面是扩大我们算法库的影响，另外一个也为国产开源做一些贡献。</p><p></p><p></p><blockquote>InfoQ：你觉得启智社区最吸引您的是什么地方？</blockquote><p></p><p></p><p>石川教授：首先它有一个很优秀的技术支持团队，我跟<a href=\"https://www.infoq.cn/article/txRfv7UbRKZAPFA1QqG4\">启智社区</a>\"的负责人也很熟。他是个很有理想，很有激情的一个人，也是做这种开源社区很多年，在这方面有很强的技术背景，所以放在上面，我们也是放心，会有很好的维护。另外就是国产开源，我也觉得是一个方向，也是我们必须要坚持的一件事情。我们做得优秀的东西不仅要跟世界分享，更加要首先跟国内分享。所以说能够在这方面做一些贡献，能够与启智社区合作，我也感觉很荣幸。</p><p></p><p></p><blockquote>InfoQ：在合作期间，启智社区为您和您的项目提供了哪些帮助和支持？未来咱们还会与启智社区有哪些方面的合作？</blockquote><p></p><p></p><p>石川教授：启智社区提供了很多技术支持，比如在文档建设和代码上传方面为我们提供了很多支持，操作也都很方便。使用<a href=\"https://www.infoq.cn/article/EkVixxywgNE3zavD1zSx\">启智社区</a>\"的感受跟国外的GitHup没什么区别，甚至更友好一些。后面肯定我们还是希望能够跟启智社区有更多更好的合作，做这种算法开源、算法库，我们后面还会做更多的事情，这些比较好的、优秀的开源项目我们都会把它放在启智社区上面。</p><p></p><p></p><blockquote>InfoQ：我看到现在社会上比较赞同一个声音，就是倡导学术界和行业界深度融合，整体来看现在产业界和学术界的融合情况是怎么样的？如果想要进一步发展，现在还需要在哪些方面做一些努力来促进发展？</blockquote><p></p><p></p><p>石川教授：我觉得产业界跟学术界结合的环境是越来越好，一方面是企业技术水平有大幅的提升，这些研发人员本身就都是很优秀的博士、硕士，具有研究背景和研究思维。另外一方面我们学术界，很多方面也是达到了国际水平，能够为企业解决一些实际问题，所以说这两方面都发展起来后，学术合作我觉得是有现实的基础。</p><p></p><p>因为我是主要做计算机和互联网，我们与企业合作挺多的，这应该是产学研结合最紧密的一个行业，我们研究的一些东西可以迅速在企业里面应用，他们做的一些东西也都是技术水平相当高的，也具有很好的学术价值，这个行业我感觉也是合作最好的。当然其他一些传统行业，我觉得也还是有很多潜力可以挖掘的。要培养产学研合作的意识，也得要有这方面的技术水平，也要有相应的投入。我们共同真正解决问题，相互促进，能够更好地实现产学研的协同发展。</p><p></p><p></p><blockquote>InfoQ：还有一些想要了解图神经网络的同学，他们如果个人想朝着这个方向去学习，他们应该从哪些方面入手？</blockquote><p></p><p></p><p>石川教授：这个学习是一个比较漫长的过程，实话实说，在我们实验室培养学生，首先要有一些基本的计算机编程的基础，然后再去学机器学习，不是说有了深度学习，就不学机器学习了，这肯定是有问题的。先是学好机器学习，再学一些深度学习，然后再学图神经网络，大概是这么一个流程，这样学得才比较扎实一点。</p><p></p><p></p><blockquote>InfoQ：在其他行业有什么应用场景吗？图神经网络在金融行业有什么典型的应用场景？</blockquote><p></p><p></p><p>石川教授：在金融行业应该说是有很广泛的应用前景的。金融行业主要就是转账交易这些数据，我知道金融行业这种图数据库是用得挺多的，但是<a href=\"https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247500424&amp;idx=2&amp;sn=dcf22dc313db442f824fe892ca670784&amp;chksm=fbea7b47cc9df2515bd7298af0b566e868d1918153a5dfd665d835e66b11b8aa3da2fd9ad363&amp;scene=27#wechat_redirect\">图数据库</a>\"更多的是满足一些查询和简单的计算和分析，对这些交易的结构数据做深入分析，就需要用图学习和图神经网络这样一些技术，这里面应用场景是相当多的。对于风险防范、欺诈检测等技术，我们跟蚂蚁合作的时候是挺多的，这是有广泛的使用价值的。</p><p></p><p></p><blockquote>InfoQ：最后一个问题，您觉得目前图神经网络，大家所遇到的最大的瓶颈是什么？</blockquote><p></p><p></p><p>石川教授：最大的瓶颈目前有点太火了，已经成为一个红海了。传统的图神经网络已经研究得挺多的了，那么在学术研究上面，模型和图神经网络模型的安全性，是学术上值得技术研究的。</p><p></p><p>在工业上我觉得可能还需要更多的应用，目前像互联网企业、社交、金融、电商这些是广泛使用的，而其他行业像银行，用得都不多。银行、电信这些行业都有大量的图数据，这些行业的使用要找到一些杀手锏级的应用，也就是说要开发出一款非图神经学习不可的应用，才能推动图神经网络更进一步发展，这是我的一些个人观点。</p>",
    "publish_time": "2022-11-09 16:45:40",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]