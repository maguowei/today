[
  {
    "title": "36 亿融资“造假”被揭穿！挣钱太难了，前苹果 AI 工程师 3 年打造的“欧洲 OpenAI”宣告退出模型竞赛",
    "url": "https://www.infoq.cn/article/qJPbo2exxTRb3mRWIgrA",
    "summary": "<p>整理 | 华卫、核子可乐</p><p></p><p>德国 AI 初创公司 Aleph Alpha 曾被认为是 OpenAI 的潜在欧洲竞争对手，去年还筹集了超过 5 亿美元。然而，近日 Aleph Alpha 开始将其商业重点从开发大型语言模型转向生成式 AI 操作系统和咨询服务。该公司表示，市场变化和来自科技巨头的激烈竞争是其转向的原因。</p><p></p><p>对 Aleph Alpha 来说，不再执着于 AI 模型竞赛将使其能够在无需为维持尖端人工智能模型支付巨额费用的情况下追求增长。然而，这不仅反映出大模型当前的市场挑战正在加剧，也表明了资金雄厚的科技巨头在 AI 开发中日益增长的主导地位，最近 Character.AI 、Inflection 等人工智能初创公司在创始人加入大型科技公司后都改变了发展方向。</p><p></p><p></p><h1>创始人曾在苹果工作三年，如今开始质疑大模型产品</h1><p></p><p></p><p>在被问及欧洲科技圈的从业者们最抱希望的 AI 企业时，出现最多的名字当数 Mistral。这是一家法国初创公司，已经筹集到 1 亿美元但尚未发布任何产品；紧随其后的就是 Andrulis 创立的 Aleph Alpha 了。</p><p></p><p>尽管持怀疑论的从业者们一直质疑这家公司到底有没有能力跟谷歌和 OpenAI 同台竞争，但欧盟有许多人都希望 Aleph Alpha 能够抵消美国在这一技术领域的主导地位。虽然 Aleph Alpha 首席执行官 Jonas Andrulis 强调他的公司不是什么“民族主义项目”——毕竟该公司也有不少美国员工，但他似乎也很乐意成为欧洲 AI 力量的先锋和代表，声称“我个人非常关注要如何为欧洲做出卓越的技术贡献。”</p><p></p><p>现年 42 岁的 Andrulis 曾经在苹果公司作为高级 AI 研究工程师工作过三年，主要从事 AI 研究并于 2019 年离职，理由是探索这项技术在科技巨头以外的潜在应用。此前，他还是机器学习和计算机视觉公司 Pallas Ludens 的创始人兼首席执行官，该公司后被苹果收购。之后，他在德国西南部城市海德堡成立了 Aleph Alpha，主要目标就是开发大语言模型，并在两年后成功筹集到 2700 万美元。</p><p></p><p>据 Aleph Alpha 介绍，该公司的客户（从银行到政府机构）在使用 Aleph Alpha 的大语言模型来撰写财务报告、将数百页长度的文档提炼成简明扼要的概述，同时根据企业客户的运营情况构建业务聊天机器人。</p><p></p><p>Aleph Alpha 的模型能够支持用德语、法语、西班牙语、意大利语和英语进行交流，其训练数据包括欧洲议会发布的大量多语言公共文件。而强调其欧洲血统的还不仅仅在于该公司 AI 方案所支持的语言种类，其对透明决策流程的强调以及对 AI 系统“幻觉”问题的重视和解决，也有着相当强烈的欧洲特色。欧盟 AI 行业认为，相较于美国企业，欧洲公司对于隐私和歧视等问题往往更加敏感。</p><p></p><p>但事实上，有不少人都在怀疑 Aleph Alpha 的底层技术是否足够先进，能否承载起欧洲打造 AI 巨头的希望。未来社会智库欧洲人工智能治理主管 Nicolas Moës 表示，“任何接触过多种语言模型的朋友都会注意到，Alepha Alpha 的模型质量绝对达不到一线水平。”前 OpenAI 研究员、人工智能技术顾问 Matthias Plappert 也表示，在用于证明新 AI 模型有效性的标准化测试中，Aleph Alpha 的得分并没能超越其美国竞争对手。</p><p></p><p>现在，该公司正在从大型语言模型转向专注于 Pharia AI，这是一个面向企业和政府客户的“生成式 AI 操作系统”，旨在帮助企业和政府机构企业和公共机构快速扩展 AI 项目。该系统由几个组件组成：用于构建专业知识的 Pharia Catch、用于创建特定于应用程序的 AI 系统的 Pharia Studio、用于操作和扩展的 Pharia OS 以及作为用户界面的 Pharia Assistant。</p><p></p><p>这种转变使 Aleph Alpha 能够在无需为维持尖端人工智能模型支付巨额费用的情况下追求增长。对于这一转变，Andrulis 进一步解释道：“世界改变了 。仅仅拥有欧洲大模型产品作为一种商业模式是不够的，这并不能证明投资的合理性。”</p><p></p><p></p><h1>商业经营不善，并涉嫌融资“造假”</h1><p></p><p></p><p>Aleph Alpha 之所以开始退出 AI 模型竞赛，似乎主要还是源于其正面临的各种商业模式挑战，包括未能实现销售目标和融资结构受到的质疑。</p><p></p><p>据知情人士透露，该公司现在拥有约 200 名员工，声称 2024 年总收入将达到 2000 万欧元，2025 年将达到 7000 万欧元。但该公司 2023 年预计销售额为 590 万欧元，实际销量却不到 100 万欧元。</p><p></p><p>去年 11 月，Aleph Alpha 宣布完成 B 轮融资，公司从一个由 7 名新投资者以及前几轮现有投资者组成的财团获得超过 5 亿美元（36 亿元）。然而，这一融资数字却似乎有“为炒作”估值而夸大不少的嫌疑。</p><p></p><p>据该公司介绍，Aleph Alpha 在一轮融资中筹得总计 4.7 亿欧元，按签约日汇率计算相当于 5 亿美元以上。此番融资由三部分组成：1.1 亿欧元作为纯股权融资，3 亿欧元作为研究资金，余下 6000 万欧元则以订单承诺的形式提供。其中，用作研究资金的 3 亿欧元将全部用于新成立的研究子公司 Aleph Alpha Research，且这些资金不附带任何条件。</p><p></p><p>但在今年 6 月，德国记者 Thomas Knüwer 对该公司于公布的这项总额 5 亿美元的融资计划表达了担忧：“根据我在过去几个月收集的所有信息，我认为这轮 5 亿美元的融资并没有发生。他们的融资额要低得多，只有 1 亿美元——至少在 99% 的融资定义中是这样。”</p><p></p><p>Knüwer 的疑虑主要基于以下几点。首先也最值得注意的是，一位有权查阅条款清单的消息人士向他反映，投资者以约 1 亿美元的价格掌握了该公司约 20% 的股份，意味着 Aleph Alpha 的估值约在 5 亿至 6.25 亿美元之间。如果 Aleph Alpha 真的完成了 5 亿美元的融资，并出售了 20% 的股份（这是 B 轮融资的惯例），那么其估值将达到 25 亿美元。</p><p></p><p>其次，此前 Aleph Alpha 在谈及这轮融资时多次提到财务“贡献”，而 Knüwer 认为这样的表述太过模糊。英文版本则明确提到“融资超过 5 亿美元”，数字更加准确但根据公司估值来看似乎又不太现实，具体恐怕取决于如何定义“资金”二字。而且可以看到，这 5 亿美元的数字中包含销售承诺（即“预消费许可”）、研究合同及“业务发展”承诺，这与用股份换取资本的典型融资轮定义并不一致。</p><p></p><p>Aleph Alpha 在德语版新闻稿中将这 5 亿美元描述为包含许可证购买在内的“投资方案”，而 Knüwer 则正确将其定义为收入，而非持股形式的投资。在被问及这个问题时，Aleph Alpha 方面拒绝对 Knüwer 的观点发表置评。该公司称此前已告知 Knüwer，除了公开发表关于融资轮的声明之外，其不会做出任何进一步评论。</p><p></p><p>在 Knüwer 看来，这种对融资总额的过度夸大可能会损害德国 AI 行业的长期声誉，造成与互联网泡沫时期相似的负面影响。但也必须承认，AI 企业在合作当中以实物形式收取捐赠也并不罕见。以美国最大的两家 AI 厂商 OpenAI 和 Anthropic 为例，他们在创业过程中就先后享受过由微软、谷歌和亚马逊云科技提供的云计算资源，这反过来又帮助三大巨头发展了云业务并拉高股价——也有人认为这种商业行为存在争议，相当于建立起一台自我驱动的炒作机器。可即使是这样，这类资源通常也不会被纳入传统融资轮的计算范围。</p><p></p><p>而 Aleph Alpha 明显是找到了新的“突破口”，把 1 亿美元融资、4 亿美元潜在营业额这个对媒体和该公司自身都不够有吸引力的成果，转化成了“5 亿美元融资”的夸张新闻。Aleph Alpha 选择这条路，很可能是为了让其体量看起来比实际更大，在紧跟行业炒作风口的同时在国际社会上展现一个可观的数字。可即使采用这种充满争议的算法，其融资额仍然远远落后于中美两国的水平。</p><p></p><p></p><h1>大模型市场面临严峻考验</h1><p></p><p></p><p>大型语言模型市场竞争激烈，由于开发和运营成本高昂，目前尚未盈利。但与此同时，却有越来越多具有类似功能的模型正在争夺相同的客户和用例。几个月来，行业内的人们一直在关注两个因素：效率和价格。虽然大模型用户的使用成本在急剧下降，但业内不少公司的开发成本却仍居高不下。</p><p></p><p>今年 7 月，OpenAI 推出能够提供更高性能的小型模型 GPT-4o mini，价格比此前的版本降低 60% 。而其他大模型供应商和开源模型也正在市场上争夺高效、小型和低成本的模型市场，微软推出 38 亿个参数的 Phi-3-mini，Anthropic 等有时会通过 API 提供更好或更便宜的模型。</p><p></p><p>就连国内的大模型市场，今年也不断爆发了“价格战”。5 月，字节跳动旗下的云服务平台火山引擎宣布其豆包通用模型、阿里云的通义千问系列 9 款大模型相继降价，随后百度文心大模型系列中的 ErnieSpeed 和 ErnieLite、科大讯飞旗下的讯飞星火 SparkLite 模型及智谱 AI 的 GLM-4-Flash 模型又接连宣布对用户免费开放。</p><p></p><p>有外媒指出，花费数百万美元开发和训练的人工智能模型，可能在发布后短短几周甚至几天就变得过时和毫无价值。而自 GPT-4 以来，还没有一家人工智能公司成功开发出具有显著优势的模型。</p><p></p><p>现在的关键问题是，大模型供应商是否能够通过大幅提升推理能力、扩大现有业务领域和开辟新业务领域来摆脱这场激烈的竞争。否则，鉴于 AI 研究、开发和运营的高成本以及激烈的竞争，大模型市场可能很快就会面临一个严峻的考验，无法达到投资者设定的高估值。</p><p></p><p>参考链接：</p><p></p><p><a href=\"https://the-decoder.com/aleph-alpha-quits-ai-model-race/\">https://the-decoder.com/aleph-alpha-quits-ai-model-race/</a>\"</p><p></p><p><a href=\"https://www.bloomberg.com/news/articles/2024-09-05/the-rise-and-pivot-of-germany-s-one-time-ai-champion\">https://www.bloomberg.com/news/articles/2024-09-05/the-rise-and-pivot-of-germany-s-one-time-ai-champion</a>\"</p><p></p><p><a href=\"https://www.wired.com/story/aleph-alpha-europe-openai/\">https://www.wired.com/story/aleph-alpha-europe-openai/</a>\"</p><p></p><p><a href=\"https://www.indiskretionehrensache.de/2024/06/das-maerchen-von-der-500-millionen-finanzierungsrunde-bei-aleph-alpha/\">https://www.indiskretionehrensache.de/2024/06/das-maerchen-von-der-500-millionen-finanzierungsrunde-bei-aleph-alpha/</a>\"</p><p></p>",
    "publish_time": "2024-09-10 10:05:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "企业数智化升级，大模型低成本、高效能落地的密码是什么？丨InfoQ《极客有约》",
    "url": "https://www.infoq.cn/article/IlO83s6DvV7o7dfz1swO",
    "summary": "<p>在 AI 时代的浪潮之下，“云智融合”正逐渐成为企业数字化转型的核心议题。分布式云计算、生成式 AI 和大模型等前沿技术在提升工作效率和推动数字业务升级方面发挥着越来越重要的作用。那么，如何才能利用这些前沿技术，低成本、高效能的助力企业部署落地大模型，并将其实际应用于企业业务场景中？</p>",
    "publish_time": "2024-09-10 14:49:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "国产OS移动开发新时代，如何做好应用生态“中间层”？",
    "url": "https://www.infoq.cn/article/T41PfG8eufUWSHxaWWjj",
    "summary": "<p>随着技术的迅猛发展和市场需求的不断变化，以鸿蒙为代表的国产OS 正引领着移动操作系统市场格局的深刻变革。万物互联、微内核架构变革等新兴技术的发展，为国产 OS 提供了突破契机，人工智能技术的应用则为其注入了新的 “灵魂”，能提升功能与性能，为用户带来更智能、便捷的体验。</p><p>&nbsp;</p><p>然而，国产OS 在发展道路上面临诸多挑战。先发者的技术和市场优势巨大，国内操作系统提升市场占有率充满艰辛。此外，技术研发瓶颈、生态构建困难以及用户体验提升等问题，都亟待解决。</p><p>&nbsp;</p><p>作为鸿蒙生态的共建者，蚂蚁mPaaS 不断探索破局之道，为国产操作系统的全景应用注入动力。2024 年 9 月 6 日，Inclusion・外滩大会上，由蚂蚁数字科技与鸿蒙联合主办的《跨越安卓和 iOS：开启国产 OS 移动开发新时代》见解论坛开幕，众多领域的专家、高管、开发者和生态伙伴齐聚，探讨国产操作系统在移动开发领域的现状、机遇与挑战，为其未来发展出谋划策。</p><p>&nbsp;</p><p></p><h2>国产OS 移动开发新时代：机遇、挑战、智能未来</h2><p></p><p>&nbsp;</p><p>全球移动操作系统生态发展波澜壮阔。自上世纪90 年代数字移动通信技术商用以来，手机产品从 2G 时代演进至 5G 时代，操作系统也发生翻天覆地的变化。1996 年微软发布 windows CE 1.0 版本后，移动操作系统飞速发展，2014 年后市场格局趋于稳定，形成 iOS 和安卓双强竞争格局。</p><p>&nbsp;</p><p>我国于2009 年入局移动操作系统生态圈，但受限于生态圈和安卓闭源化策略，多数企业未能形成独立生态环境。2020 年以后，以华为 OpenAI Harmony 为代表的国内终端企业的移动操作系统迎来创新突破，国产移动操作系统的时代伴随 AI 大模型等前沿技术的发展而来。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/19/19cf1159b047d60ef0352a40b62f445c.png\" /></p><p></p><p>但机遇与挑战并存。中国信通院泰尔终端实验室副主任果敢分享了对移动操作系统生态发展的观察，国产移动操作系统作为“后发者”，面临巨大困难。</p><p>&nbsp;</p><p>先发者具有明显优势，通过技术和市场的正循环，牢牢占据市场先机，安卓和苹果几乎覆盖90% 的市场份额，我国国内操作系统提升市场占有率面临漫长而艰巨的挑战。</p><p>&nbsp;</p><p>但果敢并不悲观，我国的优势也很明显。万物互联时代，不同类型的终端设备呈现指数性增长，为操作系统提供了更广阔的应用载体，推动其向泛化发展。在国内，借助华为等企业的布局和蚂蚁mPaas 平台，操作系统能在更多样化的终端上发挥作用，为用户提供更丰富便捷的服务。</p><p>&nbsp;</p><p>同时，5G 时代对操作系统的灵活性和可扩展性提出更高要求，微内核架构使其能更好地满足这些要求，为操作系统发展带来机遇。人工智能正在重构操作系统的开发逻辑，通过 “AI for OS”“OS for AI”，使操作系统更智能强大，也为开发者利用人工智能技术开发创新应用提供机会，通过南北向开放生态架构聚合应用，打破应用孤岛，构建新的端侧智能体生态，为用户提供智能化和个性化服务。</p><p>&nbsp;</p><p>果敢指出，与安卓的开放合作生态和iOS 的极致用户体验相比，我国的移动生态路径应围绕设备、应用和用户展开。为确保操作系统生态的存活和可持续发展，市场占有率需达到 16% 这一关键指标，实现这一目标需要在 OS、应用和用户扩展方面持续发力，丰富应用种类和功能，提升用户体验，吸引更多用户使用国产操作系统。</p><p>&nbsp;</p><p>这需要多方共同努力。果敢认为，华为鸿蒙等OS 厂商与蚂蚁 mPaas 等移动开发平台应携手合作，通过生态联动、开放协作以及软硬件垂直一体化优化等方式，打造高质量产品。同时，中国信通院等第三方机构应发挥专业支持作用，完善和提升标准化工作及公共服务平台水平，共同推进生态自建和发展，为国产操作系统的崛起营造良好环境。</p><p>&nbsp;</p><p></p><h2>蚂蚁mPaaS：为国产操作系统应用开发注入创新动力</h2><p></p><p>&nbsp;</p><p>见解论坛上，华为终端BG生态发展部首席战略官孙大宁介绍了鸿蒙生态的最新进展。&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d1/d1538d0f452a3cc6549960572f6249ed.png\" /></p><p></p><p>HarmonyOS是打通硬件、软件和场景，支持多样交互、实现服务自由流转的新一代操作系统。基于一次开发、多端部署的开发理念，鸿蒙使开发者能更便捷地将应用部署到不同终端设备上，在全场景时代探索中，通过多模态交互提升用户操作体验。随着大模型技术发展，鸿蒙提供推荐、搜索、对话、视觉、触控等五大能力给开发者使用，满足用户需求。更好用、更易开发、多端互联等核心优势使鸿蒙开发者畅享全场景时代红利。</p><p></p><p>在应用开发层面，鸿蒙通过原生智能的服务基座为开发者提供AI化的应用开发能力，既包括文本识别、视觉输入等常用能力，也包含AI朗读、多主体抠图等场景化能力，满足不同类型应用的AI化诉求，让开发者拥抱万物互联的智能世界。应用生态对移动操作系统的发展至关重要，仅靠一方力量是没有办法建成生态的，鸿蒙希望携手广大伙伴共筑面向全场景时代的新生态。</p><p></p><p>在这一过程中，蚂蚁mPaaS是鸿蒙不可或缺的伙伴，双方从2021年开始深入合作，建立了紧密的合作关系，克服许多困难，如今鸿蒙生态下mPaaS已服务超过2000家新伙伴，为鸿蒙生态发展注入强大动力。</p><p>&nbsp;</p><p>蚂蚁数字科技的mPaaS 负责人祁晓龙详细分享了 mPaaS 平台与鸿蒙生态的发展历程。mPaaS 平台与支付宝在移动互联网领域的发展紧密相连，2011 年支付宝开始沉淀移动领域技术，为 mPaaS 平台奠定基础。随后，mPaaS 平台不断演进完善，从 1.0 升级到 4.0，帮助客户实现一端开发、多端部署投放，提高开发效率，降低成本，解决应用开放生态中稳定性问题。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a4/a417253cf6a4d6ceeba24b6edc62f432.png\" /></p><p></p><p>当mPaaS 进入 5.0 时代，AI 智能化技术发展和国产操作系统鸿蒙崛起，mPaaS 迎来新的进化。在智能化方面，mPaaS 与 OS、技术层和上层 APP 应用进行全方位垂直探索，通过 XNN 引擎和算法实现千人千模推荐，但传统算法存在局限性。</p><p>&nbsp;</p><p>为解决这一问题，mPaaS 通过端上引擎、端上算法和 OS 能力的协同作用，结合实时计算和传统服务端模型，实现交互智能。在研发智能方面，mPaaS 致力于降低研发效率，统一研发标准，实现一次研发多端投放。通过代码智能生成等技术，减少开发重复性工作，提高效率，降低成本。</p><p>&nbsp;</p><p>在运营智能方面，mPaaS 利用支付宝运营经验，如智能推荐、AP 测试、卡片式配置等功能，为用户推送更精确的券，提高券的核销率，实现业务增长。在全终端智能方面，随着南北向设备和物联网的发展，mPaaS 探索联合自动化的可能性，通过智能化手段实现不同终端设备的协同工作，为用户提供更便捷高效的服务。</p><p>&nbsp;</p><p>与此同时，蚂蚁mPaaS 认识到国产操作系统的重要性，积极进行鸿蒙适配，目前 mPaaS 已进行全面鸿蒙适配，所有 SDK 都已实现鸿蒙化，超过 200 个大的 APP 进行了适配，为鸿蒙生态发展提供有力支持。</p><p>&nbsp;</p><p>祁晓龙表示，未来mPaaS 将继续丰富组件能力，提升人脸识别等基础能力的安全和端到端认证水平，达到 iOS、安卓的水准。实现跨端能力，做到动态化代码，一套开发、多端搞定，为开发者提供更便捷的开发环境。持续提升体验和性能，为用户带来更流畅稳定的使用体验。</p><p>&nbsp;</p><p>此外，mPaaS 公有云上的资源从 9 月份开始开放三个月的免费使用，吸引更多开发者加入 mPaaS 生态。</p><p>&nbsp;</p><p></p><h2>蚂蚁mPaas 多领域实践：探索属于 AI 时代的全新应用体验</h2><p></p><p>&nbsp;</p><p>见解论坛上，蚂蚁mPaaS 的伙伴们分享了其在多领域的实践应用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2a/2a313c593f98a69e8008bc6af110863e.png\" /></p><p></p><p>浙江苏泊尔股份有限公司的AIoT 研发经理刘谱介绍，市场需求变化和新品类产品增加，苏泊尔面临各新品类产品操作界面差异大的问题，需解决在不更新 APP 情况下上架不同智能产品的难题。</p><p>&nbsp;</p><p>为此，苏泊尔借助mPaaS 采取了一系列措施：采用灵活架构，不同品类对应不同小程序 ID，各事业部通过小程序开发设备详情页，实现独立开发、上架和发布新品类，使创新更灵活便捷；食谱详情页通过离线包开发，考虑用户在厨房可能遇到的网络环境问题，确保用户能查看、定制和修改食谱，实现千人千面；APP 介入 mPaaS 的消息推送功能，实时推送烹饪完成和设备故障提醒等信息，让用户享受更多与家人相处的时光。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/67/67509d32a963ff76ffa199942677cda3.png\" /></p><p></p><p>上海久事智慧体育有限公司的常务副总经理黄洁智分享了mPaaS 在体育行业的实践应用。今年体育消费增长带来体育数字化需求，但体育行业数字化面临诸多挑战，如用户需求个性化和周期化，平台需体现全流程并匹配服务，以及承接体育赛事带来的溢出效应等。</p><p>&nbsp;</p><p>久事体育APP 于去年 1 日上线，基于 mPaaS 实现多端无缝协作，用户在 APP 和小程序上能获得一致流畅体验。智能推送技术确保用户及时接收赛事信息，数据分析技术基于用户授权数据推荐赛事活动、提供场馆定场、体育培训等服务。mPaaS 的智能化技术为久事智慧体育提供了新可能，如举办第三届上海虚拟体育公开赛，未来还将促进软硬件结合和虚实交互，打造体育竞技元宇宙。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9d/9d65081e52f194965dc4cb1444e92d30.png\" /></p><p></p><p>昆仑数智科技有限责任公司的高级技术专家满国君讲述了中油好客e 站重构升级的过程。中油好客 e 站是中国石油在消费零售端的核心应用，但线上渠道稳定性不足、用户体验不佳等问题暴露。昆仑数智原有的移动开发框架难以满足需求，自研移动开发平台投入巨大，此时 mPaaS 进入其视野。引入 mPaaS 后，中油好客 e 站解决了应用渠道建设的痛点，通过小程序框架实现一次开发多渠道投放，各端营销活动和展位控制实现一致。</p><p>&nbsp;</p><p>同时，mPaaS 带来研发运营理念革新，保障了稳定性和创新点，使团队能专注于用户体验优化。在业务架构层面，中油好客 e 站使用 mPaaS 的原生卡片技术，实现首屏加油，聚合业务并整合订单、会员资产等。在数据驱动方面，构建了数据标准体系和 APP 端数据指标体系，通过 AB 测试等方式优化运营。在小程序生态与开放方面，中油好客 e 站构建内部小程序生态，与外部合作开展公域、私域流量合作，构建开放平台支持本地化特色应用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/06/0638cae4d94453d572a3b137fc358190.png\" /></p><p></p><p>友邦人寿保险有限公司的高级开发经理唐啸分享了友邦友享APP 的数字化转型过程。友邦友享的前身是两个落后的 APP，评分低且问题多。在集团提出客户一致化体验的契机下，友邦将两个 APP 合二为一，但在原生跟 H5 混合开发中遇到困难，缺少平台化工具。</p><p>&nbsp;</p><p>经过选型，友邦最终选择了mPaaS，因其技术性能高、投入成本低、学习成本低，且具有离线包分发、性能监控等功能，还有专门小组提供支持。使用 mPaaS 后，友邦友享 APP 取得显著效果，测试类通过率提高，兼容性失败率几乎为零，工作异常减少，安装和启动时间缩短，流量消耗减少，页面响应时间小于一秒钟，开发 Effort 减少，Crash 率降低，页面时间响应和吞吐量提升。</p><p>&nbsp;</p><p>此外，mPaaS 的离线包能力使友邦友享的功能数翻番，实现模块化开发，上线风险降低，友邦的多款 APP 也开始使用 mPaaS，影响力扩展到集团其他国家，且友邦 APP 的鸿蒙化上架也得益于 mPaaS 的离线包支持。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/59/5905c83fa4a6a2e13b070d74628cca97.png\" /></p><p></p><p>润开鸿鸿蒙原生应用技术方案总监陈和鑫分享了公司在金融领域的实践。润开鸿作为开源鸿蒙的创始成员单位，打造了国产化操作系统品牌，与mPaaS 合作并发布了基于 mPaaS 鸿蒙原生版的移动开发应用产品。润开鸿的解决方案围绕 mPaaS 展开，提升了鸿蒙原生应用开发效率和用户体验，实现了开发效率提升、成本下降、周期缩短。</p><p>&nbsp;</p><p>在安全方面，借助鸿蒙和mPaaS 鸿蒙原生版的能力，保证金融鸿蒙原生应用安全。在跨端解决方案上，整合了鸿蒙的跨端能力和 mPaaS 小程序的跨端能力，实现了面向纯业务场景的解决方案，并对底层统一能力进行服务化。在用户体验方面，充分发挥鸿蒙操作系统的优势，如在商超支付和乘车码场景的创新应用。</p><p>&nbsp;</p><p>具体来说，润开鸿通过mPaaS 平台提供的整体开发底层能力，提升了开发效率，鸿蒙通过三大安全等级认证，mPaaS 鸿蒙原生版提供多种功能保证应用安全。金融手机银行业务复杂，mPaaS 本身的跨端能力和润开鸿引入的鸿蒙跨端能力相结合，实现了首页加载速度优化和二级业务模块的动态扩展。</p><p></p><h2>结语：</h2><p></p><p></p><p>随着技术的不断进步和市场需求的变化，国产操作系统面临着广阔的发展前景。未来，蚂蚁mPaaS 将继续与鸿蒙等合作伙伴携手共进，紧跟国产操作系统发展趋势，不断创新和优化，为国产操作系统的生态建设注入更多活力。</p><p>&nbsp;</p><p>可以预见的是，在万物互联、人工智能等新兴技术的推动下，国产操作系统有望实现弯道超车，在全球市场中占据重要地位。我们期待着国产操作系统在各方的共同努力下，能够不断突破，为用户带来更加智能、便捷和安全的体验，开创更加美好的未来。</p>",
    "publish_time": "2024-09-10 16:06:51",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "字节跳动冯佳时：大语言模型在计算机视觉领域的应用、问题和我们的解",
    "url": "https://www.infoq.cn/article/39LiyJdBGlRYXzJpUEM3",
    "summary": "<p>近年来，大语言模型 (LLMs) 在文本理解与生成领域取得了显著进展。然而，LLMs 在理解和生成自然信号（例如图像，视频）等，还处在比较早期的探索阶段。为了深入探讨这一主题，我们在 &nbsp;AICon 全球人工智能开发与应用大会上邀请到字节跳动研究科学家、豆包大模型视觉基础研究团队负责人冯佳时做主题演讲《大语言模型在计算机视觉领域的应用》。本次演讲将介绍字节跳动视觉基础研究团队在这个方向的探索与进展，包括 LLMs 在图像理解与视频生成上的阶段性结果。</p><p></p><p>我们将在 10 月 18 -19 日 QCon 上海站【AI 应用开发实践】专场，邀请各行业的优秀 AI 应用团队，分享在实际产品中成功应用计算机视觉、自然语言处理、个性化推荐、对话式交互等 AI 能力提升业务效率、优化用户体验的案例与最佳实践，共同探讨 AI 应用的未来发展方向。欲了解更多内容，可访问大会官网：<a href=\"https://qcon.infoq.cn/2024/shanghai/track/1721\">https://qcon.infoq.cn/2024/shanghai/track/1721</a>\"</p><p></p><p>以下为演讲实录（经 InfoQ 进行不改变原意的编辑整理）：</p><p></p><p>在过去三年中，大语言模型取得了显著的进展，已经发展成为一种功能强大的通用模型。这些模型已经阅读了互联网上的海量文本数据，其阅读量远远超过了我们人类一生中能够阅读的文本数据总量，因此积累了丰富的知识储备。然而，这些知识目前还局限于文本领域。如何将这些知识有效解码，并支持 AI 模型在物理世界和视觉世界中完成更复杂的任务，是我们在计算机视觉领域应用大语言模型时所面临的核心问题。</p><p></p><p>我目前就职于豆包大模型视觉基础研究团队，团队的主要职责是进行前沿技术的研究探索，同时在视觉多模态大模型的未来发展方向上进行尝试和探索。今天的分享，我将首先为大家提供一些背景知识，包括计算机视觉的定义以及我们目前关注的问题。随后，我将重点介绍豆包大模型视觉基础研究团队正在进行的两个研究项目，第一个项目是利用大语言模型帮助 AI 模型更好地理解视觉内容；第二个项目是关于 AIGC 的研究。最后会进行一个简单的总结，并对未来的研究方向进行展望。</p><p></p><p></p><h2>背景介绍</h2><p></p><p></p><h3>计算机视觉的基本问题</h3><p></p><p></p><p>计算机视觉是一个历史悠久的学科，也是人工智能研究领域中极为重要的一个分支。自 1950 年马尔出版《Vision》一书以来，视觉研究者们一直致力于解决视觉领域的核心问题。视觉问题由于其应用场景的多样性，可以抽象出多种不同的问题形式。如果我们对这些问题进行简化和抽象，可以将其归纳为三个基本能力：理解（识别）、检测和分割。</p><p></p><p>识别是最基本的能力，即给定一张图像或一段视频，要求模型能够识别并告知内容是什么。检测则在识别的基础上更进一步，要求模型能在复杂环境中定位出感兴趣的物体所在的位置。而分割则是在识别和检测的基础上的进一步深化，它要求模型不仅对图像内容进行全局理解，还要对图像中每个像素的细节进行理解，明确每个像素属于哪个物体，代表什么含义，这是视觉理解的终极问题。</p><p></p><p>除了理解能力之外，随着 AIGC 技术的发展，生成问题——即从文字描述到视觉内容的转换——也受到了广泛关注。自 2021 年以来，已经陆续有优秀的视觉 AIGC 模型发布，例如 Google 和 OpenAI 都推出了出色的图像生成模型。OpenAI 最近展示的 Sora 模型在视觉生成方面表现出色。此外，3D 生成模型也引起了人们的极大兴趣，尽管目前还处于早期阶段，但其在游戏、增强现实（AR）、虚拟现实（VR）以及构建完全虚拟的数字世界等方面具有巨大的应用潜力和想象空间。</p><p></p><p></p><h3>LLM 统一模型</h3><p></p><p></p><p>过去，在解决不同的视觉问题时，我们通常会开发或训练不同的专有模型，比如用于理解、分割、视频生成或 3D 生成等。然而，这种针对不同问题开发不同模型的方法已经落后于自然语言处理领域的研究进展。在自然语言理解方面，随着 GPT 等大语言模型的推出，我们已经进入了统一模型的时代。这种统一模型通过处理海量数据，理解文本数据背后的语法结构和包含的物理世界知识，能够根据用户询问和任务指定来完成各种任务。</p><p></p><p>例如，ChatGPT 和其他一些 AI 聊天软件已经能够处理各种文本工作。我们可以利用它们来修改邮件，或者撰写文章，甚至总结一本书的关键知识。这些软件的关键在于它们背后使用的是一个统一的模型，这个模型可以接受提示词，根据用户提供的不同提示词来定位任务解决方案，并给出相应的输出。</p><p></p><p></p><h3>视觉基础模型 ：生成与理解的统一</h3><p></p><p></p><p>作为计算机视觉领域的研究人员，我们认识到虽然历史上视觉领域的发展曾领先于语言领域，但过去两三年自然语言处理的发展实际上已经为视觉研究提供了很好的示范，并走在了前面。这给我们带来了两个重要的启示。首先，我们需要消耗和吸收海量的数据，这是大语言模型已经做到的，它们通过阅读大量文本数据，积累了丰富的知识。其次，我们应该追求一个统一的模型范式，即构建一个能够通过提示（prompt）来解决各种问题的模型。</p><p></p><p>如果从头开始搭建这样的视觉模型，我们面临许多挑战。例如，视觉的自监督学习问题尚未解决，同时视觉的多任务统一也还没有实现。这让我们思考是否可以采取一种中间形态的方法，充分利用已经包含丰富知识的大语言模型来解决一些视觉领域的关键核心问题，如图像理解或图像生成。</p><p></p><p></p><h2>基于 LLM 的图像理解</h2><p></p><p></p><p></p><h3>LLM 在图像理解中的应用与问题</h3><p></p><p></p><p>大语言模型在图像理解领域的应用是一个值得关注的研究方向。尽管目前存在许多优秀的多模态大模型，如 OpenAI 的 GPT-4v 或 GPT-4o，但这些模型在图像内容的理解上仍处于初级阶段。它们能够提供图像的全局描述或识别图像中的文字，但尚未达到像素级别的细节理解。人类在观察场景时，能够提出不同粒度的问题，从全局的场景描述到具体的细节问题，如场景中有多少人、他们的着装或表情等。这种多尺度的理解能力是当前多模态大模型尚未完全实现的，在这方面还有很大的发展空间。</p><p></p><p>现有的多模态模型架构存在一些局限性，主要体现在基本的架构设计上。这些模型通常以大语言模型作为基础，需要适应大语言模型的处理方式。大语言模型主要处理文本数据，因此，要让它们理解图像，就需要将图像通过编码器提取特征，然后通过映射层将视觉特征转换为语言模型能理解的文本特征。这样，当用户提出问题时，语言模型能够根据转换后的特征和问题提供文本输出。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/dc/dc657656e72aaed6f4eba107aeec9703.png\" /></p><p></p><p>例如，如果询问上面图片中的内容，模型可能会回答说图片中有两只动物，一只是羊驼，另一只是美洲驼。这种基本架构存在一些问题，尤其是缺少对细节的理解。在图像特征提取阶段，大量信息已经丢失，而这些信息的丢失是无法通过后续的海量数据训练、有监督的精细调整或与人类偏好对齐的强化学习来恢复的。</p><p></p><p>经过训练的模型在回答关于图像全局信息的问题时可能表现得相当不错，但当被问及更具体的细节信息时，它可能就无法给出准确的答案。这是模型面临的第一个问题。</p><p></p><p>第二个问题是幻觉现象，这在多模态大模型中尤为常见。由于这些模型以语言模型为核心，它们已经接触过大量的文本数据。虽然我们不清楚具体的内容，但模型通过分析文本数据之间的分布和涌现模式，能够根据前面的词汇推断出后续可能出现的词汇。但这种推断完全在文本空间内进行，缺乏对参考图像的实际联系或基础，因此模型可能会产生一些多余的或错误的描述，这些描述可能与图像实际展示的细节完全不符。例如，如果将同一张图片多次输入到多模态模型中，模型可能会错误地描述图像中的某些细节，如描述上图中的美洲鸵为红色，即使实际上并非如此。</p><p></p><p></p><h3>带定位能力的 LLM 及相关工作</h3><p></p><p></p><p>为了解决这些细节理解和幻觉问题，并进一步扩展大语言模型的能力，使其能够与物理世界进行可靠和准确的交互，我们需要让大语言模型具备一定的定位能力。这种定位能力可以是对图像上特定区域的定位，也可以是对周围 3D 环境的定位。例如，在自动驾驶或具身智能领域，我们通常将大模型视为机器人的\"大脑\"。在进行推理时，我们希望这个\"大脑\"能够参考周围实际的物理环境信息。比如，如果问它下图中水龙头或放水果的托盘在哪里，我们希望模型不仅能告诉我们具体位置，还能指导机器人去拿取或进行相应的操作。这就要求大语言模型扩展出一定的定位能力，以便更好地与物理世界互动。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/51/519dda9bc4d0f8953d4ee7dd178d9b14.png\" /></p><p></p><p>在计算机视觉的研究领域，自去年以来，许多研究人员已经开始关注如何拓展大语言模型的能力，使其不再局限于文本空间，而是能够与物理世界进行可靠交互。在这一领域，有许多杰出的工作，我这里举 LISA 团队的研究为例。他们开发的方法赋予了语言模型推理和定位的能力，能够识别图像中的关键区域和物体。例如，在询问图像中哪种食物的维生素含量最高时，模型不仅能回答出是橙子，还能指出橙子在图像中的具体位置。这种定位能力不仅提高了语言模型的准确性，还有助于减少对某些问题的幻觉。</p><p></p><p>LISA 团队的基本思想是通过让大语言模型的输出不仅限于文本 token，还能输出代表图像中物体位置的特殊 token。为了实现这一目标，他们采用了图像预处理技术，通过不同尺度的分割来识别图像中的物体。他们使用的是 Meta 公司的“segment anything”模型，简称 SAM 模型。SAM 模型虽然功能强大，但处理一张图片可能需要十几到二十几秒的时间，这显著增加了模型理解图像内容的推理延迟。此外，该模型架构还存在一些限制。目前，它每次只能定位图像中的一个物体。如果需要定位图像中的多个物体，当前的模型架构就无法满足。这些挑战表明，在将大语言模型与物理世界交互的能力拓展方面，还有许多工作要做。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/8f/8f95c94841f614fb896fc2024130b335.png\" /></p><p></p><p></p><h3>我们的方案：PixelLM</h3><p></p><p></p><p>针对目前学术界在大语言模型与物理世界交互方面的一些方案，我们发现它们存在效率不高、实用性有限，以及能力上的缺陷，比如只能定位单个物体而无法同时定位多个物体。为了解决这些问题，我们提出了 PixelLM 模型架构，这是一个像素级别的大语言模型，它不仅高效，而且具备多物体定位的能力，能够进行推理和分割，减少幻觉回答的发生。</p><p></p><p>PixelLM 的基础模型架构关键在于物体分割码本的设计和轻量级解码器的引入。 在不改变原有大语言模型架构的基础上，我们增加了这两个设计，使得模型能够实时高效地对分割结果进行解码，并在图像上提供定位和分割的结果。大语言模型的输出也经过了改造，不仅包括文本 token，还包含代表物体分割结果的特殊 token。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/26/26668105863bca72f40c7cb0e68d438d.png\" /></p><p></p><p>我们首先使用一个强大的图像编码器来解决图像特征提取时的信息损失问题，并进行多尺度特征提取，而不仅仅是全局特征。这里我们使用了 OpenAI 的 CLIP 模型来提取图像的全局特征。但为了同时识别不同尺度的物体，我们对图像进行了缩放和切分，然后通过同样的特征提取模型来提取不同尺度的特征。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/0c/0cf4c7a4ed380060497ed9cb210a4795.png\" /></p><p></p><p>接下来是分割词表的设计。为了克服之前工作只能定位单个物体的限制，我们设计了多组分割词表或分割 token，每组 token 代表不同的尺寸，组内每个 token 代表不同的物体。通过预测结果的融合，我们能够成功地定位图像中的多个物体和不同尺寸的物体，例如同时定位下图右侧日轨的托和指针。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/71/71d70c773fe21f36b450b11141c51f43.png\" /></p><p></p><p>我们提出了一个轻量化的解码器设计，这个设计特别注重效率和简洁性。在这个设计中，我们采用了一个结构简单但功能强大的自回归解码器，它内置了注意力机制（attention）。这个解码器的工作流程是逐步进行的：首先，它解码出图像中一个物体的分割结果，然后利用这个结果作为指导，继续解码下一个物体的分割。这个过程会持续进行，直到图像中所有关键物体都被成功定位和分割出来。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f9/f94fff08c54355fa60f2aa8bf413eb85.png\" /></p><p></p><p>在训练方法上，我们采取了一种综合策略，旨在保持原有语言模型能力的同时，增强模型在分割定位方面的性能。为此，我们在训练过程中加入了一些专门针对分割定位任务的损失函数。这样的设计确保了模型在经过训练后，不仅能够准确地定位和分割出图像中的关键物体，而且还能保持大语言模型的核心能力，包括对语言的深入理解、逻辑推理能力，以及丰富的常识。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7d/7d07c3f8d3e76a0eeb516607d72d5d3f.png\" /></p><p></p><p>大语言模型或 AI 大模型的发展离不开算力和海量数据的支持，数据的构建对于提升模型能力至关重要。为了训练具备推理、定位和分割能力的像素级大语言模型，我们需要相应的训练数据来指导模型学习和执行这些操作。然而，目前并没有现成的数据集可以直接使用，因此我们需要探索如何构建这样的数据。</p><p></p><p>在计算机视觉领域，图像分割是一个长期研究的方向，学术界已经积累了大量的相关数据，每张图像中都包含了多个物体及其对应的分割标注。我们考虑是否可以利用这些带有分割标注的图像作为种子数据，进一步构造出针对图像内容的问答数据。这些问答数据的答案中应包含物体信息及其分割结果。</p><p></p><p>我们的具体做法是，将已有分割标注的图像输入到大语言模型中，让模型针对图像提出问题，并结合关键类别信息，如图像中包含的物体类型和场景。例如，如果图像中有一只猫、一台电脑和一张床，我们可以询问大语言模型：“这张图像里有一只猫、一台电脑和一张床，你能想到什么问题？能构造出什么样的问答？”大语言模型会根据图像中的物体信息生成问答对。</p><p></p><p>通过这种方式，我们收集并构造了一个新的数据集，称为 MUSE。我们希望 MUSE 数据集能作为一个初始数据集，帮助研究人员开展更多关于大语言模型或多模态大模型的研究，从而提升模型在物理世界中的定位能力。这样的数据集将为模型提供丰富的学习和推理材料，使其能够更好地理解和与物理世界交互。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/53/533f1a074cffa864b662a6b5078cff95.png\" /></p><p></p><p>在进行模型性能评测时，尽管涉及的数字众多，但我们 可以重点关注两组关键数据：TFLOPs 和分割定位的准确率。TFLOPs 是衡量模型算力的一个指标，它反映了模型的延时和效率。在我们的模型与 LISA 模型的比较中，我们模型的能力更强，但运算量却减少了一半，显示出更高的效率。此外，我们的模型在分割定位的准确率上也有显著提升，从 LISA 模型的 9.6 提升到了 37.7。我们的模型现在已经达到了一个初步可用的状态，目前团队仍在不断地迭代数据构造和模型能力，以期进一步提升模型的表现和应用范围。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/6b/6b5f7a8e3fc202ea91175da1483631af.png\" /></p><p></p><p>一个具备定位能力和对物理世界参考能力的大语言模型在应用层面拥有非常广阔的前景。它不仅可以进行多物体分割，还能进行推理、问答，甚至与用户进行交流和聊天。这样的模型可以应用于多种场景，具有极高的灵活性和实用性。</p><p></p><p>我们的模型和数据集已经开源，可以在网上下载并试用。用户可以利用我们的数据集进行模型的迭代和进一步的研究开发。</p><p></p><p>如果一个模型已经具备了基本的定位能力，那么我们接下来期待的是它能在物理世界中进行更深层次的交互，从物理世界中学习知识。这意味着模型将能够将其从互联网文本数据中学到的知识与现实世界的物理情况相对应，并通过不断的反馈来提升自身的能力，这也是我们下一步研究的重点方向。</p><p></p><p></p><h2>基于 LLM 的图像视频生成</h2><p></p><p></p><p>大语言模型（LLM）在图像和视频生成方面的应用，尤其是视频生成，已经成为一个备受关注的研究领域。许多研究团队已经发布了他们的视频生成模型，这些模型在模拟物理世界、动作和物理规律方面已经达到了非常逼真的水平，在光影效果和三维世界结构的构建上也取得了显著的成果。</p><p></p><p></p><h3>视频生成模型面临的挑战</h3><p></p><p></p><p>但视频生成模型目前还面临一些挑战。首先是视频的一致性问题。尽管生成四五秒的视频看起来效果不错，但当生成更长的视频，比如一分钟时，就会出现人物和环境的一致性问题。人物的长相或环境可能会随着视频的进行而发生不自然的变化或扭曲，这是需要解决的关键问题。其次，是用户友好程度的问题。目前的创作界面通常需要用户输入一段文字来生成视频，但如果用户希望得到一段复杂且表现力强的视频，就需要提供非常详细的文字描述。但长篇幅的描述可能会超出模型的理解能力，导致生成的视频内容与描述不匹配。此外，文字描述难以对视频进行精细控制，比如精确控制人物的姿势变化。视频生成的另一个挑战是视频的表现力或演技。我们希望生成的视频不仅在视觉上逼真，还要具有一定的表现力，人物动作要富有变化，避免单一和刻板。</p><p></p><p>目前的视频生成方案流程可能并不完全合理。用户需要设计一段复杂的文字描述，然后依赖模型生成视频，结果往往像“抽奖”一样不确定。相比之下，专业视频制作人员在创作视频时，会首先定义角色，构思故事情节，编写剧本和分镜，然后拍摄不同场景的片段，并最终进行剪辑。这种创作过程与目前视频生成模型的工作方式存在明显差异，我们在视频生成技术的发展中，需要更多地考虑如何模拟这种专业的创作流程，以提高生成视频的质量和可用性。</p><p></p><p>如果我们根据专业视频制作的流程重新设计视频生成的范式，AI 模型是否能够胜任这一任务呢？</p><p></p><p>在角色定义阶段，我们可以利用大语言模型来定义角色的性格和形象，然后使用图像生成模型根据语言模型的描述来创建具体的形象。目前，AI 模型在这方面的能力是足够的。接下来是剧本和分镜的创作，大语言模型同样可以完成这项工作。这里关键在于如何生成角色一致的关键片段，并确保这些片段能够合成具有高表现力的长视频。这正是我们需要解决的重点问题。为了应对这一挑战，我们正在研究一个名为 StoryDiffusion 的模型。我们希望这个生成模型能够创作出具有表现力和吸引力的故事，而不是仅仅模拟一些刻板的模式，生成缺乏锐利度的视频。</p><p></p><p></p><h3>我们的探索：StoryDiffusion</h3><p></p><p></p><p>StoryDiffusion 模型解决了两个问题：提供了更友好的交互方式，允许用户通过定义角色、创作剧本来进行视频内容创作；同时引入了两项关键技术，一是提高角色的一致性，二是增强表现力。</p><p></p><p>以 StoryDiffusion 的效果为例，我们可以使用角色定义模型，比如图像生成模型，输入一个角色，比如 AI 领域的著名研究科学家 Yan LeCun。我们可以得到他的形象，然后定义一个主题，比如 Yan LeCun 去月球探险。将这个主题交给大语言模型，它将生成一段剧本。这个剧本和角色形象再输入到 StoryDiffusion 中，它就能生成连续的画面，进而合成视频。在这些画面中，角色的长相保持严格一致，同时表情也很丰富，从而完整地描述了剧本和故事。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7d/7dba6bddfcbec0322b0d9f792d06ab11.png\" /></p><p></p><p>StoryDiffusion 模型的设计包含两个关键点：一致性注意力和表现力。</p><p></p><p>首先，一致性注意力的设计基于一个简单的理念，即在单独生成每张图片时，随机性可能导致角色形象的变化。如果同时生成多张图像，并使用同一个随机种子，这种随机性就会减少。在多张图像同时生成的过程中，通过互相参考，可以确保生成的人物形象保持一致，包括长相和衣着，即使动作和表情有所不同。这种一致性注意力机制确保了人物形象的连贯性。</p><p></p><p>其次，表现力的提升关键在于运动的丰富性。传统视频生成模型通常在像素空间进行插帧来生成运动，但这往往导致运动幅度小和模式单一。StoryDiffusion 模型通过将关键帧送入语义空间进行插帧，然后再映射回像素空间，利用语义空间包含的丰富信息来增强运动的幅度和表现力。这样，生成的人物不仅表情丰富，动作幅度和多样性也得到提升，同时保持人物形象的严格一致性。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b9/b98d75e7f28d949b67b09ab52c0b14e3.png\" /></p><p></p><p>通过这种运动生成模式，StoryDiffusion 能够将多个短视频进行插帧和拼接，生成更长的视频，如网站上展示的一分钟或两分钟的视频。定量评估表明，StoryDiffusion 在角色一致性和视频生成质量方面，相比同期的其他模型和方法都具有更好的效果。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ad/ad4001db71450c8e78859504d4912351.png\" /></p><p></p><p>StoryDiffusion 背后的理念是先定义故事的角色，然后生成相应的故事。这一理念已经在即梦 AI 的故事模式中得到体现，用户可以通过图像生成模型或上传自己的图像来定义角色，再利用故事生成模型来创作连续的故事。</p><p></p><p></p><h2>总结展望</h2><p></p><p></p><p>在演讲前面的部分，我提到了我们在提升模型视觉理解能力和增强与物理世界交互方面的一些初步研究和探索。这些探索包括像素级别理解的大语言模型，以及利用大语言模型改造视频生成创作流程的尝试。虽然这些研究目前还处于初级阶段，但我们将继续迭代和优化模型。</p><p></p><p>我们接下来关注的问题之一是构建一个统一的理解和生成模型，模仿语言模型的统一架构。在理解方面，我们已经取得了一定的进展，生成方面也是如此。但如何将理解和生成统一起来，尤其是在不同粒度和语义级别的特征融合与模型复用方面，仍是一个重要问题。</p><p></p><p>完成这些研究后，我们的目标是实现语言模型和视觉理解或生成模型的充分融合，创建一个真正具备原生多模态能力的模型。这样的模型将能够与物理世界进行交互，并通过与环境的互动不断学习和迭代自身能力。</p><p></p><p>目前，语言模型在语言能力上可能已超过普通人，因为它们的阅读量远超人类。但在物理世界的学习效率上，例如识别物体或学习某些操作，这些模型仍然依赖于大量训练数据，而不是像人类那样学习。因此，开发更高效、更类似人类的智能学习方法，充分利用大语言模型已经从文本中学到的物理世界知识，提高对现实世界任务的学习效率，并增强交互的可靠性，将是未来计算机视觉领域研究的重点，也是我们特别关注的研究方向。</p><p></p><p>演讲嘉宾介绍</p><p></p><p>冯佳时，字节跳动研究科学家，现任字节跳动豆包大模型视觉基础研究团队负责人。曾任新加坡国立大学电子与计算机工程系助理教授，机器学习与视觉实验室负责人。研究方向包括深度学习与计算机视觉。目前主要研究多模态基础模型、生成模型、3D 建模。曾获得麻省理工科技评论 35 岁以下创新者（亚洲），ACM MM 最佳学生论文奖，ICCV TASK-CV 讨论会最佳论文奖，CVPR2021 最佳论文奖提名。曾担任 CVPR、ICML、ICLR、NeurIPS 等会议的领域主席。</p>",
    "publish_time": "2024-09-10 17:04:29",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]