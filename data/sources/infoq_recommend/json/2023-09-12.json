[
  {
    "title": "Java近期新闻：单查询加载、GraalVM、GlassFish、JReleaser、Quarkus、Micronaut",
    "url": "https://www.infoq.cn/article/wti8XjbwvZdWSr79kOc6",
    "summary": "<p></p><h4>OpenJDK</h4><p></p><p><a href=\"https://jcp.org/en/home/index\">Java社区进程</a>\"（JCP）执行委员会<a href=\"https://jcp.org/en/jsr/results?id=6356\">投票</a>\"通过了JSR 396（<a href=\"https://openjdk.org/projects/jdk/21/spec/\">Java SE 21平台</a>\"），向着计划在2023年9月19日发布的GA版本继续迈进。</p><p>JEP 442（<a href=\"https://openjdk.org/jeps/442\">外部函数和内存API第3个预览版</a>\"）将在即将发布的JDK 21中交付，JEP草案8310626（<a href=\"https://openjdk.org/jeps/8310626\">外部函数和内存API</a>\"）预计将在JDK 22中<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-August/008061.html\">交付</a>\"，那是<a href=\"https://openjdk.org/projects/panama/\">Panama项目</a>\"的主要特性之一。该项目将JVM与定义明确的“外部”（非Java） API连接起来，其中包括许多C程序员常用的接口。</p><p><a href=\"https://www.linkedin.com/in/minborg/\">Per-Åke Minborg</a>\"是Oracle的一名技术顾问。他在<a href=\"http://minborgsjavapot.blogspot.com/2023/08/java-22-panama-ffm-provides-massive.html\">这篇博文</a>\"中讨论了外部函数和内存API的性能优势。Minborg提供了一个关于字符串转换的基准测试：在JDK 21和JDK 22中使用该API vs. 使用旧的Java本机接口（JNI）调用。</p><p></p><h4>JDK 21</h4><p></p><p><a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-21%2B35\">Build 35</a>\"仍然是JDK 21<a href=\"https://jdk.java.net/20/\">早期访问构建</a>\"的当前构建。要了解关于这个版本的更多细节，请查看<a href=\"https://jdk.java.net/21/release-notes\">发布说明</a>\"。</p><p></p><h4>JDK 22</h4><p></p><p>JDK 22<a href=\"https://jdk.java.net/22/\">早期访问构建</a>\"<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-22%2B13\">Build 13</a>\"在上周发布，其中包括Build 12的<a href=\"https://github.com/openjdk/jdk/compare/jdk-22%2B12...jdk-22%2B13\">更新</a>\"，主要是修复了各种<a href=\"https://bugs.openjdk.org/issues/?jql=project%20%3D%20JDK%20AND%20fixversion%20%3D%2022%20and%20%22resolved%20in%20build%22%20%3D%20b13%20order%20by%20component%2C%20subcomponent\">问题</a>\"。要了解关于这个版本的更多细节，请查看<a href=\"https://jdk.java.net/22/release-notes\">发布说明</a>\"。</p><p>对于<a href=\"https://openjdk.org/projects/jdk/22/\">JDK 22</a>\"和<a href=\"https://openjdk.java.net/projects/jdk/21/\">JDK 21</a>\"，我们鼓励开发人员通过<a href=\"https://bugreport.java.com/bugreport/\">Java Bug数据库</a>\"报告Bug。</p><p></p><h4>GraalVM</h4><p></p><p>在迈向1.0版本的道路上，Oracle实验室发布了<a href=\"https://github.com/graalvm/native-build-tools/blob/master/README.md\">Native Build Tools</a>\"的<a href=\"https://github.com/graalvm/native-build-tools/releases/tag/0.9.25\">0.9.25版本</a>\"。这是一个GraalVM项目，其中包含与GraalVM原生镜像进行互操作的插件。这个最新版本将依赖项升级到了<a href=\"https://github.com/oracle/graalvm-reachability-metadata/blob/master/README.md\">GraalVM Reachability Metadata Repository</a>\" 0.3.4。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/graalvm/native-build-tools/compare/0.9.24...0.9.25\">变更日志</a>\"。</p><p></p><h4>Spring Framework</h4><p></p><p>为了解决N+1问题，Spring Data团队<a href=\"https://spring.io/blog/2023/08/31/this-is-the-beginning-of-the-end-of-the-n-1-problem-introducing-single-query\">引入</a>\"了单查询加载（Single Query Loading）。这是一种通过单个SELECT语句加载任意聚合的技术。随着<a href=\"https://spring.io/projects/spring-data-jdbc\">Spring Data JDBC</a>\" 3.2.0-M2的发布，该团队宣称，这项新技术是“解决N+1问题的开始”。类RelationalMappingContext中新增了一个方法setSingleQueryLoadingEnabled(true)，用于启用单查询加载。目前，该特性只适用于简单聚合（只包含一个聚合根和其他实体的单个集合）。但其团队承诺，<a href=\"https://github.com/spring-projects/spring-data-relational/issues/1445\">未来的版本</a>\"将改进这一限制。</p><p></p><h4>Quarkus</h4><p></p><p>Red Hat<a href=\"https://quarkus.io/blog/quarkus-3-3-1-released/\">发布</a>\"了<a href=\"https://quarkus.io/\">Quarkus</a>\"的3.3.1版本，带来了依赖项升级和一些值得注意的变化，其中包括：修复了MicrometerRecorder类中潜在的NullPointerException；在VertxPoolMetrics类中新增计数器rejected ，用来记录被拒绝的请求数；修复了VertxHttpExporter 类解析/v1/traces 端点有误的问题。要了解关于该版本的更多细节，请查看<a href=\"https://github.com/quarkusio/quarkus/releases/tag/3.3.1\">变更日志</a>\"。</p><p>类似的，Quarkus 3.2.5.Final<a href=\"https://quarkus.io/blog/quarkus-3-2-5-final-released/\">也带来了一些值得注意的变化</a>\"，其中包括：修复了当CsrfRequestResponseReactiveFilter类检查媒体类型时，<a href=\"https://quarkus.io/extensions/io.quarkus/quarkus-csrf-reactive\">跨站点请求伪造</a>\"扩展中潜在的NullPointerException；禁用ReactiveMongodbPanacheResourceTest类中的testMoreRepositoryFunctionalities()方法；修复了一个在多个线程中调用bean的写锁定方法时发生死锁的问题，其中该方法调用了同一bean中的另一个写锁定方法。要了解关于这个版本的更多细节，请查看<a href=\"https://github.com/quarkusio/quarkus/releases/tag/3.2.5.Final\">变更日志</a>\"。</p><p>最后，Quarkus 2.16.10.Final<a href=\"https://quarkus.io/blog/quarkus-2-16-10-final-released/\">发布</a>\"，将依赖项<a href=\"https://github.com/xerial/snappy-java/blob/master/README.md\">Snappy Java</a>\"从版本1.1.8.4升级到版本1.1.10.1。要了解关于该版本的更多细节，请查看<a href=\"https://github.com/quarkusio/quarkus/releases/tag/2.16.10.Final\">变更日志</a>\"。</p><p></p><h4>Micronaut</h4><p></p><p>Micronaut基金会<a href=\"https://micronaut.io/2023/09/01/micronaut-framework-4-1-0-released/\">发布</a>\"了<a href=\"https://micronaut.io/\">Micronaut Framework</a>\" 4.1.0版本，带来了<a href=\"https://github.com/micronaut-projects/micronaut-core//releases/tag/v4.1.3\">Micronaut Core 4.1.3</a>\"和一些新特性，其中包括：<a href=\"https://docs.micronaut.io/latest/guide/#beanMappers\">Bean映射器</a>\"自动创建一种类型与另一种类型的映射；新增一个Introspection Builder，如果一个类型只能通过构造器模式来构造，则可以利用@Introspected注解的builder成员来生成一个动态构造器；针对使用<a href=\"https://docs.micronaut.io/latest/guide/#ksp\">Kotlin符号处理</a>\"（KSP）构建Micronaut应用程序做了改进。要了解关于该版本的更多细节，请查看<a href=\"https://github.com/micronaut-projects/micronaut-platform/releases/tag/v4.1.0\">发布说明</a>\"。</p><p>Microaut Frameworkd 4.0.6（<a href=\"https://micronaut.io/2023/08/31/micronaut-framework-4-0-6-released/\">第6个维护版本</a>\"）升级了以下模块：<a href=\"https://micronaut-projects.github.io/micronaut-spring/latest/guide/\">M</a>\"<a href=\"https://micronaut-projects.github.io/micronaut-spring/latest/guide/\">icro</a>\"<a href=\"https://micronaut-projects.github.io/micronaut-spring/latest/guide/\">n</a>\"<a href=\"https://micronaut-projects.github.io/micronaut-spring/latest/guide/\">aut for Spring</a>\"、<a href=\"https://micronaut-projects.github.io/micronaut-jaxrs/latest/guide/\">M</a>\"<a href=\"https://micronaut-projects.github.io/micronaut-jaxrs/latest/guide/\">icro</a>\"<a href=\"https://micronaut-projects.github.io/micronaut-jaxrs/latest/guide/\">n</a>\"<a href=\"https://micronaut-projects.github.io/micronaut-jaxrs/latest/guide/\">aut JAX-RS</a>\"、<a href=\"https://micronaut-projects.github.io/micronaut-servlet/latest/guide/\">M</a>\"<a href=\"https://micronaut-projects.github.io/micronaut-servlet/latest/guide/\">icro</a>\"<a href=\"https://micronaut-projects.github.io/micronaut-servlet/latest/guide/\">n</a>\"<a href=\"https://micronaut-projects.github.io/micronaut-servlet/latest/guide/\">aut Servlet</a>\"、<a href=\"https://micronaut-projects.github.io/micronaut-validation/latest/guide/\">M</a>\"<a href=\"https://micronaut-projects.github.io/micronaut-validation/latest/guide/\">icro</a>\"<a href=\"https://micronaut-projects.github.io/micronaut-validation/latest/guide/\">n</a>\"<a href=\"https://micronaut-projects.github.io/micronaut-validation/latest/guide/\">aut Validation</a>\"、<a href=\"https://micronaut-projects.github.io/micronaut-redis/latest/guide/\">M</a>\"<a href=\"https://micronaut-projects.github.io/micronaut-redis/latest/guide/\">icro</a>\"<a href=\"https://micronaut-projects.github.io/micronaut-redis/latest/guide/\">n</a>\"<a href=\"https://micronaut-projects.github.io/micronaut-redis/latest/guide/\">aut Redis</a>\"、<a href=\"https://micronaut-projects.github.io/micronaut-tracing/latest/guide/\">M</a>\"<a href=\"https://micronaut-projects.github.io/micronaut-tracing/latest/guide/\">icro</a>\"<a href=\"https://micronaut-projects.github.io/micronaut-tracing/latest/guide/\">n</a>\"<a href=\"https://micronaut-projects.github.io/micronaut-tracing/latest/guide/\">aut Tracing</a>\"、<a href=\"https://micronaut-projects.github.io/micronaut-aws/latest/guide/\">M</a>\"<a href=\"https://micronaut-projects.github.io/micronaut-aws/latest/guide/\">icro</a>\"<a href=\"https://micronaut-projects.github.io/micronaut-aws/latest/guide/\">n</a>\"<a href=\"https://micronaut-projects.github.io/micronaut-aws/latest/guide/\">aut AWS</a>\"和<a href=\"https://micronaut-projects.github.io/micronaut-kafka/latest/guide/\">M</a>\"<a href=\"https://micronaut-projects.github.io/micronaut-kafka/latest/guide/\">icro</a>\"<a href=\"https://micronaut-projects.github.io/micronaut-kafka/latest/guide/\">n</a>\"<a href=\"https://micronaut-projects.github.io/micronaut-kafka/latest/guide/\">aut Kafka</a>\"。要了解关于该版本的更多细节，请查看<a href=\"https://github.com/micronaut-projects/micronaut-platform/releases/tag/v4.0.6\">发布说明</a>\"。</p><p></p><h4>WildFly</h4><p></p><p><a href=\"https://www.wildfly.org/\">WildFly</a>\" 29.0.1<a href=\"https://www.wildfly.org/news/2023/08/23/WildFly2901-Released/\">发布</a>\"，带来了组件升级（从Quickstarts 29.x迁移到BOMs and WildFly Server 29.0.1.Final）和一些值得注意的Bug修复，其中包括：新依赖项org.jboss.jts to jdk.jconsole 导致WildFly 29.0.0不能在Eclipse Temurin 17.0.8上启动的问题；将依赖项升级到<a href=\"https://github.com/square/okio/blob/master/README.md\">Square Okio</a>\" 3.4.0，以解决<a href=\"https://nvd.nist.gov/vuln/detail/CVE-2023-3635\">CVE-2023-3635</a>\"漏洞（可能导致Okio客户端在通过GzipSource类处理精心制作的GZIP归档文件时发生拒绝服务）；升级到WildFly 29.0.0后与MicroProfile RestClient和Jakarta CDI规范有关的问题。要了解关于该版本的更多细节，请查看<a href=\"https://github.com/wildfly/wildfly/releases/tag/29.0.1.Final\">发布说明</a>\"。</p><p></p><h4>Hibernate</h4><p></p><p><a href=\"https://hibernate.org/orm/\">Hibernate ORM</a>\"的6.3.0和6.2.8版本<a href=\"https://in.relation.to/2023/08/31/orm-630/\">发布</a>\"，带来了一些值得注意的变化，其中包括：初步支持Jakarta EE 11的<a href=\"https://jakarta.ee/specifications/persistence/3.2/\">Jakarta Persistence 3.2</a>\"规范，包括明确了HQL/JPQL查询中的<a href=\"https://hibernate.atlassian.net/browse/HHH-17076\">数值字面量类型</a>\"；新的<a href=\"https://docs.jboss.org/hibernate/orm/6.3/introduction/html_single/Hibernate_Introduction.html\">Hibernate 6入门指南</a>\"；<a href=\"https://docs.jboss.org/hibernate/orm/6.3/introduction/html_single/Hibernate_Query_Language.html\">Hibernate查询语言新语法和新特性指南</a>\"；作为JPA静态元模型生成器的一部分，能够为命名查询生成DAO风格的方法；生成器可以处理任意方法，而且创建出的查找器方法与使用新注解@Find的查询方法类似。</p><p><a href=\"https://hibernate.org/reactive/\">Hibernate Reactive</a>\" 2.0.5.Final<a href=\"https://in.relation.to/2023/09/01/hibernate-reactive-2_0_5_Final/\">发布</a>\"，兼容Hibernate ORM 6.2.8.Final和Vert.SQL driver 4.4.5。值得注意的变化包括：MutinyGenerator类中定义的generate()方法返回类型从Uni更改为Uni<!--?-->；增加了针对@TimeZoneStorage注解的测试；新增ParametersProcessorTest类来修复OracleParameters、PostgresParameters 和SQLServerParameters类处理参数时的转义问题。要了解关于该版本的更多细节，请查看<a href=\"https://github.com/hibernate/hibernate-reactive/releases/tag/2.0.5\">发布说明</a>\"。<p></p><p></p><h4>Eclipse基金会</h4><p></p><p>Eclipse <a href=\"https://glassfish.org/\">GlassFish</a>\" 7.0.8是<a href=\"https://twitter.com/OmniFishEE/status/1696188972630737402\">第8个维护版本</a>\"。该版本初步支持JDK 21，并优化了CDI扩展，减少了非必要的ProcessAnnotatedType接口处理程序调用。它还带来了一些值得注意的Bug修复，包括：RWLockDataStructureTest类中的一个JDK 11兼容性问题；多jar文件兼容性问题；管理员用户将密码改为空时的Admin Console行为。要了解关于该版本的更多细节，请查看<a href=\"https://github.com/eclipse-ee4j/glassfish/releases/tag/7.0.8\">发布说明</a>\"。</p><p>Eclipse <a href=\"https://vertx.io/\">Vert.x</a>\" 4.4.5<a href=\"https://vertx.io/blog/eclipse-vert-x-4-4-5/\">发布</a>\"，带来了依赖项升级和一些值得注意的变化，其中包括：改进ForwardedParser类，支持未用方括号括起来的IPV6地址；在实现WebSocketBase接口时，将帧聚合器与帧处理程序解耦；修复了HTTP/2在超时时抛出HttpClosedException而不是TimeoutException的问题。要了解关于该版本的更多细节，请查看<a href=\"https://github.com/vert-x3/wiki/wiki/4.4.5-Release-Notes\">发布说明</a>\"和<a href=\"https://github.com/vert-x3/wiki/wiki/4.4.5-Deprecations-and-breaking-changes\">弃用及破坏性变更清单</a>\"。</p><p>Eclipse <a href=\"https://github.com/eclipse/jkube/blob/master/README.md\">JKube</a>\" 1.14.0<a href=\"https://blog.marcnuri.com/eclipse-jkube-1-14\">发布</a>\"（一个用于Kubernetes和OpenShift的Java工具和插件实用程序），带来了Bug修复、改进，并支持Gradle 8、Helidon、Spring Boot <a href=\"https://docs.spring.io/spring-boot/docs/2.3.0.RELEASE/maven-plugin/reference/html/#repackage-layers\">Layered Jar</a>\"和向OCI注册中心推送<a href=\"https://helm.sh/\">Helm</a>\" chart。要了解关于该版本的更多细节，请查看<a href=\"https://github.com/eclipse/jkube/releases/tag/v1.14.0\">发布说明</a>\"。</p><p></p><h4>JReleaser</h4><p></p><p><a href=\"https://jreleaser.org/\">JR</a>\"<a href=\"https://jreleaser.org/\">elease</a>\"<a href=\"https://jreleaser.org/\">r</a>\" 1.8.0版本<a href=\"https://andresalmiray.com/jreleaser-1-8-0-has-been-released/\">发布</a>\"（一个简化项目发布的Java实用程序），提供了文档改进、依赖项升级和一些值得注意的变化，其中包括：为缺失的announcer创建默认模板；升级到最新的SDKMan端点；改进GitHub 422错误响应的错误处理。要了解关于该版本的更多细节，请查看<a href=\"https://github.com/jreleaser/jreleaser/releases/tag/v1.8.0\">发布说明</a>\"。</p><p>值得注意的是，SLSA（<a href=\"https://slsa.dev/\">Supply Chain Levels for Software Artifacts</a>\"）已经<a href=\"https://slsa.dev/blog/2023/08/bring-your-own-builder-github\">宣布</a>\"与JReleaser、Maven和Gradle的贡献者合作<a href=\"https://slsa.dev/blog/2023/04/slsa-v1-final\">发布</a>\"SLSA 1.0。这验证了GitHub Actions BYOB（<a href=\"https://github.com/slsa-framework/slsa-github-generator/tree/main#build-your-own-builder\">Build Your Own Builder</a>\"）框架的设计，并证明了它的灵活性。</p><p></p><h4>OpenXava</h4><p></p><p><a href=\"https://openxava.org/\">OpenXava</a>\" 7.1.5<a href=\"https://openxava.org/blog/openxava-7.1.5-released\">发布</a>\"，带来了一些显著的变化，其中包括：新增CompositeFilter类，用于在 Tab.setFilter()中同时使用两个IFilter，也可作为 @Tab注解的IFilter；新增环境变量XAVA_CALENDAR_VIEWEVENT_ACTION，用于定义日历单击事件的动作；修复在 @Editor(\"ValidValuesRadioButton\")中使用枚举时会在日志中产生IndexOutOfBoundsException异常的问题。要了解关于该版本的更多细节，请查看<a href=\"https://github.com/openxava/openxava/releases/tag/7.1.5\">发布说明</a>\"。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/09/java-news-roundup-aug28-2023/\">https://www.infoq.com/news/2023/09/java-news-roundup-aug28-2023/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/3EO246XRyUiAlTfku9mv\">Java 近期新闻：JDK 21 RC1、Apache Camel 4.0、Payara Platform、Apache Tomcat、Micronaut</a>\"</p><p><a href=\"https://www.infoq.cn/article/ClW8eLeOxRUqqpHWOJCC\">Java ZGC 垃圾收集器全面增强</a>\"</p><p></p></p>",
    "publish_time": "2023-09-12 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Ruby on Rails的创始人将TypeScript从Turbo框架中移除，引起社区不满",
    "url": "https://www.infoq.cn/article/N8QIk2frWWIJbHCMrA0W",
    "summary": "<p>Ruby on Rails 的创建者 David Heinemeier Hansson（DHH） 从即将发布的 Turbo 框架第 8 版中删除了 TypeScript，并声称从未是它的粉丝。许多 Turbo 用户抗议说决定太仓促，不欢迎这种变化。</p><p>&nbsp;</p><p>在移除 TypeScript 的 GitHub <a href=\"https://github.com/hotwired/turbo/pull/971\">pull request</a>\" 上有一条评论认为，这个举措“对于库的用户和贡献者都是一种倒退”。截止目前，这条评论已经有357个赞，仅8个踩，显示了广泛的支持。</p><p>&nbsp;</p><p><a href=\"https://turbo.hotwired.dev/\">Turbo</a>\" 是一个用于传递 HTML 页面的框架，旨在“显著减少自定义 JavaScript 的数量”，并由 Hannson 的公司 37signals 赞助，其产品包括 Basecamp 项目管理平台和 Hey 消息系统。Turbo 是 Hotwire 的引擎，Hotwire 是“HTML over the wire”的缩写，因为它更喜欢发送 HTML 本身而不是 JSON 数据和 JavaScript 代码。</p><p>&nbsp;</p><p>尽管 Turbo 并不属于那批最受欢迎的框架，但 Ruby on Rails 很有名，像 GitHub 和 Shopify 这样的主要网站都在使用它。</p><p>&nbsp;</p><p>Hansson <a href=\"https://world.hey.com/dhh/turbo-8-is-dropping-typescript-70165c01\">发文</a>\"称 TypeScript “通过添加微不足道的类型技巧，让我的开发体验变得更加糟糕，而且频繁引发很多困扰。本应简单的事情反而变得很困难。”</p><p>围绕着 Turbo 开源项目的社区大多感到困惑和失望，不仅是因为变更本身，还因为变更的方式。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c3/c305bb08962171e1598bd37ec9bf28a2.png\" /></p><p></p><p>\"回到 JS 意味着许多 Hotwire 生态系统的包都会受到影响。当前的所有开放 PR 都已完全过时。从我的角度来看，其中一些是非常好的候选项。IDE 不再提供与以前一样的自动补全功能，\" <a href=\"https://github.com/hotwired/turbo/pull/971#issuecomment-1708302536\">一位用户表示</a>\"。</p><p>&nbsp;</p><p>另一位用户<a href=\"https://github.com/hotwired/turbo/pull/971#pullrequestreview-1613489798\">抱怨</a>\"说：“匆忙进行这个重要的更改，忽视了所有（我是说所有）的 PR 评论...这会开一个坏头。Ruby on Rails 也会像这样来开发吗？取决于一个人的心血来潮？”</p><p>&nbsp;</p><p>Hansson <a href=\"https://github.com/hotwired/turbo/pull/971#issuecomment-1708430006\">回应</a>\"道：“非常感谢那些更喜欢 TypeScript 的贡献者。这只是争论之一，其中的论点不太可能改变任何人的根本立场，所以我不会尝试这样做。”</p><p>&nbsp;</p><p>他补充说：“现在，我们在 37signals 写的所有客户端代码都是纯 JavaScript，内部库也是如此。这次变更意味着保持一致。”</p><p>&nbsp;</p><p>微软的 Anders Hejlsberg 出于他的信念发明了 TypeScript，即如果使用强类型语言编写复杂应用程序，它们将更加健壮且易于维护。TypeScript 在编程社区的普及，表明了许多人持相同观点，而且一些来自 TypeScript 的概念，包括类型注解，也正在逐渐融入 ECMAScript，即 JavaScript 官方标准。无论开发者的选择如何，TypeScript 都会编译成 JavaScript，最终在浏览器或 Node.js 等环境中执行。</p><p>&nbsp;</p><p></p><h5>原文链接：</h5><p></p><p><a href=\"https://devclass.com/2023/09/07/ruby-on-rails-creator-removes-typescript-from-turbo-framework-upsets-community/?td=rt-3a\">https://devclass.com/2023/09/07/ruby-on-rails-creator-removes-typescript-from-turbo-framework-upsets-community/?td=rt-3a</a>\"</p><p></p><p></p><h5>相关阅读：</h5><p></p><p></p><p><a href=\"https://www.infoq.cn/article/3le2VX8uRPBOllXeoTKz\">重磅！OpenAI 开放 GPT-3.5 Turbo 微调，网友：将 prompt 减少 90% 才实惠&nbsp;</a>\"</p><p><a href=\"https://xie.infoq.cn/article/6ff79700fb3bfa972c1beebf3\">TypeScript 与 JavaScript：你应该知道的区别</a>\"</p><p><a href=\"https://www.infoq.cn/article/dDXbcLHT7teNYSPL3sm7\">“TypeScript 不值得！”前端框架 Svelte 作者宣布重构代码，反向迁移到 JavaScript 引争议</a>\"</p><p><a href=\"https://xie.infoq.cn/article/b7f556a866805cf5c71be7af8\">Typescript- 类型检测和变量的定义</a>\"</p>",
    "publish_time": "2023-09-12 09:46:56",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Slack蜂窝架构迁移：背后的技术策略与挑战",
    "url": "https://www.infoq.cn/article/JFv6Qoc3Nfe2Z1KblgA2",
    "summary": "<p>近年来，蜂窝架构（Cell-Based Architecture）作为一种增加冗余和有效限制站点故障影响范围的方式，在大型的在线服务中越来越流行。为了实现这些目标，在过去的一年半里，我们将Slack最关键的面向用户的服务从单体架构迁移到了基于蜂窝的架构。在本系列文章中，我们将解释我们为什么要进行大规模迁移、介绍蜂窝拓扑设计以及我们在此过程中所做出的工程技术权衡，并讨论我们成功对许多相连接的服务进行深度改造所采用的策略。</p><p>&nbsp;</p><p></p><h1>背景说明：事故</h1><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/32/325a2c99f5ee2777c35de46b84761a47.png\" /></p><p></p><p>2021年6月30日事故中的TCP重传图表</p><p>&nbsp;</p><p>在Slack，我们会在每一次发生明显的服务中断后进行一次事故评审。以下是我们内部事故评审报告的一些摘录，总结了其中的一起事故和我们的发现：</p><p>&nbsp;</p><p></p><blockquote>太平洋时间20121年6月30日上午11点45分，我们的云供应商在美国东海岸的一个可用区域发生网络中断，Slack的大部分服务都托管在那里。连接一个可用区域和其他几个包含Slack服务器的可用区域的网络链路发生了间歇性故障，导致Slack服务器之间的连接变慢，进而出现服务降级。&nbsp;太平洋时间2021年6月30日下午12点33分，我们的云供应商自动从服务中删除了网络链接，恢复了对Slack客户的全部服务。经过他们的一系列自动检查之后，网络链接再次进入服务状态。&nbsp;太平洋时间20121年6月30日下午5点22分，网络链路又发生了同样的间歇性故障。下午5点31分，云供应商永久地从服务中删除了网络链接，恢复了对我们全部的服务。</blockquote><p></p><p>&nbsp;</p><p>乍一看，这似乎没什么大不了。我们的服务所使用的一块物理硬件发生了故障，因此出现了一些错误，直到发生故障的硬件被移除。然而，在进行事故评审时，我们不禁问自己：让我们的用户体验到这样的中断是合理的吗？</p><p>&nbsp;</p><p>Slack运营着一个全球性的、多区域的边缘网络，但我们的大多数核心计算基础设施都位于单个地区（us-east-1）的多个可用区域内。可用区域（AZ）是指单个区域内的隔离的数据中心，它们除了可以提供物理隔离之外，也会限制我们所依赖的云服务组件（虚拟化、存储、网络等）的故障影响范围，这样就不会在多个AZ中同时发生故障。在云端托管服务的构建者（如Slack）可以通过这样的一种方式来构建服务——在一个区域内整个服务的可用性高于任何一个AZ的可用性。那么问题来了：为什么这个策略在6月30日没有奏效？为什么一个AZ发生故障会让用户体验到中断？</p><p>&nbsp;</p><p>事实证明，在分布式系统中检测故障是一个难题。来自用户的一个针对Slack API的请求（例如，在一个频道中加载消息）可能会扇出数百个发给后端服务的RPC，每个RPC都必须完成调用才能向用户返回正确的响应。我们的服务前端不断尝试检测和排除发生故障的后端，但在能够排除发生故障的服务器之前必须先将故障记录下来！让事情变得难上加难的是，我们的一些关键数据存储（包括我们的主数据存储Vitess）提供了高度一致的语义，这对应用程序开发人员来说非常有用，但也要求任何写入都要有可用的后端。如果一个分片主节点对应用程序前端不可用，那么到该分片的写入将会失败，直到主分片返回错误或一个次分片被提升为主分片。</p><p>&nbsp;</p><p>我们可以将上述的中断归类为灰色故障。在发生灰色故障时，系统可用性对于不同的组件来说是不一样的。在我们的事故中，受影响AZ内的系统看到其AZ内的后端完全可用，但AZ外的后端不可用。反过来，未受影响AZ内的系统看到受影响的AZ是不可用的。即使是同一个受影响的AZ内的客户端能够看到的后端可用性也是不一样的，这取决于它们的网络流量是否碰巧流经发生故障的设备。这就好比要求分布式系统在为我们的客户处理消息和提供小动物动图的同时处理好一切故障，这是一个相当复杂的任务。</p><p>&nbsp;</p><p>我们对这个难题的解决方案并不是试图去自动修复灰色故障，而是通过利用人类的判断力来让计算机的工作变得更容易。工程师们很清楚，在发生宕机时，主要的问题在于一个AZ不可达——我们汇总的目标AZ的每一张图表都与上面的重传图很相似。如果我们有一个可以告诉所有系统“这个AZ已坏，请避开它”的按钮，我们肯定会把它盘得发亮！因此，我们开始着手构建这样的按钮，可以将流量从AZ中抽走。</p><p>&nbsp;</p><p></p><h1>我们的解决方案：AZ就是会被引流的蜂窝单元</h1><p></p><p>&nbsp;</p><p>与其他许多基础设施一样，AZ引流按钮在概念上很简单，但在实践中却很复杂。我们的设计目标是：</p><p>&nbsp;</p><p>尽可能在5分钟内减少AZ内的流量。Slack的99.99%可用性SLA只允许我们每年不到1小时的总体不可用，因此，为了有效地保持这种可用性，我们需要能够快速奏效的工具。引流不能导致对用户可见的错误。引流是一种通用的缓解措施：只要故障包含在单个AZ内，即使尚未清楚导致故障的根本原因是什么，也可以有效地使用引流来缓解故障。这是一种实验性的方法，在发生故障期间，运维人员可以尝试对AZ进行引流，看看故障是否能够恢复，如果不能，则进行放流。如果引流会导致额外的错误，那么这种方法就没有用了。引流和放流必须是增量的。在放流时，运维人员将流量的1%分配给AZ，看看它是否已经恢复。引流机制不能依赖于被引流的AZ内的资源。例如，只是通过向每台服务器发送SSH命令并强制其关闭健康检查机制来激活引流是不行的。这是为了确保即使AZ完全离线也可以进行引流。</p><p>&nbsp;</p><p>一种符合这些需求的简单实现是向每个RPC客户端发送一个信号，当客户端接收到这个信号时，它们会让流向特定AZ的一定百分比的流量失败。这个方案隐含了很多复杂性。Slack没有共享代码库，甚至没有共享运行时，处理用户请求的服务使用多种语言编写，如Hack、Go、Java和C++，这就需要为每一种语言单独实现客户端。除此之外，我们还支持许多内部服务发现接口，包括Envoy xDS API、Consul API，甚至DNS。况且，DNS没有为AZ或部分引流等机制提供抽象，客户端只希望能够解析DNS地址并接收IP列表。最后，我们在很大程度上依赖了开源系统，如Vitess，要修改代码，就需要在内部维护分支，并做一些额外的工作，将变更合并到上游，这并不是一份令人愉悦的差事。</p><p>&nbsp;</p><p>我们采用的主要策略叫作“筒仓（Siloing）”。如果服务只从其所在的AZ内接收流量，并且只向该AZ内的服务器发送流量，那么这个服务就可以被称为一个筒仓。从整体上看，这种架构的效果是：每个服务似乎都有N个虚拟服务，每个AZ中有一个。重要的是，我们可以通过对某个AZ内的用户请求进行重定向来有效地将AZ内所有筒仓服务的流量抽走。如果没有来自用户的新请求到达筒仓所在的AZ，那么这个AZ的内部服务自然会停止，因为它们没有新的工作要做。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/96b91fa8de07ddea5d77b5e442564d83.png\" /></p><p></p><p>我们最初的架构，后端分布在各个AZ中，因此错误会出现在所有AZ的前端</p><p>&nbsp;</p><p>最终，我们得到了一个蜂窝架构。所有服务都存在于所有AZ中，但每个服务只与其AZ内的服务通信。一个AZ内的系统故障被包含在该AZ内，我们可以动态路由流量以避开这些故障，只需在前端重定向即可。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/86/86ec2b2988618e82625195d13b5d599f.png\" /></p><p></p><p>筒仓架构，一个AZ中的故障被包含在该AZ中，流量可能被抽走</p><p>&nbsp;</p><p>有了筒仓架构，我们就可以将精力集中在一个地方来实现流量转换：将来自用户的查询路由到us-east-1区域的核心服务。在过去的几年里，我们进行了大量投入，从HAProxy迁移到了Envoy/xDS生态系统，因此我们所有的边缘负载均衡器现在都在运行Envoy，并从我们内部的xDS控制平面Rotor接收配置。因此，我们能够通过简单地使用两个开箱即用的Envoy功能来进行AZ引流：加权集群和基于RTDS的动态权重分配。在对一个AZ进行引流时，我们只需通过Rotor向边缘Envoy负载均衡器发送一个信号，指示它们在us-east-1重新分配每个AZ的目标集群权重。如果us-east-1某个AZ的权重变为零，Envoy将继续处理请求，但会将所有新请求分配给另一个AZ，也就完成了对这个AZ的引流。我们来看看这是如何满足我们的目标的：</p><p>&nbsp;</p><p>通过控制平面的传播为秒级，Envoy负载均衡器将立即应用新的权重。引流不会丢失请求，负载均衡层不会放弃任何一个查询。权重提供粒度为1%的增量式引流。边缘负载均衡器完全位于不同的区域，控制平面有区域副本，可以抵御任意的单AZ故障。</p><p>&nbsp;</p><p>下图是我们逐步将流量从一个AZ引到另外两个AZ时每个AZ的带宽情况。注意图中的“膝盖”部分，它反映了Envoy/xDS实现为我们提供的快速、大粒度的传播保证。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bd/bd7b81effa8e644b6a259149d7815a99.png\" /></p><p></p><p>单AZ的每秒查询走势</p><p>&nbsp;&nbsp;</p><p>原文链接：</p><p></p><p><a href=\"https://slack.engineering/slacks-migration-to-a-cellular-architecture/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTM1NDUwNDgsImZpbGVHVUlEIjoiZXpGV0loMmZYNkZWNDZVOCIsImlhdCI6MTY5MzU0NDc0OCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.E_FTADwFvxpEVro_6zuU3qcVnPYv5Uk-2h8-T6hWslk\">https://slack.engineering/slacks-migration-to-a-cellular-architecture/</a>\"</p><p></p><p></p><h5>相关阅读：</h5><p></p><p></p><p><a href=\"https://www.infoq.cn/article/LAYRE8jxE2z42QuU5pNX\">自定义跟踪架构：Slack&nbsp;高效解决通知问题</a>\"</p><p><a href=\"https://www.infoq.cn/article/9lp0pYfij3bUxmHDXkxl\">Slack实时消息处理架构，更新、更快、更稳定</a>\"</p><p><a href=\"https://www.infoq.cn/article/hhh8OGLNbsz121H43Df4\">Slack工程师如何解决最常见的移动开发痛点</a>\"</p><p><a href=\"https://www.infoq.cn/article/Pwkm3Ro1IqSzM3wLXvMS\">Zoom和Slack的第二曲线</a>\"</p>",
    "publish_time": "2023-09-12 09:49:15",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "隐私与安全同行：探索阿里云可信云架构与机密计算",
    "url": "https://www.infoq.cn/article/A1rDsG3luPU1eaRLcmO7",
    "summary": "<p>《英特尔®️ 至强®️ 实战课》新一期内容即将上线，大招来袭！本期以“大模型时代的云服务安全利器”为主题，邀请 InfoQ 极客传媒主编赵钰莹、英特尔首席工程师宋川、阿里云机密计算安全专家于国瑞、阿里云高级安全专家刘煜堃四位业内大咖，从基本原理、技术框架、场景案例等方面，详细阐述英特尔®️ 至强®️ 处理器机密计算在人工智能数据安全和隐私保护方面的应用及实践。通过本期课程，您将了解到当前云服务安全领域的前沿趋势和解决方案，并获得更专业的实战经验！</p>",
    "publish_time": "2023-09-12 11:11:50",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "《英特尔®️至强®️实战课》机密计算赋能数据为中心的云安全",
    "url": "https://www.infoq.cn/article/P2rM88BBFvQMxSLxxhUO",
    "summary": "<p>《英特尔®️ 至强®️ 实战课》新一期内容即将上线，大招来袭！本期以“大模型时代的云服务安全利器”为主题，邀请 InfoQ 极客传媒主编赵钰莹、英特尔首席工程师宋川、阿里云机密计算安全专家于国瑞、阿里云高级安全专家刘煜堃四位业内大咖，从基本原理、技术框架、场景案例等方面，详细阐述英特尔®️ 至强®️ 处理器机密计算在人工智能数据安全和隐私保护方面的应用及实践。通过本期课程，您将了解到当前云服务安全领域的前沿趋势和解决方案，并获得更专业的实战经验！</p>",
    "publish_time": "2023-09-12 11:13:43",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "腾讯云商业银行总经理曹骏确认出席 FCon ，分享商业银行核心系统国产化策略与实战",
    "url": "https://www.infoq.cn/article/uW0HmUR1tx8Z02iZXm3c",
    "summary": "<p><a href=\"https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle\">FCon 全球金融科技大会</a>\"，将于 11 月在上海召开。腾讯云商业银行总经理曹骏将发表题为《<a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5526?utm_source=infoqweb&amp;utm_medium=article\">商业银行核心系统国产化策略与实战</a>\"》主题分享，介绍在国产化的要求下如何通过云原生的思路来进行银行核心系统改造，为金融机构的 IT 从业者和为金融机构提供服务的 IT 从业者提供一些新的思路，以及对腾讯云近年来进行核心系统国产化实践过程中的经验和教训进行分析总结。</p><p></p><p><a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5526?utm_source=infoqweb&amp;utm_medium=article\">曹骏</a>\"，负责腾讯云在银行行业解决方案。曹骏先生多年服务于金融行业客户，是业内资深金融行业技术专家与云计算技术专家，具有超过 20 年的 IT 咨询服务和项目实施经验，为多家银行、保险、互联网金融机构提供 IT 战略规划、云计算等咨询规划与落地实施服务。 加入腾讯云之前，他曾任 IBM 中国资深架构师、微软全球服务部中国区金融行业首席架构师等职位。他在本次会议的演讲内容如下：</p><p></p><p>演讲：商业银行核心系统国产化策略与实战</p><p></p><p>商业银行的业务系统建设一直是电子化、数字化最为成熟且全面的行业之一。银行核心系统一直作为 IT 建设最为关键应用支撑着整个银行的商业运转，其业务系统的高性能、稳定性和安全防范以及系统数据的产生、传输、存储是 IT 行业者非常关注的方向。</p><p></p><p>本话题将结合腾讯云多年来的技术积累与项目实践，探讨在国产化的要求下如何通过云原生的思路来进行银行核心系统改造，为金融机构的 IT 从业者和为金融机构提供服务的 IT 从业者提供一些新的思路。也会对腾讯云近年来进行核心系统国产化实践过程中的经验和教训进行分析总结。</p><p></p><p>演讲提纲：</p><p></p><p>银行业核心系统的挑战与发展路径银行核心系统国产化过程中的挑战与应对云原生的银行核心系统总体架构与关键技术腾讯云的核心国产化落地实践</p><p></p><p>你将获得：</p><p></p><p>○ 了解银行核心系统的国产化技术方案和方案要点</p><p>○ 了解银行行业如何落地云原生、国产化的技术架构</p><p>○ 通过实际案例的分析获取更多技术落地的实践经验</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle\">DevOps&nbsp;在金融企业落地实践</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle\">金融行业大模型应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle\">创新的金融科技应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle\">金融实时数据平台建设之路</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle\">金融安全风险管控</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle\">数据要素流通与数据合规</a>\"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，前 100 人可享 5 折特惠购票，咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png\" /></p><p></p>",
    "publish_time": "2023-09-12 11:30:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "人红是非多！Rust社区冲突不断，创始人：别Call我了，我也救不了！",
    "url": "https://www.infoq.cn/article/6TzaQ6wNB9vd8SJ3RCet",
    "summary": "<p></p><blockquote>Rust为什么会有这么多管理上的问题？如果Rust采用由创始人治理的方式，会不会更好？实际上，Rust的创造者Graydon Hoare曾回应过这个问题，他认为如果是由他来治理的话，事情肯定会很不一样，但是Rust就不太可能像现在这样“出圈”。</blockquote><p></p><p>&nbsp;</p><p></p><h2>Rust团队冲突不断</h2><p></p><p>&nbsp;</p><p>前几天，作为Rust 发布团队（Release team）的一员，Jonas Schievink要求Rust团队从项目中删除掉和他有关的所有文件。</p><p>&nbsp;</p><p>“请求将我从‘校友’中删除，并删除和我的用户名绑定在一起的文件”，“我还想请求 Rust 团队从项目的commits中删除我所有作者信息。”</p><p>&nbsp;</p><p>“我不想再以任何身份参与 Rust 项目。”</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a6/a617983877cee47ef08c2d5f10d3a20e.jpeg\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>Jonas Schievink还吐槽了Rust领导团队，认为这些人“破坏了社区项目，并压制了公众讨论”。</p><p>&nbsp;</p><p>Rust团队一直风波不断。此前，还发生过为了抗议 Rust 核心团队（Core team），<a href=\"https://www.infoq.cn/article/798bgzaO1ujBgzQsAGHC\">审核团队集体辞职</a>\"的事情。他们认为 Rust 核心团队在执行社区行为准则和标准上让自己不受制约。Rust 核心团队并没有和其他成员遵循同样的行为准则 (CoC)，Coc 似乎变成了核心团队 “严于律人” 的工具。</p><p>&nbsp;</p><p>今年5月，Rust领导小组粗暴撤换RustConf主题演讲人，事态升级后<a href=\"https://www.infoq.cn/article/3vsBhtLeXU3QzBDuJ7AZ\">引发多人出走</a>\"。</p><p>&nbsp;</p><p>今年6月，在经历了多次治理风波后，Rust 项目宣布成立新的顶级治理机构：领导委员会（Rust Leadership Council）。由Rust 各团队成员合力创建一份新的、名为 “ Rust 领导理事会” 的 RFC 草案，并确立了以下内容：移除 Rust 核心团队，由各团队出一个代表，成立一个顶级的治理团队“领导委员会”。&nbsp;</p><p>&nbsp;</p><p>“领导委员会” 负责一些职责不清的工作安排及其优先次序，然后对这些工作进行精确到子团队或成员的委托。另外，“领导委员会” 还要以跨团队工作、规划和项目的长期成功等为目标，成为团队之间的协调、组织和问责机构。领导委员会还需要协调因项目而导致的团队、结构或流程的变化，确保顶层团队负起责任，并负责展示 Rust 项目的官方态度。</p><p>&nbsp;</p><p>可能“ Rust 领导理事会”还是没有解决好当前的各种乱象，所以Jonas Schievink又站了出来：“对最近 RustConf 主题演讲的怯懦处理只是最近的一个例子，而且它也不太可能是最后一个。即使领导结构发生了变化。永久解决这些问题的唯一方法是从 Rust 项目中完全驱逐那些对这些问题负责的人，或者为这些问题辩护的人。”</p><p>&nbsp;</p><p>Rust为什么会有这么多管理上的问题？如果Rust采用由创始人治理方式，是不是更好？实际上，Rust的创造者Graydon Hoare曾从侧面回应过这个问题，他认为如果是由他来治理的话，方向肯定会很不一样，但是Rust就不太可能像现在这样“出圈”。</p><p>&nbsp;</p><p>Rust最早诞生于2006年，刚开始只是Hoare的个人开发项目。但在发展过程中，Rust吸引到更多贡献者，并于2009年正式获得Mozilla的官方赞助。</p><p>&nbsp;</p><p></p><h2>Hoare表示自己也无法处理好各种冲突</h2><p></p><p>&nbsp;</p><p>Hoare在他的个人博客可以说是无所不聊。2023年他撰写了四篇文章，第一篇谈的是业余无线电技术，第二篇则是企业雇用的维护人员往往对于开源贡献没什么热情（他认为雇主应该引导这些「维护人员成为真正的维护者」）。</p><p>&nbsp;</p><p>然后，Hoare连发两篇博文，对Rust语言的演变进行了快速梳理。</p><p>&nbsp;</p><p>今年5月底，Graydon Hoare在自己的博客上回顾了Rust诞生历程。Hoare首先提醒读者，“我已经有十年没参与这个项目了”，所以“大家对我的一切言论都请保持谨慎态度，单纯把我看作一位曾经在重要阶段参与过Rust发展的当事人就好……”</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d9/d98923ca82fdc32c2104f970332a2b8e.jpeg\" /></p><p></p><p>&nbsp;</p><p>有趣的是，6月份发布的第二篇文章题为《我理想中的Rust不会有未来》（The Rust I Wanted Had No Future，<a href=\"https://graydon2.dreamwidth.org/307291.html\">https://graydon2.dreamwidth.org/307291.html</a>\"）。</p><p>&nbsp;</p><p>首先，Hoare提起最近人们执的问题，“你有没有想过在Rust项目中BDFL（终身扮演仁慈的独裁者？）”而如果他真的这样做了，Rust项目的发展会不会更加顺遂？BDFL是授予少数开源软件开发领导者的头衔，通常是在社区内的争议或争论中保留最终决定权的项目创始人。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ba/baf8b0e3ab3202b6cbbb11614947d62e.jpeg\" /></p><p></p><p>&nbsp;</p><p>Hoare首先给出了明确的回复，“不会。”他进一步补充道，“我不喜欢受到关注、也不喜欢公众压力。在2009年到2013年担任项目的技术主管时，我就已经快到极限了……另外，我觉得自己没办法建立起强大或者健康的团队制度，处理不好决策、冲突、授权和扩展之类的具体工作。”</p><p>&nbsp;</p><p>后来这篇文章被发到了Reddit上的Rust子论坛中，Hoare也经常在这里转悠。有位用户询问Rust最近的项目开发是否有所放缓，Hoare回应称“就主要功能来说，开发速度的适当放缓是有好处的。”</p><p>&nbsp;</p><p>而在他那篇文章的评论区中，Hoare本人表示“千万别让我聊类型参数里的尖括号和生命周期里的单引号！”</p><p>&nbsp;</p><p>有位Reddit用户倒是坚持跟进，而Hoare澄清说“我们曾经就这些语法问题展开过争论，但最后我失败了。”他甚至公开了一个指向“Rust prehistory”GitHub&nbsp;repo的链接，其中存放着13年前的Rust代码。可以看到，Hore当初是想在类型参数中使用方括号的，他补充说“我个人一直觉得，类型参数就应该使用方括号，根本不需要争论。”</p><p>&nbsp;</p><p>Hoare还反对在引用中显式使用生命周期，在他看来“生命周期几乎肯定可以推断出来，所以无论具体使用哪种语法，都没必要让开发者单独编写。但很明显，Rust最后没有顺着这个路子走。”Hoare后来在Reddit评论中感叹道，“终有一天，我可能会写篇〈我心目中的真正Rust〉的博文，告诉大家我当初想象中的Rust和如今真实的Rust间其实有着巨大差异。但请别误会，尽管大有不同，但我对Rust语言获得的成功仍然抱有巨大的成就感和满足感！”</p><p>&nbsp;</p><p></p><h2>希望Rust变更好</h2><p></p><p>&nbsp;</p><p>Hoare认为偏好差异的确真实存在，“我自己的偏好就比较特殊，可能跟大多数朋友有所不同。”</p><p>他强调他心目中的Rust“可能会让所有参与者都不满意，也没办法像现在这样真正破圈……”</p><p>&nbsp;</p><p>“请别误会我的意思：我对现在的结果非常满意。我很高兴行业中有了一种可行的C++替代方案，它给人们提供一种新的范式、一种可供日常使用的合理选项。我也在用Rust，也很高兴能有它来替代C++。但是……”</p><p>&nbsp;</p><p>在文中，Hoare也列出了“Rust中那些我特别不认可且/或目前不太喜欢的地方。”比方说，在文中“复杂的语法”这部分，Hoare就抱怨说Rust仍然难于解析。“它虽然比C++更易用，但跟C++比较本身就说明它的易用性不足。当初我也努力过，但从类型参数里的尖括号到模式绑定的歧义、再到分号和大括号的使用规则，我几乎在每个具体问题上都失败了……我现在甚至不想再谈这个话题，总之现在的语法跟我的设想相去甚远。抱歉了各位。”</p><p>&nbsp;</p><p>另一个例子，则是Rust处理类型的方式。Hoare本人更偏向“结构”类型（即只要各对象的结构相同，则其类型就相互兼容——不受声明时所使用的类型名称的影响）。Hoare还透露，“Rust语言最初带有（我也希望它能再次拥有）编译器发出的「类型描述符」，用户可以在其上调用反射算符。”</p><p>&nbsp;</p><p>Hoare对于Rust如何处理十进制浮点数也有不少想法。“基本上，每种语言都意识到金融数学有其特殊性，并最终添加了小数类型。我希望Rust能提前完成这项工作，但最终还是被放进了库里。虽然选项不少，但我觉得能内置的话也许更好……”</p><p>&nbsp;</p><p>还有更多例子，但Hoare倒是没有列举他的构想跟现在真实Rust之间的差异。相反，“重要的是表达当时在各个设计主题上的分歧。”</p><p>&nbsp;</p><p>Hoare写道，“我在研究这门语言时考虑的各种优先事项，基本上跟围绕该语言发展出来的社区所认定的优先事项出现了巨大偏差。甚至经过多年发展，我关注的那些问题还是没有得到重视。”</p><p>&nbsp;</p><p>“我会为了简单性而牺牲性能和表达力——也就是更强调帮助最终用户减轻认知负荷、在编译器中降低实现难度。我觉得这才是Rust的正确发展方向，但事实证明这似乎跟大多数人对于Rust的预期截然相反。”</p><p>&nbsp;</p><p>Hoare甚至给出了不少细节：</p><p>“Rust社区中的很多人认为「零成本抽象」是Rust语言的核心承诺。我永远不会这么讲，而且我个人觉得这种机制本身就有问题。这是种典型的C++思路，对设计空间造成了不必要的限制……换作是我，会更倾向用大量相对较小的恒定性能成本，来替代包含大量抽象的所谓更简单/更强大的版本，哪怕语言的实际性能会变得更慢。”“同样的，我也会牺牲掉一部分表达力。但这可能会让很多现代Rust程序员感觉不爽，认为Rust项目既笨拙又充满官僚气息、像是一种保姆式语言，根本不允许用户在库代码中编写各类功能，甚至不信任程序员用变量隐藏、环境捕捉或内联函数等简单结构。”</p><p>&nbsp;</p><p>大家可以想见，这篇博文在登陆Reddit之后，很快引起了各种各样的讨论。一位用户明确表示：“我真希望能拥有Hoare设想中的Rust，那听起来很美。”</p><p>&nbsp;</p><p>但另一位评论者似乎更加务实更改，认为“他的Rust不会更好，只是跟现状不同……”</p><p>&nbsp;</p><p>“我倒是更喜欢如今的Rust……我喜欢性能更高而且脚踏实地的代码，而真实的Rust恰好给了我这些。”</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://twitter.com/sheevink\">https://twitter.com/sheevink</a>\"</p><p><a href=\"https://graydon2.dreamwidth.org/307105.html\">https://graydon2.dreamwidth.org/307105.html</a>\"</p><p><a href=\"https://graydon2.dreamwidth.org/307291.html\">https://graydon2.dreamwidth.org/307291.html</a>\"</p><p><a href=\"https://github.com/oxidecomputer/oxide-and-friends/blob/master/2023_05_30.md\">https://github.com/oxidecomputer/oxide-and-friends/blob/master/2023_05_30.md</a>\"</p><p><a href=\"https://thenewstack.io/graydon-hoare-remembers-the-early-days-of-rust/\">https://thenewstack.io/graydon-hoare-remembers-the-early-days-of-rust/</a>\"</p>",
    "publish_time": "2023-09-12 15:00:32",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从计算到智算，如何降低 AI 算力使用门槛？ | InfoQ《极客有约》",
    "url": "https://www.infoq.cn/article/2RLlk4XePkSXUNU4eQIw",
    "summary": "<p>随着生成式 AI 技术得到广泛应用，算力产业正从“计算”迈向“智算”，这一变化给算力产业带来哪些挑战？不同应用场景对算力芯片的运算能力有何需求？如何降低 AI 算力使用门槛？本期，我们邀请到了大禹智芯产品及解决方案负责人余曦老师，为大家分享《从计算到智算，如何降低 AI 算力使用门槛？》。</p>",
    "publish_time": "2023-09-12 15:08:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "深度解读字节跳动的画质评估工具：抖音也在用~",
    "url": "https://www.infoq.cn/article/Vsc9cCloJx9mCOTyURGT",
    "summary": "<p>本文从抖音集团内部画质评估体系的建设历程着笔，主要分享画质评测对于业务的重要性、主要应用场景和内部产品的一些典型实践案例，希望通过分享业务视角遇到的一些问题和解决思路，能够为遇到类似困扰的伙伴提供有价值的参考。</p><p></p><h2>一、画质评估体系建设历程</h2><p></p><p></p><h3>（一）为何评测画质如此重要？</h3><p></p><p></p><p>我们通过线上业务大量实验发现，图片画质优劣对点击率、&nbsp;停留时长等消费类指标有正相关影响，间接影响用户收益指标。因此，建设一套行之有效的画质评估体系，保障用户的画质体验是非常有必要性的。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/93/93d84ba57ceb929a4647ec913efa78bb.png\" /></p><p></p><p>直观来讲，画质提升能够为带来更好的观感体验，但 QoE 综合体验也需要考虑其他方面如用户设备、网络状况、观看环境等多方面因素，不计成本地提升画质是否能持续为用户带来 QoE 的收益需要在业务场景中通过严谨的实验方案来验证效果的。</p><p></p><p>在低质图像打压和基于画质的推荐优化等多项业务中的数据分析积累沉淀，我们获取画质评分与用户主观体验之间的明确关系，数据统计显示用户对不同画质内容的敏感程度有着不同趋势，在中档画质分区间持续提升画质，用户的 QoE 体验也会显著提升，但当画质低于或者高于某个阈值时，用户对于画质将变得不再敏感，提升/降低画质对用户的影响均会降低。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/94/94a1187dfc0e3a9f89ea5c68ec6557e1.png\" /></p><p></p><p>期望中的画质甜点关系，中段区间的画质提升会持续带来 QoE 收益：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/94/94c9f701a2646c1146f84d35ca4a8a66.png\" /></p><p></p><p>实际业务场景中，分析画质与用户平均观看时长的关系，中高画质可以带来持续的看播收益。下图具体描述了两类典型应用场景下，画质评估体系在业务实践中发挥的主要价值：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dc/dc6695ca49b86c25f54bf62ff9526f17.png\" /></p><p></p><p></p><h3>（二）我们为何自研画质评估体系？</h3><p></p><p></p><p>图像服务的最终用户是人类，图像质量评价致力于成为可衡量图像的人眼感知质量需求的客观计算方法。</p><p></p><h4>1、行业现状</h4><p></p><p>主观质量评估：最准确，但费时费力费钱，难以批量应用。例如专家评测、众包测试等。客观评估算法：省时省力可大规模应用，但无论全参/无参考算法与主观评测均存在一定 GAP，在 UGC 场景，差距会更加明显。</p><p></p><p>业界常用的有参画质评估算法，主要包括 PSNR、SSIM、VMAF 3种：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d0/d0b664cb786f9f833b5ff43f7907031f.png\" /></p><p></p><h4>2、痛点</h4><p></p><p>难以量化画质增强效果：行业通用指标（ PSNR、SSIM、VMAF等）均为有参考画质指标， 主要适用于压缩失真的画质评估，难以量化评估画质增强效果。不适合&nbsp;UGC&nbsp;场景的评分：行业通用指标适用场景存在一定局限性，其训练数据集主要为 PGC 内容，在 UGC 场景的泛化效果较差。评估维度有限：UGC 场景下，图片内容复杂且画质影响因素多样，需要更多维度评估指标用于画质分析和指导优化。</p><p></p><h4>3、我们如何建设画质评估体系？</h4><p></p><p></p><p>根据点播、直播和图片等不同形态业务需求，视频架构多媒体实验室自研的 VQScore 画质体系提供配套最优的全链路画质打分能力，提供异步或实时画质打分数据，为后续转码、增强、推荐策略和大盘监控提供能力支持。</p><p></p><p>具体画质分析打分能力分为两个部分：</p><p>内容分析理解：主要包含 ROI 检测、CG 内容检测、人脸检测、内容分类等基础分类和检测的能力，为后续画质打分和增强转码提供细分的维度拆解能力和关键内容识别能力，实现精细准确的端到端自适应增强转码组合能力画质打分能力：主要包含通用清晰度打分算法、美学指标、高阶色彩指标、人像画质等评估指标，噪声、块效应、过曝、脏镜头、模糊和伪高清等细分归因指标，以及超分质量、锐化质量和增强组合评估等前处理画质提升能力评估指标，通用+归因+增强多个维度组合，为不同的业务场景的画质优化需求提供集监控、分析、策略推荐等全方位画质打分能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/33/33efc2a96fdd4c0545968c783205483a.png\" /></p><p></p><p>通用的画质清晰度评估算法基于多样化多业务场景主观标注样本、开源数据集和多样化失真合成数据集，驱动的轻量 transformer-based 深度学习的方案，在 UGC 视频/图像场景提供更稳定准确的客观清晰度预测能力。</p><p></p><p>在多种业务场景下，根据点播、直播和图片不同形态业务需求，支持最高4K分辨率内不同投稿内容的源画质分析，结合业务属性维度提供深入细化的画质维度分析，为自适应转码提供编码优化对比和不同时间尺度的画质监控，为 AB 实验和版本迭代等业务流程提供有效的QoE维度数据，同时也可以为多分辨率/码率档位播放下发提供画质与 QoS 网络、设备等因素组合组合的自适应播放分发优化能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/aa/aa473e297ed0e365080b62a1c8e7cab6.png\" /></p><p></p><h3>（三）抖音画质评估体系有哪些优势？</h3><p></p><p></p><h4>1、适用范围广泛</h4><p></p><p></p><p>高质量且规模庞大的训练数据集，覆盖 PGC 和 UGC 内容，适用范围广泛（特别针对 UGC <a href=\"https://www.infoq.cn/article/z1CW0cFhLxLi2KYk258t\">场景</a>\"）。算法模型历经亿级 DAU 产品持续打磨优化，泛化能力强。</p><p></p><h4>2、评估维度多元</h4><p></p><p></p><p>包含主观清晰度、大众美学质量等两类综合指标和噪声、亮度等十余类细分指标，支持更多维度、更细粒度地分析画质问题，便于业务有针对性地进行优化和调整策略。</p><p></p><h4>3、多业务线上验证收益显著</h4><p></p><p></p><p>历经抖音、头条、番茄小说等数十个大体量业务线上验证，评估效果可靠，能有效支持业务进行画质体验提升，进而带来用户消费指标提升，收益<a href=\"https://www.infoq.cn/news/WPmK0BeY0dDJB6wLL0zM\">显著</a>\"。</p><p></p><h4>4、算法能力业内领先</h4><p></p><p></p><p>画质评估体系涉及的算法模型已申请多项专利。eg. 一种检测伪高清视频的方法，一种基于多任务孪生神经网络的高阶视频色彩质量评价模型，一种三明治视频自适应播放方法等。</p><p></p><p>在 ICME 2021 的「压缩UGC视频质量评估」比赛中，火山引擎-多媒体实验室凭借自研的 VQScore 算法斩获无参考视频质量评价（NR-VQA）MOS 赛道第一名。（<a href=\"https://mp.weixin.qq.com/s?__biz=MzU1NTEzOTM5Mw==&amp;mid=2247512713&amp;idx=2&amp;sn=525ebd47bb4a8ecff2139bf8cf3dd260&amp;scene=21#wechat_redirect\">详细介绍</a>\"）</p><p></p><blockquote>该比赛主要针对 UGC 源视频画质和 H.264/AVC 压缩失真对视频主观画质的影响的研究。</blockquote><p></p><p></p><p></p><h2>二、画质评估主要应用在哪些场景？</h2><p></p><p></p><p>以瘦身计划和体重秤之间的关系做个简单类比，画质评估体系作为一套相对客观且行之有效的评测工具，在帮助产品了解业务画质现状、了解行业和市场现状、监测线上<a href=\"https://www.infoq.cn/article/yoQtcCA6p3arSMemh0ZG\">画质</a>\"变化和支持提升用户体验等方面都有非常广泛的应用。</p><p></p><p>了解业务画质现状</p><p></p><p>业务团队可以借助 veImageX 提供的画质评估工具，通过离线测评和在线评估等手段高效完成业务产品的画质摸底；同时，画质评估体系包含丰富的评测维度（例如噪声强度、色彩质量、块效应检测、过曝光检测等），数十项细分评测指标可高效帮助业务团队完成低质图像归因分析，快速锁定问题所在。</p><p></p><p>了解行业/市场现状</p><p></p><p>借助画质评估工具，可以帮助业务团队对市场主流产品或同类业务进行画质评测，以便制定合理的画质提升目标；同时，综合用户主观评测和客观指标的对应关系，高效帮助业务团队确定适合自身业务的画质评估标准。</p><p></p><p>监测线上画质变化</p><p></p><p>对于一款关注用户画质体验的产品来说，线上画质监测工具必不可少。而 veImageX 提供端到端的画质指标监测工具，可帮助业务团队长期高效监测线上画质变化；通过前后数据对比分析，帮助业务有效验证画质优化举措的效果；同时，线上低质问题告警也可帮助业务团队及时发现问题，保障线上用户浏览体验。</p><p></p><p>支持提升用户体验</p><p></p><p>借助画质评估体系提供的评测结果，业务团队可以通过对低质图片进行搜索/推荐降权等方式打压低质内容，或借助画质增强能力提升画质，有效提升用户的浏览体验，进而带来点击率、人均阅读/消费时长、用户留存等业务指标正向提升。</p><p></p><p></p><h2>三、典型案例实践分享</h2><p></p><p></p><p>目前，由火山引擎 veImageX 提供的画质评估工具已服务于抖音、头条、西瓜、番茄小说、懂球帝等数十条业务线，在保障用户的画质体验方面发挥着重要作用。接下来，我们选取了几个典型案例为大家简要分享我们的实践经验。</p><p></p><h3>（一）某短视频/社区平台</h3><p></p><p></p><h4>1、需求背景</h4><p></p><p>某短视频/社区平台是主要用户分布在多个国家和地区，发布内容覆盖多个细分垂类。业务团队收到部分用户反馈关注到不同国家和内容垂类间的画质存在一定差异，影响了用户的浏览体验，从而设立专项进行问题解决。</p><p></p><h4>2、实践方案</h4><p></p><p>业务团队首先使用画质评估工具对全地区的图片画质进行了离线摸底分析，发现部分国家间、某些重点垂类间的图片画质有较大差异，故使用自适应增强模型，针对性进行画质提升的同时尽可能节省码率。</p><p></p><h4>3、整体收益</h4><p></p><p>优化后，该平台各地区间、重点垂类间的画质基本拉齐且均达到【良好】及以上水平，图片大小显著降低，人均停留时长、人均互动、人均阅读时长、人均 session 次数等消费指标均显著正向。</p><p></p><h3>（二）番茄小说</h3><p></p><p></p><h4>1、需求背景</h4><p></p><p>相比于网文，漫画的书封更加精美，信息量也更多，因此在产品形态上，番茄小说频道采用了大屏的展现形式。然而，在漫画功能上线后，业务团队发现，有部分漫画的原始书封比较模糊，严重影响用户浏览体验。如下图所示：</p><p><img src=\"https://static001.geekbang.org/infoq/00/009755aed925213c41d2afcfbea8f7e1.png\" /></p><p></p><p>为了提升这部分图片的画质，业务团队想到了通过画质评估筛查低质图片，使用画质增强能力搭建自动化处理流程，针对性处理低质图片，得到高清图，以提升整体观感。</p><p></p><h4>2、实践方案</h4><p></p><p>业务团队使用 veImageX 画质评估工具，针对出版物（如小说封面、插图、电子书书封、有声播放器封面等）&nbsp;和漫画（漫画封面、横图等）&nbsp;等场景进行离线画质测评，对不同分辨率图片进行画质摸底。根据对低质原因的分析和增强算法对主观画质提升的收益大小综合评估，明确差异化的处理方案。最终业务团队选择搭建自动化处理流程，根据评估结果对不同画质等级的图片进行如自适应增强、超分等优化处理，针对性提升用户的画质浏览体验。</p><p></p><p>低质图片优化前后对比如下：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/03/03028351146a8a60c10a30e44aa320bf.png\" /></p><p></p><h4>3、整体收益</h4><p></p><p>番茄小说团队借助 veImageX 画质评估和画质增强能力，有的放矢的提升画质，有效提升了用户画质体验和点击率、人均阅读/消费时长、留存等用户消费指标。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b3/b3794655873870e47f7a5a341e2149bf.png\" /></p><p></p><h3>（三）今日头条</h3><p></p><p></p><h4>1、需求背景</h4><p></p><p>头条小视频频道主要以双列展示为主，而双列流频道展现形式又以封面图为主。综合线上实验结果和实践经验发现，封面图的画质质量不仅会影响用户浏览体验，也会影响点击转化率和用户留存等业务指标，如何有效识别封面模糊的内容并进行打压调控成为一项较为棘手的工作。</p><p></p><h4>2、实践方案</h4><p></p><p>借助画质评估工具，业务团队对封面图进行画质打分，高效识别出低质封面（blockiness≥ X且vqscore&lt; Y）并实行打压调控策略；同时将 vqscore 纳入推荐模型的参考指标，给优质内容提供更多优先曝光机会。</p><p></p><h4>3、整体收益</h4><p></p><p>业务团队通过对低质封面图进行打压调控，人工评估封面优质率提升约3倍，封面低质率降低了约36.7%&nbsp;，模糊封面图占比降低了约 51.4%&nbsp;，人均阅读数、&nbsp;停留时长&nbsp;、点击转化率等业务指标也得到显著提升。（数据来自业务AB实验）</p><p></p><p></p><h3>（四）幸福里VR</h3><p></p><p></p><h4>1、需求背景</h4><p></p><p>幸福里房产 VR 能力在建设初期，因素材供给来源多样且渠道纷杂，质量良莠不齐，频繁收到线上用户反馈；图像质量把控主要依靠人工审核、定期抽检和线上反馈，不仅耗费人力且评估主观，对全景图缺乏有区分度的数据指标量化衡量图像质量和行业领先水平的差距，导致业务团队难以高效定位画质问题并针对性的改善和评估优化效果。</p><p></p><h4>2、实践方案</h4><p></p><p>通过对线上样本数据进行离线画质摸底并综合算法专家建议，业务团队最终选定清晰度&nbsp;（&nbsp;VQScore&nbsp;）、噪声（Noise）、亮度（Brightness）、过曝光（Overexporsure）&nbsp;等四项指标作为全景图量化评估指标。评估发现精装 、 简装 、毛坯等三种装修类型存在显著画质差异，关键差异与环境光线、灯光照明等因素有较高关联，业务团队针对性进行迭代优化并监测画质指标变化，显著提升了VR看房效果。</p><p></p><h4>3、整体收益</h4><p></p><p>业务团队通过画质评估工具，定位具体的画质问题，针对性进行迭代优化以缩小和行业领先水平的差距；同时借助 veImgaeX 提供的 VR 画质增强能力，显著提升全景图画质，阶段性实现用户 0 客诉，弥补了前端采集设备质量参差等问题。</p>",
    "publish_time": "2023-09-12 15:13:24",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Spring 中三种 BeanName 生成器！",
    "url": "https://www.infoq.cn/article/e2fdb6b926bb413cbee326fc4",
    "summary": "<p>无论我们是通过 XML 文件，还是 Java 代码，亦或是包扫描的方式去注册 Bean，都可以不设置 BeanName，而 Spring 均会为之提供默认的 beanName，今天我们就来看看 Spring 中三种处理不同情况的 beanName 生成器。</p><p></p><h2>1. BeanNameGenerator</h2><p></p><p>Spring 中提供了一个名为 BeanNameGenerator 的接口，这个接口就只有一个需要实现的方法就是 generateBeanName，从名字就能看出来，这就是专门用来生成 beanName 的方法。</p><p></p><p><code lang=\"java\">public interface BeanNameGenerator {\n  String generateBeanName(BeanDefinition definition, BeanDefinitionRegistry registry);\n}\n</code></p><p></p><p>这个方法有两个参数：</p><p></p><p>definition：这个是要生成的 Bean 定义。registry：这个是将来 BeanDefinition 的注册器。</p><p></p><p>BeanNameGenerator 有三个不同的实现类，对应不同的处理场景：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d4/d495c11aeba1e61ab15449111f912a16.png\" /></p><p></p><p>AnnotationBeanNameGenerator：这个专门用来处理包扫描的时候扫到的 Bean，对于这些 Bean，其 name 属性该如何处理，由这个类来解决，当然，小伙伴们都知道，通过 @Component/@Service/@Repository/@Controller 这些注解定义的 Bean，默认情况下，beanName 就是类名首字母小写。FullyQualifiedAnnotationBeanNameGenerator：这个继承自 AnnotationBeanNameGenerator，并重写了 AnnotationBeanNameGenerator#buildDefaultBeanName 方法，这个是使用类的全路径来作为 Bean 的默认名称。DefaultBeanNameGenerator：这个是专门用来解决 XML 文件中定义的 Bean 如果没有设置 beanName，那么就通过 DefaultBeanNameGenerator 来为其生成 beanName。</p><p></p><p>看了上面三个场景之后，可能有小伙伴发现一个 BUG，那么 @Bean 注解定义的 Bean，其 beanName 属性是在哪里处理的呢？这个其实比较特殊，是当场处理的，没用到 BeanNameGenerator，松哥后面单独说。</p><p></p><p>接下来我们详细看下上面这三个实现类。</p><p></p><h2>2. AnnotationBeanNameGenerator</h2><p></p><p>咱们直接来看最关键的 generateBeanName 方法吧：</p><p></p><p><code lang=\"java\">@Override\npublic String generateBeanName(BeanDefinition definition, BeanDefinitionRegistry registry) {\n  if (definition instanceof AnnotatedBeanDefinition) {\n    String beanName = determineBeanNameFromAnnotation((AnnotatedBeanDefinition) definition);\n    if (StringUtils.hasText(beanName)) {\n      // Explicit bean name found.\n      return beanName;\n    }\n  }\n  // Fallback: generate a unique default bean name.\n  return buildDefaultBeanName(definition, registry);\n}\n</code></p><p></p><p>这个方法首先判断 definition 是否为 AnnotatedBeanDefinition 类型，根据我们前面文章对 BeanDefinition 的介绍（<a href=\"https://mp.weixin.qq.com/s/G5_wqgjbpVp0qmscIkFaTg\">七种 BeanDefinition，各显其能！</a>\"），大家知道，AnnotatedBeanDefinition 的实现类主要是针对三种情况：@Bean 注解定义的 Bean、@Service/@Controller/@Component/@Repository 等注解标记的 Bean 以及系统的启动配置类，如果是这三种情况，那么就去调用 determineBeanNameFromAnnotation 方法，这个方法会尝试从注解中提取出来 beanName，如果不是上面三种情况，那么就调用 buildDefaultBeanName 方法去生成 beanName。</p><p></p><p>那我们先来看 determineBeanNameFromAnnotation 方法：</p><p></p><p><code lang=\"java\">@Nullable\nprotected String determineBeanNameFromAnnotation(AnnotatedBeanDefinition annotatedDef) {\n  AnnotationMetadata amd = annotatedDef.getMetadata();\n  Set types = amd.getAnnotationTypes();\n  String beanName = null;\n  for (String type : types) {\n    AnnotationAttributes attributes = AnnotationConfigUtils.attributesFor(amd, type);\n    if (attributes != null) {\n      Set metaTypes = this.metaAnnotationTypesCache.computeIfAbsent(type, key -&gt; {\n        Set result = amd.getMetaAnnotationTypes(key);\n        return (result.isEmpty() ? Collections.emptySet() : result);\n      });\n      if (isStereotypeWithNameValue(type, metaTypes, attributes)) {\n        Object value = attributes.get(\"value\");\n        if (value instanceof String strVal) {\n          if (StringUtils.hasLength(strVal)) {\n            if (beanName != null &amp;&amp; !strVal.equals(beanName)) {\n              throw new IllegalStateException(\"Stereotype annotations suggest inconsistent \" +\n                  \"component names: '\" + beanName + \"' versus '\" + strVal + \"'\");\n            }\n            beanName = strVal;\n          }\n        }\n      }\n    }\n  }\n  return beanName;\n}\n</code></p><p></p><p>这个方法首先会去获取类上的注解信息，拿到 amd 之后，获取到所有的注解类型，然后进行遍历。</p><p></p><p>遍历的时候，首先获取到注解上的所有属性 attributes，当 attributes 不为空的时候，继续去读取当前注解的元注解，并将读取到的结果存入到 metaAnnotationTypesCache 集合中。这个是干嘛呢？大家知道，Spring 中用来标记 Bean 的注解大部分衍生自 @Component，甚至我们也可以自定义注解，那么如果自定义注解了，这个地方就没法判断了，因为每个人自定义出来的注解都不一样。所以，万变不离其宗，这里就去找各个注解的元注解。例如如果我们在类上添加的是 @Configuration，那么 @Configuration 的元注解有两个，分别是 @Component 和 @Indexed。</p><p></p><p>接下来的 isStereotypeWithNameValue 方法就是判断 type 是不是 @Component 或者 Jakarta 中自带的 @ManagedBean、@Named，亦或者 metaTypes 里是否包含 @Component。如果确定是 @Component 衍生出来的注解，亦或者是 @ManagedBean、@Named 注解标记的 Bean，那么就将其 value 属性读取出来，作为 beanName，如果包含多个有效注解，且各自配置的 beanName 不一致，就会抛出异常。</p><p></p><p>例如下面这种情况：</p><p></p><p><code lang=\"java\">@Configuration(\"j\")\n@Component(\"a\")\npublic class JavaConfig {\n}\n</code></p><p></p><p>这两个 beanName 不一致，运行时就会出错。</p><p></p><p>同时，经过上面的分析，小伙伴也看到了，我们其实可以通过自定义注解为 Bean 设置名称，例如我有如下注解：</p><p></p><p><code lang=\"java\">@Retention(RetentionPolicy.RUNTIME)\n@Component\npublic @interface MyBeanName {\n    String value() default \"\";\n}\n</code></p><p></p><p>这个注解衍生自 @Component，那么它的用法如下：</p><p></p><p><code lang=\"java\">@MyBeanName(\"f\")\npublic class JavaConfig {\n\n}\n</code></p><p></p><p>那么 f 就是当前类生成的 beanName。</p><p></p><p>以上是从注解中去提取 beanName，但是注解中可能没有提供 beanName，那么就得调用 buildDefaultBeanName 方法去自动生成了，如下：</p><p></p><p><code lang=\"java\">protected String buildDefaultBeanName(BeanDefinition definition, BeanDefinitionRegistry registry) {\n  return buildDefaultBeanName(definition);\n}\nprotected String buildDefaultBeanName(BeanDefinition definition) {\n  String beanClassName = definition.getBeanClassName();\n  Assert.state(beanClassName != null, \"No bean class name set\");\n  String shortClassName = ClassUtils.getShortName(beanClassName);\n  return StringUtils.uncapitalizeAsProperty(shortClassName);\n}\n</code></p><p></p><p>这个就很好懂了，先拿到 bean 的完整类名，然后提取出来 shortName，也就是去除包名之后的名字，然后首字母小写之后返回。</p><p></p><p>这就是 @Component 注解体系下的 beanName 生成流程。</p><p></p><h2>3. FullyQualifiedAnnotationBeanNameGenerator</h2><p></p><p>FullyQualifiedAnnotationBeanNameGenerator 类只是重写了 AnnotationBeanNameGenerator 的 buildDefaultBeanName 方法，如下：</p><p></p><p><code lang=\"java\">@Override\nprotected String buildDefaultBeanName(BeanDefinition definition) {\n  String beanClassName = definition.getBeanClassName();\n  Assert.state(beanClassName != null, \"No bean class name set\");\n  return beanClassName;\n}\n</code></p><p></p><p>重写后的方法就是获取类的完整路径返回。</p><p></p><p>FullyQualifiedAnnotationBeanNameGenerator 默认情况下并不会直接使用，需要自己手动配置，像下面这样：</p><p></p><p><code lang=\"java\">@Configuration\n@ComponentScan(nameGenerator = FullyQualifiedAnnotationBeanNameGenerator.class)\npublic class JavaConfig {\n\n}\n</code></p><p></p><p>此时，生成的 Bean 的默认名称就是类的全路径了。</p><p></p><h2>4. DefaultBeanNameGenerator</h2><p></p><p>这个是专门用来处理 XML 中默认的 beanName 的。这个在最近录制的 Spring 源码视频中已经详细介绍过了，这里就不再啰嗦了，感兴趣的小伙伴戳这里：<a href=\"https://mp.weixin.qq.com/s/mHizA4NQj1_94g8mMrAm4w\">Spring源码应该怎么学？</a>\"。</p><p></p><h2>5. @Bean 处理特殊情况</h2><p></p><p>如果类是被 @Bean 注解标记的，那么处理情况就特殊一些，直接现场处理，方法在 org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader#loadBeanDefinitionsForBeanMethod 位置：</p><p></p><p><code lang=\"java\">private void loadBeanDefinitionsForBeanMethod(BeanMethod beanMethod) {\n  // Consider name and any aliases\n  List names = new ArrayList&lt;&gt;(Arrays.asList(bean.getStringArray(\"name\")));\n  String beanName = (!names.isEmpty() ? names.remove(0) : methodName);\n\n  // Register aliases even when overridden\n  for (String alias : names) {\n    this.registry.registerAlias(beanName, alias);\n  }\n}\n</code></p><p></p><p>从这里可以看到，如果一开始配置了 name 属性，那么就把 names 集合中的第一个值拿出来作为 beanName，集合中的其他值则当作别名来处理，如果没有配置 name 属性值，那么就使用方法名作为 beanName。</p><p></p><h2>6. 小结</h2><p></p><p>好啦，这就是松哥和大家讲的 Spring 中默认的 beanName 生成策略，感兴趣的小伙伴可以试试哦</p>",
    "publish_time": "2023-09-12 10:54:37",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "谷歌推出3个新的云存储选项：Cloud Storage FUSE、Parallelstore和NetApp Volumes",
    "url": "https://www.infoq.cn/article/sHSt1JqevLArJ8XxI3xG",
    "summary": "<p>最近，谷歌推出了3个新的云存储选项：<a href=\"https://cloud.google.com/storage/docs/gcs-fuse\">Cloud Storage FUSE</a>\"（用于需要文件系统语义的人工智能应用程序）、<a href=\"https://cloud.google.com/parallelstore\">Parallelstore</a>\"（这是一个并行文件系统，用于需要使用GPU的人工智能和高性能计算应用程序）和<a href=\"https://cloud.google.com/netapp-volumes\">NetApp Volumes</a>\"（用于在云中运行的企业级应用程序）。</p><p>&nbsp;</p><p>Cloud Storage FUSE已经提供了开源版本，允许将<a href=\"https://cloud.google.com/storage\">Cloud Storage</a>\"桶中的对象作为挂载到本地文件系统的文件来访问。谷歌针对人工智能工作负载增强了它的可移植性、可靠性、性能和集成能力。在<a href=\"https://cloud.google.com/blog/products/storage-data-transfer/cloud-storage-fuse-now-ga\">谷歌的一篇博文</a>\"中，谷歌产品经理<a href=\"https://www.linkedin.com/in/marco-abela-a7b24963/\">Marco Abela</a>\"和高级产品经理<a href=\"https://www.linkedin.com/in/akshay-ram-20913953/\">Akshay Ram</a>\"解释说：</p><p></p><blockquote>新推出的Cloud Storage FUSE对于人工智能工作负载尤为重要。由于应用程序可以直接访问数据（而不是将数据下载到本地），所以不需要实现自定义逻辑，而且复制数据时TPU和GPU等宝贵资源的空闲时间也缩短了。此外，GKE（Google Kubernetes Engine）新增的<a href=\"https://cloud.google.com/kubernetes-engine/docs/how-to/persistent-volumes/cloud-storage-fuse-csi-driver\">Cloud Storage FUSE CSI驱动程序</a>\"允许应用程序使用为人熟知的Kubernetes API挂载Cloud Storage，并且是作为由GKE托管的turn-key部署提供的。</blockquote><p></p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/38/389598bb5a0ecb71f9fe92e7da68fd81.png\" /></p><p></p><p>Cloud Storage FUSE概览（图片来源：<a href=\"https://cloud.google.com/blog/products/storage-data-transfer/cloud-storage-fuse-now-ga\">谷歌的博文</a>\"）</p><p>&nbsp;</p><p>云布道师<a href=\"https://twitter.com/jwd_gcp/\">J.W. Davis</a>\"在一则<a href=\"https://twitter.com/jwd_gcp/status/1694875605446389847\">推特</a>\"中评论了GKE FUSE文件系统的可用性：</p><p></p><blockquote>这似乎已经注定会带来许多灾难。它的应用场景非常有限；大多数人会遭受滥用之苦。</blockquote><p></p><p>&nbsp;</p><p>除了用于AI应用程序的Cloud Storage FUSE之外，谷歌还宣布了并行文件系统Parallelstore的内部预览。它可以为AI/ML和HPC工作负载提供高性能的并行文件存储解决方案，帮助用户减少因I/O存储等待所浪费的宝贵的GPU资源。该解决方案基于<a href=\"https://www.intel.com/content/dam/www/public/us/en/documents/solution-briefs/high-performance-storage-brief.pdf\">英特尔下一代分布式异步对象存储</a>\"（DAOS）架构。</p><p>&nbsp;</p><p>存储业务副总裁兼总经理<a href=\"https://www.linkedin.com/in/sameet-agarwal/\">Sameet Agarwal</a>\"和存储业务集团产品经理<a href=\"https://twitter.com/SeanDerrington\">Sean Derrington</a>\"在谷歌的一篇博文中介绍了这个新的云存储选项：</p><p></p><blockquote>基于英特尔下一代的DAOS架构，Parallelstore环境中的所有计算节点都具有同样的存储访问权限，因此，VM可以即时地访问其数据。与竞争对手Lustre Scratch的产品相比，Parallelstore的读吞吐量是其6.3倍。Parallelstore非常适合需要极高性能（IOPS和吞吐量）和超低延迟的云端应用。</blockquote><p></p><p>&nbsp;</p><p>最后，第3个新增的云存储选项是NetApp Volumes。这是一项完全由谷歌托管的高性能文件存储服务。该存储选项专为希望将基于本地NetApp存储阵列的应用程序迁移上云的企业而设计。该服务提供的容量在100GiB到100TiB之间，为混合工作负载实现了ONTAP数据管理，并且无需重构即可将Windows或Linux应用程序作为虚拟机运行。</p><p>&nbsp;</p><p>当InfoQ问到是什么促使谷歌进行这些投资时，Derrington是这么说的：</p><p></p><blockquote>随着人工智能在自动化数据管理方面变得越来越重要，组织开始转向云计算来为应用程序寻求合适的存储解决方案。借助谷歌云新提供的专门针对人工智能优化过的存储产品Cloud Storage FUSE和Parallelstore，我们提供了定制的存储解决方案，简化操作，激发创新，降低成本，帮助客户适应复杂的人工智能工作负载。</blockquote><p></p><p>&nbsp;</p><p>Cloud Storage FUSE和NetApp Volumes可以通过谷歌云控制台获得，而Parallelstore需要通过谷歌账户管理器获得。</p><p>&nbsp;</p><p>声明：本文为InfoQ翻译，未经许可禁止转载。</p><p>&nbsp;</p><p>原文链接：<a href=\"https://www.infoq.com/news/2023/08/google-cloud-new-storage-options/\">https://www.infoq.com/news/2023/08/google-cloud-new-storage-options/</a>\"</p>",
    "publish_time": "2023-09-12 16:20:54",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Pinterest使用Kubernetes和Helix构建下一代异步计算平台Pacer",
    "url": "https://www.infoq.cn/article/ZcvPUQRbtRVbIxKcxD3Q",
    "summary": "<p>Pinterest推出其下一代异步计算平台Pacer，用以取代旧的解决方案Pinlater。随着公司的发展，Pinlater在伸缩性和可靠性方面面临着挑战。新的架构使用Kubernetes来调度作业，使用Apache Helix来进行集群管理。</p><p></p><p>Pinterest之前构建了一个异步作业执行平台<a href=\"https://github.com/pinterest/pinlater?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTQ1MDcyNTQsImZpbGVHVUlEIjoiWk02R1VrY2dIQWJBOGlXdiIsImlhdCI6MTY5NDUwNjk1NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.z-LSghRE_Q52tbVl_z1e0M3d4fse5_hTJO09XWUo1wI\">Pinlater</a>\"，并在几年前将其<a href=\"https://medium.com/pinterest-engineering/open-sourcing-pinlater-an-asynchronous-job-execution-system-d8ec4e39859a?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTQ1MDcyNTQsImZpbGVHVUlEIjoiWk02R1VrY2dIQWJBOGlXdiIsImlhdCI6MTY5NDUwNjk1NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.z-LSghRE_Q52tbVl_z1e0M3d4fse5_hTJO09XWUo1wI\">开源</a>\"。Pinlater已在生产环境中使用了多年，并支持许多关键的功能领域。Pinterest在<a href=\"https://aws.amazon.com/ec2/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTQ1MDcyNTQsImZpbGVHVUlEIjoiWk02R1VrY2dIQWJBOGlXdiIsImlhdCI6MTY5NDUwNjk1NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.z-LSghRE_Q52tbVl_z1e0M3d4fse5_hTJO09XWUo1wI\">AWS EC2</a>\"上运行了几个Pinlater集群，每分钟处理数百万个任务。</p><p></p><p>Pinterest软件工程师<a href=\"https://www.linkedin.com/in/qi-li-b16910b9/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTQ1MDcyNTQsImZpbGVHVUlEIjoiWk02R1VrY2dIQWJBOGlXdiIsImlhdCI6MTY5NDUwNjk1NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.z-LSghRE_Q52tbVl_z1e0M3d4fse5_hTJO09XWUo1wI\">Li Qi</a>\"和<a href=\"https://www.linkedin.com/in/zhihuang-chen-585930122/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTQ1MDcyNTQsImZpbGVHVUlEIjoiWk02R1VrY2dIQWJBOGlXdiIsImlhdCI6MTY5NDUwNjk1NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.z-LSghRE_Q52tbVl_z1e0M3d4fse5_hTJO09XWUo1wI\">Chen Zhihuang</a>\"解释了促使他们构建新平台的动机：</p><p></p><p></p><blockquote>随着Pinterest在过去几年的增长和Pinlater流量的增加，我们发现Pinlater存在许多局限性，包括伸缩性瓶颈、硬件效率、缺乏隔离性和可用性。我们在平台方面也遇到了新的挑战，包括那些影响我们数据存储吞吐量和可靠性的挑战。</blockquote><p></p><p></p><p>基于他们使用Pinlater的经历，团队意识到他们不可能在现有架构中解决所有已知的问题，于是他们决定构建下一代平台。</p><p></p><p>新的架构Pacer包含了一个无状态的<a href=\"https://thrift.apache.org/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTQ1MDcyNTQsImZpbGVHVUlEIjoiWk02R1VrY2dIQWJBOGlXdiIsImlhdCI6MTY5NDUwNjk1NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.z-LSghRE_Q52tbVl_z1e0M3d4fse5_hTJO09XWUo1wI\">Thrift</a>\" API服务（与Pinlater兼容）、一个数据存储（<a href=\"https://www.mysql.com/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTQ1MDcyNTQsImZpbGVHVUlEIjoiWk02R1VrY2dIQWJBOGlXdiIsImlhdCI6MTY5NDUwNjk1NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.z-LSghRE_Q52tbVl_z1e0M3d4fse5_hTJO09XWUo1wI\">MySQL</a>\"）、一个有状态的脱队列代理服务（Dequeue Broker），以及在<a href=\"https://kubernetes.io/pl/docs/concepts/overview/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTQ1MDcyNTQsImZpbGVHVUlEIjoiWk02R1VrY2dIQWJBOGlXdiIsImlhdCI6MTY5NDUwNjk1NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.z-LSghRE_Q52tbVl_z1e0M3d4fse5_hTJO09XWUo1wI\">Kubernetes</a>\"上运行的作业执行Worker池。<a href=\"https://helix.apache.org/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTQ1MDcyNTQsImZpbGVHVUlEIjoiWk02R1VrY2dIQWJBOGlXdiIsImlhdCI6MTY5NDUwNjk1NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.z-LSghRE_Q52tbVl_z1e0M3d4fse5_hTJO09XWUo1wI\">Apache Helix</a>\"（带有<a href=\"https://zookeeper.apache.org/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTQ1MDcyNTQsImZpbGVHVUlEIjoiWk02R1VrY2dIQWJBOGlXdiIsImlhdCI6MTY5NDUwNjk1NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.z-LSghRE_Q52tbVl_z1e0M3d4fse5_hTJO09XWUo1wI\">Zookeeper</a>\"）被用来将作业队列分区分配给脱队列代理。</p><p></p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/news/2023/08/pinterest-pacer-kubernetes/en/resources/11_aMUUI-P4Gl_378E0XysF6Q-1692289081279.jpeg\" /></p><p></p><p>Pacer架构（来源：<a href=\"https://medium.com/pinterest-engineering/pacer-pinterests-new-generation-of-asynchronous-computing-platform-5c338a15d2a0?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTQ1MDcyNTQsImZpbGVHVUlEIjoiWk02R1VrY2dIQWJBOGlXdiIsImlhdCI6MTY5NDUwNjk1NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.z-LSghRE_Q52tbVl_z1e0M3d4fse5_hTJO09XWUo1wI\">Pinterest工程博客</a>\"）</p><p></p><p>脱队列代理是一种有状态服务，负责从数据存储中预取作业队列数据并将其缓存到内存中，以减少延迟和隔离入队列和脱队列的工作负载。每个脱队列代理分配到一组作业队列分区，因此可以独占获取和执行作业，从而避免出现争用的情况。Kubernetes为每个作业队列提供了一个专用的Pod池，消除因不同作业类型对资源倾斜消耗所带来的影响。</p><p></p><p>新的脱队列和执行模型缓解了Pinlater所遭遇的问题，包括在从热点分区获取数据时避免扫描所有分区或减少锁的争用。此外，它支持按照排队顺序（<a href=\"https://en.wikipedia.org/wiki/FIFO_(computing_and_electronics)?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTQ1MDcyNTQsImZpbGVHVUlEIjoiWk02R1VrY2dIQWJBOGlXdiIsImlhdCI6MTY5NDUwNjk1NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.z-LSghRE_Q52tbVl_z1e0M3d4fse5_hTJO09XWUo1wI\">FIFO</a>\"）的方式执行作业，前提是为作业队列配置单独的分区。</p><p></p><p>新的架构需要给脱队列代理实例进行独占式队列分区分配，与<a href=\"https://kafka.apache.org/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTQ1MDcyNTQsImZpbGVHVUlEIjoiWk02R1VrY2dIQWJBOGlXdiIsImlhdCI6MTY5NDUwNjk1NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.z-LSghRE_Q52tbVl_z1e0M3d4fse5_hTJO09XWUo1wI\">Kafka</a>\"</p><p>消费者主题分区分配类似。Pinterest的团队选择使用Apache Helix来实现这个功能。Apache Helix提供了一个通用的集群管理框架，用于给集群内的脱队列代理进行分区分配。Helix使用Apache Zookeeper实现嵌在脱队列代理实例中的Helix控制器和Helix代理之间的资源配置通信。</p><p></p><p></p><p><img src=\"https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/news/2023/08/pinterest-pacer-kubernetes/en/resources/11_-YVqXf-1c-elcPRM5xvu7Q-1692289081279.jpeg\" /></p><p></p><p>用Apache Helix和Zookeeper协调脱队列代理（来源：<a href=\"https://medium.com/pinterest-engineering/pacer-pinterests-new-generation-of-asynchronous-computing-platform-5c338a15d2a0?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTQ1MDcyNTQsImZpbGVHVUlEIjoiWk02R1VrY2dIQWJBOGlXdiIsImlhdCI6MTY5NDUwNjk1NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.z-LSghRE_Q52tbVl_z1e0M3d4fse5_hTJO09XWUo1wI\">Pinterest工程博客</a>\"）</p><p></p><p>Helix控制监控加入和离开集群的脱队列代理实例，以及对已配置的作业队列做出的任何变更，如果发生变更，它将重新计算理想的队列分区与代理分布。在最新的分区分配被保存到Zookeeper之后，各个代理实例就会更新它们的内部状态，并从它们负责的队列分区中获取数据。</p><p></p><p></p><p>查看英文原文：<a href=\"https://www.infoq.com/news/2023/08/pinterest-pacer-kubernetes/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTQ1MDcyNTQsImZpbGVHVUlEIjoiWk02R1VrY2dIQWJBOGlXdiIsImlhdCI6MTY5NDUwNjk1NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.z-LSghRE_Q52tbVl_z1e0M3d4fse5_hTJO09XWUo1wI\">https://www.infoq.com/news/2023/08/pinterest-pacer-kubernetes/</a>\"</p>",
    "publish_time": "2023-09-12 16:30:48",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "谷歌云推出AlloyDB AI：用先进的向量嵌入和AI改造PostgreSQL",
    "url": "https://www.infoq.cn/article/s0Ou9xLi1TtbTzUzTj9x",
    "summary": "<p>在最近的<a href=\"https://cloud.withgoogle.com/next\">Google Cloud Next</a>\"中，谷歌在预告中宣布了<a href=\"https://cloud.google.com/alloydb/ai\">AlloyDB AI</a>\"是<a href=\"https://cloud.google.com/alloydb\">AlloyDB for PostgreSQL</a>\"的一个组成部分，允许开发人员利用大语言模型（LLM）来构建生成式（gen）人工智能（AI）应用程序，并通过内置的、端到端的<a href=\"https://cloud.google.com/blog/topics/developers-practitioners/meet-ais-multitool-vector-embeddings\">向量嵌入</a>\"支持来利用它们的实时操作数据。</p><p>&nbsp;</p><p>早些时候，该公司<a href=\"https://www.infoq.com/news/2023/07/gcp-databases-vector-search/\">推出了</a>\"对Cloud SQL for PostgreSQL和AlloyDB for PostgreSQL的pgvector支持，将向量搜索操作引入到了托管数据库中，允许开发人员存储由<a href=\"https://developers.google.com/machine-learning/resources/intro-llms\">大语言模型（LLM）</a>\"生成的向量嵌入并执行相似性搜索。AlloyDB AI建立在标准PostgreSQL所提供的基本向量支持之上，该公司表示，它为开发人员提供了“创建和查询嵌入的能力，只需几行SQL即可找到相关数据，既不需要专门的数据堆栈，也不需要移动数据。”</p><p>&nbsp;</p><p>此外，AlloyDB AI还为AlloyDB带来了一些其他新功能，可以帮助开发人员将实时数据整合到生成式AI应用程序中：</p><p>&nbsp;</p><p>通过与AlloyDB查询处理引擎的紧密集成，增强了向量支持，比标准PostgreSQL查询更快。此外，该公司还引入了基于<a href=\"https://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html\">ScaNN技术</a>\"的量化技术，以在启用时支持四倍的向量尺寸和三倍的空间缩小。&nbsp;访问AlloyDB中的本地模型和<a href=\"https://cloud.google.com/vertex-ai\">Vertex AI</a>\"中托管的远程模型，包括自定义和预训练模型。开发人员可以使用存储在AlloyDB中的数据来训练和微调模型，然后将它们作为端点部署在Vertex AI上。与人工智能生态系统的集成，包括<a href=\"https://cloud.google.com/blog/products/ai-machine-learning/vertex-ai-next-2023-announcements\">Vertex AI Extensions</a>\"（将于今年晚些时候推出）和<a href=\"https://python.langchain.com/docs/get_started/introduction.html\">LangChain</a>\"，这将提供在Vertex AI中调用远程模型的能力，以实现低延迟、高吞吐量的增强事务，使用SQL进行欺诈检测等用例。</p><p>&nbsp;</p><p>谷歌云数据库总经理兼工程副总裁<a href=\"https://twitter.com/andigutmans\">Andi Gutmans</a>\"在<a href=\"https://cloud.google.com/blog/products/databases/helping-developers-build-gen-ai-apps-with-google-cloud-databases/\">谷歌博客中</a>\"写道：</p><p>&nbsp;</p><p></p><blockquote>AlloyDB AI允许用户使用简单的SQL函数轻松地将数据转换为向量嵌入，用于数据库内的嵌入生成，并且运行向量查询的速度比标准PostgreSQL快10倍。与开源人工智能生态系统和谷歌云的Vertex AI平台的集成为构建生成式人工智能应用程序提供了端到端的解决方案。</blockquote><p></p><p>&nbsp;</p><p>根据Andi的<a href=\"https://news.ycombinator.com/item?id=37312502\">声明</a>\"，Reddit上的一名受访者问道，谷歌是否是在试图用AlloyDB AI拥抱、扩展再消灭（Embrace, extend, and extinguish，EEE）PostgreSQL，另一个答案是：</p><p>&nbsp;</p><p></p><blockquote>我想你想说的是，仅仅因为有人，尤其是[大公司]，试图改进/整合流行的开放项目，并不意味着它总是EEE。&nbsp;我怀疑EEE在最初的大部分时间里都是有目的的，即使后来有可能变成那样。以谷歌为例，我认为这将是一个“我们如何为我们的产品增加销售价值”的案例，然后是“这个功能花费了我们太多的资源来维护，致使我们必须削减它，专注于[新功能]”</blockquote><p></p><p>&nbsp;</p><p>此外，其他数据库和公有云提供商也已经支持向量嵌入，包括MongoDB、DataStax的Cassandra数据库服务Astra、开源的PostgreSQL（通过Pgvector）和Azure Cognitive Search。后者最近发布了<a href=\"https://www.infoq.com/news/2023/07/microsoft-launches-vector-search/\">一个新的功能</a>\"，可以在预览版本中对搜索索引中的向量嵌入进行索引、存储和检索。</p><p>&nbsp;</p><p>最后，AlloyDB AI可在谷歌云和<a href=\"https://cloud.google.com/alloydb/omni\">AlloyDB Omni</a>\"上的AlloyDB中使用，无需额外的费用。AlloyDB的定价详细信息可在<a href=\"https://cloud.google.com/alloydb/pricing\">定价页面</a>\"上查看。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/09/google-cloud-alloydb-ai-preview/\">https://www.infoq.com/news/2023/09/google-cloud-alloydb-ai-preview/</a>\"</p>",
    "publish_time": "2023-09-12 16:36:28",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "腾讯做大模型：要拼技术细节、用内部业务“磨刀”",
    "url": "https://www.infoq.cn/article/Nj2C7Vkk6MameTEXto0A",
    "summary": "<p>“<a href=\"https://www.infoq.cn/news/HXQtZJxYy5SeK9OH3Xzi\">腾讯混元大模型</a>\"从第一个token开始从零训练。”腾讯集团副总裁蒋杰说道。9月7日，腾讯正式对外开放了全链路自研的通用大模型——混元大模型，这也意味着腾讯正式加入了“<a href=\"https://www.infoq.cn/article/FksReogLLESJpqOR3ZxD\">百模大战</a>\"”之中。</p><p>&nbsp;</p><p>在已经有首批8家企业机构的大模型产品通过《生成式人工智能服务管理暂行办法》备案准备正式上线开放后，腾讯的通用大模型才刚刚发布，这个时间并不算早。那么，腾讯的大模型之路将如何走下去？</p><p></p><h3>做大模型要“拼细节”</h3><p></p><p>&nbsp;</p><p>“混元”不是腾讯推出的第一个大模型。从2018年开始探索大模型相关技术，腾讯先后推出了多个千万/亿参数大模型：2021年-2022年推出了多个千亿和万亿参数规模的大模型。</p><p>&nbsp;</p><p>腾讯混元大模型平台架构、模型、算法能力等整个体系都是纯自研的，而构建腾讯混元的技术能力都得益于这些年大模型能力的积累。像今天的锯齿状注意力、探真等都是技术循序渐进的产物。</p><p>&nbsp;</p><p>“现在国内外有很多开源的大模型，很多企业也是基于开源模型来做，但是如果不从头自研的话，就没办法完全掌握这个技术。”蒋杰说道。</p><p>&nbsp;</p><p>腾讯对大模型的期望是先给企业内部业务带来突破，这要求大模型必须更好融入到腾讯的技术栈中，但很多开源架构并不适合腾讯业务场景。比如，幻觉是每一个大模型厂商都会面临的重要问题，业内普遍会用知识图谱甚至搜索外挂让大模型的检索支持能力变得更强，但是这些方式不适用腾讯的场景占比很高，于是腾讯使用了自研的“探真”技术来降低幻觉出现的比例。</p><p>&nbsp;</p><p>混元大模型目前还是聚焦在国内市场，中文创作是其主要攻破的能力之一，支持文学创作、文本摘要、角色扮演等。通用大模型的逻辑推理能力非常关键，而大模型如何可靠地执行是腾讯最关注的。</p><p>&nbsp;</p><p>混元大模型拥有超千亿参数规模，预训练语料超2万亿tokens。腾讯的内容产品为混元大模型提供了大规模、高质量、多样化的语料库，混元大模型能从中学习到各类应用场景中丰富的语言知识和语境理解能力。</p><p>&nbsp;</p><p>面对海量数据，腾讯使用了AngelPTM训练框架，优化算法，改进了注意力机制。而在逻辑推理方面，腾讯则使用了AngelHCF推理框架，开发了思维链（Chain-of-Thought，CoT）新算法。腾讯表示，通过自研机器学习框架Angel使训练速度相比业界主流框架提升1倍，推理速度比业界主流框架提升1.3倍。</p><p>&nbsp;</p><p>注：思维链指的是一系列有逻辑关系的思考步骤形成一个完整的思考过程，用的是离散式token，能自动构建问题、推理步骤和样例。但思维链必须在模型规模足够大时才能涌现。</p><p>&nbsp;</p><p>在蒋杰看来，业内做强化学习的方法大体相似，腾讯要做的就是“拼细节”。“未来几个头部厂商大模型的评分可能仅仅是1分、2分的差距，这个厂家版本高1分，另外厂家的下一个版本就会比它再高1分，就是这样一个不断博弈和循序渐进的过程。而大家投入的资源不一样、抠的细节不一样，大模型的差异才会最终显露出来。”&nbsp;</p><p></p><h3>先做内部业务的“倍增器”</h3><p></p><p>&nbsp;</p><p>在通用大模型上，腾讯确实走得不急。腾讯强调，研发大模型的目标不是在评测上获得高分，而是将技术应用到实际场景中。腾讯6月份发布行业大模型后，一直努力将能力拓展到更多领域，腾讯内部的海量业务场景也成了混元大模型的“磨刀石”。</p><p>&nbsp;</p><p>众所周知，腾讯业务特别广泛，混元大模型能在内部各种场景上很好地应用就很不容易。比如，to C的腾讯会议、腾讯文档在使用大模型时就有很大的差异。混元大模型的文字总结能力能与文档环境天然很好地结合，但会议场景强实时交互，需要会议团队和混元团队一起探索如何将混元大模型的基础指令理解能力、文字总结能力与会议内容生成结合起来。</p><p>&nbsp;</p><p>“像会议、文档这样的场景，单纯将一个大模型直接融合进去短期内不一定能够给业务带来很大提升，因此一定要针对具体的业务需求做专门优化和提效，才能达到更好的效果。”腾讯机器学习平台部副总经理王迪说道。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f1/f1bd1aeae2d9e13e610c22b5118e6ab7.png\" /></p><p></p><p>在腾讯看来，提效是大模型更有商业价值的地方，腾讯希望混元大模型成为业务的“倍增器”。</p><p>&nbsp;</p><p>目前，腾讯内部所有的应用都会基于混元大模型做智能化研发，混元大模型将作为基础设施去支持腾讯的各种产品和应用能力。<a href=\"https://www.infoq.cn/news/dVusdTArjZDRQ1dwL8wo\">腾讯会议</a>\"基于腾讯混元大模型打造了AI小助手，只需要简单的自然语言指令，就能完成会议信息提取、内容分析等复杂任务，会后还能生成智能总结纪要。混元大模型支持数十种文本创作场景，在腾讯文档推出的智能助手功能中已有应用。</p><p>&nbsp;</p><p>与之前技术产品的商业化路径相似，腾讯大模型也会先服务腾讯内部业务，然后再通过腾讯云对外开放，服务外部客户。</p><p></p><h3>结束语</h3><p></p><p>&nbsp;</p><p>在蒋杰看来，大模型的天花板现在还没有完全碰触到的技术体系和演进上，行业不仅需要技术突破，还需要语料的完整度、数据的标注能力、后续的纠错能力等，单点的技术突破无法带来大模型的最终效果。</p><p>&nbsp;</p><p>“未来，混元大模型还要做更多的数据标注、更多的框架、训练更多的数据，这才是我们团队工作的真正核心。”蒋杰说道，“腾讯混元永远在路上。”</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-09-12 17:28:34",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]