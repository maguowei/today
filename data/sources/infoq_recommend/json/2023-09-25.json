[
  {
    "title": "Java近期新闻：JDK 22发布时间表、巴比伦项目、Helidon 4.0-RC2、MicroProfile 6.1-RC1",
    "url": "https://www.infoq.cn/article/3F3uczlwd3ee361zhvId",
    "summary": "<p></p><h4>OpenJDK</h4><p></p><p></p><p>Oracle Java架构师<a href=\"https://www.linkedin.com/in/paul-sandoz-4704562/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Paul Sandoz</a>\"<a href=\"https://mail.openjdk.org/pipermail/discuss/2023-September/006226.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">发起了一个提案</a>\"，准备启动一个叫作巴比伦（Babylon）的Java项目，主要目标是“将Java扩展到外部编程模型，如SQL、可微分编程、机器学习模型和GPU中”。巴比伦可以通过<a href=\"https://cr.openjdk.org/~psandoz/conferences/2023-JVMLS/Code-Reflection-JVMLS-23-08-07.pdf?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">代码反射</a>\"实现将Java扩展到外部编程模型中，这是对Java反射机制的增强，支持以适当的形式访问、分析和转换Java代码。这样一来，通过Java库的形式来支持外部编程模型就变得相对容易。</p><p></p><p>Sandoz将领导这个新项目，并提供了一份初步评审人员名单，其中包括Oracle软件架构师兼Panama项目负责人<a href=\"https://www.linkedin.com/in/mcimadamore/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Maurizio Cimadamore</a>\"、Oracle软件架构师<a href=\"https://www.linkedin.com/in/gary-frost-8048575/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Gary Frost</a>\"和英特尔首席软件工程师<a href=\"https://www.linkedin.com/in/sandhya-viswanathan-4484942/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Sandhya Viswanathan</a>\"。想要了解更多信息的开发者可以观看最近的<a href=\"https://openjdk.org/projects/mlvm/jvmlangsummit/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">JVM语言峰会</a>\"YouTube<a href=\"https://youtu.be/xbk9_6XA_IY?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">视频</a>\"。</p><p></p><p>Sandoz上周还介绍了JEP草案8315945，<a href=\"https://openjdk.org/jeps/8315945?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Vector API(第七轮孵化器)</a>\"。这个JEP来自<a href=\"https://openjdk.org/projects/panama/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Panama</a>\"项目，整合了针对前六轮孵化的增强和改进：即将在JDK 21 GA版本中交付的JEP 448（<a href=\"https://openjdk.org/jeps/448?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Vector API (第六轮孵化器)</a>\"）、在JDK 20中交付的JEP 438（<a href=\"https://openjdk.org/jeps/438?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Vector API (第五轮孵化器)</a>\"）、在JDK 19中交付的JEP 426（<a href=\"https://openjdk.org/jeps/426?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Vector API (第四轮孵化器)</a>\"）、在JDK 18中交付的JEP 417（<a href=\"https://openjdk.java.net/jeps/417?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Vector API (第三轮孵化器)</a>\"）在JDK 17中交付的JEP 414（<a href=\"https://openjdk.java.net/jeps/414?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Vector API (第二轮孵化器)</a>\"）、在JDK 16中作为<a href=\"https://openjdk.java.net/jeps/11?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">孵化器模块</a>\"交付的JEP 338（<a href=\"https://openjdk.java.net/jeps/338?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Vector API (孵化器)</a>\"）。JEP 448最重要的变化包括为支持Vector API值而对<a href=\"https://docs.oracle.com/en/graalvm/enterprise/20/docs/reference-manual/compiler/#graalvm-compiler?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">JVM编译器接口</a>\" (JVMCI)进行的增强。</p><p></p><h4>JDK 21</h4><p></p><p></p><p><a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-21%2B35?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Build 35</a>\"仍然是JDK 21当前的<a href=\"https://jdk.java.net/20/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">早期访问构建</a>\"版本。关于该构建的更多细节可以在<a href=\"https://jdk.java.net/21/release-notes?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">发行说明</a>\"中找到。</p><p></p><h4>JDK 22</h4><p></p><p></p><p>JDK 22的<a href=\"https://jdk.java.net/22/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">早期访问构建</a>\"版本<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-22%2B14?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Build 14</a>\"提供了针对Build 13的<a href=\"https://github.com/openjdk/jdk/compare/jdk-22%2B13...jdk-22%2B14?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">更新</a>\"，其中包括对各种<a href=\"https://bugs.openjdk.org/issues/?jql=project%20%3D%20JDK%20AND%20fixversion%20%3D%2022%20and%20%22resolved%20in%20build%22%20%3D%20b14%20order%20by%20component%2C%20subcomponent&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">问题</a>\"的修复。关于这个版本的更多细节可以在<a href=\"https://jdk.java.net/22/release-notes?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">发行说明</a>\"中找到。</p><p></p><p>Oracle Java平台组首席架构师<a href=\"https://www.linkedin.com/in/markreinhold?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Mark Reinhold</a>\"正式<a href=\"https://mail.openjdk.org/pipermail/jdk-dev/2023-September/008256.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">提议</a>\"JDK 22的发布时间表：</p><p></p><p>Rampdown Phase One(从主分支fork)：2023年12月7日Rampdown Phase Two：2024年1月18日初始候选版本：2024年2月8日最终候选版本：2024年2月22日普遍可用：2024年3月19日</p><p></p><p>JDK<a href=\"https://openjdk.org/census#jdk?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">提交者和评审者</a>\"对该提案的评论将在2023年9月15日23点 之前开放讨论。如果届时没有人反对，那么根据JEP 2.0<a href=\"https://cr.openjdk.org/~mr/jep/jep-2.0-02.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">流程建议</a>\"，这将是JDK 22的发布时间表。</p><p></p><p>对于<a href=\"https://openjdk.org/projects/jdk/22/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">JDK 22</a>\"和<a href=\"https://openjdk.java.net/projects/jdk/21/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">JDK 21</a>\"，开发者可以通过<a href=\"https://bugreport.java.com/bugreport/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Java Bug Database</a>\"报告缺陷。</p><p></p><h4>GraalVM</h4><p></p><p></p><p>Oracle Labs发布<a href=\"https://github.com/graalvm/native-build-tools/releases/tag/0.9.26?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">0.9.26</a>\"版本的<a href=\"https://github.com/graalvm/native-build-tools/blob/master/README.md?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">原生构建工具</a>\"，一个GraalVM项目，提供了可与GraalVM原生镜像互操作的插件。新版本包含了一些值得注意的变化，例如：使用<a href=\"https://docs.gradle.org/current/kotlin-dsl/gradle/org.gradle.api.attributes/-attribute-container/attribute-provider.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">AttributeProvider</a>\"API修复与Gradle 8.3的兼容性问题、显式声明<a href=\"https://github.com/codehaus-plexus/plexus-xml/blob/master/README.md?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Plexus-Xml</a>\"和<a href=\"https://github.com/codehaus-plexus/plexus-utils/blob/master/README.md?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Plexus-Utils</a>\"依赖项来修复与Maven 3.9.x的兼容性问题、为即将发布的GraalVM for JDK 21准备原生构建工具。关于该版本的更多细节可以在<a href=\"https://github.com/graalvm/native-build-tools/compare/0.9.25...0.9.26?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">变更日志</a>\"中找到。</p><p></p><h4>Spring Framework</h4><p></p><p></p><p>在过去的两周里，Spring一直很平静，但VMware的Spring开发者布道师<a href=\"https://www.linkedin.com/in/joshlong/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Josh Long</a>\"却没有闲着。除了他每周发表的“This Week in Spring”博文之外，Long还发表了针对SpringOne 2023的个人<a href=\"https://spring.io/blog/2023/08/29/my-springone-2023-recap?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">概述</a>\"。他最近的一篇<a href=\"https://spring.io/blog/2023/09/09/all-together-now-spring-boot-3-2-graalvm-native-images-java-21-and-virtual?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">博文</a>\"是关于Spring Boot 3.2、GraalVM原生镜像、Java 21和虚拟线程是如何协同工作的。他还与VMware Spring安全负责人<a href=\"https://spring.io/blog/2023/09/07/a-bootiful-podcast-spring-security-lead-rob-winch?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Rob Winch</a>\"、VMware Spring工程高级技术人员<a href=\"https://spring.io/blog/2023/08/31/a-bootiful-podcast-spring-security-and-kubernetes-legend-daniel-garnier?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Daniel Garnier-Moiroux</a>\"和Eventuate创始人兼CEO <a href=\"https://spring.io/blog/2023/08/25/a-bootiful-podcast-cloud-native-chris-richardson?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Chris Richardson</a>\"一起录制了“Bootiful”播客。</p><p></p><h4>Quarkus</h4><p></p><p></p><p><a href=\"https://quarkus.io/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Quarkus</a>\"3.3.2版本<a href=\"https://quarkus.io/blog/quarkus-3-3-2-released/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">发布</a>\"，带来了依赖项升级和一些显著的变化，如：改进了Dev UI的OIDC Auth0；删除<a href=\"https://www.javadoc.io/doc/io.fabric8/kubernetes-model/1.0.12/io/fabric8/openshift/api/model/BuildConfig.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">**`BuildConfig`**</a>\"类的imagePushSecret()方法，这个方法在使用内部注册表时是无效的；修复了Quarkus构建问题（使用quarkus.container-image.builder=jib属性时不考虑Podman的auth.json文件。关于该版本的更多细节可以在<a href=\"https://github.com/quarkusio/quarkus/releases/tag/3.3.2?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">变更日志</a>\"中找到。</p><p></p><h4>MicroProfile</h4><p></p><p></p><p>MicroProfile工作组发布<a href=\"https://github.com/microprofile/microprofile-wg/tree/main/microprofile-6.1?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">MicroProfile 6.1</a>\"的<a href=\"https://github.com/eclipse/microprofile/releases/tag/6.1-RC1?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">首个发行候选版本</a>\"，其中包括对<a href=\"https://microprofile.io/specifications/microprofile-config/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">MicroProfile Config</a>\"、<a href=\"https://microprofile.io/specifications/microprofile-metrics/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">MicroProfile Metrics</a>\"和<a href=\"https://microprofile.io/specifications/microprofile-telemetry/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">MicroProfile Telemetry</a>\"规范的更新。因此，MicroProfile 6.1的最终特性(定于10月初发布GA版本)将包含：</p><p></p><p>Jakarta EE 10 Core ProfileMicroProfile Config 3.1MicroProfile Fault Tolerance 4.0MicroProfile Metrics 5.1MicroProfile Health 4.0MicroProfile Telemetry 1.1MicroProfile OpenAPI 3.1MicroProfile JWT Authentication 2.1MicroProfile Rest Client 3.0</p><p></p><p>值得注意的是，<a href=\"https://jakarta.ee/specifications/coreprofile/10/jakarta-coreprofile-spec-10.0?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Jakarta EE 10核心概要</a>\"包含了七个规范中的四个，即：<a href=\"https://jakarta.ee/specifications/cdi/4.0/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Jakarta Contexts and Dependency Injection (CDI) 4.0</a>\"、<a href=\"https://jakarta.ee/specifications/restful-ws/3.1/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Jakarta RESTful Web Services 3.1</a>\"、<a href=\"https://jakarta.ee/specifications/jsonp/2.1/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Jakarta JSON Processing 2.1</a>\"和<a href=\"https://jakarta.ee/specifications/jsonb/3.0/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Jakarta JSON Binding 3.0</a>\"，这些是在MicroProfile早期从Java EE 7和Java EE 8发展而来的JSR规范。</p><p></p><p>MicroProfile Config 3.1的<a href=\"https://github.com/eclipse/microprofile-config/releases/tag/3.1-RC2?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">第二个候选发行版</a>\"带来了一些值得注意的变化，如：更新了TCK，与CDI 4.0的重大变更保持一致，包含了一个空的beans.xml文件，Bean发现模式从all改为annotated；<a href=\"https://github.com/eclipse/microprofile-config/blob/main/tck/src/main/java/org/eclipse/microprofile/config/tck/broken/MissingValueOnObserverMethodInjectionTest.java?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">**`MissingValueOnObserverMethodInjectionTest`**</a>\"类的更新，在<a href=\"https://github.com/eclipse/microprofile-config/blob/main/tck/src/main/java/org/eclipse/microprofile/config/tck/broken/ConfigObserver.java?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">**`ConfigObserver`**</a>\"被定义为@ApplicationScoped(可代理)和final(不可代理)时会抛出DeploymentException。关于该版本的更多细节可以在<a href=\"https://github.com/eclipse/microprofile-config/milestone/11?closed=1&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">问题列表</a>\"中找到。</p><p></p><h4>Helidon</h4><p></p><p></p><p><a href=\"https://helidon.io/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Helidon</a>\"4.0.0的<a href=\"https://github.com/helidon-io/helidon/releases/tag/4.0.0-M2?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">第二个候选发行版</a>\"包含：JDK 21基线；完全集成<a href=\"https://helidon.io/nima?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Helidon Níma</a>\"Web服务器；经过重度重构的Helidon SE API，优化了命令式/阻塞场景；对<a href=\"https://helidon.io/docs/v3/#/se/webserver?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Web Server</a>\"和<a href=\"https://helidon.io/docs/v3/#/se/webclient?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Web Client</a>\"组件的增强，实现与Helidon 3.0相同的功能。关于该版本的更多细节可以在<a href=\"https://github.com/helidon-io/helidon/blob/4.0.0-M2/CHANGELOG.md?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">变更日志</a>\"中找到。</p><p></p><h4>Open Liberty</h4><p></p><p></p><p>IBM<a href=\"https://openliberty.io/blog/2023/09/05/23.0.0.9-beta.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">发布</a>\"23.0.0.9-beta版<a href=\"https://openliberty.io/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Open Liberty</a>\"，包含：对<a href=\"https://openliberty.io/blog/2023/08/03/23.0.0.8-beta.html#sp3?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Liberty Spring Boot Support 3.0</a>\"的持续改进，可对在容器中创建的应用程序进行“瘦身”；<a href=\"https://jakarta.ee/specifications/data/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Jakarta Data</a>\"规范的<a href=\"https://openliberty.io/blog/2023/07/11/23.0.0.7-beta.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">早期预览版</a>\"。</p><p></p><h4>Hibernate</h4><p></p><p></p><p><a href=\"https://hibernate.org/search/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Hibernate Search</a>\"7.0.0的<a href=\"https://in.relation.to/2023/09/05/hibernate-search-7-0-0-Beta1/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">第一个测试版</a>\"包含了许多依赖项升级：JDK 11作为基准、迁移到Jakarta EE、Hibernate ORM 6.3.0.Final、Lucene 9.7.0、Elasticsearch 8.9.0和OpenSearch 2.9.0。</p><p></p><h4>Infinispan</h4><p></p><p></p><p><a href=\"https://infinispan.org/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Infinispan</a>\"<a href=\"https://github.com/infinispan/infinispan/releases/tag/14.0.17.Final?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">发布</a>\"14.0.17.Final版，包含了一些值得注意的问题修复，例如：由<a href=\"https://github.com/infinispan/infinispan/blob/main/server/runtime/src/main/java/org/infinispan/server/logging/events/ServerEventLogger.java?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">**`ServerEventLogger`**</a>\"类创建的缓存阻塞了可能导致死锁的缓存连接；<a href=\"https://docs.jboss.org/infinispan/14.0/apidocs/org/infinispan/executors/DefaultExecutorFactory.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">**`DefaultExecutorFactory`**</a>\"类创建的不必要的多个Java <a href=\"https://download.java.net/java/early_access/jdk21/docs/api/java.base/java/lang/ThreadGroup.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">**`ThreadGroup`**</a>\"；为<a href=\"https://docs.jboss.org/infinispan/14.0/apidocs/org/infinispan/remoting/rpc/RpcManager.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">**`RpcManager`**</a>\"接口的实现添加缺失的跨站点指标。关于该版本的更多细节可以在<a href=\"https://github.com/infinispan/infinispan/compare/14.0.16.Final...14.0.17.Final?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">问题列表</a>\"中找到。</p><p></p><h4>Eclipse Mojarra</h4><p></p><p></p><p><a href=\"https://projects.eclipse.org/projects/ee4j.mojarra?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Eclipse Mojarra</a>\"4.0.4<a href=\"https://twitter.com/OmniFishEE/status/1700439466500841842?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">发布</a>\"，带来了一些值得注意的变化，例如：修复了当<a href=\"https://weld.cdi-spec.org/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Weld</a>\"中的Bean Deployment Archive为空时Mojarra无法初始化的问题；更健壮的<a href=\"https://javadoc.io/doc/org.glassfish/jakarta.faces/latest/com/sun/faces/facelets/tag/composite/RetargetedAjaxBehavior.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">**`RetargetedAjaxBehavior`**</a>\"类实现；<a href=\"https://javadoc.io/doc/org.glassfish/jakarta.faces/latest/jakarta/faces/component/UIData.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">**`UIData`**</a>\"类的当前值是null时返回一个静态空数据模型。关于该版本的更多细节可以在<a href=\"https://github.com/eclipse-ee4j/mojarra/releases/tag/4.0.4-RELEASE?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">发行说明</a>\"中找到。</p><p></p><h4>JDKMon</h4><p></p><p></p><p>由Azul首席工程师<a href=\"https://de.linkedin.com/in/gerritgrunwald?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">Gerrit Grunwald</a>\"创建的JDK监控和更新工具<a href=\"https://github.com/HanSolo/JDKMon?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">JDKMon</a>\"发布了<a href=\"https://github.com/HanSolo/JDKMon/releases/tag/17.0.71?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">17.0.71</a>\"版本，从新版本可以知道关于JDK 21 GA版本和下一个OpenJDK更新的时间。</p><p></p><h4>JHipster</h4><p></p><p></p><p>JHipster 8.0.0的<a href=\"https://www.jhipster.tech/2023/09/05/jhipster-release-8.0.0-beta.3.html#jhipster-release-v800-beta3?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">第三个测试版</a>\"带来了以下增强功能：支持JDK 20和JDK 21；清理<a href=\"https://www.jhipster.tech/jdl/intro?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">JHipster领域语言</a>\" (JDL)，将文件操作、配置和验证转移到JDL生成器中；修复H2控制台由于路径设置错误而无法加载的问题。关于该版本的更多细节可以在<a href=\"https://github.com/jhipster/generator-jhipster/releases/tag/v8.0.0-beta.3?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">发行说明</a>\"中找到。</p><p></p><p>类似地，JHipster 7.9.4的<a href=\"https://www.jhipster.tech/2023/09/05/jhipster-release-7.9.4.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">发行版</a>\"修复了bug并支持Node.js 18。关于该版本的更多细节可以在<a href=\"https://github.com/jhipster/generator-jhipster/releases/tag/v7.9.4?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">发行说明</a>\"中找到。</p><p></p><h4>JavaZone大会</h4><p></p><p></p><p><a href=\"https://2023.javazone.no/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">JavaZone</a>\"大会在挪威奥斯陆的<a href=\"https://oslospektrum.no/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">奥斯陆光谱剧院</a>\"举行，来自Java社区的演讲者发表了<a href=\"https://2023.javazone.no/program?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">演讲</a>\"并举行了<a href=\"https://2023.javazone.no/workshops?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU2MDUzNDcsImZpbGVHVUlEIjoiOTAzMEoxVkVtREkxSlJrdyIsImlhdCI6MTY5NTYwNTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.ipZvuALQG_bbMXTIs6bTWlSK49j78imNY8lFRyAhosE\">研讨会</a>\"，主题包括：垃圾回收、量子计算、Haskell、Kubernetes、应用程序监控、微前端、JavaScript和Quarkus。</p><p></p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/09/java-news-roundup-sep04-2023/\">https://www.infoq.com/news/2023/09/java-news-roundup-sep04-2023/</a>\"</p>",
    "publish_time": "2023-09-25 09:27:58",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "ByConity 技术详解：Hive 外表和数据湖接入实践",
    "url": "https://www.infoq.cn/article/zTo0jazjLIhjweX2TmLw",
    "summary": "<p>随着大数据处理需求的不断增加，更低成本的存储和更统一的分析视角变得愈发重要。数据仓库作为企业核心决策支持系统，如何接入外部数据存储已经是一个技术选型必须考虑的问题。也出于同样的考虑，ByConity 0.2.0 中发布了一系列对接外部存储的能力，初步实现对 Hive 外表及数据湖格式的接入。</p><p></p><h1>支持 Hive 外表</h1><p></p><p>随着企业数据决策的要求越来越高，Hive 数据仓库已成为了许多组织的首选工具之一。通过在查询场景中结合 Hive， ByConity 可以提供更全面的企业决策支持和打造更完整的数据管理模式。因此从 0.2.0 版本开始，ByConity 可以通过建立外表的形式访问 Hive 数据。</p><p></p><h2>原理和使用</h2><p></p><p>ByConity 主要的表引擎为 CnchMergeTree。在连接外部存储时，需要基于不同的外表引擎。比如创建 Hive 外表时，需要通过 CnchHive 引擎读取 Parquet 以及 ORC 格式的 Hive 数据。</p><p><code lang=\"null\">CREATE TABLE tpcds_100g_parquet_s3.call_center\nENGINE = CnchHive('thrift://localhost:9083', 'tpcds', 'call_center')\nSETTINGS region = '', endpoint = 'http://localhost:9000', \n         ak_id = 'aws_access_key', ak_secret = 'aws_secret_key', vw_default = 'vw_default'</code></p><p></p><p>通过指定 HiveMetastore uri，Hive database 以及 Hive table。 ByConity 会获取并解析 Hive table 元数据，自动推断表的结构（列名，类型，分区）。查询时 server 通过 List 远端文件系统，来获取需要读取的文件，之后 server 下发文件给 workers，worker 负责从远端文件系统读取数据，整体的执行流程与 CnchMergeTree 基本一致。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d5/d58d244a05a3df67915b9cab52c84835.png\" /></p><p>通过配置 disk_cache，worker 端可以把远端的文件存入本地磁盘缓存来加速下一次读取的速度。</p><p></p><h2>性能优化</h2><p></p><p>此外，CnchHive 还实现了一些重要的性能优化手段以达到与 Presto/Trino 同水平的外表性能：</p><p></p><p>支持分区剪枝和分片级别剪枝</p><p>分区剪枝和分片级别剪枝是 Hive 的性能优化技术。分区剪枝允许 Hive 在查询时仅扫描与查询条件相关的分区，而不是全表扫描，从而大大减少查询的执行时间。对于一些文件格式，例如 Parquet，可以通过读取文件中每个 row group 的 minmax value，对 row groups 进行裁剪，进一步减少读取的数据量。</p><p></p><p>Hive 统计信息集成优化器</p><p>CnchHive 引入了统计信息集成优化器，它可以根据数据的统计信息自动选择最佳的执行计划。这使得查询的执行更加智能和高效，同时减少了手动调整查询计划的工作量。统计信息集成优化器可以在 benchmark 中显著提高查询性能。</p><p></p><p>Benchmark（ByConity vs Trino)</p><p>TPC-DS（Transaction Processing Performance Council Decision Support）是一个标准化的决策支持基准，用于评估数据仓库系统的性能。ByConity 0.2.0 发布的 CnchHive 引擎通过优化查询执行计划，不仅能完整跑通 TPC-DS 基准测试，同时在性能方面表现出色。</p><p></p><p>测试信息：</p><p>部署模式：Kubernetes 部署，基于 AWS EC2 r5.12large 机型物理资源规模：4 Worker(48cpu, 256Gb mem)测试使用的参数：enable_optimizer : 开启优化器dialect_type ANSI: 使用标准 Ansi SQLs3_use_read_ahead: 关闭 S3 的 ReadAhead 功能remote_read_min_bytes_for_seek: 两个读之间如果间隔小于 1MB， 不回 seekdisk_cache_mode=SKIP_DISK_CACHE 关闭 worker 的本地磁盘缓存，模拟纯冷读场景parquet_parallel_read=1 使用 parquet 的 parallel readenable_optimizer_fallback=0 优化器执行失败直接返回报错，用于测试场景exchange_enable_multipath_reciever=0 执行层的参数优化图例补充：纵坐标单位 毫秒，横坐标单位 TPC-DS 查询语句标号；</p><p><img src=\"https://static001.geekbang.org/infoq/eb/eb931a71a0e433d18970abbf4bf11225.png\" /></p><p></p><h1>支持 Hudi 外表</h1><p></p><p></p><h2>Hudi 主要概念</h2><p></p><p>从实际的业务场景出发，对于数据湖数据的需求可以先分为两大类：读偏好和写偏好；所以 Apache Hudi 提供了两种类型的表：</p><p>Copy On Write 表：简称 COW，这类 Hudi 表使用列文件格式（例如 Parquet）存储数据，如果有数据更新，则会重写整个 Parquet 文件，适合读偏好的操作；Merge On Read 表：简称 MOR，这类 Hudi 表使用列文件格式（例如 Parquet）和行文件格式（例如 Avro）共同存储数据。一般 MOR 表是用列存存储历史数据，行存存储增量和有更新的数据。数据更新时，先写入行存文件中，然后进行压缩，根据可配置的策略以同步或异步方式生成列式存储文件，适合写偏好的操作；</p><p></p><p>对于这两种不同类型的表和场景，Hudi 提供了不同的查询方式：</p><p><img src=\"https://static001.geekbang.org/infoq/ec/ec9d23eafa71bf03c290ab6e7f36c02c.png\" /></p><p>补充说明：Read Optimized Queries 是对 MOR 表类型快照查询的优化，通过牺牲查询数据的时效性，来减少在线合并日志数据产生的查询延迟。</p><p></p><h2>原理和使用</h2><p></p><p></p><h3>原理概述</h3><p></p><p>ByConity 实现了对 COW 表的进行快照查询。在开启 JNI Reader 后可以支持 MoR 表的读取。Hudi 支持同步 HiveMetastore，因此 ByConity 可以通过 HiveMetastore 感知 Hudi 表。</p><p></p><p>普通 CoW 表可以直接使用 CnchHive 引擎进行查询。</p><p><code lang=\"null\">CREATE TABLE hudi_table\nENGINE = CnchHive('thrift://localhost:9083', 'hudi', 'trips_cow')</code></p><p>开启 JNI Reader 后，ByConity 可以通过 CnchHudi 表引擎来读取 Hudi CoW 以及 MoR 表。</p><p><code lang=\"null\">CREATE TABLE hudi_table\nENGINE = CnchHudi('thrift://localhost:9083', 'hudi', 'trips_cow')</code></p><p>对于 Hudi MoR 表，ByConity 引入 JNI 模块来调用 Hudi Java Client 读取数据。Java 读取的数据会写入内存中的 arrow table，并且通过<a href=\"https://arrow.apache.org/docs/format/CDataInterface.html\">Arrow C Data Interface</a>\"实现内存数据在 Java 与 C++之间的交换 ， C++把 arrow table 转换成 Block 的数据进行后续的数据处理。</p><p></p><h3>通过 Hudi Docker 快速上手</h3><p></p><p></p><p>https://hudi.apache.org/docs/docker_demo/ 配置 Hudi 的 docker 环境后，确保 ByConity 集群连接 hivemetastore 后，可在 ByConity 中进行建 Hudi 外表及查询操作。</p><p><code lang=\"null\">CREATE TABLE hudi.stock_ticks_mor_rt\nENGINE = CnchHudi('thrift://hivemetastore:9083', 'default', 'stock_ticks_mor_rt')\n\n-- MOR 查询\nSELECT\n    symbol,\n    max(ts)\nFROM stock_ticks_mor_rt\nGROUP BY symbol\nHAVING symbol = 'GOOG';\n\n┌─symbol─┬─max(ts)─────────────┐\n│ GOOG   │ 2018-08-31 10:59:00 │\n└────────┴─────────────────────┘</code></p><p></p><h1>Multi-Catalog</h1><p></p><p></p><h2>透明的 Catalog 设计</h2><p></p><p></p><p>Multi-Catalog 设计的目的是为了更方便地连接到多个外部数据目录，以增强 ByConity 的数据湖分析和外表查询功能。在数据架构设计上，核心的数据对象依然只有数据库和表。将 Catalog 信息在处理的时候嵌入到数据库名字中， 根据不同的数据库的命名模式来实现对应的处理。此类设计可以透明的兼容之前已经创建的库表元数据，仅就新增的外部数据目录进行更新。</p><p></p><p> 比如，创建 Hive 的 catalog 后，如果 query 的表名中带了 hive 的 catalog 名字，就会走 external catalog 相关的逻辑，从 Hive Metastore 中获取库表相关信息。查询方式如下所示。</p><p><code lang=\"null\">select * from hive_s3.tpcds.call_center</code></p><p></p><h2>Multi-Catalog 便捷性</h2><p></p><p></p><p>多 Catalog 的设计允许用户在同一个 Hive 实例中同时连接多个不同的存储和元数据服务，而不必为每个存储创建单独的 Hive 实例。这简化了数据管理和查询的复杂性，使组织能够更好地管理和利用其多样化的数据资源。目前已经支持的外部 Catalog 有：Hive，Apache Hudi，AWS Glue。</p><p></p><p>用户可以使用创建一个基于 Hive 和 S3 存储的 Catalog</p><p><code lang=\"null\">create external catalog hive_s3\nproperties\ntype='hive',\nhive.metastore.uri = 'thrift://localhost:9083',\naws.s3.region= 'aws_s3_region',\naws.s3.endpoint = 'http://localhost:9000',\naws.s3.access_key = 'aws_access_key',\naws.s3.secret_key = 'aws_secret_key'</code></p><p>然后使用三段式的命名来直接访问 Hive 外表</p><p><code lang=\"null\">select * from hive_s3.tpcds.call_center;</code></p><p>也可以使用 query 来查看 external catalog 相关的信息</p><p><code lang=\"null\">show create external catalog hive_s3; // display information releated to hive_s3\nshow databases from hive_s3; // show databases in hive_s3\nshow tables from hive_s3.tpcds; // show tables in tpcds database in hive. </code></p><p></p><p><code lang=\"null\">show create external catalog hive_s3;\nshow databases from hive_s3; \nshow tables from hive_s3.tpcds; </code></p><p></p><h1>未来规划</h1><p></p><p>因为越来越多的数据需求时需要整合不同的数据存储，ByConity 会持续丰富对接数据湖和外部存储的能力，增强与上下游工具的集成。2023 年路线图可以查看 Github 上的讨论：https://github.com/ByConity/ByConity/issues/26。同时我们也会重点考虑先投入以下内容：对接 Iceberg，DeltaLake 等更多数据湖格式；引入 Native reader 提高 Parquet 文件读取效率；优化文件分配策略，使得每个 worker 的 workload 更加均匀等。</p><p></p><p>相关专题推荐：<a href=\"https://www.infoq.cn/theme/193\">《开源云原生数仓ByConity技术与实践全解》</a>\"</p><p></p><p></p>",
    "publish_time": "2023-09-25 09:57:10",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "ByConity 技术详解：内置 ELT 能力实现原理和使用",
    "url": "https://www.infoq.cn/article/6bWZDrEHV2DzNZef8qko",
    "summary": "<p>谈到数据仓库， 一定离不开使用Extract-Transform-Load (ETL)或 Extract-Load-Transform (ELT)，即将来源不同、格式各异的数据提取到数据仓库中，并进行处理加工。传统的数据转换过程一般采用Extract-Transform-Load (ETL)来将业务数据转换为适合数仓的数据模型，然而，这依赖于独立于数仓外的ETL系统，因而维护成本较高。</p><p></p><p>ByConity 作为云原生数据仓库，从0.2.0版本开始逐步支持 Extract-Load-Transform (ELT)，使用户免于维护多套异构数据系统。本文将介绍 ByConity 在ELT方面的能力规划，实现原理和使用方式等。</p><p></p><h2>ETL场景和方案</h2><p></p><p></p><h3>ELT与ETL的区别</h3><p></p><p>ETL：是用来描述将数据从来源端经过抽取、转置、加载至目的端（数据仓库）的过程。Transform通常描述在数据仓库中的前置数据加工过程。</p><p><img src=\"https://static001.geekbang.org/infoq/db/db9dfdb346e9b17b146a8baf590cc32d.png\" /></p><p>ELT 专注于将最小处理的数据加载到数据仓库中，而把大部分的转换操作留给分析阶段。相比起前者（ETL)，它不需要过多的数据建模，而给分析者提供更灵活的选项。ELT已经成为当今大数据的处理常态，它对数据仓库也提出了很多新的要求。</p><p></p><h3>资源重复的挑战</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/59/59e844ada9156d24a49cb2aa623df08f.png\" /></p><p></p><p>典型的数据链路如下：我们将行为数据、日志、点击流等通过MQ/ Kafka/ Flink将其接入存储系统当中，存储系统又可分为域内的HDFS 和云上的 OSS&amp; S3 这种远程储存系统，然后进行一系列的数仓的ETL操作，提供给 OLAP系统完成分析查询。</p><p></p><p>但有些业务需要从上述的存储中做一个分支，因此会在数据分析的某一阶段，从整体链路中将数据导出，做一些不同于主链路的ETL操作，会出现两份数据存储。其次在这过程中也会出现两套不同的ETL逻辑。</p><p>当数据量变大，计算冗余以及存储冗余所带来的成本压力也会愈发变大，同时，存储空间的膨胀也会让弹性扩容变得不便利。</p><p></p><h3>业界解决思路</h3><p></p><p>在业界中，为了解决以上问题，有以下几类流派：</p><p>数据预计算流派：如Kylin等。如果Hadoop系统中出报表较慢或聚合能力较差，可以去做一个数据的预计算，提前将配的指标的cube或一些视图算好。实际SQL查询时，可以直接用里面的cube或视图做替换，之后直接返回。流批一体派：如 Flink、Risingwave。在数据流进时，针对一些需要出报表或者需要做大屏的数据直接内存中做聚合。聚合完成后，将结果写入HBase或MySQL中再去取数据，将数据取出后作展示。Flink还会去直接暴露中间状态的接口，即queryable state，让用户更好的使用状态数据。但是最后还会与批计算的结果完成对数，如果不一致，需要进行回查操作，整个过程考验运维/开发同学的功力。湖仓一体&amp;HxxP：将数据湖与数据仓库结合起来。</p><p></p><h2>ELT in ByConity</h2><p></p><p></p><h3>整体执行流程</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/55/55fa10d8fdc390e0fd0003a0f217cff4.png\" /></p><p>ELT任务对系统的要求：</p><p>整体易扩展：导入和转换通常需要大量的资源，系统需要通过水平扩展的方式来满足数据量的快速增长。可靠性和容错能力：大量的job能有序调度；出现task偶然失败（OOM）、container失败时，能够拉起重试；能处理一定的数据倾斜效率&amp;性能：有效利用多核多机并发能力；数据快速导入；内存使用有效（内存管理）；CPU优化（向量化、codegen）生态&amp;可观测性：可对接多种工具；任务状态感知；任务进度感知；失败日志查询；有一定可视化能力</p><p></p><p>ByConity 针对ELT任务的要求，以及当前场景遇到的困难，新增了以下特性和优化改进。</p><p></p><h3>分阶段执行（Stage-level Scheduling）</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/6f/6feaa47877b8523f604b661a027ef754.png\" /></p><p></p><h4>原理解析</h4><p></p><p>当前 ClickHouse的 SQL 执行过程如下：</p><p>第一阶段，Coordinator 收到分布式表查询后将请求转换为对 local 表查询发送给每个 shard 节点；第二阶段，Coordinator 收到各个节点的结果后汇聚起来处理后返回给客户端；</p><p></p><p>ClickHouse 将Join操作中的右表转换为子查询，带来如下几个问题都很难以解决：</p><p>复杂的query有多个子查询，转换复杂度高；Join表较大时，容易造成worker节点的OOM；聚合阶段在Cooridnator，压力大，容易成为性能瓶颈；</p><p><img src=\"https://static001.geekbang.org/infoq/ec/ec35ad59497d898e76e6e5ab1df7b87a.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/53/53642ac5e0c232e8c5791e45d48a7d59.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fe/fef407ce1f5dc6f4c34f3adb87ccc38a.png\" /></p><p></p><p>不同于ClickHouse，我们在ByConity 中实现了对复杂查询的执行优化。通过对执行计划的切分，将之前的两阶段执行模型转换为分阶段执行。在逻辑计划阶段，根据算子类型插入exchange算子。执行阶段根据exchange算子将整个执行计划进行DAG切分，并且分stage进行调度。stage之间的exchange算子负责完成数据传输和交换。</p><p></p><p>关键节点：</p><p>exchange节点插入切分stagestage schedulersegment executerexchange manager</p><p><img src=\"https://static001.geekbang.org/infoq/cc/cc3d3d1607d89c020a5256c1c8a72941.png\" /></p><p>这里重点来讲一下exchange的视线。上图可以看到，最顶层的是query plan。下面转换成物理计划的时候，我们会根据不同的数据分布的要求转换成不同的算子。source层是接收数据的节点，基本都是统一的，叫做ExchangeSource。Sink则有不同的实现，BroadcastSink、Local、PartitionSink等，他们是作为map task的一部分去运行的。如果是跨节点的数据操作，我们在底层使用统一的brpc流式数据传输，如果是本地，则使用内存队列来实现。针对不同的点，我们进行了非常细致的优化：</p><p>数据传输层进程内通过内存队列，无序列化，zero copy进程间使用brpc stream rpc，保序、连接复用、状态码传输、压缩等算子层批量发送线程复用，减少线程数量</p><p></p><h4>带来的收益</h4><p></p><p>因为ByConity 彻底采用了多阶段的查询执行方式，整体有很大的收益：</p><p>Cooridnator更稳定、更高效聚合等算子拆分到worker节点执行Cooridnator节点只需要聚合最终结果Worker OOM减少进行了stage切分，每个stage的计算相对简单增加了exchange算子，减少内存压力网络连接更加稳定、高效exchange算子有效传输复用连接池</p><p></p><h3>自适应的调度器（Adaptive Scheduler）</h3><p></p><p>Adaptive Scheduler 属于我们在稳定性方面所做的特性。在OLAP场景中可能会发现部分数据不全或数据查询超时等，原因是每个worker是所有的query共用的，这样一旦有一个worker 较慢就会导致整个query的执行受到影响。</p><p><img src=\"https://static001.geekbang.org/infoq/a8/a8a0cbbcc9483dfa450c22278ed120a4.png\" /></p><p>计算节点共用存在的问题：</p><p>Scan 所在的节点负载和不同查询所需的扫描数据量相关，做不到完全平均；各 Plan Segment 所需资源差异大；</p><p></p><p>这就导致worker节点之间的负载严重不均衡。负载较重的worker节点就会影响query整体的进程。因此我们做了以下的优化方案：</p><p>建立 Worker 健康度机制。Server 端建立 Worker 健康度管理类，可以快速获取 Worker Group 的健康度信息，包括CPU、内存、运行Query数量等信息。自适应调度：每个SQL 根据 Worker 健康度动态的进行选择以及计算节点并发度控制。</p><p></p><h3>查询的队列机制（Query Queue）</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/ad/ad3a3313d4dcc5abb1a30e6305fc4a28.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/96cb548b0092e6994faf05dda0da3fb7.png\" /></p><p>我们的集群也会出现满载情况，即所有的worker都是不健康的或者满载/超载的，就会用查询队列来进行优化。</p><p></p><p>我们直接在server端做了一个manager。每次查询的时候manager会去check集群的资源，并且持有一个锁。如果资源不够用，则等待资源释放后去唤醒这个锁。这就避免了Server端不限制的下发计算任务，导致worker节点超载，然后崩掉的情况。</p><p></p><p>当前实现相对简单。server是多实例，每个server实例中都有queue，所持有的是一个局部视角，缺乏全局的资源视角。除此之外，每个queue中的查询状态没有持久化，只是简单的缓存在内存中。</p><p></p><p>后续，我们会增加server之间的协调，在一个全局的视角上对查询并发做限制。也会对server实例中query做持久化，增加一些failover的场景支持。</p><p></p><h3>异步执行（Async Execution）</h3><p></p><p><img src=\"https://static001.geekbang.org/infoq/2e/2e73bab299f6f8583eaba569078ab6cb.png\" /></p><p>ELT任务的一个典型特征就是：相对于即时分析，他们的运行时间会相对较长。一般ELT任务执行时长为分钟级，甚至到达小时级。</p><p></p><p>目前 ClickHouse的客户端查询都采用阻塞的方式进行返回。这样就造成了客户端长期处于等待的情况，而在这个等待过程中还需要保持和服务端的连接。在不稳定的网络情况下，客户端和服务端的连接会断开，从而导致服务端的任务失败。</p><p></p><p>为了减少这种不必要的失败，以及减少客户端为了维持连接的增加的复杂度。我们开发了异步执行的功能，它的实现如下：</p><p>用户指定异步执行。用户可以通过settings enable_async_query = 1的方式进行per query的指定。也可以通过set enable_async_query = 1的方式进行session级别的指定。如果是异步query，则将其放到后台线程池中运行静默io。当异步query执行时，则需要切断它和客户端的交互逻辑，比如输出日志等。</p><p></p><p>针对query的初始化还是在session的同步线程中进行。一旦完成初始化，则将query状态写入到metastore，并向客户端返回async query id。客户端可以用这个id查询query的状态。async query id返回后，则表示完成此次查询的交互。这种模式下，如果语句是select，那么后续结果则无法回传给客户端。这种情况下我们推荐用户使用async query + select...into outfile的组合来满足需求。</p><p></p><h2>未来规划</h2><p></p><p>针对ELT混合负载，ByConity 0.2.0版本目前只是牛刀小试。后续的版本中我们会持续优化查询相关的能力，ELT为核心的规划如下：</p><p></p><h3>故障恢复能力</h3><p></p><p>算子SpillSort、Agg、Join 算子Spill；Exchange Spill 能力；Recoverability 容错恢复算子执行恢复：ELT任务运行时长较长时，中间 Task的偶发失败会导致整个Query失败，支持Task 级别重试可以极大地降低环境原因导致的偶发失败；Stage重试：当节点失败时，可以进行 Stage级别的重试；保存队列作业状态的能力；Remote Shuffle Service：当前业界开源的 shuffle service通常为Spark定制，没有通用的客户端，比如c++客户端。后续我们会补充这部分能力。</p><p></p><h3>资源</h3><p></p><p>计算资源可指定：用户可指定query需要的计算资源；计算资源预估/预占：可动态预估query需要的计算资源，并通过预占的方式进行调配；动态申请资源：当前worker均为常驻进程/节点。动态申请资源可以提高利用率；更细粒度的资源隔离：通过worker group或者进程级别的隔离，减少各query之间相互影响。</p><p></p><p>相关专题推荐：<a href=\"https://www.infoq.cn/theme/193\">《开源云原生数仓ByConity技术与实践全解》</a>\"</p>",
    "publish_time": "2023-09-25 10:15:12",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "使用 Ruby on Rails 构建 GitHub，每周做一次升级",
    "url": "https://www.infoq.cn/article/cKazWQfw5AxHobR4FcTI",
    "summary": "<p></p><blockquote>本文介绍了 GitHub 如何使用 Ruby on Rails 构建他们的应用程序，并且每周如何进行升级。文章中提到 GitHub 与社区合作来确保每个 Rails 发布版本在生产环境中运行，并强调了投资于 Rails 的重要性。</blockquote><p></p><p></p><p>自从成立以来，GitHub.com 一直是一个基于 Ruby on Rails 的单体应用。如今，该应用已经接近两百万行代码，每天有超过一千名工程师在上面协作。我们平均每天部署 20 次，几乎每周都会进行一次 Rails 的升级。</p><p></p><p></p><h3>每周升级 Rails</h3><p></p><p></p><p>每个周一，我们都会自动触发一个<a href=\"https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows#schedule\">计划好的 GitHub Action 工作流</a>\"，创建一个拉取请求，将我们的 Rails 版本更新到当天 Rails 主干分支的最新提交。我们所有的构建都在这个新版本的 Rails 上运行。一旦所有构建通过，我们会审核这些更改，并在第二天发布。从周一开始升级，用户就已经有一个打开的拉取请求，链接到此次 Rails 升级提出的更改和一个已经完成的构建。</p><p></p><p>这个过程与几年前我们进行 Rails 升级的方法大不相同。过去，我们花费数月的时间从自定义的 Rails 分支迁移到更新的稳定版本，然后我们维护了两个 Gemfiles，以确保我们能够与即将发布的版本兼容。现在，升级只需要不到一周的时间。（可以在这篇 <a href=\"https://github.blog/2018-09-28-upgrading-github-from-rails-3-2-to-5-2/\">2018 年的博文</a>\"中了解更多有关此过程的信息。）我们与社区密切合作，确保每个 Rails 发布版本在正式发布之前都在生产环境中运行。</p><p></p><p>使用最新版本的 Rails 有很多实际的好处：</p><p></p><p>我们为 GitHub 的开发人员提供最新版本的 Rails，确保他们可以使用所有最新的改进，包括更好的数据库连接处理、更快的视图渲染以及每天在 Rails 中发生的惊人工作，为他们提供最佳的工具版本。我们已经几乎删除了所有的 Rails 补丁。由于我们正在运行最新版本的 Rails，开发人员现在可以直接提交补丁到 Rails，无需等待 Rails 的更改。与团队共享 Rails 工作现在比以往任何时候都更容易！你不需要再告诉团队你在下一版中发现的 Rails 问题，而是可以在 Rails 上直接工作并在下周就看到结果！保持最新的依赖关系可以使我们拥有更好的安全姿态。由于我们每周进行升级，所以在出现安全咨询时添加升级是标准做法，不需要额外的工作。没有所谓的“大爆炸”迁移。由于每个 Rails 升级只包含少量更改，如果有不兼容性，更容易理解和深入挖掘。从一个未知的位置出现的意外更改是来自困难升级的最糟糕的问题。这种升级策略可以减轻这些问题。在主干分支中捕获错误并做出贡献可以加强我们的工程团队，并帮助我们的开发人员深入了解我们的应用程序及其依赖项。</p><p></p><h3>持续测试 Ruby</h3><p></p><p></p><p>为了确保应用在最新的 Ruby 版本上运行良好，我们采用了持续测试的方法。在 2022 年 2 月，我们升级到 Ruby 3.1，并开始使用并行构建来测试从 3.2-alpha 版本提交的 Ruby shas。当 CI 运行 GitHub Rails 应用程序时，会运行两个版本的构建：一个版本使用我们在生产环境中运行的 Ruby 版本进行构建，另一个版本则使用包括最新 Ruby 更改的最新 Ruby 提交进行构建。我们每周更新一次。</p><p></p><p>尽管我们每次更改都会构建 Ruby，但 GitHub 只会发布经过编号的 Ruby 版本到生产环境。这些构建帮助我们保持与即将到来的 Ruby 版本的兼容性，并为我们提供关于 Ruby 更改的见解。</p><p></p><p>2022 年 12 月初，CI 让我们有了信心，认为我们与即将发布的 Ruby 3.2 兼容。因此，我们可以使用部分生产流量测试 Ruby 发布候选版，并向 Ruby 团队提供我们发现的任何更改的见解。例如，我们可以复现由于<a href=\"https://bugs.ruby-lang.org/issues/19165\">关键字参数处理引起的分配</a>\"增加问题，并在 Ruby 3.2 发布之前得到修复。此外，我们还确定了在<a href=\"https://github.com/ruby/ruby/commit/7563604fb868d87057733f52d780d841fc1ab6bb\">应用</a>\" to_str 和 #to_i 时的微妙变化。由于我们不断升级，识别和解决这些问题已经成为标准惯例。</p><p></p><p>每周升级 Ruby 的过程使我们能够在一个月内从 Ruby 3.1 升级到 Ruby 3.2 的单体架构，毕竟，我们已经在生产中测试和运行过 Ruby 3.2！这是我们迄今为止完成的最快的 Ruby 升级。我们在 Ruby 3.2.1 发布当天打破了这个记录。</p><p></p><p>这个升级过程对我们与 Ruby 核心团队的合作证明非常宝贵。拥有这些构建的一个好的附带效果是，我们能够轻松地测试和分析我们自己的 Ruby 更改，然后再向上游建议。这使我们更容易识别我们自己应用程序中的回归，并更好地理解更改对生产环境的影响。</p><p></p><h3>我也应该这么做吗？</h3><p></p><p></p><p>GitHub 之所以能够频繁升级 Ruby 和 Rails，是因为具备了一定的工程成熟度。每周升级 Rails 需要一个全面的测试套件，许多优秀的工程师致力于维护和改进它。此外，我们还从拥有出色的测试环境和渐进式部署中获得信心。我们的测试套件很可能会捕捉到问题，如果没有，我们相信在部署之前会发现并解决它。</p><p></p><p>如果你拥有这些工具，你也应该每周升级 Rails，并使用最新的 Ruby 进行测试。GitHub 成为了更好的 Rails 应用程序，这使我们的团队能够进行我非常自豪的工作。</p><p></p><p>Ruby 专家 Eileen Uchitelle 在 2022 年的 <a href=\"https://www.youtube.com/watch?v=MbqJzACF-54\">Rails Conf Keynote</a>\" 中解释了为什么投资于 Rails 很重要：</p><p></p><p>归根结底，如果更多公司将框架视为应用程序的扩展，这将导致更高的韧性和稳定性。投资于 Rails 可确保您的基础不会在应用程序的重压下崩溃。将其视为应用程序中不重要的部分是一个错误，许多领导者都犯了这个错误。</p><p></p><p>感谢来自全世界的人们的贡献，使用 Ruby 比以往任何时候都更好。GitHub 和其他数百家公司一样，受益于 Ruby 和 Rails 不断改进。定期升级和投资于我们的框架是我们在 GitHub Ruby 架构团队上的工作的核心。我们始终感激 Ruby 社区，并很高兴我们能以一种改进我们的应用程序和工具以及为每个人改进它们的方式回馈。</p><p></p><p>作者介绍：</p><p>Adam Hess，软件开发者。</p><p></p><p>原文链接：</p><p>https://github.blog/2023-04-06-building-github-with-ruby-and-rails/</p>",
    "publish_time": "2023-09-25 12:06:07",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "裁错了还是变相降薪？大厂粗暴裁员后又求员工回来，网友：拿什么再爱你？",
    "url": "https://www.infoq.cn/article/7FI0GiPmjOD70e0WSCNZ",
    "summary": "<p>过去一年，多家大厂掀起了“裁员潮”。但在裁员风波过去后，一些企业似乎开始“反思”自己的行为：是不是裁多了？裁错了？</p><p>&nbsp;</p><p>近期，包括 Meta、Salesforce 在内的企业开始召回一部分之前被解雇的员工，并在 AI 等热门领域加大招聘力度。但对于被裁的员工来说，该不该回去呢？</p><p></p><h2>粗暴裁员后，Meta 恳请部分员工回归</h2><p></p><p>&nbsp;</p><p>去年 11 月，Meta 首席执行官扎克伯格曾宣布裁员 1.1 万人，约占当时员工总数的 13%。今年&nbsp;3 月，Meta 宣布将在今年裁员 1 万人。截至今年 5 月，Meta 已经通过多轮裁员削减了四分之一人力。</p><p>&nbsp;</p><p>消息显示，随着 Meta 公司业绩改善，招聘工作再次启动。Meta 公司重新开始加快招聘步伐，特别是工程和技术岗位。Meta 当前的几百个招聘岗位主要集中在软件、硬件和 AR/VR 工程领域，外加基础设施和数据中心方面的主要技术角色。一位知情人士表示，业务岗位则几乎没有招聘，这也是受到最新一轮裁员影响最大的领域。由于大幅削减了经理岗，Meta 目前的大多数空缺职位集中在个人贡献者方面。</p><p>&nbsp;</p><p>值得一提的是，在过去几个月，不少之前被 Meta 解雇的员工都再次接到了社交巨头伸来的橄榄枝。据悉，自去年 11 月以来，所有被解雇的 Meta 员工都可通过“校友门户”重新申请新职位。</p><p>&nbsp;</p><p>有知情人士指出，Meta 正在寻求经验丰富的人才，并减少对应届毕业生和实习生的招录。返岗成功率最高的，往往是那些之前担任较高工程职务且绩效评估良好的人选。该公司也对外部候选人敞开了怀抱，离职的老员工也需要经过完整面试的筛选。另一位知情人士提到，尽管如此，“10 比 1”的招聘比例还是更倾向于之前被裁撤的老员工。</p><p>&nbsp;</p><p>据外媒报道，三名知悉公司内情的人士透露，目前已经有几十名员工被重新雇用，且大部分是在今年 6 月。但知情人士称，Meta 重新雇用的老员工中，有不少担任的是之前没接触过的工作、或者工资/职级有所下降。</p><p>&nbsp;</p><p>一位重新回归 Meta 的老员工表示，尽管他申请的职级与被裁之前相同，但总薪酬还是缩水了约 10%。不过考虑到目前 Meta 股价正在上涨，此人预计收入将在一年之内回归被裁前的水平。</p><p>&nbsp;</p><p>其他人则不太能接受 Meta 这番神奇操作。另一位曾被解雇、目前在重新申请入职的老员工表示，他们最近看到关于原本工作岗位的招聘信息。现在这个岗位已经被转为外包形式，且薪酬比之前降低了 20%。</p><p></p><h2>裁员后又召回，成大厂常规操作？</h2><p></p><p>&nbsp;</p><p>Meta 这波裁员后又召回老员工的操作并非先例。马斯克在刚接手 Twitter 时，也曾大刀阔斧砍掉不少岗位，但在员工离开之后才意识到 Twitter 根本离不开他们掌握的技能和经验。</p><p>&nbsp;</p><p>去年 11 月，Twitter 在解雇了 3700 人之后，很快又对数十名员工进行了召回。有消息人士称，一些被要求重回&nbsp;Twitter&nbsp;的人是“被错误解雇”的，还有一些人在管理层意识到他们的工作和经验可能是构建马斯克设想的新功能所必需之前就被解雇了：这些人对 Twitter 生态系统的运转至关重要。管理层很快就意识到了这一点，并要求他们回去。</p><p>&nbsp;</p><p>云计算公司 Salesforce 也有过类似的操作。去年 11 月初，Salesforce 宣布进行第一轮裁员，尽管具体裁员人数没有透露，但据悉不超过 1000 人。今年年初，Salesforce 宣布裁员 10%，大约 8000 名员工将受到影响。此外，还将关闭部分办公室以降低开支。</p><p>&nbsp;</p><p>此前不少硅谷巨头发现疫情期间的盲目扩张令人员冗余，于是开始大刀阔斧加以裁撤。据科技招聘网站 Trueup.io 称，今年到目前为止，全球科技企业已经累计裁员 35 万名，且一月份的裁员力度最大。</p><p>&nbsp;</p><p>与今年年初相比，如今的市场需求有了巨大转变，不少曾经裁员的大厂开始重新招聘。近期，Salesforce 计划招聘 3000 名员工，Salesforce 向彭博社证实，本轮招聘重点主要集中在销售、工程和数据云产品团队，并表示新员工将有助于发展其接下来重点关注的 AI 业务。</p><p>&nbsp;</p><p>此外，Salesforce 还开始召回一部分之前被解雇的员工。Salesforce 公司 CEO Marc Benioff 甚至直接向已经在其他单位就职的前员工们喊话，希望他们能考虑回归。Salesforce 最近还举办了一场吸引老员工的活动，向约 50 名前高管送上穿着绘有“飞去来器”图案衬衫的毛绒玩具。</p><p>&nbsp;</p><p>但对于已经被解雇、特别是还没有找到新工作的员工们来说，Salesforce 当初粗暴的裁员方式实在令人心有余悸。部分员工对此提出批评，称这种方式似乎与 Salesforce 这家云软件厂商的企业文化背道而驰。毕竟 Salesforce 高管、特别是 Benioff 本人，一直强调公司员工之间都是“家人”。</p><p>&nbsp;</p><p>当然，这种忽冷忽热的态度对于酒店等行业的雇员来说一点也不新鲜。在疫情爆发之时，不少餐饮服务业的员工被解雇。而在政策放开之后，雇主们又争先恐后填补空缺，为员工们开出了更好的工作条件。</p><p>&nbsp;</p><p>现在，同样的情况又落到了科技工作者头上。有些人可能要求开出更高的薪酬才考虑回归，也有些人则对此表示理解，毕竟大规模裁员并非人力所能掌控。但劳动保障仍然成为行业内一大重要考量因素：在 Trueup.io 上，亚马逊和 Meta 等大厂的招聘列表旁，都会用数字标注该公司上一轮裁员是多少天之前。</p><p>&nbsp;</p><p>强劲的需求当然会吸引一部分员工回归。总体而言，行业对于掌握 AI 技能的人才抱有强烈兴趣。LinkedIn 发言人在邮件采访中表示，LinkedIn 上用英语提及 AI 技术的全球职位发布量比 ChatGPT 刚刚亮相时的 2022 年 11 月增长了 21 倍。</p><p></p><h2>被裁后该不该再回去？</h2><p></p><p>&nbsp;</p><p>哈佛商学院研究裁员问题的管理实践教授 Sandra Sucher 表示，粗暴裁员的企业往往更难说服前员工重返岗位。在某些情况下，如果当初的裁员比较顺畅合理，那么前员工可能更愿意回归。</p><p>Sucher 解释道，“想让我回去，说明你还重视我。”但前员工们还是想确定自己要如何在企业内重建职业生涯，比如“不止是当前，我的未来道路会是什么？”</p><p>&nbsp;</p><p>Sucher 表示，对于部分员工来说，个人和组织之间的彼此认知可能是影响回归的核心因素。她认为在做出决定之前，员工们不妨问问自己：我当初为什么被解雇？最近发生了什么变化，让你再次需要我了？我为什么要继续相信你？</p><p>&nbsp;</p><p>要做出这样的决定并不容易。特别对某些被粗暴对待的员工，重建信任已经几乎没有可能。Sucher 指出，“我会在心中暗暗对公司做一番评判，但不会从根本上给予信任。”</p><p>&nbsp;</p><p>而对于那些打算回归的员工，则需要认真打听公司的下一步战略，确定自己不会很快被再次裁撤。</p><p>&nbsp;</p><p>Sucher 认为，裁员后又被召回的员工对公司的态度恐怕会发生难以逆转的影响。“人们心中的安全感被永久打破，大家再也不相信「只要干得好，就能保住工作」这套理论了。”</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.businessinsider.com/salesforce-meta-big-tech-companies-rehire-workers-employees-laid-off-2023-9\">https://www.businessinsider.com/salesforce-meta-big-tech-companies-rehire-workers-employees-laid-off-2023-9</a>\"</p><p><a href=\"https://www.businessinsider.com/meta-rehiring-workers-from-layoffs-2023-8\">https://www.businessinsider.com/meta-rehiring-workers-from-layoffs-2023-8</a>\"</p>",
    "publish_time": "2023-09-25 13:59:17",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "大数据日志分析值2000亿？从思科收购Splunk说开去",
    "url": "https://www.infoq.cn/article/aIlET2GUut4SgrQYIEZ4",
    "summary": "<p><a href=\"https://www.infoq.cn/news/VVL0kfRbYXJH7W2pxiUA\">9月21日，思科公司表示，将以每股 157 美元的价格收购网络安全软件厂商 Splunk</a>\"。这笔现金交易总值约 280 亿美元（折合约 2047 亿元人民币），成为思科有史以来手笔最大的收购活动。此次收购价格相当于思科公司总市值的 12%左右。</p><p>&nbsp;</p><p>Splunk 以强大的日志分析功能出名，是一款在混合环境中增强企业可观察性、统一安全性和无限自定义应用的数据平台。Splunk是一家大数据厂商，也是一家安全厂商。该公司基于大数据平台构建了SIEM平台，将可观测性数据与安全数据相关联，帮助组织跟上动态威胁形势。另外还有一个产品线是IT运维类的可观测性产品，也是云计算里面比较通用的一个场景。</p><p>&nbsp;</p><p>思科 CEO Chuck Robbins 在声明中说道，“双方合兵一处，将共同推动下一代 AI 安全性与可观测性。从威胁检测与响应、再到威胁预测和预防，我们将帮助不同规模的组织机构拥有更高的安全性和弹性。”</p><p>&nbsp;</p><p>Splunk的收购案刷新了日志分析场景的企业的估值记录。对于这个新闻，安全圈显得特别激动。毕竟中国网络安全上市企业前100强，加起来的年营收额也没有超过1000亿人民币。而且整个A股上市的公司，几个头部的厂商加起来不到2000亿人民币的市值。</p><p>&nbsp;</p><p>恰巧腾讯安全在9月20日发布了一款云原生安全数据湖产品，腾讯安全也是这个领域的一个重磅玩家，这款产品也很对标Splunk，并且性能可达到PB级别的数据秒级查询（详情见：<a href=\"https://www.infoq.cn/article/ffVDN4YNTXAk4O5TfFDi\">腾讯安全发布云原生安全数据湖</a>\"）</p><p>&nbsp;</p><p>大数据日志分析这个细分场景为什么“价值千亿”？它有哪些应用前景？我们和腾讯云原生安全日志湖的两位资深专家进行了交流。</p><p>&nbsp;</p><p>采访嘉宾：</p><p>洪春华，腾讯安全副总经理洪春华，自2009年加入腾讯以来，先后负责腾讯安全后台海量服务开发、安全运营数据平台研发等工作。</p><p>Nill，腾讯安全大数据实验室数据湖技术负责人、资深技术专家。</p><p>&nbsp;</p><p>InfoQ：思科在2019年的时候也曾想收购数据分析公司Datadog，那么Datadog的日志分析产品跟腾讯安全的日志湖、Splunk之间有什么相同和不同。</p><p>&nbsp;</p><p>答：Datadog最早应该是做一些IT、基础设施、APM可观测的，后来开始做日志了，希望把一些log、trace 和 Metrics 做到一起，形成一个统一的分析，但大的方向还是大数据方向的。</p><p></p><p>他们在日志这块儿其实本身可以说经历了三代：</p><p>1. 第一代是分布式，但是是多个租户共享一个集群，租户之间的相互影响会比较大。</p><p>2. 第二代在分布式这块儿做了一些优化，存算一体但是可以横向快速扩容。</p><p>3. Datadog去年进行了第三代升级，真正做到了面向云原生，增加了存算分离、读写分离等一些新的特性。</p><p>&nbsp;</p><p>从这个意义层面上来说，其实Datadog跟腾讯安全日志湖的目标是一致的。</p><p>&nbsp;</p><p>而Splunk很早之前就是从日志出发的，慢慢发展到可观测性和安全场景，相当于是从大数据底层逻辑慢慢推上端应用。Splunk架构相对比较稳定，已经发展多年了，最近也在往云上推。所以，其实在我们的定位里，Splunk比较强的是它的可扩展性和应用性，用户可以在上面去定制开发自己的插件和应用，来满足各种各样的需求。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a1/a1bbfffbfc5c5d9e0adb5e3ce37c2b29.png\" /></p><p></p><p>&nbsp;</p><p>然而，从大数据能力这块儿，不管是Datadog、Splunk，他们都在逐步升级，但升级其实也是很痛苦的，因为他们对底层架构有依赖，包括协同客户的迁移。尤其是Datadog，可以看到它面向新的日志架构迁移的时候是非常痛苦的，因为整个架构存算分离这些东西跟原来是完全不一样的，它会背负一定的历史包袱。</p><p></p><p>对于腾讯安全日志湖的话，我们的优势是没有历史包袱。我们很早就注意到日志这块儿的苗头，比如大概在2021年的时候，海外Scalyr被安全厂商 SentinelOne收购，Humio 被安全厂商 CrowdStrike 收购。回头看整个国内的大数据市场（或者说安全市场），传统的安全厂商主要还是依赖于底层ES、Hadoop这些，在这上面做安全的分析，但从大数据能力来说，这些都是好几代之前的东西了。</p><p></p><p>考虑到我们现在已经进入到新的大数据时代了，大数据是各个场景和产品的生产资料，数据的能力是至关重要的。因此我们关注到这个问题之后，就开始投入研发推动腾讯安全日志湖的建设。</p><p>&nbsp;</p><p>其实在大的方向上，我们当时也是对标了海外比较先进的几个商业化的产品，比如Snowflake，我们在学习它的弹性。Datedog去年发布新的日志架构时，他们也提到了在弹性和存算分离上，他们也借鉴了Snowflake的理念。同时我们也一直在关注Splunk，在应用性、App化这块儿，也向它借鉴了不少。所以，回顾起来，我们当时看到在国内整个市场特别是安全市场，没有一款开源的东西能够满足我们自己的需求。基于这些契机，我们就决定研发了自己的安全日志湖。</p><p>&nbsp;</p><p>&nbsp;</p><p>InfoQ：腾讯安全的云原生数据湖的应用方式是什么？作为独立的产品来对外提供的话，还需要提供哪些功能？</p><p>&nbsp;</p><p>答：我们现在整个路径上面主要分为两条路：</p><p>&nbsp;</p><p>内部被集成。腾讯这几年在讲“被集成”战略，数据湖作为一个底座，会集成到SOC（安全运营中心）、NDR、零信任，云原生安全产品会集成我们这个数据湖的能力，用来做数据的存储、分析及后续的使用。外部被集成。我们现在也是发现特别多，包括安全厂商，包括系统集成商或者一些大型集团的信息化子公司，在应用上存在“卡点”。最近因为我们发布了这个数据湖，有友商也找过来，因为他们推了他们的XDR（可扩展安全检测与响应）产品推出来了以后，已经在客户侧都有落地了，但他们现在很快遇到一个瓶颈，就是在于数据量大的情况下确实算不过来，成本也极其之高，所以看到我们这个方案的时候，也会找过来聊这一块的合作。或者可以这么说，他们现在的方案基本上可以认为在真正的XDR方向上是跑不动的，所以现在也会找过来，这就是外部被集成。这块儿战略来看，我们可能会走得更稳健一些，现在看起来需求量挺大。</p><p>&nbsp;</p><p>另外，我们强调云原生数据湖作为“数据底座”，再在上层做App化。有了云原生，我们可以做弹性的伸缩，更方便地做隔离的操作。如果横向去看，整个行业来看，如果从安全厂商来看，这个我们肯定是独一份的，安全厂商多数还是在卖盒子，就是硬件服务器这种模式，远远还达不到云计算，更不用说云原生了。在整个云的大盘子里，用在安全里面我们也是独一家的技术落地。在App化方面，我们已经做了安全场景的App，包括情报的回溯、主机安全、零信任、全流量的分析等，这些方面的应用我们现在整个版本都已经准备好了。</p><p>&nbsp;</p><p>InfoQ：我们理解这次收购，一方面就是安全赛道，另一方面就是AI驱动的安全这条赛道，思科“借钱都要买”，您可不可以更细化地解释一下为什么安全领域的AI驱动是这样一个紧迫的态势？</p><p>&nbsp;</p><p>答：我简单介绍一下，因为今天早上也看到了数据，Splunk占了思科12%的市值，对思科来说收购Splunk确实是大手笔。思科这几年收购了不少安全方向的公司，包括做网络安全的公司，还有身份安全公司，及云原生安全的公司。在这个过程中，它把组件收购了以后马上发现了一个点，就是它缺少一个“大脑”。</p><p></p><p>刚刚讲到收购的公司，大家可以把它理解成是数据的生产方。举个例子，相当于家里装了摄像头，我在家门口装了摄像头，我在每个地方装了红外的感应，这些东西确实能够很简单地感受到有没有人入侵、有没有人把你家门给打开，但是很难做到你的一些熟人或者是家里经常来的这些人，或者是绕过你家防护的人，最后他到底有没有侵入到你整个资产的安全？这个时候缺少的是数据沉淀的平台、一个大脑分析的中心节点。所以，思科就着手做这件事情了。</p><p></p><p>当数据多了以后，能够跟AI大模型契合起来。我们都知道要去AI的话，就是算力、算法加数据，我相信思科肯定是有算力，也会有算法，但是数据方面其实是需要去沉淀的，如果你的一个数据不能保存下来，不能够留存下来做后续处理，那你比如说就是30天的数据，那你的大脑相当于永远只能够判定过去30天的事件，而人脑（之所以强大）在于能够把经验整体存下来。这个过程当中，数据的驱动的可能性是非常大的。</p><p></p><p>所以，它已经走到了这一步，它原来收购的安全组件、采集端已经收到了，再一个就是智能化大模型的契机，它需要有数据沉淀的平台。所以，在这个趋势下，我们认为它应该是会担心赶不上AI的末班车。</p><p>&nbsp;</p><p>InfoQ：大模型出来之后，大家看待数据的方式好像也发生了一些变化。如果落地在安全行业，您感觉我们看待数据的方式跟以前有哪些不同，或者说这次思科收购了这家公司之后，行业有哪些明显的反应？</p><p>&nbsp;</p><p>答：安全其实是一个挺悖论的行业，当你没有出现安全事件的时候，老板领导层、投资方很难感觉到安全的价值。但是如果说你出了安全事件以后，他依然会感觉你的安全投入在哪儿去了？我们看待数据的角度是一样的，原来大家看到数据就是你有没有直接检测出来入侵的行为，将这些入侵的行为处置，只要保存下来数据，通常会只保存的是结果，不关心过程。所以，包括我们的很多法律法规还是要求六个月只是存储一些基本的告警信息就够了，这个过程是这样的。</p><p></p><p>现在去看数据的时候，就不仅仅只是存六个月来满足合规，而是数据已经是生产的要素了，当这些数据积累下来，能不能帮助安全运维人员、专家更好更快地发现问题、解决问题，从而提升效率。</p><p></p><p>在腾讯内部，我们经常讲安全团队是能够帮助业务团队去成功的。为什么呢？因为我们在安全数据里面能够挖掘到不少关于业务本身的问题，能够帮助业务去成长，类似于说某一个漏洞它影响了这个业务，甚至是说某一群客户、某一个区域的客户对这块儿业务感兴趣的程度，从而帮助业务成长。所以，我的理解，原来我们只是为了满足一个合规，只要存一个结果，到现在它是一个生产要素，它是用来生产更多的高价值内容和结果，用数据喂养大模型，能够帮助业务更快地提升转型。</p><p></p><p>在这个过程中，其实像思科收购Splunk也是一个典型的案例，因为Splunk号称能够达到PB级存储，在这个存储过程当中成本能做到尽可能低。我的理解，接下来会有非常多的大模型在安全行业落地，在这个过程中大家对数据（特别是原始数据）的需求会急剧提升。</p><p>&nbsp;</p><p>InfoQ：您刚提到Splunk能处理PB级的数据，同时成本能做到很低，看报道说腾讯云原生数据湖也能做到PB级别的数据秒级查询，那腾讯这边是怎么平衡成本问题的呢？</p><p>&nbsp;</p><p>答：之前我们也做了分享。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/63/63130e663dbf99c2bd8f2b4244173d92.png\" /></p><p></p><p>&nbsp;</p><p>我们做的数据湖在降本这块儿做了不少工作，几个原因：</p><p>&nbsp;</p><p>底层技术层面，架构就是面向存算分离的。在传统存算一体的架构下，进行扩容的话，整个资源都需要扩容，在实现存算分离之后，面向新的云原生架构，可以按CPU扩容、按存储扩容，这样的话在扩容的时候就会避免一些浪费。之前提到弹性性能，传统的在安全领域做分析的时候，为了保证安全的可靠性，需要预留大量的资源。举个简单的例子，比如说像事件调查，可能是“偶尔”才需要，比如说一天或者是一周发生几次。但为了保证这个安全事件调查的可靠性、可用性，企业可能需要提前预留很多资源。其实现在通过我们弹性的能力，当你在需要进行情报回扫或者是事件调查的时候，我可以快速拉起你所需要的资源，帮你快速完成任务分析，完成之后释放这批资源，从这个层面会减少一些资源的损耗和成本的降低。更底层的我们在一些技术实现上，比如说像有无索引架构，在这种情况下大家已有的解决方案需要存储大量的索引，这些索引本身是一些额外的开销，大部分的索引之前有篇文章也分析过，像传统的索引80%在实际中是不会用到的，但是这些东西占用了大量的存储和内存，这个成本和代价都是非常高的。我们在现在的架构中也采用无索引的架构，来避免成本。</p><p>&nbsp;</p><p>所以，整体来看，一个是从面向云原生的弹性架构上，另外一个是在底层架构的实现上，对资源的损耗做了很大的优化和提升。</p><p>&nbsp;</p><p>InfoQ：现在国内一些安全厂家发了安全GPT，您觉得大模型会改变安全日志这个领域吗？或者您怎么看待这件事情？</p><p>&nbsp;</p><p>答：目前从市面上看到大家都在用GPT做上层应用，但这本身也是基于日志来做的。所以，基于日志本身的存储和分析上，大模型可能是没有太大的帮助，它节约的成本更多是安全专家运营的成本，传统的安全专家需要拉数据做分析，需要分析很久，现在通过GPT或者是通过基本的机器学习、API、自动编排的能力，把分析的链路缩短，从而提升效率。但GPT依赖于丰富的数据，需要存储更多的数据。</p><p>&nbsp;</p><p>另外我们也是在朝着这个方向做，但过程中有以下前提是一定要解决的：</p><p>1. 通用大模型能力的考验，包括类似于混元的能力。</p><p>2. 通用大模型构建行业大模型，就是安全大模型，需要有安全的数据，原始数据需要数据湖的能力支撑整个数据的处理和使用。</p><p>&nbsp;</p><p>我们一直觉得还是要把底座夯实得更好。现在整个人口红利、模式创新都已经到达瓶颈了，我们需要做些技术创新，所以腾讯推出了安全数据湖产品，这块儿是能够很好地帮助安全人员解决在应用GPT过程当中的难题。</p><p>&nbsp;</p><p>总之，我们更关心底层能力。首先说数据，在大模型上我们怎么把安全数据梳理好、整理好，能够提供高性能的分析。整个安全数据湖未来也会走商业化的能力，因为本身我们的架构是完全兼容的，我们在做这方面的探索。这样的话，就把数据进入到湖里之后，大模型去转化的时候，又往前推进了一步。然后就是整个大模型底层模型的能力，腾讯混元底层能力一直在打磨。还有一块就是GPT交互能力，包括对于自然语言的识别能力，包括对上下文的对话能力，在技术方面我们安全团队也一直在打磨和探索。</p><p>&nbsp;</p><p>在目前的地缘政治和国际形势的情况下，有些我们该练的内功还是要提前布局好，特别是对腾讯这种公司，确实还是需要尽到一定的职责解决卡脖子方面的像中间件以及其他软件的问题。</p><p>&nbsp;</p>",
    "publish_time": "2023-09-25 14:01:53",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AIGC如何改变金融业？不是所有智能化问题都要用大模型解决",
    "url": "https://www.infoq.cn/article/eZ8J5Z7SuUSM4ql4ioVW",
    "summary": "<p>和所有新技术诞生之初一样，随着 AIGC 持续引发关注，各行各业都在寻找自身与 AIGC 结合的可能性。金融行业也不例外，丰富的场景、海量的数据、相对完善的技术实力...... 这些都是 AIGC 技术应用落地的温润土壤。</p><p></p><p>同样和所有新技术的发展一样，从技术出现到技术落地，需要跨越一定的周期，在这期间，市场会由感性的狂热慢慢转入理性的思考。AIGC 究竟适合在哪些场景应用？成本投入和效益产出如何做好平衡？商业落地的瓶颈又如何突破？</p><p></p><p>在 InfoQ《超级连麦. 数智大脑》直播中，太保寿险首席架构师周建华、富滇银行数字金融中心副主任李涛、华盛证券技术 VP 黄曙光围绕这些问题进行了探讨。大家认为，讨论 AIGC 技术应用，必须回归到业务目标和价值本身，并不是所有智能化问题都需要用到 AIGC 和大模型，很多时候，利用现有的智能化技术就能解决。</p><p></p><p>以下是分享全文（经 InfoQ 进行不改变原意的编辑整理）（<a href=\"https://www.infoq.cn/video/k0QUqSaEI4Hxbb4V94hZ\">点击链接</a>\"可查看完整直播回放）：</p><p></p><h5>InfoQ：AIGC 热度高涨，大家如何看待这一技术？它在金融行业的哪些业务场景会有落地可能性？</h5><p></p><p></p><p>周建华：AIGC 在落地应用方面，有很多可能性。从我的角度来看，要讨论 AIGC 的能力，需要回到技术本身，以及技术带来的变革。</p><p></p><p>具体看 AIGC，它有三个基础能力和三个发展方向：第一，大模型是它的基础，拥有广泛的知识；第二，具备超强理解力；第三，能够自我迭代，根据新的输入不断训练自身模型，无论是在金融还是其他领域，这些基础能力都可以扩展出不同的应用方向。</p><p></p><p>在应用层，我认为这三个能力可以分别体现在创造性、专业性和标准化方面。就创造性而言，AIGC 可以在营销文案编写、数据分析等领域发挥作用，甚至可以帮助开发人员实现自动化代码编写。</p><p></p><p>专业性方面，AIGC 可以在运营场景中，对业务规则进行自动化处理，减少安全漏洞的风险。此外，金融领域的技能培训也可以通过 AIGC 来提高，特别是在安全方面，AIGC 可以帮助提升整个团队的技能。</p><p></p><p>此外，AIGC 的交互能力也非常强大的。它可以作为个人助手、虚拟理财顾问，甚至可以处理客服、条款等复杂的问题。通过 AIGC，许多运营、客户服务、财富规划等工作可以实现自动化，进而提高效率。</p><p></p><p>黄曙光：我们已经在几个场景中进行了 AIGC 的应用实践。首先，由于证券行业的专业性与其他金融领域有所不同，用户在这里做投资决策时使用自己的资金，要求他们具备更丰富的金融知识，如财务报表理解等等。所以，我们将 AIGC 技术应用分为两类，一类是面向公司内部的应用，另一类是面向客户的应用。</p><p></p><p>在公司内部，我们利用 AIGC 技术提升工作效率。举例来说，内容部门需要进行诸如股票早评、午评和晚评等信息运营，通过采用 AIGC 技术，就可以大大加快内容生成速度，减少人力投入。</p><p></p><p>第二个场景针对的是技术支持和内部后勤岗位，我们需要让不同国家的员工能够理解我们的系统和文档，以更好地为客户提供服务。在这里，就可以利用 AIGC 构建辅助功能，帮助员工提升专业技能，特别是在不同语言环境下的技能培训。此外，我们还在尝试将 AIGC 应用于研发团队，以提高整体效率，特别是在一些单一逻辑或场景中，如单元测试。</p><p></p><p>从客户角度来看，我们希望通过 AIGC 降低用户交易的门槛，帮助用户更好地理解金融产品，辅导他们做出更好的投资决策。我们正在考虑引入“数字人”的概念，帮助客户解读财务报表中涉及的大量专业术语和知识积累。</p><p></p><h5>InfoQ：在 AIGC 落地过程中，如何在模型训练开销与效益、效能间实现平衡？</h5><p></p><p></p><p>周建华：首先提一下，关于 AIGC 和大模型的概念，我们需要将分开来讨论。AIGC 的概念在大模型出现之前就已经存在，这是需要澄清的第一点。另一方面，并不是所有智能化问题都需要借助 AIGC 和大模型来解决。很多问题实际上利用现有的智能化技术就能解决。</p><p></p><p>那么，如何平衡模型训练的开销、效益和效能，这是一个庞大的议题。首先，金融行业的大模型应用基于私有化的训练，这涉及到微调等步骤，必须在私有化环境中进行。所以，涉及两个方面的问题：第一，确保公司能够有足够持续的资源投入，包括 GPU 设备、大模型人才招募等；第二，确保有足够的数据或者能够生产足够高质量的数据进行微调。</p><p></p><p>其中，私有化模型的微调，在目前阶段不建议大规模投入，因为工程量巨大，微调不是只需要数据和 GPU，微调之后的大模型如何产生对齐的效果，如何能够符合监管合规要求都是非常大的难题。在解决效益问题方面，重要的是回到问题的原点，解决的是什么业务问题，为什么需要大模型才能解决？找到切实可行的应用点之后，然后再进行尝试性的试验。</p><p></p><p>在过去的智能化应用中，很多公司都因为未能找到业务流程上的痛点，导致创新停滞。解决这个问题并不容易，需要克服诸多门槛。所以，技术应用必须回到目标和业务价值，生产力的提升如何带来生产关系的改变。从目前来看，解决这个问题并没有简单的方法。</p><p></p><p>李涛：这个问题其实在我们准备进行 AIGC 应用以及制定 POC 时也充分进行了考虑。先谈谈关于开销和效益的问题。我们所在的金融领域正处于迅速发展的阶段，尽管在真正形成完整的应用生态方面还有很长的路要走。然而，从我们数字化转型的角度来看，实践已经逐步证明了其价值。</p><p></p><p>AIGC 引入确实为数字化转型增添了许多不确定性。我们感受到这种不确定性，是因为在过去的两年里，我们一直在发展前台、中台、后台一体化，但并未涵盖整个私有云的部署。这包括购买服务器、A100 和 V100 等显卡设备。或许在接下来的一年半里，许多银行会通过大型模型的技术超越我们。</p><p></p><p>从银行的角度来看，的确存在许多监管法规等问题，尤其是关于用户隐私。银行的技术变革往往从内部开始。因此，当我们与阿里、腾讯、华为等公司讨论 POC 时，大家对于开销的问题也并不清楚。与 OpenAI 不同，私有模型的训练不能像按照 token 收费。在国内的大型模型中，必须首先基于金融领域训练一个行业模型，然后再挂接到知识库并进行进一步的训练。这涉及到一定的成本，而且主要问题是，如何明确提示工程师的工作内容，目前并没有清晰的指导。尽管许多人认为这是一个简单的问题，但在实际技术研发中，提示工程师应该做什么还没有明确的方向。</p><p></p><p>因此，从内部研发、效能提升的角度来看，我们目前会优先使用公有云的能力。我们正在尝试将贷款制度、风控要求等挂接到库中，并进行问题检查和答案。我们的想法是，首先通过辅助人工的方式，然后逐步过渡到人工智能。与目前的规则性职能开销类似，这一过程的成本很难评估，但我们已经建立了强大的算力体系，也有了基本的硬件设施。</p><p></p><p>在富滇银行的战略中，首要任务是解释清楚。对于像我们这样的小型银行来说，人力资源非常有限，因此我们迫切需要利用远程数字银行等能力来提升服务水平，通过机器人理解客户意图。AIGC 的出现为我们指明了一个方向，并且我们也正在尝试着去实现这些目标。</p><p></p><p>在实现效益方面，很难有即时的收益。俗话说“飞猪能上天”，但对于金融领域的大型模型，我们仍然不太清楚整只猪是什么样的。这个探索的过程可能会有些疯狂，但实践将告诉我们真相，也许它会成为让我们弯道超车的一个机会。</p><p></p><h5>InfoQ：技术发展与商业应用是两回事，AIGC 要在金融业实现应用落地，目前还存在哪些瓶颈？如何突破？</h5><p></p><p></p><p>黄曙光：首先，政策是关键因素，因为金融行业在政策监管方面相当严格，对于新事物的尝试必然会面临不确定性。政策对于商业化落地的态度是重要的，需要不断摸索。像之前提到的，很多同行可能不得不面临私有化的问题。</p><p></p><p>其次是效果，效果决定了商业化的程度。商业化与演示之间的差异非常明显，如果在演示中成功率达到 90%，但在实际使用中失败了，这显然不行。业务部门面临巨大的业务风险，所以应用的成熟度对商业化落地有影响。</p><p></p><p>再者是成本。财务部门通常会关注投资回报率（ROI），短期内要达到一定规模才能解决一些问题，所以公司的财务决策会影响商业化的判断。</p><p></p><p>最后，人才方面的储备也是一个关键因素。</p><p></p><p>总之，AI 落地存在许多因素，这些因素相互影响，对于不同的企业来说，权衡这些因素会影响其商业化的决策。</p><p></p><h5>InfoQ：智能技术的应用可以降低对人的要求，但是新技术的出现，也会衍生出新的人才技能需求。对于金融机构来说，要更好地使用 AIGC 技术，需要哪些类型的人才？如何提前布局和培养这些人才？</h5><p></p><p></p><p>周建华：我个人认为，首先，算法方面的人才是必不可少的。但在基础设施建设方面，特别是数字化基础设施，例如大型模型的基建方面，金融行业自己可能并不需要过多涉足，因为门槛相当高。这不仅仅是硬件的问题，还涉及到复杂的工程化和各种问题。我认为这个领域可能只有大公司才有可能完成。</p><p></p><p>此外，还有两类人才是至关重要的：一类是智能化战略规划人才，他们能够通过对其他领域的成功案例中的借鉴，对企业自身的战略规划做出部署；另一类是智能化应用人才，他们不需要成为顶尖的算法专家，需要的是智能化应用实战能力。</p><p></p><p>最后，我认为业务方面也需要提升对 AIGC 或大型模型能力的培训，形成对数字化生产力的统一认识。从来没有一个数字化项目是仅靠技术就能成功的，这需要公司级别的战略转型，而技术只是工具之一。</p><p></p><p>李涛：目前确实很难给出一个明确的答案，即银行在 IT 领域需要什么样的人才。我之前提到了一些当前比较火的趋势，如大规模工程师等，但实际上具体的需求还不清楚。因此，我们需要通过实践来探索，只有在实践中才能了解我们需要什么样的人才。</p><p></p><p>大模型的发展现在有点类似于当初大数据发展的情况。随着时间的推移，大模型正在逐渐降低应用门槛。就像刚才提到的，我们并不一定需要高级的大模型建模人员，而可以基于现有行业模型进行产品模型的开发。然而，这需要通过探索来确定，也就是在实践过程中了解我们确切需要哪些人才。</p><p></p><p>正如刚才周老师所说，数字化转型的核心是业务价值，而当我们进入到模型阶段时，核心就变成了用户价值。然而，业务价值和用户价值之间有何区别，这是一个问题，需要深入探讨。</p><p></p><p>事实上，我最近也一直在思考业务价值驱动和用户价值驱动的问题。尽管我们一厢情愿地触及用户，但实际上我们并不清楚用户真正的需求。我目前更关心的是，如何在接触用户的过程中，真正了解他们的想法和需求。</p><p></p><p>当前银行业务相当复杂，同质性很高，因此实现数字化转型需要突破壁垒，纯粹的技术“自嗨”是行不通的，必须有业务价值的支撑。在专业人才方面，首先，我们需要明确的业务价值，然后需要既懂业务又懂技术的人才来实现。然而，这样的人才在各个机构中都很紧缺。</p><p></p><h5>InfoQ：在未来三到五年的短中期内，对 AIGC 技术在银行 / 保险 / 证券的应用和发展趋势有哪些看法和预测？</h5><p></p><p></p><p>黄曙光：我认为在未来的 3-5 年里，我们将迎来大规模应用的时期，我对在各个领域看到 AI 技术的应用充满信心，可能会出现一些杀手级应用，或者是具有重大影响力的应用，它们将逐渐浮出水面。</p><p></p><p>李涛：我总结两句话：第一，大模型将成为新一代决策支持系统，完整连接理解、思考和行动的链路；第二，我对明年银行的 APP 充满期待，相信它将经历改变，不再保持现有的静态外观，而是朝向一个数字人坐镇其中的状态转变，我希望我们银行能尽快推出这样的产品。</p><p></p><p>周建华：在未来的发展中，有几个方面可以比较确定：</p><p></p><p>第一，在营销素材领域，大规模应用会显而易见。金融行业都拥有庞大的线下团队，他们的诉求是需要高质量的营销素材来进行的客户拓展和持续经营。</p><p></p><p>第二，智能客服方面也会发生巨大的变革。传统的知识库和知识图谱运维成本相对较高，而利用大模型进行智能客服可以降低成本，提高用户满意度。此外，未来智能客服可以借助大模型直接回答问题，类似之前的 ChatGPT 等应用。</p><p></p><p>第三，私人助理领域也将迎来大规模的应用。这意味着各种角色将有机会通过 copilot 的方式获得个人助理服务。这三个领域的发展比较确定，其他方面可能还需要观望。</p><p></p><p>这三个领域的共同特点之一是涉及的数据并不是特别私密，不需要核心数据，这为尝试提供了机会，也不一定需要私有化部署。其次，需求非常明确，因此开发过程相对比较容易。</p><p></p><p>除此之外，还有其他领域可以考虑，比如从开发和技术的角度，一个方面是协助编写代码，金融行业存在大量外包，代码质量不一定很高。另一个方面是解决安全性问题，代码漏洞是一个头疼的问题，可以通过大模型来解决水平越权和垂直越权的问题，这也是我认为能够直接看到价值的两个方面。</p><p></p><h4>活动推荐</h4><p></p><p>首届<a href=\"https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">FCon全球金融科技大会</a>\"将于 11 月 19-20 日在上海举办。大会将围绕金融领域数字化转型挑战探索、DevOps 在金融企业落地实践、金融行业大模型应用、创新的金融科技应用、金融实时数据平台建设之路、金融安全风险管控、数据要素流通与数据合规等 10+专题进行交流。</p><p></p><p>目前大会邀请了汇丰科技中国区的代理总经理马国栋、度小满金融数据智能部总经理杨青先、蚂蚁集团副总裁 &amp; 首席技术安全官韦韬博士、恒生聚源总经理吴震操担任大会联席主席。更多嘉宾仍在邀请中......</p><p></p><p>我们诚挚地邀请您加入我们，共同探索金融科技的未来，<a href=\"https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">点击链接</a>\"即可查看全部演讲专题。</p><p></p><p>目前 <a href=\"https://fcon.infoq.cn/2023/shanghai/apply?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">5 折 优惠购票</a>\"，仅限前 100 人，咨询购票可联系：17310043226（微信同手机号）。</p>",
    "publish_time": "2023-09-25 14:25:40",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "中国银联技术开发中心安全攻防团队总监蔡水捷确认出席 FCon ，分享从安全左移到安全内生——中国银联安全研发体系建设实践",
    "url": "https://www.infoq.cn/article/XTVfdNbKaRD2L7Oj7czg",
    "summary": "<p><a href=\"https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle\">FCon 全球金融科技大会</a>\"，将于 11 月在上海召开。中国银联技术开发中心安全攻防团队总监蔡水捷将发表题为《<a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5554?utm_source=infoqweb&amp;utm_medium=article\">从安全左移到安全内生——中国银联安全研发体系建设实践</a>\"》主题分享，介绍应用安全防护机制的历史演进，强调企业组织在安全成熟度达到一定阶段后，应考虑应用系统安全防护的本源回归，以软件研发全生命周期为基础，形成应用系统自我安全属性，实现有机联动和乘数效应，以真正有效保障软件产品安全。</p><p></p><p><a href=\"https://fcon.infoq.cn/2023/shanghai/presentation/5554?utm_source=infoqweb&amp;utm_medium=article\">蔡水捷</a>\"，拥有多年金融行业应用安全领域的专业技术及团队管理经验，带领团队致力于应用安全保障、应用安全体系建设、攻防技术研究、安全创新赋能、安全数字化转型等工作。他在本次会议的演讲内容如下：</p><p></p><p>演讲：从安全左移到安全内生——中国银联安全研发体系建设实践</p><p></p><p>随着数字化高速发展，也让网络安全威胁加速向各领域渗透。应用系统作为数据信息重要载体，也是攻防双方激烈对抗的重要战场之一，大部分的网络攻击事件都是通过利用应用系统的漏洞造成，某种程度上可以说软件开发者已然身处网络安全斗争的前线。以安全检测为主的安全左移，本质仍侧重于单点的安全防护，左移后，右侧还要不要？左移的尽头又是什么？而如何有效保障应用系统安全，让应用系统自我产生抵御攻击的内生能力，是值得我们思考研究的一个课题。</p><p></p><p>本次演讲，从上线前单点检测、安全左移、到现在讨论的安全内生，其实是应用安全防护机制的一个历史演进过程。当一个企业组织的安全成熟度达到一定阶段后，应要考虑应用系统安全防护的本源回归，以需求、设计、编码、测试、构建、发布、运营等软件研发全生命周期为基础，形成应用系统自我安全属性，且互相之间能有机联动，产生乘数效应，才能真正有效的保障软件产品安全，即安全内生。</p><p></p><p>演讲提纲：</p><p></p><p>发展历程</p><p>○ 从单点安全，到安全左移，再到安全内生的演进</p><p>左移与内生</p><p>○ 左移与内生的区别，何为内生</p><p>建设实践</p><p>○ 银联安全研发体系总览 </p><p>○ 如何挖掘安全内生属性 </p><p>○ 研发各阶段痛点与应对 </p><p>○ 安全内生，不止于形 </p><p>○ 没有度量，就没有管理</p><p>挑战与展望</p><p>○ 当前遇到的困难，如何应对 </p><p>○ 下一步的探索方向</p><p></p><p>你将获得：</p><p></p><p>○ 了解安全内生的理念</p><p>○ 了解银联在安全内生方面的建设实践，给听众带来借鉴思考</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle\">DevOps&nbsp;在金融企业落地实践</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle\">金融行业大模型应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle\">创新的金融科技应用</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle\">金融实时数据平台建设之路</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle\">金融安全风险管控</a>\"、<a href=\"https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle\">数据要素流通与数据合规</a>\"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，前 100 人可享 5 折特惠购票，咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png\" /></p><p></p>",
    "publish_time": "2023-09-25 14:31:06",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "吉利发布汽车座舱云原生技术；蔚来 12 项技术全栈布局；哪吒汽车与国创中心达成战略合作｜汽车科技资讯",
    "url": "https://www.infoq.cn/article/8iBQVtVFkjAJm7JaS1G7",
    "summary": "<p></p><h2>沃尔沃与 Connected Energy 共同开发电池储能系统，回收旧电池</h2><p></p><p></p><p>沃尔沃能源公司与电池回收商 Connected Energy 签署了一份意向书，共同开发电池储能系统（BESS）。双方计划利用从沃尔沃电动巴士、卡车和机器中回收的电池来构建 BESS，为电池创造第二次生命。</p><p>据悉，储能系统将被构建成“集装箱式系统”，沃尔沃预计到 2025 年在欧洲推出该系统。同时，沃尔沃开始在瑞典哥德堡工厂使用 Connected Energy 的 E-STOR 系统，该系统用于分析对电网的响应率。</p><p></p><h2>哪吒汽车与国创中心达成战略合作</h2><p></p><p></p><p>日前，哪吒汽车与国家新能源汽车技术创新中心（简称：国创中心）签署战略合作协议，双方合作共建的整车联合试验室、车规级芯片测试认证联合试验室、数字化场景试验室正式揭牌。根据协议，国创中心将在整车效能、芯片测试、电驱动、电子电气等关键核心技术领域，为哪吒汽车提供相应测试与能效提升服务。</p><p></p><h2>索尼发布 IMX735 CMOS 图像传感器：1742 万像素，助力智车行业发展</h2><p></p><p></p><p>索尼近日发布了一款面向车载行业的 CMOS 传感器“IMX735”，该传感器拥有 1742 万像素，适用于智能驾驶领域。当下利用视觉感知的自动驾驶功能对 CMOS 传感器有一定要求，必须有较高的像素，从而能够与激光雷达等传感系统结合，而这款传感器像素更高，因此照片中也具有更多细节，便于算法进行识别。</p><p></p><p>索尼声称，IMX735 为自家自研的像素结构、采用“特别的曝光方式”，从而提升饱和度与光照范围，“即使同时使用 HDR、LED 闪烁抑制，动态范围可达 106dB，而在动态范围优先模式下，可达 130dB。”</p><p></p><h2>蔚来 12 项技术全栈布局，智能电动车迈进新阶段</h2><p></p><p></p><p>9 月 21 日，蔚来汽车在上海举办了一场 NIO IN 科技创新日活动，由蔚来创始人李斌为我们介绍了蔚来在 12 个领域所进行的研发进展和成果，先后发布了业内首颗自研量产激光雷达主控芯片「杨戬」、首个有车企自研并发布的智能电动汽车整车全域操作系统「天枢 SkyOS」、以车为中心的全景互联技术「NIO Link」、更加安全高效的「全域增强领航辅助功能」、基于开放生态接入能力的「蔚来智能座舱应用商店」，以及最重磅的蔚来首款自研智能手机——「NIO Phone」。</p><p></p><p>NIO Phone 基于 NIO Link 蔚来全景互联技术，让手机和智能电动汽车融合，可以说是一把“超级汽车钥匙”。同时，NIO Phone 打通了车和手机之间的软硬件隔阂，共享设备算力，实现了手机和智能座舱之间的“无缝连接”。</p><p></p><h2>吉利发布汽车座舱云原生技术</h2><p></p><p>在近日举行的世界智能网联汽车大会上，吉利汽车发布数字孪生座舱系统云化应用技术，官方称这是行业内首个面向智能汽车座舱体验的专属云应用架构。</p><p></p><p>据介绍，“吉利云原生技术”将实现车端、云端算力协同，基于云计算和 4G / 5G 通讯技术进行实施推流，能够突破汽车座舱本地算力瓶颈。该技术可将核心算力转移至云端服务器，车内仅需负责终端显示和操控，从而减轻座舱体验对空间硬件的要求。“吉利云原生技术”目前已实现应用部署云端化，号称像 3A 级游戏大作、流媒体视频等对实时算力有极高要求的内容生态也能在车上即点即用。</p>",
    "publish_time": "2023-09-25 14:33:17",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "漏洞产生快于识别修复，数字化企业需要什么样的新“安全范式”",
    "url": "https://www.infoq.cn/article/sCFWacrvvYWq1ltpfJkW",
    "summary": "<p>网络安全，是数字化企业面临的一场硬仗。</p><p></p><p>日前，在 2023 外滩大会上，蚂蚁集团与浙江大学网络空间安全学院重磅首发了一项引领性网络安全成果“原生安全范式框架 v1.0”。这是探寻网络安全本源的技术思想和方法体系的集成，主要包括“OVTP 可溯范式”和“NbSP 零越范式”两大安全范式，一大技术创新“安全平行切面”。</p><p></p><p>蚂蚁集团副总裁、首席技术安全官韦韬（已确认担任<a href=\"https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=article\"> FCon 全球金融科技大会</a>\"联席主席）表示，现代化数字企业已经成为不断演变和进化的数字生命体，其架构复杂性会爆炸式增长，正在加据企业内部数字化风险。“我们希望通过原生安全范式框架，为企业安全架构设计提供指引，让原生安全从宏观要求，走向可落地实践。”</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/39/43/39570e8be17091131f1e370d77d02243.png\" /></p><p></p><p></p><h2>为什么要有“安全范式”？</h2><p></p><p></p><p>“范式这两年被提得蛮多的，很多其实被‘滥用’了”。当提到原生安全范式时，韦韬在一场沟通会上强调了对范式的认知的重要性。</p><p></p><p>他使用了星空和天文学的比喻，比如古代天文学家以地球为中心去看九大行星的运动轨迹的时候，这事非常复杂，而当他们意识到以太阳为中心来计算行星轨迹时，问题就变得及其简单。再进一步，牛顿的万有引力理论，为登上月球和进行太空活动提供支持。“我们对范式的描述是对问题本源的认知和领域实践的指导。”</p><p></p><p>回到网络安全，为什么需要建立更好的原生安全范式？</p><p></p><p>韦韬谈到了网络安全行业面临的一些挑战和难题。比如网络安全领域，真正令人困扰的问题不在于一些复杂漏洞，而是在于生态系统中存在大量的漏洞，这些漏洞看起来都很简单，但无论修复多少漏洞，都会有新的漏洞源源不断产生。而这部分问题的一个重要原因是研发人员对如何做好安全保障的认知模糊不清，再加上很多行业安全工程师配比往往严重不足，导致漏洞产生的速度远远快于漏洞的被识别和修复速度。</p><p></p><p>一个典型的“生态级”漏洞是“水平越权漏洞”。韦韬举例说，假设用户要访问自己的个人服务，比如抖音账号或外卖订单。通常情况下，用户只对自己的相关信息感兴趣。然而，如果访问服务没有做好适当的安全措施，可能会导致问题：“有很多时候，用户访问的时候会带上 ID 信息。但是访问服务做返回的时候没有检查 ID，黑产有机会随便改 ID，又没有合适的安全检查，那么就会有很糟糕的事情发生，黑产就有可能把整个用户信息库全部偷出来。”</p><p></p><p>这种情况下，最基本的安全是要对访问请求进行检查，确保用户只访问自己的数据，确保访问是合法的。但由于缺乏明确的权限管理和范式，这种问题屡见不鲜。</p><p></p><p>诸如此类的现象促使韦韬等人坚定地追求清晰的范式，一种能够引导开发人员更加清晰地理解和预防安全问题的模式。</p><p></p><p>“如果我们能在设计、在架构阶段把这些想清楚、实现好，就是所谓的原生安全。”韦韬强调，原生安全并不是简单地把安全内置，而是安全应该从一开始就被纳入到系统的设计和早期开发过程中，被集成到系统中，而不是作为外挂产品存在。</p><p></p><p></p><h2>两大范式相辅相成</h2><p></p><p></p><p>据介绍，蚂蚁集团从 2019 年开始便探索了原生安全范式，并通过迭代升级，实践验证不断完善，凝聚成 “原生安全范式框架 v1.0”。主要包括两大安全范式、一大技术创新。两大安全范式包括“OVTP 可溯范式”（Operator-Voucher-Traceable Paradigm，即 OVTP) 和“NbSP 零越范式”（Non-bypassable Security Paradigm，即 NbSP)。</p><p></p><p>网络安全保障，本源之一是访问是否合法的问题。OVTP 可溯范式指出，要完整准确地研判一个网络访问是否合法，应该基于该访问的操作者（Operator）的访问链路信息与凭证 (Voucher) 的传递链路信息。可以让我们站在一个数字化企业或机构的全局视角，来思考研判访问是否安全合法究竟应该获取和研判哪些因素。尤其是，需要知道该操作的实际操作人究竟是谁，以及该链路上的应用和环境是否符合安全要求，以避免访问被篡改或者泄露。</p><p></p><p>根据韦韬的阐述，OATP 可溯范式的提出旨在填补针对之前存在的一些安全盲区。</p><p></p><p>第一个是凭证的重要性被忽略。在传统的安全认证中，通常关注的是用户的身份凭据和权限管理。然而，这种方法通常忽略了操作所需的凭证，例如，财务进行一些交易操作需要相关的合同和发票，而客服需要有效的用户工单才能查看相关信息。</p><p></p><p>凭证在操作的合法性和合规性方面起着至关重要的作用。问题在于，之前的安全模型未能明确强调凭证的作用，导致了许多潜在的安全漏洞。</p><p></p><p>第二是链路的复杂性。随着<a href=\"https://www.infoq.cn/article/33fHgos8E50WwGOx9Xmf\">云计算</a>\"和分布式系统的广泛采用，许多任务涉及复杂的操作链路。与传统的单一认证环境不同，现在的任务可能需要在多个环节和设备之间进行多次跳转。可追溯性丧失掉，就意味着在一些情况下，不清楚是谁发起了操作。</p><p></p><p>比如今天在云上最严重的问题之一——AccessKey 泄露。云服务通常要求开发者使用 AccessKey 来验证其对服务的访问权限。然而这些密钥可能被写进到程序代码中或存储在配置文件中，这增加了潜在的泄露风险。更重要的是，一旦泄露，很难追溯是哪个应用、个人、商户或攻击者使用了这个 AccessKey。就在最近，微软被曝出意外泄露 38TB 内部数据。据云安全公司 Wiz 报告，微软人工智能研究小组下的一个名为 robust-models-transfer 的仓库，包含可用于构建新神经网络的图像识别模型和训练数据集。此次泄露是由其中一个训练数据文件引起的，该文件托管在 Azure 存储帐户中。微软方面原本打算仅公开共享 AI 训练数据集，但意外地开放了对包含该数据集的整个 Azure 存储帐户的访问权限 。这就是 AccessKey 泄露导致的严重事件。</p><p></p><p>韦韬进一步表示，OVTP 可溯范式更关注的是策略层，即身份验证、权限和凭证，以确保只有授权人员在合法的上下文下才能执行敏感操作。然而，OVTP 范式要发挥作用还依赖于系统中的安全检查点来实施策略。但如果这些安全检查点被绕过，OVTP 的策略也就无效了。</p><p></p><p>这时候就需要 NbSP 零越范式来互补。实际上 NbSP 零越范式是韦韬早在 2018 年就提出的范式，与 OVTP 不同，NbSP 范式关注的是机制层面的保障。它要求确保关键安全检查点不可被绕过。这看起来是一个安全的基本要求，但是在当今复杂系统里，这点往往无法得到有效保证。其目标是确保系统中的安全性机制是强制执行的，无论用户或攻击者如何尝试绕过它们。</p><p></p><p>简单来看，OVTP 就是确保网络访问敏感操作可追溯可研判；而 NbSP 就是类似机场安检，攻击者不会通过各种漏洞形成的隐蔽通道（比如下水道或者通风管）绕过安检点。</p><p></p><p>韦韬在接受 InfoQ 采访时强调，这两种范式在技术和攻防体系上都有不同，混合在一起设计和实现往往可能导致混淆和缺乏重点，而攻防策略也会有所不同，需要不同方向的专家来实施。比如 NbSP 侧重于系统级防御，由专门的网络系统层专家负责保障，而 OVTP 范式则与业务和应用相关，更多地由相关研发专家负责。因此，将两者分开更有助于实现更综合的安全保障。</p><p></p><p></p><h2>让业务和安全平行发展</h2><p></p><p></p><p>两大范式是“道”，那么如何通过方法体系来落实？</p><p></p><p>从现实来看，安全范式的实施成本在传统体系中可能比较高。在过去，安全方面的考虑通常没有得到足够的重视，因此需要对系统进行昂贵的改造。尤其是在国内数字化发展较晚、没有太多技术包袱的情况下，许多大型系统也积累了大量的安全隐患。国外的情况更为严峻，因为一些大型金融机构的系统还运行着古老的编程语言，而且随着了解这些语言的专家逐渐退休，维护这些系统变得更加困难。</p><p></p><p>对此，蚂蚁集团给出的解法是“<a href=\"https://www.zte.com.cn/content/dam/zte-site/res-www-zte-com-cn/mediares/magazine/publication/com_cn/article/202206/11.pdf\">安全平行切面</a>\"”，这是蚂蚁集团最初于 2019 年提出的理念和技术体系，也是其面向数字化企业推出的新一代安全基础平台。其核心思路是将切面安全基础平台通过插装或者 AOP 机制融入业务应用系统，并且将切面安全应用逻辑与业务应用逻辑解耦，从而实现安全与业务的快速平行迭代。</p><p></p><p>这种平行迭代能力在数字化时代非常关键。</p><p></p><p>企业中业务应用系统的迭代具有自己的周期节奏，而安全策略保障却往往有不一样的时间要求。如果企业强行将这两者紧密耦合在一起，将会导致“绑脚走路”的情况。比如安全策略的要求可能与业务应用系统的节奏不匹配，这可能导致在实现安全保障时牺牲了业务的灵活性和效率，或者在迭代业务应用系统时忽略了安全问题。</p><p></p><p>这时，安全平行切面在业务与安全之间既融合又解耦的能力，能够把包括原生安全范式在内的安全迭代更好地跟业务应用系统结合起来，从而更高效地推动安全保障能力的升级实现。</p><p></p><p>以蚂蚁自身为例，2021 年双十二大促期间，针对 log4j2 漏洞攻击，蚂蚁集团通过安全平行切面的方式实现小时级全站止血，应急人力从 fastjson 应急时的 6000 人日降低到 30 人日，效能提升百倍，在确保安全能力不降级的情况下，业务 0 打扰平稳度过危机。</p><p></p><p>今年 7 月，包括蚂蚁集团在内的数家企业发起“安全平行切面联盟”（AOTA），旨在推广平行切面技术到整个行业，共同开源代码、共建标准，以促进整个行业的发展。</p><p></p><p></p><h2>结语</h2><p></p><p>现代数字化企业已成为技术创新的重要力量。数字化业务属性，要求他们在处理复杂业务同时兼顾安全与效率。以蚂蚁为典型的<a href=\"https://www.infoq.cn/article/mL5RPaXideg2BOU2HtRO\">数字化企业</a>\"，在实践中摸索出的技术思想和方法，不失为一条可复制的网络安全治理技术路径：从原生安全范式探索安全本源之“道”，安全平行切面是范式指导下的“法”，安全平行切面系统上的应用是“术”，三者结合，驱动网络安全治理迈入新阶段。</p><p></p><p>正如韦韬在采访中所言，网络安全问题已经成为了蔓延全球的“灾害”，要从根源上防范灾害，就要思考灾害产生的本质。“我们希望能将原生安全范式推广到全球，为这个时代的网络安全治理贡献一份中国科技力量。”</p><p></p><p></p><h4>活动推荐</h4><p></p><p>首届<a href=\"https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">FCon全球金融科技大会</a>\"将于 11 月 19-20 日在上海举办。大会将围绕金融领域数字化转型挑战探索、DevOps 在金融企业落地实践、金融行业大模型应用、创新的金融科技应用、金融实时数据平台建设之路、金融安全风险管控、数据要素流通与数据合规等 10+专题进行交流。</p><p></p><p>目前大会邀请了汇丰科技中国区的代理总经理马国栋、度小满金融数据智能部总经理杨青先、蚂蚁集团副总裁 &amp; 首席技术安全官韦韬博士、恒生聚源总经理吴震操担任大会联席主席。更多嘉宾仍在邀请中......</p><p></p><p>我们诚挚地邀请您加入我们，共同探索金融科技的未来，<a href=\"https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">点击链接</a>\"即可查看全部演讲专题。</p><p></p><p>目前 <a href=\"https://fcon.infoq.cn/2023/shanghai/apply?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5\">5 折 优惠购票</a>\"，仅限前 100 人，咨询购票可联系：13269078023（微信同手机号）。</p><p></p>",
    "publish_time": "2023-09-25 14:33:42",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "深入解析Netflix后端架构与云服务的系统设计",
    "url": "https://www.infoq.cn/article/7ozSkjX1sp49J8YBuMeN",
    "summary": "<p></p><h2>统计数据</h2><p></p><p>&nbsp;</p><p>在深入介绍Netflix的架构之前，我们首先看一些重要的统计数据，它们是系统设计的基础：</p><p>Netflix应用程序每天有大约4000亿个事件；在高峰期，每秒要处理大约800万个事件和17GB数据；有超过2亿名订阅用户；订阅用户分布在全球200多个国家；支持2000+设备；每位用户平均每天观看5个视频；视频平均大小为500 MB；平均每天从后台上传1000个视频；每天上传所需的存储空间为：1000 * 500 MB = 500 GB（大概）5年内所需的总存储空间为：500 GB * 5 * 365 = 912.5 TB</p><p>&nbsp;</p><p></p><h2>在Netflix上线一个视频</h2><p></p><p>&nbsp;</p><p>Netflix从制作公司获得高质量的视频和内容。然而，Netflix支持2000多种设备，每种设备都需要不同的分辨率和格式。</p><p>&nbsp;</p><p>对于同一部电影，Netflix要准备多种不同的视频，而且还要为每一种视频准备多个拥有不同分辨率的副本，然后根据用户的网速和设备确定向他们提供何种视频质量的视频。为了实现这一目标，Netflix将原始视频切分成不同的小块，并使用AWS提供的并行工作者进程将它们转换成不同的格式（如mp4、3gp等）和不同的分辨率（如4k、1080p等）。这个过程称为转码。</p><p>&nbsp;</p><p>经过转码之后，同一部电影就有了多个文件副本。它们会被传输到世界各地不同地方的每一台Open Connect服务器上。</p><p>&nbsp;</p><p></p><h4>云服务</h4><p></p><p></p><p>Open Connect —— Open Connect或Netflix CDN是一个分布在不同地理位置的分布式服务器网络。同一电影文件的不同副本会被传输到每个Open Connect服务器上。Open Connect主要负责Netflix的视频流。当你点击播放按钮，Netflix会从距离你最近的Open Connect服务器把视频提供给你，从而提供更快、更好的体验。此外，这还增加了整个系统的可扩展性。这些服务器被称为Open Connect Appliances（OCA）。</p><p>&nbsp;</p><p>注意：上面的912.5 TB并不包括存储这些副本的存储空间。</p><p>&nbsp;</p><p>AWS ——&nbsp;除了视频流，Netflix几乎所有业务都使用AWS。这包括在线存储、推荐引擎、视频转码、数据库和分析。</p><p>&nbsp;</p><p>当用户点击播放按钮时，Netflix会分析网速或连接稳定性，然后找出离用户最近、最合适的Open Connect服务器。Netflix会根据设备和屏幕的大小将正确的视频格式以流的方式传输到用户的设备中。</p><p>&nbsp;</p><p></p><h2>Netflix的后端架构</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cf/cf023d4a51a5caace1129903bc86939d.png\" /></p><p></p><p>除了视频流之外，Netflix的所有业务都由其后端服务处理，包括上线新内容、处理视频、将视频分发到位于世界各地的服务器，以及管理网络流量。来自客户的请求被发送到AWS Elastic负载均衡器，后者是一个2层架构：</p><p>     1.第1层：来自ELB的请求会首先到达这一层。该层负责基于DNS的轮询调度在不同的区域之间平衡负载。</p><p>     2.第2层：该层包含一组负载均衡实例。这些实例在同一区域内的多个实例之间通过轮循方式实现负载均衡。</p><p>ELB将此请求转发到API网关。Netflix使用运行在AWS EC2实例上的ZUUL作为API网关。ZUUL是由Netflix开发的一个库，主要用途包括：动态路由、监控和安全。ZUUL根据查询参数、URL和路径进行路由。Netflix基于一系列服务构建。使用服务集合构建应用程序的方式被称为微服务架构。在这种架构中，服务之间相互独立。从设备和网站发起的所有请求都要经过ZUUL才能到达Netflix流媒体应用程序的后端。ZUUL根据用户请求将其路由到特定的服务。例如，如果用户试图登录，则将请求发送到身份验证服务。Netflix架构具有复杂的分布式结构。这种结构有很多优点，也存在一些依赖关系。例如，一台服务器可能要依赖于另一台服务器的输出才能工作。这些服务器之间的依赖关系可能会导致延迟，如果其中一台服务器停止工作，还可能导致单点故障。对于上述问题，Netflix使用了Hystrix。Hystrix是Netflix开发的一个功能非常强大的库，它能使微服务之间彼此隔离，从而将失败数降至最低。Hystrix是通过隔离服务之间的访问点来实现的。Hystrix的用途包括：快速失败和快速恢复、准实时监视、预警和操作控制，减少通过第三方客户端库访问（通常通过网络）依赖项时可能产生的延迟和故障，避免复杂分布式系统中的级联故障。用户活动和历史数据会被发送到流处理管道，用于后续的电影推荐。这些数据还会被发送到AWS、Hadoop、Cassandra等大数据处理工具做进一步处理。</p><p>&nbsp;</p><p></p><h2>Netflix使用的数据库</h2><p></p><p>&nbsp;</p><p>Netflix使用了两种不同的数据库：</p><p>MySQLCassandra</p><p>&nbsp;</p><p></p><h3>MySQL</h3><p></p><p></p><p>对于账单信息、用户信息和交易信息等数据，因为需要遵从ACID，所以Netflix使用MySQL来存储。Netflix的MySQL采用了主-主设置，部署在Amazon的大型EC2实例上。</p><p>&nbsp;</p><p>在主-主设置中，主主节点的写入会被复制到另一个主节点。只有当主主节点和远程主节点的写操作都确认后，才会发送写入确认信息。这确保了数据的高可用性。</p><p>&nbsp;</p><p>Netflix为每个节点（本地和跨区域）设置了读副本，确保了高可用性和可扩展性。</p><p>&nbsp;</p><p></p><h3>Cassandra</h3><p></p><p></p><p>Netflix使用Cassandra是因为它的可扩展性、无单点故障和跨区域部署。总之，一个全局Cassandra集群就可以既为应用程序提供服务，又跨多个地理位置异步复制数据。</p><p>&nbsp;</p><p>Netflix的Cassandra数据模型：</p><p>50+ Cassandra集群500+ 节点日备份数据量30TB单节点每秒写入次数250k</p><p>&nbsp;</p><p></p><h2>Kafka和Apache Chukwa在Netflix的应用</h2><p></p><p></p><p>如上所述，Netflix基于一系列微服务构建，这些微服务共同为用户提供许多服务。</p><p>&nbsp;</p><p>通常，在微服务架构中，一定的失败率是可以接受的。不过，有些失败可能会导致更大的问题。任何一个微服务调用的失败都可能导致大量计算不同步，并可能导致数据差个几百万美元。那还会导致可用性问题和盲点，让你无法有效地追踪数据并回答用户关于什么导致了数据不匹配的问题。</p><p>&nbsp;</p><p>上述问题的解决方案是重新考虑服务的交互方式，将一系列同步请求替换为异步事件交换。这样做有以下好处：</p><p>1. 我们的基础设施变成了天生异步的；</p><p>2. 我们的应用程序变成了松耦合的，错误的可追溯性得到改进。</p><p>&nbsp;</p><p>Netflix使用Apache Kafka来满足事件、消息和流处理需求。</p><p>&nbsp;</p><p>Apache Kafka以发布/订阅模型为基础。Netflix的服务将它们的更改作为事件发布到消息总线上，然后由另一个对该消息感兴趣的服务消费，用于调整其自身的状态。</p><p>&nbsp;</p><p>这使我们能够跟踪服务状态更改是否同步，如果不同步，那么它们需要多长时间才能完成同步。在管理大型服务依赖图时，这种洞察非常有用。</p><p>&nbsp;</p><p>基于事件的通信和去中心化消费帮助我们克服了在大型同步调用图中经常看到的问题（如上所述）。</p><p>&nbsp;</p><p></p><h3>Apache Chukwa</h3><p></p><p></p><p>Apache Chukwa是一个开源的数据收集系统，可用于监控复杂的分布式系统。Chukwa收集来自不同微服务的事件，并将其写入Hadoop文件序列格式。Chukwa还为Kafka提供流量，以便将事件上传到不同的目标，如S3、Elastic搜索等。</p><p>&nbsp;</p><p></p><h3>ElasticSearch</h3><p></p><p></p><p>Netflix使用Elastic搜索来提供客户支持服务、数据可视化和错误检测。例如，如果用户不能播放视频，那么播放团队将使用Elastic搜索来查找问题的原因。它还用于跟踪资源使用情况及检测注册或登录问题。</p><p>&nbsp;</p><p></p><h5>原文链接：</h5><p></p><p><a href=\"https://medium.com/@nidhiupreti99/understanding-system-design-of-netflix-backend-architecture-and-cloud-services-b077162e45bc\">https://medium.com/@nidhiupreti99/understanding-system-design-of-netflix-backend-architecture-and-cloud-services-b077162e45bc</a>\"</p><p></p><h5>相关阅读：</h5><p></p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MzA4NTU2MTg3MQ==&amp;mid=2655180031&amp;idx=1&amp;sn=6deb0568464e2ed75d846419404bd1e6&amp;chksm=8460739fb317fa89a1fd278e62c2e17684fa96d05b4aa50d3fd7dae1193fbd468a0a1f4cf961&amp;scene=27#wechat_redirect\">没有CTO的Netflix：为什么程序员都愿意来？</a>\"</p><p><a href=\"https://www.infoq.cn/article/w4VV1MBhw6VGuxHO9ui2\">Netflix 的 CEO：为什么我们愿意高薪雇佣程序员？</a>\"</p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MzIzNjUxMzk2NQ==&amp;mid=2247527784&amp;idx=1&amp;sn=06439af2abafac8a4aab4859d1555cc6&amp;chksm=e8d492aadfa31bbc94f695d285d0403a8407cbdca4f3ebfe020d71fd1337a47ced0f7a7ab7b4&amp;scene=27#wechat_redirect\">不要让框架影响你最初的架构设计</a>\"</p><p><a href=\"https://www.infoq.cn/article/ZESNdLWpvj8gWf0hdrJA\">混合云的多活架构指南</a>\"</p>",
    "publish_time": "2023-09-25 15:24:59",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AI大模型时代下的算力需求与挑战",
    "url": "https://www.infoq.cn/article/Joe403tMlSW3gHQVOHTm",
    "summary": "<p>算力是信息时代的新生产力，也是 AI 的三大要素之一。随着 ChatGPT 在全球范围内掀起 AI 大模型热潮，AI 算力需求也实现了大爆发。当前&nbsp;AI 大模型的算力需求特点是什么？怎样才能降低算力的使用门槛？IT 基础设施如何应对大模型不断增长的算力需求？近日，InfoQ《极客有约》邀请到了浪潮信息 AI 应用架构师&nbsp;Owen Zhu 博士，为大家分享 AI 大模型时代下的算力需求与挑战。</p><p>&nbsp;</p><p>以下为访谈实录，完整视频参看：<a href=\"https://www.infoq.cn/video/axAUyTihpRTtlJBa20la\">https://www.infoq.cn/video/axAUyTihpRTtlJBa20la</a>\"</p><p>&nbsp;</p><p>姜雨生：欢迎大家来到 InfoQ 极客有约，我是今天的特邀主持人，微软软件工程师姜雨生。本期直播，我们邀请到了浪潮信息 Owen Zhu 博士来给我们做分享。我们今天直播的主题是《AI 大模型时代下的算力需求与挑战》，首先请您给大家介绍一下浪潮信息这家公司。</p><p>&nbsp;</p><p>Owen Zhu：非常荣幸可以在InfoQ 这个平台上与雨生老师一起进行在线交流。首先，我想简要介绍一下浪潮信息。我们是一家历史悠久的公司，主要专注于现代技术领域，特别是在计算能力方面，提供了广泛的基础设施支持。我们可以自豪地说，我们是全球领先的 IT 基础设施提供商，涵盖了计算、存储和网络等各种领域，为互联网、金融、通信等各行各业提供产品、解决方案和服务。</p><p>&nbsp;</p><p>随着 AI 的兴起，我们的 AI 服务器产品也处于全球领先地位。我个人负责人工智能、算法和应用领域的研究工作。在国内，每两台 AI 服务器中就有一台是由浪潮信息生产的，这也是我们的骄傲。</p><p>&nbsp;</p><p>在算法方面，我们一直在努力开展各种工作，尤其是在大模型领域。大约两三年前，我们就开始关注大模型领域，因为这个领域对计算能力有着巨大的需求。两年前，我们发布了千亿级别的大模型“源1.0\"，至今我们仍在不断拓展大模型和其他前沿 AI 技术领域的研究和工作。</p><p></p><h2>“计算力就是生产力，智算力就是创新力”</h2><p></p><p>&nbsp;</p><p>姜雨生：算力是信息时代的新生产力，能分享下您对算力及其重要性的理解吗？它的价值主要体现在哪些方面？</p><p>&nbsp;</p><p>Owen Zhu：从浪潮信息的角度来看，我们在很早之前就开始关注算力的重要性。我们自己定位为算力供应商，因此早早地就开始强调算力的重要性，提出了像“计算力就是生产力”这样的概念。</p><p>&nbsp;</p><p>此外，我们与全球领先的产业研究院机构如国际数据公司IDC、清华大学进行联合编制，发布了许多关于算力的评估报告，例如，此前发布的《2022-2023全球计算力指数评估报告》。在宏观层面上，我们对算力与经济增长之间的关系进行了评估。一个有趣的数据是，我们引入了计算力指数，它用来量化评估每个国家的算力水平，范围从 0 到 100。最新评估结果显示，十五个样本国家的计算力指数平均每提高1点，国家的数字经济和GDP将分别增长3.6‰和1.7‰。这个数据在国内的很多报告中都被引用，说明越来越多的人，包括政府层面，认识到了算力的重要性。</p><p>&nbsp;</p><p>进一步来看，在智能计算领域，我们也提出了一个新概念，即智算力就是创新力，旨在生产力的基础上进一步增强人工智能计算的重要性。具体来说，人工智能在各个领域的应用中都发挥了举足轻重的作用非常明显，包括大模型。此外，在&nbsp;AI for Science 这些领域，人工智能正推动着科学研究，这表明算力在提供创新力和社会创新方面发挥着根本性的作用。现在热门的 AIGC，深刻反映了AI 在创造力方面的能力体现，而这些能力都是在算力的支持下实现的。</p><p>&nbsp;</p><p>此外，如果我们深入研究算力对整个 AI 发展的驱动作用，可以清楚地看到，它实际上是 AI 发展的核心支持和引擎。有很多例子可以证明这一点，包括算力从 2012 年以来的指数级增长。一个具体的例子是自动驾驶领域，这个领域已经取得了长足的发展。从最早只能提供辅助驾驶功能，到能够在高速公路上实现无人干预的自动驾驶，再到最近针对城市通勤的自动驾驶应用。浪潮信息服务非常多的汽车制造商和自动驾驶客户，他们对算力的需求也在逐步增加。在这些年里，我们还看到他们在 AI 算法方面的投入，特别是在模型训练方面，从技术进步的角度看，算力的需求可能增加了数十到数百倍。</p><p>&nbsp;</p><p>总之，无论从宏观经济发展层面还是从微观应用场景和算法层面来看，算力都扮演着至关重要的角色。</p><p>&nbsp;</p><p>姜雨生：算力是不是分很多的类别？从你的角度来说，算力能按哪些类别来区分呢？</p><p>&nbsp;</p><p>Owen Zhu：实际上，当我们谈论算力时，如果要进行分类，首先需要明确两个相似但不同的概念，即计算和算力。在过去，我们更多地强调计算，如云计算、边缘计算、科学计算、AI 计算、量子计算，等等。计算领域有各种分类方法，通常根据供给方式或计算发生的位置来划分，例如云计算和边缘计算。而算力实际上是计算能力的一个简称，它是一种衡量指标，通常是量化的。更进一步，我们可以使用类似 flops（每秒浮点运算次数）或者整数算力（int）等具体数值来衡量算力。因为算力是一种衡量指标，目前通常的分类方法是将其分为通用算力和专用算力，或者称之为智能算力，即 AI 算力。</p><p>&nbsp;</p><p>为什么要这样分类呢？这背后有一些历史渊源。在过去，CPU 通常是支持计算的主要处理器，因此我们将 CPU 提供的算力称为通用算力。在 AI 时代，我们更多地使用加速计算，也就是使用 GPU 或 AI 芯片，并且在算力的具体支持方面，我们可能会使用专门针对 AI 的数据格式，如 LP16、INT8、BF16、TF32 等。因此，在进行算力衡量时，我们将其区分为通用算力和智能算力。大致来说，当今我们谈论算力时，更多的是在讨论 AI 算力。</p><p>&nbsp;</p><p>姜雨生：针对刚才您提到的这几个分类，我们国内现在在这几方面的发展现状如何？</p><p>&nbsp;</p><p>Owen Zhu：这个问题实际上是一个相对宏观的问题。我们之前提到过的我们和国际数据公司 IDC 的评估报告，对各个国家在算力领域的投入进行评估和打分。总体来说，我国算力总规模全球第二，仅次于美国，年增长率近30%。将目光再聚焦于当下最热议的生成式AI算力，其从 2022 年的 8.2 亿美元增长到 2026 年的 109.9 亿美元，市场占比（生成式 AI 计算占整体 AI 计算市场）更是从 4.2% 增长到 31.7% 。</p><p>&nbsp;</p><p>姜雨生：有观众提问，自动驾驶系统哪部分对算力的需求最大？</p><p>&nbsp;</p><p>Owen Zhu：当涉及到自动驾驶时，我们需要考虑到一些关键环节，其中最重要的一个环节是感知。</p><p>&nbsp;</p><p>在自动驾驶中，感知是一个关键步骤。车辆上配备了多种传感器，如摄像头、雷达、激光雷达等，这些传感器收集到的数据需要进行处理，通常需要引入各种人工智能模型。对于雷达数据，我们可能需要使用基于雷达的 3D 目标检测或其他模型来进行感知。对于摄像头数据，我们可能需要使用基于图片或视频的 2D 或 3D 感知算法。在整个自动驾驶系统中，感知阶段通常是算力需求最大的阶段。这些计算通常在云端完成。在实际应用之前，自动驾驶模型通常需要大规模的训练。一些领先的自动驾驶企业，如特斯拉，拥有庞大的 GPU 和 AI 算力规模。此外，一些公司还在自研 AI 芯片和AI算力系统，这些芯片主要用于感知。</p><p>&nbsp;</p><p>近年来，人们还在尝试将大型模型引入自动驾驶领域，实现端到端的模型，也就是将各个环节整合到一个模型中。这意味着传感器数据被输入到一个大型模型中，以进行决策控制，并指导车辆下一步的操作。这个决策控制阶段也需要大量的算力投入。</p><p>&nbsp;</p><p>在自动驾驶领域，算力需求不仅限于感知阶段，还包括决策控制阶段，尤其是在引入深度学习算法后。这就是目前自动驾驶领域的大致情况。</p><p></p><h2>“算力的投入与智能的涌现有直接关系”</h2><p></p><p>&nbsp;</p><p>姜雨生：在我刚参加工作的时候，AI 并不是一个热门话题，很少有人提到 AI 这个概念。大多数人当时更多地从事计算机相关的工作，专注于一些传统的服务和应用层面的工作。在 AI 的大型模型兴起之前，算力用在哪些方面呢？</p><p>&nbsp;</p><p>Owen Zhu：这是一个很有趣的问题。虽然现在公众对算力的概念越来越熟悉，近年来也举办了越来越多的专门针对算力的活动，但实际上在此之前，算力的概念早已存在。从浪潮信息的角度来看，我们早在多年前就已经开始讨论算力。至于在 AI 大模型兴起之前，实际上有很多领域都在使用算力：</p><p>&nbsp;</p><p>互联网服务：在互联网领域，算力的需求一直很高。例如，回顾到 2019 年，百度中标了春晚的红包活动，为了支持这一活动，他们准备了高达 10 万台服务器的算力。这显示了在互联网抢红包等活动中，需要大规模的算力支持。在线购票和出行服务：在线购票、滴滴打车、美团外卖等服务都依赖于大量的算力来支持实时交易和路线规划。科学计算：科学领域一直在使用算力来进行复杂的计算，如天气预报、工程仿真、分子工程模拟、材料仿真等。天气预报的准确性不断提高，台风和洪水的预测也得益于强大的算力。</p><p>&nbsp;</p><p>总之，算力在许多不同领域都发挥着关键作用，早在 AI 大模型兴起之前就已经是一个重要的资源需求。</p><p>&nbsp;</p><p>姜雨生：我们现在正处于一个非常有趣的时刻，OpenAI 推出了 ChatGPT，全球范围内引发了对 AI 大模型的热潮。许多公司都在全力以赴投入算力，现阶段算力需求发生了哪些变化？算力对于 AI 的发展有多大的影响？</p><p>&nbsp;</p><p>Owen Zhu：我们必须承认算力在当前 AI 发展中的重要性是非常高的，这也是为什么人们争相获取算力的根本原因。我们可以展开讨论这个问题。之前我们一直提到深度学习的三驾马车：算力、算法和数据，它们共同推动了深度学习技术的进步。但随着大模型时代的到来，尽管这些要素仍然很重要，但算力的重要性更加凸显。</p><p>&nbsp;</p><p>为什么这样说呢？因为我们现在逐渐认识到一个事实，那就是通用人工智能引入了一些重要的概念，如泛化和涌现。这些是非常核心的能力，但如何衡量它们呢？渐渐地，业界形成了一个共识，即算力的投入与智能的涌现有着直接关系。</p><p>&nbsp;</p><p>这个观点为什么会出现呢？从理论分析的角度来看，大模型中有一个重要概念，称为\"扩展性\"，即如何扩展大模型的能力。比如，如果我们要将一个模型的参数扩大 10 倍，需要训练一个 10 倍规模的模型，我们需要多少算力来支持这个过程？这就是所谓的\"扩展性\"问题。在这方面，OpenAI 和其他公司进行了大量研究，发现扩展模型的过程是近似线性的。这意味着，要扩大 10 倍的模型，需要 100 倍的算力投入。这使得算力成为一个重要的标尺，用来衡量模型的能力。因此，算力的投入越大，模型的能力也越强。</p><p>&nbsp;</p><p>举个例子，GPT-3 拥有 1750 亿参数，训练时使用了 3000 亿的 token 数。而像&nbsp;Llama 2&nbsp;这样的新模型，虽然参数较少，只有 650 亿，但训练使用了 1.4 万亿的 token 数，实际上投入的算力更大。从评测指标上看，Llama 2&nbsp;在某些方面超越了 GPT-3，这进一步证实了算力投入与模型能力的关系。</p><p>&nbsp;</p><p>最近，有一些关于 GPT-4 的估测表明，它的算力投入可能是 GPT-3 的 68 倍，甚至更多。而谷歌即将发布的下一代模型 Gemini，被认为将投入超过 GPT-4 5 倍以上的算力。这显示出在大模型的算力投入方面，业界领先公司在成本上毫不吝啬。</p><p>&nbsp;</p><p>姜雨生：有观众提问，在算力足够的情况下，模型能力可以无限的增强，带来无限可能吗？</p><p>&nbsp;</p><p>Owen Zhu：业界对于这个问题尚无明确答案。然而，有一个观点是，当算力不再是限制时，数据将成为限制因素。这个观点在业界已经有一些人在讨论，即像 OpenAI 和其他互联网公司一样，他们正在大规模地进行模型训练，很快可能会耗尽互联网上的数据资源，这并非无稽之谈。</p><p>&nbsp;</p><p>事实上，当我们自己进行数据处理时，我们会发现互联网上的文本数据的质量和数量是有限的。特别是对于中文互联网来说，由于相对封闭的特性，获取高质量的数据可能会受到一些限制。因此，数据的限制可能很快会成为一个瓶颈。因此，尽管我们拥有强大的算力，但并不意味着智能会无限增长。</p><p>&nbsp;</p><p>然而，有很多解决方法，例如引入多模态数据。我们知道引入新的模态数据可以带入大量新信息，从而进一步提升模型的性能。因此，这个问题的解决方案可能是多种多样的，非常值得继续探讨。</p><p></p><h2>“大模型时代的基础设施建设”</h2><p></p><p>&nbsp;</p><p>姜雨生：云服务提供商在算力方面可能存在垄断或半垄断的情况，这使得访问大型模型成为一种昂贵的资源。对于个人开发者来说，有些人可能确实用不到这种大型模型，而另一些人可能承受不起这些服务的高成本。有声音认为买不起算力，直接将一大部分开发者挡在了 AI 时代的大门外，您怎么看“买不起”这一现象？</p><p>&nbsp;</p><p>Owen Zhu：今年以来，算力供应情况紧张，这涉及到多个层面的原因，不一一探讨，但与供应关系密切相关。解决买不起算力的问题，我们从基础设施和算力提供商的角度尝试各种方法。云服务可能是一种解决方案，即直接从公有云购买算力。</p><p>&nbsp;</p><p>此外，我们提出了一个重要的概念和策略，即“智算中心”。其逻辑是，政府或类似公益机构作为主体购买和储备以 AI 算力为主的资源中心。这种方法的提供方向更侧重于社会经济效益和社会效益，而不仅仅是商业利润。通过建立智算中心，我们可以推动产业发展，例如国内模型的培训，以及改进社会效率和模型应用，从而提高生活质量和企业效率等方面的利益。因此，在解决买不起算力的问题方面，智算中心的建立有很大帮助。</p><p>&nbsp;</p><p>多年来，我们一直在推动这些事情，并已经与许多地方政府建立了多个智算中心，如济南、南京、宿州等地，基于这样模式之上的模型已经帮助许多企业解决了各种问题，这也可以视为一种解决方案或策略。</p><p>&nbsp;</p><p>姜雨生：对于企业而言，大模型时代基础设施建设面临两个比较大的困难：一是高额的成本，二是随着算力集群规模增大，稳定性越难做到，效率也很难提升。对于第二点，目前有哪些解决方案？</p><p>&nbsp;</p><p>Owen Zhu：我们正在尝试解决这一问题，并与您之前提到的类似方向有些相似。实际上，我们可以从观察多家企业的现状入手，以解释这个情况。在过去，许多企业可能更倾向于使用公有云等云服务提供商的算力来满足 AI 需求，但是今年我们观察到了一些变化，即企业更倾向于选择高质量的算力，例如智算中心，或者自建基础设施。</p><p>&nbsp;</p><p>这种变化有多个原因，其中之一是对算力的需求发生了重大变化。现在，训练AI大模型可能需要数百甚至上千块 GPU 卡。对于企业来说，购买如此大规模的算力可能成为挑战，因为即使是公有云，其资源分布在不同的数据中心，难以实现集中供给。此外，云服务商通常通过资源超售等方式提高利用率，从而降低成本，但对于 AI 算力，用户更希望充分利用资源，不希望资源被超售。</p><p>&nbsp;</p><p>自建基础设施的成本可能相对较低，但也带来了一些新的挑战，如操作系统、驱动程序、环境配置、监控和调度等问题。为了解决这些问题，我们上月刚发布了一个大模型智算软件栈 OGAI，全称是Open GenAI Infra，旨在为客户提供一套技术堆栈，通过多层次的软件解决方案来解决这些问题。这包括对智算中心的支持，以及指南和工具，帮助用户部署和配置 AI 基础设施。对于许多用户来说，特别是那些刚刚购买算力的用户，部署可能是一个挑战，因此我们提供了一个指南，以指导他们完成部署并避免一些常见问题。此外，我们还提供一些商业化的软件解决方案，用于大规模算力的调度和硬件兼容性等问题。</p><p>&nbsp;</p><p>姜雨生：在大型 AI 模型时代，IT 服务领域的厂商正在积极探索新的可能性。展开来看，对于国内 IT 服务领域的厂商来说，大模型时代带来了一些机遇和挑战。我也很关心浪潮信息作为一家公司，是否在产品策略上发生了变化或者采取了一些创新举措。您提到了大数据平台，这确实是一个关键领域，许多公司都在不懈努力，旨在为客户提供更强大且易于使用的体验。我很想听听您的更多观点。</p><p>&nbsp;</p><p>Owen Zhu：您谈到的关于基础设施和算力的问题，确实对 AI 行业产生了许多挑战和机遇。最近，我注意到业界开始聊到&nbsp;AI 领域的人才，并强调了其重要性，可能超过了大型&nbsp;AI 模型的重要性。</p><p>&nbsp;</p><p>回到这个问题，我觉得有几个方面需要关注。首先，从市场的角度来看，当前算力仍然是一项短期内比较突出的问题，特别是在上半年，大家一直都在争抢算力资源。这种紧缺局面可能会一直持续到明年的 Q1 和 Q2。大模型对整个 AI 行业产生了革命性的影响，这是继 AlphaGo 之后的第二次重大变革。因此，算力短缺将继续存在。</p><p>&nbsp;</p><p>第二，我们需要关注的趋势是多元异构计算的概念，尽管这听起来有点抽象。目前，主要的加速芯片是 Nvidia 的 GPU，但随着加速计算和异构计算在计算中变得越来越重要，更多的加速计算芯片和解决方案将涌现，包括英特尔的 Habana 和 AMD 的 MI 系列等针对 AI 的加速芯片。这将导致市场出现多元化的生态系统，这一趋势将逐渐凸显。因此，我们需要思考如何在这种情况下实现兼容性和融合，以确保各种芯片和产品能够无缝协作，提供给用户一个一致的接口。</p><p>&nbsp;</p><p>第三，算力基建化将成为一个重要趋势，随着算力的不断增加，它将成为基础设施的一部分。政府、云服务提供商和科技公司等都在大规模投资和建设算力基础设施，将算力作为一种服务提供给外部。这将推动算力基建化技术的加速发展，以满足不同行业和应用领域的需求。</p><p>&nbsp;</p><p>总之，我们需要在硬件、软件和算法等多个层面上积极应对这些趋势。在硬件层面，我们需要关注多元化的 AI 芯片接入。在软件和算法层面，我们需要投入更多的资源来研发和支持算法，以及解决用户在应用 AI 时可能遇到的问题。此外，构建生态系统也是一个关键战略，让不同领域的专业公司和行业解决方案提供商共同合作，以实现 AI 技术在各个领域的落地应用。这将有助于促进 AI 产业的发展和应用。</p><p></p><h4>嘉宾介绍</h4><p></p><p></p><p>特邀主持：</p><p></p><p>姜雨生，微软软件工程师，负责微软资讯业务与 GPT 集成，曾负责微软广告团队基础设施搭建与维护工作。</p><p></p><p>嘉宾：</p><p></p><p>Owen Zhu，浪潮信息 AI 应用架构师，中国科学技术大学博士。从事人工智能方向相关工作多年，当前主要负责大模型、AIGC 等前沿 AI 算法研发和 AI 应用落地研究工作。</p>",
    "publish_time": "2023-09-25 15:29:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "阿里云通义千问14B模型开源：性能超越Llama2等同尺寸模型",
    "url": "https://www.infoq.cn/article/MTaYW6a4CNrahgkYXAyT",
    "summary": "<p></p><blockquote>两个月三连发，通义千问又开源了。</blockquote><p></p><p></p><p>9月25日，阿里云开源通义千问140亿参数模型Qwen-14B及其对话模型Qwen-14B-Chat，支持免费商用。在多项权威评测中，Qwen-14B的性能表现超越同等规模模型，部分指标甚至接近Llama2-70B。此前阿里云于8月开源了通义千问70亿参数基座模型Qwen-7B，先后冲上HuggingFace、GitHub的Trending榜单。短短一个多月，累计下载量就突破100万，开源社区出现了约50个基于Qwen的模型。</p><p>多个知名工具和框架都集成了Qwen，如支持用大模型搭建WebUI、API以及微调的工具FastChat、量化模型框架AutoGPTQ、大模型部署和推理框架LMDeploy、大模型微调框架XTuner等等。</p><p></p><p>据了解，此次开源的Qwen-14B是一款支持多种语言的高性能开源模型，相比同类模型使用了更多的高质量数据，整体训练数据超过3万亿Token，使模型具备更强大的推理、认知、规划和记忆能力。Qwen-14B最大支持8k的上下文窗口长度。</p><p><img src=\"https://static001.geekbang.org/infoq/16/166ee1f62a1c35fb0c11ac5079f70bbc.jpeg\" /></p><p></p><p>图1：Qwen-14B在十二个权威测评中全方位超越同规模SOTA大模型</p><p></p><p>而Qwen-14B-Chat则是在基座模型上经过精细SFT得到的对话模型。借助基座模型强大的性能，Qwen-14B-Chat生成内容的准确度大幅提升，也更符合人类偏好，内容创作上的想象力和丰富度也有显著扩展。</p><p></p><p>Qwen拥有出色的工具调用能力，能让开发者更快地构建基于Qwen的Agent（智能体）。开发者可用简单指令教会Qwen使用复杂工具，比如使用Code&nbsp;Interpreter工具执行Python代码以进行复杂的数学计算数据分析、图表绘制等；还能开发具有多文档问答、长文写作等能力的“高级数字助理”。</p><p></p><p>百亿以内参数级别大语言模型是目前开发者进行应用开发和迭代的主流选择，&nbsp;Qwen-14B进一步提高了小尺寸模型的性能上限，从众多同尺寸模型中冲出重围，在MMLU、C-Eval、GSM8K、MATH、GaoKao-Bench等12个权威测评中取得最优成绩，超越所有测评中的SOTA（State-Of-The-Art）大模型，也全面超越Llama 2-13B，比起Llama&nbsp;2的34B、70B模型也并不逊色。与此同时，Qwen-7B也全新升级，核心指标最高提升22.5%。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4f/4fbdbdc1d80f97d6c961cd076ca7a4ce.png\" /></p><p>图2：Qwen-14B性能超越同尺寸模型</p><p></p><p>据InfoQ向通义千问研发团队了解，Qwen-14B之所以能较上一代Qwen-7B获得显著的性能提升，主要有三方面原因。</p><p></p><p>在数据集构建方面：</p><p></p><p>研发团队使用了多达3万亿token的大规模预训练数据集，覆盖了各个领域和千行百业的知识，包含多个语种的语言，还有代码数据。在此基础之上，研发团队做了较为精细的数据处理，包括大规模数据去重、垃圾文本过滤、以及提升高质量数据比例等。</p><p></p><p>在模型结构设计和训练方法方面：</p><p></p><p>模型结构方面，研发团队此前做了一系列前期实验验证模型结构设计对效果的影响，整体而言，Google的PaLM、Meta的LLaMA的大多数技术选择都是效果较好的，包括SwiGLU的激活函数设计、ROPE的位置编码等，在Qwen的结构设计中也都采用了。</p><p></p><p>通义千问团队专门针对词表做了优化，词表大小超过15万，具有较好的编码效率，也就是说，相比其他tokenizer能用更少的token表示更大量的信息，意味着更加节省的token数，或者说更低的成本。</p><p></p><p>此外，通义千问团队重点针对长序列数据建模做了优化，采用当前最有效的策路，包括但不限于Dynamnic NTK、Log-N attention scaling、window attention等，并做了一些细节的调整保证长序列数据上，模型表现效果更稳定。当前模型能够适配井取得稳定表现的序列长度也达到了8192。</p><p></p><p>研发团队成员向InfoQ表示：“大模型训练其实没有太多复杂的技巧，更多是经过大量尝试与迭代，找到较好的训练参数，达到训练稳定性、训练效果和训练效率的最优平衡，包括但不限于优化器的配置、模型并行的配置等。”</p><p></p><p>在外接工具能力方面：</p><p></p><p>此前开源的Qwen-7B已经展现出了出色的工具使用能力，只需通过文本描述即可理解并使用未经训练的新工具，可用于各种Agent应用。这次开源的新模型进一步增强了Agent能力，在使用复杂工具时的可靠性有了显著提升。</p><p></p><p>例如，Qwen-14B可以熟练地使用Code Interpreter工具执行Python代码，进行复杂的数学计算、数据分析和数据图表绘制。同时，Qwen-14B的规划和记忆能力也得到了提升，在执行多文档问答和长文写作等任务时表现更加可靠。</p><p></p><p>为了实现这一效果，研发团队主要做了两方面的优化。首先，在微调样本方面进行优化，通过建立更全面的自动评估基准，主动发现了之前Qwen表现不稳定的情況，并针对性地使用Self-Instruct方法扩充了高质量的微调样本。其次，底座预训练模型的能力得到了提升，带来了更强的理解和代码能力。</p><p></p><p>即日起，用户可从魔搭社区直接下载模型，也可通过阿里云灵积平台访问和调用Qwen-14B和Qwen-14B-Chat。阿里云为用户提供包括模型训练、推理、部署、精调等在内的全方位服务。</p><p></p><p>据了解，当前国内已有多个月活过亿的应用接入通义千问，大量中小企业、科研机构和个人开发者都在基于通义千问开发专属大模型或应用产品，如阿里系的淘宝、钉钉、未来精灵，以及外部的科研机构、创业企业。</p><p></p><p>钉钉是最早接入通义千问的应用之一。4月18日，钉钉发布了一条“斜杠”， 接入千问大模型后，通过输入“/”即可在钉钉唤起AI能力，涵盖群聊、文档、视频会议及应用开发等场景。</p><p>&nbsp;</p><p>在群聊中，新入群者无需爬楼，在对话框输入钉钉斜杠“/”即可自动整理群聊要点，快速了解上下文，并生成待办、预约日程。还可以用“/”在群聊中创作文案、表情包等；在钉钉文档中，“/”可以是用户的创意助理，帮助写文案、生成海报。在视频会议中，“/”也是会议助理，能一键生成讨论要点、会议结论、待办事项等；“/”还可用自然语言或拍照生成应用，并以钉钉酷应用的形式在群聊内使用。比如，公司行政人员需要统计午餐的订餐份数，只需要在群聊对话框中输入“/”和需求，几秒钟后一个订餐统计小程序就会展现在群聊中。</p><p>&nbsp;</p><p>在过去100多天里，钉钉正逐渐实现全面智能化，已经有17条产品线、55个场景完成了智能化再造，包含钉钉 IM 群聊、酷应用、低代码、钉钉会议、Teambition、闪记、邮箱、钉钉文档、表格、脑图、白板、知识库等，覆盖多模态内容生成、摘要提取、应用开发等。</p><p></p><p>浙江大学联合高等教育出版社基于Qwen-7B开发了智海-三乐教育垂直大模型，已在全国12所高校应用，可提供智能问答、试题生成、学习导航、教学评估等能力，模型已在阿里云灵积平台对外提供服务，一行代码即可调用；浙江有鹿机器人科技有限公司在路面清洁机器人中集成了Qwen-7B，使机器人能以自然语言与用户进行实时交互，理解用户提出的需求，将用户的高层指令进行分析和拆解，做高层的逻辑分析和任务规划，完成清洁任务。</p><p></p><p>阿里云CTO周靖人表示，阿里云将持续拥抱开源开放，推动中国大模型生态建设。阿里云笃信开源开放的力量，率先开源自研大模型，希望让大模型技术更快触达中小企业和个人开发者。</p><p></p><p>附相关链接：</p><p></p><p>魔搭社区模型地址：</p><p>https://www.modelscope.cn/models/qwen/Qwen-14B-Chat/summaryhttps://www.modelscope.cn/models/qwen/Qwen-14B/summary</p><p></p><p>Qwen论文地址：</p><p>https://qianwen-res.oss-cn-beijing.aliyuncs.com/QWEN_TECHNICAL_REPORT.pdf</p><p></p><p>GitHub：</p><p>https://github.com/QwenLM/Qwen</p><p></p><p>HuggingFace:</p><p>https://huggingface.co/Qwen/Qwen-14Bhttps://huggingface.co/Qwen/Qwen-14B-Chat</p>",
    "publish_time": "2023-09-25 15:40:11",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]