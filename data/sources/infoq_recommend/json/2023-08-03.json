[
  {
    "title": "Kubernetes物料清单（KBOMs）助力安全团队应对CVE攻防战",
    "url": "https://www.infoq.cn/article/CeVizGJmN9M8e5EWc2w1",
    "summary": "<p>KSOC&nbsp;<a href=\"https://ksoc.com/\">实验室</a>\"近期宣布了首批 Kubernetes 物料清单（KBOMs）。KBOM 是一款开源标准和命令行工具，可帮助安全团队快速分析集群配置并应对 CVE。</p><p></p><p>该项目包含一份初始规范和实施方案，可跨云供应商、企业内部（on-premise)及自定义环境使用。</p><p><a href=\"https://www.infoq.com/search.action?queryString=JSON\">JSON</a>\"&nbsp;格式的规范中提供了关于集群不同组件，以及内部和托管应用程序的实例、Kubernetes 对象、容器镜像的详细信息。</p><p></p><p>这些信息有助于安全和规范团队将 Kubernetes 集群视为单一个体，快速识别漏洞和维系，不再需要单独查看其中的基础组件。</p><p></p><p>KBOM 给出了针对 Kubernetes 集群的简单概述，如：</p><p>以工作负载数计算的集群规模云提供商上的节点成本和类型Kubernetes 相关组件和托管应用程序镜像的漏洞来自三方的客户化和插件，如定制资源、认证和服务网格平台及其组件的版本细节</p><p></p><p>今年上半年，KSOC 实验室于<a href=\"https://kccnceu2023.sched.com/?\">2023年欧洲 KubeCon+CloudNativeCon 大会</a>\"中就容器安全、云态势管理和运行时安全解决方案，以及是否需要专门为 Kubernetes 配置安全解决方案的问题，对与会者进行了调研，97% 的参与者回答为肯定。</p><p></p><p>KSOC 团队认为，即使是目前已有的类似标准和工具有助于对应用及其底层基础设施组件的理解，如软件物料清单（<a href=\"https://www.infoq.com/news/2023/02/sboms-vex-kubernetes/\">SBOMs</a>\"）和基础设施物料清单（IBOMs），但这些并不一定能让安全团队对集群进行快速分析，并对&nbsp;<a href=\"https://www.infoq.com/news/2021/08/cve-cloud-vulnerabilities/\">CVE</a>\"&nbsp;做出快速响应。</p><p></p><p>通过 KBOM 的发布，KSOC 团队希望能让 Kubernetes 进入安全并合乎规范的区域。</p><p></p><p>安全和规范团队可通过使用 KBOM 对其 Kubernetes 集群（尤其是三方插件），获得更高的可见性。举例来说，KBOM 可对最近 Kubernetes CVE 漏洞，允许权限升级，进行分析，该漏洞技术复杂，恶意者可从应用容器进入底层主机，从而接管全部集群。</p><p></p><p>这些项目中也包含&nbsp;<a href=\"https://landscape.cncf.io/\">CNCF 全景图</a>\"（landscape）中的项目，如影响&nbsp;<a href=\"https://www.crossplane.io/\">crossplane</a>\"&nbsp;的&nbsp;<a href=\"https://nvd.nist.gov/vuln/detail/CVE-2023-27483\">CVE-2023-27483</a>\"，crossplane 为一款借助 Kubernetes API 配置和管理云基础设施的多云控制面板；影响&nbsp;<a href=\"https://clusternet.io/\">Clusternet</a>\"&nbsp;的&nbsp;<a href=\"https://nvd.nist.gov/vuln/detail/CVE-2023-30622\">CVE-2023-30622</a>\"，Clusternet 为一款管理公共、私有、混合以及边缘环境中多个 Kubernetes 集群的解决方案。</p><p></p><p>此外，还包含涉及 Jenkins 插件的&nbsp;<a href=\"https://nvd.nist.gov/vuln/detail/CVE-2023-30513\">CVE-2023-30513</a>\"&nbsp;，该 Jenkins 插件可管理从 Jenkins 到集群中的所有 CI/CD 管道的通信。</p><p></p><p>该规范为 Kubernetes 社区打下了基础，人们可在该基础上增添更多信息以支持未来的不同用例。</p><p>KBOM 在所有主流云供应商上均进行了测试，其中包括 AWS、Azure和谷歌云，可适用于所有 Kubernetes v1 往后的版本。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/06/kubernetes-bill-of-materials/\">KSOC Labs Release the First Kubernetes Bill of Materials (KBOMs)</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/AhfmZfWjvUAmap5lcTAI\">三步实现Lambda向Kubernetes大迁移</a>\"</p><p><a href=\"https://www.infoq.cn/article/jU8j08BurbpglgY8zqoD\">从修复 Kubernetes 集群中，我学到了什么</a>\"</p>",
    "publish_time": "2023-08-03 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "复杂业务开发之服务通信 ：HTTP、Kafka 组件",
    "url": "https://www.infoq.cn/article/794y1bQBBS9UhPODeTWJ",
    "summary": "<p>在现代企业开发中，初级开发者难以掌握开发企业级 Java 应用，中高级开发者则被繁琐任务所占据。为了让大家能快速上手可以解决这个难题的“SoFlu 软件机器人”，前蚂蚁金服技术专家杨彪设计了《2 小时学会 10 个组件“取代”传统 Java 开发》课程，本节为该系列课程的第四讲。</p>\n<p>本讲将聚焦于“服务通信”话题——在当今微服务流行之下，服务之交互也变得非常频繁，如何保证服务通信稳定也是企业服务稳定性治理中一大难题。本节便将通过介绍SoFlu提供的常用组件——HTTP组件、Kafka组件，来解决业务服务通信稳定的问题。</p>\n<p>大家在课后可以登录 Gitee 下载 SoFlu 软件机器人客户端进行实践：<a href=\"http://suo.im/8wROo\">点击下载</a></p>\n<p>大家可以扫码添加小助手，进学习群与专家一对一交流：<br />\n<img alt=\"\" src=\"https://static001.infoq.cn/resource/image/e8/c9/e8833a01ba0bc705acab14a572b57cc9.png\" /></p>",
    "publish_time": "2023-08-03 09:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "中国卓越技术团队访谈录（2023 年第二季）",
    "url": "https://www.infoq.cn/article/b8qPXJ8SuGLwTDVO7sSJ",
    "summary": "<p><strong>封面故事</strong></p>\n<ul>\n<li>两个多月完成全自研：大模型之争，从GPU卷到了向量数据库</li>\n</ul>\n<p>之所以能如此快地推出这款产品，罗云表示，这主要得益于两方面：一个是云团队内部多年的技术积累；另一方面是这个团队中每个人都是能打“硬仗”的好兵。</p>\n<p><strong>重磅访谈</strong></p>\n<ul>\n<li>越来越“卷”的文生图模型，如何在中文世界“杀”出一条路？</li>\n</ul>\n<p>“我们需要重新审视自身的工作路径，并考虑如何与有志于参与模型建设的行业伙伴建立关系。同时，我们也要考虑如何支持内部同事，尤其是那些掌握了一定 AI 生产能力的美术同事们，帮助他们更好地利用 AIGC 技术，以提升他们的工作效率和质量。”</p>\n<ul>\n<li>中国最大公有云服务商，如何从零开始构建一支云效团队</li>\n</ul>\n<p>“在国内的 To B 赛道，绝大部分产品市场销量不好的原因很简单，就是不好用，用了以后解决不了业务问题。”</p>\n<ul>\n<li>桌面QQ重构，探寻跨平台开发挑战与Electron内存优化突破</li>\n</ul>\n<p>“QQ的重构其实是两方面的重构：一个是面向复杂业务的梳理重构，一个面向工程技术债的全新技术重构，重构之路也是两者相互伴随的过程。”</p>\n<p><strong>管理与研效</strong></p>\n<ul>\n<li>MySQL 之父：不要把一个优秀的开发者提升为管理者，那会是种资源浪费</li>\n</ul>\n<p>程序员需要 8-10 年，甚至更长的时间才能达到他们的巅峰。优秀的程序员是企业的宝贵资源，他们甚至 70 年间都可以输出高质量的代码。</p>\n<ul>\n<li>传统管理秩序消失，数字化下的组织和人才如何重塑</li>\n</ul>\n<p>着“岗位”的边界消失，技能将替代岗位，成为员工和工作的连接点。对于企业而言，需要健全人才能力标签体系，从而更好的选人、识人、用人，最大化发挥员工价值。</p>\n<ul>\n<li>第一批因 AIGC 裁掉自家员工的老板该后悔了？</li>\n</ul>\n<p>试图将 AI 应用到多个地方，期望能降低成本，包括生产产品描述、创建虚拟助手、开发仍处于 Beta 测试阶段的新客服中心 AI 代理等。然而，这种成本削减策略已经对客户满意度产生了负面影响。</p>\n<ul>\n<li>如何利用 AIGC 自动化编程提高研发效率？</li>\n</ul>\n<p>我们就像多了一个无所不能的“师傅”，随叫随到还可以给你直接写出可能的代码，让你参考学习，让一个初级的程序员快速具有“师傅”写代码的能力。</p>",
    "publish_time": "2023-08-03 12:15:19",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "LMOps工具链与文心千帆大模型平台",
    "url": "https://www.infoq.cn/article/aJ4X2k7oSvKE8WT1R8PP",
    "summary": "<p>在《大模型时代的AI基础设施——百度AI大底座》系列云智公开课第七讲中，百度智能云主任架构师谢永康分享了LMOPs工具链与文心千帆大模型平台的相关技术。</p>\n<p>他在介绍了大模型的技术发展趋势并简述了本讲的要点后，从包括机器学习、百模大战的大模型训练推理的主要环节及挑战等几个方面进行了详述，同时对于企业级大模型LMOPs工具链和基础设施也做了详解；在技术应用层面，他对于百度AI大底座中的文心千帆大模型平台的核心技术、AI大底座与产业实践、产品的相关应用也做了介绍。</p>\n<p>希望本期视频可以让各位了解更多大模型的相关知识。</p>",
    "publish_time": "2023-08-03 14:02:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "程序员的未来：工作和学习都要依赖 AI 了？",
    "url": "https://www.infoq.cn/article/1v2AHRigg5Je1bK0A1hV",
    "summary": "<p>“开发遇到问题，基本上‘官方文档 + Stack Overflow + Github Issues’能解决90%的问题。剩下10%的‘问题’不是问题，而是压根没用对，你的方向就是错的。”有开发者说道，这足以证明Stack Overflow在程序员心里的地位，至少曾经如此。</p><p>&nbsp;</p><p>近日，有人分享了Stack Overflow的流量数据：在过去一年半的时间里，Stack Overflow的流量下降了大约50%。这种下降同样反映在网站使用率上，问题和答案的数量减少了约50%，这些帖子获得的投票数量也减少了约50%。这无疑又引发了大家对于“Stack Overflow 衰落”的讨论。</p><p>&nbsp;</p><p>对此，马斯克在<a href=\"https://twitter.com/elonmusk/status/1683910138220929028\">推特上评论</a>\"称：“被LLM杀死了。”随后，ARK分析师Brett Winton发帖称：“花在Stack Overflow上的时间比去年同期下降了40%，比峰值下降了约2亿小时。以每小时50美元计算，在Stack Overflow上节省的时间价值100亿美元(一些时间转移到Replit/ChatGPT/Copilot，一些被认为是生产力提升)。”马斯克评论称：“LLM导致的死亡将越来越普遍。”</p><p><img src=\"https://static001.geekbang.org/infoq/4d/4dc0e507e5a9f220b3203f5e42d5b25c.jpeg\" /></p><p></p><p></p><h2>&nbsp;</h2><p></p><p></p><h2>压死骆驼的最后一根稻草?</h2><p></p><p>&nbsp;</p><p>ChatGPT 推出后不久，开发人员发现它的有用之处之一是生成详细的代码示例和完整的功能，ChatGPT附带的教程内容还解释了代码的工作原理。与 Stack Overflow 的比较以及 ChatGPT 将“杀死”Stack Overflow 的预测也从那时便开始了。</p><p>&nbsp;</p><p>“我向 ChatGPT 询问了一个编程问题，不到一秒就生成了答案，而且答案是正确的。鉴于大多数用户在 Stack Overflow 上发帖，甚至没有得到问题的答案，这对于大多数经历过这种情况的用户来说可能是一种解脱。”<a href=\"https://meta.stackoverflow.com/questions/422392/chatgpt-seems-to-be-better-than-stack-overflow-both-in-speed-and-accuracy-what\">有开发者</a>\"说道。</p><p>&nbsp;</p><p>也有开发者表示，“我尝试通过参考 Stack Overflow 和 Reddit 这样的方式进行编程……是的，花了我几乎 10 倍的时间。ChatGPT 通过一个措辞良好的提示解决了我的问题！”</p><p>&nbsp;</p><p>尝到好处的开发者自然会选择用脚投票。不过，Stack Overflow 流量下跌其实算不上什么新鲜事儿。网络分析公司 <a href=\"https://www.similarweb.com/blog/insights/ai-news/stack-overflow-chatgpt/\">SimilarWeb</a>\" 在4月发布报告称，自 2022 年初以来，Stack Overflow 的流量每月都在下降，平均下降了 6%。Sametime Web 认为，Copilot 和 ChatGPT 是造成流量下降的原因之一。</p><p>&nbsp;</p><p>“Stack Overflow 的传统做法是，社区成员针对任何给定的编码问题发布各种答案，讨论优势和权衡，并投票选出最佳解决方案，”Similar Web 高级洞察经理 David Carr 表示，“ChatGPT 的用户错过了辩论环节，只得到了答案，这看起来更快、更高效。返回的答案可能并不完全是开发人员所需要的，但通常足够接近，可以被塑造和调整为可行的解决方案。”</p><p>&nbsp;</p><p>“Copilot 一直是基于开源做代码生成争议的中心，它不考虑相关的开源许可证，但这些问题也适用于 ChatGPT 提供的编码建议。此外，OpenAI 在编码技术方面积累的一些做法很可能来自于对 Stack Overflow 和类似网站上内容的消化。”</p><p>&nbsp;</p><p>6月份时候，Stack Overflow 也做过一项调查，结果显示，尽管开发人员不完全信任人工智能工具，但他们也已经准备好使用这些工具。显然，GitHub 的流量正在增长，而 Stack Overflow 正在萎缩。</p><p><img src=\"https://static001.geekbang.org/infoq/24/24a8b40a30304ffec9137b9193d5a457.png\" /></p><p></p><p>图源：SimilarWeb</p><p>&nbsp;</p><p>有网友注意到，Stack Overflow 似乎已经也在 Google 搜索结果占比中下降了，谷歌搜索的“所有热门结果都是人工智能生成的文章，其中包含与用户正在寻找的实际答案不相关的废话。”</p><p>&nbsp;</p><p>为此，有网友指出，随着越来越多的网站开始大力开展 SEO 以获得最佳结果，搜索引擎将会变得更糟。还有网友指出，不仅仅是人工智能。“在大流行期间，我和几位同事注意到，一些有效的答案被管理员在没有说明明显原因的情况下删除了。</p><p>&nbsp;</p><p></p><h2>真的是AI背全锅？</h2><p></p><p>&nbsp;</p><p>虽然说大模型给Stack Overflow 带来了很大的冲击，但 Stack Overflow 的衰落并不完全归咎于人工智能。</p><p>&nbsp;</p><p>“记得在 2013 年左右，我对响应式网页设计和 Twitter Bootstrap 着迷，便尝试学习前端开发。我在那个网站上问了一些问题，因为我的业余问题被嘲笑了几次，之后再也没有接触过这个网站，也没有学前端。这就是我与该网站的故事。”网友“pentagrama“说道。</p><p>&nbsp;</p><p>“我认为SO（Stack Overflow）的问题在于他们会鼓励mod关闭某些内容，所以他们会关闭所有能够关闭的内容。“matthieum”表示。</p><p>&nbsp;</p><p>网友 John Makin 表示，“我注意到Stack Overflow的一些问题，很难缩小范围，基本上如下：谷歌曾经返回与SO非常相关的结果，但它在一段时间前停止了这样做；SO的限制变得越来越可怕。我不知道有多少次遇到了确切的、奇怪的问题，我只是试图回答一个评论里的问题，然后一个mod积极地关闭它，因为不够‘主题‘或任何东西；由于前一个问题，通常最好的答案被隐藏在评论中，尽管准确回答了问题，但仍然有非常负面的反馈。</p><p>由于这些事情，屏蔽噪音变得越来越困难，通常搜索Github评论或随机的博客更容易找到我提出问题的答案。”</p><p>&nbsp;</p><p>还有开发者总结道，除了痛苦的mod地狱，停止回答问题主要是因为：</p><p>&nbsp;</p><p>写一个好的答案是需要时间的；快速复制粘贴答案通常是错误的，但无论如何都会有人支持;让提问的人从众多答案中挑选出可接受的答案，但他通常根本不知道怎么做！很多时候，问题没有答案是被接受的，就像问问题的人也不再在意。</p><p>&nbsp;</p><p>“我的SO账户差不多有12年了，只有2k多一点的点赞量，我不在乎。到目前为止，我仍然在帮助回答一些移动开发领域的基本问题，我唯一的不满是一些拥有巨大点赞量mod的敌意。有些人似乎从中得到了乐趣，但忘记了点赞不能转化为专业知识。12年来，他们一直没有弄明白这一点。新用户会问一个非常有价值的问题，然后不再回应。我每天都看到这一幕上演。在过去，即使是一个简单的基本问题，用户也会慷慨地给它点赞，但现在已经不是这样了。”“lawgimenez”说道。</p><p>&nbsp;</p><p>可以看出，Stack Overflow 自身社区运营也存在一些问题，无论用户还是内容管理，都被诟病已久。</p><p>&nbsp;</p><p></p><h2>打不过就加入？</h2><p></p><p>&nbsp;</p><p>“在 Stack Overflow，我们不得不坐下来问自己一些棘手的问题。当用户可以像向其他人一样轻松地向聊天机器人寻求帮助时，我们在软件社区中扮演什么角色？”CEO Prashanth Chandrasekar 也思考了这个问题。他给出的答案是“社区是人工智能的未来”。</p><p>&nbsp;</p><p>Chandrasekar 预测，程序员的工作远不会消失，最终将出现数百万新的软件开发人员。“我们热忱欢迎下一代开发人员和技术人员，为他们提供社区和解决方案，就像我们过去 15 年所做的那样。”</p><p>&nbsp;</p><p>为此，该公司正投入 10% 员工开发旗下 AI 工具，致力于将 GenAI 添加到 Stack Overflow 和 Stack Overflow for Teams 中。一个用例就是，“使用 Stack Overflow for Teams 将生成式人工智能技术融入到组织中，使用户能够在丰富的信息之上构建一个对话界面。”</p><p>&nbsp;</p><p>“社区和声誉也将继续是我们努力的核心。如果说人工智能模型之所以强大，是因为它们是在开源或公开可用的代码上进行训练的，那么我们希望制作模型来奖励做出贡献的用户，并保持我们所依赖知识库的开放和不断发展，确保我们仍然是未来新技术知识的首选。”Chandrasekar 说道。</p><p>&nbsp;</p><p>实际上，在大模型带来冲击的这段时间里，Stack Overflow 对人工智能的态度发生了很大的变化</p><p>&nbsp;</p><p>去年 12 月，Stack Overflow <a href=\"https://www.infoq.cn/article/7juf18dsyCRiqohyv0Bs\">暂时禁止用户</a>\"提交人工智能生成的内容，给出的理由是：从 ChatGPT 处获得正确答案的平均比率太低，发布由 ChatGPT 创建的答案对网站及询问或寻找正确答案的用户来说是非常有害的。</p><p>&nbsp;</p><p>但在 5 月，Stack Overflow 推翻了这一决定，新政策表示所有由 AI 生成的内容都可以在网站上发布，而且不得因为 AI 内容而对用户进行封禁。只有在真实可验证的情况下，版主们才能禁言账号。不管是写作风格等主观猜测，还是GPT检测器的结果，都不可作为衡量指标。作为回应，一些版主发起了<a href=\"https://openletter.mousetail.nl/\">罢工</a>\"，版主们表示，他们担心这样会导致错误信息泛滥，损害网站的质量和信誉。</p><p>&nbsp;</p><p>但目前，Stack Overflow 显然对于AI抱有了很大的希望。但这条路怎么走，我们只能拭目以待。</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://www.reddit.com/r/programming/comments/1592s82/the_fall_of_stack_overflow/\">https://www.reddit.com/r/programming/comments/1592s82/the_fall_of_stack_overflow/</a>\"</p><p><a href=\"https://observablehq.com/@ayhanfuat/the-fall-of-stack-overflow\">https://observablehq.com/@ayhanfuat/the-fall-of-stack-overflow</a>\"</p><p><a href=\"https://news.ycombinator.com/item?id=36855516\">https://news.ycombinator.com/item?id=36855516</a>\"</p><p><a href=\"https://www.theverge.com/2023/6/13/23759101/stack-overflow-developers-survey-ai-coding-tools-moderators-strike\">https://www.theverge.com/2023/6/13/23759101/stack-overflow-developers-survey-ai-coding-tools-moderators-strike</a>\"</p><p><a href=\"https://stackoverflow.blog/2023/04/17/community-is-the-future-of-ai/\">https://stackoverflow.blog/2023/04/17/community-is-the-future-of-ai/</a>\"</p>",
    "publish_time": "2023-08-03 14:27:59",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "GPU 容器虚拟化新能力发布和全场景实践",
    "url": "https://www.infoq.cn/article/Juvvj2VZVLAQmBaupixq",
    "summary": "<p>在《大模型时代的 AI 基础设施——百度 AI 大底座》系列云智公开课第二讲中，百度智能云的研发工程师王利明分享了关于百度智能云 GPU 容器虚拟化的最新进展和全场景实践。</p>\n<p>在本期公开课中，他介绍了去年发布的双引擎 GPU 容器虚拟化架构和今年推出的 2.0 版本。在实际的业务场景中，GPU 虚拟化可以应用于模型开发、模型训练和在线推理等各种场景。他介绍了在不同场景中使用用户态和内核态的不同技术特性和应用案例。针对云游戏场景，他提到使用内核态虚拟化来进行渲染显存的隔离，提高了 GPU 资源的使用效率。最后，他回答了关于 GPU 容器虚拟化在云游戏、多用户开发和自动驾驶仿真等领域的应用和挑战的问题，并分享了对未来发展的展望。</p>",
    "publish_time": "2023-08-03 14:30:16",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Kotlin 1.9.0 发布：带来多项新的语言特性，改进Multiplatform/Native支持",
    "url": "https://www.infoq.cn/article/yMbBLjvKRp5JUAIXhpa4",
    "summary": "<p>Kotlin的最新版本引入了许多新的语言特性，包括用于开放范围的…&lt;操作符、扩展正则表达式等。此外，它还改进了Kotlin Multiplatform和Kotlin/Native支持。</p><p></p><p>Kotlin 1.9稳定了与枚举类关联的entries 属性，它会返回所定义的枚举常量的所有值的列表。entries弃用了values()，它不再每次分配一个新数组，而是采用了预分配的值列表，提升了性能。</p><p></p><p>另一个小的语言特性是新引入了用于表示开放范围的…&lt;操作符。JetBrains表示，这个新语法可以让不包括上限的情况看起来更清晰。</p><p></p><p>在Kotlin 1.9中，正则表达式变得更加灵活，这要归功于一个新的函数group。该函数可以按名称检索正则表达式组。如下所示，可以用几个命名组定义正则表达式：</p><p></p><p><code lang=\"text\">val regex = \"\"\"\\b(?[A-Za-z\\s]+),\\s(?[A-Z]{2}):\\s(?[0-9]{3})\\b\"\"\".toRegex()\n</code></p><p></p><p>然后使用组名来访问匹配的值：</p><p></p><p><code lang=\"text\">val match = regex.find(input)!!\nprintln(match.groups[\"city\"]?.value)\n// Austin\nprintln(match.groups[\"state\"]?.value)\n// TX\nprintln(match.groups[\"areaCode\"]?.value)\n</code></p><p></p><p>Kotlin 1.9还改进了对Kotlin/Native和Kotlin Multiplatform的支持。</p><p></p><p>在Kotlin/Native中，现在可以预览自定义内存分配器了，其目的是提高Kotlin/Native内存管理器的运行时性能。自定义分配器将系统内存划分为多个页，并允许按顺序单独进行清理。使用编译器选项-Xallocator= Custom可以启用自定义内存分配器。</p><p></p><p>Objective-C/Swift互操作性也得到了改善，这要归功于新引入的Objective-C/Swift对象释放策略。现在，对象释放会在适当的时候在主线程上进行，减少了内存泄漏的机会。</p><p></p><p>Kotlin 1.9的其他新特性还包括：可以为iOS模拟器测试配置独立的iOS模式；可以跨Kotlin JVM和Kotlin/Native对链接问题进行统一处理。特别是，当存在链接问题时，构建将不再失败。</p><p></p><p>再来看下Kotlin Multiform。它包括Gradle配置缓存预览，以及改进Android目标支持，为谷歌新开发的一个Gradle插件铺平了道路。</p><p></p><p>最后，关于Kotlin 1.9，值得一提的是，它包含面向JVM的新的K2编译器的Beta版本，旨在提供更好的性能，加快语言特性开发，并为多平台对象提供更好的架构。在Kotlin 2.0中，K2将成为稳定版本，并成为默认的编译器。</p><p></p><p>以下是Kotlin 1.9的详细变更信息全部官方声明。</p><p></p><p>Kotlin 1.9.0 版本现已发布，适用于 JVM 的 K2 编译器目前处于测试版阶段。 这个版本包含新的语言功能以及针对 Kotlin Multiplatform 和 Kotlin/Native 的改进。</p><p></p><p>以下是此版本的一些亮点：</p><p></p><p>新的 Kotlin K2 编译器更新枚举类值函数的稳定替换开放范围的稳定 ..&lt; 运算符通过名称获取正则表达式捕获组的新通用函数用于创建父目录的新路径实用函数Kotlin Multiplatform 中的 Gradle 配置缓存预览Kotlin Multiplatform 中对 Android 目标支持的更改Kotlin/Native 中自定义内存分配器的预览Kotlin/Native 中的库链接Kotlin/Wasm 中的大小相关优化</p><p></p><p>有关完整的更改列表，请参阅 Kotlin 1.9.0 最新变化或 GitHub 上的版本说明：</p><p></p><p>https://github.com/JetBrains/kotlin/releases/tag/v1.9.0</p><p></p><p></p><h2>适用于 JVM 的新 Kotlin K2 编译器进入测试版阶段</h2><p></p><p></p><p>JetBrains 的 Kotlin 团队持续稳定新的 K2 编译器，我们很高兴地宣布，在我们迈向 Kotlin 2.0 版本的旅程中，适用于 JVM 的新 Kotlin K2 编译器达到了测试版里程碑。 编译器已经过彻底测试，成功编译了 Kotlin 团队用于质量保证的大量项目。</p><p></p><p>K2 编译器旨在带来重大性能改进，加快新语言功能的开发，统一 Kotlin 支持的所有平台，并为多平台项目提供更好的架构。</p><p></p><p>我们在促进与其他流行编译器插件的兼容性方面取得了巨大进步。 对 Kotlin Symbol Processing (KSP) 和 Jetpack Compose 的支持即将推出，预计很快集成 K2 支持。 我们邀请您在 Kotlin/JVM 项目上测试 K2，并在我们的问题跟踪器中分享您的宝贵反馈。 您的意见将帮助我们完善 K2，使其在 Kotlin 2.0 中成为默认的稳定编译器。</p><p></p><p>我们的目标还不止于此。 我们希望通过 K2 编译器实现同样高质量的多平台支持。 这一愿景与我们在 Kotlin Multiplatform 稳定性方面的持续努力相符合。 我们的目标是在 Kotlin Multiplatform 稳定版本发布的同时，在 K2 中实现对多平台项目的完全测试版品质支持。</p><p></p><p>我们热切期待您的反馈，同时，我们也将在这段精彩的开发旅程中继续前进。 Kotlin 2.0 的未来将由我们共同塑造。</p><p></p><p>有关如何启用 K2 编译器的更多信息，请参阅在项目中试用 K2 编译器。</p><p></p><p></p><h2>如何安装 Kotlin 1.9.0</h2><p></p><p></p><p>如果您已经在使用 IntelliJ IDEA 2022.3.3 或 2023.1.1，IDE 会自动建议将 Kotlin 更新到 1.9.0。 您也可以按照这些说明手动更新：</p><p></p><p>https://kotlinlang.org/docs/releases.html#update-to-a-new-release</p><p></p><p>IntelliJ IDEA 2023.2 将内置 Kotlin 1.9.0 插件。</p><p></p><p>对于 Android Studio Giraffe (223) 和 Hedgehog (231)，Kotlin 1.9.0 插件将随即将推出的 Android Studio 更新一起提供。 如果需要命令行编译器，请从 GitHub 版本页面下载：</p><p></p><p>https://github.com/JetBrains/kotlin/releases/tag/v1.9.0</p><p></p><p></p><h2>更多文章和视频</h2><p></p><p></p><p>“Kotlin 1.9.0 最新变化”文档：</p><p>https://kotlinlang.org/docs/whatsnew19.html</p><p></p><p>Kotlin 1.9.0 最新变化 YouTube 视频</p><p>https://youtu.be/fvwTZc-dxsM</p><p></p><p>K2 编译器将在 Kotlin 2.0 中进入稳定状态</p><p>https://blog.jetbrains.com/zh-hans/kotlin/2023/02/k2-kotlin-2-0/</p><p></p><p>Kotlin EAP Champion</p><p>https://blog.jetbrains.com/kotlin/2022/11/eap-champions/</p><p></p><p></p><h5>相关阅读：</h5><p></p><p></p><p><a href=\"https://xie.infoq.cn/article/942bb329c38cd72544c860f41\">浅谈 Kotlin 编程 01. 初识 Kotlin 和入门示例</a>\"</p><p><a href=\"https://xie.infoq.cn/article/ba7cceea4b506026b9cb0d42f\">从 HelloWorld 看 Java 与 Kotlin</a>\"</p><p><a href=\"https://www.infoq.cn/article/aTY2ysTOjaEwUv9Hzls6\">Meta 将百万行代码从 Java 移植到 Kotlin</a>\"</p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MzAxODcyNjEzNQ==&amp;mid=2247571124&amp;idx=1&amp;sn=93bb6d6dc0678677eb89f03fbc256824&amp;chksm=9bd27b2caca5f23a436467fe7b5f6c3809a9bba3d7ccd4091bc2c70ac714814e7092709758a5&amp;scene=27#wechat_redirect\">又一巨头从 Java 迁移到 Kotlin ！</a>\"</p>",
    "publish_time": "2023-08-03 14:37:20",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "都在追“新潮”技术，但你有大厂们的动作快吗？",
    "url": "https://www.infoq.cn/article/oA8TAAjl4YoSl9yGlR2I",
    "summary": "<p>曾经，触屏技术几乎将诺基亚淘汰出手机市场，如今的 AIGC 撼动了谷歌多年的搜索龙头地位地位。就像 API7.ai 联合创始人 &amp; CEO 温铭曾说的，“真正的挑战可能不是来自技术，而是其他完全不同的产品将传统的这些厂商挤出市场。”</p><p>&nbsp;</p><p>每年，Gartner&nbsp;都会做战略科技的预测，入围的都是当下最流行的技术，也是让各种规模企业、创业者纷纷趋之若鹜的领域。但能改变当下竞争格局的技术并不多。比如2017年入榜的区块链，到2021时候已经少有人提起；元宇宙也出现了一次后就迅速退出大家视野。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/35/35fdc9dfc8253c957f64f6b44b38a4d0.jpeg\" /></p><p>Gartner近五年战略科技预测，by InfoQ</p><p>&nbsp;</p><p>但人们还是不会放弃追逐每次新出来的技术热点，因为毕竟有 AIGC、云计算这样的例外。大厂们亦是如此。</p><p></p><h4>腾讯云，“卷向”向量数据库</h4><p></p><p>&nbsp;</p><p>大模型的爆火带红了向量数据库。向量数据库专门用于存储和查询向量数据，业界称之为大模型的“海马体”。</p><p>&nbsp;</p><p>市场方面，根据<a href=\"https://pdf.dfcfw.com/pdf/H3_AP202305091586392505_1.pdf?1683626830000.pdf\">华福证券</a>\"推测，到2025年，向量数据库将约占非结构化数据处理需求的三成，同时数据向量化后相比传统非结构化数据存储有较大膨胀，因此其价格将会数倍于传统的非关系型数据库产品。</p><p>&nbsp;</p><p>此前，向量数据库赛道仍是创业公司为主。但如今已有不少企业入局，腾讯便是其中之一。</p><p>&nbsp;</p><p>7 月 4 日，腾讯云正式发布 AI 原生向量数据库 Tencent Cloud VectorDB。据介绍，该数据库最高支持 10 亿级向量检索规模，延迟控制在毫秒级，具备百万级每秒查询（QPS）的峰值能力，能够被广泛应用于大模型的训练、推理和知识库补充等场景。</p><p>&nbsp;</p><p>据悉，腾讯云向量数据库提供了接入层、计算层、存储层的AI 化解决方案，企业原先接入一个大模型需要一个月左右时间，现在可以用三天左右的时间完成。腾讯云向量数据库目前也已经在腾讯视频、QQ 浏览器、QQ 音乐等 30 多款国民级产品中应用。官方数据显示，使用腾讯云向量数据库后，QQ 音乐人均听歌时长提升 3.2%、腾讯视频有效曝光人均时长提升 1.74%、QQ 浏览器成本降低 37.9%。</p><p>&nbsp;</p><p>有统计显示，将腾讯云向量数据库用于大模型预训练数据的分类、去重和清洗相比传统方式可以实现10倍效率的提升，如果将向量数据库作为外部知识库用于模型推理，则可以将成本降低2-4个数量级。</p><p>&nbsp;</p><p>那么，腾讯是如何快速打造出这款向量数据库的呢？</p><p>&nbsp;</p><p>负责向量数据库研发的腾讯云NoSQL数据库团队向InfoQ表示，他们前后用了两个多月完成了全自研，“走了不少弯路，也踩过很多坑，但最终还是遇见了星辰大海。”期间的更多精彩故事，可以查看<a href=\"https://sourl.co/wbychZ\">《中国卓越技术团队访谈录》（2023年第二季）</a>\"。</p><p></p><h4>网易伏羲，做个100%国产的大模型</h4><p></p><p>&nbsp;</p><p>2022 年，AI 绘画实火。输入三四个形容词，点击“生成”，然后人们就得到了相关的图片。这像不像你给魔术师一张纸，最后他给你“变出”了一张百元大钞？英国科幻小说家Arthur C. Clarke曾说过，任何足够先进的技术都等同于魔术。而在AI 绘画这场“魔术表演”中，大模型就扮演着魔术师的角色。</p><p>&nbsp;</p><p>AI 绘画是AIGC重要的应用分支。网易伏羲是从2018 年开始关注 AIGC 技术在产品中应用可能性的，直到今年的2023世界人工智能大会，联合推出了首届AI绘画体验，向更多人展示了自己多年的研发成果。对于这次展示，网易伏羲的丹青约提供了技术支持，背后依托于网易伏羲自研的文生图模型“丹青”。</p><p>&nbsp;</p><p>据悉，丹青是网易伏羲自研的中文模型，基于原生中文语料数据及网易自有高质量图片数据训练，为100%的国产大模型。该模型训练数据经过严格的文本及图片审核，在确保数据来源合规、生成内容合规的同时，使得模型拥有较好的中文理解能力，创作出的作品能更好满足中式审美。</p><p>&nbsp;</p><p>丹青约还充分结合了网易游戏美术设计的工作流，无论是生成图片的美观度，还是满足高质量要求的图片生产(如原画、美术资产等)，都做了深入的探索和研发。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ac/accf120e14d6331c3a3de2ab81d5809f.jpeg\" /></p><p></p><p>丹青模型生成的“天空之城”</p><p>&nbsp;</p><p>网易伏羲AI平台团队向 InfoQ表示，Stable Diffusion 在很大程度上仍是“黑盒”，如果在其基础上进行修改，对模型的优化和控制力是相对有限的。做文生图模型，如果只是简单的重复并无意义，需要走出自己的一条路子。那么，网易伏羲如何摸索出属于自己的路呢？更多精彩内容，可查看<a href=\"https://sourl.co/wbychZ\">《中国卓越技术团队访谈录》（2023年第二季）</a>\"。</p><p>&nbsp;</p><p></p><h4>阿里云，做好“提高效能”这件事</h4><p></p><p>&nbsp;</p><p>讲了AIGC的大厂故事，我们再看看云计算的。</p><p>&nbsp;</p><p>作为小型券商，德邦证券面临来自外部市场竞争和内部人员提效的双重压力。在德邦证券内部有多种内部运营系统工具，如OA系统、专属钉、工豹等，这些工具在某些情况下是不可替换的。为了深入结合DevOps，他们需要针对不同场景落地规范协作流程，如确定每个阶段的具体步骤和责任人、要做什么、何时做等问题。</p><p>&nbsp;</p><p>在竞争激烈的现代，高效、持续的交付能力是企业抢占市场先机的重要基础。在多数企业完成上云后，云原生研发效能平台成为越来越多企业和开发团队关注的重点。</p><p>&nbsp;</p><p>云原生研发效能平台建立在云计算基础之上，将现代开发工具、自动化流程和持续交付理念结合在一起。软件开发团队借此能够更加专注于业务创新和功能开发，而不是被繁琐的基础架构和运维工作所束缚。通过云原生研发效能平台，团队可以快速构建、部署和扩展应用程序，缩短产品上市时间，提升市场竞争力。不少企业收益于此，如Spotify、Airbnb、Pinterest等。</p><p>&nbsp;</p><p>但国内能建立这样团队的企业并不多。</p><p>&nbsp;</p><p>构建和维护一个完善的云原生研发效能平台需要深厚的技术功底和专业知识。涉及到多种技术栈和开发工具的集成，以及复杂的自动化流程和持续交付机制。这对于许多企业来说是一个巨大的挑战。同时，企业需要大量的资源投入，包括技术团队、硬件设施、云计算资源等。对于一些中小型企业来说，这样的成本可能难以承担。采购成熟的商业产品成了大多企业的选择，德邦证券也是如此。</p><p>&nbsp;</p><p>帮助德邦证券解决难题的阿里云云效团队告诉 InfoQ，这一赛道的工程师往往都带着一些“客服色彩”，“让后端的人，干前端的事，这对团队心性、企业文化是个考验。”那么，阿里云云效团队是如何组建起来的？又是如何随着需求变化而调整策略的？更多精彩内容，可查看<a href=\"https://sourl.co/wbychZ\">《中国卓越技术团队访谈录》（2023年第二季）</a>\"。&nbsp;</p><p></p><h4>QQ的一次重构</h4><p></p><p>&nbsp;</p><p>前端，是非常热闹的一个领域。新的前端框架、库、工具和技术不断涌现，社区里的开发者们积极探讨，共享代码和经验。而前端的技术选型则是备受关注的一点。</p><p>&nbsp;</p><p>今年4月底，新版 Windows QQ 正式公测，采用全新 QQ NT 架构，并带来了全新交互界面。至此，QQ 最大的无法跨平台的问题得到了解决。在此之前，Windows QQ 最早用的是 MFC，后来用了 DirectUI、WPF 等，Linux 和 Mac 端则必须使用其他技术，比如 Qt。这三个平台的更新迭代节奏也完全不同。</p><p>&nbsp;</p><p>但引发大家广泛讨论的是，这次重构中，QQ 开发团队使用了 Electron 作为新版 QQ 桌面端 UI 跨平台解决方案。</p><p>&nbsp;</p><p>Electron 是由 GitHub 开发的开源框架，使用Web技术（HTML、CSS和JavaScript）开发，Web开发者可以轻松转向桌面应用程序开发，并复用现有的Web技能和代码。社区也有许多开源插件和工具。但是，Electron性能消耗比较大，在处理大规模数据和复杂动画时可能表现不如原生应用。</p><p>&nbsp;</p><p>那么，QQ 是如何考虑这次重构的技术选型的呢？QQ 开发团队向InfoQ表示，“我们历史上踩过了很多很多非标准化的坑，一旦某个技术栈热度一过、维护力度不够，它就会成为全新的负债，做选型时必然也是避免再有类似经历。”更多选型细节和过程，查看<a href=\"https://sourl.co/wbychZ\">《中国卓越技术团队访谈录》（2023年第二季）</a>\"。&nbsp;</p><p></p><p></p>",
    "publish_time": "2023-08-03 14:46:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "阿里云通义千问开源！70亿参数模型上线魔搭社区，免费可商用",
    "url": "https://www.infoq.cn/article/JyR6k3JGacTcyTK3ffGS",
    "summary": "<p><a href=\"https://www.infoq.cn/article/MBhLRG3KXdBw3QSJL2gR\">通义千问</a>\"开源！8月3日，AI模型社区魔搭<a href=\"https://www.infoq.cn/article/NifbwmdGvISTtEyTTNT7\">ModelScope</a>\"上架两款开源模型Qwen-7B和Qwen-7B-Chat，阿里云确认其为通义千问70亿参数通用模型和对话模型，两款模型均开源、免费、可商用。在多个权威测评中，通义千问7B模型取得了远超国内外同等尺寸模型的效果，成为当下业界最强的中英文7B开源模型。</p><p>今年4月，阿里云推出自研大模型通义千问，引发井喷式的市场需求。此次小型化模型版本开源，有望抹平模型使用门槛，让海量中小企业和AI开发者更早、更快地用上通义千问。这一举动也让阿里云成为国内首个加入大模型开源行列的大型科技企业。</p><p></p><p>Qwen-7B是支持中、英等多种语言的基座模型，在超过2万亿token数据集上训练，上下文窗口长度达到8k。Qwen-7B-Chat是基于基座模型的中英文对话模型，已实现与人类认知对齐。开源代码支持对Qwen-7B和Qwen-7B-Chat的量化，支持用户在消费级显卡上部署和运行模型。</p><p></p><p>用户既可从魔搭社区直接下载模型，也可通过阿里云灵积平台访问和调用Qwen-7B和Qwen-7B-Chat，阿里云为用户提供包括模型训练、推理、部署、精调等在内的全方位服务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ce/cef833cab66ab7c9245e4cd042428b8b.png\" /></p><p></p><p>通义千问7B预训练模型在多个权威基准测评中表现出色，中英文能力远超国内外同等规模开源模型，部分能力甚至“跃级”赶超12B、13B尺寸开源模型。</p><p></p><p>在英文能力测评基准MMLU上，通义千问7B模型得分超过一众7B、12B、13B主流开源模型。该基准包含57个学科的英文题目，考验人文、社科、理工等领域的综合知识和问题解决能力。</p><p></p><p>在中文常识能力测评基准C-Eval上，通义千问在验证集和测试集中都是得分最高的7B开源模型，展现了扎实的中文能力。相比英文世界热闹的AI开源生态，中文社区缺少优秀的基座模型。通义千问的加入有望为开源社区提供更多选择，推动中国AI开源生态建设。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/44/44d425cae73e7efea394bcad7430bf79.png\" /></p><p></p><p>在数学解题能力评测GSM8K、代码能力评测HumanEval等基准上，通义千问7B模型也有不俗表现，胜过所有同等尺寸开源模型和和部分大尺寸开源模型。</p><p></p><p>阿里云表示，<a href=\"https://xie.infoq.cn/article/462125fa016e696d638206688\">开源大模型</a>\"可以帮助用户简化模型训练和部署的过程，用户不必从头训练模型，只需下载预训练好的模型并进行微调，就可快速构建高质量的模型。</p><p></p><p>开源生态对促进中国大模型的技术进步与应用落地至关重要。今年7月，阿里云宣布将促进中国大模型生态的繁荣作为首要目标，向大模型创业公司提供智能算力、开发工具等全方位服务。2022年阿里云牵头发起AI模型社区魔搭，以AI模型为核心服务AI开发者。目前，魔搭聚集了20多家顶尖人工智能机构贡献的1000多款开源模型，已经成为中国大模型开源第一门户。</p><p>&nbsp;</p><p></p><h2>附：开源地址</h2><p></p><p></p><p>魔搭ModelScope：</p><p>https://modelscope.cn/models/qwen/Qwen-7B/summary</p><p>https://modelscope.cn/models/qwen/Qwen-7B-Chat/summary</p><p></p><p>Hugging Face：</p><p>https://huggingface.co/Qwen</p><p></p><p>GitHub：</p><p>https://github.com/QwenLM/Qwen-7B</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-08-03 15:03:16",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "字节跳动火山引擎云原生研发负责人邓德源，确认担任QCon北京云原生专题出品人",
    "url": "https://www.infoq.cn/article/j9e8dQQ94gtaYWTfCEoT",
    "summary": "<p>9 月 3 日 - 5 日，在<a href=\"https://qcon.infoq.cn/202309/beijing?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=0803&amp;utm_content=dengdeyuan\"> QCon 全球软件开发大会（北京站）</a>\"，字节跳动火山引擎云原生研发负责人邓德源将担任「云原生」的专题出品人。在此次专题中，你将了解到云原生下一步的发展方向和一些有趣的实践案例。</p><p></p><p>邓德源，现任字节跳动火山引擎云原生研发负责人，主要负责包括容器集群与运行时、服务观测与治理、持续交付、多云管理等领域的产品。毕业于美国卡耐基梅隆大学，曾为美国 Google 集群管理组核心成员，主要参与开发集群管控系统、自动化风险分析，系统容错与高可用架构设计等，并作为早期核心成员参与 Kubernetes 容器集群项目开源。2015 年回国创办才云科技，推动容器 / 云原生技术在国内的普及与落地，于 2020 年加入字节跳动。</p><p></p><p>相信邓德源的到来，可以帮助提升此专题的质量，让你通过一些实践案例，发现云原生未来发展的新视角。</p><p></p><p>除上述专题外，QCon 北京还将围绕<a href=\"https://qcon.infoq.cn/202309/beijing/track/1553?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">异构计算</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1554?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">向量数据库</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1556?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">FinOps&nbsp;落地</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1558?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">业务安全技术</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1557?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">从&nbsp;BI&nbsp;到&nbsp;BI+AI，新计算范式下的大数据平台</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1559?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">从&nbsp;MLOps&nbsp;到&nbsp;LLMOps</a>\" 等进行分享。</p><p></p><p>近 100 名讲师、近 30 个精彩专题、8 种交流活动，QCon 北京 2023，相约 9 月！现在购票，享 9 折特惠，立省 ¥880！咨询购票请联系 18514549229（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/33/33cbbbf20baa8b2a18db4f0681f159aa.jpeg\" /></p><p></p>",
    "publish_time": "2023-08-03 15:04:19",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]