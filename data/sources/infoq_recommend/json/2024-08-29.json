[
  {
    "title": "所有主流浏览器都支持新的JavaScript集合方法",
    "url": "https://www.infoq.cn/article/BXCwkECbShAAe1hGYwdj",
    "summary": "<p>随着Firefox 127的发布，现在所有主流浏览器引擎都全面支持新的<a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Set#Set_methods?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MjQ3MjQ3OTEsImZpbGVHVUlEIjoiZ08zb2RNWVlKWHNuT09xRCIsImlhdCI6MTcyNDcyNDQ5MSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTA2fQ.b5qKNZ2C82AbROURfTZxso_SxxHGVUN-AWDuyBPm2zk\">JavaScript集合方法</a>\"，包括intersection()、union()、difference()、symmetricDifference()、isSubsetOf()、isSupersetOf()和isDisjointFrom()。这意味着开发者们不再需要依赖polyfill来确保这些方法在不同环境中的兼容性。这些新加入的特性提供了一套便捷的内置工具来操作和比较集合，不仅简化了开发，还提升了程序的性能。</p><p></p><p>JavaScript中的Set与Array类似，但它可以确保集合中的每个元素都是唯一的。这种自动除重的特性使得Set成为创建唯一元素集合的理想选择。下面是一个简单的例子，展示了如何创建一个Set并向其添加元素：</p><p></p><p><code lang=\"javascript\">const users = new Set();\n\nconst alice = { id: 1, name: \"Alice\" };\n\nusers.add(alice);\n\nusers.forEach(user =&gt; { console.log(user) });</code></p><p></p><p>在检查元素是否存在时， Set通常比Array更加高效，这一特性使得它对于性能要求较高的应用程序来说非常有价值。</p><p></p><p>union()方法返回一个新Set，包含原始Set和给定Set中的元素。这个方法在合并集合时极为有用，同时确保结果集中不包含重复项：</p><p></p><p><code lang=\"javascript\">const set1 = new Set([\"Alice\", \"Bob\", \"Charlie\"]);\n\nconst set2 = new Set([\"Bob\", \"Charlie\", \"David\"]);\n\nconst unionSet = set1.union(set2);\n\nunionSet.forEach(name =&gt; {\n\n&nbsp; console.log(name); // 输出: Alice, Bob, Charlie, David\n\n});</code></p><p></p><p>intersection()方法返回一个新Set，只包含两个Set共有的元素。这个方法在识别两个集合共同元素时非常有用：</p><p></p><p><code lang=\"javascript\">const intersectionSet = set1.intersection(set2);\n\nintersectionSet.forEach(name =&gt; {\n\n&nbsp; console.log(name); // 输出: Bob, Charlie\n\n});</code></p><p></p><p>symmetricDifference()方法返回一个新Set，包含只在其中一个Set中出现的元素，不包含两个Set共有的元素。这个方法在识别两个集合各自的不同元素时非常有用：</p><p></p><p><code lang=\"javascript\">const symmetricDifferenceSet = set1.symmetricDifference(set2);\n\nsymmetricDifferenceSet.forEach(name =&gt; {\n\n&nbsp; console.log(name); // 输出: Alice, David\n\n});</code></p><p></p><p>difference()方法返回一个新Set，包含了原始Set中有而给定Set中没有的元素。这在需要从集合中排除某些元素时非常有用：</p><p></p><p><code lang=\"javascript\">const set1Only = set1.difference(set2);\n\nset1Only.forEach(name =&gt; {\n\n&nbsp; console.log(name); // 输出: Alice\n\n});</code></p><p></p><p>isSubsetOf()和isSupersetOf()方法根据两个Set之间的包含关系返回一个布尔值。isSubsetOf()方法检查一个Set的所有元素是否都包含在另一个Set中，而isSupersetOf()方法检查一个Set是否包含了另一个Set的所有元素。</p><p><code lang=\"javascript\">const subset = new Set([\"Alice\", \"Bob\"]);\n\nconst superset = new Set([\"Alice\", \"Bob\", \"Charlie\"]);\n\nif (subset.isSubsetOf(superset)) {\n\n&nbsp; console.log(\"subset is a subset of superset\"); // 这将被打印出来，因为subset的所有元素也都在superset中。\n\n} else {\n\n&nbsp; console.log(\"subset is not a subset of superset\");\n\n}\n\nif (superset.isSupersetOf(subset)) {\n\n&nbsp; console.log(\"superset is a superset of subset\"); // 这将被打印出来，因为subset中的所有元素也都在superset中。\n\n} else {\n\n&nbsp; console.log(\"superset is not a superset of subset\");\n\n}\n</code></p><p></p><p>isDisjointFrom()方法检查两个Set是否有共同元素：</p><p><code lang=\"javascript\">const set3 = new Set([\"Eve\", \"Frank\", \"Gina\"]);\n\nif (set1.isDisjointFrom(set2)) {\n  console.log(\"Set1 and Set2 are disjoint\"); // 这将被打印出来，因为集合set1和集合set2没有共同元素\n} else {\n  console.log(\"Set1 and Set2 are not disjoint\");\n}\n\nif (set1.isDisjointFrom(set3)) {\n  console.log(\"Set1 and Set3 are disjoint\");\n} else {\n  console.log(\"Set1 and Set3 are not disjoint\"); // 这将被打印出来，因为集合set1和集合set3有一个共同的元素“Charlie”</code></p><p>社区对这些新方法反响热烈。在<a href=\"https://www.reddit.com/r/javascript/comments/1dzqmj6/new_javascript_set_methods?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MjQ3MjQ3OTEsImZpbGVHVUlEIjoiZ08zb2RNWVlKWHNuT09xRCIsImlhdCI6MTcyNDcyNDQ5MSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTA2fQ.b5qKNZ2C82AbROURfTZxso_SxxHGVUN-AWDuyBPm2zk\">Reddit的一个讨论帖</a>\"中，用户peterlinddk表示：</p><p></p><p></p><blockquote>“太好了，我们终于可以用Set做更多的事情，不仅仅是‘重复项检测器’。我还希望有一种方法，允许对象在不必是完全相同的实例的情况下也能被认为是‘相等’的，有点像Java的.equals和.hashCode方法。”</blockquote><p></p><p></p><p>另一位用户Pelopida92对这些新方法在性能上带来的提升表示赞赏，并表示：</p><p></p><p></p><blockquote>“Set太棒了。我在一些处理大数据量的脚本中广泛使用了这些Set方法，因为它们不仅在性能上优于数组，使用起来也非常简便和直观。”</blockquote><p></p><p></p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2024/07/javascript-set-methods/\">https://www.infoq.com/news/2024/07/javascript-set-methods/</a>\"</p>",
    "publish_time": "2024-08-29 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AI技术如何深入各行各业？Intel AI Summit专场全栈落地实践分享丨AICon",
    "url": "https://www.infoq.cn/article/40q0yogaX2i13pOKQQar",
    "summary": "<p>在当今时代，人工智能技术正以前所未有的速度迅猛发展，企业落地人工智能应用已成为不可逆转的趋势。然而，这一过程中也伴随着诸多挑战和问题。如何助力企业加速人工智能的落地进程，如何最大限度地提升 IT 系统的资源利用率，以及如何有效增强计算效能，并便捷、稳定地部署应用 AI，都已成为整个行业关注的焦点。</p><p></p><p>8 月 18 日至 8 月 19 日，在上海举办的 AICon 2024 全球人工智能开发与应用大会上，诸多讨论都聚焦于这些问题。其中的 Intel AI Summit 「AI 全栈解决方案及行业实践」专场，来自英特尔及其合作伙伴的四位行业专家就 AI 应用落地的全栈解决方案，以及医疗领域的应用案例进行了深入探讨。</p><p></p><p></p><h2>激发 AI 潜能：xFT 助力算力解锁，最大化提升计算效能</h2><p></p><p></p><p>尽管“AI 赋能”具有巨大吸引力，但在资源有限的条件下，企业必须确保每一项投入都能获得最大化的效益，这对应用落地的成本和利用率提出了严格的要求。特别是在计算效能提升方面，需要硬件、软件、算法等多个层面的协同优化。高效的计算能力能够加速数据处理、模型训练和推理速度，使企业更迅速地做出明智决策，推出创新产品和服务。</p><p></p><p>为了解决算力对 AI 落地的限制，英特尔一直走在行业前列，力求为企业推出实用可靠的计算资源方案，通过技术优化最大化提升算力，推动大模型应用的落地，充分释放 AI 潜能。在本次会议上，英特尔数据中心和 AI 事业部首席工程师何普江带来了主题为《xFT 解锁至强算力，释放 AI 潜能》的演讲。</p><p></p><p>何普江认为，AI 的未来将由算力的突破来定义，而第五代英特尔®️&nbsp;至强®️&nbsp;可扩展处理器及其内置的英特尔®️&nbsp;AMX 技术正是这一突破的关键。英特尔®️ AMX 通过深度优化矩阵运算，为算力释放提供了坚实的硬件基础。</p><p></p><p>在演讲中，何普江分享了 xFT（xFasterTransformer）技术的设计理念：这是一个专为 AMX 优化的开源项目，不仅支持广泛的 AI 模型和数据类型，更通过软硬件的深度融合，显著加速了 AI 大模型推理。何普江也在分享中提到，与传统方法相比，目前通过 xFT 技术，可以在第五代处理器上面用 48 核跑出高达 1300 的 CRGPU 吞吐量，这一数字远超行业标准，在处理大规模数据集和复杂运算时表现出色。</p><p></p><p>在算法层面，何普江深入分享了 xFT 技术的多项创新，包括对 oneDNN 库的优化使用，以及针对不同 token size 优化的 Slim attention 机制。这些创新不仅提升了 xFT 技术的性能，也为 AI 社区提供了宝贵的实践经验。</p><p></p><p>探讨大模型与小模型的未来发展时，何普江指出，两者各有优势，将共同推动 AI 技术进步。他强调了多模态和 RAG 技术的重要性，并预测开源与闭源模型间差距将缩小。何普江还提到了 KV Cache 的关键作用，以及它对未来 AI 系统设计的影响。</p><p></p><p>他认为，随着硬件和软件的不断进步，大语言模型的成本将大幅降低，推动 AI 技术的更广泛应用和深入发展。开源与闭源模型间的差距正在缩小，未来开源模型将在 AI 领域扮演更加重要的角色。</p><p></p><p></p><h2>GenAI 开放平台 OPEA：一站式助力大模型应用，企业 AI 落地加速器？</h2><p></p><p></p><p>除了底层算力效能提升之外，在目前企业的 AI 应用实践中，还存在着训推优化、基础设施扩展、数据传输安全、应用碎片化等诸多环节。企业需要一个能够全栈助力落地 AI 应用的方案与平台，一站式解决生成式 AI 的落地问题，在性能优化、可扩展性、安全等角度为企业保驾护航。</p><p></p><p>在本次会议上，英特尔 AI 首席工程师吴震华围绕 OPEA 开放平台进行了分享。作为人工智能建模、特征工程、效果分析以及推荐增强等领域的资深专家，他在演讲《基于检索增强的企业 GenAI 开放平台落地实践》中详细梳理了 AI 技术的发展历程，并深入解析了英特尔企业 GenAI 开放平台（OPEA）的架构与底层技术。</p><p></p><p>吴震华认为，尽管基于检索增强的 RAG 技术并非新生事物，但其在企业中的应用潜力正随着大语言模型的能力而日益凸显。在吴震华看来，企业 AI 落地面临的挑战与机遇并存，特别是在生成式 AI 技术，如 ChatGPT 引爆市场之后，行业关注的焦点已从模型预训练的竞争转向了具体的应用落地。</p><p></p><p>OPEA 开放平台是一个由英特尔推动、捐赠给 Linux 基金会的开源项目。OPEA 旨在构建一个开放的生态系统，使企业能够快速利用大语言模型和 AI 技术带来的创新优势。吴震华详细介绍了 OPEA 的全栈架构，从基础设施层到平台集成层，再到面向用户的服务层，展示了一个多层次、模块化的 AI 应用平台。</p><p></p><p>展望未来，吴震华预计到 2028 年，80% 以上的商用 PC 将被新形态的 AIPC 所替代。他将企业 AI 应用的发展分为三个阶段：今天，AI 助手如 CO-Pilot 和 RAG 正在提升数据检索和编程流程的效率；明天，智能体将拥有更大的自主权，利用 AI 的推理能力完成特定任务；未来，AI 将深入企业流程的每个环节，优化每个生产要素。</p><p></p><p>吴震华还提出了企业 AI 应用的四个关键方向：易用性、开放性、安全性、负责任的使用，以及平台的可扩展性和参考实践的提供。他希望通过这些方向的努力，使企业 AI 快速享受到生成式 AI 革命的技术成果。</p><p></p><p>在演讲的最后，吴震华通过一个应用 demo 展示了低代码的基于至强®️&nbsp;微服务实现生成 AI 服务功能，他期待通过不断的迭代和更新，OPEA 能够推动企业 AI 方案的发展，方便快速地帮助企业用户解决实际的问题，让企业真正享受到生成式 AI 技术带来的红利。</p><p></p><p></p><h2>AI+ 医疗：大模型在病历质控中的应用实践</h2><p></p><p></p><p>生成式 AI、大模型技术正在为各行各业带来革命性的变化，医疗领域也不例外。在医院、健康机构等场景下，AI 辅助诊疗、病历质控等应用将成为未来技术趋势。惠每科技致力于通过人工智能解决方案提升医疗质量，守卫患者安全，在智能化诊疗、病历质控等技术领域不断创新大模型技术应用，推动医疗行业的数智化发展。在 Intel AI Summit 专场上，惠每科技算法专家凌鸿顺以《破解病历质控难题：医疗大模型质控优化策略》为主题，分享了惠每科技在病历质控领域的成功实践。</p><p></p><p>病历质控作为医疗质量评估的核心，直接影响医疗服务水平和患者安全。面对病历书写的及时性、规范性和完整性问题，惠每科技采用了大模型技术，利用其强大的文本理解和知识推理能力，有效提升了病历质控的效率和准确性。大模型基于 Transformer 架构，通过持续预训练和任务对齐，以及直接偏好优化，显著提高了对病历中关键信息的提取和分析能力。</p><p></p><p>凌鸿顺还提到，在模型训练优化方面，惠每科技采取了基座模型优化和大模型 prompt 工程优化的策略。通过知识注入、指令跟随和直接偏好学习，模型能够更好地理解和执行医疗领域特定的任务。特别是在处理病历中的矛盾和不规范问题时，大模型展现了其跨字段理解和医疗知识对比的优势。</p><p></p><p>惠每科技还制定了自动化 Few-shot 示例的方案，通过初始化阶段的 badcase 识别和迭代优化，以及相似度计算和多样性 prompt 的加入，进一步提升了模型的预测效果和泛化能力。这一策略不仅减轻了筛选 Few-shot prompt 的工作量，也为不同医院的特殊 case 提供了快速修复的可能。</p><p></p><p>凌鸿顺还提到，在大模型部署推理的实践中，惠每科技与英特尔的合作成果显著。通过xFasterTransformer、BigDL 量化方案和&nbsp;OpenVINO™️&nbsp;非量化方案，实现了医疗模型私有化部署的优化，解决了大模型在硬件资源和计算效率上的挑战。特别是英特尔®️&nbsp;AMX 技术的应用，为大模型的推理性能带来了质的飞跃。</p><p></p><p>展望未来，凌鸿顺对医疗大模型的应用持乐观态度。模型蒸馏技术有望将大模型的效果转移到更小、更易于部署的模型上。自动化 Few-shot 的进一步优化，将实现更高效、更准确的病历质控。同时，惠每科技也将与英特尔展开持续合作，进一步推动医疗 AI 技术的创新和应用，为医疗行业带来更多的价值和可能性。</p><p></p><p></p><h2>医疗 AI 革新：大模型技术深度融合与应用实践</h2><p></p><p></p><p>人工智能技术的发展对医疗行业的信息化升级和数智化变革具有重大意义。以国内医疗场景为例，大量专业化数据和对信息化处理的精准度要求极高，这些都是信息化过程中需要解决的实际问题。垂直领域的大语言模型将成为新一代医疗信息化系统的有力助手，帮助解决医疗系统中的诸多问题。然而，如何让医疗大模型真正可用、易用，仍需解决模型构建、集成、系统结合和应用设计的一系列问题。</p><p></p><p>在 Intel AI Summit 专场上，卫宁健康研发总监刘鸣谦带来了题为《大语言模型在医疗场景的落地实践》的分享，深入探讨了大模型技术如何深刻影响医疗信息化的发展和临床应用。</p><p></p><p>刘鸣谦首先回顾了医疗系统的发展历程，从早期的专家系统、本体推理到现代基于 AI 的图像辅助诊断和自然语言处理。她认为，自 OpenAI GPT3.5 发布以来，基于 Transformer 的大模型已成为医疗领域开发和应用的新范式。大模型的文本生成能力、推理能力和交互能力，为医疗领域带来了前所未有的创新潜力。</p><p></p><p>在数据工程方面，刘鸣谦分享了卫宁健康如何通过高质量的数据集和场景化处理来优化大模型的训练效果。通过上下文学习、RAG（Retrieval-Augmented Generation）和 Agent 方式，进一步提升了模型的效果和适应性。此外，通过直接偏好优化（DPO）和提示工程，模型在医疗场景中的适用性得到了显著提升。</p><p></p><p>卫宁健康的大模型训练采用了多轮迭代，结合了开源数据和自身积累的医疗知识，形成了强大的模型能力。刘鸣谦提到，卫宁健康开源了多款垂直领域大模型，以促进社区的交流和发展，并与英特尔合作，优化了基于英特尔®️&nbsp;AMX 技术的本地化部署方案，有效降低了成本同时保证了高性能。</p><p></p><p>卫宁团队开发的 Copilot，作为信息化系统和 AI 模型之间的桥梁，通过 API 插件等多种形式，实现了不同应用场景下的模型管理和服务。Copilot 的应用，使得医务人员能够无缝地体验到 AI 带来的便利。</p><p></p><p>在医疗应用场景方面，刘鸣谦详细介绍了大模型在医技、临床和管理场景下的实际应用案例。例如，在影像科中，大模型辅助医生快速生成报告，提高了工作效率；在超声科中，实现了实时报告质控，提升了医疗质量；在临床辅助诊断中，通过增强型 CDSS 系统，提供了更加精准的辅助决策支持。</p><p></p><p>此外，大模型还在病历文书助手和智能语言查房助手中发挥了重要作用，通过语音识别和自然语言处理技术，实现了医生口述内容的自动结构化输出，极大地提高了医生的工作效率。</p><p></p><p></p><h2>AI 企业落地，从概念走向现实</h2><p></p><p></p><p>随着人工智能技术的不断成熟和创新，其在企业中的应用已不再是遥远的梦想，而是触手可及的现实。英特尔 AI 全栈解决方案的提出和实践，为企业智能化转型提供了一个清晰的路径：从底层硬件的优化到顶层应用的创新，从单一技术的突破到全栈生态的构建，每一步需要关注企业实实在在的效益，才能让 AI 发挥出真正的价值。</p><p></p><p>未来，随着技术的进一步发展和应用的不断深入，AI 必将成为推动企业创新和增长的关键力量，开启一个全新的智能化时代。让我们拭目以待，共同见证 AI 技术如何助力企业实现跨越式发展，引领行业变革。</p>",
    "publish_time": "2024-08-29 11:16:31",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "NVIDIA H20与计算领域的革命：深入解析算力评估与应用",
    "url": "https://www.infoq.cn/article/fVwFv0bBwCKAN5tm1Cc6",
    "summary": "<p></p><blockquote>在当今快速发展的科技时代，计算能力的重要性毋庸置疑。无论是在人工智能、深度学习还是高性能计算领域，算力的强弱决定了创新的速度与效果。作为NVIDIA最新推出的顶级显卡，H20以其强大的硬件配置和卓越的实际表现，吸引了众多关注。本文将深入探讨算力的概念、评估方法，以及在现代计算任务中的应用，特别是如何利用NVIDIA H20显卡来最大化算力优势。我们将结合理论与实际数据，全面分析H20的独特价值与未来发展方向。</blockquote><p></p><p></p><p></p><h1>算力的概念与历史演进</h1><p></p><p>1.1 算力的定义与基本概念</p><p></p><p>算力，或计算能力，是指计算设备在单位时间内所能完成的计算量。通常情况下，算力以每秒浮点运算次数（FLOPS）来衡量，这是浮点运算能力的标准单位。FLOPS代表每秒能进行的浮点数运算的次数，因此FLOPS越高，设备的计算能力越强。</p><p></p><p>在实际应用中，计算任务的种类繁多，从科学计算到深度学习模型训练，从金融数据分析到自动驾驶系统，各类任务对算力的需求各不相同。计算能力不仅仅是一个硬件性能指标，更是决定技术可行性和应用效果的重要因素。随着科技的进步，计算任务变得越来越复杂，数据量也在不断增加，因此对高算力的需求变得日益迫切。</p><p></p><p>1.2算力的发展历程</p><p></p><p>计算能力的发展可以追溯到计算机的早期历史。从最初的机械计算机到电子计算机，再到现代的超级计算机，计算能力的提升伴随着硬件技术的飞跃。早期的计算设备如ENIAC，每秒只能完成几千次简单的加法运算，而今天的超级计算机每秒可以完成数千万亿次浮点运算。</p><p></p><p>随着时间的推移，计算设备从单一处理器发展到多核处理器，再到并行计算和分布式计算。尤其是在图形处理单元（GPU）领域，NVIDIA等公司通过不断优化硬件架构，显著提升了计算能力。现代GPU如H20显卡，不仅在图形处理上表现优异，在并行计算、深度学习和科学模拟等领域也展现了强大的算力。</p><p></p><p>1.3 计算能力的重要性</p><p></p><p>计算能力是现代科技发展的基础。从物理模拟到分子建模，从图像识别到自然语言处理，强大的计算能力使得这些复杂任务得以实现。特别是在人工智能领域，深度学习模型的训练依赖于海量的数据和复杂的计算，因此对算力的要求极高。</p><p></p><p>在金融领域，高速交易系统依赖于实时的数据分析和决策，这些操作需要在微秒级别内完成，因此需要极高的计算能力。同样，在自动驾驶领域，车辆需要在短时间内处理来自多个传感器的数据，并做出驾驶决策，这也需要强大的算力支持。可以说，算力不仅是硬件性能的体现，更是推动科技进步的重要引擎。</p><p></p><p></p><h1>算力的评估与衡量方法</h1><p></p><p></p><p>2.1 评估算力的标准与方法</p><p></p><p>评估算力涉及多个方面，包括理论计算能力、实际执行效率和任务特定的表现。以下是几种常用的评估标准：</p><p></p><p>#1.&nbsp;FLOPS（每秒浮点运算次数）</p><p></p><p>FLOPS是评估计算能力的最直接指标，它表示硬件在一秒钟内能够完成的浮点运算次数。计算能力越高，硬件处理数据和执行任务的速度就越快。FLOPS通常分为单精度（FP32）、双精度（FP64）和混合精度（FP16、BFLOAT16等）不同类型，根据任务的不同，使用的精度类型也会不同。</p><p></p><p>#2.&nbsp;带宽（Bandwidth）</p><p>带宽指的是在单位时间内能够传输的数据量。内存带宽是决定计算设备性能的关键因素之一，尤其是在需要处理大量数据的任务中。高带宽可以有效减少数据传输的瓶颈，从而提高整体计算效率。在GPU计算中，带宽不仅影响数据加载的速度，也直接影响到模型训练的速度。</p><p></p><p>#3.&nbsp;延迟（Latency）</p><p>延迟是指从输入数据到获得输出结果所需要的时间。低延迟有助于减少数据传输和处理过程中的等待时间，特别是在并行计算中，减少延迟可以显著提高计算效率。延迟通常是并行计算系统的瓶颈，尤其是在大规模数据处理或多GPU协同工作时。</p><p></p><p>#4.&nbsp;能效比（Efficiency Ratio）</p><p>能效比是单位功耗下的计算能力。高能效比意味着在相同的功耗下，硬件能够提供更高的计算能力，这对于数据中心和高性能计算集群尤为重要。在实际应用中，能效比不仅影响计算成本，还影响系统的冷却和维护需求。</p><p></p><p>2.2 模型训练和推理中的算力评估</p><p></p><p>在深度学习和机器学习中，算力的评估往往与具体的任务需求挂钩。以下是几种常见的评估标准：</p><p></p><p>#1.&nbsp;训练速度（Training Speed）</p><p># 评估单位与计算方式 #</p><p>&nbsp;单位&nbsp;：训练速度通常以每秒处理的样本数（Samples per Second, SPS）或每秒处理的tokens数（Tokens per Second, TPS）来衡量。&nbsp;计算方式&nbsp;：SPS和TPS的计算方式如下：</p><p>SPS = 处理的样本总数 / 训练时间（秒）</p><p>TPS = 处理的tokens总数 / 训练时间（秒）</p><p></p><p>在计算过程中，样本数指的是输入数据的批次（Batch Size），而tokens数通常用于自然语言处理（NLP）模型的训练，指的是输入文本被分割后的最小单位（如词语或子词）。</p><p></p><p>#&nbsp;重要性与实际应用&nbsp;#</p><p></p><p>训练速度是衡量计算设备在模型训练过程中效率的关键指标。更高的训练速度意味着模型可以在更短的时间内处理更多的数据，从而加速模型的整体训练进程。这对于处理大型数据集或复杂模型（如深度神经网络、卷积神经网络等）尤为重要。</p><p></p><p>在实际应用中，提升训练速度有助于：</p><p>缩短模型的开发周期。提高资源的利用率，减少计算成本。在相同时间内进行更多实验，从而优化模型效果。</p><p></p><p>特别是在深度学习领域，使用更大的批次处理数据可以显著提高SPS或TPS，而高效的硬件如NVIDIA H20显卡能够支持更大的批次大小和更快的数据处理，从而提升训练速度。</p><p></p><p>#2.&nbsp;模型收敛性（Convergence）</p><p># 评估单位与计算方式 #</p><p></p><p>&nbsp;单位&nbsp;：模型收敛性没有统一的度量单位，但通常以训练轮数（Epochs）、迭代次数（Iterations），或达到某个性能指标所需的时间来衡量。&nbsp;计算方式&nbsp;：</p><p>收敛速度 = 目标性能指标 / 训练时间（秒）</p><p>或者使用收敛的轮数来衡量，即训练到模型性能稳定为止所需的训练轮数或迭代次数。</p><p></p><p>例如，在一个深度学习任务中，收敛速度可以通过模型达到一定的准确率或损失函数值所需的时间来表示。更少的训练轮数或迭代次数意味着更快的收敛速度。</p><p></p><p>#&nbsp;重要性与实际应用&nbsp;#</p><p></p><p>收敛性是衡量模型在训练过程中逐步逼近最优解的能力。算力越强，通常收敛速度越快，因为高算力设备可以支持更大的批次大小、更复杂的优化算法和更快的数据处理速度。这对于研究和开发时间有限的项目至关重要，因为加快收敛速度可以更快地得到有效的模型。</p><p></p><p>在实际应用中，收敛性与以下因素密切相关：</p><p>优化算法：如Adam、SGD等优化算法的选择和调整，直接影响模型的收敛速度。批次大小：更大的批次大小通常会加快收敛速度，但需要足够的显存支持，这也是高算力设备的优势。学习率：调整学习率可以帮助模型更快地达到收敛状态，但需要精细的调试以避免过拟合或欠拟合。</p><p>使用像NVIDIA H20这样具备高算力和大显存的设备，可以在保证计算精度的同时，加快模型的收敛速度。</p><p></p><p>#3.&nbsp;推理速度（Inference Speed）</p><p># 评估单位与计算方式 #</p><p>&nbsp;单位&nbsp;：推理速度通常以每秒处理的样本数（Samples per Second, SPS）或每秒处理的tokens数（Tokens per Second, TPS）来衡量，类似于训练速度。&nbsp;计算方式&nbsp;：SPS和TPS的计算方式如下：</p><p></p><p>SPS = 处理的样本总数 / 推理时间（秒）</p><p>TPS = 处理的tokens总数 / 推理时间（秒）</p><p></p><p>推理速度评估的是模型在实际应用中的响应时间，特别是在实时或近实时的应用中（如自动驾驶、语音识别、在线推荐系统等）。</p><p></p><p>#&nbsp;重要性与实际应用&nbsp;#</p><p>推理速度是决定模型在生产环境中表现的关键指标之一。特别是在需要实时处理和响应的应用中，推理速度直接影响系统的用户体验和效能。</p><p>推理速度越快，系统的响应时间就越短，这对于以下场景尤为重要：</p><p></p><p>自动驾驶：车辆必须在极短时间内处理传感器数据并作出驾驶决策。实时翻译与语音识别：需要在用户发出命令后迅速给出响应。在线推荐系统：实时分析用户行为并推荐个性化内容。</p><p></p><p>NVIDIA H20显卡在推理任务中的表现尤为出色，特别是在FP8低精度计算中，能够在保持高效能的同时，提供极快的推理速度。</p><p></p><p>#4.&nbsp;精度与效率的平衡</p><p># 评估单位与计算方式 #</p><p>&nbsp;单位&nbsp;：精度通常以百分比（%）或数值（如损失值、准确率等）来表示；效率则以处理速度或能效比（FLOPS/Watt）来衡量。&nbsp;计算方式&nbsp;：</p><p></p><p>精度 = 模型在测试数据集上的性能指标（如准确率、F1分数等）</p><p>效率 = 计算资源消耗 / 达到目标性能所需的时间或能量。</p><p></p><p>在深度学习中，精度和效率往往需要进行权衡。例如，高精度计算通常需要更多的计算资源和时间，而低精度计算则可以在速度和资源占用上实现更高的效率。</p><p></p><p>#&nbsp;重要性与实际应用&nbsp;#</p><p></p><p>在实际应用中，精度与效率的平衡是设计和部署AI系统时必须考虑的重要因素。虽然追求更高的精度是许多AI任务的目标，但在某些场景下，高精度并不是唯一的考量。例如：</p><p>边缘计算设备：受限于计算资源和能耗，可能需要在精度和效率之间做出妥协。实时应用：如语音助手或实时翻译，更快的响应速度可能比绝对精度更重要。低成本部署：在大规模部署中，能够以更低的成本达到“足够好”的精度，可能比追求极限精度更具现实意义。</p><p></p><p>NVIDIA H20显卡提供了多种浮点运算模式（如FP16、FP8），允许开发者根据任务需求选择合适的精度和效率组合。例如，在训练阶段使用FP16混合精度可以提高训练速度，而在推理阶段使用FP8可以进一步优化性能，同时保持足够的预测精度。</p><p></p><p></p><h1>Part 3 NVIDIA H20显卡的深入解析</h1><p></p><p></p><p>3.1 H20显卡的硬件架构与技术创新</p><p></p><p>NVIDIA H20显卡基于最新的Hopper架构，在图形计算和并行计算领域引领了新一轮的技术革命。与前几代基于Ampere架构的显卡相比，H20在多个方面进行了大幅升级。尤其是在FP32、FP16以及新增的FP8精度计算能力上，H20展现了其在各种复杂计算任务中的卓越性能。</p><p></p><p>根据提供的图表，H20在FP32单精度浮点运算中达到了44 TFLOPS，这远高于基于Ampere架构的前代产品的19.5 TFLOPS。这一提升对于需要高精度计算的任务，如媒体处理、物理模拟等，具有重大意义。</p><p>在FP16和FP8的Tensor Core性能上，H20也大幅领先于前代产品。在FP16运算中，H20达到了148 TFLOPS，而在FP8的8bit浮点数据类型运算中，H20的性能更是达到了296 TFLOPS。这使得H20在处理需要大量并行计算的任务时，如深度学习模型的训练和推理，具备了极大的优势。</p><p></p><p>3.2 显存与带宽的优越性</p><p></p><p>H20显卡配备了96GB的HBM3显存，这是当前显存配置的顶级标准。这种显存不仅在容量上远超前代产品（80GB HBM2e），在内存带宽上也达到了惊人的4 TB/s，是前代产品带宽的近两倍。如此高的内存带宽使得H20显卡在处理大规模数据集和高分辨率任务时，能够更快地进行数据传输，减少处理延迟。</p><p>对于大模型训练和深度学习应用来说，显存的大小和带宽直接决定了硬件能否有效载入和处理训练数据。H20显卡凭借其96GB的显存，可以轻松应对需要大批量数据的任务，同时其4TB/s的带宽也确保了这些数据能够快速传输到GPU进行处理，这对于需要高效处理数据的任务如自动驾驶、图像识别等尤为重要。</p><p></p><p>3.3 H20的计算能力与实际表现</p><p></p><p>通过分析H20的计算能力图表，我们可以看到它在FP8、FP16等精度下的强劲表现。特别是在处理需要高效浮点运算的任务时，H20的Tensor Core能够提供前所未有的计算性能。例如，在8bit浮点数数据类型的FP8精度运算中，H20的性能达到了296 TFLOPS，适合用于量化训练和模型推理等场景。</p><p>NVLink互联带宽方面，H20也进行了显著的提升。相比前代产品的600GB/s和400GB/s，H20的NVLink带宽高达900GB/s。这意味着多个H20显卡在多卡互联时可以通过更高效的方式进行数据交换，减少了多GPU协同工作的延迟，从而提高了整体计算效率。</p><p></p><p>3.4 浮点运算模式的选择与H20的应用场景</p><p></p><p>在NVIDIA H20显卡中，不同的浮点运算模式为各种计算任务提供了灵活的选择。H20显卡支持从双精度（FP64）到最新的FP8低精度运算模式，覆盖了从高精度科学计算到高效推理任务的广泛应用需求。</p><p>双精度运算模式（FP64）：通常用于需要极高精度的科学和工程计算，如流体力学模拟、气候预测等领域。单精度运算模式（FP32）：是深度学习领域的主力，特别是在训练大型AI模型时，FP32能够提供足够的精度和较高的计算效率。半精度运算模式（FP16）：近年来在深度学习加速方面获得了广泛应用，尤其是在卷积神经网络（CNN）等任务中，FP16能够显著提高训练速度并减少显存占用。低精度运算模式（FP8和INT8）：随着量化技术的发展，FP8和INT8在推理任务中的应用越来越多，H20显卡的296 TFLOPS FP8算力使其在大规模模型推理中占据了显著优势。</p><p></p><p>3.5不同GPU型号的选择:SXM、PCIe、NVLink</p><p></p><p>为了满足不同用户的需求，NVIDIA为H20显卡提供了多种型号，包括SXM、PCIe和NVLink。这些型号的区别在于其硬件架构和连接方式，进而决定了它们在不同应用场景中的适用性。</p><p>SXM版：通过SXM模块设计，可以实现8块GPU的紧密互联，主要应用于高密度GPU服务器集群，如NVIDIA的DGX系统。这种设计不依赖传统的PCIe接口，而是通过NVSwitch实现更高的带宽和更低的延迟，特别适合用于超大规模AI训练和科学模拟任务。PCIe版：沿用了传统的PCIe接口，提供了更为灵活的部署方式。它支持与主板和CPU之间的直接通信，适用于传统的GPU服务器和通用计算任务。每两块GPU通过NVLink Bridge进行连接，虽然在带宽上不如SXM版，但在扩展性和兼容性上具有一定的优势。NVLink版：专为需要超高带宽的数据密集型任务设计。它提供了高达7.8 TB/s的传输带宽，适用于需要实时处理大量数据的大规模语言模型（LLM）训练任务。通过NVLink接口，多个H20显卡可以实现高速数据交换，减少计算过程中数据传输的瓶颈，提升整体计算效率。</p><p></p><p>通过结合这些不同型号的特点和应用场景，用户可以根据自己的具体需求选择最适合的GPU类型，从而在不同的计算任务中最大化地发挥H20显卡的性能优势。</p><p></p><h1>Part 4 H20在模型训练与推理中的实际应用</h1><p></p><p></p><p>4.1 通过Llama2模型探讨H20的应用</p><p></p><p>为了更好地理解H20显卡在实际应用中的表现，我们可以借助Llama2-70B模型的训练和推理数据来分析其性能。根据提供的图表，H20显卡在不同精度（FP8和FP16）以及不同输入输出长度下展现了卓越的计算能力。</p><p></p><p>在图表中，HGX H20模块在处理LLAMA2_70B模型时，在FP8精度下，输入长度为2048、输出长度为128的配置中，H20的吞吐量达到了1.2244595*A tokens/秒。而在输入长度为128、输出长度为2048的配置中，FP8精度下的吞吐量更是高达2.0981547*B tokens/秒。这表明在高精度和复杂模型的训练和推理任务中，H20显卡能够提供极为高效的计算性能。</p><p></p><p>相比之下，HGX A1XX模块在相同配置下，使用FP16精度的表现明显不如H20。这进一步证实了H20显卡在处理大规模语言模型时的优势。特别是在需要处理复杂输入输出关系的推理任务中，H20的高带宽和Tensor Core的强大性能，使其能够在更短的时间内完成推理，提供更高的吞吐量。</p><p></p><p>4.2 H20在推理任务中的独特优势</p><p></p><p>推理任务中，吞吐量和响应速度是两个关键指标。H20显卡凭借其FP8精度的计算能力，在处理LLAMA2_70B等大规模模型时，能够提供更高的tokens处理速度。结合前面的数据分析，H20在推理任务中的表现不仅仅体现在其计算能力上，还得益于其大容量的显存和超高的内存带宽，这些因素共同作用，使得H20能够在处理复杂推理任务时，保持高效和准确的性能输出。</p><p></p><p>通过NVLink的高带宽支持，多个H20显卡在多卡集群中可以实现高效的数据交换和协同计算，这对于需要实时处理和分析数据的任务来说，至关重要。例如，在自动驾驶系统中，H20显卡可以通过快速处理传感器数据并作出决策，从而提高系统的安全性和反应速度。</p><p></p><p>4.3 H20的GEMM性能分析</p><p></p><p>在矩阵乘法（GEMM）任务中，浮点运算性能是评估GPU计算能力的重要指标之一。以下是从表格中筛选出的伊迪雅H20在不同浮点精度下的GEMM性能数据，并对其进行详细分析。</p><p><img src=\"https://static001.geekbang.org/infoq/a3/a3e16713905cdb6c63c8cc433b76ba02.png\" /></p><p>分析与解读</p><p># FP8精度 #</p><p>峰值性能：293 TFLOPS实测性能：267.33 TFLOPS峰值百分比：91.25%</p><p></p><p>FP8精度下，伊迪雅H20的实测性能达到了267.33 TFLOPS，占峰值性能的91.25%。这一结果表明在低精度浮点运算中，伊迪雅H20的表现非常接近其理论最大值，表明其硬件设计在FP8运算任务中的效率极高，适合用于大规模模型推理和量化训练等场景。</p><p></p><p># INT8精度 #</p><p>峰值性能：293 TFLOPS实测性能：188.30 TFLOPS峰值百分比：64.27%</p><p></p><p>在INT8精度下，伊迪雅H20的实测性能为188.30 TFLOPS，占峰值性能的64.27%。虽然相对于FP8的表现有所下降，但INT8仍然提供了高效的计算能力。INT8精度广泛应用于需要处理大量数据的推理任务，尤其在资源受限的环境下，可以在降低计算复杂度的同时，保持合理的精度。</p><p></p><p># FP16精度 #</p><p>峰值性能：147 TFLOPS实测性能：141.55 TFLOPS峰值百分比：96.31%</p><p></p><p>在FP16精度下，伊迪雅H20几乎达到了其峰值性能，实测值为141.55 TFLOPS，占峰值的96.31%。这表明伊迪雅H20在FP16运算中能够充分发挥其硬件潜力，非常适合用于深度学习训练任务，特别是卷积神经网络（CNN）和递归神经网络（RNN）等对计算速度要求较高的模型。</p><p></p><p># TF32精度 #</p><p>峰值性能：74 TFLOPS实测性能：69.47 TFLOPS峰值百分比：93.88%</p><p></p><p>TF32是一种介于FP16和FP32之间的浮点精度模式，旨在提供比FP32更高的计算效率，同时保留一定的计算精度。在这一模式下，伊迪雅H20的实测性能为69.47 TFLOPS，占峰值性能的93.88%。这一表现说明TF32是一个平衡精度和效率的理想选择，特别是在要求较高的科学计算和AI模型训练中，能够显著提升计算速度。</p><p></p><p># FP32精度 #</p><p>峰值性能：40 TFLOPS实测性能：31.41 TFLOPS峰值百分比：78.53%</p><p></p><p>在FP32精度下，伊迪雅H20的实测性能为31.41 TFLOPS，占峰值性能的78.53%。虽然相对其他精度模式的效率稍低，但FP32依然是许多AI模型和科学计算任务的首选精度模式，特别是在需要高精度结果的场景中，FP32的稳定表现非常重要。</p><p></p><p>H20在不同精度下的GEMM性能分析，我们可以看到其在多种运算模式中的强大表现。无论是在高效推理任务中的FP8和INT8，还是在深度学习训练中的FP16和TF32，伊迪雅H20都能够提供接近其理论峰值的实际性能。这表明H20显卡不仅具备出色的硬件设计，还能在实际应用中充分发挥其计算能力，适合于从AI模型训练到大规模推理等广泛应用场景。</p><p></p><h1>Part 5 NVIDIA H20与H100的深入对比</h1><p></p><p></p><p>5.1 H100显卡的优势与应用场景</p><p></p><p>NVIDIA H100显卡是目前市场上最强大的GPU之一，其高达1979 TFLOP的理论计算能力，使得H100在处理高精度计算任务时具备无可比拟的优势。H100显卡的性能密度高达19.4，远超H20显卡的2.9，这使得H100在单位面积内能够提供更高的计算能力，特别适用于空间受限但需要高性能的计算环境。</p><p>在实际应用中，H100显卡主要应用于高精度科学计算、复杂AI模型训练和大规模数据分析等领域。对于那些需要极致性能的用户，H100显卡无疑是最佳选择。例如，在气候模拟、分子动力学和高精度物理模拟等任务中，H100显卡可以显著加快计算速度，减少模拟时间。</p><p></p><p>5.2 H20显卡的核心价值与独特优势</p><p></p><p>尽管H20显卡在理论计算能力上不如H100，但其在实际应用中的表现依然出色。特别是在大规模低精度模型训练和推理中，H20凭借其高显存、大带宽和较低的成本，展现了极高的性价比。对于那些需要处理大量数据且对计算精度要求不高的任务，如自然语言处理、推荐系统、图像识别等，H20显卡是一个非常具有竞争力的选择。</p><p></p><p>H20显卡的核心价值在于其出色的内存管理和高效的计算能力，特别是在FP8精度下，H20显卡能够以更少的节点数量完成训练任务，从而降低整体计算成本。这使得H20显卡在一些预算敏感的项目中，成为了性价比最高的解决方案。</p><p></p><h1>Part 6 H20在工业领域的广泛应用</h1><p></p><p></p><p>除了在AI研究中的广泛应用外，H20显卡在工业领域也展现了巨大的应用潜力。无论是在自动驾驶、智能制造，还是金融科技和医疗健康，H20显卡都能够通过其强大的计算能力，为各类复杂的计算任务提供解决方案。</p><p></p><p>在自动驾驶领域，H20显卡的高带宽和低延迟使得其能够实时处理来自多个传感器的数据，并做出驾驶决策。智能制造领域的复杂工艺模拟和优化，同样可以通过H20显卡的高算力得到加速。而在金融科技领域，H20显卡的快速数据处理能力可以显著提升高频交易系统的响应速度，降低市场风险。</p>",
    "publish_time": "2024-08-29 15:40:24",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "“懒”人请进—— 有洞察的 AI 帮你完成数据分析",
    "url": "https://www.infoq.cn/article/6oDad1wtR7tgRJSMIKas",
    "summary": "<p>【云上探索实验室】专为开发者设计，旨在创造最前沿技术的一站式实操体验。2.0 版本的云上探索实验室全面升级！我们将采用沉浸式直播与实验平台实操相结合的方式，带你沉浸式感受生成式 AI 时代的技术魅力。</p>\n<p>系列公开课直播第三期《“懒”人请进—— 有洞察的 AI 帮你完成数据分析》将带你实操演示如何使用 Amazon Q in QuickSight 来构建 BI 报表，以及利用 Amazon Q，通过自然语言的方式来快速创建报表视图，并且体验如何利用大语言模型来生成一个数据故事。</p>\n<p>戳 <a href=\"https://sourl.co/fpUE76\">https://sourl.co/fpUE76</a> 进入云上探索实验平台，边学边玩开启实验！</p>",
    "publish_time": "2024-08-29 16:14:09",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "你“渣”过 AI 吗？你的工作流程被 AI 颠覆了吗？",
    "url": "https://www.infoq.cn/article/fyegw1UWxr8J5xoZiLEw",
    "summary": "<p>导语：对 AI 的态度，就是不主动使用 AI，不主动学习提示词工程；各大厂商推广 AI 的时候，不拒绝听一听，也不拒绝用一用；对于使用 AI 生成的结果不负责，结果不好都是 AI 的问题，跟我无关。你是不是也这么想的？那么你的工作流程现在被 AI 颠覆了吗？</p><p></p><p></p><blockquote>在将于 2024 年 10 月 18-19 日举办的 QCon 全球软件开发大会（上海站），我们设置了【<a href=\"https://qcon.infoq.cn/2024/shanghai/track/1704\">AI 重塑技术工作流程</a>\"】这一专题，旨在探索那些超越单点 AI 应用，进一步利用 AI 技术重塑产品研发核心流程的最佳实践。我们关注实际案例和解决问题的策略，旨在解决当前研发团队面临的困境，让智能能真正赋能业务，创造价值。欲了解更多内容，可访问<a href=\"https://qcon.infoq.cn/2024/shanghai/\">大会官网</a>\"获悉。</blockquote><p></p><p></p><p>本文主要聚焦 AI 如何重塑技术工作流程，以及流程如何反过来塑造 AI 。我们将从单点 AI 应用转向全流程 AI 集成，并讨论这种转变带来的挑战和机遇。</p><p></p><h3>单点看 AI VS 流程看 AI</h3><p></p><p></p><p>说起技术工作流程，大家肯定想起诸如 DevOps 之类的。但我今天要讲的是另外一个场景， toB 业务的痛：工单。做 toB 业务的都知道，团队每天都要处理数百个客户工单，从简单的咨询到复杂的系统故障，有时还得承担客户的怒火，这真是一项耗时且常常令人沮丧的工作。然而处理好工单，一方面是对我们自己产品负责，另外一方面，这也是产品进化的机会。就因为这个痛太明显了，大家一看到生成式 AI 的能力之后，都迫不及待地去投入建设。比如：建立知识库，使用 RAG + LLM ，让处理工单的同学能快速检索知识库，去回答和解决问题。我们也一样，经历了 RAG 各种问题的折磨和不断调整后，我们也实现了类似的能力（如下图），但是观察一段时间后，我发现大家还是很痛苦，很忙。询问大家的使用体验，对工作有没有帮助？都说有点儿用吧。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/30/30235c866b97486d99071d02173a65c5.png\" /></p><p></p><p>后来，我跟同事们开始复盘这个事情，一起绘制了如下工作流程图。这才发现我们的 AI 仅仅只是用在了工单答疑上（下图中蓝色星星处）</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3d/3da4b054c2007835e9768d3db4ee83e8.png\" /></p><p></p><p>除此之外，还有哪些是 AI 可以发挥作用的呢？AI 是一个简单系统，它包含输入、处理、输出。于是，我们从\"输入输出\"开始，我们梳理了每个部分可能的输入输出（如下图）</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c2/c26201d2b18b5535f716d729aa25a0ac.png\" /></p><p></p><p></p><h3>AI 重塑工单工作流程</h3><p></p><p></p><p>然后有趣的事情就发生了，我们突然发现还有很多地方可以落地 &nbsp;AI ，除了用于指引工单处理和回答的 AI 工单回答助手，还可以有：</p><p></p><p>● AI 总结助手：用来把工单处理过程中产生的新知识自动总结提炼到知识库的 AI，这也同时解决了知识库的知识保持持续更新的问题，AI 总结助手可以帮助我们把隐藏的知识按照指定格式外化保存下来。这里还有一个更大的启发，LLM 还可以帮助我们从信息转变成知识的能力。除了工单的场景，大家可以想想，这会带来多少新的有价值的用法。</p><p></p><p>● AI 代码助手：利用工单上下文（ eg：日志、metrics ）等信息，自动定界甚至提供修改代码 patch 的 AI。这个助手可以分析错误日志和性能指标，定位问题所在的代码段，并提供可能的修复方案。在我们的未来设想中，它不仅可以加速问题解决，还能帮助开发人员学习和改进代码质量。</p><p></p><p>● AI 复盘助手：每个工单都是一个产品学习和成长的机会，但是事实上复盘耗时又烧脑，最简单的时间线记录都很难，所以复盘助手除了帮助复盘，提供从预防、缓解、解决、检测不同方向的思考外，还应该可以帮助提炼聊天记录中的时间线。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/44/44d9c4bfc1b75e237c295fd88f3b1509.png\" /></p><p></p><p>之前我们的 AI 落地都是单点思考，而逆转点就在于我们用流程展开工单的处理过程为开始。我想，这也算是为我坚信“流程化 - 数字化 - 智能化向上叠加又相互作用”的知行合一了。</p><p></p><h3>AI 重塑流程，还是流程也在塑造 AI</h3><p></p><p></p><p></p><blockquote>“人类驯化了小麦，还是小麦驯化了人类?”</blockquote><p></p><p></p><p>这是我从一本科普书籍里面看到的，其实很多事物都是相互作用，而不是单向作用。AI 与流程，也正如前面说的，流程化 - 数字化 - 智能化，相互叠加也相互作用，所以 AI 重塑流程的同时，流程也在塑造 AI。流程怎么塑造 AI 呢？最普遍的会认为数据是 AI 的基础，流程是数据的基础。但是，除了这个，其实还有两个部份在影响和塑造 AI 和 AI 使用的场景， 这里，我先说个有意思的真实故事。</p><p></p><p></p><blockquote>Boss：给你两个人力，你可以帮我打下什么”山头“员工：我承诺我会……….Boss：好！两个人力马上给你。来，认识下他们。分别是 &nbsp;GPT-4 和 &nbsp;GPT-4o</blockquote><p></p><p></p><p>上面这段对话是我在我们中心年会一个评奖环节时发生的，当时大家听完开怀大笑起来。这似乎是个不错的段子，有种老板耍流氓的感觉。为什么会有这个感觉呢？</p><p></p><h4>AI 的局限性</h4><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/fa/fa0c9a932f0a22be216033b9ed440a20.png\" /></p><p></p><p>如上图所示：</p><p></p><p>不信任。我们不相信 AI 的有两个核心原因，一个就是幻觉，所谓一本正经胡说八道。另外一个就是不确定性，看起来是产生创意的关键，但同时也让问相同问题却会得出不同的答案，在需要确定性的企业应用场合，这个特征简直绝杀。最后一个原因，就是没人味儿，一股赛博朋克味儿，可信度天然就下降了。不可用。如果给 AI 配首歌，热狗的\"差不多先生\"最配，车轱辘一大堆，看起来有用，但是解决不了任何问题。例如，当你问 AI 使用 AVX 指令的风险的时候，它可能会给出一大堆泛泛而谈的建议，就是不提 AVX512 可能带来的 CPU 降频风险。还有就是上下文的限制，无论是输入的上下文，还是输出的上下文，直接让我们在一些场景下根本就无法使用。比如，要基于完整的代码和历史修改的上下文去做 AICR。“渣”AI。这应该算是 AI 被“渣”，AI 再美，不如自己更有性价比。所以很多时候，大家对 AI 的态度，就是不主动使用 AI，真正去学习提示词工程的寥寥可数；各大厂商推广 AI 的时候，不拒绝听一听，也不拒绝用一用；对于使用 AI 生成的结果不负责，结果不好都是 AI 的问题，跟我无关。这么说来，绝对就是“渣”男 / 女本“渣”。</p><p></p><p>怎么破呢？当前，AI 发展非常快，也衍生出很多解决问题的技术手段。但是，老生常谈的就不说了，我只说两个真难事儿，因为涉及到人的本质和 AI 的本质。</p><p></p><p></p><blockquote>AI 的本质： 基于概率去关联词与词的特征的模型，所以\"不确定性\"是 LLM 天然的。人的本质： 人的本质是人的需要。（马克思在《詹姆斯·穆勒〈政治经济学原理〉一书摘要》中多次提到人的本质就是人的需要）。我“需要”，比“给我好的”，更重要。所以“渣”似乎也有理论依据，所谓“千金难买我想要”。</blockquote><p></p><p></p><h4>流程如何塑造 AI</h4><p></p><p></p><p></p><blockquote>一部分的破解之道，就在流程中</blockquote><p></p><p></p><p>不确定性 -&gt; “确定的结果”需要“确定的流程”</p><p></p><p>正如在《思考，快与慢》中，慢系统其实就是我们通常说的思路，理性且耗费脑力，但是他能获取比直觉更高确定性的结果。我们也可以称之为思考的流程，在 AI 里面类似思维链 CoT。但是，其实一切都没有脱离概率，思考的流程从另外一个角度看，通过思考的步骤来强化期待结果概率的方法。而放大到组织的粒度来说，就是流程，流程的步骤其实是放大达成目标的概率的方法。</p><p></p><p>“渣”AI -&gt; 主动 AI 变成被动 AI，让 AI 嵌入流程中</p><p></p><p>正如酒店里的机器人，你不会主动用，但在你每次叫外卖的时候会被动用到它。这就是流程的力量，因为外卖机器人嵌入了酒店大堂到房间的送货流程中，让你不得不用，想“渣”也不行。</p><p></p><p>“渣”&nbsp;AI &nbsp;-&gt; 你想要 = 你负责 = 要流程</p><p></p><p>粤语有句话叫“吃得了咸鱼，抵得住渴”，意思就是我选择结果，我要为之负责。所以，对于 AI 的“不负责”和我的“不抉择”其实就有着微妙的关系。要不要“抉择”，关键就是我有没有明确的、具象的目标，我称之为“我想要的”。深入使用大型语言模型后，我发现一旦我明确知道“我想要的”，像 Agent 那样让 AI 自己规划流程输出的结果就不那么成立。这时，我们人类自己来定义的”流程“就成了是我们让 AI 输出“我想要的”的关键手段。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/cd/cd45fb07d6d01ddf54309d5a5cc53a22.png\" /></p><p></p><p>那么流程究竟是什么？为什么会有这个作用。我理解流程是一系列规划好的步骤和对于每个步骤产出的标准。它的特质，注定流程追求的是效率和确定性。如上图，映射到 AI 的原理中也很有意思，AI 回答的每一个词都由前者的词的特征来计算概率得出。而你写的思考流程，每一步的生成内容，其实都是在不断增强你最终想要的词出现的概率，跟真实世界的流程有着异曲同工之妙。</p><p></p><p>总而言之，数据需要基于流程之上的数字化，而流程本身的确定性和强制性又从一定程度上解决 AI 和人的本质带来的难题。所以 AI 在重塑我们的流程的同时，流程也在塑造 AI 。</p><p></p><h3>用\"技术工作流程\"作为他山之玉</h3><p></p><p></p><p>在将于 10 月 18-19 日举办的 <a href=\"https://qcon.infoq.cn/2024/shanghai/schedule\">QCon 全球软件开发大会（上海站）</a>\"，我策划了「AI 重塑技术工作流程」这个专题，一开始其实有个更开放性的专题设计思路，不限制在技术工作中。后面仔细思考了一下，技术领域作为 AI 赋能的先行者，也作为最了解 AI 原理的一群人，也许可以有他山之玉之功。所以最终我们将专题聚焦在\"技术工作流程\"中的 AI 重塑。</p><p></p><p>我们期望，正如文章最前面所讲，希望从流程角度去思考，那一刻带来的启发和兴奋，能够在这次专题中得到延续。我们也希望能从改善到重塑，从 AI 作用于流程，到流程作用于 AI，给听众带来丰富的案例和启发。同时，我们也期待有干货的伙伴能加入我们的专题，一起分享你们的经验和见解。</p><p></p><h3>结语</h3><p></p><p></p><p>AI 和流程的双向奔赴正在改变我们的工作方式。从单点 AI 应用到全流程 AI 集成，我们看到了巨大的潜力和挑战。这种转变不仅提高了效率，还可能彻底重塑我们的工作流程和组织结构。</p><p></p><p>但这也引发了一些值得思考的问题，欢迎针对下面的问题分享你的想法并讨论：</p><p></p><p>应该基于最痛的单点痛点去落地 AI，还是应该从流程的整体出发借助 AI 去优化效率？你的工作流程被 AI 颠覆了吗？产出的质量和效率发生了什么改变？组织结构发生了什么改变？什么是阻挡 AI 落地的最大障碍，倘若 AI 真的全面融合到工作流程中了，它会不会也变成其它事物出现的障碍呢？</p><p></p><h4>会议推荐</h4><p></p><p>InfoQ 将于 10 月 18-19 日在上海举办 QCon 全球软件开发大会 ，覆盖前后端 / 算法工程师、技术管理者、创业者、投资人等泛开发者群体，内容涵盖当下热点（AI Agent、AI Infra、RAG 等）和传统经典（架构、稳定性、云原生等），侧重实操性和可借鉴性。现在大会已开始正式报名，可以享受 8 折优惠，单张门票立省 960 元（原价 4800 元），详情可联系票务经理 17310043226 咨询。</p><p><img src=\"https://static001.geekbang.org/wechat/images/57/5780f7c4c252e5d0848c35279ed4f0d9.png\" /></p><p></p>",
    "publish_time": "2024-08-29 16:52:26",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "哎呀，系统“挂了”！——这是能说的吗？",
    "url": "https://www.infoq.cn/article/tm6KUFeRX2rFGWiszbFs",
    "summary": "<p>近年来，多家知名互联网公司遭遇的软件系统故障，导致服务中断、数据丢失，这不仅影响了用户体验，甚至给企业带来直接或间接的经济损失。这些事件促使整个行业开始深刻反思，服务提供商、用户和其他利益相关者都在寻求改进现有技术和流程的方法。</p><p></p><p>如果线上可靠性工程出现问题，那么前期在应用产品设计、研发测试、发布变更等环节的所有投入都可能变得毫无意义。高质量的线上可靠性工程不仅能够减少故障发生的概率，还能够在故障发生时快速恢复服务，成为企业的核心竞争力之一。</p><p></p><p>鉴于此，我们策划了「哎呀，系统“挂了”」的圆桌讨论活动，旨在探讨不同规模的公司在稳定性可靠性方面面临的挑战及应对策略。</p><p></p><p></p><blockquote>我们也在即将于 10 月 18 -19 日召开的 QCon 上海站策划了【<a href=\"https://qcon.infoq.cn/2024/shanghai/track/1726\">线上可靠性工程</a>\"】专场，将邀请不同公司的稳定性技术专家，分享他们在各自的业务场景中的可靠性/ 稳定性保障的实践经验，共同探讨线上可靠性工程的问题的解决思路。目前是<a href=\"https://qcon.infoq.cn/2024/shanghai/apply\"> 8 折购票</a>\"最后优惠期最后 2 天，感兴趣的同学抓紧机会。&nbsp;&nbsp;</blockquote><p></p><p></p><h4>内容涵盖</h4><p></p><p>不同规模的公司，稳定性和可靠性的关注点会有所不同吗？“低级错误”带来的故障不少，这是能忍的吗？在系统出现故障时，如何与用户进行有效沟通并保持透明度？在处理系统故障时，如何推进跨技术团队之间的有效协作？展望未来，稳定性和可靠性工程将面临哪些新的机遇和挑战？</p><p></p><h4>直播回放👇</h4><p></p><p><a href=\"https://www.infoq.cn/video/WyLQrNEAwNExliKAHfdd\">https://www.infoq.cn/video/WyLQrNEAwNExliKAHfdd</a>\"</p><p></p><p>更多精彩内容，欢迎持续关注 10 月 18-19 日的 QCon 上海站，届时，几位老师将带来如下分享：</p><p></p><h4>演讲主题：AI 驱动下的可观测平台架构升级实践</h4><p></p><p><img src=\"https://static001.geekbang.org/infoq/c5/c5628e9acbfc18697fca6e19ceb80184.png\" /></p><p></p><p>主要介绍携程对内部可观测平台进行架构升级的工程实践，涵盖 Metric 和 Logging 数据进行统一治理、为 AIOPS 落地提供数据和工具支撑以及云平台团队通过使用 AI 工具来提升平台运维效率的真实案例，希望能给大家带来一些帮助。</p><p></p><p>演讲提纲</p><p>1. 携程可观测性平台现存问题</p><p>监控指标只增不减日志场景只增不减非关键的指标占用大量的计算存储资源，核心指标的实时性得不到保障各类监控工具烟囱林立，资源没有打通，无法统一治理</p><p></p><p>2. 数据治理实践</p><p>&nbsp;Metrics 数据治理&nbsp;Logging 数据治理&nbsp;统一监控 Agent 落地实践</p><p></p><p>3. 升级架构助力 AIOPS 落地</p><p>通过物化视图等技术实践，提升数据时效性通过分层存储技术将数据冷热分离, 降低丢失率，提升数据可靠性通过建设数据质量度量工具，提升数据准确性</p><p></p><p>4. 实践案例与展望</p><p>&nbsp;使用 AI 工具来提升平台运维工作效率的案例&nbsp;可观测平台架构升级的问题总结和未来展望</p><p></p><p>演讲亮点</p><p>可观测性平台架构升级的实际案例，重在实践AIOPS 落地的前置依赖</p><p></p><p>实践痛点</p><p>监控领域随着时间推移，会产生大量的老旧系统、老旧数据，相关遗留问题，也不是仅靠一次架构升级可以完全解决，需要持续投入精力做治理；如何与业务实际需求结合，不断调整技术方案和需求适配，保障最核心的链路；可观测性数据的价值挖掘，数据实时性和准确性需要放在第一位</p><p></p><p>听众收益</p><p>主流的监控告警、可观测性工具选型了解监控和日志数据持续膨胀的治理方案AIOPS 依赖的可观测性数据集质量保障体系AI 工具如何协助处理琐碎的日常运维工作</p><p></p><h4>演讲主题：蚂蚁故障应急全流程体系构建及应用实践</h4><p></p><p><img src=\"https://static001.geekbang.org/infoq/0e/0eb82d10ec1e757c268161ecae261d92.png\" /></p><p>主要介绍蚂蚁的故障应急体系，通过实际的故障案例来简要介绍故障定义、组织阵型、平台能力、应急流程、应急评价等内容，并分享 AIOPS、LLM 大模型等能力在应急定位中的落地情况，以期能够回答业务稳定性保障要“做什么”、“谁来做”、“怎么算做得好”等问题，希望能给大家带来一些新的保障思路。</p><p></p><p>演讲提纲</p><p></p><p>1. 引子：一个真实的线上故障</p><p>是怎么发现的？是怎么定位根因的？是怎么止血的？是怎么复盘的？</p><p></p><p>2. 蚂蚁故障体系构建</p><p>故障的定义、分类，以及对应的平台能力和评价指标故障数据如何驱动日常稳定性保障工作的开展和能力演进</p><p></p><p>3. 蚂蚁应急体系构建</p><p>应急的目标和各阶段的数据指标定义，组织阵型设计和对应的评价指标应急各阶段的目标和平台能力支撑</p><p></p><p>4. 一个线上故障的全生命周期</p><p>从故障定义、故障注入、故障发生、故障发现、故障响应、故障定位、故障止血、故障复盘全生命周期进行详细的分析，并尽可能多的展示实践效果</p><p></p><p>5. 未来已来</p><p>AIOPS 助力应急定位快速发现故障原因的方法通过 LLM 加速故障复盘及 ACtion 跟进</p><p></p><p>实践痛点</p><p>SRE 团队与开发团队、质量团队在稳定性保障事项中的目标、分工、合作方式，会因各公司的组织结构差异而有非常大的不同，在落地的过程中难免会有一些冲突故障应急的根因定位能力非常依赖公司的基础设施基建，AIOPS 和 LLM 在落地的过程中会不可避免的遇到定位准确率低、定位结果方差大的问题</p><p></p><p>演讲亮点</p><p>以业务稳定为中心的、以风险事件及线上故障数据为驱动的、以 SRE 能力提升和平台能力演进为路径的技术风险整体防控方案AI 大模型在应急根因定位、应急快恢决策、应急 Action 跟踪等方面的能力实践和未来展望</p><p></p><p>听众收益</p><p>了解蚂蚁集团风险事件和线上故障管理的设计思路及现有能力了解蚂蚁集团应急全流程的设计思路、平台能力、机制流程了解典型故障应急的全流程应对及处理方案探索 AI 大模型能力如何落地到故障应急领域</p><p></p><p></p><h4>演讲主题：全球网络环境下的用户体验优化实践</h4><p></p><p><img src=\"https://static001.geekbang.org/infoq/ce/ce25dd53c944fce27bc4c721172e7689.png\" /></p><p>除了从架构、容灾、监控的角度提升可靠性之外，用户体验的波动也影响着用户对线上系统稳定性和可靠性的感知。在全球网络环境下，云服务商众多，网络延迟多变，成本计算复杂，影响因素难料，单纯依赖人的选择应用的部署节点，已经不能完全满足业务在用户体验方面的要求。</p><p></p><p>腾讯游戏 SRE 团队，利用 AIOPS 能力，从数据工程角度，通过分析全球网络数据，云服务商数据，用户访问模拟等方式，建立一套用户体验评价体系，找到了一种相对通用的全球网络环境下的用户体验优化实践方案，为海外业务发展提供关键决策。这是一套实践方案不仅适用于游戏行业，也同样适用于其他互联网行业的用户体验优化方案。</p><p></p><p>演讲提纲</p><p></p><p>1. 真实的全球网络环境到底什么样？</p><p>复杂的全球网络线路每天都可能会变化的路由非技术原因网络波动断崖式的网络质量变化</p><p></p><p>2. 腾讯游戏全球网络环境优化实践</p><p>游戏战斗服智能选择场景介绍如何通过数据模拟玩家行为？数据采集匹配重现迭代最优解如何通过数据工程验证效果？增加测速服务器模拟匹配模拟对战</p><p></p><p>3. 非游戏业务的应用实践</p><p>此方法的本质通用流程定制与适配</p><p></p><p>4. 经验总结和未来展望</p><p>在业务逻辑上寻找优化点&nbsp;降低成本，提升通用性</p><p></p><p>实践痛点</p><p>数据存储与分析成本成本高分析结论在实际应用中的时效性</p><p></p><p>演讲亮点</p><p>基于业务实际数据的真实实践案例用数据工程的方法改善玩家体验</p><p></p><p>听众收益</p><p>了解全球网络现状SRE 团队的 AIOPS 能力需要具备哪些基础设施学习数据模拟和数据验证工程的实践方法游戏体验优化方案如何应用在非游戏业务</p><p></p><h4>演讲主题：B 站轻量级容灾演练体系构建与业务实践</h4><p></p><p><img src=\"https://static001.geekbang.org/infoq/ce/cecf191707033541f3df8da540a83082.png\" /></p><p>本次分享将从 B 站的容灾演练体系构建入手，逐步拆解体系，带大家深入了解 B 站在容灾演练上的组织阵型搭建模式、运营机制设定方法以及容灾产品能力建设，最后通过结合业务实践为大家展示 B 站是如何通过容灾演练体系来支撑业务多活、大促保障和研发质量交付等多个环节的，希望能为大家带来一些稳定性保障的新思路。</p><p></p><p>演讲提纲</p><p></p><p>1. 新形式下的稳定性挑战</p><p>分析当下基础设施层故障频发、业务高可用手段失效的原因如何破局？主动出击，以演带练</p><p></p><p>2. 轻量级容灾演练体系构建</p><p>组织阵型搭建：横向容灾演练推进小组、基础架构运营机制流程：如何围绕演练风险分，通过容灾演练专项牵引基础架构和业务 BU，有效推进演练工作容灾产品能力：从混沌引擎能力演进、容灾场景定义、演练全生命周期管理、演练可视化、智能演练防护来详细介绍容灾相关产品能力</p><p></p><p>3. 业务场景实践</p><p>业务多活场景：借助容灾演练能力，确保业务多活的有效性活动大促场景：活动场景的容灾演练点快速挖掘和针对性演练需求交付场景：在常态化的需求交付阶段，助力质量保障部门快速完成服务依赖演练</p><p></p><p>4. 总结展望</p><p>总结 B 站的实践效果和过程反思未来如何通过 LLM 挖掘更多的容灾场景，提升容灾演练的效率</p><p></p><p>实践痛点</p><p>如何有效的定义和模拟容灾演练场景如何组织多 BU 和多职能角色进行项目落地</p><p></p><p>演讲亮点</p><p>轻量级的容量演练体系设计思路和实践参考</p><p></p><p>听众收益</p><p>了解 B 站如何轻量级在组织内部常态化实施容灾演练了解 B 站容灾演练的技术演进路线、组织搭建模式和运营机制流程，掌握体系化的解决方案</p><p></p><p></p><h4>会议推荐</h4><p></p><p>InfoQ 将于 10 月 18-19 日在上海举办 QCon 全球软件开发大会 ，覆盖前后端 / 算法工程师、技术管理者、创业者、投资人等泛开发者群体，内容涵盖当下热点技术（AI Agent、AI Infra、RAG 等）和传统经典技术（架构、稳定性、云原生等），侧重实操性和可借鉴性。现在报名可以享受 8 折优惠，单张门票立省 960 元（原价 4800 元），详情可联系票务经理 &nbsp;17310043226 咨询。</p><p><img src=\"https://static001.geekbang.org/wechat/images/df/dfd31ee989a7951439a77fec138d4cf8.png\" /></p><p></p>",
    "publish_time": "2024-08-29 17:14:20",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AI 浪潮下应用开发的“华山论剑” | QCon",
    "url": "https://www.infoq.cn/article/9V9jYGvjYd5Nzfb7GHGe",
    "summary": "<p>随着人工智能技术的突破性进展，AI 应用开发已成为全球技术革新的核心，并以前所未有的速度改变着世界，您准备好了吗？作为企业技术管理者和架构师，您是否在思考如何利用 AI 推动业务强劲增长？</p><p></p><p>AI 应用开发实践涉及到数据采集与处理、机器学习模型的构建与训练、深度学习技术的应用、以及 AI 系统的集成与部署等多个环节。从智能个性化推荐算法到复杂的自动驾驶系统，再到医疗健康领域的精准诊断，AI 正以其独特的方式重塑着各行各业的面貌。我们惊喜地看到从中小创业公司到大型企业，都在利用计算机视觉、自然语言处理、个性化推荐、对话式交互等 AI 能力提升业务效率、优化用户体验，显著增强了产品的市场竞争力。</p><p></p><p>同时我们也关注到，在实际的 AI 应用中，确保 AI 技术与具体业务需求的紧密结合仍然是一个复杂的挑战，涉及到高质量的数据收集与预处理、模型的选型、RAG 等工程扩展技术，去取得更具鲁棒性和灵活性的解决方案。</p><p></p><p></p><blockquote>10 月 18—19 日 QCon 全球软件开发大会（上海站），我们设置了【<a href=\"https://qcon.infoq.cn/2024/shanghai/track/1721\">AI 应用开发实践</a>\"】专题，聚焦实战直击痛点！我们邀请了来自字节跳动、百度、阿里巴巴等头部企业的 AI 专家，分享他们在 AI 代码补全、Agent 开发、电商 AI 落地等方面的实战经验，并探讨如何解决数据安全、性能优化、跨平台兼容等关键挑战。目前是<a href=\"https://qcon.infoq.cn/2024/shanghai/apply\">8 折购票</a>\"倒计时 2 天，感兴趣的同学抓紧机会。&nbsp;&nbsp;</blockquote><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/78/78f7726a60773e15db02c833ca9e3464.png\" /></p><p></p><h3>精彩内容抢先看</h3><p></p><p></p><h4>演讲主题：豆包 MarsCode 在 AI Coding 的探索与实践</h4><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/cd/cdb423aa98b6a3b2f7679afb12faf478.png\" /></p><p></p><p>自 LLM 用于辅助编码以来，Al 增强开发成为目前最具革命性的技术趋势，人类开发软件的方式正在发生根本性的变化。预计未来几年，世界上每一位工程师都会在 AI 辅助下进行开发，这是一个令人振奋和向往的技术浪潮，豆包 MarsCode 作为浪潮中的一份子，对 AI Coding 技术在编码开发场景的落地有一些自己的见解。本次演讲我们将分享豆包 MarsCode 在 AI Coding 方向的实践和探索，探讨 AI 与编程工具如何深度融合以及我们对未来软件开发形态的展望。</p><p></p><p>演讲提纲</p><p></p><p>1. AI Coding 的演进史和发展趋势</p><p></p><p>2. AI 代码补全和 AI 问答的效果优化实践</p><p></p><p>代码补全关键指标 (CPO)CPO 的定义要素如何用 CPO 衡量代码补全的真实价值代码补全核心实现架构如何降低 debounce，提升注释、补全的续写效果提高尝试率如何通过模型推理优化和网络、压缩等工程侧优化提升反馈速度如何通过推荐时机优化和模型训练提升采纳率基于 CKG 优化 AI 代码知识问答效果实践</p><p></p><p>3. AI Coding 带给 IDE 的变革和工程实践</p><p></p><p>AI IDE 核心三要素：AI 原生交互 + 随时随地开发 + 服务集成化基于前后端分离实现 IDE 模块解耦划分IDE 性能优化：Rust 重构、通道复用、协议压缩、Web Component 化云 IDE 秒级启动实践：基于 K8s 定制池化调度策略、存储热挂载、进程 HotReload</p><p></p><p>4. 未来 AI Coding 的展望</p><p></p><p>谈谈下一代的 AI Coding 技术升级版 AI 代码编辑推荐 (补全 Pro) 和 AutoDebug 的产品化探索未来软件开发趋势展望</p><p></p><p>实践痛点</p><p></p><p>如何更好去优化 AI 代码补全，如何定义指标，如何从算法侧和工程侧如何综合去优化整个链路AI Coding 新技术多且不算特别成熟，如何基于当下评估能力的可用性，做新技术的探索和落地云 IDE 如何做工程化落地 AI 给 IDE 带来的变革</p><p></p><p>演讲亮点</p><p></p><p>字节跳动对于 AI 代码补全和 AI 问答的效果优化实践字节跳动对于 代码推荐 (补全 Pro) &nbsp;和 AI AutoDebug 两类新 AI Coding 场景的技术探索和产品化落地探索业内 Top 级云 IDE 工程</p><p></p><p>听众收益</p><p></p><p>了解目前 AI Coding 领域最前沿的行业动态和知识了解 MarsCode 在 AI 代码补全效果和 AI 问答效果的优化实践了解 AI 代码编辑推荐和 AI AutoDebug 两大即将普惠的 AI Coding 技术和对其在落地形态的思考和探索了解 MarsCode 在 AI IDE 领域关键工程技术和实践经验</p><p></p><h4>演讲主题：百度文心智能体开发实战与分发模式创新</h4><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c8/c8c7c802b573fe88f6007c0517e271f2.png\" /></p><p></p><p>随着人工智能技术的蓬勃发展，AI Agent 作为智能服务的关键载体正深刻影响着各行各业。本次演讲，我将以“文心智能体”平台的智能体开发实战为蓝本，深入剖析 AI Agent 从理论到实践的构建过程；同时，结合“旅游 AI 助手”的分发实践，探讨 AI Agent 在多样化市场中的高效、安全分发策略。通过这两个具体案例，结合最新的开发工具、框架及最佳实践，揭示 AI Agent 在提升服务效率、优化用户体验方面的独特价值。此外，我们还将直面数据安全、性能优化、跨平台兼容等核心挑战，提出切实可行的解决方案，为听众呈现一场既具深度又具实用性的 AI Agent 开发与分发盛宴。</p><p></p><p>演讲提纲</p><p></p><p>1. 引言</p><p></p><p>Agent 技术背景与定义演讲目的与结构概述</p><p></p><p>2. Agent 开发实战（文心智能体）</p><p></p><p>Agent 应用理论基础技术选型与架构设计：构建高效能 Agent 的基石文心智能体的特点与应用效果</p><p></p><p>3. 分发模式创新（以旅游 Agent 为例）</p><p></p><p>分发策略设计：质量评估、用户体验优化与反馈机制实战案例分析：旅游领域的 Agent 分发实践，包括市场定位、渠道选择、用户反馈等分发成效评估：市场反响、用户满意度、业务增长等关键指标</p><p></p><p>4. 核心难点与挑战及解法建议</p><p></p><p>数据安全与隐私保护：挑战分析、现有策略与未来展望跨平台兼容性与标准化问题：现状剖析、解决方案与标准化路径实战中的其他挑战与应对策略分享</p><p></p><p>5. 总结与展望</p><p></p><p>Agent 应用研发与分发实践的关键点回顾未来发展趋势预测：技术革新、市场变化与用户需求鼓励行业交流与合作，共同推动 AI Agent 技术的持续进步</p><p></p><p>实践痛点</p><p></p><p>数据安全与隐私保护：如何确保 Agent 应用的数据安全与隐私保护成为一大挑战算法性能优化：随着应用场景的复杂化，如何提升 Agent 的算法性能，确保其实时性与准确性成为关键跨平台兼容性与标准化问题：不同平台间的兼容性问题以及缺乏统一的标准框架，限制了 Agent 应用的广泛推广与应用</p><p></p><p>演讲亮点</p><p></p><p>探索最新的 Agent 应用开发范式分享 Agent 应用设计和开发过程中的关键技术考虑，以及在实际应用中的成功案例</p><p></p><p>听众收益</p><p></p><p>深入理解 Agent 技术的理论基础与应用场景掌握 Agent 应用的研发流程与分发策略获得最新 Agent 应用领域的前沿知识和工具应用经验</p><p></p><h4>演讲主题：AI 托管商家经营：1688 电商 AI 落地实战</h4><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ba/ba8ff320c70f8808539c2fd65635085c.png\" /></p><p></p><p>1688 对接了大量的工厂类型商家，他们普遍存在供应链能力强但是线上运营能力较弱的问题，这类商家在网站上缺乏有效的方法论指导，电商经营的试错成本居高不下，导致流失率较高。如何通过 AI 技术帮助商家提升线上运营能力，从而提升商家的经营效果是一个具有挑战性的命题。本次分享将结合 1688 商家端的 AI 实战，介绍面向商家提供的 AI 智能化服务，包括咨询问答、 客户管理、 商品运营、经营计划等工作，以及业界领先的 AI 经营托管能力，并阐述相关的技术方案和踩坑经验。</p><p></p><p>演讲提纲</p><p></p><p>1. AI 应用的趋势洞察与判断</p><p></p><p>产业 AI 应用观察商家 AI 产业应用深度定义和全景AI 2B 市场和客户画像分析</p><p></p><p>2. 商家 AI 场景的应用实战</p><p></p><p>各类 AI 技术在商家领域内的应用图文 GC：隐藏在标题、图片里的坑问答：多轮对话牵引商家行动诊断归因：业界难题，我的流量为什么跌了</p><p></p><p>3. 商家 AI 托管模式探索</p><p></p><p>AI 托管的几大障碍核心技术架构和关键技术点AI 经营计划的版本升级AgentSwarm 模式如何工作巧用营销模型让商家 AI 价值最大化</p><p></p><p>4. 未来商家域 AI 的空间和路线</p><p></p><p>实践痛点</p><p></p><p>大模型当前的知识储备和推理能力依然不足，很多命题必须通过 LLM+DL+ML+ 工程方案求解Agent 是个美好的概念，但是落地过程中有诸多水土不服，需要重新认识</p><p></p><p>演讲亮点</p><p></p><p>业内领先的 AI 经营托管的技术，通过经营计划的一揽子方案接管商家的线上经营，并取得不错的业务结果在 RAG 应用、AI 归因分析、AgentSwarm 模式等方面有一定的探索和结果</p><p></p><p>听众收益</p><p></p><p>了解商家端 AI 应用全景和阿里体系商家 AI 探索路径了解各类 AI 技术在商家端业务里的坑以及常见商家端问题的解法了解 AI 托管的模式创新、问题和解法思路</p><p></p><p>更多精彩内容将在 10 月 18 - 19 日 QCon 上海站为您现场呈现，期待与您共赴这场技术之约。如果您有好的技术实践案例想要与我们分享，欢迎<a href=\"https://jinshuju.net/f/EbrZFg\">点击链接</a>\"提交演讲申请。</p><p></p><p>会议推荐</p><p>InfoQ 将于 10 月 18-19 日在上海举办 QCon 全球软件开发大会 ，覆盖前后端 / 算法工程师、技术管理者、创业者、投资人等泛开发者群体，内容涵盖当下热点（AI Agent、AI Infra、RAG 等）和传统经典（架构、稳定性、云原生等），侧重实操性和可借鉴性。现在大会已开始正式报名，可以享受 8 折优惠，单张门票立省 960 元（原价 4800 元），详情可联系票务经理 &nbsp;17310043226 咨询。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/df/dfd31ee989a7951439a77fec138d4cf8.png\" /></p><p></p>",
    "publish_time": "2024-08-29 17:22:17",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]