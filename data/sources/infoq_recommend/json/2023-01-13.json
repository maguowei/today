[
  {
    "title": "DevOps缺少定义，平台工程需要指导性路线图",
    "url": "https://www.infoq.cn/article/GaUyduw3FQ0dHXu9Druq",
    "summary": "<p>在<a href=\"https://www.youtube.com/watch?v=u4o1jcQIaYo&amp;ab_channel=PlatformEngineering\">PlatformCon 2022大会</a>\"上，Puppet现场首席技术官<a href=\"https://twitter.com/nigelkersten\">Nigel Kersten</a>\"谈了平台工程指导性路线图的需求。他分享道，在之前的文化转型中，如敏捷和DevOps，行业在方法和定义方面开始出现分歧。关于如何进行组织和文化变革才是拥抱新范式的最佳方法，人们感到很困惑。</p><p>&nbsp;</p><p>Kersten认为，缺少方向不仅会导致实现很糟糕，而且还会产生不良后果。缺乏对DevOps的理解会产生一个副作用，就是DevOps工具和软件生态系统会自称是实现DevOps的手段，导致许多人错误地认为，DevOps的目的仅仅是实施恰当的工具。</p><p>&nbsp;</p><p>然而，正如Showpad工程副总裁<a href=\"https://www.linkedin.com/in/patrickdebois\">Patrick Debois</a>\"在2010年<a href=\"https://www.jedi.be/blog/2010/02/12/what-is-this-devops-thing-anyway/\">所指出的那样</a>\"，DevOps不仅仅是软件：</p><p></p><p></p><blockquote>DevOps运动是围绕着一群人开展起来的，他们相信，将适当的技术和态度相结合可以彻底改变软件开发和交付的世界。</blockquote><p></p><p>&nbsp;</p><p>在大规模迁移过程中，对文化和流程的关注往往不够。在企业层面，现有团队、流程和沟通渠道的数量使得这项运动很容易失去目标。正如Kersten所指出的那样，大量供应商和软件公司向该领域发布工具，加剧了这种情况：</p><p></p><p></p><blockquote>有太多供应商看到了这个巨大的、充满活力的社区，这些人非常热衷于改变现状，并且说，“那个软件，是的，完全是DevOps的”。所有这些都开始扭曲和异化整个运动，以至于人们的期望和理解变得有点难以实现。</blockquote><p></p><p>&nbsp;</p><p>Kersten认为，有必要制定一个指导性路线图，以确保这段历史不会在平台工程运动中重演。创建一个合适的团队结构只是为成为一个成功的组织奠定基础的开始。团队之间的互动同样重要。正是在这一点上，组织往往会陷入困境。</p><p>&nbsp;</p><p>对平台工程来说，这并不新鲜，而对DevOps来说，这也一直是项挑战。SoundHound高级工程主管<a href=\"https://www.linkedin.com/in/adam-mclaurin/\">Adam mclurin</a>\"<a href=\"https://www.linkedin.com/feed/update/urn:li:share:6987945573748264960/\">指出</a>\"：</p><p></p><p></p><blockquote>关于DevOps到底是什么，现在有太多无用的争论。我认为，我们应该退一步看，DevOps只是价值流优化的一个子集和一个切实的指导。</blockquote><p></p><p>&nbsp;</p><p>如果没有一个清晰的前进路径，如果对希望通过平台工程推动什么价值缺少共同的理解，那么就有可能产生不确定性和误解。然而，正是在将这些理念应用于活跃的组织时，许多人开始陷入挣扎。</p><p>&nbsp;</p><p>组织，特别是大型企业公司，已经有了许多模式和流程，这使得进行任何变革都成为一项挑战。虽然团队拓扑和价值流优化等理念帮我们提供了一个变革的入口，但它们可能不足以确保变革执行过程完全正确。</p><p>&nbsp;</p><p>InfoQ采访了Kersten，详细讨论了这个路线图理念和平台工程的未来。</p><p>&nbsp;</p><p>InfoQ：您曾说过，现在是时候为实施平台工程制定一个指导性的地图和模型了。您能详细说明这是什么意思吗？为什么是现在？</p><p></p><p></p><blockquote>Nigel Kersten：我几乎是从一开始就深入参与了DevOps运动。我看到，这个领域的活力和生产力令人难以置信，而且对中小型科技公司产生了巨大的影响，但我也观察到，通常，大型企业在尝试采用这些实践时没有得到同样的好处。&nbsp;正是DevOps宽泛的定义造就了这个充满活力的社区，然而，同样是因为缺少明确的定义，当大多数企业开始尝试“做DevOps”时，他们以DevOps的名义做了各种不同的事，其中大多数都失败了。我一直在和企业里设法实践DevOps的人交流，这可能是发布工程师、（重命名的）系统管理员和（按开发人员要求行事的）运维人员所做的任何事，在我看来，这都不是真正的“DevOps”，因为他们缺乏高效协作这个基本特征。&nbsp;我担心，我们会在平台工程中看到同样的事情。如果满腔热忱的早期实践者社区不聚在一起，进一步明确通往成功的路径，那么我们终将重复之前的遭遇，这会非常遗憾。&nbsp;请注意，我不认为像SAFe这样的模型是正确的方法，因为在这种模型中，角色和流程都高度具体，让人感觉非常僵硬，与敏捷截然相反。我认为，我们需要的是一个如何逐步采用平台工程方法的地图，而不是一个高度具体的最终目标。</blockquote><p></p><p>&nbsp;</p><p>InfoQ：为什么当前的模型（如团队拓扑）无法满足这种对指导性模型的需求呢？</p><p></p><p></p><blockquote>Kersten：团队拓扑是目前为止最好的模型，Matt和Manuel的出色工作让我感到敬畏，虽然正在使用TT模型的人大多数都声称已经读完了这本书，但我是不大相信的。那不仅仅是关于实现我们一开始介绍的各种团队，还涉及确保这些团队之间有恰当的交互模式与实践。&nbsp;我看到，人们最常犯的两个错误是：一、不关注团队之间的互动；二、没有严肃地对平台产品负责人这样的角色进行投资。&nbsp;坦率地说，如果整个企业领域都能接受团队拓扑关于“平台即产品”的相关工作，认真地遵循它，并相互学习如何推动那种变革，那么我们将处于一个非常有利的位置。</blockquote><p></p><p>&nbsp;</p><p>InfoQ：为什么您认为企业领域在实现敏捷、DevOps和现在的平台工程转型方面面临的挑战更多？对于我们这些当事人来说，要想成功转型，应该关注什么？</p><p></p><p></p><blockquote>Kersten：最根本的问题是，所有这些转型都涉及大量的人员互动，组织规模越大、存在时间越长，要改变人员互动方式就越难，你必须从链条的上游推送组织变革。&nbsp;我曾“Web规模”的大型科技公司工作过，然后是中小型科技公司，再然后是在过去十年里，与许多非常传统的企业共事。令人惊讶的是，与科技公司相比，大多数企业的内部沟通都很糟糕。我已经记不清参加过多少次会议和小组讨论了，很明显，与我一起工作的团队以前从未真正地一起工作过。&nbsp;最终的成功需要通过非常谨慎地设计实现团队之间的高效交互，尽可能减少中介，并重点关注系统生产者和消费者之间的反馈循环。我看到人们经常犯的一个错误是，在团队之间设定一个开放式的“协作”目标，导致了没完没了的会议和小组讨论，事实证明，当消费者数量超过生产者时（几乎在任何情况下都是如此），这会非常低效。&nbsp;作为供其他人使用的系统的生产者，你绝对应该在设计阶段专注于有意义的协作，对于用户使用系统的体验，要确保自己可以直接从他们那里获得及时的反馈，但在规模比较大时，要想真正的高效，你就会希望专注于构建自助服务系统，让用户可以按自己的速度和节奏进行操作。&nbsp;我坚信，大多数企业失败的原因是，他们试图通过项目管理而不是产品管理来实施这些计划。将内部用户群视为用户市场，将自己构建的解决方案视为面向这些用户的产品。这意味着你需要以适合他们的方式为他们解决问题，而不仅仅是提供“能力”，这意味着你需要随着时间的推移、问题的变化不断地解决它们，而问题总是会变化的！</blockquote><p></p><p>&nbsp;</p><p>InfoQ：在最近的一次演讲中，您讨论了如何在底层云基础设施过多抽象和平台过度灵活之间找到适当的平衡。对于许多新成立的平台团队，这似乎都是一个难题。您能再深入地介绍下这个问题吗，尤其是平台团队如何从一开始就为成功做好准备？</p><p></p><p></p><blockquote>Kersten：我发现，当你为拥有大型公有云组件的开发者构建平台时，有两种常见的失败模式。第一种是构建全新的接口，将底层的公有云服务完全抽象，这里的问题是，用户对这些服务几乎总是有一些了解，他们会因为你将它们隐藏起来而感到沮丧，而且没有你的帮助就无法自己解决新问题。&nbsp;第二种则完全走另一个方向，简单地向所有用户公开所有的公有云服务，并简单地将身份管理和成本控制的所有权交给“平台团队”。开发团队都将针对相同的问题提出不同的解决方案，而安全性和合规性等领域的处理成本将越来越高。&nbsp;要在这两种模式之间切换，你必须尽早找人担任产品经理，一个对平台有远见的人，就像其他产品一样。在产品管理中有句话是这样说的：“真相在大楼外”，这一点至关重要，从一开始就要记住。如果你的平台团队是由公司其他部门的基础设施运营人员组成的，而且没有和真正使用平台的人建立沟通渠道，那么你就不知道用户真正想要的是什么，你就无法为他们构建可以真正解决他们问题的解决方案。&nbsp;最理想的情况是，团队成员既有具备基础设施运营经验的人，也有可以代表平台用户的人，而产品经理负责确定功能优先级及平衡竞争性需求，并致力于确保你可以从平台用户那里获得可靠的反馈。&nbsp;如果这些你都有，就可以在我提到的两个失败点之间不断地进行路线修正。</blockquote><p></p><p>&nbsp;</p><p>InfoQ：对于即将到来的2022年DevOps现状调查，您期望看到什么？在接下来的一年里，您期望看到什么样的趋势？</p><p></p><p></p><blockquote>Kersten：我们仍在整理最终报告，但数据中出现了一些非常有趣的观点。一般来说，现在的从业者对平台工程的看法比对DevOps要积极得多，而且更多的人看到了可度量的积极结果。看起来，平台工程有巨大的潜力，有望成为一种更容易采用的模型，让企业可以获得DevOps的好处。&nbsp;但这可不是闹着玩的，绝大多数受访者都担心，他们的平台团队无法跟上产品团队消费平台的需求，抵制变化和沟通问题妨碍了许多人的工作。&nbsp;我们还看到，产品经理的角色至关重要，几乎可以肯定，整个行业都人手不足，团队希望招聘具有更好沟通技能的人，并希望有人帮他们在整个组织内传播和设定切合实际的预期。</blockquote><p></p><p>&nbsp;&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/platform-engineering-roadmap/\">https://www.infoq.com/articles/platform-engineering-roadmap/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/doz4HmWsaZwH4hi6FqXX\">平台工程中认知负荷的挑战</a>\"</p><p><a href=\"https://www.infoq.cn/article/7porVp7qVF03BVc2tDd6\">DevOps 已死，平台工程才是未来</a>\"</p>",
    "publish_time": "2023-01-13 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "展望前端研发工程师的 2023 | InfoQ《极客有约》",
    "url": "https://www.infoq.cn/article/HvDdiQutbkVeQQ3B8ysT",
    "summary": "<p>2023 年，成为一名出色的前端开发，我们需要提升哪些技能、做好哪些准备？本《极客有约》，我们邀请到了字节跳动云原生PaaS 资深前端工程师黄健，一起展望前端研发工程师的 2023。<br />\n讲师照片：</p>",
    "publish_time": "2023-01-13 10:40:31",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "中国软件技术发展洞察和趋势预测报告2023",
    "url": "https://www.infoq.cn/article/UGhD7MTY5Z43JG5YmWP3",
    "summary": "<h2>内容介绍</h2>\n<p>2022年中国技术市场受到整体经济环境不确定性和企业自身定位发生变化的影响，中国技术发展整体呈现稳重有进的宏观态势。本份报告从2022年技术市场发展回顾、2022年技术发展特征解读和2023年技术发展趋势预测三部分展开对中国技术市场的研究和洞察。 报告全文共 50+ 页研究成果，呈现20+图表、模型。<br />\n报告通过对 130+ 技术领域技术专利数量、技术诞生时间、技术舆论指数、技术融资事件、重要技术突破、主要厂商动态等数据和内容进行研究， 结合近20位专家的访谈结果，绘制了中国技术成熟度评估曲线。<br />\n<img alt=\"\" src=\"https://static001.infoq.cn/resource/image/7e/ca/7e64ccd5a516aaf07520107328c166ca.jpg\" /><br />\n另外， 报告总结2022年的技术服务市场呈现三大突破（理念突破、技术突破和产业突破），并且在2023年将呈现出六大技术发展趋势：</p>\n<ul>\n<li>趋势一：云上基础设施日益完善，助力IT部门进一步赋能业务</li>\n<li>趋势二：平台工程技术或将引领中国研发效能再升级</li>\n<li>趋势三：超级算力拓展技术能量边界</li>\n<li>趋势四：从前沿科技到产业应用，AI无处不在</li>\n<li>趋势五：数字世界与现实世界进一步打通</li>\n<li>趋势六：能源互联网工业互联网技术间交融与业务需求融合更加深入</li>\n</ul>\n<h2>目录</h2>\n<ul>\n<li>2022年技术市场发展回顾</li>\n<li>2022年技术发展特征解读</li>\n<li>2023年技术发展趋势展望</li>\n</ul>\n<h2>报告特邀专家</h2>\n<ul>\n<li>鲍   捷&nbsp;&nbsp; 文因互联 创始人</li>\n<li>贝春恒&nbsp; 金蝶云 首席架构师</li>\n<li>龚&nbsp;&nbsp; 银&nbsp; 超级猩猩 合伙人&amp;CTO&amp;TGO学员</li>\n<li>黄俊洪&nbsp; 腾讯云 副总裁</li>\n<li>蒋林泉（雁杨）阿里云 CIPU&amp;神龙计算负责人</li>\n<li>刘道儒&nbsp; 星汉未来 CEO</li>\n<li>李&nbsp;&nbsp; 昊&nbsp; 中科链源 CTO &amp;TGO学员</li>\n<li>孟曦东&nbsp; 博睿数据 创始人兼CTO</li>\n<li>沙   嘉  华为云中间件首席专家</li>\n<li>施继成&nbsp; 达坦科技 CTO&amp;联合创始人</li>\n<li>施   兴  (叔宝) 阿里云机器学习平台PAI产品架构负责人</li>\n<li>陶征霖  偶数科技数据库 首席架构师</li>\n<li>王&nbsp;&nbsp; 斌&nbsp; 达闼机器人 副总裁</li>\n<li>王昕溥  大禹智芯 CTO</li>\n<li>魏兴华&nbsp; 沃趣科技 CTO</li>\n<li>朱浩齐&nbsp; 网易易盾 总经理</li>\n<li>于&nbsp;&nbsp; 游&nbsp; ⻢泷医疗集团 CTO</li>\n<li>张&nbsp;&nbsp; 超&nbsp;&nbsp; 国环碳中和 CEO</li>\n<li>朱伟彬&nbsp; 卓越瑞新 CTO &amp;TGO学员</li>\n</ul>",
    "publish_time": "2023-01-13 13:35:41",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "爆火一个月后，“顶流”ChatGPT开始搞钱了",
    "url": "https://www.infoq.cn/article/FRcz5vjOvl3bM2d57opX",
    "summary": "<p></p><blockquote>火爆全网、惊艳科技界，“顶流”ChatGPT 也开始琢磨赚钱了。</blockquote><p></p><p></p><h2>OpenAI 准备推出付费版 ChatGPT</h2><p></p><p></p><p>据外媒报道，OpenAI 本周表示将推出付费版 <a href=\"https://www.infoq.cn/article/AWWsrfb54zTvglZ0I5qS\">ChatGPT</a>\"—— ChatGPT 专业版，但目前还没有制定售价标准。</p><p></p><p>作为 ChatGPT 的高级版本，ChatGPT 专业版具有几大优势：不存在任何“中断”（即不可用）窗口、不设节流、可支持无限数量的 ChatGPT 消息（至少两倍于常规每日上限）。</p><p></p><p>1 月 11 日，OpenAI 总裁兼联合创始人 Greg Brockman 专门在 Twitter 上发帖为 ChatGPT 专业版做宣传：“使用 ChatGPT 专业版，您将享受到更高配额上限与更佳性能。如果有兴趣，请加入我们的候选名单”。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cf/cfbb13a26ca71bd0feedf93d2926097c.png\" /></p><p></p><p>据悉，OpenAI 在 Discord 服务器上发布的候选名单链接中，提出了一系列关于付费偏好的问题，例如“您所能接受的 ChatGPT 最高价格（每月）是多少？”</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/aa/aad5367b8dbd2a5b3ec85af06d1cbaca.png\" /></p><p></p><p>OpenAI 表示，参与填写候选名单的朋友可能被选中并率先体验 ChatGPT 专业版。但由于程序仍处于试验阶段，因此目前还不会广泛开放。</p><p></p><p>ChatGPT 是 OpenAI 最新发布的<a href=\"https://www.infoq.cn/article/6UmmSt3XGmIRuxJlkT4q\">聊天机器人模型</a>\"，这也是 GPT-3.5 系列的主力模型之一。目前，ChatGPT 还处于测试阶段，只需登录就能免费使用。</p><p></p><p>虽然类似的聊天机器人并不少见，但 ChatGPT 一经发布迅速火爆全网，并收获了无数好评。有开发者认为，有些技术问题就算问谷歌和 Stack Overflow，都没有 ChatGPT 回答得靠谱。马斯克也曾感叹“很多人疯狂地陷入了 ChatGPT 循环中”，“ChatGPT 好得吓人，我们离强大到危险的人工智能不远了”。</p><p></p><p>2022 年 12 月，ChatGPT 发布仅一周的时间，就已经拥有超 100 万用户。这也印证了 ChatGPT 在全球范围内的火爆程度。</p><p></p><h2>有学校开始“封杀”ChatGPT</h2><p></p><p></p><p>ChatGPT 的爆红给科技界带来了很多惊喜，但作为新兴技术，ChatGPT 也面对不小的争议。</p><p></p><p>一方面，能写论文、诗歌的 ChatGPT 让学术界开始担忧学生会用其作弊。对此，纽约市教育官员还专门明令禁止学生在公立学校使用 ChatGPT。</p><p></p><p>纽约市教育局发言人 Jenna Lyle 表示，虽然 ChatGPT 可以提供快速和简单的问题答案，但它不能培养学生批判性思维和解决问题的能力，而这些对于学术和终身成功来说至关重要。</p><p></p><p>另一方面，ChatGPT 本身存在的技术局限性导致其生成的内容并不完全准确。比如，有网友指出，ChatGPT 提供的代码包含完全不相关的解释；也有网友称，ChatGPT 有时还会生成听起来合理，但既不正确又无意义的回复。</p><p></p><p>OpenAI 表示：“ChatGPT 模型还有许多局限性，所以我们计划定期更新模型，在这些方面做些改进。但我们也希望，通过提供 ChatGPT 的访问接口，获取宝贵的用户反馈，以发现我们尚未意识到的问题。”</p><p></p><h2>OpenAI 需要证明自己的盈利能力</h2><p></p><p></p><p>在争议之外，ChatGPT 还不得不面对另一个让人头疼的问题，那就是运营成本。而这，或许也正是 OpenAI 决定推出 ChatGPT 专业版的原因之一。</p><p></p><p>据了解，ChatGPT 的运营成本不菲。根据 OpenAI 联合创始人兼 CEO Sam Altman 的介绍，ChatGPT 的运营费用“令人瞠目结舌”，每次聊天的平均计算成本都要好几美分（ChatGPT 托管在微软 Azure 云上）。</p><p></p><p>为了保证 ChatGPT 能够长期运营下去，OpenAI 需要想出合适的商业化路径。在近日公司官方 Discord 上发布的公告中，OpenAI 明确表示“已经在考虑如何推动 ChatGPT 商业化”，借此“保证该工具拥有长期生命力”。</p><p></p><p>除了积极探索商业化路径，OpenAI 也在近日开始<a href=\"https://www.infoq.cn/article/ZWixRo76hFsOw38tRHNF\">寻求融资</a>\"。</p><p></p><p>据媒体 1 月 10 日报道，微软计划向 OpenAI 投资 100 亿美元（合人民币 673 亿元）以收购其 49% 股权，目前双方正在谈判，预计 OpenAI 投后估值将达到 290 亿美元。</p><p></p><p>消息显示，此前曾有一些大型 VC 公司放弃了对 OpenAI 的投资，其中一些投资者对 OpenAI 是否撑得起这样高的估值表示怀疑。</p><p></p><p>而在融资传闻流出之前，OpenAI 一直面临着从 ChatGPT 等产品中获利的压力。OpenAI 预计其 2023 年的收入将达到 2 亿美元，但与截至目前已经投入的 10 亿美元资金相比，这家初创企业的盈利能力明显还太过孱弱。</p><p></p><p>在接下来的日子里，OpenAI 需要好好证明自己的盈利能力了。</p>",
    "publish_time": "2023-01-13 14:06:22",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "抖音世界杯直播的低延迟是怎么做到的？",
    "url": "https://www.infoq.cn/article/S2Zh7B2P0V1xtZVXYAvv",
    "summary": "<p>世界杯已经结束了，梅西带领阿根廷时隔三十六年之后终于如愿捧杯。抖音直播提供的 4K 超高清超低延迟看播能力给亿万观众留下了深刻的印象，决赛的 PCU 达到 3700w+，在这样大规模并发下，如何能稳定流畅地做到更低的延迟，是一个巨大的挑战。本文主要介绍世界杯期间火山引擎视频云和相关团队在低延迟上的工作和优化，作为低延迟方向上的总结。</p><p></p><p>本文主要讨论生产和传输环节的延迟。生产环节的延迟主要受视频流供应商控制，技术团队可以实现的是，尽可能准确地测量出生产的每一个环节的实际延迟，并在发现不合理的情况时推动供应商解决。传输环节的延迟技术团队更可控，也是本次优化的重点。这部分技术能力可以作为<a href=\"https://xie.infoq.cn/article/f4c98a7b651ceaf1342f9134f\">火山引擎</a>\"视频云的优势能力积累并对外提供服务。在优化的过程中，一个越来越清晰的认知是：降低延迟并不困难，难的是延迟降低之后，怎么通过优化保证播放体验不下降甚至变得更好。</p><p></p><h2>一、背景信息</h2><p></p><p></p><p>首先简单介绍下世界杯直播的整个分发链路，还有每个环节的延迟的测量方法，让大家对整体的链路有初步的全局认识。</p><p></p><h4>（一）抖音世界杯信号分发链路</h4><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/90/901c04b61b3f5b51377411ee66a94605.png\" /></p><p></p><p></p><h4>（二）全链路延迟测量以及方法</h4><p></p><p></p><p>测算方法：</p><p>拍照视频画面上有时钟展示的(比如画面左上角或者右上角的北京时间或者比赛持续时间，一般精确到秒)，可以通过同时拍照两个播放画面的方式，记录同一时刻两个画面，然后通过照片中的时钟做差来计算。手动秒表计算如果视频画面中无时钟相关内容，那么可以从延迟低的视频画面中选取具有标志性易识别的帧启动秒表，然后观察延迟高的画面出现同样的帧画面时，停止秒表，记录秒表结果为延迟对比结果。仅适用演播室推流到抖音播放链路</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/44/44ed70e1ba1486b95d1871564cdc98bc.png\" /></p><p></p><p>计算方法：端到端延迟&nbsp;= 观众当前系统时间戳 -&nbsp;SEI&nbsp;中的时间戳，单位 ms。统计频度：每 2s 计算一次，每 10s 上报一次当前计算结果。每个 I 帧前会有一个 SEI，流规格设置为 I 帧间隔为 2s，因此每 2s 演播室推流侧会生成一个 SEI 帧。前置要求：演播室推流前进行&nbsp;NTP&nbsp;本地时钟校准。</p><p></p><p>延迟测量手册：</p><p><img src=\"https://static001.geekbang.org/infoq/13/13e02668279d4f50e85a3e90da8ecb33.png\" /></p><p></p><h2>二、生产环节的低延迟</h2><p></p><p></p><h4>（一）信号源</h4><p></p><p></p><p>网络流信号源在给到抖音之前存在多个环节，每个环节都可能会对最终的延迟有影响，但这一部分技术团队可以影响的比较少，主要是运营同学在沟通。</p><p></p><h4>（二）演播室制作环节</h4><p></p><p></p><p>演播室在收到央视的源流之后，需要加上解说和包装，所以也会引入一定的延迟。这次抖音的多个演播室是由多家第三方公司负责的，第三方公司的制作规格不一，在正式比赛之前经过大量的沟通，基本确认最重要的两个演播室的技术方案和使用的编码系统是一致的。</p><p></p><p>不过这次在演播室环节引入的延迟仍然偏高，达到了 1.5s 左右，和供应商工程师沟通后，短期内为了保证稳定，没有再进一步压缩了，这部分引入的延迟和竞品也是一致的。</p><p></p><h2>三、传输环节的低延迟</h2><p></p><p></p><p>下图是一次直播的简化的流程：</p><p><img src=\"https://static001.geekbang.org/infoq/0d/0d2132417287a6ee6bf92fbb31fbf150.png\" /></p><p></p><p>直播的传输环节里，对延迟影响大的主要是转码、分发和播放缓冲，使用实时的转码模式，转码器引入的延迟一般在 300ms 以内甚至更短。CDN 的分发环节也会带来一定的延迟，但相对也较短。为了对抗网络抖动引入的播放缓冲区引入的延迟播放缓冲引入的延迟常常会有 5s 甚至更多，所以本文主要讨论怎么在减少播放缓冲的情况下，通过不断地优化延迟降低的同时不影响整体的播放体验(不仅仅是卡顿)&nbsp;。在调优过程中，大家对播放体验也有了更细致、更深的理解，逐渐弄清楚了哪些 QoS 指标可以对关键的 QoE 指标产生直接的影响，对以后要优化的方向也更明确了。</p><p></p><h4>（一）FLV 方案</h4><p></p><p></p><p>FLV 是现在国内主流直播播放使用的协议，<a href=\"https://xie.infoq.cn/article/c39061b760f9bba3ccf5719b4\">火山引擎</a>\"对低延迟直播的探索也是从 FLV 开始的。在百万英雄、内购会等活动中，FLV 低延迟方案也多次得到了验证。</p><p></p><p>之前详细介绍过 FLV-3s 方案在抖音落地的详细实践过程(细节内容可跳转到&nbsp;<a href=\"https://mp.weixin.qq.com/s?__biz=MzI1MzYzMjE0MQ==&amp;mid=2247496039&amp;idx=1&amp;sn=9d3c0750d604d615f718cebf4382dc25&amp;scene=21#wechat_redirect\">基于 http-FLV 的抖音直播端到端延迟优化实践</a>\"），同时提出过基于 FLV 方案做更低延迟下探，所面临的挑战也会更大：更低延迟的场景对直播全链路的传输稳定性要求苛刻程度会几何倍数增加，由于端到端链路的整体 buffer 更低，生产环节或者观众网络抖动，就更容易发生卡顿。只要发生一次卡顿，延迟就会秒级增加，最终累积延迟会越来越大。而世界杯赛事延迟要求达到 2s，继续延续 FLV-3s 方案显然达不到要求，需要配合精细的追帧或者丢帧策略。</p><p></p><h5>1、基于 buffer &amp; 卡顿信息的双阈值延迟追赶策略</h5><p></p><p></p><p>音视频数据流转时序</p><p></p><p>在展开描述延迟追赶策略方案细节前，先简单介绍播放器音视频数据流转时序：网络 IO 下载音视频数据到播放器缓存 buffer-&gt;解码器从 buffer 中取数据解码并降解码后的数据存入待播放缓存-&gt;音画同步等播控策略-&gt;渲染播放音视频帧。</p><p></p><p>数据驱动 QoE &amp; QoS 优化</p><p></p><p>由于进一步下探延迟，卡顿也会随之恶化，反而延迟逐渐累积增加达不到低延迟的效果，因此延迟下探必须配合延迟追赶播控策略来确保延迟增大后可及时追赶恢复到低延迟。是否只要在延迟增加后立即倍速追赶就能满足业务的需求呢？对于延迟 QoS 指标来说的确是，但对于用户主观体验的 QoE 指标，这样的策略反而可能是负向的。</p><p></p><p>结合历史 AB 实验以及 DA 详细数据分析，有以下几点倍速追赶与 QoE 指标之间的关联现象：</p><p>倍速追赶带来的播放速度变化本身就是负面的体验倍速时长超过2秒，用户即可有感知且负向反馈倍速速度越大，播放速度前后变化&nbsp;diff&nbsp;越大，负向越严重倍速与正常速度的切换过于频繁，会带来负向反馈</p><p></p><p>综上，需要一套精细的播控策略兼顾延迟与 QoE 指标的平衡。详细方案设计如下：</p><p></p><p>输入：播放器当前 Buffer 时长、历史 Ns 内 buffer 抖动方差、历史 Ns 内卡顿信息以及追帧参数配置。</p><p>策略可配置参数以及含义映射：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6d/6da9511e5857cf19ef749162f6a401c2.png\" /></p><p></p><p>输出：目标播放速度。</p><p>原理：</p><p>基于 buffer 抖动方差 &amp; 历史卡顿信息，来定性衡量网络质量，判断是否可以追赶，只有在网络质量良好是才能触发追赶逻辑避免卡顿。追帧采用双阈值，并且支持可配置，可以控制追帧持续时长不超过 2s，同时也可以保证不频繁变速。追帧速度可配置，保证倍速变化不超过一定辐度。</p><p></p><h5>2、FLV 2s 低延迟方案在抖音上调优总结</h5><p></p><p></p><p>（1）收益总结</p><p>FLV 2s 低延迟已在抖音验证收益：核心 QoE 波动，电商指标显著正向，成本也有一定比例的节省，目前已全量。世界杯：双端 FLV-2s 方案作为世界杯低延迟方案之一，支持了开幕赛到决赛的全部赛事。</p><p></p><p>（2）调优经验总结</p><p>无论播放过程中丢帧方式追赶延迟，还是卡顿后立即丢帧追赶延迟，只要是丢帧，QoE 都是负向。iOS 端对倍速负向没有 Android 敏感，对倍速容忍度高。精细化倍速追帧策略可以满足 FLV-2s 的延迟需求，但再进一步下探延迟，就需要同时配合卡顿优化方案从源头避免延迟增加。</p><p></p><h4>（二） RTM 方案</h4><p></p><p></p><p>RTM 的方案参考了 WebRTC，可以让端到端延迟直接进入 1s 以内，已经持续在抖音上打磨了一年多，整体来说遇到的困难很大，在推进的过程也不断地发现了新的问题，也逐渐认识到，直接把&nbsp;RTC&nbsp;在视频会议上的方案应用到直播播放场景的效果并不好，需要做大量的改造才能让直播的体验得到抖音用户的认可。同时评测的同学也持续对行业内已经上线的类似方案进行了跟踪和测试，经过线上测试后，也发现现有多方案也存在很多问题, 所以一直也没有停止自研。RTM 优化的目标是在延迟降低的情况下，用户核心体验指标对齐或者优于大盘的 FLV 方案。但是由于 FLV 低延迟方案的持续优化并拿到结果，一定程度上&nbsp;RTM 的优化目标的&nbsp;bar&nbsp;是在不断提高的。</p><p></p><p>每次迭代都要经过分析数据-&gt;找到问题点-&gt;提出优化方案-&gt;完成开发和测试-&gt;AB 实验-&gt;分析数据的反复循环，每一次循环的都需要至少一个版本甚至多个版本的周期，所以项目整体耗时较长。关于如何提升实验的效率，也做了很多思考和探索。最后通过多次的实验和反复的问题解决，在核心用户体验指标基本对齐了 FLV,所以在世界杯的多场比赛中，RTM 方案也承担了一定量级的 CDN 容量，核心键指标上都对齐了大盘，稳定性和质量得到了充分的验证。</p><p></p><h5>1、RTM&nbsp;方案优化概述</h5><p></p><p></p><p>项目启动后，将 RTC 实时通信 SDK 直接集成进入播放器后首先进行线上 AB 测试，初期的实验效果显得大跌眼镜：除了端到端延迟指标符合预期以外无论是拉流成功率，首屏秒开时间，卡顿等指标均与&nbsp;FLV&nbsp;差距很大；所以 RTC 技术方案要顺利部署到直播场景，还需要配合直播播控策略进一步优化。</p><p></p><p>为了让 RTM 的综合指标对齐 FLV，从若干角度来进行 RTM 的播控逻辑定制化，所有的优化围绕着核心用户体验指标进行展开：</p><p>DNS 节点优选、SDK 信令预加载、UDP 连通性预探测主要解决的拉流成功率相关问题。SDP 信令相关优化主要解决信令时间消耗的问题(首帧时间)与成功率问题。RTC 内核播控定制化主要解决播放的卡顿问题。播放器播控逻辑结合解决的音画同步与渲染策略的问题。</p><p></p><h5>2、首帧时间的优化</h5><p></p><p></p><p>传统的 RTC 技术采用 SDP 信令方式进行媒体能力协商，SDP 信令通过如下图方式进行交互参见下图：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7a/7ab8b710f0551d2758ebbde2bc0a03f5.png\" /></p><p></p><p>但是 HTTP SDP 信令交互存在如下方案的弊端：弱网环境下(如 RTT 较大/网络信号不稳定)，HTTP 信令建联成功率不理想；导致播放请求响应缓慢或超时（基于信令数据包庞大且发生 TCP 重传导致信令响应速度不理想）；另一方面 SDP 交互传输 SDP 文本的内容很大（通常 3KB~10KB）建联的成本较高导致初始化的成本无法忍受；对比 FLV 的 HTTP 请求完成后直接完成建联和媒体数据直接传输，可以采用新的信令模式：MiniSDP 信令。这是一种基于二进制编码的压缩协议，提供对标准 SDP 协议进行压缩处理；这种方案可以降低信令交互时间，提高网络传输效能，降低直播拉流首帧渲染时间，提高拉流秒开率/成功率等 QoS 统计指标。其作用原理是将原生 SDP 转换成更小的二进制格式（300bytes）通过一个 UDP 包（MTU 限制之内）完成整个 C/S 交互。</p><p></p><p>采用 MiniSDP 信令进行媒体协商通信的信令交互流程如下图所示：采用 MiniSDP 压缩信令方式利用 UDP 网络传输；预期单个 UDP 数据包请求即可完成 SDP 完整压缩信息的传输。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ad/ad423b952e2f559ee323e261ded6f2d7.png\" /></p><p></p><p>当前 MiniSDP 信令（UDP）信令上线后观察后续的 QoS 指标发现，信令建联的成功率和首帧时间得到了大幅度的优化。</p><p></p><h5>3、拉流成功率的优化</h5><p></p><p></p><p>经过线上的 AB 实验发现：RTM 拉流成功率相比 FLV 持续存在着一定的差距，而且这种差距经过观察得知：用户的网络等级质量和用户的拉流成功率存在一定的正相关性（UDP 协议本身特性），即用户网络质量越高成功率越高。</p><p></p><p>拉流网络等级筛选</p><p></p><p>根据网络质量预估信息综合评估用户的 TCP/UDP RTT 和数据下行吞吐率，得出用户网络等级；选择网络质量优异的用户采用 RTM 拉流降低失败率。</p><p></p><p>当线上 AB 实验采用网络等级漏斗进行网络筛选以后，选择用户网络情况相对较好的这一部分的用户开启实验（这部分用户占全网用户的绝大部分，剩余的用户采用默认 FLV 低延时）,原理就是用户在拉流前综合权衡当前网络状态，当网络不适合 RTM 时候通过策略前置回落到 FLV，使得这部分用户的体验不受到影响。</p><p></p><p>UDP&nbsp;节点探测</p><p></p><p>拉流前根据用户请求的 URL 所归属的对应 CDN 边缘节点，发起 UDP 探测；一段时间内发送数据包观察对应 CDN 节点的数据 RTT 和丢包率，只有满足一定条件（如 RTT&lt;80ms 且丢包率&lt;10%）的场景才会认为 UDP 传输可以保证质量和组帧成功率。</p><p></p><p>信令预加载</p><p></p><p>在当前点播/直播房间中，预先加载后一个直播间的信令信息，提前做好 SDP 加载，降低下一个房间的首帧上屏时间。</p><p></p><h5>4、卡顿的优化</h5><p></p><p></p><p>内核 JitterBuffer 禁用丢帧优化</p><p></p><p>未调优时候经过 AB 实验发现，RTM 的视频卡顿大幅度上涨，跟预期不匹配，对此团队分析了线上的大量日志数据观察。当前的硬解具有核心用户体验指标的收益，但卡顿是 FLV 的将近 3 倍,分析了大量线上 badcase，发现部分机型网络条件较好，但帧率却极低，类似下表这种：</p><p><img src=\"https://static001.geekbang.org/infoq/55/550a27aa53dc9d89f3542c1a5ec9aea2.png\" /></p><p></p><p>这种问题在部分高热机型上的比例也是很高的，但同样的机型，FLV 播放并无这样的问题，通过对比 FLV 和 RTM 的播控策略，发现了一个关键不同点——传统的 RTC 场景优先保时延，全链路会触发各种丢帧（包括但不限于解码模块，网络模块），FLV 直播场景会优先保证观播体验（不丢帧，良好的音画同步效果）。RTM 要想减少卡顿，取得 QoE 的收益，播控策略需进行定制化，不影响连麦场景下的逻辑，内部采用新的播控策略，最后上线后卡顿显著减少。</p><p></p><p>RTC&nbsp;内核 JitterBuffer 平滑出帧优化</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0d/0df76a1e7ebc459c04b4e4d3353b62f9.png\" /></p><p></p><h5>5、播控逻辑的优化</h5><p></p><p></p><p>RTM 网络传输 SDK 的抽象：将内核进行改造，复用引擎中的网络传输-组包-JitterBuffer/NetEQ 模块；去掉解码/渲染等模块；将音视频的裸数据抛出供播放器 demuxer 集成。</p><p></p><p>解码器复用：降低解码器重新初始化的时间，降低解码首帧延时；复用解码器-渲染器的播放缓冲区控速逻辑。</p><p></p><p>音画同步的优化：RTC 音视频出帧之后在播放器侧按照 FLV 的播控逻辑进行二次音画同步处理；按照 audio master clock 主时钟进行渲染校准，视频帧渲染同步到音频时间轴上。</p><p></p><h5>6、RTM 针对世界杯的优化</h5><p></p><p></p><p>本次世界杯超高清档位的分辨率达到了 4K，对 RTM 方案的性能带来了很大的挑战，在前期测试时也发现了一些低分辨率没有的问题。当时时间非常紧，不过在正式比赛之前，还是完成了这些问题的修复，赶上了最后一班车。主要的问题和解决方案如下：</p><p>4K 高清档位卡顿严重卡顿: 优化 NACK 策略，保证更大的帧的组帧成功率。CPU/GPU 内存: 优化 video 传输 pipeline，减少不必要的 raw 数据格式转换。</p><p></p><p>最终在性能和效果都通过了测试，RTM 在世界杯期间也顺利上线，承担了一定的流量，上线后稳定性和质量都符合预期。</p><p></p><h4>（三）世界杯中抖音和其它产品平均的延迟对比</h4><p></p><p></p><p>在实际的世界杯比赛中，抖音的延迟一直领先于相同信号源的其它产品 30s 左右。即使最后两场其它产品在个别直播间上了快速追赶策略比抖音快 0~1s，但追的速度过快且持续时间超过 15s+，有明显感知，体验相对较差，这种策略在抖音上也曾经做过&nbsp;AB 实验&nbsp;，播放时长是显著负向的，所以最后并没有跟进。</p><p></p><h2>四、未来的优化方向</h2><p></p><p></p><p>未来在高清、沉浸、互动的直播场景中，针对高码率、低延迟的需求，火山引擎视频云会继续打磨现有的适合不同场景的各种低延迟的方案，同时也会不断地探索新的方案，在延迟、成本、卡顿和其它播放体验上找到适合不同场景的最佳或者最平衡的方案。</p><p></p><p>在我看来，火山引擎视频云的最大的优势，在于可以把先进的技术放到真实的海量用户的场景去做线上训练，通过不断地总结失败的教训和成功的经验，对用户体验有更深更细微的理解。下面简单介绍一下火山引擎视频云在各个方案上继续努力的方向。</p><p></p><h4>（一）FLV</h4><p></p><p></p><p>追帧策略实现更细粒度的追帧，做到“按需追帧”，避免不必要的追帧，引起 QoE 的负向。挖掘合适的传输框架，建立与边缘云节点(发送端)交互的通道，实现云端联动的拥塞控制算法，优化卡顿，避免延迟增加。目前大盘的平均延迟已经有了相当程度的降低，但有一小部分长尾用户的延迟是很大的，后期的优化方向也会适当地侧重到这部分长尾用户，让更多的长尾用户能享受到真正的低延迟，降低观看同一直播流的观众间延迟差，满足基于流内容的一些强互动玩法，比如倒计时跨年。FLV 低延迟协议标准化：沉淀适用不同直播场景(电商、赛事、游戏、演唱会等)、不同网络环境、可一键部署的套餐方案。</p><p></p><h4>（二）RTM</h4><p></p><p></p><p>在 RTM 方案上，火山引擎视频云还在不断地发掘优化点。以下几点是未来会继续探索的几个方向：</p><p></p><p>拉流成功率的持续改进</p><p>从 SDK 技术层面共性差异看，RTM 协议中的 RTP 包组首帧存在成功率短板，后续的成功率优化需要从引擎的调优持续探索。</p><p></p><p>RTP&nbsp;扩展特性的持续迭代</p><p>降低首帧时间缩小和 FLV 的差距：RTM 异步回源的深入探索，目前只有一家 CDN 支持，需要推广至其它 CDN。进一步探索提升 RTM 的拉流成功率（针对用户网络不佳的场景）：探测 ICE 多模式启播能力对成功率的提升，明确各家 CDN 支持 RTM 启播 TCP/UDP 及混合模式的能力。</p><p></p><p>RTM 是降低延迟的一种全新方案，为了把在海量用户的业务上积累的经验和教训反馈给整个业界，火山引擎视频云也联合腾讯和阿里发起了 RTM 行业标准的制订，具体可以参考<a href=\"https://www.volcengine.com/docs/6469/103014\">https://www.volcengine.com/docs/6469/103014</a>\"，未来也会把标准推广到更多的 CDN，不断完善的同时，和业界一起向更低延迟演进。</p><p></p><h4>（三）切片类协议的延迟优化</h4><p></p><p></p><p>海外的 CDN 基本都只支持切片式的协议如 HLS/Dash 等，不支持 FLV 这类“过时”的传输协议。但 HLS/Dash 因为切片的存在，而且为了保证视频的压缩率，切片一般都是秒级的，且需要切片完全生成才能分发该分片，并且需要至少两三个分片都生成完才能分发，所以和流式的协议相比，延迟上天然有一些劣势。其实这也是竞品使用的方式，如下图，每个分片 6s，在三个分片生成完后才可以分发，带来了 23s 的延迟。世界杯期间，在视频同源的情况下，其它产品的延迟显著高于&nbsp;抖音&nbsp;，就是因为使用了类似的 HLS 的切片传输方案。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7a/7ac8c42cb338f71f980453aa7d32bf1d.png\" /></p><p></p><p>但随着 Akamai 和 Apple 分别提出了 CMAF 和 LL-HLS，引入了 fmp4 和 chunk 的概念，可以实现分片没有完全生成的时候就开始分发分片的部分 chunk，延迟下限有了很大程度的下降。如下图，延迟可以降到 1s。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e3/e345930a9e9bcce7f7f9f7f2349e04b4.png\" /></p><p></p><p>火山引擎视频云在 Apple 提出 LL-HLS 之前就跟进了 CMAF，在 CMAF 的延迟和卡顿、拉流成功率上的优化上也持续有不小的投入。现在回顾 CMAF 的优化的过程，可以发现其实要解决的问题和&nbsp;RTM&nbsp;有很大的相似性，比如 CMAF 也存在拉流成功率、音画同步、性能问题，优化前在核心&nbsp;体验指标&nbsp;上同样显著差于&nbsp;FLV。</p><p></p><p>与 FLV 的流式传输不同，CMAF 需要依赖用户不断发起各个分片的请求来获取音视频数据，如果继续采用 FLV 的请求模式，即建连-&gt;请求-&gt;响应-&gt;断开连接，会引入大量的建连耗时，造成卡顿，同时导致延迟的增大。做一个简单的计算，假设每个切片是 2s，那么平均 1s 就会有一次音频或视频请求的建连，这对于网络较差，尤其是高 RTT 的用户来说是不可接受的，如果此时为了低延迟强行降低 buffer 水位，建连时的缓存消耗将导致频繁的卡顿。</p><p></p><p>为此，可以在 CMAF 上采用 QUIC 协议与连接复用结合的方式，首先 QUIC 协议的 0-RTT 建连允许客户端在服务端确认握手成功之前就发出 HTTP 请求，而连接复用直接省去了后续请求的建连操作，大幅优化了建连耗时，维持延迟的稳定。但即使如此，每个分片的请求也会引入 1-RTT 的延迟，未来将与服务端一起探索预请求模式，进一步压缩延迟、降低卡顿。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1a/1a223e80d8af8910be8bd527fc03ec1c.png\" /></p><p></p><p>CMAF 优化的整体难度较大，团队同学也经常需要在半夜和海外的 CDN 的工程师对齐和解决问题。不过经过不断的努力，最近在部分地区的也已经有了阶段性的进展，在部分场景下核心指标已经对齐 FLV，团队也有信心在最近一段时间就能去掉机型和网络类型的限制，让 CMAF 可以承载更多常规比例的流量。</p><p></p><h4>（四）XR 直播的延迟优化</h4><p></p><p></p><p>XR 直播的沉浸感以及高交互性是普通直播无法比拟的，但是这也导致了传输层需要承担更大的压力：分辨率为 8K x 4K 或 8K x 8K, 源流码率达到 50M 甚至120M、非常容易因为拥塞导致卡顿、延迟增大，甚至无法正常解码播放。火山引擎视频云的做法是将 8K 的视频切分成多个块(tile)，只传输用户视角(viewport)内的部分超高清块，其它区域只传输 2K 或 4K 分辨率的缩小后的背景流，在用户切换视角的时候再去重新请求新的超高清块。当然这里需要把切换延迟尽可能降到更低，经过长时间的优化，切换延迟已经降低到非常低，一般情况下已经感受不到切换的过程，未来会持续优化，让切换延迟更低。</p><p></p><p>这两种做法都引入了优先级的概念，即用户视角内的数据优先级高于其他部分，低清数据优先级高于高清数据。基于这种特性，火山引擎视频云将探索基于 UDP 的内容优先级感知的传输方案，优先保障高优数据的传输，对于低优数据可选择非可靠传输，即使丢失也无需重传，保证 XR 直播低延迟的同时不引入过大的视觉失真。经过优化后，在传输 8K x 8K/8K x 4K 的超高清视频时对播放端的码率要求从 120M/50M 降低到 20M/10M 左右甚至更低，在用户侧极大地减少了卡顿发生的概率，从而也减少了延迟增大的概率。</p><p></p><p>未来<a href=\"https://xie.infoq.cn/article/2b41c1bd956506770ac2529f7\">火山引擎视频云</a>\"也会持续优化 XR 直播下在更高码率更高分辨率下的卡顿和延迟，为用户提供更沉浸的观看体验。</p>",
    "publish_time": "2023-01-13 16:22:35",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "元年方舟低代码平台解读：“低代码 +PaaS”的技术创新实践",
    "url": "https://www.infoq.cn/article/ct6oJpRUKpNUmROobVFz",
    "summary": "<p>数字化转型已经成为必然趋势，几乎所有传统行业都喊出了数字化转型的口号。在数字化转型中，很多企业面临着成本高、周期长的难题，那低代码就是一种破解难题的方式，如今的低代码已经是企业数字化的核心引擎。</p><p>&nbsp;</p><p>低代码平台越来越多，如何做好平台选型也成为了令企业头疼的问题。那如今市面上的低代码平台已经发展成什么样了？低代码技术实现了哪些技术突破？遇到一个具体的业务需求，如何通过高度可配置、可扩展的低代码能力，在项目的需求调研 - 实施 - 运维阶段提供服务、提升效率、降低成本？</p><p>&nbsp;</p><p><a href=\"https://www.infoq.cn/video/QSTOa2HCmQOmSxRrD9mB\">元年科技高级产品经理徐帆在 InfoQ 技术公开课</a>\"中为大家做了详细解答，以下为公开课精华内容整理。</p><p></p><h1>一、正在数字化转型的企业都遇到了什么困境？</h1><p></p><p>&nbsp;</p><p>数字化转型的本质其实就是企业需要去在内外建立在线链接，能够对产生大量的数据进行云端，通过算法和算力进行分析以辅助企业做决策，从根本上去解决企业管理问题、提升业务运营效率。</p><p>&nbsp;</p><p>目前企业数字化转型，主要有三大驱动。第一驱动是国家政策支持，在“十四五”规划和纲要中，有人做了统计，“数字化”这个词出现了 25 次，像数字社会、数字孪生、数字技术等其他关键词出现了 60 多次；第二驱动是疫情加快了<a href=\"https://xie.infoq.cn/article/cd4b5284b86dc495a82790e55\">企业数字化转型</a>\"的速度；第三驱动是企业亟需降本增效。</p><p>&nbsp;</p><p>大家都在做数字化转型，但是这条转型之路并不平坦，有数据表示 70%的企业数字化转型都是以失败告终的。大多数企业在转型过程中都存在着四个“缺失”——缺失完整的数字化的战略、缺失数字化转型文化、缺失数字化人才、没有合适的技术平台。后两个缺失尤为关键，企业业务需求变化快，新技术层出不穷，能够与客户直接交互的数字化人才越来越紧缺，企业迫切需要一个可以稳健发展并能够平滑演进的技术平台，但传统企业的技术平台难以满足敏捷开发和客户需求。</p><p>&nbsp;</p><p>从技术层面看，企业数字化转型也面临着三个困境：</p><p></p><p>第一个困境是统一架构的企业 PaaS 平台有待建立。企业在转型的过程中，会根据企业自身的状况，去各自创建具有相同功能的一些 IT 应用，而这些应用可能往往在能力上没有达到能够去扩展功能。企业在这个时候就迫切的需要去有这么一个统一架构的企业 PaaS 平台，能够整合功能，并且能够提供标准化、公共化的服务。</p><p>&nbsp;</p><p>第二个困境是云端安全架构问题有待解决。企业上云，安全问题至关重要，数字分散使数据安全及非法访问的风险增大。</p><p></p><p>第三个困境是企业内部的“数据生态”有待建立。目前许多传统企业都还存在着一些异构的企业系统同时运转，这些系统都是各自独立的，数据相互封闭，没有实现共享和融合，形成了数据信息孤岛。如何构建数据模型，让数据与数据之间产生关联，从而打造一个数据生态，同时还可以保证信息安全，这是令企业很头疼的问题。</p><p></p><p></p><h1>二、为什么说企业数字化转型需要“低代码”？</h1><p></p><p>&nbsp;</p><p>从低代码和<a href=\"https://xie.infoq.cn/article/2a19285fa69986b3abfae953f\">数字化转型</a>\"的发展进程中我们可以看到，两者一直是相辅相成的。在行业内，低代码的定义为其可以基于可视化和模型驱动的理念，结合云原生和多端体验技术，它能够在业务场景下实现大幅度的降本提效，为专业的开发者提供一种全新的高生产力开发方式。</p><p>&nbsp;</p><p>低代码能够让不懂代码的人，通过“拖拉拽”开发组件，就能完成应用程序的搭建。主要有四大优势：</p><p>更快，组件式开发：开发周期短，组件化开发模式，配置式开发，难度低，无须精通开发语言，复用性好；更省，画布式设计：开发成本低，人工成本低，维护成本低，配置修改，无需改代码，技术人员依赖度低；更优，出错率低：质量更有保障，出错率低，模块调用中间件，界面美观、风格统一，安全性高，运行快；更活，可扩展性好：支持多类数据库，无须针对数据库单独配置，支持扩展开发，复用性好。</p><p>&nbsp;</p><p>拿低代码平台开发和传统软件开发流程做一个对比，传统开发的整个流程非常冗长，基于低代码平台进行开发，一般只用三步就可以完成。企业级的低代码开发实现的是传统软件工程到智能软件工程的一个升级。它解决了传统软件工程在开发过程中，业务与开发之间的矛盾及交付时间长的问题。基于低代码平台开发的流程可以使整个开发软件周期缩短了 45%，需求修改速度提升了 70%，同时人才招聘的压力降低。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/e8/08/e83d76278b76b86a4da106f6cb71b808.png\" /></p><p></p><p>同时低代码平台助力“业务驱动系统建设”进入快车道。业务与技术做链接，低代码平台可以为企业提供业务流引擎、业务建模、页面设计、规则引擎、数据分析模板等内容，设计过程业务人员全程可见，易于理解，减少了中间沟通环节，真正做到了业务驱动系统设计。</p><p>&nbsp;</p><p>交易与分析做链接。低代码平台是多功能集成平台，在统一云原生技术平台的基础上，无缝集成了大数据、人工智能、移动应用设计的能力。在支持快速开发创新应用的同时，可以随时引入大智移云，为企业运营提供新的助力。</p><p>&nbsp;</p><p>功能与体验做链接。<a href=\"https://xie.infoq.cn/article/f247c1afaf8f93d4cc9ed58b2\">低代码平台</a>\"贯彻了 SecDevOps 的理念，安全性贯穿平台每个细节，保证了平台上每个应用都坚不可摧。根据国际领先 UX 规范设计的组件库，从组件到系统整体信息架构上保证了极高的用户体验。</p><p>&nbsp;</p><p></p><h1>三、为什么要选择“元年方舟低代码平台”？</h1><p></p><p>&nbsp;</p><p>元年低代码平台是提供了基于低代码平台快速搭建应用的方法论和应用创建的指引，支持企业用户在平台上根据自身的需求去搭建第三方的扩展应用。低代码平台提供标准的能力，包括授权中心、业务对象、流程引擎、页面设计器等标准统一的能力。元年基于这些能力搭建标准应用、扩展应用，并会上架在元年的应用市场里，与 ISV 厂商形成商业共存。</p><p>&nbsp;</p><p>目前低代码平台的研发大多都是基于 BS 架构，采用前后端分离的研发模式，以一个技术平台为底座去形成架构。元年方舟低代码平台也是如此，元年自身技术平台支持云原生、微服务和容器化部署，支持一套完整的业务对象建模。基于面向对象的思想，元年科技将业务进行拆分，支持业务进行建模组合，其中流程引擎和规则引擎支持一些复杂的业务场景的搭建。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/d9/c5/d99f95d7935665b7f0453d70ea0766c5.png\" /></p><p></p><h4>（一）元年方舟低代码平台核心引擎能力拆解</h4><p></p><p></p><p>元年方舟低代码平台最核心的引擎能力有五个——业务建模、页面设计、规则引擎、业务流程引擎以及集成引擎。</p><p>&nbsp;</p><p>业务对象引擎是元年低代码平台的核心，所有的业务应用都是基于业务对象的基础上进行创建的。用户使用业务对象的动态建模能力进行业务建模，主要有 4 个亮点：</p><p>平台提供强力的一个模型驱动，通过业务对象与对象之间的关联连接来承载复杂的业务场景，同时支持数据动态实时追溯；可以在建模的过程中定义业务事件，根据规则触发执行来满足业务需求，全程比较灵活；可视化的配置，整个业务建模的过程中都是可视化的；业务对象开放了流程权限、规则、页面设计、导入导出等各种接口，与方舟平台内部的其他组件和第三方组件都能无缝集成。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/67/678b5ce8803a4a63b78e6f3472b3bc70.png\" /></p><p></p><p>与业务对象引擎不同，页面设计引擎的前端往往都会涉及到大量复杂的页面，比如列表页、详情页、左数右表等。元年方舟低代码平台将这些页面预置为模板，模板结合业务对象结构，一键构成样式统一的一个业务对象的页面。用户就无需再做任何其他的配置，即可直接使用。另外，元年的组件库提供了 132 个基本组件和 45 个业务组件，都是页面设计的基础元素，可根据业务需求灵活布局。此外，平台还提供了 18 种预置好的快捷页面模板，企业可以根据模板快速的去创建典型的应用。而且，多端适配、开放扩展、页面元素动态展示等功能也是页面设计引擎的小亮点。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/34/34f60550a25837b7ea01b183269d42a9.png\" /></p><p></p><p>作为最核心的流程引擎，元年方舟平台提供了图形化定义，用户只用通过简单的拖拽就能够生成审批流并可以针对不同审批节点，灵活指定审批人，此功能可以大大提升业务推进效率。主要有以下五大优势：</p><p>图形化配置：通过封装好的组件可以直接进行拖拽，快速的去设计复杂地审批流程；全流程体系：流程引擎是遵循了 BPMN2.0 的规范，支持审批业务中所有流程的一个流转模式和活动；企业权责矩阵：提供审批职责功能，支持企业根据多个维度定义权责矩阵；企业流程中心：流程管理员可以在流程中心管理所有流程实例，流程版本，流程日志；社交化驱动业务：审批过程中社交化的交换意见，快速驱动业务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9a/9a2dca9b43ed7b5d96453957387ab833.png\" /></p><p></p><p>业务流引擎与流程引擎的工作流引擎是有一定的区别的。对于元年方舟低代码平台来说，工作流引擎聚焦在业务上某一个流程的审批流的构建。而业务流引擎是更聚焦于业务的一个端到端的流程，将大目标拆解为一个个里程碑式的业务事件。业务流引擎的搭建过程主要分为三步，构建业务模型、创建业务节点，链接多个节点构建业务关系 →在业务节点上添加业务事件，驱动业务流转→在业务事件内添加数据转换、自定义活动、工作流等需要执行的业务活动。业务流引擎主要有以下4个优势：</p><p>&nbsp;</p><p>数据运行安全可控：集中管理业务数据运转，实时监控业务数据的有序运转，可随时管控干预流程降低风险；业务流程清晰可见：业务运转逻辑以流程图的方式展示，用户可直观清晰地了解每个业务节点的流转逻辑及运行效率；业务数据自由组合：每个业务节点自由连接形成端到端流程，且节点数据源支持业务对象、元对象、表单报告等多种数据；流程建模简单快速：拖拽式的业务流设计器，零学习成本用户可快速绘制业务流程图，还原出真实的业务场景。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/d4/d45f65eef18f51cdf2817acd8ec98d88.png\" /></p><p></p><p>规则引擎衔接稳定的底层架构和快速变化的业务，是业务中台的重要组成部分。规则引擎综合考虑业务的复杂性、稳态常规业务和敏态业务的比例、业务和 IT 的依赖强度等因素，将业务决策从应用代码中分离出来，支持用户使用类自然语言编写业务规则，接受数据输入，解释业务规则并根据业务规则作出业务决策。</p><p><img src=\"https://static001.geekbang.org/infoq/80/80b4e19b5c5854010aeb52c761b2059b.png\" /></p><p></p><p>系统集成引擎提供标准的二开接口和系统集成能力。结合企业内外部的诉求，平台提供标准的二开接口和系统集成能力，可以与 OA 系统、ERP 系统、CRM 系统、钉钉、微信、短信平台等平台进行集成。此外，元年方舟低代码平台也是支持代码多层级二开架构的，支持企业个性化的需求。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/71/715f65ec241e290a2f55d70a4e13d597.png\" /></p><p></p><p></p><h4>（二）元年方舟低代码平台云原生技术架构介绍</h4><p></p><p>&nbsp;</p><p>整个方舟低代码平台采用云原生技术，主要涉及微服务、容器编排、DevOps 及可观测性四方面技术。</p><p>&nbsp;</p><p>关于微服务的架构，元年方舟低代码平台采用 SpringCloud 框架，系统中每一个微服务被独立的部署，各个微服务之间是松耦合的，加快了应用交付时间。从微服务治理方面，元年科技有自己的一套方案，包括网关、注册中心、配置中心、安全中心、服务容错和服务监控等等。比如每一个服务在注册中心进行注册，提供服务的位置信息、IP 地址、端口；又如注册列表支持负载均衡和智能路由，智能监测服务的健康状态、实例调用的情况等；再如配置中心集中管理项目中各种配置参数开关，封装屏蔽了配置管理的细节和配置的不同格式，提供标准接口供服务调取。</p><p>&nbsp;</p><p>同时，平台通过 Docker 完成镜像部署，用户通过负载均衡策略和服务网关、路由配置等访问到对应的服务应用，同时也会受到熔断限流等策略的约束，避免某个服务故障后产生连锁反应和雪崩效应。同时在服务治理层面，元年方舟平台还可以进行链路追踪、日志监控、流量监控和管理监控。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/32/32311581f20c84163dc38b779d6c5db7.png\" /></p><p></p><p>关于容器编排，元年方舟低代码平台采用 K8s 提供持续的编排能力，其可根据运行资源、状态进行实例的扩容和伸缩，以及进行资源的隔离，进行安全的防护和自我的修复，这可以在一定程度上帮企业实现降本增效的目的。平台提供 K8s 运行面板，资源管控和故障记录均可实现可视化。</p><p>&nbsp;</p><p>关于 DevOps，元年方舟低代码平台主要聚焦在 CI/CD 流水线上，覆盖了研发、持续集成、测试和生产的四个阶段。使平台开发编码到测试，再到 K8s 部署全程实现自动化，大幅提升了代码部署的交互效率和交互质量，快速实现研发迭代。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/47/4758ddc37bb39e9608439aa8ece37430.png\" /></p><p></p><p>关于可观测性，元年方舟低代码平台的监控中心就很值得一提。在监控中心，Prometheus 通过采集工具在数据层进行采集，拉取监控指标，通过自定义的告警信息进行告警的配置，当检测到异常则发送消息，消息不限于邮件或者其他形式。视图层将展示整个监控画面，整个监控系统可以根据丰富的告警规则进行监控预警，能够采集到的监控的覆盖面也很广，而且可视化的看板的数据可读性高。最重要的是企业可以对该功能“开箱即用”，并且还可以根据自己需求进行功能拓展。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/59/59c8c04fe8f27f158d9cbd6df4437b1a.png\" /></p><p></p><p>除了以上提到的五大核心引擎能力和云原生架构，元年方舟低代码平台在构建过程中，也设置了一系列的安全机制和防护措施。要知道，对于低代码平台来说，安全一直都是大家在密切关注的问题。所以，元年方舟低代码平台提供了关键数据的加密储存，提供了统一的认证授权中心以及 HTTPS 的加密通信，拥有统一的网关控制和超级严格的参数校验，对传输数据防篡改设置了不少安全机制。对于正在数字化转型中的企业来说，是一个很不错的选择。</p><p></p><p>更多内容请关注元年方舟低代码平台官网：<a href=\"https://www.yuanian.com/cpfw/fz/ddm/\">https://www.yuanian.com/cpfw/fz/ddm/</a>\"</p>",
    "publish_time": "2023-01-13 16:39:12",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "加速多样化算力释放，超聚变发布服务器操作系统FusionOS 23等三大算力新品",
    "url": "https://www.infoq.cn/article/Uj5ugZHsOSxdNxoKLYLW",
    "summary": "<p>2023 年 1 月 12 日，以“南北东西，焕然一新”为主题的超聚变2023新品发布会在北京举行。会上，<a href=\"https://www.infoq.cn/article/8vW6cjL6TG7BqYu38TgV\">超聚变</a>\"重磅发布三款算力新品：全新一代FusionServer V7智能服务器，FusionPoD整机柜服务器，以及服务器操作系统FusionOS 23。</p><p></p><h2>服务器操作系统新版FusionOS 23正式发布</h2><p></p><p></p><p>在算力服务领域，超聚变算力服务领域总裁郝峰重磅发布了服务器操作系统FusionOS 23。FusionOS是一款基于openEuler打造的支持多样性算力的国产化操作系统，它是首个通过欧拉技术路线认证的操作系统发行版，支持主流的计算架构。</p><p></p><p>据其介绍，超聚变服务器<a href=\"https://www.infoq.cn/article/4lDxHRoqXbSw6zl29AEo\">操作系统</a>\"提供了完善的CentOS替换解决方案，一站式迁移包含了OS迁移、OS托管、<a href=\"https://www.infoq.cn/article/TpGZGpR2o8kYZRdp73rQ\">openEuler</a>\"技术支持，原地迁移和部署迁移两种模式灵活选择，同时可支持1个人1套工具并发迁移200台服务器操作系统，实现迁移效率相比其他操作系统提升10倍，大幅降低了迁移和运维成本。</p><p></p><p>在新技术应用方面，本次发布的FusionOS 23采用欧拉5.10内核版本，全面支持eBPF技术并增强了网络运维及监控能力。它同时还是首个支持第四代英特尔® 至强® 可扩展处理器的国产操作系统发行版。未来，超聚变将继续携手生态伙伴，与欧拉生态创新中心一起，促进生态繁荣。</p><p></p><p>中国联通云计算事业部基础技术研发部总监钟忻表示，联通云和FusionOS正围绕着操作系统迁移问题共同探索最佳解决方案，旨在实现现网业务安全高效迁移。在多样性算力、云原生、内生安全等方面，超聚变和联通云也将持续展开联合创新，助力夯实联通云算力引擎底座。</p><p></p><h2>发布FusionServer V7智能服务器与FusionPoD整机柜服务器</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/bf/bfbd7cebb2442452cde2d4b148e6a06a.png\" /></p><p></p><p>据介绍，全新一代FusionServer V7服务器搭载了第四代英特尔®至强®可扩展处理器，围绕高效、智能和安全可靠等方面，主要有三大优势。</p><p></p><p>第一，通过CPU调优、自研电源、节能算法、散热和高速互联等关键技术，实现了综合性能领先业界10%，以及同等配置下节能8%。在最新的SPEC打榜测试中，SPECcpu和SPECpower测试均取得第一的好成绩。</p><p></p><p>第二，通过内嵌系列AI算法技术，实现了对内存、硬盘、整机的故障诊断、预测和自愈等，帮助客户减少业务中断的风险。其中，AI内存故障自愈技术，可以将内存引起的系统宕机率降低66%；AI硬盘故障预测专利技术，可以提前5分钟预测慢盘故障，避免业务受影响；AI故障诊断FDM2.0技术，诊断准确率达到96%，领先业界，可以大幅提升运维效率，降低运维成本。</p><p></p><p>第三，兼容东西双生态，打造最强端到端算力安全，比如自研BMC芯片和软件，软件100%完成白盒测试，服务器系统通过CC EAL4+业界最高等级安全认证。</p><p></p><p>超聚变算力基础设施领域总裁唐启明表示：“算力是数字经济发展的核心驱动力，千行百业的新型数字化转型大幕已拉开，超聚变率先融合东西方产业生态，整合南北向软硬件，布局无边界计算，为客户提供高效、智能、安全可靠的算力基础设施，为加速行业的数字化转型助力。”</p><p></p><p>英特尔市场营销集团副总裁、中国区总经理王稚聪表示：“面对数字化带来的前所未有的巨大机遇，英特尔将持续推动产品和技术创新，为生态持续赋能，与像超聚变这样的优质伙伴一起助力产业向纵深发展。”</p><p></p><p>会上，超聚变算力基础设施领域总裁唐启明与英特尔市场营销集团副总裁、中国区总经理王稚聪联合发布了FusionPoD整机柜服务器。</p><p></p><p>据介绍，FusionPoD整机柜服务器垂直整合数据中心L1/L2资源、提升数据中心运营效率为设计理念，通过先进的集中供电、总线盲插和原生液冷技术，具备以下特点：超高算力密度、超级智能、原生液冷设计。</p><p></p><p>供电方面，FusionPoD整机柜服务器具备业界独有的CQC 6级认证（超钛金）电源模块，转换效率高达96.5%；散热方面，创新的高密铲齿冷板，支持单芯片散热能力超过800W；数据通信方面，高速无缘线缆背板技术实现数据通信速率是业界的2倍。</p><p></p><p>FusionPoD整机柜服务器首创电、网、液三总线设计，柜内0线缆维护；所有节点支持盲插，可支撑面向未来的机器人无人化运维；整机柜交付至客户机房，现场0安装，上线效率提升10+倍。通过高效冷板与无源水冷背门设计相结合，FusionPoD整机柜服务器实现100%全液冷，并获得业界首个南德能效认证证书。</p><p></p><p>截至目前，FusionPoD整机柜服务器已全面规模化商用，现网部署超5万节点。</p>",
    "publish_time": "2023-01-13 17:31:11",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "百万Twitter用户集体出逃，“反推特平台”Mastodon火了",
    "url": "https://www.infoq.cn/article/8cCHD4twQffIKwyC23OT",
    "summary": "<p></p><p></p><blockquote>不止 Web 3，互联网去中心化的新希望还有Mastodon。</blockquote><p></p><p></p><h2>Medium宣布将推出Mastodon实例</h2><p></p><p></p><p>据悉，Medium日前宣布将推出Mastodon（长毛象）实例me.dm。</p><p></p><p>不同于“生杀大权”高度集中的Twitter，<a href=\"https://blog.medium.com/medium-embraces-mastodon-19dcb873eb11\">Mastodon</a>\" （长毛象）是一个去中心化的社交平台，它没有人工智能算法驱动的推荐机制和内容审核功能，禁止广告，拒绝商业化。该平台的基本规则反映了欧洲对人类尊严的重视，禁止仇恨言论、性别歧视、种族主义、恐跨性别言论和恐同言论。</p><p></p><p>2015年，德国软件开发者尤金·罗奇科（Eugen Rochko）出于对美国社交网络平台的失望而开发了Twitter的竞品“长毛象（Mastodon）”。</p><p></p><p>Medium首席执行官Tony Stubblebine表示，此举希望帮助作者以及其出版物和读者在fediverse中找到新的交互空间。</p><p></p><p>Medium的使命是通过分享好的观点和信息帮助人们加深对世界的理解。这项使命并不受限于具体媒介。长久以来，Medium一直专注于严肃文章的创作，Medium这个名称也是在表达希望成为网络中高质量文章的发源地。</p><p></p><p>相比之下，Mastodon上的发布内容一般不超过500个字符。但Medium也认为，应当顺应新的趋势，因此计划将内容扩展至Mastodon实例me.dm上的短篇medium（为了与原本强调中篇的Medium做区分，这里的「m」是小写）。</p><p></p><p>除了篇幅更短外，Mastodon还围绕“联邦”这个概念做出了创新。</p><p></p><p>联邦是一种去中心化的实现形式。这意味着人们并不集中在同一个社区，而是各自归属于不同社区，但同样能够相互交流。这些社区，也就是所谓的Mastodon实例。在加入Mastodon时，用户需要选择一个社区作为自己的大本营。而相互对话的各实例集合就被称为“Fediverse”。</p><p></p><p>“我们的目标，是让me.dm实例成为更多人的网上家园”，Tony Stubblebine表示。</p><p></p><p>Medium称，接下来，将邀请所有Medium作者和读者加入进来，这也将成为Medium会员系统内的附加服务。此外，Medium还正在开发“使用Medium注册”选项，帮助用户更轻松地开启Mastodon之旅，找到自己感兴趣的人和主题。点击<a href=\"https://me.dm/auth/sign_up\">此处</a>\"可申请加入。</p><p></p><p>面对成百上千的Mastodon实例选项，Medium打算为me.dm设计一些独特优势：可靠的基础设施与适度管理，保持简短域名以降低共享难度，采用更友好的新用户参与流程，高质量的本地内容推送。</p><p></p><p>与其他新平台一样，Mastodon也有自己的学习曲线。毕竟Mastdon是个拥有900万注册用户的庞大生态，其中已经存在大量侧重于消除“有毒”社交元素的现行规范。</p><p></p><p>正因为如此，Medium决定不直接向所有Medium读者全面开放。Medium会整理出清晰的韦恩图，确保选取其中Medium与Mastodon最精华的交集部分。Tony Stubblebine称，“我们双方对于健康的社区规范有着类似的观点，相信能够良好完成融合。我们认为这种基于社区规范的多方联合，正是社交媒体中最令人兴奋的创新根源”。</p><p></p><h2>Mastodon：燃起互联网去中心化的新希望</h2><p></p><p></p><h3>逃离Twitter运动</h3><p></p><p>去中心化肯定不止于Web 3，Mastodon和Fediverse的迅速流行就是个值得研究的有趣案例。Mastodon遵循的是早期联合社交网络的设计思路，代表一种去中心化理念。</p><p></p><p>“逃离Twitter”运动仍在持续。在技术和主流出版物中，出现了大量用户从Twitter流失到Mastodon的文章。值得一提的是，自马斯克收购Twitter以来，Mastodon的活跃用户数量从30万飙升至260万。有数据显示，有约百万Twitter用户转移到了Mastodon上。</p><p></p><p>Twitter并不是个整体，它是一套巨大的分布式系统，由大量微服务组成。下面来看Twitter基础设施博文中的表述：</p><p></p><p>我们实时处理约4000亿个事件，每天生成PB级别数据。我们从多种多样的事件源处消费数据，其各自产生于不同的平台和存储系统，例如Hadoop、Vertica、Manhattan 分布式数据库、Kafka、Twitter Eventbus、GCS、BigQuery&nbsp;和&nbsp;PubSub。</p><p></p><p>但在组织层面，Twitter又是高度中心化的。 如果Twitter决定更改其API，该公司完成可以单方面将意愿转化成现实，进而损害一切需要使用该API的第三方应用程序。同样的，Twitter也可以、并确实单方面改变了内容审核、用户封禁等管理政策，这也是大量用户选择出逃的原因。</p><p></p><p>与之对应，Mastodon和Fediverse中的各类应用程序在组织上同样保持分布。Mastodon服务器的每个实例都由个人或团队运行，他们可以就服务运行技术和实例内的策略应用做出判断。当然，这种“分权于民”的做法带来了极高的上手难度，比如需要用户动手运营生产级别的严肃实例。</p><p></p><h3>Mastodon：去中心化的范例</h3><p></p><p></p><p>有些网友评论说，<a href=\"https://www.theregister.com/2023/01/01/mastodon_activitypub/\">Mastodon</a>\"也不是真正的去中心化，因为跨实例用户分布遵循类似Zipf的模式。有人做出分析，发现97%的Mastodon用户都集中在前5%的实例当中。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e8/e8e3d8daa5755fe54c8e675172f9213f.png\" /></p><p></p><p>图表显示，最多Mastodon用户集中在少数最大的实例当中。</p><p></p><p>但实际上这恰恰意味着去中心化取得了良好进展。没错，某些大实例的用户已接近百万。根据instances.social数据显示，aus.social目前拥有约20000名用户，在实例人气榜是排名第50。@SystemsAppr所在的discuss.systems则拥有1200多名用户，位次在400名左右。</p><p></p><p>面对数以千计的活跃实例，再加上每天新增的更多实例，这显然不是什么过度中心化的体现。如果Mastodon继续保持目前的增长速度，那后面的发展趋势无疑令人期待。</p><p></p><p>去中心化的另一个问题，在于这些实例是如何运行在底层互联网基础设施上的。 如前文所述，互联网的中心化趋势体现在其高度依赖于少数服务，例如Cloudflare、Fastly和Akamai。如果其中一项服务发生中断，互联网就会受到沉重打击。而Mastodon在这方面的统计数字似乎更令人安心。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/56/56155fcd276c529376e8cc2668bde603.png\" /></p><p></p><p>按托管的Mastodon实例数量排序，vanlueckn [at] gametoots.de整理出了排名前15位的ASN。其中占比最大的是“其他”。</p><p></p><p>所以至少肉眼观察，可以说Mastodon并不会对少数ISP构成严重依赖。而且Cloudflare所管理的Mastodon实例似乎也没超过10%（只是初步结论，并未经过严格论证）。再有，整个数据集共包含约30000个实例，这对我们来说已经足够去中心化了。</p><p></p><p>Mastodon有助于保持互联网去中心化的另一个证据，就是用户可以轻松在不同实例间往来迁移。 很多新用户在选择Mastodon实例时犹豫不决，传统社交网络明显没这方面问题。虽然可以观察各实例的运行稳定性和内容管理政策，但想选到最适合自己的实例确实没那么简单。</p><p></p><p>可归功于ActivityPub的设计理念和Mastodon的具体实现，用户可以轻松从一个实例迁移至另一实例，而且直接带走所有关注者（这是传统社交网络无法实现的）。</p><p></p><p>这种用户自由迁移的能力，让新实例能持续拥有吸引用户的空间，大家根本不用担心被困在自己不喜欢的实例上。</p><p></p><h3>ActivityPub协议：去中心化互联网重要底层协议</h3><p></p><p></p><p>Mastodon的底层技术是ActivityPub，万维网联盟（W3C）指定的协议。 换言之，Mastodon是ActivityPub的一个具体实现。</p><p></p><p>ActivityPub是发布-订阅系统长期研究下的成果。不少研究文章都讨论过这项协议所支撑的去中心化社交媒体具有哪些独特优势。简言之，如果社交网络的运营不再由单一企业大权独揽，那试验和创新的空间也将豁然开朗。</p><p></p><p>事实也的确如此，大量关于Mastodon的部署实验陆续涌现、参与者们共享数据，而且出现了一系列超规Mastodon服务器（例如GoToSocial、Takahe）等不同的AcitivityPub实现。</p><p></p><p>这里强调一下ActivityPub协议所扮演的核心角色。Mastodon的大部分功能都依托于ActivityPub，包括：1）建立社交网络（使用ActivityPub）；2）作为ActivityPub的最常见服务器实现；3）让用户通过移动应用（客户端）与Mastodon实例会话。</p><p></p><p>但正如HTTP协议催生出大量Web浏览器和服务器实现，ActivityPub的具体服务器和客户端实现也是多种多样。</p><p></p><p>由于ActivityPub的某些实现跟Mastodon完全不是一个类别（例如Pixelfed建立的是图像共享社交网络，BookWyrm则是社交图书评级与评论服务），所以情况难以一概而论。但感谢W3C，ActivityPub这一稳定标准协议的存在为我们提供了在各个层面上开展创新的坚实基础，客户端、服务器乃至应用程序都没问题。</p><p></p><p>这里还有弹性空间：如果目前的Mastodon服务器实现因为某种原因而不可持续，开发人员也完全可以创建出新的、甚至是更好的ActivityPub实现。事实上，大家就是这么做的，所以才有了缤纷多彩的互联网世界。</p><p></p><p>当然，稳定协议的存在也是把双刃剑：在同一组织之内，对协议做出实质性更改、甚至用其他标准（例如gRPC）进行替换都很容易；但当开发团队的独立产出成果多到一定程度，想在不同组件间找到稳定可行的API就没那么简单了。</p><p></p><p>不过互联网的发展历程告诉我们，只要依托于明确规定的协议鼓励应用及其具体实现，就能创造出长达数十年的创新与增长期。这里我们可以乐观地判断，ActivityPub将成为未来去中心化互联网中最重要的底层协议之一。</p><p></p><p>参考链接：</p><p></p><p><a href=\"https://www.theregister.com/2023/01/01/mastodon_activitypub/\">https://www.theregister.com/2023/01/01/mastodon_activitypub/</a>\"</p><p></p><p><a href=\"https://blog.medium.com/medium-embraces-mastodon-19dcb873eb11\">https://blog.medium.com/medium-embraces-mastodon-19dcb873eb11</a>\"</p>",
    "publish_time": "2023-01-13 19:02:02",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]